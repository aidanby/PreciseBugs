{"buggy_code": ["/*\n * fs/dcache.c\n *\n * Complete reimplementation\n * (C) 1997 Thomas Schoebel-Theuer,\n * with heavy changes by Linus Torvalds\n */\n\n/*\n * Notes on the allocation strategy:\n *\n * The dcache is a master of the icache - whenever a dcache entry\n * exists, the inode will always exist. \"iput()\" is done either when\n * the dcache entry is deleted or garbage collected.\n */\n\n#include <linux/syscalls.h>\n#include <linux/string.h>\n#include <linux/mm.h>\n#include <linux/fs.h>\n#include <linux/fsnotify.h>\n#include <linux/slab.h>\n#include <linux/init.h>\n#include <linux/hash.h>\n#include <linux/cache.h>\n#include <linux/export.h>\n#include <linux/mount.h>\n#include <linux/file.h>\n#include <linux/uaccess.h>\n#include <linux/security.h>\n#include <linux/seqlock.h>\n#include <linux/swap.h>\n#include <linux/bootmem.h>\n#include <linux/fs_struct.h>\n#include <linux/hardirq.h>\n#include <linux/bit_spinlock.h>\n#include <linux/rculist_bl.h>\n#include <linux/prefetch.h>\n#include <linux/ratelimit.h>\n#include <linux/list_lru.h>\n#include <linux/kasan.h>\n\n#include \"internal.h\"\n#include \"mount.h\"\n\n/*\n * Usage:\n * dcache->d_inode->i_lock protects:\n *   - i_dentry, d_u.d_alias, d_inode of aliases\n * dcache_hash_bucket lock protects:\n *   - the dcache hash table\n * s_anon bl list spinlock protects:\n *   - the s_anon list (see __d_drop)\n * dentry->d_sb->s_dentry_lru_lock protects:\n *   - the dcache lru lists and counters\n * d_lock protects:\n *   - d_flags\n *   - d_name\n *   - d_lru\n *   - d_count\n *   - d_unhashed()\n *   - d_parent and d_subdirs\n *   - childrens' d_child and d_parent\n *   - d_u.d_alias, d_inode\n *\n * Ordering:\n * dentry->d_inode->i_lock\n *   dentry->d_lock\n *     dentry->d_sb->s_dentry_lru_lock\n *     dcache_hash_bucket lock\n *     s_anon lock\n *\n * If there is an ancestor relationship:\n * dentry->d_parent->...->d_parent->d_lock\n *   ...\n *     dentry->d_parent->d_lock\n *       dentry->d_lock\n *\n * If no ancestor relationship:\n * if (dentry1 < dentry2)\n *   dentry1->d_lock\n *     dentry2->d_lock\n */\nint sysctl_vfs_cache_pressure __read_mostly = 100;\nEXPORT_SYMBOL_GPL(sysctl_vfs_cache_pressure);\n\n__cacheline_aligned_in_smp DEFINE_SEQLOCK(rename_lock);\n\nEXPORT_SYMBOL(rename_lock);\n\nstatic struct kmem_cache *dentry_cache __read_mostly;\n\n/*\n * This is the single most critical data structure when it comes\n * to the dcache: the hashtable for lookups. Somebody should try\n * to make this good - I've just made it work.\n *\n * This hash-function tries to avoid losing too many bits of hash\n * information, yet avoid using a prime hash-size or similar.\n */\n\nstatic unsigned int d_hash_mask __read_mostly;\nstatic unsigned int d_hash_shift __read_mostly;\n\nstatic struct hlist_bl_head *dentry_hashtable __read_mostly;\n\nstatic inline struct hlist_bl_head *d_hash(unsigned int hash)\n{\n\treturn dentry_hashtable + (hash >> (32 - d_hash_shift));\n}\n\n#define IN_LOOKUP_SHIFT 10\nstatic struct hlist_bl_head in_lookup_hashtable[1 << IN_LOOKUP_SHIFT];\n\nstatic inline struct hlist_bl_head *in_lookup_hash(const struct dentry *parent,\n\t\t\t\t\tunsigned int hash)\n{\n\thash += (unsigned long) parent / L1_CACHE_BYTES;\n\treturn in_lookup_hashtable + hash_32(hash, IN_LOOKUP_SHIFT);\n}\n\n\n/* Statistics gathering. */\nstruct dentry_stat_t dentry_stat = {\n\t.age_limit = 45,\n};\n\nstatic DEFINE_PER_CPU(long, nr_dentry);\nstatic DEFINE_PER_CPU(long, nr_dentry_unused);\n\n#if defined(CONFIG_SYSCTL) && defined(CONFIG_PROC_FS)\n\n/*\n * Here we resort to our own counters instead of using generic per-cpu counters\n * for consistency with what the vfs inode code does. We are expected to harvest\n * better code and performance by having our own specialized counters.\n *\n * Please note that the loop is done over all possible CPUs, not over all online\n * CPUs. The reason for this is that we don't want to play games with CPUs going\n * on and off. If one of them goes off, we will just keep their counters.\n *\n * glommer: See cffbc8a for details, and if you ever intend to change this,\n * please update all vfs counters to match.\n */\nstatic long get_nr_dentry(void)\n{\n\tint i;\n\tlong sum = 0;\n\tfor_each_possible_cpu(i)\n\t\tsum += per_cpu(nr_dentry, i);\n\treturn sum < 0 ? 0 : sum;\n}\n\nstatic long get_nr_dentry_unused(void)\n{\n\tint i;\n\tlong sum = 0;\n\tfor_each_possible_cpu(i)\n\t\tsum += per_cpu(nr_dentry_unused, i);\n\treturn sum < 0 ? 0 : sum;\n}\n\nint proc_nr_dentry(struct ctl_table *table, int write, void __user *buffer,\n\t\t   size_t *lenp, loff_t *ppos)\n{\n\tdentry_stat.nr_dentry = get_nr_dentry();\n\tdentry_stat.nr_unused = get_nr_dentry_unused();\n\treturn proc_doulongvec_minmax(table, write, buffer, lenp, ppos);\n}\n#endif\n\n/*\n * Compare 2 name strings, return 0 if they match, otherwise non-zero.\n * The strings are both count bytes long, and count is non-zero.\n */\n#ifdef CONFIG_DCACHE_WORD_ACCESS\n\n#include <asm/word-at-a-time.h>\n/*\n * NOTE! 'cs' and 'scount' come from a dentry, so it has a\n * aligned allocation for this particular component. We don't\n * strictly need the load_unaligned_zeropad() safety, but it\n * doesn't hurt either.\n *\n * In contrast, 'ct' and 'tcount' can be from a pathname, and do\n * need the careful unaligned handling.\n */\nstatic inline int dentry_string_cmp(const unsigned char *cs, const unsigned char *ct, unsigned tcount)\n{\n\tunsigned long a,b,mask;\n\n\tfor (;;) {\n\t\ta = *(unsigned long *)cs;\n\t\tb = load_unaligned_zeropad(ct);\n\t\tif (tcount < sizeof(unsigned long))\n\t\t\tbreak;\n\t\tif (unlikely(a != b))\n\t\t\treturn 1;\n\t\tcs += sizeof(unsigned long);\n\t\tct += sizeof(unsigned long);\n\t\ttcount -= sizeof(unsigned long);\n\t\tif (!tcount)\n\t\t\treturn 0;\n\t}\n\tmask = bytemask_from_count(tcount);\n\treturn unlikely(!!((a ^ b) & mask));\n}\n\n#else\n\nstatic inline int dentry_string_cmp(const unsigned char *cs, const unsigned char *ct, unsigned tcount)\n{\n\tdo {\n\t\tif (*cs != *ct)\n\t\t\treturn 1;\n\t\tcs++;\n\t\tct++;\n\t\ttcount--;\n\t} while (tcount);\n\treturn 0;\n}\n\n#endif\n\nstatic inline int dentry_cmp(const struct dentry *dentry, const unsigned char *ct, unsigned tcount)\n{\n\t/*\n\t * Be careful about RCU walk racing with rename:\n\t * use 'lockless_dereference' to fetch the name pointer.\n\t *\n\t * NOTE! Even if a rename will mean that the length\n\t * was not loaded atomically, we don't care. The\n\t * RCU walk will check the sequence count eventually,\n\t * and catch it. And we won't overrun the buffer,\n\t * because we're reading the name pointer atomically,\n\t * and a dentry name is guaranteed to be properly\n\t * terminated with a NUL byte.\n\t *\n\t * End result: even if 'len' is wrong, we'll exit\n\t * early because the data cannot match (there can\n\t * be no NUL in the ct/tcount data)\n\t */\n\tconst unsigned char *cs = lockless_dereference(dentry->d_name.name);\n\n\treturn dentry_string_cmp(cs, ct, tcount);\n}\n\nstruct external_name {\n\tunion {\n\t\tatomic_t count;\n\t\tstruct rcu_head head;\n\t} u;\n\tunsigned char name[];\n};\n\nstatic inline struct external_name *external_name(struct dentry *dentry)\n{\n\treturn container_of(dentry->d_name.name, struct external_name, name[0]);\n}\n\nstatic void __d_free(struct rcu_head *head)\n{\n\tstruct dentry *dentry = container_of(head, struct dentry, d_u.d_rcu);\n\n\tkmem_cache_free(dentry_cache, dentry); \n}\n\nstatic void __d_free_external(struct rcu_head *head)\n{\n\tstruct dentry *dentry = container_of(head, struct dentry, d_u.d_rcu);\n\tkfree(external_name(dentry));\n\tkmem_cache_free(dentry_cache, dentry); \n}\n\nstatic inline int dname_external(const struct dentry *dentry)\n{\n\treturn dentry->d_name.name != dentry->d_iname;\n}\n\nstatic inline void __d_set_inode_and_type(struct dentry *dentry,\n\t\t\t\t\t  struct inode *inode,\n\t\t\t\t\t  unsigned type_flags)\n{\n\tunsigned flags;\n\n\tdentry->d_inode = inode;\n\tflags = READ_ONCE(dentry->d_flags);\n\tflags &= ~(DCACHE_ENTRY_TYPE | DCACHE_FALLTHRU);\n\tflags |= type_flags;\n\tWRITE_ONCE(dentry->d_flags, flags);\n}\n\nstatic inline void __d_clear_type_and_inode(struct dentry *dentry)\n{\n\tunsigned flags = READ_ONCE(dentry->d_flags);\n\n\tflags &= ~(DCACHE_ENTRY_TYPE | DCACHE_FALLTHRU);\n\tWRITE_ONCE(dentry->d_flags, flags);\n\tdentry->d_inode = NULL;\n}\n\nstatic void dentry_free(struct dentry *dentry)\n{\n\tWARN_ON(!hlist_unhashed(&dentry->d_u.d_alias));\n\tif (unlikely(dname_external(dentry))) {\n\t\tstruct external_name *p = external_name(dentry);\n\t\tif (likely(atomic_dec_and_test(&p->u.count))) {\n\t\t\tcall_rcu(&dentry->d_u.d_rcu, __d_free_external);\n\t\t\treturn;\n\t\t}\n\t}\n\t/* if dentry was never visible to RCU, immediate free is OK */\n\tif (!(dentry->d_flags & DCACHE_RCUACCESS))\n\t\t__d_free(&dentry->d_u.d_rcu);\n\telse\n\t\tcall_rcu(&dentry->d_u.d_rcu, __d_free);\n}\n\n/*\n * Release the dentry's inode, using the filesystem\n * d_iput() operation if defined.\n */\nstatic void dentry_unlink_inode(struct dentry * dentry)\n\t__releases(dentry->d_lock)\n\t__releases(dentry->d_inode->i_lock)\n{\n\tstruct inode *inode = dentry->d_inode;\n\tbool hashed = !d_unhashed(dentry);\n\n\tif (hashed)\n\t\traw_write_seqcount_begin(&dentry->d_seq);\n\t__d_clear_type_and_inode(dentry);\n\thlist_del_init(&dentry->d_u.d_alias);\n\tif (hashed)\n\t\traw_write_seqcount_end(&dentry->d_seq);\n\tspin_unlock(&dentry->d_lock);\n\tspin_unlock(&inode->i_lock);\n\tif (!inode->i_nlink)\n\t\tfsnotify_inoderemove(inode);\n\tif (dentry->d_op && dentry->d_op->d_iput)\n\t\tdentry->d_op->d_iput(dentry, inode);\n\telse\n\t\tiput(inode);\n}\n\n/*\n * The DCACHE_LRU_LIST bit is set whenever the 'd_lru' entry\n * is in use - which includes both the \"real\" per-superblock\n * LRU list _and_ the DCACHE_SHRINK_LIST use.\n *\n * The DCACHE_SHRINK_LIST bit is set whenever the dentry is\n * on the shrink list (ie not on the superblock LRU list).\n *\n * The per-cpu \"nr_dentry_unused\" counters are updated with\n * the DCACHE_LRU_LIST bit.\n *\n * These helper functions make sure we always follow the\n * rules. d_lock must be held by the caller.\n */\n#define D_FLAG_VERIFY(dentry,x) WARN_ON_ONCE(((dentry)->d_flags & (DCACHE_LRU_LIST | DCACHE_SHRINK_LIST)) != (x))\nstatic void d_lru_add(struct dentry *dentry)\n{\n\tD_FLAG_VERIFY(dentry, 0);\n\tdentry->d_flags |= DCACHE_LRU_LIST;\n\tthis_cpu_inc(nr_dentry_unused);\n\tWARN_ON_ONCE(!list_lru_add(&dentry->d_sb->s_dentry_lru, &dentry->d_lru));\n}\n\nstatic void d_lru_del(struct dentry *dentry)\n{\n\tD_FLAG_VERIFY(dentry, DCACHE_LRU_LIST);\n\tdentry->d_flags &= ~DCACHE_LRU_LIST;\n\tthis_cpu_dec(nr_dentry_unused);\n\tWARN_ON_ONCE(!list_lru_del(&dentry->d_sb->s_dentry_lru, &dentry->d_lru));\n}\n\nstatic void d_shrink_del(struct dentry *dentry)\n{\n\tD_FLAG_VERIFY(dentry, DCACHE_SHRINK_LIST | DCACHE_LRU_LIST);\n\tlist_del_init(&dentry->d_lru);\n\tdentry->d_flags &= ~(DCACHE_SHRINK_LIST | DCACHE_LRU_LIST);\n\tthis_cpu_dec(nr_dentry_unused);\n}\n\nstatic void d_shrink_add(struct dentry *dentry, struct list_head *list)\n{\n\tD_FLAG_VERIFY(dentry, 0);\n\tlist_add(&dentry->d_lru, list);\n\tdentry->d_flags |= DCACHE_SHRINK_LIST | DCACHE_LRU_LIST;\n\tthis_cpu_inc(nr_dentry_unused);\n}\n\n/*\n * These can only be called under the global LRU lock, ie during the\n * callback for freeing the LRU list. \"isolate\" removes it from the\n * LRU lists entirely, while shrink_move moves it to the indicated\n * private list.\n */\nstatic void d_lru_isolate(struct list_lru_one *lru, struct dentry *dentry)\n{\n\tD_FLAG_VERIFY(dentry, DCACHE_LRU_LIST);\n\tdentry->d_flags &= ~DCACHE_LRU_LIST;\n\tthis_cpu_dec(nr_dentry_unused);\n\tlist_lru_isolate(lru, &dentry->d_lru);\n}\n\nstatic void d_lru_shrink_move(struct list_lru_one *lru, struct dentry *dentry,\n\t\t\t      struct list_head *list)\n{\n\tD_FLAG_VERIFY(dentry, DCACHE_LRU_LIST);\n\tdentry->d_flags |= DCACHE_SHRINK_LIST;\n\tlist_lru_isolate_move(lru, &dentry->d_lru, list);\n}\n\n/*\n * dentry_lru_(add|del)_list) must be called with d_lock held.\n */\nstatic void dentry_lru_add(struct dentry *dentry)\n{\n\tif (unlikely(!(dentry->d_flags & DCACHE_LRU_LIST)))\n\t\td_lru_add(dentry);\n\telse if (unlikely(!(dentry->d_flags & DCACHE_REFERENCED)))\n\t\tdentry->d_flags |= DCACHE_REFERENCED;\n}\n\n/**\n * d_drop - drop a dentry\n * @dentry: dentry to drop\n *\n * d_drop() unhashes the entry from the parent dentry hashes, so that it won't\n * be found through a VFS lookup any more. Note that this is different from\n * deleting the dentry - d_delete will try to mark the dentry negative if\n * possible, giving a successful _negative_ lookup, while d_drop will\n * just make the cache lookup fail.\n *\n * d_drop() is used mainly for stuff that wants to invalidate a dentry for some\n * reason (NFS timeouts or autofs deletes).\n *\n * __d_drop requires dentry->d_lock.\n */\nvoid __d_drop(struct dentry *dentry)\n{\n\tif (!d_unhashed(dentry)) {\n\t\tstruct hlist_bl_head *b;\n\t\t/*\n\t\t * Hashed dentries are normally on the dentry hashtable,\n\t\t * with the exception of those newly allocated by\n\t\t * d_obtain_alias, which are always IS_ROOT:\n\t\t */\n\t\tif (unlikely(IS_ROOT(dentry)))\n\t\t\tb = &dentry->d_sb->s_anon;\n\t\telse\n\t\t\tb = d_hash(dentry->d_name.hash);\n\n\t\thlist_bl_lock(b);\n\t\t__hlist_bl_del(&dentry->d_hash);\n\t\tdentry->d_hash.pprev = NULL;\n\t\thlist_bl_unlock(b);\n\t\t/* After this call, in-progress rcu-walk path lookup will fail. */\n\t\twrite_seqcount_invalidate(&dentry->d_seq);\n\t}\n}\nEXPORT_SYMBOL(__d_drop);\n\nvoid d_drop(struct dentry *dentry)\n{\n\tspin_lock(&dentry->d_lock);\n\t__d_drop(dentry);\n\tspin_unlock(&dentry->d_lock);\n}\nEXPORT_SYMBOL(d_drop);\n\nstatic inline void dentry_unlist(struct dentry *dentry, struct dentry *parent)\n{\n\tstruct dentry *next;\n\t/*\n\t * Inform d_walk() and shrink_dentry_list() that we are no longer\n\t * attached to the dentry tree\n\t */\n\tdentry->d_flags |= DCACHE_DENTRY_KILLED;\n\tif (unlikely(list_empty(&dentry->d_child)))\n\t\treturn;\n\t__list_del_entry(&dentry->d_child);\n\t/*\n\t * Cursors can move around the list of children.  While we'd been\n\t * a normal list member, it didn't matter - ->d_child.next would've\n\t * been updated.  However, from now on it won't be and for the\n\t * things like d_walk() it might end up with a nasty surprise.\n\t * Normally d_walk() doesn't care about cursors moving around -\n\t * ->d_lock on parent prevents that and since a cursor has no children\n\t * of its own, we get through it without ever unlocking the parent.\n\t * There is one exception, though - if we ascend from a child that\n\t * gets killed as soon as we unlock it, the next sibling is found\n\t * using the value left in its ->d_child.next.  And if _that_\n\t * pointed to a cursor, and cursor got moved (e.g. by lseek())\n\t * before d_walk() regains parent->d_lock, we'll end up skipping\n\t * everything the cursor had been moved past.\n\t *\n\t * Solution: make sure that the pointer left behind in ->d_child.next\n\t * points to something that won't be moving around.  I.e. skip the\n\t * cursors.\n\t */\n\twhile (dentry->d_child.next != &parent->d_subdirs) {\n\t\tnext = list_entry(dentry->d_child.next, struct dentry, d_child);\n\t\tif (likely(!(next->d_flags & DCACHE_DENTRY_CURSOR)))\n\t\t\tbreak;\n\t\tdentry->d_child.next = next->d_child.next;\n\t}\n}\n\nstatic void __dentry_kill(struct dentry *dentry)\n{\n\tstruct dentry *parent = NULL;\n\tbool can_free = true;\n\tif (!IS_ROOT(dentry))\n\t\tparent = dentry->d_parent;\n\n\t/*\n\t * The dentry is now unrecoverably dead to the world.\n\t */\n\tlockref_mark_dead(&dentry->d_lockref);\n\n\t/*\n\t * inform the fs via d_prune that this dentry is about to be\n\t * unhashed and destroyed.\n\t */\n\tif (dentry->d_flags & DCACHE_OP_PRUNE)\n\t\tdentry->d_op->d_prune(dentry);\n\n\tif (dentry->d_flags & DCACHE_LRU_LIST) {\n\t\tif (!(dentry->d_flags & DCACHE_SHRINK_LIST))\n\t\t\td_lru_del(dentry);\n\t}\n\t/* if it was on the hash then remove it */\n\t__d_drop(dentry);\n\tdentry_unlist(dentry, parent);\n\tif (parent)\n\t\tspin_unlock(&parent->d_lock);\n\tif (dentry->d_inode)\n\t\tdentry_unlink_inode(dentry);\n\telse\n\t\tspin_unlock(&dentry->d_lock);\n\tthis_cpu_dec(nr_dentry);\n\tif (dentry->d_op && dentry->d_op->d_release)\n\t\tdentry->d_op->d_release(dentry);\n\n\tspin_lock(&dentry->d_lock);\n\tif (dentry->d_flags & DCACHE_SHRINK_LIST) {\n\t\tdentry->d_flags |= DCACHE_MAY_FREE;\n\t\tcan_free = false;\n\t}\n\tspin_unlock(&dentry->d_lock);\n\tif (likely(can_free))\n\t\tdentry_free(dentry);\n}\n\n/*\n * Finish off a dentry we've decided to kill.\n * dentry->d_lock must be held, returns with it unlocked.\n * If ref is non-zero, then decrement the refcount too.\n * Returns dentry requiring refcount drop, or NULL if we're done.\n */\nstatic struct dentry *dentry_kill(struct dentry *dentry)\n\t__releases(dentry->d_lock)\n{\n\tstruct inode *inode = dentry->d_inode;\n\tstruct dentry *parent = NULL;\n\n\tif (inode && unlikely(!spin_trylock(&inode->i_lock)))\n\t\tgoto failed;\n\n\tif (!IS_ROOT(dentry)) {\n\t\tparent = dentry->d_parent;\n\t\tif (unlikely(!spin_trylock(&parent->d_lock))) {\n\t\t\tif (inode)\n\t\t\t\tspin_unlock(&inode->i_lock);\n\t\t\tgoto failed;\n\t\t}\n\t}\n\n\t__dentry_kill(dentry);\n\treturn parent;\n\nfailed:\n\tspin_unlock(&dentry->d_lock);\n\treturn dentry; /* try again with same dentry */\n}\n\nstatic inline struct dentry *lock_parent(struct dentry *dentry)\n{\n\tstruct dentry *parent = dentry->d_parent;\n\tif (IS_ROOT(dentry))\n\t\treturn NULL;\n\tif (unlikely(dentry->d_lockref.count < 0))\n\t\treturn NULL;\n\tif (likely(spin_trylock(&parent->d_lock)))\n\t\treturn parent;\n\trcu_read_lock();\n\tspin_unlock(&dentry->d_lock);\nagain:\n\tparent = ACCESS_ONCE(dentry->d_parent);\n\tspin_lock(&parent->d_lock);\n\t/*\n\t * We can't blindly lock dentry until we are sure\n\t * that we won't violate the locking order.\n\t * Any changes of dentry->d_parent must have\n\t * been done with parent->d_lock held, so\n\t * spin_lock() above is enough of a barrier\n\t * for checking if it's still our child.\n\t */\n\tif (unlikely(parent != dentry->d_parent)) {\n\t\tspin_unlock(&parent->d_lock);\n\t\tgoto again;\n\t}\n\trcu_read_unlock();\n\tif (parent != dentry)\n\t\tspin_lock_nested(&dentry->d_lock, DENTRY_D_LOCK_NESTED);\n\telse\n\t\tparent = NULL;\n\treturn parent;\n}\n\n/*\n * Try to do a lockless dput(), and return whether that was successful.\n *\n * If unsuccessful, we return false, having already taken the dentry lock.\n *\n * The caller needs to hold the RCU read lock, so that the dentry is\n * guaranteed to stay around even if the refcount goes down to zero!\n */\nstatic inline bool fast_dput(struct dentry *dentry)\n{\n\tint ret;\n\tunsigned int d_flags;\n\n\t/*\n\t * If we have a d_op->d_delete() operation, we sould not\n\t * let the dentry count go to zero, so use \"put_or_lock\".\n\t */\n\tif (unlikely(dentry->d_flags & DCACHE_OP_DELETE))\n\t\treturn lockref_put_or_lock(&dentry->d_lockref);\n\n\t/*\n\t * .. otherwise, we can try to just decrement the\n\t * lockref optimistically.\n\t */\n\tret = lockref_put_return(&dentry->d_lockref);\n\n\t/*\n\t * If the lockref_put_return() failed due to the lock being held\n\t * by somebody else, the fast path has failed. We will need to\n\t * get the lock, and then check the count again.\n\t */\n\tif (unlikely(ret < 0)) {\n\t\tspin_lock(&dentry->d_lock);\n\t\tif (dentry->d_lockref.count > 1) {\n\t\t\tdentry->d_lockref.count--;\n\t\t\tspin_unlock(&dentry->d_lock);\n\t\t\treturn 1;\n\t\t}\n\t\treturn 0;\n\t}\n\n\t/*\n\t * If we weren't the last ref, we're done.\n\t */\n\tif (ret)\n\t\treturn 1;\n\n\t/*\n\t * Careful, careful. The reference count went down\n\t * to zero, but we don't hold the dentry lock, so\n\t * somebody else could get it again, and do another\n\t * dput(), and we need to not race with that.\n\t *\n\t * However, there is a very special and common case\n\t * where we don't care, because there is nothing to\n\t * do: the dentry is still hashed, it does not have\n\t * a 'delete' op, and it's referenced and already on\n\t * the LRU list.\n\t *\n\t * NOTE! Since we aren't locked, these values are\n\t * not \"stable\". However, it is sufficient that at\n\t * some point after we dropped the reference the\n\t * dentry was hashed and the flags had the proper\n\t * value. Other dentry users may have re-gotten\n\t * a reference to the dentry and change that, but\n\t * our work is done - we can leave the dentry\n\t * around with a zero refcount.\n\t */\n\tsmp_rmb();\n\td_flags = ACCESS_ONCE(dentry->d_flags);\n\td_flags &= DCACHE_REFERENCED | DCACHE_LRU_LIST | DCACHE_DISCONNECTED;\n\n\t/* Nothing to do? Dropping the reference was all we needed? */\n\tif (d_flags == (DCACHE_REFERENCED | DCACHE_LRU_LIST) && !d_unhashed(dentry))\n\t\treturn 1;\n\n\t/*\n\t * Not the fast normal case? Get the lock. We've already decremented\n\t * the refcount, but we'll need to re-check the situation after\n\t * getting the lock.\n\t */\n\tspin_lock(&dentry->d_lock);\n\n\t/*\n\t * Did somebody else grab a reference to it in the meantime, and\n\t * we're no longer the last user after all? Alternatively, somebody\n\t * else could have killed it and marked it dead. Either way, we\n\t * don't need to do anything else.\n\t */\n\tif (dentry->d_lockref.count) {\n\t\tspin_unlock(&dentry->d_lock);\n\t\treturn 1;\n\t}\n\n\t/*\n\t * Re-get the reference we optimistically dropped. We hold the\n\t * lock, and we just tested that it was zero, so we can just\n\t * set it to 1.\n\t */\n\tdentry->d_lockref.count = 1;\n\treturn 0;\n}\n\n\n/* \n * This is dput\n *\n * This is complicated by the fact that we do not want to put\n * dentries that are no longer on any hash chain on the unused\n * list: we'd much rather just get rid of them immediately.\n *\n * However, that implies that we have to traverse the dentry\n * tree upwards to the parents which might _also_ now be\n * scheduled for deletion (it may have been only waiting for\n * its last child to go away).\n *\n * This tail recursion is done by hand as we don't want to depend\n * on the compiler to always get this right (gcc generally doesn't).\n * Real recursion would eat up our stack space.\n */\n\n/*\n * dput - release a dentry\n * @dentry: dentry to release \n *\n * Release a dentry. This will drop the usage count and if appropriate\n * call the dentry unlink method as well as removing it from the queues and\n * releasing its resources. If the parent dentries were scheduled for release\n * they too may now get deleted.\n */\nvoid dput(struct dentry *dentry)\n{\n\tif (unlikely(!dentry))\n\t\treturn;\n\nrepeat:\n\tmight_sleep();\n\n\trcu_read_lock();\n\tif (likely(fast_dput(dentry))) {\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\n\t/* Slow case: now with the dentry lock held */\n\trcu_read_unlock();\n\n\tWARN_ON(d_in_lookup(dentry));\n\n\t/* Unreachable? Get rid of it */\n\tif (unlikely(d_unhashed(dentry)))\n\t\tgoto kill_it;\n\n\tif (unlikely(dentry->d_flags & DCACHE_DISCONNECTED))\n\t\tgoto kill_it;\n\n\tif (unlikely(dentry->d_flags & DCACHE_OP_DELETE)) {\n\t\tif (dentry->d_op->d_delete(dentry))\n\t\t\tgoto kill_it;\n\t}\n\n\tdentry_lru_add(dentry);\n\n\tdentry->d_lockref.count--;\n\tspin_unlock(&dentry->d_lock);\n\treturn;\n\nkill_it:\n\tdentry = dentry_kill(dentry);\n\tif (dentry) {\n\t\tcond_resched();\n\t\tgoto repeat;\n\t}\n}\nEXPORT_SYMBOL(dput);\n\n\n/* This must be called with d_lock held */\nstatic inline void __dget_dlock(struct dentry *dentry)\n{\n\tdentry->d_lockref.count++;\n}\n\nstatic inline void __dget(struct dentry *dentry)\n{\n\tlockref_get(&dentry->d_lockref);\n}\n\nstruct dentry *dget_parent(struct dentry *dentry)\n{\n\tint gotref;\n\tstruct dentry *ret;\n\n\t/*\n\t * Do optimistic parent lookup without any\n\t * locking.\n\t */\n\trcu_read_lock();\n\tret = ACCESS_ONCE(dentry->d_parent);\n\tgotref = lockref_get_not_zero(&ret->d_lockref);\n\trcu_read_unlock();\n\tif (likely(gotref)) {\n\t\tif (likely(ret == ACCESS_ONCE(dentry->d_parent)))\n\t\t\treturn ret;\n\t\tdput(ret);\n\t}\n\nrepeat:\n\t/*\n\t * Don't need rcu_dereference because we re-check it was correct under\n\t * the lock.\n\t */\n\trcu_read_lock();\n\tret = dentry->d_parent;\n\tspin_lock(&ret->d_lock);\n\tif (unlikely(ret != dentry->d_parent)) {\n\t\tspin_unlock(&ret->d_lock);\n\t\trcu_read_unlock();\n\t\tgoto repeat;\n\t}\n\trcu_read_unlock();\n\tBUG_ON(!ret->d_lockref.count);\n\tret->d_lockref.count++;\n\tspin_unlock(&ret->d_lock);\n\treturn ret;\n}\nEXPORT_SYMBOL(dget_parent);\n\n/**\n * d_find_alias - grab a hashed alias of inode\n * @inode: inode in question\n *\n * If inode has a hashed alias, or is a directory and has any alias,\n * acquire the reference to alias and return it. Otherwise return NULL.\n * Notice that if inode is a directory there can be only one alias and\n * it can be unhashed only if it has no children, or if it is the root\n * of a filesystem, or if the directory was renamed and d_revalidate\n * was the first vfs operation to notice.\n *\n * If the inode has an IS_ROOT, DCACHE_DISCONNECTED alias, then prefer\n * any other hashed alias over that one.\n */\nstatic struct dentry *__d_find_alias(struct inode *inode)\n{\n\tstruct dentry *alias, *discon_alias;\n\nagain:\n\tdiscon_alias = NULL;\n\thlist_for_each_entry(alias, &inode->i_dentry, d_u.d_alias) {\n\t\tspin_lock(&alias->d_lock);\n \t\tif (S_ISDIR(inode->i_mode) || !d_unhashed(alias)) {\n\t\t\tif (IS_ROOT(alias) &&\n\t\t\t    (alias->d_flags & DCACHE_DISCONNECTED)) {\n\t\t\t\tdiscon_alias = alias;\n\t\t\t} else {\n\t\t\t\t__dget_dlock(alias);\n\t\t\t\tspin_unlock(&alias->d_lock);\n\t\t\t\treturn alias;\n\t\t\t}\n\t\t}\n\t\tspin_unlock(&alias->d_lock);\n\t}\n\tif (discon_alias) {\n\t\talias = discon_alias;\n\t\tspin_lock(&alias->d_lock);\n\t\tif (S_ISDIR(inode->i_mode) || !d_unhashed(alias)) {\n\t\t\t__dget_dlock(alias);\n\t\t\tspin_unlock(&alias->d_lock);\n\t\t\treturn alias;\n\t\t}\n\t\tspin_unlock(&alias->d_lock);\n\t\tgoto again;\n\t}\n\treturn NULL;\n}\n\nstruct dentry *d_find_alias(struct inode *inode)\n{\n\tstruct dentry *de = NULL;\n\n\tif (!hlist_empty(&inode->i_dentry)) {\n\t\tspin_lock(&inode->i_lock);\n\t\tde = __d_find_alias(inode);\n\t\tspin_unlock(&inode->i_lock);\n\t}\n\treturn de;\n}\nEXPORT_SYMBOL(d_find_alias);\n\n/*\n *\tTry to kill dentries associated with this inode.\n * WARNING: you must own a reference to inode.\n */\nvoid d_prune_aliases(struct inode *inode)\n{\n\tstruct dentry *dentry;\nrestart:\n\tspin_lock(&inode->i_lock);\n\thlist_for_each_entry(dentry, &inode->i_dentry, d_u.d_alias) {\n\t\tspin_lock(&dentry->d_lock);\n\t\tif (!dentry->d_lockref.count) {\n\t\t\tstruct dentry *parent = lock_parent(dentry);\n\t\t\tif (likely(!dentry->d_lockref.count)) {\n\t\t\t\t__dentry_kill(dentry);\n\t\t\t\tdput(parent);\n\t\t\t\tgoto restart;\n\t\t\t}\n\t\t\tif (parent)\n\t\t\t\tspin_unlock(&parent->d_lock);\n\t\t}\n\t\tspin_unlock(&dentry->d_lock);\n\t}\n\tspin_unlock(&inode->i_lock);\n}\nEXPORT_SYMBOL(d_prune_aliases);\n\nstatic void shrink_dentry_list(struct list_head *list)\n{\n\tstruct dentry *dentry, *parent;\n\n\twhile (!list_empty(list)) {\n\t\tstruct inode *inode;\n\t\tdentry = list_entry(list->prev, struct dentry, d_lru);\n\t\tspin_lock(&dentry->d_lock);\n\t\tparent = lock_parent(dentry);\n\n\t\t/*\n\t\t * The dispose list is isolated and dentries are not accounted\n\t\t * to the LRU here, so we can simply remove it from the list\n\t\t * here regardless of whether it is referenced or not.\n\t\t */\n\t\td_shrink_del(dentry);\n\n\t\t/*\n\t\t * We found an inuse dentry which was not removed from\n\t\t * the LRU because of laziness during lookup. Do not free it.\n\t\t */\n\t\tif (dentry->d_lockref.count > 0) {\n\t\t\tspin_unlock(&dentry->d_lock);\n\t\t\tif (parent)\n\t\t\t\tspin_unlock(&parent->d_lock);\n\t\t\tcontinue;\n\t\t}\n\n\n\t\tif (unlikely(dentry->d_flags & DCACHE_DENTRY_KILLED)) {\n\t\t\tbool can_free = dentry->d_flags & DCACHE_MAY_FREE;\n\t\t\tspin_unlock(&dentry->d_lock);\n\t\t\tif (parent)\n\t\t\t\tspin_unlock(&parent->d_lock);\n\t\t\tif (can_free)\n\t\t\t\tdentry_free(dentry);\n\t\t\tcontinue;\n\t\t}\n\n\t\tinode = dentry->d_inode;\n\t\tif (inode && unlikely(!spin_trylock(&inode->i_lock))) {\n\t\t\td_shrink_add(dentry, list);\n\t\t\tspin_unlock(&dentry->d_lock);\n\t\t\tif (parent)\n\t\t\t\tspin_unlock(&parent->d_lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\t__dentry_kill(dentry);\n\n\t\t/*\n\t\t * We need to prune ancestors too. This is necessary to prevent\n\t\t * quadratic behavior of shrink_dcache_parent(), but is also\n\t\t * expected to be beneficial in reducing dentry cache\n\t\t * fragmentation.\n\t\t */\n\t\tdentry = parent;\n\t\twhile (dentry && !lockref_put_or_lock(&dentry->d_lockref)) {\n\t\t\tparent = lock_parent(dentry);\n\t\t\tif (dentry->d_lockref.count != 1) {\n\t\t\t\tdentry->d_lockref.count--;\n\t\t\t\tspin_unlock(&dentry->d_lock);\n\t\t\t\tif (parent)\n\t\t\t\t\tspin_unlock(&parent->d_lock);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tinode = dentry->d_inode;\t/* can't be NULL */\n\t\t\tif (unlikely(!spin_trylock(&inode->i_lock))) {\n\t\t\t\tspin_unlock(&dentry->d_lock);\n\t\t\t\tif (parent)\n\t\t\t\t\tspin_unlock(&parent->d_lock);\n\t\t\t\tcpu_relax();\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t__dentry_kill(dentry);\n\t\t\tdentry = parent;\n\t\t}\n\t}\n}\n\nstatic enum lru_status dentry_lru_isolate(struct list_head *item,\n\t\tstruct list_lru_one *lru, spinlock_t *lru_lock, void *arg)\n{\n\tstruct list_head *freeable = arg;\n\tstruct dentry\t*dentry = container_of(item, struct dentry, d_lru);\n\n\n\t/*\n\t * we are inverting the lru lock/dentry->d_lock here,\n\t * so use a trylock. If we fail to get the lock, just skip\n\t * it\n\t */\n\tif (!spin_trylock(&dentry->d_lock))\n\t\treturn LRU_SKIP;\n\n\t/*\n\t * Referenced dentries are still in use. If they have active\n\t * counts, just remove them from the LRU. Otherwise give them\n\t * another pass through the LRU.\n\t */\n\tif (dentry->d_lockref.count) {\n\t\td_lru_isolate(lru, dentry);\n\t\tspin_unlock(&dentry->d_lock);\n\t\treturn LRU_REMOVED;\n\t}\n\n\tif (dentry->d_flags & DCACHE_REFERENCED) {\n\t\tdentry->d_flags &= ~DCACHE_REFERENCED;\n\t\tspin_unlock(&dentry->d_lock);\n\n\t\t/*\n\t\t * The list move itself will be made by the common LRU code. At\n\t\t * this point, we've dropped the dentry->d_lock but keep the\n\t\t * lru lock. This is safe to do, since every list movement is\n\t\t * protected by the lru lock even if both locks are held.\n\t\t *\n\t\t * This is guaranteed by the fact that all LRU management\n\t\t * functions are intermediated by the LRU API calls like\n\t\t * list_lru_add and list_lru_del. List movement in this file\n\t\t * only ever occur through this functions or through callbacks\n\t\t * like this one, that are called from the LRU API.\n\t\t *\n\t\t * The only exceptions to this are functions like\n\t\t * shrink_dentry_list, and code that first checks for the\n\t\t * DCACHE_SHRINK_LIST flag.  Those are guaranteed to be\n\t\t * operating only with stack provided lists after they are\n\t\t * properly isolated from the main list.  It is thus, always a\n\t\t * local access.\n\t\t */\n\t\treturn LRU_ROTATE;\n\t}\n\n\td_lru_shrink_move(lru, dentry, freeable);\n\tspin_unlock(&dentry->d_lock);\n\n\treturn LRU_REMOVED;\n}\n\n/**\n * prune_dcache_sb - shrink the dcache\n * @sb: superblock\n * @sc: shrink control, passed to list_lru_shrink_walk()\n *\n * Attempt to shrink the superblock dcache LRU by @sc->nr_to_scan entries. This\n * is done when we need more memory and called from the superblock shrinker\n * function.\n *\n * This function may fail to free any resources if all the dentries are in\n * use.\n */\nlong prune_dcache_sb(struct super_block *sb, struct shrink_control *sc)\n{\n\tLIST_HEAD(dispose);\n\tlong freed;\n\n\tfreed = list_lru_shrink_walk(&sb->s_dentry_lru, sc,\n\t\t\t\t     dentry_lru_isolate, &dispose);\n\tshrink_dentry_list(&dispose);\n\treturn freed;\n}\n\nstatic enum lru_status dentry_lru_isolate_shrink(struct list_head *item,\n\t\tstruct list_lru_one *lru, spinlock_t *lru_lock, void *arg)\n{\n\tstruct list_head *freeable = arg;\n\tstruct dentry\t*dentry = container_of(item, struct dentry, d_lru);\n\n\t/*\n\t * we are inverting the lru lock/dentry->d_lock here,\n\t * so use a trylock. If we fail to get the lock, just skip\n\t * it\n\t */\n\tif (!spin_trylock(&dentry->d_lock))\n\t\treturn LRU_SKIP;\n\n\td_lru_shrink_move(lru, dentry, freeable);\n\tspin_unlock(&dentry->d_lock);\n\n\treturn LRU_REMOVED;\n}\n\n\n/**\n * shrink_dcache_sb - shrink dcache for a superblock\n * @sb: superblock\n *\n * Shrink the dcache for the specified super block. This is used to free\n * the dcache before unmounting a file system.\n */\nvoid shrink_dcache_sb(struct super_block *sb)\n{\n\tlong freed;\n\n\tdo {\n\t\tLIST_HEAD(dispose);\n\n\t\tfreed = list_lru_walk(&sb->s_dentry_lru,\n\t\t\tdentry_lru_isolate_shrink, &dispose, UINT_MAX);\n\n\t\tthis_cpu_sub(nr_dentry_unused, freed);\n\t\tshrink_dentry_list(&dispose);\n\t} while (freed > 0);\n}\nEXPORT_SYMBOL(shrink_dcache_sb);\n\n/**\n * enum d_walk_ret - action to talke during tree walk\n * @D_WALK_CONTINUE:\tcontrinue walk\n * @D_WALK_QUIT:\tquit walk\n * @D_WALK_NORETRY:\tquit when retry is needed\n * @D_WALK_SKIP:\tskip this dentry and its children\n */\nenum d_walk_ret {\n\tD_WALK_CONTINUE,\n\tD_WALK_QUIT,\n\tD_WALK_NORETRY,\n\tD_WALK_SKIP,\n};\n\n/**\n * d_walk - walk the dentry tree\n * @parent:\tstart of walk\n * @data:\tdata passed to @enter() and @finish()\n * @enter:\tcallback when first entering the dentry\n * @finish:\tcallback when successfully finished the walk\n *\n * The @enter() and @finish() callbacks are called with d_lock held.\n */\nstatic void d_walk(struct dentry *parent, void *data,\n\t\t   enum d_walk_ret (*enter)(void *, struct dentry *),\n\t\t   void (*finish)(void *))\n{\n\tstruct dentry *this_parent;\n\tstruct list_head *next;\n\tunsigned seq = 0;\n\tenum d_walk_ret ret;\n\tbool retry = true;\n\nagain:\n\tread_seqbegin_or_lock(&rename_lock, &seq);\n\tthis_parent = parent;\n\tspin_lock(&this_parent->d_lock);\n\n\tret = enter(data, this_parent);\n\tswitch (ret) {\n\tcase D_WALK_CONTINUE:\n\t\tbreak;\n\tcase D_WALK_QUIT:\n\tcase D_WALK_SKIP:\n\t\tgoto out_unlock;\n\tcase D_WALK_NORETRY:\n\t\tretry = false;\n\t\tbreak;\n\t}\nrepeat:\n\tnext = this_parent->d_subdirs.next;\nresume:\n\twhile (next != &this_parent->d_subdirs) {\n\t\tstruct list_head *tmp = next;\n\t\tstruct dentry *dentry = list_entry(tmp, struct dentry, d_child);\n\t\tnext = tmp->next;\n\n\t\tif (unlikely(dentry->d_flags & DCACHE_DENTRY_CURSOR))\n\t\t\tcontinue;\n\n\t\tspin_lock_nested(&dentry->d_lock, DENTRY_D_LOCK_NESTED);\n\n\t\tret = enter(data, dentry);\n\t\tswitch (ret) {\n\t\tcase D_WALK_CONTINUE:\n\t\t\tbreak;\n\t\tcase D_WALK_QUIT:\n\t\t\tspin_unlock(&dentry->d_lock);\n\t\t\tgoto out_unlock;\n\t\tcase D_WALK_NORETRY:\n\t\t\tretry = false;\n\t\t\tbreak;\n\t\tcase D_WALK_SKIP:\n\t\t\tspin_unlock(&dentry->d_lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!list_empty(&dentry->d_subdirs)) {\n\t\t\tspin_unlock(&this_parent->d_lock);\n\t\t\tspin_release(&dentry->d_lock.dep_map, 1, _RET_IP_);\n\t\t\tthis_parent = dentry;\n\t\t\tspin_acquire(&this_parent->d_lock.dep_map, 0, 1, _RET_IP_);\n\t\t\tgoto repeat;\n\t\t}\n\t\tspin_unlock(&dentry->d_lock);\n\t}\n\t/*\n\t * All done at this level ... ascend and resume the search.\n\t */\n\trcu_read_lock();\nascend:\n\tif (this_parent != parent) {\n\t\tstruct dentry *child = this_parent;\n\t\tthis_parent = child->d_parent;\n\n\t\tspin_unlock(&child->d_lock);\n\t\tspin_lock(&this_parent->d_lock);\n\n\t\t/* might go back up the wrong parent if we have had a rename. */\n\t\tif (need_seqretry(&rename_lock, seq))\n\t\t\tgoto rename_retry;\n\t\t/* go into the first sibling still alive */\n\t\tdo {\n\t\t\tnext = child->d_child.next;\n\t\t\tif (next == &this_parent->d_subdirs)\n\t\t\t\tgoto ascend;\n\t\t\tchild = list_entry(next, struct dentry, d_child);\n\t\t} while (unlikely(child->d_flags & DCACHE_DENTRY_KILLED));\n\t\trcu_read_unlock();\n\t\tgoto resume;\n\t}\n\tif (need_seqretry(&rename_lock, seq))\n\t\tgoto rename_retry;\n\trcu_read_unlock();\n\tif (finish)\n\t\tfinish(data);\n\nout_unlock:\n\tspin_unlock(&this_parent->d_lock);\n\tdone_seqretry(&rename_lock, seq);\n\treturn;\n\nrename_retry:\n\tspin_unlock(&this_parent->d_lock);\n\trcu_read_unlock();\n\tBUG_ON(seq & 1);\n\tif (!retry)\n\t\treturn;\n\tseq = 1;\n\tgoto again;\n}\n\nstruct check_mount {\n\tstruct vfsmount *mnt;\n\tunsigned int mounted;\n};\n\nstatic enum d_walk_ret path_check_mount(void *data, struct dentry *dentry)\n{\n\tstruct check_mount *info = data;\n\tstruct path path = { .mnt = info->mnt, .dentry = dentry };\n\n\tif (likely(!d_mountpoint(dentry)))\n\t\treturn D_WALK_CONTINUE;\n\tif (__path_is_mountpoint(&path)) {\n\t\tinfo->mounted = 1;\n\t\treturn D_WALK_QUIT;\n\t}\n\treturn D_WALK_CONTINUE;\n}\n\n/**\n * path_has_submounts - check for mounts over a dentry in the\n *                      current namespace.\n * @parent: path to check.\n *\n * Return true if the parent or its subdirectories contain\n * a mount point in the current namespace.\n */\nint path_has_submounts(const struct path *parent)\n{\n\tstruct check_mount data = { .mnt = parent->mnt, .mounted = 0 };\n\n\tread_seqlock_excl(&mount_lock);\n\td_walk(parent->dentry, &data, path_check_mount, NULL);\n\tread_sequnlock_excl(&mount_lock);\n\n\treturn data.mounted;\n}\nEXPORT_SYMBOL(path_has_submounts);\n\n/*\n * Called by mount code to set a mountpoint and check if the mountpoint is\n * reachable (e.g. NFS can unhash a directory dentry and then the complete\n * subtree can become unreachable).\n *\n * Only one of d_invalidate() and d_set_mounted() must succeed.  For\n * this reason take rename_lock and d_lock on dentry and ancestors.\n */\nint d_set_mounted(struct dentry *dentry)\n{\n\tstruct dentry *p;\n\tint ret = -ENOENT;\n\twrite_seqlock(&rename_lock);\n\tfor (p = dentry->d_parent; !IS_ROOT(p); p = p->d_parent) {\n\t\t/* Need exclusion wrt. d_invalidate() */\n\t\tspin_lock(&p->d_lock);\n\t\tif (unlikely(d_unhashed(p))) {\n\t\t\tspin_unlock(&p->d_lock);\n\t\t\tgoto out;\n\t\t}\n\t\tspin_unlock(&p->d_lock);\n\t}\n\tspin_lock(&dentry->d_lock);\n\tif (!d_unlinked(dentry)) {\n\t\tret = -EBUSY;\n\t\tif (!d_mountpoint(dentry)) {\n\t\t\tdentry->d_flags |= DCACHE_MOUNTED;\n\t\t\tret = 0;\n\t\t}\n\t}\n \tspin_unlock(&dentry->d_lock);\nout:\n\twrite_sequnlock(&rename_lock);\n\treturn ret;\n}\n\n/*\n * Search the dentry child list of the specified parent,\n * and move any unused dentries to the end of the unused\n * list for prune_dcache(). We descend to the next level\n * whenever the d_subdirs list is non-empty and continue\n * searching.\n *\n * It returns zero iff there are no unused children,\n * otherwise  it returns the number of children moved to\n * the end of the unused list. This may not be the total\n * number of unused children, because select_parent can\n * drop the lock and return early due to latency\n * constraints.\n */\n\nstruct select_data {\n\tstruct dentry *start;\n\tstruct list_head dispose;\n\tint found;\n};\n\nstatic enum d_walk_ret select_collect(void *_data, struct dentry *dentry)\n{\n\tstruct select_data *data = _data;\n\tenum d_walk_ret ret = D_WALK_CONTINUE;\n\n\tif (data->start == dentry)\n\t\tgoto out;\n\n\tif (dentry->d_flags & DCACHE_SHRINK_LIST) {\n\t\tdata->found++;\n\t} else {\n\t\tif (dentry->d_flags & DCACHE_LRU_LIST)\n\t\t\td_lru_del(dentry);\n\t\tif (!dentry->d_lockref.count) {\n\t\t\td_shrink_add(dentry, &data->dispose);\n\t\t\tdata->found++;\n\t\t}\n\t}\n\t/*\n\t * We can return to the caller if we have found some (this\n\t * ensures forward progress). We'll be coming back to find\n\t * the rest.\n\t */\n\tif (!list_empty(&data->dispose))\n\t\tret = need_resched() ? D_WALK_QUIT : D_WALK_NORETRY;\nout:\n\treturn ret;\n}\n\n/**\n * shrink_dcache_parent - prune dcache\n * @parent: parent of entries to prune\n *\n * Prune the dcache to remove unused children of the parent dentry.\n */\nvoid shrink_dcache_parent(struct dentry *parent)\n{\n\tfor (;;) {\n\t\tstruct select_data data;\n\n\t\tINIT_LIST_HEAD(&data.dispose);\n\t\tdata.start = parent;\n\t\tdata.found = 0;\n\n\t\td_walk(parent, &data, select_collect, NULL);\n\t\tif (!data.found)\n\t\t\tbreak;\n\n\t\tshrink_dentry_list(&data.dispose);\n\t\tcond_resched();\n\t}\n}\nEXPORT_SYMBOL(shrink_dcache_parent);\n\nstatic enum d_walk_ret umount_check(void *_data, struct dentry *dentry)\n{\n\t/* it has busy descendents; complain about those instead */\n\tif (!list_empty(&dentry->d_subdirs))\n\t\treturn D_WALK_CONTINUE;\n\n\t/* root with refcount 1 is fine */\n\tif (dentry == _data && dentry->d_lockref.count == 1)\n\t\treturn D_WALK_CONTINUE;\n\n\tprintk(KERN_ERR \"BUG: Dentry %p{i=%lx,n=%pd} \"\n\t\t\t\" still in use (%d) [unmount of %s %s]\\n\",\n\t\t       dentry,\n\t\t       dentry->d_inode ?\n\t\t       dentry->d_inode->i_ino : 0UL,\n\t\t       dentry,\n\t\t       dentry->d_lockref.count,\n\t\t       dentry->d_sb->s_type->name,\n\t\t       dentry->d_sb->s_id);\n\tWARN_ON(1);\n\treturn D_WALK_CONTINUE;\n}\n\nstatic void do_one_tree(struct dentry *dentry)\n{\n\tshrink_dcache_parent(dentry);\n\td_walk(dentry, dentry, umount_check, NULL);\n\td_drop(dentry);\n\tdput(dentry);\n}\n\n/*\n * destroy the dentries attached to a superblock on unmounting\n */\nvoid shrink_dcache_for_umount(struct super_block *sb)\n{\n\tstruct dentry *dentry;\n\n\tWARN(down_read_trylock(&sb->s_umount), \"s_umount should've been locked\");\n\n\tdentry = sb->s_root;\n\tsb->s_root = NULL;\n\tdo_one_tree(dentry);\n\n\twhile (!hlist_bl_empty(&sb->s_anon)) {\n\t\tdentry = dget(hlist_bl_entry(hlist_bl_first(&sb->s_anon), struct dentry, d_hash));\n\t\tdo_one_tree(dentry);\n\t}\n}\n\nstruct detach_data {\n\tstruct select_data select;\n\tstruct dentry *mountpoint;\n};\nstatic enum d_walk_ret detach_and_collect(void *_data, struct dentry *dentry)\n{\n\tstruct detach_data *data = _data;\n\n\tif (d_mountpoint(dentry)) {\n\t\t__dget_dlock(dentry);\n\t\tdata->mountpoint = dentry;\n\t\treturn D_WALK_QUIT;\n\t}\n\n\treturn select_collect(&data->select, dentry);\n}\n\nstatic void check_and_drop(void *_data)\n{\n\tstruct detach_data *data = _data;\n\n\tif (!data->mountpoint && list_empty(&data->select.dispose))\n\t\t__d_drop(data->select.start);\n}\n\n/**\n * d_invalidate - detach submounts, prune dcache, and drop\n * @dentry: dentry to invalidate (aka detach, prune and drop)\n *\n * no dcache lock.\n *\n * The final d_drop is done as an atomic operation relative to\n * rename_lock ensuring there are no races with d_set_mounted.  This\n * ensures there are no unhashed dentries on the path to a mountpoint.\n */\nvoid d_invalidate(struct dentry *dentry)\n{\n\t/*\n\t * If it's already been dropped, return OK.\n\t */\n\tspin_lock(&dentry->d_lock);\n\tif (d_unhashed(dentry)) {\n\t\tspin_unlock(&dentry->d_lock);\n\t\treturn;\n\t}\n\tspin_unlock(&dentry->d_lock);\n\n\t/* Negative dentries can be dropped without further checks */\n\tif (!dentry->d_inode) {\n\t\td_drop(dentry);\n\t\treturn;\n\t}\n\n\tfor (;;) {\n\t\tstruct detach_data data;\n\n\t\tdata.mountpoint = NULL;\n\t\tINIT_LIST_HEAD(&data.select.dispose);\n\t\tdata.select.start = dentry;\n\t\tdata.select.found = 0;\n\n\t\td_walk(dentry, &data, detach_and_collect, check_and_drop);\n\n\t\tif (!list_empty(&data.select.dispose))\n\t\t\tshrink_dentry_list(&data.select.dispose);\n\t\telse if (!data.mountpoint)\n\t\t\treturn;\n\n\t\tif (data.mountpoint) {\n\t\t\tdetach_mounts(data.mountpoint);\n\t\t\tdput(data.mountpoint);\n\t\t}\n\t\tcond_resched();\n\t}\n}\nEXPORT_SYMBOL(d_invalidate);\n\n/**\n * __d_alloc\t-\tallocate a dcache entry\n * @sb: filesystem it will belong to\n * @name: qstr of the name\n *\n * Allocates a dentry. It returns %NULL if there is insufficient memory\n * available. On a success the dentry is returned. The name passed in is\n * copied and the copy passed in may be reused after this call.\n */\n \nstruct dentry *__d_alloc(struct super_block *sb, const struct qstr *name)\n{\n\tstruct dentry *dentry;\n\tchar *dname;\n\tint err;\n\n\tdentry = kmem_cache_alloc(dentry_cache, GFP_KERNEL);\n\tif (!dentry)\n\t\treturn NULL;\n\n\t/*\n\t * We guarantee that the inline name is always NUL-terminated.\n\t * This way the memcpy() done by the name switching in rename\n\t * will still always have a NUL at the end, even if we might\n\t * be overwriting an internal NUL character\n\t */\n\tdentry->d_iname[DNAME_INLINE_LEN-1] = 0;\n\tif (unlikely(!name)) {\n\t\tstatic const struct qstr anon = QSTR_INIT(\"/\", 1);\n\t\tname = &anon;\n\t\tdname = dentry->d_iname;\n\t} else if (name->len > DNAME_INLINE_LEN-1) {\n\t\tsize_t size = offsetof(struct external_name, name[1]);\n\t\tstruct external_name *p = kmalloc(size + name->len,\n\t\t\t\t\t\t  GFP_KERNEL_ACCOUNT);\n\t\tif (!p) {\n\t\t\tkmem_cache_free(dentry_cache, dentry); \n\t\t\treturn NULL;\n\t\t}\n\t\tatomic_set(&p->u.count, 1);\n\t\tdname = p->name;\n\t\tif (IS_ENABLED(CONFIG_DCACHE_WORD_ACCESS))\n\t\t\tkasan_unpoison_shadow(dname,\n\t\t\t\tround_up(name->len + 1,\tsizeof(unsigned long)));\n\t} else  {\n\t\tdname = dentry->d_iname;\n\t}\t\n\n\tdentry->d_name.len = name->len;\n\tdentry->d_name.hash = name->hash;\n\tmemcpy(dname, name->name, name->len);\n\tdname[name->len] = 0;\n\n\t/* Make sure we always see the terminating NUL character */\n\tsmp_wmb();\n\tdentry->d_name.name = dname;\n\n\tdentry->d_lockref.count = 1;\n\tdentry->d_flags = 0;\n\tspin_lock_init(&dentry->d_lock);\n\tseqcount_init(&dentry->d_seq);\n\tdentry->d_inode = NULL;\n\tdentry->d_parent = dentry;\n\tdentry->d_sb = sb;\n\tdentry->d_op = NULL;\n\tdentry->d_fsdata = NULL;\n\tINIT_HLIST_BL_NODE(&dentry->d_hash);\n\tINIT_LIST_HEAD(&dentry->d_lru);\n\tINIT_LIST_HEAD(&dentry->d_subdirs);\n\tINIT_HLIST_NODE(&dentry->d_u.d_alias);\n\tINIT_LIST_HEAD(&dentry->d_child);\n\td_set_d_op(dentry, dentry->d_sb->s_d_op);\n\n\tif (dentry->d_op && dentry->d_op->d_init) {\n\t\terr = dentry->d_op->d_init(dentry);\n\t\tif (err) {\n\t\t\tif (dname_external(dentry))\n\t\t\t\tkfree(external_name(dentry));\n\t\t\tkmem_cache_free(dentry_cache, dentry);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\tthis_cpu_inc(nr_dentry);\n\n\treturn dentry;\n}\n\n/**\n * d_alloc\t-\tallocate a dcache entry\n * @parent: parent of entry to allocate\n * @name: qstr of the name\n *\n * Allocates a dentry. It returns %NULL if there is insufficient memory\n * available. On a success the dentry is returned. The name passed in is\n * copied and the copy passed in may be reused after this call.\n */\nstruct dentry *d_alloc(struct dentry * parent, const struct qstr *name)\n{\n\tstruct dentry *dentry = __d_alloc(parent->d_sb, name);\n\tif (!dentry)\n\t\treturn NULL;\n\tdentry->d_flags |= DCACHE_RCUACCESS;\n\tspin_lock(&parent->d_lock);\n\t/*\n\t * don't need child lock because it is not subject\n\t * to concurrency here\n\t */\n\t__dget_dlock(parent);\n\tdentry->d_parent = parent;\n\tlist_add(&dentry->d_child, &parent->d_subdirs);\n\tspin_unlock(&parent->d_lock);\n\n\treturn dentry;\n}\nEXPORT_SYMBOL(d_alloc);\n\nstruct dentry *d_alloc_cursor(struct dentry * parent)\n{\n\tstruct dentry *dentry = __d_alloc(parent->d_sb, NULL);\n\tif (dentry) {\n\t\tdentry->d_flags |= DCACHE_RCUACCESS | DCACHE_DENTRY_CURSOR;\n\t\tdentry->d_parent = dget(parent);\n\t}\n\treturn dentry;\n}\n\n/**\n * d_alloc_pseudo - allocate a dentry (for lookup-less filesystems)\n * @sb: the superblock\n * @name: qstr of the name\n *\n * For a filesystem that just pins its dentries in memory and never\n * performs lookups at all, return an unhashed IS_ROOT dentry.\n */\nstruct dentry *d_alloc_pseudo(struct super_block *sb, const struct qstr *name)\n{\n\treturn __d_alloc(sb, name);\n}\nEXPORT_SYMBOL(d_alloc_pseudo);\n\nstruct dentry *d_alloc_name(struct dentry *parent, const char *name)\n{\n\tstruct qstr q;\n\n\tq.name = name;\n\tq.hash_len = hashlen_string(parent, name);\n\treturn d_alloc(parent, &q);\n}\nEXPORT_SYMBOL(d_alloc_name);\n\nvoid d_set_d_op(struct dentry *dentry, const struct dentry_operations *op)\n{\n\tWARN_ON_ONCE(dentry->d_op);\n\tWARN_ON_ONCE(dentry->d_flags & (DCACHE_OP_HASH\t|\n\t\t\t\tDCACHE_OP_COMPARE\t|\n\t\t\t\tDCACHE_OP_REVALIDATE\t|\n\t\t\t\tDCACHE_OP_WEAK_REVALIDATE\t|\n\t\t\t\tDCACHE_OP_DELETE\t|\n\t\t\t\tDCACHE_OP_REAL));\n\tdentry->d_op = op;\n\tif (!op)\n\t\treturn;\n\tif (op->d_hash)\n\t\tdentry->d_flags |= DCACHE_OP_HASH;\n\tif (op->d_compare)\n\t\tdentry->d_flags |= DCACHE_OP_COMPARE;\n\tif (op->d_revalidate)\n\t\tdentry->d_flags |= DCACHE_OP_REVALIDATE;\n\tif (op->d_weak_revalidate)\n\t\tdentry->d_flags |= DCACHE_OP_WEAK_REVALIDATE;\n\tif (op->d_delete)\n\t\tdentry->d_flags |= DCACHE_OP_DELETE;\n\tif (op->d_prune)\n\t\tdentry->d_flags |= DCACHE_OP_PRUNE;\n\tif (op->d_real)\n\t\tdentry->d_flags |= DCACHE_OP_REAL;\n\n}\nEXPORT_SYMBOL(d_set_d_op);\n\n\n/*\n * d_set_fallthru - Mark a dentry as falling through to a lower layer\n * @dentry - The dentry to mark\n *\n * Mark a dentry as falling through to the lower layer (as set with\n * d_pin_lower()).  This flag may be recorded on the medium.\n */\nvoid d_set_fallthru(struct dentry *dentry)\n{\n\tspin_lock(&dentry->d_lock);\n\tdentry->d_flags |= DCACHE_FALLTHRU;\n\tspin_unlock(&dentry->d_lock);\n}\nEXPORT_SYMBOL(d_set_fallthru);\n\nstatic unsigned d_flags_for_inode(struct inode *inode)\n{\n\tunsigned add_flags = DCACHE_REGULAR_TYPE;\n\n\tif (!inode)\n\t\treturn DCACHE_MISS_TYPE;\n\n\tif (S_ISDIR(inode->i_mode)) {\n\t\tadd_flags = DCACHE_DIRECTORY_TYPE;\n\t\tif (unlikely(!(inode->i_opflags & IOP_LOOKUP))) {\n\t\t\tif (unlikely(!inode->i_op->lookup))\n\t\t\t\tadd_flags = DCACHE_AUTODIR_TYPE;\n\t\t\telse\n\t\t\t\tinode->i_opflags |= IOP_LOOKUP;\n\t\t}\n\t\tgoto type_determined;\n\t}\n\n\tif (unlikely(!(inode->i_opflags & IOP_NOFOLLOW))) {\n\t\tif (unlikely(inode->i_op->get_link)) {\n\t\t\tadd_flags = DCACHE_SYMLINK_TYPE;\n\t\t\tgoto type_determined;\n\t\t}\n\t\tinode->i_opflags |= IOP_NOFOLLOW;\n\t}\n\n\tif (unlikely(!S_ISREG(inode->i_mode)))\n\t\tadd_flags = DCACHE_SPECIAL_TYPE;\n\ntype_determined:\n\tif (unlikely(IS_AUTOMOUNT(inode)))\n\t\tadd_flags |= DCACHE_NEED_AUTOMOUNT;\n\treturn add_flags;\n}\n\nstatic void __d_instantiate(struct dentry *dentry, struct inode *inode)\n{\n\tunsigned add_flags = d_flags_for_inode(inode);\n\tWARN_ON(d_in_lookup(dentry));\n\n\tspin_lock(&dentry->d_lock);\n\thlist_add_head(&dentry->d_u.d_alias, &inode->i_dentry);\n\traw_write_seqcount_begin(&dentry->d_seq);\n\t__d_set_inode_and_type(dentry, inode, add_flags);\n\traw_write_seqcount_end(&dentry->d_seq);\n\tfsnotify_update_flags(dentry);\n\tspin_unlock(&dentry->d_lock);\n}\n\n/**\n * d_instantiate - fill in inode information for a dentry\n * @entry: dentry to complete\n * @inode: inode to attach to this dentry\n *\n * Fill in inode information in the entry.\n *\n * This turns negative dentries into productive full members\n * of society.\n *\n * NOTE! This assumes that the inode count has been incremented\n * (or otherwise set) by the caller to indicate that it is now\n * in use by the dcache.\n */\n \nvoid d_instantiate(struct dentry *entry, struct inode * inode)\n{\n\tBUG_ON(!hlist_unhashed(&entry->d_u.d_alias));\n\tif (inode) {\n\t\tsecurity_d_instantiate(entry, inode);\n\t\tspin_lock(&inode->i_lock);\n\t\t__d_instantiate(entry, inode);\n\t\tspin_unlock(&inode->i_lock);\n\t}\n}\nEXPORT_SYMBOL(d_instantiate);\n\n/**\n * d_instantiate_no_diralias - instantiate a non-aliased dentry\n * @entry: dentry to complete\n * @inode: inode to attach to this dentry\n *\n * Fill in inode information in the entry.  If a directory alias is found, then\n * return an error (and drop inode).  Together with d_materialise_unique() this\n * guarantees that a directory inode may never have more than one alias.\n */\nint d_instantiate_no_diralias(struct dentry *entry, struct inode *inode)\n{\n\tBUG_ON(!hlist_unhashed(&entry->d_u.d_alias));\n\n\tsecurity_d_instantiate(entry, inode);\n\tspin_lock(&inode->i_lock);\n\tif (S_ISDIR(inode->i_mode) && !hlist_empty(&inode->i_dentry)) {\n\t\tspin_unlock(&inode->i_lock);\n\t\tiput(inode);\n\t\treturn -EBUSY;\n\t}\n\t__d_instantiate(entry, inode);\n\tspin_unlock(&inode->i_lock);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(d_instantiate_no_diralias);\n\nstruct dentry *d_make_root(struct inode *root_inode)\n{\n\tstruct dentry *res = NULL;\n\n\tif (root_inode) {\n\t\tres = __d_alloc(root_inode->i_sb, NULL);\n\t\tif (res)\n\t\t\td_instantiate(res, root_inode);\n\t\telse\n\t\t\tiput(root_inode);\n\t}\n\treturn res;\n}\nEXPORT_SYMBOL(d_make_root);\n\nstatic struct dentry * __d_find_any_alias(struct inode *inode)\n{\n\tstruct dentry *alias;\n\n\tif (hlist_empty(&inode->i_dentry))\n\t\treturn NULL;\n\talias = hlist_entry(inode->i_dentry.first, struct dentry, d_u.d_alias);\n\t__dget(alias);\n\treturn alias;\n}\n\n/**\n * d_find_any_alias - find any alias for a given inode\n * @inode: inode to find an alias for\n *\n * If any aliases exist for the given inode, take and return a\n * reference for one of them.  If no aliases exist, return %NULL.\n */\nstruct dentry *d_find_any_alias(struct inode *inode)\n{\n\tstruct dentry *de;\n\n\tspin_lock(&inode->i_lock);\n\tde = __d_find_any_alias(inode);\n\tspin_unlock(&inode->i_lock);\n\treturn de;\n}\nEXPORT_SYMBOL(d_find_any_alias);\n\nstatic struct dentry *__d_obtain_alias(struct inode *inode, int disconnected)\n{\n\tstruct dentry *tmp;\n\tstruct dentry *res;\n\tunsigned add_flags;\n\n\tif (!inode)\n\t\treturn ERR_PTR(-ESTALE);\n\tif (IS_ERR(inode))\n\t\treturn ERR_CAST(inode);\n\n\tres = d_find_any_alias(inode);\n\tif (res)\n\t\tgoto out_iput;\n\n\ttmp = __d_alloc(inode->i_sb, NULL);\n\tif (!tmp) {\n\t\tres = ERR_PTR(-ENOMEM);\n\t\tgoto out_iput;\n\t}\n\n\tsecurity_d_instantiate(tmp, inode);\n\tspin_lock(&inode->i_lock);\n\tres = __d_find_any_alias(inode);\n\tif (res) {\n\t\tspin_unlock(&inode->i_lock);\n\t\tdput(tmp);\n\t\tgoto out_iput;\n\t}\n\n\t/* attach a disconnected dentry */\n\tadd_flags = d_flags_for_inode(inode);\n\n\tif (disconnected)\n\t\tadd_flags |= DCACHE_DISCONNECTED;\n\n\tspin_lock(&tmp->d_lock);\n\t__d_set_inode_and_type(tmp, inode, add_flags);\n\thlist_add_head(&tmp->d_u.d_alias, &inode->i_dentry);\n\thlist_bl_lock(&tmp->d_sb->s_anon);\n\thlist_bl_add_head(&tmp->d_hash, &tmp->d_sb->s_anon);\n\thlist_bl_unlock(&tmp->d_sb->s_anon);\n\tspin_unlock(&tmp->d_lock);\n\tspin_unlock(&inode->i_lock);\n\n\treturn tmp;\n\n out_iput:\n\tiput(inode);\n\treturn res;\n}\n\n/**\n * d_obtain_alias - find or allocate a DISCONNECTED dentry for a given inode\n * @inode: inode to allocate the dentry for\n *\n * Obtain a dentry for an inode resulting from NFS filehandle conversion or\n * similar open by handle operations.  The returned dentry may be anonymous,\n * or may have a full name (if the inode was already in the cache).\n *\n * When called on a directory inode, we must ensure that the inode only ever\n * has one dentry.  If a dentry is found, that is returned instead of\n * allocating a new one.\n *\n * On successful return, the reference to the inode has been transferred\n * to the dentry.  In case of an error the reference on the inode is released.\n * To make it easier to use in export operations a %NULL or IS_ERR inode may\n * be passed in and the error will be propagated to the return value,\n * with a %NULL @inode replaced by ERR_PTR(-ESTALE).\n */\nstruct dentry *d_obtain_alias(struct inode *inode)\n{\n\treturn __d_obtain_alias(inode, 1);\n}\nEXPORT_SYMBOL(d_obtain_alias);\n\n/**\n * d_obtain_root - find or allocate a dentry for a given inode\n * @inode: inode to allocate the dentry for\n *\n * Obtain an IS_ROOT dentry for the root of a filesystem.\n *\n * We must ensure that directory inodes only ever have one dentry.  If a\n * dentry is found, that is returned instead of allocating a new one.\n *\n * On successful return, the reference to the inode has been transferred\n * to the dentry.  In case of an error the reference on the inode is\n * released.  A %NULL or IS_ERR inode may be passed in and will be the\n * error will be propagate to the return value, with a %NULL @inode\n * replaced by ERR_PTR(-ESTALE).\n */\nstruct dentry *d_obtain_root(struct inode *inode)\n{\n\treturn __d_obtain_alias(inode, 0);\n}\nEXPORT_SYMBOL(d_obtain_root);\n\n/**\n * d_add_ci - lookup or allocate new dentry with case-exact name\n * @inode:  the inode case-insensitive lookup has found\n * @dentry: the negative dentry that was passed to the parent's lookup func\n * @name:   the case-exact name to be associated with the returned dentry\n *\n * This is to avoid filling the dcache with case-insensitive names to the\n * same inode, only the actual correct case is stored in the dcache for\n * case-insensitive filesystems.\n *\n * For a case-insensitive lookup match and if the the case-exact dentry\n * already exists in in the dcache, use it and return it.\n *\n * If no entry exists with the exact case name, allocate new dentry with\n * the exact case, and return the spliced entry.\n */\nstruct dentry *d_add_ci(struct dentry *dentry, struct inode *inode,\n\t\t\tstruct qstr *name)\n{\n\tstruct dentry *found, *res;\n\n\t/*\n\t * First check if a dentry matching the name already exists,\n\t * if not go ahead and create it now.\n\t */\n\tfound = d_hash_and_lookup(dentry->d_parent, name);\n\tif (found) {\n\t\tiput(inode);\n\t\treturn found;\n\t}\n\tif (d_in_lookup(dentry)) {\n\t\tfound = d_alloc_parallel(dentry->d_parent, name,\n\t\t\t\t\tdentry->d_wait);\n\t\tif (IS_ERR(found) || !d_in_lookup(found)) {\n\t\t\tiput(inode);\n\t\t\treturn found;\n\t\t}\n\t} else {\n\t\tfound = d_alloc(dentry->d_parent, name);\n\t\tif (!found) {\n\t\t\tiput(inode);\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t} \n\t}\n\tres = d_splice_alias(inode, found);\n\tif (res) {\n\t\tdput(found);\n\t\treturn res;\n\t}\n\treturn found;\n}\nEXPORT_SYMBOL(d_add_ci);\n\n\nstatic inline bool d_same_name(const struct dentry *dentry,\n\t\t\t\tconst struct dentry *parent,\n\t\t\t\tconst struct qstr *name)\n{\n\tif (likely(!(parent->d_flags & DCACHE_OP_COMPARE))) {\n\t\tif (dentry->d_name.len != name->len)\n\t\t\treturn false;\n\t\treturn dentry_cmp(dentry, name->name, name->len) == 0;\n\t}\n\treturn parent->d_op->d_compare(dentry,\n\t\t\t\t       dentry->d_name.len, dentry->d_name.name,\n\t\t\t\t       name) == 0;\n}\n\n/**\n * __d_lookup_rcu - search for a dentry (racy, store-free)\n * @parent: parent dentry\n * @name: qstr of name we wish to find\n * @seqp: returns d_seq value at the point where the dentry was found\n * Returns: dentry, or NULL\n *\n * __d_lookup_rcu is the dcache lookup function for rcu-walk name\n * resolution (store-free path walking) design described in\n * Documentation/filesystems/path-lookup.txt.\n *\n * This is not to be used outside core vfs.\n *\n * __d_lookup_rcu must only be used in rcu-walk mode, ie. with vfsmount lock\n * held, and rcu_read_lock held. The returned dentry must not be stored into\n * without taking d_lock and checking d_seq sequence count against @seq\n * returned here.\n *\n * A refcount may be taken on the found dentry with the d_rcu_to_refcount\n * function.\n *\n * Alternatively, __d_lookup_rcu may be called again to look up the child of\n * the returned dentry, so long as its parent's seqlock is checked after the\n * child is looked up. Thus, an interlocking stepping of sequence lock checks\n * is formed, giving integrity down the path walk.\n *\n * NOTE! The caller *has* to check the resulting dentry against the sequence\n * number we've returned before using any of the resulting dentry state!\n */\nstruct dentry *__d_lookup_rcu(const struct dentry *parent,\n\t\t\t\tconst struct qstr *name,\n\t\t\t\tunsigned *seqp)\n{\n\tu64 hashlen = name->hash_len;\n\tconst unsigned char *str = name->name;\n\tstruct hlist_bl_head *b = d_hash(hashlen_hash(hashlen));\n\tstruct hlist_bl_node *node;\n\tstruct dentry *dentry;\n\n\t/*\n\t * Note: There is significant duplication with __d_lookup_rcu which is\n\t * required to prevent single threaded performance regressions\n\t * especially on architectures where smp_rmb (in seqcounts) are costly.\n\t * Keep the two functions in sync.\n\t */\n\n\t/*\n\t * The hash list is protected using RCU.\n\t *\n\t * Carefully use d_seq when comparing a candidate dentry, to avoid\n\t * races with d_move().\n\t *\n\t * It is possible that concurrent renames can mess up our list\n\t * walk here and result in missing our dentry, resulting in the\n\t * false-negative result. d_lookup() protects against concurrent\n\t * renames using rename_lock seqlock.\n\t *\n\t * See Documentation/filesystems/path-lookup.txt for more details.\n\t */\n\thlist_bl_for_each_entry_rcu(dentry, node, b, d_hash) {\n\t\tunsigned seq;\n\nseqretry:\n\t\t/*\n\t\t * The dentry sequence count protects us from concurrent\n\t\t * renames, and thus protects parent and name fields.\n\t\t *\n\t\t * The caller must perform a seqcount check in order\n\t\t * to do anything useful with the returned dentry.\n\t\t *\n\t\t * NOTE! We do a \"raw\" seqcount_begin here. That means that\n\t\t * we don't wait for the sequence count to stabilize if it\n\t\t * is in the middle of a sequence change. If we do the slow\n\t\t * dentry compare, we will do seqretries until it is stable,\n\t\t * and if we end up with a successful lookup, we actually\n\t\t * want to exit RCU lookup anyway.\n\t\t *\n\t\t * Note that raw_seqcount_begin still *does* smp_rmb(), so\n\t\t * we are still guaranteed NUL-termination of ->d_name.name.\n\t\t */\n\t\tseq = raw_seqcount_begin(&dentry->d_seq);\n\t\tif (dentry->d_parent != parent)\n\t\t\tcontinue;\n\t\tif (d_unhashed(dentry))\n\t\t\tcontinue;\n\n\t\tif (unlikely(parent->d_flags & DCACHE_OP_COMPARE)) {\n\t\t\tint tlen;\n\t\t\tconst char *tname;\n\t\t\tif (dentry->d_name.hash != hashlen_hash(hashlen))\n\t\t\t\tcontinue;\n\t\t\ttlen = dentry->d_name.len;\n\t\t\ttname = dentry->d_name.name;\n\t\t\t/* we want a consistent (name,len) pair */\n\t\t\tif (read_seqcount_retry(&dentry->d_seq, seq)) {\n\t\t\t\tcpu_relax();\n\t\t\t\tgoto seqretry;\n\t\t\t}\n\t\t\tif (parent->d_op->d_compare(dentry,\n\t\t\t\t\t\t    tlen, tname, name) != 0)\n\t\t\t\tcontinue;\n\t\t} else {\n\t\t\tif (dentry->d_name.hash_len != hashlen)\n\t\t\t\tcontinue;\n\t\t\tif (dentry_cmp(dentry, str, hashlen_len(hashlen)) != 0)\n\t\t\t\tcontinue;\n\t\t}\n\t\t*seqp = seq;\n\t\treturn dentry;\n\t}\n\treturn NULL;\n}\n\n/**\n * d_lookup - search for a dentry\n * @parent: parent dentry\n * @name: qstr of name we wish to find\n * Returns: dentry, or NULL\n *\n * d_lookup searches the children of the parent dentry for the name in\n * question. If the dentry is found its reference count is incremented and the\n * dentry is returned. The caller must use dput to free the entry when it has\n * finished using it. %NULL is returned if the dentry does not exist.\n */\nstruct dentry *d_lookup(const struct dentry *parent, const struct qstr *name)\n{\n\tstruct dentry *dentry;\n\tunsigned seq;\n\n\tdo {\n\t\tseq = read_seqbegin(&rename_lock);\n\t\tdentry = __d_lookup(parent, name);\n\t\tif (dentry)\n\t\t\tbreak;\n\t} while (read_seqretry(&rename_lock, seq));\n\treturn dentry;\n}\nEXPORT_SYMBOL(d_lookup);\n\n/**\n * __d_lookup - search for a dentry (racy)\n * @parent: parent dentry\n * @name: qstr of name we wish to find\n * Returns: dentry, or NULL\n *\n * __d_lookup is like d_lookup, however it may (rarely) return a\n * false-negative result due to unrelated rename activity.\n *\n * __d_lookup is slightly faster by avoiding rename_lock read seqlock,\n * however it must be used carefully, eg. with a following d_lookup in\n * the case of failure.\n *\n * __d_lookup callers must be commented.\n */\nstruct dentry *__d_lookup(const struct dentry *parent, const struct qstr *name)\n{\n\tunsigned int hash = name->hash;\n\tstruct hlist_bl_head *b = d_hash(hash);\n\tstruct hlist_bl_node *node;\n\tstruct dentry *found = NULL;\n\tstruct dentry *dentry;\n\n\t/*\n\t * Note: There is significant duplication with __d_lookup_rcu which is\n\t * required to prevent single threaded performance regressions\n\t * especially on architectures where smp_rmb (in seqcounts) are costly.\n\t * Keep the two functions in sync.\n\t */\n\n\t/*\n\t * The hash list is protected using RCU.\n\t *\n\t * Take d_lock when comparing a candidate dentry, to avoid races\n\t * with d_move().\n\t *\n\t * It is possible that concurrent renames can mess up our list\n\t * walk here and result in missing our dentry, resulting in the\n\t * false-negative result. d_lookup() protects against concurrent\n\t * renames using rename_lock seqlock.\n\t *\n\t * See Documentation/filesystems/path-lookup.txt for more details.\n\t */\n\trcu_read_lock();\n\t\n\thlist_bl_for_each_entry_rcu(dentry, node, b, d_hash) {\n\n\t\tif (dentry->d_name.hash != hash)\n\t\t\tcontinue;\n\n\t\tspin_lock(&dentry->d_lock);\n\t\tif (dentry->d_parent != parent)\n\t\t\tgoto next;\n\t\tif (d_unhashed(dentry))\n\t\t\tgoto next;\n\n\t\tif (!d_same_name(dentry, parent, name))\n\t\t\tgoto next;\n\n\t\tdentry->d_lockref.count++;\n\t\tfound = dentry;\n\t\tspin_unlock(&dentry->d_lock);\n\t\tbreak;\nnext:\n\t\tspin_unlock(&dentry->d_lock);\n \t}\n \trcu_read_unlock();\n\n \treturn found;\n}\n\n/**\n * d_hash_and_lookup - hash the qstr then search for a dentry\n * @dir: Directory to search in\n * @name: qstr of name we wish to find\n *\n * On lookup failure NULL is returned; on bad name - ERR_PTR(-error)\n */\nstruct dentry *d_hash_and_lookup(struct dentry *dir, struct qstr *name)\n{\n\t/*\n\t * Check for a fs-specific hash function. Note that we must\n\t * calculate the standard hash first, as the d_op->d_hash()\n\t * routine may choose to leave the hash value unchanged.\n\t */\n\tname->hash = full_name_hash(dir, name->name, name->len);\n\tif (dir->d_flags & DCACHE_OP_HASH) {\n\t\tint err = dir->d_op->d_hash(dir, name);\n\t\tif (unlikely(err < 0))\n\t\t\treturn ERR_PTR(err);\n\t}\n\treturn d_lookup(dir, name);\n}\nEXPORT_SYMBOL(d_hash_and_lookup);\n\n/*\n * When a file is deleted, we have two options:\n * - turn this dentry into a negative dentry\n * - unhash this dentry and free it.\n *\n * Usually, we want to just turn this into\n * a negative dentry, but if anybody else is\n * currently using the dentry or the inode\n * we can't do that and we fall back on removing\n * it from the hash queues and waiting for\n * it to be deleted later when it has no users\n */\n \n/**\n * d_delete - delete a dentry\n * @dentry: The dentry to delete\n *\n * Turn the dentry into a negative dentry if possible, otherwise\n * remove it from the hash queues so it can be deleted later\n */\n \nvoid d_delete(struct dentry * dentry)\n{\n\tstruct inode *inode;\n\tint isdir = 0;\n\t/*\n\t * Are we the only user?\n\t */\nagain:\n\tspin_lock(&dentry->d_lock);\n\tinode = dentry->d_inode;\n\tisdir = S_ISDIR(inode->i_mode);\n\tif (dentry->d_lockref.count == 1) {\n\t\tif (!spin_trylock(&inode->i_lock)) {\n\t\t\tspin_unlock(&dentry->d_lock);\n\t\t\tcpu_relax();\n\t\t\tgoto again;\n\t\t}\n\t\tdentry->d_flags &= ~DCACHE_CANT_MOUNT;\n\t\tdentry_unlink_inode(dentry);\n\t\tfsnotify_nameremove(dentry, isdir);\n\t\treturn;\n\t}\n\n\tif (!d_unhashed(dentry))\n\t\t__d_drop(dentry);\n\n\tspin_unlock(&dentry->d_lock);\n\n\tfsnotify_nameremove(dentry, isdir);\n}\nEXPORT_SYMBOL(d_delete);\n\nstatic void __d_rehash(struct dentry *entry)\n{\n\tstruct hlist_bl_head *b = d_hash(entry->d_name.hash);\n\tBUG_ON(!d_unhashed(entry));\n\thlist_bl_lock(b);\n\thlist_bl_add_head_rcu(&entry->d_hash, b);\n\thlist_bl_unlock(b);\n}\n\n/**\n * d_rehash\t- add an entry back to the hash\n * @entry: dentry to add to the hash\n *\n * Adds a dentry to the hash according to its name.\n */\n \nvoid d_rehash(struct dentry * entry)\n{\n\tspin_lock(&entry->d_lock);\n\t__d_rehash(entry);\n\tspin_unlock(&entry->d_lock);\n}\nEXPORT_SYMBOL(d_rehash);\n\nstatic inline unsigned start_dir_add(struct inode *dir)\n{\n\n\tfor (;;) {\n\t\tunsigned n = dir->i_dir_seq;\n\t\tif (!(n & 1) && cmpxchg(&dir->i_dir_seq, n, n + 1) == n)\n\t\t\treturn n;\n\t\tcpu_relax();\n\t}\n}\n\nstatic inline void end_dir_add(struct inode *dir, unsigned n)\n{\n\tsmp_store_release(&dir->i_dir_seq, n + 2);\n}\n\nstatic void d_wait_lookup(struct dentry *dentry)\n{\n\tif (d_in_lookup(dentry)) {\n\t\tDECLARE_WAITQUEUE(wait, current);\n\t\tadd_wait_queue(dentry->d_wait, &wait);\n\t\tdo {\n\t\t\tset_current_state(TASK_UNINTERRUPTIBLE);\n\t\t\tspin_unlock(&dentry->d_lock);\n\t\t\tschedule();\n\t\t\tspin_lock(&dentry->d_lock);\n\t\t} while (d_in_lookup(dentry));\n\t}\n}\n\nstruct dentry *d_alloc_parallel(struct dentry *parent,\n\t\t\t\tconst struct qstr *name,\n\t\t\t\twait_queue_head_t *wq)\n{\n\tunsigned int hash = name->hash;\n\tstruct hlist_bl_head *b = in_lookup_hash(parent, hash);\n\tstruct hlist_bl_node *node;\n\tstruct dentry *new = d_alloc(parent, name);\n\tstruct dentry *dentry;\n\tunsigned seq, r_seq, d_seq;\n\n\tif (unlikely(!new))\n\t\treturn ERR_PTR(-ENOMEM);\n\nretry:\n\trcu_read_lock();\n\tseq = smp_load_acquire(&parent->d_inode->i_dir_seq) & ~1;\n\tr_seq = read_seqbegin(&rename_lock);\n\tdentry = __d_lookup_rcu(parent, name, &d_seq);\n\tif (unlikely(dentry)) {\n\t\tif (!lockref_get_not_dead(&dentry->d_lockref)) {\n\t\t\trcu_read_unlock();\n\t\t\tgoto retry;\n\t\t}\n\t\tif (read_seqcount_retry(&dentry->d_seq, d_seq)) {\n\t\t\trcu_read_unlock();\n\t\t\tdput(dentry);\n\t\t\tgoto retry;\n\t\t}\n\t\trcu_read_unlock();\n\t\tdput(new);\n\t\treturn dentry;\n\t}\n\tif (unlikely(read_seqretry(&rename_lock, r_seq))) {\n\t\trcu_read_unlock();\n\t\tgoto retry;\n\t}\n\thlist_bl_lock(b);\n\tif (unlikely(parent->d_inode->i_dir_seq != seq)) {\n\t\thlist_bl_unlock(b);\n\t\trcu_read_unlock();\n\t\tgoto retry;\n\t}\n\t/*\n\t * No changes for the parent since the beginning of d_lookup().\n\t * Since all removals from the chain happen with hlist_bl_lock(),\n\t * any potential in-lookup matches are going to stay here until\n\t * we unlock the chain.  All fields are stable in everything\n\t * we encounter.\n\t */\n\thlist_bl_for_each_entry(dentry, node, b, d_u.d_in_lookup_hash) {\n\t\tif (dentry->d_name.hash != hash)\n\t\t\tcontinue;\n\t\tif (dentry->d_parent != parent)\n\t\t\tcontinue;\n\t\tif (!d_same_name(dentry, parent, name))\n\t\t\tcontinue;\n\t\thlist_bl_unlock(b);\n\t\t/* now we can try to grab a reference */\n\t\tif (!lockref_get_not_dead(&dentry->d_lockref)) {\n\t\t\trcu_read_unlock();\n\t\t\tgoto retry;\n\t\t}\n\n\t\trcu_read_unlock();\n\t\t/*\n\t\t * somebody is likely to be still doing lookup for it;\n\t\t * wait for them to finish\n\t\t */\n\t\tspin_lock(&dentry->d_lock);\n\t\td_wait_lookup(dentry);\n\t\t/*\n\t\t * it's not in-lookup anymore; in principle we should repeat\n\t\t * everything from dcache lookup, but it's likely to be what\n\t\t * d_lookup() would've found anyway.  If it is, just return it;\n\t\t * otherwise we really have to repeat the whole thing.\n\t\t */\n\t\tif (unlikely(dentry->d_name.hash != hash))\n\t\t\tgoto mismatch;\n\t\tif (unlikely(dentry->d_parent != parent))\n\t\t\tgoto mismatch;\n\t\tif (unlikely(d_unhashed(dentry)))\n\t\t\tgoto mismatch;\n\t\tif (unlikely(!d_same_name(dentry, parent, name)))\n\t\t\tgoto mismatch;\n\t\t/* OK, it *is* a hashed match; return it */\n\t\tspin_unlock(&dentry->d_lock);\n\t\tdput(new);\n\t\treturn dentry;\n\t}\n\trcu_read_unlock();\n\t/* we can't take ->d_lock here; it's OK, though. */\n\tnew->d_flags |= DCACHE_PAR_LOOKUP;\n\tnew->d_wait = wq;\n\thlist_bl_add_head_rcu(&new->d_u.d_in_lookup_hash, b);\n\thlist_bl_unlock(b);\n\treturn new;\nmismatch:\n\tspin_unlock(&dentry->d_lock);\n\tdput(dentry);\n\tgoto retry;\n}\nEXPORT_SYMBOL(d_alloc_parallel);\n\nvoid __d_lookup_done(struct dentry *dentry)\n{\n\tstruct hlist_bl_head *b = in_lookup_hash(dentry->d_parent,\n\t\t\t\t\t\t dentry->d_name.hash);\n\thlist_bl_lock(b);\n\tdentry->d_flags &= ~DCACHE_PAR_LOOKUP;\n\t__hlist_bl_del(&dentry->d_u.d_in_lookup_hash);\n\twake_up_all(dentry->d_wait);\n\tdentry->d_wait = NULL;\n\thlist_bl_unlock(b);\n\tINIT_HLIST_NODE(&dentry->d_u.d_alias);\n\tINIT_LIST_HEAD(&dentry->d_lru);\n}\nEXPORT_SYMBOL(__d_lookup_done);\n\n/* inode->i_lock held if inode is non-NULL */\n\nstatic inline void __d_add(struct dentry *dentry, struct inode *inode)\n{\n\tstruct inode *dir = NULL;\n\tunsigned n;\n\tspin_lock(&dentry->d_lock);\n\tif (unlikely(d_in_lookup(dentry))) {\n\t\tdir = dentry->d_parent->d_inode;\n\t\tn = start_dir_add(dir);\n\t\t__d_lookup_done(dentry);\n\t}\n\tif (inode) {\n\t\tunsigned add_flags = d_flags_for_inode(inode);\n\t\thlist_add_head(&dentry->d_u.d_alias, &inode->i_dentry);\n\t\traw_write_seqcount_begin(&dentry->d_seq);\n\t\t__d_set_inode_and_type(dentry, inode, add_flags);\n\t\traw_write_seqcount_end(&dentry->d_seq);\n\t\tfsnotify_update_flags(dentry);\n\t}\n\t__d_rehash(dentry);\n\tif (dir)\n\t\tend_dir_add(dir, n);\n\tspin_unlock(&dentry->d_lock);\n\tif (inode)\n\t\tspin_unlock(&inode->i_lock);\n}\n\n/**\n * d_add - add dentry to hash queues\n * @entry: dentry to add\n * @inode: The inode to attach to this dentry\n *\n * This adds the entry to the hash queues and initializes @inode.\n * The entry was actually filled in earlier during d_alloc().\n */\n\nvoid d_add(struct dentry *entry, struct inode *inode)\n{\n\tif (inode) {\n\t\tsecurity_d_instantiate(entry, inode);\n\t\tspin_lock(&inode->i_lock);\n\t}\n\t__d_add(entry, inode);\n}\nEXPORT_SYMBOL(d_add);\n\n/**\n * d_exact_alias - find and hash an exact unhashed alias\n * @entry: dentry to add\n * @inode: The inode to go with this dentry\n *\n * If an unhashed dentry with the same name/parent and desired\n * inode already exists, hash and return it.  Otherwise, return\n * NULL.\n *\n * Parent directory should be locked.\n */\nstruct dentry *d_exact_alias(struct dentry *entry, struct inode *inode)\n{\n\tstruct dentry *alias;\n\tunsigned int hash = entry->d_name.hash;\n\n\tspin_lock(&inode->i_lock);\n\thlist_for_each_entry(alias, &inode->i_dentry, d_u.d_alias) {\n\t\t/*\n\t\t * Don't need alias->d_lock here, because aliases with\n\t\t * d_parent == entry->d_parent are not subject to name or\n\t\t * parent changes, because the parent inode i_mutex is held.\n\t\t */\n\t\tif (alias->d_name.hash != hash)\n\t\t\tcontinue;\n\t\tif (alias->d_parent != entry->d_parent)\n\t\t\tcontinue;\n\t\tif (!d_same_name(alias, entry->d_parent, &entry->d_name))\n\t\t\tcontinue;\n\t\tspin_lock(&alias->d_lock);\n\t\tif (!d_unhashed(alias)) {\n\t\t\tspin_unlock(&alias->d_lock);\n\t\t\talias = NULL;\n\t\t} else {\n\t\t\t__dget_dlock(alias);\n\t\t\t__d_rehash(alias);\n\t\t\tspin_unlock(&alias->d_lock);\n\t\t}\n\t\tspin_unlock(&inode->i_lock);\n\t\treturn alias;\n\t}\n\tspin_unlock(&inode->i_lock);\n\treturn NULL;\n}\nEXPORT_SYMBOL(d_exact_alias);\n\n/**\n * dentry_update_name_case - update case insensitive dentry with a new name\n * @dentry: dentry to be updated\n * @name: new name\n *\n * Update a case insensitive dentry with new case of name.\n *\n * dentry must have been returned by d_lookup with name @name. Old and new\n * name lengths must match (ie. no d_compare which allows mismatched name\n * lengths).\n *\n * Parent inode i_mutex must be held over d_lookup and into this call (to\n * keep renames and concurrent inserts, and readdir(2) away).\n */\nvoid dentry_update_name_case(struct dentry *dentry, const struct qstr *name)\n{\n\tBUG_ON(!inode_is_locked(dentry->d_parent->d_inode));\n\tBUG_ON(dentry->d_name.len != name->len); /* d_lookup gives this */\n\n\tspin_lock(&dentry->d_lock);\n\twrite_seqcount_begin(&dentry->d_seq);\n\tmemcpy((unsigned char *)dentry->d_name.name, name->name, name->len);\n\twrite_seqcount_end(&dentry->d_seq);\n\tspin_unlock(&dentry->d_lock);\n}\nEXPORT_SYMBOL(dentry_update_name_case);\n\nstatic void swap_names(struct dentry *dentry, struct dentry *target)\n{\n\tif (unlikely(dname_external(target))) {\n\t\tif (unlikely(dname_external(dentry))) {\n\t\t\t/*\n\t\t\t * Both external: swap the pointers\n\t\t\t */\n\t\t\tswap(target->d_name.name, dentry->d_name.name);\n\t\t} else {\n\t\t\t/*\n\t\t\t * dentry:internal, target:external.  Steal target's\n\t\t\t * storage and make target internal.\n\t\t\t */\n\t\t\tmemcpy(target->d_iname, dentry->d_name.name,\n\t\t\t\t\tdentry->d_name.len + 1);\n\t\t\tdentry->d_name.name = target->d_name.name;\n\t\t\ttarget->d_name.name = target->d_iname;\n\t\t}\n\t} else {\n\t\tif (unlikely(dname_external(dentry))) {\n\t\t\t/*\n\t\t\t * dentry:external, target:internal.  Give dentry's\n\t\t\t * storage to target and make dentry internal\n\t\t\t */\n\t\t\tmemcpy(dentry->d_iname, target->d_name.name,\n\t\t\t\t\ttarget->d_name.len + 1);\n\t\t\ttarget->d_name.name = dentry->d_name.name;\n\t\t\tdentry->d_name.name = dentry->d_iname;\n\t\t} else {\n\t\t\t/*\n\t\t\t * Both are internal.\n\t\t\t */\n\t\t\tunsigned int i;\n\t\t\tBUILD_BUG_ON(!IS_ALIGNED(DNAME_INLINE_LEN, sizeof(long)));\n\t\t\tkmemcheck_mark_initialized(dentry->d_iname, DNAME_INLINE_LEN);\n\t\t\tkmemcheck_mark_initialized(target->d_iname, DNAME_INLINE_LEN);\n\t\t\tfor (i = 0; i < DNAME_INLINE_LEN / sizeof(long); i++) {\n\t\t\t\tswap(((long *) &dentry->d_iname)[i],\n\t\t\t\t     ((long *) &target->d_iname)[i]);\n\t\t\t}\n\t\t}\n\t}\n\tswap(dentry->d_name.hash_len, target->d_name.hash_len);\n}\n\nstatic void copy_name(struct dentry *dentry, struct dentry *target)\n{\n\tstruct external_name *old_name = NULL;\n\tif (unlikely(dname_external(dentry)))\n\t\told_name = external_name(dentry);\n\tif (unlikely(dname_external(target))) {\n\t\tatomic_inc(&external_name(target)->u.count);\n\t\tdentry->d_name = target->d_name;\n\t} else {\n\t\tmemcpy(dentry->d_iname, target->d_name.name,\n\t\t\t\ttarget->d_name.len + 1);\n\t\tdentry->d_name.name = dentry->d_iname;\n\t\tdentry->d_name.hash_len = target->d_name.hash_len;\n\t}\n\tif (old_name && likely(atomic_dec_and_test(&old_name->u.count)))\n\t\tkfree_rcu(old_name, u.head);\n}\n\nstatic void dentry_lock_for_move(struct dentry *dentry, struct dentry *target)\n{\n\t/*\n\t * XXXX: do we really need to take target->d_lock?\n\t */\n\tif (IS_ROOT(dentry) || dentry->d_parent == target->d_parent)\n\t\tspin_lock(&target->d_parent->d_lock);\n\telse {\n\t\tif (d_ancestor(dentry->d_parent, target->d_parent)) {\n\t\t\tspin_lock(&dentry->d_parent->d_lock);\n\t\t\tspin_lock_nested(&target->d_parent->d_lock,\n\t\t\t\t\t\tDENTRY_D_LOCK_NESTED);\n\t\t} else {\n\t\t\tspin_lock(&target->d_parent->d_lock);\n\t\t\tspin_lock_nested(&dentry->d_parent->d_lock,\n\t\t\t\t\t\tDENTRY_D_LOCK_NESTED);\n\t\t}\n\t}\n\tif (target < dentry) {\n\t\tspin_lock_nested(&target->d_lock, 2);\n\t\tspin_lock_nested(&dentry->d_lock, 3);\n\t} else {\n\t\tspin_lock_nested(&dentry->d_lock, 2);\n\t\tspin_lock_nested(&target->d_lock, 3);\n\t}\n}\n\nstatic void dentry_unlock_for_move(struct dentry *dentry, struct dentry *target)\n{\n\tif (target->d_parent != dentry->d_parent)\n\t\tspin_unlock(&dentry->d_parent->d_lock);\n\tif (target->d_parent != target)\n\t\tspin_unlock(&target->d_parent->d_lock);\n\tspin_unlock(&target->d_lock);\n\tspin_unlock(&dentry->d_lock);\n}\n\n/*\n * When switching names, the actual string doesn't strictly have to\n * be preserved in the target - because we're dropping the target\n * anyway. As such, we can just do a simple memcpy() to copy over\n * the new name before we switch, unless we are going to rehash\n * it.  Note that if we *do* unhash the target, we are not allowed\n * to rehash it without giving it a new name/hash key - whether\n * we swap or overwrite the names here, resulting name won't match\n * the reality in filesystem; it's only there for d_path() purposes.\n * Note that all of this is happening under rename_lock, so the\n * any hash lookup seeing it in the middle of manipulations will\n * be discarded anyway.  So we do not care what happens to the hash\n * key in that case.\n */\n/*\n * __d_move - move a dentry\n * @dentry: entry to move\n * @target: new dentry\n * @exchange: exchange the two dentries\n *\n * Update the dcache to reflect the move of a file name. Negative\n * dcache entries should not be moved in this way. Caller must hold\n * rename_lock, the i_mutex of the source and target directories,\n * and the sb->s_vfs_rename_mutex if they differ. See lock_rename().\n */\nstatic void __d_move(struct dentry *dentry, struct dentry *target,\n\t\t     bool exchange)\n{\n\tstruct inode *dir = NULL;\n\tunsigned n;\n\tif (!dentry->d_inode)\n\t\tprintk(KERN_WARNING \"VFS: moving negative dcache entry\\n\");\n\n\tBUG_ON(d_ancestor(dentry, target));\n\tBUG_ON(d_ancestor(target, dentry));\n\n\tdentry_lock_for_move(dentry, target);\n\tif (unlikely(d_in_lookup(target))) {\n\t\tdir = target->d_parent->d_inode;\n\t\tn = start_dir_add(dir);\n\t\t__d_lookup_done(target);\n\t}\n\n\twrite_seqcount_begin(&dentry->d_seq);\n\twrite_seqcount_begin_nested(&target->d_seq, DENTRY_D_LOCK_NESTED);\n\n\t/* unhash both */\n\t/* __d_drop does write_seqcount_barrier, but they're OK to nest. */\n\t__d_drop(dentry);\n\t__d_drop(target);\n\n\t/* Switch the names.. */\n\tif (exchange)\n\t\tswap_names(dentry, target);\n\telse\n\t\tcopy_name(dentry, target);\n\n\t/* rehash in new place(s) */\n\t__d_rehash(dentry);\n\tif (exchange)\n\t\t__d_rehash(target);\n\n\t/* ... and switch them in the tree */\n\tif (IS_ROOT(dentry)) {\n\t\t/* splicing a tree */\n\t\tdentry->d_flags |= DCACHE_RCUACCESS;\n\t\tdentry->d_parent = target->d_parent;\n\t\ttarget->d_parent = target;\n\t\tlist_del_init(&target->d_child);\n\t\tlist_move(&dentry->d_child, &dentry->d_parent->d_subdirs);\n\t} else {\n\t\t/* swapping two dentries */\n\t\tswap(dentry->d_parent, target->d_parent);\n\t\tlist_move(&target->d_child, &target->d_parent->d_subdirs);\n\t\tlist_move(&dentry->d_child, &dentry->d_parent->d_subdirs);\n\t\tif (exchange)\n\t\t\tfsnotify_update_flags(target);\n\t\tfsnotify_update_flags(dentry);\n\t}\n\n\twrite_seqcount_end(&target->d_seq);\n\twrite_seqcount_end(&dentry->d_seq);\n\n\tif (dir)\n\t\tend_dir_add(dir, n);\n\tdentry_unlock_for_move(dentry, target);\n}\n\n/*\n * d_move - move a dentry\n * @dentry: entry to move\n * @target: new dentry\n *\n * Update the dcache to reflect the move of a file name. Negative\n * dcache entries should not be moved in this way. See the locking\n * requirements for __d_move.\n */\nvoid d_move(struct dentry *dentry, struct dentry *target)\n{\n\twrite_seqlock(&rename_lock);\n\t__d_move(dentry, target, false);\n\twrite_sequnlock(&rename_lock);\n}\nEXPORT_SYMBOL(d_move);\n\n/*\n * d_exchange - exchange two dentries\n * @dentry1: first dentry\n * @dentry2: second dentry\n */\nvoid d_exchange(struct dentry *dentry1, struct dentry *dentry2)\n{\n\twrite_seqlock(&rename_lock);\n\n\tWARN_ON(!dentry1->d_inode);\n\tWARN_ON(!dentry2->d_inode);\n\tWARN_ON(IS_ROOT(dentry1));\n\tWARN_ON(IS_ROOT(dentry2));\n\n\t__d_move(dentry1, dentry2, true);\n\n\twrite_sequnlock(&rename_lock);\n}\n\n/**\n * d_ancestor - search for an ancestor\n * @p1: ancestor dentry\n * @p2: child dentry\n *\n * Returns the ancestor dentry of p2 which is a child of p1, if p1 is\n * an ancestor of p2, else NULL.\n */\nstruct dentry *d_ancestor(struct dentry *p1, struct dentry *p2)\n{\n\tstruct dentry *p;\n\n\tfor (p = p2; !IS_ROOT(p); p = p->d_parent) {\n\t\tif (p->d_parent == p1)\n\t\t\treturn p;\n\t}\n\treturn NULL;\n}\n\n/*\n * This helper attempts to cope with remotely renamed directories\n *\n * It assumes that the caller is already holding\n * dentry->d_parent->d_inode->i_mutex, and rename_lock\n *\n * Note: If ever the locking in lock_rename() changes, then please\n * remember to update this too...\n */\nstatic int __d_unalias(struct inode *inode,\n\t\tstruct dentry *dentry, struct dentry *alias)\n{\n\tstruct mutex *m1 = NULL;\n\tstruct rw_semaphore *m2 = NULL;\n\tint ret = -ESTALE;\n\n\t/* If alias and dentry share a parent, then no extra locks required */\n\tif (alias->d_parent == dentry->d_parent)\n\t\tgoto out_unalias;\n\n\t/* See lock_rename() */\n\tif (!mutex_trylock(&dentry->d_sb->s_vfs_rename_mutex))\n\t\tgoto out_err;\n\tm1 = &dentry->d_sb->s_vfs_rename_mutex;\n\tif (!inode_trylock_shared(alias->d_parent->d_inode))\n\t\tgoto out_err;\n\tm2 = &alias->d_parent->d_inode->i_rwsem;\nout_unalias:\n\t__d_move(alias, dentry, false);\n\tret = 0;\nout_err:\n\tif (m2)\n\t\tup_read(m2);\n\tif (m1)\n\t\tmutex_unlock(m1);\n\treturn ret;\n}\n\n/**\n * d_splice_alias - splice a disconnected dentry into the tree if one exists\n * @inode:  the inode which may have a disconnected dentry\n * @dentry: a negative dentry which we want to point to the inode.\n *\n * If inode is a directory and has an IS_ROOT alias, then d_move that in\n * place of the given dentry and return it, else simply d_add the inode\n * to the dentry and return NULL.\n *\n * If a non-IS_ROOT directory is found, the filesystem is corrupt, and\n * we should error out: directories can't have multiple aliases.\n *\n * This is needed in the lookup routine of any filesystem that is exportable\n * (via knfsd) so that we can build dcache paths to directories effectively.\n *\n * If a dentry was found and moved, then it is returned.  Otherwise NULL\n * is returned.  This matches the expected return value of ->lookup.\n *\n * Cluster filesystems may call this function with a negative, hashed dentry.\n * In that case, we know that the inode will be a regular file, and also this\n * will only occur during atomic_open. So we need to check for the dentry\n * being already hashed only in the final case.\n */\nstruct dentry *d_splice_alias(struct inode *inode, struct dentry *dentry)\n{\n\tif (IS_ERR(inode))\n\t\treturn ERR_CAST(inode);\n\n\tBUG_ON(!d_unhashed(dentry));\n\n\tif (!inode)\n\t\tgoto out;\n\n\tsecurity_d_instantiate(dentry, inode);\n\tspin_lock(&inode->i_lock);\n\tif (S_ISDIR(inode->i_mode)) {\n\t\tstruct dentry *new = __d_find_any_alias(inode);\n\t\tif (unlikely(new)) {\n\t\t\t/* The reference to new ensures it remains an alias */\n\t\t\tspin_unlock(&inode->i_lock);\n\t\t\twrite_seqlock(&rename_lock);\n\t\t\tif (unlikely(d_ancestor(new, dentry))) {\n\t\t\t\twrite_sequnlock(&rename_lock);\n\t\t\t\tdput(new);\n\t\t\t\tnew = ERR_PTR(-ELOOP);\n\t\t\t\tpr_warn_ratelimited(\n\t\t\t\t\t\"VFS: Lookup of '%s' in %s %s\"\n\t\t\t\t\t\" would have caused loop\\n\",\n\t\t\t\t\tdentry->d_name.name,\n\t\t\t\t\tinode->i_sb->s_type->name,\n\t\t\t\t\tinode->i_sb->s_id);\n\t\t\t} else if (!IS_ROOT(new)) {\n\t\t\t\tint err = __d_unalias(inode, dentry, new);\n\t\t\t\twrite_sequnlock(&rename_lock);\n\t\t\t\tif (err) {\n\t\t\t\t\tdput(new);\n\t\t\t\t\tnew = ERR_PTR(err);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t__d_move(new, dentry, false);\n\t\t\t\twrite_sequnlock(&rename_lock);\n\t\t\t}\n\t\t\tiput(inode);\n\t\t\treturn new;\n\t\t}\n\t}\nout:\n\t__d_add(dentry, inode);\n\treturn NULL;\n}\nEXPORT_SYMBOL(d_splice_alias);\n\nstatic int prepend(char **buffer, int *buflen, const char *str, int namelen)\n{\n\t*buflen -= namelen;\n\tif (*buflen < 0)\n\t\treturn -ENAMETOOLONG;\n\t*buffer -= namelen;\n\tmemcpy(*buffer, str, namelen);\n\treturn 0;\n}\n\n/**\n * prepend_name - prepend a pathname in front of current buffer pointer\n * @buffer: buffer pointer\n * @buflen: allocated length of the buffer\n * @name:   name string and length qstr structure\n *\n * With RCU path tracing, it may race with d_move(). Use ACCESS_ONCE() to\n * make sure that either the old or the new name pointer and length are\n * fetched. However, there may be mismatch between length and pointer.\n * The length cannot be trusted, we need to copy it byte-by-byte until\n * the length is reached or a null byte is found. It also prepends \"/\" at\n * the beginning of the name. The sequence number check at the caller will\n * retry it again when a d_move() does happen. So any garbage in the buffer\n * due to mismatched pointer and length will be discarded.\n *\n * Data dependency barrier is needed to make sure that we see that terminating\n * NUL.  Alpha strikes again, film at 11...\n */\nstatic int prepend_name(char **buffer, int *buflen, const struct qstr *name)\n{\n\tconst char *dname = ACCESS_ONCE(name->name);\n\tu32 dlen = ACCESS_ONCE(name->len);\n\tchar *p;\n\n\tsmp_read_barrier_depends();\n\n\t*buflen -= dlen + 1;\n\tif (*buflen < 0)\n\t\treturn -ENAMETOOLONG;\n\tp = *buffer -= dlen + 1;\n\t*p++ = '/';\n\twhile (dlen--) {\n\t\tchar c = *dname++;\n\t\tif (!c)\n\t\t\tbreak;\n\t\t*p++ = c;\n\t}\n\treturn 0;\n}\n\n/**\n * prepend_path - Prepend path string to a buffer\n * @path: the dentry/vfsmount to report\n * @root: root vfsmnt/dentry\n * @buffer: pointer to the end of the buffer\n * @buflen: pointer to buffer length\n *\n * The function will first try to write out the pathname without taking any\n * lock other than the RCU read lock to make sure that dentries won't go away.\n * It only checks the sequence number of the global rename_lock as any change\n * in the dentry's d_seq will be preceded by changes in the rename_lock\n * sequence number. If the sequence number had been changed, it will restart\n * the whole pathname back-tracing sequence again by taking the rename_lock.\n * In this case, there is no need to take the RCU read lock as the recursive\n * parent pointer references will keep the dentry chain alive as long as no\n * rename operation is performed.\n */\nstatic int prepend_path(const struct path *path,\n\t\t\tconst struct path *root,\n\t\t\tchar **buffer, int *buflen)\n{\n\tstruct dentry *dentry;\n\tstruct vfsmount *vfsmnt;\n\tstruct mount *mnt;\n\tint error = 0;\n\tunsigned seq, m_seq = 0;\n\tchar *bptr;\n\tint blen;\n\n\trcu_read_lock();\nrestart_mnt:\n\tread_seqbegin_or_lock(&mount_lock, &m_seq);\n\tseq = 0;\n\trcu_read_lock();\nrestart:\n\tbptr = *buffer;\n\tblen = *buflen;\n\terror = 0;\n\tdentry = path->dentry;\n\tvfsmnt = path->mnt;\n\tmnt = real_mount(vfsmnt);\n\tread_seqbegin_or_lock(&rename_lock, &seq);\n\twhile (dentry != root->dentry || vfsmnt != root->mnt) {\n\t\tstruct dentry * parent;\n\n\t\tif (dentry == vfsmnt->mnt_root || IS_ROOT(dentry)) {\n\t\t\tstruct mount *parent = ACCESS_ONCE(mnt->mnt_parent);\n\t\t\t/* Escaped? */\n\t\t\tif (dentry != vfsmnt->mnt_root) {\n\t\t\t\tbptr = *buffer;\n\t\t\t\tblen = *buflen;\n\t\t\t\terror = 3;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t/* Global root? */\n\t\t\tif (mnt != parent) {\n\t\t\t\tdentry = ACCESS_ONCE(mnt->mnt_mountpoint);\n\t\t\t\tmnt = parent;\n\t\t\t\tvfsmnt = &mnt->mnt;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (!error)\n\t\t\t\terror = is_mounted(vfsmnt) ? 1 : 2;\n\t\t\tbreak;\n\t\t}\n\t\tparent = dentry->d_parent;\n\t\tprefetch(parent);\n\t\terror = prepend_name(&bptr, &blen, &dentry->d_name);\n\t\tif (error)\n\t\t\tbreak;\n\n\t\tdentry = parent;\n\t}\n\tif (!(seq & 1))\n\t\trcu_read_unlock();\n\tif (need_seqretry(&rename_lock, seq)) {\n\t\tseq = 1;\n\t\tgoto restart;\n\t}\n\tdone_seqretry(&rename_lock, seq);\n\n\tif (!(m_seq & 1))\n\t\trcu_read_unlock();\n\tif (need_seqretry(&mount_lock, m_seq)) {\n\t\tm_seq = 1;\n\t\tgoto restart_mnt;\n\t}\n\tdone_seqretry(&mount_lock, m_seq);\n\n\tif (error >= 0 && bptr == *buffer) {\n\t\tif (--blen < 0)\n\t\t\terror = -ENAMETOOLONG;\n\t\telse\n\t\t\t*--bptr = '/';\n\t}\n\t*buffer = bptr;\n\t*buflen = blen;\n\treturn error;\n}\n\n/**\n * __d_path - return the path of a dentry\n * @path: the dentry/vfsmount to report\n * @root: root vfsmnt/dentry\n * @buf: buffer to return value in\n * @buflen: buffer length\n *\n * Convert a dentry into an ASCII path name.\n *\n * Returns a pointer into the buffer or an error code if the\n * path was too long.\n *\n * \"buflen\" should be positive.\n *\n * If the path is not reachable from the supplied root, return %NULL.\n */\nchar *__d_path(const struct path *path,\n\t       const struct path *root,\n\t       char *buf, int buflen)\n{\n\tchar *res = buf + buflen;\n\tint error;\n\n\tprepend(&res, &buflen, \"\\0\", 1);\n\terror = prepend_path(path, root, &res, &buflen);\n\n\tif (error < 0)\n\t\treturn ERR_PTR(error);\n\tif (error > 0)\n\t\treturn NULL;\n\treturn res;\n}\n\nchar *d_absolute_path(const struct path *path,\n\t       char *buf, int buflen)\n{\n\tstruct path root = {};\n\tchar *res = buf + buflen;\n\tint error;\n\n\tprepend(&res, &buflen, \"\\0\", 1);\n\terror = prepend_path(path, &root, &res, &buflen);\n\n\tif (error > 1)\n\t\terror = -EINVAL;\n\tif (error < 0)\n\t\treturn ERR_PTR(error);\n\treturn res;\n}\n\n/*\n * same as __d_path but appends \"(deleted)\" for unlinked files.\n */\nstatic int path_with_deleted(const struct path *path,\n\t\t\t     const struct path *root,\n\t\t\t     char **buf, int *buflen)\n{\n\tprepend(buf, buflen, \"\\0\", 1);\n\tif (d_unlinked(path->dentry)) {\n\t\tint error = prepend(buf, buflen, \" (deleted)\", 10);\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\n\treturn prepend_path(path, root, buf, buflen);\n}\n\nstatic int prepend_unreachable(char **buffer, int *buflen)\n{\n\treturn prepend(buffer, buflen, \"(unreachable)\", 13);\n}\n\nstatic void get_fs_root_rcu(struct fs_struct *fs, struct path *root)\n{\n\tunsigned seq;\n\n\tdo {\n\t\tseq = read_seqcount_begin(&fs->seq);\n\t\t*root = fs->root;\n\t} while (read_seqcount_retry(&fs->seq, seq));\n}\n\n/**\n * d_path - return the path of a dentry\n * @path: path to report\n * @buf: buffer to return value in\n * @buflen: buffer length\n *\n * Convert a dentry into an ASCII path name. If the entry has been deleted\n * the string \" (deleted)\" is appended. Note that this is ambiguous.\n *\n * Returns a pointer into the buffer or an error code if the path was\n * too long. Note: Callers should use the returned pointer, not the passed\n * in buffer, to use the name! The implementation often starts at an offset\n * into the buffer, and may leave 0 bytes at the start.\n *\n * \"buflen\" should be positive.\n */\nchar *d_path(const struct path *path, char *buf, int buflen)\n{\n\tchar *res = buf + buflen;\n\tstruct path root;\n\tint error;\n\n\t/*\n\t * We have various synthetic filesystems that never get mounted.  On\n\t * these filesystems dentries are never used for lookup purposes, and\n\t * thus don't need to be hashed.  They also don't need a name until a\n\t * user wants to identify the object in /proc/pid/fd/.  The little hack\n\t * below allows us to generate a name for these objects on demand:\n\t *\n\t * Some pseudo inodes are mountable.  When they are mounted\n\t * path->dentry == path->mnt->mnt_root.  In that case don't call d_dname\n\t * and instead have d_path return the mounted path.\n\t */\n\tif (path->dentry->d_op && path->dentry->d_op->d_dname &&\n\t    (!IS_ROOT(path->dentry) || path->dentry != path->mnt->mnt_root))\n\t\treturn path->dentry->d_op->d_dname(path->dentry, buf, buflen);\n\n\trcu_read_lock();\n\tget_fs_root_rcu(current->fs, &root);\n\terror = path_with_deleted(path, &root, &res, &buflen);\n\trcu_read_unlock();\n\n\tif (error < 0)\n\t\tres = ERR_PTR(error);\n\treturn res;\n}\nEXPORT_SYMBOL(d_path);\n\n/*\n * Helper function for dentry_operations.d_dname() members\n */\nchar *dynamic_dname(struct dentry *dentry, char *buffer, int buflen,\n\t\t\tconst char *fmt, ...)\n{\n\tva_list args;\n\tchar temp[64];\n\tint sz;\n\n\tva_start(args, fmt);\n\tsz = vsnprintf(temp, sizeof(temp), fmt, args) + 1;\n\tva_end(args);\n\n\tif (sz > sizeof(temp) || sz > buflen)\n\t\treturn ERR_PTR(-ENAMETOOLONG);\n\n\tbuffer += buflen - sz;\n\treturn memcpy(buffer, temp, sz);\n}\n\nchar *simple_dname(struct dentry *dentry, char *buffer, int buflen)\n{\n\tchar *end = buffer + buflen;\n\t/* these dentries are never renamed, so d_lock is not needed */\n\tif (prepend(&end, &buflen, \" (deleted)\", 11) ||\n\t    prepend(&end, &buflen, dentry->d_name.name, dentry->d_name.len) ||\n\t    prepend(&end, &buflen, \"/\", 1))  \n\t\tend = ERR_PTR(-ENAMETOOLONG);\n\treturn end;\n}\nEXPORT_SYMBOL(simple_dname);\n\n/*\n * Write full pathname from the root of the filesystem into the buffer.\n */\nstatic char *__dentry_path(struct dentry *d, char *buf, int buflen)\n{\n\tstruct dentry *dentry;\n\tchar *end, *retval;\n\tint len, seq = 0;\n\tint error = 0;\n\n\tif (buflen < 2)\n\t\tgoto Elong;\n\n\trcu_read_lock();\nrestart:\n\tdentry = d;\n\tend = buf + buflen;\n\tlen = buflen;\n\tprepend(&end, &len, \"\\0\", 1);\n\t/* Get '/' right */\n\tretval = end-1;\n\t*retval = '/';\n\tread_seqbegin_or_lock(&rename_lock, &seq);\n\twhile (!IS_ROOT(dentry)) {\n\t\tstruct dentry *parent = dentry->d_parent;\n\n\t\tprefetch(parent);\n\t\terror = prepend_name(&end, &len, &dentry->d_name);\n\t\tif (error)\n\t\t\tbreak;\n\n\t\tretval = end;\n\t\tdentry = parent;\n\t}\n\tif (!(seq & 1))\n\t\trcu_read_unlock();\n\tif (need_seqretry(&rename_lock, seq)) {\n\t\tseq = 1;\n\t\tgoto restart;\n\t}\n\tdone_seqretry(&rename_lock, seq);\n\tif (error)\n\t\tgoto Elong;\n\treturn retval;\nElong:\n\treturn ERR_PTR(-ENAMETOOLONG);\n}\n\nchar *dentry_path_raw(struct dentry *dentry, char *buf, int buflen)\n{\n\treturn __dentry_path(dentry, buf, buflen);\n}\nEXPORT_SYMBOL(dentry_path_raw);\n\nchar *dentry_path(struct dentry *dentry, char *buf, int buflen)\n{\n\tchar *p = NULL;\n\tchar *retval;\n\n\tif (d_unlinked(dentry)) {\n\t\tp = buf + buflen;\n\t\tif (prepend(&p, &buflen, \"//deleted\", 10) != 0)\n\t\t\tgoto Elong;\n\t\tbuflen++;\n\t}\n\tretval = __dentry_path(dentry, buf, buflen);\n\tif (!IS_ERR(retval) && p)\n\t\t*p = '/';\t/* restore '/' overriden with '\\0' */\n\treturn retval;\nElong:\n\treturn ERR_PTR(-ENAMETOOLONG);\n}\n\nstatic void get_fs_root_and_pwd_rcu(struct fs_struct *fs, struct path *root,\n\t\t\t\t    struct path *pwd)\n{\n\tunsigned seq;\n\n\tdo {\n\t\tseq = read_seqcount_begin(&fs->seq);\n\t\t*root = fs->root;\n\t\t*pwd = fs->pwd;\n\t} while (read_seqcount_retry(&fs->seq, seq));\n}\n\n/*\n * NOTE! The user-level library version returns a\n * character pointer. The kernel system call just\n * returns the length of the buffer filled (which\n * includes the ending '\\0' character), or a negative\n * error value. So libc would do something like\n *\n *\tchar *getcwd(char * buf, size_t size)\n *\t{\n *\t\tint retval;\n *\n *\t\tretval = sys_getcwd(buf, size);\n *\t\tif (retval >= 0)\n *\t\t\treturn buf;\n *\t\terrno = -retval;\n *\t\treturn NULL;\n *\t}\n */\nSYSCALL_DEFINE2(getcwd, char __user *, buf, unsigned long, size)\n{\n\tint error;\n\tstruct path pwd, root;\n\tchar *page = __getname();\n\n\tif (!page)\n\t\treturn -ENOMEM;\n\n\trcu_read_lock();\n\tget_fs_root_and_pwd_rcu(current->fs, &root, &pwd);\n\n\terror = -ENOENT;\n\tif (!d_unlinked(pwd.dentry)) {\n\t\tunsigned long len;\n\t\tchar *cwd = page + PATH_MAX;\n\t\tint buflen = PATH_MAX;\n\n\t\tprepend(&cwd, &buflen, \"\\0\", 1);\n\t\terror = prepend_path(&pwd, &root, &cwd, &buflen);\n\t\trcu_read_unlock();\n\n\t\tif (error < 0)\n\t\t\tgoto out;\n\n\t\t/* Unreachable from current root */\n\t\tif (error > 0) {\n\t\t\terror = prepend_unreachable(&cwd, &buflen);\n\t\t\tif (error)\n\t\t\t\tgoto out;\n\t\t}\n\n\t\terror = -ERANGE;\n\t\tlen = PATH_MAX + page - cwd;\n\t\tif (len <= size) {\n\t\t\terror = len;\n\t\t\tif (copy_to_user(buf, cwd, len))\n\t\t\t\terror = -EFAULT;\n\t\t}\n\t} else {\n\t\trcu_read_unlock();\n\t}\n\nout:\n\t__putname(page);\n\treturn error;\n}\n\n/*\n * Test whether new_dentry is a subdirectory of old_dentry.\n *\n * Trivially implemented using the dcache structure\n */\n\n/**\n * is_subdir - is new dentry a subdirectory of old_dentry\n * @new_dentry: new dentry\n * @old_dentry: old dentry\n *\n * Returns true if new_dentry is a subdirectory of the parent (at any depth).\n * Returns false otherwise.\n * Caller must ensure that \"new_dentry\" is pinned before calling is_subdir()\n */\n  \nbool is_subdir(struct dentry *new_dentry, struct dentry *old_dentry)\n{\n\tbool result;\n\tunsigned seq;\n\n\tif (new_dentry == old_dentry)\n\t\treturn true;\n\n\tdo {\n\t\t/* for restarting inner loop in case of seq retry */\n\t\tseq = read_seqbegin(&rename_lock);\n\t\t/*\n\t\t * Need rcu_readlock to protect against the d_parent trashing\n\t\t * due to d_move\n\t\t */\n\t\trcu_read_lock();\n\t\tif (d_ancestor(old_dentry, new_dentry))\n\t\t\tresult = true;\n\t\telse\n\t\t\tresult = false;\n\t\trcu_read_unlock();\n\t} while (read_seqretry(&rename_lock, seq));\n\n\treturn result;\n}\n\nstatic enum d_walk_ret d_genocide_kill(void *data, struct dentry *dentry)\n{\n\tstruct dentry *root = data;\n\tif (dentry != root) {\n\t\tif (d_unhashed(dentry) || !dentry->d_inode)\n\t\t\treturn D_WALK_SKIP;\n\n\t\tif (!(dentry->d_flags & DCACHE_GENOCIDE)) {\n\t\t\tdentry->d_flags |= DCACHE_GENOCIDE;\n\t\t\tdentry->d_lockref.count--;\n\t\t}\n\t}\n\treturn D_WALK_CONTINUE;\n}\n\nvoid d_genocide(struct dentry *parent)\n{\n\td_walk(parent, parent, d_genocide_kill, NULL);\n}\n\nvoid d_tmpfile(struct dentry *dentry, struct inode *inode)\n{\n\tinode_dec_link_count(inode);\n\tBUG_ON(dentry->d_name.name != dentry->d_iname ||\n\t\t!hlist_unhashed(&dentry->d_u.d_alias) ||\n\t\t!d_unlinked(dentry));\n\tspin_lock(&dentry->d_parent->d_lock);\n\tspin_lock_nested(&dentry->d_lock, DENTRY_D_LOCK_NESTED);\n\tdentry->d_name.len = sprintf(dentry->d_iname, \"#%llu\",\n\t\t\t\t(unsigned long long)inode->i_ino);\n\tspin_unlock(&dentry->d_lock);\n\tspin_unlock(&dentry->d_parent->d_lock);\n\td_instantiate(dentry, inode);\n}\nEXPORT_SYMBOL(d_tmpfile);\n\nstatic __initdata unsigned long dhash_entries;\nstatic int __init set_dhash_entries(char *str)\n{\n\tif (!str)\n\t\treturn 0;\n\tdhash_entries = simple_strtoul(str, &str, 0);\n\treturn 1;\n}\n__setup(\"dhash_entries=\", set_dhash_entries);\n\nstatic void __init dcache_init_early(void)\n{\n\tunsigned int loop;\n\n\t/* If hashes are distributed across NUMA nodes, defer\n\t * hash allocation until vmalloc space is available.\n\t */\n\tif (hashdist)\n\t\treturn;\n\n\tdentry_hashtable =\n\t\talloc_large_system_hash(\"Dentry cache\",\n\t\t\t\t\tsizeof(struct hlist_bl_head),\n\t\t\t\t\tdhash_entries,\n\t\t\t\t\t13,\n\t\t\t\t\tHASH_EARLY,\n\t\t\t\t\t&d_hash_shift,\n\t\t\t\t\t&d_hash_mask,\n\t\t\t\t\t0,\n\t\t\t\t\t0);\n\n\tfor (loop = 0; loop < (1U << d_hash_shift); loop++)\n\t\tINIT_HLIST_BL_HEAD(dentry_hashtable + loop);\n}\n\nstatic void __init dcache_init(void)\n{\n\tunsigned int loop;\n\n\t/* \n\t * A constructor could be added for stable state like the lists,\n\t * but it is probably not worth it because of the cache nature\n\t * of the dcache. \n\t */\n\tdentry_cache = KMEM_CACHE(dentry,\n\t\tSLAB_RECLAIM_ACCOUNT|SLAB_PANIC|SLAB_MEM_SPREAD|SLAB_ACCOUNT);\n\n\t/* Hash may have been set up in dcache_init_early */\n\tif (!hashdist)\n\t\treturn;\n\n\tdentry_hashtable =\n\t\talloc_large_system_hash(\"Dentry cache\",\n\t\t\t\t\tsizeof(struct hlist_bl_head),\n\t\t\t\t\tdhash_entries,\n\t\t\t\t\t13,\n\t\t\t\t\t0,\n\t\t\t\t\t&d_hash_shift,\n\t\t\t\t\t&d_hash_mask,\n\t\t\t\t\t0,\n\t\t\t\t\t0);\n\n\tfor (loop = 0; loop < (1U << d_hash_shift); loop++)\n\t\tINIT_HLIST_BL_HEAD(dentry_hashtable + loop);\n}\n\n/* SLAB cache for __getname() consumers */\nstruct kmem_cache *names_cachep __read_mostly;\nEXPORT_SYMBOL(names_cachep);\n\nEXPORT_SYMBOL(d_genocide);\n\nvoid __init vfs_caches_init_early(void)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(in_lookup_hashtable); i++)\n\t\tINIT_HLIST_BL_HEAD(&in_lookup_hashtable[i]);\n\n\tdcache_init_early();\n\tinode_init_early();\n}\n\nvoid __init vfs_caches_init(void)\n{\n\tnames_cachep = kmem_cache_create(\"names_cache\", PATH_MAX, 0,\n\t\t\tSLAB_HWCACHE_ALIGN|SLAB_PANIC, NULL);\n\n\tdcache_init();\n\tinode_init();\n\tfiles_init();\n\tfiles_maxfiles_init();\n\tmnt_init();\n\tbdev_cache_init();\n\tchrdev_init();\n}\n", "/*\n *  inode.c - part of debugfs, a tiny little debug file system\n *\n *  Copyright (C) 2004 Greg Kroah-Hartman <greg@kroah.com>\n *  Copyright (C) 2004 IBM Inc.\n *\n *\tThis program is free software; you can redistribute it and/or\n *\tmodify it under the terms of the GNU General Public License version\n *\t2 as published by the Free Software Foundation.\n *\n *  debugfs is for people to use instead of /proc or /sys.\n *  See Documentation/DocBook/kernel-api for more details.\n *\n */\n\n#include <linux/module.h>\n#include <linux/fs.h>\n#include <linux/mount.h>\n#include <linux/pagemap.h>\n#include <linux/init.h>\n#include <linux/kobject.h>\n#include <linux/namei.h>\n#include <linux/debugfs.h>\n#include <linux/fsnotify.h>\n#include <linux/string.h>\n#include <linux/seq_file.h>\n#include <linux/parser.h>\n#include <linux/magic.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n\n#include \"internal.h\"\n\n#define DEBUGFS_DEFAULT_MODE\t0700\n\nDEFINE_SRCU(debugfs_srcu);\n\nstatic struct vfsmount *debugfs_mount;\nstatic int debugfs_mount_count;\nstatic bool debugfs_registered;\n\nstatic struct inode *debugfs_get_inode(struct super_block *sb)\n{\n\tstruct inode *inode = new_inode(sb);\n\tif (inode) {\n\t\tinode->i_ino = get_next_ino();\n\t\tinode->i_atime = inode->i_mtime =\n\t\t\tinode->i_ctime = current_time(inode);\n\t}\n\treturn inode;\n}\n\nstruct debugfs_mount_opts {\n\tkuid_t uid;\n\tkgid_t gid;\n\tumode_t mode;\n};\n\nenum {\n\tOpt_uid,\n\tOpt_gid,\n\tOpt_mode,\n\tOpt_err\n};\n\nstatic const match_table_t tokens = {\n\t{Opt_uid, \"uid=%u\"},\n\t{Opt_gid, \"gid=%u\"},\n\t{Opt_mode, \"mode=%o\"},\n\t{Opt_err, NULL}\n};\n\nstruct debugfs_fs_info {\n\tstruct debugfs_mount_opts mount_opts;\n};\n\nstatic int debugfs_parse_options(char *data, struct debugfs_mount_opts *opts)\n{\n\tsubstring_t args[MAX_OPT_ARGS];\n\tint option;\n\tint token;\n\tkuid_t uid;\n\tkgid_t gid;\n\tchar *p;\n\n\topts->mode = DEBUGFS_DEFAULT_MODE;\n\n\twhile ((p = strsep(&data, \",\")) != NULL) {\n\t\tif (!*p)\n\t\t\tcontinue;\n\n\t\ttoken = match_token(p, tokens, args);\n\t\tswitch (token) {\n\t\tcase Opt_uid:\n\t\t\tif (match_int(&args[0], &option))\n\t\t\t\treturn -EINVAL;\n\t\t\tuid = make_kuid(current_user_ns(), option);\n\t\t\tif (!uid_valid(uid))\n\t\t\t\treturn -EINVAL;\n\t\t\topts->uid = uid;\n\t\t\tbreak;\n\t\tcase Opt_gid:\n\t\t\tif (match_int(&args[0], &option))\n\t\t\t\treturn -EINVAL;\n\t\t\tgid = make_kgid(current_user_ns(), option);\n\t\t\tif (!gid_valid(gid))\n\t\t\t\treturn -EINVAL;\n\t\t\topts->gid = gid;\n\t\t\tbreak;\n\t\tcase Opt_mode:\n\t\t\tif (match_octal(&args[0], &option))\n\t\t\t\treturn -EINVAL;\n\t\t\topts->mode = option & S_IALLUGO;\n\t\t\tbreak;\n\t\t/*\n\t\t * We might like to report bad mount options here;\n\t\t * but traditionally debugfs has ignored all mount options\n\t\t */\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int debugfs_apply_options(struct super_block *sb)\n{\n\tstruct debugfs_fs_info *fsi = sb->s_fs_info;\n\tstruct inode *inode = d_inode(sb->s_root);\n\tstruct debugfs_mount_opts *opts = &fsi->mount_opts;\n\n\tinode->i_mode &= ~S_IALLUGO;\n\tinode->i_mode |= opts->mode;\n\n\tinode->i_uid = opts->uid;\n\tinode->i_gid = opts->gid;\n\n\treturn 0;\n}\n\nstatic int debugfs_remount(struct super_block *sb, int *flags, char *data)\n{\n\tint err;\n\tstruct debugfs_fs_info *fsi = sb->s_fs_info;\n\n\tsync_filesystem(sb);\n\terr = debugfs_parse_options(data, &fsi->mount_opts);\n\tif (err)\n\t\tgoto fail;\n\n\tdebugfs_apply_options(sb);\n\nfail:\n\treturn err;\n}\n\nstatic int debugfs_show_options(struct seq_file *m, struct dentry *root)\n{\n\tstruct debugfs_fs_info *fsi = root->d_sb->s_fs_info;\n\tstruct debugfs_mount_opts *opts = &fsi->mount_opts;\n\n\tif (!uid_eq(opts->uid, GLOBAL_ROOT_UID))\n\t\tseq_printf(m, \",uid=%u\",\n\t\t\t   from_kuid_munged(&init_user_ns, opts->uid));\n\tif (!gid_eq(opts->gid, GLOBAL_ROOT_GID))\n\t\tseq_printf(m, \",gid=%u\",\n\t\t\t   from_kgid_munged(&init_user_ns, opts->gid));\n\tif (opts->mode != DEBUGFS_DEFAULT_MODE)\n\t\tseq_printf(m, \",mode=%o\", opts->mode);\n\n\treturn 0;\n}\n\nstatic void debugfs_evict_inode(struct inode *inode)\n{\n\ttruncate_inode_pages_final(&inode->i_data);\n\tclear_inode(inode);\n\tif (S_ISLNK(inode->i_mode))\n\t\tkfree(inode->i_link);\n}\n\nstatic const struct super_operations debugfs_super_operations = {\n\t.statfs\t\t= simple_statfs,\n\t.remount_fs\t= debugfs_remount,\n\t.show_options\t= debugfs_show_options,\n\t.evict_inode\t= debugfs_evict_inode,\n};\n\nstatic struct vfsmount *debugfs_automount(struct path *path)\n{\n\tdebugfs_automount_t f;\n\tf = (debugfs_automount_t)path->dentry->d_fsdata;\n\treturn f(path->dentry, d_inode(path->dentry)->i_private);\n}\n\nstatic const struct dentry_operations debugfs_dops = {\n\t.d_delete = always_delete_dentry,\n\t.d_automount = debugfs_automount,\n};\n\nstatic int debug_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tstatic const struct tree_descr debug_files[] = {{\"\"}};\n\tstruct debugfs_fs_info *fsi;\n\tint err;\n\n\tsave_mount_options(sb, data);\n\n\tfsi = kzalloc(sizeof(struct debugfs_fs_info), GFP_KERNEL);\n\tsb->s_fs_info = fsi;\n\tif (!fsi) {\n\t\terr = -ENOMEM;\n\t\tgoto fail;\n\t}\n\n\terr = debugfs_parse_options(data, &fsi->mount_opts);\n\tif (err)\n\t\tgoto fail;\n\n\terr  =  simple_fill_super(sb, DEBUGFS_MAGIC, debug_files);\n\tif (err)\n\t\tgoto fail;\n\n\tsb->s_op = &debugfs_super_operations;\n\tsb->s_d_op = &debugfs_dops;\n\n\tdebugfs_apply_options(sb);\n\n\treturn 0;\n\nfail:\n\tkfree(fsi);\n\tsb->s_fs_info = NULL;\n\treturn err;\n}\n\nstatic struct dentry *debug_mount(struct file_system_type *fs_type,\n\t\t\tint flags, const char *dev_name,\n\t\t\tvoid *data)\n{\n\treturn mount_single(fs_type, flags, data, debug_fill_super);\n}\n\nstatic struct file_system_type debug_fs_type = {\n\t.owner =\tTHIS_MODULE,\n\t.name =\t\t\"debugfs\",\n\t.mount =\tdebug_mount,\n\t.kill_sb =\tkill_litter_super,\n};\nMODULE_ALIAS_FS(\"debugfs\");\n\n/**\n * debugfs_lookup() - look up an existing debugfs file\n * @name: a pointer to a string containing the name of the file to look up.\n * @parent: a pointer to the parent dentry of the file.\n *\n * This function will return a pointer to a dentry if it succeeds.  If the file\n * doesn't exist or an error occurs, %NULL will be returned.  The returned\n * dentry must be passed to dput() when it is no longer needed.\n *\n * If debugfs is not enabled in the kernel, the value -%ENODEV will be\n * returned.\n */\nstruct dentry *debugfs_lookup(const char *name, struct dentry *parent)\n{\n\tstruct dentry *dentry;\n\n\tif (IS_ERR(parent))\n\t\treturn NULL;\n\n\tif (!parent)\n\t\tparent = debugfs_mount->mnt_root;\n\n\tinode_lock(d_inode(parent));\n\tdentry = lookup_one_len(name, parent, strlen(name));\n\tinode_unlock(d_inode(parent));\n\n\tif (IS_ERR(dentry))\n\t\treturn NULL;\n\tif (!d_really_is_positive(dentry)) {\n\t\tdput(dentry);\n\t\treturn NULL;\n\t}\n\treturn dentry;\n}\nEXPORT_SYMBOL_GPL(debugfs_lookup);\n\nstatic struct dentry *start_creating(const char *name, struct dentry *parent)\n{\n\tstruct dentry *dentry;\n\tint error;\n\n\tpr_debug(\"debugfs: creating file '%s'\\n\",name);\n\n\tif (IS_ERR(parent))\n\t\treturn parent;\n\n\terror = simple_pin_fs(&debug_fs_type, &debugfs_mount,\n\t\t\t      &debugfs_mount_count);\n\tif (error)\n\t\treturn ERR_PTR(error);\n\n\t/* If the parent is not specified, we create it in the root.\n\t * We need the root dentry to do this, which is in the super\n\t * block. A pointer to that is in the struct vfsmount that we\n\t * have around.\n\t */\n\tif (!parent)\n\t\tparent = debugfs_mount->mnt_root;\n\n\tinode_lock(d_inode(parent));\n\tdentry = lookup_one_len(name, parent, strlen(name));\n\tif (!IS_ERR(dentry) && d_really_is_positive(dentry)) {\n\t\tdput(dentry);\n\t\tdentry = ERR_PTR(-EEXIST);\n\t}\n\n\tif (IS_ERR(dentry)) {\n\t\tinode_unlock(d_inode(parent));\n\t\tsimple_release_fs(&debugfs_mount, &debugfs_mount_count);\n\t}\n\n\treturn dentry;\n}\n\nstatic struct dentry *failed_creating(struct dentry *dentry)\n{\n\tinode_unlock(d_inode(dentry->d_parent));\n\tdput(dentry);\n\tsimple_release_fs(&debugfs_mount, &debugfs_mount_count);\n\treturn NULL;\n}\n\nstatic struct dentry *end_creating(struct dentry *dentry)\n{\n\tinode_unlock(d_inode(dentry->d_parent));\n\treturn dentry;\n}\n\nstatic struct dentry *__debugfs_create_file(const char *name, umode_t mode,\n\t\t\t\tstruct dentry *parent, void *data,\n\t\t\t\tconst struct file_operations *proxy_fops,\n\t\t\t\tconst struct file_operations *real_fops)\n{\n\tstruct dentry *dentry;\n\tstruct inode *inode;\n\n\tif (!(mode & S_IFMT))\n\t\tmode |= S_IFREG;\n\tBUG_ON(!S_ISREG(mode));\n\tdentry = start_creating(name, parent);\n\n\tif (IS_ERR(dentry))\n\t\treturn NULL;\n\n\tinode = debugfs_get_inode(dentry->d_sb);\n\tif (unlikely(!inode))\n\t\treturn failed_creating(dentry);\n\n\tinode->i_mode = mode;\n\tinode->i_private = data;\n\n\tinode->i_fop = proxy_fops;\n\tdentry->d_fsdata = (void *)real_fops;\n\n\td_instantiate(dentry, inode);\n\tfsnotify_create(d_inode(dentry->d_parent), dentry);\n\treturn end_creating(dentry);\n}\n\n/**\n * debugfs_create_file - create a file in the debugfs filesystem\n * @name: a pointer to a string containing the name of the file to create.\n * @mode: the permission that the file should have.\n * @parent: a pointer to the parent dentry for this file.  This should be a\n *          directory dentry if set.  If this parameter is NULL, then the\n *          file will be created in the root of the debugfs filesystem.\n * @data: a pointer to something that the caller will want to get to later\n *        on.  The inode.i_private pointer will point to this value on\n *        the open() call.\n * @fops: a pointer to a struct file_operations that should be used for\n *        this file.\n *\n * This is the basic \"create a file\" function for debugfs.  It allows for a\n * wide range of flexibility in creating a file, or a directory (if you want\n * to create a directory, the debugfs_create_dir() function is\n * recommended to be used instead.)\n *\n * This function will return a pointer to a dentry if it succeeds.  This\n * pointer must be passed to the debugfs_remove() function when the file is\n * to be removed (no automatic cleanup happens if your module is unloaded,\n * you are responsible here.)  If an error occurs, %NULL will be returned.\n *\n * If debugfs is not enabled in the kernel, the value -%ENODEV will be\n * returned.\n */\nstruct dentry *debugfs_create_file(const char *name, umode_t mode,\n\t\t\t\t   struct dentry *parent, void *data,\n\t\t\t\t   const struct file_operations *fops)\n{\n\n\treturn __debugfs_create_file(name, mode, parent, data,\n\t\t\t\tfops ? &debugfs_full_proxy_file_operations :\n\t\t\t\t\t&debugfs_noop_file_operations,\n\t\t\t\tfops);\n}\nEXPORT_SYMBOL_GPL(debugfs_create_file);\n\n/**\n * debugfs_create_file_unsafe - create a file in the debugfs filesystem\n * @name: a pointer to a string containing the name of the file to create.\n * @mode: the permission that the file should have.\n * @parent: a pointer to the parent dentry for this file.  This should be a\n *          directory dentry if set.  If this parameter is NULL, then the\n *          file will be created in the root of the debugfs filesystem.\n * @data: a pointer to something that the caller will want to get to later\n *        on.  The inode.i_private pointer will point to this value on\n *        the open() call.\n * @fops: a pointer to a struct file_operations that should be used for\n *        this file.\n *\n * debugfs_create_file_unsafe() is completely analogous to\n * debugfs_create_file(), the only difference being that the fops\n * handed it will not get protected against file removals by the\n * debugfs core.\n *\n * It is your responsibility to protect your struct file_operation\n * methods against file removals by means of debugfs_use_file_start()\n * and debugfs_use_file_finish(). ->open() is still protected by\n * debugfs though.\n *\n * Any struct file_operations defined by means of\n * DEFINE_DEBUGFS_ATTRIBUTE() is protected against file removals and\n * thus, may be used here.\n */\nstruct dentry *debugfs_create_file_unsafe(const char *name, umode_t mode,\n\t\t\t\t   struct dentry *parent, void *data,\n\t\t\t\t   const struct file_operations *fops)\n{\n\n\treturn __debugfs_create_file(name, mode, parent, data,\n\t\t\t\tfops ? &debugfs_open_proxy_file_operations :\n\t\t\t\t\t&debugfs_noop_file_operations,\n\t\t\t\tfops);\n}\nEXPORT_SYMBOL_GPL(debugfs_create_file_unsafe);\n\n/**\n * debugfs_create_file_size - create a file in the debugfs filesystem\n * @name: a pointer to a string containing the name of the file to create.\n * @mode: the permission that the file should have.\n * @parent: a pointer to the parent dentry for this file.  This should be a\n *          directory dentry if set.  If this parameter is NULL, then the\n *          file will be created in the root of the debugfs filesystem.\n * @data: a pointer to something that the caller will want to get to later\n *        on.  The inode.i_private pointer will point to this value on\n *        the open() call.\n * @fops: a pointer to a struct file_operations that should be used for\n *        this file.\n * @file_size: initial file size\n *\n * This is the basic \"create a file\" function for debugfs.  It allows for a\n * wide range of flexibility in creating a file, or a directory (if you want\n * to create a directory, the debugfs_create_dir() function is\n * recommended to be used instead.)\n *\n * This function will return a pointer to a dentry if it succeeds.  This\n * pointer must be passed to the debugfs_remove() function when the file is\n * to be removed (no automatic cleanup happens if your module is unloaded,\n * you are responsible here.)  If an error occurs, %NULL will be returned.\n *\n * If debugfs is not enabled in the kernel, the value -%ENODEV will be\n * returned.\n */\nstruct dentry *debugfs_create_file_size(const char *name, umode_t mode,\n\t\t\t\t\tstruct dentry *parent, void *data,\n\t\t\t\t\tconst struct file_operations *fops,\n\t\t\t\t\tloff_t file_size)\n{\n\tstruct dentry *de = debugfs_create_file(name, mode, parent, data, fops);\n\n\tif (de)\n\t\td_inode(de)->i_size = file_size;\n\treturn de;\n}\nEXPORT_SYMBOL_GPL(debugfs_create_file_size);\n\n/**\n * debugfs_create_dir - create a directory in the debugfs filesystem\n * @name: a pointer to a string containing the name of the directory to\n *        create.\n * @parent: a pointer to the parent dentry for this file.  This should be a\n *          directory dentry if set.  If this parameter is NULL, then the\n *          directory will be created in the root of the debugfs filesystem.\n *\n * This function creates a directory in debugfs with the given name.\n *\n * This function will return a pointer to a dentry if it succeeds.  This\n * pointer must be passed to the debugfs_remove() function when the file is\n * to be removed (no automatic cleanup happens if your module is unloaded,\n * you are responsible here.)  If an error occurs, %NULL will be returned.\n *\n * If debugfs is not enabled in the kernel, the value -%ENODEV will be\n * returned.\n */\nstruct dentry *debugfs_create_dir(const char *name, struct dentry *parent)\n{\n\tstruct dentry *dentry = start_creating(name, parent);\n\tstruct inode *inode;\n\n\tif (IS_ERR(dentry))\n\t\treturn NULL;\n\n\tinode = debugfs_get_inode(dentry->d_sb);\n\tif (unlikely(!inode))\n\t\treturn failed_creating(dentry);\n\n\tinode->i_mode = S_IFDIR | S_IRWXU | S_IRUGO | S_IXUGO;\n\tinode->i_op = &simple_dir_inode_operations;\n\tinode->i_fop = &simple_dir_operations;\n\n\t/* directory inodes start off with i_nlink == 2 (for \".\" entry) */\n\tinc_nlink(inode);\n\td_instantiate(dentry, inode);\n\tinc_nlink(d_inode(dentry->d_parent));\n\tfsnotify_mkdir(d_inode(dentry->d_parent), dentry);\n\treturn end_creating(dentry);\n}\nEXPORT_SYMBOL_GPL(debugfs_create_dir);\n\n/**\n * debugfs_create_automount - create automount point in the debugfs filesystem\n * @name: a pointer to a string containing the name of the file to create.\n * @parent: a pointer to the parent dentry for this file.  This should be a\n *          directory dentry if set.  If this parameter is NULL, then the\n *          file will be created in the root of the debugfs filesystem.\n * @f: function to be called when pathname resolution steps on that one.\n * @data: opaque argument to pass to f().\n *\n * @f should return what ->d_automount() would.\n */\nstruct dentry *debugfs_create_automount(const char *name,\n\t\t\t\t\tstruct dentry *parent,\n\t\t\t\t\tdebugfs_automount_t f,\n\t\t\t\t\tvoid *data)\n{\n\tstruct dentry *dentry = start_creating(name, parent);\n\tstruct inode *inode;\n\n\tif (IS_ERR(dentry))\n\t\treturn NULL;\n\n\tinode = debugfs_get_inode(dentry->d_sb);\n\tif (unlikely(!inode))\n\t\treturn failed_creating(dentry);\n\n\tmake_empty_dir_inode(inode);\n\tinode->i_flags |= S_AUTOMOUNT;\n\tinode->i_private = data;\n\tdentry->d_fsdata = (void *)f;\n\t/* directory inodes start off with i_nlink == 2 (for \".\" entry) */\n\tinc_nlink(inode);\n\td_instantiate(dentry, inode);\n\tinc_nlink(d_inode(dentry->d_parent));\n\tfsnotify_mkdir(d_inode(dentry->d_parent), dentry);\n\treturn end_creating(dentry);\n}\nEXPORT_SYMBOL(debugfs_create_automount);\n\n/**\n * debugfs_create_symlink- create a symbolic link in the debugfs filesystem\n * @name: a pointer to a string containing the name of the symbolic link to\n *        create.\n * @parent: a pointer to the parent dentry for this symbolic link.  This\n *          should be a directory dentry if set.  If this parameter is NULL,\n *          then the symbolic link will be created in the root of the debugfs\n *          filesystem.\n * @target: a pointer to a string containing the path to the target of the\n *          symbolic link.\n *\n * This function creates a symbolic link with the given name in debugfs that\n * links to the given target path.\n *\n * This function will return a pointer to a dentry if it succeeds.  This\n * pointer must be passed to the debugfs_remove() function when the symbolic\n * link is to be removed (no automatic cleanup happens if your module is\n * unloaded, you are responsible here.)  If an error occurs, %NULL will be\n * returned.\n *\n * If debugfs is not enabled in the kernel, the value -%ENODEV will be\n * returned.\n */\nstruct dentry *debugfs_create_symlink(const char *name, struct dentry *parent,\n\t\t\t\t      const char *target)\n{\n\tstruct dentry *dentry;\n\tstruct inode *inode;\n\tchar *link = kstrdup(target, GFP_KERNEL);\n\tif (!link)\n\t\treturn NULL;\n\n\tdentry = start_creating(name, parent);\n\tif (IS_ERR(dentry)) {\n\t\tkfree(link);\n\t\treturn NULL;\n\t}\n\n\tinode = debugfs_get_inode(dentry->d_sb);\n\tif (unlikely(!inode)) {\n\t\tkfree(link);\n\t\treturn failed_creating(dentry);\n\t}\n\tinode->i_mode = S_IFLNK | S_IRWXUGO;\n\tinode->i_op = &simple_symlink_inode_operations;\n\tinode->i_link = link;\n\td_instantiate(dentry, inode);\n\treturn end_creating(dentry);\n}\nEXPORT_SYMBOL_GPL(debugfs_create_symlink);\n\nstatic int __debugfs_remove(struct dentry *dentry, struct dentry *parent)\n{\n\tint ret = 0;\n\n\tif (simple_positive(dentry)) {\n\t\tdget(dentry);\n\t\tif (d_is_dir(dentry))\n\t\t\tret = simple_rmdir(d_inode(parent), dentry);\n\t\telse\n\t\t\tsimple_unlink(d_inode(parent), dentry);\n\t\tif (!ret)\n\t\t\td_delete(dentry);\n\t\tdput(dentry);\n\t}\n\treturn ret;\n}\n\n/**\n * debugfs_remove - removes a file or directory from the debugfs filesystem\n * @dentry: a pointer to a the dentry of the file or directory to be\n *          removed.  If this parameter is NULL or an error value, nothing\n *          will be done.\n *\n * This function removes a file or directory in debugfs that was previously\n * created with a call to another debugfs function (like\n * debugfs_create_file() or variants thereof.)\n *\n * This function is required to be called in order for the file to be\n * removed, no automatic cleanup of files will happen when a module is\n * removed, you are responsible here.\n */\nvoid debugfs_remove(struct dentry *dentry)\n{\n\tstruct dentry *parent;\n\tint ret;\n\n\tif (IS_ERR_OR_NULL(dentry))\n\t\treturn;\n\n\tparent = dentry->d_parent;\n\tinode_lock(d_inode(parent));\n\tret = __debugfs_remove(dentry, parent);\n\tinode_unlock(d_inode(parent));\n\tif (!ret)\n\t\tsimple_release_fs(&debugfs_mount, &debugfs_mount_count);\n\n\tsynchronize_srcu(&debugfs_srcu);\n}\nEXPORT_SYMBOL_GPL(debugfs_remove);\n\n/**\n * debugfs_remove_recursive - recursively removes a directory\n * @dentry: a pointer to a the dentry of the directory to be removed.  If this\n *          parameter is NULL or an error value, nothing will be done.\n *\n * This function recursively removes a directory tree in debugfs that\n * was previously created with a call to another debugfs function\n * (like debugfs_create_file() or variants thereof.)\n *\n * This function is required to be called in order for the file to be\n * removed, no automatic cleanup of files will happen when a module is\n * removed, you are responsible here.\n */\nvoid debugfs_remove_recursive(struct dentry *dentry)\n{\n\tstruct dentry *child, *parent;\n\n\tif (IS_ERR_OR_NULL(dentry))\n\t\treturn;\n\n\tparent = dentry;\n down:\n\tinode_lock(d_inode(parent));\n loop:\n\t/*\n\t * The parent->d_subdirs is protected by the d_lock. Outside that\n\t * lock, the child can be unlinked and set to be freed which can\n\t * use the d_u.d_child as the rcu head and corrupt this list.\n\t */\n\tspin_lock(&parent->d_lock);\n\tlist_for_each_entry(child, &parent->d_subdirs, d_child) {\n\t\tif (!simple_positive(child))\n\t\t\tcontinue;\n\n\t\t/* perhaps simple_empty(child) makes more sense */\n\t\tif (!list_empty(&child->d_subdirs)) {\n\t\t\tspin_unlock(&parent->d_lock);\n\t\t\tinode_unlock(d_inode(parent));\n\t\t\tparent = child;\n\t\t\tgoto down;\n\t\t}\n\n\t\tspin_unlock(&parent->d_lock);\n\n\t\tif (!__debugfs_remove(child, parent))\n\t\t\tsimple_release_fs(&debugfs_mount, &debugfs_mount_count);\n\n\t\t/*\n\t\t * The parent->d_lock protects agaist child from unlinking\n\t\t * from d_subdirs. When releasing the parent->d_lock we can\n\t\t * no longer trust that the next pointer is valid.\n\t\t * Restart the loop. We'll skip this one with the\n\t\t * simple_positive() check.\n\t\t */\n\t\tgoto loop;\n\t}\n\tspin_unlock(&parent->d_lock);\n\n\tinode_unlock(d_inode(parent));\n\tchild = parent;\n\tparent = parent->d_parent;\n\tinode_lock(d_inode(parent));\n\n\tif (child != dentry)\n\t\t/* go up */\n\t\tgoto loop;\n\n\tif (!__debugfs_remove(child, parent))\n\t\tsimple_release_fs(&debugfs_mount, &debugfs_mount_count);\n\tinode_unlock(d_inode(parent));\n\n\tsynchronize_srcu(&debugfs_srcu);\n}\nEXPORT_SYMBOL_GPL(debugfs_remove_recursive);\n\n/**\n * debugfs_rename - rename a file/directory in the debugfs filesystem\n * @old_dir: a pointer to the parent dentry for the renamed object. This\n *          should be a directory dentry.\n * @old_dentry: dentry of an object to be renamed.\n * @new_dir: a pointer to the parent dentry where the object should be\n *          moved. This should be a directory dentry.\n * @new_name: a pointer to a string containing the target name.\n *\n * This function renames a file/directory in debugfs.  The target must not\n * exist for rename to succeed.\n *\n * This function will return a pointer to old_dentry (which is updated to\n * reflect renaming) if it succeeds. If an error occurs, %NULL will be\n * returned.\n *\n * If debugfs is not enabled in the kernel, the value -%ENODEV will be\n * returned.\n */\nstruct dentry *debugfs_rename(struct dentry *old_dir, struct dentry *old_dentry,\n\t\tstruct dentry *new_dir, const char *new_name)\n{\n\tint error;\n\tstruct dentry *dentry = NULL, *trap;\n\tconst char *old_name;\n\n\ttrap = lock_rename(new_dir, old_dir);\n\t/* Source or destination directories don't exist? */\n\tif (d_really_is_negative(old_dir) || d_really_is_negative(new_dir))\n\t\tgoto exit;\n\t/* Source does not exist, cyclic rename, or mountpoint? */\n\tif (d_really_is_negative(old_dentry) || old_dentry == trap ||\n\t    d_mountpoint(old_dentry))\n\t\tgoto exit;\n\tdentry = lookup_one_len(new_name, new_dir, strlen(new_name));\n\t/* Lookup failed, cyclic rename or target exists? */\n\tif (IS_ERR(dentry) || dentry == trap || d_really_is_positive(dentry))\n\t\tgoto exit;\n\n\told_name = fsnotify_oldname_init(old_dentry->d_name.name);\n\n\terror = simple_rename(d_inode(old_dir), old_dentry, d_inode(new_dir),\n\t\t\t      dentry, 0);\n\tif (error) {\n\t\tfsnotify_oldname_free(old_name);\n\t\tgoto exit;\n\t}\n\td_move(old_dentry, dentry);\n\tfsnotify_move(d_inode(old_dir), d_inode(new_dir), old_name,\n\t\td_is_dir(old_dentry),\n\t\tNULL, old_dentry);\n\tfsnotify_oldname_free(old_name);\n\tunlock_rename(new_dir, old_dir);\n\tdput(dentry);\n\treturn old_dentry;\nexit:\n\tif (dentry && !IS_ERR(dentry))\n\t\tdput(dentry);\n\tunlock_rename(new_dir, old_dir);\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(debugfs_rename);\n\n/**\n * debugfs_initialized - Tells whether debugfs has been registered\n */\nbool debugfs_initialized(void)\n{\n\treturn debugfs_registered;\n}\nEXPORT_SYMBOL_GPL(debugfs_initialized);\n\nstatic int __init debugfs_init(void)\n{\n\tint retval;\n\n\tretval = sysfs_create_mount_point(kernel_kobj, \"debug\");\n\tif (retval)\n\t\treturn retval;\n\n\tretval = register_filesystem(&debug_fs_type);\n\tif (retval)\n\t\tsysfs_remove_mount_point(kernel_kobj, \"debug\");\n\telse\n\t\tdebugfs_registered = true;\n\n\treturn retval;\n}\ncore_initcall(debugfs_init);\n\n", "/*\n *  linux/fs/namei.c\n *\n *  Copyright (C) 1991, 1992  Linus Torvalds\n */\n\n/*\n * Some corrections by tytso.\n */\n\n/* [Feb 1997 T. Schoebel-Theuer] Complete rewrite of the pathname\n * lookup logic.\n */\n/* [Feb-Apr 2000, AV] Rewrite to the new namespace architecture.\n */\n\n#include <linux/init.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/slab.h>\n#include <linux/fs.h>\n#include <linux/namei.h>\n#include <linux/pagemap.h>\n#include <linux/fsnotify.h>\n#include <linux/personality.h>\n#include <linux/security.h>\n#include <linux/ima.h>\n#include <linux/syscalls.h>\n#include <linux/mount.h>\n#include <linux/audit.h>\n#include <linux/capability.h>\n#include <linux/file.h>\n#include <linux/fcntl.h>\n#include <linux/device_cgroup.h>\n#include <linux/fs_struct.h>\n#include <linux/posix_acl.h>\n#include <linux/hash.h>\n#include <linux/bitops.h>\n#include <linux/init_task.h>\n#include <linux/uaccess.h>\n\n#include \"internal.h\"\n#include \"mount.h\"\n\n/* [Feb-1997 T. Schoebel-Theuer]\n * Fundamental changes in the pathname lookup mechanisms (namei)\n * were necessary because of omirr.  The reason is that omirr needs\n * to know the _real_ pathname, not the user-supplied one, in case\n * of symlinks (and also when transname replacements occur).\n *\n * The new code replaces the old recursive symlink resolution with\n * an iterative one (in case of non-nested symlink chains).  It does\n * this with calls to <fs>_follow_link().\n * As a side effect, dir_namei(), _namei() and follow_link() are now \n * replaced with a single function lookup_dentry() that can handle all \n * the special cases of the former code.\n *\n * With the new dcache, the pathname is stored at each inode, at least as\n * long as the refcount of the inode is positive.  As a side effect, the\n * size of the dcache depends on the inode cache and thus is dynamic.\n *\n * [29-Apr-1998 C. Scott Ananian] Updated above description of symlink\n * resolution to correspond with current state of the code.\n *\n * Note that the symlink resolution is not *completely* iterative.\n * There is still a significant amount of tail- and mid- recursion in\n * the algorithm.  Also, note that <fs>_readlink() is not used in\n * lookup_dentry(): lookup_dentry() on the result of <fs>_readlink()\n * may return different results than <fs>_follow_link().  Many virtual\n * filesystems (including /proc) exhibit this behavior.\n */\n\n/* [24-Feb-97 T. Schoebel-Theuer] Side effects caused by new implementation:\n * New symlink semantics: when open() is called with flags O_CREAT | O_EXCL\n * and the name already exists in form of a symlink, try to create the new\n * name indicated by the symlink. The old code always complained that the\n * name already exists, due to not following the symlink even if its target\n * is nonexistent.  The new semantics affects also mknod() and link() when\n * the name is a symlink pointing to a non-existent name.\n *\n * I don't know which semantics is the right one, since I have no access\n * to standards. But I found by trial that HP-UX 9.0 has the full \"new\"\n * semantics implemented, while SunOS 4.1.1 and Solaris (SunOS 5.4) have the\n * \"old\" one. Personally, I think the new semantics is much more logical.\n * Note that \"ln old new\" where \"new\" is a symlink pointing to a non-existing\n * file does succeed in both HP-UX and SunOs, but not in Solaris\n * and in the old Linux semantics.\n */\n\n/* [16-Dec-97 Kevin Buhr] For security reasons, we change some symlink\n * semantics.  See the comments in \"open_namei\" and \"do_link\" below.\n *\n * [10-Sep-98 Alan Modra] Another symlink change.\n */\n\n/* [Feb-Apr 2000 AV] Complete rewrite. Rules for symlinks:\n *\tinside the path - always follow.\n *\tin the last component in creation/removal/renaming - never follow.\n *\tif LOOKUP_FOLLOW passed - follow.\n *\tif the pathname has trailing slashes - follow.\n *\totherwise - don't follow.\n * (applied in that order).\n *\n * [Jun 2000 AV] Inconsistent behaviour of open() in case if flags==O_CREAT\n * restored for 2.4. This is the last surviving part of old 4.2BSD bug.\n * During the 2.4 we need to fix the userland stuff depending on it -\n * hopefully we will be able to get rid of that wart in 2.5. So far only\n * XEmacs seems to be relying on it...\n */\n/*\n * [Sep 2001 AV] Single-semaphore locking scheme (kudos to David Holland)\n * implemented.  Let's see if raised priority of ->s_vfs_rename_mutex gives\n * any extra contention...\n */\n\n/* In order to reduce some races, while at the same time doing additional\n * checking and hopefully speeding things up, we copy filenames to the\n * kernel data space before using them..\n *\n * POSIX.1 2.4: an empty pathname is invalid (ENOENT).\n * PATH_MAX includes the nul terminator --RR.\n */\n\n#define EMBEDDED_NAME_MAX\t(PATH_MAX - offsetof(struct filename, iname))\n\nstruct filename *\ngetname_flags(const char __user *filename, int flags, int *empty)\n{\n\tstruct filename *result;\n\tchar *kname;\n\tint len;\n\n\tresult = audit_reusename(filename);\n\tif (result)\n\t\treturn result;\n\n\tresult = __getname();\n\tif (unlikely(!result))\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t/*\n\t * First, try to embed the struct filename inside the names_cache\n\t * allocation\n\t */\n\tkname = (char *)result->iname;\n\tresult->name = kname;\n\n\tlen = strncpy_from_user(kname, filename, EMBEDDED_NAME_MAX);\n\tif (unlikely(len < 0)) {\n\t\t__putname(result);\n\t\treturn ERR_PTR(len);\n\t}\n\n\t/*\n\t * Uh-oh. We have a name that's approaching PATH_MAX. Allocate a\n\t * separate struct filename so we can dedicate the entire\n\t * names_cache allocation for the pathname, and re-do the copy from\n\t * userland.\n\t */\n\tif (unlikely(len == EMBEDDED_NAME_MAX)) {\n\t\tconst size_t size = offsetof(struct filename, iname[1]);\n\t\tkname = (char *)result;\n\n\t\t/*\n\t\t * size is chosen that way we to guarantee that\n\t\t * result->iname[0] is within the same object and that\n\t\t * kname can't be equal to result->iname, no matter what.\n\t\t */\n\t\tresult = kzalloc(size, GFP_KERNEL);\n\t\tif (unlikely(!result)) {\n\t\t\t__putname(kname);\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t}\n\t\tresult->name = kname;\n\t\tlen = strncpy_from_user(kname, filename, PATH_MAX);\n\t\tif (unlikely(len < 0)) {\n\t\t\t__putname(kname);\n\t\t\tkfree(result);\n\t\t\treturn ERR_PTR(len);\n\t\t}\n\t\tif (unlikely(len == PATH_MAX)) {\n\t\t\t__putname(kname);\n\t\t\tkfree(result);\n\t\t\treturn ERR_PTR(-ENAMETOOLONG);\n\t\t}\n\t}\n\n\tresult->refcnt = 1;\n\t/* The empty path is special. */\n\tif (unlikely(!len)) {\n\t\tif (empty)\n\t\t\t*empty = 1;\n\t\tif (!(flags & LOOKUP_EMPTY)) {\n\t\t\tputname(result);\n\t\t\treturn ERR_PTR(-ENOENT);\n\t\t}\n\t}\n\n\tresult->uptr = filename;\n\tresult->aname = NULL;\n\taudit_getname(result);\n\treturn result;\n}\n\nstruct filename *\ngetname(const char __user * filename)\n{\n\treturn getname_flags(filename, 0, NULL);\n}\n\nstruct filename *\ngetname_kernel(const char * filename)\n{\n\tstruct filename *result;\n\tint len = strlen(filename) + 1;\n\n\tresult = __getname();\n\tif (unlikely(!result))\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tif (len <= EMBEDDED_NAME_MAX) {\n\t\tresult->name = (char *)result->iname;\n\t} else if (len <= PATH_MAX) {\n\t\tstruct filename *tmp;\n\n\t\ttmp = kmalloc(sizeof(*tmp), GFP_KERNEL);\n\t\tif (unlikely(!tmp)) {\n\t\t\t__putname(result);\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t}\n\t\ttmp->name = (char *)result;\n\t\tresult = tmp;\n\t} else {\n\t\t__putname(result);\n\t\treturn ERR_PTR(-ENAMETOOLONG);\n\t}\n\tmemcpy((char *)result->name, filename, len);\n\tresult->uptr = NULL;\n\tresult->aname = NULL;\n\tresult->refcnt = 1;\n\taudit_getname(result);\n\n\treturn result;\n}\n\nvoid putname(struct filename *name)\n{\n\tBUG_ON(name->refcnt <= 0);\n\n\tif (--name->refcnt > 0)\n\t\treturn;\n\n\tif (name->name != name->iname) {\n\t\t__putname(name->name);\n\t\tkfree(name);\n\t} else\n\t\t__putname(name);\n}\n\nstatic int check_acl(struct inode *inode, int mask)\n{\n#ifdef CONFIG_FS_POSIX_ACL\n\tstruct posix_acl *acl;\n\n\tif (mask & MAY_NOT_BLOCK) {\n\t\tacl = get_cached_acl_rcu(inode, ACL_TYPE_ACCESS);\n\t        if (!acl)\n\t                return -EAGAIN;\n\t\t/* no ->get_acl() calls in RCU mode... */\n\t\tif (is_uncached_acl(acl))\n\t\t\treturn -ECHILD;\n\t        return posix_acl_permission(inode, acl, mask & ~MAY_NOT_BLOCK);\n\t}\n\n\tacl = get_acl(inode, ACL_TYPE_ACCESS);\n\tif (IS_ERR(acl))\n\t\treturn PTR_ERR(acl);\n\tif (acl) {\n\t        int error = posix_acl_permission(inode, acl, mask);\n\t        posix_acl_release(acl);\n\t        return error;\n\t}\n#endif\n\n\treturn -EAGAIN;\n}\n\n/*\n * This does the basic permission checking\n */\nstatic int acl_permission_check(struct inode *inode, int mask)\n{\n\tunsigned int mode = inode->i_mode;\n\n\tif (likely(uid_eq(current_fsuid(), inode->i_uid)))\n\t\tmode >>= 6;\n\telse {\n\t\tif (IS_POSIXACL(inode) && (mode & S_IRWXG)) {\n\t\t\tint error = check_acl(inode, mask);\n\t\t\tif (error != -EAGAIN)\n\t\t\t\treturn error;\n\t\t}\n\n\t\tif (in_group_p(inode->i_gid))\n\t\t\tmode >>= 3;\n\t}\n\n\t/*\n\t * If the DACs are ok we don't need any capability check.\n\t */\n\tif ((mask & ~mode & (MAY_READ | MAY_WRITE | MAY_EXEC)) == 0)\n\t\treturn 0;\n\treturn -EACCES;\n}\n\n/**\n * generic_permission -  check for access rights on a Posix-like filesystem\n * @inode:\tinode to check access rights for\n * @mask:\tright to check for (%MAY_READ, %MAY_WRITE, %MAY_EXEC, ...)\n *\n * Used to check for read/write/execute permissions on a file.\n * We use \"fsuid\" for this, letting us set arbitrary permissions\n * for filesystem access without changing the \"normal\" uids which\n * are used for other things.\n *\n * generic_permission is rcu-walk aware. It returns -ECHILD in case an rcu-walk\n * request cannot be satisfied (eg. requires blocking or too much complexity).\n * It would then be called again in ref-walk mode.\n */\nint generic_permission(struct inode *inode, int mask)\n{\n\tint ret;\n\n\t/*\n\t * Do the basic permission checks.\n\t */\n\tret = acl_permission_check(inode, mask);\n\tif (ret != -EACCES)\n\t\treturn ret;\n\n\tif (S_ISDIR(inode->i_mode)) {\n\t\t/* DACs are overridable for directories */\n\t\tif (!(mask & MAY_WRITE))\n\t\t\tif (capable_wrt_inode_uidgid(inode,\n\t\t\t\t\t\t     CAP_DAC_READ_SEARCH))\n\t\t\t\treturn 0;\n\t\tif (capable_wrt_inode_uidgid(inode, CAP_DAC_OVERRIDE))\n\t\t\treturn 0;\n\t\treturn -EACCES;\n\t}\n\n\t/*\n\t * Searching includes executable on directories, else just read.\n\t */\n\tmask &= MAY_READ | MAY_WRITE | MAY_EXEC;\n\tif (mask == MAY_READ)\n\t\tif (capable_wrt_inode_uidgid(inode, CAP_DAC_READ_SEARCH))\n\t\t\treturn 0;\n\t/*\n\t * Read/write DACs are always overridable.\n\t * Executable DACs are overridable when there is\n\t * at least one exec bit set.\n\t */\n\tif (!(mask & MAY_EXEC) || (inode->i_mode & S_IXUGO))\n\t\tif (capable_wrt_inode_uidgid(inode, CAP_DAC_OVERRIDE))\n\t\t\treturn 0;\n\n\treturn -EACCES;\n}\nEXPORT_SYMBOL(generic_permission);\n\n/*\n * We _really_ want to just do \"generic_permission()\" without\n * even looking at the inode->i_op values. So we keep a cache\n * flag in inode->i_opflags, that says \"this has not special\n * permission function, use the fast case\".\n */\nstatic inline int do_inode_permission(struct inode *inode, int mask)\n{\n\tif (unlikely(!(inode->i_opflags & IOP_FASTPERM))) {\n\t\tif (likely(inode->i_op->permission))\n\t\t\treturn inode->i_op->permission(inode, mask);\n\n\t\t/* This gets set once for the inode lifetime */\n\t\tspin_lock(&inode->i_lock);\n\t\tinode->i_opflags |= IOP_FASTPERM;\n\t\tspin_unlock(&inode->i_lock);\n\t}\n\treturn generic_permission(inode, mask);\n}\n\n/**\n * __inode_permission - Check for access rights to a given inode\n * @inode: Inode to check permission on\n * @mask: Right to check for (%MAY_READ, %MAY_WRITE, %MAY_EXEC)\n *\n * Check for read/write/execute permissions on an inode.\n *\n * When checking for MAY_APPEND, MAY_WRITE must also be set in @mask.\n *\n * This does not check for a read-only file system.  You probably want\n * inode_permission().\n */\nint __inode_permission(struct inode *inode, int mask)\n{\n\tint retval;\n\n\tif (unlikely(mask & MAY_WRITE)) {\n\t\t/*\n\t\t * Nobody gets write access to an immutable file.\n\t\t */\n\t\tif (IS_IMMUTABLE(inode))\n\t\t\treturn -EPERM;\n\n\t\t/*\n\t\t * Updating mtime will likely cause i_uid and i_gid to be\n\t\t * written back improperly if their true value is unknown\n\t\t * to the vfs.\n\t\t */\n\t\tif (HAS_UNMAPPED_ID(inode))\n\t\t\treturn -EACCES;\n\t}\n\n\tretval = do_inode_permission(inode, mask);\n\tif (retval)\n\t\treturn retval;\n\n\tretval = devcgroup_inode_permission(inode, mask);\n\tif (retval)\n\t\treturn retval;\n\n\treturn security_inode_permission(inode, mask);\n}\nEXPORT_SYMBOL(__inode_permission);\n\n/**\n * sb_permission - Check superblock-level permissions\n * @sb: Superblock of inode to check permission on\n * @inode: Inode to check permission on\n * @mask: Right to check for (%MAY_READ, %MAY_WRITE, %MAY_EXEC)\n *\n * Separate out file-system wide checks from inode-specific permission checks.\n */\nstatic int sb_permission(struct super_block *sb, struct inode *inode, int mask)\n{\n\tif (unlikely(mask & MAY_WRITE)) {\n\t\tumode_t mode = inode->i_mode;\n\n\t\t/* Nobody gets write access to a read-only fs. */\n\t\tif ((sb->s_flags & MS_RDONLY) &&\n\t\t    (S_ISREG(mode) || S_ISDIR(mode) || S_ISLNK(mode)))\n\t\t\treturn -EROFS;\n\t}\n\treturn 0;\n}\n\n/**\n * inode_permission - Check for access rights to a given inode\n * @inode: Inode to check permission on\n * @mask: Right to check for (%MAY_READ, %MAY_WRITE, %MAY_EXEC)\n *\n * Check for read/write/execute permissions on an inode.  We use fs[ug]id for\n * this, letting us set arbitrary permissions for filesystem access without\n * changing the \"normal\" UIDs which are used for other things.\n *\n * When checking for MAY_APPEND, MAY_WRITE must also be set in @mask.\n */\nint inode_permission(struct inode *inode, int mask)\n{\n\tint retval;\n\n\tretval = sb_permission(inode->i_sb, inode, mask);\n\tif (retval)\n\t\treturn retval;\n\treturn __inode_permission(inode, mask);\n}\nEXPORT_SYMBOL(inode_permission);\n\n/**\n * path_get - get a reference to a path\n * @path: path to get the reference to\n *\n * Given a path increment the reference count to the dentry and the vfsmount.\n */\nvoid path_get(const struct path *path)\n{\n\tmntget(path->mnt);\n\tdget(path->dentry);\n}\nEXPORT_SYMBOL(path_get);\n\n/**\n * path_put - put a reference to a path\n * @path: path to put the reference to\n *\n * Given a path decrement the reference count to the dentry and the vfsmount.\n */\nvoid path_put(const struct path *path)\n{\n\tdput(path->dentry);\n\tmntput(path->mnt);\n}\nEXPORT_SYMBOL(path_put);\n\n#define EMBEDDED_LEVELS 2\nstruct nameidata {\n\tstruct path\tpath;\n\tstruct qstr\tlast;\n\tstruct path\troot;\n\tstruct inode\t*inode; /* path.dentry.d_inode */\n\tunsigned int\tflags;\n\tunsigned\tseq, m_seq;\n\tint\t\tlast_type;\n\tunsigned\tdepth;\n\tint\t\ttotal_link_count;\n\tstruct saved {\n\t\tstruct path link;\n\t\tstruct delayed_call done;\n\t\tconst char *name;\n\t\tunsigned seq;\n\t} *stack, internal[EMBEDDED_LEVELS];\n\tstruct filename\t*name;\n\tstruct nameidata *saved;\n\tstruct inode\t*link_inode;\n\tunsigned\troot_seq;\n\tint\t\tdfd;\n};\n\nstatic void set_nameidata(struct nameidata *p, int dfd, struct filename *name)\n{\n\tstruct nameidata *old = current->nameidata;\n\tp->stack = p->internal;\n\tp->dfd = dfd;\n\tp->name = name;\n\tp->total_link_count = old ? old->total_link_count : 0;\n\tp->saved = old;\n\tcurrent->nameidata = p;\n}\n\nstatic void restore_nameidata(void)\n{\n\tstruct nameidata *now = current->nameidata, *old = now->saved;\n\n\tcurrent->nameidata = old;\n\tif (old)\n\t\told->total_link_count = now->total_link_count;\n\tif (now->stack != now->internal)\n\t\tkfree(now->stack);\n}\n\nstatic int __nd_alloc_stack(struct nameidata *nd)\n{\n\tstruct saved *p;\n\n\tif (nd->flags & LOOKUP_RCU) {\n\t\tp= kmalloc(MAXSYMLINKS * sizeof(struct saved),\n\t\t\t\t  GFP_ATOMIC);\n\t\tif (unlikely(!p))\n\t\t\treturn -ECHILD;\n\t} else {\n\t\tp= kmalloc(MAXSYMLINKS * sizeof(struct saved),\n\t\t\t\t  GFP_KERNEL);\n\t\tif (unlikely(!p))\n\t\t\treturn -ENOMEM;\n\t}\n\tmemcpy(p, nd->internal, sizeof(nd->internal));\n\tnd->stack = p;\n\treturn 0;\n}\n\n/**\n * path_connected - Verify that a path->dentry is below path->mnt.mnt_root\n * @path: nameidate to verify\n *\n * Rename can sometimes move a file or directory outside of a bind\n * mount, path_connected allows those cases to be detected.\n */\nstatic bool path_connected(const struct path *path)\n{\n\tstruct vfsmount *mnt = path->mnt;\n\n\t/* Only bind mounts can have disconnected paths */\n\tif (mnt->mnt_root == mnt->mnt_sb->s_root)\n\t\treturn true;\n\n\treturn is_subdir(path->dentry, mnt->mnt_root);\n}\n\nstatic inline int nd_alloc_stack(struct nameidata *nd)\n{\n\tif (likely(nd->depth != EMBEDDED_LEVELS))\n\t\treturn 0;\n\tif (likely(nd->stack != nd->internal))\n\t\treturn 0;\n\treturn __nd_alloc_stack(nd);\n}\n\nstatic void drop_links(struct nameidata *nd)\n{\n\tint i = nd->depth;\n\twhile (i--) {\n\t\tstruct saved *last = nd->stack + i;\n\t\tdo_delayed_call(&last->done);\n\t\tclear_delayed_call(&last->done);\n\t}\n}\n\nstatic void terminate_walk(struct nameidata *nd)\n{\n\tdrop_links(nd);\n\tif (!(nd->flags & LOOKUP_RCU)) {\n\t\tint i;\n\t\tpath_put(&nd->path);\n\t\tfor (i = 0; i < nd->depth; i++)\n\t\t\tpath_put(&nd->stack[i].link);\n\t\tif (nd->root.mnt && !(nd->flags & LOOKUP_ROOT)) {\n\t\t\tpath_put(&nd->root);\n\t\t\tnd->root.mnt = NULL;\n\t\t}\n\t} else {\n\t\tnd->flags &= ~LOOKUP_RCU;\n\t\tif (!(nd->flags & LOOKUP_ROOT))\n\t\t\tnd->root.mnt = NULL;\n\t\trcu_read_unlock();\n\t}\n\tnd->depth = 0;\n}\n\n/* path_put is needed afterwards regardless of success or failure */\nstatic bool legitimize_path(struct nameidata *nd,\n\t\t\t    struct path *path, unsigned seq)\n{\n\tint res = __legitimize_mnt(path->mnt, nd->m_seq);\n\tif (unlikely(res)) {\n\t\tif (res > 0)\n\t\t\tpath->mnt = NULL;\n\t\tpath->dentry = NULL;\n\t\treturn false;\n\t}\n\tif (unlikely(!lockref_get_not_dead(&path->dentry->d_lockref))) {\n\t\tpath->dentry = NULL;\n\t\treturn false;\n\t}\n\treturn !read_seqcount_retry(&path->dentry->d_seq, seq);\n}\n\nstatic bool legitimize_links(struct nameidata *nd)\n{\n\tint i;\n\tfor (i = 0; i < nd->depth; i++) {\n\t\tstruct saved *last = nd->stack + i;\n\t\tif (unlikely(!legitimize_path(nd, &last->link, last->seq))) {\n\t\t\tdrop_links(nd);\n\t\t\tnd->depth = i + 1;\n\t\t\treturn false;\n\t\t}\n\t}\n\treturn true;\n}\n\n/*\n * Path walking has 2 modes, rcu-walk and ref-walk (see\n * Documentation/filesystems/path-lookup.txt).  In situations when we can't\n * continue in RCU mode, we attempt to drop out of rcu-walk mode and grab\n * normal reference counts on dentries and vfsmounts to transition to ref-walk\n * mode.  Refcounts are grabbed at the last known good point before rcu-walk\n * got stuck, so ref-walk may continue from there. If this is not successful\n * (eg. a seqcount has changed), then failure is returned and it's up to caller\n * to restart the path walk from the beginning in ref-walk mode.\n */\n\n/**\n * unlazy_walk - try to switch to ref-walk mode.\n * @nd: nameidata pathwalk data\n * Returns: 0 on success, -ECHILD on failure\n *\n * unlazy_walk attempts to legitimize the current nd->path and nd->root\n * for ref-walk mode.\n * Must be called from rcu-walk context.\n * Nothing should touch nameidata between unlazy_walk() failure and\n * terminate_walk().\n */\nstatic int unlazy_walk(struct nameidata *nd)\n{\n\tstruct dentry *parent = nd->path.dentry;\n\n\tBUG_ON(!(nd->flags & LOOKUP_RCU));\n\n\tnd->flags &= ~LOOKUP_RCU;\n\tif (unlikely(!legitimize_links(nd)))\n\t\tgoto out2;\n\tif (unlikely(!legitimize_path(nd, &nd->path, nd->seq)))\n\t\tgoto out1;\n\tif (nd->root.mnt && !(nd->flags & LOOKUP_ROOT)) {\n\t\tif (unlikely(!legitimize_path(nd, &nd->root, nd->root_seq)))\n\t\t\tgoto out;\n\t}\n\trcu_read_unlock();\n\tBUG_ON(nd->inode != parent->d_inode);\n\treturn 0;\n\nout2:\n\tnd->path.mnt = NULL;\n\tnd->path.dentry = NULL;\nout1:\n\tif (!(nd->flags & LOOKUP_ROOT))\n\t\tnd->root.mnt = NULL;\nout:\n\trcu_read_unlock();\n\treturn -ECHILD;\n}\n\n/**\n * unlazy_child - try to switch to ref-walk mode.\n * @nd: nameidata pathwalk data\n * @dentry: child of nd->path.dentry\n * @seq: seq number to check dentry against\n * Returns: 0 on success, -ECHILD on failure\n *\n * unlazy_child attempts to legitimize the current nd->path, nd->root and dentry\n * for ref-walk mode.  @dentry must be a path found by a do_lookup call on\n * @nd.  Must be called from rcu-walk context.\n * Nothing should touch nameidata between unlazy_child() failure and\n * terminate_walk().\n */\nstatic int unlazy_child(struct nameidata *nd, struct dentry *dentry, unsigned seq)\n{\n\tBUG_ON(!(nd->flags & LOOKUP_RCU));\n\n\tnd->flags &= ~LOOKUP_RCU;\n\tif (unlikely(!legitimize_links(nd)))\n\t\tgoto out2;\n\tif (unlikely(!legitimize_mnt(nd->path.mnt, nd->m_seq)))\n\t\tgoto out2;\n\tif (unlikely(!lockref_get_not_dead(&nd->path.dentry->d_lockref)))\n\t\tgoto out1;\n\n\t/*\n\t * We need to move both the parent and the dentry from the RCU domain\n\t * to be properly refcounted. And the sequence number in the dentry\n\t * validates *both* dentry counters, since we checked the sequence\n\t * number of the parent after we got the child sequence number. So we\n\t * know the parent must still be valid if the child sequence number is\n\t */\n\tif (unlikely(!lockref_get_not_dead(&dentry->d_lockref)))\n\t\tgoto out;\n\tif (unlikely(read_seqcount_retry(&dentry->d_seq, seq))) {\n\t\trcu_read_unlock();\n\t\tdput(dentry);\n\t\tgoto drop_root_mnt;\n\t}\n\t/*\n\t * Sequence counts matched. Now make sure that the root is\n\t * still valid and get it if required.\n\t */\n\tif (nd->root.mnt && !(nd->flags & LOOKUP_ROOT)) {\n\t\tif (unlikely(!legitimize_path(nd, &nd->root, nd->root_seq))) {\n\t\t\trcu_read_unlock();\n\t\t\tdput(dentry);\n\t\t\treturn -ECHILD;\n\t\t}\n\t}\n\n\trcu_read_unlock();\n\treturn 0;\n\nout2:\n\tnd->path.mnt = NULL;\nout1:\n\tnd->path.dentry = NULL;\nout:\n\trcu_read_unlock();\ndrop_root_mnt:\n\tif (!(nd->flags & LOOKUP_ROOT))\n\t\tnd->root.mnt = NULL;\n\treturn -ECHILD;\n}\n\nstatic inline int d_revalidate(struct dentry *dentry, unsigned int flags)\n{\n\tif (unlikely(dentry->d_flags & DCACHE_OP_REVALIDATE))\n\t\treturn dentry->d_op->d_revalidate(dentry, flags);\n\telse\n\t\treturn 1;\n}\n\n/**\n * complete_walk - successful completion of path walk\n * @nd:  pointer nameidata\n *\n * If we had been in RCU mode, drop out of it and legitimize nd->path.\n * Revalidate the final result, unless we'd already done that during\n * the path walk or the filesystem doesn't ask for it.  Return 0 on\n * success, -error on failure.  In case of failure caller does not\n * need to drop nd->path.\n */\nstatic int complete_walk(struct nameidata *nd)\n{\n\tstruct dentry *dentry = nd->path.dentry;\n\tint status;\n\n\tif (nd->flags & LOOKUP_RCU) {\n\t\tif (!(nd->flags & LOOKUP_ROOT))\n\t\t\tnd->root.mnt = NULL;\n\t\tif (unlikely(unlazy_walk(nd)))\n\t\t\treturn -ECHILD;\n\t}\n\n\tif (likely(!(nd->flags & LOOKUP_JUMPED)))\n\t\treturn 0;\n\n\tif (likely(!(dentry->d_flags & DCACHE_OP_WEAK_REVALIDATE)))\n\t\treturn 0;\n\n\tstatus = dentry->d_op->d_weak_revalidate(dentry, nd->flags);\n\tif (status > 0)\n\t\treturn 0;\n\n\tif (!status)\n\t\tstatus = -ESTALE;\n\n\treturn status;\n}\n\nstatic void set_root(struct nameidata *nd)\n{\n\tstruct fs_struct *fs = current->fs;\n\n\tif (nd->flags & LOOKUP_RCU) {\n\t\tunsigned seq;\n\n\t\tdo {\n\t\t\tseq = read_seqcount_begin(&fs->seq);\n\t\t\tnd->root = fs->root;\n\t\t\tnd->root_seq = __read_seqcount_begin(&nd->root.dentry->d_seq);\n\t\t} while (read_seqcount_retry(&fs->seq, seq));\n\t} else {\n\t\tget_fs_root(fs, &nd->root);\n\t}\n}\n\nstatic void path_put_conditional(struct path *path, struct nameidata *nd)\n{\n\tdput(path->dentry);\n\tif (path->mnt != nd->path.mnt)\n\t\tmntput(path->mnt);\n}\n\nstatic inline void path_to_nameidata(const struct path *path,\n\t\t\t\t\tstruct nameidata *nd)\n{\n\tif (!(nd->flags & LOOKUP_RCU)) {\n\t\tdput(nd->path.dentry);\n\t\tif (nd->path.mnt != path->mnt)\n\t\t\tmntput(nd->path.mnt);\n\t}\n\tnd->path.mnt = path->mnt;\n\tnd->path.dentry = path->dentry;\n}\n\nstatic int nd_jump_root(struct nameidata *nd)\n{\n\tif (nd->flags & LOOKUP_RCU) {\n\t\tstruct dentry *d;\n\t\tnd->path = nd->root;\n\t\td = nd->path.dentry;\n\t\tnd->inode = d->d_inode;\n\t\tnd->seq = nd->root_seq;\n\t\tif (unlikely(read_seqcount_retry(&d->d_seq, nd->seq)))\n\t\t\treturn -ECHILD;\n\t} else {\n\t\tpath_put(&nd->path);\n\t\tnd->path = nd->root;\n\t\tpath_get(&nd->path);\n\t\tnd->inode = nd->path.dentry->d_inode;\n\t}\n\tnd->flags |= LOOKUP_JUMPED;\n\treturn 0;\n}\n\n/*\n * Helper to directly jump to a known parsed path from ->get_link,\n * caller must have taken a reference to path beforehand.\n */\nvoid nd_jump_link(struct path *path)\n{\n\tstruct nameidata *nd = current->nameidata;\n\tpath_put(&nd->path);\n\n\tnd->path = *path;\n\tnd->inode = nd->path.dentry->d_inode;\n\tnd->flags |= LOOKUP_JUMPED;\n}\n\nstatic inline void put_link(struct nameidata *nd)\n{\n\tstruct saved *last = nd->stack + --nd->depth;\n\tdo_delayed_call(&last->done);\n\tif (!(nd->flags & LOOKUP_RCU))\n\t\tpath_put(&last->link);\n}\n\nint sysctl_protected_symlinks __read_mostly = 0;\nint sysctl_protected_hardlinks __read_mostly = 0;\n\n/**\n * may_follow_link - Check symlink following for unsafe situations\n * @nd: nameidata pathwalk data\n *\n * In the case of the sysctl_protected_symlinks sysctl being enabled,\n * CAP_DAC_OVERRIDE needs to be specifically ignored if the symlink is\n * in a sticky world-writable directory. This is to protect privileged\n * processes from failing races against path names that may change out\n * from under them by way of other users creating malicious symlinks.\n * It will permit symlinks to be followed only when outside a sticky\n * world-writable directory, or when the uid of the symlink and follower\n * match, or when the directory owner matches the symlink's owner.\n *\n * Returns 0 if following the symlink is allowed, -ve on error.\n */\nstatic inline int may_follow_link(struct nameidata *nd)\n{\n\tconst struct inode *inode;\n\tconst struct inode *parent;\n\tkuid_t puid;\n\n\tif (!sysctl_protected_symlinks)\n\t\treturn 0;\n\n\t/* Allowed if owner and follower match. */\n\tinode = nd->link_inode;\n\tif (uid_eq(current_cred()->fsuid, inode->i_uid))\n\t\treturn 0;\n\n\t/* Allowed if parent directory not sticky and world-writable. */\n\tparent = nd->inode;\n\tif ((parent->i_mode & (S_ISVTX|S_IWOTH)) != (S_ISVTX|S_IWOTH))\n\t\treturn 0;\n\n\t/* Allowed if parent directory and link owner match. */\n\tpuid = parent->i_uid;\n\tif (uid_valid(puid) && uid_eq(puid, inode->i_uid))\n\t\treturn 0;\n\n\tif (nd->flags & LOOKUP_RCU)\n\t\treturn -ECHILD;\n\n\taudit_log_link_denied(\"follow_link\", &nd->stack[0].link);\n\treturn -EACCES;\n}\n\n/**\n * safe_hardlink_source - Check for safe hardlink conditions\n * @inode: the source inode to hardlink from\n *\n * Return false if at least one of the following conditions:\n *    - inode is not a regular file\n *    - inode is setuid\n *    - inode is setgid and group-exec\n *    - access failure for read and write\n *\n * Otherwise returns true.\n */\nstatic bool safe_hardlink_source(struct inode *inode)\n{\n\tumode_t mode = inode->i_mode;\n\n\t/* Special files should not get pinned to the filesystem. */\n\tif (!S_ISREG(mode))\n\t\treturn false;\n\n\t/* Setuid files should not get pinned to the filesystem. */\n\tif (mode & S_ISUID)\n\t\treturn false;\n\n\t/* Executable setgid files should not get pinned to the filesystem. */\n\tif ((mode & (S_ISGID | S_IXGRP)) == (S_ISGID | S_IXGRP))\n\t\treturn false;\n\n\t/* Hardlinking to unreadable or unwritable sources is dangerous. */\n\tif (inode_permission(inode, MAY_READ | MAY_WRITE))\n\t\treturn false;\n\n\treturn true;\n}\n\n/**\n * may_linkat - Check permissions for creating a hardlink\n * @link: the source to hardlink from\n *\n * Block hardlink when all of:\n *  - sysctl_protected_hardlinks enabled\n *  - fsuid does not match inode\n *  - hardlink source is unsafe (see safe_hardlink_source() above)\n *  - not CAP_FOWNER in a namespace with the inode owner uid mapped\n *\n * Returns 0 if successful, -ve on error.\n */\nstatic int may_linkat(struct path *link)\n{\n\tstruct inode *inode;\n\n\tif (!sysctl_protected_hardlinks)\n\t\treturn 0;\n\n\tinode = link->dentry->d_inode;\n\n\t/* Source inode owner (or CAP_FOWNER) can hardlink all they like,\n\t * otherwise, it must be a safe source.\n\t */\n\tif (safe_hardlink_source(inode) || inode_owner_or_capable(inode))\n\t\treturn 0;\n\n\taudit_log_link_denied(\"linkat\", link);\n\treturn -EPERM;\n}\n\nstatic __always_inline\nconst char *get_link(struct nameidata *nd)\n{\n\tstruct saved *last = nd->stack + nd->depth - 1;\n\tstruct dentry *dentry = last->link.dentry;\n\tstruct inode *inode = nd->link_inode;\n\tint error;\n\tconst char *res;\n\n\tif (!(nd->flags & LOOKUP_RCU)) {\n\t\ttouch_atime(&last->link);\n\t\tcond_resched();\n\t} else if (atime_needs_update_rcu(&last->link, inode)) {\n\t\tif (unlikely(unlazy_walk(nd)))\n\t\t\treturn ERR_PTR(-ECHILD);\n\t\ttouch_atime(&last->link);\n\t}\n\n\terror = security_inode_follow_link(dentry, inode,\n\t\t\t\t\t   nd->flags & LOOKUP_RCU);\n\tif (unlikely(error))\n\t\treturn ERR_PTR(error);\n\n\tnd->last_type = LAST_BIND;\n\tres = inode->i_link;\n\tif (!res) {\n\t\tconst char * (*get)(struct dentry *, struct inode *,\n\t\t\t\tstruct delayed_call *);\n\t\tget = inode->i_op->get_link;\n\t\tif (nd->flags & LOOKUP_RCU) {\n\t\t\tres = get(NULL, inode, &last->done);\n\t\t\tif (res == ERR_PTR(-ECHILD)) {\n\t\t\t\tif (unlikely(unlazy_walk(nd)))\n\t\t\t\t\treturn ERR_PTR(-ECHILD);\n\t\t\t\tres = get(dentry, inode, &last->done);\n\t\t\t}\n\t\t} else {\n\t\t\tres = get(dentry, inode, &last->done);\n\t\t}\n\t\tif (IS_ERR_OR_NULL(res))\n\t\t\treturn res;\n\t}\n\tif (*res == '/') {\n\t\tif (!nd->root.mnt)\n\t\t\tset_root(nd);\n\t\tif (unlikely(nd_jump_root(nd)))\n\t\t\treturn ERR_PTR(-ECHILD);\n\t\twhile (unlikely(*++res == '/'))\n\t\t\t;\n\t}\n\tif (!*res)\n\t\tres = NULL;\n\treturn res;\n}\n\n/*\n * follow_up - Find the mountpoint of path's vfsmount\n *\n * Given a path, find the mountpoint of its source file system.\n * Replace @path with the path of the mountpoint in the parent mount.\n * Up is towards /.\n *\n * Return 1 if we went up a level and 0 if we were already at the\n * root.\n */\nint follow_up(struct path *path)\n{\n\tstruct mount *mnt = real_mount(path->mnt);\n\tstruct mount *parent;\n\tstruct dentry *mountpoint;\n\n\tread_seqlock_excl(&mount_lock);\n\tparent = mnt->mnt_parent;\n\tif (parent == mnt) {\n\t\tread_sequnlock_excl(&mount_lock);\n\t\treturn 0;\n\t}\n\tmntget(&parent->mnt);\n\tmountpoint = dget(mnt->mnt_mountpoint);\n\tread_sequnlock_excl(&mount_lock);\n\tdput(path->dentry);\n\tpath->dentry = mountpoint;\n\tmntput(path->mnt);\n\tpath->mnt = &parent->mnt;\n\treturn 1;\n}\nEXPORT_SYMBOL(follow_up);\n\n/*\n * Perform an automount\n * - return -EISDIR to tell follow_managed() to stop and return the path we\n *   were called with.\n */\nstatic int follow_automount(struct path *path, struct nameidata *nd,\n\t\t\t    bool *need_mntput)\n{\n\tstruct vfsmount *mnt;\n\tint err;\n\n\tif (!path->dentry->d_op || !path->dentry->d_op->d_automount)\n\t\treturn -EREMOTE;\n\n\t/* We don't want to mount if someone's just doing a stat -\n\t * unless they're stat'ing a directory and appended a '/' to\n\t * the name.\n\t *\n\t * We do, however, want to mount if someone wants to open or\n\t * create a file of any type under the mountpoint, wants to\n\t * traverse through the mountpoint or wants to open the\n\t * mounted directory.  Also, autofs may mark negative dentries\n\t * as being automount points.  These will need the attentions\n\t * of the daemon to instantiate them before they can be used.\n\t */\n\tif (!(nd->flags & (LOOKUP_PARENT | LOOKUP_DIRECTORY |\n\t\t\t   LOOKUP_OPEN | LOOKUP_CREATE | LOOKUP_AUTOMOUNT)) &&\n\t    path->dentry->d_inode)\n\t\treturn -EISDIR;\n\n\tif (path->dentry->d_sb->s_user_ns != &init_user_ns)\n\t\treturn -EACCES;\n\n\tnd->total_link_count++;\n\tif (nd->total_link_count >= 40)\n\t\treturn -ELOOP;\n\n\tmnt = path->dentry->d_op->d_automount(path);\n\tif (IS_ERR(mnt)) {\n\t\t/*\n\t\t * The filesystem is allowed to return -EISDIR here to indicate\n\t\t * it doesn't want to automount.  For instance, autofs would do\n\t\t * this so that its userspace daemon can mount on this dentry.\n\t\t *\n\t\t * However, we can only permit this if it's a terminal point in\n\t\t * the path being looked up; if it wasn't then the remainder of\n\t\t * the path is inaccessible and we should say so.\n\t\t */\n\t\tif (PTR_ERR(mnt) == -EISDIR && (nd->flags & LOOKUP_PARENT))\n\t\t\treturn -EREMOTE;\n\t\treturn PTR_ERR(mnt);\n\t}\n\n\tif (!mnt) /* mount collision */\n\t\treturn 0;\n\n\tif (!*need_mntput) {\n\t\t/* lock_mount() may release path->mnt on error */\n\t\tmntget(path->mnt);\n\t\t*need_mntput = true;\n\t}\n\terr = finish_automount(mnt, path);\n\n\tswitch (err) {\n\tcase -EBUSY:\n\t\t/* Someone else made a mount here whilst we were busy */\n\t\treturn 0;\n\tcase 0:\n\t\tpath_put(path);\n\t\tpath->mnt = mnt;\n\t\tpath->dentry = dget(mnt->mnt_root);\n\t\treturn 0;\n\tdefault:\n\t\treturn err;\n\t}\n\n}\n\n/*\n * Handle a dentry that is managed in some way.\n * - Flagged for transit management (autofs)\n * - Flagged as mountpoint\n * - Flagged as automount point\n *\n * This may only be called in refwalk mode.\n *\n * Serialization is taken care of in namespace.c\n */\nstatic int follow_managed(struct path *path, struct nameidata *nd)\n{\n\tstruct vfsmount *mnt = path->mnt; /* held by caller, must be left alone */\n\tunsigned managed;\n\tbool need_mntput = false;\n\tint ret = 0;\n\n\t/* Given that we're not holding a lock here, we retain the value in a\n\t * local variable for each dentry as we look at it so that we don't see\n\t * the components of that value change under us */\n\twhile (managed = ACCESS_ONCE(path->dentry->d_flags),\n\t       managed &= DCACHE_MANAGED_DENTRY,\n\t       unlikely(managed != 0)) {\n\t\t/* Allow the filesystem to manage the transit without i_mutex\n\t\t * being held. */\n\t\tif (managed & DCACHE_MANAGE_TRANSIT) {\n\t\t\tBUG_ON(!path->dentry->d_op);\n\t\t\tBUG_ON(!path->dentry->d_op->d_manage);\n\t\t\tret = path->dentry->d_op->d_manage(path, false);\n\t\t\tif (ret < 0)\n\t\t\t\tbreak;\n\t\t}\n\n\t\t/* Transit to a mounted filesystem. */\n\t\tif (managed & DCACHE_MOUNTED) {\n\t\t\tstruct vfsmount *mounted = lookup_mnt(path);\n\t\t\tif (mounted) {\n\t\t\t\tdput(path->dentry);\n\t\t\t\tif (need_mntput)\n\t\t\t\t\tmntput(path->mnt);\n\t\t\t\tpath->mnt = mounted;\n\t\t\t\tpath->dentry = dget(mounted->mnt_root);\n\t\t\t\tneed_mntput = true;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t/* Something is mounted on this dentry in another\n\t\t\t * namespace and/or whatever was mounted there in this\n\t\t\t * namespace got unmounted before lookup_mnt() could\n\t\t\t * get it */\n\t\t}\n\n\t\t/* Handle an automount point */\n\t\tif (managed & DCACHE_NEED_AUTOMOUNT) {\n\t\t\tret = follow_automount(path, nd, &need_mntput);\n\t\t\tif (ret < 0)\n\t\t\t\tbreak;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* We didn't change the current path point */\n\t\tbreak;\n\t}\n\n\tif (need_mntput && path->mnt == mnt)\n\t\tmntput(path->mnt);\n\tif (ret == -EISDIR || !ret)\n\t\tret = 1;\n\tif (need_mntput)\n\t\tnd->flags |= LOOKUP_JUMPED;\n\tif (unlikely(ret < 0))\n\t\tpath_put_conditional(path, nd);\n\treturn ret;\n}\n\nint follow_down_one(struct path *path)\n{\n\tstruct vfsmount *mounted;\n\n\tmounted = lookup_mnt(path);\n\tif (mounted) {\n\t\tdput(path->dentry);\n\t\tmntput(path->mnt);\n\t\tpath->mnt = mounted;\n\t\tpath->dentry = dget(mounted->mnt_root);\n\t\treturn 1;\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL(follow_down_one);\n\nstatic inline int managed_dentry_rcu(const struct path *path)\n{\n\treturn (path->dentry->d_flags & DCACHE_MANAGE_TRANSIT) ?\n\t\tpath->dentry->d_op->d_manage(path, true) : 0;\n}\n\n/*\n * Try to skip to top of mountpoint pile in rcuwalk mode.  Fail if\n * we meet a managed dentry that would need blocking.\n */\nstatic bool __follow_mount_rcu(struct nameidata *nd, struct path *path,\n\t\t\t       struct inode **inode, unsigned *seqp)\n{\n\tfor (;;) {\n\t\tstruct mount *mounted;\n\t\t/*\n\t\t * Don't forget we might have a non-mountpoint managed dentry\n\t\t * that wants to block transit.\n\t\t */\n\t\tswitch (managed_dentry_rcu(path)) {\n\t\tcase -ECHILD:\n\t\tdefault:\n\t\t\treturn false;\n\t\tcase -EISDIR:\n\t\t\treturn true;\n\t\tcase 0:\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!d_mountpoint(path->dentry))\n\t\t\treturn !(path->dentry->d_flags & DCACHE_NEED_AUTOMOUNT);\n\n\t\tmounted = __lookup_mnt(path->mnt, path->dentry);\n\t\tif (!mounted)\n\t\t\tbreak;\n\t\tpath->mnt = &mounted->mnt;\n\t\tpath->dentry = mounted->mnt.mnt_root;\n\t\tnd->flags |= LOOKUP_JUMPED;\n\t\t*seqp = read_seqcount_begin(&path->dentry->d_seq);\n\t\t/*\n\t\t * Update the inode too. We don't need to re-check the\n\t\t * dentry sequence number here after this d_inode read,\n\t\t * because a mount-point is always pinned.\n\t\t */\n\t\t*inode = path->dentry->d_inode;\n\t}\n\treturn !read_seqretry(&mount_lock, nd->m_seq) &&\n\t\t!(path->dentry->d_flags & DCACHE_NEED_AUTOMOUNT);\n}\n\nstatic int follow_dotdot_rcu(struct nameidata *nd)\n{\n\tstruct inode *inode = nd->inode;\n\n\twhile (1) {\n\t\tif (path_equal(&nd->path, &nd->root))\n\t\t\tbreak;\n\t\tif (nd->path.dentry != nd->path.mnt->mnt_root) {\n\t\t\tstruct dentry *old = nd->path.dentry;\n\t\t\tstruct dentry *parent = old->d_parent;\n\t\t\tunsigned seq;\n\n\t\t\tinode = parent->d_inode;\n\t\t\tseq = read_seqcount_begin(&parent->d_seq);\n\t\t\tif (unlikely(read_seqcount_retry(&old->d_seq, nd->seq)))\n\t\t\t\treturn -ECHILD;\n\t\t\tnd->path.dentry = parent;\n\t\t\tnd->seq = seq;\n\t\t\tif (unlikely(!path_connected(&nd->path)))\n\t\t\t\treturn -ENOENT;\n\t\t\tbreak;\n\t\t} else {\n\t\t\tstruct mount *mnt = real_mount(nd->path.mnt);\n\t\t\tstruct mount *mparent = mnt->mnt_parent;\n\t\t\tstruct dentry *mountpoint = mnt->mnt_mountpoint;\n\t\t\tstruct inode *inode2 = mountpoint->d_inode;\n\t\t\tunsigned seq = read_seqcount_begin(&mountpoint->d_seq);\n\t\t\tif (unlikely(read_seqretry(&mount_lock, nd->m_seq)))\n\t\t\t\treturn -ECHILD;\n\t\t\tif (&mparent->mnt == nd->path.mnt)\n\t\t\t\tbreak;\n\t\t\t/* we know that mountpoint was pinned */\n\t\t\tnd->path.dentry = mountpoint;\n\t\t\tnd->path.mnt = &mparent->mnt;\n\t\t\tinode = inode2;\n\t\t\tnd->seq = seq;\n\t\t}\n\t}\n\twhile (unlikely(d_mountpoint(nd->path.dentry))) {\n\t\tstruct mount *mounted;\n\t\tmounted = __lookup_mnt(nd->path.mnt, nd->path.dentry);\n\t\tif (unlikely(read_seqretry(&mount_lock, nd->m_seq)))\n\t\t\treturn -ECHILD;\n\t\tif (!mounted)\n\t\t\tbreak;\n\t\tnd->path.mnt = &mounted->mnt;\n\t\tnd->path.dentry = mounted->mnt.mnt_root;\n\t\tinode = nd->path.dentry->d_inode;\n\t\tnd->seq = read_seqcount_begin(&nd->path.dentry->d_seq);\n\t}\n\tnd->inode = inode;\n\treturn 0;\n}\n\n/*\n * Follow down to the covering mount currently visible to userspace.  At each\n * point, the filesystem owning that dentry may be queried as to whether the\n * caller is permitted to proceed or not.\n */\nint follow_down(struct path *path)\n{\n\tunsigned managed;\n\tint ret;\n\n\twhile (managed = ACCESS_ONCE(path->dentry->d_flags),\n\t       unlikely(managed & DCACHE_MANAGED_DENTRY)) {\n\t\t/* Allow the filesystem to manage the transit without i_mutex\n\t\t * being held.\n\t\t *\n\t\t * We indicate to the filesystem if someone is trying to mount\n\t\t * something here.  This gives autofs the chance to deny anyone\n\t\t * other than its daemon the right to mount on its\n\t\t * superstructure.\n\t\t *\n\t\t * The filesystem may sleep at this point.\n\t\t */\n\t\tif (managed & DCACHE_MANAGE_TRANSIT) {\n\t\t\tBUG_ON(!path->dentry->d_op);\n\t\t\tBUG_ON(!path->dentry->d_op->d_manage);\n\t\t\tret = path->dentry->d_op->d_manage(path, false);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret == -EISDIR ? 0 : ret;\n\t\t}\n\n\t\t/* Transit to a mounted filesystem. */\n\t\tif (managed & DCACHE_MOUNTED) {\n\t\t\tstruct vfsmount *mounted = lookup_mnt(path);\n\t\t\tif (!mounted)\n\t\t\t\tbreak;\n\t\t\tdput(path->dentry);\n\t\t\tmntput(path->mnt);\n\t\t\tpath->mnt = mounted;\n\t\t\tpath->dentry = dget(mounted->mnt_root);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Don't handle automount points here */\n\t\tbreak;\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL(follow_down);\n\n/*\n * Skip to top of mountpoint pile in refwalk mode for follow_dotdot()\n */\nstatic void follow_mount(struct path *path)\n{\n\twhile (d_mountpoint(path->dentry)) {\n\t\tstruct vfsmount *mounted = lookup_mnt(path);\n\t\tif (!mounted)\n\t\t\tbreak;\n\t\tdput(path->dentry);\n\t\tmntput(path->mnt);\n\t\tpath->mnt = mounted;\n\t\tpath->dentry = dget(mounted->mnt_root);\n\t}\n}\n\nstatic int path_parent_directory(struct path *path)\n{\n\tstruct dentry *old = path->dentry;\n\t/* rare case of legitimate dget_parent()... */\n\tpath->dentry = dget_parent(path->dentry);\n\tdput(old);\n\tif (unlikely(!path_connected(path)))\n\t\treturn -ENOENT;\n\treturn 0;\n}\n\nstatic int follow_dotdot(struct nameidata *nd)\n{\n\twhile(1) {\n\t\tif (nd->path.dentry == nd->root.dentry &&\n\t\t    nd->path.mnt == nd->root.mnt) {\n\t\t\tbreak;\n\t\t}\n\t\tif (nd->path.dentry != nd->path.mnt->mnt_root) {\n\t\t\tint ret = path_parent_directory(&nd->path);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t\tbreak;\n\t\t}\n\t\tif (!follow_up(&nd->path))\n\t\t\tbreak;\n\t}\n\tfollow_mount(&nd->path);\n\tnd->inode = nd->path.dentry->d_inode;\n\treturn 0;\n}\n\n/*\n * This looks up the name in dcache and possibly revalidates the found dentry.\n * NULL is returned if the dentry does not exist in the cache.\n */\nstatic struct dentry *lookup_dcache(const struct qstr *name,\n\t\t\t\t    struct dentry *dir,\n\t\t\t\t    unsigned int flags)\n{\n\tstruct dentry *dentry = d_lookup(dir, name);\n\tif (dentry) {\n\t\tint error = d_revalidate(dentry, flags);\n\t\tif (unlikely(error <= 0)) {\n\t\t\tif (!error)\n\t\t\t\td_invalidate(dentry);\n\t\t\tdput(dentry);\n\t\t\treturn ERR_PTR(error);\n\t\t}\n\t}\n\treturn dentry;\n}\n\n/*\n * Call i_op->lookup on the dentry.  The dentry must be negative and\n * unhashed.\n *\n * dir->d_inode->i_mutex must be held\n */\nstatic struct dentry *lookup_real(struct inode *dir, struct dentry *dentry,\n\t\t\t\t  unsigned int flags)\n{\n\tstruct dentry *old;\n\n\t/* Don't create child dentry for a dead directory. */\n\tif (unlikely(IS_DEADDIR(dir))) {\n\t\tdput(dentry);\n\t\treturn ERR_PTR(-ENOENT);\n\t}\n\n\told = dir->i_op->lookup(dir, dentry, flags);\n\tif (unlikely(old)) {\n\t\tdput(dentry);\n\t\tdentry = old;\n\t}\n\treturn dentry;\n}\n\nstatic struct dentry *__lookup_hash(const struct qstr *name,\n\t\tstruct dentry *base, unsigned int flags)\n{\n\tstruct dentry *dentry = lookup_dcache(name, base, flags);\n\n\tif (dentry)\n\t\treturn dentry;\n\n\tdentry = d_alloc(base, name);\n\tif (unlikely(!dentry))\n\t\treturn ERR_PTR(-ENOMEM);\n\n\treturn lookup_real(base->d_inode, dentry, flags);\n}\n\nstatic int lookup_fast(struct nameidata *nd,\n\t\t       struct path *path, struct inode **inode,\n\t\t       unsigned *seqp)\n{\n\tstruct vfsmount *mnt = nd->path.mnt;\n\tstruct dentry *dentry, *parent = nd->path.dentry;\n\tint status = 1;\n\tint err;\n\n\t/*\n\t * Rename seqlock is not required here because in the off chance\n\t * of a false negative due to a concurrent rename, the caller is\n\t * going to fall back to non-racy lookup.\n\t */\n\tif (nd->flags & LOOKUP_RCU) {\n\t\tunsigned seq;\n\t\tbool negative;\n\t\tdentry = __d_lookup_rcu(parent, &nd->last, &seq);\n\t\tif (unlikely(!dentry)) {\n\t\t\tif (unlazy_walk(nd))\n\t\t\t\treturn -ECHILD;\n\t\t\treturn 0;\n\t\t}\n\n\t\t/*\n\t\t * This sequence count validates that the inode matches\n\t\t * the dentry name information from lookup.\n\t\t */\n\t\t*inode = d_backing_inode(dentry);\n\t\tnegative = d_is_negative(dentry);\n\t\tif (unlikely(read_seqcount_retry(&dentry->d_seq, seq)))\n\t\t\treturn -ECHILD;\n\n\t\t/*\n\t\t * This sequence count validates that the parent had no\n\t\t * changes while we did the lookup of the dentry above.\n\t\t *\n\t\t * The memory barrier in read_seqcount_begin of child is\n\t\t *  enough, we can use __read_seqcount_retry here.\n\t\t */\n\t\tif (unlikely(__read_seqcount_retry(&parent->d_seq, nd->seq)))\n\t\t\treturn -ECHILD;\n\n\t\t*seqp = seq;\n\t\tstatus = d_revalidate(dentry, nd->flags);\n\t\tif (likely(status > 0)) {\n\t\t\t/*\n\t\t\t * Note: do negative dentry check after revalidation in\n\t\t\t * case that drops it.\n\t\t\t */\n\t\t\tif (unlikely(negative))\n\t\t\t\treturn -ENOENT;\n\t\t\tpath->mnt = mnt;\n\t\t\tpath->dentry = dentry;\n\t\t\tif (likely(__follow_mount_rcu(nd, path, inode, seqp)))\n\t\t\t\treturn 1;\n\t\t}\n\t\tif (unlazy_child(nd, dentry, seq))\n\t\t\treturn -ECHILD;\n\t\tif (unlikely(status == -ECHILD))\n\t\t\t/* we'd been told to redo it in non-rcu mode */\n\t\t\tstatus = d_revalidate(dentry, nd->flags);\n\t} else {\n\t\tdentry = __d_lookup(parent, &nd->last);\n\t\tif (unlikely(!dentry))\n\t\t\treturn 0;\n\t\tstatus = d_revalidate(dentry, nd->flags);\n\t}\n\tif (unlikely(status <= 0)) {\n\t\tif (!status)\n\t\t\td_invalidate(dentry);\n\t\tdput(dentry);\n\t\treturn status;\n\t}\n\tif (unlikely(d_is_negative(dentry))) {\n\t\tdput(dentry);\n\t\treturn -ENOENT;\n\t}\n\n\tpath->mnt = mnt;\n\tpath->dentry = dentry;\n\terr = follow_managed(path, nd);\n\tif (likely(err > 0))\n\t\t*inode = d_backing_inode(path->dentry);\n\treturn err;\n}\n\n/* Fast lookup failed, do it the slow way */\nstatic struct dentry *lookup_slow(const struct qstr *name,\n\t\t\t\t  struct dentry *dir,\n\t\t\t\t  unsigned int flags)\n{\n\tstruct dentry *dentry = ERR_PTR(-ENOENT), *old;\n\tstruct inode *inode = dir->d_inode;\n\tDECLARE_WAIT_QUEUE_HEAD_ONSTACK(wq);\n\n\tinode_lock_shared(inode);\n\t/* Don't go there if it's already dead */\n\tif (unlikely(IS_DEADDIR(inode)))\n\t\tgoto out;\nagain:\n\tdentry = d_alloc_parallel(dir, name, &wq);\n\tif (IS_ERR(dentry))\n\t\tgoto out;\n\tif (unlikely(!d_in_lookup(dentry))) {\n\t\tif (!(flags & LOOKUP_NO_REVAL)) {\n\t\t\tint error = d_revalidate(dentry, flags);\n\t\t\tif (unlikely(error <= 0)) {\n\t\t\t\tif (!error) {\n\t\t\t\t\td_invalidate(dentry);\n\t\t\t\t\tdput(dentry);\n\t\t\t\t\tgoto again;\n\t\t\t\t}\n\t\t\t\tdput(dentry);\n\t\t\t\tdentry = ERR_PTR(error);\n\t\t\t}\n\t\t}\n\t} else {\n\t\told = inode->i_op->lookup(inode, dentry, flags);\n\t\td_lookup_done(dentry);\n\t\tif (unlikely(old)) {\n\t\t\tdput(dentry);\n\t\t\tdentry = old;\n\t\t}\n\t}\nout:\n\tinode_unlock_shared(inode);\n\treturn dentry;\n}\n\nstatic inline int may_lookup(struct nameidata *nd)\n{\n\tif (nd->flags & LOOKUP_RCU) {\n\t\tint err = inode_permission(nd->inode, MAY_EXEC|MAY_NOT_BLOCK);\n\t\tif (err != -ECHILD)\n\t\t\treturn err;\n\t\tif (unlazy_walk(nd))\n\t\t\treturn -ECHILD;\n\t}\n\treturn inode_permission(nd->inode, MAY_EXEC);\n}\n\nstatic inline int handle_dots(struct nameidata *nd, int type)\n{\n\tif (type == LAST_DOTDOT) {\n\t\tif (!nd->root.mnt)\n\t\t\tset_root(nd);\n\t\tif (nd->flags & LOOKUP_RCU) {\n\t\t\treturn follow_dotdot_rcu(nd);\n\t\t} else\n\t\t\treturn follow_dotdot(nd);\n\t}\n\treturn 0;\n}\n\nstatic int pick_link(struct nameidata *nd, struct path *link,\n\t\t     struct inode *inode, unsigned seq)\n{\n\tint error;\n\tstruct saved *last;\n\tif (unlikely(nd->total_link_count++ >= MAXSYMLINKS)) {\n\t\tpath_to_nameidata(link, nd);\n\t\treturn -ELOOP;\n\t}\n\tif (!(nd->flags & LOOKUP_RCU)) {\n\t\tif (link->mnt == nd->path.mnt)\n\t\t\tmntget(link->mnt);\n\t}\n\terror = nd_alloc_stack(nd);\n\tif (unlikely(error)) {\n\t\tif (error == -ECHILD) {\n\t\t\tif (unlikely(!legitimize_path(nd, link, seq))) {\n\t\t\t\tdrop_links(nd);\n\t\t\t\tnd->depth = 0;\n\t\t\t\tnd->flags &= ~LOOKUP_RCU;\n\t\t\t\tnd->path.mnt = NULL;\n\t\t\t\tnd->path.dentry = NULL;\n\t\t\t\tif (!(nd->flags & LOOKUP_ROOT))\n\t\t\t\t\tnd->root.mnt = NULL;\n\t\t\t\trcu_read_unlock();\n\t\t\t} else if (likely(unlazy_walk(nd)) == 0)\n\t\t\t\terror = nd_alloc_stack(nd);\n\t\t}\n\t\tif (error) {\n\t\t\tpath_put(link);\n\t\t\treturn error;\n\t\t}\n\t}\n\n\tlast = nd->stack + nd->depth++;\n\tlast->link = *link;\n\tclear_delayed_call(&last->done);\n\tnd->link_inode = inode;\n\tlast->seq = seq;\n\treturn 1;\n}\n\nenum {WALK_FOLLOW = 1, WALK_MORE = 2};\n\n/*\n * Do we need to follow links? We _really_ want to be able\n * to do this check without having to look at inode->i_op,\n * so we keep a cache of \"no, this doesn't need follow_link\"\n * for the common case.\n */\nstatic inline int step_into(struct nameidata *nd, struct path *path,\n\t\t\t    int flags, struct inode *inode, unsigned seq)\n{\n\tif (!(flags & WALK_MORE) && nd->depth)\n\t\tput_link(nd);\n\tif (likely(!d_is_symlink(path->dentry)) ||\n\t   !(flags & WALK_FOLLOW || nd->flags & LOOKUP_FOLLOW)) {\n\t\t/* not a symlink or should not follow */\n\t\tpath_to_nameidata(path, nd);\n\t\tnd->inode = inode;\n\t\tnd->seq = seq;\n\t\treturn 0;\n\t}\n\t/* make sure that d_is_symlink above matches inode */\n\tif (nd->flags & LOOKUP_RCU) {\n\t\tif (read_seqcount_retry(&path->dentry->d_seq, seq))\n\t\t\treturn -ECHILD;\n\t}\n\treturn pick_link(nd, path, inode, seq);\n}\n\nstatic int walk_component(struct nameidata *nd, int flags)\n{\n\tstruct path path;\n\tstruct inode *inode;\n\tunsigned seq;\n\tint err;\n\t/*\n\t * \".\" and \"..\" are special - \"..\" especially so because it has\n\t * to be able to know about the current root directory and\n\t * parent relationships.\n\t */\n\tif (unlikely(nd->last_type != LAST_NORM)) {\n\t\terr = handle_dots(nd, nd->last_type);\n\t\tif (!(flags & WALK_MORE) && nd->depth)\n\t\t\tput_link(nd);\n\t\treturn err;\n\t}\n\terr = lookup_fast(nd, &path, &inode, &seq);\n\tif (unlikely(err <= 0)) {\n\t\tif (err < 0)\n\t\t\treturn err;\n\t\tpath.dentry = lookup_slow(&nd->last, nd->path.dentry,\n\t\t\t\t\t  nd->flags);\n\t\tif (IS_ERR(path.dentry))\n\t\t\treturn PTR_ERR(path.dentry);\n\n\t\tpath.mnt = nd->path.mnt;\n\t\terr = follow_managed(&path, nd);\n\t\tif (unlikely(err < 0))\n\t\t\treturn err;\n\n\t\tif (unlikely(d_is_negative(path.dentry))) {\n\t\t\tpath_to_nameidata(&path, nd);\n\t\t\treturn -ENOENT;\n\t\t}\n\n\t\tseq = 0;\t/* we are already out of RCU mode */\n\t\tinode = d_backing_inode(path.dentry);\n\t}\n\n\treturn step_into(nd, &path, flags, inode, seq);\n}\n\n/*\n * We can do the critical dentry name comparison and hashing\n * operations one word at a time, but we are limited to:\n *\n * - Architectures with fast unaligned word accesses. We could\n *   do a \"get_unaligned()\" if this helps and is sufficiently\n *   fast.\n *\n * - non-CONFIG_DEBUG_PAGEALLOC configurations (so that we\n *   do not trap on the (extremely unlikely) case of a page\n *   crossing operation.\n *\n * - Furthermore, we need an efficient 64-bit compile for the\n *   64-bit case in order to generate the \"number of bytes in\n *   the final mask\". Again, that could be replaced with a\n *   efficient population count instruction or similar.\n */\n#ifdef CONFIG_DCACHE_WORD_ACCESS\n\n#include <asm/word-at-a-time.h>\n\n#ifdef HASH_MIX\n\n/* Architecture provides HASH_MIX and fold_hash() in <asm/hash.h> */\n\n#elif defined(CONFIG_64BIT)\n/*\n * Register pressure in the mixing function is an issue, particularly\n * on 32-bit x86, but almost any function requires one state value and\n * one temporary.  Instead, use a function designed for two state values\n * and no temporaries.\n *\n * This function cannot create a collision in only two iterations, so\n * we have two iterations to achieve avalanche.  In those two iterations,\n * we have six layers of mixing, which is enough to spread one bit's\n * influence out to 2^6 = 64 state bits.\n *\n * Rotate constants are scored by considering either 64 one-bit input\n * deltas or 64*63/2 = 2016 two-bit input deltas, and finding the\n * probability of that delta causing a change to each of the 128 output\n * bits, using a sample of random initial states.\n *\n * The Shannon entropy of the computed probabilities is then summed\n * to produce a score.  Ideally, any input change has a 50% chance of\n * toggling any given output bit.\n *\n * Mixing scores (in bits) for (12,45):\n * Input delta: 1-bit      2-bit\n * 1 round:     713.3    42542.6\n * 2 rounds:   2753.7   140389.8\n * 3 rounds:   5954.1   233458.2\n * 4 rounds:   7862.6   256672.2\n * Perfect:    8192     258048\n *            (64*128) (64*63/2 * 128)\n */\n#define HASH_MIX(x, y, a)\t\\\n\t(\tx ^= (a),\t\\\n\ty ^= x,\tx = rol64(x,12),\\\n\tx += y,\ty = rol64(y,45),\\\n\ty *= 9\t\t\t)\n\n/*\n * Fold two longs into one 32-bit hash value.  This must be fast, but\n * latency isn't quite as critical, as there is a fair bit of additional\n * work done before the hash value is used.\n */\nstatic inline unsigned int fold_hash(unsigned long x, unsigned long y)\n{\n\ty ^= x * GOLDEN_RATIO_64;\n\ty *= GOLDEN_RATIO_64;\n\treturn y >> 32;\n}\n\n#else\t/* 32-bit case */\n\n/*\n * Mixing scores (in bits) for (7,20):\n * Input delta: 1-bit      2-bit\n * 1 round:     330.3     9201.6\n * 2 rounds:   1246.4    25475.4\n * 3 rounds:   1907.1    31295.1\n * 4 rounds:   2042.3    31718.6\n * Perfect:    2048      31744\n *            (32*64)   (32*31/2 * 64)\n */\n#define HASH_MIX(x, y, a)\t\\\n\t(\tx ^= (a),\t\\\n\ty ^= x,\tx = rol32(x, 7),\\\n\tx += y,\ty = rol32(y,20),\\\n\ty *= 9\t\t\t)\n\nstatic inline unsigned int fold_hash(unsigned long x, unsigned long y)\n{\n\t/* Use arch-optimized multiply if one exists */\n\treturn __hash_32(y ^ __hash_32(x));\n}\n\n#endif\n\n/*\n * Return the hash of a string of known length.  This is carfully\n * designed to match hash_name(), which is the more critical function.\n * In particular, we must end by hashing a final word containing 0..7\n * payload bytes, to match the way that hash_name() iterates until it\n * finds the delimiter after the name.\n */\nunsigned int full_name_hash(const void *salt, const char *name, unsigned int len)\n{\n\tunsigned long a, x = 0, y = (unsigned long)salt;\n\n\tfor (;;) {\n\t\tif (!len)\n\t\t\tgoto done;\n\t\ta = load_unaligned_zeropad(name);\n\t\tif (len < sizeof(unsigned long))\n\t\t\tbreak;\n\t\tHASH_MIX(x, y, a);\n\t\tname += sizeof(unsigned long);\n\t\tlen -= sizeof(unsigned long);\n\t}\n\tx ^= a & bytemask_from_count(len);\ndone:\n\treturn fold_hash(x, y);\n}\nEXPORT_SYMBOL(full_name_hash);\n\n/* Return the \"hash_len\" (hash and length) of a null-terminated string */\nu64 hashlen_string(const void *salt, const char *name)\n{\n\tunsigned long a = 0, x = 0, y = (unsigned long)salt;\n\tunsigned long adata, mask, len;\n\tconst struct word_at_a_time constants = WORD_AT_A_TIME_CONSTANTS;\n\n\tlen = 0;\n\tgoto inside;\n\n\tdo {\n\t\tHASH_MIX(x, y, a);\n\t\tlen += sizeof(unsigned long);\ninside:\n\t\ta = load_unaligned_zeropad(name+len);\n\t} while (!has_zero(a, &adata, &constants));\n\n\tadata = prep_zero_mask(a, adata, &constants);\n\tmask = create_zero_mask(adata);\n\tx ^= a & zero_bytemask(mask);\n\n\treturn hashlen_create(fold_hash(x, y), len + find_zero(mask));\n}\nEXPORT_SYMBOL(hashlen_string);\n\n/*\n * Calculate the length and hash of the path component, and\n * return the \"hash_len\" as the result.\n */\nstatic inline u64 hash_name(const void *salt, const char *name)\n{\n\tunsigned long a = 0, b, x = 0, y = (unsigned long)salt;\n\tunsigned long adata, bdata, mask, len;\n\tconst struct word_at_a_time constants = WORD_AT_A_TIME_CONSTANTS;\n\n\tlen = 0;\n\tgoto inside;\n\n\tdo {\n\t\tHASH_MIX(x, y, a);\n\t\tlen += sizeof(unsigned long);\ninside:\n\t\ta = load_unaligned_zeropad(name+len);\n\t\tb = a ^ REPEAT_BYTE('/');\n\t} while (!(has_zero(a, &adata, &constants) | has_zero(b, &bdata, &constants)));\n\n\tadata = prep_zero_mask(a, adata, &constants);\n\tbdata = prep_zero_mask(b, bdata, &constants);\n\tmask = create_zero_mask(adata | bdata);\n\tx ^= a & zero_bytemask(mask);\n\n\treturn hashlen_create(fold_hash(x, y), len + find_zero(mask));\n}\n\n#else\t/* !CONFIG_DCACHE_WORD_ACCESS: Slow, byte-at-a-time version */\n\n/* Return the hash of a string of known length */\nunsigned int full_name_hash(const void *salt, const char *name, unsigned int len)\n{\n\tunsigned long hash = init_name_hash(salt);\n\twhile (len--)\n\t\thash = partial_name_hash((unsigned char)*name++, hash);\n\treturn end_name_hash(hash);\n}\nEXPORT_SYMBOL(full_name_hash);\n\n/* Return the \"hash_len\" (hash and length) of a null-terminated string */\nu64 hashlen_string(const void *salt, const char *name)\n{\n\tunsigned long hash = init_name_hash(salt);\n\tunsigned long len = 0, c;\n\n\tc = (unsigned char)*name;\n\twhile (c) {\n\t\tlen++;\n\t\thash = partial_name_hash(c, hash);\n\t\tc = (unsigned char)name[len];\n\t}\n\treturn hashlen_create(end_name_hash(hash), len);\n}\nEXPORT_SYMBOL(hashlen_string);\n\n/*\n * We know there's a real path component here of at least\n * one character.\n */\nstatic inline u64 hash_name(const void *salt, const char *name)\n{\n\tunsigned long hash = init_name_hash(salt);\n\tunsigned long len = 0, c;\n\n\tc = (unsigned char)*name;\n\tdo {\n\t\tlen++;\n\t\thash = partial_name_hash(c, hash);\n\t\tc = (unsigned char)name[len];\n\t} while (c && c != '/');\n\treturn hashlen_create(end_name_hash(hash), len);\n}\n\n#endif\n\n/*\n * Name resolution.\n * This is the basic name resolution function, turning a pathname into\n * the final dentry. We expect 'base' to be positive and a directory.\n *\n * Returns 0 and nd will have valid dentry and mnt on success.\n * Returns error and drops reference to input namei data on failure.\n */\nstatic int link_path_walk(const char *name, struct nameidata *nd)\n{\n\tint err;\n\n\twhile (*name=='/')\n\t\tname++;\n\tif (!*name)\n\t\treturn 0;\n\n\t/* At this point we know we have a real path component. */\n\tfor(;;) {\n\t\tu64 hash_len;\n\t\tint type;\n\n\t\terr = may_lookup(nd);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\thash_len = hash_name(nd->path.dentry, name);\n\n\t\ttype = LAST_NORM;\n\t\tif (name[0] == '.') switch (hashlen_len(hash_len)) {\n\t\t\tcase 2:\n\t\t\t\tif (name[1] == '.') {\n\t\t\t\t\ttype = LAST_DOTDOT;\n\t\t\t\t\tnd->flags |= LOOKUP_JUMPED;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 1:\n\t\t\t\ttype = LAST_DOT;\n\t\t}\n\t\tif (likely(type == LAST_NORM)) {\n\t\t\tstruct dentry *parent = nd->path.dentry;\n\t\t\tnd->flags &= ~LOOKUP_JUMPED;\n\t\t\tif (unlikely(parent->d_flags & DCACHE_OP_HASH)) {\n\t\t\t\tstruct qstr this = { { .hash_len = hash_len }, .name = name };\n\t\t\t\terr = parent->d_op->d_hash(parent, &this);\n\t\t\t\tif (err < 0)\n\t\t\t\t\treturn err;\n\t\t\t\thash_len = this.hash_len;\n\t\t\t\tname = this.name;\n\t\t\t}\n\t\t}\n\n\t\tnd->last.hash_len = hash_len;\n\t\tnd->last.name = name;\n\t\tnd->last_type = type;\n\n\t\tname += hashlen_len(hash_len);\n\t\tif (!*name)\n\t\t\tgoto OK;\n\t\t/*\n\t\t * If it wasn't NUL, we know it was '/'. Skip that\n\t\t * slash, and continue until no more slashes.\n\t\t */\n\t\tdo {\n\t\t\tname++;\n\t\t} while (unlikely(*name == '/'));\n\t\tif (unlikely(!*name)) {\nOK:\n\t\t\t/* pathname body, done */\n\t\t\tif (!nd->depth)\n\t\t\t\treturn 0;\n\t\t\tname = nd->stack[nd->depth - 1].name;\n\t\t\t/* trailing symlink, done */\n\t\t\tif (!name)\n\t\t\t\treturn 0;\n\t\t\t/* last component of nested symlink */\n\t\t\terr = walk_component(nd, WALK_FOLLOW);\n\t\t} else {\n\t\t\t/* not the last component */\n\t\t\terr = walk_component(nd, WALK_FOLLOW | WALK_MORE);\n\t\t}\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\tif (err) {\n\t\t\tconst char *s = get_link(nd);\n\n\t\t\tif (IS_ERR(s))\n\t\t\t\treturn PTR_ERR(s);\n\t\t\terr = 0;\n\t\t\tif (unlikely(!s)) {\n\t\t\t\t/* jumped */\n\t\t\t\tput_link(nd);\n\t\t\t} else {\n\t\t\t\tnd->stack[nd->depth - 1].name = name;\n\t\t\t\tname = s;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\t\tif (unlikely(!d_can_lookup(nd->path.dentry))) {\n\t\t\tif (nd->flags & LOOKUP_RCU) {\n\t\t\t\tif (unlazy_walk(nd))\n\t\t\t\t\treturn -ECHILD;\n\t\t\t}\n\t\t\treturn -ENOTDIR;\n\t\t}\n\t}\n}\n\nstatic const char *path_init(struct nameidata *nd, unsigned flags)\n{\n\tconst char *s = nd->name->name;\n\n\tif (!*s)\n\t\tflags &= ~LOOKUP_RCU;\n\n\tnd->last_type = LAST_ROOT; /* if there are only slashes... */\n\tnd->flags = flags | LOOKUP_JUMPED | LOOKUP_PARENT;\n\tnd->depth = 0;\n\tif (flags & LOOKUP_ROOT) {\n\t\tstruct dentry *root = nd->root.dentry;\n\t\tstruct inode *inode = root->d_inode;\n\t\tif (*s && unlikely(!d_can_lookup(root)))\n\t\t\treturn ERR_PTR(-ENOTDIR);\n\t\tnd->path = nd->root;\n\t\tnd->inode = inode;\n\t\tif (flags & LOOKUP_RCU) {\n\t\t\trcu_read_lock();\n\t\t\tnd->seq = __read_seqcount_begin(&nd->path.dentry->d_seq);\n\t\t\tnd->root_seq = nd->seq;\n\t\t\tnd->m_seq = read_seqbegin(&mount_lock);\n\t\t} else {\n\t\t\tpath_get(&nd->path);\n\t\t}\n\t\treturn s;\n\t}\n\n\tnd->root.mnt = NULL;\n\tnd->path.mnt = NULL;\n\tnd->path.dentry = NULL;\n\n\tnd->m_seq = read_seqbegin(&mount_lock);\n\tif (*s == '/') {\n\t\tif (flags & LOOKUP_RCU)\n\t\t\trcu_read_lock();\n\t\tset_root(nd);\n\t\tif (likely(!nd_jump_root(nd)))\n\t\t\treturn s;\n\t\tnd->root.mnt = NULL;\n\t\trcu_read_unlock();\n\t\treturn ERR_PTR(-ECHILD);\n\t} else if (nd->dfd == AT_FDCWD) {\n\t\tif (flags & LOOKUP_RCU) {\n\t\t\tstruct fs_struct *fs = current->fs;\n\t\t\tunsigned seq;\n\n\t\t\trcu_read_lock();\n\n\t\t\tdo {\n\t\t\t\tseq = read_seqcount_begin(&fs->seq);\n\t\t\t\tnd->path = fs->pwd;\n\t\t\t\tnd->inode = nd->path.dentry->d_inode;\n\t\t\t\tnd->seq = __read_seqcount_begin(&nd->path.dentry->d_seq);\n\t\t\t} while (read_seqcount_retry(&fs->seq, seq));\n\t\t} else {\n\t\t\tget_fs_pwd(current->fs, &nd->path);\n\t\t\tnd->inode = nd->path.dentry->d_inode;\n\t\t}\n\t\treturn s;\n\t} else {\n\t\t/* Caller must check execute permissions on the starting path component */\n\t\tstruct fd f = fdget_raw(nd->dfd);\n\t\tstruct dentry *dentry;\n\n\t\tif (!f.file)\n\t\t\treturn ERR_PTR(-EBADF);\n\n\t\tdentry = f.file->f_path.dentry;\n\n\t\tif (*s) {\n\t\t\tif (!d_can_lookup(dentry)) {\n\t\t\t\tfdput(f);\n\t\t\t\treturn ERR_PTR(-ENOTDIR);\n\t\t\t}\n\t\t}\n\n\t\tnd->path = f.file->f_path;\n\t\tif (flags & LOOKUP_RCU) {\n\t\t\trcu_read_lock();\n\t\t\tnd->inode = nd->path.dentry->d_inode;\n\t\t\tnd->seq = read_seqcount_begin(&nd->path.dentry->d_seq);\n\t\t} else {\n\t\t\tpath_get(&nd->path);\n\t\t\tnd->inode = nd->path.dentry->d_inode;\n\t\t}\n\t\tfdput(f);\n\t\treturn s;\n\t}\n}\n\nstatic const char *trailing_symlink(struct nameidata *nd)\n{\n\tconst char *s;\n\tint error = may_follow_link(nd);\n\tif (unlikely(error))\n\t\treturn ERR_PTR(error);\n\tnd->flags |= LOOKUP_PARENT;\n\tnd->stack[0].name = NULL;\n\ts = get_link(nd);\n\treturn s ? s : \"\";\n}\n\nstatic inline int lookup_last(struct nameidata *nd)\n{\n\tif (nd->last_type == LAST_NORM && nd->last.name[nd->last.len])\n\t\tnd->flags |= LOOKUP_FOLLOW | LOOKUP_DIRECTORY;\n\n\tnd->flags &= ~LOOKUP_PARENT;\n\treturn walk_component(nd, 0);\n}\n\nstatic int handle_lookup_down(struct nameidata *nd)\n{\n\tstruct path path = nd->path;\n\tstruct inode *inode = nd->inode;\n\tunsigned seq = nd->seq;\n\tint err;\n\n\tif (nd->flags & LOOKUP_RCU) {\n\t\t/*\n\t\t * don't bother with unlazy_walk on failure - we are\n\t\t * at the very beginning of walk, so we lose nothing\n\t\t * if we simply redo everything in non-RCU mode\n\t\t */\n\t\tif (unlikely(!__follow_mount_rcu(nd, &path, &inode, &seq)))\n\t\t\treturn -ECHILD;\n\t} else {\n\t\tdget(path.dentry);\n\t\terr = follow_managed(&path, nd);\n\t\tif (unlikely(err < 0))\n\t\t\treturn err;\n\t\tinode = d_backing_inode(path.dentry);\n\t\tseq = 0;\n\t}\n\tpath_to_nameidata(&path, nd);\n\tnd->inode = inode;\n\tnd->seq = seq;\n\treturn 0;\n}\n\n/* Returns 0 and nd will be valid on success; Retuns error, otherwise. */\nstatic int path_lookupat(struct nameidata *nd, unsigned flags, struct path *path)\n{\n\tconst char *s = path_init(nd, flags);\n\tint err;\n\n\tif (IS_ERR(s))\n\t\treturn PTR_ERR(s);\n\n\tif (unlikely(flags & LOOKUP_DOWN)) {\n\t\terr = handle_lookup_down(nd);\n\t\tif (unlikely(err < 0)) {\n\t\t\tterminate_walk(nd);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\twhile (!(err = link_path_walk(s, nd))\n\t\t&& ((err = lookup_last(nd)) > 0)) {\n\t\ts = trailing_symlink(nd);\n\t\tif (IS_ERR(s)) {\n\t\t\terr = PTR_ERR(s);\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!err)\n\t\terr = complete_walk(nd);\n\n\tif (!err && nd->flags & LOOKUP_DIRECTORY)\n\t\tif (!d_can_lookup(nd->path.dentry))\n\t\t\terr = -ENOTDIR;\n\tif (!err) {\n\t\t*path = nd->path;\n\t\tnd->path.mnt = NULL;\n\t\tnd->path.dentry = NULL;\n\t}\n\tterminate_walk(nd);\n\treturn err;\n}\n\nstatic int filename_lookup(int dfd, struct filename *name, unsigned flags,\n\t\t\t   struct path *path, struct path *root)\n{\n\tint retval;\n\tstruct nameidata nd;\n\tif (IS_ERR(name))\n\t\treturn PTR_ERR(name);\n\tif (unlikely(root)) {\n\t\tnd.root = *root;\n\t\tflags |= LOOKUP_ROOT;\n\t}\n\tset_nameidata(&nd, dfd, name);\n\tretval = path_lookupat(&nd, flags | LOOKUP_RCU, path);\n\tif (unlikely(retval == -ECHILD))\n\t\tretval = path_lookupat(&nd, flags, path);\n\tif (unlikely(retval == -ESTALE))\n\t\tretval = path_lookupat(&nd, flags | LOOKUP_REVAL, path);\n\n\tif (likely(!retval))\n\t\taudit_inode(name, path->dentry, flags & LOOKUP_PARENT);\n\trestore_nameidata();\n\tputname(name);\n\treturn retval;\n}\n\n/* Returns 0 and nd will be valid on success; Retuns error, otherwise. */\nstatic int path_parentat(struct nameidata *nd, unsigned flags,\n\t\t\t\tstruct path *parent)\n{\n\tconst char *s = path_init(nd, flags);\n\tint err;\n\tif (IS_ERR(s))\n\t\treturn PTR_ERR(s);\n\terr = link_path_walk(s, nd);\n\tif (!err)\n\t\terr = complete_walk(nd);\n\tif (!err) {\n\t\t*parent = nd->path;\n\t\tnd->path.mnt = NULL;\n\t\tnd->path.dentry = NULL;\n\t}\n\tterminate_walk(nd);\n\treturn err;\n}\n\nstatic struct filename *filename_parentat(int dfd, struct filename *name,\n\t\t\t\tunsigned int flags, struct path *parent,\n\t\t\t\tstruct qstr *last, int *type)\n{\n\tint retval;\n\tstruct nameidata nd;\n\n\tif (IS_ERR(name))\n\t\treturn name;\n\tset_nameidata(&nd, dfd, name);\n\tretval = path_parentat(&nd, flags | LOOKUP_RCU, parent);\n\tif (unlikely(retval == -ECHILD))\n\t\tretval = path_parentat(&nd, flags, parent);\n\tif (unlikely(retval == -ESTALE))\n\t\tretval = path_parentat(&nd, flags | LOOKUP_REVAL, parent);\n\tif (likely(!retval)) {\n\t\t*last = nd.last;\n\t\t*type = nd.last_type;\n\t\taudit_inode(name, parent->dentry, LOOKUP_PARENT);\n\t} else {\n\t\tputname(name);\n\t\tname = ERR_PTR(retval);\n\t}\n\trestore_nameidata();\n\treturn name;\n}\n\n/* does lookup, returns the object with parent locked */\nstruct dentry *kern_path_locked(const char *name, struct path *path)\n{\n\tstruct filename *filename;\n\tstruct dentry *d;\n\tstruct qstr last;\n\tint type;\n\n\tfilename = filename_parentat(AT_FDCWD, getname_kernel(name), 0, path,\n\t\t\t\t    &last, &type);\n\tif (IS_ERR(filename))\n\t\treturn ERR_CAST(filename);\n\tif (unlikely(type != LAST_NORM)) {\n\t\tpath_put(path);\n\t\tputname(filename);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\tinode_lock_nested(path->dentry->d_inode, I_MUTEX_PARENT);\n\td = __lookup_hash(&last, path->dentry, 0);\n\tif (IS_ERR(d)) {\n\t\tinode_unlock(path->dentry->d_inode);\n\t\tpath_put(path);\n\t}\n\tputname(filename);\n\treturn d;\n}\n\nint kern_path(const char *name, unsigned int flags, struct path *path)\n{\n\treturn filename_lookup(AT_FDCWD, getname_kernel(name),\n\t\t\t       flags, path, NULL);\n}\nEXPORT_SYMBOL(kern_path);\n\n/**\n * vfs_path_lookup - lookup a file path relative to a dentry-vfsmount pair\n * @dentry:  pointer to dentry of the base directory\n * @mnt: pointer to vfs mount of the base directory\n * @name: pointer to file name\n * @flags: lookup flags\n * @path: pointer to struct path to fill\n */\nint vfs_path_lookup(struct dentry *dentry, struct vfsmount *mnt,\n\t\t    const char *name, unsigned int flags,\n\t\t    struct path *path)\n{\n\tstruct path root = {.mnt = mnt, .dentry = dentry};\n\t/* the first argument of filename_lookup() is ignored with root */\n\treturn filename_lookup(AT_FDCWD, getname_kernel(name),\n\t\t\t       flags , path, &root);\n}\nEXPORT_SYMBOL(vfs_path_lookup);\n\n/**\n * lookup_one_len - filesystem helper to lookup single pathname component\n * @name:\tpathname component to lookup\n * @base:\tbase directory to lookup from\n * @len:\tmaximum length @len should be interpreted to\n *\n * Note that this routine is purely a helper for filesystem usage and should\n * not be called by generic code.\n *\n * The caller must hold base->i_mutex.\n */\nstruct dentry *lookup_one_len(const char *name, struct dentry *base, int len)\n{\n\tstruct qstr this;\n\tunsigned int c;\n\tint err;\n\n\tWARN_ON_ONCE(!inode_is_locked(base->d_inode));\n\n\tthis.name = name;\n\tthis.len = len;\n\tthis.hash = full_name_hash(base, name, len);\n\tif (!len)\n\t\treturn ERR_PTR(-EACCES);\n\n\tif (unlikely(name[0] == '.')) {\n\t\tif (len < 2 || (len == 2 && name[1] == '.'))\n\t\t\treturn ERR_PTR(-EACCES);\n\t}\n\n\twhile (len--) {\n\t\tc = *(const unsigned char *)name++;\n\t\tif (c == '/' || c == '\\0')\n\t\t\treturn ERR_PTR(-EACCES);\n\t}\n\t/*\n\t * See if the low-level filesystem might want\n\t * to use its own hash..\n\t */\n\tif (base->d_flags & DCACHE_OP_HASH) {\n\t\tint err = base->d_op->d_hash(base, &this);\n\t\tif (err < 0)\n\t\t\treturn ERR_PTR(err);\n\t}\n\n\terr = inode_permission(base->d_inode, MAY_EXEC);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\treturn __lookup_hash(&this, base, 0);\n}\nEXPORT_SYMBOL(lookup_one_len);\n\n/**\n * lookup_one_len_unlocked - filesystem helper to lookup single pathname component\n * @name:\tpathname component to lookup\n * @base:\tbase directory to lookup from\n * @len:\tmaximum length @len should be interpreted to\n *\n * Note that this routine is purely a helper for filesystem usage and should\n * not be called by generic code.\n *\n * Unlike lookup_one_len, it should be called without the parent\n * i_mutex held, and will take the i_mutex itself if necessary.\n */\nstruct dentry *lookup_one_len_unlocked(const char *name,\n\t\t\t\t       struct dentry *base, int len)\n{\n\tstruct qstr this;\n\tunsigned int c;\n\tint err;\n\tstruct dentry *ret;\n\n\tthis.name = name;\n\tthis.len = len;\n\tthis.hash = full_name_hash(base, name, len);\n\tif (!len)\n\t\treturn ERR_PTR(-EACCES);\n\n\tif (unlikely(name[0] == '.')) {\n\t\tif (len < 2 || (len == 2 && name[1] == '.'))\n\t\t\treturn ERR_PTR(-EACCES);\n\t}\n\n\twhile (len--) {\n\t\tc = *(const unsigned char *)name++;\n\t\tif (c == '/' || c == '\\0')\n\t\t\treturn ERR_PTR(-EACCES);\n\t}\n\t/*\n\t * See if the low-level filesystem might want\n\t * to use its own hash..\n\t */\n\tif (base->d_flags & DCACHE_OP_HASH) {\n\t\tint err = base->d_op->d_hash(base, &this);\n\t\tif (err < 0)\n\t\t\treturn ERR_PTR(err);\n\t}\n\n\terr = inode_permission(base->d_inode, MAY_EXEC);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\tret = lookup_dcache(&this, base, 0);\n\tif (!ret)\n\t\tret = lookup_slow(&this, base, 0);\n\treturn ret;\n}\nEXPORT_SYMBOL(lookup_one_len_unlocked);\n\n#ifdef CONFIG_UNIX98_PTYS\nint path_pts(struct path *path)\n{\n\t/* Find something mounted on \"pts\" in the same directory as\n\t * the input path.\n\t */\n\tstruct dentry *child, *parent;\n\tstruct qstr this;\n\tint ret;\n\n\tret = path_parent_directory(path);\n\tif (ret)\n\t\treturn ret;\n\n\tparent = path->dentry;\n\tthis.name = \"pts\";\n\tthis.len = 3;\n\tchild = d_hash_and_lookup(parent, &this);\n\tif (!child)\n\t\treturn -ENOENT;\n\n\tpath->dentry = child;\n\tdput(parent);\n\tfollow_mount(path);\n\treturn 0;\n}\n#endif\n\nint user_path_at_empty(int dfd, const char __user *name, unsigned flags,\n\t\t struct path *path, int *empty)\n{\n\treturn filename_lookup(dfd, getname_flags(name, flags, empty),\n\t\t\t       flags, path, NULL);\n}\nEXPORT_SYMBOL(user_path_at_empty);\n\n/**\n * mountpoint_last - look up last component for umount\n * @nd:   pathwalk nameidata - currently pointing at parent directory of \"last\"\n *\n * This is a special lookup_last function just for umount. In this case, we\n * need to resolve the path without doing any revalidation.\n *\n * The nameidata should be the result of doing a LOOKUP_PARENT pathwalk. Since\n * mountpoints are always pinned in the dcache, their ancestors are too. Thus,\n * in almost all cases, this lookup will be served out of the dcache. The only\n * cases where it won't are if nd->last refers to a symlink or the path is\n * bogus and it doesn't exist.\n *\n * Returns:\n * -error: if there was an error during lookup. This includes -ENOENT if the\n *         lookup found a negative dentry.\n *\n * 0:      if we successfully resolved nd->last and found it to not to be a\n *         symlink that needs to be followed.\n *\n * 1:      if we successfully resolved nd->last and found it to be a symlink\n *         that needs to be followed.\n */\nstatic int\nmountpoint_last(struct nameidata *nd)\n{\n\tint error = 0;\n\tstruct dentry *dir = nd->path.dentry;\n\tstruct path path;\n\n\t/* If we're in rcuwalk, drop out of it to handle last component */\n\tif (nd->flags & LOOKUP_RCU) {\n\t\tif (unlazy_walk(nd))\n\t\t\treturn -ECHILD;\n\t}\n\n\tnd->flags &= ~LOOKUP_PARENT;\n\n\tif (unlikely(nd->last_type != LAST_NORM)) {\n\t\terror = handle_dots(nd, nd->last_type);\n\t\tif (error)\n\t\t\treturn error;\n\t\tpath.dentry = dget(nd->path.dentry);\n\t} else {\n\t\tpath.dentry = d_lookup(dir, &nd->last);\n\t\tif (!path.dentry) {\n\t\t\t/*\n\t\t\t * No cached dentry. Mounted dentries are pinned in the\n\t\t\t * cache, so that means that this dentry is probably\n\t\t\t * a symlink or the path doesn't actually point\n\t\t\t * to a mounted dentry.\n\t\t\t */\n\t\t\tpath.dentry = lookup_slow(&nd->last, dir,\n\t\t\t\t\t     nd->flags | LOOKUP_NO_REVAL);\n\t\t\tif (IS_ERR(path.dentry))\n\t\t\t\treturn PTR_ERR(path.dentry);\n\t\t}\n\t}\n\tif (d_is_negative(path.dentry)) {\n\t\tdput(path.dentry);\n\t\treturn -ENOENT;\n\t}\n\tpath.mnt = nd->path.mnt;\n\treturn step_into(nd, &path, 0, d_backing_inode(path.dentry), 0);\n}\n\n/**\n * path_mountpoint - look up a path to be umounted\n * @nd:\t\tlookup context\n * @flags:\tlookup flags\n * @path:\tpointer to container for result\n *\n * Look up the given name, but don't attempt to revalidate the last component.\n * Returns 0 and \"path\" will be valid on success; Returns error otherwise.\n */\nstatic int\npath_mountpoint(struct nameidata *nd, unsigned flags, struct path *path)\n{\n\tconst char *s = path_init(nd, flags);\n\tint err;\n\tif (IS_ERR(s))\n\t\treturn PTR_ERR(s);\n\twhile (!(err = link_path_walk(s, nd)) &&\n\t\t(err = mountpoint_last(nd)) > 0) {\n\t\ts = trailing_symlink(nd);\n\t\tif (IS_ERR(s)) {\n\t\t\terr = PTR_ERR(s);\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!err) {\n\t\t*path = nd->path;\n\t\tnd->path.mnt = NULL;\n\t\tnd->path.dentry = NULL;\n\t\tfollow_mount(path);\n\t}\n\tterminate_walk(nd);\n\treturn err;\n}\n\nstatic int\nfilename_mountpoint(int dfd, struct filename *name, struct path *path,\n\t\t\tunsigned int flags)\n{\n\tstruct nameidata nd;\n\tint error;\n\tif (IS_ERR(name))\n\t\treturn PTR_ERR(name);\n\tset_nameidata(&nd, dfd, name);\n\terror = path_mountpoint(&nd, flags | LOOKUP_RCU, path);\n\tif (unlikely(error == -ECHILD))\n\t\terror = path_mountpoint(&nd, flags, path);\n\tif (unlikely(error == -ESTALE))\n\t\terror = path_mountpoint(&nd, flags | LOOKUP_REVAL, path);\n\tif (likely(!error))\n\t\taudit_inode(name, path->dentry, 0);\n\trestore_nameidata();\n\tputname(name);\n\treturn error;\n}\n\n/**\n * user_path_mountpoint_at - lookup a path from userland in order to umount it\n * @dfd:\tdirectory file descriptor\n * @name:\tpathname from userland\n * @flags:\tlookup flags\n * @path:\tpointer to container to hold result\n *\n * A umount is a special case for path walking. We're not actually interested\n * in the inode in this situation, and ESTALE errors can be a problem. We\n * simply want track down the dentry and vfsmount attached at the mountpoint\n * and avoid revalidating the last component.\n *\n * Returns 0 and populates \"path\" on success.\n */\nint\nuser_path_mountpoint_at(int dfd, const char __user *name, unsigned int flags,\n\t\t\tstruct path *path)\n{\n\treturn filename_mountpoint(dfd, getname(name), path, flags);\n}\n\nint\nkern_path_mountpoint(int dfd, const char *name, struct path *path,\n\t\t\tunsigned int flags)\n{\n\treturn filename_mountpoint(dfd, getname_kernel(name), path, flags);\n}\nEXPORT_SYMBOL(kern_path_mountpoint);\n\nint __check_sticky(struct inode *dir, struct inode *inode)\n{\n\tkuid_t fsuid = current_fsuid();\n\n\tif (uid_eq(inode->i_uid, fsuid))\n\t\treturn 0;\n\tif (uid_eq(dir->i_uid, fsuid))\n\t\treturn 0;\n\treturn !capable_wrt_inode_uidgid(inode, CAP_FOWNER);\n}\nEXPORT_SYMBOL(__check_sticky);\n\n/*\n *\tCheck whether we can remove a link victim from directory dir, check\n *  whether the type of victim is right.\n *  1. We can't do it if dir is read-only (done in permission())\n *  2. We should have write and exec permissions on dir\n *  3. We can't remove anything from append-only dir\n *  4. We can't do anything with immutable dir (done in permission())\n *  5. If the sticky bit on dir is set we should either\n *\ta. be owner of dir, or\n *\tb. be owner of victim, or\n *\tc. have CAP_FOWNER capability\n *  6. If the victim is append-only or immutable we can't do antyhing with\n *     links pointing to it.\n *  7. If the victim has an unknown uid or gid we can't change the inode.\n *  8. If we were asked to remove a directory and victim isn't one - ENOTDIR.\n *  9. If we were asked to remove a non-directory and victim isn't one - EISDIR.\n * 10. We can't remove a root or mountpoint.\n * 11. We don't allow removal of NFS sillyrenamed files; it's handled by\n *     nfs_async_unlink().\n */\nstatic int may_delete(struct inode *dir, struct dentry *victim, bool isdir)\n{\n\tstruct inode *inode = d_backing_inode(victim);\n\tint error;\n\n\tif (d_is_negative(victim))\n\t\treturn -ENOENT;\n\tBUG_ON(!inode);\n\n\tBUG_ON(victim->d_parent->d_inode != dir);\n\taudit_inode_child(dir, victim, AUDIT_TYPE_CHILD_DELETE);\n\n\terror = inode_permission(dir, MAY_WRITE | MAY_EXEC);\n\tif (error)\n\t\treturn error;\n\tif (IS_APPEND(dir))\n\t\treturn -EPERM;\n\n\tif (check_sticky(dir, inode) || IS_APPEND(inode) ||\n\t    IS_IMMUTABLE(inode) || IS_SWAPFILE(inode) || HAS_UNMAPPED_ID(inode))\n\t\treturn -EPERM;\n\tif (isdir) {\n\t\tif (!d_is_dir(victim))\n\t\t\treturn -ENOTDIR;\n\t\tif (IS_ROOT(victim))\n\t\t\treturn -EBUSY;\n\t} else if (d_is_dir(victim))\n\t\treturn -EISDIR;\n\tif (IS_DEADDIR(dir))\n\t\treturn -ENOENT;\n\tif (victim->d_flags & DCACHE_NFSFS_RENAMED)\n\t\treturn -EBUSY;\n\treturn 0;\n}\n\n/*\tCheck whether we can create an object with dentry child in directory\n *  dir.\n *  1. We can't do it if child already exists (open has special treatment for\n *     this case, but since we are inlined it's OK)\n *  2. We can't do it if dir is read-only (done in permission())\n *  3. We can't do it if the fs can't represent the fsuid or fsgid.\n *  4. We should have write and exec permissions on dir\n *  5. We can't do it if dir is immutable (done in permission())\n */\nstatic inline int may_create(struct inode *dir, struct dentry *child)\n{\n\tstruct user_namespace *s_user_ns;\n\taudit_inode_child(dir, child, AUDIT_TYPE_CHILD_CREATE);\n\tif (child->d_inode)\n\t\treturn -EEXIST;\n\tif (IS_DEADDIR(dir))\n\t\treturn -ENOENT;\n\ts_user_ns = dir->i_sb->s_user_ns;\n\tif (!kuid_has_mapping(s_user_ns, current_fsuid()) ||\n\t    !kgid_has_mapping(s_user_ns, current_fsgid()))\n\t\treturn -EOVERFLOW;\n\treturn inode_permission(dir, MAY_WRITE | MAY_EXEC);\n}\n\n/*\n * p1 and p2 should be directories on the same fs.\n */\nstruct dentry *lock_rename(struct dentry *p1, struct dentry *p2)\n{\n\tstruct dentry *p;\n\n\tif (p1 == p2) {\n\t\tinode_lock_nested(p1->d_inode, I_MUTEX_PARENT);\n\t\treturn NULL;\n\t}\n\n\tmutex_lock(&p1->d_sb->s_vfs_rename_mutex);\n\n\tp = d_ancestor(p2, p1);\n\tif (p) {\n\t\tinode_lock_nested(p2->d_inode, I_MUTEX_PARENT);\n\t\tinode_lock_nested(p1->d_inode, I_MUTEX_CHILD);\n\t\treturn p;\n\t}\n\n\tp = d_ancestor(p1, p2);\n\tif (p) {\n\t\tinode_lock_nested(p1->d_inode, I_MUTEX_PARENT);\n\t\tinode_lock_nested(p2->d_inode, I_MUTEX_CHILD);\n\t\treturn p;\n\t}\n\n\tinode_lock_nested(p1->d_inode, I_MUTEX_PARENT);\n\tinode_lock_nested(p2->d_inode, I_MUTEX_PARENT2);\n\treturn NULL;\n}\nEXPORT_SYMBOL(lock_rename);\n\nvoid unlock_rename(struct dentry *p1, struct dentry *p2)\n{\n\tinode_unlock(p1->d_inode);\n\tif (p1 != p2) {\n\t\tinode_unlock(p2->d_inode);\n\t\tmutex_unlock(&p1->d_sb->s_vfs_rename_mutex);\n\t}\n}\nEXPORT_SYMBOL(unlock_rename);\n\nint vfs_create(struct inode *dir, struct dentry *dentry, umode_t mode,\n\t\tbool want_excl)\n{\n\tint error = may_create(dir, dentry);\n\tif (error)\n\t\treturn error;\n\n\tif (!dir->i_op->create)\n\t\treturn -EACCES;\t/* shouldn't it be ENOSYS? */\n\tmode &= S_IALLUGO;\n\tmode |= S_IFREG;\n\terror = security_inode_create(dir, dentry, mode);\n\tif (error)\n\t\treturn error;\n\terror = dir->i_op->create(dir, dentry, mode, want_excl);\n\tif (!error)\n\t\tfsnotify_create(dir, dentry);\n\treturn error;\n}\nEXPORT_SYMBOL(vfs_create);\n\nbool may_open_dev(const struct path *path)\n{\n\treturn !(path->mnt->mnt_flags & MNT_NODEV) &&\n\t\t!(path->mnt->mnt_sb->s_iflags & SB_I_NODEV);\n}\n\nstatic int may_open(const struct path *path, int acc_mode, int flag)\n{\n\tstruct dentry *dentry = path->dentry;\n\tstruct inode *inode = dentry->d_inode;\n\tint error;\n\n\tif (!inode)\n\t\treturn -ENOENT;\n\n\tswitch (inode->i_mode & S_IFMT) {\n\tcase S_IFLNK:\n\t\treturn -ELOOP;\n\tcase S_IFDIR:\n\t\tif (acc_mode & MAY_WRITE)\n\t\t\treturn -EISDIR;\n\t\tbreak;\n\tcase S_IFBLK:\n\tcase S_IFCHR:\n\t\tif (!may_open_dev(path))\n\t\t\treturn -EACCES;\n\t\t/*FALLTHRU*/\n\tcase S_IFIFO:\n\tcase S_IFSOCK:\n\t\tflag &= ~O_TRUNC;\n\t\tbreak;\n\t}\n\n\terror = inode_permission(inode, MAY_OPEN | acc_mode);\n\tif (error)\n\t\treturn error;\n\n\t/*\n\t * An append-only file must be opened in append mode for writing.\n\t */\n\tif (IS_APPEND(inode)) {\n\t\tif  ((flag & O_ACCMODE) != O_RDONLY && !(flag & O_APPEND))\n\t\t\treturn -EPERM;\n\t\tif (flag & O_TRUNC)\n\t\t\treturn -EPERM;\n\t}\n\n\t/* O_NOATIME can only be set by the owner or superuser */\n\tif (flag & O_NOATIME && !inode_owner_or_capable(inode))\n\t\treturn -EPERM;\n\n\treturn 0;\n}\n\nstatic int handle_truncate(struct file *filp)\n{\n\tconst struct path *path = &filp->f_path;\n\tstruct inode *inode = path->dentry->d_inode;\n\tint error = get_write_access(inode);\n\tif (error)\n\t\treturn error;\n\t/*\n\t * Refuse to truncate files with mandatory locks held on them.\n\t */\n\terror = locks_verify_locked(filp);\n\tif (!error)\n\t\terror = security_path_truncate(path);\n\tif (!error) {\n\t\terror = do_truncate(path->dentry, 0,\n\t\t\t\t    ATTR_MTIME|ATTR_CTIME|ATTR_OPEN,\n\t\t\t\t    filp);\n\t}\n\tput_write_access(inode);\n\treturn error;\n}\n\nstatic inline int open_to_namei_flags(int flag)\n{\n\tif ((flag & O_ACCMODE) == 3)\n\t\tflag--;\n\treturn flag;\n}\n\nstatic int may_o_create(const struct path *dir, struct dentry *dentry, umode_t mode)\n{\n\tstruct user_namespace *s_user_ns;\n\tint error = security_path_mknod(dir, dentry, mode, 0);\n\tif (error)\n\t\treturn error;\n\n\ts_user_ns = dir->dentry->d_sb->s_user_ns;\n\tif (!kuid_has_mapping(s_user_ns, current_fsuid()) ||\n\t    !kgid_has_mapping(s_user_ns, current_fsgid()))\n\t\treturn -EOVERFLOW;\n\n\terror = inode_permission(dir->dentry->d_inode, MAY_WRITE | MAY_EXEC);\n\tif (error)\n\t\treturn error;\n\n\treturn security_inode_create(dir->dentry->d_inode, dentry, mode);\n}\n\n/*\n * Attempt to atomically look up, create and open a file from a negative\n * dentry.\n *\n * Returns 0 if successful.  The file will have been created and attached to\n * @file by the filesystem calling finish_open().\n *\n * Returns 1 if the file was looked up only or didn't need creating.  The\n * caller will need to perform the open themselves.  @path will have been\n * updated to point to the new dentry.  This may be negative.\n *\n * Returns an error code otherwise.\n */\nstatic int atomic_open(struct nameidata *nd, struct dentry *dentry,\n\t\t\tstruct path *path, struct file *file,\n\t\t\tconst struct open_flags *op,\n\t\t\tint open_flag, umode_t mode,\n\t\t\tint *opened)\n{\n\tstruct dentry *const DENTRY_NOT_SET = (void *) -1UL;\n\tstruct inode *dir =  nd->path.dentry->d_inode;\n\tint error;\n\n\tif (!(~open_flag & (O_EXCL | O_CREAT)))\t/* both O_EXCL and O_CREAT */\n\t\topen_flag &= ~O_TRUNC;\n\n\tif (nd->flags & LOOKUP_DIRECTORY)\n\t\topen_flag |= O_DIRECTORY;\n\n\tfile->f_path.dentry = DENTRY_NOT_SET;\n\tfile->f_path.mnt = nd->path.mnt;\n\terror = dir->i_op->atomic_open(dir, dentry, file,\n\t\t\t\t       open_to_namei_flags(open_flag),\n\t\t\t\t       mode, opened);\n\td_lookup_done(dentry);\n\tif (!error) {\n\t\t/*\n\t\t * We didn't have the inode before the open, so check open\n\t\t * permission here.\n\t\t */\n\t\tint acc_mode = op->acc_mode;\n\t\tif (*opened & FILE_CREATED) {\n\t\t\tWARN_ON(!(open_flag & O_CREAT));\n\t\t\tfsnotify_create(dir, dentry);\n\t\t\tacc_mode = 0;\n\t\t}\n\t\terror = may_open(&file->f_path, acc_mode, open_flag);\n\t\tif (WARN_ON(error > 0))\n\t\t\terror = -EINVAL;\n\t} else if (error > 0) {\n\t\tif (WARN_ON(file->f_path.dentry == DENTRY_NOT_SET)) {\n\t\t\terror = -EIO;\n\t\t} else {\n\t\t\tif (file->f_path.dentry) {\n\t\t\t\tdput(dentry);\n\t\t\t\tdentry = file->f_path.dentry;\n\t\t\t}\n\t\t\tif (*opened & FILE_CREATED)\n\t\t\t\tfsnotify_create(dir, dentry);\n\t\t\tif (unlikely(d_is_negative(dentry))) {\n\t\t\t\terror = -ENOENT;\n\t\t\t} else {\n\t\t\t\tpath->dentry = dentry;\n\t\t\t\tpath->mnt = nd->path.mnt;\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\t}\n\tdput(dentry);\n\treturn error;\n}\n\n/*\n * Look up and maybe create and open the last component.\n *\n * Must be called with i_mutex held on parent.\n *\n * Returns 0 if the file was successfully atomically created (if necessary) and\n * opened.  In this case the file will be returned attached to @file.\n *\n * Returns 1 if the file was not completely opened at this time, though lookups\n * and creations will have been performed and the dentry returned in @path will\n * be positive upon return if O_CREAT was specified.  If O_CREAT wasn't\n * specified then a negative dentry may be returned.\n *\n * An error code is returned otherwise.\n *\n * FILE_CREATE will be set in @*opened if the dentry was created and will be\n * cleared otherwise prior to returning.\n */\nstatic int lookup_open(struct nameidata *nd, struct path *path,\n\t\t\tstruct file *file,\n\t\t\tconst struct open_flags *op,\n\t\t\tbool got_write, int *opened)\n{\n\tstruct dentry *dir = nd->path.dentry;\n\tstruct inode *dir_inode = dir->d_inode;\n\tint open_flag = op->open_flag;\n\tstruct dentry *dentry;\n\tint error, create_error = 0;\n\tumode_t mode = op->mode;\n\tDECLARE_WAIT_QUEUE_HEAD_ONSTACK(wq);\n\n\tif (unlikely(IS_DEADDIR(dir_inode)))\n\t\treturn -ENOENT;\n\n\t*opened &= ~FILE_CREATED;\n\tdentry = d_lookup(dir, &nd->last);\n\tfor (;;) {\n\t\tif (!dentry) {\n\t\t\tdentry = d_alloc_parallel(dir, &nd->last, &wq);\n\t\t\tif (IS_ERR(dentry))\n\t\t\t\treturn PTR_ERR(dentry);\n\t\t}\n\t\tif (d_in_lookup(dentry))\n\t\t\tbreak;\n\n\t\terror = d_revalidate(dentry, nd->flags);\n\t\tif (likely(error > 0))\n\t\t\tbreak;\n\t\tif (error)\n\t\t\tgoto out_dput;\n\t\td_invalidate(dentry);\n\t\tdput(dentry);\n\t\tdentry = NULL;\n\t}\n\tif (dentry->d_inode) {\n\t\t/* Cached positive dentry: will open in f_op->open */\n\t\tgoto out_no_open;\n\t}\n\n\t/*\n\t * Checking write permission is tricky, bacuse we don't know if we are\n\t * going to actually need it: O_CREAT opens should work as long as the\n\t * file exists.  But checking existence breaks atomicity.  The trick is\n\t * to check access and if not granted clear O_CREAT from the flags.\n\t *\n\t * Another problem is returing the \"right\" error value (e.g. for an\n\t * O_EXCL open we want to return EEXIST not EROFS).\n\t */\n\tif (open_flag & O_CREAT) {\n\t\tif (!IS_POSIXACL(dir->d_inode))\n\t\t\tmode &= ~current_umask();\n\t\tif (unlikely(!got_write)) {\n\t\t\tcreate_error = -EROFS;\n\t\t\topen_flag &= ~O_CREAT;\n\t\t\tif (open_flag & (O_EXCL | O_TRUNC))\n\t\t\t\tgoto no_open;\n\t\t\t/* No side effects, safe to clear O_CREAT */\n\t\t} else {\n\t\t\tcreate_error = may_o_create(&nd->path, dentry, mode);\n\t\t\tif (create_error) {\n\t\t\t\topen_flag &= ~O_CREAT;\n\t\t\t\tif (open_flag & O_EXCL)\n\t\t\t\t\tgoto no_open;\n\t\t\t}\n\t\t}\n\t} else if ((open_flag & (O_TRUNC|O_WRONLY|O_RDWR)) &&\n\t\t   unlikely(!got_write)) {\n\t\t/*\n\t\t * No O_CREATE -> atomicity not a requirement -> fall\n\t\t * back to lookup + open\n\t\t */\n\t\tgoto no_open;\n\t}\n\n\tif (dir_inode->i_op->atomic_open) {\n\t\terror = atomic_open(nd, dentry, path, file, op, open_flag,\n\t\t\t\t    mode, opened);\n\t\tif (unlikely(error == -ENOENT) && create_error)\n\t\t\terror = create_error;\n\t\treturn error;\n\t}\n\nno_open:\n\tif (d_in_lookup(dentry)) {\n\t\tstruct dentry *res = dir_inode->i_op->lookup(dir_inode, dentry,\n\t\t\t\t\t\t\t     nd->flags);\n\t\td_lookup_done(dentry);\n\t\tif (unlikely(res)) {\n\t\t\tif (IS_ERR(res)) {\n\t\t\t\terror = PTR_ERR(res);\n\t\t\t\tgoto out_dput;\n\t\t\t}\n\t\t\tdput(dentry);\n\t\t\tdentry = res;\n\t\t}\n\t}\n\n\t/* Negative dentry, just create the file */\n\tif (!dentry->d_inode && (open_flag & O_CREAT)) {\n\t\t*opened |= FILE_CREATED;\n\t\taudit_inode_child(dir_inode, dentry, AUDIT_TYPE_CHILD_CREATE);\n\t\tif (!dir_inode->i_op->create) {\n\t\t\terror = -EACCES;\n\t\t\tgoto out_dput;\n\t\t}\n\t\terror = dir_inode->i_op->create(dir_inode, dentry, mode,\n\t\t\t\t\t\topen_flag & O_EXCL);\n\t\tif (error)\n\t\t\tgoto out_dput;\n\t\tfsnotify_create(dir_inode, dentry);\n\t}\n\tif (unlikely(create_error) && !dentry->d_inode) {\n\t\terror = create_error;\n\t\tgoto out_dput;\n\t}\nout_no_open:\n\tpath->dentry = dentry;\n\tpath->mnt = nd->path.mnt;\n\treturn 1;\n\nout_dput:\n\tdput(dentry);\n\treturn error;\n}\n\n/*\n * Handle the last step of open()\n */\nstatic int do_last(struct nameidata *nd,\n\t\t   struct file *file, const struct open_flags *op,\n\t\t   int *opened)\n{\n\tstruct dentry *dir = nd->path.dentry;\n\tint open_flag = op->open_flag;\n\tbool will_truncate = (open_flag & O_TRUNC) != 0;\n\tbool got_write = false;\n\tint acc_mode = op->acc_mode;\n\tunsigned seq;\n\tstruct inode *inode;\n\tstruct path path;\n\tint error;\n\n\tnd->flags &= ~LOOKUP_PARENT;\n\tnd->flags |= op->intent;\n\n\tif (nd->last_type != LAST_NORM) {\n\t\terror = handle_dots(nd, nd->last_type);\n\t\tif (unlikely(error))\n\t\t\treturn error;\n\t\tgoto finish_open;\n\t}\n\n\tif (!(open_flag & O_CREAT)) {\n\t\tif (nd->last.name[nd->last.len])\n\t\t\tnd->flags |= LOOKUP_FOLLOW | LOOKUP_DIRECTORY;\n\t\t/* we _can_ be in RCU mode here */\n\t\terror = lookup_fast(nd, &path, &inode, &seq);\n\t\tif (likely(error > 0))\n\t\t\tgoto finish_lookup;\n\n\t\tif (error < 0)\n\t\t\treturn error;\n\n\t\tBUG_ON(nd->inode != dir->d_inode);\n\t\tBUG_ON(nd->flags & LOOKUP_RCU);\n\t} else {\n\t\t/* create side of things */\n\t\t/*\n\t\t * This will *only* deal with leaving RCU mode - LOOKUP_JUMPED\n\t\t * has been cleared when we got to the last component we are\n\t\t * about to look up\n\t\t */\n\t\terror = complete_walk(nd);\n\t\tif (error)\n\t\t\treturn error;\n\n\t\taudit_inode(nd->name, dir, LOOKUP_PARENT);\n\t\t/* trailing slashes? */\n\t\tif (unlikely(nd->last.name[nd->last.len]))\n\t\t\treturn -EISDIR;\n\t}\n\n\tif (open_flag & (O_CREAT | O_TRUNC | O_WRONLY | O_RDWR)) {\n\t\terror = mnt_want_write(nd->path.mnt);\n\t\tif (!error)\n\t\t\tgot_write = true;\n\t\t/*\n\t\t * do _not_ fail yet - we might not need that or fail with\n\t\t * a different error; let lookup_open() decide; we'll be\n\t\t * dropping this one anyway.\n\t\t */\n\t}\n\tif (open_flag & O_CREAT)\n\t\tinode_lock(dir->d_inode);\n\telse\n\t\tinode_lock_shared(dir->d_inode);\n\terror = lookup_open(nd, &path, file, op, got_write, opened);\n\tif (open_flag & O_CREAT)\n\t\tinode_unlock(dir->d_inode);\n\telse\n\t\tinode_unlock_shared(dir->d_inode);\n\n\tif (error <= 0) {\n\t\tif (error)\n\t\t\tgoto out;\n\n\t\tif ((*opened & FILE_CREATED) ||\n\t\t    !S_ISREG(file_inode(file)->i_mode))\n\t\t\twill_truncate = false;\n\n\t\taudit_inode(nd->name, file->f_path.dentry, 0);\n\t\tgoto opened;\n\t}\n\n\tif (*opened & FILE_CREATED) {\n\t\t/* Don't check for write permission, don't truncate */\n\t\topen_flag &= ~O_TRUNC;\n\t\twill_truncate = false;\n\t\tacc_mode = 0;\n\t\tpath_to_nameidata(&path, nd);\n\t\tgoto finish_open_created;\n\t}\n\n\t/*\n\t * If atomic_open() acquired write access it is dropped now due to\n\t * possible mount and symlink following (this might be optimized away if\n\t * necessary...)\n\t */\n\tif (got_write) {\n\t\tmnt_drop_write(nd->path.mnt);\n\t\tgot_write = false;\n\t}\n\n\terror = follow_managed(&path, nd);\n\tif (unlikely(error < 0))\n\t\treturn error;\n\n\tif (unlikely(d_is_negative(path.dentry))) {\n\t\tpath_to_nameidata(&path, nd);\n\t\treturn -ENOENT;\n\t}\n\n\t/*\n\t * create/update audit record if it already exists.\n\t */\n\taudit_inode(nd->name, path.dentry, 0);\n\n\tif (unlikely((open_flag & (O_EXCL | O_CREAT)) == (O_EXCL | O_CREAT))) {\n\t\tpath_to_nameidata(&path, nd);\n\t\treturn -EEXIST;\n\t}\n\n\tseq = 0;\t/* out of RCU mode, so the value doesn't matter */\n\tinode = d_backing_inode(path.dentry);\nfinish_lookup:\n\terror = step_into(nd, &path, 0, inode, seq);\n\tif (unlikely(error))\n\t\treturn error;\nfinish_open:\n\t/* Why this, you ask?  _Now_ we might have grown LOOKUP_JUMPED... */\n\terror = complete_walk(nd);\n\tif (error)\n\t\treturn error;\n\taudit_inode(nd->name, nd->path.dentry, 0);\n\terror = -EISDIR;\n\tif ((open_flag & O_CREAT) && d_is_dir(nd->path.dentry))\n\t\tgoto out;\n\terror = -ENOTDIR;\n\tif ((nd->flags & LOOKUP_DIRECTORY) && !d_can_lookup(nd->path.dentry))\n\t\tgoto out;\n\tif (!d_is_reg(nd->path.dentry))\n\t\twill_truncate = false;\n\n\tif (will_truncate) {\n\t\terror = mnt_want_write(nd->path.mnt);\n\t\tif (error)\n\t\t\tgoto out;\n\t\tgot_write = true;\n\t}\nfinish_open_created:\n\terror = may_open(&nd->path, acc_mode, open_flag);\n\tif (error)\n\t\tgoto out;\n\tBUG_ON(*opened & FILE_OPENED); /* once it's opened, it's opened */\n\terror = vfs_open(&nd->path, file, current_cred());\n\tif (error)\n\t\tgoto out;\n\t*opened |= FILE_OPENED;\nopened:\n\terror = open_check_o_direct(file);\n\tif (!error)\n\t\terror = ima_file_check(file, op->acc_mode, *opened);\n\tif (!error && will_truncate)\n\t\terror = handle_truncate(file);\nout:\n\tif (unlikely(error) && (*opened & FILE_OPENED))\n\t\tfput(file);\n\tif (unlikely(error > 0)) {\n\t\tWARN_ON(1);\n\t\terror = -EINVAL;\n\t}\n\tif (got_write)\n\t\tmnt_drop_write(nd->path.mnt);\n\treturn error;\n}\n\nstruct dentry *vfs_tmpfile(struct dentry *dentry, umode_t mode, int open_flag)\n{\n\tstatic const struct qstr name = QSTR_INIT(\"/\", 1);\n\tstruct dentry *child = NULL;\n\tstruct inode *dir = dentry->d_inode;\n\tstruct inode *inode;\n\tint error;\n\n\t/* we want directory to be writable */\n\terror = inode_permission(dir, MAY_WRITE | MAY_EXEC);\n\tif (error)\n\t\tgoto out_err;\n\terror = -EOPNOTSUPP;\n\tif (!dir->i_op->tmpfile)\n\t\tgoto out_err;\n\terror = -ENOMEM;\n\tchild = d_alloc(dentry, &name);\n\tif (unlikely(!child))\n\t\tgoto out_err;\n\terror = dir->i_op->tmpfile(dir, child, mode);\n\tif (error)\n\t\tgoto out_err;\n\terror = -ENOENT;\n\tinode = child->d_inode;\n\tif (unlikely(!inode))\n\t\tgoto out_err;\n\tif (!(open_flag & O_EXCL)) {\n\t\tspin_lock(&inode->i_lock);\n\t\tinode->i_state |= I_LINKABLE;\n\t\tspin_unlock(&inode->i_lock);\n\t}\n\treturn child;\n\nout_err:\n\tdput(child);\n\treturn ERR_PTR(error);\n}\nEXPORT_SYMBOL(vfs_tmpfile);\n\nstatic int do_tmpfile(struct nameidata *nd, unsigned flags,\n\t\tconst struct open_flags *op,\n\t\tstruct file *file, int *opened)\n{\n\tstruct dentry *child;\n\tstruct path path;\n\tint error = path_lookupat(nd, flags | LOOKUP_DIRECTORY, &path);\n\tif (unlikely(error))\n\t\treturn error;\n\terror = mnt_want_write(path.mnt);\n\tif (unlikely(error))\n\t\tgoto out;\n\tchild = vfs_tmpfile(path.dentry, op->mode, op->open_flag);\n\terror = PTR_ERR(child);\n\tif (unlikely(IS_ERR(child)))\n\t\tgoto out2;\n\tdput(path.dentry);\n\tpath.dentry = child;\n\taudit_inode(nd->name, child, 0);\n\t/* Don't check for other permissions, the inode was just created */\n\terror = may_open(&path, 0, op->open_flag);\n\tif (error)\n\t\tgoto out2;\n\tfile->f_path.mnt = path.mnt;\n\terror = finish_open(file, child, NULL, opened);\n\tif (error)\n\t\tgoto out2;\n\terror = open_check_o_direct(file);\n\tif (error)\n\t\tfput(file);\nout2:\n\tmnt_drop_write(path.mnt);\nout:\n\tpath_put(&path);\n\treturn error;\n}\n\nstatic int do_o_path(struct nameidata *nd, unsigned flags, struct file *file)\n{\n\tstruct path path;\n\tint error = path_lookupat(nd, flags, &path);\n\tif (!error) {\n\t\taudit_inode(nd->name, path.dentry, 0);\n\t\terror = vfs_open(&path, file, current_cred());\n\t\tpath_put(&path);\n\t}\n\treturn error;\n}\n\nstatic struct file *path_openat(struct nameidata *nd,\n\t\t\tconst struct open_flags *op, unsigned flags)\n{\n\tconst char *s;\n\tstruct file *file;\n\tint opened = 0;\n\tint error;\n\n\tfile = get_empty_filp();\n\tif (IS_ERR(file))\n\t\treturn file;\n\n\tfile->f_flags = op->open_flag;\n\n\tif (unlikely(file->f_flags & __O_TMPFILE)) {\n\t\terror = do_tmpfile(nd, flags, op, file, &opened);\n\t\tgoto out2;\n\t}\n\n\tif (unlikely(file->f_flags & O_PATH)) {\n\t\terror = do_o_path(nd, flags, file);\n\t\tif (!error)\n\t\t\topened |= FILE_OPENED;\n\t\tgoto out2;\n\t}\n\n\ts = path_init(nd, flags);\n\tif (IS_ERR(s)) {\n\t\tput_filp(file);\n\t\treturn ERR_CAST(s);\n\t}\n\twhile (!(error = link_path_walk(s, nd)) &&\n\t\t(error = do_last(nd, file, op, &opened)) > 0) {\n\t\tnd->flags &= ~(LOOKUP_OPEN|LOOKUP_CREATE|LOOKUP_EXCL);\n\t\ts = trailing_symlink(nd);\n\t\tif (IS_ERR(s)) {\n\t\t\terror = PTR_ERR(s);\n\t\t\tbreak;\n\t\t}\n\t}\n\tterminate_walk(nd);\nout2:\n\tif (!(opened & FILE_OPENED)) {\n\t\tBUG_ON(!error);\n\t\tput_filp(file);\n\t}\n\tif (unlikely(error)) {\n\t\tif (error == -EOPENSTALE) {\n\t\t\tif (flags & LOOKUP_RCU)\n\t\t\t\terror = -ECHILD;\n\t\t\telse\n\t\t\t\terror = -ESTALE;\n\t\t}\n\t\tfile = ERR_PTR(error);\n\t}\n\treturn file;\n}\n\nstruct file *do_filp_open(int dfd, struct filename *pathname,\n\t\tconst struct open_flags *op)\n{\n\tstruct nameidata nd;\n\tint flags = op->lookup_flags;\n\tstruct file *filp;\n\n\tset_nameidata(&nd, dfd, pathname);\n\tfilp = path_openat(&nd, op, flags | LOOKUP_RCU);\n\tif (unlikely(filp == ERR_PTR(-ECHILD)))\n\t\tfilp = path_openat(&nd, op, flags);\n\tif (unlikely(filp == ERR_PTR(-ESTALE)))\n\t\tfilp = path_openat(&nd, op, flags | LOOKUP_REVAL);\n\trestore_nameidata();\n\treturn filp;\n}\n\nstruct file *do_file_open_root(struct dentry *dentry, struct vfsmount *mnt,\n\t\tconst char *name, const struct open_flags *op)\n{\n\tstruct nameidata nd;\n\tstruct file *file;\n\tstruct filename *filename;\n\tint flags = op->lookup_flags | LOOKUP_ROOT;\n\n\tnd.root.mnt = mnt;\n\tnd.root.dentry = dentry;\n\n\tif (d_is_symlink(dentry) && op->intent & LOOKUP_OPEN)\n\t\treturn ERR_PTR(-ELOOP);\n\n\tfilename = getname_kernel(name);\n\tif (IS_ERR(filename))\n\t\treturn ERR_CAST(filename);\n\n\tset_nameidata(&nd, -1, filename);\n\tfile = path_openat(&nd, op, flags | LOOKUP_RCU);\n\tif (unlikely(file == ERR_PTR(-ECHILD)))\n\t\tfile = path_openat(&nd, op, flags);\n\tif (unlikely(file == ERR_PTR(-ESTALE)))\n\t\tfile = path_openat(&nd, op, flags | LOOKUP_REVAL);\n\trestore_nameidata();\n\tputname(filename);\n\treturn file;\n}\n\nstatic struct dentry *filename_create(int dfd, struct filename *name,\n\t\t\t\tstruct path *path, unsigned int lookup_flags)\n{\n\tstruct dentry *dentry = ERR_PTR(-EEXIST);\n\tstruct qstr last;\n\tint type;\n\tint err2;\n\tint error;\n\tbool is_dir = (lookup_flags & LOOKUP_DIRECTORY);\n\n\t/*\n\t * Note that only LOOKUP_REVAL and LOOKUP_DIRECTORY matter here. Any\n\t * other flags passed in are ignored!\n\t */\n\tlookup_flags &= LOOKUP_REVAL;\n\n\tname = filename_parentat(dfd, name, lookup_flags, path, &last, &type);\n\tif (IS_ERR(name))\n\t\treturn ERR_CAST(name);\n\n\t/*\n\t * Yucky last component or no last component at all?\n\t * (foo/., foo/.., /////)\n\t */\n\tif (unlikely(type != LAST_NORM))\n\t\tgoto out;\n\n\t/* don't fail immediately if it's r/o, at least try to report other errors */\n\terr2 = mnt_want_write(path->mnt);\n\t/*\n\t * Do the final lookup.\n\t */\n\tlookup_flags |= LOOKUP_CREATE | LOOKUP_EXCL;\n\tinode_lock_nested(path->dentry->d_inode, I_MUTEX_PARENT);\n\tdentry = __lookup_hash(&last, path->dentry, lookup_flags);\n\tif (IS_ERR(dentry))\n\t\tgoto unlock;\n\n\terror = -EEXIST;\n\tif (d_is_positive(dentry))\n\t\tgoto fail;\n\n\t/*\n\t * Special case - lookup gave negative, but... we had foo/bar/\n\t * From the vfs_mknod() POV we just have a negative dentry -\n\t * all is fine. Let's be bastards - you had / on the end, you've\n\t * been asking for (non-existent) directory. -ENOENT for you.\n\t */\n\tif (unlikely(!is_dir && last.name[last.len])) {\n\t\terror = -ENOENT;\n\t\tgoto fail;\n\t}\n\tif (unlikely(err2)) {\n\t\terror = err2;\n\t\tgoto fail;\n\t}\n\tputname(name);\n\treturn dentry;\nfail:\n\tdput(dentry);\n\tdentry = ERR_PTR(error);\nunlock:\n\tinode_unlock(path->dentry->d_inode);\n\tif (!err2)\n\t\tmnt_drop_write(path->mnt);\nout:\n\tpath_put(path);\n\tputname(name);\n\treturn dentry;\n}\n\nstruct dentry *kern_path_create(int dfd, const char *pathname,\n\t\t\t\tstruct path *path, unsigned int lookup_flags)\n{\n\treturn filename_create(dfd, getname_kernel(pathname),\n\t\t\t\tpath, lookup_flags);\n}\nEXPORT_SYMBOL(kern_path_create);\n\nvoid done_path_create(struct path *path, struct dentry *dentry)\n{\n\tdput(dentry);\n\tinode_unlock(path->dentry->d_inode);\n\tmnt_drop_write(path->mnt);\n\tpath_put(path);\n}\nEXPORT_SYMBOL(done_path_create);\n\ninline struct dentry *user_path_create(int dfd, const char __user *pathname,\n\t\t\t\tstruct path *path, unsigned int lookup_flags)\n{\n\treturn filename_create(dfd, getname(pathname), path, lookup_flags);\n}\nEXPORT_SYMBOL(user_path_create);\n\nint vfs_mknod(struct inode *dir, struct dentry *dentry, umode_t mode, dev_t dev)\n{\n\tint error = may_create(dir, dentry);\n\n\tif (error)\n\t\treturn error;\n\n\tif ((S_ISCHR(mode) || S_ISBLK(mode)) && !capable(CAP_MKNOD))\n\t\treturn -EPERM;\n\n\tif (!dir->i_op->mknod)\n\t\treturn -EPERM;\n\n\terror = devcgroup_inode_mknod(mode, dev);\n\tif (error)\n\t\treturn error;\n\n\terror = security_inode_mknod(dir, dentry, mode, dev);\n\tif (error)\n\t\treturn error;\n\n\terror = dir->i_op->mknod(dir, dentry, mode, dev);\n\tif (!error)\n\t\tfsnotify_create(dir, dentry);\n\treturn error;\n}\nEXPORT_SYMBOL(vfs_mknod);\n\nstatic int may_mknod(umode_t mode)\n{\n\tswitch (mode & S_IFMT) {\n\tcase S_IFREG:\n\tcase S_IFCHR:\n\tcase S_IFBLK:\n\tcase S_IFIFO:\n\tcase S_IFSOCK:\n\tcase 0: /* zero mode translates to S_IFREG */\n\t\treturn 0;\n\tcase S_IFDIR:\n\t\treturn -EPERM;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nSYSCALL_DEFINE4(mknodat, int, dfd, const char __user *, filename, umode_t, mode,\n\t\tunsigned, dev)\n{\n\tstruct dentry *dentry;\n\tstruct path path;\n\tint error;\n\tunsigned int lookup_flags = 0;\n\n\terror = may_mknod(mode);\n\tif (error)\n\t\treturn error;\nretry:\n\tdentry = user_path_create(dfd, filename, &path, lookup_flags);\n\tif (IS_ERR(dentry))\n\t\treturn PTR_ERR(dentry);\n\n\tif (!IS_POSIXACL(path.dentry->d_inode))\n\t\tmode &= ~current_umask();\n\terror = security_path_mknod(&path, dentry, mode, dev);\n\tif (error)\n\t\tgoto out;\n\tswitch (mode & S_IFMT) {\n\t\tcase 0: case S_IFREG:\n\t\t\terror = vfs_create(path.dentry->d_inode,dentry,mode,true);\n\t\t\tif (!error)\n\t\t\t\tima_post_path_mknod(dentry);\n\t\t\tbreak;\n\t\tcase S_IFCHR: case S_IFBLK:\n\t\t\terror = vfs_mknod(path.dentry->d_inode,dentry,mode,\n\t\t\t\t\tnew_decode_dev(dev));\n\t\t\tbreak;\n\t\tcase S_IFIFO: case S_IFSOCK:\n\t\t\terror = vfs_mknod(path.dentry->d_inode,dentry,mode,0);\n\t\t\tbreak;\n\t}\nout:\n\tdone_path_create(&path, dentry);\n\tif (retry_estale(error, lookup_flags)) {\n\t\tlookup_flags |= LOOKUP_REVAL;\n\t\tgoto retry;\n\t}\n\treturn error;\n}\n\nSYSCALL_DEFINE3(mknod, const char __user *, filename, umode_t, mode, unsigned, dev)\n{\n\treturn sys_mknodat(AT_FDCWD, filename, mode, dev);\n}\n\nint vfs_mkdir(struct inode *dir, struct dentry *dentry, umode_t mode)\n{\n\tint error = may_create(dir, dentry);\n\tunsigned max_links = dir->i_sb->s_max_links;\n\n\tif (error)\n\t\treturn error;\n\n\tif (!dir->i_op->mkdir)\n\t\treturn -EPERM;\n\n\tmode &= (S_IRWXUGO|S_ISVTX);\n\terror = security_inode_mkdir(dir, dentry, mode);\n\tif (error)\n\t\treturn error;\n\n\tif (max_links && dir->i_nlink >= max_links)\n\t\treturn -EMLINK;\n\n\terror = dir->i_op->mkdir(dir, dentry, mode);\n\tif (!error)\n\t\tfsnotify_mkdir(dir, dentry);\n\treturn error;\n}\nEXPORT_SYMBOL(vfs_mkdir);\n\nSYSCALL_DEFINE3(mkdirat, int, dfd, const char __user *, pathname, umode_t, mode)\n{\n\tstruct dentry *dentry;\n\tstruct path path;\n\tint error;\n\tunsigned int lookup_flags = LOOKUP_DIRECTORY;\n\nretry:\n\tdentry = user_path_create(dfd, pathname, &path, lookup_flags);\n\tif (IS_ERR(dentry))\n\t\treturn PTR_ERR(dentry);\n\n\tif (!IS_POSIXACL(path.dentry->d_inode))\n\t\tmode &= ~current_umask();\n\terror = security_path_mkdir(&path, dentry, mode);\n\tif (!error)\n\t\terror = vfs_mkdir(path.dentry->d_inode, dentry, mode);\n\tdone_path_create(&path, dentry);\n\tif (retry_estale(error, lookup_flags)) {\n\t\tlookup_flags |= LOOKUP_REVAL;\n\t\tgoto retry;\n\t}\n\treturn error;\n}\n\nSYSCALL_DEFINE2(mkdir, const char __user *, pathname, umode_t, mode)\n{\n\treturn sys_mkdirat(AT_FDCWD, pathname, mode);\n}\n\nint vfs_rmdir(struct inode *dir, struct dentry *dentry)\n{\n\tint error = may_delete(dir, dentry, 1);\n\n\tif (error)\n\t\treturn error;\n\n\tif (!dir->i_op->rmdir)\n\t\treturn -EPERM;\n\n\tdget(dentry);\n\tinode_lock(dentry->d_inode);\n\n\terror = -EBUSY;\n\tif (is_local_mountpoint(dentry))\n\t\tgoto out;\n\n\terror = security_inode_rmdir(dir, dentry);\n\tif (error)\n\t\tgoto out;\n\n\tshrink_dcache_parent(dentry);\n\terror = dir->i_op->rmdir(dir, dentry);\n\tif (error)\n\t\tgoto out;\n\n\tdentry->d_inode->i_flags |= S_DEAD;\n\tdont_mount(dentry);\n\tdetach_mounts(dentry);\n\nout:\n\tinode_unlock(dentry->d_inode);\n\tdput(dentry);\n\tif (!error)\n\t\td_delete(dentry);\n\treturn error;\n}\nEXPORT_SYMBOL(vfs_rmdir);\n\nstatic long do_rmdir(int dfd, const char __user *pathname)\n{\n\tint error = 0;\n\tstruct filename *name;\n\tstruct dentry *dentry;\n\tstruct path path;\n\tstruct qstr last;\n\tint type;\n\tunsigned int lookup_flags = 0;\nretry:\n\tname = filename_parentat(dfd, getname(pathname), lookup_flags,\n\t\t\t\t&path, &last, &type);\n\tif (IS_ERR(name))\n\t\treturn PTR_ERR(name);\n\n\tswitch (type) {\n\tcase LAST_DOTDOT:\n\t\terror = -ENOTEMPTY;\n\t\tgoto exit1;\n\tcase LAST_DOT:\n\t\terror = -EINVAL;\n\t\tgoto exit1;\n\tcase LAST_ROOT:\n\t\terror = -EBUSY;\n\t\tgoto exit1;\n\t}\n\n\terror = mnt_want_write(path.mnt);\n\tif (error)\n\t\tgoto exit1;\n\n\tinode_lock_nested(path.dentry->d_inode, I_MUTEX_PARENT);\n\tdentry = __lookup_hash(&last, path.dentry, lookup_flags);\n\terror = PTR_ERR(dentry);\n\tif (IS_ERR(dentry))\n\t\tgoto exit2;\n\tif (!dentry->d_inode) {\n\t\terror = -ENOENT;\n\t\tgoto exit3;\n\t}\n\terror = security_path_rmdir(&path, dentry);\n\tif (error)\n\t\tgoto exit3;\n\terror = vfs_rmdir(path.dentry->d_inode, dentry);\nexit3:\n\tdput(dentry);\nexit2:\n\tinode_unlock(path.dentry->d_inode);\n\tmnt_drop_write(path.mnt);\nexit1:\n\tpath_put(&path);\n\tputname(name);\n\tif (retry_estale(error, lookup_flags)) {\n\t\tlookup_flags |= LOOKUP_REVAL;\n\t\tgoto retry;\n\t}\n\treturn error;\n}\n\nSYSCALL_DEFINE1(rmdir, const char __user *, pathname)\n{\n\treturn do_rmdir(AT_FDCWD, pathname);\n}\n\n/**\n * vfs_unlink - unlink a filesystem object\n * @dir:\tparent directory\n * @dentry:\tvictim\n * @delegated_inode: returns victim inode, if the inode is delegated.\n *\n * The caller must hold dir->i_mutex.\n *\n * If vfs_unlink discovers a delegation, it will return -EWOULDBLOCK and\n * return a reference to the inode in delegated_inode.  The caller\n * should then break the delegation on that inode and retry.  Because\n * breaking a delegation may take a long time, the caller should drop\n * dir->i_mutex before doing so.\n *\n * Alternatively, a caller may pass NULL for delegated_inode.  This may\n * be appropriate for callers that expect the underlying filesystem not\n * to be NFS exported.\n */\nint vfs_unlink(struct inode *dir, struct dentry *dentry, struct inode **delegated_inode)\n{\n\tstruct inode *target = dentry->d_inode;\n\tint error = may_delete(dir, dentry, 0);\n\n\tif (error)\n\t\treturn error;\n\n\tif (!dir->i_op->unlink)\n\t\treturn -EPERM;\n\n\tinode_lock(target);\n\tif (is_local_mountpoint(dentry))\n\t\terror = -EBUSY;\n\telse {\n\t\terror = security_inode_unlink(dir, dentry);\n\t\tif (!error) {\n\t\t\terror = try_break_deleg(target, delegated_inode);\n\t\t\tif (error)\n\t\t\t\tgoto out;\n\t\t\terror = dir->i_op->unlink(dir, dentry);\n\t\t\tif (!error) {\n\t\t\t\tdont_mount(dentry);\n\t\t\t\tdetach_mounts(dentry);\n\t\t\t}\n\t\t}\n\t}\nout:\n\tinode_unlock(target);\n\n\t/* We don't d_delete() NFS sillyrenamed files--they still exist. */\n\tif (!error && !(dentry->d_flags & DCACHE_NFSFS_RENAMED)) {\n\t\tfsnotify_link_count(target);\n\t\td_delete(dentry);\n\t}\n\n\treturn error;\n}\nEXPORT_SYMBOL(vfs_unlink);\n\n/*\n * Make sure that the actual truncation of the file will occur outside its\n * directory's i_mutex.  Truncate can take a long time if there is a lot of\n * writeout happening, and we don't want to prevent access to the directory\n * while waiting on the I/O.\n */\nstatic long do_unlinkat(int dfd, const char __user *pathname)\n{\n\tint error;\n\tstruct filename *name;\n\tstruct dentry *dentry;\n\tstruct path path;\n\tstruct qstr last;\n\tint type;\n\tstruct inode *inode = NULL;\n\tstruct inode *delegated_inode = NULL;\n\tunsigned int lookup_flags = 0;\nretry:\n\tname = filename_parentat(dfd, getname(pathname), lookup_flags,\n\t\t\t\t&path, &last, &type);\n\tif (IS_ERR(name))\n\t\treturn PTR_ERR(name);\n\n\terror = -EISDIR;\n\tif (type != LAST_NORM)\n\t\tgoto exit1;\n\n\terror = mnt_want_write(path.mnt);\n\tif (error)\n\t\tgoto exit1;\nretry_deleg:\n\tinode_lock_nested(path.dentry->d_inode, I_MUTEX_PARENT);\n\tdentry = __lookup_hash(&last, path.dentry, lookup_flags);\n\terror = PTR_ERR(dentry);\n\tif (!IS_ERR(dentry)) {\n\t\t/* Why not before? Because we want correct error value */\n\t\tif (last.name[last.len])\n\t\t\tgoto slashes;\n\t\tinode = dentry->d_inode;\n\t\tif (d_is_negative(dentry))\n\t\t\tgoto slashes;\n\t\tihold(inode);\n\t\terror = security_path_unlink(&path, dentry);\n\t\tif (error)\n\t\t\tgoto exit2;\n\t\terror = vfs_unlink(path.dentry->d_inode, dentry, &delegated_inode);\nexit2:\n\t\tdput(dentry);\n\t}\n\tinode_unlock(path.dentry->d_inode);\n\tif (inode)\n\t\tiput(inode);\t/* truncate the inode here */\n\tinode = NULL;\n\tif (delegated_inode) {\n\t\terror = break_deleg_wait(&delegated_inode);\n\t\tif (!error)\n\t\t\tgoto retry_deleg;\n\t}\n\tmnt_drop_write(path.mnt);\nexit1:\n\tpath_put(&path);\n\tputname(name);\n\tif (retry_estale(error, lookup_flags)) {\n\t\tlookup_flags |= LOOKUP_REVAL;\n\t\tinode = NULL;\n\t\tgoto retry;\n\t}\n\treturn error;\n\nslashes:\n\tif (d_is_negative(dentry))\n\t\terror = -ENOENT;\n\telse if (d_is_dir(dentry))\n\t\terror = -EISDIR;\n\telse\n\t\terror = -ENOTDIR;\n\tgoto exit2;\n}\n\nSYSCALL_DEFINE3(unlinkat, int, dfd, const char __user *, pathname, int, flag)\n{\n\tif ((flag & ~AT_REMOVEDIR) != 0)\n\t\treturn -EINVAL;\n\n\tif (flag & AT_REMOVEDIR)\n\t\treturn do_rmdir(dfd, pathname);\n\n\treturn do_unlinkat(dfd, pathname);\n}\n\nSYSCALL_DEFINE1(unlink, const char __user *, pathname)\n{\n\treturn do_unlinkat(AT_FDCWD, pathname);\n}\n\nint vfs_symlink(struct inode *dir, struct dentry *dentry, const char *oldname)\n{\n\tint error = may_create(dir, dentry);\n\n\tif (error)\n\t\treturn error;\n\n\tif (!dir->i_op->symlink)\n\t\treturn -EPERM;\n\n\terror = security_inode_symlink(dir, dentry, oldname);\n\tif (error)\n\t\treturn error;\n\n\terror = dir->i_op->symlink(dir, dentry, oldname);\n\tif (!error)\n\t\tfsnotify_create(dir, dentry);\n\treturn error;\n}\nEXPORT_SYMBOL(vfs_symlink);\n\nSYSCALL_DEFINE3(symlinkat, const char __user *, oldname,\n\t\tint, newdfd, const char __user *, newname)\n{\n\tint error;\n\tstruct filename *from;\n\tstruct dentry *dentry;\n\tstruct path path;\n\tunsigned int lookup_flags = 0;\n\n\tfrom = getname(oldname);\n\tif (IS_ERR(from))\n\t\treturn PTR_ERR(from);\nretry:\n\tdentry = user_path_create(newdfd, newname, &path, lookup_flags);\n\terror = PTR_ERR(dentry);\n\tif (IS_ERR(dentry))\n\t\tgoto out_putname;\n\n\terror = security_path_symlink(&path, dentry, from->name);\n\tif (!error)\n\t\terror = vfs_symlink(path.dentry->d_inode, dentry, from->name);\n\tdone_path_create(&path, dentry);\n\tif (retry_estale(error, lookup_flags)) {\n\t\tlookup_flags |= LOOKUP_REVAL;\n\t\tgoto retry;\n\t}\nout_putname:\n\tputname(from);\n\treturn error;\n}\n\nSYSCALL_DEFINE2(symlink, const char __user *, oldname, const char __user *, newname)\n{\n\treturn sys_symlinkat(oldname, AT_FDCWD, newname);\n}\n\n/**\n * vfs_link - create a new link\n * @old_dentry:\tobject to be linked\n * @dir:\tnew parent\n * @new_dentry:\twhere to create the new link\n * @delegated_inode: returns inode needing a delegation break\n *\n * The caller must hold dir->i_mutex\n *\n * If vfs_link discovers a delegation on the to-be-linked file in need\n * of breaking, it will return -EWOULDBLOCK and return a reference to the\n * inode in delegated_inode.  The caller should then break the delegation\n * and retry.  Because breaking a delegation may take a long time, the\n * caller should drop the i_mutex before doing so.\n *\n * Alternatively, a caller may pass NULL for delegated_inode.  This may\n * be appropriate for callers that expect the underlying filesystem not\n * to be NFS exported.\n */\nint vfs_link(struct dentry *old_dentry, struct inode *dir, struct dentry *new_dentry, struct inode **delegated_inode)\n{\n\tstruct inode *inode = old_dentry->d_inode;\n\tunsigned max_links = dir->i_sb->s_max_links;\n\tint error;\n\n\tif (!inode)\n\t\treturn -ENOENT;\n\n\terror = may_create(dir, new_dentry);\n\tif (error)\n\t\treturn error;\n\n\tif (dir->i_sb != inode->i_sb)\n\t\treturn -EXDEV;\n\n\t/*\n\t * A link to an append-only or immutable file cannot be created.\n\t */\n\tif (IS_APPEND(inode) || IS_IMMUTABLE(inode))\n\t\treturn -EPERM;\n\t/*\n\t * Updating the link count will likely cause i_uid and i_gid to\n\t * be writen back improperly if their true value is unknown to\n\t * the vfs.\n\t */\n\tif (HAS_UNMAPPED_ID(inode))\n\t\treturn -EPERM;\n\tif (!dir->i_op->link)\n\t\treturn -EPERM;\n\tif (S_ISDIR(inode->i_mode))\n\t\treturn -EPERM;\n\n\terror = security_inode_link(old_dentry, dir, new_dentry);\n\tif (error)\n\t\treturn error;\n\n\tinode_lock(inode);\n\t/* Make sure we don't allow creating hardlink to an unlinked file */\n\tif (inode->i_nlink == 0 && !(inode->i_state & I_LINKABLE))\n\t\terror =  -ENOENT;\n\telse if (max_links && inode->i_nlink >= max_links)\n\t\terror = -EMLINK;\n\telse {\n\t\terror = try_break_deleg(inode, delegated_inode);\n\t\tif (!error)\n\t\t\terror = dir->i_op->link(old_dentry, dir, new_dentry);\n\t}\n\n\tif (!error && (inode->i_state & I_LINKABLE)) {\n\t\tspin_lock(&inode->i_lock);\n\t\tinode->i_state &= ~I_LINKABLE;\n\t\tspin_unlock(&inode->i_lock);\n\t}\n\tinode_unlock(inode);\n\tif (!error)\n\t\tfsnotify_link(dir, inode, new_dentry);\n\treturn error;\n}\nEXPORT_SYMBOL(vfs_link);\n\n/*\n * Hardlinks are often used in delicate situations.  We avoid\n * security-related surprises by not following symlinks on the\n * newname.  --KAB\n *\n * We don't follow them on the oldname either to be compatible\n * with linux 2.0, and to avoid hard-linking to directories\n * and other special files.  --ADM\n */\nSYSCALL_DEFINE5(linkat, int, olddfd, const char __user *, oldname,\n\t\tint, newdfd, const char __user *, newname, int, flags)\n{\n\tstruct dentry *new_dentry;\n\tstruct path old_path, new_path;\n\tstruct inode *delegated_inode = NULL;\n\tint how = 0;\n\tint error;\n\n\tif ((flags & ~(AT_SYMLINK_FOLLOW | AT_EMPTY_PATH)) != 0)\n\t\treturn -EINVAL;\n\t/*\n\t * To use null names we require CAP_DAC_READ_SEARCH\n\t * This ensures that not everyone will be able to create\n\t * handlink using the passed filedescriptor.\n\t */\n\tif (flags & AT_EMPTY_PATH) {\n\t\tif (!capable(CAP_DAC_READ_SEARCH))\n\t\t\treturn -ENOENT;\n\t\thow = LOOKUP_EMPTY;\n\t}\n\n\tif (flags & AT_SYMLINK_FOLLOW)\n\t\thow |= LOOKUP_FOLLOW;\nretry:\n\terror = user_path_at(olddfd, oldname, how, &old_path);\n\tif (error)\n\t\treturn error;\n\n\tnew_dentry = user_path_create(newdfd, newname, &new_path,\n\t\t\t\t\t(how & LOOKUP_REVAL));\n\terror = PTR_ERR(new_dentry);\n\tif (IS_ERR(new_dentry))\n\t\tgoto out;\n\n\terror = -EXDEV;\n\tif (old_path.mnt != new_path.mnt)\n\t\tgoto out_dput;\n\terror = may_linkat(&old_path);\n\tif (unlikely(error))\n\t\tgoto out_dput;\n\terror = security_path_link(old_path.dentry, &new_path, new_dentry);\n\tif (error)\n\t\tgoto out_dput;\n\terror = vfs_link(old_path.dentry, new_path.dentry->d_inode, new_dentry, &delegated_inode);\nout_dput:\n\tdone_path_create(&new_path, new_dentry);\n\tif (delegated_inode) {\n\t\terror = break_deleg_wait(&delegated_inode);\n\t\tif (!error) {\n\t\t\tpath_put(&old_path);\n\t\t\tgoto retry;\n\t\t}\n\t}\n\tif (retry_estale(error, how)) {\n\t\tpath_put(&old_path);\n\t\thow |= LOOKUP_REVAL;\n\t\tgoto retry;\n\t}\nout:\n\tpath_put(&old_path);\n\n\treturn error;\n}\n\nSYSCALL_DEFINE2(link, const char __user *, oldname, const char __user *, newname)\n{\n\treturn sys_linkat(AT_FDCWD, oldname, AT_FDCWD, newname, 0);\n}\n\n/**\n * vfs_rename - rename a filesystem object\n * @old_dir:\tparent of source\n * @old_dentry:\tsource\n * @new_dir:\tparent of destination\n * @new_dentry:\tdestination\n * @delegated_inode: returns an inode needing a delegation break\n * @flags:\trename flags\n *\n * The caller must hold multiple mutexes--see lock_rename()).\n *\n * If vfs_rename discovers a delegation in need of breaking at either\n * the source or destination, it will return -EWOULDBLOCK and return a\n * reference to the inode in delegated_inode.  The caller should then\n * break the delegation and retry.  Because breaking a delegation may\n * take a long time, the caller should drop all locks before doing\n * so.\n *\n * Alternatively, a caller may pass NULL for delegated_inode.  This may\n * be appropriate for callers that expect the underlying filesystem not\n * to be NFS exported.\n *\n * The worst of all namespace operations - renaming directory. \"Perverted\"\n * doesn't even start to describe it. Somebody in UCB had a heck of a trip...\n * Problems:\n *\ta) we can get into loop creation.\n *\tb) race potential - two innocent renames can create a loop together.\n *\t   That's where 4.4 screws up. Current fix: serialization on\n *\t   sb->s_vfs_rename_mutex. We might be more accurate, but that's another\n *\t   story.\n *\tc) we have to lock _four_ objects - parents and victim (if it exists),\n *\t   and source (if it is not a directory).\n *\t   And that - after we got ->i_mutex on parents (until then we don't know\n *\t   whether the target exists).  Solution: try to be smart with locking\n *\t   order for inodes.  We rely on the fact that tree topology may change\n *\t   only under ->s_vfs_rename_mutex _and_ that parent of the object we\n *\t   move will be locked.  Thus we can rank directories by the tree\n *\t   (ancestors first) and rank all non-directories after them.\n *\t   That works since everybody except rename does \"lock parent, lookup,\n *\t   lock child\" and rename is under ->s_vfs_rename_mutex.\n *\t   HOWEVER, it relies on the assumption that any object with ->lookup()\n *\t   has no more than 1 dentry.  If \"hybrid\" objects will ever appear,\n *\t   we'd better make sure that there's no link(2) for them.\n *\td) conversion from fhandle to dentry may come in the wrong moment - when\n *\t   we are removing the target. Solution: we will have to grab ->i_mutex\n *\t   in the fhandle_to_dentry code. [FIXME - current nfsfh.c relies on\n *\t   ->i_mutex on parents, which works but leads to some truly excessive\n *\t   locking].\n */\nint vfs_rename(struct inode *old_dir, struct dentry *old_dentry,\n\t       struct inode *new_dir, struct dentry *new_dentry,\n\t       struct inode **delegated_inode, unsigned int flags)\n{\n\tint error;\n\tbool is_dir = d_is_dir(old_dentry);\n\tconst unsigned char *old_name;\n\tstruct inode *source = old_dentry->d_inode;\n\tstruct inode *target = new_dentry->d_inode;\n\tbool new_is_dir = false;\n\tunsigned max_links = new_dir->i_sb->s_max_links;\n\n\tif (source == target)\n\t\treturn 0;\n\n\terror = may_delete(old_dir, old_dentry, is_dir);\n\tif (error)\n\t\treturn error;\n\n\tif (!target) {\n\t\terror = may_create(new_dir, new_dentry);\n\t} else {\n\t\tnew_is_dir = d_is_dir(new_dentry);\n\n\t\tif (!(flags & RENAME_EXCHANGE))\n\t\t\terror = may_delete(new_dir, new_dentry, is_dir);\n\t\telse\n\t\t\terror = may_delete(new_dir, new_dentry, new_is_dir);\n\t}\n\tif (error)\n\t\treturn error;\n\n\tif (!old_dir->i_op->rename)\n\t\treturn -EPERM;\n\n\t/*\n\t * If we are going to change the parent - check write permissions,\n\t * we'll need to flip '..'.\n\t */\n\tif (new_dir != old_dir) {\n\t\tif (is_dir) {\n\t\t\terror = inode_permission(source, MAY_WRITE);\n\t\t\tif (error)\n\t\t\t\treturn error;\n\t\t}\n\t\tif ((flags & RENAME_EXCHANGE) && new_is_dir) {\n\t\t\terror = inode_permission(target, MAY_WRITE);\n\t\t\tif (error)\n\t\t\t\treturn error;\n\t\t}\n\t}\n\n\terror = security_inode_rename(old_dir, old_dentry, new_dir, new_dentry,\n\t\t\t\t      flags);\n\tif (error)\n\t\treturn error;\n\n\told_name = fsnotify_oldname_init(old_dentry->d_name.name);\n\tdget(new_dentry);\n\tif (!is_dir || (flags & RENAME_EXCHANGE))\n\t\tlock_two_nondirectories(source, target);\n\telse if (target)\n\t\tinode_lock(target);\n\n\terror = -EBUSY;\n\tif (is_local_mountpoint(old_dentry) || is_local_mountpoint(new_dentry))\n\t\tgoto out;\n\n\tif (max_links && new_dir != old_dir) {\n\t\terror = -EMLINK;\n\t\tif (is_dir && !new_is_dir && new_dir->i_nlink >= max_links)\n\t\t\tgoto out;\n\t\tif ((flags & RENAME_EXCHANGE) && !is_dir && new_is_dir &&\n\t\t    old_dir->i_nlink >= max_links)\n\t\t\tgoto out;\n\t}\n\tif (is_dir && !(flags & RENAME_EXCHANGE) && target)\n\t\tshrink_dcache_parent(new_dentry);\n\tif (!is_dir) {\n\t\terror = try_break_deleg(source, delegated_inode);\n\t\tif (error)\n\t\t\tgoto out;\n\t}\n\tif (target && !new_is_dir) {\n\t\terror = try_break_deleg(target, delegated_inode);\n\t\tif (error)\n\t\t\tgoto out;\n\t}\n\terror = old_dir->i_op->rename(old_dir, old_dentry,\n\t\t\t\t       new_dir, new_dentry, flags);\n\tif (error)\n\t\tgoto out;\n\n\tif (!(flags & RENAME_EXCHANGE) && target) {\n\t\tif (is_dir)\n\t\t\ttarget->i_flags |= S_DEAD;\n\t\tdont_mount(new_dentry);\n\t\tdetach_mounts(new_dentry);\n\t}\n\tif (!(old_dir->i_sb->s_type->fs_flags & FS_RENAME_DOES_D_MOVE)) {\n\t\tif (!(flags & RENAME_EXCHANGE))\n\t\t\td_move(old_dentry, new_dentry);\n\t\telse\n\t\t\td_exchange(old_dentry, new_dentry);\n\t}\nout:\n\tif (!is_dir || (flags & RENAME_EXCHANGE))\n\t\tunlock_two_nondirectories(source, target);\n\telse if (target)\n\t\tinode_unlock(target);\n\tdput(new_dentry);\n\tif (!error) {\n\t\tfsnotify_move(old_dir, new_dir, old_name, is_dir,\n\t\t\t      !(flags & RENAME_EXCHANGE) ? target : NULL, old_dentry);\n\t\tif (flags & RENAME_EXCHANGE) {\n\t\t\tfsnotify_move(new_dir, old_dir, old_dentry->d_name.name,\n\t\t\t\t      new_is_dir, NULL, new_dentry);\n\t\t}\n\t}\n\tfsnotify_oldname_free(old_name);\n\n\treturn error;\n}\nEXPORT_SYMBOL(vfs_rename);\n\nSYSCALL_DEFINE5(renameat2, int, olddfd, const char __user *, oldname,\n\t\tint, newdfd, const char __user *, newname, unsigned int, flags)\n{\n\tstruct dentry *old_dentry, *new_dentry;\n\tstruct dentry *trap;\n\tstruct path old_path, new_path;\n\tstruct qstr old_last, new_last;\n\tint old_type, new_type;\n\tstruct inode *delegated_inode = NULL;\n\tstruct filename *from;\n\tstruct filename *to;\n\tunsigned int lookup_flags = 0, target_flags = LOOKUP_RENAME_TARGET;\n\tbool should_retry = false;\n\tint error;\n\n\tif (flags & ~(RENAME_NOREPLACE | RENAME_EXCHANGE | RENAME_WHITEOUT))\n\t\treturn -EINVAL;\n\n\tif ((flags & (RENAME_NOREPLACE | RENAME_WHITEOUT)) &&\n\t    (flags & RENAME_EXCHANGE))\n\t\treturn -EINVAL;\n\n\tif ((flags & RENAME_WHITEOUT) && !capable(CAP_MKNOD))\n\t\treturn -EPERM;\n\n\tif (flags & RENAME_EXCHANGE)\n\t\ttarget_flags = 0;\n\nretry:\n\tfrom = filename_parentat(olddfd, getname(oldname), lookup_flags,\n\t\t\t\t&old_path, &old_last, &old_type);\n\tif (IS_ERR(from)) {\n\t\terror = PTR_ERR(from);\n\t\tgoto exit;\n\t}\n\n\tto = filename_parentat(newdfd, getname(newname), lookup_flags,\n\t\t\t\t&new_path, &new_last, &new_type);\n\tif (IS_ERR(to)) {\n\t\terror = PTR_ERR(to);\n\t\tgoto exit1;\n\t}\n\n\terror = -EXDEV;\n\tif (old_path.mnt != new_path.mnt)\n\t\tgoto exit2;\n\n\terror = -EBUSY;\n\tif (old_type != LAST_NORM)\n\t\tgoto exit2;\n\n\tif (flags & RENAME_NOREPLACE)\n\t\terror = -EEXIST;\n\tif (new_type != LAST_NORM)\n\t\tgoto exit2;\n\n\terror = mnt_want_write(old_path.mnt);\n\tif (error)\n\t\tgoto exit2;\n\nretry_deleg:\n\ttrap = lock_rename(new_path.dentry, old_path.dentry);\n\n\told_dentry = __lookup_hash(&old_last, old_path.dentry, lookup_flags);\n\terror = PTR_ERR(old_dentry);\n\tif (IS_ERR(old_dentry))\n\t\tgoto exit3;\n\t/* source must exist */\n\terror = -ENOENT;\n\tif (d_is_negative(old_dentry))\n\t\tgoto exit4;\n\tnew_dentry = __lookup_hash(&new_last, new_path.dentry, lookup_flags | target_flags);\n\terror = PTR_ERR(new_dentry);\n\tif (IS_ERR(new_dentry))\n\t\tgoto exit4;\n\terror = -EEXIST;\n\tif ((flags & RENAME_NOREPLACE) && d_is_positive(new_dentry))\n\t\tgoto exit5;\n\tif (flags & RENAME_EXCHANGE) {\n\t\terror = -ENOENT;\n\t\tif (d_is_negative(new_dentry))\n\t\t\tgoto exit5;\n\n\t\tif (!d_is_dir(new_dentry)) {\n\t\t\terror = -ENOTDIR;\n\t\t\tif (new_last.name[new_last.len])\n\t\t\t\tgoto exit5;\n\t\t}\n\t}\n\t/* unless the source is a directory trailing slashes give -ENOTDIR */\n\tif (!d_is_dir(old_dentry)) {\n\t\terror = -ENOTDIR;\n\t\tif (old_last.name[old_last.len])\n\t\t\tgoto exit5;\n\t\tif (!(flags & RENAME_EXCHANGE) && new_last.name[new_last.len])\n\t\t\tgoto exit5;\n\t}\n\t/* source should not be ancestor of target */\n\terror = -EINVAL;\n\tif (old_dentry == trap)\n\t\tgoto exit5;\n\t/* target should not be an ancestor of source */\n\tif (!(flags & RENAME_EXCHANGE))\n\t\terror = -ENOTEMPTY;\n\tif (new_dentry == trap)\n\t\tgoto exit5;\n\n\terror = security_path_rename(&old_path, old_dentry,\n\t\t\t\t     &new_path, new_dentry, flags);\n\tif (error)\n\t\tgoto exit5;\n\terror = vfs_rename(old_path.dentry->d_inode, old_dentry,\n\t\t\t   new_path.dentry->d_inode, new_dentry,\n\t\t\t   &delegated_inode, flags);\nexit5:\n\tdput(new_dentry);\nexit4:\n\tdput(old_dentry);\nexit3:\n\tunlock_rename(new_path.dentry, old_path.dentry);\n\tif (delegated_inode) {\n\t\terror = break_deleg_wait(&delegated_inode);\n\t\tif (!error)\n\t\t\tgoto retry_deleg;\n\t}\n\tmnt_drop_write(old_path.mnt);\nexit2:\n\tif (retry_estale(error, lookup_flags))\n\t\tshould_retry = true;\n\tpath_put(&new_path);\n\tputname(to);\nexit1:\n\tpath_put(&old_path);\n\tputname(from);\n\tif (should_retry) {\n\t\tshould_retry = false;\n\t\tlookup_flags |= LOOKUP_REVAL;\n\t\tgoto retry;\n\t}\nexit:\n\treturn error;\n}\n\nSYSCALL_DEFINE4(renameat, int, olddfd, const char __user *, oldname,\n\t\tint, newdfd, const char __user *, newname)\n{\n\treturn sys_renameat2(olddfd, oldname, newdfd, newname, 0);\n}\n\nSYSCALL_DEFINE2(rename, const char __user *, oldname, const char __user *, newname)\n{\n\treturn sys_renameat2(AT_FDCWD, oldname, AT_FDCWD, newname, 0);\n}\n\nint vfs_whiteout(struct inode *dir, struct dentry *dentry)\n{\n\tint error = may_create(dir, dentry);\n\tif (error)\n\t\treturn error;\n\n\tif (!dir->i_op->mknod)\n\t\treturn -EPERM;\n\n\treturn dir->i_op->mknod(dir, dentry,\n\t\t\t\tS_IFCHR | WHITEOUT_MODE, WHITEOUT_DEV);\n}\nEXPORT_SYMBOL(vfs_whiteout);\n\nint readlink_copy(char __user *buffer, int buflen, const char *link)\n{\n\tint len = PTR_ERR(link);\n\tif (IS_ERR(link))\n\t\tgoto out;\n\n\tlen = strlen(link);\n\tif (len > (unsigned) buflen)\n\t\tlen = buflen;\n\tif (copy_to_user(buffer, link, len))\n\t\tlen = -EFAULT;\nout:\n\treturn len;\n}\n\n/*\n * A helper for ->readlink().  This should be used *ONLY* for symlinks that\n * have ->get_link() not calling nd_jump_link().  Using (or not using) it\n * for any given inode is up to filesystem.\n */\nstatic int generic_readlink(struct dentry *dentry, char __user *buffer,\n\t\t\t    int buflen)\n{\n\tDEFINE_DELAYED_CALL(done);\n\tstruct inode *inode = d_inode(dentry);\n\tconst char *link = inode->i_link;\n\tint res;\n\n\tif (!link) {\n\t\tlink = inode->i_op->get_link(dentry, inode, &done);\n\t\tif (IS_ERR(link))\n\t\t\treturn PTR_ERR(link);\n\t}\n\tres = readlink_copy(buffer, buflen, link);\n\tdo_delayed_call(&done);\n\treturn res;\n}\n\n/**\n * vfs_readlink - copy symlink body into userspace buffer\n * @dentry: dentry on which to get symbolic link\n * @buffer: user memory pointer\n * @buflen: size of buffer\n *\n * Does not touch atime.  That's up to the caller if necessary\n *\n * Does not call security hook.\n */\nint vfs_readlink(struct dentry *dentry, char __user *buffer, int buflen)\n{\n\tstruct inode *inode = d_inode(dentry);\n\n\tif (unlikely(!(inode->i_opflags & IOP_DEFAULT_READLINK))) {\n\t\tif (unlikely(inode->i_op->readlink))\n\t\t\treturn inode->i_op->readlink(dentry, buffer, buflen);\n\n\t\tif (!d_is_symlink(dentry))\n\t\t\treturn -EINVAL;\n\n\t\tspin_lock(&inode->i_lock);\n\t\tinode->i_opflags |= IOP_DEFAULT_READLINK;\n\t\tspin_unlock(&inode->i_lock);\n\t}\n\n\treturn generic_readlink(dentry, buffer, buflen);\n}\nEXPORT_SYMBOL(vfs_readlink);\n\n/**\n * vfs_get_link - get symlink body\n * @dentry: dentry on which to get symbolic link\n * @done: caller needs to free returned data with this\n *\n * Calls security hook and i_op->get_link() on the supplied inode.\n *\n * It does not touch atime.  That's up to the caller if necessary.\n *\n * Does not work on \"special\" symlinks like /proc/$$/fd/N\n */\nconst char *vfs_get_link(struct dentry *dentry, struct delayed_call *done)\n{\n\tconst char *res = ERR_PTR(-EINVAL);\n\tstruct inode *inode = d_inode(dentry);\n\n\tif (d_is_symlink(dentry)) {\n\t\tres = ERR_PTR(security_inode_readlink(dentry));\n\t\tif (!res)\n\t\t\tres = inode->i_op->get_link(dentry, inode, done);\n\t}\n\treturn res;\n}\nEXPORT_SYMBOL(vfs_get_link);\n\n/* get the link contents into pagecache */\nconst char *page_get_link(struct dentry *dentry, struct inode *inode,\n\t\t\t  struct delayed_call *callback)\n{\n\tchar *kaddr;\n\tstruct page *page;\n\tstruct address_space *mapping = inode->i_mapping;\n\n\tif (!dentry) {\n\t\tpage = find_get_page(mapping, 0);\n\t\tif (!page)\n\t\t\treturn ERR_PTR(-ECHILD);\n\t\tif (!PageUptodate(page)) {\n\t\t\tput_page(page);\n\t\t\treturn ERR_PTR(-ECHILD);\n\t\t}\n\t} else {\n\t\tpage = read_mapping_page(mapping, 0, NULL);\n\t\tif (IS_ERR(page))\n\t\t\treturn (char*)page;\n\t}\n\tset_delayed_call(callback, page_put_link, page);\n\tBUG_ON(mapping_gfp_mask(mapping) & __GFP_HIGHMEM);\n\tkaddr = page_address(page);\n\tnd_terminate_link(kaddr, inode->i_size, PAGE_SIZE - 1);\n\treturn kaddr;\n}\n\nEXPORT_SYMBOL(page_get_link);\n\nvoid page_put_link(void *arg)\n{\n\tput_page(arg);\n}\nEXPORT_SYMBOL(page_put_link);\n\nint page_readlink(struct dentry *dentry, char __user *buffer, int buflen)\n{\n\tDEFINE_DELAYED_CALL(done);\n\tint res = readlink_copy(buffer, buflen,\n\t\t\t\tpage_get_link(dentry, d_inode(dentry),\n\t\t\t\t\t      &done));\n\tdo_delayed_call(&done);\n\treturn res;\n}\nEXPORT_SYMBOL(page_readlink);\n\n/*\n * The nofs argument instructs pagecache_write_begin to pass AOP_FLAG_NOFS\n */\nint __page_symlink(struct inode *inode, const char *symname, int len, int nofs)\n{\n\tstruct address_space *mapping = inode->i_mapping;\n\tstruct page *page;\n\tvoid *fsdata;\n\tint err;\n\tunsigned int flags = 0;\n\tif (nofs)\n\t\tflags |= AOP_FLAG_NOFS;\n\nretry:\n\terr = pagecache_write_begin(NULL, mapping, 0, len-1,\n\t\t\t\tflags, &page, &fsdata);\n\tif (err)\n\t\tgoto fail;\n\n\tmemcpy(page_address(page), symname, len-1);\n\n\terr = pagecache_write_end(NULL, mapping, 0, len-1, len-1,\n\t\t\t\t\t\t\tpage, fsdata);\n\tif (err < 0)\n\t\tgoto fail;\n\tif (err < len-1)\n\t\tgoto retry;\n\n\tmark_inode_dirty(inode);\n\treturn 0;\nfail:\n\treturn err;\n}\nEXPORT_SYMBOL(__page_symlink);\n\nint page_symlink(struct inode *inode, const char *symname, int len)\n{\n\treturn __page_symlink(inode, symname, len,\n\t\t\t!mapping_gfp_constraint(inode->i_mapping, __GFP_FS));\n}\nEXPORT_SYMBOL(page_symlink);\n\nconst struct inode_operations page_symlink_inode_operations = {\n\t.get_link\t= page_get_link,\n};\nEXPORT_SYMBOL(page_symlink_inode_operations);\n", "/*\n *  Copyright (C) 2008 Red Hat, Inc., Eric Paris <eparis@redhat.com>\n *\n *  This program is free software; you can redistribute it and/or modify\n *  it under the terms of the GNU General Public License as published by\n *  the Free Software Foundation; either version 2, or (at your option)\n *  any later version.\n *\n *  This program is distributed in the hope that it will be useful,\n *  but WITHOUT ANY WARRANTY; without even the implied warranty of\n *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n *  GNU General Public License for more details.\n *\n *  You should have received a copy of the GNU General Public License\n *  along with this program; see the file COPYING.  If not, write to\n *  the Free Software Foundation, 675 Mass Ave, Cambridge, MA 02139, USA.\n */\n\n#include <linux/dcache.h>\n#include <linux/fs.h>\n#include <linux/gfp.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mount.h>\n#include <linux/srcu.h>\n\n#include <linux/fsnotify_backend.h>\n#include \"fsnotify.h\"\n\n/*\n * Clear all of the marks on an inode when it is being evicted from core\n */\nvoid __fsnotify_inode_delete(struct inode *inode)\n{\n\tfsnotify_clear_marks_by_inode(inode);\n}\nEXPORT_SYMBOL_GPL(__fsnotify_inode_delete);\n\nvoid __fsnotify_vfsmount_delete(struct vfsmount *mnt)\n{\n\tfsnotify_clear_marks_by_mount(mnt);\n}\n\n/**\n * fsnotify_unmount_inodes - an sb is unmounting.  handle any watched inodes.\n * @sb: superblock being unmounted.\n *\n * Called during unmount with no locks held, so needs to be safe against\n * concurrent modifiers. We temporarily drop sb->s_inode_list_lock and CAN block.\n */\nvoid fsnotify_unmount_inodes(struct super_block *sb)\n{\n\tstruct inode *inode, *iput_inode = NULL;\n\n\tspin_lock(&sb->s_inode_list_lock);\n\tlist_for_each_entry(inode, &sb->s_inodes, i_sb_list) {\n\t\t/*\n\t\t * We cannot __iget() an inode in state I_FREEING,\n\t\t * I_WILL_FREE, or I_NEW which is fine because by that point\n\t\t * the inode cannot have any associated watches.\n\t\t */\n\t\tspin_lock(&inode->i_lock);\n\t\tif (inode->i_state & (I_FREEING|I_WILL_FREE|I_NEW)) {\n\t\t\tspin_unlock(&inode->i_lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/*\n\t\t * If i_count is zero, the inode cannot have any watches and\n\t\t * doing an __iget/iput with MS_ACTIVE clear would actually\n\t\t * evict all inodes with zero i_count from icache which is\n\t\t * unnecessarily violent and may in fact be illegal to do.\n\t\t */\n\t\tif (!atomic_read(&inode->i_count)) {\n\t\t\tspin_unlock(&inode->i_lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\t__iget(inode);\n\t\tspin_unlock(&inode->i_lock);\n\t\tspin_unlock(&sb->s_inode_list_lock);\n\n\t\tif (iput_inode)\n\t\t\tiput(iput_inode);\n\n\t\t/* for each watch, send FS_UNMOUNT and then remove it */\n\t\tfsnotify(inode, FS_UNMOUNT, inode, FSNOTIFY_EVENT_INODE, NULL, 0);\n\n\t\tfsnotify_inode_delete(inode);\n\n\t\tiput_inode = inode;\n\n\t\tspin_lock(&sb->s_inode_list_lock);\n\t}\n\tspin_unlock(&sb->s_inode_list_lock);\n\n\tif (iput_inode)\n\t\tiput(iput_inode);\n}\n\n/*\n * Given an inode, first check if we care what happens to our children.  Inotify\n * and dnotify both tell their parents about events.  If we care about any event\n * on a child we run all of our children and set a dentry flag saying that the\n * parent cares.  Thus when an event happens on a child it can quickly tell if\n * if there is a need to find a parent and send the event to the parent.\n */\nvoid __fsnotify_update_child_dentry_flags(struct inode *inode)\n{\n\tstruct dentry *alias;\n\tint watched;\n\n\tif (!S_ISDIR(inode->i_mode))\n\t\treturn;\n\n\t/* determine if the children should tell inode about their events */\n\twatched = fsnotify_inode_watches_children(inode);\n\n\tspin_lock(&inode->i_lock);\n\t/* run all of the dentries associated with this inode.  Since this is a\n\t * directory, there damn well better only be one item on this list */\n\thlist_for_each_entry(alias, &inode->i_dentry, d_u.d_alias) {\n\t\tstruct dentry *child;\n\n\t\t/* run all of the children of the original inode and fix their\n\t\t * d_flags to indicate parental interest (their parent is the\n\t\t * original inode) */\n\t\tspin_lock(&alias->d_lock);\n\t\tlist_for_each_entry(child, &alias->d_subdirs, d_child) {\n\t\t\tif (!child->d_inode)\n\t\t\t\tcontinue;\n\n\t\t\tspin_lock_nested(&child->d_lock, DENTRY_D_LOCK_NESTED);\n\t\t\tif (watched)\n\t\t\t\tchild->d_flags |= DCACHE_FSNOTIFY_PARENT_WATCHED;\n\t\t\telse\n\t\t\t\tchild->d_flags &= ~DCACHE_FSNOTIFY_PARENT_WATCHED;\n\t\t\tspin_unlock(&child->d_lock);\n\t\t}\n\t\tspin_unlock(&alias->d_lock);\n\t}\n\tspin_unlock(&inode->i_lock);\n}\n\n/* Notify this dentry's parent about a child's events. */\nint __fsnotify_parent(const struct path *path, struct dentry *dentry, __u32 mask)\n{\n\tstruct dentry *parent;\n\tstruct inode *p_inode;\n\tint ret = 0;\n\n\tif (!dentry)\n\t\tdentry = path->dentry;\n\n\tif (!(dentry->d_flags & DCACHE_FSNOTIFY_PARENT_WATCHED))\n\t\treturn 0;\n\n\tparent = dget_parent(dentry);\n\tp_inode = parent->d_inode;\n\n\tif (unlikely(!fsnotify_inode_watches_children(p_inode)))\n\t\t__fsnotify_update_child_dentry_flags(p_inode);\n\telse if (p_inode->i_fsnotify_mask & mask) {\n\t\t/* we are notifying a parent so come up with the new mask which\n\t\t * specifies these are events which came from a child. */\n\t\tmask |= FS_EVENT_ON_CHILD;\n\n\t\tif (path)\n\t\t\tret = fsnotify(p_inode, mask, path, FSNOTIFY_EVENT_PATH,\n\t\t\t\t       dentry->d_name.name, 0);\n\t\telse\n\t\t\tret = fsnotify(p_inode, mask, dentry->d_inode, FSNOTIFY_EVENT_INODE,\n\t\t\t\t       dentry->d_name.name, 0);\n\t}\n\n\tdput(parent);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(__fsnotify_parent);\n\nstatic int send_to_group(struct inode *to_tell,\n\t\t\t struct fsnotify_mark *inode_mark,\n\t\t\t struct fsnotify_mark *vfsmount_mark,\n\t\t\t __u32 mask, const void *data,\n\t\t\t int data_is, u32 cookie,\n\t\t\t const unsigned char *file_name,\n\t\t\t struct fsnotify_iter_info *iter_info)\n{\n\tstruct fsnotify_group *group = NULL;\n\t__u32 inode_test_mask = 0;\n\t__u32 vfsmount_test_mask = 0;\n\n\tif (unlikely(!inode_mark && !vfsmount_mark)) {\n\t\tBUG();\n\t\treturn 0;\n\t}\n\n\t/* clear ignored on inode modification */\n\tif (mask & FS_MODIFY) {\n\t\tif (inode_mark &&\n\t\t    !(inode_mark->flags & FSNOTIFY_MARK_FLAG_IGNORED_SURV_MODIFY))\n\t\t\tinode_mark->ignored_mask = 0;\n\t\tif (vfsmount_mark &&\n\t\t    !(vfsmount_mark->flags & FSNOTIFY_MARK_FLAG_IGNORED_SURV_MODIFY))\n\t\t\tvfsmount_mark->ignored_mask = 0;\n\t}\n\n\t/* does the inode mark tell us to do something? */\n\tif (inode_mark) {\n\t\tgroup = inode_mark->group;\n\t\tinode_test_mask = (mask & ~FS_EVENT_ON_CHILD);\n\t\tinode_test_mask &= inode_mark->mask;\n\t\tinode_test_mask &= ~inode_mark->ignored_mask;\n\t}\n\n\t/* does the vfsmount_mark tell us to do something? */\n\tif (vfsmount_mark) {\n\t\tvfsmount_test_mask = (mask & ~FS_EVENT_ON_CHILD);\n\t\tgroup = vfsmount_mark->group;\n\t\tvfsmount_test_mask &= vfsmount_mark->mask;\n\t\tvfsmount_test_mask &= ~vfsmount_mark->ignored_mask;\n\t\tif (inode_mark)\n\t\t\tvfsmount_test_mask &= ~inode_mark->ignored_mask;\n\t}\n\n\tpr_debug(\"%s: group=%p to_tell=%p mask=%x inode_mark=%p\"\n\t\t \" inode_test_mask=%x vfsmount_mark=%p vfsmount_test_mask=%x\"\n\t\t \" data=%p data_is=%d cookie=%d\\n\",\n\t\t __func__, group, to_tell, mask, inode_mark,\n\t\t inode_test_mask, vfsmount_mark, vfsmount_test_mask, data,\n\t\t data_is, cookie);\n\n\tif (!inode_test_mask && !vfsmount_test_mask)\n\t\treturn 0;\n\n\treturn group->ops->handle_event(group, to_tell, inode_mark,\n\t\t\t\t\tvfsmount_mark, mask, data, data_is,\n\t\t\t\t\tfile_name, cookie, iter_info);\n}\n\n/*\n * This is the main call to fsnotify.  The VFS calls into hook specific functions\n * in linux/fsnotify.h.  Those functions then in turn call here.  Here will call\n * out to all of the registered fsnotify_group.  Those groups can then use the\n * notification event in whatever means they feel necessary.\n */\nint fsnotify(struct inode *to_tell, __u32 mask, const void *data, int data_is,\n\t     const unsigned char *file_name, u32 cookie)\n{\n\tstruct hlist_node *inode_node = NULL, *vfsmount_node = NULL;\n\tstruct fsnotify_mark *inode_mark = NULL, *vfsmount_mark = NULL;\n\tstruct fsnotify_group *inode_group, *vfsmount_group;\n\tstruct fsnotify_mark_connector *inode_conn, *vfsmount_conn;\n\tstruct fsnotify_iter_info iter_info;\n\tstruct mount *mnt;\n\tint ret = 0;\n\t/* global tests shouldn't care about events on child only the specific event */\n\t__u32 test_mask = (mask & ~FS_EVENT_ON_CHILD);\n\n\tif (data_is == FSNOTIFY_EVENT_PATH)\n\t\tmnt = real_mount(((const struct path *)data)->mnt);\n\telse\n\t\tmnt = NULL;\n\n\t/*\n\t * Optimization: srcu_read_lock() has a memory barrier which can\n\t * be expensive.  It protects walking the *_fsnotify_marks lists.\n\t * However, if we do not walk the lists, we do not have to do\n\t * SRCU because we have no references to any objects and do not\n\t * need SRCU to keep them \"alive\".\n\t */\n\tif (!to_tell->i_fsnotify_marks &&\n\t    (!mnt || !mnt->mnt_fsnotify_marks))\n\t\treturn 0;\n\t/*\n\t * if this is a modify event we may need to clear the ignored masks\n\t * otherwise return if neither the inode nor the vfsmount care about\n\t * this type of event.\n\t */\n\tif (!(mask & FS_MODIFY) &&\n\t    !(test_mask & to_tell->i_fsnotify_mask) &&\n\t    !(mnt && test_mask & mnt->mnt_fsnotify_mask))\n\t\treturn 0;\n\n\titer_info.srcu_idx = srcu_read_lock(&fsnotify_mark_srcu);\n\n\tif ((mask & FS_MODIFY) ||\n\t    (test_mask & to_tell->i_fsnotify_mask)) {\n\t\tinode_conn = srcu_dereference(to_tell->i_fsnotify_marks,\n\t\t\t\t\t      &fsnotify_mark_srcu);\n\t\tif (inode_conn)\n\t\t\tinode_node = srcu_dereference(inode_conn->list.first,\n\t\t\t\t\t\t      &fsnotify_mark_srcu);\n\t}\n\n\tif (mnt && ((mask & FS_MODIFY) ||\n\t\t    (test_mask & mnt->mnt_fsnotify_mask))) {\n\t\tinode_conn = srcu_dereference(to_tell->i_fsnotify_marks,\n\t\t\t\t\t      &fsnotify_mark_srcu);\n\t\tif (inode_conn)\n\t\t\tinode_node = srcu_dereference(inode_conn->list.first,\n\t\t\t\t\t\t      &fsnotify_mark_srcu);\n\t\tvfsmount_conn = srcu_dereference(mnt->mnt_fsnotify_marks,\n\t\t\t\t\t         &fsnotify_mark_srcu);\n\t\tif (vfsmount_conn)\n\t\t\tvfsmount_node = srcu_dereference(\n\t\t\t\t\t\tvfsmount_conn->list.first,\n\t\t\t\t\t\t&fsnotify_mark_srcu);\n\t}\n\n\t/*\n\t * We need to merge inode & vfsmount mark lists so that inode mark\n\t * ignore masks are properly reflected for mount mark notifications.\n\t * That's why this traversal is so complicated...\n\t */\n\twhile (inode_node || vfsmount_node) {\n\t\tinode_group = NULL;\n\t\tinode_mark = NULL;\n\t\tvfsmount_group = NULL;\n\t\tvfsmount_mark = NULL;\n\n\t\tif (inode_node) {\n\t\t\tinode_mark = hlist_entry(srcu_dereference(inode_node, &fsnotify_mark_srcu),\n\t\t\t\t\t\t struct fsnotify_mark, obj_list);\n\t\t\tinode_group = inode_mark->group;\n\t\t}\n\n\t\tif (vfsmount_node) {\n\t\t\tvfsmount_mark = hlist_entry(srcu_dereference(vfsmount_node, &fsnotify_mark_srcu),\n\t\t\t\t\t\t    struct fsnotify_mark, obj_list);\n\t\t\tvfsmount_group = vfsmount_mark->group;\n\t\t}\n\n\t\tif (inode_group && vfsmount_group) {\n\t\t\tint cmp = fsnotify_compare_groups(inode_group,\n\t\t\t\t\t\t\t  vfsmount_group);\n\t\t\tif (cmp > 0) {\n\t\t\t\tinode_group = NULL;\n\t\t\t\tinode_mark = NULL;\n\t\t\t} else if (cmp < 0) {\n\t\t\t\tvfsmount_group = NULL;\n\t\t\t\tvfsmount_mark = NULL;\n\t\t\t}\n\t\t}\n\n\t\titer_info.inode_mark = inode_mark;\n\t\titer_info.vfsmount_mark = vfsmount_mark;\n\n\t\tret = send_to_group(to_tell, inode_mark, vfsmount_mark, mask,\n\t\t\t\t    data, data_is, cookie, file_name,\n\t\t\t\t    &iter_info);\n\n\t\tif (ret && (mask & ALL_FSNOTIFY_PERM_EVENTS))\n\t\t\tgoto out;\n\n\t\tif (inode_group)\n\t\t\tinode_node = srcu_dereference(inode_node->next,\n\t\t\t\t\t\t      &fsnotify_mark_srcu);\n\t\tif (vfsmount_group)\n\t\t\tvfsmount_node = srcu_dereference(vfsmount_node->next,\n\t\t\t\t\t\t\t &fsnotify_mark_srcu);\n\t}\n\tret = 0;\nout:\n\tsrcu_read_unlock(&fsnotify_mark_srcu, iter_info.srcu_idx);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(fsnotify);\n\nextern struct kmem_cache *fsnotify_mark_connector_cachep;\n\nstatic __init int fsnotify_init(void)\n{\n\tint ret;\n\n\tBUG_ON(hweight32(ALL_FSNOTIFY_EVENTS) != 23);\n\n\tret = init_srcu_struct(&fsnotify_mark_srcu);\n\tif (ret)\n\t\tpanic(\"initializing fsnotify_mark_srcu\");\n\n\tfsnotify_mark_connector_cachep = KMEM_CACHE(fsnotify_mark_connector,\n\t\t\t\t\t\t    SLAB_PANIC);\n\n\treturn 0;\n}\ncore_initcall(fsnotify_init);\n", "#ifndef __LINUX_DCACHE_H\n#define __LINUX_DCACHE_H\n\n#include <linux/atomic.h>\n#include <linux/list.h>\n#include <linux/rculist.h>\n#include <linux/rculist_bl.h>\n#include <linux/spinlock.h>\n#include <linux/seqlock.h>\n#include <linux/cache.h>\n#include <linux/rcupdate.h>\n#include <linux/lockref.h>\n#include <linux/stringhash.h>\n#include <linux/wait.h>\n\nstruct path;\nstruct vfsmount;\n\n/*\n * linux/include/linux/dcache.h\n *\n * Dirent cache data structures\n *\n * (C) Copyright 1997 Thomas Schoebel-Theuer,\n * with heavy changes by Linus Torvalds\n */\n\n#define IS_ROOT(x) ((x) == (x)->d_parent)\n\n/* The hash is always the low bits of hash_len */\n#ifdef __LITTLE_ENDIAN\n #define HASH_LEN_DECLARE u32 hash; u32 len\n #define bytemask_from_count(cnt)\t(~(~0ul << (cnt)*8))\n#else\n #define HASH_LEN_DECLARE u32 len; u32 hash\n #define bytemask_from_count(cnt)\t(~(~0ul >> (cnt)*8))\n#endif\n\n/*\n * \"quick string\" -- eases parameter passing, but more importantly\n * saves \"metadata\" about the string (ie length and the hash).\n *\n * hash comes first so it snuggles against d_parent in the\n * dentry.\n */\nstruct qstr {\n\tunion {\n\t\tstruct {\n\t\t\tHASH_LEN_DECLARE;\n\t\t};\n\t\tu64 hash_len;\n\t};\n\tconst unsigned char *name;\n};\n\n#define QSTR_INIT(n,l) { { { .len = l } }, .name = n }\n\nstruct dentry_stat_t {\n\tlong nr_dentry;\n\tlong nr_unused;\n\tlong age_limit;          /* age in seconds */\n\tlong want_pages;         /* pages requested by system */\n\tlong dummy[2];\n};\nextern struct dentry_stat_t dentry_stat;\n\n/*\n * Try to keep struct dentry aligned on 64 byte cachelines (this will\n * give reasonable cacheline footprint with larger lines without the\n * large memory footprint increase).\n */\n#ifdef CONFIG_64BIT\n# define DNAME_INLINE_LEN 32 /* 192 bytes */\n#else\n# ifdef CONFIG_SMP\n#  define DNAME_INLINE_LEN 36 /* 128 bytes */\n# else\n#  define DNAME_INLINE_LEN 40 /* 128 bytes */\n# endif\n#endif\n\n#define d_lock\td_lockref.lock\n\nstruct dentry {\n\t/* RCU lookup touched fields */\n\tunsigned int d_flags;\t\t/* protected by d_lock */\n\tseqcount_t d_seq;\t\t/* per dentry seqlock */\n\tstruct hlist_bl_node d_hash;\t/* lookup hash list */\n\tstruct dentry *d_parent;\t/* parent directory */\n\tstruct qstr d_name;\n\tstruct inode *d_inode;\t\t/* Where the name belongs to - NULL is\n\t\t\t\t\t * negative */\n\tunsigned char d_iname[DNAME_INLINE_LEN];\t/* small names */\n\n\t/* Ref lookup also touches following */\n\tstruct lockref d_lockref;\t/* per-dentry lock and refcount */\n\tconst struct dentry_operations *d_op;\n\tstruct super_block *d_sb;\t/* The root of the dentry tree */\n\tunsigned long d_time;\t\t/* used by d_revalidate */\n\tvoid *d_fsdata;\t\t\t/* fs-specific data */\n\n\tunion {\n\t\tstruct list_head d_lru;\t\t/* LRU list */\n\t\twait_queue_head_t *d_wait;\t/* in-lookup ones only */\n\t};\n\tstruct list_head d_child;\t/* child of parent list */\n\tstruct list_head d_subdirs;\t/* our children */\n\t/*\n\t * d_alias and d_rcu can share memory\n\t */\n\tunion {\n\t\tstruct hlist_node d_alias;\t/* inode alias list */\n\t\tstruct hlist_bl_node d_in_lookup_hash;\t/* only for in-lookup ones */\n\t \tstruct rcu_head d_rcu;\n\t} d_u;\n};\n\n/*\n * dentry->d_lock spinlock nesting subclasses:\n *\n * 0: normal\n * 1: nested\n */\nenum dentry_d_lock_class\n{\n\tDENTRY_D_LOCK_NORMAL, /* implicitly used by plain spin_lock() APIs. */\n\tDENTRY_D_LOCK_NESTED\n};\n\nstruct dentry_operations {\n\tint (*d_revalidate)(struct dentry *, unsigned int);\n\tint (*d_weak_revalidate)(struct dentry *, unsigned int);\n\tint (*d_hash)(const struct dentry *, struct qstr *);\n\tint (*d_compare)(const struct dentry *,\n\t\t\tunsigned int, const char *, const struct qstr *);\n\tint (*d_delete)(const struct dentry *);\n\tint (*d_init)(struct dentry *);\n\tvoid (*d_release)(struct dentry *);\n\tvoid (*d_prune)(struct dentry *);\n\tvoid (*d_iput)(struct dentry *, struct inode *);\n\tchar *(*d_dname)(struct dentry *, char *, int);\n\tstruct vfsmount *(*d_automount)(struct path *);\n\tint (*d_manage)(const struct path *, bool);\n\tstruct dentry *(*d_real)(struct dentry *, const struct inode *,\n\t\t\t\t unsigned int);\n} ____cacheline_aligned;\n\n/*\n * Locking rules for dentry_operations callbacks are to be found in\n * Documentation/filesystems/Locking. Keep it updated!\n *\n * FUrther descriptions are found in Documentation/filesystems/vfs.txt.\n * Keep it updated too!\n */\n\n/* d_flags entries */\n#define DCACHE_OP_HASH\t\t\t0x00000001\n#define DCACHE_OP_COMPARE\t\t0x00000002\n#define DCACHE_OP_REVALIDATE\t\t0x00000004\n#define DCACHE_OP_DELETE\t\t0x00000008\n#define DCACHE_OP_PRUNE\t\t\t0x00000010\n\n#define\tDCACHE_DISCONNECTED\t\t0x00000020\n     /* This dentry is possibly not currently connected to the dcache tree, in\n      * which case its parent will either be itself, or will have this flag as\n      * well.  nfsd will not use a dentry with this bit set, but will first\n      * endeavour to clear the bit either by discovering that it is connected,\n      * or by performing lookup operations.   Any filesystem which supports\n      * nfsd_operations MUST have a lookup function which, if it finds a\n      * directory inode with a DCACHE_DISCONNECTED dentry, will d_move that\n      * dentry into place and return that dentry rather than the passed one,\n      * typically using d_splice_alias. */\n\n#define DCACHE_REFERENCED\t\t0x00000040 /* Recently used, don't discard. */\n#define DCACHE_RCUACCESS\t\t0x00000080 /* Entry has ever been RCU-visible */\n\n#define DCACHE_CANT_MOUNT\t\t0x00000100\n#define DCACHE_GENOCIDE\t\t\t0x00000200\n#define DCACHE_SHRINK_LIST\t\t0x00000400\n\n#define DCACHE_OP_WEAK_REVALIDATE\t0x00000800\n\n#define DCACHE_NFSFS_RENAMED\t\t0x00001000\n     /* this dentry has been \"silly renamed\" and has to be deleted on the last\n      * dput() */\n#define DCACHE_COOKIE\t\t\t0x00002000 /* For use by dcookie subsystem */\n#define DCACHE_FSNOTIFY_PARENT_WATCHED\t0x00004000\n     /* Parent inode is watched by some fsnotify listener */\n\n#define DCACHE_DENTRY_KILLED\t\t0x00008000\n\n#define DCACHE_MOUNTED\t\t\t0x00010000 /* is a mountpoint */\n#define DCACHE_NEED_AUTOMOUNT\t\t0x00020000 /* handle automount on this dir */\n#define DCACHE_MANAGE_TRANSIT\t\t0x00040000 /* manage transit from this dirent */\n#define DCACHE_MANAGED_DENTRY \\\n\t(DCACHE_MOUNTED|DCACHE_NEED_AUTOMOUNT|DCACHE_MANAGE_TRANSIT)\n\n#define DCACHE_LRU_LIST\t\t\t0x00080000\n\n#define DCACHE_ENTRY_TYPE\t\t0x00700000\n#define DCACHE_MISS_TYPE\t\t0x00000000 /* Negative dentry (maybe fallthru to nowhere) */\n#define DCACHE_WHITEOUT_TYPE\t\t0x00100000 /* Whiteout dentry (stop pathwalk) */\n#define DCACHE_DIRECTORY_TYPE\t\t0x00200000 /* Normal directory */\n#define DCACHE_AUTODIR_TYPE\t\t0x00300000 /* Lookupless directory (presumed automount) */\n#define DCACHE_REGULAR_TYPE\t\t0x00400000 /* Regular file type (or fallthru to such) */\n#define DCACHE_SPECIAL_TYPE\t\t0x00500000 /* Other file type (or fallthru to such) */\n#define DCACHE_SYMLINK_TYPE\t\t0x00600000 /* Symlink (or fallthru to such) */\n\n#define DCACHE_MAY_FREE\t\t\t0x00800000\n#define DCACHE_FALLTHRU\t\t\t0x01000000 /* Fall through to lower layer */\n#define DCACHE_ENCRYPTED_WITH_KEY\t0x02000000 /* dir is encrypted with a valid key */\n#define DCACHE_OP_REAL\t\t\t0x04000000\n\n#define DCACHE_PAR_LOOKUP\t\t0x10000000 /* being looked up (with parent locked shared) */\n#define DCACHE_DENTRY_CURSOR\t\t0x20000000\n\nextern seqlock_t rename_lock;\n\n/*\n * These are the low-level FS interfaces to the dcache..\n */\nextern void d_instantiate(struct dentry *, struct inode *);\nextern struct dentry * d_instantiate_unique(struct dentry *, struct inode *);\nextern int d_instantiate_no_diralias(struct dentry *, struct inode *);\nextern void __d_drop(struct dentry *dentry);\nextern void d_drop(struct dentry *dentry);\nextern void d_delete(struct dentry *);\nextern void d_set_d_op(struct dentry *dentry, const struct dentry_operations *op);\n\n/* allocate/de-allocate */\nextern struct dentry * d_alloc(struct dentry *, const struct qstr *);\nextern struct dentry * d_alloc_pseudo(struct super_block *, const struct qstr *);\nextern struct dentry * d_alloc_parallel(struct dentry *, const struct qstr *,\n\t\t\t\t\twait_queue_head_t *);\nextern struct dentry * d_splice_alias(struct inode *, struct dentry *);\nextern struct dentry * d_add_ci(struct dentry *, struct inode *, struct qstr *);\nextern struct dentry * d_exact_alias(struct dentry *, struct inode *);\nextern struct dentry *d_find_any_alias(struct inode *inode);\nextern struct dentry * d_obtain_alias(struct inode *);\nextern struct dentry * d_obtain_root(struct inode *);\nextern void shrink_dcache_sb(struct super_block *);\nextern void shrink_dcache_parent(struct dentry *);\nextern void shrink_dcache_for_umount(struct super_block *);\nextern void d_invalidate(struct dentry *);\n\n/* only used at mount-time */\nextern struct dentry * d_make_root(struct inode *);\n\n/* <clickety>-<click> the ramfs-type tree */\nextern void d_genocide(struct dentry *);\n\nextern void d_tmpfile(struct dentry *, struct inode *);\n\nextern struct dentry *d_find_alias(struct inode *);\nextern void d_prune_aliases(struct inode *);\n\n/* test whether we have any submounts in a subdir tree */\nextern int path_has_submounts(const struct path *);\n\n/*\n * This adds the entry to the hash queues.\n */\nextern void d_rehash(struct dentry *);\n \nextern void d_add(struct dentry *, struct inode *);\n\nextern void dentry_update_name_case(struct dentry *, const struct qstr *);\n\n/* used for rename() and baskets */\nextern void d_move(struct dentry *, struct dentry *);\nextern void d_exchange(struct dentry *, struct dentry *);\nextern struct dentry *d_ancestor(struct dentry *, struct dentry *);\n\n/* appendix may either be NULL or be used for transname suffixes */\nextern struct dentry *d_lookup(const struct dentry *, const struct qstr *);\nextern struct dentry *d_hash_and_lookup(struct dentry *, struct qstr *);\nextern struct dentry *__d_lookup(const struct dentry *, const struct qstr *);\nextern struct dentry *__d_lookup_rcu(const struct dentry *parent,\n\t\t\t\tconst struct qstr *name, unsigned *seq);\n\nstatic inline unsigned d_count(const struct dentry *dentry)\n{\n\treturn dentry->d_lockref.count;\n}\n\n/*\n * helper function for dentry_operations.d_dname() members\n */\nextern __printf(4, 5)\nchar *dynamic_dname(struct dentry *, char *, int, const char *, ...);\nextern char *simple_dname(struct dentry *, char *, int);\n\nextern char *__d_path(const struct path *, const struct path *, char *, int);\nextern char *d_absolute_path(const struct path *, char *, int);\nextern char *d_path(const struct path *, char *, int);\nextern char *dentry_path_raw(struct dentry *, char *, int);\nextern char *dentry_path(struct dentry *, char *, int);\n\n/* Allocation counts.. */\n\n/**\n *\tdget, dget_dlock -\tget a reference to a dentry\n *\t@dentry: dentry to get a reference to\n *\n *\tGiven a dentry or %NULL pointer increment the reference count\n *\tif appropriate and return the dentry. A dentry will not be \n *\tdestroyed when it has references.\n */\nstatic inline struct dentry *dget_dlock(struct dentry *dentry)\n{\n\tif (dentry)\n\t\tdentry->d_lockref.count++;\n\treturn dentry;\n}\n\nstatic inline struct dentry *dget(struct dentry *dentry)\n{\n\tif (dentry)\n\t\tlockref_get(&dentry->d_lockref);\n\treturn dentry;\n}\n\nextern struct dentry *dget_parent(struct dentry *dentry);\n\n/**\n *\td_unhashed -\tis dentry hashed\n *\t@dentry: entry to check\n *\n *\tReturns true if the dentry passed is not currently hashed.\n */\n \nstatic inline int d_unhashed(const struct dentry *dentry)\n{\n\treturn hlist_bl_unhashed(&dentry->d_hash);\n}\n\nstatic inline int d_unlinked(const struct dentry *dentry)\n{\n\treturn d_unhashed(dentry) && !IS_ROOT(dentry);\n}\n\nstatic inline int cant_mount(const struct dentry *dentry)\n{\n\treturn (dentry->d_flags & DCACHE_CANT_MOUNT);\n}\n\nstatic inline void dont_mount(struct dentry *dentry)\n{\n\tspin_lock(&dentry->d_lock);\n\tdentry->d_flags |= DCACHE_CANT_MOUNT;\n\tspin_unlock(&dentry->d_lock);\n}\n\nextern void __d_lookup_done(struct dentry *);\n\nstatic inline int d_in_lookup(struct dentry *dentry)\n{\n\treturn dentry->d_flags & DCACHE_PAR_LOOKUP;\n}\n\nstatic inline void d_lookup_done(struct dentry *dentry)\n{\n\tif (unlikely(d_in_lookup(dentry))) {\n\t\tspin_lock(&dentry->d_lock);\n\t\t__d_lookup_done(dentry);\n\t\tspin_unlock(&dentry->d_lock);\n\t}\n}\n\nextern void dput(struct dentry *);\n\nstatic inline bool d_managed(const struct dentry *dentry)\n{\n\treturn dentry->d_flags & DCACHE_MANAGED_DENTRY;\n}\n\nstatic inline bool d_mountpoint(const struct dentry *dentry)\n{\n\treturn dentry->d_flags & DCACHE_MOUNTED;\n}\n\n/*\n * Directory cache entry type accessor functions.\n */\nstatic inline unsigned __d_entry_type(const struct dentry *dentry)\n{\n\treturn dentry->d_flags & DCACHE_ENTRY_TYPE;\n}\n\nstatic inline bool d_is_miss(const struct dentry *dentry)\n{\n\treturn __d_entry_type(dentry) == DCACHE_MISS_TYPE;\n}\n\nstatic inline bool d_is_whiteout(const struct dentry *dentry)\n{\n\treturn __d_entry_type(dentry) == DCACHE_WHITEOUT_TYPE;\n}\n\nstatic inline bool d_can_lookup(const struct dentry *dentry)\n{\n\treturn __d_entry_type(dentry) == DCACHE_DIRECTORY_TYPE;\n}\n\nstatic inline bool d_is_autodir(const struct dentry *dentry)\n{\n\treturn __d_entry_type(dentry) == DCACHE_AUTODIR_TYPE;\n}\n\nstatic inline bool d_is_dir(const struct dentry *dentry)\n{\n\treturn d_can_lookup(dentry) || d_is_autodir(dentry);\n}\n\nstatic inline bool d_is_symlink(const struct dentry *dentry)\n{\n\treturn __d_entry_type(dentry) == DCACHE_SYMLINK_TYPE;\n}\n\nstatic inline bool d_is_reg(const struct dentry *dentry)\n{\n\treturn __d_entry_type(dentry) == DCACHE_REGULAR_TYPE;\n}\n\nstatic inline bool d_is_special(const struct dentry *dentry)\n{\n\treturn __d_entry_type(dentry) == DCACHE_SPECIAL_TYPE;\n}\n\nstatic inline bool d_is_file(const struct dentry *dentry)\n{\n\treturn d_is_reg(dentry) || d_is_special(dentry);\n}\n\nstatic inline bool d_is_negative(const struct dentry *dentry)\n{\n\t// TODO: check d_is_whiteout(dentry) also.\n\treturn d_is_miss(dentry);\n}\n\nstatic inline bool d_is_positive(const struct dentry *dentry)\n{\n\treturn !d_is_negative(dentry);\n}\n\n/**\n * d_really_is_negative - Determine if a dentry is really negative (ignoring fallthroughs)\n * @dentry: The dentry in question\n *\n * Returns true if the dentry represents either an absent name or a name that\n * doesn't map to an inode (ie. ->d_inode is NULL).  The dentry could represent\n * a true miss, a whiteout that isn't represented by a 0,0 chardev or a\n * fallthrough marker in an opaque directory.\n *\n * Note!  (1) This should be used *only* by a filesystem to examine its own\n * dentries.  It should not be used to look at some other filesystem's\n * dentries.  (2) It should also be used in combination with d_inode() to get\n * the inode.  (3) The dentry may have something attached to ->d_lower and the\n * type field of the flags may be set to something other than miss or whiteout.\n */\nstatic inline bool d_really_is_negative(const struct dentry *dentry)\n{\n\treturn dentry->d_inode == NULL;\n}\n\n/**\n * d_really_is_positive - Determine if a dentry is really positive (ignoring fallthroughs)\n * @dentry: The dentry in question\n *\n * Returns true if the dentry represents a name that maps to an inode\n * (ie. ->d_inode is not NULL).  The dentry might still represent a whiteout if\n * that is represented on medium as a 0,0 chardev.\n *\n * Note!  (1) This should be used *only* by a filesystem to examine its own\n * dentries.  It should not be used to look at some other filesystem's\n * dentries.  (2) It should also be used in combination with d_inode() to get\n * the inode.\n */\nstatic inline bool d_really_is_positive(const struct dentry *dentry)\n{\n\treturn dentry->d_inode != NULL;\n}\n\nstatic inline int simple_positive(struct dentry *dentry)\n{\n\treturn d_really_is_positive(dentry) && !d_unhashed(dentry);\n}\n\nextern void d_set_fallthru(struct dentry *dentry);\n\nstatic inline bool d_is_fallthru(const struct dentry *dentry)\n{\n\treturn dentry->d_flags & DCACHE_FALLTHRU;\n}\n\n\nextern int sysctl_vfs_cache_pressure;\n\nstatic inline unsigned long vfs_pressure_ratio(unsigned long val)\n{\n\treturn mult_frac(val, sysctl_vfs_cache_pressure, 100);\n}\n\n/**\n * d_inode - Get the actual inode of this dentry\n * @dentry: The dentry to query\n *\n * This is the helper normal filesystems should use to get at their own inodes\n * in their own dentries and ignore the layering superimposed upon them.\n */\nstatic inline struct inode *d_inode(const struct dentry *dentry)\n{\n\treturn dentry->d_inode;\n}\n\n/**\n * d_inode_rcu - Get the actual inode of this dentry with ACCESS_ONCE()\n * @dentry: The dentry to query\n *\n * This is the helper normal filesystems should use to get at their own inodes\n * in their own dentries and ignore the layering superimposed upon them.\n */\nstatic inline struct inode *d_inode_rcu(const struct dentry *dentry)\n{\n\treturn ACCESS_ONCE(dentry->d_inode);\n}\n\n/**\n * d_backing_inode - Get upper or lower inode we should be using\n * @upper: The upper layer\n *\n * This is the helper that should be used to get at the inode that will be used\n * if this dentry were to be opened as a file.  The inode may be on the upper\n * dentry or it may be on a lower dentry pinned by the upper.\n *\n * Normal filesystems should not use this to access their own inodes.\n */\nstatic inline struct inode *d_backing_inode(const struct dentry *upper)\n{\n\tstruct inode *inode = upper->d_inode;\n\n\treturn inode;\n}\n\n/**\n * d_backing_dentry - Get upper or lower dentry we should be using\n * @upper: The upper layer\n *\n * This is the helper that should be used to get the dentry of the inode that\n * will be used if this dentry were opened as a file.  It may be the upper\n * dentry or it may be a lower dentry pinned by the upper.\n *\n * Normal filesystems should not use this to access their own dentries.\n */\nstatic inline struct dentry *d_backing_dentry(struct dentry *upper)\n{\n\treturn upper;\n}\n\n/**\n * d_real - Return the real dentry\n * @dentry: the dentry to query\n * @inode: inode to select the dentry from multiple layers (can be NULL)\n * @flags: open flags to control copy-up behavior\n *\n * If dentry is on a union/overlay, then return the underlying, real dentry.\n * Otherwise return the dentry itself.\n *\n * See also: Documentation/filesystems/vfs.txt\n */\nstatic inline struct dentry *d_real(struct dentry *dentry,\n\t\t\t\t    const struct inode *inode,\n\t\t\t\t    unsigned int flags)\n{\n\tif (unlikely(dentry->d_flags & DCACHE_OP_REAL))\n\t\treturn dentry->d_op->d_real(dentry, inode, flags);\n\telse\n\t\treturn dentry;\n}\n\n/**\n * d_real_inode - Return the real inode\n * @dentry: The dentry to query\n *\n * If dentry is on a union/overlay, then return the underlying, real inode.\n * Otherwise return d_inode().\n */\nstatic inline struct inode *d_real_inode(const struct dentry *dentry)\n{\n\t/* This usage of d_real() results in const dentry */\n\treturn d_backing_inode(d_real((struct dentry *) dentry, NULL, 0));\n}\n\n\n#endif\t/* __LINUX_DCACHE_H */\n", "#ifndef _LINUX_FS_NOTIFY_H\n#define _LINUX_FS_NOTIFY_H\n\n/*\n * include/linux/fsnotify.h - generic hooks for filesystem notification, to\n * reduce in-source duplication from both dnotify and inotify.\n *\n * We don't compile any of this away in some complicated menagerie of ifdefs.\n * Instead, we rely on the code inside to optimize away as needed.\n *\n * (C) Copyright 2005 Robert Love\n */\n\n#include <linux/fsnotify_backend.h>\n#include <linux/audit.h>\n#include <linux/slab.h>\n#include <linux/bug.h>\n\n/* Notify this dentry's parent about a child's events. */\nstatic inline int fsnotify_parent(const struct path *path, struct dentry *dentry, __u32 mask)\n{\n\tif (!dentry)\n\t\tdentry = path->dentry;\n\n\treturn __fsnotify_parent(path, dentry, mask);\n}\n\n/* simple call site for access decisions */\nstatic inline int fsnotify_perm(struct file *file, int mask)\n{\n\tconst struct path *path = &file->f_path;\n\t/*\n\t * Do not use file_inode() here or anywhere in this file to get the\n\t * inode.  That would break *notity on overlayfs.\n\t */\n\tstruct inode *inode = path->dentry->d_inode;\n\t__u32 fsnotify_mask = 0;\n\tint ret;\n\n\tif (file->f_mode & FMODE_NONOTIFY)\n\t\treturn 0;\n\tif (!(mask & (MAY_READ | MAY_OPEN)))\n\t\treturn 0;\n\tif (mask & MAY_OPEN)\n\t\tfsnotify_mask = FS_OPEN_PERM;\n\telse if (mask & MAY_READ)\n\t\tfsnotify_mask = FS_ACCESS_PERM;\n\telse\n\t\tBUG();\n\n\tret = fsnotify_parent(path, NULL, fsnotify_mask);\n\tif (ret)\n\t\treturn ret;\n\n\treturn fsnotify(inode, fsnotify_mask, path, FSNOTIFY_EVENT_PATH, NULL, 0);\n}\n\n/*\n * fsnotify_link_count - inode's link count changed\n */\nstatic inline void fsnotify_link_count(struct inode *inode)\n{\n\tfsnotify(inode, FS_ATTRIB, inode, FSNOTIFY_EVENT_INODE, NULL, 0);\n}\n\n/*\n * fsnotify_move - file old_name at old_dir was moved to new_name at new_dir\n */\nstatic inline void fsnotify_move(struct inode *old_dir, struct inode *new_dir,\n\t\t\t\t const unsigned char *old_name,\n\t\t\t\t int isdir, struct inode *target, struct dentry *moved)\n{\n\tstruct inode *source = moved->d_inode;\n\tu32 fs_cookie = fsnotify_get_cookie();\n\t__u32 old_dir_mask = (FS_EVENT_ON_CHILD | FS_MOVED_FROM);\n\t__u32 new_dir_mask = (FS_EVENT_ON_CHILD | FS_MOVED_TO);\n\tconst unsigned char *new_name = moved->d_name.name;\n\n\tif (old_dir == new_dir)\n\t\told_dir_mask |= FS_DN_RENAME;\n\n\tif (isdir) {\n\t\told_dir_mask |= FS_ISDIR;\n\t\tnew_dir_mask |= FS_ISDIR;\n\t}\n\n\tfsnotify(old_dir, old_dir_mask, source, FSNOTIFY_EVENT_INODE, old_name,\n\t\t fs_cookie);\n\tfsnotify(new_dir, new_dir_mask, source, FSNOTIFY_EVENT_INODE, new_name,\n\t\t fs_cookie);\n\n\tif (target)\n\t\tfsnotify_link_count(target);\n\n\tif (source)\n\t\tfsnotify(source, FS_MOVE_SELF, moved->d_inode, FSNOTIFY_EVENT_INODE, NULL, 0);\n\taudit_inode_child(new_dir, moved, AUDIT_TYPE_CHILD_CREATE);\n}\n\n/*\n * fsnotify_inode_delete - and inode is being evicted from cache, clean up is needed\n */\nstatic inline void fsnotify_inode_delete(struct inode *inode)\n{\n\t__fsnotify_inode_delete(inode);\n}\n\n/*\n * fsnotify_vfsmount_delete - a vfsmount is being destroyed, clean up is needed\n */\nstatic inline void fsnotify_vfsmount_delete(struct vfsmount *mnt)\n{\n\t__fsnotify_vfsmount_delete(mnt);\n}\n\n/*\n * fsnotify_nameremove - a filename was removed from a directory\n */\nstatic inline void fsnotify_nameremove(struct dentry *dentry, int isdir)\n{\n\t__u32 mask = FS_DELETE;\n\n\tif (isdir)\n\t\tmask |= FS_ISDIR;\n\n\tfsnotify_parent(NULL, dentry, mask);\n}\n\n/*\n * fsnotify_inoderemove - an inode is going away\n */\nstatic inline void fsnotify_inoderemove(struct inode *inode)\n{\n\tfsnotify(inode, FS_DELETE_SELF, inode, FSNOTIFY_EVENT_INODE, NULL, 0);\n\t__fsnotify_inode_delete(inode);\n}\n\n/*\n * fsnotify_create - 'name' was linked in\n */\nstatic inline void fsnotify_create(struct inode *inode, struct dentry *dentry)\n{\n\taudit_inode_child(inode, dentry, AUDIT_TYPE_CHILD_CREATE);\n\n\tfsnotify(inode, FS_CREATE, dentry->d_inode, FSNOTIFY_EVENT_INODE, dentry->d_name.name, 0);\n}\n\n/*\n * fsnotify_link - new hardlink in 'inode' directory\n * Note: We have to pass also the linked inode ptr as some filesystems leave\n *   new_dentry->d_inode NULL and instantiate inode pointer later\n */\nstatic inline void fsnotify_link(struct inode *dir, struct inode *inode, struct dentry *new_dentry)\n{\n\tfsnotify_link_count(inode);\n\taudit_inode_child(dir, new_dentry, AUDIT_TYPE_CHILD_CREATE);\n\n\tfsnotify(dir, FS_CREATE, inode, FSNOTIFY_EVENT_INODE, new_dentry->d_name.name, 0);\n}\n\n/*\n * fsnotify_mkdir - directory 'name' was created\n */\nstatic inline void fsnotify_mkdir(struct inode *inode, struct dentry *dentry)\n{\n\t__u32 mask = (FS_CREATE | FS_ISDIR);\n\tstruct inode *d_inode = dentry->d_inode;\n\n\taudit_inode_child(inode, dentry, AUDIT_TYPE_CHILD_CREATE);\n\n\tfsnotify(inode, mask, d_inode, FSNOTIFY_EVENT_INODE, dentry->d_name.name, 0);\n}\n\n/*\n * fsnotify_access - file was read\n */\nstatic inline void fsnotify_access(struct file *file)\n{\n\tconst struct path *path = &file->f_path;\n\tstruct inode *inode = path->dentry->d_inode;\n\t__u32 mask = FS_ACCESS;\n\n\tif (S_ISDIR(inode->i_mode))\n\t\tmask |= FS_ISDIR;\n\n\tif (!(file->f_mode & FMODE_NONOTIFY)) {\n\t\tfsnotify_parent(path, NULL, mask);\n\t\tfsnotify(inode, mask, path, FSNOTIFY_EVENT_PATH, NULL, 0);\n\t}\n}\n\n/*\n * fsnotify_modify - file was modified\n */\nstatic inline void fsnotify_modify(struct file *file)\n{\n\tconst struct path *path = &file->f_path;\n\tstruct inode *inode = path->dentry->d_inode;\n\t__u32 mask = FS_MODIFY;\n\n\tif (S_ISDIR(inode->i_mode))\n\t\tmask |= FS_ISDIR;\n\n\tif (!(file->f_mode & FMODE_NONOTIFY)) {\n\t\tfsnotify_parent(path, NULL, mask);\n\t\tfsnotify(inode, mask, path, FSNOTIFY_EVENT_PATH, NULL, 0);\n\t}\n}\n\n/*\n * fsnotify_open - file was opened\n */\nstatic inline void fsnotify_open(struct file *file)\n{\n\tconst struct path *path = &file->f_path;\n\tstruct inode *inode = path->dentry->d_inode;\n\t__u32 mask = FS_OPEN;\n\n\tif (S_ISDIR(inode->i_mode))\n\t\tmask |= FS_ISDIR;\n\n\tfsnotify_parent(path, NULL, mask);\n\tfsnotify(inode, mask, path, FSNOTIFY_EVENT_PATH, NULL, 0);\n}\n\n/*\n * fsnotify_close - file was closed\n */\nstatic inline void fsnotify_close(struct file *file)\n{\n\tconst struct path *path = &file->f_path;\n\tstruct inode *inode = path->dentry->d_inode;\n\tfmode_t mode = file->f_mode;\n\t__u32 mask = (mode & FMODE_WRITE) ? FS_CLOSE_WRITE : FS_CLOSE_NOWRITE;\n\n\tif (S_ISDIR(inode->i_mode))\n\t\tmask |= FS_ISDIR;\n\n\tif (!(file->f_mode & FMODE_NONOTIFY)) {\n\t\tfsnotify_parent(path, NULL, mask);\n\t\tfsnotify(inode, mask, path, FSNOTIFY_EVENT_PATH, NULL, 0);\n\t}\n}\n\n/*\n * fsnotify_xattr - extended attributes were changed\n */\nstatic inline void fsnotify_xattr(struct dentry *dentry)\n{\n\tstruct inode *inode = dentry->d_inode;\n\t__u32 mask = FS_ATTRIB;\n\n\tif (S_ISDIR(inode->i_mode))\n\t\tmask |= FS_ISDIR;\n\n\tfsnotify_parent(NULL, dentry, mask);\n\tfsnotify(inode, mask, inode, FSNOTIFY_EVENT_INODE, NULL, 0);\n}\n\n/*\n * fsnotify_change - notify_change event.  file was modified and/or metadata\n * was changed.\n */\nstatic inline void fsnotify_change(struct dentry *dentry, unsigned int ia_valid)\n{\n\tstruct inode *inode = dentry->d_inode;\n\t__u32 mask = 0;\n\n\tif (ia_valid & ATTR_UID)\n\t\tmask |= FS_ATTRIB;\n\tif (ia_valid & ATTR_GID)\n\t\tmask |= FS_ATTRIB;\n\tif (ia_valid & ATTR_SIZE)\n\t\tmask |= FS_MODIFY;\n\n\t/* both times implies a utime(s) call */\n\tif ((ia_valid & (ATTR_ATIME | ATTR_MTIME)) == (ATTR_ATIME | ATTR_MTIME))\n\t\tmask |= FS_ATTRIB;\n\telse if (ia_valid & ATTR_ATIME)\n\t\tmask |= FS_ACCESS;\n\telse if (ia_valid & ATTR_MTIME)\n\t\tmask |= FS_MODIFY;\n\n\tif (ia_valid & ATTR_MODE)\n\t\tmask |= FS_ATTRIB;\n\n\tif (mask) {\n\t\tif (S_ISDIR(inode->i_mode))\n\t\t\tmask |= FS_ISDIR;\n\n\t\tfsnotify_parent(NULL, dentry, mask);\n\t\tfsnotify(inode, mask, inode, FSNOTIFY_EVENT_INODE, NULL, 0);\n\t}\n}\n\n#if defined(CONFIG_FSNOTIFY)\t/* notify helpers */\n\n/*\n * fsnotify_oldname_init - save off the old filename before we change it\n */\nstatic inline const unsigned char *fsnotify_oldname_init(const unsigned char *name)\n{\n\treturn kstrdup(name, GFP_KERNEL);\n}\n\n/*\n * fsnotify_oldname_free - free the name we got from fsnotify_oldname_init\n */\nstatic inline void fsnotify_oldname_free(const unsigned char *old_name)\n{\n\tkfree(old_name);\n}\n\n#else\t/* CONFIG_FSNOTIFY */\n\nstatic inline const char *fsnotify_oldname_init(const unsigned char *name)\n{\n\treturn NULL;\n}\n\nstatic inline void fsnotify_oldname_free(const unsigned char *old_name)\n{\n}\n\n#endif\t/*  CONFIG_FSNOTIFY */\n\n#endif\t/* _LINUX_FS_NOTIFY_H */\n"], "fixing_code": ["/*\n * fs/dcache.c\n *\n * Complete reimplementation\n * (C) 1997 Thomas Schoebel-Theuer,\n * with heavy changes by Linus Torvalds\n */\n\n/*\n * Notes on the allocation strategy:\n *\n * The dcache is a master of the icache - whenever a dcache entry\n * exists, the inode will always exist. \"iput()\" is done either when\n * the dcache entry is deleted or garbage collected.\n */\n\n#include <linux/syscalls.h>\n#include <linux/string.h>\n#include <linux/mm.h>\n#include <linux/fs.h>\n#include <linux/fsnotify.h>\n#include <linux/slab.h>\n#include <linux/init.h>\n#include <linux/hash.h>\n#include <linux/cache.h>\n#include <linux/export.h>\n#include <linux/mount.h>\n#include <linux/file.h>\n#include <linux/uaccess.h>\n#include <linux/security.h>\n#include <linux/seqlock.h>\n#include <linux/swap.h>\n#include <linux/bootmem.h>\n#include <linux/fs_struct.h>\n#include <linux/hardirq.h>\n#include <linux/bit_spinlock.h>\n#include <linux/rculist_bl.h>\n#include <linux/prefetch.h>\n#include <linux/ratelimit.h>\n#include <linux/list_lru.h>\n#include <linux/kasan.h>\n\n#include \"internal.h\"\n#include \"mount.h\"\n\n/*\n * Usage:\n * dcache->d_inode->i_lock protects:\n *   - i_dentry, d_u.d_alias, d_inode of aliases\n * dcache_hash_bucket lock protects:\n *   - the dcache hash table\n * s_anon bl list spinlock protects:\n *   - the s_anon list (see __d_drop)\n * dentry->d_sb->s_dentry_lru_lock protects:\n *   - the dcache lru lists and counters\n * d_lock protects:\n *   - d_flags\n *   - d_name\n *   - d_lru\n *   - d_count\n *   - d_unhashed()\n *   - d_parent and d_subdirs\n *   - childrens' d_child and d_parent\n *   - d_u.d_alias, d_inode\n *\n * Ordering:\n * dentry->d_inode->i_lock\n *   dentry->d_lock\n *     dentry->d_sb->s_dentry_lru_lock\n *     dcache_hash_bucket lock\n *     s_anon lock\n *\n * If there is an ancestor relationship:\n * dentry->d_parent->...->d_parent->d_lock\n *   ...\n *     dentry->d_parent->d_lock\n *       dentry->d_lock\n *\n * If no ancestor relationship:\n * if (dentry1 < dentry2)\n *   dentry1->d_lock\n *     dentry2->d_lock\n */\nint sysctl_vfs_cache_pressure __read_mostly = 100;\nEXPORT_SYMBOL_GPL(sysctl_vfs_cache_pressure);\n\n__cacheline_aligned_in_smp DEFINE_SEQLOCK(rename_lock);\n\nEXPORT_SYMBOL(rename_lock);\n\nstatic struct kmem_cache *dentry_cache __read_mostly;\n\n/*\n * This is the single most critical data structure when it comes\n * to the dcache: the hashtable for lookups. Somebody should try\n * to make this good - I've just made it work.\n *\n * This hash-function tries to avoid losing too many bits of hash\n * information, yet avoid using a prime hash-size or similar.\n */\n\nstatic unsigned int d_hash_mask __read_mostly;\nstatic unsigned int d_hash_shift __read_mostly;\n\nstatic struct hlist_bl_head *dentry_hashtable __read_mostly;\n\nstatic inline struct hlist_bl_head *d_hash(unsigned int hash)\n{\n\treturn dentry_hashtable + (hash >> (32 - d_hash_shift));\n}\n\n#define IN_LOOKUP_SHIFT 10\nstatic struct hlist_bl_head in_lookup_hashtable[1 << IN_LOOKUP_SHIFT];\n\nstatic inline struct hlist_bl_head *in_lookup_hash(const struct dentry *parent,\n\t\t\t\t\tunsigned int hash)\n{\n\thash += (unsigned long) parent / L1_CACHE_BYTES;\n\treturn in_lookup_hashtable + hash_32(hash, IN_LOOKUP_SHIFT);\n}\n\n\n/* Statistics gathering. */\nstruct dentry_stat_t dentry_stat = {\n\t.age_limit = 45,\n};\n\nstatic DEFINE_PER_CPU(long, nr_dentry);\nstatic DEFINE_PER_CPU(long, nr_dentry_unused);\n\n#if defined(CONFIG_SYSCTL) && defined(CONFIG_PROC_FS)\n\n/*\n * Here we resort to our own counters instead of using generic per-cpu counters\n * for consistency with what the vfs inode code does. We are expected to harvest\n * better code and performance by having our own specialized counters.\n *\n * Please note that the loop is done over all possible CPUs, not over all online\n * CPUs. The reason for this is that we don't want to play games with CPUs going\n * on and off. If one of them goes off, we will just keep their counters.\n *\n * glommer: See cffbc8a for details, and if you ever intend to change this,\n * please update all vfs counters to match.\n */\nstatic long get_nr_dentry(void)\n{\n\tint i;\n\tlong sum = 0;\n\tfor_each_possible_cpu(i)\n\t\tsum += per_cpu(nr_dentry, i);\n\treturn sum < 0 ? 0 : sum;\n}\n\nstatic long get_nr_dentry_unused(void)\n{\n\tint i;\n\tlong sum = 0;\n\tfor_each_possible_cpu(i)\n\t\tsum += per_cpu(nr_dentry_unused, i);\n\treturn sum < 0 ? 0 : sum;\n}\n\nint proc_nr_dentry(struct ctl_table *table, int write, void __user *buffer,\n\t\t   size_t *lenp, loff_t *ppos)\n{\n\tdentry_stat.nr_dentry = get_nr_dentry();\n\tdentry_stat.nr_unused = get_nr_dentry_unused();\n\treturn proc_doulongvec_minmax(table, write, buffer, lenp, ppos);\n}\n#endif\n\n/*\n * Compare 2 name strings, return 0 if they match, otherwise non-zero.\n * The strings are both count bytes long, and count is non-zero.\n */\n#ifdef CONFIG_DCACHE_WORD_ACCESS\n\n#include <asm/word-at-a-time.h>\n/*\n * NOTE! 'cs' and 'scount' come from a dentry, so it has a\n * aligned allocation for this particular component. We don't\n * strictly need the load_unaligned_zeropad() safety, but it\n * doesn't hurt either.\n *\n * In contrast, 'ct' and 'tcount' can be from a pathname, and do\n * need the careful unaligned handling.\n */\nstatic inline int dentry_string_cmp(const unsigned char *cs, const unsigned char *ct, unsigned tcount)\n{\n\tunsigned long a,b,mask;\n\n\tfor (;;) {\n\t\ta = *(unsigned long *)cs;\n\t\tb = load_unaligned_zeropad(ct);\n\t\tif (tcount < sizeof(unsigned long))\n\t\t\tbreak;\n\t\tif (unlikely(a != b))\n\t\t\treturn 1;\n\t\tcs += sizeof(unsigned long);\n\t\tct += sizeof(unsigned long);\n\t\ttcount -= sizeof(unsigned long);\n\t\tif (!tcount)\n\t\t\treturn 0;\n\t}\n\tmask = bytemask_from_count(tcount);\n\treturn unlikely(!!((a ^ b) & mask));\n}\n\n#else\n\nstatic inline int dentry_string_cmp(const unsigned char *cs, const unsigned char *ct, unsigned tcount)\n{\n\tdo {\n\t\tif (*cs != *ct)\n\t\t\treturn 1;\n\t\tcs++;\n\t\tct++;\n\t\ttcount--;\n\t} while (tcount);\n\treturn 0;\n}\n\n#endif\n\nstatic inline int dentry_cmp(const struct dentry *dentry, const unsigned char *ct, unsigned tcount)\n{\n\t/*\n\t * Be careful about RCU walk racing with rename:\n\t * use 'lockless_dereference' to fetch the name pointer.\n\t *\n\t * NOTE! Even if a rename will mean that the length\n\t * was not loaded atomically, we don't care. The\n\t * RCU walk will check the sequence count eventually,\n\t * and catch it. And we won't overrun the buffer,\n\t * because we're reading the name pointer atomically,\n\t * and a dentry name is guaranteed to be properly\n\t * terminated with a NUL byte.\n\t *\n\t * End result: even if 'len' is wrong, we'll exit\n\t * early because the data cannot match (there can\n\t * be no NUL in the ct/tcount data)\n\t */\n\tconst unsigned char *cs = lockless_dereference(dentry->d_name.name);\n\n\treturn dentry_string_cmp(cs, ct, tcount);\n}\n\nstruct external_name {\n\tunion {\n\t\tatomic_t count;\n\t\tstruct rcu_head head;\n\t} u;\n\tunsigned char name[];\n};\n\nstatic inline struct external_name *external_name(struct dentry *dentry)\n{\n\treturn container_of(dentry->d_name.name, struct external_name, name[0]);\n}\n\nstatic void __d_free(struct rcu_head *head)\n{\n\tstruct dentry *dentry = container_of(head, struct dentry, d_u.d_rcu);\n\n\tkmem_cache_free(dentry_cache, dentry); \n}\n\nstatic void __d_free_external(struct rcu_head *head)\n{\n\tstruct dentry *dentry = container_of(head, struct dentry, d_u.d_rcu);\n\tkfree(external_name(dentry));\n\tkmem_cache_free(dentry_cache, dentry); \n}\n\nstatic inline int dname_external(const struct dentry *dentry)\n{\n\treturn dentry->d_name.name != dentry->d_iname;\n}\n\nvoid take_dentry_name_snapshot(struct name_snapshot *name, struct dentry *dentry)\n{\n\tspin_lock(&dentry->d_lock);\n\tif (unlikely(dname_external(dentry))) {\n\t\tstruct external_name *p = external_name(dentry);\n\t\tatomic_inc(&p->u.count);\n\t\tspin_unlock(&dentry->d_lock);\n\t\tname->name = p->name;\n\t} else {\n\t\tmemcpy(name->inline_name, dentry->d_iname, DNAME_INLINE_LEN);\n\t\tspin_unlock(&dentry->d_lock);\n\t\tname->name = name->inline_name;\n\t}\n}\nEXPORT_SYMBOL(take_dentry_name_snapshot);\n\nvoid release_dentry_name_snapshot(struct name_snapshot *name)\n{\n\tif (unlikely(name->name != name->inline_name)) {\n\t\tstruct external_name *p;\n\t\tp = container_of(name->name, struct external_name, name[0]);\n\t\tif (unlikely(atomic_dec_and_test(&p->u.count)))\n\t\t\tkfree_rcu(p, u.head);\n\t}\n}\nEXPORT_SYMBOL(release_dentry_name_snapshot);\n\nstatic inline void __d_set_inode_and_type(struct dentry *dentry,\n\t\t\t\t\t  struct inode *inode,\n\t\t\t\t\t  unsigned type_flags)\n{\n\tunsigned flags;\n\n\tdentry->d_inode = inode;\n\tflags = READ_ONCE(dentry->d_flags);\n\tflags &= ~(DCACHE_ENTRY_TYPE | DCACHE_FALLTHRU);\n\tflags |= type_flags;\n\tWRITE_ONCE(dentry->d_flags, flags);\n}\n\nstatic inline void __d_clear_type_and_inode(struct dentry *dentry)\n{\n\tunsigned flags = READ_ONCE(dentry->d_flags);\n\n\tflags &= ~(DCACHE_ENTRY_TYPE | DCACHE_FALLTHRU);\n\tWRITE_ONCE(dentry->d_flags, flags);\n\tdentry->d_inode = NULL;\n}\n\nstatic void dentry_free(struct dentry *dentry)\n{\n\tWARN_ON(!hlist_unhashed(&dentry->d_u.d_alias));\n\tif (unlikely(dname_external(dentry))) {\n\t\tstruct external_name *p = external_name(dentry);\n\t\tif (likely(atomic_dec_and_test(&p->u.count))) {\n\t\t\tcall_rcu(&dentry->d_u.d_rcu, __d_free_external);\n\t\t\treturn;\n\t\t}\n\t}\n\t/* if dentry was never visible to RCU, immediate free is OK */\n\tif (!(dentry->d_flags & DCACHE_RCUACCESS))\n\t\t__d_free(&dentry->d_u.d_rcu);\n\telse\n\t\tcall_rcu(&dentry->d_u.d_rcu, __d_free);\n}\n\n/*\n * Release the dentry's inode, using the filesystem\n * d_iput() operation if defined.\n */\nstatic void dentry_unlink_inode(struct dentry * dentry)\n\t__releases(dentry->d_lock)\n\t__releases(dentry->d_inode->i_lock)\n{\n\tstruct inode *inode = dentry->d_inode;\n\tbool hashed = !d_unhashed(dentry);\n\n\tif (hashed)\n\t\traw_write_seqcount_begin(&dentry->d_seq);\n\t__d_clear_type_and_inode(dentry);\n\thlist_del_init(&dentry->d_u.d_alias);\n\tif (hashed)\n\t\traw_write_seqcount_end(&dentry->d_seq);\n\tspin_unlock(&dentry->d_lock);\n\tspin_unlock(&inode->i_lock);\n\tif (!inode->i_nlink)\n\t\tfsnotify_inoderemove(inode);\n\tif (dentry->d_op && dentry->d_op->d_iput)\n\t\tdentry->d_op->d_iput(dentry, inode);\n\telse\n\t\tiput(inode);\n}\n\n/*\n * The DCACHE_LRU_LIST bit is set whenever the 'd_lru' entry\n * is in use - which includes both the \"real\" per-superblock\n * LRU list _and_ the DCACHE_SHRINK_LIST use.\n *\n * The DCACHE_SHRINK_LIST bit is set whenever the dentry is\n * on the shrink list (ie not on the superblock LRU list).\n *\n * The per-cpu \"nr_dentry_unused\" counters are updated with\n * the DCACHE_LRU_LIST bit.\n *\n * These helper functions make sure we always follow the\n * rules. d_lock must be held by the caller.\n */\n#define D_FLAG_VERIFY(dentry,x) WARN_ON_ONCE(((dentry)->d_flags & (DCACHE_LRU_LIST | DCACHE_SHRINK_LIST)) != (x))\nstatic void d_lru_add(struct dentry *dentry)\n{\n\tD_FLAG_VERIFY(dentry, 0);\n\tdentry->d_flags |= DCACHE_LRU_LIST;\n\tthis_cpu_inc(nr_dentry_unused);\n\tWARN_ON_ONCE(!list_lru_add(&dentry->d_sb->s_dentry_lru, &dentry->d_lru));\n}\n\nstatic void d_lru_del(struct dentry *dentry)\n{\n\tD_FLAG_VERIFY(dentry, DCACHE_LRU_LIST);\n\tdentry->d_flags &= ~DCACHE_LRU_LIST;\n\tthis_cpu_dec(nr_dentry_unused);\n\tWARN_ON_ONCE(!list_lru_del(&dentry->d_sb->s_dentry_lru, &dentry->d_lru));\n}\n\nstatic void d_shrink_del(struct dentry *dentry)\n{\n\tD_FLAG_VERIFY(dentry, DCACHE_SHRINK_LIST | DCACHE_LRU_LIST);\n\tlist_del_init(&dentry->d_lru);\n\tdentry->d_flags &= ~(DCACHE_SHRINK_LIST | DCACHE_LRU_LIST);\n\tthis_cpu_dec(nr_dentry_unused);\n}\n\nstatic void d_shrink_add(struct dentry *dentry, struct list_head *list)\n{\n\tD_FLAG_VERIFY(dentry, 0);\n\tlist_add(&dentry->d_lru, list);\n\tdentry->d_flags |= DCACHE_SHRINK_LIST | DCACHE_LRU_LIST;\n\tthis_cpu_inc(nr_dentry_unused);\n}\n\n/*\n * These can only be called under the global LRU lock, ie during the\n * callback for freeing the LRU list. \"isolate\" removes it from the\n * LRU lists entirely, while shrink_move moves it to the indicated\n * private list.\n */\nstatic void d_lru_isolate(struct list_lru_one *lru, struct dentry *dentry)\n{\n\tD_FLAG_VERIFY(dentry, DCACHE_LRU_LIST);\n\tdentry->d_flags &= ~DCACHE_LRU_LIST;\n\tthis_cpu_dec(nr_dentry_unused);\n\tlist_lru_isolate(lru, &dentry->d_lru);\n}\n\nstatic void d_lru_shrink_move(struct list_lru_one *lru, struct dentry *dentry,\n\t\t\t      struct list_head *list)\n{\n\tD_FLAG_VERIFY(dentry, DCACHE_LRU_LIST);\n\tdentry->d_flags |= DCACHE_SHRINK_LIST;\n\tlist_lru_isolate_move(lru, &dentry->d_lru, list);\n}\n\n/*\n * dentry_lru_(add|del)_list) must be called with d_lock held.\n */\nstatic void dentry_lru_add(struct dentry *dentry)\n{\n\tif (unlikely(!(dentry->d_flags & DCACHE_LRU_LIST)))\n\t\td_lru_add(dentry);\n\telse if (unlikely(!(dentry->d_flags & DCACHE_REFERENCED)))\n\t\tdentry->d_flags |= DCACHE_REFERENCED;\n}\n\n/**\n * d_drop - drop a dentry\n * @dentry: dentry to drop\n *\n * d_drop() unhashes the entry from the parent dentry hashes, so that it won't\n * be found through a VFS lookup any more. Note that this is different from\n * deleting the dentry - d_delete will try to mark the dentry negative if\n * possible, giving a successful _negative_ lookup, while d_drop will\n * just make the cache lookup fail.\n *\n * d_drop() is used mainly for stuff that wants to invalidate a dentry for some\n * reason (NFS timeouts or autofs deletes).\n *\n * __d_drop requires dentry->d_lock.\n */\nvoid __d_drop(struct dentry *dentry)\n{\n\tif (!d_unhashed(dentry)) {\n\t\tstruct hlist_bl_head *b;\n\t\t/*\n\t\t * Hashed dentries are normally on the dentry hashtable,\n\t\t * with the exception of those newly allocated by\n\t\t * d_obtain_alias, which are always IS_ROOT:\n\t\t */\n\t\tif (unlikely(IS_ROOT(dentry)))\n\t\t\tb = &dentry->d_sb->s_anon;\n\t\telse\n\t\t\tb = d_hash(dentry->d_name.hash);\n\n\t\thlist_bl_lock(b);\n\t\t__hlist_bl_del(&dentry->d_hash);\n\t\tdentry->d_hash.pprev = NULL;\n\t\thlist_bl_unlock(b);\n\t\t/* After this call, in-progress rcu-walk path lookup will fail. */\n\t\twrite_seqcount_invalidate(&dentry->d_seq);\n\t}\n}\nEXPORT_SYMBOL(__d_drop);\n\nvoid d_drop(struct dentry *dentry)\n{\n\tspin_lock(&dentry->d_lock);\n\t__d_drop(dentry);\n\tspin_unlock(&dentry->d_lock);\n}\nEXPORT_SYMBOL(d_drop);\n\nstatic inline void dentry_unlist(struct dentry *dentry, struct dentry *parent)\n{\n\tstruct dentry *next;\n\t/*\n\t * Inform d_walk() and shrink_dentry_list() that we are no longer\n\t * attached to the dentry tree\n\t */\n\tdentry->d_flags |= DCACHE_DENTRY_KILLED;\n\tif (unlikely(list_empty(&dentry->d_child)))\n\t\treturn;\n\t__list_del_entry(&dentry->d_child);\n\t/*\n\t * Cursors can move around the list of children.  While we'd been\n\t * a normal list member, it didn't matter - ->d_child.next would've\n\t * been updated.  However, from now on it won't be and for the\n\t * things like d_walk() it might end up with a nasty surprise.\n\t * Normally d_walk() doesn't care about cursors moving around -\n\t * ->d_lock on parent prevents that and since a cursor has no children\n\t * of its own, we get through it without ever unlocking the parent.\n\t * There is one exception, though - if we ascend from a child that\n\t * gets killed as soon as we unlock it, the next sibling is found\n\t * using the value left in its ->d_child.next.  And if _that_\n\t * pointed to a cursor, and cursor got moved (e.g. by lseek())\n\t * before d_walk() regains parent->d_lock, we'll end up skipping\n\t * everything the cursor had been moved past.\n\t *\n\t * Solution: make sure that the pointer left behind in ->d_child.next\n\t * points to something that won't be moving around.  I.e. skip the\n\t * cursors.\n\t */\n\twhile (dentry->d_child.next != &parent->d_subdirs) {\n\t\tnext = list_entry(dentry->d_child.next, struct dentry, d_child);\n\t\tif (likely(!(next->d_flags & DCACHE_DENTRY_CURSOR)))\n\t\t\tbreak;\n\t\tdentry->d_child.next = next->d_child.next;\n\t}\n}\n\nstatic void __dentry_kill(struct dentry *dentry)\n{\n\tstruct dentry *parent = NULL;\n\tbool can_free = true;\n\tif (!IS_ROOT(dentry))\n\t\tparent = dentry->d_parent;\n\n\t/*\n\t * The dentry is now unrecoverably dead to the world.\n\t */\n\tlockref_mark_dead(&dentry->d_lockref);\n\n\t/*\n\t * inform the fs via d_prune that this dentry is about to be\n\t * unhashed and destroyed.\n\t */\n\tif (dentry->d_flags & DCACHE_OP_PRUNE)\n\t\tdentry->d_op->d_prune(dentry);\n\n\tif (dentry->d_flags & DCACHE_LRU_LIST) {\n\t\tif (!(dentry->d_flags & DCACHE_SHRINK_LIST))\n\t\t\td_lru_del(dentry);\n\t}\n\t/* if it was on the hash then remove it */\n\t__d_drop(dentry);\n\tdentry_unlist(dentry, parent);\n\tif (parent)\n\t\tspin_unlock(&parent->d_lock);\n\tif (dentry->d_inode)\n\t\tdentry_unlink_inode(dentry);\n\telse\n\t\tspin_unlock(&dentry->d_lock);\n\tthis_cpu_dec(nr_dentry);\n\tif (dentry->d_op && dentry->d_op->d_release)\n\t\tdentry->d_op->d_release(dentry);\n\n\tspin_lock(&dentry->d_lock);\n\tif (dentry->d_flags & DCACHE_SHRINK_LIST) {\n\t\tdentry->d_flags |= DCACHE_MAY_FREE;\n\t\tcan_free = false;\n\t}\n\tspin_unlock(&dentry->d_lock);\n\tif (likely(can_free))\n\t\tdentry_free(dentry);\n}\n\n/*\n * Finish off a dentry we've decided to kill.\n * dentry->d_lock must be held, returns with it unlocked.\n * If ref is non-zero, then decrement the refcount too.\n * Returns dentry requiring refcount drop, or NULL if we're done.\n */\nstatic struct dentry *dentry_kill(struct dentry *dentry)\n\t__releases(dentry->d_lock)\n{\n\tstruct inode *inode = dentry->d_inode;\n\tstruct dentry *parent = NULL;\n\n\tif (inode && unlikely(!spin_trylock(&inode->i_lock)))\n\t\tgoto failed;\n\n\tif (!IS_ROOT(dentry)) {\n\t\tparent = dentry->d_parent;\n\t\tif (unlikely(!spin_trylock(&parent->d_lock))) {\n\t\t\tif (inode)\n\t\t\t\tspin_unlock(&inode->i_lock);\n\t\t\tgoto failed;\n\t\t}\n\t}\n\n\t__dentry_kill(dentry);\n\treturn parent;\n\nfailed:\n\tspin_unlock(&dentry->d_lock);\n\treturn dentry; /* try again with same dentry */\n}\n\nstatic inline struct dentry *lock_parent(struct dentry *dentry)\n{\n\tstruct dentry *parent = dentry->d_parent;\n\tif (IS_ROOT(dentry))\n\t\treturn NULL;\n\tif (unlikely(dentry->d_lockref.count < 0))\n\t\treturn NULL;\n\tif (likely(spin_trylock(&parent->d_lock)))\n\t\treturn parent;\n\trcu_read_lock();\n\tspin_unlock(&dentry->d_lock);\nagain:\n\tparent = ACCESS_ONCE(dentry->d_parent);\n\tspin_lock(&parent->d_lock);\n\t/*\n\t * We can't blindly lock dentry until we are sure\n\t * that we won't violate the locking order.\n\t * Any changes of dentry->d_parent must have\n\t * been done with parent->d_lock held, so\n\t * spin_lock() above is enough of a barrier\n\t * for checking if it's still our child.\n\t */\n\tif (unlikely(parent != dentry->d_parent)) {\n\t\tspin_unlock(&parent->d_lock);\n\t\tgoto again;\n\t}\n\trcu_read_unlock();\n\tif (parent != dentry)\n\t\tspin_lock_nested(&dentry->d_lock, DENTRY_D_LOCK_NESTED);\n\telse\n\t\tparent = NULL;\n\treturn parent;\n}\n\n/*\n * Try to do a lockless dput(), and return whether that was successful.\n *\n * If unsuccessful, we return false, having already taken the dentry lock.\n *\n * The caller needs to hold the RCU read lock, so that the dentry is\n * guaranteed to stay around even if the refcount goes down to zero!\n */\nstatic inline bool fast_dput(struct dentry *dentry)\n{\n\tint ret;\n\tunsigned int d_flags;\n\n\t/*\n\t * If we have a d_op->d_delete() operation, we sould not\n\t * let the dentry count go to zero, so use \"put_or_lock\".\n\t */\n\tif (unlikely(dentry->d_flags & DCACHE_OP_DELETE))\n\t\treturn lockref_put_or_lock(&dentry->d_lockref);\n\n\t/*\n\t * .. otherwise, we can try to just decrement the\n\t * lockref optimistically.\n\t */\n\tret = lockref_put_return(&dentry->d_lockref);\n\n\t/*\n\t * If the lockref_put_return() failed due to the lock being held\n\t * by somebody else, the fast path has failed. We will need to\n\t * get the lock, and then check the count again.\n\t */\n\tif (unlikely(ret < 0)) {\n\t\tspin_lock(&dentry->d_lock);\n\t\tif (dentry->d_lockref.count > 1) {\n\t\t\tdentry->d_lockref.count--;\n\t\t\tspin_unlock(&dentry->d_lock);\n\t\t\treturn 1;\n\t\t}\n\t\treturn 0;\n\t}\n\n\t/*\n\t * If we weren't the last ref, we're done.\n\t */\n\tif (ret)\n\t\treturn 1;\n\n\t/*\n\t * Careful, careful. The reference count went down\n\t * to zero, but we don't hold the dentry lock, so\n\t * somebody else could get it again, and do another\n\t * dput(), and we need to not race with that.\n\t *\n\t * However, there is a very special and common case\n\t * where we don't care, because there is nothing to\n\t * do: the dentry is still hashed, it does not have\n\t * a 'delete' op, and it's referenced and already on\n\t * the LRU list.\n\t *\n\t * NOTE! Since we aren't locked, these values are\n\t * not \"stable\". However, it is sufficient that at\n\t * some point after we dropped the reference the\n\t * dentry was hashed and the flags had the proper\n\t * value. Other dentry users may have re-gotten\n\t * a reference to the dentry and change that, but\n\t * our work is done - we can leave the dentry\n\t * around with a zero refcount.\n\t */\n\tsmp_rmb();\n\td_flags = ACCESS_ONCE(dentry->d_flags);\n\td_flags &= DCACHE_REFERENCED | DCACHE_LRU_LIST | DCACHE_DISCONNECTED;\n\n\t/* Nothing to do? Dropping the reference was all we needed? */\n\tif (d_flags == (DCACHE_REFERENCED | DCACHE_LRU_LIST) && !d_unhashed(dentry))\n\t\treturn 1;\n\n\t/*\n\t * Not the fast normal case? Get the lock. We've already decremented\n\t * the refcount, but we'll need to re-check the situation after\n\t * getting the lock.\n\t */\n\tspin_lock(&dentry->d_lock);\n\n\t/*\n\t * Did somebody else grab a reference to it in the meantime, and\n\t * we're no longer the last user after all? Alternatively, somebody\n\t * else could have killed it and marked it dead. Either way, we\n\t * don't need to do anything else.\n\t */\n\tif (dentry->d_lockref.count) {\n\t\tspin_unlock(&dentry->d_lock);\n\t\treturn 1;\n\t}\n\n\t/*\n\t * Re-get the reference we optimistically dropped. We hold the\n\t * lock, and we just tested that it was zero, so we can just\n\t * set it to 1.\n\t */\n\tdentry->d_lockref.count = 1;\n\treturn 0;\n}\n\n\n/* \n * This is dput\n *\n * This is complicated by the fact that we do not want to put\n * dentries that are no longer on any hash chain on the unused\n * list: we'd much rather just get rid of them immediately.\n *\n * However, that implies that we have to traverse the dentry\n * tree upwards to the parents which might _also_ now be\n * scheduled for deletion (it may have been only waiting for\n * its last child to go away).\n *\n * This tail recursion is done by hand as we don't want to depend\n * on the compiler to always get this right (gcc generally doesn't).\n * Real recursion would eat up our stack space.\n */\n\n/*\n * dput - release a dentry\n * @dentry: dentry to release \n *\n * Release a dentry. This will drop the usage count and if appropriate\n * call the dentry unlink method as well as removing it from the queues and\n * releasing its resources. If the parent dentries were scheduled for release\n * they too may now get deleted.\n */\nvoid dput(struct dentry *dentry)\n{\n\tif (unlikely(!dentry))\n\t\treturn;\n\nrepeat:\n\tmight_sleep();\n\n\trcu_read_lock();\n\tif (likely(fast_dput(dentry))) {\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\n\t/* Slow case: now with the dentry lock held */\n\trcu_read_unlock();\n\n\tWARN_ON(d_in_lookup(dentry));\n\n\t/* Unreachable? Get rid of it */\n\tif (unlikely(d_unhashed(dentry)))\n\t\tgoto kill_it;\n\n\tif (unlikely(dentry->d_flags & DCACHE_DISCONNECTED))\n\t\tgoto kill_it;\n\n\tif (unlikely(dentry->d_flags & DCACHE_OP_DELETE)) {\n\t\tif (dentry->d_op->d_delete(dentry))\n\t\t\tgoto kill_it;\n\t}\n\n\tdentry_lru_add(dentry);\n\n\tdentry->d_lockref.count--;\n\tspin_unlock(&dentry->d_lock);\n\treturn;\n\nkill_it:\n\tdentry = dentry_kill(dentry);\n\tif (dentry) {\n\t\tcond_resched();\n\t\tgoto repeat;\n\t}\n}\nEXPORT_SYMBOL(dput);\n\n\n/* This must be called with d_lock held */\nstatic inline void __dget_dlock(struct dentry *dentry)\n{\n\tdentry->d_lockref.count++;\n}\n\nstatic inline void __dget(struct dentry *dentry)\n{\n\tlockref_get(&dentry->d_lockref);\n}\n\nstruct dentry *dget_parent(struct dentry *dentry)\n{\n\tint gotref;\n\tstruct dentry *ret;\n\n\t/*\n\t * Do optimistic parent lookup without any\n\t * locking.\n\t */\n\trcu_read_lock();\n\tret = ACCESS_ONCE(dentry->d_parent);\n\tgotref = lockref_get_not_zero(&ret->d_lockref);\n\trcu_read_unlock();\n\tif (likely(gotref)) {\n\t\tif (likely(ret == ACCESS_ONCE(dentry->d_parent)))\n\t\t\treturn ret;\n\t\tdput(ret);\n\t}\n\nrepeat:\n\t/*\n\t * Don't need rcu_dereference because we re-check it was correct under\n\t * the lock.\n\t */\n\trcu_read_lock();\n\tret = dentry->d_parent;\n\tspin_lock(&ret->d_lock);\n\tif (unlikely(ret != dentry->d_parent)) {\n\t\tspin_unlock(&ret->d_lock);\n\t\trcu_read_unlock();\n\t\tgoto repeat;\n\t}\n\trcu_read_unlock();\n\tBUG_ON(!ret->d_lockref.count);\n\tret->d_lockref.count++;\n\tspin_unlock(&ret->d_lock);\n\treturn ret;\n}\nEXPORT_SYMBOL(dget_parent);\n\n/**\n * d_find_alias - grab a hashed alias of inode\n * @inode: inode in question\n *\n * If inode has a hashed alias, or is a directory and has any alias,\n * acquire the reference to alias and return it. Otherwise return NULL.\n * Notice that if inode is a directory there can be only one alias and\n * it can be unhashed only if it has no children, or if it is the root\n * of a filesystem, or if the directory was renamed and d_revalidate\n * was the first vfs operation to notice.\n *\n * If the inode has an IS_ROOT, DCACHE_DISCONNECTED alias, then prefer\n * any other hashed alias over that one.\n */\nstatic struct dentry *__d_find_alias(struct inode *inode)\n{\n\tstruct dentry *alias, *discon_alias;\n\nagain:\n\tdiscon_alias = NULL;\n\thlist_for_each_entry(alias, &inode->i_dentry, d_u.d_alias) {\n\t\tspin_lock(&alias->d_lock);\n \t\tif (S_ISDIR(inode->i_mode) || !d_unhashed(alias)) {\n\t\t\tif (IS_ROOT(alias) &&\n\t\t\t    (alias->d_flags & DCACHE_DISCONNECTED)) {\n\t\t\t\tdiscon_alias = alias;\n\t\t\t} else {\n\t\t\t\t__dget_dlock(alias);\n\t\t\t\tspin_unlock(&alias->d_lock);\n\t\t\t\treturn alias;\n\t\t\t}\n\t\t}\n\t\tspin_unlock(&alias->d_lock);\n\t}\n\tif (discon_alias) {\n\t\talias = discon_alias;\n\t\tspin_lock(&alias->d_lock);\n\t\tif (S_ISDIR(inode->i_mode) || !d_unhashed(alias)) {\n\t\t\t__dget_dlock(alias);\n\t\t\tspin_unlock(&alias->d_lock);\n\t\t\treturn alias;\n\t\t}\n\t\tspin_unlock(&alias->d_lock);\n\t\tgoto again;\n\t}\n\treturn NULL;\n}\n\nstruct dentry *d_find_alias(struct inode *inode)\n{\n\tstruct dentry *de = NULL;\n\n\tif (!hlist_empty(&inode->i_dentry)) {\n\t\tspin_lock(&inode->i_lock);\n\t\tde = __d_find_alias(inode);\n\t\tspin_unlock(&inode->i_lock);\n\t}\n\treturn de;\n}\nEXPORT_SYMBOL(d_find_alias);\n\n/*\n *\tTry to kill dentries associated with this inode.\n * WARNING: you must own a reference to inode.\n */\nvoid d_prune_aliases(struct inode *inode)\n{\n\tstruct dentry *dentry;\nrestart:\n\tspin_lock(&inode->i_lock);\n\thlist_for_each_entry(dentry, &inode->i_dentry, d_u.d_alias) {\n\t\tspin_lock(&dentry->d_lock);\n\t\tif (!dentry->d_lockref.count) {\n\t\t\tstruct dentry *parent = lock_parent(dentry);\n\t\t\tif (likely(!dentry->d_lockref.count)) {\n\t\t\t\t__dentry_kill(dentry);\n\t\t\t\tdput(parent);\n\t\t\t\tgoto restart;\n\t\t\t}\n\t\t\tif (parent)\n\t\t\t\tspin_unlock(&parent->d_lock);\n\t\t}\n\t\tspin_unlock(&dentry->d_lock);\n\t}\n\tspin_unlock(&inode->i_lock);\n}\nEXPORT_SYMBOL(d_prune_aliases);\n\nstatic void shrink_dentry_list(struct list_head *list)\n{\n\tstruct dentry *dentry, *parent;\n\n\twhile (!list_empty(list)) {\n\t\tstruct inode *inode;\n\t\tdentry = list_entry(list->prev, struct dentry, d_lru);\n\t\tspin_lock(&dentry->d_lock);\n\t\tparent = lock_parent(dentry);\n\n\t\t/*\n\t\t * The dispose list is isolated and dentries are not accounted\n\t\t * to the LRU here, so we can simply remove it from the list\n\t\t * here regardless of whether it is referenced or not.\n\t\t */\n\t\td_shrink_del(dentry);\n\n\t\t/*\n\t\t * We found an inuse dentry which was not removed from\n\t\t * the LRU because of laziness during lookup. Do not free it.\n\t\t */\n\t\tif (dentry->d_lockref.count > 0) {\n\t\t\tspin_unlock(&dentry->d_lock);\n\t\t\tif (parent)\n\t\t\t\tspin_unlock(&parent->d_lock);\n\t\t\tcontinue;\n\t\t}\n\n\n\t\tif (unlikely(dentry->d_flags & DCACHE_DENTRY_KILLED)) {\n\t\t\tbool can_free = dentry->d_flags & DCACHE_MAY_FREE;\n\t\t\tspin_unlock(&dentry->d_lock);\n\t\t\tif (parent)\n\t\t\t\tspin_unlock(&parent->d_lock);\n\t\t\tif (can_free)\n\t\t\t\tdentry_free(dentry);\n\t\t\tcontinue;\n\t\t}\n\n\t\tinode = dentry->d_inode;\n\t\tif (inode && unlikely(!spin_trylock(&inode->i_lock))) {\n\t\t\td_shrink_add(dentry, list);\n\t\t\tspin_unlock(&dentry->d_lock);\n\t\t\tif (parent)\n\t\t\t\tspin_unlock(&parent->d_lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\t__dentry_kill(dentry);\n\n\t\t/*\n\t\t * We need to prune ancestors too. This is necessary to prevent\n\t\t * quadratic behavior of shrink_dcache_parent(), but is also\n\t\t * expected to be beneficial in reducing dentry cache\n\t\t * fragmentation.\n\t\t */\n\t\tdentry = parent;\n\t\twhile (dentry && !lockref_put_or_lock(&dentry->d_lockref)) {\n\t\t\tparent = lock_parent(dentry);\n\t\t\tif (dentry->d_lockref.count != 1) {\n\t\t\t\tdentry->d_lockref.count--;\n\t\t\t\tspin_unlock(&dentry->d_lock);\n\t\t\t\tif (parent)\n\t\t\t\t\tspin_unlock(&parent->d_lock);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tinode = dentry->d_inode;\t/* can't be NULL */\n\t\t\tif (unlikely(!spin_trylock(&inode->i_lock))) {\n\t\t\t\tspin_unlock(&dentry->d_lock);\n\t\t\t\tif (parent)\n\t\t\t\t\tspin_unlock(&parent->d_lock);\n\t\t\t\tcpu_relax();\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t__dentry_kill(dentry);\n\t\t\tdentry = parent;\n\t\t}\n\t}\n}\n\nstatic enum lru_status dentry_lru_isolate(struct list_head *item,\n\t\tstruct list_lru_one *lru, spinlock_t *lru_lock, void *arg)\n{\n\tstruct list_head *freeable = arg;\n\tstruct dentry\t*dentry = container_of(item, struct dentry, d_lru);\n\n\n\t/*\n\t * we are inverting the lru lock/dentry->d_lock here,\n\t * so use a trylock. If we fail to get the lock, just skip\n\t * it\n\t */\n\tif (!spin_trylock(&dentry->d_lock))\n\t\treturn LRU_SKIP;\n\n\t/*\n\t * Referenced dentries are still in use. If they have active\n\t * counts, just remove them from the LRU. Otherwise give them\n\t * another pass through the LRU.\n\t */\n\tif (dentry->d_lockref.count) {\n\t\td_lru_isolate(lru, dentry);\n\t\tspin_unlock(&dentry->d_lock);\n\t\treturn LRU_REMOVED;\n\t}\n\n\tif (dentry->d_flags & DCACHE_REFERENCED) {\n\t\tdentry->d_flags &= ~DCACHE_REFERENCED;\n\t\tspin_unlock(&dentry->d_lock);\n\n\t\t/*\n\t\t * The list move itself will be made by the common LRU code. At\n\t\t * this point, we've dropped the dentry->d_lock but keep the\n\t\t * lru lock. This is safe to do, since every list movement is\n\t\t * protected by the lru lock even if both locks are held.\n\t\t *\n\t\t * This is guaranteed by the fact that all LRU management\n\t\t * functions are intermediated by the LRU API calls like\n\t\t * list_lru_add and list_lru_del. List movement in this file\n\t\t * only ever occur through this functions or through callbacks\n\t\t * like this one, that are called from the LRU API.\n\t\t *\n\t\t * The only exceptions to this are functions like\n\t\t * shrink_dentry_list, and code that first checks for the\n\t\t * DCACHE_SHRINK_LIST flag.  Those are guaranteed to be\n\t\t * operating only with stack provided lists after they are\n\t\t * properly isolated from the main list.  It is thus, always a\n\t\t * local access.\n\t\t */\n\t\treturn LRU_ROTATE;\n\t}\n\n\td_lru_shrink_move(lru, dentry, freeable);\n\tspin_unlock(&dentry->d_lock);\n\n\treturn LRU_REMOVED;\n}\n\n/**\n * prune_dcache_sb - shrink the dcache\n * @sb: superblock\n * @sc: shrink control, passed to list_lru_shrink_walk()\n *\n * Attempt to shrink the superblock dcache LRU by @sc->nr_to_scan entries. This\n * is done when we need more memory and called from the superblock shrinker\n * function.\n *\n * This function may fail to free any resources if all the dentries are in\n * use.\n */\nlong prune_dcache_sb(struct super_block *sb, struct shrink_control *sc)\n{\n\tLIST_HEAD(dispose);\n\tlong freed;\n\n\tfreed = list_lru_shrink_walk(&sb->s_dentry_lru, sc,\n\t\t\t\t     dentry_lru_isolate, &dispose);\n\tshrink_dentry_list(&dispose);\n\treturn freed;\n}\n\nstatic enum lru_status dentry_lru_isolate_shrink(struct list_head *item,\n\t\tstruct list_lru_one *lru, spinlock_t *lru_lock, void *arg)\n{\n\tstruct list_head *freeable = arg;\n\tstruct dentry\t*dentry = container_of(item, struct dentry, d_lru);\n\n\t/*\n\t * we are inverting the lru lock/dentry->d_lock here,\n\t * so use a trylock. If we fail to get the lock, just skip\n\t * it\n\t */\n\tif (!spin_trylock(&dentry->d_lock))\n\t\treturn LRU_SKIP;\n\n\td_lru_shrink_move(lru, dentry, freeable);\n\tspin_unlock(&dentry->d_lock);\n\n\treturn LRU_REMOVED;\n}\n\n\n/**\n * shrink_dcache_sb - shrink dcache for a superblock\n * @sb: superblock\n *\n * Shrink the dcache for the specified super block. This is used to free\n * the dcache before unmounting a file system.\n */\nvoid shrink_dcache_sb(struct super_block *sb)\n{\n\tlong freed;\n\n\tdo {\n\t\tLIST_HEAD(dispose);\n\n\t\tfreed = list_lru_walk(&sb->s_dentry_lru,\n\t\t\tdentry_lru_isolate_shrink, &dispose, UINT_MAX);\n\n\t\tthis_cpu_sub(nr_dentry_unused, freed);\n\t\tshrink_dentry_list(&dispose);\n\t} while (freed > 0);\n}\nEXPORT_SYMBOL(shrink_dcache_sb);\n\n/**\n * enum d_walk_ret - action to talke during tree walk\n * @D_WALK_CONTINUE:\tcontrinue walk\n * @D_WALK_QUIT:\tquit walk\n * @D_WALK_NORETRY:\tquit when retry is needed\n * @D_WALK_SKIP:\tskip this dentry and its children\n */\nenum d_walk_ret {\n\tD_WALK_CONTINUE,\n\tD_WALK_QUIT,\n\tD_WALK_NORETRY,\n\tD_WALK_SKIP,\n};\n\n/**\n * d_walk - walk the dentry tree\n * @parent:\tstart of walk\n * @data:\tdata passed to @enter() and @finish()\n * @enter:\tcallback when first entering the dentry\n * @finish:\tcallback when successfully finished the walk\n *\n * The @enter() and @finish() callbacks are called with d_lock held.\n */\nstatic void d_walk(struct dentry *parent, void *data,\n\t\t   enum d_walk_ret (*enter)(void *, struct dentry *),\n\t\t   void (*finish)(void *))\n{\n\tstruct dentry *this_parent;\n\tstruct list_head *next;\n\tunsigned seq = 0;\n\tenum d_walk_ret ret;\n\tbool retry = true;\n\nagain:\n\tread_seqbegin_or_lock(&rename_lock, &seq);\n\tthis_parent = parent;\n\tspin_lock(&this_parent->d_lock);\n\n\tret = enter(data, this_parent);\n\tswitch (ret) {\n\tcase D_WALK_CONTINUE:\n\t\tbreak;\n\tcase D_WALK_QUIT:\n\tcase D_WALK_SKIP:\n\t\tgoto out_unlock;\n\tcase D_WALK_NORETRY:\n\t\tretry = false;\n\t\tbreak;\n\t}\nrepeat:\n\tnext = this_parent->d_subdirs.next;\nresume:\n\twhile (next != &this_parent->d_subdirs) {\n\t\tstruct list_head *tmp = next;\n\t\tstruct dentry *dentry = list_entry(tmp, struct dentry, d_child);\n\t\tnext = tmp->next;\n\n\t\tif (unlikely(dentry->d_flags & DCACHE_DENTRY_CURSOR))\n\t\t\tcontinue;\n\n\t\tspin_lock_nested(&dentry->d_lock, DENTRY_D_LOCK_NESTED);\n\n\t\tret = enter(data, dentry);\n\t\tswitch (ret) {\n\t\tcase D_WALK_CONTINUE:\n\t\t\tbreak;\n\t\tcase D_WALK_QUIT:\n\t\t\tspin_unlock(&dentry->d_lock);\n\t\t\tgoto out_unlock;\n\t\tcase D_WALK_NORETRY:\n\t\t\tretry = false;\n\t\t\tbreak;\n\t\tcase D_WALK_SKIP:\n\t\t\tspin_unlock(&dentry->d_lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!list_empty(&dentry->d_subdirs)) {\n\t\t\tspin_unlock(&this_parent->d_lock);\n\t\t\tspin_release(&dentry->d_lock.dep_map, 1, _RET_IP_);\n\t\t\tthis_parent = dentry;\n\t\t\tspin_acquire(&this_parent->d_lock.dep_map, 0, 1, _RET_IP_);\n\t\t\tgoto repeat;\n\t\t}\n\t\tspin_unlock(&dentry->d_lock);\n\t}\n\t/*\n\t * All done at this level ... ascend and resume the search.\n\t */\n\trcu_read_lock();\nascend:\n\tif (this_parent != parent) {\n\t\tstruct dentry *child = this_parent;\n\t\tthis_parent = child->d_parent;\n\n\t\tspin_unlock(&child->d_lock);\n\t\tspin_lock(&this_parent->d_lock);\n\n\t\t/* might go back up the wrong parent if we have had a rename. */\n\t\tif (need_seqretry(&rename_lock, seq))\n\t\t\tgoto rename_retry;\n\t\t/* go into the first sibling still alive */\n\t\tdo {\n\t\t\tnext = child->d_child.next;\n\t\t\tif (next == &this_parent->d_subdirs)\n\t\t\t\tgoto ascend;\n\t\t\tchild = list_entry(next, struct dentry, d_child);\n\t\t} while (unlikely(child->d_flags & DCACHE_DENTRY_KILLED));\n\t\trcu_read_unlock();\n\t\tgoto resume;\n\t}\n\tif (need_seqretry(&rename_lock, seq))\n\t\tgoto rename_retry;\n\trcu_read_unlock();\n\tif (finish)\n\t\tfinish(data);\n\nout_unlock:\n\tspin_unlock(&this_parent->d_lock);\n\tdone_seqretry(&rename_lock, seq);\n\treturn;\n\nrename_retry:\n\tspin_unlock(&this_parent->d_lock);\n\trcu_read_unlock();\n\tBUG_ON(seq & 1);\n\tif (!retry)\n\t\treturn;\n\tseq = 1;\n\tgoto again;\n}\n\nstruct check_mount {\n\tstruct vfsmount *mnt;\n\tunsigned int mounted;\n};\n\nstatic enum d_walk_ret path_check_mount(void *data, struct dentry *dentry)\n{\n\tstruct check_mount *info = data;\n\tstruct path path = { .mnt = info->mnt, .dentry = dentry };\n\n\tif (likely(!d_mountpoint(dentry)))\n\t\treturn D_WALK_CONTINUE;\n\tif (__path_is_mountpoint(&path)) {\n\t\tinfo->mounted = 1;\n\t\treturn D_WALK_QUIT;\n\t}\n\treturn D_WALK_CONTINUE;\n}\n\n/**\n * path_has_submounts - check for mounts over a dentry in the\n *                      current namespace.\n * @parent: path to check.\n *\n * Return true if the parent or its subdirectories contain\n * a mount point in the current namespace.\n */\nint path_has_submounts(const struct path *parent)\n{\n\tstruct check_mount data = { .mnt = parent->mnt, .mounted = 0 };\n\n\tread_seqlock_excl(&mount_lock);\n\td_walk(parent->dentry, &data, path_check_mount, NULL);\n\tread_sequnlock_excl(&mount_lock);\n\n\treturn data.mounted;\n}\nEXPORT_SYMBOL(path_has_submounts);\n\n/*\n * Called by mount code to set a mountpoint and check if the mountpoint is\n * reachable (e.g. NFS can unhash a directory dentry and then the complete\n * subtree can become unreachable).\n *\n * Only one of d_invalidate() and d_set_mounted() must succeed.  For\n * this reason take rename_lock and d_lock on dentry and ancestors.\n */\nint d_set_mounted(struct dentry *dentry)\n{\n\tstruct dentry *p;\n\tint ret = -ENOENT;\n\twrite_seqlock(&rename_lock);\n\tfor (p = dentry->d_parent; !IS_ROOT(p); p = p->d_parent) {\n\t\t/* Need exclusion wrt. d_invalidate() */\n\t\tspin_lock(&p->d_lock);\n\t\tif (unlikely(d_unhashed(p))) {\n\t\t\tspin_unlock(&p->d_lock);\n\t\t\tgoto out;\n\t\t}\n\t\tspin_unlock(&p->d_lock);\n\t}\n\tspin_lock(&dentry->d_lock);\n\tif (!d_unlinked(dentry)) {\n\t\tret = -EBUSY;\n\t\tif (!d_mountpoint(dentry)) {\n\t\t\tdentry->d_flags |= DCACHE_MOUNTED;\n\t\t\tret = 0;\n\t\t}\n\t}\n \tspin_unlock(&dentry->d_lock);\nout:\n\twrite_sequnlock(&rename_lock);\n\treturn ret;\n}\n\n/*\n * Search the dentry child list of the specified parent,\n * and move any unused dentries to the end of the unused\n * list for prune_dcache(). We descend to the next level\n * whenever the d_subdirs list is non-empty and continue\n * searching.\n *\n * It returns zero iff there are no unused children,\n * otherwise  it returns the number of children moved to\n * the end of the unused list. This may not be the total\n * number of unused children, because select_parent can\n * drop the lock and return early due to latency\n * constraints.\n */\n\nstruct select_data {\n\tstruct dentry *start;\n\tstruct list_head dispose;\n\tint found;\n};\n\nstatic enum d_walk_ret select_collect(void *_data, struct dentry *dentry)\n{\n\tstruct select_data *data = _data;\n\tenum d_walk_ret ret = D_WALK_CONTINUE;\n\n\tif (data->start == dentry)\n\t\tgoto out;\n\n\tif (dentry->d_flags & DCACHE_SHRINK_LIST) {\n\t\tdata->found++;\n\t} else {\n\t\tif (dentry->d_flags & DCACHE_LRU_LIST)\n\t\t\td_lru_del(dentry);\n\t\tif (!dentry->d_lockref.count) {\n\t\t\td_shrink_add(dentry, &data->dispose);\n\t\t\tdata->found++;\n\t\t}\n\t}\n\t/*\n\t * We can return to the caller if we have found some (this\n\t * ensures forward progress). We'll be coming back to find\n\t * the rest.\n\t */\n\tif (!list_empty(&data->dispose))\n\t\tret = need_resched() ? D_WALK_QUIT : D_WALK_NORETRY;\nout:\n\treturn ret;\n}\n\n/**\n * shrink_dcache_parent - prune dcache\n * @parent: parent of entries to prune\n *\n * Prune the dcache to remove unused children of the parent dentry.\n */\nvoid shrink_dcache_parent(struct dentry *parent)\n{\n\tfor (;;) {\n\t\tstruct select_data data;\n\n\t\tINIT_LIST_HEAD(&data.dispose);\n\t\tdata.start = parent;\n\t\tdata.found = 0;\n\n\t\td_walk(parent, &data, select_collect, NULL);\n\t\tif (!data.found)\n\t\t\tbreak;\n\n\t\tshrink_dentry_list(&data.dispose);\n\t\tcond_resched();\n\t}\n}\nEXPORT_SYMBOL(shrink_dcache_parent);\n\nstatic enum d_walk_ret umount_check(void *_data, struct dentry *dentry)\n{\n\t/* it has busy descendents; complain about those instead */\n\tif (!list_empty(&dentry->d_subdirs))\n\t\treturn D_WALK_CONTINUE;\n\n\t/* root with refcount 1 is fine */\n\tif (dentry == _data && dentry->d_lockref.count == 1)\n\t\treturn D_WALK_CONTINUE;\n\n\tprintk(KERN_ERR \"BUG: Dentry %p{i=%lx,n=%pd} \"\n\t\t\t\" still in use (%d) [unmount of %s %s]\\n\",\n\t\t       dentry,\n\t\t       dentry->d_inode ?\n\t\t       dentry->d_inode->i_ino : 0UL,\n\t\t       dentry,\n\t\t       dentry->d_lockref.count,\n\t\t       dentry->d_sb->s_type->name,\n\t\t       dentry->d_sb->s_id);\n\tWARN_ON(1);\n\treturn D_WALK_CONTINUE;\n}\n\nstatic void do_one_tree(struct dentry *dentry)\n{\n\tshrink_dcache_parent(dentry);\n\td_walk(dentry, dentry, umount_check, NULL);\n\td_drop(dentry);\n\tdput(dentry);\n}\n\n/*\n * destroy the dentries attached to a superblock on unmounting\n */\nvoid shrink_dcache_for_umount(struct super_block *sb)\n{\n\tstruct dentry *dentry;\n\n\tWARN(down_read_trylock(&sb->s_umount), \"s_umount should've been locked\");\n\n\tdentry = sb->s_root;\n\tsb->s_root = NULL;\n\tdo_one_tree(dentry);\n\n\twhile (!hlist_bl_empty(&sb->s_anon)) {\n\t\tdentry = dget(hlist_bl_entry(hlist_bl_first(&sb->s_anon), struct dentry, d_hash));\n\t\tdo_one_tree(dentry);\n\t}\n}\n\nstruct detach_data {\n\tstruct select_data select;\n\tstruct dentry *mountpoint;\n};\nstatic enum d_walk_ret detach_and_collect(void *_data, struct dentry *dentry)\n{\n\tstruct detach_data *data = _data;\n\n\tif (d_mountpoint(dentry)) {\n\t\t__dget_dlock(dentry);\n\t\tdata->mountpoint = dentry;\n\t\treturn D_WALK_QUIT;\n\t}\n\n\treturn select_collect(&data->select, dentry);\n}\n\nstatic void check_and_drop(void *_data)\n{\n\tstruct detach_data *data = _data;\n\n\tif (!data->mountpoint && list_empty(&data->select.dispose))\n\t\t__d_drop(data->select.start);\n}\n\n/**\n * d_invalidate - detach submounts, prune dcache, and drop\n * @dentry: dentry to invalidate (aka detach, prune and drop)\n *\n * no dcache lock.\n *\n * The final d_drop is done as an atomic operation relative to\n * rename_lock ensuring there are no races with d_set_mounted.  This\n * ensures there are no unhashed dentries on the path to a mountpoint.\n */\nvoid d_invalidate(struct dentry *dentry)\n{\n\t/*\n\t * If it's already been dropped, return OK.\n\t */\n\tspin_lock(&dentry->d_lock);\n\tif (d_unhashed(dentry)) {\n\t\tspin_unlock(&dentry->d_lock);\n\t\treturn;\n\t}\n\tspin_unlock(&dentry->d_lock);\n\n\t/* Negative dentries can be dropped without further checks */\n\tif (!dentry->d_inode) {\n\t\td_drop(dentry);\n\t\treturn;\n\t}\n\n\tfor (;;) {\n\t\tstruct detach_data data;\n\n\t\tdata.mountpoint = NULL;\n\t\tINIT_LIST_HEAD(&data.select.dispose);\n\t\tdata.select.start = dentry;\n\t\tdata.select.found = 0;\n\n\t\td_walk(dentry, &data, detach_and_collect, check_and_drop);\n\n\t\tif (!list_empty(&data.select.dispose))\n\t\t\tshrink_dentry_list(&data.select.dispose);\n\t\telse if (!data.mountpoint)\n\t\t\treturn;\n\n\t\tif (data.mountpoint) {\n\t\t\tdetach_mounts(data.mountpoint);\n\t\t\tdput(data.mountpoint);\n\t\t}\n\t\tcond_resched();\n\t}\n}\nEXPORT_SYMBOL(d_invalidate);\n\n/**\n * __d_alloc\t-\tallocate a dcache entry\n * @sb: filesystem it will belong to\n * @name: qstr of the name\n *\n * Allocates a dentry. It returns %NULL if there is insufficient memory\n * available. On a success the dentry is returned. The name passed in is\n * copied and the copy passed in may be reused after this call.\n */\n \nstruct dentry *__d_alloc(struct super_block *sb, const struct qstr *name)\n{\n\tstruct dentry *dentry;\n\tchar *dname;\n\tint err;\n\n\tdentry = kmem_cache_alloc(dentry_cache, GFP_KERNEL);\n\tif (!dentry)\n\t\treturn NULL;\n\n\t/*\n\t * We guarantee that the inline name is always NUL-terminated.\n\t * This way the memcpy() done by the name switching in rename\n\t * will still always have a NUL at the end, even if we might\n\t * be overwriting an internal NUL character\n\t */\n\tdentry->d_iname[DNAME_INLINE_LEN-1] = 0;\n\tif (unlikely(!name)) {\n\t\tstatic const struct qstr anon = QSTR_INIT(\"/\", 1);\n\t\tname = &anon;\n\t\tdname = dentry->d_iname;\n\t} else if (name->len > DNAME_INLINE_LEN-1) {\n\t\tsize_t size = offsetof(struct external_name, name[1]);\n\t\tstruct external_name *p = kmalloc(size + name->len,\n\t\t\t\t\t\t  GFP_KERNEL_ACCOUNT);\n\t\tif (!p) {\n\t\t\tkmem_cache_free(dentry_cache, dentry); \n\t\t\treturn NULL;\n\t\t}\n\t\tatomic_set(&p->u.count, 1);\n\t\tdname = p->name;\n\t\tif (IS_ENABLED(CONFIG_DCACHE_WORD_ACCESS))\n\t\t\tkasan_unpoison_shadow(dname,\n\t\t\t\tround_up(name->len + 1,\tsizeof(unsigned long)));\n\t} else  {\n\t\tdname = dentry->d_iname;\n\t}\t\n\n\tdentry->d_name.len = name->len;\n\tdentry->d_name.hash = name->hash;\n\tmemcpy(dname, name->name, name->len);\n\tdname[name->len] = 0;\n\n\t/* Make sure we always see the terminating NUL character */\n\tsmp_wmb();\n\tdentry->d_name.name = dname;\n\n\tdentry->d_lockref.count = 1;\n\tdentry->d_flags = 0;\n\tspin_lock_init(&dentry->d_lock);\n\tseqcount_init(&dentry->d_seq);\n\tdentry->d_inode = NULL;\n\tdentry->d_parent = dentry;\n\tdentry->d_sb = sb;\n\tdentry->d_op = NULL;\n\tdentry->d_fsdata = NULL;\n\tINIT_HLIST_BL_NODE(&dentry->d_hash);\n\tINIT_LIST_HEAD(&dentry->d_lru);\n\tINIT_LIST_HEAD(&dentry->d_subdirs);\n\tINIT_HLIST_NODE(&dentry->d_u.d_alias);\n\tINIT_LIST_HEAD(&dentry->d_child);\n\td_set_d_op(dentry, dentry->d_sb->s_d_op);\n\n\tif (dentry->d_op && dentry->d_op->d_init) {\n\t\terr = dentry->d_op->d_init(dentry);\n\t\tif (err) {\n\t\t\tif (dname_external(dentry))\n\t\t\t\tkfree(external_name(dentry));\n\t\t\tkmem_cache_free(dentry_cache, dentry);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\tthis_cpu_inc(nr_dentry);\n\n\treturn dentry;\n}\n\n/**\n * d_alloc\t-\tallocate a dcache entry\n * @parent: parent of entry to allocate\n * @name: qstr of the name\n *\n * Allocates a dentry. It returns %NULL if there is insufficient memory\n * available. On a success the dentry is returned. The name passed in is\n * copied and the copy passed in may be reused after this call.\n */\nstruct dentry *d_alloc(struct dentry * parent, const struct qstr *name)\n{\n\tstruct dentry *dentry = __d_alloc(parent->d_sb, name);\n\tif (!dentry)\n\t\treturn NULL;\n\tdentry->d_flags |= DCACHE_RCUACCESS;\n\tspin_lock(&parent->d_lock);\n\t/*\n\t * don't need child lock because it is not subject\n\t * to concurrency here\n\t */\n\t__dget_dlock(parent);\n\tdentry->d_parent = parent;\n\tlist_add(&dentry->d_child, &parent->d_subdirs);\n\tspin_unlock(&parent->d_lock);\n\n\treturn dentry;\n}\nEXPORT_SYMBOL(d_alloc);\n\nstruct dentry *d_alloc_cursor(struct dentry * parent)\n{\n\tstruct dentry *dentry = __d_alloc(parent->d_sb, NULL);\n\tif (dentry) {\n\t\tdentry->d_flags |= DCACHE_RCUACCESS | DCACHE_DENTRY_CURSOR;\n\t\tdentry->d_parent = dget(parent);\n\t}\n\treturn dentry;\n}\n\n/**\n * d_alloc_pseudo - allocate a dentry (for lookup-less filesystems)\n * @sb: the superblock\n * @name: qstr of the name\n *\n * For a filesystem that just pins its dentries in memory and never\n * performs lookups at all, return an unhashed IS_ROOT dentry.\n */\nstruct dentry *d_alloc_pseudo(struct super_block *sb, const struct qstr *name)\n{\n\treturn __d_alloc(sb, name);\n}\nEXPORT_SYMBOL(d_alloc_pseudo);\n\nstruct dentry *d_alloc_name(struct dentry *parent, const char *name)\n{\n\tstruct qstr q;\n\n\tq.name = name;\n\tq.hash_len = hashlen_string(parent, name);\n\treturn d_alloc(parent, &q);\n}\nEXPORT_SYMBOL(d_alloc_name);\n\nvoid d_set_d_op(struct dentry *dentry, const struct dentry_operations *op)\n{\n\tWARN_ON_ONCE(dentry->d_op);\n\tWARN_ON_ONCE(dentry->d_flags & (DCACHE_OP_HASH\t|\n\t\t\t\tDCACHE_OP_COMPARE\t|\n\t\t\t\tDCACHE_OP_REVALIDATE\t|\n\t\t\t\tDCACHE_OP_WEAK_REVALIDATE\t|\n\t\t\t\tDCACHE_OP_DELETE\t|\n\t\t\t\tDCACHE_OP_REAL));\n\tdentry->d_op = op;\n\tif (!op)\n\t\treturn;\n\tif (op->d_hash)\n\t\tdentry->d_flags |= DCACHE_OP_HASH;\n\tif (op->d_compare)\n\t\tdentry->d_flags |= DCACHE_OP_COMPARE;\n\tif (op->d_revalidate)\n\t\tdentry->d_flags |= DCACHE_OP_REVALIDATE;\n\tif (op->d_weak_revalidate)\n\t\tdentry->d_flags |= DCACHE_OP_WEAK_REVALIDATE;\n\tif (op->d_delete)\n\t\tdentry->d_flags |= DCACHE_OP_DELETE;\n\tif (op->d_prune)\n\t\tdentry->d_flags |= DCACHE_OP_PRUNE;\n\tif (op->d_real)\n\t\tdentry->d_flags |= DCACHE_OP_REAL;\n\n}\nEXPORT_SYMBOL(d_set_d_op);\n\n\n/*\n * d_set_fallthru - Mark a dentry as falling through to a lower layer\n * @dentry - The dentry to mark\n *\n * Mark a dentry as falling through to the lower layer (as set with\n * d_pin_lower()).  This flag may be recorded on the medium.\n */\nvoid d_set_fallthru(struct dentry *dentry)\n{\n\tspin_lock(&dentry->d_lock);\n\tdentry->d_flags |= DCACHE_FALLTHRU;\n\tspin_unlock(&dentry->d_lock);\n}\nEXPORT_SYMBOL(d_set_fallthru);\n\nstatic unsigned d_flags_for_inode(struct inode *inode)\n{\n\tunsigned add_flags = DCACHE_REGULAR_TYPE;\n\n\tif (!inode)\n\t\treturn DCACHE_MISS_TYPE;\n\n\tif (S_ISDIR(inode->i_mode)) {\n\t\tadd_flags = DCACHE_DIRECTORY_TYPE;\n\t\tif (unlikely(!(inode->i_opflags & IOP_LOOKUP))) {\n\t\t\tif (unlikely(!inode->i_op->lookup))\n\t\t\t\tadd_flags = DCACHE_AUTODIR_TYPE;\n\t\t\telse\n\t\t\t\tinode->i_opflags |= IOP_LOOKUP;\n\t\t}\n\t\tgoto type_determined;\n\t}\n\n\tif (unlikely(!(inode->i_opflags & IOP_NOFOLLOW))) {\n\t\tif (unlikely(inode->i_op->get_link)) {\n\t\t\tadd_flags = DCACHE_SYMLINK_TYPE;\n\t\t\tgoto type_determined;\n\t\t}\n\t\tinode->i_opflags |= IOP_NOFOLLOW;\n\t}\n\n\tif (unlikely(!S_ISREG(inode->i_mode)))\n\t\tadd_flags = DCACHE_SPECIAL_TYPE;\n\ntype_determined:\n\tif (unlikely(IS_AUTOMOUNT(inode)))\n\t\tadd_flags |= DCACHE_NEED_AUTOMOUNT;\n\treturn add_flags;\n}\n\nstatic void __d_instantiate(struct dentry *dentry, struct inode *inode)\n{\n\tunsigned add_flags = d_flags_for_inode(inode);\n\tWARN_ON(d_in_lookup(dentry));\n\n\tspin_lock(&dentry->d_lock);\n\thlist_add_head(&dentry->d_u.d_alias, &inode->i_dentry);\n\traw_write_seqcount_begin(&dentry->d_seq);\n\t__d_set_inode_and_type(dentry, inode, add_flags);\n\traw_write_seqcount_end(&dentry->d_seq);\n\tfsnotify_update_flags(dentry);\n\tspin_unlock(&dentry->d_lock);\n}\n\n/**\n * d_instantiate - fill in inode information for a dentry\n * @entry: dentry to complete\n * @inode: inode to attach to this dentry\n *\n * Fill in inode information in the entry.\n *\n * This turns negative dentries into productive full members\n * of society.\n *\n * NOTE! This assumes that the inode count has been incremented\n * (or otherwise set) by the caller to indicate that it is now\n * in use by the dcache.\n */\n \nvoid d_instantiate(struct dentry *entry, struct inode * inode)\n{\n\tBUG_ON(!hlist_unhashed(&entry->d_u.d_alias));\n\tif (inode) {\n\t\tsecurity_d_instantiate(entry, inode);\n\t\tspin_lock(&inode->i_lock);\n\t\t__d_instantiate(entry, inode);\n\t\tspin_unlock(&inode->i_lock);\n\t}\n}\nEXPORT_SYMBOL(d_instantiate);\n\n/**\n * d_instantiate_no_diralias - instantiate a non-aliased dentry\n * @entry: dentry to complete\n * @inode: inode to attach to this dentry\n *\n * Fill in inode information in the entry.  If a directory alias is found, then\n * return an error (and drop inode).  Together with d_materialise_unique() this\n * guarantees that a directory inode may never have more than one alias.\n */\nint d_instantiate_no_diralias(struct dentry *entry, struct inode *inode)\n{\n\tBUG_ON(!hlist_unhashed(&entry->d_u.d_alias));\n\n\tsecurity_d_instantiate(entry, inode);\n\tspin_lock(&inode->i_lock);\n\tif (S_ISDIR(inode->i_mode) && !hlist_empty(&inode->i_dentry)) {\n\t\tspin_unlock(&inode->i_lock);\n\t\tiput(inode);\n\t\treturn -EBUSY;\n\t}\n\t__d_instantiate(entry, inode);\n\tspin_unlock(&inode->i_lock);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(d_instantiate_no_diralias);\n\nstruct dentry *d_make_root(struct inode *root_inode)\n{\n\tstruct dentry *res = NULL;\n\n\tif (root_inode) {\n\t\tres = __d_alloc(root_inode->i_sb, NULL);\n\t\tif (res)\n\t\t\td_instantiate(res, root_inode);\n\t\telse\n\t\t\tiput(root_inode);\n\t}\n\treturn res;\n}\nEXPORT_SYMBOL(d_make_root);\n\nstatic struct dentry * __d_find_any_alias(struct inode *inode)\n{\n\tstruct dentry *alias;\n\n\tif (hlist_empty(&inode->i_dentry))\n\t\treturn NULL;\n\talias = hlist_entry(inode->i_dentry.first, struct dentry, d_u.d_alias);\n\t__dget(alias);\n\treturn alias;\n}\n\n/**\n * d_find_any_alias - find any alias for a given inode\n * @inode: inode to find an alias for\n *\n * If any aliases exist for the given inode, take and return a\n * reference for one of them.  If no aliases exist, return %NULL.\n */\nstruct dentry *d_find_any_alias(struct inode *inode)\n{\n\tstruct dentry *de;\n\n\tspin_lock(&inode->i_lock);\n\tde = __d_find_any_alias(inode);\n\tspin_unlock(&inode->i_lock);\n\treturn de;\n}\nEXPORT_SYMBOL(d_find_any_alias);\n\nstatic struct dentry *__d_obtain_alias(struct inode *inode, int disconnected)\n{\n\tstruct dentry *tmp;\n\tstruct dentry *res;\n\tunsigned add_flags;\n\n\tif (!inode)\n\t\treturn ERR_PTR(-ESTALE);\n\tif (IS_ERR(inode))\n\t\treturn ERR_CAST(inode);\n\n\tres = d_find_any_alias(inode);\n\tif (res)\n\t\tgoto out_iput;\n\n\ttmp = __d_alloc(inode->i_sb, NULL);\n\tif (!tmp) {\n\t\tres = ERR_PTR(-ENOMEM);\n\t\tgoto out_iput;\n\t}\n\n\tsecurity_d_instantiate(tmp, inode);\n\tspin_lock(&inode->i_lock);\n\tres = __d_find_any_alias(inode);\n\tif (res) {\n\t\tspin_unlock(&inode->i_lock);\n\t\tdput(tmp);\n\t\tgoto out_iput;\n\t}\n\n\t/* attach a disconnected dentry */\n\tadd_flags = d_flags_for_inode(inode);\n\n\tif (disconnected)\n\t\tadd_flags |= DCACHE_DISCONNECTED;\n\n\tspin_lock(&tmp->d_lock);\n\t__d_set_inode_and_type(tmp, inode, add_flags);\n\thlist_add_head(&tmp->d_u.d_alias, &inode->i_dentry);\n\thlist_bl_lock(&tmp->d_sb->s_anon);\n\thlist_bl_add_head(&tmp->d_hash, &tmp->d_sb->s_anon);\n\thlist_bl_unlock(&tmp->d_sb->s_anon);\n\tspin_unlock(&tmp->d_lock);\n\tspin_unlock(&inode->i_lock);\n\n\treturn tmp;\n\n out_iput:\n\tiput(inode);\n\treturn res;\n}\n\n/**\n * d_obtain_alias - find or allocate a DISCONNECTED dentry for a given inode\n * @inode: inode to allocate the dentry for\n *\n * Obtain a dentry for an inode resulting from NFS filehandle conversion or\n * similar open by handle operations.  The returned dentry may be anonymous,\n * or may have a full name (if the inode was already in the cache).\n *\n * When called on a directory inode, we must ensure that the inode only ever\n * has one dentry.  If a dentry is found, that is returned instead of\n * allocating a new one.\n *\n * On successful return, the reference to the inode has been transferred\n * to the dentry.  In case of an error the reference on the inode is released.\n * To make it easier to use in export operations a %NULL or IS_ERR inode may\n * be passed in and the error will be propagated to the return value,\n * with a %NULL @inode replaced by ERR_PTR(-ESTALE).\n */\nstruct dentry *d_obtain_alias(struct inode *inode)\n{\n\treturn __d_obtain_alias(inode, 1);\n}\nEXPORT_SYMBOL(d_obtain_alias);\n\n/**\n * d_obtain_root - find or allocate a dentry for a given inode\n * @inode: inode to allocate the dentry for\n *\n * Obtain an IS_ROOT dentry for the root of a filesystem.\n *\n * We must ensure that directory inodes only ever have one dentry.  If a\n * dentry is found, that is returned instead of allocating a new one.\n *\n * On successful return, the reference to the inode has been transferred\n * to the dentry.  In case of an error the reference on the inode is\n * released.  A %NULL or IS_ERR inode may be passed in and will be the\n * error will be propagate to the return value, with a %NULL @inode\n * replaced by ERR_PTR(-ESTALE).\n */\nstruct dentry *d_obtain_root(struct inode *inode)\n{\n\treturn __d_obtain_alias(inode, 0);\n}\nEXPORT_SYMBOL(d_obtain_root);\n\n/**\n * d_add_ci - lookup or allocate new dentry with case-exact name\n * @inode:  the inode case-insensitive lookup has found\n * @dentry: the negative dentry that was passed to the parent's lookup func\n * @name:   the case-exact name to be associated with the returned dentry\n *\n * This is to avoid filling the dcache with case-insensitive names to the\n * same inode, only the actual correct case is stored in the dcache for\n * case-insensitive filesystems.\n *\n * For a case-insensitive lookup match and if the the case-exact dentry\n * already exists in in the dcache, use it and return it.\n *\n * If no entry exists with the exact case name, allocate new dentry with\n * the exact case, and return the spliced entry.\n */\nstruct dentry *d_add_ci(struct dentry *dentry, struct inode *inode,\n\t\t\tstruct qstr *name)\n{\n\tstruct dentry *found, *res;\n\n\t/*\n\t * First check if a dentry matching the name already exists,\n\t * if not go ahead and create it now.\n\t */\n\tfound = d_hash_and_lookup(dentry->d_parent, name);\n\tif (found) {\n\t\tiput(inode);\n\t\treturn found;\n\t}\n\tif (d_in_lookup(dentry)) {\n\t\tfound = d_alloc_parallel(dentry->d_parent, name,\n\t\t\t\t\tdentry->d_wait);\n\t\tif (IS_ERR(found) || !d_in_lookup(found)) {\n\t\t\tiput(inode);\n\t\t\treturn found;\n\t\t}\n\t} else {\n\t\tfound = d_alloc(dentry->d_parent, name);\n\t\tif (!found) {\n\t\t\tiput(inode);\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t} \n\t}\n\tres = d_splice_alias(inode, found);\n\tif (res) {\n\t\tdput(found);\n\t\treturn res;\n\t}\n\treturn found;\n}\nEXPORT_SYMBOL(d_add_ci);\n\n\nstatic inline bool d_same_name(const struct dentry *dentry,\n\t\t\t\tconst struct dentry *parent,\n\t\t\t\tconst struct qstr *name)\n{\n\tif (likely(!(parent->d_flags & DCACHE_OP_COMPARE))) {\n\t\tif (dentry->d_name.len != name->len)\n\t\t\treturn false;\n\t\treturn dentry_cmp(dentry, name->name, name->len) == 0;\n\t}\n\treturn parent->d_op->d_compare(dentry,\n\t\t\t\t       dentry->d_name.len, dentry->d_name.name,\n\t\t\t\t       name) == 0;\n}\n\n/**\n * __d_lookup_rcu - search for a dentry (racy, store-free)\n * @parent: parent dentry\n * @name: qstr of name we wish to find\n * @seqp: returns d_seq value at the point where the dentry was found\n * Returns: dentry, or NULL\n *\n * __d_lookup_rcu is the dcache lookup function for rcu-walk name\n * resolution (store-free path walking) design described in\n * Documentation/filesystems/path-lookup.txt.\n *\n * This is not to be used outside core vfs.\n *\n * __d_lookup_rcu must only be used in rcu-walk mode, ie. with vfsmount lock\n * held, and rcu_read_lock held. The returned dentry must not be stored into\n * without taking d_lock and checking d_seq sequence count against @seq\n * returned here.\n *\n * A refcount may be taken on the found dentry with the d_rcu_to_refcount\n * function.\n *\n * Alternatively, __d_lookup_rcu may be called again to look up the child of\n * the returned dentry, so long as its parent's seqlock is checked after the\n * child is looked up. Thus, an interlocking stepping of sequence lock checks\n * is formed, giving integrity down the path walk.\n *\n * NOTE! The caller *has* to check the resulting dentry against the sequence\n * number we've returned before using any of the resulting dentry state!\n */\nstruct dentry *__d_lookup_rcu(const struct dentry *parent,\n\t\t\t\tconst struct qstr *name,\n\t\t\t\tunsigned *seqp)\n{\n\tu64 hashlen = name->hash_len;\n\tconst unsigned char *str = name->name;\n\tstruct hlist_bl_head *b = d_hash(hashlen_hash(hashlen));\n\tstruct hlist_bl_node *node;\n\tstruct dentry *dentry;\n\n\t/*\n\t * Note: There is significant duplication with __d_lookup_rcu which is\n\t * required to prevent single threaded performance regressions\n\t * especially on architectures where smp_rmb (in seqcounts) are costly.\n\t * Keep the two functions in sync.\n\t */\n\n\t/*\n\t * The hash list is protected using RCU.\n\t *\n\t * Carefully use d_seq when comparing a candidate dentry, to avoid\n\t * races with d_move().\n\t *\n\t * It is possible that concurrent renames can mess up our list\n\t * walk here and result in missing our dentry, resulting in the\n\t * false-negative result. d_lookup() protects against concurrent\n\t * renames using rename_lock seqlock.\n\t *\n\t * See Documentation/filesystems/path-lookup.txt for more details.\n\t */\n\thlist_bl_for_each_entry_rcu(dentry, node, b, d_hash) {\n\t\tunsigned seq;\n\nseqretry:\n\t\t/*\n\t\t * The dentry sequence count protects us from concurrent\n\t\t * renames, and thus protects parent and name fields.\n\t\t *\n\t\t * The caller must perform a seqcount check in order\n\t\t * to do anything useful with the returned dentry.\n\t\t *\n\t\t * NOTE! We do a \"raw\" seqcount_begin here. That means that\n\t\t * we don't wait for the sequence count to stabilize if it\n\t\t * is in the middle of a sequence change. If we do the slow\n\t\t * dentry compare, we will do seqretries until it is stable,\n\t\t * and if we end up with a successful lookup, we actually\n\t\t * want to exit RCU lookup anyway.\n\t\t *\n\t\t * Note that raw_seqcount_begin still *does* smp_rmb(), so\n\t\t * we are still guaranteed NUL-termination of ->d_name.name.\n\t\t */\n\t\tseq = raw_seqcount_begin(&dentry->d_seq);\n\t\tif (dentry->d_parent != parent)\n\t\t\tcontinue;\n\t\tif (d_unhashed(dentry))\n\t\t\tcontinue;\n\n\t\tif (unlikely(parent->d_flags & DCACHE_OP_COMPARE)) {\n\t\t\tint tlen;\n\t\t\tconst char *tname;\n\t\t\tif (dentry->d_name.hash != hashlen_hash(hashlen))\n\t\t\t\tcontinue;\n\t\t\ttlen = dentry->d_name.len;\n\t\t\ttname = dentry->d_name.name;\n\t\t\t/* we want a consistent (name,len) pair */\n\t\t\tif (read_seqcount_retry(&dentry->d_seq, seq)) {\n\t\t\t\tcpu_relax();\n\t\t\t\tgoto seqretry;\n\t\t\t}\n\t\t\tif (parent->d_op->d_compare(dentry,\n\t\t\t\t\t\t    tlen, tname, name) != 0)\n\t\t\t\tcontinue;\n\t\t} else {\n\t\t\tif (dentry->d_name.hash_len != hashlen)\n\t\t\t\tcontinue;\n\t\t\tif (dentry_cmp(dentry, str, hashlen_len(hashlen)) != 0)\n\t\t\t\tcontinue;\n\t\t}\n\t\t*seqp = seq;\n\t\treturn dentry;\n\t}\n\treturn NULL;\n}\n\n/**\n * d_lookup - search for a dentry\n * @parent: parent dentry\n * @name: qstr of name we wish to find\n * Returns: dentry, or NULL\n *\n * d_lookup searches the children of the parent dentry for the name in\n * question. If the dentry is found its reference count is incremented and the\n * dentry is returned. The caller must use dput to free the entry when it has\n * finished using it. %NULL is returned if the dentry does not exist.\n */\nstruct dentry *d_lookup(const struct dentry *parent, const struct qstr *name)\n{\n\tstruct dentry *dentry;\n\tunsigned seq;\n\n\tdo {\n\t\tseq = read_seqbegin(&rename_lock);\n\t\tdentry = __d_lookup(parent, name);\n\t\tif (dentry)\n\t\t\tbreak;\n\t} while (read_seqretry(&rename_lock, seq));\n\treturn dentry;\n}\nEXPORT_SYMBOL(d_lookup);\n\n/**\n * __d_lookup - search for a dentry (racy)\n * @parent: parent dentry\n * @name: qstr of name we wish to find\n * Returns: dentry, or NULL\n *\n * __d_lookup is like d_lookup, however it may (rarely) return a\n * false-negative result due to unrelated rename activity.\n *\n * __d_lookup is slightly faster by avoiding rename_lock read seqlock,\n * however it must be used carefully, eg. with a following d_lookup in\n * the case of failure.\n *\n * __d_lookup callers must be commented.\n */\nstruct dentry *__d_lookup(const struct dentry *parent, const struct qstr *name)\n{\n\tunsigned int hash = name->hash;\n\tstruct hlist_bl_head *b = d_hash(hash);\n\tstruct hlist_bl_node *node;\n\tstruct dentry *found = NULL;\n\tstruct dentry *dentry;\n\n\t/*\n\t * Note: There is significant duplication with __d_lookup_rcu which is\n\t * required to prevent single threaded performance regressions\n\t * especially on architectures where smp_rmb (in seqcounts) are costly.\n\t * Keep the two functions in sync.\n\t */\n\n\t/*\n\t * The hash list is protected using RCU.\n\t *\n\t * Take d_lock when comparing a candidate dentry, to avoid races\n\t * with d_move().\n\t *\n\t * It is possible that concurrent renames can mess up our list\n\t * walk here and result in missing our dentry, resulting in the\n\t * false-negative result. d_lookup() protects against concurrent\n\t * renames using rename_lock seqlock.\n\t *\n\t * See Documentation/filesystems/path-lookup.txt for more details.\n\t */\n\trcu_read_lock();\n\t\n\thlist_bl_for_each_entry_rcu(dentry, node, b, d_hash) {\n\n\t\tif (dentry->d_name.hash != hash)\n\t\t\tcontinue;\n\n\t\tspin_lock(&dentry->d_lock);\n\t\tif (dentry->d_parent != parent)\n\t\t\tgoto next;\n\t\tif (d_unhashed(dentry))\n\t\t\tgoto next;\n\n\t\tif (!d_same_name(dentry, parent, name))\n\t\t\tgoto next;\n\n\t\tdentry->d_lockref.count++;\n\t\tfound = dentry;\n\t\tspin_unlock(&dentry->d_lock);\n\t\tbreak;\nnext:\n\t\tspin_unlock(&dentry->d_lock);\n \t}\n \trcu_read_unlock();\n\n \treturn found;\n}\n\n/**\n * d_hash_and_lookup - hash the qstr then search for a dentry\n * @dir: Directory to search in\n * @name: qstr of name we wish to find\n *\n * On lookup failure NULL is returned; on bad name - ERR_PTR(-error)\n */\nstruct dentry *d_hash_and_lookup(struct dentry *dir, struct qstr *name)\n{\n\t/*\n\t * Check for a fs-specific hash function. Note that we must\n\t * calculate the standard hash first, as the d_op->d_hash()\n\t * routine may choose to leave the hash value unchanged.\n\t */\n\tname->hash = full_name_hash(dir, name->name, name->len);\n\tif (dir->d_flags & DCACHE_OP_HASH) {\n\t\tint err = dir->d_op->d_hash(dir, name);\n\t\tif (unlikely(err < 0))\n\t\t\treturn ERR_PTR(err);\n\t}\n\treturn d_lookup(dir, name);\n}\nEXPORT_SYMBOL(d_hash_and_lookup);\n\n/*\n * When a file is deleted, we have two options:\n * - turn this dentry into a negative dentry\n * - unhash this dentry and free it.\n *\n * Usually, we want to just turn this into\n * a negative dentry, but if anybody else is\n * currently using the dentry or the inode\n * we can't do that and we fall back on removing\n * it from the hash queues and waiting for\n * it to be deleted later when it has no users\n */\n \n/**\n * d_delete - delete a dentry\n * @dentry: The dentry to delete\n *\n * Turn the dentry into a negative dentry if possible, otherwise\n * remove it from the hash queues so it can be deleted later\n */\n \nvoid d_delete(struct dentry * dentry)\n{\n\tstruct inode *inode;\n\tint isdir = 0;\n\t/*\n\t * Are we the only user?\n\t */\nagain:\n\tspin_lock(&dentry->d_lock);\n\tinode = dentry->d_inode;\n\tisdir = S_ISDIR(inode->i_mode);\n\tif (dentry->d_lockref.count == 1) {\n\t\tif (!spin_trylock(&inode->i_lock)) {\n\t\t\tspin_unlock(&dentry->d_lock);\n\t\t\tcpu_relax();\n\t\t\tgoto again;\n\t\t}\n\t\tdentry->d_flags &= ~DCACHE_CANT_MOUNT;\n\t\tdentry_unlink_inode(dentry);\n\t\tfsnotify_nameremove(dentry, isdir);\n\t\treturn;\n\t}\n\n\tif (!d_unhashed(dentry))\n\t\t__d_drop(dentry);\n\n\tspin_unlock(&dentry->d_lock);\n\n\tfsnotify_nameremove(dentry, isdir);\n}\nEXPORT_SYMBOL(d_delete);\n\nstatic void __d_rehash(struct dentry *entry)\n{\n\tstruct hlist_bl_head *b = d_hash(entry->d_name.hash);\n\tBUG_ON(!d_unhashed(entry));\n\thlist_bl_lock(b);\n\thlist_bl_add_head_rcu(&entry->d_hash, b);\n\thlist_bl_unlock(b);\n}\n\n/**\n * d_rehash\t- add an entry back to the hash\n * @entry: dentry to add to the hash\n *\n * Adds a dentry to the hash according to its name.\n */\n \nvoid d_rehash(struct dentry * entry)\n{\n\tspin_lock(&entry->d_lock);\n\t__d_rehash(entry);\n\tspin_unlock(&entry->d_lock);\n}\nEXPORT_SYMBOL(d_rehash);\n\nstatic inline unsigned start_dir_add(struct inode *dir)\n{\n\n\tfor (;;) {\n\t\tunsigned n = dir->i_dir_seq;\n\t\tif (!(n & 1) && cmpxchg(&dir->i_dir_seq, n, n + 1) == n)\n\t\t\treturn n;\n\t\tcpu_relax();\n\t}\n}\n\nstatic inline void end_dir_add(struct inode *dir, unsigned n)\n{\n\tsmp_store_release(&dir->i_dir_seq, n + 2);\n}\n\nstatic void d_wait_lookup(struct dentry *dentry)\n{\n\tif (d_in_lookup(dentry)) {\n\t\tDECLARE_WAITQUEUE(wait, current);\n\t\tadd_wait_queue(dentry->d_wait, &wait);\n\t\tdo {\n\t\t\tset_current_state(TASK_UNINTERRUPTIBLE);\n\t\t\tspin_unlock(&dentry->d_lock);\n\t\t\tschedule();\n\t\t\tspin_lock(&dentry->d_lock);\n\t\t} while (d_in_lookup(dentry));\n\t}\n}\n\nstruct dentry *d_alloc_parallel(struct dentry *parent,\n\t\t\t\tconst struct qstr *name,\n\t\t\t\twait_queue_head_t *wq)\n{\n\tunsigned int hash = name->hash;\n\tstruct hlist_bl_head *b = in_lookup_hash(parent, hash);\n\tstruct hlist_bl_node *node;\n\tstruct dentry *new = d_alloc(parent, name);\n\tstruct dentry *dentry;\n\tunsigned seq, r_seq, d_seq;\n\n\tif (unlikely(!new))\n\t\treturn ERR_PTR(-ENOMEM);\n\nretry:\n\trcu_read_lock();\n\tseq = smp_load_acquire(&parent->d_inode->i_dir_seq) & ~1;\n\tr_seq = read_seqbegin(&rename_lock);\n\tdentry = __d_lookup_rcu(parent, name, &d_seq);\n\tif (unlikely(dentry)) {\n\t\tif (!lockref_get_not_dead(&dentry->d_lockref)) {\n\t\t\trcu_read_unlock();\n\t\t\tgoto retry;\n\t\t}\n\t\tif (read_seqcount_retry(&dentry->d_seq, d_seq)) {\n\t\t\trcu_read_unlock();\n\t\t\tdput(dentry);\n\t\t\tgoto retry;\n\t\t}\n\t\trcu_read_unlock();\n\t\tdput(new);\n\t\treturn dentry;\n\t}\n\tif (unlikely(read_seqretry(&rename_lock, r_seq))) {\n\t\trcu_read_unlock();\n\t\tgoto retry;\n\t}\n\thlist_bl_lock(b);\n\tif (unlikely(parent->d_inode->i_dir_seq != seq)) {\n\t\thlist_bl_unlock(b);\n\t\trcu_read_unlock();\n\t\tgoto retry;\n\t}\n\t/*\n\t * No changes for the parent since the beginning of d_lookup().\n\t * Since all removals from the chain happen with hlist_bl_lock(),\n\t * any potential in-lookup matches are going to stay here until\n\t * we unlock the chain.  All fields are stable in everything\n\t * we encounter.\n\t */\n\thlist_bl_for_each_entry(dentry, node, b, d_u.d_in_lookup_hash) {\n\t\tif (dentry->d_name.hash != hash)\n\t\t\tcontinue;\n\t\tif (dentry->d_parent != parent)\n\t\t\tcontinue;\n\t\tif (!d_same_name(dentry, parent, name))\n\t\t\tcontinue;\n\t\thlist_bl_unlock(b);\n\t\t/* now we can try to grab a reference */\n\t\tif (!lockref_get_not_dead(&dentry->d_lockref)) {\n\t\t\trcu_read_unlock();\n\t\t\tgoto retry;\n\t\t}\n\n\t\trcu_read_unlock();\n\t\t/*\n\t\t * somebody is likely to be still doing lookup for it;\n\t\t * wait for them to finish\n\t\t */\n\t\tspin_lock(&dentry->d_lock);\n\t\td_wait_lookup(dentry);\n\t\t/*\n\t\t * it's not in-lookup anymore; in principle we should repeat\n\t\t * everything from dcache lookup, but it's likely to be what\n\t\t * d_lookup() would've found anyway.  If it is, just return it;\n\t\t * otherwise we really have to repeat the whole thing.\n\t\t */\n\t\tif (unlikely(dentry->d_name.hash != hash))\n\t\t\tgoto mismatch;\n\t\tif (unlikely(dentry->d_parent != parent))\n\t\t\tgoto mismatch;\n\t\tif (unlikely(d_unhashed(dentry)))\n\t\t\tgoto mismatch;\n\t\tif (unlikely(!d_same_name(dentry, parent, name)))\n\t\t\tgoto mismatch;\n\t\t/* OK, it *is* a hashed match; return it */\n\t\tspin_unlock(&dentry->d_lock);\n\t\tdput(new);\n\t\treturn dentry;\n\t}\n\trcu_read_unlock();\n\t/* we can't take ->d_lock here; it's OK, though. */\n\tnew->d_flags |= DCACHE_PAR_LOOKUP;\n\tnew->d_wait = wq;\n\thlist_bl_add_head_rcu(&new->d_u.d_in_lookup_hash, b);\n\thlist_bl_unlock(b);\n\treturn new;\nmismatch:\n\tspin_unlock(&dentry->d_lock);\n\tdput(dentry);\n\tgoto retry;\n}\nEXPORT_SYMBOL(d_alloc_parallel);\n\nvoid __d_lookup_done(struct dentry *dentry)\n{\n\tstruct hlist_bl_head *b = in_lookup_hash(dentry->d_parent,\n\t\t\t\t\t\t dentry->d_name.hash);\n\thlist_bl_lock(b);\n\tdentry->d_flags &= ~DCACHE_PAR_LOOKUP;\n\t__hlist_bl_del(&dentry->d_u.d_in_lookup_hash);\n\twake_up_all(dentry->d_wait);\n\tdentry->d_wait = NULL;\n\thlist_bl_unlock(b);\n\tINIT_HLIST_NODE(&dentry->d_u.d_alias);\n\tINIT_LIST_HEAD(&dentry->d_lru);\n}\nEXPORT_SYMBOL(__d_lookup_done);\n\n/* inode->i_lock held if inode is non-NULL */\n\nstatic inline void __d_add(struct dentry *dentry, struct inode *inode)\n{\n\tstruct inode *dir = NULL;\n\tunsigned n;\n\tspin_lock(&dentry->d_lock);\n\tif (unlikely(d_in_lookup(dentry))) {\n\t\tdir = dentry->d_parent->d_inode;\n\t\tn = start_dir_add(dir);\n\t\t__d_lookup_done(dentry);\n\t}\n\tif (inode) {\n\t\tunsigned add_flags = d_flags_for_inode(inode);\n\t\thlist_add_head(&dentry->d_u.d_alias, &inode->i_dentry);\n\t\traw_write_seqcount_begin(&dentry->d_seq);\n\t\t__d_set_inode_and_type(dentry, inode, add_flags);\n\t\traw_write_seqcount_end(&dentry->d_seq);\n\t\tfsnotify_update_flags(dentry);\n\t}\n\t__d_rehash(dentry);\n\tif (dir)\n\t\tend_dir_add(dir, n);\n\tspin_unlock(&dentry->d_lock);\n\tif (inode)\n\t\tspin_unlock(&inode->i_lock);\n}\n\n/**\n * d_add - add dentry to hash queues\n * @entry: dentry to add\n * @inode: The inode to attach to this dentry\n *\n * This adds the entry to the hash queues and initializes @inode.\n * The entry was actually filled in earlier during d_alloc().\n */\n\nvoid d_add(struct dentry *entry, struct inode *inode)\n{\n\tif (inode) {\n\t\tsecurity_d_instantiate(entry, inode);\n\t\tspin_lock(&inode->i_lock);\n\t}\n\t__d_add(entry, inode);\n}\nEXPORT_SYMBOL(d_add);\n\n/**\n * d_exact_alias - find and hash an exact unhashed alias\n * @entry: dentry to add\n * @inode: The inode to go with this dentry\n *\n * If an unhashed dentry with the same name/parent and desired\n * inode already exists, hash and return it.  Otherwise, return\n * NULL.\n *\n * Parent directory should be locked.\n */\nstruct dentry *d_exact_alias(struct dentry *entry, struct inode *inode)\n{\n\tstruct dentry *alias;\n\tunsigned int hash = entry->d_name.hash;\n\n\tspin_lock(&inode->i_lock);\n\thlist_for_each_entry(alias, &inode->i_dentry, d_u.d_alias) {\n\t\t/*\n\t\t * Don't need alias->d_lock here, because aliases with\n\t\t * d_parent == entry->d_parent are not subject to name or\n\t\t * parent changes, because the parent inode i_mutex is held.\n\t\t */\n\t\tif (alias->d_name.hash != hash)\n\t\t\tcontinue;\n\t\tif (alias->d_parent != entry->d_parent)\n\t\t\tcontinue;\n\t\tif (!d_same_name(alias, entry->d_parent, &entry->d_name))\n\t\t\tcontinue;\n\t\tspin_lock(&alias->d_lock);\n\t\tif (!d_unhashed(alias)) {\n\t\t\tspin_unlock(&alias->d_lock);\n\t\t\talias = NULL;\n\t\t} else {\n\t\t\t__dget_dlock(alias);\n\t\t\t__d_rehash(alias);\n\t\t\tspin_unlock(&alias->d_lock);\n\t\t}\n\t\tspin_unlock(&inode->i_lock);\n\t\treturn alias;\n\t}\n\tspin_unlock(&inode->i_lock);\n\treturn NULL;\n}\nEXPORT_SYMBOL(d_exact_alias);\n\n/**\n * dentry_update_name_case - update case insensitive dentry with a new name\n * @dentry: dentry to be updated\n * @name: new name\n *\n * Update a case insensitive dentry with new case of name.\n *\n * dentry must have been returned by d_lookup with name @name. Old and new\n * name lengths must match (ie. no d_compare which allows mismatched name\n * lengths).\n *\n * Parent inode i_mutex must be held over d_lookup and into this call (to\n * keep renames and concurrent inserts, and readdir(2) away).\n */\nvoid dentry_update_name_case(struct dentry *dentry, const struct qstr *name)\n{\n\tBUG_ON(!inode_is_locked(dentry->d_parent->d_inode));\n\tBUG_ON(dentry->d_name.len != name->len); /* d_lookup gives this */\n\n\tspin_lock(&dentry->d_lock);\n\twrite_seqcount_begin(&dentry->d_seq);\n\tmemcpy((unsigned char *)dentry->d_name.name, name->name, name->len);\n\twrite_seqcount_end(&dentry->d_seq);\n\tspin_unlock(&dentry->d_lock);\n}\nEXPORT_SYMBOL(dentry_update_name_case);\n\nstatic void swap_names(struct dentry *dentry, struct dentry *target)\n{\n\tif (unlikely(dname_external(target))) {\n\t\tif (unlikely(dname_external(dentry))) {\n\t\t\t/*\n\t\t\t * Both external: swap the pointers\n\t\t\t */\n\t\t\tswap(target->d_name.name, dentry->d_name.name);\n\t\t} else {\n\t\t\t/*\n\t\t\t * dentry:internal, target:external.  Steal target's\n\t\t\t * storage and make target internal.\n\t\t\t */\n\t\t\tmemcpy(target->d_iname, dentry->d_name.name,\n\t\t\t\t\tdentry->d_name.len + 1);\n\t\t\tdentry->d_name.name = target->d_name.name;\n\t\t\ttarget->d_name.name = target->d_iname;\n\t\t}\n\t} else {\n\t\tif (unlikely(dname_external(dentry))) {\n\t\t\t/*\n\t\t\t * dentry:external, target:internal.  Give dentry's\n\t\t\t * storage to target and make dentry internal\n\t\t\t */\n\t\t\tmemcpy(dentry->d_iname, target->d_name.name,\n\t\t\t\t\ttarget->d_name.len + 1);\n\t\t\ttarget->d_name.name = dentry->d_name.name;\n\t\t\tdentry->d_name.name = dentry->d_iname;\n\t\t} else {\n\t\t\t/*\n\t\t\t * Both are internal.\n\t\t\t */\n\t\t\tunsigned int i;\n\t\t\tBUILD_BUG_ON(!IS_ALIGNED(DNAME_INLINE_LEN, sizeof(long)));\n\t\t\tkmemcheck_mark_initialized(dentry->d_iname, DNAME_INLINE_LEN);\n\t\t\tkmemcheck_mark_initialized(target->d_iname, DNAME_INLINE_LEN);\n\t\t\tfor (i = 0; i < DNAME_INLINE_LEN / sizeof(long); i++) {\n\t\t\t\tswap(((long *) &dentry->d_iname)[i],\n\t\t\t\t     ((long *) &target->d_iname)[i]);\n\t\t\t}\n\t\t}\n\t}\n\tswap(dentry->d_name.hash_len, target->d_name.hash_len);\n}\n\nstatic void copy_name(struct dentry *dentry, struct dentry *target)\n{\n\tstruct external_name *old_name = NULL;\n\tif (unlikely(dname_external(dentry)))\n\t\told_name = external_name(dentry);\n\tif (unlikely(dname_external(target))) {\n\t\tatomic_inc(&external_name(target)->u.count);\n\t\tdentry->d_name = target->d_name;\n\t} else {\n\t\tmemcpy(dentry->d_iname, target->d_name.name,\n\t\t\t\ttarget->d_name.len + 1);\n\t\tdentry->d_name.name = dentry->d_iname;\n\t\tdentry->d_name.hash_len = target->d_name.hash_len;\n\t}\n\tif (old_name && likely(atomic_dec_and_test(&old_name->u.count)))\n\t\tkfree_rcu(old_name, u.head);\n}\n\nstatic void dentry_lock_for_move(struct dentry *dentry, struct dentry *target)\n{\n\t/*\n\t * XXXX: do we really need to take target->d_lock?\n\t */\n\tif (IS_ROOT(dentry) || dentry->d_parent == target->d_parent)\n\t\tspin_lock(&target->d_parent->d_lock);\n\telse {\n\t\tif (d_ancestor(dentry->d_parent, target->d_parent)) {\n\t\t\tspin_lock(&dentry->d_parent->d_lock);\n\t\t\tspin_lock_nested(&target->d_parent->d_lock,\n\t\t\t\t\t\tDENTRY_D_LOCK_NESTED);\n\t\t} else {\n\t\t\tspin_lock(&target->d_parent->d_lock);\n\t\t\tspin_lock_nested(&dentry->d_parent->d_lock,\n\t\t\t\t\t\tDENTRY_D_LOCK_NESTED);\n\t\t}\n\t}\n\tif (target < dentry) {\n\t\tspin_lock_nested(&target->d_lock, 2);\n\t\tspin_lock_nested(&dentry->d_lock, 3);\n\t} else {\n\t\tspin_lock_nested(&dentry->d_lock, 2);\n\t\tspin_lock_nested(&target->d_lock, 3);\n\t}\n}\n\nstatic void dentry_unlock_for_move(struct dentry *dentry, struct dentry *target)\n{\n\tif (target->d_parent != dentry->d_parent)\n\t\tspin_unlock(&dentry->d_parent->d_lock);\n\tif (target->d_parent != target)\n\t\tspin_unlock(&target->d_parent->d_lock);\n\tspin_unlock(&target->d_lock);\n\tspin_unlock(&dentry->d_lock);\n}\n\n/*\n * When switching names, the actual string doesn't strictly have to\n * be preserved in the target - because we're dropping the target\n * anyway. As such, we can just do a simple memcpy() to copy over\n * the new name before we switch, unless we are going to rehash\n * it.  Note that if we *do* unhash the target, we are not allowed\n * to rehash it without giving it a new name/hash key - whether\n * we swap or overwrite the names here, resulting name won't match\n * the reality in filesystem; it's only there for d_path() purposes.\n * Note that all of this is happening under rename_lock, so the\n * any hash lookup seeing it in the middle of manipulations will\n * be discarded anyway.  So we do not care what happens to the hash\n * key in that case.\n */\n/*\n * __d_move - move a dentry\n * @dentry: entry to move\n * @target: new dentry\n * @exchange: exchange the two dentries\n *\n * Update the dcache to reflect the move of a file name. Negative\n * dcache entries should not be moved in this way. Caller must hold\n * rename_lock, the i_mutex of the source and target directories,\n * and the sb->s_vfs_rename_mutex if they differ. See lock_rename().\n */\nstatic void __d_move(struct dentry *dentry, struct dentry *target,\n\t\t     bool exchange)\n{\n\tstruct inode *dir = NULL;\n\tunsigned n;\n\tif (!dentry->d_inode)\n\t\tprintk(KERN_WARNING \"VFS: moving negative dcache entry\\n\");\n\n\tBUG_ON(d_ancestor(dentry, target));\n\tBUG_ON(d_ancestor(target, dentry));\n\n\tdentry_lock_for_move(dentry, target);\n\tif (unlikely(d_in_lookup(target))) {\n\t\tdir = target->d_parent->d_inode;\n\t\tn = start_dir_add(dir);\n\t\t__d_lookup_done(target);\n\t}\n\n\twrite_seqcount_begin(&dentry->d_seq);\n\twrite_seqcount_begin_nested(&target->d_seq, DENTRY_D_LOCK_NESTED);\n\n\t/* unhash both */\n\t/* __d_drop does write_seqcount_barrier, but they're OK to nest. */\n\t__d_drop(dentry);\n\t__d_drop(target);\n\n\t/* Switch the names.. */\n\tif (exchange)\n\t\tswap_names(dentry, target);\n\telse\n\t\tcopy_name(dentry, target);\n\n\t/* rehash in new place(s) */\n\t__d_rehash(dentry);\n\tif (exchange)\n\t\t__d_rehash(target);\n\n\t/* ... and switch them in the tree */\n\tif (IS_ROOT(dentry)) {\n\t\t/* splicing a tree */\n\t\tdentry->d_flags |= DCACHE_RCUACCESS;\n\t\tdentry->d_parent = target->d_parent;\n\t\ttarget->d_parent = target;\n\t\tlist_del_init(&target->d_child);\n\t\tlist_move(&dentry->d_child, &dentry->d_parent->d_subdirs);\n\t} else {\n\t\t/* swapping two dentries */\n\t\tswap(dentry->d_parent, target->d_parent);\n\t\tlist_move(&target->d_child, &target->d_parent->d_subdirs);\n\t\tlist_move(&dentry->d_child, &dentry->d_parent->d_subdirs);\n\t\tif (exchange)\n\t\t\tfsnotify_update_flags(target);\n\t\tfsnotify_update_flags(dentry);\n\t}\n\n\twrite_seqcount_end(&target->d_seq);\n\twrite_seqcount_end(&dentry->d_seq);\n\n\tif (dir)\n\t\tend_dir_add(dir, n);\n\tdentry_unlock_for_move(dentry, target);\n}\n\n/*\n * d_move - move a dentry\n * @dentry: entry to move\n * @target: new dentry\n *\n * Update the dcache to reflect the move of a file name. Negative\n * dcache entries should not be moved in this way. See the locking\n * requirements for __d_move.\n */\nvoid d_move(struct dentry *dentry, struct dentry *target)\n{\n\twrite_seqlock(&rename_lock);\n\t__d_move(dentry, target, false);\n\twrite_sequnlock(&rename_lock);\n}\nEXPORT_SYMBOL(d_move);\n\n/*\n * d_exchange - exchange two dentries\n * @dentry1: first dentry\n * @dentry2: second dentry\n */\nvoid d_exchange(struct dentry *dentry1, struct dentry *dentry2)\n{\n\twrite_seqlock(&rename_lock);\n\n\tWARN_ON(!dentry1->d_inode);\n\tWARN_ON(!dentry2->d_inode);\n\tWARN_ON(IS_ROOT(dentry1));\n\tWARN_ON(IS_ROOT(dentry2));\n\n\t__d_move(dentry1, dentry2, true);\n\n\twrite_sequnlock(&rename_lock);\n}\n\n/**\n * d_ancestor - search for an ancestor\n * @p1: ancestor dentry\n * @p2: child dentry\n *\n * Returns the ancestor dentry of p2 which is a child of p1, if p1 is\n * an ancestor of p2, else NULL.\n */\nstruct dentry *d_ancestor(struct dentry *p1, struct dentry *p2)\n{\n\tstruct dentry *p;\n\n\tfor (p = p2; !IS_ROOT(p); p = p->d_parent) {\n\t\tif (p->d_parent == p1)\n\t\t\treturn p;\n\t}\n\treturn NULL;\n}\n\n/*\n * This helper attempts to cope with remotely renamed directories\n *\n * It assumes that the caller is already holding\n * dentry->d_parent->d_inode->i_mutex, and rename_lock\n *\n * Note: If ever the locking in lock_rename() changes, then please\n * remember to update this too...\n */\nstatic int __d_unalias(struct inode *inode,\n\t\tstruct dentry *dentry, struct dentry *alias)\n{\n\tstruct mutex *m1 = NULL;\n\tstruct rw_semaphore *m2 = NULL;\n\tint ret = -ESTALE;\n\n\t/* If alias and dentry share a parent, then no extra locks required */\n\tif (alias->d_parent == dentry->d_parent)\n\t\tgoto out_unalias;\n\n\t/* See lock_rename() */\n\tif (!mutex_trylock(&dentry->d_sb->s_vfs_rename_mutex))\n\t\tgoto out_err;\n\tm1 = &dentry->d_sb->s_vfs_rename_mutex;\n\tif (!inode_trylock_shared(alias->d_parent->d_inode))\n\t\tgoto out_err;\n\tm2 = &alias->d_parent->d_inode->i_rwsem;\nout_unalias:\n\t__d_move(alias, dentry, false);\n\tret = 0;\nout_err:\n\tif (m2)\n\t\tup_read(m2);\n\tif (m1)\n\t\tmutex_unlock(m1);\n\treturn ret;\n}\n\n/**\n * d_splice_alias - splice a disconnected dentry into the tree if one exists\n * @inode:  the inode which may have a disconnected dentry\n * @dentry: a negative dentry which we want to point to the inode.\n *\n * If inode is a directory and has an IS_ROOT alias, then d_move that in\n * place of the given dentry and return it, else simply d_add the inode\n * to the dentry and return NULL.\n *\n * If a non-IS_ROOT directory is found, the filesystem is corrupt, and\n * we should error out: directories can't have multiple aliases.\n *\n * This is needed in the lookup routine of any filesystem that is exportable\n * (via knfsd) so that we can build dcache paths to directories effectively.\n *\n * If a dentry was found and moved, then it is returned.  Otherwise NULL\n * is returned.  This matches the expected return value of ->lookup.\n *\n * Cluster filesystems may call this function with a negative, hashed dentry.\n * In that case, we know that the inode will be a regular file, and also this\n * will only occur during atomic_open. So we need to check for the dentry\n * being already hashed only in the final case.\n */\nstruct dentry *d_splice_alias(struct inode *inode, struct dentry *dentry)\n{\n\tif (IS_ERR(inode))\n\t\treturn ERR_CAST(inode);\n\n\tBUG_ON(!d_unhashed(dentry));\n\n\tif (!inode)\n\t\tgoto out;\n\n\tsecurity_d_instantiate(dentry, inode);\n\tspin_lock(&inode->i_lock);\n\tif (S_ISDIR(inode->i_mode)) {\n\t\tstruct dentry *new = __d_find_any_alias(inode);\n\t\tif (unlikely(new)) {\n\t\t\t/* The reference to new ensures it remains an alias */\n\t\t\tspin_unlock(&inode->i_lock);\n\t\t\twrite_seqlock(&rename_lock);\n\t\t\tif (unlikely(d_ancestor(new, dentry))) {\n\t\t\t\twrite_sequnlock(&rename_lock);\n\t\t\t\tdput(new);\n\t\t\t\tnew = ERR_PTR(-ELOOP);\n\t\t\t\tpr_warn_ratelimited(\n\t\t\t\t\t\"VFS: Lookup of '%s' in %s %s\"\n\t\t\t\t\t\" would have caused loop\\n\",\n\t\t\t\t\tdentry->d_name.name,\n\t\t\t\t\tinode->i_sb->s_type->name,\n\t\t\t\t\tinode->i_sb->s_id);\n\t\t\t} else if (!IS_ROOT(new)) {\n\t\t\t\tint err = __d_unalias(inode, dentry, new);\n\t\t\t\twrite_sequnlock(&rename_lock);\n\t\t\t\tif (err) {\n\t\t\t\t\tdput(new);\n\t\t\t\t\tnew = ERR_PTR(err);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t__d_move(new, dentry, false);\n\t\t\t\twrite_sequnlock(&rename_lock);\n\t\t\t}\n\t\t\tiput(inode);\n\t\t\treturn new;\n\t\t}\n\t}\nout:\n\t__d_add(dentry, inode);\n\treturn NULL;\n}\nEXPORT_SYMBOL(d_splice_alias);\n\nstatic int prepend(char **buffer, int *buflen, const char *str, int namelen)\n{\n\t*buflen -= namelen;\n\tif (*buflen < 0)\n\t\treturn -ENAMETOOLONG;\n\t*buffer -= namelen;\n\tmemcpy(*buffer, str, namelen);\n\treturn 0;\n}\n\n/**\n * prepend_name - prepend a pathname in front of current buffer pointer\n * @buffer: buffer pointer\n * @buflen: allocated length of the buffer\n * @name:   name string and length qstr structure\n *\n * With RCU path tracing, it may race with d_move(). Use ACCESS_ONCE() to\n * make sure that either the old or the new name pointer and length are\n * fetched. However, there may be mismatch between length and pointer.\n * The length cannot be trusted, we need to copy it byte-by-byte until\n * the length is reached or a null byte is found. It also prepends \"/\" at\n * the beginning of the name. The sequence number check at the caller will\n * retry it again when a d_move() does happen. So any garbage in the buffer\n * due to mismatched pointer and length will be discarded.\n *\n * Data dependency barrier is needed to make sure that we see that terminating\n * NUL.  Alpha strikes again, film at 11...\n */\nstatic int prepend_name(char **buffer, int *buflen, const struct qstr *name)\n{\n\tconst char *dname = ACCESS_ONCE(name->name);\n\tu32 dlen = ACCESS_ONCE(name->len);\n\tchar *p;\n\n\tsmp_read_barrier_depends();\n\n\t*buflen -= dlen + 1;\n\tif (*buflen < 0)\n\t\treturn -ENAMETOOLONG;\n\tp = *buffer -= dlen + 1;\n\t*p++ = '/';\n\twhile (dlen--) {\n\t\tchar c = *dname++;\n\t\tif (!c)\n\t\t\tbreak;\n\t\t*p++ = c;\n\t}\n\treturn 0;\n}\n\n/**\n * prepend_path - Prepend path string to a buffer\n * @path: the dentry/vfsmount to report\n * @root: root vfsmnt/dentry\n * @buffer: pointer to the end of the buffer\n * @buflen: pointer to buffer length\n *\n * The function will first try to write out the pathname without taking any\n * lock other than the RCU read lock to make sure that dentries won't go away.\n * It only checks the sequence number of the global rename_lock as any change\n * in the dentry's d_seq will be preceded by changes in the rename_lock\n * sequence number. If the sequence number had been changed, it will restart\n * the whole pathname back-tracing sequence again by taking the rename_lock.\n * In this case, there is no need to take the RCU read lock as the recursive\n * parent pointer references will keep the dentry chain alive as long as no\n * rename operation is performed.\n */\nstatic int prepend_path(const struct path *path,\n\t\t\tconst struct path *root,\n\t\t\tchar **buffer, int *buflen)\n{\n\tstruct dentry *dentry;\n\tstruct vfsmount *vfsmnt;\n\tstruct mount *mnt;\n\tint error = 0;\n\tunsigned seq, m_seq = 0;\n\tchar *bptr;\n\tint blen;\n\n\trcu_read_lock();\nrestart_mnt:\n\tread_seqbegin_or_lock(&mount_lock, &m_seq);\n\tseq = 0;\n\trcu_read_lock();\nrestart:\n\tbptr = *buffer;\n\tblen = *buflen;\n\terror = 0;\n\tdentry = path->dentry;\n\tvfsmnt = path->mnt;\n\tmnt = real_mount(vfsmnt);\n\tread_seqbegin_or_lock(&rename_lock, &seq);\n\twhile (dentry != root->dentry || vfsmnt != root->mnt) {\n\t\tstruct dentry * parent;\n\n\t\tif (dentry == vfsmnt->mnt_root || IS_ROOT(dentry)) {\n\t\t\tstruct mount *parent = ACCESS_ONCE(mnt->mnt_parent);\n\t\t\t/* Escaped? */\n\t\t\tif (dentry != vfsmnt->mnt_root) {\n\t\t\t\tbptr = *buffer;\n\t\t\t\tblen = *buflen;\n\t\t\t\terror = 3;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t/* Global root? */\n\t\t\tif (mnt != parent) {\n\t\t\t\tdentry = ACCESS_ONCE(mnt->mnt_mountpoint);\n\t\t\t\tmnt = parent;\n\t\t\t\tvfsmnt = &mnt->mnt;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (!error)\n\t\t\t\terror = is_mounted(vfsmnt) ? 1 : 2;\n\t\t\tbreak;\n\t\t}\n\t\tparent = dentry->d_parent;\n\t\tprefetch(parent);\n\t\terror = prepend_name(&bptr, &blen, &dentry->d_name);\n\t\tif (error)\n\t\t\tbreak;\n\n\t\tdentry = parent;\n\t}\n\tif (!(seq & 1))\n\t\trcu_read_unlock();\n\tif (need_seqretry(&rename_lock, seq)) {\n\t\tseq = 1;\n\t\tgoto restart;\n\t}\n\tdone_seqretry(&rename_lock, seq);\n\n\tif (!(m_seq & 1))\n\t\trcu_read_unlock();\n\tif (need_seqretry(&mount_lock, m_seq)) {\n\t\tm_seq = 1;\n\t\tgoto restart_mnt;\n\t}\n\tdone_seqretry(&mount_lock, m_seq);\n\n\tif (error >= 0 && bptr == *buffer) {\n\t\tif (--blen < 0)\n\t\t\terror = -ENAMETOOLONG;\n\t\telse\n\t\t\t*--bptr = '/';\n\t}\n\t*buffer = bptr;\n\t*buflen = blen;\n\treturn error;\n}\n\n/**\n * __d_path - return the path of a dentry\n * @path: the dentry/vfsmount to report\n * @root: root vfsmnt/dentry\n * @buf: buffer to return value in\n * @buflen: buffer length\n *\n * Convert a dentry into an ASCII path name.\n *\n * Returns a pointer into the buffer or an error code if the\n * path was too long.\n *\n * \"buflen\" should be positive.\n *\n * If the path is not reachable from the supplied root, return %NULL.\n */\nchar *__d_path(const struct path *path,\n\t       const struct path *root,\n\t       char *buf, int buflen)\n{\n\tchar *res = buf + buflen;\n\tint error;\n\n\tprepend(&res, &buflen, \"\\0\", 1);\n\terror = prepend_path(path, root, &res, &buflen);\n\n\tif (error < 0)\n\t\treturn ERR_PTR(error);\n\tif (error > 0)\n\t\treturn NULL;\n\treturn res;\n}\n\nchar *d_absolute_path(const struct path *path,\n\t       char *buf, int buflen)\n{\n\tstruct path root = {};\n\tchar *res = buf + buflen;\n\tint error;\n\n\tprepend(&res, &buflen, \"\\0\", 1);\n\terror = prepend_path(path, &root, &res, &buflen);\n\n\tif (error > 1)\n\t\terror = -EINVAL;\n\tif (error < 0)\n\t\treturn ERR_PTR(error);\n\treturn res;\n}\n\n/*\n * same as __d_path but appends \"(deleted)\" for unlinked files.\n */\nstatic int path_with_deleted(const struct path *path,\n\t\t\t     const struct path *root,\n\t\t\t     char **buf, int *buflen)\n{\n\tprepend(buf, buflen, \"\\0\", 1);\n\tif (d_unlinked(path->dentry)) {\n\t\tint error = prepend(buf, buflen, \" (deleted)\", 10);\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\n\treturn prepend_path(path, root, buf, buflen);\n}\n\nstatic int prepend_unreachable(char **buffer, int *buflen)\n{\n\treturn prepend(buffer, buflen, \"(unreachable)\", 13);\n}\n\nstatic void get_fs_root_rcu(struct fs_struct *fs, struct path *root)\n{\n\tunsigned seq;\n\n\tdo {\n\t\tseq = read_seqcount_begin(&fs->seq);\n\t\t*root = fs->root;\n\t} while (read_seqcount_retry(&fs->seq, seq));\n}\n\n/**\n * d_path - return the path of a dentry\n * @path: path to report\n * @buf: buffer to return value in\n * @buflen: buffer length\n *\n * Convert a dentry into an ASCII path name. If the entry has been deleted\n * the string \" (deleted)\" is appended. Note that this is ambiguous.\n *\n * Returns a pointer into the buffer or an error code if the path was\n * too long. Note: Callers should use the returned pointer, not the passed\n * in buffer, to use the name! The implementation often starts at an offset\n * into the buffer, and may leave 0 bytes at the start.\n *\n * \"buflen\" should be positive.\n */\nchar *d_path(const struct path *path, char *buf, int buflen)\n{\n\tchar *res = buf + buflen;\n\tstruct path root;\n\tint error;\n\n\t/*\n\t * We have various synthetic filesystems that never get mounted.  On\n\t * these filesystems dentries are never used for lookup purposes, and\n\t * thus don't need to be hashed.  They also don't need a name until a\n\t * user wants to identify the object in /proc/pid/fd/.  The little hack\n\t * below allows us to generate a name for these objects on demand:\n\t *\n\t * Some pseudo inodes are mountable.  When they are mounted\n\t * path->dentry == path->mnt->mnt_root.  In that case don't call d_dname\n\t * and instead have d_path return the mounted path.\n\t */\n\tif (path->dentry->d_op && path->dentry->d_op->d_dname &&\n\t    (!IS_ROOT(path->dentry) || path->dentry != path->mnt->mnt_root))\n\t\treturn path->dentry->d_op->d_dname(path->dentry, buf, buflen);\n\n\trcu_read_lock();\n\tget_fs_root_rcu(current->fs, &root);\n\terror = path_with_deleted(path, &root, &res, &buflen);\n\trcu_read_unlock();\n\n\tif (error < 0)\n\t\tres = ERR_PTR(error);\n\treturn res;\n}\nEXPORT_SYMBOL(d_path);\n\n/*\n * Helper function for dentry_operations.d_dname() members\n */\nchar *dynamic_dname(struct dentry *dentry, char *buffer, int buflen,\n\t\t\tconst char *fmt, ...)\n{\n\tva_list args;\n\tchar temp[64];\n\tint sz;\n\n\tva_start(args, fmt);\n\tsz = vsnprintf(temp, sizeof(temp), fmt, args) + 1;\n\tva_end(args);\n\n\tif (sz > sizeof(temp) || sz > buflen)\n\t\treturn ERR_PTR(-ENAMETOOLONG);\n\n\tbuffer += buflen - sz;\n\treturn memcpy(buffer, temp, sz);\n}\n\nchar *simple_dname(struct dentry *dentry, char *buffer, int buflen)\n{\n\tchar *end = buffer + buflen;\n\t/* these dentries are never renamed, so d_lock is not needed */\n\tif (prepend(&end, &buflen, \" (deleted)\", 11) ||\n\t    prepend(&end, &buflen, dentry->d_name.name, dentry->d_name.len) ||\n\t    prepend(&end, &buflen, \"/\", 1))  \n\t\tend = ERR_PTR(-ENAMETOOLONG);\n\treturn end;\n}\nEXPORT_SYMBOL(simple_dname);\n\n/*\n * Write full pathname from the root of the filesystem into the buffer.\n */\nstatic char *__dentry_path(struct dentry *d, char *buf, int buflen)\n{\n\tstruct dentry *dentry;\n\tchar *end, *retval;\n\tint len, seq = 0;\n\tint error = 0;\n\n\tif (buflen < 2)\n\t\tgoto Elong;\n\n\trcu_read_lock();\nrestart:\n\tdentry = d;\n\tend = buf + buflen;\n\tlen = buflen;\n\tprepend(&end, &len, \"\\0\", 1);\n\t/* Get '/' right */\n\tretval = end-1;\n\t*retval = '/';\n\tread_seqbegin_or_lock(&rename_lock, &seq);\n\twhile (!IS_ROOT(dentry)) {\n\t\tstruct dentry *parent = dentry->d_parent;\n\n\t\tprefetch(parent);\n\t\terror = prepend_name(&end, &len, &dentry->d_name);\n\t\tif (error)\n\t\t\tbreak;\n\n\t\tretval = end;\n\t\tdentry = parent;\n\t}\n\tif (!(seq & 1))\n\t\trcu_read_unlock();\n\tif (need_seqretry(&rename_lock, seq)) {\n\t\tseq = 1;\n\t\tgoto restart;\n\t}\n\tdone_seqretry(&rename_lock, seq);\n\tif (error)\n\t\tgoto Elong;\n\treturn retval;\nElong:\n\treturn ERR_PTR(-ENAMETOOLONG);\n}\n\nchar *dentry_path_raw(struct dentry *dentry, char *buf, int buflen)\n{\n\treturn __dentry_path(dentry, buf, buflen);\n}\nEXPORT_SYMBOL(dentry_path_raw);\n\nchar *dentry_path(struct dentry *dentry, char *buf, int buflen)\n{\n\tchar *p = NULL;\n\tchar *retval;\n\n\tif (d_unlinked(dentry)) {\n\t\tp = buf + buflen;\n\t\tif (prepend(&p, &buflen, \"//deleted\", 10) != 0)\n\t\t\tgoto Elong;\n\t\tbuflen++;\n\t}\n\tretval = __dentry_path(dentry, buf, buflen);\n\tif (!IS_ERR(retval) && p)\n\t\t*p = '/';\t/* restore '/' overriden with '\\0' */\n\treturn retval;\nElong:\n\treturn ERR_PTR(-ENAMETOOLONG);\n}\n\nstatic void get_fs_root_and_pwd_rcu(struct fs_struct *fs, struct path *root,\n\t\t\t\t    struct path *pwd)\n{\n\tunsigned seq;\n\n\tdo {\n\t\tseq = read_seqcount_begin(&fs->seq);\n\t\t*root = fs->root;\n\t\t*pwd = fs->pwd;\n\t} while (read_seqcount_retry(&fs->seq, seq));\n}\n\n/*\n * NOTE! The user-level library version returns a\n * character pointer. The kernel system call just\n * returns the length of the buffer filled (which\n * includes the ending '\\0' character), or a negative\n * error value. So libc would do something like\n *\n *\tchar *getcwd(char * buf, size_t size)\n *\t{\n *\t\tint retval;\n *\n *\t\tretval = sys_getcwd(buf, size);\n *\t\tif (retval >= 0)\n *\t\t\treturn buf;\n *\t\terrno = -retval;\n *\t\treturn NULL;\n *\t}\n */\nSYSCALL_DEFINE2(getcwd, char __user *, buf, unsigned long, size)\n{\n\tint error;\n\tstruct path pwd, root;\n\tchar *page = __getname();\n\n\tif (!page)\n\t\treturn -ENOMEM;\n\n\trcu_read_lock();\n\tget_fs_root_and_pwd_rcu(current->fs, &root, &pwd);\n\n\terror = -ENOENT;\n\tif (!d_unlinked(pwd.dentry)) {\n\t\tunsigned long len;\n\t\tchar *cwd = page + PATH_MAX;\n\t\tint buflen = PATH_MAX;\n\n\t\tprepend(&cwd, &buflen, \"\\0\", 1);\n\t\terror = prepend_path(&pwd, &root, &cwd, &buflen);\n\t\trcu_read_unlock();\n\n\t\tif (error < 0)\n\t\t\tgoto out;\n\n\t\t/* Unreachable from current root */\n\t\tif (error > 0) {\n\t\t\terror = prepend_unreachable(&cwd, &buflen);\n\t\t\tif (error)\n\t\t\t\tgoto out;\n\t\t}\n\n\t\terror = -ERANGE;\n\t\tlen = PATH_MAX + page - cwd;\n\t\tif (len <= size) {\n\t\t\terror = len;\n\t\t\tif (copy_to_user(buf, cwd, len))\n\t\t\t\terror = -EFAULT;\n\t\t}\n\t} else {\n\t\trcu_read_unlock();\n\t}\n\nout:\n\t__putname(page);\n\treturn error;\n}\n\n/*\n * Test whether new_dentry is a subdirectory of old_dentry.\n *\n * Trivially implemented using the dcache structure\n */\n\n/**\n * is_subdir - is new dentry a subdirectory of old_dentry\n * @new_dentry: new dentry\n * @old_dentry: old dentry\n *\n * Returns true if new_dentry is a subdirectory of the parent (at any depth).\n * Returns false otherwise.\n * Caller must ensure that \"new_dentry\" is pinned before calling is_subdir()\n */\n  \nbool is_subdir(struct dentry *new_dentry, struct dentry *old_dentry)\n{\n\tbool result;\n\tunsigned seq;\n\n\tif (new_dentry == old_dentry)\n\t\treturn true;\n\n\tdo {\n\t\t/* for restarting inner loop in case of seq retry */\n\t\tseq = read_seqbegin(&rename_lock);\n\t\t/*\n\t\t * Need rcu_readlock to protect against the d_parent trashing\n\t\t * due to d_move\n\t\t */\n\t\trcu_read_lock();\n\t\tif (d_ancestor(old_dentry, new_dentry))\n\t\t\tresult = true;\n\t\telse\n\t\t\tresult = false;\n\t\trcu_read_unlock();\n\t} while (read_seqretry(&rename_lock, seq));\n\n\treturn result;\n}\n\nstatic enum d_walk_ret d_genocide_kill(void *data, struct dentry *dentry)\n{\n\tstruct dentry *root = data;\n\tif (dentry != root) {\n\t\tif (d_unhashed(dentry) || !dentry->d_inode)\n\t\t\treturn D_WALK_SKIP;\n\n\t\tif (!(dentry->d_flags & DCACHE_GENOCIDE)) {\n\t\t\tdentry->d_flags |= DCACHE_GENOCIDE;\n\t\t\tdentry->d_lockref.count--;\n\t\t}\n\t}\n\treturn D_WALK_CONTINUE;\n}\n\nvoid d_genocide(struct dentry *parent)\n{\n\td_walk(parent, parent, d_genocide_kill, NULL);\n}\n\nvoid d_tmpfile(struct dentry *dentry, struct inode *inode)\n{\n\tinode_dec_link_count(inode);\n\tBUG_ON(dentry->d_name.name != dentry->d_iname ||\n\t\t!hlist_unhashed(&dentry->d_u.d_alias) ||\n\t\t!d_unlinked(dentry));\n\tspin_lock(&dentry->d_parent->d_lock);\n\tspin_lock_nested(&dentry->d_lock, DENTRY_D_LOCK_NESTED);\n\tdentry->d_name.len = sprintf(dentry->d_iname, \"#%llu\",\n\t\t\t\t(unsigned long long)inode->i_ino);\n\tspin_unlock(&dentry->d_lock);\n\tspin_unlock(&dentry->d_parent->d_lock);\n\td_instantiate(dentry, inode);\n}\nEXPORT_SYMBOL(d_tmpfile);\n\nstatic __initdata unsigned long dhash_entries;\nstatic int __init set_dhash_entries(char *str)\n{\n\tif (!str)\n\t\treturn 0;\n\tdhash_entries = simple_strtoul(str, &str, 0);\n\treturn 1;\n}\n__setup(\"dhash_entries=\", set_dhash_entries);\n\nstatic void __init dcache_init_early(void)\n{\n\tunsigned int loop;\n\n\t/* If hashes are distributed across NUMA nodes, defer\n\t * hash allocation until vmalloc space is available.\n\t */\n\tif (hashdist)\n\t\treturn;\n\n\tdentry_hashtable =\n\t\talloc_large_system_hash(\"Dentry cache\",\n\t\t\t\t\tsizeof(struct hlist_bl_head),\n\t\t\t\t\tdhash_entries,\n\t\t\t\t\t13,\n\t\t\t\t\tHASH_EARLY,\n\t\t\t\t\t&d_hash_shift,\n\t\t\t\t\t&d_hash_mask,\n\t\t\t\t\t0,\n\t\t\t\t\t0);\n\n\tfor (loop = 0; loop < (1U << d_hash_shift); loop++)\n\t\tINIT_HLIST_BL_HEAD(dentry_hashtable + loop);\n}\n\nstatic void __init dcache_init(void)\n{\n\tunsigned int loop;\n\n\t/* \n\t * A constructor could be added for stable state like the lists,\n\t * but it is probably not worth it because of the cache nature\n\t * of the dcache. \n\t */\n\tdentry_cache = KMEM_CACHE(dentry,\n\t\tSLAB_RECLAIM_ACCOUNT|SLAB_PANIC|SLAB_MEM_SPREAD|SLAB_ACCOUNT);\n\n\t/* Hash may have been set up in dcache_init_early */\n\tif (!hashdist)\n\t\treturn;\n\n\tdentry_hashtable =\n\t\talloc_large_system_hash(\"Dentry cache\",\n\t\t\t\t\tsizeof(struct hlist_bl_head),\n\t\t\t\t\tdhash_entries,\n\t\t\t\t\t13,\n\t\t\t\t\t0,\n\t\t\t\t\t&d_hash_shift,\n\t\t\t\t\t&d_hash_mask,\n\t\t\t\t\t0,\n\t\t\t\t\t0);\n\n\tfor (loop = 0; loop < (1U << d_hash_shift); loop++)\n\t\tINIT_HLIST_BL_HEAD(dentry_hashtable + loop);\n}\n\n/* SLAB cache for __getname() consumers */\nstruct kmem_cache *names_cachep __read_mostly;\nEXPORT_SYMBOL(names_cachep);\n\nEXPORT_SYMBOL(d_genocide);\n\nvoid __init vfs_caches_init_early(void)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(in_lookup_hashtable); i++)\n\t\tINIT_HLIST_BL_HEAD(&in_lookup_hashtable[i]);\n\n\tdcache_init_early();\n\tinode_init_early();\n}\n\nvoid __init vfs_caches_init(void)\n{\n\tnames_cachep = kmem_cache_create(\"names_cache\", PATH_MAX, 0,\n\t\t\tSLAB_HWCACHE_ALIGN|SLAB_PANIC, NULL);\n\n\tdcache_init();\n\tinode_init();\n\tfiles_init();\n\tfiles_maxfiles_init();\n\tmnt_init();\n\tbdev_cache_init();\n\tchrdev_init();\n}\n", "/*\n *  inode.c - part of debugfs, a tiny little debug file system\n *\n *  Copyright (C) 2004 Greg Kroah-Hartman <greg@kroah.com>\n *  Copyright (C) 2004 IBM Inc.\n *\n *\tThis program is free software; you can redistribute it and/or\n *\tmodify it under the terms of the GNU General Public License version\n *\t2 as published by the Free Software Foundation.\n *\n *  debugfs is for people to use instead of /proc or /sys.\n *  See Documentation/DocBook/kernel-api for more details.\n *\n */\n\n#include <linux/module.h>\n#include <linux/fs.h>\n#include <linux/mount.h>\n#include <linux/pagemap.h>\n#include <linux/init.h>\n#include <linux/kobject.h>\n#include <linux/namei.h>\n#include <linux/debugfs.h>\n#include <linux/fsnotify.h>\n#include <linux/string.h>\n#include <linux/seq_file.h>\n#include <linux/parser.h>\n#include <linux/magic.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n\n#include \"internal.h\"\n\n#define DEBUGFS_DEFAULT_MODE\t0700\n\nDEFINE_SRCU(debugfs_srcu);\n\nstatic struct vfsmount *debugfs_mount;\nstatic int debugfs_mount_count;\nstatic bool debugfs_registered;\n\nstatic struct inode *debugfs_get_inode(struct super_block *sb)\n{\n\tstruct inode *inode = new_inode(sb);\n\tif (inode) {\n\t\tinode->i_ino = get_next_ino();\n\t\tinode->i_atime = inode->i_mtime =\n\t\t\tinode->i_ctime = current_time(inode);\n\t}\n\treturn inode;\n}\n\nstruct debugfs_mount_opts {\n\tkuid_t uid;\n\tkgid_t gid;\n\tumode_t mode;\n};\n\nenum {\n\tOpt_uid,\n\tOpt_gid,\n\tOpt_mode,\n\tOpt_err\n};\n\nstatic const match_table_t tokens = {\n\t{Opt_uid, \"uid=%u\"},\n\t{Opt_gid, \"gid=%u\"},\n\t{Opt_mode, \"mode=%o\"},\n\t{Opt_err, NULL}\n};\n\nstruct debugfs_fs_info {\n\tstruct debugfs_mount_opts mount_opts;\n};\n\nstatic int debugfs_parse_options(char *data, struct debugfs_mount_opts *opts)\n{\n\tsubstring_t args[MAX_OPT_ARGS];\n\tint option;\n\tint token;\n\tkuid_t uid;\n\tkgid_t gid;\n\tchar *p;\n\n\topts->mode = DEBUGFS_DEFAULT_MODE;\n\n\twhile ((p = strsep(&data, \",\")) != NULL) {\n\t\tif (!*p)\n\t\t\tcontinue;\n\n\t\ttoken = match_token(p, tokens, args);\n\t\tswitch (token) {\n\t\tcase Opt_uid:\n\t\t\tif (match_int(&args[0], &option))\n\t\t\t\treturn -EINVAL;\n\t\t\tuid = make_kuid(current_user_ns(), option);\n\t\t\tif (!uid_valid(uid))\n\t\t\t\treturn -EINVAL;\n\t\t\topts->uid = uid;\n\t\t\tbreak;\n\t\tcase Opt_gid:\n\t\t\tif (match_int(&args[0], &option))\n\t\t\t\treturn -EINVAL;\n\t\t\tgid = make_kgid(current_user_ns(), option);\n\t\t\tif (!gid_valid(gid))\n\t\t\t\treturn -EINVAL;\n\t\t\topts->gid = gid;\n\t\t\tbreak;\n\t\tcase Opt_mode:\n\t\t\tif (match_octal(&args[0], &option))\n\t\t\t\treturn -EINVAL;\n\t\t\topts->mode = option & S_IALLUGO;\n\t\t\tbreak;\n\t\t/*\n\t\t * We might like to report bad mount options here;\n\t\t * but traditionally debugfs has ignored all mount options\n\t\t */\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int debugfs_apply_options(struct super_block *sb)\n{\n\tstruct debugfs_fs_info *fsi = sb->s_fs_info;\n\tstruct inode *inode = d_inode(sb->s_root);\n\tstruct debugfs_mount_opts *opts = &fsi->mount_opts;\n\n\tinode->i_mode &= ~S_IALLUGO;\n\tinode->i_mode |= opts->mode;\n\n\tinode->i_uid = opts->uid;\n\tinode->i_gid = opts->gid;\n\n\treturn 0;\n}\n\nstatic int debugfs_remount(struct super_block *sb, int *flags, char *data)\n{\n\tint err;\n\tstruct debugfs_fs_info *fsi = sb->s_fs_info;\n\n\tsync_filesystem(sb);\n\terr = debugfs_parse_options(data, &fsi->mount_opts);\n\tif (err)\n\t\tgoto fail;\n\n\tdebugfs_apply_options(sb);\n\nfail:\n\treturn err;\n}\n\nstatic int debugfs_show_options(struct seq_file *m, struct dentry *root)\n{\n\tstruct debugfs_fs_info *fsi = root->d_sb->s_fs_info;\n\tstruct debugfs_mount_opts *opts = &fsi->mount_opts;\n\n\tif (!uid_eq(opts->uid, GLOBAL_ROOT_UID))\n\t\tseq_printf(m, \",uid=%u\",\n\t\t\t   from_kuid_munged(&init_user_ns, opts->uid));\n\tif (!gid_eq(opts->gid, GLOBAL_ROOT_GID))\n\t\tseq_printf(m, \",gid=%u\",\n\t\t\t   from_kgid_munged(&init_user_ns, opts->gid));\n\tif (opts->mode != DEBUGFS_DEFAULT_MODE)\n\t\tseq_printf(m, \",mode=%o\", opts->mode);\n\n\treturn 0;\n}\n\nstatic void debugfs_evict_inode(struct inode *inode)\n{\n\ttruncate_inode_pages_final(&inode->i_data);\n\tclear_inode(inode);\n\tif (S_ISLNK(inode->i_mode))\n\t\tkfree(inode->i_link);\n}\n\nstatic const struct super_operations debugfs_super_operations = {\n\t.statfs\t\t= simple_statfs,\n\t.remount_fs\t= debugfs_remount,\n\t.show_options\t= debugfs_show_options,\n\t.evict_inode\t= debugfs_evict_inode,\n};\n\nstatic struct vfsmount *debugfs_automount(struct path *path)\n{\n\tdebugfs_automount_t f;\n\tf = (debugfs_automount_t)path->dentry->d_fsdata;\n\treturn f(path->dentry, d_inode(path->dentry)->i_private);\n}\n\nstatic const struct dentry_operations debugfs_dops = {\n\t.d_delete = always_delete_dentry,\n\t.d_automount = debugfs_automount,\n};\n\nstatic int debug_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tstatic const struct tree_descr debug_files[] = {{\"\"}};\n\tstruct debugfs_fs_info *fsi;\n\tint err;\n\n\tsave_mount_options(sb, data);\n\n\tfsi = kzalloc(sizeof(struct debugfs_fs_info), GFP_KERNEL);\n\tsb->s_fs_info = fsi;\n\tif (!fsi) {\n\t\terr = -ENOMEM;\n\t\tgoto fail;\n\t}\n\n\terr = debugfs_parse_options(data, &fsi->mount_opts);\n\tif (err)\n\t\tgoto fail;\n\n\terr  =  simple_fill_super(sb, DEBUGFS_MAGIC, debug_files);\n\tif (err)\n\t\tgoto fail;\n\n\tsb->s_op = &debugfs_super_operations;\n\tsb->s_d_op = &debugfs_dops;\n\n\tdebugfs_apply_options(sb);\n\n\treturn 0;\n\nfail:\n\tkfree(fsi);\n\tsb->s_fs_info = NULL;\n\treturn err;\n}\n\nstatic struct dentry *debug_mount(struct file_system_type *fs_type,\n\t\t\tint flags, const char *dev_name,\n\t\t\tvoid *data)\n{\n\treturn mount_single(fs_type, flags, data, debug_fill_super);\n}\n\nstatic struct file_system_type debug_fs_type = {\n\t.owner =\tTHIS_MODULE,\n\t.name =\t\t\"debugfs\",\n\t.mount =\tdebug_mount,\n\t.kill_sb =\tkill_litter_super,\n};\nMODULE_ALIAS_FS(\"debugfs\");\n\n/**\n * debugfs_lookup() - look up an existing debugfs file\n * @name: a pointer to a string containing the name of the file to look up.\n * @parent: a pointer to the parent dentry of the file.\n *\n * This function will return a pointer to a dentry if it succeeds.  If the file\n * doesn't exist or an error occurs, %NULL will be returned.  The returned\n * dentry must be passed to dput() when it is no longer needed.\n *\n * If debugfs is not enabled in the kernel, the value -%ENODEV will be\n * returned.\n */\nstruct dentry *debugfs_lookup(const char *name, struct dentry *parent)\n{\n\tstruct dentry *dentry;\n\n\tif (IS_ERR(parent))\n\t\treturn NULL;\n\n\tif (!parent)\n\t\tparent = debugfs_mount->mnt_root;\n\n\tinode_lock(d_inode(parent));\n\tdentry = lookup_one_len(name, parent, strlen(name));\n\tinode_unlock(d_inode(parent));\n\n\tif (IS_ERR(dentry))\n\t\treturn NULL;\n\tif (!d_really_is_positive(dentry)) {\n\t\tdput(dentry);\n\t\treturn NULL;\n\t}\n\treturn dentry;\n}\nEXPORT_SYMBOL_GPL(debugfs_lookup);\n\nstatic struct dentry *start_creating(const char *name, struct dentry *parent)\n{\n\tstruct dentry *dentry;\n\tint error;\n\n\tpr_debug(\"debugfs: creating file '%s'\\n\",name);\n\n\tif (IS_ERR(parent))\n\t\treturn parent;\n\n\terror = simple_pin_fs(&debug_fs_type, &debugfs_mount,\n\t\t\t      &debugfs_mount_count);\n\tif (error)\n\t\treturn ERR_PTR(error);\n\n\t/* If the parent is not specified, we create it in the root.\n\t * We need the root dentry to do this, which is in the super\n\t * block. A pointer to that is in the struct vfsmount that we\n\t * have around.\n\t */\n\tif (!parent)\n\t\tparent = debugfs_mount->mnt_root;\n\n\tinode_lock(d_inode(parent));\n\tdentry = lookup_one_len(name, parent, strlen(name));\n\tif (!IS_ERR(dentry) && d_really_is_positive(dentry)) {\n\t\tdput(dentry);\n\t\tdentry = ERR_PTR(-EEXIST);\n\t}\n\n\tif (IS_ERR(dentry)) {\n\t\tinode_unlock(d_inode(parent));\n\t\tsimple_release_fs(&debugfs_mount, &debugfs_mount_count);\n\t}\n\n\treturn dentry;\n}\n\nstatic struct dentry *failed_creating(struct dentry *dentry)\n{\n\tinode_unlock(d_inode(dentry->d_parent));\n\tdput(dentry);\n\tsimple_release_fs(&debugfs_mount, &debugfs_mount_count);\n\treturn NULL;\n}\n\nstatic struct dentry *end_creating(struct dentry *dentry)\n{\n\tinode_unlock(d_inode(dentry->d_parent));\n\treturn dentry;\n}\n\nstatic struct dentry *__debugfs_create_file(const char *name, umode_t mode,\n\t\t\t\tstruct dentry *parent, void *data,\n\t\t\t\tconst struct file_operations *proxy_fops,\n\t\t\t\tconst struct file_operations *real_fops)\n{\n\tstruct dentry *dentry;\n\tstruct inode *inode;\n\n\tif (!(mode & S_IFMT))\n\t\tmode |= S_IFREG;\n\tBUG_ON(!S_ISREG(mode));\n\tdentry = start_creating(name, parent);\n\n\tif (IS_ERR(dentry))\n\t\treturn NULL;\n\n\tinode = debugfs_get_inode(dentry->d_sb);\n\tif (unlikely(!inode))\n\t\treturn failed_creating(dentry);\n\n\tinode->i_mode = mode;\n\tinode->i_private = data;\n\n\tinode->i_fop = proxy_fops;\n\tdentry->d_fsdata = (void *)real_fops;\n\n\td_instantiate(dentry, inode);\n\tfsnotify_create(d_inode(dentry->d_parent), dentry);\n\treturn end_creating(dentry);\n}\n\n/**\n * debugfs_create_file - create a file in the debugfs filesystem\n * @name: a pointer to a string containing the name of the file to create.\n * @mode: the permission that the file should have.\n * @parent: a pointer to the parent dentry for this file.  This should be a\n *          directory dentry if set.  If this parameter is NULL, then the\n *          file will be created in the root of the debugfs filesystem.\n * @data: a pointer to something that the caller will want to get to later\n *        on.  The inode.i_private pointer will point to this value on\n *        the open() call.\n * @fops: a pointer to a struct file_operations that should be used for\n *        this file.\n *\n * This is the basic \"create a file\" function for debugfs.  It allows for a\n * wide range of flexibility in creating a file, or a directory (if you want\n * to create a directory, the debugfs_create_dir() function is\n * recommended to be used instead.)\n *\n * This function will return a pointer to a dentry if it succeeds.  This\n * pointer must be passed to the debugfs_remove() function when the file is\n * to be removed (no automatic cleanup happens if your module is unloaded,\n * you are responsible here.)  If an error occurs, %NULL will be returned.\n *\n * If debugfs is not enabled in the kernel, the value -%ENODEV will be\n * returned.\n */\nstruct dentry *debugfs_create_file(const char *name, umode_t mode,\n\t\t\t\t   struct dentry *parent, void *data,\n\t\t\t\t   const struct file_operations *fops)\n{\n\n\treturn __debugfs_create_file(name, mode, parent, data,\n\t\t\t\tfops ? &debugfs_full_proxy_file_operations :\n\t\t\t\t\t&debugfs_noop_file_operations,\n\t\t\t\tfops);\n}\nEXPORT_SYMBOL_GPL(debugfs_create_file);\n\n/**\n * debugfs_create_file_unsafe - create a file in the debugfs filesystem\n * @name: a pointer to a string containing the name of the file to create.\n * @mode: the permission that the file should have.\n * @parent: a pointer to the parent dentry for this file.  This should be a\n *          directory dentry if set.  If this parameter is NULL, then the\n *          file will be created in the root of the debugfs filesystem.\n * @data: a pointer to something that the caller will want to get to later\n *        on.  The inode.i_private pointer will point to this value on\n *        the open() call.\n * @fops: a pointer to a struct file_operations that should be used for\n *        this file.\n *\n * debugfs_create_file_unsafe() is completely analogous to\n * debugfs_create_file(), the only difference being that the fops\n * handed it will not get protected against file removals by the\n * debugfs core.\n *\n * It is your responsibility to protect your struct file_operation\n * methods against file removals by means of debugfs_use_file_start()\n * and debugfs_use_file_finish(). ->open() is still protected by\n * debugfs though.\n *\n * Any struct file_operations defined by means of\n * DEFINE_DEBUGFS_ATTRIBUTE() is protected against file removals and\n * thus, may be used here.\n */\nstruct dentry *debugfs_create_file_unsafe(const char *name, umode_t mode,\n\t\t\t\t   struct dentry *parent, void *data,\n\t\t\t\t   const struct file_operations *fops)\n{\n\n\treturn __debugfs_create_file(name, mode, parent, data,\n\t\t\t\tfops ? &debugfs_open_proxy_file_operations :\n\t\t\t\t\t&debugfs_noop_file_operations,\n\t\t\t\tfops);\n}\nEXPORT_SYMBOL_GPL(debugfs_create_file_unsafe);\n\n/**\n * debugfs_create_file_size - create a file in the debugfs filesystem\n * @name: a pointer to a string containing the name of the file to create.\n * @mode: the permission that the file should have.\n * @parent: a pointer to the parent dentry for this file.  This should be a\n *          directory dentry if set.  If this parameter is NULL, then the\n *          file will be created in the root of the debugfs filesystem.\n * @data: a pointer to something that the caller will want to get to later\n *        on.  The inode.i_private pointer will point to this value on\n *        the open() call.\n * @fops: a pointer to a struct file_operations that should be used for\n *        this file.\n * @file_size: initial file size\n *\n * This is the basic \"create a file\" function for debugfs.  It allows for a\n * wide range of flexibility in creating a file, or a directory (if you want\n * to create a directory, the debugfs_create_dir() function is\n * recommended to be used instead.)\n *\n * This function will return a pointer to a dentry if it succeeds.  This\n * pointer must be passed to the debugfs_remove() function when the file is\n * to be removed (no automatic cleanup happens if your module is unloaded,\n * you are responsible here.)  If an error occurs, %NULL will be returned.\n *\n * If debugfs is not enabled in the kernel, the value -%ENODEV will be\n * returned.\n */\nstruct dentry *debugfs_create_file_size(const char *name, umode_t mode,\n\t\t\t\t\tstruct dentry *parent, void *data,\n\t\t\t\t\tconst struct file_operations *fops,\n\t\t\t\t\tloff_t file_size)\n{\n\tstruct dentry *de = debugfs_create_file(name, mode, parent, data, fops);\n\n\tif (de)\n\t\td_inode(de)->i_size = file_size;\n\treturn de;\n}\nEXPORT_SYMBOL_GPL(debugfs_create_file_size);\n\n/**\n * debugfs_create_dir - create a directory in the debugfs filesystem\n * @name: a pointer to a string containing the name of the directory to\n *        create.\n * @parent: a pointer to the parent dentry for this file.  This should be a\n *          directory dentry if set.  If this parameter is NULL, then the\n *          directory will be created in the root of the debugfs filesystem.\n *\n * This function creates a directory in debugfs with the given name.\n *\n * This function will return a pointer to a dentry if it succeeds.  This\n * pointer must be passed to the debugfs_remove() function when the file is\n * to be removed (no automatic cleanup happens if your module is unloaded,\n * you are responsible here.)  If an error occurs, %NULL will be returned.\n *\n * If debugfs is not enabled in the kernel, the value -%ENODEV will be\n * returned.\n */\nstruct dentry *debugfs_create_dir(const char *name, struct dentry *parent)\n{\n\tstruct dentry *dentry = start_creating(name, parent);\n\tstruct inode *inode;\n\n\tif (IS_ERR(dentry))\n\t\treturn NULL;\n\n\tinode = debugfs_get_inode(dentry->d_sb);\n\tif (unlikely(!inode))\n\t\treturn failed_creating(dentry);\n\n\tinode->i_mode = S_IFDIR | S_IRWXU | S_IRUGO | S_IXUGO;\n\tinode->i_op = &simple_dir_inode_operations;\n\tinode->i_fop = &simple_dir_operations;\n\n\t/* directory inodes start off with i_nlink == 2 (for \".\" entry) */\n\tinc_nlink(inode);\n\td_instantiate(dentry, inode);\n\tinc_nlink(d_inode(dentry->d_parent));\n\tfsnotify_mkdir(d_inode(dentry->d_parent), dentry);\n\treturn end_creating(dentry);\n}\nEXPORT_SYMBOL_GPL(debugfs_create_dir);\n\n/**\n * debugfs_create_automount - create automount point in the debugfs filesystem\n * @name: a pointer to a string containing the name of the file to create.\n * @parent: a pointer to the parent dentry for this file.  This should be a\n *          directory dentry if set.  If this parameter is NULL, then the\n *          file will be created in the root of the debugfs filesystem.\n * @f: function to be called when pathname resolution steps on that one.\n * @data: opaque argument to pass to f().\n *\n * @f should return what ->d_automount() would.\n */\nstruct dentry *debugfs_create_automount(const char *name,\n\t\t\t\t\tstruct dentry *parent,\n\t\t\t\t\tdebugfs_automount_t f,\n\t\t\t\t\tvoid *data)\n{\n\tstruct dentry *dentry = start_creating(name, parent);\n\tstruct inode *inode;\n\n\tif (IS_ERR(dentry))\n\t\treturn NULL;\n\n\tinode = debugfs_get_inode(dentry->d_sb);\n\tif (unlikely(!inode))\n\t\treturn failed_creating(dentry);\n\n\tmake_empty_dir_inode(inode);\n\tinode->i_flags |= S_AUTOMOUNT;\n\tinode->i_private = data;\n\tdentry->d_fsdata = (void *)f;\n\t/* directory inodes start off with i_nlink == 2 (for \".\" entry) */\n\tinc_nlink(inode);\n\td_instantiate(dentry, inode);\n\tinc_nlink(d_inode(dentry->d_parent));\n\tfsnotify_mkdir(d_inode(dentry->d_parent), dentry);\n\treturn end_creating(dentry);\n}\nEXPORT_SYMBOL(debugfs_create_automount);\n\n/**\n * debugfs_create_symlink- create a symbolic link in the debugfs filesystem\n * @name: a pointer to a string containing the name of the symbolic link to\n *        create.\n * @parent: a pointer to the parent dentry for this symbolic link.  This\n *          should be a directory dentry if set.  If this parameter is NULL,\n *          then the symbolic link will be created in the root of the debugfs\n *          filesystem.\n * @target: a pointer to a string containing the path to the target of the\n *          symbolic link.\n *\n * This function creates a symbolic link with the given name in debugfs that\n * links to the given target path.\n *\n * This function will return a pointer to a dentry if it succeeds.  This\n * pointer must be passed to the debugfs_remove() function when the symbolic\n * link is to be removed (no automatic cleanup happens if your module is\n * unloaded, you are responsible here.)  If an error occurs, %NULL will be\n * returned.\n *\n * If debugfs is not enabled in the kernel, the value -%ENODEV will be\n * returned.\n */\nstruct dentry *debugfs_create_symlink(const char *name, struct dentry *parent,\n\t\t\t\t      const char *target)\n{\n\tstruct dentry *dentry;\n\tstruct inode *inode;\n\tchar *link = kstrdup(target, GFP_KERNEL);\n\tif (!link)\n\t\treturn NULL;\n\n\tdentry = start_creating(name, parent);\n\tif (IS_ERR(dentry)) {\n\t\tkfree(link);\n\t\treturn NULL;\n\t}\n\n\tinode = debugfs_get_inode(dentry->d_sb);\n\tif (unlikely(!inode)) {\n\t\tkfree(link);\n\t\treturn failed_creating(dentry);\n\t}\n\tinode->i_mode = S_IFLNK | S_IRWXUGO;\n\tinode->i_op = &simple_symlink_inode_operations;\n\tinode->i_link = link;\n\td_instantiate(dentry, inode);\n\treturn end_creating(dentry);\n}\nEXPORT_SYMBOL_GPL(debugfs_create_symlink);\n\nstatic int __debugfs_remove(struct dentry *dentry, struct dentry *parent)\n{\n\tint ret = 0;\n\n\tif (simple_positive(dentry)) {\n\t\tdget(dentry);\n\t\tif (d_is_dir(dentry))\n\t\t\tret = simple_rmdir(d_inode(parent), dentry);\n\t\telse\n\t\t\tsimple_unlink(d_inode(parent), dentry);\n\t\tif (!ret)\n\t\t\td_delete(dentry);\n\t\tdput(dentry);\n\t}\n\treturn ret;\n}\n\n/**\n * debugfs_remove - removes a file or directory from the debugfs filesystem\n * @dentry: a pointer to a the dentry of the file or directory to be\n *          removed.  If this parameter is NULL or an error value, nothing\n *          will be done.\n *\n * This function removes a file or directory in debugfs that was previously\n * created with a call to another debugfs function (like\n * debugfs_create_file() or variants thereof.)\n *\n * This function is required to be called in order for the file to be\n * removed, no automatic cleanup of files will happen when a module is\n * removed, you are responsible here.\n */\nvoid debugfs_remove(struct dentry *dentry)\n{\n\tstruct dentry *parent;\n\tint ret;\n\n\tif (IS_ERR_OR_NULL(dentry))\n\t\treturn;\n\n\tparent = dentry->d_parent;\n\tinode_lock(d_inode(parent));\n\tret = __debugfs_remove(dentry, parent);\n\tinode_unlock(d_inode(parent));\n\tif (!ret)\n\t\tsimple_release_fs(&debugfs_mount, &debugfs_mount_count);\n\n\tsynchronize_srcu(&debugfs_srcu);\n}\nEXPORT_SYMBOL_GPL(debugfs_remove);\n\n/**\n * debugfs_remove_recursive - recursively removes a directory\n * @dentry: a pointer to a the dentry of the directory to be removed.  If this\n *          parameter is NULL or an error value, nothing will be done.\n *\n * This function recursively removes a directory tree in debugfs that\n * was previously created with a call to another debugfs function\n * (like debugfs_create_file() or variants thereof.)\n *\n * This function is required to be called in order for the file to be\n * removed, no automatic cleanup of files will happen when a module is\n * removed, you are responsible here.\n */\nvoid debugfs_remove_recursive(struct dentry *dentry)\n{\n\tstruct dentry *child, *parent;\n\n\tif (IS_ERR_OR_NULL(dentry))\n\t\treturn;\n\n\tparent = dentry;\n down:\n\tinode_lock(d_inode(parent));\n loop:\n\t/*\n\t * The parent->d_subdirs is protected by the d_lock. Outside that\n\t * lock, the child can be unlinked and set to be freed which can\n\t * use the d_u.d_child as the rcu head and corrupt this list.\n\t */\n\tspin_lock(&parent->d_lock);\n\tlist_for_each_entry(child, &parent->d_subdirs, d_child) {\n\t\tif (!simple_positive(child))\n\t\t\tcontinue;\n\n\t\t/* perhaps simple_empty(child) makes more sense */\n\t\tif (!list_empty(&child->d_subdirs)) {\n\t\t\tspin_unlock(&parent->d_lock);\n\t\t\tinode_unlock(d_inode(parent));\n\t\t\tparent = child;\n\t\t\tgoto down;\n\t\t}\n\n\t\tspin_unlock(&parent->d_lock);\n\n\t\tif (!__debugfs_remove(child, parent))\n\t\t\tsimple_release_fs(&debugfs_mount, &debugfs_mount_count);\n\n\t\t/*\n\t\t * The parent->d_lock protects agaist child from unlinking\n\t\t * from d_subdirs. When releasing the parent->d_lock we can\n\t\t * no longer trust that the next pointer is valid.\n\t\t * Restart the loop. We'll skip this one with the\n\t\t * simple_positive() check.\n\t\t */\n\t\tgoto loop;\n\t}\n\tspin_unlock(&parent->d_lock);\n\n\tinode_unlock(d_inode(parent));\n\tchild = parent;\n\tparent = parent->d_parent;\n\tinode_lock(d_inode(parent));\n\n\tif (child != dentry)\n\t\t/* go up */\n\t\tgoto loop;\n\n\tif (!__debugfs_remove(child, parent))\n\t\tsimple_release_fs(&debugfs_mount, &debugfs_mount_count);\n\tinode_unlock(d_inode(parent));\n\n\tsynchronize_srcu(&debugfs_srcu);\n}\nEXPORT_SYMBOL_GPL(debugfs_remove_recursive);\n\n/**\n * debugfs_rename - rename a file/directory in the debugfs filesystem\n * @old_dir: a pointer to the parent dentry for the renamed object. This\n *          should be a directory dentry.\n * @old_dentry: dentry of an object to be renamed.\n * @new_dir: a pointer to the parent dentry where the object should be\n *          moved. This should be a directory dentry.\n * @new_name: a pointer to a string containing the target name.\n *\n * This function renames a file/directory in debugfs.  The target must not\n * exist for rename to succeed.\n *\n * This function will return a pointer to old_dentry (which is updated to\n * reflect renaming) if it succeeds. If an error occurs, %NULL will be\n * returned.\n *\n * If debugfs is not enabled in the kernel, the value -%ENODEV will be\n * returned.\n */\nstruct dentry *debugfs_rename(struct dentry *old_dir, struct dentry *old_dentry,\n\t\tstruct dentry *new_dir, const char *new_name)\n{\n\tint error;\n\tstruct dentry *dentry = NULL, *trap;\n\tstruct name_snapshot old_name;\n\n\ttrap = lock_rename(new_dir, old_dir);\n\t/* Source or destination directories don't exist? */\n\tif (d_really_is_negative(old_dir) || d_really_is_negative(new_dir))\n\t\tgoto exit;\n\t/* Source does not exist, cyclic rename, or mountpoint? */\n\tif (d_really_is_negative(old_dentry) || old_dentry == trap ||\n\t    d_mountpoint(old_dentry))\n\t\tgoto exit;\n\tdentry = lookup_one_len(new_name, new_dir, strlen(new_name));\n\t/* Lookup failed, cyclic rename or target exists? */\n\tif (IS_ERR(dentry) || dentry == trap || d_really_is_positive(dentry))\n\t\tgoto exit;\n\n\ttake_dentry_name_snapshot(&old_name, old_dentry);\n\n\terror = simple_rename(d_inode(old_dir), old_dentry, d_inode(new_dir),\n\t\t\t      dentry, 0);\n\tif (error) {\n\t\trelease_dentry_name_snapshot(&old_name);\n\t\tgoto exit;\n\t}\n\td_move(old_dentry, dentry);\n\tfsnotify_move(d_inode(old_dir), d_inode(new_dir), old_name.name,\n\t\td_is_dir(old_dentry),\n\t\tNULL, old_dentry);\n\trelease_dentry_name_snapshot(&old_name);\n\tunlock_rename(new_dir, old_dir);\n\tdput(dentry);\n\treturn old_dentry;\nexit:\n\tif (dentry && !IS_ERR(dentry))\n\t\tdput(dentry);\n\tunlock_rename(new_dir, old_dir);\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(debugfs_rename);\n\n/**\n * debugfs_initialized - Tells whether debugfs has been registered\n */\nbool debugfs_initialized(void)\n{\n\treturn debugfs_registered;\n}\nEXPORT_SYMBOL_GPL(debugfs_initialized);\n\nstatic int __init debugfs_init(void)\n{\n\tint retval;\n\n\tretval = sysfs_create_mount_point(kernel_kobj, \"debug\");\n\tif (retval)\n\t\treturn retval;\n\n\tretval = register_filesystem(&debug_fs_type);\n\tif (retval)\n\t\tsysfs_remove_mount_point(kernel_kobj, \"debug\");\n\telse\n\t\tdebugfs_registered = true;\n\n\treturn retval;\n}\ncore_initcall(debugfs_init);\n\n", "/*\n *  linux/fs/namei.c\n *\n *  Copyright (C) 1991, 1992  Linus Torvalds\n */\n\n/*\n * Some corrections by tytso.\n */\n\n/* [Feb 1997 T. Schoebel-Theuer] Complete rewrite of the pathname\n * lookup logic.\n */\n/* [Feb-Apr 2000, AV] Rewrite to the new namespace architecture.\n */\n\n#include <linux/init.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/slab.h>\n#include <linux/fs.h>\n#include <linux/namei.h>\n#include <linux/pagemap.h>\n#include <linux/fsnotify.h>\n#include <linux/personality.h>\n#include <linux/security.h>\n#include <linux/ima.h>\n#include <linux/syscalls.h>\n#include <linux/mount.h>\n#include <linux/audit.h>\n#include <linux/capability.h>\n#include <linux/file.h>\n#include <linux/fcntl.h>\n#include <linux/device_cgroup.h>\n#include <linux/fs_struct.h>\n#include <linux/posix_acl.h>\n#include <linux/hash.h>\n#include <linux/bitops.h>\n#include <linux/init_task.h>\n#include <linux/uaccess.h>\n\n#include \"internal.h\"\n#include \"mount.h\"\n\n/* [Feb-1997 T. Schoebel-Theuer]\n * Fundamental changes in the pathname lookup mechanisms (namei)\n * were necessary because of omirr.  The reason is that omirr needs\n * to know the _real_ pathname, not the user-supplied one, in case\n * of symlinks (and also when transname replacements occur).\n *\n * The new code replaces the old recursive symlink resolution with\n * an iterative one (in case of non-nested symlink chains).  It does\n * this with calls to <fs>_follow_link().\n * As a side effect, dir_namei(), _namei() and follow_link() are now \n * replaced with a single function lookup_dentry() that can handle all \n * the special cases of the former code.\n *\n * With the new dcache, the pathname is stored at each inode, at least as\n * long as the refcount of the inode is positive.  As a side effect, the\n * size of the dcache depends on the inode cache and thus is dynamic.\n *\n * [29-Apr-1998 C. Scott Ananian] Updated above description of symlink\n * resolution to correspond with current state of the code.\n *\n * Note that the symlink resolution is not *completely* iterative.\n * There is still a significant amount of tail- and mid- recursion in\n * the algorithm.  Also, note that <fs>_readlink() is not used in\n * lookup_dentry(): lookup_dentry() on the result of <fs>_readlink()\n * may return different results than <fs>_follow_link().  Many virtual\n * filesystems (including /proc) exhibit this behavior.\n */\n\n/* [24-Feb-97 T. Schoebel-Theuer] Side effects caused by new implementation:\n * New symlink semantics: when open() is called with flags O_CREAT | O_EXCL\n * and the name already exists in form of a symlink, try to create the new\n * name indicated by the symlink. The old code always complained that the\n * name already exists, due to not following the symlink even if its target\n * is nonexistent.  The new semantics affects also mknod() and link() when\n * the name is a symlink pointing to a non-existent name.\n *\n * I don't know which semantics is the right one, since I have no access\n * to standards. But I found by trial that HP-UX 9.0 has the full \"new\"\n * semantics implemented, while SunOS 4.1.1 and Solaris (SunOS 5.4) have the\n * \"old\" one. Personally, I think the new semantics is much more logical.\n * Note that \"ln old new\" where \"new\" is a symlink pointing to a non-existing\n * file does succeed in both HP-UX and SunOs, but not in Solaris\n * and in the old Linux semantics.\n */\n\n/* [16-Dec-97 Kevin Buhr] For security reasons, we change some symlink\n * semantics.  See the comments in \"open_namei\" and \"do_link\" below.\n *\n * [10-Sep-98 Alan Modra] Another symlink change.\n */\n\n/* [Feb-Apr 2000 AV] Complete rewrite. Rules for symlinks:\n *\tinside the path - always follow.\n *\tin the last component in creation/removal/renaming - never follow.\n *\tif LOOKUP_FOLLOW passed - follow.\n *\tif the pathname has trailing slashes - follow.\n *\totherwise - don't follow.\n * (applied in that order).\n *\n * [Jun 2000 AV] Inconsistent behaviour of open() in case if flags==O_CREAT\n * restored for 2.4. This is the last surviving part of old 4.2BSD bug.\n * During the 2.4 we need to fix the userland stuff depending on it -\n * hopefully we will be able to get rid of that wart in 2.5. So far only\n * XEmacs seems to be relying on it...\n */\n/*\n * [Sep 2001 AV] Single-semaphore locking scheme (kudos to David Holland)\n * implemented.  Let's see if raised priority of ->s_vfs_rename_mutex gives\n * any extra contention...\n */\n\n/* In order to reduce some races, while at the same time doing additional\n * checking and hopefully speeding things up, we copy filenames to the\n * kernel data space before using them..\n *\n * POSIX.1 2.4: an empty pathname is invalid (ENOENT).\n * PATH_MAX includes the nul terminator --RR.\n */\n\n#define EMBEDDED_NAME_MAX\t(PATH_MAX - offsetof(struct filename, iname))\n\nstruct filename *\ngetname_flags(const char __user *filename, int flags, int *empty)\n{\n\tstruct filename *result;\n\tchar *kname;\n\tint len;\n\n\tresult = audit_reusename(filename);\n\tif (result)\n\t\treturn result;\n\n\tresult = __getname();\n\tif (unlikely(!result))\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t/*\n\t * First, try to embed the struct filename inside the names_cache\n\t * allocation\n\t */\n\tkname = (char *)result->iname;\n\tresult->name = kname;\n\n\tlen = strncpy_from_user(kname, filename, EMBEDDED_NAME_MAX);\n\tif (unlikely(len < 0)) {\n\t\t__putname(result);\n\t\treturn ERR_PTR(len);\n\t}\n\n\t/*\n\t * Uh-oh. We have a name that's approaching PATH_MAX. Allocate a\n\t * separate struct filename so we can dedicate the entire\n\t * names_cache allocation for the pathname, and re-do the copy from\n\t * userland.\n\t */\n\tif (unlikely(len == EMBEDDED_NAME_MAX)) {\n\t\tconst size_t size = offsetof(struct filename, iname[1]);\n\t\tkname = (char *)result;\n\n\t\t/*\n\t\t * size is chosen that way we to guarantee that\n\t\t * result->iname[0] is within the same object and that\n\t\t * kname can't be equal to result->iname, no matter what.\n\t\t */\n\t\tresult = kzalloc(size, GFP_KERNEL);\n\t\tif (unlikely(!result)) {\n\t\t\t__putname(kname);\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t}\n\t\tresult->name = kname;\n\t\tlen = strncpy_from_user(kname, filename, PATH_MAX);\n\t\tif (unlikely(len < 0)) {\n\t\t\t__putname(kname);\n\t\t\tkfree(result);\n\t\t\treturn ERR_PTR(len);\n\t\t}\n\t\tif (unlikely(len == PATH_MAX)) {\n\t\t\t__putname(kname);\n\t\t\tkfree(result);\n\t\t\treturn ERR_PTR(-ENAMETOOLONG);\n\t\t}\n\t}\n\n\tresult->refcnt = 1;\n\t/* The empty path is special. */\n\tif (unlikely(!len)) {\n\t\tif (empty)\n\t\t\t*empty = 1;\n\t\tif (!(flags & LOOKUP_EMPTY)) {\n\t\t\tputname(result);\n\t\t\treturn ERR_PTR(-ENOENT);\n\t\t}\n\t}\n\n\tresult->uptr = filename;\n\tresult->aname = NULL;\n\taudit_getname(result);\n\treturn result;\n}\n\nstruct filename *\ngetname(const char __user * filename)\n{\n\treturn getname_flags(filename, 0, NULL);\n}\n\nstruct filename *\ngetname_kernel(const char * filename)\n{\n\tstruct filename *result;\n\tint len = strlen(filename) + 1;\n\n\tresult = __getname();\n\tif (unlikely(!result))\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tif (len <= EMBEDDED_NAME_MAX) {\n\t\tresult->name = (char *)result->iname;\n\t} else if (len <= PATH_MAX) {\n\t\tstruct filename *tmp;\n\n\t\ttmp = kmalloc(sizeof(*tmp), GFP_KERNEL);\n\t\tif (unlikely(!tmp)) {\n\t\t\t__putname(result);\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t}\n\t\ttmp->name = (char *)result;\n\t\tresult = tmp;\n\t} else {\n\t\t__putname(result);\n\t\treturn ERR_PTR(-ENAMETOOLONG);\n\t}\n\tmemcpy((char *)result->name, filename, len);\n\tresult->uptr = NULL;\n\tresult->aname = NULL;\n\tresult->refcnt = 1;\n\taudit_getname(result);\n\n\treturn result;\n}\n\nvoid putname(struct filename *name)\n{\n\tBUG_ON(name->refcnt <= 0);\n\n\tif (--name->refcnt > 0)\n\t\treturn;\n\n\tif (name->name != name->iname) {\n\t\t__putname(name->name);\n\t\tkfree(name);\n\t} else\n\t\t__putname(name);\n}\n\nstatic int check_acl(struct inode *inode, int mask)\n{\n#ifdef CONFIG_FS_POSIX_ACL\n\tstruct posix_acl *acl;\n\n\tif (mask & MAY_NOT_BLOCK) {\n\t\tacl = get_cached_acl_rcu(inode, ACL_TYPE_ACCESS);\n\t        if (!acl)\n\t                return -EAGAIN;\n\t\t/* no ->get_acl() calls in RCU mode... */\n\t\tif (is_uncached_acl(acl))\n\t\t\treturn -ECHILD;\n\t        return posix_acl_permission(inode, acl, mask & ~MAY_NOT_BLOCK);\n\t}\n\n\tacl = get_acl(inode, ACL_TYPE_ACCESS);\n\tif (IS_ERR(acl))\n\t\treturn PTR_ERR(acl);\n\tif (acl) {\n\t        int error = posix_acl_permission(inode, acl, mask);\n\t        posix_acl_release(acl);\n\t        return error;\n\t}\n#endif\n\n\treturn -EAGAIN;\n}\n\n/*\n * This does the basic permission checking\n */\nstatic int acl_permission_check(struct inode *inode, int mask)\n{\n\tunsigned int mode = inode->i_mode;\n\n\tif (likely(uid_eq(current_fsuid(), inode->i_uid)))\n\t\tmode >>= 6;\n\telse {\n\t\tif (IS_POSIXACL(inode) && (mode & S_IRWXG)) {\n\t\t\tint error = check_acl(inode, mask);\n\t\t\tif (error != -EAGAIN)\n\t\t\t\treturn error;\n\t\t}\n\n\t\tif (in_group_p(inode->i_gid))\n\t\t\tmode >>= 3;\n\t}\n\n\t/*\n\t * If the DACs are ok we don't need any capability check.\n\t */\n\tif ((mask & ~mode & (MAY_READ | MAY_WRITE | MAY_EXEC)) == 0)\n\t\treturn 0;\n\treturn -EACCES;\n}\n\n/**\n * generic_permission -  check for access rights on a Posix-like filesystem\n * @inode:\tinode to check access rights for\n * @mask:\tright to check for (%MAY_READ, %MAY_WRITE, %MAY_EXEC, ...)\n *\n * Used to check for read/write/execute permissions on a file.\n * We use \"fsuid\" for this, letting us set arbitrary permissions\n * for filesystem access without changing the \"normal\" uids which\n * are used for other things.\n *\n * generic_permission is rcu-walk aware. It returns -ECHILD in case an rcu-walk\n * request cannot be satisfied (eg. requires blocking or too much complexity).\n * It would then be called again in ref-walk mode.\n */\nint generic_permission(struct inode *inode, int mask)\n{\n\tint ret;\n\n\t/*\n\t * Do the basic permission checks.\n\t */\n\tret = acl_permission_check(inode, mask);\n\tif (ret != -EACCES)\n\t\treturn ret;\n\n\tif (S_ISDIR(inode->i_mode)) {\n\t\t/* DACs are overridable for directories */\n\t\tif (!(mask & MAY_WRITE))\n\t\t\tif (capable_wrt_inode_uidgid(inode,\n\t\t\t\t\t\t     CAP_DAC_READ_SEARCH))\n\t\t\t\treturn 0;\n\t\tif (capable_wrt_inode_uidgid(inode, CAP_DAC_OVERRIDE))\n\t\t\treturn 0;\n\t\treturn -EACCES;\n\t}\n\n\t/*\n\t * Searching includes executable on directories, else just read.\n\t */\n\tmask &= MAY_READ | MAY_WRITE | MAY_EXEC;\n\tif (mask == MAY_READ)\n\t\tif (capable_wrt_inode_uidgid(inode, CAP_DAC_READ_SEARCH))\n\t\t\treturn 0;\n\t/*\n\t * Read/write DACs are always overridable.\n\t * Executable DACs are overridable when there is\n\t * at least one exec bit set.\n\t */\n\tif (!(mask & MAY_EXEC) || (inode->i_mode & S_IXUGO))\n\t\tif (capable_wrt_inode_uidgid(inode, CAP_DAC_OVERRIDE))\n\t\t\treturn 0;\n\n\treturn -EACCES;\n}\nEXPORT_SYMBOL(generic_permission);\n\n/*\n * We _really_ want to just do \"generic_permission()\" without\n * even looking at the inode->i_op values. So we keep a cache\n * flag in inode->i_opflags, that says \"this has not special\n * permission function, use the fast case\".\n */\nstatic inline int do_inode_permission(struct inode *inode, int mask)\n{\n\tif (unlikely(!(inode->i_opflags & IOP_FASTPERM))) {\n\t\tif (likely(inode->i_op->permission))\n\t\t\treturn inode->i_op->permission(inode, mask);\n\n\t\t/* This gets set once for the inode lifetime */\n\t\tspin_lock(&inode->i_lock);\n\t\tinode->i_opflags |= IOP_FASTPERM;\n\t\tspin_unlock(&inode->i_lock);\n\t}\n\treturn generic_permission(inode, mask);\n}\n\n/**\n * __inode_permission - Check for access rights to a given inode\n * @inode: Inode to check permission on\n * @mask: Right to check for (%MAY_READ, %MAY_WRITE, %MAY_EXEC)\n *\n * Check for read/write/execute permissions on an inode.\n *\n * When checking for MAY_APPEND, MAY_WRITE must also be set in @mask.\n *\n * This does not check for a read-only file system.  You probably want\n * inode_permission().\n */\nint __inode_permission(struct inode *inode, int mask)\n{\n\tint retval;\n\n\tif (unlikely(mask & MAY_WRITE)) {\n\t\t/*\n\t\t * Nobody gets write access to an immutable file.\n\t\t */\n\t\tif (IS_IMMUTABLE(inode))\n\t\t\treturn -EPERM;\n\n\t\t/*\n\t\t * Updating mtime will likely cause i_uid and i_gid to be\n\t\t * written back improperly if their true value is unknown\n\t\t * to the vfs.\n\t\t */\n\t\tif (HAS_UNMAPPED_ID(inode))\n\t\t\treturn -EACCES;\n\t}\n\n\tretval = do_inode_permission(inode, mask);\n\tif (retval)\n\t\treturn retval;\n\n\tretval = devcgroup_inode_permission(inode, mask);\n\tif (retval)\n\t\treturn retval;\n\n\treturn security_inode_permission(inode, mask);\n}\nEXPORT_SYMBOL(__inode_permission);\n\n/**\n * sb_permission - Check superblock-level permissions\n * @sb: Superblock of inode to check permission on\n * @inode: Inode to check permission on\n * @mask: Right to check for (%MAY_READ, %MAY_WRITE, %MAY_EXEC)\n *\n * Separate out file-system wide checks from inode-specific permission checks.\n */\nstatic int sb_permission(struct super_block *sb, struct inode *inode, int mask)\n{\n\tif (unlikely(mask & MAY_WRITE)) {\n\t\tumode_t mode = inode->i_mode;\n\n\t\t/* Nobody gets write access to a read-only fs. */\n\t\tif ((sb->s_flags & MS_RDONLY) &&\n\t\t    (S_ISREG(mode) || S_ISDIR(mode) || S_ISLNK(mode)))\n\t\t\treturn -EROFS;\n\t}\n\treturn 0;\n}\n\n/**\n * inode_permission - Check for access rights to a given inode\n * @inode: Inode to check permission on\n * @mask: Right to check for (%MAY_READ, %MAY_WRITE, %MAY_EXEC)\n *\n * Check for read/write/execute permissions on an inode.  We use fs[ug]id for\n * this, letting us set arbitrary permissions for filesystem access without\n * changing the \"normal\" UIDs which are used for other things.\n *\n * When checking for MAY_APPEND, MAY_WRITE must also be set in @mask.\n */\nint inode_permission(struct inode *inode, int mask)\n{\n\tint retval;\n\n\tretval = sb_permission(inode->i_sb, inode, mask);\n\tif (retval)\n\t\treturn retval;\n\treturn __inode_permission(inode, mask);\n}\nEXPORT_SYMBOL(inode_permission);\n\n/**\n * path_get - get a reference to a path\n * @path: path to get the reference to\n *\n * Given a path increment the reference count to the dentry and the vfsmount.\n */\nvoid path_get(const struct path *path)\n{\n\tmntget(path->mnt);\n\tdget(path->dentry);\n}\nEXPORT_SYMBOL(path_get);\n\n/**\n * path_put - put a reference to a path\n * @path: path to put the reference to\n *\n * Given a path decrement the reference count to the dentry and the vfsmount.\n */\nvoid path_put(const struct path *path)\n{\n\tdput(path->dentry);\n\tmntput(path->mnt);\n}\nEXPORT_SYMBOL(path_put);\n\n#define EMBEDDED_LEVELS 2\nstruct nameidata {\n\tstruct path\tpath;\n\tstruct qstr\tlast;\n\tstruct path\troot;\n\tstruct inode\t*inode; /* path.dentry.d_inode */\n\tunsigned int\tflags;\n\tunsigned\tseq, m_seq;\n\tint\t\tlast_type;\n\tunsigned\tdepth;\n\tint\t\ttotal_link_count;\n\tstruct saved {\n\t\tstruct path link;\n\t\tstruct delayed_call done;\n\t\tconst char *name;\n\t\tunsigned seq;\n\t} *stack, internal[EMBEDDED_LEVELS];\n\tstruct filename\t*name;\n\tstruct nameidata *saved;\n\tstruct inode\t*link_inode;\n\tunsigned\troot_seq;\n\tint\t\tdfd;\n};\n\nstatic void set_nameidata(struct nameidata *p, int dfd, struct filename *name)\n{\n\tstruct nameidata *old = current->nameidata;\n\tp->stack = p->internal;\n\tp->dfd = dfd;\n\tp->name = name;\n\tp->total_link_count = old ? old->total_link_count : 0;\n\tp->saved = old;\n\tcurrent->nameidata = p;\n}\n\nstatic void restore_nameidata(void)\n{\n\tstruct nameidata *now = current->nameidata, *old = now->saved;\n\n\tcurrent->nameidata = old;\n\tif (old)\n\t\told->total_link_count = now->total_link_count;\n\tif (now->stack != now->internal)\n\t\tkfree(now->stack);\n}\n\nstatic int __nd_alloc_stack(struct nameidata *nd)\n{\n\tstruct saved *p;\n\n\tif (nd->flags & LOOKUP_RCU) {\n\t\tp= kmalloc(MAXSYMLINKS * sizeof(struct saved),\n\t\t\t\t  GFP_ATOMIC);\n\t\tif (unlikely(!p))\n\t\t\treturn -ECHILD;\n\t} else {\n\t\tp= kmalloc(MAXSYMLINKS * sizeof(struct saved),\n\t\t\t\t  GFP_KERNEL);\n\t\tif (unlikely(!p))\n\t\t\treturn -ENOMEM;\n\t}\n\tmemcpy(p, nd->internal, sizeof(nd->internal));\n\tnd->stack = p;\n\treturn 0;\n}\n\n/**\n * path_connected - Verify that a path->dentry is below path->mnt.mnt_root\n * @path: nameidate to verify\n *\n * Rename can sometimes move a file or directory outside of a bind\n * mount, path_connected allows those cases to be detected.\n */\nstatic bool path_connected(const struct path *path)\n{\n\tstruct vfsmount *mnt = path->mnt;\n\n\t/* Only bind mounts can have disconnected paths */\n\tif (mnt->mnt_root == mnt->mnt_sb->s_root)\n\t\treturn true;\n\n\treturn is_subdir(path->dentry, mnt->mnt_root);\n}\n\nstatic inline int nd_alloc_stack(struct nameidata *nd)\n{\n\tif (likely(nd->depth != EMBEDDED_LEVELS))\n\t\treturn 0;\n\tif (likely(nd->stack != nd->internal))\n\t\treturn 0;\n\treturn __nd_alloc_stack(nd);\n}\n\nstatic void drop_links(struct nameidata *nd)\n{\n\tint i = nd->depth;\n\twhile (i--) {\n\t\tstruct saved *last = nd->stack + i;\n\t\tdo_delayed_call(&last->done);\n\t\tclear_delayed_call(&last->done);\n\t}\n}\n\nstatic void terminate_walk(struct nameidata *nd)\n{\n\tdrop_links(nd);\n\tif (!(nd->flags & LOOKUP_RCU)) {\n\t\tint i;\n\t\tpath_put(&nd->path);\n\t\tfor (i = 0; i < nd->depth; i++)\n\t\t\tpath_put(&nd->stack[i].link);\n\t\tif (nd->root.mnt && !(nd->flags & LOOKUP_ROOT)) {\n\t\t\tpath_put(&nd->root);\n\t\t\tnd->root.mnt = NULL;\n\t\t}\n\t} else {\n\t\tnd->flags &= ~LOOKUP_RCU;\n\t\tif (!(nd->flags & LOOKUP_ROOT))\n\t\t\tnd->root.mnt = NULL;\n\t\trcu_read_unlock();\n\t}\n\tnd->depth = 0;\n}\n\n/* path_put is needed afterwards regardless of success or failure */\nstatic bool legitimize_path(struct nameidata *nd,\n\t\t\t    struct path *path, unsigned seq)\n{\n\tint res = __legitimize_mnt(path->mnt, nd->m_seq);\n\tif (unlikely(res)) {\n\t\tif (res > 0)\n\t\t\tpath->mnt = NULL;\n\t\tpath->dentry = NULL;\n\t\treturn false;\n\t}\n\tif (unlikely(!lockref_get_not_dead(&path->dentry->d_lockref))) {\n\t\tpath->dentry = NULL;\n\t\treturn false;\n\t}\n\treturn !read_seqcount_retry(&path->dentry->d_seq, seq);\n}\n\nstatic bool legitimize_links(struct nameidata *nd)\n{\n\tint i;\n\tfor (i = 0; i < nd->depth; i++) {\n\t\tstruct saved *last = nd->stack + i;\n\t\tif (unlikely(!legitimize_path(nd, &last->link, last->seq))) {\n\t\t\tdrop_links(nd);\n\t\t\tnd->depth = i + 1;\n\t\t\treturn false;\n\t\t}\n\t}\n\treturn true;\n}\n\n/*\n * Path walking has 2 modes, rcu-walk and ref-walk (see\n * Documentation/filesystems/path-lookup.txt).  In situations when we can't\n * continue in RCU mode, we attempt to drop out of rcu-walk mode and grab\n * normal reference counts on dentries and vfsmounts to transition to ref-walk\n * mode.  Refcounts are grabbed at the last known good point before rcu-walk\n * got stuck, so ref-walk may continue from there. If this is not successful\n * (eg. a seqcount has changed), then failure is returned and it's up to caller\n * to restart the path walk from the beginning in ref-walk mode.\n */\n\n/**\n * unlazy_walk - try to switch to ref-walk mode.\n * @nd: nameidata pathwalk data\n * Returns: 0 on success, -ECHILD on failure\n *\n * unlazy_walk attempts to legitimize the current nd->path and nd->root\n * for ref-walk mode.\n * Must be called from rcu-walk context.\n * Nothing should touch nameidata between unlazy_walk() failure and\n * terminate_walk().\n */\nstatic int unlazy_walk(struct nameidata *nd)\n{\n\tstruct dentry *parent = nd->path.dentry;\n\n\tBUG_ON(!(nd->flags & LOOKUP_RCU));\n\n\tnd->flags &= ~LOOKUP_RCU;\n\tif (unlikely(!legitimize_links(nd)))\n\t\tgoto out2;\n\tif (unlikely(!legitimize_path(nd, &nd->path, nd->seq)))\n\t\tgoto out1;\n\tif (nd->root.mnt && !(nd->flags & LOOKUP_ROOT)) {\n\t\tif (unlikely(!legitimize_path(nd, &nd->root, nd->root_seq)))\n\t\t\tgoto out;\n\t}\n\trcu_read_unlock();\n\tBUG_ON(nd->inode != parent->d_inode);\n\treturn 0;\n\nout2:\n\tnd->path.mnt = NULL;\n\tnd->path.dentry = NULL;\nout1:\n\tif (!(nd->flags & LOOKUP_ROOT))\n\t\tnd->root.mnt = NULL;\nout:\n\trcu_read_unlock();\n\treturn -ECHILD;\n}\n\n/**\n * unlazy_child - try to switch to ref-walk mode.\n * @nd: nameidata pathwalk data\n * @dentry: child of nd->path.dentry\n * @seq: seq number to check dentry against\n * Returns: 0 on success, -ECHILD on failure\n *\n * unlazy_child attempts to legitimize the current nd->path, nd->root and dentry\n * for ref-walk mode.  @dentry must be a path found by a do_lookup call on\n * @nd.  Must be called from rcu-walk context.\n * Nothing should touch nameidata between unlazy_child() failure and\n * terminate_walk().\n */\nstatic int unlazy_child(struct nameidata *nd, struct dentry *dentry, unsigned seq)\n{\n\tBUG_ON(!(nd->flags & LOOKUP_RCU));\n\n\tnd->flags &= ~LOOKUP_RCU;\n\tif (unlikely(!legitimize_links(nd)))\n\t\tgoto out2;\n\tif (unlikely(!legitimize_mnt(nd->path.mnt, nd->m_seq)))\n\t\tgoto out2;\n\tif (unlikely(!lockref_get_not_dead(&nd->path.dentry->d_lockref)))\n\t\tgoto out1;\n\n\t/*\n\t * We need to move both the parent and the dentry from the RCU domain\n\t * to be properly refcounted. And the sequence number in the dentry\n\t * validates *both* dentry counters, since we checked the sequence\n\t * number of the parent after we got the child sequence number. So we\n\t * know the parent must still be valid if the child sequence number is\n\t */\n\tif (unlikely(!lockref_get_not_dead(&dentry->d_lockref)))\n\t\tgoto out;\n\tif (unlikely(read_seqcount_retry(&dentry->d_seq, seq))) {\n\t\trcu_read_unlock();\n\t\tdput(dentry);\n\t\tgoto drop_root_mnt;\n\t}\n\t/*\n\t * Sequence counts matched. Now make sure that the root is\n\t * still valid and get it if required.\n\t */\n\tif (nd->root.mnt && !(nd->flags & LOOKUP_ROOT)) {\n\t\tif (unlikely(!legitimize_path(nd, &nd->root, nd->root_seq))) {\n\t\t\trcu_read_unlock();\n\t\t\tdput(dentry);\n\t\t\treturn -ECHILD;\n\t\t}\n\t}\n\n\trcu_read_unlock();\n\treturn 0;\n\nout2:\n\tnd->path.mnt = NULL;\nout1:\n\tnd->path.dentry = NULL;\nout:\n\trcu_read_unlock();\ndrop_root_mnt:\n\tif (!(nd->flags & LOOKUP_ROOT))\n\t\tnd->root.mnt = NULL;\n\treturn -ECHILD;\n}\n\nstatic inline int d_revalidate(struct dentry *dentry, unsigned int flags)\n{\n\tif (unlikely(dentry->d_flags & DCACHE_OP_REVALIDATE))\n\t\treturn dentry->d_op->d_revalidate(dentry, flags);\n\telse\n\t\treturn 1;\n}\n\n/**\n * complete_walk - successful completion of path walk\n * @nd:  pointer nameidata\n *\n * If we had been in RCU mode, drop out of it and legitimize nd->path.\n * Revalidate the final result, unless we'd already done that during\n * the path walk or the filesystem doesn't ask for it.  Return 0 on\n * success, -error on failure.  In case of failure caller does not\n * need to drop nd->path.\n */\nstatic int complete_walk(struct nameidata *nd)\n{\n\tstruct dentry *dentry = nd->path.dentry;\n\tint status;\n\n\tif (nd->flags & LOOKUP_RCU) {\n\t\tif (!(nd->flags & LOOKUP_ROOT))\n\t\t\tnd->root.mnt = NULL;\n\t\tif (unlikely(unlazy_walk(nd)))\n\t\t\treturn -ECHILD;\n\t}\n\n\tif (likely(!(nd->flags & LOOKUP_JUMPED)))\n\t\treturn 0;\n\n\tif (likely(!(dentry->d_flags & DCACHE_OP_WEAK_REVALIDATE)))\n\t\treturn 0;\n\n\tstatus = dentry->d_op->d_weak_revalidate(dentry, nd->flags);\n\tif (status > 0)\n\t\treturn 0;\n\n\tif (!status)\n\t\tstatus = -ESTALE;\n\n\treturn status;\n}\n\nstatic void set_root(struct nameidata *nd)\n{\n\tstruct fs_struct *fs = current->fs;\n\n\tif (nd->flags & LOOKUP_RCU) {\n\t\tunsigned seq;\n\n\t\tdo {\n\t\t\tseq = read_seqcount_begin(&fs->seq);\n\t\t\tnd->root = fs->root;\n\t\t\tnd->root_seq = __read_seqcount_begin(&nd->root.dentry->d_seq);\n\t\t} while (read_seqcount_retry(&fs->seq, seq));\n\t} else {\n\t\tget_fs_root(fs, &nd->root);\n\t}\n}\n\nstatic void path_put_conditional(struct path *path, struct nameidata *nd)\n{\n\tdput(path->dentry);\n\tif (path->mnt != nd->path.mnt)\n\t\tmntput(path->mnt);\n}\n\nstatic inline void path_to_nameidata(const struct path *path,\n\t\t\t\t\tstruct nameidata *nd)\n{\n\tif (!(nd->flags & LOOKUP_RCU)) {\n\t\tdput(nd->path.dentry);\n\t\tif (nd->path.mnt != path->mnt)\n\t\t\tmntput(nd->path.mnt);\n\t}\n\tnd->path.mnt = path->mnt;\n\tnd->path.dentry = path->dentry;\n}\n\nstatic int nd_jump_root(struct nameidata *nd)\n{\n\tif (nd->flags & LOOKUP_RCU) {\n\t\tstruct dentry *d;\n\t\tnd->path = nd->root;\n\t\td = nd->path.dentry;\n\t\tnd->inode = d->d_inode;\n\t\tnd->seq = nd->root_seq;\n\t\tif (unlikely(read_seqcount_retry(&d->d_seq, nd->seq)))\n\t\t\treturn -ECHILD;\n\t} else {\n\t\tpath_put(&nd->path);\n\t\tnd->path = nd->root;\n\t\tpath_get(&nd->path);\n\t\tnd->inode = nd->path.dentry->d_inode;\n\t}\n\tnd->flags |= LOOKUP_JUMPED;\n\treturn 0;\n}\n\n/*\n * Helper to directly jump to a known parsed path from ->get_link,\n * caller must have taken a reference to path beforehand.\n */\nvoid nd_jump_link(struct path *path)\n{\n\tstruct nameidata *nd = current->nameidata;\n\tpath_put(&nd->path);\n\n\tnd->path = *path;\n\tnd->inode = nd->path.dentry->d_inode;\n\tnd->flags |= LOOKUP_JUMPED;\n}\n\nstatic inline void put_link(struct nameidata *nd)\n{\n\tstruct saved *last = nd->stack + --nd->depth;\n\tdo_delayed_call(&last->done);\n\tif (!(nd->flags & LOOKUP_RCU))\n\t\tpath_put(&last->link);\n}\n\nint sysctl_protected_symlinks __read_mostly = 0;\nint sysctl_protected_hardlinks __read_mostly = 0;\n\n/**\n * may_follow_link - Check symlink following for unsafe situations\n * @nd: nameidata pathwalk data\n *\n * In the case of the sysctl_protected_symlinks sysctl being enabled,\n * CAP_DAC_OVERRIDE needs to be specifically ignored if the symlink is\n * in a sticky world-writable directory. This is to protect privileged\n * processes from failing races against path names that may change out\n * from under them by way of other users creating malicious symlinks.\n * It will permit symlinks to be followed only when outside a sticky\n * world-writable directory, or when the uid of the symlink and follower\n * match, or when the directory owner matches the symlink's owner.\n *\n * Returns 0 if following the symlink is allowed, -ve on error.\n */\nstatic inline int may_follow_link(struct nameidata *nd)\n{\n\tconst struct inode *inode;\n\tconst struct inode *parent;\n\tkuid_t puid;\n\n\tif (!sysctl_protected_symlinks)\n\t\treturn 0;\n\n\t/* Allowed if owner and follower match. */\n\tinode = nd->link_inode;\n\tif (uid_eq(current_cred()->fsuid, inode->i_uid))\n\t\treturn 0;\n\n\t/* Allowed if parent directory not sticky and world-writable. */\n\tparent = nd->inode;\n\tif ((parent->i_mode & (S_ISVTX|S_IWOTH)) != (S_ISVTX|S_IWOTH))\n\t\treturn 0;\n\n\t/* Allowed if parent directory and link owner match. */\n\tpuid = parent->i_uid;\n\tif (uid_valid(puid) && uid_eq(puid, inode->i_uid))\n\t\treturn 0;\n\n\tif (nd->flags & LOOKUP_RCU)\n\t\treturn -ECHILD;\n\n\taudit_log_link_denied(\"follow_link\", &nd->stack[0].link);\n\treturn -EACCES;\n}\n\n/**\n * safe_hardlink_source - Check for safe hardlink conditions\n * @inode: the source inode to hardlink from\n *\n * Return false if at least one of the following conditions:\n *    - inode is not a regular file\n *    - inode is setuid\n *    - inode is setgid and group-exec\n *    - access failure for read and write\n *\n * Otherwise returns true.\n */\nstatic bool safe_hardlink_source(struct inode *inode)\n{\n\tumode_t mode = inode->i_mode;\n\n\t/* Special files should not get pinned to the filesystem. */\n\tif (!S_ISREG(mode))\n\t\treturn false;\n\n\t/* Setuid files should not get pinned to the filesystem. */\n\tif (mode & S_ISUID)\n\t\treturn false;\n\n\t/* Executable setgid files should not get pinned to the filesystem. */\n\tif ((mode & (S_ISGID | S_IXGRP)) == (S_ISGID | S_IXGRP))\n\t\treturn false;\n\n\t/* Hardlinking to unreadable or unwritable sources is dangerous. */\n\tif (inode_permission(inode, MAY_READ | MAY_WRITE))\n\t\treturn false;\n\n\treturn true;\n}\n\n/**\n * may_linkat - Check permissions for creating a hardlink\n * @link: the source to hardlink from\n *\n * Block hardlink when all of:\n *  - sysctl_protected_hardlinks enabled\n *  - fsuid does not match inode\n *  - hardlink source is unsafe (see safe_hardlink_source() above)\n *  - not CAP_FOWNER in a namespace with the inode owner uid mapped\n *\n * Returns 0 if successful, -ve on error.\n */\nstatic int may_linkat(struct path *link)\n{\n\tstruct inode *inode;\n\n\tif (!sysctl_protected_hardlinks)\n\t\treturn 0;\n\n\tinode = link->dentry->d_inode;\n\n\t/* Source inode owner (or CAP_FOWNER) can hardlink all they like,\n\t * otherwise, it must be a safe source.\n\t */\n\tif (safe_hardlink_source(inode) || inode_owner_or_capable(inode))\n\t\treturn 0;\n\n\taudit_log_link_denied(\"linkat\", link);\n\treturn -EPERM;\n}\n\nstatic __always_inline\nconst char *get_link(struct nameidata *nd)\n{\n\tstruct saved *last = nd->stack + nd->depth - 1;\n\tstruct dentry *dentry = last->link.dentry;\n\tstruct inode *inode = nd->link_inode;\n\tint error;\n\tconst char *res;\n\n\tif (!(nd->flags & LOOKUP_RCU)) {\n\t\ttouch_atime(&last->link);\n\t\tcond_resched();\n\t} else if (atime_needs_update_rcu(&last->link, inode)) {\n\t\tif (unlikely(unlazy_walk(nd)))\n\t\t\treturn ERR_PTR(-ECHILD);\n\t\ttouch_atime(&last->link);\n\t}\n\n\terror = security_inode_follow_link(dentry, inode,\n\t\t\t\t\t   nd->flags & LOOKUP_RCU);\n\tif (unlikely(error))\n\t\treturn ERR_PTR(error);\n\n\tnd->last_type = LAST_BIND;\n\tres = inode->i_link;\n\tif (!res) {\n\t\tconst char * (*get)(struct dentry *, struct inode *,\n\t\t\t\tstruct delayed_call *);\n\t\tget = inode->i_op->get_link;\n\t\tif (nd->flags & LOOKUP_RCU) {\n\t\t\tres = get(NULL, inode, &last->done);\n\t\t\tif (res == ERR_PTR(-ECHILD)) {\n\t\t\t\tif (unlikely(unlazy_walk(nd)))\n\t\t\t\t\treturn ERR_PTR(-ECHILD);\n\t\t\t\tres = get(dentry, inode, &last->done);\n\t\t\t}\n\t\t} else {\n\t\t\tres = get(dentry, inode, &last->done);\n\t\t}\n\t\tif (IS_ERR_OR_NULL(res))\n\t\t\treturn res;\n\t}\n\tif (*res == '/') {\n\t\tif (!nd->root.mnt)\n\t\t\tset_root(nd);\n\t\tif (unlikely(nd_jump_root(nd)))\n\t\t\treturn ERR_PTR(-ECHILD);\n\t\twhile (unlikely(*++res == '/'))\n\t\t\t;\n\t}\n\tif (!*res)\n\t\tres = NULL;\n\treturn res;\n}\n\n/*\n * follow_up - Find the mountpoint of path's vfsmount\n *\n * Given a path, find the mountpoint of its source file system.\n * Replace @path with the path of the mountpoint in the parent mount.\n * Up is towards /.\n *\n * Return 1 if we went up a level and 0 if we were already at the\n * root.\n */\nint follow_up(struct path *path)\n{\n\tstruct mount *mnt = real_mount(path->mnt);\n\tstruct mount *parent;\n\tstruct dentry *mountpoint;\n\n\tread_seqlock_excl(&mount_lock);\n\tparent = mnt->mnt_parent;\n\tif (parent == mnt) {\n\t\tread_sequnlock_excl(&mount_lock);\n\t\treturn 0;\n\t}\n\tmntget(&parent->mnt);\n\tmountpoint = dget(mnt->mnt_mountpoint);\n\tread_sequnlock_excl(&mount_lock);\n\tdput(path->dentry);\n\tpath->dentry = mountpoint;\n\tmntput(path->mnt);\n\tpath->mnt = &parent->mnt;\n\treturn 1;\n}\nEXPORT_SYMBOL(follow_up);\n\n/*\n * Perform an automount\n * - return -EISDIR to tell follow_managed() to stop and return the path we\n *   were called with.\n */\nstatic int follow_automount(struct path *path, struct nameidata *nd,\n\t\t\t    bool *need_mntput)\n{\n\tstruct vfsmount *mnt;\n\tint err;\n\n\tif (!path->dentry->d_op || !path->dentry->d_op->d_automount)\n\t\treturn -EREMOTE;\n\n\t/* We don't want to mount if someone's just doing a stat -\n\t * unless they're stat'ing a directory and appended a '/' to\n\t * the name.\n\t *\n\t * We do, however, want to mount if someone wants to open or\n\t * create a file of any type under the mountpoint, wants to\n\t * traverse through the mountpoint or wants to open the\n\t * mounted directory.  Also, autofs may mark negative dentries\n\t * as being automount points.  These will need the attentions\n\t * of the daemon to instantiate them before they can be used.\n\t */\n\tif (!(nd->flags & (LOOKUP_PARENT | LOOKUP_DIRECTORY |\n\t\t\t   LOOKUP_OPEN | LOOKUP_CREATE | LOOKUP_AUTOMOUNT)) &&\n\t    path->dentry->d_inode)\n\t\treturn -EISDIR;\n\n\tif (path->dentry->d_sb->s_user_ns != &init_user_ns)\n\t\treturn -EACCES;\n\n\tnd->total_link_count++;\n\tif (nd->total_link_count >= 40)\n\t\treturn -ELOOP;\n\n\tmnt = path->dentry->d_op->d_automount(path);\n\tif (IS_ERR(mnt)) {\n\t\t/*\n\t\t * The filesystem is allowed to return -EISDIR here to indicate\n\t\t * it doesn't want to automount.  For instance, autofs would do\n\t\t * this so that its userspace daemon can mount on this dentry.\n\t\t *\n\t\t * However, we can only permit this if it's a terminal point in\n\t\t * the path being looked up; if it wasn't then the remainder of\n\t\t * the path is inaccessible and we should say so.\n\t\t */\n\t\tif (PTR_ERR(mnt) == -EISDIR && (nd->flags & LOOKUP_PARENT))\n\t\t\treturn -EREMOTE;\n\t\treturn PTR_ERR(mnt);\n\t}\n\n\tif (!mnt) /* mount collision */\n\t\treturn 0;\n\n\tif (!*need_mntput) {\n\t\t/* lock_mount() may release path->mnt on error */\n\t\tmntget(path->mnt);\n\t\t*need_mntput = true;\n\t}\n\terr = finish_automount(mnt, path);\n\n\tswitch (err) {\n\tcase -EBUSY:\n\t\t/* Someone else made a mount here whilst we were busy */\n\t\treturn 0;\n\tcase 0:\n\t\tpath_put(path);\n\t\tpath->mnt = mnt;\n\t\tpath->dentry = dget(mnt->mnt_root);\n\t\treturn 0;\n\tdefault:\n\t\treturn err;\n\t}\n\n}\n\n/*\n * Handle a dentry that is managed in some way.\n * - Flagged for transit management (autofs)\n * - Flagged as mountpoint\n * - Flagged as automount point\n *\n * This may only be called in refwalk mode.\n *\n * Serialization is taken care of in namespace.c\n */\nstatic int follow_managed(struct path *path, struct nameidata *nd)\n{\n\tstruct vfsmount *mnt = path->mnt; /* held by caller, must be left alone */\n\tunsigned managed;\n\tbool need_mntput = false;\n\tint ret = 0;\n\n\t/* Given that we're not holding a lock here, we retain the value in a\n\t * local variable for each dentry as we look at it so that we don't see\n\t * the components of that value change under us */\n\twhile (managed = ACCESS_ONCE(path->dentry->d_flags),\n\t       managed &= DCACHE_MANAGED_DENTRY,\n\t       unlikely(managed != 0)) {\n\t\t/* Allow the filesystem to manage the transit without i_mutex\n\t\t * being held. */\n\t\tif (managed & DCACHE_MANAGE_TRANSIT) {\n\t\t\tBUG_ON(!path->dentry->d_op);\n\t\t\tBUG_ON(!path->dentry->d_op->d_manage);\n\t\t\tret = path->dentry->d_op->d_manage(path, false);\n\t\t\tif (ret < 0)\n\t\t\t\tbreak;\n\t\t}\n\n\t\t/* Transit to a mounted filesystem. */\n\t\tif (managed & DCACHE_MOUNTED) {\n\t\t\tstruct vfsmount *mounted = lookup_mnt(path);\n\t\t\tif (mounted) {\n\t\t\t\tdput(path->dentry);\n\t\t\t\tif (need_mntput)\n\t\t\t\t\tmntput(path->mnt);\n\t\t\t\tpath->mnt = mounted;\n\t\t\t\tpath->dentry = dget(mounted->mnt_root);\n\t\t\t\tneed_mntput = true;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t/* Something is mounted on this dentry in another\n\t\t\t * namespace and/or whatever was mounted there in this\n\t\t\t * namespace got unmounted before lookup_mnt() could\n\t\t\t * get it */\n\t\t}\n\n\t\t/* Handle an automount point */\n\t\tif (managed & DCACHE_NEED_AUTOMOUNT) {\n\t\t\tret = follow_automount(path, nd, &need_mntput);\n\t\t\tif (ret < 0)\n\t\t\t\tbreak;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* We didn't change the current path point */\n\t\tbreak;\n\t}\n\n\tif (need_mntput && path->mnt == mnt)\n\t\tmntput(path->mnt);\n\tif (ret == -EISDIR || !ret)\n\t\tret = 1;\n\tif (need_mntput)\n\t\tnd->flags |= LOOKUP_JUMPED;\n\tif (unlikely(ret < 0))\n\t\tpath_put_conditional(path, nd);\n\treturn ret;\n}\n\nint follow_down_one(struct path *path)\n{\n\tstruct vfsmount *mounted;\n\n\tmounted = lookup_mnt(path);\n\tif (mounted) {\n\t\tdput(path->dentry);\n\t\tmntput(path->mnt);\n\t\tpath->mnt = mounted;\n\t\tpath->dentry = dget(mounted->mnt_root);\n\t\treturn 1;\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL(follow_down_one);\n\nstatic inline int managed_dentry_rcu(const struct path *path)\n{\n\treturn (path->dentry->d_flags & DCACHE_MANAGE_TRANSIT) ?\n\t\tpath->dentry->d_op->d_manage(path, true) : 0;\n}\n\n/*\n * Try to skip to top of mountpoint pile in rcuwalk mode.  Fail if\n * we meet a managed dentry that would need blocking.\n */\nstatic bool __follow_mount_rcu(struct nameidata *nd, struct path *path,\n\t\t\t       struct inode **inode, unsigned *seqp)\n{\n\tfor (;;) {\n\t\tstruct mount *mounted;\n\t\t/*\n\t\t * Don't forget we might have a non-mountpoint managed dentry\n\t\t * that wants to block transit.\n\t\t */\n\t\tswitch (managed_dentry_rcu(path)) {\n\t\tcase -ECHILD:\n\t\tdefault:\n\t\t\treturn false;\n\t\tcase -EISDIR:\n\t\t\treturn true;\n\t\tcase 0:\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!d_mountpoint(path->dentry))\n\t\t\treturn !(path->dentry->d_flags & DCACHE_NEED_AUTOMOUNT);\n\n\t\tmounted = __lookup_mnt(path->mnt, path->dentry);\n\t\tif (!mounted)\n\t\t\tbreak;\n\t\tpath->mnt = &mounted->mnt;\n\t\tpath->dentry = mounted->mnt.mnt_root;\n\t\tnd->flags |= LOOKUP_JUMPED;\n\t\t*seqp = read_seqcount_begin(&path->dentry->d_seq);\n\t\t/*\n\t\t * Update the inode too. We don't need to re-check the\n\t\t * dentry sequence number here after this d_inode read,\n\t\t * because a mount-point is always pinned.\n\t\t */\n\t\t*inode = path->dentry->d_inode;\n\t}\n\treturn !read_seqretry(&mount_lock, nd->m_seq) &&\n\t\t!(path->dentry->d_flags & DCACHE_NEED_AUTOMOUNT);\n}\n\nstatic int follow_dotdot_rcu(struct nameidata *nd)\n{\n\tstruct inode *inode = nd->inode;\n\n\twhile (1) {\n\t\tif (path_equal(&nd->path, &nd->root))\n\t\t\tbreak;\n\t\tif (nd->path.dentry != nd->path.mnt->mnt_root) {\n\t\t\tstruct dentry *old = nd->path.dentry;\n\t\t\tstruct dentry *parent = old->d_parent;\n\t\t\tunsigned seq;\n\n\t\t\tinode = parent->d_inode;\n\t\t\tseq = read_seqcount_begin(&parent->d_seq);\n\t\t\tif (unlikely(read_seqcount_retry(&old->d_seq, nd->seq)))\n\t\t\t\treturn -ECHILD;\n\t\t\tnd->path.dentry = parent;\n\t\t\tnd->seq = seq;\n\t\t\tif (unlikely(!path_connected(&nd->path)))\n\t\t\t\treturn -ENOENT;\n\t\t\tbreak;\n\t\t} else {\n\t\t\tstruct mount *mnt = real_mount(nd->path.mnt);\n\t\t\tstruct mount *mparent = mnt->mnt_parent;\n\t\t\tstruct dentry *mountpoint = mnt->mnt_mountpoint;\n\t\t\tstruct inode *inode2 = mountpoint->d_inode;\n\t\t\tunsigned seq = read_seqcount_begin(&mountpoint->d_seq);\n\t\t\tif (unlikely(read_seqretry(&mount_lock, nd->m_seq)))\n\t\t\t\treturn -ECHILD;\n\t\t\tif (&mparent->mnt == nd->path.mnt)\n\t\t\t\tbreak;\n\t\t\t/* we know that mountpoint was pinned */\n\t\t\tnd->path.dentry = mountpoint;\n\t\t\tnd->path.mnt = &mparent->mnt;\n\t\t\tinode = inode2;\n\t\t\tnd->seq = seq;\n\t\t}\n\t}\n\twhile (unlikely(d_mountpoint(nd->path.dentry))) {\n\t\tstruct mount *mounted;\n\t\tmounted = __lookup_mnt(nd->path.mnt, nd->path.dentry);\n\t\tif (unlikely(read_seqretry(&mount_lock, nd->m_seq)))\n\t\t\treturn -ECHILD;\n\t\tif (!mounted)\n\t\t\tbreak;\n\t\tnd->path.mnt = &mounted->mnt;\n\t\tnd->path.dentry = mounted->mnt.mnt_root;\n\t\tinode = nd->path.dentry->d_inode;\n\t\tnd->seq = read_seqcount_begin(&nd->path.dentry->d_seq);\n\t}\n\tnd->inode = inode;\n\treturn 0;\n}\n\n/*\n * Follow down to the covering mount currently visible to userspace.  At each\n * point, the filesystem owning that dentry may be queried as to whether the\n * caller is permitted to proceed or not.\n */\nint follow_down(struct path *path)\n{\n\tunsigned managed;\n\tint ret;\n\n\twhile (managed = ACCESS_ONCE(path->dentry->d_flags),\n\t       unlikely(managed & DCACHE_MANAGED_DENTRY)) {\n\t\t/* Allow the filesystem to manage the transit without i_mutex\n\t\t * being held.\n\t\t *\n\t\t * We indicate to the filesystem if someone is trying to mount\n\t\t * something here.  This gives autofs the chance to deny anyone\n\t\t * other than its daemon the right to mount on its\n\t\t * superstructure.\n\t\t *\n\t\t * The filesystem may sleep at this point.\n\t\t */\n\t\tif (managed & DCACHE_MANAGE_TRANSIT) {\n\t\t\tBUG_ON(!path->dentry->d_op);\n\t\t\tBUG_ON(!path->dentry->d_op->d_manage);\n\t\t\tret = path->dentry->d_op->d_manage(path, false);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret == -EISDIR ? 0 : ret;\n\t\t}\n\n\t\t/* Transit to a mounted filesystem. */\n\t\tif (managed & DCACHE_MOUNTED) {\n\t\t\tstruct vfsmount *mounted = lookup_mnt(path);\n\t\t\tif (!mounted)\n\t\t\t\tbreak;\n\t\t\tdput(path->dentry);\n\t\t\tmntput(path->mnt);\n\t\t\tpath->mnt = mounted;\n\t\t\tpath->dentry = dget(mounted->mnt_root);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Don't handle automount points here */\n\t\tbreak;\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL(follow_down);\n\n/*\n * Skip to top of mountpoint pile in refwalk mode for follow_dotdot()\n */\nstatic void follow_mount(struct path *path)\n{\n\twhile (d_mountpoint(path->dentry)) {\n\t\tstruct vfsmount *mounted = lookup_mnt(path);\n\t\tif (!mounted)\n\t\t\tbreak;\n\t\tdput(path->dentry);\n\t\tmntput(path->mnt);\n\t\tpath->mnt = mounted;\n\t\tpath->dentry = dget(mounted->mnt_root);\n\t}\n}\n\nstatic int path_parent_directory(struct path *path)\n{\n\tstruct dentry *old = path->dentry;\n\t/* rare case of legitimate dget_parent()... */\n\tpath->dentry = dget_parent(path->dentry);\n\tdput(old);\n\tif (unlikely(!path_connected(path)))\n\t\treturn -ENOENT;\n\treturn 0;\n}\n\nstatic int follow_dotdot(struct nameidata *nd)\n{\n\twhile(1) {\n\t\tif (nd->path.dentry == nd->root.dentry &&\n\t\t    nd->path.mnt == nd->root.mnt) {\n\t\t\tbreak;\n\t\t}\n\t\tif (nd->path.dentry != nd->path.mnt->mnt_root) {\n\t\t\tint ret = path_parent_directory(&nd->path);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t\tbreak;\n\t\t}\n\t\tif (!follow_up(&nd->path))\n\t\t\tbreak;\n\t}\n\tfollow_mount(&nd->path);\n\tnd->inode = nd->path.dentry->d_inode;\n\treturn 0;\n}\n\n/*\n * This looks up the name in dcache and possibly revalidates the found dentry.\n * NULL is returned if the dentry does not exist in the cache.\n */\nstatic struct dentry *lookup_dcache(const struct qstr *name,\n\t\t\t\t    struct dentry *dir,\n\t\t\t\t    unsigned int flags)\n{\n\tstruct dentry *dentry = d_lookup(dir, name);\n\tif (dentry) {\n\t\tint error = d_revalidate(dentry, flags);\n\t\tif (unlikely(error <= 0)) {\n\t\t\tif (!error)\n\t\t\t\td_invalidate(dentry);\n\t\t\tdput(dentry);\n\t\t\treturn ERR_PTR(error);\n\t\t}\n\t}\n\treturn dentry;\n}\n\n/*\n * Call i_op->lookup on the dentry.  The dentry must be negative and\n * unhashed.\n *\n * dir->d_inode->i_mutex must be held\n */\nstatic struct dentry *lookup_real(struct inode *dir, struct dentry *dentry,\n\t\t\t\t  unsigned int flags)\n{\n\tstruct dentry *old;\n\n\t/* Don't create child dentry for a dead directory. */\n\tif (unlikely(IS_DEADDIR(dir))) {\n\t\tdput(dentry);\n\t\treturn ERR_PTR(-ENOENT);\n\t}\n\n\told = dir->i_op->lookup(dir, dentry, flags);\n\tif (unlikely(old)) {\n\t\tdput(dentry);\n\t\tdentry = old;\n\t}\n\treturn dentry;\n}\n\nstatic struct dentry *__lookup_hash(const struct qstr *name,\n\t\tstruct dentry *base, unsigned int flags)\n{\n\tstruct dentry *dentry = lookup_dcache(name, base, flags);\n\n\tif (dentry)\n\t\treturn dentry;\n\n\tdentry = d_alloc(base, name);\n\tif (unlikely(!dentry))\n\t\treturn ERR_PTR(-ENOMEM);\n\n\treturn lookup_real(base->d_inode, dentry, flags);\n}\n\nstatic int lookup_fast(struct nameidata *nd,\n\t\t       struct path *path, struct inode **inode,\n\t\t       unsigned *seqp)\n{\n\tstruct vfsmount *mnt = nd->path.mnt;\n\tstruct dentry *dentry, *parent = nd->path.dentry;\n\tint status = 1;\n\tint err;\n\n\t/*\n\t * Rename seqlock is not required here because in the off chance\n\t * of a false negative due to a concurrent rename, the caller is\n\t * going to fall back to non-racy lookup.\n\t */\n\tif (nd->flags & LOOKUP_RCU) {\n\t\tunsigned seq;\n\t\tbool negative;\n\t\tdentry = __d_lookup_rcu(parent, &nd->last, &seq);\n\t\tif (unlikely(!dentry)) {\n\t\t\tif (unlazy_walk(nd))\n\t\t\t\treturn -ECHILD;\n\t\t\treturn 0;\n\t\t}\n\n\t\t/*\n\t\t * This sequence count validates that the inode matches\n\t\t * the dentry name information from lookup.\n\t\t */\n\t\t*inode = d_backing_inode(dentry);\n\t\tnegative = d_is_negative(dentry);\n\t\tif (unlikely(read_seqcount_retry(&dentry->d_seq, seq)))\n\t\t\treturn -ECHILD;\n\n\t\t/*\n\t\t * This sequence count validates that the parent had no\n\t\t * changes while we did the lookup of the dentry above.\n\t\t *\n\t\t * The memory barrier in read_seqcount_begin of child is\n\t\t *  enough, we can use __read_seqcount_retry here.\n\t\t */\n\t\tif (unlikely(__read_seqcount_retry(&parent->d_seq, nd->seq)))\n\t\t\treturn -ECHILD;\n\n\t\t*seqp = seq;\n\t\tstatus = d_revalidate(dentry, nd->flags);\n\t\tif (likely(status > 0)) {\n\t\t\t/*\n\t\t\t * Note: do negative dentry check after revalidation in\n\t\t\t * case that drops it.\n\t\t\t */\n\t\t\tif (unlikely(negative))\n\t\t\t\treturn -ENOENT;\n\t\t\tpath->mnt = mnt;\n\t\t\tpath->dentry = dentry;\n\t\t\tif (likely(__follow_mount_rcu(nd, path, inode, seqp)))\n\t\t\t\treturn 1;\n\t\t}\n\t\tif (unlazy_child(nd, dentry, seq))\n\t\t\treturn -ECHILD;\n\t\tif (unlikely(status == -ECHILD))\n\t\t\t/* we'd been told to redo it in non-rcu mode */\n\t\t\tstatus = d_revalidate(dentry, nd->flags);\n\t} else {\n\t\tdentry = __d_lookup(parent, &nd->last);\n\t\tif (unlikely(!dentry))\n\t\t\treturn 0;\n\t\tstatus = d_revalidate(dentry, nd->flags);\n\t}\n\tif (unlikely(status <= 0)) {\n\t\tif (!status)\n\t\t\td_invalidate(dentry);\n\t\tdput(dentry);\n\t\treturn status;\n\t}\n\tif (unlikely(d_is_negative(dentry))) {\n\t\tdput(dentry);\n\t\treturn -ENOENT;\n\t}\n\n\tpath->mnt = mnt;\n\tpath->dentry = dentry;\n\terr = follow_managed(path, nd);\n\tif (likely(err > 0))\n\t\t*inode = d_backing_inode(path->dentry);\n\treturn err;\n}\n\n/* Fast lookup failed, do it the slow way */\nstatic struct dentry *lookup_slow(const struct qstr *name,\n\t\t\t\t  struct dentry *dir,\n\t\t\t\t  unsigned int flags)\n{\n\tstruct dentry *dentry = ERR_PTR(-ENOENT), *old;\n\tstruct inode *inode = dir->d_inode;\n\tDECLARE_WAIT_QUEUE_HEAD_ONSTACK(wq);\n\n\tinode_lock_shared(inode);\n\t/* Don't go there if it's already dead */\n\tif (unlikely(IS_DEADDIR(inode)))\n\t\tgoto out;\nagain:\n\tdentry = d_alloc_parallel(dir, name, &wq);\n\tif (IS_ERR(dentry))\n\t\tgoto out;\n\tif (unlikely(!d_in_lookup(dentry))) {\n\t\tif (!(flags & LOOKUP_NO_REVAL)) {\n\t\t\tint error = d_revalidate(dentry, flags);\n\t\t\tif (unlikely(error <= 0)) {\n\t\t\t\tif (!error) {\n\t\t\t\t\td_invalidate(dentry);\n\t\t\t\t\tdput(dentry);\n\t\t\t\t\tgoto again;\n\t\t\t\t}\n\t\t\t\tdput(dentry);\n\t\t\t\tdentry = ERR_PTR(error);\n\t\t\t}\n\t\t}\n\t} else {\n\t\told = inode->i_op->lookup(inode, dentry, flags);\n\t\td_lookup_done(dentry);\n\t\tif (unlikely(old)) {\n\t\t\tdput(dentry);\n\t\t\tdentry = old;\n\t\t}\n\t}\nout:\n\tinode_unlock_shared(inode);\n\treturn dentry;\n}\n\nstatic inline int may_lookup(struct nameidata *nd)\n{\n\tif (nd->flags & LOOKUP_RCU) {\n\t\tint err = inode_permission(nd->inode, MAY_EXEC|MAY_NOT_BLOCK);\n\t\tif (err != -ECHILD)\n\t\t\treturn err;\n\t\tif (unlazy_walk(nd))\n\t\t\treturn -ECHILD;\n\t}\n\treturn inode_permission(nd->inode, MAY_EXEC);\n}\n\nstatic inline int handle_dots(struct nameidata *nd, int type)\n{\n\tif (type == LAST_DOTDOT) {\n\t\tif (!nd->root.mnt)\n\t\t\tset_root(nd);\n\t\tif (nd->flags & LOOKUP_RCU) {\n\t\t\treturn follow_dotdot_rcu(nd);\n\t\t} else\n\t\t\treturn follow_dotdot(nd);\n\t}\n\treturn 0;\n}\n\nstatic int pick_link(struct nameidata *nd, struct path *link,\n\t\t     struct inode *inode, unsigned seq)\n{\n\tint error;\n\tstruct saved *last;\n\tif (unlikely(nd->total_link_count++ >= MAXSYMLINKS)) {\n\t\tpath_to_nameidata(link, nd);\n\t\treturn -ELOOP;\n\t}\n\tif (!(nd->flags & LOOKUP_RCU)) {\n\t\tif (link->mnt == nd->path.mnt)\n\t\t\tmntget(link->mnt);\n\t}\n\terror = nd_alloc_stack(nd);\n\tif (unlikely(error)) {\n\t\tif (error == -ECHILD) {\n\t\t\tif (unlikely(!legitimize_path(nd, link, seq))) {\n\t\t\t\tdrop_links(nd);\n\t\t\t\tnd->depth = 0;\n\t\t\t\tnd->flags &= ~LOOKUP_RCU;\n\t\t\t\tnd->path.mnt = NULL;\n\t\t\t\tnd->path.dentry = NULL;\n\t\t\t\tif (!(nd->flags & LOOKUP_ROOT))\n\t\t\t\t\tnd->root.mnt = NULL;\n\t\t\t\trcu_read_unlock();\n\t\t\t} else if (likely(unlazy_walk(nd)) == 0)\n\t\t\t\terror = nd_alloc_stack(nd);\n\t\t}\n\t\tif (error) {\n\t\t\tpath_put(link);\n\t\t\treturn error;\n\t\t}\n\t}\n\n\tlast = nd->stack + nd->depth++;\n\tlast->link = *link;\n\tclear_delayed_call(&last->done);\n\tnd->link_inode = inode;\n\tlast->seq = seq;\n\treturn 1;\n}\n\nenum {WALK_FOLLOW = 1, WALK_MORE = 2};\n\n/*\n * Do we need to follow links? We _really_ want to be able\n * to do this check without having to look at inode->i_op,\n * so we keep a cache of \"no, this doesn't need follow_link\"\n * for the common case.\n */\nstatic inline int step_into(struct nameidata *nd, struct path *path,\n\t\t\t    int flags, struct inode *inode, unsigned seq)\n{\n\tif (!(flags & WALK_MORE) && nd->depth)\n\t\tput_link(nd);\n\tif (likely(!d_is_symlink(path->dentry)) ||\n\t   !(flags & WALK_FOLLOW || nd->flags & LOOKUP_FOLLOW)) {\n\t\t/* not a symlink or should not follow */\n\t\tpath_to_nameidata(path, nd);\n\t\tnd->inode = inode;\n\t\tnd->seq = seq;\n\t\treturn 0;\n\t}\n\t/* make sure that d_is_symlink above matches inode */\n\tif (nd->flags & LOOKUP_RCU) {\n\t\tif (read_seqcount_retry(&path->dentry->d_seq, seq))\n\t\t\treturn -ECHILD;\n\t}\n\treturn pick_link(nd, path, inode, seq);\n}\n\nstatic int walk_component(struct nameidata *nd, int flags)\n{\n\tstruct path path;\n\tstruct inode *inode;\n\tunsigned seq;\n\tint err;\n\t/*\n\t * \".\" and \"..\" are special - \"..\" especially so because it has\n\t * to be able to know about the current root directory and\n\t * parent relationships.\n\t */\n\tif (unlikely(nd->last_type != LAST_NORM)) {\n\t\terr = handle_dots(nd, nd->last_type);\n\t\tif (!(flags & WALK_MORE) && nd->depth)\n\t\t\tput_link(nd);\n\t\treturn err;\n\t}\n\terr = lookup_fast(nd, &path, &inode, &seq);\n\tif (unlikely(err <= 0)) {\n\t\tif (err < 0)\n\t\t\treturn err;\n\t\tpath.dentry = lookup_slow(&nd->last, nd->path.dentry,\n\t\t\t\t\t  nd->flags);\n\t\tif (IS_ERR(path.dentry))\n\t\t\treturn PTR_ERR(path.dentry);\n\n\t\tpath.mnt = nd->path.mnt;\n\t\terr = follow_managed(&path, nd);\n\t\tif (unlikely(err < 0))\n\t\t\treturn err;\n\n\t\tif (unlikely(d_is_negative(path.dentry))) {\n\t\t\tpath_to_nameidata(&path, nd);\n\t\t\treturn -ENOENT;\n\t\t}\n\n\t\tseq = 0;\t/* we are already out of RCU mode */\n\t\tinode = d_backing_inode(path.dentry);\n\t}\n\n\treturn step_into(nd, &path, flags, inode, seq);\n}\n\n/*\n * We can do the critical dentry name comparison and hashing\n * operations one word at a time, but we are limited to:\n *\n * - Architectures with fast unaligned word accesses. We could\n *   do a \"get_unaligned()\" if this helps and is sufficiently\n *   fast.\n *\n * - non-CONFIG_DEBUG_PAGEALLOC configurations (so that we\n *   do not trap on the (extremely unlikely) case of a page\n *   crossing operation.\n *\n * - Furthermore, we need an efficient 64-bit compile for the\n *   64-bit case in order to generate the \"number of bytes in\n *   the final mask\". Again, that could be replaced with a\n *   efficient population count instruction or similar.\n */\n#ifdef CONFIG_DCACHE_WORD_ACCESS\n\n#include <asm/word-at-a-time.h>\n\n#ifdef HASH_MIX\n\n/* Architecture provides HASH_MIX and fold_hash() in <asm/hash.h> */\n\n#elif defined(CONFIG_64BIT)\n/*\n * Register pressure in the mixing function is an issue, particularly\n * on 32-bit x86, but almost any function requires one state value and\n * one temporary.  Instead, use a function designed for two state values\n * and no temporaries.\n *\n * This function cannot create a collision in only two iterations, so\n * we have two iterations to achieve avalanche.  In those two iterations,\n * we have six layers of mixing, which is enough to spread one bit's\n * influence out to 2^6 = 64 state bits.\n *\n * Rotate constants are scored by considering either 64 one-bit input\n * deltas or 64*63/2 = 2016 two-bit input deltas, and finding the\n * probability of that delta causing a change to each of the 128 output\n * bits, using a sample of random initial states.\n *\n * The Shannon entropy of the computed probabilities is then summed\n * to produce a score.  Ideally, any input change has a 50% chance of\n * toggling any given output bit.\n *\n * Mixing scores (in bits) for (12,45):\n * Input delta: 1-bit      2-bit\n * 1 round:     713.3    42542.6\n * 2 rounds:   2753.7   140389.8\n * 3 rounds:   5954.1   233458.2\n * 4 rounds:   7862.6   256672.2\n * Perfect:    8192     258048\n *            (64*128) (64*63/2 * 128)\n */\n#define HASH_MIX(x, y, a)\t\\\n\t(\tx ^= (a),\t\\\n\ty ^= x,\tx = rol64(x,12),\\\n\tx += y,\ty = rol64(y,45),\\\n\ty *= 9\t\t\t)\n\n/*\n * Fold two longs into one 32-bit hash value.  This must be fast, but\n * latency isn't quite as critical, as there is a fair bit of additional\n * work done before the hash value is used.\n */\nstatic inline unsigned int fold_hash(unsigned long x, unsigned long y)\n{\n\ty ^= x * GOLDEN_RATIO_64;\n\ty *= GOLDEN_RATIO_64;\n\treturn y >> 32;\n}\n\n#else\t/* 32-bit case */\n\n/*\n * Mixing scores (in bits) for (7,20):\n * Input delta: 1-bit      2-bit\n * 1 round:     330.3     9201.6\n * 2 rounds:   1246.4    25475.4\n * 3 rounds:   1907.1    31295.1\n * 4 rounds:   2042.3    31718.6\n * Perfect:    2048      31744\n *            (32*64)   (32*31/2 * 64)\n */\n#define HASH_MIX(x, y, a)\t\\\n\t(\tx ^= (a),\t\\\n\ty ^= x,\tx = rol32(x, 7),\\\n\tx += y,\ty = rol32(y,20),\\\n\ty *= 9\t\t\t)\n\nstatic inline unsigned int fold_hash(unsigned long x, unsigned long y)\n{\n\t/* Use arch-optimized multiply if one exists */\n\treturn __hash_32(y ^ __hash_32(x));\n}\n\n#endif\n\n/*\n * Return the hash of a string of known length.  This is carfully\n * designed to match hash_name(), which is the more critical function.\n * In particular, we must end by hashing a final word containing 0..7\n * payload bytes, to match the way that hash_name() iterates until it\n * finds the delimiter after the name.\n */\nunsigned int full_name_hash(const void *salt, const char *name, unsigned int len)\n{\n\tunsigned long a, x = 0, y = (unsigned long)salt;\n\n\tfor (;;) {\n\t\tif (!len)\n\t\t\tgoto done;\n\t\ta = load_unaligned_zeropad(name);\n\t\tif (len < sizeof(unsigned long))\n\t\t\tbreak;\n\t\tHASH_MIX(x, y, a);\n\t\tname += sizeof(unsigned long);\n\t\tlen -= sizeof(unsigned long);\n\t}\n\tx ^= a & bytemask_from_count(len);\ndone:\n\treturn fold_hash(x, y);\n}\nEXPORT_SYMBOL(full_name_hash);\n\n/* Return the \"hash_len\" (hash and length) of a null-terminated string */\nu64 hashlen_string(const void *salt, const char *name)\n{\n\tunsigned long a = 0, x = 0, y = (unsigned long)salt;\n\tunsigned long adata, mask, len;\n\tconst struct word_at_a_time constants = WORD_AT_A_TIME_CONSTANTS;\n\n\tlen = 0;\n\tgoto inside;\n\n\tdo {\n\t\tHASH_MIX(x, y, a);\n\t\tlen += sizeof(unsigned long);\ninside:\n\t\ta = load_unaligned_zeropad(name+len);\n\t} while (!has_zero(a, &adata, &constants));\n\n\tadata = prep_zero_mask(a, adata, &constants);\n\tmask = create_zero_mask(adata);\n\tx ^= a & zero_bytemask(mask);\n\n\treturn hashlen_create(fold_hash(x, y), len + find_zero(mask));\n}\nEXPORT_SYMBOL(hashlen_string);\n\n/*\n * Calculate the length and hash of the path component, and\n * return the \"hash_len\" as the result.\n */\nstatic inline u64 hash_name(const void *salt, const char *name)\n{\n\tunsigned long a = 0, b, x = 0, y = (unsigned long)salt;\n\tunsigned long adata, bdata, mask, len;\n\tconst struct word_at_a_time constants = WORD_AT_A_TIME_CONSTANTS;\n\n\tlen = 0;\n\tgoto inside;\n\n\tdo {\n\t\tHASH_MIX(x, y, a);\n\t\tlen += sizeof(unsigned long);\ninside:\n\t\ta = load_unaligned_zeropad(name+len);\n\t\tb = a ^ REPEAT_BYTE('/');\n\t} while (!(has_zero(a, &adata, &constants) | has_zero(b, &bdata, &constants)));\n\n\tadata = prep_zero_mask(a, adata, &constants);\n\tbdata = prep_zero_mask(b, bdata, &constants);\n\tmask = create_zero_mask(adata | bdata);\n\tx ^= a & zero_bytemask(mask);\n\n\treturn hashlen_create(fold_hash(x, y), len + find_zero(mask));\n}\n\n#else\t/* !CONFIG_DCACHE_WORD_ACCESS: Slow, byte-at-a-time version */\n\n/* Return the hash of a string of known length */\nunsigned int full_name_hash(const void *salt, const char *name, unsigned int len)\n{\n\tunsigned long hash = init_name_hash(salt);\n\twhile (len--)\n\t\thash = partial_name_hash((unsigned char)*name++, hash);\n\treturn end_name_hash(hash);\n}\nEXPORT_SYMBOL(full_name_hash);\n\n/* Return the \"hash_len\" (hash and length) of a null-terminated string */\nu64 hashlen_string(const void *salt, const char *name)\n{\n\tunsigned long hash = init_name_hash(salt);\n\tunsigned long len = 0, c;\n\n\tc = (unsigned char)*name;\n\twhile (c) {\n\t\tlen++;\n\t\thash = partial_name_hash(c, hash);\n\t\tc = (unsigned char)name[len];\n\t}\n\treturn hashlen_create(end_name_hash(hash), len);\n}\nEXPORT_SYMBOL(hashlen_string);\n\n/*\n * We know there's a real path component here of at least\n * one character.\n */\nstatic inline u64 hash_name(const void *salt, const char *name)\n{\n\tunsigned long hash = init_name_hash(salt);\n\tunsigned long len = 0, c;\n\n\tc = (unsigned char)*name;\n\tdo {\n\t\tlen++;\n\t\thash = partial_name_hash(c, hash);\n\t\tc = (unsigned char)name[len];\n\t} while (c && c != '/');\n\treturn hashlen_create(end_name_hash(hash), len);\n}\n\n#endif\n\n/*\n * Name resolution.\n * This is the basic name resolution function, turning a pathname into\n * the final dentry. We expect 'base' to be positive and a directory.\n *\n * Returns 0 and nd will have valid dentry and mnt on success.\n * Returns error and drops reference to input namei data on failure.\n */\nstatic int link_path_walk(const char *name, struct nameidata *nd)\n{\n\tint err;\n\n\twhile (*name=='/')\n\t\tname++;\n\tif (!*name)\n\t\treturn 0;\n\n\t/* At this point we know we have a real path component. */\n\tfor(;;) {\n\t\tu64 hash_len;\n\t\tint type;\n\n\t\terr = may_lookup(nd);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\thash_len = hash_name(nd->path.dentry, name);\n\n\t\ttype = LAST_NORM;\n\t\tif (name[0] == '.') switch (hashlen_len(hash_len)) {\n\t\t\tcase 2:\n\t\t\t\tif (name[1] == '.') {\n\t\t\t\t\ttype = LAST_DOTDOT;\n\t\t\t\t\tnd->flags |= LOOKUP_JUMPED;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 1:\n\t\t\t\ttype = LAST_DOT;\n\t\t}\n\t\tif (likely(type == LAST_NORM)) {\n\t\t\tstruct dentry *parent = nd->path.dentry;\n\t\t\tnd->flags &= ~LOOKUP_JUMPED;\n\t\t\tif (unlikely(parent->d_flags & DCACHE_OP_HASH)) {\n\t\t\t\tstruct qstr this = { { .hash_len = hash_len }, .name = name };\n\t\t\t\terr = parent->d_op->d_hash(parent, &this);\n\t\t\t\tif (err < 0)\n\t\t\t\t\treturn err;\n\t\t\t\thash_len = this.hash_len;\n\t\t\t\tname = this.name;\n\t\t\t}\n\t\t}\n\n\t\tnd->last.hash_len = hash_len;\n\t\tnd->last.name = name;\n\t\tnd->last_type = type;\n\n\t\tname += hashlen_len(hash_len);\n\t\tif (!*name)\n\t\t\tgoto OK;\n\t\t/*\n\t\t * If it wasn't NUL, we know it was '/'. Skip that\n\t\t * slash, and continue until no more slashes.\n\t\t */\n\t\tdo {\n\t\t\tname++;\n\t\t} while (unlikely(*name == '/'));\n\t\tif (unlikely(!*name)) {\nOK:\n\t\t\t/* pathname body, done */\n\t\t\tif (!nd->depth)\n\t\t\t\treturn 0;\n\t\t\tname = nd->stack[nd->depth - 1].name;\n\t\t\t/* trailing symlink, done */\n\t\t\tif (!name)\n\t\t\t\treturn 0;\n\t\t\t/* last component of nested symlink */\n\t\t\terr = walk_component(nd, WALK_FOLLOW);\n\t\t} else {\n\t\t\t/* not the last component */\n\t\t\terr = walk_component(nd, WALK_FOLLOW | WALK_MORE);\n\t\t}\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\tif (err) {\n\t\t\tconst char *s = get_link(nd);\n\n\t\t\tif (IS_ERR(s))\n\t\t\t\treturn PTR_ERR(s);\n\t\t\terr = 0;\n\t\t\tif (unlikely(!s)) {\n\t\t\t\t/* jumped */\n\t\t\t\tput_link(nd);\n\t\t\t} else {\n\t\t\t\tnd->stack[nd->depth - 1].name = name;\n\t\t\t\tname = s;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\t\tif (unlikely(!d_can_lookup(nd->path.dentry))) {\n\t\t\tif (nd->flags & LOOKUP_RCU) {\n\t\t\t\tif (unlazy_walk(nd))\n\t\t\t\t\treturn -ECHILD;\n\t\t\t}\n\t\t\treturn -ENOTDIR;\n\t\t}\n\t}\n}\n\nstatic const char *path_init(struct nameidata *nd, unsigned flags)\n{\n\tconst char *s = nd->name->name;\n\n\tif (!*s)\n\t\tflags &= ~LOOKUP_RCU;\n\n\tnd->last_type = LAST_ROOT; /* if there are only slashes... */\n\tnd->flags = flags | LOOKUP_JUMPED | LOOKUP_PARENT;\n\tnd->depth = 0;\n\tif (flags & LOOKUP_ROOT) {\n\t\tstruct dentry *root = nd->root.dentry;\n\t\tstruct inode *inode = root->d_inode;\n\t\tif (*s && unlikely(!d_can_lookup(root)))\n\t\t\treturn ERR_PTR(-ENOTDIR);\n\t\tnd->path = nd->root;\n\t\tnd->inode = inode;\n\t\tif (flags & LOOKUP_RCU) {\n\t\t\trcu_read_lock();\n\t\t\tnd->seq = __read_seqcount_begin(&nd->path.dentry->d_seq);\n\t\t\tnd->root_seq = nd->seq;\n\t\t\tnd->m_seq = read_seqbegin(&mount_lock);\n\t\t} else {\n\t\t\tpath_get(&nd->path);\n\t\t}\n\t\treturn s;\n\t}\n\n\tnd->root.mnt = NULL;\n\tnd->path.mnt = NULL;\n\tnd->path.dentry = NULL;\n\n\tnd->m_seq = read_seqbegin(&mount_lock);\n\tif (*s == '/') {\n\t\tif (flags & LOOKUP_RCU)\n\t\t\trcu_read_lock();\n\t\tset_root(nd);\n\t\tif (likely(!nd_jump_root(nd)))\n\t\t\treturn s;\n\t\tnd->root.mnt = NULL;\n\t\trcu_read_unlock();\n\t\treturn ERR_PTR(-ECHILD);\n\t} else if (nd->dfd == AT_FDCWD) {\n\t\tif (flags & LOOKUP_RCU) {\n\t\t\tstruct fs_struct *fs = current->fs;\n\t\t\tunsigned seq;\n\n\t\t\trcu_read_lock();\n\n\t\t\tdo {\n\t\t\t\tseq = read_seqcount_begin(&fs->seq);\n\t\t\t\tnd->path = fs->pwd;\n\t\t\t\tnd->inode = nd->path.dentry->d_inode;\n\t\t\t\tnd->seq = __read_seqcount_begin(&nd->path.dentry->d_seq);\n\t\t\t} while (read_seqcount_retry(&fs->seq, seq));\n\t\t} else {\n\t\t\tget_fs_pwd(current->fs, &nd->path);\n\t\t\tnd->inode = nd->path.dentry->d_inode;\n\t\t}\n\t\treturn s;\n\t} else {\n\t\t/* Caller must check execute permissions on the starting path component */\n\t\tstruct fd f = fdget_raw(nd->dfd);\n\t\tstruct dentry *dentry;\n\n\t\tif (!f.file)\n\t\t\treturn ERR_PTR(-EBADF);\n\n\t\tdentry = f.file->f_path.dentry;\n\n\t\tif (*s) {\n\t\t\tif (!d_can_lookup(dentry)) {\n\t\t\t\tfdput(f);\n\t\t\t\treturn ERR_PTR(-ENOTDIR);\n\t\t\t}\n\t\t}\n\n\t\tnd->path = f.file->f_path;\n\t\tif (flags & LOOKUP_RCU) {\n\t\t\trcu_read_lock();\n\t\t\tnd->inode = nd->path.dentry->d_inode;\n\t\t\tnd->seq = read_seqcount_begin(&nd->path.dentry->d_seq);\n\t\t} else {\n\t\t\tpath_get(&nd->path);\n\t\t\tnd->inode = nd->path.dentry->d_inode;\n\t\t}\n\t\tfdput(f);\n\t\treturn s;\n\t}\n}\n\nstatic const char *trailing_symlink(struct nameidata *nd)\n{\n\tconst char *s;\n\tint error = may_follow_link(nd);\n\tif (unlikely(error))\n\t\treturn ERR_PTR(error);\n\tnd->flags |= LOOKUP_PARENT;\n\tnd->stack[0].name = NULL;\n\ts = get_link(nd);\n\treturn s ? s : \"\";\n}\n\nstatic inline int lookup_last(struct nameidata *nd)\n{\n\tif (nd->last_type == LAST_NORM && nd->last.name[nd->last.len])\n\t\tnd->flags |= LOOKUP_FOLLOW | LOOKUP_DIRECTORY;\n\n\tnd->flags &= ~LOOKUP_PARENT;\n\treturn walk_component(nd, 0);\n}\n\nstatic int handle_lookup_down(struct nameidata *nd)\n{\n\tstruct path path = nd->path;\n\tstruct inode *inode = nd->inode;\n\tunsigned seq = nd->seq;\n\tint err;\n\n\tif (nd->flags & LOOKUP_RCU) {\n\t\t/*\n\t\t * don't bother with unlazy_walk on failure - we are\n\t\t * at the very beginning of walk, so we lose nothing\n\t\t * if we simply redo everything in non-RCU mode\n\t\t */\n\t\tif (unlikely(!__follow_mount_rcu(nd, &path, &inode, &seq)))\n\t\t\treturn -ECHILD;\n\t} else {\n\t\tdget(path.dentry);\n\t\terr = follow_managed(&path, nd);\n\t\tif (unlikely(err < 0))\n\t\t\treturn err;\n\t\tinode = d_backing_inode(path.dentry);\n\t\tseq = 0;\n\t}\n\tpath_to_nameidata(&path, nd);\n\tnd->inode = inode;\n\tnd->seq = seq;\n\treturn 0;\n}\n\n/* Returns 0 and nd will be valid on success; Retuns error, otherwise. */\nstatic int path_lookupat(struct nameidata *nd, unsigned flags, struct path *path)\n{\n\tconst char *s = path_init(nd, flags);\n\tint err;\n\n\tif (IS_ERR(s))\n\t\treturn PTR_ERR(s);\n\n\tif (unlikely(flags & LOOKUP_DOWN)) {\n\t\terr = handle_lookup_down(nd);\n\t\tif (unlikely(err < 0)) {\n\t\t\tterminate_walk(nd);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\twhile (!(err = link_path_walk(s, nd))\n\t\t&& ((err = lookup_last(nd)) > 0)) {\n\t\ts = trailing_symlink(nd);\n\t\tif (IS_ERR(s)) {\n\t\t\terr = PTR_ERR(s);\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!err)\n\t\terr = complete_walk(nd);\n\n\tif (!err && nd->flags & LOOKUP_DIRECTORY)\n\t\tif (!d_can_lookup(nd->path.dentry))\n\t\t\terr = -ENOTDIR;\n\tif (!err) {\n\t\t*path = nd->path;\n\t\tnd->path.mnt = NULL;\n\t\tnd->path.dentry = NULL;\n\t}\n\tterminate_walk(nd);\n\treturn err;\n}\n\nstatic int filename_lookup(int dfd, struct filename *name, unsigned flags,\n\t\t\t   struct path *path, struct path *root)\n{\n\tint retval;\n\tstruct nameidata nd;\n\tif (IS_ERR(name))\n\t\treturn PTR_ERR(name);\n\tif (unlikely(root)) {\n\t\tnd.root = *root;\n\t\tflags |= LOOKUP_ROOT;\n\t}\n\tset_nameidata(&nd, dfd, name);\n\tretval = path_lookupat(&nd, flags | LOOKUP_RCU, path);\n\tif (unlikely(retval == -ECHILD))\n\t\tretval = path_lookupat(&nd, flags, path);\n\tif (unlikely(retval == -ESTALE))\n\t\tretval = path_lookupat(&nd, flags | LOOKUP_REVAL, path);\n\n\tif (likely(!retval))\n\t\taudit_inode(name, path->dentry, flags & LOOKUP_PARENT);\n\trestore_nameidata();\n\tputname(name);\n\treturn retval;\n}\n\n/* Returns 0 and nd will be valid on success; Retuns error, otherwise. */\nstatic int path_parentat(struct nameidata *nd, unsigned flags,\n\t\t\t\tstruct path *parent)\n{\n\tconst char *s = path_init(nd, flags);\n\tint err;\n\tif (IS_ERR(s))\n\t\treturn PTR_ERR(s);\n\terr = link_path_walk(s, nd);\n\tif (!err)\n\t\terr = complete_walk(nd);\n\tif (!err) {\n\t\t*parent = nd->path;\n\t\tnd->path.mnt = NULL;\n\t\tnd->path.dentry = NULL;\n\t}\n\tterminate_walk(nd);\n\treturn err;\n}\n\nstatic struct filename *filename_parentat(int dfd, struct filename *name,\n\t\t\t\tunsigned int flags, struct path *parent,\n\t\t\t\tstruct qstr *last, int *type)\n{\n\tint retval;\n\tstruct nameidata nd;\n\n\tif (IS_ERR(name))\n\t\treturn name;\n\tset_nameidata(&nd, dfd, name);\n\tretval = path_parentat(&nd, flags | LOOKUP_RCU, parent);\n\tif (unlikely(retval == -ECHILD))\n\t\tretval = path_parentat(&nd, flags, parent);\n\tif (unlikely(retval == -ESTALE))\n\t\tretval = path_parentat(&nd, flags | LOOKUP_REVAL, parent);\n\tif (likely(!retval)) {\n\t\t*last = nd.last;\n\t\t*type = nd.last_type;\n\t\taudit_inode(name, parent->dentry, LOOKUP_PARENT);\n\t} else {\n\t\tputname(name);\n\t\tname = ERR_PTR(retval);\n\t}\n\trestore_nameidata();\n\treturn name;\n}\n\n/* does lookup, returns the object with parent locked */\nstruct dentry *kern_path_locked(const char *name, struct path *path)\n{\n\tstruct filename *filename;\n\tstruct dentry *d;\n\tstruct qstr last;\n\tint type;\n\n\tfilename = filename_parentat(AT_FDCWD, getname_kernel(name), 0, path,\n\t\t\t\t    &last, &type);\n\tif (IS_ERR(filename))\n\t\treturn ERR_CAST(filename);\n\tif (unlikely(type != LAST_NORM)) {\n\t\tpath_put(path);\n\t\tputname(filename);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\tinode_lock_nested(path->dentry->d_inode, I_MUTEX_PARENT);\n\td = __lookup_hash(&last, path->dentry, 0);\n\tif (IS_ERR(d)) {\n\t\tinode_unlock(path->dentry->d_inode);\n\t\tpath_put(path);\n\t}\n\tputname(filename);\n\treturn d;\n}\n\nint kern_path(const char *name, unsigned int flags, struct path *path)\n{\n\treturn filename_lookup(AT_FDCWD, getname_kernel(name),\n\t\t\t       flags, path, NULL);\n}\nEXPORT_SYMBOL(kern_path);\n\n/**\n * vfs_path_lookup - lookup a file path relative to a dentry-vfsmount pair\n * @dentry:  pointer to dentry of the base directory\n * @mnt: pointer to vfs mount of the base directory\n * @name: pointer to file name\n * @flags: lookup flags\n * @path: pointer to struct path to fill\n */\nint vfs_path_lookup(struct dentry *dentry, struct vfsmount *mnt,\n\t\t    const char *name, unsigned int flags,\n\t\t    struct path *path)\n{\n\tstruct path root = {.mnt = mnt, .dentry = dentry};\n\t/* the first argument of filename_lookup() is ignored with root */\n\treturn filename_lookup(AT_FDCWD, getname_kernel(name),\n\t\t\t       flags , path, &root);\n}\nEXPORT_SYMBOL(vfs_path_lookup);\n\n/**\n * lookup_one_len - filesystem helper to lookup single pathname component\n * @name:\tpathname component to lookup\n * @base:\tbase directory to lookup from\n * @len:\tmaximum length @len should be interpreted to\n *\n * Note that this routine is purely a helper for filesystem usage and should\n * not be called by generic code.\n *\n * The caller must hold base->i_mutex.\n */\nstruct dentry *lookup_one_len(const char *name, struct dentry *base, int len)\n{\n\tstruct qstr this;\n\tunsigned int c;\n\tint err;\n\n\tWARN_ON_ONCE(!inode_is_locked(base->d_inode));\n\n\tthis.name = name;\n\tthis.len = len;\n\tthis.hash = full_name_hash(base, name, len);\n\tif (!len)\n\t\treturn ERR_PTR(-EACCES);\n\n\tif (unlikely(name[0] == '.')) {\n\t\tif (len < 2 || (len == 2 && name[1] == '.'))\n\t\t\treturn ERR_PTR(-EACCES);\n\t}\n\n\twhile (len--) {\n\t\tc = *(const unsigned char *)name++;\n\t\tif (c == '/' || c == '\\0')\n\t\t\treturn ERR_PTR(-EACCES);\n\t}\n\t/*\n\t * See if the low-level filesystem might want\n\t * to use its own hash..\n\t */\n\tif (base->d_flags & DCACHE_OP_HASH) {\n\t\tint err = base->d_op->d_hash(base, &this);\n\t\tif (err < 0)\n\t\t\treturn ERR_PTR(err);\n\t}\n\n\terr = inode_permission(base->d_inode, MAY_EXEC);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\treturn __lookup_hash(&this, base, 0);\n}\nEXPORT_SYMBOL(lookup_one_len);\n\n/**\n * lookup_one_len_unlocked - filesystem helper to lookup single pathname component\n * @name:\tpathname component to lookup\n * @base:\tbase directory to lookup from\n * @len:\tmaximum length @len should be interpreted to\n *\n * Note that this routine is purely a helper for filesystem usage and should\n * not be called by generic code.\n *\n * Unlike lookup_one_len, it should be called without the parent\n * i_mutex held, and will take the i_mutex itself if necessary.\n */\nstruct dentry *lookup_one_len_unlocked(const char *name,\n\t\t\t\t       struct dentry *base, int len)\n{\n\tstruct qstr this;\n\tunsigned int c;\n\tint err;\n\tstruct dentry *ret;\n\n\tthis.name = name;\n\tthis.len = len;\n\tthis.hash = full_name_hash(base, name, len);\n\tif (!len)\n\t\treturn ERR_PTR(-EACCES);\n\n\tif (unlikely(name[0] == '.')) {\n\t\tif (len < 2 || (len == 2 && name[1] == '.'))\n\t\t\treturn ERR_PTR(-EACCES);\n\t}\n\n\twhile (len--) {\n\t\tc = *(const unsigned char *)name++;\n\t\tif (c == '/' || c == '\\0')\n\t\t\treturn ERR_PTR(-EACCES);\n\t}\n\t/*\n\t * See if the low-level filesystem might want\n\t * to use its own hash..\n\t */\n\tif (base->d_flags & DCACHE_OP_HASH) {\n\t\tint err = base->d_op->d_hash(base, &this);\n\t\tif (err < 0)\n\t\t\treturn ERR_PTR(err);\n\t}\n\n\terr = inode_permission(base->d_inode, MAY_EXEC);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\tret = lookup_dcache(&this, base, 0);\n\tif (!ret)\n\t\tret = lookup_slow(&this, base, 0);\n\treturn ret;\n}\nEXPORT_SYMBOL(lookup_one_len_unlocked);\n\n#ifdef CONFIG_UNIX98_PTYS\nint path_pts(struct path *path)\n{\n\t/* Find something mounted on \"pts\" in the same directory as\n\t * the input path.\n\t */\n\tstruct dentry *child, *parent;\n\tstruct qstr this;\n\tint ret;\n\n\tret = path_parent_directory(path);\n\tif (ret)\n\t\treturn ret;\n\n\tparent = path->dentry;\n\tthis.name = \"pts\";\n\tthis.len = 3;\n\tchild = d_hash_and_lookup(parent, &this);\n\tif (!child)\n\t\treturn -ENOENT;\n\n\tpath->dentry = child;\n\tdput(parent);\n\tfollow_mount(path);\n\treturn 0;\n}\n#endif\n\nint user_path_at_empty(int dfd, const char __user *name, unsigned flags,\n\t\t struct path *path, int *empty)\n{\n\treturn filename_lookup(dfd, getname_flags(name, flags, empty),\n\t\t\t       flags, path, NULL);\n}\nEXPORT_SYMBOL(user_path_at_empty);\n\n/**\n * mountpoint_last - look up last component for umount\n * @nd:   pathwalk nameidata - currently pointing at parent directory of \"last\"\n *\n * This is a special lookup_last function just for umount. In this case, we\n * need to resolve the path without doing any revalidation.\n *\n * The nameidata should be the result of doing a LOOKUP_PARENT pathwalk. Since\n * mountpoints are always pinned in the dcache, their ancestors are too. Thus,\n * in almost all cases, this lookup will be served out of the dcache. The only\n * cases where it won't are if nd->last refers to a symlink or the path is\n * bogus and it doesn't exist.\n *\n * Returns:\n * -error: if there was an error during lookup. This includes -ENOENT if the\n *         lookup found a negative dentry.\n *\n * 0:      if we successfully resolved nd->last and found it to not to be a\n *         symlink that needs to be followed.\n *\n * 1:      if we successfully resolved nd->last and found it to be a symlink\n *         that needs to be followed.\n */\nstatic int\nmountpoint_last(struct nameidata *nd)\n{\n\tint error = 0;\n\tstruct dentry *dir = nd->path.dentry;\n\tstruct path path;\n\n\t/* If we're in rcuwalk, drop out of it to handle last component */\n\tif (nd->flags & LOOKUP_RCU) {\n\t\tif (unlazy_walk(nd))\n\t\t\treturn -ECHILD;\n\t}\n\n\tnd->flags &= ~LOOKUP_PARENT;\n\n\tif (unlikely(nd->last_type != LAST_NORM)) {\n\t\terror = handle_dots(nd, nd->last_type);\n\t\tif (error)\n\t\t\treturn error;\n\t\tpath.dentry = dget(nd->path.dentry);\n\t} else {\n\t\tpath.dentry = d_lookup(dir, &nd->last);\n\t\tif (!path.dentry) {\n\t\t\t/*\n\t\t\t * No cached dentry. Mounted dentries are pinned in the\n\t\t\t * cache, so that means that this dentry is probably\n\t\t\t * a symlink or the path doesn't actually point\n\t\t\t * to a mounted dentry.\n\t\t\t */\n\t\t\tpath.dentry = lookup_slow(&nd->last, dir,\n\t\t\t\t\t     nd->flags | LOOKUP_NO_REVAL);\n\t\t\tif (IS_ERR(path.dentry))\n\t\t\t\treturn PTR_ERR(path.dentry);\n\t\t}\n\t}\n\tif (d_is_negative(path.dentry)) {\n\t\tdput(path.dentry);\n\t\treturn -ENOENT;\n\t}\n\tpath.mnt = nd->path.mnt;\n\treturn step_into(nd, &path, 0, d_backing_inode(path.dentry), 0);\n}\n\n/**\n * path_mountpoint - look up a path to be umounted\n * @nd:\t\tlookup context\n * @flags:\tlookup flags\n * @path:\tpointer to container for result\n *\n * Look up the given name, but don't attempt to revalidate the last component.\n * Returns 0 and \"path\" will be valid on success; Returns error otherwise.\n */\nstatic int\npath_mountpoint(struct nameidata *nd, unsigned flags, struct path *path)\n{\n\tconst char *s = path_init(nd, flags);\n\tint err;\n\tif (IS_ERR(s))\n\t\treturn PTR_ERR(s);\n\twhile (!(err = link_path_walk(s, nd)) &&\n\t\t(err = mountpoint_last(nd)) > 0) {\n\t\ts = trailing_symlink(nd);\n\t\tif (IS_ERR(s)) {\n\t\t\terr = PTR_ERR(s);\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!err) {\n\t\t*path = nd->path;\n\t\tnd->path.mnt = NULL;\n\t\tnd->path.dentry = NULL;\n\t\tfollow_mount(path);\n\t}\n\tterminate_walk(nd);\n\treturn err;\n}\n\nstatic int\nfilename_mountpoint(int dfd, struct filename *name, struct path *path,\n\t\t\tunsigned int flags)\n{\n\tstruct nameidata nd;\n\tint error;\n\tif (IS_ERR(name))\n\t\treturn PTR_ERR(name);\n\tset_nameidata(&nd, dfd, name);\n\terror = path_mountpoint(&nd, flags | LOOKUP_RCU, path);\n\tif (unlikely(error == -ECHILD))\n\t\terror = path_mountpoint(&nd, flags, path);\n\tif (unlikely(error == -ESTALE))\n\t\terror = path_mountpoint(&nd, flags | LOOKUP_REVAL, path);\n\tif (likely(!error))\n\t\taudit_inode(name, path->dentry, 0);\n\trestore_nameidata();\n\tputname(name);\n\treturn error;\n}\n\n/**\n * user_path_mountpoint_at - lookup a path from userland in order to umount it\n * @dfd:\tdirectory file descriptor\n * @name:\tpathname from userland\n * @flags:\tlookup flags\n * @path:\tpointer to container to hold result\n *\n * A umount is a special case for path walking. We're not actually interested\n * in the inode in this situation, and ESTALE errors can be a problem. We\n * simply want track down the dentry and vfsmount attached at the mountpoint\n * and avoid revalidating the last component.\n *\n * Returns 0 and populates \"path\" on success.\n */\nint\nuser_path_mountpoint_at(int dfd, const char __user *name, unsigned int flags,\n\t\t\tstruct path *path)\n{\n\treturn filename_mountpoint(dfd, getname(name), path, flags);\n}\n\nint\nkern_path_mountpoint(int dfd, const char *name, struct path *path,\n\t\t\tunsigned int flags)\n{\n\treturn filename_mountpoint(dfd, getname_kernel(name), path, flags);\n}\nEXPORT_SYMBOL(kern_path_mountpoint);\n\nint __check_sticky(struct inode *dir, struct inode *inode)\n{\n\tkuid_t fsuid = current_fsuid();\n\n\tif (uid_eq(inode->i_uid, fsuid))\n\t\treturn 0;\n\tif (uid_eq(dir->i_uid, fsuid))\n\t\treturn 0;\n\treturn !capable_wrt_inode_uidgid(inode, CAP_FOWNER);\n}\nEXPORT_SYMBOL(__check_sticky);\n\n/*\n *\tCheck whether we can remove a link victim from directory dir, check\n *  whether the type of victim is right.\n *  1. We can't do it if dir is read-only (done in permission())\n *  2. We should have write and exec permissions on dir\n *  3. We can't remove anything from append-only dir\n *  4. We can't do anything with immutable dir (done in permission())\n *  5. If the sticky bit on dir is set we should either\n *\ta. be owner of dir, or\n *\tb. be owner of victim, or\n *\tc. have CAP_FOWNER capability\n *  6. If the victim is append-only or immutable we can't do antyhing with\n *     links pointing to it.\n *  7. If the victim has an unknown uid or gid we can't change the inode.\n *  8. If we were asked to remove a directory and victim isn't one - ENOTDIR.\n *  9. If we were asked to remove a non-directory and victim isn't one - EISDIR.\n * 10. We can't remove a root or mountpoint.\n * 11. We don't allow removal of NFS sillyrenamed files; it's handled by\n *     nfs_async_unlink().\n */\nstatic int may_delete(struct inode *dir, struct dentry *victim, bool isdir)\n{\n\tstruct inode *inode = d_backing_inode(victim);\n\tint error;\n\n\tif (d_is_negative(victim))\n\t\treturn -ENOENT;\n\tBUG_ON(!inode);\n\n\tBUG_ON(victim->d_parent->d_inode != dir);\n\taudit_inode_child(dir, victim, AUDIT_TYPE_CHILD_DELETE);\n\n\terror = inode_permission(dir, MAY_WRITE | MAY_EXEC);\n\tif (error)\n\t\treturn error;\n\tif (IS_APPEND(dir))\n\t\treturn -EPERM;\n\n\tif (check_sticky(dir, inode) || IS_APPEND(inode) ||\n\t    IS_IMMUTABLE(inode) || IS_SWAPFILE(inode) || HAS_UNMAPPED_ID(inode))\n\t\treturn -EPERM;\n\tif (isdir) {\n\t\tif (!d_is_dir(victim))\n\t\t\treturn -ENOTDIR;\n\t\tif (IS_ROOT(victim))\n\t\t\treturn -EBUSY;\n\t} else if (d_is_dir(victim))\n\t\treturn -EISDIR;\n\tif (IS_DEADDIR(dir))\n\t\treturn -ENOENT;\n\tif (victim->d_flags & DCACHE_NFSFS_RENAMED)\n\t\treturn -EBUSY;\n\treturn 0;\n}\n\n/*\tCheck whether we can create an object with dentry child in directory\n *  dir.\n *  1. We can't do it if child already exists (open has special treatment for\n *     this case, but since we are inlined it's OK)\n *  2. We can't do it if dir is read-only (done in permission())\n *  3. We can't do it if the fs can't represent the fsuid or fsgid.\n *  4. We should have write and exec permissions on dir\n *  5. We can't do it if dir is immutable (done in permission())\n */\nstatic inline int may_create(struct inode *dir, struct dentry *child)\n{\n\tstruct user_namespace *s_user_ns;\n\taudit_inode_child(dir, child, AUDIT_TYPE_CHILD_CREATE);\n\tif (child->d_inode)\n\t\treturn -EEXIST;\n\tif (IS_DEADDIR(dir))\n\t\treturn -ENOENT;\n\ts_user_ns = dir->i_sb->s_user_ns;\n\tif (!kuid_has_mapping(s_user_ns, current_fsuid()) ||\n\t    !kgid_has_mapping(s_user_ns, current_fsgid()))\n\t\treturn -EOVERFLOW;\n\treturn inode_permission(dir, MAY_WRITE | MAY_EXEC);\n}\n\n/*\n * p1 and p2 should be directories on the same fs.\n */\nstruct dentry *lock_rename(struct dentry *p1, struct dentry *p2)\n{\n\tstruct dentry *p;\n\n\tif (p1 == p2) {\n\t\tinode_lock_nested(p1->d_inode, I_MUTEX_PARENT);\n\t\treturn NULL;\n\t}\n\n\tmutex_lock(&p1->d_sb->s_vfs_rename_mutex);\n\n\tp = d_ancestor(p2, p1);\n\tif (p) {\n\t\tinode_lock_nested(p2->d_inode, I_MUTEX_PARENT);\n\t\tinode_lock_nested(p1->d_inode, I_MUTEX_CHILD);\n\t\treturn p;\n\t}\n\n\tp = d_ancestor(p1, p2);\n\tif (p) {\n\t\tinode_lock_nested(p1->d_inode, I_MUTEX_PARENT);\n\t\tinode_lock_nested(p2->d_inode, I_MUTEX_CHILD);\n\t\treturn p;\n\t}\n\n\tinode_lock_nested(p1->d_inode, I_MUTEX_PARENT);\n\tinode_lock_nested(p2->d_inode, I_MUTEX_PARENT2);\n\treturn NULL;\n}\nEXPORT_SYMBOL(lock_rename);\n\nvoid unlock_rename(struct dentry *p1, struct dentry *p2)\n{\n\tinode_unlock(p1->d_inode);\n\tif (p1 != p2) {\n\t\tinode_unlock(p2->d_inode);\n\t\tmutex_unlock(&p1->d_sb->s_vfs_rename_mutex);\n\t}\n}\nEXPORT_SYMBOL(unlock_rename);\n\nint vfs_create(struct inode *dir, struct dentry *dentry, umode_t mode,\n\t\tbool want_excl)\n{\n\tint error = may_create(dir, dentry);\n\tif (error)\n\t\treturn error;\n\n\tif (!dir->i_op->create)\n\t\treturn -EACCES;\t/* shouldn't it be ENOSYS? */\n\tmode &= S_IALLUGO;\n\tmode |= S_IFREG;\n\terror = security_inode_create(dir, dentry, mode);\n\tif (error)\n\t\treturn error;\n\terror = dir->i_op->create(dir, dentry, mode, want_excl);\n\tif (!error)\n\t\tfsnotify_create(dir, dentry);\n\treturn error;\n}\nEXPORT_SYMBOL(vfs_create);\n\nbool may_open_dev(const struct path *path)\n{\n\treturn !(path->mnt->mnt_flags & MNT_NODEV) &&\n\t\t!(path->mnt->mnt_sb->s_iflags & SB_I_NODEV);\n}\n\nstatic int may_open(const struct path *path, int acc_mode, int flag)\n{\n\tstruct dentry *dentry = path->dentry;\n\tstruct inode *inode = dentry->d_inode;\n\tint error;\n\n\tif (!inode)\n\t\treturn -ENOENT;\n\n\tswitch (inode->i_mode & S_IFMT) {\n\tcase S_IFLNK:\n\t\treturn -ELOOP;\n\tcase S_IFDIR:\n\t\tif (acc_mode & MAY_WRITE)\n\t\t\treturn -EISDIR;\n\t\tbreak;\n\tcase S_IFBLK:\n\tcase S_IFCHR:\n\t\tif (!may_open_dev(path))\n\t\t\treturn -EACCES;\n\t\t/*FALLTHRU*/\n\tcase S_IFIFO:\n\tcase S_IFSOCK:\n\t\tflag &= ~O_TRUNC;\n\t\tbreak;\n\t}\n\n\terror = inode_permission(inode, MAY_OPEN | acc_mode);\n\tif (error)\n\t\treturn error;\n\n\t/*\n\t * An append-only file must be opened in append mode for writing.\n\t */\n\tif (IS_APPEND(inode)) {\n\t\tif  ((flag & O_ACCMODE) != O_RDONLY && !(flag & O_APPEND))\n\t\t\treturn -EPERM;\n\t\tif (flag & O_TRUNC)\n\t\t\treturn -EPERM;\n\t}\n\n\t/* O_NOATIME can only be set by the owner or superuser */\n\tif (flag & O_NOATIME && !inode_owner_or_capable(inode))\n\t\treturn -EPERM;\n\n\treturn 0;\n}\n\nstatic int handle_truncate(struct file *filp)\n{\n\tconst struct path *path = &filp->f_path;\n\tstruct inode *inode = path->dentry->d_inode;\n\tint error = get_write_access(inode);\n\tif (error)\n\t\treturn error;\n\t/*\n\t * Refuse to truncate files with mandatory locks held on them.\n\t */\n\terror = locks_verify_locked(filp);\n\tif (!error)\n\t\terror = security_path_truncate(path);\n\tif (!error) {\n\t\terror = do_truncate(path->dentry, 0,\n\t\t\t\t    ATTR_MTIME|ATTR_CTIME|ATTR_OPEN,\n\t\t\t\t    filp);\n\t}\n\tput_write_access(inode);\n\treturn error;\n}\n\nstatic inline int open_to_namei_flags(int flag)\n{\n\tif ((flag & O_ACCMODE) == 3)\n\t\tflag--;\n\treturn flag;\n}\n\nstatic int may_o_create(const struct path *dir, struct dentry *dentry, umode_t mode)\n{\n\tstruct user_namespace *s_user_ns;\n\tint error = security_path_mknod(dir, dentry, mode, 0);\n\tif (error)\n\t\treturn error;\n\n\ts_user_ns = dir->dentry->d_sb->s_user_ns;\n\tif (!kuid_has_mapping(s_user_ns, current_fsuid()) ||\n\t    !kgid_has_mapping(s_user_ns, current_fsgid()))\n\t\treturn -EOVERFLOW;\n\n\terror = inode_permission(dir->dentry->d_inode, MAY_WRITE | MAY_EXEC);\n\tif (error)\n\t\treturn error;\n\n\treturn security_inode_create(dir->dentry->d_inode, dentry, mode);\n}\n\n/*\n * Attempt to atomically look up, create and open a file from a negative\n * dentry.\n *\n * Returns 0 if successful.  The file will have been created and attached to\n * @file by the filesystem calling finish_open().\n *\n * Returns 1 if the file was looked up only or didn't need creating.  The\n * caller will need to perform the open themselves.  @path will have been\n * updated to point to the new dentry.  This may be negative.\n *\n * Returns an error code otherwise.\n */\nstatic int atomic_open(struct nameidata *nd, struct dentry *dentry,\n\t\t\tstruct path *path, struct file *file,\n\t\t\tconst struct open_flags *op,\n\t\t\tint open_flag, umode_t mode,\n\t\t\tint *opened)\n{\n\tstruct dentry *const DENTRY_NOT_SET = (void *) -1UL;\n\tstruct inode *dir =  nd->path.dentry->d_inode;\n\tint error;\n\n\tif (!(~open_flag & (O_EXCL | O_CREAT)))\t/* both O_EXCL and O_CREAT */\n\t\topen_flag &= ~O_TRUNC;\n\n\tif (nd->flags & LOOKUP_DIRECTORY)\n\t\topen_flag |= O_DIRECTORY;\n\n\tfile->f_path.dentry = DENTRY_NOT_SET;\n\tfile->f_path.mnt = nd->path.mnt;\n\terror = dir->i_op->atomic_open(dir, dentry, file,\n\t\t\t\t       open_to_namei_flags(open_flag),\n\t\t\t\t       mode, opened);\n\td_lookup_done(dentry);\n\tif (!error) {\n\t\t/*\n\t\t * We didn't have the inode before the open, so check open\n\t\t * permission here.\n\t\t */\n\t\tint acc_mode = op->acc_mode;\n\t\tif (*opened & FILE_CREATED) {\n\t\t\tWARN_ON(!(open_flag & O_CREAT));\n\t\t\tfsnotify_create(dir, dentry);\n\t\t\tacc_mode = 0;\n\t\t}\n\t\terror = may_open(&file->f_path, acc_mode, open_flag);\n\t\tif (WARN_ON(error > 0))\n\t\t\terror = -EINVAL;\n\t} else if (error > 0) {\n\t\tif (WARN_ON(file->f_path.dentry == DENTRY_NOT_SET)) {\n\t\t\terror = -EIO;\n\t\t} else {\n\t\t\tif (file->f_path.dentry) {\n\t\t\t\tdput(dentry);\n\t\t\t\tdentry = file->f_path.dentry;\n\t\t\t}\n\t\t\tif (*opened & FILE_CREATED)\n\t\t\t\tfsnotify_create(dir, dentry);\n\t\t\tif (unlikely(d_is_negative(dentry))) {\n\t\t\t\terror = -ENOENT;\n\t\t\t} else {\n\t\t\t\tpath->dentry = dentry;\n\t\t\t\tpath->mnt = nd->path.mnt;\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\t}\n\tdput(dentry);\n\treturn error;\n}\n\n/*\n * Look up and maybe create and open the last component.\n *\n * Must be called with i_mutex held on parent.\n *\n * Returns 0 if the file was successfully atomically created (if necessary) and\n * opened.  In this case the file will be returned attached to @file.\n *\n * Returns 1 if the file was not completely opened at this time, though lookups\n * and creations will have been performed and the dentry returned in @path will\n * be positive upon return if O_CREAT was specified.  If O_CREAT wasn't\n * specified then a negative dentry may be returned.\n *\n * An error code is returned otherwise.\n *\n * FILE_CREATE will be set in @*opened if the dentry was created and will be\n * cleared otherwise prior to returning.\n */\nstatic int lookup_open(struct nameidata *nd, struct path *path,\n\t\t\tstruct file *file,\n\t\t\tconst struct open_flags *op,\n\t\t\tbool got_write, int *opened)\n{\n\tstruct dentry *dir = nd->path.dentry;\n\tstruct inode *dir_inode = dir->d_inode;\n\tint open_flag = op->open_flag;\n\tstruct dentry *dentry;\n\tint error, create_error = 0;\n\tumode_t mode = op->mode;\n\tDECLARE_WAIT_QUEUE_HEAD_ONSTACK(wq);\n\n\tif (unlikely(IS_DEADDIR(dir_inode)))\n\t\treturn -ENOENT;\n\n\t*opened &= ~FILE_CREATED;\n\tdentry = d_lookup(dir, &nd->last);\n\tfor (;;) {\n\t\tif (!dentry) {\n\t\t\tdentry = d_alloc_parallel(dir, &nd->last, &wq);\n\t\t\tif (IS_ERR(dentry))\n\t\t\t\treturn PTR_ERR(dentry);\n\t\t}\n\t\tif (d_in_lookup(dentry))\n\t\t\tbreak;\n\n\t\terror = d_revalidate(dentry, nd->flags);\n\t\tif (likely(error > 0))\n\t\t\tbreak;\n\t\tif (error)\n\t\t\tgoto out_dput;\n\t\td_invalidate(dentry);\n\t\tdput(dentry);\n\t\tdentry = NULL;\n\t}\n\tif (dentry->d_inode) {\n\t\t/* Cached positive dentry: will open in f_op->open */\n\t\tgoto out_no_open;\n\t}\n\n\t/*\n\t * Checking write permission is tricky, bacuse we don't know if we are\n\t * going to actually need it: O_CREAT opens should work as long as the\n\t * file exists.  But checking existence breaks atomicity.  The trick is\n\t * to check access and if not granted clear O_CREAT from the flags.\n\t *\n\t * Another problem is returing the \"right\" error value (e.g. for an\n\t * O_EXCL open we want to return EEXIST not EROFS).\n\t */\n\tif (open_flag & O_CREAT) {\n\t\tif (!IS_POSIXACL(dir->d_inode))\n\t\t\tmode &= ~current_umask();\n\t\tif (unlikely(!got_write)) {\n\t\t\tcreate_error = -EROFS;\n\t\t\topen_flag &= ~O_CREAT;\n\t\t\tif (open_flag & (O_EXCL | O_TRUNC))\n\t\t\t\tgoto no_open;\n\t\t\t/* No side effects, safe to clear O_CREAT */\n\t\t} else {\n\t\t\tcreate_error = may_o_create(&nd->path, dentry, mode);\n\t\t\tif (create_error) {\n\t\t\t\topen_flag &= ~O_CREAT;\n\t\t\t\tif (open_flag & O_EXCL)\n\t\t\t\t\tgoto no_open;\n\t\t\t}\n\t\t}\n\t} else if ((open_flag & (O_TRUNC|O_WRONLY|O_RDWR)) &&\n\t\t   unlikely(!got_write)) {\n\t\t/*\n\t\t * No O_CREATE -> atomicity not a requirement -> fall\n\t\t * back to lookup + open\n\t\t */\n\t\tgoto no_open;\n\t}\n\n\tif (dir_inode->i_op->atomic_open) {\n\t\terror = atomic_open(nd, dentry, path, file, op, open_flag,\n\t\t\t\t    mode, opened);\n\t\tif (unlikely(error == -ENOENT) && create_error)\n\t\t\terror = create_error;\n\t\treturn error;\n\t}\n\nno_open:\n\tif (d_in_lookup(dentry)) {\n\t\tstruct dentry *res = dir_inode->i_op->lookup(dir_inode, dentry,\n\t\t\t\t\t\t\t     nd->flags);\n\t\td_lookup_done(dentry);\n\t\tif (unlikely(res)) {\n\t\t\tif (IS_ERR(res)) {\n\t\t\t\terror = PTR_ERR(res);\n\t\t\t\tgoto out_dput;\n\t\t\t}\n\t\t\tdput(dentry);\n\t\t\tdentry = res;\n\t\t}\n\t}\n\n\t/* Negative dentry, just create the file */\n\tif (!dentry->d_inode && (open_flag & O_CREAT)) {\n\t\t*opened |= FILE_CREATED;\n\t\taudit_inode_child(dir_inode, dentry, AUDIT_TYPE_CHILD_CREATE);\n\t\tif (!dir_inode->i_op->create) {\n\t\t\terror = -EACCES;\n\t\t\tgoto out_dput;\n\t\t}\n\t\terror = dir_inode->i_op->create(dir_inode, dentry, mode,\n\t\t\t\t\t\topen_flag & O_EXCL);\n\t\tif (error)\n\t\t\tgoto out_dput;\n\t\tfsnotify_create(dir_inode, dentry);\n\t}\n\tif (unlikely(create_error) && !dentry->d_inode) {\n\t\terror = create_error;\n\t\tgoto out_dput;\n\t}\nout_no_open:\n\tpath->dentry = dentry;\n\tpath->mnt = nd->path.mnt;\n\treturn 1;\n\nout_dput:\n\tdput(dentry);\n\treturn error;\n}\n\n/*\n * Handle the last step of open()\n */\nstatic int do_last(struct nameidata *nd,\n\t\t   struct file *file, const struct open_flags *op,\n\t\t   int *opened)\n{\n\tstruct dentry *dir = nd->path.dentry;\n\tint open_flag = op->open_flag;\n\tbool will_truncate = (open_flag & O_TRUNC) != 0;\n\tbool got_write = false;\n\tint acc_mode = op->acc_mode;\n\tunsigned seq;\n\tstruct inode *inode;\n\tstruct path path;\n\tint error;\n\n\tnd->flags &= ~LOOKUP_PARENT;\n\tnd->flags |= op->intent;\n\n\tif (nd->last_type != LAST_NORM) {\n\t\terror = handle_dots(nd, nd->last_type);\n\t\tif (unlikely(error))\n\t\t\treturn error;\n\t\tgoto finish_open;\n\t}\n\n\tif (!(open_flag & O_CREAT)) {\n\t\tif (nd->last.name[nd->last.len])\n\t\t\tnd->flags |= LOOKUP_FOLLOW | LOOKUP_DIRECTORY;\n\t\t/* we _can_ be in RCU mode here */\n\t\terror = lookup_fast(nd, &path, &inode, &seq);\n\t\tif (likely(error > 0))\n\t\t\tgoto finish_lookup;\n\n\t\tif (error < 0)\n\t\t\treturn error;\n\n\t\tBUG_ON(nd->inode != dir->d_inode);\n\t\tBUG_ON(nd->flags & LOOKUP_RCU);\n\t} else {\n\t\t/* create side of things */\n\t\t/*\n\t\t * This will *only* deal with leaving RCU mode - LOOKUP_JUMPED\n\t\t * has been cleared when we got to the last component we are\n\t\t * about to look up\n\t\t */\n\t\terror = complete_walk(nd);\n\t\tif (error)\n\t\t\treturn error;\n\n\t\taudit_inode(nd->name, dir, LOOKUP_PARENT);\n\t\t/* trailing slashes? */\n\t\tif (unlikely(nd->last.name[nd->last.len]))\n\t\t\treturn -EISDIR;\n\t}\n\n\tif (open_flag & (O_CREAT | O_TRUNC | O_WRONLY | O_RDWR)) {\n\t\terror = mnt_want_write(nd->path.mnt);\n\t\tif (!error)\n\t\t\tgot_write = true;\n\t\t/*\n\t\t * do _not_ fail yet - we might not need that or fail with\n\t\t * a different error; let lookup_open() decide; we'll be\n\t\t * dropping this one anyway.\n\t\t */\n\t}\n\tif (open_flag & O_CREAT)\n\t\tinode_lock(dir->d_inode);\n\telse\n\t\tinode_lock_shared(dir->d_inode);\n\terror = lookup_open(nd, &path, file, op, got_write, opened);\n\tif (open_flag & O_CREAT)\n\t\tinode_unlock(dir->d_inode);\n\telse\n\t\tinode_unlock_shared(dir->d_inode);\n\n\tif (error <= 0) {\n\t\tif (error)\n\t\t\tgoto out;\n\n\t\tif ((*opened & FILE_CREATED) ||\n\t\t    !S_ISREG(file_inode(file)->i_mode))\n\t\t\twill_truncate = false;\n\n\t\taudit_inode(nd->name, file->f_path.dentry, 0);\n\t\tgoto opened;\n\t}\n\n\tif (*opened & FILE_CREATED) {\n\t\t/* Don't check for write permission, don't truncate */\n\t\topen_flag &= ~O_TRUNC;\n\t\twill_truncate = false;\n\t\tacc_mode = 0;\n\t\tpath_to_nameidata(&path, nd);\n\t\tgoto finish_open_created;\n\t}\n\n\t/*\n\t * If atomic_open() acquired write access it is dropped now due to\n\t * possible mount and symlink following (this might be optimized away if\n\t * necessary...)\n\t */\n\tif (got_write) {\n\t\tmnt_drop_write(nd->path.mnt);\n\t\tgot_write = false;\n\t}\n\n\terror = follow_managed(&path, nd);\n\tif (unlikely(error < 0))\n\t\treturn error;\n\n\tif (unlikely(d_is_negative(path.dentry))) {\n\t\tpath_to_nameidata(&path, nd);\n\t\treturn -ENOENT;\n\t}\n\n\t/*\n\t * create/update audit record if it already exists.\n\t */\n\taudit_inode(nd->name, path.dentry, 0);\n\n\tif (unlikely((open_flag & (O_EXCL | O_CREAT)) == (O_EXCL | O_CREAT))) {\n\t\tpath_to_nameidata(&path, nd);\n\t\treturn -EEXIST;\n\t}\n\n\tseq = 0;\t/* out of RCU mode, so the value doesn't matter */\n\tinode = d_backing_inode(path.dentry);\nfinish_lookup:\n\terror = step_into(nd, &path, 0, inode, seq);\n\tif (unlikely(error))\n\t\treturn error;\nfinish_open:\n\t/* Why this, you ask?  _Now_ we might have grown LOOKUP_JUMPED... */\n\terror = complete_walk(nd);\n\tif (error)\n\t\treturn error;\n\taudit_inode(nd->name, nd->path.dentry, 0);\n\terror = -EISDIR;\n\tif ((open_flag & O_CREAT) && d_is_dir(nd->path.dentry))\n\t\tgoto out;\n\terror = -ENOTDIR;\n\tif ((nd->flags & LOOKUP_DIRECTORY) && !d_can_lookup(nd->path.dentry))\n\t\tgoto out;\n\tif (!d_is_reg(nd->path.dentry))\n\t\twill_truncate = false;\n\n\tif (will_truncate) {\n\t\terror = mnt_want_write(nd->path.mnt);\n\t\tif (error)\n\t\t\tgoto out;\n\t\tgot_write = true;\n\t}\nfinish_open_created:\n\terror = may_open(&nd->path, acc_mode, open_flag);\n\tif (error)\n\t\tgoto out;\n\tBUG_ON(*opened & FILE_OPENED); /* once it's opened, it's opened */\n\terror = vfs_open(&nd->path, file, current_cred());\n\tif (error)\n\t\tgoto out;\n\t*opened |= FILE_OPENED;\nopened:\n\terror = open_check_o_direct(file);\n\tif (!error)\n\t\terror = ima_file_check(file, op->acc_mode, *opened);\n\tif (!error && will_truncate)\n\t\terror = handle_truncate(file);\nout:\n\tif (unlikely(error) && (*opened & FILE_OPENED))\n\t\tfput(file);\n\tif (unlikely(error > 0)) {\n\t\tWARN_ON(1);\n\t\terror = -EINVAL;\n\t}\n\tif (got_write)\n\t\tmnt_drop_write(nd->path.mnt);\n\treturn error;\n}\n\nstruct dentry *vfs_tmpfile(struct dentry *dentry, umode_t mode, int open_flag)\n{\n\tstatic const struct qstr name = QSTR_INIT(\"/\", 1);\n\tstruct dentry *child = NULL;\n\tstruct inode *dir = dentry->d_inode;\n\tstruct inode *inode;\n\tint error;\n\n\t/* we want directory to be writable */\n\terror = inode_permission(dir, MAY_WRITE | MAY_EXEC);\n\tif (error)\n\t\tgoto out_err;\n\terror = -EOPNOTSUPP;\n\tif (!dir->i_op->tmpfile)\n\t\tgoto out_err;\n\terror = -ENOMEM;\n\tchild = d_alloc(dentry, &name);\n\tif (unlikely(!child))\n\t\tgoto out_err;\n\terror = dir->i_op->tmpfile(dir, child, mode);\n\tif (error)\n\t\tgoto out_err;\n\terror = -ENOENT;\n\tinode = child->d_inode;\n\tif (unlikely(!inode))\n\t\tgoto out_err;\n\tif (!(open_flag & O_EXCL)) {\n\t\tspin_lock(&inode->i_lock);\n\t\tinode->i_state |= I_LINKABLE;\n\t\tspin_unlock(&inode->i_lock);\n\t}\n\treturn child;\n\nout_err:\n\tdput(child);\n\treturn ERR_PTR(error);\n}\nEXPORT_SYMBOL(vfs_tmpfile);\n\nstatic int do_tmpfile(struct nameidata *nd, unsigned flags,\n\t\tconst struct open_flags *op,\n\t\tstruct file *file, int *opened)\n{\n\tstruct dentry *child;\n\tstruct path path;\n\tint error = path_lookupat(nd, flags | LOOKUP_DIRECTORY, &path);\n\tif (unlikely(error))\n\t\treturn error;\n\terror = mnt_want_write(path.mnt);\n\tif (unlikely(error))\n\t\tgoto out;\n\tchild = vfs_tmpfile(path.dentry, op->mode, op->open_flag);\n\terror = PTR_ERR(child);\n\tif (unlikely(IS_ERR(child)))\n\t\tgoto out2;\n\tdput(path.dentry);\n\tpath.dentry = child;\n\taudit_inode(nd->name, child, 0);\n\t/* Don't check for other permissions, the inode was just created */\n\terror = may_open(&path, 0, op->open_flag);\n\tif (error)\n\t\tgoto out2;\n\tfile->f_path.mnt = path.mnt;\n\terror = finish_open(file, child, NULL, opened);\n\tif (error)\n\t\tgoto out2;\n\terror = open_check_o_direct(file);\n\tif (error)\n\t\tfput(file);\nout2:\n\tmnt_drop_write(path.mnt);\nout:\n\tpath_put(&path);\n\treturn error;\n}\n\nstatic int do_o_path(struct nameidata *nd, unsigned flags, struct file *file)\n{\n\tstruct path path;\n\tint error = path_lookupat(nd, flags, &path);\n\tif (!error) {\n\t\taudit_inode(nd->name, path.dentry, 0);\n\t\terror = vfs_open(&path, file, current_cred());\n\t\tpath_put(&path);\n\t}\n\treturn error;\n}\n\nstatic struct file *path_openat(struct nameidata *nd,\n\t\t\tconst struct open_flags *op, unsigned flags)\n{\n\tconst char *s;\n\tstruct file *file;\n\tint opened = 0;\n\tint error;\n\n\tfile = get_empty_filp();\n\tif (IS_ERR(file))\n\t\treturn file;\n\n\tfile->f_flags = op->open_flag;\n\n\tif (unlikely(file->f_flags & __O_TMPFILE)) {\n\t\terror = do_tmpfile(nd, flags, op, file, &opened);\n\t\tgoto out2;\n\t}\n\n\tif (unlikely(file->f_flags & O_PATH)) {\n\t\terror = do_o_path(nd, flags, file);\n\t\tif (!error)\n\t\t\topened |= FILE_OPENED;\n\t\tgoto out2;\n\t}\n\n\ts = path_init(nd, flags);\n\tif (IS_ERR(s)) {\n\t\tput_filp(file);\n\t\treturn ERR_CAST(s);\n\t}\n\twhile (!(error = link_path_walk(s, nd)) &&\n\t\t(error = do_last(nd, file, op, &opened)) > 0) {\n\t\tnd->flags &= ~(LOOKUP_OPEN|LOOKUP_CREATE|LOOKUP_EXCL);\n\t\ts = trailing_symlink(nd);\n\t\tif (IS_ERR(s)) {\n\t\t\terror = PTR_ERR(s);\n\t\t\tbreak;\n\t\t}\n\t}\n\tterminate_walk(nd);\nout2:\n\tif (!(opened & FILE_OPENED)) {\n\t\tBUG_ON(!error);\n\t\tput_filp(file);\n\t}\n\tif (unlikely(error)) {\n\t\tif (error == -EOPENSTALE) {\n\t\t\tif (flags & LOOKUP_RCU)\n\t\t\t\terror = -ECHILD;\n\t\t\telse\n\t\t\t\terror = -ESTALE;\n\t\t}\n\t\tfile = ERR_PTR(error);\n\t}\n\treturn file;\n}\n\nstruct file *do_filp_open(int dfd, struct filename *pathname,\n\t\tconst struct open_flags *op)\n{\n\tstruct nameidata nd;\n\tint flags = op->lookup_flags;\n\tstruct file *filp;\n\n\tset_nameidata(&nd, dfd, pathname);\n\tfilp = path_openat(&nd, op, flags | LOOKUP_RCU);\n\tif (unlikely(filp == ERR_PTR(-ECHILD)))\n\t\tfilp = path_openat(&nd, op, flags);\n\tif (unlikely(filp == ERR_PTR(-ESTALE)))\n\t\tfilp = path_openat(&nd, op, flags | LOOKUP_REVAL);\n\trestore_nameidata();\n\treturn filp;\n}\n\nstruct file *do_file_open_root(struct dentry *dentry, struct vfsmount *mnt,\n\t\tconst char *name, const struct open_flags *op)\n{\n\tstruct nameidata nd;\n\tstruct file *file;\n\tstruct filename *filename;\n\tint flags = op->lookup_flags | LOOKUP_ROOT;\n\n\tnd.root.mnt = mnt;\n\tnd.root.dentry = dentry;\n\n\tif (d_is_symlink(dentry) && op->intent & LOOKUP_OPEN)\n\t\treturn ERR_PTR(-ELOOP);\n\n\tfilename = getname_kernel(name);\n\tif (IS_ERR(filename))\n\t\treturn ERR_CAST(filename);\n\n\tset_nameidata(&nd, -1, filename);\n\tfile = path_openat(&nd, op, flags | LOOKUP_RCU);\n\tif (unlikely(file == ERR_PTR(-ECHILD)))\n\t\tfile = path_openat(&nd, op, flags);\n\tif (unlikely(file == ERR_PTR(-ESTALE)))\n\t\tfile = path_openat(&nd, op, flags | LOOKUP_REVAL);\n\trestore_nameidata();\n\tputname(filename);\n\treturn file;\n}\n\nstatic struct dentry *filename_create(int dfd, struct filename *name,\n\t\t\t\tstruct path *path, unsigned int lookup_flags)\n{\n\tstruct dentry *dentry = ERR_PTR(-EEXIST);\n\tstruct qstr last;\n\tint type;\n\tint err2;\n\tint error;\n\tbool is_dir = (lookup_flags & LOOKUP_DIRECTORY);\n\n\t/*\n\t * Note that only LOOKUP_REVAL and LOOKUP_DIRECTORY matter here. Any\n\t * other flags passed in are ignored!\n\t */\n\tlookup_flags &= LOOKUP_REVAL;\n\n\tname = filename_parentat(dfd, name, lookup_flags, path, &last, &type);\n\tif (IS_ERR(name))\n\t\treturn ERR_CAST(name);\n\n\t/*\n\t * Yucky last component or no last component at all?\n\t * (foo/., foo/.., /////)\n\t */\n\tif (unlikely(type != LAST_NORM))\n\t\tgoto out;\n\n\t/* don't fail immediately if it's r/o, at least try to report other errors */\n\terr2 = mnt_want_write(path->mnt);\n\t/*\n\t * Do the final lookup.\n\t */\n\tlookup_flags |= LOOKUP_CREATE | LOOKUP_EXCL;\n\tinode_lock_nested(path->dentry->d_inode, I_MUTEX_PARENT);\n\tdentry = __lookup_hash(&last, path->dentry, lookup_flags);\n\tif (IS_ERR(dentry))\n\t\tgoto unlock;\n\n\terror = -EEXIST;\n\tif (d_is_positive(dentry))\n\t\tgoto fail;\n\n\t/*\n\t * Special case - lookup gave negative, but... we had foo/bar/\n\t * From the vfs_mknod() POV we just have a negative dentry -\n\t * all is fine. Let's be bastards - you had / on the end, you've\n\t * been asking for (non-existent) directory. -ENOENT for you.\n\t */\n\tif (unlikely(!is_dir && last.name[last.len])) {\n\t\terror = -ENOENT;\n\t\tgoto fail;\n\t}\n\tif (unlikely(err2)) {\n\t\terror = err2;\n\t\tgoto fail;\n\t}\n\tputname(name);\n\treturn dentry;\nfail:\n\tdput(dentry);\n\tdentry = ERR_PTR(error);\nunlock:\n\tinode_unlock(path->dentry->d_inode);\n\tif (!err2)\n\t\tmnt_drop_write(path->mnt);\nout:\n\tpath_put(path);\n\tputname(name);\n\treturn dentry;\n}\n\nstruct dentry *kern_path_create(int dfd, const char *pathname,\n\t\t\t\tstruct path *path, unsigned int lookup_flags)\n{\n\treturn filename_create(dfd, getname_kernel(pathname),\n\t\t\t\tpath, lookup_flags);\n}\nEXPORT_SYMBOL(kern_path_create);\n\nvoid done_path_create(struct path *path, struct dentry *dentry)\n{\n\tdput(dentry);\n\tinode_unlock(path->dentry->d_inode);\n\tmnt_drop_write(path->mnt);\n\tpath_put(path);\n}\nEXPORT_SYMBOL(done_path_create);\n\ninline struct dentry *user_path_create(int dfd, const char __user *pathname,\n\t\t\t\tstruct path *path, unsigned int lookup_flags)\n{\n\treturn filename_create(dfd, getname(pathname), path, lookup_flags);\n}\nEXPORT_SYMBOL(user_path_create);\n\nint vfs_mknod(struct inode *dir, struct dentry *dentry, umode_t mode, dev_t dev)\n{\n\tint error = may_create(dir, dentry);\n\n\tif (error)\n\t\treturn error;\n\n\tif ((S_ISCHR(mode) || S_ISBLK(mode)) && !capable(CAP_MKNOD))\n\t\treturn -EPERM;\n\n\tif (!dir->i_op->mknod)\n\t\treturn -EPERM;\n\n\terror = devcgroup_inode_mknod(mode, dev);\n\tif (error)\n\t\treturn error;\n\n\terror = security_inode_mknod(dir, dentry, mode, dev);\n\tif (error)\n\t\treturn error;\n\n\terror = dir->i_op->mknod(dir, dentry, mode, dev);\n\tif (!error)\n\t\tfsnotify_create(dir, dentry);\n\treturn error;\n}\nEXPORT_SYMBOL(vfs_mknod);\n\nstatic int may_mknod(umode_t mode)\n{\n\tswitch (mode & S_IFMT) {\n\tcase S_IFREG:\n\tcase S_IFCHR:\n\tcase S_IFBLK:\n\tcase S_IFIFO:\n\tcase S_IFSOCK:\n\tcase 0: /* zero mode translates to S_IFREG */\n\t\treturn 0;\n\tcase S_IFDIR:\n\t\treturn -EPERM;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nSYSCALL_DEFINE4(mknodat, int, dfd, const char __user *, filename, umode_t, mode,\n\t\tunsigned, dev)\n{\n\tstruct dentry *dentry;\n\tstruct path path;\n\tint error;\n\tunsigned int lookup_flags = 0;\n\n\terror = may_mknod(mode);\n\tif (error)\n\t\treturn error;\nretry:\n\tdentry = user_path_create(dfd, filename, &path, lookup_flags);\n\tif (IS_ERR(dentry))\n\t\treturn PTR_ERR(dentry);\n\n\tif (!IS_POSIXACL(path.dentry->d_inode))\n\t\tmode &= ~current_umask();\n\terror = security_path_mknod(&path, dentry, mode, dev);\n\tif (error)\n\t\tgoto out;\n\tswitch (mode & S_IFMT) {\n\t\tcase 0: case S_IFREG:\n\t\t\terror = vfs_create(path.dentry->d_inode,dentry,mode,true);\n\t\t\tif (!error)\n\t\t\t\tima_post_path_mknod(dentry);\n\t\t\tbreak;\n\t\tcase S_IFCHR: case S_IFBLK:\n\t\t\terror = vfs_mknod(path.dentry->d_inode,dentry,mode,\n\t\t\t\t\tnew_decode_dev(dev));\n\t\t\tbreak;\n\t\tcase S_IFIFO: case S_IFSOCK:\n\t\t\terror = vfs_mknod(path.dentry->d_inode,dentry,mode,0);\n\t\t\tbreak;\n\t}\nout:\n\tdone_path_create(&path, dentry);\n\tif (retry_estale(error, lookup_flags)) {\n\t\tlookup_flags |= LOOKUP_REVAL;\n\t\tgoto retry;\n\t}\n\treturn error;\n}\n\nSYSCALL_DEFINE3(mknod, const char __user *, filename, umode_t, mode, unsigned, dev)\n{\n\treturn sys_mknodat(AT_FDCWD, filename, mode, dev);\n}\n\nint vfs_mkdir(struct inode *dir, struct dentry *dentry, umode_t mode)\n{\n\tint error = may_create(dir, dentry);\n\tunsigned max_links = dir->i_sb->s_max_links;\n\n\tif (error)\n\t\treturn error;\n\n\tif (!dir->i_op->mkdir)\n\t\treturn -EPERM;\n\n\tmode &= (S_IRWXUGO|S_ISVTX);\n\terror = security_inode_mkdir(dir, dentry, mode);\n\tif (error)\n\t\treturn error;\n\n\tif (max_links && dir->i_nlink >= max_links)\n\t\treturn -EMLINK;\n\n\terror = dir->i_op->mkdir(dir, dentry, mode);\n\tif (!error)\n\t\tfsnotify_mkdir(dir, dentry);\n\treturn error;\n}\nEXPORT_SYMBOL(vfs_mkdir);\n\nSYSCALL_DEFINE3(mkdirat, int, dfd, const char __user *, pathname, umode_t, mode)\n{\n\tstruct dentry *dentry;\n\tstruct path path;\n\tint error;\n\tunsigned int lookup_flags = LOOKUP_DIRECTORY;\n\nretry:\n\tdentry = user_path_create(dfd, pathname, &path, lookup_flags);\n\tif (IS_ERR(dentry))\n\t\treturn PTR_ERR(dentry);\n\n\tif (!IS_POSIXACL(path.dentry->d_inode))\n\t\tmode &= ~current_umask();\n\terror = security_path_mkdir(&path, dentry, mode);\n\tif (!error)\n\t\terror = vfs_mkdir(path.dentry->d_inode, dentry, mode);\n\tdone_path_create(&path, dentry);\n\tif (retry_estale(error, lookup_flags)) {\n\t\tlookup_flags |= LOOKUP_REVAL;\n\t\tgoto retry;\n\t}\n\treturn error;\n}\n\nSYSCALL_DEFINE2(mkdir, const char __user *, pathname, umode_t, mode)\n{\n\treturn sys_mkdirat(AT_FDCWD, pathname, mode);\n}\n\nint vfs_rmdir(struct inode *dir, struct dentry *dentry)\n{\n\tint error = may_delete(dir, dentry, 1);\n\n\tif (error)\n\t\treturn error;\n\n\tif (!dir->i_op->rmdir)\n\t\treturn -EPERM;\n\n\tdget(dentry);\n\tinode_lock(dentry->d_inode);\n\n\terror = -EBUSY;\n\tif (is_local_mountpoint(dentry))\n\t\tgoto out;\n\n\terror = security_inode_rmdir(dir, dentry);\n\tif (error)\n\t\tgoto out;\n\n\tshrink_dcache_parent(dentry);\n\terror = dir->i_op->rmdir(dir, dentry);\n\tif (error)\n\t\tgoto out;\n\n\tdentry->d_inode->i_flags |= S_DEAD;\n\tdont_mount(dentry);\n\tdetach_mounts(dentry);\n\nout:\n\tinode_unlock(dentry->d_inode);\n\tdput(dentry);\n\tif (!error)\n\t\td_delete(dentry);\n\treturn error;\n}\nEXPORT_SYMBOL(vfs_rmdir);\n\nstatic long do_rmdir(int dfd, const char __user *pathname)\n{\n\tint error = 0;\n\tstruct filename *name;\n\tstruct dentry *dentry;\n\tstruct path path;\n\tstruct qstr last;\n\tint type;\n\tunsigned int lookup_flags = 0;\nretry:\n\tname = filename_parentat(dfd, getname(pathname), lookup_flags,\n\t\t\t\t&path, &last, &type);\n\tif (IS_ERR(name))\n\t\treturn PTR_ERR(name);\n\n\tswitch (type) {\n\tcase LAST_DOTDOT:\n\t\terror = -ENOTEMPTY;\n\t\tgoto exit1;\n\tcase LAST_DOT:\n\t\terror = -EINVAL;\n\t\tgoto exit1;\n\tcase LAST_ROOT:\n\t\terror = -EBUSY;\n\t\tgoto exit1;\n\t}\n\n\terror = mnt_want_write(path.mnt);\n\tif (error)\n\t\tgoto exit1;\n\n\tinode_lock_nested(path.dentry->d_inode, I_MUTEX_PARENT);\n\tdentry = __lookup_hash(&last, path.dentry, lookup_flags);\n\terror = PTR_ERR(dentry);\n\tif (IS_ERR(dentry))\n\t\tgoto exit2;\n\tif (!dentry->d_inode) {\n\t\terror = -ENOENT;\n\t\tgoto exit3;\n\t}\n\terror = security_path_rmdir(&path, dentry);\n\tif (error)\n\t\tgoto exit3;\n\terror = vfs_rmdir(path.dentry->d_inode, dentry);\nexit3:\n\tdput(dentry);\nexit2:\n\tinode_unlock(path.dentry->d_inode);\n\tmnt_drop_write(path.mnt);\nexit1:\n\tpath_put(&path);\n\tputname(name);\n\tif (retry_estale(error, lookup_flags)) {\n\t\tlookup_flags |= LOOKUP_REVAL;\n\t\tgoto retry;\n\t}\n\treturn error;\n}\n\nSYSCALL_DEFINE1(rmdir, const char __user *, pathname)\n{\n\treturn do_rmdir(AT_FDCWD, pathname);\n}\n\n/**\n * vfs_unlink - unlink a filesystem object\n * @dir:\tparent directory\n * @dentry:\tvictim\n * @delegated_inode: returns victim inode, if the inode is delegated.\n *\n * The caller must hold dir->i_mutex.\n *\n * If vfs_unlink discovers a delegation, it will return -EWOULDBLOCK and\n * return a reference to the inode in delegated_inode.  The caller\n * should then break the delegation on that inode and retry.  Because\n * breaking a delegation may take a long time, the caller should drop\n * dir->i_mutex before doing so.\n *\n * Alternatively, a caller may pass NULL for delegated_inode.  This may\n * be appropriate for callers that expect the underlying filesystem not\n * to be NFS exported.\n */\nint vfs_unlink(struct inode *dir, struct dentry *dentry, struct inode **delegated_inode)\n{\n\tstruct inode *target = dentry->d_inode;\n\tint error = may_delete(dir, dentry, 0);\n\n\tif (error)\n\t\treturn error;\n\n\tif (!dir->i_op->unlink)\n\t\treturn -EPERM;\n\n\tinode_lock(target);\n\tif (is_local_mountpoint(dentry))\n\t\terror = -EBUSY;\n\telse {\n\t\terror = security_inode_unlink(dir, dentry);\n\t\tif (!error) {\n\t\t\terror = try_break_deleg(target, delegated_inode);\n\t\t\tif (error)\n\t\t\t\tgoto out;\n\t\t\terror = dir->i_op->unlink(dir, dentry);\n\t\t\tif (!error) {\n\t\t\t\tdont_mount(dentry);\n\t\t\t\tdetach_mounts(dentry);\n\t\t\t}\n\t\t}\n\t}\nout:\n\tinode_unlock(target);\n\n\t/* We don't d_delete() NFS sillyrenamed files--they still exist. */\n\tif (!error && !(dentry->d_flags & DCACHE_NFSFS_RENAMED)) {\n\t\tfsnotify_link_count(target);\n\t\td_delete(dentry);\n\t}\n\n\treturn error;\n}\nEXPORT_SYMBOL(vfs_unlink);\n\n/*\n * Make sure that the actual truncation of the file will occur outside its\n * directory's i_mutex.  Truncate can take a long time if there is a lot of\n * writeout happening, and we don't want to prevent access to the directory\n * while waiting on the I/O.\n */\nstatic long do_unlinkat(int dfd, const char __user *pathname)\n{\n\tint error;\n\tstruct filename *name;\n\tstruct dentry *dentry;\n\tstruct path path;\n\tstruct qstr last;\n\tint type;\n\tstruct inode *inode = NULL;\n\tstruct inode *delegated_inode = NULL;\n\tunsigned int lookup_flags = 0;\nretry:\n\tname = filename_parentat(dfd, getname(pathname), lookup_flags,\n\t\t\t\t&path, &last, &type);\n\tif (IS_ERR(name))\n\t\treturn PTR_ERR(name);\n\n\terror = -EISDIR;\n\tif (type != LAST_NORM)\n\t\tgoto exit1;\n\n\terror = mnt_want_write(path.mnt);\n\tif (error)\n\t\tgoto exit1;\nretry_deleg:\n\tinode_lock_nested(path.dentry->d_inode, I_MUTEX_PARENT);\n\tdentry = __lookup_hash(&last, path.dentry, lookup_flags);\n\terror = PTR_ERR(dentry);\n\tif (!IS_ERR(dentry)) {\n\t\t/* Why not before? Because we want correct error value */\n\t\tif (last.name[last.len])\n\t\t\tgoto slashes;\n\t\tinode = dentry->d_inode;\n\t\tif (d_is_negative(dentry))\n\t\t\tgoto slashes;\n\t\tihold(inode);\n\t\terror = security_path_unlink(&path, dentry);\n\t\tif (error)\n\t\t\tgoto exit2;\n\t\terror = vfs_unlink(path.dentry->d_inode, dentry, &delegated_inode);\nexit2:\n\t\tdput(dentry);\n\t}\n\tinode_unlock(path.dentry->d_inode);\n\tif (inode)\n\t\tiput(inode);\t/* truncate the inode here */\n\tinode = NULL;\n\tif (delegated_inode) {\n\t\terror = break_deleg_wait(&delegated_inode);\n\t\tif (!error)\n\t\t\tgoto retry_deleg;\n\t}\n\tmnt_drop_write(path.mnt);\nexit1:\n\tpath_put(&path);\n\tputname(name);\n\tif (retry_estale(error, lookup_flags)) {\n\t\tlookup_flags |= LOOKUP_REVAL;\n\t\tinode = NULL;\n\t\tgoto retry;\n\t}\n\treturn error;\n\nslashes:\n\tif (d_is_negative(dentry))\n\t\terror = -ENOENT;\n\telse if (d_is_dir(dentry))\n\t\terror = -EISDIR;\n\telse\n\t\terror = -ENOTDIR;\n\tgoto exit2;\n}\n\nSYSCALL_DEFINE3(unlinkat, int, dfd, const char __user *, pathname, int, flag)\n{\n\tif ((flag & ~AT_REMOVEDIR) != 0)\n\t\treturn -EINVAL;\n\n\tif (flag & AT_REMOVEDIR)\n\t\treturn do_rmdir(dfd, pathname);\n\n\treturn do_unlinkat(dfd, pathname);\n}\n\nSYSCALL_DEFINE1(unlink, const char __user *, pathname)\n{\n\treturn do_unlinkat(AT_FDCWD, pathname);\n}\n\nint vfs_symlink(struct inode *dir, struct dentry *dentry, const char *oldname)\n{\n\tint error = may_create(dir, dentry);\n\n\tif (error)\n\t\treturn error;\n\n\tif (!dir->i_op->symlink)\n\t\treturn -EPERM;\n\n\terror = security_inode_symlink(dir, dentry, oldname);\n\tif (error)\n\t\treturn error;\n\n\terror = dir->i_op->symlink(dir, dentry, oldname);\n\tif (!error)\n\t\tfsnotify_create(dir, dentry);\n\treturn error;\n}\nEXPORT_SYMBOL(vfs_symlink);\n\nSYSCALL_DEFINE3(symlinkat, const char __user *, oldname,\n\t\tint, newdfd, const char __user *, newname)\n{\n\tint error;\n\tstruct filename *from;\n\tstruct dentry *dentry;\n\tstruct path path;\n\tunsigned int lookup_flags = 0;\n\n\tfrom = getname(oldname);\n\tif (IS_ERR(from))\n\t\treturn PTR_ERR(from);\nretry:\n\tdentry = user_path_create(newdfd, newname, &path, lookup_flags);\n\terror = PTR_ERR(dentry);\n\tif (IS_ERR(dentry))\n\t\tgoto out_putname;\n\n\terror = security_path_symlink(&path, dentry, from->name);\n\tif (!error)\n\t\terror = vfs_symlink(path.dentry->d_inode, dentry, from->name);\n\tdone_path_create(&path, dentry);\n\tif (retry_estale(error, lookup_flags)) {\n\t\tlookup_flags |= LOOKUP_REVAL;\n\t\tgoto retry;\n\t}\nout_putname:\n\tputname(from);\n\treturn error;\n}\n\nSYSCALL_DEFINE2(symlink, const char __user *, oldname, const char __user *, newname)\n{\n\treturn sys_symlinkat(oldname, AT_FDCWD, newname);\n}\n\n/**\n * vfs_link - create a new link\n * @old_dentry:\tobject to be linked\n * @dir:\tnew parent\n * @new_dentry:\twhere to create the new link\n * @delegated_inode: returns inode needing a delegation break\n *\n * The caller must hold dir->i_mutex\n *\n * If vfs_link discovers a delegation on the to-be-linked file in need\n * of breaking, it will return -EWOULDBLOCK and return a reference to the\n * inode in delegated_inode.  The caller should then break the delegation\n * and retry.  Because breaking a delegation may take a long time, the\n * caller should drop the i_mutex before doing so.\n *\n * Alternatively, a caller may pass NULL for delegated_inode.  This may\n * be appropriate for callers that expect the underlying filesystem not\n * to be NFS exported.\n */\nint vfs_link(struct dentry *old_dentry, struct inode *dir, struct dentry *new_dentry, struct inode **delegated_inode)\n{\n\tstruct inode *inode = old_dentry->d_inode;\n\tunsigned max_links = dir->i_sb->s_max_links;\n\tint error;\n\n\tif (!inode)\n\t\treturn -ENOENT;\n\n\terror = may_create(dir, new_dentry);\n\tif (error)\n\t\treturn error;\n\n\tif (dir->i_sb != inode->i_sb)\n\t\treturn -EXDEV;\n\n\t/*\n\t * A link to an append-only or immutable file cannot be created.\n\t */\n\tif (IS_APPEND(inode) || IS_IMMUTABLE(inode))\n\t\treturn -EPERM;\n\t/*\n\t * Updating the link count will likely cause i_uid and i_gid to\n\t * be writen back improperly if their true value is unknown to\n\t * the vfs.\n\t */\n\tif (HAS_UNMAPPED_ID(inode))\n\t\treturn -EPERM;\n\tif (!dir->i_op->link)\n\t\treturn -EPERM;\n\tif (S_ISDIR(inode->i_mode))\n\t\treturn -EPERM;\n\n\terror = security_inode_link(old_dentry, dir, new_dentry);\n\tif (error)\n\t\treturn error;\n\n\tinode_lock(inode);\n\t/* Make sure we don't allow creating hardlink to an unlinked file */\n\tif (inode->i_nlink == 0 && !(inode->i_state & I_LINKABLE))\n\t\terror =  -ENOENT;\n\telse if (max_links && inode->i_nlink >= max_links)\n\t\terror = -EMLINK;\n\telse {\n\t\terror = try_break_deleg(inode, delegated_inode);\n\t\tif (!error)\n\t\t\terror = dir->i_op->link(old_dentry, dir, new_dentry);\n\t}\n\n\tif (!error && (inode->i_state & I_LINKABLE)) {\n\t\tspin_lock(&inode->i_lock);\n\t\tinode->i_state &= ~I_LINKABLE;\n\t\tspin_unlock(&inode->i_lock);\n\t}\n\tinode_unlock(inode);\n\tif (!error)\n\t\tfsnotify_link(dir, inode, new_dentry);\n\treturn error;\n}\nEXPORT_SYMBOL(vfs_link);\n\n/*\n * Hardlinks are often used in delicate situations.  We avoid\n * security-related surprises by not following symlinks on the\n * newname.  --KAB\n *\n * We don't follow them on the oldname either to be compatible\n * with linux 2.0, and to avoid hard-linking to directories\n * and other special files.  --ADM\n */\nSYSCALL_DEFINE5(linkat, int, olddfd, const char __user *, oldname,\n\t\tint, newdfd, const char __user *, newname, int, flags)\n{\n\tstruct dentry *new_dentry;\n\tstruct path old_path, new_path;\n\tstruct inode *delegated_inode = NULL;\n\tint how = 0;\n\tint error;\n\n\tif ((flags & ~(AT_SYMLINK_FOLLOW | AT_EMPTY_PATH)) != 0)\n\t\treturn -EINVAL;\n\t/*\n\t * To use null names we require CAP_DAC_READ_SEARCH\n\t * This ensures that not everyone will be able to create\n\t * handlink using the passed filedescriptor.\n\t */\n\tif (flags & AT_EMPTY_PATH) {\n\t\tif (!capable(CAP_DAC_READ_SEARCH))\n\t\t\treturn -ENOENT;\n\t\thow = LOOKUP_EMPTY;\n\t}\n\n\tif (flags & AT_SYMLINK_FOLLOW)\n\t\thow |= LOOKUP_FOLLOW;\nretry:\n\terror = user_path_at(olddfd, oldname, how, &old_path);\n\tif (error)\n\t\treturn error;\n\n\tnew_dentry = user_path_create(newdfd, newname, &new_path,\n\t\t\t\t\t(how & LOOKUP_REVAL));\n\terror = PTR_ERR(new_dentry);\n\tif (IS_ERR(new_dentry))\n\t\tgoto out;\n\n\terror = -EXDEV;\n\tif (old_path.mnt != new_path.mnt)\n\t\tgoto out_dput;\n\terror = may_linkat(&old_path);\n\tif (unlikely(error))\n\t\tgoto out_dput;\n\terror = security_path_link(old_path.dentry, &new_path, new_dentry);\n\tif (error)\n\t\tgoto out_dput;\n\terror = vfs_link(old_path.dentry, new_path.dentry->d_inode, new_dentry, &delegated_inode);\nout_dput:\n\tdone_path_create(&new_path, new_dentry);\n\tif (delegated_inode) {\n\t\terror = break_deleg_wait(&delegated_inode);\n\t\tif (!error) {\n\t\t\tpath_put(&old_path);\n\t\t\tgoto retry;\n\t\t}\n\t}\n\tif (retry_estale(error, how)) {\n\t\tpath_put(&old_path);\n\t\thow |= LOOKUP_REVAL;\n\t\tgoto retry;\n\t}\nout:\n\tpath_put(&old_path);\n\n\treturn error;\n}\n\nSYSCALL_DEFINE2(link, const char __user *, oldname, const char __user *, newname)\n{\n\treturn sys_linkat(AT_FDCWD, oldname, AT_FDCWD, newname, 0);\n}\n\n/**\n * vfs_rename - rename a filesystem object\n * @old_dir:\tparent of source\n * @old_dentry:\tsource\n * @new_dir:\tparent of destination\n * @new_dentry:\tdestination\n * @delegated_inode: returns an inode needing a delegation break\n * @flags:\trename flags\n *\n * The caller must hold multiple mutexes--see lock_rename()).\n *\n * If vfs_rename discovers a delegation in need of breaking at either\n * the source or destination, it will return -EWOULDBLOCK and return a\n * reference to the inode in delegated_inode.  The caller should then\n * break the delegation and retry.  Because breaking a delegation may\n * take a long time, the caller should drop all locks before doing\n * so.\n *\n * Alternatively, a caller may pass NULL for delegated_inode.  This may\n * be appropriate for callers that expect the underlying filesystem not\n * to be NFS exported.\n *\n * The worst of all namespace operations - renaming directory. \"Perverted\"\n * doesn't even start to describe it. Somebody in UCB had a heck of a trip...\n * Problems:\n *\ta) we can get into loop creation.\n *\tb) race potential - two innocent renames can create a loop together.\n *\t   That's where 4.4 screws up. Current fix: serialization on\n *\t   sb->s_vfs_rename_mutex. We might be more accurate, but that's another\n *\t   story.\n *\tc) we have to lock _four_ objects - parents and victim (if it exists),\n *\t   and source (if it is not a directory).\n *\t   And that - after we got ->i_mutex on parents (until then we don't know\n *\t   whether the target exists).  Solution: try to be smart with locking\n *\t   order for inodes.  We rely on the fact that tree topology may change\n *\t   only under ->s_vfs_rename_mutex _and_ that parent of the object we\n *\t   move will be locked.  Thus we can rank directories by the tree\n *\t   (ancestors first) and rank all non-directories after them.\n *\t   That works since everybody except rename does \"lock parent, lookup,\n *\t   lock child\" and rename is under ->s_vfs_rename_mutex.\n *\t   HOWEVER, it relies on the assumption that any object with ->lookup()\n *\t   has no more than 1 dentry.  If \"hybrid\" objects will ever appear,\n *\t   we'd better make sure that there's no link(2) for them.\n *\td) conversion from fhandle to dentry may come in the wrong moment - when\n *\t   we are removing the target. Solution: we will have to grab ->i_mutex\n *\t   in the fhandle_to_dentry code. [FIXME - current nfsfh.c relies on\n *\t   ->i_mutex on parents, which works but leads to some truly excessive\n *\t   locking].\n */\nint vfs_rename(struct inode *old_dir, struct dentry *old_dentry,\n\t       struct inode *new_dir, struct dentry *new_dentry,\n\t       struct inode **delegated_inode, unsigned int flags)\n{\n\tint error;\n\tbool is_dir = d_is_dir(old_dentry);\n\tstruct inode *source = old_dentry->d_inode;\n\tstruct inode *target = new_dentry->d_inode;\n\tbool new_is_dir = false;\n\tunsigned max_links = new_dir->i_sb->s_max_links;\n\tstruct name_snapshot old_name;\n\n\tif (source == target)\n\t\treturn 0;\n\n\terror = may_delete(old_dir, old_dentry, is_dir);\n\tif (error)\n\t\treturn error;\n\n\tif (!target) {\n\t\terror = may_create(new_dir, new_dentry);\n\t} else {\n\t\tnew_is_dir = d_is_dir(new_dentry);\n\n\t\tif (!(flags & RENAME_EXCHANGE))\n\t\t\terror = may_delete(new_dir, new_dentry, is_dir);\n\t\telse\n\t\t\terror = may_delete(new_dir, new_dentry, new_is_dir);\n\t}\n\tif (error)\n\t\treturn error;\n\n\tif (!old_dir->i_op->rename)\n\t\treturn -EPERM;\n\n\t/*\n\t * If we are going to change the parent - check write permissions,\n\t * we'll need to flip '..'.\n\t */\n\tif (new_dir != old_dir) {\n\t\tif (is_dir) {\n\t\t\terror = inode_permission(source, MAY_WRITE);\n\t\t\tif (error)\n\t\t\t\treturn error;\n\t\t}\n\t\tif ((flags & RENAME_EXCHANGE) && new_is_dir) {\n\t\t\terror = inode_permission(target, MAY_WRITE);\n\t\t\tif (error)\n\t\t\t\treturn error;\n\t\t}\n\t}\n\n\terror = security_inode_rename(old_dir, old_dentry, new_dir, new_dentry,\n\t\t\t\t      flags);\n\tif (error)\n\t\treturn error;\n\n\ttake_dentry_name_snapshot(&old_name, old_dentry);\n\tdget(new_dentry);\n\tif (!is_dir || (flags & RENAME_EXCHANGE))\n\t\tlock_two_nondirectories(source, target);\n\telse if (target)\n\t\tinode_lock(target);\n\n\terror = -EBUSY;\n\tif (is_local_mountpoint(old_dentry) || is_local_mountpoint(new_dentry))\n\t\tgoto out;\n\n\tif (max_links && new_dir != old_dir) {\n\t\terror = -EMLINK;\n\t\tif (is_dir && !new_is_dir && new_dir->i_nlink >= max_links)\n\t\t\tgoto out;\n\t\tif ((flags & RENAME_EXCHANGE) && !is_dir && new_is_dir &&\n\t\t    old_dir->i_nlink >= max_links)\n\t\t\tgoto out;\n\t}\n\tif (is_dir && !(flags & RENAME_EXCHANGE) && target)\n\t\tshrink_dcache_parent(new_dentry);\n\tif (!is_dir) {\n\t\terror = try_break_deleg(source, delegated_inode);\n\t\tif (error)\n\t\t\tgoto out;\n\t}\n\tif (target && !new_is_dir) {\n\t\terror = try_break_deleg(target, delegated_inode);\n\t\tif (error)\n\t\t\tgoto out;\n\t}\n\terror = old_dir->i_op->rename(old_dir, old_dentry,\n\t\t\t\t       new_dir, new_dentry, flags);\n\tif (error)\n\t\tgoto out;\n\n\tif (!(flags & RENAME_EXCHANGE) && target) {\n\t\tif (is_dir)\n\t\t\ttarget->i_flags |= S_DEAD;\n\t\tdont_mount(new_dentry);\n\t\tdetach_mounts(new_dentry);\n\t}\n\tif (!(old_dir->i_sb->s_type->fs_flags & FS_RENAME_DOES_D_MOVE)) {\n\t\tif (!(flags & RENAME_EXCHANGE))\n\t\t\td_move(old_dentry, new_dentry);\n\t\telse\n\t\t\td_exchange(old_dentry, new_dentry);\n\t}\nout:\n\tif (!is_dir || (flags & RENAME_EXCHANGE))\n\t\tunlock_two_nondirectories(source, target);\n\telse if (target)\n\t\tinode_unlock(target);\n\tdput(new_dentry);\n\tif (!error) {\n\t\tfsnotify_move(old_dir, new_dir, old_name.name, is_dir,\n\t\t\t      !(flags & RENAME_EXCHANGE) ? target : NULL, old_dentry);\n\t\tif (flags & RENAME_EXCHANGE) {\n\t\t\tfsnotify_move(new_dir, old_dir, old_dentry->d_name.name,\n\t\t\t\t      new_is_dir, NULL, new_dentry);\n\t\t}\n\t}\n\trelease_dentry_name_snapshot(&old_name);\n\n\treturn error;\n}\nEXPORT_SYMBOL(vfs_rename);\n\nSYSCALL_DEFINE5(renameat2, int, olddfd, const char __user *, oldname,\n\t\tint, newdfd, const char __user *, newname, unsigned int, flags)\n{\n\tstruct dentry *old_dentry, *new_dentry;\n\tstruct dentry *trap;\n\tstruct path old_path, new_path;\n\tstruct qstr old_last, new_last;\n\tint old_type, new_type;\n\tstruct inode *delegated_inode = NULL;\n\tstruct filename *from;\n\tstruct filename *to;\n\tunsigned int lookup_flags = 0, target_flags = LOOKUP_RENAME_TARGET;\n\tbool should_retry = false;\n\tint error;\n\n\tif (flags & ~(RENAME_NOREPLACE | RENAME_EXCHANGE | RENAME_WHITEOUT))\n\t\treturn -EINVAL;\n\n\tif ((flags & (RENAME_NOREPLACE | RENAME_WHITEOUT)) &&\n\t    (flags & RENAME_EXCHANGE))\n\t\treturn -EINVAL;\n\n\tif ((flags & RENAME_WHITEOUT) && !capable(CAP_MKNOD))\n\t\treturn -EPERM;\n\n\tif (flags & RENAME_EXCHANGE)\n\t\ttarget_flags = 0;\n\nretry:\n\tfrom = filename_parentat(olddfd, getname(oldname), lookup_flags,\n\t\t\t\t&old_path, &old_last, &old_type);\n\tif (IS_ERR(from)) {\n\t\terror = PTR_ERR(from);\n\t\tgoto exit;\n\t}\n\n\tto = filename_parentat(newdfd, getname(newname), lookup_flags,\n\t\t\t\t&new_path, &new_last, &new_type);\n\tif (IS_ERR(to)) {\n\t\terror = PTR_ERR(to);\n\t\tgoto exit1;\n\t}\n\n\terror = -EXDEV;\n\tif (old_path.mnt != new_path.mnt)\n\t\tgoto exit2;\n\n\terror = -EBUSY;\n\tif (old_type != LAST_NORM)\n\t\tgoto exit2;\n\n\tif (flags & RENAME_NOREPLACE)\n\t\terror = -EEXIST;\n\tif (new_type != LAST_NORM)\n\t\tgoto exit2;\n\n\terror = mnt_want_write(old_path.mnt);\n\tif (error)\n\t\tgoto exit2;\n\nretry_deleg:\n\ttrap = lock_rename(new_path.dentry, old_path.dentry);\n\n\told_dentry = __lookup_hash(&old_last, old_path.dentry, lookup_flags);\n\terror = PTR_ERR(old_dentry);\n\tif (IS_ERR(old_dentry))\n\t\tgoto exit3;\n\t/* source must exist */\n\terror = -ENOENT;\n\tif (d_is_negative(old_dentry))\n\t\tgoto exit4;\n\tnew_dentry = __lookup_hash(&new_last, new_path.dentry, lookup_flags | target_flags);\n\terror = PTR_ERR(new_dentry);\n\tif (IS_ERR(new_dentry))\n\t\tgoto exit4;\n\terror = -EEXIST;\n\tif ((flags & RENAME_NOREPLACE) && d_is_positive(new_dentry))\n\t\tgoto exit5;\n\tif (flags & RENAME_EXCHANGE) {\n\t\terror = -ENOENT;\n\t\tif (d_is_negative(new_dentry))\n\t\t\tgoto exit5;\n\n\t\tif (!d_is_dir(new_dentry)) {\n\t\t\terror = -ENOTDIR;\n\t\t\tif (new_last.name[new_last.len])\n\t\t\t\tgoto exit5;\n\t\t}\n\t}\n\t/* unless the source is a directory trailing slashes give -ENOTDIR */\n\tif (!d_is_dir(old_dentry)) {\n\t\terror = -ENOTDIR;\n\t\tif (old_last.name[old_last.len])\n\t\t\tgoto exit5;\n\t\tif (!(flags & RENAME_EXCHANGE) && new_last.name[new_last.len])\n\t\t\tgoto exit5;\n\t}\n\t/* source should not be ancestor of target */\n\terror = -EINVAL;\n\tif (old_dentry == trap)\n\t\tgoto exit5;\n\t/* target should not be an ancestor of source */\n\tif (!(flags & RENAME_EXCHANGE))\n\t\terror = -ENOTEMPTY;\n\tif (new_dentry == trap)\n\t\tgoto exit5;\n\n\terror = security_path_rename(&old_path, old_dentry,\n\t\t\t\t     &new_path, new_dentry, flags);\n\tif (error)\n\t\tgoto exit5;\n\terror = vfs_rename(old_path.dentry->d_inode, old_dentry,\n\t\t\t   new_path.dentry->d_inode, new_dentry,\n\t\t\t   &delegated_inode, flags);\nexit5:\n\tdput(new_dentry);\nexit4:\n\tdput(old_dentry);\nexit3:\n\tunlock_rename(new_path.dentry, old_path.dentry);\n\tif (delegated_inode) {\n\t\terror = break_deleg_wait(&delegated_inode);\n\t\tif (!error)\n\t\t\tgoto retry_deleg;\n\t}\n\tmnt_drop_write(old_path.mnt);\nexit2:\n\tif (retry_estale(error, lookup_flags))\n\t\tshould_retry = true;\n\tpath_put(&new_path);\n\tputname(to);\nexit1:\n\tpath_put(&old_path);\n\tputname(from);\n\tif (should_retry) {\n\t\tshould_retry = false;\n\t\tlookup_flags |= LOOKUP_REVAL;\n\t\tgoto retry;\n\t}\nexit:\n\treturn error;\n}\n\nSYSCALL_DEFINE4(renameat, int, olddfd, const char __user *, oldname,\n\t\tint, newdfd, const char __user *, newname)\n{\n\treturn sys_renameat2(olddfd, oldname, newdfd, newname, 0);\n}\n\nSYSCALL_DEFINE2(rename, const char __user *, oldname, const char __user *, newname)\n{\n\treturn sys_renameat2(AT_FDCWD, oldname, AT_FDCWD, newname, 0);\n}\n\nint vfs_whiteout(struct inode *dir, struct dentry *dentry)\n{\n\tint error = may_create(dir, dentry);\n\tif (error)\n\t\treturn error;\n\n\tif (!dir->i_op->mknod)\n\t\treturn -EPERM;\n\n\treturn dir->i_op->mknod(dir, dentry,\n\t\t\t\tS_IFCHR | WHITEOUT_MODE, WHITEOUT_DEV);\n}\nEXPORT_SYMBOL(vfs_whiteout);\n\nint readlink_copy(char __user *buffer, int buflen, const char *link)\n{\n\tint len = PTR_ERR(link);\n\tif (IS_ERR(link))\n\t\tgoto out;\n\n\tlen = strlen(link);\n\tif (len > (unsigned) buflen)\n\t\tlen = buflen;\n\tif (copy_to_user(buffer, link, len))\n\t\tlen = -EFAULT;\nout:\n\treturn len;\n}\n\n/*\n * A helper for ->readlink().  This should be used *ONLY* for symlinks that\n * have ->get_link() not calling nd_jump_link().  Using (or not using) it\n * for any given inode is up to filesystem.\n */\nstatic int generic_readlink(struct dentry *dentry, char __user *buffer,\n\t\t\t    int buflen)\n{\n\tDEFINE_DELAYED_CALL(done);\n\tstruct inode *inode = d_inode(dentry);\n\tconst char *link = inode->i_link;\n\tint res;\n\n\tif (!link) {\n\t\tlink = inode->i_op->get_link(dentry, inode, &done);\n\t\tif (IS_ERR(link))\n\t\t\treturn PTR_ERR(link);\n\t}\n\tres = readlink_copy(buffer, buflen, link);\n\tdo_delayed_call(&done);\n\treturn res;\n}\n\n/**\n * vfs_readlink - copy symlink body into userspace buffer\n * @dentry: dentry on which to get symbolic link\n * @buffer: user memory pointer\n * @buflen: size of buffer\n *\n * Does not touch atime.  That's up to the caller if necessary\n *\n * Does not call security hook.\n */\nint vfs_readlink(struct dentry *dentry, char __user *buffer, int buflen)\n{\n\tstruct inode *inode = d_inode(dentry);\n\n\tif (unlikely(!(inode->i_opflags & IOP_DEFAULT_READLINK))) {\n\t\tif (unlikely(inode->i_op->readlink))\n\t\t\treturn inode->i_op->readlink(dentry, buffer, buflen);\n\n\t\tif (!d_is_symlink(dentry))\n\t\t\treturn -EINVAL;\n\n\t\tspin_lock(&inode->i_lock);\n\t\tinode->i_opflags |= IOP_DEFAULT_READLINK;\n\t\tspin_unlock(&inode->i_lock);\n\t}\n\n\treturn generic_readlink(dentry, buffer, buflen);\n}\nEXPORT_SYMBOL(vfs_readlink);\n\n/**\n * vfs_get_link - get symlink body\n * @dentry: dentry on which to get symbolic link\n * @done: caller needs to free returned data with this\n *\n * Calls security hook and i_op->get_link() on the supplied inode.\n *\n * It does not touch atime.  That's up to the caller if necessary.\n *\n * Does not work on \"special\" symlinks like /proc/$$/fd/N\n */\nconst char *vfs_get_link(struct dentry *dentry, struct delayed_call *done)\n{\n\tconst char *res = ERR_PTR(-EINVAL);\n\tstruct inode *inode = d_inode(dentry);\n\n\tif (d_is_symlink(dentry)) {\n\t\tres = ERR_PTR(security_inode_readlink(dentry));\n\t\tif (!res)\n\t\t\tres = inode->i_op->get_link(dentry, inode, done);\n\t}\n\treturn res;\n}\nEXPORT_SYMBOL(vfs_get_link);\n\n/* get the link contents into pagecache */\nconst char *page_get_link(struct dentry *dentry, struct inode *inode,\n\t\t\t  struct delayed_call *callback)\n{\n\tchar *kaddr;\n\tstruct page *page;\n\tstruct address_space *mapping = inode->i_mapping;\n\n\tif (!dentry) {\n\t\tpage = find_get_page(mapping, 0);\n\t\tif (!page)\n\t\t\treturn ERR_PTR(-ECHILD);\n\t\tif (!PageUptodate(page)) {\n\t\t\tput_page(page);\n\t\t\treturn ERR_PTR(-ECHILD);\n\t\t}\n\t} else {\n\t\tpage = read_mapping_page(mapping, 0, NULL);\n\t\tif (IS_ERR(page))\n\t\t\treturn (char*)page;\n\t}\n\tset_delayed_call(callback, page_put_link, page);\n\tBUG_ON(mapping_gfp_mask(mapping) & __GFP_HIGHMEM);\n\tkaddr = page_address(page);\n\tnd_terminate_link(kaddr, inode->i_size, PAGE_SIZE - 1);\n\treturn kaddr;\n}\n\nEXPORT_SYMBOL(page_get_link);\n\nvoid page_put_link(void *arg)\n{\n\tput_page(arg);\n}\nEXPORT_SYMBOL(page_put_link);\n\nint page_readlink(struct dentry *dentry, char __user *buffer, int buflen)\n{\n\tDEFINE_DELAYED_CALL(done);\n\tint res = readlink_copy(buffer, buflen,\n\t\t\t\tpage_get_link(dentry, d_inode(dentry),\n\t\t\t\t\t      &done));\n\tdo_delayed_call(&done);\n\treturn res;\n}\nEXPORT_SYMBOL(page_readlink);\n\n/*\n * The nofs argument instructs pagecache_write_begin to pass AOP_FLAG_NOFS\n */\nint __page_symlink(struct inode *inode, const char *symname, int len, int nofs)\n{\n\tstruct address_space *mapping = inode->i_mapping;\n\tstruct page *page;\n\tvoid *fsdata;\n\tint err;\n\tunsigned int flags = 0;\n\tif (nofs)\n\t\tflags |= AOP_FLAG_NOFS;\n\nretry:\n\terr = pagecache_write_begin(NULL, mapping, 0, len-1,\n\t\t\t\tflags, &page, &fsdata);\n\tif (err)\n\t\tgoto fail;\n\n\tmemcpy(page_address(page), symname, len-1);\n\n\terr = pagecache_write_end(NULL, mapping, 0, len-1, len-1,\n\t\t\t\t\t\t\tpage, fsdata);\n\tif (err < 0)\n\t\tgoto fail;\n\tif (err < len-1)\n\t\tgoto retry;\n\n\tmark_inode_dirty(inode);\n\treturn 0;\nfail:\n\treturn err;\n}\nEXPORT_SYMBOL(__page_symlink);\n\nint page_symlink(struct inode *inode, const char *symname, int len)\n{\n\treturn __page_symlink(inode, symname, len,\n\t\t\t!mapping_gfp_constraint(inode->i_mapping, __GFP_FS));\n}\nEXPORT_SYMBOL(page_symlink);\n\nconst struct inode_operations page_symlink_inode_operations = {\n\t.get_link\t= page_get_link,\n};\nEXPORT_SYMBOL(page_symlink_inode_operations);\n", "/*\n *  Copyright (C) 2008 Red Hat, Inc., Eric Paris <eparis@redhat.com>\n *\n *  This program is free software; you can redistribute it and/or modify\n *  it under the terms of the GNU General Public License as published by\n *  the Free Software Foundation; either version 2, or (at your option)\n *  any later version.\n *\n *  This program is distributed in the hope that it will be useful,\n *  but WITHOUT ANY WARRANTY; without even the implied warranty of\n *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n *  GNU General Public License for more details.\n *\n *  You should have received a copy of the GNU General Public License\n *  along with this program; see the file COPYING.  If not, write to\n *  the Free Software Foundation, 675 Mass Ave, Cambridge, MA 02139, USA.\n */\n\n#include <linux/dcache.h>\n#include <linux/fs.h>\n#include <linux/gfp.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mount.h>\n#include <linux/srcu.h>\n\n#include <linux/fsnotify_backend.h>\n#include \"fsnotify.h\"\n\n/*\n * Clear all of the marks on an inode when it is being evicted from core\n */\nvoid __fsnotify_inode_delete(struct inode *inode)\n{\n\tfsnotify_clear_marks_by_inode(inode);\n}\nEXPORT_SYMBOL_GPL(__fsnotify_inode_delete);\n\nvoid __fsnotify_vfsmount_delete(struct vfsmount *mnt)\n{\n\tfsnotify_clear_marks_by_mount(mnt);\n}\n\n/**\n * fsnotify_unmount_inodes - an sb is unmounting.  handle any watched inodes.\n * @sb: superblock being unmounted.\n *\n * Called during unmount with no locks held, so needs to be safe against\n * concurrent modifiers. We temporarily drop sb->s_inode_list_lock and CAN block.\n */\nvoid fsnotify_unmount_inodes(struct super_block *sb)\n{\n\tstruct inode *inode, *iput_inode = NULL;\n\n\tspin_lock(&sb->s_inode_list_lock);\n\tlist_for_each_entry(inode, &sb->s_inodes, i_sb_list) {\n\t\t/*\n\t\t * We cannot __iget() an inode in state I_FREEING,\n\t\t * I_WILL_FREE, or I_NEW which is fine because by that point\n\t\t * the inode cannot have any associated watches.\n\t\t */\n\t\tspin_lock(&inode->i_lock);\n\t\tif (inode->i_state & (I_FREEING|I_WILL_FREE|I_NEW)) {\n\t\t\tspin_unlock(&inode->i_lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/*\n\t\t * If i_count is zero, the inode cannot have any watches and\n\t\t * doing an __iget/iput with MS_ACTIVE clear would actually\n\t\t * evict all inodes with zero i_count from icache which is\n\t\t * unnecessarily violent and may in fact be illegal to do.\n\t\t */\n\t\tif (!atomic_read(&inode->i_count)) {\n\t\t\tspin_unlock(&inode->i_lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\t__iget(inode);\n\t\tspin_unlock(&inode->i_lock);\n\t\tspin_unlock(&sb->s_inode_list_lock);\n\n\t\tif (iput_inode)\n\t\t\tiput(iput_inode);\n\n\t\t/* for each watch, send FS_UNMOUNT and then remove it */\n\t\tfsnotify(inode, FS_UNMOUNT, inode, FSNOTIFY_EVENT_INODE, NULL, 0);\n\n\t\tfsnotify_inode_delete(inode);\n\n\t\tiput_inode = inode;\n\n\t\tspin_lock(&sb->s_inode_list_lock);\n\t}\n\tspin_unlock(&sb->s_inode_list_lock);\n\n\tif (iput_inode)\n\t\tiput(iput_inode);\n}\n\n/*\n * Given an inode, first check if we care what happens to our children.  Inotify\n * and dnotify both tell their parents about events.  If we care about any event\n * on a child we run all of our children and set a dentry flag saying that the\n * parent cares.  Thus when an event happens on a child it can quickly tell if\n * if there is a need to find a parent and send the event to the parent.\n */\nvoid __fsnotify_update_child_dentry_flags(struct inode *inode)\n{\n\tstruct dentry *alias;\n\tint watched;\n\n\tif (!S_ISDIR(inode->i_mode))\n\t\treturn;\n\n\t/* determine if the children should tell inode about their events */\n\twatched = fsnotify_inode_watches_children(inode);\n\n\tspin_lock(&inode->i_lock);\n\t/* run all of the dentries associated with this inode.  Since this is a\n\t * directory, there damn well better only be one item on this list */\n\thlist_for_each_entry(alias, &inode->i_dentry, d_u.d_alias) {\n\t\tstruct dentry *child;\n\n\t\t/* run all of the children of the original inode and fix their\n\t\t * d_flags to indicate parental interest (their parent is the\n\t\t * original inode) */\n\t\tspin_lock(&alias->d_lock);\n\t\tlist_for_each_entry(child, &alias->d_subdirs, d_child) {\n\t\t\tif (!child->d_inode)\n\t\t\t\tcontinue;\n\n\t\t\tspin_lock_nested(&child->d_lock, DENTRY_D_LOCK_NESTED);\n\t\t\tif (watched)\n\t\t\t\tchild->d_flags |= DCACHE_FSNOTIFY_PARENT_WATCHED;\n\t\t\telse\n\t\t\t\tchild->d_flags &= ~DCACHE_FSNOTIFY_PARENT_WATCHED;\n\t\t\tspin_unlock(&child->d_lock);\n\t\t}\n\t\tspin_unlock(&alias->d_lock);\n\t}\n\tspin_unlock(&inode->i_lock);\n}\n\n/* Notify this dentry's parent about a child's events. */\nint __fsnotify_parent(const struct path *path, struct dentry *dentry, __u32 mask)\n{\n\tstruct dentry *parent;\n\tstruct inode *p_inode;\n\tint ret = 0;\n\n\tif (!dentry)\n\t\tdentry = path->dentry;\n\n\tif (!(dentry->d_flags & DCACHE_FSNOTIFY_PARENT_WATCHED))\n\t\treturn 0;\n\n\tparent = dget_parent(dentry);\n\tp_inode = parent->d_inode;\n\n\tif (unlikely(!fsnotify_inode_watches_children(p_inode)))\n\t\t__fsnotify_update_child_dentry_flags(p_inode);\n\telse if (p_inode->i_fsnotify_mask & mask) {\n\t\tstruct name_snapshot name;\n\n\t\t/* we are notifying a parent so come up with the new mask which\n\t\t * specifies these are events which came from a child. */\n\t\tmask |= FS_EVENT_ON_CHILD;\n\n\t\ttake_dentry_name_snapshot(&name, dentry);\n\t\tif (path)\n\t\t\tret = fsnotify(p_inode, mask, path, FSNOTIFY_EVENT_PATH,\n\t\t\t\t       name.name, 0);\n\t\telse\n\t\t\tret = fsnotify(p_inode, mask, dentry->d_inode, FSNOTIFY_EVENT_INODE,\n\t\t\t\t       name.name, 0);\n\t\trelease_dentry_name_snapshot(&name);\n\t}\n\n\tdput(parent);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(__fsnotify_parent);\n\nstatic int send_to_group(struct inode *to_tell,\n\t\t\t struct fsnotify_mark *inode_mark,\n\t\t\t struct fsnotify_mark *vfsmount_mark,\n\t\t\t __u32 mask, const void *data,\n\t\t\t int data_is, u32 cookie,\n\t\t\t const unsigned char *file_name,\n\t\t\t struct fsnotify_iter_info *iter_info)\n{\n\tstruct fsnotify_group *group = NULL;\n\t__u32 inode_test_mask = 0;\n\t__u32 vfsmount_test_mask = 0;\n\n\tif (unlikely(!inode_mark && !vfsmount_mark)) {\n\t\tBUG();\n\t\treturn 0;\n\t}\n\n\t/* clear ignored on inode modification */\n\tif (mask & FS_MODIFY) {\n\t\tif (inode_mark &&\n\t\t    !(inode_mark->flags & FSNOTIFY_MARK_FLAG_IGNORED_SURV_MODIFY))\n\t\t\tinode_mark->ignored_mask = 0;\n\t\tif (vfsmount_mark &&\n\t\t    !(vfsmount_mark->flags & FSNOTIFY_MARK_FLAG_IGNORED_SURV_MODIFY))\n\t\t\tvfsmount_mark->ignored_mask = 0;\n\t}\n\n\t/* does the inode mark tell us to do something? */\n\tif (inode_mark) {\n\t\tgroup = inode_mark->group;\n\t\tinode_test_mask = (mask & ~FS_EVENT_ON_CHILD);\n\t\tinode_test_mask &= inode_mark->mask;\n\t\tinode_test_mask &= ~inode_mark->ignored_mask;\n\t}\n\n\t/* does the vfsmount_mark tell us to do something? */\n\tif (vfsmount_mark) {\n\t\tvfsmount_test_mask = (mask & ~FS_EVENT_ON_CHILD);\n\t\tgroup = vfsmount_mark->group;\n\t\tvfsmount_test_mask &= vfsmount_mark->mask;\n\t\tvfsmount_test_mask &= ~vfsmount_mark->ignored_mask;\n\t\tif (inode_mark)\n\t\t\tvfsmount_test_mask &= ~inode_mark->ignored_mask;\n\t}\n\n\tpr_debug(\"%s: group=%p to_tell=%p mask=%x inode_mark=%p\"\n\t\t \" inode_test_mask=%x vfsmount_mark=%p vfsmount_test_mask=%x\"\n\t\t \" data=%p data_is=%d cookie=%d\\n\",\n\t\t __func__, group, to_tell, mask, inode_mark,\n\t\t inode_test_mask, vfsmount_mark, vfsmount_test_mask, data,\n\t\t data_is, cookie);\n\n\tif (!inode_test_mask && !vfsmount_test_mask)\n\t\treturn 0;\n\n\treturn group->ops->handle_event(group, to_tell, inode_mark,\n\t\t\t\t\tvfsmount_mark, mask, data, data_is,\n\t\t\t\t\tfile_name, cookie, iter_info);\n}\n\n/*\n * This is the main call to fsnotify.  The VFS calls into hook specific functions\n * in linux/fsnotify.h.  Those functions then in turn call here.  Here will call\n * out to all of the registered fsnotify_group.  Those groups can then use the\n * notification event in whatever means they feel necessary.\n */\nint fsnotify(struct inode *to_tell, __u32 mask, const void *data, int data_is,\n\t     const unsigned char *file_name, u32 cookie)\n{\n\tstruct hlist_node *inode_node = NULL, *vfsmount_node = NULL;\n\tstruct fsnotify_mark *inode_mark = NULL, *vfsmount_mark = NULL;\n\tstruct fsnotify_group *inode_group, *vfsmount_group;\n\tstruct fsnotify_mark_connector *inode_conn, *vfsmount_conn;\n\tstruct fsnotify_iter_info iter_info;\n\tstruct mount *mnt;\n\tint ret = 0;\n\t/* global tests shouldn't care about events on child only the specific event */\n\t__u32 test_mask = (mask & ~FS_EVENT_ON_CHILD);\n\n\tif (data_is == FSNOTIFY_EVENT_PATH)\n\t\tmnt = real_mount(((const struct path *)data)->mnt);\n\telse\n\t\tmnt = NULL;\n\n\t/*\n\t * Optimization: srcu_read_lock() has a memory barrier which can\n\t * be expensive.  It protects walking the *_fsnotify_marks lists.\n\t * However, if we do not walk the lists, we do not have to do\n\t * SRCU because we have no references to any objects and do not\n\t * need SRCU to keep them \"alive\".\n\t */\n\tif (!to_tell->i_fsnotify_marks &&\n\t    (!mnt || !mnt->mnt_fsnotify_marks))\n\t\treturn 0;\n\t/*\n\t * if this is a modify event we may need to clear the ignored masks\n\t * otherwise return if neither the inode nor the vfsmount care about\n\t * this type of event.\n\t */\n\tif (!(mask & FS_MODIFY) &&\n\t    !(test_mask & to_tell->i_fsnotify_mask) &&\n\t    !(mnt && test_mask & mnt->mnt_fsnotify_mask))\n\t\treturn 0;\n\n\titer_info.srcu_idx = srcu_read_lock(&fsnotify_mark_srcu);\n\n\tif ((mask & FS_MODIFY) ||\n\t    (test_mask & to_tell->i_fsnotify_mask)) {\n\t\tinode_conn = srcu_dereference(to_tell->i_fsnotify_marks,\n\t\t\t\t\t      &fsnotify_mark_srcu);\n\t\tif (inode_conn)\n\t\t\tinode_node = srcu_dereference(inode_conn->list.first,\n\t\t\t\t\t\t      &fsnotify_mark_srcu);\n\t}\n\n\tif (mnt && ((mask & FS_MODIFY) ||\n\t\t    (test_mask & mnt->mnt_fsnotify_mask))) {\n\t\tinode_conn = srcu_dereference(to_tell->i_fsnotify_marks,\n\t\t\t\t\t      &fsnotify_mark_srcu);\n\t\tif (inode_conn)\n\t\t\tinode_node = srcu_dereference(inode_conn->list.first,\n\t\t\t\t\t\t      &fsnotify_mark_srcu);\n\t\tvfsmount_conn = srcu_dereference(mnt->mnt_fsnotify_marks,\n\t\t\t\t\t         &fsnotify_mark_srcu);\n\t\tif (vfsmount_conn)\n\t\t\tvfsmount_node = srcu_dereference(\n\t\t\t\t\t\tvfsmount_conn->list.first,\n\t\t\t\t\t\t&fsnotify_mark_srcu);\n\t}\n\n\t/*\n\t * We need to merge inode & vfsmount mark lists so that inode mark\n\t * ignore masks are properly reflected for mount mark notifications.\n\t * That's why this traversal is so complicated...\n\t */\n\twhile (inode_node || vfsmount_node) {\n\t\tinode_group = NULL;\n\t\tinode_mark = NULL;\n\t\tvfsmount_group = NULL;\n\t\tvfsmount_mark = NULL;\n\n\t\tif (inode_node) {\n\t\t\tinode_mark = hlist_entry(srcu_dereference(inode_node, &fsnotify_mark_srcu),\n\t\t\t\t\t\t struct fsnotify_mark, obj_list);\n\t\t\tinode_group = inode_mark->group;\n\t\t}\n\n\t\tif (vfsmount_node) {\n\t\t\tvfsmount_mark = hlist_entry(srcu_dereference(vfsmount_node, &fsnotify_mark_srcu),\n\t\t\t\t\t\t    struct fsnotify_mark, obj_list);\n\t\t\tvfsmount_group = vfsmount_mark->group;\n\t\t}\n\n\t\tif (inode_group && vfsmount_group) {\n\t\t\tint cmp = fsnotify_compare_groups(inode_group,\n\t\t\t\t\t\t\t  vfsmount_group);\n\t\t\tif (cmp > 0) {\n\t\t\t\tinode_group = NULL;\n\t\t\t\tinode_mark = NULL;\n\t\t\t} else if (cmp < 0) {\n\t\t\t\tvfsmount_group = NULL;\n\t\t\t\tvfsmount_mark = NULL;\n\t\t\t}\n\t\t}\n\n\t\titer_info.inode_mark = inode_mark;\n\t\titer_info.vfsmount_mark = vfsmount_mark;\n\n\t\tret = send_to_group(to_tell, inode_mark, vfsmount_mark, mask,\n\t\t\t\t    data, data_is, cookie, file_name,\n\t\t\t\t    &iter_info);\n\n\t\tif (ret && (mask & ALL_FSNOTIFY_PERM_EVENTS))\n\t\t\tgoto out;\n\n\t\tif (inode_group)\n\t\t\tinode_node = srcu_dereference(inode_node->next,\n\t\t\t\t\t\t      &fsnotify_mark_srcu);\n\t\tif (vfsmount_group)\n\t\t\tvfsmount_node = srcu_dereference(vfsmount_node->next,\n\t\t\t\t\t\t\t &fsnotify_mark_srcu);\n\t}\n\tret = 0;\nout:\n\tsrcu_read_unlock(&fsnotify_mark_srcu, iter_info.srcu_idx);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(fsnotify);\n\nextern struct kmem_cache *fsnotify_mark_connector_cachep;\n\nstatic __init int fsnotify_init(void)\n{\n\tint ret;\n\n\tBUG_ON(hweight32(ALL_FSNOTIFY_EVENTS) != 23);\n\n\tret = init_srcu_struct(&fsnotify_mark_srcu);\n\tif (ret)\n\t\tpanic(\"initializing fsnotify_mark_srcu\");\n\n\tfsnotify_mark_connector_cachep = KMEM_CACHE(fsnotify_mark_connector,\n\t\t\t\t\t\t    SLAB_PANIC);\n\n\treturn 0;\n}\ncore_initcall(fsnotify_init);\n", "#ifndef __LINUX_DCACHE_H\n#define __LINUX_DCACHE_H\n\n#include <linux/atomic.h>\n#include <linux/list.h>\n#include <linux/rculist.h>\n#include <linux/rculist_bl.h>\n#include <linux/spinlock.h>\n#include <linux/seqlock.h>\n#include <linux/cache.h>\n#include <linux/rcupdate.h>\n#include <linux/lockref.h>\n#include <linux/stringhash.h>\n#include <linux/wait.h>\n\nstruct path;\nstruct vfsmount;\n\n/*\n * linux/include/linux/dcache.h\n *\n * Dirent cache data structures\n *\n * (C) Copyright 1997 Thomas Schoebel-Theuer,\n * with heavy changes by Linus Torvalds\n */\n\n#define IS_ROOT(x) ((x) == (x)->d_parent)\n\n/* The hash is always the low bits of hash_len */\n#ifdef __LITTLE_ENDIAN\n #define HASH_LEN_DECLARE u32 hash; u32 len\n #define bytemask_from_count(cnt)\t(~(~0ul << (cnt)*8))\n#else\n #define HASH_LEN_DECLARE u32 len; u32 hash\n #define bytemask_from_count(cnt)\t(~(~0ul >> (cnt)*8))\n#endif\n\n/*\n * \"quick string\" -- eases parameter passing, but more importantly\n * saves \"metadata\" about the string (ie length and the hash).\n *\n * hash comes first so it snuggles against d_parent in the\n * dentry.\n */\nstruct qstr {\n\tunion {\n\t\tstruct {\n\t\t\tHASH_LEN_DECLARE;\n\t\t};\n\t\tu64 hash_len;\n\t};\n\tconst unsigned char *name;\n};\n\n#define QSTR_INIT(n,l) { { { .len = l } }, .name = n }\n\nstruct dentry_stat_t {\n\tlong nr_dentry;\n\tlong nr_unused;\n\tlong age_limit;          /* age in seconds */\n\tlong want_pages;         /* pages requested by system */\n\tlong dummy[2];\n};\nextern struct dentry_stat_t dentry_stat;\n\n/*\n * Try to keep struct dentry aligned on 64 byte cachelines (this will\n * give reasonable cacheline footprint with larger lines without the\n * large memory footprint increase).\n */\n#ifdef CONFIG_64BIT\n# define DNAME_INLINE_LEN 32 /* 192 bytes */\n#else\n# ifdef CONFIG_SMP\n#  define DNAME_INLINE_LEN 36 /* 128 bytes */\n# else\n#  define DNAME_INLINE_LEN 40 /* 128 bytes */\n# endif\n#endif\n\n#define d_lock\td_lockref.lock\n\nstruct dentry {\n\t/* RCU lookup touched fields */\n\tunsigned int d_flags;\t\t/* protected by d_lock */\n\tseqcount_t d_seq;\t\t/* per dentry seqlock */\n\tstruct hlist_bl_node d_hash;\t/* lookup hash list */\n\tstruct dentry *d_parent;\t/* parent directory */\n\tstruct qstr d_name;\n\tstruct inode *d_inode;\t\t/* Where the name belongs to - NULL is\n\t\t\t\t\t * negative */\n\tunsigned char d_iname[DNAME_INLINE_LEN];\t/* small names */\n\n\t/* Ref lookup also touches following */\n\tstruct lockref d_lockref;\t/* per-dentry lock and refcount */\n\tconst struct dentry_operations *d_op;\n\tstruct super_block *d_sb;\t/* The root of the dentry tree */\n\tunsigned long d_time;\t\t/* used by d_revalidate */\n\tvoid *d_fsdata;\t\t\t/* fs-specific data */\n\n\tunion {\n\t\tstruct list_head d_lru;\t\t/* LRU list */\n\t\twait_queue_head_t *d_wait;\t/* in-lookup ones only */\n\t};\n\tstruct list_head d_child;\t/* child of parent list */\n\tstruct list_head d_subdirs;\t/* our children */\n\t/*\n\t * d_alias and d_rcu can share memory\n\t */\n\tunion {\n\t\tstruct hlist_node d_alias;\t/* inode alias list */\n\t\tstruct hlist_bl_node d_in_lookup_hash;\t/* only for in-lookup ones */\n\t \tstruct rcu_head d_rcu;\n\t} d_u;\n};\n\n/*\n * dentry->d_lock spinlock nesting subclasses:\n *\n * 0: normal\n * 1: nested\n */\nenum dentry_d_lock_class\n{\n\tDENTRY_D_LOCK_NORMAL, /* implicitly used by plain spin_lock() APIs. */\n\tDENTRY_D_LOCK_NESTED\n};\n\nstruct dentry_operations {\n\tint (*d_revalidate)(struct dentry *, unsigned int);\n\tint (*d_weak_revalidate)(struct dentry *, unsigned int);\n\tint (*d_hash)(const struct dentry *, struct qstr *);\n\tint (*d_compare)(const struct dentry *,\n\t\t\tunsigned int, const char *, const struct qstr *);\n\tint (*d_delete)(const struct dentry *);\n\tint (*d_init)(struct dentry *);\n\tvoid (*d_release)(struct dentry *);\n\tvoid (*d_prune)(struct dentry *);\n\tvoid (*d_iput)(struct dentry *, struct inode *);\n\tchar *(*d_dname)(struct dentry *, char *, int);\n\tstruct vfsmount *(*d_automount)(struct path *);\n\tint (*d_manage)(const struct path *, bool);\n\tstruct dentry *(*d_real)(struct dentry *, const struct inode *,\n\t\t\t\t unsigned int);\n} ____cacheline_aligned;\n\n/*\n * Locking rules for dentry_operations callbacks are to be found in\n * Documentation/filesystems/Locking. Keep it updated!\n *\n * FUrther descriptions are found in Documentation/filesystems/vfs.txt.\n * Keep it updated too!\n */\n\n/* d_flags entries */\n#define DCACHE_OP_HASH\t\t\t0x00000001\n#define DCACHE_OP_COMPARE\t\t0x00000002\n#define DCACHE_OP_REVALIDATE\t\t0x00000004\n#define DCACHE_OP_DELETE\t\t0x00000008\n#define DCACHE_OP_PRUNE\t\t\t0x00000010\n\n#define\tDCACHE_DISCONNECTED\t\t0x00000020\n     /* This dentry is possibly not currently connected to the dcache tree, in\n      * which case its parent will either be itself, or will have this flag as\n      * well.  nfsd will not use a dentry with this bit set, but will first\n      * endeavour to clear the bit either by discovering that it is connected,\n      * or by performing lookup operations.   Any filesystem which supports\n      * nfsd_operations MUST have a lookup function which, if it finds a\n      * directory inode with a DCACHE_DISCONNECTED dentry, will d_move that\n      * dentry into place and return that dentry rather than the passed one,\n      * typically using d_splice_alias. */\n\n#define DCACHE_REFERENCED\t\t0x00000040 /* Recently used, don't discard. */\n#define DCACHE_RCUACCESS\t\t0x00000080 /* Entry has ever been RCU-visible */\n\n#define DCACHE_CANT_MOUNT\t\t0x00000100\n#define DCACHE_GENOCIDE\t\t\t0x00000200\n#define DCACHE_SHRINK_LIST\t\t0x00000400\n\n#define DCACHE_OP_WEAK_REVALIDATE\t0x00000800\n\n#define DCACHE_NFSFS_RENAMED\t\t0x00001000\n     /* this dentry has been \"silly renamed\" and has to be deleted on the last\n      * dput() */\n#define DCACHE_COOKIE\t\t\t0x00002000 /* For use by dcookie subsystem */\n#define DCACHE_FSNOTIFY_PARENT_WATCHED\t0x00004000\n     /* Parent inode is watched by some fsnotify listener */\n\n#define DCACHE_DENTRY_KILLED\t\t0x00008000\n\n#define DCACHE_MOUNTED\t\t\t0x00010000 /* is a mountpoint */\n#define DCACHE_NEED_AUTOMOUNT\t\t0x00020000 /* handle automount on this dir */\n#define DCACHE_MANAGE_TRANSIT\t\t0x00040000 /* manage transit from this dirent */\n#define DCACHE_MANAGED_DENTRY \\\n\t(DCACHE_MOUNTED|DCACHE_NEED_AUTOMOUNT|DCACHE_MANAGE_TRANSIT)\n\n#define DCACHE_LRU_LIST\t\t\t0x00080000\n\n#define DCACHE_ENTRY_TYPE\t\t0x00700000\n#define DCACHE_MISS_TYPE\t\t0x00000000 /* Negative dentry (maybe fallthru to nowhere) */\n#define DCACHE_WHITEOUT_TYPE\t\t0x00100000 /* Whiteout dentry (stop pathwalk) */\n#define DCACHE_DIRECTORY_TYPE\t\t0x00200000 /* Normal directory */\n#define DCACHE_AUTODIR_TYPE\t\t0x00300000 /* Lookupless directory (presumed automount) */\n#define DCACHE_REGULAR_TYPE\t\t0x00400000 /* Regular file type (or fallthru to such) */\n#define DCACHE_SPECIAL_TYPE\t\t0x00500000 /* Other file type (or fallthru to such) */\n#define DCACHE_SYMLINK_TYPE\t\t0x00600000 /* Symlink (or fallthru to such) */\n\n#define DCACHE_MAY_FREE\t\t\t0x00800000\n#define DCACHE_FALLTHRU\t\t\t0x01000000 /* Fall through to lower layer */\n#define DCACHE_ENCRYPTED_WITH_KEY\t0x02000000 /* dir is encrypted with a valid key */\n#define DCACHE_OP_REAL\t\t\t0x04000000\n\n#define DCACHE_PAR_LOOKUP\t\t0x10000000 /* being looked up (with parent locked shared) */\n#define DCACHE_DENTRY_CURSOR\t\t0x20000000\n\nextern seqlock_t rename_lock;\n\n/*\n * These are the low-level FS interfaces to the dcache..\n */\nextern void d_instantiate(struct dentry *, struct inode *);\nextern struct dentry * d_instantiate_unique(struct dentry *, struct inode *);\nextern int d_instantiate_no_diralias(struct dentry *, struct inode *);\nextern void __d_drop(struct dentry *dentry);\nextern void d_drop(struct dentry *dentry);\nextern void d_delete(struct dentry *);\nextern void d_set_d_op(struct dentry *dentry, const struct dentry_operations *op);\n\n/* allocate/de-allocate */\nextern struct dentry * d_alloc(struct dentry *, const struct qstr *);\nextern struct dentry * d_alloc_pseudo(struct super_block *, const struct qstr *);\nextern struct dentry * d_alloc_parallel(struct dentry *, const struct qstr *,\n\t\t\t\t\twait_queue_head_t *);\nextern struct dentry * d_splice_alias(struct inode *, struct dentry *);\nextern struct dentry * d_add_ci(struct dentry *, struct inode *, struct qstr *);\nextern struct dentry * d_exact_alias(struct dentry *, struct inode *);\nextern struct dentry *d_find_any_alias(struct inode *inode);\nextern struct dentry * d_obtain_alias(struct inode *);\nextern struct dentry * d_obtain_root(struct inode *);\nextern void shrink_dcache_sb(struct super_block *);\nextern void shrink_dcache_parent(struct dentry *);\nextern void shrink_dcache_for_umount(struct super_block *);\nextern void d_invalidate(struct dentry *);\n\n/* only used at mount-time */\nextern struct dentry * d_make_root(struct inode *);\n\n/* <clickety>-<click> the ramfs-type tree */\nextern void d_genocide(struct dentry *);\n\nextern void d_tmpfile(struct dentry *, struct inode *);\n\nextern struct dentry *d_find_alias(struct inode *);\nextern void d_prune_aliases(struct inode *);\n\n/* test whether we have any submounts in a subdir tree */\nextern int path_has_submounts(const struct path *);\n\n/*\n * This adds the entry to the hash queues.\n */\nextern void d_rehash(struct dentry *);\n \nextern void d_add(struct dentry *, struct inode *);\n\nextern void dentry_update_name_case(struct dentry *, const struct qstr *);\n\n/* used for rename() and baskets */\nextern void d_move(struct dentry *, struct dentry *);\nextern void d_exchange(struct dentry *, struct dentry *);\nextern struct dentry *d_ancestor(struct dentry *, struct dentry *);\n\n/* appendix may either be NULL or be used for transname suffixes */\nextern struct dentry *d_lookup(const struct dentry *, const struct qstr *);\nextern struct dentry *d_hash_and_lookup(struct dentry *, struct qstr *);\nextern struct dentry *__d_lookup(const struct dentry *, const struct qstr *);\nextern struct dentry *__d_lookup_rcu(const struct dentry *parent,\n\t\t\t\tconst struct qstr *name, unsigned *seq);\n\nstatic inline unsigned d_count(const struct dentry *dentry)\n{\n\treturn dentry->d_lockref.count;\n}\n\n/*\n * helper function for dentry_operations.d_dname() members\n */\nextern __printf(4, 5)\nchar *dynamic_dname(struct dentry *, char *, int, const char *, ...);\nextern char *simple_dname(struct dentry *, char *, int);\n\nextern char *__d_path(const struct path *, const struct path *, char *, int);\nextern char *d_absolute_path(const struct path *, char *, int);\nextern char *d_path(const struct path *, char *, int);\nextern char *dentry_path_raw(struct dentry *, char *, int);\nextern char *dentry_path(struct dentry *, char *, int);\n\n/* Allocation counts.. */\n\n/**\n *\tdget, dget_dlock -\tget a reference to a dentry\n *\t@dentry: dentry to get a reference to\n *\n *\tGiven a dentry or %NULL pointer increment the reference count\n *\tif appropriate and return the dentry. A dentry will not be \n *\tdestroyed when it has references.\n */\nstatic inline struct dentry *dget_dlock(struct dentry *dentry)\n{\n\tif (dentry)\n\t\tdentry->d_lockref.count++;\n\treturn dentry;\n}\n\nstatic inline struct dentry *dget(struct dentry *dentry)\n{\n\tif (dentry)\n\t\tlockref_get(&dentry->d_lockref);\n\treturn dentry;\n}\n\nextern struct dentry *dget_parent(struct dentry *dentry);\n\n/**\n *\td_unhashed -\tis dentry hashed\n *\t@dentry: entry to check\n *\n *\tReturns true if the dentry passed is not currently hashed.\n */\n \nstatic inline int d_unhashed(const struct dentry *dentry)\n{\n\treturn hlist_bl_unhashed(&dentry->d_hash);\n}\n\nstatic inline int d_unlinked(const struct dentry *dentry)\n{\n\treturn d_unhashed(dentry) && !IS_ROOT(dentry);\n}\n\nstatic inline int cant_mount(const struct dentry *dentry)\n{\n\treturn (dentry->d_flags & DCACHE_CANT_MOUNT);\n}\n\nstatic inline void dont_mount(struct dentry *dentry)\n{\n\tspin_lock(&dentry->d_lock);\n\tdentry->d_flags |= DCACHE_CANT_MOUNT;\n\tspin_unlock(&dentry->d_lock);\n}\n\nextern void __d_lookup_done(struct dentry *);\n\nstatic inline int d_in_lookup(struct dentry *dentry)\n{\n\treturn dentry->d_flags & DCACHE_PAR_LOOKUP;\n}\n\nstatic inline void d_lookup_done(struct dentry *dentry)\n{\n\tif (unlikely(d_in_lookup(dentry))) {\n\t\tspin_lock(&dentry->d_lock);\n\t\t__d_lookup_done(dentry);\n\t\tspin_unlock(&dentry->d_lock);\n\t}\n}\n\nextern void dput(struct dentry *);\n\nstatic inline bool d_managed(const struct dentry *dentry)\n{\n\treturn dentry->d_flags & DCACHE_MANAGED_DENTRY;\n}\n\nstatic inline bool d_mountpoint(const struct dentry *dentry)\n{\n\treturn dentry->d_flags & DCACHE_MOUNTED;\n}\n\n/*\n * Directory cache entry type accessor functions.\n */\nstatic inline unsigned __d_entry_type(const struct dentry *dentry)\n{\n\treturn dentry->d_flags & DCACHE_ENTRY_TYPE;\n}\n\nstatic inline bool d_is_miss(const struct dentry *dentry)\n{\n\treturn __d_entry_type(dentry) == DCACHE_MISS_TYPE;\n}\n\nstatic inline bool d_is_whiteout(const struct dentry *dentry)\n{\n\treturn __d_entry_type(dentry) == DCACHE_WHITEOUT_TYPE;\n}\n\nstatic inline bool d_can_lookup(const struct dentry *dentry)\n{\n\treturn __d_entry_type(dentry) == DCACHE_DIRECTORY_TYPE;\n}\n\nstatic inline bool d_is_autodir(const struct dentry *dentry)\n{\n\treturn __d_entry_type(dentry) == DCACHE_AUTODIR_TYPE;\n}\n\nstatic inline bool d_is_dir(const struct dentry *dentry)\n{\n\treturn d_can_lookup(dentry) || d_is_autodir(dentry);\n}\n\nstatic inline bool d_is_symlink(const struct dentry *dentry)\n{\n\treturn __d_entry_type(dentry) == DCACHE_SYMLINK_TYPE;\n}\n\nstatic inline bool d_is_reg(const struct dentry *dentry)\n{\n\treturn __d_entry_type(dentry) == DCACHE_REGULAR_TYPE;\n}\n\nstatic inline bool d_is_special(const struct dentry *dentry)\n{\n\treturn __d_entry_type(dentry) == DCACHE_SPECIAL_TYPE;\n}\n\nstatic inline bool d_is_file(const struct dentry *dentry)\n{\n\treturn d_is_reg(dentry) || d_is_special(dentry);\n}\n\nstatic inline bool d_is_negative(const struct dentry *dentry)\n{\n\t// TODO: check d_is_whiteout(dentry) also.\n\treturn d_is_miss(dentry);\n}\n\nstatic inline bool d_is_positive(const struct dentry *dentry)\n{\n\treturn !d_is_negative(dentry);\n}\n\n/**\n * d_really_is_negative - Determine if a dentry is really negative (ignoring fallthroughs)\n * @dentry: The dentry in question\n *\n * Returns true if the dentry represents either an absent name or a name that\n * doesn't map to an inode (ie. ->d_inode is NULL).  The dentry could represent\n * a true miss, a whiteout that isn't represented by a 0,0 chardev or a\n * fallthrough marker in an opaque directory.\n *\n * Note!  (1) This should be used *only* by a filesystem to examine its own\n * dentries.  It should not be used to look at some other filesystem's\n * dentries.  (2) It should also be used in combination with d_inode() to get\n * the inode.  (3) The dentry may have something attached to ->d_lower and the\n * type field of the flags may be set to something other than miss or whiteout.\n */\nstatic inline bool d_really_is_negative(const struct dentry *dentry)\n{\n\treturn dentry->d_inode == NULL;\n}\n\n/**\n * d_really_is_positive - Determine if a dentry is really positive (ignoring fallthroughs)\n * @dentry: The dentry in question\n *\n * Returns true if the dentry represents a name that maps to an inode\n * (ie. ->d_inode is not NULL).  The dentry might still represent a whiteout if\n * that is represented on medium as a 0,0 chardev.\n *\n * Note!  (1) This should be used *only* by a filesystem to examine its own\n * dentries.  It should not be used to look at some other filesystem's\n * dentries.  (2) It should also be used in combination with d_inode() to get\n * the inode.\n */\nstatic inline bool d_really_is_positive(const struct dentry *dentry)\n{\n\treturn dentry->d_inode != NULL;\n}\n\nstatic inline int simple_positive(struct dentry *dentry)\n{\n\treturn d_really_is_positive(dentry) && !d_unhashed(dentry);\n}\n\nextern void d_set_fallthru(struct dentry *dentry);\n\nstatic inline bool d_is_fallthru(const struct dentry *dentry)\n{\n\treturn dentry->d_flags & DCACHE_FALLTHRU;\n}\n\n\nextern int sysctl_vfs_cache_pressure;\n\nstatic inline unsigned long vfs_pressure_ratio(unsigned long val)\n{\n\treturn mult_frac(val, sysctl_vfs_cache_pressure, 100);\n}\n\n/**\n * d_inode - Get the actual inode of this dentry\n * @dentry: The dentry to query\n *\n * This is the helper normal filesystems should use to get at their own inodes\n * in their own dentries and ignore the layering superimposed upon them.\n */\nstatic inline struct inode *d_inode(const struct dentry *dentry)\n{\n\treturn dentry->d_inode;\n}\n\n/**\n * d_inode_rcu - Get the actual inode of this dentry with ACCESS_ONCE()\n * @dentry: The dentry to query\n *\n * This is the helper normal filesystems should use to get at their own inodes\n * in their own dentries and ignore the layering superimposed upon them.\n */\nstatic inline struct inode *d_inode_rcu(const struct dentry *dentry)\n{\n\treturn ACCESS_ONCE(dentry->d_inode);\n}\n\n/**\n * d_backing_inode - Get upper or lower inode we should be using\n * @upper: The upper layer\n *\n * This is the helper that should be used to get at the inode that will be used\n * if this dentry were to be opened as a file.  The inode may be on the upper\n * dentry or it may be on a lower dentry pinned by the upper.\n *\n * Normal filesystems should not use this to access their own inodes.\n */\nstatic inline struct inode *d_backing_inode(const struct dentry *upper)\n{\n\tstruct inode *inode = upper->d_inode;\n\n\treturn inode;\n}\n\n/**\n * d_backing_dentry - Get upper or lower dentry we should be using\n * @upper: The upper layer\n *\n * This is the helper that should be used to get the dentry of the inode that\n * will be used if this dentry were opened as a file.  It may be the upper\n * dentry or it may be a lower dentry pinned by the upper.\n *\n * Normal filesystems should not use this to access their own dentries.\n */\nstatic inline struct dentry *d_backing_dentry(struct dentry *upper)\n{\n\treturn upper;\n}\n\n/**\n * d_real - Return the real dentry\n * @dentry: the dentry to query\n * @inode: inode to select the dentry from multiple layers (can be NULL)\n * @flags: open flags to control copy-up behavior\n *\n * If dentry is on a union/overlay, then return the underlying, real dentry.\n * Otherwise return the dentry itself.\n *\n * See also: Documentation/filesystems/vfs.txt\n */\nstatic inline struct dentry *d_real(struct dentry *dentry,\n\t\t\t\t    const struct inode *inode,\n\t\t\t\t    unsigned int flags)\n{\n\tif (unlikely(dentry->d_flags & DCACHE_OP_REAL))\n\t\treturn dentry->d_op->d_real(dentry, inode, flags);\n\telse\n\t\treturn dentry;\n}\n\n/**\n * d_real_inode - Return the real inode\n * @dentry: The dentry to query\n *\n * If dentry is on a union/overlay, then return the underlying, real inode.\n * Otherwise return d_inode().\n */\nstatic inline struct inode *d_real_inode(const struct dentry *dentry)\n{\n\t/* This usage of d_real() results in const dentry */\n\treturn d_backing_inode(d_real((struct dentry *) dentry, NULL, 0));\n}\n\nstruct name_snapshot {\n\tconst char *name;\n\tchar inline_name[DNAME_INLINE_LEN];\n};\nvoid take_dentry_name_snapshot(struct name_snapshot *, struct dentry *);\nvoid release_dentry_name_snapshot(struct name_snapshot *);\n\n#endif\t/* __LINUX_DCACHE_H */\n", "#ifndef _LINUX_FS_NOTIFY_H\n#define _LINUX_FS_NOTIFY_H\n\n/*\n * include/linux/fsnotify.h - generic hooks for filesystem notification, to\n * reduce in-source duplication from both dnotify and inotify.\n *\n * We don't compile any of this away in some complicated menagerie of ifdefs.\n * Instead, we rely on the code inside to optimize away as needed.\n *\n * (C) Copyright 2005 Robert Love\n */\n\n#include <linux/fsnotify_backend.h>\n#include <linux/audit.h>\n#include <linux/slab.h>\n#include <linux/bug.h>\n\n/* Notify this dentry's parent about a child's events. */\nstatic inline int fsnotify_parent(const struct path *path, struct dentry *dentry, __u32 mask)\n{\n\tif (!dentry)\n\t\tdentry = path->dentry;\n\n\treturn __fsnotify_parent(path, dentry, mask);\n}\n\n/* simple call site for access decisions */\nstatic inline int fsnotify_perm(struct file *file, int mask)\n{\n\tconst struct path *path = &file->f_path;\n\t/*\n\t * Do not use file_inode() here or anywhere in this file to get the\n\t * inode.  That would break *notity on overlayfs.\n\t */\n\tstruct inode *inode = path->dentry->d_inode;\n\t__u32 fsnotify_mask = 0;\n\tint ret;\n\n\tif (file->f_mode & FMODE_NONOTIFY)\n\t\treturn 0;\n\tif (!(mask & (MAY_READ | MAY_OPEN)))\n\t\treturn 0;\n\tif (mask & MAY_OPEN)\n\t\tfsnotify_mask = FS_OPEN_PERM;\n\telse if (mask & MAY_READ)\n\t\tfsnotify_mask = FS_ACCESS_PERM;\n\telse\n\t\tBUG();\n\n\tret = fsnotify_parent(path, NULL, fsnotify_mask);\n\tif (ret)\n\t\treturn ret;\n\n\treturn fsnotify(inode, fsnotify_mask, path, FSNOTIFY_EVENT_PATH, NULL, 0);\n}\n\n/*\n * fsnotify_link_count - inode's link count changed\n */\nstatic inline void fsnotify_link_count(struct inode *inode)\n{\n\tfsnotify(inode, FS_ATTRIB, inode, FSNOTIFY_EVENT_INODE, NULL, 0);\n}\n\n/*\n * fsnotify_move - file old_name at old_dir was moved to new_name at new_dir\n */\nstatic inline void fsnotify_move(struct inode *old_dir, struct inode *new_dir,\n\t\t\t\t const unsigned char *old_name,\n\t\t\t\t int isdir, struct inode *target, struct dentry *moved)\n{\n\tstruct inode *source = moved->d_inode;\n\tu32 fs_cookie = fsnotify_get_cookie();\n\t__u32 old_dir_mask = (FS_EVENT_ON_CHILD | FS_MOVED_FROM);\n\t__u32 new_dir_mask = (FS_EVENT_ON_CHILD | FS_MOVED_TO);\n\tconst unsigned char *new_name = moved->d_name.name;\n\n\tif (old_dir == new_dir)\n\t\told_dir_mask |= FS_DN_RENAME;\n\n\tif (isdir) {\n\t\told_dir_mask |= FS_ISDIR;\n\t\tnew_dir_mask |= FS_ISDIR;\n\t}\n\n\tfsnotify(old_dir, old_dir_mask, source, FSNOTIFY_EVENT_INODE, old_name,\n\t\t fs_cookie);\n\tfsnotify(new_dir, new_dir_mask, source, FSNOTIFY_EVENT_INODE, new_name,\n\t\t fs_cookie);\n\n\tif (target)\n\t\tfsnotify_link_count(target);\n\n\tif (source)\n\t\tfsnotify(source, FS_MOVE_SELF, moved->d_inode, FSNOTIFY_EVENT_INODE, NULL, 0);\n\taudit_inode_child(new_dir, moved, AUDIT_TYPE_CHILD_CREATE);\n}\n\n/*\n * fsnotify_inode_delete - and inode is being evicted from cache, clean up is needed\n */\nstatic inline void fsnotify_inode_delete(struct inode *inode)\n{\n\t__fsnotify_inode_delete(inode);\n}\n\n/*\n * fsnotify_vfsmount_delete - a vfsmount is being destroyed, clean up is needed\n */\nstatic inline void fsnotify_vfsmount_delete(struct vfsmount *mnt)\n{\n\t__fsnotify_vfsmount_delete(mnt);\n}\n\n/*\n * fsnotify_nameremove - a filename was removed from a directory\n */\nstatic inline void fsnotify_nameremove(struct dentry *dentry, int isdir)\n{\n\t__u32 mask = FS_DELETE;\n\n\tif (isdir)\n\t\tmask |= FS_ISDIR;\n\n\tfsnotify_parent(NULL, dentry, mask);\n}\n\n/*\n * fsnotify_inoderemove - an inode is going away\n */\nstatic inline void fsnotify_inoderemove(struct inode *inode)\n{\n\tfsnotify(inode, FS_DELETE_SELF, inode, FSNOTIFY_EVENT_INODE, NULL, 0);\n\t__fsnotify_inode_delete(inode);\n}\n\n/*\n * fsnotify_create - 'name' was linked in\n */\nstatic inline void fsnotify_create(struct inode *inode, struct dentry *dentry)\n{\n\taudit_inode_child(inode, dentry, AUDIT_TYPE_CHILD_CREATE);\n\n\tfsnotify(inode, FS_CREATE, dentry->d_inode, FSNOTIFY_EVENT_INODE, dentry->d_name.name, 0);\n}\n\n/*\n * fsnotify_link - new hardlink in 'inode' directory\n * Note: We have to pass also the linked inode ptr as some filesystems leave\n *   new_dentry->d_inode NULL and instantiate inode pointer later\n */\nstatic inline void fsnotify_link(struct inode *dir, struct inode *inode, struct dentry *new_dentry)\n{\n\tfsnotify_link_count(inode);\n\taudit_inode_child(dir, new_dentry, AUDIT_TYPE_CHILD_CREATE);\n\n\tfsnotify(dir, FS_CREATE, inode, FSNOTIFY_EVENT_INODE, new_dentry->d_name.name, 0);\n}\n\n/*\n * fsnotify_mkdir - directory 'name' was created\n */\nstatic inline void fsnotify_mkdir(struct inode *inode, struct dentry *dentry)\n{\n\t__u32 mask = (FS_CREATE | FS_ISDIR);\n\tstruct inode *d_inode = dentry->d_inode;\n\n\taudit_inode_child(inode, dentry, AUDIT_TYPE_CHILD_CREATE);\n\n\tfsnotify(inode, mask, d_inode, FSNOTIFY_EVENT_INODE, dentry->d_name.name, 0);\n}\n\n/*\n * fsnotify_access - file was read\n */\nstatic inline void fsnotify_access(struct file *file)\n{\n\tconst struct path *path = &file->f_path;\n\tstruct inode *inode = path->dentry->d_inode;\n\t__u32 mask = FS_ACCESS;\n\n\tif (S_ISDIR(inode->i_mode))\n\t\tmask |= FS_ISDIR;\n\n\tif (!(file->f_mode & FMODE_NONOTIFY)) {\n\t\tfsnotify_parent(path, NULL, mask);\n\t\tfsnotify(inode, mask, path, FSNOTIFY_EVENT_PATH, NULL, 0);\n\t}\n}\n\n/*\n * fsnotify_modify - file was modified\n */\nstatic inline void fsnotify_modify(struct file *file)\n{\n\tconst struct path *path = &file->f_path;\n\tstruct inode *inode = path->dentry->d_inode;\n\t__u32 mask = FS_MODIFY;\n\n\tif (S_ISDIR(inode->i_mode))\n\t\tmask |= FS_ISDIR;\n\n\tif (!(file->f_mode & FMODE_NONOTIFY)) {\n\t\tfsnotify_parent(path, NULL, mask);\n\t\tfsnotify(inode, mask, path, FSNOTIFY_EVENT_PATH, NULL, 0);\n\t}\n}\n\n/*\n * fsnotify_open - file was opened\n */\nstatic inline void fsnotify_open(struct file *file)\n{\n\tconst struct path *path = &file->f_path;\n\tstruct inode *inode = path->dentry->d_inode;\n\t__u32 mask = FS_OPEN;\n\n\tif (S_ISDIR(inode->i_mode))\n\t\tmask |= FS_ISDIR;\n\n\tfsnotify_parent(path, NULL, mask);\n\tfsnotify(inode, mask, path, FSNOTIFY_EVENT_PATH, NULL, 0);\n}\n\n/*\n * fsnotify_close - file was closed\n */\nstatic inline void fsnotify_close(struct file *file)\n{\n\tconst struct path *path = &file->f_path;\n\tstruct inode *inode = path->dentry->d_inode;\n\tfmode_t mode = file->f_mode;\n\t__u32 mask = (mode & FMODE_WRITE) ? FS_CLOSE_WRITE : FS_CLOSE_NOWRITE;\n\n\tif (S_ISDIR(inode->i_mode))\n\t\tmask |= FS_ISDIR;\n\n\tif (!(file->f_mode & FMODE_NONOTIFY)) {\n\t\tfsnotify_parent(path, NULL, mask);\n\t\tfsnotify(inode, mask, path, FSNOTIFY_EVENT_PATH, NULL, 0);\n\t}\n}\n\n/*\n * fsnotify_xattr - extended attributes were changed\n */\nstatic inline void fsnotify_xattr(struct dentry *dentry)\n{\n\tstruct inode *inode = dentry->d_inode;\n\t__u32 mask = FS_ATTRIB;\n\n\tif (S_ISDIR(inode->i_mode))\n\t\tmask |= FS_ISDIR;\n\n\tfsnotify_parent(NULL, dentry, mask);\n\tfsnotify(inode, mask, inode, FSNOTIFY_EVENT_INODE, NULL, 0);\n}\n\n/*\n * fsnotify_change - notify_change event.  file was modified and/or metadata\n * was changed.\n */\nstatic inline void fsnotify_change(struct dentry *dentry, unsigned int ia_valid)\n{\n\tstruct inode *inode = dentry->d_inode;\n\t__u32 mask = 0;\n\n\tif (ia_valid & ATTR_UID)\n\t\tmask |= FS_ATTRIB;\n\tif (ia_valid & ATTR_GID)\n\t\tmask |= FS_ATTRIB;\n\tif (ia_valid & ATTR_SIZE)\n\t\tmask |= FS_MODIFY;\n\n\t/* both times implies a utime(s) call */\n\tif ((ia_valid & (ATTR_ATIME | ATTR_MTIME)) == (ATTR_ATIME | ATTR_MTIME))\n\t\tmask |= FS_ATTRIB;\n\telse if (ia_valid & ATTR_ATIME)\n\t\tmask |= FS_ACCESS;\n\telse if (ia_valid & ATTR_MTIME)\n\t\tmask |= FS_MODIFY;\n\n\tif (ia_valid & ATTR_MODE)\n\t\tmask |= FS_ATTRIB;\n\n\tif (mask) {\n\t\tif (S_ISDIR(inode->i_mode))\n\t\t\tmask |= FS_ISDIR;\n\n\t\tfsnotify_parent(NULL, dentry, mask);\n\t\tfsnotify(inode, mask, inode, FSNOTIFY_EVENT_INODE, NULL, 0);\n\t}\n}\n\n#endif\t/* _LINUX_FS_NOTIFY_H */\n"], "filenames": ["fs/dcache.c", "fs/debugfs/inode.c", "fs/namei.c", "fs/notify/fsnotify.c", "include/linux/dcache.h", "include/linux/fsnotify.h"], "buggy_code_start_loc": [278, 769, 4365, 163, 593, 296], "buggy_code_end_loc": [278, 797, 4479, 174, 593, 327], "fixing_code_start_loc": [279, 769, 4364, 164, 594, 295], "fixing_code_end_loc": [306, 797, 4479, 178, 600, 295], "type": "CWE-362", "message": "Race condition in the fsnotify implementation in the Linux kernel through 4.12.4 allows local users to gain privileges or cause a denial of service (memory corruption) via a crafted application that leverages simultaneous execution of the inotify_handle_event and vfs_rename functions.", "other": {"cve": {"id": "CVE-2017-7533", "sourceIdentifier": "secalert@redhat.com", "published": "2017-08-05T16:29:00.180", "lastModified": "2023-02-12T23:30:19.347", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "Race condition in the fsnotify implementation in the Linux kernel through 4.12.4 allows local users to gain privileges or cause a denial of service (memory corruption) via a crafted application that leverages simultaneous execution of the inotify_handle_event and vfs_rename functions."}, {"lang": "es", "value": "Una condici\u00f3n de carrera en la implementaci\u00f3n de fsnotify en el kernel de Linux hasta la versi\u00f3n 4.12.4, permite a los usuarios locales alcanzar privilegios o causar una denegaci\u00f3n de servicio (corrupci\u00f3n de memoria) por medio de una aplicaci\u00f3n creada que aprovecha la ejecuci\u00f3n simult\u00e1nea de las funciones inotify_handle_event y vfs_rename."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:L/AC:H/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.0, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.0, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:M/Au:N/C:C/I:C/A:C", "accessVector": "LOCAL", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "COMPLETE", "integrityImpact": "COMPLETE", "availabilityImpact": "COMPLETE", "baseScore": 6.9}, "baseSeverity": "MEDIUM", "exploitabilityScore": 3.4, "impactScore": 10.0, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-362"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndIncluding": "4.12.4", "matchCriteriaId": "F295C5A4-6970-4A20-A0AA-12DFBAF500BE"}]}]}], "references": [{"url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=49d31c2f389acfe83417083e1208422b4091cd9e", "source": "secalert@redhat.com", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "http://openwall.com/lists/oss-security/2017/08/03/2", "source": "secalert@redhat.com", "tags": ["Mailing List", "Patch", "Third Party Advisory"]}, {"url": "http://www.debian.org/security/2017/dsa-3927", "source": "secalert@redhat.com"}, {"url": "http://www.debian.org/security/2017/dsa-3945", "source": "secalert@redhat.com"}, {"url": "http://www.openwall.com/lists/oss-security/2019/06/27/7", "source": "secalert@redhat.com"}, {"url": "http://www.openwall.com/lists/oss-security/2019/06/28/1", "source": "secalert@redhat.com"}, {"url": "http://www.openwall.com/lists/oss-security/2019/06/28/2", "source": "secalert@redhat.com"}, {"url": "http://www.securityfocus.com/bid/100123", "source": "secalert@redhat.com", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "http://www.securitytracker.com/id/1039075", "source": "secalert@redhat.com", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://access.redhat.com/errata/RHSA-2017:2473", "source": "secalert@redhat.com"}, {"url": "https://access.redhat.com/errata/RHSA-2017:2585", "source": "secalert@redhat.com"}, {"url": "https://access.redhat.com/errata/RHSA-2017:2669", "source": "secalert@redhat.com"}, {"url": "https://access.redhat.com/errata/RHSA-2017:2770", "source": "secalert@redhat.com"}, {"url": "https://access.redhat.com/errata/RHSA-2017:2869", "source": "secalert@redhat.com"}, {"url": "https://bugzilla.redhat.com/show_bug.cgi?id=1468283", "source": "secalert@redhat.com", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/49d31c2f389acfe83417083e1208422b4091cd9e", "source": "secalert@redhat.com", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://patchwork.kernel.org/patch/9755753/", "source": "secalert@redhat.com", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://patchwork.kernel.org/patch/9755757/", "source": "secalert@redhat.com", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://source.android.com/security/bulletin/2017-12-01", "source": "secalert@redhat.com"}, {"url": "https://www.mail-archive.com/linux-kernel%40vger.kernel.org/msg1408967.html", "source": "secalert@redhat.com"}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/49d31c2f389acfe83417083e1208422b4091cd9e"}}
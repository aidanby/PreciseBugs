{"buggy_code": ["\n#include <linux/ceph/ceph_debug.h>\n\n#include <linux/err.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n#include <crypto/aes.h>\n#include <crypto/skcipher.h>\n#include <linux/key-type.h>\n\n#include <keys/ceph-type.h>\n#include <keys/user-type.h>\n#include <linux/ceph/decode.h>\n#include \"crypto.h\"\n\nint ceph_crypto_key_clone(struct ceph_crypto_key *dst,\n\t\t\t  const struct ceph_crypto_key *src)\n{\n\tmemcpy(dst, src, sizeof(struct ceph_crypto_key));\n\tdst->key = kmemdup(src->key, src->len, GFP_NOFS);\n\tif (!dst->key)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nint ceph_crypto_key_encode(struct ceph_crypto_key *key, void **p, void *end)\n{\n\tif (*p + sizeof(u16) + sizeof(key->created) +\n\t    sizeof(u16) + key->len > end)\n\t\treturn -ERANGE;\n\tceph_encode_16(p, key->type);\n\tceph_encode_copy(p, &key->created, sizeof(key->created));\n\tceph_encode_16(p, key->len);\n\tceph_encode_copy(p, key->key, key->len);\n\treturn 0;\n}\n\nint ceph_crypto_key_decode(struct ceph_crypto_key *key, void **p, void *end)\n{\n\tceph_decode_need(p, end, 2*sizeof(u16) + sizeof(key->created), bad);\n\tkey->type = ceph_decode_16(p);\n\tceph_decode_copy(p, &key->created, sizeof(key->created));\n\tkey->len = ceph_decode_16(p);\n\tceph_decode_need(p, end, key->len, bad);\n\tkey->key = kmalloc(key->len, GFP_NOFS);\n\tif (!key->key)\n\t\treturn -ENOMEM;\n\tceph_decode_copy(p, key->key, key->len);\n\treturn 0;\n\nbad:\n\tdout(\"failed to decode crypto key\\n\");\n\treturn -EINVAL;\n}\n\nint ceph_crypto_key_unarmor(struct ceph_crypto_key *key, const char *inkey)\n{\n\tint inlen = strlen(inkey);\n\tint blen = inlen * 3 / 4;\n\tvoid *buf, *p;\n\tint ret;\n\n\tdout(\"crypto_key_unarmor %s\\n\", inkey);\n\tbuf = kmalloc(blen, GFP_NOFS);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\tblen = ceph_unarmor(buf, inkey, inkey+inlen);\n\tif (blen < 0) {\n\t\tkfree(buf);\n\t\treturn blen;\n\t}\n\n\tp = buf;\n\tret = ceph_crypto_key_decode(key, &p, p + blen);\n\tkfree(buf);\n\tif (ret)\n\t\treturn ret;\n\tdout(\"crypto_key_unarmor key %p type %d len %d\\n\", key,\n\t     key->type, key->len);\n\treturn 0;\n}\n\nstatic struct crypto_skcipher *ceph_crypto_alloc_cipher(void)\n{\n\treturn crypto_alloc_skcipher(\"cbc(aes)\", 0, CRYPTO_ALG_ASYNC);\n}\n\nstatic const u8 *aes_iv = (u8 *)CEPH_AES_IV;\n\n/*\n * Should be used for buffers allocated with ceph_kvmalloc().\n * Currently these are encrypt out-buffer (ceph_buffer) and decrypt\n * in-buffer (msg front).\n *\n * Dispose of @sgt with teardown_sgtable().\n *\n * @prealloc_sg is to avoid memory allocation inside sg_alloc_table()\n * in cases where a single sg is sufficient.  No attempt to reduce the\n * number of sgs by squeezing physically contiguous pages together is\n * made though, for simplicity.\n */\nstatic int setup_sgtable(struct sg_table *sgt, struct scatterlist *prealloc_sg,\n\t\t\t const void *buf, unsigned int buf_len)\n{\n\tstruct scatterlist *sg;\n\tconst bool is_vmalloc = is_vmalloc_addr(buf);\n\tunsigned int off = offset_in_page(buf);\n\tunsigned int chunk_cnt = 1;\n\tunsigned int chunk_len = PAGE_ALIGN(off + buf_len);\n\tint i;\n\tint ret;\n\n\tif (buf_len == 0) {\n\t\tmemset(sgt, 0, sizeof(*sgt));\n\t\treturn -EINVAL;\n\t}\n\n\tif (is_vmalloc) {\n\t\tchunk_cnt = chunk_len >> PAGE_SHIFT;\n\t\tchunk_len = PAGE_SIZE;\n\t}\n\n\tif (chunk_cnt > 1) {\n\t\tret = sg_alloc_table(sgt, chunk_cnt, GFP_NOFS);\n\t\tif (ret)\n\t\t\treturn ret;\n\t} else {\n\t\tWARN_ON(chunk_cnt != 1);\n\t\tsg_init_table(prealloc_sg, 1);\n\t\tsgt->sgl = prealloc_sg;\n\t\tsgt->nents = sgt->orig_nents = 1;\n\t}\n\n\tfor_each_sg(sgt->sgl, sg, sgt->orig_nents, i) {\n\t\tstruct page *page;\n\t\tunsigned int len = min(chunk_len - off, buf_len);\n\n\t\tif (is_vmalloc)\n\t\t\tpage = vmalloc_to_page(buf);\n\t\telse\n\t\t\tpage = virt_to_page(buf);\n\n\t\tsg_set_page(sg, page, len, off);\n\n\t\toff = 0;\n\t\tbuf += len;\n\t\tbuf_len -= len;\n\t}\n\tWARN_ON(buf_len != 0);\n\n\treturn 0;\n}\n\nstatic void teardown_sgtable(struct sg_table *sgt)\n{\n\tif (sgt->orig_nents > 1)\n\t\tsg_free_table(sgt);\n}\n\nstatic int ceph_aes_encrypt(const void *key, int key_len,\n\t\t\t    void *dst, size_t *dst_len,\n\t\t\t    const void *src, size_t src_len)\n{\n\tstruct scatterlist sg_in[2], prealloc_sg;\n\tstruct sg_table sg_out;\n\tstruct crypto_skcipher *tfm = ceph_crypto_alloc_cipher();\n\tSKCIPHER_REQUEST_ON_STACK(req, tfm);\n\tint ret;\n\tchar iv[AES_BLOCK_SIZE];\n\tsize_t zero_padding = (0x10 - (src_len & 0x0f));\n\tchar pad[16];\n\n\tif (IS_ERR(tfm))\n\t\treturn PTR_ERR(tfm);\n\n\tmemset(pad, zero_padding, zero_padding);\n\n\t*dst_len = src_len + zero_padding;\n\n\tsg_init_table(sg_in, 2);\n\tsg_set_buf(&sg_in[0], src, src_len);\n\tsg_set_buf(&sg_in[1], pad, zero_padding);\n\tret = setup_sgtable(&sg_out, &prealloc_sg, dst, *dst_len);\n\tif (ret)\n\t\tgoto out_tfm;\n\n\tcrypto_skcipher_setkey((void *)tfm, key, key_len);\n\tmemcpy(iv, aes_iv, AES_BLOCK_SIZE);\n\n\tskcipher_request_set_tfm(req, tfm);\n\tskcipher_request_set_callback(req, 0, NULL, NULL);\n\tskcipher_request_set_crypt(req, sg_in, sg_out.sgl,\n\t\t\t\t   src_len + zero_padding, iv);\n\n\t/*\n\tprint_hex_dump(KERN_ERR, \"enc key: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       key, key_len, 1);\n\tprint_hex_dump(KERN_ERR, \"enc src: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t\tsrc, src_len, 1);\n\tprint_hex_dump(KERN_ERR, \"enc pad: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t\tpad, zero_padding, 1);\n\t*/\n\tret = crypto_skcipher_encrypt(req);\n\tskcipher_request_zero(req);\n\tif (ret < 0) {\n\t\tpr_err(\"ceph_aes_crypt failed %d\\n\", ret);\n\t\tgoto out_sg;\n\t}\n\t/*\n\tprint_hex_dump(KERN_ERR, \"enc out: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       dst, *dst_len, 1);\n\t*/\n\nout_sg:\n\tteardown_sgtable(&sg_out);\nout_tfm:\n\tcrypto_free_skcipher(tfm);\n\treturn ret;\n}\n\nstatic int ceph_aes_encrypt2(const void *key, int key_len, void *dst,\n\t\t\t     size_t *dst_len,\n\t\t\t     const void *src1, size_t src1_len,\n\t\t\t     const void *src2, size_t src2_len)\n{\n\tstruct scatterlist sg_in[3], prealloc_sg;\n\tstruct sg_table sg_out;\n\tstruct crypto_skcipher *tfm = ceph_crypto_alloc_cipher();\n\tSKCIPHER_REQUEST_ON_STACK(req, tfm);\n\tint ret;\n\tchar iv[AES_BLOCK_SIZE];\n\tsize_t zero_padding = (0x10 - ((src1_len + src2_len) & 0x0f));\n\tchar pad[16];\n\n\tif (IS_ERR(tfm))\n\t\treturn PTR_ERR(tfm);\n\n\tmemset(pad, zero_padding, zero_padding);\n\n\t*dst_len = src1_len + src2_len + zero_padding;\n\n\tsg_init_table(sg_in, 3);\n\tsg_set_buf(&sg_in[0], src1, src1_len);\n\tsg_set_buf(&sg_in[1], src2, src2_len);\n\tsg_set_buf(&sg_in[2], pad, zero_padding);\n\tret = setup_sgtable(&sg_out, &prealloc_sg, dst, *dst_len);\n\tif (ret)\n\t\tgoto out_tfm;\n\n\tcrypto_skcipher_setkey((void *)tfm, key, key_len);\n\tmemcpy(iv, aes_iv, AES_BLOCK_SIZE);\n\n\tskcipher_request_set_tfm(req, tfm);\n\tskcipher_request_set_callback(req, 0, NULL, NULL);\n\tskcipher_request_set_crypt(req, sg_in, sg_out.sgl,\n\t\t\t\t   src1_len + src2_len + zero_padding, iv);\n\n\t/*\n\tprint_hex_dump(KERN_ERR, \"enc  key: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       key, key_len, 1);\n\tprint_hex_dump(KERN_ERR, \"enc src1: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t\tsrc1, src1_len, 1);\n\tprint_hex_dump(KERN_ERR, \"enc src2: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t\tsrc2, src2_len, 1);\n\tprint_hex_dump(KERN_ERR, \"enc  pad: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t\tpad, zero_padding, 1);\n\t*/\n\tret = crypto_skcipher_encrypt(req);\n\tskcipher_request_zero(req);\n\tif (ret < 0) {\n\t\tpr_err(\"ceph_aes_crypt2 failed %d\\n\", ret);\n\t\tgoto out_sg;\n\t}\n\t/*\n\tprint_hex_dump(KERN_ERR, \"enc  out: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       dst, *dst_len, 1);\n\t*/\n\nout_sg:\n\tteardown_sgtable(&sg_out);\nout_tfm:\n\tcrypto_free_skcipher(tfm);\n\treturn ret;\n}\n\nstatic int ceph_aes_decrypt(const void *key, int key_len,\n\t\t\t    void *dst, size_t *dst_len,\n\t\t\t    const void *src, size_t src_len)\n{\n\tstruct sg_table sg_in;\n\tstruct scatterlist sg_out[2], prealloc_sg;\n\tstruct crypto_skcipher *tfm = ceph_crypto_alloc_cipher();\n\tSKCIPHER_REQUEST_ON_STACK(req, tfm);\n\tchar pad[16];\n\tchar iv[AES_BLOCK_SIZE];\n\tint ret;\n\tint last_byte;\n\n\tif (IS_ERR(tfm))\n\t\treturn PTR_ERR(tfm);\n\n\tsg_init_table(sg_out, 2);\n\tsg_set_buf(&sg_out[0], dst, *dst_len);\n\tsg_set_buf(&sg_out[1], pad, sizeof(pad));\n\tret = setup_sgtable(&sg_in, &prealloc_sg, src, src_len);\n\tif (ret)\n\t\tgoto out_tfm;\n\n\tcrypto_skcipher_setkey((void *)tfm, key, key_len);\n\tmemcpy(iv, aes_iv, AES_BLOCK_SIZE);\n\n\tskcipher_request_set_tfm(req, tfm);\n\tskcipher_request_set_callback(req, 0, NULL, NULL);\n\tskcipher_request_set_crypt(req, sg_in.sgl, sg_out,\n\t\t\t\t   src_len, iv);\n\n\t/*\n\tprint_hex_dump(KERN_ERR, \"dec key: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       key, key_len, 1);\n\tprint_hex_dump(KERN_ERR, \"dec  in: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       src, src_len, 1);\n\t*/\n\tret = crypto_skcipher_decrypt(req);\n\tskcipher_request_zero(req);\n\tif (ret < 0) {\n\t\tpr_err(\"ceph_aes_decrypt failed %d\\n\", ret);\n\t\tgoto out_sg;\n\t}\n\n\tif (src_len <= *dst_len)\n\t\tlast_byte = ((char *)dst)[src_len - 1];\n\telse\n\t\tlast_byte = pad[src_len - *dst_len - 1];\n\tif (last_byte <= 16 && src_len >= last_byte) {\n\t\t*dst_len = src_len - last_byte;\n\t} else {\n\t\tpr_err(\"ceph_aes_decrypt got bad padding %d on src len %d\\n\",\n\t\t       last_byte, (int)src_len);\n\t\treturn -EPERM;  /* bad padding */\n\t}\n\t/*\n\tprint_hex_dump(KERN_ERR, \"dec out: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       dst, *dst_len, 1);\n\t*/\n\nout_sg:\n\tteardown_sgtable(&sg_in);\nout_tfm:\n\tcrypto_free_skcipher(tfm);\n\treturn ret;\n}\n\nstatic int ceph_aes_decrypt2(const void *key, int key_len,\n\t\t\t     void *dst1, size_t *dst1_len,\n\t\t\t     void *dst2, size_t *dst2_len,\n\t\t\t     const void *src, size_t src_len)\n{\n\tstruct sg_table sg_in;\n\tstruct scatterlist sg_out[3], prealloc_sg;\n\tstruct crypto_skcipher *tfm = ceph_crypto_alloc_cipher();\n\tSKCIPHER_REQUEST_ON_STACK(req, tfm);\n\tchar pad[16];\n\tchar iv[AES_BLOCK_SIZE];\n\tint ret;\n\tint last_byte;\n\n\tif (IS_ERR(tfm))\n\t\treturn PTR_ERR(tfm);\n\n\tsg_init_table(sg_out, 3);\n\tsg_set_buf(&sg_out[0], dst1, *dst1_len);\n\tsg_set_buf(&sg_out[1], dst2, *dst2_len);\n\tsg_set_buf(&sg_out[2], pad, sizeof(pad));\n\tret = setup_sgtable(&sg_in, &prealloc_sg, src, src_len);\n\tif (ret)\n\t\tgoto out_tfm;\n\n\tcrypto_skcipher_setkey((void *)tfm, key, key_len);\n\tmemcpy(iv, aes_iv, AES_BLOCK_SIZE);\n\n\tskcipher_request_set_tfm(req, tfm);\n\tskcipher_request_set_callback(req, 0, NULL, NULL);\n\tskcipher_request_set_crypt(req, sg_in.sgl, sg_out,\n\t\t\t\t   src_len, iv);\n\n\t/*\n\tprint_hex_dump(KERN_ERR, \"dec  key: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       key, key_len, 1);\n\tprint_hex_dump(KERN_ERR, \"dec   in: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       src, src_len, 1);\n\t*/\n\tret = crypto_skcipher_decrypt(req);\n\tskcipher_request_zero(req);\n\tif (ret < 0) {\n\t\tpr_err(\"ceph_aes_decrypt failed %d\\n\", ret);\n\t\tgoto out_sg;\n\t}\n\n\tif (src_len <= *dst1_len)\n\t\tlast_byte = ((char *)dst1)[src_len - 1];\n\telse if (src_len <= *dst1_len + *dst2_len)\n\t\tlast_byte = ((char *)dst2)[src_len - *dst1_len - 1];\n\telse\n\t\tlast_byte = pad[src_len - *dst1_len - *dst2_len - 1];\n\tif (last_byte <= 16 && src_len >= last_byte) {\n\t\tsrc_len -= last_byte;\n\t} else {\n\t\tpr_err(\"ceph_aes_decrypt got bad padding %d on src len %d\\n\",\n\t\t       last_byte, (int)src_len);\n\t\treturn -EPERM;  /* bad padding */\n\t}\n\n\tif (src_len < *dst1_len) {\n\t\t*dst1_len = src_len;\n\t\t*dst2_len = 0;\n\t} else {\n\t\t*dst2_len = src_len - *dst1_len;\n\t}\n\t/*\n\tprint_hex_dump(KERN_ERR, \"dec  out1: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       dst1, *dst1_len, 1);\n\tprint_hex_dump(KERN_ERR, \"dec  out2: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       dst2, *dst2_len, 1);\n\t*/\n\nout_sg:\n\tteardown_sgtable(&sg_in);\nout_tfm:\n\tcrypto_free_skcipher(tfm);\n\treturn ret;\n}\n\n\nint ceph_decrypt(struct ceph_crypto_key *secret, void *dst, size_t *dst_len,\n\t\t const void *src, size_t src_len)\n{\n\tswitch (secret->type) {\n\tcase CEPH_CRYPTO_NONE:\n\t\tif (*dst_len < src_len)\n\t\t\treturn -ERANGE;\n\t\tmemcpy(dst, src, src_len);\n\t\t*dst_len = src_len;\n\t\treturn 0;\n\n\tcase CEPH_CRYPTO_AES:\n\t\treturn ceph_aes_decrypt(secret->key, secret->len, dst,\n\t\t\t\t\tdst_len, src, src_len);\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nint ceph_decrypt2(struct ceph_crypto_key *secret,\n\t\t\tvoid *dst1, size_t *dst1_len,\n\t\t\tvoid *dst2, size_t *dst2_len,\n\t\t\tconst void *src, size_t src_len)\n{\n\tsize_t t;\n\n\tswitch (secret->type) {\n\tcase CEPH_CRYPTO_NONE:\n\t\tif (*dst1_len + *dst2_len < src_len)\n\t\t\treturn -ERANGE;\n\t\tt = min(*dst1_len, src_len);\n\t\tmemcpy(dst1, src, t);\n\t\t*dst1_len = t;\n\t\tsrc += t;\n\t\tsrc_len -= t;\n\t\tif (src_len) {\n\t\t\tt = min(*dst2_len, src_len);\n\t\t\tmemcpy(dst2, src, t);\n\t\t\t*dst2_len = t;\n\t\t}\n\t\treturn 0;\n\n\tcase CEPH_CRYPTO_AES:\n\t\treturn ceph_aes_decrypt2(secret->key, secret->len,\n\t\t\t\t\t dst1, dst1_len, dst2, dst2_len,\n\t\t\t\t\t src, src_len);\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nint ceph_encrypt(struct ceph_crypto_key *secret, void *dst, size_t *dst_len,\n\t\t const void *src, size_t src_len)\n{\n\tswitch (secret->type) {\n\tcase CEPH_CRYPTO_NONE:\n\t\tif (*dst_len < src_len)\n\t\t\treturn -ERANGE;\n\t\tmemcpy(dst, src, src_len);\n\t\t*dst_len = src_len;\n\t\treturn 0;\n\n\tcase CEPH_CRYPTO_AES:\n\t\treturn ceph_aes_encrypt(secret->key, secret->len, dst,\n\t\t\t\t\tdst_len, src, src_len);\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nint ceph_encrypt2(struct ceph_crypto_key *secret, void *dst, size_t *dst_len,\n\t\t  const void *src1, size_t src1_len,\n\t\t  const void *src2, size_t src2_len)\n{\n\tswitch (secret->type) {\n\tcase CEPH_CRYPTO_NONE:\n\t\tif (*dst_len < src1_len + src2_len)\n\t\t\treturn -ERANGE;\n\t\tmemcpy(dst, src1, src1_len);\n\t\tmemcpy(dst + src1_len, src2, src2_len);\n\t\t*dst_len = src1_len + src2_len;\n\t\treturn 0;\n\n\tcase CEPH_CRYPTO_AES:\n\t\treturn ceph_aes_encrypt2(secret->key, secret->len, dst, dst_len,\n\t\t\t\t\t src1, src1_len, src2, src2_len);\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic int ceph_key_preparse(struct key_preparsed_payload *prep)\n{\n\tstruct ceph_crypto_key *ckey;\n\tsize_t datalen = prep->datalen;\n\tint ret;\n\tvoid *p;\n\n\tret = -EINVAL;\n\tif (datalen <= 0 || datalen > 32767 || !prep->data)\n\t\tgoto err;\n\n\tret = -ENOMEM;\n\tckey = kmalloc(sizeof(*ckey), GFP_KERNEL);\n\tif (!ckey)\n\t\tgoto err;\n\n\t/* TODO ceph_crypto_key_decode should really take const input */\n\tp = (void *)prep->data;\n\tret = ceph_crypto_key_decode(ckey, &p, (char*)prep->data+datalen);\n\tif (ret < 0)\n\t\tgoto err_ckey;\n\n\tprep->payload.data[0] = ckey;\n\tprep->quotalen = datalen;\n\treturn 0;\n\nerr_ckey:\n\tkfree(ckey);\nerr:\n\treturn ret;\n}\n\nstatic void ceph_key_free_preparse(struct key_preparsed_payload *prep)\n{\n\tstruct ceph_crypto_key *ckey = prep->payload.data[0];\n\tceph_crypto_key_destroy(ckey);\n\tkfree(ckey);\n}\n\nstatic void ceph_key_destroy(struct key *key)\n{\n\tstruct ceph_crypto_key *ckey = key->payload.data[0];\n\n\tceph_crypto_key_destroy(ckey);\n\tkfree(ckey);\n}\n\nstruct key_type key_type_ceph = {\n\t.name\t\t= \"ceph\",\n\t.preparse\t= ceph_key_preparse,\n\t.free_preparse\t= ceph_key_free_preparse,\n\t.instantiate\t= generic_key_instantiate,\n\t.destroy\t= ceph_key_destroy,\n};\n\nint ceph_crypto_init(void) {\n\treturn register_key_type(&key_type_ceph);\n}\n\nvoid ceph_crypto_shutdown(void) {\n\tunregister_key_type(&key_type_ceph);\n}\n", "#ifndef _FS_CEPH_CRYPTO_H\n#define _FS_CEPH_CRYPTO_H\n\n#include <linux/ceph/types.h>\n#include <linux/ceph/buffer.h>\n\n/*\n * cryptographic secret\n */\nstruct ceph_crypto_key {\n\tint type;\n\tstruct ceph_timespec created;\n\tint len;\n\tvoid *key;\n};\n\nstatic inline void ceph_crypto_key_destroy(struct ceph_crypto_key *key)\n{\n\tif (key) {\n\t\tkfree(key->key);\n\t\tkey->key = NULL;\n\t}\n}\n\nint ceph_crypto_key_clone(struct ceph_crypto_key *dst,\n\t\t\t  const struct ceph_crypto_key *src);\nint ceph_crypto_key_encode(struct ceph_crypto_key *key, void **p, void *end);\nint ceph_crypto_key_decode(struct ceph_crypto_key *key, void **p, void *end);\nint ceph_crypto_key_unarmor(struct ceph_crypto_key *key, const char *in);\n\n/* crypto.c */\nint ceph_decrypt(struct ceph_crypto_key *secret,\n\t\t void *dst, size_t *dst_len,\n\t\t const void *src, size_t src_len);\nint ceph_encrypt(struct ceph_crypto_key *secret,\n\t\t void *dst, size_t *dst_len,\n\t\t const void *src, size_t src_len);\nint ceph_decrypt2(struct ceph_crypto_key *secret,\n\t\t  void *dst1, size_t *dst1_len,\n\t\t  void *dst2, size_t *dst2_len,\n\t\t  const void *src, size_t src_len);\nint ceph_encrypt2(struct ceph_crypto_key *secret,\n\t\t  void *dst, size_t *dst_len,\n\t\t  const void *src1, size_t src1_len,\n\t\t  const void *src2, size_t src2_len);\nint ceph_crypto_init(void);\nvoid ceph_crypto_shutdown(void);\n\n/* armor.c */\nint ceph_armor(char *dst, const char *src, const char *end);\nint ceph_unarmor(char *dst, const char *src, const char *end);\n\n#endif\n"], "fixing_code": ["\n#include <linux/ceph/ceph_debug.h>\n\n#include <linux/err.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n#include <crypto/aes.h>\n#include <crypto/skcipher.h>\n#include <linux/key-type.h>\n\n#include <keys/ceph-type.h>\n#include <keys/user-type.h>\n#include <linux/ceph/decode.h>\n#include \"crypto.h\"\n\nint ceph_crypto_key_clone(struct ceph_crypto_key *dst,\n\t\t\t  const struct ceph_crypto_key *src)\n{\n\tmemcpy(dst, src, sizeof(struct ceph_crypto_key));\n\tdst->key = kmemdup(src->key, src->len, GFP_NOFS);\n\tif (!dst->key)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nint ceph_crypto_key_encode(struct ceph_crypto_key *key, void **p, void *end)\n{\n\tif (*p + sizeof(u16) + sizeof(key->created) +\n\t    sizeof(u16) + key->len > end)\n\t\treturn -ERANGE;\n\tceph_encode_16(p, key->type);\n\tceph_encode_copy(p, &key->created, sizeof(key->created));\n\tceph_encode_16(p, key->len);\n\tceph_encode_copy(p, key->key, key->len);\n\treturn 0;\n}\n\nint ceph_crypto_key_decode(struct ceph_crypto_key *key, void **p, void *end)\n{\n\tceph_decode_need(p, end, 2*sizeof(u16) + sizeof(key->created), bad);\n\tkey->type = ceph_decode_16(p);\n\tceph_decode_copy(p, &key->created, sizeof(key->created));\n\tkey->len = ceph_decode_16(p);\n\tceph_decode_need(p, end, key->len, bad);\n\tkey->key = kmalloc(key->len, GFP_NOFS);\n\tif (!key->key)\n\t\treturn -ENOMEM;\n\tceph_decode_copy(p, key->key, key->len);\n\treturn 0;\n\nbad:\n\tdout(\"failed to decode crypto key\\n\");\n\treturn -EINVAL;\n}\n\nint ceph_crypto_key_unarmor(struct ceph_crypto_key *key, const char *inkey)\n{\n\tint inlen = strlen(inkey);\n\tint blen = inlen * 3 / 4;\n\tvoid *buf, *p;\n\tint ret;\n\n\tdout(\"crypto_key_unarmor %s\\n\", inkey);\n\tbuf = kmalloc(blen, GFP_NOFS);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\tblen = ceph_unarmor(buf, inkey, inkey+inlen);\n\tif (blen < 0) {\n\t\tkfree(buf);\n\t\treturn blen;\n\t}\n\n\tp = buf;\n\tret = ceph_crypto_key_decode(key, &p, p + blen);\n\tkfree(buf);\n\tif (ret)\n\t\treturn ret;\n\tdout(\"crypto_key_unarmor key %p type %d len %d\\n\", key,\n\t     key->type, key->len);\n\treturn 0;\n}\n\nstatic struct crypto_skcipher *ceph_crypto_alloc_cipher(void)\n{\n\treturn crypto_alloc_skcipher(\"cbc(aes)\", 0, CRYPTO_ALG_ASYNC);\n}\n\nstatic const u8 *aes_iv = (u8 *)CEPH_AES_IV;\n\n/*\n * Should be used for buffers allocated with ceph_kvmalloc().\n * Currently these are encrypt out-buffer (ceph_buffer) and decrypt\n * in-buffer (msg front).\n *\n * Dispose of @sgt with teardown_sgtable().\n *\n * @prealloc_sg is to avoid memory allocation inside sg_alloc_table()\n * in cases where a single sg is sufficient.  No attempt to reduce the\n * number of sgs by squeezing physically contiguous pages together is\n * made though, for simplicity.\n */\nstatic int setup_sgtable(struct sg_table *sgt, struct scatterlist *prealloc_sg,\n\t\t\t const void *buf, unsigned int buf_len)\n{\n\tstruct scatterlist *sg;\n\tconst bool is_vmalloc = is_vmalloc_addr(buf);\n\tunsigned int off = offset_in_page(buf);\n\tunsigned int chunk_cnt = 1;\n\tunsigned int chunk_len = PAGE_ALIGN(off + buf_len);\n\tint i;\n\tint ret;\n\n\tif (buf_len == 0) {\n\t\tmemset(sgt, 0, sizeof(*sgt));\n\t\treturn -EINVAL;\n\t}\n\n\tif (is_vmalloc) {\n\t\tchunk_cnt = chunk_len >> PAGE_SHIFT;\n\t\tchunk_len = PAGE_SIZE;\n\t}\n\n\tif (chunk_cnt > 1) {\n\t\tret = sg_alloc_table(sgt, chunk_cnt, GFP_NOFS);\n\t\tif (ret)\n\t\t\treturn ret;\n\t} else {\n\t\tWARN_ON(chunk_cnt != 1);\n\t\tsg_init_table(prealloc_sg, 1);\n\t\tsgt->sgl = prealloc_sg;\n\t\tsgt->nents = sgt->orig_nents = 1;\n\t}\n\n\tfor_each_sg(sgt->sgl, sg, sgt->orig_nents, i) {\n\t\tstruct page *page;\n\t\tunsigned int len = min(chunk_len - off, buf_len);\n\n\t\tif (is_vmalloc)\n\t\t\tpage = vmalloc_to_page(buf);\n\t\telse\n\t\t\tpage = virt_to_page(buf);\n\n\t\tsg_set_page(sg, page, len, off);\n\n\t\toff = 0;\n\t\tbuf += len;\n\t\tbuf_len -= len;\n\t}\n\tWARN_ON(buf_len != 0);\n\n\treturn 0;\n}\n\nstatic void teardown_sgtable(struct sg_table *sgt)\n{\n\tif (sgt->orig_nents > 1)\n\t\tsg_free_table(sgt);\n}\n\nstatic int ceph_aes_encrypt(const void *key, int key_len,\n\t\t\t    void *dst, size_t *dst_len,\n\t\t\t    const void *src, size_t src_len)\n{\n\tstruct scatterlist sg_in[2], prealloc_sg;\n\tstruct sg_table sg_out;\n\tstruct crypto_skcipher *tfm = ceph_crypto_alloc_cipher();\n\tSKCIPHER_REQUEST_ON_STACK(req, tfm);\n\tint ret;\n\tchar iv[AES_BLOCK_SIZE];\n\tsize_t zero_padding = (0x10 - (src_len & 0x0f));\n\tchar pad[16];\n\n\tif (IS_ERR(tfm))\n\t\treturn PTR_ERR(tfm);\n\n\tmemset(pad, zero_padding, zero_padding);\n\n\t*dst_len = src_len + zero_padding;\n\n\tsg_init_table(sg_in, 2);\n\tsg_set_buf(&sg_in[0], src, src_len);\n\tsg_set_buf(&sg_in[1], pad, zero_padding);\n\tret = setup_sgtable(&sg_out, &prealloc_sg, dst, *dst_len);\n\tif (ret)\n\t\tgoto out_tfm;\n\n\tcrypto_skcipher_setkey((void *)tfm, key, key_len);\n\tmemcpy(iv, aes_iv, AES_BLOCK_SIZE);\n\n\tskcipher_request_set_tfm(req, tfm);\n\tskcipher_request_set_callback(req, 0, NULL, NULL);\n\tskcipher_request_set_crypt(req, sg_in, sg_out.sgl,\n\t\t\t\t   src_len + zero_padding, iv);\n\n\t/*\n\tprint_hex_dump(KERN_ERR, \"enc key: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       key, key_len, 1);\n\tprint_hex_dump(KERN_ERR, \"enc src: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t\tsrc, src_len, 1);\n\tprint_hex_dump(KERN_ERR, \"enc pad: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t\tpad, zero_padding, 1);\n\t*/\n\tret = crypto_skcipher_encrypt(req);\n\tskcipher_request_zero(req);\n\tif (ret < 0) {\n\t\tpr_err(\"ceph_aes_crypt failed %d\\n\", ret);\n\t\tgoto out_sg;\n\t}\n\t/*\n\tprint_hex_dump(KERN_ERR, \"enc out: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       dst, *dst_len, 1);\n\t*/\n\nout_sg:\n\tteardown_sgtable(&sg_out);\nout_tfm:\n\tcrypto_free_skcipher(tfm);\n\treturn ret;\n}\n\nstatic int ceph_aes_encrypt2(const void *key, int key_len, void *dst,\n\t\t\t     size_t *dst_len,\n\t\t\t     const void *src1, size_t src1_len,\n\t\t\t     const void *src2, size_t src2_len)\n{\n\tstruct scatterlist sg_in[3], prealloc_sg;\n\tstruct sg_table sg_out;\n\tstruct crypto_skcipher *tfm = ceph_crypto_alloc_cipher();\n\tSKCIPHER_REQUEST_ON_STACK(req, tfm);\n\tint ret;\n\tchar iv[AES_BLOCK_SIZE];\n\tsize_t zero_padding = (0x10 - ((src1_len + src2_len) & 0x0f));\n\tchar pad[16];\n\n\tif (IS_ERR(tfm))\n\t\treturn PTR_ERR(tfm);\n\n\tmemset(pad, zero_padding, zero_padding);\n\n\t*dst_len = src1_len + src2_len + zero_padding;\n\n\tsg_init_table(sg_in, 3);\n\tsg_set_buf(&sg_in[0], src1, src1_len);\n\tsg_set_buf(&sg_in[1], src2, src2_len);\n\tsg_set_buf(&sg_in[2], pad, zero_padding);\n\tret = setup_sgtable(&sg_out, &prealloc_sg, dst, *dst_len);\n\tif (ret)\n\t\tgoto out_tfm;\n\n\tcrypto_skcipher_setkey((void *)tfm, key, key_len);\n\tmemcpy(iv, aes_iv, AES_BLOCK_SIZE);\n\n\tskcipher_request_set_tfm(req, tfm);\n\tskcipher_request_set_callback(req, 0, NULL, NULL);\n\tskcipher_request_set_crypt(req, sg_in, sg_out.sgl,\n\t\t\t\t   src1_len + src2_len + zero_padding, iv);\n\n\t/*\n\tprint_hex_dump(KERN_ERR, \"enc  key: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       key, key_len, 1);\n\tprint_hex_dump(KERN_ERR, \"enc src1: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t\tsrc1, src1_len, 1);\n\tprint_hex_dump(KERN_ERR, \"enc src2: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t\tsrc2, src2_len, 1);\n\tprint_hex_dump(KERN_ERR, \"enc  pad: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t\tpad, zero_padding, 1);\n\t*/\n\tret = crypto_skcipher_encrypt(req);\n\tskcipher_request_zero(req);\n\tif (ret < 0) {\n\t\tpr_err(\"ceph_aes_crypt2 failed %d\\n\", ret);\n\t\tgoto out_sg;\n\t}\n\t/*\n\tprint_hex_dump(KERN_ERR, \"enc  out: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       dst, *dst_len, 1);\n\t*/\n\nout_sg:\n\tteardown_sgtable(&sg_out);\nout_tfm:\n\tcrypto_free_skcipher(tfm);\n\treturn ret;\n}\n\nstatic int ceph_aes_decrypt(const void *key, int key_len,\n\t\t\t    void *dst, size_t *dst_len,\n\t\t\t    const void *src, size_t src_len)\n{\n\tstruct sg_table sg_in;\n\tstruct scatterlist sg_out[2], prealloc_sg;\n\tstruct crypto_skcipher *tfm = ceph_crypto_alloc_cipher();\n\tSKCIPHER_REQUEST_ON_STACK(req, tfm);\n\tchar pad[16];\n\tchar iv[AES_BLOCK_SIZE];\n\tint ret;\n\tint last_byte;\n\n\tif (IS_ERR(tfm))\n\t\treturn PTR_ERR(tfm);\n\n\tsg_init_table(sg_out, 2);\n\tsg_set_buf(&sg_out[0], dst, *dst_len);\n\tsg_set_buf(&sg_out[1], pad, sizeof(pad));\n\tret = setup_sgtable(&sg_in, &prealloc_sg, src, src_len);\n\tif (ret)\n\t\tgoto out_tfm;\n\n\tcrypto_skcipher_setkey((void *)tfm, key, key_len);\n\tmemcpy(iv, aes_iv, AES_BLOCK_SIZE);\n\n\tskcipher_request_set_tfm(req, tfm);\n\tskcipher_request_set_callback(req, 0, NULL, NULL);\n\tskcipher_request_set_crypt(req, sg_in.sgl, sg_out,\n\t\t\t\t   src_len, iv);\n\n\t/*\n\tprint_hex_dump(KERN_ERR, \"dec key: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       key, key_len, 1);\n\tprint_hex_dump(KERN_ERR, \"dec  in: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       src, src_len, 1);\n\t*/\n\tret = crypto_skcipher_decrypt(req);\n\tskcipher_request_zero(req);\n\tif (ret < 0) {\n\t\tpr_err(\"ceph_aes_decrypt failed %d\\n\", ret);\n\t\tgoto out_sg;\n\t}\n\n\tif (src_len <= *dst_len)\n\t\tlast_byte = ((char *)dst)[src_len - 1];\n\telse\n\t\tlast_byte = pad[src_len - *dst_len - 1];\n\tif (last_byte <= 16 && src_len >= last_byte) {\n\t\t*dst_len = src_len - last_byte;\n\t} else {\n\t\tpr_err(\"ceph_aes_decrypt got bad padding %d on src len %d\\n\",\n\t\t       last_byte, (int)src_len);\n\t\treturn -EPERM;  /* bad padding */\n\t}\n\t/*\n\tprint_hex_dump(KERN_ERR, \"dec out: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       dst, *dst_len, 1);\n\t*/\n\nout_sg:\n\tteardown_sgtable(&sg_in);\nout_tfm:\n\tcrypto_free_skcipher(tfm);\n\treturn ret;\n}\n\nstatic int ceph_aes_decrypt2(const void *key, int key_len,\n\t\t\t     void *dst1, size_t *dst1_len,\n\t\t\t     void *dst2, size_t *dst2_len,\n\t\t\t     const void *src, size_t src_len)\n{\n\tstruct sg_table sg_in;\n\tstruct scatterlist sg_out[3], prealloc_sg;\n\tstruct crypto_skcipher *tfm = ceph_crypto_alloc_cipher();\n\tSKCIPHER_REQUEST_ON_STACK(req, tfm);\n\tchar pad[16];\n\tchar iv[AES_BLOCK_SIZE];\n\tint ret;\n\tint last_byte;\n\n\tif (IS_ERR(tfm))\n\t\treturn PTR_ERR(tfm);\n\n\tsg_init_table(sg_out, 3);\n\tsg_set_buf(&sg_out[0], dst1, *dst1_len);\n\tsg_set_buf(&sg_out[1], dst2, *dst2_len);\n\tsg_set_buf(&sg_out[2], pad, sizeof(pad));\n\tret = setup_sgtable(&sg_in, &prealloc_sg, src, src_len);\n\tif (ret)\n\t\tgoto out_tfm;\n\n\tcrypto_skcipher_setkey((void *)tfm, key, key_len);\n\tmemcpy(iv, aes_iv, AES_BLOCK_SIZE);\n\n\tskcipher_request_set_tfm(req, tfm);\n\tskcipher_request_set_callback(req, 0, NULL, NULL);\n\tskcipher_request_set_crypt(req, sg_in.sgl, sg_out,\n\t\t\t\t   src_len, iv);\n\n\t/*\n\tprint_hex_dump(KERN_ERR, \"dec  key: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       key, key_len, 1);\n\tprint_hex_dump(KERN_ERR, \"dec   in: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       src, src_len, 1);\n\t*/\n\tret = crypto_skcipher_decrypt(req);\n\tskcipher_request_zero(req);\n\tif (ret < 0) {\n\t\tpr_err(\"ceph_aes_decrypt failed %d\\n\", ret);\n\t\tgoto out_sg;\n\t}\n\n\tif (src_len <= *dst1_len)\n\t\tlast_byte = ((char *)dst1)[src_len - 1];\n\telse if (src_len <= *dst1_len + *dst2_len)\n\t\tlast_byte = ((char *)dst2)[src_len - *dst1_len - 1];\n\telse\n\t\tlast_byte = pad[src_len - *dst1_len - *dst2_len - 1];\n\tif (last_byte <= 16 && src_len >= last_byte) {\n\t\tsrc_len -= last_byte;\n\t} else {\n\t\tpr_err(\"ceph_aes_decrypt got bad padding %d on src len %d\\n\",\n\t\t       last_byte, (int)src_len);\n\t\treturn -EPERM;  /* bad padding */\n\t}\n\n\tif (src_len < *dst1_len) {\n\t\t*dst1_len = src_len;\n\t\t*dst2_len = 0;\n\t} else {\n\t\t*dst2_len = src_len - *dst1_len;\n\t}\n\t/*\n\tprint_hex_dump(KERN_ERR, \"dec  out1: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       dst1, *dst1_len, 1);\n\tprint_hex_dump(KERN_ERR, \"dec  out2: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       dst2, *dst2_len, 1);\n\t*/\n\nout_sg:\n\tteardown_sgtable(&sg_in);\nout_tfm:\n\tcrypto_free_skcipher(tfm);\n\treturn ret;\n}\n\n\nint ceph_decrypt(struct ceph_crypto_key *secret, void *dst, size_t *dst_len,\n\t\t const void *src, size_t src_len)\n{\n\tswitch (secret->type) {\n\tcase CEPH_CRYPTO_NONE:\n\t\tif (*dst_len < src_len)\n\t\t\treturn -ERANGE;\n\t\tmemcpy(dst, src, src_len);\n\t\t*dst_len = src_len;\n\t\treturn 0;\n\n\tcase CEPH_CRYPTO_AES:\n\t\treturn ceph_aes_decrypt(secret->key, secret->len, dst,\n\t\t\t\t\tdst_len, src, src_len);\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nint ceph_decrypt2(struct ceph_crypto_key *secret,\n\t\t\tvoid *dst1, size_t *dst1_len,\n\t\t\tvoid *dst2, size_t *dst2_len,\n\t\t\tconst void *src, size_t src_len)\n{\n\tsize_t t;\n\n\tswitch (secret->type) {\n\tcase CEPH_CRYPTO_NONE:\n\t\tif (*dst1_len + *dst2_len < src_len)\n\t\t\treturn -ERANGE;\n\t\tt = min(*dst1_len, src_len);\n\t\tmemcpy(dst1, src, t);\n\t\t*dst1_len = t;\n\t\tsrc += t;\n\t\tsrc_len -= t;\n\t\tif (src_len) {\n\t\t\tt = min(*dst2_len, src_len);\n\t\t\tmemcpy(dst2, src, t);\n\t\t\t*dst2_len = t;\n\t\t}\n\t\treturn 0;\n\n\tcase CEPH_CRYPTO_AES:\n\t\treturn ceph_aes_decrypt2(secret->key, secret->len,\n\t\t\t\t\t dst1, dst1_len, dst2, dst2_len,\n\t\t\t\t\t src, src_len);\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nint ceph_encrypt(struct ceph_crypto_key *secret, void *dst, size_t *dst_len,\n\t\t const void *src, size_t src_len)\n{\n\tswitch (secret->type) {\n\tcase CEPH_CRYPTO_NONE:\n\t\tif (*dst_len < src_len)\n\t\t\treturn -ERANGE;\n\t\tmemcpy(dst, src, src_len);\n\t\t*dst_len = src_len;\n\t\treturn 0;\n\n\tcase CEPH_CRYPTO_AES:\n\t\treturn ceph_aes_encrypt(secret->key, secret->len, dst,\n\t\t\t\t\tdst_len, src, src_len);\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nint ceph_encrypt2(struct ceph_crypto_key *secret, void *dst, size_t *dst_len,\n\t\t  const void *src1, size_t src1_len,\n\t\t  const void *src2, size_t src2_len)\n{\n\tswitch (secret->type) {\n\tcase CEPH_CRYPTO_NONE:\n\t\tif (*dst_len < src1_len + src2_len)\n\t\t\treturn -ERANGE;\n\t\tmemcpy(dst, src1, src1_len);\n\t\tmemcpy(dst + src1_len, src2, src2_len);\n\t\t*dst_len = src1_len + src2_len;\n\t\treturn 0;\n\n\tcase CEPH_CRYPTO_AES:\n\t\treturn ceph_aes_encrypt2(secret->key, secret->len, dst, dst_len,\n\t\t\t\t\t src1, src1_len, src2, src2_len);\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic int ceph_aes_crypt(const struct ceph_crypto_key *key, bool encrypt,\n\t\t\t  void *buf, int buf_len, int in_len, int *pout_len)\n{\n\tstruct crypto_skcipher *tfm = ceph_crypto_alloc_cipher();\n\tSKCIPHER_REQUEST_ON_STACK(req, tfm);\n\tstruct sg_table sgt;\n\tstruct scatterlist prealloc_sg;\n\tchar iv[AES_BLOCK_SIZE];\n\tint pad_byte = AES_BLOCK_SIZE - (in_len & (AES_BLOCK_SIZE - 1));\n\tint crypt_len = encrypt ? in_len + pad_byte : in_len;\n\tint ret;\n\n\tif (IS_ERR(tfm))\n\t\treturn PTR_ERR(tfm);\n\n\tWARN_ON(crypt_len > buf_len);\n\tif (encrypt)\n\t\tmemset(buf + in_len, pad_byte, pad_byte);\n\tret = setup_sgtable(&sgt, &prealloc_sg, buf, crypt_len);\n\tif (ret)\n\t\tgoto out_tfm;\n\n\tcrypto_skcipher_setkey((void *)tfm, key->key, key->len);\n\tmemcpy(iv, aes_iv, AES_BLOCK_SIZE);\n\n\tskcipher_request_set_tfm(req, tfm);\n\tskcipher_request_set_callback(req, 0, NULL, NULL);\n\tskcipher_request_set_crypt(req, sgt.sgl, sgt.sgl, crypt_len, iv);\n\n\t/*\n\tprint_hex_dump(KERN_ERR, \"key: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       key->key, key->len, 1);\n\tprint_hex_dump(KERN_ERR, \" in: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       buf, crypt_len, 1);\n\t*/\n\tif (encrypt)\n\t\tret = crypto_skcipher_encrypt(req);\n\telse\n\t\tret = crypto_skcipher_decrypt(req);\n\tskcipher_request_zero(req);\n\tif (ret) {\n\t\tpr_err(\"%s %scrypt failed: %d\\n\", __func__,\n\t\t       encrypt ? \"en\" : \"de\", ret);\n\t\tgoto out_sgt;\n\t}\n\t/*\n\tprint_hex_dump(KERN_ERR, \"out: \", DUMP_PREFIX_NONE, 16, 1,\n\t\t       buf, crypt_len, 1);\n\t*/\n\n\tif (encrypt) {\n\t\t*pout_len = crypt_len;\n\t} else {\n\t\tpad_byte = *(char *)(buf + in_len - 1);\n\t\tif (pad_byte > 0 && pad_byte <= AES_BLOCK_SIZE &&\n\t\t    in_len >= pad_byte) {\n\t\t\t*pout_len = in_len - pad_byte;\n\t\t} else {\n\t\t\tpr_err(\"%s got bad padding %d on in_len %d\\n\",\n\t\t\t       __func__, pad_byte, in_len);\n\t\t\tret = -EPERM;\n\t\t\tgoto out_sgt;\n\t\t}\n\t}\n\nout_sgt:\n\tteardown_sgtable(&sgt);\nout_tfm:\n\tcrypto_free_skcipher(tfm);\n\treturn ret;\n}\n\nint ceph_crypt(const struct ceph_crypto_key *key, bool encrypt,\n\t       void *buf, int buf_len, int in_len, int *pout_len)\n{\n\tswitch (key->type) {\n\tcase CEPH_CRYPTO_NONE:\n\t\t*pout_len = in_len;\n\t\treturn 0;\n\tcase CEPH_CRYPTO_AES:\n\t\treturn ceph_aes_crypt(key, encrypt, buf, buf_len, in_len,\n\t\t\t\t      pout_len);\n\tdefault:\n\t\treturn -ENOTSUPP;\n\t}\n}\n\nstatic int ceph_key_preparse(struct key_preparsed_payload *prep)\n{\n\tstruct ceph_crypto_key *ckey;\n\tsize_t datalen = prep->datalen;\n\tint ret;\n\tvoid *p;\n\n\tret = -EINVAL;\n\tif (datalen <= 0 || datalen > 32767 || !prep->data)\n\t\tgoto err;\n\n\tret = -ENOMEM;\n\tckey = kmalloc(sizeof(*ckey), GFP_KERNEL);\n\tif (!ckey)\n\t\tgoto err;\n\n\t/* TODO ceph_crypto_key_decode should really take const input */\n\tp = (void *)prep->data;\n\tret = ceph_crypto_key_decode(ckey, &p, (char*)prep->data+datalen);\n\tif (ret < 0)\n\t\tgoto err_ckey;\n\n\tprep->payload.data[0] = ckey;\n\tprep->quotalen = datalen;\n\treturn 0;\n\nerr_ckey:\n\tkfree(ckey);\nerr:\n\treturn ret;\n}\n\nstatic void ceph_key_free_preparse(struct key_preparsed_payload *prep)\n{\n\tstruct ceph_crypto_key *ckey = prep->payload.data[0];\n\tceph_crypto_key_destroy(ckey);\n\tkfree(ckey);\n}\n\nstatic void ceph_key_destroy(struct key *key)\n{\n\tstruct ceph_crypto_key *ckey = key->payload.data[0];\n\n\tceph_crypto_key_destroy(ckey);\n\tkfree(ckey);\n}\n\nstruct key_type key_type_ceph = {\n\t.name\t\t= \"ceph\",\n\t.preparse\t= ceph_key_preparse,\n\t.free_preparse\t= ceph_key_free_preparse,\n\t.instantiate\t= generic_key_instantiate,\n\t.destroy\t= ceph_key_destroy,\n};\n\nint ceph_crypto_init(void) {\n\treturn register_key_type(&key_type_ceph);\n}\n\nvoid ceph_crypto_shutdown(void) {\n\tunregister_key_type(&key_type_ceph);\n}\n", "#ifndef _FS_CEPH_CRYPTO_H\n#define _FS_CEPH_CRYPTO_H\n\n#include <linux/ceph/types.h>\n#include <linux/ceph/buffer.h>\n\n/*\n * cryptographic secret\n */\nstruct ceph_crypto_key {\n\tint type;\n\tstruct ceph_timespec created;\n\tint len;\n\tvoid *key;\n};\n\nstatic inline void ceph_crypto_key_destroy(struct ceph_crypto_key *key)\n{\n\tif (key) {\n\t\tkfree(key->key);\n\t\tkey->key = NULL;\n\t}\n}\n\nint ceph_crypto_key_clone(struct ceph_crypto_key *dst,\n\t\t\t  const struct ceph_crypto_key *src);\nint ceph_crypto_key_encode(struct ceph_crypto_key *key, void **p, void *end);\nint ceph_crypto_key_decode(struct ceph_crypto_key *key, void **p, void *end);\nint ceph_crypto_key_unarmor(struct ceph_crypto_key *key, const char *in);\n\n/* crypto.c */\nint ceph_decrypt(struct ceph_crypto_key *secret,\n\t\t void *dst, size_t *dst_len,\n\t\t const void *src, size_t src_len);\nint ceph_encrypt(struct ceph_crypto_key *secret,\n\t\t void *dst, size_t *dst_len,\n\t\t const void *src, size_t src_len);\nint ceph_decrypt2(struct ceph_crypto_key *secret,\n\t\t  void *dst1, size_t *dst1_len,\n\t\t  void *dst2, size_t *dst2_len,\n\t\t  const void *src, size_t src_len);\nint ceph_encrypt2(struct ceph_crypto_key *secret,\n\t\t  void *dst, size_t *dst_len,\n\t\t  const void *src1, size_t src1_len,\n\t\t  const void *src2, size_t src2_len);\nint ceph_crypt(const struct ceph_crypto_key *key, bool encrypt,\n\t       void *buf, int buf_len, int in_len, int *pout_len);\nint ceph_crypto_init(void);\nvoid ceph_crypto_shutdown(void);\n\n/* armor.c */\nint ceph_armor(char *dst, const char *src, const char *end);\nint ceph_unarmor(char *dst, const char *src, const char *end);\n\n#endif\n"], "filenames": ["net/ceph/crypto.c", "net/ceph/crypto.h"], "buggy_code_start_loc": [528, 45], "buggy_code_end_loc": [528, 45], "fixing_code_start_loc": [529, 46], "fixing_code_end_loc": [616, 48], "type": "CWE-399", "message": "The crypto scatterlist API in the Linux kernel 4.9.x before 4.9.6 interacts incorrectly with the CONFIG_VMAP_STACK option, which allows local users to cause a denial of service (system crash or memory corruption) or possibly have unspecified other impact by leveraging reliance on earlier net/ceph/crypto.c code.", "other": {"cve": {"id": "CVE-2016-10153", "sourceIdentifier": "cve@mitre.org", "published": "2017-02-06T06:59:00.277", "lastModified": "2017-02-09T14:57:19.417", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "The crypto scatterlist API in the Linux kernel 4.9.x before 4.9.6 interacts incorrectly with the CONFIG_VMAP_STACK option, which allows local users to cause a denial of service (system crash or memory corruption) or possibly have unspecified other impact by leveraging reliance on earlier net/ceph/crypto.c code."}, {"lang": "es", "value": "La API criptogr\u00e1fica de la lista de dispersi\u00f3n en el kernel de Linux 4.9.x en versiones anteriores a 4.9.6 interact\u00faa incorrectamente con la opci\u00f3n CONFIG_VMAP_STACK, lo que permite a usuarios locales provocar una denegaci\u00f3n de servicio (ca\u00edda de sistema o corrupci\u00f3n de memoria) o posiblemente tener otro impacto no especificado aprovechando la confianza en el c\u00f3digo anterior net/ceph/crypto.c."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:C/I:C/A:C", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "COMPLETE", "integrityImpact": "COMPLETE", "availabilityImpact": "COMPLETE", "baseScore": 7.2}, "baseSeverity": "HIGH", "exploitabilityScore": 3.9, "impactScore": 10.0, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-399"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:4.9:*:*:*:*:*:*:*", "matchCriteriaId": "27B10B33-5F64-4039-8351-694A7AB6E4E4"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:4.9.1:*:*:*:*:*:*:*", "matchCriteriaId": "686DF390-3DCA-4D64-9858-FF699FA21D9A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:4.9.2:*:*:*:*:*:*:*", "matchCriteriaId": "D24EF446-2120-4F2F-9D84-F782BF1D85CF"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:4.9.3:*:*:*:*:*:*:*", "matchCriteriaId": "DA879AFB-E995-458B-ABD2-87477376A70D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:4.9.4:*:*:*:*:*:*:*", "matchCriteriaId": "719F2C9D-1897-480A-93CE-C2AC987B80AC"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:4.9.5:*:*:*:*:*:*:*", "matchCriteriaId": "F1516D1D-261D-421C-83FF-05DD90DAEB50"}]}]}], "references": [{"url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=a45f795c65b479b4ba107b6ccde29b896d51ee98", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "http://www.kernel.org/pub/linux/kernel/v4.x/ChangeLog-4.9.6", "source": "cve@mitre.org", "tags": ["Release Notes", "Vendor Advisory"]}, {"url": "http://www.openwall.com/lists/oss-security/2017/01/21/3", "source": "cve@mitre.org", "tags": ["Mailing List", "Patch", "Third Party Advisory"]}, {"url": "http://www.securityfocus.com/bid/95713", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://bugzilla.redhat.com/show_bug.cgi?id=1416101", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch"]}, {"url": "https://github.com/torvalds/linux/commit/a45f795c65b479b4ba107b6ccde29b896d51ee98", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/a45f795c65b479b4ba107b6ccde29b896d51ee98"}}
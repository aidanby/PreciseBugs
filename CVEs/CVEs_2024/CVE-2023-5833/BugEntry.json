{"buggy_code": ["process.env.NODE_ENV === \"development\"\n  ? require(\"dotenv\").config({ path: `.env.${process.env.NODE_ENV}` })\n  : require(\"dotenv\").config();\nconst { viewLocalFiles } = require(\"../utils/files\");\nconst { exportData, unpackAndOverwriteImport } = require(\"../utils/files/data\");\nconst {\n  checkPythonAppAlive,\n  acceptedFileTypes,\n} = require(\"../utils/files/documentProcessor\");\nconst { purgeDocument } = require(\"../utils/files/purgeDocument\");\nconst { getVectorDbClass } = require(\"../utils/helpers\");\nconst { updateENV, dumpENV } = require(\"../utils/helpers/updateENV\");\nconst {\n  reqBody,\n  makeJWT,\n  userFromSession,\n  multiUserMode,\n} = require(\"../utils/http\");\nconst { setupDataImports, setupLogoUploads } = require(\"../utils/files/multer\");\nconst { v4 } = require(\"uuid\");\nconst { SystemSettings } = require(\"../models/systemSettings\");\nconst { User } = require(\"../models/user\");\nconst { validatedRequest } = require(\"../utils/middleware/validatedRequest\");\nconst { handleImports } = setupDataImports();\nconst { handleLogoUploads } = setupLogoUploads();\nconst fs = require(\"fs\");\nconst path = require(\"path\");\nconst {\n  getDefaultFilename,\n  determineLogoFilepath,\n  fetchLogo,\n  validFilename,\n  renameLogoFile,\n  removeCustomLogo,\n  DARK_LOGO_FILENAME,\n} = require(\"../utils/files/logo\");\nconst { Telemetry } = require(\"../models/telemetry\");\nconst { WelcomeMessages } = require(\"../models/welcomeMessages\");\nconst { ApiKey } = require(\"../models/apiKeys\");\n\nfunction systemEndpoints(app) {\n  if (!app) return;\n\n  app.get(\"/ping\", (_, response) => {\n    response.status(200).json({ online: true });\n  });\n\n  app.get(\"/migrate\", async (_, response) => {\n    const execSync = require(\"child_process\").execSync;\n    execSync(\"npx prisma migrate deploy --schema=./prisma/schema.prisma\", {\n      stdio: \"inherit\",\n    });\n    response.sendStatus(200);\n  });\n\n  app.get(\"/env-dump\", async (_, response) => {\n    if (process.env.NODE_ENV !== \"production\")\n      return response.sendStatus(200).end();\n    await dumpENV();\n    response.sendStatus(200).end();\n  });\n\n  app.get(\"/setup-complete\", async (_, response) => {\n    try {\n      const results = await SystemSettings.currentSettings();\n      response.status(200).json({ results });\n    } catch (e) {\n      console.log(e.message, e);\n      response.sendStatus(500).end();\n    }\n  });\n\n  app.get(\n    \"/system/check-token\",\n    [validatedRequest],\n    async (request, response) => {\n      try {\n        if (multiUserMode(response)) {\n          const user = await userFromSession(request, response);\n          if (!user || user.suspended) {\n            response.sendStatus(403).end();\n            return;\n          }\n\n          response.sendStatus(200).end();\n          return;\n        }\n\n        response.sendStatus(200).end();\n      } catch (e) {\n        console.log(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.post(\"/request-token\", async (request, response) => {\n    try {\n      if (await SystemSettings.isMultiUserMode()) {\n        const { username, password } = reqBody(request);\n        const existingUser = await User.get({ username });\n\n        if (!existingUser) {\n          response.status(200).json({\n            user: null,\n            valid: false,\n            token: null,\n            message: \"[001] Invalid login credentials.\",\n          });\n          return;\n        }\n\n        const bcrypt = require(\"bcrypt\");\n        if (!bcrypt.compareSync(password, existingUser.password)) {\n          response.status(200).json({\n            user: null,\n            valid: false,\n            token: null,\n            message: \"[002] Invalid login credentials.\",\n          });\n          return;\n        }\n\n        if (existingUser.suspended) {\n          response.status(200).json({\n            user: null,\n            valid: false,\n            token: null,\n            message: \"[004] Account suspended by admin.\",\n          });\n          return;\n        }\n\n        response.status(200).json({\n          valid: true,\n          user: existingUser,\n          token: makeJWT(\n            { id: existingUser.id, username: existingUser.username },\n            \"30d\"\n          ),\n          message: null,\n        });\n        return;\n      } else {\n        const { password } = reqBody(request);\n        if (password !== process.env.AUTH_TOKEN) {\n          response.status(401).json({\n            valid: false,\n            token: null,\n            message: \"[003] Invalid password provided\",\n          });\n          return;\n        }\n\n        response.status(200).json({\n          valid: true,\n          token: makeJWT({ p: password }, \"30d\"),\n          message: null,\n        });\n      }\n    } catch (e) {\n      console.log(e.message, e);\n      response.sendStatus(500).end();\n    }\n  });\n\n  app.get(\"/system/system-vectors\", [validatedRequest], async (_, response) => {\n    try {\n      const VectorDb = getVectorDbClass();\n      const vectorCount = await VectorDb.totalVectors();\n      response.status(200).json({ vectorCount });\n    } catch (e) {\n      console.log(e.message, e);\n      response.sendStatus(500).end();\n    }\n  });\n\n  app.delete(\n    \"/system/remove-document\",\n    [validatedRequest],\n    async (request, response) => {\n      try {\n        const { name, meta } = reqBody(request);\n        await purgeDocument(name, meta);\n        response.sendStatus(200).end();\n      } catch (e) {\n        console.log(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.get(\"/system/local-files\", [validatedRequest], async (_, response) => {\n    try {\n      const localFiles = await viewLocalFiles();\n      response.status(200).json({ localFiles });\n    } catch (e) {\n      console.log(e.message, e);\n      response.sendStatus(500).end();\n    }\n  });\n\n  app.get(\n    \"/system/document-processing-status\",\n    [validatedRequest],\n    async (_, response) => {\n      try {\n        const online = await checkPythonAppAlive();\n        response.sendStatus(online ? 200 : 503);\n      } catch (e) {\n        console.log(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.get(\n    \"/system/accepted-document-types\",\n    [validatedRequest],\n    async (_, response) => {\n      try {\n        const types = await acceptedFileTypes();\n        if (!types) {\n          response.sendStatus(404).end();\n          return;\n        }\n\n        response.status(200).json({ types });\n      } catch (e) {\n        console.log(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.post(\n    \"/system/update-env\",\n    [validatedRequest],\n    async (request, response) => {\n      try {\n        const body = reqBody(request);\n        const { newValues, error } = updateENV(body);\n        if (process.env.NODE_ENV === \"production\") await dumpENV();\n        response.status(200).json({ newValues, error });\n      } catch (e) {\n        console.log(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.post(\n    \"/system/update-password\",\n    [validatedRequest],\n    async (request, response) => {\n      try {\n        const { usePassword, newPassword } = reqBody(request);\n        const { error } = updateENV({\n          AuthToken: usePassword ? newPassword : \"\",\n          JWTSecret: usePassword ? v4() : \"\",\n        });\n        response.status(200).json({ success: !error, error });\n      } catch (e) {\n        console.log(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.post(\n    \"/system/enable-multi-user\",\n    [validatedRequest],\n    async (request, response) => {\n      try {\n        const { username, password } = reqBody(request);\n        const multiUserModeEnabled = await SystemSettings.isMultiUserMode();\n        if (multiUserModeEnabled) {\n          response.status(200).json({\n            success: false,\n            error: \"Multi-user mode is already enabled.\",\n          });\n          return;\n        }\n\n        const { user, error } = await User.create({\n          username,\n          password,\n          role: \"admin\",\n        });\n        await SystemSettings.updateSettings({\n          multi_user_mode: true,\n          users_can_delete_workspaces: false,\n          limit_user_messages: false,\n          message_limit: 25,\n        });\n        process.env.AUTH_TOKEN = null;\n        process.env.JWT_SECRET = process.env.JWT_SECRET ?? v4(); // Make sure JWT_SECRET is set for JWT issuance.\n        await Telemetry.sendTelemetry(\"enabled_multi_user_mode\");\n        response.status(200).json({ success: !!user, error });\n      } catch (e) {\n        console.log(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.get(\"/system/data-export\", [validatedRequest], async (_, response) => {\n    try {\n      const { filename, error } = await exportData();\n      response.status(200).json({ filename, error });\n    } catch (e) {\n      console.log(e.message, e);\n      response.sendStatus(500).end();\n    }\n  });\n\n  app.get(\n    \"/system/data-exports/:filename\",\n    [validatedRequest],\n    (request, response) => {\n      const exportLocation = __dirname + \"/../storage/exports/\";\n      const sanitized = path\n        .normalize(request.params.filename)\n        .replace(/^(\\.\\.(\\/|\\\\|$))+/, \"\");\n      const finalDestination = path.join(exportLocation, sanitized);\n\n      if (!fs.existsSync(finalDestination)) {\n        response.status(404).json({\n          error: 404,\n          msg: `File ${request.params.filename} does not exist in exports.`,\n        });\n        return;\n      }\n\n      response.download(finalDestination, request.params.filename, (err) => {\n        if (err) {\n          response.send({\n            error: err,\n            msg: \"Problem downloading the file\",\n          });\n        }\n      });\n    }\n  );\n\n  app.post(\n    \"/system/data-import\",\n    handleImports.single(\"file\"),\n    async function (request, response) {\n      const { originalname } = request.file;\n      const { success, error } = await unpackAndOverwriteImport(originalname);\n      response.status(200).json({ success, error });\n    }\n  );\n\n  app.get(\"/system/logo/:mode?\", async function (request, response) {\n    try {\n      const defaultFilename = getDefaultFilename(request.params.mode);\n      const logoPath = await determineLogoFilepath(defaultFilename);\n      const { buffer, size, mime } = fetchLogo(logoPath);\n      response.writeHead(200, {\n        \"Content-Type\": mime || \"image/png\",\n        \"Content-Disposition\": `attachment; filename=${path.basename(\n          logoPath\n        )}`,\n        \"Content-Length\": size,\n      });\n      response.end(Buffer.from(buffer, \"base64\"));\n      return;\n    } catch (error) {\n      console.error(\"Error processing the logo request:\", error);\n      response.status(500).json({ message: \"Internal server error\" });\n    }\n  });\n\n  app.post(\n    \"/system/upload-logo\",\n    [validatedRequest],\n    handleLogoUploads.single(\"logo\"),\n    async (request, response) => {\n      if (!request.file || !request.file.originalname) {\n        return response.status(400).json({ message: \"No logo file provided.\" });\n      }\n\n      if (!validFilename(request.file.originalname)) {\n        return response.status(400).json({\n          message: \"Invalid file name. Please choose a different file.\",\n        });\n      }\n\n      try {\n        if (\n          response.locals.multiUserMode &&\n          response.locals.user?.role !== \"admin\"\n        ) {\n          return response.sendStatus(401).end();\n        }\n\n        const newFilename = await renameLogoFile(request.file.originalname);\n        const existingLogoFilename = await SystemSettings.currentLogoFilename();\n        await removeCustomLogo(existingLogoFilename);\n\n        const { success, error } = await SystemSettings.updateSettings({\n          logo_filename: newFilename,\n        });\n\n        return response.status(success ? 200 : 500).json({\n          message: success\n            ? \"Logo uploaded successfully.\"\n            : error || \"Failed to update with new logo.\",\n        });\n      } catch (error) {\n        console.error(\"Error processing the logo upload:\", error);\n        response.status(500).json({ message: \"Error uploading the logo.\" });\n      }\n    }\n  );\n\n  app.get(\n    \"/system/remove-logo\",\n    [validatedRequest],\n    async (request, response) => {\n      try {\n        if (\n          response.locals.multiUserMode &&\n          response.locals.user?.role !== \"admin\"\n        ) {\n          return response.sendStatus(401).end();\n        }\n\n        const currentLogoFilename = await SystemSettings.currentLogoFilename();\n        await removeCustomLogo(currentLogoFilename);\n        const { success, error } = await SystemSettings.updateSettings({\n          logo_filename: DARK_LOGO_FILENAME,\n        });\n\n        return response.status(success ? 200 : 500).json({\n          message: success\n            ? \"Logo removed successfully.\"\n            : error || \"Failed to update with new logo.\",\n        });\n      } catch (error) {\n        console.error(\"Error processing the logo removal:\", error);\n        response.status(500).json({ message: \"Error removing the logo.\" });\n      }\n    }\n  );\n\n  app.get(\n    \"/system/can-delete-workspaces\",\n    [validatedRequest],\n    async function (request, response) {\n      try {\n        if (!response.locals.multiUserMode) {\n          return response.status(200).json({ canDelete: true });\n        }\n\n        if (response.locals.user?.role === \"admin\") {\n          return response.status(200).json({ canDelete: true });\n        }\n\n        const canDelete = await SystemSettings.canDeleteWorkspaces();\n        response.status(200).json({ canDelete });\n      } catch (error) {\n        console.error(\"Error fetching can delete workspaces:\", error);\n        response.status(500).json({\n          success: false,\n          message: \"Internal server error\",\n          canDelete: false,\n        });\n      }\n    }\n  );\n\n  app.get(\"/system/welcome-messages\", async function (request, response) {\n    try {\n      const welcomeMessages = await WelcomeMessages.getMessages();\n      response.status(200).json({ success: true, welcomeMessages });\n    } catch (error) {\n      console.error(\"Error fetching welcome messages:\", error);\n      response\n        .status(500)\n        .json({ success: false, message: \"Internal server error\" });\n    }\n  });\n\n  app.post(\n    \"/system/set-welcome-messages\",\n    [validatedRequest],\n    async (request, response) => {\n      try {\n        if (\n          response.locals.multiUserMode &&\n          response.locals.user?.role !== \"admin\"\n        ) {\n          return response.sendStatus(401).end();\n        }\n\n        const { messages = [] } = reqBody(request);\n        if (!Array.isArray(messages)) {\n          return response.status(400).json({\n            success: false,\n            message: \"Invalid message format. Expected an array of messages.\",\n          });\n        }\n\n        await WelcomeMessages.saveAll(messages);\n        return response.status(200).json({\n          success: true,\n          message: \"Welcome messages saved successfully.\",\n        });\n      } catch (error) {\n        console.error(\"Error processing the welcome messages:\", error);\n        response.status(500).json({\n          success: true,\n          message: \"Error saving the welcome messages.\",\n        });\n      }\n    }\n  );\n\n  app.get(\"/system/api-key\", [validatedRequest], async (_, response) => {\n    try {\n      if (response.locals.multiUserMode) {\n        return response.sendStatus(401).end();\n      }\n\n      const apiKey = await ApiKey.get({});\n      return response.status(200).json({\n        apiKey,\n        error: null,\n      });\n    } catch (error) {\n      console.error(error);\n      response.status(500).json({\n        apiKey: null,\n        error: \"Could not find an API Key.\",\n      });\n    }\n  });\n\n  app.post(\n    \"/system/generate-api-key\",\n    [validatedRequest],\n    async (_, response) => {\n      try {\n        if (response.locals.multiUserMode) {\n          return response.sendStatus(401).end();\n        }\n\n        await ApiKey.delete();\n        const { apiKey, error } = await ApiKey.create();\n        return response.status(200).json({\n          apiKey,\n          error,\n        });\n      } catch (error) {\n        console.error(error);\n        response.status(500).json({\n          apiKey: null,\n          error: \"Error generating api key.\",\n        });\n      }\n    }\n  );\n\n  app.delete(\"/system/api-key\", [validatedRequest], async (_, response) => {\n    try {\n      if (response.locals.multiUserMode) {\n        return response.sendStatus(401).end();\n      }\n\n      await ApiKey.delete();\n      return response.status(200).end();\n    } catch (error) {\n      console.error(error);\n      response.status(500).end();\n    }\n  });\n}\n\nmodule.exports = { systemEndpoints };\n", "const KEY_MAPPING = {\n  LLMProvider: {\n    envKey: \"LLM_PROVIDER\",\n    checks: [isNotEmpty, supportedLLM],\n  },\n  // OpenAI Settings\n  OpenAiKey: {\n    envKey: \"OPEN_AI_KEY\",\n    checks: [isNotEmpty, validOpenAIKey],\n  },\n  OpenAiModelPref: {\n    envKey: \"OPEN_MODEL_PREF\",\n    checks: [isNotEmpty, validOpenAIModel],\n  },\n  // Azure OpenAI Settings\n  AzureOpenAiEndpoint: {\n    envKey: \"AZURE_OPENAI_ENDPOINT\",\n    checks: [isNotEmpty, validAzureURL],\n  },\n  AzureOpenAiKey: {\n    envKey: \"AZURE_OPENAI_KEY\",\n    checks: [isNotEmpty],\n  },\n  AzureOpenAiModelPref: {\n    envKey: \"OPEN_MODEL_PREF\",\n    checks: [isNotEmpty],\n  },\n  AzureOpenAiEmbeddingModelPref: {\n    envKey: \"EMBEDDING_MODEL_PREF\",\n    checks: [isNotEmpty],\n  },\n\n  // Vector Database Selection Settings\n  VectorDB: {\n    envKey: \"VECTOR_DB\",\n    checks: [isNotEmpty, supportedVectorDB],\n  },\n  ChromaEndpoint: {\n    envKey: \"CHROMA_ENDPOINT\",\n    checks: [isValidURL, validChromaURL],\n  },\n  WeaviateEndpoint: {\n    envKey: \"WEAVIATE_ENDPOINT\",\n    checks: [isValidURL],\n  },\n  WeaviateApiKey: {\n    envKey: \"WEAVIATE_API_KEY\",\n    checks: [],\n  },\n  QdrantEndpoint: {\n    envKey: \"QDRANT_ENDPOINT\",\n    checks: [isValidURL],\n  },\n  QdrantApiKey: {\n    envKey: \"QDRANT_API_KEY\",\n    checks: [],\n  },\n\n  PineConeEnvironment: {\n    envKey: \"PINECONE_ENVIRONMENT\",\n    checks: [],\n  },\n  PineConeKey: {\n    envKey: \"PINECONE_API_KEY\",\n    checks: [],\n  },\n  PineConeIndex: {\n    envKey: \"PINECONE_INDEX\",\n    checks: [],\n  },\n\n  // System Settings\n  AuthToken: {\n    envKey: \"AUTH_TOKEN\",\n    checks: [],\n  },\n  JWTSecret: {\n    envKey: \"JWT_SECRET\",\n    checks: [],\n  },\n  // Not supported yet.\n  // 'StorageDir': 'STORAGE_DIR',\n};\n\nfunction isNotEmpty(input = \"\") {\n  return !input || input.length === 0 ? \"Value cannot be empty\" : null;\n}\n\nfunction isValidURL(input = \"\") {\n  try {\n    new URL(input);\n    return null;\n  } catch (e) {\n    return \"URL is not a valid URL.\";\n  }\n}\n\nfunction validOpenAIKey(input = \"\") {\n  return input.startsWith(\"sk-\") ? null : \"OpenAI Key must start with sk-\";\n}\n\nfunction supportedLLM(input = \"\") {\n  return [\"openai\", \"azure\"].includes(input);\n}\n\nfunction validOpenAIModel(input = \"\") {\n  const validModels = [\n    \"gpt-4\",\n    \"gpt-4-0613\",\n    \"gpt-4-32k\",\n    \"gpt-4-32k-0613\",\n    \"gpt-3.5-turbo\",\n    \"gpt-3.5-turbo-0613\",\n    \"gpt-3.5-turbo-16k\",\n    \"gpt-3.5-turbo-16k-0613\",\n  ];\n  return validModels.includes(input)\n    ? null\n    : `Invalid Model type. Must be one of ${validModels.join(\", \")}.`;\n}\n\nfunction supportedVectorDB(input = \"\") {\n  const supported = [\"chroma\", \"pinecone\", \"lancedb\", \"weaviate\", \"qdrant\"];\n  return supported.includes(input)\n    ? null\n    : `Invalid VectorDB type. Must be one of ${supported.join(\", \")}.`;\n}\n\nfunction validChromaURL(input = \"\") {\n  return input.slice(-1) === \"/\"\n    ? `Chroma Instance URL should not end in a trailing slash.`\n    : null;\n}\n\nfunction validAzureURL(input = \"\") {\n  try {\n    new URL(input);\n    if (!input.includes(\"openai.azure.com\"))\n      return \"URL must include openai.azure.com\";\n    return null;\n  } catch {\n    return \"Not a valid URL\";\n  }\n}\n\n// This will force update .env variables which for any which reason were not able to be parsed or\n// read from an ENV file as this seems to be a complicating step for many so allowing people to write\n// to the process will at least alleviate that issue. It does not perform comprehensive validity checks or sanity checks\n// and is simply for debugging when the .env not found issue many come across.\nfunction updateENV(newENVs = {}) {\n  let error = \"\";\n  const validKeys = Object.keys(KEY_MAPPING);\n  const ENV_KEYS = Object.keys(newENVs).filter(\n    (key) => validKeys.includes(key) && !newENVs[key].includes(\"******\") // strip out answers where the value is all asterisks\n  );\n  const newValues = {};\n\n  ENV_KEYS.forEach((key) => {\n    const { envKey, checks } = KEY_MAPPING[key];\n    const value = newENVs[key];\n    const errors = checks\n      .map((validityCheck) => validityCheck(value))\n      .filter((err) => typeof err === \"string\");\n\n    if (errors.length > 0) {\n      error += errors.join(\"\\n\");\n      return;\n    }\n\n    newValues[key] = value;\n    process.env[envKey] = value;\n  });\n\n  return { newValues, error: error?.length > 0 ? error : false };\n}\n\nasync function dumpENV() {\n  const fs = require(\"fs\");\n  const path = require(\"path\");\n\n  const frozenEnvs = {};\n  const protectedKeys = [\n    ...Object.values(KEY_MAPPING).map((values) => values.envKey),\n    \"CACHE_VECTORS\",\n    \"STORAGE_DIR\",\n    \"SERVER_PORT\",\n  ];\n\n  for (const key of protectedKeys) {\n    const envValue = process.env?.[key] || null;\n    if (!envValue) continue;\n    frozenEnvs[key] = process.env?.[key] || null;\n  }\n\n  var envResult = `# Auto-dump ENV from system call on ${new Date().toTimeString()}\\n`;\n  envResult += Object.entries(frozenEnvs)\n    .map(([key, value]) => {\n      return `${key}='${value}'`;\n    })\n    .join(\"\\n\");\n\n  const envPath = path.join(__dirname, \"../../.env\");\n  fs.writeFileSync(envPath, envResult, { encoding: \"utf8\", flag: \"w\" });\n  return true;\n}\n\nmodule.exports = {\n  dumpENV,\n  updateENV,\n};\n", "const { PrismaClient } = require(\"@prisma/client\");\nconst execSync = require(\"child_process\").execSync;\nconst fs = require(\"fs\");\nconst path = require(\"path\");\nrequire(\"dotenv\").config();\n\nconst DATABASE_PATH = process.env.DB_URL || \"../../storage/anythingllm.db\";\nconst BACKUP_PATH = path.join(\n  path.dirname(DATABASE_PATH),\n  \"anythingllm_backup.db\"\n);\n\n// Backup the database before migrating data\nfunction backupDatabase() {\n  try {\n    fs.copyFileSync(DATABASE_PATH, BACKUP_PATH);\n    console.log(\"Database backup created successfully.\");\n  } catch (error) {\n    console.error(\"Failed to create database backup:\", error);\n  }\n}\n\nbackupDatabase();\n\nconst prisma = new PrismaClient();\n\n// Reset the prisma database and prepare it for migration of data from sqlite\nfunction resetAndMigrateDatabase() {\n  try {\n    console.log(\"Resetting and migrating the database...\");\n    execSync(\"cd ../.. && npx prisma migrate reset --skip-seed --force\", {\n      stdio: \"inherit\",\n    });\n    execSync(\"cd ../.. && npx prisma migrate dev --name init\", {\n      stdio: \"inherit\",\n    });\n    console.log(\"Database reset and initial migration completed successfully\");\n  } catch (error) {\n    console.error(\"Failed to reset and migrate the database:\", error);\n  }\n}\n\nresetAndMigrateDatabase();\n\n// Migrate data from sqlite to prisma\nasync function migrateData() {\n  try {\n    console.log(\"Starting data migration...\");\n    var legacyMap = {\n      users: {\n        count: 0,\n      },\n      workspaces: {\n        count: 0,\n      },\n    };\n\n    // Step 1: Migrate system_settings table\n    await migrateTable(\"system_settings\", (row) => {\n      return prisma.system_settings.create({\n        data: {\n          label: row.label,\n          value: row.value,\n          createdAt: new Date(row.createdAt),\n          lastUpdatedAt: new Date(row.lastUpdatedAt),\n        },\n      });\n    });\n\n    // Step 2: Migrate users table\n    await migrateTable(\"users\", (row) => {\n      legacyMap.users[`user_${row.id}`] = legacyMap.users.count + 1;\n      legacyMap.users.count++;\n\n      return prisma.users.create({\n        data: {\n          username: row.username,\n          password: row.password,\n          role: row.role,\n          suspended: row.suspended,\n          createdAt: new Date(row.createdAt),\n          lastUpdatedAt: new Date(row.lastUpdatedAt),\n        },\n      });\n    });\n\n    // Step 3: Migrate workspaces table\n    await migrateTable(\"workspaces\", (row) => {\n      legacyMap.workspaces[`workspace_${row.id}`] =\n        legacyMap.workspaces.count + 1;\n      legacyMap.workspaces.count++;\n\n      return prisma.workspaces.create({\n        data: {\n          name: row.name,\n          slug: row.slug,\n          vectorTag: row.vectorTag,\n          openAiTemp: Number(row.openAiTemp) || 0.7,\n          openAiHistory: Number(row.openAiHistory) || 20,\n          openAiPrompt: row.openAiPrompt,\n          createdAt: new Date(row.createdAt),\n          lastUpdatedAt: new Date(row.lastUpdatedAt),\n        },\n      });\n    });\n\n    // Step 4: Migrate api_keys table\n    await migrateTable(\"api_keys\", async (row) => {\n      const legacyUserId = row.createdBy\n        ? legacyMap.users?.[`user_${row.createdBy}`]\n        : null;\n      return prisma.api_keys.create({\n        data: {\n          secret: row.secret,\n          ...(legacyUserId\n            ? { createdBy: Number(legacyUserId) }\n            : { createdBy: Number(row.createdBy) }),\n          createdAt: new Date(row.createdAt),\n          lastUpdatedAt: new Date(row.lastUpdatedAt),\n        },\n      });\n    });\n\n    // Step 5: Migrate invites table\n    await migrateTable(\"invites\", async (row) => {\n      const legacyCreatedUserId = row.createdBy\n        ? legacyMap.users?.[`user_${row.createdBy}`]\n        : null;\n      const legacyClaimedUserId = row.claimedBy\n        ? legacyMap.users?.[`user_${row.claimedBy}`]\n        : null;\n\n      return prisma.invites.create({\n        data: {\n          code: row.code,\n          status: row.status,\n          ...(legacyClaimedUserId\n            ? { claimedBy: Number(legacyClaimedUserId) }\n            : { claimedBy: Number(row.claimedBy) }),\n          ...(legacyCreatedUserId\n            ? { createdBy: Number(legacyCreatedUserId) }\n            : { createdBy: Number(row.createdBy) }),\n          createdAt: new Date(row.createdAt),\n          lastUpdatedAt: new Date(row.lastUpdatedAt),\n        },\n      });\n    });\n\n    // Step 6: Migrate workspace_documents table\n    await migrateTable(\"workspace_documents\", async (row) => {\n      const legacyWorkspaceId = row.workspaceId\n        ? legacyMap.workspaces?.[`workspace_${row.workspaceId}`]\n        : null;\n\n      return prisma.workspace_documents.create({\n        data: {\n          docId: row.docId,\n          filename: row.filename,\n          docpath: row.docpath,\n          ...(legacyWorkspaceId\n            ? { workspaceId: Number(legacyWorkspaceId) }\n            : {}),\n          metadata: row.metadata,\n          createdAt: new Date(row.createdAt),\n          lastUpdatedAt: new Date(row.lastUpdatedAt),\n        },\n      });\n    });\n\n    // Step 7: Migrate document_vectors table\n    await migrateTable(\"document_vectors\", (row) => {\n      return prisma.document_vectors.create({\n        data: {\n          docId: row.docId,\n          vectorId: row.vectorId,\n          createdAt: new Date(row.createdAt),\n          lastUpdatedAt: new Date(row.lastUpdatedAt),\n        },\n      });\n    });\n\n    // Step 8: Migrate welcome_messages table\n    await migrateTable(\"welcome_messages\", (row) => {\n      return prisma.welcome_messages.create({\n        data: {\n          user: row.user,\n          response: row.response,\n          orderIndex: row.orderIndex,\n          createdAt: new Date(row.createdAt),\n        },\n      });\n    });\n\n    // Step 9: Migrate workspace_users table\n    await migrateTable(\"workspace_users\", async (row) => {\n      const legacyUserId = row.user_id\n        ? legacyMap.users?.[`user_${row.user_id}`]\n        : null;\n      const legacyWorkspaceId = row.workspace_id\n        ? legacyMap.workspaces?.[`workspace_${row.workspace_id}`]\n        : null;\n\n      if (!legacyUserId || !legacyWorkspaceId) return;\n\n      return prisma.workspace_users.create({\n        data: {\n          user_id: Number(legacyUserId),\n          workspace_id: Number(legacyWorkspaceId),\n          createdAt: new Date(row.createdAt),\n          lastUpdatedAt: new Date(row.lastUpdatedAt),\n        },\n      });\n    });\n\n    // Step 10: Migrate workspace_chats table\n    await migrateTable(\"workspace_chats\", async (row) => {\n      const legacyUserId = row.user_id\n        ? legacyMap.users?.[`user_${row.user_id}`]\n        : null;\n      const legacyWorkspaceId = row.workspaceId\n        ? legacyMap.workspaces?.[`workspace_${row.workspaceId}`]\n        : null;\n\n      return prisma.workspace_chats.create({\n        data: {\n          workspaceId: Number(legacyWorkspaceId),\n          prompt: row.prompt,\n          response: row.response,\n          include: row.include === 1,\n          ...(legacyUserId ? { user_id: Number(legacyUserId) } : {}),\n          createdAt: new Date(row.createdAt),\n          lastUpdatedAt: new Date(row.lastUpdatedAt),\n        },\n      });\n    });\n\n    console.log(\"Data migration completed successfully\");\n  } catch (error) {\n    console.error(\"Data migration failed:\", error);\n  } finally {\n    await prisma.$disconnect();\n  }\n}\n\nasync function migrateTable(tableName, migrateRowFunc) {\n  const sqlite3 = require(\"sqlite3\").verbose();\n  const { open } = require(\"sqlite\");\n  const db = await open({\n    filename: BACKUP_PATH,\n    driver: sqlite3.Database,\n  });\n\n  // Check table exists\n  const { count } = await db.get(\n    `SELECT COUNT(*) as count FROM sqlite_master WHERE name='${tableName}'`\n  )\n  if (count === 0) {\n    console.log(\n      `${tableName} does not exist in legacy DB - nothing to migrate - skipping.`\n    );\n    return;\n  }\n\n  const upserts = [];\n  const rows = await db.all(`SELECT * FROM ${tableName}`);\n\n  try {\n    for (const row of rows) {\n      await migrateRowFunc(row);\n      upserts.push(row);\n    }\n  } catch (e) {\n    console.error(e);\n    console.log({ tableName, upserts });\n  } finally {\n    await db.close();\n  }\n  return;\n}\n\nmigrateData();\n"], "fixing_code": ["process.env.NODE_ENV === \"development\"\n  ? require(\"dotenv\").config({ path: `.env.${process.env.NODE_ENV}` })\n  : require(\"dotenv\").config();\nconst { viewLocalFiles } = require(\"../utils/files\");\nconst { exportData, unpackAndOverwriteImport } = require(\"../utils/files/data\");\nconst {\n  checkPythonAppAlive,\n  acceptedFileTypes,\n} = require(\"../utils/files/documentProcessor\");\nconst { purgeDocument } = require(\"../utils/files/purgeDocument\");\nconst { getVectorDbClass } = require(\"../utils/helpers\");\nconst { updateENV, dumpENV } = require(\"../utils/helpers/updateENV\");\nconst {\n  reqBody,\n  makeJWT,\n  userFromSession,\n  multiUserMode,\n} = require(\"../utils/http\");\nconst { setupDataImports, setupLogoUploads } = require(\"../utils/files/multer\");\nconst { v4 } = require(\"uuid\");\nconst { SystemSettings } = require(\"../models/systemSettings\");\nconst { User } = require(\"../models/user\");\nconst { validatedRequest } = require(\"../utils/middleware/validatedRequest\");\nconst { handleImports } = setupDataImports();\nconst { handleLogoUploads } = setupLogoUploads();\nconst fs = require(\"fs\");\nconst path = require(\"path\");\nconst {\n  getDefaultFilename,\n  determineLogoFilepath,\n  fetchLogo,\n  validFilename,\n  renameLogoFile,\n  removeCustomLogo,\n  DARK_LOGO_FILENAME,\n} = require(\"../utils/files/logo\");\nconst { Telemetry } = require(\"../models/telemetry\");\nconst { WelcomeMessages } = require(\"../models/welcomeMessages\");\nconst { ApiKey } = require(\"../models/apiKeys\");\n\nfunction systemEndpoints(app) {\n  if (!app) return;\n\n  app.get(\"/ping\", (_, response) => {\n    response.status(200).json({ online: true });\n  });\n\n  app.get(\"/migrate\", async (_, response) => {\n    const execSync = require(\"child_process\").execSync;\n    execSync(\"npx prisma migrate deploy --schema=./prisma/schema.prisma\", {\n      stdio: \"inherit\",\n    });\n    response.sendStatus(200);\n  });\n\n  app.get(\"/env-dump\", async (_, response) => {\n    if (process.env.NODE_ENV !== \"production\")\n      return response.sendStatus(200).end();\n    await dumpENV();\n    response.sendStatus(200).end();\n  });\n\n  app.get(\"/setup-complete\", async (_, response) => {\n    try {\n      const results = await SystemSettings.currentSettings();\n      response.status(200).json({ results });\n    } catch (e) {\n      console.log(e.message, e);\n      response.sendStatus(500).end();\n    }\n  });\n\n  app.get(\n    \"/system/check-token\",\n    [validatedRequest],\n    async (request, response) => {\n      try {\n        if (multiUserMode(response)) {\n          const user = await userFromSession(request, response);\n          if (!user || user.suspended) {\n            response.sendStatus(403).end();\n            return;\n          }\n\n          response.sendStatus(200).end();\n          return;\n        }\n\n        response.sendStatus(200).end();\n      } catch (e) {\n        console.log(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.post(\"/request-token\", async (request, response) => {\n    try {\n      if (await SystemSettings.isMultiUserMode()) {\n        const { username, password } = reqBody(request);\n        const existingUser = await User.get({ username });\n\n        if (!existingUser) {\n          response.status(200).json({\n            user: null,\n            valid: false,\n            token: null,\n            message: \"[001] Invalid login credentials.\",\n          });\n          return;\n        }\n\n        const bcrypt = require(\"bcrypt\");\n        if (!bcrypt.compareSync(password, existingUser.password)) {\n          response.status(200).json({\n            user: null,\n            valid: false,\n            token: null,\n            message: \"[002] Invalid login credentials.\",\n          });\n          return;\n        }\n\n        if (existingUser.suspended) {\n          response.status(200).json({\n            user: null,\n            valid: false,\n            token: null,\n            message: \"[004] Account suspended by admin.\",\n          });\n          return;\n        }\n\n        response.status(200).json({\n          valid: true,\n          user: existingUser,\n          token: makeJWT(\n            { id: existingUser.id, username: existingUser.username },\n            \"30d\"\n          ),\n          message: null,\n        });\n        return;\n      } else {\n        const { password } = reqBody(request);\n        if (password !== process.env.AUTH_TOKEN) {\n          response.status(401).json({\n            valid: false,\n            token: null,\n            message: \"[003] Invalid password provided\",\n          });\n          return;\n        }\n\n        response.status(200).json({\n          valid: true,\n          token: makeJWT({ p: password }, \"30d\"),\n          message: null,\n        });\n      }\n    } catch (e) {\n      console.log(e.message, e);\n      response.sendStatus(500).end();\n    }\n  });\n\n  app.get(\"/system/system-vectors\", [validatedRequest], async (_, response) => {\n    try {\n      const VectorDb = getVectorDbClass();\n      const vectorCount = await VectorDb.totalVectors();\n      response.status(200).json({ vectorCount });\n    } catch (e) {\n      console.log(e.message, e);\n      response.sendStatus(500).end();\n    }\n  });\n\n  app.delete(\n    \"/system/remove-document\",\n    [validatedRequest],\n    async (request, response) => {\n      try {\n        const { name, meta } = reqBody(request);\n        await purgeDocument(name, meta);\n        response.sendStatus(200).end();\n      } catch (e) {\n        console.log(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.get(\"/system/local-files\", [validatedRequest], async (_, response) => {\n    try {\n      const localFiles = await viewLocalFiles();\n      response.status(200).json({ localFiles });\n    } catch (e) {\n      console.log(e.message, e);\n      response.sendStatus(500).end();\n    }\n  });\n\n  app.get(\n    \"/system/document-processing-status\",\n    [validatedRequest],\n    async (_, response) => {\n      try {\n        const online = await checkPythonAppAlive();\n        response.sendStatus(online ? 200 : 503);\n      } catch (e) {\n        console.log(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.get(\n    \"/system/accepted-document-types\",\n    [validatedRequest],\n    async (_, response) => {\n      try {\n        const types = await acceptedFileTypes();\n        if (!types) {\n          response.sendStatus(404).end();\n          return;\n        }\n\n        response.status(200).json({ types });\n      } catch (e) {\n        console.log(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.post(\n    \"/system/update-env\",\n    [validatedRequest],\n    async (request, response) => {\n      try {\n        const body = reqBody(request);\n\n        // Only admins can update the ENV settings.\n        if (multiUserMode(response)) {\n          const user = await userFromSession(request, response);\n          if (!user || user?.role !== \"admin\") {\n            response.sendStatus(401).end();\n            return;\n          }\n        }\n\n        const { newValues, error } = updateENV(body);\n        if (process.env.NODE_ENV === \"production\") await dumpENV();\n        response.status(200).json({ newValues, error });\n      } catch (e) {\n        console.log(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.post(\n    \"/system/update-password\",\n    [validatedRequest],\n    async (request, response) => {\n      try {\n        // Cannot update password in multi - user mode.\n        if (multiUserMode(response)) {\n          response.sendStatus(401).end();\n          return;\n        }\n\n        const { usePassword, newPassword } = reqBody(request);\n        const { error } = updateENV(\n          {\n            AuthToken: usePassword ? newPassword : \"\",\n            JWTSecret: usePassword ? v4() : \"\",\n          },\n          true\n        );\n        if (process.env.NODE_ENV === \"production\") await dumpENV();\n        response.status(200).json({ success: !error, error });\n      } catch (e) {\n        console.log(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.post(\n    \"/system/enable-multi-user\",\n    [validatedRequest],\n    async (request, response) => {\n      try {\n        const { username, password } = reqBody(request);\n        const multiUserModeEnabled = await SystemSettings.isMultiUserMode();\n        if (multiUserModeEnabled) {\n          response.status(200).json({\n            success: false,\n            error: \"Multi-user mode is already enabled.\",\n          });\n          return;\n        }\n\n        const { user, error } = await User.create({\n          username,\n          password,\n          role: \"admin\",\n        });\n        await SystemSettings.updateSettings({\n          multi_user_mode: true,\n          users_can_delete_workspaces: false,\n          limit_user_messages: false,\n          message_limit: 25,\n        });\n\n        updateENV(\n          {\n            AuthToken: null,\n            JWTSecret: process.env.JWT_SECRET ?? v4(),\n          },\n          true\n        );\n        if (process.env.NODE_ENV === \"production\") await dumpENV();\n        await Telemetry.sendTelemetry(\"enabled_multi_user_mode\");\n        response.status(200).json({ success: !!user, error });\n      } catch (e) {\n        console.log(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.get(\"/system/data-export\", [validatedRequest], async (_, response) => {\n    try {\n      const { filename, error } = await exportData();\n      response.status(200).json({ filename, error });\n    } catch (e) {\n      console.log(e.message, e);\n      response.sendStatus(500).end();\n    }\n  });\n\n  app.get(\n    \"/system/data-exports/:filename\",\n    [validatedRequest],\n    (request, response) => {\n      const exportLocation = __dirname + \"/../storage/exports/\";\n      const sanitized = path\n        .normalize(request.params.filename)\n        .replace(/^(\\.\\.(\\/|\\\\|$))+/, \"\");\n      const finalDestination = path.join(exportLocation, sanitized);\n\n      if (!fs.existsSync(finalDestination)) {\n        response.status(404).json({\n          error: 404,\n          msg: `File ${request.params.filename} does not exist in exports.`,\n        });\n        return;\n      }\n\n      response.download(finalDestination, request.params.filename, (err) => {\n        if (err) {\n          response.send({\n            error: err,\n            msg: \"Problem downloading the file\",\n          });\n        }\n      });\n    }\n  );\n\n  app.post(\n    \"/system/data-import\",\n    handleImports.single(\"file\"),\n    async function (request, response) {\n      const { originalname } = request.file;\n      const { success, error } = await unpackAndOverwriteImport(originalname);\n      response.status(200).json({ success, error });\n    }\n  );\n\n  app.get(\"/system/logo/:mode?\", async function (request, response) {\n    try {\n      const defaultFilename = getDefaultFilename(request.params.mode);\n      const logoPath = await determineLogoFilepath(defaultFilename);\n      const { buffer, size, mime } = fetchLogo(logoPath);\n      response.writeHead(200, {\n        \"Content-Type\": mime || \"image/png\",\n        \"Content-Disposition\": `attachment; filename=${path.basename(\n          logoPath\n        )}`,\n        \"Content-Length\": size,\n      });\n      response.end(Buffer.from(buffer, \"base64\"));\n      return;\n    } catch (error) {\n      console.error(\"Error processing the logo request:\", error);\n      response.status(500).json({ message: \"Internal server error\" });\n    }\n  });\n\n  app.post(\n    \"/system/upload-logo\",\n    [validatedRequest],\n    handleLogoUploads.single(\"logo\"),\n    async (request, response) => {\n      if (!request.file || !request.file.originalname) {\n        return response.status(400).json({ message: \"No logo file provided.\" });\n      }\n\n      if (!validFilename(request.file.originalname)) {\n        return response.status(400).json({\n          message: \"Invalid file name. Please choose a different file.\",\n        });\n      }\n\n      try {\n        if (\n          response.locals.multiUserMode &&\n          response.locals.user?.role !== \"admin\"\n        ) {\n          return response.sendStatus(401).end();\n        }\n\n        const newFilename = await renameLogoFile(request.file.originalname);\n        const existingLogoFilename = await SystemSettings.currentLogoFilename();\n        await removeCustomLogo(existingLogoFilename);\n\n        const { success, error } = await SystemSettings.updateSettings({\n          logo_filename: newFilename,\n        });\n\n        return response.status(success ? 200 : 500).json({\n          message: success\n            ? \"Logo uploaded successfully.\"\n            : error || \"Failed to update with new logo.\",\n        });\n      } catch (error) {\n        console.error(\"Error processing the logo upload:\", error);\n        response.status(500).json({ message: \"Error uploading the logo.\" });\n      }\n    }\n  );\n\n  app.get(\n    \"/system/remove-logo\",\n    [validatedRequest],\n    async (request, response) => {\n      try {\n        if (\n          response.locals.multiUserMode &&\n          response.locals.user?.role !== \"admin\"\n        ) {\n          return response.sendStatus(401).end();\n        }\n\n        const currentLogoFilename = await SystemSettings.currentLogoFilename();\n        await removeCustomLogo(currentLogoFilename);\n        const { success, error } = await SystemSettings.updateSettings({\n          logo_filename: DARK_LOGO_FILENAME,\n        });\n\n        return response.status(success ? 200 : 500).json({\n          message: success\n            ? \"Logo removed successfully.\"\n            : error || \"Failed to update with new logo.\",\n        });\n      } catch (error) {\n        console.error(\"Error processing the logo removal:\", error);\n        response.status(500).json({ message: \"Error removing the logo.\" });\n      }\n    }\n  );\n\n  app.get(\n    \"/system/can-delete-workspaces\",\n    [validatedRequest],\n    async function (request, response) {\n      try {\n        if (!response.locals.multiUserMode) {\n          return response.status(200).json({ canDelete: true });\n        }\n\n        if (response.locals.user?.role === \"admin\") {\n          return response.status(200).json({ canDelete: true });\n        }\n\n        const canDelete = await SystemSettings.canDeleteWorkspaces();\n        response.status(200).json({ canDelete });\n      } catch (error) {\n        console.error(\"Error fetching can delete workspaces:\", error);\n        response.status(500).json({\n          success: false,\n          message: \"Internal server error\",\n          canDelete: false,\n        });\n      }\n    }\n  );\n\n  app.get(\"/system/welcome-messages\", async function (request, response) {\n    try {\n      const welcomeMessages = await WelcomeMessages.getMessages();\n      response.status(200).json({ success: true, welcomeMessages });\n    } catch (error) {\n      console.error(\"Error fetching welcome messages:\", error);\n      response\n        .status(500)\n        .json({ success: false, message: \"Internal server error\" });\n    }\n  });\n\n  app.post(\n    \"/system/set-welcome-messages\",\n    [validatedRequest],\n    async (request, response) => {\n      try {\n        if (\n          response.locals.multiUserMode &&\n          response.locals.user?.role !== \"admin\"\n        ) {\n          return response.sendStatus(401).end();\n        }\n\n        const { messages = [] } = reqBody(request);\n        if (!Array.isArray(messages)) {\n          return response.status(400).json({\n            success: false,\n            message: \"Invalid message format. Expected an array of messages.\",\n          });\n        }\n\n        await WelcomeMessages.saveAll(messages);\n        return response.status(200).json({\n          success: true,\n          message: \"Welcome messages saved successfully.\",\n        });\n      } catch (error) {\n        console.error(\"Error processing the welcome messages:\", error);\n        response.status(500).json({\n          success: true,\n          message: \"Error saving the welcome messages.\",\n        });\n      }\n    }\n  );\n\n  app.get(\"/system/api-key\", [validatedRequest], async (_, response) => {\n    try {\n      if (response.locals.multiUserMode) {\n        return response.sendStatus(401).end();\n      }\n\n      const apiKey = await ApiKey.get({});\n      return response.status(200).json({\n        apiKey,\n        error: null,\n      });\n    } catch (error) {\n      console.error(error);\n      response.status(500).json({\n        apiKey: null,\n        error: \"Could not find an API Key.\",\n      });\n    }\n  });\n\n  app.post(\n    \"/system/generate-api-key\",\n    [validatedRequest],\n    async (_, response) => {\n      try {\n        if (response.locals.multiUserMode) {\n          return response.sendStatus(401).end();\n        }\n\n        await ApiKey.delete();\n        const { apiKey, error } = await ApiKey.create();\n        return response.status(200).json({\n          apiKey,\n          error,\n        });\n      } catch (error) {\n        console.error(error);\n        response.status(500).json({\n          apiKey: null,\n          error: \"Error generating api key.\",\n        });\n      }\n    }\n  );\n\n  app.delete(\"/system/api-key\", [validatedRequest], async (_, response) => {\n    try {\n      if (response.locals.multiUserMode) {\n        return response.sendStatus(401).end();\n      }\n\n      await ApiKey.delete();\n      return response.status(200).end();\n    } catch (error) {\n      console.error(error);\n      response.status(500).end();\n    }\n  });\n}\n\nmodule.exports = { systemEndpoints };\n", "const KEY_MAPPING = {\n  LLMProvider: {\n    envKey: \"LLM_PROVIDER\",\n    checks: [isNotEmpty, supportedLLM],\n  },\n  // OpenAI Settings\n  OpenAiKey: {\n    envKey: \"OPEN_AI_KEY\",\n    checks: [isNotEmpty, validOpenAIKey],\n  },\n  OpenAiModelPref: {\n    envKey: \"OPEN_MODEL_PREF\",\n    checks: [isNotEmpty, validOpenAIModel],\n  },\n  // Azure OpenAI Settings\n  AzureOpenAiEndpoint: {\n    envKey: \"AZURE_OPENAI_ENDPOINT\",\n    checks: [isNotEmpty, validAzureURL],\n  },\n  AzureOpenAiKey: {\n    envKey: \"AZURE_OPENAI_KEY\",\n    checks: [isNotEmpty],\n  },\n  AzureOpenAiModelPref: {\n    envKey: \"OPEN_MODEL_PREF\",\n    checks: [isNotEmpty],\n  },\n  AzureOpenAiEmbeddingModelPref: {\n    envKey: \"EMBEDDING_MODEL_PREF\",\n    checks: [isNotEmpty],\n  },\n\n  // Vector Database Selection Settings\n  VectorDB: {\n    envKey: \"VECTOR_DB\",\n    checks: [isNotEmpty, supportedVectorDB],\n  },\n  ChromaEndpoint: {\n    envKey: \"CHROMA_ENDPOINT\",\n    checks: [isValidURL, validChromaURL],\n  },\n  WeaviateEndpoint: {\n    envKey: \"WEAVIATE_ENDPOINT\",\n    checks: [isValidURL],\n  },\n  WeaviateApiKey: {\n    envKey: \"WEAVIATE_API_KEY\",\n    checks: [],\n  },\n  QdrantEndpoint: {\n    envKey: \"QDRANT_ENDPOINT\",\n    checks: [isValidURL],\n  },\n  QdrantApiKey: {\n    envKey: \"QDRANT_API_KEY\",\n    checks: [],\n  },\n\n  PineConeEnvironment: {\n    envKey: \"PINECONE_ENVIRONMENT\",\n    checks: [],\n  },\n  PineConeKey: {\n    envKey: \"PINECONE_API_KEY\",\n    checks: [],\n  },\n  PineConeIndex: {\n    envKey: \"PINECONE_INDEX\",\n    checks: [],\n  },\n\n  // System Settings\n  AuthToken: {\n    envKey: \"AUTH_TOKEN\",\n    checks: [requiresForceMode],\n  },\n  JWTSecret: {\n    envKey: \"JWT_SECRET\",\n    checks: [requiresForceMode],\n  },\n  // Not supported yet.\n  // 'StorageDir': 'STORAGE_DIR',\n};\n\nfunction isNotEmpty(input = \"\") {\n  return !input || input.length === 0 ? \"Value cannot be empty\" : null;\n}\n\nfunction isValidURL(input = \"\") {\n  try {\n    new URL(input);\n    return null;\n  } catch (e) {\n    return \"URL is not a valid URL.\";\n  }\n}\n\nfunction validOpenAIKey(input = \"\") {\n  return input.startsWith(\"sk-\") ? null : \"OpenAI Key must start with sk-\";\n}\n\nfunction supportedLLM(input = \"\") {\n  return [\"openai\", \"azure\"].includes(input);\n}\n\nfunction validOpenAIModel(input = \"\") {\n  const validModels = [\n    \"gpt-4\",\n    \"gpt-4-0613\",\n    \"gpt-4-32k\",\n    \"gpt-4-32k-0613\",\n    \"gpt-3.5-turbo\",\n    \"gpt-3.5-turbo-0613\",\n    \"gpt-3.5-turbo-16k\",\n    \"gpt-3.5-turbo-16k-0613\",\n  ];\n  return validModels.includes(input)\n    ? null\n    : `Invalid Model type. Must be one of ${validModels.join(\", \")}.`;\n}\n\nfunction supportedVectorDB(input = \"\") {\n  const supported = [\"chroma\", \"pinecone\", \"lancedb\", \"weaviate\", \"qdrant\"];\n  return supported.includes(input)\n    ? null\n    : `Invalid VectorDB type. Must be one of ${supported.join(\", \")}.`;\n}\n\nfunction validChromaURL(input = \"\") {\n  return input.slice(-1) === \"/\"\n    ? `Chroma Instance URL should not end in a trailing slash.`\n    : null;\n}\n\nfunction validAzureURL(input = \"\") {\n  try {\n    new URL(input);\n    if (!input.includes(\"openai.azure.com\"))\n      return \"URL must include openai.azure.com\";\n    return null;\n  } catch {\n    return \"Not a valid URL\";\n  }\n}\n\nfunction requiresForceMode(_, forceModeEnabled = false) {\n  return forceModeEnabled === true ? null : \"Cannot set this setting.\";\n}\n\n// This will force update .env variables which for any which reason were not able to be parsed or\n// read from an ENV file as this seems to be a complicating step for many so allowing people to write\n// to the process will at least alleviate that issue. It does not perform comprehensive validity checks or sanity checks\n// and is simply for debugging when the .env not found issue many come across.\nfunction updateENV(newENVs = {}, force = false) {\n  let error = \"\";\n  const validKeys = Object.keys(KEY_MAPPING);\n  const ENV_KEYS = Object.keys(newENVs).filter(\n    (key) => validKeys.includes(key) && !newENVs[key].includes(\"******\") // strip out answers where the value is all asterisks\n  );\n  const newValues = {};\n\n  ENV_KEYS.forEach((key) => {\n    const { envKey, checks } = KEY_MAPPING[key];\n    const value = newENVs[key];\n    const errors = checks\n      .map((validityCheck) => validityCheck(value, force))\n      .filter((err) => typeof err === \"string\");\n\n    if (errors.length > 0) {\n      error += errors.join(\"\\n\");\n      return;\n    }\n\n    newValues[key] = value;\n    process.env[envKey] = value;\n  });\n\n  return { newValues, error: error?.length > 0 ? error : false };\n}\n\nasync function dumpENV() {\n  const fs = require(\"fs\");\n  const path = require(\"path\");\n\n  const frozenEnvs = {};\n  const protectedKeys = [\n    ...Object.values(KEY_MAPPING).map((values) => values.envKey),\n    \"CACHE_VECTORS\",\n    \"STORAGE_DIR\",\n    \"SERVER_PORT\",\n  ];\n\n  for (const key of protectedKeys) {\n    const envValue = process.env?.[key] || null;\n    if (!envValue) continue;\n    frozenEnvs[key] = process.env?.[key] || null;\n  }\n\n  var envResult = `# Auto-dump ENV from system call on ${new Date().toTimeString()}\\n`;\n  envResult += Object.entries(frozenEnvs)\n    .map(([key, value]) => {\n      return `${key}='${value}'`;\n    })\n    .join(\"\\n\");\n\n  const envPath = path.join(__dirname, \"../../.env\");\n  fs.writeFileSync(envPath, envResult, { encoding: \"utf8\", flag: \"w\" });\n  return true;\n}\n\nmodule.exports = {\n  dumpENV,\n  updateENV,\n};\n", "const { PrismaClient } = require(\"@prisma/client\");\nconst execSync = require(\"child_process\").execSync;\nconst fs = require(\"fs\");\nconst path = require(\"path\");\nrequire(\"dotenv\").config();\n\nconst DATABASE_PATH = process.env.DB_URL || \"../../storage/anythingllm.db\";\nconst BACKUP_PATH = path.join(\n  path.dirname(DATABASE_PATH),\n  \"anythingllm_backup.db\"\n);\n\n// Backup the database before migrating data\nfunction backupDatabase() {\n  try {\n    fs.copyFileSync(DATABASE_PATH, BACKUP_PATH);\n    console.log(\"Database backup created successfully.\");\n  } catch (error) {\n    console.error(\"Failed to create database backup:\", error);\n  }\n}\n\nbackupDatabase();\n\nconst prisma = new PrismaClient();\n\n// Reset the prisma database and prepare it for migration of data from sqlite\nfunction resetAndMigrateDatabase() {\n  try {\n    console.log(\"Resetting and migrating the database...\");\n    execSync(\"cd ../.. && npx prisma migrate reset --skip-seed --force\", {\n      stdio: \"inherit\",\n    });\n    execSync(\"cd ../.. && npx prisma migrate dev --name init\", {\n      stdio: \"inherit\",\n    });\n    console.log(\"Database reset and initial migration completed successfully\");\n  } catch (error) {\n    console.error(\"Failed to reset and migrate the database:\", error);\n  }\n}\n\nresetAndMigrateDatabase();\n\n// Migrate data from sqlite to prisma\nasync function migrateData() {\n  try {\n    console.log(\"Starting data migration...\");\n    var legacyMap = {\n      users: {\n        count: 0,\n      },\n      workspaces: {\n        count: 0,\n      },\n    };\n\n    // Step 1: Migrate system_settings table\n    await migrateTable(\"system_settings\", (row) => {\n      return prisma.system_settings.create({\n        data: {\n          label: row.label,\n          value: row.value,\n          createdAt: new Date(row.createdAt),\n          lastUpdatedAt: new Date(row.lastUpdatedAt),\n        },\n      });\n    });\n\n    // Step 2: Migrate users table\n    await migrateTable(\"users\", (row) => {\n      legacyMap.users[`user_${row.id}`] = legacyMap.users.count + 1;\n      legacyMap.users.count++;\n\n      return prisma.users.create({\n        data: {\n          username: row.username,\n          password: row.password,\n          role: row.role,\n          suspended: row.suspended,\n          createdAt: new Date(row.createdAt),\n          lastUpdatedAt: new Date(row.lastUpdatedAt),\n        },\n      });\n    });\n\n    // Step 3: Migrate workspaces table\n    await migrateTable(\"workspaces\", (row) => {\n      legacyMap.workspaces[`workspace_${row.id}`] =\n        legacyMap.workspaces.count + 1;\n      legacyMap.workspaces.count++;\n\n      return prisma.workspaces.create({\n        data: {\n          name: row.name,\n          slug: row.slug,\n          vectorTag: row.vectorTag,\n          openAiTemp: Number(row.openAiTemp) || 0.7,\n          openAiHistory: Number(row.openAiHistory) || 20,\n          openAiPrompt: row.openAiPrompt,\n          createdAt: new Date(row.createdAt),\n          lastUpdatedAt: new Date(row.lastUpdatedAt),\n        },\n      });\n    });\n\n    // Step 4: Migrate api_keys table\n    await migrateTable(\"api_keys\", async (row) => {\n      const legacyUserId = row.createdBy\n        ? legacyMap.users?.[`user_${row.createdBy}`]\n        : null;\n      return prisma.api_keys.create({\n        data: {\n          secret: row.secret,\n          ...(legacyUserId\n            ? { createdBy: Number(legacyUserId) }\n            : { createdBy: Number(row.createdBy) }),\n          createdAt: new Date(row.createdAt),\n          lastUpdatedAt: new Date(row.lastUpdatedAt),\n        },\n      });\n    });\n\n    // Step 5: Migrate invites table\n    await migrateTable(\"invites\", async (row) => {\n      const legacyCreatedUserId = row.createdBy\n        ? legacyMap.users?.[`user_${row.createdBy}`]\n        : null;\n      const legacyClaimedUserId = row.claimedBy\n        ? legacyMap.users?.[`user_${row.claimedBy}`]\n        : null;\n\n      return prisma.invites.create({\n        data: {\n          code: row.code,\n          status: row.status,\n          ...(legacyClaimedUserId\n            ? { claimedBy: Number(legacyClaimedUserId) }\n            : { claimedBy: Number(row.claimedBy) }),\n          ...(legacyCreatedUserId\n            ? { createdBy: Number(legacyCreatedUserId) }\n            : { createdBy: Number(row.createdBy) }),\n          createdAt: new Date(row.createdAt),\n          lastUpdatedAt: new Date(row.lastUpdatedAt),\n        },\n      });\n    });\n\n    // Step 6: Migrate workspace_documents table\n    await migrateTable(\"workspace_documents\", async (row) => {\n      const legacyWorkspaceId = row.workspaceId\n        ? legacyMap.workspaces?.[`workspace_${row.workspaceId}`]\n        : null;\n\n      return prisma.workspace_documents.create({\n        data: {\n          docId: row.docId,\n          filename: row.filename,\n          docpath: row.docpath,\n          ...(legacyWorkspaceId\n            ? { workspaceId: Number(legacyWorkspaceId) }\n            : {}),\n          metadata: row.metadata,\n          createdAt: new Date(row.createdAt),\n          lastUpdatedAt: new Date(row.lastUpdatedAt),\n        },\n      });\n    });\n\n    // Step 7: Migrate document_vectors table\n    await migrateTable(\"document_vectors\", (row) => {\n      return prisma.document_vectors.create({\n        data: {\n          docId: row.docId,\n          vectorId: row.vectorId,\n          createdAt: new Date(row.createdAt),\n          lastUpdatedAt: new Date(row.lastUpdatedAt),\n        },\n      });\n    });\n\n    // Step 8: Migrate welcome_messages table\n    await migrateTable(\"welcome_messages\", (row) => {\n      return prisma.welcome_messages.create({\n        data: {\n          user: row.user,\n          response: row.response,\n          orderIndex: row.orderIndex,\n          createdAt: new Date(row.createdAt),\n        },\n      });\n    });\n\n    // Step 9: Migrate workspace_users table\n    await migrateTable(\"workspace_users\", async (row) => {\n      const legacyUserId = row.user_id\n        ? legacyMap.users?.[`user_${row.user_id}`]\n        : null;\n      const legacyWorkspaceId = row.workspace_id\n        ? legacyMap.workspaces?.[`workspace_${row.workspace_id}`]\n        : null;\n\n      if (!legacyUserId || !legacyWorkspaceId) return;\n\n      return prisma.workspace_users.create({\n        data: {\n          user_id: Number(legacyUserId),\n          workspace_id: Number(legacyWorkspaceId),\n          createdAt: new Date(row.createdAt),\n          lastUpdatedAt: new Date(row.lastUpdatedAt),\n        },\n      });\n    });\n\n    // Step 10: Migrate workspace_chats table\n    await migrateTable(\"workspace_chats\", async (row) => {\n      const legacyUserId = row.user_id\n        ? legacyMap.users?.[`user_${row.user_id}`]\n        : null;\n      const legacyWorkspaceId = row.workspaceId\n        ? legacyMap.workspaces?.[`workspace_${row.workspaceId}`]\n        : null;\n\n      return prisma.workspace_chats.create({\n        data: {\n          workspaceId: Number(legacyWorkspaceId),\n          prompt: row.prompt,\n          response: row.response,\n          include: row.include === 1,\n          ...(legacyUserId ? { user_id: Number(legacyUserId) } : {}),\n          createdAt: new Date(row.createdAt),\n          lastUpdatedAt: new Date(row.lastUpdatedAt),\n        },\n      });\n    });\n\n    console.log(\"Data migration completed successfully\");\n  } catch (error) {\n    console.error(\"Data migration failed:\", error);\n  } finally {\n    await prisma.$disconnect();\n  }\n}\n\nasync function migrateTable(tableName, migrateRowFunc) {\n  const sqlite3 = require(\"sqlite3\").verbose();\n  const { open } = require(\"sqlite\");\n  const db = await open({\n    filename: BACKUP_PATH,\n    driver: sqlite3.Database,\n  });\n\n  // Check table exists\n  const { count } = await db.get(\n    `SELECT COUNT(*) as count FROM sqlite_master WHERE name='${tableName}'`\n  );\n  if (count === 0) {\n    console.log(\n      `${tableName} does not exist in legacy DB - nothing to migrate - skipping.`\n    );\n    return;\n  }\n\n  const upserts = [];\n  const rows = await db.all(`SELECT * FROM ${tableName}`);\n\n  try {\n    for (const row of rows) {\n      await migrateRowFunc(row);\n      upserts.push(row);\n    }\n  } catch (e) {\n    console.error(e);\n    console.log({ tableName, upserts });\n  } finally {\n    await db.close();\n  }\n  return;\n}\n\nmigrateData();\n"], "filenames": ["server/endpoints/system.js", "server/utils/helpers/updateENV.js", "server/utils/prisma/migrateFromSqlite.js"], "buggy_code_start_loc": [241, 75, 256], "buggy_code_end_loc": [298, 163, 257], "fixing_code_start_loc": [242, 75, 256], "fixing_code_end_loc": [325, 167, 257], "type": "CWE-284", "message": "Improper Access Control in GitHub repository mintplex-labs/anything-llm prior to 0.1.0.", "other": {"cve": {"id": "CVE-2023-5833", "sourceIdentifier": "security@huntr.dev", "published": "2023-10-30T13:15:31.917", "lastModified": "2023-11-08T13:22:27.337", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Improper Access Control in GitHub repository mintplex-labs/anything-llm prior to 0.1.0."}, {"lang": "es", "value": "Control de acceso inadecuado en el repositorio de GitHub mintplex-labs/anything-llm anterior a 0.1.0."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.8, "impactScore": 5.9}], "cvssMetricV30": [{"source": "security@huntr.dev", "type": "Secondary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "NONE", "baseScore": 8.1, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.8, "impactScore": 5.2}]}, "weaknesses": [{"source": "security@huntr.dev", "type": "Primary", "description": [{"lang": "en", "value": "CWE-284"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:mintplexlabs:anythingllm:*:*:*:*:*:*:*:*", "versionEndExcluding": "0.1.0", "matchCriteriaId": "D3415DEB-007D-4160-B318-C69CC1335DB9"}]}]}], "references": [{"url": "https://github.com/mintplex-labs/anything-llm/commit/d5b1f84a4c7991987eac3454d4f1b4067841d783", "source": "security@huntr.dev", "tags": ["Patch"]}, {"url": "https://huntr.com/bounties/00ec6847-125b-43e9-9658-d3cace1751d6", "source": "security@huntr.dev", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/mintplex-labs/anything-llm/commit/d5b1f84a4c7991987eac3454d4f1b4067841d783"}}
{"buggy_code": ["// Package criteria implements a Criteria API based on Masterminds/squirrel\npackage criteria\n\nimport (\n\t\"encoding/json\"\n\t\"errors\"\n\t\"strings\"\n\n\t\"github.com/navidrome/navidrome/log\"\n\n\t\"github.com/Masterminds/squirrel\"\n)\n\ntype Expression = squirrel.Sqlizer\n\ntype Criteria struct {\n\tExpression\n\tSort   string\n\tOrder  string\n\tLimit  int\n\tOffset int\n}\n\nfunc (c Criteria) OrderBy() string {\n\tif c.Sort == \"\" {\n\t\tc.Sort = \"title\"\n\t}\n\tf := fieldMap[strings.ToLower(c.Sort)]\n\tvar mapped string\n\tif f == nil {\n\t\tlog.Error(\"Invalid field in 'sort' field\", \"field\", c.Sort)\n\t\tmapped = c.Sort\n\t} else {\n\t\tif f.order == \"\" {\n\t\t\tmapped = f.field\n\t\t} else {\n\t\t\tmapped = f.order\n\t\t}\n\t}\n\tif c.Order != \"\" {\n\t\tmapped = mapped + \" \" + c.Order\n\t}\n\treturn mapped\n}\n\nfunc (c Criteria) ToSql() (sql string, args []interface{}, err error) {\n\treturn c.Expression.ToSql()\n}\n\nfunc (c Criteria) MarshalJSON() ([]byte, error) {\n\taux := struct {\n\t\tAll    []Expression `json:\"all,omitempty\"`\n\t\tAny    []Expression `json:\"any,omitempty\"`\n\t\tSort   string       `json:\"sort,omitempty\"`\n\t\tOrder  string       `json:\"order,omitempty\"`\n\t\tLimit  int          `json:\"limit,omitempty\"`\n\t\tOffset int          `json:\"offset,omitempty\"`\n\t}{\n\t\tSort:   c.Sort,\n\t\tOrder:  c.Order,\n\t\tLimit:  c.Limit,\n\t\tOffset: c.Offset,\n\t}\n\tswitch rules := c.Expression.(type) {\n\tcase Any:\n\t\taux.Any = rules\n\tcase All:\n\t\taux.All = rules\n\tdefault:\n\t\taux.All = All{rules}\n\t}\n\treturn json.Marshal(aux)\n}\n\nfunc (c *Criteria) UnmarshalJSON(data []byte) error {\n\tvar aux struct {\n\t\tAll    unmarshalConjunctionType `json:\"all\"`\n\t\tAny    unmarshalConjunctionType `json:\"any\"`\n\t\tSort   string                   `json:\"sort\"`\n\t\tOrder  string                   `json:\"order\"`\n\t\tLimit  int                      `json:\"limit\"`\n\t\tOffset int                      `json:\"offset\"`\n\t}\n\tif err := json.Unmarshal(data, &aux); err != nil {\n\t\treturn err\n\t}\n\tif len(aux.Any) > 0 {\n\t\tc.Expression = Any(aux.Any)\n\t} else if len(aux.All) > 0 {\n\t\tc.Expression = All(aux.All)\n\t} else {\n\t\treturn errors.New(\"invalid criteria json. missing rules (key 'all' or 'any')\")\n\t}\n\tc.Sort = aux.Sort\n\tc.Order = aux.Order\n\tc.Limit = aux.Limit\n\tc.Offset = aux.Offset\n\treturn nil\n}\n", "package scanner\n\nimport (\n\t\"context\"\n\t\"io/fs\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"sort\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/navidrome/navidrome/conf\"\n\t\"github.com/navidrome/navidrome/core\"\n\t\"github.com/navidrome/navidrome/log\"\n\t\"github.com/navidrome/navidrome/model\"\n\t\"github.com/navidrome/navidrome/model/request\"\n\t\"github.com/navidrome/navidrome/scanner/metadata\"\n\t\"github.com/navidrome/navidrome/utils\"\n)\n\ntype TagScanner struct {\n\trootFolder  string\n\tds          model.DataStore\n\tcacheWarmer core.CacheWarmer\n\tplsSync     *playlistImporter\n\tcnt         *counters\n\tmapper      *mediaFileMapper\n}\n\nfunc NewTagScanner(rootFolder string, ds model.DataStore, playlists core.Playlists, cacheWarmer core.CacheWarmer) *TagScanner {\n\treturn &TagScanner{\n\t\trootFolder:  rootFolder,\n\t\tplsSync:     newPlaylistImporter(ds, playlists, rootFolder),\n\t\tds:          ds,\n\t\tcacheWarmer: cacheWarmer,\n\t}\n}\n\ntype dirMap map[string]dirStats\n\ntype counters struct {\n\tadded     int64\n\tupdated   int64\n\tdeleted   int64\n\tplaylists int64\n}\n\nfunc (cnt *counters) total() int64 { return cnt.added + cnt.updated + cnt.deleted }\n\nconst (\n\t// filesBatchSize used for batching file metadata extraction\n\tfilesBatchSize = 100\n)\n\n// Scan algorithm overview:\n// Load all directories from the DB\n// Traverse the music folder, collecting each subfolder's ModTime (self or any non-dir children, whichever is newer)\n// For each changed folder: get all files from DB whose path starts with the changed folder (non-recursively), check each file:\n//\t    if file in folder is newer, update the one in DB\n//      if file in folder does not exists in DB, add it\n// \t    for each file in the DB that is not found in the folder, delete it from DB\n// Compare directories in the fs with the ones in the DB to find deleted folders\n// For each deleted folder: delete all files from DB whose path starts with the delete folder path (non-recursively)\n// Create new albums/artists, update counters:\n//      collect all albumIDs and artistIDs from previous steps\n//\t    refresh the collected albums and artists with the metadata from the mediafiles\n// For each changed folder, process playlists:\n//      If the playlist is not in the DB, import it, setting sync = true\n//      If the playlist is in the DB and sync == true, import it, or else skip it\n// Delete all empty albums, delete all empty artists, clean-up playlists\nfunc (s *TagScanner) Scan(ctx context.Context, lastModifiedSince time.Time, progress chan uint32) (int64, error) {\n\tctx = s.withAdminUser(ctx)\n\tstart := time.Now()\n\n\t// Special case: if lastModifiedSInce is zero, re-import all files\n\tfullScan := lastModifiedSince.IsZero()\n\n\tallDBDirs, err := s.getDBDirTree(ctx)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\tallFSDirs := dirMap{}\n\tvar changedDirs []string\n\ts.cnt = &counters{}\n\tgenres := newCachedGenreRepository(ctx, s.ds.Genre(ctx))\n\ts.mapper = newMediaFileMapper(s.rootFolder, genres)\n\n\tfoldersFound, walkerError := s.getRootFolderWalker(ctx)\n\tfor {\n\t\tfolderStats, more := <-foldersFound\n\t\tif !more {\n\t\t\tbreak\n\t\t}\n\t\tprogress <- folderStats.AudioFilesCount\n\t\tallFSDirs[folderStats.Path] = folderStats\n\n\t\tif s.folderHasChanged(ctx, folderStats, allDBDirs, lastModifiedSince) {\n\t\t\tchangedDirs = append(changedDirs, folderStats.Path)\n\t\t\tlog.Debug(\"Processing changed folder\", \"dir\", folderStats.Path)\n\t\t\terr := s.processChangedDir(ctx, folderStats.Path, fullScan)\n\t\t\tif err != nil {\n\t\t\t\tlog.Error(\"Error updating folder in the DB\", \"dir\", folderStats.Path, err)\n\t\t\t}\n\t\t}\n\t}\n\n\tif err := <-walkerError; err != nil {\n\t\tlog.Error(\"Scan was interrupted by error. See errors above\", err)\n\t\treturn 0, err\n\t}\n\n\t// If the media folder is empty, abort to avoid deleting all data\n\tif len(allFSDirs) <= 1 {\n\t\tlog.Error(ctx, \"Media Folder is empty. Aborting scan.\", \"folder\", s.rootFolder)\n\t\treturn 0, nil\n\t}\n\n\tdeletedDirs := s.getDeletedDirs(ctx, allFSDirs, allDBDirs)\n\tif len(deletedDirs)+len(changedDirs) == 0 {\n\t\tlog.Debug(ctx, \"No changes found in Music Folder\", \"folder\", s.rootFolder, \"elapsed\", time.Since(start))\n\t\treturn 0, nil\n\t}\n\n\tfor _, dir := range deletedDirs {\n\t\terr := s.processDeletedDir(ctx, dir)\n\t\tif err != nil {\n\t\t\tlog.Error(\"Error removing deleted folder from DB\", \"dir\", dir, err)\n\t\t}\n\t}\n\n\ts.cnt.playlists = 0\n\tif conf.Server.AutoImportPlaylists {\n\t\t// Now that all mediafiles are imported/updated, search for and import/update playlists\n\t\tu, _ := request.UserFrom(ctx)\n\t\tfor _, dir := range changedDirs {\n\t\t\tinfo := allFSDirs[dir]\n\t\t\tif info.HasPlaylist {\n\t\t\t\tif !u.IsAdmin {\n\t\t\t\t\tlog.Warn(\"Playlists will not be imported, as there are no admin users yet, \"+\n\t\t\t\t\t\t\"Please create an admin user first, and then update the playlists for them to be imported\", \"dir\", dir)\n\t\t\t\t} else {\n\t\t\t\t\ts.cnt.playlists = s.plsSync.processPlaylists(ctx, dir)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\n\t\tlog.Debug(\"Playlist auto-import is disabled\")\n\t}\n\n\terr = s.ds.GC(log.NewContext(ctx), s.rootFolder)\n\tlog.Info(\"Finished processing Music Folder\", \"folder\", s.rootFolder, \"elapsed\", time.Since(start),\n\t\t\"added\", s.cnt.added, \"updated\", s.cnt.updated, \"deleted\", s.cnt.deleted, \"playlistsImported\", s.cnt.playlists)\n\n\treturn s.cnt.total(), err\n}\n\nfunc (s *TagScanner) getRootFolderWalker(ctx context.Context) (walkResults, chan error) {\n\tstart := time.Now()\n\tlog.Trace(ctx, \"Loading directory tree from music folder\", \"folder\", s.rootFolder)\n\tresults := make(chan dirStats, 5000)\n\twalkerError := make(chan error)\n\tgo func() {\n\t\terr := walkDirTree(ctx, s.rootFolder, results)\n\t\tif err != nil {\n\t\t\tlog.Error(\"There were errors reading directories from filesystem\", err)\n\t\t}\n\t\twalkerError <- err\n\t\tlog.Debug(\"Finished reading directories from filesystem\", \"elapsed\", time.Since(start))\n\t}()\n\treturn results, walkerError\n}\n\nfunc (s *TagScanner) getDBDirTree(ctx context.Context) (map[string]struct{}, error) {\n\tstart := time.Now()\n\tlog.Trace(ctx, \"Loading directory tree from database\", \"folder\", s.rootFolder)\n\n\trepo := s.ds.MediaFile(ctx)\n\tdirs, err := repo.FindPathsRecursively(s.rootFolder)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tresp := map[string]struct{}{}\n\tfor _, d := range dirs {\n\t\tresp[filepath.Clean(d)] = struct{}{}\n\t}\n\n\tlog.Debug(\"Directory tree loaded from DB\", \"total\", len(resp), \"elapsed\", time.Since(start))\n\treturn resp, nil\n}\n\nfunc (s *TagScanner) folderHasChanged(ctx context.Context, folder dirStats, dbDirs map[string]struct{}, lastModified time.Time) bool {\n\t_, inDB := dbDirs[folder.Path]\n\t// If is a new folder with at least one song OR it was modified after lastModified\n\treturn (!inDB && (folder.AudioFilesCount > 0)) || folder.ModTime.After(lastModified)\n}\n\nfunc (s *TagScanner) getDeletedDirs(ctx context.Context, fsDirs dirMap, dbDirs map[string]struct{}) []string {\n\tstart := time.Now()\n\tlog.Trace(ctx, \"Checking for deleted folders\")\n\tvar deleted []string\n\n\tfor d := range dbDirs {\n\t\tif _, ok := fsDirs[d]; !ok {\n\t\t\tdeleted = append(deleted, d)\n\t\t}\n\t}\n\n\tsort.Strings(deleted)\n\tlog.Debug(ctx, \"Finished deleted folders check\", \"total\", len(deleted), \"elapsed\", time.Since(start))\n\treturn deleted\n}\n\nfunc (s *TagScanner) processDeletedDir(ctx context.Context, dir string) error {\n\tstart := time.Now()\n\tbuffer := newRefreshBuffer(ctx, s.ds)\n\n\tmfs, err := s.ds.MediaFile(ctx).FindAllByPath(dir)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tc, err := s.ds.MediaFile(ctx).DeleteByPath(dir)\n\tif err != nil {\n\t\treturn err\n\t}\n\ts.cnt.deleted += c\n\n\tfor _, t := range mfs {\n\t\tbuffer.accumulate(t)\n\t\ts.cacheWarmer.AddAlbum(ctx, t.AlbumID)\n\t}\n\n\terr = buffer.flush()\n\tlog.Info(ctx, \"Finished processing deleted folder\", \"dir\", dir, \"purged\", len(mfs), \"elapsed\", time.Since(start))\n\treturn err\n}\n\nfunc (s *TagScanner) processChangedDir(ctx context.Context, dir string, fullScan bool) error {\n\tstart := time.Now()\n\tbuffer := newRefreshBuffer(ctx, s.ds)\n\n\t// Load folder's current tracks from DB into a map\n\tcurrentTracks := map[string]model.MediaFile{}\n\tct, err := s.ds.MediaFile(ctx).FindAllByPath(dir)\n\tif err != nil {\n\t\treturn err\n\t}\n\tfor _, t := range ct {\n\t\tcurrentTracks[t.Path] = t\n\t}\n\n\t// Load track list from the folder\n\tfiles, err := loadAllAudioFiles(dir)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// If no files to process, return\n\tif len(files)+len(currentTracks) == 0 {\n\t\treturn nil\n\t}\n\n\torphanTracks := map[string]model.MediaFile{}\n\tfor k, v := range currentTracks {\n\t\torphanTracks[k] = v\n\t}\n\n\t// If track from folder is newer than the one in DB, select for update/insert in DB\n\tlog.Trace(ctx, \"Processing changed folder\", \"dir\", dir, \"tracksInDB\", len(currentTracks), \"tracksInFolder\", len(files))\n\tvar filesToUpdate []string\n\tfor filePath, entry := range files {\n\t\tc, inDB := currentTracks[filePath]\n\t\tif !inDB || fullScan {\n\t\t\tfilesToUpdate = append(filesToUpdate, filePath)\n\t\t\ts.cnt.added++\n\t\t} else {\n\t\t\tinfo, err := entry.Info()\n\t\t\tif err != nil {\n\t\t\t\tlog.Error(\"Could not stat file\", \"filePath\", filePath, err)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif info.ModTime().After(c.UpdatedAt) {\n\t\t\t\tfilesToUpdate = append(filesToUpdate, filePath)\n\t\t\t\ts.cnt.updated++\n\t\t\t}\n\t\t}\n\n\t\t// Force a refresh of the album and artist, to cater for cover art files\n\t\tbuffer.accumulate(c)\n\n\t\t// Only leaves in orphanTracks the ones not found in the folder. After this loop any remaining orphanTracks\n\t\t// are considered gone from the music folder and will be deleted from DB\n\t\tdelete(orphanTracks, filePath)\n\t}\n\n\tnumUpdatedTracks := 0\n\tnumPurgedTracks := 0\n\n\tif len(filesToUpdate) > 0 {\n\t\tnumUpdatedTracks, err = s.addOrUpdateTracksInDB(ctx, dir, currentTracks, filesToUpdate, buffer)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif len(orphanTracks) > 0 {\n\t\tnumPurgedTracks, err = s.deleteOrphanSongs(ctx, dir, orphanTracks, buffer)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Pre cache all changed album artwork\n\tfor albumID := range buffer.album {\n\t\ts.cacheWarmer.AddAlbum(ctx, albumID)\n\t}\n\n\terr = buffer.flush()\n\tlog.Info(ctx, \"Finished processing changed folder\", \"dir\", dir, \"updated\", numUpdatedTracks,\n\t\t\"deleted\", numPurgedTracks, \"elapsed\", time.Since(start))\n\treturn err\n}\n\nfunc (s *TagScanner) deleteOrphanSongs(ctx context.Context, dir string, tracksToDelete map[string]model.MediaFile, buffer *refreshBuffer) (int, error) {\n\tnumPurgedTracks := 0\n\n\tlog.Debug(ctx, \"Deleting orphan tracks from DB\", \"dir\", dir, \"numTracks\", len(tracksToDelete))\n\t// Remaining tracks from DB that are not in the folder are deleted\n\tfor _, ct := range tracksToDelete {\n\t\tnumPurgedTracks++\n\t\tbuffer.accumulate(ct)\n\t\tif err := s.ds.MediaFile(ctx).Delete(ct.ID); err != nil {\n\t\t\treturn 0, err\n\t\t}\n\t\ts.cnt.deleted++\n\t}\n\treturn numPurgedTracks, nil\n}\n\nfunc (s *TagScanner) addOrUpdateTracksInDB(ctx context.Context, dir string, currentTracks map[string]model.MediaFile, filesToUpdate []string, buffer *refreshBuffer) (int, error) {\n\tnumUpdatedTracks := 0\n\n\tlog.Trace(ctx, \"Updating mediaFiles in DB\", \"dir\", dir, \"numFiles\", len(filesToUpdate))\n\t// Break the file list in chunks to avoid calling ffmpeg with too many parameters\n\tchunks := utils.BreakUpStringSlice(filesToUpdate, filesBatchSize)\n\tfor _, chunk := range chunks {\n\t\t// Load tracks Metadata from the folder\n\t\tnewTracks, err := s.loadTracks(chunk)\n\t\tif err != nil {\n\t\t\treturn 0, err\n\t\t}\n\n\t\t// If track from folder is newer than the one in DB, update/insert in DB\n\t\tlog.Trace(ctx, \"Updating mediaFiles in DB\", \"dir\", dir, \"files\", chunk, \"numFiles\", len(chunk))\n\t\tfor i := range newTracks {\n\t\t\tn := newTracks[i]\n\t\t\t// Keep current annotations if the track is in the DB\n\t\t\tif t, ok := currentTracks[n.Path]; ok {\n\t\t\t\tn.Annotations = t.Annotations\n\t\t\t}\n\t\t\terr := s.ds.MediaFile(ctx).Put(&n)\n\t\t\tif err != nil {\n\t\t\t\treturn 0, err\n\t\t\t}\n\t\t\tbuffer.accumulate(n)\n\t\t\tnumUpdatedTracks++\n\t\t}\n\t}\n\treturn numUpdatedTracks, nil\n}\n\nfunc (s *TagScanner) loadTracks(filePaths []string) (model.MediaFiles, error) {\n\tmds, err := metadata.Extract(filePaths...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar mfs model.MediaFiles\n\tfor _, md := range mds {\n\t\tmf := s.mapper.toMediaFile(md)\n\t\tmfs = append(mfs, mf)\n\t}\n\treturn mfs, nil\n}\n\nfunc (s *TagScanner) withAdminUser(ctx context.Context) context.Context {\n\tu, err := s.ds.User(ctx).FindFirstAdmin()\n\tif err != nil {\n\t\tc, err := s.ds.User(ctx).CountAll()\n\t\tif c == 0 && err == nil {\n\t\t\tlog.Debug(ctx, \"Scanner: No admin user yet!\", err)\n\t\t} else {\n\t\t\tlog.Error(ctx, \"Scanner: No admin user found!\", err)\n\t\t}\n\t\tu = &model.User{}\n\t}\n\n\tctx = request.WithUsername(ctx, u.UserName)\n\treturn request.WithUser(ctx, *u)\n}\n\nfunc loadAllAudioFiles(dirPath string) (map[string]fs.DirEntry, error) {\n\tfiles, err := fs.ReadDir(os.DirFS(dirPath), \".\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfileInfos := make(map[string]fs.DirEntry)\n\tfor _, f := range files {\n\t\tif f.IsDir() {\n\t\t\tcontinue\n\t\t}\n\t\tif strings.HasPrefix(f.Name(), \".\") {\n\t\t\tcontinue\n\t\t}\n\t\tfilePath := filepath.Join(dirPath, f.Name())\n\t\tif !utils.IsAudioFile(filePath) {\n\t\t\tcontinue\n\t\t}\n\t\tfileInfos[filePath] = f\n\t}\n\n\treturn fileInfos, nil\n}\n"], "fixing_code": ["// Package criteria implements a Criteria API based on Masterminds/squirrel\npackage criteria\n\nimport (\n\t\"encoding/json\"\n\t\"errors\"\n\t\"strings\"\n\n\t\"github.com/navidrome/navidrome/log\"\n\n\t\"github.com/Masterminds/squirrel\"\n)\n\ntype Expression = squirrel.Sqlizer\n\ntype Criteria struct {\n\tExpression\n\tSort   string\n\tOrder  string\n\tLimit  int\n\tOffset int\n}\n\nfunc (c Criteria) OrderBy() string {\n\tif c.Sort == \"\" {\n\t\tc.Sort = \"title\"\n\t}\n\tf := fieldMap[strings.ToLower(c.Sort)]\n\tvar mapped string\n\tif f == nil {\n\t\tlog.Error(\"Invalid field in 'sort' field. Using 'title'\", \"sort\", c.Sort)\n\t\tmapped = fieldMap[\"title\"].field\n\t} else {\n\t\tif f.order == \"\" {\n\t\t\tmapped = f.field\n\t\t} else {\n\t\t\tmapped = f.order\n\t\t}\n\t}\n\tif c.Order != \"\" {\n\t\tif strings.EqualFold(c.Order, \"asc\") || strings.EqualFold(c.Order, \"desc\") {\n\t\t\tmapped = mapped + \" \" + c.Order\n\t\t} else {\n\t\t\tlog.Error(\"Invalid value in 'order' field. Valid values: 'asc', 'desc'\", \"order\", c.Order)\n\t\t}\n\t}\n\treturn mapped\n}\n\nfunc (c Criteria) ToSql() (sql string, args []interface{}, err error) {\n\treturn c.Expression.ToSql()\n}\n\nfunc (c Criteria) MarshalJSON() ([]byte, error) {\n\taux := struct {\n\t\tAll    []Expression `json:\"all,omitempty\"`\n\t\tAny    []Expression `json:\"any,omitempty\"`\n\t\tSort   string       `json:\"sort,omitempty\"`\n\t\tOrder  string       `json:\"order,omitempty\"`\n\t\tLimit  int          `json:\"limit,omitempty\"`\n\t\tOffset int          `json:\"offset,omitempty\"`\n\t}{\n\t\tSort:   c.Sort,\n\t\tOrder:  c.Order,\n\t\tLimit:  c.Limit,\n\t\tOffset: c.Offset,\n\t}\n\tswitch rules := c.Expression.(type) {\n\tcase Any:\n\t\taux.Any = rules\n\tcase All:\n\t\taux.All = rules\n\tdefault:\n\t\taux.All = All{rules}\n\t}\n\treturn json.Marshal(aux)\n}\n\nfunc (c *Criteria) UnmarshalJSON(data []byte) error {\n\tvar aux struct {\n\t\tAll    unmarshalConjunctionType `json:\"all\"`\n\t\tAny    unmarshalConjunctionType `json:\"any\"`\n\t\tSort   string                   `json:\"sort\"`\n\t\tOrder  string                   `json:\"order\"`\n\t\tLimit  int                      `json:\"limit\"`\n\t\tOffset int                      `json:\"offset\"`\n\t}\n\tif err := json.Unmarshal(data, &aux); err != nil {\n\t\treturn err\n\t}\n\tif len(aux.Any) > 0 {\n\t\tc.Expression = Any(aux.Any)\n\t} else if len(aux.All) > 0 {\n\t\tc.Expression = All(aux.All)\n\t} else {\n\t\treturn errors.New(\"invalid criteria json. missing rules (key 'all' or 'any')\")\n\t}\n\tc.Sort = aux.Sort\n\tc.Order = aux.Order\n\tc.Limit = aux.Limit\n\tc.Offset = aux.Offset\n\treturn nil\n}\n", "package scanner\n\nimport (\n\t\"context\"\n\t\"io/fs\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"sort\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/navidrome/navidrome/conf\"\n\t\"github.com/navidrome/navidrome/core\"\n\t\"github.com/navidrome/navidrome/log\"\n\t\"github.com/navidrome/navidrome/model\"\n\t\"github.com/navidrome/navidrome/model/request\"\n\t\"github.com/navidrome/navidrome/scanner/metadata\"\n\t\"github.com/navidrome/navidrome/utils\"\n)\n\ntype TagScanner struct {\n\trootFolder  string\n\tds          model.DataStore\n\tcacheWarmer core.CacheWarmer\n\tplsSync     *playlistImporter\n\tcnt         *counters\n\tmapper      *mediaFileMapper\n}\n\nfunc NewTagScanner(rootFolder string, ds model.DataStore, playlists core.Playlists, cacheWarmer core.CacheWarmer) *TagScanner {\n\treturn &TagScanner{\n\t\trootFolder:  rootFolder,\n\t\tplsSync:     newPlaylistImporter(ds, playlists, rootFolder),\n\t\tds:          ds,\n\t\tcacheWarmer: cacheWarmer,\n\t}\n}\n\ntype dirMap map[string]dirStats\n\ntype counters struct {\n\tadded     int64\n\tupdated   int64\n\tdeleted   int64\n\tplaylists int64\n}\n\nfunc (cnt *counters) total() int64 { return cnt.added + cnt.updated + cnt.deleted }\n\nconst (\n\t// filesBatchSize used for batching file metadata extraction\n\tfilesBatchSize = 100\n)\n\n// Scan algorithm overview:\n// Load all directories from the DB\n// Traverse the music folder, collecting each subfolder's ModTime (self or any non-dir children, whichever is newer)\n// For each changed folder: get all files from DB whose path starts with the changed folder (non-recursively), check each file:\n//\t    if file in folder is newer, update the one in DB\n//      if file in folder does not exists in DB, add it\n// \t    for each file in the DB that is not found in the folder, delete it from DB\n// Compare directories in the fs with the ones in the DB to find deleted folders\n// For each deleted folder: delete all files from DB whose path starts with the delete folder path (non-recursively)\n// Create new albums/artists, update counters:\n//      collect all albumIDs and artistIDs from previous steps\n//\t    refresh the collected albums and artists with the metadata from the mediafiles\n// For each changed folder, process playlists:\n//      If the playlist is not in the DB, import it, setting sync = true\n//      If the playlist is in the DB and sync == true, import it, or else skip it\n// Delete all empty albums, delete all empty artists, clean-up playlists\nfunc (s *TagScanner) Scan(ctx context.Context, lastModifiedSince time.Time, progress chan uint32) (int64, error) {\n\tctx = s.withAdminUser(ctx)\n\tstart := time.Now()\n\n\t// Special case: if lastModifiedSince is zero, re-import all files\n\tfullScan := lastModifiedSince.IsZero()\n\n\tallDBDirs, err := s.getDBDirTree(ctx)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\tallFSDirs := dirMap{}\n\tvar changedDirs []string\n\ts.cnt = &counters{}\n\tgenres := newCachedGenreRepository(ctx, s.ds.Genre(ctx))\n\ts.mapper = newMediaFileMapper(s.rootFolder, genres)\n\n\tfoldersFound, walkerError := s.getRootFolderWalker(ctx)\n\tfor {\n\t\tfolderStats, more := <-foldersFound\n\t\tif !more {\n\t\t\tbreak\n\t\t}\n\t\tprogress <- folderStats.AudioFilesCount\n\t\tallFSDirs[folderStats.Path] = folderStats\n\n\t\tif s.folderHasChanged(ctx, folderStats, allDBDirs, lastModifiedSince) {\n\t\t\tchangedDirs = append(changedDirs, folderStats.Path)\n\t\t\tlog.Debug(\"Processing changed folder\", \"dir\", folderStats.Path)\n\t\t\terr := s.processChangedDir(ctx, folderStats.Path, fullScan)\n\t\t\tif err != nil {\n\t\t\t\tlog.Error(\"Error updating folder in the DB\", \"dir\", folderStats.Path, err)\n\t\t\t}\n\t\t}\n\t}\n\n\tif err := <-walkerError; err != nil {\n\t\tlog.Error(\"Scan was interrupted by error. See errors above\", err)\n\t\treturn 0, err\n\t}\n\n\t// If the media folder is empty, abort to avoid deleting all data\n\tif len(allFSDirs) <= 1 {\n\t\tlog.Error(ctx, \"Media Folder is empty. Aborting scan.\", \"folder\", s.rootFolder)\n\t\treturn 0, nil\n\t}\n\n\tdeletedDirs := s.getDeletedDirs(ctx, allFSDirs, allDBDirs)\n\tif len(deletedDirs)+len(changedDirs) == 0 {\n\t\tlog.Debug(ctx, \"No changes found in Music Folder\", \"folder\", s.rootFolder, \"elapsed\", time.Since(start))\n\t\treturn 0, nil\n\t}\n\n\tfor _, dir := range deletedDirs {\n\t\terr := s.processDeletedDir(ctx, dir)\n\t\tif err != nil {\n\t\t\tlog.Error(\"Error removing deleted folder from DB\", \"dir\", dir, err)\n\t\t}\n\t}\n\n\ts.cnt.playlists = 0\n\tif conf.Server.AutoImportPlaylists {\n\t\t// Now that all mediafiles are imported/updated, search for and import/update playlists\n\t\tu, _ := request.UserFrom(ctx)\n\t\tfor _, dir := range changedDirs {\n\t\t\tinfo := allFSDirs[dir]\n\t\t\tif info.HasPlaylist {\n\t\t\t\tif !u.IsAdmin {\n\t\t\t\t\tlog.Warn(\"Playlists will not be imported, as there are no admin users yet, \"+\n\t\t\t\t\t\t\"Please create an admin user first, and then update the playlists for them to be imported\", \"dir\", dir)\n\t\t\t\t} else {\n\t\t\t\t\ts.cnt.playlists = s.plsSync.processPlaylists(ctx, dir)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\n\t\tlog.Debug(\"Playlist auto-import is disabled\")\n\t}\n\n\terr = s.ds.GC(log.NewContext(ctx), s.rootFolder)\n\tlog.Info(\"Finished processing Music Folder\", \"folder\", s.rootFolder, \"elapsed\", time.Since(start),\n\t\t\"added\", s.cnt.added, \"updated\", s.cnt.updated, \"deleted\", s.cnt.deleted, \"playlistsImported\", s.cnt.playlists)\n\n\treturn s.cnt.total(), err\n}\n\nfunc (s *TagScanner) getRootFolderWalker(ctx context.Context) (walkResults, chan error) {\n\tstart := time.Now()\n\tlog.Trace(ctx, \"Loading directory tree from music folder\", \"folder\", s.rootFolder)\n\tresults := make(chan dirStats, 5000)\n\twalkerError := make(chan error)\n\tgo func() {\n\t\terr := walkDirTree(ctx, s.rootFolder, results)\n\t\tif err != nil {\n\t\t\tlog.Error(\"There were errors reading directories from filesystem\", err)\n\t\t}\n\t\twalkerError <- err\n\t\tlog.Debug(\"Finished reading directories from filesystem\", \"elapsed\", time.Since(start))\n\t}()\n\treturn results, walkerError\n}\n\nfunc (s *TagScanner) getDBDirTree(ctx context.Context) (map[string]struct{}, error) {\n\tstart := time.Now()\n\tlog.Trace(ctx, \"Loading directory tree from database\", \"folder\", s.rootFolder)\n\n\trepo := s.ds.MediaFile(ctx)\n\tdirs, err := repo.FindPathsRecursively(s.rootFolder)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tresp := map[string]struct{}{}\n\tfor _, d := range dirs {\n\t\tresp[filepath.Clean(d)] = struct{}{}\n\t}\n\n\tlog.Debug(\"Directory tree loaded from DB\", \"total\", len(resp), \"elapsed\", time.Since(start))\n\treturn resp, nil\n}\n\nfunc (s *TagScanner) folderHasChanged(ctx context.Context, folder dirStats, dbDirs map[string]struct{}, lastModified time.Time) bool {\n\t_, inDB := dbDirs[folder.Path]\n\t// If is a new folder with at least one song OR it was modified after lastModified\n\treturn (!inDB && (folder.AudioFilesCount > 0)) || folder.ModTime.After(lastModified)\n}\n\nfunc (s *TagScanner) getDeletedDirs(ctx context.Context, fsDirs dirMap, dbDirs map[string]struct{}) []string {\n\tstart := time.Now()\n\tlog.Trace(ctx, \"Checking for deleted folders\")\n\tvar deleted []string\n\n\tfor d := range dbDirs {\n\t\tif _, ok := fsDirs[d]; !ok {\n\t\t\tdeleted = append(deleted, d)\n\t\t}\n\t}\n\n\tsort.Strings(deleted)\n\tlog.Debug(ctx, \"Finished deleted folders check\", \"total\", len(deleted), \"elapsed\", time.Since(start))\n\treturn deleted\n}\n\nfunc (s *TagScanner) processDeletedDir(ctx context.Context, dir string) error {\n\tstart := time.Now()\n\tbuffer := newRefreshBuffer(ctx, s.ds)\n\n\tmfs, err := s.ds.MediaFile(ctx).FindAllByPath(dir)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tc, err := s.ds.MediaFile(ctx).DeleteByPath(dir)\n\tif err != nil {\n\t\treturn err\n\t}\n\ts.cnt.deleted += c\n\n\tfor _, t := range mfs {\n\t\tbuffer.accumulate(t)\n\t\ts.cacheWarmer.AddAlbum(ctx, t.AlbumID)\n\t}\n\n\terr = buffer.flush()\n\tlog.Info(ctx, \"Finished processing deleted folder\", \"dir\", dir, \"purged\", len(mfs), \"elapsed\", time.Since(start))\n\treturn err\n}\n\nfunc (s *TagScanner) processChangedDir(ctx context.Context, dir string, fullScan bool) error {\n\tstart := time.Now()\n\tbuffer := newRefreshBuffer(ctx, s.ds)\n\n\t// Load folder's current tracks from DB into a map\n\tcurrentTracks := map[string]model.MediaFile{}\n\tct, err := s.ds.MediaFile(ctx).FindAllByPath(dir)\n\tif err != nil {\n\t\treturn err\n\t}\n\tfor _, t := range ct {\n\t\tcurrentTracks[t.Path] = t\n\t}\n\n\t// Load track list from the folder\n\tfiles, err := loadAllAudioFiles(dir)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// If no files to process, return\n\tif len(files)+len(currentTracks) == 0 {\n\t\treturn nil\n\t}\n\n\torphanTracks := map[string]model.MediaFile{}\n\tfor k, v := range currentTracks {\n\t\torphanTracks[k] = v\n\t}\n\n\t// If track from folder is newer than the one in DB, select for update/insert in DB\n\tlog.Trace(ctx, \"Processing changed folder\", \"dir\", dir, \"tracksInDB\", len(currentTracks), \"tracksInFolder\", len(files))\n\tvar filesToUpdate []string\n\tfor filePath, entry := range files {\n\t\tc, inDB := currentTracks[filePath]\n\t\tif !inDB || fullScan {\n\t\t\tfilesToUpdate = append(filesToUpdate, filePath)\n\t\t\ts.cnt.added++\n\t\t} else {\n\t\t\tinfo, err := entry.Info()\n\t\t\tif err != nil {\n\t\t\t\tlog.Error(\"Could not stat file\", \"filePath\", filePath, err)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif info.ModTime().After(c.UpdatedAt) {\n\t\t\t\tfilesToUpdate = append(filesToUpdate, filePath)\n\t\t\t\ts.cnt.updated++\n\t\t\t}\n\t\t}\n\n\t\t// Force a refresh of the album and artist, to cater for cover art files\n\t\tbuffer.accumulate(c)\n\n\t\t// Only leaves in orphanTracks the ones not found in the folder. After this loop any remaining orphanTracks\n\t\t// are considered gone from the music folder and will be deleted from DB\n\t\tdelete(orphanTracks, filePath)\n\t}\n\n\tnumUpdatedTracks := 0\n\tnumPurgedTracks := 0\n\n\tif len(filesToUpdate) > 0 {\n\t\tnumUpdatedTracks, err = s.addOrUpdateTracksInDB(ctx, dir, currentTracks, filesToUpdate, buffer)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif len(orphanTracks) > 0 {\n\t\tnumPurgedTracks, err = s.deleteOrphanSongs(ctx, dir, orphanTracks, buffer)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Pre cache all changed album artwork\n\tfor albumID := range buffer.album {\n\t\ts.cacheWarmer.AddAlbum(ctx, albumID)\n\t}\n\n\terr = buffer.flush()\n\tlog.Info(ctx, \"Finished processing changed folder\", \"dir\", dir, \"updated\", numUpdatedTracks,\n\t\t\"deleted\", numPurgedTracks, \"elapsed\", time.Since(start))\n\treturn err\n}\n\nfunc (s *TagScanner) deleteOrphanSongs(ctx context.Context, dir string, tracksToDelete map[string]model.MediaFile, buffer *refreshBuffer) (int, error) {\n\tnumPurgedTracks := 0\n\n\tlog.Debug(ctx, \"Deleting orphan tracks from DB\", \"dir\", dir, \"numTracks\", len(tracksToDelete))\n\t// Remaining tracks from DB that are not in the folder are deleted\n\tfor _, ct := range tracksToDelete {\n\t\tnumPurgedTracks++\n\t\tbuffer.accumulate(ct)\n\t\tif err := s.ds.MediaFile(ctx).Delete(ct.ID); err != nil {\n\t\t\treturn 0, err\n\t\t}\n\t\ts.cnt.deleted++\n\t}\n\treturn numPurgedTracks, nil\n}\n\nfunc (s *TagScanner) addOrUpdateTracksInDB(ctx context.Context, dir string, currentTracks map[string]model.MediaFile, filesToUpdate []string, buffer *refreshBuffer) (int, error) {\n\tnumUpdatedTracks := 0\n\n\tlog.Trace(ctx, \"Updating mediaFiles in DB\", \"dir\", dir, \"numFiles\", len(filesToUpdate))\n\t// Break the file list in chunks to avoid calling ffmpeg with too many parameters\n\tchunks := utils.BreakUpStringSlice(filesToUpdate, filesBatchSize)\n\tfor _, chunk := range chunks {\n\t\t// Load tracks Metadata from the folder\n\t\tnewTracks, err := s.loadTracks(chunk)\n\t\tif err != nil {\n\t\t\treturn 0, err\n\t\t}\n\n\t\t// If track from folder is newer than the one in DB, update/insert in DB\n\t\tlog.Trace(ctx, \"Updating mediaFiles in DB\", \"dir\", dir, \"files\", chunk, \"numFiles\", len(chunk))\n\t\tfor i := range newTracks {\n\t\t\tn := newTracks[i]\n\t\t\t// Keep current annotations if the track is in the DB\n\t\t\tif t, ok := currentTracks[n.Path]; ok {\n\t\t\t\tn.Annotations = t.Annotations\n\t\t\t}\n\t\t\terr := s.ds.MediaFile(ctx).Put(&n)\n\t\t\tif err != nil {\n\t\t\t\treturn 0, err\n\t\t\t}\n\t\t\tbuffer.accumulate(n)\n\t\t\tnumUpdatedTracks++\n\t\t}\n\t}\n\treturn numUpdatedTracks, nil\n}\n\nfunc (s *TagScanner) loadTracks(filePaths []string) (model.MediaFiles, error) {\n\tmds, err := metadata.Extract(filePaths...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar mfs model.MediaFiles\n\tfor _, md := range mds {\n\t\tmf := s.mapper.toMediaFile(md)\n\t\tmfs = append(mfs, mf)\n\t}\n\treturn mfs, nil\n}\n\nfunc (s *TagScanner) withAdminUser(ctx context.Context) context.Context {\n\tu, err := s.ds.User(ctx).FindFirstAdmin()\n\tif err != nil {\n\t\tc, err := s.ds.User(ctx).CountAll()\n\t\tif c == 0 && err == nil {\n\t\t\tlog.Debug(ctx, \"Scanner: No admin user yet!\", err)\n\t\t} else {\n\t\t\tlog.Error(ctx, \"Scanner: No admin user found!\", err)\n\t\t}\n\t\tu = &model.User{}\n\t}\n\n\tctx = request.WithUsername(ctx, u.UserName)\n\treturn request.WithUser(ctx, *u)\n}\n\nfunc loadAllAudioFiles(dirPath string) (map[string]fs.DirEntry, error) {\n\tfiles, err := fs.ReadDir(os.DirFS(dirPath), \".\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfileInfos := make(map[string]fs.DirEntry)\n\tfor _, f := range files {\n\t\tif f.IsDir() {\n\t\t\tcontinue\n\t\t}\n\t\tif strings.HasPrefix(f.Name(), \".\") {\n\t\t\tcontinue\n\t\t}\n\t\tfilePath := filepath.Join(dirPath, f.Name())\n\t\tif !utils.IsAudioFile(filePath) {\n\t\t\tcontinue\n\t\t}\n\t\tfileInfos[filePath] = f\n\t}\n\n\treturn fileInfos, nil\n}\n"], "filenames": ["model/criteria/criteria.go", "scanner/tag_scanner.go"], "buggy_code_start_loc": [31, 75], "buggy_code_end_loc": [42, 76], "fixing_code_start_loc": [31, 75], "fixing_code_end_loc": [46, 76], "type": "CWE-89", "message": "model/criteria/criteria.go in Navidrome before 0.47.5 is vulnerable to SQL injection attacks when processing crafted Smart Playlists. An authenticated user could abuse this to extract arbitrary data from the database, including the user table (which contains sensitive information such as the users' encrypted passwords).", "other": {"cve": {"id": "CVE-2022-23857", "sourceIdentifier": "cve@mitre.org", "published": "2022-01-24T02:15:06.877", "lastModified": "2022-01-27T16:14:04.917", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "model/criteria/criteria.go in Navidrome before 0.47.5 is vulnerable to SQL injection attacks when processing crafted Smart Playlists. An authenticated user could abuse this to extract arbitrary data from the database, including the user table (which contains sensitive information such as the users' encrypted passwords)."}, {"lang": "es", "value": "El archivo model/criteria/criteria.go en Navidrome versiones anteriores a 0.47.5, es vulnerable a ataques de inyecci\u00f3n SQL cuando son procesados listas de reproducci\u00f3n inteligentes dise\u00f1adas. Un usuario autenticado podr\u00eda abusar de esto para extraer datos arbitrarios de la base de datos, incluyendo la tabla de usuarios (que contiene informaci\u00f3n confidencial como las contrase\u00f1as cifradas de usuarios)"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 6.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:S/C:P/I:N/A:N", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "SINGLE", "confidentialityImpact": "PARTIAL", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 4.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-89"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:navidrome:navidrome:*:*:*:*:*:*:*:*", "versionEndExcluding": "0.47.5", "matchCriteriaId": "6BC0E5B5-AC3D-45CF-91C5-1B32926512AE"}]}]}], "references": [{"url": "https://github.com/navidrome/navidrome/commit/9e79b5cbf2a48c1e4344df00fea4ed3844ea965d", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/navidrome/navidrome/releases/tag/v0.47.5", "source": "cve@mitre.org", "tags": ["Release Notes", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/navidrome/navidrome/commit/9e79b5cbf2a48c1e4344df00fea4ed3844ea965d"}}
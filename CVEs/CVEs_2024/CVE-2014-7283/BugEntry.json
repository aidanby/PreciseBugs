{"buggy_code": ["/*\n * Copyright (c) 2000-2005 Silicon Graphics, Inc.\n * Copyright (c) 2013 Red Hat, Inc.\n * All Rights Reserved.\n *\n * This program is free software; you can redistribute it and/or\n * modify it under the terms of the GNU General Public License as\n * published by the Free Software Foundation.\n *\n * This program is distributed in the hope that it would be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write the Free Software Foundation,\n * Inc.,  51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA\n */\n#include \"xfs.h\"\n#include \"xfs_fs.h\"\n#include \"xfs_shared.h\"\n#include \"xfs_format.h\"\n#include \"xfs_log_format.h\"\n#include \"xfs_trans_resv.h\"\n#include \"xfs_bit.h\"\n#include \"xfs_sb.h\"\n#include \"xfs_ag.h\"\n#include \"xfs_mount.h\"\n#include \"xfs_da_format.h\"\n#include \"xfs_da_btree.h\"\n#include \"xfs_dir2.h\"\n#include \"xfs_dir2_priv.h\"\n#include \"xfs_inode.h\"\n#include \"xfs_trans.h\"\n#include \"xfs_inode_item.h\"\n#include \"xfs_alloc.h\"\n#include \"xfs_bmap.h\"\n#include \"xfs_attr.h\"\n#include \"xfs_attr_leaf.h\"\n#include \"xfs_error.h\"\n#include \"xfs_trace.h\"\n#include \"xfs_cksum.h\"\n#include \"xfs_buf_item.h\"\n\n/*\n * xfs_da_btree.c\n *\n * Routines to implement directories as Btrees of hashed names.\n */\n\n/*========================================================================\n * Function prototypes for the kernel.\n *========================================================================*/\n\n/*\n * Routines used for growing the Btree.\n */\nSTATIC int xfs_da3_root_split(xfs_da_state_t *state,\n\t\t\t\t\t    xfs_da_state_blk_t *existing_root,\n\t\t\t\t\t    xfs_da_state_blk_t *new_child);\nSTATIC int xfs_da3_node_split(xfs_da_state_t *state,\n\t\t\t\t\t    xfs_da_state_blk_t *existing_blk,\n\t\t\t\t\t    xfs_da_state_blk_t *split_blk,\n\t\t\t\t\t    xfs_da_state_blk_t *blk_to_add,\n\t\t\t\t\t    int treelevel,\n\t\t\t\t\t    int *result);\nSTATIC void xfs_da3_node_rebalance(xfs_da_state_t *state,\n\t\t\t\t\t xfs_da_state_blk_t *node_blk_1,\n\t\t\t\t\t xfs_da_state_blk_t *node_blk_2);\nSTATIC void xfs_da3_node_add(xfs_da_state_t *state,\n\t\t\t\t   xfs_da_state_blk_t *old_node_blk,\n\t\t\t\t   xfs_da_state_blk_t *new_node_blk);\n\n/*\n * Routines used for shrinking the Btree.\n */\nSTATIC int xfs_da3_root_join(xfs_da_state_t *state,\n\t\t\t\t\t   xfs_da_state_blk_t *root_blk);\nSTATIC int xfs_da3_node_toosmall(xfs_da_state_t *state, int *retval);\nSTATIC void xfs_da3_node_remove(xfs_da_state_t *state,\n\t\t\t\t\t      xfs_da_state_blk_t *drop_blk);\nSTATIC void xfs_da3_node_unbalance(xfs_da_state_t *state,\n\t\t\t\t\t xfs_da_state_blk_t *src_node_blk,\n\t\t\t\t\t xfs_da_state_blk_t *dst_node_blk);\n\n/*\n * Utility routines.\n */\nSTATIC int\txfs_da3_blk_unlink(xfs_da_state_t *state,\n\t\t\t\t  xfs_da_state_blk_t *drop_blk,\n\t\t\t\t  xfs_da_state_blk_t *save_blk);\n\n\nkmem_zone_t *xfs_da_state_zone;\t/* anchor for state struct zone */\n\n/*\n * Allocate a dir-state structure.\n * We don't put them on the stack since they're large.\n */\nxfs_da_state_t *\nxfs_da_state_alloc(void)\n{\n\treturn kmem_zone_zalloc(xfs_da_state_zone, KM_NOFS);\n}\n\n/*\n * Kill the altpath contents of a da-state structure.\n */\nSTATIC void\nxfs_da_state_kill_altpath(xfs_da_state_t *state)\n{\n\tint\ti;\n\n\tfor (i = 0; i < state->altpath.active; i++)\n\t\tstate->altpath.blk[i].bp = NULL;\n\tstate->altpath.active = 0;\n}\n\n/*\n * Free a da-state structure.\n */\nvoid\nxfs_da_state_free(xfs_da_state_t *state)\n{\n\txfs_da_state_kill_altpath(state);\n#ifdef DEBUG\n\tmemset((char *)state, 0, sizeof(*state));\n#endif /* DEBUG */\n\tkmem_zone_free(xfs_da_state_zone, state);\n}\n\nstatic bool\nxfs_da3_node_verify(\n\tstruct xfs_buf\t\t*bp)\n{\n\tstruct xfs_mount\t*mp = bp->b_target->bt_mount;\n\tstruct xfs_da_intnode\t*hdr = bp->b_addr;\n\tstruct xfs_da3_icnode_hdr ichdr;\n\tconst struct xfs_dir_ops *ops;\n\n\tops = xfs_dir_get_ops(mp, NULL);\n\n\tops->node_hdr_from_disk(&ichdr, hdr);\n\n\tif (xfs_sb_version_hascrc(&mp->m_sb)) {\n\t\tstruct xfs_da3_node_hdr *hdr3 = bp->b_addr;\n\n\t\tif (ichdr.magic != XFS_DA3_NODE_MAGIC)\n\t\t\treturn false;\n\n\t\tif (!uuid_equal(&hdr3->info.uuid, &mp->m_sb.sb_uuid))\n\t\t\treturn false;\n\t\tif (be64_to_cpu(hdr3->info.blkno) != bp->b_bn)\n\t\t\treturn false;\n\t} else {\n\t\tif (ichdr.magic != XFS_DA_NODE_MAGIC)\n\t\t\treturn false;\n\t}\n\tif (ichdr.level == 0)\n\t\treturn false;\n\tif (ichdr.level > XFS_DA_NODE_MAXDEPTH)\n\t\treturn false;\n\tif (ichdr.count == 0)\n\t\treturn false;\n\n\t/*\n\t * we don't know if the node is for and attribute or directory tree,\n\t * so only fail if the count is outside both bounds\n\t */\n\tif (ichdr.count > mp->m_dir_node_ents &&\n\t    ichdr.count > mp->m_attr_node_ents)\n\t\treturn false;\n\n\t/* XXX: hash order check? */\n\n\treturn true;\n}\n\nstatic void\nxfs_da3_node_write_verify(\n\tstruct xfs_buf\t*bp)\n{\n\tstruct xfs_mount\t*mp = bp->b_target->bt_mount;\n\tstruct xfs_buf_log_item\t*bip = bp->b_fspriv;\n\tstruct xfs_da3_node_hdr *hdr3 = bp->b_addr;\n\n\tif (!xfs_da3_node_verify(bp)) {\n\t\tXFS_CORRUPTION_ERROR(__func__, XFS_ERRLEVEL_LOW, mp, bp->b_addr);\n\t\txfs_buf_ioerror(bp, EFSCORRUPTED);\n\t\treturn;\n\t}\n\n\tif (!xfs_sb_version_hascrc(&mp->m_sb))\n\t\treturn;\n\n\tif (bip)\n\t\thdr3->info.lsn = cpu_to_be64(bip->bli_item.li_lsn);\n\n\txfs_update_cksum(bp->b_addr, BBTOB(bp->b_length), XFS_DA3_NODE_CRC_OFF);\n}\n\n/*\n * leaf/node format detection on trees is sketchy, so a node read can be done on\n * leaf level blocks when detection identifies the tree as a node format tree\n * incorrectly. In this case, we need to swap the verifier to match the correct\n * format of the block being read.\n */\nstatic void\nxfs_da3_node_read_verify(\n\tstruct xfs_buf\t\t*bp)\n{\n\tstruct xfs_mount\t*mp = bp->b_target->bt_mount;\n\tstruct xfs_da_blkinfo\t*info = bp->b_addr;\n\n\tswitch (be16_to_cpu(info->magic)) {\n\t\tcase XFS_DA3_NODE_MAGIC:\n\t\t\tif (!xfs_verify_cksum(bp->b_addr, BBTOB(bp->b_length),\n\t\t\t\t\t      XFS_DA3_NODE_CRC_OFF))\n\t\t\t\tbreak;\n\t\t\t/* fall through */\n\t\tcase XFS_DA_NODE_MAGIC:\n\t\t\tif (!xfs_da3_node_verify(bp))\n\t\t\t\tbreak;\n\t\t\treturn;\n\t\tcase XFS_ATTR_LEAF_MAGIC:\n\t\tcase XFS_ATTR3_LEAF_MAGIC:\n\t\t\tbp->b_ops = &xfs_attr3_leaf_buf_ops;\n\t\t\tbp->b_ops->verify_read(bp);\n\t\t\treturn;\n\t\tcase XFS_DIR2_LEAFN_MAGIC:\n\t\tcase XFS_DIR3_LEAFN_MAGIC:\n\t\t\tbp->b_ops = &xfs_dir3_leafn_buf_ops;\n\t\t\tbp->b_ops->verify_read(bp);\n\t\t\treturn;\n\t\tdefault:\n\t\t\tbreak;\n\t}\n\n\t/* corrupt block */\n\tXFS_CORRUPTION_ERROR(__func__, XFS_ERRLEVEL_LOW, mp, bp->b_addr);\n\txfs_buf_ioerror(bp, EFSCORRUPTED);\n}\n\nconst struct xfs_buf_ops xfs_da3_node_buf_ops = {\n\t.verify_read = xfs_da3_node_read_verify,\n\t.verify_write = xfs_da3_node_write_verify,\n};\n\nint\nxfs_da3_node_read(\n\tstruct xfs_trans\t*tp,\n\tstruct xfs_inode\t*dp,\n\txfs_dablk_t\t\tbno,\n\txfs_daddr_t\t\tmappedbno,\n\tstruct xfs_buf\t\t**bpp,\n\tint\t\t\twhich_fork)\n{\n\tint\t\t\terr;\n\n\terr = xfs_da_read_buf(tp, dp, bno, mappedbno, bpp,\n\t\t\t\t\twhich_fork, &xfs_da3_node_buf_ops);\n\tif (!err && tp) {\n\t\tstruct xfs_da_blkinfo\t*info = (*bpp)->b_addr;\n\t\tint\t\t\ttype;\n\n\t\tswitch (be16_to_cpu(info->magic)) {\n\t\tcase XFS_DA_NODE_MAGIC:\n\t\tcase XFS_DA3_NODE_MAGIC:\n\t\t\ttype = XFS_BLFT_DA_NODE_BUF;\n\t\t\tbreak;\n\t\tcase XFS_ATTR_LEAF_MAGIC:\n\t\tcase XFS_ATTR3_LEAF_MAGIC:\n\t\t\ttype = XFS_BLFT_ATTR_LEAF_BUF;\n\t\t\tbreak;\n\t\tcase XFS_DIR2_LEAFN_MAGIC:\n\t\tcase XFS_DIR3_LEAFN_MAGIC:\n\t\t\ttype = XFS_BLFT_DIR_LEAFN_BUF;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\ttype = 0;\n\t\t\tASSERT(0);\n\t\t\tbreak;\n\t\t}\n\t\txfs_trans_buf_set_type(tp, *bpp, type);\n\t}\n\treturn err;\n}\n\n/*========================================================================\n * Routines used for growing the Btree.\n *========================================================================*/\n\n/*\n * Create the initial contents of an intermediate node.\n */\nint\nxfs_da3_node_create(\n\tstruct xfs_da_args\t*args,\n\txfs_dablk_t\t\tblkno,\n\tint\t\t\tlevel,\n\tstruct xfs_buf\t\t**bpp,\n\tint\t\t\twhichfork)\n{\n\tstruct xfs_da_intnode\t*node;\n\tstruct xfs_trans\t*tp = args->trans;\n\tstruct xfs_mount\t*mp = tp->t_mountp;\n\tstruct xfs_da3_icnode_hdr ichdr = {0};\n\tstruct xfs_buf\t\t*bp;\n\tint\t\t\terror;\n\tstruct xfs_inode\t*dp = args->dp;\n\n\ttrace_xfs_da_node_create(args);\n\tASSERT(level <= XFS_DA_NODE_MAXDEPTH);\n\n\terror = xfs_da_get_buf(tp, dp, blkno, -1, &bp, whichfork);\n\tif (error)\n\t\treturn(error);\n\tbp->b_ops = &xfs_da3_node_buf_ops;\n\txfs_trans_buf_set_type(tp, bp, XFS_BLFT_DA_NODE_BUF);\n\tnode = bp->b_addr;\n\n\tif (xfs_sb_version_hascrc(&mp->m_sb)) {\n\t\tstruct xfs_da3_node_hdr *hdr3 = bp->b_addr;\n\n\t\tichdr.magic = XFS_DA3_NODE_MAGIC;\n\t\thdr3->info.blkno = cpu_to_be64(bp->b_bn);\n\t\thdr3->info.owner = cpu_to_be64(args->dp->i_ino);\n\t\tuuid_copy(&hdr3->info.uuid, &mp->m_sb.sb_uuid);\n\t} else {\n\t\tichdr.magic = XFS_DA_NODE_MAGIC;\n\t}\n\tichdr.level = level;\n\n\tdp->d_ops->node_hdr_to_disk(node, &ichdr);\n\txfs_trans_log_buf(tp, bp,\n\t\tXFS_DA_LOGRANGE(node, &node->hdr, dp->d_ops->node_hdr_size));\n\n\t*bpp = bp;\n\treturn(0);\n}\n\n/*\n * Split a leaf node, rebalance, then possibly split\n * intermediate nodes, rebalance, etc.\n */\nint\t\t\t\t\t\t\t/* error */\nxfs_da3_split(\n\tstruct xfs_da_state\t*state)\n{\n\tstruct xfs_da_state_blk\t*oldblk;\n\tstruct xfs_da_state_blk\t*newblk;\n\tstruct xfs_da_state_blk\t*addblk;\n\tstruct xfs_da_intnode\t*node;\n\tstruct xfs_buf\t\t*bp;\n\tint\t\t\tmax;\n\tint\t\t\taction = 0;\n\tint\t\t\terror;\n\tint\t\t\ti;\n\n\ttrace_xfs_da_split(state->args);\n\n\t/*\n\t * Walk back up the tree splitting/inserting/adjusting as necessary.\n\t * If we need to insert and there isn't room, split the node, then\n\t * decide which fragment to insert the new block from below into.\n\t * Note that we may split the root this way, but we need more fixup.\n\t */\n\tmax = state->path.active - 1;\n\tASSERT((max >= 0) && (max < XFS_DA_NODE_MAXDEPTH));\n\tASSERT(state->path.blk[max].magic == XFS_ATTR_LEAF_MAGIC ||\n\t       state->path.blk[max].magic == XFS_DIR2_LEAFN_MAGIC);\n\n\taddblk = &state->path.blk[max];\t\t/* initial dummy value */\n\tfor (i = max; (i >= 0) && addblk; state->path.active--, i--) {\n\t\toldblk = &state->path.blk[i];\n\t\tnewblk = &state->altpath.blk[i];\n\n\t\t/*\n\t\t * If a leaf node then\n\t\t *     Allocate a new leaf node, then rebalance across them.\n\t\t * else if an intermediate node then\n\t\t *     We split on the last layer, must we split the node?\n\t\t */\n\t\tswitch (oldblk->magic) {\n\t\tcase XFS_ATTR_LEAF_MAGIC:\n\t\t\terror = xfs_attr3_leaf_split(state, oldblk, newblk);\n\t\t\tif ((error != 0) && (error != ENOSPC)) {\n\t\t\t\treturn(error);\t/* GROT: attr is inconsistent */\n\t\t\t}\n\t\t\tif (!error) {\n\t\t\t\taddblk = newblk;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t/*\n\t\t\t * Entry wouldn't fit, split the leaf again.\n\t\t\t */\n\t\t\tstate->extravalid = 1;\n\t\t\tif (state->inleaf) {\n\t\t\t\tstate->extraafter = 0;\t/* before newblk */\n\t\t\t\ttrace_xfs_attr_leaf_split_before(state->args);\n\t\t\t\terror = xfs_attr3_leaf_split(state, oldblk,\n\t\t\t\t\t\t\t    &state->extrablk);\n\t\t\t} else {\n\t\t\t\tstate->extraafter = 1;\t/* after newblk */\n\t\t\t\ttrace_xfs_attr_leaf_split_after(state->args);\n\t\t\t\terror = xfs_attr3_leaf_split(state, newblk,\n\t\t\t\t\t\t\t    &state->extrablk);\n\t\t\t}\n\t\t\tif (error)\n\t\t\t\treturn(error);\t/* GROT: attr inconsistent */\n\t\t\taddblk = newblk;\n\t\t\tbreak;\n\t\tcase XFS_DIR2_LEAFN_MAGIC:\n\t\t\terror = xfs_dir2_leafn_split(state, oldblk, newblk);\n\t\t\tif (error)\n\t\t\t\treturn error;\n\t\t\taddblk = newblk;\n\t\t\tbreak;\n\t\tcase XFS_DA_NODE_MAGIC:\n\t\t\terror = xfs_da3_node_split(state, oldblk, newblk, addblk,\n\t\t\t\t\t\t\t max - i, &action);\n\t\t\taddblk->bp = NULL;\n\t\t\tif (error)\n\t\t\t\treturn(error);\t/* GROT: dir is inconsistent */\n\t\t\t/*\n\t\t\t * Record the newly split block for the next time thru?\n\t\t\t */\n\t\t\tif (action)\n\t\t\t\taddblk = newblk;\n\t\t\telse\n\t\t\t\taddblk = NULL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Update the btree to show the new hashval for this child.\n\t\t */\n\t\txfs_da3_fixhashpath(state, &state->path);\n\t}\n\tif (!addblk)\n\t\treturn(0);\n\n\t/*\n\t * Split the root node.\n\t */\n\tASSERT(state->path.active == 0);\n\toldblk = &state->path.blk[0];\n\terror = xfs_da3_root_split(state, oldblk, addblk);\n\tif (error) {\n\t\taddblk->bp = NULL;\n\t\treturn(error);\t/* GROT: dir is inconsistent */\n\t}\n\n\t/*\n\t * Update pointers to the node which used to be block 0 and\n\t * just got bumped because of the addition of a new root node.\n\t * There might be three blocks involved if a double split occurred,\n\t * and the original block 0 could be at any position in the list.\n\t *\n\t * Note: the magic numbers and sibling pointers are in the same\n\t * physical place for both v2 and v3 headers (by design). Hence it\n\t * doesn't matter which version of the xfs_da_intnode structure we use\n\t * here as the result will be the same using either structure.\n\t */\n\tnode = oldblk->bp->b_addr;\n\tif (node->hdr.info.forw) {\n\t\tif (be32_to_cpu(node->hdr.info.forw) == addblk->blkno) {\n\t\t\tbp = addblk->bp;\n\t\t} else {\n\t\t\tASSERT(state->extravalid);\n\t\t\tbp = state->extrablk.bp;\n\t\t}\n\t\tnode = bp->b_addr;\n\t\tnode->hdr.info.back = cpu_to_be32(oldblk->blkno);\n\t\txfs_trans_log_buf(state->args->trans, bp,\n\t\t    XFS_DA_LOGRANGE(node, &node->hdr.info,\n\t\t    sizeof(node->hdr.info)));\n\t}\n\tnode = oldblk->bp->b_addr;\n\tif (node->hdr.info.back) {\n\t\tif (be32_to_cpu(node->hdr.info.back) == addblk->blkno) {\n\t\t\tbp = addblk->bp;\n\t\t} else {\n\t\t\tASSERT(state->extravalid);\n\t\t\tbp = state->extrablk.bp;\n\t\t}\n\t\tnode = bp->b_addr;\n\t\tnode->hdr.info.forw = cpu_to_be32(oldblk->blkno);\n\t\txfs_trans_log_buf(state->args->trans, bp,\n\t\t    XFS_DA_LOGRANGE(node, &node->hdr.info,\n\t\t    sizeof(node->hdr.info)));\n\t}\n\taddblk->bp = NULL;\n\treturn(0);\n}\n\n/*\n * Split the root.  We have to create a new root and point to the two\n * parts (the split old root) that we just created.  Copy block zero to\n * the EOF, extending the inode in process.\n */\nSTATIC int\t\t\t\t\t\t/* error */\nxfs_da3_root_split(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_blk\t*blk1,\n\tstruct xfs_da_state_blk\t*blk2)\n{\n\tstruct xfs_da_intnode\t*node;\n\tstruct xfs_da_intnode\t*oldroot;\n\tstruct xfs_da_node_entry *btree;\n\tstruct xfs_da3_icnode_hdr nodehdr;\n\tstruct xfs_da_args\t*args;\n\tstruct xfs_buf\t\t*bp;\n\tstruct xfs_inode\t*dp;\n\tstruct xfs_trans\t*tp;\n\tstruct xfs_mount\t*mp;\n\tstruct xfs_dir2_leaf\t*leaf;\n\txfs_dablk_t\t\tblkno;\n\tint\t\t\tlevel;\n\tint\t\t\terror;\n\tint\t\t\tsize;\n\n\ttrace_xfs_da_root_split(state->args);\n\n\t/*\n\t * Copy the existing (incorrect) block from the root node position\n\t * to a free space somewhere.\n\t */\n\targs = state->args;\n\terror = xfs_da_grow_inode(args, &blkno);\n\tif (error)\n\t\treturn error;\n\n\tdp = args->dp;\n\ttp = args->trans;\n\tmp = state->mp;\n\terror = xfs_da_get_buf(tp, dp, blkno, -1, &bp, args->whichfork);\n\tif (error)\n\t\treturn error;\n\tnode = bp->b_addr;\n\toldroot = blk1->bp->b_addr;\n\tif (oldroot->hdr.info.magic == cpu_to_be16(XFS_DA_NODE_MAGIC) ||\n\t    oldroot->hdr.info.magic == cpu_to_be16(XFS_DA3_NODE_MAGIC)) {\n\t\tstruct xfs_da3_icnode_hdr nodehdr;\n\n\t\tdp->d_ops->node_hdr_from_disk(&nodehdr, oldroot);\n\t\tbtree = dp->d_ops->node_tree_p(oldroot);\n\t\tsize = (int)((char *)&btree[nodehdr.count] - (char *)oldroot);\n\t\tlevel = nodehdr.level;\n\n\t\t/*\n\t\t * we are about to copy oldroot to bp, so set up the type\n\t\t * of bp while we know exactly what it will be.\n\t\t */\n\t\txfs_trans_buf_set_type(tp, bp, XFS_BLFT_DA_NODE_BUF);\n\t} else {\n\t\tstruct xfs_dir3_icleaf_hdr leafhdr;\n\t\tstruct xfs_dir2_leaf_entry *ents;\n\n\t\tleaf = (xfs_dir2_leaf_t *)oldroot;\n\t\tdp->d_ops->leaf_hdr_from_disk(&leafhdr, leaf);\n\t\tents = dp->d_ops->leaf_ents_p(leaf);\n\n\t\tASSERT(leafhdr.magic == XFS_DIR2_LEAFN_MAGIC ||\n\t\t       leafhdr.magic == XFS_DIR3_LEAFN_MAGIC);\n\t\tsize = (int)((char *)&ents[leafhdr.count] - (char *)leaf);\n\t\tlevel = 0;\n\n\t\t/*\n\t\t * we are about to copy oldroot to bp, so set up the type\n\t\t * of bp while we know exactly what it will be.\n\t\t */\n\t\txfs_trans_buf_set_type(tp, bp, XFS_BLFT_DIR_LEAFN_BUF);\n\t}\n\n\t/*\n\t * we can copy most of the information in the node from one block to\n\t * another, but for CRC enabled headers we have to make sure that the\n\t * block specific identifiers are kept intact. We update the buffer\n\t * directly for this.\n\t */\n\tmemcpy(node, oldroot, size);\n\tif (oldroot->hdr.info.magic == cpu_to_be16(XFS_DA3_NODE_MAGIC) ||\n\t    oldroot->hdr.info.magic == cpu_to_be16(XFS_DIR3_LEAFN_MAGIC)) {\n\t\tstruct xfs_da3_intnode *node3 = (struct xfs_da3_intnode *)node;\n\n\t\tnode3->hdr.info.blkno = cpu_to_be64(bp->b_bn);\n\t}\n\txfs_trans_log_buf(tp, bp, 0, size - 1);\n\n\tbp->b_ops = blk1->bp->b_ops;\n\txfs_trans_buf_copy_type(bp, blk1->bp);\n\tblk1->bp = bp;\n\tblk1->blkno = blkno;\n\n\t/*\n\t * Set up the new root node.\n\t */\n\terror = xfs_da3_node_create(args,\n\t\t(args->whichfork == XFS_DATA_FORK) ? mp->m_dirleafblk : 0,\n\t\tlevel + 1, &bp, args->whichfork);\n\tif (error)\n\t\treturn error;\n\n\tnode = bp->b_addr;\n\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\tbtree = dp->d_ops->node_tree_p(node);\n\tbtree[0].hashval = cpu_to_be32(blk1->hashval);\n\tbtree[0].before = cpu_to_be32(blk1->blkno);\n\tbtree[1].hashval = cpu_to_be32(blk2->hashval);\n\tbtree[1].before = cpu_to_be32(blk2->blkno);\n\tnodehdr.count = 2;\n\tdp->d_ops->node_hdr_to_disk(node, &nodehdr);\n\n#ifdef DEBUG\n\tif (oldroot->hdr.info.magic == cpu_to_be16(XFS_DIR2_LEAFN_MAGIC) ||\n\t    oldroot->hdr.info.magic == cpu_to_be16(XFS_DIR3_LEAFN_MAGIC)) {\n\t\tASSERT(blk1->blkno >= mp->m_dirleafblk &&\n\t\t       blk1->blkno < mp->m_dirfreeblk);\n\t\tASSERT(blk2->blkno >= mp->m_dirleafblk &&\n\t\t       blk2->blkno < mp->m_dirfreeblk);\n\t}\n#endif\n\n\t/* Header is already logged by xfs_da_node_create */\n\txfs_trans_log_buf(tp, bp,\n\t\tXFS_DA_LOGRANGE(node, btree, sizeof(xfs_da_node_entry_t) * 2));\n\n\treturn 0;\n}\n\n/*\n * Split the node, rebalance, then add the new entry.\n */\nSTATIC int\t\t\t\t\t\t/* error */\nxfs_da3_node_split(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_blk\t*oldblk,\n\tstruct xfs_da_state_blk\t*newblk,\n\tstruct xfs_da_state_blk\t*addblk,\n\tint\t\t\ttreelevel,\n\tint\t\t\t*result)\n{\n\tstruct xfs_da_intnode\t*node;\n\tstruct xfs_da3_icnode_hdr nodehdr;\n\txfs_dablk_t\t\tblkno;\n\tint\t\t\tnewcount;\n\tint\t\t\terror;\n\tint\t\t\tuseextra;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\ttrace_xfs_da_node_split(state->args);\n\n\tnode = oldblk->bp->b_addr;\n\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\n\t/*\n\t * With V2 dirs the extra block is data or freespace.\n\t */\n\tuseextra = state->extravalid && state->args->whichfork == XFS_ATTR_FORK;\n\tnewcount = 1 + useextra;\n\t/*\n\t * Do we have to split the node?\n\t */\n\tif (nodehdr.count + newcount > state->node_ents) {\n\t\t/*\n\t\t * Allocate a new node, add to the doubly linked chain of\n\t\t * nodes, then move some of our excess entries into it.\n\t\t */\n\t\terror = xfs_da_grow_inode(state->args, &blkno);\n\t\tif (error)\n\t\t\treturn(error);\t/* GROT: dir is inconsistent */\n\n\t\terror = xfs_da3_node_create(state->args, blkno, treelevel,\n\t\t\t\t\t   &newblk->bp, state->args->whichfork);\n\t\tif (error)\n\t\t\treturn(error);\t/* GROT: dir is inconsistent */\n\t\tnewblk->blkno = blkno;\n\t\tnewblk->magic = XFS_DA_NODE_MAGIC;\n\t\txfs_da3_node_rebalance(state, oldblk, newblk);\n\t\terror = xfs_da3_blk_link(state, oldblk, newblk);\n\t\tif (error)\n\t\t\treturn(error);\n\t\t*result = 1;\n\t} else {\n\t\t*result = 0;\n\t}\n\n\t/*\n\t * Insert the new entry(s) into the correct block\n\t * (updating last hashval in the process).\n\t *\n\t * xfs_da3_node_add() inserts BEFORE the given index,\n\t * and as a result of using node_lookup_int() we always\n\t * point to a valid entry (not after one), but a split\n\t * operation always results in a new block whose hashvals\n\t * FOLLOW the current block.\n\t *\n\t * If we had double-split op below us, then add the extra block too.\n\t */\n\tnode = oldblk->bp->b_addr;\n\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\tif (oldblk->index <= nodehdr.count) {\n\t\toldblk->index++;\n\t\txfs_da3_node_add(state, oldblk, addblk);\n\t\tif (useextra) {\n\t\t\tif (state->extraafter)\n\t\t\t\toldblk->index++;\n\t\t\txfs_da3_node_add(state, oldblk, &state->extrablk);\n\t\t\tstate->extravalid = 0;\n\t\t}\n\t} else {\n\t\tnewblk->index++;\n\t\txfs_da3_node_add(state, newblk, addblk);\n\t\tif (useextra) {\n\t\t\tif (state->extraafter)\n\t\t\t\tnewblk->index++;\n\t\t\txfs_da3_node_add(state, newblk, &state->extrablk);\n\t\t\tstate->extravalid = 0;\n\t\t}\n\t}\n\n\treturn(0);\n}\n\n/*\n * Balance the btree elements between two intermediate nodes,\n * usually one full and one empty.\n *\n * NOTE: if blk2 is empty, then it will get the upper half of blk1.\n */\nSTATIC void\nxfs_da3_node_rebalance(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_blk\t*blk1,\n\tstruct xfs_da_state_blk\t*blk2)\n{\n\tstruct xfs_da_intnode\t*node1;\n\tstruct xfs_da_intnode\t*node2;\n\tstruct xfs_da_intnode\t*tmpnode;\n\tstruct xfs_da_node_entry *btree1;\n\tstruct xfs_da_node_entry *btree2;\n\tstruct xfs_da_node_entry *btree_s;\n\tstruct xfs_da_node_entry *btree_d;\n\tstruct xfs_da3_icnode_hdr nodehdr1;\n\tstruct xfs_da3_icnode_hdr nodehdr2;\n\tstruct xfs_trans\t*tp;\n\tint\t\t\tcount;\n\tint\t\t\ttmp;\n\tint\t\t\tswap = 0;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\ttrace_xfs_da_node_rebalance(state->args);\n\n\tnode1 = blk1->bp->b_addr;\n\tnode2 = blk2->bp->b_addr;\n\tdp->d_ops->node_hdr_from_disk(&nodehdr1, node1);\n\tdp->d_ops->node_hdr_from_disk(&nodehdr2, node2);\n\tbtree1 = dp->d_ops->node_tree_p(node1);\n\tbtree2 = dp->d_ops->node_tree_p(node2);\n\n\t/*\n\t * Figure out how many entries need to move, and in which direction.\n\t * Swap the nodes around if that makes it simpler.\n\t */\n\tif (nodehdr1.count > 0 && nodehdr2.count > 0 &&\n\t    ((be32_to_cpu(btree2[0].hashval) < be32_to_cpu(btree1[0].hashval)) ||\n\t     (be32_to_cpu(btree2[nodehdr2.count - 1].hashval) <\n\t\t\tbe32_to_cpu(btree1[nodehdr1.count - 1].hashval)))) {\n\t\ttmpnode = node1;\n\t\tnode1 = node2;\n\t\tnode2 = tmpnode;\n\t\tdp->d_ops->node_hdr_from_disk(&nodehdr1, node1);\n\t\tdp->d_ops->node_hdr_from_disk(&nodehdr2, node2);\n\t\tbtree1 = dp->d_ops->node_tree_p(node1);\n\t\tbtree2 = dp->d_ops->node_tree_p(node2);\n\t\tswap = 1;\n\t}\n\n\tcount = (nodehdr1.count - nodehdr2.count) / 2;\n\tif (count == 0)\n\t\treturn;\n\ttp = state->args->trans;\n\t/*\n\t * Two cases: high-to-low and low-to-high.\n\t */\n\tif (count > 0) {\n\t\t/*\n\t\t * Move elements in node2 up to make a hole.\n\t\t */\n\t\ttmp = nodehdr2.count;\n\t\tif (tmp > 0) {\n\t\t\ttmp *= (uint)sizeof(xfs_da_node_entry_t);\n\t\t\tbtree_s = &btree2[0];\n\t\t\tbtree_d = &btree2[count];\n\t\t\tmemmove(btree_d, btree_s, tmp);\n\t\t}\n\n\t\t/*\n\t\t * Move the req'd B-tree elements from high in node1 to\n\t\t * low in node2.\n\t\t */\n\t\tnodehdr2.count += count;\n\t\ttmp = count * (uint)sizeof(xfs_da_node_entry_t);\n\t\tbtree_s = &btree1[nodehdr1.count - count];\n\t\tbtree_d = &btree2[0];\n\t\tmemcpy(btree_d, btree_s, tmp);\n\t\tnodehdr1.count -= count;\n\t} else {\n\t\t/*\n\t\t * Move the req'd B-tree elements from low in node2 to\n\t\t * high in node1.\n\t\t */\n\t\tcount = -count;\n\t\ttmp = count * (uint)sizeof(xfs_da_node_entry_t);\n\t\tbtree_s = &btree2[0];\n\t\tbtree_d = &btree1[nodehdr1.count];\n\t\tmemcpy(btree_d, btree_s, tmp);\n\t\tnodehdr1.count += count;\n\n\t\txfs_trans_log_buf(tp, blk1->bp,\n\t\t\tXFS_DA_LOGRANGE(node1, btree_d, tmp));\n\n\t\t/*\n\t\t * Move elements in node2 down to fill the hole.\n\t\t */\n\t\ttmp  = nodehdr2.count - count;\n\t\ttmp *= (uint)sizeof(xfs_da_node_entry_t);\n\t\tbtree_s = &btree2[count];\n\t\tbtree_d = &btree2[0];\n\t\tmemmove(btree_d, btree_s, tmp);\n\t\tnodehdr2.count -= count;\n\t}\n\n\t/*\n\t * Log header of node 1 and all current bits of node 2.\n\t */\n\tdp->d_ops->node_hdr_to_disk(node1, &nodehdr1);\n\txfs_trans_log_buf(tp, blk1->bp,\n\t\tXFS_DA_LOGRANGE(node1, &node1->hdr, dp->d_ops->node_hdr_size));\n\n\tdp->d_ops->node_hdr_to_disk(node2, &nodehdr2);\n\txfs_trans_log_buf(tp, blk2->bp,\n\t\tXFS_DA_LOGRANGE(node2, &node2->hdr,\n\t\t\t\tdp->d_ops->node_hdr_size +\n\t\t\t\t(sizeof(btree2[0]) * nodehdr2.count)));\n\n\t/*\n\t * Record the last hashval from each block for upward propagation.\n\t * (note: don't use the swapped node pointers)\n\t */\n\tif (swap) {\n\t\tnode1 = blk1->bp->b_addr;\n\t\tnode2 = blk2->bp->b_addr;\n\t\tdp->d_ops->node_hdr_from_disk(&nodehdr1, node1);\n\t\tdp->d_ops->node_hdr_from_disk(&nodehdr2, node2);\n\t\tbtree1 = dp->d_ops->node_tree_p(node1);\n\t\tbtree2 = dp->d_ops->node_tree_p(node2);\n\t}\n\tblk1->hashval = be32_to_cpu(btree1[nodehdr1.count - 1].hashval);\n\tblk2->hashval = be32_to_cpu(btree2[nodehdr2.count - 1].hashval);\n\n\t/*\n\t * Adjust the expected index for insertion.\n\t */\n\tif (blk1->index >= nodehdr1.count) {\n\t\tblk2->index = blk1->index - nodehdr1.count;\n\t\tblk1->index = nodehdr1.count + 1;\t/* make it invalid */\n\t}\n}\n\n/*\n * Add a new entry to an intermediate node.\n */\nSTATIC void\nxfs_da3_node_add(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_blk\t*oldblk,\n\tstruct xfs_da_state_blk\t*newblk)\n{\n\tstruct xfs_da_intnode\t*node;\n\tstruct xfs_da3_icnode_hdr nodehdr;\n\tstruct xfs_da_node_entry *btree;\n\tint\t\t\ttmp;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\ttrace_xfs_da_node_add(state->args);\n\n\tnode = oldblk->bp->b_addr;\n\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\tbtree = dp->d_ops->node_tree_p(node);\n\n\tASSERT(oldblk->index >= 0 && oldblk->index <= nodehdr.count);\n\tASSERT(newblk->blkno != 0);\n\tif (state->args->whichfork == XFS_DATA_FORK)\n\t\tASSERT(newblk->blkno >= state->mp->m_dirleafblk &&\n\t\t       newblk->blkno < state->mp->m_dirfreeblk);\n\n\t/*\n\t * We may need to make some room before we insert the new node.\n\t */\n\ttmp = 0;\n\tif (oldblk->index < nodehdr.count) {\n\t\ttmp = (nodehdr.count - oldblk->index) * (uint)sizeof(*btree);\n\t\tmemmove(&btree[oldblk->index + 1], &btree[oldblk->index], tmp);\n\t}\n\tbtree[oldblk->index].hashval = cpu_to_be32(newblk->hashval);\n\tbtree[oldblk->index].before = cpu_to_be32(newblk->blkno);\n\txfs_trans_log_buf(state->args->trans, oldblk->bp,\n\t\tXFS_DA_LOGRANGE(node, &btree[oldblk->index],\n\t\t\t\ttmp + sizeof(*btree)));\n\n\tnodehdr.count += 1;\n\tdp->d_ops->node_hdr_to_disk(node, &nodehdr);\n\txfs_trans_log_buf(state->args->trans, oldblk->bp,\n\t\tXFS_DA_LOGRANGE(node, &node->hdr, dp->d_ops->node_hdr_size));\n\n\t/*\n\t * Copy the last hash value from the oldblk to propagate upwards.\n\t */\n\toldblk->hashval = be32_to_cpu(btree[nodehdr.count - 1].hashval);\n}\n\n/*========================================================================\n * Routines used for shrinking the Btree.\n *========================================================================*/\n\n/*\n * Deallocate an empty leaf node, remove it from its parent,\n * possibly deallocating that block, etc...\n */\nint\nxfs_da3_join(\n\tstruct xfs_da_state\t*state)\n{\n\tstruct xfs_da_state_blk\t*drop_blk;\n\tstruct xfs_da_state_blk\t*save_blk;\n\tint\t\t\taction = 0;\n\tint\t\t\terror;\n\n\ttrace_xfs_da_join(state->args);\n\n\tdrop_blk = &state->path.blk[ state->path.active-1 ];\n\tsave_blk = &state->altpath.blk[ state->path.active-1 ];\n\tASSERT(state->path.blk[0].magic == XFS_DA_NODE_MAGIC);\n\tASSERT(drop_blk->magic == XFS_ATTR_LEAF_MAGIC ||\n\t       drop_blk->magic == XFS_DIR2_LEAFN_MAGIC);\n\n\t/*\n\t * Walk back up the tree joining/deallocating as necessary.\n\t * When we stop dropping blocks, break out.\n\t */\n\tfor (  ; state->path.active >= 2; drop_blk--, save_blk--,\n\t\t state->path.active--) {\n\t\t/*\n\t\t * See if we can combine the block with a neighbor.\n\t\t *   (action == 0) => no options, just leave\n\t\t *   (action == 1) => coalesce, then unlink\n\t\t *   (action == 2) => block empty, unlink it\n\t\t */\n\t\tswitch (drop_blk->magic) {\n\t\tcase XFS_ATTR_LEAF_MAGIC:\n\t\t\terror = xfs_attr3_leaf_toosmall(state, &action);\n\t\t\tif (error)\n\t\t\t\treturn(error);\n\t\t\tif (action == 0)\n\t\t\t\treturn(0);\n\t\t\txfs_attr3_leaf_unbalance(state, drop_blk, save_blk);\n\t\t\tbreak;\n\t\tcase XFS_DIR2_LEAFN_MAGIC:\n\t\t\terror = xfs_dir2_leafn_toosmall(state, &action);\n\t\t\tif (error)\n\t\t\t\treturn error;\n\t\t\tif (action == 0)\n\t\t\t\treturn 0;\n\t\t\txfs_dir2_leafn_unbalance(state, drop_blk, save_blk);\n\t\t\tbreak;\n\t\tcase XFS_DA_NODE_MAGIC:\n\t\t\t/*\n\t\t\t * Remove the offending node, fixup hashvals,\n\t\t\t * check for a toosmall neighbor.\n\t\t\t */\n\t\t\txfs_da3_node_remove(state, drop_blk);\n\t\t\txfs_da3_fixhashpath(state, &state->path);\n\t\t\terror = xfs_da3_node_toosmall(state, &action);\n\t\t\tif (error)\n\t\t\t\treturn(error);\n\t\t\tif (action == 0)\n\t\t\t\treturn 0;\n\t\t\txfs_da3_node_unbalance(state, drop_blk, save_blk);\n\t\t\tbreak;\n\t\t}\n\t\txfs_da3_fixhashpath(state, &state->altpath);\n\t\terror = xfs_da3_blk_unlink(state, drop_blk, save_blk);\n\t\txfs_da_state_kill_altpath(state);\n\t\tif (error)\n\t\t\treturn(error);\n\t\terror = xfs_da_shrink_inode(state->args, drop_blk->blkno,\n\t\t\t\t\t\t\t drop_blk->bp);\n\t\tdrop_blk->bp = NULL;\n\t\tif (error)\n\t\t\treturn(error);\n\t}\n\t/*\n\t * We joined all the way to the top.  If it turns out that\n\t * we only have one entry in the root, make the child block\n\t * the new root.\n\t */\n\txfs_da3_node_remove(state, drop_blk);\n\txfs_da3_fixhashpath(state, &state->path);\n\terror = xfs_da3_root_join(state, &state->path.blk[0]);\n\treturn(error);\n}\n\n#ifdef\tDEBUG\nstatic void\nxfs_da_blkinfo_onlychild_validate(struct xfs_da_blkinfo *blkinfo, __u16 level)\n{\n\t__be16\tmagic = blkinfo->magic;\n\n\tif (level == 1) {\n\t\tASSERT(magic == cpu_to_be16(XFS_DIR2_LEAFN_MAGIC) ||\n\t\t       magic == cpu_to_be16(XFS_DIR3_LEAFN_MAGIC) ||\n\t\t       magic == cpu_to_be16(XFS_ATTR_LEAF_MAGIC) ||\n\t\t       magic == cpu_to_be16(XFS_ATTR3_LEAF_MAGIC));\n\t} else {\n\t\tASSERT(magic == cpu_to_be16(XFS_DA_NODE_MAGIC) ||\n\t\t       magic == cpu_to_be16(XFS_DA3_NODE_MAGIC));\n\t}\n\tASSERT(!blkinfo->forw);\n\tASSERT(!blkinfo->back);\n}\n#else\t/* !DEBUG */\n#define\txfs_da_blkinfo_onlychild_validate(blkinfo, level)\n#endif\t/* !DEBUG */\n\n/*\n * We have only one entry in the root.  Copy the only remaining child of\n * the old root to block 0 as the new root node.\n */\nSTATIC int\nxfs_da3_root_join(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_blk\t*root_blk)\n{\n\tstruct xfs_da_intnode\t*oldroot;\n\tstruct xfs_da_args\t*args;\n\txfs_dablk_t\t\tchild;\n\tstruct xfs_buf\t\t*bp;\n\tstruct xfs_da3_icnode_hdr oldroothdr;\n\tstruct xfs_da_node_entry *btree;\n\tint\t\t\terror;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\ttrace_xfs_da_root_join(state->args);\n\n\tASSERT(root_blk->magic == XFS_DA_NODE_MAGIC);\n\n\targs = state->args;\n\toldroot = root_blk->bp->b_addr;\n\tdp->d_ops->node_hdr_from_disk(&oldroothdr, oldroot);\n\tASSERT(oldroothdr.forw == 0);\n\tASSERT(oldroothdr.back == 0);\n\n\t/*\n\t * If the root has more than one child, then don't do anything.\n\t */\n\tif (oldroothdr.count > 1)\n\t\treturn 0;\n\n\t/*\n\t * Read in the (only) child block, then copy those bytes into\n\t * the root block's buffer and free the original child block.\n\t */\n\tbtree = dp->d_ops->node_tree_p(oldroot);\n\tchild = be32_to_cpu(btree[0].before);\n\tASSERT(child != 0);\n\terror = xfs_da3_node_read(args->trans, dp, child, -1, &bp,\n\t\t\t\t\t     args->whichfork);\n\tif (error)\n\t\treturn error;\n\txfs_da_blkinfo_onlychild_validate(bp->b_addr, oldroothdr.level);\n\n\t/*\n\t * This could be copying a leaf back into the root block in the case of\n\t * there only being a single leaf block left in the tree. Hence we have\n\t * to update the b_ops pointer as well to match the buffer type change\n\t * that could occur. For dir3 blocks we also need to update the block\n\t * number in the buffer header.\n\t */\n\tmemcpy(root_blk->bp->b_addr, bp->b_addr, state->blocksize);\n\troot_blk->bp->b_ops = bp->b_ops;\n\txfs_trans_buf_copy_type(root_blk->bp, bp);\n\tif (oldroothdr.magic == XFS_DA3_NODE_MAGIC) {\n\t\tstruct xfs_da3_blkinfo *da3 = root_blk->bp->b_addr;\n\t\tda3->blkno = cpu_to_be64(root_blk->bp->b_bn);\n\t}\n\txfs_trans_log_buf(args->trans, root_blk->bp, 0, state->blocksize - 1);\n\terror = xfs_da_shrink_inode(args, child, bp);\n\treturn(error);\n}\n\n/*\n * Check a node block and its neighbors to see if the block should be\n * collapsed into one or the other neighbor.  Always keep the block\n * with the smaller block number.\n * If the current block is over 50% full, don't try to join it, return 0.\n * If the block is empty, fill in the state structure and return 2.\n * If it can be collapsed, fill in the state structure and return 1.\n * If nothing can be done, return 0.\n */\nSTATIC int\nxfs_da3_node_toosmall(\n\tstruct xfs_da_state\t*state,\n\tint\t\t\t*action)\n{\n\tstruct xfs_da_intnode\t*node;\n\tstruct xfs_da_state_blk\t*blk;\n\tstruct xfs_da_blkinfo\t*info;\n\txfs_dablk_t\t\tblkno;\n\tstruct xfs_buf\t\t*bp;\n\tstruct xfs_da3_icnode_hdr nodehdr;\n\tint\t\t\tcount;\n\tint\t\t\tforward;\n\tint\t\t\terror;\n\tint\t\t\tretval;\n\tint\t\t\ti;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\ttrace_xfs_da_node_toosmall(state->args);\n\n\t/*\n\t * Check for the degenerate case of the block being over 50% full.\n\t * If so, it's not worth even looking to see if we might be able\n\t * to coalesce with a sibling.\n\t */\n\tblk = &state->path.blk[ state->path.active-1 ];\n\tinfo = blk->bp->b_addr;\n\tnode = (xfs_da_intnode_t *)info;\n\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\tif (nodehdr.count > (state->node_ents >> 1)) {\n\t\t*action = 0;\t/* blk over 50%, don't try to join */\n\t\treturn(0);\t/* blk over 50%, don't try to join */\n\t}\n\n\t/*\n\t * Check for the degenerate case of the block being empty.\n\t * If the block is empty, we'll simply delete it, no need to\n\t * coalesce it with a sibling block.  We choose (arbitrarily)\n\t * to merge with the forward block unless it is NULL.\n\t */\n\tif (nodehdr.count == 0) {\n\t\t/*\n\t\t * Make altpath point to the block we want to keep and\n\t\t * path point to the block we want to drop (this one).\n\t\t */\n\t\tforward = (info->forw != 0);\n\t\tmemcpy(&state->altpath, &state->path, sizeof(state->path));\n\t\terror = xfs_da3_path_shift(state, &state->altpath, forward,\n\t\t\t\t\t\t 0, &retval);\n\t\tif (error)\n\t\t\treturn(error);\n\t\tif (retval) {\n\t\t\t*action = 0;\n\t\t} else {\n\t\t\t*action = 2;\n\t\t}\n\t\treturn(0);\n\t}\n\n\t/*\n\t * Examine each sibling block to see if we can coalesce with\n\t * at least 25% free space to spare.  We need to figure out\n\t * whether to merge with the forward or the backward block.\n\t * We prefer coalescing with the lower numbered sibling so as\n\t * to shrink a directory over time.\n\t */\n\tcount  = state->node_ents;\n\tcount -= state->node_ents >> 2;\n\tcount -= nodehdr.count;\n\n\t/* start with smaller blk num */\n\tforward = nodehdr.forw < nodehdr.back;\n\tfor (i = 0; i < 2; forward = !forward, i++) {\n\t\tstruct xfs_da3_icnode_hdr thdr;\n\t\tif (forward)\n\t\t\tblkno = nodehdr.forw;\n\t\telse\n\t\t\tblkno = nodehdr.back;\n\t\tif (blkno == 0)\n\t\t\tcontinue;\n\t\terror = xfs_da3_node_read(state->args->trans, dp,\n\t\t\t\t\tblkno, -1, &bp, state->args->whichfork);\n\t\tif (error)\n\t\t\treturn(error);\n\n\t\tnode = bp->b_addr;\n\t\tdp->d_ops->node_hdr_from_disk(&thdr, node);\n\t\txfs_trans_brelse(state->args->trans, bp);\n\n\t\tif (count - thdr.count >= 0)\n\t\t\tbreak;\t/* fits with at least 25% to spare */\n\t}\n\tif (i >= 2) {\n\t\t*action = 0;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Make altpath point to the block we want to keep (the lower\n\t * numbered block) and path point to the block we want to drop.\n\t */\n\tmemcpy(&state->altpath, &state->path, sizeof(state->path));\n\tif (blkno < blk->blkno) {\n\t\terror = xfs_da3_path_shift(state, &state->altpath, forward,\n\t\t\t\t\t\t 0, &retval);\n\t} else {\n\t\terror = xfs_da3_path_shift(state, &state->path, forward,\n\t\t\t\t\t\t 0, &retval);\n\t}\n\tif (error)\n\t\treturn error;\n\tif (retval) {\n\t\t*action = 0;\n\t\treturn 0;\n\t}\n\t*action = 1;\n\treturn 0;\n}\n\n/*\n * Pick up the last hashvalue from an intermediate node.\n */\nSTATIC uint\nxfs_da3_node_lasthash(\n\tstruct xfs_inode\t*dp,\n\tstruct xfs_buf\t\t*bp,\n\tint\t\t\t*count)\n{\n\tstruct xfs_da_intnode\t *node;\n\tstruct xfs_da_node_entry *btree;\n\tstruct xfs_da3_icnode_hdr nodehdr;\n\n\tnode = bp->b_addr;\n\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\tif (count)\n\t\t*count = nodehdr.count;\n\tif (!nodehdr.count)\n\t\treturn 0;\n\tbtree = dp->d_ops->node_tree_p(node);\n\treturn be32_to_cpu(btree[nodehdr.count - 1].hashval);\n}\n\n/*\n * Walk back up the tree adjusting hash values as necessary,\n * when we stop making changes, return.\n */\nvoid\nxfs_da3_fixhashpath(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_path *path)\n{\n\tstruct xfs_da_state_blk\t*blk;\n\tstruct xfs_da_intnode\t*node;\n\tstruct xfs_da_node_entry *btree;\n\txfs_dahash_t\t\tlasthash=0;\n\tint\t\t\tlevel;\n\tint\t\t\tcount;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\ttrace_xfs_da_fixhashpath(state->args);\n\n\tlevel = path->active-1;\n\tblk = &path->blk[ level ];\n\tswitch (blk->magic) {\n\tcase XFS_ATTR_LEAF_MAGIC:\n\t\tlasthash = xfs_attr_leaf_lasthash(blk->bp, &count);\n\t\tif (count == 0)\n\t\t\treturn;\n\t\tbreak;\n\tcase XFS_DIR2_LEAFN_MAGIC:\n\t\tlasthash = xfs_dir2_leafn_lasthash(dp, blk->bp, &count);\n\t\tif (count == 0)\n\t\t\treturn;\n\t\tbreak;\n\tcase XFS_DA_NODE_MAGIC:\n\t\tlasthash = xfs_da3_node_lasthash(dp, blk->bp, &count);\n\t\tif (count == 0)\n\t\t\treturn;\n\t\tbreak;\n\t}\n\tfor (blk--, level--; level >= 0; blk--, level--) {\n\t\tstruct xfs_da3_icnode_hdr nodehdr;\n\n\t\tnode = blk->bp->b_addr;\n\t\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\t\tbtree = dp->d_ops->node_tree_p(node);\n\t\tif (be32_to_cpu(btree->hashval) == lasthash)\n\t\t\tbreak;\n\t\tblk->hashval = lasthash;\n\t\tbtree[blk->index].hashval = cpu_to_be32(lasthash);\n\t\txfs_trans_log_buf(state->args->trans, blk->bp,\n\t\t\t\t  XFS_DA_LOGRANGE(node, &btree[blk->index],\n\t\t\t\t\t\t  sizeof(*btree)));\n\n\t\tlasthash = be32_to_cpu(btree[nodehdr.count - 1].hashval);\n\t}\n}\n\n/*\n * Remove an entry from an intermediate node.\n */\nSTATIC void\nxfs_da3_node_remove(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_blk\t*drop_blk)\n{\n\tstruct xfs_da_intnode\t*node;\n\tstruct xfs_da3_icnode_hdr nodehdr;\n\tstruct xfs_da_node_entry *btree;\n\tint\t\t\tindex;\n\tint\t\t\ttmp;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\ttrace_xfs_da_node_remove(state->args);\n\n\tnode = drop_blk->bp->b_addr;\n\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\tASSERT(drop_blk->index < nodehdr.count);\n\tASSERT(drop_blk->index >= 0);\n\n\t/*\n\t * Copy over the offending entry, or just zero it out.\n\t */\n\tindex = drop_blk->index;\n\tbtree = dp->d_ops->node_tree_p(node);\n\tif (index < nodehdr.count - 1) {\n\t\ttmp  = nodehdr.count - index - 1;\n\t\ttmp *= (uint)sizeof(xfs_da_node_entry_t);\n\t\tmemmove(&btree[index], &btree[index + 1], tmp);\n\t\txfs_trans_log_buf(state->args->trans, drop_blk->bp,\n\t\t    XFS_DA_LOGRANGE(node, &btree[index], tmp));\n\t\tindex = nodehdr.count - 1;\n\t}\n\tmemset(&btree[index], 0, sizeof(xfs_da_node_entry_t));\n\txfs_trans_log_buf(state->args->trans, drop_blk->bp,\n\t    XFS_DA_LOGRANGE(node, &btree[index], sizeof(btree[index])));\n\tnodehdr.count -= 1;\n\tdp->d_ops->node_hdr_to_disk(node, &nodehdr);\n\txfs_trans_log_buf(state->args->trans, drop_blk->bp,\n\t    XFS_DA_LOGRANGE(node, &node->hdr, dp->d_ops->node_hdr_size));\n\n\t/*\n\t * Copy the last hash value from the block to propagate upwards.\n\t */\n\tdrop_blk->hashval = be32_to_cpu(btree[index - 1].hashval);\n}\n\n/*\n * Unbalance the elements between two intermediate nodes,\n * move all Btree elements from one node into another.\n */\nSTATIC void\nxfs_da3_node_unbalance(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_blk\t*drop_blk,\n\tstruct xfs_da_state_blk\t*save_blk)\n{\n\tstruct xfs_da_intnode\t*drop_node;\n\tstruct xfs_da_intnode\t*save_node;\n\tstruct xfs_da_node_entry *drop_btree;\n\tstruct xfs_da_node_entry *save_btree;\n\tstruct xfs_da3_icnode_hdr drop_hdr;\n\tstruct xfs_da3_icnode_hdr save_hdr;\n\tstruct xfs_trans\t*tp;\n\tint\t\t\tsindex;\n\tint\t\t\ttmp;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\ttrace_xfs_da_node_unbalance(state->args);\n\n\tdrop_node = drop_blk->bp->b_addr;\n\tsave_node = save_blk->bp->b_addr;\n\tdp->d_ops->node_hdr_from_disk(&drop_hdr, drop_node);\n\tdp->d_ops->node_hdr_from_disk(&save_hdr, save_node);\n\tdrop_btree = dp->d_ops->node_tree_p(drop_node);\n\tsave_btree = dp->d_ops->node_tree_p(save_node);\n\ttp = state->args->trans;\n\n\t/*\n\t * If the dying block has lower hashvals, then move all the\n\t * elements in the remaining block up to make a hole.\n\t */\n\tif ((be32_to_cpu(drop_btree[0].hashval) <\n\t\t\tbe32_to_cpu(save_btree[0].hashval)) ||\n\t    (be32_to_cpu(drop_btree[drop_hdr.count - 1].hashval) <\n\t\t\tbe32_to_cpu(save_btree[save_hdr.count - 1].hashval))) {\n\t\t/* XXX: check this - is memmove dst correct? */\n\t\ttmp = save_hdr.count * sizeof(xfs_da_node_entry_t);\n\t\tmemmove(&save_btree[drop_hdr.count], &save_btree[0], tmp);\n\n\t\tsindex = 0;\n\t\txfs_trans_log_buf(tp, save_blk->bp,\n\t\t\tXFS_DA_LOGRANGE(save_node, &save_btree[0],\n\t\t\t\t(save_hdr.count + drop_hdr.count) *\n\t\t\t\t\t\tsizeof(xfs_da_node_entry_t)));\n\t} else {\n\t\tsindex = save_hdr.count;\n\t\txfs_trans_log_buf(tp, save_blk->bp,\n\t\t\tXFS_DA_LOGRANGE(save_node, &save_btree[sindex],\n\t\t\t\tdrop_hdr.count * sizeof(xfs_da_node_entry_t)));\n\t}\n\n\t/*\n\t * Move all the B-tree elements from drop_blk to save_blk.\n\t */\n\ttmp = drop_hdr.count * (uint)sizeof(xfs_da_node_entry_t);\n\tmemcpy(&save_btree[sindex], &drop_btree[0], tmp);\n\tsave_hdr.count += drop_hdr.count;\n\n\tdp->d_ops->node_hdr_to_disk(save_node, &save_hdr);\n\txfs_trans_log_buf(tp, save_blk->bp,\n\t\tXFS_DA_LOGRANGE(save_node, &save_node->hdr,\n\t\t\t\tdp->d_ops->node_hdr_size));\n\n\t/*\n\t * Save the last hashval in the remaining block for upward propagation.\n\t */\n\tsave_blk->hashval = be32_to_cpu(save_btree[save_hdr.count - 1].hashval);\n}\n\n/*========================================================================\n * Routines used for finding things in the Btree.\n *========================================================================*/\n\n/*\n * Walk down the Btree looking for a particular filename, filling\n * in the state structure as we go.\n *\n * We will set the state structure to point to each of the elements\n * in each of the nodes where either the hashval is or should be.\n *\n * We support duplicate hashval's so for each entry in the current\n * node that could contain the desired hashval, descend.  This is a\n * pruned depth-first tree search.\n */\nint\t\t\t\t\t\t\t/* error */\nxfs_da3_node_lookup_int(\n\tstruct xfs_da_state\t*state,\n\tint\t\t\t*result)\n{\n\tstruct xfs_da_state_blk\t*blk;\n\tstruct xfs_da_blkinfo\t*curr;\n\tstruct xfs_da_intnode\t*node;\n\tstruct xfs_da_node_entry *btree;\n\tstruct xfs_da3_icnode_hdr nodehdr;\n\tstruct xfs_da_args\t*args;\n\txfs_dablk_t\t\tblkno;\n\txfs_dahash_t\t\thashval;\n\txfs_dahash_t\t\tbtreehashval;\n\tint\t\t\tprobe;\n\tint\t\t\tspan;\n\tint\t\t\tmax;\n\tint\t\t\terror;\n\tint\t\t\tretval;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\targs = state->args;\n\n\t/*\n\t * Descend thru the B-tree searching each level for the right\n\t * node to use, until the right hashval is found.\n\t */\n\tblkno = (args->whichfork == XFS_DATA_FORK)? state->mp->m_dirleafblk : 0;\n\tfor (blk = &state->path.blk[0], state->path.active = 1;\n\t\t\t state->path.active <= XFS_DA_NODE_MAXDEPTH;\n\t\t\t blk++, state->path.active++) {\n\t\t/*\n\t\t * Read the next node down in the tree.\n\t\t */\n\t\tblk->blkno = blkno;\n\t\terror = xfs_da3_node_read(args->trans, args->dp, blkno,\n\t\t\t\t\t-1, &blk->bp, args->whichfork);\n\t\tif (error) {\n\t\t\tblk->blkno = 0;\n\t\t\tstate->path.active--;\n\t\t\treturn(error);\n\t\t}\n\t\tcurr = blk->bp->b_addr;\n\t\tblk->magic = be16_to_cpu(curr->magic);\n\n\t\tif (blk->magic == XFS_ATTR_LEAF_MAGIC ||\n\t\t    blk->magic == XFS_ATTR3_LEAF_MAGIC) {\n\t\t\tblk->magic = XFS_ATTR_LEAF_MAGIC;\n\t\t\tblk->hashval = xfs_attr_leaf_lasthash(blk->bp, NULL);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (blk->magic == XFS_DIR2_LEAFN_MAGIC ||\n\t\t    blk->magic == XFS_DIR3_LEAFN_MAGIC) {\n\t\t\tblk->magic = XFS_DIR2_LEAFN_MAGIC;\n\t\t\tblk->hashval = xfs_dir2_leafn_lasthash(args->dp,\n\t\t\t\t\t\t\t       blk->bp, NULL);\n\t\t\tbreak;\n\t\t}\n\n\t\tblk->magic = XFS_DA_NODE_MAGIC;\n\n\n\t\t/*\n\t\t * Search an intermediate node for a match.\n\t\t */\n\t\tnode = blk->bp->b_addr;\n\t\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\t\tbtree = dp->d_ops->node_tree_p(node);\n\n\t\tmax = nodehdr.count;\n\t\tblk->hashval = be32_to_cpu(btree[max - 1].hashval);\n\n\t\t/*\n\t\t * Binary search.  (note: small blocks will skip loop)\n\t\t */\n\t\tprobe = span = max / 2;\n\t\thashval = args->hashval;\n\t\twhile (span > 4) {\n\t\t\tspan /= 2;\n\t\t\tbtreehashval = be32_to_cpu(btree[probe].hashval);\n\t\t\tif (btreehashval < hashval)\n\t\t\t\tprobe += span;\n\t\t\telse if (btreehashval > hashval)\n\t\t\t\tprobe -= span;\n\t\t\telse\n\t\t\t\tbreak;\n\t\t}\n\t\tASSERT((probe >= 0) && (probe < max));\n\t\tASSERT((span <= 4) ||\n\t\t\t(be32_to_cpu(btree[probe].hashval) == hashval));\n\n\t\t/*\n\t\t * Since we may have duplicate hashval's, find the first\n\t\t * matching hashval in the node.\n\t\t */\n\t\twhile (probe > 0 &&\n\t\t       be32_to_cpu(btree[probe].hashval) >= hashval) {\n\t\t\tprobe--;\n\t\t}\n\t\twhile (probe < max &&\n\t\t       be32_to_cpu(btree[probe].hashval) < hashval) {\n\t\t\tprobe++;\n\t\t}\n\n\t\t/*\n\t\t * Pick the right block to descend on.\n\t\t */\n\t\tif (probe == max) {\n\t\t\tblk->index = max - 1;\n\t\t\tblkno = be32_to_cpu(btree[max - 1].before);\n\t\t} else {\n\t\t\tblk->index = probe;\n\t\t\tblkno = be32_to_cpu(btree[probe].before);\n\t\t}\n\t}\n\n\t/*\n\t * A leaf block that ends in the hashval that we are interested in\n\t * (final hashval == search hashval) means that the next block may\n\t * contain more entries with the same hashval, shift upward to the\n\t * next leaf and keep searching.\n\t */\n\tfor (;;) {\n\t\tif (blk->magic == XFS_DIR2_LEAFN_MAGIC) {\n\t\t\tretval = xfs_dir2_leafn_lookup_int(blk->bp, args,\n\t\t\t\t\t\t\t&blk->index, state);\n\t\t} else if (blk->magic == XFS_ATTR_LEAF_MAGIC) {\n\t\t\tretval = xfs_attr3_leaf_lookup_int(blk->bp, args);\n\t\t\tblk->index = args->index;\n\t\t\targs->blkno = blk->blkno;\n\t\t} else {\n\t\t\tASSERT(0);\n\t\t\treturn XFS_ERROR(EFSCORRUPTED);\n\t\t}\n\t\tif (((retval == ENOENT) || (retval == ENOATTR)) &&\n\t\t    (blk->hashval == args->hashval)) {\n\t\t\terror = xfs_da3_path_shift(state, &state->path, 1, 1,\n\t\t\t\t\t\t\t &retval);\n\t\t\tif (error)\n\t\t\t\treturn(error);\n\t\t\tif (retval == 0) {\n\t\t\t\tcontinue;\n\t\t\t} else if (blk->magic == XFS_ATTR_LEAF_MAGIC) {\n\t\t\t\t/* path_shift() gives ENOENT */\n\t\t\t\tretval = XFS_ERROR(ENOATTR);\n\t\t\t}\n\t\t}\n\t\tbreak;\n\t}\n\t*result = retval;\n\treturn(0);\n}\n\n/*========================================================================\n * Utility routines.\n *========================================================================*/\n\n/*\n * Compare two intermediate nodes for \"order\".\n */\nSTATIC int\nxfs_da3_node_order(\n\tstruct xfs_inode *dp,\n\tstruct xfs_buf\t*node1_bp,\n\tstruct xfs_buf\t*node2_bp)\n{\n\tstruct xfs_da_intnode\t*node1;\n\tstruct xfs_da_intnode\t*node2;\n\tstruct xfs_da_node_entry *btree1;\n\tstruct xfs_da_node_entry *btree2;\n\tstruct xfs_da3_icnode_hdr node1hdr;\n\tstruct xfs_da3_icnode_hdr node2hdr;\n\n\tnode1 = node1_bp->b_addr;\n\tnode2 = node2_bp->b_addr;\n\tdp->d_ops->node_hdr_from_disk(&node1hdr, node1);\n\tdp->d_ops->node_hdr_from_disk(&node2hdr, node2);\n\tbtree1 = dp->d_ops->node_tree_p(node1);\n\tbtree2 = dp->d_ops->node_tree_p(node2);\n\n\tif (node1hdr.count > 0 && node2hdr.count > 0 &&\n\t    ((be32_to_cpu(btree2[0].hashval) < be32_to_cpu(btree1[0].hashval)) ||\n\t     (be32_to_cpu(btree2[node2hdr.count - 1].hashval) <\n\t      be32_to_cpu(btree1[node1hdr.count - 1].hashval)))) {\n\t\treturn 1;\n\t}\n\treturn 0;\n}\n\n/*\n * Link a new block into a doubly linked list of blocks (of whatever type).\n */\nint\t\t\t\t\t\t\t/* error */\nxfs_da3_blk_link(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_blk\t*old_blk,\n\tstruct xfs_da_state_blk\t*new_blk)\n{\n\tstruct xfs_da_blkinfo\t*old_info;\n\tstruct xfs_da_blkinfo\t*new_info;\n\tstruct xfs_da_blkinfo\t*tmp_info;\n\tstruct xfs_da_args\t*args;\n\tstruct xfs_buf\t\t*bp;\n\tint\t\t\tbefore = 0;\n\tint\t\t\terror;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\t/*\n\t * Set up environment.\n\t */\n\targs = state->args;\n\tASSERT(args != NULL);\n\told_info = old_blk->bp->b_addr;\n\tnew_info = new_blk->bp->b_addr;\n\tASSERT(old_blk->magic == XFS_DA_NODE_MAGIC ||\n\t       old_blk->magic == XFS_DIR2_LEAFN_MAGIC ||\n\t       old_blk->magic == XFS_ATTR_LEAF_MAGIC);\n\n\tswitch (old_blk->magic) {\n\tcase XFS_ATTR_LEAF_MAGIC:\n\t\tbefore = xfs_attr_leaf_order(old_blk->bp, new_blk->bp);\n\t\tbreak;\n\tcase XFS_DIR2_LEAFN_MAGIC:\n\t\tbefore = xfs_dir2_leafn_order(dp, old_blk->bp, new_blk->bp);\n\t\tbreak;\n\tcase XFS_DA_NODE_MAGIC:\n\t\tbefore = xfs_da3_node_order(dp, old_blk->bp, new_blk->bp);\n\t\tbreak;\n\t}\n\n\t/*\n\t * Link blocks in appropriate order.\n\t */\n\tif (before) {\n\t\t/*\n\t\t * Link new block in before existing block.\n\t\t */\n\t\ttrace_xfs_da_link_before(args);\n\t\tnew_info->forw = cpu_to_be32(old_blk->blkno);\n\t\tnew_info->back = old_info->back;\n\t\tif (old_info->back) {\n\t\t\terror = xfs_da3_node_read(args->trans, dp,\n\t\t\t\t\t\tbe32_to_cpu(old_info->back),\n\t\t\t\t\t\t-1, &bp, args->whichfork);\n\t\t\tif (error)\n\t\t\t\treturn(error);\n\t\t\tASSERT(bp != NULL);\n\t\t\ttmp_info = bp->b_addr;\n\t\t\tASSERT(tmp_info->magic == old_info->magic);\n\t\t\tASSERT(be32_to_cpu(tmp_info->forw) == old_blk->blkno);\n\t\t\ttmp_info->forw = cpu_to_be32(new_blk->blkno);\n\t\t\txfs_trans_log_buf(args->trans, bp, 0, sizeof(*tmp_info)-1);\n\t\t}\n\t\told_info->back = cpu_to_be32(new_blk->blkno);\n\t} else {\n\t\t/*\n\t\t * Link new block in after existing block.\n\t\t */\n\t\ttrace_xfs_da_link_after(args);\n\t\tnew_info->forw = old_info->forw;\n\t\tnew_info->back = cpu_to_be32(old_blk->blkno);\n\t\tif (old_info->forw) {\n\t\t\terror = xfs_da3_node_read(args->trans, dp,\n\t\t\t\t\t\tbe32_to_cpu(old_info->forw),\n\t\t\t\t\t\t-1, &bp, args->whichfork);\n\t\t\tif (error)\n\t\t\t\treturn(error);\n\t\t\tASSERT(bp != NULL);\n\t\t\ttmp_info = bp->b_addr;\n\t\t\tASSERT(tmp_info->magic == old_info->magic);\n\t\t\tASSERT(be32_to_cpu(tmp_info->back) == old_blk->blkno);\n\t\t\ttmp_info->back = cpu_to_be32(new_blk->blkno);\n\t\t\txfs_trans_log_buf(args->trans, bp, 0, sizeof(*tmp_info)-1);\n\t\t}\n\t\told_info->forw = cpu_to_be32(new_blk->blkno);\n\t}\n\n\txfs_trans_log_buf(args->trans, old_blk->bp, 0, sizeof(*tmp_info) - 1);\n\txfs_trans_log_buf(args->trans, new_blk->bp, 0, sizeof(*tmp_info) - 1);\n\treturn(0);\n}\n\n/*\n * Unlink a block from a doubly linked list of blocks.\n */\nSTATIC int\t\t\t\t\t\t/* error */\nxfs_da3_blk_unlink(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_blk\t*drop_blk,\n\tstruct xfs_da_state_blk\t*save_blk)\n{\n\tstruct xfs_da_blkinfo\t*drop_info;\n\tstruct xfs_da_blkinfo\t*save_info;\n\tstruct xfs_da_blkinfo\t*tmp_info;\n\tstruct xfs_da_args\t*args;\n\tstruct xfs_buf\t\t*bp;\n\tint\t\t\terror;\n\n\t/*\n\t * Set up environment.\n\t */\n\targs = state->args;\n\tASSERT(args != NULL);\n\tsave_info = save_blk->bp->b_addr;\n\tdrop_info = drop_blk->bp->b_addr;\n\tASSERT(save_blk->magic == XFS_DA_NODE_MAGIC ||\n\t       save_blk->magic == XFS_DIR2_LEAFN_MAGIC ||\n\t       save_blk->magic == XFS_ATTR_LEAF_MAGIC);\n\tASSERT(save_blk->magic == drop_blk->magic);\n\tASSERT((be32_to_cpu(save_info->forw) == drop_blk->blkno) ||\n\t       (be32_to_cpu(save_info->back) == drop_blk->blkno));\n\tASSERT((be32_to_cpu(drop_info->forw) == save_blk->blkno) ||\n\t       (be32_to_cpu(drop_info->back) == save_blk->blkno));\n\n\t/*\n\t * Unlink the leaf block from the doubly linked chain of leaves.\n\t */\n\tif (be32_to_cpu(save_info->back) == drop_blk->blkno) {\n\t\ttrace_xfs_da_unlink_back(args);\n\t\tsave_info->back = drop_info->back;\n\t\tif (drop_info->back) {\n\t\t\terror = xfs_da3_node_read(args->trans, args->dp,\n\t\t\t\t\t\tbe32_to_cpu(drop_info->back),\n\t\t\t\t\t\t-1, &bp, args->whichfork);\n\t\t\tif (error)\n\t\t\t\treturn(error);\n\t\t\tASSERT(bp != NULL);\n\t\t\ttmp_info = bp->b_addr;\n\t\t\tASSERT(tmp_info->magic == save_info->magic);\n\t\t\tASSERT(be32_to_cpu(tmp_info->forw) == drop_blk->blkno);\n\t\t\ttmp_info->forw = cpu_to_be32(save_blk->blkno);\n\t\t\txfs_trans_log_buf(args->trans, bp, 0,\n\t\t\t\t\t\t    sizeof(*tmp_info) - 1);\n\t\t}\n\t} else {\n\t\ttrace_xfs_da_unlink_forward(args);\n\t\tsave_info->forw = drop_info->forw;\n\t\tif (drop_info->forw) {\n\t\t\terror = xfs_da3_node_read(args->trans, args->dp,\n\t\t\t\t\t\tbe32_to_cpu(drop_info->forw),\n\t\t\t\t\t\t-1, &bp, args->whichfork);\n\t\t\tif (error)\n\t\t\t\treturn(error);\n\t\t\tASSERT(bp != NULL);\n\t\t\ttmp_info = bp->b_addr;\n\t\t\tASSERT(tmp_info->magic == save_info->magic);\n\t\t\tASSERT(be32_to_cpu(tmp_info->back) == drop_blk->blkno);\n\t\t\ttmp_info->back = cpu_to_be32(save_blk->blkno);\n\t\t\txfs_trans_log_buf(args->trans, bp, 0,\n\t\t\t\t\t\t    sizeof(*tmp_info) - 1);\n\t\t}\n\t}\n\n\txfs_trans_log_buf(args->trans, save_blk->bp, 0, sizeof(*save_info) - 1);\n\treturn(0);\n}\n\n/*\n * Move a path \"forward\" or \"!forward\" one block at the current level.\n *\n * This routine will adjust a \"path\" to point to the next block\n * \"forward\" (higher hashvalues) or \"!forward\" (lower hashvals) in the\n * Btree, including updating pointers to the intermediate nodes between\n * the new bottom and the root.\n */\nint\t\t\t\t\t\t\t/* error */\nxfs_da3_path_shift(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_path *path,\n\tint\t\t\tforward,\n\tint\t\t\trelease,\n\tint\t\t\t*result)\n{\n\tstruct xfs_da_state_blk\t*blk;\n\tstruct xfs_da_blkinfo\t*info;\n\tstruct xfs_da_intnode\t*node;\n\tstruct xfs_da_args\t*args;\n\tstruct xfs_da_node_entry *btree;\n\tstruct xfs_da3_icnode_hdr nodehdr;\n\txfs_dablk_t\t\tblkno = 0;\n\tint\t\t\tlevel;\n\tint\t\t\terror;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\ttrace_xfs_da_path_shift(state->args);\n\n\t/*\n\t * Roll up the Btree looking for the first block where our\n\t * current index is not at the edge of the block.  Note that\n\t * we skip the bottom layer because we want the sibling block.\n\t */\n\targs = state->args;\n\tASSERT(args != NULL);\n\tASSERT(path != NULL);\n\tASSERT((path->active > 0) && (path->active < XFS_DA_NODE_MAXDEPTH));\n\tlevel = (path->active-1) - 1;\t/* skip bottom layer in path */\n\tfor (blk = &path->blk[level]; level >= 0; blk--, level--) {\n\t\tnode = blk->bp->b_addr;\n\t\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\t\tbtree = dp->d_ops->node_tree_p(node);\n\n\t\tif (forward && (blk->index < nodehdr.count - 1)) {\n\t\t\tblk->index++;\n\t\t\tblkno = be32_to_cpu(btree[blk->index].before);\n\t\t\tbreak;\n\t\t} else if (!forward && (blk->index > 0)) {\n\t\t\tblk->index--;\n\t\t\tblkno = be32_to_cpu(btree[blk->index].before);\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (level < 0) {\n\t\t*result = XFS_ERROR(ENOENT);\t/* we're out of our tree */\n\t\tASSERT(args->op_flags & XFS_DA_OP_OKNOENT);\n\t\treturn(0);\n\t}\n\n\t/*\n\t * Roll down the edge of the subtree until we reach the\n\t * same depth we were at originally.\n\t */\n\tfor (blk++, level++; level < path->active; blk++, level++) {\n\t\t/*\n\t\t * Release the old block.\n\t\t * (if it's dirty, trans won't actually let go)\n\t\t */\n\t\tif (release)\n\t\t\txfs_trans_brelse(args->trans, blk->bp);\n\n\t\t/*\n\t\t * Read the next child block.\n\t\t */\n\t\tblk->blkno = blkno;\n\t\terror = xfs_da3_node_read(args->trans, dp, blkno, -1,\n\t\t\t\t\t&blk->bp, args->whichfork);\n\t\tif (error)\n\t\t\treturn(error);\n\t\tinfo = blk->bp->b_addr;\n\t\tASSERT(info->magic == cpu_to_be16(XFS_DA_NODE_MAGIC) ||\n\t\t       info->magic == cpu_to_be16(XFS_DA3_NODE_MAGIC) ||\n\t\t       info->magic == cpu_to_be16(XFS_DIR2_LEAFN_MAGIC) ||\n\t\t       info->magic == cpu_to_be16(XFS_DIR3_LEAFN_MAGIC) ||\n\t\t       info->magic == cpu_to_be16(XFS_ATTR_LEAF_MAGIC) ||\n\t\t       info->magic == cpu_to_be16(XFS_ATTR3_LEAF_MAGIC));\n\n\n\t\t/*\n\t\t * Note: we flatten the magic number to a single type so we\n\t\t * don't have to compare against crc/non-crc types elsewhere.\n\t\t */\n\t\tswitch (be16_to_cpu(info->magic)) {\n\t\tcase XFS_DA_NODE_MAGIC:\n\t\tcase XFS_DA3_NODE_MAGIC:\n\t\t\tblk->magic = XFS_DA_NODE_MAGIC;\n\t\t\tnode = (xfs_da_intnode_t *)info;\n\t\t\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\t\t\tbtree = dp->d_ops->node_tree_p(node);\n\t\t\tblk->hashval = be32_to_cpu(btree[nodehdr.count - 1].hashval);\n\t\t\tif (forward)\n\t\t\t\tblk->index = 0;\n\t\t\telse\n\t\t\t\tblk->index = nodehdr.count - 1;\n\t\t\tblkno = be32_to_cpu(btree[blk->index].before);\n\t\t\tbreak;\n\t\tcase XFS_ATTR_LEAF_MAGIC:\n\t\tcase XFS_ATTR3_LEAF_MAGIC:\n\t\t\tblk->magic = XFS_ATTR_LEAF_MAGIC;\n\t\t\tASSERT(level == path->active-1);\n\t\t\tblk->index = 0;\n\t\t\tblk->hashval = xfs_attr_leaf_lasthash(blk->bp, NULL);\n\t\t\tbreak;\n\t\tcase XFS_DIR2_LEAFN_MAGIC:\n\t\tcase XFS_DIR3_LEAFN_MAGIC:\n\t\t\tblk->magic = XFS_DIR2_LEAFN_MAGIC;\n\t\t\tASSERT(level == path->active-1);\n\t\t\tblk->index = 0;\n\t\t\tblk->hashval = xfs_dir2_leafn_lasthash(args->dp,\n\t\t\t\t\t\t\t       blk->bp, NULL);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tASSERT(0);\n\t\t\tbreak;\n\t\t}\n\t}\n\t*result = 0;\n\treturn 0;\n}\n\n\n/*========================================================================\n * Utility routines.\n *========================================================================*/\n\n/*\n * Implement a simple hash on a character string.\n * Rotate the hash value by 7 bits, then XOR each character in.\n * This is implemented with some source-level loop unrolling.\n */\nxfs_dahash_t\nxfs_da_hashname(const __uint8_t *name, int namelen)\n{\n\txfs_dahash_t hash;\n\n\t/*\n\t * Do four characters at a time as long as we can.\n\t */\n\tfor (hash = 0; namelen >= 4; namelen -= 4, name += 4)\n\t\thash = (name[0] << 21) ^ (name[1] << 14) ^ (name[2] << 7) ^\n\t\t       (name[3] << 0) ^ rol32(hash, 7 * 4);\n\n\t/*\n\t * Now do the rest of the characters.\n\t */\n\tswitch (namelen) {\n\tcase 3:\n\t\treturn (name[0] << 14) ^ (name[1] << 7) ^ (name[2] << 0) ^\n\t\t       rol32(hash, 7 * 3);\n\tcase 2:\n\t\treturn (name[0] << 7) ^ (name[1] << 0) ^ rol32(hash, 7 * 2);\n\tcase 1:\n\t\treturn (name[0] << 0) ^ rol32(hash, 7 * 1);\n\tdefault: /* case 0: */\n\t\treturn hash;\n\t}\n}\n\nenum xfs_dacmp\nxfs_da_compname(\n\tstruct xfs_da_args *args,\n\tconst unsigned char *name,\n\tint\t\tlen)\n{\n\treturn (args->namelen == len && memcmp(args->name, name, len) == 0) ?\n\t\t\t\t\tXFS_CMP_EXACT : XFS_CMP_DIFFERENT;\n}\n\nstatic xfs_dahash_t\nxfs_default_hashname(\n\tstruct xfs_name\t*name)\n{\n\treturn xfs_da_hashname(name->name, name->len);\n}\n\nconst struct xfs_nameops xfs_default_nameops = {\n\t.hashname\t= xfs_default_hashname,\n\t.compname\t= xfs_da_compname\n};\n\nint\nxfs_da_grow_inode_int(\n\tstruct xfs_da_args\t*args,\n\txfs_fileoff_t\t\t*bno,\n\tint\t\t\tcount)\n{\n\tstruct xfs_trans\t*tp = args->trans;\n\tstruct xfs_inode\t*dp = args->dp;\n\tint\t\t\tw = args->whichfork;\n\txfs_drfsbno_t\t\tnblks = dp->i_d.di_nblocks;\n\tstruct xfs_bmbt_irec\tmap, *mapp;\n\tint\t\t\tnmap, error, got, i, mapi;\n\n\t/*\n\t * Find a spot in the file space to put the new block.\n\t */\n\terror = xfs_bmap_first_unused(tp, dp, count, bno, w);\n\tif (error)\n\t\treturn error;\n\n\t/*\n\t * Try mapping it in one filesystem block.\n\t */\n\tnmap = 1;\n\tASSERT(args->firstblock != NULL);\n\terror = xfs_bmapi_write(tp, dp, *bno, count,\n\t\t\txfs_bmapi_aflag(w)|XFS_BMAPI_METADATA|XFS_BMAPI_CONTIG,\n\t\t\targs->firstblock, args->total, &map, &nmap,\n\t\t\targs->flist);\n\tif (error)\n\t\treturn error;\n\n\tASSERT(nmap <= 1);\n\tif (nmap == 1) {\n\t\tmapp = &map;\n\t\tmapi = 1;\n\t} else if (nmap == 0 && count > 1) {\n\t\txfs_fileoff_t\t\tb;\n\t\tint\t\t\tc;\n\n\t\t/*\n\t\t * If we didn't get it and the block might work if fragmented,\n\t\t * try without the CONTIG flag.  Loop until we get it all.\n\t\t */\n\t\tmapp = kmem_alloc(sizeof(*mapp) * count, KM_SLEEP);\n\t\tfor (b = *bno, mapi = 0; b < *bno + count; ) {\n\t\t\tnmap = MIN(XFS_BMAP_MAX_NMAP, count);\n\t\t\tc = (int)(*bno + count - b);\n\t\t\terror = xfs_bmapi_write(tp, dp, b, c,\n\t\t\t\t\txfs_bmapi_aflag(w)|XFS_BMAPI_METADATA,\n\t\t\t\t\targs->firstblock, args->total,\n\t\t\t\t\t&mapp[mapi], &nmap, args->flist);\n\t\t\tif (error)\n\t\t\t\tgoto out_free_map;\n\t\t\tif (nmap < 1)\n\t\t\t\tbreak;\n\t\t\tmapi += nmap;\n\t\t\tb = mapp[mapi - 1].br_startoff +\n\t\t\t    mapp[mapi - 1].br_blockcount;\n\t\t}\n\t} else {\n\t\tmapi = 0;\n\t\tmapp = NULL;\n\t}\n\n\t/*\n\t * Count the blocks we got, make sure it matches the total.\n\t */\n\tfor (i = 0, got = 0; i < mapi; i++)\n\t\tgot += mapp[i].br_blockcount;\n\tif (got != count || mapp[0].br_startoff != *bno ||\n\t    mapp[mapi - 1].br_startoff + mapp[mapi - 1].br_blockcount !=\n\t    *bno + count) {\n\t\terror = XFS_ERROR(ENOSPC);\n\t\tgoto out_free_map;\n\t}\n\n\t/* account for newly allocated blocks in reserved blocks total */\n\targs->total -= dp->i_d.di_nblocks - nblks;\n\nout_free_map:\n\tif (mapp != &map)\n\t\tkmem_free(mapp);\n\treturn error;\n}\n\n/*\n * Add a block to the btree ahead of the file.\n * Return the new block number to the caller.\n */\nint\nxfs_da_grow_inode(\n\tstruct xfs_da_args\t*args,\n\txfs_dablk_t\t\t*new_blkno)\n{\n\txfs_fileoff_t\t\tbno;\n\tint\t\t\tcount;\n\tint\t\t\terror;\n\n\ttrace_xfs_da_grow_inode(args);\n\n\tif (args->whichfork == XFS_DATA_FORK) {\n\t\tbno = args->dp->i_mount->m_dirleafblk;\n\t\tcount = args->dp->i_mount->m_dirblkfsbs;\n\t} else {\n\t\tbno = 0;\n\t\tcount = 1;\n\t}\n\n\terror = xfs_da_grow_inode_int(args, &bno, count);\n\tif (!error)\n\t\t*new_blkno = (xfs_dablk_t)bno;\n\treturn error;\n}\n\n/*\n * Ick.  We need to always be able to remove a btree block, even\n * if there's no space reservation because the filesystem is full.\n * This is called if xfs_bunmapi on a btree block fails due to ENOSPC.\n * It swaps the target block with the last block in the file.  The\n * last block in the file can always be removed since it can't cause\n * a bmap btree split to do that.\n */\nSTATIC int\nxfs_da3_swap_lastblock(\n\tstruct xfs_da_args\t*args,\n\txfs_dablk_t\t\t*dead_blknop,\n\tstruct xfs_buf\t\t**dead_bufp)\n{\n\tstruct xfs_da_blkinfo\t*dead_info;\n\tstruct xfs_da_blkinfo\t*sib_info;\n\tstruct xfs_da_intnode\t*par_node;\n\tstruct xfs_da_intnode\t*dead_node;\n\tstruct xfs_dir2_leaf\t*dead_leaf2;\n\tstruct xfs_da_node_entry *btree;\n\tstruct xfs_da3_icnode_hdr par_hdr;\n\tstruct xfs_inode\t*dp;\n\tstruct xfs_trans\t*tp;\n\tstruct xfs_mount\t*mp;\n\tstruct xfs_buf\t\t*dead_buf;\n\tstruct xfs_buf\t\t*last_buf;\n\tstruct xfs_buf\t\t*sib_buf;\n\tstruct xfs_buf\t\t*par_buf;\n\txfs_dahash_t\t\tdead_hash;\n\txfs_fileoff_t\t\tlastoff;\n\txfs_dablk_t\t\tdead_blkno;\n\txfs_dablk_t\t\tlast_blkno;\n\txfs_dablk_t\t\tsib_blkno;\n\txfs_dablk_t\t\tpar_blkno;\n\tint\t\t\terror;\n\tint\t\t\tw;\n\tint\t\t\tentno;\n\tint\t\t\tlevel;\n\tint\t\t\tdead_level;\n\n\ttrace_xfs_da_swap_lastblock(args);\n\n\tdead_buf = *dead_bufp;\n\tdead_blkno = *dead_blknop;\n\ttp = args->trans;\n\tdp = args->dp;\n\tw = args->whichfork;\n\tASSERT(w == XFS_DATA_FORK);\n\tmp = dp->i_mount;\n\tlastoff = mp->m_dirfreeblk;\n\terror = xfs_bmap_last_before(tp, dp, &lastoff, w);\n\tif (error)\n\t\treturn error;\n\tif (unlikely(lastoff == 0)) {\n\t\tXFS_ERROR_REPORT(\"xfs_da_swap_lastblock(1)\", XFS_ERRLEVEL_LOW,\n\t\t\t\t mp);\n\t\treturn XFS_ERROR(EFSCORRUPTED);\n\t}\n\t/*\n\t * Read the last block in the btree space.\n\t */\n\tlast_blkno = (xfs_dablk_t)lastoff - mp->m_dirblkfsbs;\n\terror = xfs_da3_node_read(tp, dp, last_blkno, -1, &last_buf, w);\n\tif (error)\n\t\treturn error;\n\t/*\n\t * Copy the last block into the dead buffer and log it.\n\t */\n\tmemcpy(dead_buf->b_addr, last_buf->b_addr, mp->m_dirblksize);\n\txfs_trans_log_buf(tp, dead_buf, 0, mp->m_dirblksize - 1);\n\tdead_info = dead_buf->b_addr;\n\t/*\n\t * Get values from the moved block.\n\t */\n\tif (dead_info->magic == cpu_to_be16(XFS_DIR2_LEAFN_MAGIC) ||\n\t    dead_info->magic == cpu_to_be16(XFS_DIR3_LEAFN_MAGIC)) {\n\t\tstruct xfs_dir3_icleaf_hdr leafhdr;\n\t\tstruct xfs_dir2_leaf_entry *ents;\n\n\t\tdead_leaf2 = (xfs_dir2_leaf_t *)dead_info;\n\t\tdp->d_ops->leaf_hdr_from_disk(&leafhdr, dead_leaf2);\n\t\tents = dp->d_ops->leaf_ents_p(dead_leaf2);\n\t\tdead_level = 0;\n\t\tdead_hash = be32_to_cpu(ents[leafhdr.count - 1].hashval);\n\t} else {\n\t\tstruct xfs_da3_icnode_hdr deadhdr;\n\n\t\tdead_node = (xfs_da_intnode_t *)dead_info;\n\t\tdp->d_ops->node_hdr_from_disk(&deadhdr, dead_node);\n\t\tbtree = dp->d_ops->node_tree_p(dead_node);\n\t\tdead_level = deadhdr.level;\n\t\tdead_hash = be32_to_cpu(btree[deadhdr.count - 1].hashval);\n\t}\n\tsib_buf = par_buf = NULL;\n\t/*\n\t * If the moved block has a left sibling, fix up the pointers.\n\t */\n\tif ((sib_blkno = be32_to_cpu(dead_info->back))) {\n\t\terror = xfs_da3_node_read(tp, dp, sib_blkno, -1, &sib_buf, w);\n\t\tif (error)\n\t\t\tgoto done;\n\t\tsib_info = sib_buf->b_addr;\n\t\tif (unlikely(\n\t\t    be32_to_cpu(sib_info->forw) != last_blkno ||\n\t\t    sib_info->magic != dead_info->magic)) {\n\t\t\tXFS_ERROR_REPORT(\"xfs_da_swap_lastblock(2)\",\n\t\t\t\t\t XFS_ERRLEVEL_LOW, mp);\n\t\t\terror = XFS_ERROR(EFSCORRUPTED);\n\t\t\tgoto done;\n\t\t}\n\t\tsib_info->forw = cpu_to_be32(dead_blkno);\n\t\txfs_trans_log_buf(tp, sib_buf,\n\t\t\tXFS_DA_LOGRANGE(sib_info, &sib_info->forw,\n\t\t\t\t\tsizeof(sib_info->forw)));\n\t\tsib_buf = NULL;\n\t}\n\t/*\n\t * If the moved block has a right sibling, fix up the pointers.\n\t */\n\tif ((sib_blkno = be32_to_cpu(dead_info->forw))) {\n\t\terror = xfs_da3_node_read(tp, dp, sib_blkno, -1, &sib_buf, w);\n\t\tif (error)\n\t\t\tgoto done;\n\t\tsib_info = sib_buf->b_addr;\n\t\tif (unlikely(\n\t\t       be32_to_cpu(sib_info->back) != last_blkno ||\n\t\t       sib_info->magic != dead_info->magic)) {\n\t\t\tXFS_ERROR_REPORT(\"xfs_da_swap_lastblock(3)\",\n\t\t\t\t\t XFS_ERRLEVEL_LOW, mp);\n\t\t\terror = XFS_ERROR(EFSCORRUPTED);\n\t\t\tgoto done;\n\t\t}\n\t\tsib_info->back = cpu_to_be32(dead_blkno);\n\t\txfs_trans_log_buf(tp, sib_buf,\n\t\t\tXFS_DA_LOGRANGE(sib_info, &sib_info->back,\n\t\t\t\t\tsizeof(sib_info->back)));\n\t\tsib_buf = NULL;\n\t}\n\tpar_blkno = mp->m_dirleafblk;\n\tlevel = -1;\n\t/*\n\t * Walk down the tree looking for the parent of the moved block.\n\t */\n\tfor (;;) {\n\t\terror = xfs_da3_node_read(tp, dp, par_blkno, -1, &par_buf, w);\n\t\tif (error)\n\t\t\tgoto done;\n\t\tpar_node = par_buf->b_addr;\n\t\tdp->d_ops->node_hdr_from_disk(&par_hdr, par_node);\n\t\tif (level >= 0 && level != par_hdr.level + 1) {\n\t\t\tXFS_ERROR_REPORT(\"xfs_da_swap_lastblock(4)\",\n\t\t\t\t\t XFS_ERRLEVEL_LOW, mp);\n\t\t\terror = XFS_ERROR(EFSCORRUPTED);\n\t\t\tgoto done;\n\t\t}\n\t\tlevel = par_hdr.level;\n\t\tbtree = dp->d_ops->node_tree_p(par_node);\n\t\tfor (entno = 0;\n\t\t     entno < par_hdr.count &&\n\t\t     be32_to_cpu(btree[entno].hashval) < dead_hash;\n\t\t     entno++)\n\t\t\tcontinue;\n\t\tif (entno == par_hdr.count) {\n\t\t\tXFS_ERROR_REPORT(\"xfs_da_swap_lastblock(5)\",\n\t\t\t\t\t XFS_ERRLEVEL_LOW, mp);\n\t\t\terror = XFS_ERROR(EFSCORRUPTED);\n\t\t\tgoto done;\n\t\t}\n\t\tpar_blkno = be32_to_cpu(btree[entno].before);\n\t\tif (level == dead_level + 1)\n\t\t\tbreak;\n\t\txfs_trans_brelse(tp, par_buf);\n\t\tpar_buf = NULL;\n\t}\n\t/*\n\t * We're in the right parent block.\n\t * Look for the right entry.\n\t */\n\tfor (;;) {\n\t\tfor (;\n\t\t     entno < par_hdr.count &&\n\t\t     be32_to_cpu(btree[entno].before) != last_blkno;\n\t\t     entno++)\n\t\t\tcontinue;\n\t\tif (entno < par_hdr.count)\n\t\t\tbreak;\n\t\tpar_blkno = par_hdr.forw;\n\t\txfs_trans_brelse(tp, par_buf);\n\t\tpar_buf = NULL;\n\t\tif (unlikely(par_blkno == 0)) {\n\t\t\tXFS_ERROR_REPORT(\"xfs_da_swap_lastblock(6)\",\n\t\t\t\t\t XFS_ERRLEVEL_LOW, mp);\n\t\t\terror = XFS_ERROR(EFSCORRUPTED);\n\t\t\tgoto done;\n\t\t}\n\t\terror = xfs_da3_node_read(tp, dp, par_blkno, -1, &par_buf, w);\n\t\tif (error)\n\t\t\tgoto done;\n\t\tpar_node = par_buf->b_addr;\n\t\tdp->d_ops->node_hdr_from_disk(&par_hdr, par_node);\n\t\tif (par_hdr.level != level) {\n\t\t\tXFS_ERROR_REPORT(\"xfs_da_swap_lastblock(7)\",\n\t\t\t\t\t XFS_ERRLEVEL_LOW, mp);\n\t\t\terror = XFS_ERROR(EFSCORRUPTED);\n\t\t\tgoto done;\n\t\t}\n\t\tbtree = dp->d_ops->node_tree_p(par_node);\n\t\tentno = 0;\n\t}\n\t/*\n\t * Update the parent entry pointing to the moved block.\n\t */\n\tbtree[entno].before = cpu_to_be32(dead_blkno);\n\txfs_trans_log_buf(tp, par_buf,\n\t\tXFS_DA_LOGRANGE(par_node, &btree[entno].before,\n\t\t\t\tsizeof(btree[entno].before)));\n\t*dead_blknop = last_blkno;\n\t*dead_bufp = last_buf;\n\treturn 0;\ndone:\n\tif (par_buf)\n\t\txfs_trans_brelse(tp, par_buf);\n\tif (sib_buf)\n\t\txfs_trans_brelse(tp, sib_buf);\n\txfs_trans_brelse(tp, last_buf);\n\treturn error;\n}\n\n/*\n * Remove a btree block from a directory or attribute.\n */\nint\nxfs_da_shrink_inode(\n\txfs_da_args_t\t*args,\n\txfs_dablk_t\tdead_blkno,\n\tstruct xfs_buf\t*dead_buf)\n{\n\txfs_inode_t *dp;\n\tint done, error, w, count;\n\txfs_trans_t *tp;\n\txfs_mount_t *mp;\n\n\ttrace_xfs_da_shrink_inode(args);\n\n\tdp = args->dp;\n\tw = args->whichfork;\n\ttp = args->trans;\n\tmp = dp->i_mount;\n\tif (w == XFS_DATA_FORK)\n\t\tcount = mp->m_dirblkfsbs;\n\telse\n\t\tcount = 1;\n\tfor (;;) {\n\t\t/*\n\t\t * Remove extents.  If we get ENOSPC for a dir we have to move\n\t\t * the last block to the place we want to kill.\n\t\t */\n\t\terror = xfs_bunmapi(tp, dp, dead_blkno, count,\n\t\t\t\t    xfs_bmapi_aflag(w)|XFS_BMAPI_METADATA,\n\t\t\t\t    0, args->firstblock, args->flist, &done);\n\t\tif (error == ENOSPC) {\n\t\t\tif (w != XFS_DATA_FORK)\n\t\t\t\tbreak;\n\t\t\terror = xfs_da3_swap_lastblock(args, &dead_blkno,\n\t\t\t\t\t\t      &dead_buf);\n\t\t\tif (error)\n\t\t\t\tbreak;\n\t\t} else {\n\t\t\tbreak;\n\t\t}\n\t}\n\txfs_trans_binval(tp, dead_buf);\n\treturn error;\n}\n\n/*\n * See if the mapping(s) for this btree block are valid, i.e.\n * don't contain holes, are logically contiguous, and cover the whole range.\n */\nSTATIC int\nxfs_da_map_covers_blocks(\n\tint\t\tnmap,\n\txfs_bmbt_irec_t\t*mapp,\n\txfs_dablk_t\tbno,\n\tint\t\tcount)\n{\n\tint\t\ti;\n\txfs_fileoff_t\toff;\n\n\tfor (i = 0, off = bno; i < nmap; i++) {\n\t\tif (mapp[i].br_startblock == HOLESTARTBLOCK ||\n\t\t    mapp[i].br_startblock == DELAYSTARTBLOCK) {\n\t\t\treturn 0;\n\t\t}\n\t\tif (off != mapp[i].br_startoff) {\n\t\t\treturn 0;\n\t\t}\n\t\toff += mapp[i].br_blockcount;\n\t}\n\treturn off == bno + count;\n}\n\n/*\n * Convert a struct xfs_bmbt_irec to a struct xfs_buf_map.\n *\n * For the single map case, it is assumed that the caller has provided a pointer\n * to a valid xfs_buf_map.  For the multiple map case, this function will\n * allocate the xfs_buf_map to hold all the maps and replace the caller's single\n * map pointer with the allocated map.\n */\nstatic int\nxfs_buf_map_from_irec(\n\tstruct xfs_mount\t*mp,\n\tstruct xfs_buf_map\t**mapp,\n\tint\t\t\t*nmaps,\n\tstruct xfs_bmbt_irec\t*irecs,\n\tint\t\t\tnirecs)\n{\n\tstruct xfs_buf_map\t*map;\n\tint\t\t\ti;\n\n\tASSERT(*nmaps == 1);\n\tASSERT(nirecs >= 1);\n\n\tif (nirecs > 1) {\n\t\tmap = kmem_zalloc(nirecs * sizeof(struct xfs_buf_map),\n\t\t\t\t  KM_SLEEP | KM_NOFS);\n\t\tif (!map)\n\t\t\treturn ENOMEM;\n\t\t*mapp = map;\n\t}\n\n\t*nmaps = nirecs;\n\tmap = *mapp;\n\tfor (i = 0; i < *nmaps; i++) {\n\t\tASSERT(irecs[i].br_startblock != DELAYSTARTBLOCK &&\n\t\t       irecs[i].br_startblock != HOLESTARTBLOCK);\n\t\tmap[i].bm_bn = XFS_FSB_TO_DADDR(mp, irecs[i].br_startblock);\n\t\tmap[i].bm_len = XFS_FSB_TO_BB(mp, irecs[i].br_blockcount);\n\t}\n\treturn 0;\n}\n\n/*\n * Map the block we are given ready for reading. There are three possible return\n * values:\n *\t-1 - will be returned if we land in a hole and mappedbno == -2 so the\n *\t     caller knows not to execute a subsequent read.\n *\t 0 - if we mapped the block successfully\n *\t>0 - positive error number if there was an error.\n */\nstatic int\nxfs_dabuf_map(\n\tstruct xfs_trans\t*trans,\n\tstruct xfs_inode\t*dp,\n\txfs_dablk_t\t\tbno,\n\txfs_daddr_t\t\tmappedbno,\n\tint\t\t\twhichfork,\n\tstruct xfs_buf_map\t**map,\n\tint\t\t\t*nmaps)\n{\n\tstruct xfs_mount\t*mp = dp->i_mount;\n\tint\t\t\tnfsb;\n\tint\t\t\terror = 0;\n\tstruct xfs_bmbt_irec\tirec;\n\tstruct xfs_bmbt_irec\t*irecs = &irec;\n\tint\t\t\tnirecs;\n\n\tASSERT(map && *map);\n\tASSERT(*nmaps == 1);\n\n\tnfsb = (whichfork == XFS_DATA_FORK) ? mp->m_dirblkfsbs : 1;\n\n\t/*\n\t * Caller doesn't have a mapping.  -2 means don't complain\n\t * if we land in a hole.\n\t */\n\tif (mappedbno == -1 || mappedbno == -2) {\n\t\t/*\n\t\t * Optimize the one-block case.\n\t\t */\n\t\tif (nfsb != 1)\n\t\t\tirecs = kmem_zalloc(sizeof(irec) * nfsb,\n\t\t\t\t\t    KM_SLEEP | KM_NOFS);\n\n\t\tnirecs = nfsb;\n\t\terror = xfs_bmapi_read(dp, (xfs_fileoff_t)bno, nfsb, irecs,\n\t\t\t\t       &nirecs, xfs_bmapi_aflag(whichfork));\n\t\tif (error)\n\t\t\tgoto out;\n\t} else {\n\t\tirecs->br_startblock = XFS_DADDR_TO_FSB(mp, mappedbno);\n\t\tirecs->br_startoff = (xfs_fileoff_t)bno;\n\t\tirecs->br_blockcount = nfsb;\n\t\tirecs->br_state = 0;\n\t\tnirecs = 1;\n\t}\n\n\tif (!xfs_da_map_covers_blocks(nirecs, irecs, bno, nfsb)) {\n\t\terror = mappedbno == -2 ? -1 : XFS_ERROR(EFSCORRUPTED);\n\t\tif (unlikely(error == EFSCORRUPTED)) {\n\t\t\tif (xfs_error_level >= XFS_ERRLEVEL_LOW) {\n\t\t\t\tint i;\n\t\t\t\txfs_alert(mp, \"%s: bno %lld dir: inode %lld\",\n\t\t\t\t\t__func__, (long long)bno,\n\t\t\t\t\t(long long)dp->i_ino);\n\t\t\t\tfor (i = 0; i < *nmaps; i++) {\n\t\t\t\t\txfs_alert(mp,\n\"[%02d] br_startoff %lld br_startblock %lld br_blockcount %lld br_state %d\",\n\t\t\t\t\t\ti,\n\t\t\t\t\t\t(long long)irecs[i].br_startoff,\n\t\t\t\t\t\t(long long)irecs[i].br_startblock,\n\t\t\t\t\t\t(long long)irecs[i].br_blockcount,\n\t\t\t\t\t\tirecs[i].br_state);\n\t\t\t\t}\n\t\t\t}\n\t\t\tXFS_ERROR_REPORT(\"xfs_da_do_buf(1)\",\n\t\t\t\t\t XFS_ERRLEVEL_LOW, mp);\n\t\t}\n\t\tgoto out;\n\t}\n\terror = xfs_buf_map_from_irec(mp, map, nmaps, irecs, nirecs);\nout:\n\tif (irecs != &irec)\n\t\tkmem_free(irecs);\n\treturn error;\n}\n\n/*\n * Get a buffer for the dir/attr block.\n */\nint\nxfs_da_get_buf(\n\tstruct xfs_trans\t*trans,\n\tstruct xfs_inode\t*dp,\n\txfs_dablk_t\t\tbno,\n\txfs_daddr_t\t\tmappedbno,\n\tstruct xfs_buf\t\t**bpp,\n\tint\t\t\twhichfork)\n{\n\tstruct xfs_buf\t\t*bp;\n\tstruct xfs_buf_map\tmap;\n\tstruct xfs_buf_map\t*mapp;\n\tint\t\t\tnmap;\n\tint\t\t\terror;\n\n\t*bpp = NULL;\n\tmapp = &map;\n\tnmap = 1;\n\terror = xfs_dabuf_map(trans, dp, bno, mappedbno, whichfork,\n\t\t\t\t&mapp, &nmap);\n\tif (error) {\n\t\t/* mapping a hole is not an error, but we don't continue */\n\t\tif (error == -1)\n\t\t\terror = 0;\n\t\tgoto out_free;\n\t}\n\n\tbp = xfs_trans_get_buf_map(trans, dp->i_mount->m_ddev_targp,\n\t\t\t\t    mapp, nmap, 0);\n\terror = bp ? bp->b_error : XFS_ERROR(EIO);\n\tif (error) {\n\t\txfs_trans_brelse(trans, bp);\n\t\tgoto out_free;\n\t}\n\n\t*bpp = bp;\n\nout_free:\n\tif (mapp != &map)\n\t\tkmem_free(mapp);\n\n\treturn error;\n}\n\n/*\n * Get a buffer for the dir/attr block, fill in the contents.\n */\nint\nxfs_da_read_buf(\n\tstruct xfs_trans\t*trans,\n\tstruct xfs_inode\t*dp,\n\txfs_dablk_t\t\tbno,\n\txfs_daddr_t\t\tmappedbno,\n\tstruct xfs_buf\t\t**bpp,\n\tint\t\t\twhichfork,\n\tconst struct xfs_buf_ops *ops)\n{\n\tstruct xfs_buf\t\t*bp;\n\tstruct xfs_buf_map\tmap;\n\tstruct xfs_buf_map\t*mapp;\n\tint\t\t\tnmap;\n\tint\t\t\terror;\n\n\t*bpp = NULL;\n\tmapp = &map;\n\tnmap = 1;\n\terror = xfs_dabuf_map(trans, dp, bno, mappedbno, whichfork,\n\t\t\t\t&mapp, &nmap);\n\tif (error) {\n\t\t/* mapping a hole is not an error, but we don't continue */\n\t\tif (error == -1)\n\t\t\terror = 0;\n\t\tgoto out_free;\n\t}\n\n\terror = xfs_trans_read_buf_map(dp->i_mount, trans,\n\t\t\t\t\tdp->i_mount->m_ddev_targp,\n\t\t\t\t\tmapp, nmap, 0, &bp, ops);\n\tif (error)\n\t\tgoto out_free;\n\n\tif (whichfork == XFS_ATTR_FORK)\n\t\txfs_buf_set_ref(bp, XFS_ATTR_BTREE_REF);\n\telse\n\t\txfs_buf_set_ref(bp, XFS_DIR_BTREE_REF);\n\n\t/*\n\t * This verification code will be moved to a CRC verification callback\n\t * function so just leave it here unchanged until then.\n\t */\n\t{\n\t\txfs_dir2_data_hdr_t\t*hdr = bp->b_addr;\n\t\txfs_dir2_free_t\t\t*free = bp->b_addr;\n\t\txfs_da_blkinfo_t\t*info = bp->b_addr;\n\t\tuint\t\t\tmagic, magic1;\n\t\tstruct xfs_mount\t*mp = dp->i_mount;\n\n\t\tmagic = be16_to_cpu(info->magic);\n\t\tmagic1 = be32_to_cpu(hdr->magic);\n\t\tif (unlikely(\n\t\t    XFS_TEST_ERROR((magic != XFS_DA_NODE_MAGIC) &&\n\t\t\t\t   (magic != XFS_DA3_NODE_MAGIC) &&\n\t\t\t\t   (magic != XFS_ATTR_LEAF_MAGIC) &&\n\t\t\t\t   (magic != XFS_ATTR3_LEAF_MAGIC) &&\n\t\t\t\t   (magic != XFS_DIR2_LEAF1_MAGIC) &&\n\t\t\t\t   (magic != XFS_DIR3_LEAF1_MAGIC) &&\n\t\t\t\t   (magic != XFS_DIR2_LEAFN_MAGIC) &&\n\t\t\t\t   (magic != XFS_DIR3_LEAFN_MAGIC) &&\n\t\t\t\t   (magic1 != XFS_DIR2_BLOCK_MAGIC) &&\n\t\t\t\t   (magic1 != XFS_DIR3_BLOCK_MAGIC) &&\n\t\t\t\t   (magic1 != XFS_DIR2_DATA_MAGIC) &&\n\t\t\t\t   (magic1 != XFS_DIR3_DATA_MAGIC) &&\n\t\t\t\t   (free->hdr.magic !=\n\t\t\t\t\tcpu_to_be32(XFS_DIR2_FREE_MAGIC)) &&\n\t\t\t\t   (free->hdr.magic !=\n\t\t\t\t\tcpu_to_be32(XFS_DIR3_FREE_MAGIC)),\n\t\t\t\tmp, XFS_ERRTAG_DA_READ_BUF,\n\t\t\t\tXFS_RANDOM_DA_READ_BUF))) {\n\t\t\ttrace_xfs_da_btree_corrupt(bp, _RET_IP_);\n\t\t\tXFS_CORRUPTION_ERROR(\"xfs_da_do_buf(2)\",\n\t\t\t\t\t     XFS_ERRLEVEL_LOW, mp, info);\n\t\t\terror = XFS_ERROR(EFSCORRUPTED);\n\t\t\txfs_trans_brelse(trans, bp);\n\t\t\tgoto out_free;\n\t\t}\n\t}\n\t*bpp = bp;\nout_free:\n\tif (mapp != &map)\n\t\tkmem_free(mapp);\n\n\treturn error;\n}\n\n/*\n * Readahead the dir/attr block.\n */\nxfs_daddr_t\nxfs_da_reada_buf(\n\tstruct xfs_trans\t*trans,\n\tstruct xfs_inode\t*dp,\n\txfs_dablk_t\t\tbno,\n\txfs_daddr_t\t\tmappedbno,\n\tint\t\t\twhichfork,\n\tconst struct xfs_buf_ops *ops)\n{\n\tstruct xfs_buf_map\tmap;\n\tstruct xfs_buf_map\t*mapp;\n\tint\t\t\tnmap;\n\tint\t\t\terror;\n\n\tmapp = &map;\n\tnmap = 1;\n\terror = xfs_dabuf_map(trans, dp, bno, mappedbno, whichfork,\n\t\t\t\t&mapp, &nmap);\n\tif (error) {\n\t\t/* mapping a hole is not an error, but we don't continue */\n\t\tif (error == -1)\n\t\t\terror = 0;\n\t\tgoto out_free;\n\t}\n\n\tmappedbno = mapp[0].bm_bn;\n\txfs_buf_readahead_map(dp->i_mount->m_ddev_targp, mapp, nmap, ops);\n\nout_free:\n\tif (mapp != &map)\n\t\tkmem_free(mapp);\n\n\tif (error)\n\t\treturn -1;\n\treturn mappedbno;\n}\n"], "fixing_code": ["/*\n * Copyright (c) 2000-2005 Silicon Graphics, Inc.\n * Copyright (c) 2013 Red Hat, Inc.\n * All Rights Reserved.\n *\n * This program is free software; you can redistribute it and/or\n * modify it under the terms of the GNU General Public License as\n * published by the Free Software Foundation.\n *\n * This program is distributed in the hope that it would be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write the Free Software Foundation,\n * Inc.,  51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA\n */\n#include \"xfs.h\"\n#include \"xfs_fs.h\"\n#include \"xfs_shared.h\"\n#include \"xfs_format.h\"\n#include \"xfs_log_format.h\"\n#include \"xfs_trans_resv.h\"\n#include \"xfs_bit.h\"\n#include \"xfs_sb.h\"\n#include \"xfs_ag.h\"\n#include \"xfs_mount.h\"\n#include \"xfs_da_format.h\"\n#include \"xfs_da_btree.h\"\n#include \"xfs_dir2.h\"\n#include \"xfs_dir2_priv.h\"\n#include \"xfs_inode.h\"\n#include \"xfs_trans.h\"\n#include \"xfs_inode_item.h\"\n#include \"xfs_alloc.h\"\n#include \"xfs_bmap.h\"\n#include \"xfs_attr.h\"\n#include \"xfs_attr_leaf.h\"\n#include \"xfs_error.h\"\n#include \"xfs_trace.h\"\n#include \"xfs_cksum.h\"\n#include \"xfs_buf_item.h\"\n\n/*\n * xfs_da_btree.c\n *\n * Routines to implement directories as Btrees of hashed names.\n */\n\n/*========================================================================\n * Function prototypes for the kernel.\n *========================================================================*/\n\n/*\n * Routines used for growing the Btree.\n */\nSTATIC int xfs_da3_root_split(xfs_da_state_t *state,\n\t\t\t\t\t    xfs_da_state_blk_t *existing_root,\n\t\t\t\t\t    xfs_da_state_blk_t *new_child);\nSTATIC int xfs_da3_node_split(xfs_da_state_t *state,\n\t\t\t\t\t    xfs_da_state_blk_t *existing_blk,\n\t\t\t\t\t    xfs_da_state_blk_t *split_blk,\n\t\t\t\t\t    xfs_da_state_blk_t *blk_to_add,\n\t\t\t\t\t    int treelevel,\n\t\t\t\t\t    int *result);\nSTATIC void xfs_da3_node_rebalance(xfs_da_state_t *state,\n\t\t\t\t\t xfs_da_state_blk_t *node_blk_1,\n\t\t\t\t\t xfs_da_state_blk_t *node_blk_2);\nSTATIC void xfs_da3_node_add(xfs_da_state_t *state,\n\t\t\t\t   xfs_da_state_blk_t *old_node_blk,\n\t\t\t\t   xfs_da_state_blk_t *new_node_blk);\n\n/*\n * Routines used for shrinking the Btree.\n */\nSTATIC int xfs_da3_root_join(xfs_da_state_t *state,\n\t\t\t\t\t   xfs_da_state_blk_t *root_blk);\nSTATIC int xfs_da3_node_toosmall(xfs_da_state_t *state, int *retval);\nSTATIC void xfs_da3_node_remove(xfs_da_state_t *state,\n\t\t\t\t\t      xfs_da_state_blk_t *drop_blk);\nSTATIC void xfs_da3_node_unbalance(xfs_da_state_t *state,\n\t\t\t\t\t xfs_da_state_blk_t *src_node_blk,\n\t\t\t\t\t xfs_da_state_blk_t *dst_node_blk);\n\n/*\n * Utility routines.\n */\nSTATIC int\txfs_da3_blk_unlink(xfs_da_state_t *state,\n\t\t\t\t  xfs_da_state_blk_t *drop_blk,\n\t\t\t\t  xfs_da_state_blk_t *save_blk);\n\n\nkmem_zone_t *xfs_da_state_zone;\t/* anchor for state struct zone */\n\n/*\n * Allocate a dir-state structure.\n * We don't put them on the stack since they're large.\n */\nxfs_da_state_t *\nxfs_da_state_alloc(void)\n{\n\treturn kmem_zone_zalloc(xfs_da_state_zone, KM_NOFS);\n}\n\n/*\n * Kill the altpath contents of a da-state structure.\n */\nSTATIC void\nxfs_da_state_kill_altpath(xfs_da_state_t *state)\n{\n\tint\ti;\n\n\tfor (i = 0; i < state->altpath.active; i++)\n\t\tstate->altpath.blk[i].bp = NULL;\n\tstate->altpath.active = 0;\n}\n\n/*\n * Free a da-state structure.\n */\nvoid\nxfs_da_state_free(xfs_da_state_t *state)\n{\n\txfs_da_state_kill_altpath(state);\n#ifdef DEBUG\n\tmemset((char *)state, 0, sizeof(*state));\n#endif /* DEBUG */\n\tkmem_zone_free(xfs_da_state_zone, state);\n}\n\nstatic bool\nxfs_da3_node_verify(\n\tstruct xfs_buf\t\t*bp)\n{\n\tstruct xfs_mount\t*mp = bp->b_target->bt_mount;\n\tstruct xfs_da_intnode\t*hdr = bp->b_addr;\n\tstruct xfs_da3_icnode_hdr ichdr;\n\tconst struct xfs_dir_ops *ops;\n\n\tops = xfs_dir_get_ops(mp, NULL);\n\n\tops->node_hdr_from_disk(&ichdr, hdr);\n\n\tif (xfs_sb_version_hascrc(&mp->m_sb)) {\n\t\tstruct xfs_da3_node_hdr *hdr3 = bp->b_addr;\n\n\t\tif (ichdr.magic != XFS_DA3_NODE_MAGIC)\n\t\t\treturn false;\n\n\t\tif (!uuid_equal(&hdr3->info.uuid, &mp->m_sb.sb_uuid))\n\t\t\treturn false;\n\t\tif (be64_to_cpu(hdr3->info.blkno) != bp->b_bn)\n\t\t\treturn false;\n\t} else {\n\t\tif (ichdr.magic != XFS_DA_NODE_MAGIC)\n\t\t\treturn false;\n\t}\n\tif (ichdr.level == 0)\n\t\treturn false;\n\tif (ichdr.level > XFS_DA_NODE_MAXDEPTH)\n\t\treturn false;\n\tif (ichdr.count == 0)\n\t\treturn false;\n\n\t/*\n\t * we don't know if the node is for and attribute or directory tree,\n\t * so only fail if the count is outside both bounds\n\t */\n\tif (ichdr.count > mp->m_dir_node_ents &&\n\t    ichdr.count > mp->m_attr_node_ents)\n\t\treturn false;\n\n\t/* XXX: hash order check? */\n\n\treturn true;\n}\n\nstatic void\nxfs_da3_node_write_verify(\n\tstruct xfs_buf\t*bp)\n{\n\tstruct xfs_mount\t*mp = bp->b_target->bt_mount;\n\tstruct xfs_buf_log_item\t*bip = bp->b_fspriv;\n\tstruct xfs_da3_node_hdr *hdr3 = bp->b_addr;\n\n\tif (!xfs_da3_node_verify(bp)) {\n\t\tXFS_CORRUPTION_ERROR(__func__, XFS_ERRLEVEL_LOW, mp, bp->b_addr);\n\t\txfs_buf_ioerror(bp, EFSCORRUPTED);\n\t\treturn;\n\t}\n\n\tif (!xfs_sb_version_hascrc(&mp->m_sb))\n\t\treturn;\n\n\tif (bip)\n\t\thdr3->info.lsn = cpu_to_be64(bip->bli_item.li_lsn);\n\n\txfs_update_cksum(bp->b_addr, BBTOB(bp->b_length), XFS_DA3_NODE_CRC_OFF);\n}\n\n/*\n * leaf/node format detection on trees is sketchy, so a node read can be done on\n * leaf level blocks when detection identifies the tree as a node format tree\n * incorrectly. In this case, we need to swap the verifier to match the correct\n * format of the block being read.\n */\nstatic void\nxfs_da3_node_read_verify(\n\tstruct xfs_buf\t\t*bp)\n{\n\tstruct xfs_mount\t*mp = bp->b_target->bt_mount;\n\tstruct xfs_da_blkinfo\t*info = bp->b_addr;\n\n\tswitch (be16_to_cpu(info->magic)) {\n\t\tcase XFS_DA3_NODE_MAGIC:\n\t\t\tif (!xfs_verify_cksum(bp->b_addr, BBTOB(bp->b_length),\n\t\t\t\t\t      XFS_DA3_NODE_CRC_OFF))\n\t\t\t\tbreak;\n\t\t\t/* fall through */\n\t\tcase XFS_DA_NODE_MAGIC:\n\t\t\tif (!xfs_da3_node_verify(bp))\n\t\t\t\tbreak;\n\t\t\treturn;\n\t\tcase XFS_ATTR_LEAF_MAGIC:\n\t\tcase XFS_ATTR3_LEAF_MAGIC:\n\t\t\tbp->b_ops = &xfs_attr3_leaf_buf_ops;\n\t\t\tbp->b_ops->verify_read(bp);\n\t\t\treturn;\n\t\tcase XFS_DIR2_LEAFN_MAGIC:\n\t\tcase XFS_DIR3_LEAFN_MAGIC:\n\t\t\tbp->b_ops = &xfs_dir3_leafn_buf_ops;\n\t\t\tbp->b_ops->verify_read(bp);\n\t\t\treturn;\n\t\tdefault:\n\t\t\tbreak;\n\t}\n\n\t/* corrupt block */\n\tXFS_CORRUPTION_ERROR(__func__, XFS_ERRLEVEL_LOW, mp, bp->b_addr);\n\txfs_buf_ioerror(bp, EFSCORRUPTED);\n}\n\nconst struct xfs_buf_ops xfs_da3_node_buf_ops = {\n\t.verify_read = xfs_da3_node_read_verify,\n\t.verify_write = xfs_da3_node_write_verify,\n};\n\nint\nxfs_da3_node_read(\n\tstruct xfs_trans\t*tp,\n\tstruct xfs_inode\t*dp,\n\txfs_dablk_t\t\tbno,\n\txfs_daddr_t\t\tmappedbno,\n\tstruct xfs_buf\t\t**bpp,\n\tint\t\t\twhich_fork)\n{\n\tint\t\t\terr;\n\n\terr = xfs_da_read_buf(tp, dp, bno, mappedbno, bpp,\n\t\t\t\t\twhich_fork, &xfs_da3_node_buf_ops);\n\tif (!err && tp) {\n\t\tstruct xfs_da_blkinfo\t*info = (*bpp)->b_addr;\n\t\tint\t\t\ttype;\n\n\t\tswitch (be16_to_cpu(info->magic)) {\n\t\tcase XFS_DA_NODE_MAGIC:\n\t\tcase XFS_DA3_NODE_MAGIC:\n\t\t\ttype = XFS_BLFT_DA_NODE_BUF;\n\t\t\tbreak;\n\t\tcase XFS_ATTR_LEAF_MAGIC:\n\t\tcase XFS_ATTR3_LEAF_MAGIC:\n\t\t\ttype = XFS_BLFT_ATTR_LEAF_BUF;\n\t\t\tbreak;\n\t\tcase XFS_DIR2_LEAFN_MAGIC:\n\t\tcase XFS_DIR3_LEAFN_MAGIC:\n\t\t\ttype = XFS_BLFT_DIR_LEAFN_BUF;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\ttype = 0;\n\t\t\tASSERT(0);\n\t\t\tbreak;\n\t\t}\n\t\txfs_trans_buf_set_type(tp, *bpp, type);\n\t}\n\treturn err;\n}\n\n/*========================================================================\n * Routines used for growing the Btree.\n *========================================================================*/\n\n/*\n * Create the initial contents of an intermediate node.\n */\nint\nxfs_da3_node_create(\n\tstruct xfs_da_args\t*args,\n\txfs_dablk_t\t\tblkno,\n\tint\t\t\tlevel,\n\tstruct xfs_buf\t\t**bpp,\n\tint\t\t\twhichfork)\n{\n\tstruct xfs_da_intnode\t*node;\n\tstruct xfs_trans\t*tp = args->trans;\n\tstruct xfs_mount\t*mp = tp->t_mountp;\n\tstruct xfs_da3_icnode_hdr ichdr = {0};\n\tstruct xfs_buf\t\t*bp;\n\tint\t\t\terror;\n\tstruct xfs_inode\t*dp = args->dp;\n\n\ttrace_xfs_da_node_create(args);\n\tASSERT(level <= XFS_DA_NODE_MAXDEPTH);\n\n\terror = xfs_da_get_buf(tp, dp, blkno, -1, &bp, whichfork);\n\tif (error)\n\t\treturn(error);\n\tbp->b_ops = &xfs_da3_node_buf_ops;\n\txfs_trans_buf_set_type(tp, bp, XFS_BLFT_DA_NODE_BUF);\n\tnode = bp->b_addr;\n\n\tif (xfs_sb_version_hascrc(&mp->m_sb)) {\n\t\tstruct xfs_da3_node_hdr *hdr3 = bp->b_addr;\n\n\t\tichdr.magic = XFS_DA3_NODE_MAGIC;\n\t\thdr3->info.blkno = cpu_to_be64(bp->b_bn);\n\t\thdr3->info.owner = cpu_to_be64(args->dp->i_ino);\n\t\tuuid_copy(&hdr3->info.uuid, &mp->m_sb.sb_uuid);\n\t} else {\n\t\tichdr.magic = XFS_DA_NODE_MAGIC;\n\t}\n\tichdr.level = level;\n\n\tdp->d_ops->node_hdr_to_disk(node, &ichdr);\n\txfs_trans_log_buf(tp, bp,\n\t\tXFS_DA_LOGRANGE(node, &node->hdr, dp->d_ops->node_hdr_size));\n\n\t*bpp = bp;\n\treturn(0);\n}\n\n/*\n * Split a leaf node, rebalance, then possibly split\n * intermediate nodes, rebalance, etc.\n */\nint\t\t\t\t\t\t\t/* error */\nxfs_da3_split(\n\tstruct xfs_da_state\t*state)\n{\n\tstruct xfs_da_state_blk\t*oldblk;\n\tstruct xfs_da_state_blk\t*newblk;\n\tstruct xfs_da_state_blk\t*addblk;\n\tstruct xfs_da_intnode\t*node;\n\tstruct xfs_buf\t\t*bp;\n\tint\t\t\tmax;\n\tint\t\t\taction = 0;\n\tint\t\t\terror;\n\tint\t\t\ti;\n\n\ttrace_xfs_da_split(state->args);\n\n\t/*\n\t * Walk back up the tree splitting/inserting/adjusting as necessary.\n\t * If we need to insert and there isn't room, split the node, then\n\t * decide which fragment to insert the new block from below into.\n\t * Note that we may split the root this way, but we need more fixup.\n\t */\n\tmax = state->path.active - 1;\n\tASSERT((max >= 0) && (max < XFS_DA_NODE_MAXDEPTH));\n\tASSERT(state->path.blk[max].magic == XFS_ATTR_LEAF_MAGIC ||\n\t       state->path.blk[max].magic == XFS_DIR2_LEAFN_MAGIC);\n\n\taddblk = &state->path.blk[max];\t\t/* initial dummy value */\n\tfor (i = max; (i >= 0) && addblk; state->path.active--, i--) {\n\t\toldblk = &state->path.blk[i];\n\t\tnewblk = &state->altpath.blk[i];\n\n\t\t/*\n\t\t * If a leaf node then\n\t\t *     Allocate a new leaf node, then rebalance across them.\n\t\t * else if an intermediate node then\n\t\t *     We split on the last layer, must we split the node?\n\t\t */\n\t\tswitch (oldblk->magic) {\n\t\tcase XFS_ATTR_LEAF_MAGIC:\n\t\t\terror = xfs_attr3_leaf_split(state, oldblk, newblk);\n\t\t\tif ((error != 0) && (error != ENOSPC)) {\n\t\t\t\treturn(error);\t/* GROT: attr is inconsistent */\n\t\t\t}\n\t\t\tif (!error) {\n\t\t\t\taddblk = newblk;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t/*\n\t\t\t * Entry wouldn't fit, split the leaf again.\n\t\t\t */\n\t\t\tstate->extravalid = 1;\n\t\t\tif (state->inleaf) {\n\t\t\t\tstate->extraafter = 0;\t/* before newblk */\n\t\t\t\ttrace_xfs_attr_leaf_split_before(state->args);\n\t\t\t\terror = xfs_attr3_leaf_split(state, oldblk,\n\t\t\t\t\t\t\t    &state->extrablk);\n\t\t\t} else {\n\t\t\t\tstate->extraafter = 1;\t/* after newblk */\n\t\t\t\ttrace_xfs_attr_leaf_split_after(state->args);\n\t\t\t\terror = xfs_attr3_leaf_split(state, newblk,\n\t\t\t\t\t\t\t    &state->extrablk);\n\t\t\t}\n\t\t\tif (error)\n\t\t\t\treturn(error);\t/* GROT: attr inconsistent */\n\t\t\taddblk = newblk;\n\t\t\tbreak;\n\t\tcase XFS_DIR2_LEAFN_MAGIC:\n\t\t\terror = xfs_dir2_leafn_split(state, oldblk, newblk);\n\t\t\tif (error)\n\t\t\t\treturn error;\n\t\t\taddblk = newblk;\n\t\t\tbreak;\n\t\tcase XFS_DA_NODE_MAGIC:\n\t\t\terror = xfs_da3_node_split(state, oldblk, newblk, addblk,\n\t\t\t\t\t\t\t max - i, &action);\n\t\t\taddblk->bp = NULL;\n\t\t\tif (error)\n\t\t\t\treturn(error);\t/* GROT: dir is inconsistent */\n\t\t\t/*\n\t\t\t * Record the newly split block for the next time thru?\n\t\t\t */\n\t\t\tif (action)\n\t\t\t\taddblk = newblk;\n\t\t\telse\n\t\t\t\taddblk = NULL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Update the btree to show the new hashval for this child.\n\t\t */\n\t\txfs_da3_fixhashpath(state, &state->path);\n\t}\n\tif (!addblk)\n\t\treturn(0);\n\n\t/*\n\t * Split the root node.\n\t */\n\tASSERT(state->path.active == 0);\n\toldblk = &state->path.blk[0];\n\terror = xfs_da3_root_split(state, oldblk, addblk);\n\tif (error) {\n\t\taddblk->bp = NULL;\n\t\treturn(error);\t/* GROT: dir is inconsistent */\n\t}\n\n\t/*\n\t * Update pointers to the node which used to be block 0 and\n\t * just got bumped because of the addition of a new root node.\n\t * There might be three blocks involved if a double split occurred,\n\t * and the original block 0 could be at any position in the list.\n\t *\n\t * Note: the magic numbers and sibling pointers are in the same\n\t * physical place for both v2 and v3 headers (by design). Hence it\n\t * doesn't matter which version of the xfs_da_intnode structure we use\n\t * here as the result will be the same using either structure.\n\t */\n\tnode = oldblk->bp->b_addr;\n\tif (node->hdr.info.forw) {\n\t\tif (be32_to_cpu(node->hdr.info.forw) == addblk->blkno) {\n\t\t\tbp = addblk->bp;\n\t\t} else {\n\t\t\tASSERT(state->extravalid);\n\t\t\tbp = state->extrablk.bp;\n\t\t}\n\t\tnode = bp->b_addr;\n\t\tnode->hdr.info.back = cpu_to_be32(oldblk->blkno);\n\t\txfs_trans_log_buf(state->args->trans, bp,\n\t\t    XFS_DA_LOGRANGE(node, &node->hdr.info,\n\t\t    sizeof(node->hdr.info)));\n\t}\n\tnode = oldblk->bp->b_addr;\n\tif (node->hdr.info.back) {\n\t\tif (be32_to_cpu(node->hdr.info.back) == addblk->blkno) {\n\t\t\tbp = addblk->bp;\n\t\t} else {\n\t\t\tASSERT(state->extravalid);\n\t\t\tbp = state->extrablk.bp;\n\t\t}\n\t\tnode = bp->b_addr;\n\t\tnode->hdr.info.forw = cpu_to_be32(oldblk->blkno);\n\t\txfs_trans_log_buf(state->args->trans, bp,\n\t\t    XFS_DA_LOGRANGE(node, &node->hdr.info,\n\t\t    sizeof(node->hdr.info)));\n\t}\n\taddblk->bp = NULL;\n\treturn(0);\n}\n\n/*\n * Split the root.  We have to create a new root and point to the two\n * parts (the split old root) that we just created.  Copy block zero to\n * the EOF, extending the inode in process.\n */\nSTATIC int\t\t\t\t\t\t/* error */\nxfs_da3_root_split(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_blk\t*blk1,\n\tstruct xfs_da_state_blk\t*blk2)\n{\n\tstruct xfs_da_intnode\t*node;\n\tstruct xfs_da_intnode\t*oldroot;\n\tstruct xfs_da_node_entry *btree;\n\tstruct xfs_da3_icnode_hdr nodehdr;\n\tstruct xfs_da_args\t*args;\n\tstruct xfs_buf\t\t*bp;\n\tstruct xfs_inode\t*dp;\n\tstruct xfs_trans\t*tp;\n\tstruct xfs_mount\t*mp;\n\tstruct xfs_dir2_leaf\t*leaf;\n\txfs_dablk_t\t\tblkno;\n\tint\t\t\tlevel;\n\tint\t\t\terror;\n\tint\t\t\tsize;\n\n\ttrace_xfs_da_root_split(state->args);\n\n\t/*\n\t * Copy the existing (incorrect) block from the root node position\n\t * to a free space somewhere.\n\t */\n\targs = state->args;\n\terror = xfs_da_grow_inode(args, &blkno);\n\tif (error)\n\t\treturn error;\n\n\tdp = args->dp;\n\ttp = args->trans;\n\tmp = state->mp;\n\terror = xfs_da_get_buf(tp, dp, blkno, -1, &bp, args->whichfork);\n\tif (error)\n\t\treturn error;\n\tnode = bp->b_addr;\n\toldroot = blk1->bp->b_addr;\n\tif (oldroot->hdr.info.magic == cpu_to_be16(XFS_DA_NODE_MAGIC) ||\n\t    oldroot->hdr.info.magic == cpu_to_be16(XFS_DA3_NODE_MAGIC)) {\n\t\tstruct xfs_da3_icnode_hdr nodehdr;\n\n\t\tdp->d_ops->node_hdr_from_disk(&nodehdr, oldroot);\n\t\tbtree = dp->d_ops->node_tree_p(oldroot);\n\t\tsize = (int)((char *)&btree[nodehdr.count] - (char *)oldroot);\n\t\tlevel = nodehdr.level;\n\n\t\t/*\n\t\t * we are about to copy oldroot to bp, so set up the type\n\t\t * of bp while we know exactly what it will be.\n\t\t */\n\t\txfs_trans_buf_set_type(tp, bp, XFS_BLFT_DA_NODE_BUF);\n\t} else {\n\t\tstruct xfs_dir3_icleaf_hdr leafhdr;\n\t\tstruct xfs_dir2_leaf_entry *ents;\n\n\t\tleaf = (xfs_dir2_leaf_t *)oldroot;\n\t\tdp->d_ops->leaf_hdr_from_disk(&leafhdr, leaf);\n\t\tents = dp->d_ops->leaf_ents_p(leaf);\n\n\t\tASSERT(leafhdr.magic == XFS_DIR2_LEAFN_MAGIC ||\n\t\t       leafhdr.magic == XFS_DIR3_LEAFN_MAGIC);\n\t\tsize = (int)((char *)&ents[leafhdr.count] - (char *)leaf);\n\t\tlevel = 0;\n\n\t\t/*\n\t\t * we are about to copy oldroot to bp, so set up the type\n\t\t * of bp while we know exactly what it will be.\n\t\t */\n\t\txfs_trans_buf_set_type(tp, bp, XFS_BLFT_DIR_LEAFN_BUF);\n\t}\n\n\t/*\n\t * we can copy most of the information in the node from one block to\n\t * another, but for CRC enabled headers we have to make sure that the\n\t * block specific identifiers are kept intact. We update the buffer\n\t * directly for this.\n\t */\n\tmemcpy(node, oldroot, size);\n\tif (oldroot->hdr.info.magic == cpu_to_be16(XFS_DA3_NODE_MAGIC) ||\n\t    oldroot->hdr.info.magic == cpu_to_be16(XFS_DIR3_LEAFN_MAGIC)) {\n\t\tstruct xfs_da3_intnode *node3 = (struct xfs_da3_intnode *)node;\n\n\t\tnode3->hdr.info.blkno = cpu_to_be64(bp->b_bn);\n\t}\n\txfs_trans_log_buf(tp, bp, 0, size - 1);\n\n\tbp->b_ops = blk1->bp->b_ops;\n\txfs_trans_buf_copy_type(bp, blk1->bp);\n\tblk1->bp = bp;\n\tblk1->blkno = blkno;\n\n\t/*\n\t * Set up the new root node.\n\t */\n\terror = xfs_da3_node_create(args,\n\t\t(args->whichfork == XFS_DATA_FORK) ? mp->m_dirleafblk : 0,\n\t\tlevel + 1, &bp, args->whichfork);\n\tif (error)\n\t\treturn error;\n\n\tnode = bp->b_addr;\n\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\tbtree = dp->d_ops->node_tree_p(node);\n\tbtree[0].hashval = cpu_to_be32(blk1->hashval);\n\tbtree[0].before = cpu_to_be32(blk1->blkno);\n\tbtree[1].hashval = cpu_to_be32(blk2->hashval);\n\tbtree[1].before = cpu_to_be32(blk2->blkno);\n\tnodehdr.count = 2;\n\tdp->d_ops->node_hdr_to_disk(node, &nodehdr);\n\n#ifdef DEBUG\n\tif (oldroot->hdr.info.magic == cpu_to_be16(XFS_DIR2_LEAFN_MAGIC) ||\n\t    oldroot->hdr.info.magic == cpu_to_be16(XFS_DIR3_LEAFN_MAGIC)) {\n\t\tASSERT(blk1->blkno >= mp->m_dirleafblk &&\n\t\t       blk1->blkno < mp->m_dirfreeblk);\n\t\tASSERT(blk2->blkno >= mp->m_dirleafblk &&\n\t\t       blk2->blkno < mp->m_dirfreeblk);\n\t}\n#endif\n\n\t/* Header is already logged by xfs_da_node_create */\n\txfs_trans_log_buf(tp, bp,\n\t\tXFS_DA_LOGRANGE(node, btree, sizeof(xfs_da_node_entry_t) * 2));\n\n\treturn 0;\n}\n\n/*\n * Split the node, rebalance, then add the new entry.\n */\nSTATIC int\t\t\t\t\t\t/* error */\nxfs_da3_node_split(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_blk\t*oldblk,\n\tstruct xfs_da_state_blk\t*newblk,\n\tstruct xfs_da_state_blk\t*addblk,\n\tint\t\t\ttreelevel,\n\tint\t\t\t*result)\n{\n\tstruct xfs_da_intnode\t*node;\n\tstruct xfs_da3_icnode_hdr nodehdr;\n\txfs_dablk_t\t\tblkno;\n\tint\t\t\tnewcount;\n\tint\t\t\terror;\n\tint\t\t\tuseextra;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\ttrace_xfs_da_node_split(state->args);\n\n\tnode = oldblk->bp->b_addr;\n\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\n\t/*\n\t * With V2 dirs the extra block is data or freespace.\n\t */\n\tuseextra = state->extravalid && state->args->whichfork == XFS_ATTR_FORK;\n\tnewcount = 1 + useextra;\n\t/*\n\t * Do we have to split the node?\n\t */\n\tif (nodehdr.count + newcount > state->node_ents) {\n\t\t/*\n\t\t * Allocate a new node, add to the doubly linked chain of\n\t\t * nodes, then move some of our excess entries into it.\n\t\t */\n\t\terror = xfs_da_grow_inode(state->args, &blkno);\n\t\tif (error)\n\t\t\treturn(error);\t/* GROT: dir is inconsistent */\n\n\t\terror = xfs_da3_node_create(state->args, blkno, treelevel,\n\t\t\t\t\t   &newblk->bp, state->args->whichfork);\n\t\tif (error)\n\t\t\treturn(error);\t/* GROT: dir is inconsistent */\n\t\tnewblk->blkno = blkno;\n\t\tnewblk->magic = XFS_DA_NODE_MAGIC;\n\t\txfs_da3_node_rebalance(state, oldblk, newblk);\n\t\terror = xfs_da3_blk_link(state, oldblk, newblk);\n\t\tif (error)\n\t\t\treturn(error);\n\t\t*result = 1;\n\t} else {\n\t\t*result = 0;\n\t}\n\n\t/*\n\t * Insert the new entry(s) into the correct block\n\t * (updating last hashval in the process).\n\t *\n\t * xfs_da3_node_add() inserts BEFORE the given index,\n\t * and as a result of using node_lookup_int() we always\n\t * point to a valid entry (not after one), but a split\n\t * operation always results in a new block whose hashvals\n\t * FOLLOW the current block.\n\t *\n\t * If we had double-split op below us, then add the extra block too.\n\t */\n\tnode = oldblk->bp->b_addr;\n\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\tif (oldblk->index <= nodehdr.count) {\n\t\toldblk->index++;\n\t\txfs_da3_node_add(state, oldblk, addblk);\n\t\tif (useextra) {\n\t\t\tif (state->extraafter)\n\t\t\t\toldblk->index++;\n\t\t\txfs_da3_node_add(state, oldblk, &state->extrablk);\n\t\t\tstate->extravalid = 0;\n\t\t}\n\t} else {\n\t\tnewblk->index++;\n\t\txfs_da3_node_add(state, newblk, addblk);\n\t\tif (useextra) {\n\t\t\tif (state->extraafter)\n\t\t\t\tnewblk->index++;\n\t\t\txfs_da3_node_add(state, newblk, &state->extrablk);\n\t\t\tstate->extravalid = 0;\n\t\t}\n\t}\n\n\treturn(0);\n}\n\n/*\n * Balance the btree elements between two intermediate nodes,\n * usually one full and one empty.\n *\n * NOTE: if blk2 is empty, then it will get the upper half of blk1.\n */\nSTATIC void\nxfs_da3_node_rebalance(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_blk\t*blk1,\n\tstruct xfs_da_state_blk\t*blk2)\n{\n\tstruct xfs_da_intnode\t*node1;\n\tstruct xfs_da_intnode\t*node2;\n\tstruct xfs_da_intnode\t*tmpnode;\n\tstruct xfs_da_node_entry *btree1;\n\tstruct xfs_da_node_entry *btree2;\n\tstruct xfs_da_node_entry *btree_s;\n\tstruct xfs_da_node_entry *btree_d;\n\tstruct xfs_da3_icnode_hdr nodehdr1;\n\tstruct xfs_da3_icnode_hdr nodehdr2;\n\tstruct xfs_trans\t*tp;\n\tint\t\t\tcount;\n\tint\t\t\ttmp;\n\tint\t\t\tswap = 0;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\ttrace_xfs_da_node_rebalance(state->args);\n\n\tnode1 = blk1->bp->b_addr;\n\tnode2 = blk2->bp->b_addr;\n\tdp->d_ops->node_hdr_from_disk(&nodehdr1, node1);\n\tdp->d_ops->node_hdr_from_disk(&nodehdr2, node2);\n\tbtree1 = dp->d_ops->node_tree_p(node1);\n\tbtree2 = dp->d_ops->node_tree_p(node2);\n\n\t/*\n\t * Figure out how many entries need to move, and in which direction.\n\t * Swap the nodes around if that makes it simpler.\n\t */\n\tif (nodehdr1.count > 0 && nodehdr2.count > 0 &&\n\t    ((be32_to_cpu(btree2[0].hashval) < be32_to_cpu(btree1[0].hashval)) ||\n\t     (be32_to_cpu(btree2[nodehdr2.count - 1].hashval) <\n\t\t\tbe32_to_cpu(btree1[nodehdr1.count - 1].hashval)))) {\n\t\ttmpnode = node1;\n\t\tnode1 = node2;\n\t\tnode2 = tmpnode;\n\t\tdp->d_ops->node_hdr_from_disk(&nodehdr1, node1);\n\t\tdp->d_ops->node_hdr_from_disk(&nodehdr2, node2);\n\t\tbtree1 = dp->d_ops->node_tree_p(node1);\n\t\tbtree2 = dp->d_ops->node_tree_p(node2);\n\t\tswap = 1;\n\t}\n\n\tcount = (nodehdr1.count - nodehdr2.count) / 2;\n\tif (count == 0)\n\t\treturn;\n\ttp = state->args->trans;\n\t/*\n\t * Two cases: high-to-low and low-to-high.\n\t */\n\tif (count > 0) {\n\t\t/*\n\t\t * Move elements in node2 up to make a hole.\n\t\t */\n\t\ttmp = nodehdr2.count;\n\t\tif (tmp > 0) {\n\t\t\ttmp *= (uint)sizeof(xfs_da_node_entry_t);\n\t\t\tbtree_s = &btree2[0];\n\t\t\tbtree_d = &btree2[count];\n\t\t\tmemmove(btree_d, btree_s, tmp);\n\t\t}\n\n\t\t/*\n\t\t * Move the req'd B-tree elements from high in node1 to\n\t\t * low in node2.\n\t\t */\n\t\tnodehdr2.count += count;\n\t\ttmp = count * (uint)sizeof(xfs_da_node_entry_t);\n\t\tbtree_s = &btree1[nodehdr1.count - count];\n\t\tbtree_d = &btree2[0];\n\t\tmemcpy(btree_d, btree_s, tmp);\n\t\tnodehdr1.count -= count;\n\t} else {\n\t\t/*\n\t\t * Move the req'd B-tree elements from low in node2 to\n\t\t * high in node1.\n\t\t */\n\t\tcount = -count;\n\t\ttmp = count * (uint)sizeof(xfs_da_node_entry_t);\n\t\tbtree_s = &btree2[0];\n\t\tbtree_d = &btree1[nodehdr1.count];\n\t\tmemcpy(btree_d, btree_s, tmp);\n\t\tnodehdr1.count += count;\n\n\t\txfs_trans_log_buf(tp, blk1->bp,\n\t\t\tXFS_DA_LOGRANGE(node1, btree_d, tmp));\n\n\t\t/*\n\t\t * Move elements in node2 down to fill the hole.\n\t\t */\n\t\ttmp  = nodehdr2.count - count;\n\t\ttmp *= (uint)sizeof(xfs_da_node_entry_t);\n\t\tbtree_s = &btree2[count];\n\t\tbtree_d = &btree2[0];\n\t\tmemmove(btree_d, btree_s, tmp);\n\t\tnodehdr2.count -= count;\n\t}\n\n\t/*\n\t * Log header of node 1 and all current bits of node 2.\n\t */\n\tdp->d_ops->node_hdr_to_disk(node1, &nodehdr1);\n\txfs_trans_log_buf(tp, blk1->bp,\n\t\tXFS_DA_LOGRANGE(node1, &node1->hdr, dp->d_ops->node_hdr_size));\n\n\tdp->d_ops->node_hdr_to_disk(node2, &nodehdr2);\n\txfs_trans_log_buf(tp, blk2->bp,\n\t\tXFS_DA_LOGRANGE(node2, &node2->hdr,\n\t\t\t\tdp->d_ops->node_hdr_size +\n\t\t\t\t(sizeof(btree2[0]) * nodehdr2.count)));\n\n\t/*\n\t * Record the last hashval from each block for upward propagation.\n\t * (note: don't use the swapped node pointers)\n\t */\n\tif (swap) {\n\t\tnode1 = blk1->bp->b_addr;\n\t\tnode2 = blk2->bp->b_addr;\n\t\tdp->d_ops->node_hdr_from_disk(&nodehdr1, node1);\n\t\tdp->d_ops->node_hdr_from_disk(&nodehdr2, node2);\n\t\tbtree1 = dp->d_ops->node_tree_p(node1);\n\t\tbtree2 = dp->d_ops->node_tree_p(node2);\n\t}\n\tblk1->hashval = be32_to_cpu(btree1[nodehdr1.count - 1].hashval);\n\tblk2->hashval = be32_to_cpu(btree2[nodehdr2.count - 1].hashval);\n\n\t/*\n\t * Adjust the expected index for insertion.\n\t */\n\tif (blk1->index >= nodehdr1.count) {\n\t\tblk2->index = blk1->index - nodehdr1.count;\n\t\tblk1->index = nodehdr1.count + 1;\t/* make it invalid */\n\t}\n}\n\n/*\n * Add a new entry to an intermediate node.\n */\nSTATIC void\nxfs_da3_node_add(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_blk\t*oldblk,\n\tstruct xfs_da_state_blk\t*newblk)\n{\n\tstruct xfs_da_intnode\t*node;\n\tstruct xfs_da3_icnode_hdr nodehdr;\n\tstruct xfs_da_node_entry *btree;\n\tint\t\t\ttmp;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\ttrace_xfs_da_node_add(state->args);\n\n\tnode = oldblk->bp->b_addr;\n\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\tbtree = dp->d_ops->node_tree_p(node);\n\n\tASSERT(oldblk->index >= 0 && oldblk->index <= nodehdr.count);\n\tASSERT(newblk->blkno != 0);\n\tif (state->args->whichfork == XFS_DATA_FORK)\n\t\tASSERT(newblk->blkno >= state->mp->m_dirleafblk &&\n\t\t       newblk->blkno < state->mp->m_dirfreeblk);\n\n\t/*\n\t * We may need to make some room before we insert the new node.\n\t */\n\ttmp = 0;\n\tif (oldblk->index < nodehdr.count) {\n\t\ttmp = (nodehdr.count - oldblk->index) * (uint)sizeof(*btree);\n\t\tmemmove(&btree[oldblk->index + 1], &btree[oldblk->index], tmp);\n\t}\n\tbtree[oldblk->index].hashval = cpu_to_be32(newblk->hashval);\n\tbtree[oldblk->index].before = cpu_to_be32(newblk->blkno);\n\txfs_trans_log_buf(state->args->trans, oldblk->bp,\n\t\tXFS_DA_LOGRANGE(node, &btree[oldblk->index],\n\t\t\t\ttmp + sizeof(*btree)));\n\n\tnodehdr.count += 1;\n\tdp->d_ops->node_hdr_to_disk(node, &nodehdr);\n\txfs_trans_log_buf(state->args->trans, oldblk->bp,\n\t\tXFS_DA_LOGRANGE(node, &node->hdr, dp->d_ops->node_hdr_size));\n\n\t/*\n\t * Copy the last hash value from the oldblk to propagate upwards.\n\t */\n\toldblk->hashval = be32_to_cpu(btree[nodehdr.count - 1].hashval);\n}\n\n/*========================================================================\n * Routines used for shrinking the Btree.\n *========================================================================*/\n\n/*\n * Deallocate an empty leaf node, remove it from its parent,\n * possibly deallocating that block, etc...\n */\nint\nxfs_da3_join(\n\tstruct xfs_da_state\t*state)\n{\n\tstruct xfs_da_state_blk\t*drop_blk;\n\tstruct xfs_da_state_blk\t*save_blk;\n\tint\t\t\taction = 0;\n\tint\t\t\terror;\n\n\ttrace_xfs_da_join(state->args);\n\n\tdrop_blk = &state->path.blk[ state->path.active-1 ];\n\tsave_blk = &state->altpath.blk[ state->path.active-1 ];\n\tASSERT(state->path.blk[0].magic == XFS_DA_NODE_MAGIC);\n\tASSERT(drop_blk->magic == XFS_ATTR_LEAF_MAGIC ||\n\t       drop_blk->magic == XFS_DIR2_LEAFN_MAGIC);\n\n\t/*\n\t * Walk back up the tree joining/deallocating as necessary.\n\t * When we stop dropping blocks, break out.\n\t */\n\tfor (  ; state->path.active >= 2; drop_blk--, save_blk--,\n\t\t state->path.active--) {\n\t\t/*\n\t\t * See if we can combine the block with a neighbor.\n\t\t *   (action == 0) => no options, just leave\n\t\t *   (action == 1) => coalesce, then unlink\n\t\t *   (action == 2) => block empty, unlink it\n\t\t */\n\t\tswitch (drop_blk->magic) {\n\t\tcase XFS_ATTR_LEAF_MAGIC:\n\t\t\terror = xfs_attr3_leaf_toosmall(state, &action);\n\t\t\tif (error)\n\t\t\t\treturn(error);\n\t\t\tif (action == 0)\n\t\t\t\treturn(0);\n\t\t\txfs_attr3_leaf_unbalance(state, drop_blk, save_blk);\n\t\t\tbreak;\n\t\tcase XFS_DIR2_LEAFN_MAGIC:\n\t\t\terror = xfs_dir2_leafn_toosmall(state, &action);\n\t\t\tif (error)\n\t\t\t\treturn error;\n\t\t\tif (action == 0)\n\t\t\t\treturn 0;\n\t\t\txfs_dir2_leafn_unbalance(state, drop_blk, save_blk);\n\t\t\tbreak;\n\t\tcase XFS_DA_NODE_MAGIC:\n\t\t\t/*\n\t\t\t * Remove the offending node, fixup hashvals,\n\t\t\t * check for a toosmall neighbor.\n\t\t\t */\n\t\t\txfs_da3_node_remove(state, drop_blk);\n\t\t\txfs_da3_fixhashpath(state, &state->path);\n\t\t\terror = xfs_da3_node_toosmall(state, &action);\n\t\t\tif (error)\n\t\t\t\treturn(error);\n\t\t\tif (action == 0)\n\t\t\t\treturn 0;\n\t\t\txfs_da3_node_unbalance(state, drop_blk, save_blk);\n\t\t\tbreak;\n\t\t}\n\t\txfs_da3_fixhashpath(state, &state->altpath);\n\t\terror = xfs_da3_blk_unlink(state, drop_blk, save_blk);\n\t\txfs_da_state_kill_altpath(state);\n\t\tif (error)\n\t\t\treturn(error);\n\t\terror = xfs_da_shrink_inode(state->args, drop_blk->blkno,\n\t\t\t\t\t\t\t drop_blk->bp);\n\t\tdrop_blk->bp = NULL;\n\t\tif (error)\n\t\t\treturn(error);\n\t}\n\t/*\n\t * We joined all the way to the top.  If it turns out that\n\t * we only have one entry in the root, make the child block\n\t * the new root.\n\t */\n\txfs_da3_node_remove(state, drop_blk);\n\txfs_da3_fixhashpath(state, &state->path);\n\terror = xfs_da3_root_join(state, &state->path.blk[0]);\n\treturn(error);\n}\n\n#ifdef\tDEBUG\nstatic void\nxfs_da_blkinfo_onlychild_validate(struct xfs_da_blkinfo *blkinfo, __u16 level)\n{\n\t__be16\tmagic = blkinfo->magic;\n\n\tif (level == 1) {\n\t\tASSERT(magic == cpu_to_be16(XFS_DIR2_LEAFN_MAGIC) ||\n\t\t       magic == cpu_to_be16(XFS_DIR3_LEAFN_MAGIC) ||\n\t\t       magic == cpu_to_be16(XFS_ATTR_LEAF_MAGIC) ||\n\t\t       magic == cpu_to_be16(XFS_ATTR3_LEAF_MAGIC));\n\t} else {\n\t\tASSERT(magic == cpu_to_be16(XFS_DA_NODE_MAGIC) ||\n\t\t       magic == cpu_to_be16(XFS_DA3_NODE_MAGIC));\n\t}\n\tASSERT(!blkinfo->forw);\n\tASSERT(!blkinfo->back);\n}\n#else\t/* !DEBUG */\n#define\txfs_da_blkinfo_onlychild_validate(blkinfo, level)\n#endif\t/* !DEBUG */\n\n/*\n * We have only one entry in the root.  Copy the only remaining child of\n * the old root to block 0 as the new root node.\n */\nSTATIC int\nxfs_da3_root_join(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_blk\t*root_blk)\n{\n\tstruct xfs_da_intnode\t*oldroot;\n\tstruct xfs_da_args\t*args;\n\txfs_dablk_t\t\tchild;\n\tstruct xfs_buf\t\t*bp;\n\tstruct xfs_da3_icnode_hdr oldroothdr;\n\tstruct xfs_da_node_entry *btree;\n\tint\t\t\terror;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\ttrace_xfs_da_root_join(state->args);\n\n\tASSERT(root_blk->magic == XFS_DA_NODE_MAGIC);\n\n\targs = state->args;\n\toldroot = root_blk->bp->b_addr;\n\tdp->d_ops->node_hdr_from_disk(&oldroothdr, oldroot);\n\tASSERT(oldroothdr.forw == 0);\n\tASSERT(oldroothdr.back == 0);\n\n\t/*\n\t * If the root has more than one child, then don't do anything.\n\t */\n\tif (oldroothdr.count > 1)\n\t\treturn 0;\n\n\t/*\n\t * Read in the (only) child block, then copy those bytes into\n\t * the root block's buffer and free the original child block.\n\t */\n\tbtree = dp->d_ops->node_tree_p(oldroot);\n\tchild = be32_to_cpu(btree[0].before);\n\tASSERT(child != 0);\n\terror = xfs_da3_node_read(args->trans, dp, child, -1, &bp,\n\t\t\t\t\t     args->whichfork);\n\tif (error)\n\t\treturn error;\n\txfs_da_blkinfo_onlychild_validate(bp->b_addr, oldroothdr.level);\n\n\t/*\n\t * This could be copying a leaf back into the root block in the case of\n\t * there only being a single leaf block left in the tree. Hence we have\n\t * to update the b_ops pointer as well to match the buffer type change\n\t * that could occur. For dir3 blocks we also need to update the block\n\t * number in the buffer header.\n\t */\n\tmemcpy(root_blk->bp->b_addr, bp->b_addr, state->blocksize);\n\troot_blk->bp->b_ops = bp->b_ops;\n\txfs_trans_buf_copy_type(root_blk->bp, bp);\n\tif (oldroothdr.magic == XFS_DA3_NODE_MAGIC) {\n\t\tstruct xfs_da3_blkinfo *da3 = root_blk->bp->b_addr;\n\t\tda3->blkno = cpu_to_be64(root_blk->bp->b_bn);\n\t}\n\txfs_trans_log_buf(args->trans, root_blk->bp, 0, state->blocksize - 1);\n\terror = xfs_da_shrink_inode(args, child, bp);\n\treturn(error);\n}\n\n/*\n * Check a node block and its neighbors to see if the block should be\n * collapsed into one or the other neighbor.  Always keep the block\n * with the smaller block number.\n * If the current block is over 50% full, don't try to join it, return 0.\n * If the block is empty, fill in the state structure and return 2.\n * If it can be collapsed, fill in the state structure and return 1.\n * If nothing can be done, return 0.\n */\nSTATIC int\nxfs_da3_node_toosmall(\n\tstruct xfs_da_state\t*state,\n\tint\t\t\t*action)\n{\n\tstruct xfs_da_intnode\t*node;\n\tstruct xfs_da_state_blk\t*blk;\n\tstruct xfs_da_blkinfo\t*info;\n\txfs_dablk_t\t\tblkno;\n\tstruct xfs_buf\t\t*bp;\n\tstruct xfs_da3_icnode_hdr nodehdr;\n\tint\t\t\tcount;\n\tint\t\t\tforward;\n\tint\t\t\terror;\n\tint\t\t\tretval;\n\tint\t\t\ti;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\ttrace_xfs_da_node_toosmall(state->args);\n\n\t/*\n\t * Check for the degenerate case of the block being over 50% full.\n\t * If so, it's not worth even looking to see if we might be able\n\t * to coalesce with a sibling.\n\t */\n\tblk = &state->path.blk[ state->path.active-1 ];\n\tinfo = blk->bp->b_addr;\n\tnode = (xfs_da_intnode_t *)info;\n\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\tif (nodehdr.count > (state->node_ents >> 1)) {\n\t\t*action = 0;\t/* blk over 50%, don't try to join */\n\t\treturn(0);\t/* blk over 50%, don't try to join */\n\t}\n\n\t/*\n\t * Check for the degenerate case of the block being empty.\n\t * If the block is empty, we'll simply delete it, no need to\n\t * coalesce it with a sibling block.  We choose (arbitrarily)\n\t * to merge with the forward block unless it is NULL.\n\t */\n\tif (nodehdr.count == 0) {\n\t\t/*\n\t\t * Make altpath point to the block we want to keep and\n\t\t * path point to the block we want to drop (this one).\n\t\t */\n\t\tforward = (info->forw != 0);\n\t\tmemcpy(&state->altpath, &state->path, sizeof(state->path));\n\t\terror = xfs_da3_path_shift(state, &state->altpath, forward,\n\t\t\t\t\t\t 0, &retval);\n\t\tif (error)\n\t\t\treturn(error);\n\t\tif (retval) {\n\t\t\t*action = 0;\n\t\t} else {\n\t\t\t*action = 2;\n\t\t}\n\t\treturn(0);\n\t}\n\n\t/*\n\t * Examine each sibling block to see if we can coalesce with\n\t * at least 25% free space to spare.  We need to figure out\n\t * whether to merge with the forward or the backward block.\n\t * We prefer coalescing with the lower numbered sibling so as\n\t * to shrink a directory over time.\n\t */\n\tcount  = state->node_ents;\n\tcount -= state->node_ents >> 2;\n\tcount -= nodehdr.count;\n\n\t/* start with smaller blk num */\n\tforward = nodehdr.forw < nodehdr.back;\n\tfor (i = 0; i < 2; forward = !forward, i++) {\n\t\tstruct xfs_da3_icnode_hdr thdr;\n\t\tif (forward)\n\t\t\tblkno = nodehdr.forw;\n\t\telse\n\t\t\tblkno = nodehdr.back;\n\t\tif (blkno == 0)\n\t\t\tcontinue;\n\t\terror = xfs_da3_node_read(state->args->trans, dp,\n\t\t\t\t\tblkno, -1, &bp, state->args->whichfork);\n\t\tif (error)\n\t\t\treturn(error);\n\n\t\tnode = bp->b_addr;\n\t\tdp->d_ops->node_hdr_from_disk(&thdr, node);\n\t\txfs_trans_brelse(state->args->trans, bp);\n\n\t\tif (count - thdr.count >= 0)\n\t\t\tbreak;\t/* fits with at least 25% to spare */\n\t}\n\tif (i >= 2) {\n\t\t*action = 0;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Make altpath point to the block we want to keep (the lower\n\t * numbered block) and path point to the block we want to drop.\n\t */\n\tmemcpy(&state->altpath, &state->path, sizeof(state->path));\n\tif (blkno < blk->blkno) {\n\t\terror = xfs_da3_path_shift(state, &state->altpath, forward,\n\t\t\t\t\t\t 0, &retval);\n\t} else {\n\t\terror = xfs_da3_path_shift(state, &state->path, forward,\n\t\t\t\t\t\t 0, &retval);\n\t}\n\tif (error)\n\t\treturn error;\n\tif (retval) {\n\t\t*action = 0;\n\t\treturn 0;\n\t}\n\t*action = 1;\n\treturn 0;\n}\n\n/*\n * Pick up the last hashvalue from an intermediate node.\n */\nSTATIC uint\nxfs_da3_node_lasthash(\n\tstruct xfs_inode\t*dp,\n\tstruct xfs_buf\t\t*bp,\n\tint\t\t\t*count)\n{\n\tstruct xfs_da_intnode\t *node;\n\tstruct xfs_da_node_entry *btree;\n\tstruct xfs_da3_icnode_hdr nodehdr;\n\n\tnode = bp->b_addr;\n\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\tif (count)\n\t\t*count = nodehdr.count;\n\tif (!nodehdr.count)\n\t\treturn 0;\n\tbtree = dp->d_ops->node_tree_p(node);\n\treturn be32_to_cpu(btree[nodehdr.count - 1].hashval);\n}\n\n/*\n * Walk back up the tree adjusting hash values as necessary,\n * when we stop making changes, return.\n */\nvoid\nxfs_da3_fixhashpath(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_path *path)\n{\n\tstruct xfs_da_state_blk\t*blk;\n\tstruct xfs_da_intnode\t*node;\n\tstruct xfs_da_node_entry *btree;\n\txfs_dahash_t\t\tlasthash=0;\n\tint\t\t\tlevel;\n\tint\t\t\tcount;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\ttrace_xfs_da_fixhashpath(state->args);\n\n\tlevel = path->active-1;\n\tblk = &path->blk[ level ];\n\tswitch (blk->magic) {\n\tcase XFS_ATTR_LEAF_MAGIC:\n\t\tlasthash = xfs_attr_leaf_lasthash(blk->bp, &count);\n\t\tif (count == 0)\n\t\t\treturn;\n\t\tbreak;\n\tcase XFS_DIR2_LEAFN_MAGIC:\n\t\tlasthash = xfs_dir2_leafn_lasthash(dp, blk->bp, &count);\n\t\tif (count == 0)\n\t\t\treturn;\n\t\tbreak;\n\tcase XFS_DA_NODE_MAGIC:\n\t\tlasthash = xfs_da3_node_lasthash(dp, blk->bp, &count);\n\t\tif (count == 0)\n\t\t\treturn;\n\t\tbreak;\n\t}\n\tfor (blk--, level--; level >= 0; blk--, level--) {\n\t\tstruct xfs_da3_icnode_hdr nodehdr;\n\n\t\tnode = blk->bp->b_addr;\n\t\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\t\tbtree = dp->d_ops->node_tree_p(node);\n\t\tif (be32_to_cpu(btree[blk->index].hashval) == lasthash)\n\t\t\tbreak;\n\t\tblk->hashval = lasthash;\n\t\tbtree[blk->index].hashval = cpu_to_be32(lasthash);\n\t\txfs_trans_log_buf(state->args->trans, blk->bp,\n\t\t\t\t  XFS_DA_LOGRANGE(node, &btree[blk->index],\n\t\t\t\t\t\t  sizeof(*btree)));\n\n\t\tlasthash = be32_to_cpu(btree[nodehdr.count - 1].hashval);\n\t}\n}\n\n/*\n * Remove an entry from an intermediate node.\n */\nSTATIC void\nxfs_da3_node_remove(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_blk\t*drop_blk)\n{\n\tstruct xfs_da_intnode\t*node;\n\tstruct xfs_da3_icnode_hdr nodehdr;\n\tstruct xfs_da_node_entry *btree;\n\tint\t\t\tindex;\n\tint\t\t\ttmp;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\ttrace_xfs_da_node_remove(state->args);\n\n\tnode = drop_blk->bp->b_addr;\n\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\tASSERT(drop_blk->index < nodehdr.count);\n\tASSERT(drop_blk->index >= 0);\n\n\t/*\n\t * Copy over the offending entry, or just zero it out.\n\t */\n\tindex = drop_blk->index;\n\tbtree = dp->d_ops->node_tree_p(node);\n\tif (index < nodehdr.count - 1) {\n\t\ttmp  = nodehdr.count - index - 1;\n\t\ttmp *= (uint)sizeof(xfs_da_node_entry_t);\n\t\tmemmove(&btree[index], &btree[index + 1], tmp);\n\t\txfs_trans_log_buf(state->args->trans, drop_blk->bp,\n\t\t    XFS_DA_LOGRANGE(node, &btree[index], tmp));\n\t\tindex = nodehdr.count - 1;\n\t}\n\tmemset(&btree[index], 0, sizeof(xfs_da_node_entry_t));\n\txfs_trans_log_buf(state->args->trans, drop_blk->bp,\n\t    XFS_DA_LOGRANGE(node, &btree[index], sizeof(btree[index])));\n\tnodehdr.count -= 1;\n\tdp->d_ops->node_hdr_to_disk(node, &nodehdr);\n\txfs_trans_log_buf(state->args->trans, drop_blk->bp,\n\t    XFS_DA_LOGRANGE(node, &node->hdr, dp->d_ops->node_hdr_size));\n\n\t/*\n\t * Copy the last hash value from the block to propagate upwards.\n\t */\n\tdrop_blk->hashval = be32_to_cpu(btree[index - 1].hashval);\n}\n\n/*\n * Unbalance the elements between two intermediate nodes,\n * move all Btree elements from one node into another.\n */\nSTATIC void\nxfs_da3_node_unbalance(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_blk\t*drop_blk,\n\tstruct xfs_da_state_blk\t*save_blk)\n{\n\tstruct xfs_da_intnode\t*drop_node;\n\tstruct xfs_da_intnode\t*save_node;\n\tstruct xfs_da_node_entry *drop_btree;\n\tstruct xfs_da_node_entry *save_btree;\n\tstruct xfs_da3_icnode_hdr drop_hdr;\n\tstruct xfs_da3_icnode_hdr save_hdr;\n\tstruct xfs_trans\t*tp;\n\tint\t\t\tsindex;\n\tint\t\t\ttmp;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\ttrace_xfs_da_node_unbalance(state->args);\n\n\tdrop_node = drop_blk->bp->b_addr;\n\tsave_node = save_blk->bp->b_addr;\n\tdp->d_ops->node_hdr_from_disk(&drop_hdr, drop_node);\n\tdp->d_ops->node_hdr_from_disk(&save_hdr, save_node);\n\tdrop_btree = dp->d_ops->node_tree_p(drop_node);\n\tsave_btree = dp->d_ops->node_tree_p(save_node);\n\ttp = state->args->trans;\n\n\t/*\n\t * If the dying block has lower hashvals, then move all the\n\t * elements in the remaining block up to make a hole.\n\t */\n\tif ((be32_to_cpu(drop_btree[0].hashval) <\n\t\t\tbe32_to_cpu(save_btree[0].hashval)) ||\n\t    (be32_to_cpu(drop_btree[drop_hdr.count - 1].hashval) <\n\t\t\tbe32_to_cpu(save_btree[save_hdr.count - 1].hashval))) {\n\t\t/* XXX: check this - is memmove dst correct? */\n\t\ttmp = save_hdr.count * sizeof(xfs_da_node_entry_t);\n\t\tmemmove(&save_btree[drop_hdr.count], &save_btree[0], tmp);\n\n\t\tsindex = 0;\n\t\txfs_trans_log_buf(tp, save_blk->bp,\n\t\t\tXFS_DA_LOGRANGE(save_node, &save_btree[0],\n\t\t\t\t(save_hdr.count + drop_hdr.count) *\n\t\t\t\t\t\tsizeof(xfs_da_node_entry_t)));\n\t} else {\n\t\tsindex = save_hdr.count;\n\t\txfs_trans_log_buf(tp, save_blk->bp,\n\t\t\tXFS_DA_LOGRANGE(save_node, &save_btree[sindex],\n\t\t\t\tdrop_hdr.count * sizeof(xfs_da_node_entry_t)));\n\t}\n\n\t/*\n\t * Move all the B-tree elements from drop_blk to save_blk.\n\t */\n\ttmp = drop_hdr.count * (uint)sizeof(xfs_da_node_entry_t);\n\tmemcpy(&save_btree[sindex], &drop_btree[0], tmp);\n\tsave_hdr.count += drop_hdr.count;\n\n\tdp->d_ops->node_hdr_to_disk(save_node, &save_hdr);\n\txfs_trans_log_buf(tp, save_blk->bp,\n\t\tXFS_DA_LOGRANGE(save_node, &save_node->hdr,\n\t\t\t\tdp->d_ops->node_hdr_size));\n\n\t/*\n\t * Save the last hashval in the remaining block for upward propagation.\n\t */\n\tsave_blk->hashval = be32_to_cpu(save_btree[save_hdr.count - 1].hashval);\n}\n\n/*========================================================================\n * Routines used for finding things in the Btree.\n *========================================================================*/\n\n/*\n * Walk down the Btree looking for a particular filename, filling\n * in the state structure as we go.\n *\n * We will set the state structure to point to each of the elements\n * in each of the nodes where either the hashval is or should be.\n *\n * We support duplicate hashval's so for each entry in the current\n * node that could contain the desired hashval, descend.  This is a\n * pruned depth-first tree search.\n */\nint\t\t\t\t\t\t\t/* error */\nxfs_da3_node_lookup_int(\n\tstruct xfs_da_state\t*state,\n\tint\t\t\t*result)\n{\n\tstruct xfs_da_state_blk\t*blk;\n\tstruct xfs_da_blkinfo\t*curr;\n\tstruct xfs_da_intnode\t*node;\n\tstruct xfs_da_node_entry *btree;\n\tstruct xfs_da3_icnode_hdr nodehdr;\n\tstruct xfs_da_args\t*args;\n\txfs_dablk_t\t\tblkno;\n\txfs_dahash_t\t\thashval;\n\txfs_dahash_t\t\tbtreehashval;\n\tint\t\t\tprobe;\n\tint\t\t\tspan;\n\tint\t\t\tmax;\n\tint\t\t\terror;\n\tint\t\t\tretval;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\targs = state->args;\n\n\t/*\n\t * Descend thru the B-tree searching each level for the right\n\t * node to use, until the right hashval is found.\n\t */\n\tblkno = (args->whichfork == XFS_DATA_FORK)? state->mp->m_dirleafblk : 0;\n\tfor (blk = &state->path.blk[0], state->path.active = 1;\n\t\t\t state->path.active <= XFS_DA_NODE_MAXDEPTH;\n\t\t\t blk++, state->path.active++) {\n\t\t/*\n\t\t * Read the next node down in the tree.\n\t\t */\n\t\tblk->blkno = blkno;\n\t\terror = xfs_da3_node_read(args->trans, args->dp, blkno,\n\t\t\t\t\t-1, &blk->bp, args->whichfork);\n\t\tif (error) {\n\t\t\tblk->blkno = 0;\n\t\t\tstate->path.active--;\n\t\t\treturn(error);\n\t\t}\n\t\tcurr = blk->bp->b_addr;\n\t\tblk->magic = be16_to_cpu(curr->magic);\n\n\t\tif (blk->magic == XFS_ATTR_LEAF_MAGIC ||\n\t\t    blk->magic == XFS_ATTR3_LEAF_MAGIC) {\n\t\t\tblk->magic = XFS_ATTR_LEAF_MAGIC;\n\t\t\tblk->hashval = xfs_attr_leaf_lasthash(blk->bp, NULL);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (blk->magic == XFS_DIR2_LEAFN_MAGIC ||\n\t\t    blk->magic == XFS_DIR3_LEAFN_MAGIC) {\n\t\t\tblk->magic = XFS_DIR2_LEAFN_MAGIC;\n\t\t\tblk->hashval = xfs_dir2_leafn_lasthash(args->dp,\n\t\t\t\t\t\t\t       blk->bp, NULL);\n\t\t\tbreak;\n\t\t}\n\n\t\tblk->magic = XFS_DA_NODE_MAGIC;\n\n\n\t\t/*\n\t\t * Search an intermediate node for a match.\n\t\t */\n\t\tnode = blk->bp->b_addr;\n\t\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\t\tbtree = dp->d_ops->node_tree_p(node);\n\n\t\tmax = nodehdr.count;\n\t\tblk->hashval = be32_to_cpu(btree[max - 1].hashval);\n\n\t\t/*\n\t\t * Binary search.  (note: small blocks will skip loop)\n\t\t */\n\t\tprobe = span = max / 2;\n\t\thashval = args->hashval;\n\t\twhile (span > 4) {\n\t\t\tspan /= 2;\n\t\t\tbtreehashval = be32_to_cpu(btree[probe].hashval);\n\t\t\tif (btreehashval < hashval)\n\t\t\t\tprobe += span;\n\t\t\telse if (btreehashval > hashval)\n\t\t\t\tprobe -= span;\n\t\t\telse\n\t\t\t\tbreak;\n\t\t}\n\t\tASSERT((probe >= 0) && (probe < max));\n\t\tASSERT((span <= 4) ||\n\t\t\t(be32_to_cpu(btree[probe].hashval) == hashval));\n\n\t\t/*\n\t\t * Since we may have duplicate hashval's, find the first\n\t\t * matching hashval in the node.\n\t\t */\n\t\twhile (probe > 0 &&\n\t\t       be32_to_cpu(btree[probe].hashval) >= hashval) {\n\t\t\tprobe--;\n\t\t}\n\t\twhile (probe < max &&\n\t\t       be32_to_cpu(btree[probe].hashval) < hashval) {\n\t\t\tprobe++;\n\t\t}\n\n\t\t/*\n\t\t * Pick the right block to descend on.\n\t\t */\n\t\tif (probe == max) {\n\t\t\tblk->index = max - 1;\n\t\t\tblkno = be32_to_cpu(btree[max - 1].before);\n\t\t} else {\n\t\t\tblk->index = probe;\n\t\t\tblkno = be32_to_cpu(btree[probe].before);\n\t\t}\n\t}\n\n\t/*\n\t * A leaf block that ends in the hashval that we are interested in\n\t * (final hashval == search hashval) means that the next block may\n\t * contain more entries with the same hashval, shift upward to the\n\t * next leaf and keep searching.\n\t */\n\tfor (;;) {\n\t\tif (blk->magic == XFS_DIR2_LEAFN_MAGIC) {\n\t\t\tretval = xfs_dir2_leafn_lookup_int(blk->bp, args,\n\t\t\t\t\t\t\t&blk->index, state);\n\t\t} else if (blk->magic == XFS_ATTR_LEAF_MAGIC) {\n\t\t\tretval = xfs_attr3_leaf_lookup_int(blk->bp, args);\n\t\t\tblk->index = args->index;\n\t\t\targs->blkno = blk->blkno;\n\t\t} else {\n\t\t\tASSERT(0);\n\t\t\treturn XFS_ERROR(EFSCORRUPTED);\n\t\t}\n\t\tif (((retval == ENOENT) || (retval == ENOATTR)) &&\n\t\t    (blk->hashval == args->hashval)) {\n\t\t\terror = xfs_da3_path_shift(state, &state->path, 1, 1,\n\t\t\t\t\t\t\t &retval);\n\t\t\tif (error)\n\t\t\t\treturn(error);\n\t\t\tif (retval == 0) {\n\t\t\t\tcontinue;\n\t\t\t} else if (blk->magic == XFS_ATTR_LEAF_MAGIC) {\n\t\t\t\t/* path_shift() gives ENOENT */\n\t\t\t\tretval = XFS_ERROR(ENOATTR);\n\t\t\t}\n\t\t}\n\t\tbreak;\n\t}\n\t*result = retval;\n\treturn(0);\n}\n\n/*========================================================================\n * Utility routines.\n *========================================================================*/\n\n/*\n * Compare two intermediate nodes for \"order\".\n */\nSTATIC int\nxfs_da3_node_order(\n\tstruct xfs_inode *dp,\n\tstruct xfs_buf\t*node1_bp,\n\tstruct xfs_buf\t*node2_bp)\n{\n\tstruct xfs_da_intnode\t*node1;\n\tstruct xfs_da_intnode\t*node2;\n\tstruct xfs_da_node_entry *btree1;\n\tstruct xfs_da_node_entry *btree2;\n\tstruct xfs_da3_icnode_hdr node1hdr;\n\tstruct xfs_da3_icnode_hdr node2hdr;\n\n\tnode1 = node1_bp->b_addr;\n\tnode2 = node2_bp->b_addr;\n\tdp->d_ops->node_hdr_from_disk(&node1hdr, node1);\n\tdp->d_ops->node_hdr_from_disk(&node2hdr, node2);\n\tbtree1 = dp->d_ops->node_tree_p(node1);\n\tbtree2 = dp->d_ops->node_tree_p(node2);\n\n\tif (node1hdr.count > 0 && node2hdr.count > 0 &&\n\t    ((be32_to_cpu(btree2[0].hashval) < be32_to_cpu(btree1[0].hashval)) ||\n\t     (be32_to_cpu(btree2[node2hdr.count - 1].hashval) <\n\t      be32_to_cpu(btree1[node1hdr.count - 1].hashval)))) {\n\t\treturn 1;\n\t}\n\treturn 0;\n}\n\n/*\n * Link a new block into a doubly linked list of blocks (of whatever type).\n */\nint\t\t\t\t\t\t\t/* error */\nxfs_da3_blk_link(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_blk\t*old_blk,\n\tstruct xfs_da_state_blk\t*new_blk)\n{\n\tstruct xfs_da_blkinfo\t*old_info;\n\tstruct xfs_da_blkinfo\t*new_info;\n\tstruct xfs_da_blkinfo\t*tmp_info;\n\tstruct xfs_da_args\t*args;\n\tstruct xfs_buf\t\t*bp;\n\tint\t\t\tbefore = 0;\n\tint\t\t\terror;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\t/*\n\t * Set up environment.\n\t */\n\targs = state->args;\n\tASSERT(args != NULL);\n\told_info = old_blk->bp->b_addr;\n\tnew_info = new_blk->bp->b_addr;\n\tASSERT(old_blk->magic == XFS_DA_NODE_MAGIC ||\n\t       old_blk->magic == XFS_DIR2_LEAFN_MAGIC ||\n\t       old_blk->magic == XFS_ATTR_LEAF_MAGIC);\n\n\tswitch (old_blk->magic) {\n\tcase XFS_ATTR_LEAF_MAGIC:\n\t\tbefore = xfs_attr_leaf_order(old_blk->bp, new_blk->bp);\n\t\tbreak;\n\tcase XFS_DIR2_LEAFN_MAGIC:\n\t\tbefore = xfs_dir2_leafn_order(dp, old_blk->bp, new_blk->bp);\n\t\tbreak;\n\tcase XFS_DA_NODE_MAGIC:\n\t\tbefore = xfs_da3_node_order(dp, old_blk->bp, new_blk->bp);\n\t\tbreak;\n\t}\n\n\t/*\n\t * Link blocks in appropriate order.\n\t */\n\tif (before) {\n\t\t/*\n\t\t * Link new block in before existing block.\n\t\t */\n\t\ttrace_xfs_da_link_before(args);\n\t\tnew_info->forw = cpu_to_be32(old_blk->blkno);\n\t\tnew_info->back = old_info->back;\n\t\tif (old_info->back) {\n\t\t\terror = xfs_da3_node_read(args->trans, dp,\n\t\t\t\t\t\tbe32_to_cpu(old_info->back),\n\t\t\t\t\t\t-1, &bp, args->whichfork);\n\t\t\tif (error)\n\t\t\t\treturn(error);\n\t\t\tASSERT(bp != NULL);\n\t\t\ttmp_info = bp->b_addr;\n\t\t\tASSERT(tmp_info->magic == old_info->magic);\n\t\t\tASSERT(be32_to_cpu(tmp_info->forw) == old_blk->blkno);\n\t\t\ttmp_info->forw = cpu_to_be32(new_blk->blkno);\n\t\t\txfs_trans_log_buf(args->trans, bp, 0, sizeof(*tmp_info)-1);\n\t\t}\n\t\told_info->back = cpu_to_be32(new_blk->blkno);\n\t} else {\n\t\t/*\n\t\t * Link new block in after existing block.\n\t\t */\n\t\ttrace_xfs_da_link_after(args);\n\t\tnew_info->forw = old_info->forw;\n\t\tnew_info->back = cpu_to_be32(old_blk->blkno);\n\t\tif (old_info->forw) {\n\t\t\terror = xfs_da3_node_read(args->trans, dp,\n\t\t\t\t\t\tbe32_to_cpu(old_info->forw),\n\t\t\t\t\t\t-1, &bp, args->whichfork);\n\t\t\tif (error)\n\t\t\t\treturn(error);\n\t\t\tASSERT(bp != NULL);\n\t\t\ttmp_info = bp->b_addr;\n\t\t\tASSERT(tmp_info->magic == old_info->magic);\n\t\t\tASSERT(be32_to_cpu(tmp_info->back) == old_blk->blkno);\n\t\t\ttmp_info->back = cpu_to_be32(new_blk->blkno);\n\t\t\txfs_trans_log_buf(args->trans, bp, 0, sizeof(*tmp_info)-1);\n\t\t}\n\t\told_info->forw = cpu_to_be32(new_blk->blkno);\n\t}\n\n\txfs_trans_log_buf(args->trans, old_blk->bp, 0, sizeof(*tmp_info) - 1);\n\txfs_trans_log_buf(args->trans, new_blk->bp, 0, sizeof(*tmp_info) - 1);\n\treturn(0);\n}\n\n/*\n * Unlink a block from a doubly linked list of blocks.\n */\nSTATIC int\t\t\t\t\t\t/* error */\nxfs_da3_blk_unlink(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_blk\t*drop_blk,\n\tstruct xfs_da_state_blk\t*save_blk)\n{\n\tstruct xfs_da_blkinfo\t*drop_info;\n\tstruct xfs_da_blkinfo\t*save_info;\n\tstruct xfs_da_blkinfo\t*tmp_info;\n\tstruct xfs_da_args\t*args;\n\tstruct xfs_buf\t\t*bp;\n\tint\t\t\terror;\n\n\t/*\n\t * Set up environment.\n\t */\n\targs = state->args;\n\tASSERT(args != NULL);\n\tsave_info = save_blk->bp->b_addr;\n\tdrop_info = drop_blk->bp->b_addr;\n\tASSERT(save_blk->magic == XFS_DA_NODE_MAGIC ||\n\t       save_blk->magic == XFS_DIR2_LEAFN_MAGIC ||\n\t       save_blk->magic == XFS_ATTR_LEAF_MAGIC);\n\tASSERT(save_blk->magic == drop_blk->magic);\n\tASSERT((be32_to_cpu(save_info->forw) == drop_blk->blkno) ||\n\t       (be32_to_cpu(save_info->back) == drop_blk->blkno));\n\tASSERT((be32_to_cpu(drop_info->forw) == save_blk->blkno) ||\n\t       (be32_to_cpu(drop_info->back) == save_blk->blkno));\n\n\t/*\n\t * Unlink the leaf block from the doubly linked chain of leaves.\n\t */\n\tif (be32_to_cpu(save_info->back) == drop_blk->blkno) {\n\t\ttrace_xfs_da_unlink_back(args);\n\t\tsave_info->back = drop_info->back;\n\t\tif (drop_info->back) {\n\t\t\terror = xfs_da3_node_read(args->trans, args->dp,\n\t\t\t\t\t\tbe32_to_cpu(drop_info->back),\n\t\t\t\t\t\t-1, &bp, args->whichfork);\n\t\t\tif (error)\n\t\t\t\treturn(error);\n\t\t\tASSERT(bp != NULL);\n\t\t\ttmp_info = bp->b_addr;\n\t\t\tASSERT(tmp_info->magic == save_info->magic);\n\t\t\tASSERT(be32_to_cpu(tmp_info->forw) == drop_blk->blkno);\n\t\t\ttmp_info->forw = cpu_to_be32(save_blk->blkno);\n\t\t\txfs_trans_log_buf(args->trans, bp, 0,\n\t\t\t\t\t\t    sizeof(*tmp_info) - 1);\n\t\t}\n\t} else {\n\t\ttrace_xfs_da_unlink_forward(args);\n\t\tsave_info->forw = drop_info->forw;\n\t\tif (drop_info->forw) {\n\t\t\terror = xfs_da3_node_read(args->trans, args->dp,\n\t\t\t\t\t\tbe32_to_cpu(drop_info->forw),\n\t\t\t\t\t\t-1, &bp, args->whichfork);\n\t\t\tif (error)\n\t\t\t\treturn(error);\n\t\t\tASSERT(bp != NULL);\n\t\t\ttmp_info = bp->b_addr;\n\t\t\tASSERT(tmp_info->magic == save_info->magic);\n\t\t\tASSERT(be32_to_cpu(tmp_info->back) == drop_blk->blkno);\n\t\t\ttmp_info->back = cpu_to_be32(save_blk->blkno);\n\t\t\txfs_trans_log_buf(args->trans, bp, 0,\n\t\t\t\t\t\t    sizeof(*tmp_info) - 1);\n\t\t}\n\t}\n\n\txfs_trans_log_buf(args->trans, save_blk->bp, 0, sizeof(*save_info) - 1);\n\treturn(0);\n}\n\n/*\n * Move a path \"forward\" or \"!forward\" one block at the current level.\n *\n * This routine will adjust a \"path\" to point to the next block\n * \"forward\" (higher hashvalues) or \"!forward\" (lower hashvals) in the\n * Btree, including updating pointers to the intermediate nodes between\n * the new bottom and the root.\n */\nint\t\t\t\t\t\t\t/* error */\nxfs_da3_path_shift(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_path *path,\n\tint\t\t\tforward,\n\tint\t\t\trelease,\n\tint\t\t\t*result)\n{\n\tstruct xfs_da_state_blk\t*blk;\n\tstruct xfs_da_blkinfo\t*info;\n\tstruct xfs_da_intnode\t*node;\n\tstruct xfs_da_args\t*args;\n\tstruct xfs_da_node_entry *btree;\n\tstruct xfs_da3_icnode_hdr nodehdr;\n\txfs_dablk_t\t\tblkno = 0;\n\tint\t\t\tlevel;\n\tint\t\t\terror;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\ttrace_xfs_da_path_shift(state->args);\n\n\t/*\n\t * Roll up the Btree looking for the first block where our\n\t * current index is not at the edge of the block.  Note that\n\t * we skip the bottom layer because we want the sibling block.\n\t */\n\targs = state->args;\n\tASSERT(args != NULL);\n\tASSERT(path != NULL);\n\tASSERT((path->active > 0) && (path->active < XFS_DA_NODE_MAXDEPTH));\n\tlevel = (path->active-1) - 1;\t/* skip bottom layer in path */\n\tfor (blk = &path->blk[level]; level >= 0; blk--, level--) {\n\t\tnode = blk->bp->b_addr;\n\t\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\t\tbtree = dp->d_ops->node_tree_p(node);\n\n\t\tif (forward && (blk->index < nodehdr.count - 1)) {\n\t\t\tblk->index++;\n\t\t\tblkno = be32_to_cpu(btree[blk->index].before);\n\t\t\tbreak;\n\t\t} else if (!forward && (blk->index > 0)) {\n\t\t\tblk->index--;\n\t\t\tblkno = be32_to_cpu(btree[blk->index].before);\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (level < 0) {\n\t\t*result = XFS_ERROR(ENOENT);\t/* we're out of our tree */\n\t\tASSERT(args->op_flags & XFS_DA_OP_OKNOENT);\n\t\treturn(0);\n\t}\n\n\t/*\n\t * Roll down the edge of the subtree until we reach the\n\t * same depth we were at originally.\n\t */\n\tfor (blk++, level++; level < path->active; blk++, level++) {\n\t\t/*\n\t\t * Release the old block.\n\t\t * (if it's dirty, trans won't actually let go)\n\t\t */\n\t\tif (release)\n\t\t\txfs_trans_brelse(args->trans, blk->bp);\n\n\t\t/*\n\t\t * Read the next child block.\n\t\t */\n\t\tblk->blkno = blkno;\n\t\terror = xfs_da3_node_read(args->trans, dp, blkno, -1,\n\t\t\t\t\t&blk->bp, args->whichfork);\n\t\tif (error)\n\t\t\treturn(error);\n\t\tinfo = blk->bp->b_addr;\n\t\tASSERT(info->magic == cpu_to_be16(XFS_DA_NODE_MAGIC) ||\n\t\t       info->magic == cpu_to_be16(XFS_DA3_NODE_MAGIC) ||\n\t\t       info->magic == cpu_to_be16(XFS_DIR2_LEAFN_MAGIC) ||\n\t\t       info->magic == cpu_to_be16(XFS_DIR3_LEAFN_MAGIC) ||\n\t\t       info->magic == cpu_to_be16(XFS_ATTR_LEAF_MAGIC) ||\n\t\t       info->magic == cpu_to_be16(XFS_ATTR3_LEAF_MAGIC));\n\n\n\t\t/*\n\t\t * Note: we flatten the magic number to a single type so we\n\t\t * don't have to compare against crc/non-crc types elsewhere.\n\t\t */\n\t\tswitch (be16_to_cpu(info->magic)) {\n\t\tcase XFS_DA_NODE_MAGIC:\n\t\tcase XFS_DA3_NODE_MAGIC:\n\t\t\tblk->magic = XFS_DA_NODE_MAGIC;\n\t\t\tnode = (xfs_da_intnode_t *)info;\n\t\t\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\t\t\tbtree = dp->d_ops->node_tree_p(node);\n\t\t\tblk->hashval = be32_to_cpu(btree[nodehdr.count - 1].hashval);\n\t\t\tif (forward)\n\t\t\t\tblk->index = 0;\n\t\t\telse\n\t\t\t\tblk->index = nodehdr.count - 1;\n\t\t\tblkno = be32_to_cpu(btree[blk->index].before);\n\t\t\tbreak;\n\t\tcase XFS_ATTR_LEAF_MAGIC:\n\t\tcase XFS_ATTR3_LEAF_MAGIC:\n\t\t\tblk->magic = XFS_ATTR_LEAF_MAGIC;\n\t\t\tASSERT(level == path->active-1);\n\t\t\tblk->index = 0;\n\t\t\tblk->hashval = xfs_attr_leaf_lasthash(blk->bp, NULL);\n\t\t\tbreak;\n\t\tcase XFS_DIR2_LEAFN_MAGIC:\n\t\tcase XFS_DIR3_LEAFN_MAGIC:\n\t\t\tblk->magic = XFS_DIR2_LEAFN_MAGIC;\n\t\t\tASSERT(level == path->active-1);\n\t\t\tblk->index = 0;\n\t\t\tblk->hashval = xfs_dir2_leafn_lasthash(args->dp,\n\t\t\t\t\t\t\t       blk->bp, NULL);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tASSERT(0);\n\t\t\tbreak;\n\t\t}\n\t}\n\t*result = 0;\n\treturn 0;\n}\n\n\n/*========================================================================\n * Utility routines.\n *========================================================================*/\n\n/*\n * Implement a simple hash on a character string.\n * Rotate the hash value by 7 bits, then XOR each character in.\n * This is implemented with some source-level loop unrolling.\n */\nxfs_dahash_t\nxfs_da_hashname(const __uint8_t *name, int namelen)\n{\n\txfs_dahash_t hash;\n\n\t/*\n\t * Do four characters at a time as long as we can.\n\t */\n\tfor (hash = 0; namelen >= 4; namelen -= 4, name += 4)\n\t\thash = (name[0] << 21) ^ (name[1] << 14) ^ (name[2] << 7) ^\n\t\t       (name[3] << 0) ^ rol32(hash, 7 * 4);\n\n\t/*\n\t * Now do the rest of the characters.\n\t */\n\tswitch (namelen) {\n\tcase 3:\n\t\treturn (name[0] << 14) ^ (name[1] << 7) ^ (name[2] << 0) ^\n\t\t       rol32(hash, 7 * 3);\n\tcase 2:\n\t\treturn (name[0] << 7) ^ (name[1] << 0) ^ rol32(hash, 7 * 2);\n\tcase 1:\n\t\treturn (name[0] << 0) ^ rol32(hash, 7 * 1);\n\tdefault: /* case 0: */\n\t\treturn hash;\n\t}\n}\n\nenum xfs_dacmp\nxfs_da_compname(\n\tstruct xfs_da_args *args,\n\tconst unsigned char *name,\n\tint\t\tlen)\n{\n\treturn (args->namelen == len && memcmp(args->name, name, len) == 0) ?\n\t\t\t\t\tXFS_CMP_EXACT : XFS_CMP_DIFFERENT;\n}\n\nstatic xfs_dahash_t\nxfs_default_hashname(\n\tstruct xfs_name\t*name)\n{\n\treturn xfs_da_hashname(name->name, name->len);\n}\n\nconst struct xfs_nameops xfs_default_nameops = {\n\t.hashname\t= xfs_default_hashname,\n\t.compname\t= xfs_da_compname\n};\n\nint\nxfs_da_grow_inode_int(\n\tstruct xfs_da_args\t*args,\n\txfs_fileoff_t\t\t*bno,\n\tint\t\t\tcount)\n{\n\tstruct xfs_trans\t*tp = args->trans;\n\tstruct xfs_inode\t*dp = args->dp;\n\tint\t\t\tw = args->whichfork;\n\txfs_drfsbno_t\t\tnblks = dp->i_d.di_nblocks;\n\tstruct xfs_bmbt_irec\tmap, *mapp;\n\tint\t\t\tnmap, error, got, i, mapi;\n\n\t/*\n\t * Find a spot in the file space to put the new block.\n\t */\n\terror = xfs_bmap_first_unused(tp, dp, count, bno, w);\n\tif (error)\n\t\treturn error;\n\n\t/*\n\t * Try mapping it in one filesystem block.\n\t */\n\tnmap = 1;\n\tASSERT(args->firstblock != NULL);\n\terror = xfs_bmapi_write(tp, dp, *bno, count,\n\t\t\txfs_bmapi_aflag(w)|XFS_BMAPI_METADATA|XFS_BMAPI_CONTIG,\n\t\t\targs->firstblock, args->total, &map, &nmap,\n\t\t\targs->flist);\n\tif (error)\n\t\treturn error;\n\n\tASSERT(nmap <= 1);\n\tif (nmap == 1) {\n\t\tmapp = &map;\n\t\tmapi = 1;\n\t} else if (nmap == 0 && count > 1) {\n\t\txfs_fileoff_t\t\tb;\n\t\tint\t\t\tc;\n\n\t\t/*\n\t\t * If we didn't get it and the block might work if fragmented,\n\t\t * try without the CONTIG flag.  Loop until we get it all.\n\t\t */\n\t\tmapp = kmem_alloc(sizeof(*mapp) * count, KM_SLEEP);\n\t\tfor (b = *bno, mapi = 0; b < *bno + count; ) {\n\t\t\tnmap = MIN(XFS_BMAP_MAX_NMAP, count);\n\t\t\tc = (int)(*bno + count - b);\n\t\t\terror = xfs_bmapi_write(tp, dp, b, c,\n\t\t\t\t\txfs_bmapi_aflag(w)|XFS_BMAPI_METADATA,\n\t\t\t\t\targs->firstblock, args->total,\n\t\t\t\t\t&mapp[mapi], &nmap, args->flist);\n\t\t\tif (error)\n\t\t\t\tgoto out_free_map;\n\t\t\tif (nmap < 1)\n\t\t\t\tbreak;\n\t\t\tmapi += nmap;\n\t\t\tb = mapp[mapi - 1].br_startoff +\n\t\t\t    mapp[mapi - 1].br_blockcount;\n\t\t}\n\t} else {\n\t\tmapi = 0;\n\t\tmapp = NULL;\n\t}\n\n\t/*\n\t * Count the blocks we got, make sure it matches the total.\n\t */\n\tfor (i = 0, got = 0; i < mapi; i++)\n\t\tgot += mapp[i].br_blockcount;\n\tif (got != count || mapp[0].br_startoff != *bno ||\n\t    mapp[mapi - 1].br_startoff + mapp[mapi - 1].br_blockcount !=\n\t    *bno + count) {\n\t\terror = XFS_ERROR(ENOSPC);\n\t\tgoto out_free_map;\n\t}\n\n\t/* account for newly allocated blocks in reserved blocks total */\n\targs->total -= dp->i_d.di_nblocks - nblks;\n\nout_free_map:\n\tif (mapp != &map)\n\t\tkmem_free(mapp);\n\treturn error;\n}\n\n/*\n * Add a block to the btree ahead of the file.\n * Return the new block number to the caller.\n */\nint\nxfs_da_grow_inode(\n\tstruct xfs_da_args\t*args,\n\txfs_dablk_t\t\t*new_blkno)\n{\n\txfs_fileoff_t\t\tbno;\n\tint\t\t\tcount;\n\tint\t\t\terror;\n\n\ttrace_xfs_da_grow_inode(args);\n\n\tif (args->whichfork == XFS_DATA_FORK) {\n\t\tbno = args->dp->i_mount->m_dirleafblk;\n\t\tcount = args->dp->i_mount->m_dirblkfsbs;\n\t} else {\n\t\tbno = 0;\n\t\tcount = 1;\n\t}\n\n\terror = xfs_da_grow_inode_int(args, &bno, count);\n\tif (!error)\n\t\t*new_blkno = (xfs_dablk_t)bno;\n\treturn error;\n}\n\n/*\n * Ick.  We need to always be able to remove a btree block, even\n * if there's no space reservation because the filesystem is full.\n * This is called if xfs_bunmapi on a btree block fails due to ENOSPC.\n * It swaps the target block with the last block in the file.  The\n * last block in the file can always be removed since it can't cause\n * a bmap btree split to do that.\n */\nSTATIC int\nxfs_da3_swap_lastblock(\n\tstruct xfs_da_args\t*args,\n\txfs_dablk_t\t\t*dead_blknop,\n\tstruct xfs_buf\t\t**dead_bufp)\n{\n\tstruct xfs_da_blkinfo\t*dead_info;\n\tstruct xfs_da_blkinfo\t*sib_info;\n\tstruct xfs_da_intnode\t*par_node;\n\tstruct xfs_da_intnode\t*dead_node;\n\tstruct xfs_dir2_leaf\t*dead_leaf2;\n\tstruct xfs_da_node_entry *btree;\n\tstruct xfs_da3_icnode_hdr par_hdr;\n\tstruct xfs_inode\t*dp;\n\tstruct xfs_trans\t*tp;\n\tstruct xfs_mount\t*mp;\n\tstruct xfs_buf\t\t*dead_buf;\n\tstruct xfs_buf\t\t*last_buf;\n\tstruct xfs_buf\t\t*sib_buf;\n\tstruct xfs_buf\t\t*par_buf;\n\txfs_dahash_t\t\tdead_hash;\n\txfs_fileoff_t\t\tlastoff;\n\txfs_dablk_t\t\tdead_blkno;\n\txfs_dablk_t\t\tlast_blkno;\n\txfs_dablk_t\t\tsib_blkno;\n\txfs_dablk_t\t\tpar_blkno;\n\tint\t\t\terror;\n\tint\t\t\tw;\n\tint\t\t\tentno;\n\tint\t\t\tlevel;\n\tint\t\t\tdead_level;\n\n\ttrace_xfs_da_swap_lastblock(args);\n\n\tdead_buf = *dead_bufp;\n\tdead_blkno = *dead_blknop;\n\ttp = args->trans;\n\tdp = args->dp;\n\tw = args->whichfork;\n\tASSERT(w == XFS_DATA_FORK);\n\tmp = dp->i_mount;\n\tlastoff = mp->m_dirfreeblk;\n\terror = xfs_bmap_last_before(tp, dp, &lastoff, w);\n\tif (error)\n\t\treturn error;\n\tif (unlikely(lastoff == 0)) {\n\t\tXFS_ERROR_REPORT(\"xfs_da_swap_lastblock(1)\", XFS_ERRLEVEL_LOW,\n\t\t\t\t mp);\n\t\treturn XFS_ERROR(EFSCORRUPTED);\n\t}\n\t/*\n\t * Read the last block in the btree space.\n\t */\n\tlast_blkno = (xfs_dablk_t)lastoff - mp->m_dirblkfsbs;\n\terror = xfs_da3_node_read(tp, dp, last_blkno, -1, &last_buf, w);\n\tif (error)\n\t\treturn error;\n\t/*\n\t * Copy the last block into the dead buffer and log it.\n\t */\n\tmemcpy(dead_buf->b_addr, last_buf->b_addr, mp->m_dirblksize);\n\txfs_trans_log_buf(tp, dead_buf, 0, mp->m_dirblksize - 1);\n\tdead_info = dead_buf->b_addr;\n\t/*\n\t * Get values from the moved block.\n\t */\n\tif (dead_info->magic == cpu_to_be16(XFS_DIR2_LEAFN_MAGIC) ||\n\t    dead_info->magic == cpu_to_be16(XFS_DIR3_LEAFN_MAGIC)) {\n\t\tstruct xfs_dir3_icleaf_hdr leafhdr;\n\t\tstruct xfs_dir2_leaf_entry *ents;\n\n\t\tdead_leaf2 = (xfs_dir2_leaf_t *)dead_info;\n\t\tdp->d_ops->leaf_hdr_from_disk(&leafhdr, dead_leaf2);\n\t\tents = dp->d_ops->leaf_ents_p(dead_leaf2);\n\t\tdead_level = 0;\n\t\tdead_hash = be32_to_cpu(ents[leafhdr.count - 1].hashval);\n\t} else {\n\t\tstruct xfs_da3_icnode_hdr deadhdr;\n\n\t\tdead_node = (xfs_da_intnode_t *)dead_info;\n\t\tdp->d_ops->node_hdr_from_disk(&deadhdr, dead_node);\n\t\tbtree = dp->d_ops->node_tree_p(dead_node);\n\t\tdead_level = deadhdr.level;\n\t\tdead_hash = be32_to_cpu(btree[deadhdr.count - 1].hashval);\n\t}\n\tsib_buf = par_buf = NULL;\n\t/*\n\t * If the moved block has a left sibling, fix up the pointers.\n\t */\n\tif ((sib_blkno = be32_to_cpu(dead_info->back))) {\n\t\terror = xfs_da3_node_read(tp, dp, sib_blkno, -1, &sib_buf, w);\n\t\tif (error)\n\t\t\tgoto done;\n\t\tsib_info = sib_buf->b_addr;\n\t\tif (unlikely(\n\t\t    be32_to_cpu(sib_info->forw) != last_blkno ||\n\t\t    sib_info->magic != dead_info->magic)) {\n\t\t\tXFS_ERROR_REPORT(\"xfs_da_swap_lastblock(2)\",\n\t\t\t\t\t XFS_ERRLEVEL_LOW, mp);\n\t\t\terror = XFS_ERROR(EFSCORRUPTED);\n\t\t\tgoto done;\n\t\t}\n\t\tsib_info->forw = cpu_to_be32(dead_blkno);\n\t\txfs_trans_log_buf(tp, sib_buf,\n\t\t\tXFS_DA_LOGRANGE(sib_info, &sib_info->forw,\n\t\t\t\t\tsizeof(sib_info->forw)));\n\t\tsib_buf = NULL;\n\t}\n\t/*\n\t * If the moved block has a right sibling, fix up the pointers.\n\t */\n\tif ((sib_blkno = be32_to_cpu(dead_info->forw))) {\n\t\terror = xfs_da3_node_read(tp, dp, sib_blkno, -1, &sib_buf, w);\n\t\tif (error)\n\t\t\tgoto done;\n\t\tsib_info = sib_buf->b_addr;\n\t\tif (unlikely(\n\t\t       be32_to_cpu(sib_info->back) != last_blkno ||\n\t\t       sib_info->magic != dead_info->magic)) {\n\t\t\tXFS_ERROR_REPORT(\"xfs_da_swap_lastblock(3)\",\n\t\t\t\t\t XFS_ERRLEVEL_LOW, mp);\n\t\t\terror = XFS_ERROR(EFSCORRUPTED);\n\t\t\tgoto done;\n\t\t}\n\t\tsib_info->back = cpu_to_be32(dead_blkno);\n\t\txfs_trans_log_buf(tp, sib_buf,\n\t\t\tXFS_DA_LOGRANGE(sib_info, &sib_info->back,\n\t\t\t\t\tsizeof(sib_info->back)));\n\t\tsib_buf = NULL;\n\t}\n\tpar_blkno = mp->m_dirleafblk;\n\tlevel = -1;\n\t/*\n\t * Walk down the tree looking for the parent of the moved block.\n\t */\n\tfor (;;) {\n\t\terror = xfs_da3_node_read(tp, dp, par_blkno, -1, &par_buf, w);\n\t\tif (error)\n\t\t\tgoto done;\n\t\tpar_node = par_buf->b_addr;\n\t\tdp->d_ops->node_hdr_from_disk(&par_hdr, par_node);\n\t\tif (level >= 0 && level != par_hdr.level + 1) {\n\t\t\tXFS_ERROR_REPORT(\"xfs_da_swap_lastblock(4)\",\n\t\t\t\t\t XFS_ERRLEVEL_LOW, mp);\n\t\t\terror = XFS_ERROR(EFSCORRUPTED);\n\t\t\tgoto done;\n\t\t}\n\t\tlevel = par_hdr.level;\n\t\tbtree = dp->d_ops->node_tree_p(par_node);\n\t\tfor (entno = 0;\n\t\t     entno < par_hdr.count &&\n\t\t     be32_to_cpu(btree[entno].hashval) < dead_hash;\n\t\t     entno++)\n\t\t\tcontinue;\n\t\tif (entno == par_hdr.count) {\n\t\t\tXFS_ERROR_REPORT(\"xfs_da_swap_lastblock(5)\",\n\t\t\t\t\t XFS_ERRLEVEL_LOW, mp);\n\t\t\terror = XFS_ERROR(EFSCORRUPTED);\n\t\t\tgoto done;\n\t\t}\n\t\tpar_blkno = be32_to_cpu(btree[entno].before);\n\t\tif (level == dead_level + 1)\n\t\t\tbreak;\n\t\txfs_trans_brelse(tp, par_buf);\n\t\tpar_buf = NULL;\n\t}\n\t/*\n\t * We're in the right parent block.\n\t * Look for the right entry.\n\t */\n\tfor (;;) {\n\t\tfor (;\n\t\t     entno < par_hdr.count &&\n\t\t     be32_to_cpu(btree[entno].before) != last_blkno;\n\t\t     entno++)\n\t\t\tcontinue;\n\t\tif (entno < par_hdr.count)\n\t\t\tbreak;\n\t\tpar_blkno = par_hdr.forw;\n\t\txfs_trans_brelse(tp, par_buf);\n\t\tpar_buf = NULL;\n\t\tif (unlikely(par_blkno == 0)) {\n\t\t\tXFS_ERROR_REPORT(\"xfs_da_swap_lastblock(6)\",\n\t\t\t\t\t XFS_ERRLEVEL_LOW, mp);\n\t\t\terror = XFS_ERROR(EFSCORRUPTED);\n\t\t\tgoto done;\n\t\t}\n\t\terror = xfs_da3_node_read(tp, dp, par_blkno, -1, &par_buf, w);\n\t\tif (error)\n\t\t\tgoto done;\n\t\tpar_node = par_buf->b_addr;\n\t\tdp->d_ops->node_hdr_from_disk(&par_hdr, par_node);\n\t\tif (par_hdr.level != level) {\n\t\t\tXFS_ERROR_REPORT(\"xfs_da_swap_lastblock(7)\",\n\t\t\t\t\t XFS_ERRLEVEL_LOW, mp);\n\t\t\terror = XFS_ERROR(EFSCORRUPTED);\n\t\t\tgoto done;\n\t\t}\n\t\tbtree = dp->d_ops->node_tree_p(par_node);\n\t\tentno = 0;\n\t}\n\t/*\n\t * Update the parent entry pointing to the moved block.\n\t */\n\tbtree[entno].before = cpu_to_be32(dead_blkno);\n\txfs_trans_log_buf(tp, par_buf,\n\t\tXFS_DA_LOGRANGE(par_node, &btree[entno].before,\n\t\t\t\tsizeof(btree[entno].before)));\n\t*dead_blknop = last_blkno;\n\t*dead_bufp = last_buf;\n\treturn 0;\ndone:\n\tif (par_buf)\n\t\txfs_trans_brelse(tp, par_buf);\n\tif (sib_buf)\n\t\txfs_trans_brelse(tp, sib_buf);\n\txfs_trans_brelse(tp, last_buf);\n\treturn error;\n}\n\n/*\n * Remove a btree block from a directory or attribute.\n */\nint\nxfs_da_shrink_inode(\n\txfs_da_args_t\t*args,\n\txfs_dablk_t\tdead_blkno,\n\tstruct xfs_buf\t*dead_buf)\n{\n\txfs_inode_t *dp;\n\tint done, error, w, count;\n\txfs_trans_t *tp;\n\txfs_mount_t *mp;\n\n\ttrace_xfs_da_shrink_inode(args);\n\n\tdp = args->dp;\n\tw = args->whichfork;\n\ttp = args->trans;\n\tmp = dp->i_mount;\n\tif (w == XFS_DATA_FORK)\n\t\tcount = mp->m_dirblkfsbs;\n\telse\n\t\tcount = 1;\n\tfor (;;) {\n\t\t/*\n\t\t * Remove extents.  If we get ENOSPC for a dir we have to move\n\t\t * the last block to the place we want to kill.\n\t\t */\n\t\terror = xfs_bunmapi(tp, dp, dead_blkno, count,\n\t\t\t\t    xfs_bmapi_aflag(w)|XFS_BMAPI_METADATA,\n\t\t\t\t    0, args->firstblock, args->flist, &done);\n\t\tif (error == ENOSPC) {\n\t\t\tif (w != XFS_DATA_FORK)\n\t\t\t\tbreak;\n\t\t\terror = xfs_da3_swap_lastblock(args, &dead_blkno,\n\t\t\t\t\t\t      &dead_buf);\n\t\t\tif (error)\n\t\t\t\tbreak;\n\t\t} else {\n\t\t\tbreak;\n\t\t}\n\t}\n\txfs_trans_binval(tp, dead_buf);\n\treturn error;\n}\n\n/*\n * See if the mapping(s) for this btree block are valid, i.e.\n * don't contain holes, are logically contiguous, and cover the whole range.\n */\nSTATIC int\nxfs_da_map_covers_blocks(\n\tint\t\tnmap,\n\txfs_bmbt_irec_t\t*mapp,\n\txfs_dablk_t\tbno,\n\tint\t\tcount)\n{\n\tint\t\ti;\n\txfs_fileoff_t\toff;\n\n\tfor (i = 0, off = bno; i < nmap; i++) {\n\t\tif (mapp[i].br_startblock == HOLESTARTBLOCK ||\n\t\t    mapp[i].br_startblock == DELAYSTARTBLOCK) {\n\t\t\treturn 0;\n\t\t}\n\t\tif (off != mapp[i].br_startoff) {\n\t\t\treturn 0;\n\t\t}\n\t\toff += mapp[i].br_blockcount;\n\t}\n\treturn off == bno + count;\n}\n\n/*\n * Convert a struct xfs_bmbt_irec to a struct xfs_buf_map.\n *\n * For the single map case, it is assumed that the caller has provided a pointer\n * to a valid xfs_buf_map.  For the multiple map case, this function will\n * allocate the xfs_buf_map to hold all the maps and replace the caller's single\n * map pointer with the allocated map.\n */\nstatic int\nxfs_buf_map_from_irec(\n\tstruct xfs_mount\t*mp,\n\tstruct xfs_buf_map\t**mapp,\n\tint\t\t\t*nmaps,\n\tstruct xfs_bmbt_irec\t*irecs,\n\tint\t\t\tnirecs)\n{\n\tstruct xfs_buf_map\t*map;\n\tint\t\t\ti;\n\n\tASSERT(*nmaps == 1);\n\tASSERT(nirecs >= 1);\n\n\tif (nirecs > 1) {\n\t\tmap = kmem_zalloc(nirecs * sizeof(struct xfs_buf_map),\n\t\t\t\t  KM_SLEEP | KM_NOFS);\n\t\tif (!map)\n\t\t\treturn ENOMEM;\n\t\t*mapp = map;\n\t}\n\n\t*nmaps = nirecs;\n\tmap = *mapp;\n\tfor (i = 0; i < *nmaps; i++) {\n\t\tASSERT(irecs[i].br_startblock != DELAYSTARTBLOCK &&\n\t\t       irecs[i].br_startblock != HOLESTARTBLOCK);\n\t\tmap[i].bm_bn = XFS_FSB_TO_DADDR(mp, irecs[i].br_startblock);\n\t\tmap[i].bm_len = XFS_FSB_TO_BB(mp, irecs[i].br_blockcount);\n\t}\n\treturn 0;\n}\n\n/*\n * Map the block we are given ready for reading. There are three possible return\n * values:\n *\t-1 - will be returned if we land in a hole and mappedbno == -2 so the\n *\t     caller knows not to execute a subsequent read.\n *\t 0 - if we mapped the block successfully\n *\t>0 - positive error number if there was an error.\n */\nstatic int\nxfs_dabuf_map(\n\tstruct xfs_trans\t*trans,\n\tstruct xfs_inode\t*dp,\n\txfs_dablk_t\t\tbno,\n\txfs_daddr_t\t\tmappedbno,\n\tint\t\t\twhichfork,\n\tstruct xfs_buf_map\t**map,\n\tint\t\t\t*nmaps)\n{\n\tstruct xfs_mount\t*mp = dp->i_mount;\n\tint\t\t\tnfsb;\n\tint\t\t\terror = 0;\n\tstruct xfs_bmbt_irec\tirec;\n\tstruct xfs_bmbt_irec\t*irecs = &irec;\n\tint\t\t\tnirecs;\n\n\tASSERT(map && *map);\n\tASSERT(*nmaps == 1);\n\n\tnfsb = (whichfork == XFS_DATA_FORK) ? mp->m_dirblkfsbs : 1;\n\n\t/*\n\t * Caller doesn't have a mapping.  -2 means don't complain\n\t * if we land in a hole.\n\t */\n\tif (mappedbno == -1 || mappedbno == -2) {\n\t\t/*\n\t\t * Optimize the one-block case.\n\t\t */\n\t\tif (nfsb != 1)\n\t\t\tirecs = kmem_zalloc(sizeof(irec) * nfsb,\n\t\t\t\t\t    KM_SLEEP | KM_NOFS);\n\n\t\tnirecs = nfsb;\n\t\terror = xfs_bmapi_read(dp, (xfs_fileoff_t)bno, nfsb, irecs,\n\t\t\t\t       &nirecs, xfs_bmapi_aflag(whichfork));\n\t\tif (error)\n\t\t\tgoto out;\n\t} else {\n\t\tirecs->br_startblock = XFS_DADDR_TO_FSB(mp, mappedbno);\n\t\tirecs->br_startoff = (xfs_fileoff_t)bno;\n\t\tirecs->br_blockcount = nfsb;\n\t\tirecs->br_state = 0;\n\t\tnirecs = 1;\n\t}\n\n\tif (!xfs_da_map_covers_blocks(nirecs, irecs, bno, nfsb)) {\n\t\terror = mappedbno == -2 ? -1 : XFS_ERROR(EFSCORRUPTED);\n\t\tif (unlikely(error == EFSCORRUPTED)) {\n\t\t\tif (xfs_error_level >= XFS_ERRLEVEL_LOW) {\n\t\t\t\tint i;\n\t\t\t\txfs_alert(mp, \"%s: bno %lld dir: inode %lld\",\n\t\t\t\t\t__func__, (long long)bno,\n\t\t\t\t\t(long long)dp->i_ino);\n\t\t\t\tfor (i = 0; i < *nmaps; i++) {\n\t\t\t\t\txfs_alert(mp,\n\"[%02d] br_startoff %lld br_startblock %lld br_blockcount %lld br_state %d\",\n\t\t\t\t\t\ti,\n\t\t\t\t\t\t(long long)irecs[i].br_startoff,\n\t\t\t\t\t\t(long long)irecs[i].br_startblock,\n\t\t\t\t\t\t(long long)irecs[i].br_blockcount,\n\t\t\t\t\t\tirecs[i].br_state);\n\t\t\t\t}\n\t\t\t}\n\t\t\tXFS_ERROR_REPORT(\"xfs_da_do_buf(1)\",\n\t\t\t\t\t XFS_ERRLEVEL_LOW, mp);\n\t\t}\n\t\tgoto out;\n\t}\n\terror = xfs_buf_map_from_irec(mp, map, nmaps, irecs, nirecs);\nout:\n\tif (irecs != &irec)\n\t\tkmem_free(irecs);\n\treturn error;\n}\n\n/*\n * Get a buffer for the dir/attr block.\n */\nint\nxfs_da_get_buf(\n\tstruct xfs_trans\t*trans,\n\tstruct xfs_inode\t*dp,\n\txfs_dablk_t\t\tbno,\n\txfs_daddr_t\t\tmappedbno,\n\tstruct xfs_buf\t\t**bpp,\n\tint\t\t\twhichfork)\n{\n\tstruct xfs_buf\t\t*bp;\n\tstruct xfs_buf_map\tmap;\n\tstruct xfs_buf_map\t*mapp;\n\tint\t\t\tnmap;\n\tint\t\t\terror;\n\n\t*bpp = NULL;\n\tmapp = &map;\n\tnmap = 1;\n\terror = xfs_dabuf_map(trans, dp, bno, mappedbno, whichfork,\n\t\t\t\t&mapp, &nmap);\n\tif (error) {\n\t\t/* mapping a hole is not an error, but we don't continue */\n\t\tif (error == -1)\n\t\t\terror = 0;\n\t\tgoto out_free;\n\t}\n\n\tbp = xfs_trans_get_buf_map(trans, dp->i_mount->m_ddev_targp,\n\t\t\t\t    mapp, nmap, 0);\n\terror = bp ? bp->b_error : XFS_ERROR(EIO);\n\tif (error) {\n\t\txfs_trans_brelse(trans, bp);\n\t\tgoto out_free;\n\t}\n\n\t*bpp = bp;\n\nout_free:\n\tif (mapp != &map)\n\t\tkmem_free(mapp);\n\n\treturn error;\n}\n\n/*\n * Get a buffer for the dir/attr block, fill in the contents.\n */\nint\nxfs_da_read_buf(\n\tstruct xfs_trans\t*trans,\n\tstruct xfs_inode\t*dp,\n\txfs_dablk_t\t\tbno,\n\txfs_daddr_t\t\tmappedbno,\n\tstruct xfs_buf\t\t**bpp,\n\tint\t\t\twhichfork,\n\tconst struct xfs_buf_ops *ops)\n{\n\tstruct xfs_buf\t\t*bp;\n\tstruct xfs_buf_map\tmap;\n\tstruct xfs_buf_map\t*mapp;\n\tint\t\t\tnmap;\n\tint\t\t\terror;\n\n\t*bpp = NULL;\n\tmapp = &map;\n\tnmap = 1;\n\terror = xfs_dabuf_map(trans, dp, bno, mappedbno, whichfork,\n\t\t\t\t&mapp, &nmap);\n\tif (error) {\n\t\t/* mapping a hole is not an error, but we don't continue */\n\t\tif (error == -1)\n\t\t\terror = 0;\n\t\tgoto out_free;\n\t}\n\n\terror = xfs_trans_read_buf_map(dp->i_mount, trans,\n\t\t\t\t\tdp->i_mount->m_ddev_targp,\n\t\t\t\t\tmapp, nmap, 0, &bp, ops);\n\tif (error)\n\t\tgoto out_free;\n\n\tif (whichfork == XFS_ATTR_FORK)\n\t\txfs_buf_set_ref(bp, XFS_ATTR_BTREE_REF);\n\telse\n\t\txfs_buf_set_ref(bp, XFS_DIR_BTREE_REF);\n\n\t/*\n\t * This verification code will be moved to a CRC verification callback\n\t * function so just leave it here unchanged until then.\n\t */\n\t{\n\t\txfs_dir2_data_hdr_t\t*hdr = bp->b_addr;\n\t\txfs_dir2_free_t\t\t*free = bp->b_addr;\n\t\txfs_da_blkinfo_t\t*info = bp->b_addr;\n\t\tuint\t\t\tmagic, magic1;\n\t\tstruct xfs_mount\t*mp = dp->i_mount;\n\n\t\tmagic = be16_to_cpu(info->magic);\n\t\tmagic1 = be32_to_cpu(hdr->magic);\n\t\tif (unlikely(\n\t\t    XFS_TEST_ERROR((magic != XFS_DA_NODE_MAGIC) &&\n\t\t\t\t   (magic != XFS_DA3_NODE_MAGIC) &&\n\t\t\t\t   (magic != XFS_ATTR_LEAF_MAGIC) &&\n\t\t\t\t   (magic != XFS_ATTR3_LEAF_MAGIC) &&\n\t\t\t\t   (magic != XFS_DIR2_LEAF1_MAGIC) &&\n\t\t\t\t   (magic != XFS_DIR3_LEAF1_MAGIC) &&\n\t\t\t\t   (magic != XFS_DIR2_LEAFN_MAGIC) &&\n\t\t\t\t   (magic != XFS_DIR3_LEAFN_MAGIC) &&\n\t\t\t\t   (magic1 != XFS_DIR2_BLOCK_MAGIC) &&\n\t\t\t\t   (magic1 != XFS_DIR3_BLOCK_MAGIC) &&\n\t\t\t\t   (magic1 != XFS_DIR2_DATA_MAGIC) &&\n\t\t\t\t   (magic1 != XFS_DIR3_DATA_MAGIC) &&\n\t\t\t\t   (free->hdr.magic !=\n\t\t\t\t\tcpu_to_be32(XFS_DIR2_FREE_MAGIC)) &&\n\t\t\t\t   (free->hdr.magic !=\n\t\t\t\t\tcpu_to_be32(XFS_DIR3_FREE_MAGIC)),\n\t\t\t\tmp, XFS_ERRTAG_DA_READ_BUF,\n\t\t\t\tXFS_RANDOM_DA_READ_BUF))) {\n\t\t\ttrace_xfs_da_btree_corrupt(bp, _RET_IP_);\n\t\t\tXFS_CORRUPTION_ERROR(\"xfs_da_do_buf(2)\",\n\t\t\t\t\t     XFS_ERRLEVEL_LOW, mp, info);\n\t\t\terror = XFS_ERROR(EFSCORRUPTED);\n\t\t\txfs_trans_brelse(trans, bp);\n\t\t\tgoto out_free;\n\t\t}\n\t}\n\t*bpp = bp;\nout_free:\n\tif (mapp != &map)\n\t\tkmem_free(mapp);\n\n\treturn error;\n}\n\n/*\n * Readahead the dir/attr block.\n */\nxfs_daddr_t\nxfs_da_reada_buf(\n\tstruct xfs_trans\t*trans,\n\tstruct xfs_inode\t*dp,\n\txfs_dablk_t\t\tbno,\n\txfs_daddr_t\t\tmappedbno,\n\tint\t\t\twhichfork,\n\tconst struct xfs_buf_ops *ops)\n{\n\tstruct xfs_buf_map\tmap;\n\tstruct xfs_buf_map\t*mapp;\n\tint\t\t\tnmap;\n\tint\t\t\terror;\n\n\tmapp = &map;\n\tnmap = 1;\n\terror = xfs_dabuf_map(trans, dp, bno, mappedbno, whichfork,\n\t\t\t\t&mapp, &nmap);\n\tif (error) {\n\t\t/* mapping a hole is not an error, but we don't continue */\n\t\tif (error == -1)\n\t\t\terror = 0;\n\t\tgoto out_free;\n\t}\n\n\tmappedbno = mapp[0].bm_bn;\n\txfs_buf_readahead_map(dp->i_mount->m_ddev_targp, mapp, nmap, ops);\n\nout_free:\n\tif (mapp != &map)\n\t\tkmem_free(mapp);\n\n\tif (error)\n\t\treturn -1;\n\treturn mappedbno;\n}\n"], "filenames": ["fs/xfs/xfs_da_btree.c"], "buggy_code_start_loc": [1298], "buggy_code_end_loc": [1299], "fixing_code_start_loc": [1298], "fixing_code_end_loc": [1299], "type": "CWE-399", "message": "The xfs_da3_fixhashpath function in fs/xfs/xfs_da_btree.c in the xfs implementation in the Linux kernel before 3.14.2 does not properly compare btree hash values, which allows local users to cause a denial of service (filesystem corruption, and OOPS or panic) via operations on directories that have hash collisions, as demonstrated by rmdir operations.", "other": {"cve": {"id": "CVE-2014-7283", "sourceIdentifier": "cve@mitre.org", "published": "2014-10-13T10:55:08.013", "lastModified": "2020-08-06T15:11:18.063", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "The xfs_da3_fixhashpath function in fs/xfs/xfs_da_btree.c in the xfs implementation in the Linux kernel before 3.14.2 does not properly compare btree hash values, which allows local users to cause a denial of service (filesystem corruption, and OOPS or panic) via operations on directories that have hash collisions, as demonstrated by rmdir operations."}, {"lang": "es", "value": "La funci\u00f3n xfs_da3_fixhashpath en fs/xfs/xfs_da_btree.c en la implementaci\u00f3n xfs en el kernel de Linux anterior a 3.14.2 no compara debidamente los valores de hashes btree, lo que permite a usuarios locales causar una denegaci\u00f3n de servicio (corrupci\u00f3n del sistema de ficheros y OOPS o p\u00e1nico) a trav\u00e9s de operaciones sobre directorios que tienen colisiones de hashes, tal y como fue demostrado por operaciones rmdir."}], "metrics": {"cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:N/I:N/A:C", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "COMPLETE", "baseScore": 4.9}, "baseSeverity": "MEDIUM", "exploitabilityScore": 3.9, "impactScore": 6.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-399"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndExcluding": "3.14.2", "matchCriteriaId": "C27D50E1-62A9-4D9A-ABBE-39072238A67B"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:redhat:mrg_realtime:2.0:*:*:*:*:*:*:*", "matchCriteriaId": "AFB0FFE3-4BE1-4024-BCC6-1B87074DE2E3"}]}]}], "references": [{"url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commit;h=c88547a8119e3b581318ab65e9b72f27f23e641d", "source": "cve@mitre.org", "tags": ["Exploit", "Patch", "Vendor Advisory"]}, {"url": "http://marc.info/?l=linux-xfs&m=139590613002926&w=2", "source": "cve@mitre.org", "tags": ["Exploit", "Third Party Advisory"]}, {"url": "http://rhn.redhat.com/errata/RHSA-2014-1943.html", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "http://www.kernel.org/pub/linux/kernel/v3.x/ChangeLog-3.14.2", "source": "cve@mitre.org", "tags": ["Release Notes", "Vendor Advisory"]}, {"url": "http://www.openwall.com/lists/oss-security/2014/10/01/29", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://www.securityfocus.com/bid/70261", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://bugzilla.redhat.com/show_bug.cgi?id=1148777", "source": "cve@mitre.org", "tags": ["Exploit", "Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/c88547a8119e3b581318ab65e9b72f27f23e641d", "source": "cve@mitre.org", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/c88547a8119e3b581318ab65e9b72f27f23e641d"}}
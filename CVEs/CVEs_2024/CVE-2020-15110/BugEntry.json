{"buggy_code": ["\"\"\"\nJupyterHub Spawner to spawn user notebooks on a Kubernetes cluster.\n\nThis module exports `KubeSpawner` class, which is the actual spawner\nimplementation that should be used by JupyterHub.\n\"\"\"\n\nfrom functools import partial  # noqa\nfrom datetime import datetime\nimport json\nimport os\nimport sys\nimport string\nimport multiprocessing\nfrom concurrent.futures import ThreadPoolExecutor\nimport warnings\n\nfrom tornado import gen\nfrom tornado.ioloop import IOLoop\nfrom tornado.concurrent import run_on_executor\nfrom tornado import web\nfrom traitlets import (\n    Bool,\n    Dict,\n    Integer,\n    List,\n    Unicode,\n    Union,\n    default,\n    observe,\n    validate,\n)\nfrom jupyterhub.spawner import Spawner\nfrom jupyterhub.utils import exponential_backoff\nfrom jupyterhub.traitlets import Command\nfrom kubernetes.client.rest import ApiException\nfrom kubernetes import client\nimport escapism\nfrom jinja2 import Environment, BaseLoader\n\nfrom .clients import shared_client\nfrom kubespawner.traitlets import Callable\nfrom kubespawner.objects import make_pod, make_pvc\nfrom kubespawner.reflector import NamespacedResourceReflector\nfrom asyncio import sleep\nfrom async_generator import async_generator, yield_\nfrom slugify import slugify\n\nclass PodReflector(NamespacedResourceReflector):\n    \"\"\"\n    PodReflector is merely a configured NamespacedResourceReflector. It exposes\n    the pods property, which is simply mapping to self.resources where the\n    NamespacedResourceReflector keeps an updated list of the resource defined by\n    the `kind` field and the `list_method_name` field.\n    \"\"\"\n    kind = 'pods'\n    list_method_name = 'list_namespaced_pod'\n    # FUTURE: These labels are the selection labels for the PodReflector. We\n    # might want to support multiple deployments in the same namespace, so we\n    # would need to select based on additional labels such as `app` and\n    # `release`.\n    labels = {\n        'component': 'singleuser-server',\n    }\n\n    @property\n    def pods(self):\n        \"\"\"\n        A dictionary of the python kubernetes client's representation of pods\n        for the namespace. The dictionary keys are the pod ids and the values\n        are the actual pod resource representations.\n\n        ref: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.16/#pod-v1-core\n        \"\"\"\n        return self.resources\n\n\nclass EventReflector(NamespacedResourceReflector):\n    \"\"\"\n    EventsReflector is merely a configured NamespacedResourceReflector. It\n    exposes the events property, which is simply mapping to self.resources where\n    the NamespacedResourceReflector keeps an updated list of the resource\n    defined by the `kind` field and the `list_method_name` field.\n    \"\"\"\n    kind = 'events'\n    list_method_name = 'list_namespaced_event'\n\n    @property\n    def events(self):\n        \"\"\"\n        Returns list of the python kubernetes client's representation of k8s\n        events within the namespace, sorted by the latest event.\n\n        ref: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.16/#event-v1-core\n        \"\"\"\n\n        # NOTE:\n        # - self.resources is a dictionary with keys mapping unique ids of\n        #   Kubernetes Event resources, updated by NamespacedResourceReflector.\n        #   self.resources will builds up with incoming k8s events, but can also\n        #   suddenly refreshes itself entirely. We should not assume a call to\n        #   this dictionary's values will result in a consistently ordered list,\n        #   so we sort it to get it somewhat more structured.\n        # - We either seem to get only event.last_timestamp or event.event_time,\n        #   both fields serve the same role but the former is a low resolution\n        #   timestamp without and the other is a higher resolution timestamp.\n        return sorted(\n            self.resources.values(),\n            key=lambda event: event.last_timestamp or event.event_time,\n        )\n\n\nclass MockObject(object):\n    pass\n\nclass KubeSpawner(Spawner):\n    \"\"\"\n    A JupyterHub spawner that spawn pods in a Kubernetes Cluster. Each server\n    spawned by a user will have its own KubeSpawner instance.\n    \"\"\"\n\n    # We want to have one single threadpool executor that is shared across all\n    # KubeSpawner instances, so we apply a Singleton pattern. We initialize this\n    # class variable from the first KubeSpawner instance that is created and\n    # then reference it from all instances. The same goes for the PodReflector\n    # and EventReflector.\n    executor = None\n    reflectors = {\n        \"pods\": None,\n        \"events\": None,\n    }\n\n    @property\n    def pod_reflector(self):\n        \"\"\"\n        A convinience alias to the class variable reflectors['pods'].\n        \"\"\"\n        return self.__class__.reflectors['pods']\n\n    @property\n    def event_reflector(self):\n        \"\"\"\n        A convninience alias to the class variable reflectors['events'] if the\n        spawner instance has events_enabled.\n        \"\"\"\n        if self.events_enabled:\n            return self.__class__.reflectors['events']\n\n    def __init__(self, *args, **kwargs):\n        _mock = kwargs.pop('_mock', False)\n        super().__init__(*args, **kwargs)\n\n        if _mock:\n            # runs during test execution only\n            if 'user' not in kwargs:\n                user = MockObject()\n                user.name = 'mock_name'\n                user.id = 'mock_id'\n                user.url = 'mock_url'\n                self.user = user\n\n            if 'hub' not in kwargs:\n                hub = MockObject()\n                hub.public_host = 'mock_public_host'\n                hub.url = 'mock_url'\n                hub.base_url = 'mock_base_url'\n                hub.api_url = 'mock_api_url'\n                self.hub = hub\n        else:\n            # runs during normal execution only\n\n            # By now, all the traitlets have been set, so we can use them to compute\n            # other attributes\n            if self.__class__.executor is None:\n                self.__class__.executor = ThreadPoolExecutor(\n                    max_workers=self.k8s_api_threadpool_workers\n                )\n\n            # This will start watching in __init__, so it'll start the first\n            # time any spawner object is created. Not ideal but works!\n            self._start_watching_pods()\n            if self.events_enabled:\n                self._start_watching_events()\n\n            self.api = shared_client('CoreV1Api')\n\n        # runs during both test and normal execution\n        self.pod_name = self._expand_user_properties(self.pod_name_template)\n        self.pvc_name = self._expand_user_properties(self.pvc_name_template)\n        if self.working_dir:\n            self.working_dir = self._expand_user_properties(self.working_dir)\n        if self.port == 0:\n            # Our default port is 8888\n            self.port = 8888\n\n    k8s_api_threadpool_workers = Integer(\n        # Set this explicitly, since this is the default in Python 3.5+\n        # but not in 3.4\n        5 * multiprocessing.cpu_count(),\n        config=True,\n        help=\"\"\"\n        Number of threads in thread pool used to talk to the k8s API.\n\n        Increase this if you are dealing with a very large number of users.\n\n        Defaults to `5 * cpu_cores`, which is the default for `ThreadPoolExecutor`.\n        \"\"\"\n    )\n\n    events_enabled = Bool(\n        True,\n        config=True,\n        help=\"\"\"\n        Enable event-watching for progress-reports to the user spawn page.\n\n        Disable if these events are not desirable\n        or to save some performance cost.\n        \"\"\"\n    )\n\n    namespace = Unicode(\n        config=True,\n        help=\"\"\"\n        Kubernetes namespace to spawn user pods in.\n\n        If running inside a kubernetes cluster with service accounts enabled,\n        defaults to the current namespace. If not, defaults to `default`\n        \"\"\"\n    )\n\n    @default('namespace')\n    def _namespace_default(self):\n        \"\"\"\n        Set namespace default to current namespace if running in a k8s cluster\n\n        If not in a k8s cluster with service accounts enabled, default to\n        `default`\n        \"\"\"\n        ns_path = '/var/run/secrets/kubernetes.io/serviceaccount/namespace'\n        if os.path.exists(ns_path):\n            with open(ns_path) as f:\n                return f.read().strip()\n        return 'default'\n\n    ip = Unicode(\n        '0.0.0.0',\n        config=True,\n        help=\"\"\"\n        The IP address (or hostname) the single-user server should listen on.\n\n        We override this from the parent so we can set a more sane default for\n        the Kubernetes setup.\n        \"\"\"\n    )\n\n    cmd = Command(\n        None,\n        allow_none=True,\n        minlen=0,\n        config=True,\n        help=\"\"\"\n        The command used for starting the single-user server.\n\n        Provide either a string or a list containing the path to the startup script command. Extra arguments,\n        other than this path, should be provided via `args`.\n\n        This is usually set if you want to start the single-user server in a different python\n        environment (with virtualenv/conda) than JupyterHub itself.\n\n        Some spawners allow shell-style expansion here, allowing you to use environment variables.\n        Most, including the default, do not. Consult the documentation for your spawner to verify!\n\n        If set to `None`, Kubernetes will start the `CMD` that is specified in the Docker image being started.\n        \"\"\"\n    )\n\n    # FIXME: Don't override 'default_value' (\"\") or 'allow_none' (False) (Breaking change)\n    working_dir = Unicode(\n        None,\n        allow_none=True,\n        config=True,\n        help=\"\"\"\n        The working directory where the Notebook server will be started inside the container.\n        Defaults to `None` so the working directory will be the one defined in the Dockerfile.\n\n        `{username}` is expanded to the escaped, dns-label safe username.\n        \"\"\"\n    )\n\n    # FIXME: Don't override 'default_value' (\"\") or 'allow_none' (False) (Breaking change)\n    service_account = Unicode(\n        None,\n        allow_none=True,\n        config=True,\n        help=\"\"\"\n        The service account to be mounted in the spawned user pod.\n\n        When set to `None` (the default), no service account is mounted, and the default service account\n        is explicitly disabled.\n\n        This `serviceaccount` must already exist in the namespace the user pod is being spawned in.\n\n        WARNING: Be careful with this configuration! Make sure the service account being mounted\n        has the minimal permissions needed, and nothing more. When misconfigured, this can easily\n        give arbitrary users root over your entire cluster.\n        \"\"\"\n    )\n\n    pod_name_template = Unicode(\n        'jupyter-{username}{servername}',\n        config=True,\n        help=\"\"\"\n        Template to use to form the name of user's pods.\n\n        `{username}` is expanded to the escaped, dns-label safe username.\n\n        This must be unique within the namespace the pods are being spawned\n        in, so if you are running multiple jupyterhubs spawning in the\n        same namespace, consider setting this to be something more unique.\n        \"\"\"\n    )\n\n    storage_pvc_ensure = Bool(\n        False,\n        config=True,\n        help=\"\"\"\n        Ensure that a PVC exists for each user before spawning.\n\n        Set to true to create a PVC named with `pvc_name_template` if it does\n        not exist for the user when their pod is spawning.\n        \"\"\"\n    )\n\n    pvc_name_template = Unicode(\n        'claim-{username}{servername}',\n        config=True,\n        help=\"\"\"\n        Template to use to form the name of user's pvc.\n\n        `{username}` is expanded to the escaped, dns-label safe username.\n\n        This must be unique within the namespace the pvc are being spawned\n        in, so if you are running multiple jupyterhubs spawning in the\n        same namespace, consider setting this to be something more unique.\n        \"\"\"\n    )\n\n    # FIXME: Don't override 'default_value' (\"\") or 'allow_none' (False) (Breaking change)\n    hub_connect_ip = Unicode(\n        allow_none=True,\n        config=True,\n        help=\"\"\"DEPRECATED. Use c.JupyterHub.hub_connect_ip\"\"\"\n    )\n\n    hub_connect_port = Integer(\n        config=True,\n        help=\"\"\"DEPRECATED. Use c.JupyterHub.hub_connect_url\"\"\"\n    )\n\n    @observe('hub_connect_ip', 'hub_connect_port')\n    def _deprecated_changed(self, change):\n        warnings.warn(\"\"\"\n            KubeSpawner.{0} is deprecated with JupyterHub >= 0.8.\n            Use JupyterHub.{0}\n            \"\"\".format(change.name),\n            DeprecationWarning)\n        setattr(self.hub, change.name.split('_', 1)[1], change.new)\n\n    common_labels = Dict(\n        {\n            'app': 'jupyterhub',\n            'heritage': 'jupyterhub',\n        },\n        config=True,\n        help=\"\"\"\n        Kubernetes labels that both spawned singleuser server pods and created\n        user PVCs will get.\n\n        Note that these are only set when the Pods and PVCs are created, not\n        later when this setting is updated.\n        \"\"\"\n    )\n\n    extra_labels = Dict(\n        config=True,\n        help=\"\"\"\n        Extra kubernetes labels to set on the spawned single-user pods.\n\n        The keys and values specified here would be set as labels on the spawned single-user\n        kubernetes pods. The keys and values must both be strings that match the kubernetes\n        label key / value constraints.\n\n        See `the Kubernetes documentation <https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/>`__\n        for more info on what labels are and why you might want to use them!\n\n        `{username}` is expanded to the escaped, dns-label safe username.\n        \"\"\"\n    )\n\n    extra_annotations = Dict(\n        config=True,\n        help=\"\"\"\n        Extra Kubernetes annotations to set on the spawned single-user pods.\n\n        The keys and values specified here are added as annotations on the spawned single-user\n        kubernetes pods. The keys and values must both be strings.\n\n        See `the Kubernetes documentation <https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/>`__\n        for more info on what annotations are and why you might want to use them!\n\n        `{username}` is expanded to the escaped, dns-label safe username.\n        \"\"\"\n    )\n\n    image = Unicode(\n        'jupyterhub/singleuser:latest',\n        config=True,\n        help=\"\"\"\n        Docker image to use for spawning user's containers.\n\n        Defaults to `jupyterhub/singleuser:latest`\n\n        Name of the container + a tag, same as would be used with\n        a `docker pull` command. If tag is set to `latest`, kubernetes will\n        check the registry each time a new user is spawned to see if there\n        is a newer image available. If available, new image will be pulled.\n        Note that this could cause long delays when spawning, especially\n        if the image is large. If you do not specify a tag, whatever version\n        of the image is first pulled on the node will be used, thus possibly\n        leading to inconsistent images on different nodes. For all these\n        reasons, it is recommended to specify a specific immutable tag\n        for the image.\n\n        If your image is very large, you might need to increase the timeout\n        for starting the single user container from the default. You can\n        set this with::\n\n           c.KubeSpawner.start_timeout = 60 * 5  # Up to 5 minutes\n\n        \"\"\"\n    )\n\n    image_pull_policy = Unicode(\n        'IfNotPresent',\n        config=True,\n        help=\"\"\"\n        The image pull policy of the docker container specified in\n        `image`.\n\n        Defaults to `IfNotPresent` which causes the Kubelet to NOT pull the image\n        specified in KubeSpawner.image if it already exists, except if the tag\n        is `:latest`. For more information on image pull policy,\n        refer to `the Kubernetes documentation <https://kubernetes.io/docs/concepts/containers/images/>`__.\n\n\n        This configuration is primarily used in development if you are\n        actively changing the `image_spec` and would like to pull the image\n        whenever a user container is spawned.\n        \"\"\"\n    )\n\n    # FIXME: Don't override 'default_value' (\"\") or 'allow_none' (False) (Breaking change)\n    image_pull_secrets = Unicode(\n        None,\n        allow_none=True,\n        config=True,\n        help=\"\"\"\n        The kubernetes secret to use for pulling images from private repository.\n\n        Set this to the name of a Kubernetes secret containing the docker configuration\n        required to pull the image.\n\n        See `the Kubernetes documentation <https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod>`__\n        for more information on when and why this might need to be set, and what\n        it should be set to.\n        \"\"\"\n    )\n\n    node_selector = Dict(\n        config=True,\n        help=\"\"\"\n        The dictionary Selector labels used to match the Nodes where Pods will be launched.\n\n        Default is None and means it will be launched in any available Node.\n\n        For example to match the Nodes that have a label of `disktype: ssd` use::\n\n           c.KubeSpawner.node_selector = {'disktype': 'ssd'}\n        \"\"\"\n    )\n\n    uid = Union(\n        trait_types=[\n            Integer(),\n            Callable(),\n        ],\n        allow_none=True,\n        config=True,\n        help=\"\"\"\n        The UID to run the single-user server containers as.\n\n        This UID should ideally map to a user that already exists in the container\n        image being used. Running as root is discouraged.\n\n        Instead of an integer, this could also be a callable that takes as one\n        parameter the current spawner instance and returns an integer. The callable\n        will be called asynchronously if it returns a future. Note that\n        the interface of the spawner class is not deemed stable across versions,\n        so using this functionality might cause your JupyterHub or kubespawner\n        upgrades to break.\n\n        If set to `None`, the user specified with the `USER` directive in the\n        container metadata is used.\n        \"\"\"\n    )\n\n    gid = Union(\n        trait_types=[\n            Integer(),\n            Callable(),\n        ],\n        allow_none=True,\n        config=True,\n        help=\"\"\"\n        The GID to run the single-user server containers as.\n\n        This GID should ideally map to a group that already exists in the container\n        image being used. Running as root is discouraged.\n\n        Instead of an integer, this could also be a callable that takes as one\n        parameter the current spawner instance and returns an integer. The callable\n        will be called asynchronously if it returns a future. Note that\n        the interface of the spawner class is not deemed stable across versions,\n        so using this functionality might cause your JupyterHub or kubespawner\n        upgrades to break.\n\n        If set to `None`, the group of the user specified with the `USER` directive\n        in the container metadata is used.\n        \"\"\"\n    )\n\n    fs_gid = Union(\n        trait_types=[\n            Integer(),\n            Callable(),\n        ],\n        allow_none=True,\n        config=True,\n        help=\"\"\"\n        The GID of the group that should own any volumes that are created & mounted.\n\n        A special supplemental group that applies primarily to the volumes mounted\n        in the single-user server. In volumes from supported providers, the following\n        things happen:\n\n          1. The owning GID will be the this GID\n          2. The setgid bit is set (new files created in the volume will be owned by\n             this GID)\n          3. The permission bits are OR\u2019d with rw-rw\n\n        The single-user server will also be run with this gid as part of its supplemental\n        groups.\n\n        Instead of an integer, this could also be a callable that takes as one\n        parameter the current spawner instance and returns an integer. The callable will\n        be called asynchronously if it returns a future, rather than an int. Note that\n        the interface of the spawner class is not deemed stable across versions,\n        so using this functionality might cause your JupyterHub or kubespawner\n        upgrades to break.\n\n        You'll *have* to set this if you are using auto-provisioned volumes with most\n        cloud providers. See `fsGroup <https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#podsecuritycontext-v1-core>`_\n        for more details.\n        \"\"\"\n    )\n\n    supplemental_gids = Union(\n        trait_types=[\n            List(),\n            Callable(),\n        ],\n        config=True,\n        help=\"\"\"\n        A list of GIDs that should be set as additional supplemental groups to the\n        user that the container runs as.\n\n        Instead of a list of integers, this could also be a callable that takes as one\n        parameter the current spawner instance and returns a list of integers. The\n        callable will be called asynchronously if it returns a future, rather than\n        a list. Note that the interface of the spawner class is not deemed stable\n        across versions, so using this functionality might cause your JupyterHub\n        or kubespawner upgrades to break.\n\n        You may have to set this if you are deploying to an environment with RBAC/SCC\n        enforced and pods run with a 'restricted' SCC which results in the image being\n        run as an assigned user ID. The supplemental group IDs would need to include\n        the corresponding group ID of the user ID the image normally would run as. The\n        image must setup all directories/files any application needs access to, as group\n        writable.\n        \"\"\"\n    )\n\n    privileged = Bool(\n        False,\n        config=True,\n        help=\"\"\"\n        Whether to run the pod with a privileged security context.\n        \"\"\"\n    )\n\n    modify_pod_hook = Callable(\n        None,\n        allow_none=True,\n        config=True,\n        help=\"\"\"\n        Callable to augment the Pod object before launching.\n\n        Expects a callable that takes two parameters:\n\n           1. The spawner object that is doing the spawning\n           2. The Pod object that is to be launched\n\n        You should modify the Pod object and return it.\n\n        This can be a coroutine if necessary. When set to none, no augmenting is done.\n\n        This is very useful if you want to modify the pod being launched dynamically.\n        Note that the spawner object can change between versions of KubeSpawner and JupyterHub,\n        so be careful relying on this!\n        \"\"\"\n    )\n\n    volumes = List(\n        config=True,\n        help=\"\"\"\n        List of Kubernetes Volume specifications that will be mounted in the user pod.\n\n        This list will be directly added under `volumes` in the kubernetes pod spec,\n        so you should use the same structure. Each item in the list must have the\n        following two keys:\n\n          - `name`\n            Name that'll be later used in the `volume_mounts` config to mount this\n            volume at a specific path.\n          - `<name-of-a-supported-volume-type>` (such as `hostPath`, `persistentVolumeClaim`,\n            etc)\n            The key name determines the type of volume to mount, and the value should\n            be an object specifying the various options available for that kind of\n            volume.\n\n        See `the Kubernetes documentation <https://kubernetes.io/docs/concepts/storage/volumes>`__\n        for more information on the various kinds of volumes available and their options.\n        Your kubernetes cluster must already be configured to support the volume types you want to use.\n\n        `{username}` is expanded to the escaped, dns-label safe username.\n        \"\"\"\n    )\n\n    volume_mounts = List(\n        config=True,\n        help=\"\"\"\n        List of paths on which to mount volumes in the user notebook's pod.\n\n        This list will be added to the values of the `volumeMounts` key under the user's\n        container in the kubernetes pod spec, so you should use the same structure as that.\n        Each item in the list should be a dictionary with at least these two keys:\n\n           - `mountPath` The path on the container in which we want to mount the volume.\n           - `name` The name of the volume we want to mount, as specified in the `volumes` config.\n\n        See `the Kubernetes documentation <https://kubernetes.io/docs/concepts/storage/volumes>`__\n        for more information on how the `volumeMount` item works.\n\n        `{username}` is expanded to the escaped, dns-label safe username.\n        \"\"\"\n    )\n\n    # FIXME: Don't override 'default_value' (\"\") or 'allow_none' (False) (Breaking change)\n    storage_capacity = Unicode(\n        None,\n        config=True,\n        allow_none=True,\n        help=\"\"\"\n        The amount of storage space to request from the volume that the pvc will\n        mount to. This amount will be the amount of storage space the user has\n        to work with on their notebook. If left blank, the kubespawner will not\n        create a pvc for the pod.\n\n        This will be added to the `resources: requests: storage:` in the k8s pod spec.\n\n        See `the Kubernetes documentation <https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims>`__\n        for more information on how storage works.\n\n        Quantities can be represented externally as unadorned integers, or as fixed-point\n        integers with one of these SI suffices (`E, P, T, G, M, K, m`) or their power-of-two\n        equivalents (`Ei, Pi, Ti, Gi, Mi, Ki`). For example, the following represent roughly\n        the same value: `128974848`, `129e6`, `129M`, `123Mi`.\n        \"\"\"\n    )\n\n    storage_extra_labels = Dict(\n        config=True,\n        help=\"\"\"\n        Extra kubernetes labels to set on the user PVCs.\n\n        The keys and values specified here would be set as labels on the PVCs\n        created by kubespawner for the user. Note that these are only set\n        when the PVC is created, not later when this setting is updated.\n\n        See `the Kubernetes documentation <https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/>`__\n        for more info on what labels are and why you might want to use them!\n\n        `{username}` is expanded to the escaped, dns-label safe username.\n        \"\"\"\n    )\n\n    # FIXME: Don't override 'default_value' (\"\") or 'allow_none' (False) (Breaking change)\n    storage_class = Unicode(\n        None,\n        config=True,\n        allow_none=True,\n        help=\"\"\"\n        The storage class that the pvc will use.\n\n        This will be added to the `annotations: volume.beta.kubernetes.io/storage-class:`\n        in the pvc metadata.\n\n        This will determine what type of volume the pvc will request to use. If one exists\n        that matches the criteria of the StorageClass, the pvc will mount to that. Otherwise,\n        b/c it has a storage class, k8s will dynamically spawn a pv for the pvc to bind to\n        and a machine in the cluster for the pv to bind to.\n\n        Note that an empty string is a valid value and is always interpreted to be\n        requesting a pv with no class.\n\n        See `the Kubernetes documentation <https://kubernetes.io/docs/concepts/storage/storage-classes/>`__\n        for more information on how StorageClasses work.\n\n        \"\"\"\n    )\n\n    storage_access_modes = List(\n        [\"ReadWriteOnce\"],\n        config=True,\n        help=\"\"\"\n        List of access modes the user has for the pvc.\n\n        The access modes are:\n\n            - `ReadWriteOnce` \u2013 the volume can be mounted as read-write by a single node\n            - `ReadOnlyMany` \u2013 the volume can be mounted read-only by many nodes\n            - `ReadWriteMany` \u2013 the volume can be mounted as read-write by many nodes\n\n        See `the Kubernetes documentation <https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes>`__\n        for more information on how access modes work.\n        \"\"\"\n    )\n\n    storage_selector = Dict(\n        config=True,\n        help=\"\"\"\n        The dictionary Selector labels used to match a PersistentVolumeClaim to\n        a PersistentVolume.\n\n        Default is None and means it will match based only on other storage criteria.\n\n        For example to match the Nodes that have a label of `content: jupyter` use::\n\n           c.KubeSpawner.storage_selector = {'matchLabels':{'content': 'jupyter'}}\n        \"\"\"\n    )\n\n    lifecycle_hooks = Dict(\n        config=True,\n        help=\"\"\"\n        Kubernetes lifecycle hooks to set on the spawned single-user pods.\n\n        The keys is name of hooks and there are only two hooks, postStart and preStop.\n        The values are handler of hook which executes by Kubernetes management system when hook is called.\n\n        Below is an sample copied from\n        `the Kubernetes documentation <https://kubernetes.io/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/>`__::\n\n\n            c.KubeSpawner.lifecycle_hooks = {\n                \"postStart\": {\n                    \"exec\": {\n                        \"command\": [\"/bin/sh\", \"-c\", \"echo Hello from the postStart handler > /usr/share/message\"]\n                    }\n                },\n                \"preStop\": {\n                    \"exec\": {\n                        \"command\": [\"/usr/sbin/nginx\", \"-s\", \"quit\"]\n                    }\n                }\n            }\n\n        See `the Kubernetes documentation <https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/>`__\n        for more info on what lifecycle hooks are and why you might want to use them!\n        \"\"\"\n    )\n\n    init_containers = List(\n        config=True,\n        help=\"\"\"\n        List of initialization containers belonging to the pod.\n\n        This list will be directly added under `initContainers` in the kubernetes pod spec,\n        so you should use the same structure. Each item in the dict must a field\n        of the `V1Container specification <https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#container-v1-core>`_.\n\n        One usage is disabling access to metadata service from single-user\n        notebook server with configuration below::\n\n            c.KubeSpawner.init_containers = [{\n                \"name\": \"init-iptables\",\n                \"image\": \"<image with iptables installed>\",\n                \"command\": [\"iptables\", \"-A\", \"OUTPUT\", \"-p\", \"tcp\", \"--dport\", \"80\", \"-d\", \"169.254.169.254\", \"-j\", \"DROP\"],\n                \"securityContext\": {\n                    \"capabilities\": {\n                        \"add\": [\"NET_ADMIN\"]\n                    }\n                }\n            }]\n\n\n        See `the Kubernetes documentation <https://kubernetes.io/docs/concepts/workloads/pods/init-containers/>`__\n        for more info on what init containers are and why you might want to use them!\n\n        To user this feature, Kubernetes version must greater than 1.6.\n        \"\"\"\n    )\n\n    extra_container_config = Dict(\n        config=True,\n        help=\"\"\"\n        Extra configuration (e.g. ``envFrom``) for notebook container which is not covered by other attributes.\n\n        This dict will be directly merge into `container` of notebook server,\n        so you should use the same structure. Each item in the dict must a field\n        of the `V1Container specification <https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#container-v1-core>`_.\n\n        One usage is set ``envFrom`` on notebook container with configuration below::\n\n            c.KubeSpawner.extra_container_config = {\n                \"envFrom\": [{\n                    \"configMapRef\": {\n                        \"name\": \"special-config\"\n                    }\n                }]\n            }\n\n        The key could be either a camelCase word (used by Kubernetes yaml, e.g.\n        ``envFrom``) or a snake_case word (used by Kubernetes Python client,\n        e.g. ``env_from``).\n        \"\"\"\n    )\n\n    extra_pod_config = Dict(\n        config=True,\n        help=\"\"\"\n        Extra configuration for the pod which is not covered by other attributes.\n\n        This dict will be directly merge into pod,so you should use the same structure.\n        Each item in the dict is field of pod configuration\n        which follows spec at https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#podspec-v1-core.\n\n        One usage is set restartPolicy and dnsPolicy with configuration below::\n\n            c.KubeSpawner.extra_pod_config = {\n                \"restartPolicy\": \"OnFailure\",\n                \"dns_policy\": \"ClusterFirstWithHostNet\"\n            }\n\n        The `key` could be either a camelCase word (used by Kubernetes yaml,\n        e.g. `restartPolicy`) or a snake_case word (used by Kubernetes Python\n        client, e.g. `dns_policy`).\n        \"\"\"\n    )\n\n    extra_containers = List(\n        config=True,\n        help=\"\"\"\n        List of containers belonging to the pod which besides to the container generated for notebook server.\n\n        This list will be directly appended under `containers` in the kubernetes pod spec,\n        so you should use the same structure. Each item in the list is container configuration\n        which follows spec at https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#container-v1-core.\n\n        One usage is setting crontab in a container to clean sensitive data with configuration below::\n\n            c.KubeSpawner.extra_containers = [{\n                \"name\": \"crontab\",\n                \"image\": \"supercronic\",\n                \"command\": [\"/usr/local/bin/supercronic\", \"/etc/crontab\"]\n            }]\n\n        `{username}` is expanded to the escaped, dns-label safe username.\n        \"\"\"\n    )\n\n    # FIXME: Don't override 'default_value' (\"\") or 'allow_none' (False) (Breaking change)\n    scheduler_name = Unicode(\n        None,\n        allow_none=True,\n        config=True,\n        help=\"\"\"\n        Set the pod's scheduler explicitly by name. See `the Kubernetes documentation <https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#podspec-v1-core>`__\n        for more information.\n        \"\"\"\n    )\n\n    tolerations = List(\n        config=True,\n        help=\"\"\"\n        List of tolerations that are to be assigned to the pod in order to be able to schedule the pod\n        on a node with the corresponding taints. See the official Kubernetes documentation for additional details\n        https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n\n        Pass this field an array of `\"Toleration\" objects\n        <https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#nodeselectorterm-v1-core>`__\n\n        Example::\n\n            [\n                {\n                    'key': 'key',\n                    'operator': 'Equal',\n                    'value': 'value',\n                    'effect': 'NoSchedule'\n                },\n                {\n                    'key': 'key',\n                    'operator': 'Exists',\n                    'effect': 'NoSchedule'\n                }\n            ]\n\n        \"\"\"\n    )\n\n    node_affinity_preferred = List(\n        config=True,\n        help=\"\"\"\n        Affinities describe where pods prefer or require to be scheduled, they\n        may prefer or require a node to have a certain label or be in proximity\n        / remoteness to another pod. To learn more visit\n        https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n\n        Pass this field an array of \"PreferredSchedulingTerm\" objects.*\n        * https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#preferredschedulingterm-v1-core\n        \"\"\"\n    )\n    node_affinity_required = List(\n        config=True,\n        help=\"\"\"\n        Affinities describe where pods prefer or require to be scheduled, they\n        may prefer or require a node to have a certain label or be in proximity\n        / remoteness to another pod. To learn more visit\n        https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n\n        Pass this field an array of \"NodeSelectorTerm\" objects.*\n        * https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#nodeselectorterm-v1-core\n        \"\"\"\n    )\n    pod_affinity_preferred = List(\n        config=True,\n        help=\"\"\"\n        Affinities describe where pods prefer or require to be scheduled, they\n        may prefer or require a node to have a certain label or be in proximity\n        / remoteness to another pod. To learn more visit\n        https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n\n        Pass this field an array of \"WeightedPodAffinityTerm\" objects.*\n        * https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#weightedpodaffinityterm-v1-core\n        \"\"\"\n    )\n    pod_affinity_required = List(\n        config=True,\n        help=\"\"\"\n        Affinities describe where pods prefer or require to be scheduled, they\n        may prefer or require a node to have a certain label or be in proximity\n        / remoteness to another pod. To learn more visit\n        https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n\n        Pass this field an array of \"PodAffinityTerm\" objects.*\n        * https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#podaffinityterm-v1-core\n        \"\"\"\n    )\n    pod_anti_affinity_preferred = List(\n        config=True,\n        help=\"\"\"\n        Affinities describe where pods prefer or require to be scheduled, they\n        may prefer or require a node to have a certain label or be in proximity\n        / remoteness to another pod. To learn more visit\n        https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n\n        Pass this field an array of \"WeightedPodAffinityTerm\" objects.*\n        * https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#weightedpodaffinityterm-v1-core\n        \"\"\"\n    )\n    pod_anti_affinity_required = List(\n        config=True,\n        help=\"\"\"\n        Affinities describe where pods prefer or require to be scheduled, they\n        may prefer or require a node to have a certain label or be in proximity\n        / remoteness to another pod. To learn more visit\n        https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n\n        Pass this field an array of \"PodAffinityTerm\" objects.*\n        * https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#podaffinityterm-v1-core\n        \"\"\"\n    )\n\n    extra_resource_guarantees = Dict(\n        config=True,\n        help=\"\"\"\n        The dictionary used to request arbitrary resources.\n        Default is None and means no additional resources are requested.\n        For example, to request 1 Nvidia GPUs::\n\n            c.KubeSpawner.extra_resource_guarantees = {\"nvidia.com/gpu\": \"1\"}\n        \"\"\"\n    )\n\n    extra_resource_limits = Dict(\n        config=True,\n        help=\"\"\"\n        The dictionary used to limit arbitrary resources.\n        Default is None and means no additional resources are limited.\n        For example, to add a limit of 3 Nvidia GPUs::\n\n            c.KubeSpawner.extra_resource_limits = {\"nvidia.com/gpu\": \"3\"}\n        \"\"\"\n    )\n\n    delete_stopped_pods = Bool(\n        True,\n        config=True,\n        help=\"\"\"\n        Whether to delete pods that have stopped themselves.\n        Set to False to leave stopped pods in the completed state,\n        allowing for easier debugging of why they may have stopped.\n        \"\"\"\n    )\n\n    profile_form_template = Unicode(\n        \"\"\"\n        <script>\n        // JupyterHub 0.8 applied form-control indisciminately to all form elements.\n        // Can be removed once we stop supporting JupyterHub 0.8\n        $(document).ready(function() {\n            $('#kubespawner-profiles-list input[type=\"radio\"]').removeClass('form-control');\n        });\n        </script>\n        <style>\n        /* The profile description should not be bold, even though it is inside the <label> tag */\n        #kubespawner-profiles-list label p {\n            font-weight: normal;\n        }\n        </style>\n\n        <div class='form-group' id='kubespawner-profiles-list'>\n        {% for profile in profile_list %}\n        <label for='profile-item-{{ profile.slug }}' class='form-control input-group'>\n            <div class='col-md-1'>\n                <input type='radio' name='profile' id='profile-item-{{ profile.slug }}' value='{{ profile.slug }}' {% if profile.default %}checked{% endif %} />\n            </div>\n            <div class='col-md-11'>\n                <strong>{{ profile.display_name }}</strong>\n                {% if profile.description %}\n                <p>{{ profile.description }}</p>\n                {% endif %}\n            </div>\n        </label>\n        {% endfor %}\n        </div>\n        \"\"\",\n        config=True,\n        help=\"\"\"\n        Jinja2 template for constructing profile list shown to user.\n\n        Used when `profile_list` is set.\n\n        The contents of `profile_list` are passed in to the template.\n        This should be used to construct the contents of a HTML form. When\n        posted, this form is expected to have an item with name `profile` and\n        the value the index of the profile in `profile_list`.\n        \"\"\"\n    )\n\n    profile_list = Union(\n        trait_types=[\n            List(trait=Dict()),\n            Callable()\n        ],\n        config=True,\n        help=\"\"\"\n        List of profiles to offer for selection by the user.\n\n        Signature is: `List(Dict())`, where each item is a dictionary that has two keys:\n\n        - `display_name`: the human readable display name (should be HTML safe)\n        - `slug`: the machine readable slug to identify the profile\n          (missing slugs are generated from display_name)\n        - `description`: Optional description of this profile displayed to the user.\n        - `kubespawner_override`: a dictionary with overrides to apply to the KubeSpawner\n          settings. Each value can be either the final value to change or a callable that\n          take the `KubeSpawner` instance as parameter and return the final value.\n        - `default`: (optional Bool) True if this is the default selected option\n\n        Example::\n\n            c.KubeSpawner.profile_list = [\n                {\n                    'display_name': 'Training Env - Python',\n                    'slug': 'training-python',\n                    'default': True,\n                    'kubespawner_override': {\n                        'image': 'training/python:label',\n                        'cpu_limit': 1,\n                        'mem_limit': '512M',\n                    }\n                }, {\n                    'display_name': 'Training Env - Datascience',\n                    'slug': 'training-datascience',\n                    'kubespawner_override': {\n                        'image': 'training/datascience:label',\n                        'cpu_limit': 4,\n                        'mem_limit': '8G',\n                    }\n                }, {\n                    'display_name': 'DataScience - Small instance',\n                    'slug': 'datascience-small',\n                    'kubespawner_override': {\n                        'image': 'datascience/small:label',\n                        'cpu_limit': 10,\n                        'mem_limit': '16G',\n                    }\n                }, {\n                    'display_name': 'DataScience - Medium instance',\n                    'slug': 'datascience-medium',\n                    'kubespawner_override': {\n                        'image': 'datascience/medium:label',\n                        'cpu_limit': 48,\n                        'mem_limit': '96G',\n                    }\n                }, {\n                    'display_name': 'DataScience - Medium instance (GPUx2)',\n                    'slug': 'datascience-gpu2x',\n                    'kubespawner_override': {\n                        'image': 'datascience/medium:label',\n                        'cpu_limit': 48,\n                        'mem_limit': '96G',\n                        'extra_resource_guarantees': {\"nvidia.com/gpu\": \"2\"},\n                    }\n                }\n            ]\n\n        Instead of a list of dictionaries, this could also be a callable that takes as one\n        parameter the current spawner instance and returns a list of dictionaries. The\n        callable will be called asynchronously if it returns a future, rather than\n        a list. Note that the interface of the spawner class is not deemed stable\n        across versions, so using this functionality might cause your JupyterHub\n        or kubespawner upgrades to break.\n        \"\"\"\n    )\n\n    priority_class_name = Unicode(\n        config=True,\n        help=\"\"\"\n        The priority class that the pods will use.\n\n        See https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption for\n        more information on how pod priority works.\n        \"\"\"\n    )\n\n    delete_grace_period = Integer(\n        1,\n        config=True,\n        help=\"\"\"\n        Time in seconds for the pod to be in `terminating` state before is forcefully killed.\n        \n        Increase this if you need more time to execute a `preStop` lifecycle hook.\n\n        See https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods for\n        more information on how pod termination works.\n\n        Defaults to `1`.\n        \"\"\"\n    )\n\n    # deprecate redundant and inconsistent singleuser_ and user_ prefixes:\n    _deprecated_traits_09 = [\n        \"singleuser_working_dir\",\n        \"singleuser_service_account\",\n        \"singleuser_extra_labels\",\n        \"singleuser_extra_annotations\",\n        \"singleuser_image_spec\",\n        \"singleuser_image_pull_policy\",\n        \"singleuser_image_pull_secrets\",\n        \"singleuser_node_selector\",\n        \"singleuser_uid\",\n        \"singleuser_fs_gid\",\n        \"singleuser_supplemental_gids\",\n        \"singleuser_privileged\",\n        \"singleuser_lifecycle_hooks\",\n        \"singleuser_extra_pod_config\",\n        \"singleuser_init_containers\",\n        \"singleuser_extra_container_config\",\n        \"singleuser_extra_containers\",\n        \"user_storage_class\",\n        \"user_storage_pvc_ensure\",\n        \"user_storage_capacity\",\n        \"user_storage_extra_labels\",\n        \"user_storage_access_modes\",\n    ]\n    # other general deprecations:\n    _deprecated_traits = {\n        'image_spec': ('image', '0.10'),\n    }\n    # add the bulk deprecations from 0.9\n    for _deprecated_name in _deprecated_traits_09:\n        _new_name = _deprecated_name.split('_', 1)[1]\n        _deprecated_traits[_deprecated_name] = (_new_name, '0.9')\n\n    @validate('config')\n    def _handle_deprecated_config(self, proposal):\n        config = proposal.value\n        if 'KubeSpawner' not in config:\n            # nothing to check\n            return config\n        for _deprecated_name, (_new_name, version) in self._deprecated_traits.items():\n            # for any `singleuser_name` deprecate in favor of `name`\n            if _deprecated_name not in config.KubeSpawner:\n                # nothing to do\n                continue\n\n            # remove deprecated value from config\n            _deprecated_value = config.KubeSpawner.pop(_deprecated_name)\n            self.log.warning(\n                \"KubeSpawner.%s is deprecated in %s. Use KubeSpawner.%s instead\",\n                _deprecated_name,\n                version,\n                _new_name,\n            )\n            if _new_name in config.KubeSpawner:\n                # *both* config values found,\n                # ignore deprecated config and warn about the collision\n                _new_value = config.KubeSpawner[_new_name]\n                # ignore deprecated config in favor of non-deprecated config\n                self.log.warning(\n                    \"Ignoring deprecated config KubeSpawner.%s = %r \"\n                    \" in favor of KubeSpawner.%s = %r\",\n                    _deprecated_name,\n                    _deprecated_value,\n                    _new_name,\n                    _new_value,\n                )\n            else:\n                # move deprecated config to its new home\n                config.KubeSpawner[_new_name] = _deprecated_value\n\n        return config\n\n    # define properties for deprecated names\n    # so we can propagate their values to the new traits.\n    # most deprecations should be handled via config above,\n    # but in case these are set at runtime, e.g. by subclasses\n    # or hooks, hook this up.\n    # The signature-order of these is funny\n    # because the property methods are created with\n    # functools.partial(f, name) so name is passed as the first arg\n    # before self.\n\n    def _get_deprecated(name, new_name, version, self):\n        # warn about the deprecated name\n        self.log.warning(\n            \"KubeSpawner.%s is deprecated in %s. Use KubeSpawner.%s\",\n            name,\n            version,\n            new_name,\n        )\n        return getattr(self, new_name)\n\n    def _set_deprecated(name, new_name, version, self, value):\n        # warn about the deprecated name\n        self.log.warning(\n            \"KubeSpawner.%s is deprecated in %s. Use KubeSpawner.%s\",\n            name,\n            version,\n            new_name,\n        )\n        return setattr(self, new_name, value)\n\n    for _deprecated_name, (_new_name, _version) in _deprecated_traits.items():\n        exec(\n            \"\"\"{0} = property(\n                partial(_get_deprecated, '{0}', '{1}', '{2}'),\n                partial(_set_deprecated, '{0}', '{1}', '{2}'),\n            )\n            \"\"\".format(\n                _deprecated_name,\n                _new_name,\n                _version,\n            )\n        )\n    del _deprecated_name\n\n    def _expand_user_properties(self, template):\n        # Make sure username and servername match the restrictions for DNS labels\n        # Note: '-' is not in safe_chars, as it is being used as escape character\n        safe_chars = set(string.ascii_lowercase + string.digits)\n\n        # Set servername based on whether named-server initialised\n        if self.name:\n            # use two -- to ensure no collision possibilities\n            # are created by an ambiguous boundary between username and\n            # servername.\n            # -- cannot occur in a string where - is the escape char.\n            servername = '--{}'.format(self.name)\n            safe_servername = '--{}'.format(escapism.escape(self.name, safe=safe_chars, escape_char='-').lower())\n        else:\n            servername = ''\n            safe_servername = ''\n\n        legacy_escaped_username = ''.join([s if s in safe_chars else '-' for s in self.user.name.lower()])\n        safe_username = escapism.escape(self.user.name, safe=safe_chars, escape_char='-').lower()\n        return template.format(\n            userid=self.user.id,\n            username=safe_username,\n            unescaped_username=self.user.name,\n            legacy_escape_username=legacy_escaped_username,\n            servername=safe_servername,\n            unescaped_servername=servername,\n        )\n\n    def _expand_all(self, src):\n        if isinstance(src, list):\n            return [self._expand_all(i) for i in src]\n        elif isinstance(src, dict):\n            return {k: self._expand_all(v) for k, v in src.items()}\n        elif isinstance(src, str):\n            return self._expand_user_properties(src)\n        else:\n            return src\n\n    def _build_common_labels(self, extra_labels):\n        # Default set of labels, picked up from\n        # https://github.com/kubernetes/helm/blob/master/docs/chart_best_practices/labels.md\n        labels = {}\n        labels.update(extra_labels)\n        labels.update(self.common_labels)\n        return labels\n\n    def _build_pod_labels(self, extra_labels):\n        labels = self._build_common_labels(extra_labels)\n        labels.update({\n            'component': 'singleuser-server'\n        })\n        return labels\n\n    def _build_common_annotations(self, extra_annotations):\n        # Annotations don't need to be escaped\n        annotations = {\n            'hub.jupyter.org/username': self.user.name\n        }\n        if self.name:\n            annotations['hub.jupyter.org/servername'] = self.name\n\n        annotations.update(extra_annotations)\n        return annotations\n\n    @gen.coroutine\n    def get_pod_manifest(self):\n        \"\"\"\n        Make a pod manifest that will spawn current user's notebook pod.\n        \"\"\"\n        if callable(self.uid):\n            uid = yield gen.maybe_future(self.uid(self))\n        else:\n            uid = self.uid\n\n        if callable(self.gid):\n            gid = yield gen.maybe_future(self.gid(self))\n        else:\n            gid = self.gid\n\n        if callable(self.fs_gid):\n            fs_gid = yield gen.maybe_future(self.fs_gid(self))\n        else:\n            fs_gid = self.fs_gid\n\n        if callable(self.supplemental_gids):\n            supplemental_gids = yield gen.maybe_future(self.supplemental_gids(self))\n        else:\n            supplemental_gids = self.supplemental_gids\n\n        if self.cmd:\n            real_cmd = self.cmd + self.get_args()\n        else:\n            real_cmd = None\n\n        labels = self._build_pod_labels(self._expand_all(self.extra_labels))\n        annotations = self._build_common_annotations(self._expand_all(self.extra_annotations))\n\n        return make_pod(\n            name=self.pod_name,\n            cmd=real_cmd,\n            port=self.port,\n            image=self.image,\n            image_pull_policy=self.image_pull_policy,\n            image_pull_secret=self.image_pull_secrets,\n            node_selector=self.node_selector,\n            run_as_uid=uid,\n            run_as_gid=gid,\n            fs_gid=fs_gid,\n            supplemental_gids=supplemental_gids,\n            run_privileged=self.privileged,\n            env=self.get_env(),\n            volumes=self._expand_all(self.volumes),\n            volume_mounts=self._expand_all(self.volume_mounts),\n            working_dir=self.working_dir,\n            labels=labels,\n            annotations=annotations,\n            cpu_limit=self.cpu_limit,\n            cpu_guarantee=self.cpu_guarantee,\n            mem_limit=self.mem_limit,\n            mem_guarantee=self.mem_guarantee,\n            extra_resource_limits=self.extra_resource_limits,\n            extra_resource_guarantees=self.extra_resource_guarantees,\n            lifecycle_hooks=self.lifecycle_hooks,\n            init_containers=self._expand_all(self.init_containers),\n            service_account=self.service_account,\n            extra_container_config=self.extra_container_config,\n            extra_pod_config=self._expand_all(self.extra_pod_config),\n            extra_containers=self._expand_all(self.extra_containers),\n            scheduler_name=self.scheduler_name,\n            tolerations=self.tolerations,\n            node_affinity_preferred=self.node_affinity_preferred,\n            node_affinity_required=self.node_affinity_required,\n            pod_affinity_preferred=self.pod_affinity_preferred,\n            pod_affinity_required=self.pod_affinity_required,\n            pod_anti_affinity_preferred=self.pod_anti_affinity_preferred,\n            pod_anti_affinity_required=self.pod_anti_affinity_required,\n            priority_class_name=self.priority_class_name,\n            logger=self.log,\n        )\n\n    def get_pvc_manifest(self):\n        \"\"\"\n        Make a pvc manifest that will spawn current user's pvc.\n        \"\"\"\n        labels = self._build_common_labels(self._expand_all(self.storage_extra_labels))\n        labels.update({\n            'component': 'singleuser-storage'\n        })\n\n        annotations = self._build_common_annotations({})\n\n        return make_pvc(\n            name=self.pvc_name,\n            storage_class=self.storage_class,\n            access_modes=self.storage_access_modes,\n            selector=self.storage_selector,\n            storage=self.storage_capacity,\n            labels=labels,\n            annotations=annotations\n        )\n\n    def is_pod_running(self, pod):\n        \"\"\"\n        Check if the given pod is running\n\n        pod must be a dictionary representing a Pod kubernetes API object.\n        \"\"\"\n        # FIXME: Validate if this is really the best way\n        is_running = (\n            pod is not None and\n            pod.status.phase == 'Running' and\n            pod.status.pod_ip is not None and\n            pod.metadata.deletion_timestamp is None and\n            all([cs.ready for cs in pod.status.container_statuses])\n        )\n        return is_running\n\n    def get_state(self):\n        \"\"\"\n        Save state required to reinstate this user's pod from scratch\n\n        We save the `pod_name`, even though we could easily compute it,\n        because JupyterHub requires you save *some* state! Otherwise\n        it assumes your server is dead. This works around that.\n\n        It's also useful for cases when the `pod_template` changes between\n        restarts - this keeps the old pods around.\n        \"\"\"\n        state = super().get_state()\n        state['pod_name'] = self.pod_name\n        return state\n\n    def get_env(self):\n        \"\"\"Return the environment dict to use for the Spawner.\n\n        See also: jupyterhub.Spawner.get_env\n        \"\"\"\n\n        env = super(KubeSpawner, self).get_env()\n        # deprecate image\n        env['JUPYTER_IMAGE_SPEC'] = self.image\n        env['JUPYTER_IMAGE'] = self.image\n\n        return env\n\n    def load_state(self, state):\n        \"\"\"\n        Load state from storage required to reinstate this user's pod\n\n        Since this runs after `__init__`, this will override the generated `pod_name`\n        if there's one we have saved in state. These are the same in most cases,\n        but if the `pod_template` has changed in between restarts, it will no longer\n        be the case. This allows us to continue serving from the old pods with\n        the old names.\n        \"\"\"\n        if 'pod_name' in state:\n            self.pod_name = state['pod_name']\n\n    @gen.coroutine\n    def poll(self):\n        \"\"\"\n        Check if the pod is still running.\n\n        Uses the same interface as subprocess.Popen.poll(): if the pod is\n        still running, returns None.  If the pod has exited, return the\n        exit code if we can determine it, or 1 if it has exited but we\n        don't know how.  These are the return values JupyterHub expects.\n\n        Note that a clean exit will have an exit code of zero, so it is\n        necessary to check that the returned value is None, rather than\n        just Falsy, to determine that the pod is still running.\n        \"\"\"\n        # have to wait for first load of data before we have a valid answer\n        if not self.pod_reflector.first_load_future.done():\n            yield self.pod_reflector.first_load_future\n        data = self.pod_reflector.pods.get(self.pod_name, None)\n        if data is not None:\n            if data.status.phase == 'Pending':\n                return None\n            ctr_stat = data.status.container_statuses\n            if ctr_stat is None:  # No status, no container (we hope)\n                # This seems to happen when a pod is idle-culled.\n                return 1\n            for c in ctr_stat:\n                # return exit code if notebook container has terminated\n                if c.name == 'notebook':\n                    if c.state.terminated:\n                        # call self.stop to delete the pod\n                        if self.delete_stopped_pods:\n                            yield self.stop(now=True)\n                        return c.state.terminated.exit_code\n                    break\n            # None means pod is running or starting up\n            return None\n        # pod doesn't exist or has been deleted\n        return 1\n\n    @run_on_executor\n    def asynchronize(self, method, *args, **kwargs):\n        return method(*args, **kwargs)\n\n    @property\n    def events(self):\n        \"\"\"Filter event-reflector to just this pods events\n\n        Returns list of all events that match our pod_name\n        since our ._last_event (if defined).\n        ._last_event is set at the beginning of .start().\n        \"\"\"\n        if not self.event_reflector:\n            return []\n\n        events = []\n        for event in self.event_reflector.events:\n            if event.involved_object.name != self.pod_name:\n                # only consider events for my pod name\n                continue\n\n            if self._last_event and event.metadata.uid == self._last_event:\n                # saw last_event marker, ignore any previous events\n                # and only consider future events\n                # only include events *after* our _last_event marker\n                events = []\n            else:\n                events.append(event)\n        return events\n\n    @async_generator\n    async def progress(self):\n        \"\"\"\n        This function is reporting back the progress of spawning a pod until\n        self._start_future has fired.\n\n        This is working with events parsed by the python kubernetes client,\n        and here is the specification of events that is relevant to understand:\n        ref: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.16/#event-v1-core\n        \"\"\"\n        if not self.events_enabled:\n            return\n\n        self.log.debug('progress generator: %s', self.pod_name)\n        start_future = self._start_future\n        pod_id = None\n        progress = 0\n        next_event = 0\n\n        break_while_loop = False\n        while True:\n            # Ensure we always capture events following the start_future\n            # signal has fired.\n            if start_future.done():\n                break_while_loop = True\n            events = self.events\n\n            len_events = len(events)\n            if next_event < len_events:\n                # only show messages for the 'current' pod\n                # pod_id may change if a previous pod is being stopped\n                # before starting a new one\n                # use the uid of the latest event to identify 'current'\n                pod_id = events[-1].involved_object.uid\n                for i in range(next_event, len_events):\n                    event = events[i]\n                    # move the progress bar.\n                    # Since we don't know how many events we will get,\n                    # asymptotically approach 90% completion with each event.\n                    # each event gets 33% closer to 90%:\n                    # 30 50 63 72 78 82 84 86 87 88 88 89\n                    progress += (90 - progress) / 3\n\n                    # V1Event isn't serializable, and neither is the datetime\n                    # objects within it, and we need what we pass back to be\n                    # serializable to it can be sent back from JupyterHub to\n                    # a browser wanting to display progress.\n                    serializable_event = json.loads(\n                        json.dumps(event.to_dict(), default=datetime.isoformat)\n                    )\n                    await yield_({\n                        'progress': int(progress),\n                        'raw_event': serializable_event,\n                        'message':  \"%s [%s] %s\" % (\n                            event.last_timestamp or event.event_time,\n                            event.type,\n                            event.message,\n                        )\n                    })\n                next_event = len_events\n\n            if break_while_loop:\n                break\n            await sleep(1)\n\n    def _start_reflector(self, key, ReflectorClass, replace=False, **kwargs):\n        \"\"\"Start a shared reflector on the KubeSpawner class\n\n\n        key: key for the reflector (e.g. 'pod' or 'events')\n        Reflector: Reflector class to be instantiated\n        kwargs: extra keyword-args to be relayed to ReflectorClass\n\n        If replace=False and the pod reflector is already running,\n        do nothing.\n\n        If replace=True, a running pod reflector will be stopped\n        and a new one started (for recovering from possible errors).\n        \"\"\"\n        main_loop = IOLoop.current()\n        def on_reflector_failure():\n            self.log.critical(\n                \"%s reflector failed, halting Hub.\",\n                key.title(),\n            )\n            sys.exit(1)\n\n        previous_reflector = self.__class__.reflectors.get(key)\n\n        if replace or not previous_reflector:\n            self.__class__.reflectors[key] = ReflectorClass(\n                parent=self,\n                namespace=self.namespace,\n                on_failure=on_reflector_failure,\n                **kwargs,\n            )\n\n        if replace and previous_reflector:\n            # we replaced the reflector, stop the old one\n            previous_reflector.stop()\n\n        # return the current reflector\n        return self.__class__.reflectors[key]\n\n\n    def _start_watching_events(self, replace=False):\n        \"\"\"Start the events reflector\n\n        If replace=False and the event reflector is already running,\n        do nothing.\n\n        If replace=True, a running pod reflector will be stopped\n        and a new one started (for recovering from possible errors).\n        \"\"\"\n        return self._start_reflector(\n            \"events\",\n            EventReflector,\n            fields={\"involvedObject.kind\": \"Pod\"},\n            replace=replace,\n        )\n\n    def _start_watching_pods(self, replace=False):\n        \"\"\"Start the pod reflector\n\n        If replace=False and the pod reflector is already running,\n        do nothing.\n\n        If replace=True, a running pod reflector will be stopped\n        and a new one started (for recovering from possible errors).\n        \"\"\"\n        return self._start_reflector(\"pods\", PodReflector, replace=replace)\n\n    # record a future for the call to .start()\n    # so we can use it to terminate .progress()\n    def start(self):\n        \"\"\"Thin wrapper around self._start\n\n        so we can hold onto a reference for the Future\n        start returns, which we can use to terminate\n        .progress()\n        \"\"\"\n        self._start_future = self._start()\n        return self._start_future\n\n    _last_event = None\n\n    @gen.coroutine\n    def _start(self):\n        \"\"\"Start the user's pod\"\"\"\n\n        # load user options (including profile)\n        yield self.load_user_options()\n\n        # record latest event so we don't include old\n        # events from previous pods in self.events\n        # track by order and name instead of uid\n        # so we get events like deletion of a previously stale\n        # pod if it's part of this spawn process\n        events = self.events\n        if events:\n            self._last_event = events[-1].metadata.uid\n\n        if self.storage_pvc_ensure:\n            # Try and create the pvc. If it succeeds we are good. If\n            # returns a 409 indicating it already exists we are good. If\n            # it returns a 403, indicating potential quota issue we need\n            # to see if pvc already exists before we decide to raise the\n            # error for quota being exceeded. This is because quota is\n            # checked before determining if the PVC needed to be\n            # created.\n\n            pvc = self.get_pvc_manifest()\n\n            try:\n                yield self.asynchronize(\n                    self.api.create_namespaced_persistent_volume_claim,\n                    namespace=self.namespace,\n                    body=pvc\n                )\n            except ApiException as e:\n                if e.status == 409:\n                    self.log.info(\"PVC \" + self.pvc_name + \" already exists, so did not create new pvc.\")\n\n                elif e.status == 403:\n                    t, v, tb = sys.exc_info()\n\n                    try:\n                        yield self.asynchronize(\n                            self.api.read_namespaced_persistent_volume_claim,\n                            name=self.pvc_name,\n                            namespace=self.namespace)\n\n                    except ApiException as e:\n                        raise v.with_traceback(tb)\n\n                    self.log.info(\"PVC \" + self.pvc_name + \" already exists, possibly have reached quota though.\")\n\n                else:\n                    raise\n\n        # If we run into a 409 Conflict error, it means a pod with the\n        # same name already exists. We stop it, wait for it to stop, and\n        # try again. We try 4 times, and if it still fails we give up.\n        # FIXME: Have better / cleaner retry logic!\n        retry_times = 4\n        pod = yield self.get_pod_manifest()\n        if self.modify_pod_hook:\n            pod = yield gen.maybe_future(self.modify_pod_hook(self, pod))\n        for i in range(retry_times):\n            try:\n                yield self.asynchronize(\n                    self.api.create_namespaced_pod,\n                    self.namespace,\n                    pod,\n                )\n                break\n            except ApiException as e:\n                if e.status != 409:\n                    # We only want to handle 409 conflict errors\n                    self.log.exception(\"Failed for %s\", pod.to_str())\n                    raise\n                self.log.info('Found existing pod %s, attempting to kill', self.pod_name)\n                # TODO: this should show up in events\n                yield self.stop(True)\n\n                self.log.info('Killed pod %s, will try starting singleuser pod again', self.pod_name)\n        else:\n            raise Exception(\n                'Can not create user pod %s already exists & could not be deleted' % self.pod_name)\n\n        # we need a timeout here even though start itself has a timeout\n        # in order for this coroutine to finish at some point.\n        # using the same start_timeout here\n        # essentially ensures that this timeout should never propagate up\n        # because the handler will have stopped waiting after\n        # start_timeout, starting from a slightly earlier point.\n        try:\n            yield exponential_backoff(\n                lambda: self.is_pod_running(self.pod_reflector.pods.get(self.pod_name, None)),\n                'pod/%s did not start in %s seconds!' % (self.pod_name, self.start_timeout),\n                timeout=self.start_timeout,\n            )\n        except TimeoutError:\n            if self.pod_name not in self.pod_reflector.pods:\n                # if pod never showed up at all,\n                # restart the pod reflector which may have become disconnected.\n                self.log.error(\n                    \"Pod %s never showed up in reflector, restarting pod reflector\",\n                    self.pod_name,\n                )\n                self._start_watching_pods(replace=True)\n            raise\n\n        pod = self.pod_reflector.pods[self.pod_name]\n        self.pod_id = pod.metadata.uid\n        if self.event_reflector:\n            self.log.debug(\n                'pod %s events before launch: %s',\n                self.pod_name,\n                \"\\n\".join(\n                    [\n                        \"%s [%s] %s\" % (event.last_timestamp or event.event_time, event.type, event.message)\n                        for event in self.events\n                    ]\n                ),\n            )\n        return (pod.status.pod_ip, self.port)\n\n    @gen.coroutine\n    def stop(self, now=False):\n        delete_options = client.V1DeleteOptions()\n\n        if now:\n            grace_seconds = 0\n        else:\n            grace_seconds = self.delete_grace_period\n\n        delete_options.grace_period_seconds = grace_seconds\n        self.log.info(\"Deleting pod %s\", self.pod_name)\n        try:\n            yield self.asynchronize(\n                self.api.delete_namespaced_pod,\n                name=self.pod_name,\n                namespace=self.namespace,\n                body=delete_options,\n                grace_period_seconds=grace_seconds,\n            )\n        except ApiException as e:\n            if e.status == 404:\n                self.log.warning(\n                    \"No pod %s to delete. Assuming already deleted.\",\n                    self.pod_name,\n                )\n            else:\n                raise\n        try:\n            yield exponential_backoff(\n                lambda: self.pod_reflector.pods.get(self.pod_name, None) is None,\n                'pod/%s did not disappear in %s seconds!' % (self.pod_name, self.start_timeout),\n                timeout=self.start_timeout,\n            )\n        except TimeoutError:\n            self.log.error(\"Pod %s did not disappear, restarting pod reflector\", self.pod_name)\n            self._start_watching_pods(replace=True)\n            raise\n\n    @default('env_keep')\n    def _env_keep_default(self):\n        return []\n\n    _profile_list = None\n\n    def _render_options_form(self, profile_list):\n        self._profile_list = self._init_profile_list(profile_list)\n        profile_form_template = Environment(loader=BaseLoader).from_string(self.profile_form_template)\n        return profile_form_template.render(profile_list=self._profile_list)\n\n    @gen.coroutine\n    def _render_options_form_dynamically(self, current_spawner):\n        profile_list = yield gen.maybe_future(self.profile_list(current_spawner))\n        profile_list = self._init_profile_list(profile_list)\n        return self._render_options_form(profile_list)\n\n    @default('options_form')\n    def _options_form_default(self):\n        '''\n        Build the form template according to the `profile_list` setting.\n\n        Returns:\n            '' when no `profile_list` has been defined\n            The rendered template (using jinja2) when `profile_list` is defined.\n        '''\n        if not self.profile_list:\n            return ''\n        if callable(self.profile_list):\n            return self._render_options_form_dynamically\n        else:\n            return self._render_options_form(self.profile_list)\n\n    def options_from_form(self, formdata):\n        \"\"\"get the option selected by the user on the form\n\n        This only constructs the user_options dict,\n        it should not actually load any options.\n        That is done later in `.load_user_options()`\n\n        Args:\n            formdata: user selection returned by the form\n\n        To access to the value, you can use the `get` accessor and the name of the html element,\n        for example::\n\n            formdata.get('profile',[0])\n\n        to get the value of the form named \"profile\", as defined in `form_template`::\n\n            <select class=\"form-control\" name=\"profile\"...>\n            </select>\n\n        Returns:\n            user_options (dict): the selected profile in the user_options form,\n                e.g. ``{\"profile\": \"cpus-8\"}``\n        \"\"\"\n        return {\n            'profile': formdata.get('profile', [None])[0]\n        }\n\n    @gen.coroutine\n    def _load_profile(self, slug):\n        \"\"\"Load a profile by name\n\n        Called by load_user_options\n        \"\"\"\n\n        # find the profile\n        default_profile = self._profile_list[0]\n        for profile in self._profile_list:\n            if profile.get('default', False):\n                # explicit default, not the first\n                default_profile = profile\n\n            if profile['slug'] == slug:\n                break\n        else:\n            if slug:\n                # name specified, but not found\n                raise ValueError(\"No such profile: %s. Options include: %s\" % (\n                    slug, ', '.join(p['slug'] for p in self._profile_list)\n                ))\n            else:\n                # no name specified, use the default\n                profile = default_profile\n\n        self.log.debug(\"Applying KubeSpawner override for profile '%s'\", profile['display_name'])\n        kubespawner_override = profile.get('kubespawner_override', {})\n        for k, v in kubespawner_override.items():\n            if callable(v):\n                v = v(self)\n                self.log.debug(\".. overriding KubeSpawner value %s=%s (callable result)\", k, v)\n            else:\n                self.log.debug(\".. overriding KubeSpawner value %s=%s\", k, v)\n            setattr(self, k, v)\n\n    # set of recognised user option keys\n    # used for warning about ignoring unrecognised options\n    _user_option_keys = {'profile',}\n\n    def _init_profile_list(self, profile_list):\n        # generate missing slug fields from display_name\n        for profile in profile_list:\n            if 'slug' not in profile:\n                profile['slug'] = slugify(profile['display_name'])\n\n        return profile_list\n\n    @gen.coroutine\n    def load_user_options(self):\n        \"\"\"Load user options from self.user_options dict\n\n        This can be set via POST to the API or via options_from_form\n\n        Only supported argument by default is 'profile'.\n        Override in subclasses to support other options.\n        \"\"\"\n\n        if self._profile_list is None:\n            if callable(self.profile_list):\n                profile_list = yield gen.maybe_future(self.profile_list(self))\n            else:\n                profile_list = self.profile_list\n\n            self._profile_list = self._init_profile_list(profile_list)\n\n        selected_profile = self.user_options.get('profile', None)\n        if self._profile_list:\n            yield self._load_profile(selected_profile)\n        elif selected_profile:\n            self.log.warning(\"Profile %r requested, but profiles are not enabled\", selected_profile)\n\n        # help debugging by logging any option fields that are not recognized\n        option_keys = set(self.user_options)\n        unrecognized_keys = option_keys.difference(self._user_option_keys)\n        if unrecognized_keys:\n            self.log.warning(\n                \"Ignoring unrecognized KubeSpawner user_options: %s\",\n                \", \".join(\n                    map(\n                        str,\n                        sorted(unrecognized_keys)\n                    )\n                )\n            )\n"], "fixing_code": ["\"\"\"\nJupyterHub Spawner to spawn user notebooks on a Kubernetes cluster.\n\nThis module exports `KubeSpawner` class, which is the actual spawner\nimplementation that should be used by JupyterHub.\n\"\"\"\n\nfrom functools import partial  # noqa\nfrom datetime import datetime\nimport json\nimport os\nimport sys\nimport string\nimport multiprocessing\nfrom concurrent.futures import ThreadPoolExecutor\nimport warnings\n\nfrom tornado import gen\nfrom tornado.ioloop import IOLoop\nfrom tornado.concurrent import run_on_executor\nfrom tornado import web\nfrom traitlets import (\n    Bool,\n    Dict,\n    Integer,\n    List,\n    Unicode,\n    Union,\n    default,\n    observe,\n    validate,\n)\nfrom jupyterhub.spawner import Spawner\nfrom jupyterhub.utils import exponential_backoff\nfrom jupyterhub.traitlets import Command\nfrom kubernetes.client.rest import ApiException\nfrom kubernetes import client\nimport escapism\nfrom jinja2 import Environment, BaseLoader\n\nfrom .clients import shared_client\nfrom kubespawner.traitlets import Callable\nfrom kubespawner.objects import make_pod, make_pvc\nfrom kubespawner.reflector import NamespacedResourceReflector\nfrom asyncio import sleep\nfrom async_generator import async_generator, yield_\nfrom slugify import slugify\n\nclass PodReflector(NamespacedResourceReflector):\n    \"\"\"\n    PodReflector is merely a configured NamespacedResourceReflector. It exposes\n    the pods property, which is simply mapping to self.resources where the\n    NamespacedResourceReflector keeps an updated list of the resource defined by\n    the `kind` field and the `list_method_name` field.\n    \"\"\"\n    kind = 'pods'\n    list_method_name = 'list_namespaced_pod'\n    # FUTURE: These labels are the selection labels for the PodReflector. We\n    # might want to support multiple deployments in the same namespace, so we\n    # would need to select based on additional labels such as `app` and\n    # `release`.\n    labels = {\n        'component': 'singleuser-server',\n    }\n\n    @property\n    def pods(self):\n        \"\"\"\n        A dictionary of the python kubernetes client's representation of pods\n        for the namespace. The dictionary keys are the pod ids and the values\n        are the actual pod resource representations.\n\n        ref: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.16/#pod-v1-core\n        \"\"\"\n        return self.resources\n\n\nclass EventReflector(NamespacedResourceReflector):\n    \"\"\"\n    EventsReflector is merely a configured NamespacedResourceReflector. It\n    exposes the events property, which is simply mapping to self.resources where\n    the NamespacedResourceReflector keeps an updated list of the resource\n    defined by the `kind` field and the `list_method_name` field.\n    \"\"\"\n    kind = 'events'\n    list_method_name = 'list_namespaced_event'\n\n    @property\n    def events(self):\n        \"\"\"\n        Returns list of the python kubernetes client's representation of k8s\n        events within the namespace, sorted by the latest event.\n\n        ref: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.16/#event-v1-core\n        \"\"\"\n\n        # NOTE:\n        # - self.resources is a dictionary with keys mapping unique ids of\n        #   Kubernetes Event resources, updated by NamespacedResourceReflector.\n        #   self.resources will builds up with incoming k8s events, but can also\n        #   suddenly refreshes itself entirely. We should not assume a call to\n        #   this dictionary's values will result in a consistently ordered list,\n        #   so we sort it to get it somewhat more structured.\n        # - We either seem to get only event.last_timestamp or event.event_time,\n        #   both fields serve the same role but the former is a low resolution\n        #   timestamp without and the other is a higher resolution timestamp.\n        return sorted(\n            self.resources.values(),\n            key=lambda event: event.last_timestamp or event.event_time,\n        )\n\n\nclass MockObject(object):\n    pass\n\nclass KubeSpawner(Spawner):\n    \"\"\"\n    A JupyterHub spawner that spawn pods in a Kubernetes Cluster. Each server\n    spawned by a user will have its own KubeSpawner instance.\n    \"\"\"\n\n    # We want to have one single threadpool executor that is shared across all\n    # KubeSpawner instances, so we apply a Singleton pattern. We initialize this\n    # class variable from the first KubeSpawner instance that is created and\n    # then reference it from all instances. The same goes for the PodReflector\n    # and EventReflector.\n    executor = None\n    reflectors = {\n        \"pods\": None,\n        \"events\": None,\n    }\n\n    @property\n    def pod_reflector(self):\n        \"\"\"\n        A convinience alias to the class variable reflectors['pods'].\n        \"\"\"\n        return self.__class__.reflectors['pods']\n\n    @property\n    def event_reflector(self):\n        \"\"\"\n        A convninience alias to the class variable reflectors['events'] if the\n        spawner instance has events_enabled.\n        \"\"\"\n        if self.events_enabled:\n            return self.__class__.reflectors['events']\n\n    def __init__(self, *args, **kwargs):\n        _mock = kwargs.pop('_mock', False)\n        super().__init__(*args, **kwargs)\n\n        if _mock:\n            # runs during test execution only\n            if 'user' not in kwargs:\n                user = MockObject()\n                user.name = 'mock_name'\n                user.id = 'mock_id'\n                user.url = 'mock_url'\n                self.user = user\n\n            if 'hub' not in kwargs:\n                hub = MockObject()\n                hub.public_host = 'mock_public_host'\n                hub.url = 'mock_url'\n                hub.base_url = 'mock_base_url'\n                hub.api_url = 'mock_api_url'\n                self.hub = hub\n        else:\n            # runs during normal execution only\n\n            # By now, all the traitlets have been set, so we can use them to compute\n            # other attributes\n            if self.__class__.executor is None:\n                self.__class__.executor = ThreadPoolExecutor(\n                    max_workers=self.k8s_api_threadpool_workers\n                )\n\n            # This will start watching in __init__, so it'll start the first\n            # time any spawner object is created. Not ideal but works!\n            self._start_watching_pods()\n            if self.events_enabled:\n                self._start_watching_events()\n\n            self.api = shared_client('CoreV1Api')\n\n        # runs during both test and normal execution\n        self.pod_name = self._expand_user_properties(self.pod_name_template)\n        self.pvc_name = self._expand_user_properties(self.pvc_name_template)\n        if self.working_dir:\n            self.working_dir = self._expand_user_properties(self.working_dir)\n        if self.port == 0:\n            # Our default port is 8888\n            self.port = 8888\n\n    k8s_api_threadpool_workers = Integer(\n        # Set this explicitly, since this is the default in Python 3.5+\n        # but not in 3.4\n        5 * multiprocessing.cpu_count(),\n        config=True,\n        help=\"\"\"\n        Number of threads in thread pool used to talk to the k8s API.\n\n        Increase this if you are dealing with a very large number of users.\n\n        Defaults to `5 * cpu_cores`, which is the default for `ThreadPoolExecutor`.\n        \"\"\"\n    )\n\n    events_enabled = Bool(\n        True,\n        config=True,\n        help=\"\"\"\n        Enable event-watching for progress-reports to the user spawn page.\n\n        Disable if these events are not desirable\n        or to save some performance cost.\n        \"\"\"\n    )\n\n    namespace = Unicode(\n        config=True,\n        help=\"\"\"\n        Kubernetes namespace to spawn user pods in.\n\n        If running inside a kubernetes cluster with service accounts enabled,\n        defaults to the current namespace. If not, defaults to `default`\n        \"\"\"\n    )\n\n    @default('namespace')\n    def _namespace_default(self):\n        \"\"\"\n        Set namespace default to current namespace if running in a k8s cluster\n\n        If not in a k8s cluster with service accounts enabled, default to\n        `default`\n        \"\"\"\n        ns_path = '/var/run/secrets/kubernetes.io/serviceaccount/namespace'\n        if os.path.exists(ns_path):\n            with open(ns_path) as f:\n                return f.read().strip()\n        return 'default'\n\n    ip = Unicode(\n        '0.0.0.0',\n        config=True,\n        help=\"\"\"\n        The IP address (or hostname) the single-user server should listen on.\n\n        We override this from the parent so we can set a more sane default for\n        the Kubernetes setup.\n        \"\"\"\n    )\n\n    cmd = Command(\n        None,\n        allow_none=True,\n        minlen=0,\n        config=True,\n        help=\"\"\"\n        The command used for starting the single-user server.\n\n        Provide either a string or a list containing the path to the startup script command. Extra arguments,\n        other than this path, should be provided via `args`.\n\n        This is usually set if you want to start the single-user server in a different python\n        environment (with virtualenv/conda) than JupyterHub itself.\n\n        Some spawners allow shell-style expansion here, allowing you to use environment variables.\n        Most, including the default, do not. Consult the documentation for your spawner to verify!\n\n        If set to `None`, Kubernetes will start the `CMD` that is specified in the Docker image being started.\n        \"\"\"\n    )\n\n    # FIXME: Don't override 'default_value' (\"\") or 'allow_none' (False) (Breaking change)\n    working_dir = Unicode(\n        None,\n        allow_none=True,\n        config=True,\n        help=\"\"\"\n        The working directory where the Notebook server will be started inside the container.\n        Defaults to `None` so the working directory will be the one defined in the Dockerfile.\n\n        `{username}` is expanded to the escaped, dns-label safe username.\n        \"\"\"\n    )\n\n    # FIXME: Don't override 'default_value' (\"\") or 'allow_none' (False) (Breaking change)\n    service_account = Unicode(\n        None,\n        allow_none=True,\n        config=True,\n        help=\"\"\"\n        The service account to be mounted in the spawned user pod.\n\n        When set to `None` (the default), no service account is mounted, and the default service account\n        is explicitly disabled.\n\n        This `serviceaccount` must already exist in the namespace the user pod is being spawned in.\n\n        WARNING: Be careful with this configuration! Make sure the service account being mounted\n        has the minimal permissions needed, and nothing more. When misconfigured, this can easily\n        give arbitrary users root over your entire cluster.\n        \"\"\"\n    )\n\n    pod_name_template = Unicode(\n        'jupyter-{username}--{servername}',\n        config=True,\n        help=\"\"\"\n        Template to use to form the name of user's pods.\n\n        `{username}` is expanded to the escaped, dns-label-safe username.\n        `{servername}` is expanded to the escaped, dns-label-safe server name, if any.\n\n        Trailing `-` characters are stripped for safe handling of empty server names (user default servers).\n\n        This must be unique within the namespace the pods are being spawned\n        in, so if you are running multiple jupyterhubs spawning in the\n        same namespace, consider setting this to be something more unique.\n\n        .. versionchanged:: 0.12\n            `--` delimiter added to the template,\n            where it was implicitly added to the `servername` field before.\n            Additionally, `username--servername` delimiter was `-` instead of `--`,\n            allowing collisions in certain circumstances.\n        \"\"\"\n    )\n\n    storage_pvc_ensure = Bool(\n        False,\n        config=True,\n        help=\"\"\"\n        Ensure that a PVC exists for each user before spawning.\n\n        Set to true to create a PVC named with `pvc_name_template` if it does\n        not exist for the user when their pod is spawning.\n        \"\"\"\n    )\n\n    pvc_name_template = Unicode(\n        'claim-{username}--{servername}',\n        config=True,\n        help=\"\"\"\n        Template to use to form the name of user's pvc.\n\n        `{username}` is expanded to the escaped, dns-label safe username.\n        `{servername}` is expanded to the escaped, dns-label-safe server name, if any.\n\n        Trailing `-` characters are stripped for safe handling of empty server names (user default servers).\n\n        This must be unique within the namespace the pvc are being spawned\n        in, so if you are running multiple jupyterhubs spawning in the\n        same namespace, consider setting this to be something more unique.\n\n        .. versionchanged:: 0.12\n            `--` delimiter added to the template,\n            where it was implicitly added to the `servername` field before.\n            Additionally, `username--servername` delimiter was `-` instead of `--`,\n            allowing collisions in certain circumstances.\n        \"\"\"\n    )\n\n    # FIXME: Don't override 'default_value' (\"\") or 'allow_none' (False) (Breaking change)\n    hub_connect_ip = Unicode(\n        allow_none=True,\n        config=True,\n        help=\"\"\"DEPRECATED. Use c.JupyterHub.hub_connect_ip\"\"\"\n    )\n\n    hub_connect_port = Integer(\n        config=True,\n        help=\"\"\"DEPRECATED. Use c.JupyterHub.hub_connect_url\"\"\"\n    )\n\n    @observe('hub_connect_ip', 'hub_connect_port')\n    def _deprecated_changed(self, change):\n        warnings.warn(\"\"\"\n            KubeSpawner.{0} is deprecated with JupyterHub >= 0.8.\n            Use JupyterHub.{0}\n            \"\"\".format(change.name),\n            DeprecationWarning)\n        setattr(self.hub, change.name.split('_', 1)[1], change.new)\n\n    common_labels = Dict(\n        {\n            'app': 'jupyterhub',\n            'heritage': 'jupyterhub',\n        },\n        config=True,\n        help=\"\"\"\n        Kubernetes labels that both spawned singleuser server pods and created\n        user PVCs will get.\n\n        Note that these are only set when the Pods and PVCs are created, not\n        later when this setting is updated.\n        \"\"\"\n    )\n\n    extra_labels = Dict(\n        config=True,\n        help=\"\"\"\n        Extra kubernetes labels to set on the spawned single-user pods.\n\n        The keys and values specified here would be set as labels on the spawned single-user\n        kubernetes pods. The keys and values must both be strings that match the kubernetes\n        label key / value constraints.\n\n        See `the Kubernetes documentation <https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/>`__\n        for more info on what labels are and why you might want to use them!\n\n        `{username}` is expanded to the escaped, dns-label safe username.\n        \"\"\"\n    )\n\n    extra_annotations = Dict(\n        config=True,\n        help=\"\"\"\n        Extra Kubernetes annotations to set on the spawned single-user pods.\n\n        The keys and values specified here are added as annotations on the spawned single-user\n        kubernetes pods. The keys and values must both be strings.\n\n        See `the Kubernetes documentation <https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/>`__\n        for more info on what annotations are and why you might want to use them!\n\n        `{username}` is expanded to the escaped, dns-label safe username.\n        \"\"\"\n    )\n\n    image = Unicode(\n        'jupyterhub/singleuser:latest',\n        config=True,\n        help=\"\"\"\n        Docker image to use for spawning user's containers.\n\n        Defaults to `jupyterhub/singleuser:latest`\n\n        Name of the container + a tag, same as would be used with\n        a `docker pull` command. If tag is set to `latest`, kubernetes will\n        check the registry each time a new user is spawned to see if there\n        is a newer image available. If available, new image will be pulled.\n        Note that this could cause long delays when spawning, especially\n        if the image is large. If you do not specify a tag, whatever version\n        of the image is first pulled on the node will be used, thus possibly\n        leading to inconsistent images on different nodes. For all these\n        reasons, it is recommended to specify a specific immutable tag\n        for the image.\n\n        If your image is very large, you might need to increase the timeout\n        for starting the single user container from the default. You can\n        set this with::\n\n           c.KubeSpawner.start_timeout = 60 * 5  # Up to 5 minutes\n\n        \"\"\"\n    )\n\n    image_pull_policy = Unicode(\n        'IfNotPresent',\n        config=True,\n        help=\"\"\"\n        The image pull policy of the docker container specified in\n        `image`.\n\n        Defaults to `IfNotPresent` which causes the Kubelet to NOT pull the image\n        specified in KubeSpawner.image if it already exists, except if the tag\n        is `:latest`. For more information on image pull policy,\n        refer to `the Kubernetes documentation <https://kubernetes.io/docs/concepts/containers/images/>`__.\n\n\n        This configuration is primarily used in development if you are\n        actively changing the `image_spec` and would like to pull the image\n        whenever a user container is spawned.\n        \"\"\"\n    )\n\n    # FIXME: Don't override 'default_value' (\"\") or 'allow_none' (False) (Breaking change)\n    image_pull_secrets = Unicode(\n        None,\n        allow_none=True,\n        config=True,\n        help=\"\"\"\n        The kubernetes secret to use for pulling images from private repository.\n\n        Set this to the name of a Kubernetes secret containing the docker configuration\n        required to pull the image.\n\n        See `the Kubernetes documentation <https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod>`__\n        for more information on when and why this might need to be set, and what\n        it should be set to.\n        \"\"\"\n    )\n\n    node_selector = Dict(\n        config=True,\n        help=\"\"\"\n        The dictionary Selector labels used to match the Nodes where Pods will be launched.\n\n        Default is None and means it will be launched in any available Node.\n\n        For example to match the Nodes that have a label of `disktype: ssd` use::\n\n           c.KubeSpawner.node_selector = {'disktype': 'ssd'}\n        \"\"\"\n    )\n\n    uid = Union(\n        trait_types=[\n            Integer(),\n            Callable(),\n        ],\n        allow_none=True,\n        config=True,\n        help=\"\"\"\n        The UID to run the single-user server containers as.\n\n        This UID should ideally map to a user that already exists in the container\n        image being used. Running as root is discouraged.\n\n        Instead of an integer, this could also be a callable that takes as one\n        parameter the current spawner instance and returns an integer. The callable\n        will be called asynchronously if it returns a future. Note that\n        the interface of the spawner class is not deemed stable across versions,\n        so using this functionality might cause your JupyterHub or kubespawner\n        upgrades to break.\n\n        If set to `None`, the user specified with the `USER` directive in the\n        container metadata is used.\n        \"\"\"\n    )\n\n    gid = Union(\n        trait_types=[\n            Integer(),\n            Callable(),\n        ],\n        allow_none=True,\n        config=True,\n        help=\"\"\"\n        The GID to run the single-user server containers as.\n\n        This GID should ideally map to a group that already exists in the container\n        image being used. Running as root is discouraged.\n\n        Instead of an integer, this could also be a callable that takes as one\n        parameter the current spawner instance and returns an integer. The callable\n        will be called asynchronously if it returns a future. Note that\n        the interface of the spawner class is not deemed stable across versions,\n        so using this functionality might cause your JupyterHub or kubespawner\n        upgrades to break.\n\n        If set to `None`, the group of the user specified with the `USER` directive\n        in the container metadata is used.\n        \"\"\"\n    )\n\n    fs_gid = Union(\n        trait_types=[\n            Integer(),\n            Callable(),\n        ],\n        allow_none=True,\n        config=True,\n        help=\"\"\"\n        The GID of the group that should own any volumes that are created & mounted.\n\n        A special supplemental group that applies primarily to the volumes mounted\n        in the single-user server. In volumes from supported providers, the following\n        things happen:\n\n          1. The owning GID will be the this GID\n          2. The setgid bit is set (new files created in the volume will be owned by\n             this GID)\n          3. The permission bits are OR\u2019d with rw-rw\n\n        The single-user server will also be run with this gid as part of its supplemental\n        groups.\n\n        Instead of an integer, this could also be a callable that takes as one\n        parameter the current spawner instance and returns an integer. The callable will\n        be called asynchronously if it returns a future, rather than an int. Note that\n        the interface of the spawner class is not deemed stable across versions,\n        so using this functionality might cause your JupyterHub or kubespawner\n        upgrades to break.\n\n        You'll *have* to set this if you are using auto-provisioned volumes with most\n        cloud providers. See `fsGroup <https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#podsecuritycontext-v1-core>`_\n        for more details.\n        \"\"\"\n    )\n\n    supplemental_gids = Union(\n        trait_types=[\n            List(),\n            Callable(),\n        ],\n        config=True,\n        help=\"\"\"\n        A list of GIDs that should be set as additional supplemental groups to the\n        user that the container runs as.\n\n        Instead of a list of integers, this could also be a callable that takes as one\n        parameter the current spawner instance and returns a list of integers. The\n        callable will be called asynchronously if it returns a future, rather than\n        a list. Note that the interface of the spawner class is not deemed stable\n        across versions, so using this functionality might cause your JupyterHub\n        or kubespawner upgrades to break.\n\n        You may have to set this if you are deploying to an environment with RBAC/SCC\n        enforced and pods run with a 'restricted' SCC which results in the image being\n        run as an assigned user ID. The supplemental group IDs would need to include\n        the corresponding group ID of the user ID the image normally would run as. The\n        image must setup all directories/files any application needs access to, as group\n        writable.\n        \"\"\"\n    )\n\n    privileged = Bool(\n        False,\n        config=True,\n        help=\"\"\"\n        Whether to run the pod with a privileged security context.\n        \"\"\"\n    )\n\n    modify_pod_hook = Callable(\n        None,\n        allow_none=True,\n        config=True,\n        help=\"\"\"\n        Callable to augment the Pod object before launching.\n\n        Expects a callable that takes two parameters:\n\n           1. The spawner object that is doing the spawning\n           2. The Pod object that is to be launched\n\n        You should modify the Pod object and return it.\n\n        This can be a coroutine if necessary. When set to none, no augmenting is done.\n\n        This is very useful if you want to modify the pod being launched dynamically.\n        Note that the spawner object can change between versions of KubeSpawner and JupyterHub,\n        so be careful relying on this!\n        \"\"\"\n    )\n\n    volumes = List(\n        config=True,\n        help=\"\"\"\n        List of Kubernetes Volume specifications that will be mounted in the user pod.\n\n        This list will be directly added under `volumes` in the kubernetes pod spec,\n        so you should use the same structure. Each item in the list must have the\n        following two keys:\n\n          - `name`\n            Name that'll be later used in the `volume_mounts` config to mount this\n            volume at a specific path.\n          - `<name-of-a-supported-volume-type>` (such as `hostPath`, `persistentVolumeClaim`,\n            etc)\n            The key name determines the type of volume to mount, and the value should\n            be an object specifying the various options available for that kind of\n            volume.\n\n        See `the Kubernetes documentation <https://kubernetes.io/docs/concepts/storage/volumes>`__\n        for more information on the various kinds of volumes available and their options.\n        Your kubernetes cluster must already be configured to support the volume types you want to use.\n\n        `{username}` is expanded to the escaped, dns-label safe username.\n        \"\"\"\n    )\n\n    volume_mounts = List(\n        config=True,\n        help=\"\"\"\n        List of paths on which to mount volumes in the user notebook's pod.\n\n        This list will be added to the values of the `volumeMounts` key under the user's\n        container in the kubernetes pod spec, so you should use the same structure as that.\n        Each item in the list should be a dictionary with at least these two keys:\n\n           - `mountPath` The path on the container in which we want to mount the volume.\n           - `name` The name of the volume we want to mount, as specified in the `volumes` config.\n\n        See `the Kubernetes documentation <https://kubernetes.io/docs/concepts/storage/volumes>`__\n        for more information on how the `volumeMount` item works.\n\n        `{username}` is expanded to the escaped, dns-label safe username.\n        \"\"\"\n    )\n\n    # FIXME: Don't override 'default_value' (\"\") or 'allow_none' (False) (Breaking change)\n    storage_capacity = Unicode(\n        None,\n        config=True,\n        allow_none=True,\n        help=\"\"\"\n        The amount of storage space to request from the volume that the pvc will\n        mount to. This amount will be the amount of storage space the user has\n        to work with on their notebook. If left blank, the kubespawner will not\n        create a pvc for the pod.\n\n        This will be added to the `resources: requests: storage:` in the k8s pod spec.\n\n        See `the Kubernetes documentation <https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims>`__\n        for more information on how storage works.\n\n        Quantities can be represented externally as unadorned integers, or as fixed-point\n        integers with one of these SI suffices (`E, P, T, G, M, K, m`) or their power-of-two\n        equivalents (`Ei, Pi, Ti, Gi, Mi, Ki`). For example, the following represent roughly\n        the same value: `128974848`, `129e6`, `129M`, `123Mi`.\n        \"\"\"\n    )\n\n    storage_extra_labels = Dict(\n        config=True,\n        help=\"\"\"\n        Extra kubernetes labels to set on the user PVCs.\n\n        The keys and values specified here would be set as labels on the PVCs\n        created by kubespawner for the user. Note that these are only set\n        when the PVC is created, not later when this setting is updated.\n\n        See `the Kubernetes documentation <https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/>`__\n        for more info on what labels are and why you might want to use them!\n\n        `{username}` is expanded to the escaped, dns-label safe username.\n        \"\"\"\n    )\n\n    # FIXME: Don't override 'default_value' (\"\") or 'allow_none' (False) (Breaking change)\n    storage_class = Unicode(\n        None,\n        config=True,\n        allow_none=True,\n        help=\"\"\"\n        The storage class that the pvc will use.\n\n        This will be added to the `annotations: volume.beta.kubernetes.io/storage-class:`\n        in the pvc metadata.\n\n        This will determine what type of volume the pvc will request to use. If one exists\n        that matches the criteria of the StorageClass, the pvc will mount to that. Otherwise,\n        b/c it has a storage class, k8s will dynamically spawn a pv for the pvc to bind to\n        and a machine in the cluster for the pv to bind to.\n\n        Note that an empty string is a valid value and is always interpreted to be\n        requesting a pv with no class.\n\n        See `the Kubernetes documentation <https://kubernetes.io/docs/concepts/storage/storage-classes/>`__\n        for more information on how StorageClasses work.\n\n        \"\"\"\n    )\n\n    storage_access_modes = List(\n        [\"ReadWriteOnce\"],\n        config=True,\n        help=\"\"\"\n        List of access modes the user has for the pvc.\n\n        The access modes are:\n\n            - `ReadWriteOnce` \u2013 the volume can be mounted as read-write by a single node\n            - `ReadOnlyMany` \u2013 the volume can be mounted read-only by many nodes\n            - `ReadWriteMany` \u2013 the volume can be mounted as read-write by many nodes\n\n        See `the Kubernetes documentation <https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes>`__\n        for more information on how access modes work.\n        \"\"\"\n    )\n\n    storage_selector = Dict(\n        config=True,\n        help=\"\"\"\n        The dictionary Selector labels used to match a PersistentVolumeClaim to\n        a PersistentVolume.\n\n        Default is None and means it will match based only on other storage criteria.\n\n        For example to match the Nodes that have a label of `content: jupyter` use::\n\n           c.KubeSpawner.storage_selector = {'matchLabels':{'content': 'jupyter'}}\n        \"\"\"\n    )\n\n    lifecycle_hooks = Dict(\n        config=True,\n        help=\"\"\"\n        Kubernetes lifecycle hooks to set on the spawned single-user pods.\n\n        The keys is name of hooks and there are only two hooks, postStart and preStop.\n        The values are handler of hook which executes by Kubernetes management system when hook is called.\n\n        Below is an sample copied from\n        `the Kubernetes documentation <https://kubernetes.io/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/>`__::\n\n\n            c.KubeSpawner.lifecycle_hooks = {\n                \"postStart\": {\n                    \"exec\": {\n                        \"command\": [\"/bin/sh\", \"-c\", \"echo Hello from the postStart handler > /usr/share/message\"]\n                    }\n                },\n                \"preStop\": {\n                    \"exec\": {\n                        \"command\": [\"/usr/sbin/nginx\", \"-s\", \"quit\"]\n                    }\n                }\n            }\n\n        See `the Kubernetes documentation <https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/>`__\n        for more info on what lifecycle hooks are and why you might want to use them!\n        \"\"\"\n    )\n\n    init_containers = List(\n        config=True,\n        help=\"\"\"\n        List of initialization containers belonging to the pod.\n\n        This list will be directly added under `initContainers` in the kubernetes pod spec,\n        so you should use the same structure. Each item in the dict must a field\n        of the `V1Container specification <https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#container-v1-core>`_.\n\n        One usage is disabling access to metadata service from single-user\n        notebook server with configuration below::\n\n            c.KubeSpawner.init_containers = [{\n                \"name\": \"init-iptables\",\n                \"image\": \"<image with iptables installed>\",\n                \"command\": [\"iptables\", \"-A\", \"OUTPUT\", \"-p\", \"tcp\", \"--dport\", \"80\", \"-d\", \"169.254.169.254\", \"-j\", \"DROP\"],\n                \"securityContext\": {\n                    \"capabilities\": {\n                        \"add\": [\"NET_ADMIN\"]\n                    }\n                }\n            }]\n\n\n        See `the Kubernetes documentation <https://kubernetes.io/docs/concepts/workloads/pods/init-containers/>`__\n        for more info on what init containers are and why you might want to use them!\n\n        To user this feature, Kubernetes version must greater than 1.6.\n        \"\"\"\n    )\n\n    extra_container_config = Dict(\n        config=True,\n        help=\"\"\"\n        Extra configuration (e.g. ``envFrom``) for notebook container which is not covered by other attributes.\n\n        This dict will be directly merge into `container` of notebook server,\n        so you should use the same structure. Each item in the dict must a field\n        of the `V1Container specification <https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#container-v1-core>`_.\n\n        One usage is set ``envFrom`` on notebook container with configuration below::\n\n            c.KubeSpawner.extra_container_config = {\n                \"envFrom\": [{\n                    \"configMapRef\": {\n                        \"name\": \"special-config\"\n                    }\n                }]\n            }\n\n        The key could be either a camelCase word (used by Kubernetes yaml, e.g.\n        ``envFrom``) or a snake_case word (used by Kubernetes Python client,\n        e.g. ``env_from``).\n        \"\"\"\n    )\n\n    extra_pod_config = Dict(\n        config=True,\n        help=\"\"\"\n        Extra configuration for the pod which is not covered by other attributes.\n\n        This dict will be directly merge into pod,so you should use the same structure.\n        Each item in the dict is field of pod configuration\n        which follows spec at https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#podspec-v1-core.\n\n        One usage is set restartPolicy and dnsPolicy with configuration below::\n\n            c.KubeSpawner.extra_pod_config = {\n                \"restartPolicy\": \"OnFailure\",\n                \"dns_policy\": \"ClusterFirstWithHostNet\"\n            }\n\n        The `key` could be either a camelCase word (used by Kubernetes yaml,\n        e.g. `restartPolicy`) or a snake_case word (used by Kubernetes Python\n        client, e.g. `dns_policy`).\n        \"\"\"\n    )\n\n    extra_containers = List(\n        config=True,\n        help=\"\"\"\n        List of containers belonging to the pod which besides to the container generated for notebook server.\n\n        This list will be directly appended under `containers` in the kubernetes pod spec,\n        so you should use the same structure. Each item in the list is container configuration\n        which follows spec at https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#container-v1-core.\n\n        One usage is setting crontab in a container to clean sensitive data with configuration below::\n\n            c.KubeSpawner.extra_containers = [{\n                \"name\": \"crontab\",\n                \"image\": \"supercronic\",\n                \"command\": [\"/usr/local/bin/supercronic\", \"/etc/crontab\"]\n            }]\n\n        `{username}` is expanded to the escaped, dns-label safe username.\n        \"\"\"\n    )\n\n    # FIXME: Don't override 'default_value' (\"\") or 'allow_none' (False) (Breaking change)\n    scheduler_name = Unicode(\n        None,\n        allow_none=True,\n        config=True,\n        help=\"\"\"\n        Set the pod's scheduler explicitly by name. See `the Kubernetes documentation <https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#podspec-v1-core>`__\n        for more information.\n        \"\"\"\n    )\n\n    tolerations = List(\n        config=True,\n        help=\"\"\"\n        List of tolerations that are to be assigned to the pod in order to be able to schedule the pod\n        on a node with the corresponding taints. See the official Kubernetes documentation for additional details\n        https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n\n        Pass this field an array of `\"Toleration\" objects\n        <https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#nodeselectorterm-v1-core>`__\n\n        Example::\n\n            [\n                {\n                    'key': 'key',\n                    'operator': 'Equal',\n                    'value': 'value',\n                    'effect': 'NoSchedule'\n                },\n                {\n                    'key': 'key',\n                    'operator': 'Exists',\n                    'effect': 'NoSchedule'\n                }\n            ]\n\n        \"\"\"\n    )\n\n    node_affinity_preferred = List(\n        config=True,\n        help=\"\"\"\n        Affinities describe where pods prefer or require to be scheduled, they\n        may prefer or require a node to have a certain label or be in proximity\n        / remoteness to another pod. To learn more visit\n        https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n\n        Pass this field an array of \"PreferredSchedulingTerm\" objects.*\n        * https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#preferredschedulingterm-v1-core\n        \"\"\"\n    )\n    node_affinity_required = List(\n        config=True,\n        help=\"\"\"\n        Affinities describe where pods prefer or require to be scheduled, they\n        may prefer or require a node to have a certain label or be in proximity\n        / remoteness to another pod. To learn more visit\n        https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n\n        Pass this field an array of \"NodeSelectorTerm\" objects.*\n        * https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#nodeselectorterm-v1-core\n        \"\"\"\n    )\n    pod_affinity_preferred = List(\n        config=True,\n        help=\"\"\"\n        Affinities describe where pods prefer or require to be scheduled, they\n        may prefer or require a node to have a certain label or be in proximity\n        / remoteness to another pod. To learn more visit\n        https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n\n        Pass this field an array of \"WeightedPodAffinityTerm\" objects.*\n        * https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#weightedpodaffinityterm-v1-core\n        \"\"\"\n    )\n    pod_affinity_required = List(\n        config=True,\n        help=\"\"\"\n        Affinities describe where pods prefer or require to be scheduled, they\n        may prefer or require a node to have a certain label or be in proximity\n        / remoteness to another pod. To learn more visit\n        https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n\n        Pass this field an array of \"PodAffinityTerm\" objects.*\n        * https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#podaffinityterm-v1-core\n        \"\"\"\n    )\n    pod_anti_affinity_preferred = List(\n        config=True,\n        help=\"\"\"\n        Affinities describe where pods prefer or require to be scheduled, they\n        may prefer or require a node to have a certain label or be in proximity\n        / remoteness to another pod. To learn more visit\n        https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n\n        Pass this field an array of \"WeightedPodAffinityTerm\" objects.*\n        * https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#weightedpodaffinityterm-v1-core\n        \"\"\"\n    )\n    pod_anti_affinity_required = List(\n        config=True,\n        help=\"\"\"\n        Affinities describe where pods prefer or require to be scheduled, they\n        may prefer or require a node to have a certain label or be in proximity\n        / remoteness to another pod. To learn more visit\n        https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n\n        Pass this field an array of \"PodAffinityTerm\" objects.*\n        * https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#podaffinityterm-v1-core\n        \"\"\"\n    )\n\n    extra_resource_guarantees = Dict(\n        config=True,\n        help=\"\"\"\n        The dictionary used to request arbitrary resources.\n        Default is None and means no additional resources are requested.\n        For example, to request 1 Nvidia GPUs::\n\n            c.KubeSpawner.extra_resource_guarantees = {\"nvidia.com/gpu\": \"1\"}\n        \"\"\"\n    )\n\n    extra_resource_limits = Dict(\n        config=True,\n        help=\"\"\"\n        The dictionary used to limit arbitrary resources.\n        Default is None and means no additional resources are limited.\n        For example, to add a limit of 3 Nvidia GPUs::\n\n            c.KubeSpawner.extra_resource_limits = {\"nvidia.com/gpu\": \"3\"}\n        \"\"\"\n    )\n\n    delete_stopped_pods = Bool(\n        True,\n        config=True,\n        help=\"\"\"\n        Whether to delete pods that have stopped themselves.\n        Set to False to leave stopped pods in the completed state,\n        allowing for easier debugging of why they may have stopped.\n        \"\"\"\n    )\n\n    profile_form_template = Unicode(\n        \"\"\"\n        <script>\n        // JupyterHub 0.8 applied form-control indisciminately to all form elements.\n        // Can be removed once we stop supporting JupyterHub 0.8\n        $(document).ready(function() {\n            $('#kubespawner-profiles-list input[type=\"radio\"]').removeClass('form-control');\n        });\n        </script>\n        <style>\n        /* The profile description should not be bold, even though it is inside the <label> tag */\n        #kubespawner-profiles-list label p {\n            font-weight: normal;\n        }\n        </style>\n\n        <div class='form-group' id='kubespawner-profiles-list'>\n        {% for profile in profile_list %}\n        <label for='profile-item-{{ profile.slug }}' class='form-control input-group'>\n            <div class='col-md-1'>\n                <input type='radio' name='profile' id='profile-item-{{ profile.slug }}' value='{{ profile.slug }}' {% if profile.default %}checked{% endif %} />\n            </div>\n            <div class='col-md-11'>\n                <strong>{{ profile.display_name }}</strong>\n                {% if profile.description %}\n                <p>{{ profile.description }}</p>\n                {% endif %}\n            </div>\n        </label>\n        {% endfor %}\n        </div>\n        \"\"\",\n        config=True,\n        help=\"\"\"\n        Jinja2 template for constructing profile list shown to user.\n\n        Used when `profile_list` is set.\n\n        The contents of `profile_list` are passed in to the template.\n        This should be used to construct the contents of a HTML form. When\n        posted, this form is expected to have an item with name `profile` and\n        the value the index of the profile in `profile_list`.\n        \"\"\"\n    )\n\n    profile_list = Union(\n        trait_types=[\n            List(trait=Dict()),\n            Callable()\n        ],\n        config=True,\n        help=\"\"\"\n        List of profiles to offer for selection by the user.\n\n        Signature is: `List(Dict())`, where each item is a dictionary that has two keys:\n\n        - `display_name`: the human readable display name (should be HTML safe)\n        - `slug`: the machine readable slug to identify the profile\n          (missing slugs are generated from display_name)\n        - `description`: Optional description of this profile displayed to the user.\n        - `kubespawner_override`: a dictionary with overrides to apply to the KubeSpawner\n          settings. Each value can be either the final value to change or a callable that\n          take the `KubeSpawner` instance as parameter and return the final value.\n        - `default`: (optional Bool) True if this is the default selected option\n\n        Example::\n\n            c.KubeSpawner.profile_list = [\n                {\n                    'display_name': 'Training Env - Python',\n                    'slug': 'training-python',\n                    'default': True,\n                    'kubespawner_override': {\n                        'image': 'training/python:label',\n                        'cpu_limit': 1,\n                        'mem_limit': '512M',\n                    }\n                }, {\n                    'display_name': 'Training Env - Datascience',\n                    'slug': 'training-datascience',\n                    'kubespawner_override': {\n                        'image': 'training/datascience:label',\n                        'cpu_limit': 4,\n                        'mem_limit': '8G',\n                    }\n                }, {\n                    'display_name': 'DataScience - Small instance',\n                    'slug': 'datascience-small',\n                    'kubespawner_override': {\n                        'image': 'datascience/small:label',\n                        'cpu_limit': 10,\n                        'mem_limit': '16G',\n                    }\n                }, {\n                    'display_name': 'DataScience - Medium instance',\n                    'slug': 'datascience-medium',\n                    'kubespawner_override': {\n                        'image': 'datascience/medium:label',\n                        'cpu_limit': 48,\n                        'mem_limit': '96G',\n                    }\n                }, {\n                    'display_name': 'DataScience - Medium instance (GPUx2)',\n                    'slug': 'datascience-gpu2x',\n                    'kubespawner_override': {\n                        'image': 'datascience/medium:label',\n                        'cpu_limit': 48,\n                        'mem_limit': '96G',\n                        'extra_resource_guarantees': {\"nvidia.com/gpu\": \"2\"},\n                    }\n                }\n            ]\n\n        Instead of a list of dictionaries, this could also be a callable that takes as one\n        parameter the current spawner instance and returns a list of dictionaries. The\n        callable will be called asynchronously if it returns a future, rather than\n        a list. Note that the interface of the spawner class is not deemed stable\n        across versions, so using this functionality might cause your JupyterHub\n        or kubespawner upgrades to break.\n        \"\"\"\n    )\n\n    priority_class_name = Unicode(\n        config=True,\n        help=\"\"\"\n        The priority class that the pods will use.\n\n        See https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption for\n        more information on how pod priority works.\n        \"\"\"\n    )\n\n    delete_grace_period = Integer(\n        1,\n        config=True,\n        help=\"\"\"\n        Time in seconds for the pod to be in `terminating` state before is forcefully killed.\n        \n        Increase this if you need more time to execute a `preStop` lifecycle hook.\n\n        See https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods for\n        more information on how pod termination works.\n\n        Defaults to `1`.\n        \"\"\"\n    )\n\n    # deprecate redundant and inconsistent singleuser_ and user_ prefixes:\n    _deprecated_traits_09 = [\n        \"singleuser_working_dir\",\n        \"singleuser_service_account\",\n        \"singleuser_extra_labels\",\n        \"singleuser_extra_annotations\",\n        \"singleuser_image_spec\",\n        \"singleuser_image_pull_policy\",\n        \"singleuser_image_pull_secrets\",\n        \"singleuser_node_selector\",\n        \"singleuser_uid\",\n        \"singleuser_fs_gid\",\n        \"singleuser_supplemental_gids\",\n        \"singleuser_privileged\",\n        \"singleuser_lifecycle_hooks\",\n        \"singleuser_extra_pod_config\",\n        \"singleuser_init_containers\",\n        \"singleuser_extra_container_config\",\n        \"singleuser_extra_containers\",\n        \"user_storage_class\",\n        \"user_storage_pvc_ensure\",\n        \"user_storage_capacity\",\n        \"user_storage_extra_labels\",\n        \"user_storage_access_modes\",\n    ]\n    # other general deprecations:\n    _deprecated_traits = {\n        'image_spec': ('image', '0.10'),\n    }\n    # add the bulk deprecations from 0.9\n    for _deprecated_name in _deprecated_traits_09:\n        _new_name = _deprecated_name.split('_', 1)[1]\n        _deprecated_traits[_deprecated_name] = (_new_name, '0.9')\n\n    @validate('config')\n    def _handle_deprecated_config(self, proposal):\n        config = proposal.value\n        if 'KubeSpawner' not in config:\n            # nothing to check\n            return config\n        for _deprecated_name, (_new_name, version) in self._deprecated_traits.items():\n            # for any `singleuser_name` deprecate in favor of `name`\n            if _deprecated_name not in config.KubeSpawner:\n                # nothing to do\n                continue\n\n            # remove deprecated value from config\n            _deprecated_value = config.KubeSpawner.pop(_deprecated_name)\n            self.log.warning(\n                \"KubeSpawner.%s is deprecated in %s. Use KubeSpawner.%s instead\",\n                _deprecated_name,\n                version,\n                _new_name,\n            )\n            if _new_name in config.KubeSpawner:\n                # *both* config values found,\n                # ignore deprecated config and warn about the collision\n                _new_value = config.KubeSpawner[_new_name]\n                # ignore deprecated config in favor of non-deprecated config\n                self.log.warning(\n                    \"Ignoring deprecated config KubeSpawner.%s = %r \"\n                    \" in favor of KubeSpawner.%s = %r\",\n                    _deprecated_name,\n                    _deprecated_value,\n                    _new_name,\n                    _new_value,\n                )\n            else:\n                # move deprecated config to its new home\n                config.KubeSpawner[_new_name] = _deprecated_value\n\n        return config\n\n    # define properties for deprecated names\n    # so we can propagate their values to the new traits.\n    # most deprecations should be handled via config above,\n    # but in case these are set at runtime, e.g. by subclasses\n    # or hooks, hook this up.\n    # The signature-order of these is funny\n    # because the property methods are created with\n    # functools.partial(f, name) so name is passed as the first arg\n    # before self.\n\n    def _get_deprecated(name, new_name, version, self):\n        # warn about the deprecated name\n        self.log.warning(\n            \"KubeSpawner.%s is deprecated in %s. Use KubeSpawner.%s\",\n            name,\n            version,\n            new_name,\n        )\n        return getattr(self, new_name)\n\n    def _set_deprecated(name, new_name, version, self, value):\n        # warn about the deprecated name\n        self.log.warning(\n            \"KubeSpawner.%s is deprecated in %s. Use KubeSpawner.%s\",\n            name,\n            version,\n            new_name,\n        )\n        return setattr(self, new_name, value)\n\n    for _deprecated_name, (_new_name, _version) in _deprecated_traits.items():\n        exec(\n            \"\"\"{0} = property(\n                partial(_get_deprecated, '{0}', '{1}', '{2}'),\n                partial(_set_deprecated, '{0}', '{1}', '{2}'),\n            )\n            \"\"\".format(\n                _deprecated_name,\n                _new_name,\n                _version,\n            )\n        )\n    del _deprecated_name\n\n    def _expand_user_properties(self, template):\n        # Make sure username and servername match the restrictions for DNS labels\n        # Note: '-' is not in safe_chars, as it is being used as escape character\n        safe_chars = set(string.ascii_lowercase + string.digits)\n\n        raw_servername = self.name or ''\n        safe_servername = escapism.escape(raw_servername, safe=safe_chars, escape_char='-').lower()\n\n        legacy_escaped_username = ''.join([s if s in safe_chars else '-' for s in self.user.name.lower()])\n        safe_username = escapism.escape(self.user.name, safe=safe_chars, escape_char='-').lower()\n        rendered = template.format(\n            userid=self.user.id,\n            username=safe_username,\n            unescaped_username=self.user.name,\n            legacy_escape_username=legacy_escaped_username,\n            servername=safe_servername,\n            unescaped_servername=raw_servername,\n        )\n        # strip trailing - delimiter in case of empty servername.\n        # k8s object names cannot have trailing -\n        return rendered.rstrip(\"-\")\n\n    def _expand_all(self, src):\n        if isinstance(src, list):\n            return [self._expand_all(i) for i in src]\n        elif isinstance(src, dict):\n            return {k: self._expand_all(v) for k, v in src.items()}\n        elif isinstance(src, str):\n            return self._expand_user_properties(src)\n        else:\n            return src\n\n    def _build_common_labels(self, extra_labels):\n        # Default set of labels, picked up from\n        # https://github.com/kubernetes/helm/blob/master/docs/chart_best_practices/labels.md\n        labels = {}\n        labels.update(extra_labels)\n        labels.update(self.common_labels)\n        return labels\n\n    def _build_pod_labels(self, extra_labels):\n        labels = self._build_common_labels(extra_labels)\n        labels.update({\n            'component': 'singleuser-server'\n        })\n        return labels\n\n    def _build_common_annotations(self, extra_annotations):\n        # Annotations don't need to be escaped\n        annotations = {\n            'hub.jupyter.org/username': self.user.name\n        }\n        if self.name:\n            annotations['hub.jupyter.org/servername'] = self.name\n\n        annotations.update(extra_annotations)\n        return annotations\n\n    @gen.coroutine\n    def get_pod_manifest(self):\n        \"\"\"\n        Make a pod manifest that will spawn current user's notebook pod.\n        \"\"\"\n        if callable(self.uid):\n            uid = yield gen.maybe_future(self.uid(self))\n        else:\n            uid = self.uid\n\n        if callable(self.gid):\n            gid = yield gen.maybe_future(self.gid(self))\n        else:\n            gid = self.gid\n\n        if callable(self.fs_gid):\n            fs_gid = yield gen.maybe_future(self.fs_gid(self))\n        else:\n            fs_gid = self.fs_gid\n\n        if callable(self.supplemental_gids):\n            supplemental_gids = yield gen.maybe_future(self.supplemental_gids(self))\n        else:\n            supplemental_gids = self.supplemental_gids\n\n        if self.cmd:\n            real_cmd = self.cmd + self.get_args()\n        else:\n            real_cmd = None\n\n        labels = self._build_pod_labels(self._expand_all(self.extra_labels))\n        annotations = self._build_common_annotations(self._expand_all(self.extra_annotations))\n\n        return make_pod(\n            name=self.pod_name,\n            cmd=real_cmd,\n            port=self.port,\n            image=self.image,\n            image_pull_policy=self.image_pull_policy,\n            image_pull_secret=self.image_pull_secrets,\n            node_selector=self.node_selector,\n            run_as_uid=uid,\n            run_as_gid=gid,\n            fs_gid=fs_gid,\n            supplemental_gids=supplemental_gids,\n            run_privileged=self.privileged,\n            env=self.get_env(),\n            volumes=self._expand_all(self.volumes),\n            volume_mounts=self._expand_all(self.volume_mounts),\n            working_dir=self.working_dir,\n            labels=labels,\n            annotations=annotations,\n            cpu_limit=self.cpu_limit,\n            cpu_guarantee=self.cpu_guarantee,\n            mem_limit=self.mem_limit,\n            mem_guarantee=self.mem_guarantee,\n            extra_resource_limits=self.extra_resource_limits,\n            extra_resource_guarantees=self.extra_resource_guarantees,\n            lifecycle_hooks=self.lifecycle_hooks,\n            init_containers=self._expand_all(self.init_containers),\n            service_account=self.service_account,\n            extra_container_config=self.extra_container_config,\n            extra_pod_config=self._expand_all(self.extra_pod_config),\n            extra_containers=self._expand_all(self.extra_containers),\n            scheduler_name=self.scheduler_name,\n            tolerations=self.tolerations,\n            node_affinity_preferred=self.node_affinity_preferred,\n            node_affinity_required=self.node_affinity_required,\n            pod_affinity_preferred=self.pod_affinity_preferred,\n            pod_affinity_required=self.pod_affinity_required,\n            pod_anti_affinity_preferred=self.pod_anti_affinity_preferred,\n            pod_anti_affinity_required=self.pod_anti_affinity_required,\n            priority_class_name=self.priority_class_name,\n            logger=self.log,\n        )\n\n    def get_pvc_manifest(self):\n        \"\"\"\n        Make a pvc manifest that will spawn current user's pvc.\n        \"\"\"\n        labels = self._build_common_labels(self._expand_all(self.storage_extra_labels))\n        labels.update({\n            'component': 'singleuser-storage'\n        })\n\n        annotations = self._build_common_annotations({})\n\n        return make_pvc(\n            name=self.pvc_name,\n            storage_class=self.storage_class,\n            access_modes=self.storage_access_modes,\n            selector=self.storage_selector,\n            storage=self.storage_capacity,\n            labels=labels,\n            annotations=annotations\n        )\n\n    def is_pod_running(self, pod):\n        \"\"\"\n        Check if the given pod is running\n\n        pod must be a dictionary representing a Pod kubernetes API object.\n        \"\"\"\n        # FIXME: Validate if this is really the best way\n        is_running = (\n            pod is not None and\n            pod.status.phase == 'Running' and\n            pod.status.pod_ip is not None and\n            pod.metadata.deletion_timestamp is None and\n            all([cs.ready for cs in pod.status.container_statuses])\n        )\n        return is_running\n\n    def get_state(self):\n        \"\"\"\n        Save state required to reinstate this user's pod from scratch\n\n        We save the `pod_name`, even though we could easily compute it,\n        because JupyterHub requires you save *some* state! Otherwise\n        it assumes your server is dead. This works around that.\n\n        It's also useful for cases when the `pod_template` changes between\n        restarts - this keeps the old pods around.\n        \"\"\"\n        state = super().get_state()\n        state['pod_name'] = self.pod_name\n        return state\n\n    def get_env(self):\n        \"\"\"Return the environment dict to use for the Spawner.\n\n        See also: jupyterhub.Spawner.get_env\n        \"\"\"\n\n        env = super(KubeSpawner, self).get_env()\n        # deprecate image\n        env['JUPYTER_IMAGE_SPEC'] = self.image\n        env['JUPYTER_IMAGE'] = self.image\n\n        return env\n\n    def load_state(self, state):\n        \"\"\"\n        Load state from storage required to reinstate this user's pod\n\n        Since this runs after `__init__`, this will override the generated `pod_name`\n        if there's one we have saved in state. These are the same in most cases,\n        but if the `pod_template` has changed in between restarts, it will no longer\n        be the case. This allows us to continue serving from the old pods with\n        the old names.\n        \"\"\"\n        if 'pod_name' in state:\n            self.pod_name = state['pod_name']\n\n    @gen.coroutine\n    def poll(self):\n        \"\"\"\n        Check if the pod is still running.\n\n        Uses the same interface as subprocess.Popen.poll(): if the pod is\n        still running, returns None.  If the pod has exited, return the\n        exit code if we can determine it, or 1 if it has exited but we\n        don't know how.  These are the return values JupyterHub expects.\n\n        Note that a clean exit will have an exit code of zero, so it is\n        necessary to check that the returned value is None, rather than\n        just Falsy, to determine that the pod is still running.\n        \"\"\"\n        # have to wait for first load of data before we have a valid answer\n        if not self.pod_reflector.first_load_future.done():\n            yield self.pod_reflector.first_load_future\n        data = self.pod_reflector.pods.get(self.pod_name, None)\n        if data is not None:\n            if data.status.phase == 'Pending':\n                return None\n            ctr_stat = data.status.container_statuses\n            if ctr_stat is None:  # No status, no container (we hope)\n                # This seems to happen when a pod is idle-culled.\n                return 1\n            for c in ctr_stat:\n                # return exit code if notebook container has terminated\n                if c.name == 'notebook':\n                    if c.state.terminated:\n                        # call self.stop to delete the pod\n                        if self.delete_stopped_pods:\n                            yield self.stop(now=True)\n                        return c.state.terminated.exit_code\n                    break\n            # None means pod is running or starting up\n            return None\n        # pod doesn't exist or has been deleted\n        return 1\n\n    @run_on_executor\n    def asynchronize(self, method, *args, **kwargs):\n        return method(*args, **kwargs)\n\n    @property\n    def events(self):\n        \"\"\"Filter event-reflector to just this pods events\n\n        Returns list of all events that match our pod_name\n        since our ._last_event (if defined).\n        ._last_event is set at the beginning of .start().\n        \"\"\"\n        if not self.event_reflector:\n            return []\n\n        events = []\n        for event in self.event_reflector.events:\n            if event.involved_object.name != self.pod_name:\n                # only consider events for my pod name\n                continue\n\n            if self._last_event and event.metadata.uid == self._last_event:\n                # saw last_event marker, ignore any previous events\n                # and only consider future events\n                # only include events *after* our _last_event marker\n                events = []\n            else:\n                events.append(event)\n        return events\n\n    @async_generator\n    async def progress(self):\n        \"\"\"\n        This function is reporting back the progress of spawning a pod until\n        self._start_future has fired.\n\n        This is working with events parsed by the python kubernetes client,\n        and here is the specification of events that is relevant to understand:\n        ref: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.16/#event-v1-core\n        \"\"\"\n        if not self.events_enabled:\n            return\n\n        self.log.debug('progress generator: %s', self.pod_name)\n        start_future = self._start_future\n        pod_id = None\n        progress = 0\n        next_event = 0\n\n        break_while_loop = False\n        while True:\n            # Ensure we always capture events following the start_future\n            # signal has fired.\n            if start_future.done():\n                break_while_loop = True\n            events = self.events\n\n            len_events = len(events)\n            if next_event < len_events:\n                # only show messages for the 'current' pod\n                # pod_id may change if a previous pod is being stopped\n                # before starting a new one\n                # use the uid of the latest event to identify 'current'\n                pod_id = events[-1].involved_object.uid\n                for i in range(next_event, len_events):\n                    event = events[i]\n                    # move the progress bar.\n                    # Since we don't know how many events we will get,\n                    # asymptotically approach 90% completion with each event.\n                    # each event gets 33% closer to 90%:\n                    # 30 50 63 72 78 82 84 86 87 88 88 89\n                    progress += (90 - progress) / 3\n\n                    # V1Event isn't serializable, and neither is the datetime\n                    # objects within it, and we need what we pass back to be\n                    # serializable to it can be sent back from JupyterHub to\n                    # a browser wanting to display progress.\n                    serializable_event = json.loads(\n                        json.dumps(event.to_dict(), default=datetime.isoformat)\n                    )\n                    await yield_({\n                        'progress': int(progress),\n                        'raw_event': serializable_event,\n                        'message':  \"%s [%s] %s\" % (\n                            event.last_timestamp or event.event_time,\n                            event.type,\n                            event.message,\n                        )\n                    })\n                next_event = len_events\n\n            if break_while_loop:\n                break\n            await sleep(1)\n\n    def _start_reflector(self, key, ReflectorClass, replace=False, **kwargs):\n        \"\"\"Start a shared reflector on the KubeSpawner class\n\n\n        key: key for the reflector (e.g. 'pod' or 'events')\n        Reflector: Reflector class to be instantiated\n        kwargs: extra keyword-args to be relayed to ReflectorClass\n\n        If replace=False and the pod reflector is already running,\n        do nothing.\n\n        If replace=True, a running pod reflector will be stopped\n        and a new one started (for recovering from possible errors).\n        \"\"\"\n        main_loop = IOLoop.current()\n        def on_reflector_failure():\n            self.log.critical(\n                \"%s reflector failed, halting Hub.\",\n                key.title(),\n            )\n            sys.exit(1)\n\n        previous_reflector = self.__class__.reflectors.get(key)\n\n        if replace or not previous_reflector:\n            self.__class__.reflectors[key] = ReflectorClass(\n                parent=self,\n                namespace=self.namespace,\n                on_failure=on_reflector_failure,\n                **kwargs,\n            )\n\n        if replace and previous_reflector:\n            # we replaced the reflector, stop the old one\n            previous_reflector.stop()\n\n        # return the current reflector\n        return self.__class__.reflectors[key]\n\n\n    def _start_watching_events(self, replace=False):\n        \"\"\"Start the events reflector\n\n        If replace=False and the event reflector is already running,\n        do nothing.\n\n        If replace=True, a running pod reflector will be stopped\n        and a new one started (for recovering from possible errors).\n        \"\"\"\n        return self._start_reflector(\n            \"events\",\n            EventReflector,\n            fields={\"involvedObject.kind\": \"Pod\"},\n            replace=replace,\n        )\n\n    def _start_watching_pods(self, replace=False):\n        \"\"\"Start the pod reflector\n\n        If replace=False and the pod reflector is already running,\n        do nothing.\n\n        If replace=True, a running pod reflector will be stopped\n        and a new one started (for recovering from possible errors).\n        \"\"\"\n        return self._start_reflector(\"pods\", PodReflector, replace=replace)\n\n    # record a future for the call to .start()\n    # so we can use it to terminate .progress()\n    def start(self):\n        \"\"\"Thin wrapper around self._start\n\n        so we can hold onto a reference for the Future\n        start returns, which we can use to terminate\n        .progress()\n        \"\"\"\n        self._start_future = self._start()\n        return self._start_future\n\n    _last_event = None\n\n    @gen.coroutine\n    def _start(self):\n        \"\"\"Start the user's pod\"\"\"\n\n        # load user options (including profile)\n        yield self.load_user_options()\n\n        # record latest event so we don't include old\n        # events from previous pods in self.events\n        # track by order and name instead of uid\n        # so we get events like deletion of a previously stale\n        # pod if it's part of this spawn process\n        events = self.events\n        if events:\n            self._last_event = events[-1].metadata.uid\n\n        if self.storage_pvc_ensure:\n            # Try and create the pvc. If it succeeds we are good. If\n            # returns a 409 indicating it already exists we are good. If\n            # it returns a 403, indicating potential quota issue we need\n            # to see if pvc already exists before we decide to raise the\n            # error for quota being exceeded. This is because quota is\n            # checked before determining if the PVC needed to be\n            # created.\n\n            pvc = self.get_pvc_manifest()\n\n            try:\n                yield self.asynchronize(\n                    self.api.create_namespaced_persistent_volume_claim,\n                    namespace=self.namespace,\n                    body=pvc\n                )\n            except ApiException as e:\n                if e.status == 409:\n                    self.log.info(\"PVC \" + self.pvc_name + \" already exists, so did not create new pvc.\")\n\n                elif e.status == 403:\n                    t, v, tb = sys.exc_info()\n\n                    try:\n                        yield self.asynchronize(\n                            self.api.read_namespaced_persistent_volume_claim,\n                            name=self.pvc_name,\n                            namespace=self.namespace)\n\n                    except ApiException as e:\n                        raise v.with_traceback(tb)\n\n                    self.log.info(\"PVC \" + self.pvc_name + \" already exists, possibly have reached quota though.\")\n\n                else:\n                    raise\n\n        # If we run into a 409 Conflict error, it means a pod with the\n        # same name already exists. We stop it, wait for it to stop, and\n        # try again. We try 4 times, and if it still fails we give up.\n        # FIXME: Have better / cleaner retry logic!\n        retry_times = 4\n        pod = yield self.get_pod_manifest()\n        if self.modify_pod_hook:\n            pod = yield gen.maybe_future(self.modify_pod_hook(self, pod))\n        for i in range(retry_times):\n            try:\n                yield self.asynchronize(\n                    self.api.create_namespaced_pod,\n                    self.namespace,\n                    pod,\n                )\n                break\n            except ApiException as e:\n                if e.status != 409:\n                    # We only want to handle 409 conflict errors\n                    self.log.exception(\"Failed for %s\", pod.to_str())\n                    raise\n                self.log.info('Found existing pod %s, attempting to kill', self.pod_name)\n                # TODO: this should show up in events\n                yield self.stop(True)\n\n                self.log.info('Killed pod %s, will try starting singleuser pod again', self.pod_name)\n        else:\n            raise Exception(\n                'Can not create user pod %s already exists & could not be deleted' % self.pod_name)\n\n        # we need a timeout here even though start itself has a timeout\n        # in order for this coroutine to finish at some point.\n        # using the same start_timeout here\n        # essentially ensures that this timeout should never propagate up\n        # because the handler will have stopped waiting after\n        # start_timeout, starting from a slightly earlier point.\n        try:\n            yield exponential_backoff(\n                lambda: self.is_pod_running(self.pod_reflector.pods.get(self.pod_name, None)),\n                'pod/%s did not start in %s seconds!' % (self.pod_name, self.start_timeout),\n                timeout=self.start_timeout,\n            )\n        except TimeoutError:\n            if self.pod_name not in self.pod_reflector.pods:\n                # if pod never showed up at all,\n                # restart the pod reflector which may have become disconnected.\n                self.log.error(\n                    \"Pod %s never showed up in reflector, restarting pod reflector\",\n                    self.pod_name,\n                )\n                self._start_watching_pods(replace=True)\n            raise\n\n        pod = self.pod_reflector.pods[self.pod_name]\n        self.pod_id = pod.metadata.uid\n        if self.event_reflector:\n            self.log.debug(\n                'pod %s events before launch: %s',\n                self.pod_name,\n                \"\\n\".join(\n                    [\n                        \"%s [%s] %s\" % (event.last_timestamp or event.event_time, event.type, event.message)\n                        for event in self.events\n                    ]\n                ),\n            )\n        return (pod.status.pod_ip, self.port)\n\n    @gen.coroutine\n    def stop(self, now=False):\n        delete_options = client.V1DeleteOptions()\n\n        if now:\n            grace_seconds = 0\n        else:\n            grace_seconds = self.delete_grace_period\n\n        delete_options.grace_period_seconds = grace_seconds\n        self.log.info(\"Deleting pod %s\", self.pod_name)\n        try:\n            yield self.asynchronize(\n                self.api.delete_namespaced_pod,\n                name=self.pod_name,\n                namespace=self.namespace,\n                body=delete_options,\n                grace_period_seconds=grace_seconds,\n            )\n        except ApiException as e:\n            if e.status == 404:\n                self.log.warning(\n                    \"No pod %s to delete. Assuming already deleted.\",\n                    self.pod_name,\n                )\n            else:\n                raise\n        try:\n            yield exponential_backoff(\n                lambda: self.pod_reflector.pods.get(self.pod_name, None) is None,\n                'pod/%s did not disappear in %s seconds!' % (self.pod_name, self.start_timeout),\n                timeout=self.start_timeout,\n            )\n        except TimeoutError:\n            self.log.error(\"Pod %s did not disappear, restarting pod reflector\", self.pod_name)\n            self._start_watching_pods(replace=True)\n            raise\n\n    @default('env_keep')\n    def _env_keep_default(self):\n        return []\n\n    _profile_list = None\n\n    def _render_options_form(self, profile_list):\n        self._profile_list = self._init_profile_list(profile_list)\n        profile_form_template = Environment(loader=BaseLoader).from_string(self.profile_form_template)\n        return profile_form_template.render(profile_list=self._profile_list)\n\n    @gen.coroutine\n    def _render_options_form_dynamically(self, current_spawner):\n        profile_list = yield gen.maybe_future(self.profile_list(current_spawner))\n        profile_list = self._init_profile_list(profile_list)\n        return self._render_options_form(profile_list)\n\n    @default('options_form')\n    def _options_form_default(self):\n        '''\n        Build the form template according to the `profile_list` setting.\n\n        Returns:\n            '' when no `profile_list` has been defined\n            The rendered template (using jinja2) when `profile_list` is defined.\n        '''\n        if not self.profile_list:\n            return ''\n        if callable(self.profile_list):\n            return self._render_options_form_dynamically\n        else:\n            return self._render_options_form(self.profile_list)\n\n    def options_from_form(self, formdata):\n        \"\"\"get the option selected by the user on the form\n\n        This only constructs the user_options dict,\n        it should not actually load any options.\n        That is done later in `.load_user_options()`\n\n        Args:\n            formdata: user selection returned by the form\n\n        To access to the value, you can use the `get` accessor and the name of the html element,\n        for example::\n\n            formdata.get('profile',[0])\n\n        to get the value of the form named \"profile\", as defined in `form_template`::\n\n            <select class=\"form-control\" name=\"profile\"...>\n            </select>\n\n        Returns:\n            user_options (dict): the selected profile in the user_options form,\n                e.g. ``{\"profile\": \"cpus-8\"}``\n        \"\"\"\n        return {\n            'profile': formdata.get('profile', [None])[0]\n        }\n\n    @gen.coroutine\n    def _load_profile(self, slug):\n        \"\"\"Load a profile by name\n\n        Called by load_user_options\n        \"\"\"\n\n        # find the profile\n        default_profile = self._profile_list[0]\n        for profile in self._profile_list:\n            if profile.get('default', False):\n                # explicit default, not the first\n                default_profile = profile\n\n            if profile['slug'] == slug:\n                break\n        else:\n            if slug:\n                # name specified, but not found\n                raise ValueError(\"No such profile: %s. Options include: %s\" % (\n                    slug, ', '.join(p['slug'] for p in self._profile_list)\n                ))\n            else:\n                # no name specified, use the default\n                profile = default_profile\n\n        self.log.debug(\"Applying KubeSpawner override for profile '%s'\", profile['display_name'])\n        kubespawner_override = profile.get('kubespawner_override', {})\n        for k, v in kubespawner_override.items():\n            if callable(v):\n                v = v(self)\n                self.log.debug(\".. overriding KubeSpawner value %s=%s (callable result)\", k, v)\n            else:\n                self.log.debug(\".. overriding KubeSpawner value %s=%s\", k, v)\n            setattr(self, k, v)\n\n    # set of recognised user option keys\n    # used for warning about ignoring unrecognised options\n    _user_option_keys = {'profile',}\n\n    def _init_profile_list(self, profile_list):\n        # generate missing slug fields from display_name\n        for profile in profile_list:\n            if 'slug' not in profile:\n                profile['slug'] = slugify(profile['display_name'])\n\n        return profile_list\n\n    @gen.coroutine\n    def load_user_options(self):\n        \"\"\"Load user options from self.user_options dict\n\n        This can be set via POST to the API or via options_from_form\n\n        Only supported argument by default is 'profile'.\n        Override in subclasses to support other options.\n        \"\"\"\n\n        if self._profile_list is None:\n            if callable(self.profile_list):\n                profile_list = yield gen.maybe_future(self.profile_list(self))\n            else:\n                profile_list = self.profile_list\n\n            self._profile_list = self._init_profile_list(profile_list)\n\n        selected_profile = self.user_options.get('profile', None)\n        if self._profile_list:\n            yield self._load_profile(selected_profile)\n        elif selected_profile:\n            self.log.warning(\"Profile %r requested, but profiles are not enabled\", selected_profile)\n\n        # help debugging by logging any option fields that are not recognized\n        option_keys = set(self.user_options)\n        unrecognized_keys = option_keys.difference(self._user_option_keys)\n        if unrecognized_keys:\n            self.log.warning(\n                \"Ignoring unrecognized KubeSpawner user_options: %s\",\n                \", \".join(\n                    map(\n                        str,\n                        sorted(unrecognized_keys)\n                    )\n                )\n            )\n"], "filenames": ["kubespawner/spawner.py"], "buggy_code_start_loc": [310], "buggy_code_end_loc": [1337], "fixing_code_start_loc": [310], "fixing_code_end_loc": [1350], "type": "CWE-863", "message": "In jupyterhub-kubespawner before 0.12, certain usernames will be able to craft particular server names which will grant them access to the default server of other users who have matching usernames. This has been fixed in 0.12.", "other": {"cve": {"id": "CVE-2020-15110", "sourceIdentifier": "security-advisories@github.com", "published": "2020-07-17T21:15:12.857", "lastModified": "2021-11-18T18:23:10.907", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "In jupyterhub-kubespawner before 0.12, certain usernames will be able to craft particular server names which will grant them access to the default server of other users who have matching usernames. This has been fixed in 0.12."}, {"lang": "es", "value": "En jupyterhub-kubespawner versiones anteriores a 0.12, determinados nombres de usuario ser\u00e1n capaces de dise\u00f1ar nombres de servidores particulares que les otorgar\u00e1n acceso al servidor predeterminado de otros usuarios que presentan nombres de usuario coincidentes. Esto ha sido corregido en la versi\u00f3n 0.12"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "NONE", "baseScore": 8.1, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.8, "impactScore": 5.2}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:L/UI:N/S:U/C:H/I:H/A:N", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "NONE", "baseScore": 6.8, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.6, "impactScore": 5.2}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:S/C:P/I:P/A:N", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "SINGLE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "NONE", "baseScore": 5.5}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.0, "impactScore": 4.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-863"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-863"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:jupyterhub:kubespawner:*:*:*:*:*:*:*:*", "versionEndExcluding": "0.12", "matchCriteriaId": "0E62EAF1-40C4-45C2-9383-FA5890E23FF8"}]}]}], "references": [{"url": "https://github.com/jupyterhub/kubespawner/commit/3dfe870a7f5e98e2e398b01996ca6b8eff4bb1d0", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/jupyterhub/kubespawner/security/advisories/GHSA-v7m9-9497-p9gr", "source": "security-advisories@github.com", "tags": ["Exploit", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/jupyterhub/kubespawner/commit/3dfe870a7f5e98e2e398b01996ca6b8eff4bb1d0"}}
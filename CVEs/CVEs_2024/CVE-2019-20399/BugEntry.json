{"buggy_code": ["[package]\nname = \"libsecp256k1\"\ndescription = \"Pure Rust secp256k1 implementation.\"\nlicense = \"Apache-2.0\"\nversion = \"0.3.0\"\nauthors = [\"Wei Tang <hi@that.world>\"]\nrepository = \"https://github.com/sorpaas/libsecp256k1-rs\"\nkeywords = [ \"crypto\", \"ECDSA\", \"secp256k1\", \"bitcoin\", \"no_std\" ]\nedition = \"2018\"\n\n[lib]\nname = \"secp256k1\"\n\n[dependencies]\nrand = { version = \"0.6\", default-features = false }\nhmac-drbg = \"0.2\"\nsha2 = \"0.8\"\ndigest = \"0.8\"\ntypenum = \"1.11\"\narrayref = \"0.3\"\n\n[dev-dependencies]\nsecp256k1-test = \"0.7\"\nclear_on_drop = \"0.2\"\nrand-test = { package = \"rand\", version = \"0.4\" }\n\n[workspace]\nmembers = [\n  \"./gen/ecmult\",\n  \"./gen/genmult\",\n]\n", "//! Pure Rust implementation of the secp256k1 curve and fast ECDSA\n//! signatures. The secp256k1 curve is used excusively in Bitcoin and\n//! Ethereum alike cryptocurrencies.\n\n#![deny(unused_import_braces, unused_imports,\n        unused_comparisons, unused_must_use,\n        unused_variables, non_shorthand_field_patterns,\n        unreachable_code, unused_parens)]\n\n#![no_std]\n\n#[macro_use]\nmod field;\n#[macro_use]\nmod group;\nmod scalar;\nmod ecmult;\nmod ecdsa;\nmod ecdh;\nmod error;\nmod der;\n\nuse hmac_drbg::HmacDRBG;\nuse sha2::Sha256;\nuse typenum::U32;\nuse arrayref::{array_ref, array_mut_ref};\nuse rand::Rng;\n\nuse crate::field::Field;\nuse crate::group::{Affine, Jacobian};\nuse crate::scalar::Scalar;\nuse crate::ecmult::{ECMULT_CONTEXT, ECMULT_GEN_CONTEXT};\n\npub use crate::error::Error;\n\n/// Curve related structs.\npub mod curve {\n    pub use crate::field::Field;\n    pub use crate::group::{Affine, Jacobian, AffineStorage, AFFINE_G, CURVE_B};\n    pub use crate::scalar::Scalar;\n\n    pub use crate::ecmult::{ECMultContext, ECMultGenContext,\n                            ECMULT_CONTEXT, ECMULT_GEN_CONTEXT};\n}\n\n/// Utilities to manipulate the secp256k1 curve parameters.\npub mod util {\n    pub const TAG_PUBKEY_EVEN: u8 = 0x02;\n    pub const TAG_PUBKEY_ODD: u8 = 0x03;\n    pub const TAG_PUBKEY_FULL: u8 = 0x04;\n    pub const TAG_PUBKEY_HYBRID_EVEN: u8 = 0x06;\n    pub const TAG_PUBKEY_HYBRID_ODD: u8 = 0x07;\n\n    pub const MESSAGE_SIZE: usize = 32;\n    pub const SECRET_KEY_SIZE: usize = 32;\n    pub const RAW_PUBLIC_KEY_SIZE: usize = 64;\n    pub const FULL_PUBLIC_KEY_SIZE: usize = 65;\n    pub const COMPRESSED_PUBLIC_KEY_SIZE: usize = 33;\n    pub const SIGNATURE_SIZE: usize = 64;\n    pub const DER_MAX_SIGNATURE_SIZE: usize = 72;\n\n    pub use crate::group::{AFFINE_INFINITY, JACOBIAN_INFINITY,\n                           set_table_gej_var, globalz_set_table_gej};\n    pub use crate::ecmult::{WINDOW_A, WINDOW_G, ECMULT_TABLE_SIZE_A, ECMULT_TABLE_SIZE_G,\n                            odd_multiples_table};\n\n    pub use crate::der::SignatureArray;\n}\n\n#[derive(Debug, Clone, Eq, PartialEq)]\n/// Public key on a secp256k1 curve.\npub struct PublicKey(Affine);\n#[derive(Debug, Clone, Eq, PartialEq)]\n/// Secret key (256-bit) on a secp256k1 curve.\npub struct SecretKey(Scalar);\n#[derive(Debug, Clone, Eq, PartialEq)]\n/// An ECDSA signature.\npub struct Signature {\n    pub r: Scalar,\n    pub s: Scalar\n}\n#[derive(Debug, Clone, Copy, Eq, PartialEq)]\n/// Tag used for public key recovery from signatures.\npub struct RecoveryId(u8);\n#[derive(Debug, Clone, Eq, PartialEq)]\n/// Hashed message input to an ECDSA signature.\npub struct Message(pub Scalar);\n#[derive(Debug, Clone, Eq, PartialEq)]\n/// Shared secret using ECDH.\npub struct SharedSecret([u8; 32]);\n\n/// Format for public key parsing.\npub enum PublicKeyFormat {\n    /// Compressed public key, 33 bytes.\n    Compressed,\n    /// Full length public key, 65 bytes.\n    Full,\n    /// Raw public key, 64 bytes.\n    Raw,\n}\n\nimpl PublicKey {\n    pub fn from_secret_key(seckey: &SecretKey) -> PublicKey {\n        let mut pj = Jacobian::default();\n        ECMULT_GEN_CONTEXT.ecmult_gen(&mut pj, &seckey.0);\n        let mut p = Affine::default();\n        p.set_gej(&pj);\n        PublicKey(p)\n    }\n\n    pub fn parse_slice(p: &[u8], format: Option<PublicKeyFormat>) -> Result<PublicKey, Error> {\n        let format = match (p.len(), format) {\n            (util::FULL_PUBLIC_KEY_SIZE, None) |\n            (util::FULL_PUBLIC_KEY_SIZE, Some(PublicKeyFormat::Full)) =>\n                PublicKeyFormat::Full,\n            (util::COMPRESSED_PUBLIC_KEY_SIZE, None) |\n            (util::COMPRESSED_PUBLIC_KEY_SIZE, Some(PublicKeyFormat::Compressed)) =>\n                PublicKeyFormat::Compressed,\n            (util::RAW_PUBLIC_KEY_SIZE, None) |\n            (util::RAW_PUBLIC_KEY_SIZE, Some(PublicKeyFormat::Raw)) =>\n                PublicKeyFormat::Raw,\n            _ => return Err(Error::InvalidInputLength),\n        };\n\n        match format {\n            PublicKeyFormat::Full => {\n                let mut a = [0; util::FULL_PUBLIC_KEY_SIZE];\n                a.copy_from_slice(p);\n                Self::parse(&a)\n            },\n            PublicKeyFormat::Raw => {\n                use util::TAG_PUBKEY_FULL;\n\n                let mut a = [0; util::FULL_PUBLIC_KEY_SIZE];\n                a[0] = TAG_PUBKEY_FULL;\n                a[1..].copy_from_slice(p);\n                Self::parse(&a)\n            },\n            PublicKeyFormat::Compressed => {\n                let mut a = [0; util::COMPRESSED_PUBLIC_KEY_SIZE];\n                a.copy_from_slice(p);\n                Self::parse_compressed(&a)\n            },\n        }\n    }\n\n    pub fn parse(p: &[u8; util::FULL_PUBLIC_KEY_SIZE]) -> Result<PublicKey, Error> {\n        use util::{TAG_PUBKEY_FULL, TAG_PUBKEY_HYBRID_EVEN, TAG_PUBKEY_HYBRID_ODD};\n\n        if !(p[0] == TAG_PUBKEY_FULL || p[0] == TAG_PUBKEY_HYBRID_EVEN || p[0] == TAG_PUBKEY_HYBRID_ODD) {\n            return Err(Error::InvalidPublicKey);\n        }\n        let mut x = Field::default();\n        let mut y = Field::default();\n        if !x.set_b32(array_ref!(p, 1, 32)) {\n            return Err(Error::InvalidPublicKey);\n        }\n        if !y.set_b32(array_ref!(p, 33, 32)) {\n            return Err(Error::InvalidPublicKey);\n        }\n        let mut elem = Affine::default();\n        elem.set_xy(&x, &y);\n        if (p[0] == TAG_PUBKEY_HYBRID_EVEN || p[0] == TAG_PUBKEY_HYBRID_ODD) &&\n            (y.is_odd() != (p[0] == TAG_PUBKEY_HYBRID_ODD))\n        {\n            return Err(Error::InvalidPublicKey);\n        }\n        if elem.is_infinity() {\n            return Err(Error::InvalidPublicKey);\n        }\n        if elem.is_valid_var() {\n            return Ok(PublicKey(elem));\n        } else {\n            return Err(Error::InvalidPublicKey);\n        }\n    }\n\n    pub fn parse_compressed(p: &[u8; util::COMPRESSED_PUBLIC_KEY_SIZE]) -> Result<PublicKey, Error> {\n        use util::{TAG_PUBKEY_EVEN, TAG_PUBKEY_ODD};\n\n        if !(p[0] == TAG_PUBKEY_EVEN || p[0] == TAG_PUBKEY_ODD) {\n            return Err(Error::InvalidPublicKey);\n        }\n        let mut x = Field::default();\n        if !x.set_b32(array_ref!(p, 1, 32)) {\n            return Err(Error::InvalidPublicKey);\n        }\n        let mut elem = Affine::default();\n        elem.set_xo_var(&x, p[0] == TAG_PUBKEY_ODD);\n        if elem.is_infinity() {\n            return Err(Error::InvalidPublicKey);\n        }\n        if elem.is_valid_var() {\n            return Ok(PublicKey(elem));\n        } else {\n            return Err(Error::InvalidPublicKey);\n        }\n    }\n\n    pub fn serialize(&self) -> [u8; util::FULL_PUBLIC_KEY_SIZE] {\n        use util::TAG_PUBKEY_FULL;\n\n        debug_assert!(!self.0.is_infinity());\n\n        let mut ret = [0u8; 65];\n        let mut elem = self.0.clone();\n\n        elem.x.normalize_var();\n        elem.y.normalize_var();\n        elem.x.fill_b32(array_mut_ref!(ret, 1, 32));\n        elem.y.fill_b32(array_mut_ref!(ret, 33, 32));\n        ret[0] = TAG_PUBKEY_FULL;\n\n        ret\n    }\n\n    pub fn serialize_compressed(&self) -> [u8; util::COMPRESSED_PUBLIC_KEY_SIZE] {\n        use util::{TAG_PUBKEY_ODD, TAG_PUBKEY_EVEN};\n\n        debug_assert!(!self.0.is_infinity());\n\n        let mut ret = [0u8; 33];\n        let mut elem = self.0.clone();\n\n        elem.x.normalize_var();\n        elem.y.normalize_var();\n        elem.x.fill_b32(array_mut_ref!(ret, 1, 32));\n        ret[0] = if elem.y.is_odd() {\n            TAG_PUBKEY_ODD\n        } else {\n            TAG_PUBKEY_EVEN\n        };\n\n        ret\n    }\n\n    pub fn tweak_add_assign(&mut self, tweak: &SecretKey) -> Result<(), Error> {\n        let mut r = Jacobian::default();\n        let a = Jacobian::from_ge(&self.0);\n        let one = Scalar::from_int(1);\n        ECMULT_CONTEXT.ecmult(&mut r, &a, &one, &tweak.0);\n\n        if r.is_infinity() {\n            return Err(Error::TweakOutOfRange);\n        }\n\n        self.0.set_gej(&r);\n        Ok(())\n    }\n\n    pub fn tweak_mul_assign(&mut self, tweak: &SecretKey) -> Result<(), Error> {\n        if tweak.0.is_zero() {\n            return Err(Error::TweakOutOfRange);\n        }\n\n        let mut r = Jacobian::default();\n        let zero = Scalar::from_int(0);\n        let pt = Jacobian::from_ge(&self.0);\n        ECMULT_CONTEXT.ecmult(&mut r, &pt, &tweak.0, &zero);\n\n        self.0.set_gej(&r);\n        Ok(())\n    }\n\n    pub fn combine(keys: &[PublicKey]) -> Result<Self, Error> {\n        let mut qj = Jacobian::default();\n        qj.set_infinity();\n\n        for key in keys {\n            qj = qj.add_ge(&key.0);\n        }\n\n        if qj.is_infinity() {\n            return Err(Error::InvalidPublicKey);\n        }\n\n        let q = Affine::from_gej(&qj);\n        Ok(PublicKey(q))\n    }\n}\n\nimpl Into<Affine> for PublicKey {\n    fn into(self) -> Affine {\n        self.0\n    }\n}\n\nimpl SecretKey {\n    pub fn parse(p: &[u8; util::SECRET_KEY_SIZE]) -> Result<SecretKey, Error> {\n        let mut elem = Scalar::default();\n        if !elem.set_b32(p) && !elem.is_zero() {\n            Ok(SecretKey(elem))\n        } else {\n            Err(Error::InvalidSecretKey)\n        }\n    }\n\n    pub fn parse_slice(p: &[u8]) -> Result<SecretKey, Error> {\n        if p.len() != util::SECRET_KEY_SIZE {\n            return Err(Error::InvalidInputLength);\n        }\n\n        let mut a = [0; 32];\n        a.copy_from_slice(p);\n        Self::parse(&a)\n    }\n\n    pub fn random<R: Rng>(rng: &mut R) -> SecretKey {\n        loop {\n            let mut ret = [0u8; util::SECRET_KEY_SIZE];\n            rng.fill_bytes(&mut ret);\n\n            match Self::parse(&ret) {\n                Ok(key) => return key,\n                Err(_) => (),\n            }\n        }\n    }\n\n    pub fn serialize(&self) -> [u8; util::SECRET_KEY_SIZE] {\n        self.0.b32()\n    }\n\n    pub fn tweak_add_assign(&mut self, tweak: &SecretKey) -> Result<(), Error> {\n        let v = &self.0 + &tweak.0;\n        if v.is_zero() {\n            return Err(Error::TweakOutOfRange);\n        }\n        self.0 = v;\n        Ok(())\n    }\n\n    pub fn tweak_mul_assign(&mut self, tweak: &SecretKey) -> Result<(), Error> {\n        if tweak.0.is_zero() {\n            return Err(Error::TweakOutOfRange);\n        }\n\n        self.0 *= &tweak.0;\n        Ok(())\n    }\n\n    pub fn inv(&self) -> Self {\n        SecretKey(self.0.inv())\n    }\n}\n\nimpl Default for SecretKey {\n    fn default() -> SecretKey {\n        let mut elem = Scalar::default();\n        let overflowed = elem.set_b32(\n            &[0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t      0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n              0x00,0x00,0x00,0x00,0x00,0x01]\n        );\n        debug_assert!(!overflowed);\n        debug_assert!(!elem.is_zero());\n        SecretKey(elem)\n    }\n}\n\nimpl Into<Scalar> for SecretKey {\n    fn into(self) -> Scalar {\n        self.0.clone()\n    }\n}\n\nimpl Drop for SecretKey {\n    fn drop(&mut self) {\n        self.0.clear();\n    }\n}\n\nimpl Signature {\n    pub fn parse(p: &[u8; util::SIGNATURE_SIZE]) -> Signature {\n        let mut r = Scalar::default();\n        let mut s = Scalar::default();\n\n        // Okay for signature to overflow\n        let _ = r.set_b32(array_ref!(p, 0, 32));\n        let _ = s.set_b32(array_ref!(p, 32, 32));\n\n        Signature { r, s }\n    }\n\n    pub fn parse_slice(p: &[u8]) -> Result<Signature, Error> {\n        if p.len() != util::SIGNATURE_SIZE {\n            return Err(Error::InvalidInputLength);\n        }\n\n        let mut a = [0; util::SIGNATURE_SIZE];\n        a.copy_from_slice(p);\n        Ok(Self::parse(&a))\n    }\n\n    pub fn parse_der(p: &[u8]) -> Result<Signature, Error> {\n        let mut decoder = der::Decoder::new(p);\n\n        decoder.read_constructed_sequence()?;\n        let rlen = decoder.read_len()?;\n\n        if rlen != decoder.remaining_len() {\n            return Err(Error::InvalidSignature);\n        }\n\n        let r = decoder.read_integer()?;\n        let s = decoder.read_integer()?;\n\n        if decoder.remaining_len() != 0 {\n            return Err(Error::InvalidSignature);\n        }\n\n        Ok(Signature { r, s })\n    }\n\n    /// Converts a \"lax DER\"-encoded byte slice to a signature. This is basically\n    /// only useful for validating signatures in the Bitcoin blockchain from before\n    /// 2016. It should never be used in new applications. This library does not\n    /// support serializing to this \"format\"\n    pub fn parse_der_lax(p: &[u8]) -> Result<Signature, Error> {\n        let mut decoder = der::Decoder::new(p);\n\n        decoder.read_constructed_sequence()?;\n        decoder.read_seq_len_lax()?;\n\n        let r = decoder.read_integer_lax()?;\n        let s = decoder.read_integer_lax()?;\n\n        Ok(Signature { r, s })\n    }\n\n    /// Normalizes a signature to a \"low S\" form. In ECDSA, signatures are\n    /// of the form (r, s) where r and s are numbers lying in some finite\n    /// field. The verification equation will pass for (r, s) iff it passes\n    /// for (r, -s), so it is possible to ``modify'' signatures in transit\n    /// by flipping the sign of s. This does not constitute a forgery since\n    /// the signed message still cannot be changed, but for some applications,\n    /// changing even the signature itself can be a problem. Such applications\n    /// require a \"strong signature\". It is believed that ECDSA is a strong\n    /// signature except for this ambiguity in the sign of s, so to accommodate\n    /// these applications libsecp256k1 will only accept signatures for which\n    /// s is in the lower half of the field range. This eliminates the\n    /// ambiguity.\n    ///\n    /// However, for some systems, signatures with high s-values are considered\n    /// valid. (For example, parsing the historic Bitcoin blockchain requires\n    /// this.) For these applications we provide this normalization function,\n    /// which ensures that the s value lies in the lower half of its range.\n    pub fn normalize_s(&mut self) {\n        if self.s.is_high() {\n            let s = self.s.clone();\n            self.s.neg_in_place(&s);\n        }\n    }\n\n\n    pub fn serialize(&self) -> [u8; util::SIGNATURE_SIZE] {\n        let mut ret = [0u8; 64];\n        self.r.fill_b32(array_mut_ref!(ret, 0, 32));\n        self.s.fill_b32(array_mut_ref!(ret, 32, 32));\n        ret\n    }\n\n    pub fn serialize_der(&self) -> der::SignatureArray {\n        fn fill_scalar_with_leading_zero(scalar: &Scalar) -> [u8; 33] {\n            let mut ret = [0u8; 33];\n            scalar.fill_b32(array_mut_ref!(ret, 1, 32));\n            ret\n        }\n\n        let r_full = fill_scalar_with_leading_zero(&self.r);\n        let s_full = fill_scalar_with_leading_zero(&self.s);\n\n        fn integer_slice(full: &[u8; 33]) -> &[u8] {\n            let mut len = 33;\n            while len > 1 &&\n                full[full.len() - len] == 0 &&\n                full[full.len() - len + 1] < 0x80\n            {\n                len -= 1;\n            }\n            &full[(full.len() - len)..]\n        }\n\n        let r = integer_slice(&r_full);\n        let s = integer_slice(&s_full);\n\n        let mut ret = der::SignatureArray::new(6 + r.len() + s.len());\n        {\n            let l = ret.as_mut();\n            l[0] = 0x30;\n            l[1] = 4 + r.len() as u8 + s.len() as u8;\n            l[2] = 0x02;\n            l[3] = r.len() as u8;\n            l[4..(4 + r.len())].copy_from_slice(r);\n            l[4 + r.len()] = 0x02;\n            l[5 + r.len()] = s.len() as u8;\n            l[(6 + r.len())..(6 + r.len() + s.len())].copy_from_slice(s);\n        }\n\n        ret\n    }\n}\n\nimpl Message {\n    pub fn parse(p: &[u8; util::MESSAGE_SIZE]) -> Message {\n        let mut m = Scalar::default();\n\n        // Okay for message to overflow.\n        let _ = m.set_b32(p);\n\n        Message(m)\n    }\n\n    pub fn parse_slice(p: &[u8]) -> Result<Message, Error> {\n        if p.len() != util::MESSAGE_SIZE {\n            return Err(Error::InvalidInputLength);\n        }\n\n        let mut a = [0; util::MESSAGE_SIZE];\n        a.copy_from_slice(p);\n        Ok(Self::parse(&a))\n    }\n\n    pub fn serialize(&self) -> [u8; util::MESSAGE_SIZE] {\n        self.0.b32()\n    }\n}\n\nimpl RecoveryId {\n    /// Parse recovery ID starting with 0.\n    pub fn parse(p: u8) -> Result<RecoveryId, Error> {\n        if p < 4 {\n            Ok(RecoveryId(p))\n        } else {\n            Err(Error::InvalidRecoveryId)\n        }\n    }\n\n    /// Parse recovery ID as Ethereum RPC format, starting with 27.\n    pub fn parse_rpc(p: u8) -> Result<RecoveryId, Error> {\n        if p >= 27 && p < 27 + 4 {\n            RecoveryId::parse(p - 27)\n        } else {\n            Err(Error::InvalidRecoveryId)\n        }\n    }\n\n    pub fn serialize(&self) -> u8 {\n        self.0\n    }\n}\n\nimpl Into<u8> for RecoveryId {\n    fn into(self) -> u8 {\n        self.0\n    }\n}\n\nimpl Into<i32> for RecoveryId {\n    fn into(self) -> i32 {\n        self.0 as i32\n    }\n}\n\nimpl SharedSecret {\n    pub fn new(pubkey: &PublicKey, seckey: &SecretKey) -> Result<SharedSecret, Error> {\n        let inner = match ECMULT_CONTEXT.ecdh_raw(&pubkey.0, &seckey.0) {\n            Some(val) => val,\n            None => return Err(Error::InvalidSecretKey),\n        };\n\n        Ok(SharedSecret(inner))\n    }\n\n}\n\nimpl AsRef<[u8]> for SharedSecret {\n    fn as_ref(&self) -> &[u8] {\n        &self.0\n    }\n}\n\nimpl Drop for SharedSecret {\n    fn drop(&mut self) {\n         unsafe {\n            core::ptr::write_volatile(&mut self.0, [0u8; 32]);\n        }\n    }\n}\n\n/// Check signature is a valid message signed by public key.\npub fn verify(message: &Message, signature: &Signature, pubkey: &PublicKey) -> bool {\n    ECMULT_CONTEXT.verify_raw(&signature.r, &signature.s, &pubkey.0, &message.0)\n}\n\n/// Recover public key from a signed message.\npub fn recover(message: &Message, signature: &Signature, recovery_id: &RecoveryId) -> Result<PublicKey, Error> {\n    ECMULT_CONTEXT.recover_raw(&signature.r, &signature.s, recovery_id.0, &message.0).map(|v| PublicKey(v))\n}\n\n/// Sign a message using the secret key.\npub fn sign(message: &Message, seckey: &SecretKey) -> (Signature, RecoveryId) {\n    let seckey_b32 = seckey.0.b32();\n    let message_b32 = message.0.b32();\n\n    let mut drbg = HmacDRBG::<Sha256>::new(&seckey_b32, &message_b32, &[]);\n    let mut nonce = Scalar::default();\n    let mut overflow;\n\n    let result;\n    loop {\n        let generated = drbg.generate::<U32>(None);\n        overflow = nonce.set_b32(array_ref!(generated, 0, 32));\n\n        if !overflow && !nonce.is_zero() {\n            match ECMULT_GEN_CONTEXT.sign_raw(&seckey.0, &message.0, &nonce) {\n                Ok(val) => {\n                    result = val;\n                    break\n                },\n                Err(_) => (),\n            }\n        }\n    }\n\n    #[allow(unused_assignments)]\n    {\n        nonce = Scalar::default();\n    }\n    let (sigr, sigs, recid) = result;\n\n    (Signature {\n        r: sigr,\n        s: sigs,\n    }, RecoveryId(recid))\n}\n", "use core::ops::{Add, AddAssign, Mul, MulAssign};\n\nconst SECP256K1_N_0: u32 = 0xD0364141;\nconst SECP256K1_N_1: u32 = 0xBFD25E8C;\nconst SECP256K1_N_2: u32 = 0xAF48A03B;\nconst SECP256K1_N_3: u32 = 0xBAAEDCE6;\nconst SECP256K1_N_4: u32 = 0xFFFFFFFE;\nconst SECP256K1_N_5: u32 = 0xFFFFFFFF;\nconst SECP256K1_N_6: u32 = 0xFFFFFFFF;\nconst SECP256K1_N_7: u32 = 0xFFFFFFFF;\n\nconst SECP256K1_N_C_0: u32 = !SECP256K1_N_0 + 1;\nconst SECP256K1_N_C_1: u32 = !SECP256K1_N_1;\nconst SECP256K1_N_C_2: u32 = !SECP256K1_N_2;\nconst SECP256K1_N_C_3: u32 = !SECP256K1_N_3;\nconst SECP256K1_N_C_4: u32 = 1;\n\nconst SECP256K1_N_H_0: u32 = 0x681B20A0;\nconst SECP256K1_N_H_1: u32 = 0xDFE92F46;\nconst SECP256K1_N_H_2: u32 = 0x57A4501D;\nconst SECP256K1_N_H_3: u32 = 0x5D576E73;\nconst SECP256K1_N_H_4: u32 = 0xFFFFFFFF;\nconst SECP256K1_N_H_5: u32 = 0xFFFFFFFF;\nconst SECP256K1_N_H_6: u32 = 0xFFFFFFFF;\nconst SECP256K1_N_H_7: u32 = 0x7FFFFFFF;\n\n#[derive(Debug, Clone, Eq, PartialEq)]\n/// A 256-bit scalar value.\npub struct Scalar(pub [u32; 8]);\n\nimpl Scalar {\n    /// Clear a scalar to prevent the leak of sensitive data.\n    pub fn clear(&mut self) {\n        unsafe {\n            core::ptr::write_volatile(&mut self.0, [0u32; 8]);\n        }\n    }\n\n    /// Set a scalar to an unsigned integer.\n    pub fn set_int(&mut self, v: u32) {\n        self.0 = [v, 0, 0, 0, 0, 0, 0, 0];\n    }\n\n    /// Create a scalar from an unsigned integer.\n    pub fn from_int(v: u32) -> Self {\n        let mut scalar = Self::default();\n        scalar.set_int(v);\n        scalar\n    }\n\n    /// Access bits from a scalar. All requested bits must belong to\n    /// the same 32-bit limb.\n    pub fn bits(&self, offset: usize, count: usize) -> u32 {\n        debug_assert!((offset + count - 1) >> 5 == offset >> 5);\n        (self.0[offset >> 5] >> (offset & 0x1F)) & ((1 << count) - 1)\n    }\n\n    /// Access bits from a scalar. Not constant time.\n    pub fn bits_var(&self, offset: usize, count: usize) -> u32 {\n        debug_assert!(count < 32);\n        debug_assert!(offset + count <= 256);\n        if (offset + count - 1) >> 5 == offset >> 5 {\n            return self.bits(offset, count);\n        } else {\n            debug_assert!((offset >> 5) + 1 < 8);\n            return ((self.0[offset >> 5] >> (offset & 0x1f)) | (self.0[(offset >> 5) + 1] << (32 - (offset & 0x1f)))) & ((1 << count) - 1);\n        }\n    }\n\n    #[must_use]\n    fn check_overflow(&self) -> bool {\n        let mut yes: bool = false;\n        let mut no: bool = false;\n        no = no || (self.0[7] < SECP256K1_N_7); /* No need for a > check. */\n        no = no || (self.0[6] < SECP256K1_N_6); /* No need for a > check. */\n        no = no || (self.0[5] < SECP256K1_N_5); /* No need for a > check. */\n        no = no || (self.0[4] < SECP256K1_N_4);\n        yes = yes || ((self.0[4] > SECP256K1_N_4) && !no);\n        no = no || ((self.0[3] < SECP256K1_N_3) && !yes);\n        yes = yes || ((self.0[3] > SECP256K1_N_3) && !no);\n        no = no || ((self.0[2] < SECP256K1_N_2) && !yes);\n        yes = yes || ((self.0[2] > SECP256K1_N_2) && !no);\n        no = no || ((self.0[1] < SECP256K1_N_1) && !yes);\n        yes = yes || ((self.0[1] > SECP256K1_N_1) && !no);\n        yes = yes || ((self.0[0] >= SECP256K1_N_0) && !no);\n        return yes;\n    }\n\n    #[must_use]\n    fn reduce(&mut self, overflow: bool) -> bool {\n        let o: u64 = if overflow { 1 } else { 0 };\n        let mut t: u64;\n        t = (self.0[0] as u64) + o * (SECP256K1_N_C_0 as u64);\n        self.0[0] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (self.0[1] as u64) + o * (SECP256K1_N_C_1 as u64);\n        self.0[1] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (self.0[2] as u64) + o * (SECP256K1_N_C_2 as u64);\n        self.0[2] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (self.0[3] as u64) + o * (SECP256K1_N_C_3 as u64);\n        self.0[3] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (self.0[4] as u64) + o * (SECP256K1_N_C_4 as u64);\n        self.0[4] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += self.0[5] as u64;\n        self.0[5] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += self.0[6] as u64;\n        self.0[6] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += self.0[7] as u64;\n        self.0[7] = (t & 0xFFFFFFFF) as u32;\n        overflow\n    }\n\n    /// Add two scalars together (modulo the group order). Returns\n    /// whether it overflowed.\n    #[must_use]\n    pub fn add_in_place(&mut self, a: &Scalar, b: &Scalar) -> bool {\n        let mut overflow: u64;\n        let mut t: u64 = (a.0[0] as u64) + (b.0[0] as u64);\n        self.0[0] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (a.0[1] as u64) + (b.0[1] as u64);\n        self.0[1] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (a.0[2] as u64) + (b.0[2] as u64);\n        self.0[2] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (a.0[3] as u64) + (b.0[3] as u64);\n        self.0[3] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (a.0[4] as u64) + (b.0[4] as u64);\n        self.0[4] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (a.0[5] as u64) + (b.0[5] as u64);\n        self.0[5] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (a.0[6] as u64) + (b.0[6] as u64);\n        self.0[6] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (a.0[7] as u64) + (b.0[7] as u64);\n        self.0[7] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        overflow = t + if self.check_overflow() { 1 } else { 0 };\n        debug_assert!(overflow == 0 || overflow == 1);\n        overflow = overflow | if self.reduce(overflow == 1) { 1 } else { 0 };\n        return overflow == 1;\n    }\n\n    /// Conditionally add a power of two to a scalar. The result is\n    /// not allowed to overflow.\n    pub fn cadd_bit(&mut self, mut bit: usize, flag: bool) {\n        let mut t: u64;\n        debug_assert!(bit < 256);\n        bit += if flag { 0 } else { usize::max_value() } & 0x100;\n        t = (self.0[0] as u64) + ((if (bit >> 5) == 0 { 1 } else { 0 }) << (bit & 0x1F));\n        self.0[0] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (self.0[1] as u64) + ((if (bit >> 5) == 1 { 1 } else { 0 }) << (bit & 0x1F));\n        self.0[1] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (self.0[2] as u64) + ((if (bit >> 5) == 2 { 1 } else { 0 }) << (bit & 0x1F));\n        self.0[2] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (self.0[3] as u64) + ((if (bit >> 5) == 3 { 1 } else { 0 }) << (bit & 0x1F));\n        self.0[3] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (self.0[4] as u64) + ((if (bit >> 5) == 4 { 1 } else { 0 }) << (bit & 0x1F));\n        self.0[4] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (self.0[5] as u64) + ((if (bit >> 5) == 5 { 1 } else { 0 }) << (bit & 0x1F));\n        self.0[5] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (self.0[6] as u64) + ((if (bit >> 5) == 6 { 1 } else { 0 }) << (bit & 0x1F));\n        self.0[6] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (self.0[7] as u64) + ((if (bit >> 5) == 7 { 1 } else { 0 }) << (bit & 0x1F));\n        self.0[7] = (t & 0xFFFFFFFF) as u32;\n        debug_assert!((t >> 32) == 0);\n        debug_assert!(!self.check_overflow());\n    }\n\n    /// Set a scalar from a big endian byte array, return whether it overflowed.\n    #[must_use]\n    pub fn set_b32(&mut self, b32: &[u8; 32]) -> bool {\n        self.0[0] = (b32[31] as u32) | ((b32[30] as u32) << 8) | ((b32[29] as u32) << 16) | ((b32[28] as u32) << 24);\n        self.0[1] = (b32[27] as u32) | ((b32[26] as u32) << 8) | ((b32[25] as u32) << 16) | ((b32[24] as u32) << 24);\n        self.0[2] = (b32[23] as u32) | ((b32[22] as u32) << 8) | ((b32[21] as u32) << 16) | ((b32[20] as u32) << 24);\n        self.0[3] = (b32[19] as u32) | ((b32[18] as u32) << 8) | ((b32[17] as u32) << 16) | ((b32[16] as u32) << 24);\n        self.0[4] = (b32[15] as u32) | ((b32[14] as u32) << 8) | ((b32[13] as u32) << 16) | ((b32[12] as u32) << 24);\n        self.0[5] = (b32[11] as u32) | ((b32[10] as u32) << 8) | ((b32[9] as u32) << 16) | ((b32[8] as u32) << 24);\n        self.0[6] = (b32[7] as u32) | ((b32[6] as u32) << 8) | ((b32[5] as u32) << 16) | ((b32[4] as u32) << 24);\n        self.0[7] = (b32[3] as u32) | ((b32[2] as u32) << 8) | ((b32[1] as u32) << 16) | ((b32[0] as u32) << 24);\n\n        let overflow = self.check_overflow();\n        self.reduce(overflow)\n    }\n\n    /// Convert a scalar to a byte array.\n    pub fn b32(&self) -> [u8; 32] {\n        let mut bin = [0u8; 32];\n        self.fill_b32(&mut bin);\n        bin\n    }\n\n    /// Convert a scalar to a byte array.\n    pub fn fill_b32(&self, bin: &mut [u8; 32]) {\n        bin[0] = (self.0[7] >> 24) as u8; bin[1] = (self.0[7] >> 16) as u8; bin[2] = (self.0[7] >> 8) as u8; bin[3] = (self.0[7]) as u8;\n        bin[4] = (self.0[6] >> 24) as u8; bin[5] = (self.0[6] >> 16) as u8; bin[6] = (self.0[6] >> 8) as u8; bin[7] = (self.0[6]) as u8;\n        bin[8] = (self.0[5] >> 24) as u8; bin[9] = (self.0[5] >> 16) as u8; bin[10] = (self.0[5] >> 8) as u8; bin[11] = (self.0[5]) as u8;\n        bin[12] = (self.0[4] >> 24) as u8; bin[13] = (self.0[4] >> 16) as u8; bin[14] = (self.0[4] >> 8) as u8; bin[15] = (self.0[4]) as u8;\n        bin[16] = (self.0[3] >> 24) as u8; bin[17] = (self.0[3] >> 16) as u8; bin[18] = (self.0[3] >> 8) as u8; bin[19] = (self.0[3]) as u8;\n        bin[20] = (self.0[2] >> 24) as u8; bin[21] = (self.0[2] >> 16) as u8; bin[22] = (self.0[2] >> 8) as u8; bin[23] = (self.0[2]) as u8;\n        bin[24] = (self.0[1] >> 24) as u8; bin[25] = (self.0[1] >> 16) as u8; bin[26] = (self.0[1] >> 8) as u8; bin[27] = (self.0[1]) as u8;\n        bin[28] = (self.0[0] >> 24) as u8; bin[29] = (self.0[0] >> 16) as u8; bin[30] = (self.0[0] >> 8) as u8; bin[31] = (self.0[0]) as u8;\n    }\n\n    /// Check whether a scalar equals zero.\n    pub fn is_zero(&self) -> bool {\n        (self.0[0] | self.0[1] | self.0[2] | self.0[3] | self.0[4] | self.0[5] | self.0[6] | self.0[7]) == 0\n    }\n\n    /// Compute the complement of a scalar (modulo the group order).\n    pub fn neg_in_place(&mut self, a: &Scalar) {\n        let nonzero: u64 = 0xFFFFFFFF * if !a.is_zero() { 1 } else { 0 };\n        let mut t: u64 = (!a.0[0]) as u64 + (SECP256K1_N_0 + 1) as u64;\n        self.0[0] = (t & nonzero) as u32; t >>= 32;\n        t += (!a.0[1]) as u64 + SECP256K1_N_1 as u64;\n        self.0[1] = (t & nonzero) as u32; t >>= 32;\n        t += (!a.0[2]) as u64 + SECP256K1_N_2 as u64;\n        self.0[2] = (t & nonzero) as u32; t >>= 32;\n        t += (!a.0[3]) as u64 + SECP256K1_N_3 as u64;\n        self.0[3] = (t & nonzero) as u32; t >>= 32;\n        t += (!a.0[4]) as u64 + SECP256K1_N_4 as u64;\n        self.0[4] = (t & nonzero) as u32; t >>= 32;\n        t += (!a.0[5]) as u64 + SECP256K1_N_5 as u64;\n        self.0[5] = (t & nonzero) as u32; t >>= 32;\n        t += (!a.0[6]) as u64 + SECP256K1_N_6 as u64;\n        self.0[6] = (t & nonzero) as u32; t >>= 32;\n        t += (!a.0[7]) as u64 + SECP256K1_N_7 as u64;\n        self.0[7] = (t & nonzero) as u32;\n    }\n\n    pub fn neg(&self) -> Scalar {\n        let mut ret = Scalar::default();\n        ret.neg_in_place(self);\n        ret\n    }\n\n    /// Check whether a scalar equals one.\n    pub fn is_one(&self) -> bool {\n        ((self.0[0] ^ 1) |  self.0[1] | self.0[2] | self.0[3] | self.0[4] | self.0[5] | self.0[6] | self.0[7]) == 0\n    }\n\n    /// Check whether a scalar is higher than the group order divided\n    /// by 2.\n    pub fn is_high(&self) -> bool {\n        let mut yes: bool = false;\n        let mut no: bool = false;\n        no = no || (self.0[7] < SECP256K1_N_H_7);\n        yes = yes || ((self.0[7] > SECP256K1_N_H_7) & !no);\n        no = no || ((self.0[6] < SECP256K1_N_H_6) & !yes); /* No need for a > check. */\n        no = no || ((self.0[5] < SECP256K1_N_H_5) & !yes); /* No need for a > check. */\n        no = no || ((self.0[4] < SECP256K1_N_H_4) & !yes); /* No need for a > check. */\n        no = no || ((self.0[3] < SECP256K1_N_H_3) & !yes);\n        yes = yes || ((self.0[3] > SECP256K1_N_H_3) && !no);\n        no = no || ((self.0[2] < SECP256K1_N_H_2) && !yes);\n        yes = yes || ((self.0[2] > SECP256K1_N_H_2) && !no);\n        no = no || ((self.0[1] < SECP256K1_N_H_1) && !yes);\n        yes = yes || ((self.0[1] > SECP256K1_N_H_1) && !no);\n        yes = yes || ((self.0[0] >= SECP256K1_N_H_0) && !no);\n        return yes;\n    }\n\n    /// Conditionally negate a number, in constant time. Returns -1 if\n    /// the number was negated, 1 otherwise.\n    pub fn cond_neg_mut(&mut self, flag: bool) -> isize {\n        let mask = if flag { u32::max_value() } else { 0 };\n        let nonzero: u64 = 0xFFFFFFFF * if !self.is_zero() { 1 } else { 0 };\n        let mut t: u64 = (self.0[0] ^ mask) as u64 + ((SECP256K1_N_0 + 1) & mask) as u64;\n        self.0[0] = (t & nonzero) as u32; t >>= 32;\n        t += (self.0[1] ^ mask) as u64 + (SECP256K1_N_1 & mask) as u64;\n        self.0[1] = (t & nonzero) as u32; t >>= 32;\n        t += (self.0[2] ^ mask) as u64 + (SECP256K1_N_2 & mask) as u64;\n        self.0[2] = (t & nonzero) as u32; t >>= 32;\n        t += (self.0[3] ^ mask) as u64 + (SECP256K1_N_3 & mask) as u64;\n        self.0[3] = (t & nonzero) as u32; t >>= 32;\n        t += (self.0[4] ^ mask) as u64 + (SECP256K1_N_4 & mask) as u64;\n        self.0[4] = (t & nonzero) as u32; t >>= 32;\n        t += (self.0[5] ^ mask) as u64 + (SECP256K1_N_5 & mask) as u64;\n        self.0[5] = (t & nonzero) as u32; t >>= 32;\n        t += (self.0[6] ^ mask) as u64 + (SECP256K1_N_6 & mask) as u64;\n        self.0[6] = (t & nonzero) as u32; t >>= 32;\n        t += (self.0[7] ^ mask) as u64 + (SECP256K1_N_7 & mask) as u64;\n        self.0[7] = (t & nonzero) as u32;\n\n        if mask == 0 {\n            return 1;\n        } else {\n            return -1;\n        }\n    }\n}\n\nmacro_rules! define_ops {\n    ($c0: ident, $c1: ident, $c2: ident) => {\n        #[allow(unused_macros)]\n        macro_rules! muladd {\n            ($a: expr, $b: expr) => {\n                let a = $a; let b = $b;\n                let t = (a as u64) * (b as u64);\n                let mut th = (t >> 32) as u32;\n                let tl = t as u32;\n                $c0 = $c0.wrapping_add(tl);\n                th = th.wrapping_add(if $c0 < tl { 1 } else { 0 });\n                $c1 = $c1.wrapping_add(th);\n                $c2 = $c2.wrapping_add(if $c1 < th { 1 } else { 0 });\n                debug_assert!($c1 >= th || $c2 != 0);\n            }\n        }\n\n        #[allow(unused_macros)]\n        macro_rules! muladd_fast {\n            ($a: expr, $b: expr) => {\n                let a = $a; let b = $b;\n                let t = (a as u64) * (b as u64);\n                let mut th = (t >> 32) as u32;\n                let tl = t as u32;\n                $c0 = $c0.wrapping_add(tl);\n                th = th.wrapping_add(if $c0 < tl { 1 } else { 0 });\n                $c1 = $c1.wrapping_add(th);\n                debug_assert!($c1 >= th);\n            }\n        }\n\n        #[allow(unused_macros)]\n        macro_rules! muladd2 {\n            ($a: expr, $b: expr) => {\n                let a = $a; let b = $b;\n                let t = (a as u64) * (b as u64);\n                let th = (t >> 32) as u32;\n                let tl = t as u32;\n                let mut th2 = th.wrapping_add(th);\n                $c2 = $c2.wrapping_add(if th2 < th { 1 } else { 0 });\n                debug_assert!(th2 >= th || $c2 != 0);\n                let tl2 = tl.wrapping_add(tl);\n                th2 = th2.wrapping_add(if tl2 < tl { 1 } else { 0 });\n                $c0 = $c0.wrapping_add(tl2);\n                th2 = th2.wrapping_add(if $c0 < tl2 { 1 } else { 0 });\n                $c2 = $c2.wrapping_add(if $c0 < tl2 && th2 == 0 { 1 } else { 0 });\n                debug_assert!($c0 >= tl2 || th2 != 0 || $c2 != 0);\n                $c1 = $c1.wrapping_add(th2);\n                $c2 = $c2.wrapping_add(if $c1 < th2 { 1 } else { 0 });\n                debug_assert!($c1 >= th2 || $c2 != 0);\n            }\n        }\n\n        #[allow(unused_macros)]\n        macro_rules! sumadd {\n            ($a: expr) => {\n                let a = $a;\n                $c0 = $c0.wrapping_add(a);\n                let over = if $c0 < a { 1 } else { 0 };\n                $c1 = $c1.wrapping_add(over);\n                $c2 = $c2.wrapping_add(if $c1 < over { 1 } else { 0 });\n            }\n        }\n\n        #[allow(unused_macros)]\n        macro_rules! sumadd_fast {\n            ($a: expr) => {\n                let a = $a;\n                $c0 = $c0.wrapping_add(a);\n                $c1 = $c1.wrapping_add(if $c0 < a { 1 } else { 0 });\n                debug_assert!($c1 != 0 || $c0 >= a);\n                debug_assert!($c2 == 0);\n            }\n        }\n\n        #[allow(unused_macros)]\n        macro_rules! extract {\n            () => {\n                {\n                    #[allow(unused_assignments)]\n                    {\n                        let n = $c0;\n                        $c0 = $c1;\n                        $c1 = $c2;\n                        $c2 = 0;\n                        n\n                    }\n                }\n            }\n        }\n\n        #[allow(unused_macros)]\n        macro_rules! extract_fast {\n            () => {\n                {\n                    #[allow(unused_assignments)]\n                    {\n                        let n = $c0;\n                        $c0 = $c1;\n                        $c1 = 0;\n                        debug_assert!($c2 == 0);\n                        n\n                    }\n                }\n            }\n        }\n    }\n}\n\nimpl Scalar {\n    fn reduce_512(&mut self, l: &[u32; 16]) {\n        let (mut c0, mut c1, mut c2): (u32, u32, u32);\n        define_ops!(c0, c1, c2);\n\n        let mut c: u64;\n        let (n0, n1, n2, n3, n4, n5, n6, n7) = (l[8], l[9], l[10], l[11], l[12], l[13], l[14], l[15]);\n        let (m0, m1, m2, m3, m4, m5, m6, m7, m8, m9, m10, m11, m12): (u32, u32, u32, u32, u32, u32, u32, u32, u32, u32, u32, u32, u32);\n        let (p0, p1, p2, p3, p4, p5, p6, p7, p8): (u32, u32, u32, u32, u32, u32, u32, u32, u32);\n\n        c0 = l[0]; c1 = 0; c2 = 0;\n        muladd_fast!(n0, SECP256K1_N_C_0);\n        m0 = extract_fast!();\n        sumadd_fast!(l[1]);\n        muladd!(n1, SECP256K1_N_C_0);\n        muladd!(n0, SECP256K1_N_C_1);\n        m1 = extract!();\n        sumadd!(l[2]);\n        muladd!(n2, SECP256K1_N_C_0);\n        muladd!(n1, SECP256K1_N_C_1);\n        muladd!(n0, SECP256K1_N_C_2);\n        m2 = extract!();\n        sumadd!(l[3]);\n        muladd!(n3, SECP256K1_N_C_0);\n        muladd!(n2, SECP256K1_N_C_1);\n        muladd!(n1, SECP256K1_N_C_2);\n        muladd!(n0, SECP256K1_N_C_3);\n        m3 = extract!();\n        sumadd!(l[4]);\n        muladd!(n4, SECP256K1_N_C_0);\n        muladd!(n3, SECP256K1_N_C_1);\n        muladd!(n2, SECP256K1_N_C_2);\n        muladd!(n1, SECP256K1_N_C_3);\n        sumadd!(n0);\n        m4 = extract!();\n        sumadd!(l[5]);\n        muladd!(n5, SECP256K1_N_C_0);\n        muladd!(n4, SECP256K1_N_C_1);\n        muladd!(n3, SECP256K1_N_C_2);\n        muladd!(n2, SECP256K1_N_C_3);\n        sumadd!(n1);\n        m5 = extract!();\n        sumadd!(l[6]);\n        muladd!(n6, SECP256K1_N_C_0);\n        muladd!(n5, SECP256K1_N_C_1);\n        muladd!(n4, SECP256K1_N_C_2);\n        muladd!(n3, SECP256K1_N_C_3);\n        sumadd!(n2);\n        m6 = extract!();\n        sumadd!(l[7]);\n        muladd!(n7, SECP256K1_N_C_0);\n        muladd!(n6, SECP256K1_N_C_1);\n        muladd!(n5, SECP256K1_N_C_2);\n        muladd!(n4, SECP256K1_N_C_3);\n        sumadd!(n3);\n        m7 = extract!();\n        muladd!(n7, SECP256K1_N_C_1);\n        muladd!(n6, SECP256K1_N_C_2);\n        muladd!(n5, SECP256K1_N_C_3);\n        sumadd!(n4);\n        m8 = extract!();\n        muladd!(n7, SECP256K1_N_C_2);\n        muladd!(n6, SECP256K1_N_C_3);\n        sumadd!(n5);\n        m9 = extract!();\n        muladd!(n7, SECP256K1_N_C_3);\n        sumadd!(n6);\n        m10 = extract!();\n        sumadd_fast!(n7);\n        m11 = extract_fast!();\n        debug_assert!(c0 <= 1);\n        m12 = c0;\n\n        /* Reduce 385 bits into 258. */\n        /* p[0..8] = m[0..7] + m[8..12] * SECP256K1_N_C. */\n        c0 = m0; c1 = 0; c2 = 0;\n        muladd_fast!(m8, SECP256K1_N_C_0);\n        p0 = extract_fast!();\n        sumadd_fast!(m1);\n        muladd!(m9, SECP256K1_N_C_0);\n        muladd!(m8, SECP256K1_N_C_1);\n        p1 = extract!();\n        sumadd!(m2);\n        muladd!(m10, SECP256K1_N_C_0);\n        muladd!(m9, SECP256K1_N_C_1);\n        muladd!(m8, SECP256K1_N_C_2);\n        p2 = extract!();\n        sumadd!(m3);\n        muladd!(m11, SECP256K1_N_C_0);\n        muladd!(m10, SECP256K1_N_C_1);\n        muladd!(m9, SECP256K1_N_C_2);\n        muladd!(m8, SECP256K1_N_C_3);\n        p3 = extract!();\n        sumadd!(m4);\n        muladd!(m12, SECP256K1_N_C_0);\n        muladd!(m11, SECP256K1_N_C_1);\n        muladd!(m10, SECP256K1_N_C_2);\n        muladd!(m9, SECP256K1_N_C_3);\n        sumadd!(m8);\n        p4 = extract!();\n        sumadd!(m5);\n        muladd!(m12, SECP256K1_N_C_1);\n        muladd!(m11, SECP256K1_N_C_2);\n        muladd!(m10, SECP256K1_N_C_3);\n        sumadd!(m9);\n        p5 = extract!();\n        sumadd!(m6);\n        muladd!(m12, SECP256K1_N_C_2);\n        muladd!(m11, SECP256K1_N_C_3);\n        sumadd!(m10);\n        p6 = extract!();\n        sumadd_fast!(m7);\n        muladd_fast!(m12, SECP256K1_N_C_3);\n        sumadd_fast!(m11);\n        p7 = extract_fast!();\n        p8 = c0 + m12;\n        debug_assert!(p8 <= 2);\n\n        /* Reduce 258 bits into 256. */\n        /* r[0..7] = p[0..7] + p[8] * SECP256K1_N_C. */\n        c = p0 as u64 + SECP256K1_N_C_0 as u64 * p8 as u64;\n        self.0[0] = (c & 0xFFFFFFFF) as u32; c >>= 32;\n        c += p1 as u64 + SECP256K1_N_C_1 as u64 * p8 as u64;\n        self.0[1] = (c & 0xFFFFFFFF) as u32; c >>= 32;\n        c += p2 as u64 + SECP256K1_N_C_2 as u64 * p8 as u64;\n        self.0[2] = (c & 0xFFFFFFFF) as u32; c >>= 32;\n        c += p3 as u64 + SECP256K1_N_C_3 as u64 * p8 as u64;\n        self.0[3] = (c & 0xFFFFFFFF) as u32; c >>= 32;\n        c += p4 as u64 + p8 as u64;\n        self.0[4] = (c & 0xFFFFFFFF) as u32; c >>= 32;\n        c += p5 as u64;\n        self.0[5] = (c & 0xFFFFFFFF) as u32; c >>= 32;\n        c += p6 as u64;\n        self.0[6] = (c & 0xFFFFFFFF) as u32; c >>= 32;\n        c += p7 as u64;\n        self.0[7] = (c & 0xFFFFFFFF) as u32; c >>= 32;\n\n        let overflow = self.check_overflow();\n        debug_assert!(c + if overflow { 1 } else { 0 } <= 1);\n        let _ = self.reduce(c + if overflow { 1 } else { 0 } == 1);\n    }\n\n    fn mul_512(&self, b: &Scalar, l: &mut [u32; 16]) {\n        let (mut c0, mut c1, mut c2): (u32, u32, u32) = (0, 0, 0);\n        define_ops!(c0, c1, c2);\n\n        /* l[0..15] = a[0..7] * b[0..7]. */\n        muladd_fast!(self.0[0], b.0[0]);\n        l[0] = extract_fast!();\n        muladd!(self.0[0], b.0[1]);\n        muladd!(self.0[1], b.0[0]);\n        l[1] = extract!();\n        muladd!(self.0[0], b.0[2]);\n        muladd!(self.0[1], b.0[1]);\n        muladd!(self.0[2], b.0[0]);\n        l[2] = extract!();\n        muladd!(self.0[0], b.0[3]);\n        muladd!(self.0[1], b.0[2]);\n        muladd!(self.0[2], b.0[1]);\n        muladd!(self.0[3], b.0[0]);\n        l[3] = extract!();\n        muladd!(self.0[0], b.0[4]);\n        muladd!(self.0[1], b.0[3]);\n        muladd!(self.0[2], b.0[2]);\n        muladd!(self.0[3], b.0[1]);\n        muladd!(self.0[4], b.0[0]);\n        l[4] = extract!();\n        muladd!(self.0[0], b.0[5]);\n        muladd!(self.0[1], b.0[4]);\n        muladd!(self.0[2], b.0[3]);\n        muladd!(self.0[3], b.0[2]);\n        muladd!(self.0[4], b.0[1]);\n        muladd!(self.0[5], b.0[0]);\n        l[5] = extract!();\n        muladd!(self.0[0], b.0[6]);\n        muladd!(self.0[1], b.0[5]);\n        muladd!(self.0[2], b.0[4]);\n        muladd!(self.0[3], b.0[3]);\n        muladd!(self.0[4], b.0[2]);\n        muladd!(self.0[5], b.0[1]);\n        muladd!(self.0[6], b.0[0]);\n        l[6] = extract!();\n        muladd!(self.0[0], b.0[7]);\n        muladd!(self.0[1], b.0[6]);\n        muladd!(self.0[2], b.0[5]);\n        muladd!(self.0[3], b.0[4]);\n        muladd!(self.0[4], b.0[3]);\n        muladd!(self.0[5], b.0[2]);\n        muladd!(self.0[6], b.0[1]);\n        muladd!(self.0[7], b.0[0]);\n        l[7] = extract!();\n        muladd!(self.0[1], b.0[7]);\n        muladd!(self.0[2], b.0[6]);\n        muladd!(self.0[3], b.0[5]);\n        muladd!(self.0[4], b.0[4]);\n        muladd!(self.0[5], b.0[3]);\n        muladd!(self.0[6], b.0[2]);\n        muladd!(self.0[7], b.0[1]);\n        l[8] = extract!();\n        muladd!(self.0[2], b.0[7]);\n        muladd!(self.0[3], b.0[6]);\n        muladd!(self.0[4], b.0[5]);\n        muladd!(self.0[5], b.0[4]);\n        muladd!(self.0[6], b.0[3]);\n        muladd!(self.0[7], b.0[2]);\n        l[9] = extract!();\n        muladd!(self.0[3], b.0[7]);\n        muladd!(self.0[4], b.0[6]);\n        muladd!(self.0[5], b.0[5]);\n        muladd!(self.0[6], b.0[4]);\n        muladd!(self.0[7], b.0[3]);\n        l[10] = extract!();\n        muladd!(self.0[4], b.0[7]);\n        muladd!(self.0[5], b.0[6]);\n        muladd!(self.0[6], b.0[5]);\n        muladd!(self.0[7], b.0[4]);\n        l[11] = extract!();\n        muladd!(self.0[5], b.0[7]);\n        muladd!(self.0[6], b.0[6]);\n        muladd!(self.0[7], b.0[5]);\n        l[12] = extract!();\n        muladd!(self.0[6], b.0[7]);\n        muladd!(self.0[7], b.0[6]);\n        l[13] = extract!();\n        muladd_fast!(self.0[7], b.0[7]);\n        l[14] = extract_fast!();\n        debug_assert!(c1 == 0);\n        l[15] = c0;\n    }\n\n    fn sqr_512(&self, l: &mut [u32; 16]) {\n        let (mut c0, mut c1, mut c2): (u32, u32, u32) = (0, 0, 0);\n        define_ops!(c0, c1, c2);\n\n        /* l[0..15] = a[0..7]^2. */\n        muladd_fast!(self.0[0], self.0[0]);\n        l[0] = extract_fast!();\n        muladd2!(self.0[0], self.0[1]);\n        l[1] = extract!();\n        muladd2!(self.0[0], self.0[2]);\n        muladd!(self.0[1], self.0[1]);\n        l[2] = extract!();\n        muladd2!(self.0[0], self.0[3]);\n        muladd2!(self.0[1], self.0[2]);\n        l[3] = extract!();\n        muladd2!(self.0[0], self.0[4]);\n        muladd2!(self.0[1], self.0[3]);\n        muladd!(self.0[2], self.0[2]);\n        l[4] = extract!();\n        muladd2!(self.0[0], self.0[5]);\n        muladd2!(self.0[1], self.0[4]);\n        muladd2!(self.0[2], self.0[3]);\n        l[5] = extract!();\n        muladd2!(self.0[0], self.0[6]);\n        muladd2!(self.0[1], self.0[5]);\n        muladd2!(self.0[2], self.0[4]);\n        muladd!(self.0[3], self.0[3]);\n        l[6] = extract!();\n        muladd2!(self.0[0], self.0[7]);\n        muladd2!(self.0[1], self.0[6]);\n        muladd2!(self.0[2], self.0[5]);\n        muladd2!(self.0[3], self.0[4]);\n        l[7] = extract!();\n        muladd2!(self.0[1], self.0[7]);\n        muladd2!(self.0[2], self.0[6]);\n        muladd2!(self.0[3], self.0[5]);\n        muladd!(self.0[4], self.0[4]);\n        l[8] = extract!();\n        muladd2!(self.0[2], self.0[7]);\n        muladd2!(self.0[3], self.0[6]);\n        muladd2!(self.0[4], self.0[5]);\n        l[9] = extract!();\n        muladd2!(self.0[3], self.0[7]);\n        muladd2!(self.0[4], self.0[6]);\n        muladd!(self.0[5], self.0[5]);\n        l[10] = extract!();\n        muladd2!(self.0[4], self.0[7]);\n        muladd2!(self.0[5], self.0[6]);\n        l[11] = extract!();\n        muladd2!(self.0[5], self.0[7]);\n        muladd!(self.0[6], self.0[6]);\n        l[12] = extract!();\n        muladd2!(self.0[6], self.0[7]);\n        l[13] = extract!();\n        muladd_fast!(self.0[7], self.0[7]);\n        l[14] = extract_fast!();\n        debug_assert!(c1 == 0);\n        l[15] = c0;\n    }\n\n    pub fn mul_in_place(&mut self, a: &Scalar, b: &Scalar) {\n        let mut l = [0u32; 16];\n        a.mul_512(b, &mut l);\n        self.reduce_512(&l);\n    }\n\n    /// Shift a scalar right by some amount strictly between 0 and 16,\n    /// returning the low bits that were shifted off.\n    pub fn shr_int(&mut self, n: usize) -> u32 {\n        let ret: u32;\n        debug_assert!(n > 0);\n        debug_assert!(n < 16);\n        ret = self.0[0] & ((1 << n) - 1);\n        self.0[0] = (self.0[0] >> n) + (self.0[1] << (32 - n));\n        self.0[1] = (self.0[1] >> n) + (self.0[2] << (32 - n));\n        self.0[2] = (self.0[2] >> n) + (self.0[3] << (32 - n));\n        self.0[3] = (self.0[3] >> n) + (self.0[4] << (32 - n));\n        self.0[4] = (self.0[4] >> n) + (self.0[5] << (32 - n));\n        self.0[5] = (self.0[5] >> n) + (self.0[6] << (32 - n));\n        self.0[6] = (self.0[6] >> n) + (self.0[7] << (32 - n));\n        self.0[7] = self.0[7] >> n;\n        return ret;\n    }\n\n    pub fn sqr_in_place(&mut self, a: &Scalar) {\n        let mut l = [0u32; 16];\n        a.sqr_512(&mut l);\n        self.reduce_512(&l);\n    }\n\n    pub fn sqr(&self) -> Scalar {\n        let mut ret = Scalar::default();\n        ret.sqr_in_place(self);\n        ret\n    }\n\n    pub fn inv_in_place(&mut self, x: &Scalar) {\n        let u2 = x.sqr();\n        let x2 = &u2 * x;\n        let u5 = &u2 * &x2;\n        let x3 = &u5 * &u2;\n        let u9 = &x3 * &u2;\n        let u11 = &u9 * &u2;\n        let u13 = &u11 * &u2;\n\n        let mut x6 = u13.sqr();\n        x6 = x6.sqr();\n        x6 *= &u11;\n\n        let mut x8 = x6.sqr();\n        x8 = x8.sqr();\n        x8 *= &x2;\n\n        let mut x14 = x8.sqr();\n        for _ in 0..5 {\n            x14 = x14.sqr();\n        }\n        x14 *= &x6;\n\n        let mut x28 = x14.sqr();\n        for _ in 0..13 {\n            x28 = x28.sqr();\n        }\n        x28 *= &x14;\n\n        let mut x56 = x28.sqr();\n        for _ in 0..27 {\n            x56 = x56.sqr();\n        }\n        x56 *= &x28;\n\n        let mut x112 = x56.sqr();\n        for _ in 0..55 {\n            x112 = x112.sqr();\n        }\n        x112 *= &x56;\n\n        let mut x126 = x112.sqr();\n        for _ in 0..13 {\n            x126 = x126.sqr();\n        }\n        x126 *= &x14;\n\n        let mut t = x126;\n        for _ in 0..3 {\n            t = t.sqr();\n        }\n        t *= &u5;\n        for _ in 0..4 {\n            t = t.sqr();\n        }\n        t *= &x3;\n        for _ in 0..4 {\n            t = t.sqr();\n        }\n        t *= &u5;\n        for _ in 0..5 {\n            t = t.sqr();\n        }\n        t *= &u11;\n        for _ in 0..4 {\n            t = t.sqr();\n        }\n        t *= &u11;\n        for _ in 0..4 {\n            t = t.sqr();\n        }\n        t *= &x3;\n        for _ in 0..5 {\n            t = t.sqr();\n        }\n        t *= &x3;\n        for _ in 0..6 {\n            t = t.sqr();\n        }\n        t *= &u13;\n        for _ in 0..4 {\n            t = t.sqr();\n        }\n        t *= &u5;\n        for _ in 0..3 {\n            t = t.sqr();\n        }\n        t *= &x3;\n        for _ in 0..5 {\n            t = t.sqr();\n        }\n        t *= &u9;\n        for _ in 0..6 {\n            t = t.sqr();\n        }\n        t *= &u5;\n        for _ in 0..10 {\n            t = t.sqr();\n        }\n        t *= &x3;\n        for _ in 0..4 {\n            t = t.sqr();\n        }\n        t *= &x3;\n        for _ in 0..9 {\n            t = t.sqr();\n        }\n        t *= &x8;\n        for _ in 0..5 {\n            t = t.sqr();\n        }\n        t *= &u9;\n        for _ in 0..6 {\n            t = t.sqr();\n        }\n        t *= &u11;\n        for _ in 0..4 {\n            t = t.sqr();\n        }\n        t *= &u13;\n        for _ in 0..5 {\n            t = t.sqr();\n        }\n        t *= &x2;\n        for _ in 0..6 {\n            t = t.sqr();\n        }\n        t *= &u13;\n        for _ in 0..10 {\n            t = t.sqr();\n        }\n        t *= &u13;\n        for _ in 0..4 {\n            t = t.sqr();\n        }\n        t *= &u9;\n        for _ in 0..6 {\n            t = t.sqr();\n        }\n        t *= x;\n        for _ in 0..8 {\n            t = t.sqr();\n        }\n        *self = &t * &x6;\n    }\n\n    pub fn inv(&self) -> Scalar {\n        let mut ret = Scalar::default();\n        ret.inv_in_place(self);\n        ret\n    }\n\n    pub fn inv_var(&self) -> Scalar {\n        self.inv()\n    }\n\n    pub fn is_even(&self) -> bool {\n        return self.0[0] & 1 == 0;\n    }\n}\n\nimpl Default for Scalar {\n    fn default() -> Scalar {\n        Scalar([0u32; 8])\n    }\n}\n\nimpl Add<Scalar> for Scalar {\n    type Output = Scalar;\n    fn add(self, other: Scalar) -> Scalar {\n        let mut ret = Scalar::default();\n        let _ = ret.add_in_place(&self, &other);\n        ret\n    }\n}\n\nimpl<'a, 'b> Add<&'a Scalar> for &'b Scalar {\n    type Output = Scalar;\n    fn add(self, other: &'a Scalar) -> Scalar {\n        let mut ret = Scalar::default();\n        let _ = ret.add_in_place(self, other);\n        ret\n    }\n}\n\nimpl<'a> AddAssign<&'a Scalar> for Scalar {\n    fn add_assign(&mut self, other: &'a Scalar) {\n        let mut ret = Scalar::default();\n        let _ = ret.add_in_place(self, other);\n        *self = ret;\n    }\n}\n\nimpl AddAssign<Scalar> for Scalar {\n    fn add_assign(&mut self, other: Scalar) {\n        self.add_assign(&other)\n    }\n}\n\nimpl Mul<Scalar> for Scalar {\n    type Output = Scalar;\n    fn mul(self, other: Scalar) -> Scalar {\n        let mut ret = Scalar::default();\n        ret.mul_in_place(&self, &other);\n        ret\n    }\n}\n\nimpl<'a, 'b> Mul<&'a Scalar> for &'b Scalar {\n    type Output = Scalar;\n    fn mul(self, other: &'a Scalar) -> Scalar {\n        let mut ret = Scalar::default();\n        ret.mul_in_place(self, other);\n        ret\n    }\n}\n\nimpl<'a> MulAssign<&'a Scalar> for Scalar {\n    fn mul_assign(&mut self, other: &'a Scalar) {\n        let mut ret = Scalar::default();\n        ret.mul_in_place(self, other);\n        *self = ret;\n    }\n}\n\nimpl MulAssign<Scalar> for Scalar {\n    fn mul_assign(&mut self, other: Scalar) {\n        self.mul_assign(&other)\n    }\n}\n"], "fixing_code": ["[package]\nname = \"libsecp256k1\"\ndescription = \"Pure Rust secp256k1 implementation.\"\nlicense = \"Apache-2.0\"\nversion = \"0.4.0\"\nauthors = [\"Wei Tang <hi@that.world>\"]\nrepository = \"https://github.com/sorpaas/libsecp256k1-rs\"\nkeywords = [ \"crypto\", \"ECDSA\", \"secp256k1\", \"bitcoin\", \"no_std\" ]\nedition = \"2018\"\n\n[lib]\nname = \"secp256k1\"\n\n[dependencies]\nrand = { version = \"0.6\", default-features = false }\nhmac-drbg = \"0.2\"\nsha2 = \"0.8\"\ndigest = \"0.8\"\ntypenum = \"1.11\"\narrayref = \"0.3\"\nsubtle = { version = \"2.2\", default-features = false }\n\n[dev-dependencies]\nsecp256k1-test = \"0.7\"\nclear_on_drop = \"0.2\"\nrand-test = { package = \"rand\", version = \"0.4\" }\n\n[features]\ndefault = [\"std\"]\nstd = [\"subtle/std\", \"rand/std\"]\n\n[workspace]\nmembers = [\n  \"./gen/ecmult\",\n  \"./gen/genmult\",\n]\n", "//! Pure Rust implementation of the secp256k1 curve and fast ECDSA\n//! signatures. The secp256k1 curve is used excusively in Bitcoin and\n//! Ethereum alike cryptocurrencies.\n\n#![deny(unused_import_braces, unused_imports,\n        unused_comparisons, unused_must_use,\n        unused_variables, non_shorthand_field_patterns,\n        unreachable_code, unused_parens)]\n\n#![cfg_attr(not(feature = \"std\"), no_std)]\n\n#[macro_use]\nmod field;\n#[macro_use]\nmod group;\nmod scalar;\nmod ecmult;\nmod ecdsa;\nmod ecdh;\nmod error;\nmod der;\n\nuse hmac_drbg::HmacDRBG;\nuse sha2::Sha256;\nuse typenum::U32;\nuse arrayref::{array_ref, array_mut_ref};\nuse rand::Rng;\n\nuse crate::field::Field;\nuse crate::group::{Affine, Jacobian};\nuse crate::scalar::Scalar;\nuse crate::ecmult::{ECMULT_CONTEXT, ECMULT_GEN_CONTEXT};\n\npub use crate::error::Error;\n\n/// Curve related structs.\npub mod curve {\n    pub use crate::field::Field;\n    pub use crate::group::{Affine, Jacobian, AffineStorage, AFFINE_G, CURVE_B};\n    pub use crate::scalar::Scalar;\n\n    pub use crate::ecmult::{ECMultContext, ECMultGenContext,\n                            ECMULT_CONTEXT, ECMULT_GEN_CONTEXT};\n}\n\n/// Utilities to manipulate the secp256k1 curve parameters.\npub mod util {\n    pub const TAG_PUBKEY_EVEN: u8 = 0x02;\n    pub const TAG_PUBKEY_ODD: u8 = 0x03;\n    pub const TAG_PUBKEY_FULL: u8 = 0x04;\n    pub const TAG_PUBKEY_HYBRID_EVEN: u8 = 0x06;\n    pub const TAG_PUBKEY_HYBRID_ODD: u8 = 0x07;\n\n    pub const MESSAGE_SIZE: usize = 32;\n    pub const SECRET_KEY_SIZE: usize = 32;\n    pub const RAW_PUBLIC_KEY_SIZE: usize = 64;\n    pub const FULL_PUBLIC_KEY_SIZE: usize = 65;\n    pub const COMPRESSED_PUBLIC_KEY_SIZE: usize = 33;\n    pub const SIGNATURE_SIZE: usize = 64;\n    pub const DER_MAX_SIGNATURE_SIZE: usize = 72;\n\n    pub use crate::group::{AFFINE_INFINITY, JACOBIAN_INFINITY,\n                           set_table_gej_var, globalz_set_table_gej};\n    pub use crate::ecmult::{WINDOW_A, WINDOW_G, ECMULT_TABLE_SIZE_A, ECMULT_TABLE_SIZE_G,\n                            odd_multiples_table};\n\n    pub use crate::der::SignatureArray;\n}\n\n#[derive(Debug, Clone, Eq, PartialEq)]\n/// Public key on a secp256k1 curve.\npub struct PublicKey(Affine);\n#[derive(Debug, Clone, Eq, PartialEq)]\n/// Secret key (256-bit) on a secp256k1 curve.\npub struct SecretKey(Scalar);\n#[derive(Debug, Clone, Eq, PartialEq)]\n/// An ECDSA signature.\npub struct Signature {\n    pub r: Scalar,\n    pub s: Scalar\n}\n#[derive(Debug, Clone, Copy, Eq, PartialEq)]\n/// Tag used for public key recovery from signatures.\npub struct RecoveryId(u8);\n#[derive(Debug, Clone, Eq, PartialEq)]\n/// Hashed message input to an ECDSA signature.\npub struct Message(pub Scalar);\n#[derive(Debug, Clone, Eq, PartialEq)]\n/// Shared secret using ECDH.\npub struct SharedSecret([u8; 32]);\n\n/// Format for public key parsing.\npub enum PublicKeyFormat {\n    /// Compressed public key, 33 bytes.\n    Compressed,\n    /// Full length public key, 65 bytes.\n    Full,\n    /// Raw public key, 64 bytes.\n    Raw,\n}\n\nimpl PublicKey {\n    pub fn from_secret_key(seckey: &SecretKey) -> PublicKey {\n        let mut pj = Jacobian::default();\n        ECMULT_GEN_CONTEXT.ecmult_gen(&mut pj, &seckey.0);\n        let mut p = Affine::default();\n        p.set_gej(&pj);\n        PublicKey(p)\n    }\n\n    pub fn parse_slice(p: &[u8], format: Option<PublicKeyFormat>) -> Result<PublicKey, Error> {\n        let format = match (p.len(), format) {\n            (util::FULL_PUBLIC_KEY_SIZE, None) |\n            (util::FULL_PUBLIC_KEY_SIZE, Some(PublicKeyFormat::Full)) =>\n                PublicKeyFormat::Full,\n            (util::COMPRESSED_PUBLIC_KEY_SIZE, None) |\n            (util::COMPRESSED_PUBLIC_KEY_SIZE, Some(PublicKeyFormat::Compressed)) =>\n                PublicKeyFormat::Compressed,\n            (util::RAW_PUBLIC_KEY_SIZE, None) |\n            (util::RAW_PUBLIC_KEY_SIZE, Some(PublicKeyFormat::Raw)) =>\n                PublicKeyFormat::Raw,\n            _ => return Err(Error::InvalidInputLength),\n        };\n\n        match format {\n            PublicKeyFormat::Full => {\n                let mut a = [0; util::FULL_PUBLIC_KEY_SIZE];\n                a.copy_from_slice(p);\n                Self::parse(&a)\n            },\n            PublicKeyFormat::Raw => {\n                use util::TAG_PUBKEY_FULL;\n\n                let mut a = [0; util::FULL_PUBLIC_KEY_SIZE];\n                a[0] = TAG_PUBKEY_FULL;\n                a[1..].copy_from_slice(p);\n                Self::parse(&a)\n            },\n            PublicKeyFormat::Compressed => {\n                let mut a = [0; util::COMPRESSED_PUBLIC_KEY_SIZE];\n                a.copy_from_slice(p);\n                Self::parse_compressed(&a)\n            },\n        }\n    }\n\n    pub fn parse(p: &[u8; util::FULL_PUBLIC_KEY_SIZE]) -> Result<PublicKey, Error> {\n        use util::{TAG_PUBKEY_FULL, TAG_PUBKEY_HYBRID_EVEN, TAG_PUBKEY_HYBRID_ODD};\n\n        if !(p[0] == TAG_PUBKEY_FULL || p[0] == TAG_PUBKEY_HYBRID_EVEN || p[0] == TAG_PUBKEY_HYBRID_ODD) {\n            return Err(Error::InvalidPublicKey);\n        }\n        let mut x = Field::default();\n        let mut y = Field::default();\n        if !x.set_b32(array_ref!(p, 1, 32)) {\n            return Err(Error::InvalidPublicKey);\n        }\n        if !y.set_b32(array_ref!(p, 33, 32)) {\n            return Err(Error::InvalidPublicKey);\n        }\n        let mut elem = Affine::default();\n        elem.set_xy(&x, &y);\n        if (p[0] == TAG_PUBKEY_HYBRID_EVEN || p[0] == TAG_PUBKEY_HYBRID_ODD) &&\n            (y.is_odd() != (p[0] == TAG_PUBKEY_HYBRID_ODD))\n        {\n            return Err(Error::InvalidPublicKey);\n        }\n        if elem.is_infinity() {\n            return Err(Error::InvalidPublicKey);\n        }\n        if elem.is_valid_var() {\n            return Ok(PublicKey(elem));\n        } else {\n            return Err(Error::InvalidPublicKey);\n        }\n    }\n\n    pub fn parse_compressed(p: &[u8; util::COMPRESSED_PUBLIC_KEY_SIZE]) -> Result<PublicKey, Error> {\n        use util::{TAG_PUBKEY_EVEN, TAG_PUBKEY_ODD};\n\n        if !(p[0] == TAG_PUBKEY_EVEN || p[0] == TAG_PUBKEY_ODD) {\n            return Err(Error::InvalidPublicKey);\n        }\n        let mut x = Field::default();\n        if !x.set_b32(array_ref!(p, 1, 32)) {\n            return Err(Error::InvalidPublicKey);\n        }\n        let mut elem = Affine::default();\n        elem.set_xo_var(&x, p[0] == TAG_PUBKEY_ODD);\n        if elem.is_infinity() {\n            return Err(Error::InvalidPublicKey);\n        }\n        if elem.is_valid_var() {\n            return Ok(PublicKey(elem));\n        } else {\n            return Err(Error::InvalidPublicKey);\n        }\n    }\n\n    pub fn serialize(&self) -> [u8; util::FULL_PUBLIC_KEY_SIZE] {\n        use util::TAG_PUBKEY_FULL;\n\n        debug_assert!(!self.0.is_infinity());\n\n        let mut ret = [0u8; 65];\n        let mut elem = self.0.clone();\n\n        elem.x.normalize_var();\n        elem.y.normalize_var();\n        elem.x.fill_b32(array_mut_ref!(ret, 1, 32));\n        elem.y.fill_b32(array_mut_ref!(ret, 33, 32));\n        ret[0] = TAG_PUBKEY_FULL;\n\n        ret\n    }\n\n    pub fn serialize_compressed(&self) -> [u8; util::COMPRESSED_PUBLIC_KEY_SIZE] {\n        use util::{TAG_PUBKEY_ODD, TAG_PUBKEY_EVEN};\n\n        debug_assert!(!self.0.is_infinity());\n\n        let mut ret = [0u8; 33];\n        let mut elem = self.0.clone();\n\n        elem.x.normalize_var();\n        elem.y.normalize_var();\n        elem.x.fill_b32(array_mut_ref!(ret, 1, 32));\n        ret[0] = if elem.y.is_odd() {\n            TAG_PUBKEY_ODD\n        } else {\n            TAG_PUBKEY_EVEN\n        };\n\n        ret\n    }\n\n    pub fn tweak_add_assign(&mut self, tweak: &SecretKey) -> Result<(), Error> {\n        let mut r = Jacobian::default();\n        let a = Jacobian::from_ge(&self.0);\n        let one = Scalar::from_int(1);\n        ECMULT_CONTEXT.ecmult(&mut r, &a, &one, &tweak.0);\n\n        if r.is_infinity() {\n            return Err(Error::TweakOutOfRange);\n        }\n\n        self.0.set_gej(&r);\n        Ok(())\n    }\n\n    pub fn tweak_mul_assign(&mut self, tweak: &SecretKey) -> Result<(), Error> {\n        if tweak.0.is_zero() {\n            return Err(Error::TweakOutOfRange);\n        }\n\n        let mut r = Jacobian::default();\n        let zero = Scalar::from_int(0);\n        let pt = Jacobian::from_ge(&self.0);\n        ECMULT_CONTEXT.ecmult(&mut r, &pt, &tweak.0, &zero);\n\n        self.0.set_gej(&r);\n        Ok(())\n    }\n\n    pub fn combine(keys: &[PublicKey]) -> Result<Self, Error> {\n        let mut qj = Jacobian::default();\n        qj.set_infinity();\n\n        for key in keys {\n            qj = qj.add_ge(&key.0);\n        }\n\n        if qj.is_infinity() {\n            return Err(Error::InvalidPublicKey);\n        }\n\n        let q = Affine::from_gej(&qj);\n        Ok(PublicKey(q))\n    }\n}\n\nimpl Into<Affine> for PublicKey {\n    fn into(self) -> Affine {\n        self.0\n    }\n}\n\nimpl SecretKey {\n    pub fn parse(p: &[u8; util::SECRET_KEY_SIZE]) -> Result<SecretKey, Error> {\n        let mut elem = Scalar::default();\n        if !elem.set_b32(p) && !elem.is_zero() {\n            Ok(SecretKey(elem))\n        } else {\n            Err(Error::InvalidSecretKey)\n        }\n    }\n\n    pub fn parse_slice(p: &[u8]) -> Result<SecretKey, Error> {\n        if p.len() != util::SECRET_KEY_SIZE {\n            return Err(Error::InvalidInputLength);\n        }\n\n        let mut a = [0; 32];\n        a.copy_from_slice(p);\n        Self::parse(&a)\n    }\n\n    pub fn random<R: Rng>(rng: &mut R) -> SecretKey {\n        loop {\n            let mut ret = [0u8; util::SECRET_KEY_SIZE];\n            rng.fill_bytes(&mut ret);\n\n            match Self::parse(&ret) {\n                Ok(key) => return key,\n                Err(_) => (),\n            }\n        }\n    }\n\n    pub fn serialize(&self) -> [u8; util::SECRET_KEY_SIZE] {\n        self.0.b32()\n    }\n\n    pub fn tweak_add_assign(&mut self, tweak: &SecretKey) -> Result<(), Error> {\n        let v = &self.0 + &tweak.0;\n        if v.is_zero() {\n            return Err(Error::TweakOutOfRange);\n        }\n        self.0 = v;\n        Ok(())\n    }\n\n    pub fn tweak_mul_assign(&mut self, tweak: &SecretKey) -> Result<(), Error> {\n        if tweak.0.is_zero() {\n            return Err(Error::TweakOutOfRange);\n        }\n\n        self.0 *= &tweak.0;\n        Ok(())\n    }\n\n    pub fn inv(&self) -> Self {\n        SecretKey(self.0.inv())\n    }\n}\n\nimpl Default for SecretKey {\n    fn default() -> SecretKey {\n        let mut elem = Scalar::default();\n        let overflowed = elem.set_b32(\n            &[0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t      0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n              0x00,0x00,0x00,0x00,0x00,0x01]\n        );\n        debug_assert!(!overflowed);\n        debug_assert!(!elem.is_zero());\n        SecretKey(elem)\n    }\n}\n\nimpl Into<Scalar> for SecretKey {\n    fn into(self) -> Scalar {\n        self.0.clone()\n    }\n}\n\nimpl Drop for SecretKey {\n    fn drop(&mut self) {\n        self.0.clear();\n    }\n}\n\nimpl Signature {\n    pub fn parse(p: &[u8; util::SIGNATURE_SIZE]) -> Signature {\n        let mut r = Scalar::default();\n        let mut s = Scalar::default();\n\n        // Okay for signature to overflow\n        let _ = r.set_b32(array_ref!(p, 0, 32));\n        let _ = s.set_b32(array_ref!(p, 32, 32));\n\n        Signature { r, s }\n    }\n\n    pub fn parse_slice(p: &[u8]) -> Result<Signature, Error> {\n        if p.len() != util::SIGNATURE_SIZE {\n            return Err(Error::InvalidInputLength);\n        }\n\n        let mut a = [0; util::SIGNATURE_SIZE];\n        a.copy_from_slice(p);\n        Ok(Self::parse(&a))\n    }\n\n    pub fn parse_der(p: &[u8]) -> Result<Signature, Error> {\n        let mut decoder = der::Decoder::new(p);\n\n        decoder.read_constructed_sequence()?;\n        let rlen = decoder.read_len()?;\n\n        if rlen != decoder.remaining_len() {\n            return Err(Error::InvalidSignature);\n        }\n\n        let r = decoder.read_integer()?;\n        let s = decoder.read_integer()?;\n\n        if decoder.remaining_len() != 0 {\n            return Err(Error::InvalidSignature);\n        }\n\n        Ok(Signature { r, s })\n    }\n\n    /// Converts a \"lax DER\"-encoded byte slice to a signature. This is basically\n    /// only useful for validating signatures in the Bitcoin blockchain from before\n    /// 2016. It should never be used in new applications. This library does not\n    /// support serializing to this \"format\"\n    pub fn parse_der_lax(p: &[u8]) -> Result<Signature, Error> {\n        let mut decoder = der::Decoder::new(p);\n\n        decoder.read_constructed_sequence()?;\n        decoder.read_seq_len_lax()?;\n\n        let r = decoder.read_integer_lax()?;\n        let s = decoder.read_integer_lax()?;\n\n        Ok(Signature { r, s })\n    }\n\n    /// Normalizes a signature to a \"low S\" form. In ECDSA, signatures are\n    /// of the form (r, s) where r and s are numbers lying in some finite\n    /// field. The verification equation will pass for (r, s) iff it passes\n    /// for (r, -s), so it is possible to ``modify'' signatures in transit\n    /// by flipping the sign of s. This does not constitute a forgery since\n    /// the signed message still cannot be changed, but for some applications,\n    /// changing even the signature itself can be a problem. Such applications\n    /// require a \"strong signature\". It is believed that ECDSA is a strong\n    /// signature except for this ambiguity in the sign of s, so to accommodate\n    /// these applications libsecp256k1 will only accept signatures for which\n    /// s is in the lower half of the field range. This eliminates the\n    /// ambiguity.\n    ///\n    /// However, for some systems, signatures with high s-values are considered\n    /// valid. (For example, parsing the historic Bitcoin blockchain requires\n    /// this.) For these applications we provide this normalization function,\n    /// which ensures that the s value lies in the lower half of its range.\n    pub fn normalize_s(&mut self) {\n        if self.s.is_high() {\n            let s = self.s.clone();\n            self.s.neg_in_place(&s);\n        }\n    }\n\n\n    pub fn serialize(&self) -> [u8; util::SIGNATURE_SIZE] {\n        let mut ret = [0u8; 64];\n        self.r.fill_b32(array_mut_ref!(ret, 0, 32));\n        self.s.fill_b32(array_mut_ref!(ret, 32, 32));\n        ret\n    }\n\n    pub fn serialize_der(&self) -> der::SignatureArray {\n        fn fill_scalar_with_leading_zero(scalar: &Scalar) -> [u8; 33] {\n            let mut ret = [0u8; 33];\n            scalar.fill_b32(array_mut_ref!(ret, 1, 32));\n            ret\n        }\n\n        let r_full = fill_scalar_with_leading_zero(&self.r);\n        let s_full = fill_scalar_with_leading_zero(&self.s);\n\n        fn integer_slice(full: &[u8; 33]) -> &[u8] {\n            let mut len = 33;\n            while len > 1 &&\n                full[full.len() - len] == 0 &&\n                full[full.len() - len + 1] < 0x80\n            {\n                len -= 1;\n            }\n            &full[(full.len() - len)..]\n        }\n\n        let r = integer_slice(&r_full);\n        let s = integer_slice(&s_full);\n\n        let mut ret = der::SignatureArray::new(6 + r.len() + s.len());\n        {\n            let l = ret.as_mut();\n            l[0] = 0x30;\n            l[1] = 4 + r.len() as u8 + s.len() as u8;\n            l[2] = 0x02;\n            l[3] = r.len() as u8;\n            l[4..(4 + r.len())].copy_from_slice(r);\n            l[4 + r.len()] = 0x02;\n            l[5 + r.len()] = s.len() as u8;\n            l[(6 + r.len())..(6 + r.len() + s.len())].copy_from_slice(s);\n        }\n\n        ret\n    }\n}\n\nimpl Message {\n    pub fn parse(p: &[u8; util::MESSAGE_SIZE]) -> Message {\n        let mut m = Scalar::default();\n\n        // Okay for message to overflow.\n        let _ = m.set_b32(p);\n\n        Message(m)\n    }\n\n    pub fn parse_slice(p: &[u8]) -> Result<Message, Error> {\n        if p.len() != util::MESSAGE_SIZE {\n            return Err(Error::InvalidInputLength);\n        }\n\n        let mut a = [0; util::MESSAGE_SIZE];\n        a.copy_from_slice(p);\n        Ok(Self::parse(&a))\n    }\n\n    pub fn serialize(&self) -> [u8; util::MESSAGE_SIZE] {\n        self.0.b32()\n    }\n}\n\nimpl RecoveryId {\n    /// Parse recovery ID starting with 0.\n    pub fn parse(p: u8) -> Result<RecoveryId, Error> {\n        if p < 4 {\n            Ok(RecoveryId(p))\n        } else {\n            Err(Error::InvalidRecoveryId)\n        }\n    }\n\n    /// Parse recovery ID as Ethereum RPC format, starting with 27.\n    pub fn parse_rpc(p: u8) -> Result<RecoveryId, Error> {\n        if p >= 27 && p < 27 + 4 {\n            RecoveryId::parse(p - 27)\n        } else {\n            Err(Error::InvalidRecoveryId)\n        }\n    }\n\n    pub fn serialize(&self) -> u8 {\n        self.0\n    }\n}\n\nimpl Into<u8> for RecoveryId {\n    fn into(self) -> u8 {\n        self.0\n    }\n}\n\nimpl Into<i32> for RecoveryId {\n    fn into(self) -> i32 {\n        self.0 as i32\n    }\n}\n\nimpl SharedSecret {\n    pub fn new(pubkey: &PublicKey, seckey: &SecretKey) -> Result<SharedSecret, Error> {\n        let inner = match ECMULT_CONTEXT.ecdh_raw(&pubkey.0, &seckey.0) {\n            Some(val) => val,\n            None => return Err(Error::InvalidSecretKey),\n        };\n\n        Ok(SharedSecret(inner))\n    }\n\n}\n\nimpl AsRef<[u8]> for SharedSecret {\n    fn as_ref(&self) -> &[u8] {\n        &self.0\n    }\n}\n\nimpl Drop for SharedSecret {\n    fn drop(&mut self) {\n         unsafe {\n            core::ptr::write_volatile(&mut self.0, [0u8; 32]);\n        }\n    }\n}\n\n/// Check signature is a valid message signed by public key.\npub fn verify(message: &Message, signature: &Signature, pubkey: &PublicKey) -> bool {\n    ECMULT_CONTEXT.verify_raw(&signature.r, &signature.s, &pubkey.0, &message.0)\n}\n\n/// Recover public key from a signed message.\npub fn recover(message: &Message, signature: &Signature, recovery_id: &RecoveryId) -> Result<PublicKey, Error> {\n    ECMULT_CONTEXT.recover_raw(&signature.r, &signature.s, recovery_id.0, &message.0).map(|v| PublicKey(v))\n}\n\n/// Sign a message using the secret key.\npub fn sign(message: &Message, seckey: &SecretKey) -> (Signature, RecoveryId) {\n    let seckey_b32 = seckey.0.b32();\n    let message_b32 = message.0.b32();\n\n    let mut drbg = HmacDRBG::<Sha256>::new(&seckey_b32, &message_b32, &[]);\n    let mut nonce = Scalar::default();\n    let mut overflow;\n\n    let result;\n    loop {\n        let generated = drbg.generate::<U32>(None);\n        overflow = nonce.set_b32(array_ref!(generated, 0, 32));\n\n        if !overflow && !nonce.is_zero() {\n            match ECMULT_GEN_CONTEXT.sign_raw(&seckey.0, &message.0, &nonce) {\n                Ok(val) => {\n                    result = val;\n                    break\n                },\n                Err(_) => (),\n            }\n        }\n    }\n\n    #[allow(unused_assignments)]\n    {\n        nonce = Scalar::default();\n    }\n    let (sigr, sigs, recid) = result;\n\n    (Signature {\n        r: sigr,\n        s: sigs,\n    }, RecoveryId(recid))\n}\n", "use core::ops::{Add, AddAssign, Mul, MulAssign};\nuse subtle::Choice;\n\nconst SECP256K1_N_0: u32 = 0xD0364141;\nconst SECP256K1_N_1: u32 = 0xBFD25E8C;\nconst SECP256K1_N_2: u32 = 0xAF48A03B;\nconst SECP256K1_N_3: u32 = 0xBAAEDCE6;\nconst SECP256K1_N_4: u32 = 0xFFFFFFFE;\nconst SECP256K1_N_5: u32 = 0xFFFFFFFF;\nconst SECP256K1_N_6: u32 = 0xFFFFFFFF;\nconst SECP256K1_N_7: u32 = 0xFFFFFFFF;\n\nconst SECP256K1_N_C_0: u32 = !SECP256K1_N_0 + 1;\nconst SECP256K1_N_C_1: u32 = !SECP256K1_N_1;\nconst SECP256K1_N_C_2: u32 = !SECP256K1_N_2;\nconst SECP256K1_N_C_3: u32 = !SECP256K1_N_3;\nconst SECP256K1_N_C_4: u32 = 1;\n\nconst SECP256K1_N_H_0: u32 = 0x681B20A0;\nconst SECP256K1_N_H_1: u32 = 0xDFE92F46;\nconst SECP256K1_N_H_2: u32 = 0x57A4501D;\nconst SECP256K1_N_H_3: u32 = 0x5D576E73;\nconst SECP256K1_N_H_4: u32 = 0xFFFFFFFF;\nconst SECP256K1_N_H_5: u32 = 0xFFFFFFFF;\nconst SECP256K1_N_H_6: u32 = 0xFFFFFFFF;\nconst SECP256K1_N_H_7: u32 = 0x7FFFFFFF;\n\n#[derive(Debug, Clone, Eq, PartialEq)]\n/// A 256-bit scalar value.\npub struct Scalar(pub [u32; 8]);\n\nimpl Scalar {\n    /// Clear a scalar to prevent the leak of sensitive data.\n    pub fn clear(&mut self) {\n        unsafe {\n            core::ptr::write_volatile(&mut self.0, [0u32; 8]);\n        }\n    }\n\n    /// Set a scalar to an unsigned integer.\n    pub fn set_int(&mut self, v: u32) {\n        self.0 = [v, 0, 0, 0, 0, 0, 0, 0];\n    }\n\n    /// Create a scalar from an unsigned integer.\n    pub fn from_int(v: u32) -> Self {\n        let mut scalar = Self::default();\n        scalar.set_int(v);\n        scalar\n    }\n\n    /// Access bits from a scalar. All requested bits must belong to\n    /// the same 32-bit limb.\n    pub fn bits(&self, offset: usize, count: usize) -> u32 {\n        debug_assert!((offset + count - 1) >> 5 == offset >> 5);\n        (self.0[offset >> 5] >> (offset & 0x1F)) & ((1 << count) - 1)\n    }\n\n    /// Access bits from a scalar. Not constant time.\n    pub fn bits_var(&self, offset: usize, count: usize) -> u32 {\n        debug_assert!(count < 32);\n        debug_assert!(offset + count <= 256);\n        if (offset + count - 1) >> 5 == offset >> 5 {\n            return self.bits(offset, count);\n        } else {\n            debug_assert!((offset >> 5) + 1 < 8);\n            return ((self.0[offset >> 5] >> (offset & 0x1f)) | (self.0[(offset >> 5) + 1] << (32 - (offset & 0x1f)))) & ((1 << count) - 1);\n        }\n    }\n\n    #[must_use]\n    fn check_overflow(&self) -> bool {\n        let mut yes: Choice = 0.into();\n        let mut no: Choice = 0.into();\n        no |= Choice::from((self.0[7] < SECP256K1_N_7) as u8); /* No need for a > check. */\n        no |= Choice::from((self.0[6] < SECP256K1_N_6) as u8); /* No need for a > check. */\n        no |= Choice::from((self.0[5] < SECP256K1_N_5) as u8); /* No need for a > check. */\n        no |= Choice::from((self.0[4] < SECP256K1_N_4) as u8);\n        yes |= Choice::from((self.0[4] > SECP256K1_N_4) as u8) & !no;\n        no |= Choice::from((self.0[3] < SECP256K1_N_3) as u8) & !yes;\n        yes |= Choice::from((self.0[3] > SECP256K1_N_3) as u8) & !no;\n        no |= Choice::from((self.0[2] < SECP256K1_N_2) as u8) & !yes;\n        yes |= Choice::from((self.0[2] > SECP256K1_N_2) as u8) & !no;\n        no |= Choice::from((self.0[1] < SECP256K1_N_1) as u8) & !yes;\n        yes |= Choice::from((self.0[1] > SECP256K1_N_1) as u8) & !no;\n        yes |= Choice::from((self.0[0] >= SECP256K1_N_0) as u8) & !no;\n        return yes.into();\n    }\n\n    #[must_use]\n    fn reduce(&mut self, overflow: bool) -> bool {\n        let o: u64 = if overflow { 1 } else { 0 };\n        let mut t: u64;\n        t = (self.0[0] as u64) + o * (SECP256K1_N_C_0 as u64);\n        self.0[0] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (self.0[1] as u64) + o * (SECP256K1_N_C_1 as u64);\n        self.0[1] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (self.0[2] as u64) + o * (SECP256K1_N_C_2 as u64);\n        self.0[2] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (self.0[3] as u64) + o * (SECP256K1_N_C_3 as u64);\n        self.0[3] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (self.0[4] as u64) + o * (SECP256K1_N_C_4 as u64);\n        self.0[4] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += self.0[5] as u64;\n        self.0[5] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += self.0[6] as u64;\n        self.0[6] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += self.0[7] as u64;\n        self.0[7] = (t & 0xFFFFFFFF) as u32;\n        overflow\n    }\n\n    /// Add two scalars together (modulo the group order). Returns\n    /// whether it overflowed.\n    #[must_use]\n    pub fn add_in_place(&mut self, a: &Scalar, b: &Scalar) -> bool {\n        let mut overflow: u64;\n        let mut t: u64 = (a.0[0] as u64) + (b.0[0] as u64);\n        self.0[0] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (a.0[1] as u64) + (b.0[1] as u64);\n        self.0[1] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (a.0[2] as u64) + (b.0[2] as u64);\n        self.0[2] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (a.0[3] as u64) + (b.0[3] as u64);\n        self.0[3] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (a.0[4] as u64) + (b.0[4] as u64);\n        self.0[4] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (a.0[5] as u64) + (b.0[5] as u64);\n        self.0[5] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (a.0[6] as u64) + (b.0[6] as u64);\n        self.0[6] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (a.0[7] as u64) + (b.0[7] as u64);\n        self.0[7] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        overflow = t + if self.check_overflow() { 1 } else { 0 };\n        debug_assert!(overflow == 0 || overflow == 1);\n        overflow = overflow | if self.reduce(overflow == 1) { 1 } else { 0 };\n        return overflow == 1;\n    }\n\n    /// Conditionally add a power of two to a scalar. The result is\n    /// not allowed to overflow.\n    pub fn cadd_bit(&mut self, mut bit: usize, flag: bool) {\n        let mut t: u64;\n        debug_assert!(bit < 256);\n        bit += if flag { 0 } else { usize::max_value() } & 0x100;\n        t = (self.0[0] as u64) + ((if (bit >> 5) == 0 { 1 } else { 0 }) << (bit & 0x1F));\n        self.0[0] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (self.0[1] as u64) + ((if (bit >> 5) == 1 { 1 } else { 0 }) << (bit & 0x1F));\n        self.0[1] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (self.0[2] as u64) + ((if (bit >> 5) == 2 { 1 } else { 0 }) << (bit & 0x1F));\n        self.0[2] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (self.0[3] as u64) + ((if (bit >> 5) == 3 { 1 } else { 0 }) << (bit & 0x1F));\n        self.0[3] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (self.0[4] as u64) + ((if (bit >> 5) == 4 { 1 } else { 0 }) << (bit & 0x1F));\n        self.0[4] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (self.0[5] as u64) + ((if (bit >> 5) == 5 { 1 } else { 0 }) << (bit & 0x1F));\n        self.0[5] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (self.0[6] as u64) + ((if (bit >> 5) == 6 { 1 } else { 0 }) << (bit & 0x1F));\n        self.0[6] = (t & 0xFFFFFFFF) as u32; t >>= 32;\n        t += (self.0[7] as u64) + ((if (bit >> 5) == 7 { 1 } else { 0 }) << (bit & 0x1F));\n        self.0[7] = (t & 0xFFFFFFFF) as u32;\n        debug_assert!((t >> 32) == 0);\n        debug_assert!(!self.check_overflow());\n    }\n\n    /// Set a scalar from a big endian byte array, return whether it overflowed.\n    #[must_use]\n    pub fn set_b32(&mut self, b32: &[u8; 32]) -> bool {\n        self.0[0] = (b32[31] as u32) | ((b32[30] as u32) << 8) | ((b32[29] as u32) << 16) | ((b32[28] as u32) << 24);\n        self.0[1] = (b32[27] as u32) | ((b32[26] as u32) << 8) | ((b32[25] as u32) << 16) | ((b32[24] as u32) << 24);\n        self.0[2] = (b32[23] as u32) | ((b32[22] as u32) << 8) | ((b32[21] as u32) << 16) | ((b32[20] as u32) << 24);\n        self.0[3] = (b32[19] as u32) | ((b32[18] as u32) << 8) | ((b32[17] as u32) << 16) | ((b32[16] as u32) << 24);\n        self.0[4] = (b32[15] as u32) | ((b32[14] as u32) << 8) | ((b32[13] as u32) << 16) | ((b32[12] as u32) << 24);\n        self.0[5] = (b32[11] as u32) | ((b32[10] as u32) << 8) | ((b32[9] as u32) << 16) | ((b32[8] as u32) << 24);\n        self.0[6] = (b32[7] as u32) | ((b32[6] as u32) << 8) | ((b32[5] as u32) << 16) | ((b32[4] as u32) << 24);\n        self.0[7] = (b32[3] as u32) | ((b32[2] as u32) << 8) | ((b32[1] as u32) << 16) | ((b32[0] as u32) << 24);\n\n        let overflow = self.check_overflow();\n        self.reduce(overflow)\n    }\n\n    /// Convert a scalar to a byte array.\n    pub fn b32(&self) -> [u8; 32] {\n        let mut bin = [0u8; 32];\n        self.fill_b32(&mut bin);\n        bin\n    }\n\n    /// Convert a scalar to a byte array.\n    pub fn fill_b32(&self, bin: &mut [u8; 32]) {\n        bin[0] = (self.0[7] >> 24) as u8; bin[1] = (self.0[7] >> 16) as u8; bin[2] = (self.0[7] >> 8) as u8; bin[3] = (self.0[7]) as u8;\n        bin[4] = (self.0[6] >> 24) as u8; bin[5] = (self.0[6] >> 16) as u8; bin[6] = (self.0[6] >> 8) as u8; bin[7] = (self.0[6]) as u8;\n        bin[8] = (self.0[5] >> 24) as u8; bin[9] = (self.0[5] >> 16) as u8; bin[10] = (self.0[5] >> 8) as u8; bin[11] = (self.0[5]) as u8;\n        bin[12] = (self.0[4] >> 24) as u8; bin[13] = (self.0[4] >> 16) as u8; bin[14] = (self.0[4] >> 8) as u8; bin[15] = (self.0[4]) as u8;\n        bin[16] = (self.0[3] >> 24) as u8; bin[17] = (self.0[3] >> 16) as u8; bin[18] = (self.0[3] >> 8) as u8; bin[19] = (self.0[3]) as u8;\n        bin[20] = (self.0[2] >> 24) as u8; bin[21] = (self.0[2] >> 16) as u8; bin[22] = (self.0[2] >> 8) as u8; bin[23] = (self.0[2]) as u8;\n        bin[24] = (self.0[1] >> 24) as u8; bin[25] = (self.0[1] >> 16) as u8; bin[26] = (self.0[1] >> 8) as u8; bin[27] = (self.0[1]) as u8;\n        bin[28] = (self.0[0] >> 24) as u8; bin[29] = (self.0[0] >> 16) as u8; bin[30] = (self.0[0] >> 8) as u8; bin[31] = (self.0[0]) as u8;\n    }\n\n    /// Check whether a scalar equals zero.\n    pub fn is_zero(&self) -> bool {\n        (self.0[0] | self.0[1] | self.0[2] | self.0[3] | self.0[4] | self.0[5] | self.0[6] | self.0[7]) == 0\n    }\n\n    /// Compute the complement of a scalar (modulo the group order).\n    pub fn neg_in_place(&mut self, a: &Scalar) {\n        let nonzero: u64 = 0xFFFFFFFF * if !a.is_zero() { 1 } else { 0 };\n        let mut t: u64 = (!a.0[0]) as u64 + (SECP256K1_N_0 + 1) as u64;\n        self.0[0] = (t & nonzero) as u32; t >>= 32;\n        t += (!a.0[1]) as u64 + SECP256K1_N_1 as u64;\n        self.0[1] = (t & nonzero) as u32; t >>= 32;\n        t += (!a.0[2]) as u64 + SECP256K1_N_2 as u64;\n        self.0[2] = (t & nonzero) as u32; t >>= 32;\n        t += (!a.0[3]) as u64 + SECP256K1_N_3 as u64;\n        self.0[3] = (t & nonzero) as u32; t >>= 32;\n        t += (!a.0[4]) as u64 + SECP256K1_N_4 as u64;\n        self.0[4] = (t & nonzero) as u32; t >>= 32;\n        t += (!a.0[5]) as u64 + SECP256K1_N_5 as u64;\n        self.0[5] = (t & nonzero) as u32; t >>= 32;\n        t += (!a.0[6]) as u64 + SECP256K1_N_6 as u64;\n        self.0[6] = (t & nonzero) as u32; t >>= 32;\n        t += (!a.0[7]) as u64 + SECP256K1_N_7 as u64;\n        self.0[7] = (t & nonzero) as u32;\n    }\n\n    pub fn neg(&self) -> Scalar {\n        let mut ret = Scalar::default();\n        ret.neg_in_place(self);\n        ret\n    }\n\n    /// Check whether a scalar equals one.\n    pub fn is_one(&self) -> bool {\n        ((self.0[0] ^ 1) |  self.0[1] | self.0[2] | self.0[3] | self.0[4] | self.0[5] | self.0[6] | self.0[7]) == 0\n    }\n\n    /// Check whether a scalar is higher than the group order divided\n    /// by 2.\n    pub fn is_high(&self) -> bool {\n        let mut yes: bool = false;\n        let mut no: bool = false;\n        no = no || (self.0[7] < SECP256K1_N_H_7);\n        yes = yes || ((self.0[7] > SECP256K1_N_H_7) & !no);\n        no = no || ((self.0[6] < SECP256K1_N_H_6) & !yes); /* No need for a > check. */\n        no = no || ((self.0[5] < SECP256K1_N_H_5) & !yes); /* No need for a > check. */\n        no = no || ((self.0[4] < SECP256K1_N_H_4) & !yes); /* No need for a > check. */\n        no = no || ((self.0[3] < SECP256K1_N_H_3) & !yes);\n        yes = yes || ((self.0[3] > SECP256K1_N_H_3) && !no);\n        no = no || ((self.0[2] < SECP256K1_N_H_2) && !yes);\n        yes = yes || ((self.0[2] > SECP256K1_N_H_2) && !no);\n        no = no || ((self.0[1] < SECP256K1_N_H_1) && !yes);\n        yes = yes || ((self.0[1] > SECP256K1_N_H_1) && !no);\n        yes = yes || ((self.0[0] >= SECP256K1_N_H_0) && !no);\n        return yes;\n    }\n\n    /// Conditionally negate a number, in constant time. Returns -1 if\n    /// the number was negated, 1 otherwise.\n    pub fn cond_neg_mut(&mut self, flag: bool) -> isize {\n        let mask = if flag { u32::max_value() } else { 0 };\n        let nonzero: u64 = 0xFFFFFFFF * if !self.is_zero() { 1 } else { 0 };\n        let mut t: u64 = (self.0[0] ^ mask) as u64 + ((SECP256K1_N_0 + 1) & mask) as u64;\n        self.0[0] = (t & nonzero) as u32; t >>= 32;\n        t += (self.0[1] ^ mask) as u64 + (SECP256K1_N_1 & mask) as u64;\n        self.0[1] = (t & nonzero) as u32; t >>= 32;\n        t += (self.0[2] ^ mask) as u64 + (SECP256K1_N_2 & mask) as u64;\n        self.0[2] = (t & nonzero) as u32; t >>= 32;\n        t += (self.0[3] ^ mask) as u64 + (SECP256K1_N_3 & mask) as u64;\n        self.0[3] = (t & nonzero) as u32; t >>= 32;\n        t += (self.0[4] ^ mask) as u64 + (SECP256K1_N_4 & mask) as u64;\n        self.0[4] = (t & nonzero) as u32; t >>= 32;\n        t += (self.0[5] ^ mask) as u64 + (SECP256K1_N_5 & mask) as u64;\n        self.0[5] = (t & nonzero) as u32; t >>= 32;\n        t += (self.0[6] ^ mask) as u64 + (SECP256K1_N_6 & mask) as u64;\n        self.0[6] = (t & nonzero) as u32; t >>= 32;\n        t += (self.0[7] ^ mask) as u64 + (SECP256K1_N_7 & mask) as u64;\n        self.0[7] = (t & nonzero) as u32;\n\n        if mask == 0 {\n            return 1;\n        } else {\n            return -1;\n        }\n    }\n}\n\nmacro_rules! define_ops {\n    ($c0: ident, $c1: ident, $c2: ident) => {\n        #[allow(unused_macros)]\n        macro_rules! muladd {\n            ($a: expr, $b: expr) => {\n                let a = $a; let b = $b;\n                let t = (a as u64) * (b as u64);\n                let mut th = (t >> 32) as u32;\n                let tl = t as u32;\n                $c0 = $c0.wrapping_add(tl);\n                th = th.wrapping_add(if $c0 < tl { 1 } else { 0 });\n                $c1 = $c1.wrapping_add(th);\n                $c2 = $c2.wrapping_add(if $c1 < th { 1 } else { 0 });\n                debug_assert!($c1 >= th || $c2 != 0);\n            }\n        }\n\n        #[allow(unused_macros)]\n        macro_rules! muladd_fast {\n            ($a: expr, $b: expr) => {\n                let a = $a; let b = $b;\n                let t = (a as u64) * (b as u64);\n                let mut th = (t >> 32) as u32;\n                let tl = t as u32;\n                $c0 = $c0.wrapping_add(tl);\n                th = th.wrapping_add(if $c0 < tl { 1 } else { 0 });\n                $c1 = $c1.wrapping_add(th);\n                debug_assert!($c1 >= th);\n            }\n        }\n\n        #[allow(unused_macros)]\n        macro_rules! muladd2 {\n            ($a: expr, $b: expr) => {\n                let a = $a; let b = $b;\n                let t = (a as u64) * (b as u64);\n                let th = (t >> 32) as u32;\n                let tl = t as u32;\n                let mut th2 = th.wrapping_add(th);\n                $c2 = $c2.wrapping_add(if th2 < th { 1 } else { 0 });\n                debug_assert!(th2 >= th || $c2 != 0);\n                let tl2 = tl.wrapping_add(tl);\n                th2 = th2.wrapping_add(if tl2 < tl { 1 } else { 0 });\n                $c0 = $c0.wrapping_add(tl2);\n                th2 = th2.wrapping_add(if $c0 < tl2 { 1 } else { 0 });\n                $c2 = $c2.wrapping_add(if $c0 < tl2 && th2 == 0 { 1 } else { 0 });\n                debug_assert!($c0 >= tl2 || th2 != 0 || $c2 != 0);\n                $c1 = $c1.wrapping_add(th2);\n                $c2 = $c2.wrapping_add(if $c1 < th2 { 1 } else { 0 });\n                debug_assert!($c1 >= th2 || $c2 != 0);\n            }\n        }\n\n        #[allow(unused_macros)]\n        macro_rules! sumadd {\n            ($a: expr) => {\n                let a = $a;\n                $c0 = $c0.wrapping_add(a);\n                let over = if $c0 < a { 1 } else { 0 };\n                $c1 = $c1.wrapping_add(over);\n                $c2 = $c2.wrapping_add(if $c1 < over { 1 } else { 0 });\n            }\n        }\n\n        #[allow(unused_macros)]\n        macro_rules! sumadd_fast {\n            ($a: expr) => {\n                let a = $a;\n                $c0 = $c0.wrapping_add(a);\n                $c1 = $c1.wrapping_add(if $c0 < a { 1 } else { 0 });\n                debug_assert!($c1 != 0 || $c0 >= a);\n                debug_assert!($c2 == 0);\n            }\n        }\n\n        #[allow(unused_macros)]\n        macro_rules! extract {\n            () => {\n                {\n                    #[allow(unused_assignments)]\n                    {\n                        let n = $c0;\n                        $c0 = $c1;\n                        $c1 = $c2;\n                        $c2 = 0;\n                        n\n                    }\n                }\n            }\n        }\n\n        #[allow(unused_macros)]\n        macro_rules! extract_fast {\n            () => {\n                {\n                    #[allow(unused_assignments)]\n                    {\n                        let n = $c0;\n                        $c0 = $c1;\n                        $c1 = 0;\n                        debug_assert!($c2 == 0);\n                        n\n                    }\n                }\n            }\n        }\n    }\n}\n\nimpl Scalar {\n    fn reduce_512(&mut self, l: &[u32; 16]) {\n        let (mut c0, mut c1, mut c2): (u32, u32, u32);\n        define_ops!(c0, c1, c2);\n\n        let mut c: u64;\n        let (n0, n1, n2, n3, n4, n5, n6, n7) = (l[8], l[9], l[10], l[11], l[12], l[13], l[14], l[15]);\n        let (m0, m1, m2, m3, m4, m5, m6, m7, m8, m9, m10, m11, m12): (u32, u32, u32, u32, u32, u32, u32, u32, u32, u32, u32, u32, u32);\n        let (p0, p1, p2, p3, p4, p5, p6, p7, p8): (u32, u32, u32, u32, u32, u32, u32, u32, u32);\n\n        c0 = l[0]; c1 = 0; c2 = 0;\n        muladd_fast!(n0, SECP256K1_N_C_0);\n        m0 = extract_fast!();\n        sumadd_fast!(l[1]);\n        muladd!(n1, SECP256K1_N_C_0);\n        muladd!(n0, SECP256K1_N_C_1);\n        m1 = extract!();\n        sumadd!(l[2]);\n        muladd!(n2, SECP256K1_N_C_0);\n        muladd!(n1, SECP256K1_N_C_1);\n        muladd!(n0, SECP256K1_N_C_2);\n        m2 = extract!();\n        sumadd!(l[3]);\n        muladd!(n3, SECP256K1_N_C_0);\n        muladd!(n2, SECP256K1_N_C_1);\n        muladd!(n1, SECP256K1_N_C_2);\n        muladd!(n0, SECP256K1_N_C_3);\n        m3 = extract!();\n        sumadd!(l[4]);\n        muladd!(n4, SECP256K1_N_C_0);\n        muladd!(n3, SECP256K1_N_C_1);\n        muladd!(n2, SECP256K1_N_C_2);\n        muladd!(n1, SECP256K1_N_C_3);\n        sumadd!(n0);\n        m4 = extract!();\n        sumadd!(l[5]);\n        muladd!(n5, SECP256K1_N_C_0);\n        muladd!(n4, SECP256K1_N_C_1);\n        muladd!(n3, SECP256K1_N_C_2);\n        muladd!(n2, SECP256K1_N_C_3);\n        sumadd!(n1);\n        m5 = extract!();\n        sumadd!(l[6]);\n        muladd!(n6, SECP256K1_N_C_0);\n        muladd!(n5, SECP256K1_N_C_1);\n        muladd!(n4, SECP256K1_N_C_2);\n        muladd!(n3, SECP256K1_N_C_3);\n        sumadd!(n2);\n        m6 = extract!();\n        sumadd!(l[7]);\n        muladd!(n7, SECP256K1_N_C_0);\n        muladd!(n6, SECP256K1_N_C_1);\n        muladd!(n5, SECP256K1_N_C_2);\n        muladd!(n4, SECP256K1_N_C_3);\n        sumadd!(n3);\n        m7 = extract!();\n        muladd!(n7, SECP256K1_N_C_1);\n        muladd!(n6, SECP256K1_N_C_2);\n        muladd!(n5, SECP256K1_N_C_3);\n        sumadd!(n4);\n        m8 = extract!();\n        muladd!(n7, SECP256K1_N_C_2);\n        muladd!(n6, SECP256K1_N_C_3);\n        sumadd!(n5);\n        m9 = extract!();\n        muladd!(n7, SECP256K1_N_C_3);\n        sumadd!(n6);\n        m10 = extract!();\n        sumadd_fast!(n7);\n        m11 = extract_fast!();\n        debug_assert!(c0 <= 1);\n        m12 = c0;\n\n        /* Reduce 385 bits into 258. */\n        /* p[0..8] = m[0..7] + m[8..12] * SECP256K1_N_C. */\n        c0 = m0; c1 = 0; c2 = 0;\n        muladd_fast!(m8, SECP256K1_N_C_0);\n        p0 = extract_fast!();\n        sumadd_fast!(m1);\n        muladd!(m9, SECP256K1_N_C_0);\n        muladd!(m8, SECP256K1_N_C_1);\n        p1 = extract!();\n        sumadd!(m2);\n        muladd!(m10, SECP256K1_N_C_0);\n        muladd!(m9, SECP256K1_N_C_1);\n        muladd!(m8, SECP256K1_N_C_2);\n        p2 = extract!();\n        sumadd!(m3);\n        muladd!(m11, SECP256K1_N_C_0);\n        muladd!(m10, SECP256K1_N_C_1);\n        muladd!(m9, SECP256K1_N_C_2);\n        muladd!(m8, SECP256K1_N_C_3);\n        p3 = extract!();\n        sumadd!(m4);\n        muladd!(m12, SECP256K1_N_C_0);\n        muladd!(m11, SECP256K1_N_C_1);\n        muladd!(m10, SECP256K1_N_C_2);\n        muladd!(m9, SECP256K1_N_C_3);\n        sumadd!(m8);\n        p4 = extract!();\n        sumadd!(m5);\n        muladd!(m12, SECP256K1_N_C_1);\n        muladd!(m11, SECP256K1_N_C_2);\n        muladd!(m10, SECP256K1_N_C_3);\n        sumadd!(m9);\n        p5 = extract!();\n        sumadd!(m6);\n        muladd!(m12, SECP256K1_N_C_2);\n        muladd!(m11, SECP256K1_N_C_3);\n        sumadd!(m10);\n        p6 = extract!();\n        sumadd_fast!(m7);\n        muladd_fast!(m12, SECP256K1_N_C_3);\n        sumadd_fast!(m11);\n        p7 = extract_fast!();\n        p8 = c0 + m12;\n        debug_assert!(p8 <= 2);\n\n        /* Reduce 258 bits into 256. */\n        /* r[0..7] = p[0..7] + p[8] * SECP256K1_N_C. */\n        c = p0 as u64 + SECP256K1_N_C_0 as u64 * p8 as u64;\n        self.0[0] = (c & 0xFFFFFFFF) as u32; c >>= 32;\n        c += p1 as u64 + SECP256K1_N_C_1 as u64 * p8 as u64;\n        self.0[1] = (c & 0xFFFFFFFF) as u32; c >>= 32;\n        c += p2 as u64 + SECP256K1_N_C_2 as u64 * p8 as u64;\n        self.0[2] = (c & 0xFFFFFFFF) as u32; c >>= 32;\n        c += p3 as u64 + SECP256K1_N_C_3 as u64 * p8 as u64;\n        self.0[3] = (c & 0xFFFFFFFF) as u32; c >>= 32;\n        c += p4 as u64 + p8 as u64;\n        self.0[4] = (c & 0xFFFFFFFF) as u32; c >>= 32;\n        c += p5 as u64;\n        self.0[5] = (c & 0xFFFFFFFF) as u32; c >>= 32;\n        c += p6 as u64;\n        self.0[6] = (c & 0xFFFFFFFF) as u32; c >>= 32;\n        c += p7 as u64;\n        self.0[7] = (c & 0xFFFFFFFF) as u32; c >>= 32;\n\n        let overflow = self.check_overflow();\n        debug_assert!(c + if overflow { 1 } else { 0 } <= 1);\n        let _ = self.reduce(c + if overflow { 1 } else { 0 } == 1);\n    }\n\n    fn mul_512(&self, b: &Scalar, l: &mut [u32; 16]) {\n        let (mut c0, mut c1, mut c2): (u32, u32, u32) = (0, 0, 0);\n        define_ops!(c0, c1, c2);\n\n        /* l[0..15] = a[0..7] * b[0..7]. */\n        muladd_fast!(self.0[0], b.0[0]);\n        l[0] = extract_fast!();\n        muladd!(self.0[0], b.0[1]);\n        muladd!(self.0[1], b.0[0]);\n        l[1] = extract!();\n        muladd!(self.0[0], b.0[2]);\n        muladd!(self.0[1], b.0[1]);\n        muladd!(self.0[2], b.0[0]);\n        l[2] = extract!();\n        muladd!(self.0[0], b.0[3]);\n        muladd!(self.0[1], b.0[2]);\n        muladd!(self.0[2], b.0[1]);\n        muladd!(self.0[3], b.0[0]);\n        l[3] = extract!();\n        muladd!(self.0[0], b.0[4]);\n        muladd!(self.0[1], b.0[3]);\n        muladd!(self.0[2], b.0[2]);\n        muladd!(self.0[3], b.0[1]);\n        muladd!(self.0[4], b.0[0]);\n        l[4] = extract!();\n        muladd!(self.0[0], b.0[5]);\n        muladd!(self.0[1], b.0[4]);\n        muladd!(self.0[2], b.0[3]);\n        muladd!(self.0[3], b.0[2]);\n        muladd!(self.0[4], b.0[1]);\n        muladd!(self.0[5], b.0[0]);\n        l[5] = extract!();\n        muladd!(self.0[0], b.0[6]);\n        muladd!(self.0[1], b.0[5]);\n        muladd!(self.0[2], b.0[4]);\n        muladd!(self.0[3], b.0[3]);\n        muladd!(self.0[4], b.0[2]);\n        muladd!(self.0[5], b.0[1]);\n        muladd!(self.0[6], b.0[0]);\n        l[6] = extract!();\n        muladd!(self.0[0], b.0[7]);\n        muladd!(self.0[1], b.0[6]);\n        muladd!(self.0[2], b.0[5]);\n        muladd!(self.0[3], b.0[4]);\n        muladd!(self.0[4], b.0[3]);\n        muladd!(self.0[5], b.0[2]);\n        muladd!(self.0[6], b.0[1]);\n        muladd!(self.0[7], b.0[0]);\n        l[7] = extract!();\n        muladd!(self.0[1], b.0[7]);\n        muladd!(self.0[2], b.0[6]);\n        muladd!(self.0[3], b.0[5]);\n        muladd!(self.0[4], b.0[4]);\n        muladd!(self.0[5], b.0[3]);\n        muladd!(self.0[6], b.0[2]);\n        muladd!(self.0[7], b.0[1]);\n        l[8] = extract!();\n        muladd!(self.0[2], b.0[7]);\n        muladd!(self.0[3], b.0[6]);\n        muladd!(self.0[4], b.0[5]);\n        muladd!(self.0[5], b.0[4]);\n        muladd!(self.0[6], b.0[3]);\n        muladd!(self.0[7], b.0[2]);\n        l[9] = extract!();\n        muladd!(self.0[3], b.0[7]);\n        muladd!(self.0[4], b.0[6]);\n        muladd!(self.0[5], b.0[5]);\n        muladd!(self.0[6], b.0[4]);\n        muladd!(self.0[7], b.0[3]);\n        l[10] = extract!();\n        muladd!(self.0[4], b.0[7]);\n        muladd!(self.0[5], b.0[6]);\n        muladd!(self.0[6], b.0[5]);\n        muladd!(self.0[7], b.0[4]);\n        l[11] = extract!();\n        muladd!(self.0[5], b.0[7]);\n        muladd!(self.0[6], b.0[6]);\n        muladd!(self.0[7], b.0[5]);\n        l[12] = extract!();\n        muladd!(self.0[6], b.0[7]);\n        muladd!(self.0[7], b.0[6]);\n        l[13] = extract!();\n        muladd_fast!(self.0[7], b.0[7]);\n        l[14] = extract_fast!();\n        debug_assert!(c1 == 0);\n        l[15] = c0;\n    }\n\n    fn sqr_512(&self, l: &mut [u32; 16]) {\n        let (mut c0, mut c1, mut c2): (u32, u32, u32) = (0, 0, 0);\n        define_ops!(c0, c1, c2);\n\n        /* l[0..15] = a[0..7]^2. */\n        muladd_fast!(self.0[0], self.0[0]);\n        l[0] = extract_fast!();\n        muladd2!(self.0[0], self.0[1]);\n        l[1] = extract!();\n        muladd2!(self.0[0], self.0[2]);\n        muladd!(self.0[1], self.0[1]);\n        l[2] = extract!();\n        muladd2!(self.0[0], self.0[3]);\n        muladd2!(self.0[1], self.0[2]);\n        l[3] = extract!();\n        muladd2!(self.0[0], self.0[4]);\n        muladd2!(self.0[1], self.0[3]);\n        muladd!(self.0[2], self.0[2]);\n        l[4] = extract!();\n        muladd2!(self.0[0], self.0[5]);\n        muladd2!(self.0[1], self.0[4]);\n        muladd2!(self.0[2], self.0[3]);\n        l[5] = extract!();\n        muladd2!(self.0[0], self.0[6]);\n        muladd2!(self.0[1], self.0[5]);\n        muladd2!(self.0[2], self.0[4]);\n        muladd!(self.0[3], self.0[3]);\n        l[6] = extract!();\n        muladd2!(self.0[0], self.0[7]);\n        muladd2!(self.0[1], self.0[6]);\n        muladd2!(self.0[2], self.0[5]);\n        muladd2!(self.0[3], self.0[4]);\n        l[7] = extract!();\n        muladd2!(self.0[1], self.0[7]);\n        muladd2!(self.0[2], self.0[6]);\n        muladd2!(self.0[3], self.0[5]);\n        muladd!(self.0[4], self.0[4]);\n        l[8] = extract!();\n        muladd2!(self.0[2], self.0[7]);\n        muladd2!(self.0[3], self.0[6]);\n        muladd2!(self.0[4], self.0[5]);\n        l[9] = extract!();\n        muladd2!(self.0[3], self.0[7]);\n        muladd2!(self.0[4], self.0[6]);\n        muladd!(self.0[5], self.0[5]);\n        l[10] = extract!();\n        muladd2!(self.0[4], self.0[7]);\n        muladd2!(self.0[5], self.0[6]);\n        l[11] = extract!();\n        muladd2!(self.0[5], self.0[7]);\n        muladd!(self.0[6], self.0[6]);\n        l[12] = extract!();\n        muladd2!(self.0[6], self.0[7]);\n        l[13] = extract!();\n        muladd_fast!(self.0[7], self.0[7]);\n        l[14] = extract_fast!();\n        debug_assert!(c1 == 0);\n        l[15] = c0;\n    }\n\n    pub fn mul_in_place(&mut self, a: &Scalar, b: &Scalar) {\n        let mut l = [0u32; 16];\n        a.mul_512(b, &mut l);\n        self.reduce_512(&l);\n    }\n\n    /// Shift a scalar right by some amount strictly between 0 and 16,\n    /// returning the low bits that were shifted off.\n    pub fn shr_int(&mut self, n: usize) -> u32 {\n        let ret: u32;\n        debug_assert!(n > 0);\n        debug_assert!(n < 16);\n        ret = self.0[0] & ((1 << n) - 1);\n        self.0[0] = (self.0[0] >> n) + (self.0[1] << (32 - n));\n        self.0[1] = (self.0[1] >> n) + (self.0[2] << (32 - n));\n        self.0[2] = (self.0[2] >> n) + (self.0[3] << (32 - n));\n        self.0[3] = (self.0[3] >> n) + (self.0[4] << (32 - n));\n        self.0[4] = (self.0[4] >> n) + (self.0[5] << (32 - n));\n        self.0[5] = (self.0[5] >> n) + (self.0[6] << (32 - n));\n        self.0[6] = (self.0[6] >> n) + (self.0[7] << (32 - n));\n        self.0[7] = self.0[7] >> n;\n        return ret;\n    }\n\n    pub fn sqr_in_place(&mut self, a: &Scalar) {\n        let mut l = [0u32; 16];\n        a.sqr_512(&mut l);\n        self.reduce_512(&l);\n    }\n\n    pub fn sqr(&self) -> Scalar {\n        let mut ret = Scalar::default();\n        ret.sqr_in_place(self);\n        ret\n    }\n\n    pub fn inv_in_place(&mut self, x: &Scalar) {\n        let u2 = x.sqr();\n        let x2 = &u2 * x;\n        let u5 = &u2 * &x2;\n        let x3 = &u5 * &u2;\n        let u9 = &x3 * &u2;\n        let u11 = &u9 * &u2;\n        let u13 = &u11 * &u2;\n\n        let mut x6 = u13.sqr();\n        x6 = x6.sqr();\n        x6 *= &u11;\n\n        let mut x8 = x6.sqr();\n        x8 = x8.sqr();\n        x8 *= &x2;\n\n        let mut x14 = x8.sqr();\n        for _ in 0..5 {\n            x14 = x14.sqr();\n        }\n        x14 *= &x6;\n\n        let mut x28 = x14.sqr();\n        for _ in 0..13 {\n            x28 = x28.sqr();\n        }\n        x28 *= &x14;\n\n        let mut x56 = x28.sqr();\n        for _ in 0..27 {\n            x56 = x56.sqr();\n        }\n        x56 *= &x28;\n\n        let mut x112 = x56.sqr();\n        for _ in 0..55 {\n            x112 = x112.sqr();\n        }\n        x112 *= &x56;\n\n        let mut x126 = x112.sqr();\n        for _ in 0..13 {\n            x126 = x126.sqr();\n        }\n        x126 *= &x14;\n\n        let mut t = x126;\n        for _ in 0..3 {\n            t = t.sqr();\n        }\n        t *= &u5;\n        for _ in 0..4 {\n            t = t.sqr();\n        }\n        t *= &x3;\n        for _ in 0..4 {\n            t = t.sqr();\n        }\n        t *= &u5;\n        for _ in 0..5 {\n            t = t.sqr();\n        }\n        t *= &u11;\n        for _ in 0..4 {\n            t = t.sqr();\n        }\n        t *= &u11;\n        for _ in 0..4 {\n            t = t.sqr();\n        }\n        t *= &x3;\n        for _ in 0..5 {\n            t = t.sqr();\n        }\n        t *= &x3;\n        for _ in 0..6 {\n            t = t.sqr();\n        }\n        t *= &u13;\n        for _ in 0..4 {\n            t = t.sqr();\n        }\n        t *= &u5;\n        for _ in 0..3 {\n            t = t.sqr();\n        }\n        t *= &x3;\n        for _ in 0..5 {\n            t = t.sqr();\n        }\n        t *= &u9;\n        for _ in 0..6 {\n            t = t.sqr();\n        }\n        t *= &u5;\n        for _ in 0..10 {\n            t = t.sqr();\n        }\n        t *= &x3;\n        for _ in 0..4 {\n            t = t.sqr();\n        }\n        t *= &x3;\n        for _ in 0..9 {\n            t = t.sqr();\n        }\n        t *= &x8;\n        for _ in 0..5 {\n            t = t.sqr();\n        }\n        t *= &u9;\n        for _ in 0..6 {\n            t = t.sqr();\n        }\n        t *= &u11;\n        for _ in 0..4 {\n            t = t.sqr();\n        }\n        t *= &u13;\n        for _ in 0..5 {\n            t = t.sqr();\n        }\n        t *= &x2;\n        for _ in 0..6 {\n            t = t.sqr();\n        }\n        t *= &u13;\n        for _ in 0..10 {\n            t = t.sqr();\n        }\n        t *= &u13;\n        for _ in 0..4 {\n            t = t.sqr();\n        }\n        t *= &u9;\n        for _ in 0..6 {\n            t = t.sqr();\n        }\n        t *= x;\n        for _ in 0..8 {\n            t = t.sqr();\n        }\n        *self = &t * &x6;\n    }\n\n    pub fn inv(&self) -> Scalar {\n        let mut ret = Scalar::default();\n        ret.inv_in_place(self);\n        ret\n    }\n\n    pub fn inv_var(&self) -> Scalar {\n        self.inv()\n    }\n\n    pub fn is_even(&self) -> bool {\n        return self.0[0] & 1 == 0;\n    }\n}\n\nimpl Default for Scalar {\n    fn default() -> Scalar {\n        Scalar([0u32; 8])\n    }\n}\n\nimpl Add<Scalar> for Scalar {\n    type Output = Scalar;\n    fn add(self, other: Scalar) -> Scalar {\n        let mut ret = Scalar::default();\n        let _ = ret.add_in_place(&self, &other);\n        ret\n    }\n}\n\nimpl<'a, 'b> Add<&'a Scalar> for &'b Scalar {\n    type Output = Scalar;\n    fn add(self, other: &'a Scalar) -> Scalar {\n        let mut ret = Scalar::default();\n        let _ = ret.add_in_place(self, other);\n        ret\n    }\n}\n\nimpl<'a> AddAssign<&'a Scalar> for Scalar {\n    fn add_assign(&mut self, other: &'a Scalar) {\n        let mut ret = Scalar::default();\n        let _ = ret.add_in_place(self, other);\n        *self = ret;\n    }\n}\n\nimpl AddAssign<Scalar> for Scalar {\n    fn add_assign(&mut self, other: Scalar) {\n        self.add_assign(&other)\n    }\n}\n\nimpl Mul<Scalar> for Scalar {\n    type Output = Scalar;\n    fn mul(self, other: Scalar) -> Scalar {\n        let mut ret = Scalar::default();\n        ret.mul_in_place(&self, &other);\n        ret\n    }\n}\n\nimpl<'a, 'b> Mul<&'a Scalar> for &'b Scalar {\n    type Output = Scalar;\n    fn mul(self, other: &'a Scalar) -> Scalar {\n        let mut ret = Scalar::default();\n        ret.mul_in_place(self, other);\n        ret\n    }\n}\n\nimpl<'a> MulAssign<&'a Scalar> for Scalar {\n    fn mul_assign(&mut self, other: &'a Scalar) {\n        let mut ret = Scalar::default();\n        ret.mul_in_place(self, other);\n        *self = ret;\n    }\n}\n\nimpl MulAssign<Scalar> for Scalar {\n    fn mul_assign(&mut self, other: Scalar) {\n        self.mul_assign(&other)\n    }\n}\n"], "filenames": ["Cargo.toml", "src/lib.rs", "src/scalar.rs"], "buggy_code_start_loc": [5, 10, 1], "buggy_code_end_loc": [26, 11, 87], "fixing_code_start_loc": [5, 10, 2], "fixing_code_end_loc": [32, 11, 88], "type": "CWE-203", "message": "A timing vulnerability in the Scalar::check_overflow function in Parity libsecp256k1-rs before 0.3.1 potentially allows an attacker to leak information via a side-channel attack.", "other": {"cve": {"id": "CVE-2019-20399", "sourceIdentifier": "cve@mitre.org", "published": "2020-01-23T00:15:09.953", "lastModified": "2021-07-21T11:39:23.747", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "A timing vulnerability in the Scalar::check_overflow function in Parity libsecp256k1-rs before 0.3.1 potentially allows an attacker to leak information via a side-channel attack."}, {"lang": "es", "value": "Una vulnerabilidad de sincronizaci\u00f3n en la funci\u00f3n Scalar::check_overflow en Parity libsecp256k1-rs versiones anteriores a 0.3.1, potencialmente permite a un atacante filtrar informaci\u00f3n por medio de un ataque de canal lateral."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 5.9, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.2, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:P/I:N/A:N", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 4.3}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.6, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-203"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:parity:libsecp256k1:*:*:*:*:*:*:*:*", "versionEndExcluding": "0.3.1", "matchCriteriaId": "A7665033-D035-4D05-B501-2D9BA2DA7B1A"}]}]}], "references": [{"url": "https://github.com/paritytech/libsecp256k1/commit/11ba23a9766a5079918cd9f515bc100bc8164b50", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/paritytech/libsecp256k1/commit/11ba23a9766a5079918cd9f515bc100bc8164b50"}}
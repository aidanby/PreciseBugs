{"buggy_code": ["\"\"\"\nSPDX-License-Identifier: Apache-2.0\nCopyright 2017 Massachusetts Institute of Technology.\n\"\"\"\n\nimport ast\nimport base64\nimport time\n\nfrom keylime import config\nfrom keylime import keylime_logging\nfrom keylime import crypto\nfrom keylime import json\nfrom keylime import revocation_notifier\nfrom keylime.agentstates import AgentAttestStates\nfrom keylime.failure import Failure, Component\nfrom keylime.tpm.tpm_main import tpm\nfrom keylime.tpm.tpm_abstract import TPM_Utilities\nfrom keylime.common import algorithms\nfrom keylime import ima_file_signatures\n\n# setup logging\nlogger = keylime_logging.init_logging('cloudverifier_common')\n\nGLOBAL_TPM_INSTANCE = None\nDEFAULT_VERIFIER_ID = \"default\"\n\n\ndef get_tpm_instance():\n    global GLOBAL_TPM_INSTANCE\n    if GLOBAL_TPM_INSTANCE is None:\n        GLOBAL_TPM_INSTANCE = tpm()\n    return GLOBAL_TPM_INSTANCE\n\n\ndef get_AgentAttestStates():\n    return AgentAttestStates.get_instance()\n\n\ndef process_quote_response(agent, json_response, agentAttestState) -> Failure:\n    \"\"\"Validates the response from the Cloud agent.\n\n    This method invokes an Registrar Server call to register, and then check the quote.\n    \"\"\"\n    failure = Failure(Component.QUOTE_VALIDATION)\n    received_public_key = None\n    quote = None\n    # in case of failure in response content do not continue\n    try:\n        received_public_key = json_response.get(\"pubkey\", None)\n        quote = json_response[\"quote\"]\n\n        ima_measurement_list = json_response.get(\"ima_measurement_list\", None)\n        ima_measurement_list_entry = json_response.get(\"ima_measurement_list_entry\", 0)\n        mb_measurement_list = json_response.get(\"mb_measurement_list\", None)\n        boottime = json_response.get(\"boottime\", 0)\n\n        logger.debug(\"received quote:      %s\", quote)\n        logger.debug(\"for nonce:           %s\", agent['nonce'])\n        logger.debug(\"received public key: %s\", received_public_key)\n        logger.debug(\"received ima_measurement_list    %s\", (ima_measurement_list is not None))\n        logger.debug(\"received ima_measurement_list_entry: %d\", ima_measurement_list_entry)\n        logger.debug(\"received boottime: %s\", boottime)\n        logger.debug(\"received boot log    %s\", (mb_measurement_list is not None))\n    except Exception as e:\n        failure.add_event(\"invalid_data\", {\"message\": \"parsing agents get quote respone failed\", \"data\": e}, False)\n        return failure\n\n    # TODO: Are those separate failures?\n    if not isinstance(ima_measurement_list_entry, int):\n        raise Exception(\"ima_measurement_list_entry parameter must be an integer\")\n\n    if not isinstance(boottime, int):\n        raise Exception(\"boottime parameter must be an integer\")\n\n    # if no public key provided, then ensure we have cached it\n    if received_public_key is None:\n        if agent.get('public_key', \"\") == \"\" or agent.get('b64_encrypted_V', \"\") == \"\":\n            logger.error(\"agent did not provide public key and no key or encrypted_v was cached at CV\")\n            failure.add_event(\"no_pubkey\", \"agent did not provide public key and no key or encrypted_v was cached at CV\", False)\n            return failure\n        agent['provide_V'] = False\n        received_public_key = agent['public_key']\n\n    hash_alg = json_response.get('hash_alg')\n    enc_alg = json_response.get('enc_alg')\n    sign_alg = json_response.get('sign_alg')\n\n    # Update chosen tpm and algorithms\n    agent['hash_alg'] = hash_alg\n    agent['enc_alg'] = enc_alg\n    agent['sign_alg'] = sign_alg\n\n    # Ensure hash_alg is in accept_tpm_hash_alg list\n    if not algorithms.is_accepted(hash_alg, agent['accept_tpm_hash_algs'])\\\n            or not algorithms.Hash.is_recognized(hash_alg):\n        logger.error(f\"TPM Quote is using an unaccepted hash algorithm: {hash_alg}\")\n        failure.add_event(\"invalid_hash_alg\",\n                          {\"message\": f\"TPM Quote is using an unaccepted hash algorithm: {hash_alg}\", \"data\": hash_alg},\n                          False)\n        return failure\n\n    # Ensure enc_alg is in accept_tpm_encryption_algs list\n    if not algorithms.is_accepted(enc_alg, agent['accept_tpm_encryption_algs']):\n        logger.error(f\"TPM Quote is using an unaccepted encryption algorithm: {enc_alg}\")\n        failure.add_event(\"invalid_enc_alg\",\n                          {\"message\": f\"TPM Quote is using an unaccepted encryption algorithm: {enc_alg}\", \"data\": enc_alg},\n                          False)\n        return failure\n\n    # Ensure sign_alg is in accept_tpm_encryption_algs list\n    if not algorithms.is_accepted(sign_alg, agent['accept_tpm_signing_algs']):\n        logger.error(f\"TPM Quote is using an unaccepted signing algorithm: {sign_alg}\")\n        failure.add_event(\"invalid_sign_alg\",\n                          {\"message\": f\"TPM Quote is using an unaccepted signing algorithm: {sign_alg}\", \"data\": {sign_alg}},\n                          False)\n        return failure\n\n    if ima_measurement_list_entry == 0:\n        agentAttestState.reset_ima_attestation()\n    elif ima_measurement_list_entry != agentAttestState.get_next_ima_ml_entry():\n        # If we requested a particular entry number then the agent must return either\n        # starting at 0 (handled above) or with the requested number.\n        logger.error(\"Agent did not respond with requested next IMA measurement list entry \"\n                     f\"{agentAttestState.get_next_ima_ml_entry()} but started at {ima_measurement_list_entry}\")\n        failure.add_event(\"invalid_ima_entry_nb\",\n                          {\"message\": \"Agent did not respond with requested next IMA measurement list entry\",\n                           \"got\": ima_measurement_list_entry, \"expected\": agentAttestState.get_next_ima_ml_entry()},\n                          False)\n    elif not agentAttestState.is_expected_boottime(boottime):\n        # agent sent a list not starting at 0 and provided a boottime that doesn't\n        # match the expected boottime, so it must have been rebooted; we would fail\n        # attestation this time so we retry with a full attestation next time.\n        agentAttestState.reset_ima_attestation()\n        return failure\n\n    agentAttestState.set_boottime(boottime)\n\n    ima_keyrings = agentAttestState.get_ima_keyrings()\n    tenant_keyring = ima_file_signatures.ImaKeyring.from_string(agent['ima_sign_verification_keys'])\n    ima_keyrings.set_tenant_keyring(tenant_keyring)\n\n    quote_validation_failure = get_tpm_instance().check_quote(\n        agentAttestState,\n        agent['nonce'],\n        received_public_key,\n        quote,\n        agent['ak_tpm'],\n        agent['tpm_policy'],\n        ima_measurement_list,\n        agent['allowlist'],\n        algorithms.Hash(hash_alg),\n        ima_keyrings,\n        mb_measurement_list,\n        agent['mb_refstate'])\n    failure.merge(quote_validation_failure)\n\n    if not failure:\n        # set a flag so that we know that the agent was verified once.\n        # we only issue notifications for agents that were at some point good\n        agent['first_verified'] = True\n\n        # has public key changed? if so, clear out b64_encrypted_V, it is no longer valid\n        if received_public_key != agent.get('public_key', \"\"):\n            agent['public_key'] = received_public_key\n            agent['b64_encrypted_V'] = \"\"\n            agent['provide_V'] = True\n\n    # ok we're done\n    return failure\n\n\ndef prepare_v(agent):\n    # be very careful printing K, U, or V as they leak in logs stored on unprotected disks\n    if config.INSECURE_DEBUG:\n        logger.debug(\"b64_V (non encrypted): %s\", agent['v'])\n\n    if agent.get('b64_encrypted_V', \"\") != \"\":\n        b64_encrypted_V = agent['b64_encrypted_V']\n        logger.debug(\"Re-using cached encrypted V\")\n    else:\n        # encrypt V with the public key\n        b64_encrypted_V = base64.b64encode(crypto.rsa_encrypt(\n            crypto.rsa_import_pubkey(agent['public_key']), base64.b64decode(agent['v'])))\n        agent['b64_encrypted_V'] = b64_encrypted_V\n\n    # logger.debug(\"b64_encrypted_V:\" + b64_encrypted_V)\n    post_data = {\n        'encrypted_key': b64_encrypted_V\n    }\n    return post_data\n\n\ndef prepare_get_quote(agent):\n    \"\"\"This method encapsulates the action required to invoke a quote request on the Cloud Agent.\n\n    This method is part of the polling loop of the thread launched on Tenant POST.\n    \"\"\"\n    agentAttestState = get_AgentAttestStates().get_by_agent_id(agent['agent_id'])\n    agent['nonce'] = TPM_Utilities.random_password(20)\n\n    tpm_policy = ast.literal_eval(agent['tpm_policy'])\n    vtpm_policy = ast.literal_eval(agent['vtpm_policy'])\n\n    params = {\n        'nonce': agent['nonce'],\n        'mask': tpm_policy['mask'],\n        'vmask': vtpm_policy['mask'],\n        'ima_ml_entry': agentAttestState.get_next_ima_ml_entry(),\n    }\n    return params\n\n\ndef process_get_status(agent):\n    allowlist = json.loads(agent.allowlist)\n    if isinstance(allowlist, dict) and 'allowlist' in allowlist:\n        al_len = len(allowlist['allowlist'])\n    else:\n        al_len = 0\n\n    try :\n        mb_refstate = json.loads(agent.mb_refstate)\n    except Exception as e:\n        logger.warning('Non-fatal problem ocurred while attempting to evaluate agent attribute \"mb_refstate\" (%s). Will just consider the value of this attribute to be \"None\"', e.args)\n        mb_refstate = None\n        logger.debug('The contents of the agent attribute \"mb_refstate\" are %s', agent.mb_refstate)\n\n    if isinstance(mb_refstate, dict) and 'mb_refstate' in mb_refstate:\n        mb_refstate_len = len(mb_refstate['mb_refstate'])\n    else:\n        mb_refstate_len = 0\n    response = {'operational_state': agent.operational_state,\n                'v': agent.v,\n                'ip': agent.ip,\n                'port': agent.port,\n                'tpm_policy': agent.tpm_policy,\n                'vtpm_policy': agent.vtpm_policy,\n                'meta_data': agent.meta_data,\n                'allowlist_len': al_len,\n                'mb_refstate_len': mb_refstate_len,\n                'accept_tpm_hash_algs': agent.accept_tpm_hash_algs,\n                'accept_tpm_encryption_algs': agent.accept_tpm_encryption_algs,\n                'accept_tpm_signing_algs': agent.accept_tpm_signing_algs,\n                'hash_alg': agent.hash_alg,\n                'enc_alg': agent.enc_alg,\n                'sign_alg': agent.sign_alg,\n                'verifier_id' : agent.verifier_id,\n                'verifier_ip' : agent.verifier_ip,\n                'verifier_port' : agent.verifier_port,\n                'severity_level': agent.severity_level,\n                'last_event_id': agent.last_event_id\n                }\n    return response\n\n\n# sign a message with revocation key.  telling of verification problem\n\n\ndef notify_error(agent, msgtype='revocation', event=None):\n    send_mq = config.getboolean('cloud_verifier', 'revocation_notifier')\n    send_webhook = config.getboolean('cloud_verifier', 'revocation_notifier_webhook', fallback=False)\n    if not (send_mq or send_webhook):\n        return\n\n    # prepare the revocation message:\n    revocation = {'type': msgtype,\n                  'ip': agent['ip'],\n                  'agent_id': agent['agent_id'],\n                  'port': agent['port'],\n                  'tpm_policy': agent['tpm_policy'],\n                  'vtpm_policy': agent['vtpm_policy'],\n                  'meta_data': agent['meta_data'],\n                  'event_time': time.asctime()}\n    if event:\n        revocation['event_id'] = event.event_id\n        revocation['severity_label'] = event.severity_label.name\n        revocation['context'] = event.context\n\n    tosend = {'msg': json.dumps(revocation).encode('utf-8')}\n\n    # also need to load up private key for signing revocations\n    if agent['revocation_key'] != \"\":\n        signing_key = crypto.rsa_import_privkey(agent['revocation_key'])\n        tosend['signature'] = crypto.rsa_sign(signing_key, tosend['msg'])\n\n    else:\n        tosend['signature'] = \"none\"\n    if send_mq:\n        revocation_notifier.notify(tosend)\n    if send_webhook:\n        revocation_notifier.notify_webhook(tosend)\n\n\ndef validate_agent_data(agent_data):\n    if agent_data is None:\n        return False, None\n\n    # validate that the allowlist is proper JSON\n    lists = json.loads(agent_data['allowlist'])\n\n    # Validate exlude list contains valid regular expressions\n    is_valid, _, err_msg = config.valid_exclude_list(lists.get('exclude'))\n    if not is_valid:\n        err_msg += \" Exclude list regex is misformatted. Please correct the issue and try again.\"\n\n    return is_valid, err_msg\n", "#!/usr/bin/python3\n\n'''\nSPDX-License-Identifier: Apache-2.0\nCopyright 2017 Massachusetts Institute of Technology.\n'''\n\nimport argparse\nimport base64\nimport hashlib\nimport io\nimport logging\nimport os\nimport subprocess\nimport sys\nimport time\nimport zipfile\nimport json\nimport tempfile\nimport requests\n\nfrom cryptography.hazmat.primitives import serialization as crypto_serialization\n\nfrom keylime.agentstates import AgentAttestState\nfrom keylime.requests_client import RequestsClient\nfrom keylime.common import states\nfrom keylime import config\nfrom keylime import keylime_logging\nfrom keylime import registrar_client\nfrom keylime.tpm import tpm2_objects\nfrom keylime.tpm.tpm_main import tpm\nfrom keylime.tpm.tpm_abstract import TPM_Utilities\nfrom keylime import ima\nfrom keylime import crypto\nfrom keylime.cmd import user_data_encrypt\nfrom keylime import ca_util\nfrom keylime.common import algorithms\nfrom keylime import ima_file_signatures\nfrom keylime import measured_boot\nfrom keylime import gpg\nfrom keylime import api_version as keylime_api_version\n\n# setup logging\nlogger = keylime_logging.init_logging('tenant')\n\n# special exception that suppresses stack traces when it happens\nclass UserError(Exception):\n    pass\n\n\nclass Tenant():\n    \"\"\"Simple command processor example.\"\"\"\n\n    config = None\n\n    cloudverifier_ip = None\n    cloudverifier_port = None\n\n    cloudagent_ip = None\n    cv_cloudagent_ip = None\n    cloudagent_port = None\n\n    registrar_ip = None\n    registrar_port = None\n    registrar_data = None\n\n    webapp_ip = None\n    webapp_port = None\n\n    api_version = None\n\n    uuid_service_generate_locally = None\n    agent_uuid = None\n\n    K = None\n    V = None\n    U = None\n    auth_tag = None\n\n    tpm_policy = None\n    vtpm_policy = {}\n    metadata = {}\n    allowlist = {}\n    ima_sign_verification_keys = []\n    revocation_key = \"\"\n    accept_tpm_hash_algs = []\n    accept_tpm_encryption_algs = []\n    accept_tpm_signing_algs = []\n    mb_refstate = None\n    supported_version = None\n\n    payload = None\n\n    tpm_instance = tpm()\n\n    def __init__(self):\n        \"\"\" Set up required values and TLS\n        \"\"\"\n        self.nonce = None\n        self.agent_ip = None\n        self.verifier_id = None\n        self.agent_port = None\n        self.verifier_ip = config.get('tenant', 'cloudverifier_ip')\n        self.verifier_port = config.get('tenant', 'cloudverifier_port')\n        self.registrar_ip = config.get('tenant', 'registrar_ip')\n        self.registrar_port = config.get('tenant', 'registrar_port')\n        self.webapp_port = config.getint('webapp', 'webapp_port')\n        if not config.REQUIRE_ROOT and self.webapp_port < 1024:\n            self.webapp_port += 2000\n        self.webapp_ip = config.get('webapp', 'webapp_ip')\n\n        self.api_version = keylime_api_version.current_version()\n\n        (self.my_cert, self.my_priv_key), (self.my_agent_cert, self.my_agent_priv_key) = self.get_tls_context()\n        self.cert = (self.my_cert, self.my_priv_key)\n        self.agent_cert = (self.my_agent_cert, self.my_agent_priv_key)\n        if config.getboolean('general', \"enable_tls\"):\n            self.tls_enabled = True\n        else:\n            self.tls_enabled = False\n            self.cert = \"\"\n            logger.warning(\n                \"Warning: TLS is currently disabled, keys will be sent in the clear! This should only be used for testing.\")\n\n    @property\n    def verifier_base_url(self):\n        return f'{self.verifier_ip}:{self.verifier_port}'\n\n    def get_tls_context(self):\n        \"\"\"Generate certifcate naming and path\n\n        Returns:\n            string -- my_cert (client_cert), my_priv_key (client private key)\n        \"\"\"\n        my_cert = config.get('tenant', 'my_cert')\n        my_priv_key = config.get('tenant', 'private_key')\n        tls_dir = config.get('tenant', 'tls_dir')\n\n        if tls_dir == 'default':\n            my_cert = 'client-cert.crt'\n            my_priv_key = 'client-private.pem'\n            tls_dir = 'cv_ca'\n\n        if tls_dir[0] != '/':\n            tls_dir = os.path.abspath(os.path.join(config.WORK_DIR, tls_dir))\n\n        logger.info(\"Setting up client TLS in %s\", tls_dir)\n        my_cert = os.path.join(tls_dir, my_cert)\n        my_priv_key = os.path.join(tls_dir, my_priv_key)\n\n        tls_context = (my_cert, my_priv_key)\n\n        # Check for user defined CA to connect to agent\n        agent_mtls_cert = config.get(\"cloud_verifier\", \"agent_mtls_cert\", fallback=None)\n        agent_mtls_private_key = config.get(\"cloud_verifier\", \"agent_mtls_private_key\", fallback=None)\n\n        agent_mtls_context = tls_context\n        if agent_mtls_cert != \"CV\":\n            agent_mtls_context = (agent_mtls_cert, agent_mtls_private_key)\n\n        return tls_context, agent_mtls_context\n\n    def process_allowlist(self, args):\n        # Set up PCR values\n        tpm_policy = config.get('tenant', 'tpm_policy')\n        if \"tpm_policy\" in args and args[\"tpm_policy\"] is not None:\n            tpm_policy = args[\"tpm_policy\"]\n        self.tpm_policy = TPM_Utilities.readPolicy(tpm_policy)\n        logger.info(\"TPM PCR Mask from policy is %s\", self.tpm_policy['mask'])\n\n        vtpm_policy = config.get('tenant', 'vtpm_policy')\n        if \"vtpm_policy\" in args and args[\"vtpm_policy\"] is not None:\n            vtpm_policy = args[\"vtpm_policy\"]\n        self.vtpm_policy = TPM_Utilities.readPolicy(vtpm_policy)\n        logger.info(\"TPM PCR Mask from policy is %s\", self.vtpm_policy['mask'])\n\n        if len(args.get(\"ima_sign_verification_keys\")) > 0:\n            # Auto-enable IMA (or-bit mask)\n            self.tpm_policy['mask'] = \"0x%X\" % (\n                    int(self.tpm_policy['mask'], 0) | (1 << config.IMA_PCR))\n\n            # Add all IMA file signing verification keys to a keyring\n            tenant_keyring = ima_file_signatures.ImaKeyring()\n            for filename in args[\"ima_sign_verification_keys\"]:\n                pubkey, keyidv2 = ima_file_signatures.get_pubkey_from_file(filename)\n                if not pubkey:\n                    raise UserError(\n                        \"File '%s' is not a file with a key\" % filename)\n                tenant_keyring.add_pubkey(pubkey, keyidv2)\n            self.ima_sign_verification_keys = tenant_keyring.to_string()\n\n        # Read command-line path string allowlist\n        al_data = None\n\n        if \"allowlist\" in args and args[\"allowlist\"] is not None:\n\n            self.enforce_pcrs(list(self.tpm_policy.keys()), [ config.IMA_PCR ], \"IMA\")\n\n            # Auto-enable IMA (or-bit mask)\n            self.tpm_policy['mask'] = \"0x%X\" % (\n                    int(self.tpm_policy['mask'], 0) | (1 << config.IMA_PCR))\n\n            if isinstance(args[\"allowlist\"], str):\n                if args[\"allowlist\"] == \"default\":\n                    args[\"allowlist\"] = config.get('tenant', 'allowlist')\n                al_data = ima.read_allowlist(args[\"allowlist\"], args[\"allowlist_checksum\"], args[\"allowlist_sig\"], args[\"allowlist_sig_key\"])\n            elif isinstance(args[\"allowlist\"], list):\n                al_data = args[\"allowlist\"]\n            else:\n                raise UserError(\"Invalid allowlist provided\")\n\n        # Read command-line path string IMA exclude list\n        excl_data = None\n        if \"ima_exclude\" in args and args[\"ima_exclude\"] is not None:\n            if isinstance(args[\"ima_exclude\"], str):\n                if args[\"ima_exclude\"] == \"default\":\n                    args[\"ima_exclude\"] = config.get(\n                        'tenant', 'ima_excludelist')\n                excl_data = ima.read_excllist(args[\"ima_exclude\"])\n            elif isinstance(args[\"ima_exclude\"], list):\n                excl_data = args[\"ima_exclude\"]\n            else:\n                raise UserError(\"Invalid exclude list provided\")\n\n        # Set up IMA\n        if TPM_Utilities.check_mask(self.tpm_policy['mask'], config.IMA_PCR) or \\\n                TPM_Utilities.check_mask(self.vtpm_policy['mask'],\n                                         config.IMA_PCR):\n            # Process allowlists\n            self.allowlist = ima.process_allowlists(al_data, excl_data)\n\n        # Read command-line path string TPM event log (measured boot) reference state\n        mb_refstate_data = None\n        if \"mb_refstate\" in args and args[\"mb_refstate\"] is not None:\n\n            self.enforce_pcrs(list(self.tpm_policy.keys()), config.MEASUREDBOOT_PCRS, \"measured boot\")\n\n            # Auto-enable TPM event log mesured boot (or-bit mask)\n            for _pcr in config.MEASUREDBOOT_PCRS :\n                self.tpm_policy['mask'] = \"0x%X\" % (\n                    int(self.tpm_policy['mask'], 0) | (1 << _pcr))\n\n            logger.info(\"TPM PCR Mask automatically modified is %s to include IMA/Event log PCRs\", self.tpm_policy['mask'])\n\n            if isinstance(args[\"mb_refstate\"], str):\n                if args[\"mb_refstate\"] == \"default\":\n                    args[\"mb_refstate\"] = config.get('tenant', 'mb_refstate')\n                mb_refstate_data = measured_boot.read_mb_refstate(args[\"mb_refstate\"])\n            else:\n                raise UserError(\"Invalid measured boot reference state (intended state) provided\")\n\n        # Set up measured boot (TPM event log) reference state\n        if TPM_Utilities.check_mask(self.tpm_policy['mask'], config.MEASUREDBOOT_PCRS[2]) :\n            # Process measured boot reference state\n            self.mb_refstate = mb_refstate_data\n\n    def init_add(self, args):\n        \"\"\" Set up required values. Command line options can overwrite these config values\n\n        Arguments:\n            args {[string]} -- agent_ip|agent_port|cv_agent_ip\n        \"\"\"\n        if \"agent_ip\" in args:\n            self.agent_ip = args[\"agent_ip\"]\n\n        if 'agent_port' in args and args['agent_port'] is not None:\n            self.agent_port = args['agent_port']\n\n        registrar_client.init_client_tls(\"tenant\")\n        self.registrar_data = registrar_client.getData(self.registrar_ip, self.registrar_port, self.agent_uuid)\n\n        # try to get the port or ip from the registrar if it is missing\n        if (self.agent_ip is None or self.agent_port is None) and self.registrar_data is not None:\n            if self.agent_ip is None:\n                if self.registrar_data['ip'] is not None:\n                    self.agent_ip = self.registrar_data['ip']\n                else:\n                    raise UserError(\"No Ip was specified or found in the Registrar\")\n\n            if self.agent_port is None and self.registrar_data['port'] is not None:\n                self.agent_port = self.registrar_data[\"port\"]\n\n        # If no agent port was found try to use the default from the config file\n        if self.agent_port is None:\n            self.agent_port = config.get('cloud_agent', 'cloudagent_port')\n\n        # Check if a contact ip and port for the agent was found\n        if self.agent_ip is None:\n            raise UserError(\"The contact ip address for the agent was not specified.\")\n\n        if self.agent_port is None:\n            raise UserError(\"The contact port for the agent was not specified.\")\n\n        # Auto-detection for API version\n        self.supported_version = args[\"supported_version\"]\n        if self.supported_version is None:\n            # Default to 1.0 if the agent did not send a mTLS certificate\n            if self.registrar_data.get(\"mtls_cert\", None) is None:\n                self.supported_version = \"1.0\"\n            else:\n                # Try to connect to the agent to get supported version\n                with RequestsClient(f\"{self.agent_ip}:{self.agent_port}\", tls_enabled=True, cert=self.agent_cert,\n                                    ignore_hostname=True, verify_custom=self.registrar_data['mtls_cert']) as get_version:\n                    res = get_version.get(\"/version\")\n                    if res and res.status_code == 200:\n                        try:\n                            data = res.json()\n                            api_version = data[\"results\"][\"supported_version\"]\n                            if keylime_api_version.validate_version(api_version):\n                                self.supported_version = api_version\n                            else:\n                                logger.warning(\"API version provided by the agent is not valid\")\n                        except (TypeError, KeyError):\n                            pass\n\n        if self.supported_version is None:\n            api_version = keylime_api_version.current_version()\n            logger.warning(\"Could not detect supported API version. Defaulting to %s\", api_version)\n            self.supported_version = api_version\n\n        # Now set the cv_agent_ip\n        if 'cv_agent_ip' in args and args['cv_agent_ip'] is not None:\n            self.cv_cloudagent_ip = args['cv_agent_ip']\n        else:\n            self.cv_cloudagent_ip = self.agent_ip\n\n        # Make sure all keys exist in dictionary\n        if \"file\" not in args:\n            args[\"file\"] = None\n        if \"keyfile\" not in args:\n            args[\"keyfile\"] = None\n        if \"payload\" not in args:\n            args[\"payload\"] = None\n        if \"ca_dir\" not in args:\n            args[\"ca_dir\"] = None\n        if \"incl_dir\" not in args:\n            args[\"incl_dir\"] = None\n        if \"ca_dir_pw\" not in args:\n            args[\"ca_dir_pw\"] = None\n\n        # Set up accepted algorithms\n        self.accept_tpm_hash_algs = config.get(\n            'tenant', 'accept_tpm_hash_algs').split(',')\n        self.accept_tpm_encryption_algs = config.get(\n            'tenant', 'accept_tpm_encryption_algs').split(',')\n        self.accept_tpm_signing_algs = config.get(\n            'tenant', 'accept_tpm_signing_algs').split(',')\n\n        self.process_allowlist(args)\n\n        # if none\n        if (args[\"file\"] is None and args[\"keyfile\"] is None and args[\"ca_dir\"] is None):\n            raise UserError(\n                \"You must specify one of -k, -f, or --cert to specify the key/contents to be securely delivered to the agent\")\n\n        if args[\"keyfile\"] is not None:\n            if args[\"file\"] is not None or args[\"ca_dir\"] is not None:\n                raise UserError(\n                    \"You must specify one of -k, -f, or --cert to specify the key/contents to be securely delivered to the agent\")\n\n            # read the keys in\n            if isinstance(args[\"keyfile\"], dict) and \"data\" in args[\"keyfile\"]:\n                if isinstance(args[\"keyfile\"][\"data\"], list) and len(args[\"keyfile\"][\"data\"]) == 1:\n                    keyfile = args[\"keyfile\"][\"data\"][0]\n                    if keyfile is None:\n                        raise UserError(\"Invalid key file contents\")\n                    f = io.StringIO(keyfile)\n                else:\n                    raise UserError(\"Invalid key file provided\")\n            else:\n                f = open(args[\"keyfile\"], encoding=\"utf-8\")\n            self.K = base64.b64decode(f.readline())\n            self.U = base64.b64decode(f.readline())\n            self.V = base64.b64decode(f.readline())\n            f.close()\n\n            # read the payload in (opt.)\n            if isinstance(args[\"payload\"], dict) and \"data\" in args[\"payload\"]:\n                if isinstance(args[\"payload\"][\"data\"], list) and len(args[\"payload\"][\"data\"]) > 0:\n                    self.payload = args[\"payload\"][\"data\"][0]\n            else:\n                if args[\"payload\"] is not None:\n                    f = open(args[\"payload\"], 'rb')\n                    self.payload = f.read()\n                    f.close()\n\n        if args[\"file\"] is not None:\n            if args[\"keyfile\"] is not None or args[\"ca_dir\"] is not None:\n                raise UserError(\n                    \"You must specify one of -k, -f, or --cert to specify the key/contents to be securely delivered to the agent\")\n\n            if isinstance(args[\"file\"], dict) and \"data\" in args[\"file\"]:\n                if isinstance(args[\"file\"][\"data\"], list) and len(args[\"file\"][\"data\"]) > 0:\n                    contents = args[\"file\"][\"data\"][0]\n                    if contents is None:\n                        raise UserError(\"Invalid file payload contents\")\n                else:\n                    raise UserError(\"Invalid file payload provided\")\n            else:\n                with open(args[\"file\"], encoding=\"utf-8\") as f:\n                    contents = f.read()\n            ret = user_data_encrypt.encrypt(contents)\n            self.K = ret['k']\n            self.U = ret['u']\n            self.V = ret['v']\n            self.payload = ret['ciphertext']\n\n        if args[\"ca_dir\"] is None and args[\"incl_dir\"] is not None:\n            raise UserError(\n                \"--include option is only valid when used with --cert\")\n        if args[\"ca_dir\"] is not None:\n            if args[\"file\"] is not None or args[\"keyfile\"] is not None:\n                raise UserError(\n                    \"You must specify one of -k, -f, or --cert to specify the key/contents to be securely delivered to the agent\")\n            if args[\"ca_dir\"] == 'default':\n                args[\"ca_dir\"] = config.CA_WORK_DIR\n\n            if \"ca_dir_pw\" in args and args[\"ca_dir_pw\"] is not None:\n                ca_util.setpassword(args[\"ca_dir_pw\"])\n\n            if not os.path.exists(args[\"ca_dir\"]) or not os.path.exists(\"%s/cacert.crt\" % args[\"ca_dir\"]):\n                logger.warning(\"CA directory does not exist. Creating...\")\n                ca_util.cmd_init(args[\"ca_dir\"])\n            if not os.path.exists(\n                    os.path.join(args[\"ca_dir\"],\n                                 f\"{self.agent_uuid}-private.pem\")):\n                ca_util.cmd_mkcert(args[\"ca_dir\"], self.agent_uuid)\n\n            cert_pkg, serial, subject = ca_util.cmd_certpkg(\n                args[\"ca_dir\"], self.agent_uuid)\n\n            # support revocation\n            if not os.path.exists(\"%s/RevocationNotifier-private.pem\" % args[\"ca_dir\"]):\n                ca_util.cmd_mkcert(args[\"ca_dir\"], \"RevocationNotifier\")\n            rev_package, _, _ = ca_util.cmd_certpkg(\n                args[\"ca_dir\"], \"RevocationNotifier\")\n\n            # extract public and private keys from package\n            sf = io.BytesIO(rev_package)\n            with zipfile.ZipFile(sf) as zf:\n                privkey = zf.read(\"RevocationNotifier-private.pem\")\n                cert = zf.read(\"RevocationNotifier-cert.crt\")\n\n            # put the cert of the revoker into the cert package\n            sf = io.BytesIO(cert_pkg)\n            with zipfile.ZipFile(sf, 'a', compression=zipfile.ZIP_STORED) as zf:\n                zf.writestr('RevocationNotifier-cert.crt', cert)\n\n                # add additional files to zip\n                if args[\"incl_dir\"] is not None:\n                    if isinstance(args[\"incl_dir\"], dict) and \"data\" in args[\"incl_dir\"] and \"name\" in args[\"incl_dir\"]:\n                        if isinstance(args[\"incl_dir\"][\"data\"], list) and isinstance(args[\"incl_dir\"][\"name\"], list):\n                            if len(args[\"incl_dir\"][\"data\"]) != len(args[\"incl_dir\"][\"name\"]):\n                                raise UserError(\"Invalid incl_dir provided\")\n                            for i in range(len(args[\"incl_dir\"][\"data\"])):\n                                zf.writestr(os.path.basename(\n                                    args[\"incl_dir\"][\"name\"][i]), args[\"incl_dir\"][\"data\"][i])\n                    else:\n                        if os.path.exists(args[\"incl_dir\"]):\n                            files = next(os.walk(args[\"incl_dir\"]))[2]\n                            for filename in files:\n                                with open(os.path.join(args[\"incl_dir\"],\n                                                       filename), 'rb') as f:\n                                    zf.writestr(\n                                        os.path.basename(f.name), f.read())\n                        else:\n                            logger.warning('Specified include directory %s does not exist. Skipping...', args[\"incl_dir\"])\n\n            cert_pkg = sf.getvalue()\n\n            # put the private key into the data to be send to the CV\n            self.revocation_key = privkey.decode('utf-8')\n\n            # encrypt up the cert package\n            ret = user_data_encrypt.encrypt(cert_pkg)\n            self.K = ret['k']\n            self.U = ret['u']\n            self.V = ret['v']\n            self.metadata = {'cert_serial': serial, 'subject': subject}\n            self.payload = ret['ciphertext']\n\n        if self.payload is not None and len(self.payload) > config.getint('tenant', 'max_payload_size'):\n            raise UserError(\"Payload size %s exceeds max size %d\" % (\n                len(self.payload), config.getint('tenant', 'max_payload_size')))\n\n    def enforce_pcrs(self, policy_pcrs, protected_pcrs, pcr_use) :\n        policy_pcrs = list(self.tpm_policy.keys())\n        policy_pcrs.remove('mask')\n\n        for _pcr in policy_pcrs :\n            if int(_pcr) in protected_pcrs :\n                logger.error('WARNING: PCR %s is specified in \"tpm_policy\", but will in fact be used by %s. Please remove it from policy', _pcr, pcr_use)\n                sys.exit(1)\n\n    def preloop(self):\n        \"\"\" encrypt the agent UUID as a check for delivering the correct key\n        \"\"\"\n        self.auth_tag = crypto.do_hmac(self.K, self.agent_uuid)\n        # be very careful printing K, U, or V as they leak in logs stored on unprotected disks\n        if config.INSECURE_DEBUG:\n            logger.debug(\"K: %s\", base64.b64encode(self.K))\n            logger.debug(\"V: %s\", base64.b64encode(self.V))\n            logger.debug(\"U: %s\", base64.b64encode(self.U))\n            logger.debug(\"Auth Tag: %s\", self.auth_tag)\n\n    def check_ek(self, ekcert):\n        \"\"\" Check the Entity Key\n\n        Arguments:\n            ekcert {str} -- The endorsement key, either None, \"emulator\", or base64 encoded der cert\n\n        Returns:\n            [type] -- [description]\n        \"\"\"\n        if config.getboolean('tenant', 'require_ek_cert'):\n            if config.STUB_TPM:\n                logger.debug(\"Not checking ekcert due to STUB_TPM mode\")\n            elif ekcert == 'emulator' and config.DISABLE_EK_CERT_CHECK_EMULATOR:\n                logger.info(\"Not checking ekcert of TPM emulator\")\n            elif ekcert is None:\n                logger.warning(\"No EK cert provided, require_ek_cert option in config set to True\")\n                return False\n            elif not self.tpm_instance.verify_ek(base64.b64decode(ekcert)):\n                logger.warning(\"Invalid EK certificate\")\n                return False\n\n        return True\n\n    def validate_tpm_quote(self, public_key, quote, hash_alg):\n        \"\"\" Validate TPM Quote received from the Agent\n\n        Arguments:\n            public_key {[type]} -- [description]\n            quote {[type]} -- [description]\n            hash_alg {bool} -- [description]\n\n        Raises:\n            UserError: [description]\n\n        Returns:\n            [type] -- [description]\n        \"\"\"\n        registrar_client.init_client_tls('tenant')\n        if self.registrar_data is None:\n            logger.warning(\"AIK not found in registrar, quote not validated\")\n            return False\n\n        failure = self.tpm_instance.check_quote(AgentAttestState(self.agent_uuid), self.nonce, public_key, quote, self.registrar_data['aik_tpm'], hash_alg=hash_alg)\n        if failure:\n            if self.registrar_data['regcount'] > 1:\n                logger.error(\"WARNING: This UUID had more than one ek-ekcert registered to it! This might indicate that your system is misconfigured or a malicious host is present. Run 'regdelete' for this agent and restart\")\n                sys.exit()\n            return False\n\n        if self.registrar_data['regcount'] > 1:\n            logger.warning(\"WARNING: This UUID had more than one ek-ekcert registered to it! This might indicate that your system is misconfigured. Run 'regdelete' for this agent and restart\")\n\n        if not config.STUB_TPM and (not config.getboolean('tenant', 'require_ek_cert') and config.get('tenant', 'ek_check_script') == \"\"):\n            logger.warning(\n                \"DANGER: EK cert checking is disabled and no additional checks on EKs have been specified with ek_check_script option. Keylime is not secure!!\")\n\n        # check EK cert and make sure it matches EK\n        if not self.check_ek(self.registrar_data['ekcert']):\n            return False\n        # if agent is virtual, check phyisical EK cert and make sure it matches phyiscal EK\n        if 'provider_keys' in self.registrar_data:\n            if not self.check_ek(self.registrar_data['provider_keys']['ekcert']):\n                return False\n\n        # check all EKs with optional script:\n        script = config.get('tenant', 'ek_check_script')\n        if not script:\n            return True\n\n        if script[0] != '/':\n            script = os.path.join(config.WORK_DIR, script)\n\n        logger.info(\"Checking EK with script %s\", script)\n        # now we need to exec the script with the ek and ek cert in vars\n        env = os.environ.copy()\n        env['AGENT_UUID'] = self.agent_uuid\n        env['EK'] = tpm2_objects.pubkey_from_tpm2b_public(\n            base64.b64decode(self.registrar_data['ek_tpm']),\n            ).public_bytes(\n                crypto_serialization.Encoding.PEM,\n                crypto_serialization.PublicFormat.SubjectPublicKeyInfo,\n            )\n        env['EK_TPM'] = self.registrar_data['ek_tpm']\n        if self.registrar_data['ekcert'] is not None:\n            env['EK_CERT'] = self.registrar_data['ekcert']\n        else:\n            env['EK_CERT'] = \"\"\n\n        env['PROVKEYS'] = json.dumps(self.registrar_data.get('provider_keys', {}))\n        proc = subprocess.Popen(script, env=env, shell=True,\n                                cwd=config.WORK_DIR, stdout=subprocess.PIPE,\n                                stderr=subprocess.STDOUT)\n        retval = proc.wait()\n        if retval != 0:\n            raise UserError(\"External check script failed to validate EK\")\n        logger.debug(\"External check script successfully to validated EK\")\n        while True:\n            line = proc.stdout.readline().decode()\n            if line == \"\":\n                break\n            logger.debug(\"ek_check output: %s\", line.strip())\n        return True\n\n    def do_cv(self):\n        \"\"\" Initiaite v, agent_id and ip and initiate the cloudinit sequence\n        \"\"\"\n        b64_v = base64.b64encode(self.V).decode('utf-8')\n        logger.debug(\"b64_v: %s\", b64_v)\n        data = {\n            'v': b64_v,\n            'cloudagent_ip': self.cv_cloudagent_ip,\n            'cloudagent_port': self.agent_port,\n            'tpm_policy': json.dumps(self.tpm_policy),\n            'vtpm_policy': json.dumps(self.vtpm_policy),\n            'allowlist': json.dumps(self.allowlist),\n            'mb_refstate': json.dumps(self.mb_refstate),\n            'ima_sign_verification_keys': json.dumps(self.ima_sign_verification_keys),\n            'metadata': json.dumps(self.metadata),\n            'revocation_key': self.revocation_key,\n            'accept_tpm_hash_algs': self.accept_tpm_hash_algs,\n            'accept_tpm_encryption_algs': self.accept_tpm_encryption_algs,\n            'accept_tpm_signing_algs': self.accept_tpm_signing_algs,\n            'supported_version': self.supported_version,\n        }\n        json_message = json.dumps(data)\n        do_cv = RequestsClient(self.verifier_base_url, self.tls_enabled)\n        response = do_cv.post(\n            (f'/v{self.api_version}/agents/{self.agent_uuid}'),\n            data=json_message,\n            cert=self.cert,\n            verify=False\n        )\n\n        if response.status_code == 503:\n            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)\n            sys.exit()\n        elif response.status_code == 504:\n            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)\n            sys.exit()\n\n        if response.status_code == 409:\n            # this is a conflict, need to update or delete it\n            logger.error(\"Agent %s already existed at CV. Please use delete or update.\", self.agent_uuid)\n            sys.exit()\n        elif response.status_code != 200:\n            keylime_logging.log_http_response(\n                logger, logging.ERROR, response.json())\n            logger.error(\"POST command response: %s Unexpected response from Cloud Verifier: %s\", response.status_code, response.text)\n            sys.exit()\n\n    def do_cvstatus(self):\n        \"\"\"Perform operational state look up for agent\"\"\"\n\n        do_cvstatus = RequestsClient(self.verifier_base_url, self.tls_enabled)\n\n        response = do_cvstatus.get(\n            (f'/v{self.api_version}/agents/{self.agent_uuid}'),\n            cert=self.cert,\n            verify=False\n        )\n\n        if response.status_code == 503:\n            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)\n            return response.json()\n        if response.status_code == 504:\n            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)\n            return response.json()\n        if response.status_code == 404:\n            logger.info(\"Verifier at %s with Port %s does not have agent %s.\",\n                        self.verifier_ip, self.verifier_port, self.agent_uuid)\n            return response.json()\n        if response.status_code == 200:\n            response = response.json()\n\n            res = response.pop('results')\n            response['results'] = {self.agent_uuid: res}\n\n            operational_state = states.state_to_str(\n                response['results'][self.agent_uuid]['operational_state'])\n            response['results'][self.agent_uuid]['operational_state'] = operational_state\n\n            logger.info(\"Agent Info:\\n%s\" % json.dumps(response[\"results\"]))\n\n            return response\n\n        logger.info(\"Status command response: %s. Unexpected response \"\n                    \"from Cloud Verifier %s on port %s. %s\",\n                    response.status_code,\n                    self.verifier_ip, self.verifier_port, str(response))\n        return response\n\n    def do_cvlist(self):\n        \"\"\"List all agent statues in cloudverifier\"\"\"\n\n        do_cvstatus = RequestsClient(self.verifier_base_url, self.tls_enabled)\n        verifier_id = \"\"\n        if self.verifier_id is not None:\n            verifier_id = self.verifier_id\n        response = do_cvstatus.get(\n            (f'/v{self.api_version}/agents/?verifier={verifier_id}'),\n            cert=self.cert,\n            verify=False\n        )\n\n        if response.status_code == 503:\n            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)\n            return response.json()\n        if response.status_code == 504:\n            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)\n            return response.json()\n        if response.status_code == 404:\n            logger.info(\"Verifier at %s with Port %s does not have agent %s.\",\n                        self.verifier_ip, self.verifier_port, self.agent_uuid)\n            return response.json()\n        if response.status_code == 200:\n            response = response.json()\n\n            logger.info('From verifier %s port %s retrieved: \"%s\"',\n                        self.verifier_ip, self.verifier_port, response)\n\n            return response\n\n        logger.info(\"Status command response: %s. Unexpected response \"\n                    \"from Cloud Verifier %s on port %s. %s\",\n                    response.status_code,\n                    self.verifier_ip, self.verifier_port, str(response))\n        return response\n\n    def do_cvbulkinfo(self):\n        \"\"\"Perform operational state look up for agent\"\"\"\n\n        do_cvstatus = RequestsClient(self.verifier_base_url, self.tls_enabled)\n\n        verifier_id = \"\"\n        if self.verifier_id is not None:\n            verifier_id = self.verifier_id\n        response = do_cvstatus.get(\n            (f'/v{self.api_version}/agents/?bulk={True}&verifier={verifier_id}'),\n            cert=self.cert,\n            verify=False\n        )\n\n        if response.status_code == 503:\n            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)\n            return response.json()\n        if response.status_code == 504:\n            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)\n            return response.json()\n        if response.status_code == 404:\n            logger.info(\"Verifier at %s with Port %s does not have agent %s.\",\n                        self.verifier_ip, self.verifier_port, self.agent_uuid)\n            return response.json()\n        if response.status_code == 200:\n            response = response.json()\n\n            for agent in response[\"results\"].keys():\n                response[\"results\"][agent][\"operational_state\"] = \\\n                    states.state_to_str(response[\"results\"][agent][\n                                            \"operational_state\"])\n            logger.info(\"Bulk Agent Info:\\n%s\" % json.dumps(response[\"results\"]))\n\n            return response\n\n        logger.info(\"Status command response: %s. Unexpected response \"\n                    \"from Cloud Verifier %s on port %s. %s\",\n                    response.status_code,\n                    self.verifier_ip, self.verifier_port, str(response))\n        return response\n\n    def do_cvdelete(self, verifier_check=True):\n        \"\"\"Delete agent from Verifier.\"\"\"\n        if verifier_check:\n            cvresponse = self.do_cvstatus()\n\n            if not isinstance(cvresponse, dict):\n                return cvresponse\n\n            if cvresponse['code'] != 200:\n                logger.error(\"Could not get status of agent %s from \"\n                             \"verifier %s.\", self.agent_uuid, self.verifier_ip)\n                return cvresponse\n\n            self.verifier_ip = cvresponse['results'][self.agent_uuid][\"verifier_ip\"]\n            self.verifier_port = cvresponse['results'][self.agent_uuid][\"verifier_port\"]\n\n        do_cvdelete = RequestsClient(self.verifier_base_url, self.tls_enabled)\n        response = do_cvdelete.delete(\n            (f'/v{self.api_version}/agents/{self.agent_uuid}'),\n            cert=self.cert,\n            verify=False\n        )\n\n        response = response.json()\n\n        if response['code'] == 503:\n            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)\n            return response\n        if response['code'] == 504:\n            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)\n            return response\n        if response['code'] == 202:\n            deleted = False\n            for _ in range(12):\n                get_cvdelete = RequestsClient(\n                    self.verifier_base_url, self.tls_enabled)\n                response = get_cvdelete.get(\n                    (f'/v{self.api_version}/agents/{self.agent_uuid}'),\n                    cert=self.cert,\n                    verify=False\n                )\n\n                if response.status_code == 404:\n                    deleted = True\n                    break\n                time.sleep(.4)\n            if deleted:\n                logger.info(\"CV completed deletion of agent %s\", self.agent_uuid)\n                return response.json()\n            logger.error(\"Timed out waiting for delete of agent %s to complete at CV\", self.agent_uuid)\n            return response.json()\n        if response['code'] == 200:\n            logger.info(\"Agent %s deleted from the CV\", self.agent_uuid)\n            return response\n\n        keylime_logging.log_http_response(\n            logger, logging.ERROR, response)\n        return response\n\n    def do_regstatus(self):\n        registrar_client.init_client_tls('tenant')\n        agent_info = registrar_client.getData(self.registrar_ip,\n                                              self.registrar_port,\n                                              self.agent_uuid)\n\n        if not agent_info:\n            logger.info(\n                \"Agent %s does not exist on the registrar. Please register the agent with the registrar.\",\n                self.agent_uuid)\n            response = {}\n            response['code'] = 404\n            response['status'] = \"Agent {0} does not exist on \" \\\n                                 \"registrar {1} port {2}.\".format(\n                self.agent_uuid, self.registrar_ip, self.registrar_port)\n            response['results'] = {}\n            logger.info(json.dumps((response)))\n            return response\n\n        response = {}\n        response['code'] = 200\n        response['status'] = \"Agent {0} exists on registrar {1} port {2}.\".format(\n                self.agent_uuid, self.registrar_ip, self.registrar_port)\n        response['results'] = {}\n        response['results'][self.agent_uuid] = agent_info\n        response['results'][self.agent_uuid]['operational_state'] = \\\n            states.state_to_str(states.REGISTERED)\n\n        logger.info(json.dumps(response))\n\n        return response\n\n    def do_reglist(self):\n        \"\"\"List agents from Registrar\"\"\"\n        registrar_client.init_client_tls('tenant')\n        response = registrar_client.doRegistrarList(\n            self.registrar_ip, self.registrar_port)\n\n        logger.info(\"From registrar %s port %s retrieved %s\",\n                    self.registrar_ip, self.registrar_port,\n                    json.dumps(response))\n        return response\n\n    def do_regdelete(self):\n        \"\"\"Delete agent from Registrar\"\"\"\n        registrar_client.init_client_tls('tenant')\n        response = registrar_client.doRegistrarDelete(self.registrar_ip,\n                                           self.registrar_port,\n                                           self.agent_uuid)\n\n        return response\n\n    def do_status(self):\n        \"\"\"Perform operational state look up for agent\"\"\"\n\n        regresponse = self.do_regstatus()\n\n        if regresponse['code'] == 404:\n            return regresponse\n\n        cvresponse = self.do_cvstatus()\n\n        if not isinstance(cvresponse, dict):\n            logger.error(\"Unexpected response from Cloud Verifier %s on \"\n                         \"port %s. response %s\", self.verifier_ip,\n                         self.verifier_port, str(cvresponse))\n            return cvresponse\n\n        if regresponse['code'] == 200 and cvresponse['code'] == 200:\n            return cvresponse\n        if regresponse['code'] == 200 and cvresponse['code'] != 200:\n            return regresponse\n\n        logger.error(\"Unknown inconsistent state between registrar %s on \"\n                     \"port %s and verifier %s on port %s occured. Got \"\n                     \"registrar response %s verifier response %s\",\n                     self.verifier_ip, self.verifier_port, self.registrar_ip,\n                     self.registrar_port, str(regresponse), str(cvresponse))\n\n        return {'registrar': regresponse, 'verifier': cvresponse}\n\n    def do_cvreactivate(self, verifier_check=True):\n        \"\"\"Reactive Agent.\"\"\"\n        if verifier_check:\n            agent_json = self.do_cvstatus()\n            self.verifier_ip = agent_json['results'][self.agent_uuid]['verifier_ip']\n            self.verifier_port = agent_json['results'][self.agent_uuid]['verifier_port']\n\n        do_cvreactivate = RequestsClient(\n            self.verifier_base_url, self.tls_enabled)\n        response = do_cvreactivate.put(\n            f'/v{self.api_version}/agents/{self.agent_uuid}/reactivate',\n            data=b'',\n            cert=self.cert,\n            verify=False\n        )\n\n        if response.status_code == 503:\n            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)\n            return response.json()\n        if response.status_code == 504:\n            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)\n            return response.json()\n        if response.status_code == 200:\n            logger.info(\"Agent %s re-activated\", self.agent_uuid)\n            return response.json()\n\n        response_body = response.json()\n        keylime_logging.log_http_response(\n            logger, logging.ERROR, response_body)\n        logger.error(\"Update command response: %s Unexpected response from Cloud Verifier.\", response.status_code)\n        return response.json()\n\n    def do_cvstop(self):\n        \"\"\" Stop declared active agent\n        \"\"\"\n        params = f'/v{self.api_version}/agents/{self.agent_uuid}/stop'\n        do_cvstop = RequestsClient(self.verifier_base_url, self.tls_enabled)\n        response = do_cvstop.put(\n            params,\n            cert=self.cert,\n            data=b'',\n            verify=False\n        )\n\n        if response.status_code == 503:\n            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)\n            sys.exit()\n        elif response.status_code == 504:\n            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)\n            sys.exit()\n\n        response_body = response.json()\n        if response.status_code != 200:\n            keylime_logging.log_http_response(\n                logger, logging.ERROR, response_body)\n        else:\n            logger.info(\"Agent %s stopped\", self.agent_uuid)\n\n    def do_quote(self):\n        \"\"\" Perform TPM quote by GET towards Agent\n\n        Raises:\n            UserError: Connection handler\n        \"\"\"\n        self.nonce = TPM_Utilities.random_password(20)\n\n        numtries = 0\n        response = None\n        # Note: We need a specific retry handler (perhaps in common), no point having localised unless we have too.\n        while True:\n            try:\n                params = f'/v{self.supported_version}/quotes/identity?nonce=%s' % (self.nonce)\n                cloudagent_base_url = f'{self.agent_ip}:{self.agent_port}'\n\n                if self.registrar_data['mtls_cert']:\n                    with RequestsClient(cloudagent_base_url, tls_enabled=True, ignore_hostname=True, cert=self.agent_cert,\n                                        verify_custom=self.registrar_data['mtls_cert']) as do_quote:\n                        response = do_quote.get(params)\n                else:\n                    logger.warning(\"Connecting to agent without using mTLS!\")\n                    do_quote = RequestsClient(cloudagent_base_url, tls_enabled=False)\n                    response = do_quote.get(params)\n\n                print(response)\n                response_body = response.json()\n\n            except Exception as e:\n                if response.status_code in (503, 504):\n                    numtries += 1\n                    maxr = config.getint('tenant', 'max_retries')\n                    if numtries >= maxr:\n                        logger.error(\"Tenant cannot establish connection to agent on %s with port %s\", self.agent_ip, self.agent_port)\n                        sys.exit()\n                    retry = config.getfloat('tenant', 'retry_interval')\n                    logger.info(\"Tenant connection to agent at %s refused %s/%s times, trying again in %s seconds...\",\n                        self.agent_ip, numtries, maxr, retry)\n                    time.sleep(retry)\n                    continue\n\n                raise e\n            break\n\n        try:\n            if response is not None and response.status_code != 200:\n                raise UserError(\n                    \"Status command response: %d Unexpected response from Cloud Agent.\" % response.status)\n\n            if \"results\" not in response_body:\n                raise UserError(\n                    \"Error: unexpected http response body from Cloud Agent: %s\" % str(response.status))\n\n            quote = response_body[\"results\"][\"quote\"]\n            logger.debug(\"Agent_quote received quote: %s\", quote)\n\n            public_key = response_body[\"results\"][\"pubkey\"]\n            logger.debug(\"Agent_quote received public key: %s\", public_key)\n\n            # Ensure hash_alg is in accept_tpm_hash_algs list\n            hash_alg = response_body[\"results\"][\"hash_alg\"]\n            logger.debug(\"Agent_quote received hash algorithm: %s\", hash_alg)\n            if not algorithms.is_accepted(hash_alg, config.get('tenant', 'accept_tpm_hash_algs').split(','))\\\n                    or not algorithms.Hash.is_recognized(hash_alg):\n                raise UserError(\n                    \"TPM Quote is using an unaccepted hash algorithm: %s\" % hash_alg)\n\n            # Ensure enc_alg is in accept_tpm_encryption_algs list\n            enc_alg = response_body[\"results\"][\"enc_alg\"]\n            logger.debug(\"Agent_quote received encryption algorithm: %s\", enc_alg)\n            if not algorithms.is_accepted(enc_alg, config.get('tenant', 'accept_tpm_encryption_algs').split(',')):\n                raise UserError(\n                    \"TPM Quote is using an unaccepted encryption algorithm: %s\" % enc_alg)\n\n            # Ensure sign_alg is in accept_tpm_encryption_algs list\n            sign_alg = response_body[\"results\"][\"sign_alg\"]\n            logger.debug(\"Agent_quote received signing algorithm: %s\", sign_alg)\n            if not algorithms.is_accepted(sign_alg, config.get('tenant', 'accept_tpm_signing_algs').split(',')):\n                raise UserError(\n                    \"TPM Quote is using an unaccepted signing algorithm: %s\" % sign_alg)\n\n            if not self.validate_tpm_quote(public_key, quote, algorithms.Hash(hash_alg)):\n                raise UserError(\n                    \"TPM Quote from cloud agent is invalid for nonce: %s\" % self.nonce)\n\n            logger.info(\"Quote from %s validated\", self.agent_ip)\n\n            # encrypt U with the public key\n            encrypted_U = crypto.rsa_encrypt(\n                crypto.rsa_import_pubkey(public_key), self.U)\n\n            b64_encrypted_u = base64.b64encode(encrypted_U)\n            logger.debug(\"b64_encrypted_u: %s\", b64_encrypted_u.decode('utf-8'))\n            data = {\n                'encrypted_key': b64_encrypted_u.decode('utf-8'),\n                'auth_tag': self.auth_tag\n            }\n\n            if self.payload is not None:\n                data['payload'] = self.payload.decode('utf-8')\n\n\n            # post encrypted U back to CloudAgent\n            params = f'/v{self.supported_version}/keys/ukey'\n            cloudagent_base_url = (\n                f'{self.agent_ip}:{self.agent_port}'\n            )\n\n            if self.registrar_data['mtls_cert']:\n                with RequestsClient(cloudagent_base_url, tls_enabled=True, ignore_hostname=True, cert=self.agent_cert,\n                                    verify_custom=self.registrar_data['mtls_cert']) as post_ukey:\n                    response = post_ukey.post(params, json=data)\n            else:\n                logger.warning(\"Connecting to agent without using mTLS!\")\n                post_ukey = RequestsClient(cloudagent_base_url, tls_enabled=False)\n                response = post_ukey.post(params, json=data)\n\n            if response.status_code == 503:\n                logger.error(\"Cannot connect to Agent at %s with Port %s. Connection refused.\", self.agent_ip, self.agent_port)\n                sys.exit()\n            elif response.status_code == 504:\n                logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)\n                sys.exit()\n\n            if response.status_code != 200:\n                keylime_logging.log_http_response(\n                    logger, logging.ERROR, response_body)\n                raise UserError(\n                    \"Posting of Encrypted U to the Cloud Agent failed with response code %d (%s)\" % (response.status_code, response.text))\n        except Exception as e:\n            self.do_cvstop()\n            raise e\n\n    def do_verify(self):\n        \"\"\" Perform verify using a random generated challenge\n        \"\"\"\n        challenge = TPM_Utilities.random_password(20)\n        numtries = 0\n        while True:\n            try:\n                cloudagent_base_url = (\n                    f'{self.agent_ip}:{self.agent_port}'\n                )\n\n\n                if self.registrar_data['mtls_cert']:\n                    with RequestsClient(cloudagent_base_url, tls_enabled=True, ignore_hostname=True,\n                                        cert=self.agent_cert, verify_custom=self.registrar_data['mtls_cert']) as do_verify:\n                        response = do_verify.get(f'/v{self.supported_version}/keys/verify?challenge={challenge}')\n                else:\n                    logger.warning(\"Connecting to agent without using mTLS!\")\n                    do_verify = RequestsClient(cloudagent_base_url, tls_enabled=False)\n                    response = do_verify.get(f'/v{self.supported_version}/keys/verify?challenge={challenge}')\n\n            except Exception as e:\n                if response.status_code in (503, 504):\n                    numtries += 1\n                    maxr = config.getint('tenant', 'max_retries')\n                    if numtries >= maxr:\n                        logger.error(\"Cannot establish connection to agent on %s with port %s\", self.agent_ip, self.agent_port)\n                        sys.exit()\n                    retry = config.getfloat('tenant', 'retry_interval')\n                    logger.info(\"Verifier connection to agent at %s refused %s/%s times, trying again in %s seconds...\",\n                        self.agent_ip, numtries, maxr, retry)\n                    time.sleep(retry)\n                    continue\n\n                raise e\n            response_body = response.json()\n            if response.status_code == 200:\n                if \"results\" not in response_body or 'hmac' not in response_body['results']:\n                    logger.critical(\"Error: unexpected http response body from Cloud Agent: %s\", response.status_code)\n                    break\n                mac = response_body['results']['hmac']\n\n                ex_mac = crypto.do_hmac(self.K, challenge)\n\n                if mac == ex_mac:\n                    logger.info(\"Key derivation successful\")\n                else:\n                    logger.error(\"Key derivation failed\")\n            else:\n                keylime_logging.log_http_response(\n                    logger, logging.ERROR, response_body)\n                retry = config.getfloat('tenant', 'retry_interval')\n                logger.warning(\"Key derivation not yet complete...trying again in %s seconds...Ctrl-C to stop\", retry)\n                time.sleep(retry)\n                continue\n            break\n\n    def do_add_allowlist(self, args):\n        if 'allowlist_name' not in args or not args['allowlist_name']:\n            raise UserError('allowlist_name is required to add an allowlist')\n\n        allowlist_name = args['allowlist_name']\n        self.process_allowlist(args)\n        data = {\n            'tpm_policy': json.dumps(self.tpm_policy),\n            'vtpm_policy': json.dumps(self.vtpm_policy),\n            'allowlist': json.dumps(self.allowlist)\n        }\n        body = json.dumps(data)\n        cv_client = RequestsClient(self.verifier_base_url, self.tls_enabled)\n        response = cv_client.post(f'/v{self.api_version}/allowlists/{allowlist_name}', data=body,\n                                  cert=self.cert, verify=False)\n        print(response.json())\n\n    def do_delete_allowlist(self, name):\n        cv_client = RequestsClient(self.verifier_base_url, self.tls_enabled)\n        response = cv_client.delete(f'/v{self.api_version}/allowlists/{name}',\n                                    cert=self.cert, verify=False)\n        print(response.json())\n\n    def do_show_allowlist(self, name):\n        cv_client = RequestsClient(self.verifier_base_url, self.tls_enabled)\n        response = cv_client.get(f'/v{self.api_version}/allowlists/{name}',\n                                 cert=self.cert, verify=False)\n        print(f\"Show allowlist command response: {response.status_code}.\")\n        print(response.json())\n\n\ndef write_to_namedtempfile(data, delete_tmp_files):\n    temp = tempfile.NamedTemporaryFile(prefix=\"keylime-\", delete=delete_tmp_files)\n    temp.write(data)\n    temp.flush()\n    return temp.name\n\ndef main(argv=sys.argv):\n    \"\"\"[summary]\n\n    Keyword Arguments:\n        argv {[type]} -- [description] (default: {sys.argv})\n\n    Raises:\n        UserError: [description]\n        UserError: [description]\n        UserError: [description]\n    \"\"\"\n    parser = argparse.ArgumentParser(argv[0])\n    parser.add_argument('-c', '--command', action='store', dest='command', default='add',\n                        help=\"valid commands are add,delete,update,\"\n                             \"regstatus,cvstatus,status,reglist,cvlist,reactivate,\"\n                             \"regdelete,\"\n                             \"bulkinfo. defaults to add\")\n    parser.add_argument('-t', '--targethost', action='store',\n                        dest='agent_ip', help=\"the IP address of the host to provision\")\n    parser.add_argument('-tp', '--targetport', action='store',\n                        dest='agent_port', help=\"the Port of the host to provision\")\n    parser.add_argument('-r', '--registrarhost', action='store',\n                        dest='registrar_ip', help=\"the IP address of the registrar where to retrieve the agents data from.\")\n    parser.add_argument('-rp', '--registrarport', action=\"store\",\n                        dest='registrar_port', help=\"the port of the registrar.\")\n    parser.add_argument('--cv_targethost', action='store', default=None, dest='cv_agent_ip',\n                        help='the IP address of the host to provision that the verifier will use (optional).  Use only if different than argument to option -t/--targethost')\n    parser.add_argument('-v', '--cv', action='store', dest='verifier_ip',\n                        help=\"the IP address of the cloud verifier\")\n    parser.add_argument('-vp', '--cvport', action='store', dest='verifier_port',\n                        help=\"the port of the cloud verifier\")\n    parser.add_argument('-vi', '--cvid', action='store', dest='verifier_id',\n                        help=\"the unique identifier of a cloud verifier\")\n    parser.add_argument('-nvc', '--no-verifier-check', action='store_false', dest='verifier_check', default=True,\n                        help='Disable the check to confirm if the agent is being processed by the specified verifier. Use only with -c/--command delete or reactivate')\n    parser.add_argument('-u', '--uuid', action='store',\n                        dest='agent_uuid', help=\"UUID for the agent to provision\")\n    parser.add_argument('-f', '--file', action='store', default=None,\n                        help='Deliver the specified plaintext to the provisioned agent')\n    parser.add_argument('--cert', action='store', dest='ca_dir', default=None,\n                        help='Create and deliver a certificate using a CA created by ca-util. Pass in the CA directory or use \"default\" to use the standard dir')\n    parser.add_argument('-k', '--key', action='store', dest='keyfile',\n                        help='an intermedia key file produced by user_data_encrypt')\n    parser.add_argument('-p', '--payload', action='store', default=None,\n                        help='Specify the encrypted payload to deliver with encrypted keys specified by -k')\n    parser.add_argument('--include', action='store', dest='incl_dir', default=None,\n                        help=\"Include additional files in provided directory in certificate zip file.  Must be specified with --cert\")\n    parser.add_argument('--allowlist', action='store', dest='allowlist',\n                        default=None, help=\"Specify the file path of an allowlist\")\n    parser.add_argument('--signature-verification-key', '--sign_verification_key', action='append', dest='ima_sign_verification_keys',\n                        default=[], help=\"Specify an IMA file signature verification key\")\n    parser.add_argument('--signature-verification-key-sig', action='append', dest='ima_sign_verification_key_sigs',\n                        default=[], help=\"Specify the GPG signature file for an IMA file signature verification key; pair this option with --signature-verification-key\")\n    parser.add_argument('--signature-verification-key-sig-key', action='append', dest='ima_sign_verification_key_sig_keys',\n                        default=[], help=\"Specify the GPG public key file use to validate the --signature-verification-key-sig; pair this option with --signature-verification-key\")\n    parser.add_argument('--signature-verification-key-url', action='append', dest='ima_sign_verification_key_urls',\n                        default=[], help=\"Specify the URL for a remote IMA file signature verification key\")\n    parser.add_argument('--signature-verification-key-sig-url', action='append',\n                        dest='ima_sign_verification_key_sig_urls',\n                        default=[], help=\"Specify the URL for the remote GPG signature of a remote IMA file signature verification key; pair this option with --signature-verification-key-url\")\n    parser.add_argument('--signature-verification-key-sig-url-key', action='append',\n                        dest='ima_sign_verification_key_sig_url_keys',\n                        default=[], help=\"Specify the GPG public key file used to validate the --signature-verification-key-sig-url; pair this option with --signature-verification-key-url\")\n    parser.add_argument('--mb_refstate', action='store', dest='mb_refstate',\n                        default=None, help=\"Specify the location of a measure boot reference state (intended state)\")\n    parser.add_argument('--allowlist-checksum', action='store', dest='allowlist_checksum',\n                        default=None, help=\"Specify the SHA2 checksum of an allowlist\")\n    parser.add_argument('--allowlist-sig', action='store', dest='allowlist_sig',\n                        default=None, help=\"Specify the GPG signature file of an allowlist\")\n    parser.add_argument('--allowlist-sig-key', action='store', dest='allowlist_sig_key',\n                        default=None, help=\"Specify the GPG public key file used to validate the --allowlist-sig or --allowlist-sig-url\")\n    parser.add_argument('--allowlist-url', action='store', dest='allowlist_url',\n                        default=None, help=\"Specify the URL of a remote allowlist\")\n    parser.add_argument('--allowlist-sig-url', action='store', dest='allowlist_sig_url',\n                        default=None, help=\"Specify the URL of the remote GPG signature file of an allowlist\")\n    parser.add_argument('--exclude', action='store', dest='ima_exclude',\n                        default=None, help=\"Specify the location of an IMA exclude list\")\n    parser.add_argument('--tpm_policy', action='store', dest='tpm_policy', default=None,\n                        help=\"Specify a TPM policy in JSON format. e.g., {\\\"15\\\":\\\"0000000000000000000000000000000000000000\\\"}\")\n    parser.add_argument('--vtpm_policy', action='store', dest='vtpm_policy',\n                        default=None, help=\"Specify a vTPM policy in JSON format\")\n    parser.add_argument('--verify', action='store_true', default=False,\n                        help='Block on cryptographically checked key derivation confirmation from the agent once it has been provisioned')\n    parser.add_argument('--allowlist-name', help='The name of allowlist to operate with')\n    parser.add_argument('--supported-version', default=None, action=\"store\", dest='supported_version', help='API version that is supported by the agent. Detected automatically by default')\n\n    args = parser.parse_args(argv[1:])\n\n    # Make sure argument dependencies are enforced\n    if( args.allowlist and args.allowlist_url):\n        parser.error(\"--allowlist and --allowlist-url cannot be specified at the same time\")\n    if( args.allowlist_url and not (args.allowlist_sig or args.allowlist_sig_url or args.allowlist_checksum)):\n        parser.error(\"--allowlist-url must have either --allowlist-sig, --allowlist-sig-url or --allowlist-checksum to verifier integrity\")\n    if( args.allowlist_sig and not (args.allowlist_url or args.allowlist)):\n        parser.error(\"--allowlist-sig must have either --allowlist or --allowlist-url\")\n    if( args.allowlist_sig_url and not (args.allowlist_url or args.allowlist)):\n        parser.error(\"--allowlist-sig-url must have either --allowlist or --allowlist-url\")\n    if( args.allowlist_checksum and not (args.allowlist_url or args.allowlist)):\n        parser.error(\"--allowlist-checksum must have either --allowlist or --allowlist-url\")\n    if( args.allowlist_sig and not args.allowlist_sig_key):\n        parser.error(\"--allowlist-sig must also have --allowlist-sig-key\")\n    if( args.allowlist_sig_url and not args.allowlist_sig_key):\n        parser.error(\"--allowlist-sig-url must also have --allowlist-sig-key\")\n    if( args.allowlist_sig_key and not (args.allowlist_sig or args.allowlist_sig_url)):\n        parser.error(\"--allowlist-sig-key must have either --allowlist-sig or --allowlist-sig-url\")\n\n    mytenant = Tenant()\n\n    if args.agent_uuid is not None:\n        mytenant.agent_uuid = args.agent_uuid\n        # if the uuid is actually a public key, then hash it\n        if mytenant.agent_uuid.startswith('-----BEGIN PUBLIC KEY-----'):\n            mytenant.agent_uuid = hashlib.sha256(\n                mytenant.agent_uuid).hexdigest()\n    else:\n        logger.warning(\"Using default UUID d432fbb3-d2f1-4a97-9ef7-75bd81c00000\")\n        mytenant.agent_uuid = \"d432fbb3-d2f1-4a97-9ef7-75bd81c00000\"\n\n    if config.STUB_VTPM and config.TPM_CANNED_VALUES is not None:\n        # Use canned values for agent UUID\n        jsonIn = config.TPM_CANNED_VALUES\n        if \"add_vtpm_to_group\" in jsonIn:\n            mytenant.agent_uuid = jsonIn['add_vtpm_to_group']['retout']\n        else:\n            # Our command hasn't been canned!\n            raise UserError(\"Command %s not found in canned JSON!\" %\n                            (\"add_vtpm_to_group\"))\n\n    if args.verifier_id is not None:\n        mytenant.verifier_id = args.verifier_id\n    if args.verifier_ip is not None:\n        mytenant.verifier_ip = args.verifier_ip\n    if args.verifier_port is not None:\n        mytenant.verifier_port = args.verifier_port\n\n    if args.registrar_ip is not None:\n        mytenant.registrar_ip = args.registrar_ip\n    if args.registrar_port is not None:\n        mytenant.registrar_port = args.registrar_port\n\n    # we only need to fetch remote files if we are adding or updating\n    if args.command in ['add', 'update']:\n        delete_tmp_files = logger.level > logging.DEBUG # delete tmp files unless in DEBUG mode\n\n        if args.allowlist_url:\n            logger.info(\"Downloading Allowlist from %s\", args.allowlist_url)\n            response = requests.get(args.allowlist_url, allow_redirects=False)\n            if response.status_code == 200:\n                args.allowlist = write_to_namedtempfile(response.content, delete_tmp_files)\n                logger.debug(\"Allowlist temporarily saved in %s\" % args.allowlist)\n            else:\n                raise Exception(f\"Downloading allowlist ({args.allowlist_url}) failed with status code {response.status_code}!\")\n\n        if args.allowlist_sig_url:\n            logger.info(\"Downloading Allowlist signature from %s\", args.allowlist_sig_url)\n            response = requests.get(args.allowlist_sig_url, allow_redirects=False)\n            if response.status_code == 200:\n                args.allowlist_sig = write_to_namedtempfile(response.content, delete_tmp_files)\n                logger.debug(\"Allowlist signature temporarily saved in %s\", args.allowlist_sig)\n            else:\n                raise Exception(f\"Downloading allowlist signature ({args.allowlist_sig_url}) failed with status code {response.status_code}!\")\n\n        # verify all the local keys for which we have a signature file and a key to verify\n        for i, key_file in enumerate(args.ima_sign_verification_keys):\n            if len(args.ima_sign_verification_key_sigs) <= i:\n                break\n            keysig_file = args.ima_sign_verification_key_sigs[i]\n            if len(args.ima_sign_verification_key_sig_keys) == 0:\n                raise UserError(\"A gpg key is missing for key signature file '%s'\" % keysig_file)\n\n            gpg_key_file = args.ima_sign_verification_key_sig_keys[i]\n            gpg.gpg_verify_filesignature(gpg_key_file, key_file, keysig_file, \"IMA file signing key\")\n\n            logger.info(\"Signature verification on %s was successful\" % key_file)\n\n        # verify all the remote keys for which we have a signature URL and key to to verify\n        # Append the downloaded key files to args.ima_sign_verification_keys\n        for i, key_url in enumerate(args.ima_sign_verification_key_urls):\n\n            logger.info(\"Downloading key from %s\", key_url)\n            response = requests.get(key_url, allow_redirects=False)\n            if response.status_code == 200:\n                key_file = write_to_namedtempfile(response.content, delete_tmp_files)\n                args.ima_sign_verification_keys.append(key_file)\n                logger.debug(\"Key temporarily saved in %s\" % key_file)\n            else:\n                raise Exception(f\"Downloading key ({key_url}) failed with status code {response.status_code}!\")\n\n            if len(args.ima_sign_verification_key_sig_urls) <= i:\n                continue\n\n            keysig_url = args.ima_sign_verification_key_sig_urls[i]\n\n            if len(args.ima_sign_verification_key_sig_url_keys) == 0:\n                raise UserError(\"A gpg key is missing for key signature URL '%s'\" % keysig_url)\n\n            logger.info(\"Downloading key signature from %s\" % keysig_url)\n            response = requests.get(keysig_url, allow_redirects=False)\n            if response.status_code == 200:\n                keysig_file = write_to_namedtempfile(response.content, delete_tmp_files)\n                logger.debug(\"Key signature temporarily saved in %s\" % keysig_file)\n            else:\n                raise Exception(f\"Downloading key signature ({key_url}) failed with status code {response.status_code}!\")\n\n            gpg_key_file = args.ima_sign_verification_key_sig_url_keys[i]\n            gpg.gpg_verify_filesignature(gpg_key_file, key_file, keysig_file, \"IMA file signing key\")\n            logger.info(\"Signature verification on %s was successful\" % key_url)\n\n    if args.command == 'add':\n        mytenant.init_add(vars(args))\n        mytenant.preloop()\n        mytenant.do_cv()\n        mytenant.do_quote()\n        if args.verify:\n            mytenant.do_verify()\n    elif args.command == 'update':\n        mytenant.init_add(vars(args))\n        mytenant.do_cvdelete(args.verifier_check)\n        mytenant.preloop()\n        mytenant.do_cv()\n        mytenant.do_quote()\n        if args.verify:\n            mytenant.do_verify()\n    elif args.command == 'delete':\n        mytenant.do_cvdelete(args.verifier_check)\n    elif args.command == 'status':\n        mytenant.do_status()\n    elif args.command == 'cvstatus':\n        mytenant.do_cvstatus()\n    elif args.command == 'bulkinfo':\n        mytenant.do_cvbulkinfo()\n    elif args.command == 'cvlist':\n        mytenant.do_cvlist()\n    elif args.command == 'reactivate':\n        mytenant.do_cvreactivate(args.verifier_check)\n    elif args.command == 'regstatus':\n        mytenant.do_regstatus()\n    elif args.command == 'reglist':\n        mytenant.do_reglist()\n    elif args.command == 'regdelete':\n        mytenant.do_regdelete()\n    elif args.command == 'addallowlist':\n        mytenant.do_add_allowlist(vars(args))\n    elif args.command == 'showallowlist':\n        mytenant.do_show_allowlist(args.allowlist_name)\n    elif args.command == 'deleteallowlist':\n        mytenant.do_delete_allowlist(args.allowlist_name)\n    else:\n        raise UserError(\"Invalid command specified: %s\" % (args.command))\n", "'''\nSPDX-License-Identifier: Apache-2.0\nCopyright 2017 Massachusetts Institute of Technology.\n'''\nimport codecs\nfrom abc import ABCMeta, abstractmethod\nimport os\nimport string\nimport typing\n\nimport yaml\ntry:\n    from yaml import CSafeLoader as SafeLoader, CSafeDumper as SafeDumper\nexcept ImportError:\n    from yaml import SafeLoader, SafeDumper\n\nfrom keylime import config\nfrom keylime import json\nfrom keylime import keylime_logging\nfrom keylime import crypto\nfrom keylime import ima\nfrom keylime import measured_boot\nfrom keylime.common import algorithms\nfrom keylime.failure import Failure, Component\n\nlogger = keylime_logging.init_logging('tpm')\n\n\nclass TPM_Utilities:\n\n    @staticmethod\n    def check_mask(mask, pcr):\n        if mask is None:\n            return False\n        return bool(1 << pcr & int(mask, 0))\n\n    @staticmethod\n    def random_password(length=20):\n        rand = crypto.generate_random_key(length)\n        chars = string.ascii_uppercase + string.digits + string.ascii_lowercase\n        password = ''\n        for i in range(length):\n            password += chars[(rand[i]) % len(chars)]\n        return password\n\n    @staticmethod\n    def readPolicy(configval):\n        policy = json.loads(configval)\n\n        # compute PCR mask from tpm_policy\n        mask = 0\n        for key in list(policy.keys()):\n            if not key.isdigit() or int(key) > 24:\n                raise Exception(\"Invalid tpm policy pcr number: %s\" % (key))\n\n            if int(key) == config.TPM_DATA_PCR:\n                raise Exception(\"Invalid allowlist PCR number %s, keylime uses this PCR to bind data.\" % key)\n            if int(key) == config.IMA_PCR:\n                raise Exception(\"Invalid allowlist PCR number %s, this PCR is used for IMA.\" % key)\n\n            mask = mask | (1 << int(key))\n\n            # wrap it in a list if it is a singleton\n            if isinstance(policy[key], str):\n                policy[key] = [policy[key]]\n\n            # convert all hash values to lowercase\n            policy[key] = [x.lower() for x in policy[key]]\n\n        policy['mask'] = \"0x%X\" % (mask)\n        return policy\n\n\nclass AbstractTPM(metaclass=ABCMeta):\n    # Abstract base class\n    EXIT_SUCESS = 0\n    TPM_IO_ERR = 5\n    EMPTYMASK = \"1\"\n    MAX_NONCE_SIZE = 64\n\n    # constructor\n    def __init__(self, need_hw_tpm=True):\n        # read the config file\n        self.need_hw_tpm = need_hw_tpm\n        self.global_tpmdata = None\n        self.tpmrand_warned = False\n        self.defaults = {}\n        self.defaults['hash'] = algorithms.Hash.SHA1\n        self.defaults['encrypt'] = algorithms.Encrypt.RSA\n        self.defaults['sign'] = algorithms.Sign.RSASSA\n        self.supported = {}\n\n    # tpm_initialize\n    @abstractmethod\n    def flush_keys(self):\n        pass\n\n    @abstractmethod\n    def encryptAIK(self, uuid, ek_tpm: bytes, aik_tpm: bytes):\n        pass\n\n    @abstractmethod\n    def activate_identity(self, keyblob):\n        pass\n\n    @abstractmethod\n    def verify_ek(self, ekcert):\n        pass\n\n    @abstractmethod\n    def get_tpm_manufacturer(self):\n        pass\n\n    @abstractmethod\n    def is_emulator(self):\n        pass\n\n    @abstractmethod\n    def is_vtpm(self):\n        pass\n\n    def warn_emulator(self):\n        if self.is_emulator():\n            logger.warning(\"INSECURE: Keylime is using a software TPM emulator rather than a real hardware TPM.\")\n            logger.warning(\"INSECURE: The security of Keylime is NOT linked to a hardware root of trust.\")\n            logger.warning(\"INSECURE: Only use Keylime in this mode for testing or debugging purposes.\")\n\n    def __read_tpm_data(self):\n        if os.path.exists('tpmdata.yml'):\n            with open('tpmdata.yml', 'rb') as f:\n                return yaml.load(f, Loader=SafeLoader)\n        else:\n            return {}\n\n    def __write_tpm_data(self):\n        os.umask(0o077)\n        if os.geteuid() != 0 and config.REQUIRE_ROOT:\n            logger.warning(\"Creating tpm metadata file without root. Sensitive trust roots may be at risk!\")\n        with open('tpmdata.yml', 'w', encoding=\"utf-8\") as f:\n            yaml.dump(self.global_tpmdata, f, Dumper=SafeDumper)\n\n    def get_tpm_metadata(self, key):\n        if self.global_tpmdata is None:\n            self.global_tpmdata = self.__read_tpm_data()\n        return self.global_tpmdata.get(key, None)\n\n    def _set_tpm_metadata(self, key, value):\n        if self.global_tpmdata is None:\n            self.global_tpmdata = self.__read_tpm_data()\n\n        if self.global_tpmdata.get(key, None) is not value:\n            self.global_tpmdata[key] = value\n            self.__write_tpm_data()\n\n    @abstractmethod\n    def tpm_init(self, self_activate=False, config_pw=None):\n        pass\n\n    # tpm_quote\n    @abstractmethod\n    def create_quote(self, nonce, data=None, pcrmask=EMPTYMASK, hash_alg=None):\n        pass\n\n    @abstractmethod\n    def check_quote(self, agentAttestState, nonce, data, quote, aikTpmFromRegistrar, tpm_policy={}, ima_measurement_list=None, allowlist={}, hash_alg=None, ima_keyrings=None, mb_measurement_list=None, mb_refstate=None):\n        pass\n\n    def START_HASH(self, algorithm=None):\n        if algorithm is None:\n            algorithm = self.defaults['hash']\n\n        alg_size = algorithm.get_size() // 4\n        return \"0\" * alg_size\n\n    def hashdigest(self, payload, algorithm=None):\n        if algorithm is None:\n            algorithm = self.defaults['hash']\n\n        digest = algorithm.hash(payload)\n        if digest is None:\n            return None\n        return codecs.encode(digest, 'hex').decode('utf-8')\n\n    @abstractmethod\n    def sim_extend(self, hashval_1, hashval_0=None, hash_alg=None):\n        pass\n\n    @abstractmethod\n    def extendPCR(self, pcrval, hashval, hash_alg=None, lock=True):\n        pass\n\n    @abstractmethod\n    def readPCR(self, pcrval, hash_alg=None):\n        pass\n\n    @abstractmethod\n    def _get_tpm_rand_block(self, size=4096):\n        pass\n\n    def __check_ima(self, agentAttestState, pcrval, ima_measurement_list, allowlist,\n                    ima_keyrings, boot_aggregates, hash_alg):\n        failure = Failure(Component.IMA)\n        logger.info(\"Checking IMA measurement list on agent: %s\", agentAttestState.get_agent_id())\n        if config.STUB_IMA:\n            pcrval = None\n\n        _, ima_failure = ima.process_measurement_list(agentAttestState, ima_measurement_list.split('\\n'), allowlist,\n                                                      pcrval=pcrval, ima_keyrings=ima_keyrings,\n                                                      boot_aggregates=boot_aggregates, hash_alg=hash_alg)\n        failure.merge(ima_failure)\n        if not failure:\n            logger.debug(\"IMA measurement list of agent %s validated\", agentAttestState.get_agent_id())\n        return failure\n\n    def __parse_pcrs(self, pcrs, virtual) -> typing.Dict[int, str]:\n        \"\"\"Parses and validates the format of a list of PCR data\"\"\"\n        output = {}\n        for line in pcrs:\n            tokens = line.split()\n            if len(tokens) != 3:\n                logger.error(\"Invalid %sPCR in quote: %s\", (\"\", \"v\")[virtual], pcrs)\n                continue\n            try:\n                pcr_num = int(tokens[1])\n            except ValueError:\n                logger.error(\"Invalid PCR number %s\", tokens[1])\n                continue\n            output[pcr_num] = tokens[2].lower()\n\n        return output\n\n    def check_pcrs(self, agentAttestState, tpm_policy, pcrs, data, virtual, ima_measurement_list,\n                   allowlist, ima_keyrings, mb_measurement_list, mb_refstate_str, hash_alg) -> Failure:\n        failure = Failure(Component.PCR_VALIDATION)\n        if isinstance(tpm_policy, str):\n            tpm_policy = json.loads(tpm_policy)\n\n        pcr_allowlist = tpm_policy.copy()\n\n        if 'mask' in pcr_allowlist:\n            del pcr_allowlist['mask']\n        # convert all pcr num keys to integers\n        pcr_allowlist = {int(k): v for k, v in list(pcr_allowlist.items())}\n\n        mb_policy, mb_refstate_data = measured_boot.get_policy(mb_refstate_str)\n        mb_pcrs_hashes, boot_aggregates, mb_measurement_data, mb_failure = self.parse_mb_bootlog(mb_measurement_list, hash_alg)\n        failure.merge(mb_failure)\n\n        pcrs_in_quote = set()  # PCRs in quote that were already used for some kind of validation\n\n        pcrs = self.__parse_pcrs(pcrs, virtual)\n        pcr_nums = set(pcrs.keys())\n\n        # Skip validation if TPM is stubbed.\n        if config.STUB_TPM:\n            return failure\n\n        # Validate data PCR\n        if config.TPM_DATA_PCR in pcr_nums and data is not None:\n            expectedval = self.sim_extend(data, hash_alg=hash_alg)\n            if expectedval != pcrs[config.TPM_DATA_PCR]:\n                logger.error(\n                    \"%sPCR #%s: invalid bind data %s from quote does not match expected value %s\",\n                    (\"\", \"v\")[virtual], config.TPM_DATA_PCR, pcrs[config.TPM_DATA_PCR], expectedval)\n                failure.add_event(f\"invalid_pcr_{config.TPM_DATA_PCR}\", {\"got\": pcrs[config.TPM_DATA_PCR], \"expected\": expectedval}, True)\n            pcrs_in_quote.add(config.TPM_DATA_PCR)\n        else:\n            logger.error(\"Binding %sPCR #%s was not included in the quote, but is required\", (\"\", \"v\")[virtual],\n                         config.TPM_DATA_PCR)\n            failure.add_event(f\"missing_pcr_{config.TPM_DATA_PCR}\", f\"Data PCR {config.TPM_DATA_PCR} is missing in quote, but is required\", True)\n        # Check for ima PCR\n        if config.IMA_PCR in pcr_nums:\n            if ima_measurement_list is None:\n                logger.error(\"IMA PCR in policy, but no measurement list provided\")\n                failure.add_event(f\"unused_pcr_{config.IMA_PCR}\", \"IMA PCR in policy, but no measurement list provided\", True)\n            else:\n                ima_failure = self.__check_ima(agentAttestState, pcrs[config.IMA_PCR], ima_measurement_list, allowlist,\n                                               ima_keyrings, boot_aggregates, hash_alg)\n                failure.merge(ima_failure)\n\n            pcrs_in_quote.add(config.IMA_PCR)\n\n        # Collect mismatched measured boot PCRs as measured_boot failures\n        mb_pcr_failure = Failure(Component.MEASURED_BOOT)\n        # Handle measured boot PCRs only if the parsing worked\n        if not mb_failure:\n            for pcr_num in set(config.MEASUREDBOOT_PCRS) & pcr_nums:\n                if mb_refstate_data:\n                    if not mb_measurement_list:\n                        logger.error(\"Measured Boot PCR %d in policy, but no measurement list provided\", pcr_num)\n                        failure.add_event(f\"unused_pcr_{pcr_num}\",\n                                          f\"Measured Boot PCR {pcr_num} in policy, but no measurement list provided\", True)\n                        continue\n\n                    val_from_log_int = mb_pcrs_hashes.get(str(pcr_num), 0)\n                    val_from_log_hex = hex(val_from_log_int)[2:]\n                    val_from_log_hex_stripped = val_from_log_hex.lstrip('0')\n                    pcrval_stripped = pcrs[pcr_num].lstrip('0')\n                    if val_from_log_hex_stripped != pcrval_stripped:\n                        logger.error(\n                            \"For PCR %d and hash %s the boot event log has value %r but the agent returned %r\",\n                            str(hash_alg), pcr_num, val_from_log_hex, pcrs[pcr_num])\n                        mb_pcr_failure.add_event(f\"invalid_pcr_{pcr_num}\",\n                                                 {\"context\": \"SHA256 boot event log PCR value does not match\",\n                                                  \"got\": pcrs[pcr_num], \"expected\": val_from_log_hex}, True)\n\n                    if pcr_num in pcr_allowlist and pcrs[pcr_num] not in pcr_allowlist[pcr_num]:\n                        logger.error(\n                            \"%sPCR #%s: %s from quote does not match expected value %s\",\n                            (\"\", \"v\")[virtual], pcr_num, pcrs[pcr_num], pcr_allowlist[pcr_num])\n                        failure.add_event(f\"invalid_pcr_{pcr_num}\",\n                                          {\"context\": \"PCR value is not in allowlist\",\n                                           \"got\": pcrs[pcr_num], \"expected\": pcr_allowlist[pcr_num]}, True)\n                    pcrs_in_quote.add(pcr_num)\n        failure.merge(mb_pcr_failure)\n\n        # Check the remaining non validated PCRs\n        for pcr_num in pcr_nums - pcrs_in_quote:\n            if pcr_num not in list(pcr_allowlist.keys()):\n                logger.warning(\"%sPCR #%s in quote not found in %stpm_policy, skipping.\",\n                               (\"\", \"v\")[virtual], pcr_num, (\"\", \"v\")[virtual])\n                continue\n            if pcrs[pcr_num] not in pcr_allowlist[pcr_num]:\n                logger.error(\"%sPCR #%s: %s from quote does not match expected value %s\",\n                             (\"\", \"v\")[virtual], pcr_num, pcrs[pcr_num], pcr_allowlist[pcr_num])\n                failure.add_event(f\"invalid_pcr_{pcr_num}\",\n                                  {\"context\": \"PCR value is not in allowlist\",\n                                   \"got\": pcrs[pcr_num], \"expected\": pcr_allowlist[pcr_num]}, True)\n\n            pcrs_in_quote.add(pcr_num)\n\n        missing = set(pcr_allowlist.keys()) - pcrs_in_quote\n        if len(missing) > 0:\n            logger.error(\"%sPCRs specified in policy not in quote: %s\", (\"\", \"v\")[virtual], missing)\n            failure.add_event(\"missing_pcrs\", {\"context\": \"PCRs are missing in quote\", \"data\": missing}, True)\n\n        if not mb_failure and mb_refstate_data:\n            mb_policy_failure = measured_boot.evaluate_policy(mb_policy, mb_refstate_data, mb_measurement_data,\n                                                    pcrs_in_quote, (\"\", \"v\")[virtual], agentAttestState.get_agent_id())\n            failure.merge(mb_policy_failure)\n\n        return failure\n\n    # tpm_nvram\n    @abstractmethod\n    def write_key_nvram(self, key):\n        pass\n\n    @abstractmethod\n    def read_key_nvram(self):\n        pass\n\n    @abstractmethod\n    def parse_mb_bootlog(self, mb_measurement_list: str, hash_alg: algorithms.Hash) -> dict:\n        raise NotImplementedError\n", "'''\nSPDX-License-Identifier: Apache-2.0\nCopyright 2017 Massachusetts Institute of Technology.\n'''\n\nimport base64\nimport binascii\nimport hashlib\nimport os\nimport re\nimport sys\nimport tempfile\nimport threading\nimport time\nimport typing\nimport zlib\nimport codecs\nfrom distutils.version import StrictVersion\n\nfrom cryptography import exceptions as crypto_exceptions\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives import serialization as crypto_serialization\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography import x509\n\nfrom keylime import cmd_exec\nfrom keylime import config\nfrom keylime import json\nfrom keylime import keylime_logging\nfrom keylime import secure_mount\nfrom keylime.tpm import tpm_abstract\nfrom keylime import tpm_ek_ca\nfrom keylime.common import algorithms\nfrom keylime.tpm import tpm2_objects\nfrom keylime.failure import Failure, Component\n\nlogger = keylime_logging.init_logging('tpm')\n\n\ndef _get_cmd_env():\n    env = os.environ.copy()\n    if 'TPM2TOOLS_TCTI' not in env:\n        # Don't clobber existing setting (if present)\n        env['TPM2TOOLS_TCTI'] = 'device:/dev/tpmrm0'\n        # env['TPM2TOOLS_TCTI'] = 'tabrmd:bus_name=com.intel.tss2.Tabrmd'\n        # Other (not recommended) options are direct emulator and chardev communications:\n        # env['TPM2TOOLS_TCTI'] = 'mssim:port=2321'\n        # env['TPM2TOOLS_TCTI'] = 'device:/dev/tpm0'\n    return env\n\n\ndef _stub_command(fprt, lock, cmd, outputpaths):\n    # cmd is an iteratable now, change cmd to string to match old logic below\n    cmd = ' '.join(cmd)\n    # Use canned values for stubbing\n    jsonIn = config.TPM_CANNED_VALUES\n    if fprt in jsonIn:\n        # The value we're looking for has been canned!\n        thisTiming = jsonIn[fprt]['timing']\n        thisRetout = jsonIn[fprt]['retout']\n        thisCode = jsonIn[fprt]['code']\n        thisFileout = jsonIn[fprt]['fileout']\n        fileoutEncoded = {}\n\n        # Decode files that are supplied (and requested)\n        if outputpaths is not None and len(outputpaths) > 0:\n            if len(thisFileout) == 1 and len(outputpaths) == 1:\n                # fileoutEncoded[outputpaths[0]] = base64.b64decode(next(iter(thisFileout.values()))).decode(\"zlib\")\n                fileoutEncoded[outputpaths[0]] = zlib.decompress(base64.b64decode(next(iter(thisFileout.values()))))\n            elif fprt == \"tpm2_deluxequote\":\n                # quotes need 3 outputs, so we need a consistent way to match them back up when reading\n                quote_msg = \"\"\n                match = re.search(r\"-m ([^\\s]+)\", cmd)\n                if match:\n                    quote_msg = match.group(1)\n                    if \"file://quoteMessage\" in thisFileout:\n                        # fileoutEncoded[quote_msg] = base64.b64decode(thisFileout[\"file://quoteMessage\"]).decode(\"zlib\")\n                        fileoutEncoded[quote_msg] = zlib.decompress(\n                            base64.b64decode(thisFileout[\"file://quoteMessage\"]))\n                quote_sig = \"\"\n                match = re.search(r\"-s ([^\\s]+)\", cmd)\n                if match:\n                    quote_sig = match.group(1)\n                    if \"file://quoteSignature\" in thisFileout:\n                        # fileoutEncoded[quote_sig] = base64.b64decode(thisFileout[\"file://quoteSignature\"]).decode(\"zlib\")\n                        fileoutEncoded[quote_sig] = zlib.decompress(\n                            base64.b64decode(thisFileout[\"file://quoteSignature\"]))\n                quote_pcr = \"\"\n                match = re.search(r\"-p ([^\\s]+)\", cmd)\n                if match:\n                    quote_pcr = match.group(1)\n                    if \"file://quotePCR\" in thisFileout:\n                        # fileoutEncoded[quote_pcr] = base64.b64decode(thisFileout[\"file://quotePCR\"]).decode(\"zlib\")\n                        fileoutEncoded[quote_pcr] = zlib.decompress(\n                            base64.b64decode(thisFileout[\"file://quotePCR\"]))\n            else:\n                raise Exception(\"Command %s is using multiple files unexpectedly!\" % fprt)\n\n        logger.debug(\"TPM call '%s' was stubbed out, with a simulated delay of %f sec\" % (fprt, thisTiming))\n        time.sleep(thisTiming)\n\n        # Package for return\n        returnDict = {\n            'retout': thisRetout,\n            'reterr': [],\n            'code': thisCode,\n            'fileouts': fileoutEncoded,\n            'timing': thisTiming,\n        }\n        return returnDict\n    if not lock:\n        # non-lock calls don't go to the TPM (just let it pass through)\n        return None\n\n    # Our command hasn't been canned!\n    raise Exception(\"Command %s not found in canned YAML!\" % fprt)\n\n\ndef _output_metrics(fprt, cmd, cmd_ret, outputpaths):\n    # cmd is an iteratable now, change cmd to string to match old logic below\n    cmd = ' '.join(cmd)\n    t0 = cmd_ret['timing']['t0']\n    t1 = cmd_ret['timing']['t1']\n    code = cmd_ret['code']\n    retout = cmd_ret['retout']\n    fileouts = cmd_ret['fileouts']\n\n    pad = \"\"\n    if len(fprt) < 8:\n        pad += \"\\t\"\n    if len(fprt) < 16:\n        pad += \"\\t\"\n    if len(fprt) < 24:\n        pad += \"\\t\"\n\n    filelen = 0\n    if fileouts is not None:\n        filelen = len(fileouts)\n\n    # Print out benchmarking information for TPM (if requested)\n    # print \"\\033[95mTIMING: %s%s\\t:%f\\toutlines:%d\\tfilelines:%d\\t%s\\033[0m\" % (fprt, pad, t1-t0, len(retout), filelen, cmd)\n    if config.TPM_BENCHMARK_PATH is not None:\n        with open(config.TPM_BENCHMARK_PATH, \"ab\") as f:\n            f.write(\n                \"TIMING: %s%s\\t:%f\\toutlines:%d\\tfilelines:%d\\t%s\\n\" % (fprt, pad, t1 - t0, len(retout), filelen, cmd))\n\n    # Print out YAML canned values (if requested)\n    # NOTE: resulting file will be missing the surrounding braces! (must add '{' and '}' for reading)\n    if config.TPM_CANNED_VALUES_PATH is not None:\n        with open(config.TPM_CANNED_VALUES_PATH, \"ab\") as can:\n            fileoutEncoded = {}\n\n            # Process files\n            if outputpaths is not None and len(outputpaths) > 0:\n                if len(fileouts) == 1 and len(outputpaths) == 1:\n                    # fileoutEncoded[outputpaths[0]] = base64.b64encode(iter(fileouts.values()).next().encode(\"zlib\"))\n                    fileoutEncoded[outputpaths[0]] = zlib.compress(base64.b64decode(iter(fileouts.values()).next()))\n                elif fprt == \"tpm2_deluxequote\":\n                    # quotes need 3 outputs, so we need a consistent way to match them back up when reading\n                    quote_msg = \"\"\n                    match = re.search(r\"-m ([^\\s]+)\", cmd)\n                    if match:\n                        quote_msg = match.group(1)\n                        if quote_msg in fileouts:\n                            # fileoutEncoded[\"file://quoteMessage\"] = base64.b64encode(fileouts[quote_msg].encode(\"zlib\"))\n                            fileoutEncoded[\"file://quoteMessage\"] = zlib.compress(base64.b64decode(fileouts[quote_msg]))\n                    quote_sig = \"\"\n                    match = re.search(r\"-s ([^\\s]+)\", cmd)\n                    if match:\n                        quote_sig = match.group(1)\n                        if quote_sig in fileouts:\n                            # fileoutEncoded[\"file://quoteSignature\"] = base64.b64encode(fileouts[quote_sig].encode(\"zlib\"))\n                            fileoutEncoded[\"file://quoteSignature\"] = zlib.compress(\n                                base64.b64decode(fileouts[quote_sig]))\n                    quote_pcr = \"\"\n                    match = re.search(r\"-p ([^\\s]+)\", cmd)\n                    if match:\n                        quote_pcr = match.group(1)\n                        if quote_pcr in fileouts:\n                            # fileoutEncoded[\"file://quotePCR\"] = base64.b64encode(fileouts[quote_pcr].encode(\"zlib\"))\n                            fileoutEncoded[\"file://quotePCR\"] = zlib.compress(base64.b64decode(fileouts[quote_pcr]))\n                else:\n                    raise Exception(\"Command %s is using multiple files unexpectedly!\" % (fprt))\n\n            # tpm_cexec will need to know the nonce\n            nonce = \"\"\n            match = re.search(r\"-q ([\\w]+)\", cmd)\n            if match:\n                nonce = binascii.a2b_hex(match.group(1))\n\n            jsonObj = {\n                'type': fprt,\n                'retout': retout,\n                'fileout': fileoutEncoded,\n                'cmd': cmd,\n                'timing': t1 - t0,\n                'code': code,\n                'nonce': nonce\n            }\n            can.write(\"\\\"%s\\\": %s,\\n\" % (fprt, json.dumps(jsonObj, indent=4, sort_keys=True)))\n\n\nclass tpm(tpm_abstract.AbstractTPM):\n    VERSION = 2\n    tools_version = \"\"\n\n    def __init__(self, need_hw_tpm=False):\n        tpm_abstract.AbstractTPM.__init__(self, need_hw_tpm)\n\n        # Shared lock to serialize access to tools\n        self.tpmutilLock = threading.Lock()\n\n        self.__get_tpm2_tools()\n\n        # We don't know which algs the TPM supports yet\n        self.supported['encrypt'] = set()\n        self.supported['hash'] = set()\n        self.supported['sign'] = set()\n\n        # Grab which default algs the config requested\n        defaultHash = config.get('cloud_agent', \"tpm_hash_alg\")\n        defaultEncrypt = config.get('cloud_agent', \"tpm_encryption_alg\")\n        defaultSign = config.get('cloud_agent', \"tpm_signing_alg\")\n\n        ek_handle = config.get('cloud_agent', 'ek_handle')\n\n        if self.need_hw_tpm:\n            if ek_handle == \"generate\":\n                # Start up the TPM\n                self.__startup_tpm()\n\n            # Figure out which algorithms the TPM supports\n            self.__get_tpm_algorithms()\n\n            # Ensure TPM supports the defaults requested\n            if defaultHash not in self.supported['hash']:\n                raise Exception('Unsupported hash algorithm specified: %s!' % (defaultHash))\n            if defaultEncrypt not in self.supported['encrypt']:\n                raise Exception('Unsupported encryption algorithm specified: %s!' % (defaultEncrypt))\n            if defaultSign not in self.supported['sign']:\n                raise Exception('Unsupported signing algorithm specified: %s!' % (defaultSign))\n        else:\n            # Assume their defaults are sane?\n            pass\n\n        self.defaults['hash'] = algorithms.Hash(defaultHash)\n        self.defaults['encrypt'] = defaultEncrypt\n        self.defaults['sign'] = defaultSign\n        self.defaults['ek_handle'] = ek_handle\n\n    def __get_tpm2_tools(self):\n        retDict = self.__run([\"tpm2_startup\", \"--version\"])\n\n        code = retDict['code']\n        output = ''.join(config.convert(retDict['retout']))\n        errout = ''.join(config.convert(retDict['reterr']))\n        if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n            raise Exception(\"Error establishing tpm2-tools version using TPM2_Startup: %s\" + str(code) + \": \" + str(errout))\n\n        # Extract the `version=\"x.x.x\"` from tools\n        version_str = re.search(r'version=\"([^\"]+)\"', output).group(1)\n        # Extract the full semver release number.\n        self.tools_version = version_str.split(\"-\")\n\n        if StrictVersion(self.tools_version[0]) >= StrictVersion(\"4.2\"):\n            logger.info(\"TPM2-TOOLS Version: %s\" % self.tools_version[0])\n            self.tools_version = \"4.2\"\n        elif StrictVersion(self.tools_version[0]) >= StrictVersion(\"4.0.0\"):\n            logger.info(\"TPM2-TOOLS Version: %s\" % self.tools_version[0])\n            self.tools_version = \"4.0\"\n        elif StrictVersion(self.tools_version[0]) >= StrictVersion(\"3.2.0\"):\n            logger.info(\"TPM2-TOOLS Version: %s\" % self.tools_version[0])\n            self.tools_version = \"3.2\"\n        else:\n            logger.error(\"TPM2-TOOLS Version %s is not supported.\" % self.tools_version[0])\n            sys.exit()\n\n    def __get_tpm_algorithms(self):\n        if self.tools_version == \"3.2\":\n            retDict = self.__run([\"tpm2_getcap\", \"-c\", \"algorithms\"])\n        elif self.tools_version in [\"4.0\", \"4.2\"]:\n            retDict = self.__run([\"tpm2_getcap\", \"algorithms\"])\n\n        output = config.convert(retDict['retout'])\n        errout = config.convert(retDict['reterr'])\n        code = retDict['code']\n\n        if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n            raise Exception(\"get_tpm_algorithms failed with code \" + str(code) + \": \" + str(errout))\n\n        if self.tools_version == \"3.2\":\n            # output, human-readable -> json\n            output = \"\".join(output)\n            output = re.sub(r'TPMA_ALGORITHM for ALG_ID: 0x[0-9a-f]+\\s+-\\s+([a-z0-9_]+)', r'\\1:', output)\n            output = output.replace(\"set\", \"1\")\n            output = output.replace(\"clear\", \"0\")\n            output = [output]\n\n        retyaml = config.yaml_to_dict(output, logger=logger)\n        if retyaml is None:\n            logger.warning(\"Could not read YAML output of tpm2_getcap.\")\n            return\n        for algorithm, details in retyaml.items():\n            if details[\"asymmetric\"] == 1 and details[\"object\"] == 1 and algorithms.Encrypt.is_recognized(algorithm):\n                self.supported['encrypt'].add(algorithm)\n            elif details[\"hash\"] == 1 and algorithms.Hash.is_recognized(algorithm):\n                self.supported['hash'].add(algorithm)\n            elif details[\"asymmetric\"] == 1 and details[\"signing\"] == 1 and algorithms.Sign.is_recognized(algorithm):\n                self.supported['sign'].add(algorithm)\n\n    # tpm_exec\n    @staticmethod\n    def __fingerprint(cmd):\n        # Creates a unique-enough ID from the given command\n        # The command should be an iterable\n        fprt = cmd[0]\n        if fprt == 'tpm2_nvread':\n            if '0x1c00002' in cmd:  # read_ekcert_nvram\n                fprt += '-ekcert'\n            else:  # read_key_nvram\n                fprt += '-key'\n        elif fprt == \"tpm2_getcap\":\n            if 'handles-persistent' in cmd:\n                fprt += '-handles'\n            elif 'properties-fixed' in cmd:\n                fprt += '-props'\n        else:\n            # other commands are already unique\n            pass\n        return fprt\n\n    def run(self, cmd):\n        return self.__run(cmd, lock=False)\n\n    def __run(self, cmd, expectedcode=tpm_abstract.AbstractTPM.EXIT_SUCESS, raiseOnError=True, lock=True, outputpaths=None):\n        env = _get_cmd_env()\n\n        # Convert single outputpath to list\n        if isinstance(outputpaths, str):\n            outputpaths = [outputpaths]\n\n        # Handle stubbing the TPM out\n        fprt = tpm.__fingerprint(cmd)\n        if config.STUB_TPM and config.TPM_CANNED_VALUES is not None:\n            stub = _stub_command(fprt, lock, cmd, outputpaths)\n            if stub:\n                return stub\n\n        numtries = 0\n        while True:\n            if lock:\n                with self.tpmutilLock:\n                    retDict = cmd_exec.run(cmd=cmd, expectedcode=expectedcode,\n                                           raiseOnError=False,\n                                           outputpaths=outputpaths, env=env)\n            else:\n                retDict = cmd_exec.run(cmd=cmd, expectedcode=expectedcode,\n                                       raiseOnError=False,\n                                       outputpaths=outputpaths, env=env)\n            code = retDict['code']\n            retout = retDict['retout']\n            reterr = retDict['reterr']\n\n            # keep trying to get quote if a PCR race condition occurred in deluxe quote\n            if fprt == \"tpm2_quote\" and cmd_exec.list_contains_substring(reterr, \"Error validating calculated PCR composite with quote\"):\n                numtries += 1\n                maxr = config.getint('cloud_agent', 'max_retries')\n                if numtries >= maxr:\n                    logger.error(\"Agent did not return proper quote due to PCR race condition.\")\n                    break\n                retry = config.getfloat('cloud_agent', 'retry_interval')\n                logger.info(\"Failed to get quote %d/%d times, trying again in %f seconds...\" % (numtries, maxr, retry))\n                time.sleep(retry)\n                continue\n\n            break\n\n        # Don't bother continuing if TPM call failed and we're raising on error\n        if code != expectedcode and raiseOnError:\n            raise Exception(\"Command: %s returned %d, expected %d, output %s, stderr %s\" % (cmd, code, expectedcode, retout, reterr))\n\n        # Metric output\n        if lock or self.tpmutilLock.locked():\n            _output_metrics(fprt, cmd, retDict, outputpaths)\n\n        return retDict\n\n    # tpm_initialize\n    def __startup_tpm(self):\n        retDict = self.__run(['tpm2_startup', '-c'])\n        errout = config.convert(retDict['reterr'])\n        code = retDict['code']\n        if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n            raise Exception(\"Error initializing emulated TPM with TPM2_Startup: %s\" + str(code) + \": \" + str(errout))\n\n    def __create_ek(self, asym_alg=None):\n        # this function is intended to be idempotent\n        if asym_alg is None:\n            asym_alg = self.defaults['encrypt']\n\n        current_handle = self.get_tpm_metadata(\"ek_handle\")\n        owner_pw = self.get_tpm_metadata(\"owner_pw\")\n\n        # clear out old handle before starting again (give idempotence)\n        if current_handle is not None and owner_pw is not None:\n            logger.info(\"Flushing old ek handle: %s\" % hex(current_handle))\n            if self.tools_version == \"3.2\":\n                retDict = self.__run([\"tpm2_getcap\", \"-c\", \"handles-persistent\"],\n                                     raiseOnError=False)\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                retDict = self.__run([\"tpm2_getcap\", \"handles-persistent\"],\n                                     raiseOnError=False)\n            output = retDict['retout']\n            reterr = retDict['reterr']\n            code = retDict['code']\n\n            if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n                raise Exception(\"tpm2_getcap failed with code \" + str(code) + \": \" + str(reterr))\n\n            outjson = config.yaml_to_dict(output, logger=logger)\n            if outjson is not None and hex(current_handle) in outjson:\n                if self.tools_version == \"3.2\":\n                    cmd = [\"tpm2_evictcontrol\", \"-A\", \"o\", \"-H\",\n                           hex(current_handle), \"-P\", owner_pw]\n                    retDict = self.__run(cmd, raiseOnError=False)\n                elif self.tools_version in [\"4.0\", \"4.2\"]:\n                    cmd = [\"tpm2_evictcontrol\", \"-C\", \"o\", \"-c\",\n                           hex(current_handle), \"-P\", owner_pw]\n                    retDict = self.__run(cmd, raiseOnError=False)\n                output = retDict['retout']\n                reterr = retDict['reterr']\n                code = retDict['code']\n\n                if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n                    logger.info(\"Failed to flush old ek handle: %s.  Code %s\" % (hex(current_handle), str(code) + \": \" + str(reterr)))\n\n                self._set_tpm_metadata('ek_handle', None)\n                self._set_tpm_metadata('ek_tpm', None)\n                self._set_tpm_metadata('ek_pw', None)\n\n        # make sure an ownership pw is set\n        if owner_pw is None:\n            owner_pw = tpm_abstract.TPM_Utilities.random_password(20)\n            self._set_tpm_metadata('owner_pw', owner_pw)\n        ek_pw = tpm_abstract.TPM_Utilities.random_password(20)\n\n        # create a new ek\n        with tempfile.NamedTemporaryFile() as tmppath:\n            # TODO(kaifeng) Missing else here for other versions\n            if self.tools_version == \"3.2\":\n                command = [\"tpm2_getpubek\", \"-H\", \"0x81010007\", \"-g\", asym_alg, \"-f\", tmppath.name, \"-P\", ek_pw, \"-o\", owner_pw, \"-e\", owner_pw]\n            elif self.tools_version == \"4.0\":\n                command = [\"tpm2_createek\", \"-c\", \"-\", \"-G\", asym_alg, \"-u\", tmppath.name, \"-p\", ek_pw, \"-w\", owner_pw, \"-P\", owner_pw]\n            elif self.tools_version == \"4.2\":\n                command = [\"tpm2_createek\", \"-c\", \"-\", \"-G\", asym_alg, \"-u\", tmppath.name, \"-w\", owner_pw, \"-P\", owner_pw]\n\n            retDict = self.__run(command, raiseOnError=False, outputpaths=tmppath.name)\n            output = retDict['retout']\n            reterr = retDict['reterr']\n            code = retDict['code']\n            ek_tpm = retDict['fileouts'][tmppath.name]\n\n            if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n                raise Exception(\"createek failed with code \" + str(code) + \": \" + str(reterr))\n\n            if self.tools_version == \"3.2\":\n                handle = int(0x81010007)\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                handle = None\n                retyaml = config.yaml_to_dict(output, logger=logger)\n                if retyaml is None:\n                    raise Exception(\"Could not read YAML output of tpm2_createek.\")\n                if \"persistent-handle\" in retyaml:\n                    handle = retyaml[\"persistent-handle\"]\n\n            self._set_tpm_metadata('ek_handle', handle)\n            self._set_tpm_metadata('ek_pw', ek_pw)\n            self._set_tpm_metadata('ek_tpm', base64.b64encode(ek_tpm))\n            self._set_tpm_metadata('ek_alg', asym_alg)\n\n    def __use_ek(self, ek_handle, config_pw):\n        ek_handle = int(ek_handle, 16)\n        logger.info(\"Using an already created ek with handle: %s\" % hex(ek_handle))\n\n        self._set_tpm_metadata('owner_pw', config_pw)\n\n        with tempfile.NamedTemporaryFile() as tmppath:\n            if self.tools_version == \"3.2\":\n                cmd = [\"tpm2_readpublic\", \"-H\", hex(ek_handle),\n                       \"-o\", tmppath.name, \"-f\", \"tss\"]\n                retDict = self.__run(cmd, raiseOnError=False, outputpaths=tmppath.name)\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                cmd = [\"tpm2_readpublic\", \"-c\", hex(ek_handle),\n                       \"-o\", tmppath.name, \"-f\", \"tss\"]\n                retDict = self.__run(cmd, raiseOnError=False, outputpaths=tmppath.name)\n\n            reterr = retDict['reterr']\n            code = retDict['code']\n            ek_tpm = retDict['fileouts'][tmppath.name]\n            if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n                raise Exception(\"tpm2_readpublic failed with code \" + str(code) + \": \" + str(reterr))\n            self._set_tpm_metadata('ek_tpm', base64.b64encode(ek_tpm))\n\n        self._set_tpm_metadata('ek_handle', int(ek_handle))\n\n    def __take_ownership(self, config_pw):\n        # if no ownerpassword\n        if config_pw == 'generate':\n            logger.info(\"Generating random TPM owner password\")\n            owner_pw = tpm_abstract.TPM_Utilities.random_password(20)\n        else:\n            logger.info(\"Taking ownership with config provided TPM owner password\")\n            owner_pw = config_pw\n\n        logger.debug(\"Removing all saved sessions from TPM\")\n        retDict = self.__run([\"tpm2_flushcontext\", \"-s\"], raiseOnError=False)\n\n        if self.tools_version == \"3.2\":\n            retDict = self.__run([\"tpm2_takeownership\", \"-c\"], raiseOnError=False)\n            retDict = self.__run([\"tpm2_takeownership\", \"-o\", owner_pw, \"-e\", owner_pw],\n                                 raiseOnError=False)\n        elif self.tools_version in [\"4.0\", \"4.2\"]:\n            retDict = self.__run([\"tpm2_changeauth\", \"-c\", \"o\", owner_pw],\n                                 raiseOnError=False)\n            retDict = self.__run([\"tpm2_changeauth\", \"-c\", \"e\", owner_pw],\n                                 raiseOnError=False)\n\n        code = retDict['code']\n        if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n            # if we fail, see if already owned with this pw\n            if self.tools_version == \"3.2\":\n                retDict = self.__run([\"tpm2_takeownership\", \"-o\", owner_pw,\n                                      \"-e\", owner_pw, \"-O\", owner_pw, \"-E\", owner_pw],\n                                     raiseOnError=False)\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                retDict = self.__run([\"tpm2_changeauth\", \"-c\", \"o\", \"-p\", owner_pw, owner_pw],\n                                     raiseOnError=False)\n                retDict = self.__run([\"tpm2_changeauth\", \"-c\", \"e\", \"-p\", owner_pw, owner_pw],\n                                     raiseOnError=False)\n\n            reterr = retDict['reterr']\n            code = retDict['code']\n            if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n                # ut-oh, already owned but not with provided pw!\n                raise Exception(\"Owner password unknown, TPM reset required. Code %s\" + str(code) + \": \" + str(reterr))\n\n        self._set_tpm_metadata('owner_pw', owner_pw)\n        logger.info(\"TPM Owner password confirmed: %s\" % owner_pw)\n\n    def __get_pub_ek(self):  # assumes that owner_pw is correct at this point\n        handle = self.get_tpm_metadata('ek_handle')\n        if handle is None:\n            raise Exception(\"create_ek has not been run yet?\")\n        # make a temp file for the output\n        with tempfile.NamedTemporaryFile() as tmppath:\n            # generates pubek.pem\n            if self.tools_version == \"3.2\":\n                cmd = [\"tpm2_readpublic\", \"-H\", hex(handle), \"-o\", tmppath.name]\n                retDict = self.__run(cmd, raiseOnError=False, outputpaths=tmppath.name)\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                cmd = [\"tpm2_readpublic\", \"-c\", hex(handle), \"-o\", tmppath.name]\n                retDict = self.__run(cmd, raiseOnError=False, outputpaths=tmppath.name)\n\n            reterr = retDict['reterr']\n            code = retDict['code']\n            ek = retDict['fileouts'][tmppath.name]\n            if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n                raise Exception(\"tpm2_readpublic failed with code \" + str(code) + \": \" + str(reterr))\n\n        self._set_tpm_metadata('ek_tpm', base64.b64encode(ek))\n\n    def __create_aik(self, asym_alg=None, hash_alg=None, sign_alg=None):\n        if hash_alg is None:\n            hash_alg = self.defaults['hash']\n        if asym_alg is None:\n            asym_alg = self.defaults['encrypt']\n        if sign_alg is None:\n            sign_alg = self.defaults['sign']\n\n        owner_pw = self.get_tpm_metadata('owner_pw')\n\n        # clear out old handle before starting again (give idempotence)\n        if self.get_tpm_metadata('aik_handle') is not None:\n            aik_handle = self.get_tpm_metadata('aik_handle')\n            if self.tools_version == \"3.2\":\n                logger.info(\"Flushing old ak handle: %s\" % hex(aik_handle))\n                retDict = self.__run([\"tpm2_getcap\", \"-c\", \"handles-persistent\"],\n                                     raiseOnError=False)\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                logger.info(\"Flushing old ak handle: %s\" % aik_handle)\n                retDict = self.__run([\"tpm2_getcap\", \"handles-persistent\"],\n                                     raiseOnError=False)\n            output = config.convert(retDict['retout'])\n            errout = config.convert(retDict['reterr'])\n            code = retDict['code']\n\n            if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n                raise Exception(\"tpm2_getcap failed with code \" + str(code) + \": \" + str(errout))\n\n            if self.tools_version == \"3.2\":\n                # output, human-readable -> json\n                output = \"\".join(output)\n                output = output.replace(\"0x\", \" - 0x\")\n                output = [output]\n\n            outjson = config.yaml_to_dict(output, logger=logger)\n            if self.tools_version == \"3.2\":\n                evict_it = outjson is not None and aik_handle in outjson\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                evict_it = os.path.exists(aik_handle)\n            if evict_it:\n                if self.tools_version == \"3.2\":\n                    cmd = [\"tpm2_evictcontrol\", \"-A\", \"o\", \"-H\", hex(aik_handle), \"-P\", owner_pw]\n                    retDict = self.__run(cmd, raiseOnError=False)\n                elif self.tools_version in [\"4.0\", \"4.2\"]:\n                    cmd = [\"tpm2_evictcontrol\", \"-C\", \"o\", \"-c\", aik_handle, \"-P\", owner_pw]\n                    retDict = self.__run(cmd, raiseOnError=False)\n                    os.remove(aik_handle)\n\n                output = retDict['retout']\n                reterr = retDict['reterr']\n                code = retDict['code']\n\n                if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n                    if self.tools_version == \"3.2\":\n                        logger.info(\"Failed to flush old ak handle: %s.  Code %s\" % (hex(aik_handle), str(code) + \": \" + str(reterr)))\n                    elif self.tools_version in [\"4.0\", \"4.2\"]:\n                        logger.info(\"Failed to flush old ak handle: %s.  Code %s\" % (aik_handle, str(code) + \": \" + str(reterr)))\n\n                self._set_tpm_metadata('aik_pw', None)\n                self._set_tpm_metadata('aik_tpm', None)\n                self._set_tpm_metadata('aik_handle', None)\n\n        logger.debug(\"Creating a new AIK identity\")\n\n        # We need an ek handle to make an aik\n        ek_handle = self.get_tpm_metadata(\"ek_handle\")\n        if ek_handle is None:\n            raise Exception(\"Failed to create AIK, since EK has not yet been created!\")\n\n        aik_pw = tpm_abstract.TPM_Utilities.random_password(20)\n        # make a temp file for the output\n        with tempfile.NamedTemporaryFile() as akpubfile:\n            secpath = \"\"\n            if self.tools_version in [\"4.0\", \"4.2\"]:\n                # ok lets write out the key now\n                secdir = secure_mount.mount()  # confirm that storage is still securely mounted\n                secfd, secpath = tempfile.mkstemp(dir=secdir)\n\n            if self.tools_version == \"3.2\":\n                command = [\"tpm2_getpubak\", \"-E\", hex(ek_handle), \"-k\", \"0x81010008\",\n                           \"-g\", asym_alg, \"-D\", hash_alg, \"-s\", sign_alg,\n                           \"-f\", akpubfile.name, \"-e\", owner_pw, \"-P\", aik_pw,\n                           \"-o\", owner_pw]\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                command = [\"tpm2_createak\", \"-C\", hex(ek_handle), \"-c\", secpath,\n                           \"-G\", asym_alg, \"-g\", hash_alg, \"-s\", sign_alg,\n                           \"-u\", akpubfile.name, \"-p\", aik_pw, \"-P\", owner_pw]\n            retDict = self.__run(command, outputpaths=akpubfile.name)\n            if secfd >= 0:\n                os.close(secfd)\n            retout = retDict['retout']\n            reterr = retDict['reterr']\n            code = retDict['code']\n\n            if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n                raise Exception(\"tpm2_createak failed with code \" + str(code) + \": \" + str(reterr))\n\n            jsonout = config.yaml_to_dict(retout, logger=logger)\n            if jsonout is None:\n                raise Exception(\"unable to parse YAML output of tpm2_createak. Is your tpm2-tools installation up to date?\")\n            aik_tpm = retDict['fileouts'][akpubfile.name]\n            if aik_tpm == \"\":\n                raise Exception(\"unable to read public aik from create identity.  Is your tpm2-tools installation up to date?\")\n            self._set_tpm_metadata('aik_tpm', base64.b64encode(aik_tpm))\n\n        if self.tools_version == \"3.2\":\n            if 'loaded-key' not in jsonout or 'name' not in jsonout['loaded-key']:\n                raise Exception(\"tpm2_createak failed to create aik: return \" + str(reterr))\n\n            handle = int(0x81010008)\n\n            # get and persist the pem (not returned by tpm2_getpubak)\n            self._set_tpm_metadata('aik_handle', handle)\n        elif self.tools_version in [\"4.0\", \"4.2\"]:\n            if 'loaded-key' not in jsonout:\n                raise Exception(\"tpm2_createak failed to create aik: return \" + str(reterr))\n\n            handle = secpath\n\n            # persist the pem\n            self._set_tpm_metadata('aik_handle', handle)\n\n        # persist common results\n        self._set_tpm_metadata('aik_pw', aik_pw)\n\n    def flush_keys(self):\n        logger.debug(\"Flushing keys from TPM...\")\n        if self.tools_version == \"3.2\":\n            retDict = self.__run([\"tpm2_getcap\", \"-c\", \"handles-persistent\"])\n        elif self.tools_version in [\"4.0\", \"4.2\"]:\n            retDict = self.__run([\"tpm2_getcap\", \"handles-persistent\"])\n        # retout = retDict['retout']\n        retout = config.convert(retDict['retout'])\n        errout = config.convert(retDict['reterr'])\n        code = retDict['code']\n\n        if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n            logger.debug(\"tpm2_getcap failed with code \" + str(code) + \": \" + str(errout))\n\n        if self.tools_version == \"3.2\":\n            # output, human-readable -> json\n            retout = \"\".join(retout)\n            retout = retout.replace(\"0x\", \" - 0x\")\n            retout = [retout]\n\n        owner_pw = self.get_tpm_metadata(\"owner_pw\")\n        jsonout = config.yaml_to_dict(retout, logger=logger)\n        if jsonout is None:\n            logger.warning(\"Could not read YAML output of tpm2_getcap.\")\n            jsonout = {}\n        for key in jsonout:\n            if str(hex(key)) != self.defaults['ek_handle']:\n                logger.debug(\"Flushing key handle %s\" % hex(key))\n                if self.tools_version == \"3.2\":\n                    self.__run([\"tpm2_evictcontrol\", \"-A\", \"o\", \"-H\", hex(key), \"-P\", owner_pw],\n                               raiseOnError=False)\n                elif self.tools_version in [\"4.0\", \"4.2\"]:\n                    self.__run([\"tpm2_evictcontrol\", \"-C\", \"o\", \"-c\", hex(key), \"-P\", owner_pw],\n                               raiseOnError=False)\n\n    def encryptAIK(self, uuid, ek_tpm: bytes, aik_tpm: bytes):\n\n        if ek_tpm is None or aik_tpm is None:\n            logger.error(\"Missing parameters for encryptAIK\")\n            return None\n\n        aik_name = tpm2_objects.get_tpm2b_public_name(aik_tpm)\n\n        efd = keyfd = blobfd = -1\n        ekFile = None\n        challengeFile = None\n        keyblob = None\n        blobpath = None\n\n        try:\n            # write out the public EK\n            efd, etemp = tempfile.mkstemp()\n            ekFile = open(etemp, \"wb\")\n            ekFile.write(ek_tpm)\n            ekFile.close()\n\n            # write out the challenge\n            challenge = tpm_abstract.TPM_Utilities.random_password(32)\n            challenge = challenge.encode()\n            keyfd, keypath = tempfile.mkstemp()\n            challengeFile = open(keypath, \"wb\")\n            challengeFile.write(challenge)\n            challengeFile.close()\n\n            # create temp file for the blob\n            blobfd, blobpath = tempfile.mkstemp()\n            command = [\"tpm2_makecredential\", \"-T\", \"none\", \"-e\", ekFile.name,\n                       \"-s\", challengeFile.name, \"-n\", aik_name, \"-o\", blobpath]\n            self.__run(command, lock=False)\n\n            logger.info(\"Encrypting AIK for UUID %s\" % uuid)\n\n            # read in the blob\n            f = open(blobpath, \"rb\")\n            keyblob = base64.b64encode(f.read())\n            f.close()\n\n            # read in the aes key\n            key = base64.b64encode(challenge)\n\n        except Exception as e:\n            logger.error(\"Error encrypting AIK: \" + str(e))\n            logger.exception(e)\n            raise\n        finally:\n            for fd in [efd, keyfd, blobfd]:\n                if fd >= 0:\n                    os.close(fd)\n            for fi in [ekFile, challengeFile]:\n                if fi is not None:\n                    os.remove(fi.name)\n            if blobpath is not None:\n                os.remove(blobpath)\n\n        return (keyblob, key)\n\n    def activate_identity(self, keyblob):\n        owner_pw = self.get_tpm_metadata('owner_pw')\n        aik_keyhandle = self.get_tpm_metadata('aik_handle')\n        ek_keyhandle = self.get_tpm_metadata('ek_handle')\n\n        keyblobFile = None\n        secpath = None\n        secfd = -1\n        sesspath = None\n        sesspathfd = -1\n        try:\n            # write out key blob\n            kfd, ktemp = tempfile.mkstemp()\n            keyblobFile = open(ktemp, \"wb\")\n            # the below is a coroutine?\n            keyblobFile.write(base64.b64decode(keyblob))\n\n            keyblobFile.close()\n            os.close(kfd)\n\n            # ok lets write out the key now\n            secdir = secure_mount.mount()  # confirm that storage is still securely mounted\n\n            secfd, secpath = tempfile.mkstemp(dir=secdir)\n            sesspathfd, sesspath = tempfile.mkstemp(dir=secdir)\n\n            apw = self.get_tpm_metadata('aik_pw')\n            if self.tools_version == \"3.2\":\n                command = [\"tpm2_activatecredential\", \"-H\", hex(aik_keyhandle),\n                           \"-k\", hex(ek_keyhandle), \"-f\", keyblobFile.name,\n                           \"-o\", secpath, \"-P\", apw, \"-e\", owner_pw]\n                retDict = self.__run(command, outputpaths=secpath)\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                self.__run([\"tpm2_startauthsession\", \"--policy-session\", \"-S\", sesspath])\n                self.__run([\"tpm2_policysecret\", \"-S\", sesspath, \"-c\", \"0x4000000B\", owner_pw])\n                command = [\"tpm2_activatecredential\", \"-c\", aik_keyhandle, \"-C\", hex(ek_keyhandle),\n                           \"-i\", keyblobFile.name, \"-o\", secpath, \"-p\", apw,\n                           \"-P\", \"session:%s\" % sesspath]\n                retDict = self.__run(command, outputpaths=secpath)\n                self.__run([\"tpm2_flushcontext\", sesspath])\n\n            fileout = retDict['fileouts'][secpath]\n            logger.info(\"AIK activated.\")\n\n            key = base64.b64encode(fileout)\n\n        except Exception as e:\n            logger.error(\"Error decrypting AIK: \" + str(e))\n            logger.exception(e)\n            return None\n        finally:\n            if keyblobFile is not None:\n                os.remove(keyblobFile.name)\n            if secfd >= 0:\n                os.close(secfd)\n            if secpath is not None and os.path.exists(secpath):\n                os.remove(secpath)\n            if sesspathfd >= 0:\n                os.close(sesspathfd)\n            if sesspath is not None and os.path.exists(sesspath):\n                os.remove(sesspath)\n        return key\n\n    def verify_ek(self, ekcert):\n        \"\"\"Verify that the provided EK certificate is signed by a trusted root\n        :param ekcert: The Endorsement Key certificate in DER format\n        :returns: True if the certificate can be verified, false otherwise\n        \"\"\"\n        # openssl x509 -inform der -in certificate.cer -out certificate.pem\n        try:\n            ek509 = x509.load_der_x509_certificate(\n                data=ekcert,\n                backend=default_backend(),\n            )\n\n            trusted_certs = tpm_ek_ca.cert_loader()\n            for cert in trusted_certs:\n                signcert = x509.load_pem_x509_certificate(\n                    data=cert.encode(),\n                    backend=default_backend(),\n                )\n\n                if ek509.issuer.rfc4514_string() != signcert.subject.rfc4514_string():\n                    continue\n\n                try:\n                    signcert.public_key().verify(\n                        ek509.signature,\n                        ek509.tbs_certificate_bytes,\n                        padding.PKCS1v15(),\n                        ek509.signature_hash_algorithm,\n                    )\n                except crypto_exceptions.InvalidSignature:\n                    continue\n\n                logger.debug(\"EK cert matched cert: %s\" % cert)\n                return True\n        except Exception as e:\n            # Log the exception so we don't lose the raw message\n            logger.exception(e)\n            raise Exception(\"Error processing ek/ekcert. Does this TPM have a valid EK?\").with_traceback(sys.exc_info()[2])\n\n        logger.error(\"No Root CA matched EK Certificate\")\n        return False\n\n    def get_tpm_manufacturer(self):\n        vendorStr = None\n        if self.tools_version == \"3.2\":\n            retDict = self.__run([\"tpm2_getcap\", \"-c\", \"properties-fixed\"])\n        elif self.tools_version in [\"4.0\", \"4.2\"]:\n            retDict = self.__run([\"tpm2_getcap\", \"properties-fixed\"])\n        output = retDict['retout']\n        reterr = retDict['reterr']\n        code = retDict['code']\n\n        if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n            raise Exception(\"get_tpm_manufacturer failed with code \" + str(code) + \": \" + str(reterr))\n\n        # Clean up TPM manufacturer information (strip control characters)\n        # These strings are supposed to be printable ASCII characters, but\n        # some TPM manufacturers put control characters in here\n        for i, s in enumerate(output):\n            output[i] = re.sub(r\"[\\x01-\\x1F\\x7F]\", \"\", s.decode('utf-8')).encode('utf-8')\n\n        retyaml = config.yaml_to_dict(output, logger=logger)\n        if retyaml is None:\n            raise Exception(\"Could not read YAML output of tpm2_getcap.\")\n        if \"TPM2_PT_VENDOR_STRING_1\" in retyaml:\n            vendorStr = retyaml[\"TPM2_PT_VENDOR_STRING_1\"][\"value\"]\n        elif \"TPM_PT_VENDOR_STRING_1\" in retyaml:\n            vendorStr = retyaml[\"TPM_PT_VENDOR_STRING_1\"][\"as string\"].strip()\n\n        return vendorStr\n\n    def is_emulator(self):\n        return self.get_tpm_manufacturer() == 'SW'\n\n    def is_vtpm(self):\n        return False\n\n    def tpm_init(self, self_activate=False, config_pw=None):\n        # this was called tpm_initialize.init before\n        self.warn_emulator()\n\n        if self.defaults['ek_handle'] == \"generate\":\n            self.__take_ownership(config_pw)\n            self.__create_ek()\n        else:\n            self.__use_ek(self.defaults['ek_handle'], config_pw)\n\n        self.__get_pub_ek()\n\n        ekcert = self.read_ekcert_nvram()\n        self._set_tpm_metadata('ekcert', ekcert)\n\n        # if no AIK created, then create one\n        self.__create_aik()\n\n        return self.get_tpm_metadata('ekcert'), self.get_tpm_metadata('ek_tpm'), self.get_tpm_metadata('aik_tpm')\n\n    # tpm_quote\n    @staticmethod\n    def __pcr_mask_to_list(mask):\n        pcr_list = []\n        for pcr in range(24):\n            if tpm_abstract.TPM_Utilities.check_mask(mask, pcr):\n                pcr_list.append(str(pcr))\n        return \",\".join(pcr_list)\n\n    def create_quote(self, nonce, data=None, pcrmask=tpm_abstract.AbstractTPM.EMPTYMASK, hash_alg=None):\n        if hash_alg is None:\n            hash_alg = self.defaults['hash']\n\n        quote = \"\"\n\n        with tempfile.NamedTemporaryFile() as quotepath, \\\n                tempfile.NamedTemporaryFile() as sigpath, \\\n                tempfile.NamedTemporaryFile() as pcrpath:\n            keyhandle = self.get_tpm_metadata('aik_handle')\n            aik_pw = self.get_tpm_metadata('aik_pw')\n\n            if pcrmask is None:\n                pcrmask = tpm_abstract.AbstractTPM.EMPTYMASK\n\n            if data is not None:\n                # add PCR 16 to pcrmask\n                pcrmask = \"0x%X\" % (int(pcrmask, 0) + (1 << config.TPM_DATA_PCR))\n\n            pcrlist = self.__pcr_mask_to_list(pcrmask)\n\n            with self.tpmutilLock:\n                if data is not None:\n                    self.__run([\"tpm2_pcrreset\", str(config.TPM_DATA_PCR)], lock=False)\n                    self.extendPCR(pcrval=config.TPM_DATA_PCR, hashval=self.hashdigest(data), lock=False)\n\n                nonce = bytes(nonce, encoding=\"utf8\").hex()\n                if self.tools_version == \"3.2\":\n                    command = [\"tpm2_quote\", \"-k\", hex(keyhandle), \"-L\", \"%s:%s\" % (hash_alg, pcrlist), \"-q\", nonce, \"-m\", quotepath.name, \"-s\", sigpath.name, \"-p\", pcrpath.name, \"-G\", hash_alg, \"-P\", aik_pw]\n                elif self.tools_version in [\"4.0\", \"4.2\"]:\n                    command = [\"tpm2_quote\", \"-c\", keyhandle, \"-l\", \"%s:%s\" % (hash_alg, pcrlist), \"-q\", nonce, \"-m\", quotepath.name, \"-s\", sigpath.name, \"-o\", pcrpath.name, \"-g\", hash_alg, \"-p\", aik_pw]\n                retDict = self.__run(command, lock=False, outputpaths=[quotepath.name, sigpath.name, pcrpath.name])\n                quoteraw = retDict['fileouts'][quotepath.name]\n                quote_b64encode = base64.b64encode(zlib.compress(quoteraw))\n                sigraw = retDict['fileouts'][sigpath.name]\n                sigraw_b64encode = base64.b64encode(zlib.compress(sigraw))\n                pcrraw = retDict['fileouts'][pcrpath.name]\n                pcrraw_b64encode = base64.b64encode(zlib.compress(pcrraw))\n                quote = quote_b64encode.decode('utf-8') + \":\" + sigraw_b64encode.decode('utf-8') + \":\" + pcrraw_b64encode.decode('utf-8')\n\n        return 'r' + quote\n\n    def __tpm2_checkquote(self, pubaik, nonce, quoteFile, sigFile, pcrFile, hash_alg):\n        if config.STUB_TPM and config.TPM_CANNED_VALUES is not None:\n            jsonIn = config.TPM_CANNED_VALUES\n            if 'tpm2_deluxequote' in jsonIn and 'nonce' in jsonIn['tpm2_deluxequote']:\n                # YAML unicode-ifies strings, and C calls require byte strings (str)\n                nonce = str(jsonIn['tpm2_deluxequote']['nonce'])\n            else:\n                raise Exception(\"Could not get quote nonce from canned JSON!\")\n\n        nonce = bytes(nonce, encoding=\"utf8\").hex()\n        if self.tools_version == \"3.2\":\n            command = [\"tpm2_checkquote\", \"-c\", pubaik, \"-m\", quoteFile, \"-s\", sigFile, \"-p\", pcrFile, \"-G\", hash_alg, \"-q\", nonce]\n        elif self.tools_version in [\"4.0\", \"4.2\"]:\n            command = [\"tpm2_checkquote\", \"-u\", pubaik, \"-m\", quoteFile, \"-s\", sigFile, \"-f\", pcrFile, \"-g\", hash_alg, \"-q\", nonce]\n        retDict = self.__run(command, lock=False)\n        return retDict\n\n    def _tpm2_checkquote(self, aikTpmFromRegistrar, quote, nonce, hash_alg):\n        \"\"\"Write the files from data returned from tpm2_quote for running tpm2_checkquote\n        :param aikTpmFromRegistrar: AIK used to generate the quote and is needed for verifying it now.\n        :param quote: quote data in the format 'r<b64-compressed-quoteblob>:<b64-compressed-sigblob>:<b64-compressed-pcrblob>\n        :param nonce: nonce that was used to create the quote\n        :param hash_alg: the hash algorithm that was used\n        :returns: Returns the 'retout' from running tpm2_checkquote and True in case of success, None and False in case of error.\n        This function throws an Exception on bad input.\n        \"\"\"\n        aikFromRegistrar = tpm2_objects.pubkey_from_tpm2b_public(\n            base64.b64decode(aikTpmFromRegistrar),\n            ).public_bytes(\n                crypto_serialization.Encoding.PEM,\n                crypto_serialization.PublicFormat.SubjectPublicKeyInfo,\n            )\n\n        if quote[0] != 'r':\n            raise Exception(\"Invalid quote type %s\" % quote[0])\n        quote = quote[1:]\n\n        quote_tokens = quote.split(\":\")\n        if len(quote_tokens) < 3:\n            raise Exception(\"Quote is not compound! %s\" % quote)\n\n        quoteblob = zlib.decompress(base64.b64decode(quote_tokens[0]))\n        sigblob = zlib.decompress(base64.b64decode(quote_tokens[1]))\n        pcrblob = zlib.decompress(base64.b64decode(quote_tokens[2]))\n\n        qfd = sfd = pfd = afd = -1\n        quoteFile = None\n        aikFile = None\n        sigFile = None\n        pcrFile = None\n\n        try:\n            # write out quote\n            qfd, qtemp = tempfile.mkstemp()\n            quoteFile = open(qtemp, \"wb\")\n            quoteFile.write(quoteblob)\n            quoteFile.close()\n\n            # write out sig\n            sfd, stemp = tempfile.mkstemp()\n            sigFile = open(stemp, \"wb\")\n            sigFile.write(sigblob)\n            sigFile.close()\n\n            # write out pcr\n            pfd, ptemp = tempfile.mkstemp()\n            pcrFile = open(ptemp, \"wb\")\n            pcrFile.write(pcrblob)\n            pcrFile.close()\n\n            afd, atemp = tempfile.mkstemp()\n            aikFile = open(atemp, \"wb\")\n            aikFile.write(aikFromRegistrar)\n            aikFile.close()\n\n            retDict = self.__tpm2_checkquote(aikFile.name, nonce, quoteFile.name, sigFile.name, pcrFile.name, hash_alg)\n            retout = retDict['retout']\n            reterr = retDict['reterr']\n            code = retDict['code']\n        except Exception as e:\n            logger.error(\"Error verifying quote: \" + str(e))\n            logger.exception(e)\n            return None, False\n        finally:\n            for fd in [qfd, sfd, pfd, afd]:\n                if fd >= 0:\n                    os.close(fd)\n            for fi in [aikFile, quoteFile, sigFile, pcrFile]:\n                if fi is not None:\n                    os.remove(fi.name)\n\n        if len(retout) < 1 or code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n            logger.error(\"Failed to validate signature, output: %s\" % reterr)\n            return None, False\n\n        return retout, True\n\n    def check_quote(self, agentAttestState, nonce, data, quote, aikTpmFromRegistrar, tpm_policy={},\n                    ima_measurement_list=None, allowlist={}, hash_alg=None, ima_keyrings=None,\n                    mb_measurement_list=None, mb_refstate=None) -> Failure:\n        failure = Failure(Component.QUOTE_VALIDATION)\n        if hash_alg is None:\n            hash_alg = self.defaults['hash']\n\n        retout, success = self._tpm2_checkquote(aikTpmFromRegistrar, quote, nonce, hash_alg)\n        if not success:\n            # If the quote validation fails we will skip all other steps therefore this failure is irrecoverable.\n            failure.add_event(\"quote_validation\", {\"message\": \"Quote validation using tpm2-tools\", \"data\": retout}, False)\n            return failure\n\n        pcrs = []\n        jsonout = config.yaml_to_dict(retout, logger=logger)\n        if jsonout is None:\n            failure.add_event(\"quote_validation\", {\"message\": \"YAML parsing failed for quote validation using tpm2-tools.\",\n                                                    \"data\": retout}, False)\n            return failure\n        if \"pcrs\" in jsonout:\n            if hash_alg in jsonout[\"pcrs\"]:\n                alg_size = hash_alg.get_size() // 4\n                for pcrval, hashval in jsonout[\"pcrs\"][hash_alg].items():\n                    pcrs.append(\"PCR \" + str(pcrval) + \" \" + '{0:0{1}x}'.format(hashval, alg_size))\n\n        if len(pcrs) == 0:\n            pcrs = None\n\n        return self.check_pcrs(agentAttestState, tpm_policy, pcrs, data, False, ima_measurement_list, allowlist,\n                               ima_keyrings, mb_measurement_list, mb_refstate, hash_alg)\n\n    def sim_extend(self, hashval_1, hashval_0=None, hash_alg=None):\n        # simulate extending a PCR value by performing TPM-specific extend procedure\n\n        if hashval_0 is None:\n            hashval_0 = self.START_HASH(hash_alg)\n\n        # compute expected value  H(0|H(data))\n        extendedval = self.hashdigest(codecs.decode(hashval_0, 'hex_codec') +\n                                      codecs.decode(self.hashdigest(hashval_1.encode('utf-8'), hash_alg), 'hex_codec'),\n                                      hash_alg).lower()\n        return extendedval\n\n    def extendPCR(self, pcrval, hashval, hash_alg=None, lock=True):\n        if hash_alg is None:\n            hash_alg = self.defaults['hash'].value\n\n        self.__run([\"tpm2_pcrextend\", \"%d:%s=%s\" % (pcrval, hash_alg, hashval)], lock=lock)\n\n    def readPCR(self, pcrval, hash_alg=None):\n        if hash_alg is None:\n            hash_alg = self.defaults['hash']\n        if self.tools_version == \"3.2\":\n            output = config.convert(self.__run(\"tpm2_pcrlist\")['retout'])\n        elif self.tools_version in [\"4.0\", \"4.2\"]:\n            output = config.convert(self.__run(\"tpm2_pcrread\")['retout'])\n\n        jsonout = config.yaml_to_dict(output, logger=logger)\n        if jsonout is None:\n            raise Exception(\"Could not read YAML output of tpm2_pcrread.\")\n\n        if hash_alg not in jsonout:\n            raise Exception(\"Invalid hashing algorithm '%s' for reading PCR number %d.\" % (hash_alg, pcrval))\n\n        # alg_size = Hash_Algorithms.get_hash_size(hash_alg)/4\n        alg_size = hash_alg.get_size() // 4\n        return '{0:0{1}x}'.format(jsonout[hash_alg][pcrval], alg_size)\n\n    # tpm_random\n    def _get_tpm_rand_block(self, size=32):\n        # make a temp file for the output\n        rand = None\n        with tempfile.NamedTemporaryFile() as randpath:\n            try:\n                command = [\"tpm2_getrandom\", \"-o\", randpath.name, str(size)]\n                retDict = self.__run(command, outputpaths=randpath.name)\n                rand = retDict['fileouts'][randpath.name]\n            except Exception as e:\n                if not self.tpmrand_warned:\n                    logger.warning(\"TPM randomness not available: %s\" % e)\n                    self.tpmrand_warned = True\n                return None\n        return rand\n\n    # tpm_nvram\n    def write_key_nvram(self, key):\n        owner_pw = self.get_tpm_metadata('owner_pw')\n\n        # write out quote\n        with tempfile.NamedTemporaryFile() as keyFile:\n            keyFile.write(key)\n            keyFile.flush()\n\n            attrs = \"ownerread|ownerwrite\"\n            # TODO(kaifeng) Escaping attrs is probably not required\n            if self.tools_version == \"3.2\":\n                self.__run([\"tpm2_nvdefine\", \"-x\", \"0x1500018\", \"-a\", \"0x40000001\", \"-s\", str(config.BOOTSTRAP_KEY_SIZE), \"-t\", '\"%s\"' % attrs, \"-I\", owner_pw, \"-P\", owner_pw], raiseOnError=False)\n                self.__run([\"tpm2_nvwrite\", \"-x\", \"0x1500018\", \"-a\", \"0x40000001\", \"-P\", owner_pw, keyFile.name], raiseOnError=False)\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                self.__run([\"tpm2_nvdefine\", \"0x1500018\", \"-C\", \"0x40000001\", \"-s\", str(config.BOOTSTRAP_KEY_SIZE), \"-a\", '\"%s\"' % attrs, \"-p\", owner_pw, \"-P\", owner_pw], raiseOnError=False)\n                self.__run([\"tpm2_nvwrite\", \"0x1500018\", \"-C\", \"0x40000001\", \"-P\", owner_pw, \"-i\", keyFile.name], raiseOnError=False)\n\n    def read_ekcert_nvram(self):\n        # make a temp file for the quote\n        with tempfile.NamedTemporaryFile() as nvpath:\n\n            # Check for RSA EK cert in NVRAM (and get length)\n            if self.tools_version == \"3.2\":\n                retDict = self.__run(\"tpm2_nvlist\", raiseOnError=False)\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                retDict = self.__run(\"tpm2_nvreadpublic\", raiseOnError=False)\n            output = retDict['retout']\n            reterr = retDict['reterr']\n            code = retDict['code']\n\n            if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n                if self.tools_version == \"3.2\":\n                    raise Exception(\"tpm2_nvlist for ekcert failed with code \" + str(code) + \": \" + str(reterr))\n                if self.tools_version in [\"4.0\", \"4.2\"]:\n                    raise Exception(\"tpm2_nvreadpublic for ekcert failed with code \" + str(code) + \": \" + str(reterr))\n\n            outjson = config.yaml_to_dict(output, logger=logger)\n\n            if outjson is None or 0x1c00002 not in outjson or \"size\" not in outjson[0x1c00002]:\n                logger.warning(\"No EK certificate found in TPM NVRAM\")\n                return None\n\n            ekcert_size = str(outjson[0x1c00002][\"size\"])\n\n            # Read the RSA EK cert from NVRAM (DER format)\n            if self.tools_version == \"3.2\":\n                retDict = self.__run([\"tpm2_nvread\", \"-x\", '0x1c00002', \"-s\", ekcert_size,\n                                      \"-f\", nvpath.name, \"-a\", \"0x01c00002\"],\n                                     raiseOnError=False, outputpaths=nvpath.name)\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                retDict = self.__run([\"tpm2_nvread\", '0x1c00002', \"-s\", ekcert_size, \"-o\", nvpath.name],\n                                     raiseOnError=False, outputpaths=nvpath.name)\n            output = config.convert(retDict['retout'])\n            errout = config.convert(retDict['reterr'])\n            code = retDict['code']\n            ekcert = retDict['fileouts'][nvpath.name]\n\n            if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n                raise Exception(\"tpm2_nvread for ekcert failed with code \" + str(code) + \": \" + str(errout))\n\n        return base64.b64encode(ekcert)\n\n    def read_key_nvram(self):\n        owner_pw = self.get_tpm_metadata('owner_pw')\n        if self.tools_version == \"3.2\":\n            retDict = self.__run([\"tpm2_nvread\", \"-x\", \"0x1500018\", \"-a\", \"0x40000001\", \"-s\", str(config.BOOTSTRAP_KEY_SIZE), \"-P\", owner_pw], raiseOnError=False)\n        elif self.tools_version in [\"4.0\", \"4.2\"]:\n            retDict = self.__run([\"tpm2_nvread\", \"0x1500018\", \"-C\", \"0x40000001\", \"-s\", str(config.BOOTSTRAP_KEY_SIZE), \"-P\", owner_pw], raiseOnError=False)\n\n        output = retDict['retout']\n        errout = config.convert(retDict['reterr'])\n        code = retDict['code']\n\n        if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n            if len(errout) > 0 and \"handle does not exist\" in \"\\n\".join(errout):\n                logger.debug(\"No stored U in TPM NVRAM\")\n                return None\n            if len(errout) > 0 and \"ERROR: Failed to read NVRAM public area at index\" in \"\\n\".join(errout):\n                logger.debug(\"No stored U in TPM NVRAM\")\n                return None\n            if len(errout) > 0 and \"the handle is not correct for the use\" in \"\\n\".join(errout):\n                logger.debug(\"No stored U in TPM NVRAM\")\n                return None\n\n            raise Exception(\"nv_readvalue failed with code \" + str(code) + \": \" + str(errout))\n\n        if len(output) != config.BOOTSTRAP_KEY_SIZE:\n            logger.debug(\"Invalid key length from NVRAM: %d\" % (len(output)))\n            return None\n        return output\n\n    def __stringify_pcr_keys(self, log: dict) -> None:\n        '''Ensure that the PCR indices are strings\n\n        The YAML produced by `tpm2_eventlog`, when loaded by the yaml module,\n        uses integer keys in the dicts holding PCR contents.  That does not\n        correspond to any JSON data.  This method ensures those keys are\n        strings.\n        The log is untrusted because it ultimately comes from an untrusted\n        source and has been processed by software that has had bugs.'''\n        if (not isinstance(log, dict)) or 'pcrs' not in log:\n            return\n        old_pcrs = log['pcrs']\n        if not isinstance(old_pcrs, dict):\n            return\n        new_pcrs = {}\n        for hash_alg, cells in old_pcrs.items():\n            if not isinstance(cells, dict):\n                new_pcrs[hash_alg] = cells\n                continue\n            new_pcrs[hash_alg] = {str(index): val for index, val in cells.items()}\n        log['pcrs'] = new_pcrs\n        return\n\n    def __add_boot_aggregate(self, log: dict) -> None :\n        '''Scan the boot event log and calculate possible boot aggregates.\n\n        Hashes are calculated for both sha1 and sha256,\n        as well as for 8 or 10 participant PCRs.\n\n        Technically the sha1/10PCR combination is unnecessary, since it has no\n        implementation.\n\n        Error conditions caused by improper string formatting etc. are\n        ignored. The current assumption is that the boot event log PCR\n        values are in decimal encoding, but this is liable to change.'''\n        if (not isinstance(log, dict)) or 'pcrs' not in log:\n            return\n        log['boot_aggregates'] = {}\n        for hashalg in log['pcrs'].keys():\n            log['boot_aggregates'][hashalg] = []\n            for maxpcr in [8,10]:\n                try:\n                    hashclass = getattr(hashlib,hashalg)\n                    h = hashclass()\n                    for pcrno in range(0,maxpcr):\n                        pcrstrg=log['pcrs'][hashalg][str(pcrno)]\n                        pcrhex= '{0:0{1}x}'.format(pcrstrg, h.digest_size*2)\n                        h.update(bytes.fromhex(pcrhex))\n                    log['boot_aggregates'][hashalg].append(h.hexdigest())\n                except Exception:\n                    pass\n\n    def parse_binary_bootlog(self, log_bin:bytes) -> typing.Optional[dict]:\n        '''Parse and enrich a BIOS boot log\n\n        The input is the binary log.\n        The output is the result of parsing and applying other conveniences.'''\n        with tempfile.NamedTemporaryFile() as log_bin_file:\n            log_bin_file.write(log_bin)\n            log_bin_filename = log_bin_file.name\n            retDict_tpm2 = self.__run(['tpm2_eventlog', '--eventlog-version=2', log_bin_filename])\n        log_parsed_strs = retDict_tpm2['retout']\n        log_parsed_data = config.yaml_to_dict(log_parsed_strs, add_newlines=False, logger=logger)\n        if log_parsed_data is None:\n            return None\n        #pylint: disable=import-outside-toplevel\n        try:\n            from keylime import tpm_bootlog_enrich\n        except Exception as e:\n            logger.error(\"Could not load tpm_bootlog_enrich (which depends on %s): %s\" % (config.LIBEFIVAR,str(e)))\n            return None\n        #pylint: enable=import-outside-toplevel\n        tpm_bootlog_enrich.enrich(log_parsed_data)\n        self.__stringify_pcr_keys(log_parsed_data)\n        self.__add_boot_aggregate(log_parsed_data)\n        return log_parsed_data\n\n    def _parse_mb_bootlog(self, log_b64:str) -> dict:\n        '''Parse and enrich a BIOS boot log\n\n        The input is the base64 encoding of a binary log.\n        The output is the result of parsing and applying other conveniences.'''\n        log_bin = base64.b64decode(log_b64, validate=True)\n        return self.parse_binary_bootlog(log_bin)\n\n    def parse_mb_bootlog(self, mb_measurement_list: str, hash_alg: algorithms.Hash) -> typing.Tuple[dict, typing.Optional[dict], dict, Failure]:\n        \"\"\" Parse the measured boot log and return its object and the state of the PCRs\n        :param mb_measurement_list: The measured boot measurement list\n        :param hash_alg: the hash algorithm that should be used for the PCRs\n        :returns: Returns a map of the state of the PCRs, measured boot data object and True for success\n                  and False in case an error occurred\n        \"\"\"\n        failure = Failure(Component.MEASURED_BOOT, [\"parser\"])\n        if mb_measurement_list:\n            #TODO add tagging for _parse_mb_bootlog\n            mb_measurement_data = self._parse_mb_bootlog(mb_measurement_list)\n            if not mb_measurement_data:\n                logger.error(\"Unable to parse measured boot event log. Check previous messages for a reason for error.\")\n                return {}, None, {}, failure\n            log_pcrs = mb_measurement_data.get('pcrs')\n            if not isinstance(log_pcrs, dict):\n                logger.error(\"Parse of measured boot event log has unexpected value for .pcrs: %r\", log_pcrs)\n                failure.add_event(\"invalid_pcrs\", {\"got\": log_pcrs}, True)\n                return {}, None, {}, failure\n            pcr_hashes = log_pcrs.get(str(hash_alg))\n            if (not isinstance(pcr_hashes, dict)) or not pcr_hashes:\n                logger.error(\"Parse of measured boot event log has unexpected value for .pcrs.%s: %r\", str(hash_alg), pcr_hashes)\n                failure.add_event(\"invalid_pcrs_hashes\", {\"got\": pcr_hashes}, True)\n                return {}, None, {}, failure\n            boot_aggregates = mb_measurement_data.get('boot_aggregates')\n            if (not isinstance(boot_aggregates, dict)) or not boot_aggregates:\n                logger.error(\"Parse of measured boot event log has unexpected value for .boot_aggragtes: %r\", boot_aggregates)\n                failure.add_event(\"invalid_boot_aggregates\", {\"got\": boot_aggregates}, True)\n                return {}, None, {}, failure\n\n            return pcr_hashes, boot_aggregates, mb_measurement_data, failure\n\n        return {}, None, {}, failure\n"], "fixing_code": ["\"\"\"\nSPDX-License-Identifier: Apache-2.0\nCopyright 2017 Massachusetts Institute of Technology.\n\"\"\"\n\nimport ast\nimport base64\nimport time\n\nfrom keylime import config\nfrom keylime import keylime_logging\nfrom keylime import crypto\nfrom keylime import json\nfrom keylime import revocation_notifier\nfrom keylime.agentstates import AgentAttestStates\nfrom keylime.failure import Failure, Component\nfrom keylime.tpm.tpm_main import tpm\nfrom keylime.tpm.tpm_abstract import TPM_Utilities\nfrom keylime.common import algorithms\nfrom keylime import ima_file_signatures\n\n# setup logging\nlogger = keylime_logging.init_logging('cloudverifier_common')\n\nGLOBAL_TPM_INSTANCE = None\nDEFAULT_VERIFIER_ID = \"default\"\n\n\ndef get_tpm_instance():\n    global GLOBAL_TPM_INSTANCE\n    if GLOBAL_TPM_INSTANCE is None:\n        GLOBAL_TPM_INSTANCE = tpm()\n    return GLOBAL_TPM_INSTANCE\n\n\ndef get_AgentAttestStates():\n    return AgentAttestStates.get_instance()\n\n\ndef process_quote_response(agent, json_response, agentAttestState) -> Failure:\n    \"\"\"Validates the response from the Cloud agent.\n\n    This method invokes an Registrar Server call to register, and then check the quote.\n    \"\"\"\n    failure = Failure(Component.QUOTE_VALIDATION)\n    received_public_key = None\n    quote = None\n    # in case of failure in response content do not continue\n    try:\n        received_public_key = json_response.get(\"pubkey\", None)\n        quote = json_response[\"quote\"]\n\n        ima_measurement_list = json_response.get(\"ima_measurement_list\", None)\n        ima_measurement_list_entry = json_response.get(\"ima_measurement_list_entry\", 0)\n        mb_measurement_list = json_response.get(\"mb_measurement_list\", None)\n        boottime = json_response.get(\"boottime\", 0)\n\n        logger.debug(\"received quote:      %s\", quote)\n        logger.debug(\"for nonce:           %s\", agent['nonce'])\n        logger.debug(\"received public key: %s\", received_public_key)\n        logger.debug(\"received ima_measurement_list    %s\", (ima_measurement_list is not None))\n        logger.debug(\"received ima_measurement_list_entry: %d\", ima_measurement_list_entry)\n        logger.debug(\"received boottime: %s\", boottime)\n        logger.debug(\"received boot log    %s\", (mb_measurement_list is not None))\n    except Exception as e:\n        failure.add_event(\"invalid_data\", {\"message\": \"parsing agents get quote respone failed\", \"data\": e}, False)\n        return failure\n\n    # TODO: Are those separate failures?\n    if not isinstance(ima_measurement_list_entry, int):\n        raise Exception(\"ima_measurement_list_entry parameter must be an integer\")\n\n    if not isinstance(boottime, int):\n        raise Exception(\"boottime parameter must be an integer\")\n\n    # if no public key provided, then ensure we have cached it\n    if received_public_key is None:\n        if agent.get('public_key', \"\") == \"\" or agent.get('b64_encrypted_V', \"\") == \"\":\n            logger.error(\"agent did not provide public key and no key or encrypted_v was cached at CV\")\n            failure.add_event(\"no_pubkey\", \"agent did not provide public key and no key or encrypted_v was cached at CV\", False)\n            return failure\n        agent['provide_V'] = False\n        received_public_key = agent['public_key']\n\n    hash_alg = json_response.get('hash_alg')\n    enc_alg = json_response.get('enc_alg')\n    sign_alg = json_response.get('sign_alg')\n\n    # Update chosen tpm and algorithms\n    agent['hash_alg'] = hash_alg\n    agent['enc_alg'] = enc_alg\n    agent['sign_alg'] = sign_alg\n\n    # Ensure hash_alg is in accept_tpm_hash_alg list\n    if not algorithms.is_accepted(hash_alg, agent['accept_tpm_hash_algs'])\\\n            or not algorithms.Hash.is_recognized(hash_alg):\n        logger.error(f\"TPM Quote is using an unaccepted hash algorithm: {hash_alg}\")\n        failure.add_event(\"invalid_hash_alg\",\n                          {\"message\": f\"TPM Quote is using an unaccepted hash algorithm: {hash_alg}\", \"data\": hash_alg},\n                          False)\n        return failure\n\n    # Ensure enc_alg is in accept_tpm_encryption_algs list\n    if not algorithms.is_accepted(enc_alg, agent['accept_tpm_encryption_algs']):\n        logger.error(f\"TPM Quote is using an unaccepted encryption algorithm: {enc_alg}\")\n        failure.add_event(\"invalid_enc_alg\",\n                          {\"message\": f\"TPM Quote is using an unaccepted encryption algorithm: {enc_alg}\", \"data\": enc_alg},\n                          False)\n        return failure\n\n    # Ensure sign_alg is in accept_tpm_encryption_algs list\n    if not algorithms.is_accepted(sign_alg, agent['accept_tpm_signing_algs']):\n        logger.error(f\"TPM Quote is using an unaccepted signing algorithm: {sign_alg}\")\n        failure.add_event(\"invalid_sign_alg\",\n                          {\"message\": f\"TPM Quote is using an unaccepted signing algorithm: {sign_alg}\", \"data\": {sign_alg}},\n                          False)\n        return failure\n\n    if ima_measurement_list_entry == 0:\n        agentAttestState.reset_ima_attestation()\n    elif ima_measurement_list_entry != agentAttestState.get_next_ima_ml_entry():\n        # If we requested a particular entry number then the agent must return either\n        # starting at 0 (handled above) or with the requested number.\n        logger.error(\"Agent did not respond with requested next IMA measurement list entry \"\n                     f\"{agentAttestState.get_next_ima_ml_entry()} but started at {ima_measurement_list_entry}\")\n        failure.add_event(\"invalid_ima_entry_nb\",\n                          {\"message\": \"Agent did not respond with requested next IMA measurement list entry\",\n                           \"got\": ima_measurement_list_entry, \"expected\": agentAttestState.get_next_ima_ml_entry()},\n                          False)\n    elif not agentAttestState.is_expected_boottime(boottime):\n        # agent sent a list not starting at 0 and provided a boottime that doesn't\n        # match the expected boottime, so it must have been rebooted; we would fail\n        # attestation this time so we retry with a full attestation next time.\n        agentAttestState.reset_ima_attestation()\n        return failure\n\n    agentAttestState.set_boottime(boottime)\n\n    ima_keyrings = agentAttestState.get_ima_keyrings()\n    tenant_keyring = ima_file_signatures.ImaKeyring.from_string(agent['ima_sign_verification_keys'])\n    ima_keyrings.set_tenant_keyring(tenant_keyring)\n\n    quote_validation_failure = get_tpm_instance().check_quote(\n        agentAttestState,\n        agent['nonce'],\n        received_public_key,\n        quote,\n        agent['ak_tpm'],\n        agent['tpm_policy'],\n        ima_measurement_list,\n        agent['allowlist'],\n        algorithms.Hash(hash_alg),\n        ima_keyrings,\n        mb_measurement_list,\n        agent['mb_refstate'],\n        compressed=(agent['supported_version'] == \"1.0\"))  # TODO: change this to always False after initial update\n    failure.merge(quote_validation_failure)\n\n    if not failure:\n        # set a flag so that we know that the agent was verified once.\n        # we only issue notifications for agents that were at some point good\n        agent['first_verified'] = True\n\n        # has public key changed? if so, clear out b64_encrypted_V, it is no longer valid\n        if received_public_key != agent.get('public_key', \"\"):\n            agent['public_key'] = received_public_key\n            agent['b64_encrypted_V'] = \"\"\n            agent['provide_V'] = True\n\n    # ok we're done\n    return failure\n\n\ndef prepare_v(agent):\n    # be very careful printing K, U, or V as they leak in logs stored on unprotected disks\n    if config.INSECURE_DEBUG:\n        logger.debug(\"b64_V (non encrypted): %s\", agent['v'])\n\n    if agent.get('b64_encrypted_V', \"\") != \"\":\n        b64_encrypted_V = agent['b64_encrypted_V']\n        logger.debug(\"Re-using cached encrypted V\")\n    else:\n        # encrypt V with the public key\n        b64_encrypted_V = base64.b64encode(crypto.rsa_encrypt(\n            crypto.rsa_import_pubkey(agent['public_key']), base64.b64decode(agent['v'])))\n        agent['b64_encrypted_V'] = b64_encrypted_V\n\n    # logger.debug(\"b64_encrypted_V:\" + b64_encrypted_V)\n    post_data = {\n        'encrypted_key': b64_encrypted_V\n    }\n    return post_data\n\n\ndef prepare_get_quote(agent):\n    \"\"\"This method encapsulates the action required to invoke a quote request on the Cloud Agent.\n\n    This method is part of the polling loop of the thread launched on Tenant POST.\n    \"\"\"\n    agentAttestState = get_AgentAttestStates().get_by_agent_id(agent['agent_id'])\n    agent['nonce'] = TPM_Utilities.random_password(20)\n\n    tpm_policy = ast.literal_eval(agent['tpm_policy'])\n    vtpm_policy = ast.literal_eval(agent['vtpm_policy'])\n\n    params = {\n        'nonce': agent['nonce'],\n        'mask': tpm_policy['mask'],\n        'vmask': vtpm_policy['mask'],\n        'ima_ml_entry': agentAttestState.get_next_ima_ml_entry(),\n    }\n    return params\n\n\ndef process_get_status(agent):\n    allowlist = json.loads(agent.allowlist)\n    if isinstance(allowlist, dict) and 'allowlist' in allowlist:\n        al_len = len(allowlist['allowlist'])\n    else:\n        al_len = 0\n\n    try :\n        mb_refstate = json.loads(agent.mb_refstate)\n    except Exception as e:\n        logger.warning('Non-fatal problem ocurred while attempting to evaluate agent attribute \"mb_refstate\" (%s). Will just consider the value of this attribute to be \"None\"', e.args)\n        mb_refstate = None\n        logger.debug('The contents of the agent attribute \"mb_refstate\" are %s', agent.mb_refstate)\n\n    if isinstance(mb_refstate, dict) and 'mb_refstate' in mb_refstate:\n        mb_refstate_len = len(mb_refstate['mb_refstate'])\n    else:\n        mb_refstate_len = 0\n    response = {'operational_state': agent.operational_state,\n                'v': agent.v,\n                'ip': agent.ip,\n                'port': agent.port,\n                'tpm_policy': agent.tpm_policy,\n                'vtpm_policy': agent.vtpm_policy,\n                'meta_data': agent.meta_data,\n                'allowlist_len': al_len,\n                'mb_refstate_len': mb_refstate_len,\n                'accept_tpm_hash_algs': agent.accept_tpm_hash_algs,\n                'accept_tpm_encryption_algs': agent.accept_tpm_encryption_algs,\n                'accept_tpm_signing_algs': agent.accept_tpm_signing_algs,\n                'hash_alg': agent.hash_alg,\n                'enc_alg': agent.enc_alg,\n                'sign_alg': agent.sign_alg,\n                'verifier_id' : agent.verifier_id,\n                'verifier_ip' : agent.verifier_ip,\n                'verifier_port' : agent.verifier_port,\n                'severity_level': agent.severity_level,\n                'last_event_id': agent.last_event_id\n                }\n    return response\n\n\n# sign a message with revocation key.  telling of verification problem\n\n\ndef notify_error(agent, msgtype='revocation', event=None):\n    send_mq = config.getboolean('cloud_verifier', 'revocation_notifier')\n    send_webhook = config.getboolean('cloud_verifier', 'revocation_notifier_webhook', fallback=False)\n    if not (send_mq or send_webhook):\n        return\n\n    # prepare the revocation message:\n    revocation = {'type': msgtype,\n                  'ip': agent['ip'],\n                  'agent_id': agent['agent_id'],\n                  'port': agent['port'],\n                  'tpm_policy': agent['tpm_policy'],\n                  'vtpm_policy': agent['vtpm_policy'],\n                  'meta_data': agent['meta_data'],\n                  'event_time': time.asctime()}\n    if event:\n        revocation['event_id'] = event.event_id\n        revocation['severity_label'] = event.severity_label.name\n        revocation['context'] = event.context\n\n    tosend = {'msg': json.dumps(revocation).encode('utf-8')}\n\n    # also need to load up private key for signing revocations\n    if agent['revocation_key'] != \"\":\n        signing_key = crypto.rsa_import_privkey(agent['revocation_key'])\n        tosend['signature'] = crypto.rsa_sign(signing_key, tosend['msg'])\n\n    else:\n        tosend['signature'] = \"none\"\n    if send_mq:\n        revocation_notifier.notify(tosend)\n    if send_webhook:\n        revocation_notifier.notify_webhook(tosend)\n\n\ndef validate_agent_data(agent_data):\n    if agent_data is None:\n        return False, None\n\n    # validate that the allowlist is proper JSON\n    lists = json.loads(agent_data['allowlist'])\n\n    # Validate exlude list contains valid regular expressions\n    is_valid, _, err_msg = config.valid_exclude_list(lists.get('exclude'))\n    if not is_valid:\n        err_msg += \" Exclude list regex is misformatted. Please correct the issue and try again.\"\n\n    return is_valid, err_msg\n", "#!/usr/bin/python3\n\n'''\nSPDX-License-Identifier: Apache-2.0\nCopyright 2017 Massachusetts Institute of Technology.\n'''\n\nimport argparse\nimport base64\nimport hashlib\nimport io\nimport logging\nimport os\nimport subprocess\nimport sys\nimport time\nimport zipfile\nimport json\nimport tempfile\nimport requests\n\nfrom cryptography.hazmat.primitives import serialization as crypto_serialization\n\nfrom keylime.agentstates import AgentAttestState\nfrom keylime.requests_client import RequestsClient\nfrom keylime.common import states\nfrom keylime import config\nfrom keylime import keylime_logging\nfrom keylime import registrar_client\nfrom keylime.tpm import tpm2_objects\nfrom keylime.tpm.tpm_main import tpm\nfrom keylime.tpm.tpm_abstract import TPM_Utilities\nfrom keylime import ima\nfrom keylime import crypto\nfrom keylime.cmd import user_data_encrypt\nfrom keylime import ca_util\nfrom keylime.common import algorithms\nfrom keylime import ima_file_signatures\nfrom keylime import measured_boot\nfrom keylime import gpg\nfrom keylime import api_version as keylime_api_version\n\n# setup logging\nlogger = keylime_logging.init_logging('tenant')\n\n# special exception that suppresses stack traces when it happens\nclass UserError(Exception):\n    pass\n\n\nclass Tenant():\n    \"\"\"Simple command processor example.\"\"\"\n\n    config = None\n\n    cloudverifier_ip = None\n    cloudverifier_port = None\n\n    cloudagent_ip = None\n    cv_cloudagent_ip = None\n    cloudagent_port = None\n\n    registrar_ip = None\n    registrar_port = None\n    registrar_data = None\n\n    webapp_ip = None\n    webapp_port = None\n\n    api_version = None\n\n    uuid_service_generate_locally = None\n    agent_uuid = None\n\n    K = None\n    V = None\n    U = None\n    auth_tag = None\n\n    tpm_policy = None\n    vtpm_policy = {}\n    metadata = {}\n    allowlist = {}\n    ima_sign_verification_keys = []\n    revocation_key = \"\"\n    accept_tpm_hash_algs = []\n    accept_tpm_encryption_algs = []\n    accept_tpm_signing_algs = []\n    mb_refstate = None\n    supported_version = None\n\n    payload = None\n\n    tpm_instance = tpm()\n\n    def __init__(self):\n        \"\"\" Set up required values and TLS\n        \"\"\"\n        self.nonce = None\n        self.agent_ip = None\n        self.verifier_id = None\n        self.agent_port = None\n        self.verifier_ip = config.get('tenant', 'cloudverifier_ip')\n        self.verifier_port = config.get('tenant', 'cloudverifier_port')\n        self.registrar_ip = config.get('tenant', 'registrar_ip')\n        self.registrar_port = config.get('tenant', 'registrar_port')\n        self.webapp_port = config.getint('webapp', 'webapp_port')\n        if not config.REQUIRE_ROOT and self.webapp_port < 1024:\n            self.webapp_port += 2000\n        self.webapp_ip = config.get('webapp', 'webapp_ip')\n\n        self.api_version = keylime_api_version.current_version()\n\n        (self.my_cert, self.my_priv_key), (self.my_agent_cert, self.my_agent_priv_key) = self.get_tls_context()\n        self.cert = (self.my_cert, self.my_priv_key)\n        self.agent_cert = (self.my_agent_cert, self.my_agent_priv_key)\n        if config.getboolean('general', \"enable_tls\"):\n            self.tls_enabled = True\n        else:\n            self.tls_enabled = False\n            self.cert = \"\"\n            logger.warning(\n                \"Warning: TLS is currently disabled, keys will be sent in the clear! This should only be used for testing.\")\n\n    @property\n    def verifier_base_url(self):\n        return f'{self.verifier_ip}:{self.verifier_port}'\n\n    def get_tls_context(self):\n        \"\"\"Generate certifcate naming and path\n\n        Returns:\n            string -- my_cert (client_cert), my_priv_key (client private key)\n        \"\"\"\n        my_cert = config.get('tenant', 'my_cert')\n        my_priv_key = config.get('tenant', 'private_key')\n        tls_dir = config.get('tenant', 'tls_dir')\n\n        if tls_dir == 'default':\n            my_cert = 'client-cert.crt'\n            my_priv_key = 'client-private.pem'\n            tls_dir = 'cv_ca'\n\n        if tls_dir[0] != '/':\n            tls_dir = os.path.abspath(os.path.join(config.WORK_DIR, tls_dir))\n\n        logger.info(\"Setting up client TLS in %s\", tls_dir)\n        my_cert = os.path.join(tls_dir, my_cert)\n        my_priv_key = os.path.join(tls_dir, my_priv_key)\n\n        tls_context = (my_cert, my_priv_key)\n\n        # Check for user defined CA to connect to agent\n        agent_mtls_cert = config.get(\"cloud_verifier\", \"agent_mtls_cert\", fallback=None)\n        agent_mtls_private_key = config.get(\"cloud_verifier\", \"agent_mtls_private_key\", fallback=None)\n\n        agent_mtls_context = tls_context\n        if agent_mtls_cert != \"CV\":\n            agent_mtls_context = (agent_mtls_cert, agent_mtls_private_key)\n\n        return tls_context, agent_mtls_context\n\n    def process_allowlist(self, args):\n        # Set up PCR values\n        tpm_policy = config.get('tenant', 'tpm_policy')\n        if \"tpm_policy\" in args and args[\"tpm_policy\"] is not None:\n            tpm_policy = args[\"tpm_policy\"]\n        self.tpm_policy = TPM_Utilities.readPolicy(tpm_policy)\n        logger.info(\"TPM PCR Mask from policy is %s\", self.tpm_policy['mask'])\n\n        vtpm_policy = config.get('tenant', 'vtpm_policy')\n        if \"vtpm_policy\" in args and args[\"vtpm_policy\"] is not None:\n            vtpm_policy = args[\"vtpm_policy\"]\n        self.vtpm_policy = TPM_Utilities.readPolicy(vtpm_policy)\n        logger.info(\"TPM PCR Mask from policy is %s\", self.vtpm_policy['mask'])\n\n        if len(args.get(\"ima_sign_verification_keys\")) > 0:\n            # Auto-enable IMA (or-bit mask)\n            self.tpm_policy['mask'] = \"0x%X\" % (\n                    int(self.tpm_policy['mask'], 0) | (1 << config.IMA_PCR))\n\n            # Add all IMA file signing verification keys to a keyring\n            tenant_keyring = ima_file_signatures.ImaKeyring()\n            for filename in args[\"ima_sign_verification_keys\"]:\n                pubkey, keyidv2 = ima_file_signatures.get_pubkey_from_file(filename)\n                if not pubkey:\n                    raise UserError(\n                        \"File '%s' is not a file with a key\" % filename)\n                tenant_keyring.add_pubkey(pubkey, keyidv2)\n            self.ima_sign_verification_keys = tenant_keyring.to_string()\n\n        # Read command-line path string allowlist\n        al_data = None\n\n        if \"allowlist\" in args and args[\"allowlist\"] is not None:\n\n            self.enforce_pcrs(list(self.tpm_policy.keys()), [ config.IMA_PCR ], \"IMA\")\n\n            # Auto-enable IMA (or-bit mask)\n            self.tpm_policy['mask'] = \"0x%X\" % (\n                    int(self.tpm_policy['mask'], 0) | (1 << config.IMA_PCR))\n\n            if isinstance(args[\"allowlist\"], str):\n                if args[\"allowlist\"] == \"default\":\n                    args[\"allowlist\"] = config.get('tenant', 'allowlist')\n                al_data = ima.read_allowlist(args[\"allowlist\"], args[\"allowlist_checksum\"], args[\"allowlist_sig\"], args[\"allowlist_sig_key\"])\n            elif isinstance(args[\"allowlist\"], list):\n                al_data = args[\"allowlist\"]\n            else:\n                raise UserError(\"Invalid allowlist provided\")\n\n        # Read command-line path string IMA exclude list\n        excl_data = None\n        if \"ima_exclude\" in args and args[\"ima_exclude\"] is not None:\n            if isinstance(args[\"ima_exclude\"], str):\n                if args[\"ima_exclude\"] == \"default\":\n                    args[\"ima_exclude\"] = config.get(\n                        'tenant', 'ima_excludelist')\n                excl_data = ima.read_excllist(args[\"ima_exclude\"])\n            elif isinstance(args[\"ima_exclude\"], list):\n                excl_data = args[\"ima_exclude\"]\n            else:\n                raise UserError(\"Invalid exclude list provided\")\n\n        # Set up IMA\n        if TPM_Utilities.check_mask(self.tpm_policy['mask'], config.IMA_PCR) or \\\n                TPM_Utilities.check_mask(self.vtpm_policy['mask'],\n                                         config.IMA_PCR):\n            # Process allowlists\n            self.allowlist = ima.process_allowlists(al_data, excl_data)\n\n        # Read command-line path string TPM event log (measured boot) reference state\n        mb_refstate_data = None\n        if \"mb_refstate\" in args and args[\"mb_refstate\"] is not None:\n\n            self.enforce_pcrs(list(self.tpm_policy.keys()), config.MEASUREDBOOT_PCRS, \"measured boot\")\n\n            # Auto-enable TPM event log mesured boot (or-bit mask)\n            for _pcr in config.MEASUREDBOOT_PCRS :\n                self.tpm_policy['mask'] = \"0x%X\" % (\n                    int(self.tpm_policy['mask'], 0) | (1 << _pcr))\n\n            logger.info(\"TPM PCR Mask automatically modified is %s to include IMA/Event log PCRs\", self.tpm_policy['mask'])\n\n            if isinstance(args[\"mb_refstate\"], str):\n                if args[\"mb_refstate\"] == \"default\":\n                    args[\"mb_refstate\"] = config.get('tenant', 'mb_refstate')\n                mb_refstate_data = measured_boot.read_mb_refstate(args[\"mb_refstate\"])\n            else:\n                raise UserError(\"Invalid measured boot reference state (intended state) provided\")\n\n        # Set up measured boot (TPM event log) reference state\n        if TPM_Utilities.check_mask(self.tpm_policy['mask'], config.MEASUREDBOOT_PCRS[2]) :\n            # Process measured boot reference state\n            self.mb_refstate = mb_refstate_data\n\n    def init_add(self, args):\n        \"\"\" Set up required values. Command line options can overwrite these config values\n\n        Arguments:\n            args {[string]} -- agent_ip|agent_port|cv_agent_ip\n        \"\"\"\n        if \"agent_ip\" in args:\n            self.agent_ip = args[\"agent_ip\"]\n\n        if 'agent_port' in args and args['agent_port'] is not None:\n            self.agent_port = args['agent_port']\n\n        registrar_client.init_client_tls(\"tenant\")\n        self.registrar_data = registrar_client.getData(self.registrar_ip, self.registrar_port, self.agent_uuid)\n\n        # try to get the port or ip from the registrar if it is missing\n        if (self.agent_ip is None or self.agent_port is None) and self.registrar_data is not None:\n            if self.agent_ip is None:\n                if self.registrar_data['ip'] is not None:\n                    self.agent_ip = self.registrar_data['ip']\n                else:\n                    raise UserError(\"No Ip was specified or found in the Registrar\")\n\n            if self.agent_port is None and self.registrar_data['port'] is not None:\n                self.agent_port = self.registrar_data[\"port\"]\n\n        # If no agent port was found try to use the default from the config file\n        if self.agent_port is None:\n            self.agent_port = config.get('cloud_agent', 'cloudagent_port')\n\n        # Check if a contact ip and port for the agent was found\n        if self.agent_ip is None:\n            raise UserError(\"The contact ip address for the agent was not specified.\")\n\n        if self.agent_port is None:\n            raise UserError(\"The contact port for the agent was not specified.\")\n\n        # Auto-detection for API version\n        self.supported_version = args[\"supported_version\"]\n        if self.supported_version is None:\n            # Default to 1.0 if the agent did not send a mTLS certificate\n            if self.registrar_data.get(\"mtls_cert\", None) is None:\n                self.supported_version = \"1.0\"\n            else:\n                # Try to connect to the agent to get supported version\n                with RequestsClient(f\"{self.agent_ip}:{self.agent_port}\", tls_enabled=True, cert=self.agent_cert,\n                                    ignore_hostname=True, verify_custom=self.registrar_data['mtls_cert']) as get_version:\n                    res = get_version.get(\"/version\")\n                    if res and res.status_code == 200:\n                        try:\n                            data = res.json()\n                            api_version = data[\"results\"][\"supported_version\"]\n                            if keylime_api_version.validate_version(api_version):\n                                self.supported_version = api_version\n                            else:\n                                logger.warning(\"API version provided by the agent is not valid\")\n                        except (TypeError, KeyError):\n                            pass\n\n        if self.supported_version is None:\n            api_version = keylime_api_version.current_version()\n            logger.warning(\"Could not detect supported API version. Defaulting to %s\", api_version)\n            self.supported_version = api_version\n\n        # Now set the cv_agent_ip\n        if 'cv_agent_ip' in args and args['cv_agent_ip'] is not None:\n            self.cv_cloudagent_ip = args['cv_agent_ip']\n        else:\n            self.cv_cloudagent_ip = self.agent_ip\n\n        # Make sure all keys exist in dictionary\n        if \"file\" not in args:\n            args[\"file\"] = None\n        if \"keyfile\" not in args:\n            args[\"keyfile\"] = None\n        if \"payload\" not in args:\n            args[\"payload\"] = None\n        if \"ca_dir\" not in args:\n            args[\"ca_dir\"] = None\n        if \"incl_dir\" not in args:\n            args[\"incl_dir\"] = None\n        if \"ca_dir_pw\" not in args:\n            args[\"ca_dir_pw\"] = None\n\n        # Set up accepted algorithms\n        self.accept_tpm_hash_algs = config.get(\n            'tenant', 'accept_tpm_hash_algs').split(',')\n        self.accept_tpm_encryption_algs = config.get(\n            'tenant', 'accept_tpm_encryption_algs').split(',')\n        self.accept_tpm_signing_algs = config.get(\n            'tenant', 'accept_tpm_signing_algs').split(',')\n\n        self.process_allowlist(args)\n\n        # if none\n        if (args[\"file\"] is None and args[\"keyfile\"] is None and args[\"ca_dir\"] is None):\n            raise UserError(\n                \"You must specify one of -k, -f, or --cert to specify the key/contents to be securely delivered to the agent\")\n\n        if args[\"keyfile\"] is not None:\n            if args[\"file\"] is not None or args[\"ca_dir\"] is not None:\n                raise UserError(\n                    \"You must specify one of -k, -f, or --cert to specify the key/contents to be securely delivered to the agent\")\n\n            # read the keys in\n            if isinstance(args[\"keyfile\"], dict) and \"data\" in args[\"keyfile\"]:\n                if isinstance(args[\"keyfile\"][\"data\"], list) and len(args[\"keyfile\"][\"data\"]) == 1:\n                    keyfile = args[\"keyfile\"][\"data\"][0]\n                    if keyfile is None:\n                        raise UserError(\"Invalid key file contents\")\n                    f = io.StringIO(keyfile)\n                else:\n                    raise UserError(\"Invalid key file provided\")\n            else:\n                f = open(args[\"keyfile\"], encoding=\"utf-8\")\n            self.K = base64.b64decode(f.readline())\n            self.U = base64.b64decode(f.readline())\n            self.V = base64.b64decode(f.readline())\n            f.close()\n\n            # read the payload in (opt.)\n            if isinstance(args[\"payload\"], dict) and \"data\" in args[\"payload\"]:\n                if isinstance(args[\"payload\"][\"data\"], list) and len(args[\"payload\"][\"data\"]) > 0:\n                    self.payload = args[\"payload\"][\"data\"][0]\n            else:\n                if args[\"payload\"] is not None:\n                    f = open(args[\"payload\"], 'rb')\n                    self.payload = f.read()\n                    f.close()\n\n        if args[\"file\"] is not None:\n            if args[\"keyfile\"] is not None or args[\"ca_dir\"] is not None:\n                raise UserError(\n                    \"You must specify one of -k, -f, or --cert to specify the key/contents to be securely delivered to the agent\")\n\n            if isinstance(args[\"file\"], dict) and \"data\" in args[\"file\"]:\n                if isinstance(args[\"file\"][\"data\"], list) and len(args[\"file\"][\"data\"]) > 0:\n                    contents = args[\"file\"][\"data\"][0]\n                    if contents is None:\n                        raise UserError(\"Invalid file payload contents\")\n                else:\n                    raise UserError(\"Invalid file payload provided\")\n            else:\n                with open(args[\"file\"], encoding=\"utf-8\") as f:\n                    contents = f.read()\n            ret = user_data_encrypt.encrypt(contents)\n            self.K = ret['k']\n            self.U = ret['u']\n            self.V = ret['v']\n            self.payload = ret['ciphertext']\n\n        if args[\"ca_dir\"] is None and args[\"incl_dir\"] is not None:\n            raise UserError(\n                \"--include option is only valid when used with --cert\")\n        if args[\"ca_dir\"] is not None:\n            if args[\"file\"] is not None or args[\"keyfile\"] is not None:\n                raise UserError(\n                    \"You must specify one of -k, -f, or --cert to specify the key/contents to be securely delivered to the agent\")\n            if args[\"ca_dir\"] == 'default':\n                args[\"ca_dir\"] = config.CA_WORK_DIR\n\n            if \"ca_dir_pw\" in args and args[\"ca_dir_pw\"] is not None:\n                ca_util.setpassword(args[\"ca_dir_pw\"])\n\n            if not os.path.exists(args[\"ca_dir\"]) or not os.path.exists(\"%s/cacert.crt\" % args[\"ca_dir\"]):\n                logger.warning(\"CA directory does not exist. Creating...\")\n                ca_util.cmd_init(args[\"ca_dir\"])\n            if not os.path.exists(\n                    os.path.join(args[\"ca_dir\"],\n                                 f\"{self.agent_uuid}-private.pem\")):\n                ca_util.cmd_mkcert(args[\"ca_dir\"], self.agent_uuid)\n\n            cert_pkg, serial, subject = ca_util.cmd_certpkg(\n                args[\"ca_dir\"], self.agent_uuid)\n\n            # support revocation\n            if not os.path.exists(\"%s/RevocationNotifier-private.pem\" % args[\"ca_dir\"]):\n                ca_util.cmd_mkcert(args[\"ca_dir\"], \"RevocationNotifier\")\n            rev_package, _, _ = ca_util.cmd_certpkg(\n                args[\"ca_dir\"], \"RevocationNotifier\")\n\n            # extract public and private keys from package\n            sf = io.BytesIO(rev_package)\n            with zipfile.ZipFile(sf) as zf:\n                privkey = zf.read(\"RevocationNotifier-private.pem\")\n                cert = zf.read(\"RevocationNotifier-cert.crt\")\n\n            # put the cert of the revoker into the cert package\n            sf = io.BytesIO(cert_pkg)\n            with zipfile.ZipFile(sf, 'a', compression=zipfile.ZIP_STORED) as zf:\n                zf.writestr('RevocationNotifier-cert.crt', cert)\n\n                # add additional files to zip\n                if args[\"incl_dir\"] is not None:\n                    if isinstance(args[\"incl_dir\"], dict) and \"data\" in args[\"incl_dir\"] and \"name\" in args[\"incl_dir\"]:\n                        if isinstance(args[\"incl_dir\"][\"data\"], list) and isinstance(args[\"incl_dir\"][\"name\"], list):\n                            if len(args[\"incl_dir\"][\"data\"]) != len(args[\"incl_dir\"][\"name\"]):\n                                raise UserError(\"Invalid incl_dir provided\")\n                            for i in range(len(args[\"incl_dir\"][\"data\"])):\n                                zf.writestr(os.path.basename(\n                                    args[\"incl_dir\"][\"name\"][i]), args[\"incl_dir\"][\"data\"][i])\n                    else:\n                        if os.path.exists(args[\"incl_dir\"]):\n                            files = next(os.walk(args[\"incl_dir\"]))[2]\n                            for filename in files:\n                                with open(os.path.join(args[\"incl_dir\"],\n                                                       filename), 'rb') as f:\n                                    zf.writestr(\n                                        os.path.basename(f.name), f.read())\n                        else:\n                            logger.warning('Specified include directory %s does not exist. Skipping...', args[\"incl_dir\"])\n\n            cert_pkg = sf.getvalue()\n\n            # put the private key into the data to be send to the CV\n            self.revocation_key = privkey.decode('utf-8')\n\n            # encrypt up the cert package\n            ret = user_data_encrypt.encrypt(cert_pkg)\n            self.K = ret['k']\n            self.U = ret['u']\n            self.V = ret['v']\n            self.metadata = {'cert_serial': serial, 'subject': subject}\n            self.payload = ret['ciphertext']\n\n        if self.payload is not None and len(self.payload) > config.getint('tenant', 'max_payload_size'):\n            raise UserError(\"Payload size %s exceeds max size %d\" % (\n                len(self.payload), config.getint('tenant', 'max_payload_size')))\n\n    def enforce_pcrs(self, policy_pcrs, protected_pcrs, pcr_use) :\n        policy_pcrs = list(self.tpm_policy.keys())\n        policy_pcrs.remove('mask')\n\n        for _pcr in policy_pcrs :\n            if int(_pcr) in protected_pcrs :\n                logger.error('WARNING: PCR %s is specified in \"tpm_policy\", but will in fact be used by %s. Please remove it from policy', _pcr, pcr_use)\n                sys.exit(1)\n\n    def preloop(self):\n        \"\"\" encrypt the agent UUID as a check for delivering the correct key\n        \"\"\"\n        self.auth_tag = crypto.do_hmac(self.K, self.agent_uuid)\n        # be very careful printing K, U, or V as they leak in logs stored on unprotected disks\n        if config.INSECURE_DEBUG:\n            logger.debug(\"K: %s\", base64.b64encode(self.K))\n            logger.debug(\"V: %s\", base64.b64encode(self.V))\n            logger.debug(\"U: %s\", base64.b64encode(self.U))\n            logger.debug(\"Auth Tag: %s\", self.auth_tag)\n\n    def check_ek(self, ekcert):\n        \"\"\" Check the Entity Key\n\n        Arguments:\n            ekcert {str} -- The endorsement key, either None, \"emulator\", or base64 encoded der cert\n\n        Returns:\n            [type] -- [description]\n        \"\"\"\n        if config.getboolean('tenant', 'require_ek_cert'):\n            if config.STUB_TPM:\n                logger.debug(\"Not checking ekcert due to STUB_TPM mode\")\n            elif ekcert == 'emulator' and config.DISABLE_EK_CERT_CHECK_EMULATOR:\n                logger.info(\"Not checking ekcert of TPM emulator\")\n            elif ekcert is None:\n                logger.warning(\"No EK cert provided, require_ek_cert option in config set to True\")\n                return False\n            elif not self.tpm_instance.verify_ek(base64.b64decode(ekcert)):\n                logger.warning(\"Invalid EK certificate\")\n                return False\n\n        return True\n\n    def validate_tpm_quote(self, public_key, quote, hash_alg):\n        \"\"\" Validate TPM Quote received from the Agent\n\n        Arguments:\n            public_key {[type]} -- [description]\n            quote {[type]} -- [description]\n            hash_alg {bool} -- [description]\n\n        Raises:\n            UserError: [description]\n\n        Returns:\n            [type] -- [description]\n        \"\"\"\n        registrar_client.init_client_tls('tenant')\n        if self.registrar_data is None:\n            logger.warning(\"AIK not found in registrar, quote not validated\")\n            return False\n\n        failure = self.tpm_instance.check_quote(AgentAttestState(self.agent_uuid), self.nonce, public_key, quote,\n                                                self.registrar_data['aik_tpm'], hash_alg=hash_alg,\n                                                compressed=(self.supported_version == \"1.0\"))\n        if failure:\n            if self.registrar_data['regcount'] > 1:\n                logger.error(\"WARNING: This UUID had more than one ek-ekcert registered to it! This might indicate that your system is misconfigured or a malicious host is present. Run 'regdelete' for this agent and restart\")\n                sys.exit()\n            return False\n\n        if self.registrar_data['regcount'] > 1:\n            logger.warning(\"WARNING: This UUID had more than one ek-ekcert registered to it! This might indicate that your system is misconfigured. Run 'regdelete' for this agent and restart\")\n\n        if not config.STUB_TPM and (not config.getboolean('tenant', 'require_ek_cert') and config.get('tenant', 'ek_check_script') == \"\"):\n            logger.warning(\n                \"DANGER: EK cert checking is disabled and no additional checks on EKs have been specified with ek_check_script option. Keylime is not secure!!\")\n\n        # check EK cert and make sure it matches EK\n        if not self.check_ek(self.registrar_data['ekcert']):\n            return False\n        # if agent is virtual, check phyisical EK cert and make sure it matches phyiscal EK\n        if 'provider_keys' in self.registrar_data:\n            if not self.check_ek(self.registrar_data['provider_keys']['ekcert']):\n                return False\n\n        # check all EKs with optional script:\n        script = config.get('tenant', 'ek_check_script')\n        if not script:\n            return True\n\n        if script[0] != '/':\n            script = os.path.join(config.WORK_DIR, script)\n\n        logger.info(\"Checking EK with script %s\", script)\n        # now we need to exec the script with the ek and ek cert in vars\n        env = os.environ.copy()\n        env['AGENT_UUID'] = self.agent_uuid\n        env['EK'] = tpm2_objects.pubkey_from_tpm2b_public(\n            base64.b64decode(self.registrar_data['ek_tpm']),\n            ).public_bytes(\n                crypto_serialization.Encoding.PEM,\n                crypto_serialization.PublicFormat.SubjectPublicKeyInfo,\n            )\n        env['EK_TPM'] = self.registrar_data['ek_tpm']\n        if self.registrar_data['ekcert'] is not None:\n            env['EK_CERT'] = self.registrar_data['ekcert']\n        else:\n            env['EK_CERT'] = \"\"\n\n        env['PROVKEYS'] = json.dumps(self.registrar_data.get('provider_keys', {}))\n        proc = subprocess.Popen(script, env=env, shell=True,\n                                cwd=config.WORK_DIR, stdout=subprocess.PIPE,\n                                stderr=subprocess.STDOUT)\n        retval = proc.wait()\n        if retval != 0:\n            raise UserError(\"External check script failed to validate EK\")\n        logger.debug(\"External check script successfully to validated EK\")\n        while True:\n            line = proc.stdout.readline().decode()\n            if line == \"\":\n                break\n            logger.debug(\"ek_check output: %s\", line.strip())\n        return True\n\n    def do_cv(self):\n        \"\"\" Initiaite v, agent_id and ip and initiate the cloudinit sequence\n        \"\"\"\n        b64_v = base64.b64encode(self.V).decode('utf-8')\n        logger.debug(\"b64_v: %s\", b64_v)\n        data = {\n            'v': b64_v,\n            'cloudagent_ip': self.cv_cloudagent_ip,\n            'cloudagent_port': self.agent_port,\n            'tpm_policy': json.dumps(self.tpm_policy),\n            'vtpm_policy': json.dumps(self.vtpm_policy),\n            'allowlist': json.dumps(self.allowlist),\n            'mb_refstate': json.dumps(self.mb_refstate),\n            'ima_sign_verification_keys': json.dumps(self.ima_sign_verification_keys),\n            'metadata': json.dumps(self.metadata),\n            'revocation_key': self.revocation_key,\n            'accept_tpm_hash_algs': self.accept_tpm_hash_algs,\n            'accept_tpm_encryption_algs': self.accept_tpm_encryption_algs,\n            'accept_tpm_signing_algs': self.accept_tpm_signing_algs,\n            'supported_version': self.supported_version,\n        }\n        json_message = json.dumps(data)\n        do_cv = RequestsClient(self.verifier_base_url, self.tls_enabled)\n        response = do_cv.post(\n            (f'/v{self.api_version}/agents/{self.agent_uuid}'),\n            data=json_message,\n            cert=self.cert,\n            verify=False\n        )\n\n        if response.status_code == 503:\n            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)\n            sys.exit()\n        elif response.status_code == 504:\n            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)\n            sys.exit()\n\n        if response.status_code == 409:\n            # this is a conflict, need to update or delete it\n            logger.error(\"Agent %s already existed at CV. Please use delete or update.\", self.agent_uuid)\n            sys.exit()\n        elif response.status_code != 200:\n            keylime_logging.log_http_response(\n                logger, logging.ERROR, response.json())\n            logger.error(\"POST command response: %s Unexpected response from Cloud Verifier: %s\", response.status_code, response.text)\n            sys.exit()\n\n    def do_cvstatus(self):\n        \"\"\"Perform operational state look up for agent\"\"\"\n\n        do_cvstatus = RequestsClient(self.verifier_base_url, self.tls_enabled)\n\n        response = do_cvstatus.get(\n            (f'/v{self.api_version}/agents/{self.agent_uuid}'),\n            cert=self.cert,\n            verify=False\n        )\n\n        if response.status_code == 503:\n            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)\n            return response.json()\n        if response.status_code == 504:\n            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)\n            return response.json()\n        if response.status_code == 404:\n            logger.info(\"Verifier at %s with Port %s does not have agent %s.\",\n                        self.verifier_ip, self.verifier_port, self.agent_uuid)\n            return response.json()\n        if response.status_code == 200:\n            response = response.json()\n\n            res = response.pop('results')\n            response['results'] = {self.agent_uuid: res}\n\n            operational_state = states.state_to_str(\n                response['results'][self.agent_uuid]['operational_state'])\n            response['results'][self.agent_uuid]['operational_state'] = operational_state\n\n            logger.info(\"Agent Info:\\n%s\" % json.dumps(response[\"results\"]))\n\n            return response\n\n        logger.info(\"Status command response: %s. Unexpected response \"\n                    \"from Cloud Verifier %s on port %s. %s\",\n                    response.status_code,\n                    self.verifier_ip, self.verifier_port, str(response))\n        return response\n\n    def do_cvlist(self):\n        \"\"\"List all agent statues in cloudverifier\"\"\"\n\n        do_cvstatus = RequestsClient(self.verifier_base_url, self.tls_enabled)\n        verifier_id = \"\"\n        if self.verifier_id is not None:\n            verifier_id = self.verifier_id\n        response = do_cvstatus.get(\n            (f'/v{self.api_version}/agents/?verifier={verifier_id}'),\n            cert=self.cert,\n            verify=False\n        )\n\n        if response.status_code == 503:\n            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)\n            return response.json()\n        if response.status_code == 504:\n            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)\n            return response.json()\n        if response.status_code == 404:\n            logger.info(\"Verifier at %s with Port %s does not have agent %s.\",\n                        self.verifier_ip, self.verifier_port, self.agent_uuid)\n            return response.json()\n        if response.status_code == 200:\n            response = response.json()\n\n            logger.info('From verifier %s port %s retrieved: \"%s\"',\n                        self.verifier_ip, self.verifier_port, response)\n\n            return response\n\n        logger.info(\"Status command response: %s. Unexpected response \"\n                    \"from Cloud Verifier %s on port %s. %s\",\n                    response.status_code,\n                    self.verifier_ip, self.verifier_port, str(response))\n        return response\n\n    def do_cvbulkinfo(self):\n        \"\"\"Perform operational state look up for agent\"\"\"\n\n        do_cvstatus = RequestsClient(self.verifier_base_url, self.tls_enabled)\n\n        verifier_id = \"\"\n        if self.verifier_id is not None:\n            verifier_id = self.verifier_id\n        response = do_cvstatus.get(\n            (f'/v{self.api_version}/agents/?bulk={True}&verifier={verifier_id}'),\n            cert=self.cert,\n            verify=False\n        )\n\n        if response.status_code == 503:\n            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)\n            return response.json()\n        if response.status_code == 504:\n            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)\n            return response.json()\n        if response.status_code == 404:\n            logger.info(\"Verifier at %s with Port %s does not have agent %s.\",\n                        self.verifier_ip, self.verifier_port, self.agent_uuid)\n            return response.json()\n        if response.status_code == 200:\n            response = response.json()\n\n            for agent in response[\"results\"].keys():\n                response[\"results\"][agent][\"operational_state\"] = \\\n                    states.state_to_str(response[\"results\"][agent][\n                                            \"operational_state\"])\n            logger.info(\"Bulk Agent Info:\\n%s\" % json.dumps(response[\"results\"]))\n\n            return response\n\n        logger.info(\"Status command response: %s. Unexpected response \"\n                    \"from Cloud Verifier %s on port %s. %s\",\n                    response.status_code,\n                    self.verifier_ip, self.verifier_port, str(response))\n        return response\n\n    def do_cvdelete(self, verifier_check=True):\n        \"\"\"Delete agent from Verifier.\"\"\"\n        if verifier_check:\n            cvresponse = self.do_cvstatus()\n\n            if not isinstance(cvresponse, dict):\n                return cvresponse\n\n            if cvresponse['code'] != 200:\n                logger.error(\"Could not get status of agent %s from \"\n                             \"verifier %s.\", self.agent_uuid, self.verifier_ip)\n                return cvresponse\n\n            self.verifier_ip = cvresponse['results'][self.agent_uuid][\"verifier_ip\"]\n            self.verifier_port = cvresponse['results'][self.agent_uuid][\"verifier_port\"]\n\n        do_cvdelete = RequestsClient(self.verifier_base_url, self.tls_enabled)\n        response = do_cvdelete.delete(\n            (f'/v{self.api_version}/agents/{self.agent_uuid}'),\n            cert=self.cert,\n            verify=False\n        )\n\n        response = response.json()\n\n        if response['code'] == 503:\n            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)\n            return response\n        if response['code'] == 504:\n            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)\n            return response\n        if response['code'] == 202:\n            deleted = False\n            for _ in range(12):\n                get_cvdelete = RequestsClient(\n                    self.verifier_base_url, self.tls_enabled)\n                response = get_cvdelete.get(\n                    (f'/v{self.api_version}/agents/{self.agent_uuid}'),\n                    cert=self.cert,\n                    verify=False\n                )\n\n                if response.status_code == 404:\n                    deleted = True\n                    break\n                time.sleep(.4)\n            if deleted:\n                logger.info(\"CV completed deletion of agent %s\", self.agent_uuid)\n                return response.json()\n            logger.error(\"Timed out waiting for delete of agent %s to complete at CV\", self.agent_uuid)\n            return response.json()\n        if response['code'] == 200:\n            logger.info(\"Agent %s deleted from the CV\", self.agent_uuid)\n            return response\n\n        keylime_logging.log_http_response(\n            logger, logging.ERROR, response)\n        return response\n\n    def do_regstatus(self):\n        registrar_client.init_client_tls('tenant')\n        agent_info = registrar_client.getData(self.registrar_ip,\n                                              self.registrar_port,\n                                              self.agent_uuid)\n\n        if not agent_info:\n            logger.info(\n                \"Agent %s does not exist on the registrar. Please register the agent with the registrar.\",\n                self.agent_uuid)\n            response = {}\n            response['code'] = 404\n            response['status'] = \"Agent {0} does not exist on \" \\\n                                 \"registrar {1} port {2}.\".format(\n                self.agent_uuid, self.registrar_ip, self.registrar_port)\n            response['results'] = {}\n            logger.info(json.dumps((response)))\n            return response\n\n        response = {}\n        response['code'] = 200\n        response['status'] = \"Agent {0} exists on registrar {1} port {2}.\".format(\n                self.agent_uuid, self.registrar_ip, self.registrar_port)\n        response['results'] = {}\n        response['results'][self.agent_uuid] = agent_info\n        response['results'][self.agent_uuid]['operational_state'] = \\\n            states.state_to_str(states.REGISTERED)\n\n        logger.info(json.dumps(response))\n\n        return response\n\n    def do_reglist(self):\n        \"\"\"List agents from Registrar\"\"\"\n        registrar_client.init_client_tls('tenant')\n        response = registrar_client.doRegistrarList(\n            self.registrar_ip, self.registrar_port)\n\n        logger.info(\"From registrar %s port %s retrieved %s\",\n                    self.registrar_ip, self.registrar_port,\n                    json.dumps(response))\n        return response\n\n    def do_regdelete(self):\n        \"\"\"Delete agent from Registrar\"\"\"\n        registrar_client.init_client_tls('tenant')\n        response = registrar_client.doRegistrarDelete(self.registrar_ip,\n                                           self.registrar_port,\n                                           self.agent_uuid)\n\n        return response\n\n    def do_status(self):\n        \"\"\"Perform operational state look up for agent\"\"\"\n\n        regresponse = self.do_regstatus()\n\n        if regresponse['code'] == 404:\n            return regresponse\n\n        cvresponse = self.do_cvstatus()\n\n        if not isinstance(cvresponse, dict):\n            logger.error(\"Unexpected response from Cloud Verifier %s on \"\n                         \"port %s. response %s\", self.verifier_ip,\n                         self.verifier_port, str(cvresponse))\n            return cvresponse\n\n        if regresponse['code'] == 200 and cvresponse['code'] == 200:\n            return cvresponse\n        if regresponse['code'] == 200 and cvresponse['code'] != 200:\n            return regresponse\n\n        logger.error(\"Unknown inconsistent state between registrar %s on \"\n                     \"port %s and verifier %s on port %s occured. Got \"\n                     \"registrar response %s verifier response %s\",\n                     self.verifier_ip, self.verifier_port, self.registrar_ip,\n                     self.registrar_port, str(regresponse), str(cvresponse))\n\n        return {'registrar': regresponse, 'verifier': cvresponse}\n\n    def do_cvreactivate(self, verifier_check=True):\n        \"\"\"Reactive Agent.\"\"\"\n        if verifier_check:\n            agent_json = self.do_cvstatus()\n            self.verifier_ip = agent_json['results'][self.agent_uuid]['verifier_ip']\n            self.verifier_port = agent_json['results'][self.agent_uuid]['verifier_port']\n\n        do_cvreactivate = RequestsClient(\n            self.verifier_base_url, self.tls_enabled)\n        response = do_cvreactivate.put(\n            f'/v{self.api_version}/agents/{self.agent_uuid}/reactivate',\n            data=b'',\n            cert=self.cert,\n            verify=False\n        )\n\n        if response.status_code == 503:\n            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)\n            return response.json()\n        if response.status_code == 504:\n            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)\n            return response.json()\n        if response.status_code == 200:\n            logger.info(\"Agent %s re-activated\", self.agent_uuid)\n            return response.json()\n\n        response_body = response.json()\n        keylime_logging.log_http_response(\n            logger, logging.ERROR, response_body)\n        logger.error(\"Update command response: %s Unexpected response from Cloud Verifier.\", response.status_code)\n        return response.json()\n\n    def do_cvstop(self):\n        \"\"\" Stop declared active agent\n        \"\"\"\n        params = f'/v{self.api_version}/agents/{self.agent_uuid}/stop'\n        do_cvstop = RequestsClient(self.verifier_base_url, self.tls_enabled)\n        response = do_cvstop.put(\n            params,\n            cert=self.cert,\n            data=b'',\n            verify=False\n        )\n\n        if response.status_code == 503:\n            logger.error(\"Cannot connect to Verifier at %s with Port %s. Connection refused.\", self.verifier_ip, self.verifier_port)\n            sys.exit()\n        elif response.status_code == 504:\n            logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)\n            sys.exit()\n\n        response_body = response.json()\n        if response.status_code != 200:\n            keylime_logging.log_http_response(\n                logger, logging.ERROR, response_body)\n        else:\n            logger.info(\"Agent %s stopped\", self.agent_uuid)\n\n    def do_quote(self):\n        \"\"\" Perform TPM quote by GET towards Agent\n\n        Raises:\n            UserError: Connection handler\n        \"\"\"\n        self.nonce = TPM_Utilities.random_password(20)\n\n        numtries = 0\n        response = None\n        # Note: We need a specific retry handler (perhaps in common), no point having localised unless we have too.\n        while True:\n            try:\n                params = f'/v{self.supported_version}/quotes/identity?nonce=%s' % (self.nonce)\n                cloudagent_base_url = f'{self.agent_ip}:{self.agent_port}'\n\n                if self.registrar_data['mtls_cert']:\n                    with RequestsClient(cloudagent_base_url, tls_enabled=True, ignore_hostname=True, cert=self.agent_cert,\n                                        verify_custom=self.registrar_data['mtls_cert']) as do_quote:\n                        response = do_quote.get(params)\n                else:\n                    logger.warning(\"Connecting to agent without using mTLS!\")\n                    do_quote = RequestsClient(cloudagent_base_url, tls_enabled=False)\n                    response = do_quote.get(params)\n\n                print(response)\n                response_body = response.json()\n\n            except Exception as e:\n                if response.status_code in (503, 504):\n                    numtries += 1\n                    maxr = config.getint('tenant', 'max_retries')\n                    if numtries >= maxr:\n                        logger.error(\"Tenant cannot establish connection to agent on %s with port %s\", self.agent_ip, self.agent_port)\n                        sys.exit()\n                    retry = config.getfloat('tenant', 'retry_interval')\n                    logger.info(\"Tenant connection to agent at %s refused %s/%s times, trying again in %s seconds...\",\n                        self.agent_ip, numtries, maxr, retry)\n                    time.sleep(retry)\n                    continue\n\n                raise e\n            break\n\n        try:\n            if response is not None and response.status_code != 200:\n                raise UserError(\n                    \"Status command response: %d Unexpected response from Cloud Agent.\" % response.status)\n\n            if \"results\" not in response_body:\n                raise UserError(\n                    \"Error: unexpected http response body from Cloud Agent: %s\" % str(response.status))\n\n            quote = response_body[\"results\"][\"quote\"]\n            logger.debug(\"Agent_quote received quote: %s\", quote)\n\n            public_key = response_body[\"results\"][\"pubkey\"]\n            logger.debug(\"Agent_quote received public key: %s\", public_key)\n\n            # Ensure hash_alg is in accept_tpm_hash_algs list\n            hash_alg = response_body[\"results\"][\"hash_alg\"]\n            logger.debug(\"Agent_quote received hash algorithm: %s\", hash_alg)\n            if not algorithms.is_accepted(hash_alg, config.get('tenant', 'accept_tpm_hash_algs').split(','))\\\n                    or not algorithms.Hash.is_recognized(hash_alg):\n                raise UserError(\n                    \"TPM Quote is using an unaccepted hash algorithm: %s\" % hash_alg)\n\n            # Ensure enc_alg is in accept_tpm_encryption_algs list\n            enc_alg = response_body[\"results\"][\"enc_alg\"]\n            logger.debug(\"Agent_quote received encryption algorithm: %s\", enc_alg)\n            if not algorithms.is_accepted(enc_alg, config.get('tenant', 'accept_tpm_encryption_algs').split(',')):\n                raise UserError(\n                    \"TPM Quote is using an unaccepted encryption algorithm: %s\" % enc_alg)\n\n            # Ensure sign_alg is in accept_tpm_encryption_algs list\n            sign_alg = response_body[\"results\"][\"sign_alg\"]\n            logger.debug(\"Agent_quote received signing algorithm: %s\", sign_alg)\n            if not algorithms.is_accepted(sign_alg, config.get('tenant', 'accept_tpm_signing_algs').split(',')):\n                raise UserError(\n                    \"TPM Quote is using an unaccepted signing algorithm: %s\" % sign_alg)\n\n            if not self.validate_tpm_quote(public_key, quote, algorithms.Hash(hash_alg)):\n                raise UserError(\n                    \"TPM Quote from cloud agent is invalid for nonce: %s\" % self.nonce)\n\n            logger.info(\"Quote from %s validated\", self.agent_ip)\n\n            # encrypt U with the public key\n            encrypted_U = crypto.rsa_encrypt(\n                crypto.rsa_import_pubkey(public_key), self.U)\n\n            b64_encrypted_u = base64.b64encode(encrypted_U)\n            logger.debug(\"b64_encrypted_u: %s\", b64_encrypted_u.decode('utf-8'))\n            data = {\n                'encrypted_key': b64_encrypted_u.decode('utf-8'),\n                'auth_tag': self.auth_tag\n            }\n\n            if self.payload is not None:\n                data['payload'] = self.payload.decode('utf-8')\n\n\n            # post encrypted U back to CloudAgent\n            params = f'/v{self.supported_version}/keys/ukey'\n            cloudagent_base_url = (\n                f'{self.agent_ip}:{self.agent_port}'\n            )\n\n            if self.registrar_data['mtls_cert']:\n                with RequestsClient(cloudagent_base_url, tls_enabled=True, ignore_hostname=True, cert=self.agent_cert,\n                                    verify_custom=self.registrar_data['mtls_cert']) as post_ukey:\n                    response = post_ukey.post(params, json=data)\n            else:\n                logger.warning(\"Connecting to agent without using mTLS!\")\n                post_ukey = RequestsClient(cloudagent_base_url, tls_enabled=False)\n                response = post_ukey.post(params, json=data)\n\n            if response.status_code == 503:\n                logger.error(\"Cannot connect to Agent at %s with Port %s. Connection refused.\", self.agent_ip, self.agent_port)\n                sys.exit()\n            elif response.status_code == 504:\n                logger.error(\"Verifier at %s with Port %s timed out.\", self.verifier_ip, self.verifier_port)\n                sys.exit()\n\n            if response.status_code != 200:\n                keylime_logging.log_http_response(\n                    logger, logging.ERROR, response_body)\n                raise UserError(\n                    \"Posting of Encrypted U to the Cloud Agent failed with response code %d (%s)\" % (response.status_code, response.text))\n        except Exception as e:\n            self.do_cvstop()\n            raise e\n\n    def do_verify(self):\n        \"\"\" Perform verify using a random generated challenge\n        \"\"\"\n        challenge = TPM_Utilities.random_password(20)\n        numtries = 0\n        while True:\n            try:\n                cloudagent_base_url = (\n                    f'{self.agent_ip}:{self.agent_port}'\n                )\n\n\n                if self.registrar_data['mtls_cert']:\n                    with RequestsClient(cloudagent_base_url, tls_enabled=True, ignore_hostname=True,\n                                        cert=self.agent_cert, verify_custom=self.registrar_data['mtls_cert']) as do_verify:\n                        response = do_verify.get(f'/v{self.supported_version}/keys/verify?challenge={challenge}')\n                else:\n                    logger.warning(\"Connecting to agent without using mTLS!\")\n                    do_verify = RequestsClient(cloudagent_base_url, tls_enabled=False)\n                    response = do_verify.get(f'/v{self.supported_version}/keys/verify?challenge={challenge}')\n\n            except Exception as e:\n                if response.status_code in (503, 504):\n                    numtries += 1\n                    maxr = config.getint('tenant', 'max_retries')\n                    if numtries >= maxr:\n                        logger.error(\"Cannot establish connection to agent on %s with port %s\", self.agent_ip, self.agent_port)\n                        sys.exit()\n                    retry = config.getfloat('tenant', 'retry_interval')\n                    logger.info(\"Verifier connection to agent at %s refused %s/%s times, trying again in %s seconds...\",\n                        self.agent_ip, numtries, maxr, retry)\n                    time.sleep(retry)\n                    continue\n\n                raise e\n            response_body = response.json()\n            if response.status_code == 200:\n                if \"results\" not in response_body or 'hmac' not in response_body['results']:\n                    logger.critical(\"Error: unexpected http response body from Cloud Agent: %s\", response.status_code)\n                    break\n                mac = response_body['results']['hmac']\n\n                ex_mac = crypto.do_hmac(self.K, challenge)\n\n                if mac == ex_mac:\n                    logger.info(\"Key derivation successful\")\n                else:\n                    logger.error(\"Key derivation failed\")\n            else:\n                keylime_logging.log_http_response(\n                    logger, logging.ERROR, response_body)\n                retry = config.getfloat('tenant', 'retry_interval')\n                logger.warning(\"Key derivation not yet complete...trying again in %s seconds...Ctrl-C to stop\", retry)\n                time.sleep(retry)\n                continue\n            break\n\n    def do_add_allowlist(self, args):\n        if 'allowlist_name' not in args or not args['allowlist_name']:\n            raise UserError('allowlist_name is required to add an allowlist')\n\n        allowlist_name = args['allowlist_name']\n        self.process_allowlist(args)\n        data = {\n            'tpm_policy': json.dumps(self.tpm_policy),\n            'vtpm_policy': json.dumps(self.vtpm_policy),\n            'allowlist': json.dumps(self.allowlist)\n        }\n        body = json.dumps(data)\n        cv_client = RequestsClient(self.verifier_base_url, self.tls_enabled)\n        response = cv_client.post(f'/v{self.api_version}/allowlists/{allowlist_name}', data=body,\n                                  cert=self.cert, verify=False)\n        print(response.json())\n\n    def do_delete_allowlist(self, name):\n        cv_client = RequestsClient(self.verifier_base_url, self.tls_enabled)\n        response = cv_client.delete(f'/v{self.api_version}/allowlists/{name}',\n                                    cert=self.cert, verify=False)\n        print(response.json())\n\n    def do_show_allowlist(self, name):\n        cv_client = RequestsClient(self.verifier_base_url, self.tls_enabled)\n        response = cv_client.get(f'/v{self.api_version}/allowlists/{name}',\n                                 cert=self.cert, verify=False)\n        print(f\"Show allowlist command response: {response.status_code}.\")\n        print(response.json())\n\n\ndef write_to_namedtempfile(data, delete_tmp_files):\n    temp = tempfile.NamedTemporaryFile(prefix=\"keylime-\", delete=delete_tmp_files)\n    temp.write(data)\n    temp.flush()\n    return temp.name\n\ndef main(argv=sys.argv):\n    \"\"\"[summary]\n\n    Keyword Arguments:\n        argv {[type]} -- [description] (default: {sys.argv})\n\n    Raises:\n        UserError: [description]\n        UserError: [description]\n        UserError: [description]\n    \"\"\"\n    parser = argparse.ArgumentParser(argv[0])\n    parser.add_argument('-c', '--command', action='store', dest='command', default='add',\n                        help=\"valid commands are add,delete,update,\"\n                             \"regstatus,cvstatus,status,reglist,cvlist,reactivate,\"\n                             \"regdelete,\"\n                             \"bulkinfo. defaults to add\")\n    parser.add_argument('-t', '--targethost', action='store',\n                        dest='agent_ip', help=\"the IP address of the host to provision\")\n    parser.add_argument('-tp', '--targetport', action='store',\n                        dest='agent_port', help=\"the Port of the host to provision\")\n    parser.add_argument('-r', '--registrarhost', action='store',\n                        dest='registrar_ip', help=\"the IP address of the registrar where to retrieve the agents data from.\")\n    parser.add_argument('-rp', '--registrarport', action=\"store\",\n                        dest='registrar_port', help=\"the port of the registrar.\")\n    parser.add_argument('--cv_targethost', action='store', default=None, dest='cv_agent_ip',\n                        help='the IP address of the host to provision that the verifier will use (optional).  Use only if different than argument to option -t/--targethost')\n    parser.add_argument('-v', '--cv', action='store', dest='verifier_ip',\n                        help=\"the IP address of the cloud verifier\")\n    parser.add_argument('-vp', '--cvport', action='store', dest='verifier_port',\n                        help=\"the port of the cloud verifier\")\n    parser.add_argument('-vi', '--cvid', action='store', dest='verifier_id',\n                        help=\"the unique identifier of a cloud verifier\")\n    parser.add_argument('-nvc', '--no-verifier-check', action='store_false', dest='verifier_check', default=True,\n                        help='Disable the check to confirm if the agent is being processed by the specified verifier. Use only with -c/--command delete or reactivate')\n    parser.add_argument('-u', '--uuid', action='store',\n                        dest='agent_uuid', help=\"UUID for the agent to provision\")\n    parser.add_argument('-f', '--file', action='store', default=None,\n                        help='Deliver the specified plaintext to the provisioned agent')\n    parser.add_argument('--cert', action='store', dest='ca_dir', default=None,\n                        help='Create and deliver a certificate using a CA created by ca-util. Pass in the CA directory or use \"default\" to use the standard dir')\n    parser.add_argument('-k', '--key', action='store', dest='keyfile',\n                        help='an intermedia key file produced by user_data_encrypt')\n    parser.add_argument('-p', '--payload', action='store', default=None,\n                        help='Specify the encrypted payload to deliver with encrypted keys specified by -k')\n    parser.add_argument('--include', action='store', dest='incl_dir', default=None,\n                        help=\"Include additional files in provided directory in certificate zip file.  Must be specified with --cert\")\n    parser.add_argument('--allowlist', action='store', dest='allowlist',\n                        default=None, help=\"Specify the file path of an allowlist\")\n    parser.add_argument('--signature-verification-key', '--sign_verification_key', action='append', dest='ima_sign_verification_keys',\n                        default=[], help=\"Specify an IMA file signature verification key\")\n    parser.add_argument('--signature-verification-key-sig', action='append', dest='ima_sign_verification_key_sigs',\n                        default=[], help=\"Specify the GPG signature file for an IMA file signature verification key; pair this option with --signature-verification-key\")\n    parser.add_argument('--signature-verification-key-sig-key', action='append', dest='ima_sign_verification_key_sig_keys',\n                        default=[], help=\"Specify the GPG public key file use to validate the --signature-verification-key-sig; pair this option with --signature-verification-key\")\n    parser.add_argument('--signature-verification-key-url', action='append', dest='ima_sign_verification_key_urls',\n                        default=[], help=\"Specify the URL for a remote IMA file signature verification key\")\n    parser.add_argument('--signature-verification-key-sig-url', action='append',\n                        dest='ima_sign_verification_key_sig_urls',\n                        default=[], help=\"Specify the URL for the remote GPG signature of a remote IMA file signature verification key; pair this option with --signature-verification-key-url\")\n    parser.add_argument('--signature-verification-key-sig-url-key', action='append',\n                        dest='ima_sign_verification_key_sig_url_keys',\n                        default=[], help=\"Specify the GPG public key file used to validate the --signature-verification-key-sig-url; pair this option with --signature-verification-key-url\")\n    parser.add_argument('--mb_refstate', action='store', dest='mb_refstate',\n                        default=None, help=\"Specify the location of a measure boot reference state (intended state)\")\n    parser.add_argument('--allowlist-checksum', action='store', dest='allowlist_checksum',\n                        default=None, help=\"Specify the SHA2 checksum of an allowlist\")\n    parser.add_argument('--allowlist-sig', action='store', dest='allowlist_sig',\n                        default=None, help=\"Specify the GPG signature file of an allowlist\")\n    parser.add_argument('--allowlist-sig-key', action='store', dest='allowlist_sig_key',\n                        default=None, help=\"Specify the GPG public key file used to validate the --allowlist-sig or --allowlist-sig-url\")\n    parser.add_argument('--allowlist-url', action='store', dest='allowlist_url',\n                        default=None, help=\"Specify the URL of a remote allowlist\")\n    parser.add_argument('--allowlist-sig-url', action='store', dest='allowlist_sig_url',\n                        default=None, help=\"Specify the URL of the remote GPG signature file of an allowlist\")\n    parser.add_argument('--exclude', action='store', dest='ima_exclude',\n                        default=None, help=\"Specify the location of an IMA exclude list\")\n    parser.add_argument('--tpm_policy', action='store', dest='tpm_policy', default=None,\n                        help=\"Specify a TPM policy in JSON format. e.g., {\\\"15\\\":\\\"0000000000000000000000000000000000000000\\\"}\")\n    parser.add_argument('--vtpm_policy', action='store', dest='vtpm_policy',\n                        default=None, help=\"Specify a vTPM policy in JSON format\")\n    parser.add_argument('--verify', action='store_true', default=False,\n                        help='Block on cryptographically checked key derivation confirmation from the agent once it has been provisioned')\n    parser.add_argument('--allowlist-name', help='The name of allowlist to operate with')\n    parser.add_argument('--supported-version', default=None, action=\"store\", dest='supported_version', help='API version that is supported by the agent. Detected automatically by default')\n\n    args = parser.parse_args(argv[1:])\n\n    # Make sure argument dependencies are enforced\n    if( args.allowlist and args.allowlist_url):\n        parser.error(\"--allowlist and --allowlist-url cannot be specified at the same time\")\n    if( args.allowlist_url and not (args.allowlist_sig or args.allowlist_sig_url or args.allowlist_checksum)):\n        parser.error(\"--allowlist-url must have either --allowlist-sig, --allowlist-sig-url or --allowlist-checksum to verifier integrity\")\n    if( args.allowlist_sig and not (args.allowlist_url or args.allowlist)):\n        parser.error(\"--allowlist-sig must have either --allowlist or --allowlist-url\")\n    if( args.allowlist_sig_url and not (args.allowlist_url or args.allowlist)):\n        parser.error(\"--allowlist-sig-url must have either --allowlist or --allowlist-url\")\n    if( args.allowlist_checksum and not (args.allowlist_url or args.allowlist)):\n        parser.error(\"--allowlist-checksum must have either --allowlist or --allowlist-url\")\n    if( args.allowlist_sig and not args.allowlist_sig_key):\n        parser.error(\"--allowlist-sig must also have --allowlist-sig-key\")\n    if( args.allowlist_sig_url and not args.allowlist_sig_key):\n        parser.error(\"--allowlist-sig-url must also have --allowlist-sig-key\")\n    if( args.allowlist_sig_key and not (args.allowlist_sig or args.allowlist_sig_url)):\n        parser.error(\"--allowlist-sig-key must have either --allowlist-sig or --allowlist-sig-url\")\n\n    mytenant = Tenant()\n\n    if args.agent_uuid is not None:\n        mytenant.agent_uuid = args.agent_uuid\n        # if the uuid is actually a public key, then hash it\n        if mytenant.agent_uuid.startswith('-----BEGIN PUBLIC KEY-----'):\n            mytenant.agent_uuid = hashlib.sha256(\n                mytenant.agent_uuid).hexdigest()\n    else:\n        logger.warning(\"Using default UUID d432fbb3-d2f1-4a97-9ef7-75bd81c00000\")\n        mytenant.agent_uuid = \"d432fbb3-d2f1-4a97-9ef7-75bd81c00000\"\n\n    if config.STUB_VTPM and config.TPM_CANNED_VALUES is not None:\n        # Use canned values for agent UUID\n        jsonIn = config.TPM_CANNED_VALUES\n        if \"add_vtpm_to_group\" in jsonIn:\n            mytenant.agent_uuid = jsonIn['add_vtpm_to_group']['retout']\n        else:\n            # Our command hasn't been canned!\n            raise UserError(\"Command %s not found in canned JSON!\" %\n                            (\"add_vtpm_to_group\"))\n\n    if args.verifier_id is not None:\n        mytenant.verifier_id = args.verifier_id\n    if args.verifier_ip is not None:\n        mytenant.verifier_ip = args.verifier_ip\n    if args.verifier_port is not None:\n        mytenant.verifier_port = args.verifier_port\n\n    if args.registrar_ip is not None:\n        mytenant.registrar_ip = args.registrar_ip\n    if args.registrar_port is not None:\n        mytenant.registrar_port = args.registrar_port\n\n    # we only need to fetch remote files if we are adding or updating\n    if args.command in ['add', 'update']:\n        delete_tmp_files = logger.level > logging.DEBUG # delete tmp files unless in DEBUG mode\n\n        if args.allowlist_url:\n            logger.info(\"Downloading Allowlist from %s\", args.allowlist_url)\n            response = requests.get(args.allowlist_url, allow_redirects=False)\n            if response.status_code == 200:\n                args.allowlist = write_to_namedtempfile(response.content, delete_tmp_files)\n                logger.debug(\"Allowlist temporarily saved in %s\" % args.allowlist)\n            else:\n                raise Exception(f\"Downloading allowlist ({args.allowlist_url}) failed with status code {response.status_code}!\")\n\n        if args.allowlist_sig_url:\n            logger.info(\"Downloading Allowlist signature from %s\", args.allowlist_sig_url)\n            response = requests.get(args.allowlist_sig_url, allow_redirects=False)\n            if response.status_code == 200:\n                args.allowlist_sig = write_to_namedtempfile(response.content, delete_tmp_files)\n                logger.debug(\"Allowlist signature temporarily saved in %s\", args.allowlist_sig)\n            else:\n                raise Exception(f\"Downloading allowlist signature ({args.allowlist_sig_url}) failed with status code {response.status_code}!\")\n\n        # verify all the local keys for which we have a signature file and a key to verify\n        for i, key_file in enumerate(args.ima_sign_verification_keys):\n            if len(args.ima_sign_verification_key_sigs) <= i:\n                break\n            keysig_file = args.ima_sign_verification_key_sigs[i]\n            if len(args.ima_sign_verification_key_sig_keys) == 0:\n                raise UserError(\"A gpg key is missing for key signature file '%s'\" % keysig_file)\n\n            gpg_key_file = args.ima_sign_verification_key_sig_keys[i]\n            gpg.gpg_verify_filesignature(gpg_key_file, key_file, keysig_file, \"IMA file signing key\")\n\n            logger.info(\"Signature verification on %s was successful\" % key_file)\n\n        # verify all the remote keys for which we have a signature URL and key to to verify\n        # Append the downloaded key files to args.ima_sign_verification_keys\n        for i, key_url in enumerate(args.ima_sign_verification_key_urls):\n\n            logger.info(\"Downloading key from %s\", key_url)\n            response = requests.get(key_url, allow_redirects=False)\n            if response.status_code == 200:\n                key_file = write_to_namedtempfile(response.content, delete_tmp_files)\n                args.ima_sign_verification_keys.append(key_file)\n                logger.debug(\"Key temporarily saved in %s\" % key_file)\n            else:\n                raise Exception(f\"Downloading key ({key_url}) failed with status code {response.status_code}!\")\n\n            if len(args.ima_sign_verification_key_sig_urls) <= i:\n                continue\n\n            keysig_url = args.ima_sign_verification_key_sig_urls[i]\n\n            if len(args.ima_sign_verification_key_sig_url_keys) == 0:\n                raise UserError(\"A gpg key is missing for key signature URL '%s'\" % keysig_url)\n\n            logger.info(\"Downloading key signature from %s\" % keysig_url)\n            response = requests.get(keysig_url, allow_redirects=False)\n            if response.status_code == 200:\n                keysig_file = write_to_namedtempfile(response.content, delete_tmp_files)\n                logger.debug(\"Key signature temporarily saved in %s\" % keysig_file)\n            else:\n                raise Exception(f\"Downloading key signature ({key_url}) failed with status code {response.status_code}!\")\n\n            gpg_key_file = args.ima_sign_verification_key_sig_url_keys[i]\n            gpg.gpg_verify_filesignature(gpg_key_file, key_file, keysig_file, \"IMA file signing key\")\n            logger.info(\"Signature verification on %s was successful\" % key_url)\n\n    if args.command == 'add':\n        mytenant.init_add(vars(args))\n        mytenant.preloop()\n        mytenant.do_cv()\n        mytenant.do_quote()\n        if args.verify:\n            mytenant.do_verify()\n    elif args.command == 'update':\n        mytenant.init_add(vars(args))\n        mytenant.do_cvdelete(args.verifier_check)\n        mytenant.preloop()\n        mytenant.do_cv()\n        mytenant.do_quote()\n        if args.verify:\n            mytenant.do_verify()\n    elif args.command == 'delete':\n        mytenant.do_cvdelete(args.verifier_check)\n    elif args.command == 'status':\n        mytenant.do_status()\n    elif args.command == 'cvstatus':\n        mytenant.do_cvstatus()\n    elif args.command == 'bulkinfo':\n        mytenant.do_cvbulkinfo()\n    elif args.command == 'cvlist':\n        mytenant.do_cvlist()\n    elif args.command == 'reactivate':\n        mytenant.do_cvreactivate(args.verifier_check)\n    elif args.command == 'regstatus':\n        mytenant.do_regstatus()\n    elif args.command == 'reglist':\n        mytenant.do_reglist()\n    elif args.command == 'regdelete':\n        mytenant.do_regdelete()\n    elif args.command == 'addallowlist':\n        mytenant.do_add_allowlist(vars(args))\n    elif args.command == 'showallowlist':\n        mytenant.do_show_allowlist(args.allowlist_name)\n    elif args.command == 'deleteallowlist':\n        mytenant.do_delete_allowlist(args.allowlist_name)\n    else:\n        raise UserError(\"Invalid command specified: %s\" % (args.command))\n", "'''\nSPDX-License-Identifier: Apache-2.0\nCopyright 2017 Massachusetts Institute of Technology.\n'''\nimport codecs\nfrom abc import ABCMeta, abstractmethod\nimport os\nimport string\nimport typing\n\nimport yaml\ntry:\n    from yaml import CSafeLoader as SafeLoader, CSafeDumper as SafeDumper\nexcept ImportError:\n    from yaml import SafeLoader, SafeDumper\n\nfrom keylime import config\nfrom keylime import json\nfrom keylime import keylime_logging\nfrom keylime import crypto\nfrom keylime import ima\nfrom keylime import measured_boot\nfrom keylime.common import algorithms\nfrom keylime.failure import Failure, Component\n\nlogger = keylime_logging.init_logging('tpm')\n\n\nclass TPM_Utilities:\n\n    @staticmethod\n    def check_mask(mask, pcr):\n        if mask is None:\n            return False\n        return bool(1 << pcr & int(mask, 0))\n\n    @staticmethod\n    def random_password(length=20):\n        rand = crypto.generate_random_key(length)\n        chars = string.ascii_uppercase + string.digits + string.ascii_lowercase\n        password = ''\n        for i in range(length):\n            password += chars[(rand[i]) % len(chars)]\n        return password\n\n    @staticmethod\n    def readPolicy(configval):\n        policy = json.loads(configval)\n\n        # compute PCR mask from tpm_policy\n        mask = 0\n        for key in list(policy.keys()):\n            if not key.isdigit() or int(key) > 24:\n                raise Exception(\"Invalid tpm policy pcr number: %s\" % (key))\n\n            if int(key) == config.TPM_DATA_PCR:\n                raise Exception(\"Invalid allowlist PCR number %s, keylime uses this PCR to bind data.\" % key)\n            if int(key) == config.IMA_PCR:\n                raise Exception(\"Invalid allowlist PCR number %s, this PCR is used for IMA.\" % key)\n\n            mask = mask | (1 << int(key))\n\n            # wrap it in a list if it is a singleton\n            if isinstance(policy[key], str):\n                policy[key] = [policy[key]]\n\n            # convert all hash values to lowercase\n            policy[key] = [x.lower() for x in policy[key]]\n\n        policy['mask'] = \"0x%X\" % (mask)\n        return policy\n\n\nclass AbstractTPM(metaclass=ABCMeta):\n    # Abstract base class\n    EXIT_SUCESS = 0\n    TPM_IO_ERR = 5\n    EMPTYMASK = \"1\"\n    MAX_NONCE_SIZE = 64\n\n    # constructor\n    def __init__(self, need_hw_tpm=True):\n        # read the config file\n        self.need_hw_tpm = need_hw_tpm\n        self.global_tpmdata = None\n        self.tpmrand_warned = False\n        self.defaults = {}\n        self.defaults['hash'] = algorithms.Hash.SHA1\n        self.defaults['encrypt'] = algorithms.Encrypt.RSA\n        self.defaults['sign'] = algorithms.Sign.RSASSA\n        self.supported = {}\n\n    # tpm_initialize\n    @abstractmethod\n    def flush_keys(self):\n        pass\n\n    @abstractmethod\n    def encryptAIK(self, uuid, ek_tpm: bytes, aik_tpm: bytes):\n        pass\n\n    @abstractmethod\n    def activate_identity(self, keyblob):\n        pass\n\n    @abstractmethod\n    def verify_ek(self, ekcert):\n        pass\n\n    @abstractmethod\n    def get_tpm_manufacturer(self):\n        pass\n\n    @abstractmethod\n    def is_emulator(self):\n        pass\n\n    @abstractmethod\n    def is_vtpm(self):\n        pass\n\n    def warn_emulator(self):\n        if self.is_emulator():\n            logger.warning(\"INSECURE: Keylime is using a software TPM emulator rather than a real hardware TPM.\")\n            logger.warning(\"INSECURE: The security of Keylime is NOT linked to a hardware root of trust.\")\n            logger.warning(\"INSECURE: Only use Keylime in this mode for testing or debugging purposes.\")\n\n    def __read_tpm_data(self):\n        if os.path.exists('tpmdata.yml'):\n            with open('tpmdata.yml', 'rb') as f:\n                return yaml.load(f, Loader=SafeLoader)\n        else:\n            return {}\n\n    def __write_tpm_data(self):\n        os.umask(0o077)\n        if os.geteuid() != 0 and config.REQUIRE_ROOT:\n            logger.warning(\"Creating tpm metadata file without root. Sensitive trust roots may be at risk!\")\n        with open('tpmdata.yml', 'w', encoding=\"utf-8\") as f:\n            yaml.dump(self.global_tpmdata, f, Dumper=SafeDumper)\n\n    def get_tpm_metadata(self, key):\n        if self.global_tpmdata is None:\n            self.global_tpmdata = self.__read_tpm_data()\n        return self.global_tpmdata.get(key, None)\n\n    def _set_tpm_metadata(self, key, value):\n        if self.global_tpmdata is None:\n            self.global_tpmdata = self.__read_tpm_data()\n\n        if self.global_tpmdata.get(key, None) is not value:\n            self.global_tpmdata[key] = value\n            self.__write_tpm_data()\n\n    @abstractmethod\n    def tpm_init(self, self_activate=False, config_pw=None):\n        pass\n\n    # tpm_quote\n    @abstractmethod\n    def create_quote(self, nonce, data=None, pcrmask=EMPTYMASK, hash_alg=None, compress=False):\n        pass\n\n    @abstractmethod\n    def check_quote(self, agentAttestState, nonce, data, quote, aikTpmFromRegistrar, tpm_policy={}, ima_measurement_list=None, allowlist={}, hash_alg=None, ima_keyrings=None, mb_measurement_list=None, mb_refstate=None, compressed=False):\n        pass\n\n    def START_HASH(self, algorithm=None):\n        if algorithm is None:\n            algorithm = self.defaults['hash']\n\n        alg_size = algorithm.get_size() // 4\n        return \"0\" * alg_size\n\n    def hashdigest(self, payload, algorithm=None):\n        if algorithm is None:\n            algorithm = self.defaults['hash']\n\n        digest = algorithm.hash(payload)\n        if digest is None:\n            return None\n        return codecs.encode(digest, 'hex').decode('utf-8')\n\n    @abstractmethod\n    def sim_extend(self, hashval_1, hashval_0=None, hash_alg=None):\n        pass\n\n    @abstractmethod\n    def extendPCR(self, pcrval, hashval, hash_alg=None, lock=True):\n        pass\n\n    @abstractmethod\n    def readPCR(self, pcrval, hash_alg=None):\n        pass\n\n    @abstractmethod\n    def _get_tpm_rand_block(self, size=4096):\n        pass\n\n    def __check_ima(self, agentAttestState, pcrval, ima_measurement_list, allowlist,\n                    ima_keyrings, boot_aggregates, hash_alg):\n        failure = Failure(Component.IMA)\n        logger.info(\"Checking IMA measurement list on agent: %s\", agentAttestState.get_agent_id())\n        if config.STUB_IMA:\n            pcrval = None\n\n        _, ima_failure = ima.process_measurement_list(agentAttestState, ima_measurement_list.split('\\n'), allowlist,\n                                                      pcrval=pcrval, ima_keyrings=ima_keyrings,\n                                                      boot_aggregates=boot_aggregates, hash_alg=hash_alg)\n        failure.merge(ima_failure)\n        if not failure:\n            logger.debug(\"IMA measurement list of agent %s validated\", agentAttestState.get_agent_id())\n        return failure\n\n    def __parse_pcrs(self, pcrs, virtual) -> typing.Dict[int, str]:\n        \"\"\"Parses and validates the format of a list of PCR data\"\"\"\n        output = {}\n        for line in pcrs:\n            tokens = line.split()\n            if len(tokens) != 3:\n                logger.error(\"Invalid %sPCR in quote: %s\", (\"\", \"v\")[virtual], pcrs)\n                continue\n            try:\n                pcr_num = int(tokens[1])\n            except ValueError:\n                logger.error(\"Invalid PCR number %s\", tokens[1])\n                continue\n            output[pcr_num] = tokens[2].lower()\n\n        return output\n\n    def check_pcrs(self, agentAttestState, tpm_policy, pcrs, data, virtual, ima_measurement_list,\n                   allowlist, ima_keyrings, mb_measurement_list, mb_refstate_str, hash_alg) -> Failure:\n        failure = Failure(Component.PCR_VALIDATION)\n        if isinstance(tpm_policy, str):\n            tpm_policy = json.loads(tpm_policy)\n\n        pcr_allowlist = tpm_policy.copy()\n\n        if 'mask' in pcr_allowlist:\n            del pcr_allowlist['mask']\n        # convert all pcr num keys to integers\n        pcr_allowlist = {int(k): v for k, v in list(pcr_allowlist.items())}\n\n        mb_policy, mb_refstate_data = measured_boot.get_policy(mb_refstate_str)\n        mb_pcrs_hashes, boot_aggregates, mb_measurement_data, mb_failure = self.parse_mb_bootlog(mb_measurement_list, hash_alg)\n        failure.merge(mb_failure)\n\n        pcrs_in_quote = set()  # PCRs in quote that were already used for some kind of validation\n\n        pcrs = self.__parse_pcrs(pcrs, virtual)\n        pcr_nums = set(pcrs.keys())\n\n        # Skip validation if TPM is stubbed.\n        if config.STUB_TPM:\n            return failure\n\n        # Validate data PCR\n        if config.TPM_DATA_PCR in pcr_nums and data is not None:\n            expectedval = self.sim_extend(data, hash_alg=hash_alg)\n            if expectedval != pcrs[config.TPM_DATA_PCR]:\n                logger.error(\n                    \"%sPCR #%s: invalid bind data %s from quote does not match expected value %s\",\n                    (\"\", \"v\")[virtual], config.TPM_DATA_PCR, pcrs[config.TPM_DATA_PCR], expectedval)\n                failure.add_event(f\"invalid_pcr_{config.TPM_DATA_PCR}\", {\"got\": pcrs[config.TPM_DATA_PCR], \"expected\": expectedval}, True)\n            pcrs_in_quote.add(config.TPM_DATA_PCR)\n        else:\n            logger.error(\"Binding %sPCR #%s was not included in the quote, but is required\", (\"\", \"v\")[virtual],\n                         config.TPM_DATA_PCR)\n            failure.add_event(f\"missing_pcr_{config.TPM_DATA_PCR}\", f\"Data PCR {config.TPM_DATA_PCR} is missing in quote, but is required\", True)\n        # Check for ima PCR\n        if config.IMA_PCR in pcr_nums:\n            if ima_measurement_list is None:\n                logger.error(\"IMA PCR in policy, but no measurement list provided\")\n                failure.add_event(f\"unused_pcr_{config.IMA_PCR}\", \"IMA PCR in policy, but no measurement list provided\", True)\n            else:\n                ima_failure = self.__check_ima(agentAttestState, pcrs[config.IMA_PCR], ima_measurement_list, allowlist,\n                                               ima_keyrings, boot_aggregates, hash_alg)\n                failure.merge(ima_failure)\n\n            pcrs_in_quote.add(config.IMA_PCR)\n\n        # Collect mismatched measured boot PCRs as measured_boot failures\n        mb_pcr_failure = Failure(Component.MEASURED_BOOT)\n        # Handle measured boot PCRs only if the parsing worked\n        if not mb_failure:\n            for pcr_num in set(config.MEASUREDBOOT_PCRS) & pcr_nums:\n                if mb_refstate_data:\n                    if not mb_measurement_list:\n                        logger.error(\"Measured Boot PCR %d in policy, but no measurement list provided\", pcr_num)\n                        failure.add_event(f\"unused_pcr_{pcr_num}\",\n                                          f\"Measured Boot PCR {pcr_num} in policy, but no measurement list provided\", True)\n                        continue\n\n                    val_from_log_int = mb_pcrs_hashes.get(str(pcr_num), 0)\n                    val_from_log_hex = hex(val_from_log_int)[2:]\n                    val_from_log_hex_stripped = val_from_log_hex.lstrip('0')\n                    pcrval_stripped = pcrs[pcr_num].lstrip('0')\n                    if val_from_log_hex_stripped != pcrval_stripped:\n                        logger.error(\n                            \"For PCR %d and hash %s the boot event log has value %r but the agent returned %r\",\n                            str(hash_alg), pcr_num, val_from_log_hex, pcrs[pcr_num])\n                        mb_pcr_failure.add_event(f\"invalid_pcr_{pcr_num}\",\n                                                 {\"context\": \"SHA256 boot event log PCR value does not match\",\n                                                  \"got\": pcrs[pcr_num], \"expected\": val_from_log_hex}, True)\n\n                    if pcr_num in pcr_allowlist and pcrs[pcr_num] not in pcr_allowlist[pcr_num]:\n                        logger.error(\n                            \"%sPCR #%s: %s from quote does not match expected value %s\",\n                            (\"\", \"v\")[virtual], pcr_num, pcrs[pcr_num], pcr_allowlist[pcr_num])\n                        failure.add_event(f\"invalid_pcr_{pcr_num}\",\n                                          {\"context\": \"PCR value is not in allowlist\",\n                                           \"got\": pcrs[pcr_num], \"expected\": pcr_allowlist[pcr_num]}, True)\n                    pcrs_in_quote.add(pcr_num)\n        failure.merge(mb_pcr_failure)\n\n        # Check the remaining non validated PCRs\n        for pcr_num in pcr_nums - pcrs_in_quote:\n            if pcr_num not in list(pcr_allowlist.keys()):\n                logger.warning(\"%sPCR #%s in quote not found in %stpm_policy, skipping.\",\n                               (\"\", \"v\")[virtual], pcr_num, (\"\", \"v\")[virtual])\n                continue\n            if pcrs[pcr_num] not in pcr_allowlist[pcr_num]:\n                logger.error(\"%sPCR #%s: %s from quote does not match expected value %s\",\n                             (\"\", \"v\")[virtual], pcr_num, pcrs[pcr_num], pcr_allowlist[pcr_num])\n                failure.add_event(f\"invalid_pcr_{pcr_num}\",\n                                  {\"context\": \"PCR value is not in allowlist\",\n                                   \"got\": pcrs[pcr_num], \"expected\": pcr_allowlist[pcr_num]}, True)\n\n            pcrs_in_quote.add(pcr_num)\n\n        missing = set(pcr_allowlist.keys()) - pcrs_in_quote\n        if len(missing) > 0:\n            logger.error(\"%sPCRs specified in policy not in quote: %s\", (\"\", \"v\")[virtual], missing)\n            failure.add_event(\"missing_pcrs\", {\"context\": \"PCRs are missing in quote\", \"data\": missing}, True)\n\n        if not mb_failure and mb_refstate_data:\n            mb_policy_failure = measured_boot.evaluate_policy(mb_policy, mb_refstate_data, mb_measurement_data,\n                                                    pcrs_in_quote, (\"\", \"v\")[virtual], agentAttestState.get_agent_id())\n            failure.merge(mb_policy_failure)\n\n        return failure\n\n    # tpm_nvram\n    @abstractmethod\n    def write_key_nvram(self, key):\n        pass\n\n    @abstractmethod\n    def read_key_nvram(self):\n        pass\n\n    @abstractmethod\n    def parse_mb_bootlog(self, mb_measurement_list: str, hash_alg: algorithms.Hash) -> dict:\n        raise NotImplementedError\n", "'''\nSPDX-License-Identifier: Apache-2.0\nCopyright 2017 Massachusetts Institute of Technology.\n'''\n\nimport base64\nimport binascii\nimport hashlib\nimport os\nimport re\nimport sys\nimport tempfile\nimport threading\nimport time\nimport typing\nimport zlib\nimport codecs\nfrom distutils.version import StrictVersion\n\nfrom cryptography import exceptions as crypto_exceptions\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives import serialization as crypto_serialization\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography import x509\n\nfrom keylime import cmd_exec\nfrom keylime import config\nfrom keylime import json\nfrom keylime import keylime_logging\nfrom keylime import secure_mount\nfrom keylime.tpm import tpm_abstract\nfrom keylime import tpm_ek_ca\nfrom keylime.common import algorithms\nfrom keylime.tpm import tpm2_objects\nfrom keylime.failure import Failure, Component\n\nlogger = keylime_logging.init_logging('tpm')\n\n\ndef _get_cmd_env():\n    env = os.environ.copy()\n    if 'TPM2TOOLS_TCTI' not in env:\n        # Don't clobber existing setting (if present)\n        env['TPM2TOOLS_TCTI'] = 'device:/dev/tpmrm0'\n        # env['TPM2TOOLS_TCTI'] = 'tabrmd:bus_name=com.intel.tss2.Tabrmd'\n        # Other (not recommended) options are direct emulator and chardev communications:\n        # env['TPM2TOOLS_TCTI'] = 'mssim:port=2321'\n        # env['TPM2TOOLS_TCTI'] = 'device:/dev/tpm0'\n    return env\n\n\ndef _stub_command(fprt, lock, cmd, outputpaths):\n    # cmd is an iteratable now, change cmd to string to match old logic below\n    cmd = ' '.join(cmd)\n    # Use canned values for stubbing\n    jsonIn = config.TPM_CANNED_VALUES\n    if fprt in jsonIn:\n        # The value we're looking for has been canned!\n        thisTiming = jsonIn[fprt]['timing']\n        thisRetout = jsonIn[fprt]['retout']\n        thisCode = jsonIn[fprt]['code']\n        thisFileout = jsonIn[fprt]['fileout']\n        fileoutEncoded = {}\n\n        # Decode files that are supplied (and requested)\n        if outputpaths is not None and len(outputpaths) > 0:\n            if len(thisFileout) == 1 and len(outputpaths) == 1:\n                # fileoutEncoded[outputpaths[0]] = base64.b64decode(next(iter(thisFileout.values()))).decode(\"zlib\")\n                fileoutEncoded[outputpaths[0]] = zlib.decompress(base64.b64decode(next(iter(thisFileout.values()))))\n            elif fprt == \"tpm2_deluxequote\":\n                # quotes need 3 outputs, so we need a consistent way to match them back up when reading\n                quote_msg = \"\"\n                match = re.search(r\"-m ([^\\s]+)\", cmd)\n                if match:\n                    quote_msg = match.group(1)\n                    if \"file://quoteMessage\" in thisFileout:\n                        # fileoutEncoded[quote_msg] = base64.b64decode(thisFileout[\"file://quoteMessage\"]).decode(\"zlib\")\n                        fileoutEncoded[quote_msg] = zlib.decompress(\n                            base64.b64decode(thisFileout[\"file://quoteMessage\"]))\n                quote_sig = \"\"\n                match = re.search(r\"-s ([^\\s]+)\", cmd)\n                if match:\n                    quote_sig = match.group(1)\n                    if \"file://quoteSignature\" in thisFileout:\n                        # fileoutEncoded[quote_sig] = base64.b64decode(thisFileout[\"file://quoteSignature\"]).decode(\"zlib\")\n                        fileoutEncoded[quote_sig] = zlib.decompress(\n                            base64.b64decode(thisFileout[\"file://quoteSignature\"]))\n                quote_pcr = \"\"\n                match = re.search(r\"-p ([^\\s]+)\", cmd)\n                if match:\n                    quote_pcr = match.group(1)\n                    if \"file://quotePCR\" in thisFileout:\n                        # fileoutEncoded[quote_pcr] = base64.b64decode(thisFileout[\"file://quotePCR\"]).decode(\"zlib\")\n                        fileoutEncoded[quote_pcr] = zlib.decompress(\n                            base64.b64decode(thisFileout[\"file://quotePCR\"]))\n            else:\n                raise Exception(\"Command %s is using multiple files unexpectedly!\" % fprt)\n\n        logger.debug(\"TPM call '%s' was stubbed out, with a simulated delay of %f sec\" % (fprt, thisTiming))\n        time.sleep(thisTiming)\n\n        # Package for return\n        returnDict = {\n            'retout': thisRetout,\n            'reterr': [],\n            'code': thisCode,\n            'fileouts': fileoutEncoded,\n            'timing': thisTiming,\n        }\n        return returnDict\n    if not lock:\n        # non-lock calls don't go to the TPM (just let it pass through)\n        return None\n\n    # Our command hasn't been canned!\n    raise Exception(\"Command %s not found in canned YAML!\" % fprt)\n\n\ndef _output_metrics(fprt, cmd, cmd_ret, outputpaths):\n    # cmd is an iteratable now, change cmd to string to match old logic below\n    cmd = ' '.join(cmd)\n    t0 = cmd_ret['timing']['t0']\n    t1 = cmd_ret['timing']['t1']\n    code = cmd_ret['code']\n    retout = cmd_ret['retout']\n    fileouts = cmd_ret['fileouts']\n\n    pad = \"\"\n    if len(fprt) < 8:\n        pad += \"\\t\"\n    if len(fprt) < 16:\n        pad += \"\\t\"\n    if len(fprt) < 24:\n        pad += \"\\t\"\n\n    filelen = 0\n    if fileouts is not None:\n        filelen = len(fileouts)\n\n    # Print out benchmarking information for TPM (if requested)\n    # print \"\\033[95mTIMING: %s%s\\t:%f\\toutlines:%d\\tfilelines:%d\\t%s\\033[0m\" % (fprt, pad, t1-t0, len(retout), filelen, cmd)\n    if config.TPM_BENCHMARK_PATH is not None:\n        with open(config.TPM_BENCHMARK_PATH, \"ab\") as f:\n            f.write(\n                \"TIMING: %s%s\\t:%f\\toutlines:%d\\tfilelines:%d\\t%s\\n\" % (fprt, pad, t1 - t0, len(retout), filelen, cmd))\n\n    # Print out YAML canned values (if requested)\n    # NOTE: resulting file will be missing the surrounding braces! (must add '{' and '}' for reading)\n    if config.TPM_CANNED_VALUES_PATH is not None:\n        with open(config.TPM_CANNED_VALUES_PATH, \"ab\") as can:\n            fileoutEncoded = {}\n\n            # Process files\n            if outputpaths is not None and len(outputpaths) > 0:\n                if len(fileouts) == 1 and len(outputpaths) == 1:\n                    # fileoutEncoded[outputpaths[0]] = base64.b64encode(iter(fileouts.values()).next().encode(\"zlib\"))\n                    fileoutEncoded[outputpaths[0]] = zlib.compress(base64.b64decode(iter(fileouts.values()).next()))\n                elif fprt == \"tpm2_deluxequote\":\n                    # quotes need 3 outputs, so we need a consistent way to match them back up when reading\n                    quote_msg = \"\"\n                    match = re.search(r\"-m ([^\\s]+)\", cmd)\n                    if match:\n                        quote_msg = match.group(1)\n                        if quote_msg in fileouts:\n                            # fileoutEncoded[\"file://quoteMessage\"] = base64.b64encode(fileouts[quote_msg].encode(\"zlib\"))\n                            fileoutEncoded[\"file://quoteMessage\"] = zlib.compress(base64.b64decode(fileouts[quote_msg]))\n                    quote_sig = \"\"\n                    match = re.search(r\"-s ([^\\s]+)\", cmd)\n                    if match:\n                        quote_sig = match.group(1)\n                        if quote_sig in fileouts:\n                            # fileoutEncoded[\"file://quoteSignature\"] = base64.b64encode(fileouts[quote_sig].encode(\"zlib\"))\n                            fileoutEncoded[\"file://quoteSignature\"] = zlib.compress(\n                                base64.b64decode(fileouts[quote_sig]))\n                    quote_pcr = \"\"\n                    match = re.search(r\"-p ([^\\s]+)\", cmd)\n                    if match:\n                        quote_pcr = match.group(1)\n                        if quote_pcr in fileouts:\n                            # fileoutEncoded[\"file://quotePCR\"] = base64.b64encode(fileouts[quote_pcr].encode(\"zlib\"))\n                            fileoutEncoded[\"file://quotePCR\"] = zlib.compress(base64.b64decode(fileouts[quote_pcr]))\n                else:\n                    raise Exception(\"Command %s is using multiple files unexpectedly!\" % (fprt))\n\n            # tpm_cexec will need to know the nonce\n            nonce = \"\"\n            match = re.search(r\"-q ([\\w]+)\", cmd)\n            if match:\n                nonce = binascii.a2b_hex(match.group(1))\n\n            jsonObj = {\n                'type': fprt,\n                'retout': retout,\n                'fileout': fileoutEncoded,\n                'cmd': cmd,\n                'timing': t1 - t0,\n                'code': code,\n                'nonce': nonce\n            }\n            can.write(\"\\\"%s\\\": %s,\\n\" % (fprt, json.dumps(jsonObj, indent=4, sort_keys=True)))\n\n\nclass tpm(tpm_abstract.AbstractTPM):\n    VERSION = 2\n    tools_version = \"\"\n\n    def __init__(self, need_hw_tpm=False):\n        tpm_abstract.AbstractTPM.__init__(self, need_hw_tpm)\n\n        # Shared lock to serialize access to tools\n        self.tpmutilLock = threading.Lock()\n\n        self.__get_tpm2_tools()\n\n        # We don't know which algs the TPM supports yet\n        self.supported['encrypt'] = set()\n        self.supported['hash'] = set()\n        self.supported['sign'] = set()\n\n        # Grab which default algs the config requested\n        defaultHash = config.get('cloud_agent', \"tpm_hash_alg\")\n        defaultEncrypt = config.get('cloud_agent', \"tpm_encryption_alg\")\n        defaultSign = config.get('cloud_agent', \"tpm_signing_alg\")\n\n        ek_handle = config.get('cloud_agent', 'ek_handle')\n\n        if self.need_hw_tpm:\n            if ek_handle == \"generate\":\n                # Start up the TPM\n                self.__startup_tpm()\n\n            # Figure out which algorithms the TPM supports\n            self.__get_tpm_algorithms()\n\n            # Ensure TPM supports the defaults requested\n            if defaultHash not in self.supported['hash']:\n                raise Exception('Unsupported hash algorithm specified: %s!' % (defaultHash))\n            if defaultEncrypt not in self.supported['encrypt']:\n                raise Exception('Unsupported encryption algorithm specified: %s!' % (defaultEncrypt))\n            if defaultSign not in self.supported['sign']:\n                raise Exception('Unsupported signing algorithm specified: %s!' % (defaultSign))\n        else:\n            # Assume their defaults are sane?\n            pass\n\n        self.defaults['hash'] = algorithms.Hash(defaultHash)\n        self.defaults['encrypt'] = defaultEncrypt\n        self.defaults['sign'] = defaultSign\n        self.defaults['ek_handle'] = ek_handle\n\n    def __get_tpm2_tools(self):\n        retDict = self.__run([\"tpm2_startup\", \"--version\"])\n\n        code = retDict['code']\n        output = ''.join(config.convert(retDict['retout']))\n        errout = ''.join(config.convert(retDict['reterr']))\n        if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n            raise Exception(\"Error establishing tpm2-tools version using TPM2_Startup: %s\" + str(code) + \": \" + str(errout))\n\n        # Extract the `version=\"x.x.x\"` from tools\n        version_str = re.search(r'version=\"([^\"]+)\"', output).group(1)\n        # Extract the full semver release number.\n        self.tools_version = version_str.split(\"-\")\n\n        if StrictVersion(self.tools_version[0]) >= StrictVersion(\"4.2\"):\n            logger.info(\"TPM2-TOOLS Version: %s\" % self.tools_version[0])\n            self.tools_version = \"4.2\"\n        elif StrictVersion(self.tools_version[0]) >= StrictVersion(\"4.0.0\"):\n            logger.info(\"TPM2-TOOLS Version: %s\" % self.tools_version[0])\n            self.tools_version = \"4.0\"\n        elif StrictVersion(self.tools_version[0]) >= StrictVersion(\"3.2.0\"):\n            logger.info(\"TPM2-TOOLS Version: %s\" % self.tools_version[0])\n            self.tools_version = \"3.2\"\n        else:\n            logger.error(\"TPM2-TOOLS Version %s is not supported.\" % self.tools_version[0])\n            sys.exit()\n\n    def __get_tpm_algorithms(self):\n        if self.tools_version == \"3.2\":\n            retDict = self.__run([\"tpm2_getcap\", \"-c\", \"algorithms\"])\n        elif self.tools_version in [\"4.0\", \"4.2\"]:\n            retDict = self.__run([\"tpm2_getcap\", \"algorithms\"])\n\n        output = config.convert(retDict['retout'])\n        errout = config.convert(retDict['reterr'])\n        code = retDict['code']\n\n        if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n            raise Exception(\"get_tpm_algorithms failed with code \" + str(code) + \": \" + str(errout))\n\n        if self.tools_version == \"3.2\":\n            # output, human-readable -> json\n            output = \"\".join(output)\n            output = re.sub(r'TPMA_ALGORITHM for ALG_ID: 0x[0-9a-f]+\\s+-\\s+([a-z0-9_]+)', r'\\1:', output)\n            output = output.replace(\"set\", \"1\")\n            output = output.replace(\"clear\", \"0\")\n            output = [output]\n\n        retyaml = config.yaml_to_dict(output, logger=logger)\n        if retyaml is None:\n            logger.warning(\"Could not read YAML output of tpm2_getcap.\")\n            return\n        for algorithm, details in retyaml.items():\n            if details[\"asymmetric\"] == 1 and details[\"object\"] == 1 and algorithms.Encrypt.is_recognized(algorithm):\n                self.supported['encrypt'].add(algorithm)\n            elif details[\"hash\"] == 1 and algorithms.Hash.is_recognized(algorithm):\n                self.supported['hash'].add(algorithm)\n            elif details[\"asymmetric\"] == 1 and details[\"signing\"] == 1 and algorithms.Sign.is_recognized(algorithm):\n                self.supported['sign'].add(algorithm)\n\n    # tpm_exec\n    @staticmethod\n    def __fingerprint(cmd):\n        # Creates a unique-enough ID from the given command\n        # The command should be an iterable\n        fprt = cmd[0]\n        if fprt == 'tpm2_nvread':\n            if '0x1c00002' in cmd:  # read_ekcert_nvram\n                fprt += '-ekcert'\n            else:  # read_key_nvram\n                fprt += '-key'\n        elif fprt == \"tpm2_getcap\":\n            if 'handles-persistent' in cmd:\n                fprt += '-handles'\n            elif 'properties-fixed' in cmd:\n                fprt += '-props'\n        else:\n            # other commands are already unique\n            pass\n        return fprt\n\n    def run(self, cmd):\n        return self.__run(cmd, lock=False)\n\n    def __run(self, cmd, expectedcode=tpm_abstract.AbstractTPM.EXIT_SUCESS, raiseOnError=True, lock=True, outputpaths=None):\n        env = _get_cmd_env()\n\n        # Convert single outputpath to list\n        if isinstance(outputpaths, str):\n            outputpaths = [outputpaths]\n\n        # Handle stubbing the TPM out\n        fprt = tpm.__fingerprint(cmd)\n        if config.STUB_TPM and config.TPM_CANNED_VALUES is not None:\n            stub = _stub_command(fprt, lock, cmd, outputpaths)\n            if stub:\n                return stub\n\n        numtries = 0\n        while True:\n            if lock:\n                with self.tpmutilLock:\n                    retDict = cmd_exec.run(cmd=cmd, expectedcode=expectedcode,\n                                           raiseOnError=False,\n                                           outputpaths=outputpaths, env=env)\n            else:\n                retDict = cmd_exec.run(cmd=cmd, expectedcode=expectedcode,\n                                       raiseOnError=False,\n                                       outputpaths=outputpaths, env=env)\n            code = retDict['code']\n            retout = retDict['retout']\n            reterr = retDict['reterr']\n\n            # keep trying to get quote if a PCR race condition occurred in deluxe quote\n            if fprt == \"tpm2_quote\" and cmd_exec.list_contains_substring(reterr, \"Error validating calculated PCR composite with quote\"):\n                numtries += 1\n                maxr = config.getint('cloud_agent', 'max_retries')\n                if numtries >= maxr:\n                    logger.error(\"Agent did not return proper quote due to PCR race condition.\")\n                    break\n                retry = config.getfloat('cloud_agent', 'retry_interval')\n                logger.info(\"Failed to get quote %d/%d times, trying again in %f seconds...\" % (numtries, maxr, retry))\n                time.sleep(retry)\n                continue\n\n            break\n\n        # Don't bother continuing if TPM call failed and we're raising on error\n        if code != expectedcode and raiseOnError:\n            raise Exception(\"Command: %s returned %d, expected %d, output %s, stderr %s\" % (cmd, code, expectedcode, retout, reterr))\n\n        # Metric output\n        if lock or self.tpmutilLock.locked():\n            _output_metrics(fprt, cmd, retDict, outputpaths)\n\n        return retDict\n\n    # tpm_initialize\n    def __startup_tpm(self):\n        retDict = self.__run(['tpm2_startup', '-c'])\n        errout = config.convert(retDict['reterr'])\n        code = retDict['code']\n        if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n            raise Exception(\"Error initializing emulated TPM with TPM2_Startup: %s\" + str(code) + \": \" + str(errout))\n\n    def __create_ek(self, asym_alg=None):\n        # this function is intended to be idempotent\n        if asym_alg is None:\n            asym_alg = self.defaults['encrypt']\n\n        current_handle = self.get_tpm_metadata(\"ek_handle\")\n        owner_pw = self.get_tpm_metadata(\"owner_pw\")\n\n        # clear out old handle before starting again (give idempotence)\n        if current_handle is not None and owner_pw is not None:\n            logger.info(\"Flushing old ek handle: %s\" % hex(current_handle))\n            if self.tools_version == \"3.2\":\n                retDict = self.__run([\"tpm2_getcap\", \"-c\", \"handles-persistent\"],\n                                     raiseOnError=False)\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                retDict = self.__run([\"tpm2_getcap\", \"handles-persistent\"],\n                                     raiseOnError=False)\n            output = retDict['retout']\n            reterr = retDict['reterr']\n            code = retDict['code']\n\n            if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n                raise Exception(\"tpm2_getcap failed with code \" + str(code) + \": \" + str(reterr))\n\n            outjson = config.yaml_to_dict(output, logger=logger)\n            if outjson is not None and hex(current_handle) in outjson:\n                if self.tools_version == \"3.2\":\n                    cmd = [\"tpm2_evictcontrol\", \"-A\", \"o\", \"-H\",\n                           hex(current_handle), \"-P\", owner_pw]\n                    retDict = self.__run(cmd, raiseOnError=False)\n                elif self.tools_version in [\"4.0\", \"4.2\"]:\n                    cmd = [\"tpm2_evictcontrol\", \"-C\", \"o\", \"-c\",\n                           hex(current_handle), \"-P\", owner_pw]\n                    retDict = self.__run(cmd, raiseOnError=False)\n                output = retDict['retout']\n                reterr = retDict['reterr']\n                code = retDict['code']\n\n                if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n                    logger.info(\"Failed to flush old ek handle: %s.  Code %s\" % (hex(current_handle), str(code) + \": \" + str(reterr)))\n\n                self._set_tpm_metadata('ek_handle', None)\n                self._set_tpm_metadata('ek_tpm', None)\n                self._set_tpm_metadata('ek_pw', None)\n\n        # make sure an ownership pw is set\n        if owner_pw is None:\n            owner_pw = tpm_abstract.TPM_Utilities.random_password(20)\n            self._set_tpm_metadata('owner_pw', owner_pw)\n        ek_pw = tpm_abstract.TPM_Utilities.random_password(20)\n\n        # create a new ek\n        with tempfile.NamedTemporaryFile() as tmppath:\n            # TODO(kaifeng) Missing else here for other versions\n            if self.tools_version == \"3.2\":\n                command = [\"tpm2_getpubek\", \"-H\", \"0x81010007\", \"-g\", asym_alg, \"-f\", tmppath.name, \"-P\", ek_pw, \"-o\", owner_pw, \"-e\", owner_pw]\n            elif self.tools_version == \"4.0\":\n                command = [\"tpm2_createek\", \"-c\", \"-\", \"-G\", asym_alg, \"-u\", tmppath.name, \"-p\", ek_pw, \"-w\", owner_pw, \"-P\", owner_pw]\n            elif self.tools_version == \"4.2\":\n                command = [\"tpm2_createek\", \"-c\", \"-\", \"-G\", asym_alg, \"-u\", tmppath.name, \"-w\", owner_pw, \"-P\", owner_pw]\n\n            retDict = self.__run(command, raiseOnError=False, outputpaths=tmppath.name)\n            output = retDict['retout']\n            reterr = retDict['reterr']\n            code = retDict['code']\n            ek_tpm = retDict['fileouts'][tmppath.name]\n\n            if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n                raise Exception(\"createek failed with code \" + str(code) + \": \" + str(reterr))\n\n            if self.tools_version == \"3.2\":\n                handle = int(0x81010007)\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                handle = None\n                retyaml = config.yaml_to_dict(output, logger=logger)\n                if retyaml is None:\n                    raise Exception(\"Could not read YAML output of tpm2_createek.\")\n                if \"persistent-handle\" in retyaml:\n                    handle = retyaml[\"persistent-handle\"]\n\n            self._set_tpm_metadata('ek_handle', handle)\n            self._set_tpm_metadata('ek_pw', ek_pw)\n            self._set_tpm_metadata('ek_tpm', base64.b64encode(ek_tpm))\n            self._set_tpm_metadata('ek_alg', asym_alg)\n\n    def __use_ek(self, ek_handle, config_pw):\n        ek_handle = int(ek_handle, 16)\n        logger.info(\"Using an already created ek with handle: %s\" % hex(ek_handle))\n\n        self._set_tpm_metadata('owner_pw', config_pw)\n\n        with tempfile.NamedTemporaryFile() as tmppath:\n            if self.tools_version == \"3.2\":\n                cmd = [\"tpm2_readpublic\", \"-H\", hex(ek_handle),\n                       \"-o\", tmppath.name, \"-f\", \"tss\"]\n                retDict = self.__run(cmd, raiseOnError=False, outputpaths=tmppath.name)\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                cmd = [\"tpm2_readpublic\", \"-c\", hex(ek_handle),\n                       \"-o\", tmppath.name, \"-f\", \"tss\"]\n                retDict = self.__run(cmd, raiseOnError=False, outputpaths=tmppath.name)\n\n            reterr = retDict['reterr']\n            code = retDict['code']\n            ek_tpm = retDict['fileouts'][tmppath.name]\n            if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n                raise Exception(\"tpm2_readpublic failed with code \" + str(code) + \": \" + str(reterr))\n            self._set_tpm_metadata('ek_tpm', base64.b64encode(ek_tpm))\n\n        self._set_tpm_metadata('ek_handle', int(ek_handle))\n\n    def __take_ownership(self, config_pw):\n        # if no ownerpassword\n        if config_pw == 'generate':\n            logger.info(\"Generating random TPM owner password\")\n            owner_pw = tpm_abstract.TPM_Utilities.random_password(20)\n        else:\n            logger.info(\"Taking ownership with config provided TPM owner password\")\n            owner_pw = config_pw\n\n        logger.debug(\"Removing all saved sessions from TPM\")\n        retDict = self.__run([\"tpm2_flushcontext\", \"-s\"], raiseOnError=False)\n\n        if self.tools_version == \"3.2\":\n            retDict = self.__run([\"tpm2_takeownership\", \"-c\"], raiseOnError=False)\n            retDict = self.__run([\"tpm2_takeownership\", \"-o\", owner_pw, \"-e\", owner_pw],\n                                 raiseOnError=False)\n        elif self.tools_version in [\"4.0\", \"4.2\"]:\n            retDict = self.__run([\"tpm2_changeauth\", \"-c\", \"o\", owner_pw],\n                                 raiseOnError=False)\n            retDict = self.__run([\"tpm2_changeauth\", \"-c\", \"e\", owner_pw],\n                                 raiseOnError=False)\n\n        code = retDict['code']\n        if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n            # if we fail, see if already owned with this pw\n            if self.tools_version == \"3.2\":\n                retDict = self.__run([\"tpm2_takeownership\", \"-o\", owner_pw,\n                                      \"-e\", owner_pw, \"-O\", owner_pw, \"-E\", owner_pw],\n                                     raiseOnError=False)\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                retDict = self.__run([\"tpm2_changeauth\", \"-c\", \"o\", \"-p\", owner_pw, owner_pw],\n                                     raiseOnError=False)\n                retDict = self.__run([\"tpm2_changeauth\", \"-c\", \"e\", \"-p\", owner_pw, owner_pw],\n                                     raiseOnError=False)\n\n            reterr = retDict['reterr']\n            code = retDict['code']\n            if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n                # ut-oh, already owned but not with provided pw!\n                raise Exception(\"Owner password unknown, TPM reset required. Code %s\" + str(code) + \": \" + str(reterr))\n\n        self._set_tpm_metadata('owner_pw', owner_pw)\n        logger.info(\"TPM Owner password confirmed: %s\" % owner_pw)\n\n    def __get_pub_ek(self):  # assumes that owner_pw is correct at this point\n        handle = self.get_tpm_metadata('ek_handle')\n        if handle is None:\n            raise Exception(\"create_ek has not been run yet?\")\n        # make a temp file for the output\n        with tempfile.NamedTemporaryFile() as tmppath:\n            # generates pubek.pem\n            if self.tools_version == \"3.2\":\n                cmd = [\"tpm2_readpublic\", \"-H\", hex(handle), \"-o\", tmppath.name]\n                retDict = self.__run(cmd, raiseOnError=False, outputpaths=tmppath.name)\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                cmd = [\"tpm2_readpublic\", \"-c\", hex(handle), \"-o\", tmppath.name]\n                retDict = self.__run(cmd, raiseOnError=False, outputpaths=tmppath.name)\n\n            reterr = retDict['reterr']\n            code = retDict['code']\n            ek = retDict['fileouts'][tmppath.name]\n            if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n                raise Exception(\"tpm2_readpublic failed with code \" + str(code) + \": \" + str(reterr))\n\n        self._set_tpm_metadata('ek_tpm', base64.b64encode(ek))\n\n    def __create_aik(self, asym_alg=None, hash_alg=None, sign_alg=None):\n        if hash_alg is None:\n            hash_alg = self.defaults['hash']\n        if asym_alg is None:\n            asym_alg = self.defaults['encrypt']\n        if sign_alg is None:\n            sign_alg = self.defaults['sign']\n\n        owner_pw = self.get_tpm_metadata('owner_pw')\n\n        # clear out old handle before starting again (give idempotence)\n        if self.get_tpm_metadata('aik_handle') is not None:\n            aik_handle = self.get_tpm_metadata('aik_handle')\n            if self.tools_version == \"3.2\":\n                logger.info(\"Flushing old ak handle: %s\" % hex(aik_handle))\n                retDict = self.__run([\"tpm2_getcap\", \"-c\", \"handles-persistent\"],\n                                     raiseOnError=False)\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                logger.info(\"Flushing old ak handle: %s\" % aik_handle)\n                retDict = self.__run([\"tpm2_getcap\", \"handles-persistent\"],\n                                     raiseOnError=False)\n            output = config.convert(retDict['retout'])\n            errout = config.convert(retDict['reterr'])\n            code = retDict['code']\n\n            if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n                raise Exception(\"tpm2_getcap failed with code \" + str(code) + \": \" + str(errout))\n\n            if self.tools_version == \"3.2\":\n                # output, human-readable -> json\n                output = \"\".join(output)\n                output = output.replace(\"0x\", \" - 0x\")\n                output = [output]\n\n            outjson = config.yaml_to_dict(output, logger=logger)\n            if self.tools_version == \"3.2\":\n                evict_it = outjson is not None and aik_handle in outjson\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                evict_it = os.path.exists(aik_handle)\n            if evict_it:\n                if self.tools_version == \"3.2\":\n                    cmd = [\"tpm2_evictcontrol\", \"-A\", \"o\", \"-H\", hex(aik_handle), \"-P\", owner_pw]\n                    retDict = self.__run(cmd, raiseOnError=False)\n                elif self.tools_version in [\"4.0\", \"4.2\"]:\n                    cmd = [\"tpm2_evictcontrol\", \"-C\", \"o\", \"-c\", aik_handle, \"-P\", owner_pw]\n                    retDict = self.__run(cmd, raiseOnError=False)\n                    os.remove(aik_handle)\n\n                output = retDict['retout']\n                reterr = retDict['reterr']\n                code = retDict['code']\n\n                if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n                    if self.tools_version == \"3.2\":\n                        logger.info(\"Failed to flush old ak handle: %s.  Code %s\" % (hex(aik_handle), str(code) + \": \" + str(reterr)))\n                    elif self.tools_version in [\"4.0\", \"4.2\"]:\n                        logger.info(\"Failed to flush old ak handle: %s.  Code %s\" % (aik_handle, str(code) + \": \" + str(reterr)))\n\n                self._set_tpm_metadata('aik_pw', None)\n                self._set_tpm_metadata('aik_tpm', None)\n                self._set_tpm_metadata('aik_handle', None)\n\n        logger.debug(\"Creating a new AIK identity\")\n\n        # We need an ek handle to make an aik\n        ek_handle = self.get_tpm_metadata(\"ek_handle\")\n        if ek_handle is None:\n            raise Exception(\"Failed to create AIK, since EK has not yet been created!\")\n\n        aik_pw = tpm_abstract.TPM_Utilities.random_password(20)\n        # make a temp file for the output\n        with tempfile.NamedTemporaryFile() as akpubfile:\n            secpath = \"\"\n            if self.tools_version in [\"4.0\", \"4.2\"]:\n                # ok lets write out the key now\n                secdir = secure_mount.mount()  # confirm that storage is still securely mounted\n                secfd, secpath = tempfile.mkstemp(dir=secdir)\n\n            if self.tools_version == \"3.2\":\n                command = [\"tpm2_getpubak\", \"-E\", hex(ek_handle), \"-k\", \"0x81010008\",\n                           \"-g\", asym_alg, \"-D\", hash_alg, \"-s\", sign_alg,\n                           \"-f\", akpubfile.name, \"-e\", owner_pw, \"-P\", aik_pw,\n                           \"-o\", owner_pw]\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                command = [\"tpm2_createak\", \"-C\", hex(ek_handle), \"-c\", secpath,\n                           \"-G\", asym_alg, \"-g\", hash_alg, \"-s\", sign_alg,\n                           \"-u\", akpubfile.name, \"-p\", aik_pw, \"-P\", owner_pw]\n            retDict = self.__run(command, outputpaths=akpubfile.name)\n            if secfd >= 0:\n                os.close(secfd)\n            retout = retDict['retout']\n            reterr = retDict['reterr']\n            code = retDict['code']\n\n            if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n                raise Exception(\"tpm2_createak failed with code \" + str(code) + \": \" + str(reterr))\n\n            jsonout = config.yaml_to_dict(retout, logger=logger)\n            if jsonout is None:\n                raise Exception(\"unable to parse YAML output of tpm2_createak. Is your tpm2-tools installation up to date?\")\n            aik_tpm = retDict['fileouts'][akpubfile.name]\n            if aik_tpm == \"\":\n                raise Exception(\"unable to read public aik from create identity.  Is your tpm2-tools installation up to date?\")\n            self._set_tpm_metadata('aik_tpm', base64.b64encode(aik_tpm))\n\n        if self.tools_version == \"3.2\":\n            if 'loaded-key' not in jsonout or 'name' not in jsonout['loaded-key']:\n                raise Exception(\"tpm2_createak failed to create aik: return \" + str(reterr))\n\n            handle = int(0x81010008)\n\n            # get and persist the pem (not returned by tpm2_getpubak)\n            self._set_tpm_metadata('aik_handle', handle)\n        elif self.tools_version in [\"4.0\", \"4.2\"]:\n            if 'loaded-key' not in jsonout:\n                raise Exception(\"tpm2_createak failed to create aik: return \" + str(reterr))\n\n            handle = secpath\n\n            # persist the pem\n            self._set_tpm_metadata('aik_handle', handle)\n\n        # persist common results\n        self._set_tpm_metadata('aik_pw', aik_pw)\n\n    def flush_keys(self):\n        logger.debug(\"Flushing keys from TPM...\")\n        if self.tools_version == \"3.2\":\n            retDict = self.__run([\"tpm2_getcap\", \"-c\", \"handles-persistent\"])\n        elif self.tools_version in [\"4.0\", \"4.2\"]:\n            retDict = self.__run([\"tpm2_getcap\", \"handles-persistent\"])\n        # retout = retDict['retout']\n        retout = config.convert(retDict['retout'])\n        errout = config.convert(retDict['reterr'])\n        code = retDict['code']\n\n        if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n            logger.debug(\"tpm2_getcap failed with code \" + str(code) + \": \" + str(errout))\n\n        if self.tools_version == \"3.2\":\n            # output, human-readable -> json\n            retout = \"\".join(retout)\n            retout = retout.replace(\"0x\", \" - 0x\")\n            retout = [retout]\n\n        owner_pw = self.get_tpm_metadata(\"owner_pw\")\n        jsonout = config.yaml_to_dict(retout, logger=logger)\n        if jsonout is None:\n            logger.warning(\"Could not read YAML output of tpm2_getcap.\")\n            jsonout = {}\n        for key in jsonout:\n            if str(hex(key)) != self.defaults['ek_handle']:\n                logger.debug(\"Flushing key handle %s\" % hex(key))\n                if self.tools_version == \"3.2\":\n                    self.__run([\"tpm2_evictcontrol\", \"-A\", \"o\", \"-H\", hex(key), \"-P\", owner_pw],\n                               raiseOnError=False)\n                elif self.tools_version in [\"4.0\", \"4.2\"]:\n                    self.__run([\"tpm2_evictcontrol\", \"-C\", \"o\", \"-c\", hex(key), \"-P\", owner_pw],\n                               raiseOnError=False)\n\n    def encryptAIK(self, uuid, ek_tpm: bytes, aik_tpm: bytes):\n\n        if ek_tpm is None or aik_tpm is None:\n            logger.error(\"Missing parameters for encryptAIK\")\n            return None\n\n        aik_name = tpm2_objects.get_tpm2b_public_name(aik_tpm)\n\n        efd = keyfd = blobfd = -1\n        ekFile = None\n        challengeFile = None\n        keyblob = None\n        blobpath = None\n\n        try:\n            # write out the public EK\n            efd, etemp = tempfile.mkstemp()\n            ekFile = open(etemp, \"wb\")\n            ekFile.write(ek_tpm)\n            ekFile.close()\n\n            # write out the challenge\n            challenge = tpm_abstract.TPM_Utilities.random_password(32)\n            challenge = challenge.encode()\n            keyfd, keypath = tempfile.mkstemp()\n            challengeFile = open(keypath, \"wb\")\n            challengeFile.write(challenge)\n            challengeFile.close()\n\n            # create temp file for the blob\n            blobfd, blobpath = tempfile.mkstemp()\n            command = [\"tpm2_makecredential\", \"-T\", \"none\", \"-e\", ekFile.name,\n                       \"-s\", challengeFile.name, \"-n\", aik_name, \"-o\", blobpath]\n            self.__run(command, lock=False)\n\n            logger.info(\"Encrypting AIK for UUID %s\" % uuid)\n\n            # read in the blob\n            f = open(blobpath, \"rb\")\n            keyblob = base64.b64encode(f.read())\n            f.close()\n\n            # read in the aes key\n            key = base64.b64encode(challenge)\n\n        except Exception as e:\n            logger.error(\"Error encrypting AIK: \" + str(e))\n            logger.exception(e)\n            raise\n        finally:\n            for fd in [efd, keyfd, blobfd]:\n                if fd >= 0:\n                    os.close(fd)\n            for fi in [ekFile, challengeFile]:\n                if fi is not None:\n                    os.remove(fi.name)\n            if blobpath is not None:\n                os.remove(blobpath)\n\n        return (keyblob, key)\n\n    def activate_identity(self, keyblob):\n        owner_pw = self.get_tpm_metadata('owner_pw')\n        aik_keyhandle = self.get_tpm_metadata('aik_handle')\n        ek_keyhandle = self.get_tpm_metadata('ek_handle')\n\n        keyblobFile = None\n        secpath = None\n        secfd = -1\n        sesspath = None\n        sesspathfd = -1\n        try:\n            # write out key blob\n            kfd, ktemp = tempfile.mkstemp()\n            keyblobFile = open(ktemp, \"wb\")\n            # the below is a coroutine?\n            keyblobFile.write(base64.b64decode(keyblob))\n\n            keyblobFile.close()\n            os.close(kfd)\n\n            # ok lets write out the key now\n            secdir = secure_mount.mount()  # confirm that storage is still securely mounted\n\n            secfd, secpath = tempfile.mkstemp(dir=secdir)\n            sesspathfd, sesspath = tempfile.mkstemp(dir=secdir)\n\n            apw = self.get_tpm_metadata('aik_pw')\n            if self.tools_version == \"3.2\":\n                command = [\"tpm2_activatecredential\", \"-H\", hex(aik_keyhandle),\n                           \"-k\", hex(ek_keyhandle), \"-f\", keyblobFile.name,\n                           \"-o\", secpath, \"-P\", apw, \"-e\", owner_pw]\n                retDict = self.__run(command, outputpaths=secpath)\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                self.__run([\"tpm2_startauthsession\", \"--policy-session\", \"-S\", sesspath])\n                self.__run([\"tpm2_policysecret\", \"-S\", sesspath, \"-c\", \"0x4000000B\", owner_pw])\n                command = [\"tpm2_activatecredential\", \"-c\", aik_keyhandle, \"-C\", hex(ek_keyhandle),\n                           \"-i\", keyblobFile.name, \"-o\", secpath, \"-p\", apw,\n                           \"-P\", \"session:%s\" % sesspath]\n                retDict = self.__run(command, outputpaths=secpath)\n                self.__run([\"tpm2_flushcontext\", sesspath])\n\n            fileout = retDict['fileouts'][secpath]\n            logger.info(\"AIK activated.\")\n\n            key = base64.b64encode(fileout)\n\n        except Exception as e:\n            logger.error(\"Error decrypting AIK: \" + str(e))\n            logger.exception(e)\n            return None\n        finally:\n            if keyblobFile is not None:\n                os.remove(keyblobFile.name)\n            if secfd >= 0:\n                os.close(secfd)\n            if secpath is not None and os.path.exists(secpath):\n                os.remove(secpath)\n            if sesspathfd >= 0:\n                os.close(sesspathfd)\n            if sesspath is not None and os.path.exists(sesspath):\n                os.remove(sesspath)\n        return key\n\n    def verify_ek(self, ekcert):\n        \"\"\"Verify that the provided EK certificate is signed by a trusted root\n        :param ekcert: The Endorsement Key certificate in DER format\n        :returns: True if the certificate can be verified, false otherwise\n        \"\"\"\n        # openssl x509 -inform der -in certificate.cer -out certificate.pem\n        try:\n            ek509 = x509.load_der_x509_certificate(\n                data=ekcert,\n                backend=default_backend(),\n            )\n\n            trusted_certs = tpm_ek_ca.cert_loader()\n            for cert in trusted_certs:\n                signcert = x509.load_pem_x509_certificate(\n                    data=cert.encode(),\n                    backend=default_backend(),\n                )\n\n                if ek509.issuer.rfc4514_string() != signcert.subject.rfc4514_string():\n                    continue\n\n                try:\n                    signcert.public_key().verify(\n                        ek509.signature,\n                        ek509.tbs_certificate_bytes,\n                        padding.PKCS1v15(),\n                        ek509.signature_hash_algorithm,\n                    )\n                except crypto_exceptions.InvalidSignature:\n                    continue\n\n                logger.debug(\"EK cert matched cert: %s\" % cert)\n                return True\n        except Exception as e:\n            # Log the exception so we don't lose the raw message\n            logger.exception(e)\n            raise Exception(\"Error processing ek/ekcert. Does this TPM have a valid EK?\").with_traceback(sys.exc_info()[2])\n\n        logger.error(\"No Root CA matched EK Certificate\")\n        return False\n\n    def get_tpm_manufacturer(self):\n        vendorStr = None\n        if self.tools_version == \"3.2\":\n            retDict = self.__run([\"tpm2_getcap\", \"-c\", \"properties-fixed\"])\n        elif self.tools_version in [\"4.0\", \"4.2\"]:\n            retDict = self.__run([\"tpm2_getcap\", \"properties-fixed\"])\n        output = retDict['retout']\n        reterr = retDict['reterr']\n        code = retDict['code']\n\n        if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n            raise Exception(\"get_tpm_manufacturer failed with code \" + str(code) + \": \" + str(reterr))\n\n        # Clean up TPM manufacturer information (strip control characters)\n        # These strings are supposed to be printable ASCII characters, but\n        # some TPM manufacturers put control characters in here\n        for i, s in enumerate(output):\n            output[i] = re.sub(r\"[\\x01-\\x1F\\x7F]\", \"\", s.decode('utf-8')).encode('utf-8')\n\n        retyaml = config.yaml_to_dict(output, logger=logger)\n        if retyaml is None:\n            raise Exception(\"Could not read YAML output of tpm2_getcap.\")\n        if \"TPM2_PT_VENDOR_STRING_1\" in retyaml:\n            vendorStr = retyaml[\"TPM2_PT_VENDOR_STRING_1\"][\"value\"]\n        elif \"TPM_PT_VENDOR_STRING_1\" in retyaml:\n            vendorStr = retyaml[\"TPM_PT_VENDOR_STRING_1\"][\"as string\"].strip()\n\n        return vendorStr\n\n    def is_emulator(self):\n        return self.get_tpm_manufacturer() == 'SW'\n\n    def is_vtpm(self):\n        return False\n\n    def tpm_init(self, self_activate=False, config_pw=None):\n        # this was called tpm_initialize.init before\n        self.warn_emulator()\n\n        if self.defaults['ek_handle'] == \"generate\":\n            self.__take_ownership(config_pw)\n            self.__create_ek()\n        else:\n            self.__use_ek(self.defaults['ek_handle'], config_pw)\n\n        self.__get_pub_ek()\n\n        ekcert = self.read_ekcert_nvram()\n        self._set_tpm_metadata('ekcert', ekcert)\n\n        # if no AIK created, then create one\n        self.__create_aik()\n\n        return self.get_tpm_metadata('ekcert'), self.get_tpm_metadata('ek_tpm'), self.get_tpm_metadata('aik_tpm')\n\n    # tpm_quote\n    @staticmethod\n    def __pcr_mask_to_list(mask):\n        pcr_list = []\n        for pcr in range(24):\n            if tpm_abstract.TPM_Utilities.check_mask(mask, pcr):\n                pcr_list.append(str(pcr))\n        return \",\".join(pcr_list)\n\n    def create_quote(self, nonce, data=None, pcrmask=tpm_abstract.AbstractTPM.EMPTYMASK, hash_alg=None, compress=False):\n        if hash_alg is None:\n            hash_alg = self.defaults['hash']\n\n        quote = \"\"\n\n        with tempfile.NamedTemporaryFile() as quotepath, \\\n                tempfile.NamedTemporaryFile() as sigpath, \\\n                tempfile.NamedTemporaryFile() as pcrpath:\n            keyhandle = self.get_tpm_metadata('aik_handle')\n            aik_pw = self.get_tpm_metadata('aik_pw')\n\n            if pcrmask is None:\n                pcrmask = tpm_abstract.AbstractTPM.EMPTYMASK\n\n            if data is not None:\n                # add PCR 16 to pcrmask\n                pcrmask = \"0x%X\" % (int(pcrmask, 0) + (1 << config.TPM_DATA_PCR))\n\n            pcrlist = self.__pcr_mask_to_list(pcrmask)\n\n            with self.tpmutilLock:\n                if data is not None:\n                    self.__run([\"tpm2_pcrreset\", str(config.TPM_DATA_PCR)], lock=False)\n                    self.extendPCR(pcrval=config.TPM_DATA_PCR, hashval=self.hashdigest(data), lock=False)\n\n                nonce = bytes(nonce, encoding=\"utf8\").hex()\n                if self.tools_version == \"3.2\":\n                    command = [\"tpm2_quote\", \"-k\", hex(keyhandle), \"-L\", \"%s:%s\" % (hash_alg, pcrlist), \"-q\", nonce, \"-m\", quotepath.name, \"-s\", sigpath.name, \"-p\", pcrpath.name, \"-G\", hash_alg, \"-P\", aik_pw]\n                elif self.tools_version in [\"4.0\", \"4.2\"]:\n                    command = [\"tpm2_quote\", \"-c\", keyhandle, \"-l\", \"%s:%s\" % (hash_alg, pcrlist), \"-q\", nonce, \"-m\", quotepath.name, \"-s\", sigpath.name, \"-o\", pcrpath.name, \"-g\", hash_alg, \"-p\", aik_pw]\n                retDict = self.__run(command, lock=False, outputpaths=[quotepath.name, sigpath.name, pcrpath.name])\n                quoteraw = retDict['fileouts'][quotepath.name]\n                sigraw = retDict['fileouts'][sigpath.name]\n                pcrraw = retDict['fileouts'][pcrpath.name]\n                if compress:\n                    quoteraw = zlib.compress(quoteraw)\n                    sigraw = zlib.compress(sigraw)\n                    pcrraw = zlib.compress(pcrraw)\n                quote_b64encode = base64.b64encode(quoteraw)\n                sigraw_b64encode = base64.b64encode(sigraw)\n                pcrraw_b64encode = base64.b64encode(pcrraw)\n                quote = quote_b64encode.decode('utf-8') + \":\" + sigraw_b64encode.decode('utf-8') + \":\" + pcrraw_b64encode.decode('utf-8')\n\n        return 'r' + quote\n\n    def __tpm2_checkquote(self, pubaik, nonce, quoteFile, sigFile, pcrFile, hash_alg):\n        if config.STUB_TPM and config.TPM_CANNED_VALUES is not None:\n            jsonIn = config.TPM_CANNED_VALUES\n            if 'tpm2_deluxequote' in jsonIn and 'nonce' in jsonIn['tpm2_deluxequote']:\n                # YAML unicode-ifies strings, and C calls require byte strings (str)\n                nonce = str(jsonIn['tpm2_deluxequote']['nonce'])\n            else:\n                raise Exception(\"Could not get quote nonce from canned JSON!\")\n\n        nonce = bytes(nonce, encoding=\"utf8\").hex()\n        if self.tools_version == \"3.2\":\n            command = [\"tpm2_checkquote\", \"-c\", pubaik, \"-m\", quoteFile, \"-s\", sigFile, \"-p\", pcrFile, \"-G\", hash_alg, \"-q\", nonce]\n        elif self.tools_version in [\"4.0\", \"4.2\"]:\n            command = [\"tpm2_checkquote\", \"-u\", pubaik, \"-m\", quoteFile, \"-s\", sigFile, \"-f\", pcrFile, \"-g\", hash_alg, \"-q\", nonce]\n        retDict = self.__run(command, lock=False)\n        return retDict\n\n    def _tpm2_checkquote(self, aikTpmFromRegistrar, quote, nonce, hash_alg, compressed):\n        \"\"\"Write the files from data returned from tpm2_quote for running tpm2_checkquote\n        :param aikTpmFromRegistrar: AIK used to generate the quote and is needed for verifying it now.\n        :param quote: quote data in the format 'r<b64-compressed-quoteblob>:<b64-compressed-sigblob>:<b64-compressed-pcrblob>\n        :param nonce: nonce that was used to create the quote\n        :param hash_alg: the hash algorithm that was used\n        :param compressed: if the quote data is compressed with zlib or not\n        :returns: Returns the 'retout' from running tpm2_checkquote and True in case of success, None and False in case of error.\n        This function throws an Exception on bad input.\n        \"\"\"\n        aikFromRegistrar = tpm2_objects.pubkey_from_tpm2b_public(\n            base64.b64decode(aikTpmFromRegistrar),\n            ).public_bytes(\n                crypto_serialization.Encoding.PEM,\n                crypto_serialization.PublicFormat.SubjectPublicKeyInfo,\n            )\n\n        if quote[0] != 'r':\n            raise Exception(\"Invalid quote type %s\" % quote[0])\n        quote = quote[1:]\n\n        quote_tokens = quote.split(\":\")\n        if len(quote_tokens) < 3:\n            raise Exception(\"Quote is not compound! %s\" % quote)\n\n        quoteblob = base64.b64decode(quote_tokens[0])\n        sigblob = base64.b64decode(quote_tokens[1])\n        pcrblob = base64.b64decode(quote_tokens[2])\n\n        if compressed:\n            logger.warning(\"Decompressing quote data which is unsafe!\")\n            quoteblob = zlib.decompress(quoteblob)\n            sigblob = zlib.decompress(sigblob)\n            pcrblob = zlib.decompress(pcrblob)\n\n\n        qfd = sfd = pfd = afd = -1\n        quoteFile = None\n        aikFile = None\n        sigFile = None\n        pcrFile = None\n\n        try:\n            # write out quote\n            qfd, qtemp = tempfile.mkstemp()\n            quoteFile = open(qtemp, \"wb\")\n            quoteFile.write(quoteblob)\n            quoteFile.close()\n\n            # write out sig\n            sfd, stemp = tempfile.mkstemp()\n            sigFile = open(stemp, \"wb\")\n            sigFile.write(sigblob)\n            sigFile.close()\n\n            # write out pcr\n            pfd, ptemp = tempfile.mkstemp()\n            pcrFile = open(ptemp, \"wb\")\n            pcrFile.write(pcrblob)\n            pcrFile.close()\n\n            afd, atemp = tempfile.mkstemp()\n            aikFile = open(atemp, \"wb\")\n            aikFile.write(aikFromRegistrar)\n            aikFile.close()\n\n            retDict = self.__tpm2_checkquote(aikFile.name, nonce, quoteFile.name, sigFile.name, pcrFile.name, hash_alg)\n            retout = retDict['retout']\n            reterr = retDict['reterr']\n            code = retDict['code']\n        except Exception as e:\n            logger.error(\"Error verifying quote: \" + str(e))\n            logger.exception(e)\n            return None, False\n        finally:\n            for fd in [qfd, sfd, pfd, afd]:\n                if fd >= 0:\n                    os.close(fd)\n            for fi in [aikFile, quoteFile, sigFile, pcrFile]:\n                if fi is not None:\n                    os.remove(fi.name)\n\n        if len(retout) < 1 or code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n            logger.error(\"Failed to validate signature, output: %s\" % reterr)\n            return None, False\n\n        return retout, True\n\n    def check_quote(self, agentAttestState, nonce, data, quote, aikTpmFromRegistrar, tpm_policy={},\n                    ima_measurement_list=None, allowlist={}, hash_alg=None, ima_keyrings=None,\n                    mb_measurement_list=None, mb_refstate=None, compressed=False) -> Failure:\n        failure = Failure(Component.QUOTE_VALIDATION)\n        if hash_alg is None:\n            hash_alg = self.defaults['hash']\n\n        retout, success = self._tpm2_checkquote(aikTpmFromRegistrar, quote, nonce, hash_alg, compressed)\n        if not success:\n            # If the quote validation fails we will skip all other steps therefore this failure is irrecoverable.\n            failure.add_event(\"quote_validation\", {\"message\": \"Quote validation using tpm2-tools\", \"data\": retout}, False)\n            return failure\n\n        pcrs = []\n        jsonout = config.yaml_to_dict(retout, logger=logger)\n        if jsonout is None:\n            failure.add_event(\"quote_validation\", {\"message\": \"YAML parsing failed for quote validation using tpm2-tools.\",\n                                                    \"data\": retout}, False)\n            return failure\n        if \"pcrs\" in jsonout:\n            if hash_alg in jsonout[\"pcrs\"]:\n                alg_size = hash_alg.get_size() // 4\n                for pcrval, hashval in jsonout[\"pcrs\"][hash_alg].items():\n                    pcrs.append(\"PCR \" + str(pcrval) + \" \" + '{0:0{1}x}'.format(hashval, alg_size))\n\n        if len(pcrs) == 0:\n            pcrs = None\n\n        return self.check_pcrs(agentAttestState, tpm_policy, pcrs, data, False, ima_measurement_list, allowlist,\n                               ima_keyrings, mb_measurement_list, mb_refstate, hash_alg)\n\n    def sim_extend(self, hashval_1, hashval_0=None, hash_alg=None):\n        # simulate extending a PCR value by performing TPM-specific extend procedure\n\n        if hashval_0 is None:\n            hashval_0 = self.START_HASH(hash_alg)\n\n        # compute expected value  H(0|H(data))\n        extendedval = self.hashdigest(codecs.decode(hashval_0, 'hex_codec') +\n                                      codecs.decode(self.hashdigest(hashval_1.encode('utf-8'), hash_alg), 'hex_codec'),\n                                      hash_alg).lower()\n        return extendedval\n\n    def extendPCR(self, pcrval, hashval, hash_alg=None, lock=True):\n        if hash_alg is None:\n            hash_alg = self.defaults['hash'].value\n\n        self.__run([\"tpm2_pcrextend\", \"%d:%s=%s\" % (pcrval, hash_alg, hashval)], lock=lock)\n\n    def readPCR(self, pcrval, hash_alg=None):\n        if hash_alg is None:\n            hash_alg = self.defaults['hash']\n        if self.tools_version == \"3.2\":\n            output = config.convert(self.__run(\"tpm2_pcrlist\")['retout'])\n        elif self.tools_version in [\"4.0\", \"4.2\"]:\n            output = config.convert(self.__run(\"tpm2_pcrread\")['retout'])\n\n        jsonout = config.yaml_to_dict(output, logger=logger)\n        if jsonout is None:\n            raise Exception(\"Could not read YAML output of tpm2_pcrread.\")\n\n        if hash_alg not in jsonout:\n            raise Exception(\"Invalid hashing algorithm '%s' for reading PCR number %d.\" % (hash_alg, pcrval))\n\n        # alg_size = Hash_Algorithms.get_hash_size(hash_alg)/4\n        alg_size = hash_alg.get_size() // 4\n        return '{0:0{1}x}'.format(jsonout[hash_alg][pcrval], alg_size)\n\n    # tpm_random\n    def _get_tpm_rand_block(self, size=32):\n        # make a temp file for the output\n        rand = None\n        with tempfile.NamedTemporaryFile() as randpath:\n            try:\n                command = [\"tpm2_getrandom\", \"-o\", randpath.name, str(size)]\n                retDict = self.__run(command, outputpaths=randpath.name)\n                rand = retDict['fileouts'][randpath.name]\n            except Exception as e:\n                if not self.tpmrand_warned:\n                    logger.warning(\"TPM randomness not available: %s\" % e)\n                    self.tpmrand_warned = True\n                return None\n        return rand\n\n    # tpm_nvram\n    def write_key_nvram(self, key):\n        owner_pw = self.get_tpm_metadata('owner_pw')\n\n        # write out quote\n        with tempfile.NamedTemporaryFile() as keyFile:\n            keyFile.write(key)\n            keyFile.flush()\n\n            attrs = \"ownerread|ownerwrite\"\n            # TODO(kaifeng) Escaping attrs is probably not required\n            if self.tools_version == \"3.2\":\n                self.__run([\"tpm2_nvdefine\", \"-x\", \"0x1500018\", \"-a\", \"0x40000001\", \"-s\", str(config.BOOTSTRAP_KEY_SIZE), \"-t\", '\"%s\"' % attrs, \"-I\", owner_pw, \"-P\", owner_pw], raiseOnError=False)\n                self.__run([\"tpm2_nvwrite\", \"-x\", \"0x1500018\", \"-a\", \"0x40000001\", \"-P\", owner_pw, keyFile.name], raiseOnError=False)\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                self.__run([\"tpm2_nvdefine\", \"0x1500018\", \"-C\", \"0x40000001\", \"-s\", str(config.BOOTSTRAP_KEY_SIZE), \"-a\", '\"%s\"' % attrs, \"-p\", owner_pw, \"-P\", owner_pw], raiseOnError=False)\n                self.__run([\"tpm2_nvwrite\", \"0x1500018\", \"-C\", \"0x40000001\", \"-P\", owner_pw, \"-i\", keyFile.name], raiseOnError=False)\n\n    def read_ekcert_nvram(self):\n        # make a temp file for the quote\n        with tempfile.NamedTemporaryFile() as nvpath:\n\n            # Check for RSA EK cert in NVRAM (and get length)\n            if self.tools_version == \"3.2\":\n                retDict = self.__run(\"tpm2_nvlist\", raiseOnError=False)\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                retDict = self.__run(\"tpm2_nvreadpublic\", raiseOnError=False)\n            output = retDict['retout']\n            reterr = retDict['reterr']\n            code = retDict['code']\n\n            if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n                if self.tools_version == \"3.2\":\n                    raise Exception(\"tpm2_nvlist for ekcert failed with code \" + str(code) + \": \" + str(reterr))\n                if self.tools_version in [\"4.0\", \"4.2\"]:\n                    raise Exception(\"tpm2_nvreadpublic for ekcert failed with code \" + str(code) + \": \" + str(reterr))\n\n            outjson = config.yaml_to_dict(output, logger=logger)\n\n            if outjson is None or 0x1c00002 not in outjson or \"size\" not in outjson[0x1c00002]:\n                logger.warning(\"No EK certificate found in TPM NVRAM\")\n                return None\n\n            ekcert_size = str(outjson[0x1c00002][\"size\"])\n\n            # Read the RSA EK cert from NVRAM (DER format)\n            if self.tools_version == \"3.2\":\n                retDict = self.__run([\"tpm2_nvread\", \"-x\", '0x1c00002', \"-s\", ekcert_size,\n                                      \"-f\", nvpath.name, \"-a\", \"0x01c00002\"],\n                                     raiseOnError=False, outputpaths=nvpath.name)\n            elif self.tools_version in [\"4.0\", \"4.2\"]:\n                retDict = self.__run([\"tpm2_nvread\", '0x1c00002', \"-s\", ekcert_size, \"-o\", nvpath.name],\n                                     raiseOnError=False, outputpaths=nvpath.name)\n            output = config.convert(retDict['retout'])\n            errout = config.convert(retDict['reterr'])\n            code = retDict['code']\n            ekcert = retDict['fileouts'][nvpath.name]\n\n            if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n                raise Exception(\"tpm2_nvread for ekcert failed with code \" + str(code) + \": \" + str(errout))\n\n        return base64.b64encode(ekcert)\n\n    def read_key_nvram(self):\n        owner_pw = self.get_tpm_metadata('owner_pw')\n        if self.tools_version == \"3.2\":\n            retDict = self.__run([\"tpm2_nvread\", \"-x\", \"0x1500018\", \"-a\", \"0x40000001\", \"-s\", str(config.BOOTSTRAP_KEY_SIZE), \"-P\", owner_pw], raiseOnError=False)\n        elif self.tools_version in [\"4.0\", \"4.2\"]:\n            retDict = self.__run([\"tpm2_nvread\", \"0x1500018\", \"-C\", \"0x40000001\", \"-s\", str(config.BOOTSTRAP_KEY_SIZE), \"-P\", owner_pw], raiseOnError=False)\n\n        output = retDict['retout']\n        errout = config.convert(retDict['reterr'])\n        code = retDict['code']\n\n        if code != tpm_abstract.AbstractTPM.EXIT_SUCESS:\n            if len(errout) > 0 and \"handle does not exist\" in \"\\n\".join(errout):\n                logger.debug(\"No stored U in TPM NVRAM\")\n                return None\n            if len(errout) > 0 and \"ERROR: Failed to read NVRAM public area at index\" in \"\\n\".join(errout):\n                logger.debug(\"No stored U in TPM NVRAM\")\n                return None\n            if len(errout) > 0 and \"the handle is not correct for the use\" in \"\\n\".join(errout):\n                logger.debug(\"No stored U in TPM NVRAM\")\n                return None\n\n            raise Exception(\"nv_readvalue failed with code \" + str(code) + \": \" + str(errout))\n\n        if len(output) != config.BOOTSTRAP_KEY_SIZE:\n            logger.debug(\"Invalid key length from NVRAM: %d\" % (len(output)))\n            return None\n        return output\n\n    def __stringify_pcr_keys(self, log: dict) -> None:\n        '''Ensure that the PCR indices are strings\n\n        The YAML produced by `tpm2_eventlog`, when loaded by the yaml module,\n        uses integer keys in the dicts holding PCR contents.  That does not\n        correspond to any JSON data.  This method ensures those keys are\n        strings.\n        The log is untrusted because it ultimately comes from an untrusted\n        source and has been processed by software that has had bugs.'''\n        if (not isinstance(log, dict)) or 'pcrs' not in log:\n            return\n        old_pcrs = log['pcrs']\n        if not isinstance(old_pcrs, dict):\n            return\n        new_pcrs = {}\n        for hash_alg, cells in old_pcrs.items():\n            if not isinstance(cells, dict):\n                new_pcrs[hash_alg] = cells\n                continue\n            new_pcrs[hash_alg] = {str(index): val for index, val in cells.items()}\n        log['pcrs'] = new_pcrs\n        return\n\n    def __add_boot_aggregate(self, log: dict) -> None :\n        '''Scan the boot event log and calculate possible boot aggregates.\n\n        Hashes are calculated for both sha1 and sha256,\n        as well as for 8 or 10 participant PCRs.\n\n        Technically the sha1/10PCR combination is unnecessary, since it has no\n        implementation.\n\n        Error conditions caused by improper string formatting etc. are\n        ignored. The current assumption is that the boot event log PCR\n        values are in decimal encoding, but this is liable to change.'''\n        if (not isinstance(log, dict)) or 'pcrs' not in log:\n            return\n        log['boot_aggregates'] = {}\n        for hashalg in log['pcrs'].keys():\n            log['boot_aggregates'][hashalg] = []\n            for maxpcr in [8,10]:\n                try:\n                    hashclass = getattr(hashlib,hashalg)\n                    h = hashclass()\n                    for pcrno in range(0,maxpcr):\n                        pcrstrg=log['pcrs'][hashalg][str(pcrno)]\n                        pcrhex= '{0:0{1}x}'.format(pcrstrg, h.digest_size*2)\n                        h.update(bytes.fromhex(pcrhex))\n                    log['boot_aggregates'][hashalg].append(h.hexdigest())\n                except Exception:\n                    pass\n\n    def parse_binary_bootlog(self, log_bin:bytes) -> typing.Optional[dict]:\n        '''Parse and enrich a BIOS boot log\n\n        The input is the binary log.\n        The output is the result of parsing and applying other conveniences.'''\n        with tempfile.NamedTemporaryFile() as log_bin_file:\n            log_bin_file.write(log_bin)\n            log_bin_filename = log_bin_file.name\n            retDict_tpm2 = self.__run(['tpm2_eventlog', '--eventlog-version=2', log_bin_filename])\n        log_parsed_strs = retDict_tpm2['retout']\n        log_parsed_data = config.yaml_to_dict(log_parsed_strs, add_newlines=False, logger=logger)\n        if log_parsed_data is None:\n            return None\n        #pylint: disable=import-outside-toplevel\n        try:\n            from keylime import tpm_bootlog_enrich\n        except Exception as e:\n            logger.error(\"Could not load tpm_bootlog_enrich (which depends on %s): %s\" % (config.LIBEFIVAR,str(e)))\n            return None\n        #pylint: enable=import-outside-toplevel\n        tpm_bootlog_enrich.enrich(log_parsed_data)\n        self.__stringify_pcr_keys(log_parsed_data)\n        self.__add_boot_aggregate(log_parsed_data)\n        return log_parsed_data\n\n    def _parse_mb_bootlog(self, log_b64:str) -> dict:\n        '''Parse and enrich a BIOS boot log\n\n        The input is the base64 encoding of a binary log.\n        The output is the result of parsing and applying other conveniences.'''\n        log_bin = base64.b64decode(log_b64, validate=True)\n        return self.parse_binary_bootlog(log_bin)\n\n    def parse_mb_bootlog(self, mb_measurement_list: str, hash_alg: algorithms.Hash) -> typing.Tuple[dict, typing.Optional[dict], dict, Failure]:\n        \"\"\" Parse the measured boot log and return its object and the state of the PCRs\n        :param mb_measurement_list: The measured boot measurement list\n        :param hash_alg: the hash algorithm that should be used for the PCRs\n        :returns: Returns a map of the state of the PCRs, measured boot data object and True for success\n                  and False in case an error occurred\n        \"\"\"\n        failure = Failure(Component.MEASURED_BOOT, [\"parser\"])\n        if mb_measurement_list:\n            #TODO add tagging for _parse_mb_bootlog\n            mb_measurement_data = self._parse_mb_bootlog(mb_measurement_list)\n            if not mb_measurement_data:\n                logger.error(\"Unable to parse measured boot event log. Check previous messages for a reason for error.\")\n                return {}, None, {}, failure\n            log_pcrs = mb_measurement_data.get('pcrs')\n            if not isinstance(log_pcrs, dict):\n                logger.error(\"Parse of measured boot event log has unexpected value for .pcrs: %r\", log_pcrs)\n                failure.add_event(\"invalid_pcrs\", {\"got\": log_pcrs}, True)\n                return {}, None, {}, failure\n            pcr_hashes = log_pcrs.get(str(hash_alg))\n            if (not isinstance(pcr_hashes, dict)) or not pcr_hashes:\n                logger.error(\"Parse of measured boot event log has unexpected value for .pcrs.%s: %r\", str(hash_alg), pcr_hashes)\n                failure.add_event(\"invalid_pcrs_hashes\", {\"got\": pcr_hashes}, True)\n                return {}, None, {}, failure\n            boot_aggregates = mb_measurement_data.get('boot_aggregates')\n            if (not isinstance(boot_aggregates, dict)) or not boot_aggregates:\n                logger.error(\"Parse of measured boot event log has unexpected value for .boot_aggragtes: %r\", boot_aggregates)\n                failure.add_event(\"invalid_boot_aggregates\", {\"got\": boot_aggregates}, True)\n                return {}, None, {}, failure\n\n            return pcr_hashes, boot_aggregates, mb_measurement_data, failure\n\n        return {}, None, {}, failure\n"], "filenames": ["keylime/cloud_verifier_common.py", "keylime/tenant.py", "keylime/tpm/tpm_abstract.py", "keylime/tpm/tpm_main.py"], "buggy_code_start_loc": [155, 548, 161, 962], "buggy_code_end_loc": [156, 549, 166, 1109], "fixing_code_start_loc": [155, 548, 161, 962], "fixing_code_end_loc": [157, 551, 166, 1121], "type": "NVD-CWE-noinfo", "message": "In Keylime before 6.3.0, quote responses from the agent can contain possibly untrusted ZIP data which can lead to zip bombs.", "other": {"cve": {"id": "CVE-2022-23951", "sourceIdentifier": "patrick@puiterwijk.org", "published": "2022-09-21T19:15:10.240", "lastModified": "2022-12-21T15:01:19.963", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "In Keylime before 6.3.0, quote responses from the agent can contain possibly untrusted ZIP data which can lead to zip bombs."}, {"lang": "es", "value": "En Keylime versiones anteriores a 6.3.0, las respuestas de cotizaci\u00f3n del agente pueden contener datos ZIP que no son confiables y que pueden conllevar a bombas zip"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "NVD-CWE-noinfo"}]}, {"source": "patrick@puiterwijk.org", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-400"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:keylime:keylime:*:*:*:*:*:*:*:*", "versionEndExcluding": "6.3.0", "matchCriteriaId": "8BF970A4-62CA-4D1A-BDCC-4E5C717AD6C5"}]}]}], "references": [{"url": "https://github.com/keylime/keylime/commit/6e44758b64b0ee13564fc46e807f4ba98091c355", "source": "patrick@puiterwijk.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/keylime/keylime/security/advisories/GHSA-6xx7-m45w-76m2", "source": "patrick@puiterwijk.org", "tags": ["Third Party Advisory"]}, {"url": "https://seclists.org/oss-sec/2022/q1/101", "source": "patrick@puiterwijk.org", "tags": ["Exploit", "Mailing List", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/keylime/keylime/commit/6e44758b64b0ee13564fc46e807f4ba98091c355"}}
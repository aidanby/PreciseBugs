{"buggy_code": ["// Copyright 2016 The OPA Authors.  All rights reserved.\n// Use of this source code is governed by an Apache2\n// license that can be found in the LICENSE file.\n\npackage ast\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/open-policy-agent/opa/ast/location\"\n\t\"github.com/open-policy-agent/opa/internal/debug\"\n\t\"github.com/open-policy-agent/opa/internal/gojsonschema\"\n\t\"github.com/open-policy-agent/opa/metrics\"\n\t\"github.com/open-policy-agent/opa/types\"\n\t\"github.com/open-policy-agent/opa/util\"\n)\n\n// CompileErrorLimitDefault is the default number errors a compiler will allow before\n// exiting.\nconst CompileErrorLimitDefault = 10\n\nvar errLimitReached = NewError(CompileErr, nil, \"error limit reached\")\n\n// Compiler contains the state of a compilation process.\ntype Compiler struct {\n\n\t// Errors contains errors that occurred during the compilation process.\n\t// If there are one or more errors, the compilation process is considered\n\t// \"failed\".\n\tErrors Errors\n\n\t// Modules contains the compiled modules. The compiled modules are the\n\t// output of the compilation process. If the compilation process failed,\n\t// there is no guarantee about the state of the modules.\n\tModules map[string]*Module\n\n\t// ModuleTree organizes the modules into a tree where each node is keyed by\n\t// an element in the module's package path. E.g., given modules containing\n\t// the following package directives: \"a\", \"a.b\", \"a.c\", and \"a.b\", the\n\t// resulting module tree would be:\n\t//\n\t//  root\n\t//    |\n\t//    +--- data (no modules)\n\t//           |\n\t//           +--- a (1 module)\n\t//                |\n\t//                +--- b (2 modules)\n\t//                |\n\t//                +--- c (1 module)\n\t//\n\tModuleTree *ModuleTreeNode\n\n\t// RuleTree organizes rules into a tree where each node is keyed by an\n\t// element in the rule's path. The rule path is the concatenation of the\n\t// containing package and the stringified rule name. E.g., given the\n\t// following module:\n\t//\n\t//  package ex\n\t//  p[1] { true }\n\t//  p[2] { true }\n\t//  q = true\n\t//\n\t//  root\n\t//    |\n\t//    +--- data (no rules)\n\t//           |\n\t//           +--- ex (no rules)\n\t//                |\n\t//                +--- p (2 rules)\n\t//                |\n\t//                +--- q (1 rule)\n\tRuleTree *TreeNode\n\n\t// Graph contains dependencies between rules. An edge (u,v) is added to the\n\t// graph if rule 'u' refers to the virtual document defined by 'v'.\n\tGraph *Graph\n\n\t// TypeEnv holds type information for values inferred by the compiler.\n\tTypeEnv *TypeEnv\n\n\t// RewrittenVars is a mapping of variables that have been rewritten\n\t// with the key being the generated name and value being the original.\n\tRewrittenVars map[Var]Var\n\n\tlocalvargen  *localVarGenerator\n\tmoduleLoader ModuleLoader\n\truleIndices  *util.HashMap\n\tstages       []struct {\n\t\tname       string\n\t\tmetricName string\n\t\tf          func()\n\t}\n\tmaxErrs               int\n\tsorted                []string // list of sorted module names\n\tpathExists            func([]string) (bool, error)\n\tafter                 map[string][]CompilerStageDefinition\n\tmetrics               metrics.Metrics\n\tcapabilities          *Capabilities                 // user-supplied capabilities\n\tbuiltins              map[string]*Builtin           // universe of built-in functions\n\tcustomBuiltins        map[string]*Builtin           // user-supplied custom built-in functions (deprecated: use capabilities)\n\tunsafeBuiltinsMap     map[string]struct{}           // user-supplied set of unsafe built-ins functions to block (deprecated: use capabilities)\n\tdeprecatedBuiltinsMap map[string]struct{}           // set of deprecated, but not removed, built-in functions\n\tenablePrintStatements bool                          // indicates if print statements should be elided (default)\n\tcomprehensionIndices  map[*Term]*ComprehensionIndex // comprehension key index\n\tinitialized           bool                          // indicates if init() has been called\n\tdebug                 debug.Debug                   // emits debug information produced during compilation\n\tschemaSet             *SchemaSet                    // user-supplied schemas for input and data documents\n\tinputType             types.Type                    // global input type retrieved from schema set\n\tannotationSet         *AnnotationSet                // hierarchical set of annotations\n\tstrict                bool                          // enforce strict compilation checks\n\tkeepModules           bool                          // whether to keep the unprocessed, parse modules (below)\n\tparsedModules         map[string]*Module            // parsed, but otherwise unprocessed modules, kept track of when keepModules is true\n}\n\n// CompilerStage defines the interface for stages in the compiler.\ntype CompilerStage func(*Compiler) *Error\n\n// CompilerStageDefinition defines a compiler stage\ntype CompilerStageDefinition struct {\n\tName       string\n\tMetricName string\n\tStage      CompilerStage\n}\n\n// RulesOptions defines the options for retrieving rules by Ref from the\n// compiler.\ntype RulesOptions struct {\n\t// IncludeHiddenModules determines if the result contains hidden modules,\n\t// currently only the \"system\" namespace, i.e. \"data.system.*\".\n\tIncludeHiddenModules bool\n}\n\n// QueryContext contains contextual information for running an ad-hoc query.\n//\n// Ad-hoc queries can be run in the context of a package and imports may be\n// included to provide concise access to data.\ntype QueryContext struct {\n\tPackage *Package\n\tImports []*Import\n}\n\n// NewQueryContext returns a new QueryContext object.\nfunc NewQueryContext() *QueryContext {\n\treturn &QueryContext{}\n}\n\n// WithPackage sets the pkg on qc.\nfunc (qc *QueryContext) WithPackage(pkg *Package) *QueryContext {\n\tif qc == nil {\n\t\tqc = NewQueryContext()\n\t}\n\tqc.Package = pkg\n\treturn qc\n}\n\n// WithImports sets the imports on qc.\nfunc (qc *QueryContext) WithImports(imports []*Import) *QueryContext {\n\tif qc == nil {\n\t\tqc = NewQueryContext()\n\t}\n\tqc.Imports = imports\n\treturn qc\n}\n\n// Copy returns a deep copy of qc.\nfunc (qc *QueryContext) Copy() *QueryContext {\n\tif qc == nil {\n\t\treturn nil\n\t}\n\tcpy := *qc\n\tif cpy.Package != nil {\n\t\tcpy.Package = qc.Package.Copy()\n\t}\n\tcpy.Imports = make([]*Import, len(qc.Imports))\n\tfor i := range qc.Imports {\n\t\tcpy.Imports[i] = qc.Imports[i].Copy()\n\t}\n\treturn &cpy\n}\n\n// QueryCompiler defines the interface for compiling ad-hoc queries.\ntype QueryCompiler interface {\n\n\t// Compile should be called to compile ad-hoc queries. The return value is\n\t// the compiled version of the query.\n\tCompile(q Body) (Body, error)\n\n\t// TypeEnv returns the type environment built after running type checking\n\t// on the query.\n\tTypeEnv() *TypeEnv\n\n\t// WithContext sets the QueryContext on the QueryCompiler. Subsequent calls\n\t// to Compile will take the QueryContext into account.\n\tWithContext(qctx *QueryContext) QueryCompiler\n\n\t// WithEnablePrintStatements enables print statements in queries compiled\n\t// with the QueryCompiler.\n\tWithEnablePrintStatements(yes bool) QueryCompiler\n\n\t// WithUnsafeBuiltins sets the built-in functions to treat as unsafe and not\n\t// allow inside of queries. By default the query compiler inherits the\n\t// compiler's unsafe built-in functions. This function allows callers to\n\t// override that set. If an empty (non-nil) map is provided, all built-ins\n\t// are allowed.\n\tWithUnsafeBuiltins(unsafe map[string]struct{}) QueryCompiler\n\n\t// WithStageAfter registers a stage to run during query compilation after\n\t// the named stage.\n\tWithStageAfter(after string, stage QueryCompilerStageDefinition) QueryCompiler\n\n\t// RewrittenVars maps generated vars in the compiled query to vars from the\n\t// parsed query. For example, given the query \"input := 1\" the rewritten\n\t// query would be \"__local0__ = 1\". The mapping would then be {__local0__: input}.\n\tRewrittenVars() map[Var]Var\n\n\t// ComprehensionIndex returns an index data structure for the given comprehension\n\t// term. If no index is found, returns nil.\n\tComprehensionIndex(term *Term) *ComprehensionIndex\n}\n\n// QueryCompilerStage defines the interface for stages in the query compiler.\ntype QueryCompilerStage func(QueryCompiler, Body) (Body, error)\n\n// QueryCompilerStageDefinition defines a QueryCompiler stage\ntype QueryCompilerStageDefinition struct {\n\tName       string\n\tMetricName string\n\tStage      QueryCompilerStage\n}\n\n// NewCompiler returns a new empty compiler.\nfunc NewCompiler() *Compiler {\n\n\tc := &Compiler{\n\t\tModules:       map[string]*Module{},\n\t\tRewrittenVars: map[Var]Var{},\n\t\truleIndices: util.NewHashMap(func(a, b util.T) bool {\n\t\t\tr1, r2 := a.(Ref), b.(Ref)\n\t\t\treturn r1.Equal(r2)\n\t\t}, func(x util.T) int {\n\t\t\treturn x.(Ref).Hash()\n\t\t}),\n\t\tmaxErrs:               CompileErrorLimitDefault,\n\t\tafter:                 map[string][]CompilerStageDefinition{},\n\t\tunsafeBuiltinsMap:     map[string]struct{}{},\n\t\tdeprecatedBuiltinsMap: map[string]struct{}{},\n\t\tcomprehensionIndices:  map[*Term]*ComprehensionIndex{},\n\t\tdebug:                 debug.Discard(),\n\t}\n\n\tc.ModuleTree = NewModuleTree(nil)\n\tc.RuleTree = NewRuleTree(c.ModuleTree)\n\n\tc.stages = []struct {\n\t\tname       string\n\t\tmetricName string\n\t\tf          func()\n\t}{\n\t\t// Reference resolution should run first as it may be used to lazily\n\t\t// load additional modules. If any stages run before resolution, they\n\t\t// need to be re-run after resolution.\n\t\t{\"ResolveRefs\", \"compile_stage_resolve_refs\", c.resolveAllRefs},\n\t\t{\"CheckKeywordOverrides\", \"compile_stage_check_keyword_overrides\", c.checkKeywordOverrides},\n\t\t{\"CheckDuplicateImports\", \"compile_stage_check_duplicate_imports\", c.checkDuplicateImports},\n\t\t{\"RemoveImports\", \"compile_stage_remove_imports\", c.removeImports},\n\t\t{\"SetModuleTree\", \"compile_stage_set_module_tree\", c.setModuleTree},\n\t\t{\"SetRuleTree\", \"compile_stage_set_rule_tree\", c.setRuleTree},\n\t\t// The local variable generator must be initialized after references are\n\t\t// resolved and the dynamic module loader has run but before subsequent\n\t\t// stages that need to generate variables.\n\t\t{\"InitLocalVarGen\", \"compile_stage_init_local_var_gen\", c.initLocalVarGen},\n\t\t{\"RewriteLocalVars\", \"compile_stage_rewrite_local_vars\", c.rewriteLocalVars},\n\t\t{\"CheckVoidCalls\", \"compile_stage_check_void_calls\", c.checkVoidCalls},\n\t\t{\"RewritePrintCalls\", \"compile_stage_rewrite_print_calls\", c.rewritePrintCalls},\n\t\t{\"RewriteExprTerms\", \"compile_stage_rewrite_expr_terms\", c.rewriteExprTerms},\n\t\t{\"ParseMetadataBlocks\", \"compile_stage_parse_metadata_blocks\", c.parseMetadataBlocks},\n\t\t{\"SetAnnotationSet\", \"compile_stage_set_annotationset\", c.setAnnotationSet},\n\t\t{\"RewriteRegoMetadataCalls\", \"compile_stage_rewrite_rego_metadata_calls\", c.rewriteRegoMetadataCalls},\n\t\t{\"SetGraph\", \"compile_stage_set_graph\", c.setGraph},\n\t\t{\"RewriteComprehensionTerms\", \"compile_stage_rewrite_comprehension_terms\", c.rewriteComprehensionTerms},\n\t\t{\"RewriteRefsInHead\", \"compile_stage_rewrite_refs_in_head\", c.rewriteRefsInHead},\n\t\t{\"RewriteWithValues\", \"compile_stage_rewrite_with_values\", c.rewriteWithModifiers},\n\t\t{\"CheckRuleConflicts\", \"compile_stage_check_rule_conflicts\", c.checkRuleConflicts},\n\t\t{\"CheckUndefinedFuncs\", \"compile_stage_check_undefined_funcs\", c.checkUndefinedFuncs},\n\t\t{\"CheckSafetyRuleHeads\", \"compile_stage_check_safety_rule_heads\", c.checkSafetyRuleHeads},\n\t\t{\"CheckSafetyRuleBodies\", \"compile_stage_check_safety_rule_bodies\", c.checkSafetyRuleBodies},\n\t\t{\"RewriteEquals\", \"compile_stage_rewrite_equals\", c.rewriteEquals},\n\t\t{\"RewriteDynamicTerms\", \"compile_stage_rewrite_dynamic_terms\", c.rewriteDynamicTerms},\n\t\t{\"CheckRecursion\", \"compile_stage_check_recursion\", c.checkRecursion},\n\t\t{\"CheckTypes\", \"compile_stage_check_types\", c.checkTypes}, // must be run after CheckRecursion\n\t\t{\"CheckUnsafeBuiltins\", \"compile_state_check_unsafe_builtins\", c.checkUnsafeBuiltins},\n\t\t{\"CheckDeprecatedBuiltins\", \"compile_state_check_deprecated_builtins\", c.checkDeprecatedBuiltins},\n\t\t{\"BuildRuleIndices\", \"compile_stage_rebuild_indices\", c.buildRuleIndices},\n\t\t{\"BuildComprehensionIndices\", \"compile_stage_rebuild_comprehension_indices\", c.buildComprehensionIndices},\n\t}\n\n\treturn c\n}\n\n// SetErrorLimit sets the number of errors the compiler can encounter before it\n// quits. Zero or a negative number indicates no limit.\nfunc (c *Compiler) SetErrorLimit(limit int) *Compiler {\n\tc.maxErrs = limit\n\treturn c\n}\n\n// WithEnablePrintStatements enables print statements inside of modules compiled\n// by the compiler. If print statements are not enabled, calls to print() are\n// erased at compile-time.\nfunc (c *Compiler) WithEnablePrintStatements(yes bool) *Compiler {\n\tc.enablePrintStatements = yes\n\treturn c\n}\n\n// WithPathConflictsCheck enables base-virtual document conflict\n// detection. The compiler will check that rules don't overlap with\n// paths that exist as determined by the provided callable.\nfunc (c *Compiler) WithPathConflictsCheck(fn func([]string) (bool, error)) *Compiler {\n\tc.pathExists = fn\n\treturn c\n}\n\n// WithStageAfter registers a stage to run during compilation after\n// the named stage.\nfunc (c *Compiler) WithStageAfter(after string, stage CompilerStageDefinition) *Compiler {\n\tc.after[after] = append(c.after[after], stage)\n\treturn c\n}\n\n// WithMetrics will set a metrics.Metrics and be used for profiling\n// the Compiler instance.\nfunc (c *Compiler) WithMetrics(metrics metrics.Metrics) *Compiler {\n\tc.metrics = metrics\n\treturn c\n}\n\n// WithCapabilities sets capabilities to enable during compilation. Capabilities allow the caller\n// to specify the set of built-in functions available to the policy. In the future, capabilities\n// may be able to restrict access to other language features. Capabilities allow callers to check\n// if policies are compatible with a particular version of OPA. If policies are a compiled for a\n// specific version of OPA, there is no guarantee that _this_ version of OPA can evaluate them\n// successfully.\nfunc (c *Compiler) WithCapabilities(capabilities *Capabilities) *Compiler {\n\tc.capabilities = capabilities\n\treturn c\n}\n\n// Capabilities returns the capabilities enabled during compilation.\nfunc (c *Compiler) Capabilities() *Capabilities {\n\treturn c.capabilities\n}\n\n// WithDebug sets where debug messages are written to. Passing `nil` has no\n// effect.\nfunc (c *Compiler) WithDebug(sink io.Writer) *Compiler {\n\tif sink != nil {\n\t\tc.debug = debug.New(sink)\n\t}\n\treturn c\n}\n\n// WithBuiltins is deprecated. Use WithCapabilities instead.\nfunc (c *Compiler) WithBuiltins(builtins map[string]*Builtin) *Compiler {\n\tc.customBuiltins = make(map[string]*Builtin)\n\tfor k, v := range builtins {\n\t\tc.customBuiltins[k] = v\n\t}\n\treturn c\n}\n\n// WithUnsafeBuiltins is deprecated. Use WithCapabilities instead.\nfunc (c *Compiler) WithUnsafeBuiltins(unsafeBuiltins map[string]struct{}) *Compiler {\n\tfor name := range unsafeBuiltins {\n\t\tc.unsafeBuiltinsMap[name] = struct{}{}\n\t}\n\treturn c\n}\n\n// WithStrict enables strict mode in the compiler.\nfunc (c *Compiler) WithStrict(strict bool) *Compiler {\n\tc.strict = strict\n\treturn c\n}\n\n// WithKeepModules enables retaining unprocessed modules in the compiler.\n// Note that the modules aren't copied on the way in or out -- so when\n// accessing them via ParsedModules(), mutations will occur in the module\n// map that was passed into Compile().`\nfunc (c *Compiler) WithKeepModules(y bool) *Compiler {\n\tc.keepModules = y\n\treturn c\n}\n\n// ParsedModules returns the parsed, unprocessed modules from the compiler.\n// It is `nil` if keeping modules wasn't enabled via `WithKeepModules(true)`.\n// The map includes all modules loaded via the ModuleLoader, if one was used.\nfunc (c *Compiler) ParsedModules() map[string]*Module {\n\treturn c.parsedModules\n}\n\n// QueryCompiler returns a new QueryCompiler object.\nfunc (c *Compiler) QueryCompiler() QueryCompiler {\n\tc.init()\n\treturn newQueryCompiler(c)\n}\n\n// Compile runs the compilation process on the input modules. The compiled\n// version of the modules and associated data structures are stored on the\n// compiler. If the compilation process fails for any reason, the compiler will\n// contain a slice of errors.\nfunc (c *Compiler) Compile(modules map[string]*Module) {\n\n\tc.init()\n\n\tc.Modules = make(map[string]*Module, len(modules))\n\tc.sorted = make([]string, 0, len(modules))\n\n\tif c.keepModules {\n\t\tc.parsedModules = make(map[string]*Module, len(modules))\n\t} else {\n\t\tc.parsedModules = nil\n\t}\n\n\tfor k, v := range modules {\n\t\tc.Modules[k] = v.Copy()\n\t\tc.sorted = append(c.sorted, k)\n\t\tif c.parsedModules != nil {\n\t\t\tc.parsedModules[k] = v\n\t\t}\n\t}\n\n\tsort.Strings(c.sorted)\n\n\tc.compile()\n}\n\n// WithSchemas sets a schemaSet to the compiler\nfunc (c *Compiler) WithSchemas(schemas *SchemaSet) *Compiler {\n\tc.schemaSet = schemas\n\treturn c\n}\n\n// Failed returns true if a compilation error has been encountered.\nfunc (c *Compiler) Failed() bool {\n\treturn len(c.Errors) > 0\n}\n\n// ComprehensionIndex returns a data structure specifying how to index comprehension\n// results so that callers do not have to recompute the comprehension more than once.\n// If no index is found, returns nil.\nfunc (c *Compiler) ComprehensionIndex(term *Term) *ComprehensionIndex {\n\treturn c.comprehensionIndices[term]\n}\n\n// GetArity returns the number of args a function referred to by ref takes. If\n// ref refers to built-in function, the built-in declaration is consulted,\n// otherwise, the ref is used to perform a ruleset lookup.\nfunc (c *Compiler) GetArity(ref Ref) int {\n\tif bi := c.builtins[ref.String()]; bi != nil {\n\t\treturn len(bi.Decl.Args())\n\t}\n\trules := c.GetRulesExact(ref)\n\tif len(rules) == 0 {\n\t\treturn -1\n\t}\n\treturn len(rules[0].Head.Args)\n}\n\n// GetRulesExact returns a slice of rules referred to by the reference.\n//\n// E.g., given the following module:\n//\n//\tpackage a.b.c\n//\n//\tp[k] = v { ... }    # rule1\n//  p[k1] = v1 { ... }  # rule2\n//\n// The following calls yield the rules on the right.\n//\n//  GetRulesExact(\"data.a.b.c.p\")   => [rule1, rule2]\n//  GetRulesExact(\"data.a.b.c.p.x\") => nil\n//  GetRulesExact(\"data.a.b.c\")     => nil\nfunc (c *Compiler) GetRulesExact(ref Ref) (rules []*Rule) {\n\tnode := c.RuleTree\n\n\tfor _, x := range ref {\n\t\tif node = node.Child(x.Value); node == nil {\n\t\t\treturn nil\n\t\t}\n\t}\n\n\treturn extractRules(node.Values)\n}\n\n// GetRulesForVirtualDocument returns a slice of rules that produce the virtual\n// document referred to by the reference.\n//\n// E.g., given the following module:\n//\n//\tpackage a.b.c\n//\n//\tp[k] = v { ... }    # rule1\n//  p[k1] = v1 { ... }  # rule2\n//\n// The following calls yield the rules on the right.\n//\n//  GetRulesForVirtualDocument(\"data.a.b.c.p\")   => [rule1, rule2]\n//  GetRulesForVirtualDocument(\"data.a.b.c.p.x\") => [rule1, rule2]\n//  GetRulesForVirtualDocument(\"data.a.b.c\")     => nil\nfunc (c *Compiler) GetRulesForVirtualDocument(ref Ref) (rules []*Rule) {\n\n\tnode := c.RuleTree\n\n\tfor _, x := range ref {\n\t\tif node = node.Child(x.Value); node == nil {\n\t\t\treturn nil\n\t\t}\n\t\tif len(node.Values) > 0 {\n\t\t\treturn extractRules(node.Values)\n\t\t}\n\t}\n\n\treturn extractRules(node.Values)\n}\n\n// GetRulesWithPrefix returns a slice of rules that share the prefix ref.\n//\n// E.g., given the following module:\n//\n//  package a.b.c\n//\n//  p[x] = y { ... }  # rule1\n//  p[k] = v { ... }  # rule2\n//  q { ... }         # rule3\n//\n// The following calls yield the rules on the right.\n//\n//  GetRulesWithPrefix(\"data.a.b.c.p\")   => [rule1, rule2]\n//  GetRulesWithPrefix(\"data.a.b.c.p.a\") => nil\n//  GetRulesWithPrefix(\"data.a.b.c\")     => [rule1, rule2, rule3]\nfunc (c *Compiler) GetRulesWithPrefix(ref Ref) (rules []*Rule) {\n\n\tnode := c.RuleTree\n\n\tfor _, x := range ref {\n\t\tif node = node.Child(x.Value); node == nil {\n\t\t\treturn nil\n\t\t}\n\t}\n\n\tvar acc func(node *TreeNode)\n\n\tacc = func(node *TreeNode) {\n\t\trules = append(rules, extractRules(node.Values)...)\n\t\tfor _, child := range node.Children {\n\t\t\tif child.Hide {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tacc(child)\n\t\t}\n\t}\n\n\tacc(node)\n\n\treturn rules\n}\n\nfunc extractRules(s []util.T) (rules []*Rule) {\n\tfor _, r := range s {\n\t\trules = append(rules, r.(*Rule))\n\t}\n\treturn rules\n}\n\n// GetRules returns a slice of rules that are referred to by ref.\n//\n// E.g., given the following module:\n//\n//  package a.b.c\n//\n//  p[x] = y { q[x] = y; ... } # rule1\n//  q[x] = y { ... }           # rule2\n//\n// The following calls yield the rules on the right.\n//\n//  GetRules(\"data.a.b.c.p\")\t=> [rule1]\n//  GetRules(\"data.a.b.c.p.x\")\t=> [rule1]\n//  GetRules(\"data.a.b.c.q\")\t=> [rule2]\n//  GetRules(\"data.a.b.c\")\t\t=> [rule1, rule2]\n//  GetRules(\"data.a.b.d\")\t\t=> nil\nfunc (c *Compiler) GetRules(ref Ref) (rules []*Rule) {\n\n\tset := map[*Rule]struct{}{}\n\n\tfor _, rule := range c.GetRulesForVirtualDocument(ref) {\n\t\tset[rule] = struct{}{}\n\t}\n\n\tfor _, rule := range c.GetRulesWithPrefix(ref) {\n\t\tset[rule] = struct{}{}\n\t}\n\n\tfor rule := range set {\n\t\trules = append(rules, rule)\n\t}\n\n\treturn rules\n}\n\n// GetRulesDynamic returns a slice of rules that could be referred to by a ref.\n//\n// Deprecated: use GetRulesDynamicWithOpts\nfunc (c *Compiler) GetRulesDynamic(ref Ref) []*Rule {\n\treturn c.GetRulesDynamicWithOpts(ref, RulesOptions{})\n}\n\n// GetRulesDynamicWithOpts returns a slice of rules that could be referred to by\n// a ref.\n// When parts of the ref are statically known, we use that information to narrow\n// down which rules the ref could refer to, but in the most general case this\n// will be an over-approximation.\n//\n// E.g., given the following modules:\n//\n//  package a.b.c\n//\n//  r1 = 1  # rule1\n//\n// and:\n//\n//  package a.d.c\n//\n//  r2 = 2  # rule2\n//\n// The following calls yield the rules on the right.\n//\n//  GetRulesDynamicWithOpts(\"data.a[x].c[y]\", opts) => [rule1, rule2]\n//  GetRulesDynamicWithOpts(\"data.a[x].c.r2\", opts) => [rule2]\n//  GetRulesDynamicWithOpts(\"data.a.b[x][y]\", opts) => [rule1]\n//\n// Using the RulesOptions parameter, the inclusion of hidden modules can be\n// controlled:\n//\n// With\n//\n//  package system.main\n//\n//  r3 = 3 # rule3\n//\n// We'd get this result:\n//\n//  GetRulesDynamicWithOpts(\"data[x]\", RulesOptions{IncludeHiddenModules: true}) => [rule1, rule2, rule3]\n//\n// Without the options, it would be excluded.\nfunc (c *Compiler) GetRulesDynamicWithOpts(ref Ref, opts RulesOptions) []*Rule {\n\tnode := c.RuleTree\n\n\tset := map[*Rule]struct{}{}\n\tvar walk func(node *TreeNode, i int)\n\twalk = func(node *TreeNode, i int) {\n\t\tswitch {\n\t\tcase i >= len(ref):\n\t\t\t// We've reached the end of the reference and want to collect everything\n\t\t\t// under this \"prefix\".\n\t\t\tnode.DepthFirst(func(descendant *TreeNode) bool {\n\t\t\t\tinsertRules(set, descendant.Values)\n\t\t\t\tif opts.IncludeHiddenModules {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t\treturn descendant.Hide\n\t\t\t})\n\n\t\tcase i == 0 || IsConstant(ref[i].Value):\n\t\t\t// The head of the ref is always grounded.  In case another part of the\n\t\t\t// ref is also grounded, we can lookup the exact child.  If it's not found\n\t\t\t// we can immediately return...\n\t\t\tif child := node.Child(ref[i].Value); child == nil {\n\t\t\t\treturn\n\t\t\t} else if len(child.Values) > 0 {\n\t\t\t\t// If there are any rules at this position, it's what the ref would\n\t\t\t\t// refer to.  We can just append those and stop here.\n\t\t\t\tinsertRules(set, child.Values)\n\t\t\t} else {\n\t\t\t\t// Otherwise, we continue using the child node.\n\t\t\t\twalk(child, i+1)\n\t\t\t}\n\n\t\tdefault:\n\t\t\t// This part of the ref is a dynamic term.  We can't know what it refers\n\t\t\t// to and will just need to try all of the children.\n\t\t\tfor _, child := range node.Children {\n\t\t\t\tif child.Hide && !opts.IncludeHiddenModules {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tinsertRules(set, child.Values)\n\t\t\t\twalk(child, i+1)\n\t\t\t}\n\t\t}\n\t}\n\n\twalk(node, 0)\n\trules := make([]*Rule, 0, len(set))\n\tfor rule := range set {\n\t\trules = append(rules, rule)\n\t}\n\treturn rules\n}\n\n// Utility: add all rule values to the set.\nfunc insertRules(set map[*Rule]struct{}, rules []util.T) {\n\tfor _, rule := range rules {\n\t\tset[rule.(*Rule)] = struct{}{}\n\t}\n}\n\n// RuleIndex returns a RuleIndex built for the rule set referred to by path.\n// The path must refer to the rule set exactly, i.e., given a rule set at path\n// data.a.b.c.p, refs data.a.b.c.p.x and data.a.b.c would not return a\n// RuleIndex built for the rule.\nfunc (c *Compiler) RuleIndex(path Ref) RuleIndex {\n\tr, ok := c.ruleIndices.Get(path)\n\tif !ok {\n\t\treturn nil\n\t}\n\treturn r.(RuleIndex)\n}\n\n// PassesTypeCheck determines whether the given body passes type checking\nfunc (c *Compiler) PassesTypeCheck(body Body) bool {\n\tchecker := newTypeChecker().WithSchemaSet(c.schemaSet).WithInputType(c.inputType)\n\tenv := c.TypeEnv\n\t_, errs := checker.CheckBody(env, body)\n\treturn len(errs) == 0\n}\n\n// ModuleLoader defines the interface that callers can implement to enable lazy\n// loading of modules during compilation.\ntype ModuleLoader func(resolved map[string]*Module) (parsed map[string]*Module, err error)\n\n// WithModuleLoader sets f as the ModuleLoader on the compiler.\n//\n// The compiler will invoke the ModuleLoader after resolving all references in\n// the current set of input modules. The ModuleLoader can return a new\n// collection of parsed modules that are to be included in the compilation\n// process. This process will repeat until the ModuleLoader returns an empty\n// collection or an error. If an error is returned, compilation will stop\n// immediately.\nfunc (c *Compiler) WithModuleLoader(f ModuleLoader) *Compiler {\n\tc.moduleLoader = f\n\treturn c\n}\n\nfunc (c *Compiler) counterAdd(name string, n uint64) {\n\tif c.metrics == nil {\n\t\treturn\n\t}\n\tc.metrics.Counter(name).Add(n)\n}\n\nfunc (c *Compiler) buildRuleIndices() {\n\n\tc.RuleTree.DepthFirst(func(node *TreeNode) bool {\n\t\tif len(node.Values) == 0 {\n\t\t\treturn false\n\t\t}\n\t\tindex := newBaseDocEqIndex(func(ref Ref) bool {\n\t\t\treturn isVirtual(c.RuleTree, ref.GroundPrefix())\n\t\t})\n\t\tif rules := extractRules(node.Values); index.Build(rules) {\n\t\t\tc.ruleIndices.Put(rules[0].Path(), index)\n\t\t}\n\t\treturn false\n\t})\n\n}\n\nfunc (c *Compiler) buildComprehensionIndices() {\n\tfor _, name := range c.sorted {\n\t\tWalkRules(c.Modules[name], func(r *Rule) bool {\n\t\t\tcandidates := r.Head.Args.Vars()\n\t\t\tcandidates.Update(ReservedVars)\n\t\t\tn := buildComprehensionIndices(c.debug, c.GetArity, candidates, c.RewrittenVars, r.Body, c.comprehensionIndices)\n\t\t\tc.counterAdd(compileStageComprehensionIndexBuild, n)\n\t\t\treturn false\n\t\t})\n\t}\n}\n\n// checkRecursion ensures that there are no recursive definitions, i.e., there are\n// no cycles in the Graph.\nfunc (c *Compiler) checkRecursion() {\n\teq := func(a, b util.T) bool {\n\t\treturn a.(*Rule) == b.(*Rule)\n\t}\n\n\tc.RuleTree.DepthFirst(func(node *TreeNode) bool {\n\t\tfor _, rule := range node.Values {\n\t\t\tfor node := rule.(*Rule); node != nil; node = node.Else {\n\t\t\t\tc.checkSelfPath(node.Loc(), eq, node, node)\n\t\t\t}\n\t\t}\n\t\treturn false\n\t})\n}\n\nfunc (c *Compiler) checkSelfPath(loc *Location, eq func(a, b util.T) bool, a, b util.T) {\n\ttr := NewGraphTraversal(c.Graph)\n\tif p := util.DFSPath(tr, eq, a, b); len(p) > 0 {\n\t\tn := []string{}\n\t\tfor _, x := range p {\n\t\t\tn = append(n, astNodeToString(x))\n\t\t}\n\t\tc.err(NewError(RecursionErr, loc, \"rule %v is recursive: %v\", astNodeToString(a), strings.Join(n, \" -> \")))\n\t}\n}\n\nfunc astNodeToString(x interface{}) string {\n\tswitch x := x.(type) {\n\tcase *Rule:\n\t\treturn string(x.Head.Name)\n\tdefault:\n\t\tpanic(\"not reached\")\n\t}\n}\n\n// checkRuleConflicts ensures that rules definitions are not in conflict.\nfunc (c *Compiler) checkRuleConflicts() {\n\tc.RuleTree.DepthFirst(func(node *TreeNode) bool {\n\t\tif len(node.Values) == 0 {\n\t\t\treturn false\n\t\t}\n\n\t\tkinds := map[DocKind]struct{}{}\n\t\tdefaultRules := 0\n\t\tarities := map[int]struct{}{}\n\n\t\tfor _, rule := range node.Values {\n\t\t\tr := rule.(*Rule)\n\t\t\tkinds[r.Head.DocKind()] = struct{}{}\n\t\t\tarities[len(r.Head.Args)] = struct{}{}\n\t\t\tif r.Default {\n\t\t\t\tdefaultRules++\n\t\t\t}\n\t\t}\n\n\t\tname := Var(node.Key.(String))\n\n\t\tif len(kinds) > 1 || len(arities) > 1 {\n\t\t\tc.err(NewError(TypeErr, node.Values[0].(*Rule).Loc(), \"conflicting rules named %v found\", name))\n\t\t} else if defaultRules > 1 {\n\t\t\tc.err(NewError(TypeErr, node.Values[0].(*Rule).Loc(), \"multiple default rules named %s found\", name))\n\t\t}\n\n\t\treturn false\n\t})\n\n\tif c.pathExists != nil {\n\t\tfor _, err := range CheckPathConflicts(c, c.pathExists) {\n\t\t\tc.err(err)\n\t\t}\n\t}\n\n\tc.ModuleTree.DepthFirst(func(node *ModuleTreeNode) bool {\n\t\tfor _, mod := range node.Modules {\n\t\t\tfor _, rule := range mod.Rules {\n\t\t\t\tif childNode, ok := node.Children[String(rule.Head.Name)]; ok {\n\t\t\t\t\tfor _, childMod := range childNode.Modules {\n\t\t\t\t\t\tmsg := fmt.Sprintf(\"%v conflicts with rule defined at %v\", childMod.Package, rule.Loc())\n\t\t\t\t\t\tc.err(NewError(TypeErr, mod.Package.Loc(), msg))\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn false\n\t})\n}\n\nfunc (c *Compiler) checkUndefinedFuncs() {\n\tfor _, name := range c.sorted {\n\t\tm := c.Modules[name]\n\t\tfor _, err := range checkUndefinedFuncs(c.TypeEnv, m, c.GetArity, c.RewrittenVars) {\n\t\t\tc.err(err)\n\t\t}\n\t}\n}\n\nfunc checkUndefinedFuncs(env *TypeEnv, x interface{}, arity func(Ref) int, rwVars map[Var]Var) Errors {\n\n\tvar errs Errors\n\n\tWalkExprs(x, func(expr *Expr) bool {\n\t\tif !expr.IsCall() {\n\t\t\treturn false\n\t\t}\n\t\tref := expr.Operator()\n\t\tif arity := arity(ref); arity >= 0 {\n\t\t\toperands := len(expr.Operands())\n\t\t\tif expr.Generated { // an output var was added\n\t\t\t\tif !expr.IsEquality() && operands != arity+1 {\n\t\t\t\t\tref = rewriteVarsInRef(rwVars)(ref)\n\t\t\t\t\terrs = append(errs, arityMismatchError(env, ref, expr, arity, operands-1))\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t} else { // either output var or not\n\t\t\t\tif operands != arity && operands != arity+1 {\n\t\t\t\t\tref = rewriteVarsInRef(rwVars)(ref)\n\t\t\t\t\terrs = append(errs, arityMismatchError(env, ref, expr, arity, operands))\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn false\n\t\t}\n\t\tref = rewriteVarsInRef(rwVars)(ref)\n\t\terrs = append(errs, NewError(TypeErr, expr.Loc(), \"undefined function %v\", ref))\n\t\treturn true\n\t})\n\n\treturn errs\n}\n\nfunc arityMismatchError(env *TypeEnv, f Ref, expr *Expr, exp, act int) *Error {\n\tif want, ok := env.Get(f).(*types.Function); ok { // generate richer error for built-in functions\n\t\thave := make([]types.Type, len(expr.Operands()))\n\t\tfor i, op := range expr.Operands() {\n\t\t\thave[i] = env.Get(op)\n\t\t}\n\t\treturn newArgError(expr.Loc(), f, \"arity mismatch\", have, want.NamedFuncArgs())\n\t}\n\tif act != 1 {\n\t\treturn NewError(TypeErr, expr.Loc(), \"function %v has arity %d, got %d arguments\", f, exp, act)\n\t}\n\treturn NewError(TypeErr, expr.Loc(), \"function %v has arity %d, got %d argument\", f, exp, act)\n}\n\n// checkSafetyRuleBodies ensures that variables appearing in negated expressions or non-target\n// positions of built-in expressions will be bound when evaluating the rule from left\n// to right, re-ordering as necessary.\nfunc (c *Compiler) checkSafetyRuleBodies() {\n\tfor _, name := range c.sorted {\n\t\tm := c.Modules[name]\n\t\tWalkRules(m, func(r *Rule) bool {\n\t\t\tsafe := ReservedVars.Copy()\n\t\t\tsafe.Update(r.Head.Args.Vars())\n\t\t\tr.Body = c.checkBodySafety(safe, r.Body)\n\t\t\treturn false\n\t\t})\n\t}\n}\n\nfunc (c *Compiler) checkBodySafety(safe VarSet, b Body) Body {\n\treordered, unsafe := reorderBodyForSafety(c.builtins, c.GetArity, safe, b)\n\tif errs := safetyErrorSlice(unsafe, c.RewrittenVars); len(errs) > 0 {\n\t\tfor _, err := range errs {\n\t\t\tc.err(err)\n\t\t}\n\t\treturn b\n\t}\n\treturn reordered\n}\n\n// SafetyCheckVisitorParams defines the AST visitor parameters to use for collecting\n// variables during the safety check. This has to be exported because it's relied on\n// by the copy propagation implementation in topdown.\nvar SafetyCheckVisitorParams = VarVisitorParams{\n\tSkipRefCallHead: true,\n\tSkipClosures:    true,\n}\n\n// checkSafetyRuleHeads ensures that variables appearing in the head of a\n// rule also appear in the body.\nfunc (c *Compiler) checkSafetyRuleHeads() {\n\n\tfor _, name := range c.sorted {\n\t\tm := c.Modules[name]\n\t\tWalkRules(m, func(r *Rule) bool {\n\t\t\tsafe := r.Body.Vars(SafetyCheckVisitorParams)\n\t\t\tsafe.Update(r.Head.Args.Vars())\n\t\t\tunsafe := r.Head.Vars().Diff(safe)\n\t\t\tfor v := range unsafe {\n\t\t\t\tif w, ok := c.RewrittenVars[v]; ok {\n\t\t\t\t\tv = w\n\t\t\t\t}\n\t\t\t\tif !v.IsGenerated() {\n\t\t\t\t\tc.err(NewError(UnsafeVarErr, r.Loc(), \"var %v is unsafe\", v))\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn false\n\t\t})\n\t}\n}\n\nfunc compileSchema(goSchema interface{}, allowNet []string) (*gojsonschema.Schema, error) {\n\tgojsonschema.SetAllowNet(allowNet)\n\n\tvar refLoader gojsonschema.JSONLoader\n\tsl := gojsonschema.NewSchemaLoader()\n\n\tif goSchema != nil {\n\t\trefLoader = gojsonschema.NewGoLoader(goSchema)\n\t} else {\n\t\treturn nil, fmt.Errorf(\"no schema as input to compile\")\n\t}\n\tschemasCompiled, err := sl.Compile(refLoader)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"unable to compile the schema: %w\", err)\n\t}\n\treturn schemasCompiled, nil\n}\n\nfunc mergeSchemas(schemas ...*gojsonschema.SubSchema) (*gojsonschema.SubSchema, error) {\n\tif len(schemas) == 0 {\n\t\treturn nil, nil\n\t}\n\tvar result = schemas[0]\n\n\tfor i := range schemas {\n\t\tif len(schemas[i].PropertiesChildren) > 0 {\n\t\t\tif !schemas[i].Types.Contains(\"object\") {\n\t\t\t\tif err := schemas[i].Types.Add(\"object\"); err != nil {\n\t\t\t\t\treturn nil, fmt.Errorf(\"unable to set the type in schemas\")\n\t\t\t\t}\n\t\t\t}\n\t\t} else if len(schemas[i].ItemsChildren) > 0 {\n\t\t\tif !schemas[i].Types.Contains(\"array\") {\n\t\t\t\tif err := schemas[i].Types.Add(\"array\"); err != nil {\n\t\t\t\t\treturn nil, fmt.Errorf(\"unable to set the type in schemas\")\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor i := 1; i < len(schemas); i++ {\n\t\tif result.Types.String() != schemas[i].Types.String() {\n\t\t\treturn nil, fmt.Errorf(\"unable to merge these schemas: type mismatch: %v and %v\", result.Types.String(), schemas[i].Types.String())\n\t\t} else if result.Types.Contains(\"object\") && len(result.PropertiesChildren) > 0 && schemas[i].Types.Contains(\"object\") && len(schemas[i].PropertiesChildren) > 0 {\n\t\t\tresult.PropertiesChildren = append(result.PropertiesChildren, schemas[i].PropertiesChildren...)\n\t\t} else if result.Types.Contains(\"array\") && len(result.ItemsChildren) > 0 && schemas[i].Types.Contains(\"array\") && len(schemas[i].ItemsChildren) > 0 {\n\t\t\tfor j := 0; j < len(schemas[i].ItemsChildren); j++ {\n\t\t\t\tif len(result.ItemsChildren)-1 < j && !(len(schemas[i].ItemsChildren)-1 < j) {\n\t\t\t\t\tresult.ItemsChildren = append(result.ItemsChildren, schemas[i].ItemsChildren[j])\n\t\t\t\t}\n\t\t\t\tif result.ItemsChildren[j].Types.String() != schemas[i].ItemsChildren[j].Types.String() {\n\t\t\t\t\treturn nil, fmt.Errorf(\"unable to merge these schemas\")\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn result, nil\n}\n\nfunc parseSchema(schema interface{}) (types.Type, error) {\n\tsubSchema, ok := schema.(*gojsonschema.SubSchema)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"unexpected schema type %v\", subSchema)\n\t}\n\n\t// Handle referenced schemas, returns directly when a $ref is found\n\tif subSchema.RefSchema != nil {\n\t\treturn parseSchema(subSchema.RefSchema)\n\t}\n\n\t// Handle anyOf\n\tif subSchema.AnyOf != nil {\n\t\tvar orType types.Type\n\n\t\t// If there is a core schema, find its type first\n\t\tif subSchema.Types.IsTyped() {\n\t\t\tcopySchema := *subSchema\n\t\t\tcopySchemaRef := &copySchema\n\t\t\tcopySchemaRef.AnyOf = nil\n\t\t\tcoreType, err := parseSchema(copySchemaRef)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"unexpected schema type %v: %w\", subSchema, err)\n\t\t\t}\n\n\t\t\t// Only add Object type with static props to orType\n\t\t\tif objType, ok := coreType.(*types.Object); ok {\n\t\t\t\tif objType.StaticProperties() != nil && objType.DynamicProperties() == nil {\n\t\t\t\t\torType = types.Or(orType, coreType)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Iterate through every property of AnyOf and add it to orType\n\t\tfor _, pSchema := range subSchema.AnyOf {\n\t\t\tnewtype, err := parseSchema(pSchema)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"unexpected schema type %v: %w\", pSchema, err)\n\t\t\t}\n\t\t\torType = types.Or(newtype, orType)\n\t\t}\n\n\t\treturn orType, nil\n\t}\n\n\tif subSchema.AllOf != nil {\n\t\tsubSchemaArray := subSchema.AllOf\n\t\tallOfResult, err := mergeSchemas(subSchemaArray...)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tif subSchema.Types.IsTyped() {\n\t\t\tif (subSchema.Types.Contains(\"object\") && allOfResult.Types.Contains(\"object\")) || (subSchema.Types.Contains(\"array\") && allOfResult.Types.Contains(\"array\")) {\n\t\t\t\tobjectOrArrayResult, err := mergeSchemas(allOfResult, subSchema)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\treturn parseSchema(objectOrArrayResult)\n\t\t\t} else if subSchema.Types.String() != allOfResult.Types.String() {\n\t\t\t\treturn nil, fmt.Errorf(\"unable to merge these schemas\")\n\t\t\t}\n\t\t}\n\t\treturn parseSchema(allOfResult)\n\t}\n\n\tif subSchema.Types.IsTyped() {\n\t\tif subSchema.Types.Contains(\"boolean\") {\n\t\t\treturn types.B, nil\n\n\t\t} else if subSchema.Types.Contains(\"string\") {\n\t\t\treturn types.S, nil\n\n\t\t} else if subSchema.Types.Contains(\"integer\") || subSchema.Types.Contains(\"number\") {\n\t\t\treturn types.N, nil\n\n\t\t} else if subSchema.Types.Contains(\"object\") {\n\t\t\tif len(subSchema.PropertiesChildren) > 0 {\n\t\t\t\tstaticProps := make([]*types.StaticProperty, 0, len(subSchema.PropertiesChildren))\n\t\t\t\tfor _, pSchema := range subSchema.PropertiesChildren {\n\t\t\t\t\tnewtype, err := parseSchema(pSchema)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, fmt.Errorf(\"unexpected schema type %v: %w\", pSchema, err)\n\t\t\t\t\t}\n\t\t\t\t\tstaticProps = append(staticProps, types.NewStaticProperty(pSchema.Property, newtype))\n\t\t\t\t}\n\t\t\t\treturn types.NewObject(staticProps, nil), nil\n\t\t\t}\n\t\t\treturn types.NewObject(nil, types.NewDynamicProperty(types.A, types.A)), nil\n\n\t\t} else if subSchema.Types.Contains(\"array\") {\n\t\t\tif len(subSchema.ItemsChildren) > 0 {\n\t\t\t\tif subSchema.ItemsChildrenIsSingleSchema {\n\t\t\t\t\tiSchema := subSchema.ItemsChildren[0]\n\t\t\t\t\tnewtype, err := parseSchema(iSchema)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, fmt.Errorf(\"unexpected schema type %v\", iSchema)\n\t\t\t\t\t}\n\t\t\t\t\treturn types.NewArray(nil, newtype), nil\n\t\t\t\t}\n\t\t\t\tnewTypes := make([]types.Type, 0, len(subSchema.ItemsChildren))\n\t\t\t\tfor i := 0; i != len(subSchema.ItemsChildren); i++ {\n\t\t\t\t\tiSchema := subSchema.ItemsChildren[i]\n\t\t\t\t\tnewtype, err := parseSchema(iSchema)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, fmt.Errorf(\"unexpected schema type %v\", iSchema)\n\t\t\t\t\t}\n\t\t\t\t\tnewTypes = append(newTypes, newtype)\n\t\t\t\t}\n\t\t\t\treturn types.NewArray(newTypes, nil), nil\n\t\t\t}\n\t\t\treturn types.NewArray(nil, types.A), nil\n\t\t}\n\t}\n\n\t// Assume types if not specified in schema\n\tif len(subSchema.PropertiesChildren) > 0 {\n\t\tif err := subSchema.Types.Add(\"object\"); err == nil {\n\t\t\treturn parseSchema(subSchema)\n\t\t}\n\t} else if len(subSchema.ItemsChildren) > 0 {\n\t\tif err := subSchema.Types.Add(\"array\"); err == nil {\n\t\t\treturn parseSchema(subSchema)\n\t\t}\n\t}\n\n\treturn types.A, nil\n}\n\nfunc (c *Compiler) setAnnotationSet() {\n\t// Sorting modules by name for stable error reporting\n\tsorted := make([]*Module, 0, len(c.Modules))\n\tfor _, mName := range c.sorted {\n\t\tsorted = append(sorted, c.Modules[mName])\n\t}\n\n\tas, errs := BuildAnnotationSet(sorted)\n\tfor _, err := range errs {\n\t\tc.err(err)\n\t}\n\tc.annotationSet = as\n}\n\n// checkTypes runs the type checker on all rules. The type checker builds a\n// TypeEnv that is stored on the compiler.\nfunc (c *Compiler) checkTypes() {\n\t// Recursion is caught in earlier step, so this cannot fail.\n\tsorted, _ := c.Graph.Sort()\n\tchecker := newTypeChecker().\n\t\tWithSchemaSet(c.schemaSet).\n\t\tWithInputType(c.inputType).\n\t\tWithVarRewriter(rewriteVarsInRef(c.RewrittenVars))\n\tenv, errs := checker.CheckTypes(c.TypeEnv, sorted, c.annotationSet)\n\tfor _, err := range errs {\n\t\tc.err(err)\n\t}\n\tc.TypeEnv = env\n}\n\nfunc (c *Compiler) checkUnsafeBuiltins() {\n\tfor _, name := range c.sorted {\n\t\terrs := checkUnsafeBuiltins(c.unsafeBuiltinsMap, c.Modules[name])\n\t\tfor _, err := range errs {\n\t\t\tc.err(err)\n\t\t}\n\t}\n}\n\nfunc (c *Compiler) checkDeprecatedBuiltins() {\n\tfor _, name := range c.sorted {\n\t\terrs := checkDeprecatedBuiltins(c.deprecatedBuiltinsMap, c.Modules[name], c.strict)\n\t\tfor _, err := range errs {\n\t\t\tc.err(err)\n\t\t}\n\t}\n}\n\nfunc (c *Compiler) runStage(metricName string, f func()) {\n\tif c.metrics != nil {\n\t\tc.metrics.Timer(metricName).Start()\n\t\tdefer c.metrics.Timer(metricName).Stop()\n\t}\n\tf()\n}\n\nfunc (c *Compiler) runStageAfter(metricName string, s CompilerStage) *Error {\n\tif c.metrics != nil {\n\t\tc.metrics.Timer(metricName).Start()\n\t\tdefer c.metrics.Timer(metricName).Stop()\n\t}\n\treturn s(c)\n}\n\nfunc (c *Compiler) compile() {\n\n\tdefer func() {\n\t\tif r := recover(); r != nil && r != errLimitReached {\n\t\t\tpanic(r)\n\t\t}\n\t}()\n\n\tfor _, s := range c.stages {\n\t\tc.runStage(s.metricName, s.f)\n\t\tif c.Failed() {\n\t\t\treturn\n\t\t}\n\t\tfor _, a := range c.after[s.name] {\n\t\t\tif err := c.runStageAfter(a.MetricName, a.Stage); err != nil {\n\t\t\t\tc.err(err)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc (c *Compiler) init() {\n\n\tif c.initialized {\n\t\treturn\n\t}\n\n\tif c.capabilities == nil {\n\t\tc.capabilities = CapabilitiesForThisVersion()\n\t}\n\n\tc.builtins = make(map[string]*Builtin, len(c.capabilities.Builtins)+len(c.customBuiltins))\n\n\tfor _, bi := range c.capabilities.Builtins {\n\t\tc.builtins[bi.Name] = bi\n\t\tif c.strict && bi.IsDeprecated() {\n\t\t\tc.deprecatedBuiltinsMap[bi.Name] = struct{}{}\n\t\t}\n\t}\n\n\tfor name, bi := range c.customBuiltins {\n\t\tc.builtins[name] = bi\n\t}\n\n\t// Load the global input schema if one was provided.\n\tif c.schemaSet != nil {\n\t\tif schema := c.schemaSet.Get(SchemaRootRef); schema != nil {\n\t\t\ttpe, err := loadSchema(schema, c.capabilities.AllowNet)\n\t\t\tif err != nil {\n\t\t\t\tc.err(NewError(TypeErr, nil, err.Error()))\n\t\t\t} else {\n\t\t\t\tc.inputType = tpe\n\t\t\t}\n\t\t}\n\t}\n\n\tc.TypeEnv = newTypeChecker().\n\t\tWithSchemaSet(c.schemaSet).\n\t\tWithInputType(c.inputType).\n\t\tEnv(c.builtins)\n\n\tc.initialized = true\n}\n\nfunc (c *Compiler) err(err *Error) {\n\tif c.maxErrs > 0 && len(c.Errors) >= c.maxErrs {\n\t\tc.Errors = append(c.Errors, errLimitReached)\n\t\tpanic(errLimitReached)\n\t}\n\tc.Errors = append(c.Errors, err)\n}\n\nfunc (c *Compiler) getExports() *util.HashMap {\n\n\trules := util.NewHashMap(func(a, b util.T) bool {\n\t\treturn a.(Ref).Equal(b.(Ref))\n\t}, func(v util.T) int {\n\t\treturn v.(Ref).Hash()\n\t})\n\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\trv, ok := rules.Get(mod.Package.Path)\n\t\tif !ok {\n\t\t\trv = []Var{}\n\t\t}\n\t\trvs := rv.([]Var)\n\n\t\tfor _, rule := range mod.Rules {\n\t\t\trvs = append(rvs, rule.Head.Name)\n\t\t}\n\t\trules.Put(mod.Package.Path, rvs)\n\t}\n\n\treturn rules\n}\n\nfunc (c *Compiler) GetAnnotationSet() *AnnotationSet {\n\treturn c.annotationSet\n}\n\nfunc (c *Compiler) checkDuplicateImports() {\n\tif !c.strict {\n\t\treturn\n\t}\n\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\tprocessedImports := map[Var]*Import{}\n\n\t\tfor _, imp := range mod.Imports {\n\t\t\tname := imp.Name()\n\n\t\t\tif processed, conflict := processedImports[name]; conflict {\n\t\t\t\tc.err(NewError(CompileErr, imp.Location, \"import must not shadow %v\", processed))\n\t\t\t} else {\n\t\t\t\tprocessedImports[name] = imp\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc (c *Compiler) checkKeywordOverrides() {\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\terrs := checkKeywordOverrides(mod, c.strict)\n\t\tfor _, err := range errs {\n\t\t\tc.err(err)\n\t\t}\n\t}\n}\n\nfunc checkKeywordOverrides(node interface{}, strict bool) Errors {\n\tif !strict {\n\t\treturn nil\n\t}\n\n\terrors := Errors{}\n\n\tWalkRules(node, func(rule *Rule) bool {\n\t\tname := rule.Head.Name.String()\n\t\tif RootDocumentRefs.Contains(RefTerm(VarTerm(name))) {\n\t\t\terrors = append(errors, NewError(CompileErr, rule.Location, \"rules must not shadow %v (use a different rule name)\", name))\n\t\t}\n\t\treturn true\n\t})\n\n\tWalkExprs(node, func(expr *Expr) bool {\n\t\tif expr.IsAssignment() {\n\t\t\tname := expr.Operand(0).String()\n\t\t\tif RootDocumentRefs.Contains(RefTerm(VarTerm(name))) {\n\t\t\t\terrors = append(errors, NewError(CompileErr, expr.Location, \"variables must not shadow %v (use a different variable name)\", name))\n\t\t\t}\n\t\t}\n\t\treturn false\n\t})\n\n\treturn errors\n}\n\n// resolveAllRefs resolves references in expressions to their fully qualified values.\n//\n// For instance, given the following module:\n//\n// package a.b\n// import data.foo.bar\n// p[x] { bar[_] = x }\n//\n// The reference \"bar[_]\" would be resolved to \"data.foo.bar[_]\".\nfunc (c *Compiler) resolveAllRefs() {\n\n\trules := c.getExports()\n\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\n\t\tvar ruleExports []Var\n\t\tif x, ok := rules.Get(mod.Package.Path); ok {\n\t\t\truleExports = x.([]Var)\n\t\t}\n\n\t\tglobals := getGlobals(mod.Package, ruleExports, mod.Imports)\n\n\t\tWalkRules(mod, func(rule *Rule) bool {\n\t\t\terr := resolveRefsInRule(globals, rule)\n\t\t\tif err != nil {\n\t\t\t\tc.err(NewError(CompileErr, rule.Location, err.Error()))\n\t\t\t}\n\t\t\treturn false\n\t\t})\n\n\t\tif c.strict { // check for unused imports\n\t\t\tfor _, imp := range mod.Imports {\n\t\t\t\tpath := imp.Path.Value.(Ref)\n\t\t\t\tif FutureRootDocument.Equal(path[0]) {\n\t\t\t\t\tcontinue // ignore future imports\n\t\t\t\t}\n\n\t\t\t\tfor v, u := range globals {\n\t\t\t\t\tif v.Equal(imp.Name()) && !u.used {\n\t\t\t\t\t\tc.err(NewError(CompileErr, imp.Location, \"%s unused\", imp.String()))\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif c.moduleLoader != nil {\n\n\t\tparsed, err := c.moduleLoader(c.Modules)\n\t\tif err != nil {\n\t\t\tc.err(NewError(CompileErr, nil, err.Error()))\n\t\t\treturn\n\t\t}\n\n\t\tif len(parsed) == 0 {\n\t\t\treturn\n\t\t}\n\n\t\tfor id, module := range parsed {\n\t\t\tc.Modules[id] = module.Copy()\n\t\t\tc.sorted = append(c.sorted, id)\n\t\t\tif c.parsedModules != nil {\n\t\t\t\tc.parsedModules[id] = module\n\t\t\t}\n\t\t}\n\n\t\tsort.Strings(c.sorted)\n\t\tc.resolveAllRefs()\n\t}\n}\n\nfunc (c *Compiler) removeImports() {\n\tfor name := range c.Modules {\n\t\tc.Modules[name].Imports = nil\n\t}\n}\n\nfunc (c *Compiler) initLocalVarGen() {\n\tc.localvargen = newLocalVarGeneratorForModuleSet(c.sorted, c.Modules)\n}\n\nfunc (c *Compiler) rewriteComprehensionTerms() {\n\tf := newEqualityFactory(c.localvargen)\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\t_, _ = rewriteComprehensionTerms(f, mod) // ignore error\n\t}\n}\n\nfunc (c *Compiler) rewriteExprTerms() {\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\tWalkRules(mod, func(rule *Rule) bool {\n\t\t\trewriteExprTermsInHead(c.localvargen, rule)\n\t\t\trule.Body = rewriteExprTermsInBody(c.localvargen, rule.Body)\n\t\t\treturn false\n\t\t})\n\t}\n}\n\nfunc (c *Compiler) checkVoidCalls() {\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\tfor _, err := range checkVoidCalls(c.TypeEnv, mod) {\n\t\t\tc.err(err)\n\t\t}\n\t}\n}\n\nfunc (c *Compiler) rewritePrintCalls() {\n\tif !c.enablePrintStatements {\n\t\tfor _, name := range c.sorted {\n\t\t\terasePrintCalls(c.Modules[name])\n\t\t}\n\t\treturn\n\t}\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\tWalkRules(mod, func(r *Rule) bool {\n\t\t\tsafe := r.Head.Args.Vars()\n\t\t\tsafe.Update(ReservedVars)\n\t\t\tvis := func(b Body) bool {\n\t\t\t\tfor _, err := range rewritePrintCalls(c.localvargen, c.GetArity, safe, b) {\n\t\t\t\t\tc.err(err)\n\t\t\t\t}\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tWalkBodies(r.Head, vis)\n\t\t\tWalkBodies(r.Body, vis)\n\t\t\treturn false\n\t\t})\n\t}\n}\n\n// checkVoidCalls returns errors for any expressions that treat void function\n// calls as values. The only void functions in Rego are specific built-ins like\n// print().\nfunc checkVoidCalls(env *TypeEnv, x interface{}) Errors {\n\tvar errs Errors\n\tWalkTerms(x, func(x *Term) bool {\n\t\tif call, ok := x.Value.(Call); ok {\n\t\t\tif tpe, ok := env.Get(call[0]).(*types.Function); ok && tpe.Result() == nil {\n\t\t\t\terrs = append(errs, NewError(TypeErr, x.Loc(), \"%v used as value\", call))\n\t\t\t}\n\t\t}\n\t\treturn false\n\t})\n\treturn errs\n}\n\n// rewritePrintCalls will rewrite the body so that print operands are captured\n// in local variables and their evaluation occurs within a comprehension.\n// Wrapping the terms inside of a comprehension ensures that undefined values do\n// not short-circuit evaluation.\n//\n// For example, given the following print statement:\n//\n//   print(\"the value of x is:\", input.x)\n//\n// The expression would be rewritten to:\n//\n//   print({__local0__ | __local0__ = \"the value of x is:\"}, {__local1__ | __local1__ = input.x})\nfunc rewritePrintCalls(gen *localVarGenerator, getArity func(Ref) int, globals VarSet, body Body) Errors {\n\n\tvar errs Errors\n\n\t// Visit comprehension bodies recursively to ensure print statements inside\n\t// those bodies only close over variables that are safe.\n\tfor i := range body {\n\t\tif ContainsClosures(body[i]) {\n\t\t\tsafe := outputVarsForBody(body[:i], getArity, globals)\n\t\t\tsafe.Update(globals)\n\t\t\tWalkClosures(body[i], func(x interface{}) bool {\n\t\t\t\tswitch x := x.(type) {\n\t\t\t\tcase *SetComprehension:\n\t\t\t\t\terrs = rewritePrintCalls(gen, getArity, safe, x.Body)\n\t\t\t\tcase *ArrayComprehension:\n\t\t\t\t\terrs = rewritePrintCalls(gen, getArity, safe, x.Body)\n\t\t\t\tcase *ObjectComprehension:\n\t\t\t\t\terrs = rewritePrintCalls(gen, getArity, safe, x.Body)\n\t\t\t\tcase *Every:\n\t\t\t\t\tsafe.Update(x.KeyValueVars())\n\t\t\t\t\terrs = rewritePrintCalls(gen, getArity, safe, x.Body)\n\t\t\t\t}\n\t\t\t\treturn true\n\t\t\t})\n\t\t\tif len(errs) > 0 {\n\t\t\t\treturn errs\n\t\t\t}\n\t\t}\n\t}\n\n\tfor i := range body {\n\n\t\tif !isPrintCall(body[i]) {\n\t\t\tcontinue\n\t\t}\n\n\t\tvar errs Errors\n\t\tsafe := outputVarsForBody(body[:i], getArity, globals)\n\t\tsafe.Update(globals)\n\t\targs := body[i].Operands()\n\n\t\tfor j := range args {\n\t\t\tvis := NewVarVisitor().WithParams(SafetyCheckVisitorParams)\n\t\t\tvis.Walk(args[j])\n\t\t\tunsafe := vis.Vars().Diff(safe)\n\t\t\tfor _, v := range unsafe.Sorted() {\n\t\t\t\terrs = append(errs, NewError(CompileErr, args[j].Loc(), \"var %v is undeclared\", v))\n\t\t\t}\n\t\t}\n\n\t\tif len(errs) > 0 {\n\t\t\treturn errs\n\t\t}\n\n\t\tarr := NewArray()\n\n\t\tfor j := range args {\n\t\t\tx := NewTerm(gen.Generate()).SetLocation(args[j].Loc())\n\t\t\tcapture := Equality.Expr(x, args[j]).SetLocation(args[j].Loc())\n\t\t\tarr = arr.Append(SetComprehensionTerm(x, NewBody(capture)).SetLocation(args[j].Loc()))\n\t\t}\n\n\t\tbody.Set(NewExpr([]*Term{\n\t\t\tNewTerm(InternalPrint.Ref()).SetLocation(body[i].Loc()),\n\t\t\tNewTerm(arr).SetLocation(body[i].Loc()),\n\t\t}).SetLocation(body[i].Loc()), i)\n\t}\n\n\treturn nil\n}\n\nfunc erasePrintCalls(node interface{}) {\n\tNewGenericVisitor(func(x interface{}) bool {\n\t\tswitch x := x.(type) {\n\t\tcase *Rule:\n\t\t\tx.Body = erasePrintCallsInBody(x.Body)\n\t\tcase *ArrayComprehension:\n\t\t\tx.Body = erasePrintCallsInBody(x.Body)\n\t\tcase *SetComprehension:\n\t\t\tx.Body = erasePrintCallsInBody(x.Body)\n\t\tcase *ObjectComprehension:\n\t\t\tx.Body = erasePrintCallsInBody(x.Body)\n\t\tcase *Every:\n\t\t\tx.Body = erasePrintCallsInBody(x.Body)\n\t\t}\n\t\treturn false\n\t}).Walk(node)\n}\n\nfunc erasePrintCallsInBody(x Body) Body {\n\n\tif !containsPrintCall(x) {\n\t\treturn x\n\t}\n\n\tvar cpy Body\n\n\tfor i := range x {\n\n\t\t// Recursively visit any comprehensions contained in this expression.\n\t\terasePrintCalls(x[i])\n\n\t\tif !isPrintCall(x[i]) {\n\t\t\tcpy.Append(x[i])\n\t\t}\n\t}\n\n\tif len(cpy) == 0 {\n\t\tterm := BooleanTerm(true).SetLocation(x.Loc())\n\t\texpr := NewExpr(term).SetLocation(x.Loc())\n\t\tcpy.Append(expr)\n\t}\n\n\treturn cpy\n}\n\nfunc containsPrintCall(x Body) bool {\n\tvar found bool\n\tWalkExprs(x, func(expr *Expr) bool {\n\t\tif !found {\n\t\t\tif isPrintCall(expr) {\n\t\t\t\tfound = true\n\t\t\t}\n\t\t}\n\t\treturn found\n\t})\n\treturn found\n}\n\nfunc isPrintCall(x *Expr) bool {\n\treturn x.IsCall() && x.Operator().Equal(Print.Ref())\n}\n\n// rewriteTermsInHead will rewrite rules so that the head does not contain any\n// terms that require evaluation (e.g., refs or comprehensions). If the key or\n// value contains one or more of these terms, the key or value will be moved\n// into the body and assigned to a new variable. The new variable will replace\n// the key or value in the head.\n//\n// For instance, given the following rule:\n//\n// p[{\"foo\": data.foo[i]}] { i < 100 }\n//\n// The rule would be re-written as:\n//\n// p[__local0__] { i < 100; __local0__ = {\"foo\": data.foo[i]} }\nfunc (c *Compiler) rewriteRefsInHead() {\n\tf := newEqualityFactory(c.localvargen)\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\tWalkRules(mod, func(rule *Rule) bool {\n\t\t\tif requiresEval(rule.Head.Key) {\n\t\t\t\texpr := f.Generate(rule.Head.Key)\n\t\t\t\trule.Head.Key = expr.Operand(0)\n\t\t\t\trule.Body.Append(expr)\n\t\t\t}\n\t\t\tif requiresEval(rule.Head.Value) {\n\t\t\t\texpr := f.Generate(rule.Head.Value)\n\t\t\t\trule.Head.Value = expr.Operand(0)\n\t\t\t\trule.Body.Append(expr)\n\t\t\t}\n\t\t\tfor i := 0; i < len(rule.Head.Args); i++ {\n\t\t\t\tif requiresEval(rule.Head.Args[i]) {\n\t\t\t\t\texpr := f.Generate(rule.Head.Args[i])\n\t\t\t\t\trule.Head.Args[i] = expr.Operand(0)\n\t\t\t\t\trule.Body.Append(expr)\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn false\n\t\t})\n\t}\n}\n\nfunc (c *Compiler) rewriteEquals() {\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\trewriteEquals(mod)\n\t}\n}\n\nfunc (c *Compiler) rewriteDynamicTerms() {\n\tf := newEqualityFactory(c.localvargen)\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\tWalkRules(mod, func(rule *Rule) bool {\n\t\t\trule.Body = rewriteDynamics(f, rule.Body)\n\t\t\treturn false\n\t\t})\n\t}\n}\n\nfunc (c *Compiler) parseMetadataBlocks() {\n\t// Only parse annotations if rego.metadata built-ins are called\n\tregoMetadataCalled := false\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\tWalkExprs(mod, func(expr *Expr) bool {\n\t\t\tif isRegoMetadataChainCall(expr) || isRegoMetadataRuleCall(expr) {\n\t\t\t\tregoMetadataCalled = true\n\t\t\t}\n\t\t\treturn regoMetadataCalled\n\t\t})\n\n\t\tif regoMetadataCalled {\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif regoMetadataCalled {\n\t\t// NOTE: Possible optimization: only parse annotations for modules on the path of rego.metadata-calling module\n\t\tfor _, name := range c.sorted {\n\t\t\tmod := c.Modules[name]\n\n\t\t\tif len(mod.Annotations) == 0 {\n\t\t\t\tvar errs Errors\n\t\t\t\tmod.Annotations, errs = parseAnnotations(mod.Comments)\n\t\t\t\terrs = append(errs, attachAnnotationsNodes(mod)...)\n\t\t\t\tfor _, err := range errs {\n\t\t\t\t\tc.err(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc (c *Compiler) rewriteRegoMetadataCalls() {\n\teqFactory := newEqualityFactory(c.localvargen)\n\n\t_, chainFuncAllowed := c.builtins[RegoMetadataChain.Name]\n\t_, ruleFuncAllowed := c.builtins[RegoMetadataRule.Name]\n\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\n\t\tWalkRules(mod, func(rule *Rule) bool {\n\t\t\tvar firstChainCall *Expr\n\t\t\tvar firstRuleCall *Expr\n\n\t\t\tWalkExprs(rule, func(expr *Expr) bool {\n\t\t\t\tif chainFuncAllowed && firstChainCall == nil && isRegoMetadataChainCall(expr) {\n\t\t\t\t\tfirstChainCall = expr\n\t\t\t\t} else if ruleFuncAllowed && firstRuleCall == nil && isRegoMetadataRuleCall(expr) {\n\t\t\t\t\tfirstRuleCall = expr\n\t\t\t\t}\n\t\t\t\treturn firstChainCall != nil && firstRuleCall != nil\n\t\t\t})\n\n\t\t\tchainCalled := firstChainCall != nil\n\t\t\truleCalled := firstRuleCall != nil\n\n\t\t\tif chainCalled || ruleCalled {\n\t\t\t\tbody := make(Body, 0, len(rule.Body)+2)\n\n\t\t\t\tvar metadataChainVar Var\n\t\t\t\tif chainCalled {\n\t\t\t\t\t// Create and inject metadata chain for rule\n\n\t\t\t\t\tchain, err := createMetadataChain(c.annotationSet.Chain(rule))\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tc.err(err)\n\t\t\t\t\t\treturn false\n\t\t\t\t\t}\n\n\t\t\t\t\tchain.Location = firstChainCall.Location\n\t\t\t\t\teq := eqFactory.Generate(chain)\n\t\t\t\t\tmetadataChainVar = eq.Operands()[0].Value.(Var)\n\t\t\t\t\tbody.Append(eq)\n\t\t\t\t}\n\n\t\t\t\tvar metadataRuleVar Var\n\t\t\t\tif ruleCalled {\n\t\t\t\t\t// Create and inject metadata for rule\n\n\t\t\t\t\tvar metadataRuleTerm *Term\n\n\t\t\t\t\ta := getPrimaryRuleAnnotations(c.annotationSet, rule)\n\t\t\t\t\tif a != nil {\n\t\t\t\t\t\tannotObj, err := a.toObject()\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\tc.err(err)\n\t\t\t\t\t\t\treturn false\n\t\t\t\t\t\t}\n\t\t\t\t\t\tmetadataRuleTerm = NewTerm(*annotObj)\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// If rule has no annotations, assign an empty object\n\t\t\t\t\t\tmetadataRuleTerm = ObjectTerm()\n\t\t\t\t\t}\n\n\t\t\t\t\tmetadataRuleTerm.Location = firstRuleCall.Location\n\t\t\t\t\teq := eqFactory.Generate(metadataRuleTerm)\n\t\t\t\t\tmetadataRuleVar = eq.Operands()[0].Value.(Var)\n\t\t\t\t\tbody.Append(eq)\n\t\t\t\t}\n\n\t\t\t\tfor _, expr := range rule.Body {\n\t\t\t\t\tbody.Append(expr)\n\t\t\t\t}\n\t\t\t\trule.Body = body\n\n\t\t\t\tvis := func(b Body) bool {\n\t\t\t\t\tfor _, err := range rewriteRegoMetadataCalls(&metadataChainVar, &metadataRuleVar, b, &c.RewrittenVars) {\n\t\t\t\t\t\tc.err(err)\n\t\t\t\t\t}\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t\tWalkBodies(rule.Head, vis)\n\t\t\t\tWalkBodies(rule.Body, vis)\n\t\t\t}\n\n\t\t\treturn false\n\t\t})\n\t}\n}\n\nfunc getPrimaryRuleAnnotations(as *AnnotationSet, rule *Rule) *Annotations {\n\tannots := as.GetRuleScope(rule)\n\n\tif len(annots) == 0 {\n\t\treturn nil\n\t}\n\n\t// Sort by annotation location; chain must start with annotations declared closest to rule, then going outward\n\tsort.SliceStable(annots, func(i, j int) bool {\n\t\treturn annots[i].Location.Compare(annots[j].Location) > 0\n\t})\n\n\treturn annots[0]\n}\n\nfunc rewriteRegoMetadataCalls(metadataChainVar *Var, metadataRuleVar *Var, body Body, rewrittenVars *map[Var]Var) Errors {\n\tvar errs Errors\n\n\tWalkClosures(body, func(x interface{}) bool {\n\t\tswitch x := x.(type) {\n\t\tcase *ArrayComprehension:\n\t\t\terrs = rewriteRegoMetadataCalls(metadataChainVar, metadataRuleVar, x.Body, rewrittenVars)\n\t\tcase *SetComprehension:\n\t\t\terrs = rewriteRegoMetadataCalls(metadataChainVar, metadataRuleVar, x.Body, rewrittenVars)\n\t\tcase *ObjectComprehension:\n\t\t\terrs = rewriteRegoMetadataCalls(metadataChainVar, metadataRuleVar, x.Body, rewrittenVars)\n\t\tcase *Every:\n\t\t\terrs = rewriteRegoMetadataCalls(metadataChainVar, metadataRuleVar, x.Body, rewrittenVars)\n\t\t}\n\t\treturn true\n\t})\n\n\tfor i := range body {\n\t\texpr := body[i]\n\t\tvar metadataVar Var\n\n\t\tif metadataChainVar != nil && isRegoMetadataChainCall(expr) {\n\t\t\tmetadataVar = *metadataChainVar\n\t\t} else if metadataRuleVar != nil && isRegoMetadataRuleCall(expr) {\n\t\t\tmetadataVar = *metadataRuleVar\n\t\t} else {\n\t\t\tcontinue\n\t\t}\n\n\t\t// NOTE(johanfylling): An alternative strategy would be to walk the body and replace all operands[0]\n\t\t// usages with *metadataChainVar\n\t\toperands := expr.Operands()\n\t\tvar newExpr *Expr\n\t\tif len(operands) > 0 { // There is an output var to rewrite\n\t\t\trewrittenVar := operands[0]\n\t\t\tnewExpr = Equality.Expr(rewrittenVar, NewTerm(metadataVar))\n\t\t} else { // No output var, just rewrite expr to metadataVar\n\t\t\tnewExpr = NewExpr(NewTerm(metadataVar))\n\t\t}\n\n\t\tnewExpr.Generated = true\n\t\tnewExpr.Location = expr.Location\n\t\tbody.Set(newExpr, i)\n\t}\n\n\treturn errs\n}\n\nfunc isRegoMetadataChainCall(x *Expr) bool {\n\treturn x.IsCall() && x.Operator().Equal(RegoMetadataChain.Ref())\n}\n\nfunc isRegoMetadataRuleCall(x *Expr) bool {\n\treturn x.IsCall() && x.Operator().Equal(RegoMetadataRule.Ref())\n}\n\nfunc createMetadataChain(chain []*AnnotationsRef) (*Term, *Error) {\n\n\tmetaArray := NewArray()\n\tfor _, link := range chain {\n\t\tp := link.Path.toArray().\n\t\t\tSlice(1, -1) // Dropping leading 'data' element of path\n\t\tobj := NewObject(\n\t\t\tItem(StringTerm(\"path\"), NewTerm(p)),\n\t\t)\n\t\tif link.Annotations != nil {\n\t\t\tannotObj, err := link.Annotations.toObject()\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tobj.Insert(StringTerm(\"annotations\"), NewTerm(*annotObj))\n\t\t}\n\t\tmetaArray = metaArray.Append(NewTerm(obj))\n\t}\n\n\treturn NewTerm(metaArray), nil\n}\n\nfunc (c *Compiler) rewriteLocalVars() {\n\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\tgen := c.localvargen\n\n\t\tWalkRules(mod, func(rule *Rule) bool {\n\n\t\t\t// Rewrite assignments contained in head of rule. Assignments can\n\t\t\t// occur in rule head if they're inside a comprehension. Note,\n\t\t\t// assigned vars in comprehensions in the head will be rewritten\n\t\t\t// first to preserve scoping rules. For example:\n\t\t\t//\n\t\t\t// p = [x | x := 1] { x := 2 } becomes p = [__local0__ | __local0__ = 1] { __local1__ = 2 }\n\t\t\t//\n\t\t\t// This behaviour is consistent scoping inside the body. For example:\n\t\t\t//\n\t\t\t// p = xs { x := 2; xs = [x | x := 1] } becomes p = xs { __local0__ = 2; xs = [__local1__ | __local1__ = 1] }\n\t\t\tnestedXform := &rewriteNestedHeadVarLocalTransform{\n\t\t\t\tgen:           gen,\n\t\t\t\tRewrittenVars: c.RewrittenVars,\n\t\t\t\tstrict:        c.strict,\n\t\t\t}\n\n\t\t\tNewGenericVisitor(nestedXform.Visit).Walk(rule.Head)\n\n\t\t\tfor _, err := range nestedXform.errs {\n\t\t\t\tc.err(err)\n\t\t\t}\n\n\t\t\t// Rewrite assignments in body.\n\t\t\tused := NewVarSet()\n\n\t\t\tif rule.Head.Key != nil {\n\t\t\t\tused.Update(rule.Head.Key.Vars())\n\t\t\t}\n\n\t\t\tif rule.Head.Value != nil {\n\t\t\t\tused.Update(rule.Head.Value.Vars())\n\t\t\t}\n\n\t\t\tstack := newLocalDeclaredVars()\n\n\t\t\tc.rewriteLocalArgVars(gen, stack, rule)\n\n\t\t\tbody, declared, errs := rewriteLocalVars(gen, stack, used, rule.Body, c.strict)\n\t\t\tfor _, err := range errs {\n\t\t\t\tc.err(err)\n\t\t\t}\n\n\t\t\t// For rewritten vars use the collection of all variables that\n\t\t\t// were in the stack at some point in time.\n\t\t\tfor k, v := range stack.rewritten {\n\t\t\t\tc.RewrittenVars[k] = v\n\t\t\t}\n\n\t\t\trule.Body = body\n\n\t\t\t// Rewrite vars in head that refer to locally declared vars in the body.\n\t\t\tlocalXform := rewriteHeadVarLocalTransform{declared: declared}\n\n\t\t\tfor i := range rule.Head.Args {\n\t\t\t\trule.Head.Args[i], _ = transformTerm(localXform, rule.Head.Args[i])\n\t\t\t}\n\n\t\t\tif rule.Head.Key != nil {\n\t\t\t\trule.Head.Key, _ = transformTerm(localXform, rule.Head.Key)\n\t\t\t}\n\n\t\t\tif rule.Head.Value != nil {\n\t\t\t\trule.Head.Value, _ = transformTerm(localXform, rule.Head.Value)\n\t\t\t}\n\n\t\t\treturn false\n\t\t})\n\t}\n}\n\ntype rewriteNestedHeadVarLocalTransform struct {\n\tgen           *localVarGenerator\n\terrs          Errors\n\tRewrittenVars map[Var]Var\n\tstrict        bool\n}\n\nfunc (xform *rewriteNestedHeadVarLocalTransform) Visit(x interface{}) bool {\n\n\tif term, ok := x.(*Term); ok {\n\n\t\tstop := false\n\t\tstack := newLocalDeclaredVars()\n\n\t\tswitch x := term.Value.(type) {\n\t\tcase *object:\n\t\t\tcpy, _ := x.Map(func(k, v *Term) (*Term, *Term, error) {\n\t\t\t\tkcpy := k.Copy()\n\t\t\t\tNewGenericVisitor(xform.Visit).Walk(kcpy)\n\t\t\t\tvcpy := v.Copy()\n\t\t\t\tNewGenericVisitor(xform.Visit).Walk(vcpy)\n\t\t\t\treturn kcpy, vcpy, nil\n\t\t\t})\n\t\t\tterm.Value = cpy\n\t\t\tstop = true\n\t\tcase *set:\n\t\t\tcpy, _ := x.Map(func(v *Term) (*Term, error) {\n\t\t\t\tvcpy := v.Copy()\n\t\t\t\tNewGenericVisitor(xform.Visit).Walk(vcpy)\n\t\t\t\treturn vcpy, nil\n\t\t\t})\n\t\t\tterm.Value = cpy\n\t\t\tstop = true\n\t\tcase *ArrayComprehension:\n\t\t\txform.errs = rewriteDeclaredVarsInArrayComprehension(xform.gen, stack, x, xform.errs, xform.strict)\n\t\t\tstop = true\n\t\tcase *SetComprehension:\n\t\t\txform.errs = rewriteDeclaredVarsInSetComprehension(xform.gen, stack, x, xform.errs, xform.strict)\n\t\t\tstop = true\n\t\tcase *ObjectComprehension:\n\t\t\txform.errs = rewriteDeclaredVarsInObjectComprehension(xform.gen, stack, x, xform.errs, xform.strict)\n\t\t\tstop = true\n\t\t}\n\n\t\tfor k, v := range stack.rewritten {\n\t\t\txform.RewrittenVars[k] = v\n\t\t}\n\n\t\treturn stop\n\t}\n\n\treturn false\n}\n\ntype rewriteHeadVarLocalTransform struct {\n\tdeclared map[Var]Var\n}\n\nfunc (xform rewriteHeadVarLocalTransform) Transform(x interface{}) (interface{}, error) {\n\tif v, ok := x.(Var); ok {\n\t\tif gv, ok := xform.declared[v]; ok {\n\t\t\treturn gv, nil\n\t\t}\n\t}\n\treturn x, nil\n}\n\nfunc (c *Compiler) rewriteLocalArgVars(gen *localVarGenerator, stack *localDeclaredVars, rule *Rule) {\n\n\tvis := &ruleArgLocalRewriter{\n\t\tstack: stack,\n\t\tgen:   gen,\n\t}\n\n\tfor i := range rule.Head.Args {\n\t\tWalk(vis, rule.Head.Args[i])\n\t}\n\n\tfor i := range vis.errs {\n\t\tc.err(vis.errs[i])\n\t}\n}\n\ntype ruleArgLocalRewriter struct {\n\tstack *localDeclaredVars\n\tgen   *localVarGenerator\n\terrs  []*Error\n}\n\nfunc (vis *ruleArgLocalRewriter) Visit(x interface{}) Visitor {\n\n\tt, ok := x.(*Term)\n\tif !ok {\n\t\treturn vis\n\t}\n\n\tswitch v := t.Value.(type) {\n\tcase Var:\n\t\tgv, ok := vis.stack.Declared(v)\n\t\tif ok {\n\t\t\tvis.stack.Seen(v)\n\t\t} else {\n\t\t\tgv = vis.gen.Generate()\n\t\t\tvis.stack.Insert(v, gv, argVar)\n\t\t}\n\t\tt.Value = gv\n\t\treturn nil\n\tcase *object:\n\t\tif cpy, err := v.Map(func(k, v *Term) (*Term, *Term, error) {\n\t\t\tvcpy := v.Copy()\n\t\t\tWalk(vis, vcpy)\n\t\t\treturn k, vcpy, nil\n\t\t}); err != nil {\n\t\t\tvis.errs = append(vis.errs, NewError(CompileErr, t.Location, err.Error()))\n\t\t} else {\n\t\t\tt.Value = cpy\n\t\t}\n\t\treturn nil\n\tcase Null, Boolean, Number, String, *ArrayComprehension, *SetComprehension, *ObjectComprehension, Set:\n\t\t// Scalars are no-ops. Comprehensions are handled above. Sets must not\n\t\t// contain variables.\n\t\treturn nil\n\tcase Call:\n\t\tvis.errs = append(vis.errs, NewError(CompileErr, t.Location, \"rule arguments cannot contain calls\"))\n\t\treturn nil\n\tdefault:\n\t\t// Recurse on refs and arrays. Any embedded\n\t\t// variables can be rewritten.\n\t\treturn vis\n\t}\n}\n\nfunc (c *Compiler) rewriteWithModifiers() {\n\tf := newEqualityFactory(c.localvargen)\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\tt := NewGenericTransformer(func(x interface{}) (interface{}, error) {\n\t\t\tbody, ok := x.(Body)\n\t\t\tif !ok {\n\t\t\t\treturn x, nil\n\t\t\t}\n\t\t\tbody, err := rewriteWithModifiersInBody(c, f, body)\n\t\t\tif err != nil {\n\t\t\t\tc.err(err)\n\t\t\t}\n\n\t\t\treturn body, nil\n\t\t})\n\t\t_, _ = Transform(t, mod) // ignore error\n\t}\n}\n\nfunc (c *Compiler) setModuleTree() {\n\tc.ModuleTree = NewModuleTree(c.Modules)\n}\n\nfunc (c *Compiler) setRuleTree() {\n\tc.RuleTree = NewRuleTree(c.ModuleTree)\n}\n\nfunc (c *Compiler) setGraph() {\n\tlist := func(r Ref) []*Rule {\n\t\treturn c.GetRulesDynamicWithOpts(r, RulesOptions{IncludeHiddenModules: true})\n\t}\n\tc.Graph = NewGraph(c.Modules, list)\n}\n\ntype queryCompiler struct {\n\tcompiler              *Compiler\n\tqctx                  *QueryContext\n\ttypeEnv               *TypeEnv\n\trewritten             map[Var]Var\n\tafter                 map[string][]QueryCompilerStageDefinition\n\tunsafeBuiltins        map[string]struct{}\n\tcomprehensionIndices  map[*Term]*ComprehensionIndex\n\tenablePrintStatements bool\n}\n\nfunc newQueryCompiler(compiler *Compiler) QueryCompiler {\n\tqc := &queryCompiler{\n\t\tcompiler:             compiler,\n\t\tqctx:                 nil,\n\t\tafter:                map[string][]QueryCompilerStageDefinition{},\n\t\tcomprehensionIndices: map[*Term]*ComprehensionIndex{},\n\t}\n\treturn qc\n}\n\nfunc (qc *queryCompiler) WithEnablePrintStatements(yes bool) QueryCompiler {\n\tqc.enablePrintStatements = yes\n\treturn qc\n}\n\nfunc (qc *queryCompiler) WithContext(qctx *QueryContext) QueryCompiler {\n\tqc.qctx = qctx\n\treturn qc\n}\n\nfunc (qc *queryCompiler) WithStageAfter(after string, stage QueryCompilerStageDefinition) QueryCompiler {\n\tqc.after[after] = append(qc.after[after], stage)\n\treturn qc\n}\n\nfunc (qc *queryCompiler) WithUnsafeBuiltins(unsafe map[string]struct{}) QueryCompiler {\n\tqc.unsafeBuiltins = unsafe\n\treturn qc\n}\n\nfunc (qc *queryCompiler) RewrittenVars() map[Var]Var {\n\treturn qc.rewritten\n}\n\nfunc (qc *queryCompiler) ComprehensionIndex(term *Term) *ComprehensionIndex {\n\tif result, ok := qc.comprehensionIndices[term]; ok {\n\t\treturn result\n\t} else if result, ok := qc.compiler.comprehensionIndices[term]; ok {\n\t\treturn result\n\t}\n\treturn nil\n}\n\nfunc (qc *queryCompiler) runStage(metricName string, qctx *QueryContext, query Body, s func(*QueryContext, Body) (Body, error)) (Body, error) {\n\tif qc.compiler.metrics != nil {\n\t\tqc.compiler.metrics.Timer(metricName).Start()\n\t\tdefer qc.compiler.metrics.Timer(metricName).Stop()\n\t}\n\treturn s(qctx, query)\n}\n\nfunc (qc *queryCompiler) runStageAfter(metricName string, query Body, s QueryCompilerStage) (Body, error) {\n\tif qc.compiler.metrics != nil {\n\t\tqc.compiler.metrics.Timer(metricName).Start()\n\t\tdefer qc.compiler.metrics.Timer(metricName).Stop()\n\t}\n\treturn s(qc, query)\n}\n\nfunc (qc *queryCompiler) Compile(query Body) (Body, error) {\n\tif len(query) == 0 {\n\t\treturn nil, Errors{NewError(CompileErr, nil, \"empty query cannot be compiled\")}\n\t}\n\n\tquery = query.Copy()\n\n\tstages := []struct {\n\t\tname       string\n\t\tmetricName string\n\t\tf          func(*QueryContext, Body) (Body, error)\n\t}{\n\t\t{\"CheckKeywordOverrides\", \"query_compile_stage_check_keyword_overrides\", qc.checkKeywordOverrides},\n\t\t{\"ResolveRefs\", \"query_compile_stage_resolve_refs\", qc.resolveRefs},\n\t\t{\"RewriteLocalVars\", \"query_compile_stage_rewrite_local_vars\", qc.rewriteLocalVars},\n\t\t{\"CheckVoidCalls\", \"query_compile_stage_check_void_calls\", qc.checkVoidCalls},\n\t\t{\"RewritePrintCalls\", \"query_compile_stage_rewrite_print_calls\", qc.rewritePrintCalls},\n\t\t{\"RewriteExprTerms\", \"query_compile_stage_rewrite_expr_terms\", qc.rewriteExprTerms},\n\t\t{\"RewriteComprehensionTerms\", \"query_compile_stage_rewrite_comprehension_terms\", qc.rewriteComprehensionTerms},\n\t\t{\"RewriteWithValues\", \"query_compile_stage_rewrite_with_values\", qc.rewriteWithModifiers},\n\t\t{\"CheckUndefinedFuncs\", \"query_compile_stage_check_undefined_funcs\", qc.checkUndefinedFuncs},\n\t\t{\"CheckSafety\", \"query_compile_stage_check_safety\", qc.checkSafety},\n\t\t{\"RewriteDynamicTerms\", \"query_compile_stage_rewrite_dynamic_terms\", qc.rewriteDynamicTerms},\n\t\t{\"CheckTypes\", \"query_compile_stage_check_types\", qc.checkTypes},\n\t\t{\"CheckUnsafeBuiltins\", \"query_compile_stage_check_unsafe_builtins\", qc.checkUnsafeBuiltins},\n\t\t{\"CheckDeprecatedBuiltins\", \"query_compile_stage_check_deprecated_builtins\", qc.checkDeprecatedBuiltins},\n\t\t{\"BuildComprehensionIndex\", \"query_compile_stage_build_comprehension_index\", qc.buildComprehensionIndices},\n\t}\n\n\tqctx := qc.qctx.Copy()\n\n\tfor _, s := range stages {\n\t\tvar err error\n\t\tquery, err = qc.runStage(s.metricName, qctx, query, s.f)\n\t\tif err != nil {\n\t\t\treturn nil, qc.applyErrorLimit(err)\n\t\t}\n\t\tfor _, s := range qc.after[s.name] {\n\t\t\tquery, err = qc.runStageAfter(s.MetricName, query, s.Stage)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, qc.applyErrorLimit(err)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn query, nil\n}\n\nfunc (qc *queryCompiler) TypeEnv() *TypeEnv {\n\treturn qc.typeEnv\n}\n\nfunc (qc *queryCompiler) applyErrorLimit(err error) error {\n\tif errs, ok := err.(Errors); ok {\n\t\tif qc.compiler.maxErrs > 0 && len(errs) > qc.compiler.maxErrs {\n\t\t\terr = append(errs[:qc.compiler.maxErrs], errLimitReached)\n\t\t}\n\t}\n\treturn err\n}\n\nfunc (qc *queryCompiler) checkKeywordOverrides(_ *QueryContext, body Body) (Body, error) {\n\tif errs := checkKeywordOverrides(body, qc.compiler.strict); len(errs) > 0 {\n\t\treturn nil, errs\n\t}\n\treturn body, nil\n}\n\nfunc (qc *queryCompiler) resolveRefs(qctx *QueryContext, body Body) (Body, error) {\n\n\tvar globals map[Var]*usedRef\n\n\tif qctx != nil {\n\t\tpkg := qctx.Package\n\t\t// Query compiler ought to generate a package if one was not provided and one or more imports were provided.\n\t\t// The generated package name could even be an empty string to avoid conflicts (it doesn't have to be valid syntactically)\n\t\tif pkg == nil && len(qctx.Imports) > 0 {\n\t\t\tpkg = &Package{Path: RefTerm(VarTerm(\"\")).Value.(Ref)}\n\t\t}\n\t\tif pkg != nil {\n\t\t\tvar ruleExports []Var\n\t\t\trules := qc.compiler.getExports()\n\t\t\tif exist, ok := rules.Get(pkg.Path); ok {\n\t\t\t\truleExports = exist.([]Var)\n\t\t\t}\n\n\t\t\tglobals = getGlobals(qctx.Package, ruleExports, qctx.Imports)\n\t\t\tqctx.Imports = nil\n\t\t}\n\t}\n\n\tignore := &declaredVarStack{declaredVars(body)}\n\n\treturn resolveRefsInBody(globals, ignore, body), nil\n}\n\nfunc (qc *queryCompiler) rewriteComprehensionTerms(_ *QueryContext, body Body) (Body, error) {\n\tgen := newLocalVarGenerator(\"q\", body)\n\tf := newEqualityFactory(gen)\n\tnode, err := rewriteComprehensionTerms(f, body)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn node.(Body), nil\n}\n\nfunc (qc *queryCompiler) rewriteDynamicTerms(_ *QueryContext, body Body) (Body, error) {\n\tgen := newLocalVarGenerator(\"q\", body)\n\tf := newEqualityFactory(gen)\n\treturn rewriteDynamics(f, body), nil\n}\n\nfunc (qc *queryCompiler) rewriteExprTerms(_ *QueryContext, body Body) (Body, error) {\n\tgen := newLocalVarGenerator(\"q\", body)\n\treturn rewriteExprTermsInBody(gen, body), nil\n}\n\nfunc (qc *queryCompiler) rewriteLocalVars(_ *QueryContext, body Body) (Body, error) {\n\tgen := newLocalVarGenerator(\"q\", body)\n\tstack := newLocalDeclaredVars()\n\tbody, _, err := rewriteLocalVars(gen, stack, nil, body, qc.compiler.strict)\n\tif len(err) != 0 {\n\t\treturn nil, err\n\t}\n\tqc.rewritten = make(map[Var]Var, len(stack.rewritten))\n\tfor k, v := range stack.rewritten {\n\t\t// The vars returned during the rewrite will include all seen vars,\n\t\t// even if they're not declared with an assignment operation. We don't\n\t\t// want to include these inside the rewritten set though.\n\t\tqc.rewritten[k] = v\n\t}\n\treturn body, nil\n}\n\nfunc (qc *queryCompiler) rewritePrintCalls(_ *QueryContext, body Body) (Body, error) {\n\tif !qc.enablePrintStatements {\n\t\treturn erasePrintCallsInBody(body), nil\n\t}\n\tgen := newLocalVarGenerator(\"q\", body)\n\tif errs := rewritePrintCalls(gen, qc.compiler.GetArity, ReservedVars, body); len(errs) > 0 {\n\t\treturn nil, errs\n\t}\n\treturn body, nil\n}\n\nfunc (qc *queryCompiler) checkVoidCalls(_ *QueryContext, body Body) (Body, error) {\n\tif errs := checkVoidCalls(qc.compiler.TypeEnv, body); len(errs) > 0 {\n\t\treturn nil, errs\n\t}\n\treturn body, nil\n}\n\nfunc (qc *queryCompiler) checkUndefinedFuncs(_ *QueryContext, body Body) (Body, error) {\n\tif errs := checkUndefinedFuncs(qc.compiler.TypeEnv, body, qc.compiler.GetArity, qc.rewritten); len(errs) > 0 {\n\t\treturn nil, errs\n\t}\n\treturn body, nil\n}\n\nfunc (qc *queryCompiler) checkSafety(_ *QueryContext, body Body) (Body, error) {\n\tsafe := ReservedVars.Copy()\n\treordered, unsafe := reorderBodyForSafety(qc.compiler.builtins, qc.compiler.GetArity, safe, body)\n\tif errs := safetyErrorSlice(unsafe, qc.RewrittenVars()); len(errs) > 0 {\n\t\treturn nil, errs\n\t}\n\treturn reordered, nil\n}\n\nfunc (qc *queryCompiler) checkTypes(_ *QueryContext, body Body) (Body, error) {\n\tvar errs Errors\n\tchecker := newTypeChecker().\n\t\tWithSchemaSet(qc.compiler.schemaSet).\n\t\tWithInputType(qc.compiler.inputType).\n\t\tWithVarRewriter(rewriteVarsInRef(qc.rewritten, qc.compiler.RewrittenVars))\n\tqc.typeEnv, errs = checker.CheckBody(qc.compiler.TypeEnv, body)\n\tif len(errs) > 0 {\n\t\treturn nil, errs\n\t}\n\n\treturn body, nil\n}\n\nfunc (qc *queryCompiler) checkUnsafeBuiltins(_ *QueryContext, body Body) (Body, error) {\n\tvar unsafe map[string]struct{}\n\tif qc.unsafeBuiltins != nil {\n\t\tunsafe = qc.unsafeBuiltins\n\t} else {\n\t\tunsafe = qc.compiler.unsafeBuiltinsMap\n\t}\n\terrs := checkUnsafeBuiltins(unsafe, body)\n\tif len(errs) > 0 {\n\t\treturn nil, errs\n\t}\n\treturn body, nil\n}\n\nfunc (qc *queryCompiler) checkDeprecatedBuiltins(_ *QueryContext, body Body) (Body, error) {\n\terrs := checkDeprecatedBuiltins(qc.compiler.deprecatedBuiltinsMap, body, qc.compiler.strict)\n\tif len(errs) > 0 {\n\t\treturn nil, errs\n\t}\n\treturn body, nil\n}\n\nfunc (qc *queryCompiler) rewriteWithModifiers(_ *QueryContext, body Body) (Body, error) {\n\tf := newEqualityFactory(newLocalVarGenerator(\"q\", body))\n\tbody, err := rewriteWithModifiersInBody(qc.compiler, f, body)\n\tif err != nil {\n\t\treturn nil, Errors{err}\n\t}\n\treturn body, nil\n}\n\nfunc (qc *queryCompiler) buildComprehensionIndices(_ *QueryContext, body Body) (Body, error) {\n\t// NOTE(tsandall): The query compiler does not have a metrics object so we\n\t// cannot record index metrics currently.\n\t_ = buildComprehensionIndices(qc.compiler.debug, qc.compiler.GetArity, ReservedVars, qc.RewrittenVars(), body, qc.comprehensionIndices)\n\treturn body, nil\n}\n\n// ComprehensionIndex specifies how the comprehension term can be indexed. The keys\n// tell the evaluator what variables to use for indexing. In the future, the index\n// could be expanded with more information that would allow the evaluator to index\n// a larger fragment of comprehensions (e.g., by closing over variables in the outer\n// query.)\ntype ComprehensionIndex struct {\n\tTerm *Term\n\tKeys []*Term\n}\n\nfunc (ci *ComprehensionIndex) String() string {\n\tif ci == nil {\n\t\treturn \"\"\n\t}\n\treturn fmt.Sprintf(\"<keys: %v>\", NewArray(ci.Keys...))\n}\n\nfunc buildComprehensionIndices(dbg debug.Debug, arity func(Ref) int, candidates VarSet, rwVars map[Var]Var, node interface{}, result map[*Term]*ComprehensionIndex) uint64 {\n\tvar n uint64\n\tcpy := candidates.Copy()\n\tWalkBodies(node, func(b Body) bool {\n\t\tfor _, expr := range b {\n\t\t\tindex := getComprehensionIndex(dbg, arity, cpy, rwVars, expr)\n\t\t\tif index != nil {\n\t\t\t\tresult[index.Term] = index\n\t\t\t\tn++\n\t\t\t}\n\t\t\t// Any variables appearing in the expressions leading up to the comprehension\n\t\t\t// are fair-game to be used as index keys.\n\t\t\tcpy.Update(expr.Vars(VarVisitorParams{SkipClosures: true, SkipRefCallHead: true}))\n\t\t}\n\t\treturn false\n\t})\n\treturn n\n}\n\nfunc getComprehensionIndex(dbg debug.Debug, arity func(Ref) int, candidates VarSet, rwVars map[Var]Var, expr *Expr) *ComprehensionIndex {\n\n\t// Ignore everything except <var> = <comprehension> expressions. Extract\n\t// the comprehension term from the expression.\n\tif !expr.IsEquality() || expr.Negated || len(expr.With) > 0 {\n\t\t// No debug message, these are assumed to be known hinderances\n\t\t// to comprehension indexing.\n\t\treturn nil\n\t}\n\n\tvar term *Term\n\n\tlhs, rhs := expr.Operand(0), expr.Operand(1)\n\n\tif _, ok := lhs.Value.(Var); ok && IsComprehension(rhs.Value) {\n\t\tterm = rhs\n\t} else if _, ok := rhs.Value.(Var); ok && IsComprehension(lhs.Value) {\n\t\tterm = lhs\n\t}\n\n\tif term == nil {\n\t\t// no debug for this, it's the ordinary \"nothing to do here\" case\n\t\treturn nil\n\t}\n\n\t// Ignore comprehensions that contain expressions that close over variables\n\t// in the outer body if those variables are not also output variables in the\n\t// comprehension body. In other words, ignore comprehensions that we cannot\n\t// safely evaluate without bindings from the outer body. For example:\n\t//\n\t// \tx = [1]\n\t//\t[true | data.y[z] = x]     # safe to evaluate w/o outer body\n\t//\t[true | data.y[z] = x[0]]  # NOT safe to evaluate because 'x' would be unsafe.\n\t//\n\t// By identifying output variables in the body we also know what to index on by\n\t// intersecting with candidate variables from the outer query.\n\t//\n\t// For example:\n\t//\n\t//\tx = data.foo[_]\n\t//\t_ = [y | data.bar[y] = x]      # index on 'x'\n\t//\n\t// This query goes from O(data.foo*data.bar) to O(data.foo+data.bar).\n\tvar body Body\n\n\tswitch x := term.Value.(type) {\n\tcase *ArrayComprehension:\n\t\tbody = x.Body\n\tcase *SetComprehension:\n\t\tbody = x.Body\n\tcase *ObjectComprehension:\n\t\tbody = x.Body\n\t}\n\n\toutputs := outputVarsForBody(body, arity, ReservedVars)\n\tunsafe := body.Vars(SafetyCheckVisitorParams).Diff(outputs).Diff(ReservedVars)\n\n\tif len(unsafe) > 0 {\n\t\tdbg.Printf(\"%s: comprehension index: unsafe vars: %v\", expr.Location, unsafe)\n\t\treturn nil\n\t}\n\n\t// Similarly, ignore comprehensions that contain references with output variables\n\t// that intersect with the candidates. Indexing these comprehensions could worsen\n\t// performance.\n\tregressionVis := newComprehensionIndexRegressionCheckVisitor(candidates)\n\tregressionVis.Walk(body)\n\tif regressionVis.worse {\n\t\tdbg.Printf(\"%s: comprehension index: output vars intersect candidates\", expr.Location)\n\t\treturn nil\n\t}\n\n\t// Check if any nested comprehensions close over candidates. If any intersection is found\n\t// the comprehension cannot be cached because it would require closing over the candidates\n\t// which the evaluator does not support today.\n\tnestedVis := newComprehensionIndexNestedCandidateVisitor(candidates)\n\tnestedVis.Walk(body)\n\tif nestedVis.found {\n\t\tdbg.Printf(\"%s: comprehension index: nested comprehensions close over candidates\", expr.Location)\n\t\treturn nil\n\t}\n\n\t// Make a sorted set of variable names that will serve as the index key set.\n\t// Sort to ensure deterministic indexing. In future this could be relaxed\n\t// if we can decide that one ordering is better than another. If the set is\n\t// empty, there is no indexing to do.\n\tindexVars := candidates.Intersect(outputs)\n\tif len(indexVars) == 0 {\n\t\tdbg.Printf(\"%s: comprehension index: no index vars\", expr.Location)\n\t\treturn nil\n\t}\n\n\tresult := make([]*Term, 0, len(indexVars))\n\n\tfor v := range indexVars {\n\t\tresult = append(result, NewTerm(v))\n\t}\n\n\tsort.Slice(result, func(i, j int) bool {\n\t\treturn result[i].Value.Compare(result[j].Value) < 0\n\t})\n\n\tdebugRes := make([]*Term, len(result))\n\tfor i, r := range result {\n\t\tif o, ok := rwVars[r.Value.(Var)]; ok {\n\t\t\tdebugRes[i] = NewTerm(o)\n\t\t} else {\n\t\t\tdebugRes[i] = r\n\t\t}\n\t}\n\tdbg.Printf(\"%s: comprehension index: built with keys: %v\", expr.Location, debugRes)\n\treturn &ComprehensionIndex{Term: term, Keys: result}\n}\n\ntype comprehensionIndexRegressionCheckVisitor struct {\n\tcandidates VarSet\n\tseen       VarSet\n\tworse      bool\n}\n\n// TODO(tsandall): Improve this so that users can either supply this list explicitly\n// or the information is maintained on the built-in function declaration. What we really\n// need to know is whether the built-in function allows callers to push down output\n// values or not. It's unlikely that anything outside of OPA does this today so this\n// solution is fine for now.\nvar comprehensionIndexBlacklist = map[string]int{\n\tWalkBuiltin.Name: len(WalkBuiltin.Decl.Args()),\n}\n\nfunc newComprehensionIndexRegressionCheckVisitor(candidates VarSet) *comprehensionIndexRegressionCheckVisitor {\n\treturn &comprehensionIndexRegressionCheckVisitor{\n\t\tcandidates: candidates,\n\t\tseen:       NewVarSet(),\n\t}\n}\n\nfunc (vis *comprehensionIndexRegressionCheckVisitor) Walk(x interface{}) {\n\tNewGenericVisitor(vis.visit).Walk(x)\n}\n\nfunc (vis *comprehensionIndexRegressionCheckVisitor) visit(x interface{}) bool {\n\tif !vis.worse {\n\t\tswitch x := x.(type) {\n\t\tcase *Expr:\n\t\t\toperands := x.Operands()\n\t\t\tif pos := comprehensionIndexBlacklist[x.Operator().String()]; pos > 0 && pos < len(operands) {\n\t\t\t\tvis.assertEmptyIntersection(operands[pos].Vars())\n\t\t\t}\n\t\tcase Ref:\n\t\t\tvis.assertEmptyIntersection(x.OutputVars())\n\t\tcase Var:\n\t\t\tvis.seen.Add(x)\n\t\t// Always skip comprehensions. We do not have to visit their bodies here.\n\t\tcase *ArrayComprehension, *SetComprehension, *ObjectComprehension:\n\t\t\treturn true\n\t\t}\n\t}\n\treturn vis.worse\n}\n\nfunc (vis *comprehensionIndexRegressionCheckVisitor) assertEmptyIntersection(vs VarSet) {\n\tfor v := range vs {\n\t\tif vis.candidates.Contains(v) && !vis.seen.Contains(v) {\n\t\t\tvis.worse = true\n\t\t\treturn\n\t\t}\n\t}\n}\n\ntype comprehensionIndexNestedCandidateVisitor struct {\n\tcandidates VarSet\n\tfound      bool\n}\n\nfunc newComprehensionIndexNestedCandidateVisitor(candidates VarSet) *comprehensionIndexNestedCandidateVisitor {\n\treturn &comprehensionIndexNestedCandidateVisitor{\n\t\tcandidates: candidates,\n\t}\n}\n\nfunc (vis *comprehensionIndexNestedCandidateVisitor) Walk(x interface{}) {\n\tNewGenericVisitor(vis.visit).Walk(x)\n}\n\nfunc (vis *comprehensionIndexNestedCandidateVisitor) visit(x interface{}) bool {\n\n\tif vis.found {\n\t\treturn true\n\t}\n\n\tif v, ok := x.(Value); ok && IsComprehension(v) {\n\t\tvarVis := NewVarVisitor().WithParams(VarVisitorParams{SkipRefHead: true})\n\t\tvarVis.Walk(v)\n\t\tvis.found = len(varVis.Vars().Intersect(vis.candidates)) > 0\n\t\treturn true\n\t}\n\n\treturn false\n}\n\n// ModuleTreeNode represents a node in the module tree. The module\n// tree is keyed by the package path.\ntype ModuleTreeNode struct {\n\tKey      Value\n\tModules  []*Module\n\tChildren map[Value]*ModuleTreeNode\n\tHide     bool\n}\n\n// NewModuleTree returns a new ModuleTreeNode that represents the root\n// of the module tree populated with the given modules.\nfunc NewModuleTree(mods map[string]*Module) *ModuleTreeNode {\n\troot := &ModuleTreeNode{\n\t\tChildren: map[Value]*ModuleTreeNode{},\n\t}\n\tnames := make([]string, 0, len(mods))\n\tfor name := range mods {\n\t\tnames = append(names, name)\n\t}\n\tsort.Strings(names)\n\tfor _, name := range names {\n\t\tm := mods[name]\n\t\tnode := root\n\t\tfor i, x := range m.Package.Path {\n\t\t\tc, ok := node.Children[x.Value]\n\t\t\tif !ok {\n\t\t\t\tvar hide bool\n\t\t\t\tif i == 1 && x.Value.Compare(SystemDocumentKey) == 0 {\n\t\t\t\t\thide = true\n\t\t\t\t}\n\t\t\t\tc = &ModuleTreeNode{\n\t\t\t\t\tKey:      x.Value,\n\t\t\t\t\tChildren: map[Value]*ModuleTreeNode{},\n\t\t\t\t\tHide:     hide,\n\t\t\t\t}\n\t\t\t\tnode.Children[x.Value] = c\n\t\t\t}\n\t\t\tnode = c\n\t\t}\n\t\tnode.Modules = append(node.Modules, m)\n\t}\n\treturn root\n}\n\n// Size returns the number of modules in the tree.\nfunc (n *ModuleTreeNode) Size() int {\n\ts := len(n.Modules)\n\tfor _, c := range n.Children {\n\t\ts += c.Size()\n\t}\n\treturn s\n}\n\n// DepthFirst performs a depth-first traversal of the module tree rooted at n.\n// If f returns true, traversal will not continue to the children of n.\nfunc (n *ModuleTreeNode) DepthFirst(f func(node *ModuleTreeNode) bool) {\n\tif !f(n) {\n\t\tfor _, node := range n.Children {\n\t\t\tnode.DepthFirst(f)\n\t\t}\n\t}\n}\n\n// TreeNode represents a node in the rule tree. The rule tree is keyed by\n// rule path.\ntype TreeNode struct {\n\tKey      Value\n\tValues   []util.T\n\tChildren map[Value]*TreeNode\n\tSorted   []Value\n\tHide     bool\n}\n\n// NewRuleTree returns a new TreeNode that represents the root\n// of the rule tree populated with the given rules.\nfunc NewRuleTree(mtree *ModuleTreeNode) *TreeNode {\n\n\truleSets := map[String][]util.T{}\n\n\t// Build rule sets for this package.\n\tfor _, mod := range mtree.Modules {\n\t\tfor _, rule := range mod.Rules {\n\t\t\tkey := String(rule.Head.Name)\n\t\t\truleSets[key] = append(ruleSets[key], rule)\n\t\t}\n\t}\n\n\t// Each rule set becomes a leaf node.\n\tchildren := map[Value]*TreeNode{}\n\tsorted := make([]Value, 0, len(ruleSets))\n\n\tfor key, rules := range ruleSets {\n\t\tsorted = append(sorted, key)\n\t\tchildren[key] = &TreeNode{\n\t\t\tKey:      key,\n\t\t\tChildren: nil,\n\t\t\tValues:   rules,\n\t\t}\n\t}\n\n\t// Each module in subpackage becomes child node.\n\tfor key, child := range mtree.Children {\n\t\tsorted = append(sorted, key)\n\t\tchildren[child.Key] = NewRuleTree(child)\n\t}\n\n\tsort.Slice(sorted, func(i, j int) bool {\n\t\treturn sorted[i].Compare(sorted[j]) < 0\n\t})\n\n\treturn &TreeNode{\n\t\tKey:      mtree.Key,\n\t\tValues:   nil,\n\t\tChildren: children,\n\t\tSorted:   sorted,\n\t\tHide:     mtree.Hide,\n\t}\n}\n\n// Size returns the number of rules in the tree.\nfunc (n *TreeNode) Size() int {\n\ts := len(n.Values)\n\tfor _, c := range n.Children {\n\t\ts += c.Size()\n\t}\n\treturn s\n}\n\n// Child returns n's child with key k.\nfunc (n *TreeNode) Child(k Value) *TreeNode {\n\tswitch k.(type) {\n\tcase String, Var:\n\t\treturn n.Children[k]\n\t}\n\treturn nil\n}\n\n// Find dereferences ref along the tree\nfunc (n *TreeNode) Find(ref Ref) *TreeNode {\n\tnode := n\n\tfor _, r := range ref {\n\t\tchild := node.Child(r.Value)\n\t\tif child == nil {\n\t\t\treturn nil\n\t\t}\n\t\tnode = child\n\t}\n\treturn node\n}\n\n// DepthFirst performs a depth-first traversal of the rule tree rooted at n. If\n// f returns true, traversal will not continue to the children of n.\nfunc (n *TreeNode) DepthFirst(f func(node *TreeNode) bool) {\n\tif !f(n) {\n\t\tfor _, node := range n.Children {\n\t\t\tnode.DepthFirst(f)\n\t\t}\n\t}\n}\n\n// Graph represents the graph of dependencies between rules.\ntype Graph struct {\n\tadj    map[util.T]map[util.T]struct{}\n\tradj   map[util.T]map[util.T]struct{}\n\tnodes  map[util.T]struct{}\n\tsorted []util.T\n}\n\n// NewGraph returns a new Graph based on modules. The list function must return\n// the rules referred to directly by the ref.\nfunc NewGraph(modules map[string]*Module, list func(Ref) []*Rule) *Graph {\n\n\tgraph := &Graph{\n\t\tadj:    map[util.T]map[util.T]struct{}{},\n\t\tradj:   map[util.T]map[util.T]struct{}{},\n\t\tnodes:  map[util.T]struct{}{},\n\t\tsorted: nil,\n\t}\n\n\t// Create visitor to walk a rule AST and add edges to the rule graph for\n\t// each dependency.\n\tvis := func(a *Rule) *GenericVisitor {\n\t\tstop := false\n\t\treturn NewGenericVisitor(func(x interface{}) bool {\n\t\t\tswitch x := x.(type) {\n\t\t\tcase Ref:\n\t\t\t\tfor _, b := range list(x) {\n\t\t\t\t\tfor node := b; node != nil; node = node.Else {\n\t\t\t\t\t\tgraph.addDependency(a, node)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tcase *Rule:\n\t\t\t\tif stop {\n\t\t\t\t\t// Do not recurse into else clauses (which will be handled\n\t\t\t\t\t// by the outer visitor.)\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t\tstop = true\n\t\t\t}\n\t\t\treturn false\n\t\t})\n\t}\n\n\t// Walk over all rules, add them to graph, and build adjacency lists.\n\tfor _, module := range modules {\n\t\tWalkRules(module, func(a *Rule) bool {\n\t\t\tgraph.addNode(a)\n\t\t\tvis(a).Walk(a)\n\t\t\treturn false\n\t\t})\n\t}\n\n\treturn graph\n}\n\n// Dependencies returns the set of rules that x depends on.\nfunc (g *Graph) Dependencies(x util.T) map[util.T]struct{} {\n\treturn g.adj[x]\n}\n\n// Dependents returns the set of rules that depend on x.\nfunc (g *Graph) Dependents(x util.T) map[util.T]struct{} {\n\treturn g.radj[x]\n}\n\n// Sort returns a slice of rules sorted by dependencies. If a cycle is found,\n// ok is set to false.\nfunc (g *Graph) Sort() (sorted []util.T, ok bool) {\n\tif g.sorted != nil {\n\t\treturn g.sorted, true\n\t}\n\n\tsorter := &graphSort{\n\t\tsorted: make([]util.T, 0, len(g.nodes)),\n\t\tdeps:   g.Dependencies,\n\t\tmarked: map[util.T]struct{}{},\n\t\ttemp:   map[util.T]struct{}{},\n\t}\n\n\tfor node := range g.nodes {\n\t\tif !sorter.Visit(node) {\n\t\t\treturn nil, false\n\t\t}\n\t}\n\n\tg.sorted = sorter.sorted\n\treturn g.sorted, true\n}\n\nfunc (g *Graph) addDependency(u util.T, v util.T) {\n\n\tif _, ok := g.nodes[u]; !ok {\n\t\tg.addNode(u)\n\t}\n\n\tif _, ok := g.nodes[v]; !ok {\n\t\tg.addNode(v)\n\t}\n\n\tedges, ok := g.adj[u]\n\tif !ok {\n\t\tedges = map[util.T]struct{}{}\n\t\tg.adj[u] = edges\n\t}\n\n\tedges[v] = struct{}{}\n\n\tedges, ok = g.radj[v]\n\tif !ok {\n\t\tedges = map[util.T]struct{}{}\n\t\tg.radj[v] = edges\n\t}\n\n\tedges[u] = struct{}{}\n}\n\nfunc (g *Graph) addNode(n util.T) {\n\tg.nodes[n] = struct{}{}\n}\n\ntype graphSort struct {\n\tsorted []util.T\n\tdeps   func(util.T) map[util.T]struct{}\n\tmarked map[util.T]struct{}\n\ttemp   map[util.T]struct{}\n}\n\nfunc (sort *graphSort) Marked(node util.T) bool {\n\t_, marked := sort.marked[node]\n\treturn marked\n}\n\nfunc (sort *graphSort) Visit(node util.T) (ok bool) {\n\tif _, ok := sort.temp[node]; ok {\n\t\treturn false\n\t}\n\tif sort.Marked(node) {\n\t\treturn true\n\t}\n\tsort.temp[node] = struct{}{}\n\tfor other := range sort.deps(node) {\n\t\tif !sort.Visit(other) {\n\t\t\treturn false\n\t\t}\n\t}\n\tsort.marked[node] = struct{}{}\n\tdelete(sort.temp, node)\n\tsort.sorted = append(sort.sorted, node)\n\treturn true\n}\n\n// GraphTraversal is a Traversal that understands the dependency graph\ntype GraphTraversal struct {\n\tgraph   *Graph\n\tvisited map[util.T]struct{}\n}\n\n// NewGraphTraversal returns a Traversal for the dependency graph\nfunc NewGraphTraversal(graph *Graph) *GraphTraversal {\n\treturn &GraphTraversal{\n\t\tgraph:   graph,\n\t\tvisited: map[util.T]struct{}{},\n\t}\n}\n\n// Edges lists all dependency connections for a given node\nfunc (g *GraphTraversal) Edges(x util.T) []util.T {\n\tr := []util.T{}\n\tfor v := range g.graph.Dependencies(x) {\n\t\tr = append(r, v)\n\t}\n\treturn r\n}\n\n// Visited returns whether a node has been visited, setting a node to visited if not\nfunc (g *GraphTraversal) Visited(u util.T) bool {\n\t_, ok := g.visited[u]\n\tg.visited[u] = struct{}{}\n\treturn ok\n}\n\ntype unsafePair struct {\n\tExpr *Expr\n\tVars VarSet\n}\n\ntype unsafeVarLoc struct {\n\tVar Var\n\tLoc *Location\n}\n\ntype unsafeVars map[*Expr]VarSet\n\nfunc (vs unsafeVars) Add(e *Expr, v Var) {\n\tif u, ok := vs[e]; ok {\n\t\tu[v] = struct{}{}\n\t} else {\n\t\tvs[e] = VarSet{v: struct{}{}}\n\t}\n}\n\nfunc (vs unsafeVars) Set(e *Expr, s VarSet) {\n\tvs[e] = s\n}\n\nfunc (vs unsafeVars) Update(o unsafeVars) {\n\tfor k, v := range o {\n\t\tif _, ok := vs[k]; !ok {\n\t\t\tvs[k] = VarSet{}\n\t\t}\n\t\tvs[k].Update(v)\n\t}\n}\n\nfunc (vs unsafeVars) Vars() (result []unsafeVarLoc) {\n\n\tlocs := map[Var]*Location{}\n\n\t// If var appears in multiple sets then pick first by location.\n\tfor expr, vars := range vs {\n\t\tfor v := range vars {\n\t\t\tif locs[v].Compare(expr.Location) > 0 {\n\t\t\t\tlocs[v] = expr.Location\n\t\t\t}\n\t\t}\n\t}\n\n\tfor v, loc := range locs {\n\t\tresult = append(result, unsafeVarLoc{\n\t\t\tVar: v,\n\t\t\tLoc: loc,\n\t\t})\n\t}\n\n\tsort.Slice(result, func(i, j int) bool {\n\t\treturn result[i].Loc.Compare(result[j].Loc) < 0\n\t})\n\n\treturn result\n}\n\nfunc (vs unsafeVars) Slice() (result []unsafePair) {\n\tfor expr, vs := range vs {\n\t\tresult = append(result, unsafePair{\n\t\t\tExpr: expr,\n\t\t\tVars: vs,\n\t\t})\n\t}\n\treturn\n}\n\n// reorderBodyForSafety returns a copy of the body ordered such that\n// left to right evaluation of the body will not encounter unbound variables\n// in input positions or negated expressions.\n//\n// Expressions are added to the re-ordered body as soon as they are considered\n// safe. If multiple expressions become safe in the same pass, they are added\n// in their original order. This results in minimal re-ordering of the body.\n//\n// If the body cannot be reordered to ensure safety, the second return value\n// contains a mapping of expressions to unsafe variables in those expressions.\nfunc reorderBodyForSafety(builtins map[string]*Builtin, arity func(Ref) int, globals VarSet, body Body) (Body, unsafeVars) {\n\n\tbodyVars := body.Vars(SafetyCheckVisitorParams)\n\treordered := make(Body, 0, len(body))\n\tsafe := VarSet{}\n\tunsafe := unsafeVars{}\n\n\tfor _, e := range body {\n\t\tfor v := range e.Vars(SafetyCheckVisitorParams) {\n\t\t\tif globals.Contains(v) {\n\t\t\t\tsafe.Add(v)\n\t\t\t} else {\n\t\t\t\tunsafe.Add(e, v)\n\t\t\t}\n\t\t}\n\t}\n\n\tfor {\n\t\tn := len(reordered)\n\n\t\tfor _, e := range body {\n\t\t\tif reordered.Contains(e) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tovs := outputVarsForExpr(e, arity, safe)\n\n\t\t\t// check closures: is this expression closing over variables that\n\t\t\t// haven't been made safe by what's already included in `reordered`?\n\t\t\tvs := unsafeVarsInClosures(e, arity, safe)\n\t\t\tcv := vs.Intersect(bodyVars).Diff(globals)\n\t\t\tuv := cv.Diff(outputVarsForBody(reordered, arity, safe))\n\n\t\t\tif len(uv) > 0 {\n\t\t\t\tif uv.Equal(ovs) { // special case \"closure-self\"\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tunsafe.Set(e, uv)\n\t\t\t}\n\n\t\t\tfor v := range unsafe[e] {\n\t\t\t\tif ovs.Contains(v) || safe.Contains(v) {\n\t\t\t\t\tdelete(unsafe[e], v)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif len(unsafe[e]) == 0 {\n\t\t\t\tdelete(unsafe, e)\n\t\t\t\treordered.Append(e)\n\t\t\t\tsafe.Update(ovs) // this expression's outputs are safe\n\t\t\t}\n\t\t}\n\n\t\tif len(reordered) == n { // fixed point, could not add any expr of body\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// Recursively visit closures and perform the safety checks on them.\n\t// Update the globals at each expression to include the variables that could\n\t// be closed over.\n\tg := globals.Copy()\n\tfor i, e := range reordered {\n\t\tif i > 0 {\n\t\t\tg.Update(reordered[i-1].Vars(SafetyCheckVisitorParams))\n\t\t}\n\t\txform := &bodySafetyTransformer{\n\t\t\tbuiltins: builtins,\n\t\t\tarity:    arity,\n\t\t\tcurrent:  e,\n\t\t\tglobals:  g,\n\t\t\tunsafe:   unsafe,\n\t\t}\n\t\tNewGenericVisitor(xform.Visit).Walk(e)\n\t}\n\n\treturn reordered, unsafe\n}\n\ntype bodySafetyTransformer struct {\n\tbuiltins map[string]*Builtin\n\tarity    func(Ref) int\n\tcurrent  *Expr\n\tglobals  VarSet\n\tunsafe   unsafeVars\n}\n\nfunc (xform *bodySafetyTransformer) Visit(x interface{}) bool {\n\tswitch term := x.(type) {\n\tcase *Term:\n\t\tswitch x := term.Value.(type) {\n\t\tcase *object:\n\t\t\tcpy, _ := x.Map(func(k, v *Term) (*Term, *Term, error) {\n\t\t\t\tkcpy := k.Copy()\n\t\t\t\tNewGenericVisitor(xform.Visit).Walk(kcpy)\n\t\t\t\tvcpy := v.Copy()\n\t\t\t\tNewGenericVisitor(xform.Visit).Walk(vcpy)\n\t\t\t\treturn kcpy, vcpy, nil\n\t\t\t})\n\t\t\tterm.Value = cpy\n\t\t\treturn true\n\t\tcase *set:\n\t\t\tcpy, _ := x.Map(func(v *Term) (*Term, error) {\n\t\t\t\tvcpy := v.Copy()\n\t\t\t\tNewGenericVisitor(xform.Visit).Walk(vcpy)\n\t\t\t\treturn vcpy, nil\n\t\t\t})\n\t\t\tterm.Value = cpy\n\t\t\treturn true\n\t\tcase *ArrayComprehension:\n\t\t\txform.reorderArrayComprehensionSafety(x)\n\t\t\treturn true\n\t\tcase *ObjectComprehension:\n\t\t\txform.reorderObjectComprehensionSafety(x)\n\t\t\treturn true\n\t\tcase *SetComprehension:\n\t\t\txform.reorderSetComprehensionSafety(x)\n\t\t\treturn true\n\t\t}\n\tcase *Expr:\n\t\tif ev, ok := term.Terms.(*Every); ok {\n\t\t\txform.globals.Update(ev.KeyValueVars())\n\t\t\tev.Body = xform.reorderComprehensionSafety(NewVarSet(), ev.Body)\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (xform *bodySafetyTransformer) reorderComprehensionSafety(tv VarSet, body Body) Body {\n\tbv := body.Vars(SafetyCheckVisitorParams)\n\tbv.Update(xform.globals)\n\tuv := tv.Diff(bv)\n\tfor v := range uv {\n\t\txform.unsafe.Add(xform.current, v)\n\t}\n\n\tr, u := reorderBodyForSafety(xform.builtins, xform.arity, xform.globals, body)\n\tif len(u) == 0 {\n\t\treturn r\n\t}\n\n\txform.unsafe.Update(u)\n\treturn body\n}\n\nfunc (xform *bodySafetyTransformer) reorderArrayComprehensionSafety(ac *ArrayComprehension) {\n\tac.Body = xform.reorderComprehensionSafety(ac.Term.Vars(), ac.Body)\n}\n\nfunc (xform *bodySafetyTransformer) reorderObjectComprehensionSafety(oc *ObjectComprehension) {\n\ttv := oc.Key.Vars()\n\ttv.Update(oc.Value.Vars())\n\toc.Body = xform.reorderComprehensionSafety(tv, oc.Body)\n}\n\nfunc (xform *bodySafetyTransformer) reorderSetComprehensionSafety(sc *SetComprehension) {\n\tsc.Body = xform.reorderComprehensionSafety(sc.Term.Vars(), sc.Body)\n}\n\n// unsafeVarsInClosures collects vars that are contained in closures within\n// this expression.\nfunc unsafeVarsInClosures(e *Expr, arity func(Ref) int, safe VarSet) VarSet {\n\tvs := VarSet{}\n\tWalkClosures(e, func(x interface{}) bool {\n\t\tvis := &VarVisitor{vars: vs}\n\t\tif ev, ok := x.(*Every); ok {\n\t\t\tvis.Walk(ev.Body)\n\t\t\treturn true\n\t\t}\n\t\tvis.Walk(x)\n\t\treturn true\n\t})\n\treturn vs\n}\n\n// OutputVarsFromBody returns all variables which are the \"output\" for\n// the given body. For safety checks this means that they would be\n// made safe by the body.\nfunc OutputVarsFromBody(c *Compiler, body Body, safe VarSet) VarSet {\n\treturn outputVarsForBody(body, c.GetArity, safe)\n}\n\nfunc outputVarsForBody(body Body, arity func(Ref) int, safe VarSet) VarSet {\n\to := safe.Copy()\n\tfor _, e := range body {\n\t\to.Update(outputVarsForExpr(e, arity, o))\n\t}\n\treturn o.Diff(safe)\n}\n\n// OutputVarsFromExpr returns all variables which are the \"output\" for\n// the given expression. For safety checks this means that they would be\n// made safe by the expr.\nfunc OutputVarsFromExpr(c *Compiler, expr *Expr, safe VarSet) VarSet {\n\treturn outputVarsForExpr(expr, c.GetArity, safe)\n}\n\nfunc outputVarsForExpr(expr *Expr, arity func(Ref) int, safe VarSet) VarSet {\n\n\t// Negated expressions must be safe.\n\tif expr.Negated {\n\t\treturn VarSet{}\n\t}\n\n\t// With modifier inputs must be safe.\n\tfor _, with := range expr.With {\n\t\tvis := NewVarVisitor().WithParams(SafetyCheckVisitorParams)\n\t\tvis.Walk(with)\n\t\tvars := vis.Vars()\n\t\tunsafe := vars.Diff(safe)\n\t\tif len(unsafe) > 0 {\n\t\t\treturn VarSet{}\n\t\t}\n\t}\n\n\tswitch terms := expr.Terms.(type) {\n\tcase *Term:\n\t\treturn outputVarsForTerms(expr, safe)\n\tcase []*Term:\n\t\tif expr.IsEquality() {\n\t\t\treturn outputVarsForExprEq(expr, safe)\n\t\t}\n\n\t\toperator, ok := terms[0].Value.(Ref)\n\t\tif !ok {\n\t\t\treturn VarSet{}\n\t\t}\n\n\t\tar := arity(operator)\n\t\tif ar < 0 {\n\t\t\treturn VarSet{}\n\t\t}\n\n\t\treturn outputVarsForExprCall(expr, ar, safe, terms)\n\tcase *Every:\n\t\treturn outputVarsForTerms(terms.Domain, safe)\n\tdefault:\n\t\tpanic(\"illegal expression\")\n\t}\n}\n\nfunc outputVarsForExprEq(expr *Expr, safe VarSet) VarSet {\n\n\tif !validEqAssignArgCount(expr) {\n\t\treturn safe\n\t}\n\n\toutput := outputVarsForTerms(expr, safe)\n\toutput.Update(safe)\n\toutput.Update(Unify(output, expr.Operand(0), expr.Operand(1)))\n\n\treturn output.Diff(safe)\n}\n\nfunc outputVarsForExprCall(expr *Expr, arity int, safe VarSet, terms []*Term) VarSet {\n\n\toutput := outputVarsForTerms(expr, safe)\n\n\tnumInputTerms := arity + 1\n\tif numInputTerms >= len(terms) {\n\t\treturn output\n\t}\n\n\tparams := VarVisitorParams{\n\t\tSkipClosures:   true,\n\t\tSkipSets:       true,\n\t\tSkipObjectKeys: true,\n\t\tSkipRefHead:    true,\n\t}\n\tvis := NewVarVisitor().WithParams(params)\n\tvis.Walk(Args(terms[:numInputTerms]))\n\tunsafe := vis.Vars().Diff(output).Diff(safe)\n\n\tif len(unsafe) > 0 {\n\t\treturn VarSet{}\n\t}\n\n\tvis = NewVarVisitor().WithParams(params)\n\tvis.Walk(Args(terms[numInputTerms:]))\n\toutput.Update(vis.vars)\n\treturn output\n}\n\nfunc outputVarsForTerms(expr interface{}, safe VarSet) VarSet {\n\toutput := VarSet{}\n\tWalkTerms(expr, func(x *Term) bool {\n\t\tswitch r := x.Value.(type) {\n\t\tcase *SetComprehension, *ArrayComprehension, *ObjectComprehension:\n\t\t\treturn true\n\t\tcase Ref:\n\t\t\tif !isRefSafe(r, safe) {\n\t\t\t\treturn true\n\t\t\t}\n\t\t\toutput.Update(r.OutputVars())\n\t\t\treturn false\n\t\t}\n\t\treturn false\n\t})\n\treturn output\n}\n\ntype equalityFactory struct {\n\tgen *localVarGenerator\n}\n\nfunc newEqualityFactory(gen *localVarGenerator) *equalityFactory {\n\treturn &equalityFactory{gen}\n}\n\nfunc (f *equalityFactory) Generate(other *Term) *Expr {\n\tterm := NewTerm(f.gen.Generate()).SetLocation(other.Location)\n\texpr := Equality.Expr(term, other)\n\texpr.Generated = true\n\texpr.Location = other.Location\n\treturn expr\n}\n\ntype localVarGenerator struct {\n\texclude VarSet\n\tsuffix  string\n\tnext    int\n}\n\nfunc newLocalVarGeneratorForModuleSet(sorted []string, modules map[string]*Module) *localVarGenerator {\n\texclude := NewVarSet()\n\tvis := &VarVisitor{vars: exclude}\n\tfor _, key := range sorted {\n\t\tvis.Walk(modules[key])\n\t}\n\treturn &localVarGenerator{exclude: exclude, next: 0}\n}\n\nfunc newLocalVarGenerator(suffix string, node interface{}) *localVarGenerator {\n\texclude := NewVarSet()\n\tvis := &VarVisitor{vars: exclude}\n\tvis.Walk(node)\n\treturn &localVarGenerator{exclude: exclude, suffix: suffix, next: 0}\n}\n\nfunc (l *localVarGenerator) Generate() Var {\n\tfor {\n\t\tresult := Var(\"__local\" + l.suffix + strconv.Itoa(l.next) + \"__\")\n\t\tl.next++\n\t\tif !l.exclude.Contains(result) {\n\t\t\treturn result\n\t\t}\n\t}\n}\n\nfunc getGlobals(pkg *Package, rules []Var, imports []*Import) map[Var]*usedRef {\n\n\tglobals := map[Var]*usedRef{}\n\n\t// Populate globals with exports within the package.\n\tfor _, v := range rules {\n\t\tglobal := append(Ref{}, pkg.Path...)\n\t\tglobal = append(global, &Term{Value: String(v)})\n\t\tglobals[v] = &usedRef{ref: global}\n\t}\n\n\t// Populate globals with imports.\n\tfor _, imp := range imports {\n\t\tpath := imp.Path.Value.(Ref)\n\t\tif FutureRootDocument.Equal(path[0]) {\n\t\t\tcontinue // ignore future imports\n\t\t}\n\t\tglobals[imp.Name()] = &usedRef{ref: path}\n\t}\n\n\treturn globals\n}\n\nfunc requiresEval(x *Term) bool {\n\tif x == nil {\n\t\treturn false\n\t}\n\treturn ContainsRefs(x) || ContainsComprehensions(x)\n}\n\nfunc resolveRef(globals map[Var]*usedRef, ignore *declaredVarStack, ref Ref) Ref {\n\n\tr := Ref{}\n\tfor i, x := range ref {\n\t\tswitch v := x.Value.(type) {\n\t\tcase Var:\n\t\t\tif g, ok := globals[v]; ok && !ignore.Contains(v) {\n\t\t\t\tcpy := g.ref.Copy()\n\t\t\t\tfor i := range cpy {\n\t\t\t\t\tcpy[i].SetLocation(x.Location)\n\t\t\t\t}\n\t\t\t\tif i == 0 {\n\t\t\t\t\tr = cpy\n\t\t\t\t} else {\n\t\t\t\t\tr = append(r, NewTerm(cpy).SetLocation(x.Location))\n\t\t\t\t}\n\t\t\t\tg.used = true\n\t\t\t} else {\n\t\t\t\tr = append(r, x)\n\t\t\t}\n\t\tcase Ref, *Array, Object, Set, *ArrayComprehension, *SetComprehension, *ObjectComprehension, Call:\n\t\t\tr = append(r, resolveRefsInTerm(globals, ignore, x))\n\t\tdefault:\n\t\t\tr = append(r, x)\n\t\t}\n\t}\n\n\treturn r\n}\n\ntype usedRef struct {\n\tref  Ref\n\tused bool\n}\n\nfunc resolveRefsInRule(globals map[Var]*usedRef, rule *Rule) error {\n\tignore := &declaredVarStack{}\n\n\tvars := NewVarSet()\n\tvar vis *GenericVisitor\n\tvar err error\n\n\t// Walk args to collect vars and transform body so that callers can shadow\n\t// root documents.\n\tvis = NewGenericVisitor(func(x interface{}) bool {\n\t\tif err != nil {\n\t\t\treturn true\n\t\t}\n\t\tswitch x := x.(type) {\n\t\tcase Var:\n\t\t\tvars.Add(x)\n\n\t\t// Object keys cannot be pattern matched so only walk values.\n\t\tcase *object:\n\t\t\tx.Foreach(func(k, v *Term) {\n\t\t\t\tvis.Walk(v)\n\t\t\t})\n\n\t\t// Skip terms that could contain vars that cannot be pattern matched.\n\t\tcase Set, *ArrayComprehension, *SetComprehension, *ObjectComprehension, Call:\n\t\t\treturn true\n\n\t\tcase *Term:\n\t\t\tif _, ok := x.Value.(Ref); ok {\n\t\t\t\tif RootDocumentRefs.Contains(x) {\n\t\t\t\t\t// We could support args named input, data, etc. however\n\t\t\t\t\t// this would require rewriting terms in the head and body.\n\t\t\t\t\t// Preventing root document shadowing is simpler, and\n\t\t\t\t\t// arguably, will prevent confusing names from being used.\n\t\t\t\t\terr = fmt.Errorf(\"args must not shadow %v (use a different variable name)\", x)\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn false\n\t})\n\n\tvis.Walk(rule.Head.Args)\n\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tignore.Push(vars)\n\tignore.Push(declaredVars(rule.Body))\n\n\tif rule.Head.Key != nil {\n\t\trule.Head.Key = resolveRefsInTerm(globals, ignore, rule.Head.Key)\n\t}\n\n\tif rule.Head.Value != nil {\n\t\trule.Head.Value = resolveRefsInTerm(globals, ignore, rule.Head.Value)\n\t}\n\n\trule.Body = resolveRefsInBody(globals, ignore, rule.Body)\n\treturn nil\n}\n\nfunc resolveRefsInBody(globals map[Var]*usedRef, ignore *declaredVarStack, body Body) Body {\n\tr := make([]*Expr, 0, len(body))\n\tfor _, expr := range body {\n\t\tr = append(r, resolveRefsInExpr(globals, ignore, expr))\n\t}\n\treturn r\n}\n\nfunc resolveRefsInExpr(globals map[Var]*usedRef, ignore *declaredVarStack, expr *Expr) *Expr {\n\tcpy := *expr\n\tswitch ts := expr.Terms.(type) {\n\tcase *Term:\n\t\tcpy.Terms = resolveRefsInTerm(globals, ignore, ts)\n\tcase []*Term:\n\t\tbuf := make([]*Term, len(ts))\n\t\tfor i := 0; i < len(ts); i++ {\n\t\t\tbuf[i] = resolveRefsInTerm(globals, ignore, ts[i])\n\t\t}\n\t\tcpy.Terms = buf\n\tcase *SomeDecl:\n\t\tif val, ok := ts.Symbols[0].Value.(Call); ok {\n\t\t\tcpy.Terms = &SomeDecl{Symbols: []*Term{CallTerm(resolveRefsInTermSlice(globals, ignore, val)...)}}\n\t\t}\n\tcase *Every:\n\t\tlocals := NewVarSet()\n\t\tif ts.Key != nil {\n\t\t\tlocals.Update(ts.Key.Vars())\n\t\t}\n\t\tlocals.Update(ts.Value.Vars())\n\t\tignore.Push(locals)\n\t\tcpy.Terms = &Every{\n\t\t\tKey:    ts.Key.Copy(),   // TODO(sr): do more?\n\t\t\tValue:  ts.Value.Copy(), // TODO(sr): do more?\n\t\t\tDomain: resolveRefsInTerm(globals, ignore, ts.Domain),\n\t\t\tBody:   resolveRefsInBody(globals, ignore, ts.Body),\n\t\t}\n\t\tignore.Pop()\n\t}\n\tfor _, w := range cpy.With {\n\t\tw.Target = resolveRefsInTerm(globals, ignore, w.Target)\n\t\tw.Value = resolveRefsInTerm(globals, ignore, w.Value)\n\t}\n\treturn &cpy\n}\n\nfunc resolveRefsInTerm(globals map[Var]*usedRef, ignore *declaredVarStack, term *Term) *Term {\n\tswitch v := term.Value.(type) {\n\tcase Var:\n\t\tif g, ok := globals[v]; ok && !ignore.Contains(v) {\n\t\t\tcpy := g.ref.Copy()\n\t\t\tfor i := range cpy {\n\t\t\t\tcpy[i].SetLocation(term.Location)\n\t\t\t}\n\t\t\tg.used = true\n\t\t\treturn NewTerm(cpy).SetLocation(term.Location)\n\t\t}\n\t\treturn term\n\tcase Ref:\n\t\tfqn := resolveRef(globals, ignore, v)\n\t\tcpy := *term\n\t\tcpy.Value = fqn\n\t\treturn &cpy\n\tcase *object:\n\t\tcpy := *term\n\t\tcpy.Value, _ = v.Map(func(k, v *Term) (*Term, *Term, error) {\n\t\t\tk = resolveRefsInTerm(globals, ignore, k)\n\t\t\tv = resolveRefsInTerm(globals, ignore, v)\n\t\t\treturn k, v, nil\n\t\t})\n\t\treturn &cpy\n\tcase *Array:\n\t\tcpy := *term\n\t\tcpy.Value = NewArray(resolveRefsInTermArray(globals, ignore, v)...)\n\t\treturn &cpy\n\tcase Call:\n\t\tcpy := *term\n\t\tcpy.Value = Call(resolveRefsInTermSlice(globals, ignore, v))\n\t\treturn &cpy\n\tcase Set:\n\t\ts, _ := v.Map(func(e *Term) (*Term, error) {\n\t\t\treturn resolveRefsInTerm(globals, ignore, e), nil\n\t\t})\n\t\tcpy := *term\n\t\tcpy.Value = s\n\t\treturn &cpy\n\tcase *ArrayComprehension:\n\t\tac := &ArrayComprehension{}\n\t\tignore.Push(declaredVars(v.Body))\n\t\tac.Term = resolveRefsInTerm(globals, ignore, v.Term)\n\t\tac.Body = resolveRefsInBody(globals, ignore, v.Body)\n\t\tcpy := *term\n\t\tcpy.Value = ac\n\t\tignore.Pop()\n\t\treturn &cpy\n\tcase *ObjectComprehension:\n\t\toc := &ObjectComprehension{}\n\t\tignore.Push(declaredVars(v.Body))\n\t\toc.Key = resolveRefsInTerm(globals, ignore, v.Key)\n\t\toc.Value = resolveRefsInTerm(globals, ignore, v.Value)\n\t\toc.Body = resolveRefsInBody(globals, ignore, v.Body)\n\t\tcpy := *term\n\t\tcpy.Value = oc\n\t\tignore.Pop()\n\t\treturn &cpy\n\tcase *SetComprehension:\n\t\tsc := &SetComprehension{}\n\t\tignore.Push(declaredVars(v.Body))\n\t\tsc.Term = resolveRefsInTerm(globals, ignore, v.Term)\n\t\tsc.Body = resolveRefsInBody(globals, ignore, v.Body)\n\t\tcpy := *term\n\t\tcpy.Value = sc\n\t\tignore.Pop()\n\t\treturn &cpy\n\tdefault:\n\t\treturn term\n\t}\n}\n\nfunc resolveRefsInTermArray(globals map[Var]*usedRef, ignore *declaredVarStack, terms *Array) []*Term {\n\tcpy := make([]*Term, terms.Len())\n\tfor i := 0; i < terms.Len(); i++ {\n\t\tcpy[i] = resolveRefsInTerm(globals, ignore, terms.Elem(i))\n\t}\n\treturn cpy\n}\n\nfunc resolveRefsInTermSlice(globals map[Var]*usedRef, ignore *declaredVarStack, terms []*Term) []*Term {\n\tcpy := make([]*Term, len(terms))\n\tfor i := 0; i < len(terms); i++ {\n\t\tcpy[i] = resolveRefsInTerm(globals, ignore, terms[i])\n\t}\n\treturn cpy\n}\n\ntype declaredVarStack []VarSet\n\nfunc (s declaredVarStack) Contains(v Var) bool {\n\tfor i := len(s) - 1; i >= 0; i-- {\n\t\tif _, ok := s[i][v]; ok {\n\t\t\treturn ok\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (s declaredVarStack) Add(v Var) {\n\ts[len(s)-1].Add(v)\n}\n\nfunc (s *declaredVarStack) Push(vs VarSet) {\n\t*s = append(*s, vs)\n}\n\nfunc (s *declaredVarStack) Pop() {\n\tcurr := *s\n\t*s = curr[:len(curr)-1]\n}\n\nfunc declaredVars(x interface{}) VarSet {\n\tvars := NewVarSet()\n\tvis := NewGenericVisitor(func(x interface{}) bool {\n\t\tswitch x := x.(type) {\n\t\tcase *Expr:\n\t\t\tif x.IsAssignment() && validEqAssignArgCount(x) {\n\t\t\t\tWalkVars(x.Operand(0), func(v Var) bool {\n\t\t\t\t\tvars.Add(v)\n\t\t\t\t\treturn false\n\t\t\t\t})\n\t\t\t} else if decl, ok := x.Terms.(*SomeDecl); ok {\n\t\t\t\tfor i := range decl.Symbols {\n\t\t\t\t\tswitch val := decl.Symbols[i].Value.(type) {\n\t\t\t\t\tcase Var:\n\t\t\t\t\t\tvars.Add(val)\n\t\t\t\t\tcase Call:\n\t\t\t\t\t\targs := val[1:]\n\t\t\t\t\t\tif len(args) == 3 { // some x, y in xs\n\t\t\t\t\t\t\tWalkVars(args[1], func(v Var) bool {\n\t\t\t\t\t\t\t\tvars.Add(v)\n\t\t\t\t\t\t\t\treturn false\n\t\t\t\t\t\t\t})\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// some x in xs\n\t\t\t\t\t\tWalkVars(args[0], func(v Var) bool {\n\t\t\t\t\t\t\tvars.Add(v)\n\t\t\t\t\t\t\treturn false\n\t\t\t\t\t\t})\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\tcase *ArrayComprehension, *SetComprehension, *ObjectComprehension:\n\t\t\treturn true\n\t\t}\n\t\treturn false\n\t})\n\tvis.Walk(x)\n\treturn vars\n}\n\n// rewriteComprehensionTerms will rewrite comprehensions so that the term part\n// is bound to a variable in the body. This allows any type of term to be used\n// in the term part (even if the term requires evaluation.)\n//\n// For instance, given the following comprehension:\n//\n// [x[0] | x = y[_]; y = [1,2,3]]\n//\n// The comprehension would be rewritten as:\n//\n// [__local0__ | x = y[_]; y = [1,2,3]; __local0__ = x[0]]\nfunc rewriteComprehensionTerms(f *equalityFactory, node interface{}) (interface{}, error) {\n\treturn TransformComprehensions(node, func(x interface{}) (Value, error) {\n\t\tswitch x := x.(type) {\n\t\tcase *ArrayComprehension:\n\t\t\tif requiresEval(x.Term) {\n\t\t\t\texpr := f.Generate(x.Term)\n\t\t\t\tx.Term = expr.Operand(0)\n\t\t\t\tx.Body.Append(expr)\n\t\t\t}\n\t\t\treturn x, nil\n\t\tcase *SetComprehension:\n\t\t\tif requiresEval(x.Term) {\n\t\t\t\texpr := f.Generate(x.Term)\n\t\t\t\tx.Term = expr.Operand(0)\n\t\t\t\tx.Body.Append(expr)\n\t\t\t}\n\t\t\treturn x, nil\n\t\tcase *ObjectComprehension:\n\t\t\tif requiresEval(x.Key) {\n\t\t\t\texpr := f.Generate(x.Key)\n\t\t\t\tx.Key = expr.Operand(0)\n\t\t\t\tx.Body.Append(expr)\n\t\t\t}\n\t\t\tif requiresEval(x.Value) {\n\t\t\t\texpr := f.Generate(x.Value)\n\t\t\t\tx.Value = expr.Operand(0)\n\t\t\t\tx.Body.Append(expr)\n\t\t\t}\n\t\t\treturn x, nil\n\t\t}\n\t\tpanic(\"illegal type\")\n\t})\n}\n\n// rewriteEquals will rewrite exprs under x as unification calls instead of ==\n// calls. For example:\n//\n// data.foo == data.bar is rewritten as data.foo = data.bar\n//\n// This stage should only run the safety check (since == is a built-in with no\n// outputs, so the inputs must not be marked as safe.)\n//\n// This stage is not executed by the query compiler by default because when\n// callers specify == instead of = they expect to receive a true/false/undefined\n// result back whereas with = the result is only ever true/undefined. For\n// partial evaluation cases we do want to rewrite == to = to simplify the\n// result.\nfunc rewriteEquals(x interface{}) {\n\tdoubleEq := Equal.Ref()\n\tunifyOp := Equality.Ref()\n\tt := NewGenericTransformer(func(x interface{}) (interface{}, error) {\n\t\tif x, ok := x.(*Expr); ok && x.IsCall() {\n\t\t\toperator := x.Operator()\n\t\t\tif operator.Equal(doubleEq) && len(x.Operands()) == 2 {\n\t\t\t\tx.SetOperator(NewTerm(unifyOp))\n\t\t\t}\n\t\t}\n\t\treturn x, nil\n\t})\n\t_, _ = Transform(t, x) // ignore error\n}\n\n// rewriteDynamics will rewrite the body so that dynamic terms (i.e., refs and\n// comprehensions) are bound to vars earlier in the query. This translation\n// results in eager evaluation.\n//\n// For instance, given the following query:\n//\n// foo(data.bar) = 1\n//\n// The rewritten version will be:\n//\n// __local0__ = data.bar; foo(__local0__) = 1\nfunc rewriteDynamics(f *equalityFactory, body Body) Body {\n\tresult := make(Body, 0, len(body))\n\tfor _, expr := range body {\n\t\tswitch {\n\t\tcase expr.IsEquality():\n\t\t\tresult = rewriteDynamicsEqExpr(f, expr, result)\n\t\tcase expr.IsCall():\n\t\t\tresult = rewriteDynamicsCallExpr(f, expr, result)\n\t\tcase expr.IsEvery():\n\t\t\tresult = rewriteDynamicsEveryExpr(f, expr, result)\n\t\tdefault:\n\t\t\tresult = rewriteDynamicsTermExpr(f, expr, result)\n\t\t}\n\t}\n\treturn result\n}\n\nfunc appendExpr(body Body, expr *Expr) Body {\n\tbody.Append(expr)\n\treturn body\n}\n\nfunc rewriteDynamicsEqExpr(f *equalityFactory, expr *Expr, result Body) Body {\n\tif !validEqAssignArgCount(expr) {\n\t\treturn appendExpr(result, expr)\n\t}\n\tterms := expr.Terms.([]*Term)\n\tresult, terms[1] = rewriteDynamicsInTerm(expr, f, terms[1], result)\n\tresult, terms[2] = rewriteDynamicsInTerm(expr, f, terms[2], result)\n\treturn appendExpr(result, expr)\n}\n\nfunc rewriteDynamicsCallExpr(f *equalityFactory, expr *Expr, result Body) Body {\n\tterms := expr.Terms.([]*Term)\n\tfor i := 1; i < len(terms); i++ {\n\t\tresult, terms[i] = rewriteDynamicsOne(expr, f, terms[i], result)\n\t}\n\treturn appendExpr(result, expr)\n}\n\nfunc rewriteDynamicsEveryExpr(f *equalityFactory, expr *Expr, result Body) Body {\n\tev := expr.Terms.(*Every)\n\tresult, ev.Domain = rewriteDynamicsOne(expr, f, ev.Domain, result)\n\tev.Body = rewriteDynamics(f, ev.Body)\n\treturn appendExpr(result, expr)\n}\n\nfunc rewriteDynamicsTermExpr(f *equalityFactory, expr *Expr, result Body) Body {\n\tterm := expr.Terms.(*Term)\n\tresult, expr.Terms = rewriteDynamicsInTerm(expr, f, term, result)\n\treturn appendExpr(result, expr)\n}\n\nfunc rewriteDynamicsInTerm(original *Expr, f *equalityFactory, term *Term, result Body) (Body, *Term) {\n\tswitch v := term.Value.(type) {\n\tcase Ref:\n\t\tfor i := 1; i < len(v); i++ {\n\t\t\tresult, v[i] = rewriteDynamicsOne(original, f, v[i], result)\n\t\t}\n\tcase *ArrayComprehension:\n\t\tv.Body = rewriteDynamics(f, v.Body)\n\tcase *SetComprehension:\n\t\tv.Body = rewriteDynamics(f, v.Body)\n\tcase *ObjectComprehension:\n\t\tv.Body = rewriteDynamics(f, v.Body)\n\tdefault:\n\t\tresult, term = rewriteDynamicsOne(original, f, term, result)\n\t}\n\treturn result, term\n}\n\nfunc rewriteDynamicsOne(original *Expr, f *equalityFactory, term *Term, result Body) (Body, *Term) {\n\tswitch v := term.Value.(type) {\n\tcase Ref:\n\t\tfor i := 1; i < len(v); i++ {\n\t\t\tresult, v[i] = rewriteDynamicsOne(original, f, v[i], result)\n\t\t}\n\t\tgenerated := f.Generate(term)\n\t\tgenerated.With = original.With\n\t\tresult.Append(generated)\n\t\treturn result, result[len(result)-1].Operand(0)\n\tcase *Array:\n\t\tfor i := 0; i < v.Len(); i++ {\n\t\t\tvar t *Term\n\t\t\tresult, t = rewriteDynamicsOne(original, f, v.Elem(i), result)\n\t\t\tv.set(i, t)\n\t\t}\n\t\treturn result, term\n\tcase *object:\n\t\tcpy := NewObject()\n\t\tv.Foreach(func(key, value *Term) {\n\t\t\tresult, key = rewriteDynamicsOne(original, f, key, result)\n\t\t\tresult, value = rewriteDynamicsOne(original, f, value, result)\n\t\t\tcpy.Insert(key, value)\n\t\t})\n\t\treturn result, NewTerm(cpy).SetLocation(term.Location)\n\tcase Set:\n\t\tcpy := NewSet()\n\t\tfor _, term := range v.Slice() {\n\t\t\tvar rw *Term\n\t\t\tresult, rw = rewriteDynamicsOne(original, f, term, result)\n\t\t\tcpy.Add(rw)\n\t\t}\n\t\treturn result, NewTerm(cpy).SetLocation(term.Location)\n\tcase *ArrayComprehension:\n\t\tvar extra *Expr\n\t\tv.Body, extra = rewriteDynamicsComprehensionBody(original, f, v.Body, term)\n\t\tresult.Append(extra)\n\t\treturn result, result[len(result)-1].Operand(0)\n\tcase *SetComprehension:\n\t\tvar extra *Expr\n\t\tv.Body, extra = rewriteDynamicsComprehensionBody(original, f, v.Body, term)\n\t\tresult.Append(extra)\n\t\treturn result, result[len(result)-1].Operand(0)\n\tcase *ObjectComprehension:\n\t\tvar extra *Expr\n\t\tv.Body, extra = rewriteDynamicsComprehensionBody(original, f, v.Body, term)\n\t\tresult.Append(extra)\n\t\treturn result, result[len(result)-1].Operand(0)\n\t}\n\treturn result, term\n}\n\nfunc rewriteDynamicsComprehensionBody(original *Expr, f *equalityFactory, body Body, term *Term) (Body, *Expr) {\n\tbody = rewriteDynamics(f, body)\n\tgenerated := f.Generate(term)\n\tgenerated.With = original.With\n\treturn body, generated\n}\n\nfunc rewriteExprTermsInHead(gen *localVarGenerator, rule *Rule) {\n\tfor i := range rule.Head.Args {\n\t\tsupport, output := expandExprTerm(gen, rule.Head.Args[i])\n\t\tfor j := range support {\n\t\t\trule.Body.Append(support[j])\n\t\t}\n\t\trule.Head.Args[i] = output\n\t}\n\tif rule.Head.Key != nil {\n\t\tsupport, output := expandExprTerm(gen, rule.Head.Key)\n\t\tfor i := range support {\n\t\t\trule.Body.Append(support[i])\n\t\t}\n\t\trule.Head.Key = output\n\t}\n\tif rule.Head.Value != nil {\n\t\tsupport, output := expandExprTerm(gen, rule.Head.Value)\n\t\tfor i := range support {\n\t\t\trule.Body.Append(support[i])\n\t\t}\n\t\trule.Head.Value = output\n\t}\n}\n\nfunc rewriteExprTermsInBody(gen *localVarGenerator, body Body) Body {\n\tcpy := make(Body, 0, len(body))\n\tfor i := 0; i < len(body); i++ {\n\t\tfor _, expr := range expandExpr(gen, body[i]) {\n\t\t\tcpy.Append(expr)\n\t\t}\n\t}\n\treturn cpy\n}\n\nfunc expandExpr(gen *localVarGenerator, expr *Expr) (result []*Expr) {\n\tfor i := range expr.With {\n\t\textras, value := expandExprTerm(gen, expr.With[i].Value)\n\t\texpr.With[i].Value = value\n\t\tresult = append(result, extras...)\n\t}\n\tswitch terms := expr.Terms.(type) {\n\tcase *Term:\n\t\textras, term := expandExprTerm(gen, terms)\n\t\tif len(expr.With) > 0 {\n\t\t\tfor i := range extras {\n\t\t\t\textras[i].With = expr.With\n\t\t\t}\n\t\t}\n\t\tresult = append(result, extras...)\n\t\texpr.Terms = term\n\t\tresult = append(result, expr)\n\tcase []*Term:\n\t\tfor i := 1; i < len(terms); i++ {\n\t\t\tvar extras []*Expr\n\t\t\textras, terms[i] = expandExprTerm(gen, terms[i])\n\t\t\tif len(expr.With) > 0 {\n\t\t\t\tfor i := range extras {\n\t\t\t\t\textras[i].With = expr.With\n\t\t\t\t}\n\t\t\t}\n\t\t\tresult = append(result, extras...)\n\t\t}\n\t\tresult = append(result, expr)\n\tcase *Every:\n\t\tvar extras []*Expr\n\t\tif _, ok := terms.Domain.Value.(Call); ok {\n\t\t\textras, terms.Domain = expandExprTerm(gen, terms.Domain)\n\t\t} else {\n\t\t\tterm := NewTerm(gen.Generate()).SetLocation(terms.Domain.Location)\n\t\t\teq := Equality.Expr(term, terms.Domain).SetLocation(terms.Domain.Location)\n\t\t\teq.Generated = true\n\t\t\teq.With = expr.With\n\t\t\textras = append(extras, eq)\n\t\t\tterms.Domain = term\n\t\t}\n\t\tterms.Body = rewriteExprTermsInBody(gen, terms.Body)\n\t\tresult = append(result, extras...)\n\t\tresult = append(result, expr)\n\t}\n\treturn\n}\n\nfunc expandExprTerm(gen *localVarGenerator, term *Term) (support []*Expr, output *Term) {\n\toutput = term\n\tswitch v := term.Value.(type) {\n\tcase Call:\n\t\tfor i := 1; i < len(v); i++ {\n\t\t\tvar extras []*Expr\n\t\t\textras, v[i] = expandExprTerm(gen, v[i])\n\t\t\tsupport = append(support, extras...)\n\t\t}\n\t\toutput = NewTerm(gen.Generate()).SetLocation(term.Location)\n\t\texpr := v.MakeExpr(output).SetLocation(term.Location)\n\t\texpr.Generated = true\n\t\tsupport = append(support, expr)\n\tcase Ref:\n\t\tsupport = expandExprRef(gen, v)\n\tcase *Array:\n\t\tsupport = expandExprTermArray(gen, v)\n\tcase *object:\n\t\tcpy, _ := v.Map(func(k, v *Term) (*Term, *Term, error) {\n\t\t\textras1, expandedKey := expandExprTerm(gen, k)\n\t\t\textras2, expandedValue := expandExprTerm(gen, v)\n\t\t\tsupport = append(support, extras1...)\n\t\t\tsupport = append(support, extras2...)\n\t\t\treturn expandedKey, expandedValue, nil\n\t\t})\n\t\toutput = NewTerm(cpy).SetLocation(term.Location)\n\tcase Set:\n\t\tcpy, _ := v.Map(func(x *Term) (*Term, error) {\n\t\t\textras, expanded := expandExprTerm(gen, x)\n\t\t\tsupport = append(support, extras...)\n\t\t\treturn expanded, nil\n\t\t})\n\t\toutput = NewTerm(cpy).SetLocation(term.Location)\n\tcase *ArrayComprehension:\n\t\tsupport, term := expandExprTerm(gen, v.Term)\n\t\tfor i := range support {\n\t\t\tv.Body.Append(support[i])\n\t\t}\n\t\tv.Term = term\n\t\tv.Body = rewriteExprTermsInBody(gen, v.Body)\n\tcase *SetComprehension:\n\t\tsupport, term := expandExprTerm(gen, v.Term)\n\t\tfor i := range support {\n\t\t\tv.Body.Append(support[i])\n\t\t}\n\t\tv.Term = term\n\t\tv.Body = rewriteExprTermsInBody(gen, v.Body)\n\tcase *ObjectComprehension:\n\t\tsupport, key := expandExprTerm(gen, v.Key)\n\t\tfor i := range support {\n\t\t\tv.Body.Append(support[i])\n\t\t}\n\t\tv.Key = key\n\t\tsupport, value := expandExprTerm(gen, v.Value)\n\t\tfor i := range support {\n\t\t\tv.Body.Append(support[i])\n\t\t}\n\t\tv.Value = value\n\t\tv.Body = rewriteExprTermsInBody(gen, v.Body)\n\t}\n\treturn\n}\n\nfunc expandExprRef(gen *localVarGenerator, v []*Term) (support []*Expr) {\n\t// Start by calling a normal expandExprTerm on all terms.\n\tsupport = expandExprTermSlice(gen, v)\n\n\t// Rewrite references in order to support indirect references.  We rewrite\n\t// e.g.\n\t//\n\t//     [1, 2, 3][i]\n\t//\n\t// to\n\t//\n\t//     __local_var = [1, 2, 3]\n\t//     __local_var[i]\n\t//\n\t// to support these.  This only impacts the reference subject, i.e. the\n\t// first item in the slice.\n\tvar subject = v[0]\n\tswitch subject.Value.(type) {\n\tcase *Array, Object, Set, *ArrayComprehension, *SetComprehension, *ObjectComprehension, Call:\n\t\tf := newEqualityFactory(gen)\n\t\tassignToLocal := f.Generate(subject)\n\t\tsupport = append(support, assignToLocal)\n\t\tv[0] = assignToLocal.Operand(0)\n\t}\n\treturn\n}\n\nfunc expandExprTermArray(gen *localVarGenerator, arr *Array) (support []*Expr) {\n\tfor i := 0; i < arr.Len(); i++ {\n\t\textras, v := expandExprTerm(gen, arr.Elem(i))\n\t\tarr.set(i, v)\n\t\tsupport = append(support, extras...)\n\t}\n\treturn\n}\n\nfunc expandExprTermSlice(gen *localVarGenerator, v []*Term) (support []*Expr) {\n\tfor i := 0; i < len(v); i++ {\n\t\tvar extras []*Expr\n\t\textras, v[i] = expandExprTerm(gen, v[i])\n\t\tsupport = append(support, extras...)\n\t}\n\treturn\n}\n\ntype localDeclaredVars struct {\n\tvars []*declaredVarSet\n\n\t// rewritten contains a mapping of *all* user-defined variables\n\t// that have been rewritten whereas vars contains the state\n\t// from the current query (not any nested queries, and all vars\n\t// seen).\n\trewritten map[Var]Var\n}\n\ntype varOccurrence int\n\nconst (\n\tnewVar varOccurrence = iota\n\targVar\n\tseenVar\n\tassignedVar\n\tdeclaredVar\n)\n\ntype declaredVarSet struct {\n\tvs         map[Var]Var\n\treverse    map[Var]Var\n\toccurrence map[Var]varOccurrence\n\tcount      map[Var]int\n}\n\nfunc newDeclaredVarSet() *declaredVarSet {\n\treturn &declaredVarSet{\n\t\tvs:         map[Var]Var{},\n\t\treverse:    map[Var]Var{},\n\t\toccurrence: map[Var]varOccurrence{},\n\t\tcount:      map[Var]int{},\n\t}\n}\n\nfunc newLocalDeclaredVars() *localDeclaredVars {\n\treturn &localDeclaredVars{\n\t\tvars:      []*declaredVarSet{newDeclaredVarSet()},\n\t\trewritten: map[Var]Var{},\n\t}\n}\n\nfunc (s *localDeclaredVars) Push() {\n\ts.vars = append(s.vars, newDeclaredVarSet())\n}\n\nfunc (s *localDeclaredVars) Pop() *declaredVarSet {\n\tsl := s.vars\n\tcurr := sl[len(sl)-1]\n\ts.vars = sl[:len(sl)-1]\n\treturn curr\n}\n\nfunc (s localDeclaredVars) Peek() *declaredVarSet {\n\treturn s.vars[len(s.vars)-1]\n}\n\nfunc (s localDeclaredVars) Insert(x, y Var, occurrence varOccurrence) {\n\telem := s.vars[len(s.vars)-1]\n\telem.vs[x] = y\n\telem.reverse[y] = x\n\telem.occurrence[x] = occurrence\n\n\telem.count[x] = 1\n\n\t// If the variable has been rewritten (where x != y, with y being\n\t// the generated value), store it in the map of rewritten vars.\n\t// Assume that the generated values are unique for the compilation.\n\tif !x.Equal(y) {\n\t\ts.rewritten[y] = x\n\t}\n}\n\nfunc (s localDeclaredVars) Declared(x Var) (y Var, ok bool) {\n\tfor i := len(s.vars) - 1; i >= 0; i-- {\n\t\tif y, ok = s.vars[i].vs[x]; ok {\n\t\t\treturn\n\t\t}\n\t}\n\treturn\n}\n\n// Occurrence returns a flag that indicates whether x has occurred in the\n// current scope.\nfunc (s localDeclaredVars) Occurrence(x Var) varOccurrence {\n\treturn s.vars[len(s.vars)-1].occurrence[x]\n}\n\n// GlobalOccurrence returns a flag that indicates whether x has occurred in the\n// global scope.\nfunc (s localDeclaredVars) GlobalOccurrence(x Var) (varOccurrence, bool) {\n\tfor i := len(s.vars) - 1; i >= 0; i-- {\n\t\tif occ, ok := s.vars[i].occurrence[x]; ok {\n\t\t\treturn occ, true\n\t\t}\n\t}\n\treturn newVar, false\n}\n\n// Seen marks x as seen by incrementing its counter\nfunc (s localDeclaredVars) Seen(x Var) {\n\tfor i := len(s.vars) - 1; i >= 0; i-- {\n\t\tdvs := s.vars[i]\n\t\tif c, ok := dvs.count[x]; ok {\n\t\t\tdvs.count[x] = c + 1\n\t\t\treturn\n\t\t}\n\t}\n\n\ts.vars[len(s.vars)-1].count[x] = 1\n}\n\n// Count returns how many times x has been seen\nfunc (s localDeclaredVars) Count(x Var) int {\n\tfor i := len(s.vars) - 1; i >= 0; i-- {\n\t\tif c, ok := s.vars[i].count[x]; ok {\n\t\t\treturn c\n\t\t}\n\t}\n\n\treturn 0\n}\n\n// rewriteLocalVars rewrites bodies to remove assignment/declaration\n// expressions. For example:\n//\n// a := 1; p[a]\n//\n// Is rewritten to:\n//\n// __local0__ = 1; p[__local0__]\n//\n// During rewriting, assignees are validated to prevent use before declaration.\nfunc rewriteLocalVars(g *localVarGenerator, stack *localDeclaredVars, used VarSet, body Body, strict bool) (Body, map[Var]Var, Errors) {\n\tvar errs Errors\n\tbody, errs = rewriteDeclaredVarsInBody(g, stack, used, body, errs, strict)\n\treturn body, stack.Pop().vs, errs\n}\n\nfunc rewriteDeclaredVarsInBody(g *localVarGenerator, stack *localDeclaredVars, used VarSet, body Body, errs Errors, strict bool) (Body, Errors) {\n\n\tvar cpy Body\n\n\tfor i := range body {\n\t\tvar expr *Expr\n\t\tswitch {\n\t\tcase body[i].IsAssignment():\n\t\t\texpr, errs = rewriteDeclaredAssignment(g, stack, body[i], errs, strict)\n\t\tcase body[i].IsSome():\n\t\t\texpr, errs = rewriteSomeDeclStatement(g, stack, body[i], errs, strict)\n\t\tcase body[i].IsEvery():\n\t\t\texpr, errs = rewriteEveryStatement(g, stack, body[i], errs, strict)\n\t\tdefault:\n\t\t\texpr, errs = rewriteDeclaredVarsInExpr(g, stack, body[i], errs, strict)\n\t\t}\n\t\tif expr != nil {\n\t\t\tcpy.Append(expr)\n\t\t}\n\t}\n\n\t// If the body only contained a var statement it will be empty at this\n\t// point. Append true to the body to ensure that it's non-empty (zero length\n\t// bodies are not supported.)\n\tif len(cpy) == 0 {\n\t\tcpy.Append(NewExpr(BooleanTerm(true)))\n\t}\n\n\terrs = checkUnusedAssignedVars(body[0].Loc(), stack, used, errs, strict)\n\treturn cpy, checkUnusedDeclaredVars(body[0].Loc(), stack, used, cpy, errs)\n}\n\nfunc checkUnusedAssignedVars(loc *Location, stack *localDeclaredVars, used VarSet, errs Errors, strict bool) Errors {\n\n\tif !strict || len(errs) > 0 {\n\t\treturn errs\n\t}\n\n\tdvs := stack.Peek()\n\tunused := NewVarSet()\n\n\tfor v, occ := range dvs.occurrence {\n\t\t// A var that was assigned in this scope must have been seen (used) more than once (the time of assignment) in\n\t\t// the same, or nested, scope to be counted as used.\n\t\tif !v.IsWildcard() && occ == assignedVar && stack.Count(v) <= 1 {\n\t\t\tunused.Add(dvs.vs[v])\n\t\t}\n\t}\n\n\trewrittenUsed := NewVarSet()\n\tfor v := range used {\n\t\tif gv, ok := stack.Declared(v); ok {\n\t\t\trewrittenUsed.Add(gv)\n\t\t} else {\n\t\t\trewrittenUsed.Add(v)\n\t\t}\n\t}\n\n\tunused = unused.Diff(rewrittenUsed)\n\n\tfor _, gv := range unused.Sorted() {\n\t\terrs = append(errs, NewError(CompileErr, loc, \"assigned var %v unused\", dvs.reverse[gv]))\n\t}\n\n\treturn errs\n}\n\nfunc checkUnusedDeclaredVars(loc *Location, stack *localDeclaredVars, used VarSet, cpy Body, errs Errors) Errors {\n\n\t// NOTE(tsandall): Do not generate more errors if there are existing\n\t// declaration errors.\n\tif len(errs) > 0 {\n\t\treturn errs\n\t}\n\n\tdvs := stack.Peek()\n\tdeclared := NewVarSet()\n\n\tfor v, occ := range dvs.occurrence {\n\t\tif occ == declaredVar {\n\t\t\tdeclared.Add(dvs.vs[v])\n\t\t}\n\t}\n\n\tbodyvars := cpy.Vars(VarVisitorParams{})\n\n\tfor v := range used {\n\t\tif gv, ok := stack.Declared(v); ok {\n\t\t\tbodyvars.Add(gv)\n\t\t} else {\n\t\t\tbodyvars.Add(v)\n\t\t}\n\t}\n\n\tunused := declared.Diff(bodyvars).Diff(used)\n\n\tfor _, gv := range unused.Sorted() {\n\t\trv := dvs.reverse[gv]\n\t\tif !rv.IsGenerated() {\n\t\t\terrs = append(errs, NewError(CompileErr, loc, \"declared var %v unused\", rv))\n\t\t}\n\t}\n\n\treturn errs\n}\n\nfunc rewriteEveryStatement(g *localVarGenerator, stack *localDeclaredVars, expr *Expr, errs Errors, strict bool) (*Expr, Errors) {\n\te := expr.Copy()\n\tevery := e.Terms.(*Every)\n\n\terrs = rewriteDeclaredVarsInTermRecursive(g, stack, every.Domain, errs, strict)\n\n\tstack.Push()\n\tdefer stack.Pop()\n\n\t// if the key exists, rewrite\n\tif every.Key != nil {\n\t\tif v := every.Key.Value.(Var); !v.IsWildcard() {\n\t\t\tgv, err := rewriteDeclaredVar(g, stack, v, declaredVar)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, append(errs, NewError(CompileErr, every.Loc(), err.Error()))\n\t\t\t}\n\t\t\tevery.Key.Value = gv\n\t\t}\n\t} else { // if the key doesn't exist, add dummy local\n\t\tevery.Key = NewTerm(g.Generate())\n\t}\n\n\t// value is always present\n\tif v := every.Value.Value.(Var); !v.IsWildcard() {\n\t\tgv, err := rewriteDeclaredVar(g, stack, v, declaredVar)\n\t\tif err != nil {\n\t\t\treturn nil, append(errs, NewError(CompileErr, every.Loc(), err.Error()))\n\t\t}\n\t\tevery.Value.Value = gv\n\t}\n\n\tused := NewVarSet()\n\tevery.Body, errs = rewriteDeclaredVarsInBody(g, stack, used, every.Body, errs, strict)\n\n\treturn rewriteDeclaredVarsInExpr(g, stack, e, errs, strict)\n}\n\nfunc rewriteSomeDeclStatement(g *localVarGenerator, stack *localDeclaredVars, expr *Expr, errs Errors, strict bool) (*Expr, Errors) {\n\te := expr.Copy()\n\tdecl := e.Terms.(*SomeDecl)\n\tfor i := range decl.Symbols {\n\t\tswitch v := decl.Symbols[i].Value.(type) {\n\t\tcase Var:\n\t\t\tif _, err := rewriteDeclaredVar(g, stack, v, declaredVar); err != nil {\n\t\t\t\treturn nil, append(errs, NewError(CompileErr, decl.Loc(), err.Error()))\n\t\t\t}\n\t\tcase Call:\n\t\t\tvar key, val, container *Term\n\t\t\tswitch len(v) {\n\t\t\tcase 4: // member3\n\t\t\t\tkey = v[1]\n\t\t\t\tval = v[2]\n\t\t\t\tcontainer = v[3]\n\t\t\tcase 3: // member\n\t\t\t\tkey = NewTerm(g.Generate())\n\t\t\t\tval = v[1]\n\t\t\t\tcontainer = v[2]\n\t\t\t}\n\n\t\t\tvar rhs *Term\n\t\t\tswitch c := container.Value.(type) {\n\t\t\tcase Ref:\n\t\t\t\trhs = RefTerm(append(c, key)...)\n\t\t\tdefault:\n\t\t\t\trhs = RefTerm(container, key)\n\t\t\t}\n\t\t\te.Terms = []*Term{\n\t\t\t\tRefTerm(VarTerm(Equality.Name)), val, rhs,\n\t\t\t}\n\n\t\t\tfor _, v0 := range outputVarsForExprEq(e, container.Vars()).Sorted() {\n\t\t\t\tif _, err := rewriteDeclaredVar(g, stack, v0, declaredVar); err != nil {\n\t\t\t\t\treturn nil, append(errs, NewError(CompileErr, decl.Loc(), err.Error()))\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn rewriteDeclaredVarsInExpr(g, stack, e, errs, strict)\n\t\t}\n\t}\n\treturn nil, errs\n}\n\nfunc rewriteDeclaredVarsInExpr(g *localVarGenerator, stack *localDeclaredVars, expr *Expr, errs Errors, strict bool) (*Expr, Errors) {\n\tvis := NewGenericVisitor(func(x interface{}) bool {\n\t\tvar stop bool\n\t\tswitch x := x.(type) {\n\t\tcase *Term:\n\t\t\tstop, errs = rewriteDeclaredVarsInTerm(g, stack, x, errs, strict)\n\t\tcase *With:\n\t\t\t_, errs = rewriteDeclaredVarsInTerm(g, stack, x.Value, errs, strict)\n\t\t\tstop = true\n\t\t}\n\t\treturn stop\n\t})\n\tvis.Walk(expr)\n\treturn expr, errs\n}\n\nfunc rewriteDeclaredAssignment(g *localVarGenerator, stack *localDeclaredVars, expr *Expr, errs Errors, strict bool) (*Expr, Errors) {\n\n\tif expr.Negated {\n\t\terrs = append(errs, NewError(CompileErr, expr.Location, \"cannot assign vars inside negated expression\"))\n\t\treturn expr, errs\n\t}\n\n\tnumErrsBefore := len(errs)\n\n\tif !validEqAssignArgCount(expr) {\n\t\treturn expr, errs\n\t}\n\n\t// Rewrite terms on right hand side capture seen vars and recursively\n\t// process comprehensions before left hand side is processed. Also\n\t// rewrite with modifier.\n\terrs = rewriteDeclaredVarsInTermRecursive(g, stack, expr.Operand(1), errs, strict)\n\n\tfor _, w := range expr.With {\n\t\terrs = rewriteDeclaredVarsInTermRecursive(g, stack, w.Value, errs, strict)\n\t}\n\n\t// Rewrite vars on left hand side with unique names. Catch redeclaration\n\t// and invalid term types here.\n\tvar vis func(t *Term) bool\n\n\tvis = func(t *Term) bool {\n\t\tswitch v := t.Value.(type) {\n\t\tcase Var:\n\t\t\tif gv, err := rewriteDeclaredVar(g, stack, v, assignedVar); err != nil {\n\t\t\t\terrs = append(errs, NewError(CompileErr, t.Location, err.Error()))\n\t\t\t} else {\n\t\t\t\tt.Value = gv\n\t\t\t}\n\t\t\treturn true\n\t\tcase *Array:\n\t\t\treturn false\n\t\tcase *object:\n\t\t\tv.Foreach(func(_, v *Term) {\n\t\t\t\tWalkTerms(v, vis)\n\t\t\t})\n\t\t\treturn true\n\t\tcase Ref:\n\t\t\tif RootDocumentRefs.Contains(t) {\n\t\t\t\tif gv, err := rewriteDeclaredVar(g, stack, v[0].Value.(Var), assignedVar); err != nil {\n\t\t\t\t\terrs = append(errs, NewError(CompileErr, t.Location, err.Error()))\n\t\t\t\t} else {\n\t\t\t\t\tt.Value = gv\n\t\t\t\t}\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t\terrs = append(errs, NewError(CompileErr, t.Location, \"cannot assign to %v\", TypeName(t.Value)))\n\t\treturn true\n\t}\n\n\tWalkTerms(expr.Operand(0), vis)\n\n\tif len(errs) == numErrsBefore {\n\t\tloc := expr.Operator()[0].Location\n\t\texpr.SetOperator(RefTerm(VarTerm(Equality.Name).SetLocation(loc)).SetLocation(loc))\n\t}\n\n\treturn expr, errs\n}\n\nfunc rewriteDeclaredVarsInTerm(g *localVarGenerator, stack *localDeclaredVars, term *Term, errs Errors, strict bool) (bool, Errors) {\n\tswitch v := term.Value.(type) {\n\tcase Var:\n\t\tif gv, ok := stack.Declared(v); ok {\n\t\t\tterm.Value = gv\n\t\t\tstack.Seen(v)\n\t\t} else if stack.Occurrence(v) == newVar {\n\t\t\tstack.Insert(v, v, seenVar)\n\t\t}\n\tcase Ref:\n\t\tif RootDocumentRefs.Contains(term) {\n\t\t\tx := v[0].Value.(Var)\n\t\t\tif occ, ok := stack.GlobalOccurrence(x); ok && occ != seenVar {\n\t\t\t\tgv, _ := stack.Declared(x)\n\t\t\t\tterm.Value = gv\n\t\t\t}\n\n\t\t\treturn true, errs\n\t\t}\n\t\treturn false, errs\n\tcase Call:\n\t\tref := v[0]\n\t\tWalkVars(ref, func(v Var) bool {\n\t\t\tif gv, ok := stack.Declared(v); ok && !gv.Equal(v) {\n\t\t\t\t// We will rewrite the ref of a function call, which is never ok since we don't have first-class functions.\n\t\t\t\terrs = append(errs, NewError(CompileErr, term.Location, \"called function %s shadowed\", ref))\n\t\t\t\treturn true\n\t\t\t}\n\t\t\treturn false\n\t\t})\n\t\treturn false, errs\n\tcase *object:\n\t\tcpy, _ := v.Map(func(k, v *Term) (*Term, *Term, error) {\n\t\t\tkcpy := k.Copy()\n\t\t\terrs = rewriteDeclaredVarsInTermRecursive(g, stack, kcpy, errs, strict)\n\t\t\terrs = rewriteDeclaredVarsInTermRecursive(g, stack, v, errs, strict)\n\t\t\treturn kcpy, v, nil\n\t\t})\n\t\tterm.Value = cpy\n\tcase Set:\n\t\tcpy, _ := v.Map(func(elem *Term) (*Term, error) {\n\t\t\telemcpy := elem.Copy()\n\t\t\terrs = rewriteDeclaredVarsInTermRecursive(g, stack, elemcpy, errs, strict)\n\t\t\treturn elemcpy, nil\n\t\t})\n\t\tterm.Value = cpy\n\tcase *ArrayComprehension:\n\t\terrs = rewriteDeclaredVarsInArrayComprehension(g, stack, v, errs, strict)\n\tcase *SetComprehension:\n\t\terrs = rewriteDeclaredVarsInSetComprehension(g, stack, v, errs, strict)\n\tcase *ObjectComprehension:\n\t\terrs = rewriteDeclaredVarsInObjectComprehension(g, stack, v, errs, strict)\n\tdefault:\n\t\treturn false, errs\n\t}\n\treturn true, errs\n}\n\nfunc rewriteDeclaredVarsInTermRecursive(g *localVarGenerator, stack *localDeclaredVars, term *Term, errs Errors, strict bool) Errors {\n\tWalkNodes(term, func(n Node) bool {\n\t\tvar stop bool\n\t\tswitch n := n.(type) {\n\t\tcase *With:\n\t\t\t_, errs = rewriteDeclaredVarsInTerm(g, stack, n.Value, errs, strict)\n\t\t\tstop = true\n\t\tcase *Term:\n\t\t\tstop, errs = rewriteDeclaredVarsInTerm(g, stack, n, errs, strict)\n\t\t}\n\t\treturn stop\n\t})\n\treturn errs\n}\n\nfunc rewriteDeclaredVarsInArrayComprehension(g *localVarGenerator, stack *localDeclaredVars, v *ArrayComprehension, errs Errors, strict bool) Errors {\n\tused := NewVarSet()\n\tused.Update(v.Term.Vars())\n\n\tstack.Push()\n\tv.Body, errs = rewriteDeclaredVarsInBody(g, stack, used, v.Body, errs, strict)\n\terrs = rewriteDeclaredVarsInTermRecursive(g, stack, v.Term, errs, strict)\n\tstack.Pop()\n\treturn errs\n}\n\nfunc rewriteDeclaredVarsInSetComprehension(g *localVarGenerator, stack *localDeclaredVars, v *SetComprehension, errs Errors, strict bool) Errors {\n\tused := NewVarSet()\n\tused.Update(v.Term.Vars())\n\n\tstack.Push()\n\tv.Body, errs = rewriteDeclaredVarsInBody(g, stack, used, v.Body, errs, strict)\n\terrs = rewriteDeclaredVarsInTermRecursive(g, stack, v.Term, errs, strict)\n\tstack.Pop()\n\treturn errs\n}\n\nfunc rewriteDeclaredVarsInObjectComprehension(g *localVarGenerator, stack *localDeclaredVars, v *ObjectComprehension, errs Errors, strict bool) Errors {\n\tused := NewVarSet()\n\tused.Update(v.Key.Vars())\n\tused.Update(v.Value.Vars())\n\n\tstack.Push()\n\tv.Body, errs = rewriteDeclaredVarsInBody(g, stack, used, v.Body, errs, strict)\n\terrs = rewriteDeclaredVarsInTermRecursive(g, stack, v.Key, errs, strict)\n\terrs = rewriteDeclaredVarsInTermRecursive(g, stack, v.Value, errs, strict)\n\tstack.Pop()\n\treturn errs\n}\n\nfunc rewriteDeclaredVar(g *localVarGenerator, stack *localDeclaredVars, v Var, occ varOccurrence) (gv Var, err error) {\n\tswitch stack.Occurrence(v) {\n\tcase seenVar:\n\t\treturn gv, fmt.Errorf(\"var %v referenced above\", v)\n\tcase assignedVar:\n\t\treturn gv, fmt.Errorf(\"var %v assigned above\", v)\n\tcase declaredVar:\n\t\treturn gv, fmt.Errorf(\"var %v declared above\", v)\n\tcase argVar:\n\t\treturn gv, fmt.Errorf(\"arg %v redeclared\", v)\n\t}\n\tgv = g.Generate()\n\tstack.Insert(v, gv, occ)\n\treturn\n}\n\n// rewriteWithModifiersInBody will rewrite the body so that with modifiers do\n// not contain terms that require evaluation as values. If this function\n// encounters an invalid with modifier target then it will raise an error.\nfunc rewriteWithModifiersInBody(c *Compiler, f *equalityFactory, body Body) (Body, *Error) {\n\tvar result Body\n\tfor i := range body {\n\t\texprs, err := rewriteWithModifier(c, f, body[i])\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif len(exprs) > 0 {\n\t\t\tfor _, expr := range exprs {\n\t\t\t\tresult.Append(expr)\n\t\t\t}\n\t\t} else {\n\t\t\tresult.Append(body[i])\n\t\t}\n\t}\n\treturn result, nil\n}\n\nfunc rewriteWithModifier(c *Compiler, f *equalityFactory, expr *Expr) ([]*Expr, *Error) {\n\n\tvar result []*Expr\n\tfor i := range expr.With {\n\t\teval, err := validateWith(c, expr, i)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tif eval {\n\t\t\teq := f.Generate(expr.With[i].Value)\n\t\t\tresult = append(result, eq)\n\t\t\texpr.With[i].Value = eq.Operand(0)\n\t\t}\n\t}\n\n\treturn append(result, expr), nil\n}\n\nfunc validateWith(c *Compiler, expr *Expr, i int) (bool, *Error) {\n\ttarget, value := expr.With[i].Target, expr.With[i].Value\n\n\t// Ensure that values that are built-ins are rewritten to Ref (not Var)\n\tif v, ok := value.Value.(Var); ok {\n\t\tif _, ok := c.builtins[v.String()]; ok {\n\t\t\tvalue.Value = Ref([]*Term{NewTerm(v)})\n\t\t}\n\t}\n\n\tswitch {\n\tcase isDataRef(target):\n\t\tref := target.Value.(Ref)\n\t\tnode := c.RuleTree\n\t\tfor i := 0; i < len(ref)-1; i++ {\n\t\t\tchild := node.Child(ref[i].Value)\n\t\t\tif child == nil {\n\t\t\t\tbreak\n\t\t\t} else if len(child.Values) > 0 {\n\t\t\t\treturn false, NewError(CompileErr, target.Loc(), \"with keyword cannot partially replace virtual document(s)\")\n\t\t\t}\n\t\t\tnode = child\n\t\t}\n\n\t\tif node != nil {\n\t\t\t// NOTE(sr): at this point in the compiler stages, we don't have a fully-populated\n\t\t\t// TypeEnv yet -- so we have to make do with this check to see if the replacement\n\t\t\t// target is a function. It's probably wrong for arity-0 functions, but those are\n\t\t\t// and edge case anyways.\n\t\t\tif child := node.Child(ref[len(ref)-1].Value); child != nil {\n\t\t\t\tfor _, v := range child.Values {\n\t\t\t\t\tif len(v.(*Rule).Head.Args) > 0 {\n\t\t\t\t\t\tif validateWithFunctionValue(c.builtins, c.RuleTree, value) {\n\t\t\t\t\t\t\treturn false, nil\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\tcase isInputRef(target): // ok, valid\n\tcase isBuiltinRefOrVar(c.builtins, target):\n\n\t\t// NOTE(sr): first we ensure that parsed Var builtins (`count`, `concat`, etc)\n\t\t// are rewritten to their proper Ref convention\n\t\tif v, ok := target.Value.(Var); ok {\n\t\t\ttarget.Value = Ref([]*Term{NewTerm(v)})\n\t\t}\n\n\t\ttargetRef := target.Value.(Ref)\n\t\tbi := c.builtins[targetRef.String()] // safe because isBuiltinRefOrVar checked this\n\t\tif err := validateWithBuiltinTarget(bi, targetRef, target.Loc()); err != nil {\n\t\t\treturn false, err\n\t\t}\n\n\t\tif validateWithFunctionValue(c.builtins, c.RuleTree, value) {\n\t\t\treturn false, nil\n\t\t}\n\tdefault:\n\t\treturn false, NewError(TypeErr, target.Location, \"with keyword target must reference existing %v, %v, or a function\", InputRootDocument, DefaultRootDocument)\n\t}\n\treturn requiresEval(value), nil\n}\n\nfunc validateWithBuiltinTarget(bi *Builtin, target Ref, loc *location.Location) *Error {\n\tswitch bi.Name {\n\tcase Equality.Name,\n\t\tRegoMetadataChain.Name,\n\t\tRegoMetadataRule.Name:\n\t\treturn NewError(CompileErr, loc, \"with keyword replacing built-in function: replacement of %q invalid\", bi.Name)\n\t}\n\n\tswitch {\n\tcase target.HasPrefix(Ref([]*Term{VarTerm(\"internal\")})):\n\t\treturn NewError(CompileErr, loc, \"with keyword replacing built-in function: replacement of internal function %q invalid\", target)\n\n\tcase bi.Relation:\n\t\treturn NewError(CompileErr, loc, \"with keyword replacing built-in function: target must not be a relation\")\n\n\tcase bi.Decl.Result() == nil:\n\t\treturn NewError(CompileErr, loc, \"with keyword replacing built-in function: target must not be a void function\")\n\t}\n\treturn nil\n}\n\nfunc validateWithFunctionValue(bs map[string]*Builtin, ruleTree *TreeNode, value *Term) bool {\n\tif v, ok := value.Value.(Ref); ok {\n\t\tif ruleTree.Find(v) != nil { // ref exists in rule tree\n\t\t\treturn true\n\t\t}\n\t}\n\treturn isBuiltinRefOrVar(bs, value)\n}\n\nfunc isInputRef(term *Term) bool {\n\tif ref, ok := term.Value.(Ref); ok {\n\t\tif ref.HasPrefix(InputRootRef) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc isDataRef(term *Term) bool {\n\tif ref, ok := term.Value.(Ref); ok {\n\t\tif ref.HasPrefix(DefaultRootRef) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc isBuiltinRefOrVar(bs map[string]*Builtin, term *Term) bool {\n\tswitch v := term.Value.(type) {\n\tcase Ref, Var:\n\t\t_, ok := bs[v.String()]\n\t\treturn ok\n\t}\n\treturn false\n}\n\nfunc isVirtual(node *TreeNode, ref Ref) bool {\n\tfor i := 0; i < len(ref); i++ {\n\t\tchild := node.Child(ref[i].Value)\n\t\tif child == nil {\n\t\t\treturn false\n\t\t} else if len(child.Values) > 0 {\n\t\t\treturn true\n\t\t}\n\t\tnode = child\n\t}\n\treturn true\n}\n\nfunc safetyErrorSlice(unsafe unsafeVars, rewritten map[Var]Var) (result Errors) {\n\n\tif len(unsafe) == 0 {\n\t\treturn\n\t}\n\n\tfor _, pair := range unsafe.Vars() {\n\t\tv := pair.Var\n\t\tif w, ok := rewritten[v]; ok {\n\t\t\tv = w\n\t\t}\n\t\tif !v.IsGenerated() {\n\t\t\tif _, ok := futureKeywords[string(v)]; ok {\n\t\t\t\tresult = append(result, NewError(UnsafeVarErr, pair.Loc,\n\t\t\t\t\t\"var %[1]v is unsafe (hint: `import future.keywords.%[1]v` to import a future keyword)\", v))\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tresult = append(result, NewError(UnsafeVarErr, pair.Loc, \"var %v is unsafe\", v))\n\t\t}\n\t}\n\n\tif len(result) > 0 {\n\t\treturn\n\t}\n\n\t// If the expression contains unsafe generated variables, report which\n\t// expressions are unsafe instead of the variables that are unsafe (since\n\t// the latter are not meaningful to the user.)\n\tpairs := unsafe.Slice()\n\n\tsort.Slice(pairs, func(i, j int) bool {\n\t\treturn pairs[i].Expr.Location.Compare(pairs[j].Expr.Location) < 0\n\t})\n\n\t// Report at most one error per generated variable.\n\tseen := NewVarSet()\n\n\tfor _, expr := range pairs {\n\t\tbefore := len(seen)\n\t\tfor v := range expr.Vars {\n\t\t\tif v.IsGenerated() {\n\t\t\t\tseen.Add(v)\n\t\t\t}\n\t\t}\n\t\tif len(seen) > before {\n\t\t\tresult = append(result, NewError(UnsafeVarErr, expr.Expr.Location, \"expression is unsafe\"))\n\t\t}\n\t}\n\n\treturn\n}\n\nfunc checkUnsafeBuiltins(unsafeBuiltinsMap map[string]struct{}, node interface{}) Errors {\n\terrs := make(Errors, 0)\n\tWalkExprs(node, func(x *Expr) bool {\n\t\tif x.IsCall() {\n\t\t\toperator := x.Operator().String()\n\t\t\tif _, ok := unsafeBuiltinsMap[operator]; ok {\n\t\t\t\terrs = append(errs, NewError(TypeErr, x.Loc(), \"unsafe built-in function calls in expression: %v\", operator))\n\t\t\t}\n\t\t}\n\t\treturn false\n\t})\n\treturn errs\n}\n\nfunc checkDeprecatedBuiltins(deprecatedBuiltinsMap map[string]struct{}, node interface{}, strict bool) Errors {\n\t// Early out; deprecatedBuiltinsMap is only populated in strict-mode.\n\tif !strict {\n\t\treturn nil\n\t}\n\n\terrs := make(Errors, 0)\n\tWalkExprs(node, func(x *Expr) bool {\n\t\tif x.IsCall() {\n\t\t\toperator := x.Operator().String()\n\t\t\tif _, ok := deprecatedBuiltinsMap[operator]; ok {\n\t\t\t\terrs = append(errs, NewError(TypeErr, x.Loc(), \"deprecated built-in function calls in expression: %v\", operator))\n\t\t\t}\n\t\t}\n\t\treturn false\n\t})\n\treturn errs\n}\n\nfunc rewriteVarsInRef(vars ...map[Var]Var) varRewriter {\n\treturn func(node Ref) Ref {\n\t\ti, _ := TransformVars(node, func(v Var) (Value, error) {\n\t\t\tfor _, m := range vars {\n\t\t\t\tif u, ok := m[v]; ok {\n\t\t\t\t\treturn u, nil\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn v, nil\n\t\t})\n\t\treturn i.(Ref)\n\t}\n}\n", "// Copyright 2016 The OPA Authors.  All rights reserved.\n// Use of this source code is governed by an Apache2\n// license that can be found in the LICENSE file.\n\npackage ast\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"reflect\"\n\t\"sort\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/open-policy-agent/opa/metrics\"\n\t\"github.com/open-policy-agent/opa/types\"\n\t\"github.com/open-policy-agent/opa/util\"\n)\n\nfunc TestOutputVarsForNode(t *testing.T) {\n\n\ttests := []struct {\n\t\tnote      string\n\t\tquery     string\n\t\tarities   map[string]int\n\t\textraSafe string\n\t\texp       string\n\t}{\n\t\t{\n\t\t\tnote:  \"single var\",\n\t\t\tquery: \"x\",\n\t\t\texp:   \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"trivial eq\",\n\t\t\tquery: \"x = 1\",\n\t\t\texp:   \"{x}\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"negation\",\n\t\t\tquery: \"not x = 1\",\n\t\t\texp:   \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"embedded array\",\n\t\t\tquery: \"[x, [1]] = [1, [y]]\",\n\t\t\texp:   \"{x, y}\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"embedded sets\",\n\t\t\tquery: \"{x, [1]} = {1, [y]}\",\n\t\t\texp:   \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"embedded object values\",\n\t\t\tquery: `{\"foo\": x, \"bar\": {\"baz\": 1}} = {\"foo\": 1, \"bar\": {\"baz\": y}}`,\n\t\t\texp:   \"{x, y}\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"object keys are like sets\",\n\t\t\tquery: `{\"foo\": x} = {y: 1}`,\n\t\t\texp:   `set()`,\n\t\t},\n\t\t{\n\t\t\tnote:    \"built-ins\",\n\t\t\tquery:   `count([1,2,3], x)`,\n\t\t\texp:     \"{x}\",\n\t\t\tarities: map[string]int{\"count\": 1},\n\t\t},\n\t\t{\n\t\t\tnote:  \"built-ins - input args\",\n\t\t\tquery: `count(x)`,\n\t\t\texp:   \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:    \"functions - no arity\",\n\t\t\tquery:   `f(1,x)`,\n\t\t\tarities: map[string]int{},\n\t\t\texp:     \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:    \"functions\",\n\t\t\tquery:   `f(1,x)`,\n\t\t\tarities: map[string]int{\"f\": 1},\n\t\t\texp:     \"{x}\",\n\t\t},\n\t\t{\n\t\t\tnote:    \"functions - input args\",\n\t\t\tquery:   `f(1,x)`,\n\t\t\tarities: map[string]int{\"f\": 2},\n\t\t\texp:     \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:    \"functions - embedded refs\",\n\t\t\tquery:   `f(data.p[x], y)`,\n\t\t\tarities: map[string]int{\"f\": 1},\n\t\t\texp:     `{x, y}`,\n\t\t},\n\t\t{\n\t\t\tnote:    \"functions - skip ref head\",\n\t\t\tquery:   `f(x[1])`,\n\t\t\tarities: map[string]int{\"f\": 1},\n\t\t\texp:     `set()`,\n\t\t},\n\t\t{\n\t\t\tnote:    \"functions - skip sets\",\n\t\t\tquery:   `f(1, {x})`,\n\t\t\tarities: map[string]int{\"f\": 1},\n\t\t\texp:     `set()`,\n\t\t},\n\t\t{\n\t\t\tnote:    \"functions - skip object keys\",\n\t\t\tquery:   `f(1, {x: 1})`,\n\t\t\tarities: map[string]int{\"f\": 1},\n\t\t\texp:     `set()`,\n\t\t},\n\t\t{\n\t\t\tnote:    \"functions - skip closures\",\n\t\t\tquery:   `f(1, {x | x = 1})`,\n\t\t\tarities: map[string]int{\"f\": 1},\n\t\t\texp:     `set()`,\n\t\t},\n\t\t{\n\t\t\tnote:    \"functions - unsafe input\",\n\t\t\tquery:   `f(x, y)`,\n\t\t\tarities: map[string]int{\"f\": 1},\n\t\t\texp:     `set()`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"with keyword\",\n\t\t\tquery: \"1 with input as y\",\n\t\t\texp:   \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"with keyword - unsafe\",\n\t\t\tquery: \"x = 1 with input as y\",\n\t\t\texp:   \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:      \"with keyword - safe\",\n\t\t\tquery:     \"x = 1 with input as y\",\n\t\t\textraSafe: \"{y}\",\n\t\t\texp:       \"{x}\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"ref operand\",\n\t\t\tquery: \"data.p[x]\",\n\t\t\texp:   \"{x}\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"ref operand - unsafe head\",\n\t\t\tquery: \"p[x]\",\n\t\t\texp:   \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"ref operand - negation\",\n\t\t\tquery: \"not data.p[x]\",\n\t\t\texp:   \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"ref operand - nested\",\n\t\t\tquery: \"data.p[data.q[x]]\",\n\t\t\texp:   \"{x}\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"comprehension\",\n\t\t\tquery: \"[x | x = 1]\",\n\t\t\texp:   \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"comprehension containing safe ref\",\n\t\t\tquery: \"[x | data.p[x]]\",\n\t\t\texp:   \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"accumulate on exprs\",\n\t\t\tquery: \"x = 1; y = x; z = y\",\n\t\t\texp:   \"{x, y, z}\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"composite head\",\n\t\t\tquery: \"{1, 2}[1] = x\",\n\t\t\texp:   `{x}`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"composite head\",\n\t\t\tquery: \"x = 1; {x, 2}[1] = y\",\n\t\t\texp:   `{x, y}`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"composite head\",\n\t\t\tquery: \"{x, 2}[1] = y\",\n\t\t\texp:   `set()`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"nested function calls\",\n\t\t\tquery: `z = \"abc\"; x = split(z, \"\")[y]`,\n\t\t\texp:   `{x, y, z}`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"unsafe nested function calls\",\n\t\t\tquery: `z = \"abc\"; x = split(z, a)[y]`,\n\t\t\texp:   `{z}`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"every: simple: no output vars\",\n\t\t\tquery: `every k, v in [1, 2] { k < v }`,\n\t\t\texp:   `set()`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"every: output vars in domain\",\n\t\t\tquery: `xs = []; every k, v in xs[i] { k < v }`,\n\t\t\texp:   `{xs, i}`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"every: output vars in body\",\n\t\t\tquery: `every k, v in [] { k < v; i = 1 }`,\n\t\t\texp:   `set()`,\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\n\t\t\topts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\t\t\tbody, err := ParseBodyWithOpts(tc.query, opts)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tarity := func(r Ref) int {\n\t\t\t\ta, ok := tc.arities[r.String()]\n\t\t\t\tif !ok {\n\t\t\t\t\treturn -1\n\t\t\t\t}\n\t\t\t\treturn a\n\t\t\t}\n\n\t\t\tsafe := ReservedVars.Copy()\n\n\t\t\tif tc.extraSafe != \"\" {\n\t\t\t\tMustParseTerm(tc.extraSafe).Value.(Set).Foreach(func(x *Term) {\n\t\t\t\t\tsafe.Add(x.Value.(Var))\n\t\t\t\t})\n\t\t\t}\n\n\t\t\tvs := NewSet()\n\n\t\t\tfor v := range outputVarsForBody(body, arity, safe) {\n\t\t\t\tvs.Add(NewTerm(v))\n\t\t\t}\n\n\t\t\texp := MustParseTerm(tc.exp)\n\n\t\t\tif exp.Value.Compare(vs) != 0 {\n\t\t\t\tt.Fatalf(\"Expected %v but got %v\", exp, vs)\n\t\t\t}\n\t\t})\n\t}\n\n}\n\nfunc TestModuleTree(t *testing.T) {\n\n\tmods := getCompilerTestModules()\n\tmods[\"system-mod\"] = MustParseModule(`\n\tpackage system.foo\n\n\tp = 1\n\t`)\n\tmods[\"non-system-mod\"] = MustParseModule(`\n\tpackage user.system\n\n\tp = 1\n\t`)\n\ttree := NewModuleTree(mods)\n\texpectedSize := 9\n\n\tif tree.Size() != expectedSize {\n\t\tt.Fatalf(\"Expected %v but got %v modules\", expectedSize, tree.Size())\n\t}\n\n\tif !tree.Children[Var(\"data\")].Children[String(\"system\")].Hide {\n\t\tt.Fatalf(\"Expected system node to be hidden\")\n\t}\n\n\tif tree.Children[Var(\"data\")].Children[String(\"system\")].Children[String(\"foo\")].Hide {\n\t\tt.Fatalf(\"Expected system.foo node to be visible\")\n\t}\n\n\tif tree.Children[Var(\"data\")].Children[String(\"user\")].Children[String(\"system\")].Hide {\n\t\tt.Fatalf(\"Expected user.system node to be visible\")\n\t}\n\n}\n\nfunc TestModuleTreeFilenameOrder(t *testing.T) {\n\t// NOTE(sr): It doesn't matter that these are conflicting; but that's where it\n\t// becomes very apparent: before this change, the rule that was reported as\n\t// \"conflicting\" was that of either one of the input files, randomly.\n\tmods := map[string]*Module{\n\t\t\"0.rego\": MustParseModule(\"package p\\nr = 1 { true }\"),\n\t\t\"1.rego\": MustParseModule(\"package p\\nr = 2 { true }\"),\n\t}\n\ttree := NewModuleTree(mods)\n\tvals := tree.Children[Var(\"data\")].Children[String(\"p\")].Modules\n\tif exp, act := 2, len(vals); exp != act {\n\t\tt.Fatalf(\"expected %d rules, found %d\", exp, act)\n\t}\n\tmod0 := vals[0]\n\tmod1 := vals[1]\n\tif exp, act := IntNumberTerm(1), mod0.Rules[0].Head.Value; !exp.Equal(act) {\n\t\tt.Errorf(\"expected value %v, got %v\", exp, act)\n\t}\n\tif exp, act := IntNumberTerm(2), mod1.Rules[0].Head.Value; !exp.Equal(act) {\n\t\tt.Errorf(\"expected value %v, got %v\", exp, act)\n\t}\n}\nfunc TestRuleTree(t *testing.T) {\n\n\tmods := getCompilerTestModules()\n\tmods[\"system-mod\"] = MustParseModule(`\n\tpackage system.foo\n\n\tp = 1\n\t`)\n\tmods[\"non-system-mod\"] = MustParseModule(`\n\tpackage user.system\n\n\tp = 1\n\t`)\n\tmods[\"mod-incr\"] = MustParseModule(`package a.b.c\n\ns[1] { true }\ns[2] { true }`,\n\t)\n\n\ttree := NewRuleTree(NewModuleTree(mods))\n\texpectedNumRules := 23\n\n\tif tree.Size() != expectedNumRules {\n\t\tt.Errorf(\"Expected %v but got %v rules\", expectedNumRules, tree.Size())\n\t}\n\n\t// Check that empty packages are represented as leaves with no rules.\n\tnode := tree.Children[Var(\"data\")].Children[String(\"a\")].Children[String(\"b\")].Children[String(\"empty\")]\n\n\tif node == nil || len(node.Children) != 0 || len(node.Values) != 0 {\n\t\tt.Fatalf(\"Unexpected nil value or non-empty leaf of non-leaf node: %v\", node)\n\t}\n\n\tsystem := tree.Child(Var(\"data\")).Child(String(\"system\"))\n\tif !system.Hide {\n\t\tt.Fatalf(\"Expected system node to be hidden\")\n\t}\n\n\tif system.Child(String(\"foo\")).Hide {\n\t\tt.Fatalf(\"Expected system.foo node to be visible\")\n\t}\n\n\tuser := tree.Child(Var(\"data\")).Child(String(\"user\")).Child(String(\"system\"))\n\tif user.Hide {\n\t\tt.Fatalf(\"Expected user.system node to be visible\")\n\t}\n\n\tif !isVirtual(tree, MustParseRef(\"data.a.b.empty\")) {\n\t\tt.Fatal(\"Expected data.a.b.empty to be virtual\")\n\t}\n\n\tabc := tree.Children[Var(\"data\")].Children[String(\"a\")].Children[String(\"b\")].Children[String(\"c\")]\n\texp := []Value{String(\"p\"), String(\"q\"), String(\"r\"), String(\"s\"), String(\"z\")}\n\n\tif len(abc.Sorted) != len(exp) {\n\t\tt.Fatal(\"expected\", exp, \"but got\", abc)\n\t}\n\n\tfor i := range exp {\n\t\tif exp[i].Compare(abc.Sorted[i]) != 0 {\n\t\t\tt.Fatal(\"expected\", exp, \"but got\", abc)\n\t\t}\n\t}\n}\n\nfunc TestCompilerEmpty(t *testing.T) {\n\tc := NewCompiler()\n\tc.Compile(nil)\n\tassertNotFailed(t, c)\n}\n\nfunc TestCompilerExample(t *testing.T) {\n\tc := NewCompiler()\n\tm := MustParseModule(testModule)\n\tc.Compile(map[string]*Module{\"testMod\": m})\n\tassertNotFailed(t, c)\n}\n\nfunc TestCompilerWithStageAfter(t *testing.T) {\n\tt.Run(\"after failing means overall failure\", func(t *testing.T) {\n\t\tc := NewCompiler().WithStageAfter(\n\t\t\t\"CheckRecursion\",\n\t\t\tCompilerStageDefinition{\"MockStage\", \"mock_stage\",\n\t\t\t\tfunc(*Compiler) *Error { return NewError(CompileErr, &Location{}, \"mock stage error\") }},\n\t\t)\n\t\tm := MustParseModule(testModule)\n\t\tc.Compile(map[string]*Module{\"testMod\": m})\n\n\t\tif !c.Failed() {\n\t\t\tt.Errorf(\"Expected compilation error\")\n\t\t}\n\t})\n\n\tt.Run(\"first 'after' failure inhibits other 'after' stages\", func(t *testing.T) {\n\t\tc := NewCompiler().\n\t\t\tWithStageAfter(\"CheckRecursion\",\n\t\t\t\tCompilerStageDefinition{\"MockStage\", \"mock_stage\",\n\t\t\t\t\tfunc(*Compiler) *Error { return NewError(CompileErr, &Location{}, \"mock stage error\") }}).\n\t\t\tWithStageAfter(\"CheckRecursion\",\n\t\t\t\tCompilerStageDefinition{\"MockStage2\", \"mock_stage2\",\n\t\t\t\t\tfunc(*Compiler) *Error { return NewError(CompileErr, &Location{}, \"mock stage error two\") }},\n\t\t\t)\n\t\tm := MustParseModule(`package p\nq := true`)\n\n\t\tc.Compile(map[string]*Module{\"testMod\": m})\n\n\t\tif !c.Failed() {\n\t\t\tt.Errorf(\"Expected compilation error\")\n\t\t}\n\t\tif exp, act := 1, len(c.Errors); exp != act {\n\t\t\tt.Errorf(\"expected %d errors, got %d: %v\", exp, act, c.Errors)\n\t\t}\n\t})\n\n\tt.Run(\"'after' failure inhibits other ordinary stages\", func(t *testing.T) {\n\t\tc := NewCompiler().\n\t\t\tWithStageAfter(\"CheckRecursion\",\n\t\t\t\tCompilerStageDefinition{\"MockStage\", \"mock_stage\",\n\t\t\t\t\tfunc(*Compiler) *Error { return NewError(CompileErr, &Location{}, \"mock stage error\") }})\n\t\tm := MustParseModule(`package p\nq {\n\t1 == \"a\" # would fail \"CheckTypes\", the next stage\n}\n`)\n\t\tc.Compile(map[string]*Module{\"testMod\": m})\n\n\t\tif !c.Failed() {\n\t\t\tt.Errorf(\"Expected compilation error\")\n\t\t}\n\t\tif exp, act := 1, len(c.Errors); exp != act {\n\t\t\tt.Errorf(\"expected %d errors, got %d: %v\", exp, act, c.Errors)\n\t\t}\n\t})\n}\n\nfunc TestCompilerFunctions(t *testing.T) {\n\ttests := []struct {\n\t\tnote    string\n\t\tmodules []string\n\t\twantErr bool\n\t}{\n\t\t{\n\t\t\tnote: \"multiple input types\",\n\t\t\tmodules: []string{`package x\n\n\t\t\t\tf([x]) = y {\n\t\t\t\t\ty = x\n\t\t\t\t}\n\n\t\t\t\tf({\"foo\": x}) = y {\n\t\t\t\t\ty = x\n\t\t\t\t}`},\n\t\t},\n\t\t{\n\t\t\tnote: \"multiple input types\",\n\t\t\tmodules: []string{`package x\n\n\t\t\t\tf([x]) = y {\n\t\t\t\t\ty = x\n\t\t\t\t}\n\n\t\t\t\tf([[x]]) = y {\n\t\t\t\t\ty = x\n\t\t\t\t}`},\n\t\t},\n\t\t{\n\t\t\tnote: \"constant input\",\n\t\t\tmodules: []string{`package x\n\n\t\t\t\tf(1) = y {\n\t\t\t\t\ty = \"foo\"\n\t\t\t\t}\n\n\t\t\t\tf(2) = y {\n\t\t\t\t\ty = \"bar\"\n\t\t\t\t}`},\n\t\t},\n\t\t{\n\t\t\tnote: \"constant input\",\n\t\t\tmodules: []string{`package x\n\n\t\t\t\tf(1, x) = y {\n\t\t\t\t\ty = x\n\t\t\t\t}\n\n\t\t\t\tf(x, y) = z {\n\t\t\t\t\tz = x+y\n\t\t\t\t}`},\n\t\t},\n\t\t{\n\t\t\tnote: \"constant input\",\n\t\t\tmodules: []string{`package x\n\n\t\t\t\tf(x, 1) = y {\n\t\t\t\t\ty = x\n\t\t\t\t}\n\n\t\t\t\tf(x, [y]) = z {\n\t\t\t\t\tz = x+y\n\t\t\t\t}`},\n\t\t},\n\t\t{\n\t\t\tnote: \"multiple input types (nested)\",\n\t\t\tmodules: []string{`package x\n\n\t\t\t\tf({\"foo\": {\"bar\": x}}) = y {\n\t\t\t\t\ty = x\n\t\t\t\t}\n\n\t\t\t\tf({\"foo\": [x]}) = y {\n\t\t\t\t\ty = x\n\t\t\t\t}`},\n\t\t},\n\t\t{\n\t\t\tnote: \"multiple output types\",\n\t\t\tmodules: []string{`package x\n\n\t\t\t\tf(1) = y {\n\t\t\t\t\ty = \"foo\"\n\t\t\t\t}\n\n\t\t\t\tf(2) = y {\n\t\t\t\t\ty = 2\n\t\t\t\t}`},\n\t\t},\n\t\t{\n\t\t\tnote: \"namespacing\",\n\t\t\tmodules: []string{\n\t\t\t\t`package x\n\n\t\t\t\tf(x) = y {\n\t\t\t\t\tdata.y.f[x] = y\n\t\t\t\t}`,\n\t\t\t\t`package y\n\n\t\t\t\tf[x] = y {\n\t\t\t\t\ty = \"bar\"\n\t\t\t\t\tx = \"foo\"\n\t\t\t\t}`,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"implicit value\",\n\t\t\tmodules: []string{\n\t\t\t\t`package x\n\n\t\t\t\tf(x) {\n\t\t\t\t\tx = \"foo\"\n\t\t\t\t}`},\n\t\t},\n\t\t{\n\t\t\tnote: \"resolving\",\n\t\t\tmodules: []string{\n\t\t\t\t`package x\n\n\t\t\t\tf(x) = x { true }`,\n\n\t\t\t\t`package y\n\n\t\t\t\timport data.x\n\t\t\t\timport data.x.f as g\n\n\t\t\t\tp { g(1, a) }\n\t\t\t\tp { x.f(1, b) }\n\t\t\t\tp { data.x.f(1, c) }\n\t\t\t\t`,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"undefined\",\n\t\t\tmodules: []string{\n\t\t\t\t`package x\n\n\t\t\t\tp {\n\t\t\t\t\tf(1)\n\t\t\t\t}`,\n\t\t\t},\n\t\t\twantErr: true,\n\t\t},\n\t\t{\n\t\t\tnote: \"must apply\",\n\t\t\tmodules: []string{\n\t\t\t\t`package x\n\n\t\t\t\tf(1)\n\n\t\t\t\tp {\n\t\t\t\t\tf\n\t\t\t\t}\n\t\t\t\t`,\n\t\t\t},\n\t\t\twantErr: true,\n\t\t},\n\t\t{\n\t\t\tnote: \"must apply\",\n\t\t\tmodules: []string{\n\t\t\t\t`package x\n\t\t\t\tf(1)\n\t\t\t\tp { f.x }`,\n\t\t\t},\n\t\t\twantErr: true,\n\t\t},\n\t\t{\n\t\t\tnote: \"call argument ref output vars\",\n\t\t\tmodules: []string{\n\t\t\t\t`package x\n\n\t\t\t\tf(x)\n\n\t\t\t\tp { f(data.foo[i]) }`,\n\t\t\t},\n\t\t\twantErr: false,\n\t\t},\n\t}\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tvar err error\n\t\t\tmodules := map[string]*Module{}\n\t\t\tfor i, module := range tc.modules {\n\t\t\t\tname := fmt.Sprintf(\"mod%d\", i)\n\t\t\t\tmodules[name], err = ParseModule(name, module)\n\t\t\t\tif err != nil {\n\t\t\t\t\tpanic(err)\n\t\t\t\t}\n\t\t\t}\n\t\t\tc := NewCompiler()\n\t\t\tc.Compile(modules)\n\t\t\tif tc.wantErr && !c.Failed() {\n\t\t\t\tt.Errorf(\"Expected compilation error\")\n\t\t\t} else if !tc.wantErr && c.Failed() {\n\t\t\t\tt.Errorf(\"Unexpected compilation error(s): %v\", c.Errors)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerErrorLimit(t *testing.T) {\n\tmodules := map[string]*Module{\n\t\t\"test\": MustParseModule(`package test\n\tr = y { y = true; x = z }\n\n\ts[x] = y {\n\t\tz = y + x\n\t}\n\n\tt[x] { split(x, y, z) }\n\t`),\n\t}\n\n\tc := NewCompiler().SetErrorLimit(2)\n\tc.Compile(modules)\n\n\terrs := c.Errors\n\texp := []string{\n\t\t\"2:20: rego_unsafe_var_error: var x is unsafe\",\n\t\t\"2:20: rego_unsafe_var_error: var z is unsafe\",\n\t\t\"rego_compile_error: error limit reached\",\n\t}\n\n\tvar result []string\n\tfor _, err := range errs {\n\t\tresult = append(result, err.Error())\n\t}\n\n\tsort.Strings(exp)\n\tsort.Strings(result)\n\tif !reflect.DeepEqual(exp, result) {\n\t\tt.Errorf(\"Expected errors %v, got %v\", exp, result)\n\t}\n}\n\nfunc TestCompilerCheckSafetyHead(t *testing.T) {\n\tc := NewCompiler()\n\tc.Modules = getCompilerTestModules()\n\tc.Modules[\"newMod\"] = MustParseModule(`package a.b\n\nunboundKey[x] = y { q[y] = {\"foo\": [1, 2, [{\"bar\": y}]]} }\nunboundVal[y] = x { q[y] = {\"foo\": [1, 2, [{\"bar\": y}]]} }\nunboundCompositeVal[y] = [{\"foo\": x, \"bar\": y}] { q[y] = {\"foo\": [1, 2, [{\"bar\": y}]]} }\nunboundCompositeKey[[{\"x\": x}]] { q[y] }\nunboundBuiltinOperator = eq { x = 1 }\nunboundElse { false } else = else_var { true }\n`,\n\t)\n\tcompileStages(c, c.checkSafetyRuleHeads)\n\n\tmakeErrMsg := func(v string) string {\n\t\treturn fmt.Sprintf(\"rego_unsafe_var_error: var %v is unsafe\", v)\n\t}\n\n\texpected := []string{\n\t\tmakeErrMsg(\"x\"),\n\t\tmakeErrMsg(\"x\"),\n\t\tmakeErrMsg(\"x\"),\n\t\tmakeErrMsg(\"x\"),\n\t\tmakeErrMsg(\"eq\"),\n\t\tmakeErrMsg(\"else_var\"),\n\t}\n\n\tresult := compilerErrsToStringSlice(c.Errors)\n\tsort.Strings(expected)\n\n\tif len(result) != len(expected) {\n\t\tt.Fatalf(\"Expected %d:\\n%v\\nBut got %d:\\n%v\", len(expected), strings.Join(expected, \"\\n\"), len(result), strings.Join(result, \"\\n\"))\n\t}\n\n\tfor i := range result {\n\t\tif expected[i] != result[i] {\n\t\t\tt.Errorf(\"Expected %v but got: %v\", expected[i], result[i])\n\t\t}\n\t}\n\n}\n\nfunc TestCompilerCheckSafetyBodyReordering(t *testing.T) {\n\ttests := []struct {\n\t\tnote     string\n\t\tbody     string\n\t\texpected string\n\t}{\n\t\t{\"noop\", `x = 1; x != 0`, `x = 1; x != 0`},\n\t\t{\"var/ref\", `a[i] = x; a = [1, 2, 3, 4]`, `a = [1, 2, 3, 4]; a[i] = x`},\n\t\t{\"var/ref (nested)\", `a = [1, 2, 3, 4]; a[b[i]] = x; b = [0, 0, 0, 0]`, `a = [1, 2, 3, 4]; b = [0, 0, 0, 0]; a[b[i]] = x`},\n\t\t{\"negation\",\n\t\t\t`a = [true, false]; b = [true, false]; not a[i]; b[i]`,\n\t\t\t`a = [true, false]; b = [true, false]; b[i]; not a[i]`},\n\t\t{\"built-in\", `x != 0; count([1, 2, 3], x)`, `count([1, 2, 3], x); x != 0`},\n\t\t{\"var/var 1\", `x = y; z = 1; y = z`, `z = 1; y = z; x = y`},\n\t\t{\"var/var 2\", `x = y; 1 = z; z = y`, `1 = z; z = y; x = y`},\n\t\t{\"var/var 3\", `x != 0; y = x; y = 1`, `y = 1; y = x; x != 0`},\n\t\t{\"array compr/var\", `x != 0; [y | y = 1] = x`, `[y | y = 1] = x; x != 0`},\n\t\t{\"array compr/array\", `[1] != [x]; [y | y = 1] = [x]`, `[y | y = 1] = [x]; [1] != [x]`},\n\t\t{\"with\", `data.a.b.d.t with input as x; x = 1`, `x = 1; data.a.b.d.t with input as x`},\n\t\t{\"with-2\", `data.a.b.d.t with input.x as x; x = 1`, `x = 1; data.a.b.d.t with input.x as x`},\n\t\t{\"with-nop\", \"data.somedoc[x] with input as true\", \"data.somedoc[x] with input as true\"},\n\t\t{\"ref-head\", `s = [[\"foo\"], [\"bar\"]]; x = y[0]; y = s[_]; contains(x, \"oo\")`, `\n\t\ts = [[\"foo\"], [\"bar\"]];\n\t\ty = s[_];\n\t\tx = y[0];\n\t\tcontains(x, \"oo\")\n\t`},\n\t\t{\"userfunc\", `split(y, \".\", z); data.a.b.funcs.fn(\"...foo.bar..\", y)`, `data.a.b.funcs.fn(\"...foo.bar..\", y); split(y, \".\", z)`},\n\t\t{\"every\", `every _ in [] { x != 1 }; x = 1`, `__local4__ = []; x = 1; every __local3__, _ in __local4__ { x != 1}`},\n\t\t{\"every-domain\", `every _ in xs { true }; xs = [1]`, `xs = [1]; __local4__ = xs; every __local3__, _ in __local4__ { true }`},\n\t}\n\n\tfor i, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\topts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\t\t\tc := NewCompiler()\n\t\t\tc.Modules = getCompilerTestModules()\n\t\t\tc.Modules[\"reordering\"] = MustParseModuleWithOpts(fmt.Sprintf(\n\t\t\t\t`package test\n\t\t\t\tp { %s }`, tc.body), opts)\n\n\t\t\tcompileStages(c, c.checkSafetyRuleBodies)\n\n\t\t\tif c.Failed() {\n\t\t\t\tt.Errorf(\"%v (#%d): Unexpected compilation error: %v\", tc.note, i, c.Errors)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\texpected := MustParseBodyWithOpts(tc.expected, opts)\n\t\t\tresult := c.Modules[\"reordering\"].Rules[0].Body\n\n\t\t\tif !expected.Equal(result) {\n\t\t\t\tt.Errorf(\"%v (#%d): Expected body to be ordered and equal to %v but got: %v\", tc.note, i, expected, result)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerCheckSafetyBodyReorderingClosures(t *testing.T) {\n\topts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\n\ttests := []struct {\n\t\tnote string\n\t\tmod  *Module\n\t\texp  Body\n\t}{\n\t\t{\n\t\t\tnote: \"comprehensions-1\",\n\t\t\tmod: MustParseModule(`package compr\n\nimport data.b\nimport data.c\np = true { v = [null | true]; xs = [x | a[i] = x; a = [y | y != 1; y = c[j]]]; xs[j] > 0; z = [true | data.a.b.d.t with input as i2; i2 = i]; b[i] = j }\n`),\n\t\t\texp: MustParseBody(`v = [null | true]; data.b[i] = j; xs = [x | a = [y | y = data.c[j]; y != 1]; a[i] = x]; xs[j] > 0; z = [true | i2 = i; data.a.b.d.t with input as i2]`),\n\t\t},\n\t\t{\n\t\t\tnote: \"comprehensions-2\",\n\t\t\tmod: MustParseModule(`package compr\n\nimport data.b\nimport data.c\nq = true { _ = [x | x = b[i]]; _ = b[j]; _ = [x | x = true; x != false]; true != false; _ = [x | data.foo[_] = x]; data.foo[_] = _ }\n`),\n\t\t\texp: MustParseBody(`_ = [x | x = data.b[i]]; _ = data.b[j]; _ = [x | x = true; x != false]; true != false; _ = [x | data.foo[_] = x]; data.foo[_] = _`),\n\t\t},\n\n\t\t{\n\t\t\tnote: \"comprehensions-3\",\n\t\t\tmod: MustParseModule(`package compr\n\nimport data.b\nimport data.c\nfn(x) = y {\n\ttrim(x, \".\", y)\n}\nr = true { a = [x | split(y, \".\", z); x = z[i]; fn(\"...foo.bar..\", y)] }\n`),\n\t\t\texp: MustParseBody(`a = [x | data.compr.fn(\"...foo.bar..\", y); split(y, \".\", z); x = z[i]]`),\n\t\t},\n\t\t{\n\t\t\tnote: \"closure over function output\",\n\t\t\tmod: MustParseModule(`package test\nimport future.keywords\n\np {\n\tobject.get(input.subject.roles[_], comp, [\"\"], output)\n\tcomp = [ 1 | true ]\n\tevery y in [2] {\n\t\ty in output\n\t}\n}`),\n\t\t\texp: MustParseBodyWithOpts(`comp = [1 | true]\n\t\t\t\t__local2__ = [2]\n\t\t\t\tobject.get(input.subject.roles[_], comp, [\"\"], output)\n\t\t\t\tevery __local0__, __local1__ in __local2__ { internal.member_2(__local1__, output) }`, opts),\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tc := NewCompiler()\n\t\t\tc.Modules = map[string]*Module{\"mod\": tc.mod}\n\t\t\tcompileStages(c, c.checkSafetyRuleBodies)\n\t\t\tassertNotFailed(t, c)\n\t\t\tlast := len(c.Modules[\"mod\"].Rules) - 1\n\t\t\tactual := c.Modules[\"mod\"].Rules[last].Body\n\t\t\tif !actual.Equal(tc.exp) {\n\t\t\t\tt.Errorf(\"Expected reordered body to be equal to:\\n%v\\nBut got:\\n%v\", tc.exp, actual)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerCheckSafetyBodyErrors(t *testing.T) {\n\n\tmoduleBegin := `\n\t\tpackage a.b\n\n\t\timport input.aref.b.c as foo\n\t\timport input.avar as bar\n\t\timport data.m.n as baz\n\t`\n\n\ttests := []struct {\n\t\tnote          string\n\t\tmoduleContent string\n\t\texpected      string\n\t}{\n\t\t{\"ref-head\", `p { a.b.c = \"foo\" }`, `{a,}`},\n\t\t{\"ref-head-2\", `p { {\"foo\": [{\"bar\": a.b.c}]} = {\"foo\": [{\"bar\": \"baz\"}]} }`, `{a,}`},\n\t\t{\"negation\", `p { a = [1, 2, 3, 4]; not a[i] = x }`, `{i, x}`},\n\t\t{\"negation-head\", `p[x] { a = [1, 2, 3, 4]; not a[i] = x }`, `{i,x}`},\n\t\t{\"negation-multiple\", `p { a = [1, 2, 3, 4]; b = [1, 2, 3, 4]; not a[i] = x; not b[j] = x }`, `{i, x, j}`},\n\t\t{\"negation-nested\", `p { a = [{\"foo\": [\"bar\", \"baz\"]}]; not a[0].foo = [a[0].foo[i], a[0].foo[j]] } `, `{i, j}`},\n\t\t{\"builtin-input\", `p { count([1, 2, x], x) }`, `{x,}`},\n\t\t{\"builtin-input-name\", `p { count(eq, 1) }`, `{eq,}`},\n\t\t{\"builtin-multiple\", `p { x > 0; x <= 3; x != 2 }`, `{x,}`},\n\t\t{\"unordered-object-keys\", `p { x = \"a\"; [{x: y, z: a}] = [{\"a\": 1, \"b\": 2}]}`, `{a,y,z}`},\n\t\t{\"unordered-sets\", `p { x = \"a\"; [{x, y}] = [{1, 2}]}`, `{y,}`},\n\t\t{\"array-compr\", `p { _ = [x | x = data.a[_]; y > 1] }`, `{y,}`},\n\t\t{\"array-compr-nested\", `p { _ = [x | x = a[_]; a = [y | y = data.a[_]; z > 1]] }`, `{z,}`},\n\t\t{\"array-compr-closure\", `p { _ = [v | v = [x | x = data.a[_]]; x > 1] }`, `{x,}`},\n\t\t{\"array-compr-term\", `p { _ = [u | true] }`, `{u,}`},\n\t\t{\"array-compr-term-nested\", `p { _ = [v | v = [w | w != 0]] }`, `{w,}`},\n\t\t{\"array-compr-mixed\", `p { _ = [x | y = [a | a = z[i]]] }`, `{a, x, z, i}`},\n\t\t{\"array-compr-builtin\", `p { [true | eq != 2] }`, `{eq,}`},\n\t\t{\"closure-self\", `p { x = [x | x = 1] }`, `{x,}`},\n\t\t{\"closure-transitive\", `p { x = y; x = [y | y = 1] }`, `{x,y}`},\n\t\t{\"nested\", `p { count(baz[i].attr[bar[dead.beef]], n) }`, `{dead,}`},\n\t\t{\"negated-import\", `p { not foo; not bar; not baz }`, `set()`},\n\t\t{\"rewritten\", `p[{\"foo\": dead[i]}] { true }`, `{dead, i}`},\n\t\t{\"with-value\", `p { data.a.b.d.t with input as x }`, `{x,}`},\n\t\t{\"with-value-2\", `p { x = data.a.b.d.t with input as x }`, `{x,}`},\n\t\t{\"else-kw\", \"p { false } else { count(x, 1) }\", `{x,}`},\n\t\t{\"function\", \"foo(x) = [y, z] { split(x, y, z) }\", `{y,z}`},\n\t\t{\"call-vars-input\", \"p { f(x, x) } f(x) = x { true }\", `{x,}`},\n\t\t{\"call-no-output\", \"p { f(x) } f(x) = x { true }\", `{x,}`},\n\t\t{\"call-too-few\", \"p { f(1,x) } f(x,y) { true }\", \"{x,}\"},\n\t\t{\"object-key-comprehension\", \"p { { {p|x}: 0 } }\", \"{x,}\"},\n\t\t{\"set-value-comprehension\", \"p { {1, {p|x}} }\", \"{x,}\"},\n\t\t{\"every\", \"p { every y in [10] { x > y } }\", \"{x,}\"},\n\t}\n\n\tmakeErrMsg := func(varName string) string {\n\t\treturn fmt.Sprintf(\"rego_unsafe_var_error: var %v is unsafe\", varName)\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\n\t\t\t// Build slice of expected error messages.\n\t\t\texpected := []string{}\n\n\t\t\t_ = MustParseTerm(tc.expected).Value.(Set).Iter(func(x *Term) error {\n\t\t\t\texpected = append(expected, makeErrMsg(string(x.Value.(Var))))\n\t\t\t\treturn nil\n\t\t\t}) // cannot return error\n\n\t\t\tsort.Strings(expected)\n\n\t\t\t// Compile test module.\n\t\t\tpopts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\t\t\tc := NewCompiler()\n\t\t\tc.Modules = map[string]*Module{\n\t\t\t\t\"newMod\": MustParseModuleWithOpts(fmt.Sprintf(`\n\n\t\t\t\t%v\n\n\t\t\t\t%v\n\n\t\t\t\t`, moduleBegin, tc.moduleContent), popts),\n\t\t\t}\n\n\t\t\tcompileStages(c, c.checkSafetyRuleBodies)\n\n\t\t\t// Get errors.\n\t\t\tresult := compilerErrsToStringSlice(c.Errors)\n\n\t\t\t// Check against expected.\n\t\t\tif len(result) != len(expected) {\n\t\t\t\tt.Fatalf(\"Expected %d:\\n%v\\nBut got %d:\\n%v\", len(expected), strings.Join(expected, \"\\n\"), len(result), strings.Join(result, \"\\n\"))\n\t\t\t}\n\n\t\t\tfor i := range result {\n\t\t\t\tif expected[i] != result[i] {\n\t\t\t\t\tt.Errorf(\"Expected %v but got: %v\", expected[i], result[i])\n\t\t\t\t}\n\t\t\t}\n\n\t\t})\n\t}\n}\n\nfunc TestCompilerCheckSafetyVarLoc(t *testing.T) {\n\n\t_, err := CompileModules(map[string]string{\"test.rego\": `package test\n\np {\n\tnot x\n\tx > y\n}`})\n\n\tif err == nil {\n\t\tt.Fatal(\"expected error\")\n\t}\n\n\terrs := err.(Errors)\n\n\tif !strings.Contains(errs[0].Message, \"var x is unsafe\") || errs[0].Location.Row != 4 {\n\t\tt.Fatal(\"expected error on row 4 but got:\", err)\n\t}\n\n\tif !strings.Contains(errs[1].Message, \"var y is unsafe\") || errs[1].Location.Row != 5 {\n\t\tt.Fatal(\"expected y is unsafe on row 5 but got:\", err)\n\t}\n}\n\nfunc TestCompilerCheckTypes(t *testing.T) {\n\tc := NewCompiler()\n\tmodules := getCompilerTestModules()\n\tc.Modules = map[string]*Module{\"mod6\": modules[\"mod6\"], \"mod7\": modules[\"mod7\"]}\n\tcompileStages(c, c.checkTypes)\n\tassertNotFailed(t, c)\n}\n\nfunc TestCompilerCheckRuleConflicts(t *testing.T) {\n\n\tc := getCompilerWithParsedModules(map[string]string{\n\t\t\"mod1.rego\": `package badrules\n\np[x] { x = 1 }\np[x] = y { x = y; x = \"a\" }\nq[1] { true }\nq = {1, 2, 3} { true }\nr[x] = y { x = y; x = \"a\" }\nr[x] = y { x = y; x = \"a\" }`,\n\n\t\t\"mod2.rego\": `package badrules.r\n\nq[1] { true }`,\n\n\t\t\"mod3.rego\": `package badrules.defkw\n\ndefault foo = 1\ndefault foo = 2\nfoo = 3 { true }`,\n\t\t\"mod4.rego\": `package adrules.arity\n\nf(1) { true }\nf { true }\n\ng(1) { true }\ng(1,2) { true }`,\n\t\t\"mod5.rego\": `package badrules.dataoverlap\n\np { true }`,\n\t\t\"mod6.rego\": `package badrules.existserr\n\np { true }`})\n\n\tc.WithPathConflictsCheck(func(path []string) (bool, error) {\n\t\tif reflect.DeepEqual(path, []string{\"badrules\", \"dataoverlap\", \"p\"}) {\n\t\t\treturn true, nil\n\t\t} else if reflect.DeepEqual(path, []string{\"badrules\", \"existserr\", \"p\"}) {\n\t\t\treturn false, fmt.Errorf(\"unexpected error\")\n\t\t}\n\t\treturn false, nil\n\t})\n\n\tcompileStages(c, c.checkRuleConflicts)\n\n\texpected := []string{\n\t\t\"rego_compile_error: conflict check for data path badrules/existserr/p: unexpected error\",\n\t\t\"rego_compile_error: conflicting rule for data path badrules/dataoverlap/p found\",\n\t\t\"rego_type_error: conflicting rules named f found\",\n\t\t\"rego_type_error: conflicting rules named g found\",\n\t\t\"rego_type_error: conflicting rules named p found\",\n\t\t\"rego_type_error: conflicting rules named q found\",\n\t\t\"rego_type_error: multiple default rules named foo found\",\n\t\t\"rego_type_error: package badrules.r conflicts with rule defined at mod1.rego:7\",\n\t\t\"rego_type_error: package badrules.r conflicts with rule defined at mod1.rego:8\",\n\t}\n\n\tassertCompilerErrorStrings(t, c, expected)\n}\n\nfunc TestCompilerCheckUndefinedFuncs(t *testing.T) {\n\n\tmodule := `\n\t\tpackage test\n\n\t\tundefined_function {\n\t\t\tdata.deadbeef(x)\n\t\t}\n\n\t\tundefined_global {\n\t\t\tdeadbeef(x)\n\t\t}\n\n\t\t# NOTE: all the dynamic dispatch examples here are not supported,\n\t\t#       we're checking assertions about the error returned.\n\t\tundefined_dynamic_dispatch {\n\t\t\tx = \"f\"; data.test2[x](1)\n\t\t}\n\n\t\tundefined_dynamic_dispatch_declared_var {\n\t\t\ty := \"f\"; data.test2[y](1)\n\t\t}\n\n\t\tundefined_dynamic_dispatch_declared_var_in_array {\n\t\t\tz := \"f\"; data.test2[[z]](1)\n\t\t}\n\n\t\tarity_mismatch_1 {\n\t\t\tdata.test2.f(1,2,3)\n\t\t}\n\n\t\tarity_mismatch_2 {\n\t\t\tdata.test2.f()\n\t\t}\n\n\t\tarity_mismatch_3 {\n\t\t\tx:= data.test2.f()\n\t\t}\n\t`\n\n\tmodule2 := `\n\t\tpackage test2\n\n\t\tf(x) = x\n\t`\n\n\t_, err := CompileModules(map[string]string{\n\t\t\"test.rego\":  module,\n\t\t\"test2.rego\": module2,\n\t})\n\tif err == nil {\n\t\tt.Fatal(\"expected errors\")\n\t}\n\n\tresult := err.Error()\n\twant := []string{\n\t\t\"rego_type_error: undefined function data.deadbeef\",\n\t\t\"rego_type_error: undefined function deadbeef\",\n\t\t\"rego_type_error: undefined function data.test2[x]\",\n\t\t\"rego_type_error: undefined function data.test2[y]\",\n\t\t\"rego_type_error: undefined function data.test2[[z]]\",\n\t\t\"rego_type_error: function data.test2.f has arity 1, got 3 arguments\",\n\t\t\"test.rego:31: rego_type_error: function data.test2.f has arity 1, got 0 arguments\",\n\t\t\"test.rego:35: rego_type_error: function data.test2.f has arity 1, got 0 arguments\",\n\t}\n\tfor _, w := range want {\n\t\tif !strings.Contains(result, w) {\n\t\t\tt.Fatalf(\"Expected %q in result but got: %v\", w, result)\n\t\t}\n\t}\n}\n\nfunc TestCompilerQueryCompilerCheckUndefinedFuncs(t *testing.T) {\n\tcompiler := NewCompiler()\n\n\tfor _, tc := range []struct {\n\t\tnote, query, err string\n\t}{\n\n\t\t{note: \"undefined function\", query: `data.foo(1)`, err: \"undefined function data.foo\"},\n\t\t{note: \"undefined global function\", query: `foo(1)`, err: \"undefined function foo\"},\n\t\t{note: \"var\", query: `x = \"f\"; data[x](1)`, err: \"undefined function data[x]\"},\n\t\t{note: \"declared var\", query: `x := \"f\"; data[x](1)`, err: \"undefined function data[x]\"},\n\t\t{note: \"declared var in array\", query: `x := \"f\"; data[[x]](1)`, err: \"undefined function data[[x]]\"},\n\t} {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\t_, err := compiler.QueryCompiler().Compile(MustParseBody(tc.query))\n\t\t\tif !strings.Contains(err.Error(), tc.err) {\n\t\t\t\tt.Errorf(\"Unexpected compilation error: %v (want  %s)\", err, tc.err)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerImportsResolved(t *testing.T) {\n\n\tmodules := map[string]*Module{\n\t\t\"mod1\": MustParseModule(`package ex\n\nimport data\nimport input\nimport data.foo\nimport input.bar\nimport data.abc as baz\nimport input.abc as qux`,\n\t\t),\n\t}\n\n\tc := NewCompiler()\n\tc.Compile(modules)\n\n\tassertNotFailed(t, c)\n\n\tif len(c.Modules[\"mod1\"].Imports) != 0 {\n\t\tt.Fatalf(\"Expected imports to be empty after compile but got: %v\", c.Modules)\n\t}\n\n}\n\nfunc TestCompilerExprExpansion(t *testing.T) {\n\n\ttests := []struct {\n\t\tnote     string\n\t\tinput    string\n\t\texpected []*Expr\n\t}{\n\t\t{\n\t\t\tnote:  \"identity\",\n\t\t\tinput: \"x\",\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"x\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"single\",\n\t\t\tinput: \"x+y\",\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"x+y\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"chained\",\n\t\t\tinput: \"x+y+z+w\",\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"plus(x, y, __local0__)\"),\n\t\t\t\tMustParseExpr(\"plus(__local0__, z, __local1__)\"),\n\t\t\t\tMustParseExpr(\"plus(__local1__, w)\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"assoc\",\n\t\t\tinput: \"x+y*z\",\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"mul(y, z, __local0__)\"),\n\t\t\t\tMustParseExpr(\"plus(x, __local0__)\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"refs\",\n\t\t\tinput: \"p[q[f(x)]][g(x)]\",\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"f(x, __local0__)\"),\n\t\t\t\tMustParseExpr(\"g(x, __local1__)\"),\n\t\t\t\tMustParseExpr(\"p[q[__local0__]][__local1__]\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"arrays\",\n\t\t\tinput: \"[[f(x)], g(x)]\",\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"f(x, __local0__)\"),\n\t\t\t\tMustParseExpr(\"g(x, __local1__)\"),\n\t\t\t\tMustParseExpr(\"[[__local0__], __local1__]\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"objects\",\n\t\t\tinput: `{f(x): {g(x): h(x)}}`,\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"f(x, __local0__)\"),\n\t\t\t\tMustParseExpr(\"g(x, __local1__)\"),\n\t\t\t\tMustParseExpr(\"h(x, __local2__)\"),\n\t\t\t\tMustParseExpr(\"{__local0__: {__local1__: __local2__}}\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"sets\",\n\t\t\tinput: `{f(x), {g(x)}}`,\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"g(x, __local0__)\"),\n\t\t\t\tMustParseExpr(\"f(x, __local1__)\"),\n\t\t\t\tMustParseExpr(\"{__local1__, {__local0__,}}\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"unify\",\n\t\t\tinput: \"f(x) = g(x)\",\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"f(x, __local0__)\"),\n\t\t\t\tMustParseExpr(\"g(x, __local1__)\"),\n\t\t\t\tMustParseExpr(\"__local0__ = __local1__\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"unify: composites\",\n\t\t\tinput: \"[x, f(x)] = [g(y), y]\",\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"f(x, __local0__)\"),\n\t\t\t\tMustParseExpr(\"g(y, __local1__)\"),\n\t\t\t\tMustParseExpr(\"[x, __local0__] = [__local1__, y]\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"with: term expr\",\n\t\t\tinput: \"f[x+1] with input as q\",\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"plus(x, 1, __local0__) with input as q\"),\n\t\t\t\tMustParseExpr(\"f[__local0__] with input as q\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"with: call expr\",\n\t\t\tinput: `f(x) = g(x) with input as p`,\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"f(x, __local0__) with input as p\"),\n\t\t\t\tMustParseExpr(\"g(x, __local1__) with input as p\"),\n\t\t\t\tMustParseExpr(\"__local0__ = __local1__ with input as p\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"comprehensions\",\n\t\t\tinput: `f(y) = [[plus(x,1) | x = sum(y[z+1])], g(w)]`,\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"f(y, __local0__)\"),\n\t\t\t\tMustParseExpr(\"g(w, __local4__)\"),\n\t\t\t\tMustParseExpr(\"__local0__ = [[__local1__ | plus(z,1,__local2__); sum(y[__local2__], __local3__); eq(x, __local3__); plus(x, 1, __local1__)], __local4__]\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"indirect references\",\n\t\t\tinput: `[1, 2, 3][i]`,\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"__local0__ = [1, 2, 3]\"),\n\t\t\t\tMustParseExpr(\"__local0__[i]\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"multiple indirect references\",\n\t\t\tinput: `split(split(\"foo.bar:qux\", \".\")[_], \":\")[i]`,\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(`split(\"foo.bar:qux\", \".\", __local0__)`),\n\t\t\t\tMustParseExpr(`split(__local0__[_], \":\", __local1__)`),\n\t\t\t\tMustParseExpr(`__local1__[i]`),\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tgen := newLocalVarGenerator(\"\", NullTerm())\n\t\t\texpr := MustParseExpr(tc.input)\n\t\t\tresult := expandExpr(gen, expr.Copy())\n\t\t\tif len(result) != len(tc.expected) {\n\t\t\t\tt.Fatalf(\"Expected %v exprs but got %v:\\n\\nExpected:\\n\\n%v\\n\\nGot:\\n\\n%v\", len(tc.expected), len(result), Body(tc.expected), Body(result))\n\t\t\t}\n\t\t\tfor i := range tc.expected {\n\t\t\t\tif !tc.expected[i].Equal(result[i]) {\n\t\t\t\t\tt.Fatalf(\"Expected expr %d to be %v but got: %v\\n\\nExpected:\\n\\n%v\\n\\nGot:\\n\\n%v\", i, tc.expected[i], result[i], Body(tc.expected), Body(result))\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerRewriteExprTerms(t *testing.T) {\n\tcases := []struct {\n\t\tnote     string\n\t\tmodule   string\n\t\texpected interface{}\n\t}{\n\t\t{\n\t\t\tnote: \"base\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp { x = a + b * y }\n\n\t\t\t\tq[[data.test.f(x)]] { x = 1 }\n\n\t\t\t\tr = [data.test.f(x)] { x = 1 }\n\n\t\t\t\tf(x) = data.test.g(x)\n\n\t\t\t\tpi = 3 + .14\n\n\t\t\t\twith_value { 1 with input as f(1) }\n\t\t\t`,\n\t\t\texpected: `\n\t\t\t\tpackage test\n\n\t\t\t\tp { mul(b, y, __local1__); plus(a, __local1__, __local2__); eq(x, __local2__) }\n\n\t\t\t\tq[[__local3__]] { x = 1; data.test.f(x, __local3__) }\n\n\t\t\t\tr = [__local4__] { x = 1; data.test.f(x, __local4__) }\n\n\t\t\t\tf(__local0__) = __local5__ { true; data.test.g(__local0__, __local5__) }\n\n\t\t\t\tpi = __local6__ { true; plus(3, 0.14, __local6__) }\n\n\t\t\t\twith_value { data.test.f(1, __local7__); 1 with input as __local7__ }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"builtin calls in head\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tf(1+1) = 7\n\t\t\t`,\n\t\t\texpected: Errors{&Error{Message: \"rule arguments cannot contain calls\"}},\n\t\t},\n\t\t{\n\t\t\tnote: \"builtin calls in head\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tf(object.get(x)) { object := {\"a\": 1}; object.a == x }\n\t\t\t`,\n\t\t\texpected: Errors{&Error{Message: \"rule arguments cannot contain calls\"}},\n\t\t},\n\t\t{\n\t\t\tnote: \"indirect ref in args\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tf([1][0]) { true }`,\n\t\t\texpected: `\n\t\t\t\tpackage test\n\n\t\t\t\tf(__local0__[0]) { true; __local0__ = [1] }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"every: domain\",\n\t\t\tmodule: `\n\t\t\tpackage test\n\n\t\t\tp { every x in [1,2] { x } }`,\n\t\t\texpected: `\n\t\t\tpackage test\n\n\t\t\tp { __local2__ = [1, 2]; every __local0__, __local1__ in __local2__ { __local1__ } }`,\n\t\t},\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tcompiler := NewCompiler()\n\t\t\topts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\n\t\t\tcompiler.Modules = map[string]*Module{\n\t\t\t\t\"test\": MustParseModuleWithOpts(tc.module, opts),\n\t\t\t}\n\t\t\tcompileStages(compiler, compiler.rewriteExprTerms)\n\n\t\t\tswitch exp := tc.expected.(type) {\n\t\t\tcase string:\n\t\t\t\tassertNotFailed(t, compiler)\n\n\t\t\t\texpected := MustParseModuleWithOpts(exp, opts)\n\n\t\t\t\tif !expected.Equal(compiler.Modules[\"test\"]) {\n\t\t\t\t\tt.Fatalf(\"Expected modules to be equal. Expected:\\n\\n%v\\n\\nGot:\\n\\n%v\", expected, compiler.Modules[\"test\"])\n\t\t\t\t}\n\t\t\tcase Errors:\n\t\t\t\tassertErrors(t, compiler.Errors, exp, false)\n\t\t\tdefault:\n\t\t\t\tt.Fatalf(\"Unsupported value type for test case 'expected' field: %v\", exp)\n\t\t\t}\n\n\t\t})\n\t}\n}\n\nfunc TestIllegalFunctionCallRewrite(t *testing.T) {\n\tcases := []struct {\n\t\tnote           string\n\t\tmodule         string\n\t\texpectedErrors []string\n\t}{\n\t\t/*{\n\t\t\t\t\tnote: \"function call override in function value\",\n\t\t\t\t\tmodule: `package test\n\t\tfoo(x) := x\n\n\t\tp := foo(bar) {\n\t\t\t#foo := 1\n\t\t\tbar := 2\n\t\t}`,\n\t\t\t\t\texpectedErrors: []string{\n\t\t\t\t\t\t\"undefined function foo\",\n\t\t\t\t\t},\n\t\t\t\t},*/\n\t\t{\n\t\t\tnote: \"function call override in array comprehension value\",\n\t\t\tmodule: `package test\np := [foo(bar) | foo := 1; bar := 2]`,\n\t\t\texpectedErrors: []string{\n\t\t\t\t\"called function foo shadowed\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"function call override in set comprehension value\",\n\t\t\tmodule: `package test\np := {foo(bar) | foo := 1; bar := 2}`,\n\t\t\texpectedErrors: []string{\n\t\t\t\t\"called function foo shadowed\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"function call override in object comprehension value\",\n\t\t\tmodule: `package test\np := {foo(bar): bar(foo) | foo := 1; bar := 2}`,\n\t\t\texpectedErrors: []string{\n\t\t\t\t\"called function bar shadowed\",\n\t\t\t\t\"called function foo shadowed\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"function call override in array comprehension value\",\n\t\t\tmodule: `package test\np := [foo.bar(baz) | foo := 1; bar := 2; baz := 3]`,\n\t\t\texpectedErrors: []string{\n\t\t\t\t\"called function foo.bar shadowed\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"nested function call override in array comprehension value\",\n\t\t\tmodule: `package test\np := [baz(foo(bar)) | foo := 1; bar := 2]`,\n\t\t\texpectedErrors: []string{\n\t\t\t\t\"called function foo shadowed\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"function call override of 'input' root document\",\n\t\t\tmodule: `package test\np := [input() | input := 1]`,\n\t\t\texpectedErrors: []string{\n\t\t\t\t\"called function input shadowed\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"function call override of 'data' root document\",\n\t\t\tmodule: `package test\np := [data() | data := 1]`,\n\t\t\texpectedErrors: []string{\n\t\t\t\t\"called function data shadowed\",\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tcompiler := NewCompiler()\n\t\t\topts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\n\t\t\tcompiler.Modules = map[string]*Module{\n\t\t\t\t\"test\": MustParseModuleWithOpts(tc.module, opts),\n\t\t\t}\n\t\t\tcompileStages(compiler, compiler.rewriteLocalVars)\n\n\t\t\tresult := make([]string, 0, len(compiler.Errors))\n\t\t\tfor i := range compiler.Errors {\n\t\t\t\tresult = append(result, compiler.Errors[i].Message)\n\t\t\t}\n\n\t\t\tsort.Strings(tc.expectedErrors)\n\t\t\tsort.Strings(result)\n\n\t\t\tif len(tc.expectedErrors) != len(result) {\n\t\t\t\tt.Fatalf(\"Expected %d errors but got %d:\\n\\n%v\\n\\nGot:\\n\\n%v\",\n\t\t\t\t\tlen(tc.expectedErrors), len(result),\n\t\t\t\t\tstrings.Join(tc.expectedErrors, \"\\n\"), strings.Join(result, \"\\n\"))\n\t\t\t}\n\n\t\t\tfor i := range result {\n\t\t\t\tif result[i] != tc.expectedErrors[i] {\n\t\t\t\t\tt.Fatalf(\"Expected:\\n\\n%v\\n\\nGot:\\n\\n%v\",\n\t\t\t\t\t\tstrings.Join(tc.expectedErrors, \"\\n\"), strings.Join(result, \"\\n\"))\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerCheckUnusedImports(t *testing.T) {\n\tcases := []strictnessTestCase{\n\t\t{\n\t\t\tnote: \"simple unused: input ref with same name\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo.bar as bar\n\t\t\tr {\n\t\t\t\tinput.bar == 11\n\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 2, 4),\n\t\t\t\t\tMessage:  \"import data.foo.bar as bar unused\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"unused import, but imported ref used\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo # unused\n\t\t\tr { data.foo == 10 }\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 2, 4),\n\t\t\t\t\tMessage:  \"import data.foo unused\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"one of two unused\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo\n\t\t\timport data.x.power #unused\n\t\t\tr { foo == 10 }\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 3, 4),\n\t\t\t\t\tMessage:  \"import data.x.power unused\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"multiple unused: with input ref of same name\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo\n\t\t\timport data.x.power\n\t\t\tr { input.foo == 10 }\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 2, 4),\n\t\t\t\t\tMessage:  \"import data.foo unused\",\n\t\t\t\t},\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 3, 4),\n\t\t\t\t\tMessage:  \"import data.x.power unused\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"import used in comparison\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo.x\n\t\t\tr { x == 10 }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"multiple used imports in one rule\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo.x\n\t\t\timport data.power.ranger\n\t\t\tr { ranger == x }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"multiple used imports in separate rules\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo.x\n\t\t\timport data.power.ranger\n\t\t\tr { ranger == 23 }\n\t\t\tt { x == 1 }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"import used as function operand\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo\n\t\t\tr = count(foo) > 1 # only one operand\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"import used as function operand, compount term\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo\n\t\t\tr = sprintf(\"%v %d\", [foo, 0])\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"import used as plain term\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo\n\t\t\tr {\n\t\t\t\tfoo\n\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"import used in 'every' domain\",\n\t\t\tmodule: `package p\n\t\t\timport future.keywords.every\n\t\t\timport data.foo\n\t\t\tr {\n\t\t\t\tevery x in foo { x > 1 }\n\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"import used in 'every' body\",\n\t\t\tmodule: `package p\n\t\t\timport future.keywords.every\n\t\t\timport data.foo\n\t\t\tr {\n\t\t\t\tevery x in [1,2,3] { x > foo }\n\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"future import kept even if unused\",\n\t\t\tmodule: `package p\n\t\t\timport future.keywords\n\n\t\t\tr { true }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"shadowed var name in function arg\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo # unused\n\n\t\t\tr { f(1) }\n\t\t\tf(foo) = foo == 1\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 2, 4),\n\t\t\t\t\tMessage:  \"import data.foo unused\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"shadowed assigned var name\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo # unused\n\n\t\t\tr { foo := true; foo }\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 2, 4),\n\t\t\t\t\tMessage:  \"import data.foo unused\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"used as rule value\",\n\t\t\tmodule: `package p\n\t\t\timport data.bar # unused\n\t\t\timport data.foo\n\n\t\t\tr = foo { true }\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 2, 4),\n\t\t\t\t\tMessage:  \"import data.bar unused\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"unused as rule value (but same data ref)\",\n\t\t\tmodule: `package p\n\t\t\timport data.bar # unused\n\t\t\timport data.foo # unused\n\n\t\t\tr = data.foo { true }\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 2, 4),\n\t\t\t\t\tMessage:  \"import data.bar unused\",\n\t\t\t\t},\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 3, 4),\n\t\t\t\t\tMessage:  \"import data.foo unused\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\trunStrictnessTestCase(t, cases, true)\n}\n\nfunc TestCompilerCheckDuplicateImports(t *testing.T) {\n\tcases := []strictnessTestCase{\n\t\t{\n\t\t\tnote: \"shadow\",\n\t\t\tmodule: `package test\n\t\t\t\timport input.noconflict\n\t\t\t\timport input.foo\n\t\t\t\timport data.foo\n\t\t\t\timport data.bar.foo\n\n\t\t\t\tp := noconflict\n\t\t\t\tq := foo\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 4, 5),\n\t\t\t\t\tMessage:  \"import must not shadow import input.foo\",\n\t\t\t\t},\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 5, 5),\n\t\t\t\t\tMessage:  \"import must not shadow import input.foo\",\n\t\t\t\t},\n\t\t\t},\n\t\t}, {\n\t\t\tnote: \"alias shadow\",\n\t\t\tmodule: `package test\n\t\t\t\timport input.noconflict\n\t\t\t\timport input.foo\n\t\t\t\timport input.bar as foo\n\n\t\t\t\tp := noconflict\n\t\t\t\tq := foo\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 4, 5),\n\t\t\t\t\tMessage:  \"import must not shadow import input.foo\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\trunStrictnessTestCase(t, cases, true)\n}\n\nfunc TestCompilerCheckKeywordOverrides(t *testing.T) {\n\tcases := []strictnessTestCase{\n\t\t{\n\t\t\tnote: \"rule names\",\n\t\t\tmodule: `package test\n\t\t\t\tinput { true }\n\t\t\t\tp { true }\n\t\t\t\tdata { true }\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"input { true }\"), \"\", 2, 5),\n\t\t\t\t\tMessage:  \"rules must not shadow input (use a different rule name)\",\n\t\t\t\t},\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"data { true }\"), \"\", 4, 5),\n\t\t\t\t\tMessage:  \"rules must not shadow data (use a different rule name)\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"global assignments\",\n\t\t\tmodule: `package test\n\t\t\t\tinput = 1\n\t\t\t\tp := 2\n\t\t\t\tdata := 3\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"input = 1\"), \"\", 2, 5),\n\t\t\t\t\tMessage:  \"rules must not shadow input (use a different rule name)\",\n\t\t\t\t},\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"data := 3\"), \"\", 4, 5),\n\t\t\t\t\tMessage:  \"rules must not shadow data (use a different rule name)\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule-local assignments\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tinput := 1\n\t\t\t\t\tx := 2\n\t\t\t\t} else {\n\t\t\t\t\tdata := 3\n\t\t\t\t}\n\t\t\t\tq {\n\t\t\t\t\tinput := 4\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"input := 1\"), \"\", 3, 6),\n\t\t\t\t\tMessage:  \"variables must not shadow input (use a different variable name)\",\n\t\t\t\t},\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"data := 3\"), \"\", 6, 6),\n\t\t\t\t\tMessage:  \"variables must not shadow data (use a different variable name)\",\n\t\t\t\t},\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"input := 4\"), \"\", 9, 6),\n\t\t\t\t\tMessage:  \"variables must not shadow input (use a different variable name)\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"array comprehension-local assignments\",\n\t\t\tmodule: `package test\n\t\t\t\tp = [ x |\n\t\t\t\t\tinput := 1\n\t\t\t\t\tx := 2\n\t\t\t\t\tdata := 3\n\t\t\t\t]\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"input := 1\"), \"\", 3, 6),\n\t\t\t\t\tMessage:  \"variables must not shadow input (use a different variable name)\",\n\t\t\t\t},\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"data := 3\"), \"\", 5, 6),\n\t\t\t\t\tMessage:  \"variables must not shadow data (use a different variable name)\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"set comprehension-local assignments\",\n\t\t\tmodule: `package test\n\t\t\t\tp = { x |\n\t\t\t\t\tinput := 1\n\t\t\t\t\tx := 2\n\t\t\t\t\tdata := 3\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"input := 1\"), \"\", 3, 6),\n\t\t\t\t\tMessage:  \"variables must not shadow input (use a different variable name)\",\n\t\t\t\t},\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"data := 3\"), \"\", 5, 6),\n\t\t\t\t\tMessage:  \"variables must not shadow data (use a different variable name)\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"object comprehension-local assignments\",\n\t\t\tmodule: `package test\n\t\t\t\tp = { x: 1 |\n\t\t\t\t\tinput := 1\n\t\t\t\t\tx := 2\n\t\t\t\t\tdata := 3\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"input := 1\"), \"\", 3, 6),\n\t\t\t\t\tMessage:  \"variables must not shadow input (use a different variable name)\",\n\t\t\t\t},\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"data := 3\"), \"\", 5, 6),\n\t\t\t\t\tMessage:  \"variables must not shadow data (use a different variable name)\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"nested override\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\t[ x |\n\t\t\t\t\t\tinput := 1\n\t\t\t\t\t\tx := 2\n\t\t\t\t\t\tdata := 3\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"input := 1\"), \"\", 4, 7),\n\t\t\t\t\tMessage:  \"variables must not shadow input (use a different variable name)\",\n\t\t\t\t},\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"data := 3\"), \"\", 6, 7),\n\t\t\t\t\tMessage:  \"variables must not shadow data (use a different variable name)\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\trunStrictnessTestCase(t, cases, true)\n}\n\nfunc TestCompilerCheckDeprecatedMethods(t *testing.T) {\n\tcases := []strictnessTestCase{\n\t\t{\n\t\t\tnote: \"all() built-in\",\n\t\t\tmodule: `package test\n\t\t\t\tp := all([true, false])\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"all([true, false])\"), \"\", 2, 10),\n\t\t\t\t\tMessage:  \"deprecated built-in function calls in expression: all\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"user-defined all()\",\n\t\t\tmodule: `package test\n\t\t\t\timport future.keywords.in\n\t\t\t\tall(arr) = {x | some x in arr} == {true}\n\t\t\t\tp := all([true, false])\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"any() built-in\",\n\t\t\tmodule: `package test\n\t\t\t\tp := any([true, false])\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"any([true, false])\"), \"\", 2, 10),\n\t\t\t\t\tMessage:  \"deprecated built-in function calls in expression: any\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"user-defined any()\",\n\t\t\tmodule: `package test\n\t\t\t\timport future.keywords.in\n\t\t\t\tany(arr) := true in arr\n\t\t\t\tp := any([true, false])\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"re_match built-in\",\n\t\t\tmodule: `package test\n\t\t\t\tp := re_match(\"[a]\", \"a\")\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(`re_match(\"[a]\", \"a\")`), \"\", 2, 10),\n\t\t\t\t\tMessage:  \"deprecated built-in function calls in expression: re_match\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\trunStrictnessTestCase(t, cases, true)\n}\n\ntype strictnessTestCase struct {\n\tnote           string\n\tmodule         string\n\texpectedErrors Errors\n}\n\nfunc runStrictnessTestCase(t *testing.T, cases []strictnessTestCase, assertLocation bool) {\n\tt.Helper()\n\tmakeTestRunner := func(tc strictnessTestCase, strict bool) func(t *testing.T) {\n\t\treturn func(t *testing.T) {\n\t\t\tcompiler := NewCompiler().WithStrict(strict)\n\t\t\tcompiler.Modules = map[string]*Module{\n\t\t\t\t\"test\": MustParseModule(tc.module),\n\t\t\t}\n\t\t\tcompileStages(compiler, nil)\n\n\t\t\tif strict {\n\t\t\t\tassertErrors(t, compiler.Errors, tc.expectedErrors, assertLocation)\n\t\t\t} else {\n\t\t\t\tassertNotFailed(t, compiler)\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.note+\"_strict\", makeTestRunner(tc, true))\n\t\tt.Run(tc.note+\"_non-strict\", makeTestRunner(tc, false))\n\t}\n}\n\nfunc assertErrors(t *testing.T, actual Errors, expected Errors, assertLocation bool) {\n\tt.Helper()\n\tif len(expected) != len(actual) {\n\t\tt.Fatalf(\"Expected %d errors, got %d:\\n\\n%s\\n\", len(expected), len(actual), actual.Error())\n\t}\n\tincorrectErrs := false\n\tfor _, e := range expected {\n\t\tfound := false\n\t\tfor _, actual := range actual {\n\t\t\tif e.Message == actual.Message {\n\t\t\t\tif !assertLocation || e.Location.Equal(actual.Location) {\n\t\t\t\t\tfound = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif !found {\n\t\t\tincorrectErrs = true\n\t\t}\n\t}\n\tif incorrectErrs {\n\t\tt.Fatalf(\"Expected errors:\\n\\n%s\\n\\nGot:\\n\\n%s\\n\", expected.Error(), actual.Error())\n\t}\n}\n\nfunc TestCompilerResolveAllRefs(t *testing.T) {\n\tc := NewCompiler()\n\tc.Modules = getCompilerTestModules()\n\tc.Modules[\"head\"] = MustParseModule(`package head\n\nimport data.doc1 as bar\nimport input.x.y.foo\nimport input.qux as baz\n\np[foo[bar[i]]] = {\"baz\": baz} { true }`)\n\n\tc.Modules[\"elsekw\"] = MustParseModule(`package elsekw\n\n\timport input.x.y.foo\n\timport data.doc1 as bar\n\timport input.baz\n\n\tp {\n\t\tfalse\n\t} else = foo {\n\t\tbar\n\t} else = baz {\n\t\ttrue\n\t}\n\t`)\n\n\tc.Modules[\"nestedexprs\"] = MustParseModule(`package nestedexprs\n\n\t\tx = 1\n\n\t\tp {\n\t\t\tf(g(x))\n\t\t}`)\n\n\tc.Modules[\"assign\"] = MustParseModule(`package assign\n\n\t\tx = 1\n\t\ty = 1\n\n\t\tp {\n\t\t\tx := y\n\t\t\t[true | x := y]\n\t\t}`)\n\n\tc.Modules[\"someinassign\"] = MustParseModule(`package someinassign\n\t\timport future.keywords.in\n\t\tx = 1\n\t\ty = 1\n\n\t\tp[x] {\n\t\t\tsome x in [1, 2, y]\n\t\t}`)\n\n\tc.Modules[\"someinassignwithkey\"] = MustParseModule(`package someinassignwithkey\n\t\timport future.keywords.in\n\t\tx = 1\n\t\ty = 1\n\n\t\tp[x] {\n\t\t\tsome k, v in [1, 2, y]\n\t\t}`)\n\n\tc.Modules[\"donotresolve\"] = MustParseModule(`package donotresolve\n\n\t\tx = 1\n\n\t\tf(x) {\n\t\t\tx = 2\n\t\t}\n\t\t`)\n\n\tc.Modules[\"indirectrefs\"] = MustParseModule(`package indirectrefs\n\n\t\tf(x) = [x] {true}\n\n\t\tp {\n\t\t\tf(1)[0]\n\t\t}\n\t\t`)\n\n\tc.Modules[\"comprehensions\"] = MustParseModule(`package comprehensions\n\n\t\tnums = [1, 2, 3]\n\n\t\tf(x) = [x] {true}\n\n\t\tp[[1]] {true}\n\n\t\tq {\n\t\t\tp[[x | x = nums[_]]]\n\t\t}\n\n\t\tr = [y | y = f(1)[0]]\n\t\t`)\n\n\tc.Modules[\"everykw\"] = MustParseModuleWithOpts(`package everykw\n\n\tnums = {1, 2, 3}\n\tf(_) = true\n\tx = 100\n\txs = [1, 2, 3]\n\tp {\n\t\tevery x in xs {\n\t\t\tnums[x]\n\t\t\tx > 10\n\t\t}\n\t}`, ParserOptions{unreleasedKeywords: true, FutureKeywords: []string{\"every\", \"in\"}})\n\n\tcompileStages(c, c.resolveAllRefs)\n\tassertNotFailed(t, c)\n\n\t// Basic test cases.\n\tmod1 := c.Modules[\"mod1\"]\n\tp := mod1.Rules[0]\n\texpr1 := p.Body[0]\n\tterm := expr1.Terms.(*Term)\n\te := MustParseTerm(\"data.a.b.c.q[x]\")\n\tif !term.Equal(e) {\n\t\tt.Errorf(\"Wrong term (global in same module): expected %v but got: %v\", e, term)\n\t}\n\n\texpr2 := p.Body[1]\n\tterm = expr2.Terms.(*Term)\n\te = MustParseTerm(\"data.a.b.c.r[x]\")\n\tif !term.Equal(e) {\n\t\tt.Errorf(\"Wrong term (global in same package/diff module): expected %v but got: %v\", e, term)\n\t}\n\n\tmod2 := c.Modules[\"mod2\"]\n\tr := mod2.Rules[0]\n\texpr3 := r.Body[1]\n\tterm = expr3.Terms.([]*Term)[1]\n\te = MustParseTerm(\"data.x.y.p\")\n\tif !term.Equal(e) {\n\t\tt.Errorf(\"Wrong term (var import): expected %v but got: %v\", e, term)\n\t}\n\n\tmod3 := c.Modules[\"mod3\"]\n\texpr4 := mod3.Rules[0].Body[0]\n\tterm = expr4.Terms.([]*Term)[2]\n\te = MustParseTerm(\"{input.x.secret: [{input.x.keyid}]}\")\n\tif !term.Equal(e) {\n\t\tt.Errorf(\"Wrong term (nested refs): expected %v but got: %v\", e, term)\n\t}\n\n\t// Array comprehensions.\n\tmod5 := c.Modules[\"mod5\"]\n\n\tac := func(r *Rule) *ArrayComprehension {\n\t\treturn r.Body[0].Terms.(*Term).Value.(*ArrayComprehension)\n\t}\n\n\tacTerm1 := ac(mod5.Rules[0])\n\tassertTermEqual(t, acTerm1.Term, MustParseTerm(\"input.x.a\"))\n\tacTerm2 := ac(mod5.Rules[1])\n\tassertTermEqual(t, acTerm2.Term, MustParseTerm(\"data.a.b.c.q.a\"))\n\tacTerm3 := ac(mod5.Rules[2])\n\tassertTermEqual(t, acTerm3.Body[0].Terms.([]*Term)[1], MustParseTerm(\"input.x.a\"))\n\tacTerm4 := ac(mod5.Rules[3])\n\tassertTermEqual(t, acTerm4.Body[0].Terms.([]*Term)[1], MustParseTerm(\"data.a.b.c.q[i]\"))\n\tacTerm5 := ac(mod5.Rules[4])\n\tassertTermEqual(t, acTerm5.Body[0].Terms.([]*Term)[2].Value.(*ArrayComprehension).Term, MustParseTerm(\"input.x.a\"))\n\tacTerm6 := ac(mod5.Rules[5])\n\tassertTermEqual(t, acTerm6.Body[0].Terms.([]*Term)[2].Value.(*ArrayComprehension).Body[0].Terms.([]*Term)[1], MustParseTerm(\"data.a.b.c.q[i]\"))\n\n\t// Nested references.\n\tmod6 := c.Modules[\"mod6\"]\n\tnested1 := mod6.Rules[0].Body[0].Terms.(*Term)\n\tassertTermEqual(t, nested1, MustParseTerm(\"data.x[input.x[i].a[data.z.b[j]]]\"))\n\n\tnested2 := mod6.Rules[1].Body[1].Terms.(*Term)\n\tassertTermEqual(t, nested2, MustParseTerm(\"v[input.x[i]]\"))\n\n\tnested3 := mod6.Rules[3].Body[0].Terms.(*Term)\n\tassertTermEqual(t, nested3, MustParseTerm(\"data.x[data.a.b.nested.r]\"))\n\n\t// Refs in head.\n\tmod7 := c.Modules[\"head\"]\n\tassertTermEqual(t, mod7.Rules[0].Head.Key, MustParseTerm(\"input.x.y.foo[data.doc1[i]]\"))\n\tassertTermEqual(t, mod7.Rules[0].Head.Value, MustParseTerm(`{\"baz\": input.qux}`))\n\n\t// Refs in else.\n\tmod8 := c.Modules[\"elsekw\"]\n\tassertTermEqual(t, mod8.Rules[0].Else.Head.Value, MustParseTerm(\"input.x.y.foo\"))\n\tassertTermEqual(t, mod8.Rules[0].Else.Body[0].Terms.(*Term), MustParseTerm(\"data.doc1\"))\n\tassertTermEqual(t, mod8.Rules[0].Else.Else.Head.Value, MustParseTerm(\"input.baz\"))\n\n\t// Refs in calls.\n\tmod9 := c.Modules[\"nestedexprs\"]\n\tassertTermEqual(t, mod9.Rules[1].Body[0].Terms.([]*Term)[1], CallTerm(RefTerm(VarTerm(\"g\")), MustParseTerm(\"data.nestedexprs.x\")))\n\n\t// Ignore assigned vars.\n\tmod10 := c.Modules[\"assign\"]\n\tassertTermEqual(t, mod10.Rules[2].Body[0].Terms.([]*Term)[1], VarTerm(\"x\"))\n\tassertTermEqual(t, mod10.Rules[2].Body[0].Terms.([]*Term)[2], MustParseTerm(\"data.assign.y\"))\n\tassignCompr := mod10.Rules[2].Body[1].Terms.(*Term).Value.(*ArrayComprehension)\n\tassertTermEqual(t, assignCompr.Body[0].Terms.([]*Term)[1], VarTerm(\"x\"))\n\tassertTermEqual(t, assignCompr.Body[0].Terms.([]*Term)[2], MustParseTerm(\"data.assign.y\"))\n\n\t// Args\n\tmod11 := c.Modules[\"donotresolve\"]\n\tassertTermEqual(t, mod11.Rules[1].Head.Args[0], VarTerm(\"x\"))\n\tassertExprEqual(t, mod11.Rules[1].Body[0], MustParseExpr(\"x = 2\"))\n\n\t// Locations.\n\tparsedLoc := getCompilerTestModules()[\"mod1\"].Rules[0].Body[0].Terms.(*Term).Value.(Ref)[0].Location\n\tcompiledLoc := c.Modules[\"mod1\"].Rules[0].Body[0].Terms.(*Term).Value.(Ref)[0].Location\n\tif parsedLoc.Row != compiledLoc.Row {\n\t\tt.Fatalf(\"Expected parsed location (%v) and compiled location (%v) to be equal\", parsedLoc.Row, compiledLoc.Row)\n\t}\n\n\t// Indirect references.\n\tmod12 := c.Modules[\"indirectrefs\"]\n\tassertExprEqual(t, mod12.Rules[1].Body[0], MustParseExpr(\"data.indirectrefs.f(1)[0]\"))\n\n\t// Comprehensions\n\tmod13 := c.Modules[\"comprehensions\"]\n\tassertExprEqual(t, mod13.Rules[3].Body[0].Terms.(*Term).Value.(Ref)[3].Value.(*ArrayComprehension).Body[0], MustParseExpr(\"x = data.comprehensions.nums[_]\"))\n\tassertExprEqual(t, mod13.Rules[4].Head.Value.Value.(*ArrayComprehension).Body[0], MustParseExpr(\"y = data.comprehensions.f(1)[0]\"))\n\n\t// Ignore vars assigned via `some x in xs`.\n\tmod14 := c.Modules[\"someinassign\"]\n\tsomeInAssignCall := mod14.Rules[2].Body[0].Terms.(*SomeDecl).Symbols[0].Value.(Call)\n\tassertTermEqual(t, someInAssignCall[1], VarTerm(\"x\"))\n\tcollectionLastElem := someInAssignCall[2].Value.(*Array).Get(IntNumberTerm(2))\n\tassertTermEqual(t, collectionLastElem, MustParseTerm(\"data.someinassign.y\"))\n\n\t// Ignore key and val vars assigned via `some k, v in xs`.\n\tmod15 := c.Modules[\"someinassignwithkey\"]\n\tsomeInAssignCall = mod15.Rules[2].Body[0].Terms.(*SomeDecl).Symbols[0].Value.(Call)\n\tassertTermEqual(t, someInAssignCall[1], VarTerm(\"k\"))\n\tassertTermEqual(t, someInAssignCall[2], VarTerm(\"v\"))\n\tcollectionLastElem = someInAssignCall[3].Value.(*Array).Get(IntNumberTerm(2))\n\tassertTermEqual(t, collectionLastElem, MustParseTerm(\"data.someinassignwithkey.y\"))\n\n\tmod16 := c.Modules[\"everykw\"]\n\teveryExpr := mod16.Rules[len(mod16.Rules)-1].Body[0].Terms.(*Every)\n\tassertTermEqual(t, everyExpr.Body[0].Terms.(*Term), MustParseTerm(\"data.everykw.nums[x]\"))\n\tassertTermEqual(t, everyExpr.Domain, MustParseTerm(\"data.everykw.xs\"))\n\n\t// 'x' is not resolved\n\tassertTermEqual(t, everyExpr.Value, VarTerm(\"x\"))\n\tgt10 := MustParseExpr(\"x > 10\")\n\tgt10.Index++ // TODO(sr): why?\n\tassertExprEqual(t, everyExpr.Body[1], gt10)\n}\n\nfunc TestCompilerResolveErrors(t *testing.T) {\n\n\tc := NewCompiler()\n\tc.Modules = map[string]*Module{\n\t\t\"shadow-globals\": MustParseModule(`\n\t\t\tpackage shadow_globals\n\n\t\t\tf([input]) { true }\n\t\t`),\n\t}\n\n\tcompileStages(c, c.resolveAllRefs)\n\n\texpected := []string{\n\t\t`args must not shadow input`,\n\t}\n\n\tassertCompilerErrorStrings(t, c, expected)\n}\n\nfunc TestCompilerRewriteTermsInHead(t *testing.T) {\n\tc := NewCompiler()\n\tc.Modules[\"head\"] = MustParseModule(`package head\n\nimport data.doc1 as bar\nimport data.doc2 as corge\nimport input.x.y.foo\nimport input.qux as baz\n\np[foo[bar[i]]] = {\"baz\": baz, \"corge\": corge} { true }\nq = [true | true] { true }\nr = {\"true\": true | true} { true }\ns = {true | true} { true }\n\nelsekw {\n\tfalse\n} else = baz {\n\ttrue\n}\n`)\n\n\tcompileStages(c, c.rewriteRefsInHead)\n\tassertNotFailed(t, c)\n\n\trule1 := c.Modules[\"head\"].Rules[0]\n\texpected1 := MustParseRule(`p[__local0__] = __local1__ { true; __local0__ = input.x.y.foo[data.doc1[i]]; __local1__ = {\"baz\": input.qux, \"corge\": data.doc2} }`)\n\tassertRulesEqual(t, rule1, expected1)\n\n\trule2 := c.Modules[\"head\"].Rules[1]\n\texpected2 := MustParseRule(`q = __local2__ { true; __local2__ = [true | true] }`)\n\tassertRulesEqual(t, rule2, expected2)\n\n\trule3 := c.Modules[\"head\"].Rules[2]\n\texpected3 := MustParseRule(`r = __local3__ { true; __local3__ = {\"true\": true | true} }`)\n\tassertRulesEqual(t, rule3, expected3)\n\n\trule4 := c.Modules[\"head\"].Rules[3]\n\texpected4 := MustParseRule(`s = __local4__ { true; __local4__ = {true | true} }`)\n\tassertRulesEqual(t, rule4, expected4)\n\n\trule5 := c.Modules[\"head\"].Rules[4]\n\texpected5 := MustParseRule(`elsekw { false } else = __local5__ { true; __local5__ = input.qux }`)\n\tassertRulesEqual(t, rule5, expected5)\n}\n\nfunc TestCompilerRewriteRegoMetadataCalls(t *testing.T) {\n\ttests := []struct {\n\t\tnote   string\n\t\tmodule string\n\t\texp    string\n\t}{\n\t\t{\n\t\t\tnote: \"rego.metadata called, no metadata\",\n\t\t\tmodule: `package test\n\np {\n\trego.metadata.chain()[0].path == [\"test\", \"p\"]\n\trego.metadata.rule() == {}\n}`,\n\t\t\texp: `package test\n\np = true {\n\t__local2__ = [{\"path\": [\"test\", \"p\"]}]\n\t__local3__ = {}\n\t__local0__ = __local2__\n\tequal(__local0__[0].path, [\"test\", \"p\"])\n\t__local1__ = __local3__\n\tequal(__local1__, {})\n}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rego.metadata called, no output var, no metadata\",\n\t\t\tmodule: `package test\n\np {\n\trego.metadata.chain()\n\trego.metadata.rule()\n}`,\n\t\t\texp: `package test\n\np = true {\n\t__local0__ = [{\"path\": [\"test\", \"p\"]}]\n\t__local1__ = {}\n\t__local0__\n\t__local1__\n}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rego.metadata called, with metadata\",\n\t\t\tmodule: `# METADATA\n# description: A test package\npackage test\n\n# METADATA\n# title: My P Rule\np {\n\trego.metadata.chain()[0].title == \"My P Rule\"\n\trego.metadata.chain()[1].description == \"A test package\"\n}\n\n# METADATA\n# title: My Other P Rule\np {\n\trego.metadata.rule().title == \"My Other P Rule\"\n}`,\n\t\t\texp: `# METADATA\n# {\"scope\":\"package\",\"description\":\"A test package\"}\npackage test\n\n# METADATA\n# {\"scope\":\"rule\",\"title\":\"My P Rule\"}\np = true {\n\t__local3__ = [\n\t\t{\"annotations\": {\"scope\": \"rule\", \"title\": \"My P Rule\"}, \"path\": [\"test\", \"p\"]},\n\t\t{\"annotations\": {\"description\": \"A test package\", \"scope\": \"package\"}, \"path\": [\"test\"]}\n\t]\n\t__local0__ = __local3__\n\tequal(__local0__[0].title, \"My P Rule\")\n\t__local1__ = __local3__\n\tequal(__local1__[1].description, \"A test package\")\n}\n\n# METADATA\n# {\"scope\":\"rule\",\"title\":\"My Other P Rule\"}\np = true {\n\t__local4__ = {\"scope\": \"rule\", \"title\": \"My Other P Rule\"}\n\t__local2__ = __local4__\n\tequal(__local2__.title, \"My Other P Rule\")\n}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rego.metadata referenced multiple times\",\n\t\t\tmodule: `# METADATA\n# description: TEST\npackage test\n\np {\n\trego.metadata.chain()[0].path == [\"test\", \"p\"]\n\trego.metadata.chain()[1].path == [\"test\"]\n}`,\n\t\t\texp: `# METADATA\n# {\"scope\":\"package\",\"description\":\"TEST\"}\npackage test\n\np = true {\n\t__local2__ = [\n\t\t{\"path\": [\"test\", \"p\"]},\n\t\t{\"annotations\": {\"description\": \"TEST\", \"scope\": \"package\"}, \"path\": [\"test\"]}\n\t]\n\t__local0__ = __local2__\n\tequal(__local0__[0].path, [\"test\", \"p\"])\n\t__local1__ = __local2__\n\tequal(__local1__[1].path, [\"test\"]) }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rego.metadata return value\",\n\t\t\tmodule: `package test\n\np := rego.metadata.chain()`,\n\t\t\texp: `package test\n\np := __local0__ {\n\t__local1__ = [{\"path\": [\"test\", \"p\"]}]\n\ttrue\n\t__local0__ = __local1__\n}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rego.metadata argument in function call\",\n\t\t\tmodule: `package test\n\np {\n\tq(rego.metadata.chain())\n}\n\nq(s) {\n\ts == [\"test\", \"p\"]\n}`,\n\t\t\texp: `package test\n\np = true {\n\t__local2__ = [{\"path\": [\"test\", \"p\"]}]\n\t__local1__ = __local2__\n\tdata.test.q(__local1__)\n}\n\nq(__local0__) = true {\n\tequal(__local0__, [\"test\", \"p\"])\n}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rego.metadata used in array comprehension\",\n\t\t\tmodule: `package test\n\np = [x | x := rego.metadata.chain()]`,\n\t\t\texp: `package test\n\np = [__local0__ | __local1__ = __local2__; __local0__ = __local1__] {\n\t__local2__ = [{\"path\": [\"test\", \"p\"]}]\n\ttrue\n}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rego.metadata used in nested array comprehension\",\n\t\t\tmodule: `package test\n\np {\n\ty := [x | x := rego.metadata.chain()]\n\ty[0].path == [\"test\", \"p\"]\n}`,\n\t\t\texp: `package test\n\np = true {\n\t__local3__ = [{\"path\": [\"test\", \"p\"]}];\n\t__local1__ = [__local0__ | __local2__ = __local3__; __local0__ = __local2__];\n\tequal(__local1__[0].path, [\"test\", \"p\"])\n}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rego.metadata used in set comprehension\",\n\t\t\tmodule: `package test\n\np = {x | x := rego.metadata.chain()}`,\n\t\t\texp: `package test\n\np = {__local0__ | __local1__ = __local2__; __local0__ = __local1__} {\n\t__local2__ = [{\"path\": [\"test\", \"p\"]}]\n\ttrue\n}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rego.metadata used in nested set comprehension\",\n\t\t\tmodule: `package test\n\np {\n\ty := {x | x := rego.metadata.chain()}\n\ty[0].path == [\"test\", \"p\"]\n}`,\n\t\t\texp: `package test\n\np = true {\n\t__local3__ = [{\"path\": [\"test\", \"p\"]}]\n\t__local1__ = {__local0__ | __local2__ = __local3__; __local0__ = __local2__}\n\tequal(__local1__[0].path, [\"test\", \"p\"])\n}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rego.metadata used in object comprehension\",\n\t\t\tmodule: `package test\n\np = {i: x | x := rego.metadata.chain()[i]}`,\n\t\t\texp: `package test\n\np = {i: __local0__ | __local1__ = __local2__; __local0__ = __local1__[i]} {\n\t__local2__ = [{\"path\": [\"test\", \"p\"]}]\n\ttrue\n}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rego.metadata used in nested object comprehension\",\n\t\t\tmodule: `package test\n\np {\n\ty := {i: x | x := rego.metadata.chain()[i]}\n\ty[0].path == [\"test\", \"p\"]\n}`,\n\t\t\texp: `package test\n\np = true {\n\t__local3__ = [{\"path\": [\"test\", \"p\"]}]\n\t__local1__ = {i: __local0__ | __local2__ = __local3__; __local0__ = __local2__[i]}\n\tequal(__local1__[0].path, [\"test\", \"p\"])\n}`,\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tc := NewCompiler()\n\t\t\tc.Modules = map[string]*Module{\n\t\t\t\t\"test.rego\": MustParseModule(tc.module),\n\t\t\t}\n\t\t\tcompileStages(c, c.rewriteRegoMetadataCalls)\n\t\t\tassertNotFailed(t, c)\n\n\t\t\tresult := c.Modules[\"test.rego\"]\n\t\t\texp := MustParseModuleWithOpts(tc.exp, ParserOptions{ProcessAnnotation: true})\n\n\t\t\tif result.Compare(exp) != 0 {\n\t\t\t\tt.Fatalf(\"\\nExpected:\\n\\n%v\\n\\nGot:\\n\\n%v\", exp, result)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerOverridingSelfCalls(t *testing.T) {\n\tc := NewCompiler()\n\tc.Modules = map[string]*Module{\n\t\t\"self.rego\": MustParseModule(`package self.metadata\n\nchain(x) = \"foo\"\nrule := \"bar\"`),\n\t\t\"test.rego\": MustParseModule(`package test\nimport data.self\n\np := self.metadata.chain(42)\nq := self.metadata.rule`),\n\t}\n\n\tcompileStages(c, nil)\n\tassertNotFailed(t, c)\n}\n\nfunc TestCompilerRewriteLocalAssignments(t *testing.T) {\n\n\ttests := []struct {\n\t\tmodule          string\n\t\texp             interface{}\n\t\texpRewrittenMap map[Var]Var\n\t}{\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tbody { a := 1; a > 0 }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tbody = true { __local0__ = 1; gt(__local0__, 0) }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"a\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\thead_vars(a) = b { b := a }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\thead_vars(__local0__) = __local1__ { __local1__ = __local0__ }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"a\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"b\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\thead_key[a] { a := 1 }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\thead_key[__local0__] { __local0__ = 1 }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"a\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\thead_unsafe_var[a] { some a }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\thead_unsafe_var[__local0__] { true }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"a\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tp = {1,2,3}\n\t\t\t\tx = 4\n\t\t\t\thead_nested[p[x]] {\n\t\t\t\t\tsome x\n\t\t\t\t}`,\n\t\t\texp: `\n\t\t\t\t\tpackage test\n\t\t\t\t\tp = {1,2,3}\n\t\t\t\t\tx = 4\n\t\t\t\t\thead_nested[data.test.p[__local0__]]\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"x\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tp = {1,2}\n\t\t\t\thead_closure_nested[p[x]] {\n\t\t\t\t\ty = [true | some x; x = 1]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp = {1,2}\n\t\t\t\thead_closure_nested[data.test.p[x]] {\n\t\t\t\t\ty = [true | __local0__ = 1]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"x\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tnested {\n\t\t\t\t\ta := [1,2,3]\n\t\t\t\t\tx := [true | a[i] > 1]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tnested = true { __local0__ = [1, 2, 3]; __local1__ = [true | gt(__local0__[i], 1)] }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"a\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"x\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tx = 2\n\t\t\t\tshadow_globals[x] { x := 1 }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tx = 2 { true }\n\t\t\t\tshadow_globals[__local0__] { __local0__ = 1 }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"x\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tshadow_rule[shadow_rule] { shadow_rule := 1 }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tshadow_rule[__local0__] { __local0__ = 1 }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"shadow_rule\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tshadow_roots_1 { data := 1; input := 2; input > data }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tshadow_roots_1 = true { __local0__ = 1; __local1__ = 2; gt(__local1__, __local0__) }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"data\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"input\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tshadow_roots_2 { input := {\"a\": 1}; input.a > 0  }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tshadow_roots_2 = true { __local0__ = {\"a\": 1}; gt(__local0__.a, 0) }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"input\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tskip_with_target { a := 1; input := 2; data.p with input as a }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tskip_with_target = true { __local0__ = 1; __local1__ = 2; data.p with input as __local0__ }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"a\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"input\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tshadow_comprehensions {\n\t\t\t\t\ta := 1\n\t\t\t\t\t[true | a := 2; b := 1]\n\t\t\t\t\tb := 2\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tshadow_comprehensions = true { __local0__ = 1; [true | __local1__ = 2; __local2__ = 1]; __local3__ = 2 }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"a\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"a\"),\n\t\t\t\tVar(\"__local2__\"): Var(\"b\"),\n\t\t\t\tVar(\"__local3__\"): Var(\"b\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t\tscoping {\n\t\t\t\t\t\t[true | a := 1]\n\t\t\t\t\t\t[true | a := 2]\n\t\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tscoping = true { [true | __local0__ = 1]; [true | __local1__ = 2] }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"a\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"a\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tobject_keys {\n\t\t\t\t\t{k: v1, \"k2\": v2} := {\"foo\": 1, \"k2\": 2}\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tobject_keys = true { {\"k2\": __local0__, k: __local1__} = {\"foo\": 1, \"k2\": 2} }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"v2\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"v1\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\thead_array_comprehensions = [[x] | x := 1]\n\t\t\t\t\thead_set_comprehensions = {[x] | x := 1}\n\t\t\t\t\thead_object_comprehensions = {k: [x] | k := \"foo\"; x := 1}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\thead_array_comprehensions = [[__local0__] | __local0__ = 1] { true }\n\t\t\t\thead_set_comprehensions = {[__local1__] | __local1__ = 1} { true }\n\t\t\t\thead_object_comprehensions = {__local2__: [__local3__] | __local2__ = \"foo\"; __local3__ = 1} { true }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"x\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"x\"),\n\t\t\t\tVar(\"__local2__\"): Var(\"k\"),\n\t\t\t\tVar(\"__local3__\"): Var(\"x\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\trewritten_object_key {\n\t\t\t\t\tk := \"foo\"\n\t\t\t\t\t{k: 1}\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\trewritten_object_key = true { __local0__ = \"foo\"; {__local0__: 1} }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"k\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\trewritten_object_key_head[[{k: 1}]] {\n\t\t\t\t\tk := \"foo\"\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\trewritten_object_key_head[[{__local0__: 1}]] { __local0__ = \"foo\" }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"k\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\trewritten_object_key_head_value = [{k: 1}] {\n\t\t\t\t\tk := \"foo\"\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\trewritten_object_key_head_value = [{__local0__: 1}] { __local0__ = \"foo\" }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"k\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tskip_with_target_in_assignment {\n\t\t\t\t\tinput := 1\n\t\t\t\t\ta := [true | true with input as 2; true with input as 3]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tskip_with_target_in_assignment = true { __local0__ = 1; __local1__ = [true | true with input as 2; true with input as 3] }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"input\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"a\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\trewrite_value_in_assignment {\n\t\t\t\t\ta := 1\n\t\t\t\t\tb := 1 with input as [a]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\trewrite_value_in_assignment = true { __local0__ = 1; __local1__ = 1 with input as [__local0__] }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"a\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"b\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tglobal = {}\n\t\t\t\tref_shadowed {\n\t\t\t\t\tglobal := {\"a\": 1}\n\t\t\t\t\tglobal.a > 0\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tglobal = {} { true }\n\t\t\t\tref_shadowed = true { __local0__ = {\"a\": 1}; gt(__local0__.a, 0) }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"global\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tf(x) = y {\n\t\t\t\t\tx == 1\n\t\t\t\t\ty := 2\n\t\t\t\t} else = y {\n\t\t\t\t\tx == 3\n\t\t\t\t\ty := 4\n\t\t\t\t}\n\t\t\t`,\n\t\t\t// Each \"else\" rule has a separate rule head and the vars in the\n\t\t\t// args will be rewritten. Since we cannot currently redefine the\n\t\t\t// args, we must parse the module and then manually update the args.\n\t\t\texp: func() *Module {\n\t\t\t\tmodule := MustParseModule(`\n\t\t\t\t\tpackage test\n\n\t\t\t\t\tf(__local0__) = __local1__ { __local0__ == 1; __local1__ = 2 } else = __local3__ { __local2__ == 3; __local3__ = 4 }\n\t\t\t\t`)\n\t\t\t\tmodule.Rules[0].Else.Head.Args[0].Value = Var(\"__local2__\")\n\t\t\t\treturn module\n\t\t\t},\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"x\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"y\"),\n\t\t\t\tVar(\"__local2__\"): Var(\"x\"),\n\t\t\t\tVar(\"__local3__\"): Var(\"y\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tf({\"x\": [x]}) = y { x == 1; y := 2 }`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\n\t\t\t\tf({\"x\": [__local0__]}) = __local1__ { __local0__ == 1; __local1__ = 2 }`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"x\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"y\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tf(x, [x]) = x { x == 1 }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\n\t\t\t\tf(__local0__, [__local0__]) = __local0__ { __local0__ == 1 }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"x\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tf(x) = {x[0]: 1} { true }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\n\t\t\t\tf(__local0__) = {__local0__[0]: 1} { true }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"x\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tf({{t | t := 0}: 1}) {\n\t\t\t\t\ttrue\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\n\t\t\t\tf({{__local0__ | __local0__ = 0}: 1}) { true }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"t\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tf({{t | t := 0}}) {\n\t\t\t\t\ttrue\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\n\t\t\t\tf({{__local0__ | __local0__ = 0}}) { true }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"t\"),\n\t\t\t},\n\t\t},\n\t}\n\n\tfor i, tc := range tests {\n\t\tt.Run(fmt.Sprint(i), func(t *testing.T) {\n\t\t\tc := NewCompiler()\n\t\t\tc.Modules = map[string]*Module{\n\t\t\t\t\"test.rego\": MustParseModule(tc.module),\n\t\t\t}\n\t\t\tcompileStages(c, c.rewriteLocalVars)\n\t\t\tassertNotFailed(t, c)\n\t\t\tresult := c.Modules[\"test.rego\"]\n\t\t\tvar exp *Module\n\t\t\tswitch e := tc.exp.(type) {\n\t\t\tcase string:\n\t\t\t\texp = MustParseModule(e)\n\t\t\tcase func() *Module:\n\t\t\t\texp = e()\n\t\t\tdefault:\n\t\t\t\tpanic(\"expected value must be string or func() *Module\")\n\t\t\t}\n\t\t\tif result.Compare(exp) != 0 {\n\t\t\t\tt.Fatalf(\"\\nExpected:\\n\\n%v\\n\\nGot:\\n\\n%v\", exp, result)\n\t\t\t}\n\t\t\tif !reflect.DeepEqual(c.RewrittenVars, tc.expRewrittenMap) {\n\t\t\t\tt.Fatalf(\"\\nExpected Rewritten Vars:\\n\\n\\t%+v\\n\\nGot:\\n\\n\\t%+v\\n\\n\", tc.expRewrittenMap, c.RewrittenVars)\n\t\t\t}\n\t\t})\n\t}\n\n}\nfunc TestRewriteLocalVarDeclarationErrors(t *testing.T) {\n\n\tc := NewCompiler()\n\n\tc.Modules[\"test\"] = MustParseModule(`package test\n\n\tredeclaration {\n\t\tr1 = 1\n\t\tr1 := 2\n\t\tr2 := 1\n\t\t[b, r2] := [1, 2]\n\t\tinput.path == 1\n\t\tinput := \"foo\"\n\t\t_ := [1 | nested := 1; nested := 2]\n\t}\n\n\tnegation {\n\t\tnot a := 1\n\t}\n\n\tbad_assign {\n\t\tnull := x\n\t\ttrue := x\n\t\t4.5 := x\n\t\t\"foo\" := x\n\t\t[true | true] := []\n\t\t{true | true} := set()\n\t\t{\"foo\": true | true} := {}\n\t\tx + 1 := 2\n\t\tdata.foo := 1\n\t\t[z, 1] := [1, 2]\n\t}\n\n\targ_redeclared(arg1) {\n\t\targ1 := 1\n\t}\n\n\targ_nested_redeclared({{arg_nested| arg_nested := 1; arg_nested := 2}}) { true }\n\t`)\n\n\tcompileStages(c, c.rewriteLocalVars)\n\n\texpectedErrors := []string{\n\t\t\"var r1 referenced above\",\n\t\t\"var r2 assigned above\",\n\t\t\"var input referenced above\",\n\t\t\"var nested assigned above\",\n\t\t\"arg arg1 redeclared\",\n\t\t\"var arg_nested assigned above\",\n\t\t\"cannot assign vars inside negated expression\",\n\t\t\"cannot assign to ref\",\n\t\t\"cannot assign to arraycomprehension\",\n\t\t\"cannot assign to setcomprehension\",\n\t\t\"cannot assign to objectcomprehension\",\n\t\t\"cannot assign to call\",\n\t\t\"cannot assign to number\",\n\t\t\"cannot assign to number\",\n\t\t\"cannot assign to boolean\",\n\t\t\"cannot assign to string\",\n\t\t\"cannot assign to null\",\n\t}\n\n\tsort.Strings(expectedErrors)\n\n\tresult := []string{}\n\n\tfor i := range c.Errors {\n\t\tresult = append(result, c.Errors[i].Message)\n\t}\n\n\tsort.Strings(result)\n\n\tif len(expectedErrors) != len(result) {\n\t\tt.Fatalf(\"Expected %d errors but got %d:\\n\\n%v\\n\\nGot:\\n\\n%v\", len(expectedErrors), len(result), strings.Join(expectedErrors, \"\\n\"), strings.Join(result, \"\\n\"))\n\t}\n\n\tfor i := range result {\n\t\tif result[i] != expectedErrors[i] {\n\t\t\tt.Fatalf(\"Expected:\\n\\n%v\\n\\nGot:\\n\\n%v\", strings.Join(expectedErrors, \"\\n\"), strings.Join(result, \"\\n\"))\n\t\t}\n\t}\n}\n\nfunc TestRewriteDeclaredVarsStage(t *testing.T) {\n\n\t// Unlike the following test case, this only executes up to the\n\t// RewriteLocalVars stage. This is done so that later stages like\n\t// RewriteDynamics are not executed.\n\n\ttests := []struct {\n\t\tnote   string\n\t\tmodule string\n\t\texp    string\n\t}{\n\t\t{\n\t\t\tnote: \"object ref key\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\ta := {\"a\": \"a\"}\n\t\t\t\t\t{a.a: a.a}\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\t__local0__ = {\"a\": \"a\"}\n\t\t\t\t\t{__local0__.a: __local0__.a}\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"set ref element\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\ta := {\"a\": \"a\"}\n\t\t\t\t\t{a.a}\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\t__local0__ = {\"a\": \"a\"}\n\t\t\t\t\t{__local0__.a}\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\n\t\t\tc := NewCompiler()\n\n\t\t\tc.Modules = map[string]*Module{\n\t\t\t\t\"test.rego\": MustParseModule(tc.module),\n\t\t\t}\n\n\t\t\tcompileStages(c, c.rewriteLocalVars)\n\n\t\t\texp := MustParseModule(tc.exp)\n\t\t\tresult := c.Modules[\"test.rego\"]\n\n\t\t\tif !exp.Equal(result) {\n\t\t\t\tt.Fatalf(\"Expected:\\n\\n%v\\n\\nGot:\\n\\n%v\", exp, result)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestRewriteDeclaredVars(t *testing.T) {\n\ttests := []struct {\n\t\tnote    string\n\t\tmodule  string\n\t\texp     string\n\t\twantErr error\n\t}{\n\t\t{\n\t\t\tnote: \"rewrite unify\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tx = 1\n\t\t\t\ty = 2\n\t\t\t\tp { some x; input = [x, y] }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tx = 1\n\t\t\t\ty = 2\n\t\t\t\tp { __local1__ = data.test.y; input = [__local0__, __local1__] }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite call\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tx = []\n\t\t\t\ty = {}\n\t\t\t\tp { some x; walk(y, [x, y]) }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tx = []\n\t\t\t\ty = {}\n\t\t\t\tp { __local1__ = data.test.y; __local2__ = data.test.y; walk(__local1__, [__local0__, __local2__]) }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite term\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tx = \"a\"\n\t\t\t\ty = 1\n\t\t\t\tq[[2, \"b\"]]\n\t\t\t\tp { some x; q[[y,x]] }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tx = \"a\"\n\t\t\t\ty = 1\n\t\t\t\tq[[2, \"b\"]]\n\t\t\t\tp { __local1__ = data.test.y; data.test.q[[__local1__, __local0__]] }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite some x in xs\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\timport future.keywords.in\n\t\t\t\txs = [\"a\", \"b\", \"c\"]\n\t\t\t\tp { some x in xs; x == \"a\" }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\txs = [\"a\", \"b\", \"c\"]\n\t\t\t\tp { __local2__ = data.test.xs[__local1__]; __local2__ = \"a\" }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite some k, x in xs\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\timport future.keywords.in\n\t\t\t\txs = [\"a\", \"b\", \"c\"]\n\t\t\t\tp { some k, x in xs; x == \"a\"; k == 2 }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\txs = [\"a\", \"b\", \"c\"]\n\t\t\t\tp { __local1__ = data.test.xs[__local0__]; __local1__ = \"a\"; __local0__ = 2 }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite some k, x in xs[i]\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\timport future.keywords.in\n\t\t\t\txs = [[\"a\", \"b\", \"c\"], []]\n\t\t\t\tp {\n\t\t\t\t\tsome i\n\t\t\t\t\tsome k, x in xs[i]\n\t\t\t\t\tx == \"a\"\n\t\t\t\t\tk == 2\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\txs = [[\"a\", \"b\", \"c\"], []]\n\t\t\t\tp = true { __local2__ = data.test.xs[__local0__][__local1__]; __local2__ = \"a\"; __local1__ = 2 }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite some k, x in xs[i] with `i` as ref\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\timport future.keywords.in\n\t\t\t\ti = 0\n\t\t\t\txs = [[\"a\", \"b\", \"c\"], []]\n\t\t\t\tp {\n\t\t\t\t\tsome k, x in xs[i]\n\t\t\t\t\tx == \"a\"\n\t\t\t\t\tk == 2\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\ti = 0\n\t\t\t\txs = [[\"a\", \"b\", \"c\"], []]\n\t\t\t\tp = true { __local2__ = data.test.i; __local1__ = data.test.xs[__local2__][__local0__]; __local1__ = \"a\"; __local0__ = 2 }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite some: with modifier on domain\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tp {\n\t\t\t\t\tsome k, x in input with input as [1, 1, 1]\n\t\t\t\t\tk == 0\n\t\t\t\t\tx == 1\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp {\n\t\t\t\t\t__local1__ = input[__local0__] with input as [1, 1, 1]\n\t\t\t\t\t__local0__ = 0\n\t\t\t\t\t__local1__ = 1\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\ti = 0\n\t\t\t\txs = [1, 2]\n\t\t\t\tk = \"foo\"\n\t\t\t\tv = \"bar\"\n\t\t\t\tp {\n\t\t\t\t\tevery k, v in xs { k + v > i }\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\ti = 0\n\t\t\t\txs = [1, 2]\n\t\t\t\tk = \"foo\"\n\t\t\t\tv = \"bar\"\n\t\t\t\tp = true {\n\t\t\t\t\t__local2__ = data.test.xs\n\t\t\t\t\tevery __local0__, __local1__ in __local2__ {\n\t\t\t\t\t\tplus(__local0__, __local1__, __local3__)\n\t\t\t\t\t\t__local4__ = data.test.i\n\t\t\t\t\t\tgt(__local3__, __local4__)\n\t\t\t\t\t}\n\t\t\t\t}\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every: unused key var\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\tp {\n\t\t\t\t\tevery k, v in [1] { v >= 1 }\n\t\t\t\t}\n\t\t\t`,\n\t\t\twantErr: errors.New(\"declared var k unused\"),\n\t\t},\n\t\t{\n\t\t\t// NOTE(sr): this would happen when compiling modules twice:\n\t\t\t// the first run rewrites every to include a generated key var,\n\t\t\t// the second one bails because it's not used.\n\t\t\t// Seen in the wild when using `opa test -b` on a bundle that\n\t\t\t// used `every`, https://github.com/open-policy-agent/opa/issues/4420\n\t\t\tnote: \"rewrite every: unused generated key var\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\tevery __local0__, v in [1] { v >= 1 }\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp = true {\n\t\t\t\t\t__local3__ = [1]\n\t\t\t\t\tevery __local1__, __local2__ in __local3__ { __local2__ >= 1 }\n\t\t\t\t}\n\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every: unused value var\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\tp {\n\t\t\t\t\tevery v in [1] { true }\n\t\t\t\t}\n\t\t\t`,\n\t\t\twantErr: errors.New(\"declared var v unused\"),\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every: wildcard value var, used key\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\tp {\n\t\t\t\t\tevery k, _ in [1] { k >= 0 }\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp = true {\n\t\t\t\t\t__local1__ = [1]\n\t\t\t\t\tevery __local0__, _ in __local1__ { gte(__local0__, 0) }\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every: wildcard key+value var\", // NOTE(sr): may be silly, but valid\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\tp {\n\t\t\t\t\tevery _, _ in [1] { true }\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp = true { __local0__ = [1]; every _, _ in __local0__ { true } }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every: declared vars with different scopes\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\tp {\n\t\t\t\t\tsome x\n\t\t\t\t\tx = 10\n\t\t\t\t\tevery x in [1] { x == 1 }\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp = true {\n\t\t\t\t\t__local0__ = 10\n\t\t\t\t\t__local3__ = [1]\n\t\t\t\t\tevery __local1__, __local2__ in __local3__ { __local2__ = 1 }\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every: declared vars used in body\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\tp {\n\t\t\t\t\tsome y\n\t\t\t\t\ty = 10\n\t\t\t\t\tevery x in [1] { x == y }\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp = true {\n\t\t\t\t\t__local0__ = 10\n\t\t\t\t\t__local3__ = [1]\n\t\t\t\t\tevery __local1__, __local2__ in __local3__ {\n\t\t\t\t\t\t__local2__ = __local0__\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every: pops declared var stack\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\tp[x] {\n\t\t\t\t\tsome x\n\t\t\t\t\tx = 10\n\t\t\t\t\tevery _ in [1] { true }\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp[__local0__] { __local0__ = 10; __local2__ = [1]; every __local1__, _ in __local2__ { true } }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every: nested\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\tp {\n\t\t\t\t\txs := [[1], [2]]\n\t\t\t\t\tevery v in [1] {\n\t\t\t\t\t\tevery w in xs[v] {\n\t\t\t\t\t\t\tw == 2\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp = true {\n\t\t\t\t\t__local0__ = [[1], [2]]\n\t\t\t\t\t__local5__ = [1]\n\t\t\t\t\tevery __local1__, __local2__ in __local5__ {\n\t\t\t\t\t\t__local6__ = __local0__[__local2__]\n\t\t\t\t\t\tevery __local3__, __local4__ in __local6__ {\n\t\t\t\t\t\t\t__local4__ = 2\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every: with modifier on domain\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\tp {\n\t\t\t\t\tevery x in input { x == 1 } with input as [1, 1, 1]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp {\n\t\t\t\t\t__local2__ = input with input as [1, 1, 1]\n\t\t\t\t\tevery __local0__, __local1__ in __local2__ {\n\t\t\t\t\t\t__local1__ = 1\n\t\t\t\t\t} with input as [1, 1, 1]\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every: with modifier on domain with declared var\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\tp {\n\t\t\t\t\txs := [1, 2]\n\t\t\t\t\tevery x in input { x == 1 } with input as xs\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp {\n\t\t\t\t\t__local0__ = [1, 2]\n\t\t\t\t\t__local3__ = input with input as __local0__\n\t\t\t\t\tevery __local1__, __local2__ in __local3__ {\n\t\t\t\t\t\t__local2__ = 1\n\t\t\t\t\t} with input as __local0__\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every: with modifier on body\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\tp {\n\t\t\t\t\tevery x in [2] { x == input } with input as 2\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp {\n\t\t\t\t\t__local2__ = [2] with input as 2\n\t\t\t\t\tevery __local0__, __local1__ in __local2__ {\n\t\t\t\t\t\t__local1__ = input\n\t\t\t\t\t} with input as 2\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite closures\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tx = 1\n\t\t\t\ty = 2\n\t\t\t\tp {\n\t\t\t\t\tsome x, z\n\t\t\t\t\tz = 3\n\t\t\t\t\t[x | x = 2; y = 2; some z; z = 4]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tx = 1\n\t\t\t\ty = 2\n\t\t\t\tp {\n\t\t\t\t\t__local1__ = 3\n\t\t\t\t\t[__local0__ | __local0__ = 2; data.test.y = 2; __local2__ = 4]\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite head var\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tx = \"a\"\n\t\t\t\ty = 1\n\t\t\t\tz = 2\n\t\t\t\tp[x] = [y, z] {\n\t\t\t\t\tsome x, z\n\t\t\t\t\tx = \"b\"\n\t\t\t\t\tz = 4\n\t\t\t\t}`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tx = \"a\"\n\t\t\t\ty = 1\n\t\t\t\tz = 2\n\t\t\t\tp[__local0__] = __local2__ {\n\t\t\t\t\t__local0__ = \"b\"\n\t\t\t\t\t__local1__ = 4;\n\t\t\t\t\t__local3__ = data.test.y\n\t\t\t\t\t__local2__ = [__local3__, __local1__]\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite call with root document ref as arg\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\tf(input, \"bar\")\n\t\t\t\t}\n\n\t\t\t\tf(x, y) {\n\t\t\t\t\tx[y]\n\t\t\t\t}\n\t\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\n\t\t\t\tp = true {\n\t\t\t\t\t__local2__ = input;\n\t\t\t\t\tdata.test.f(__local2__, \"bar\")\n\t\t\t\t}\n\n\t\t\t\tf(__local0__, __local1__) = true {\n\t\t\t\t\t__local0__[__local1__]\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"redeclare err\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tp {\n\t\t\t\t\tsome x\n\t\t\t\t\tsome x\n\t\t\t\t}\n\t\t\t`,\n\t\t\twantErr: errors.New(\"var x declared above\"),\n\t\t},\n\t\t{\n\t\t\tnote: \"redeclare assigned err\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tp {\n\t\t\t\t\tx := 1\n\t\t\t\t\tsome x\n\t\t\t\t}\n\t\t\t`,\n\t\t\twantErr: errors.New(\"var x assigned above\"),\n\t\t},\n\t\t{\n\t\t\tnote: \"redeclare reference err\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tp {\n\t\t\t\t\tdata.q[x]\n\t\t\t\t\tsome x\n\t\t\t\t}\n\t\t\t`,\n\t\t\twantErr: errors.New(\"var x referenced above\"),\n\t\t},\n\t\t{\n\t\t\tnote: \"declare unused err\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tp {\n\t\t\t\t\tsome x\n\t\t\t\t}\n\t\t\t`,\n\t\t\twantErr: errors.New(\"declared var x unused\"),\n\t\t},\n\t\t{\n\t\t\tnote: \"declare unsafe err\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tp[x] {\n\t\t\t\t\tsome x\n\t\t\t\t\tx == 1\n\t\t\t\t}\n\t\t\t`,\n\t\t\twantErr: errors.New(\"var x is unsafe\"),\n\t\t},\n\t\t{\n\t\t\tnote: \"declare arg err\",\n\t\t\tmodule: `\n\t\t\tpackage test\n\n\t\t\tf([a]) {\n\t\t\t\tsome a\n\t\t\t\ta = 1\n\t\t\t}\n\t\t\t`,\n\t\t\twantErr: errors.New(\"arg a redeclared\"),\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\topts := CompileOpts{ParserOptions: ParserOptions{FutureKeywords: []string{\"in\", \"every\"}, unreleasedKeywords: true}}\n\t\t\tcompiler, err := CompileModulesWithOpt(map[string]string{\"test.rego\": tc.module}, opts)\n\t\t\tif tc.wantErr != nil {\n\t\t\t\tif err == nil {\n\t\t\t\t\tt.Fatal(\"Expected error but got success\")\n\t\t\t\t}\n\t\t\t\tif !strings.Contains(err.Error(), tc.wantErr.Error()) {\n\t\t\t\t\tt.Fatalf(\"Expected %v but got %v\", tc.wantErr, err)\n\t\t\t\t}\n\t\t\t} else if err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t} else {\n\t\t\t\texp := MustParseModuleWithOpts(tc.exp, opts.ParserOptions)\n\t\t\t\tresult := compiler.Modules[\"test.rego\"]\n\t\t\t\tif exp.Compare(result) != 0 {\n\t\t\t\t\tt.Fatalf(\"Expected:\\n\\n%v\\n\\nGot:\\n\\n%v\", exp, result)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompileInvalidEqAssignExpr(t *testing.T) {\n\n\tc := NewCompiler()\n\n\tc.Modules[\"error\"] = MustParseModule(`package errors\n\n\n\tp {\n\t\t# Arity mismatches are caught in the checkUndefinedFuncs check,\n\t\t# and invalid eq/assign calls are passed along until then.\n\t\tassign()\n\t\tassign(1)\n\t\teq()\n\t\teq(1)\n\t}`)\n\n\tvar prev func()\n\tcheckUndefinedFuncs := reflect.ValueOf(c.checkUndefinedFuncs)\n\n\tfor _, stage := range c.stages {\n\t\tif reflect.ValueOf(stage.f).Pointer() == checkUndefinedFuncs.Pointer() {\n\t\t\tbreak\n\t\t}\n\t\tprev = stage.f\n\t}\n\n\tcompileStages(c, prev)\n\tassertNotFailed(t, c)\n}\n\nfunc TestCompilerRewriteComprehensionTerm(t *testing.T) {\n\n\tc := NewCompiler()\n\tc.Modules[\"head\"] = MustParseModule(`package head\n\tarr = [[1], [2], [3]]\n\tarr2 = [[\"a\"], [\"b\"], [\"c\"]]\n\tarr_comp = [[x[i]] | arr[j] = x]\n\tset_comp = {[x[i]] | arr[j] = x}\n\tobj_comp = {x[i]: x[i] | arr2[j] = x}\n\t`)\n\n\tcompileStages(c, c.rewriteComprehensionTerms)\n\tassertNotFailed(t, c)\n\n\tarrCompRule := c.Modules[\"head\"].Rules[2]\n\texp1 := MustParseRule(`arr_comp = [__local0__ | data.head.arr[j] = x; __local0__ = [x[i]]] { true }`)\n\tassertRulesEqual(t, arrCompRule, exp1)\n\n\tsetCompRule := c.Modules[\"head\"].Rules[3]\n\texp2 := MustParseRule(`set_comp = {__local1__ | data.head.arr[j] = x; __local1__ = [x[i]]} { true }`)\n\tassertRulesEqual(t, setCompRule, exp2)\n\n\tobjCompRule := c.Modules[\"head\"].Rules[4]\n\texp3 := MustParseRule(`obj_comp = {__local2__: __local3__ | data.head.arr2[j] = x; __local2__ = x[i]; __local3__ = x[i]} { true }`)\n\tassertRulesEqual(t, objCompRule, exp3)\n}\n\nfunc TestCompilerRewriteDoubleEq(t *testing.T) {\n\ttests := []struct {\n\t\tnote  string\n\t\tinput string\n\t\texp   string\n\t}{\n\t\t{\n\t\t\tnote:  \"vars and constants\",\n\t\t\tinput: \"p { x = 1; x == 1; y = [1,2,3]; y == [1,2,3] }\",\n\t\t\texp:   `x = 1; x = 1; y = [1,2,3]; y = [1,2,3]`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"refs\",\n\t\t\tinput: \"p { input.x == data.y }\",\n\t\t\texp:   `input.x = data.y`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"comprehensions\",\n\t\t\tinput: \"p { [1|true] == [2|true] }\",\n\t\t\texp:   `[1|true] = [2|true]`,\n\t\t},\n\t\t// TODO(tsandall): improve support for calls so that extra unification step is\n\t\t// not required. This requires more changes to the compiler as the initial\n\t\t// stages that rewrite term exprs needs to be updated to handle == differently\n\t\t// and then other stages need to be reviewed to make sure they can deal with\n\t\t// nested calls. Alternatively, the compiler could keep track of == exprs that\n\t\t// have been converted into = and then the safety check would need to be updated.\n\t\t{\n\t\t\tnote:  \"calls\",\n\t\t\tinput: \"p { count([1,2]) == 2 }\",\n\t\t\texp:   `count([1,2], __local0__); __local0__ = 2`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"embedded\",\n\t\t\tinput: \"p { x = 1; y = [x == 0] }\",\n\t\t\texp:   `x = 1; equal(x, 0, __local0__); y = [__local0__]`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"embedded in call\",\n\t\t\tinput: `p { x = 0; neq(true, x == 1) }`,\n\t\t\texp:   `x = 0; equal(x, 1, __local0__); neq(true, __local0__)`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"comprehension in object key\",\n\t\t\tinput: `p { {{1 | 0 == 0}: 2} }`,\n\t\t\texp:   `{{1 | 0 = 0}: 2}`,\n\t\t},\n\t}\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tc := NewCompiler()\n\t\t\tc.Modules[\"test\"] = MustParseModule(\"package test\\n\" + tc.input)\n\t\t\tcompileStages(c, c.rewriteEquals)\n\t\t\tassertNotFailed(t, c)\n\t\t\texp := MustParseBody(tc.exp)\n\t\t\tresult := c.Modules[\"test\"].Rules[0].Body\n\t\t\tif result.Compare(exp) != 0 {\n\t\t\t\tt.Fatalf(\"\\nExp: %v\\nGot: %v\", exp, result)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerRewriteDynamicTerms(t *testing.T) {\n\n\tfixture := `\n\t\tpackage test\n\t\tstr = \"hello\"\n\t`\n\n\ttests := []struct {\n\t\tinput    string\n\t\texpected string\n\t}{\n\t\t{`arr { [str] }`, `__local0__ = data.test.str; [__local0__]`},\n\t\t{`arr2 { [[str]] }`, `__local0__ = data.test.str; [[__local0__]]`},\n\t\t{`obj { {\"x\": str} }`, `__local0__ = data.test.str; {\"x\": __local0__}`},\n\t\t{`obj2 { {\"x\": {\"y\": str}} }`, `__local0__ = data.test.str; {\"x\": {\"y\": __local0__}}`},\n\t\t{`set { {str} }`, `__local0__ = data.test.str; {__local0__}`},\n\t\t{`set2 { {{str}} }`, `__local0__ = data.test.str; {{__local0__}}`},\n\t\t{`ref { str[str] }`, `__local0__ = data.test.str; data.test.str[__local0__]`},\n\t\t{`ref2 { str[str[str]] }`, `__local0__ = data.test.str; __local1__ = data.test.str[__local0__]; data.test.str[__local1__]`},\n\t\t{`arr_compr { [1 | [str]] }`, `[1 | __local0__ = data.test.str; [__local0__]]`},\n\t\t{`arr_compr2 { [1 | [1 | [str]]] }`, `[1 | [1 | __local0__ = data.test.str; [__local0__]]]`},\n\t\t{`set_compr { {1 | [str]} }`, `{1 | __local0__ = data.test.str; [__local0__]}`},\n\t\t{`set_compr2 { {1 | {1 | [str]}} }`, `{1 | {1 | __local0__ = data.test.str; [__local0__]}}`},\n\t\t{`obj_compr { {\"a\": \"b\" | [str]} }`, `{\"a\": \"b\" | __local0__ = data.test.str; [__local0__]}`},\n\t\t{`obj_compr2 { {\"a\": \"b\" | {\"a\": \"b\" | [str]}} }`, `{\"a\": \"b\" | {\"a\": \"b\" | __local0__ = data.test.str; [__local0__]}}`},\n\t\t{`equality { str = str }`, `data.test.str = data.test.str`},\n\t\t{`equality2 { [str] = [str] }`, `__local0__ = data.test.str; __local1__ = data.test.str; [__local0__] = [__local1__]`},\n\t\t{`call { startswith(str, \"\") }`, `__local0__ = data.test.str; startswith(__local0__, \"\")`},\n\t\t{`call2 { count([str], n) }`, `__local0__ = data.test.str; count([__local0__], n)`},\n\t\t{`eq_with { [str] = [1] with input as 1 }`, `__local0__ = data.test.str with input as 1; [__local0__] = [1] with input as 1`},\n\t\t{`term_with { [[str]] with input as 1 }`, `__local0__ = data.test.str with input as 1; [[__local0__]] with input as 1`},\n\t\t{`call_with { count(str) with input as 1 }`, `__local0__ = data.test.str with input as 1; count(__local0__) with input as 1`},\n\t\t{`call_func { f(input, \"foo\") } f(x,y) { x[y] }`, `__local2__ = input; data.test.f(__local2__, \"foo\")`},\n\t\t{`call_func2 { f(input.foo, \"foo\") } f(x,y) { x[y] }`, `__local2__ = input.foo; data.test.f(__local2__, \"foo\")`},\n\t\t{`every_domain { every _ in str { true } }`, `__local1__ = data.test.str; every __local0__, _ in __local1__ { true }`},\n\t\t{`every_domain_call { every _ in numbers.range(1, 10) { true } }`, `numbers.range(1, 10, __local1__); every __local0__, _ in __local1__ { true }`},\n\t\t{`every_body { every _ in [] { [str] } }`,\n\t\t\t`__local1__ = []; every __local0__, _ in __local1__ { __local2__ = data.test.str; [__local2__] }`},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.input, func(t *testing.T) {\n\t\t\tc := NewCompiler()\n\t\t\topts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\t\t\tmodule := fixture + tc.input\n\t\t\tc.Modules[\"test\"] = MustParseModuleWithOpts(module, opts)\n\t\t\tcompileStages(c, c.rewriteDynamicTerms)\n\t\t\tassertNotFailed(t, c)\n\t\t\texpected := MustParseBodyWithOpts(tc.expected, opts)\n\t\t\tresult := c.Modules[\"test\"].Rules[1].Body\n\t\t\tif result.Compare(expected) != 0 {\n\t\t\t\tt.Fatalf(\"\\nExp: %v\\nGot: %v\", expected, result)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerRewriteWithValue(t *testing.T) {\n\tfixture := `package test\n\n\tarr = [\"hello\", \"goodbye\"]\n\n\t`\n\n\ttests := []struct {\n\t\tnote         string\n\t\tinput        string\n\t\texpected     string\n\t\texpectedRule *Rule\n\t\twantErr      error\n\t}{\n\t\t{\n\t\t\tnote:     \"nop\",\n\t\t\tinput:    `p { true with input as 1 }`,\n\t\t\texpected: `p { true with input as 1 }`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"refs\",\n\t\t\tinput:    `p { true with input as arr }`,\n\t\t\texpected: `p { __local0__ = data.test.arr; true with input as __local0__ }`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"array comprehension\",\n\t\t\tinput:    `p { true with input as [true | true] }`,\n\t\t\texpected: `p { __local0__ = [true | true]; true with input as __local0__ }`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"set comprehension\",\n\t\t\tinput:    `p { true with input as {true | true} }`,\n\t\t\texpected: `p { __local0__ = {true | true}; true with input as __local0__ }`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"object comprehension\",\n\t\t\tinput:    `p { true with input as {\"k\": true | true} }`,\n\t\t\texpected: `p { __local0__ = {\"k\": true | true}; true with input as __local0__ }`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"comprehension nested\",\n\t\t\tinput:    `p { true with input as [true | true with input as arr] }`,\n\t\t\texpected: `p { __local0__ = [true | __local1__ = data.test.arr; true with input as __local1__]; true with input as __local0__ }`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"multiple\",\n\t\t\tinput:    `p { true with input.a as arr[0] with input.b as arr[1] }`,\n\t\t\texpected: `p { __local0__ = data.test.arr[0]; __local1__ = data.test.arr[1]; true with input.a as __local0__ with input.b as __local1__ }`,\n\t\t},\n\t\t{\n\t\t\tnote:    \"invalid target\",\n\t\t\tinput:   `p { true with foo.q as 1 }`,\n\t\t\twantErr: fmt.Errorf(\"rego_type_error: with keyword target must reference existing input, data, or a function\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"built-in function: replaced by (unknown) var\",\n\t\t\tinput:    `p { true with time.now_ns as foo }`,\n\t\t\texpected: `p { true with time.now_ns as foo }`, // `foo` still a Var here\n\t\t},\n\t\t{\n\t\t\tnote: \"built-in function: valid, arity 0\",\n\t\t\tinput: `\n\t\t\t\tp { true with time.now_ns as now }\n\t\t\t\tnow() = 1\n\t\t\t`,\n\t\t\texpected: `p { true with time.now_ns as data.test.now }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"built-in function: valid func ref, arity 1\",\n\t\t\tinput: `\n\t\t\t\tp { true with http.send as mock_http_send }\n\t\t\t\tmock_http_send(_) = { \"body\": \"yay\" }\n\t\t\t`,\n\t\t\texpected: `p { true with http.send as data.test.mock_http_send }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"built-in function: replaced by value\",\n\t\t\tinput: `\n\t\t\t\tp { true with http.send as { \"body\": \"yay\" } }\n\t\t\t`,\n\t\t\texpected: `p { true with http.send as {\"body\": \"yay\"} }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"built-in function: replaced by comprehension\",\n\t\t\tinput: `\n\t\t\t\tp { true with http.send as { x: true | x := [\"a\", \"b\"][_] } }\n\t\t\t`,\n\t\t\texpected: `p { __local2__ = {__local0__: true | __local1__ = [\"a\", \"b\"]; __local0__ = __local1__[_]}; true with http.send as __local2__ }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"built-in function: replaced by ref\",\n\t\t\tinput: `\n\t\t\t\tp { true with http.send as resp }\n\t\t\t\tresp := { \"body\": \"yay\" }\n\t\t\t`,\n\t\t\texpected: `p { true with http.send as data.test.resp }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"built-in function: replaced by another built-in (ref)\",\n\t\t\tinput: `\n\t\t\t\tp { true with http.send as object.union_n }\n\t\t\t`,\n\t\t\texpected: `p { true with http.send as object.union_n }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"built-in function: replaced by another built-in (simple)\",\n\t\t\tinput: `\n\t\t\t\tp { true with http.send as count }\n\t\t\t`,\n\t\t\texpectedRule: func() *Rule {\n\t\t\t\tr := MustParseRule(`p { true with http.send as count }`)\n\t\t\t\tr.Body[0].With[0].Value.Value = Ref([]*Term{VarTerm(\"count\")})\n\t\t\t\treturn r\n\t\t\t}(),\n\t\t},\n\t\t{\n\t\t\tnote: \"built-in function: valid, arity 1, non-compound name\",\n\t\t\tinput: `\n\t\t\t\tp { concat(\"/\", input) with concat as mock_concat }\n\t\t\t\tmock_concat(_, _) = \"foo/bar\"\n\t\t\t`,\n\t\t\texpectedRule: func() *Rule {\n\t\t\t\tr := MustParseRule(`p { concat(\"/\", input) with concat as data.test.mock_concat }`)\n\t\t\t\tr.Body[0].With[0].Target.Value = Ref([]*Term{VarTerm(\"concat\")})\n\t\t\t\treturn r\n\t\t\t}(),\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tc := NewCompiler()\n\t\t\tmodule := fixture + tc.input\n\t\t\tc.Modules[\"test\"] = MustParseModule(module)\n\t\t\tcompileStages(c, c.rewriteWithModifiers)\n\t\t\tif tc.wantErr == nil {\n\t\t\t\tassertNotFailed(t, c)\n\t\t\t\texpected := tc.expectedRule\n\t\t\t\tif expected == nil {\n\t\t\t\t\texpected = MustParseRule(tc.expected)\n\t\t\t\t}\n\t\t\t\tresult := c.Modules[\"test\"].Rules[1]\n\t\t\t\tif result.Compare(expected) != 0 {\n\t\t\t\t\tt.Fatalf(\"\\nExp: %v\\nGot: %v\", expected, result)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tassertCompilerErrorStrings(t, c, []string{tc.wantErr.Error()})\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerRewritePrintCallsErasure(t *testing.T) {\n\n\tcases := []struct {\n\t\tnote   string\n\t\tmodule string\n\t\texp    string\n\t}{\n\t\t{\n\t\t\tnote: \"no-op\",\n\t\t\tmodule: `package test\n\t\t\tp { true }`,\n\t\t\texp: `package test\n\t\t\tp { true }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"replace empty body with true\",\n\t\t\tmodule: `package test\n\n\t\t\tp { print(1) }\n\t\t\t`,\n\t\t\texp: `package test\n\n\t\t\tp { true } `,\n\t\t},\n\t\t{\n\t\t\tnote: \"rule body\",\n\t\t\tmodule: `package test\n\n\t\t\tp { false; print(1) }\n\t\t\t`,\n\t\t\texp: `package test\n\n\t\t\tp { false } `,\n\t\t},\n\t\t{\n\t\t\tnote: \"set comprehension body\",\n\t\t\tmodule: `package test\n\n\t\t\tp { {1 | false; print(1)} }\n\t\t\t`,\n\t\t\texp: `package test\n\n\t\t\tp { {1 | false} } `,\n\t\t},\n\t\t{\n\t\t\tnote: \"array comprehension body\",\n\t\t\tmodule: `package test\n\n\t\t\tp { [1 | false; print(1)] }\n\t\t\t`,\n\t\t\texp: `package test\n\n\t\t\tp { [1 | false] } `,\n\t\t},\n\t\t{\n\t\t\tnote: \"object comprehension body\",\n\t\t\tmodule: `package test\n\n\t\t\tp { {\"x\": 1 | false; print(1)} }\n\t\t\t`,\n\t\t\texp: `package test\n\n\t\t\tp { {\"x\": 1 | false} } `,\n\t\t},\n\t\t{\n\t\t\tnote: \"every body\",\n\t\t\tmodule: `package test\n\n\t\t\tp { every _ in [] { false; print(1) } }\n\t\t\t`,\n\t\t\texp: `package test\n\n\t\t\tp = true { __local1__ = []; every __local0__, _ in __local1__ { false } }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"in head\",\n\t\t\tmodule: `package test\n\n\t\t\tp = {1 | print(\"x\")}`,\n\t\t\texp: `package test\n\n\t\t\tp = __local0__ { true; __local0__ = {1 | true} }`,\n\t\t},\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tc := NewCompiler().WithEnablePrintStatements(false)\n\t\t\topts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\t\t\tc.Compile(map[string]*Module{\n\t\t\t\t\"test.rego\": MustParseModuleWithOpts(tc.module, opts),\n\t\t\t})\n\t\t\tif c.Failed() {\n\t\t\t\tt.Fatal(c.Errors)\n\t\t\t}\n\t\t\texp := MustParseModuleWithOpts(tc.exp, opts)\n\t\t\tif !exp.Equal(c.Modules[\"test.rego\"]) {\n\t\t\t\tt.Fatalf(\"Expected:\\n\\n%v\\n\\nGot:\\n\\n%v\", exp, c.Modules[\"test.rego\"])\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerRewritePrintCallsErrors(t *testing.T) {\n\tcases := []struct {\n\t\tnote   string\n\t\tmodule string\n\t\texp    error\n\t}{\n\t\t{\n\t\t\tnote: \"non-existent var\",\n\t\t\tmodule: `package test\n\n\t\t\tp { print(x) }`,\n\t\t\texp: errors.New(\"var x is undeclared\"),\n\t\t},\n\t\t{\n\t\t\tnote: \"declared after print\",\n\t\t\tmodule: `package test\n\n\t\t\tp { print(x); x = 7 }`,\n\t\t\texp: errors.New(\"var x is undeclared\"),\n\t\t},\n\t\t{\n\t\t\tnote: \"inside comprehension\",\n\t\t\tmodule: `package test\n\t\t\tp { {1 | print(x)} }\n\t\t\t`,\n\t\t\texp: errors.New(\"var x is undeclared\"),\n\t\t},\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tc := NewCompiler().WithEnablePrintStatements(true)\n\t\t\tc.Compile(map[string]*Module{\n\t\t\t\t\"test.rego\": MustParseModule(tc.module),\n\t\t\t})\n\t\t\tif !c.Failed() {\n\t\t\t\tt.Fatal(\"expected error\")\n\t\t\t}\n\t\t\tif c.Errors[0].Code != CompileErr || c.Errors[0].Message != tc.exp.Error() {\n\t\t\t\tt.Fatal(\"unexpected error:\", c.Errors)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerRewritePrintCalls(t *testing.T) {\n\tcases := []struct {\n\t\tnote   string\n\t\tmodule string\n\t\texp    string\n\t}{\n\t\t{\n\t\t\tnote: \"print one\",\n\t\t\tmodule: `package test\n\n\t\t\tp { print(1) }`,\n\t\t\texp: `package test\n\n\t\t\tp = true { __local1__ = {__local0__ | __local0__ = 1}; internal.print([__local1__]) }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print multiple\",\n\t\t\tmodule: `package test\n\n\t\t\tp { print(1, 2) }`,\n\t\t\texp: `package test\n\n\t\t\tp = true { __local2__ = {__local0__ | __local0__ = 1}; __local3__ = {__local1__ | __local1__ = 2}; internal.print([__local2__, __local3__]) }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print inside set comprehension\",\n\t\t\tmodule: `package test\n\n\t\t\tp { x = 1; {2 | print(x)} }`,\n\t\t\texp: `package test\n\n\t\t\tp = true { x = 1; {2 | __local1__ = {__local0__ | __local0__ = x}; internal.print([__local1__])} }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print inside array comprehension\",\n\t\t\tmodule: `package test\n\n\t\t\tp { x = 1; [2 | print(x)] }`,\n\t\t\texp: `package test\n\n\t\t\tp = true { x = 1; [2 | __local1__ = {__local0__ | __local0__ = x}; internal.print([__local1__])] }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print inside object comprehension\",\n\t\t\tmodule: `package test\n\n\t\t\tp { x = 1; {\"x\": 2 | print(x)} }`,\n\t\t\texp: `package test\n\n\t\t\tp = true { x = 1; {\"x\": 2 | __local1__ = {__local0__ | __local0__ = x}; internal.print([__local1__])} }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print inside every\",\n\t\t\tmodule: `package test\n\n\t\t\tp { every x in [1,2] { print(x) } }`,\n\t\t\texp: `package test\n\n\t\t\tp = true {\n\t\t\t\t__local3__ = [1, 2]\n\t\t\t\tevery __local0__, __local1__ in __local3__ {\n\t\t\t\t\t__local4__ = {__local2__ | __local2__ = __local1__}\n\t\t\t\t\tinternal.print([__local4__])\n\t\t\t\t}\n\t\t\t}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print output of nested call\",\n\t\t\tmodule: `package test\n\n\t\t\tp {\n\t\t\t\tx := split(\"abc\", \"\")[y]\n\t\t\t\tprint(x, y)\n\t\t\t}`,\n\t\t\texp: `package test\n\n\t\t\tp = true { split(\"abc\", \"\", __local3__); __local0__ = __local3__[y]; __local4__ = {__local1__ | __local1__ = __local0__}; __local5__ = {__local2__ | __local2__ = y}; internal.print([__local4__, __local5__]) }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print call in head\",\n\t\t\tmodule: `package test\n\n\t\t\tp = {1 | print(\"x\") }`,\n\t\t\texp: `package test\n\n\t\t\tp = __local1__ {\n\t\t\t\ttrue\n\t\t\t\t__local1__ = {1 | __local2__ = { __local0__ | __local0__ = \"x\"}; internal.print([__local2__])}\n\t\t\t}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print call in head - args treated as safe\",\n\t\t\tmodule: `package test\n\n\t\t\tf(a) = {1 | a[x]; print(x)}`,\n\t\t\texp: `package test\n\n\t\t\tf(__local0__) = __local2__ { true; __local2__ = {1 | __local0__[x]; __local3__ = {__local1__ | __local1__ = x}; internal.print([__local3__])} }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print call of var in head key\",\n\t\t\tmodule: `package test\n\t\t\tf(_) = [1, 2, 3]\n\t\t\tp[x] { [_, x, _] := f(true); print(x) }`,\n\t\t\texp: `package test\n\t\t\tf(__local0__) = [1, 2, 3] { true }\n\t\t\tp[__local2__] { data.test.f(true, __local5__); [__local1__, __local2__, __local3__] = __local5__; __local6__ = {__local4__ | __local4__ = __local2__}; internal.print([__local6__]) }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print call of var in head value\",\n\t\t\tmodule: `package test\n\t\t\tf(_) = [1, 2, 3]\n\t\t\tp = x { [_, x, _] := f(true); print(x) }`,\n\t\t\texp: `package test\n\t\t\tf(__local0__) = [1, 2, 3] { true }\n\t\t\tp = __local2__ { data.test.f(true, __local5__); [__local1__, __local2__, __local3__] = __local5__; __local6__ = {__local4__ | __local4__ = __local2__}; internal.print([__local6__]) }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print call of vars in head key and value\",\n\t\t\tmodule: `package test\n\t\t\tf(_) = [1, 2, 3]\n\t\t\tp[x] = y { [_, x, y] := f(true); print(x) }`,\n\t\t\texp: `package test\n\t\t\tf(__local0__) = [1, 2, 3] { true }\n\t\t\tp[__local2__] = __local3__ { data.test.f(true, __local5__); [__local1__, __local2__, __local3__] = __local5__; __local6__ = {__local4__ | __local4__ = __local2__}; internal.print([__local6__]) }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print call of vars altered with 'with' and call\",\n\t\t\tmodule: `package test\n\t\t\tq = input\n\t\t\tp {\n\t\t\t\tx := q with input as json.unmarshal(\"{}\")\n\t\t\t\tprint(x)\n\t\t\t}`,\n\t\t\texp: `package test\n\t\t\tq = __local3__ { true; __local3__ = input }\n\t\t\tp = true {\n\t\t\t\tjson.unmarshal(\"{}\", __local2__)\n\t\t\t\t__local0__ = data.test.q with input as __local2__\n\t\t\t\t__local4__ = {__local1__ | __local1__ = __local0__}\n\t\t\t\tinternal.print([__local4__])\n\t\t\t}`,\n\t\t},\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tc := NewCompiler().WithEnablePrintStatements(true)\n\t\t\topts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\t\t\tc.Compile(map[string]*Module{\n\t\t\t\t\"test.rego\": MustParseModuleWithOpts(tc.module, opts),\n\t\t\t})\n\t\t\tif c.Failed() {\n\t\t\t\tt.Fatal(c.Errors)\n\t\t\t}\n\t\t\texp := MustParseModuleWithOpts(tc.exp, opts)\n\t\t\tif !exp.Equal(c.Modules[\"test.rego\"]) {\n\t\t\t\tt.Fatalf(\"Expected:\\n\\n%v\\n\\nGot:\\n\\n%v\", exp, c.Modules[\"test.rego\"])\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestRewritePrintCallsWithElseImplicitArgs(t *testing.T) {\n\n\tmodule := `package test\n\n\tf(x, y) {\n\t\tx = y\n\t}\n\n\telse = false {\n\t\tprint(x, y)\n\t}`\n\n\tc := NewCompiler().WithEnablePrintStatements(true)\n\topts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\tc.Compile(map[string]*Module{\n\t\t\"test.rego\": MustParseModuleWithOpts(module, opts),\n\t})\n\n\tif c.Failed() {\n\t\tt.Fatal(c.Errors)\n\t}\n\n\texp := MustParseModuleWithOpts(`package test\n\n\tf(__local0__, __local1__) = true { __local0__ = __local1__ }\n\telse = false { __local6__ = {__local4__ | __local4__ = __local2__}; __local7__ = {__local5__ | __local5__ = __local3__}; internal.print([__local6__, __local7__]) }\n\t`, opts)\n\n\t// NOTE(tsandall): we have to patch the implicit args on the else rule\n\t// because of how the parser copies the arg names across from the first\n\t// rule.\n\texp.Rules[0].Else.Head.Args[0] = VarTerm(\"__local2__\")\n\texp.Rules[0].Else.Head.Args[1] = VarTerm(\"__local3__\")\n\n\tif !exp.Equal(c.Modules[\"test.rego\"]) {\n\t\tt.Fatalf(\"Expected:\\n\\n%v\\n\\nGot:\\n\\n%v\", exp, c.Modules[\"test.rego\"])\n\t}\n}\n\nfunc TestCompilerMockFunction(t *testing.T) {\n\ttests := []struct {\n\t\tnote          string\n\t\tmodule, extra string\n\t\terr           string\n\t}{\n\t\t{\n\t\t\tnote: \"simple valid\",\n\t\t\tmodule: `package test\n\t\t\t\tnow() = 123\n\t\t\t\tp { true with time.now_ns as now }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"simple valid, simple name\",\n\t\t\tmodule: `package test\n\t\t\t\tmock_concat(_, _) = \"foo/bar\"\n\t\t\t\tp { concat(\"/\", input) with concat as mock_concat }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"invalid ref: nonexistant\",\n\t\t\tmodule: `package test\n\t\t\t\tp { true with time.now_ns as now }\n\t\t\t`,\n\t\t\terr: \"rego_unsafe_var_error: var now is unsafe\", // we're running all compiler stages here\n\t\t},\n\t\t{\n\t\t\tnote: \"valid ref: not a function, but arity = 0\",\n\t\t\tmodule: `package test\n\t\t\t\tnow = 1\n\t\t\t\tp { true with time.now_ns as now }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"ref: not a function, arity > 0\",\n\t\t\tmodule: `package test\n\t\t\t\thttp_send = { \"body\": \"nope\" }\n\t\t\t\tp { true with http.send as http_send }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"invalid ref: arity mismatch\",\n\t\t\tmodule: `package test\n\t\t\t\thttp_send(_, _) = { \"body\": \"nope\" }\n\t\t\t\tp { true with http.send as http_send }\n\t\t\t`,\n\t\t\terr: \"rego_type_error: http.send: arity mismatch\\n\\thave: (any, any)\\n\\twant: (request: object[string: any])\",\n\t\t},\n\t\t{\n\t\t\tnote: \"invalid ref: arity mismatch (in call)\",\n\t\t\tmodule: `package test\n\t\t\t\thttp_send(_, _) = { \"body\": \"nope\" }\n\t\t\t\tp { http.send({}) with http.send as http_send }\n\t\t\t`,\n\t\t\terr: \"rego_type_error: http.send: arity mismatch\\n\\thave: (any, any)\\n\\twant: (request: object[string: any])\",\n\t\t},\n\t\t{\n\t\t\tnote: \"invalid ref: value another built-in with different type\",\n\t\t\tmodule: `package test\n\t\t\t\tp { true with http.send as net.lookup_ip_addr }\n\t\t\t`,\n\t\t\terr: \"rego_type_error: http.send: arity mismatch\\n\\thave: (string)\\n\\twant: (request: object[string: any])\",\n\t\t},\n\t\t{\n\t\t\tnote: \"ref: value another built-in with compatible type\",\n\t\t\tmodule: `package test\n\t\t\t\tp { true with count as object.union_n }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"valid: package import\",\n\t\t\textra: `package mocks\n\t\t\t\thttp_send(_) = {}\n\t\t\t`,\n\t\t\tmodule: `package test\n\t\t\t\timport data.mocks\n\t\t\t\tp { true with http.send as mocks.http_send }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"valid: function import\",\n\t\t\textra: `package mocks\n\t\t\t\thttp_send(_) = {}\n\t\t\t`,\n\t\t\tmodule: `package test\n\t\t\t\timport data.mocks.http_send\n\t\t\t\tp { true with http.send as http_send }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"invalid target: relation\",\n\t\t\tmodule: `package test\n\t\t\t\tmy_walk(_, _)\n\t\t\t\tp { true with walk as my_walk }\n\t\t\t`,\n\t\t\terr: \"rego_compile_error: with keyword replacing built-in function: target must not be a relation\",\n\t\t},\n\t\t{\n\t\t\tnote: \"invalid target: eq\",\n\t\t\tmodule: `package test\n\t\t\t\tmy_eq(_, _)\n\t\t\t\tp { true with eq as my_eq }\n\t\t\t`,\n\t\t\terr: `rego_compile_error: with keyword replacing built-in function: replacement of \"eq\" invalid`,\n\t\t},\n\t\t{\n\t\t\tnote: \"invalid target: rego.metadata.chain\",\n\t\t\tmodule: `package test\n\t\t\t\tp { true with rego.metadata.chain as [] }\n\t\t\t`,\n\t\t\terr: `rego_compile_error: with keyword replacing built-in function: replacement of \"rego.metadata.chain\" invalid`,\n\t\t},\n\t\t{\n\t\t\tnote: \"invalid target: rego.metadata.rule\",\n\t\t\tmodule: `package test\n\t\t\t\tp { true with rego.metadata.rule as {} }\n\t\t\t`,\n\t\t\terr: `rego_compile_error: with keyword replacing built-in function: replacement of \"rego.metadata.rule\" invalid`,\n\t\t},\n\t\t{\n\t\t\tnote: \"invalid target: internal.print\",\n\t\t\tmodule: `package test\n\t\t\t\tmy_print(_, _)\n\t\t\t\tp { true with internal.print as my_print }\n\t\t\t`,\n\t\t\terr: `rego_compile_error: with keyword replacing built-in function: replacement of internal function \"internal.print\" invalid`,\n\t\t},\n\t\t{\n\t\t\tnote: \"mocking custom built-in\",\n\t\t\tmodule: `package test\n\t\t\t\tmock(_)\n\t\t\t\tmock_mock(_)\n\t\t\t\tp { bar(foo.bar(\"one\")) with bar as mock with foo.bar as mock_mock }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"non-built-in function replaced value\",\n\t\t\tmodule: `package test\n\t\t\t\toriginal(_)\n\t\t\t\tp { original(true) with original as 123 }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"non-built-in function replaced by another, arity 0\",\n\t\t\tmodule: `package test\n\t\t\t\toriginal() = 1\n\t\t\t\tmock() = 2\n\t\t\t\tp { original() with original as mock }\n\t\t\t`,\n\t\t\terr: \"rego_type_error: undefined function data.test.original\", // TODO(sr): file bug -- this doesn't depend on \"with\" used or not\n\t\t},\n\t\t{\n\t\t\tnote: \"non-built-in function replaced by another, arity 1\",\n\t\t\tmodule: `package test\n\t\t\t\toriginal(_)\n\t\t\t\tmock(_)\n\t\t\t\tp { original(true) with original as mock }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"non-built-in function replaced by built-in\",\n\t\t\tmodule: `package test\n\t\t\t\toriginal(_)\n\t\t\t\tp { original([1]) with original as count }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"non-built-in function replaced by another, arity mismatch\",\n\t\t\tmodule: `package test\n\t\t\t\toriginal(_)\n\t\t\t\tmock(_, _)\n\t\t\t\tp { original([1]) with original as mock }\n\t\t\t`,\n\t\t\terr: \"rego_type_error: data.test.original: arity mismatch\\n\\thave: (any, any)\\n\\twant: (any)\",\n\t\t},\n\t\t{\n\t\t\tnote: \"non-built-in function replaced by built-in, arity mismatch\",\n\t\t\tmodule: `package test\n\t\t\t\toriginal(_)\n\t\t\t\tp { original([1]) with original as concat }\n\t\t\t`,\n\t\t\terr: \"rego_type_error: data.test.original: arity mismatch\\n\\thave: (string, any<array[string], set[string]>)\\n\\twant: (any)\",\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tc := NewCompiler().WithBuiltins(map[string]*Builtin{\n\t\t\t\t\"bar\": {\n\t\t\t\t\tName: \"bar\",\n\t\t\t\t\tDecl: types.NewFunction([]types.Type{types.S}, types.A),\n\t\t\t\t},\n\t\t\t\t\"foo.bar\": {\n\t\t\t\t\tName: \"foo.bar\",\n\t\t\t\t\tDecl: types.NewFunction([]types.Type{types.S}, types.A),\n\t\t\t\t},\n\t\t\t})\n\t\t\tif tc.extra != \"\" {\n\t\t\t\tc.Modules[\"extra\"] = MustParseModule(tc.extra)\n\t\t\t}\n\t\t\tc.Modules[\"test\"] = MustParseModule(tc.module)\n\n\t\t\t// NOTE(sr): We're running all compiler stages here, since the type checking of\n\t\t\t// built-in function replacements happens at the type check stage.\n\t\t\tc.Compile(c.Modules)\n\n\t\t\tif tc.err != \"\" {\n\t\t\t\tif !strings.Contains(c.Errors.Error(), tc.err) {\n\t\t\t\t\tt.Errorf(\"expected error to contain %q, got %q\", tc.err, c.Errors.Error())\n\t\t\t\t}\n\t\t\t} else if len(c.Errors) > 0 {\n\t\t\t\tt.Errorf(\"expected no errors, got %v\", c.Errors)\n\t\t\t}\n\t\t})\n\t}\n\n}\n\nfunc TestCompilerMockVirtualDocumentPartially(t *testing.T) {\n\tc := NewCompiler()\n\n\tc.Modules[\"test\"] = MustParseModule(`\n\tpackage test\n\tp = {\"a\": 1}\n\tq = x { p = x with p.a as 2 }\n\t`)\n\n\tcompileStages(c, c.rewriteWithModifiers)\n\tassertCompilerErrorStrings(t, c, []string{\"rego_compile_error: with keyword cannot partially replace virtual document(s)\"})\n}\n\nfunc TestCompilerCheckUnusedAssignedVar(t *testing.T) {\n\ttype testCase struct {\n\t\tnote           string\n\t\tmodule         string\n\t\texpectedErrors Errors\n\t}\n\n\tcases := []testCase{\n\t\t{\n\t\t\tnote: \"global var\",\n\t\t\tmodule: `package test\n\t\t\t\tx := 1\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"simple rule with wildcard\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\t_ := 1\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"simple rule\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tx := 1\n\t\t\t\t\ty := 2\n\t\t\t\t\tz := x + 3\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t\t&Error{Message: \"assigned var z unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with return\",\n\t\t\tmodule: `package test\n\t\t\t\tp = x {\n\t\t\t\t\tx := 2\n\t\t\t\t\ty := 3\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with function call\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tx := 2\n\t\t\t\t\ty := f(x)\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with nested array comprehension\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tx := 2\n\t\t\t\t\ty := [z | z := 2 * x]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with nested array comprehension and shadowing\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tx := 2\n\t\t\t\t\ty := [x | x := 2 * x]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with nested array comprehension and shadowing (unused shadowed var)\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tx := 2\n\t\t\t\t\ty := [x | x := 2]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var x unused\"},\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with nested array comprehension and shadowing (unused shadowing var)\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tx := 2\n\t\t\t\t\tx > 1\n\t\t\t\t\t[1 | x := 2]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var x unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with nested array comprehension and some declaration\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tsome i\n\t\t\t\t\t_ := [z | z := [1, 2][i]]\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with nested set comprehension\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tx := 2\n\t\t\t\t\ty := {z | z := 2 * x}\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with nested set comprehension and unused inner var\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tx := 2\n\t\t\t\t\ty := {z | z := 2 * x; a := 2}\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var a unused\"}, // y isn't reported, as we abort early on errors when moving through the stack\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with nested object comprehension\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tx := 2\n\t\t\t\t\ty := {z: x | z := 2 * x}\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with nested closure\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tx := 1\n\t\t\t\t\ta := 1\n\t\t\t\t\t{ y | y := [ z | z:=[1,2,3][a]; z > 1 ][_] }\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var x unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with nested closure and unused inner var\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tx := 1\n\t\t\t\t\t{ y | y := [ z | z:=[1,2,3][x]; z > 1; a := 2 ][_] }\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var a unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"simple function\",\n\t\t\tmodule: `package test\n\t\t\t\tf() {\n\t\t\t\t\tx := 1\n\t\t\t\t\ty := 2\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var x unused\"},\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"simple function with wildcard\",\n\t\t\tmodule: `package test\n\t\t\t\tf() {\n\t\t\t\t\tx := 1\n\t\t\t\t\t_ := 2\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var x unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"function with return\",\n\t\t\tmodule: `package test\n\t\t\t\tf() = x {\n\t\t\t\t\tx := 1\n\t\t\t\t\ty := 2\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"array comprehension\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = [ 1 |\n\t\t\t\t\tx := [1, 2, 3]\n\t\t\t\t\ty := 2\n\t\t\t\t\tz := x[_]\n\t\t\t\t]\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t\t&Error{Message: \"assigned var z unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"array comprehension nested\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp := [ 1 |\n\t\t\t\t\tx := 1\n\t\t\t\t\ty := [a | a := x]\n\t\t\t\t]\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"array comprehension with wildcard\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = [ 1 |\n\t\t\t\t\tx := [1, 2, 3]\n\t\t\t\t\t_ := 2\n\t\t\t\t\tz := x[_]\n\t\t\t\t]\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var z unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"array comprehension with return\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = [ z |\n\t\t\t\t\tx := [1, 2, 3]\n\t\t\t\t\ty := 2\n\t\t\t\t\tz := x[_]\n\t\t\t\t]\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"array comprehension with some\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = [ i |\n\t\t\t\t\tsome i\n\t\t\t\t\ty := 2\n\t\t\t\t]\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"set comprehension\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = { 1 |\n\t\t\t\t\tx := [1, 2, 3]\n\t\t\t\t\ty := 2\n\t\t\t\t\tz := x[_]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t\t&Error{Message: \"assigned var z unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"set comprehension nested\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp := { 1 |\n\t\t\t\t\tx := 1\n\t\t\t\t\ty := [a | a := x]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"set comprehension with wildcard\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = { 1 |\n\t\t\t\t\tx := [1, 2, 3]\n\t\t\t\t\t_ := 2\n\t\t\t\t\tz := x[_]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var z unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"set comprehension with return\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = { z |\n\t\t\t\t\tx := [1, 2, 3]\n\t\t\t\t\ty := 2\n\t\t\t\t\tz := x[_]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"set comprehension with some\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = { i |\n\t\t\t\t\tsome i\n\t\t\t\t\ty := 2\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"object comprehension\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = { 1: 2 |\n\t\t\t\t\tx := [1, 2, 3]\n\t\t\t\t\ty := 2\n\t\t\t\t\tz := x[_]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t\t&Error{Message: \"assigned var z unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"object comprehension nested\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp := { 1: 1 |\n\t\t\t\t\tx := 1\n\t\t\t\t\ty := {a: x | a := x}\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"object comprehension with wildcard\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = { 1: 2 |\n\t\t\t\t\tx := [1, 2, 3]\n\t\t\t\t\t_ := 2\n\t\t\t\t\tz := x[_]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var z unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"object comprehension with return\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = { z: x |\n\t\t\t\t\tx := [1, 2, 3]\n\t\t\t\t\ty := 2\n\t\t\t\t\tz := x[_]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"object comprehension with some\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = { i |\n\t\t\t\t\tsome i\n\t\t\t\t\ty := 2\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"every: unused assigned var in body\",\n\t\t\tmodule: `package test\n\t\t\t\tp { every i in [1] { y := 10; i == 1 } }\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t}\n\n\tmakeTestRunner := func(tc testCase, strict bool) func(t *testing.T) {\n\t\treturn func(t *testing.T) {\n\t\t\tcompiler := NewCompiler().WithStrict(strict)\n\t\t\topts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\t\t\tcompiler.Modules = map[string]*Module{\n\t\t\t\t\"test\": MustParseModuleWithOpts(tc.module, opts),\n\t\t\t}\n\t\t\tcompileStages(compiler, compiler.rewriteLocalVars)\n\n\t\t\tif strict {\n\t\t\t\tassertErrors(t, compiler.Errors, tc.expectedErrors, false)\n\t\t\t} else {\n\t\t\t\tassertNotFailed(t, compiler)\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.note+\"_strict\", makeTestRunner(tc, true))\n\t\tt.Run(tc.note+\"_non-strict\", makeTestRunner(tc, false))\n\t}\n}\n\nfunc TestCompilerSetGraph(t *testing.T) {\n\tc := NewCompiler()\n\tc.Modules = getCompilerTestModules()\n\tc.Modules[\"elsekw\"] = MustParseModule(`\n\tpackage elsekw\n\n\tp {\n\t\tfalse\n\t} else = q {\n\t\tfalse\n\t} else {\n\t\tr\n\t}\n\n\tq = true\n\tr = true\n\n\ts { t }\n\tt { false } else { true }\n\n\t`)\n\tcompileStages(c, c.setGraph)\n\n\tassertNotFailed(t, c)\n\n\tmod1 := c.Modules[\"mod1\"]\n\tp := mod1.Rules[0]\n\tq := mod1.Rules[1]\n\tmod2 := c.Modules[\"mod2\"]\n\tr := mod2.Rules[0]\n\tmod5 := c.Modules[\"mod5\"]\n\n\tedges := map[util.T]struct{}{\n\t\tq: {},\n\t\tr: {},\n\t}\n\n\tif !reflect.DeepEqual(edges, c.Graph.Dependencies(p)) {\n\t\tt.Fatalf(\"Expected dependencies for p to be q and r but got: %v\", c.Graph.Dependencies(p))\n\t}\n\n\t// NOTE(tsandall): this is the correct result but it's chosen arbitrarily for the test.\n\texpDependents := []struct {\n\t\tx    *Rule\n\t\twant map[util.T]struct{}\n\t}{\n\t\t{\n\t\t\tx:    p,\n\t\t\twant: nil,\n\t\t},\n\t\t{\n\t\t\tx:    q,\n\t\t\twant: map[util.T]struct{}{p: {}, mod5.Rules[1]: {}, mod5.Rules[3]: {}, mod5.Rules[5]: {}},\n\t\t},\n\t\t{\n\t\t\tx:    r,\n\t\t\twant: map[util.T]struct{}{p: {}},\n\t\t},\n\t}\n\n\tfor _, exp := range expDependents {\n\t\tif !reflect.DeepEqual(exp.want, c.Graph.Dependents(exp.x)) {\n\t\t\tt.Fatalf(\"Expected dependents for %v to be %v but got: %v\", exp.x, exp.want, c.Graph.Dependents(exp.x))\n\t\t}\n\t}\n\n\tsorted, ok := c.Graph.Sort()\n\tif !ok {\n\t\tt.Fatalf(\"Expected sort to succeed.\")\n\t}\n\n\tnumRules := 0\n\n\tfor _, module := range c.Modules {\n\t\tWalkRules(module, func(*Rule) bool {\n\t\t\tnumRules++\n\t\t\treturn false\n\t\t})\n\t}\n\n\tif len(sorted) != numRules {\n\t\tt.Fatalf(\"Expected numRules (%v) to be same as len(sorted) (%v)\", numRules, len(sorted))\n\t}\n\n\t// Probe rules with dependencies. Ordering is not stable for ties because\n\t// nodes are stored in a map.\n\tprobes := [][2]*Rule{\n\t\t{c.Modules[\"mod1\"].Rules[1], c.Modules[\"mod1\"].Rules[0]},               // mod1.q before mod1.p\n\t\t{c.Modules[\"mod2\"].Rules[0], c.Modules[\"mod1\"].Rules[0]},               // mod2.r before mod1.p\n\t\t{c.Modules[\"mod1\"].Rules[1], c.Modules[\"mod5\"].Rules[1]},               // mod1.q before mod5.r\n\t\t{c.Modules[\"mod1\"].Rules[1], c.Modules[\"mod5\"].Rules[3]},               // mod1.q before mod6.t\n\t\t{c.Modules[\"mod1\"].Rules[1], c.Modules[\"mod5\"].Rules[5]},               // mod1.q before mod6.v\n\t\t{c.Modules[\"mod6\"].Rules[2], c.Modules[\"mod6\"].Rules[3]},               // mod6.r before mod6.s\n\t\t{c.Modules[\"elsekw\"].Rules[1], c.Modules[\"elsekw\"].Rules[0].Else},      // elsekw.q before elsekw.p.else\n\t\t{c.Modules[\"elsekw\"].Rules[2], c.Modules[\"elsekw\"].Rules[0].Else.Else}, // elsekw.r before elsekw.p.else.else\n\t\t{c.Modules[\"elsekw\"].Rules[4], c.Modules[\"elsekw\"].Rules[3]},           // elsekw.t before elsekw.s\n\t\t{c.Modules[\"elsekw\"].Rules[4].Else, c.Modules[\"elsekw\"].Rules[3]},      // elsekw.t.else before elsekw.s\n\t}\n\n\tgetSortedIdx := func(r *Rule) int {\n\t\tfor i := range sorted {\n\t\t\tif sorted[i] == r {\n\t\t\t\treturn i\n\t\t\t}\n\t\t}\n\t\treturn -1\n\t}\n\n\tfor num, probe := range probes {\n\t\ti := getSortedIdx(probe[0])\n\t\tj := getSortedIdx(probe[1])\n\t\tif i == -1 || j == -1 {\n\t\t\tt.Fatalf(\"Expected to find probe %d in sorted slice but got: i=%d, j=%d\", num+1, i, j)\n\t\t}\n\t\tif i >= j {\n\t\t\tt.Errorf(\"Sort order of probe %d (A) %v and (B) %v and is wrong (expected A before B)\", num+1, probe[0], probe[1])\n\t\t}\n\t}\n}\n\nfunc TestGraphCycle(t *testing.T) {\n\tmod1 := `package a.b.c\n\n\tp { q }\n\tq { r }\n\tr { s }\n\ts { q }`\n\n\tc := NewCompiler()\n\tc.Modules = map[string]*Module{\n\t\t\"mod1\": MustParseModule(mod1),\n\t}\n\n\tcompileStages(c, c.setGraph)\n\tassertNotFailed(t, c)\n\n\t_, ok := c.Graph.Sort()\n\tif ok {\n\t\tt.Fatalf(\"Expected to find cycle in rule graph\")\n\t}\n\n\telsekw := `package elsekw\n\n\tp {\n\t\tfalse\n\t} else = q {\n\t\ttrue\n\t}\n\n\tq {\n\t\tfalse\n\t} else {\n\t\tr\n\t}\n\n\tr { s }\n\n\ts { p }\n\t`\n\n\tc = NewCompiler()\n\tc.Modules = map[string]*Module{\n\t\t\"elsekw\": MustParseModule(elsekw),\n\t}\n\n\tcompileStages(c, c.setGraph)\n\tassertNotFailed(t, c)\n\n\t_, ok = c.Graph.Sort()\n\tif ok {\n\t\tt.Fatalf(\"Expected to find cycle in rule graph\")\n\t}\n\n}\n\nfunc TestCompilerCheckRecursion(t *testing.T) {\n\tc := NewCompiler()\n\tc.Modules = map[string]*Module{\n\t\t\"newMod1\": MustParseModule(`package rec\n\ns = true { t }\nt = true { s }\na = true { b }\nb = true { c }\nc = true { d; e }\nd = true { true }\ne = true { a }`),\n\t\t\"newMod2\": MustParseModule(`package rec\n\nx = true { s }`,\n\t\t),\n\t\t\"newMod3\": MustParseModule(`package rec2\n\nimport data.rec.x\n\ny = true { x }`),\n\t\t\"newMod4\": MustParseModule(`package rec3\n\np[x] = y { data.rec4[x][y] = z }`,\n\t\t),\n\t\t\"newMod5\": MustParseModule(`package rec4\n\nimport data.rec3.p\n\nq[x] = y { p[x] = y }`),\n\t\t\"newMod6\": MustParseModule(`package rec5\n\nacp[x] { acq[x] }\nacq[x] { a = [true | acp[_]]; a[_] = x }\n`,\n\t\t),\n\t\t\"newMod7\": MustParseModule(`package rec6\n\nnp[x] = y { data.a[data.b.c[nq[x]]] = y }\nnq[x] = y { data.d[data.e[x].f[np[y]]] }`,\n\t\t),\n\t\t\"newMod8\": MustParseModule(`package rec7\n\nprefix = true { data.rec7 }`,\n\t\t),\n\t\t\"newMod9\": MustParseModule(`package rec8\n\ndataref = true { data }`,\n\t\t),\n\t\t\"newMod10\": MustParseModule(`package rec9\n\n\t\telse_self { false } else { else_self }\n\n\t\telsetop {\n\t\t\tfalse\n\t\t} else = elsemid {\n\t\t\ttrue\n\t\t}\n\n\t\telsemid {\n\t\t\tfalse\n\t\t} else {\n\t\t\telsebottom\n\t\t}\n\n\t\telsebottom { elsetop }\n\t\t`),\n\t\t\"fnMod1\": MustParseModule(`package f0\n\n\t\tfn(x) = y {\n\t\t\tfn(x, y)\n\t\t}`),\n\t\t\"fnMod2\": MustParseModule(`package f1\n\n\t\tfoo(x) = y {\n\t\t\tbar(\"buz\", x, y)\n\t\t}\n\n\t\tbar(x, y) = z {\n\t\t\tfoo([x, y], z)\n\t\t}`),\n\t\t\"fnMod3\": MustParseModule(`package f2\n\n\t\tfoo(x) = y {\n\t\t\tbar(\"buz\", x, y)\n\t\t}\n\n\t\tbar(x, y) = z {\n\t\t\tx = p[y]\n\t\t\tz = x\n\t\t}\n\n\t\tp[x] = y {\n\t\t\tx = \"foo.bar\"\n\t\t\tfoo(x, y)\n\t\t}`),\n\t\t\"everyMod\": MustParseModule(`package everymod\n\t\timport future.keywords.every\n\t\teveryp {\n\t\t\tevery x in [true, false] { x; everyp }\n\t\t}\n\t\teveryq[1] {\n\t\t\tevery x in everyq { x == 1 }\n\t\t}`),\n\t}\n\n\tcompileStages(c, c.checkRecursion)\n\n\tmakeRuleErrMsg := func(rule string, loop ...string) string {\n\t\treturn fmt.Sprintf(\"rego_recursion_error: rule %v is recursive: %v\", rule, strings.Join(loop, \" -> \"))\n\t}\n\n\texpected := []string{\n\t\tmakeRuleErrMsg(\"s\", \"s\", \"t\", \"s\"),\n\t\tmakeRuleErrMsg(\"t\", \"t\", \"s\", \"t\"),\n\t\tmakeRuleErrMsg(\"a\", \"a\", \"b\", \"c\", \"e\", \"a\"),\n\t\tmakeRuleErrMsg(\"b\", \"b\", \"c\", \"e\", \"a\", \"b\"),\n\t\tmakeRuleErrMsg(\"c\", \"c\", \"e\", \"a\", \"b\", \"c\"),\n\t\tmakeRuleErrMsg(\"e\", \"e\", \"a\", \"b\", \"c\", \"e\"),\n\t\tmakeRuleErrMsg(\"p\", \"p\", \"q\", \"p\"),\n\t\tmakeRuleErrMsg(\"q\", \"q\", \"p\", \"q\"),\n\t\tmakeRuleErrMsg(\"acq\", \"acq\", \"acp\", \"acq\"),\n\t\tmakeRuleErrMsg(\"acp\", \"acp\", \"acq\", \"acp\"),\n\t\tmakeRuleErrMsg(\"np\", \"np\", \"nq\", \"np\"),\n\t\tmakeRuleErrMsg(\"nq\", \"nq\", \"np\", \"nq\"),\n\t\tmakeRuleErrMsg(\"prefix\", \"prefix\", \"prefix\"),\n\t\tmakeRuleErrMsg(\"dataref\", \"dataref\", \"dataref\"),\n\t\tmakeRuleErrMsg(\"else_self\", \"else_self\", \"else_self\"),\n\t\tmakeRuleErrMsg(\"elsetop\", \"elsetop\", \"elsemid\", \"elsebottom\", \"elsetop\"),\n\t\tmakeRuleErrMsg(\"elsemid\", \"elsemid\", \"elsebottom\", \"elsetop\", \"elsemid\"),\n\t\tmakeRuleErrMsg(\"elsebottom\", \"elsebottom\", \"elsetop\", \"elsemid\", \"elsebottom\"),\n\t\tmakeRuleErrMsg(\"fn\", \"fn\", \"fn\"),\n\t\tmakeRuleErrMsg(\"foo\", \"foo\", \"bar\", \"foo\"),\n\t\tmakeRuleErrMsg(\"bar\", \"bar\", \"foo\", \"bar\"),\n\t\tmakeRuleErrMsg(\"bar\", \"bar\", \"p\", \"foo\", \"bar\"),\n\t\tmakeRuleErrMsg(\"foo\", \"foo\", \"bar\", \"p\", \"foo\"),\n\t\tmakeRuleErrMsg(\"p\", \"p\", \"foo\", \"bar\", \"p\"),\n\t\tmakeRuleErrMsg(\"everyp\", \"everyp\", \"everyp\"),\n\t\tmakeRuleErrMsg(\"everyq\", \"everyq\", \"everyq\"),\n\t}\n\n\tresult := compilerErrsToStringSlice(c.Errors)\n\tsort.Strings(expected)\n\n\tif len(result) != len(expected) {\n\t\tt.Fatalf(\"Expected %d:\\n%v\\nBut got %d:\\n%v\", len(expected), strings.Join(expected, \"\\n\"), len(result), strings.Join(result, \"\\n\"))\n\t}\n\n\tfor i := range result {\n\t\tif result[i] != expected[i] {\n\t\t\tt.Errorf(\"Expected %v but got: %v\", expected[i], result[i])\n\t\t}\n\t}\n}\n\nfunc TestCompilerCheckDynamicRecursion(t *testing.T) {\n\t// This test tries to circumvent the recursion check by using dynamic\n\t// references.  For more background info, see\n\t// <https://github.com/open-policy-agent/opa/issues/1565>.\n\n\tfor note, mod := range map[string]*Module{\n\t\t\"recursion\": MustParseModule(`\npackage recursion\npkg = \"recursion\"\nfoo[x] {\n\tdata[pkg][\"foo\"][x]\n}\n`),\n\t\t\"system.main\": MustParseModule(`\npackage system.main\nfoo {\n  data[input]\n}\n`),\n\t} {\n\t\tt.Run(note, func(t *testing.T) {\n\t\t\tc := NewCompiler()\n\t\t\tc.Modules = map[string]*Module{note: mod}\n\t\t\tcompileStages(c, c.checkRecursion)\n\n\t\t\tresult := compilerErrsToStringSlice(c.Errors)\n\t\t\texpected := \"rego_recursion_error: rule foo is recursive: foo -> foo\"\n\n\t\t\tif len(result) != 1 || result[0] != expected {\n\t\t\t\tt.Errorf(\"Expected %v but got: %v\", expected, result)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerCheckVoidCalls(t *testing.T) {\n\tc := NewCompiler().WithCapabilities(&Capabilities{Builtins: []*Builtin{\n\t\t{\n\t\t\tName: \"test\",\n\t\t\tDecl: types.NewFunction([]types.Type{types.B}, nil),\n\t\t},\n\t}})\n\tc.Compile(map[string]*Module{\n\t\t\"test.rego\": MustParseModule(`package test\n\n\t\tp {\n\t\t\tx = test(true)\n\t\t}`),\n\t})\n\tif !c.Failed() {\n\t\tt.Fatal(\"expected error\")\n\t} else if c.Errors[0].Code != TypeErr || c.Errors[0].Message != \"test(true) used as value\" {\n\t\tt.Fatal(\"unexpected error:\", c.Errors)\n\t}\n}\n\nfunc TestCompilerGetRulesExact(t *testing.T) {\n\tmods := getCompilerTestModules()\n\n\t// Add incrementally defined rules.\n\tmods[\"mod-incr\"] = MustParseModule(`package a.b.c\n\np[1] { true }\np[2] { true }`,\n\t)\n\n\tc := NewCompiler()\n\tc.Compile(mods)\n\tassertNotFailed(t, c)\n\n\ttests := []struct {\n\t\tnote     string\n\t\tref      interface{}\n\t\texpected []*Rule\n\t}{\n\t\t{\"exact\", \"data.a.b.c.p\", []*Rule{\n\t\t\tc.Modules[\"mod-incr\"].Rules[0],\n\t\t\tc.Modules[\"mod-incr\"].Rules[1],\n\t\t\tc.Modules[\"mod1\"].Rules[0],\n\t\t}},\n\t\t{\"too short\", \"data.a\", []*Rule{}},\n\t\t{\"too long/not found\", \"data.a.b.c.p.q\", []*Rule{}},\n\t\t{\"outside data\", \"input.a.b.c.p\", []*Rule{}},\n\t\t{\"non-string/var\", \"data.a.b[data.foo]\", []*Rule{}},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tvar ref Ref\n\t\t\tswitch r := tc.ref.(type) {\n\t\t\tcase string:\n\t\t\t\tref = MustParseRef(r)\n\t\t\tcase Ref:\n\t\t\t\tref = r\n\t\t\t}\n\t\t\trules := c.GetRulesExact(ref)\n\t\t\tif len(rules) != len(tc.expected) {\n\t\t\t\tt.Fatalf(\"Expected exactly %v rules but got: %v\", len(tc.expected), rules)\n\t\t\t}\n\t\t\tfor i := range rules {\n\t\t\t\tfound := false\n\t\t\t\tfor j := range tc.expected {\n\t\t\t\t\tif rules[i].Equal(tc.expected[j]) {\n\t\t\t\t\t\tfound = true\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif !found {\n\t\t\t\t\tt.Fatalf(\"Expected exactly %v but got: %v\", tc.expected, rules)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerGetRulesForVirtualDocument(t *testing.T) {\n\tmods := getCompilerTestModules()\n\n\t// Add incrementally defined rules.\n\tmods[\"mod-incr\"] = MustParseModule(`package a.b.c\n\np[1] { true }\np[2] { true }`,\n\t)\n\n\tc := NewCompiler()\n\tc.Compile(mods)\n\tassertNotFailed(t, c)\n\n\ttests := []struct {\n\t\tnote     string\n\t\tref      interface{}\n\t\texpected []*Rule\n\t}{\n\t\t{\"exact\", \"data.a.b.c.p\", []*Rule{\n\t\t\tc.Modules[\"mod-incr\"].Rules[0],\n\t\t\tc.Modules[\"mod-incr\"].Rules[1],\n\t\t\tc.Modules[\"mod1\"].Rules[0],\n\t\t}},\n\t\t{\"deep\", \"data.a.b.c.p.q\", []*Rule{\n\t\t\tc.Modules[\"mod-incr\"].Rules[0],\n\t\t\tc.Modules[\"mod-incr\"].Rules[1],\n\t\t\tc.Modules[\"mod1\"].Rules[0],\n\t\t}},\n\t\t{\"too short\", \"data.a\", []*Rule{}},\n\t\t{\"non-existent\", \"data.a.deadbeef\", []*Rule{}},\n\t\t{\"non-string/var\", \"data.a.b[data.foo]\", []*Rule{}},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tvar ref Ref\n\t\t\tswitch r := tc.ref.(type) {\n\t\t\tcase string:\n\t\t\t\tref = MustParseRef(r)\n\t\t\tcase Ref:\n\t\t\t\tref = r\n\t\t\t}\n\t\t\trules := c.GetRulesForVirtualDocument(ref)\n\t\t\tif len(rules) != len(tc.expected) {\n\t\t\t\tt.Fatalf(\"Expected exactly %v rules but got: %v\", len(tc.expected), rules)\n\t\t\t}\n\t\t\tfor i := range rules {\n\t\t\t\tfound := false\n\t\t\t\tfor j := range tc.expected {\n\t\t\t\t\tif rules[i].Equal(tc.expected[j]) {\n\t\t\t\t\t\tfound = true\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif !found {\n\t\t\t\t\tt.Fatalf(\"Expected exactly %v but got: %v\", tc.expected, rules)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerGetRulesWithPrefix(t *testing.T) {\n\tmods := getCompilerTestModules()\n\n\t// Add incrementally defined rules.\n\tmods[\"mod-incr\"] = MustParseModule(`package a.b.c\n\np[1] { true }\np[2] { true }\nq[3] { true }`,\n\t)\n\n\tc := NewCompiler()\n\tc.Compile(mods)\n\tassertNotFailed(t, c)\n\n\ttests := []struct {\n\t\tnote     string\n\t\tref      interface{}\n\t\texpected []*Rule\n\t}{\n\t\t{\"exact\", \"data.a.b.c.p\", []*Rule{\n\t\t\tc.Modules[\"mod-incr\"].Rules[0],\n\t\t\tc.Modules[\"mod-incr\"].Rules[1],\n\t\t\tc.Modules[\"mod1\"].Rules[0],\n\t\t}},\n\t\t{\"too deep\", \"data.a.b.c.p.q\", []*Rule{}},\n\t\t{\"prefix\", \"data.a.b.c\", []*Rule{\n\t\t\tc.Modules[\"mod1\"].Rules[0],\n\t\t\tc.Modules[\"mod1\"].Rules[1],\n\t\t\tc.Modules[\"mod1\"].Rules[2],\n\t\t\tc.Modules[\"mod2\"].Rules[0],\n\t\t\tc.Modules[\"mod-incr\"].Rules[0],\n\t\t\tc.Modules[\"mod-incr\"].Rules[1],\n\t\t\tc.Modules[\"mod-incr\"].Rules[2],\n\t\t}},\n\t\t{\"non-existent\", \"data.a.deadbeef\", []*Rule{}},\n\t\t{\"non-string/var\", \"data.a.b[data.foo]\", []*Rule{}},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tvar ref Ref\n\t\t\tswitch r := tc.ref.(type) {\n\t\t\tcase string:\n\t\t\t\tref = MustParseRef(r)\n\t\t\tcase Ref:\n\t\t\t\tref = r\n\t\t\t}\n\t\t\trules := c.GetRulesWithPrefix(ref)\n\t\t\tif len(rules) != len(tc.expected) {\n\t\t\t\tt.Fatalf(\"Expected exactly %v rules but got: %v\", len(tc.expected), rules)\n\t\t\t}\n\t\t\tfor i := range rules {\n\t\t\t\tfound := false\n\t\t\t\tfor j := range tc.expected {\n\t\t\t\t\tif rules[i].Equal(tc.expected[j]) {\n\t\t\t\t\t\tfound = true\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif !found {\n\t\t\t\t\tt.Fatalf(\"Expected %v but got: %v\", tc.expected, rules)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerGetRules(t *testing.T) {\n\tcompiler := getCompilerWithParsedModules(map[string]string{\n\t\t\"mod1\": `package a.b.c\n\np[x] = y { q[x] = y }\nq[\"a\"] = 1 { true }\nq[\"b\"] = 2 { true }`,\n\t})\n\n\tcompileStages(compiler, nil)\n\n\trule1 := compiler.Modules[\"mod1\"].Rules[0]\n\trule2 := compiler.Modules[\"mod1\"].Rules[1]\n\trule3 := compiler.Modules[\"mod1\"].Rules[2]\n\n\ttests := []struct {\n\t\tinput    string\n\t\texpected []*Rule\n\t}{\n\t\t{\"data.a.b.c.p\", []*Rule{rule1}},\n\t\t{\"data.a.b.c.p.x\", []*Rule{rule1}},\n\t\t{\"data.a.b.c.q\", []*Rule{rule2, rule3}},\n\t\t{\"data.a.b.c\", []*Rule{rule1, rule2, rule3}},\n\t\t{\"data.a.b.d\", nil},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.input, func(t *testing.T) {\n\t\t\tresult := compiler.GetRules(MustParseRef(tc.input))\n\n\t\t\tif len(result) != len(tc.expected) {\n\t\t\t\tt.Fatalf(\"Expected %v but got: %v\", tc.expected, result)\n\t\t\t}\n\n\t\t\tfor i := range result {\n\t\t\t\tfound := false\n\t\t\t\tfor j := range tc.expected {\n\t\t\t\t\tif result[i].Equal(tc.expected[j]) {\n\t\t\t\t\t\tfound = true\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif !found {\n\t\t\t\t\tt.Fatalf(\"Expected %v but got: %v\", tc.expected, result)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n\n}\n\nfunc TestCompilerGetRulesDynamic(t *testing.T) {\n\tcompiler := getCompilerWithParsedModules(map[string]string{\n\t\t\"mod1\": `package a.b.c.d\nr1 = 1`,\n\t\t\"mod2\": `package a.b.c.e\nr2 = 2`,\n\t\t\"mod3\": `package a.b\nr3 = 3`,\n\t\t\"hidden\": `package system.hidden\nr4 = 4`,\n\t})\n\n\tcompileStages(compiler, nil)\n\n\trule1 := compiler.Modules[\"mod1\"].Rules[0]\n\trule2 := compiler.Modules[\"mod2\"].Rules[0]\n\trule3 := compiler.Modules[\"mod3\"].Rules[0]\n\trule4 := compiler.Modules[\"hidden\"].Rules[0]\n\n\ttests := []struct {\n\t\tinput         string\n\t\texpected      []*Rule\n\t\texcludeHidden bool\n\t}{\n\t\t{input: \"data.a.b.c.d.r1\", expected: []*Rule{rule1}},\n\t\t{input: \"data.a.b[x]\", expected: []*Rule{rule1, rule2, rule3}},\n\t\t{input: \"data.a.b[x].d\", expected: []*Rule{rule1, rule3}},\n\t\t{input: \"data.a.b.c\", expected: []*Rule{rule1, rule2}},\n\t\t{input: \"data.a.b.d\"},\n\t\t{input: \"data[x]\", expected: []*Rule{rule1, rule2, rule3, rule4}},\n\t\t{input: \"data[data.complex_computation].b[y]\", expected: []*Rule{rule1, rule2, rule3}},\n\t\t{input: \"data[x][y].c.e\", expected: []*Rule{rule2}},\n\t\t{input: \"data[x][y].r3\", expected: []*Rule{rule3}},\n\t\t{input: \"data[x][y]\", expected: []*Rule{rule1, rule2, rule3}, excludeHidden: true}, // old behaviour of GetRulesDynamic\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.input, func(t *testing.T) {\n\t\t\tresult := compiler.GetRulesDynamicWithOpts(\n\t\t\t\tMustParseRef(tc.input),\n\t\t\t\tRulesOptions{IncludeHiddenModules: !tc.excludeHidden},\n\t\t\t)\n\n\t\t\tif len(result) != len(tc.expected) {\n\t\t\t\tt.Fatalf(\"Expected %v but got: %v\", tc.expected, result)\n\t\t\t}\n\n\t\t\tfor i := range result {\n\t\t\t\tfound := false\n\t\t\t\tfor j := range tc.expected {\n\t\t\t\t\tif result[i].Equal(tc.expected[j]) {\n\t\t\t\t\t\tfound = true\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif !found {\n\t\t\t\t\tt.Fatalf(\"Expected %v but got: %v\", tc.expected, result)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n\n}\n\nfunc TestCompileCustomBuiltins(t *testing.T) {\n\n\tcompiler := NewCompiler().WithBuiltins(map[string]*Builtin{\n\t\t\"baz\": {\n\t\t\tName: \"baz\",\n\t\t\tDecl: types.NewFunction([]types.Type{types.S}, types.A),\n\t\t},\n\t\t\"foo.bar\": {\n\t\t\tName: \"foo.bar\",\n\t\t\tDecl: types.NewFunction([]types.Type{types.S}, types.A),\n\t\t},\n\t})\n\n\tcompiler.Compile(map[string]*Module{\n\t\t\"test.rego\": MustParseModule(`\n\t\t\tpackage test\n\n\t\t\tp { baz(\"x\") = x }\n\t\t\tq { foo.bar(\"x\") = x }\n\t\t`),\n\t})\n\n\t// Ensure no type errors occur.\n\tif compiler.Failed() {\n\t\tt.Fatal(\"Unexpected compilation error:\", compiler.Errors)\n\t}\n\n\t_, err := compiler.QueryCompiler().Compile(MustParseBody(`baz(\"x\") = x; foo.bar(\"x\") = x`))\n\tif err != nil {\n\t\tt.Fatal(\"Unexpected compilation error:\", err)\n\t}\n\n\t// Ensure type errors occur.\n\texp1 := `rego_type_error: baz: invalid argument(s)`\n\texp2 := `rego_type_error: foo.bar: invalid argument(s)`\n\n\t_, err = compiler.QueryCompiler().Compile(MustParseBody(`baz(1) = x; foo.bar(1) = x`))\n\tif err == nil {\n\t\tt.Fatal(\"Expected compilation error\")\n\t} else if !strings.Contains(err.Error(), exp1) {\n\t\tt.Fatalf(\"Expected:\\n\\n%v\\n\\nGot:\\n\\n%v\", exp1, err)\n\t} else if !strings.Contains(err.Error(), exp2) {\n\t\tt.Fatalf(\"Expected:\\n\\n%v\\n\\nGot:\\n\\n%v\", exp2, err)\n\t}\n\n\tcompiler.Compile(map[string]*Module{\n\t\t\"test.rego\": MustParseModule(`\n\t\t\tpackage test\n\n\t\t\tp { baz(1) = x }  # type error\n\t\t\tq { foo.bar(1) = x }  # type error\n\t\t`),\n\t})\n\n\tassertCompilerErrorStrings(t, compiler, []string{exp1, exp2})\n}\n\nfunc TestCompilerLazyLoadingError(t *testing.T) {\n\n\ttestLoader := func(map[string]*Module) (map[string]*Module, error) {\n\t\treturn nil, fmt.Errorf(\"something went horribly wrong\")\n\t}\n\n\tcompiler := NewCompiler().WithModuleLoader(testLoader)\n\n\tcompiler.Compile(nil)\n\n\texpected := Errors{\n\t\tNewError(CompileErr, nil, \"something went horribly wrong\"),\n\t}\n\n\tif !reflect.DeepEqual(expected, compiler.Errors) {\n\t\tt.Fatalf(\"Expected error %v but got: %v\", expected, compiler.Errors)\n\t}\n}\n\nfunc TestCompilerLazyLoading(t *testing.T) {\n\n\tmod1 := MustParseModule(`package a.b.c\n\nimport data.x.z1 as z2\n\np = true { q; r }\nq = true { z2 }`)\n\torig1 := mod1.Copy()\n\n\tmod2 := MustParseModule(`package a.b.c\n\nr = true { true }`)\n\torig2 := mod2.Copy()\n\n\tmod3 := MustParseModule(`package x\n\nimport data.foo.bar\nimport input.input\n\nz1 = true { [localvar | count(bar.baz.qux, localvar)] }`)\n\torig3 := mod3.Copy()\n\n\tmod4 := MustParseModule(`package foo.bar.baz\n\nqux = grault { true }`)\n\torig4 := mod4.Copy()\n\n\tmod5 := MustParseModule(`package foo.bar.baz\n\nimport data.d.e.f\n\ndeadbeef = f { true }\ngrault = deadbeef { true }`)\n\torig5 := mod5.Copy()\n\n\t// testLoader will return 4 rounds of parsed modules.\n\trounds := []map[string]*Module{\n\t\t{\"mod1\": mod1, \"mod2\": mod2},\n\t\t{\"mod3\": mod3},\n\t\t{\"mod4\": mod4},\n\t\t{\"mod5\": mod5},\n\t}\n\n\t// For each round, run checks.\n\ttests := []func(map[string]*Module){\n\t\tfunc(map[string]*Module) {\n\t\t\t// first round, no modules because compiler is invoked with empty\n\t\t\t// collection.\n\t\t},\n\t\tfunc(partial map[string]*Module) {\n\t\t\tp := MustParseRule(`p = true { data.a.b.c.q; data.a.b.c.r }`)\n\t\t\tif !partial[\"mod1\"].Rules[0].Equal(p) {\n\t\t\t\tt.Errorf(\"Expected %v but got %v\", p, partial[\"mod1\"].Rules[0])\n\t\t\t}\n\t\t\tq := MustParseRule(`q = true { data.x.z1 }`)\n\t\t\tif !partial[\"mod1\"].Rules[1].Equal(q) {\n\t\t\t\tt.Errorf(\"Expected %v but got %v\", q, partial[\"mod1\"].Rules[0])\n\t\t\t}\n\t\t},\n\t\tfunc(partial map[string]*Module) {\n\t\t\tz1 := MustParseRule(`z1 = true { [localvar | count(data.foo.bar.baz.qux, localvar)] }`)\n\t\t\tif !partial[\"mod3\"].Rules[0].Equal(z1) {\n\t\t\t\tt.Errorf(\"Expected %v but got %v\", z1, partial[\"mod3\"].Rules[0])\n\t\t\t}\n\t\t},\n\t\tfunc(partial map[string]*Module) {\n\t\t\tqux := MustParseRule(`qux = grault { true }`)\n\t\t\tif !partial[\"mod4\"].Rules[0].Equal(qux) {\n\t\t\t\tt.Errorf(\"Expected %v but got %v\", qux, partial[\"mod4\"].Rules[0])\n\t\t\t}\n\t\t},\n\t\tfunc(partial map[string]*Module) {\n\t\t\tgrault := MustParseRule(`qux = data.foo.bar.baz.grault { true }`) // rewrite has not happened yet\n\t\t\tf := MustParseRule(`deadbeef = data.d.e.f { true }`)\n\t\t\tif !partial[\"mod4\"].Rules[0].Equal(grault) {\n\t\t\t\tt.Errorf(\"Expected %v but got %v\", grault, partial[\"mod4\"].Rules[0])\n\t\t\t}\n\t\t\tif !partial[\"mod5\"].Rules[0].Equal(f) {\n\t\t\t\tt.Errorf(\"Expected %v but got %v\", f, partial[\"mod5\"].Rules[0])\n\t\t\t}\n\t\t},\n\t}\n\n\tround := 0\n\n\ttestLoader := func(modules map[string]*Module) (map[string]*Module, error) {\n\t\ttests[round](modules)\n\t\tif round >= len(rounds) {\n\t\t\treturn nil, nil\n\t\t}\n\t\tresult := rounds[round]\n\t\tround++\n\t\treturn result, nil\n\t}\n\n\tcompiler := NewCompiler().WithModuleLoader(testLoader)\n\n\tif compiler.Compile(nil); compiler.Failed() {\n\t\tt.Fatalf(\"Got unexpected error from compiler: %v\", compiler.Errors)\n\t}\n\n\t// Check the original modules are still untouched.\n\tif !mod1.Equal(orig1) || !mod2.Equal(orig2) || !mod3.Equal(orig3) || !mod4.Equal(orig4) || !mod5.Equal(orig5) {\n\t\tt.Errorf(\"Compiler lazy loading modified the original modules\")\n\t}\n}\n\nfunc TestCompilerWithMetrics(t *testing.T) {\n\tm := metrics.New()\n\tc := NewCompiler().WithMetrics(m)\n\tmod := MustParseModule(testModule)\n\n\tc.Compile(map[string]*Module{\"testMod\": mod})\n\tassertNotFailed(t, c)\n\n\tif len(m.All()) == 0 {\n\t\tt.Error(\"Expected to have metrics after compiling\")\n\t}\n}\n\nfunc TestCompilerWithStageAfterWithMetrics(t *testing.T) {\n\tm := metrics.New()\n\tc := NewCompiler().WithStageAfter(\n\t\t\"CheckRecursion\",\n\t\tCompilerStageDefinition{\"MockStage\", \"mock_stage\", func(*Compiler) *Error { return nil }},\n\t)\n\n\tc.WithMetrics(m)\n\n\tmod := MustParseModule(testModule)\n\n\tc.Compile(map[string]*Module{\"testMod\": mod})\n\tassertNotFailed(t, c)\n\n\tif len(m.All()) == 0 {\n\t\tt.Error(\"Expected to have metrics after compiling\")\n\t}\n}\n\nfunc TestCompilerBuildComprehensionIndexKeySet(t *testing.T) {\n\n\ttype expectedComprehension struct {\n\t\tterm, keys string\n\t}\n\ttype exp map[int]expectedComprehension\n\ttests := []struct {\n\t\tnote      string\n\t\tmodule    string\n\t\texpected  exp\n\t\twantDebug int\n\t}{\n\t\t{\n\t\t\tnote: \"example: invert object\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\tvalue = input[i]\n\t\t\t\t\tkeys = [j | value = input[j]]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpected: exp{6: {\n\t\t\t\tterm: `[j | value = input[j]]`,\n\t\t\t\tkeys: `[value]`,\n\t\t\t}},\n\t\t\twantDebug: 1,\n\t\t},\n\t\t{\n\t\t\tnote: \"example: multiple keys from body\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\tv1 = input[i].v1\n\t\t\t\t\tv2 = input[i].v2\n\t\t\t\t\tkeys = [j | v1 = input[j].v1; v2 = input[j].v2]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpected: exp{7: {\n\t\t\t\tterm: `[j | v1 = input[j].v1; v2 = input[j].v2]`,\n\t\t\t\tkeys: `[v1, v2]`,\n\t\t\t}},\n\t\t\twantDebug: 1,\n\t\t},\n\t\t{\n\t\t\tnote: \"example: nested comprehensions are supported\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp = {x: ys |\n\t\t\t\t\tx = input[i]\n\t\t\t\t\tys = {y | x = input[y]}\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpected: exp{6: {\n\t\t\t\tterm: `{y | x = input[y]}`,\n\t\t\t\tkeys: `[x]`,\n\t\t\t}},\n\t\t\t// there are still things going on here that'll be reported, besides successful indexing\n\t\t\twantDebug: 2,\n\t\t},\n\t\t{\n\t\t\tnote: \"skip: lone comprehensions\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\t[v | input[i] = v]  # skip because no assignment\n\t\t\t\t}`,\n\t\t\twantDebug: 0,\n\t\t},\n\t\t{\n\t\t\tnote: \"skip: due to with modifier\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\tv = input[i]\n\t\t\t\t\tks = [j | input[j] = v] with data.x as 1  # skip because of with modifier\n\t\t\t\t}`,\n\t\t\twantDebug: 0,\n\t\t},\n\t\t{\n\t\t\tnote: \"skip: due to negation\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\tv = input[i]\n\t\t\t\t\ta = []\n\t\t\t\t\tnot a = [j | input[j] = v] # skip due to negation\n\t\t\t\t}`,\n\t\t\twantDebug: 0,\n\t\t},\n\t\t{\n\t\t\tnote: \"skip: due to lack of comprehension\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\tv = input[i]\n\t\t\t\t}`,\n\t\t\twantDebug: 0, // nothing interesting to report here\n\t\t},\n\t\t{\n\t\t\tnote: \"skip: due to unsafe comprehension body\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tf(x) {\n\t\t\t\t\tv = input[i]\n\t\t\t\t\tys = [y | y = x[j]]  # x is not safe\n\t\t\t\t}`,\n\t\t\twantDebug: 1,\n\t\t},\n\t\t{\n\t\t\tnote: \"skip: due to no candidates\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\tys = [y | y = input[j]]\n\t\t\t\t}`,\n\t\t\twantDebug: 1,\n\t\t},\n\t\t{\n\t\t\tnote: \"mixed: due to nested comprehension containing candidate + indexed nested comprehension with key from rule body\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\tx = input[i]                # 'x' is a candidate for z (line 7)\n\t\t\t\t\ty = 2                       # 'y' is a candidate for z\n\t\t\t\t\tz = [1 |\n\t\t\t\t\t\tx = data.foo[j]             # 'x' is an index key for z\n\t\t\t\t\t\tt = [1 | data.bar[k] = y]   # 'y' disqualifies indexing of z because it is nested inside a comprehension\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t`,\n\t\t\t// Note: no comprehension index for line 7 (`z = [ ...`)\n\t\t\texpected: exp{9: {\n\t\t\t\tkeys: `[y]`,\n\t\t\t\tterm: `[1 | data.bar[k] = y]`,\n\t\t\t}},\n\t\t\twantDebug: 2,\n\t\t},\n\t\t{\n\t\t\tnote: \"skip: avoid increasing runtime (func arg)\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tf(x) {\n\t\t\t\t\ty = input[x]\n\t\t\t\t\tys = [y | y = input[x]]\n\t\t\t\t}`,\n\t\t\twantDebug: 1,\n\t\t},\n\t\t{\n\t\t\tnote: \"skip: avoid increasing runtime (head key)\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp[x] {\n\t\t\t\t\ty = input[x]\n\t\t\t\t\tys = [y | y = input[x]]\n\t\t\t\t}`,\n\t\t\twantDebug: 1,\n\t\t},\n\t\t{\n\t\t\tnote: \"skip: avoid increasing runtime (walk)\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp[x] {\n\t\t\t\t\ty = input.bar[x]\n\t\t\t\t\tys = [y | a = input.foo; walk(a, [x, y])]\n\t\t\t\t}`,\n\t\t\twantDebug: 1,\n\t\t},\n\t\t{\n\t\t\tnote: \"bypass: use intermediate var to skip regression check\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp[x] {\n\t\t\t\t\ty = input[x]\n\t\t\t\t\tys = [y | y = input[z]; z = x]\n\t\t\t\t}`,\n\t\t\texpected: exp{6: {\n\t\t\t\tterm: ` [y | y = input[z]; z = x]`,\n\t\t\t\tkeys: `[x, y]`,\n\t\t\t}},\n\t\t\twantDebug: 1,\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tdbg := bytes.Buffer{}\n\t\t\tm := metrics.New()\n\t\t\tcompiler := NewCompiler().WithMetrics(m).WithDebug(&dbg)\n\t\t\tmod, err := ParseModule(\"test.rego\", tc.module)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tcompiler.Compile(map[string]*Module{\"test.rego\": mod})\n\t\t\tif compiler.Failed() {\n\t\t\t\tt.Fatal(compiler.Errors)\n\t\t\t}\n\n\t\t\tmessages := strings.Split(dbg.String(), \"\\n\")\n\t\t\tmessages = messages[:len(messages)-1] // last one is an empty string\n\t\t\tif exp, act := tc.wantDebug, len(messages); exp != act {\n\t\t\t\tt.Errorf(\"expected %d debug messages, got %d\", exp, act)\n\t\t\t\tfor i, m := range messages {\n\t\t\t\t\tt.Logf(\"%d: %s\\n\", i, m)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tn := m.Counter(compileStageComprehensionIndexBuild).Value().(uint64)\n\t\t\tif exp, act := len(tc.expected), len(compiler.comprehensionIndices); exp != act {\n\t\t\t\tt.Fatalf(\"expected %d indices to be built. got: %d\", exp, act)\n\t\t\t}\n\t\t\tif len(tc.expected) == 0 {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif n == 0 {\n\t\t\t\tt.Fatal(\"expected counter to be incremented\")\n\t\t\t}\n\n\t\t\tfor row, exp := range tc.expected {\n\t\t\t\tvar comprehension *Term\n\t\t\t\tWalkTerms(compiler.Modules[\"test.rego\"], func(x *Term) bool {\n\t\t\t\t\tif !IsComprehension(x.Value) {\n\t\t\t\t\t\treturn true\n\t\t\t\t\t}\n\t\t\t\t\t_, ok := tc.expected[x.Location.Row]\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn false\n\t\t\t\t\t} else if comprehension != nil {\n\t\t\t\t\t\tt.Fatal(\"expected at most one comprehension per line in test module\")\n\t\t\t\t\t}\n\t\t\t\t\tcomprehension = x\n\t\t\t\t\treturn false\n\t\t\t\t})\n\t\t\t\tif comprehension == nil {\n\t\t\t\t\tt.Fatal(\"expected comprehension at line:\", row)\n\t\t\t\t}\n\n\t\t\t\tresult := compiler.ComprehensionIndex(comprehension)\n\t\t\t\tif result == nil {\n\t\t\t\t\tt.Fatal(\"expected result\")\n\t\t\t\t}\n\n\t\t\t\texpTerm := MustParseTerm(exp.term)\n\t\t\t\tif !result.Term.Equal(expTerm) {\n\t\t\t\t\tt.Fatalf(\"expected term to be %v but got: %v\", expTerm, result.Term)\n\t\t\t\t}\n\n\t\t\t\texpKeys := MustParseTerm(exp.keys).Value.(*Array)\n\t\t\t\tif NewArray(result.Keys...).Compare(expKeys) != 0 {\n\t\t\t\t\tt.Fatalf(\"expected keys to be %v but got: %v\", expKeys, result.Keys)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerAllowMultipleAssignments(t *testing.T) {\n\n\t_, err := CompileModules(map[string]string{\"test.rego\": `\n\t\tpackage test\n\n\t\tp := 7\n\t\tp := 8\n\t`})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestQueryCompiler(t *testing.T) {\n\ttests := []struct {\n\t\tnote     string\n\t\tq        string\n\t\tpkg      string\n\t\timports  []string\n\t\tinput    string\n\t\texpected interface{}\n\t}{\n\t\t{\n\t\t\tnote:     \"empty query\",\n\t\t\tq:        \"   \\t \\n # foo \\n\",\n\t\t\texpected: fmt.Errorf(\"1 error occurred: rego_compile_error: empty query cannot be compiled\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"invalid eq\",\n\t\t\tq:        \"eq()\",\n\t\t\texpected: fmt.Errorf(\"1 error occurred: 1:1: rego_type_error: eq: arity mismatch\\n\\thave: ()\\n\\twant: (any, any)\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"invalid eq\",\n\t\t\tq:        \"eq(1)\",\n\t\t\texpected: fmt.Errorf(\"1 error occurred: 1:1: rego_type_error: eq: arity mismatch\\n\\thave: (number)\\n\\twant: (any, any)\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"rewrite assignment\",\n\t\t\tq:        \"a := 1; [b, c] := data.foo\",\n\t\t\tpkg:      \"\",\n\t\t\timports:  nil,\n\t\t\texpected: \"__localq0__ = 1; [__localq1__, __localq2__] = data.foo\",\n\t\t},\n\t\t{\n\t\t\tnote:     \"exports resolved\",\n\t\t\tq:        \"z\",\n\t\t\tpkg:      `package a.b.c`,\n\t\t\timports:  nil,\n\t\t\texpected: \"data.a.b.c.z\",\n\t\t},\n\t\t{\n\t\t\tnote:     \"imports resolved\",\n\t\t\tq:        \"z\",\n\t\t\tpkg:      `package a.b.c.d`,\n\t\t\timports:  []string{\"import data.a.b.c.z\"},\n\t\t\texpected: \"data.a.b.c.z\",\n\t\t},\n\t\t{\n\t\t\tnote:     \"rewrite comprehensions\",\n\t\t\tq:        \"[x[i] | a = [[1], [2]]; x = a[j]]\",\n\t\t\tpkg:      \"\",\n\t\t\timports:  nil,\n\t\t\texpected: \"[__localq0__ | a = [[1], [2]]; x = a[j]; __localq0__ = x[i]]\",\n\t\t},\n\t\t{\n\t\t\tnote:     \"unsafe vars\",\n\t\t\tq:        \"z\",\n\t\t\tpkg:      \"\",\n\t\t\timports:  nil,\n\t\t\texpected: fmt.Errorf(\"1 error occurred: 1:1: rego_unsafe_var_error: var z is unsafe\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"unsafe var that is a future keyword\",\n\t\t\tq:        \"1 in 2\",\n\t\t\texpected: fmt.Errorf(\"1 error occurred: 1:3: rego_unsafe_var_error: var in is unsafe (hint: `import future.keywords.in` to import a future keyword)\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"unsafe declared var\",\n\t\t\tq:        \"[1 | some x; x == 1]\",\n\t\t\tpkg:      \"\",\n\t\t\timports:  nil,\n\t\t\texpected: fmt.Errorf(\"1 error occurred: 1:14: rego_unsafe_var_error: var x is unsafe\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"safe vars\",\n\t\t\tq:        `data; abc`,\n\t\t\tpkg:      `package ex`,\n\t\t\timports:  []string{\"import input.xyz as abc\"},\n\t\t\texpected: `data; input.xyz`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"reorder\",\n\t\t\tq:        `x != 1; x = 0`,\n\t\t\tpkg:      \"\",\n\t\t\timports:  nil,\n\t\t\texpected: `x = 0; x != 1`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"bad with target\",\n\t\t\tq:        \"x = 1 with foo.p as null\",\n\t\t\tpkg:      \"\",\n\t\t\timports:  nil,\n\t\t\texpected: fmt.Errorf(\"1 error occurred: 1:12: rego_type_error: with keyword target must reference existing input, data, or a function\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"rewrite with value\",\n\t\t\tq:        `1 with input as [z]`,\n\t\t\tpkg:      \"package a.b.c\",\n\t\t\timports:  nil,\n\t\t\texpected: `__localq1__ = data.a.b.c.z; __localq0__ = [__localq1__]; 1 with input as __localq0__`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"built-in function arity mismatch\",\n\t\t\tq:        `startswith(\"x\")`,\n\t\t\tpkg:      \"\",\n\t\t\timports:  nil,\n\t\t\texpected: fmt.Errorf(\"1 error occurred: 1:1: rego_type_error: startswith: arity mismatch\\n\\thave: (string)\\n\\twant: (search: string, base: string)\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"built-in function arity mismatch (arity 0)\",\n\t\t\tq:        `x := opa.runtime(\"foo\")`,\n\t\t\tpkg:      \"\",\n\t\t\timports:  nil,\n\t\t\texpected: fmt.Errorf(\"1 error occurred: 1:6: rego_type_error: opa.runtime: arity mismatch\\n\\thave: (string, ???)\\n\\twant: ()\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"built-in function arity mismatch, nested\",\n\t\t\tq:        \"count(sum())\",\n\t\t\tpkg:      \"\",\n\t\t\timports:  nil,\n\t\t\texpected: fmt.Errorf(\"1 error occurred: 1:7: rego_type_error: sum: arity mismatch\\n\\thave: (???)\\n\\twant: (collection: any<array[number], set[number]>)\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"check types\",\n\t\t\tq:        \"x = data.a.b.c.z; y = null; x = y\",\n\t\t\tpkg:      \"\",\n\t\t\timports:  nil,\n\t\t\texpected: fmt.Errorf(\"match error\\n\\tleft  : number\\n\\tright : null\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"undefined function\",\n\t\t\tq:        \"data.deadbeef(x)\",\n\t\t\texpected: fmt.Errorf(\"rego_type_error: undefined function data.deadbeef\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"imports resolved without package\",\n\t\t\tq:        \"abc\",\n\t\t\tpkg:      \"\",\n\t\t\timports:  []string{\"import input.xyz as abc\"},\n\t\t\texpected: \"input.xyz\",\n\t\t},\n\t\t{\n\t\t\tnote:     \"void call used as value\",\n\t\t\tq:        \"x = print(1)\",\n\t\t\texpected: fmt.Errorf(\"rego_type_error: print(1) used as value\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"print call erasure\",\n\t\t\tq:        `print(1)`,\n\t\t\texpected: \"true\",\n\t\t},\n\t}\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, runQueryCompilerTest(tc.q, tc.pkg, tc.imports, tc.expected))\n\t}\n}\n\nfunc TestQueryCompilerRewrittenVars(t *testing.T) {\n\ttests := []struct {\n\t\tnote string\n\t\tq    string\n\t\tvars map[string]string\n\t}{\n\t\t{\"assign\", \"a := 1\", map[string]string{\"__localq0__\": \"a\"}},\n\t\t{\"suppress only seen\", \"b = 1; a := b\", map[string]string{\"__localq0__\": \"a\"}},\n\t}\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tc := NewCompiler()\n\t\t\tc.Compile(nil)\n\t\t\tassertNotFailed(t, c)\n\t\t\tqc := c.QueryCompiler()\n\t\t\tbody, err := ParseBody(tc.q)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\t_, err = qc.Compile(body)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tvars := qc.RewrittenVars()\n\t\t\tif len(tc.vars) != len(vars) {\n\t\t\t\tt.Fatalf(\"Expected %v but got: %v\", tc.vars, vars)\n\t\t\t}\n\t\t\tfor k := range vars {\n\t\t\t\tif vars[k] != Var(tc.vars[string(k)]) {\n\t\t\t\t\tt.Fatalf(\"Expected %v but got: %v\", tc.vars, vars)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestQueryCompilerRecompile(t *testing.T) {\n\n\t// Query which contains terms that will be rewritten.\n\tparsed := MustParseBody(`a := [1]; data.bar == data.foo[a[0]]`)\n\tparsed0 := parsed\n\n\tqc := NewCompiler().QueryCompiler()\n\tcompiled, err := qc.Compile(parsed)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tcompiled2, err := qc.Compile(parsed)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif !compiled2.Equal(compiled) {\n\t\tt.Fatalf(\"Expected same compiled query. Expected: %v, Got: %v\", compiled, compiled2)\n\t}\n\n\tif !parsed0.Equal(parsed) {\n\t\tt.Fatalf(\"Expected parsed query to be unmodified. Expected %v, Got: %v\", parsed0, parsed)\n\t}\n\n}\n\nfunc TestQueryCompilerWithMetrics(t *testing.T) {\n\tm := metrics.New()\n\tc := NewCompiler().WithMetrics(m)\n\tc.Compile(getCompilerTestModules())\n\tassertNotFailed(t, c)\n\tm.Clear()\n\n\tqc := c.QueryCompiler()\n\n\tquery := MustParseBody(\"a = 1; a > 2\")\n\t_, err := qc.Compile(query)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error from %v: %v\", query, err)\n\t}\n\n\tif len(m.All()) == 0 {\n\t\tt.Error(\"Expected to have metrics after compiling\")\n\t}\n}\n\nfunc TestQueryCompilerWithStageAfterWithMetrics(t *testing.T) {\n\tm := metrics.New()\n\tc := NewCompiler().WithMetrics(m)\n\tc.Compile(getCompilerTestModules())\n\tassertNotFailed(t, c)\n\tm.Clear()\n\n\tqc := c.QueryCompiler().WithStageAfter(\n\t\t\"CheckSafety\",\n\t\tQueryCompilerStageDefinition{\n\t\t\t\"MockStage\",\n\t\t\t\"mock_stage\",\n\t\t\tfunc(_ QueryCompiler, b Body) (Body, error) {\n\t\t\t\treturn b, nil\n\t\t\t},\n\t\t})\n\n\tquery := MustParseBody(\"a = 1; a > 2\")\n\t_, err := qc.Compile(query)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error from %v: %v\", query, err)\n\t}\n\n\tif len(m.All()) == 0 {\n\t\tt.Error(\"Expected to have metrics after compiling\")\n\t}\n}\n\nfunc TestQueryCompilerWithUnsafeBuiltins(t *testing.T) {\n\tc := NewCompiler().WithUnsafeBuiltins(map[string]struct{}{\n\t\t\"count\": {},\n\t})\n\n\t_, err := c.QueryCompiler().WithUnsafeBuiltins(map[string]struct{}{}).Compile(MustParseBody(\"count([])\"))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestQueryCompilerWithDeprecatedBuiltins(t *testing.T) {\n\tcases := []strictnessQueryTestCase{\n\t\t{\n\t\t\tnote:           \"all() built-in\",\n\t\t\tquery:          \"all([true, false])\",\n\t\t\texpectedErrors: fmt.Errorf(\"1 error occurred: 1:1: rego_type_error: deprecated built-in function calls in expression: all\"),\n\t\t},\n\t\t{\n\t\t\tnote:           \"any() built-in\",\n\t\t\tquery:          \"any([true, false])\",\n\t\t\texpectedErrors: fmt.Errorf(\"1 error occurred: 1:1: rego_type_error: deprecated built-in function calls in expression: any\"),\n\t\t},\n\t}\n\n\trunStrictnessQueryTestCase(t, cases)\n}\n\nfunc TestQueryCompilerWithUnusedAssignedVar(t *testing.T) {\n\tcases := []strictnessQueryTestCase{\n\t\t{\n\t\t\tnote:           \"array comprehension\",\n\t\t\tquery:          \"[1 | x := 2]\",\n\t\t\texpectedErrors: fmt.Errorf(\"1 error occurred: 1:6: rego_compile_error: assigned var x unused\"),\n\t\t},\n\t\t{\n\t\t\tnote:           \"set comprehension\",\n\t\t\tquery:          \"{1 | x := 2}\",\n\t\t\texpectedErrors: fmt.Errorf(\"1 error occurred: 1:6: rego_compile_error: assigned var x unused\"),\n\t\t},\n\t\t{\n\t\t\tnote:           \"object comprehension\",\n\t\t\tquery:          \"{1: 2 | x := 2}\",\n\t\t\texpectedErrors: fmt.Errorf(\"1 error occurred: 1:9: rego_compile_error: assigned var x unused\"),\n\t\t},\n\t\t{\n\t\t\tnote:           \"every: unused var in body\",\n\t\t\tquery:          \"every _ in [] { x := 10 }\",\n\t\t\texpectedErrors: fmt.Errorf(\"1 error occurred: 1:17: rego_compile_error: assigned var x unused\"),\n\t\t},\n\t}\n\n\trunStrictnessQueryTestCase(t, cases)\n}\n\nfunc TestQueryCompilerCheckKeywordOverrides(t *testing.T) {\n\tcases := []strictnessQueryTestCase{\n\t\t{\n\t\t\tnote:           \"input assigned\",\n\t\t\tquery:          \"input := 1\",\n\t\t\texpectedErrors: fmt.Errorf(\"1 error occurred: 1:1: rego_compile_error: variables must not shadow input (use a different variable name)\"),\n\t\t},\n\t\t{\n\t\t\tnote:           \"data assigned\",\n\t\t\tquery:          \"data := 1\",\n\t\t\texpectedErrors: fmt.Errorf(\"1 error occurred: 1:1: rego_compile_error: variables must not shadow data (use a different variable name)\"),\n\t\t},\n\t\t{\n\t\t\tnote:           \"nested input assigned\",\n\t\t\tquery:          \"d := [input | input := 1]\",\n\t\t\texpectedErrors: fmt.Errorf(\"1 error occurred: 1:15: rego_compile_error: variables must not shadow input (use a different variable name)\"),\n\t\t},\n\t}\n\n\trunStrictnessQueryTestCase(t, cases)\n}\n\ntype strictnessQueryTestCase struct {\n\tnote           string\n\tquery          string\n\texpectedErrors error\n}\n\nfunc runStrictnessQueryTestCase(t *testing.T, cases []strictnessQueryTestCase) {\n\tt.Helper()\n\tmakeTestRunner := func(tc strictnessQueryTestCase, strict bool) func(t *testing.T) {\n\t\treturn func(t *testing.T) {\n\t\t\tc := NewCompiler().WithStrict(strict)\n\t\t\topts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\t\t\tresult, err := c.QueryCompiler().Compile(MustParseBodyWithOpts(tc.query, opts))\n\n\t\t\tif strict {\n\t\t\t\tif err == nil {\n\t\t\t\t\tt.Fatalf(\"Expected error from %v but got: %v\", tc.query, result)\n\t\t\t\t}\n\t\t\t\tif !strings.Contains(err.Error(), tc.expectedErrors.Error()) {\n\t\t\t\t\tt.Fatalf(\"Expected error %v but got: %v\", tc.expectedErrors, err)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Unexpected error from %v: %v\", tc.query, err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.note+\"_strict\", makeTestRunner(tc, true))\n\t\tt.Run(tc.note+\"_non-strict\", makeTestRunner(tc, false))\n\t}\n}\n\nfunc assertCompilerErrorStrings(t *testing.T, compiler *Compiler, expected []string) {\n\tresult := compilerErrsToStringSlice(compiler.Errors)\n\n\tif len(result) != len(expected) {\n\t\tt.Fatalf(\"Expected %d:\\n%v\\nBut got %d:\\n%v\", len(expected), strings.Join(expected, \"\\n\"), len(result), strings.Join(result, \"\\n\"))\n\t}\n\tfor i := range result {\n\t\tif !strings.Contains(result[i], expected[i]) {\n\t\t\tt.Errorf(\"Expected %v but got: %v\", expected[i], result[i])\n\t\t}\n\t}\n}\n\nfunc assertNotFailed(t *testing.T, c *Compiler) {\n\tt.Helper()\n\tif c.Failed() {\n\t\tt.Fatalf(\"Unexpected compilation error: %v\", c.Errors)\n\t}\n}\n\nfunc getCompilerWithParsedModules(mods map[string]string) *Compiler {\n\n\tparsed := map[string]*Module{}\n\n\tfor id, input := range mods {\n\t\tmod, err := ParseModule(id, input)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\tparsed[id] = mod\n\t}\n\n\tcompiler := NewCompiler()\n\tcompiler.Modules = parsed\n\n\treturn compiler\n}\n\n// helper function to run compiler upto given stage. If nil is provided, a\n// normal compile run is performed.\nfunc compileStages(c *Compiler, upto func()) {\n\n\tc.init()\n\n\tfor name := range c.Modules {\n\t\tc.sorted = append(c.sorted, name)\n\t}\n\n\tc.localvargen = newLocalVarGeneratorForModuleSet(c.sorted, c.Modules)\n\n\tsort.Strings(c.sorted)\n\tc.SetErrorLimit(0)\n\n\tif upto == nil {\n\t\tc.compile()\n\t\treturn\n\t}\n\n\ttarget := reflect.ValueOf(upto)\n\n\tfor _, s := range c.stages {\n\t\tif s.f(); c.Failed() {\n\t\t\treturn\n\t\t}\n\t\tif reflect.ValueOf(s.f).Pointer() == target.Pointer() {\n\t\t\tbreak\n\t\t}\n\t}\n}\n\nfunc getCompilerTestModules() map[string]*Module {\n\n\tmod1 := MustParseModule(`package a.b.c\n\nimport data.x.y.z as foo\nimport data.g.h.k\n\np[x] { q[x]; not r[x] }\nq[x] { foo[i] = x }\nz = 400 { true }`,\n\t)\n\n\tmod2 := MustParseModule(`package a.b.c\n\nimport data.bar\nimport data.x.y.p\n\nr[x] { bar[x] = 100; p = 101 }`)\n\n\tmod3 := MustParseModule(`package a.b.d\n\nimport input.x as y\n\nt = true { input = {y.secret: [{y.keyid}]} }\nx = false { true }`)\n\n\tmod4 := MustParseModule(`package a.b.empty`)\n\n\tmod5 := MustParseModule(`package a.b.compr\n\nimport input.x as y\nimport data.a.b.c.q\n\np = true { [y.a | true] }\nr = true { [q.a | true] }\ns = true { [true | y.a = 0] }\nt = true { [true | q[i] = 1] }\nu = true { [true | _ = [y.a | true]] }\nv = true { [true | _ = [true | q[i] = 1]] }\n`,\n\t)\n\n\tmod6 := MustParseModule(`package a.b.nested\n\nimport data.x\nimport data.z\nimport input.x as y\n\np = true { x[y[i].a[z.b[j]]] }\nq = true { x = v; v[y[i]] }\nr = 1 { true }\ns = true { x[r] }`,\n\t)\n\n\tmod7 := MustParseModule(`package a.b.funcs\n\nfn(x) = y {\n\ttrim(x, \".\", y)\n}\n\nbar([x, y]) = [a, [b, c]] {\n\tfn(x, a)\n\ty[1].b = b\n\ty[i].a = \"hi\"\n\tc = y[i].b\n}\n\nfoorule = true {\n\tbar([\"hi.there\", [{\"a\": \"hi\", \"b\": 1}, {\"a\": \"bye\", \"b\": 0}]], [a, [b, c]])\n}`)\n\n\treturn map[string]*Module{\n\t\t\"mod1\": mod1,\n\t\t\"mod2\": mod2,\n\t\t\"mod3\": mod3,\n\t\t\"mod4\": mod4,\n\t\t\"mod5\": mod5,\n\t\t\"mod6\": mod6,\n\t\t\"mod7\": mod7,\n\t}\n}\n\nfunc compilerErrsToStringSlice(errors []*Error) []string {\n\tresult := []string{}\n\tfor _, e := range errors {\n\t\tmsg := strings.SplitN(e.Error(), \":\", 3)[2]\n\t\tresult = append(result, strings.TrimSpace(msg))\n\t}\n\tsort.Strings(result)\n\treturn result\n}\n\nfunc runQueryCompilerTest(q, pkg string, imports []string, expected interface{}) func(*testing.T) {\n\treturn func(t *testing.T) {\n\t\tt.Helper()\n\t\tc := NewCompiler().WithEnablePrintStatements(false)\n\t\tc.Compile(getCompilerTestModules())\n\t\tassertNotFailed(t, c)\n\t\tqc := c.QueryCompiler()\n\t\tquery := MustParseBody(q)\n\t\tvar qctx *QueryContext\n\n\t\tif pkg != \"\" {\n\t\t\tqctx = qctx.WithPackage(MustParsePackage(pkg))\n\t\t}\n\t\tif len(imports) != 0 {\n\t\t\tqctx = qctx.WithImports(MustParseImports(strings.Join(imports, \"\\n\")))\n\t\t}\n\n\t\tif qctx != nil {\n\t\t\tqc.WithContext(qctx)\n\t\t}\n\n\t\tswitch expected := expected.(type) {\n\t\tcase string:\n\t\t\texpectedQuery := MustParseBody(expected)\n\t\t\tresult, err := qc.Compile(query)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"Unexpected error from %v: %v\", query, err)\n\t\t\t}\n\t\t\tif !expectedQuery.Equal(result) {\n\t\t\t\tt.Fatalf(\"Expected:\\n%v\\n\\nGot:\\n%v\", expectedQuery, result)\n\t\t\t}\n\t\tcase error:\n\t\t\tresult, err := qc.Compile(query)\n\t\t\tif err == nil {\n\t\t\t\tt.Fatalf(\"Expected error from %v but got: %v\", query, result)\n\t\t\t}\n\t\t\tif !strings.Contains(err.Error(), expected.Error()) {\n\t\t\t\tt.Fatalf(\"Expected error %v but got: %v\", expected, err)\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc TestCompilerCapabilitiesExtendedWithCustomBuiltins(t *testing.T) {\n\n\tcompiler := NewCompiler().WithCapabilities(&Capabilities{\n\t\tBuiltins: []*Builtin{\n\t\t\t{\n\t\t\t\tName: \"foo\",\n\t\t\t\tDecl: types.NewFunction([]types.Type{types.N}, types.B),\n\t\t\t},\n\t\t},\n\t}).WithBuiltins(map[string]*Builtin{\n\t\t\"bar\": {\n\t\t\tName: \"bar\",\n\t\t\tDecl: types.NewFunction([]types.Type{types.N}, types.B),\n\t\t},\n\t})\n\n\tmodule1 := MustParseModule(`package test\n\n\tp { foo(1); bar(2) }`)\n\tmodule2 := MustParseModule(`package test\n\n\tp { plus(1,2,x) }`)\n\n\tcompiler.Compile(map[string]*Module{\"x\": module1})\n\tif compiler.Failed() {\n\t\tt.Fatal(\"unexpected error:\", compiler.Errors)\n\t}\n\n\tcompiler.Compile(map[string]*Module{\"x\": module2})\n\tif !compiler.Failed() {\n\t\tt.Fatal(\"expected error but got success\")\n\t}\n\n}\n\nfunc TestCompilerWithUnsafeBuiltins(t *testing.T) {\n\t// Rego includes a number of built-in functions. In some cases, you may not\n\t// want all builtins to be available to a program. This test shows how to\n\t// mark a built-in as unsafe.\n\tcompiler := NewCompiler().WithUnsafeBuiltins(map[string]struct{}{\"re_match\": {}})\n\n\t// This query should not compile because the `re_match` built-in is no\n\t// longer available.\n\t_, err := compiler.QueryCompiler().Compile(MustParseBody(`re_match(\"a\", \"a\")`))\n\tif err == nil {\n\t\tt.Fatalf(\"Expected error for unsafe built-in\")\n\t} else if !strings.Contains(err.Error(), \"unsafe built-in function\") {\n\t\tt.Fatalf(\"Expected error for unsafe built-in but got %v\", err)\n\t}\n\n\t// These modules should not compile for the same reason.\n\tmodules := map[string]*Module{\"mod1\": MustParseModule(`package a.b.c\ndeny {\n    re_match(input.user, \".*bob.*\")\n}`)}\n\tcompiler.Compile(modules)\n\tif !compiler.Failed() {\n\t\tt.Fatalf(\"Expected error for unsafe built-in\")\n\t} else if !strings.Contains(compiler.Errors[0].Error(), \"unsafe built-in function\") {\n\t\tt.Fatalf(\"Expected error for unsafe built-in but got %v\", err)\n\t}\n}\n\nfunc TestCompilerPassesTypeCheck(t *testing.T) {\n\tc := NewCompiler().\n\t\tWithCapabilities(&Capabilities{Builtins: []*Builtin{Split}})\n\t// Must compile to initialize type environment after WithCapabilities\n\tc.Compile(nil)\n\tif c.PassesTypeCheck(MustParseBody(`a = input.a; split(a, \":\", x); a0 = x[0]; a0 = null`)) {\n\t\tt.Fatal(\"Did not successfully detect a type-checking violation\")\n\t}\n}\n\nfunc TestCompilerPassesTypeCheckNegative(t *testing.T) {\n\tc := NewCompiler().\n\t\tWithCapabilities(&Capabilities{Builtins: []*Builtin{Split, StartsWith}})\n\t// Must compile to initialize type environment after WithCapabilities\n\tc.Compile(nil)\n\tif !c.PassesTypeCheck(MustParseBody(`a = input.a; split(a, \":\", x); a0 = x[0]; startswith(a0, \"foo\", true)`)) {\n\t\tt.Fatal(\"Incorrectly detected a type-checking violation\")\n\t}\n}\n\nfunc TestKeepModules(t *testing.T) {\n\n\tt.Run(\"no keep\", func(t *testing.T) {\n\t\tc := NewCompiler() // no keep is default\n\n\t\t// This one is overwritten by c.Compile()\n\t\tc.Modules[\"foo.rego\"] = MustParseModule(\"package foo\\np = true\")\n\n\t\tc.Compile(map[string]*Module{\"bar.rego\": MustParseModule(\"package bar\\np = input\")})\n\n\t\tif len(c.Errors) != 0 {\n\t\t\tt.Fatalf(\"expected no error; got %v\", c.Errors)\n\t\t}\n\n\t\tmods := c.ParsedModules()\n\t\tif mods != nil {\n\t\t\tt.Errorf(\"expected ParsedModules == nil, got %v\", mods)\n\t\t}\n\t})\n\n\tt.Run(\"keep\", func(t *testing.T) {\n\n\t\tc := NewCompiler().WithKeepModules(true)\n\n\t\t// This one is overwritten by c.Compile()\n\t\tc.Modules[\"foo.rego\"] = MustParseModule(\"package foo\\np = true\")\n\n\t\tc.Compile(map[string]*Module{\"bar.rego\": MustParseModule(\"package bar\\np = input\")})\n\t\tif len(c.Errors) != 0 {\n\t\t\tt.Fatalf(\"expected no error; got %v\", c.Errors)\n\t\t}\n\n\t\tmods := c.ParsedModules()\n\t\tif exp, act := 1, len(mods); exp != act {\n\t\t\tt.Errorf(\"expected %d modules, found %d: %v\", exp, act, mods)\n\t\t}\n\t\tfor k := range mods {\n\t\t\tif k != \"bar.rego\" {\n\t\t\t\tt.Errorf(\"unexpected key: %v, want 'bar.rego'\", k)\n\t\t\t}\n\t\t}\n\n\t\tfor k := range mods {\n\t\t\tcompiled := c.Modules[k]\n\t\t\tif compiled.Equal(mods[k]) {\n\t\t\t\tt.Errorf(\"expected module %v to not be compiled: %v\", k, mods[k])\n\t\t\t}\n\t\t}\n\n\t\t// expect ParsedModules to be reset\n\t\tc.Compile(map[string]*Module{\"baz.rego\": MustParseModule(\"package baz\\np = input\")})\n\t\tmods = c.ParsedModules()\n\t\tif exp, act := 1, len(mods); exp != act {\n\t\t\tt.Errorf(\"expected %d modules, found %d: %v\", exp, act, mods)\n\t\t}\n\t\tfor k := range mods {\n\t\t\tif k != \"baz.rego\" {\n\t\t\t\tt.Errorf(\"unexpected key: %v, want 'baz.rego'\", k)\n\t\t\t}\n\t\t}\n\n\t\tfor k := range mods {\n\t\t\tcompiled := c.Modules[k]\n\t\t\tif compiled.Equal(mods[k]) {\n\t\t\t\tt.Errorf(\"expected module %v to not be compiled: %v\", k, mods[k])\n\t\t\t}\n\t\t}\n\n\t\t// expect ParsedModules to be reset to nil\n\t\tc = c.WithKeepModules(false)\n\t\tc.Compile(map[string]*Module{\"baz.rego\": MustParseModule(\"package baz\\np = input\")})\n\t\tmods = c.ParsedModules()\n\t\tif mods != nil {\n\t\t\tt.Errorf(\"expected ParsedModules == nil, got %v\", mods)\n\t\t}\n\t})\n\n\tt.Run(\"no copies\", func(t *testing.T) {\n\t\textra := MustParseModule(\"package extra\\np = input\")\n\t\tdone := false\n\t\ttestLoader := func(map[string]*Module) (map[string]*Module, error) {\n\t\t\tif done {\n\t\t\t\treturn nil, nil\n\t\t\t}\n\t\t\tdone = true\n\t\t\treturn map[string]*Module{\"extra.rego\": extra}, nil\n\t\t}\n\n\t\tc := NewCompiler().WithModuleLoader(testLoader).WithKeepModules(true)\n\n\t\tmod := MustParseModule(\"package bar\\np = input\")\n\t\tc.Compile(map[string]*Module{\"bar.rego\": mod})\n\t\tif len(c.Errors) != 0 {\n\t\t\tt.Fatalf(\"expected no error; got %v\", c.Errors)\n\t\t}\n\n\t\tmods := c.ParsedModules()\n\t\tif exp, act := 2, len(mods); exp != act {\n\t\t\tt.Errorf(\"expected %d modules, found %d: %v\", exp, act, mods)\n\t\t}\n\t\tnewName := Var(\"q\")\n\t\tmods[\"bar.rego\"].Rules[0].Head.Name = newName\n\t\tif exp, act := newName, mod.Rules[0].Head.Name; !exp.Equal(act) {\n\t\t\tt.Errorf(\"expected modified rule name %v, found %v\", exp, act)\n\t\t}\n\t\tmods[\"extra.rego\"].Rules[0].Head.Name = newName\n\t\tif exp, act := newName, extra.Rules[0].Head.Name; !exp.Equal(act) {\n\t\t\tt.Errorf(\"expected modified rule name %v, found %v\", exp, act)\n\t\t}\n\t})\n\n\tt.Run(\"keep, with loader\", func(t *testing.T) {\n\t\textra := MustParseModule(\"package extra\\np = input\")\n\t\tdone := false\n\t\ttestLoader := func(map[string]*Module) (map[string]*Module, error) {\n\t\t\tif done {\n\t\t\t\treturn nil, nil\n\t\t\t}\n\t\t\tdone = true\n\t\t\treturn map[string]*Module{\"extra.rego\": extra}, nil\n\t\t}\n\n\t\tc := NewCompiler().WithModuleLoader(testLoader).WithKeepModules(true)\n\n\t\t// This one is overwritten by c.Compile()\n\t\tc.Modules[\"foo.rego\"] = MustParseModule(\"package foo\\np = true\")\n\n\t\tc.Compile(map[string]*Module{\"bar.rego\": MustParseModule(\"package bar\\np = input\")})\n\n\t\tif len(c.Errors) != 0 {\n\t\t\tt.Fatalf(\"expected no error; got %v\", c.Errors)\n\t\t}\n\n\t\tmods := c.ParsedModules()\n\t\tif exp, act := 2, len(mods); exp != act {\n\t\t\tt.Errorf(\"expected %d modules, found %d: %v\", exp, act, mods)\n\t\t}\n\t\tfor k := range mods {\n\t\t\tif k != \"bar.rego\" && k != \"extra.rego\" {\n\t\t\t\tt.Errorf(\"unexpected key: %v, want 'extra.rego' and 'bar.rego'\", k)\n\t\t\t}\n\t\t}\n\n\t\tfor k := range mods {\n\t\t\tcompiled := c.Modules[k]\n\t\t\tif compiled.Equal(mods[k]) {\n\t\t\t\tt.Errorf(\"expected module %v to not be compiled: %v\", k, mods[k])\n\t\t\t}\n\t\t}\n\t})\n}\n", "// Copyright 2017 The OPA Authors.  All rights reserved.\n// Use of this source code is governed by an Apache2\n// license that can be found in the LICENSE file.\n\n// nolint: goconst // string duplication is for test readability.\npackage rego\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"path/filepath\"\n\t\"reflect\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/open-policy-agent/opa/ast\"\n\t\"github.com/open-policy-agent/opa/ast/location\"\n\t\"github.com/open-policy-agent/opa/bundle\"\n\t\"github.com/open-policy-agent/opa/internal/storage/mock\"\n\t\"github.com/open-policy-agent/opa/metrics\"\n\t\"github.com/open-policy-agent/opa/storage\"\n\t\"github.com/open-policy-agent/opa/storage/inmem\"\n\t\"github.com/open-policy-agent/opa/topdown\"\n\t\"github.com/open-policy-agent/opa/topdown/builtins\"\n\t\"github.com/open-policy-agent/opa/topdown/cache\"\n\t\"github.com/open-policy-agent/opa/types\"\n\t\"github.com/open-policy-agent/opa/util\"\n\t\"github.com/open-policy-agent/opa/util/test\"\n)\n\nfunc assertEval(t *testing.T, r *Rego, expected string) {\n\tt.Helper()\n\trs, err := r.Eval(context.Background())\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\tassertResultSet(t, rs, expected)\n}\n\nfunc assertPreparedEvalQueryEval(t *testing.T, pq PreparedEvalQuery, options []EvalOption, expected string) {\n\tt.Helper()\n\trs, err := pq.Eval(context.Background(), options...)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\tassertResultSet(t, rs, expected)\n}\n\nfunc assertResultSet(t *testing.T, rs ResultSet, expected string) {\n\tt.Helper()\n\tresult := []interface{}{}\n\n\tfor i := range rs {\n\t\tvalues := []interface{}{}\n\t\tfor j := range rs[i].Expressions {\n\t\t\tvalues = append(values, rs[i].Expressions[j].Value)\n\t\t}\n\t\tresult = append(result, values)\n\t}\n\n\tif !reflect.DeepEqual(result, util.MustUnmarshalJSON([]byte(expected))) {\n\t\tt.Fatalf(\"Expected:\\n\\n%v\\n\\nGot:\\n\\n%v\", expected, result)\n\t}\n}\n\nfunc TestRegoEvalExpressionValue(t *testing.T) {\n\n\tmodule := `package test\n\n\tarr = [1,false,true]\n\tf(x) = x\n\tg(x, y) = x + y\n\th(x) = false`\n\n\ttests := []struct {\n\t\tquery    string\n\t\texpected string\n\t}{\n\t\t{\n\t\t\tquery:    \"1\",\n\t\t\texpected: \"[[1]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"1+2\",\n\t\t\texpected: \"[[3]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"1+(2*3)\",\n\t\t\texpected: \"[[7]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"data.test.arr[0]\",\n\t\t\texpected: \"[[1]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"data.test.arr[1]\",\n\t\t\texpected: \"[[false]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"data.test.f(1)\",\n\t\t\texpected: \"[[1]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"data.test.f(1,x)\",\n\t\t\texpected: \"[[true]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"data.test.g(1,2)\",\n\t\t\texpected: \"[[3]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"data.test.g(1,2,x)\",\n\t\t\texpected: \"[[true]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"false\",\n\t\t\texpected: \"[[false]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"1 == 2\",\n\t\t\texpected: \"[[false]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"data.test.h(1)\",\n\t\t\texpected: \"[[false]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"data.test.g(1,2) != 3\",\n\t\t\texpected: \"[[false]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"data.test.arr[i]\",\n\t\t\texpected: \"[[1], [true]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"[x | data.test.arr[_] = x]\",\n\t\t\texpected: \"[[[1, false, true]]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"a = 1; b = 2; a > b\",\n\t\t\texpected: `[]`,\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.query, func(t *testing.T) {\n\t\t\tr := New(\n\t\t\t\tQuery(tc.query),\n\t\t\t\tModule(\"\", module),\n\t\t\t)\n\t\t\tassertEval(t, r, tc.expected)\n\t\t})\n\t}\n}\n\nfunc TestRegoInputs(t *testing.T) {\n\ttests := map[string]struct {\n\t\tinput    interface{}\n\t\texpected string\n\t}{\n\t\t\"map\":  {map[string]bool{\"foo\": true}, `[[{\"foo\": true}]]`},\n\t\t\"int\":  {1, `[[1]]`},\n\t\t\"bool\": {false, `[[false]]`},\n\t\t\"struct\": {struct {\n\t\t\tFoo string `json:\"baz\"`\n\t\t}{\"bar\"}, `[[{\"baz\":\"bar\"}]]`},\n\t\t\"pointer to struct\": {&struct {\n\t\t\tFoo string `json:\"baz\"`\n\t\t}{\"bar\"}, `[[{\"baz\":\"bar\"}]]`},\n\t\t\"pointer to pointer to struct\": {\n\t\t\tfunc() interface{} {\n\t\t\t\ta := &struct {\n\t\t\t\t\tFoo string `json:\"baz\"`\n\t\t\t\t}{\"bar\"}\n\t\t\t\treturn &a\n\t\t\t}(), `[[{\"baz\":\"bar\"}]]`},\n\t\t\"slice\":              {[]string{\"a\", \"b\"}, `[[[\"a\", \"b\"]]]`},\n\t\t\"nil\":                {nil, `[[null]]`},\n\t\t\"slice of interface\": {[]interface{}{\"a\", 2, true}, `[[[\"a\", 2, true]]]`},\n\t}\n\n\tfor desc, tc := range tests {\n\t\tt.Run(desc, func(t *testing.T) {\n\t\t\tr := New(\n\t\t\t\tQuery(\"input\"),\n\t\t\t\tInput(tc.input),\n\t\t\t\tSchemas(nil),\n\t\t\t)\n\t\t\tassertEval(t, r, tc.expected)\n\t\t})\n\t}\n}\n\nfunc TestRegoRewrittenVarsCapture(t *testing.T) {\n\n\tctx := context.Background()\n\n\tr := New(\n\t\tQuery(\"a := 1; a != 0; a\"),\n\t)\n\n\trs, err := r.Eval(ctx)\n\tif err != nil || len(rs) != 1 {\n\t\tt.Fatalf(\"Unexpected result: %v (err: %v)\", rs, err)\n\t}\n\n\tif !reflect.DeepEqual(rs[0].Bindings[\"a\"], json.Number(\"1\")) {\n\t\tt.Fatal(\"Expected a to be 1 but got:\", rs[0].Bindings[\"a\"])\n\t}\n\n}\n\nfunc TestRegoDoNotCaptureVoidCalls(t *testing.T) {\n\n\tctx := context.Background()\n\n\tr := New(Query(\"print(1)\"))\n\n\trs, err := r.Eval(ctx)\n\tif err != nil || len(rs) != 1 {\n\t\tt.Fatal(err, \"rs:\", rs)\n\t}\n\n\tif !rs[0].Expressions[0].Value.(bool) {\n\t\tt.Fatal(\"expected expression value to be true\")\n\t}\n}\n\nfunc TestRegoCancellation(t *testing.T) {\n\n\tast.RegisterBuiltin(&ast.Builtin{\n\t\tName: \"test.sleep\",\n\t\tDecl: types.NewFunction(\n\t\t\ttypes.Args(types.S),\n\t\t\ttypes.NewNull(),\n\t\t),\n\t})\n\n\ttopdown.RegisterFunctionalBuiltin1(\"test.sleep\", func(a ast.Value) (ast.Value, error) {\n\t\td, _ := time.ParseDuration(string(a.(ast.String)))\n\t\ttime.Sleep(d)\n\t\treturn ast.Null{}, nil\n\t})\n\n\tctx, cancel := context.WithTimeout(context.Background(), time.Millisecond*50)\n\tr := New(Query(`test.sleep(\"1s\")`))\n\trs, err := r.Eval(ctx)\n\tcancel()\n\n\tif err == nil {\n\t\tt.Fatalf(\"Expected cancellation error but got: %v\", rs)\n\t}\n\texp := topdown.Error{Code: topdown.CancelErr, Message: \"caller cancelled query execution\"}\n\tif !errors.Is(err, &exp) {\n\t\tt.Errorf(\"error: expected %v, got: %v\", exp, err)\n\t}\n}\n\nfunc TestRegoCustomBuiltinHalt(t *testing.T) {\n\n\tfunOpt := Function1(\n\t\t&Function{\n\t\t\tName: \"halt_func\",\n\t\t\tDecl: types.NewFunction(\n\t\t\t\ttypes.Args(types.S),\n\t\t\t\ttypes.NewNull(),\n\t\t\t),\n\t\t},\n\t\tfunc(BuiltinContext, *ast.Term) (*ast.Term, error) {\n\t\t\treturn nil, NewHaltError(fmt.Errorf(\"stop\"))\n\t\t},\n\t)\n\tr := New(Query(`halt_func(\"\")`), funOpt)\n\trs, err := r.Eval(context.Background())\n\tif err == nil {\n\t\tt.Fatalf(\"Expected halt error but got: %v\", rs)\n\t}\n\t// exp is the error topdown returns after unwrapping the Halt\n\texp := topdown.Error{Code: topdown.BuiltinErr, Message: \"halt_func: stop\",\n\t\tLocation: location.NewLocation([]byte(`halt_func(\"\")`), \"\", 1, 1)}\n\tif !errors.Is(err, &exp) {\n\t\tt.Fatalf(\"error: expected %v, got: %v\", exp, err)\n\t}\n}\n\nfunc TestRegoMetrics(t *testing.T) {\n\tm := metrics.New()\n\tr := New(Query(\"foo = 1\"), Module(\"foo.rego\", \"package x\"), Metrics(m))\n\tctx := context.Background()\n\t_, err := r.Eval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvalidateRegoMetrics(t, m, []string{\n\t\t\"timer_rego_query_parse_ns\",\n\t\t\"timer_rego_query_eval_ns\",\n\t\t\"timer_rego_query_compile_ns\",\n\t\t\"timer_rego_module_parse_ns\",\n\t\t\"timer_rego_module_compile_ns\",\n\t})\n}\n\nfunc TestPreparedRegoMetrics(t *testing.T) {\n\tm := metrics.New()\n\tr := New(Query(\"foo = 1\"), Module(\"foo.rego\", \"package x\"), Metrics(m))\n\tctx := context.Background()\n\tpq, err := r.PrepareForEval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t_, err = pq.Eval(ctx, EvalMetrics(m))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvalidateRegoMetrics(t, m, []string{\n\t\t\"timer_rego_query_parse_ns\",\n\t\t\"timer_rego_query_eval_ns\",\n\t\t\"timer_rego_query_compile_ns\",\n\t\t\"timer_rego_module_parse_ns\",\n\t\t\"timer_rego_module_compile_ns\",\n\t})\n}\n\nfunc TestPreparedRegoMetricsPrepareOnly(t *testing.T) {\n\tm := metrics.New()\n\tr := New(Query(\"foo = 1\"), Module(\"foo.rego\", \"package x\"), Metrics(m))\n\tctx := context.Background()\n\tpq, err := r.PrepareForEval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t_, err = pq.Eval(ctx) // No EvalMetrics() passed in\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvalidateRegoMetrics(t, m, []string{\n\t\t\"timer_rego_query_parse_ns\",\n\t\t\"timer_rego_query_compile_ns\",\n\t\t\"timer_rego_module_parse_ns\",\n\t\t\"timer_rego_module_compile_ns\",\n\t})\n}\n\nfunc TestPreparedRegoMetricsEvalOnly(t *testing.T) {\n\tm := metrics.New()\n\tr := New(Query(\"foo = 1\"), Module(\"foo.rego\", \"package x\")) // No Metrics() passed in\n\tctx := context.Background()\n\tpq, err := r.PrepareForEval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t_, err = pq.Eval(ctx, EvalMetrics(m))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvalidateRegoMetrics(t, m, []string{\n\t\t\"timer_rego_query_eval_ns\",\n\t})\n}\n\nfunc validateRegoMetrics(t *testing.T, m metrics.Metrics, expectedFields []string) {\n\tt.Helper()\n\n\tall := m.All()\n\n\tfor _, name := range expectedFields {\n\t\tvalue, ok := all[name]\n\t\tif !ok {\n\t\t\tt.Errorf(\"expected to find %v but did not\", name)\n\t\t}\n\t\tif value.(int64) == 0 {\n\t\t\tt.Errorf(\"expected metric %v to have some non-zero value, but found 0\", name)\n\t\t}\n\t}\n}\n\nfunc TestRegoInstrumentExtraEvalCompilerStage(t *testing.T) {\n\tm := metrics.New()\n\tr := New(Query(\"foo = 1\"), Module(\"foo.rego\", \"package x\"), Metrics(m), Instrument(true))\n\tctx := context.Background()\n\t_, err := r.Eval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\texp := []string{\n\t\t\"timer_query_compile_stage_rewrite_to_capture_value_ns\",\n\t}\n\n\tall := m.All()\n\n\tfor _, name := range exp {\n\t\tif _, ok := all[name]; !ok {\n\t\t\tt.Errorf(\"expected to find %v but did not\", name)\n\t\t}\n\t}\n}\n\nfunc TestPreparedRegoInstrumentExtraEvalCompilerStage(t *testing.T) {\n\tm := metrics.New()\n\tr := New(Query(\"foo = 1\"), Module(\"foo.rego\", \"package x\"), Metrics(m), Instrument(true))\n\tctx := context.Background()\n\tpq, err := r.PrepareForEval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// No metrics flag is passed in, should not affect results for compiler stage\n\t// but expect to turn off instrumentation for evaluation.\n\t_, err = pq.Eval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\texp := []string{\n\t\t\"timer_query_compile_stage_rewrite_to_capture_value_ns\",\n\t}\n\n\tnExp := []string{\n\t\t\"timer_eval_op_plug_ns\", // We should *not* see the eval timers\n\t}\n\n\tall := m.All()\n\n\tfor _, name := range exp {\n\t\tif _, ok := all[name]; !ok {\n\t\t\tt.Errorf(\"expected to find %v but did not\", name)\n\t\t}\n\t}\n\n\tfor _, name := range nExp {\n\t\tif _, ok := all[name]; ok {\n\t\t\tt.Errorf(\"did not expect to find %v\", name)\n\t\t}\n\t}\n}\n\nfunc TestRegoInstrumentExtraPartialCompilerStage(t *testing.T) {\n\tm := metrics.New()\n\tr := New(Query(\"foo = 1\"), Module(\"foo.rego\", \"package x\"), Metrics(m), Instrument(true))\n\tctx := context.Background()\n\t_, err := r.Partial(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\texp := []string{\n\t\t\"timer_query_compile_stage_rewrite_equals_ns\",\n\t}\n\n\tall := m.All()\n\n\tfor _, name := range exp {\n\t\tif _, ok := all[name]; !ok {\n\t\t\tt.Errorf(\"Expected to find %v but did not\", name)\n\t\t}\n\t}\n}\n\nfunc TestRegoInstrumentExtraPartialResultCompilerStage(t *testing.T) {\n\tm := metrics.New()\n\tr := New(Query(\"input.x\"), Module(\"foo.rego\", \"package x\"), Metrics(m), Instrument(true))\n\tctx := context.Background()\n\t_, err := r.PartialResult(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\texp := []string{\n\t\t\"timer_query_compile_stage_rewrite_for_partial_eval_ns\",\n\t}\n\n\tall := m.All()\n\n\tfor _, name := range exp {\n\t\tif _, ok := all[name]; !ok {\n\t\t\tt.Errorf(\"Expected to find '%v' in metrics\\n\\nActual:\\n %+v\", name, all)\n\t\t}\n\t}\n}\n\nfunc TestPreparedRegoTracerNoPropagate(t *testing.T) {\n\ttracer := topdown.NewBufferTracer()\n\tmod := `\n\tpackage test\n\n\tp = {\n\t\tinput.x == 10\n\t}\n\t`\n\tpq, err := New(\n\t\tQuery(\"data\"),\n\t\tModule(\"foo.rego\", mod),\n\t\tTracer(tracer),\n\t\tInput(map[string]interface{}{\"x\": 10})).PrepareForEval(context.Background())\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error %s\", err)\n\t}\n\n\t_, err = pq.Eval(context.Background()) // no EvalTracer option\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error %s\", err)\n\t}\n\n\tif len(*tracer) > 0 {\n\t\tt.Fatal(\"expected 0 traces to be collected\")\n\t}\n}\n\nfunc TestPreparedRegoQueryTracerNoPropagate(t *testing.T) {\n\ttracer := topdown.NewBufferTracer()\n\tmod := `\n\tpackage test\n\n\tp = {\n\t\tinput.x == 10\n\t}\n\t`\n\tpq, err := New(\n\t\tQuery(\"data\"),\n\t\tModule(\"foo.rego\", mod),\n\t\tQueryTracer(tracer),\n\t\tInput(map[string]interface{}{\"x\": 10})).PrepareForEval(context.Background())\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error %s\", err)\n\t}\n\n\t_, err = pq.Eval(context.Background()) // no EvalQueryTracer option\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error %s\", err)\n\t}\n\n\tif len(*tracer) > 0 {\n\t\tt.Fatal(\"expected 0 traces to be collected\")\n\t}\n}\n\nfunc TestRegoDisableIndexing(t *testing.T) {\n\ttracer := topdown.NewBufferTracer()\n\tmod := `\n\tpackage test\n\n\tp {\n\t\tinput.x = 1\n\t}\n\n\tp {\n\t\tinput.y = 1\n\t}\n\t`\n\tpq, err := New(\n\t\tQuery(\"data\"),\n\t\tModule(\"foo.rego\", mod),\n\t).PrepareForEval(context.Background())\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error %s\", err)\n\t}\n\n\t_, err = pq.Eval(\n\t\tcontext.Background(),\n\t\tEvalQueryTracer(tracer),\n\t\tEvalRuleIndexing(false),\n\t\tEvalInput(map[string]interface{}{\"x\": 10}),\n\t)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error %s\", err)\n\t}\n\n\tvar evalNodes []string\n\tfor _, e := range *tracer {\n\t\tif e.Op == topdown.EvalOp {\n\t\t\tevalNodes = append(evalNodes, string(e.Node.Loc().Text))\n\t\t}\n\t}\n\n\texpectedEvalNodes := []string{\n\t\t\"input.x = 1\",\n\t\t\"input.y = 1\",\n\t}\n\n\tfor _, expected := range expectedEvalNodes {\n\t\tfound := false\n\t\tfor _, actual := range evalNodes {\n\t\t\tif actual == expected {\n\t\t\t\tfound = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif !found {\n\t\t\tt.Fatalf(\"Missing expected eval node in trace: %q\\nGot: %q\\n\", expected, evalNodes)\n\t\t}\n\t}\n}\n\nfunc TestRegoCatchPathConflicts(t *testing.T) {\n\tr := New(\n\t\tQuery(\"data\"),\n\t\tModule(\"test.rego\", \"package x\\np=1\"),\n\t\tStore(inmem.NewFromObject(map[string]interface{}{\n\t\t\t\"x\": map[string]interface{}{\"p\": 1},\n\t\t})),\n\t)\n\n\tctx := context.Background()\n\t_, err := r.Eval(ctx)\n\n\tif err == nil {\n\t\tt.Fatal(\"expected error\")\n\t}\n}\n\nfunc TestPartialRewriteEquals(t *testing.T) {\n\tmod := `\n\tpackage test\n\tdefault p = false\n\tp {\n\t\tinput.x = 1\n\t}\n\t`\n\tr := New(\n\t\tQuery(\"data.test.p == true\"),\n\t\tModule(\"test.rego\", mod),\n\t)\n\n\tctx := context.Background()\n\tpq, err := r.Partial(ctx)\n\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error from Rego.Partial(): %s\", err.Error())\n\t}\n\n\t// Expect to not have any \"support\" in the resulting queries\n\tif len(pq.Support) > 0 {\n\t\tt.Errorf(\"expected to not have any Support in PartialQueries: %+v\", pq)\n\t}\n\n\texpectedQuery := \"input.x = 1\"\n\tif len(pq.Queries) != 1 {\n\t\tt.Errorf(\"expected 1 query but found %d: %+v\", len(pq.Queries), pq)\n\t}\n\tif pq.Queries[0].String() != expectedQuery {\n\t\tt.Errorf(\"unexpected query in result, expected='%s' found='%s'\",\n\t\t\texpectedQuery, pq.Queries[0].String())\n\t}\n}\n\n// NOTE(sr): https://github.com/open-policy-agent/opa/issues/4345\nfunc TestPrepareAndEvalRaceConditions(t *testing.T) {\n\ttests := []struct {\n\t\tnote   string\n\t\tmodule string\n\t\texp    string\n\t}{\n\t\t{\n\t\t\tnote: \"object\",\n\t\t\tmodule: `package test\n\t\t\tp[{\"x\":\"y\"}]`,\n\t\t\texp: `[[[{\"x\":\"y\"}]]]`,\n\t\t},\n\t\t{\n\t\t\tnote: \"set\",\n\t\t\tmodule: `package test\n\t\t\tp[{\"x\"}]`,\n\t\t\texp: `[[[[\"x\"]]]]`,\n\t\t},\n\t\t{\n\t\t\tnote: \"array\",\n\t\t\tmodule: `package test\n\t\t\tp[[\"x\"]]`,\n\t\t\texp: `[[[[\"x\"]]]]`,\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tr := New(\n\t\t\t\tQuery(\"data.test.p\"),\n\t\t\t\tModule(\"\", tc.module),\n\t\t\t\tPackage(\"foo\"),\n\t\t\t)\n\n\t\t\tpq, err := r.PrepareForEval(context.Background())\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t\t\t}\n\n\t\t\t// run this 1000 times concurrently\n\t\t\tvar wg sync.WaitGroup\n\t\t\twg.Add(1000)\n\t\t\tfor i := 0; i < 1000; i++ {\n\t\t\t\tgo func(t *testing.T) {\n\t\t\t\t\tt.Helper()\n\t\t\t\t\tassertPreparedEvalQueryEval(t, pq, []EvalOption{}, tc.exp)\n\t\t\t\t\twg.Done()\n\t\t\t\t}(t)\n\t\t\t}\n\t\t\twg.Wait()\n\t\t})\n\t}\n}\n\nfunc TestPrepareAndEvalNewInput(t *testing.T) {\n\tmodule := `\n\tpackage test\n\tx = input.y\n\t`\n\n\tr := New(\n\t\tQuery(\"data.test.x\"),\n\t\tModule(\"\", module),\n\t\tPackage(\"foo\"),\n\t)\n\n\tpq, err := r.PrepareForEval(context.Background())\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{\n\t\tEvalInput(map[string]int{\"y\": 1}),\n\t}, \"[[1]]\")\n}\n\nfunc TestPrepareAndEvalNewMetrics(t *testing.T) {\n\tmodule := `\n\tpackage test\n\tx = input.y\n\t`\n\n\toriginalMetrics := metrics.New()\n\n\tr := New(\n\t\tQuery(\"data.test.x\"),\n\t\tModule(\"\", module),\n\t\tPackage(\"foo\"),\n\t\tMetrics(originalMetrics),\n\t)\n\n\tpq, err := r.PrepareForEval(context.Background())\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\n\tif len(originalMetrics.All()) == 0 {\n\t\tt.Errorf(\"Expected metrics stored on 'originalMetrics' after Prepare()\")\n\t}\n\n\t// Reset the original ones (for testing)\n\t// and make a new one for the Eval\n\toriginalMetrics.Clear()\n\tnewMetrics := metrics.New()\n\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{\n\t\tEvalInput(map[string]int{\"y\": 1}),\n\t\tEvalMetrics(newMetrics),\n\t}, \"[[1]]\")\n\n\tif len(originalMetrics.All()) > 0 {\n\t\tt.Errorf(\"Expected no metrics stored on original Rego object metrics but found: %s\",\n\t\t\toriginalMetrics.All())\n\t}\n\n\tif len(newMetrics.All()) == 0 {\n\t\tt.Errorf(\"Expected metrics stored on 'newMetrics' after Prepare()\")\n\t}\n}\n\nfunc TestPrepareAndEvalTransaction(t *testing.T) {\n\tmodule := `\n\tpackage test\n\tx = data.foo.y\n\t`\n\tctx := context.Background()\n\tstore := mock.New()\n\ttxn := storage.NewTransactionOrDie(ctx, store, storage.WriteParams)\n\n\tpath, ok := storage.ParsePath(\"/foo\")\n\tif !ok {\n\t\tt.Fatalf(\"Unexpected error parsing path\")\n\t}\n\n\terr := storage.MakeDir(ctx, store, txn, path)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error writing to store: %s\", err.Error())\n\t}\n\n\terr = store.Write(ctx, txn, storage.AddOp, path, map[string]interface{}{\"y\": 1})\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error writing to store: %s\", err.Error())\n\t}\n\n\tr := New(\n\t\tQuery(\"data.test.x\"),\n\t\tModule(\"\", module),\n\t\tStore(store),\n\t\tTransaction(txn),\n\t)\n\n\tpq, err := r.PrepareForEval(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\n\t// Base case, expect it to use the transaction provided\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{EvalTransaction(txn)}, \"[[1]]\")\n\n\tmockTxn := store.GetTransaction(txn.ID())\n\tfor _, read := range store.Reads {\n\t\tif read.Transaction != mockTxn {\n\t\t\tt.Errorf(\"Found read operation with an invalid transaction, expected: %d, found: %d\", mockTxn.ID(), read.Transaction.ID())\n\t\t}\n\t}\n\n\tstore.AssertValid(t)\n\tstore.Reset()\n\n\t// Case with an update to the store and a new transaction\n\ttxn = storage.NewTransactionOrDie(ctx, store, storage.WriteParams)\n\terr = store.Write(ctx, txn, storage.AddOp, path, map[string]interface{}{\"y\": 2})\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error writing to store: %s\", err.Error())\n\t}\n\n\t// Expect the new result from the updated value on this transaction\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{EvalTransaction(txn)}, \"[[2]]\")\n\n\terr = store.Commit(ctx, txn)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error committing to store: %s\", err)\n\t}\n\n\tnewMockTxn := store.GetTransaction(txn.ID())\n\tfor _, read := range store.Reads {\n\t\tif read.Transaction != newMockTxn {\n\t\t\tt.Errorf(\"Found read operation with an invalid transaction, expected: %d, found: %d\", mockTxn.ID(), read.Transaction.ID())\n\t\t}\n\t}\n\n\tstore.AssertValid(t)\n\tstore.Reset()\n\n\t// Case with no transaction provided, should create a new one and see the latest value\n\ttxn = storage.NewTransactionOrDie(ctx, store, storage.WriteParams)\n\terr = store.Write(ctx, txn, storage.AddOp, path, map[string]interface{}{\"y\": 3})\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error writing to store: %s\", err.Error())\n\t}\n\terr = store.Commit(ctx, txn)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error committing to store: %s\", err)\n\t}\n\n\tassertPreparedEvalQueryEval(t, pq, nil, \"[[3]]\")\n\n\tif len(store.Transactions) != 2 {\n\t\tt.Fatalf(\"Expected only two transactions on store, found %d\", len(store.Transactions))\n\t}\n\n\tautoTxn := store.Transactions[1]\n\tfor _, read := range store.Reads {\n\t\tif read.Transaction != autoTxn {\n\t\t\tt.Errorf(\"Found read operation with an invalid transaction, expected: %d, found: %d\", autoTxn, read.Transaction.ID())\n\t\t}\n\t}\n\tstore.AssertValid(t)\n\n}\n\nfunc TestPrepareAndEvalIdempotent(t *testing.T) {\n\tmodule := `\n\tpackage test\n\tx = input.y\n\t`\n\n\tr := New(\n\t\tQuery(\"data.test.x\"),\n\t\tModule(\"\", module),\n\t\tPackage(\"foo\"),\n\t)\n\n\tpq, err := r.PrepareForEval(context.Background())\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\n\t// Expect evaluating the same thing >1 time gives the same\n\t// results each time.\n\tfor i := 0; i < 5; i++ {\n\t\tassertPreparedEvalQueryEval(t, pq, []EvalOption{\n\t\t\tEvalInput(map[string]int{\"y\": 1}),\n\t\t}, \"[[1]]\")\n\t}\n}\n\nfunc TestPrepareAndEvalOriginal(t *testing.T) {\n\tmodule := `\n\tpackage test\n\tx = input.y\n\t`\n\n\tr := New(\n\t\tQuery(\"data.test.x\"),\n\t\tModule(\"\", module),\n\t\tPackage(\"foo\"),\n\t\tInput(map[string]int{\"y\": 2}),\n\t)\n\n\tpq, err := r.PrepareForEval(context.Background())\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{\n\t\tEvalInput(map[string]int{\"y\": 1}),\n\t}, \"[[1]]\")\n\n\t// Even after prepare and eval with different input\n\t// expect that the original Rego object behaves\n\t// as expected for Eval.\n\n\tassertEval(t, r, \"[[2]]\")\n}\n\nfunc TestPrepareAndEvalNewPrintHook(t *testing.T) {\n\tmodule := `\n\tpackage test\n\tx { print(input) }\n\t`\n\n\tr := New(\n\t\tQuery(\"data.test.x\"),\n\t\tModule(\"\", module),\n\t\tPackage(\"foo\"),\n\t\tEnablePrintStatements(true),\n\t)\n\n\tpq, err := r.PrepareForEval(context.Background())\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\n\tvar buf0 bytes.Buffer\n\tph0 := topdown.NewPrintHook(&buf0)\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{\n\t\tEvalInput(\"hello\"),\n\t\tEvalPrintHook(ph0),\n\t}, \"[[true]]\")\n\n\tif exp, act := \"hello\\n\", buf0.String(); exp != act {\n\t\tt.Fatalf(\"print hook, expected %q, got %q\", exp, act)\n\t}\n\n\t// repeat\n\tvar buf1 bytes.Buffer\n\tph1 := topdown.NewPrintHook(&buf1)\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{\n\t\tEvalInput(\"world\"),\n\t\tEvalPrintHook(ph1),\n\t}, \"[[true]]\")\n\n\tif exp, act := \"world\\n\", buf1.String(); exp != act {\n\t\tt.Fatalf(\"print hook, expected %q, got %q\", exp, act)\n\t}\n}\n\nfunc TestPrepareAndPartialResult(t *testing.T) {\n\tmodule := `\n\tpackage test\n\tx = input.y\n\t`\n\n\tr := New(\n\t\tQuery(\"data.test.x\"),\n\t\tModule(\"\", module),\n\t\tPackage(\"foo\"),\n\t\tInput(map[string]int{\"y\": 2}),\n\t)\n\n\tctx := context.Background()\n\n\tpq, err := r.PrepareForEval(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{\n\t\tEvalInput(map[string]int{\"y\": 1}),\n\t}, \"[[1]]\")\n\n\t// Even after prepare and eval with different input\n\t// expect that the original Rego object behaves\n\t// as expected for PartialResult.\n\n\tpartial, err := r.PartialResult(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tr2 := partial.Rego(\n\t\tInput(map[string]int{\"y\": 7}),\n\t)\n\tassertEval(t, r2, \"[[7]]\")\n}\n\nfunc TestPrepareWithPartialEval(t *testing.T) {\n\tmodule := `\n\tpackage test\n\tx = input.y\n\t`\n\n\tr := New(\n\t\tQuery(\"data.test.x\"),\n\t\tModule(\"\", module),\n\t\tPackage(\"foo\"),\n\t)\n\n\tctx := context.Background()\n\n\t// Prepare the query and partially evaluate it\n\tpq, err := r.PrepareForEval(ctx, WithPartialEval())\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{\n\t\tEvalInput(map[string]int{\"y\": 1}),\n\t}, \"[[1]]\")\n}\n\nfunc TestPrepareAndPartial(t *testing.T) {\n\tmod := `\n\tpackage test\n\tdefault p = false\n\tp {\n\t\tinput.x = 1\n\t}\n\t`\n\tr := New(\n\t\tQuery(\"data.test.p == true\"),\n\t\tModule(\"test.rego\", mod),\n\t)\n\n\tctx := context.Background()\n\n\tpq, err := r.PrepareForEval(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{\n\t\tEvalInput(map[string]int{\"x\": 1}),\n\t}, \"[[true]]\")\n\n\t// Even after prepare and eval with different input\n\t// expect that the original Rego object behaves\n\t// as expected for Partial.\n\n\tpartialQuery, err := r.Partial(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\texpectedQuery := \"input.x = 1\"\n\tif len(partialQuery.Queries) != 1 {\n\t\tt.Errorf(\"expected 1 query but found %d: %+v\", len(partialQuery.Queries), pq)\n\t}\n\tif partialQuery.Queries[0].String() != expectedQuery {\n\t\tt.Errorf(\"unexpected query in result, expected='%s' found='%s'\",\n\t\t\texpectedQuery, partialQuery.Queries[0].String())\n\t}\n}\n\nfunc TestPartialNamespace(t *testing.T) {\n\n\tr := New(\n\t\tPartialNamespace(\"foo\"),\n\t\tQuery(\"data.test.p = x\"),\n\t\tModule(\"test.rego\", `\n\t\t\tpackage test\n\n\t\t\tdefault p = false\n\n\t\t\tp { input.x = 1 }\n\t\t`),\n\t)\n\n\tpq, err := r.Partial(context.Background())\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\texpQuery := ast.MustParseBody(`data.foo.test.p = x`)\n\n\tif len(pq.Queries) != 1 || !pq.Queries[0].Equal(expQuery) {\n\t\tt.Fatalf(\"Expected exactly one query %v but got: %v\", expQuery, pq.Queries)\n\t}\n\n\texpSupport := ast.MustParseModule(`\n\t\tpackage foo.test\n\n\t\tdefault p = false\n\n\t\tp { input.x = 1 }\n\t`)\n\n\tif len(pq.Support) != 1 || !pq.Support[0].Equal(expSupport) {\n\t\tt.Fatalf(\"Expected exactly one support:\\n\\n%v\\n\\nGot:\\n\\n%v\", expSupport, pq.Support[0])\n\t}\n}\n\nfunc TestPrepareAndCompile(t *testing.T) {\n\tmodule := `\n\tpackage test\n\tx = input.y\n\t`\n\n\tr := New(\n\t\tQuery(\"data.test.x\"),\n\t\tModule(\"\", module),\n\t\tPackage(\"foo\"),\n\t)\n\n\tctx := context.Background()\n\n\tpq, err := r.PrepareForEval(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{\n\t\tEvalInput(map[string]int{\"y\": 1}),\n\t}, \"[[1]]\")\n\n\t// Ensure that Compile still works after Prepare\n\t// and its Eval has been called.\n\t_, err = r.Compile(ctx)\n\tif err != nil {\n\t\tt.Errorf(\"Unexpected error when compiling: %s\", err.Error())\n\t}\n}\n\nfunc TestPartialResultWithInput(t *testing.T) {\n\tmod := `\n\tpackage test\n\tdefault p = false\n\tp {\n\t\tinput.x == 1\n\t}\n\t`\n\tr := New(\n\t\tQuery(\"data.test.p\"),\n\t\tModule(\"test.rego\", mod),\n\t)\n\n\tctx := context.Background()\n\tpr, err := r.PartialResult(ctx)\n\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error from Rego.PartialResult(): %s\", err.Error())\n\t}\n\n\tr2 := pr.Rego(\n\t\tInput(map[string]int{\"x\": 1}),\n\t)\n\n\tassertEval(t, r2, \"[[true]]\")\n}\n\nfunc TestPartialResultWithNamespace(t *testing.T) {\n\tmod := `\n\tpackage test\n\tp {\n\t\ttrue\n\t}\n\t`\n\tc := ast.NewCompiler()\n\tr := New(\n\t\tQuery(\"data.test.p\"),\n\t\tModule(\"test.rego\", mod),\n\t\tPartialNamespace(\"test_ns1\"),\n\t\tCompiler(c),\n\t)\n\n\tctx := context.Background()\n\tpr, err := r.PartialResult(ctx)\n\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error from Rego.PartialResult(): %s\", err.Error())\n\t}\n\n\texpectedQuery := \"data.test_ns1.__result__\"\n\tif pr.body.String() != expectedQuery {\n\t\tt.Fatalf(\"Expected partial result query %s got %s\", expectedQuery, pr.body)\n\t}\n\n\tr2 := pr.Rego()\n\n\tassertEval(t, r2, \"[[true]]\")\n\n\tif len(c.Modules) != 2 {\n\t\tt.Fatalf(\"Expected two modules on the compiler, got: %v\", c.Modules)\n\t}\n\n\texpectedModuleID := \"__partialresult__test_ns1__\"\n\tif _, ok := c.Modules[expectedModuleID]; !ok {\n\t\tt.Fatalf(\"Expected to find module %s in compiler Modules, got: %v\", expectedModuleID, c.Modules)\n\t}\n}\n\nfunc TestPreparedPartialResultWithTracer(t *testing.T) {\n\tmod := `\n\tpackage test\n\tdefault p = false\n\tp {\n\t\tinput.x = 1\n\t}\n\t`\n\tr := New(\n\t\tQuery(\"data.test.p == true\"),\n\t\tModule(\"test.rego\", mod),\n\t)\n\n\ttracer := topdown.NewBufferTracer()\n\n\tctx := context.Background()\n\tpq, err := r.PrepareForPartial(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error from Rego.PrepareForPartial(): %s\", err.Error())\n\t}\n\n\tpqs, err := pq.Partial(ctx, EvalTracer(tracer))\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error from PreparedEvalQuery.Partial(): %s\", err.Error())\n\t}\n\n\texpectedQuery := \"input.x = 1\"\n\tif len(pqs.Queries) != 1 {\n\t\tt.Errorf(\"expected 1 query but found %d: %+v\", len(pqs.Queries), pqs)\n\t}\n\tif pqs.Queries[0].String() != expectedQuery {\n\t\tt.Errorf(\"unexpected query in result, expected='%s' found='%s'\",\n\t\t\texpectedQuery, pqs.Queries[0].String())\n\t}\n\n\tif len(*tracer) == 0 {\n\t\tt.Errorf(\"Expected buffer tracer to contain > 0 traces\")\n\t}\n}\n\nfunc TestPreparedPartialResultWithQueryTracer(t *testing.T) {\n\tmod := `\n\tpackage test\n\tdefault p = false\n\tp {\n\t\tinput.x = 1\n\t}\n\t`\n\tr := New(\n\t\tQuery(\"data.test.p == true\"),\n\t\tModule(\"test.rego\", mod),\n\t)\n\n\ttracer := topdown.NewBufferTracer()\n\n\tctx := context.Background()\n\tpq, err := r.PrepareForPartial(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error from Rego.PrepareForPartial(): %s\", err.Error())\n\t}\n\n\tpqs, err := pq.Partial(ctx, EvalQueryTracer(tracer))\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error from PreparedEvalQuery.Partial(): %s\", err.Error())\n\t}\n\n\texpectedQuery := \"input.x = 1\"\n\tif len(pqs.Queries) != 1 {\n\t\tt.Errorf(\"expected 1 query but found %d: %+v\", len(pqs.Queries), pqs)\n\t}\n\tif pqs.Queries[0].String() != expectedQuery {\n\t\tt.Errorf(\"unexpected query in result, expected='%s' found='%s'\",\n\t\t\texpectedQuery, pqs.Queries[0].String())\n\t}\n\n\tif len(*tracer) == 0 {\n\t\tt.Errorf(\"Expected buffer tracer to contain > 0 traces\")\n\t}\n}\n\nfunc TestPartialResultSetsValidConflictChecker(t *testing.T) {\n\tmod := `\n\tpackage test\n\tp {\n\t\ttrue\n\t}\n\t`\n\n\tc := ast.NewCompiler().WithPathConflictsCheck(func(_ []string) (bool, error) {\n\t\tt.Fatal(\"Conflict check should not have been called\")\n\t\treturn false, nil\n\t})\n\n\tr := New(\n\t\tQuery(\"data.test.p\"),\n\t\tModule(\"test.rego\", mod),\n\t\tPartialNamespace(\"test_ns1\"),\n\t\tCompiler(c),\n\t)\n\n\tctx := context.Background()\n\tpr, err := r.PartialResult(ctx)\n\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error from Rego.PartialResult(): %s\", err.Error())\n\t}\n\n\tr2 := pr.Rego()\n\n\tassertEval(t, r2, \"[[true]]\")\n}\n\nfunc TestMissingLocation(t *testing.T) {\n\n\t// Create a query programmatically and evaluate it. The Location information\n\t// is not set so the resulting expression value will not have it.\n\tr := New(ParsedQuery(ast.NewBody(ast.NewExpr(ast.BooleanTerm(true)))))\n\trs, err := r.Eval(context.Background())\n\n\tif err != nil {\n\t\tt.Fatal(err)\n\t} else if len(rs) == 0 || !rs[0].Expressions[0].Value.(bool) {\n\t\tt.Fatal(\"Unexpected result set:\", rs)\n\t}\n\n\tif rs[0].Expressions[0].Location != nil {\n\t\tt.Fatal(\"Expected location data to be unset.\")\n\t}\n}\n\nfunc TestBundlePassing(t *testing.T) {\n\n\topaBundle := bundle.Bundle{\n\t\tModules: []bundle.ModuleFile{\n\t\t\t{\n\t\t\t\tPath: \"policy.rego\",\n\t\t\t\tParsed: ast.MustParseModule(`package foo\n                         allow = true`),\n\t\t\t\tRaw: []byte(`package foo\n                         allow = true`),\n\t\t\t},\n\t\t},\n\t\tManifest: bundle.Manifest{Revision: \"test\", Roots: &[]string{\"/\"}},\n\t}\n\n\t// Pass a bundle\n\tr := New(\n\t\tParsedBundle(\"123\", &opaBundle),\n\t\tQuery(\"x = data.foo.allow\"),\n\t)\n\n\tres, err := r.Eval(context.Background())\n\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tassertResultSet(t, res, `[[true]]`)\n}\n\nfunc TestModulePassing(t *testing.T) {\n\n\t// This module will not be loaded since it has the same filename as the\n\t// file2.rego below and the raw modules override parsed modules.\n\tmodule1, err := ast.ParseModule(\"file2.rego\", `package file2\n\n\tp = \"deadbeef\"\n\t`)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tr := New(\n\t\tQuery(\"data\"),\n\t\tModule(\"file1.rego\", `package file1\n\n\t\tp = 1\n\t\t`),\n\t\tModule(\"file2.rego\", `package file2\n\n\t\tp = 2`),\n\t\tParsedModule(module1),\n\t\tParsedModule(ast.MustParseModule(`package file4\n\n\t\tp = 4`)),\n\t)\n\n\trs, err := r.Eval(context.Background())\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\texp := util.MustUnmarshalJSON([]byte(`\n\t{\n\t\t\"file1\": {\n\t\t\t\"p\": 1\n\t\t},\n\t\t\"file2\": {\n\t\t\t\"p\": 2\n\t\t},\n\t\t\"file4\": {\n\t\t\t\"p\": 4\n\t\t}\n\t}\n\t`))\n\n\tif !reflect.DeepEqual(rs[0].Expressions[0].Value, exp) {\n\t\tt.Fatalf(\"Expected %v but got %v\", exp, rs[0].Expressions[0].Value)\n\t}\n}\n\nfunc TestUnsafeBuiltins(t *testing.T) {\n\n\tctx := context.Background()\n\n\tunsafeCountExpr := \"unsafe built-in function calls in expression: count\"\n\n\tt.Run(\"unsafe query\", func(t *testing.T) {\n\t\tr := New(\n\t\t\tQuery(`count([1, 2, 3])`),\n\t\t\tUnsafeBuiltins(map[string]struct{}{\"count\": {}}),\n\t\t)\n\t\tif _, err := r.Eval(ctx); err == nil || !strings.Contains(err.Error(), unsafeCountExpr) {\n\t\t\tt.Fatalf(\"Expected unsafe built-in error but got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"unsafe module\", func(t *testing.T) {\n\t\tr := New(\n\t\t\tQuery(`data.pkg.deny`),\n\t\t\tModule(\"pkg.rego\", `package pkg\n\t\t\tdeny {\n\t\t\t\tcount(input.requests) > 10\n\t\t\t}\n\t\t\t`),\n\t\t\tUnsafeBuiltins(map[string]struct{}{\"count\": {}}),\n\t\t)\n\t\tif _, err := r.Eval(ctx); err == nil || !strings.Contains(err.Error(), unsafeCountExpr) {\n\t\t\tt.Fatalf(\"Expected unsafe built-in error but got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"inherit in query\", func(t *testing.T) {\n\t\tr := New(\n\t\t\tCompiler(ast.NewCompiler().WithUnsafeBuiltins(map[string]struct{}{\"count\": {}})),\n\t\t\tQuery(\"count([])\"),\n\t\t)\n\t\tif _, err := r.Eval(ctx); err == nil || !strings.Contains(err.Error(), unsafeCountExpr) {\n\t\t\tt.Fatalf(\"Expected unsafe built-in error but got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"override/disable in query\", func(t *testing.T) {\n\t\tr := New(\n\t\t\tCompiler(ast.NewCompiler().WithUnsafeBuiltins(map[string]struct{}{\"count\": {}})),\n\t\t\tUnsafeBuiltins(map[string]struct{}{}),\n\t\t\tQuery(\"count([])\"),\n\t\t)\n\t\tif _, err := r.Eval(ctx); err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t})\n\n\tt.Run(\"override/change in query\", func(t *testing.T) {\n\t\tr := New(\n\t\t\tCompiler(ast.NewCompiler().WithUnsafeBuiltins(map[string]struct{}{\"count\": {}})),\n\t\t\tUnsafeBuiltins(map[string]struct{}{\"max\": {}}),\n\t\t\tQuery(\"count([]); max([1,2])\"),\n\t\t)\n\n\t\t_, err := r.Eval(ctx)\n\t\tif err == nil || err.Error() != \"1 error occurred: 1:12: rego_type_error: unsafe built-in function calls in expression: max\" {\n\t\t\tt.Fatalf(\"expected error for max but got: %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"ignore if given compiler\", func(t *testing.T) {\n\t\tr := New(\n\t\t\tCompiler(ast.NewCompiler()),\n\t\t\tUnsafeBuiltins(map[string]struct{}{\"count\": {}}),\n\t\t\tQuery(\"data.test.p = 0\"),\n\t\t\tModule(\"test.rego\", `package test\n\n\t\t\tp = count([])`),\n\t\t)\n\t\trs, err := r.Eval(context.Background())\n\t\tif err != nil || len(rs) != 1 {\n\t\t\tlog.Fatalf(\"Unexpected error or result. Result: %v. Error: %v\", rs, err)\n\t\t}\n\t})\n}\n\nfunc TestPreparedQueryGetModules(t *testing.T) {\n\tmods := map[string]string{\n\t\t\"a.rego\": \"package a\\np = 1\",\n\t\t\"b.rego\": \"package b\\nq = 1\",\n\t\t\"c.rego\": \"package c\\nr = 1\",\n\t}\n\n\tvar regoArgs []func(r *Rego)\n\n\tfor name, mod := range mods {\n\t\tregoArgs = append(regoArgs, Module(name, mod))\n\t}\n\n\tregoArgs = append(regoArgs, Query(\"data\"))\n\n\tctx := context.Background()\n\tpq, err := New(regoArgs...).PrepareForEval(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t}\n\n\tactualMods := pq.Modules()\n\n\tif len(actualMods) != len(mods) {\n\t\tt.Fatalf(\"Expected %d modules, got %d\", len(mods), len(actualMods))\n\t}\n\n\tfor name, actualMod := range actualMods {\n\t\texpectedMod, found := mods[name]\n\t\tif !found {\n\t\t\tt.Fatalf(\"Unexpected module %s\", name)\n\t\t}\n\t\tif actualMod.String() != ast.MustParseModule(expectedMod).String() {\n\t\t\tt.Fatalf(\"Modules for %s do not match.\\n\\nExpected:\\n%s\\n\\nActual:\\n%s\\n\\n\",\n\t\t\t\tname, actualMod.String(), expectedMod)\n\t\t}\n\t}\n}\n\nfunc TestRegoEvalWithFile(t *testing.T) {\n\tfiles := map[string]string{\n\t\t\"x/x.rego\": \"package x\\np = 1\",\n\t\t\"x/x.json\": `{\"y\": \"foo\"}`,\n\t}\n\n\ttest.WithTempFS(files, func(path string) {\n\t\tctx := context.Background()\n\n\t\tpq, err := New(\n\t\t\tLoad([]string{path}, nil),\n\t\t\tQuery(\"data\"),\n\t\t).PrepareForEval(ctx)\n\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t\t}\n\n\t\trs, err := pq.Eval(ctx)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t\t}\n\n\t\tassertResultSet(t, rs, `[[{\"x\":{\"p\":1,\"y\":\"foo\"}}]]`)\n\t})\n}\n\nfunc TestRegoEvalWithBundle(t *testing.T) {\n\tfiles := map[string]string{\n\t\t\"x/x.rego\":            \"package x\\np = data.x.b\",\n\t\t\"x/data.json\":         `{\"b\": \"bar\"}`,\n\t\t\"other/not-data.json\": `{\"ignored\": \"data\"}`,\n\t}\n\n\ttest.WithTempFS(files, func(path string) {\n\t\tctx := context.Background()\n\n\t\tpq, err := New(\n\t\t\tLoadBundle(path),\n\t\t\tQuery(\"data.x.p\"),\n\t\t).PrepareForEval(ctx)\n\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t\t}\n\n\t\trs, err := pq.Eval(ctx)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t\t}\n\n\t\tassertResultSet(t, rs, `[[\"bar\"]]`)\n\n\t\tmods := pq.Modules()\n\t\tif exp, act := 1, len(mods); exp != act {\n\t\t\tt.Fatalf(\"expected %d modules, found %d\", exp, act)\n\t\t}\n\t\tfor act := range mods {\n\t\t\tif exp := filepath.Join(path, \"x/x.rego\"); exp != act {\n\t\t\t\tt.Errorf(\"expected module name %q, got %q\", exp, act)\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc TestRegoEvalWithBundleURL(t *testing.T) {\n\tfiles := map[string]string{\n\t\t\"x/x.rego\": \"package x\\np = data.x.b\",\n\t}\n\n\ttest.WithTempFS(files, func(path string) {\n\t\tctx := context.Background()\n\t\tpq, err := New(\n\t\t\tLoadBundle(\"file://\"+path),\n\t\t\tQuery(\"data.x.p\"),\n\t\t).PrepareForEval(ctx)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t\t}\n\n\t\tmods := pq.Modules()\n\t\tif exp, act := 1, len(mods); exp != act {\n\t\t\tt.Fatalf(\"expected %d modules, found %d\", exp, act)\n\t\t}\n\t\tfor act := range mods {\n\t\t\tif exp := filepath.Join(path, \"x/x.rego\"); exp != act {\n\t\t\t\tt.Errorf(\"expected module name %q, got %q\", exp, act)\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc TestRegoEvalPoliciesInStore(t *testing.T) {\n\tstore := mock.New()\n\tctx := context.Background()\n\ttxn := storage.NewTransactionOrDie(ctx, store, storage.WriteParams)\n\n\terr := store.UpsertPolicy(ctx, txn, \"a.rego\", []byte(\"package a\\np=1\"))\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t}\n\terr = store.Commit(ctx, txn)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t}\n\n\tpq, err := New(\n\t\tStore(store),\n\t\tModule(\"b.rego\", \"package b\\np = data.a.p\"),\n\t\tQuery(\"data.b.p\"),\n\t).PrepareForEval(ctx)\n\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t}\n\n\trs, err := pq.Eval(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t}\n\n\tassertResultSet(t, rs, `[[1]]`)\n}\n\nfunc TestRegoEvalModulesOnCompiler(t *testing.T) {\n\tcompiler := ast.NewCompiler()\n\n\tcompiler.Compile(map[string]*ast.Module{\n\t\t\"a.rego\": ast.MustParseModule(\"package a\\np = 1\"),\n\t})\n\n\tif len(compiler.Errors) > 0 {\n\t\tt.Fatalf(\"Unexpected compile errors: %s\", compiler.Errors)\n\t}\n\n\tctx := context.Background()\n\n\tpq, err := New(\n\t\tCompiler(compiler),\n\t\tQuery(\"data.a.p\"),\n\t\tSchemas(nil),\n\t).PrepareForEval(ctx)\n\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t}\n\n\trs, err := pq.Eval(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t}\n\n\tassertResultSet(t, rs, `[[1]]`)\n}\n\nfunc TestRegoLoadFilesWithProvidedStore(t *testing.T) {\n\tctx := context.Background()\n\tstore := mock.New()\n\n\tfiles := map[string]string{\n\t\t\"x.rego\": \"package x\\np = data.x.b\",\n\t}\n\n\ttest.WithTempFS(files, func(path string) {\n\t\tpq, err := New(\n\t\t\tStore(store),\n\t\t\tQuery(\"data\"),\n\t\t\tLoad([]string{path}, nil),\n\t\t).PrepareForEval(ctx)\n\n\t\tif err == nil {\n\t\t\tt.Fatal(\"Expected an error but err == nil\")\n\t\t}\n\n\t\tif pq.r != nil {\n\t\t\tt.Fatalf(\"Expected pq.r == nil, got: %+v\", pq)\n\t\t}\n\t})\n}\n\nfunc TestRegoLoadBundleWithProvidedStore(t *testing.T) {\n\tctx := context.Background()\n\tstore := mock.New()\n\n\tfiles := map[string]string{\n\t\t\"x/x.rego\": \"package x\\np = data.x.b\",\n\t}\n\n\ttest.WithTempFS(files, func(path string) {\n\t\tpq, err := New(\n\t\t\tStore(store),\n\t\t\tQuery(\"data\"),\n\t\t\tLoadBundle(path),\n\t\t).PrepareForEval(ctx)\n\n\t\tif err == nil {\n\t\t\tt.Fatal(\"Expected an error but err == nil\")\n\t\t}\n\n\t\tif pq.r != nil {\n\t\t\tt.Fatalf(\"Expected pq.r == nil, got: %+v\", pq)\n\t\t}\n\t})\n}\n\nfunc TestRegoCustomBuiltinPartialPropagate(t *testing.T) {\n\tmod := `package test\n\tp {\n\t\tx = trim_and_split(input.foo, \"/\")\n\t\tx == [\"foo\", \"bar\", \"baz\"]\n\t}\n\t`\n\n\toriginalRego := New(\n\t\tModule(\"test.rego\", mod),\n\t\tQuery(`data.test.p`),\n\t\tFunction2(\n\t\t\t&Function{\n\t\t\t\tName: \"trim_and_split\",\n\t\t\t\tDecl: types.NewFunction(\n\t\t\t\t\ttypes.Args(types.S, types.S), // two string inputs\n\t\t\t\t\ttypes.NewArray(nil, types.S), // variable-length string array output\n\t\t\t\t),\n\t\t\t},\n\t\t\tfunc(_ BuiltinContext, a, b *ast.Term) (*ast.Term, error) {\n\n\t\t\t\tstr, ok1 := a.Value.(ast.String)\n\t\t\t\tdelim, ok2 := b.Value.(ast.String)\n\n\t\t\t\t// The function is undefined for non-string inputs. Built-in\n\t\t\t\t// functions should only return errors in unrecoverable cases.\n\t\t\t\tif !ok1 || !ok2 {\n\t\t\t\t\treturn nil, nil\n\t\t\t\t}\n\n\t\t\t\tresult := strings.Split(strings.Trim(string(str), string(delim)), string(delim))\n\n\t\t\t\tarr := make([]*ast.Term, len(result))\n\t\t\t\tfor i := range result {\n\t\t\t\t\tarr[i] = ast.StringTerm(result[i])\n\t\t\t\t}\n\n\t\t\t\treturn ast.ArrayTerm(arr...), nil\n\t\t\t},\n\t\t),\n\t)\n\n\tpr, err := originalRego.PartialResult(context.Background())\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t}\n\n\trs, err := pr.Rego(\n\t\tInput(map[string]interface{}{\"foo\": \"/foo/bar/baz/\"}),\n\t).Eval(context.Background())\n\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t}\n\tassertResultSet(t, rs, `[[true]]`)\n\n}\n\nfunc TestRegoPartialResultRecursiveRefs(t *testing.T) {\n\n\tr := New(Query(\"data\"), Module(\"test.rego\", `package foo.bar\n\n\tdefault p = false\n\n\tp { input.x = 1 }`))\n\n\t_, err := r.PartialResult(context.Background())\n\tif err == nil {\n\t\tt.Fatal(\"expected error\")\n\t}\n\n\tif !IsPartialEvaluationNotEffectiveErr(err) {\n\t\tt.Fatal(\"expected ineffective partial eval error\")\n\t}\n\n}\n\nfunc TestSkipPartialNamespaceOption(t *testing.T) {\n\tr := New(Query(\"data.test.p\"), Module(\"example.rego\", `\n\t\tpackage test\n\n\t\tdefault p = false\n\n\t\tp = true { input }\n\t`), SkipPartialNamespace(true))\n\n\tpq, err := r.Partial(context.Background())\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif len(pq.Queries) != 1 || !pq.Queries[0].Equal(ast.MustParseBody(\"data.test.p\")) {\n\t\tt.Fatal(\"expected exactly one query and for reference to not have been rewritten but got:\", pq.Queries)\n\t}\n\n\tif len(pq.Support) != 1 || !pq.Support[0].Package.Equal(ast.MustParsePackage(\"package test\")) {\n\t\tt.Fatal(\"expected exactly one support and for package to be same as input but got:\", pq.Support)\n\t}\n}\n\nfunc TestShallowInliningOption(t *testing.T) {\n\tr := New(Query(\"data.test.p = true\"), Module(\"example.rego\", `\n\t\tpackage test\n\n\t\tp {\n\t\t\tq = true\n\t\t}\n\n\t\tq {\n\t\t\tinput.x = r\n\t\t}\n\n\t\tr = 7\n\t`), ShallowInlining(true))\n\n\tpq, err := r.Partial(context.Background())\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif len(pq.Queries) != 1 || !pq.Queries[0].Equal(ast.MustParseBody(\"data.partial.test.p = true\")) {\n\t\tt.Fatal(\"expected exactly one query and ref to be rewritten but got:\", pq.Queries)\n\t}\n\n\texp := ast.MustParseModule(`\n\t\tpackage partial.test\n\n\t\tp { data.partial.test.q = true }\n\t\tq { 7 = input.x }\n\t`)\n\n\tif len(pq.Support) != 1 || !pq.Support[0].Equal(exp) {\n\t\tt.Fatal(\"expected module:\", exp, \"\\n\\ngot module:\", pq.Support[0])\n\t}\n}\n\nfunc TestRegoPartialResultSortedRules(t *testing.T) {\n\tr := New(Query(\"data.test.p\"), Module(\"example.rego\", `\n\t\tpackage test\n\n\t\tdefault p = false\n\n\t\tp {\n\t\t\tr = (input.d * input.a) + input.c\n\t\t\tr < s\n\t\t}\n\n\t\tp {\n\t\t\tr = (input.d * input.b) + input.c\n\t\t\tr < s\n\t\t}\n\n\t\ts = 100\n\n\t`))\n\n\tpq, err := r.Partial(context.Background())\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// Without sorting of support rules, the output of the above partial evaluation\n\t// resulted in a random order of the support rules (in this case two different possible outputs)\n\texp := ast.MustParseModule(\n\t\t`package partial.test\n\n\t\tdefault p = false\n\n\t\tp = true { lt(plus(mul(input.d, input.a), input.c), 100) }\n\t\tp = true { lt(plus(mul(input.d, input.b), input.c), 100) }\n\t\t`,\n\t)\n\n\tif len(pq.Support) != 1 || !pq.Support[0].Equal(exp) {\n\t\tt.Fatal(\"expected module:\", exp, \"\\n\\ngot module:\", pq.Support[0])\n\t}\n\n}\n\nfunc TestPrepareWithEmptyModule(t *testing.T) {\n\t_, err := New(\n\t\tQuery(\"d\"),\n\t\tModule(\"example.rego\", \"\"),\n\t).PrepareForEval(context.Background())\n\n\texpected := \"1 error occurred: example.rego:0: rego_parse_error: empty module\"\n\tif err == nil || err.Error() != expected {\n\t\tt.Fatalf(\"Expected error %s, got %s\", expected, err)\n\t}\n}\n\nfunc TestPrepareWithWasmTargetNotSupported(t *testing.T) {\n\tfiles := map[string]string{\n\t\t\"x/x.rego\":     \"package x\\np = data.x.b\",\n\t\t\"x/data.json\":  `{\"b\": \"bar\"}`,\n\t\t\"/policy.wasm\": `modules-compiled-as-wasm-binary`,\n\t}\n\n\ttest.WithTempFS(files, func(path string) {\n\t\tctx := context.Background()\n\n\t\t_, err := New(\n\t\t\tLoadBundle(path),\n\t\t\tQuery(\"data.x.p\"),\n\t\t\tTarget(\"wasm\"),\n\t\t).PrepareForEval(ctx)\n\n\t\texpected := \"wasm target not supported\"\n\t\tif err == nil || err.Error() != expected {\n\t\t\tt.Fatalf(\"Expected error %s, got %s\", expected, err)\n\t\t}\n\t})\n}\n\nfunc TestEvalWithInterQueryCache(t *testing.T) {\n\tnewHeaders := map[string][]string{\"Cache-Control\": {\"max-age=290304000, public\"}}\n\n\tvar requests []*http.Request\n\tts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\trequests = append(requests, r)\n\t\theaders := w.Header()\n\n\t\tfor k, v := range newHeaders {\n\t\t\theaders[k] = v\n\t\t}\n\n\t\tw.WriteHeader(http.StatusOK)\n\t\t_, _ = w.Write([]byte(`{\"x\": 1}`))\n\t}))\n\tdefer ts.Close()\n\tquery := fmt.Sprintf(`http.send({\"method\": \"get\", \"url\": \"%s\", \"force_json_decode\": true, \"cache\": true})`, ts.URL)\n\n\t// add an inter-query cache\n\tconfig, _ := cache.ParseCachingConfig(nil)\n\tinterQueryCache := cache.NewInterQueryCache(config)\n\n\tctx := context.Background()\n\t_, err := New(Query(query), InterQueryBuiltinCache(interQueryCache)).Eval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// eval again with same query\n\t// this request should be served by the cache\n\t_, err = New(Query(query), InterQueryBuiltinCache(interQueryCache)).Eval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif len(requests) != 1 {\n\t\tt.Fatal(\"Expected server to be called only once\")\n\t}\n}\n\n// We use http.send to ensure the NDBuiltinCache is involved.\nfunc TestEvalWithNDCache(t *testing.T) {\n\tvar requests []*http.Request\n\tts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\trequests = append(requests, r)\n\t\t_, _ = w.Write([]byte(`{\"x\": 1}`))\n\t}))\n\tdefer ts.Close()\n\tquery := fmt.Sprintf(`http.send({\"method\": \"get\", \"url\": \"%s\", \"force_json_decode\": true})`, ts.URL)\n\n\t// Set up the ND cache, and put in some arbitrary constants for the first K/V pair.\n\tarbitraryKey := ast.Number(strconv.Itoa(2015))\n\tarbitraryValue := ast.String(\"First commit year\")\n\tndBC := builtins.NDBCache{}\n\tndBC.Put(\"arbitrary_experiment\", arbitraryKey, arbitraryValue)\n\n\t// Query execution of http.send should add an entry to the NDBuiltinCache.\n\tctx := context.Background()\n\t_, err := New(Query(query), NDBuiltinCache(ndBC)).Eval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// Check and make sure we got exactly 2x items back in the ND builtin cache.\n\t// NDBuiltinsCache always has the structure: map[ast.String]map[ast.Array]ast.Value\n\tif len(ndBC) != 2 {\n\t\tt.Fatalf(\"Expected exactly 2 items in non-deterministic builtin cache. Found %d items.\\n\", len(ndBC))\n\t}\n\t// Check the cached k/v types for the HTTP section of the cache.\n\tif cachedResults, ok := ndBC[\"http.send\"]; ok {\n\t\terr := cachedResults.Iter(func(k, v *ast.Term) error {\n\t\t\tif _, ok := k.Value.(*ast.Array); !ok {\n\t\t\t\tt.Fatalf(\"http.send failed to store Object key in the ND builtins cache\")\n\t\t\t}\n\t\t\tif _, ok := v.Value.(ast.Object); !ok {\n\t\t\t\tt.Fatalf(\"http.send failed to store Object value in the ND builtins cache\")\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}\n\n\t// Ensure our original arbitrary data in the cache was preserved.\n\tif v, ok := ndBC.Get(\"arbitrary_experiment\", arbitraryKey); ok {\n\t\tif v != arbitraryValue {\n\t\t\tt.Fatalf(\"Non-deterministic builtins cache value was mangled. Expected: %v, got: %v\\n\", arbitraryValue, v)\n\t\t}\n\t} else {\n\t\tt.Fatal(\"Non-deterministic builtins cache lookup failed.\")\n\t}\n}\n\nfunc TestEvalWithPrebuiltNDCache(t *testing.T) {\n\tquery := \"time.now_ns()\"\n\tndBC := builtins.NDBCache{}\n\n\t// Populate the cache for time.now_ns with an arbitrary timestamp.\n\ttimeValue, err := time.Parse(\"2006-01-02T15:04:05Z\", \"2015-12-28T14:08:25Z\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// Timestamp ns value will be: 1451311705000000000\n\tndBC.Put(\"time.now_ns\", ast.NewArray(), ast.Number(json.Number(strconv.FormatInt(timeValue.UnixNano(), 10))))\n\t// time.now_ns should use the cached entry instead of the current time.\n\tctx := context.Background()\n\trs, err := New(Query(query), NDBuiltinCache(ndBC)).Eval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// Check that we got the correct time value in the result set.\n\tassertResultSet(t, rs, \"[[1451311705000000000]]\")\n}\n\nfunc TestNDBCacheWithRuleBody(t *testing.T) {\n\tctx := context.Background()\n\tts := httptest.NewServer(http.HandlerFunc(func(http.ResponseWriter, *http.Request) {}))\n\tdefer ts.Close()\n\n\tndBC := builtins.NDBCache{}\n\tquery := \"data.foo.p = x\"\n\t_, err := New(\n\t\tQuery(query),\n\t\tNDBuiltinCache(ndBC),\n\t\tModule(\"test.rego\", fmt.Sprintf(`package foo\np {\n\thttp.send({\"url\": \"%s\", \"method\":\"get\"})\n}`, ts.URL)),\n\t).Eval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\t_, ok := ndBC[\"http.send\"]\n\tif !ok {\n\t\tt.Fatalf(\"expected http.send cache entry\")\n\t}\n}\n\n// Catches issues around iteration with ND builtins.\nfunc TestNDBCacheWithRuleBodyAndIteration(t *testing.T) {\n\tctx := context.Background()\n\tts := httptest.NewServer(http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t}))\n\tdefer ts.Close()\n\n\tndBC := builtins.NDBCache{}\n\tquery := \"data.foo.results = x\"\n\t_, err := New(\n\t\tQuery(query),\n\t\tNDBuiltinCache(ndBC),\n\t\tModule(\"test.rego\", fmt.Sprintf(`package foo\n\nimport future.keywords\n\nurls := [\n\t\"%[1]s/headers\",\n\t\"%[1]s/ip\",\n\t\"%[1]s/user-agent\"\n]\n\nresults[response] {\n\tsome url in urls\n\tresponse := http.send({\n\t\t\"method\": \"GET\",\n\t\t\"url\": url\n\t})\n}`, ts.URL)),\n\t).Eval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// Ensure that the cache exists, and has exactly 3 entries.\n\tentries, ok := ndBC[\"http.send\"]\n\tif !ok {\n\t\tt.Fatalf(\"expected http.send cache entry\")\n\t}\n\tif entries.Len() != 3 {\n\t\tt.Fatalf(\"expected 3 http.send cache entries, received:\\n%v\", ndBC)\n\t}\n}\n\n// This test ensures that the NDBCache correctly serializes/deserializes.\nfunc TestNDBCacheMarshalUnmarshalJSON(t *testing.T) {\n\toriginal := builtins.NDBCache{}\n\n\t// Populate the cache for time.now_ns with an arbitrary timestamp.\n\toriginal.Put(\"time.now_ns\", ast.NewArray(), ast.Number(json.Number(strconv.FormatInt(1451311705000000000, 10))))\n\tjOriginal, err := json.Marshal(original)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvar other builtins.NDBCache\n\terr = json.Unmarshal(jOriginal, &other)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tjOther, err := json.Marshal(other)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// Check that the two NDBCache value's JSONified forms match exactly.\n\tif !bytes.Equal(jOriginal, jOther) {\n\t\tt.Fatalf(\"JSONified values of NDBCaches do not match; expected %s, got %s\", string(jOriginal), string(jOther))\n\t}\n}\n\nfunc TestStrictBuiltinErrors(t *testing.T) {\n\t_, err := New(Query(\"1/0\"), StrictBuiltinErrors(true)).Eval(context.Background())\n\tif err == nil {\n\t\tt.Fatal(\"expected error\")\n\t}\n\ttopdownErr, ok := err.(*topdown.Error)\n\tif !ok {\n\t\tt.Fatal(\"expected topdown error but got:\", err)\n\t}\n\n\tif topdownErr.Code != topdown.BuiltinErr {\n\t\tt.Fatal(\"expected builtin error code but got:\", topdownErr.Code)\n\t}\n\n\tif topdownErr.Message != \"div: divide by zero\" {\n\t\tt.Fatal(\"expected divide by zero error but got:\", topdownErr.Message)\n\t}\n}\n\nfunc TestTimeSeedingOptions(t *testing.T) {\n\n\tctx := context.Background()\n\tclock := time.Now()\n\n\t// Check expected time is returned.\n\trs, err := New(Query(\"time.now_ns(x)\"), Time(clock)).Eval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t} else if len(rs) != 1 || !reflect.DeepEqual(rs[0].Bindings[\"x\"], int64ToJSONNumber(clock.UnixNano())) {\n\t\tt.Fatal(\"unexpected wall clock value\")\n\t}\n\n\t// Check that time is not propagated to prepared query.\n\teval, err := New(Query(\"time.now_ns(x)\"), Time(clock)).PrepareForEval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\trs2, err := eval.Eval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t} else if len(rs2) != 1 || reflect.DeepEqual(rs[0].Bindings[\"x\"], rs2[0].Bindings[\"x\"]) {\n\t\tt.Fatal(\"expected new wall clock value\")\n\t}\n\n\t// Check that prepared query returns provided time.\n\trs3, err := eval.Eval(ctx, EvalTime(clock))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t} else if len(rs2) != 1 || !reflect.DeepEqual(rs[0].Bindings[\"x\"], rs3[0].Bindings[\"x\"]) {\n\t\tt.Fatal(\"expected old wall clock value\")\n\t}\n\n}\n\nfunc int64ToJSONNumber(i int64) json.Number {\n\treturn json.Number(strconv.FormatInt(i, 10))\n}\n\nfunc TestPrepareAndCompileWithSchema(t *testing.T) {\n\tmodule := `\n\tpackage test\n\tx = input.y\n\t`\n\n\tschemaBytes := `{\n\t\t\"$schema\": \"http://json-schema.org/draft-07/schema\",\n\t\t\"$id\": \"http://example.com/example.json\",\n\t\t\"type\": \"object\",\n\t\t\"title\": \"The root schema\",\n\t\t\"description\": \"The root schema comprises the entire JSON document.\",\n\t\t\"required\": [],\n\t\t\"properties\": {\n\t\t\t\"y\": {\n\t\t\t\t\"$id\": \"#/properties/y\",\n\t\t\t\t\"type\": \"integer\",\n\t\t\t\t\"title\": \"The y schema\",\n\t\t\t\t\"description\": \"An explanation about the purpose of this instance.\"\n\t\t\t}\n\t\t},\n\t\t\"additionalProperties\": false\n\t}`\n\n\tvar schema interface{}\n\terr := util.Unmarshal([]byte(schemaBytes), &schema)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tschemaSet := ast.NewSchemaSet()\n\tschemaSet.Put(ast.InputRootRef, schema)\n\n\tr := New(\n\t\tQuery(\"data.test.x\"),\n\t\tModule(\"\", module),\n\t\tPackage(\"foo\"),\n\t\tSchemas(schemaSet),\n\t)\n\n\tctx := context.Background()\n\n\tpq, err := r.PrepareForEval(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{\n\t\tEvalInput(map[string]int{\"y\": 1}),\n\t}, \"[[1]]\")\n\n\t// Ensure that Compile still works after Prepare\n\t// and its Eval has been called.\n\t_, err = r.Compile(ctx)\n\tif err != nil {\n\t\tt.Errorf(\"Unexpected error when compiling: %s\", err.Error())\n\t}\n}\n\nfunc TestGenerateJSON(t *testing.T) {\n\tr := New(\n\t\tQuery(\"input\"),\n\t\tInput(\"original-input\"),\n\t\tGenerateJSON(func(t *ast.Term, ectx *EvalContext) (interface{}, error) {\n\t\t\treturn \"converted-input\", nil\n\t\t}),\n\t)\n\tassertEval(t, r, `[[\"converted-input\"]]`)\n}\n"], "fixing_code": ["// Copyright 2016 The OPA Authors.  All rights reserved.\n// Use of this source code is governed by an Apache2\n// license that can be found in the LICENSE file.\n\npackage ast\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/open-policy-agent/opa/ast/location\"\n\t\"github.com/open-policy-agent/opa/internal/debug\"\n\t\"github.com/open-policy-agent/opa/internal/gojsonschema\"\n\t\"github.com/open-policy-agent/opa/metrics\"\n\t\"github.com/open-policy-agent/opa/types\"\n\t\"github.com/open-policy-agent/opa/util\"\n)\n\n// CompileErrorLimitDefault is the default number errors a compiler will allow before\n// exiting.\nconst CompileErrorLimitDefault = 10\n\nvar errLimitReached = NewError(CompileErr, nil, \"error limit reached\")\n\n// Compiler contains the state of a compilation process.\ntype Compiler struct {\n\n\t// Errors contains errors that occurred during the compilation process.\n\t// If there are one or more errors, the compilation process is considered\n\t// \"failed\".\n\tErrors Errors\n\n\t// Modules contains the compiled modules. The compiled modules are the\n\t// output of the compilation process. If the compilation process failed,\n\t// there is no guarantee about the state of the modules.\n\tModules map[string]*Module\n\n\t// ModuleTree organizes the modules into a tree where each node is keyed by\n\t// an element in the module's package path. E.g., given modules containing\n\t// the following package directives: \"a\", \"a.b\", \"a.c\", and \"a.b\", the\n\t// resulting module tree would be:\n\t//\n\t//  root\n\t//    |\n\t//    +--- data (no modules)\n\t//           |\n\t//           +--- a (1 module)\n\t//                |\n\t//                +--- b (2 modules)\n\t//                |\n\t//                +--- c (1 module)\n\t//\n\tModuleTree *ModuleTreeNode\n\n\t// RuleTree organizes rules into a tree where each node is keyed by an\n\t// element in the rule's path. The rule path is the concatenation of the\n\t// containing package and the stringified rule name. E.g., given the\n\t// following module:\n\t//\n\t//  package ex\n\t//  p[1] { true }\n\t//  p[2] { true }\n\t//  q = true\n\t//\n\t//  root\n\t//    |\n\t//    +--- data (no rules)\n\t//           |\n\t//           +--- ex (no rules)\n\t//                |\n\t//                +--- p (2 rules)\n\t//                |\n\t//                +--- q (1 rule)\n\tRuleTree *TreeNode\n\n\t// Graph contains dependencies between rules. An edge (u,v) is added to the\n\t// graph if rule 'u' refers to the virtual document defined by 'v'.\n\tGraph *Graph\n\n\t// TypeEnv holds type information for values inferred by the compiler.\n\tTypeEnv *TypeEnv\n\n\t// RewrittenVars is a mapping of variables that have been rewritten\n\t// with the key being the generated name and value being the original.\n\tRewrittenVars map[Var]Var\n\n\tlocalvargen  *localVarGenerator\n\tmoduleLoader ModuleLoader\n\truleIndices  *util.HashMap\n\tstages       []struct {\n\t\tname       string\n\t\tmetricName string\n\t\tf          func()\n\t}\n\tmaxErrs               int\n\tsorted                []string // list of sorted module names\n\tpathExists            func([]string) (bool, error)\n\tafter                 map[string][]CompilerStageDefinition\n\tmetrics               metrics.Metrics\n\tcapabilities          *Capabilities                 // user-supplied capabilities\n\tbuiltins              map[string]*Builtin           // universe of built-in functions\n\tcustomBuiltins        map[string]*Builtin           // user-supplied custom built-in functions (deprecated: use capabilities)\n\tunsafeBuiltinsMap     map[string]struct{}           // user-supplied set of unsafe built-ins functions to block (deprecated: use capabilities)\n\tdeprecatedBuiltinsMap map[string]struct{}           // set of deprecated, but not removed, built-in functions\n\tenablePrintStatements bool                          // indicates if print statements should be elided (default)\n\tcomprehensionIndices  map[*Term]*ComprehensionIndex // comprehension key index\n\tinitialized           bool                          // indicates if init() has been called\n\tdebug                 debug.Debug                   // emits debug information produced during compilation\n\tschemaSet             *SchemaSet                    // user-supplied schemas for input and data documents\n\tinputType             types.Type                    // global input type retrieved from schema set\n\tannotationSet         *AnnotationSet                // hierarchical set of annotations\n\tstrict                bool                          // enforce strict compilation checks\n\tkeepModules           bool                          // whether to keep the unprocessed, parse modules (below)\n\tparsedModules         map[string]*Module            // parsed, but otherwise unprocessed modules, kept track of when keepModules is true\n}\n\n// CompilerStage defines the interface for stages in the compiler.\ntype CompilerStage func(*Compiler) *Error\n\n// CompilerStageDefinition defines a compiler stage\ntype CompilerStageDefinition struct {\n\tName       string\n\tMetricName string\n\tStage      CompilerStage\n}\n\n// RulesOptions defines the options for retrieving rules by Ref from the\n// compiler.\ntype RulesOptions struct {\n\t// IncludeHiddenModules determines if the result contains hidden modules,\n\t// currently only the \"system\" namespace, i.e. \"data.system.*\".\n\tIncludeHiddenModules bool\n}\n\n// QueryContext contains contextual information for running an ad-hoc query.\n//\n// Ad-hoc queries can be run in the context of a package and imports may be\n// included to provide concise access to data.\ntype QueryContext struct {\n\tPackage *Package\n\tImports []*Import\n}\n\n// NewQueryContext returns a new QueryContext object.\nfunc NewQueryContext() *QueryContext {\n\treturn &QueryContext{}\n}\n\n// WithPackage sets the pkg on qc.\nfunc (qc *QueryContext) WithPackage(pkg *Package) *QueryContext {\n\tif qc == nil {\n\t\tqc = NewQueryContext()\n\t}\n\tqc.Package = pkg\n\treturn qc\n}\n\n// WithImports sets the imports on qc.\nfunc (qc *QueryContext) WithImports(imports []*Import) *QueryContext {\n\tif qc == nil {\n\t\tqc = NewQueryContext()\n\t}\n\tqc.Imports = imports\n\treturn qc\n}\n\n// Copy returns a deep copy of qc.\nfunc (qc *QueryContext) Copy() *QueryContext {\n\tif qc == nil {\n\t\treturn nil\n\t}\n\tcpy := *qc\n\tif cpy.Package != nil {\n\t\tcpy.Package = qc.Package.Copy()\n\t}\n\tcpy.Imports = make([]*Import, len(qc.Imports))\n\tfor i := range qc.Imports {\n\t\tcpy.Imports[i] = qc.Imports[i].Copy()\n\t}\n\treturn &cpy\n}\n\n// QueryCompiler defines the interface for compiling ad-hoc queries.\ntype QueryCompiler interface {\n\n\t// Compile should be called to compile ad-hoc queries. The return value is\n\t// the compiled version of the query.\n\tCompile(q Body) (Body, error)\n\n\t// TypeEnv returns the type environment built after running type checking\n\t// on the query.\n\tTypeEnv() *TypeEnv\n\n\t// WithContext sets the QueryContext on the QueryCompiler. Subsequent calls\n\t// to Compile will take the QueryContext into account.\n\tWithContext(qctx *QueryContext) QueryCompiler\n\n\t// WithEnablePrintStatements enables print statements in queries compiled\n\t// with the QueryCompiler.\n\tWithEnablePrintStatements(yes bool) QueryCompiler\n\n\t// WithUnsafeBuiltins sets the built-in functions to treat as unsafe and not\n\t// allow inside of queries. By default the query compiler inherits the\n\t// compiler's unsafe built-in functions. This function allows callers to\n\t// override that set. If an empty (non-nil) map is provided, all built-ins\n\t// are allowed.\n\tWithUnsafeBuiltins(unsafe map[string]struct{}) QueryCompiler\n\n\t// WithStageAfter registers a stage to run during query compilation after\n\t// the named stage.\n\tWithStageAfter(after string, stage QueryCompilerStageDefinition) QueryCompiler\n\n\t// RewrittenVars maps generated vars in the compiled query to vars from the\n\t// parsed query. For example, given the query \"input := 1\" the rewritten\n\t// query would be \"__local0__ = 1\". The mapping would then be {__local0__: input}.\n\tRewrittenVars() map[Var]Var\n\n\t// ComprehensionIndex returns an index data structure for the given comprehension\n\t// term. If no index is found, returns nil.\n\tComprehensionIndex(term *Term) *ComprehensionIndex\n}\n\n// QueryCompilerStage defines the interface for stages in the query compiler.\ntype QueryCompilerStage func(QueryCompiler, Body) (Body, error)\n\n// QueryCompilerStageDefinition defines a QueryCompiler stage\ntype QueryCompilerStageDefinition struct {\n\tName       string\n\tMetricName string\n\tStage      QueryCompilerStage\n}\n\n// NewCompiler returns a new empty compiler.\nfunc NewCompiler() *Compiler {\n\n\tc := &Compiler{\n\t\tModules:       map[string]*Module{},\n\t\tRewrittenVars: map[Var]Var{},\n\t\truleIndices: util.NewHashMap(func(a, b util.T) bool {\n\t\t\tr1, r2 := a.(Ref), b.(Ref)\n\t\t\treturn r1.Equal(r2)\n\t\t}, func(x util.T) int {\n\t\t\treturn x.(Ref).Hash()\n\t\t}),\n\t\tmaxErrs:               CompileErrorLimitDefault,\n\t\tafter:                 map[string][]CompilerStageDefinition{},\n\t\tunsafeBuiltinsMap:     map[string]struct{}{},\n\t\tdeprecatedBuiltinsMap: map[string]struct{}{},\n\t\tcomprehensionIndices:  map[*Term]*ComprehensionIndex{},\n\t\tdebug:                 debug.Discard(),\n\t}\n\n\tc.ModuleTree = NewModuleTree(nil)\n\tc.RuleTree = NewRuleTree(c.ModuleTree)\n\n\tc.stages = []struct {\n\t\tname       string\n\t\tmetricName string\n\t\tf          func()\n\t}{\n\t\t// Reference resolution should run first as it may be used to lazily\n\t\t// load additional modules. If any stages run before resolution, they\n\t\t// need to be re-run after resolution.\n\t\t{\"ResolveRefs\", \"compile_stage_resolve_refs\", c.resolveAllRefs},\n\t\t{\"CheckKeywordOverrides\", \"compile_stage_check_keyword_overrides\", c.checkKeywordOverrides},\n\t\t{\"CheckDuplicateImports\", \"compile_stage_check_duplicate_imports\", c.checkDuplicateImports},\n\t\t{\"RemoveImports\", \"compile_stage_remove_imports\", c.removeImports},\n\t\t{\"SetModuleTree\", \"compile_stage_set_module_tree\", c.setModuleTree},\n\t\t{\"SetRuleTree\", \"compile_stage_set_rule_tree\", c.setRuleTree},\n\t\t// The local variable generator must be initialized after references are\n\t\t// resolved and the dynamic module loader has run but before subsequent\n\t\t// stages that need to generate variables.\n\t\t{\"InitLocalVarGen\", \"compile_stage_init_local_var_gen\", c.initLocalVarGen},\n\t\t{\"RewriteLocalVars\", \"compile_stage_rewrite_local_vars\", c.rewriteLocalVars},\n\t\t{\"CheckVoidCalls\", \"compile_stage_check_void_calls\", c.checkVoidCalls},\n\t\t{\"RewritePrintCalls\", \"compile_stage_rewrite_print_calls\", c.rewritePrintCalls},\n\t\t{\"RewriteExprTerms\", \"compile_stage_rewrite_expr_terms\", c.rewriteExprTerms},\n\t\t{\"ParseMetadataBlocks\", \"compile_stage_parse_metadata_blocks\", c.parseMetadataBlocks},\n\t\t{\"SetAnnotationSet\", \"compile_stage_set_annotationset\", c.setAnnotationSet},\n\t\t{\"RewriteRegoMetadataCalls\", \"compile_stage_rewrite_rego_metadata_calls\", c.rewriteRegoMetadataCalls},\n\t\t{\"SetGraph\", \"compile_stage_set_graph\", c.setGraph},\n\t\t{\"RewriteComprehensionTerms\", \"compile_stage_rewrite_comprehension_terms\", c.rewriteComprehensionTerms},\n\t\t{\"RewriteRefsInHead\", \"compile_stage_rewrite_refs_in_head\", c.rewriteRefsInHead},\n\t\t{\"RewriteWithValues\", \"compile_stage_rewrite_with_values\", c.rewriteWithModifiers},\n\t\t{\"CheckRuleConflicts\", \"compile_stage_check_rule_conflicts\", c.checkRuleConflicts},\n\t\t{\"CheckUndefinedFuncs\", \"compile_stage_check_undefined_funcs\", c.checkUndefinedFuncs},\n\t\t{\"CheckSafetyRuleHeads\", \"compile_stage_check_safety_rule_heads\", c.checkSafetyRuleHeads},\n\t\t{\"CheckSafetyRuleBodies\", \"compile_stage_check_safety_rule_bodies\", c.checkSafetyRuleBodies},\n\t\t{\"RewriteEquals\", \"compile_stage_rewrite_equals\", c.rewriteEquals},\n\t\t{\"RewriteDynamicTerms\", \"compile_stage_rewrite_dynamic_terms\", c.rewriteDynamicTerms},\n\t\t{\"CheckRecursion\", \"compile_stage_check_recursion\", c.checkRecursion},\n\t\t{\"CheckTypes\", \"compile_stage_check_types\", c.checkTypes}, // must be run after CheckRecursion\n\t\t{\"CheckUnsafeBuiltins\", \"compile_state_check_unsafe_builtins\", c.checkUnsafeBuiltins},\n\t\t{\"CheckDeprecatedBuiltins\", \"compile_state_check_deprecated_builtins\", c.checkDeprecatedBuiltins},\n\t\t{\"BuildRuleIndices\", \"compile_stage_rebuild_indices\", c.buildRuleIndices},\n\t\t{\"BuildComprehensionIndices\", \"compile_stage_rebuild_comprehension_indices\", c.buildComprehensionIndices},\n\t}\n\n\treturn c\n}\n\n// SetErrorLimit sets the number of errors the compiler can encounter before it\n// quits. Zero or a negative number indicates no limit.\nfunc (c *Compiler) SetErrorLimit(limit int) *Compiler {\n\tc.maxErrs = limit\n\treturn c\n}\n\n// WithEnablePrintStatements enables print statements inside of modules compiled\n// by the compiler. If print statements are not enabled, calls to print() are\n// erased at compile-time.\nfunc (c *Compiler) WithEnablePrintStatements(yes bool) *Compiler {\n\tc.enablePrintStatements = yes\n\treturn c\n}\n\n// WithPathConflictsCheck enables base-virtual document conflict\n// detection. The compiler will check that rules don't overlap with\n// paths that exist as determined by the provided callable.\nfunc (c *Compiler) WithPathConflictsCheck(fn func([]string) (bool, error)) *Compiler {\n\tc.pathExists = fn\n\treturn c\n}\n\n// WithStageAfter registers a stage to run during compilation after\n// the named stage.\nfunc (c *Compiler) WithStageAfter(after string, stage CompilerStageDefinition) *Compiler {\n\tc.after[after] = append(c.after[after], stage)\n\treturn c\n}\n\n// WithMetrics will set a metrics.Metrics and be used for profiling\n// the Compiler instance.\nfunc (c *Compiler) WithMetrics(metrics metrics.Metrics) *Compiler {\n\tc.metrics = metrics\n\treturn c\n}\n\n// WithCapabilities sets capabilities to enable during compilation. Capabilities allow the caller\n// to specify the set of built-in functions available to the policy. In the future, capabilities\n// may be able to restrict access to other language features. Capabilities allow callers to check\n// if policies are compatible with a particular version of OPA. If policies are a compiled for a\n// specific version of OPA, there is no guarantee that _this_ version of OPA can evaluate them\n// successfully.\nfunc (c *Compiler) WithCapabilities(capabilities *Capabilities) *Compiler {\n\tc.capabilities = capabilities\n\treturn c\n}\n\n// Capabilities returns the capabilities enabled during compilation.\nfunc (c *Compiler) Capabilities() *Capabilities {\n\treturn c.capabilities\n}\n\n// WithDebug sets where debug messages are written to. Passing `nil` has no\n// effect.\nfunc (c *Compiler) WithDebug(sink io.Writer) *Compiler {\n\tif sink != nil {\n\t\tc.debug = debug.New(sink)\n\t}\n\treturn c\n}\n\n// WithBuiltins is deprecated. Use WithCapabilities instead.\nfunc (c *Compiler) WithBuiltins(builtins map[string]*Builtin) *Compiler {\n\tc.customBuiltins = make(map[string]*Builtin)\n\tfor k, v := range builtins {\n\t\tc.customBuiltins[k] = v\n\t}\n\treturn c\n}\n\n// WithUnsafeBuiltins is deprecated. Use WithCapabilities instead.\nfunc (c *Compiler) WithUnsafeBuiltins(unsafeBuiltins map[string]struct{}) *Compiler {\n\tfor name := range unsafeBuiltins {\n\t\tc.unsafeBuiltinsMap[name] = struct{}{}\n\t}\n\treturn c\n}\n\n// WithStrict enables strict mode in the compiler.\nfunc (c *Compiler) WithStrict(strict bool) *Compiler {\n\tc.strict = strict\n\treturn c\n}\n\n// WithKeepModules enables retaining unprocessed modules in the compiler.\n// Note that the modules aren't copied on the way in or out -- so when\n// accessing them via ParsedModules(), mutations will occur in the module\n// map that was passed into Compile().`\nfunc (c *Compiler) WithKeepModules(y bool) *Compiler {\n\tc.keepModules = y\n\treturn c\n}\n\n// ParsedModules returns the parsed, unprocessed modules from the compiler.\n// It is `nil` if keeping modules wasn't enabled via `WithKeepModules(true)`.\n// The map includes all modules loaded via the ModuleLoader, if one was used.\nfunc (c *Compiler) ParsedModules() map[string]*Module {\n\treturn c.parsedModules\n}\n\n// QueryCompiler returns a new QueryCompiler object.\nfunc (c *Compiler) QueryCompiler() QueryCompiler {\n\tc.init()\n\treturn newQueryCompiler(c)\n}\n\n// Compile runs the compilation process on the input modules. The compiled\n// version of the modules and associated data structures are stored on the\n// compiler. If the compilation process fails for any reason, the compiler will\n// contain a slice of errors.\nfunc (c *Compiler) Compile(modules map[string]*Module) {\n\n\tc.init()\n\n\tc.Modules = make(map[string]*Module, len(modules))\n\tc.sorted = make([]string, 0, len(modules))\n\n\tif c.keepModules {\n\t\tc.parsedModules = make(map[string]*Module, len(modules))\n\t} else {\n\t\tc.parsedModules = nil\n\t}\n\n\tfor k, v := range modules {\n\t\tc.Modules[k] = v.Copy()\n\t\tc.sorted = append(c.sorted, k)\n\t\tif c.parsedModules != nil {\n\t\t\tc.parsedModules[k] = v\n\t\t}\n\t}\n\n\tsort.Strings(c.sorted)\n\n\tc.compile()\n}\n\n// WithSchemas sets a schemaSet to the compiler\nfunc (c *Compiler) WithSchemas(schemas *SchemaSet) *Compiler {\n\tc.schemaSet = schemas\n\treturn c\n}\n\n// Failed returns true if a compilation error has been encountered.\nfunc (c *Compiler) Failed() bool {\n\treturn len(c.Errors) > 0\n}\n\n// ComprehensionIndex returns a data structure specifying how to index comprehension\n// results so that callers do not have to recompute the comprehension more than once.\n// If no index is found, returns nil.\nfunc (c *Compiler) ComprehensionIndex(term *Term) *ComprehensionIndex {\n\treturn c.comprehensionIndices[term]\n}\n\n// GetArity returns the number of args a function referred to by ref takes. If\n// ref refers to built-in function, the built-in declaration is consulted,\n// otherwise, the ref is used to perform a ruleset lookup.\nfunc (c *Compiler) GetArity(ref Ref) int {\n\tif bi := c.builtins[ref.String()]; bi != nil {\n\t\treturn len(bi.Decl.Args())\n\t}\n\trules := c.GetRulesExact(ref)\n\tif len(rules) == 0 {\n\t\treturn -1\n\t}\n\treturn len(rules[0].Head.Args)\n}\n\n// GetRulesExact returns a slice of rules referred to by the reference.\n//\n// E.g., given the following module:\n//\n//\tpackage a.b.c\n//\n//\tp[k] = v { ... }    # rule1\n//  p[k1] = v1 { ... }  # rule2\n//\n// The following calls yield the rules on the right.\n//\n//  GetRulesExact(\"data.a.b.c.p\")   => [rule1, rule2]\n//  GetRulesExact(\"data.a.b.c.p.x\") => nil\n//  GetRulesExact(\"data.a.b.c\")     => nil\nfunc (c *Compiler) GetRulesExact(ref Ref) (rules []*Rule) {\n\tnode := c.RuleTree\n\n\tfor _, x := range ref {\n\t\tif node = node.Child(x.Value); node == nil {\n\t\t\treturn nil\n\t\t}\n\t}\n\n\treturn extractRules(node.Values)\n}\n\n// GetRulesForVirtualDocument returns a slice of rules that produce the virtual\n// document referred to by the reference.\n//\n// E.g., given the following module:\n//\n//\tpackage a.b.c\n//\n//\tp[k] = v { ... }    # rule1\n//  p[k1] = v1 { ... }  # rule2\n//\n// The following calls yield the rules on the right.\n//\n//  GetRulesForVirtualDocument(\"data.a.b.c.p\")   => [rule1, rule2]\n//  GetRulesForVirtualDocument(\"data.a.b.c.p.x\") => [rule1, rule2]\n//  GetRulesForVirtualDocument(\"data.a.b.c\")     => nil\nfunc (c *Compiler) GetRulesForVirtualDocument(ref Ref) (rules []*Rule) {\n\n\tnode := c.RuleTree\n\n\tfor _, x := range ref {\n\t\tif node = node.Child(x.Value); node == nil {\n\t\t\treturn nil\n\t\t}\n\t\tif len(node.Values) > 0 {\n\t\t\treturn extractRules(node.Values)\n\t\t}\n\t}\n\n\treturn extractRules(node.Values)\n}\n\n// GetRulesWithPrefix returns a slice of rules that share the prefix ref.\n//\n// E.g., given the following module:\n//\n//  package a.b.c\n//\n//  p[x] = y { ... }  # rule1\n//  p[k] = v { ... }  # rule2\n//  q { ... }         # rule3\n//\n// The following calls yield the rules on the right.\n//\n//  GetRulesWithPrefix(\"data.a.b.c.p\")   => [rule1, rule2]\n//  GetRulesWithPrefix(\"data.a.b.c.p.a\") => nil\n//  GetRulesWithPrefix(\"data.a.b.c\")     => [rule1, rule2, rule3]\nfunc (c *Compiler) GetRulesWithPrefix(ref Ref) (rules []*Rule) {\n\n\tnode := c.RuleTree\n\n\tfor _, x := range ref {\n\t\tif node = node.Child(x.Value); node == nil {\n\t\t\treturn nil\n\t\t}\n\t}\n\n\tvar acc func(node *TreeNode)\n\n\tacc = func(node *TreeNode) {\n\t\trules = append(rules, extractRules(node.Values)...)\n\t\tfor _, child := range node.Children {\n\t\t\tif child.Hide {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tacc(child)\n\t\t}\n\t}\n\n\tacc(node)\n\n\treturn rules\n}\n\nfunc extractRules(s []util.T) (rules []*Rule) {\n\tfor _, r := range s {\n\t\trules = append(rules, r.(*Rule))\n\t}\n\treturn rules\n}\n\n// GetRules returns a slice of rules that are referred to by ref.\n//\n// E.g., given the following module:\n//\n//  package a.b.c\n//\n//  p[x] = y { q[x] = y; ... } # rule1\n//  q[x] = y { ... }           # rule2\n//\n// The following calls yield the rules on the right.\n//\n//  GetRules(\"data.a.b.c.p\")\t=> [rule1]\n//  GetRules(\"data.a.b.c.p.x\")\t=> [rule1]\n//  GetRules(\"data.a.b.c.q\")\t=> [rule2]\n//  GetRules(\"data.a.b.c\")\t\t=> [rule1, rule2]\n//  GetRules(\"data.a.b.d\")\t\t=> nil\nfunc (c *Compiler) GetRules(ref Ref) (rules []*Rule) {\n\n\tset := map[*Rule]struct{}{}\n\n\tfor _, rule := range c.GetRulesForVirtualDocument(ref) {\n\t\tset[rule] = struct{}{}\n\t}\n\n\tfor _, rule := range c.GetRulesWithPrefix(ref) {\n\t\tset[rule] = struct{}{}\n\t}\n\n\tfor rule := range set {\n\t\trules = append(rules, rule)\n\t}\n\n\treturn rules\n}\n\n// GetRulesDynamic returns a slice of rules that could be referred to by a ref.\n//\n// Deprecated: use GetRulesDynamicWithOpts\nfunc (c *Compiler) GetRulesDynamic(ref Ref) []*Rule {\n\treturn c.GetRulesDynamicWithOpts(ref, RulesOptions{})\n}\n\n// GetRulesDynamicWithOpts returns a slice of rules that could be referred to by\n// a ref.\n// When parts of the ref are statically known, we use that information to narrow\n// down which rules the ref could refer to, but in the most general case this\n// will be an over-approximation.\n//\n// E.g., given the following modules:\n//\n//  package a.b.c\n//\n//  r1 = 1  # rule1\n//\n// and:\n//\n//  package a.d.c\n//\n//  r2 = 2  # rule2\n//\n// The following calls yield the rules on the right.\n//\n//  GetRulesDynamicWithOpts(\"data.a[x].c[y]\", opts) => [rule1, rule2]\n//  GetRulesDynamicWithOpts(\"data.a[x].c.r2\", opts) => [rule2]\n//  GetRulesDynamicWithOpts(\"data.a.b[x][y]\", opts) => [rule1]\n//\n// Using the RulesOptions parameter, the inclusion of hidden modules can be\n// controlled:\n//\n// With\n//\n//  package system.main\n//\n//  r3 = 3 # rule3\n//\n// We'd get this result:\n//\n//  GetRulesDynamicWithOpts(\"data[x]\", RulesOptions{IncludeHiddenModules: true}) => [rule1, rule2, rule3]\n//\n// Without the options, it would be excluded.\nfunc (c *Compiler) GetRulesDynamicWithOpts(ref Ref, opts RulesOptions) []*Rule {\n\tnode := c.RuleTree\n\n\tset := map[*Rule]struct{}{}\n\tvar walk func(node *TreeNode, i int)\n\twalk = func(node *TreeNode, i int) {\n\t\tswitch {\n\t\tcase i >= len(ref):\n\t\t\t// We've reached the end of the reference and want to collect everything\n\t\t\t// under this \"prefix\".\n\t\t\tnode.DepthFirst(func(descendant *TreeNode) bool {\n\t\t\t\tinsertRules(set, descendant.Values)\n\t\t\t\tif opts.IncludeHiddenModules {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t\treturn descendant.Hide\n\t\t\t})\n\n\t\tcase i == 0 || IsConstant(ref[i].Value):\n\t\t\t// The head of the ref is always grounded.  In case another part of the\n\t\t\t// ref is also grounded, we can lookup the exact child.  If it's not found\n\t\t\t// we can immediately return...\n\t\t\tif child := node.Child(ref[i].Value); child == nil {\n\t\t\t\treturn\n\t\t\t} else if len(child.Values) > 0 {\n\t\t\t\t// If there are any rules at this position, it's what the ref would\n\t\t\t\t// refer to.  We can just append those and stop here.\n\t\t\t\tinsertRules(set, child.Values)\n\t\t\t} else {\n\t\t\t\t// Otherwise, we continue using the child node.\n\t\t\t\twalk(child, i+1)\n\t\t\t}\n\n\t\tdefault:\n\t\t\t// This part of the ref is a dynamic term.  We can't know what it refers\n\t\t\t// to and will just need to try all of the children.\n\t\t\tfor _, child := range node.Children {\n\t\t\t\tif child.Hide && !opts.IncludeHiddenModules {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tinsertRules(set, child.Values)\n\t\t\t\twalk(child, i+1)\n\t\t\t}\n\t\t}\n\t}\n\n\twalk(node, 0)\n\trules := make([]*Rule, 0, len(set))\n\tfor rule := range set {\n\t\trules = append(rules, rule)\n\t}\n\treturn rules\n}\n\n// Utility: add all rule values to the set.\nfunc insertRules(set map[*Rule]struct{}, rules []util.T) {\n\tfor _, rule := range rules {\n\t\tset[rule.(*Rule)] = struct{}{}\n\t}\n}\n\n// RuleIndex returns a RuleIndex built for the rule set referred to by path.\n// The path must refer to the rule set exactly, i.e., given a rule set at path\n// data.a.b.c.p, refs data.a.b.c.p.x and data.a.b.c would not return a\n// RuleIndex built for the rule.\nfunc (c *Compiler) RuleIndex(path Ref) RuleIndex {\n\tr, ok := c.ruleIndices.Get(path)\n\tif !ok {\n\t\treturn nil\n\t}\n\treturn r.(RuleIndex)\n}\n\n// PassesTypeCheck determines whether the given body passes type checking\nfunc (c *Compiler) PassesTypeCheck(body Body) bool {\n\tchecker := newTypeChecker().WithSchemaSet(c.schemaSet).WithInputType(c.inputType)\n\tenv := c.TypeEnv\n\t_, errs := checker.CheckBody(env, body)\n\treturn len(errs) == 0\n}\n\n// ModuleLoader defines the interface that callers can implement to enable lazy\n// loading of modules during compilation.\ntype ModuleLoader func(resolved map[string]*Module) (parsed map[string]*Module, err error)\n\n// WithModuleLoader sets f as the ModuleLoader on the compiler.\n//\n// The compiler will invoke the ModuleLoader after resolving all references in\n// the current set of input modules. The ModuleLoader can return a new\n// collection of parsed modules that are to be included in the compilation\n// process. This process will repeat until the ModuleLoader returns an empty\n// collection or an error. If an error is returned, compilation will stop\n// immediately.\nfunc (c *Compiler) WithModuleLoader(f ModuleLoader) *Compiler {\n\tc.moduleLoader = f\n\treturn c\n}\n\nfunc (c *Compiler) counterAdd(name string, n uint64) {\n\tif c.metrics == nil {\n\t\treturn\n\t}\n\tc.metrics.Counter(name).Add(n)\n}\n\nfunc (c *Compiler) buildRuleIndices() {\n\n\tc.RuleTree.DepthFirst(func(node *TreeNode) bool {\n\t\tif len(node.Values) == 0 {\n\t\t\treturn false\n\t\t}\n\t\tindex := newBaseDocEqIndex(func(ref Ref) bool {\n\t\t\treturn isVirtual(c.RuleTree, ref.GroundPrefix())\n\t\t})\n\t\tif rules := extractRules(node.Values); index.Build(rules) {\n\t\t\tc.ruleIndices.Put(rules[0].Path(), index)\n\t\t}\n\t\treturn false\n\t})\n\n}\n\nfunc (c *Compiler) buildComprehensionIndices() {\n\tfor _, name := range c.sorted {\n\t\tWalkRules(c.Modules[name], func(r *Rule) bool {\n\t\t\tcandidates := r.Head.Args.Vars()\n\t\t\tcandidates.Update(ReservedVars)\n\t\t\tn := buildComprehensionIndices(c.debug, c.GetArity, candidates, c.RewrittenVars, r.Body, c.comprehensionIndices)\n\t\t\tc.counterAdd(compileStageComprehensionIndexBuild, n)\n\t\t\treturn false\n\t\t})\n\t}\n}\n\n// checkRecursion ensures that there are no recursive definitions, i.e., there are\n// no cycles in the Graph.\nfunc (c *Compiler) checkRecursion() {\n\teq := func(a, b util.T) bool {\n\t\treturn a.(*Rule) == b.(*Rule)\n\t}\n\n\tc.RuleTree.DepthFirst(func(node *TreeNode) bool {\n\t\tfor _, rule := range node.Values {\n\t\t\tfor node := rule.(*Rule); node != nil; node = node.Else {\n\t\t\t\tc.checkSelfPath(node.Loc(), eq, node, node)\n\t\t\t}\n\t\t}\n\t\treturn false\n\t})\n}\n\nfunc (c *Compiler) checkSelfPath(loc *Location, eq func(a, b util.T) bool, a, b util.T) {\n\ttr := NewGraphTraversal(c.Graph)\n\tif p := util.DFSPath(tr, eq, a, b); len(p) > 0 {\n\t\tn := []string{}\n\t\tfor _, x := range p {\n\t\t\tn = append(n, astNodeToString(x))\n\t\t}\n\t\tc.err(NewError(RecursionErr, loc, \"rule %v is recursive: %v\", astNodeToString(a), strings.Join(n, \" -> \")))\n\t}\n}\n\nfunc astNodeToString(x interface{}) string {\n\tswitch x := x.(type) {\n\tcase *Rule:\n\t\treturn string(x.Head.Name)\n\tdefault:\n\t\tpanic(\"not reached\")\n\t}\n}\n\n// checkRuleConflicts ensures that rules definitions are not in conflict.\nfunc (c *Compiler) checkRuleConflicts() {\n\tc.RuleTree.DepthFirst(func(node *TreeNode) bool {\n\t\tif len(node.Values) == 0 {\n\t\t\treturn false\n\t\t}\n\n\t\tkinds := map[DocKind]struct{}{}\n\t\tdefaultRules := 0\n\t\tarities := map[int]struct{}{}\n\n\t\tfor _, rule := range node.Values {\n\t\t\tr := rule.(*Rule)\n\t\t\tkinds[r.Head.DocKind()] = struct{}{}\n\t\t\tarities[len(r.Head.Args)] = struct{}{}\n\t\t\tif r.Default {\n\t\t\t\tdefaultRules++\n\t\t\t}\n\t\t}\n\n\t\tname := Var(node.Key.(String))\n\n\t\tif len(kinds) > 1 || len(arities) > 1 {\n\t\t\tc.err(NewError(TypeErr, node.Values[0].(*Rule).Loc(), \"conflicting rules named %v found\", name))\n\t\t} else if defaultRules > 1 {\n\t\t\tc.err(NewError(TypeErr, node.Values[0].(*Rule).Loc(), \"multiple default rules named %s found\", name))\n\t\t}\n\n\t\treturn false\n\t})\n\n\tif c.pathExists != nil {\n\t\tfor _, err := range CheckPathConflicts(c, c.pathExists) {\n\t\t\tc.err(err)\n\t\t}\n\t}\n\n\tc.ModuleTree.DepthFirst(func(node *ModuleTreeNode) bool {\n\t\tfor _, mod := range node.Modules {\n\t\t\tfor _, rule := range mod.Rules {\n\t\t\t\tif childNode, ok := node.Children[String(rule.Head.Name)]; ok {\n\t\t\t\t\tfor _, childMod := range childNode.Modules {\n\t\t\t\t\t\tmsg := fmt.Sprintf(\"%v conflicts with rule defined at %v\", childMod.Package, rule.Loc())\n\t\t\t\t\t\tc.err(NewError(TypeErr, mod.Package.Loc(), msg))\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn false\n\t})\n}\n\nfunc (c *Compiler) checkUndefinedFuncs() {\n\tfor _, name := range c.sorted {\n\t\tm := c.Modules[name]\n\t\tfor _, err := range checkUndefinedFuncs(c.TypeEnv, m, c.GetArity, c.RewrittenVars) {\n\t\t\tc.err(err)\n\t\t}\n\t}\n}\n\nfunc checkUndefinedFuncs(env *TypeEnv, x interface{}, arity func(Ref) int, rwVars map[Var]Var) Errors {\n\n\tvar errs Errors\n\n\tWalkExprs(x, func(expr *Expr) bool {\n\t\tif !expr.IsCall() {\n\t\t\treturn false\n\t\t}\n\t\tref := expr.Operator()\n\t\tif arity := arity(ref); arity >= 0 {\n\t\t\toperands := len(expr.Operands())\n\t\t\tif expr.Generated { // an output var was added\n\t\t\t\tif !expr.IsEquality() && operands != arity+1 {\n\t\t\t\t\tref = rewriteVarsInRef(rwVars)(ref)\n\t\t\t\t\terrs = append(errs, arityMismatchError(env, ref, expr, arity, operands-1))\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t} else { // either output var or not\n\t\t\t\tif operands != arity && operands != arity+1 {\n\t\t\t\t\tref = rewriteVarsInRef(rwVars)(ref)\n\t\t\t\t\terrs = append(errs, arityMismatchError(env, ref, expr, arity, operands))\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn false\n\t\t}\n\t\tref = rewriteVarsInRef(rwVars)(ref)\n\t\terrs = append(errs, NewError(TypeErr, expr.Loc(), \"undefined function %v\", ref))\n\t\treturn true\n\t})\n\n\treturn errs\n}\n\nfunc arityMismatchError(env *TypeEnv, f Ref, expr *Expr, exp, act int) *Error {\n\tif want, ok := env.Get(f).(*types.Function); ok { // generate richer error for built-in functions\n\t\thave := make([]types.Type, len(expr.Operands()))\n\t\tfor i, op := range expr.Operands() {\n\t\t\thave[i] = env.Get(op)\n\t\t}\n\t\treturn newArgError(expr.Loc(), f, \"arity mismatch\", have, want.NamedFuncArgs())\n\t}\n\tif act != 1 {\n\t\treturn NewError(TypeErr, expr.Loc(), \"function %v has arity %d, got %d arguments\", f, exp, act)\n\t}\n\treturn NewError(TypeErr, expr.Loc(), \"function %v has arity %d, got %d argument\", f, exp, act)\n}\n\n// checkSafetyRuleBodies ensures that variables appearing in negated expressions or non-target\n// positions of built-in expressions will be bound when evaluating the rule from left\n// to right, re-ordering as necessary.\nfunc (c *Compiler) checkSafetyRuleBodies() {\n\tfor _, name := range c.sorted {\n\t\tm := c.Modules[name]\n\t\tWalkRules(m, func(r *Rule) bool {\n\t\t\tsafe := ReservedVars.Copy()\n\t\t\tsafe.Update(r.Head.Args.Vars())\n\t\t\tr.Body = c.checkBodySafety(safe, r.Body)\n\t\t\treturn false\n\t\t})\n\t}\n}\n\nfunc (c *Compiler) checkBodySafety(safe VarSet, b Body) Body {\n\treordered, unsafe := reorderBodyForSafety(c.builtins, c.GetArity, safe, b)\n\tif errs := safetyErrorSlice(unsafe, c.RewrittenVars); len(errs) > 0 {\n\t\tfor _, err := range errs {\n\t\t\tc.err(err)\n\t\t}\n\t\treturn b\n\t}\n\treturn reordered\n}\n\n// SafetyCheckVisitorParams defines the AST visitor parameters to use for collecting\n// variables during the safety check. This has to be exported because it's relied on\n// by the copy propagation implementation in topdown.\nvar SafetyCheckVisitorParams = VarVisitorParams{\n\tSkipRefCallHead: true,\n\tSkipClosures:    true,\n}\n\n// checkSafetyRuleHeads ensures that variables appearing in the head of a\n// rule also appear in the body.\nfunc (c *Compiler) checkSafetyRuleHeads() {\n\n\tfor _, name := range c.sorted {\n\t\tm := c.Modules[name]\n\t\tWalkRules(m, func(r *Rule) bool {\n\t\t\tsafe := r.Body.Vars(SafetyCheckVisitorParams)\n\t\t\tsafe.Update(r.Head.Args.Vars())\n\t\t\tunsafe := r.Head.Vars().Diff(safe)\n\t\t\tfor v := range unsafe {\n\t\t\t\tif w, ok := c.RewrittenVars[v]; ok {\n\t\t\t\t\tv = w\n\t\t\t\t}\n\t\t\t\tif !v.IsGenerated() {\n\t\t\t\t\tc.err(NewError(UnsafeVarErr, r.Loc(), \"var %v is unsafe\", v))\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn false\n\t\t})\n\t}\n}\n\nfunc compileSchema(goSchema interface{}, allowNet []string) (*gojsonschema.Schema, error) {\n\tgojsonschema.SetAllowNet(allowNet)\n\n\tvar refLoader gojsonschema.JSONLoader\n\tsl := gojsonschema.NewSchemaLoader()\n\n\tif goSchema != nil {\n\t\trefLoader = gojsonschema.NewGoLoader(goSchema)\n\t} else {\n\t\treturn nil, fmt.Errorf(\"no schema as input to compile\")\n\t}\n\tschemasCompiled, err := sl.Compile(refLoader)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"unable to compile the schema: %w\", err)\n\t}\n\treturn schemasCompiled, nil\n}\n\nfunc mergeSchemas(schemas ...*gojsonschema.SubSchema) (*gojsonschema.SubSchema, error) {\n\tif len(schemas) == 0 {\n\t\treturn nil, nil\n\t}\n\tvar result = schemas[0]\n\n\tfor i := range schemas {\n\t\tif len(schemas[i].PropertiesChildren) > 0 {\n\t\t\tif !schemas[i].Types.Contains(\"object\") {\n\t\t\t\tif err := schemas[i].Types.Add(\"object\"); err != nil {\n\t\t\t\t\treturn nil, fmt.Errorf(\"unable to set the type in schemas\")\n\t\t\t\t}\n\t\t\t}\n\t\t} else if len(schemas[i].ItemsChildren) > 0 {\n\t\t\tif !schemas[i].Types.Contains(\"array\") {\n\t\t\t\tif err := schemas[i].Types.Add(\"array\"); err != nil {\n\t\t\t\t\treturn nil, fmt.Errorf(\"unable to set the type in schemas\")\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor i := 1; i < len(schemas); i++ {\n\t\tif result.Types.String() != schemas[i].Types.String() {\n\t\t\treturn nil, fmt.Errorf(\"unable to merge these schemas: type mismatch: %v and %v\", result.Types.String(), schemas[i].Types.String())\n\t\t} else if result.Types.Contains(\"object\") && len(result.PropertiesChildren) > 0 && schemas[i].Types.Contains(\"object\") && len(schemas[i].PropertiesChildren) > 0 {\n\t\t\tresult.PropertiesChildren = append(result.PropertiesChildren, schemas[i].PropertiesChildren...)\n\t\t} else if result.Types.Contains(\"array\") && len(result.ItemsChildren) > 0 && schemas[i].Types.Contains(\"array\") && len(schemas[i].ItemsChildren) > 0 {\n\t\t\tfor j := 0; j < len(schemas[i].ItemsChildren); j++ {\n\t\t\t\tif len(result.ItemsChildren)-1 < j && !(len(schemas[i].ItemsChildren)-1 < j) {\n\t\t\t\t\tresult.ItemsChildren = append(result.ItemsChildren, schemas[i].ItemsChildren[j])\n\t\t\t\t}\n\t\t\t\tif result.ItemsChildren[j].Types.String() != schemas[i].ItemsChildren[j].Types.String() {\n\t\t\t\t\treturn nil, fmt.Errorf(\"unable to merge these schemas\")\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn result, nil\n}\n\nfunc parseSchema(schema interface{}) (types.Type, error) {\n\tsubSchema, ok := schema.(*gojsonschema.SubSchema)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"unexpected schema type %v\", subSchema)\n\t}\n\n\t// Handle referenced schemas, returns directly when a $ref is found\n\tif subSchema.RefSchema != nil {\n\t\treturn parseSchema(subSchema.RefSchema)\n\t}\n\n\t// Handle anyOf\n\tif subSchema.AnyOf != nil {\n\t\tvar orType types.Type\n\n\t\t// If there is a core schema, find its type first\n\t\tif subSchema.Types.IsTyped() {\n\t\t\tcopySchema := *subSchema\n\t\t\tcopySchemaRef := &copySchema\n\t\t\tcopySchemaRef.AnyOf = nil\n\t\t\tcoreType, err := parseSchema(copySchemaRef)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"unexpected schema type %v: %w\", subSchema, err)\n\t\t\t}\n\n\t\t\t// Only add Object type with static props to orType\n\t\t\tif objType, ok := coreType.(*types.Object); ok {\n\t\t\t\tif objType.StaticProperties() != nil && objType.DynamicProperties() == nil {\n\t\t\t\t\torType = types.Or(orType, coreType)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Iterate through every property of AnyOf and add it to orType\n\t\tfor _, pSchema := range subSchema.AnyOf {\n\t\t\tnewtype, err := parseSchema(pSchema)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"unexpected schema type %v: %w\", pSchema, err)\n\t\t\t}\n\t\t\torType = types.Or(newtype, orType)\n\t\t}\n\n\t\treturn orType, nil\n\t}\n\n\tif subSchema.AllOf != nil {\n\t\tsubSchemaArray := subSchema.AllOf\n\t\tallOfResult, err := mergeSchemas(subSchemaArray...)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tif subSchema.Types.IsTyped() {\n\t\t\tif (subSchema.Types.Contains(\"object\") && allOfResult.Types.Contains(\"object\")) || (subSchema.Types.Contains(\"array\") && allOfResult.Types.Contains(\"array\")) {\n\t\t\t\tobjectOrArrayResult, err := mergeSchemas(allOfResult, subSchema)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\treturn parseSchema(objectOrArrayResult)\n\t\t\t} else if subSchema.Types.String() != allOfResult.Types.String() {\n\t\t\t\treturn nil, fmt.Errorf(\"unable to merge these schemas\")\n\t\t\t}\n\t\t}\n\t\treturn parseSchema(allOfResult)\n\t}\n\n\tif subSchema.Types.IsTyped() {\n\t\tif subSchema.Types.Contains(\"boolean\") {\n\t\t\treturn types.B, nil\n\n\t\t} else if subSchema.Types.Contains(\"string\") {\n\t\t\treturn types.S, nil\n\n\t\t} else if subSchema.Types.Contains(\"integer\") || subSchema.Types.Contains(\"number\") {\n\t\t\treturn types.N, nil\n\n\t\t} else if subSchema.Types.Contains(\"object\") {\n\t\t\tif len(subSchema.PropertiesChildren) > 0 {\n\t\t\t\tstaticProps := make([]*types.StaticProperty, 0, len(subSchema.PropertiesChildren))\n\t\t\t\tfor _, pSchema := range subSchema.PropertiesChildren {\n\t\t\t\t\tnewtype, err := parseSchema(pSchema)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, fmt.Errorf(\"unexpected schema type %v: %w\", pSchema, err)\n\t\t\t\t\t}\n\t\t\t\t\tstaticProps = append(staticProps, types.NewStaticProperty(pSchema.Property, newtype))\n\t\t\t\t}\n\t\t\t\treturn types.NewObject(staticProps, nil), nil\n\t\t\t}\n\t\t\treturn types.NewObject(nil, types.NewDynamicProperty(types.A, types.A)), nil\n\n\t\t} else if subSchema.Types.Contains(\"array\") {\n\t\t\tif len(subSchema.ItemsChildren) > 0 {\n\t\t\t\tif subSchema.ItemsChildrenIsSingleSchema {\n\t\t\t\t\tiSchema := subSchema.ItemsChildren[0]\n\t\t\t\t\tnewtype, err := parseSchema(iSchema)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, fmt.Errorf(\"unexpected schema type %v\", iSchema)\n\t\t\t\t\t}\n\t\t\t\t\treturn types.NewArray(nil, newtype), nil\n\t\t\t\t}\n\t\t\t\tnewTypes := make([]types.Type, 0, len(subSchema.ItemsChildren))\n\t\t\t\tfor i := 0; i != len(subSchema.ItemsChildren); i++ {\n\t\t\t\t\tiSchema := subSchema.ItemsChildren[i]\n\t\t\t\t\tnewtype, err := parseSchema(iSchema)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, fmt.Errorf(\"unexpected schema type %v\", iSchema)\n\t\t\t\t\t}\n\t\t\t\t\tnewTypes = append(newTypes, newtype)\n\t\t\t\t}\n\t\t\t\treturn types.NewArray(newTypes, nil), nil\n\t\t\t}\n\t\t\treturn types.NewArray(nil, types.A), nil\n\t\t}\n\t}\n\n\t// Assume types if not specified in schema\n\tif len(subSchema.PropertiesChildren) > 0 {\n\t\tif err := subSchema.Types.Add(\"object\"); err == nil {\n\t\t\treturn parseSchema(subSchema)\n\t\t}\n\t} else if len(subSchema.ItemsChildren) > 0 {\n\t\tif err := subSchema.Types.Add(\"array\"); err == nil {\n\t\t\treturn parseSchema(subSchema)\n\t\t}\n\t}\n\n\treturn types.A, nil\n}\n\nfunc (c *Compiler) setAnnotationSet() {\n\t// Sorting modules by name for stable error reporting\n\tsorted := make([]*Module, 0, len(c.Modules))\n\tfor _, mName := range c.sorted {\n\t\tsorted = append(sorted, c.Modules[mName])\n\t}\n\n\tas, errs := BuildAnnotationSet(sorted)\n\tfor _, err := range errs {\n\t\tc.err(err)\n\t}\n\tc.annotationSet = as\n}\n\n// checkTypes runs the type checker on all rules. The type checker builds a\n// TypeEnv that is stored on the compiler.\nfunc (c *Compiler) checkTypes() {\n\t// Recursion is caught in earlier step, so this cannot fail.\n\tsorted, _ := c.Graph.Sort()\n\tchecker := newTypeChecker().\n\t\tWithSchemaSet(c.schemaSet).\n\t\tWithInputType(c.inputType).\n\t\tWithVarRewriter(rewriteVarsInRef(c.RewrittenVars))\n\tenv, errs := checker.CheckTypes(c.TypeEnv, sorted, c.annotationSet)\n\tfor _, err := range errs {\n\t\tc.err(err)\n\t}\n\tc.TypeEnv = env\n}\n\nfunc (c *Compiler) checkUnsafeBuiltins() {\n\tfor _, name := range c.sorted {\n\t\terrs := checkUnsafeBuiltins(c.unsafeBuiltinsMap, c.Modules[name])\n\t\tfor _, err := range errs {\n\t\t\tc.err(err)\n\t\t}\n\t}\n}\n\nfunc (c *Compiler) checkDeprecatedBuiltins() {\n\tfor _, name := range c.sorted {\n\t\terrs := checkDeprecatedBuiltins(c.deprecatedBuiltinsMap, c.Modules[name], c.strict)\n\t\tfor _, err := range errs {\n\t\t\tc.err(err)\n\t\t}\n\t}\n}\n\nfunc (c *Compiler) runStage(metricName string, f func()) {\n\tif c.metrics != nil {\n\t\tc.metrics.Timer(metricName).Start()\n\t\tdefer c.metrics.Timer(metricName).Stop()\n\t}\n\tf()\n}\n\nfunc (c *Compiler) runStageAfter(metricName string, s CompilerStage) *Error {\n\tif c.metrics != nil {\n\t\tc.metrics.Timer(metricName).Start()\n\t\tdefer c.metrics.Timer(metricName).Stop()\n\t}\n\treturn s(c)\n}\n\nfunc (c *Compiler) compile() {\n\n\tdefer func() {\n\t\tif r := recover(); r != nil && r != errLimitReached {\n\t\t\tpanic(r)\n\t\t}\n\t}()\n\n\tfor _, s := range c.stages {\n\t\tc.runStage(s.metricName, s.f)\n\t\tif c.Failed() {\n\t\t\treturn\n\t\t}\n\t\tfor _, a := range c.after[s.name] {\n\t\t\tif err := c.runStageAfter(a.MetricName, a.Stage); err != nil {\n\t\t\t\tc.err(err)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc (c *Compiler) init() {\n\n\tif c.initialized {\n\t\treturn\n\t}\n\n\tif c.capabilities == nil {\n\t\tc.capabilities = CapabilitiesForThisVersion()\n\t}\n\n\tc.builtins = make(map[string]*Builtin, len(c.capabilities.Builtins)+len(c.customBuiltins))\n\n\tfor _, bi := range c.capabilities.Builtins {\n\t\tc.builtins[bi.Name] = bi\n\t\tif c.strict && bi.IsDeprecated() {\n\t\t\tc.deprecatedBuiltinsMap[bi.Name] = struct{}{}\n\t\t}\n\t}\n\n\tfor name, bi := range c.customBuiltins {\n\t\tc.builtins[name] = bi\n\t}\n\n\t// Load the global input schema if one was provided.\n\tif c.schemaSet != nil {\n\t\tif schema := c.schemaSet.Get(SchemaRootRef); schema != nil {\n\t\t\ttpe, err := loadSchema(schema, c.capabilities.AllowNet)\n\t\t\tif err != nil {\n\t\t\t\tc.err(NewError(TypeErr, nil, err.Error()))\n\t\t\t} else {\n\t\t\t\tc.inputType = tpe\n\t\t\t}\n\t\t}\n\t}\n\n\tc.TypeEnv = newTypeChecker().\n\t\tWithSchemaSet(c.schemaSet).\n\t\tWithInputType(c.inputType).\n\t\tEnv(c.builtins)\n\n\tc.initialized = true\n}\n\nfunc (c *Compiler) err(err *Error) {\n\tif c.maxErrs > 0 && len(c.Errors) >= c.maxErrs {\n\t\tc.Errors = append(c.Errors, errLimitReached)\n\t\tpanic(errLimitReached)\n\t}\n\tc.Errors = append(c.Errors, err)\n}\n\nfunc (c *Compiler) getExports() *util.HashMap {\n\n\trules := util.NewHashMap(func(a, b util.T) bool {\n\t\treturn a.(Ref).Equal(b.(Ref))\n\t}, func(v util.T) int {\n\t\treturn v.(Ref).Hash()\n\t})\n\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\trv, ok := rules.Get(mod.Package.Path)\n\t\tif !ok {\n\t\t\trv = []Var{}\n\t\t}\n\t\trvs := rv.([]Var)\n\n\t\tfor _, rule := range mod.Rules {\n\t\t\trvs = append(rvs, rule.Head.Name)\n\t\t}\n\t\trules.Put(mod.Package.Path, rvs)\n\t}\n\n\treturn rules\n}\n\nfunc (c *Compiler) GetAnnotationSet() *AnnotationSet {\n\treturn c.annotationSet\n}\n\nfunc (c *Compiler) checkDuplicateImports() {\n\tif !c.strict {\n\t\treturn\n\t}\n\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\tprocessedImports := map[Var]*Import{}\n\n\t\tfor _, imp := range mod.Imports {\n\t\t\tname := imp.Name()\n\n\t\t\tif processed, conflict := processedImports[name]; conflict {\n\t\t\t\tc.err(NewError(CompileErr, imp.Location, \"import must not shadow %v\", processed))\n\t\t\t} else {\n\t\t\t\tprocessedImports[name] = imp\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc (c *Compiler) checkKeywordOverrides() {\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\terrs := checkKeywordOverrides(mod, c.strict)\n\t\tfor _, err := range errs {\n\t\t\tc.err(err)\n\t\t}\n\t}\n}\n\nfunc checkKeywordOverrides(node interface{}, strict bool) Errors {\n\tif !strict {\n\t\treturn nil\n\t}\n\n\terrors := Errors{}\n\n\tWalkRules(node, func(rule *Rule) bool {\n\t\tname := rule.Head.Name.String()\n\t\tif RootDocumentRefs.Contains(RefTerm(VarTerm(name))) {\n\t\t\terrors = append(errors, NewError(CompileErr, rule.Location, \"rules must not shadow %v (use a different rule name)\", name))\n\t\t}\n\t\treturn true\n\t})\n\n\tWalkExprs(node, func(expr *Expr) bool {\n\t\tif expr.IsAssignment() {\n\t\t\tname := expr.Operand(0).String()\n\t\t\tif RootDocumentRefs.Contains(RefTerm(VarTerm(name))) {\n\t\t\t\terrors = append(errors, NewError(CompileErr, expr.Location, \"variables must not shadow %v (use a different variable name)\", name))\n\t\t\t}\n\t\t}\n\t\treturn false\n\t})\n\n\treturn errors\n}\n\n// resolveAllRefs resolves references in expressions to their fully qualified values.\n//\n// For instance, given the following module:\n//\n// package a.b\n// import data.foo.bar\n// p[x] { bar[_] = x }\n//\n// The reference \"bar[_]\" would be resolved to \"data.foo.bar[_]\".\nfunc (c *Compiler) resolveAllRefs() {\n\n\trules := c.getExports()\n\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\n\t\tvar ruleExports []Var\n\t\tif x, ok := rules.Get(mod.Package.Path); ok {\n\t\t\truleExports = x.([]Var)\n\t\t}\n\n\t\tglobals := getGlobals(mod.Package, ruleExports, mod.Imports)\n\n\t\tWalkRules(mod, func(rule *Rule) bool {\n\t\t\terr := resolveRefsInRule(globals, rule)\n\t\t\tif err != nil {\n\t\t\t\tc.err(NewError(CompileErr, rule.Location, err.Error()))\n\t\t\t}\n\t\t\treturn false\n\t\t})\n\n\t\tif c.strict { // check for unused imports\n\t\t\tfor _, imp := range mod.Imports {\n\t\t\t\tpath := imp.Path.Value.(Ref)\n\t\t\t\tif FutureRootDocument.Equal(path[0]) {\n\t\t\t\t\tcontinue // ignore future imports\n\t\t\t\t}\n\n\t\t\t\tfor v, u := range globals {\n\t\t\t\t\tif v.Equal(imp.Name()) && !u.used {\n\t\t\t\t\t\tc.err(NewError(CompileErr, imp.Location, \"%s unused\", imp.String()))\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif c.moduleLoader != nil {\n\n\t\tparsed, err := c.moduleLoader(c.Modules)\n\t\tif err != nil {\n\t\t\tc.err(NewError(CompileErr, nil, err.Error()))\n\t\t\treturn\n\t\t}\n\n\t\tif len(parsed) == 0 {\n\t\t\treturn\n\t\t}\n\n\t\tfor id, module := range parsed {\n\t\t\tc.Modules[id] = module.Copy()\n\t\t\tc.sorted = append(c.sorted, id)\n\t\t\tif c.parsedModules != nil {\n\t\t\t\tc.parsedModules[id] = module\n\t\t\t}\n\t\t}\n\n\t\tsort.Strings(c.sorted)\n\t\tc.resolveAllRefs()\n\t}\n}\n\nfunc (c *Compiler) removeImports() {\n\tfor name := range c.Modules {\n\t\tc.Modules[name].Imports = nil\n\t}\n}\n\nfunc (c *Compiler) initLocalVarGen() {\n\tc.localvargen = newLocalVarGeneratorForModuleSet(c.sorted, c.Modules)\n}\n\nfunc (c *Compiler) rewriteComprehensionTerms() {\n\tf := newEqualityFactory(c.localvargen)\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\t_, _ = rewriteComprehensionTerms(f, mod) // ignore error\n\t}\n}\n\nfunc (c *Compiler) rewriteExprTerms() {\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\tWalkRules(mod, func(rule *Rule) bool {\n\t\t\trewriteExprTermsInHead(c.localvargen, rule)\n\t\t\trule.Body = rewriteExprTermsInBody(c.localvargen, rule.Body)\n\t\t\treturn false\n\t\t})\n\t}\n}\n\nfunc (c *Compiler) checkVoidCalls() {\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\tfor _, err := range checkVoidCalls(c.TypeEnv, mod) {\n\t\t\tc.err(err)\n\t\t}\n\t}\n}\n\nfunc (c *Compiler) rewritePrintCalls() {\n\tif !c.enablePrintStatements {\n\t\tfor _, name := range c.sorted {\n\t\t\terasePrintCalls(c.Modules[name])\n\t\t}\n\t\treturn\n\t}\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\tWalkRules(mod, func(r *Rule) bool {\n\t\t\tsafe := r.Head.Args.Vars()\n\t\t\tsafe.Update(ReservedVars)\n\t\t\tvis := func(b Body) bool {\n\t\t\t\tfor _, err := range rewritePrintCalls(c.localvargen, c.GetArity, safe, b) {\n\t\t\t\t\tc.err(err)\n\t\t\t\t}\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tWalkBodies(r.Head, vis)\n\t\t\tWalkBodies(r.Body, vis)\n\t\t\treturn false\n\t\t})\n\t}\n}\n\n// checkVoidCalls returns errors for any expressions that treat void function\n// calls as values. The only void functions in Rego are specific built-ins like\n// print().\nfunc checkVoidCalls(env *TypeEnv, x interface{}) Errors {\n\tvar errs Errors\n\tWalkTerms(x, func(x *Term) bool {\n\t\tif call, ok := x.Value.(Call); ok {\n\t\t\tif tpe, ok := env.Get(call[0]).(*types.Function); ok && tpe.Result() == nil {\n\t\t\t\terrs = append(errs, NewError(TypeErr, x.Loc(), \"%v used as value\", call))\n\t\t\t}\n\t\t}\n\t\treturn false\n\t})\n\treturn errs\n}\n\n// rewritePrintCalls will rewrite the body so that print operands are captured\n// in local variables and their evaluation occurs within a comprehension.\n// Wrapping the terms inside of a comprehension ensures that undefined values do\n// not short-circuit evaluation.\n//\n// For example, given the following print statement:\n//\n//   print(\"the value of x is:\", input.x)\n//\n// The expression would be rewritten to:\n//\n//   print({__local0__ | __local0__ = \"the value of x is:\"}, {__local1__ | __local1__ = input.x})\nfunc rewritePrintCalls(gen *localVarGenerator, getArity func(Ref) int, globals VarSet, body Body) Errors {\n\n\tvar errs Errors\n\n\t// Visit comprehension bodies recursively to ensure print statements inside\n\t// those bodies only close over variables that are safe.\n\tfor i := range body {\n\t\tif ContainsClosures(body[i]) {\n\t\t\tsafe := outputVarsForBody(body[:i], getArity, globals)\n\t\t\tsafe.Update(globals)\n\t\t\tWalkClosures(body[i], func(x interface{}) bool {\n\t\t\t\tswitch x := x.(type) {\n\t\t\t\tcase *SetComprehension:\n\t\t\t\t\terrs = rewritePrintCalls(gen, getArity, safe, x.Body)\n\t\t\t\tcase *ArrayComprehension:\n\t\t\t\t\terrs = rewritePrintCalls(gen, getArity, safe, x.Body)\n\t\t\t\tcase *ObjectComprehension:\n\t\t\t\t\terrs = rewritePrintCalls(gen, getArity, safe, x.Body)\n\t\t\t\tcase *Every:\n\t\t\t\t\tsafe.Update(x.KeyValueVars())\n\t\t\t\t\terrs = rewritePrintCalls(gen, getArity, safe, x.Body)\n\t\t\t\t}\n\t\t\t\treturn true\n\t\t\t})\n\t\t\tif len(errs) > 0 {\n\t\t\t\treturn errs\n\t\t\t}\n\t\t}\n\t}\n\n\tfor i := range body {\n\n\t\tif !isPrintCall(body[i]) {\n\t\t\tcontinue\n\t\t}\n\n\t\tvar errs Errors\n\t\tsafe := outputVarsForBody(body[:i], getArity, globals)\n\t\tsafe.Update(globals)\n\t\targs := body[i].Operands()\n\n\t\tfor j := range args {\n\t\t\tvis := NewVarVisitor().WithParams(SafetyCheckVisitorParams)\n\t\t\tvis.Walk(args[j])\n\t\t\tunsafe := vis.Vars().Diff(safe)\n\t\t\tfor _, v := range unsafe.Sorted() {\n\t\t\t\terrs = append(errs, NewError(CompileErr, args[j].Loc(), \"var %v is undeclared\", v))\n\t\t\t}\n\t\t}\n\n\t\tif len(errs) > 0 {\n\t\t\treturn errs\n\t\t}\n\n\t\tarr := NewArray()\n\n\t\tfor j := range args {\n\t\t\tx := NewTerm(gen.Generate()).SetLocation(args[j].Loc())\n\t\t\tcapture := Equality.Expr(x, args[j]).SetLocation(args[j].Loc())\n\t\t\tarr = arr.Append(SetComprehensionTerm(x, NewBody(capture)).SetLocation(args[j].Loc()))\n\t\t}\n\n\t\tbody.Set(NewExpr([]*Term{\n\t\t\tNewTerm(InternalPrint.Ref()).SetLocation(body[i].Loc()),\n\t\t\tNewTerm(arr).SetLocation(body[i].Loc()),\n\t\t}).SetLocation(body[i].Loc()), i)\n\t}\n\n\treturn nil\n}\n\nfunc erasePrintCalls(node interface{}) {\n\tNewGenericVisitor(func(x interface{}) bool {\n\t\tswitch x := x.(type) {\n\t\tcase *Rule:\n\t\t\tx.Body = erasePrintCallsInBody(x.Body)\n\t\tcase *ArrayComprehension:\n\t\t\tx.Body = erasePrintCallsInBody(x.Body)\n\t\tcase *SetComprehension:\n\t\t\tx.Body = erasePrintCallsInBody(x.Body)\n\t\tcase *ObjectComprehension:\n\t\t\tx.Body = erasePrintCallsInBody(x.Body)\n\t\tcase *Every:\n\t\t\tx.Body = erasePrintCallsInBody(x.Body)\n\t\t}\n\t\treturn false\n\t}).Walk(node)\n}\n\nfunc erasePrintCallsInBody(x Body) Body {\n\n\tif !containsPrintCall(x) {\n\t\treturn x\n\t}\n\n\tvar cpy Body\n\n\tfor i := range x {\n\n\t\t// Recursively visit any comprehensions contained in this expression.\n\t\terasePrintCalls(x[i])\n\n\t\tif !isPrintCall(x[i]) {\n\t\t\tcpy.Append(x[i])\n\t\t}\n\t}\n\n\tif len(cpy) == 0 {\n\t\tterm := BooleanTerm(true).SetLocation(x.Loc())\n\t\texpr := NewExpr(term).SetLocation(x.Loc())\n\t\tcpy.Append(expr)\n\t}\n\n\treturn cpy\n}\n\nfunc containsPrintCall(x Body) bool {\n\tvar found bool\n\tWalkExprs(x, func(expr *Expr) bool {\n\t\tif !found {\n\t\t\tif isPrintCall(expr) {\n\t\t\t\tfound = true\n\t\t\t}\n\t\t}\n\t\treturn found\n\t})\n\treturn found\n}\n\nfunc isPrintCall(x *Expr) bool {\n\treturn x.IsCall() && x.Operator().Equal(Print.Ref())\n}\n\n// rewriteTermsInHead will rewrite rules so that the head does not contain any\n// terms that require evaluation (e.g., refs or comprehensions). If the key or\n// value contains one or more of these terms, the key or value will be moved\n// into the body and assigned to a new variable. The new variable will replace\n// the key or value in the head.\n//\n// For instance, given the following rule:\n//\n// p[{\"foo\": data.foo[i]}] { i < 100 }\n//\n// The rule would be re-written as:\n//\n// p[__local0__] { i < 100; __local0__ = {\"foo\": data.foo[i]} }\nfunc (c *Compiler) rewriteRefsInHead() {\n\tf := newEqualityFactory(c.localvargen)\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\tWalkRules(mod, func(rule *Rule) bool {\n\t\t\tif requiresEval(rule.Head.Key) {\n\t\t\t\texpr := f.Generate(rule.Head.Key)\n\t\t\t\trule.Head.Key = expr.Operand(0)\n\t\t\t\trule.Body.Append(expr)\n\t\t\t}\n\t\t\tif requiresEval(rule.Head.Value) {\n\t\t\t\texpr := f.Generate(rule.Head.Value)\n\t\t\t\trule.Head.Value = expr.Operand(0)\n\t\t\t\trule.Body.Append(expr)\n\t\t\t}\n\t\t\tfor i := 0; i < len(rule.Head.Args); i++ {\n\t\t\t\tif requiresEval(rule.Head.Args[i]) {\n\t\t\t\t\texpr := f.Generate(rule.Head.Args[i])\n\t\t\t\t\trule.Head.Args[i] = expr.Operand(0)\n\t\t\t\t\trule.Body.Append(expr)\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn false\n\t\t})\n\t}\n}\n\nfunc (c *Compiler) rewriteEquals() {\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\trewriteEquals(mod)\n\t}\n}\n\nfunc (c *Compiler) rewriteDynamicTerms() {\n\tf := newEqualityFactory(c.localvargen)\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\tWalkRules(mod, func(rule *Rule) bool {\n\t\t\trule.Body = rewriteDynamics(f, rule.Body)\n\t\t\treturn false\n\t\t})\n\t}\n}\n\nfunc (c *Compiler) parseMetadataBlocks() {\n\t// Only parse annotations if rego.metadata built-ins are called\n\tregoMetadataCalled := false\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\tWalkExprs(mod, func(expr *Expr) bool {\n\t\t\tif isRegoMetadataChainCall(expr) || isRegoMetadataRuleCall(expr) {\n\t\t\t\tregoMetadataCalled = true\n\t\t\t}\n\t\t\treturn regoMetadataCalled\n\t\t})\n\n\t\tif regoMetadataCalled {\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif regoMetadataCalled {\n\t\t// NOTE: Possible optimization: only parse annotations for modules on the path of rego.metadata-calling module\n\t\tfor _, name := range c.sorted {\n\t\t\tmod := c.Modules[name]\n\n\t\t\tif len(mod.Annotations) == 0 {\n\t\t\t\tvar errs Errors\n\t\t\t\tmod.Annotations, errs = parseAnnotations(mod.Comments)\n\t\t\t\terrs = append(errs, attachAnnotationsNodes(mod)...)\n\t\t\t\tfor _, err := range errs {\n\t\t\t\t\tc.err(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc (c *Compiler) rewriteRegoMetadataCalls() {\n\teqFactory := newEqualityFactory(c.localvargen)\n\n\t_, chainFuncAllowed := c.builtins[RegoMetadataChain.Name]\n\t_, ruleFuncAllowed := c.builtins[RegoMetadataRule.Name]\n\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\n\t\tWalkRules(mod, func(rule *Rule) bool {\n\t\t\tvar firstChainCall *Expr\n\t\t\tvar firstRuleCall *Expr\n\n\t\t\tWalkExprs(rule, func(expr *Expr) bool {\n\t\t\t\tif chainFuncAllowed && firstChainCall == nil && isRegoMetadataChainCall(expr) {\n\t\t\t\t\tfirstChainCall = expr\n\t\t\t\t} else if ruleFuncAllowed && firstRuleCall == nil && isRegoMetadataRuleCall(expr) {\n\t\t\t\t\tfirstRuleCall = expr\n\t\t\t\t}\n\t\t\t\treturn firstChainCall != nil && firstRuleCall != nil\n\t\t\t})\n\n\t\t\tchainCalled := firstChainCall != nil\n\t\t\truleCalled := firstRuleCall != nil\n\n\t\t\tif chainCalled || ruleCalled {\n\t\t\t\tbody := make(Body, 0, len(rule.Body)+2)\n\n\t\t\t\tvar metadataChainVar Var\n\t\t\t\tif chainCalled {\n\t\t\t\t\t// Create and inject metadata chain for rule\n\n\t\t\t\t\tchain, err := createMetadataChain(c.annotationSet.Chain(rule))\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tc.err(err)\n\t\t\t\t\t\treturn false\n\t\t\t\t\t}\n\n\t\t\t\t\tchain.Location = firstChainCall.Location\n\t\t\t\t\teq := eqFactory.Generate(chain)\n\t\t\t\t\tmetadataChainVar = eq.Operands()[0].Value.(Var)\n\t\t\t\t\tbody.Append(eq)\n\t\t\t\t}\n\n\t\t\t\tvar metadataRuleVar Var\n\t\t\t\tif ruleCalled {\n\t\t\t\t\t// Create and inject metadata for rule\n\n\t\t\t\t\tvar metadataRuleTerm *Term\n\n\t\t\t\t\ta := getPrimaryRuleAnnotations(c.annotationSet, rule)\n\t\t\t\t\tif a != nil {\n\t\t\t\t\t\tannotObj, err := a.toObject()\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\tc.err(err)\n\t\t\t\t\t\t\treturn false\n\t\t\t\t\t\t}\n\t\t\t\t\t\tmetadataRuleTerm = NewTerm(*annotObj)\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// If rule has no annotations, assign an empty object\n\t\t\t\t\t\tmetadataRuleTerm = ObjectTerm()\n\t\t\t\t\t}\n\n\t\t\t\t\tmetadataRuleTerm.Location = firstRuleCall.Location\n\t\t\t\t\teq := eqFactory.Generate(metadataRuleTerm)\n\t\t\t\t\tmetadataRuleVar = eq.Operands()[0].Value.(Var)\n\t\t\t\t\tbody.Append(eq)\n\t\t\t\t}\n\n\t\t\t\tfor _, expr := range rule.Body {\n\t\t\t\t\tbody.Append(expr)\n\t\t\t\t}\n\t\t\t\trule.Body = body\n\n\t\t\t\tvis := func(b Body) bool {\n\t\t\t\t\tfor _, err := range rewriteRegoMetadataCalls(&metadataChainVar, &metadataRuleVar, b, &c.RewrittenVars) {\n\t\t\t\t\t\tc.err(err)\n\t\t\t\t\t}\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t\tWalkBodies(rule.Head, vis)\n\t\t\t\tWalkBodies(rule.Body, vis)\n\t\t\t}\n\n\t\t\treturn false\n\t\t})\n\t}\n}\n\nfunc getPrimaryRuleAnnotations(as *AnnotationSet, rule *Rule) *Annotations {\n\tannots := as.GetRuleScope(rule)\n\n\tif len(annots) == 0 {\n\t\treturn nil\n\t}\n\n\t// Sort by annotation location; chain must start with annotations declared closest to rule, then going outward\n\tsort.SliceStable(annots, func(i, j int) bool {\n\t\treturn annots[i].Location.Compare(annots[j].Location) > 0\n\t})\n\n\treturn annots[0]\n}\n\nfunc rewriteRegoMetadataCalls(metadataChainVar *Var, metadataRuleVar *Var, body Body, rewrittenVars *map[Var]Var) Errors {\n\tvar errs Errors\n\n\tWalkClosures(body, func(x interface{}) bool {\n\t\tswitch x := x.(type) {\n\t\tcase *ArrayComprehension:\n\t\t\terrs = rewriteRegoMetadataCalls(metadataChainVar, metadataRuleVar, x.Body, rewrittenVars)\n\t\tcase *SetComprehension:\n\t\t\terrs = rewriteRegoMetadataCalls(metadataChainVar, metadataRuleVar, x.Body, rewrittenVars)\n\t\tcase *ObjectComprehension:\n\t\t\terrs = rewriteRegoMetadataCalls(metadataChainVar, metadataRuleVar, x.Body, rewrittenVars)\n\t\tcase *Every:\n\t\t\terrs = rewriteRegoMetadataCalls(metadataChainVar, metadataRuleVar, x.Body, rewrittenVars)\n\t\t}\n\t\treturn true\n\t})\n\n\tfor i := range body {\n\t\texpr := body[i]\n\t\tvar metadataVar Var\n\n\t\tif metadataChainVar != nil && isRegoMetadataChainCall(expr) {\n\t\t\tmetadataVar = *metadataChainVar\n\t\t} else if metadataRuleVar != nil && isRegoMetadataRuleCall(expr) {\n\t\t\tmetadataVar = *metadataRuleVar\n\t\t} else {\n\t\t\tcontinue\n\t\t}\n\n\t\t// NOTE(johanfylling): An alternative strategy would be to walk the body and replace all operands[0]\n\t\t// usages with *metadataChainVar\n\t\toperands := expr.Operands()\n\t\tvar newExpr *Expr\n\t\tif len(operands) > 0 { // There is an output var to rewrite\n\t\t\trewrittenVar := operands[0]\n\t\t\tnewExpr = Equality.Expr(rewrittenVar, NewTerm(metadataVar))\n\t\t} else { // No output var, just rewrite expr to metadataVar\n\t\t\tnewExpr = NewExpr(NewTerm(metadataVar))\n\t\t}\n\n\t\tnewExpr.Generated = true\n\t\tnewExpr.Location = expr.Location\n\t\tbody.Set(newExpr, i)\n\t}\n\n\treturn errs\n}\n\nfunc isRegoMetadataChainCall(x *Expr) bool {\n\treturn x.IsCall() && x.Operator().Equal(RegoMetadataChain.Ref())\n}\n\nfunc isRegoMetadataRuleCall(x *Expr) bool {\n\treturn x.IsCall() && x.Operator().Equal(RegoMetadataRule.Ref())\n}\n\nfunc createMetadataChain(chain []*AnnotationsRef) (*Term, *Error) {\n\n\tmetaArray := NewArray()\n\tfor _, link := range chain {\n\t\tp := link.Path.toArray().\n\t\t\tSlice(1, -1) // Dropping leading 'data' element of path\n\t\tobj := NewObject(\n\t\t\tItem(StringTerm(\"path\"), NewTerm(p)),\n\t\t)\n\t\tif link.Annotations != nil {\n\t\t\tannotObj, err := link.Annotations.toObject()\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tobj.Insert(StringTerm(\"annotations\"), NewTerm(*annotObj))\n\t\t}\n\t\tmetaArray = metaArray.Append(NewTerm(obj))\n\t}\n\n\treturn NewTerm(metaArray), nil\n}\n\nfunc (c *Compiler) rewriteLocalVars() {\n\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\tgen := c.localvargen\n\n\t\tWalkRules(mod, func(rule *Rule) bool {\n\n\t\t\t// Rewrite assignments contained in head of rule. Assignments can\n\t\t\t// occur in rule head if they're inside a comprehension. Note,\n\t\t\t// assigned vars in comprehensions in the head will be rewritten\n\t\t\t// first to preserve scoping rules. For example:\n\t\t\t//\n\t\t\t// p = [x | x := 1] { x := 2 } becomes p = [__local0__ | __local0__ = 1] { __local1__ = 2 }\n\t\t\t//\n\t\t\t// This behaviour is consistent scoping inside the body. For example:\n\t\t\t//\n\t\t\t// p = xs { x := 2; xs = [x | x := 1] } becomes p = xs { __local0__ = 2; xs = [__local1__ | __local1__ = 1] }\n\t\t\tnestedXform := &rewriteNestedHeadVarLocalTransform{\n\t\t\t\tgen:           gen,\n\t\t\t\tRewrittenVars: c.RewrittenVars,\n\t\t\t\tstrict:        c.strict,\n\t\t\t}\n\n\t\t\tNewGenericVisitor(nestedXform.Visit).Walk(rule.Head)\n\n\t\t\tfor _, err := range nestedXform.errs {\n\t\t\t\tc.err(err)\n\t\t\t}\n\n\t\t\t// Rewrite assignments in body.\n\t\t\tused := NewVarSet()\n\n\t\t\tif rule.Head.Key != nil {\n\t\t\t\tused.Update(rule.Head.Key.Vars())\n\t\t\t}\n\n\t\t\tif rule.Head.Value != nil {\n\t\t\t\tused.Update(rule.Head.Value.Vars())\n\t\t\t}\n\n\t\t\tstack := newLocalDeclaredVars()\n\n\t\t\tc.rewriteLocalArgVars(gen, stack, rule)\n\n\t\t\tbody, declared, errs := rewriteLocalVars(gen, stack, used, rule.Body, c.strict)\n\t\t\tfor _, err := range errs {\n\t\t\t\tc.err(err)\n\t\t\t}\n\n\t\t\t// For rewritten vars use the collection of all variables that\n\t\t\t// were in the stack at some point in time.\n\t\t\tfor k, v := range stack.rewritten {\n\t\t\t\tc.RewrittenVars[k] = v\n\t\t\t}\n\n\t\t\trule.Body = body\n\n\t\t\t// Rewrite vars in head that refer to locally declared vars in the body.\n\t\t\tlocalXform := rewriteHeadVarLocalTransform{declared: declared}\n\n\t\t\tfor i := range rule.Head.Args {\n\t\t\t\trule.Head.Args[i], _ = transformTerm(localXform, rule.Head.Args[i])\n\t\t\t}\n\n\t\t\tif rule.Head.Key != nil {\n\t\t\t\trule.Head.Key, _ = transformTerm(localXform, rule.Head.Key)\n\t\t\t}\n\n\t\t\tif rule.Head.Value != nil {\n\t\t\t\trule.Head.Value, _ = transformTerm(localXform, rule.Head.Value)\n\t\t\t}\n\n\t\t\treturn false\n\t\t})\n\t}\n}\n\ntype rewriteNestedHeadVarLocalTransform struct {\n\tgen           *localVarGenerator\n\terrs          Errors\n\tRewrittenVars map[Var]Var\n\tstrict        bool\n}\n\nfunc (xform *rewriteNestedHeadVarLocalTransform) Visit(x interface{}) bool {\n\n\tif term, ok := x.(*Term); ok {\n\n\t\tstop := false\n\t\tstack := newLocalDeclaredVars()\n\n\t\tswitch x := term.Value.(type) {\n\t\tcase *object:\n\t\t\tcpy, _ := x.Map(func(k, v *Term) (*Term, *Term, error) {\n\t\t\t\tkcpy := k.Copy()\n\t\t\t\tNewGenericVisitor(xform.Visit).Walk(kcpy)\n\t\t\t\tvcpy := v.Copy()\n\t\t\t\tNewGenericVisitor(xform.Visit).Walk(vcpy)\n\t\t\t\treturn kcpy, vcpy, nil\n\t\t\t})\n\t\t\tterm.Value = cpy\n\t\t\tstop = true\n\t\tcase *set:\n\t\t\tcpy, _ := x.Map(func(v *Term) (*Term, error) {\n\t\t\t\tvcpy := v.Copy()\n\t\t\t\tNewGenericVisitor(xform.Visit).Walk(vcpy)\n\t\t\t\treturn vcpy, nil\n\t\t\t})\n\t\t\tterm.Value = cpy\n\t\t\tstop = true\n\t\tcase *ArrayComprehension:\n\t\t\txform.errs = rewriteDeclaredVarsInArrayComprehension(xform.gen, stack, x, xform.errs, xform.strict)\n\t\t\tstop = true\n\t\tcase *SetComprehension:\n\t\t\txform.errs = rewriteDeclaredVarsInSetComprehension(xform.gen, stack, x, xform.errs, xform.strict)\n\t\t\tstop = true\n\t\tcase *ObjectComprehension:\n\t\t\txform.errs = rewriteDeclaredVarsInObjectComprehension(xform.gen, stack, x, xform.errs, xform.strict)\n\t\t\tstop = true\n\t\t}\n\n\t\tfor k, v := range stack.rewritten {\n\t\t\txform.RewrittenVars[k] = v\n\t\t}\n\n\t\treturn stop\n\t}\n\n\treturn false\n}\n\ntype rewriteHeadVarLocalTransform struct {\n\tdeclared map[Var]Var\n}\n\nfunc (xform rewriteHeadVarLocalTransform) Transform(x interface{}) (interface{}, error) {\n\tif v, ok := x.(Var); ok {\n\t\tif gv, ok := xform.declared[v]; ok {\n\t\t\treturn gv, nil\n\t\t}\n\t}\n\treturn x, nil\n}\n\nfunc (c *Compiler) rewriteLocalArgVars(gen *localVarGenerator, stack *localDeclaredVars, rule *Rule) {\n\n\tvis := &ruleArgLocalRewriter{\n\t\tstack: stack,\n\t\tgen:   gen,\n\t}\n\n\tfor i := range rule.Head.Args {\n\t\tWalk(vis, rule.Head.Args[i])\n\t}\n\n\tfor i := range vis.errs {\n\t\tc.err(vis.errs[i])\n\t}\n}\n\ntype ruleArgLocalRewriter struct {\n\tstack *localDeclaredVars\n\tgen   *localVarGenerator\n\terrs  []*Error\n}\n\nfunc (vis *ruleArgLocalRewriter) Visit(x interface{}) Visitor {\n\n\tt, ok := x.(*Term)\n\tif !ok {\n\t\treturn vis\n\t}\n\n\tswitch v := t.Value.(type) {\n\tcase Var:\n\t\tgv, ok := vis.stack.Declared(v)\n\t\tif ok {\n\t\t\tvis.stack.Seen(v)\n\t\t} else {\n\t\t\tgv = vis.gen.Generate()\n\t\t\tvis.stack.Insert(v, gv, argVar)\n\t\t}\n\t\tt.Value = gv\n\t\treturn nil\n\tcase *object:\n\t\tif cpy, err := v.Map(func(k, v *Term) (*Term, *Term, error) {\n\t\t\tvcpy := v.Copy()\n\t\t\tWalk(vis, vcpy)\n\t\t\treturn k, vcpy, nil\n\t\t}); err != nil {\n\t\t\tvis.errs = append(vis.errs, NewError(CompileErr, t.Location, err.Error()))\n\t\t} else {\n\t\t\tt.Value = cpy\n\t\t}\n\t\treturn nil\n\tcase Null, Boolean, Number, String, *ArrayComprehension, *SetComprehension, *ObjectComprehension, Set:\n\t\t// Scalars are no-ops. Comprehensions are handled above. Sets must not\n\t\t// contain variables.\n\t\treturn nil\n\tcase Call:\n\t\tvis.errs = append(vis.errs, NewError(CompileErr, t.Location, \"rule arguments cannot contain calls\"))\n\t\treturn nil\n\tdefault:\n\t\t// Recurse on refs and arrays. Any embedded\n\t\t// variables can be rewritten.\n\t\treturn vis\n\t}\n}\n\nfunc (c *Compiler) rewriteWithModifiers() {\n\tf := newEqualityFactory(c.localvargen)\n\tfor _, name := range c.sorted {\n\t\tmod := c.Modules[name]\n\t\tt := NewGenericTransformer(func(x interface{}) (interface{}, error) {\n\t\t\tbody, ok := x.(Body)\n\t\t\tif !ok {\n\t\t\t\treturn x, nil\n\t\t\t}\n\t\t\tbody, err := rewriteWithModifiersInBody(c, c.unsafeBuiltinsMap, f, body)\n\t\t\tif err != nil {\n\t\t\t\tc.err(err)\n\t\t\t}\n\n\t\t\treturn body, nil\n\t\t})\n\t\t_, _ = Transform(t, mod) // ignore error\n\t}\n}\n\nfunc (c *Compiler) setModuleTree() {\n\tc.ModuleTree = NewModuleTree(c.Modules)\n}\n\nfunc (c *Compiler) setRuleTree() {\n\tc.RuleTree = NewRuleTree(c.ModuleTree)\n}\n\nfunc (c *Compiler) setGraph() {\n\tlist := func(r Ref) []*Rule {\n\t\treturn c.GetRulesDynamicWithOpts(r, RulesOptions{IncludeHiddenModules: true})\n\t}\n\tc.Graph = NewGraph(c.Modules, list)\n}\n\ntype queryCompiler struct {\n\tcompiler              *Compiler\n\tqctx                  *QueryContext\n\ttypeEnv               *TypeEnv\n\trewritten             map[Var]Var\n\tafter                 map[string][]QueryCompilerStageDefinition\n\tunsafeBuiltins        map[string]struct{}\n\tcomprehensionIndices  map[*Term]*ComprehensionIndex\n\tenablePrintStatements bool\n}\n\nfunc newQueryCompiler(compiler *Compiler) QueryCompiler {\n\tqc := &queryCompiler{\n\t\tcompiler:             compiler,\n\t\tqctx:                 nil,\n\t\tafter:                map[string][]QueryCompilerStageDefinition{},\n\t\tcomprehensionIndices: map[*Term]*ComprehensionIndex{},\n\t}\n\treturn qc\n}\n\nfunc (qc *queryCompiler) WithEnablePrintStatements(yes bool) QueryCompiler {\n\tqc.enablePrintStatements = yes\n\treturn qc\n}\n\nfunc (qc *queryCompiler) WithContext(qctx *QueryContext) QueryCompiler {\n\tqc.qctx = qctx\n\treturn qc\n}\n\nfunc (qc *queryCompiler) WithStageAfter(after string, stage QueryCompilerStageDefinition) QueryCompiler {\n\tqc.after[after] = append(qc.after[after], stage)\n\treturn qc\n}\n\nfunc (qc *queryCompiler) WithUnsafeBuiltins(unsafe map[string]struct{}) QueryCompiler {\n\tqc.unsafeBuiltins = unsafe\n\treturn qc\n}\n\nfunc (qc *queryCompiler) RewrittenVars() map[Var]Var {\n\treturn qc.rewritten\n}\n\nfunc (qc *queryCompiler) ComprehensionIndex(term *Term) *ComprehensionIndex {\n\tif result, ok := qc.comprehensionIndices[term]; ok {\n\t\treturn result\n\t} else if result, ok := qc.compiler.comprehensionIndices[term]; ok {\n\t\treturn result\n\t}\n\treturn nil\n}\n\nfunc (qc *queryCompiler) runStage(metricName string, qctx *QueryContext, query Body, s func(*QueryContext, Body) (Body, error)) (Body, error) {\n\tif qc.compiler.metrics != nil {\n\t\tqc.compiler.metrics.Timer(metricName).Start()\n\t\tdefer qc.compiler.metrics.Timer(metricName).Stop()\n\t}\n\treturn s(qctx, query)\n}\n\nfunc (qc *queryCompiler) runStageAfter(metricName string, query Body, s QueryCompilerStage) (Body, error) {\n\tif qc.compiler.metrics != nil {\n\t\tqc.compiler.metrics.Timer(metricName).Start()\n\t\tdefer qc.compiler.metrics.Timer(metricName).Stop()\n\t}\n\treturn s(qc, query)\n}\n\nfunc (qc *queryCompiler) Compile(query Body) (Body, error) {\n\tif len(query) == 0 {\n\t\treturn nil, Errors{NewError(CompileErr, nil, \"empty query cannot be compiled\")}\n\t}\n\n\tquery = query.Copy()\n\n\tstages := []struct {\n\t\tname       string\n\t\tmetricName string\n\t\tf          func(*QueryContext, Body) (Body, error)\n\t}{\n\t\t{\"CheckKeywordOverrides\", \"query_compile_stage_check_keyword_overrides\", qc.checkKeywordOverrides},\n\t\t{\"ResolveRefs\", \"query_compile_stage_resolve_refs\", qc.resolveRefs},\n\t\t{\"RewriteLocalVars\", \"query_compile_stage_rewrite_local_vars\", qc.rewriteLocalVars},\n\t\t{\"CheckVoidCalls\", \"query_compile_stage_check_void_calls\", qc.checkVoidCalls},\n\t\t{\"RewritePrintCalls\", \"query_compile_stage_rewrite_print_calls\", qc.rewritePrintCalls},\n\t\t{\"RewriteExprTerms\", \"query_compile_stage_rewrite_expr_terms\", qc.rewriteExprTerms},\n\t\t{\"RewriteComprehensionTerms\", \"query_compile_stage_rewrite_comprehension_terms\", qc.rewriteComprehensionTerms},\n\t\t{\"RewriteWithValues\", \"query_compile_stage_rewrite_with_values\", qc.rewriteWithModifiers},\n\t\t{\"CheckUndefinedFuncs\", \"query_compile_stage_check_undefined_funcs\", qc.checkUndefinedFuncs},\n\t\t{\"CheckSafety\", \"query_compile_stage_check_safety\", qc.checkSafety},\n\t\t{\"RewriteDynamicTerms\", \"query_compile_stage_rewrite_dynamic_terms\", qc.rewriteDynamicTerms},\n\t\t{\"CheckTypes\", \"query_compile_stage_check_types\", qc.checkTypes},\n\t\t{\"CheckUnsafeBuiltins\", \"query_compile_stage_check_unsafe_builtins\", qc.checkUnsafeBuiltins},\n\t\t{\"CheckDeprecatedBuiltins\", \"query_compile_stage_check_deprecated_builtins\", qc.checkDeprecatedBuiltins},\n\t\t{\"BuildComprehensionIndex\", \"query_compile_stage_build_comprehension_index\", qc.buildComprehensionIndices},\n\t}\n\n\tqctx := qc.qctx.Copy()\n\n\tfor _, s := range stages {\n\t\tvar err error\n\t\tquery, err = qc.runStage(s.metricName, qctx, query, s.f)\n\t\tif err != nil {\n\t\t\treturn nil, qc.applyErrorLimit(err)\n\t\t}\n\t\tfor _, s := range qc.after[s.name] {\n\t\t\tquery, err = qc.runStageAfter(s.MetricName, query, s.Stage)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, qc.applyErrorLimit(err)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn query, nil\n}\n\nfunc (qc *queryCompiler) TypeEnv() *TypeEnv {\n\treturn qc.typeEnv\n}\n\nfunc (qc *queryCompiler) applyErrorLimit(err error) error {\n\tif errs, ok := err.(Errors); ok {\n\t\tif qc.compiler.maxErrs > 0 && len(errs) > qc.compiler.maxErrs {\n\t\t\terr = append(errs[:qc.compiler.maxErrs], errLimitReached)\n\t\t}\n\t}\n\treturn err\n}\n\nfunc (qc *queryCompiler) checkKeywordOverrides(_ *QueryContext, body Body) (Body, error) {\n\tif errs := checkKeywordOverrides(body, qc.compiler.strict); len(errs) > 0 {\n\t\treturn nil, errs\n\t}\n\treturn body, nil\n}\n\nfunc (qc *queryCompiler) resolveRefs(qctx *QueryContext, body Body) (Body, error) {\n\n\tvar globals map[Var]*usedRef\n\n\tif qctx != nil {\n\t\tpkg := qctx.Package\n\t\t// Query compiler ought to generate a package if one was not provided and one or more imports were provided.\n\t\t// The generated package name could even be an empty string to avoid conflicts (it doesn't have to be valid syntactically)\n\t\tif pkg == nil && len(qctx.Imports) > 0 {\n\t\t\tpkg = &Package{Path: RefTerm(VarTerm(\"\")).Value.(Ref)}\n\t\t}\n\t\tif pkg != nil {\n\t\t\tvar ruleExports []Var\n\t\t\trules := qc.compiler.getExports()\n\t\t\tif exist, ok := rules.Get(pkg.Path); ok {\n\t\t\t\truleExports = exist.([]Var)\n\t\t\t}\n\n\t\t\tglobals = getGlobals(qctx.Package, ruleExports, qctx.Imports)\n\t\t\tqctx.Imports = nil\n\t\t}\n\t}\n\n\tignore := &declaredVarStack{declaredVars(body)}\n\n\treturn resolveRefsInBody(globals, ignore, body), nil\n}\n\nfunc (qc *queryCompiler) rewriteComprehensionTerms(_ *QueryContext, body Body) (Body, error) {\n\tgen := newLocalVarGenerator(\"q\", body)\n\tf := newEqualityFactory(gen)\n\tnode, err := rewriteComprehensionTerms(f, body)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn node.(Body), nil\n}\n\nfunc (qc *queryCompiler) rewriteDynamicTerms(_ *QueryContext, body Body) (Body, error) {\n\tgen := newLocalVarGenerator(\"q\", body)\n\tf := newEqualityFactory(gen)\n\treturn rewriteDynamics(f, body), nil\n}\n\nfunc (qc *queryCompiler) rewriteExprTerms(_ *QueryContext, body Body) (Body, error) {\n\tgen := newLocalVarGenerator(\"q\", body)\n\treturn rewriteExprTermsInBody(gen, body), nil\n}\n\nfunc (qc *queryCompiler) rewriteLocalVars(_ *QueryContext, body Body) (Body, error) {\n\tgen := newLocalVarGenerator(\"q\", body)\n\tstack := newLocalDeclaredVars()\n\tbody, _, err := rewriteLocalVars(gen, stack, nil, body, qc.compiler.strict)\n\tif len(err) != 0 {\n\t\treturn nil, err\n\t}\n\tqc.rewritten = make(map[Var]Var, len(stack.rewritten))\n\tfor k, v := range stack.rewritten {\n\t\t// The vars returned during the rewrite will include all seen vars,\n\t\t// even if they're not declared with an assignment operation. We don't\n\t\t// want to include these inside the rewritten set though.\n\t\tqc.rewritten[k] = v\n\t}\n\treturn body, nil\n}\n\nfunc (qc *queryCompiler) rewritePrintCalls(_ *QueryContext, body Body) (Body, error) {\n\tif !qc.enablePrintStatements {\n\t\treturn erasePrintCallsInBody(body), nil\n\t}\n\tgen := newLocalVarGenerator(\"q\", body)\n\tif errs := rewritePrintCalls(gen, qc.compiler.GetArity, ReservedVars, body); len(errs) > 0 {\n\t\treturn nil, errs\n\t}\n\treturn body, nil\n}\n\nfunc (qc *queryCompiler) checkVoidCalls(_ *QueryContext, body Body) (Body, error) {\n\tif errs := checkVoidCalls(qc.compiler.TypeEnv, body); len(errs) > 0 {\n\t\treturn nil, errs\n\t}\n\treturn body, nil\n}\n\nfunc (qc *queryCompiler) checkUndefinedFuncs(_ *QueryContext, body Body) (Body, error) {\n\tif errs := checkUndefinedFuncs(qc.compiler.TypeEnv, body, qc.compiler.GetArity, qc.rewritten); len(errs) > 0 {\n\t\treturn nil, errs\n\t}\n\treturn body, nil\n}\n\nfunc (qc *queryCompiler) checkSafety(_ *QueryContext, body Body) (Body, error) {\n\tsafe := ReservedVars.Copy()\n\treordered, unsafe := reorderBodyForSafety(qc.compiler.builtins, qc.compiler.GetArity, safe, body)\n\tif errs := safetyErrorSlice(unsafe, qc.RewrittenVars()); len(errs) > 0 {\n\t\treturn nil, errs\n\t}\n\treturn reordered, nil\n}\n\nfunc (qc *queryCompiler) checkTypes(_ *QueryContext, body Body) (Body, error) {\n\tvar errs Errors\n\tchecker := newTypeChecker().\n\t\tWithSchemaSet(qc.compiler.schemaSet).\n\t\tWithInputType(qc.compiler.inputType).\n\t\tWithVarRewriter(rewriteVarsInRef(qc.rewritten, qc.compiler.RewrittenVars))\n\tqc.typeEnv, errs = checker.CheckBody(qc.compiler.TypeEnv, body)\n\tif len(errs) > 0 {\n\t\treturn nil, errs\n\t}\n\n\treturn body, nil\n}\n\nfunc (qc *queryCompiler) checkUnsafeBuiltins(_ *QueryContext, body Body) (Body, error) {\n\terrs := checkUnsafeBuiltins(qc.unsafeBuiltinsMap(), body)\n\tif len(errs) > 0 {\n\t\treturn nil, errs\n\t}\n\treturn body, nil\n}\n\nfunc (qc *queryCompiler) unsafeBuiltinsMap() map[string]struct{} {\n\tif qc.unsafeBuiltins != nil {\n\t\treturn qc.unsafeBuiltins\n\t}\n\treturn qc.compiler.unsafeBuiltinsMap\n}\n\nfunc (qc *queryCompiler) checkDeprecatedBuiltins(_ *QueryContext, body Body) (Body, error) {\n\terrs := checkDeprecatedBuiltins(qc.compiler.deprecatedBuiltinsMap, body, qc.compiler.strict)\n\tif len(errs) > 0 {\n\t\treturn nil, errs\n\t}\n\treturn body, nil\n}\n\nfunc (qc *queryCompiler) rewriteWithModifiers(_ *QueryContext, body Body) (Body, error) {\n\tf := newEqualityFactory(newLocalVarGenerator(\"q\", body))\n\tbody, err := rewriteWithModifiersInBody(qc.compiler, qc.unsafeBuiltinsMap(), f, body)\n\tif err != nil {\n\t\treturn nil, Errors{err}\n\t}\n\treturn body, nil\n}\n\nfunc (qc *queryCompiler) buildComprehensionIndices(_ *QueryContext, body Body) (Body, error) {\n\t// NOTE(tsandall): The query compiler does not have a metrics object so we\n\t// cannot record index metrics currently.\n\t_ = buildComprehensionIndices(qc.compiler.debug, qc.compiler.GetArity, ReservedVars, qc.RewrittenVars(), body, qc.comprehensionIndices)\n\treturn body, nil\n}\n\n// ComprehensionIndex specifies how the comprehension term can be indexed. The keys\n// tell the evaluator what variables to use for indexing. In the future, the index\n// could be expanded with more information that would allow the evaluator to index\n// a larger fragment of comprehensions (e.g., by closing over variables in the outer\n// query.)\ntype ComprehensionIndex struct {\n\tTerm *Term\n\tKeys []*Term\n}\n\nfunc (ci *ComprehensionIndex) String() string {\n\tif ci == nil {\n\t\treturn \"\"\n\t}\n\treturn fmt.Sprintf(\"<keys: %v>\", NewArray(ci.Keys...))\n}\n\nfunc buildComprehensionIndices(dbg debug.Debug, arity func(Ref) int, candidates VarSet, rwVars map[Var]Var, node interface{}, result map[*Term]*ComprehensionIndex) uint64 {\n\tvar n uint64\n\tcpy := candidates.Copy()\n\tWalkBodies(node, func(b Body) bool {\n\t\tfor _, expr := range b {\n\t\t\tindex := getComprehensionIndex(dbg, arity, cpy, rwVars, expr)\n\t\t\tif index != nil {\n\t\t\t\tresult[index.Term] = index\n\t\t\t\tn++\n\t\t\t}\n\t\t\t// Any variables appearing in the expressions leading up to the comprehension\n\t\t\t// are fair-game to be used as index keys.\n\t\t\tcpy.Update(expr.Vars(VarVisitorParams{SkipClosures: true, SkipRefCallHead: true}))\n\t\t}\n\t\treturn false\n\t})\n\treturn n\n}\n\nfunc getComprehensionIndex(dbg debug.Debug, arity func(Ref) int, candidates VarSet, rwVars map[Var]Var, expr *Expr) *ComprehensionIndex {\n\n\t// Ignore everything except <var> = <comprehension> expressions. Extract\n\t// the comprehension term from the expression.\n\tif !expr.IsEquality() || expr.Negated || len(expr.With) > 0 {\n\t\t// No debug message, these are assumed to be known hinderances\n\t\t// to comprehension indexing.\n\t\treturn nil\n\t}\n\n\tvar term *Term\n\n\tlhs, rhs := expr.Operand(0), expr.Operand(1)\n\n\tif _, ok := lhs.Value.(Var); ok && IsComprehension(rhs.Value) {\n\t\tterm = rhs\n\t} else if _, ok := rhs.Value.(Var); ok && IsComprehension(lhs.Value) {\n\t\tterm = lhs\n\t}\n\n\tif term == nil {\n\t\t// no debug for this, it's the ordinary \"nothing to do here\" case\n\t\treturn nil\n\t}\n\n\t// Ignore comprehensions that contain expressions that close over variables\n\t// in the outer body if those variables are not also output variables in the\n\t// comprehension body. In other words, ignore comprehensions that we cannot\n\t// safely evaluate without bindings from the outer body. For example:\n\t//\n\t// \tx = [1]\n\t//\t[true | data.y[z] = x]     # safe to evaluate w/o outer body\n\t//\t[true | data.y[z] = x[0]]  # NOT safe to evaluate because 'x' would be unsafe.\n\t//\n\t// By identifying output variables in the body we also know what to index on by\n\t// intersecting with candidate variables from the outer query.\n\t//\n\t// For example:\n\t//\n\t//\tx = data.foo[_]\n\t//\t_ = [y | data.bar[y] = x]      # index on 'x'\n\t//\n\t// This query goes from O(data.foo*data.bar) to O(data.foo+data.bar).\n\tvar body Body\n\n\tswitch x := term.Value.(type) {\n\tcase *ArrayComprehension:\n\t\tbody = x.Body\n\tcase *SetComprehension:\n\t\tbody = x.Body\n\tcase *ObjectComprehension:\n\t\tbody = x.Body\n\t}\n\n\toutputs := outputVarsForBody(body, arity, ReservedVars)\n\tunsafe := body.Vars(SafetyCheckVisitorParams).Diff(outputs).Diff(ReservedVars)\n\n\tif len(unsafe) > 0 {\n\t\tdbg.Printf(\"%s: comprehension index: unsafe vars: %v\", expr.Location, unsafe)\n\t\treturn nil\n\t}\n\n\t// Similarly, ignore comprehensions that contain references with output variables\n\t// that intersect with the candidates. Indexing these comprehensions could worsen\n\t// performance.\n\tregressionVis := newComprehensionIndexRegressionCheckVisitor(candidates)\n\tregressionVis.Walk(body)\n\tif regressionVis.worse {\n\t\tdbg.Printf(\"%s: comprehension index: output vars intersect candidates\", expr.Location)\n\t\treturn nil\n\t}\n\n\t// Check if any nested comprehensions close over candidates. If any intersection is found\n\t// the comprehension cannot be cached because it would require closing over the candidates\n\t// which the evaluator does not support today.\n\tnestedVis := newComprehensionIndexNestedCandidateVisitor(candidates)\n\tnestedVis.Walk(body)\n\tif nestedVis.found {\n\t\tdbg.Printf(\"%s: comprehension index: nested comprehensions close over candidates\", expr.Location)\n\t\treturn nil\n\t}\n\n\t// Make a sorted set of variable names that will serve as the index key set.\n\t// Sort to ensure deterministic indexing. In future this could be relaxed\n\t// if we can decide that one ordering is better than another. If the set is\n\t// empty, there is no indexing to do.\n\tindexVars := candidates.Intersect(outputs)\n\tif len(indexVars) == 0 {\n\t\tdbg.Printf(\"%s: comprehension index: no index vars\", expr.Location)\n\t\treturn nil\n\t}\n\n\tresult := make([]*Term, 0, len(indexVars))\n\n\tfor v := range indexVars {\n\t\tresult = append(result, NewTerm(v))\n\t}\n\n\tsort.Slice(result, func(i, j int) bool {\n\t\treturn result[i].Value.Compare(result[j].Value) < 0\n\t})\n\n\tdebugRes := make([]*Term, len(result))\n\tfor i, r := range result {\n\t\tif o, ok := rwVars[r.Value.(Var)]; ok {\n\t\t\tdebugRes[i] = NewTerm(o)\n\t\t} else {\n\t\t\tdebugRes[i] = r\n\t\t}\n\t}\n\tdbg.Printf(\"%s: comprehension index: built with keys: %v\", expr.Location, debugRes)\n\treturn &ComprehensionIndex{Term: term, Keys: result}\n}\n\ntype comprehensionIndexRegressionCheckVisitor struct {\n\tcandidates VarSet\n\tseen       VarSet\n\tworse      bool\n}\n\n// TODO(tsandall): Improve this so that users can either supply this list explicitly\n// or the information is maintained on the built-in function declaration. What we really\n// need to know is whether the built-in function allows callers to push down output\n// values or not. It's unlikely that anything outside of OPA does this today so this\n// solution is fine for now.\nvar comprehensionIndexBlacklist = map[string]int{\n\tWalkBuiltin.Name: len(WalkBuiltin.Decl.Args()),\n}\n\nfunc newComprehensionIndexRegressionCheckVisitor(candidates VarSet) *comprehensionIndexRegressionCheckVisitor {\n\treturn &comprehensionIndexRegressionCheckVisitor{\n\t\tcandidates: candidates,\n\t\tseen:       NewVarSet(),\n\t}\n}\n\nfunc (vis *comprehensionIndexRegressionCheckVisitor) Walk(x interface{}) {\n\tNewGenericVisitor(vis.visit).Walk(x)\n}\n\nfunc (vis *comprehensionIndexRegressionCheckVisitor) visit(x interface{}) bool {\n\tif !vis.worse {\n\t\tswitch x := x.(type) {\n\t\tcase *Expr:\n\t\t\toperands := x.Operands()\n\t\t\tif pos := comprehensionIndexBlacklist[x.Operator().String()]; pos > 0 && pos < len(operands) {\n\t\t\t\tvis.assertEmptyIntersection(operands[pos].Vars())\n\t\t\t}\n\t\tcase Ref:\n\t\t\tvis.assertEmptyIntersection(x.OutputVars())\n\t\tcase Var:\n\t\t\tvis.seen.Add(x)\n\t\t// Always skip comprehensions. We do not have to visit their bodies here.\n\t\tcase *ArrayComprehension, *SetComprehension, *ObjectComprehension:\n\t\t\treturn true\n\t\t}\n\t}\n\treturn vis.worse\n}\n\nfunc (vis *comprehensionIndexRegressionCheckVisitor) assertEmptyIntersection(vs VarSet) {\n\tfor v := range vs {\n\t\tif vis.candidates.Contains(v) && !vis.seen.Contains(v) {\n\t\t\tvis.worse = true\n\t\t\treturn\n\t\t}\n\t}\n}\n\ntype comprehensionIndexNestedCandidateVisitor struct {\n\tcandidates VarSet\n\tfound      bool\n}\n\nfunc newComprehensionIndexNestedCandidateVisitor(candidates VarSet) *comprehensionIndexNestedCandidateVisitor {\n\treturn &comprehensionIndexNestedCandidateVisitor{\n\t\tcandidates: candidates,\n\t}\n}\n\nfunc (vis *comprehensionIndexNestedCandidateVisitor) Walk(x interface{}) {\n\tNewGenericVisitor(vis.visit).Walk(x)\n}\n\nfunc (vis *comprehensionIndexNestedCandidateVisitor) visit(x interface{}) bool {\n\n\tif vis.found {\n\t\treturn true\n\t}\n\n\tif v, ok := x.(Value); ok && IsComprehension(v) {\n\t\tvarVis := NewVarVisitor().WithParams(VarVisitorParams{SkipRefHead: true})\n\t\tvarVis.Walk(v)\n\t\tvis.found = len(varVis.Vars().Intersect(vis.candidates)) > 0\n\t\treturn true\n\t}\n\n\treturn false\n}\n\n// ModuleTreeNode represents a node in the module tree. The module\n// tree is keyed by the package path.\ntype ModuleTreeNode struct {\n\tKey      Value\n\tModules  []*Module\n\tChildren map[Value]*ModuleTreeNode\n\tHide     bool\n}\n\n// NewModuleTree returns a new ModuleTreeNode that represents the root\n// of the module tree populated with the given modules.\nfunc NewModuleTree(mods map[string]*Module) *ModuleTreeNode {\n\troot := &ModuleTreeNode{\n\t\tChildren: map[Value]*ModuleTreeNode{},\n\t}\n\tnames := make([]string, 0, len(mods))\n\tfor name := range mods {\n\t\tnames = append(names, name)\n\t}\n\tsort.Strings(names)\n\tfor _, name := range names {\n\t\tm := mods[name]\n\t\tnode := root\n\t\tfor i, x := range m.Package.Path {\n\t\t\tc, ok := node.Children[x.Value]\n\t\t\tif !ok {\n\t\t\t\tvar hide bool\n\t\t\t\tif i == 1 && x.Value.Compare(SystemDocumentKey) == 0 {\n\t\t\t\t\thide = true\n\t\t\t\t}\n\t\t\t\tc = &ModuleTreeNode{\n\t\t\t\t\tKey:      x.Value,\n\t\t\t\t\tChildren: map[Value]*ModuleTreeNode{},\n\t\t\t\t\tHide:     hide,\n\t\t\t\t}\n\t\t\t\tnode.Children[x.Value] = c\n\t\t\t}\n\t\t\tnode = c\n\t\t}\n\t\tnode.Modules = append(node.Modules, m)\n\t}\n\treturn root\n}\n\n// Size returns the number of modules in the tree.\nfunc (n *ModuleTreeNode) Size() int {\n\ts := len(n.Modules)\n\tfor _, c := range n.Children {\n\t\ts += c.Size()\n\t}\n\treturn s\n}\n\n// DepthFirst performs a depth-first traversal of the module tree rooted at n.\n// If f returns true, traversal will not continue to the children of n.\nfunc (n *ModuleTreeNode) DepthFirst(f func(node *ModuleTreeNode) bool) {\n\tif !f(n) {\n\t\tfor _, node := range n.Children {\n\t\t\tnode.DepthFirst(f)\n\t\t}\n\t}\n}\n\n// TreeNode represents a node in the rule tree. The rule tree is keyed by\n// rule path.\ntype TreeNode struct {\n\tKey      Value\n\tValues   []util.T\n\tChildren map[Value]*TreeNode\n\tSorted   []Value\n\tHide     bool\n}\n\n// NewRuleTree returns a new TreeNode that represents the root\n// of the rule tree populated with the given rules.\nfunc NewRuleTree(mtree *ModuleTreeNode) *TreeNode {\n\n\truleSets := map[String][]util.T{}\n\n\t// Build rule sets for this package.\n\tfor _, mod := range mtree.Modules {\n\t\tfor _, rule := range mod.Rules {\n\t\t\tkey := String(rule.Head.Name)\n\t\t\truleSets[key] = append(ruleSets[key], rule)\n\t\t}\n\t}\n\n\t// Each rule set becomes a leaf node.\n\tchildren := map[Value]*TreeNode{}\n\tsorted := make([]Value, 0, len(ruleSets))\n\n\tfor key, rules := range ruleSets {\n\t\tsorted = append(sorted, key)\n\t\tchildren[key] = &TreeNode{\n\t\t\tKey:      key,\n\t\t\tChildren: nil,\n\t\t\tValues:   rules,\n\t\t}\n\t}\n\n\t// Each module in subpackage becomes child node.\n\tfor key, child := range mtree.Children {\n\t\tsorted = append(sorted, key)\n\t\tchildren[child.Key] = NewRuleTree(child)\n\t}\n\n\tsort.Slice(sorted, func(i, j int) bool {\n\t\treturn sorted[i].Compare(sorted[j]) < 0\n\t})\n\n\treturn &TreeNode{\n\t\tKey:      mtree.Key,\n\t\tValues:   nil,\n\t\tChildren: children,\n\t\tSorted:   sorted,\n\t\tHide:     mtree.Hide,\n\t}\n}\n\n// Size returns the number of rules in the tree.\nfunc (n *TreeNode) Size() int {\n\ts := len(n.Values)\n\tfor _, c := range n.Children {\n\t\ts += c.Size()\n\t}\n\treturn s\n}\n\n// Child returns n's child with key k.\nfunc (n *TreeNode) Child(k Value) *TreeNode {\n\tswitch k.(type) {\n\tcase String, Var:\n\t\treturn n.Children[k]\n\t}\n\treturn nil\n}\n\n// Find dereferences ref along the tree\nfunc (n *TreeNode) Find(ref Ref) *TreeNode {\n\tnode := n\n\tfor _, r := range ref {\n\t\tchild := node.Child(r.Value)\n\t\tif child == nil {\n\t\t\treturn nil\n\t\t}\n\t\tnode = child\n\t}\n\treturn node\n}\n\n// DepthFirst performs a depth-first traversal of the rule tree rooted at n. If\n// f returns true, traversal will not continue to the children of n.\nfunc (n *TreeNode) DepthFirst(f func(node *TreeNode) bool) {\n\tif !f(n) {\n\t\tfor _, node := range n.Children {\n\t\t\tnode.DepthFirst(f)\n\t\t}\n\t}\n}\n\n// Graph represents the graph of dependencies between rules.\ntype Graph struct {\n\tadj    map[util.T]map[util.T]struct{}\n\tradj   map[util.T]map[util.T]struct{}\n\tnodes  map[util.T]struct{}\n\tsorted []util.T\n}\n\n// NewGraph returns a new Graph based on modules. The list function must return\n// the rules referred to directly by the ref.\nfunc NewGraph(modules map[string]*Module, list func(Ref) []*Rule) *Graph {\n\n\tgraph := &Graph{\n\t\tadj:    map[util.T]map[util.T]struct{}{},\n\t\tradj:   map[util.T]map[util.T]struct{}{},\n\t\tnodes:  map[util.T]struct{}{},\n\t\tsorted: nil,\n\t}\n\n\t// Create visitor to walk a rule AST and add edges to the rule graph for\n\t// each dependency.\n\tvis := func(a *Rule) *GenericVisitor {\n\t\tstop := false\n\t\treturn NewGenericVisitor(func(x interface{}) bool {\n\t\t\tswitch x := x.(type) {\n\t\t\tcase Ref:\n\t\t\t\tfor _, b := range list(x) {\n\t\t\t\t\tfor node := b; node != nil; node = node.Else {\n\t\t\t\t\t\tgraph.addDependency(a, node)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tcase *Rule:\n\t\t\t\tif stop {\n\t\t\t\t\t// Do not recurse into else clauses (which will be handled\n\t\t\t\t\t// by the outer visitor.)\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t\tstop = true\n\t\t\t}\n\t\t\treturn false\n\t\t})\n\t}\n\n\t// Walk over all rules, add them to graph, and build adjacency lists.\n\tfor _, module := range modules {\n\t\tWalkRules(module, func(a *Rule) bool {\n\t\t\tgraph.addNode(a)\n\t\t\tvis(a).Walk(a)\n\t\t\treturn false\n\t\t})\n\t}\n\n\treturn graph\n}\n\n// Dependencies returns the set of rules that x depends on.\nfunc (g *Graph) Dependencies(x util.T) map[util.T]struct{} {\n\treturn g.adj[x]\n}\n\n// Dependents returns the set of rules that depend on x.\nfunc (g *Graph) Dependents(x util.T) map[util.T]struct{} {\n\treturn g.radj[x]\n}\n\n// Sort returns a slice of rules sorted by dependencies. If a cycle is found,\n// ok is set to false.\nfunc (g *Graph) Sort() (sorted []util.T, ok bool) {\n\tif g.sorted != nil {\n\t\treturn g.sorted, true\n\t}\n\n\tsorter := &graphSort{\n\t\tsorted: make([]util.T, 0, len(g.nodes)),\n\t\tdeps:   g.Dependencies,\n\t\tmarked: map[util.T]struct{}{},\n\t\ttemp:   map[util.T]struct{}{},\n\t}\n\n\tfor node := range g.nodes {\n\t\tif !sorter.Visit(node) {\n\t\t\treturn nil, false\n\t\t}\n\t}\n\n\tg.sorted = sorter.sorted\n\treturn g.sorted, true\n}\n\nfunc (g *Graph) addDependency(u util.T, v util.T) {\n\n\tif _, ok := g.nodes[u]; !ok {\n\t\tg.addNode(u)\n\t}\n\n\tif _, ok := g.nodes[v]; !ok {\n\t\tg.addNode(v)\n\t}\n\n\tedges, ok := g.adj[u]\n\tif !ok {\n\t\tedges = map[util.T]struct{}{}\n\t\tg.adj[u] = edges\n\t}\n\n\tedges[v] = struct{}{}\n\n\tedges, ok = g.radj[v]\n\tif !ok {\n\t\tedges = map[util.T]struct{}{}\n\t\tg.radj[v] = edges\n\t}\n\n\tedges[u] = struct{}{}\n}\n\nfunc (g *Graph) addNode(n util.T) {\n\tg.nodes[n] = struct{}{}\n}\n\ntype graphSort struct {\n\tsorted []util.T\n\tdeps   func(util.T) map[util.T]struct{}\n\tmarked map[util.T]struct{}\n\ttemp   map[util.T]struct{}\n}\n\nfunc (sort *graphSort) Marked(node util.T) bool {\n\t_, marked := sort.marked[node]\n\treturn marked\n}\n\nfunc (sort *graphSort) Visit(node util.T) (ok bool) {\n\tif _, ok := sort.temp[node]; ok {\n\t\treturn false\n\t}\n\tif sort.Marked(node) {\n\t\treturn true\n\t}\n\tsort.temp[node] = struct{}{}\n\tfor other := range sort.deps(node) {\n\t\tif !sort.Visit(other) {\n\t\t\treturn false\n\t\t}\n\t}\n\tsort.marked[node] = struct{}{}\n\tdelete(sort.temp, node)\n\tsort.sorted = append(sort.sorted, node)\n\treturn true\n}\n\n// GraphTraversal is a Traversal that understands the dependency graph\ntype GraphTraversal struct {\n\tgraph   *Graph\n\tvisited map[util.T]struct{}\n}\n\n// NewGraphTraversal returns a Traversal for the dependency graph\nfunc NewGraphTraversal(graph *Graph) *GraphTraversal {\n\treturn &GraphTraversal{\n\t\tgraph:   graph,\n\t\tvisited: map[util.T]struct{}{},\n\t}\n}\n\n// Edges lists all dependency connections for a given node\nfunc (g *GraphTraversal) Edges(x util.T) []util.T {\n\tr := []util.T{}\n\tfor v := range g.graph.Dependencies(x) {\n\t\tr = append(r, v)\n\t}\n\treturn r\n}\n\n// Visited returns whether a node has been visited, setting a node to visited if not\nfunc (g *GraphTraversal) Visited(u util.T) bool {\n\t_, ok := g.visited[u]\n\tg.visited[u] = struct{}{}\n\treturn ok\n}\n\ntype unsafePair struct {\n\tExpr *Expr\n\tVars VarSet\n}\n\ntype unsafeVarLoc struct {\n\tVar Var\n\tLoc *Location\n}\n\ntype unsafeVars map[*Expr]VarSet\n\nfunc (vs unsafeVars) Add(e *Expr, v Var) {\n\tif u, ok := vs[e]; ok {\n\t\tu[v] = struct{}{}\n\t} else {\n\t\tvs[e] = VarSet{v: struct{}{}}\n\t}\n}\n\nfunc (vs unsafeVars) Set(e *Expr, s VarSet) {\n\tvs[e] = s\n}\n\nfunc (vs unsafeVars) Update(o unsafeVars) {\n\tfor k, v := range o {\n\t\tif _, ok := vs[k]; !ok {\n\t\t\tvs[k] = VarSet{}\n\t\t}\n\t\tvs[k].Update(v)\n\t}\n}\n\nfunc (vs unsafeVars) Vars() (result []unsafeVarLoc) {\n\n\tlocs := map[Var]*Location{}\n\n\t// If var appears in multiple sets then pick first by location.\n\tfor expr, vars := range vs {\n\t\tfor v := range vars {\n\t\t\tif locs[v].Compare(expr.Location) > 0 {\n\t\t\t\tlocs[v] = expr.Location\n\t\t\t}\n\t\t}\n\t}\n\n\tfor v, loc := range locs {\n\t\tresult = append(result, unsafeVarLoc{\n\t\t\tVar: v,\n\t\t\tLoc: loc,\n\t\t})\n\t}\n\n\tsort.Slice(result, func(i, j int) bool {\n\t\treturn result[i].Loc.Compare(result[j].Loc) < 0\n\t})\n\n\treturn result\n}\n\nfunc (vs unsafeVars) Slice() (result []unsafePair) {\n\tfor expr, vs := range vs {\n\t\tresult = append(result, unsafePair{\n\t\t\tExpr: expr,\n\t\t\tVars: vs,\n\t\t})\n\t}\n\treturn\n}\n\n// reorderBodyForSafety returns a copy of the body ordered such that\n// left to right evaluation of the body will not encounter unbound variables\n// in input positions or negated expressions.\n//\n// Expressions are added to the re-ordered body as soon as they are considered\n// safe. If multiple expressions become safe in the same pass, they are added\n// in their original order. This results in minimal re-ordering of the body.\n//\n// If the body cannot be reordered to ensure safety, the second return value\n// contains a mapping of expressions to unsafe variables in those expressions.\nfunc reorderBodyForSafety(builtins map[string]*Builtin, arity func(Ref) int, globals VarSet, body Body) (Body, unsafeVars) {\n\n\tbodyVars := body.Vars(SafetyCheckVisitorParams)\n\treordered := make(Body, 0, len(body))\n\tsafe := VarSet{}\n\tunsafe := unsafeVars{}\n\n\tfor _, e := range body {\n\t\tfor v := range e.Vars(SafetyCheckVisitorParams) {\n\t\t\tif globals.Contains(v) {\n\t\t\t\tsafe.Add(v)\n\t\t\t} else {\n\t\t\t\tunsafe.Add(e, v)\n\t\t\t}\n\t\t}\n\t}\n\n\tfor {\n\t\tn := len(reordered)\n\n\t\tfor _, e := range body {\n\t\t\tif reordered.Contains(e) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tovs := outputVarsForExpr(e, arity, safe)\n\n\t\t\t// check closures: is this expression closing over variables that\n\t\t\t// haven't been made safe by what's already included in `reordered`?\n\t\t\tvs := unsafeVarsInClosures(e, arity, safe)\n\t\t\tcv := vs.Intersect(bodyVars).Diff(globals)\n\t\t\tuv := cv.Diff(outputVarsForBody(reordered, arity, safe))\n\n\t\t\tif len(uv) > 0 {\n\t\t\t\tif uv.Equal(ovs) { // special case \"closure-self\"\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tunsafe.Set(e, uv)\n\t\t\t}\n\n\t\t\tfor v := range unsafe[e] {\n\t\t\t\tif ovs.Contains(v) || safe.Contains(v) {\n\t\t\t\t\tdelete(unsafe[e], v)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif len(unsafe[e]) == 0 {\n\t\t\t\tdelete(unsafe, e)\n\t\t\t\treordered.Append(e)\n\t\t\t\tsafe.Update(ovs) // this expression's outputs are safe\n\t\t\t}\n\t\t}\n\n\t\tif len(reordered) == n { // fixed point, could not add any expr of body\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// Recursively visit closures and perform the safety checks on them.\n\t// Update the globals at each expression to include the variables that could\n\t// be closed over.\n\tg := globals.Copy()\n\tfor i, e := range reordered {\n\t\tif i > 0 {\n\t\t\tg.Update(reordered[i-1].Vars(SafetyCheckVisitorParams))\n\t\t}\n\t\txform := &bodySafetyTransformer{\n\t\t\tbuiltins: builtins,\n\t\t\tarity:    arity,\n\t\t\tcurrent:  e,\n\t\t\tglobals:  g,\n\t\t\tunsafe:   unsafe,\n\t\t}\n\t\tNewGenericVisitor(xform.Visit).Walk(e)\n\t}\n\n\treturn reordered, unsafe\n}\n\ntype bodySafetyTransformer struct {\n\tbuiltins map[string]*Builtin\n\tarity    func(Ref) int\n\tcurrent  *Expr\n\tglobals  VarSet\n\tunsafe   unsafeVars\n}\n\nfunc (xform *bodySafetyTransformer) Visit(x interface{}) bool {\n\tswitch term := x.(type) {\n\tcase *Term:\n\t\tswitch x := term.Value.(type) {\n\t\tcase *object:\n\t\t\tcpy, _ := x.Map(func(k, v *Term) (*Term, *Term, error) {\n\t\t\t\tkcpy := k.Copy()\n\t\t\t\tNewGenericVisitor(xform.Visit).Walk(kcpy)\n\t\t\t\tvcpy := v.Copy()\n\t\t\t\tNewGenericVisitor(xform.Visit).Walk(vcpy)\n\t\t\t\treturn kcpy, vcpy, nil\n\t\t\t})\n\t\t\tterm.Value = cpy\n\t\t\treturn true\n\t\tcase *set:\n\t\t\tcpy, _ := x.Map(func(v *Term) (*Term, error) {\n\t\t\t\tvcpy := v.Copy()\n\t\t\t\tNewGenericVisitor(xform.Visit).Walk(vcpy)\n\t\t\t\treturn vcpy, nil\n\t\t\t})\n\t\t\tterm.Value = cpy\n\t\t\treturn true\n\t\tcase *ArrayComprehension:\n\t\t\txform.reorderArrayComprehensionSafety(x)\n\t\t\treturn true\n\t\tcase *ObjectComprehension:\n\t\t\txform.reorderObjectComprehensionSafety(x)\n\t\t\treturn true\n\t\tcase *SetComprehension:\n\t\t\txform.reorderSetComprehensionSafety(x)\n\t\t\treturn true\n\t\t}\n\tcase *Expr:\n\t\tif ev, ok := term.Terms.(*Every); ok {\n\t\t\txform.globals.Update(ev.KeyValueVars())\n\t\t\tev.Body = xform.reorderComprehensionSafety(NewVarSet(), ev.Body)\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (xform *bodySafetyTransformer) reorderComprehensionSafety(tv VarSet, body Body) Body {\n\tbv := body.Vars(SafetyCheckVisitorParams)\n\tbv.Update(xform.globals)\n\tuv := tv.Diff(bv)\n\tfor v := range uv {\n\t\txform.unsafe.Add(xform.current, v)\n\t}\n\n\tr, u := reorderBodyForSafety(xform.builtins, xform.arity, xform.globals, body)\n\tif len(u) == 0 {\n\t\treturn r\n\t}\n\n\txform.unsafe.Update(u)\n\treturn body\n}\n\nfunc (xform *bodySafetyTransformer) reorderArrayComprehensionSafety(ac *ArrayComprehension) {\n\tac.Body = xform.reorderComprehensionSafety(ac.Term.Vars(), ac.Body)\n}\n\nfunc (xform *bodySafetyTransformer) reorderObjectComprehensionSafety(oc *ObjectComprehension) {\n\ttv := oc.Key.Vars()\n\ttv.Update(oc.Value.Vars())\n\toc.Body = xform.reorderComprehensionSafety(tv, oc.Body)\n}\n\nfunc (xform *bodySafetyTransformer) reorderSetComprehensionSafety(sc *SetComprehension) {\n\tsc.Body = xform.reorderComprehensionSafety(sc.Term.Vars(), sc.Body)\n}\n\n// unsafeVarsInClosures collects vars that are contained in closures within\n// this expression.\nfunc unsafeVarsInClosures(e *Expr, arity func(Ref) int, safe VarSet) VarSet {\n\tvs := VarSet{}\n\tWalkClosures(e, func(x interface{}) bool {\n\t\tvis := &VarVisitor{vars: vs}\n\t\tif ev, ok := x.(*Every); ok {\n\t\t\tvis.Walk(ev.Body)\n\t\t\treturn true\n\t\t}\n\t\tvis.Walk(x)\n\t\treturn true\n\t})\n\treturn vs\n}\n\n// OutputVarsFromBody returns all variables which are the \"output\" for\n// the given body. For safety checks this means that they would be\n// made safe by the body.\nfunc OutputVarsFromBody(c *Compiler, body Body, safe VarSet) VarSet {\n\treturn outputVarsForBody(body, c.GetArity, safe)\n}\n\nfunc outputVarsForBody(body Body, arity func(Ref) int, safe VarSet) VarSet {\n\to := safe.Copy()\n\tfor _, e := range body {\n\t\to.Update(outputVarsForExpr(e, arity, o))\n\t}\n\treturn o.Diff(safe)\n}\n\n// OutputVarsFromExpr returns all variables which are the \"output\" for\n// the given expression. For safety checks this means that they would be\n// made safe by the expr.\nfunc OutputVarsFromExpr(c *Compiler, expr *Expr, safe VarSet) VarSet {\n\treturn outputVarsForExpr(expr, c.GetArity, safe)\n}\n\nfunc outputVarsForExpr(expr *Expr, arity func(Ref) int, safe VarSet) VarSet {\n\n\t// Negated expressions must be safe.\n\tif expr.Negated {\n\t\treturn VarSet{}\n\t}\n\n\t// With modifier inputs must be safe.\n\tfor _, with := range expr.With {\n\t\tvis := NewVarVisitor().WithParams(SafetyCheckVisitorParams)\n\t\tvis.Walk(with)\n\t\tvars := vis.Vars()\n\t\tunsafe := vars.Diff(safe)\n\t\tif len(unsafe) > 0 {\n\t\t\treturn VarSet{}\n\t\t}\n\t}\n\n\tswitch terms := expr.Terms.(type) {\n\tcase *Term:\n\t\treturn outputVarsForTerms(expr, safe)\n\tcase []*Term:\n\t\tif expr.IsEquality() {\n\t\t\treturn outputVarsForExprEq(expr, safe)\n\t\t}\n\n\t\toperator, ok := terms[0].Value.(Ref)\n\t\tif !ok {\n\t\t\treturn VarSet{}\n\t\t}\n\n\t\tar := arity(operator)\n\t\tif ar < 0 {\n\t\t\treturn VarSet{}\n\t\t}\n\n\t\treturn outputVarsForExprCall(expr, ar, safe, terms)\n\tcase *Every:\n\t\treturn outputVarsForTerms(terms.Domain, safe)\n\tdefault:\n\t\tpanic(\"illegal expression\")\n\t}\n}\n\nfunc outputVarsForExprEq(expr *Expr, safe VarSet) VarSet {\n\n\tif !validEqAssignArgCount(expr) {\n\t\treturn safe\n\t}\n\n\toutput := outputVarsForTerms(expr, safe)\n\toutput.Update(safe)\n\toutput.Update(Unify(output, expr.Operand(0), expr.Operand(1)))\n\n\treturn output.Diff(safe)\n}\n\nfunc outputVarsForExprCall(expr *Expr, arity int, safe VarSet, terms []*Term) VarSet {\n\n\toutput := outputVarsForTerms(expr, safe)\n\n\tnumInputTerms := arity + 1\n\tif numInputTerms >= len(terms) {\n\t\treturn output\n\t}\n\n\tparams := VarVisitorParams{\n\t\tSkipClosures:   true,\n\t\tSkipSets:       true,\n\t\tSkipObjectKeys: true,\n\t\tSkipRefHead:    true,\n\t}\n\tvis := NewVarVisitor().WithParams(params)\n\tvis.Walk(Args(terms[:numInputTerms]))\n\tunsafe := vis.Vars().Diff(output).Diff(safe)\n\n\tif len(unsafe) > 0 {\n\t\treturn VarSet{}\n\t}\n\n\tvis = NewVarVisitor().WithParams(params)\n\tvis.Walk(Args(terms[numInputTerms:]))\n\toutput.Update(vis.vars)\n\treturn output\n}\n\nfunc outputVarsForTerms(expr interface{}, safe VarSet) VarSet {\n\toutput := VarSet{}\n\tWalkTerms(expr, func(x *Term) bool {\n\t\tswitch r := x.Value.(type) {\n\t\tcase *SetComprehension, *ArrayComprehension, *ObjectComprehension:\n\t\t\treturn true\n\t\tcase Ref:\n\t\t\tif !isRefSafe(r, safe) {\n\t\t\t\treturn true\n\t\t\t}\n\t\t\toutput.Update(r.OutputVars())\n\t\t\treturn false\n\t\t}\n\t\treturn false\n\t})\n\treturn output\n}\n\ntype equalityFactory struct {\n\tgen *localVarGenerator\n}\n\nfunc newEqualityFactory(gen *localVarGenerator) *equalityFactory {\n\treturn &equalityFactory{gen}\n}\n\nfunc (f *equalityFactory) Generate(other *Term) *Expr {\n\tterm := NewTerm(f.gen.Generate()).SetLocation(other.Location)\n\texpr := Equality.Expr(term, other)\n\texpr.Generated = true\n\texpr.Location = other.Location\n\treturn expr\n}\n\ntype localVarGenerator struct {\n\texclude VarSet\n\tsuffix  string\n\tnext    int\n}\n\nfunc newLocalVarGeneratorForModuleSet(sorted []string, modules map[string]*Module) *localVarGenerator {\n\texclude := NewVarSet()\n\tvis := &VarVisitor{vars: exclude}\n\tfor _, key := range sorted {\n\t\tvis.Walk(modules[key])\n\t}\n\treturn &localVarGenerator{exclude: exclude, next: 0}\n}\n\nfunc newLocalVarGenerator(suffix string, node interface{}) *localVarGenerator {\n\texclude := NewVarSet()\n\tvis := &VarVisitor{vars: exclude}\n\tvis.Walk(node)\n\treturn &localVarGenerator{exclude: exclude, suffix: suffix, next: 0}\n}\n\nfunc (l *localVarGenerator) Generate() Var {\n\tfor {\n\t\tresult := Var(\"__local\" + l.suffix + strconv.Itoa(l.next) + \"__\")\n\t\tl.next++\n\t\tif !l.exclude.Contains(result) {\n\t\t\treturn result\n\t\t}\n\t}\n}\n\nfunc getGlobals(pkg *Package, rules []Var, imports []*Import) map[Var]*usedRef {\n\n\tglobals := map[Var]*usedRef{}\n\n\t// Populate globals with exports within the package.\n\tfor _, v := range rules {\n\t\tglobal := append(Ref{}, pkg.Path...)\n\t\tglobal = append(global, &Term{Value: String(v)})\n\t\tglobals[v] = &usedRef{ref: global}\n\t}\n\n\t// Populate globals with imports.\n\tfor _, imp := range imports {\n\t\tpath := imp.Path.Value.(Ref)\n\t\tif FutureRootDocument.Equal(path[0]) {\n\t\t\tcontinue // ignore future imports\n\t\t}\n\t\tglobals[imp.Name()] = &usedRef{ref: path}\n\t}\n\n\treturn globals\n}\n\nfunc requiresEval(x *Term) bool {\n\tif x == nil {\n\t\treturn false\n\t}\n\treturn ContainsRefs(x) || ContainsComprehensions(x)\n}\n\nfunc resolveRef(globals map[Var]*usedRef, ignore *declaredVarStack, ref Ref) Ref {\n\n\tr := Ref{}\n\tfor i, x := range ref {\n\t\tswitch v := x.Value.(type) {\n\t\tcase Var:\n\t\t\tif g, ok := globals[v]; ok && !ignore.Contains(v) {\n\t\t\t\tcpy := g.ref.Copy()\n\t\t\t\tfor i := range cpy {\n\t\t\t\t\tcpy[i].SetLocation(x.Location)\n\t\t\t\t}\n\t\t\t\tif i == 0 {\n\t\t\t\t\tr = cpy\n\t\t\t\t} else {\n\t\t\t\t\tr = append(r, NewTerm(cpy).SetLocation(x.Location))\n\t\t\t\t}\n\t\t\t\tg.used = true\n\t\t\t} else {\n\t\t\t\tr = append(r, x)\n\t\t\t}\n\t\tcase Ref, *Array, Object, Set, *ArrayComprehension, *SetComprehension, *ObjectComprehension, Call:\n\t\t\tr = append(r, resolveRefsInTerm(globals, ignore, x))\n\t\tdefault:\n\t\t\tr = append(r, x)\n\t\t}\n\t}\n\n\treturn r\n}\n\ntype usedRef struct {\n\tref  Ref\n\tused bool\n}\n\nfunc resolveRefsInRule(globals map[Var]*usedRef, rule *Rule) error {\n\tignore := &declaredVarStack{}\n\n\tvars := NewVarSet()\n\tvar vis *GenericVisitor\n\tvar err error\n\n\t// Walk args to collect vars and transform body so that callers can shadow\n\t// root documents.\n\tvis = NewGenericVisitor(func(x interface{}) bool {\n\t\tif err != nil {\n\t\t\treturn true\n\t\t}\n\t\tswitch x := x.(type) {\n\t\tcase Var:\n\t\t\tvars.Add(x)\n\n\t\t// Object keys cannot be pattern matched so only walk values.\n\t\tcase *object:\n\t\t\tx.Foreach(func(k, v *Term) {\n\t\t\t\tvis.Walk(v)\n\t\t\t})\n\n\t\t// Skip terms that could contain vars that cannot be pattern matched.\n\t\tcase Set, *ArrayComprehension, *SetComprehension, *ObjectComprehension, Call:\n\t\t\treturn true\n\n\t\tcase *Term:\n\t\t\tif _, ok := x.Value.(Ref); ok {\n\t\t\t\tif RootDocumentRefs.Contains(x) {\n\t\t\t\t\t// We could support args named input, data, etc. however\n\t\t\t\t\t// this would require rewriting terms in the head and body.\n\t\t\t\t\t// Preventing root document shadowing is simpler, and\n\t\t\t\t\t// arguably, will prevent confusing names from being used.\n\t\t\t\t\terr = fmt.Errorf(\"args must not shadow %v (use a different variable name)\", x)\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn false\n\t})\n\n\tvis.Walk(rule.Head.Args)\n\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tignore.Push(vars)\n\tignore.Push(declaredVars(rule.Body))\n\n\tif rule.Head.Key != nil {\n\t\trule.Head.Key = resolveRefsInTerm(globals, ignore, rule.Head.Key)\n\t}\n\n\tif rule.Head.Value != nil {\n\t\trule.Head.Value = resolveRefsInTerm(globals, ignore, rule.Head.Value)\n\t}\n\n\trule.Body = resolveRefsInBody(globals, ignore, rule.Body)\n\treturn nil\n}\n\nfunc resolveRefsInBody(globals map[Var]*usedRef, ignore *declaredVarStack, body Body) Body {\n\tr := make([]*Expr, 0, len(body))\n\tfor _, expr := range body {\n\t\tr = append(r, resolveRefsInExpr(globals, ignore, expr))\n\t}\n\treturn r\n}\n\nfunc resolveRefsInExpr(globals map[Var]*usedRef, ignore *declaredVarStack, expr *Expr) *Expr {\n\tcpy := *expr\n\tswitch ts := expr.Terms.(type) {\n\tcase *Term:\n\t\tcpy.Terms = resolveRefsInTerm(globals, ignore, ts)\n\tcase []*Term:\n\t\tbuf := make([]*Term, len(ts))\n\t\tfor i := 0; i < len(ts); i++ {\n\t\t\tbuf[i] = resolveRefsInTerm(globals, ignore, ts[i])\n\t\t}\n\t\tcpy.Terms = buf\n\tcase *SomeDecl:\n\t\tif val, ok := ts.Symbols[0].Value.(Call); ok {\n\t\t\tcpy.Terms = &SomeDecl{Symbols: []*Term{CallTerm(resolveRefsInTermSlice(globals, ignore, val)...)}}\n\t\t}\n\tcase *Every:\n\t\tlocals := NewVarSet()\n\t\tif ts.Key != nil {\n\t\t\tlocals.Update(ts.Key.Vars())\n\t\t}\n\t\tlocals.Update(ts.Value.Vars())\n\t\tignore.Push(locals)\n\t\tcpy.Terms = &Every{\n\t\t\tKey:    ts.Key.Copy(),   // TODO(sr): do more?\n\t\t\tValue:  ts.Value.Copy(), // TODO(sr): do more?\n\t\t\tDomain: resolveRefsInTerm(globals, ignore, ts.Domain),\n\t\t\tBody:   resolveRefsInBody(globals, ignore, ts.Body),\n\t\t}\n\t\tignore.Pop()\n\t}\n\tfor _, w := range cpy.With {\n\t\tw.Target = resolveRefsInTerm(globals, ignore, w.Target)\n\t\tw.Value = resolveRefsInTerm(globals, ignore, w.Value)\n\t}\n\treturn &cpy\n}\n\nfunc resolveRefsInTerm(globals map[Var]*usedRef, ignore *declaredVarStack, term *Term) *Term {\n\tswitch v := term.Value.(type) {\n\tcase Var:\n\t\tif g, ok := globals[v]; ok && !ignore.Contains(v) {\n\t\t\tcpy := g.ref.Copy()\n\t\t\tfor i := range cpy {\n\t\t\t\tcpy[i].SetLocation(term.Location)\n\t\t\t}\n\t\t\tg.used = true\n\t\t\treturn NewTerm(cpy).SetLocation(term.Location)\n\t\t}\n\t\treturn term\n\tcase Ref:\n\t\tfqn := resolveRef(globals, ignore, v)\n\t\tcpy := *term\n\t\tcpy.Value = fqn\n\t\treturn &cpy\n\tcase *object:\n\t\tcpy := *term\n\t\tcpy.Value, _ = v.Map(func(k, v *Term) (*Term, *Term, error) {\n\t\t\tk = resolveRefsInTerm(globals, ignore, k)\n\t\t\tv = resolveRefsInTerm(globals, ignore, v)\n\t\t\treturn k, v, nil\n\t\t})\n\t\treturn &cpy\n\tcase *Array:\n\t\tcpy := *term\n\t\tcpy.Value = NewArray(resolveRefsInTermArray(globals, ignore, v)...)\n\t\treturn &cpy\n\tcase Call:\n\t\tcpy := *term\n\t\tcpy.Value = Call(resolveRefsInTermSlice(globals, ignore, v))\n\t\treturn &cpy\n\tcase Set:\n\t\ts, _ := v.Map(func(e *Term) (*Term, error) {\n\t\t\treturn resolveRefsInTerm(globals, ignore, e), nil\n\t\t})\n\t\tcpy := *term\n\t\tcpy.Value = s\n\t\treturn &cpy\n\tcase *ArrayComprehension:\n\t\tac := &ArrayComprehension{}\n\t\tignore.Push(declaredVars(v.Body))\n\t\tac.Term = resolveRefsInTerm(globals, ignore, v.Term)\n\t\tac.Body = resolveRefsInBody(globals, ignore, v.Body)\n\t\tcpy := *term\n\t\tcpy.Value = ac\n\t\tignore.Pop()\n\t\treturn &cpy\n\tcase *ObjectComprehension:\n\t\toc := &ObjectComprehension{}\n\t\tignore.Push(declaredVars(v.Body))\n\t\toc.Key = resolveRefsInTerm(globals, ignore, v.Key)\n\t\toc.Value = resolveRefsInTerm(globals, ignore, v.Value)\n\t\toc.Body = resolveRefsInBody(globals, ignore, v.Body)\n\t\tcpy := *term\n\t\tcpy.Value = oc\n\t\tignore.Pop()\n\t\treturn &cpy\n\tcase *SetComprehension:\n\t\tsc := &SetComprehension{}\n\t\tignore.Push(declaredVars(v.Body))\n\t\tsc.Term = resolveRefsInTerm(globals, ignore, v.Term)\n\t\tsc.Body = resolveRefsInBody(globals, ignore, v.Body)\n\t\tcpy := *term\n\t\tcpy.Value = sc\n\t\tignore.Pop()\n\t\treturn &cpy\n\tdefault:\n\t\treturn term\n\t}\n}\n\nfunc resolveRefsInTermArray(globals map[Var]*usedRef, ignore *declaredVarStack, terms *Array) []*Term {\n\tcpy := make([]*Term, terms.Len())\n\tfor i := 0; i < terms.Len(); i++ {\n\t\tcpy[i] = resolveRefsInTerm(globals, ignore, terms.Elem(i))\n\t}\n\treturn cpy\n}\n\nfunc resolveRefsInTermSlice(globals map[Var]*usedRef, ignore *declaredVarStack, terms []*Term) []*Term {\n\tcpy := make([]*Term, len(terms))\n\tfor i := 0; i < len(terms); i++ {\n\t\tcpy[i] = resolveRefsInTerm(globals, ignore, terms[i])\n\t}\n\treturn cpy\n}\n\ntype declaredVarStack []VarSet\n\nfunc (s declaredVarStack) Contains(v Var) bool {\n\tfor i := len(s) - 1; i >= 0; i-- {\n\t\tif _, ok := s[i][v]; ok {\n\t\t\treturn ok\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (s declaredVarStack) Add(v Var) {\n\ts[len(s)-1].Add(v)\n}\n\nfunc (s *declaredVarStack) Push(vs VarSet) {\n\t*s = append(*s, vs)\n}\n\nfunc (s *declaredVarStack) Pop() {\n\tcurr := *s\n\t*s = curr[:len(curr)-1]\n}\n\nfunc declaredVars(x interface{}) VarSet {\n\tvars := NewVarSet()\n\tvis := NewGenericVisitor(func(x interface{}) bool {\n\t\tswitch x := x.(type) {\n\t\tcase *Expr:\n\t\t\tif x.IsAssignment() && validEqAssignArgCount(x) {\n\t\t\t\tWalkVars(x.Operand(0), func(v Var) bool {\n\t\t\t\t\tvars.Add(v)\n\t\t\t\t\treturn false\n\t\t\t\t})\n\t\t\t} else if decl, ok := x.Terms.(*SomeDecl); ok {\n\t\t\t\tfor i := range decl.Symbols {\n\t\t\t\t\tswitch val := decl.Symbols[i].Value.(type) {\n\t\t\t\t\tcase Var:\n\t\t\t\t\t\tvars.Add(val)\n\t\t\t\t\tcase Call:\n\t\t\t\t\t\targs := val[1:]\n\t\t\t\t\t\tif len(args) == 3 { // some x, y in xs\n\t\t\t\t\t\t\tWalkVars(args[1], func(v Var) bool {\n\t\t\t\t\t\t\t\tvars.Add(v)\n\t\t\t\t\t\t\t\treturn false\n\t\t\t\t\t\t\t})\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// some x in xs\n\t\t\t\t\t\tWalkVars(args[0], func(v Var) bool {\n\t\t\t\t\t\t\tvars.Add(v)\n\t\t\t\t\t\t\treturn false\n\t\t\t\t\t\t})\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\tcase *ArrayComprehension, *SetComprehension, *ObjectComprehension:\n\t\t\treturn true\n\t\t}\n\t\treturn false\n\t})\n\tvis.Walk(x)\n\treturn vars\n}\n\n// rewriteComprehensionTerms will rewrite comprehensions so that the term part\n// is bound to a variable in the body. This allows any type of term to be used\n// in the term part (even if the term requires evaluation.)\n//\n// For instance, given the following comprehension:\n//\n// [x[0] | x = y[_]; y = [1,2,3]]\n//\n// The comprehension would be rewritten as:\n//\n// [__local0__ | x = y[_]; y = [1,2,3]; __local0__ = x[0]]\nfunc rewriteComprehensionTerms(f *equalityFactory, node interface{}) (interface{}, error) {\n\treturn TransformComprehensions(node, func(x interface{}) (Value, error) {\n\t\tswitch x := x.(type) {\n\t\tcase *ArrayComprehension:\n\t\t\tif requiresEval(x.Term) {\n\t\t\t\texpr := f.Generate(x.Term)\n\t\t\t\tx.Term = expr.Operand(0)\n\t\t\t\tx.Body.Append(expr)\n\t\t\t}\n\t\t\treturn x, nil\n\t\tcase *SetComprehension:\n\t\t\tif requiresEval(x.Term) {\n\t\t\t\texpr := f.Generate(x.Term)\n\t\t\t\tx.Term = expr.Operand(0)\n\t\t\t\tx.Body.Append(expr)\n\t\t\t}\n\t\t\treturn x, nil\n\t\tcase *ObjectComprehension:\n\t\t\tif requiresEval(x.Key) {\n\t\t\t\texpr := f.Generate(x.Key)\n\t\t\t\tx.Key = expr.Operand(0)\n\t\t\t\tx.Body.Append(expr)\n\t\t\t}\n\t\t\tif requiresEval(x.Value) {\n\t\t\t\texpr := f.Generate(x.Value)\n\t\t\t\tx.Value = expr.Operand(0)\n\t\t\t\tx.Body.Append(expr)\n\t\t\t}\n\t\t\treturn x, nil\n\t\t}\n\t\tpanic(\"illegal type\")\n\t})\n}\n\n// rewriteEquals will rewrite exprs under x as unification calls instead of ==\n// calls. For example:\n//\n// data.foo == data.bar is rewritten as data.foo = data.bar\n//\n// This stage should only run the safety check (since == is a built-in with no\n// outputs, so the inputs must not be marked as safe.)\n//\n// This stage is not executed by the query compiler by default because when\n// callers specify == instead of = they expect to receive a true/false/undefined\n// result back whereas with = the result is only ever true/undefined. For\n// partial evaluation cases we do want to rewrite == to = to simplify the\n// result.\nfunc rewriteEquals(x interface{}) {\n\tdoubleEq := Equal.Ref()\n\tunifyOp := Equality.Ref()\n\tt := NewGenericTransformer(func(x interface{}) (interface{}, error) {\n\t\tif x, ok := x.(*Expr); ok && x.IsCall() {\n\t\t\toperator := x.Operator()\n\t\t\tif operator.Equal(doubleEq) && len(x.Operands()) == 2 {\n\t\t\t\tx.SetOperator(NewTerm(unifyOp))\n\t\t\t}\n\t\t}\n\t\treturn x, nil\n\t})\n\t_, _ = Transform(t, x) // ignore error\n}\n\n// rewriteDynamics will rewrite the body so that dynamic terms (i.e., refs and\n// comprehensions) are bound to vars earlier in the query. This translation\n// results in eager evaluation.\n//\n// For instance, given the following query:\n//\n// foo(data.bar) = 1\n//\n// The rewritten version will be:\n//\n// __local0__ = data.bar; foo(__local0__) = 1\nfunc rewriteDynamics(f *equalityFactory, body Body) Body {\n\tresult := make(Body, 0, len(body))\n\tfor _, expr := range body {\n\t\tswitch {\n\t\tcase expr.IsEquality():\n\t\t\tresult = rewriteDynamicsEqExpr(f, expr, result)\n\t\tcase expr.IsCall():\n\t\t\tresult = rewriteDynamicsCallExpr(f, expr, result)\n\t\tcase expr.IsEvery():\n\t\t\tresult = rewriteDynamicsEveryExpr(f, expr, result)\n\t\tdefault:\n\t\t\tresult = rewriteDynamicsTermExpr(f, expr, result)\n\t\t}\n\t}\n\treturn result\n}\n\nfunc appendExpr(body Body, expr *Expr) Body {\n\tbody.Append(expr)\n\treturn body\n}\n\nfunc rewriteDynamicsEqExpr(f *equalityFactory, expr *Expr, result Body) Body {\n\tif !validEqAssignArgCount(expr) {\n\t\treturn appendExpr(result, expr)\n\t}\n\tterms := expr.Terms.([]*Term)\n\tresult, terms[1] = rewriteDynamicsInTerm(expr, f, terms[1], result)\n\tresult, terms[2] = rewriteDynamicsInTerm(expr, f, terms[2], result)\n\treturn appendExpr(result, expr)\n}\n\nfunc rewriteDynamicsCallExpr(f *equalityFactory, expr *Expr, result Body) Body {\n\tterms := expr.Terms.([]*Term)\n\tfor i := 1; i < len(terms); i++ {\n\t\tresult, terms[i] = rewriteDynamicsOne(expr, f, terms[i], result)\n\t}\n\treturn appendExpr(result, expr)\n}\n\nfunc rewriteDynamicsEveryExpr(f *equalityFactory, expr *Expr, result Body) Body {\n\tev := expr.Terms.(*Every)\n\tresult, ev.Domain = rewriteDynamicsOne(expr, f, ev.Domain, result)\n\tev.Body = rewriteDynamics(f, ev.Body)\n\treturn appendExpr(result, expr)\n}\n\nfunc rewriteDynamicsTermExpr(f *equalityFactory, expr *Expr, result Body) Body {\n\tterm := expr.Terms.(*Term)\n\tresult, expr.Terms = rewriteDynamicsInTerm(expr, f, term, result)\n\treturn appendExpr(result, expr)\n}\n\nfunc rewriteDynamicsInTerm(original *Expr, f *equalityFactory, term *Term, result Body) (Body, *Term) {\n\tswitch v := term.Value.(type) {\n\tcase Ref:\n\t\tfor i := 1; i < len(v); i++ {\n\t\t\tresult, v[i] = rewriteDynamicsOne(original, f, v[i], result)\n\t\t}\n\tcase *ArrayComprehension:\n\t\tv.Body = rewriteDynamics(f, v.Body)\n\tcase *SetComprehension:\n\t\tv.Body = rewriteDynamics(f, v.Body)\n\tcase *ObjectComprehension:\n\t\tv.Body = rewriteDynamics(f, v.Body)\n\tdefault:\n\t\tresult, term = rewriteDynamicsOne(original, f, term, result)\n\t}\n\treturn result, term\n}\n\nfunc rewriteDynamicsOne(original *Expr, f *equalityFactory, term *Term, result Body) (Body, *Term) {\n\tswitch v := term.Value.(type) {\n\tcase Ref:\n\t\tfor i := 1; i < len(v); i++ {\n\t\t\tresult, v[i] = rewriteDynamicsOne(original, f, v[i], result)\n\t\t}\n\t\tgenerated := f.Generate(term)\n\t\tgenerated.With = original.With\n\t\tresult.Append(generated)\n\t\treturn result, result[len(result)-1].Operand(0)\n\tcase *Array:\n\t\tfor i := 0; i < v.Len(); i++ {\n\t\t\tvar t *Term\n\t\t\tresult, t = rewriteDynamicsOne(original, f, v.Elem(i), result)\n\t\t\tv.set(i, t)\n\t\t}\n\t\treturn result, term\n\tcase *object:\n\t\tcpy := NewObject()\n\t\tv.Foreach(func(key, value *Term) {\n\t\t\tresult, key = rewriteDynamicsOne(original, f, key, result)\n\t\t\tresult, value = rewriteDynamicsOne(original, f, value, result)\n\t\t\tcpy.Insert(key, value)\n\t\t})\n\t\treturn result, NewTerm(cpy).SetLocation(term.Location)\n\tcase Set:\n\t\tcpy := NewSet()\n\t\tfor _, term := range v.Slice() {\n\t\t\tvar rw *Term\n\t\t\tresult, rw = rewriteDynamicsOne(original, f, term, result)\n\t\t\tcpy.Add(rw)\n\t\t}\n\t\treturn result, NewTerm(cpy).SetLocation(term.Location)\n\tcase *ArrayComprehension:\n\t\tvar extra *Expr\n\t\tv.Body, extra = rewriteDynamicsComprehensionBody(original, f, v.Body, term)\n\t\tresult.Append(extra)\n\t\treturn result, result[len(result)-1].Operand(0)\n\tcase *SetComprehension:\n\t\tvar extra *Expr\n\t\tv.Body, extra = rewriteDynamicsComprehensionBody(original, f, v.Body, term)\n\t\tresult.Append(extra)\n\t\treturn result, result[len(result)-1].Operand(0)\n\tcase *ObjectComprehension:\n\t\tvar extra *Expr\n\t\tv.Body, extra = rewriteDynamicsComprehensionBody(original, f, v.Body, term)\n\t\tresult.Append(extra)\n\t\treturn result, result[len(result)-1].Operand(0)\n\t}\n\treturn result, term\n}\n\nfunc rewriteDynamicsComprehensionBody(original *Expr, f *equalityFactory, body Body, term *Term) (Body, *Expr) {\n\tbody = rewriteDynamics(f, body)\n\tgenerated := f.Generate(term)\n\tgenerated.With = original.With\n\treturn body, generated\n}\n\nfunc rewriteExprTermsInHead(gen *localVarGenerator, rule *Rule) {\n\tfor i := range rule.Head.Args {\n\t\tsupport, output := expandExprTerm(gen, rule.Head.Args[i])\n\t\tfor j := range support {\n\t\t\trule.Body.Append(support[j])\n\t\t}\n\t\trule.Head.Args[i] = output\n\t}\n\tif rule.Head.Key != nil {\n\t\tsupport, output := expandExprTerm(gen, rule.Head.Key)\n\t\tfor i := range support {\n\t\t\trule.Body.Append(support[i])\n\t\t}\n\t\trule.Head.Key = output\n\t}\n\tif rule.Head.Value != nil {\n\t\tsupport, output := expandExprTerm(gen, rule.Head.Value)\n\t\tfor i := range support {\n\t\t\trule.Body.Append(support[i])\n\t\t}\n\t\trule.Head.Value = output\n\t}\n}\n\nfunc rewriteExprTermsInBody(gen *localVarGenerator, body Body) Body {\n\tcpy := make(Body, 0, len(body))\n\tfor i := 0; i < len(body); i++ {\n\t\tfor _, expr := range expandExpr(gen, body[i]) {\n\t\t\tcpy.Append(expr)\n\t\t}\n\t}\n\treturn cpy\n}\n\nfunc expandExpr(gen *localVarGenerator, expr *Expr) (result []*Expr) {\n\tfor i := range expr.With {\n\t\textras, value := expandExprTerm(gen, expr.With[i].Value)\n\t\texpr.With[i].Value = value\n\t\tresult = append(result, extras...)\n\t}\n\tswitch terms := expr.Terms.(type) {\n\tcase *Term:\n\t\textras, term := expandExprTerm(gen, terms)\n\t\tif len(expr.With) > 0 {\n\t\t\tfor i := range extras {\n\t\t\t\textras[i].With = expr.With\n\t\t\t}\n\t\t}\n\t\tresult = append(result, extras...)\n\t\texpr.Terms = term\n\t\tresult = append(result, expr)\n\tcase []*Term:\n\t\tfor i := 1; i < len(terms); i++ {\n\t\t\tvar extras []*Expr\n\t\t\textras, terms[i] = expandExprTerm(gen, terms[i])\n\t\t\tif len(expr.With) > 0 {\n\t\t\t\tfor i := range extras {\n\t\t\t\t\textras[i].With = expr.With\n\t\t\t\t}\n\t\t\t}\n\t\t\tresult = append(result, extras...)\n\t\t}\n\t\tresult = append(result, expr)\n\tcase *Every:\n\t\tvar extras []*Expr\n\t\tif _, ok := terms.Domain.Value.(Call); ok {\n\t\t\textras, terms.Domain = expandExprTerm(gen, terms.Domain)\n\t\t} else {\n\t\t\tterm := NewTerm(gen.Generate()).SetLocation(terms.Domain.Location)\n\t\t\teq := Equality.Expr(term, terms.Domain).SetLocation(terms.Domain.Location)\n\t\t\teq.Generated = true\n\t\t\teq.With = expr.With\n\t\t\textras = append(extras, eq)\n\t\t\tterms.Domain = term\n\t\t}\n\t\tterms.Body = rewriteExprTermsInBody(gen, terms.Body)\n\t\tresult = append(result, extras...)\n\t\tresult = append(result, expr)\n\t}\n\treturn\n}\n\nfunc expandExprTerm(gen *localVarGenerator, term *Term) (support []*Expr, output *Term) {\n\toutput = term\n\tswitch v := term.Value.(type) {\n\tcase Call:\n\t\tfor i := 1; i < len(v); i++ {\n\t\t\tvar extras []*Expr\n\t\t\textras, v[i] = expandExprTerm(gen, v[i])\n\t\t\tsupport = append(support, extras...)\n\t\t}\n\t\toutput = NewTerm(gen.Generate()).SetLocation(term.Location)\n\t\texpr := v.MakeExpr(output).SetLocation(term.Location)\n\t\texpr.Generated = true\n\t\tsupport = append(support, expr)\n\tcase Ref:\n\t\tsupport = expandExprRef(gen, v)\n\tcase *Array:\n\t\tsupport = expandExprTermArray(gen, v)\n\tcase *object:\n\t\tcpy, _ := v.Map(func(k, v *Term) (*Term, *Term, error) {\n\t\t\textras1, expandedKey := expandExprTerm(gen, k)\n\t\t\textras2, expandedValue := expandExprTerm(gen, v)\n\t\t\tsupport = append(support, extras1...)\n\t\t\tsupport = append(support, extras2...)\n\t\t\treturn expandedKey, expandedValue, nil\n\t\t})\n\t\toutput = NewTerm(cpy).SetLocation(term.Location)\n\tcase Set:\n\t\tcpy, _ := v.Map(func(x *Term) (*Term, error) {\n\t\t\textras, expanded := expandExprTerm(gen, x)\n\t\t\tsupport = append(support, extras...)\n\t\t\treturn expanded, nil\n\t\t})\n\t\toutput = NewTerm(cpy).SetLocation(term.Location)\n\tcase *ArrayComprehension:\n\t\tsupport, term := expandExprTerm(gen, v.Term)\n\t\tfor i := range support {\n\t\t\tv.Body.Append(support[i])\n\t\t}\n\t\tv.Term = term\n\t\tv.Body = rewriteExprTermsInBody(gen, v.Body)\n\tcase *SetComprehension:\n\t\tsupport, term := expandExprTerm(gen, v.Term)\n\t\tfor i := range support {\n\t\t\tv.Body.Append(support[i])\n\t\t}\n\t\tv.Term = term\n\t\tv.Body = rewriteExprTermsInBody(gen, v.Body)\n\tcase *ObjectComprehension:\n\t\tsupport, key := expandExprTerm(gen, v.Key)\n\t\tfor i := range support {\n\t\t\tv.Body.Append(support[i])\n\t\t}\n\t\tv.Key = key\n\t\tsupport, value := expandExprTerm(gen, v.Value)\n\t\tfor i := range support {\n\t\t\tv.Body.Append(support[i])\n\t\t}\n\t\tv.Value = value\n\t\tv.Body = rewriteExprTermsInBody(gen, v.Body)\n\t}\n\treturn\n}\n\nfunc expandExprRef(gen *localVarGenerator, v []*Term) (support []*Expr) {\n\t// Start by calling a normal expandExprTerm on all terms.\n\tsupport = expandExprTermSlice(gen, v)\n\n\t// Rewrite references in order to support indirect references.  We rewrite\n\t// e.g.\n\t//\n\t//     [1, 2, 3][i]\n\t//\n\t// to\n\t//\n\t//     __local_var = [1, 2, 3]\n\t//     __local_var[i]\n\t//\n\t// to support these.  This only impacts the reference subject, i.e. the\n\t// first item in the slice.\n\tvar subject = v[0]\n\tswitch subject.Value.(type) {\n\tcase *Array, Object, Set, *ArrayComprehension, *SetComprehension, *ObjectComprehension, Call:\n\t\tf := newEqualityFactory(gen)\n\t\tassignToLocal := f.Generate(subject)\n\t\tsupport = append(support, assignToLocal)\n\t\tv[0] = assignToLocal.Operand(0)\n\t}\n\treturn\n}\n\nfunc expandExprTermArray(gen *localVarGenerator, arr *Array) (support []*Expr) {\n\tfor i := 0; i < arr.Len(); i++ {\n\t\textras, v := expandExprTerm(gen, arr.Elem(i))\n\t\tarr.set(i, v)\n\t\tsupport = append(support, extras...)\n\t}\n\treturn\n}\n\nfunc expandExprTermSlice(gen *localVarGenerator, v []*Term) (support []*Expr) {\n\tfor i := 0; i < len(v); i++ {\n\t\tvar extras []*Expr\n\t\textras, v[i] = expandExprTerm(gen, v[i])\n\t\tsupport = append(support, extras...)\n\t}\n\treturn\n}\n\ntype localDeclaredVars struct {\n\tvars []*declaredVarSet\n\n\t// rewritten contains a mapping of *all* user-defined variables\n\t// that have been rewritten whereas vars contains the state\n\t// from the current query (not any nested queries, and all vars\n\t// seen).\n\trewritten map[Var]Var\n}\n\ntype varOccurrence int\n\nconst (\n\tnewVar varOccurrence = iota\n\targVar\n\tseenVar\n\tassignedVar\n\tdeclaredVar\n)\n\ntype declaredVarSet struct {\n\tvs         map[Var]Var\n\treverse    map[Var]Var\n\toccurrence map[Var]varOccurrence\n\tcount      map[Var]int\n}\n\nfunc newDeclaredVarSet() *declaredVarSet {\n\treturn &declaredVarSet{\n\t\tvs:         map[Var]Var{},\n\t\treverse:    map[Var]Var{},\n\t\toccurrence: map[Var]varOccurrence{},\n\t\tcount:      map[Var]int{},\n\t}\n}\n\nfunc newLocalDeclaredVars() *localDeclaredVars {\n\treturn &localDeclaredVars{\n\t\tvars:      []*declaredVarSet{newDeclaredVarSet()},\n\t\trewritten: map[Var]Var{},\n\t}\n}\n\nfunc (s *localDeclaredVars) Push() {\n\ts.vars = append(s.vars, newDeclaredVarSet())\n}\n\nfunc (s *localDeclaredVars) Pop() *declaredVarSet {\n\tsl := s.vars\n\tcurr := sl[len(sl)-1]\n\ts.vars = sl[:len(sl)-1]\n\treturn curr\n}\n\nfunc (s localDeclaredVars) Peek() *declaredVarSet {\n\treturn s.vars[len(s.vars)-1]\n}\n\nfunc (s localDeclaredVars) Insert(x, y Var, occurrence varOccurrence) {\n\telem := s.vars[len(s.vars)-1]\n\telem.vs[x] = y\n\telem.reverse[y] = x\n\telem.occurrence[x] = occurrence\n\n\telem.count[x] = 1\n\n\t// If the variable has been rewritten (where x != y, with y being\n\t// the generated value), store it in the map of rewritten vars.\n\t// Assume that the generated values are unique for the compilation.\n\tif !x.Equal(y) {\n\t\ts.rewritten[y] = x\n\t}\n}\n\nfunc (s localDeclaredVars) Declared(x Var) (y Var, ok bool) {\n\tfor i := len(s.vars) - 1; i >= 0; i-- {\n\t\tif y, ok = s.vars[i].vs[x]; ok {\n\t\t\treturn\n\t\t}\n\t}\n\treturn\n}\n\n// Occurrence returns a flag that indicates whether x has occurred in the\n// current scope.\nfunc (s localDeclaredVars) Occurrence(x Var) varOccurrence {\n\treturn s.vars[len(s.vars)-1].occurrence[x]\n}\n\n// GlobalOccurrence returns a flag that indicates whether x has occurred in the\n// global scope.\nfunc (s localDeclaredVars) GlobalOccurrence(x Var) (varOccurrence, bool) {\n\tfor i := len(s.vars) - 1; i >= 0; i-- {\n\t\tif occ, ok := s.vars[i].occurrence[x]; ok {\n\t\t\treturn occ, true\n\t\t}\n\t}\n\treturn newVar, false\n}\n\n// Seen marks x as seen by incrementing its counter\nfunc (s localDeclaredVars) Seen(x Var) {\n\tfor i := len(s.vars) - 1; i >= 0; i-- {\n\t\tdvs := s.vars[i]\n\t\tif c, ok := dvs.count[x]; ok {\n\t\t\tdvs.count[x] = c + 1\n\t\t\treturn\n\t\t}\n\t}\n\n\ts.vars[len(s.vars)-1].count[x] = 1\n}\n\n// Count returns how many times x has been seen\nfunc (s localDeclaredVars) Count(x Var) int {\n\tfor i := len(s.vars) - 1; i >= 0; i-- {\n\t\tif c, ok := s.vars[i].count[x]; ok {\n\t\t\treturn c\n\t\t}\n\t}\n\n\treturn 0\n}\n\n// rewriteLocalVars rewrites bodies to remove assignment/declaration\n// expressions. For example:\n//\n// a := 1; p[a]\n//\n// Is rewritten to:\n//\n// __local0__ = 1; p[__local0__]\n//\n// During rewriting, assignees are validated to prevent use before declaration.\nfunc rewriteLocalVars(g *localVarGenerator, stack *localDeclaredVars, used VarSet, body Body, strict bool) (Body, map[Var]Var, Errors) {\n\tvar errs Errors\n\tbody, errs = rewriteDeclaredVarsInBody(g, stack, used, body, errs, strict)\n\treturn body, stack.Pop().vs, errs\n}\n\nfunc rewriteDeclaredVarsInBody(g *localVarGenerator, stack *localDeclaredVars, used VarSet, body Body, errs Errors, strict bool) (Body, Errors) {\n\n\tvar cpy Body\n\n\tfor i := range body {\n\t\tvar expr *Expr\n\t\tswitch {\n\t\tcase body[i].IsAssignment():\n\t\t\texpr, errs = rewriteDeclaredAssignment(g, stack, body[i], errs, strict)\n\t\tcase body[i].IsSome():\n\t\t\texpr, errs = rewriteSomeDeclStatement(g, stack, body[i], errs, strict)\n\t\tcase body[i].IsEvery():\n\t\t\texpr, errs = rewriteEveryStatement(g, stack, body[i], errs, strict)\n\t\tdefault:\n\t\t\texpr, errs = rewriteDeclaredVarsInExpr(g, stack, body[i], errs, strict)\n\t\t}\n\t\tif expr != nil {\n\t\t\tcpy.Append(expr)\n\t\t}\n\t}\n\n\t// If the body only contained a var statement it will be empty at this\n\t// point. Append true to the body to ensure that it's non-empty (zero length\n\t// bodies are not supported.)\n\tif len(cpy) == 0 {\n\t\tcpy.Append(NewExpr(BooleanTerm(true)))\n\t}\n\n\terrs = checkUnusedAssignedVars(body[0].Loc(), stack, used, errs, strict)\n\treturn cpy, checkUnusedDeclaredVars(body[0].Loc(), stack, used, cpy, errs)\n}\n\nfunc checkUnusedAssignedVars(loc *Location, stack *localDeclaredVars, used VarSet, errs Errors, strict bool) Errors {\n\n\tif !strict || len(errs) > 0 {\n\t\treturn errs\n\t}\n\n\tdvs := stack.Peek()\n\tunused := NewVarSet()\n\n\tfor v, occ := range dvs.occurrence {\n\t\t// A var that was assigned in this scope must have been seen (used) more than once (the time of assignment) in\n\t\t// the same, or nested, scope to be counted as used.\n\t\tif !v.IsWildcard() && occ == assignedVar && stack.Count(v) <= 1 {\n\t\t\tunused.Add(dvs.vs[v])\n\t\t}\n\t}\n\n\trewrittenUsed := NewVarSet()\n\tfor v := range used {\n\t\tif gv, ok := stack.Declared(v); ok {\n\t\t\trewrittenUsed.Add(gv)\n\t\t} else {\n\t\t\trewrittenUsed.Add(v)\n\t\t}\n\t}\n\n\tunused = unused.Diff(rewrittenUsed)\n\n\tfor _, gv := range unused.Sorted() {\n\t\terrs = append(errs, NewError(CompileErr, loc, \"assigned var %v unused\", dvs.reverse[gv]))\n\t}\n\n\treturn errs\n}\n\nfunc checkUnusedDeclaredVars(loc *Location, stack *localDeclaredVars, used VarSet, cpy Body, errs Errors) Errors {\n\n\t// NOTE(tsandall): Do not generate more errors if there are existing\n\t// declaration errors.\n\tif len(errs) > 0 {\n\t\treturn errs\n\t}\n\n\tdvs := stack.Peek()\n\tdeclared := NewVarSet()\n\n\tfor v, occ := range dvs.occurrence {\n\t\tif occ == declaredVar {\n\t\t\tdeclared.Add(dvs.vs[v])\n\t\t}\n\t}\n\n\tbodyvars := cpy.Vars(VarVisitorParams{})\n\n\tfor v := range used {\n\t\tif gv, ok := stack.Declared(v); ok {\n\t\t\tbodyvars.Add(gv)\n\t\t} else {\n\t\t\tbodyvars.Add(v)\n\t\t}\n\t}\n\n\tunused := declared.Diff(bodyvars).Diff(used)\n\n\tfor _, gv := range unused.Sorted() {\n\t\trv := dvs.reverse[gv]\n\t\tif !rv.IsGenerated() {\n\t\t\terrs = append(errs, NewError(CompileErr, loc, \"declared var %v unused\", rv))\n\t\t}\n\t}\n\n\treturn errs\n}\n\nfunc rewriteEveryStatement(g *localVarGenerator, stack *localDeclaredVars, expr *Expr, errs Errors, strict bool) (*Expr, Errors) {\n\te := expr.Copy()\n\tevery := e.Terms.(*Every)\n\n\terrs = rewriteDeclaredVarsInTermRecursive(g, stack, every.Domain, errs, strict)\n\n\tstack.Push()\n\tdefer stack.Pop()\n\n\t// if the key exists, rewrite\n\tif every.Key != nil {\n\t\tif v := every.Key.Value.(Var); !v.IsWildcard() {\n\t\t\tgv, err := rewriteDeclaredVar(g, stack, v, declaredVar)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, append(errs, NewError(CompileErr, every.Loc(), err.Error()))\n\t\t\t}\n\t\t\tevery.Key.Value = gv\n\t\t}\n\t} else { // if the key doesn't exist, add dummy local\n\t\tevery.Key = NewTerm(g.Generate())\n\t}\n\n\t// value is always present\n\tif v := every.Value.Value.(Var); !v.IsWildcard() {\n\t\tgv, err := rewriteDeclaredVar(g, stack, v, declaredVar)\n\t\tif err != nil {\n\t\t\treturn nil, append(errs, NewError(CompileErr, every.Loc(), err.Error()))\n\t\t}\n\t\tevery.Value.Value = gv\n\t}\n\n\tused := NewVarSet()\n\tevery.Body, errs = rewriteDeclaredVarsInBody(g, stack, used, every.Body, errs, strict)\n\n\treturn rewriteDeclaredVarsInExpr(g, stack, e, errs, strict)\n}\n\nfunc rewriteSomeDeclStatement(g *localVarGenerator, stack *localDeclaredVars, expr *Expr, errs Errors, strict bool) (*Expr, Errors) {\n\te := expr.Copy()\n\tdecl := e.Terms.(*SomeDecl)\n\tfor i := range decl.Symbols {\n\t\tswitch v := decl.Symbols[i].Value.(type) {\n\t\tcase Var:\n\t\t\tif _, err := rewriteDeclaredVar(g, stack, v, declaredVar); err != nil {\n\t\t\t\treturn nil, append(errs, NewError(CompileErr, decl.Loc(), err.Error()))\n\t\t\t}\n\t\tcase Call:\n\t\t\tvar key, val, container *Term\n\t\t\tswitch len(v) {\n\t\t\tcase 4: // member3\n\t\t\t\tkey = v[1]\n\t\t\t\tval = v[2]\n\t\t\t\tcontainer = v[3]\n\t\t\tcase 3: // member\n\t\t\t\tkey = NewTerm(g.Generate())\n\t\t\t\tval = v[1]\n\t\t\t\tcontainer = v[2]\n\t\t\t}\n\n\t\t\tvar rhs *Term\n\t\t\tswitch c := container.Value.(type) {\n\t\t\tcase Ref:\n\t\t\t\trhs = RefTerm(append(c, key)...)\n\t\t\tdefault:\n\t\t\t\trhs = RefTerm(container, key)\n\t\t\t}\n\t\t\te.Terms = []*Term{\n\t\t\t\tRefTerm(VarTerm(Equality.Name)), val, rhs,\n\t\t\t}\n\n\t\t\tfor _, v0 := range outputVarsForExprEq(e, container.Vars()).Sorted() {\n\t\t\t\tif _, err := rewriteDeclaredVar(g, stack, v0, declaredVar); err != nil {\n\t\t\t\t\treturn nil, append(errs, NewError(CompileErr, decl.Loc(), err.Error()))\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn rewriteDeclaredVarsInExpr(g, stack, e, errs, strict)\n\t\t}\n\t}\n\treturn nil, errs\n}\n\nfunc rewriteDeclaredVarsInExpr(g *localVarGenerator, stack *localDeclaredVars, expr *Expr, errs Errors, strict bool) (*Expr, Errors) {\n\tvis := NewGenericVisitor(func(x interface{}) bool {\n\t\tvar stop bool\n\t\tswitch x := x.(type) {\n\t\tcase *Term:\n\t\t\tstop, errs = rewriteDeclaredVarsInTerm(g, stack, x, errs, strict)\n\t\tcase *With:\n\t\t\t_, errs = rewriteDeclaredVarsInTerm(g, stack, x.Value, errs, strict)\n\t\t\tstop = true\n\t\t}\n\t\treturn stop\n\t})\n\tvis.Walk(expr)\n\treturn expr, errs\n}\n\nfunc rewriteDeclaredAssignment(g *localVarGenerator, stack *localDeclaredVars, expr *Expr, errs Errors, strict bool) (*Expr, Errors) {\n\n\tif expr.Negated {\n\t\terrs = append(errs, NewError(CompileErr, expr.Location, \"cannot assign vars inside negated expression\"))\n\t\treturn expr, errs\n\t}\n\n\tnumErrsBefore := len(errs)\n\n\tif !validEqAssignArgCount(expr) {\n\t\treturn expr, errs\n\t}\n\n\t// Rewrite terms on right hand side capture seen vars and recursively\n\t// process comprehensions before left hand side is processed. Also\n\t// rewrite with modifier.\n\terrs = rewriteDeclaredVarsInTermRecursive(g, stack, expr.Operand(1), errs, strict)\n\n\tfor _, w := range expr.With {\n\t\terrs = rewriteDeclaredVarsInTermRecursive(g, stack, w.Value, errs, strict)\n\t}\n\n\t// Rewrite vars on left hand side with unique names. Catch redeclaration\n\t// and invalid term types here.\n\tvar vis func(t *Term) bool\n\n\tvis = func(t *Term) bool {\n\t\tswitch v := t.Value.(type) {\n\t\tcase Var:\n\t\t\tif gv, err := rewriteDeclaredVar(g, stack, v, assignedVar); err != nil {\n\t\t\t\terrs = append(errs, NewError(CompileErr, t.Location, err.Error()))\n\t\t\t} else {\n\t\t\t\tt.Value = gv\n\t\t\t}\n\t\t\treturn true\n\t\tcase *Array:\n\t\t\treturn false\n\t\tcase *object:\n\t\t\tv.Foreach(func(_, v *Term) {\n\t\t\t\tWalkTerms(v, vis)\n\t\t\t})\n\t\t\treturn true\n\t\tcase Ref:\n\t\t\tif RootDocumentRefs.Contains(t) {\n\t\t\t\tif gv, err := rewriteDeclaredVar(g, stack, v[0].Value.(Var), assignedVar); err != nil {\n\t\t\t\t\terrs = append(errs, NewError(CompileErr, t.Location, err.Error()))\n\t\t\t\t} else {\n\t\t\t\t\tt.Value = gv\n\t\t\t\t}\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t\terrs = append(errs, NewError(CompileErr, t.Location, \"cannot assign to %v\", TypeName(t.Value)))\n\t\treturn true\n\t}\n\n\tWalkTerms(expr.Operand(0), vis)\n\n\tif len(errs) == numErrsBefore {\n\t\tloc := expr.Operator()[0].Location\n\t\texpr.SetOperator(RefTerm(VarTerm(Equality.Name).SetLocation(loc)).SetLocation(loc))\n\t}\n\n\treturn expr, errs\n}\n\nfunc rewriteDeclaredVarsInTerm(g *localVarGenerator, stack *localDeclaredVars, term *Term, errs Errors, strict bool) (bool, Errors) {\n\tswitch v := term.Value.(type) {\n\tcase Var:\n\t\tif gv, ok := stack.Declared(v); ok {\n\t\t\tterm.Value = gv\n\t\t\tstack.Seen(v)\n\t\t} else if stack.Occurrence(v) == newVar {\n\t\t\tstack.Insert(v, v, seenVar)\n\t\t}\n\tcase Ref:\n\t\tif RootDocumentRefs.Contains(term) {\n\t\t\tx := v[0].Value.(Var)\n\t\t\tif occ, ok := stack.GlobalOccurrence(x); ok && occ != seenVar {\n\t\t\t\tgv, _ := stack.Declared(x)\n\t\t\t\tterm.Value = gv\n\t\t\t}\n\n\t\t\treturn true, errs\n\t\t}\n\t\treturn false, errs\n\tcase Call:\n\t\tref := v[0]\n\t\tWalkVars(ref, func(v Var) bool {\n\t\t\tif gv, ok := stack.Declared(v); ok && !gv.Equal(v) {\n\t\t\t\t// We will rewrite the ref of a function call, which is never ok since we don't have first-class functions.\n\t\t\t\terrs = append(errs, NewError(CompileErr, term.Location, \"called function %s shadowed\", ref))\n\t\t\t\treturn true\n\t\t\t}\n\t\t\treturn false\n\t\t})\n\t\treturn false, errs\n\tcase *object:\n\t\tcpy, _ := v.Map(func(k, v *Term) (*Term, *Term, error) {\n\t\t\tkcpy := k.Copy()\n\t\t\terrs = rewriteDeclaredVarsInTermRecursive(g, stack, kcpy, errs, strict)\n\t\t\terrs = rewriteDeclaredVarsInTermRecursive(g, stack, v, errs, strict)\n\t\t\treturn kcpy, v, nil\n\t\t})\n\t\tterm.Value = cpy\n\tcase Set:\n\t\tcpy, _ := v.Map(func(elem *Term) (*Term, error) {\n\t\t\telemcpy := elem.Copy()\n\t\t\terrs = rewriteDeclaredVarsInTermRecursive(g, stack, elemcpy, errs, strict)\n\t\t\treturn elemcpy, nil\n\t\t})\n\t\tterm.Value = cpy\n\tcase *ArrayComprehension:\n\t\terrs = rewriteDeclaredVarsInArrayComprehension(g, stack, v, errs, strict)\n\tcase *SetComprehension:\n\t\terrs = rewriteDeclaredVarsInSetComprehension(g, stack, v, errs, strict)\n\tcase *ObjectComprehension:\n\t\terrs = rewriteDeclaredVarsInObjectComprehension(g, stack, v, errs, strict)\n\tdefault:\n\t\treturn false, errs\n\t}\n\treturn true, errs\n}\n\nfunc rewriteDeclaredVarsInTermRecursive(g *localVarGenerator, stack *localDeclaredVars, term *Term, errs Errors, strict bool) Errors {\n\tWalkNodes(term, func(n Node) bool {\n\t\tvar stop bool\n\t\tswitch n := n.(type) {\n\t\tcase *With:\n\t\t\t_, errs = rewriteDeclaredVarsInTerm(g, stack, n.Value, errs, strict)\n\t\t\tstop = true\n\t\tcase *Term:\n\t\t\tstop, errs = rewriteDeclaredVarsInTerm(g, stack, n, errs, strict)\n\t\t}\n\t\treturn stop\n\t})\n\treturn errs\n}\n\nfunc rewriteDeclaredVarsInArrayComprehension(g *localVarGenerator, stack *localDeclaredVars, v *ArrayComprehension, errs Errors, strict bool) Errors {\n\tused := NewVarSet()\n\tused.Update(v.Term.Vars())\n\n\tstack.Push()\n\tv.Body, errs = rewriteDeclaredVarsInBody(g, stack, used, v.Body, errs, strict)\n\terrs = rewriteDeclaredVarsInTermRecursive(g, stack, v.Term, errs, strict)\n\tstack.Pop()\n\treturn errs\n}\n\nfunc rewriteDeclaredVarsInSetComprehension(g *localVarGenerator, stack *localDeclaredVars, v *SetComprehension, errs Errors, strict bool) Errors {\n\tused := NewVarSet()\n\tused.Update(v.Term.Vars())\n\n\tstack.Push()\n\tv.Body, errs = rewriteDeclaredVarsInBody(g, stack, used, v.Body, errs, strict)\n\terrs = rewriteDeclaredVarsInTermRecursive(g, stack, v.Term, errs, strict)\n\tstack.Pop()\n\treturn errs\n}\n\nfunc rewriteDeclaredVarsInObjectComprehension(g *localVarGenerator, stack *localDeclaredVars, v *ObjectComprehension, errs Errors, strict bool) Errors {\n\tused := NewVarSet()\n\tused.Update(v.Key.Vars())\n\tused.Update(v.Value.Vars())\n\n\tstack.Push()\n\tv.Body, errs = rewriteDeclaredVarsInBody(g, stack, used, v.Body, errs, strict)\n\terrs = rewriteDeclaredVarsInTermRecursive(g, stack, v.Key, errs, strict)\n\terrs = rewriteDeclaredVarsInTermRecursive(g, stack, v.Value, errs, strict)\n\tstack.Pop()\n\treturn errs\n}\n\nfunc rewriteDeclaredVar(g *localVarGenerator, stack *localDeclaredVars, v Var, occ varOccurrence) (gv Var, err error) {\n\tswitch stack.Occurrence(v) {\n\tcase seenVar:\n\t\treturn gv, fmt.Errorf(\"var %v referenced above\", v)\n\tcase assignedVar:\n\t\treturn gv, fmt.Errorf(\"var %v assigned above\", v)\n\tcase declaredVar:\n\t\treturn gv, fmt.Errorf(\"var %v declared above\", v)\n\tcase argVar:\n\t\treturn gv, fmt.Errorf(\"arg %v redeclared\", v)\n\t}\n\tgv = g.Generate()\n\tstack.Insert(v, gv, occ)\n\treturn\n}\n\n// rewriteWithModifiersInBody will rewrite the body so that with modifiers do\n// not contain terms that require evaluation as values. If this function\n// encounters an invalid with modifier target then it will raise an error.\nfunc rewriteWithModifiersInBody(c *Compiler, unsafeBuiltinsMap map[string]struct{}, f *equalityFactory, body Body) (Body, *Error) {\n\tvar result Body\n\tfor i := range body {\n\t\texprs, err := rewriteWithModifier(c, unsafeBuiltinsMap, f, body[i])\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif len(exprs) > 0 {\n\t\t\tfor _, expr := range exprs {\n\t\t\t\tresult.Append(expr)\n\t\t\t}\n\t\t} else {\n\t\t\tresult.Append(body[i])\n\t\t}\n\t}\n\treturn result, nil\n}\n\nfunc rewriteWithModifier(c *Compiler, unsafeBuiltinsMap map[string]struct{}, f *equalityFactory, expr *Expr) ([]*Expr, *Error) {\n\n\tvar result []*Expr\n\tfor i := range expr.With {\n\t\teval, err := validateWith(c, unsafeBuiltinsMap, expr, i)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tif eval {\n\t\t\teq := f.Generate(expr.With[i].Value)\n\t\t\tresult = append(result, eq)\n\t\t\texpr.With[i].Value = eq.Operand(0)\n\t\t}\n\t}\n\n\treturn append(result, expr), nil\n}\n\nfunc validateWith(c *Compiler, unsafeBuiltinsMap map[string]struct{}, expr *Expr, i int) (bool, *Error) {\n\ttarget, value := expr.With[i].Target, expr.With[i].Value\n\n\t// Ensure that values that are built-ins are rewritten to Ref (not Var)\n\tif v, ok := value.Value.(Var); ok {\n\t\tif _, ok := c.builtins[v.String()]; ok {\n\t\t\tvalue.Value = Ref([]*Term{NewTerm(v)})\n\t\t}\n\t}\n\tisBuiltinRefOrVar, err := isBuiltinRefOrVar(c.builtins, unsafeBuiltinsMap, target)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\tswitch {\n\tcase isDataRef(target):\n\t\tref := target.Value.(Ref)\n\t\tnode := c.RuleTree\n\t\tfor i := 0; i < len(ref)-1; i++ {\n\t\t\tchild := node.Child(ref[i].Value)\n\t\t\tif child == nil {\n\t\t\t\tbreak\n\t\t\t} else if len(child.Values) > 0 {\n\t\t\t\treturn false, NewError(CompileErr, target.Loc(), \"with keyword cannot partially replace virtual document(s)\")\n\t\t\t}\n\t\t\tnode = child\n\t\t}\n\n\t\tif node != nil {\n\t\t\t// NOTE(sr): at this point in the compiler stages, we don't have a fully-populated\n\t\t\t// TypeEnv yet -- so we have to make do with this check to see if the replacement\n\t\t\t// target is a function. It's probably wrong for arity-0 functions, but those are\n\t\t\t// and edge case anyways.\n\t\t\tif child := node.Child(ref[len(ref)-1].Value); child != nil {\n\t\t\t\tfor _, v := range child.Values {\n\t\t\t\t\tif len(v.(*Rule).Head.Args) > 0 {\n\t\t\t\t\t\tif ok, err := validateWithFunctionValue(c.builtins, unsafeBuiltinsMap, c.RuleTree, value); err != nil || ok {\n\t\t\t\t\t\t\treturn false, err // may be nil\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\tcase isInputRef(target): // ok, valid\n\tcase isBuiltinRefOrVar:\n\n\t\t// NOTE(sr): first we ensure that parsed Var builtins (`count`, `concat`, etc)\n\t\t// are rewritten to their proper Ref convention\n\t\tif v, ok := target.Value.(Var); ok {\n\t\t\ttarget.Value = Ref([]*Term{NewTerm(v)})\n\t\t}\n\n\t\ttargetRef := target.Value.(Ref)\n\t\tbi := c.builtins[targetRef.String()] // safe because isBuiltinRefOrVar checked this\n\t\tif err := validateWithBuiltinTarget(bi, targetRef, target.Loc()); err != nil {\n\t\t\treturn false, err\n\t\t}\n\n\t\tif ok, err := validateWithFunctionValue(c.builtins, unsafeBuiltinsMap, c.RuleTree, value); err != nil || ok {\n\t\t\treturn false, err // may be nil\n\t\t}\n\tdefault:\n\t\treturn false, NewError(TypeErr, target.Location, \"with keyword target must reference existing %v, %v, or a function\", InputRootDocument, DefaultRootDocument)\n\t}\n\treturn requiresEval(value), nil\n}\n\nfunc validateWithBuiltinTarget(bi *Builtin, target Ref, loc *location.Location) *Error {\n\tswitch bi.Name {\n\tcase Equality.Name,\n\t\tRegoMetadataChain.Name,\n\t\tRegoMetadataRule.Name:\n\t\treturn NewError(CompileErr, loc, \"with keyword replacing built-in function: replacement of %q invalid\", bi.Name)\n\t}\n\n\tswitch {\n\tcase target.HasPrefix(Ref([]*Term{VarTerm(\"internal\")})):\n\t\treturn NewError(CompileErr, loc, \"with keyword replacing built-in function: replacement of internal function %q invalid\", target)\n\n\tcase bi.Relation:\n\t\treturn NewError(CompileErr, loc, \"with keyword replacing built-in function: target must not be a relation\")\n\n\tcase bi.Decl.Result() == nil:\n\t\treturn NewError(CompileErr, loc, \"with keyword replacing built-in function: target must not be a void function\")\n\t}\n\treturn nil\n}\n\nfunc validateWithFunctionValue(bs map[string]*Builtin, unsafeMap map[string]struct{}, ruleTree *TreeNode, value *Term) (bool, *Error) {\n\tif v, ok := value.Value.(Ref); ok {\n\t\tif ruleTree.Find(v) != nil { // ref exists in rule tree\n\t\t\treturn true, nil\n\t\t}\n\t}\n\treturn isBuiltinRefOrVar(bs, unsafeMap, value)\n}\n\nfunc isInputRef(term *Term) bool {\n\tif ref, ok := term.Value.(Ref); ok {\n\t\tif ref.HasPrefix(InputRootRef) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc isDataRef(term *Term) bool {\n\tif ref, ok := term.Value.(Ref); ok {\n\t\tif ref.HasPrefix(DefaultRootRef) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc isBuiltinRefOrVar(bs map[string]*Builtin, unsafeBuiltinsMap map[string]struct{}, term *Term) (bool, *Error) {\n\tswitch v := term.Value.(type) {\n\tcase Ref, Var:\n\t\tif _, ok := unsafeBuiltinsMap[v.String()]; ok {\n\t\t\treturn false, NewError(CompileErr, term.Location, \"with keyword replacing built-in function: target must not be unsafe: %q\", v)\n\t\t}\n\t\t_, ok := bs[v.String()]\n\t\treturn ok, nil\n\t}\n\treturn false, nil\n}\n\nfunc isVirtual(node *TreeNode, ref Ref) bool {\n\tfor i := 0; i < len(ref); i++ {\n\t\tchild := node.Child(ref[i].Value)\n\t\tif child == nil {\n\t\t\treturn false\n\t\t} else if len(child.Values) > 0 {\n\t\t\treturn true\n\t\t}\n\t\tnode = child\n\t}\n\treturn true\n}\n\nfunc safetyErrorSlice(unsafe unsafeVars, rewritten map[Var]Var) (result Errors) {\n\n\tif len(unsafe) == 0 {\n\t\treturn\n\t}\n\n\tfor _, pair := range unsafe.Vars() {\n\t\tv := pair.Var\n\t\tif w, ok := rewritten[v]; ok {\n\t\t\tv = w\n\t\t}\n\t\tif !v.IsGenerated() {\n\t\t\tif _, ok := futureKeywords[string(v)]; ok {\n\t\t\t\tresult = append(result, NewError(UnsafeVarErr, pair.Loc,\n\t\t\t\t\t\"var %[1]v is unsafe (hint: `import future.keywords.%[1]v` to import a future keyword)\", v))\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tresult = append(result, NewError(UnsafeVarErr, pair.Loc, \"var %v is unsafe\", v))\n\t\t}\n\t}\n\n\tif len(result) > 0 {\n\t\treturn\n\t}\n\n\t// If the expression contains unsafe generated variables, report which\n\t// expressions are unsafe instead of the variables that are unsafe (since\n\t// the latter are not meaningful to the user.)\n\tpairs := unsafe.Slice()\n\n\tsort.Slice(pairs, func(i, j int) bool {\n\t\treturn pairs[i].Expr.Location.Compare(pairs[j].Expr.Location) < 0\n\t})\n\n\t// Report at most one error per generated variable.\n\tseen := NewVarSet()\n\n\tfor _, expr := range pairs {\n\t\tbefore := len(seen)\n\t\tfor v := range expr.Vars {\n\t\t\tif v.IsGenerated() {\n\t\t\t\tseen.Add(v)\n\t\t\t}\n\t\t}\n\t\tif len(seen) > before {\n\t\t\tresult = append(result, NewError(UnsafeVarErr, expr.Expr.Location, \"expression is unsafe\"))\n\t\t}\n\t}\n\n\treturn\n}\n\nfunc checkUnsafeBuiltins(unsafeBuiltinsMap map[string]struct{}, node interface{}) Errors {\n\terrs := make(Errors, 0)\n\tWalkExprs(node, func(x *Expr) bool {\n\t\tif x.IsCall() {\n\t\t\toperator := x.Operator().String()\n\t\t\tif _, ok := unsafeBuiltinsMap[operator]; ok {\n\t\t\t\terrs = append(errs, NewError(TypeErr, x.Loc(), \"unsafe built-in function calls in expression: %v\", operator))\n\t\t\t}\n\t\t}\n\t\treturn false\n\t})\n\treturn errs\n}\n\nfunc checkDeprecatedBuiltins(deprecatedBuiltinsMap map[string]struct{}, node interface{}, strict bool) Errors {\n\t// Early out; deprecatedBuiltinsMap is only populated in strict-mode.\n\tif !strict {\n\t\treturn nil\n\t}\n\n\terrs := make(Errors, 0)\n\tWalkExprs(node, func(x *Expr) bool {\n\t\tif x.IsCall() {\n\t\t\toperator := x.Operator().String()\n\t\t\tif _, ok := deprecatedBuiltinsMap[operator]; ok {\n\t\t\t\terrs = append(errs, NewError(TypeErr, x.Loc(), \"deprecated built-in function calls in expression: %v\", operator))\n\t\t\t}\n\t\t}\n\t\treturn false\n\t})\n\treturn errs\n}\n\nfunc rewriteVarsInRef(vars ...map[Var]Var) varRewriter {\n\treturn func(node Ref) Ref {\n\t\ti, _ := TransformVars(node, func(v Var) (Value, error) {\n\t\t\tfor _, m := range vars {\n\t\t\t\tif u, ok := m[v]; ok {\n\t\t\t\t\treturn u, nil\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn v, nil\n\t\t})\n\t\treturn i.(Ref)\n\t}\n}\n", "// Copyright 2016 The OPA Authors.  All rights reserved.\n// Use of this source code is governed by an Apache2\n// license that can be found in the LICENSE file.\n\npackage ast\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"reflect\"\n\t\"sort\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/open-policy-agent/opa/metrics\"\n\t\"github.com/open-policy-agent/opa/types\"\n\t\"github.com/open-policy-agent/opa/util\"\n)\n\nfunc TestOutputVarsForNode(t *testing.T) {\n\n\ttests := []struct {\n\t\tnote      string\n\t\tquery     string\n\t\tarities   map[string]int\n\t\textraSafe string\n\t\texp       string\n\t}{\n\t\t{\n\t\t\tnote:  \"single var\",\n\t\t\tquery: \"x\",\n\t\t\texp:   \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"trivial eq\",\n\t\t\tquery: \"x = 1\",\n\t\t\texp:   \"{x}\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"negation\",\n\t\t\tquery: \"not x = 1\",\n\t\t\texp:   \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"embedded array\",\n\t\t\tquery: \"[x, [1]] = [1, [y]]\",\n\t\t\texp:   \"{x, y}\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"embedded sets\",\n\t\t\tquery: \"{x, [1]} = {1, [y]}\",\n\t\t\texp:   \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"embedded object values\",\n\t\t\tquery: `{\"foo\": x, \"bar\": {\"baz\": 1}} = {\"foo\": 1, \"bar\": {\"baz\": y}}`,\n\t\t\texp:   \"{x, y}\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"object keys are like sets\",\n\t\t\tquery: `{\"foo\": x} = {y: 1}`,\n\t\t\texp:   `set()`,\n\t\t},\n\t\t{\n\t\t\tnote:    \"built-ins\",\n\t\t\tquery:   `count([1,2,3], x)`,\n\t\t\texp:     \"{x}\",\n\t\t\tarities: map[string]int{\"count\": 1},\n\t\t},\n\t\t{\n\t\t\tnote:  \"built-ins - input args\",\n\t\t\tquery: `count(x)`,\n\t\t\texp:   \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:    \"functions - no arity\",\n\t\t\tquery:   `f(1,x)`,\n\t\t\tarities: map[string]int{},\n\t\t\texp:     \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:    \"functions\",\n\t\t\tquery:   `f(1,x)`,\n\t\t\tarities: map[string]int{\"f\": 1},\n\t\t\texp:     \"{x}\",\n\t\t},\n\t\t{\n\t\t\tnote:    \"functions - input args\",\n\t\t\tquery:   `f(1,x)`,\n\t\t\tarities: map[string]int{\"f\": 2},\n\t\t\texp:     \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:    \"functions - embedded refs\",\n\t\t\tquery:   `f(data.p[x], y)`,\n\t\t\tarities: map[string]int{\"f\": 1},\n\t\t\texp:     `{x, y}`,\n\t\t},\n\t\t{\n\t\t\tnote:    \"functions - skip ref head\",\n\t\t\tquery:   `f(x[1])`,\n\t\t\tarities: map[string]int{\"f\": 1},\n\t\t\texp:     `set()`,\n\t\t},\n\t\t{\n\t\t\tnote:    \"functions - skip sets\",\n\t\t\tquery:   `f(1, {x})`,\n\t\t\tarities: map[string]int{\"f\": 1},\n\t\t\texp:     `set()`,\n\t\t},\n\t\t{\n\t\t\tnote:    \"functions - skip object keys\",\n\t\t\tquery:   `f(1, {x: 1})`,\n\t\t\tarities: map[string]int{\"f\": 1},\n\t\t\texp:     `set()`,\n\t\t},\n\t\t{\n\t\t\tnote:    \"functions - skip closures\",\n\t\t\tquery:   `f(1, {x | x = 1})`,\n\t\t\tarities: map[string]int{\"f\": 1},\n\t\t\texp:     `set()`,\n\t\t},\n\t\t{\n\t\t\tnote:    \"functions - unsafe input\",\n\t\t\tquery:   `f(x, y)`,\n\t\t\tarities: map[string]int{\"f\": 1},\n\t\t\texp:     `set()`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"with keyword\",\n\t\t\tquery: \"1 with input as y\",\n\t\t\texp:   \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"with keyword - unsafe\",\n\t\t\tquery: \"x = 1 with input as y\",\n\t\t\texp:   \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:      \"with keyword - safe\",\n\t\t\tquery:     \"x = 1 with input as y\",\n\t\t\textraSafe: \"{y}\",\n\t\t\texp:       \"{x}\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"ref operand\",\n\t\t\tquery: \"data.p[x]\",\n\t\t\texp:   \"{x}\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"ref operand - unsafe head\",\n\t\t\tquery: \"p[x]\",\n\t\t\texp:   \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"ref operand - negation\",\n\t\t\tquery: \"not data.p[x]\",\n\t\t\texp:   \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"ref operand - nested\",\n\t\t\tquery: \"data.p[data.q[x]]\",\n\t\t\texp:   \"{x}\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"comprehension\",\n\t\t\tquery: \"[x | x = 1]\",\n\t\t\texp:   \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"comprehension containing safe ref\",\n\t\t\tquery: \"[x | data.p[x]]\",\n\t\t\texp:   \"set()\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"accumulate on exprs\",\n\t\t\tquery: \"x = 1; y = x; z = y\",\n\t\t\texp:   \"{x, y, z}\",\n\t\t},\n\t\t{\n\t\t\tnote:  \"composite head\",\n\t\t\tquery: \"{1, 2}[1] = x\",\n\t\t\texp:   `{x}`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"composite head\",\n\t\t\tquery: \"x = 1; {x, 2}[1] = y\",\n\t\t\texp:   `{x, y}`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"composite head\",\n\t\t\tquery: \"{x, 2}[1] = y\",\n\t\t\texp:   `set()`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"nested function calls\",\n\t\t\tquery: `z = \"abc\"; x = split(z, \"\")[y]`,\n\t\t\texp:   `{x, y, z}`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"unsafe nested function calls\",\n\t\t\tquery: `z = \"abc\"; x = split(z, a)[y]`,\n\t\t\texp:   `{z}`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"every: simple: no output vars\",\n\t\t\tquery: `every k, v in [1, 2] { k < v }`,\n\t\t\texp:   `set()`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"every: output vars in domain\",\n\t\t\tquery: `xs = []; every k, v in xs[i] { k < v }`,\n\t\t\texp:   `{xs, i}`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"every: output vars in body\",\n\t\t\tquery: `every k, v in [] { k < v; i = 1 }`,\n\t\t\texp:   `set()`,\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\n\t\t\topts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\t\t\tbody, err := ParseBodyWithOpts(tc.query, opts)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tarity := func(r Ref) int {\n\t\t\t\ta, ok := tc.arities[r.String()]\n\t\t\t\tif !ok {\n\t\t\t\t\treturn -1\n\t\t\t\t}\n\t\t\t\treturn a\n\t\t\t}\n\n\t\t\tsafe := ReservedVars.Copy()\n\n\t\t\tif tc.extraSafe != \"\" {\n\t\t\t\tMustParseTerm(tc.extraSafe).Value.(Set).Foreach(func(x *Term) {\n\t\t\t\t\tsafe.Add(x.Value.(Var))\n\t\t\t\t})\n\t\t\t}\n\n\t\t\tvs := NewSet()\n\n\t\t\tfor v := range outputVarsForBody(body, arity, safe) {\n\t\t\t\tvs.Add(NewTerm(v))\n\t\t\t}\n\n\t\t\texp := MustParseTerm(tc.exp)\n\n\t\t\tif exp.Value.Compare(vs) != 0 {\n\t\t\t\tt.Fatalf(\"Expected %v but got %v\", exp, vs)\n\t\t\t}\n\t\t})\n\t}\n\n}\n\nfunc TestModuleTree(t *testing.T) {\n\n\tmods := getCompilerTestModules()\n\tmods[\"system-mod\"] = MustParseModule(`\n\tpackage system.foo\n\n\tp = 1\n\t`)\n\tmods[\"non-system-mod\"] = MustParseModule(`\n\tpackage user.system\n\n\tp = 1\n\t`)\n\ttree := NewModuleTree(mods)\n\texpectedSize := 9\n\n\tif tree.Size() != expectedSize {\n\t\tt.Fatalf(\"Expected %v but got %v modules\", expectedSize, tree.Size())\n\t}\n\n\tif !tree.Children[Var(\"data\")].Children[String(\"system\")].Hide {\n\t\tt.Fatalf(\"Expected system node to be hidden\")\n\t}\n\n\tif tree.Children[Var(\"data\")].Children[String(\"system\")].Children[String(\"foo\")].Hide {\n\t\tt.Fatalf(\"Expected system.foo node to be visible\")\n\t}\n\n\tif tree.Children[Var(\"data\")].Children[String(\"user\")].Children[String(\"system\")].Hide {\n\t\tt.Fatalf(\"Expected user.system node to be visible\")\n\t}\n\n}\n\nfunc TestModuleTreeFilenameOrder(t *testing.T) {\n\t// NOTE(sr): It doesn't matter that these are conflicting; but that's where it\n\t// becomes very apparent: before this change, the rule that was reported as\n\t// \"conflicting\" was that of either one of the input files, randomly.\n\tmods := map[string]*Module{\n\t\t\"0.rego\": MustParseModule(\"package p\\nr = 1 { true }\"),\n\t\t\"1.rego\": MustParseModule(\"package p\\nr = 2 { true }\"),\n\t}\n\ttree := NewModuleTree(mods)\n\tvals := tree.Children[Var(\"data\")].Children[String(\"p\")].Modules\n\tif exp, act := 2, len(vals); exp != act {\n\t\tt.Fatalf(\"expected %d rules, found %d\", exp, act)\n\t}\n\tmod0 := vals[0]\n\tmod1 := vals[1]\n\tif exp, act := IntNumberTerm(1), mod0.Rules[0].Head.Value; !exp.Equal(act) {\n\t\tt.Errorf(\"expected value %v, got %v\", exp, act)\n\t}\n\tif exp, act := IntNumberTerm(2), mod1.Rules[0].Head.Value; !exp.Equal(act) {\n\t\tt.Errorf(\"expected value %v, got %v\", exp, act)\n\t}\n}\nfunc TestRuleTree(t *testing.T) {\n\n\tmods := getCompilerTestModules()\n\tmods[\"system-mod\"] = MustParseModule(`\n\tpackage system.foo\n\n\tp = 1\n\t`)\n\tmods[\"non-system-mod\"] = MustParseModule(`\n\tpackage user.system\n\n\tp = 1\n\t`)\n\tmods[\"mod-incr\"] = MustParseModule(`package a.b.c\n\ns[1] { true }\ns[2] { true }`,\n\t)\n\n\ttree := NewRuleTree(NewModuleTree(mods))\n\texpectedNumRules := 23\n\n\tif tree.Size() != expectedNumRules {\n\t\tt.Errorf(\"Expected %v but got %v rules\", expectedNumRules, tree.Size())\n\t}\n\n\t// Check that empty packages are represented as leaves with no rules.\n\tnode := tree.Children[Var(\"data\")].Children[String(\"a\")].Children[String(\"b\")].Children[String(\"empty\")]\n\n\tif node == nil || len(node.Children) != 0 || len(node.Values) != 0 {\n\t\tt.Fatalf(\"Unexpected nil value or non-empty leaf of non-leaf node: %v\", node)\n\t}\n\n\tsystem := tree.Child(Var(\"data\")).Child(String(\"system\"))\n\tif !system.Hide {\n\t\tt.Fatalf(\"Expected system node to be hidden\")\n\t}\n\n\tif system.Child(String(\"foo\")).Hide {\n\t\tt.Fatalf(\"Expected system.foo node to be visible\")\n\t}\n\n\tuser := tree.Child(Var(\"data\")).Child(String(\"user\")).Child(String(\"system\"))\n\tif user.Hide {\n\t\tt.Fatalf(\"Expected user.system node to be visible\")\n\t}\n\n\tif !isVirtual(tree, MustParseRef(\"data.a.b.empty\")) {\n\t\tt.Fatal(\"Expected data.a.b.empty to be virtual\")\n\t}\n\n\tabc := tree.Children[Var(\"data\")].Children[String(\"a\")].Children[String(\"b\")].Children[String(\"c\")]\n\texp := []Value{String(\"p\"), String(\"q\"), String(\"r\"), String(\"s\"), String(\"z\")}\n\n\tif len(abc.Sorted) != len(exp) {\n\t\tt.Fatal(\"expected\", exp, \"but got\", abc)\n\t}\n\n\tfor i := range exp {\n\t\tif exp[i].Compare(abc.Sorted[i]) != 0 {\n\t\t\tt.Fatal(\"expected\", exp, \"but got\", abc)\n\t\t}\n\t}\n}\n\nfunc TestCompilerEmpty(t *testing.T) {\n\tc := NewCompiler()\n\tc.Compile(nil)\n\tassertNotFailed(t, c)\n}\n\nfunc TestCompilerExample(t *testing.T) {\n\tc := NewCompiler()\n\tm := MustParseModule(testModule)\n\tc.Compile(map[string]*Module{\"testMod\": m})\n\tassertNotFailed(t, c)\n}\n\nfunc TestCompilerWithStageAfter(t *testing.T) {\n\tt.Run(\"after failing means overall failure\", func(t *testing.T) {\n\t\tc := NewCompiler().WithStageAfter(\n\t\t\t\"CheckRecursion\",\n\t\t\tCompilerStageDefinition{\"MockStage\", \"mock_stage\",\n\t\t\t\tfunc(*Compiler) *Error { return NewError(CompileErr, &Location{}, \"mock stage error\") }},\n\t\t)\n\t\tm := MustParseModule(testModule)\n\t\tc.Compile(map[string]*Module{\"testMod\": m})\n\n\t\tif !c.Failed() {\n\t\t\tt.Errorf(\"Expected compilation error\")\n\t\t}\n\t})\n\n\tt.Run(\"first 'after' failure inhibits other 'after' stages\", func(t *testing.T) {\n\t\tc := NewCompiler().\n\t\t\tWithStageAfter(\"CheckRecursion\",\n\t\t\t\tCompilerStageDefinition{\"MockStage\", \"mock_stage\",\n\t\t\t\t\tfunc(*Compiler) *Error { return NewError(CompileErr, &Location{}, \"mock stage error\") }}).\n\t\t\tWithStageAfter(\"CheckRecursion\",\n\t\t\t\tCompilerStageDefinition{\"MockStage2\", \"mock_stage2\",\n\t\t\t\t\tfunc(*Compiler) *Error { return NewError(CompileErr, &Location{}, \"mock stage error two\") }},\n\t\t\t)\n\t\tm := MustParseModule(`package p\nq := true`)\n\n\t\tc.Compile(map[string]*Module{\"testMod\": m})\n\n\t\tif !c.Failed() {\n\t\t\tt.Errorf(\"Expected compilation error\")\n\t\t}\n\t\tif exp, act := 1, len(c.Errors); exp != act {\n\t\t\tt.Errorf(\"expected %d errors, got %d: %v\", exp, act, c.Errors)\n\t\t}\n\t})\n\n\tt.Run(\"'after' failure inhibits other ordinary stages\", func(t *testing.T) {\n\t\tc := NewCompiler().\n\t\t\tWithStageAfter(\"CheckRecursion\",\n\t\t\t\tCompilerStageDefinition{\"MockStage\", \"mock_stage\",\n\t\t\t\t\tfunc(*Compiler) *Error { return NewError(CompileErr, &Location{}, \"mock stage error\") }})\n\t\tm := MustParseModule(`package p\nq {\n\t1 == \"a\" # would fail \"CheckTypes\", the next stage\n}\n`)\n\t\tc.Compile(map[string]*Module{\"testMod\": m})\n\n\t\tif !c.Failed() {\n\t\t\tt.Errorf(\"Expected compilation error\")\n\t\t}\n\t\tif exp, act := 1, len(c.Errors); exp != act {\n\t\t\tt.Errorf(\"expected %d errors, got %d: %v\", exp, act, c.Errors)\n\t\t}\n\t})\n}\n\nfunc TestCompilerFunctions(t *testing.T) {\n\ttests := []struct {\n\t\tnote    string\n\t\tmodules []string\n\t\twantErr bool\n\t}{\n\t\t{\n\t\t\tnote: \"multiple input types\",\n\t\t\tmodules: []string{`package x\n\n\t\t\t\tf([x]) = y {\n\t\t\t\t\ty = x\n\t\t\t\t}\n\n\t\t\t\tf({\"foo\": x}) = y {\n\t\t\t\t\ty = x\n\t\t\t\t}`},\n\t\t},\n\t\t{\n\t\t\tnote: \"multiple input types\",\n\t\t\tmodules: []string{`package x\n\n\t\t\t\tf([x]) = y {\n\t\t\t\t\ty = x\n\t\t\t\t}\n\n\t\t\t\tf([[x]]) = y {\n\t\t\t\t\ty = x\n\t\t\t\t}`},\n\t\t},\n\t\t{\n\t\t\tnote: \"constant input\",\n\t\t\tmodules: []string{`package x\n\n\t\t\t\tf(1) = y {\n\t\t\t\t\ty = \"foo\"\n\t\t\t\t}\n\n\t\t\t\tf(2) = y {\n\t\t\t\t\ty = \"bar\"\n\t\t\t\t}`},\n\t\t},\n\t\t{\n\t\t\tnote: \"constant input\",\n\t\t\tmodules: []string{`package x\n\n\t\t\t\tf(1, x) = y {\n\t\t\t\t\ty = x\n\t\t\t\t}\n\n\t\t\t\tf(x, y) = z {\n\t\t\t\t\tz = x+y\n\t\t\t\t}`},\n\t\t},\n\t\t{\n\t\t\tnote: \"constant input\",\n\t\t\tmodules: []string{`package x\n\n\t\t\t\tf(x, 1) = y {\n\t\t\t\t\ty = x\n\t\t\t\t}\n\n\t\t\t\tf(x, [y]) = z {\n\t\t\t\t\tz = x+y\n\t\t\t\t}`},\n\t\t},\n\t\t{\n\t\t\tnote: \"multiple input types (nested)\",\n\t\t\tmodules: []string{`package x\n\n\t\t\t\tf({\"foo\": {\"bar\": x}}) = y {\n\t\t\t\t\ty = x\n\t\t\t\t}\n\n\t\t\t\tf({\"foo\": [x]}) = y {\n\t\t\t\t\ty = x\n\t\t\t\t}`},\n\t\t},\n\t\t{\n\t\t\tnote: \"multiple output types\",\n\t\t\tmodules: []string{`package x\n\n\t\t\t\tf(1) = y {\n\t\t\t\t\ty = \"foo\"\n\t\t\t\t}\n\n\t\t\t\tf(2) = y {\n\t\t\t\t\ty = 2\n\t\t\t\t}`},\n\t\t},\n\t\t{\n\t\t\tnote: \"namespacing\",\n\t\t\tmodules: []string{\n\t\t\t\t`package x\n\n\t\t\t\tf(x) = y {\n\t\t\t\t\tdata.y.f[x] = y\n\t\t\t\t}`,\n\t\t\t\t`package y\n\n\t\t\t\tf[x] = y {\n\t\t\t\t\ty = \"bar\"\n\t\t\t\t\tx = \"foo\"\n\t\t\t\t}`,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"implicit value\",\n\t\t\tmodules: []string{\n\t\t\t\t`package x\n\n\t\t\t\tf(x) {\n\t\t\t\t\tx = \"foo\"\n\t\t\t\t}`},\n\t\t},\n\t\t{\n\t\t\tnote: \"resolving\",\n\t\t\tmodules: []string{\n\t\t\t\t`package x\n\n\t\t\t\tf(x) = x { true }`,\n\n\t\t\t\t`package y\n\n\t\t\t\timport data.x\n\t\t\t\timport data.x.f as g\n\n\t\t\t\tp { g(1, a) }\n\t\t\t\tp { x.f(1, b) }\n\t\t\t\tp { data.x.f(1, c) }\n\t\t\t\t`,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"undefined\",\n\t\t\tmodules: []string{\n\t\t\t\t`package x\n\n\t\t\t\tp {\n\t\t\t\t\tf(1)\n\t\t\t\t}`,\n\t\t\t},\n\t\t\twantErr: true,\n\t\t},\n\t\t{\n\t\t\tnote: \"must apply\",\n\t\t\tmodules: []string{\n\t\t\t\t`package x\n\n\t\t\t\tf(1)\n\n\t\t\t\tp {\n\t\t\t\t\tf\n\t\t\t\t}\n\t\t\t\t`,\n\t\t\t},\n\t\t\twantErr: true,\n\t\t},\n\t\t{\n\t\t\tnote: \"must apply\",\n\t\t\tmodules: []string{\n\t\t\t\t`package x\n\t\t\t\tf(1)\n\t\t\t\tp { f.x }`,\n\t\t\t},\n\t\t\twantErr: true,\n\t\t},\n\t\t{\n\t\t\tnote: \"call argument ref output vars\",\n\t\t\tmodules: []string{\n\t\t\t\t`package x\n\n\t\t\t\tf(x)\n\n\t\t\t\tp { f(data.foo[i]) }`,\n\t\t\t},\n\t\t\twantErr: false,\n\t\t},\n\t}\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tvar err error\n\t\t\tmodules := map[string]*Module{}\n\t\t\tfor i, module := range tc.modules {\n\t\t\t\tname := fmt.Sprintf(\"mod%d\", i)\n\t\t\t\tmodules[name], err = ParseModule(name, module)\n\t\t\t\tif err != nil {\n\t\t\t\t\tpanic(err)\n\t\t\t\t}\n\t\t\t}\n\t\t\tc := NewCompiler()\n\t\t\tc.Compile(modules)\n\t\t\tif tc.wantErr && !c.Failed() {\n\t\t\t\tt.Errorf(\"Expected compilation error\")\n\t\t\t} else if !tc.wantErr && c.Failed() {\n\t\t\t\tt.Errorf(\"Unexpected compilation error(s): %v\", c.Errors)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerErrorLimit(t *testing.T) {\n\tmodules := map[string]*Module{\n\t\t\"test\": MustParseModule(`package test\n\tr = y { y = true; x = z }\n\n\ts[x] = y {\n\t\tz = y + x\n\t}\n\n\tt[x] { split(x, y, z) }\n\t`),\n\t}\n\n\tc := NewCompiler().SetErrorLimit(2)\n\tc.Compile(modules)\n\n\terrs := c.Errors\n\texp := []string{\n\t\t\"2:20: rego_unsafe_var_error: var x is unsafe\",\n\t\t\"2:20: rego_unsafe_var_error: var z is unsafe\",\n\t\t\"rego_compile_error: error limit reached\",\n\t}\n\n\tvar result []string\n\tfor _, err := range errs {\n\t\tresult = append(result, err.Error())\n\t}\n\n\tsort.Strings(exp)\n\tsort.Strings(result)\n\tif !reflect.DeepEqual(exp, result) {\n\t\tt.Errorf(\"Expected errors %v, got %v\", exp, result)\n\t}\n}\n\nfunc TestCompilerCheckSafetyHead(t *testing.T) {\n\tc := NewCompiler()\n\tc.Modules = getCompilerTestModules()\n\tc.Modules[\"newMod\"] = MustParseModule(`package a.b\n\nunboundKey[x] = y { q[y] = {\"foo\": [1, 2, [{\"bar\": y}]]} }\nunboundVal[y] = x { q[y] = {\"foo\": [1, 2, [{\"bar\": y}]]} }\nunboundCompositeVal[y] = [{\"foo\": x, \"bar\": y}] { q[y] = {\"foo\": [1, 2, [{\"bar\": y}]]} }\nunboundCompositeKey[[{\"x\": x}]] { q[y] }\nunboundBuiltinOperator = eq { x = 1 }\nunboundElse { false } else = else_var { true }\n`,\n\t)\n\tcompileStages(c, c.checkSafetyRuleHeads)\n\n\tmakeErrMsg := func(v string) string {\n\t\treturn fmt.Sprintf(\"rego_unsafe_var_error: var %v is unsafe\", v)\n\t}\n\n\texpected := []string{\n\t\tmakeErrMsg(\"x\"),\n\t\tmakeErrMsg(\"x\"),\n\t\tmakeErrMsg(\"x\"),\n\t\tmakeErrMsg(\"x\"),\n\t\tmakeErrMsg(\"eq\"),\n\t\tmakeErrMsg(\"else_var\"),\n\t}\n\n\tresult := compilerErrsToStringSlice(c.Errors)\n\tsort.Strings(expected)\n\n\tif len(result) != len(expected) {\n\t\tt.Fatalf(\"Expected %d:\\n%v\\nBut got %d:\\n%v\", len(expected), strings.Join(expected, \"\\n\"), len(result), strings.Join(result, \"\\n\"))\n\t}\n\n\tfor i := range result {\n\t\tif expected[i] != result[i] {\n\t\t\tt.Errorf(\"Expected %v but got: %v\", expected[i], result[i])\n\t\t}\n\t}\n\n}\n\nfunc TestCompilerCheckSafetyBodyReordering(t *testing.T) {\n\ttests := []struct {\n\t\tnote     string\n\t\tbody     string\n\t\texpected string\n\t}{\n\t\t{\"noop\", `x = 1; x != 0`, `x = 1; x != 0`},\n\t\t{\"var/ref\", `a[i] = x; a = [1, 2, 3, 4]`, `a = [1, 2, 3, 4]; a[i] = x`},\n\t\t{\"var/ref (nested)\", `a = [1, 2, 3, 4]; a[b[i]] = x; b = [0, 0, 0, 0]`, `a = [1, 2, 3, 4]; b = [0, 0, 0, 0]; a[b[i]] = x`},\n\t\t{\"negation\",\n\t\t\t`a = [true, false]; b = [true, false]; not a[i]; b[i]`,\n\t\t\t`a = [true, false]; b = [true, false]; b[i]; not a[i]`},\n\t\t{\"built-in\", `x != 0; count([1, 2, 3], x)`, `count([1, 2, 3], x); x != 0`},\n\t\t{\"var/var 1\", `x = y; z = 1; y = z`, `z = 1; y = z; x = y`},\n\t\t{\"var/var 2\", `x = y; 1 = z; z = y`, `1 = z; z = y; x = y`},\n\t\t{\"var/var 3\", `x != 0; y = x; y = 1`, `y = 1; y = x; x != 0`},\n\t\t{\"array compr/var\", `x != 0; [y | y = 1] = x`, `[y | y = 1] = x; x != 0`},\n\t\t{\"array compr/array\", `[1] != [x]; [y | y = 1] = [x]`, `[y | y = 1] = [x]; [1] != [x]`},\n\t\t{\"with\", `data.a.b.d.t with input as x; x = 1`, `x = 1; data.a.b.d.t with input as x`},\n\t\t{\"with-2\", `data.a.b.d.t with input.x as x; x = 1`, `x = 1; data.a.b.d.t with input.x as x`},\n\t\t{\"with-nop\", \"data.somedoc[x] with input as true\", \"data.somedoc[x] with input as true\"},\n\t\t{\"ref-head\", `s = [[\"foo\"], [\"bar\"]]; x = y[0]; y = s[_]; contains(x, \"oo\")`, `\n\t\ts = [[\"foo\"], [\"bar\"]];\n\t\ty = s[_];\n\t\tx = y[0];\n\t\tcontains(x, \"oo\")\n\t`},\n\t\t{\"userfunc\", `split(y, \".\", z); data.a.b.funcs.fn(\"...foo.bar..\", y)`, `data.a.b.funcs.fn(\"...foo.bar..\", y); split(y, \".\", z)`},\n\t\t{\"every\", `every _ in [] { x != 1 }; x = 1`, `__local4__ = []; x = 1; every __local3__, _ in __local4__ { x != 1}`},\n\t\t{\"every-domain\", `every _ in xs { true }; xs = [1]`, `xs = [1]; __local4__ = xs; every __local3__, _ in __local4__ { true }`},\n\t}\n\n\tfor i, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\topts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\t\t\tc := NewCompiler()\n\t\t\tc.Modules = getCompilerTestModules()\n\t\t\tc.Modules[\"reordering\"] = MustParseModuleWithOpts(fmt.Sprintf(\n\t\t\t\t`package test\n\t\t\t\tp { %s }`, tc.body), opts)\n\n\t\t\tcompileStages(c, c.checkSafetyRuleBodies)\n\n\t\t\tif c.Failed() {\n\t\t\t\tt.Errorf(\"%v (#%d): Unexpected compilation error: %v\", tc.note, i, c.Errors)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\texpected := MustParseBodyWithOpts(tc.expected, opts)\n\t\t\tresult := c.Modules[\"reordering\"].Rules[0].Body\n\n\t\t\tif !expected.Equal(result) {\n\t\t\t\tt.Errorf(\"%v (#%d): Expected body to be ordered and equal to %v but got: %v\", tc.note, i, expected, result)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerCheckSafetyBodyReorderingClosures(t *testing.T) {\n\topts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\n\ttests := []struct {\n\t\tnote string\n\t\tmod  *Module\n\t\texp  Body\n\t}{\n\t\t{\n\t\t\tnote: \"comprehensions-1\",\n\t\t\tmod: MustParseModule(`package compr\n\nimport data.b\nimport data.c\np = true { v = [null | true]; xs = [x | a[i] = x; a = [y | y != 1; y = c[j]]]; xs[j] > 0; z = [true | data.a.b.d.t with input as i2; i2 = i]; b[i] = j }\n`),\n\t\t\texp: MustParseBody(`v = [null | true]; data.b[i] = j; xs = [x | a = [y | y = data.c[j]; y != 1]; a[i] = x]; xs[j] > 0; z = [true | i2 = i; data.a.b.d.t with input as i2]`),\n\t\t},\n\t\t{\n\t\t\tnote: \"comprehensions-2\",\n\t\t\tmod: MustParseModule(`package compr\n\nimport data.b\nimport data.c\nq = true { _ = [x | x = b[i]]; _ = b[j]; _ = [x | x = true; x != false]; true != false; _ = [x | data.foo[_] = x]; data.foo[_] = _ }\n`),\n\t\t\texp: MustParseBody(`_ = [x | x = data.b[i]]; _ = data.b[j]; _ = [x | x = true; x != false]; true != false; _ = [x | data.foo[_] = x]; data.foo[_] = _`),\n\t\t},\n\n\t\t{\n\t\t\tnote: \"comprehensions-3\",\n\t\t\tmod: MustParseModule(`package compr\n\nimport data.b\nimport data.c\nfn(x) = y {\n\ttrim(x, \".\", y)\n}\nr = true { a = [x | split(y, \".\", z); x = z[i]; fn(\"...foo.bar..\", y)] }\n`),\n\t\t\texp: MustParseBody(`a = [x | data.compr.fn(\"...foo.bar..\", y); split(y, \".\", z); x = z[i]]`),\n\t\t},\n\t\t{\n\t\t\tnote: \"closure over function output\",\n\t\t\tmod: MustParseModule(`package test\nimport future.keywords\n\np {\n\tobject.get(input.subject.roles[_], comp, [\"\"], output)\n\tcomp = [ 1 | true ]\n\tevery y in [2] {\n\t\ty in output\n\t}\n}`),\n\t\t\texp: MustParseBodyWithOpts(`comp = [1 | true]\n\t\t\t\t__local2__ = [2]\n\t\t\t\tobject.get(input.subject.roles[_], comp, [\"\"], output)\n\t\t\t\tevery __local0__, __local1__ in __local2__ { internal.member_2(__local1__, output) }`, opts),\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tc := NewCompiler()\n\t\t\tc.Modules = map[string]*Module{\"mod\": tc.mod}\n\t\t\tcompileStages(c, c.checkSafetyRuleBodies)\n\t\t\tassertNotFailed(t, c)\n\t\t\tlast := len(c.Modules[\"mod\"].Rules) - 1\n\t\t\tactual := c.Modules[\"mod\"].Rules[last].Body\n\t\t\tif !actual.Equal(tc.exp) {\n\t\t\t\tt.Errorf(\"Expected reordered body to be equal to:\\n%v\\nBut got:\\n%v\", tc.exp, actual)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerCheckSafetyBodyErrors(t *testing.T) {\n\n\tmoduleBegin := `\n\t\tpackage a.b\n\n\t\timport input.aref.b.c as foo\n\t\timport input.avar as bar\n\t\timport data.m.n as baz\n\t`\n\n\ttests := []struct {\n\t\tnote          string\n\t\tmoduleContent string\n\t\texpected      string\n\t}{\n\t\t{\"ref-head\", `p { a.b.c = \"foo\" }`, `{a,}`},\n\t\t{\"ref-head-2\", `p { {\"foo\": [{\"bar\": a.b.c}]} = {\"foo\": [{\"bar\": \"baz\"}]} }`, `{a,}`},\n\t\t{\"negation\", `p { a = [1, 2, 3, 4]; not a[i] = x }`, `{i, x}`},\n\t\t{\"negation-head\", `p[x] { a = [1, 2, 3, 4]; not a[i] = x }`, `{i,x}`},\n\t\t{\"negation-multiple\", `p { a = [1, 2, 3, 4]; b = [1, 2, 3, 4]; not a[i] = x; not b[j] = x }`, `{i, x, j}`},\n\t\t{\"negation-nested\", `p { a = [{\"foo\": [\"bar\", \"baz\"]}]; not a[0].foo = [a[0].foo[i], a[0].foo[j]] } `, `{i, j}`},\n\t\t{\"builtin-input\", `p { count([1, 2, x], x) }`, `{x,}`},\n\t\t{\"builtin-input-name\", `p { count(eq, 1) }`, `{eq,}`},\n\t\t{\"builtin-multiple\", `p { x > 0; x <= 3; x != 2 }`, `{x,}`},\n\t\t{\"unordered-object-keys\", `p { x = \"a\"; [{x: y, z: a}] = [{\"a\": 1, \"b\": 2}]}`, `{a,y,z}`},\n\t\t{\"unordered-sets\", `p { x = \"a\"; [{x, y}] = [{1, 2}]}`, `{y,}`},\n\t\t{\"array-compr\", `p { _ = [x | x = data.a[_]; y > 1] }`, `{y,}`},\n\t\t{\"array-compr-nested\", `p { _ = [x | x = a[_]; a = [y | y = data.a[_]; z > 1]] }`, `{z,}`},\n\t\t{\"array-compr-closure\", `p { _ = [v | v = [x | x = data.a[_]]; x > 1] }`, `{x,}`},\n\t\t{\"array-compr-term\", `p { _ = [u | true] }`, `{u,}`},\n\t\t{\"array-compr-term-nested\", `p { _ = [v | v = [w | w != 0]] }`, `{w,}`},\n\t\t{\"array-compr-mixed\", `p { _ = [x | y = [a | a = z[i]]] }`, `{a, x, z, i}`},\n\t\t{\"array-compr-builtin\", `p { [true | eq != 2] }`, `{eq,}`},\n\t\t{\"closure-self\", `p { x = [x | x = 1] }`, `{x,}`},\n\t\t{\"closure-transitive\", `p { x = y; x = [y | y = 1] }`, `{x,y}`},\n\t\t{\"nested\", `p { count(baz[i].attr[bar[dead.beef]], n) }`, `{dead,}`},\n\t\t{\"negated-import\", `p { not foo; not bar; not baz }`, `set()`},\n\t\t{\"rewritten\", `p[{\"foo\": dead[i]}] { true }`, `{dead, i}`},\n\t\t{\"with-value\", `p { data.a.b.d.t with input as x }`, `{x,}`},\n\t\t{\"with-value-2\", `p { x = data.a.b.d.t with input as x }`, `{x,}`},\n\t\t{\"else-kw\", \"p { false } else { count(x, 1) }\", `{x,}`},\n\t\t{\"function\", \"foo(x) = [y, z] { split(x, y, z) }\", `{y,z}`},\n\t\t{\"call-vars-input\", \"p { f(x, x) } f(x) = x { true }\", `{x,}`},\n\t\t{\"call-no-output\", \"p { f(x) } f(x) = x { true }\", `{x,}`},\n\t\t{\"call-too-few\", \"p { f(1,x) } f(x,y) { true }\", \"{x,}\"},\n\t\t{\"object-key-comprehension\", \"p { { {p|x}: 0 } }\", \"{x,}\"},\n\t\t{\"set-value-comprehension\", \"p { {1, {p|x}} }\", \"{x,}\"},\n\t\t{\"every\", \"p { every y in [10] { x > y } }\", \"{x,}\"},\n\t}\n\n\tmakeErrMsg := func(varName string) string {\n\t\treturn fmt.Sprintf(\"rego_unsafe_var_error: var %v is unsafe\", varName)\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\n\t\t\t// Build slice of expected error messages.\n\t\t\texpected := []string{}\n\n\t\t\t_ = MustParseTerm(tc.expected).Value.(Set).Iter(func(x *Term) error {\n\t\t\t\texpected = append(expected, makeErrMsg(string(x.Value.(Var))))\n\t\t\t\treturn nil\n\t\t\t}) // cannot return error\n\n\t\t\tsort.Strings(expected)\n\n\t\t\t// Compile test module.\n\t\t\tpopts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\t\t\tc := NewCompiler()\n\t\t\tc.Modules = map[string]*Module{\n\t\t\t\t\"newMod\": MustParseModuleWithOpts(fmt.Sprintf(`\n\n\t\t\t\t%v\n\n\t\t\t\t%v\n\n\t\t\t\t`, moduleBegin, tc.moduleContent), popts),\n\t\t\t}\n\n\t\t\tcompileStages(c, c.checkSafetyRuleBodies)\n\n\t\t\t// Get errors.\n\t\t\tresult := compilerErrsToStringSlice(c.Errors)\n\n\t\t\t// Check against expected.\n\t\t\tif len(result) != len(expected) {\n\t\t\t\tt.Fatalf(\"Expected %d:\\n%v\\nBut got %d:\\n%v\", len(expected), strings.Join(expected, \"\\n\"), len(result), strings.Join(result, \"\\n\"))\n\t\t\t}\n\n\t\t\tfor i := range result {\n\t\t\t\tif expected[i] != result[i] {\n\t\t\t\t\tt.Errorf(\"Expected %v but got: %v\", expected[i], result[i])\n\t\t\t\t}\n\t\t\t}\n\n\t\t})\n\t}\n}\n\nfunc TestCompilerCheckSafetyVarLoc(t *testing.T) {\n\n\t_, err := CompileModules(map[string]string{\"test.rego\": `package test\n\np {\n\tnot x\n\tx > y\n}`})\n\n\tif err == nil {\n\t\tt.Fatal(\"expected error\")\n\t}\n\n\terrs := err.(Errors)\n\n\tif !strings.Contains(errs[0].Message, \"var x is unsafe\") || errs[0].Location.Row != 4 {\n\t\tt.Fatal(\"expected error on row 4 but got:\", err)\n\t}\n\n\tif !strings.Contains(errs[1].Message, \"var y is unsafe\") || errs[1].Location.Row != 5 {\n\t\tt.Fatal(\"expected y is unsafe on row 5 but got:\", err)\n\t}\n}\n\nfunc TestCompilerCheckTypes(t *testing.T) {\n\tc := NewCompiler()\n\tmodules := getCompilerTestModules()\n\tc.Modules = map[string]*Module{\"mod6\": modules[\"mod6\"], \"mod7\": modules[\"mod7\"]}\n\tcompileStages(c, c.checkTypes)\n\tassertNotFailed(t, c)\n}\n\nfunc TestCompilerCheckRuleConflicts(t *testing.T) {\n\n\tc := getCompilerWithParsedModules(map[string]string{\n\t\t\"mod1.rego\": `package badrules\n\np[x] { x = 1 }\np[x] = y { x = y; x = \"a\" }\nq[1] { true }\nq = {1, 2, 3} { true }\nr[x] = y { x = y; x = \"a\" }\nr[x] = y { x = y; x = \"a\" }`,\n\n\t\t\"mod2.rego\": `package badrules.r\n\nq[1] { true }`,\n\n\t\t\"mod3.rego\": `package badrules.defkw\n\ndefault foo = 1\ndefault foo = 2\nfoo = 3 { true }`,\n\t\t\"mod4.rego\": `package adrules.arity\n\nf(1) { true }\nf { true }\n\ng(1) { true }\ng(1,2) { true }`,\n\t\t\"mod5.rego\": `package badrules.dataoverlap\n\np { true }`,\n\t\t\"mod6.rego\": `package badrules.existserr\n\np { true }`})\n\n\tc.WithPathConflictsCheck(func(path []string) (bool, error) {\n\t\tif reflect.DeepEqual(path, []string{\"badrules\", \"dataoverlap\", \"p\"}) {\n\t\t\treturn true, nil\n\t\t} else if reflect.DeepEqual(path, []string{\"badrules\", \"existserr\", \"p\"}) {\n\t\t\treturn false, fmt.Errorf(\"unexpected error\")\n\t\t}\n\t\treturn false, nil\n\t})\n\n\tcompileStages(c, c.checkRuleConflicts)\n\n\texpected := []string{\n\t\t\"rego_compile_error: conflict check for data path badrules/existserr/p: unexpected error\",\n\t\t\"rego_compile_error: conflicting rule for data path badrules/dataoverlap/p found\",\n\t\t\"rego_type_error: conflicting rules named f found\",\n\t\t\"rego_type_error: conflicting rules named g found\",\n\t\t\"rego_type_error: conflicting rules named p found\",\n\t\t\"rego_type_error: conflicting rules named q found\",\n\t\t\"rego_type_error: multiple default rules named foo found\",\n\t\t\"rego_type_error: package badrules.r conflicts with rule defined at mod1.rego:7\",\n\t\t\"rego_type_error: package badrules.r conflicts with rule defined at mod1.rego:8\",\n\t}\n\n\tassertCompilerErrorStrings(t, c, expected)\n}\n\nfunc TestCompilerCheckUndefinedFuncs(t *testing.T) {\n\n\tmodule := `\n\t\tpackage test\n\n\t\tundefined_function {\n\t\t\tdata.deadbeef(x)\n\t\t}\n\n\t\tundefined_global {\n\t\t\tdeadbeef(x)\n\t\t}\n\n\t\t# NOTE: all the dynamic dispatch examples here are not supported,\n\t\t#       we're checking assertions about the error returned.\n\t\tundefined_dynamic_dispatch {\n\t\t\tx = \"f\"; data.test2[x](1)\n\t\t}\n\n\t\tundefined_dynamic_dispatch_declared_var {\n\t\t\ty := \"f\"; data.test2[y](1)\n\t\t}\n\n\t\tundefined_dynamic_dispatch_declared_var_in_array {\n\t\t\tz := \"f\"; data.test2[[z]](1)\n\t\t}\n\n\t\tarity_mismatch_1 {\n\t\t\tdata.test2.f(1,2,3)\n\t\t}\n\n\t\tarity_mismatch_2 {\n\t\t\tdata.test2.f()\n\t\t}\n\n\t\tarity_mismatch_3 {\n\t\t\tx:= data.test2.f()\n\t\t}\n\t`\n\n\tmodule2 := `\n\t\tpackage test2\n\n\t\tf(x) = x\n\t`\n\n\t_, err := CompileModules(map[string]string{\n\t\t\"test.rego\":  module,\n\t\t\"test2.rego\": module2,\n\t})\n\tif err == nil {\n\t\tt.Fatal(\"expected errors\")\n\t}\n\n\tresult := err.Error()\n\twant := []string{\n\t\t\"rego_type_error: undefined function data.deadbeef\",\n\t\t\"rego_type_error: undefined function deadbeef\",\n\t\t\"rego_type_error: undefined function data.test2[x]\",\n\t\t\"rego_type_error: undefined function data.test2[y]\",\n\t\t\"rego_type_error: undefined function data.test2[[z]]\",\n\t\t\"rego_type_error: function data.test2.f has arity 1, got 3 arguments\",\n\t\t\"test.rego:31: rego_type_error: function data.test2.f has arity 1, got 0 arguments\",\n\t\t\"test.rego:35: rego_type_error: function data.test2.f has arity 1, got 0 arguments\",\n\t}\n\tfor _, w := range want {\n\t\tif !strings.Contains(result, w) {\n\t\t\tt.Fatalf(\"Expected %q in result but got: %v\", w, result)\n\t\t}\n\t}\n}\n\nfunc TestCompilerQueryCompilerCheckUndefinedFuncs(t *testing.T) {\n\tcompiler := NewCompiler()\n\n\tfor _, tc := range []struct {\n\t\tnote, query, err string\n\t}{\n\n\t\t{note: \"undefined function\", query: `data.foo(1)`, err: \"undefined function data.foo\"},\n\t\t{note: \"undefined global function\", query: `foo(1)`, err: \"undefined function foo\"},\n\t\t{note: \"var\", query: `x = \"f\"; data[x](1)`, err: \"undefined function data[x]\"},\n\t\t{note: \"declared var\", query: `x := \"f\"; data[x](1)`, err: \"undefined function data[x]\"},\n\t\t{note: \"declared var in array\", query: `x := \"f\"; data[[x]](1)`, err: \"undefined function data[[x]]\"},\n\t} {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\t_, err := compiler.QueryCompiler().Compile(MustParseBody(tc.query))\n\t\t\tif !strings.Contains(err.Error(), tc.err) {\n\t\t\t\tt.Errorf(\"Unexpected compilation error: %v (want  %s)\", err, tc.err)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerImportsResolved(t *testing.T) {\n\n\tmodules := map[string]*Module{\n\t\t\"mod1\": MustParseModule(`package ex\n\nimport data\nimport input\nimport data.foo\nimport input.bar\nimport data.abc as baz\nimport input.abc as qux`,\n\t\t),\n\t}\n\n\tc := NewCompiler()\n\tc.Compile(modules)\n\n\tassertNotFailed(t, c)\n\n\tif len(c.Modules[\"mod1\"].Imports) != 0 {\n\t\tt.Fatalf(\"Expected imports to be empty after compile but got: %v\", c.Modules)\n\t}\n\n}\n\nfunc TestCompilerExprExpansion(t *testing.T) {\n\n\ttests := []struct {\n\t\tnote     string\n\t\tinput    string\n\t\texpected []*Expr\n\t}{\n\t\t{\n\t\t\tnote:  \"identity\",\n\t\t\tinput: \"x\",\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"x\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"single\",\n\t\t\tinput: \"x+y\",\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"x+y\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"chained\",\n\t\t\tinput: \"x+y+z+w\",\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"plus(x, y, __local0__)\"),\n\t\t\t\tMustParseExpr(\"plus(__local0__, z, __local1__)\"),\n\t\t\t\tMustParseExpr(\"plus(__local1__, w)\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"assoc\",\n\t\t\tinput: \"x+y*z\",\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"mul(y, z, __local0__)\"),\n\t\t\t\tMustParseExpr(\"plus(x, __local0__)\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"refs\",\n\t\t\tinput: \"p[q[f(x)]][g(x)]\",\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"f(x, __local0__)\"),\n\t\t\t\tMustParseExpr(\"g(x, __local1__)\"),\n\t\t\t\tMustParseExpr(\"p[q[__local0__]][__local1__]\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"arrays\",\n\t\t\tinput: \"[[f(x)], g(x)]\",\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"f(x, __local0__)\"),\n\t\t\t\tMustParseExpr(\"g(x, __local1__)\"),\n\t\t\t\tMustParseExpr(\"[[__local0__], __local1__]\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"objects\",\n\t\t\tinput: `{f(x): {g(x): h(x)}}`,\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"f(x, __local0__)\"),\n\t\t\t\tMustParseExpr(\"g(x, __local1__)\"),\n\t\t\t\tMustParseExpr(\"h(x, __local2__)\"),\n\t\t\t\tMustParseExpr(\"{__local0__: {__local1__: __local2__}}\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"sets\",\n\t\t\tinput: `{f(x), {g(x)}}`,\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"g(x, __local0__)\"),\n\t\t\t\tMustParseExpr(\"f(x, __local1__)\"),\n\t\t\t\tMustParseExpr(\"{__local1__, {__local0__,}}\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"unify\",\n\t\t\tinput: \"f(x) = g(x)\",\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"f(x, __local0__)\"),\n\t\t\t\tMustParseExpr(\"g(x, __local1__)\"),\n\t\t\t\tMustParseExpr(\"__local0__ = __local1__\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"unify: composites\",\n\t\t\tinput: \"[x, f(x)] = [g(y), y]\",\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"f(x, __local0__)\"),\n\t\t\t\tMustParseExpr(\"g(y, __local1__)\"),\n\t\t\t\tMustParseExpr(\"[x, __local0__] = [__local1__, y]\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"with: term expr\",\n\t\t\tinput: \"f[x+1] with input as q\",\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"plus(x, 1, __local0__) with input as q\"),\n\t\t\t\tMustParseExpr(\"f[__local0__] with input as q\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"with: call expr\",\n\t\t\tinput: `f(x) = g(x) with input as p`,\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"f(x, __local0__) with input as p\"),\n\t\t\t\tMustParseExpr(\"g(x, __local1__) with input as p\"),\n\t\t\t\tMustParseExpr(\"__local0__ = __local1__ with input as p\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"comprehensions\",\n\t\t\tinput: `f(y) = [[plus(x,1) | x = sum(y[z+1])], g(w)]`,\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"f(y, __local0__)\"),\n\t\t\t\tMustParseExpr(\"g(w, __local4__)\"),\n\t\t\t\tMustParseExpr(\"__local0__ = [[__local1__ | plus(z,1,__local2__); sum(y[__local2__], __local3__); eq(x, __local3__); plus(x, 1, __local1__)], __local4__]\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"indirect references\",\n\t\t\tinput: `[1, 2, 3][i]`,\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(\"__local0__ = [1, 2, 3]\"),\n\t\t\t\tMustParseExpr(\"__local0__[i]\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote:  \"multiple indirect references\",\n\t\t\tinput: `split(split(\"foo.bar:qux\", \".\")[_], \":\")[i]`,\n\t\t\texpected: []*Expr{\n\t\t\t\tMustParseExpr(`split(\"foo.bar:qux\", \".\", __local0__)`),\n\t\t\t\tMustParseExpr(`split(__local0__[_], \":\", __local1__)`),\n\t\t\t\tMustParseExpr(`__local1__[i]`),\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tgen := newLocalVarGenerator(\"\", NullTerm())\n\t\t\texpr := MustParseExpr(tc.input)\n\t\t\tresult := expandExpr(gen, expr.Copy())\n\t\t\tif len(result) != len(tc.expected) {\n\t\t\t\tt.Fatalf(\"Expected %v exprs but got %v:\\n\\nExpected:\\n\\n%v\\n\\nGot:\\n\\n%v\", len(tc.expected), len(result), Body(tc.expected), Body(result))\n\t\t\t}\n\t\t\tfor i := range tc.expected {\n\t\t\t\tif !tc.expected[i].Equal(result[i]) {\n\t\t\t\t\tt.Fatalf(\"Expected expr %d to be %v but got: %v\\n\\nExpected:\\n\\n%v\\n\\nGot:\\n\\n%v\", i, tc.expected[i], result[i], Body(tc.expected), Body(result))\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerRewriteExprTerms(t *testing.T) {\n\tcases := []struct {\n\t\tnote     string\n\t\tmodule   string\n\t\texpected interface{}\n\t}{\n\t\t{\n\t\t\tnote: \"base\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp { x = a + b * y }\n\n\t\t\t\tq[[data.test.f(x)]] { x = 1 }\n\n\t\t\t\tr = [data.test.f(x)] { x = 1 }\n\n\t\t\t\tf(x) = data.test.g(x)\n\n\t\t\t\tpi = 3 + .14\n\n\t\t\t\twith_value { 1 with input as f(1) }\n\t\t\t`,\n\t\t\texpected: `\n\t\t\t\tpackage test\n\n\t\t\t\tp { mul(b, y, __local1__); plus(a, __local1__, __local2__); eq(x, __local2__) }\n\n\t\t\t\tq[[__local3__]] { x = 1; data.test.f(x, __local3__) }\n\n\t\t\t\tr = [__local4__] { x = 1; data.test.f(x, __local4__) }\n\n\t\t\t\tf(__local0__) = __local5__ { true; data.test.g(__local0__, __local5__) }\n\n\t\t\t\tpi = __local6__ { true; plus(3, 0.14, __local6__) }\n\n\t\t\t\twith_value { data.test.f(1, __local7__); 1 with input as __local7__ }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"builtin calls in head\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tf(1+1) = 7\n\t\t\t`,\n\t\t\texpected: Errors{&Error{Message: \"rule arguments cannot contain calls\"}},\n\t\t},\n\t\t{\n\t\t\tnote: \"builtin calls in head\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tf(object.get(x)) { object := {\"a\": 1}; object.a == x }\n\t\t\t`,\n\t\t\texpected: Errors{&Error{Message: \"rule arguments cannot contain calls\"}},\n\t\t},\n\t\t{\n\t\t\tnote: \"indirect ref in args\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tf([1][0]) { true }`,\n\t\t\texpected: `\n\t\t\t\tpackage test\n\n\t\t\t\tf(__local0__[0]) { true; __local0__ = [1] }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"every: domain\",\n\t\t\tmodule: `\n\t\t\tpackage test\n\n\t\t\tp { every x in [1,2] { x } }`,\n\t\t\texpected: `\n\t\t\tpackage test\n\n\t\t\tp { __local2__ = [1, 2]; every __local0__, __local1__ in __local2__ { __local1__ } }`,\n\t\t},\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tcompiler := NewCompiler()\n\t\t\topts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\n\t\t\tcompiler.Modules = map[string]*Module{\n\t\t\t\t\"test\": MustParseModuleWithOpts(tc.module, opts),\n\t\t\t}\n\t\t\tcompileStages(compiler, compiler.rewriteExprTerms)\n\n\t\t\tswitch exp := tc.expected.(type) {\n\t\t\tcase string:\n\t\t\t\tassertNotFailed(t, compiler)\n\n\t\t\t\texpected := MustParseModuleWithOpts(exp, opts)\n\n\t\t\t\tif !expected.Equal(compiler.Modules[\"test\"]) {\n\t\t\t\t\tt.Fatalf(\"Expected modules to be equal. Expected:\\n\\n%v\\n\\nGot:\\n\\n%v\", expected, compiler.Modules[\"test\"])\n\t\t\t\t}\n\t\t\tcase Errors:\n\t\t\t\tassertErrors(t, compiler.Errors, exp, false)\n\t\t\tdefault:\n\t\t\t\tt.Fatalf(\"Unsupported value type for test case 'expected' field: %v\", exp)\n\t\t\t}\n\n\t\t})\n\t}\n}\n\nfunc TestIllegalFunctionCallRewrite(t *testing.T) {\n\tcases := []struct {\n\t\tnote           string\n\t\tmodule         string\n\t\texpectedErrors []string\n\t}{\n\t\t/*{\n\t\t\t\t\tnote: \"function call override in function value\",\n\t\t\t\t\tmodule: `package test\n\t\tfoo(x) := x\n\n\t\tp := foo(bar) {\n\t\t\t#foo := 1\n\t\t\tbar := 2\n\t\t}`,\n\t\t\t\t\texpectedErrors: []string{\n\t\t\t\t\t\t\"undefined function foo\",\n\t\t\t\t\t},\n\t\t\t\t},*/\n\t\t{\n\t\t\tnote: \"function call override in array comprehension value\",\n\t\t\tmodule: `package test\np := [foo(bar) | foo := 1; bar := 2]`,\n\t\t\texpectedErrors: []string{\n\t\t\t\t\"called function foo shadowed\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"function call override in set comprehension value\",\n\t\t\tmodule: `package test\np := {foo(bar) | foo := 1; bar := 2}`,\n\t\t\texpectedErrors: []string{\n\t\t\t\t\"called function foo shadowed\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"function call override in object comprehension value\",\n\t\t\tmodule: `package test\np := {foo(bar): bar(foo) | foo := 1; bar := 2}`,\n\t\t\texpectedErrors: []string{\n\t\t\t\t\"called function bar shadowed\",\n\t\t\t\t\"called function foo shadowed\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"function call override in array comprehension value\",\n\t\t\tmodule: `package test\np := [foo.bar(baz) | foo := 1; bar := 2; baz := 3]`,\n\t\t\texpectedErrors: []string{\n\t\t\t\t\"called function foo.bar shadowed\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"nested function call override in array comprehension value\",\n\t\t\tmodule: `package test\np := [baz(foo(bar)) | foo := 1; bar := 2]`,\n\t\t\texpectedErrors: []string{\n\t\t\t\t\"called function foo shadowed\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"function call override of 'input' root document\",\n\t\t\tmodule: `package test\np := [input() | input := 1]`,\n\t\t\texpectedErrors: []string{\n\t\t\t\t\"called function input shadowed\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"function call override of 'data' root document\",\n\t\t\tmodule: `package test\np := [data() | data := 1]`,\n\t\t\texpectedErrors: []string{\n\t\t\t\t\"called function data shadowed\",\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tcompiler := NewCompiler()\n\t\t\topts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\n\t\t\tcompiler.Modules = map[string]*Module{\n\t\t\t\t\"test\": MustParseModuleWithOpts(tc.module, opts),\n\t\t\t}\n\t\t\tcompileStages(compiler, compiler.rewriteLocalVars)\n\n\t\t\tresult := make([]string, 0, len(compiler.Errors))\n\t\t\tfor i := range compiler.Errors {\n\t\t\t\tresult = append(result, compiler.Errors[i].Message)\n\t\t\t}\n\n\t\t\tsort.Strings(tc.expectedErrors)\n\t\t\tsort.Strings(result)\n\n\t\t\tif len(tc.expectedErrors) != len(result) {\n\t\t\t\tt.Fatalf(\"Expected %d errors but got %d:\\n\\n%v\\n\\nGot:\\n\\n%v\",\n\t\t\t\t\tlen(tc.expectedErrors), len(result),\n\t\t\t\t\tstrings.Join(tc.expectedErrors, \"\\n\"), strings.Join(result, \"\\n\"))\n\t\t\t}\n\n\t\t\tfor i := range result {\n\t\t\t\tif result[i] != tc.expectedErrors[i] {\n\t\t\t\t\tt.Fatalf(\"Expected:\\n\\n%v\\n\\nGot:\\n\\n%v\",\n\t\t\t\t\t\tstrings.Join(tc.expectedErrors, \"\\n\"), strings.Join(result, \"\\n\"))\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerCheckUnusedImports(t *testing.T) {\n\tcases := []strictnessTestCase{\n\t\t{\n\t\t\tnote: \"simple unused: input ref with same name\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo.bar as bar\n\t\t\tr {\n\t\t\t\tinput.bar == 11\n\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 2, 4),\n\t\t\t\t\tMessage:  \"import data.foo.bar as bar unused\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"unused import, but imported ref used\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo # unused\n\t\t\tr { data.foo == 10 }\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 2, 4),\n\t\t\t\t\tMessage:  \"import data.foo unused\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"one of two unused\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo\n\t\t\timport data.x.power #unused\n\t\t\tr { foo == 10 }\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 3, 4),\n\t\t\t\t\tMessage:  \"import data.x.power unused\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"multiple unused: with input ref of same name\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo\n\t\t\timport data.x.power\n\t\t\tr { input.foo == 10 }\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 2, 4),\n\t\t\t\t\tMessage:  \"import data.foo unused\",\n\t\t\t\t},\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 3, 4),\n\t\t\t\t\tMessage:  \"import data.x.power unused\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"import used in comparison\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo.x\n\t\t\tr { x == 10 }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"multiple used imports in one rule\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo.x\n\t\t\timport data.power.ranger\n\t\t\tr { ranger == x }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"multiple used imports in separate rules\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo.x\n\t\t\timport data.power.ranger\n\t\t\tr { ranger == 23 }\n\t\t\tt { x == 1 }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"import used as function operand\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo\n\t\t\tr = count(foo) > 1 # only one operand\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"import used as function operand, compount term\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo\n\t\t\tr = sprintf(\"%v %d\", [foo, 0])\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"import used as plain term\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo\n\t\t\tr {\n\t\t\t\tfoo\n\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"import used in 'every' domain\",\n\t\t\tmodule: `package p\n\t\t\timport future.keywords.every\n\t\t\timport data.foo\n\t\t\tr {\n\t\t\t\tevery x in foo { x > 1 }\n\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"import used in 'every' body\",\n\t\t\tmodule: `package p\n\t\t\timport future.keywords.every\n\t\t\timport data.foo\n\t\t\tr {\n\t\t\t\tevery x in [1,2,3] { x > foo }\n\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"future import kept even if unused\",\n\t\t\tmodule: `package p\n\t\t\timport future.keywords\n\n\t\t\tr { true }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"shadowed var name in function arg\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo # unused\n\n\t\t\tr { f(1) }\n\t\t\tf(foo) = foo == 1\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 2, 4),\n\t\t\t\t\tMessage:  \"import data.foo unused\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"shadowed assigned var name\",\n\t\t\tmodule: `package p\n\t\t\timport data.foo # unused\n\n\t\t\tr { foo := true; foo }\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 2, 4),\n\t\t\t\t\tMessage:  \"import data.foo unused\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"used as rule value\",\n\t\t\tmodule: `package p\n\t\t\timport data.bar # unused\n\t\t\timport data.foo\n\n\t\t\tr = foo { true }\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 2, 4),\n\t\t\t\t\tMessage:  \"import data.bar unused\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"unused as rule value (but same data ref)\",\n\t\t\tmodule: `package p\n\t\t\timport data.bar # unused\n\t\t\timport data.foo # unused\n\n\t\t\tr = data.foo { true }\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 2, 4),\n\t\t\t\t\tMessage:  \"import data.bar unused\",\n\t\t\t\t},\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 3, 4),\n\t\t\t\t\tMessage:  \"import data.foo unused\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\trunStrictnessTestCase(t, cases, true)\n}\n\nfunc TestCompilerCheckDuplicateImports(t *testing.T) {\n\tcases := []strictnessTestCase{\n\t\t{\n\t\t\tnote: \"shadow\",\n\t\t\tmodule: `package test\n\t\t\t\timport input.noconflict\n\t\t\t\timport input.foo\n\t\t\t\timport data.foo\n\t\t\t\timport data.bar.foo\n\n\t\t\t\tp := noconflict\n\t\t\t\tq := foo\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 4, 5),\n\t\t\t\t\tMessage:  \"import must not shadow import input.foo\",\n\t\t\t\t},\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 5, 5),\n\t\t\t\t\tMessage:  \"import must not shadow import input.foo\",\n\t\t\t\t},\n\t\t\t},\n\t\t}, {\n\t\t\tnote: \"alias shadow\",\n\t\t\tmodule: `package test\n\t\t\t\timport input.noconflict\n\t\t\t\timport input.foo\n\t\t\t\timport input.bar as foo\n\n\t\t\t\tp := noconflict\n\t\t\t\tq := foo\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"import\"), \"\", 4, 5),\n\t\t\t\t\tMessage:  \"import must not shadow import input.foo\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\trunStrictnessTestCase(t, cases, true)\n}\n\nfunc TestCompilerCheckKeywordOverrides(t *testing.T) {\n\tcases := []strictnessTestCase{\n\t\t{\n\t\t\tnote: \"rule names\",\n\t\t\tmodule: `package test\n\t\t\t\tinput { true }\n\t\t\t\tp { true }\n\t\t\t\tdata { true }\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"input { true }\"), \"\", 2, 5),\n\t\t\t\t\tMessage:  \"rules must not shadow input (use a different rule name)\",\n\t\t\t\t},\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"data { true }\"), \"\", 4, 5),\n\t\t\t\t\tMessage:  \"rules must not shadow data (use a different rule name)\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"global assignments\",\n\t\t\tmodule: `package test\n\t\t\t\tinput = 1\n\t\t\t\tp := 2\n\t\t\t\tdata := 3\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"input = 1\"), \"\", 2, 5),\n\t\t\t\t\tMessage:  \"rules must not shadow input (use a different rule name)\",\n\t\t\t\t},\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"data := 3\"), \"\", 4, 5),\n\t\t\t\t\tMessage:  \"rules must not shadow data (use a different rule name)\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule-local assignments\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tinput := 1\n\t\t\t\t\tx := 2\n\t\t\t\t} else {\n\t\t\t\t\tdata := 3\n\t\t\t\t}\n\t\t\t\tq {\n\t\t\t\t\tinput := 4\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"input := 1\"), \"\", 3, 6),\n\t\t\t\t\tMessage:  \"variables must not shadow input (use a different variable name)\",\n\t\t\t\t},\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"data := 3\"), \"\", 6, 6),\n\t\t\t\t\tMessage:  \"variables must not shadow data (use a different variable name)\",\n\t\t\t\t},\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"input := 4\"), \"\", 9, 6),\n\t\t\t\t\tMessage:  \"variables must not shadow input (use a different variable name)\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"array comprehension-local assignments\",\n\t\t\tmodule: `package test\n\t\t\t\tp = [ x |\n\t\t\t\t\tinput := 1\n\t\t\t\t\tx := 2\n\t\t\t\t\tdata := 3\n\t\t\t\t]\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"input := 1\"), \"\", 3, 6),\n\t\t\t\t\tMessage:  \"variables must not shadow input (use a different variable name)\",\n\t\t\t\t},\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"data := 3\"), \"\", 5, 6),\n\t\t\t\t\tMessage:  \"variables must not shadow data (use a different variable name)\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"set comprehension-local assignments\",\n\t\t\tmodule: `package test\n\t\t\t\tp = { x |\n\t\t\t\t\tinput := 1\n\t\t\t\t\tx := 2\n\t\t\t\t\tdata := 3\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"input := 1\"), \"\", 3, 6),\n\t\t\t\t\tMessage:  \"variables must not shadow input (use a different variable name)\",\n\t\t\t\t},\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"data := 3\"), \"\", 5, 6),\n\t\t\t\t\tMessage:  \"variables must not shadow data (use a different variable name)\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"object comprehension-local assignments\",\n\t\t\tmodule: `package test\n\t\t\t\tp = { x: 1 |\n\t\t\t\t\tinput := 1\n\t\t\t\t\tx := 2\n\t\t\t\t\tdata := 3\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"input := 1\"), \"\", 3, 6),\n\t\t\t\t\tMessage:  \"variables must not shadow input (use a different variable name)\",\n\t\t\t\t},\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"data := 3\"), \"\", 5, 6),\n\t\t\t\t\tMessage:  \"variables must not shadow data (use a different variable name)\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"nested override\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\t[ x |\n\t\t\t\t\t\tinput := 1\n\t\t\t\t\t\tx := 2\n\t\t\t\t\t\tdata := 3\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"input := 1\"), \"\", 4, 7),\n\t\t\t\t\tMessage:  \"variables must not shadow input (use a different variable name)\",\n\t\t\t\t},\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"data := 3\"), \"\", 6, 7),\n\t\t\t\t\tMessage:  \"variables must not shadow data (use a different variable name)\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\trunStrictnessTestCase(t, cases, true)\n}\n\nfunc TestCompilerCheckDeprecatedMethods(t *testing.T) {\n\tcases := []strictnessTestCase{\n\t\t{\n\t\t\tnote: \"all() built-in\",\n\t\t\tmodule: `package test\n\t\t\t\tp := all([true, false])\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"all([true, false])\"), \"\", 2, 10),\n\t\t\t\t\tMessage:  \"deprecated built-in function calls in expression: all\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"user-defined all()\",\n\t\t\tmodule: `package test\n\t\t\t\timport future.keywords.in\n\t\t\t\tall(arr) = {x | some x in arr} == {true}\n\t\t\t\tp := all([true, false])\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"any() built-in\",\n\t\t\tmodule: `package test\n\t\t\t\tp := any([true, false])\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(\"any([true, false])\"), \"\", 2, 10),\n\t\t\t\t\tMessage:  \"deprecated built-in function calls in expression: any\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"user-defined any()\",\n\t\t\tmodule: `package test\n\t\t\t\timport future.keywords.in\n\t\t\t\tany(arr) := true in arr\n\t\t\t\tp := any([true, false])\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"re_match built-in\",\n\t\t\tmodule: `package test\n\t\t\t\tp := re_match(\"[a]\", \"a\")\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{\n\t\t\t\t\tLocation: NewLocation([]byte(`re_match(\"[a]\", \"a\")`), \"\", 2, 10),\n\t\t\t\t\tMessage:  \"deprecated built-in function calls in expression: re_match\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\trunStrictnessTestCase(t, cases, true)\n}\n\ntype strictnessTestCase struct {\n\tnote           string\n\tmodule         string\n\texpectedErrors Errors\n}\n\nfunc runStrictnessTestCase(t *testing.T, cases []strictnessTestCase, assertLocation bool) {\n\tt.Helper()\n\tmakeTestRunner := func(tc strictnessTestCase, strict bool) func(t *testing.T) {\n\t\treturn func(t *testing.T) {\n\t\t\tcompiler := NewCompiler().WithStrict(strict)\n\t\t\tcompiler.Modules = map[string]*Module{\n\t\t\t\t\"test\": MustParseModule(tc.module),\n\t\t\t}\n\t\t\tcompileStages(compiler, nil)\n\n\t\t\tif strict {\n\t\t\t\tassertErrors(t, compiler.Errors, tc.expectedErrors, assertLocation)\n\t\t\t} else {\n\t\t\t\tassertNotFailed(t, compiler)\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.note+\"_strict\", makeTestRunner(tc, true))\n\t\tt.Run(tc.note+\"_non-strict\", makeTestRunner(tc, false))\n\t}\n}\n\nfunc assertErrors(t *testing.T, actual Errors, expected Errors, assertLocation bool) {\n\tt.Helper()\n\tif len(expected) != len(actual) {\n\t\tt.Fatalf(\"Expected %d errors, got %d:\\n\\n%s\\n\", len(expected), len(actual), actual.Error())\n\t}\n\tincorrectErrs := false\n\tfor _, e := range expected {\n\t\tfound := false\n\t\tfor _, actual := range actual {\n\t\t\tif e.Message == actual.Message {\n\t\t\t\tif !assertLocation || e.Location.Equal(actual.Location) {\n\t\t\t\t\tfound = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif !found {\n\t\t\tincorrectErrs = true\n\t\t}\n\t}\n\tif incorrectErrs {\n\t\tt.Fatalf(\"Expected errors:\\n\\n%s\\n\\nGot:\\n\\n%s\\n\", expected.Error(), actual.Error())\n\t}\n}\n\nfunc TestCompilerResolveAllRefs(t *testing.T) {\n\tc := NewCompiler()\n\tc.Modules = getCompilerTestModules()\n\tc.Modules[\"head\"] = MustParseModule(`package head\n\nimport data.doc1 as bar\nimport input.x.y.foo\nimport input.qux as baz\n\np[foo[bar[i]]] = {\"baz\": baz} { true }`)\n\n\tc.Modules[\"elsekw\"] = MustParseModule(`package elsekw\n\n\timport input.x.y.foo\n\timport data.doc1 as bar\n\timport input.baz\n\n\tp {\n\t\tfalse\n\t} else = foo {\n\t\tbar\n\t} else = baz {\n\t\ttrue\n\t}\n\t`)\n\n\tc.Modules[\"nestedexprs\"] = MustParseModule(`package nestedexprs\n\n\t\tx = 1\n\n\t\tp {\n\t\t\tf(g(x))\n\t\t}`)\n\n\tc.Modules[\"assign\"] = MustParseModule(`package assign\n\n\t\tx = 1\n\t\ty = 1\n\n\t\tp {\n\t\t\tx := y\n\t\t\t[true | x := y]\n\t\t}`)\n\n\tc.Modules[\"someinassign\"] = MustParseModule(`package someinassign\n\t\timport future.keywords.in\n\t\tx = 1\n\t\ty = 1\n\n\t\tp[x] {\n\t\t\tsome x in [1, 2, y]\n\t\t}`)\n\n\tc.Modules[\"someinassignwithkey\"] = MustParseModule(`package someinassignwithkey\n\t\timport future.keywords.in\n\t\tx = 1\n\t\ty = 1\n\n\t\tp[x] {\n\t\t\tsome k, v in [1, 2, y]\n\t\t}`)\n\n\tc.Modules[\"donotresolve\"] = MustParseModule(`package donotresolve\n\n\t\tx = 1\n\n\t\tf(x) {\n\t\t\tx = 2\n\t\t}\n\t\t`)\n\n\tc.Modules[\"indirectrefs\"] = MustParseModule(`package indirectrefs\n\n\t\tf(x) = [x] {true}\n\n\t\tp {\n\t\t\tf(1)[0]\n\t\t}\n\t\t`)\n\n\tc.Modules[\"comprehensions\"] = MustParseModule(`package comprehensions\n\n\t\tnums = [1, 2, 3]\n\n\t\tf(x) = [x] {true}\n\n\t\tp[[1]] {true}\n\n\t\tq {\n\t\t\tp[[x | x = nums[_]]]\n\t\t}\n\n\t\tr = [y | y = f(1)[0]]\n\t\t`)\n\n\tc.Modules[\"everykw\"] = MustParseModuleWithOpts(`package everykw\n\n\tnums = {1, 2, 3}\n\tf(_) = true\n\tx = 100\n\txs = [1, 2, 3]\n\tp {\n\t\tevery x in xs {\n\t\t\tnums[x]\n\t\t\tx > 10\n\t\t}\n\t}`, ParserOptions{unreleasedKeywords: true, FutureKeywords: []string{\"every\", \"in\"}})\n\n\tcompileStages(c, c.resolveAllRefs)\n\tassertNotFailed(t, c)\n\n\t// Basic test cases.\n\tmod1 := c.Modules[\"mod1\"]\n\tp := mod1.Rules[0]\n\texpr1 := p.Body[0]\n\tterm := expr1.Terms.(*Term)\n\te := MustParseTerm(\"data.a.b.c.q[x]\")\n\tif !term.Equal(e) {\n\t\tt.Errorf(\"Wrong term (global in same module): expected %v but got: %v\", e, term)\n\t}\n\n\texpr2 := p.Body[1]\n\tterm = expr2.Terms.(*Term)\n\te = MustParseTerm(\"data.a.b.c.r[x]\")\n\tif !term.Equal(e) {\n\t\tt.Errorf(\"Wrong term (global in same package/diff module): expected %v but got: %v\", e, term)\n\t}\n\n\tmod2 := c.Modules[\"mod2\"]\n\tr := mod2.Rules[0]\n\texpr3 := r.Body[1]\n\tterm = expr3.Terms.([]*Term)[1]\n\te = MustParseTerm(\"data.x.y.p\")\n\tif !term.Equal(e) {\n\t\tt.Errorf(\"Wrong term (var import): expected %v but got: %v\", e, term)\n\t}\n\n\tmod3 := c.Modules[\"mod3\"]\n\texpr4 := mod3.Rules[0].Body[0]\n\tterm = expr4.Terms.([]*Term)[2]\n\te = MustParseTerm(\"{input.x.secret: [{input.x.keyid}]}\")\n\tif !term.Equal(e) {\n\t\tt.Errorf(\"Wrong term (nested refs): expected %v but got: %v\", e, term)\n\t}\n\n\t// Array comprehensions.\n\tmod5 := c.Modules[\"mod5\"]\n\n\tac := func(r *Rule) *ArrayComprehension {\n\t\treturn r.Body[0].Terms.(*Term).Value.(*ArrayComprehension)\n\t}\n\n\tacTerm1 := ac(mod5.Rules[0])\n\tassertTermEqual(t, acTerm1.Term, MustParseTerm(\"input.x.a\"))\n\tacTerm2 := ac(mod5.Rules[1])\n\tassertTermEqual(t, acTerm2.Term, MustParseTerm(\"data.a.b.c.q.a\"))\n\tacTerm3 := ac(mod5.Rules[2])\n\tassertTermEqual(t, acTerm3.Body[0].Terms.([]*Term)[1], MustParseTerm(\"input.x.a\"))\n\tacTerm4 := ac(mod5.Rules[3])\n\tassertTermEqual(t, acTerm4.Body[0].Terms.([]*Term)[1], MustParseTerm(\"data.a.b.c.q[i]\"))\n\tacTerm5 := ac(mod5.Rules[4])\n\tassertTermEqual(t, acTerm5.Body[0].Terms.([]*Term)[2].Value.(*ArrayComprehension).Term, MustParseTerm(\"input.x.a\"))\n\tacTerm6 := ac(mod5.Rules[5])\n\tassertTermEqual(t, acTerm6.Body[0].Terms.([]*Term)[2].Value.(*ArrayComprehension).Body[0].Terms.([]*Term)[1], MustParseTerm(\"data.a.b.c.q[i]\"))\n\n\t// Nested references.\n\tmod6 := c.Modules[\"mod6\"]\n\tnested1 := mod6.Rules[0].Body[0].Terms.(*Term)\n\tassertTermEqual(t, nested1, MustParseTerm(\"data.x[input.x[i].a[data.z.b[j]]]\"))\n\n\tnested2 := mod6.Rules[1].Body[1].Terms.(*Term)\n\tassertTermEqual(t, nested2, MustParseTerm(\"v[input.x[i]]\"))\n\n\tnested3 := mod6.Rules[3].Body[0].Terms.(*Term)\n\tassertTermEqual(t, nested3, MustParseTerm(\"data.x[data.a.b.nested.r]\"))\n\n\t// Refs in head.\n\tmod7 := c.Modules[\"head\"]\n\tassertTermEqual(t, mod7.Rules[0].Head.Key, MustParseTerm(\"input.x.y.foo[data.doc1[i]]\"))\n\tassertTermEqual(t, mod7.Rules[0].Head.Value, MustParseTerm(`{\"baz\": input.qux}`))\n\n\t// Refs in else.\n\tmod8 := c.Modules[\"elsekw\"]\n\tassertTermEqual(t, mod8.Rules[0].Else.Head.Value, MustParseTerm(\"input.x.y.foo\"))\n\tassertTermEqual(t, mod8.Rules[0].Else.Body[0].Terms.(*Term), MustParseTerm(\"data.doc1\"))\n\tassertTermEqual(t, mod8.Rules[0].Else.Else.Head.Value, MustParseTerm(\"input.baz\"))\n\n\t// Refs in calls.\n\tmod9 := c.Modules[\"nestedexprs\"]\n\tassertTermEqual(t, mod9.Rules[1].Body[0].Terms.([]*Term)[1], CallTerm(RefTerm(VarTerm(\"g\")), MustParseTerm(\"data.nestedexprs.x\")))\n\n\t// Ignore assigned vars.\n\tmod10 := c.Modules[\"assign\"]\n\tassertTermEqual(t, mod10.Rules[2].Body[0].Terms.([]*Term)[1], VarTerm(\"x\"))\n\tassertTermEqual(t, mod10.Rules[2].Body[0].Terms.([]*Term)[2], MustParseTerm(\"data.assign.y\"))\n\tassignCompr := mod10.Rules[2].Body[1].Terms.(*Term).Value.(*ArrayComprehension)\n\tassertTermEqual(t, assignCompr.Body[0].Terms.([]*Term)[1], VarTerm(\"x\"))\n\tassertTermEqual(t, assignCompr.Body[0].Terms.([]*Term)[2], MustParseTerm(\"data.assign.y\"))\n\n\t// Args\n\tmod11 := c.Modules[\"donotresolve\"]\n\tassertTermEqual(t, mod11.Rules[1].Head.Args[0], VarTerm(\"x\"))\n\tassertExprEqual(t, mod11.Rules[1].Body[0], MustParseExpr(\"x = 2\"))\n\n\t// Locations.\n\tparsedLoc := getCompilerTestModules()[\"mod1\"].Rules[0].Body[0].Terms.(*Term).Value.(Ref)[0].Location\n\tcompiledLoc := c.Modules[\"mod1\"].Rules[0].Body[0].Terms.(*Term).Value.(Ref)[0].Location\n\tif parsedLoc.Row != compiledLoc.Row {\n\t\tt.Fatalf(\"Expected parsed location (%v) and compiled location (%v) to be equal\", parsedLoc.Row, compiledLoc.Row)\n\t}\n\n\t// Indirect references.\n\tmod12 := c.Modules[\"indirectrefs\"]\n\tassertExprEqual(t, mod12.Rules[1].Body[0], MustParseExpr(\"data.indirectrefs.f(1)[0]\"))\n\n\t// Comprehensions\n\tmod13 := c.Modules[\"comprehensions\"]\n\tassertExprEqual(t, mod13.Rules[3].Body[0].Terms.(*Term).Value.(Ref)[3].Value.(*ArrayComprehension).Body[0], MustParseExpr(\"x = data.comprehensions.nums[_]\"))\n\tassertExprEqual(t, mod13.Rules[4].Head.Value.Value.(*ArrayComprehension).Body[0], MustParseExpr(\"y = data.comprehensions.f(1)[0]\"))\n\n\t// Ignore vars assigned via `some x in xs`.\n\tmod14 := c.Modules[\"someinassign\"]\n\tsomeInAssignCall := mod14.Rules[2].Body[0].Terms.(*SomeDecl).Symbols[0].Value.(Call)\n\tassertTermEqual(t, someInAssignCall[1], VarTerm(\"x\"))\n\tcollectionLastElem := someInAssignCall[2].Value.(*Array).Get(IntNumberTerm(2))\n\tassertTermEqual(t, collectionLastElem, MustParseTerm(\"data.someinassign.y\"))\n\n\t// Ignore key and val vars assigned via `some k, v in xs`.\n\tmod15 := c.Modules[\"someinassignwithkey\"]\n\tsomeInAssignCall = mod15.Rules[2].Body[0].Terms.(*SomeDecl).Symbols[0].Value.(Call)\n\tassertTermEqual(t, someInAssignCall[1], VarTerm(\"k\"))\n\tassertTermEqual(t, someInAssignCall[2], VarTerm(\"v\"))\n\tcollectionLastElem = someInAssignCall[3].Value.(*Array).Get(IntNumberTerm(2))\n\tassertTermEqual(t, collectionLastElem, MustParseTerm(\"data.someinassignwithkey.y\"))\n\n\tmod16 := c.Modules[\"everykw\"]\n\teveryExpr := mod16.Rules[len(mod16.Rules)-1].Body[0].Terms.(*Every)\n\tassertTermEqual(t, everyExpr.Body[0].Terms.(*Term), MustParseTerm(\"data.everykw.nums[x]\"))\n\tassertTermEqual(t, everyExpr.Domain, MustParseTerm(\"data.everykw.xs\"))\n\n\t// 'x' is not resolved\n\tassertTermEqual(t, everyExpr.Value, VarTerm(\"x\"))\n\tgt10 := MustParseExpr(\"x > 10\")\n\tgt10.Index++ // TODO(sr): why?\n\tassertExprEqual(t, everyExpr.Body[1], gt10)\n}\n\nfunc TestCompilerResolveErrors(t *testing.T) {\n\n\tc := NewCompiler()\n\tc.Modules = map[string]*Module{\n\t\t\"shadow-globals\": MustParseModule(`\n\t\t\tpackage shadow_globals\n\n\t\t\tf([input]) { true }\n\t\t`),\n\t}\n\n\tcompileStages(c, c.resolveAllRefs)\n\n\texpected := []string{\n\t\t`args must not shadow input`,\n\t}\n\n\tassertCompilerErrorStrings(t, c, expected)\n}\n\nfunc TestCompilerRewriteTermsInHead(t *testing.T) {\n\tc := NewCompiler()\n\tc.Modules[\"head\"] = MustParseModule(`package head\n\nimport data.doc1 as bar\nimport data.doc2 as corge\nimport input.x.y.foo\nimport input.qux as baz\n\np[foo[bar[i]]] = {\"baz\": baz, \"corge\": corge} { true }\nq = [true | true] { true }\nr = {\"true\": true | true} { true }\ns = {true | true} { true }\n\nelsekw {\n\tfalse\n} else = baz {\n\ttrue\n}\n`)\n\n\tcompileStages(c, c.rewriteRefsInHead)\n\tassertNotFailed(t, c)\n\n\trule1 := c.Modules[\"head\"].Rules[0]\n\texpected1 := MustParseRule(`p[__local0__] = __local1__ { true; __local0__ = input.x.y.foo[data.doc1[i]]; __local1__ = {\"baz\": input.qux, \"corge\": data.doc2} }`)\n\tassertRulesEqual(t, rule1, expected1)\n\n\trule2 := c.Modules[\"head\"].Rules[1]\n\texpected2 := MustParseRule(`q = __local2__ { true; __local2__ = [true | true] }`)\n\tassertRulesEqual(t, rule2, expected2)\n\n\trule3 := c.Modules[\"head\"].Rules[2]\n\texpected3 := MustParseRule(`r = __local3__ { true; __local3__ = {\"true\": true | true} }`)\n\tassertRulesEqual(t, rule3, expected3)\n\n\trule4 := c.Modules[\"head\"].Rules[3]\n\texpected4 := MustParseRule(`s = __local4__ { true; __local4__ = {true | true} }`)\n\tassertRulesEqual(t, rule4, expected4)\n\n\trule5 := c.Modules[\"head\"].Rules[4]\n\texpected5 := MustParseRule(`elsekw { false } else = __local5__ { true; __local5__ = input.qux }`)\n\tassertRulesEqual(t, rule5, expected5)\n}\n\nfunc TestCompilerRewriteRegoMetadataCalls(t *testing.T) {\n\ttests := []struct {\n\t\tnote   string\n\t\tmodule string\n\t\texp    string\n\t}{\n\t\t{\n\t\t\tnote: \"rego.metadata called, no metadata\",\n\t\t\tmodule: `package test\n\np {\n\trego.metadata.chain()[0].path == [\"test\", \"p\"]\n\trego.metadata.rule() == {}\n}`,\n\t\t\texp: `package test\n\np = true {\n\t__local2__ = [{\"path\": [\"test\", \"p\"]}]\n\t__local3__ = {}\n\t__local0__ = __local2__\n\tequal(__local0__[0].path, [\"test\", \"p\"])\n\t__local1__ = __local3__\n\tequal(__local1__, {})\n}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rego.metadata called, no output var, no metadata\",\n\t\t\tmodule: `package test\n\np {\n\trego.metadata.chain()\n\trego.metadata.rule()\n}`,\n\t\t\texp: `package test\n\np = true {\n\t__local0__ = [{\"path\": [\"test\", \"p\"]}]\n\t__local1__ = {}\n\t__local0__\n\t__local1__\n}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rego.metadata called, with metadata\",\n\t\t\tmodule: `# METADATA\n# description: A test package\npackage test\n\n# METADATA\n# title: My P Rule\np {\n\trego.metadata.chain()[0].title == \"My P Rule\"\n\trego.metadata.chain()[1].description == \"A test package\"\n}\n\n# METADATA\n# title: My Other P Rule\np {\n\trego.metadata.rule().title == \"My Other P Rule\"\n}`,\n\t\t\texp: `# METADATA\n# {\"scope\":\"package\",\"description\":\"A test package\"}\npackage test\n\n# METADATA\n# {\"scope\":\"rule\",\"title\":\"My P Rule\"}\np = true {\n\t__local3__ = [\n\t\t{\"annotations\": {\"scope\": \"rule\", \"title\": \"My P Rule\"}, \"path\": [\"test\", \"p\"]},\n\t\t{\"annotations\": {\"description\": \"A test package\", \"scope\": \"package\"}, \"path\": [\"test\"]}\n\t]\n\t__local0__ = __local3__\n\tequal(__local0__[0].title, \"My P Rule\")\n\t__local1__ = __local3__\n\tequal(__local1__[1].description, \"A test package\")\n}\n\n# METADATA\n# {\"scope\":\"rule\",\"title\":\"My Other P Rule\"}\np = true {\n\t__local4__ = {\"scope\": \"rule\", \"title\": \"My Other P Rule\"}\n\t__local2__ = __local4__\n\tequal(__local2__.title, \"My Other P Rule\")\n}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rego.metadata referenced multiple times\",\n\t\t\tmodule: `# METADATA\n# description: TEST\npackage test\n\np {\n\trego.metadata.chain()[0].path == [\"test\", \"p\"]\n\trego.metadata.chain()[1].path == [\"test\"]\n}`,\n\t\t\texp: `# METADATA\n# {\"scope\":\"package\",\"description\":\"TEST\"}\npackage test\n\np = true {\n\t__local2__ = [\n\t\t{\"path\": [\"test\", \"p\"]},\n\t\t{\"annotations\": {\"description\": \"TEST\", \"scope\": \"package\"}, \"path\": [\"test\"]}\n\t]\n\t__local0__ = __local2__\n\tequal(__local0__[0].path, [\"test\", \"p\"])\n\t__local1__ = __local2__\n\tequal(__local1__[1].path, [\"test\"]) }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rego.metadata return value\",\n\t\t\tmodule: `package test\n\np := rego.metadata.chain()`,\n\t\t\texp: `package test\n\np := __local0__ {\n\t__local1__ = [{\"path\": [\"test\", \"p\"]}]\n\ttrue\n\t__local0__ = __local1__\n}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rego.metadata argument in function call\",\n\t\t\tmodule: `package test\n\np {\n\tq(rego.metadata.chain())\n}\n\nq(s) {\n\ts == [\"test\", \"p\"]\n}`,\n\t\t\texp: `package test\n\np = true {\n\t__local2__ = [{\"path\": [\"test\", \"p\"]}]\n\t__local1__ = __local2__\n\tdata.test.q(__local1__)\n}\n\nq(__local0__) = true {\n\tequal(__local0__, [\"test\", \"p\"])\n}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rego.metadata used in array comprehension\",\n\t\t\tmodule: `package test\n\np = [x | x := rego.metadata.chain()]`,\n\t\t\texp: `package test\n\np = [__local0__ | __local1__ = __local2__; __local0__ = __local1__] {\n\t__local2__ = [{\"path\": [\"test\", \"p\"]}]\n\ttrue\n}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rego.metadata used in nested array comprehension\",\n\t\t\tmodule: `package test\n\np {\n\ty := [x | x := rego.metadata.chain()]\n\ty[0].path == [\"test\", \"p\"]\n}`,\n\t\t\texp: `package test\n\np = true {\n\t__local3__ = [{\"path\": [\"test\", \"p\"]}];\n\t__local1__ = [__local0__ | __local2__ = __local3__; __local0__ = __local2__];\n\tequal(__local1__[0].path, [\"test\", \"p\"])\n}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rego.metadata used in set comprehension\",\n\t\t\tmodule: `package test\n\np = {x | x := rego.metadata.chain()}`,\n\t\t\texp: `package test\n\np = {__local0__ | __local1__ = __local2__; __local0__ = __local1__} {\n\t__local2__ = [{\"path\": [\"test\", \"p\"]}]\n\ttrue\n}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rego.metadata used in nested set comprehension\",\n\t\t\tmodule: `package test\n\np {\n\ty := {x | x := rego.metadata.chain()}\n\ty[0].path == [\"test\", \"p\"]\n}`,\n\t\t\texp: `package test\n\np = true {\n\t__local3__ = [{\"path\": [\"test\", \"p\"]}]\n\t__local1__ = {__local0__ | __local2__ = __local3__; __local0__ = __local2__}\n\tequal(__local1__[0].path, [\"test\", \"p\"])\n}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rego.metadata used in object comprehension\",\n\t\t\tmodule: `package test\n\np = {i: x | x := rego.metadata.chain()[i]}`,\n\t\t\texp: `package test\n\np = {i: __local0__ | __local1__ = __local2__; __local0__ = __local1__[i]} {\n\t__local2__ = [{\"path\": [\"test\", \"p\"]}]\n\ttrue\n}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rego.metadata used in nested object comprehension\",\n\t\t\tmodule: `package test\n\np {\n\ty := {i: x | x := rego.metadata.chain()[i]}\n\ty[0].path == [\"test\", \"p\"]\n}`,\n\t\t\texp: `package test\n\np = true {\n\t__local3__ = [{\"path\": [\"test\", \"p\"]}]\n\t__local1__ = {i: __local0__ | __local2__ = __local3__; __local0__ = __local2__[i]}\n\tequal(__local1__[0].path, [\"test\", \"p\"])\n}`,\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tc := NewCompiler()\n\t\t\tc.Modules = map[string]*Module{\n\t\t\t\t\"test.rego\": MustParseModule(tc.module),\n\t\t\t}\n\t\t\tcompileStages(c, c.rewriteRegoMetadataCalls)\n\t\t\tassertNotFailed(t, c)\n\n\t\t\tresult := c.Modules[\"test.rego\"]\n\t\t\texp := MustParseModuleWithOpts(tc.exp, ParserOptions{ProcessAnnotation: true})\n\n\t\t\tif result.Compare(exp) != 0 {\n\t\t\t\tt.Fatalf(\"\\nExpected:\\n\\n%v\\n\\nGot:\\n\\n%v\", exp, result)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerOverridingSelfCalls(t *testing.T) {\n\tc := NewCompiler()\n\tc.Modules = map[string]*Module{\n\t\t\"self.rego\": MustParseModule(`package self.metadata\n\nchain(x) = \"foo\"\nrule := \"bar\"`),\n\t\t\"test.rego\": MustParseModule(`package test\nimport data.self\n\np := self.metadata.chain(42)\nq := self.metadata.rule`),\n\t}\n\n\tcompileStages(c, nil)\n\tassertNotFailed(t, c)\n}\n\nfunc TestCompilerRewriteLocalAssignments(t *testing.T) {\n\n\ttests := []struct {\n\t\tmodule          string\n\t\texp             interface{}\n\t\texpRewrittenMap map[Var]Var\n\t}{\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tbody { a := 1; a > 0 }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tbody = true { __local0__ = 1; gt(__local0__, 0) }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"a\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\thead_vars(a) = b { b := a }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\thead_vars(__local0__) = __local1__ { __local1__ = __local0__ }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"a\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"b\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\thead_key[a] { a := 1 }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\thead_key[__local0__] { __local0__ = 1 }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"a\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\thead_unsafe_var[a] { some a }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\thead_unsafe_var[__local0__] { true }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"a\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tp = {1,2,3}\n\t\t\t\tx = 4\n\t\t\t\thead_nested[p[x]] {\n\t\t\t\t\tsome x\n\t\t\t\t}`,\n\t\t\texp: `\n\t\t\t\t\tpackage test\n\t\t\t\t\tp = {1,2,3}\n\t\t\t\t\tx = 4\n\t\t\t\t\thead_nested[data.test.p[__local0__]]\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"x\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tp = {1,2}\n\t\t\t\thead_closure_nested[p[x]] {\n\t\t\t\t\ty = [true | some x; x = 1]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp = {1,2}\n\t\t\t\thead_closure_nested[data.test.p[x]] {\n\t\t\t\t\ty = [true | __local0__ = 1]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"x\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tnested {\n\t\t\t\t\ta := [1,2,3]\n\t\t\t\t\tx := [true | a[i] > 1]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tnested = true { __local0__ = [1, 2, 3]; __local1__ = [true | gt(__local0__[i], 1)] }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"a\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"x\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tx = 2\n\t\t\t\tshadow_globals[x] { x := 1 }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tx = 2 { true }\n\t\t\t\tshadow_globals[__local0__] { __local0__ = 1 }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"x\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tshadow_rule[shadow_rule] { shadow_rule := 1 }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tshadow_rule[__local0__] { __local0__ = 1 }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"shadow_rule\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tshadow_roots_1 { data := 1; input := 2; input > data }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tshadow_roots_1 = true { __local0__ = 1; __local1__ = 2; gt(__local1__, __local0__) }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"data\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"input\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tshadow_roots_2 { input := {\"a\": 1}; input.a > 0  }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tshadow_roots_2 = true { __local0__ = {\"a\": 1}; gt(__local0__.a, 0) }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"input\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tskip_with_target { a := 1; input := 2; data.p with input as a }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tskip_with_target = true { __local0__ = 1; __local1__ = 2; data.p with input as __local0__ }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"a\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"input\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tshadow_comprehensions {\n\t\t\t\t\ta := 1\n\t\t\t\t\t[true | a := 2; b := 1]\n\t\t\t\t\tb := 2\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tshadow_comprehensions = true { __local0__ = 1; [true | __local1__ = 2; __local2__ = 1]; __local3__ = 2 }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"a\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"a\"),\n\t\t\t\tVar(\"__local2__\"): Var(\"b\"),\n\t\t\t\tVar(\"__local3__\"): Var(\"b\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t\tscoping {\n\t\t\t\t\t\t[true | a := 1]\n\t\t\t\t\t\t[true | a := 2]\n\t\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tscoping = true { [true | __local0__ = 1]; [true | __local1__ = 2] }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"a\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"a\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tobject_keys {\n\t\t\t\t\t{k: v1, \"k2\": v2} := {\"foo\": 1, \"k2\": 2}\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tobject_keys = true { {\"k2\": __local0__, k: __local1__} = {\"foo\": 1, \"k2\": 2} }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"v2\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"v1\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\thead_array_comprehensions = [[x] | x := 1]\n\t\t\t\t\thead_set_comprehensions = {[x] | x := 1}\n\t\t\t\t\thead_object_comprehensions = {k: [x] | k := \"foo\"; x := 1}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\thead_array_comprehensions = [[__local0__] | __local0__ = 1] { true }\n\t\t\t\thead_set_comprehensions = {[__local1__] | __local1__ = 1} { true }\n\t\t\t\thead_object_comprehensions = {__local2__: [__local3__] | __local2__ = \"foo\"; __local3__ = 1} { true }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"x\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"x\"),\n\t\t\t\tVar(\"__local2__\"): Var(\"k\"),\n\t\t\t\tVar(\"__local3__\"): Var(\"x\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\trewritten_object_key {\n\t\t\t\t\tk := \"foo\"\n\t\t\t\t\t{k: 1}\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\trewritten_object_key = true { __local0__ = \"foo\"; {__local0__: 1} }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"k\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\trewritten_object_key_head[[{k: 1}]] {\n\t\t\t\t\tk := \"foo\"\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\trewritten_object_key_head[[{__local0__: 1}]] { __local0__ = \"foo\" }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"k\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\trewritten_object_key_head_value = [{k: 1}] {\n\t\t\t\t\tk := \"foo\"\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\trewritten_object_key_head_value = [{__local0__: 1}] { __local0__ = \"foo\" }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"k\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tskip_with_target_in_assignment {\n\t\t\t\t\tinput := 1\n\t\t\t\t\ta := [true | true with input as 2; true with input as 3]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tskip_with_target_in_assignment = true { __local0__ = 1; __local1__ = [true | true with input as 2; true with input as 3] }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"input\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"a\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\trewrite_value_in_assignment {\n\t\t\t\t\ta := 1\n\t\t\t\t\tb := 1 with input as [a]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\trewrite_value_in_assignment = true { __local0__ = 1; __local1__ = 1 with input as [__local0__] }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"a\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"b\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tglobal = {}\n\t\t\t\tref_shadowed {\n\t\t\t\t\tglobal := {\"a\": 1}\n\t\t\t\t\tglobal.a > 0\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tglobal = {} { true }\n\t\t\t\tref_shadowed = true { __local0__ = {\"a\": 1}; gt(__local0__.a, 0) }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"global\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tf(x) = y {\n\t\t\t\t\tx == 1\n\t\t\t\t\ty := 2\n\t\t\t\t} else = y {\n\t\t\t\t\tx == 3\n\t\t\t\t\ty := 4\n\t\t\t\t}\n\t\t\t`,\n\t\t\t// Each \"else\" rule has a separate rule head and the vars in the\n\t\t\t// args will be rewritten. Since we cannot currently redefine the\n\t\t\t// args, we must parse the module and then manually update the args.\n\t\t\texp: func() *Module {\n\t\t\t\tmodule := MustParseModule(`\n\t\t\t\t\tpackage test\n\n\t\t\t\t\tf(__local0__) = __local1__ { __local0__ == 1; __local1__ = 2 } else = __local3__ { __local2__ == 3; __local3__ = 4 }\n\t\t\t\t`)\n\t\t\t\tmodule.Rules[0].Else.Head.Args[0].Value = Var(\"__local2__\")\n\t\t\t\treturn module\n\t\t\t},\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"x\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"y\"),\n\t\t\t\tVar(\"__local2__\"): Var(\"x\"),\n\t\t\t\tVar(\"__local3__\"): Var(\"y\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tf({\"x\": [x]}) = y { x == 1; y := 2 }`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\n\t\t\t\tf({\"x\": [__local0__]}) = __local1__ { __local0__ == 1; __local1__ = 2 }`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"x\"),\n\t\t\t\tVar(\"__local1__\"): Var(\"y\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tf(x, [x]) = x { x == 1 }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\n\t\t\t\tf(__local0__, [__local0__]) = __local0__ { __local0__ == 1 }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"x\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tf(x) = {x[0]: 1} { true }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\n\t\t\t\tf(__local0__) = {__local0__[0]: 1} { true }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"x\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tf({{t | t := 0}: 1}) {\n\t\t\t\t\ttrue\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\n\t\t\t\tf({{__local0__ | __local0__ = 0}: 1}) { true }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"t\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tf({{t | t := 0}}) {\n\t\t\t\t\ttrue\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\n\t\t\t\tf({{__local0__ | __local0__ = 0}}) { true }\n\t\t\t`,\n\t\t\texpRewrittenMap: map[Var]Var{\n\t\t\t\tVar(\"__local0__\"): Var(\"t\"),\n\t\t\t},\n\t\t},\n\t}\n\n\tfor i, tc := range tests {\n\t\tt.Run(fmt.Sprint(i), func(t *testing.T) {\n\t\t\tc := NewCompiler()\n\t\t\tc.Modules = map[string]*Module{\n\t\t\t\t\"test.rego\": MustParseModule(tc.module),\n\t\t\t}\n\t\t\tcompileStages(c, c.rewriteLocalVars)\n\t\t\tassertNotFailed(t, c)\n\t\t\tresult := c.Modules[\"test.rego\"]\n\t\t\tvar exp *Module\n\t\t\tswitch e := tc.exp.(type) {\n\t\t\tcase string:\n\t\t\t\texp = MustParseModule(e)\n\t\t\tcase func() *Module:\n\t\t\t\texp = e()\n\t\t\tdefault:\n\t\t\t\tpanic(\"expected value must be string or func() *Module\")\n\t\t\t}\n\t\t\tif result.Compare(exp) != 0 {\n\t\t\t\tt.Fatalf(\"\\nExpected:\\n\\n%v\\n\\nGot:\\n\\n%v\", exp, result)\n\t\t\t}\n\t\t\tif !reflect.DeepEqual(c.RewrittenVars, tc.expRewrittenMap) {\n\t\t\t\tt.Fatalf(\"\\nExpected Rewritten Vars:\\n\\n\\t%+v\\n\\nGot:\\n\\n\\t%+v\\n\\n\", tc.expRewrittenMap, c.RewrittenVars)\n\t\t\t}\n\t\t})\n\t}\n\n}\nfunc TestRewriteLocalVarDeclarationErrors(t *testing.T) {\n\n\tc := NewCompiler()\n\n\tc.Modules[\"test\"] = MustParseModule(`package test\n\n\tredeclaration {\n\t\tr1 = 1\n\t\tr1 := 2\n\t\tr2 := 1\n\t\t[b, r2] := [1, 2]\n\t\tinput.path == 1\n\t\tinput := \"foo\"\n\t\t_ := [1 | nested := 1; nested := 2]\n\t}\n\n\tnegation {\n\t\tnot a := 1\n\t}\n\n\tbad_assign {\n\t\tnull := x\n\t\ttrue := x\n\t\t4.5 := x\n\t\t\"foo\" := x\n\t\t[true | true] := []\n\t\t{true | true} := set()\n\t\t{\"foo\": true | true} := {}\n\t\tx + 1 := 2\n\t\tdata.foo := 1\n\t\t[z, 1] := [1, 2]\n\t}\n\n\targ_redeclared(arg1) {\n\t\targ1 := 1\n\t}\n\n\targ_nested_redeclared({{arg_nested| arg_nested := 1; arg_nested := 2}}) { true }\n\t`)\n\n\tcompileStages(c, c.rewriteLocalVars)\n\n\texpectedErrors := []string{\n\t\t\"var r1 referenced above\",\n\t\t\"var r2 assigned above\",\n\t\t\"var input referenced above\",\n\t\t\"var nested assigned above\",\n\t\t\"arg arg1 redeclared\",\n\t\t\"var arg_nested assigned above\",\n\t\t\"cannot assign vars inside negated expression\",\n\t\t\"cannot assign to ref\",\n\t\t\"cannot assign to arraycomprehension\",\n\t\t\"cannot assign to setcomprehension\",\n\t\t\"cannot assign to objectcomprehension\",\n\t\t\"cannot assign to call\",\n\t\t\"cannot assign to number\",\n\t\t\"cannot assign to number\",\n\t\t\"cannot assign to boolean\",\n\t\t\"cannot assign to string\",\n\t\t\"cannot assign to null\",\n\t}\n\n\tsort.Strings(expectedErrors)\n\n\tresult := []string{}\n\n\tfor i := range c.Errors {\n\t\tresult = append(result, c.Errors[i].Message)\n\t}\n\n\tsort.Strings(result)\n\n\tif len(expectedErrors) != len(result) {\n\t\tt.Fatalf(\"Expected %d errors but got %d:\\n\\n%v\\n\\nGot:\\n\\n%v\", len(expectedErrors), len(result), strings.Join(expectedErrors, \"\\n\"), strings.Join(result, \"\\n\"))\n\t}\n\n\tfor i := range result {\n\t\tif result[i] != expectedErrors[i] {\n\t\t\tt.Fatalf(\"Expected:\\n\\n%v\\n\\nGot:\\n\\n%v\", strings.Join(expectedErrors, \"\\n\"), strings.Join(result, \"\\n\"))\n\t\t}\n\t}\n}\n\nfunc TestRewriteDeclaredVarsStage(t *testing.T) {\n\n\t// Unlike the following test case, this only executes up to the\n\t// RewriteLocalVars stage. This is done so that later stages like\n\t// RewriteDynamics are not executed.\n\n\ttests := []struct {\n\t\tnote   string\n\t\tmodule string\n\t\texp    string\n\t}{\n\t\t{\n\t\t\tnote: \"object ref key\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\ta := {\"a\": \"a\"}\n\t\t\t\t\t{a.a: a.a}\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\t__local0__ = {\"a\": \"a\"}\n\t\t\t\t\t{__local0__.a: __local0__.a}\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"set ref element\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\ta := {\"a\": \"a\"}\n\t\t\t\t\t{a.a}\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\t__local0__ = {\"a\": \"a\"}\n\t\t\t\t\t{__local0__.a}\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\n\t\t\tc := NewCompiler()\n\n\t\t\tc.Modules = map[string]*Module{\n\t\t\t\t\"test.rego\": MustParseModule(tc.module),\n\t\t\t}\n\n\t\t\tcompileStages(c, c.rewriteLocalVars)\n\n\t\t\texp := MustParseModule(tc.exp)\n\t\t\tresult := c.Modules[\"test.rego\"]\n\n\t\t\tif !exp.Equal(result) {\n\t\t\t\tt.Fatalf(\"Expected:\\n\\n%v\\n\\nGot:\\n\\n%v\", exp, result)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestRewriteDeclaredVars(t *testing.T) {\n\ttests := []struct {\n\t\tnote    string\n\t\tmodule  string\n\t\texp     string\n\t\twantErr error\n\t}{\n\t\t{\n\t\t\tnote: \"rewrite unify\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tx = 1\n\t\t\t\ty = 2\n\t\t\t\tp { some x; input = [x, y] }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tx = 1\n\t\t\t\ty = 2\n\t\t\t\tp { __local1__ = data.test.y; input = [__local0__, __local1__] }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite call\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tx = []\n\t\t\t\ty = {}\n\t\t\t\tp { some x; walk(y, [x, y]) }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tx = []\n\t\t\t\ty = {}\n\t\t\t\tp { __local1__ = data.test.y; __local2__ = data.test.y; walk(__local1__, [__local0__, __local2__]) }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite term\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tx = \"a\"\n\t\t\t\ty = 1\n\t\t\t\tq[[2, \"b\"]]\n\t\t\t\tp { some x; q[[y,x]] }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tx = \"a\"\n\t\t\t\ty = 1\n\t\t\t\tq[[2, \"b\"]]\n\t\t\t\tp { __local1__ = data.test.y; data.test.q[[__local1__, __local0__]] }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite some x in xs\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\timport future.keywords.in\n\t\t\t\txs = [\"a\", \"b\", \"c\"]\n\t\t\t\tp { some x in xs; x == \"a\" }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\txs = [\"a\", \"b\", \"c\"]\n\t\t\t\tp { __local2__ = data.test.xs[__local1__]; __local2__ = \"a\" }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite some k, x in xs\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\timport future.keywords.in\n\t\t\t\txs = [\"a\", \"b\", \"c\"]\n\t\t\t\tp { some k, x in xs; x == \"a\"; k == 2 }\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\txs = [\"a\", \"b\", \"c\"]\n\t\t\t\tp { __local1__ = data.test.xs[__local0__]; __local1__ = \"a\"; __local0__ = 2 }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite some k, x in xs[i]\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\timport future.keywords.in\n\t\t\t\txs = [[\"a\", \"b\", \"c\"], []]\n\t\t\t\tp {\n\t\t\t\t\tsome i\n\t\t\t\t\tsome k, x in xs[i]\n\t\t\t\t\tx == \"a\"\n\t\t\t\t\tk == 2\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\txs = [[\"a\", \"b\", \"c\"], []]\n\t\t\t\tp = true { __local2__ = data.test.xs[__local0__][__local1__]; __local2__ = \"a\"; __local1__ = 2 }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite some k, x in xs[i] with `i` as ref\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\timport future.keywords.in\n\t\t\t\ti = 0\n\t\t\t\txs = [[\"a\", \"b\", \"c\"], []]\n\t\t\t\tp {\n\t\t\t\t\tsome k, x in xs[i]\n\t\t\t\t\tx == \"a\"\n\t\t\t\t\tk == 2\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\ti = 0\n\t\t\t\txs = [[\"a\", \"b\", \"c\"], []]\n\t\t\t\tp = true { __local2__ = data.test.i; __local1__ = data.test.xs[__local2__][__local0__]; __local1__ = \"a\"; __local0__ = 2 }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite some: with modifier on domain\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tp {\n\t\t\t\t\tsome k, x in input with input as [1, 1, 1]\n\t\t\t\t\tk == 0\n\t\t\t\t\tx == 1\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp {\n\t\t\t\t\t__local1__ = input[__local0__] with input as [1, 1, 1]\n\t\t\t\t\t__local0__ = 0\n\t\t\t\t\t__local1__ = 1\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\ti = 0\n\t\t\t\txs = [1, 2]\n\t\t\t\tk = \"foo\"\n\t\t\t\tv = \"bar\"\n\t\t\t\tp {\n\t\t\t\t\tevery k, v in xs { k + v > i }\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\ti = 0\n\t\t\t\txs = [1, 2]\n\t\t\t\tk = \"foo\"\n\t\t\t\tv = \"bar\"\n\t\t\t\tp = true {\n\t\t\t\t\t__local2__ = data.test.xs\n\t\t\t\t\tevery __local0__, __local1__ in __local2__ {\n\t\t\t\t\t\tplus(__local0__, __local1__, __local3__)\n\t\t\t\t\t\t__local4__ = data.test.i\n\t\t\t\t\t\tgt(__local3__, __local4__)\n\t\t\t\t\t}\n\t\t\t\t}\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every: unused key var\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\tp {\n\t\t\t\t\tevery k, v in [1] { v >= 1 }\n\t\t\t\t}\n\t\t\t`,\n\t\t\twantErr: errors.New(\"declared var k unused\"),\n\t\t},\n\t\t{\n\t\t\t// NOTE(sr): this would happen when compiling modules twice:\n\t\t\t// the first run rewrites every to include a generated key var,\n\t\t\t// the second one bails because it's not used.\n\t\t\t// Seen in the wild when using `opa test -b` on a bundle that\n\t\t\t// used `every`, https://github.com/open-policy-agent/opa/issues/4420\n\t\t\tnote: \"rewrite every: unused generated key var\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\tevery __local0__, v in [1] { v >= 1 }\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp = true {\n\t\t\t\t\t__local3__ = [1]\n\t\t\t\t\tevery __local1__, __local2__ in __local3__ { __local2__ >= 1 }\n\t\t\t\t}\n\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every: unused value var\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\tp {\n\t\t\t\t\tevery v in [1] { true }\n\t\t\t\t}\n\t\t\t`,\n\t\t\twantErr: errors.New(\"declared var v unused\"),\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every: wildcard value var, used key\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\tp {\n\t\t\t\t\tevery k, _ in [1] { k >= 0 }\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp = true {\n\t\t\t\t\t__local1__ = [1]\n\t\t\t\t\tevery __local0__, _ in __local1__ { gte(__local0__, 0) }\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every: wildcard key+value var\", // NOTE(sr): may be silly, but valid\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\tp {\n\t\t\t\t\tevery _, _ in [1] { true }\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp = true { __local0__ = [1]; every _, _ in __local0__ { true } }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every: declared vars with different scopes\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\tp {\n\t\t\t\t\tsome x\n\t\t\t\t\tx = 10\n\t\t\t\t\tevery x in [1] { x == 1 }\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp = true {\n\t\t\t\t\t__local0__ = 10\n\t\t\t\t\t__local3__ = [1]\n\t\t\t\t\tevery __local1__, __local2__ in __local3__ { __local2__ = 1 }\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every: declared vars used in body\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\tp {\n\t\t\t\t\tsome y\n\t\t\t\t\ty = 10\n\t\t\t\t\tevery x in [1] { x == y }\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp = true {\n\t\t\t\t\t__local0__ = 10\n\t\t\t\t\t__local3__ = [1]\n\t\t\t\t\tevery __local1__, __local2__ in __local3__ {\n\t\t\t\t\t\t__local2__ = __local0__\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every: pops declared var stack\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\tp[x] {\n\t\t\t\t\tsome x\n\t\t\t\t\tx = 10\n\t\t\t\t\tevery _ in [1] { true }\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp[__local0__] { __local0__ = 10; __local2__ = [1]; every __local1__, _ in __local2__ { true } }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every: nested\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\tp {\n\t\t\t\t\txs := [[1], [2]]\n\t\t\t\t\tevery v in [1] {\n\t\t\t\t\t\tevery w in xs[v] {\n\t\t\t\t\t\t\tw == 2\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp = true {\n\t\t\t\t\t__local0__ = [[1], [2]]\n\t\t\t\t\t__local5__ = [1]\n\t\t\t\t\tevery __local1__, __local2__ in __local5__ {\n\t\t\t\t\t\t__local6__ = __local0__[__local2__]\n\t\t\t\t\t\tevery __local3__, __local4__ in __local6__ {\n\t\t\t\t\t\t\t__local4__ = 2\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every: with modifier on domain\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\tp {\n\t\t\t\t\tevery x in input { x == 1 } with input as [1, 1, 1]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp {\n\t\t\t\t\t__local2__ = input with input as [1, 1, 1]\n\t\t\t\t\tevery __local0__, __local1__ in __local2__ {\n\t\t\t\t\t\t__local1__ = 1\n\t\t\t\t\t} with input as [1, 1, 1]\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every: with modifier on domain with declared var\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\tp {\n\t\t\t\t\txs := [1, 2]\n\t\t\t\t\tevery x in input { x == 1 } with input as xs\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp {\n\t\t\t\t\t__local0__ = [1, 2]\n\t\t\t\t\t__local3__ = input with input as __local0__\n\t\t\t\t\tevery __local1__, __local2__ in __local3__ {\n\t\t\t\t\t\t__local2__ = 1\n\t\t\t\t\t} with input as __local0__\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite every: with modifier on body\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\t# import future.keywords.in\n\t\t\t\t# import future.keywords.every\n\t\t\t\tp {\n\t\t\t\t\tevery x in [2] { x == input } with input as 2\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tp {\n\t\t\t\t\t__local2__ = [2] with input as 2\n\t\t\t\t\tevery __local0__, __local1__ in __local2__ {\n\t\t\t\t\t\t__local1__ = input\n\t\t\t\t\t} with input as 2\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite closures\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tx = 1\n\t\t\t\ty = 2\n\t\t\t\tp {\n\t\t\t\t\tsome x, z\n\t\t\t\t\tz = 3\n\t\t\t\t\t[x | x = 2; y = 2; some z; z = 4]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tx = 1\n\t\t\t\ty = 2\n\t\t\t\tp {\n\t\t\t\t\t__local1__ = 3\n\t\t\t\t\t[__local0__ | __local0__ = 2; data.test.y = 2; __local2__ = 4]\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite head var\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tx = \"a\"\n\t\t\t\ty = 1\n\t\t\t\tz = 2\n\t\t\t\tp[x] = [y, z] {\n\t\t\t\t\tsome x, z\n\t\t\t\t\tx = \"b\"\n\t\t\t\t\tz = 4\n\t\t\t\t}`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\t\t\t\tx = \"a\"\n\t\t\t\ty = 1\n\t\t\t\tz = 2\n\t\t\t\tp[__local0__] = __local2__ {\n\t\t\t\t\t__local0__ = \"b\"\n\t\t\t\t\t__local1__ = 4;\n\t\t\t\t\t__local3__ = data.test.y\n\t\t\t\t\t__local2__ = [__local3__, __local1__]\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rewrite call with root document ref as arg\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\tf(input, \"bar\")\n\t\t\t\t}\n\n\t\t\t\tf(x, y) {\n\t\t\t\t\tx[y]\n\t\t\t\t}\n\t\t\t\t`,\n\t\t\texp: `\n\t\t\t\tpackage test\n\n\t\t\t\tp = true {\n\t\t\t\t\t__local2__ = input;\n\t\t\t\t\tdata.test.f(__local2__, \"bar\")\n\t\t\t\t}\n\n\t\t\t\tf(__local0__, __local1__) = true {\n\t\t\t\t\t__local0__[__local1__]\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"redeclare err\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tp {\n\t\t\t\t\tsome x\n\t\t\t\t\tsome x\n\t\t\t\t}\n\t\t\t`,\n\t\t\twantErr: errors.New(\"var x declared above\"),\n\t\t},\n\t\t{\n\t\t\tnote: \"redeclare assigned err\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tp {\n\t\t\t\t\tx := 1\n\t\t\t\t\tsome x\n\t\t\t\t}\n\t\t\t`,\n\t\t\twantErr: errors.New(\"var x assigned above\"),\n\t\t},\n\t\t{\n\t\t\tnote: \"redeclare reference err\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tp {\n\t\t\t\t\tdata.q[x]\n\t\t\t\t\tsome x\n\t\t\t\t}\n\t\t\t`,\n\t\t\twantErr: errors.New(\"var x referenced above\"),\n\t\t},\n\t\t{\n\t\t\tnote: \"declare unused err\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tp {\n\t\t\t\t\tsome x\n\t\t\t\t}\n\t\t\t`,\n\t\t\twantErr: errors.New(\"declared var x unused\"),\n\t\t},\n\t\t{\n\t\t\tnote: \"declare unsafe err\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\t\t\t\tp[x] {\n\t\t\t\t\tsome x\n\t\t\t\t\tx == 1\n\t\t\t\t}\n\t\t\t`,\n\t\t\twantErr: errors.New(\"var x is unsafe\"),\n\t\t},\n\t\t{\n\t\t\tnote: \"declare arg err\",\n\t\t\tmodule: `\n\t\t\tpackage test\n\n\t\t\tf([a]) {\n\t\t\t\tsome a\n\t\t\t\ta = 1\n\t\t\t}\n\t\t\t`,\n\t\t\twantErr: errors.New(\"arg a redeclared\"),\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\topts := CompileOpts{ParserOptions: ParserOptions{FutureKeywords: []string{\"in\", \"every\"}, unreleasedKeywords: true}}\n\t\t\tcompiler, err := CompileModulesWithOpt(map[string]string{\"test.rego\": tc.module}, opts)\n\t\t\tif tc.wantErr != nil {\n\t\t\t\tif err == nil {\n\t\t\t\t\tt.Fatal(\"Expected error but got success\")\n\t\t\t\t}\n\t\t\t\tif !strings.Contains(err.Error(), tc.wantErr.Error()) {\n\t\t\t\t\tt.Fatalf(\"Expected %v but got %v\", tc.wantErr, err)\n\t\t\t\t}\n\t\t\t} else if err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t} else {\n\t\t\t\texp := MustParseModuleWithOpts(tc.exp, opts.ParserOptions)\n\t\t\t\tresult := compiler.Modules[\"test.rego\"]\n\t\t\t\tif exp.Compare(result) != 0 {\n\t\t\t\t\tt.Fatalf(\"Expected:\\n\\n%v\\n\\nGot:\\n\\n%v\", exp, result)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompileInvalidEqAssignExpr(t *testing.T) {\n\n\tc := NewCompiler()\n\n\tc.Modules[\"error\"] = MustParseModule(`package errors\n\n\n\tp {\n\t\t# Arity mismatches are caught in the checkUndefinedFuncs check,\n\t\t# and invalid eq/assign calls are passed along until then.\n\t\tassign()\n\t\tassign(1)\n\t\teq()\n\t\teq(1)\n\t}`)\n\n\tvar prev func()\n\tcheckUndefinedFuncs := reflect.ValueOf(c.checkUndefinedFuncs)\n\n\tfor _, stage := range c.stages {\n\t\tif reflect.ValueOf(stage.f).Pointer() == checkUndefinedFuncs.Pointer() {\n\t\t\tbreak\n\t\t}\n\t\tprev = stage.f\n\t}\n\n\tcompileStages(c, prev)\n\tassertNotFailed(t, c)\n}\n\nfunc TestCompilerRewriteComprehensionTerm(t *testing.T) {\n\n\tc := NewCompiler()\n\tc.Modules[\"head\"] = MustParseModule(`package head\n\tarr = [[1], [2], [3]]\n\tarr2 = [[\"a\"], [\"b\"], [\"c\"]]\n\tarr_comp = [[x[i]] | arr[j] = x]\n\tset_comp = {[x[i]] | arr[j] = x}\n\tobj_comp = {x[i]: x[i] | arr2[j] = x}\n\t`)\n\n\tcompileStages(c, c.rewriteComprehensionTerms)\n\tassertNotFailed(t, c)\n\n\tarrCompRule := c.Modules[\"head\"].Rules[2]\n\texp1 := MustParseRule(`arr_comp = [__local0__ | data.head.arr[j] = x; __local0__ = [x[i]]] { true }`)\n\tassertRulesEqual(t, arrCompRule, exp1)\n\n\tsetCompRule := c.Modules[\"head\"].Rules[3]\n\texp2 := MustParseRule(`set_comp = {__local1__ | data.head.arr[j] = x; __local1__ = [x[i]]} { true }`)\n\tassertRulesEqual(t, setCompRule, exp2)\n\n\tobjCompRule := c.Modules[\"head\"].Rules[4]\n\texp3 := MustParseRule(`obj_comp = {__local2__: __local3__ | data.head.arr2[j] = x; __local2__ = x[i]; __local3__ = x[i]} { true }`)\n\tassertRulesEqual(t, objCompRule, exp3)\n}\n\nfunc TestCompilerRewriteDoubleEq(t *testing.T) {\n\ttests := []struct {\n\t\tnote  string\n\t\tinput string\n\t\texp   string\n\t}{\n\t\t{\n\t\t\tnote:  \"vars and constants\",\n\t\t\tinput: \"p { x = 1; x == 1; y = [1,2,3]; y == [1,2,3] }\",\n\t\t\texp:   `x = 1; x = 1; y = [1,2,3]; y = [1,2,3]`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"refs\",\n\t\t\tinput: \"p { input.x == data.y }\",\n\t\t\texp:   `input.x = data.y`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"comprehensions\",\n\t\t\tinput: \"p { [1|true] == [2|true] }\",\n\t\t\texp:   `[1|true] = [2|true]`,\n\t\t},\n\t\t// TODO(tsandall): improve support for calls so that extra unification step is\n\t\t// not required. This requires more changes to the compiler as the initial\n\t\t// stages that rewrite term exprs needs to be updated to handle == differently\n\t\t// and then other stages need to be reviewed to make sure they can deal with\n\t\t// nested calls. Alternatively, the compiler could keep track of == exprs that\n\t\t// have been converted into = and then the safety check would need to be updated.\n\t\t{\n\t\t\tnote:  \"calls\",\n\t\t\tinput: \"p { count([1,2]) == 2 }\",\n\t\t\texp:   `count([1,2], __local0__); __local0__ = 2`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"embedded\",\n\t\t\tinput: \"p { x = 1; y = [x == 0] }\",\n\t\t\texp:   `x = 1; equal(x, 0, __local0__); y = [__local0__]`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"embedded in call\",\n\t\t\tinput: `p { x = 0; neq(true, x == 1) }`,\n\t\t\texp:   `x = 0; equal(x, 1, __local0__); neq(true, __local0__)`,\n\t\t},\n\t\t{\n\t\t\tnote:  \"comprehension in object key\",\n\t\t\tinput: `p { {{1 | 0 == 0}: 2} }`,\n\t\t\texp:   `{{1 | 0 = 0}: 2}`,\n\t\t},\n\t}\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tc := NewCompiler()\n\t\t\tc.Modules[\"test\"] = MustParseModule(\"package test\\n\" + tc.input)\n\t\t\tcompileStages(c, c.rewriteEquals)\n\t\t\tassertNotFailed(t, c)\n\t\t\texp := MustParseBody(tc.exp)\n\t\t\tresult := c.Modules[\"test\"].Rules[0].Body\n\t\t\tif result.Compare(exp) != 0 {\n\t\t\t\tt.Fatalf(\"\\nExp: %v\\nGot: %v\", exp, result)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerRewriteDynamicTerms(t *testing.T) {\n\n\tfixture := `\n\t\tpackage test\n\t\tstr = \"hello\"\n\t`\n\n\ttests := []struct {\n\t\tinput    string\n\t\texpected string\n\t}{\n\t\t{`arr { [str] }`, `__local0__ = data.test.str; [__local0__]`},\n\t\t{`arr2 { [[str]] }`, `__local0__ = data.test.str; [[__local0__]]`},\n\t\t{`obj { {\"x\": str} }`, `__local0__ = data.test.str; {\"x\": __local0__}`},\n\t\t{`obj2 { {\"x\": {\"y\": str}} }`, `__local0__ = data.test.str; {\"x\": {\"y\": __local0__}}`},\n\t\t{`set { {str} }`, `__local0__ = data.test.str; {__local0__}`},\n\t\t{`set2 { {{str}} }`, `__local0__ = data.test.str; {{__local0__}}`},\n\t\t{`ref { str[str] }`, `__local0__ = data.test.str; data.test.str[__local0__]`},\n\t\t{`ref2 { str[str[str]] }`, `__local0__ = data.test.str; __local1__ = data.test.str[__local0__]; data.test.str[__local1__]`},\n\t\t{`arr_compr { [1 | [str]] }`, `[1 | __local0__ = data.test.str; [__local0__]]`},\n\t\t{`arr_compr2 { [1 | [1 | [str]]] }`, `[1 | [1 | __local0__ = data.test.str; [__local0__]]]`},\n\t\t{`set_compr { {1 | [str]} }`, `{1 | __local0__ = data.test.str; [__local0__]}`},\n\t\t{`set_compr2 { {1 | {1 | [str]}} }`, `{1 | {1 | __local0__ = data.test.str; [__local0__]}}`},\n\t\t{`obj_compr { {\"a\": \"b\" | [str]} }`, `{\"a\": \"b\" | __local0__ = data.test.str; [__local0__]}`},\n\t\t{`obj_compr2 { {\"a\": \"b\" | {\"a\": \"b\" | [str]}} }`, `{\"a\": \"b\" | {\"a\": \"b\" | __local0__ = data.test.str; [__local0__]}}`},\n\t\t{`equality { str = str }`, `data.test.str = data.test.str`},\n\t\t{`equality2 { [str] = [str] }`, `__local0__ = data.test.str; __local1__ = data.test.str; [__local0__] = [__local1__]`},\n\t\t{`call { startswith(str, \"\") }`, `__local0__ = data.test.str; startswith(__local0__, \"\")`},\n\t\t{`call2 { count([str], n) }`, `__local0__ = data.test.str; count([__local0__], n)`},\n\t\t{`eq_with { [str] = [1] with input as 1 }`, `__local0__ = data.test.str with input as 1; [__local0__] = [1] with input as 1`},\n\t\t{`term_with { [[str]] with input as 1 }`, `__local0__ = data.test.str with input as 1; [[__local0__]] with input as 1`},\n\t\t{`call_with { count(str) with input as 1 }`, `__local0__ = data.test.str with input as 1; count(__local0__) with input as 1`},\n\t\t{`call_func { f(input, \"foo\") } f(x,y) { x[y] }`, `__local2__ = input; data.test.f(__local2__, \"foo\")`},\n\t\t{`call_func2 { f(input.foo, \"foo\") } f(x,y) { x[y] }`, `__local2__ = input.foo; data.test.f(__local2__, \"foo\")`},\n\t\t{`every_domain { every _ in str { true } }`, `__local1__ = data.test.str; every __local0__, _ in __local1__ { true }`},\n\t\t{`every_domain_call { every _ in numbers.range(1, 10) { true } }`, `numbers.range(1, 10, __local1__); every __local0__, _ in __local1__ { true }`},\n\t\t{`every_body { every _ in [] { [str] } }`,\n\t\t\t`__local1__ = []; every __local0__, _ in __local1__ { __local2__ = data.test.str; [__local2__] }`},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.input, func(t *testing.T) {\n\t\t\tc := NewCompiler()\n\t\t\topts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\t\t\tmodule := fixture + tc.input\n\t\t\tc.Modules[\"test\"] = MustParseModuleWithOpts(module, opts)\n\t\t\tcompileStages(c, c.rewriteDynamicTerms)\n\t\t\tassertNotFailed(t, c)\n\t\t\texpected := MustParseBodyWithOpts(tc.expected, opts)\n\t\t\tresult := c.Modules[\"test\"].Rules[1].Body\n\t\t\tif result.Compare(expected) != 0 {\n\t\t\t\tt.Fatalf(\"\\nExp: %v\\nGot: %v\", expected, result)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerRewriteWithValue(t *testing.T) {\n\tfixture := `package test\n\n\tarr = [\"hello\", \"goodbye\"]\n\n\t`\n\n\ttests := []struct {\n\t\tnote         string\n\t\tinput        string\n\t\topts         func(*Compiler) *Compiler\n\t\texpected     string\n\t\texpectedRule *Rule\n\t\twantErr      error\n\t}{\n\t\t{\n\t\t\tnote:     \"nop\",\n\t\t\tinput:    `p { true with input as 1 }`,\n\t\t\texpected: `p { true with input as 1 }`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"refs\",\n\t\t\tinput:    `p { true with input as arr }`,\n\t\t\texpected: `p { __local0__ = data.test.arr; true with input as __local0__ }`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"array comprehension\",\n\t\t\tinput:    `p { true with input as [true | true] }`,\n\t\t\texpected: `p { __local0__ = [true | true]; true with input as __local0__ }`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"set comprehension\",\n\t\t\tinput:    `p { true with input as {true | true} }`,\n\t\t\texpected: `p { __local0__ = {true | true}; true with input as __local0__ }`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"object comprehension\",\n\t\t\tinput:    `p { true with input as {\"k\": true | true} }`,\n\t\t\texpected: `p { __local0__ = {\"k\": true | true}; true with input as __local0__ }`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"comprehension nested\",\n\t\t\tinput:    `p { true with input as [true | true with input as arr] }`,\n\t\t\texpected: `p { __local0__ = [true | __local1__ = data.test.arr; true with input as __local1__]; true with input as __local0__ }`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"multiple\",\n\t\t\tinput:    `p { true with input.a as arr[0] with input.b as arr[1] }`,\n\t\t\texpected: `p { __local0__ = data.test.arr[0]; __local1__ = data.test.arr[1]; true with input.a as __local0__ with input.b as __local1__ }`,\n\t\t},\n\t\t{\n\t\t\tnote:    \"invalid target\",\n\t\t\tinput:   `p { true with foo.q as 1 }`,\n\t\t\twantErr: fmt.Errorf(\"rego_type_error: with keyword target must reference existing input, data, or a function\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"built-in function: replaced by (unknown) var\",\n\t\t\tinput:    `p { true with time.now_ns as foo }`,\n\t\t\texpected: `p { true with time.now_ns as foo }`, // `foo` still a Var here\n\t\t},\n\t\t{\n\t\t\tnote: \"built-in function: valid, arity 0\",\n\t\t\tinput: `\n\t\t\t\tp { true with time.now_ns as now }\n\t\t\t\tnow() = 1\n\t\t\t`,\n\t\t\texpected: `p { true with time.now_ns as data.test.now }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"built-in function: valid func ref, arity 1\",\n\t\t\tinput: `\n\t\t\t\tp { true with http.send as mock_http_send }\n\t\t\t\tmock_http_send(_) = { \"body\": \"yay\" }\n\t\t\t`,\n\t\t\texpected: `p { true with http.send as data.test.mock_http_send }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"built-in function: replaced by value\",\n\t\t\tinput: `\n\t\t\t\tp { true with http.send as { \"body\": \"yay\" } }\n\t\t\t`,\n\t\t\texpected: `p { true with http.send as {\"body\": \"yay\"} }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"built-in function: replaced by comprehension\",\n\t\t\tinput: `\n\t\t\t\tp { true with http.send as { x: true | x := [\"a\", \"b\"][_] } }\n\t\t\t`,\n\t\t\texpected: `p { __local2__ = {__local0__: true | __local1__ = [\"a\", \"b\"]; __local0__ = __local1__[_]}; true with http.send as __local2__ }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"built-in function: replaced by ref\",\n\t\t\tinput: `\n\t\t\t\tp { true with http.send as resp }\n\t\t\t\tresp := { \"body\": \"yay\" }\n\t\t\t`,\n\t\t\texpected: `p { true with http.send as data.test.resp }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"built-in function: replaced by another built-in (ref)\",\n\t\t\tinput: `\n\t\t\t\tp { true with http.send as object.union_n }\n\t\t\t`,\n\t\t\texpected: `p { true with http.send as object.union_n }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"built-in function: replaced by another built-in (simple)\",\n\t\t\tinput: `\n\t\t\t\tp { true with http.send as count }\n\t\t\t`,\n\t\t\texpectedRule: func() *Rule {\n\t\t\t\tr := MustParseRule(`p { true with http.send as count }`)\n\t\t\t\tr.Body[0].With[0].Value.Value = Ref([]*Term{VarTerm(\"count\")})\n\t\t\t\treturn r\n\t\t\t}(),\n\t\t},\n\t\t{\n\t\t\tnote: \"built-in function: replaced by another built-in that's marked unsafe\",\n\t\t\tinput: `\n\t\t\t\tq := is_object({\"url\": \"https://httpbin.org\", \"method\": \"GET\"})\n\t\t\t\tp { q with is_object as http.send }\n\t\t\t`,\n\t\t\topts:    func(c *Compiler) *Compiler { return c.WithUnsafeBuiltins(map[string]struct{}{\"http.send\": {}}) },\n\t\t\twantErr: fmt.Errorf(\"rego_compile_error: with keyword replacing built-in function: target must not be unsafe: \\\"http.send\\\"\"),\n\t\t},\n\t\t{\n\t\t\tnote: \"non-built-in function: replaced by another built-in that's marked unsafe\",\n\t\t\tinput: `\n\t\t\tr(_) = {}\n\t\t\tq := r({\"url\": \"https://httpbin.org\", \"method\": \"GET\"})\n\t\t\tp {\n\t\t\t\tq with r as http.send\n\t\t\t}`,\n\t\t\topts:    func(c *Compiler) *Compiler { return c.WithUnsafeBuiltins(map[string]struct{}{\"http.send\": {}}) },\n\t\t\twantErr: fmt.Errorf(\"rego_compile_error: with keyword replacing built-in function: target must not be unsafe: \\\"http.send\\\"\"),\n\t\t},\n\t\t{\n\t\t\tnote: \"built-in function: valid, arity 1, non-compound name\",\n\t\t\tinput: `\n\t\t\t\tp { concat(\"/\", input) with concat as mock_concat }\n\t\t\t\tmock_concat(_, _) = \"foo/bar\"\n\t\t\t`,\n\t\t\texpectedRule: func() *Rule {\n\t\t\t\tr := MustParseRule(`p { concat(\"/\", input) with concat as data.test.mock_concat }`)\n\t\t\t\tr.Body[0].With[0].Target.Value = Ref([]*Term{VarTerm(\"concat\")})\n\t\t\t\treturn r\n\t\t\t}(),\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tc := NewCompiler()\n\t\t\tif tc.opts != nil {\n\t\t\t\tc = tc.opts(c)\n\t\t\t}\n\t\t\tmodule := fixture + tc.input\n\t\t\tc.Modules[\"test\"] = MustParseModule(module)\n\t\t\tcompileStages(c, c.rewriteWithModifiers)\n\t\t\tif tc.wantErr == nil {\n\t\t\t\tassertNotFailed(t, c)\n\t\t\t\texpected := tc.expectedRule\n\t\t\t\tif expected == nil {\n\t\t\t\t\texpected = MustParseRule(tc.expected)\n\t\t\t\t}\n\t\t\t\tresult := c.Modules[\"test\"].Rules[1]\n\t\t\t\tif result.Compare(expected) != 0 {\n\t\t\t\t\tt.Fatalf(\"\\nExp: %v\\nGot: %v\", expected, result)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tassertCompilerErrorStrings(t, c, []string{tc.wantErr.Error()})\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerRewritePrintCallsErasure(t *testing.T) {\n\n\tcases := []struct {\n\t\tnote   string\n\t\tmodule string\n\t\texp    string\n\t}{\n\t\t{\n\t\t\tnote: \"no-op\",\n\t\t\tmodule: `package test\n\t\t\tp { true }`,\n\t\t\texp: `package test\n\t\t\tp { true }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"replace empty body with true\",\n\t\t\tmodule: `package test\n\n\t\t\tp { print(1) }\n\t\t\t`,\n\t\t\texp: `package test\n\n\t\t\tp { true } `,\n\t\t},\n\t\t{\n\t\t\tnote: \"rule body\",\n\t\t\tmodule: `package test\n\n\t\t\tp { false; print(1) }\n\t\t\t`,\n\t\t\texp: `package test\n\n\t\t\tp { false } `,\n\t\t},\n\t\t{\n\t\t\tnote: \"set comprehension body\",\n\t\t\tmodule: `package test\n\n\t\t\tp { {1 | false; print(1)} }\n\t\t\t`,\n\t\t\texp: `package test\n\n\t\t\tp { {1 | false} } `,\n\t\t},\n\t\t{\n\t\t\tnote: \"array comprehension body\",\n\t\t\tmodule: `package test\n\n\t\t\tp { [1 | false; print(1)] }\n\t\t\t`,\n\t\t\texp: `package test\n\n\t\t\tp { [1 | false] } `,\n\t\t},\n\t\t{\n\t\t\tnote: \"object comprehension body\",\n\t\t\tmodule: `package test\n\n\t\t\tp { {\"x\": 1 | false; print(1)} }\n\t\t\t`,\n\t\t\texp: `package test\n\n\t\t\tp { {\"x\": 1 | false} } `,\n\t\t},\n\t\t{\n\t\t\tnote: \"every body\",\n\t\t\tmodule: `package test\n\n\t\t\tp { every _ in [] { false; print(1) } }\n\t\t\t`,\n\t\t\texp: `package test\n\n\t\t\tp = true { __local1__ = []; every __local0__, _ in __local1__ { false } }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"in head\",\n\t\t\tmodule: `package test\n\n\t\t\tp = {1 | print(\"x\")}`,\n\t\t\texp: `package test\n\n\t\t\tp = __local0__ { true; __local0__ = {1 | true} }`,\n\t\t},\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tc := NewCompiler().WithEnablePrintStatements(false)\n\t\t\topts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\t\t\tc.Compile(map[string]*Module{\n\t\t\t\t\"test.rego\": MustParseModuleWithOpts(tc.module, opts),\n\t\t\t})\n\t\t\tif c.Failed() {\n\t\t\t\tt.Fatal(c.Errors)\n\t\t\t}\n\t\t\texp := MustParseModuleWithOpts(tc.exp, opts)\n\t\t\tif !exp.Equal(c.Modules[\"test.rego\"]) {\n\t\t\t\tt.Fatalf(\"Expected:\\n\\n%v\\n\\nGot:\\n\\n%v\", exp, c.Modules[\"test.rego\"])\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerRewritePrintCallsErrors(t *testing.T) {\n\tcases := []struct {\n\t\tnote   string\n\t\tmodule string\n\t\texp    error\n\t}{\n\t\t{\n\t\t\tnote: \"non-existent var\",\n\t\t\tmodule: `package test\n\n\t\t\tp { print(x) }`,\n\t\t\texp: errors.New(\"var x is undeclared\"),\n\t\t},\n\t\t{\n\t\t\tnote: \"declared after print\",\n\t\t\tmodule: `package test\n\n\t\t\tp { print(x); x = 7 }`,\n\t\t\texp: errors.New(\"var x is undeclared\"),\n\t\t},\n\t\t{\n\t\t\tnote: \"inside comprehension\",\n\t\t\tmodule: `package test\n\t\t\tp { {1 | print(x)} }\n\t\t\t`,\n\t\t\texp: errors.New(\"var x is undeclared\"),\n\t\t},\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tc := NewCompiler().WithEnablePrintStatements(true)\n\t\t\tc.Compile(map[string]*Module{\n\t\t\t\t\"test.rego\": MustParseModule(tc.module),\n\t\t\t})\n\t\t\tif !c.Failed() {\n\t\t\t\tt.Fatal(\"expected error\")\n\t\t\t}\n\t\t\tif c.Errors[0].Code != CompileErr || c.Errors[0].Message != tc.exp.Error() {\n\t\t\t\tt.Fatal(\"unexpected error:\", c.Errors)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerRewritePrintCalls(t *testing.T) {\n\tcases := []struct {\n\t\tnote   string\n\t\tmodule string\n\t\texp    string\n\t}{\n\t\t{\n\t\t\tnote: \"print one\",\n\t\t\tmodule: `package test\n\n\t\t\tp { print(1) }`,\n\t\t\texp: `package test\n\n\t\t\tp = true { __local1__ = {__local0__ | __local0__ = 1}; internal.print([__local1__]) }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print multiple\",\n\t\t\tmodule: `package test\n\n\t\t\tp { print(1, 2) }`,\n\t\t\texp: `package test\n\n\t\t\tp = true { __local2__ = {__local0__ | __local0__ = 1}; __local3__ = {__local1__ | __local1__ = 2}; internal.print([__local2__, __local3__]) }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print inside set comprehension\",\n\t\t\tmodule: `package test\n\n\t\t\tp { x = 1; {2 | print(x)} }`,\n\t\t\texp: `package test\n\n\t\t\tp = true { x = 1; {2 | __local1__ = {__local0__ | __local0__ = x}; internal.print([__local1__])} }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print inside array comprehension\",\n\t\t\tmodule: `package test\n\n\t\t\tp { x = 1; [2 | print(x)] }`,\n\t\t\texp: `package test\n\n\t\t\tp = true { x = 1; [2 | __local1__ = {__local0__ | __local0__ = x}; internal.print([__local1__])] }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print inside object comprehension\",\n\t\t\tmodule: `package test\n\n\t\t\tp { x = 1; {\"x\": 2 | print(x)} }`,\n\t\t\texp: `package test\n\n\t\t\tp = true { x = 1; {\"x\": 2 | __local1__ = {__local0__ | __local0__ = x}; internal.print([__local1__])} }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print inside every\",\n\t\t\tmodule: `package test\n\n\t\t\tp { every x in [1,2] { print(x) } }`,\n\t\t\texp: `package test\n\n\t\t\tp = true {\n\t\t\t\t__local3__ = [1, 2]\n\t\t\t\tevery __local0__, __local1__ in __local3__ {\n\t\t\t\t\t__local4__ = {__local2__ | __local2__ = __local1__}\n\t\t\t\t\tinternal.print([__local4__])\n\t\t\t\t}\n\t\t\t}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print output of nested call\",\n\t\t\tmodule: `package test\n\n\t\t\tp {\n\t\t\t\tx := split(\"abc\", \"\")[y]\n\t\t\t\tprint(x, y)\n\t\t\t}`,\n\t\t\texp: `package test\n\n\t\t\tp = true { split(\"abc\", \"\", __local3__); __local0__ = __local3__[y]; __local4__ = {__local1__ | __local1__ = __local0__}; __local5__ = {__local2__ | __local2__ = y}; internal.print([__local4__, __local5__]) }`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print call in head\",\n\t\t\tmodule: `package test\n\n\t\t\tp = {1 | print(\"x\") }`,\n\t\t\texp: `package test\n\n\t\t\tp = __local1__ {\n\t\t\t\ttrue\n\t\t\t\t__local1__ = {1 | __local2__ = { __local0__ | __local0__ = \"x\"}; internal.print([__local2__])}\n\t\t\t}`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print call in head - args treated as safe\",\n\t\t\tmodule: `package test\n\n\t\t\tf(a) = {1 | a[x]; print(x)}`,\n\t\t\texp: `package test\n\n\t\t\tf(__local0__) = __local2__ { true; __local2__ = {1 | __local0__[x]; __local3__ = {__local1__ | __local1__ = x}; internal.print([__local3__])} }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print call of var in head key\",\n\t\t\tmodule: `package test\n\t\t\tf(_) = [1, 2, 3]\n\t\t\tp[x] { [_, x, _] := f(true); print(x) }`,\n\t\t\texp: `package test\n\t\t\tf(__local0__) = [1, 2, 3] { true }\n\t\t\tp[__local2__] { data.test.f(true, __local5__); [__local1__, __local2__, __local3__] = __local5__; __local6__ = {__local4__ | __local4__ = __local2__}; internal.print([__local6__]) }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print call of var in head value\",\n\t\t\tmodule: `package test\n\t\t\tf(_) = [1, 2, 3]\n\t\t\tp = x { [_, x, _] := f(true); print(x) }`,\n\t\t\texp: `package test\n\t\t\tf(__local0__) = [1, 2, 3] { true }\n\t\t\tp = __local2__ { data.test.f(true, __local5__); [__local1__, __local2__, __local3__] = __local5__; __local6__ = {__local4__ | __local4__ = __local2__}; internal.print([__local6__]) }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print call of vars in head key and value\",\n\t\t\tmodule: `package test\n\t\t\tf(_) = [1, 2, 3]\n\t\t\tp[x] = y { [_, x, y] := f(true); print(x) }`,\n\t\t\texp: `package test\n\t\t\tf(__local0__) = [1, 2, 3] { true }\n\t\t\tp[__local2__] = __local3__ { data.test.f(true, __local5__); [__local1__, __local2__, __local3__] = __local5__; __local6__ = {__local4__ | __local4__ = __local2__}; internal.print([__local6__]) }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"print call of vars altered with 'with' and call\",\n\t\t\tmodule: `package test\n\t\t\tq = input\n\t\t\tp {\n\t\t\t\tx := q with input as json.unmarshal(\"{}\")\n\t\t\t\tprint(x)\n\t\t\t}`,\n\t\t\texp: `package test\n\t\t\tq = __local3__ { true; __local3__ = input }\n\t\t\tp = true {\n\t\t\t\tjson.unmarshal(\"{}\", __local2__)\n\t\t\t\t__local0__ = data.test.q with input as __local2__\n\t\t\t\t__local4__ = {__local1__ | __local1__ = __local0__}\n\t\t\t\tinternal.print([__local4__])\n\t\t\t}`,\n\t\t},\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tc := NewCompiler().WithEnablePrintStatements(true)\n\t\t\topts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\t\t\tc.Compile(map[string]*Module{\n\t\t\t\t\"test.rego\": MustParseModuleWithOpts(tc.module, opts),\n\t\t\t})\n\t\t\tif c.Failed() {\n\t\t\t\tt.Fatal(c.Errors)\n\t\t\t}\n\t\t\texp := MustParseModuleWithOpts(tc.exp, opts)\n\t\t\tif !exp.Equal(c.Modules[\"test.rego\"]) {\n\t\t\t\tt.Fatalf(\"Expected:\\n\\n%v\\n\\nGot:\\n\\n%v\", exp, c.Modules[\"test.rego\"])\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestRewritePrintCallsWithElseImplicitArgs(t *testing.T) {\n\n\tmodule := `package test\n\n\tf(x, y) {\n\t\tx = y\n\t}\n\n\telse = false {\n\t\tprint(x, y)\n\t}`\n\n\tc := NewCompiler().WithEnablePrintStatements(true)\n\topts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\tc.Compile(map[string]*Module{\n\t\t\"test.rego\": MustParseModuleWithOpts(module, opts),\n\t})\n\n\tif c.Failed() {\n\t\tt.Fatal(c.Errors)\n\t}\n\n\texp := MustParseModuleWithOpts(`package test\n\n\tf(__local0__, __local1__) = true { __local0__ = __local1__ }\n\telse = false { __local6__ = {__local4__ | __local4__ = __local2__}; __local7__ = {__local5__ | __local5__ = __local3__}; internal.print([__local6__, __local7__]) }\n\t`, opts)\n\n\t// NOTE(tsandall): we have to patch the implicit args on the else rule\n\t// because of how the parser copies the arg names across from the first\n\t// rule.\n\texp.Rules[0].Else.Head.Args[0] = VarTerm(\"__local2__\")\n\texp.Rules[0].Else.Head.Args[1] = VarTerm(\"__local3__\")\n\n\tif !exp.Equal(c.Modules[\"test.rego\"]) {\n\t\tt.Fatalf(\"Expected:\\n\\n%v\\n\\nGot:\\n\\n%v\", exp, c.Modules[\"test.rego\"])\n\t}\n}\n\nfunc TestCompilerMockFunction(t *testing.T) {\n\ttests := []struct {\n\t\tnote          string\n\t\tmodule, extra string\n\t\terr           string\n\t}{\n\t\t{\n\t\t\tnote: \"simple valid\",\n\t\t\tmodule: `package test\n\t\t\t\tnow() = 123\n\t\t\t\tp { true with time.now_ns as now }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"simple valid, simple name\",\n\t\t\tmodule: `package test\n\t\t\t\tmock_concat(_, _) = \"foo/bar\"\n\t\t\t\tp { concat(\"/\", input) with concat as mock_concat }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"invalid ref: nonexistant\",\n\t\t\tmodule: `package test\n\t\t\t\tp { true with time.now_ns as now }\n\t\t\t`,\n\t\t\terr: \"rego_unsafe_var_error: var now is unsafe\", // we're running all compiler stages here\n\t\t},\n\t\t{\n\t\t\tnote: \"valid ref: not a function, but arity = 0\",\n\t\t\tmodule: `package test\n\t\t\t\tnow = 1\n\t\t\t\tp { true with time.now_ns as now }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"ref: not a function, arity > 0\",\n\t\t\tmodule: `package test\n\t\t\t\thttp_send = { \"body\": \"nope\" }\n\t\t\t\tp { true with http.send as http_send }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"invalid ref: arity mismatch\",\n\t\t\tmodule: `package test\n\t\t\t\thttp_send(_, _) = { \"body\": \"nope\" }\n\t\t\t\tp { true with http.send as http_send }\n\t\t\t`,\n\t\t\terr: \"rego_type_error: http.send: arity mismatch\\n\\thave: (any, any)\\n\\twant: (request: object[string: any])\",\n\t\t},\n\t\t{\n\t\t\tnote: \"invalid ref: arity mismatch (in call)\",\n\t\t\tmodule: `package test\n\t\t\t\thttp_send(_, _) = { \"body\": \"nope\" }\n\t\t\t\tp { http.send({}) with http.send as http_send }\n\t\t\t`,\n\t\t\terr: \"rego_type_error: http.send: arity mismatch\\n\\thave: (any, any)\\n\\twant: (request: object[string: any])\",\n\t\t},\n\t\t{\n\t\t\tnote: \"invalid ref: value another built-in with different type\",\n\t\t\tmodule: `package test\n\t\t\t\tp { true with http.send as net.lookup_ip_addr }\n\t\t\t`,\n\t\t\terr: \"rego_type_error: http.send: arity mismatch\\n\\thave: (string)\\n\\twant: (request: object[string: any])\",\n\t\t},\n\t\t{\n\t\t\tnote: \"ref: value another built-in with compatible type\",\n\t\t\tmodule: `package test\n\t\t\t\tp { true with count as object.union_n }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"valid: package import\",\n\t\t\textra: `package mocks\n\t\t\t\thttp_send(_) = {}\n\t\t\t`,\n\t\t\tmodule: `package test\n\t\t\t\timport data.mocks\n\t\t\t\tp { true with http.send as mocks.http_send }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"valid: function import\",\n\t\t\textra: `package mocks\n\t\t\t\thttp_send(_) = {}\n\t\t\t`,\n\t\t\tmodule: `package test\n\t\t\t\timport data.mocks.http_send\n\t\t\t\tp { true with http.send as http_send }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"invalid target: relation\",\n\t\t\tmodule: `package test\n\t\t\t\tmy_walk(_, _)\n\t\t\t\tp { true with walk as my_walk }\n\t\t\t`,\n\t\t\terr: \"rego_compile_error: with keyword replacing built-in function: target must not be a relation\",\n\t\t},\n\t\t{\n\t\t\tnote: \"invalid target: eq\",\n\t\t\tmodule: `package test\n\t\t\t\tmy_eq(_, _)\n\t\t\t\tp { true with eq as my_eq }\n\t\t\t`,\n\t\t\terr: `rego_compile_error: with keyword replacing built-in function: replacement of \"eq\" invalid`,\n\t\t},\n\t\t{\n\t\t\tnote: \"invalid target: rego.metadata.chain\",\n\t\t\tmodule: `package test\n\t\t\t\tp { true with rego.metadata.chain as [] }\n\t\t\t`,\n\t\t\terr: `rego_compile_error: with keyword replacing built-in function: replacement of \"rego.metadata.chain\" invalid`,\n\t\t},\n\t\t{\n\t\t\tnote: \"invalid target: rego.metadata.rule\",\n\t\t\tmodule: `package test\n\t\t\t\tp { true with rego.metadata.rule as {} }\n\t\t\t`,\n\t\t\terr: `rego_compile_error: with keyword replacing built-in function: replacement of \"rego.metadata.rule\" invalid`,\n\t\t},\n\t\t{\n\t\t\tnote: \"invalid target: internal.print\",\n\t\t\tmodule: `package test\n\t\t\t\tmy_print(_, _)\n\t\t\t\tp { true with internal.print as my_print }\n\t\t\t`,\n\t\t\terr: `rego_compile_error: with keyword replacing built-in function: replacement of internal function \"internal.print\" invalid`,\n\t\t},\n\t\t{\n\t\t\tnote: \"mocking custom built-in\",\n\t\t\tmodule: `package test\n\t\t\t\tmock(_)\n\t\t\t\tmock_mock(_)\n\t\t\t\tp { bar(foo.bar(\"one\")) with bar as mock with foo.bar as mock_mock }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"non-built-in function replaced value\",\n\t\t\tmodule: `package test\n\t\t\t\toriginal(_)\n\t\t\t\tp { original(true) with original as 123 }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"non-built-in function replaced by another, arity 0\",\n\t\t\tmodule: `package test\n\t\t\t\toriginal() = 1\n\t\t\t\tmock() = 2\n\t\t\t\tp { original() with original as mock }\n\t\t\t`,\n\t\t\terr: \"rego_type_error: undefined function data.test.original\", // TODO(sr): file bug -- this doesn't depend on \"with\" used or not\n\t\t},\n\t\t{\n\t\t\tnote: \"non-built-in function replaced by another, arity 1\",\n\t\t\tmodule: `package test\n\t\t\t\toriginal(_)\n\t\t\t\tmock(_)\n\t\t\t\tp { original(true) with original as mock }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"non-built-in function replaced by built-in\",\n\t\t\tmodule: `package test\n\t\t\t\toriginal(_)\n\t\t\t\tp { original([1]) with original as count }\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"non-built-in function replaced by another, arity mismatch\",\n\t\t\tmodule: `package test\n\t\t\t\toriginal(_)\n\t\t\t\tmock(_, _)\n\t\t\t\tp { original([1]) with original as mock }\n\t\t\t`,\n\t\t\terr: \"rego_type_error: data.test.original: arity mismatch\\n\\thave: (any, any)\\n\\twant: (any)\",\n\t\t},\n\t\t{\n\t\t\tnote: \"non-built-in function replaced by built-in, arity mismatch\",\n\t\t\tmodule: `package test\n\t\t\t\toriginal(_)\n\t\t\t\tp { original([1]) with original as concat }\n\t\t\t`,\n\t\t\terr: \"rego_type_error: data.test.original: arity mismatch\\n\\thave: (string, any<array[string], set[string]>)\\n\\twant: (any)\",\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tc := NewCompiler().WithBuiltins(map[string]*Builtin{\n\t\t\t\t\"bar\": {\n\t\t\t\t\tName: \"bar\",\n\t\t\t\t\tDecl: types.NewFunction([]types.Type{types.S}, types.A),\n\t\t\t\t},\n\t\t\t\t\"foo.bar\": {\n\t\t\t\t\tName: \"foo.bar\",\n\t\t\t\t\tDecl: types.NewFunction([]types.Type{types.S}, types.A),\n\t\t\t\t},\n\t\t\t})\n\t\t\tif tc.extra != \"\" {\n\t\t\t\tc.Modules[\"extra\"] = MustParseModule(tc.extra)\n\t\t\t}\n\t\t\tc.Modules[\"test\"] = MustParseModule(tc.module)\n\n\t\t\t// NOTE(sr): We're running all compiler stages here, since the type checking of\n\t\t\t// built-in function replacements happens at the type check stage.\n\t\t\tc.Compile(c.Modules)\n\n\t\t\tif tc.err != \"\" {\n\t\t\t\tif !strings.Contains(c.Errors.Error(), tc.err) {\n\t\t\t\t\tt.Errorf(\"expected error to contain %q, got %q\", tc.err, c.Errors.Error())\n\t\t\t\t}\n\t\t\t} else if len(c.Errors) > 0 {\n\t\t\t\tt.Errorf(\"expected no errors, got %v\", c.Errors)\n\t\t\t}\n\t\t})\n\t}\n\n}\n\nfunc TestCompilerMockVirtualDocumentPartially(t *testing.T) {\n\tc := NewCompiler()\n\n\tc.Modules[\"test\"] = MustParseModule(`\n\tpackage test\n\tp = {\"a\": 1}\n\tq = x { p = x with p.a as 2 }\n\t`)\n\n\tcompileStages(c, c.rewriteWithModifiers)\n\tassertCompilerErrorStrings(t, c, []string{\"rego_compile_error: with keyword cannot partially replace virtual document(s)\"})\n}\n\nfunc TestCompilerCheckUnusedAssignedVar(t *testing.T) {\n\ttype testCase struct {\n\t\tnote           string\n\t\tmodule         string\n\t\texpectedErrors Errors\n\t}\n\n\tcases := []testCase{\n\t\t{\n\t\t\tnote: \"global var\",\n\t\t\tmodule: `package test\n\t\t\t\tx := 1\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"simple rule with wildcard\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\t_ := 1\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"simple rule\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tx := 1\n\t\t\t\t\ty := 2\n\t\t\t\t\tz := x + 3\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t\t&Error{Message: \"assigned var z unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with return\",\n\t\t\tmodule: `package test\n\t\t\t\tp = x {\n\t\t\t\t\tx := 2\n\t\t\t\t\ty := 3\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with function call\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tx := 2\n\t\t\t\t\ty := f(x)\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with nested array comprehension\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tx := 2\n\t\t\t\t\ty := [z | z := 2 * x]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with nested array comprehension and shadowing\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tx := 2\n\t\t\t\t\ty := [x | x := 2 * x]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with nested array comprehension and shadowing (unused shadowed var)\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tx := 2\n\t\t\t\t\ty := [x | x := 2]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var x unused\"},\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with nested array comprehension and shadowing (unused shadowing var)\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tx := 2\n\t\t\t\t\tx > 1\n\t\t\t\t\t[1 | x := 2]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var x unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with nested array comprehension and some declaration\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tsome i\n\t\t\t\t\t_ := [z | z := [1, 2][i]]\n\t\t\t\t}\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with nested set comprehension\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tx := 2\n\t\t\t\t\ty := {z | z := 2 * x}\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with nested set comprehension and unused inner var\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tx := 2\n\t\t\t\t\ty := {z | z := 2 * x; a := 2}\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var a unused\"}, // y isn't reported, as we abort early on errors when moving through the stack\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with nested object comprehension\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tx := 2\n\t\t\t\t\ty := {z: x | z := 2 * x}\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with nested closure\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tx := 1\n\t\t\t\t\ta := 1\n\t\t\t\t\t{ y | y := [ z | z:=[1,2,3][a]; z > 1 ][_] }\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var x unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"rule with nested closure and unused inner var\",\n\t\t\tmodule: `package test\n\t\t\t\tp {\n\t\t\t\t\tx := 1\n\t\t\t\t\t{ y | y := [ z | z:=[1,2,3][x]; z > 1; a := 2 ][_] }\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var a unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"simple function\",\n\t\t\tmodule: `package test\n\t\t\t\tf() {\n\t\t\t\t\tx := 1\n\t\t\t\t\ty := 2\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var x unused\"},\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"simple function with wildcard\",\n\t\t\tmodule: `package test\n\t\t\t\tf() {\n\t\t\t\t\tx := 1\n\t\t\t\t\t_ := 2\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var x unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"function with return\",\n\t\t\tmodule: `package test\n\t\t\t\tf() = x {\n\t\t\t\t\tx := 1\n\t\t\t\t\ty := 2\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"array comprehension\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = [ 1 |\n\t\t\t\t\tx := [1, 2, 3]\n\t\t\t\t\ty := 2\n\t\t\t\t\tz := x[_]\n\t\t\t\t]\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t\t&Error{Message: \"assigned var z unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"array comprehension nested\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp := [ 1 |\n\t\t\t\t\tx := 1\n\t\t\t\t\ty := [a | a := x]\n\t\t\t\t]\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"array comprehension with wildcard\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = [ 1 |\n\t\t\t\t\tx := [1, 2, 3]\n\t\t\t\t\t_ := 2\n\t\t\t\t\tz := x[_]\n\t\t\t\t]\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var z unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"array comprehension with return\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = [ z |\n\t\t\t\t\tx := [1, 2, 3]\n\t\t\t\t\ty := 2\n\t\t\t\t\tz := x[_]\n\t\t\t\t]\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"array comprehension with some\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = [ i |\n\t\t\t\t\tsome i\n\t\t\t\t\ty := 2\n\t\t\t\t]\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"set comprehension\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = { 1 |\n\t\t\t\t\tx := [1, 2, 3]\n\t\t\t\t\ty := 2\n\t\t\t\t\tz := x[_]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t\t&Error{Message: \"assigned var z unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"set comprehension nested\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp := { 1 |\n\t\t\t\t\tx := 1\n\t\t\t\t\ty := [a | a := x]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"set comprehension with wildcard\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = { 1 |\n\t\t\t\t\tx := [1, 2, 3]\n\t\t\t\t\t_ := 2\n\t\t\t\t\tz := x[_]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var z unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"set comprehension with return\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = { z |\n\t\t\t\t\tx := [1, 2, 3]\n\t\t\t\t\ty := 2\n\t\t\t\t\tz := x[_]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"set comprehension with some\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = { i |\n\t\t\t\t\tsome i\n\t\t\t\t\ty := 2\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"object comprehension\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = { 1: 2 |\n\t\t\t\t\tx := [1, 2, 3]\n\t\t\t\t\ty := 2\n\t\t\t\t\tz := x[_]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t\t&Error{Message: \"assigned var z unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"object comprehension nested\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp := { 1: 1 |\n\t\t\t\t\tx := 1\n\t\t\t\t\ty := {a: x | a := x}\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"object comprehension with wildcard\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = { 1: 2 |\n\t\t\t\t\tx := [1, 2, 3]\n\t\t\t\t\t_ := 2\n\t\t\t\t\tz := x[_]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var z unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"object comprehension with return\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = { z: x |\n\t\t\t\t\tx := [1, 2, 3]\n\t\t\t\t\ty := 2\n\t\t\t\t\tz := x[_]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"object comprehension with some\",\n\t\t\tmodule: `package test\n\t\t\t\tcomp = { i |\n\t\t\t\t\tsome i\n\t\t\t\t\ty := 2\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tnote: \"every: unused assigned var in body\",\n\t\t\tmodule: `package test\n\t\t\t\tp { every i in [1] { y := 10; i == 1 } }\n\t\t\t`,\n\t\t\texpectedErrors: Errors{\n\t\t\t\t&Error{Message: \"assigned var y unused\"},\n\t\t\t},\n\t\t},\n\t}\n\n\tmakeTestRunner := func(tc testCase, strict bool) func(t *testing.T) {\n\t\treturn func(t *testing.T) {\n\t\t\tcompiler := NewCompiler().WithStrict(strict)\n\t\t\topts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\t\t\tcompiler.Modules = map[string]*Module{\n\t\t\t\t\"test\": MustParseModuleWithOpts(tc.module, opts),\n\t\t\t}\n\t\t\tcompileStages(compiler, compiler.rewriteLocalVars)\n\n\t\t\tif strict {\n\t\t\t\tassertErrors(t, compiler.Errors, tc.expectedErrors, false)\n\t\t\t} else {\n\t\t\t\tassertNotFailed(t, compiler)\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.note+\"_strict\", makeTestRunner(tc, true))\n\t\tt.Run(tc.note+\"_non-strict\", makeTestRunner(tc, false))\n\t}\n}\n\nfunc TestCompilerSetGraph(t *testing.T) {\n\tc := NewCompiler()\n\tc.Modules = getCompilerTestModules()\n\tc.Modules[\"elsekw\"] = MustParseModule(`\n\tpackage elsekw\n\n\tp {\n\t\tfalse\n\t} else = q {\n\t\tfalse\n\t} else {\n\t\tr\n\t}\n\n\tq = true\n\tr = true\n\n\ts { t }\n\tt { false } else { true }\n\n\t`)\n\tcompileStages(c, c.setGraph)\n\n\tassertNotFailed(t, c)\n\n\tmod1 := c.Modules[\"mod1\"]\n\tp := mod1.Rules[0]\n\tq := mod1.Rules[1]\n\tmod2 := c.Modules[\"mod2\"]\n\tr := mod2.Rules[0]\n\tmod5 := c.Modules[\"mod5\"]\n\n\tedges := map[util.T]struct{}{\n\t\tq: {},\n\t\tr: {},\n\t}\n\n\tif !reflect.DeepEqual(edges, c.Graph.Dependencies(p)) {\n\t\tt.Fatalf(\"Expected dependencies for p to be q and r but got: %v\", c.Graph.Dependencies(p))\n\t}\n\n\t// NOTE(tsandall): this is the correct result but it's chosen arbitrarily for the test.\n\texpDependents := []struct {\n\t\tx    *Rule\n\t\twant map[util.T]struct{}\n\t}{\n\t\t{\n\t\t\tx:    p,\n\t\t\twant: nil,\n\t\t},\n\t\t{\n\t\t\tx:    q,\n\t\t\twant: map[util.T]struct{}{p: {}, mod5.Rules[1]: {}, mod5.Rules[3]: {}, mod5.Rules[5]: {}},\n\t\t},\n\t\t{\n\t\t\tx:    r,\n\t\t\twant: map[util.T]struct{}{p: {}},\n\t\t},\n\t}\n\n\tfor _, exp := range expDependents {\n\t\tif !reflect.DeepEqual(exp.want, c.Graph.Dependents(exp.x)) {\n\t\t\tt.Fatalf(\"Expected dependents for %v to be %v but got: %v\", exp.x, exp.want, c.Graph.Dependents(exp.x))\n\t\t}\n\t}\n\n\tsorted, ok := c.Graph.Sort()\n\tif !ok {\n\t\tt.Fatalf(\"Expected sort to succeed.\")\n\t}\n\n\tnumRules := 0\n\n\tfor _, module := range c.Modules {\n\t\tWalkRules(module, func(*Rule) bool {\n\t\t\tnumRules++\n\t\t\treturn false\n\t\t})\n\t}\n\n\tif len(sorted) != numRules {\n\t\tt.Fatalf(\"Expected numRules (%v) to be same as len(sorted) (%v)\", numRules, len(sorted))\n\t}\n\n\t// Probe rules with dependencies. Ordering is not stable for ties because\n\t// nodes are stored in a map.\n\tprobes := [][2]*Rule{\n\t\t{c.Modules[\"mod1\"].Rules[1], c.Modules[\"mod1\"].Rules[0]},               // mod1.q before mod1.p\n\t\t{c.Modules[\"mod2\"].Rules[0], c.Modules[\"mod1\"].Rules[0]},               // mod2.r before mod1.p\n\t\t{c.Modules[\"mod1\"].Rules[1], c.Modules[\"mod5\"].Rules[1]},               // mod1.q before mod5.r\n\t\t{c.Modules[\"mod1\"].Rules[1], c.Modules[\"mod5\"].Rules[3]},               // mod1.q before mod6.t\n\t\t{c.Modules[\"mod1\"].Rules[1], c.Modules[\"mod5\"].Rules[5]},               // mod1.q before mod6.v\n\t\t{c.Modules[\"mod6\"].Rules[2], c.Modules[\"mod6\"].Rules[3]},               // mod6.r before mod6.s\n\t\t{c.Modules[\"elsekw\"].Rules[1], c.Modules[\"elsekw\"].Rules[0].Else},      // elsekw.q before elsekw.p.else\n\t\t{c.Modules[\"elsekw\"].Rules[2], c.Modules[\"elsekw\"].Rules[0].Else.Else}, // elsekw.r before elsekw.p.else.else\n\t\t{c.Modules[\"elsekw\"].Rules[4], c.Modules[\"elsekw\"].Rules[3]},           // elsekw.t before elsekw.s\n\t\t{c.Modules[\"elsekw\"].Rules[4].Else, c.Modules[\"elsekw\"].Rules[3]},      // elsekw.t.else before elsekw.s\n\t}\n\n\tgetSortedIdx := func(r *Rule) int {\n\t\tfor i := range sorted {\n\t\t\tif sorted[i] == r {\n\t\t\t\treturn i\n\t\t\t}\n\t\t}\n\t\treturn -1\n\t}\n\n\tfor num, probe := range probes {\n\t\ti := getSortedIdx(probe[0])\n\t\tj := getSortedIdx(probe[1])\n\t\tif i == -1 || j == -1 {\n\t\t\tt.Fatalf(\"Expected to find probe %d in sorted slice but got: i=%d, j=%d\", num+1, i, j)\n\t\t}\n\t\tif i >= j {\n\t\t\tt.Errorf(\"Sort order of probe %d (A) %v and (B) %v and is wrong (expected A before B)\", num+1, probe[0], probe[1])\n\t\t}\n\t}\n}\n\nfunc TestGraphCycle(t *testing.T) {\n\tmod1 := `package a.b.c\n\n\tp { q }\n\tq { r }\n\tr { s }\n\ts { q }`\n\n\tc := NewCompiler()\n\tc.Modules = map[string]*Module{\n\t\t\"mod1\": MustParseModule(mod1),\n\t}\n\n\tcompileStages(c, c.setGraph)\n\tassertNotFailed(t, c)\n\n\t_, ok := c.Graph.Sort()\n\tif ok {\n\t\tt.Fatalf(\"Expected to find cycle in rule graph\")\n\t}\n\n\telsekw := `package elsekw\n\n\tp {\n\t\tfalse\n\t} else = q {\n\t\ttrue\n\t}\n\n\tq {\n\t\tfalse\n\t} else {\n\t\tr\n\t}\n\n\tr { s }\n\n\ts { p }\n\t`\n\n\tc = NewCompiler()\n\tc.Modules = map[string]*Module{\n\t\t\"elsekw\": MustParseModule(elsekw),\n\t}\n\n\tcompileStages(c, c.setGraph)\n\tassertNotFailed(t, c)\n\n\t_, ok = c.Graph.Sort()\n\tif ok {\n\t\tt.Fatalf(\"Expected to find cycle in rule graph\")\n\t}\n\n}\n\nfunc TestCompilerCheckRecursion(t *testing.T) {\n\tc := NewCompiler()\n\tc.Modules = map[string]*Module{\n\t\t\"newMod1\": MustParseModule(`package rec\n\ns = true { t }\nt = true { s }\na = true { b }\nb = true { c }\nc = true { d; e }\nd = true { true }\ne = true { a }`),\n\t\t\"newMod2\": MustParseModule(`package rec\n\nx = true { s }`,\n\t\t),\n\t\t\"newMod3\": MustParseModule(`package rec2\n\nimport data.rec.x\n\ny = true { x }`),\n\t\t\"newMod4\": MustParseModule(`package rec3\n\np[x] = y { data.rec4[x][y] = z }`,\n\t\t),\n\t\t\"newMod5\": MustParseModule(`package rec4\n\nimport data.rec3.p\n\nq[x] = y { p[x] = y }`),\n\t\t\"newMod6\": MustParseModule(`package rec5\n\nacp[x] { acq[x] }\nacq[x] { a = [true | acp[_]]; a[_] = x }\n`,\n\t\t),\n\t\t\"newMod7\": MustParseModule(`package rec6\n\nnp[x] = y { data.a[data.b.c[nq[x]]] = y }\nnq[x] = y { data.d[data.e[x].f[np[y]]] }`,\n\t\t),\n\t\t\"newMod8\": MustParseModule(`package rec7\n\nprefix = true { data.rec7 }`,\n\t\t),\n\t\t\"newMod9\": MustParseModule(`package rec8\n\ndataref = true { data }`,\n\t\t),\n\t\t\"newMod10\": MustParseModule(`package rec9\n\n\t\telse_self { false } else { else_self }\n\n\t\telsetop {\n\t\t\tfalse\n\t\t} else = elsemid {\n\t\t\ttrue\n\t\t}\n\n\t\telsemid {\n\t\t\tfalse\n\t\t} else {\n\t\t\telsebottom\n\t\t}\n\n\t\telsebottom { elsetop }\n\t\t`),\n\t\t\"fnMod1\": MustParseModule(`package f0\n\n\t\tfn(x) = y {\n\t\t\tfn(x, y)\n\t\t}`),\n\t\t\"fnMod2\": MustParseModule(`package f1\n\n\t\tfoo(x) = y {\n\t\t\tbar(\"buz\", x, y)\n\t\t}\n\n\t\tbar(x, y) = z {\n\t\t\tfoo([x, y], z)\n\t\t}`),\n\t\t\"fnMod3\": MustParseModule(`package f2\n\n\t\tfoo(x) = y {\n\t\t\tbar(\"buz\", x, y)\n\t\t}\n\n\t\tbar(x, y) = z {\n\t\t\tx = p[y]\n\t\t\tz = x\n\t\t}\n\n\t\tp[x] = y {\n\t\t\tx = \"foo.bar\"\n\t\t\tfoo(x, y)\n\t\t}`),\n\t\t\"everyMod\": MustParseModule(`package everymod\n\t\timport future.keywords.every\n\t\teveryp {\n\t\t\tevery x in [true, false] { x; everyp }\n\t\t}\n\t\teveryq[1] {\n\t\t\tevery x in everyq { x == 1 }\n\t\t}`),\n\t}\n\n\tcompileStages(c, c.checkRecursion)\n\n\tmakeRuleErrMsg := func(rule string, loop ...string) string {\n\t\treturn fmt.Sprintf(\"rego_recursion_error: rule %v is recursive: %v\", rule, strings.Join(loop, \" -> \"))\n\t}\n\n\texpected := []string{\n\t\tmakeRuleErrMsg(\"s\", \"s\", \"t\", \"s\"),\n\t\tmakeRuleErrMsg(\"t\", \"t\", \"s\", \"t\"),\n\t\tmakeRuleErrMsg(\"a\", \"a\", \"b\", \"c\", \"e\", \"a\"),\n\t\tmakeRuleErrMsg(\"b\", \"b\", \"c\", \"e\", \"a\", \"b\"),\n\t\tmakeRuleErrMsg(\"c\", \"c\", \"e\", \"a\", \"b\", \"c\"),\n\t\tmakeRuleErrMsg(\"e\", \"e\", \"a\", \"b\", \"c\", \"e\"),\n\t\tmakeRuleErrMsg(\"p\", \"p\", \"q\", \"p\"),\n\t\tmakeRuleErrMsg(\"q\", \"q\", \"p\", \"q\"),\n\t\tmakeRuleErrMsg(\"acq\", \"acq\", \"acp\", \"acq\"),\n\t\tmakeRuleErrMsg(\"acp\", \"acp\", \"acq\", \"acp\"),\n\t\tmakeRuleErrMsg(\"np\", \"np\", \"nq\", \"np\"),\n\t\tmakeRuleErrMsg(\"nq\", \"nq\", \"np\", \"nq\"),\n\t\tmakeRuleErrMsg(\"prefix\", \"prefix\", \"prefix\"),\n\t\tmakeRuleErrMsg(\"dataref\", \"dataref\", \"dataref\"),\n\t\tmakeRuleErrMsg(\"else_self\", \"else_self\", \"else_self\"),\n\t\tmakeRuleErrMsg(\"elsetop\", \"elsetop\", \"elsemid\", \"elsebottom\", \"elsetop\"),\n\t\tmakeRuleErrMsg(\"elsemid\", \"elsemid\", \"elsebottom\", \"elsetop\", \"elsemid\"),\n\t\tmakeRuleErrMsg(\"elsebottom\", \"elsebottom\", \"elsetop\", \"elsemid\", \"elsebottom\"),\n\t\tmakeRuleErrMsg(\"fn\", \"fn\", \"fn\"),\n\t\tmakeRuleErrMsg(\"foo\", \"foo\", \"bar\", \"foo\"),\n\t\tmakeRuleErrMsg(\"bar\", \"bar\", \"foo\", \"bar\"),\n\t\tmakeRuleErrMsg(\"bar\", \"bar\", \"p\", \"foo\", \"bar\"),\n\t\tmakeRuleErrMsg(\"foo\", \"foo\", \"bar\", \"p\", \"foo\"),\n\t\tmakeRuleErrMsg(\"p\", \"p\", \"foo\", \"bar\", \"p\"),\n\t\tmakeRuleErrMsg(\"everyp\", \"everyp\", \"everyp\"),\n\t\tmakeRuleErrMsg(\"everyq\", \"everyq\", \"everyq\"),\n\t}\n\n\tresult := compilerErrsToStringSlice(c.Errors)\n\tsort.Strings(expected)\n\n\tif len(result) != len(expected) {\n\t\tt.Fatalf(\"Expected %d:\\n%v\\nBut got %d:\\n%v\", len(expected), strings.Join(expected, \"\\n\"), len(result), strings.Join(result, \"\\n\"))\n\t}\n\n\tfor i := range result {\n\t\tif result[i] != expected[i] {\n\t\t\tt.Errorf(\"Expected %v but got: %v\", expected[i], result[i])\n\t\t}\n\t}\n}\n\nfunc TestCompilerCheckDynamicRecursion(t *testing.T) {\n\t// This test tries to circumvent the recursion check by using dynamic\n\t// references.  For more background info, see\n\t// <https://github.com/open-policy-agent/opa/issues/1565>.\n\n\tfor note, mod := range map[string]*Module{\n\t\t\"recursion\": MustParseModule(`\npackage recursion\npkg = \"recursion\"\nfoo[x] {\n\tdata[pkg][\"foo\"][x]\n}\n`),\n\t\t\"system.main\": MustParseModule(`\npackage system.main\nfoo {\n  data[input]\n}\n`),\n\t} {\n\t\tt.Run(note, func(t *testing.T) {\n\t\t\tc := NewCompiler()\n\t\t\tc.Modules = map[string]*Module{note: mod}\n\t\t\tcompileStages(c, c.checkRecursion)\n\n\t\t\tresult := compilerErrsToStringSlice(c.Errors)\n\t\t\texpected := \"rego_recursion_error: rule foo is recursive: foo -> foo\"\n\n\t\t\tif len(result) != 1 || result[0] != expected {\n\t\t\t\tt.Errorf(\"Expected %v but got: %v\", expected, result)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerCheckVoidCalls(t *testing.T) {\n\tc := NewCompiler().WithCapabilities(&Capabilities{Builtins: []*Builtin{\n\t\t{\n\t\t\tName: \"test\",\n\t\t\tDecl: types.NewFunction([]types.Type{types.B}, nil),\n\t\t},\n\t}})\n\tc.Compile(map[string]*Module{\n\t\t\"test.rego\": MustParseModule(`package test\n\n\t\tp {\n\t\t\tx = test(true)\n\t\t}`),\n\t})\n\tif !c.Failed() {\n\t\tt.Fatal(\"expected error\")\n\t} else if c.Errors[0].Code != TypeErr || c.Errors[0].Message != \"test(true) used as value\" {\n\t\tt.Fatal(\"unexpected error:\", c.Errors)\n\t}\n}\n\nfunc TestCompilerGetRulesExact(t *testing.T) {\n\tmods := getCompilerTestModules()\n\n\t// Add incrementally defined rules.\n\tmods[\"mod-incr\"] = MustParseModule(`package a.b.c\n\np[1] { true }\np[2] { true }`,\n\t)\n\n\tc := NewCompiler()\n\tc.Compile(mods)\n\tassertNotFailed(t, c)\n\n\ttests := []struct {\n\t\tnote     string\n\t\tref      interface{}\n\t\texpected []*Rule\n\t}{\n\t\t{\"exact\", \"data.a.b.c.p\", []*Rule{\n\t\t\tc.Modules[\"mod-incr\"].Rules[0],\n\t\t\tc.Modules[\"mod-incr\"].Rules[1],\n\t\t\tc.Modules[\"mod1\"].Rules[0],\n\t\t}},\n\t\t{\"too short\", \"data.a\", []*Rule{}},\n\t\t{\"too long/not found\", \"data.a.b.c.p.q\", []*Rule{}},\n\t\t{\"outside data\", \"input.a.b.c.p\", []*Rule{}},\n\t\t{\"non-string/var\", \"data.a.b[data.foo]\", []*Rule{}},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tvar ref Ref\n\t\t\tswitch r := tc.ref.(type) {\n\t\t\tcase string:\n\t\t\t\tref = MustParseRef(r)\n\t\t\tcase Ref:\n\t\t\t\tref = r\n\t\t\t}\n\t\t\trules := c.GetRulesExact(ref)\n\t\t\tif len(rules) != len(tc.expected) {\n\t\t\t\tt.Fatalf(\"Expected exactly %v rules but got: %v\", len(tc.expected), rules)\n\t\t\t}\n\t\t\tfor i := range rules {\n\t\t\t\tfound := false\n\t\t\t\tfor j := range tc.expected {\n\t\t\t\t\tif rules[i].Equal(tc.expected[j]) {\n\t\t\t\t\t\tfound = true\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif !found {\n\t\t\t\t\tt.Fatalf(\"Expected exactly %v but got: %v\", tc.expected, rules)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerGetRulesForVirtualDocument(t *testing.T) {\n\tmods := getCompilerTestModules()\n\n\t// Add incrementally defined rules.\n\tmods[\"mod-incr\"] = MustParseModule(`package a.b.c\n\np[1] { true }\np[2] { true }`,\n\t)\n\n\tc := NewCompiler()\n\tc.Compile(mods)\n\tassertNotFailed(t, c)\n\n\ttests := []struct {\n\t\tnote     string\n\t\tref      interface{}\n\t\texpected []*Rule\n\t}{\n\t\t{\"exact\", \"data.a.b.c.p\", []*Rule{\n\t\t\tc.Modules[\"mod-incr\"].Rules[0],\n\t\t\tc.Modules[\"mod-incr\"].Rules[1],\n\t\t\tc.Modules[\"mod1\"].Rules[0],\n\t\t}},\n\t\t{\"deep\", \"data.a.b.c.p.q\", []*Rule{\n\t\t\tc.Modules[\"mod-incr\"].Rules[0],\n\t\t\tc.Modules[\"mod-incr\"].Rules[1],\n\t\t\tc.Modules[\"mod1\"].Rules[0],\n\t\t}},\n\t\t{\"too short\", \"data.a\", []*Rule{}},\n\t\t{\"non-existent\", \"data.a.deadbeef\", []*Rule{}},\n\t\t{\"non-string/var\", \"data.a.b[data.foo]\", []*Rule{}},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tvar ref Ref\n\t\t\tswitch r := tc.ref.(type) {\n\t\t\tcase string:\n\t\t\t\tref = MustParseRef(r)\n\t\t\tcase Ref:\n\t\t\t\tref = r\n\t\t\t}\n\t\t\trules := c.GetRulesForVirtualDocument(ref)\n\t\t\tif len(rules) != len(tc.expected) {\n\t\t\t\tt.Fatalf(\"Expected exactly %v rules but got: %v\", len(tc.expected), rules)\n\t\t\t}\n\t\t\tfor i := range rules {\n\t\t\t\tfound := false\n\t\t\t\tfor j := range tc.expected {\n\t\t\t\t\tif rules[i].Equal(tc.expected[j]) {\n\t\t\t\t\t\tfound = true\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif !found {\n\t\t\t\t\tt.Fatalf(\"Expected exactly %v but got: %v\", tc.expected, rules)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerGetRulesWithPrefix(t *testing.T) {\n\tmods := getCompilerTestModules()\n\n\t// Add incrementally defined rules.\n\tmods[\"mod-incr\"] = MustParseModule(`package a.b.c\n\np[1] { true }\np[2] { true }\nq[3] { true }`,\n\t)\n\n\tc := NewCompiler()\n\tc.Compile(mods)\n\tassertNotFailed(t, c)\n\n\ttests := []struct {\n\t\tnote     string\n\t\tref      interface{}\n\t\texpected []*Rule\n\t}{\n\t\t{\"exact\", \"data.a.b.c.p\", []*Rule{\n\t\t\tc.Modules[\"mod-incr\"].Rules[0],\n\t\t\tc.Modules[\"mod-incr\"].Rules[1],\n\t\t\tc.Modules[\"mod1\"].Rules[0],\n\t\t}},\n\t\t{\"too deep\", \"data.a.b.c.p.q\", []*Rule{}},\n\t\t{\"prefix\", \"data.a.b.c\", []*Rule{\n\t\t\tc.Modules[\"mod1\"].Rules[0],\n\t\t\tc.Modules[\"mod1\"].Rules[1],\n\t\t\tc.Modules[\"mod1\"].Rules[2],\n\t\t\tc.Modules[\"mod2\"].Rules[0],\n\t\t\tc.Modules[\"mod-incr\"].Rules[0],\n\t\t\tc.Modules[\"mod-incr\"].Rules[1],\n\t\t\tc.Modules[\"mod-incr\"].Rules[2],\n\t\t}},\n\t\t{\"non-existent\", \"data.a.deadbeef\", []*Rule{}},\n\t\t{\"non-string/var\", \"data.a.b[data.foo]\", []*Rule{}},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tvar ref Ref\n\t\t\tswitch r := tc.ref.(type) {\n\t\t\tcase string:\n\t\t\t\tref = MustParseRef(r)\n\t\t\tcase Ref:\n\t\t\t\tref = r\n\t\t\t}\n\t\t\trules := c.GetRulesWithPrefix(ref)\n\t\t\tif len(rules) != len(tc.expected) {\n\t\t\t\tt.Fatalf(\"Expected exactly %v rules but got: %v\", len(tc.expected), rules)\n\t\t\t}\n\t\t\tfor i := range rules {\n\t\t\t\tfound := false\n\t\t\t\tfor j := range tc.expected {\n\t\t\t\t\tif rules[i].Equal(tc.expected[j]) {\n\t\t\t\t\t\tfound = true\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif !found {\n\t\t\t\t\tt.Fatalf(\"Expected %v but got: %v\", tc.expected, rules)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerGetRules(t *testing.T) {\n\tcompiler := getCompilerWithParsedModules(map[string]string{\n\t\t\"mod1\": `package a.b.c\n\np[x] = y { q[x] = y }\nq[\"a\"] = 1 { true }\nq[\"b\"] = 2 { true }`,\n\t})\n\n\tcompileStages(compiler, nil)\n\n\trule1 := compiler.Modules[\"mod1\"].Rules[0]\n\trule2 := compiler.Modules[\"mod1\"].Rules[1]\n\trule3 := compiler.Modules[\"mod1\"].Rules[2]\n\n\ttests := []struct {\n\t\tinput    string\n\t\texpected []*Rule\n\t}{\n\t\t{\"data.a.b.c.p\", []*Rule{rule1}},\n\t\t{\"data.a.b.c.p.x\", []*Rule{rule1}},\n\t\t{\"data.a.b.c.q\", []*Rule{rule2, rule3}},\n\t\t{\"data.a.b.c\", []*Rule{rule1, rule2, rule3}},\n\t\t{\"data.a.b.d\", nil},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.input, func(t *testing.T) {\n\t\t\tresult := compiler.GetRules(MustParseRef(tc.input))\n\n\t\t\tif len(result) != len(tc.expected) {\n\t\t\t\tt.Fatalf(\"Expected %v but got: %v\", tc.expected, result)\n\t\t\t}\n\n\t\t\tfor i := range result {\n\t\t\t\tfound := false\n\t\t\t\tfor j := range tc.expected {\n\t\t\t\t\tif result[i].Equal(tc.expected[j]) {\n\t\t\t\t\t\tfound = true\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif !found {\n\t\t\t\t\tt.Fatalf(\"Expected %v but got: %v\", tc.expected, result)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n\n}\n\nfunc TestCompilerGetRulesDynamic(t *testing.T) {\n\tcompiler := getCompilerWithParsedModules(map[string]string{\n\t\t\"mod1\": `package a.b.c.d\nr1 = 1`,\n\t\t\"mod2\": `package a.b.c.e\nr2 = 2`,\n\t\t\"mod3\": `package a.b\nr3 = 3`,\n\t\t\"hidden\": `package system.hidden\nr4 = 4`,\n\t})\n\n\tcompileStages(compiler, nil)\n\n\trule1 := compiler.Modules[\"mod1\"].Rules[0]\n\trule2 := compiler.Modules[\"mod2\"].Rules[0]\n\trule3 := compiler.Modules[\"mod3\"].Rules[0]\n\trule4 := compiler.Modules[\"hidden\"].Rules[0]\n\n\ttests := []struct {\n\t\tinput         string\n\t\texpected      []*Rule\n\t\texcludeHidden bool\n\t}{\n\t\t{input: \"data.a.b.c.d.r1\", expected: []*Rule{rule1}},\n\t\t{input: \"data.a.b[x]\", expected: []*Rule{rule1, rule2, rule3}},\n\t\t{input: \"data.a.b[x].d\", expected: []*Rule{rule1, rule3}},\n\t\t{input: \"data.a.b.c\", expected: []*Rule{rule1, rule2}},\n\t\t{input: \"data.a.b.d\"},\n\t\t{input: \"data[x]\", expected: []*Rule{rule1, rule2, rule3, rule4}},\n\t\t{input: \"data[data.complex_computation].b[y]\", expected: []*Rule{rule1, rule2, rule3}},\n\t\t{input: \"data[x][y].c.e\", expected: []*Rule{rule2}},\n\t\t{input: \"data[x][y].r3\", expected: []*Rule{rule3}},\n\t\t{input: \"data[x][y]\", expected: []*Rule{rule1, rule2, rule3}, excludeHidden: true}, // old behaviour of GetRulesDynamic\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.input, func(t *testing.T) {\n\t\t\tresult := compiler.GetRulesDynamicWithOpts(\n\t\t\t\tMustParseRef(tc.input),\n\t\t\t\tRulesOptions{IncludeHiddenModules: !tc.excludeHidden},\n\t\t\t)\n\n\t\t\tif len(result) != len(tc.expected) {\n\t\t\t\tt.Fatalf(\"Expected %v but got: %v\", tc.expected, result)\n\t\t\t}\n\n\t\t\tfor i := range result {\n\t\t\t\tfound := false\n\t\t\t\tfor j := range tc.expected {\n\t\t\t\t\tif result[i].Equal(tc.expected[j]) {\n\t\t\t\t\t\tfound = true\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif !found {\n\t\t\t\t\tt.Fatalf(\"Expected %v but got: %v\", tc.expected, result)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n\n}\n\nfunc TestCompileCustomBuiltins(t *testing.T) {\n\n\tcompiler := NewCompiler().WithBuiltins(map[string]*Builtin{\n\t\t\"baz\": {\n\t\t\tName: \"baz\",\n\t\t\tDecl: types.NewFunction([]types.Type{types.S}, types.A),\n\t\t},\n\t\t\"foo.bar\": {\n\t\t\tName: \"foo.bar\",\n\t\t\tDecl: types.NewFunction([]types.Type{types.S}, types.A),\n\t\t},\n\t})\n\n\tcompiler.Compile(map[string]*Module{\n\t\t\"test.rego\": MustParseModule(`\n\t\t\tpackage test\n\n\t\t\tp { baz(\"x\") = x }\n\t\t\tq { foo.bar(\"x\") = x }\n\t\t`),\n\t})\n\n\t// Ensure no type errors occur.\n\tif compiler.Failed() {\n\t\tt.Fatal(\"Unexpected compilation error:\", compiler.Errors)\n\t}\n\n\t_, err := compiler.QueryCompiler().Compile(MustParseBody(`baz(\"x\") = x; foo.bar(\"x\") = x`))\n\tif err != nil {\n\t\tt.Fatal(\"Unexpected compilation error:\", err)\n\t}\n\n\t// Ensure type errors occur.\n\texp1 := `rego_type_error: baz: invalid argument(s)`\n\texp2 := `rego_type_error: foo.bar: invalid argument(s)`\n\n\t_, err = compiler.QueryCompiler().Compile(MustParseBody(`baz(1) = x; foo.bar(1) = x`))\n\tif err == nil {\n\t\tt.Fatal(\"Expected compilation error\")\n\t} else if !strings.Contains(err.Error(), exp1) {\n\t\tt.Fatalf(\"Expected:\\n\\n%v\\n\\nGot:\\n\\n%v\", exp1, err)\n\t} else if !strings.Contains(err.Error(), exp2) {\n\t\tt.Fatalf(\"Expected:\\n\\n%v\\n\\nGot:\\n\\n%v\", exp2, err)\n\t}\n\n\tcompiler.Compile(map[string]*Module{\n\t\t\"test.rego\": MustParseModule(`\n\t\t\tpackage test\n\n\t\t\tp { baz(1) = x }  # type error\n\t\t\tq { foo.bar(1) = x }  # type error\n\t\t`),\n\t})\n\n\tassertCompilerErrorStrings(t, compiler, []string{exp1, exp2})\n}\n\nfunc TestCompilerLazyLoadingError(t *testing.T) {\n\n\ttestLoader := func(map[string]*Module) (map[string]*Module, error) {\n\t\treturn nil, fmt.Errorf(\"something went horribly wrong\")\n\t}\n\n\tcompiler := NewCompiler().WithModuleLoader(testLoader)\n\n\tcompiler.Compile(nil)\n\n\texpected := Errors{\n\t\tNewError(CompileErr, nil, \"something went horribly wrong\"),\n\t}\n\n\tif !reflect.DeepEqual(expected, compiler.Errors) {\n\t\tt.Fatalf(\"Expected error %v but got: %v\", expected, compiler.Errors)\n\t}\n}\n\nfunc TestCompilerLazyLoading(t *testing.T) {\n\n\tmod1 := MustParseModule(`package a.b.c\n\nimport data.x.z1 as z2\n\np = true { q; r }\nq = true { z2 }`)\n\torig1 := mod1.Copy()\n\n\tmod2 := MustParseModule(`package a.b.c\n\nr = true { true }`)\n\torig2 := mod2.Copy()\n\n\tmod3 := MustParseModule(`package x\n\nimport data.foo.bar\nimport input.input\n\nz1 = true { [localvar | count(bar.baz.qux, localvar)] }`)\n\torig3 := mod3.Copy()\n\n\tmod4 := MustParseModule(`package foo.bar.baz\n\nqux = grault { true }`)\n\torig4 := mod4.Copy()\n\n\tmod5 := MustParseModule(`package foo.bar.baz\n\nimport data.d.e.f\n\ndeadbeef = f { true }\ngrault = deadbeef { true }`)\n\torig5 := mod5.Copy()\n\n\t// testLoader will return 4 rounds of parsed modules.\n\trounds := []map[string]*Module{\n\t\t{\"mod1\": mod1, \"mod2\": mod2},\n\t\t{\"mod3\": mod3},\n\t\t{\"mod4\": mod4},\n\t\t{\"mod5\": mod5},\n\t}\n\n\t// For each round, run checks.\n\ttests := []func(map[string]*Module){\n\t\tfunc(map[string]*Module) {\n\t\t\t// first round, no modules because compiler is invoked with empty\n\t\t\t// collection.\n\t\t},\n\t\tfunc(partial map[string]*Module) {\n\t\t\tp := MustParseRule(`p = true { data.a.b.c.q; data.a.b.c.r }`)\n\t\t\tif !partial[\"mod1\"].Rules[0].Equal(p) {\n\t\t\t\tt.Errorf(\"Expected %v but got %v\", p, partial[\"mod1\"].Rules[0])\n\t\t\t}\n\t\t\tq := MustParseRule(`q = true { data.x.z1 }`)\n\t\t\tif !partial[\"mod1\"].Rules[1].Equal(q) {\n\t\t\t\tt.Errorf(\"Expected %v but got %v\", q, partial[\"mod1\"].Rules[0])\n\t\t\t}\n\t\t},\n\t\tfunc(partial map[string]*Module) {\n\t\t\tz1 := MustParseRule(`z1 = true { [localvar | count(data.foo.bar.baz.qux, localvar)] }`)\n\t\t\tif !partial[\"mod3\"].Rules[0].Equal(z1) {\n\t\t\t\tt.Errorf(\"Expected %v but got %v\", z1, partial[\"mod3\"].Rules[0])\n\t\t\t}\n\t\t},\n\t\tfunc(partial map[string]*Module) {\n\t\t\tqux := MustParseRule(`qux = grault { true }`)\n\t\t\tif !partial[\"mod4\"].Rules[0].Equal(qux) {\n\t\t\t\tt.Errorf(\"Expected %v but got %v\", qux, partial[\"mod4\"].Rules[0])\n\t\t\t}\n\t\t},\n\t\tfunc(partial map[string]*Module) {\n\t\t\tgrault := MustParseRule(`qux = data.foo.bar.baz.grault { true }`) // rewrite has not happened yet\n\t\t\tf := MustParseRule(`deadbeef = data.d.e.f { true }`)\n\t\t\tif !partial[\"mod4\"].Rules[0].Equal(grault) {\n\t\t\t\tt.Errorf(\"Expected %v but got %v\", grault, partial[\"mod4\"].Rules[0])\n\t\t\t}\n\t\t\tif !partial[\"mod5\"].Rules[0].Equal(f) {\n\t\t\t\tt.Errorf(\"Expected %v but got %v\", f, partial[\"mod5\"].Rules[0])\n\t\t\t}\n\t\t},\n\t}\n\n\tround := 0\n\n\ttestLoader := func(modules map[string]*Module) (map[string]*Module, error) {\n\t\ttests[round](modules)\n\t\tif round >= len(rounds) {\n\t\t\treturn nil, nil\n\t\t}\n\t\tresult := rounds[round]\n\t\tround++\n\t\treturn result, nil\n\t}\n\n\tcompiler := NewCompiler().WithModuleLoader(testLoader)\n\n\tif compiler.Compile(nil); compiler.Failed() {\n\t\tt.Fatalf(\"Got unexpected error from compiler: %v\", compiler.Errors)\n\t}\n\n\t// Check the original modules are still untouched.\n\tif !mod1.Equal(orig1) || !mod2.Equal(orig2) || !mod3.Equal(orig3) || !mod4.Equal(orig4) || !mod5.Equal(orig5) {\n\t\tt.Errorf(\"Compiler lazy loading modified the original modules\")\n\t}\n}\n\nfunc TestCompilerWithMetrics(t *testing.T) {\n\tm := metrics.New()\n\tc := NewCompiler().WithMetrics(m)\n\tmod := MustParseModule(testModule)\n\n\tc.Compile(map[string]*Module{\"testMod\": mod})\n\tassertNotFailed(t, c)\n\n\tif len(m.All()) == 0 {\n\t\tt.Error(\"Expected to have metrics after compiling\")\n\t}\n}\n\nfunc TestCompilerWithStageAfterWithMetrics(t *testing.T) {\n\tm := metrics.New()\n\tc := NewCompiler().WithStageAfter(\n\t\t\"CheckRecursion\",\n\t\tCompilerStageDefinition{\"MockStage\", \"mock_stage\", func(*Compiler) *Error { return nil }},\n\t)\n\n\tc.WithMetrics(m)\n\n\tmod := MustParseModule(testModule)\n\n\tc.Compile(map[string]*Module{\"testMod\": mod})\n\tassertNotFailed(t, c)\n\n\tif len(m.All()) == 0 {\n\t\tt.Error(\"Expected to have metrics after compiling\")\n\t}\n}\n\nfunc TestCompilerBuildComprehensionIndexKeySet(t *testing.T) {\n\n\ttype expectedComprehension struct {\n\t\tterm, keys string\n\t}\n\ttype exp map[int]expectedComprehension\n\ttests := []struct {\n\t\tnote      string\n\t\tmodule    string\n\t\texpected  exp\n\t\twantDebug int\n\t}{\n\t\t{\n\t\t\tnote: \"example: invert object\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\tvalue = input[i]\n\t\t\t\t\tkeys = [j | value = input[j]]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpected: exp{6: {\n\t\t\t\tterm: `[j | value = input[j]]`,\n\t\t\t\tkeys: `[value]`,\n\t\t\t}},\n\t\t\twantDebug: 1,\n\t\t},\n\t\t{\n\t\t\tnote: \"example: multiple keys from body\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\tv1 = input[i].v1\n\t\t\t\t\tv2 = input[i].v2\n\t\t\t\t\tkeys = [j | v1 = input[j].v1; v2 = input[j].v2]\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpected: exp{7: {\n\t\t\t\tterm: `[j | v1 = input[j].v1; v2 = input[j].v2]`,\n\t\t\t\tkeys: `[v1, v2]`,\n\t\t\t}},\n\t\t\twantDebug: 1,\n\t\t},\n\t\t{\n\t\t\tnote: \"example: nested comprehensions are supported\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp = {x: ys |\n\t\t\t\t\tx = input[i]\n\t\t\t\t\tys = {y | x = input[y]}\n\t\t\t\t}\n\t\t\t`,\n\t\t\texpected: exp{6: {\n\t\t\t\tterm: `{y | x = input[y]}`,\n\t\t\t\tkeys: `[x]`,\n\t\t\t}},\n\t\t\t// there are still things going on here that'll be reported, besides successful indexing\n\t\t\twantDebug: 2,\n\t\t},\n\t\t{\n\t\t\tnote: \"skip: lone comprehensions\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\t[v | input[i] = v]  # skip because no assignment\n\t\t\t\t}`,\n\t\t\twantDebug: 0,\n\t\t},\n\t\t{\n\t\t\tnote: \"skip: due to with modifier\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\tv = input[i]\n\t\t\t\t\tks = [j | input[j] = v] with data.x as 1  # skip because of with modifier\n\t\t\t\t}`,\n\t\t\twantDebug: 0,\n\t\t},\n\t\t{\n\t\t\tnote: \"skip: due to negation\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\tv = input[i]\n\t\t\t\t\ta = []\n\t\t\t\t\tnot a = [j | input[j] = v] # skip due to negation\n\t\t\t\t}`,\n\t\t\twantDebug: 0,\n\t\t},\n\t\t{\n\t\t\tnote: \"skip: due to lack of comprehension\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\tv = input[i]\n\t\t\t\t}`,\n\t\t\twantDebug: 0, // nothing interesting to report here\n\t\t},\n\t\t{\n\t\t\tnote: \"skip: due to unsafe comprehension body\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tf(x) {\n\t\t\t\t\tv = input[i]\n\t\t\t\t\tys = [y | y = x[j]]  # x is not safe\n\t\t\t\t}`,\n\t\t\twantDebug: 1,\n\t\t},\n\t\t{\n\t\t\tnote: \"skip: due to no candidates\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\tys = [y | y = input[j]]\n\t\t\t\t}`,\n\t\t\twantDebug: 1,\n\t\t},\n\t\t{\n\t\t\tnote: \"mixed: due to nested comprehension containing candidate + indexed nested comprehension with key from rule body\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp {\n\t\t\t\t\tx = input[i]                # 'x' is a candidate for z (line 7)\n\t\t\t\t\ty = 2                       # 'y' is a candidate for z\n\t\t\t\t\tz = [1 |\n\t\t\t\t\t\tx = data.foo[j]             # 'x' is an index key for z\n\t\t\t\t\t\tt = [1 | data.bar[k] = y]   # 'y' disqualifies indexing of z because it is nested inside a comprehension\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t`,\n\t\t\t// Note: no comprehension index for line 7 (`z = [ ...`)\n\t\t\texpected: exp{9: {\n\t\t\t\tkeys: `[y]`,\n\t\t\t\tterm: `[1 | data.bar[k] = y]`,\n\t\t\t}},\n\t\t\twantDebug: 2,\n\t\t},\n\t\t{\n\t\t\tnote: \"skip: avoid increasing runtime (func arg)\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tf(x) {\n\t\t\t\t\ty = input[x]\n\t\t\t\t\tys = [y | y = input[x]]\n\t\t\t\t}`,\n\t\t\twantDebug: 1,\n\t\t},\n\t\t{\n\t\t\tnote: \"skip: avoid increasing runtime (head key)\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp[x] {\n\t\t\t\t\ty = input[x]\n\t\t\t\t\tys = [y | y = input[x]]\n\t\t\t\t}`,\n\t\t\twantDebug: 1,\n\t\t},\n\t\t{\n\t\t\tnote: \"skip: avoid increasing runtime (walk)\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp[x] {\n\t\t\t\t\ty = input.bar[x]\n\t\t\t\t\tys = [y | a = input.foo; walk(a, [x, y])]\n\t\t\t\t}`,\n\t\t\twantDebug: 1,\n\t\t},\n\t\t{\n\t\t\tnote: \"bypass: use intermediate var to skip regression check\",\n\t\t\tmodule: `\n\t\t\t\tpackage test\n\n\t\t\t\tp[x] {\n\t\t\t\t\ty = input[x]\n\t\t\t\t\tys = [y | y = input[z]; z = x]\n\t\t\t\t}`,\n\t\t\texpected: exp{6: {\n\t\t\t\tterm: ` [y | y = input[z]; z = x]`,\n\t\t\t\tkeys: `[x, y]`,\n\t\t\t}},\n\t\t\twantDebug: 1,\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tdbg := bytes.Buffer{}\n\t\t\tm := metrics.New()\n\t\t\tcompiler := NewCompiler().WithMetrics(m).WithDebug(&dbg)\n\t\t\tmod, err := ParseModule(\"test.rego\", tc.module)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tcompiler.Compile(map[string]*Module{\"test.rego\": mod})\n\t\t\tif compiler.Failed() {\n\t\t\t\tt.Fatal(compiler.Errors)\n\t\t\t}\n\n\t\t\tmessages := strings.Split(dbg.String(), \"\\n\")\n\t\t\tmessages = messages[:len(messages)-1] // last one is an empty string\n\t\t\tif exp, act := tc.wantDebug, len(messages); exp != act {\n\t\t\t\tt.Errorf(\"expected %d debug messages, got %d\", exp, act)\n\t\t\t\tfor i, m := range messages {\n\t\t\t\t\tt.Logf(\"%d: %s\\n\", i, m)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tn := m.Counter(compileStageComprehensionIndexBuild).Value().(uint64)\n\t\t\tif exp, act := len(tc.expected), len(compiler.comprehensionIndices); exp != act {\n\t\t\t\tt.Fatalf(\"expected %d indices to be built. got: %d\", exp, act)\n\t\t\t}\n\t\t\tif len(tc.expected) == 0 {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif n == 0 {\n\t\t\t\tt.Fatal(\"expected counter to be incremented\")\n\t\t\t}\n\n\t\t\tfor row, exp := range tc.expected {\n\t\t\t\tvar comprehension *Term\n\t\t\t\tWalkTerms(compiler.Modules[\"test.rego\"], func(x *Term) bool {\n\t\t\t\t\tif !IsComprehension(x.Value) {\n\t\t\t\t\t\treturn true\n\t\t\t\t\t}\n\t\t\t\t\t_, ok := tc.expected[x.Location.Row]\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn false\n\t\t\t\t\t} else if comprehension != nil {\n\t\t\t\t\t\tt.Fatal(\"expected at most one comprehension per line in test module\")\n\t\t\t\t\t}\n\t\t\t\t\tcomprehension = x\n\t\t\t\t\treturn false\n\t\t\t\t})\n\t\t\t\tif comprehension == nil {\n\t\t\t\t\tt.Fatal(\"expected comprehension at line:\", row)\n\t\t\t\t}\n\n\t\t\t\tresult := compiler.ComprehensionIndex(comprehension)\n\t\t\t\tif result == nil {\n\t\t\t\t\tt.Fatal(\"expected result\")\n\t\t\t\t}\n\n\t\t\t\texpTerm := MustParseTerm(exp.term)\n\t\t\t\tif !result.Term.Equal(expTerm) {\n\t\t\t\t\tt.Fatalf(\"expected term to be %v but got: %v\", expTerm, result.Term)\n\t\t\t\t}\n\n\t\t\t\texpKeys := MustParseTerm(exp.keys).Value.(*Array)\n\t\t\t\tif NewArray(result.Keys...).Compare(expKeys) != 0 {\n\t\t\t\t\tt.Fatalf(\"expected keys to be %v but got: %v\", expKeys, result.Keys)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestCompilerAllowMultipleAssignments(t *testing.T) {\n\n\t_, err := CompileModules(map[string]string{\"test.rego\": `\n\t\tpackage test\n\n\t\tp := 7\n\t\tp := 8\n\t`})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestQueryCompiler(t *testing.T) {\n\ttests := []struct {\n\t\tnote     string\n\t\tq        string\n\t\tpkg      string\n\t\timports  []string\n\t\tinput    string\n\t\texpected interface{}\n\t}{\n\t\t{\n\t\t\tnote:     \"empty query\",\n\t\t\tq:        \"   \\t \\n # foo \\n\",\n\t\t\texpected: fmt.Errorf(\"1 error occurred: rego_compile_error: empty query cannot be compiled\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"invalid eq\",\n\t\t\tq:        \"eq()\",\n\t\t\texpected: fmt.Errorf(\"1 error occurred: 1:1: rego_type_error: eq: arity mismatch\\n\\thave: ()\\n\\twant: (any, any)\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"invalid eq\",\n\t\t\tq:        \"eq(1)\",\n\t\t\texpected: fmt.Errorf(\"1 error occurred: 1:1: rego_type_error: eq: arity mismatch\\n\\thave: (number)\\n\\twant: (any, any)\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"rewrite assignment\",\n\t\t\tq:        \"a := 1; [b, c] := data.foo\",\n\t\t\tpkg:      \"\",\n\t\t\timports:  nil,\n\t\t\texpected: \"__localq0__ = 1; [__localq1__, __localq2__] = data.foo\",\n\t\t},\n\t\t{\n\t\t\tnote:     \"exports resolved\",\n\t\t\tq:        \"z\",\n\t\t\tpkg:      `package a.b.c`,\n\t\t\timports:  nil,\n\t\t\texpected: \"data.a.b.c.z\",\n\t\t},\n\t\t{\n\t\t\tnote:     \"imports resolved\",\n\t\t\tq:        \"z\",\n\t\t\tpkg:      `package a.b.c.d`,\n\t\t\timports:  []string{\"import data.a.b.c.z\"},\n\t\t\texpected: \"data.a.b.c.z\",\n\t\t},\n\t\t{\n\t\t\tnote:     \"rewrite comprehensions\",\n\t\t\tq:        \"[x[i] | a = [[1], [2]]; x = a[j]]\",\n\t\t\tpkg:      \"\",\n\t\t\timports:  nil,\n\t\t\texpected: \"[__localq0__ | a = [[1], [2]]; x = a[j]; __localq0__ = x[i]]\",\n\t\t},\n\t\t{\n\t\t\tnote:     \"unsafe vars\",\n\t\t\tq:        \"z\",\n\t\t\tpkg:      \"\",\n\t\t\timports:  nil,\n\t\t\texpected: fmt.Errorf(\"1 error occurred: 1:1: rego_unsafe_var_error: var z is unsafe\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"unsafe var that is a future keyword\",\n\t\t\tq:        \"1 in 2\",\n\t\t\texpected: fmt.Errorf(\"1 error occurred: 1:3: rego_unsafe_var_error: var in is unsafe (hint: `import future.keywords.in` to import a future keyword)\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"unsafe declared var\",\n\t\t\tq:        \"[1 | some x; x == 1]\",\n\t\t\tpkg:      \"\",\n\t\t\timports:  nil,\n\t\t\texpected: fmt.Errorf(\"1 error occurred: 1:14: rego_unsafe_var_error: var x is unsafe\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"safe vars\",\n\t\t\tq:        `data; abc`,\n\t\t\tpkg:      `package ex`,\n\t\t\timports:  []string{\"import input.xyz as abc\"},\n\t\t\texpected: `data; input.xyz`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"reorder\",\n\t\t\tq:        `x != 1; x = 0`,\n\t\t\tpkg:      \"\",\n\t\t\timports:  nil,\n\t\t\texpected: `x = 0; x != 1`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"bad with target\",\n\t\t\tq:        \"x = 1 with foo.p as null\",\n\t\t\tpkg:      \"\",\n\t\t\timports:  nil,\n\t\t\texpected: fmt.Errorf(\"1 error occurred: 1:12: rego_type_error: with keyword target must reference existing input, data, or a function\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"rewrite with value\",\n\t\t\tq:        `1 with input as [z]`,\n\t\t\tpkg:      \"package a.b.c\",\n\t\t\timports:  nil,\n\t\t\texpected: `__localq1__ = data.a.b.c.z; __localq0__ = [__localq1__]; 1 with input as __localq0__`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"built-in function arity mismatch\",\n\t\t\tq:        `startswith(\"x\")`,\n\t\t\tpkg:      \"\",\n\t\t\timports:  nil,\n\t\t\texpected: fmt.Errorf(\"1 error occurred: 1:1: rego_type_error: startswith: arity mismatch\\n\\thave: (string)\\n\\twant: (search: string, base: string)\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"built-in function arity mismatch (arity 0)\",\n\t\t\tq:        `x := opa.runtime(\"foo\")`,\n\t\t\tpkg:      \"\",\n\t\t\timports:  nil,\n\t\t\texpected: fmt.Errorf(\"1 error occurred: 1:6: rego_type_error: opa.runtime: arity mismatch\\n\\thave: (string, ???)\\n\\twant: ()\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"built-in function arity mismatch, nested\",\n\t\t\tq:        \"count(sum())\",\n\t\t\tpkg:      \"\",\n\t\t\timports:  nil,\n\t\t\texpected: fmt.Errorf(\"1 error occurred: 1:7: rego_type_error: sum: arity mismatch\\n\\thave: (???)\\n\\twant: (collection: any<array[number], set[number]>)\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"check types\",\n\t\t\tq:        \"x = data.a.b.c.z; y = null; x = y\",\n\t\t\tpkg:      \"\",\n\t\t\timports:  nil,\n\t\t\texpected: fmt.Errorf(\"match error\\n\\tleft  : number\\n\\tright : null\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"undefined function\",\n\t\t\tq:        \"data.deadbeef(x)\",\n\t\t\texpected: fmt.Errorf(\"rego_type_error: undefined function data.deadbeef\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"imports resolved without package\",\n\t\t\tq:        \"abc\",\n\t\t\tpkg:      \"\",\n\t\t\timports:  []string{\"import input.xyz as abc\"},\n\t\t\texpected: \"input.xyz\",\n\t\t},\n\t\t{\n\t\t\tnote:     \"void call used as value\",\n\t\t\tq:        \"x = print(1)\",\n\t\t\texpected: fmt.Errorf(\"rego_type_error: print(1) used as value\"),\n\t\t},\n\t\t{\n\t\t\tnote:     \"print call erasure\",\n\t\t\tq:        `print(1)`,\n\t\t\texpected: \"true\",\n\t\t},\n\t}\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, runQueryCompilerTest(tc.q, tc.pkg, tc.imports, tc.expected))\n\t}\n}\n\nfunc TestQueryCompilerRewrittenVars(t *testing.T) {\n\ttests := []struct {\n\t\tnote string\n\t\tq    string\n\t\tvars map[string]string\n\t}{\n\t\t{\"assign\", \"a := 1\", map[string]string{\"__localq0__\": \"a\"}},\n\t\t{\"suppress only seen\", \"b = 1; a := b\", map[string]string{\"__localq0__\": \"a\"}},\n\t}\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tc := NewCompiler()\n\t\t\tc.Compile(nil)\n\t\t\tassertNotFailed(t, c)\n\t\t\tqc := c.QueryCompiler()\n\t\t\tbody, err := ParseBody(tc.q)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\t_, err = qc.Compile(body)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tvars := qc.RewrittenVars()\n\t\t\tif len(tc.vars) != len(vars) {\n\t\t\t\tt.Fatalf(\"Expected %v but got: %v\", tc.vars, vars)\n\t\t\t}\n\t\t\tfor k := range vars {\n\t\t\t\tif vars[k] != Var(tc.vars[string(k)]) {\n\t\t\t\t\tt.Fatalf(\"Expected %v but got: %v\", tc.vars, vars)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestQueryCompilerRecompile(t *testing.T) {\n\n\t// Query which contains terms that will be rewritten.\n\tparsed := MustParseBody(`a := [1]; data.bar == data.foo[a[0]]`)\n\tparsed0 := parsed\n\n\tqc := NewCompiler().QueryCompiler()\n\tcompiled, err := qc.Compile(parsed)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tcompiled2, err := qc.Compile(parsed)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif !compiled2.Equal(compiled) {\n\t\tt.Fatalf(\"Expected same compiled query. Expected: %v, Got: %v\", compiled, compiled2)\n\t}\n\n\tif !parsed0.Equal(parsed) {\n\t\tt.Fatalf(\"Expected parsed query to be unmodified. Expected %v, Got: %v\", parsed0, parsed)\n\t}\n\n}\n\nfunc TestQueryCompilerWithMetrics(t *testing.T) {\n\tm := metrics.New()\n\tc := NewCompiler().WithMetrics(m)\n\tc.Compile(getCompilerTestModules())\n\tassertNotFailed(t, c)\n\tm.Clear()\n\n\tqc := c.QueryCompiler()\n\n\tquery := MustParseBody(\"a = 1; a > 2\")\n\t_, err := qc.Compile(query)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error from %v: %v\", query, err)\n\t}\n\n\tif len(m.All()) == 0 {\n\t\tt.Error(\"Expected to have metrics after compiling\")\n\t}\n}\n\nfunc TestQueryCompilerWithStageAfterWithMetrics(t *testing.T) {\n\tm := metrics.New()\n\tc := NewCompiler().WithMetrics(m)\n\tc.Compile(getCompilerTestModules())\n\tassertNotFailed(t, c)\n\tm.Clear()\n\n\tqc := c.QueryCompiler().WithStageAfter(\n\t\t\"CheckSafety\",\n\t\tQueryCompilerStageDefinition{\n\t\t\t\"MockStage\",\n\t\t\t\"mock_stage\",\n\t\t\tfunc(_ QueryCompiler, b Body) (Body, error) {\n\t\t\t\treturn b, nil\n\t\t\t},\n\t\t})\n\n\tquery := MustParseBody(\"a = 1; a > 2\")\n\t_, err := qc.Compile(query)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error from %v: %v\", query, err)\n\t}\n\n\tif len(m.All()) == 0 {\n\t\tt.Error(\"Expected to have metrics after compiling\")\n\t}\n}\n\nfunc TestQueryCompilerWithUnsafeBuiltins(t *testing.T) {\n\ttests := []struct {\n\t\tnote     string\n\t\tquery    string\n\t\tcompiler *Compiler\n\t\topts     func(QueryCompiler) QueryCompiler\n\t\terr      string\n\t}{\n\t\t{\n\t\t\tnote:     \"builtin unsafe via compiler\",\n\t\t\tquery:    \"count([])\",\n\t\t\tcompiler: NewCompiler().WithUnsafeBuiltins(map[string]struct{}{\"count\": {}}),\n\t\t\terr:      \"unsafe built-in function calls in expression: count\",\n\t\t},\n\t\t{\n\t\t\tnote:     \"builtin unsafe via query compiler\",\n\t\t\tquery:    \"count([])\",\n\t\t\tcompiler: NewCompiler(),\n\t\t\topts: func(qc QueryCompiler) QueryCompiler {\n\t\t\t\treturn qc.WithUnsafeBuiltins(map[string]struct{}{\"count\": {}})\n\t\t\t},\n\t\t\terr: \"unsafe built-in function calls in expression: count\",\n\t\t},\n\t\t{\n\t\t\tnote:     \"builtin unsafe via compiler, 'with' mocking\",\n\t\t\tquery:    \"is_array([]) with is_array as count\",\n\t\t\tcompiler: NewCompiler().WithUnsafeBuiltins(map[string]struct{}{\"count\": {}}),\n\t\t\terr:      `with keyword replacing built-in function: target must not be unsafe: \"count\"`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"builtin unsafe via query compiler,  'with' mocking\",\n\t\t\tquery:    \"is_array([]) with is_array as count\",\n\t\t\tcompiler: NewCompiler(),\n\t\t\topts: func(qc QueryCompiler) QueryCompiler {\n\t\t\t\treturn qc.WithUnsafeBuiltins(map[string]struct{}{\"count\": {}})\n\t\t\t},\n\t\t\terr: `with keyword replacing built-in function: target must not be unsafe: \"count\"`,\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tqc := tc.compiler.QueryCompiler()\n\t\t\tif tc.opts != nil {\n\t\t\t\tqc = tc.opts(qc)\n\t\t\t}\n\t\t\t_, err := qc.Compile(MustParseBody(tc.query))\n\t\t\tvar errs Errors\n\t\t\tif !errors.As(err, &errs) {\n\t\t\t\tt.Fatalf(\"expected error type %T, got %v %[2]T\", errs, err)\n\t\t\t}\n\t\t\tif exp, act := 1, len(errs); exp != act {\n\t\t\t\tt.Fatalf(\"expected %d error(s), got %d\", exp, act)\n\t\t\t}\n\t\t\tif exp, act := tc.err, errs[0].Message; exp != act {\n\t\t\t\tt.Errorf(\"expected message %q, got %q\", exp, act)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestQueryCompilerWithDeprecatedBuiltins(t *testing.T) {\n\tcases := []strictnessQueryTestCase{\n\t\t{\n\t\t\tnote:           \"all() built-in\",\n\t\t\tquery:          \"all([true, false])\",\n\t\t\texpectedErrors: fmt.Errorf(\"1 error occurred: 1:1: rego_type_error: deprecated built-in function calls in expression: all\"),\n\t\t},\n\t\t{\n\t\t\tnote:           \"any() built-in\",\n\t\t\tquery:          \"any([true, false])\",\n\t\t\texpectedErrors: fmt.Errorf(\"1 error occurred: 1:1: rego_type_error: deprecated built-in function calls in expression: any\"),\n\t\t},\n\t}\n\n\trunStrictnessQueryTestCase(t, cases)\n}\n\nfunc TestQueryCompilerWithUnusedAssignedVar(t *testing.T) {\n\tcases := []strictnessQueryTestCase{\n\t\t{\n\t\t\tnote:           \"array comprehension\",\n\t\t\tquery:          \"[1 | x := 2]\",\n\t\t\texpectedErrors: fmt.Errorf(\"1 error occurred: 1:6: rego_compile_error: assigned var x unused\"),\n\t\t},\n\t\t{\n\t\t\tnote:           \"set comprehension\",\n\t\t\tquery:          \"{1 | x := 2}\",\n\t\t\texpectedErrors: fmt.Errorf(\"1 error occurred: 1:6: rego_compile_error: assigned var x unused\"),\n\t\t},\n\t\t{\n\t\t\tnote:           \"object comprehension\",\n\t\t\tquery:          \"{1: 2 | x := 2}\",\n\t\t\texpectedErrors: fmt.Errorf(\"1 error occurred: 1:9: rego_compile_error: assigned var x unused\"),\n\t\t},\n\t\t{\n\t\t\tnote:           \"every: unused var in body\",\n\t\t\tquery:          \"every _ in [] { x := 10 }\",\n\t\t\texpectedErrors: fmt.Errorf(\"1 error occurred: 1:17: rego_compile_error: assigned var x unused\"),\n\t\t},\n\t}\n\n\trunStrictnessQueryTestCase(t, cases)\n}\n\nfunc TestQueryCompilerCheckKeywordOverrides(t *testing.T) {\n\tcases := []strictnessQueryTestCase{\n\t\t{\n\t\t\tnote:           \"input assigned\",\n\t\t\tquery:          \"input := 1\",\n\t\t\texpectedErrors: fmt.Errorf(\"1 error occurred: 1:1: rego_compile_error: variables must not shadow input (use a different variable name)\"),\n\t\t},\n\t\t{\n\t\t\tnote:           \"data assigned\",\n\t\t\tquery:          \"data := 1\",\n\t\t\texpectedErrors: fmt.Errorf(\"1 error occurred: 1:1: rego_compile_error: variables must not shadow data (use a different variable name)\"),\n\t\t},\n\t\t{\n\t\t\tnote:           \"nested input assigned\",\n\t\t\tquery:          \"d := [input | input := 1]\",\n\t\t\texpectedErrors: fmt.Errorf(\"1 error occurred: 1:15: rego_compile_error: variables must not shadow input (use a different variable name)\"),\n\t\t},\n\t}\n\n\trunStrictnessQueryTestCase(t, cases)\n}\n\ntype strictnessQueryTestCase struct {\n\tnote           string\n\tquery          string\n\texpectedErrors error\n}\n\nfunc runStrictnessQueryTestCase(t *testing.T, cases []strictnessQueryTestCase) {\n\tt.Helper()\n\tmakeTestRunner := func(tc strictnessQueryTestCase, strict bool) func(t *testing.T) {\n\t\treturn func(t *testing.T) {\n\t\t\tc := NewCompiler().WithStrict(strict)\n\t\t\topts := ParserOptions{AllFutureKeywords: true, unreleasedKeywords: true}\n\t\t\tresult, err := c.QueryCompiler().Compile(MustParseBodyWithOpts(tc.query, opts))\n\n\t\t\tif strict {\n\t\t\t\tif err == nil {\n\t\t\t\t\tt.Fatalf(\"Expected error from %v but got: %v\", tc.query, result)\n\t\t\t\t}\n\t\t\t\tif !strings.Contains(err.Error(), tc.expectedErrors.Error()) {\n\t\t\t\t\tt.Fatalf(\"Expected error %v but got: %v\", tc.expectedErrors, err)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Unexpected error from %v: %v\", tc.query, err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.note+\"_strict\", makeTestRunner(tc, true))\n\t\tt.Run(tc.note+\"_non-strict\", makeTestRunner(tc, false))\n\t}\n}\n\nfunc assertCompilerErrorStrings(t *testing.T, compiler *Compiler, expected []string) {\n\tresult := compilerErrsToStringSlice(compiler.Errors)\n\n\tif len(result) != len(expected) {\n\t\tt.Fatalf(\"Expected %d:\\n%v\\nBut got %d:\\n%v\", len(expected), strings.Join(expected, \"\\n\"), len(result), strings.Join(result, \"\\n\"))\n\t}\n\tfor i := range result {\n\t\tif !strings.Contains(result[i], expected[i]) {\n\t\t\tt.Errorf(\"Expected %v but got: %v\", expected[i], result[i])\n\t\t}\n\t}\n}\n\nfunc assertNotFailed(t *testing.T, c *Compiler) {\n\tt.Helper()\n\tif c.Failed() {\n\t\tt.Fatalf(\"Unexpected compilation error: %v\", c.Errors)\n\t}\n}\n\nfunc getCompilerWithParsedModules(mods map[string]string) *Compiler {\n\n\tparsed := map[string]*Module{}\n\n\tfor id, input := range mods {\n\t\tmod, err := ParseModule(id, input)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\tparsed[id] = mod\n\t}\n\n\tcompiler := NewCompiler()\n\tcompiler.Modules = parsed\n\n\treturn compiler\n}\n\n// helper function to run compiler upto given stage. If nil is provided, a\n// normal compile run is performed.\nfunc compileStages(c *Compiler, upto func()) {\n\n\tc.init()\n\n\tfor name := range c.Modules {\n\t\tc.sorted = append(c.sorted, name)\n\t}\n\n\tc.localvargen = newLocalVarGeneratorForModuleSet(c.sorted, c.Modules)\n\n\tsort.Strings(c.sorted)\n\tc.SetErrorLimit(0)\n\n\tif upto == nil {\n\t\tc.compile()\n\t\treturn\n\t}\n\n\ttarget := reflect.ValueOf(upto)\n\n\tfor _, s := range c.stages {\n\t\tif s.f(); c.Failed() {\n\t\t\treturn\n\t\t}\n\t\tif reflect.ValueOf(s.f).Pointer() == target.Pointer() {\n\t\t\tbreak\n\t\t}\n\t}\n}\n\nfunc getCompilerTestModules() map[string]*Module {\n\n\tmod1 := MustParseModule(`package a.b.c\n\nimport data.x.y.z as foo\nimport data.g.h.k\n\np[x] { q[x]; not r[x] }\nq[x] { foo[i] = x }\nz = 400 { true }`,\n\t)\n\n\tmod2 := MustParseModule(`package a.b.c\n\nimport data.bar\nimport data.x.y.p\n\nr[x] { bar[x] = 100; p = 101 }`)\n\n\tmod3 := MustParseModule(`package a.b.d\n\nimport input.x as y\n\nt = true { input = {y.secret: [{y.keyid}]} }\nx = false { true }`)\n\n\tmod4 := MustParseModule(`package a.b.empty`)\n\n\tmod5 := MustParseModule(`package a.b.compr\n\nimport input.x as y\nimport data.a.b.c.q\n\np = true { [y.a | true] }\nr = true { [q.a | true] }\ns = true { [true | y.a = 0] }\nt = true { [true | q[i] = 1] }\nu = true { [true | _ = [y.a | true]] }\nv = true { [true | _ = [true | q[i] = 1]] }\n`,\n\t)\n\n\tmod6 := MustParseModule(`package a.b.nested\n\nimport data.x\nimport data.z\nimport input.x as y\n\np = true { x[y[i].a[z.b[j]]] }\nq = true { x = v; v[y[i]] }\nr = 1 { true }\ns = true { x[r] }`,\n\t)\n\n\tmod7 := MustParseModule(`package a.b.funcs\n\nfn(x) = y {\n\ttrim(x, \".\", y)\n}\n\nbar([x, y]) = [a, [b, c]] {\n\tfn(x, a)\n\ty[1].b = b\n\ty[i].a = \"hi\"\n\tc = y[i].b\n}\n\nfoorule = true {\n\tbar([\"hi.there\", [{\"a\": \"hi\", \"b\": 1}, {\"a\": \"bye\", \"b\": 0}]], [a, [b, c]])\n}`)\n\n\treturn map[string]*Module{\n\t\t\"mod1\": mod1,\n\t\t\"mod2\": mod2,\n\t\t\"mod3\": mod3,\n\t\t\"mod4\": mod4,\n\t\t\"mod5\": mod5,\n\t\t\"mod6\": mod6,\n\t\t\"mod7\": mod7,\n\t}\n}\n\nfunc compilerErrsToStringSlice(errors []*Error) []string {\n\tresult := []string{}\n\tfor _, e := range errors {\n\t\tmsg := strings.SplitN(e.Error(), \":\", 3)[2]\n\t\tresult = append(result, strings.TrimSpace(msg))\n\t}\n\tsort.Strings(result)\n\treturn result\n}\n\nfunc runQueryCompilerTest(q, pkg string, imports []string, expected interface{}) func(*testing.T) {\n\treturn func(t *testing.T) {\n\t\tt.Helper()\n\t\tc := NewCompiler().WithEnablePrintStatements(false)\n\t\tc.Compile(getCompilerTestModules())\n\t\tassertNotFailed(t, c)\n\t\tqc := c.QueryCompiler()\n\t\tquery := MustParseBody(q)\n\t\tvar qctx *QueryContext\n\n\t\tif pkg != \"\" {\n\t\t\tqctx = qctx.WithPackage(MustParsePackage(pkg))\n\t\t}\n\t\tif len(imports) != 0 {\n\t\t\tqctx = qctx.WithImports(MustParseImports(strings.Join(imports, \"\\n\")))\n\t\t}\n\n\t\tif qctx != nil {\n\t\t\tqc.WithContext(qctx)\n\t\t}\n\n\t\tswitch expected := expected.(type) {\n\t\tcase string:\n\t\t\texpectedQuery := MustParseBody(expected)\n\t\t\tresult, err := qc.Compile(query)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"Unexpected error from %v: %v\", query, err)\n\t\t\t}\n\t\t\tif !expectedQuery.Equal(result) {\n\t\t\t\tt.Fatalf(\"Expected:\\n%v\\n\\nGot:\\n%v\", expectedQuery, result)\n\t\t\t}\n\t\tcase error:\n\t\t\tresult, err := qc.Compile(query)\n\t\t\tif err == nil {\n\t\t\t\tt.Fatalf(\"Expected error from %v but got: %v\", query, result)\n\t\t\t}\n\t\t\tif !strings.Contains(err.Error(), expected.Error()) {\n\t\t\t\tt.Fatalf(\"Expected error %v but got: %v\", expected, err)\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc TestCompilerCapabilitiesExtendedWithCustomBuiltins(t *testing.T) {\n\n\tcompiler := NewCompiler().WithCapabilities(&Capabilities{\n\t\tBuiltins: []*Builtin{\n\t\t\t{\n\t\t\t\tName: \"foo\",\n\t\t\t\tDecl: types.NewFunction([]types.Type{types.N}, types.B),\n\t\t\t},\n\t\t},\n\t}).WithBuiltins(map[string]*Builtin{\n\t\t\"bar\": {\n\t\t\tName: \"bar\",\n\t\t\tDecl: types.NewFunction([]types.Type{types.N}, types.B),\n\t\t},\n\t})\n\n\tmodule1 := MustParseModule(`package test\n\n\tp { foo(1); bar(2) }`)\n\tmodule2 := MustParseModule(`package test\n\n\tp { plus(1,2,x) }`)\n\n\tcompiler.Compile(map[string]*Module{\"x\": module1})\n\tif compiler.Failed() {\n\t\tt.Fatal(\"unexpected error:\", compiler.Errors)\n\t}\n\n\tcompiler.Compile(map[string]*Module{\"x\": module2})\n\tif !compiler.Failed() {\n\t\tt.Fatal(\"expected error but got success\")\n\t}\n\n}\n\nfunc TestCompilerWithUnsafeBuiltins(t *testing.T) {\n\t// Rego includes a number of built-in functions. In some cases, you may not\n\t// want all builtins to be available to a program. This test shows how to\n\t// mark a built-in as unsafe.\n\tcompiler := NewCompiler().WithUnsafeBuiltins(map[string]struct{}{\"re_match\": {}})\n\n\t// This query should not compile because the `re_match` built-in is no\n\t// longer available.\n\t_, err := compiler.QueryCompiler().Compile(MustParseBody(`re_match(\"a\", \"a\")`))\n\tif err == nil {\n\t\tt.Fatalf(\"Expected error for unsafe built-in\")\n\t} else if !strings.Contains(err.Error(), \"unsafe built-in function\") {\n\t\tt.Fatalf(\"Expected error for unsafe built-in but got %v\", err)\n\t}\n\n\t// These modules should not compile for the same reason.\n\tmodules := map[string]*Module{\"mod1\": MustParseModule(`package a.b.c\ndeny {\n    re_match(input.user, \".*bob.*\")\n}`)}\n\tcompiler.Compile(modules)\n\tif !compiler.Failed() {\n\t\tt.Fatalf(\"Expected error for unsafe built-in\")\n\t} else if !strings.Contains(compiler.Errors[0].Error(), \"unsafe built-in function\") {\n\t\tt.Fatalf(\"Expected error for unsafe built-in but got %v\", err)\n\t}\n}\n\nfunc TestCompilerPassesTypeCheck(t *testing.T) {\n\tc := NewCompiler().\n\t\tWithCapabilities(&Capabilities{Builtins: []*Builtin{Split}})\n\t// Must compile to initialize type environment after WithCapabilities\n\tc.Compile(nil)\n\tif c.PassesTypeCheck(MustParseBody(`a = input.a; split(a, \":\", x); a0 = x[0]; a0 = null`)) {\n\t\tt.Fatal(\"Did not successfully detect a type-checking violation\")\n\t}\n}\n\nfunc TestCompilerPassesTypeCheckNegative(t *testing.T) {\n\tc := NewCompiler().\n\t\tWithCapabilities(&Capabilities{Builtins: []*Builtin{Split, StartsWith}})\n\t// Must compile to initialize type environment after WithCapabilities\n\tc.Compile(nil)\n\tif !c.PassesTypeCheck(MustParseBody(`a = input.a; split(a, \":\", x); a0 = x[0]; startswith(a0, \"foo\", true)`)) {\n\t\tt.Fatal(\"Incorrectly detected a type-checking violation\")\n\t}\n}\n\nfunc TestKeepModules(t *testing.T) {\n\n\tt.Run(\"no keep\", func(t *testing.T) {\n\t\tc := NewCompiler() // no keep is default\n\n\t\t// This one is overwritten by c.Compile()\n\t\tc.Modules[\"foo.rego\"] = MustParseModule(\"package foo\\np = true\")\n\n\t\tc.Compile(map[string]*Module{\"bar.rego\": MustParseModule(\"package bar\\np = input\")})\n\n\t\tif len(c.Errors) != 0 {\n\t\t\tt.Fatalf(\"expected no error; got %v\", c.Errors)\n\t\t}\n\n\t\tmods := c.ParsedModules()\n\t\tif mods != nil {\n\t\t\tt.Errorf(\"expected ParsedModules == nil, got %v\", mods)\n\t\t}\n\t})\n\n\tt.Run(\"keep\", func(t *testing.T) {\n\n\t\tc := NewCompiler().WithKeepModules(true)\n\n\t\t// This one is overwritten by c.Compile()\n\t\tc.Modules[\"foo.rego\"] = MustParseModule(\"package foo\\np = true\")\n\n\t\tc.Compile(map[string]*Module{\"bar.rego\": MustParseModule(\"package bar\\np = input\")})\n\t\tif len(c.Errors) != 0 {\n\t\t\tt.Fatalf(\"expected no error; got %v\", c.Errors)\n\t\t}\n\n\t\tmods := c.ParsedModules()\n\t\tif exp, act := 1, len(mods); exp != act {\n\t\t\tt.Errorf(\"expected %d modules, found %d: %v\", exp, act, mods)\n\t\t}\n\t\tfor k := range mods {\n\t\t\tif k != \"bar.rego\" {\n\t\t\t\tt.Errorf(\"unexpected key: %v, want 'bar.rego'\", k)\n\t\t\t}\n\t\t}\n\n\t\tfor k := range mods {\n\t\t\tcompiled := c.Modules[k]\n\t\t\tif compiled.Equal(mods[k]) {\n\t\t\t\tt.Errorf(\"expected module %v to not be compiled: %v\", k, mods[k])\n\t\t\t}\n\t\t}\n\n\t\t// expect ParsedModules to be reset\n\t\tc.Compile(map[string]*Module{\"baz.rego\": MustParseModule(\"package baz\\np = input\")})\n\t\tmods = c.ParsedModules()\n\t\tif exp, act := 1, len(mods); exp != act {\n\t\t\tt.Errorf(\"expected %d modules, found %d: %v\", exp, act, mods)\n\t\t}\n\t\tfor k := range mods {\n\t\t\tif k != \"baz.rego\" {\n\t\t\t\tt.Errorf(\"unexpected key: %v, want 'baz.rego'\", k)\n\t\t\t}\n\t\t}\n\n\t\tfor k := range mods {\n\t\t\tcompiled := c.Modules[k]\n\t\t\tif compiled.Equal(mods[k]) {\n\t\t\t\tt.Errorf(\"expected module %v to not be compiled: %v\", k, mods[k])\n\t\t\t}\n\t\t}\n\n\t\t// expect ParsedModules to be reset to nil\n\t\tc = c.WithKeepModules(false)\n\t\tc.Compile(map[string]*Module{\"baz.rego\": MustParseModule(\"package baz\\np = input\")})\n\t\tmods = c.ParsedModules()\n\t\tif mods != nil {\n\t\t\tt.Errorf(\"expected ParsedModules == nil, got %v\", mods)\n\t\t}\n\t})\n\n\tt.Run(\"no copies\", func(t *testing.T) {\n\t\textra := MustParseModule(\"package extra\\np = input\")\n\t\tdone := false\n\t\ttestLoader := func(map[string]*Module) (map[string]*Module, error) {\n\t\t\tif done {\n\t\t\t\treturn nil, nil\n\t\t\t}\n\t\t\tdone = true\n\t\t\treturn map[string]*Module{\"extra.rego\": extra}, nil\n\t\t}\n\n\t\tc := NewCompiler().WithModuleLoader(testLoader).WithKeepModules(true)\n\n\t\tmod := MustParseModule(\"package bar\\np = input\")\n\t\tc.Compile(map[string]*Module{\"bar.rego\": mod})\n\t\tif len(c.Errors) != 0 {\n\t\t\tt.Fatalf(\"expected no error; got %v\", c.Errors)\n\t\t}\n\n\t\tmods := c.ParsedModules()\n\t\tif exp, act := 2, len(mods); exp != act {\n\t\t\tt.Errorf(\"expected %d modules, found %d: %v\", exp, act, mods)\n\t\t}\n\t\tnewName := Var(\"q\")\n\t\tmods[\"bar.rego\"].Rules[0].Head.Name = newName\n\t\tif exp, act := newName, mod.Rules[0].Head.Name; !exp.Equal(act) {\n\t\t\tt.Errorf(\"expected modified rule name %v, found %v\", exp, act)\n\t\t}\n\t\tmods[\"extra.rego\"].Rules[0].Head.Name = newName\n\t\tif exp, act := newName, extra.Rules[0].Head.Name; !exp.Equal(act) {\n\t\t\tt.Errorf(\"expected modified rule name %v, found %v\", exp, act)\n\t\t}\n\t})\n\n\tt.Run(\"keep, with loader\", func(t *testing.T) {\n\t\textra := MustParseModule(\"package extra\\np = input\")\n\t\tdone := false\n\t\ttestLoader := func(map[string]*Module) (map[string]*Module, error) {\n\t\t\tif done {\n\t\t\t\treturn nil, nil\n\t\t\t}\n\t\t\tdone = true\n\t\t\treturn map[string]*Module{\"extra.rego\": extra}, nil\n\t\t}\n\n\t\tc := NewCompiler().WithModuleLoader(testLoader).WithKeepModules(true)\n\n\t\t// This one is overwritten by c.Compile()\n\t\tc.Modules[\"foo.rego\"] = MustParseModule(\"package foo\\np = true\")\n\n\t\tc.Compile(map[string]*Module{\"bar.rego\": MustParseModule(\"package bar\\np = input\")})\n\n\t\tif len(c.Errors) != 0 {\n\t\t\tt.Fatalf(\"expected no error; got %v\", c.Errors)\n\t\t}\n\n\t\tmods := c.ParsedModules()\n\t\tif exp, act := 2, len(mods); exp != act {\n\t\t\tt.Errorf(\"expected %d modules, found %d: %v\", exp, act, mods)\n\t\t}\n\t\tfor k := range mods {\n\t\t\tif k != \"bar.rego\" && k != \"extra.rego\" {\n\t\t\t\tt.Errorf(\"unexpected key: %v, want 'extra.rego' and 'bar.rego'\", k)\n\t\t\t}\n\t\t}\n\n\t\tfor k := range mods {\n\t\t\tcompiled := c.Modules[k]\n\t\t\tif compiled.Equal(mods[k]) {\n\t\t\t\tt.Errorf(\"expected module %v to not be compiled: %v\", k, mods[k])\n\t\t\t}\n\t\t}\n\t})\n}\n", "// Copyright 2017 The OPA Authors.  All rights reserved.\n// Use of this source code is governed by an Apache2\n// license that can be found in the LICENSE file.\n\n// nolint: goconst // string duplication is for test readability.\npackage rego\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"path/filepath\"\n\t\"reflect\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/open-policy-agent/opa/ast\"\n\t\"github.com/open-policy-agent/opa/ast/location\"\n\t\"github.com/open-policy-agent/opa/bundle\"\n\t\"github.com/open-policy-agent/opa/internal/storage/mock\"\n\t\"github.com/open-policy-agent/opa/metrics\"\n\t\"github.com/open-policy-agent/opa/storage\"\n\t\"github.com/open-policy-agent/opa/storage/inmem\"\n\t\"github.com/open-policy-agent/opa/topdown\"\n\t\"github.com/open-policy-agent/opa/topdown/builtins\"\n\t\"github.com/open-policy-agent/opa/topdown/cache\"\n\t\"github.com/open-policy-agent/opa/types\"\n\t\"github.com/open-policy-agent/opa/util\"\n\t\"github.com/open-policy-agent/opa/util/test\"\n)\n\nfunc assertEval(t *testing.T, r *Rego, expected string) {\n\tt.Helper()\n\trs, err := r.Eval(context.Background())\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\tassertResultSet(t, rs, expected)\n}\n\nfunc assertPreparedEvalQueryEval(t *testing.T, pq PreparedEvalQuery, options []EvalOption, expected string) {\n\tt.Helper()\n\trs, err := pq.Eval(context.Background(), options...)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\tassertResultSet(t, rs, expected)\n}\n\nfunc assertResultSet(t *testing.T, rs ResultSet, expected string) {\n\tt.Helper()\n\tresult := []interface{}{}\n\n\tfor i := range rs {\n\t\tvalues := []interface{}{}\n\t\tfor j := range rs[i].Expressions {\n\t\t\tvalues = append(values, rs[i].Expressions[j].Value)\n\t\t}\n\t\tresult = append(result, values)\n\t}\n\n\tif !reflect.DeepEqual(result, util.MustUnmarshalJSON([]byte(expected))) {\n\t\tt.Fatalf(\"Expected:\\n\\n%v\\n\\nGot:\\n\\n%v\", expected, result)\n\t}\n}\n\nfunc TestRegoEvalExpressionValue(t *testing.T) {\n\n\tmodule := `package test\n\n\tarr = [1,false,true]\n\tf(x) = x\n\tg(x, y) = x + y\n\th(x) = false`\n\n\ttests := []struct {\n\t\tquery    string\n\t\texpected string\n\t}{\n\t\t{\n\t\t\tquery:    \"1\",\n\t\t\texpected: \"[[1]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"1+2\",\n\t\t\texpected: \"[[3]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"1+(2*3)\",\n\t\t\texpected: \"[[7]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"data.test.arr[0]\",\n\t\t\texpected: \"[[1]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"data.test.arr[1]\",\n\t\t\texpected: \"[[false]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"data.test.f(1)\",\n\t\t\texpected: \"[[1]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"data.test.f(1,x)\",\n\t\t\texpected: \"[[true]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"data.test.g(1,2)\",\n\t\t\texpected: \"[[3]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"data.test.g(1,2,x)\",\n\t\t\texpected: \"[[true]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"false\",\n\t\t\texpected: \"[[false]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"1 == 2\",\n\t\t\texpected: \"[[false]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"data.test.h(1)\",\n\t\t\texpected: \"[[false]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"data.test.g(1,2) != 3\",\n\t\t\texpected: \"[[false]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"data.test.arr[i]\",\n\t\t\texpected: \"[[1], [true]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"[x | data.test.arr[_] = x]\",\n\t\t\texpected: \"[[[1, false, true]]]\",\n\t\t},\n\t\t{\n\t\t\tquery:    \"a = 1; b = 2; a > b\",\n\t\t\texpected: `[]`,\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.query, func(t *testing.T) {\n\t\t\tr := New(\n\t\t\t\tQuery(tc.query),\n\t\t\t\tModule(\"\", module),\n\t\t\t)\n\t\t\tassertEval(t, r, tc.expected)\n\t\t})\n\t}\n}\n\nfunc TestRegoInputs(t *testing.T) {\n\ttests := map[string]struct {\n\t\tinput    interface{}\n\t\texpected string\n\t}{\n\t\t\"map\":  {map[string]bool{\"foo\": true}, `[[{\"foo\": true}]]`},\n\t\t\"int\":  {1, `[[1]]`},\n\t\t\"bool\": {false, `[[false]]`},\n\t\t\"struct\": {struct {\n\t\t\tFoo string `json:\"baz\"`\n\t\t}{\"bar\"}, `[[{\"baz\":\"bar\"}]]`},\n\t\t\"pointer to struct\": {&struct {\n\t\t\tFoo string `json:\"baz\"`\n\t\t}{\"bar\"}, `[[{\"baz\":\"bar\"}]]`},\n\t\t\"pointer to pointer to struct\": {\n\t\t\tfunc() interface{} {\n\t\t\t\ta := &struct {\n\t\t\t\t\tFoo string `json:\"baz\"`\n\t\t\t\t}{\"bar\"}\n\t\t\t\treturn &a\n\t\t\t}(), `[[{\"baz\":\"bar\"}]]`},\n\t\t\"slice\":              {[]string{\"a\", \"b\"}, `[[[\"a\", \"b\"]]]`},\n\t\t\"nil\":                {nil, `[[null]]`},\n\t\t\"slice of interface\": {[]interface{}{\"a\", 2, true}, `[[[\"a\", 2, true]]]`},\n\t}\n\n\tfor desc, tc := range tests {\n\t\tt.Run(desc, func(t *testing.T) {\n\t\t\tr := New(\n\t\t\t\tQuery(\"input\"),\n\t\t\t\tInput(tc.input),\n\t\t\t\tSchemas(nil),\n\t\t\t)\n\t\t\tassertEval(t, r, tc.expected)\n\t\t})\n\t}\n}\n\nfunc TestRegoRewrittenVarsCapture(t *testing.T) {\n\n\tctx := context.Background()\n\n\tr := New(\n\t\tQuery(\"a := 1; a != 0; a\"),\n\t)\n\n\trs, err := r.Eval(ctx)\n\tif err != nil || len(rs) != 1 {\n\t\tt.Fatalf(\"Unexpected result: %v (err: %v)\", rs, err)\n\t}\n\n\tif !reflect.DeepEqual(rs[0].Bindings[\"a\"], json.Number(\"1\")) {\n\t\tt.Fatal(\"Expected a to be 1 but got:\", rs[0].Bindings[\"a\"])\n\t}\n\n}\n\nfunc TestRegoDoNotCaptureVoidCalls(t *testing.T) {\n\n\tctx := context.Background()\n\n\tr := New(Query(\"print(1)\"))\n\n\trs, err := r.Eval(ctx)\n\tif err != nil || len(rs) != 1 {\n\t\tt.Fatal(err, \"rs:\", rs)\n\t}\n\n\tif !rs[0].Expressions[0].Value.(bool) {\n\t\tt.Fatal(\"expected expression value to be true\")\n\t}\n}\n\nfunc TestRegoCancellation(t *testing.T) {\n\n\tast.RegisterBuiltin(&ast.Builtin{\n\t\tName: \"test.sleep\",\n\t\tDecl: types.NewFunction(\n\t\t\ttypes.Args(types.S),\n\t\t\ttypes.NewNull(),\n\t\t),\n\t})\n\n\ttopdown.RegisterFunctionalBuiltin1(\"test.sleep\", func(a ast.Value) (ast.Value, error) {\n\t\td, _ := time.ParseDuration(string(a.(ast.String)))\n\t\ttime.Sleep(d)\n\t\treturn ast.Null{}, nil\n\t})\n\n\tctx, cancel := context.WithTimeout(context.Background(), time.Millisecond*50)\n\tr := New(Query(`test.sleep(\"1s\")`))\n\trs, err := r.Eval(ctx)\n\tcancel()\n\n\tif err == nil {\n\t\tt.Fatalf(\"Expected cancellation error but got: %v\", rs)\n\t}\n\texp := topdown.Error{Code: topdown.CancelErr, Message: \"caller cancelled query execution\"}\n\tif !errors.Is(err, &exp) {\n\t\tt.Errorf(\"error: expected %v, got: %v\", exp, err)\n\t}\n}\n\nfunc TestRegoCustomBuiltinHalt(t *testing.T) {\n\n\tfunOpt := Function1(\n\t\t&Function{\n\t\t\tName: \"halt_func\",\n\t\t\tDecl: types.NewFunction(\n\t\t\t\ttypes.Args(types.S),\n\t\t\t\ttypes.NewNull(),\n\t\t\t),\n\t\t},\n\t\tfunc(BuiltinContext, *ast.Term) (*ast.Term, error) {\n\t\t\treturn nil, NewHaltError(fmt.Errorf(\"stop\"))\n\t\t},\n\t)\n\tr := New(Query(`halt_func(\"\")`), funOpt)\n\trs, err := r.Eval(context.Background())\n\tif err == nil {\n\t\tt.Fatalf(\"Expected halt error but got: %v\", rs)\n\t}\n\t// exp is the error topdown returns after unwrapping the Halt\n\texp := topdown.Error{Code: topdown.BuiltinErr, Message: \"halt_func: stop\",\n\t\tLocation: location.NewLocation([]byte(`halt_func(\"\")`), \"\", 1, 1)}\n\tif !errors.Is(err, &exp) {\n\t\tt.Fatalf(\"error: expected %v, got: %v\", exp, err)\n\t}\n}\n\nfunc TestRegoMetrics(t *testing.T) {\n\tm := metrics.New()\n\tr := New(Query(\"foo = 1\"), Module(\"foo.rego\", \"package x\"), Metrics(m))\n\tctx := context.Background()\n\t_, err := r.Eval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvalidateRegoMetrics(t, m, []string{\n\t\t\"timer_rego_query_parse_ns\",\n\t\t\"timer_rego_query_eval_ns\",\n\t\t\"timer_rego_query_compile_ns\",\n\t\t\"timer_rego_module_parse_ns\",\n\t\t\"timer_rego_module_compile_ns\",\n\t})\n}\n\nfunc TestPreparedRegoMetrics(t *testing.T) {\n\tm := metrics.New()\n\tr := New(Query(\"foo = 1\"), Module(\"foo.rego\", \"package x\"), Metrics(m))\n\tctx := context.Background()\n\tpq, err := r.PrepareForEval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t_, err = pq.Eval(ctx, EvalMetrics(m))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvalidateRegoMetrics(t, m, []string{\n\t\t\"timer_rego_query_parse_ns\",\n\t\t\"timer_rego_query_eval_ns\",\n\t\t\"timer_rego_query_compile_ns\",\n\t\t\"timer_rego_module_parse_ns\",\n\t\t\"timer_rego_module_compile_ns\",\n\t})\n}\n\nfunc TestPreparedRegoMetricsPrepareOnly(t *testing.T) {\n\tm := metrics.New()\n\tr := New(Query(\"foo = 1\"), Module(\"foo.rego\", \"package x\"), Metrics(m))\n\tctx := context.Background()\n\tpq, err := r.PrepareForEval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t_, err = pq.Eval(ctx) // No EvalMetrics() passed in\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvalidateRegoMetrics(t, m, []string{\n\t\t\"timer_rego_query_parse_ns\",\n\t\t\"timer_rego_query_compile_ns\",\n\t\t\"timer_rego_module_parse_ns\",\n\t\t\"timer_rego_module_compile_ns\",\n\t})\n}\n\nfunc TestPreparedRegoMetricsEvalOnly(t *testing.T) {\n\tm := metrics.New()\n\tr := New(Query(\"foo = 1\"), Module(\"foo.rego\", \"package x\")) // No Metrics() passed in\n\tctx := context.Background()\n\tpq, err := r.PrepareForEval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t_, err = pq.Eval(ctx, EvalMetrics(m))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvalidateRegoMetrics(t, m, []string{\n\t\t\"timer_rego_query_eval_ns\",\n\t})\n}\n\nfunc validateRegoMetrics(t *testing.T, m metrics.Metrics, expectedFields []string) {\n\tt.Helper()\n\n\tall := m.All()\n\n\tfor _, name := range expectedFields {\n\t\tvalue, ok := all[name]\n\t\tif !ok {\n\t\t\tt.Errorf(\"expected to find %v but did not\", name)\n\t\t}\n\t\tif value.(int64) == 0 {\n\t\t\tt.Errorf(\"expected metric %v to have some non-zero value, but found 0\", name)\n\t\t}\n\t}\n}\n\nfunc TestRegoInstrumentExtraEvalCompilerStage(t *testing.T) {\n\tm := metrics.New()\n\tr := New(Query(\"foo = 1\"), Module(\"foo.rego\", \"package x\"), Metrics(m), Instrument(true))\n\tctx := context.Background()\n\t_, err := r.Eval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\texp := []string{\n\t\t\"timer_query_compile_stage_rewrite_to_capture_value_ns\",\n\t}\n\n\tall := m.All()\n\n\tfor _, name := range exp {\n\t\tif _, ok := all[name]; !ok {\n\t\t\tt.Errorf(\"expected to find %v but did not\", name)\n\t\t}\n\t}\n}\n\nfunc TestPreparedRegoInstrumentExtraEvalCompilerStage(t *testing.T) {\n\tm := metrics.New()\n\tr := New(Query(\"foo = 1\"), Module(\"foo.rego\", \"package x\"), Metrics(m), Instrument(true))\n\tctx := context.Background()\n\tpq, err := r.PrepareForEval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// No metrics flag is passed in, should not affect results for compiler stage\n\t// but expect to turn off instrumentation for evaluation.\n\t_, err = pq.Eval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\texp := []string{\n\t\t\"timer_query_compile_stage_rewrite_to_capture_value_ns\",\n\t}\n\n\tnExp := []string{\n\t\t\"timer_eval_op_plug_ns\", // We should *not* see the eval timers\n\t}\n\n\tall := m.All()\n\n\tfor _, name := range exp {\n\t\tif _, ok := all[name]; !ok {\n\t\t\tt.Errorf(\"expected to find %v but did not\", name)\n\t\t}\n\t}\n\n\tfor _, name := range nExp {\n\t\tif _, ok := all[name]; ok {\n\t\t\tt.Errorf(\"did not expect to find %v\", name)\n\t\t}\n\t}\n}\n\nfunc TestRegoInstrumentExtraPartialCompilerStage(t *testing.T) {\n\tm := metrics.New()\n\tr := New(Query(\"foo = 1\"), Module(\"foo.rego\", \"package x\"), Metrics(m), Instrument(true))\n\tctx := context.Background()\n\t_, err := r.Partial(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\texp := []string{\n\t\t\"timer_query_compile_stage_rewrite_equals_ns\",\n\t}\n\n\tall := m.All()\n\n\tfor _, name := range exp {\n\t\tif _, ok := all[name]; !ok {\n\t\t\tt.Errorf(\"Expected to find %v but did not\", name)\n\t\t}\n\t}\n}\n\nfunc TestRegoInstrumentExtraPartialResultCompilerStage(t *testing.T) {\n\tm := metrics.New()\n\tr := New(Query(\"input.x\"), Module(\"foo.rego\", \"package x\"), Metrics(m), Instrument(true))\n\tctx := context.Background()\n\t_, err := r.PartialResult(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\texp := []string{\n\t\t\"timer_query_compile_stage_rewrite_for_partial_eval_ns\",\n\t}\n\n\tall := m.All()\n\n\tfor _, name := range exp {\n\t\tif _, ok := all[name]; !ok {\n\t\t\tt.Errorf(\"Expected to find '%v' in metrics\\n\\nActual:\\n %+v\", name, all)\n\t\t}\n\t}\n}\n\nfunc TestPreparedRegoTracerNoPropagate(t *testing.T) {\n\ttracer := topdown.NewBufferTracer()\n\tmod := `\n\tpackage test\n\n\tp = {\n\t\tinput.x == 10\n\t}\n\t`\n\tpq, err := New(\n\t\tQuery(\"data\"),\n\t\tModule(\"foo.rego\", mod),\n\t\tTracer(tracer),\n\t\tInput(map[string]interface{}{\"x\": 10})).PrepareForEval(context.Background())\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error %s\", err)\n\t}\n\n\t_, err = pq.Eval(context.Background()) // no EvalTracer option\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error %s\", err)\n\t}\n\n\tif len(*tracer) > 0 {\n\t\tt.Fatal(\"expected 0 traces to be collected\")\n\t}\n}\n\nfunc TestPreparedRegoQueryTracerNoPropagate(t *testing.T) {\n\ttracer := topdown.NewBufferTracer()\n\tmod := `\n\tpackage test\n\n\tp = {\n\t\tinput.x == 10\n\t}\n\t`\n\tpq, err := New(\n\t\tQuery(\"data\"),\n\t\tModule(\"foo.rego\", mod),\n\t\tQueryTracer(tracer),\n\t\tInput(map[string]interface{}{\"x\": 10})).PrepareForEval(context.Background())\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error %s\", err)\n\t}\n\n\t_, err = pq.Eval(context.Background()) // no EvalQueryTracer option\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error %s\", err)\n\t}\n\n\tif len(*tracer) > 0 {\n\t\tt.Fatal(\"expected 0 traces to be collected\")\n\t}\n}\n\nfunc TestRegoDisableIndexing(t *testing.T) {\n\ttracer := topdown.NewBufferTracer()\n\tmod := `\n\tpackage test\n\n\tp {\n\t\tinput.x = 1\n\t}\n\n\tp {\n\t\tinput.y = 1\n\t}\n\t`\n\tpq, err := New(\n\t\tQuery(\"data\"),\n\t\tModule(\"foo.rego\", mod),\n\t).PrepareForEval(context.Background())\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error %s\", err)\n\t}\n\n\t_, err = pq.Eval(\n\t\tcontext.Background(),\n\t\tEvalQueryTracer(tracer),\n\t\tEvalRuleIndexing(false),\n\t\tEvalInput(map[string]interface{}{\"x\": 10}),\n\t)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error %s\", err)\n\t}\n\n\tvar evalNodes []string\n\tfor _, e := range *tracer {\n\t\tif e.Op == topdown.EvalOp {\n\t\t\tevalNodes = append(evalNodes, string(e.Node.Loc().Text))\n\t\t}\n\t}\n\n\texpectedEvalNodes := []string{\n\t\t\"input.x = 1\",\n\t\t\"input.y = 1\",\n\t}\n\n\tfor _, expected := range expectedEvalNodes {\n\t\tfound := false\n\t\tfor _, actual := range evalNodes {\n\t\t\tif actual == expected {\n\t\t\t\tfound = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif !found {\n\t\t\tt.Fatalf(\"Missing expected eval node in trace: %q\\nGot: %q\\n\", expected, evalNodes)\n\t\t}\n\t}\n}\n\nfunc TestRegoCatchPathConflicts(t *testing.T) {\n\tr := New(\n\t\tQuery(\"data\"),\n\t\tModule(\"test.rego\", \"package x\\np=1\"),\n\t\tStore(inmem.NewFromObject(map[string]interface{}{\n\t\t\t\"x\": map[string]interface{}{\"p\": 1},\n\t\t})),\n\t)\n\n\tctx := context.Background()\n\t_, err := r.Eval(ctx)\n\n\tif err == nil {\n\t\tt.Fatal(\"expected error\")\n\t}\n}\n\nfunc TestPartialRewriteEquals(t *testing.T) {\n\tmod := `\n\tpackage test\n\tdefault p = false\n\tp {\n\t\tinput.x = 1\n\t}\n\t`\n\tr := New(\n\t\tQuery(\"data.test.p == true\"),\n\t\tModule(\"test.rego\", mod),\n\t)\n\n\tctx := context.Background()\n\tpq, err := r.Partial(ctx)\n\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error from Rego.Partial(): %s\", err.Error())\n\t}\n\n\t// Expect to not have any \"support\" in the resulting queries\n\tif len(pq.Support) > 0 {\n\t\tt.Errorf(\"expected to not have any Support in PartialQueries: %+v\", pq)\n\t}\n\n\texpectedQuery := \"input.x = 1\"\n\tif len(pq.Queries) != 1 {\n\t\tt.Errorf(\"expected 1 query but found %d: %+v\", len(pq.Queries), pq)\n\t}\n\tif pq.Queries[0].String() != expectedQuery {\n\t\tt.Errorf(\"unexpected query in result, expected='%s' found='%s'\",\n\t\t\texpectedQuery, pq.Queries[0].String())\n\t}\n}\n\n// NOTE(sr): https://github.com/open-policy-agent/opa/issues/4345\nfunc TestPrepareAndEvalRaceConditions(t *testing.T) {\n\ttests := []struct {\n\t\tnote   string\n\t\tmodule string\n\t\texp    string\n\t}{\n\t\t{\n\t\t\tnote: \"object\",\n\t\t\tmodule: `package test\n\t\t\tp[{\"x\":\"y\"}]`,\n\t\t\texp: `[[[{\"x\":\"y\"}]]]`,\n\t\t},\n\t\t{\n\t\t\tnote: \"set\",\n\t\t\tmodule: `package test\n\t\t\tp[{\"x\"}]`,\n\t\t\texp: `[[[[\"x\"]]]]`,\n\t\t},\n\t\t{\n\t\t\tnote: \"array\",\n\t\t\tmodule: `package test\n\t\t\tp[[\"x\"]]`,\n\t\t\texp: `[[[[\"x\"]]]]`,\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tr := New(\n\t\t\t\tQuery(\"data.test.p\"),\n\t\t\t\tModule(\"\", tc.module),\n\t\t\t\tPackage(\"foo\"),\n\t\t\t)\n\n\t\t\tpq, err := r.PrepareForEval(context.Background())\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t\t\t}\n\n\t\t\t// run this 1000 times concurrently\n\t\t\tvar wg sync.WaitGroup\n\t\t\twg.Add(1000)\n\t\t\tfor i := 0; i < 1000; i++ {\n\t\t\t\tgo func(t *testing.T) {\n\t\t\t\t\tt.Helper()\n\t\t\t\t\tassertPreparedEvalQueryEval(t, pq, []EvalOption{}, tc.exp)\n\t\t\t\t\twg.Done()\n\t\t\t\t}(t)\n\t\t\t}\n\t\t\twg.Wait()\n\t\t})\n\t}\n}\n\nfunc TestPrepareAndEvalNewInput(t *testing.T) {\n\tmodule := `\n\tpackage test\n\tx = input.y\n\t`\n\n\tr := New(\n\t\tQuery(\"data.test.x\"),\n\t\tModule(\"\", module),\n\t\tPackage(\"foo\"),\n\t)\n\n\tpq, err := r.PrepareForEval(context.Background())\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{\n\t\tEvalInput(map[string]int{\"y\": 1}),\n\t}, \"[[1]]\")\n}\n\nfunc TestPrepareAndEvalNewMetrics(t *testing.T) {\n\tmodule := `\n\tpackage test\n\tx = input.y\n\t`\n\n\toriginalMetrics := metrics.New()\n\n\tr := New(\n\t\tQuery(\"data.test.x\"),\n\t\tModule(\"\", module),\n\t\tPackage(\"foo\"),\n\t\tMetrics(originalMetrics),\n\t)\n\n\tpq, err := r.PrepareForEval(context.Background())\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\n\tif len(originalMetrics.All()) == 0 {\n\t\tt.Errorf(\"Expected metrics stored on 'originalMetrics' after Prepare()\")\n\t}\n\n\t// Reset the original ones (for testing)\n\t// and make a new one for the Eval\n\toriginalMetrics.Clear()\n\tnewMetrics := metrics.New()\n\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{\n\t\tEvalInput(map[string]int{\"y\": 1}),\n\t\tEvalMetrics(newMetrics),\n\t}, \"[[1]]\")\n\n\tif len(originalMetrics.All()) > 0 {\n\t\tt.Errorf(\"Expected no metrics stored on original Rego object metrics but found: %s\",\n\t\t\toriginalMetrics.All())\n\t}\n\n\tif len(newMetrics.All()) == 0 {\n\t\tt.Errorf(\"Expected metrics stored on 'newMetrics' after Prepare()\")\n\t}\n}\n\nfunc TestPrepareAndEvalTransaction(t *testing.T) {\n\tmodule := `\n\tpackage test\n\tx = data.foo.y\n\t`\n\tctx := context.Background()\n\tstore := mock.New()\n\ttxn := storage.NewTransactionOrDie(ctx, store, storage.WriteParams)\n\n\tpath, ok := storage.ParsePath(\"/foo\")\n\tif !ok {\n\t\tt.Fatalf(\"Unexpected error parsing path\")\n\t}\n\n\terr := storage.MakeDir(ctx, store, txn, path)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error writing to store: %s\", err.Error())\n\t}\n\n\terr = store.Write(ctx, txn, storage.AddOp, path, map[string]interface{}{\"y\": 1})\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error writing to store: %s\", err.Error())\n\t}\n\n\tr := New(\n\t\tQuery(\"data.test.x\"),\n\t\tModule(\"\", module),\n\t\tStore(store),\n\t\tTransaction(txn),\n\t)\n\n\tpq, err := r.PrepareForEval(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\n\t// Base case, expect it to use the transaction provided\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{EvalTransaction(txn)}, \"[[1]]\")\n\n\tmockTxn := store.GetTransaction(txn.ID())\n\tfor _, read := range store.Reads {\n\t\tif read.Transaction != mockTxn {\n\t\t\tt.Errorf(\"Found read operation with an invalid transaction, expected: %d, found: %d\", mockTxn.ID(), read.Transaction.ID())\n\t\t}\n\t}\n\n\tstore.AssertValid(t)\n\tstore.Reset()\n\n\t// Case with an update to the store and a new transaction\n\ttxn = storage.NewTransactionOrDie(ctx, store, storage.WriteParams)\n\terr = store.Write(ctx, txn, storage.AddOp, path, map[string]interface{}{\"y\": 2})\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error writing to store: %s\", err.Error())\n\t}\n\n\t// Expect the new result from the updated value on this transaction\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{EvalTransaction(txn)}, \"[[2]]\")\n\n\terr = store.Commit(ctx, txn)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error committing to store: %s\", err)\n\t}\n\n\tnewMockTxn := store.GetTransaction(txn.ID())\n\tfor _, read := range store.Reads {\n\t\tif read.Transaction != newMockTxn {\n\t\t\tt.Errorf(\"Found read operation with an invalid transaction, expected: %d, found: %d\", mockTxn.ID(), read.Transaction.ID())\n\t\t}\n\t}\n\n\tstore.AssertValid(t)\n\tstore.Reset()\n\n\t// Case with no transaction provided, should create a new one and see the latest value\n\ttxn = storage.NewTransactionOrDie(ctx, store, storage.WriteParams)\n\terr = store.Write(ctx, txn, storage.AddOp, path, map[string]interface{}{\"y\": 3})\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error writing to store: %s\", err.Error())\n\t}\n\terr = store.Commit(ctx, txn)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error committing to store: %s\", err)\n\t}\n\n\tassertPreparedEvalQueryEval(t, pq, nil, \"[[3]]\")\n\n\tif len(store.Transactions) != 2 {\n\t\tt.Fatalf(\"Expected only two transactions on store, found %d\", len(store.Transactions))\n\t}\n\n\tautoTxn := store.Transactions[1]\n\tfor _, read := range store.Reads {\n\t\tif read.Transaction != autoTxn {\n\t\t\tt.Errorf(\"Found read operation with an invalid transaction, expected: %d, found: %d\", autoTxn, read.Transaction.ID())\n\t\t}\n\t}\n\tstore.AssertValid(t)\n\n}\n\nfunc TestPrepareAndEvalIdempotent(t *testing.T) {\n\tmodule := `\n\tpackage test\n\tx = input.y\n\t`\n\n\tr := New(\n\t\tQuery(\"data.test.x\"),\n\t\tModule(\"\", module),\n\t\tPackage(\"foo\"),\n\t)\n\n\tpq, err := r.PrepareForEval(context.Background())\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\n\t// Expect evaluating the same thing >1 time gives the same\n\t// results each time.\n\tfor i := 0; i < 5; i++ {\n\t\tassertPreparedEvalQueryEval(t, pq, []EvalOption{\n\t\t\tEvalInput(map[string]int{\"y\": 1}),\n\t\t}, \"[[1]]\")\n\t}\n}\n\nfunc TestPrepareAndEvalOriginal(t *testing.T) {\n\tmodule := `\n\tpackage test\n\tx = input.y\n\t`\n\n\tr := New(\n\t\tQuery(\"data.test.x\"),\n\t\tModule(\"\", module),\n\t\tPackage(\"foo\"),\n\t\tInput(map[string]int{\"y\": 2}),\n\t)\n\n\tpq, err := r.PrepareForEval(context.Background())\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{\n\t\tEvalInput(map[string]int{\"y\": 1}),\n\t}, \"[[1]]\")\n\n\t// Even after prepare and eval with different input\n\t// expect that the original Rego object behaves\n\t// as expected for Eval.\n\n\tassertEval(t, r, \"[[2]]\")\n}\n\nfunc TestPrepareAndEvalNewPrintHook(t *testing.T) {\n\tmodule := `\n\tpackage test\n\tx { print(input) }\n\t`\n\n\tr := New(\n\t\tQuery(\"data.test.x\"),\n\t\tModule(\"\", module),\n\t\tPackage(\"foo\"),\n\t\tEnablePrintStatements(true),\n\t)\n\n\tpq, err := r.PrepareForEval(context.Background())\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\n\tvar buf0 bytes.Buffer\n\tph0 := topdown.NewPrintHook(&buf0)\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{\n\t\tEvalInput(\"hello\"),\n\t\tEvalPrintHook(ph0),\n\t}, \"[[true]]\")\n\n\tif exp, act := \"hello\\n\", buf0.String(); exp != act {\n\t\tt.Fatalf(\"print hook, expected %q, got %q\", exp, act)\n\t}\n\n\t// repeat\n\tvar buf1 bytes.Buffer\n\tph1 := topdown.NewPrintHook(&buf1)\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{\n\t\tEvalInput(\"world\"),\n\t\tEvalPrintHook(ph1),\n\t}, \"[[true]]\")\n\n\tif exp, act := \"world\\n\", buf1.String(); exp != act {\n\t\tt.Fatalf(\"print hook, expected %q, got %q\", exp, act)\n\t}\n}\n\nfunc TestPrepareAndPartialResult(t *testing.T) {\n\tmodule := `\n\tpackage test\n\tx = input.y\n\t`\n\n\tr := New(\n\t\tQuery(\"data.test.x\"),\n\t\tModule(\"\", module),\n\t\tPackage(\"foo\"),\n\t\tInput(map[string]int{\"y\": 2}),\n\t)\n\n\tctx := context.Background()\n\n\tpq, err := r.PrepareForEval(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{\n\t\tEvalInput(map[string]int{\"y\": 1}),\n\t}, \"[[1]]\")\n\n\t// Even after prepare and eval with different input\n\t// expect that the original Rego object behaves\n\t// as expected for PartialResult.\n\n\tpartial, err := r.PartialResult(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tr2 := partial.Rego(\n\t\tInput(map[string]int{\"y\": 7}),\n\t)\n\tassertEval(t, r2, \"[[7]]\")\n}\n\nfunc TestPrepareWithPartialEval(t *testing.T) {\n\tmodule := `\n\tpackage test\n\tx = input.y\n\t`\n\n\tr := New(\n\t\tQuery(\"data.test.x\"),\n\t\tModule(\"\", module),\n\t\tPackage(\"foo\"),\n\t)\n\n\tctx := context.Background()\n\n\t// Prepare the query and partially evaluate it\n\tpq, err := r.PrepareForEval(ctx, WithPartialEval())\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{\n\t\tEvalInput(map[string]int{\"y\": 1}),\n\t}, \"[[1]]\")\n}\n\nfunc TestPrepareAndPartial(t *testing.T) {\n\tmod := `\n\tpackage test\n\tdefault p = false\n\tp {\n\t\tinput.x = 1\n\t}\n\t`\n\tr := New(\n\t\tQuery(\"data.test.p == true\"),\n\t\tModule(\"test.rego\", mod),\n\t)\n\n\tctx := context.Background()\n\n\tpq, err := r.PrepareForEval(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{\n\t\tEvalInput(map[string]int{\"x\": 1}),\n\t}, \"[[true]]\")\n\n\t// Even after prepare and eval with different input\n\t// expect that the original Rego object behaves\n\t// as expected for Partial.\n\n\tpartialQuery, err := r.Partial(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\texpectedQuery := \"input.x = 1\"\n\tif len(partialQuery.Queries) != 1 {\n\t\tt.Errorf(\"expected 1 query but found %d: %+v\", len(partialQuery.Queries), pq)\n\t}\n\tif partialQuery.Queries[0].String() != expectedQuery {\n\t\tt.Errorf(\"unexpected query in result, expected='%s' found='%s'\",\n\t\t\texpectedQuery, partialQuery.Queries[0].String())\n\t}\n}\n\nfunc TestPartialNamespace(t *testing.T) {\n\n\tr := New(\n\t\tPartialNamespace(\"foo\"),\n\t\tQuery(\"data.test.p = x\"),\n\t\tModule(\"test.rego\", `\n\t\t\tpackage test\n\n\t\t\tdefault p = false\n\n\t\t\tp { input.x = 1 }\n\t\t`),\n\t)\n\n\tpq, err := r.Partial(context.Background())\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\texpQuery := ast.MustParseBody(`data.foo.test.p = x`)\n\n\tif len(pq.Queries) != 1 || !pq.Queries[0].Equal(expQuery) {\n\t\tt.Fatalf(\"Expected exactly one query %v but got: %v\", expQuery, pq.Queries)\n\t}\n\n\texpSupport := ast.MustParseModule(`\n\t\tpackage foo.test\n\n\t\tdefault p = false\n\n\t\tp { input.x = 1 }\n\t`)\n\n\tif len(pq.Support) != 1 || !pq.Support[0].Equal(expSupport) {\n\t\tt.Fatalf(\"Expected exactly one support:\\n\\n%v\\n\\nGot:\\n\\n%v\", expSupport, pq.Support[0])\n\t}\n}\n\nfunc TestPrepareAndCompile(t *testing.T) {\n\tmodule := `\n\tpackage test\n\tx = input.y\n\t`\n\n\tr := New(\n\t\tQuery(\"data.test.x\"),\n\t\tModule(\"\", module),\n\t\tPackage(\"foo\"),\n\t)\n\n\tctx := context.Background()\n\n\tpq, err := r.PrepareForEval(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{\n\t\tEvalInput(map[string]int{\"y\": 1}),\n\t}, \"[[1]]\")\n\n\t// Ensure that Compile still works after Prepare\n\t// and its Eval has been called.\n\t_, err = r.Compile(ctx)\n\tif err != nil {\n\t\tt.Errorf(\"Unexpected error when compiling: %s\", err.Error())\n\t}\n}\n\nfunc TestPartialResultWithInput(t *testing.T) {\n\tmod := `\n\tpackage test\n\tdefault p = false\n\tp {\n\t\tinput.x == 1\n\t}\n\t`\n\tr := New(\n\t\tQuery(\"data.test.p\"),\n\t\tModule(\"test.rego\", mod),\n\t)\n\n\tctx := context.Background()\n\tpr, err := r.PartialResult(ctx)\n\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error from Rego.PartialResult(): %s\", err.Error())\n\t}\n\n\tr2 := pr.Rego(\n\t\tInput(map[string]int{\"x\": 1}),\n\t)\n\n\tassertEval(t, r2, \"[[true]]\")\n}\n\nfunc TestPartialResultWithNamespace(t *testing.T) {\n\tmod := `\n\tpackage test\n\tp {\n\t\ttrue\n\t}\n\t`\n\tc := ast.NewCompiler()\n\tr := New(\n\t\tQuery(\"data.test.p\"),\n\t\tModule(\"test.rego\", mod),\n\t\tPartialNamespace(\"test_ns1\"),\n\t\tCompiler(c),\n\t)\n\n\tctx := context.Background()\n\tpr, err := r.PartialResult(ctx)\n\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error from Rego.PartialResult(): %s\", err.Error())\n\t}\n\n\texpectedQuery := \"data.test_ns1.__result__\"\n\tif pr.body.String() != expectedQuery {\n\t\tt.Fatalf(\"Expected partial result query %s got %s\", expectedQuery, pr.body)\n\t}\n\n\tr2 := pr.Rego()\n\n\tassertEval(t, r2, \"[[true]]\")\n\n\tif len(c.Modules) != 2 {\n\t\tt.Fatalf(\"Expected two modules on the compiler, got: %v\", c.Modules)\n\t}\n\n\texpectedModuleID := \"__partialresult__test_ns1__\"\n\tif _, ok := c.Modules[expectedModuleID]; !ok {\n\t\tt.Fatalf(\"Expected to find module %s in compiler Modules, got: %v\", expectedModuleID, c.Modules)\n\t}\n}\n\nfunc TestPreparedPartialResultWithTracer(t *testing.T) {\n\tmod := `\n\tpackage test\n\tdefault p = false\n\tp {\n\t\tinput.x = 1\n\t}\n\t`\n\tr := New(\n\t\tQuery(\"data.test.p == true\"),\n\t\tModule(\"test.rego\", mod),\n\t)\n\n\ttracer := topdown.NewBufferTracer()\n\n\tctx := context.Background()\n\tpq, err := r.PrepareForPartial(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error from Rego.PrepareForPartial(): %s\", err.Error())\n\t}\n\n\tpqs, err := pq.Partial(ctx, EvalTracer(tracer))\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error from PreparedEvalQuery.Partial(): %s\", err.Error())\n\t}\n\n\texpectedQuery := \"input.x = 1\"\n\tif len(pqs.Queries) != 1 {\n\t\tt.Errorf(\"expected 1 query but found %d: %+v\", len(pqs.Queries), pqs)\n\t}\n\tif pqs.Queries[0].String() != expectedQuery {\n\t\tt.Errorf(\"unexpected query in result, expected='%s' found='%s'\",\n\t\t\texpectedQuery, pqs.Queries[0].String())\n\t}\n\n\tif len(*tracer) == 0 {\n\t\tt.Errorf(\"Expected buffer tracer to contain > 0 traces\")\n\t}\n}\n\nfunc TestPreparedPartialResultWithQueryTracer(t *testing.T) {\n\tmod := `\n\tpackage test\n\tdefault p = false\n\tp {\n\t\tinput.x = 1\n\t}\n\t`\n\tr := New(\n\t\tQuery(\"data.test.p == true\"),\n\t\tModule(\"test.rego\", mod),\n\t)\n\n\ttracer := topdown.NewBufferTracer()\n\n\tctx := context.Background()\n\tpq, err := r.PrepareForPartial(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error from Rego.PrepareForPartial(): %s\", err.Error())\n\t}\n\n\tpqs, err := pq.Partial(ctx, EvalQueryTracer(tracer))\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error from PreparedEvalQuery.Partial(): %s\", err.Error())\n\t}\n\n\texpectedQuery := \"input.x = 1\"\n\tif len(pqs.Queries) != 1 {\n\t\tt.Errorf(\"expected 1 query but found %d: %+v\", len(pqs.Queries), pqs)\n\t}\n\tif pqs.Queries[0].String() != expectedQuery {\n\t\tt.Errorf(\"unexpected query in result, expected='%s' found='%s'\",\n\t\t\texpectedQuery, pqs.Queries[0].String())\n\t}\n\n\tif len(*tracer) == 0 {\n\t\tt.Errorf(\"Expected buffer tracer to contain > 0 traces\")\n\t}\n}\n\nfunc TestPartialResultSetsValidConflictChecker(t *testing.T) {\n\tmod := `\n\tpackage test\n\tp {\n\t\ttrue\n\t}\n\t`\n\n\tc := ast.NewCompiler().WithPathConflictsCheck(func(_ []string) (bool, error) {\n\t\tt.Fatal(\"Conflict check should not have been called\")\n\t\treturn false, nil\n\t})\n\n\tr := New(\n\t\tQuery(\"data.test.p\"),\n\t\tModule(\"test.rego\", mod),\n\t\tPartialNamespace(\"test_ns1\"),\n\t\tCompiler(c),\n\t)\n\n\tctx := context.Background()\n\tpr, err := r.PartialResult(ctx)\n\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error from Rego.PartialResult(): %s\", err.Error())\n\t}\n\n\tr2 := pr.Rego()\n\n\tassertEval(t, r2, \"[[true]]\")\n}\n\nfunc TestMissingLocation(t *testing.T) {\n\n\t// Create a query programmatically and evaluate it. The Location information\n\t// is not set so the resulting expression value will not have it.\n\tr := New(ParsedQuery(ast.NewBody(ast.NewExpr(ast.BooleanTerm(true)))))\n\trs, err := r.Eval(context.Background())\n\n\tif err != nil {\n\t\tt.Fatal(err)\n\t} else if len(rs) == 0 || !rs[0].Expressions[0].Value.(bool) {\n\t\tt.Fatal(\"Unexpected result set:\", rs)\n\t}\n\n\tif rs[0].Expressions[0].Location != nil {\n\t\tt.Fatal(\"Expected location data to be unset.\")\n\t}\n}\n\nfunc TestBundlePassing(t *testing.T) {\n\n\topaBundle := bundle.Bundle{\n\t\tModules: []bundle.ModuleFile{\n\t\t\t{\n\t\t\t\tPath: \"policy.rego\",\n\t\t\t\tParsed: ast.MustParseModule(`package foo\n                         allow = true`),\n\t\t\t\tRaw: []byte(`package foo\n                         allow = true`),\n\t\t\t},\n\t\t},\n\t\tManifest: bundle.Manifest{Revision: \"test\", Roots: &[]string{\"/\"}},\n\t}\n\n\t// Pass a bundle\n\tr := New(\n\t\tParsedBundle(\"123\", &opaBundle),\n\t\tQuery(\"x = data.foo.allow\"),\n\t)\n\n\tres, err := r.Eval(context.Background())\n\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tassertResultSet(t, res, `[[true]]`)\n}\n\nfunc TestModulePassing(t *testing.T) {\n\n\t// This module will not be loaded since it has the same filename as the\n\t// file2.rego below and the raw modules override parsed modules.\n\tmodule1, err := ast.ParseModule(\"file2.rego\", `package file2\n\n\tp = \"deadbeef\"\n\t`)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tr := New(\n\t\tQuery(\"data\"),\n\t\tModule(\"file1.rego\", `package file1\n\n\t\tp = 1\n\t\t`),\n\t\tModule(\"file2.rego\", `package file2\n\n\t\tp = 2`),\n\t\tParsedModule(module1),\n\t\tParsedModule(ast.MustParseModule(`package file4\n\n\t\tp = 4`)),\n\t)\n\n\trs, err := r.Eval(context.Background())\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\texp := util.MustUnmarshalJSON([]byte(`\n\t{\n\t\t\"file1\": {\n\t\t\t\"p\": 1\n\t\t},\n\t\t\"file2\": {\n\t\t\t\"p\": 2\n\t\t},\n\t\t\"file4\": {\n\t\t\t\"p\": 4\n\t\t}\n\t}\n\t`))\n\n\tif !reflect.DeepEqual(rs[0].Expressions[0].Value, exp) {\n\t\tt.Fatalf(\"Expected %v but got %v\", exp, rs[0].Expressions[0].Value)\n\t}\n}\n\nfunc TestUnsafeBuiltins(t *testing.T) {\n\n\tctx := context.Background()\n\n\tunsafeCountExpr := \"unsafe built-in function calls in expression: count\"\n\tunsafeCountExprWith := `with keyword replacing built-in function: target must not be unsafe: \"count\"`\n\n\tt.Run(\"unsafe query\", func(t *testing.T) {\n\t\tr := New(\n\t\t\tQuery(`count([1, 2, 3])`),\n\t\t\tUnsafeBuiltins(map[string]struct{}{\"count\": {}}),\n\t\t)\n\t\tif _, err := r.Eval(ctx); err == nil || !strings.Contains(err.Error(), unsafeCountExpr) {\n\t\t\tt.Fatalf(\"Expected unsafe built-in error but got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"unsafe query, 'with' replacement\", func(t *testing.T) {\n\t\tr := New(\n\t\t\tQuery(`is_array([1, 2, 3]) with is_array as count`),\n\t\t\tUnsafeBuiltins(map[string]struct{}{\"count\": {}}),\n\t\t)\n\t\tif _, err := r.Eval(ctx); err == nil || !strings.Contains(err.Error(), unsafeCountExprWith) {\n\t\t\tt.Fatalf(\"Expected unsafe built-in error but got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"unsafe module\", func(t *testing.T) {\n\t\tr := New(\n\t\t\tQuery(`data.pkg.deny`),\n\t\t\tModule(\"pkg.rego\", `package pkg\n\t\t\tdeny {\n\t\t\t\tcount(input.requests) > 10\n\t\t\t}\n\t\t\t`),\n\t\t\tUnsafeBuiltins(map[string]struct{}{\"count\": {}}),\n\t\t)\n\t\tif _, err := r.Eval(ctx); err == nil || !strings.Contains(err.Error(), unsafeCountExpr) {\n\t\t\tt.Fatalf(\"Expected unsafe built-in error but got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"unsafe module, 'with' replacement in query\", func(t *testing.T) {\n\t\tr := New(\n\t\t\tQuery(`data.pkg.deny with is_array as count`),\n\t\t\tModule(\"pkg.rego\", `package pkg\n\t\t\tdeny {\n\t\t\t\tis_array(input.requests) > 10\n\t\t\t}\n\t\t\t`),\n\t\t\tUnsafeBuiltins(map[string]struct{}{\"count\": {}}),\n\t\t)\n\t\tif _, err := r.Eval(ctx); err == nil || !strings.Contains(err.Error(), unsafeCountExprWith) {\n\t\t\tt.Fatalf(\"Expected unsafe built-in error but got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"unsafe module, 'with' replacement in module\", func(t *testing.T) {\n\t\tr := New(\n\t\t\tQuery(`data.pkg.deny`),\n\t\t\tModule(\"pkg.rego\", `package pkg\n\t\t\tdeny {\n\t\t\t\tis_array(input.requests) > 10 with is_array as count\n\t\t\t}\n\t\t\t`),\n\t\t\tUnsafeBuiltins(map[string]struct{}{\"count\": {}}),\n\t\t)\n\t\tif _, err := r.Eval(ctx); err == nil || !strings.Contains(err.Error(), unsafeCountExprWith) {\n\t\t\tt.Fatalf(\"Expected unsafe built-in error but got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"inherit in query\", func(t *testing.T) {\n\t\tr := New(\n\t\t\tCompiler(ast.NewCompiler().WithUnsafeBuiltins(map[string]struct{}{\"count\": {}})),\n\t\t\tQuery(\"count([])\"),\n\t\t)\n\t\tif _, err := r.Eval(ctx); err == nil || !strings.Contains(err.Error(), unsafeCountExpr) {\n\t\t\tt.Fatalf(\"Expected unsafe built-in error but got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"inherit in query, 'with' replacement\", func(t *testing.T) {\n\t\tr := New(\n\t\t\tCompiler(ast.NewCompiler().WithUnsafeBuiltins(map[string]struct{}{\"count\": {}})),\n\t\t\tQuery(\"is_array([]) with is_array as count\"),\n\t\t)\n\t\tif _, err := r.Eval(ctx); err == nil || !strings.Contains(err.Error(), unsafeCountExprWith) {\n\t\t\tt.Fatalf(\"Expected unsafe built-in error but got %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"override/disable in query\", func(t *testing.T) {\n\t\tr := New(\n\t\t\tCompiler(ast.NewCompiler().WithUnsafeBuiltins(map[string]struct{}{\"count\": {}})),\n\t\t\tUnsafeBuiltins(map[string]struct{}{}),\n\t\t\tQuery(\"count([])\"),\n\t\t)\n\t\tif _, err := r.Eval(ctx); err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t})\n\n\tt.Run(\"override/change in query\", func(t *testing.T) {\n\t\tr := New(\n\t\t\tCompiler(ast.NewCompiler().WithUnsafeBuiltins(map[string]struct{}{\"count\": {}})),\n\t\t\tUnsafeBuiltins(map[string]struct{}{\"max\": {}}),\n\t\t\tQuery(\"count([]); max([1,2])\"),\n\t\t)\n\n\t\t_, err := r.Eval(ctx)\n\t\tif err == nil || err.Error() != \"1 error occurred: 1:12: rego_type_error: unsafe built-in function calls in expression: max\" {\n\t\t\tt.Fatalf(\"expected error for max but got: %v\", err)\n\t\t}\n\t})\n\n\tt.Run(\"ignore if given compiler\", func(t *testing.T) {\n\t\tr := New(\n\t\t\tCompiler(ast.NewCompiler()),\n\t\t\tUnsafeBuiltins(map[string]struct{}{\"count\": {}}),\n\t\t\tQuery(\"data.test.p = 0\"),\n\t\t\tModule(\"test.rego\", `package test\n\n\t\t\tp = count([])`),\n\t\t)\n\t\trs, err := r.Eval(context.Background())\n\t\tif err != nil || len(rs) != 1 {\n\t\t\tlog.Fatalf(\"Unexpected error or result. Result: %v. Error: %v\", rs, err)\n\t\t}\n\t})\n}\n\nfunc TestPreparedQueryGetModules(t *testing.T) {\n\tmods := map[string]string{\n\t\t\"a.rego\": \"package a\\np = 1\",\n\t\t\"b.rego\": \"package b\\nq = 1\",\n\t\t\"c.rego\": \"package c\\nr = 1\",\n\t}\n\n\tvar regoArgs []func(r *Rego)\n\n\tfor name, mod := range mods {\n\t\tregoArgs = append(regoArgs, Module(name, mod))\n\t}\n\n\tregoArgs = append(regoArgs, Query(\"data\"))\n\n\tctx := context.Background()\n\tpq, err := New(regoArgs...).PrepareForEval(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t}\n\n\tactualMods := pq.Modules()\n\n\tif len(actualMods) != len(mods) {\n\t\tt.Fatalf(\"Expected %d modules, got %d\", len(mods), len(actualMods))\n\t}\n\n\tfor name, actualMod := range actualMods {\n\t\texpectedMod, found := mods[name]\n\t\tif !found {\n\t\t\tt.Fatalf(\"Unexpected module %s\", name)\n\t\t}\n\t\tif actualMod.String() != ast.MustParseModule(expectedMod).String() {\n\t\t\tt.Fatalf(\"Modules for %s do not match.\\n\\nExpected:\\n%s\\n\\nActual:\\n%s\\n\\n\",\n\t\t\t\tname, actualMod.String(), expectedMod)\n\t\t}\n\t}\n}\n\nfunc TestRegoEvalWithFile(t *testing.T) {\n\tfiles := map[string]string{\n\t\t\"x/x.rego\": \"package x\\np = 1\",\n\t\t\"x/x.json\": `{\"y\": \"foo\"}`,\n\t}\n\n\ttest.WithTempFS(files, func(path string) {\n\t\tctx := context.Background()\n\n\t\tpq, err := New(\n\t\t\tLoad([]string{path}, nil),\n\t\t\tQuery(\"data\"),\n\t\t).PrepareForEval(ctx)\n\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t\t}\n\n\t\trs, err := pq.Eval(ctx)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t\t}\n\n\t\tassertResultSet(t, rs, `[[{\"x\":{\"p\":1,\"y\":\"foo\"}}]]`)\n\t})\n}\n\nfunc TestRegoEvalWithBundle(t *testing.T) {\n\tfiles := map[string]string{\n\t\t\"x/x.rego\":            \"package x\\np = data.x.b\",\n\t\t\"x/data.json\":         `{\"b\": \"bar\"}`,\n\t\t\"other/not-data.json\": `{\"ignored\": \"data\"}`,\n\t}\n\n\ttest.WithTempFS(files, func(path string) {\n\t\tctx := context.Background()\n\n\t\tpq, err := New(\n\t\t\tLoadBundle(path),\n\t\t\tQuery(\"data.x.p\"),\n\t\t).PrepareForEval(ctx)\n\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t\t}\n\n\t\trs, err := pq.Eval(ctx)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t\t}\n\n\t\tassertResultSet(t, rs, `[[\"bar\"]]`)\n\n\t\tmods := pq.Modules()\n\t\tif exp, act := 1, len(mods); exp != act {\n\t\t\tt.Fatalf(\"expected %d modules, found %d\", exp, act)\n\t\t}\n\t\tfor act := range mods {\n\t\t\tif exp := filepath.Join(path, \"x/x.rego\"); exp != act {\n\t\t\t\tt.Errorf(\"expected module name %q, got %q\", exp, act)\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc TestRegoEvalWithBundleURL(t *testing.T) {\n\tfiles := map[string]string{\n\t\t\"x/x.rego\": \"package x\\np = data.x.b\",\n\t}\n\n\ttest.WithTempFS(files, func(path string) {\n\t\tctx := context.Background()\n\t\tpq, err := New(\n\t\t\tLoadBundle(\"file://\"+path),\n\t\t\tQuery(\"data.x.p\"),\n\t\t).PrepareForEval(ctx)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t\t}\n\n\t\tmods := pq.Modules()\n\t\tif exp, act := 1, len(mods); exp != act {\n\t\t\tt.Fatalf(\"expected %d modules, found %d\", exp, act)\n\t\t}\n\t\tfor act := range mods {\n\t\t\tif exp := filepath.Join(path, \"x/x.rego\"); exp != act {\n\t\t\t\tt.Errorf(\"expected module name %q, got %q\", exp, act)\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc TestRegoEvalPoliciesInStore(t *testing.T) {\n\tstore := mock.New()\n\tctx := context.Background()\n\ttxn := storage.NewTransactionOrDie(ctx, store, storage.WriteParams)\n\n\terr := store.UpsertPolicy(ctx, txn, \"a.rego\", []byte(\"package a\\np=1\"))\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t}\n\terr = store.Commit(ctx, txn)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t}\n\n\tpq, err := New(\n\t\tStore(store),\n\t\tModule(\"b.rego\", \"package b\\np = data.a.p\"),\n\t\tQuery(\"data.b.p\"),\n\t).PrepareForEval(ctx)\n\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t}\n\n\trs, err := pq.Eval(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t}\n\n\tassertResultSet(t, rs, `[[1]]`)\n}\n\nfunc TestRegoEvalModulesOnCompiler(t *testing.T) {\n\tcompiler := ast.NewCompiler()\n\n\tcompiler.Compile(map[string]*ast.Module{\n\t\t\"a.rego\": ast.MustParseModule(\"package a\\np = 1\"),\n\t})\n\n\tif len(compiler.Errors) > 0 {\n\t\tt.Fatalf(\"Unexpected compile errors: %s\", compiler.Errors)\n\t}\n\n\tctx := context.Background()\n\n\tpq, err := New(\n\t\tCompiler(compiler),\n\t\tQuery(\"data.a.p\"),\n\t\tSchemas(nil),\n\t).PrepareForEval(ctx)\n\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t}\n\n\trs, err := pq.Eval(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t}\n\n\tassertResultSet(t, rs, `[[1]]`)\n}\n\nfunc TestRegoLoadFilesWithProvidedStore(t *testing.T) {\n\tctx := context.Background()\n\tstore := mock.New()\n\n\tfiles := map[string]string{\n\t\t\"x.rego\": \"package x\\np = data.x.b\",\n\t}\n\n\ttest.WithTempFS(files, func(path string) {\n\t\tpq, err := New(\n\t\t\tStore(store),\n\t\t\tQuery(\"data\"),\n\t\t\tLoad([]string{path}, nil),\n\t\t).PrepareForEval(ctx)\n\n\t\tif err == nil {\n\t\t\tt.Fatal(\"Expected an error but err == nil\")\n\t\t}\n\n\t\tif pq.r != nil {\n\t\t\tt.Fatalf(\"Expected pq.r == nil, got: %+v\", pq)\n\t\t}\n\t})\n}\n\nfunc TestRegoLoadBundleWithProvidedStore(t *testing.T) {\n\tctx := context.Background()\n\tstore := mock.New()\n\n\tfiles := map[string]string{\n\t\t\"x/x.rego\": \"package x\\np = data.x.b\",\n\t}\n\n\ttest.WithTempFS(files, func(path string) {\n\t\tpq, err := New(\n\t\t\tStore(store),\n\t\t\tQuery(\"data\"),\n\t\t\tLoadBundle(path),\n\t\t).PrepareForEval(ctx)\n\n\t\tif err == nil {\n\t\t\tt.Fatal(\"Expected an error but err == nil\")\n\t\t}\n\n\t\tif pq.r != nil {\n\t\t\tt.Fatalf(\"Expected pq.r == nil, got: %+v\", pq)\n\t\t}\n\t})\n}\n\nfunc TestRegoCustomBuiltinPartialPropagate(t *testing.T) {\n\tmod := `package test\n\tp {\n\t\tx = trim_and_split(input.foo, \"/\")\n\t\tx == [\"foo\", \"bar\", \"baz\"]\n\t}\n\t`\n\n\toriginalRego := New(\n\t\tModule(\"test.rego\", mod),\n\t\tQuery(`data.test.p`),\n\t\tFunction2(\n\t\t\t&Function{\n\t\t\t\tName: \"trim_and_split\",\n\t\t\t\tDecl: types.NewFunction(\n\t\t\t\t\ttypes.Args(types.S, types.S), // two string inputs\n\t\t\t\t\ttypes.NewArray(nil, types.S), // variable-length string array output\n\t\t\t\t),\n\t\t\t},\n\t\t\tfunc(_ BuiltinContext, a, b *ast.Term) (*ast.Term, error) {\n\n\t\t\t\tstr, ok1 := a.Value.(ast.String)\n\t\t\t\tdelim, ok2 := b.Value.(ast.String)\n\n\t\t\t\t// The function is undefined for non-string inputs. Built-in\n\t\t\t\t// functions should only return errors in unrecoverable cases.\n\t\t\t\tif !ok1 || !ok2 {\n\t\t\t\t\treturn nil, nil\n\t\t\t\t}\n\n\t\t\t\tresult := strings.Split(strings.Trim(string(str), string(delim)), string(delim))\n\n\t\t\t\tarr := make([]*ast.Term, len(result))\n\t\t\t\tfor i := range result {\n\t\t\t\t\tarr[i] = ast.StringTerm(result[i])\n\t\t\t\t}\n\n\t\t\t\treturn ast.ArrayTerm(arr...), nil\n\t\t\t},\n\t\t),\n\t)\n\n\tpr, err := originalRego.PartialResult(context.Background())\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t}\n\n\trs, err := pr.Rego(\n\t\tInput(map[string]interface{}{\"foo\": \"/foo/bar/baz/\"}),\n\t).Eval(context.Background())\n\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t}\n\tassertResultSet(t, rs, `[[true]]`)\n\n}\n\nfunc TestRegoPartialResultRecursiveRefs(t *testing.T) {\n\n\tr := New(Query(\"data\"), Module(\"test.rego\", `package foo.bar\n\n\tdefault p = false\n\n\tp { input.x = 1 }`))\n\n\t_, err := r.PartialResult(context.Background())\n\tif err == nil {\n\t\tt.Fatal(\"expected error\")\n\t}\n\n\tif !IsPartialEvaluationNotEffectiveErr(err) {\n\t\tt.Fatal(\"expected ineffective partial eval error\")\n\t}\n\n}\n\nfunc TestSkipPartialNamespaceOption(t *testing.T) {\n\tr := New(Query(\"data.test.p\"), Module(\"example.rego\", `\n\t\tpackage test\n\n\t\tdefault p = false\n\n\t\tp = true { input }\n\t`), SkipPartialNamespace(true))\n\n\tpq, err := r.Partial(context.Background())\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif len(pq.Queries) != 1 || !pq.Queries[0].Equal(ast.MustParseBody(\"data.test.p\")) {\n\t\tt.Fatal(\"expected exactly one query and for reference to not have been rewritten but got:\", pq.Queries)\n\t}\n\n\tif len(pq.Support) != 1 || !pq.Support[0].Package.Equal(ast.MustParsePackage(\"package test\")) {\n\t\tt.Fatal(\"expected exactly one support and for package to be same as input but got:\", pq.Support)\n\t}\n}\n\nfunc TestShallowInliningOption(t *testing.T) {\n\tr := New(Query(\"data.test.p = true\"), Module(\"example.rego\", `\n\t\tpackage test\n\n\t\tp {\n\t\t\tq = true\n\t\t}\n\n\t\tq {\n\t\t\tinput.x = r\n\t\t}\n\n\t\tr = 7\n\t`), ShallowInlining(true))\n\n\tpq, err := r.Partial(context.Background())\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif len(pq.Queries) != 1 || !pq.Queries[0].Equal(ast.MustParseBody(\"data.partial.test.p = true\")) {\n\t\tt.Fatal(\"expected exactly one query and ref to be rewritten but got:\", pq.Queries)\n\t}\n\n\texp := ast.MustParseModule(`\n\t\tpackage partial.test\n\n\t\tp { data.partial.test.q = true }\n\t\tq { 7 = input.x }\n\t`)\n\n\tif len(pq.Support) != 1 || !pq.Support[0].Equal(exp) {\n\t\tt.Fatal(\"expected module:\", exp, \"\\n\\ngot module:\", pq.Support[0])\n\t}\n}\n\nfunc TestRegoPartialResultSortedRules(t *testing.T) {\n\tr := New(Query(\"data.test.p\"), Module(\"example.rego\", `\n\t\tpackage test\n\n\t\tdefault p = false\n\n\t\tp {\n\t\t\tr = (input.d * input.a) + input.c\n\t\t\tr < s\n\t\t}\n\n\t\tp {\n\t\t\tr = (input.d * input.b) + input.c\n\t\t\tr < s\n\t\t}\n\n\t\ts = 100\n\n\t`))\n\n\tpq, err := r.Partial(context.Background())\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// Without sorting of support rules, the output of the above partial evaluation\n\t// resulted in a random order of the support rules (in this case two different possible outputs)\n\texp := ast.MustParseModule(\n\t\t`package partial.test\n\n\t\tdefault p = false\n\n\t\tp = true { lt(plus(mul(input.d, input.a), input.c), 100) }\n\t\tp = true { lt(plus(mul(input.d, input.b), input.c), 100) }\n\t\t`,\n\t)\n\n\tif len(pq.Support) != 1 || !pq.Support[0].Equal(exp) {\n\t\tt.Fatal(\"expected module:\", exp, \"\\n\\ngot module:\", pq.Support[0])\n\t}\n\n}\n\nfunc TestPrepareWithEmptyModule(t *testing.T) {\n\t_, err := New(\n\t\tQuery(\"d\"),\n\t\tModule(\"example.rego\", \"\"),\n\t).PrepareForEval(context.Background())\n\n\texpected := \"1 error occurred: example.rego:0: rego_parse_error: empty module\"\n\tif err == nil || err.Error() != expected {\n\t\tt.Fatalf(\"Expected error %s, got %s\", expected, err)\n\t}\n}\n\nfunc TestPrepareWithWasmTargetNotSupported(t *testing.T) {\n\tfiles := map[string]string{\n\t\t\"x/x.rego\":     \"package x\\np = data.x.b\",\n\t\t\"x/data.json\":  `{\"b\": \"bar\"}`,\n\t\t\"/policy.wasm\": `modules-compiled-as-wasm-binary`,\n\t}\n\n\ttest.WithTempFS(files, func(path string) {\n\t\tctx := context.Background()\n\n\t\t_, err := New(\n\t\t\tLoadBundle(path),\n\t\t\tQuery(\"data.x.p\"),\n\t\t\tTarget(\"wasm\"),\n\t\t).PrepareForEval(ctx)\n\n\t\texpected := \"wasm target not supported\"\n\t\tif err == nil || err.Error() != expected {\n\t\t\tt.Fatalf(\"Expected error %s, got %s\", expected, err)\n\t\t}\n\t})\n}\n\nfunc TestEvalWithInterQueryCache(t *testing.T) {\n\tnewHeaders := map[string][]string{\"Cache-Control\": {\"max-age=290304000, public\"}}\n\n\tvar requests []*http.Request\n\tts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\trequests = append(requests, r)\n\t\theaders := w.Header()\n\n\t\tfor k, v := range newHeaders {\n\t\t\theaders[k] = v\n\t\t}\n\n\t\tw.WriteHeader(http.StatusOK)\n\t\t_, _ = w.Write([]byte(`{\"x\": 1}`))\n\t}))\n\tdefer ts.Close()\n\tquery := fmt.Sprintf(`http.send({\"method\": \"get\", \"url\": \"%s\", \"force_json_decode\": true, \"cache\": true})`, ts.URL)\n\n\t// add an inter-query cache\n\tconfig, _ := cache.ParseCachingConfig(nil)\n\tinterQueryCache := cache.NewInterQueryCache(config)\n\n\tctx := context.Background()\n\t_, err := New(Query(query), InterQueryBuiltinCache(interQueryCache)).Eval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// eval again with same query\n\t// this request should be served by the cache\n\t_, err = New(Query(query), InterQueryBuiltinCache(interQueryCache)).Eval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif len(requests) != 1 {\n\t\tt.Fatal(\"Expected server to be called only once\")\n\t}\n}\n\n// We use http.send to ensure the NDBuiltinCache is involved.\nfunc TestEvalWithNDCache(t *testing.T) {\n\tvar requests []*http.Request\n\tts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\trequests = append(requests, r)\n\t\t_, _ = w.Write([]byte(`{\"x\": 1}`))\n\t}))\n\tdefer ts.Close()\n\tquery := fmt.Sprintf(`http.send({\"method\": \"get\", \"url\": \"%s\", \"force_json_decode\": true})`, ts.URL)\n\n\t// Set up the ND cache, and put in some arbitrary constants for the first K/V pair.\n\tarbitraryKey := ast.Number(strconv.Itoa(2015))\n\tarbitraryValue := ast.String(\"First commit year\")\n\tndBC := builtins.NDBCache{}\n\tndBC.Put(\"arbitrary_experiment\", arbitraryKey, arbitraryValue)\n\n\t// Query execution of http.send should add an entry to the NDBuiltinCache.\n\tctx := context.Background()\n\t_, err := New(Query(query), NDBuiltinCache(ndBC)).Eval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// Check and make sure we got exactly 2x items back in the ND builtin cache.\n\t// NDBuiltinsCache always has the structure: map[ast.String]map[ast.Array]ast.Value\n\tif len(ndBC) != 2 {\n\t\tt.Fatalf(\"Expected exactly 2 items in non-deterministic builtin cache. Found %d items.\\n\", len(ndBC))\n\t}\n\t// Check the cached k/v types for the HTTP section of the cache.\n\tif cachedResults, ok := ndBC[\"http.send\"]; ok {\n\t\terr := cachedResults.Iter(func(k, v *ast.Term) error {\n\t\t\tif _, ok := k.Value.(*ast.Array); !ok {\n\t\t\t\tt.Fatalf(\"http.send failed to store Object key in the ND builtins cache\")\n\t\t\t}\n\t\t\tif _, ok := v.Value.(ast.Object); !ok {\n\t\t\t\tt.Fatalf(\"http.send failed to store Object value in the ND builtins cache\")\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}\n\n\t// Ensure our original arbitrary data in the cache was preserved.\n\tif v, ok := ndBC.Get(\"arbitrary_experiment\", arbitraryKey); ok {\n\t\tif v != arbitraryValue {\n\t\t\tt.Fatalf(\"Non-deterministic builtins cache value was mangled. Expected: %v, got: %v\\n\", arbitraryValue, v)\n\t\t}\n\t} else {\n\t\tt.Fatal(\"Non-deterministic builtins cache lookup failed.\")\n\t}\n}\n\nfunc TestEvalWithPrebuiltNDCache(t *testing.T) {\n\tquery := \"time.now_ns()\"\n\tndBC := builtins.NDBCache{}\n\n\t// Populate the cache for time.now_ns with an arbitrary timestamp.\n\ttimeValue, err := time.Parse(\"2006-01-02T15:04:05Z\", \"2015-12-28T14:08:25Z\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// Timestamp ns value will be: 1451311705000000000\n\tndBC.Put(\"time.now_ns\", ast.NewArray(), ast.Number(json.Number(strconv.FormatInt(timeValue.UnixNano(), 10))))\n\t// time.now_ns should use the cached entry instead of the current time.\n\tctx := context.Background()\n\trs, err := New(Query(query), NDBuiltinCache(ndBC)).Eval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// Check that we got the correct time value in the result set.\n\tassertResultSet(t, rs, \"[[1451311705000000000]]\")\n}\n\nfunc TestNDBCacheWithRuleBody(t *testing.T) {\n\tctx := context.Background()\n\tts := httptest.NewServer(http.HandlerFunc(func(http.ResponseWriter, *http.Request) {}))\n\tdefer ts.Close()\n\n\tndBC := builtins.NDBCache{}\n\tquery := \"data.foo.p = x\"\n\t_, err := New(\n\t\tQuery(query),\n\t\tNDBuiltinCache(ndBC),\n\t\tModule(\"test.rego\", fmt.Sprintf(`package foo\np {\n\thttp.send({\"url\": \"%s\", \"method\":\"get\"})\n}`, ts.URL)),\n\t).Eval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\t_, ok := ndBC[\"http.send\"]\n\tif !ok {\n\t\tt.Fatalf(\"expected http.send cache entry\")\n\t}\n}\n\n// Catches issues around iteration with ND builtins.\nfunc TestNDBCacheWithRuleBodyAndIteration(t *testing.T) {\n\tctx := context.Background()\n\tts := httptest.NewServer(http.HandlerFunc(func(http.ResponseWriter, *http.Request) {\n\t}))\n\tdefer ts.Close()\n\n\tndBC := builtins.NDBCache{}\n\tquery := \"data.foo.results = x\"\n\t_, err := New(\n\t\tQuery(query),\n\t\tNDBuiltinCache(ndBC),\n\t\tModule(\"test.rego\", fmt.Sprintf(`package foo\n\nimport future.keywords\n\nurls := [\n\t\"%[1]s/headers\",\n\t\"%[1]s/ip\",\n\t\"%[1]s/user-agent\"\n]\n\nresults[response] {\n\tsome url in urls\n\tresponse := http.send({\n\t\t\"method\": \"GET\",\n\t\t\"url\": url\n\t})\n}`, ts.URL)),\n\t).Eval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// Ensure that the cache exists, and has exactly 3 entries.\n\tentries, ok := ndBC[\"http.send\"]\n\tif !ok {\n\t\tt.Fatalf(\"expected http.send cache entry\")\n\t}\n\tif entries.Len() != 3 {\n\t\tt.Fatalf(\"expected 3 http.send cache entries, received:\\n%v\", ndBC)\n\t}\n}\n\n// This test ensures that the NDBCache correctly serializes/deserializes.\nfunc TestNDBCacheMarshalUnmarshalJSON(t *testing.T) {\n\toriginal := builtins.NDBCache{}\n\n\t// Populate the cache for time.now_ns with an arbitrary timestamp.\n\toriginal.Put(\"time.now_ns\", ast.NewArray(), ast.Number(json.Number(strconv.FormatInt(1451311705000000000, 10))))\n\tjOriginal, err := json.Marshal(original)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvar other builtins.NDBCache\n\terr = json.Unmarshal(jOriginal, &other)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tjOther, err := json.Marshal(other)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// Check that the two NDBCache value's JSONified forms match exactly.\n\tif !bytes.Equal(jOriginal, jOther) {\n\t\tt.Fatalf(\"JSONified values of NDBCaches do not match; expected %s, got %s\", string(jOriginal), string(jOther))\n\t}\n}\n\nfunc TestStrictBuiltinErrors(t *testing.T) {\n\t_, err := New(Query(\"1/0\"), StrictBuiltinErrors(true)).Eval(context.Background())\n\tif err == nil {\n\t\tt.Fatal(\"expected error\")\n\t}\n\ttopdownErr, ok := err.(*topdown.Error)\n\tif !ok {\n\t\tt.Fatal(\"expected topdown error but got:\", err)\n\t}\n\n\tif topdownErr.Code != topdown.BuiltinErr {\n\t\tt.Fatal(\"expected builtin error code but got:\", topdownErr.Code)\n\t}\n\n\tif topdownErr.Message != \"div: divide by zero\" {\n\t\tt.Fatal(\"expected divide by zero error but got:\", topdownErr.Message)\n\t}\n}\n\nfunc TestTimeSeedingOptions(t *testing.T) {\n\n\tctx := context.Background()\n\tclock := time.Now()\n\n\t// Check expected time is returned.\n\trs, err := New(Query(\"time.now_ns(x)\"), Time(clock)).Eval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t} else if len(rs) != 1 || !reflect.DeepEqual(rs[0].Bindings[\"x\"], int64ToJSONNumber(clock.UnixNano())) {\n\t\tt.Fatal(\"unexpected wall clock value\")\n\t}\n\n\t// Check that time is not propagated to prepared query.\n\teval, err := New(Query(\"time.now_ns(x)\"), Time(clock)).PrepareForEval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\trs2, err := eval.Eval(ctx)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t} else if len(rs2) != 1 || reflect.DeepEqual(rs[0].Bindings[\"x\"], rs2[0].Bindings[\"x\"]) {\n\t\tt.Fatal(\"expected new wall clock value\")\n\t}\n\n\t// Check that prepared query returns provided time.\n\trs3, err := eval.Eval(ctx, EvalTime(clock))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t} else if len(rs2) != 1 || !reflect.DeepEqual(rs[0].Bindings[\"x\"], rs3[0].Bindings[\"x\"]) {\n\t\tt.Fatal(\"expected old wall clock value\")\n\t}\n\n}\n\nfunc int64ToJSONNumber(i int64) json.Number {\n\treturn json.Number(strconv.FormatInt(i, 10))\n}\n\nfunc TestPrepareAndCompileWithSchema(t *testing.T) {\n\tmodule := `\n\tpackage test\n\tx = input.y\n\t`\n\n\tschemaBytes := `{\n\t\t\"$schema\": \"http://json-schema.org/draft-07/schema\",\n\t\t\"$id\": \"http://example.com/example.json\",\n\t\t\"type\": \"object\",\n\t\t\"title\": \"The root schema\",\n\t\t\"description\": \"The root schema comprises the entire JSON document.\",\n\t\t\"required\": [],\n\t\t\"properties\": {\n\t\t\t\"y\": {\n\t\t\t\t\"$id\": \"#/properties/y\",\n\t\t\t\t\"type\": \"integer\",\n\t\t\t\t\"title\": \"The y schema\",\n\t\t\t\t\"description\": \"An explanation about the purpose of this instance.\"\n\t\t\t}\n\t\t},\n\t\t\"additionalProperties\": false\n\t}`\n\n\tvar schema interface{}\n\terr := util.Unmarshal([]byte(schemaBytes), &schema)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tschemaSet := ast.NewSchemaSet()\n\tschemaSet.Put(ast.InputRootRef, schema)\n\n\tr := New(\n\t\tQuery(\"data.test.x\"),\n\t\tModule(\"\", module),\n\t\tPackage(\"foo\"),\n\t\tSchemas(schemaSet),\n\t)\n\n\tctx := context.Background()\n\n\tpq, err := r.PrepareForEval(ctx)\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %s\", err.Error())\n\t}\n\n\tassertPreparedEvalQueryEval(t, pq, []EvalOption{\n\t\tEvalInput(map[string]int{\"y\": 1}),\n\t}, \"[[1]]\")\n\n\t// Ensure that Compile still works after Prepare\n\t// and its Eval has been called.\n\t_, err = r.Compile(ctx)\n\tif err != nil {\n\t\tt.Errorf(\"Unexpected error when compiling: %s\", err.Error())\n\t}\n}\n\nfunc TestGenerateJSON(t *testing.T) {\n\tr := New(\n\t\tQuery(\"input\"),\n\t\tInput(\"original-input\"),\n\t\tGenerateJSON(func(t *ast.Term, ectx *EvalContext) (interface{}, error) {\n\t\t\treturn \"converted-input\", nil\n\t\t}),\n\t)\n\tassertEval(t, r, `[[\"converted-input\"]]`)\n}\n"], "filenames": ["ast/compile.go", "ast/compile_test.go", "rego/rego_test.go"], "buggy_code_start_loc": [2199, 4051, 1439], "buggy_code_end_loc": [4943, 6686, 1471], "fixing_code_start_loc": [2199, 4052, 1440], "fixing_code_end_loc": [4951, 6760, 1523], "type": "NVD-CWE-noinfo", "message": "Open Policy Agent (OPA) is an open source, general-purpose policy engine. The Rego compiler provides a (deprecated) `WithUnsafeBuiltins` function, which allows users to provide a set of built-in functions that should be deemed unsafe \u00e2\u20ac\u201d and as such rejected \u00e2\u20ac\u201d by the compiler if encountered in the policy compilation stage. A bypass of this protection has been found, where the use of the `with` keyword to mock such a built-in function (a feature introduced in OPA v0.40.0), isn\u00e2\u20ac\u2122t taken into account by `WithUnsafeBuiltins`. Multiple conditions need to be met in order to create an adverse effect. Version 0.43.1 contains a patch for this issue. As a workaround, avoid using the `WithUnsafeBuiltins` function and use the `capabilities` feature instead.", "other": {"cve": {"id": "CVE-2022-36085", "sourceIdentifier": "security-advisories@github.com", "published": "2022-09-08T14:15:08.340", "lastModified": "2022-09-13T21:15:58.360", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Open Policy Agent (OPA) is an open source, general-purpose policy engine. The Rego compiler provides a (deprecated) `WithUnsafeBuiltins` function, which allows users to provide a set of built-in functions that should be deemed unsafe \u00e2\u20ac\u201d and as such rejected \u00e2\u20ac\u201d by the compiler if encountered in the policy compilation stage. A bypass of this protection has been found, where the use of the `with` keyword to mock such a built-in function (a feature introduced in OPA v0.40.0), isn\u00e2\u20ac\u2122t taken into account by `WithUnsafeBuiltins`. Multiple conditions need to be met in order to create an adverse effect. Version 0.43.1 contains a patch for this issue. As a workaround, avoid using the `WithUnsafeBuiltins` function and use the `capabilities` feature instead."}, {"lang": "es", "value": "Open Policy Agent (OPA) es un motor de pol\u00edticas de prop\u00f3sito general de c\u00f3digo abierto.&#xa0;El compilador de Rego proporciona una funci\u00f3n \"WithUnsafeBuiltins\" (en desuso), que permite a usuarios proporcionar un conjunto de funciones integradas que el compilador deber\u00eda considerar inseguras y, como tales, rechazarlas si son encontradas en la etapa de compilaci\u00f3n de pol\u00edticas. .&#xa0;Se ha encontrado una omisi\u00f3n de esta protecci\u00f3n, en la que \"WithUnsafeBuiltins\" no es tenido en cuenta el uso de la palabra clave \"with\" para simular una funci\u00f3n integrada de este tipo (una caracter\u00edstica introducida en OPA v0.40.0).&#xa0;Deben cumplirse m\u00faltiples condiciones para crear un efecto adverso.&#xa0;La versi\u00f3n 0.43.1 contiene un parche para este problema.&#xa0;Como mitigaci\u00f3n, evite usar la funci\u00f3n \"WithUnsafeBuiltins\" y use la funcionalidad \"capabilities\" en su lugar"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.8, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.9}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:N", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "NONE", "baseScore": 7.4, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.2, "impactScore": 5.2}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "NVD-CWE-noinfo"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-20"}, {"lang": "en", "value": "CWE-693"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:openpolicyagent:open_policy_agent:*:*:*:*:*:*:*:*", "versionStartIncluding": "0.40.0", "versionEndExcluding": "0.43.1", "matchCriteriaId": "24044142-C7B3-4994-9F36-5ED0299C8E5B"}]}]}], "references": [{"url": "https://github.com/open-policy-agent/opa/commit/25a597bc3f4985162e7f65f9c36599f4f8f55823", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/open-policy-agent/opa/commit/3e8c754ed007b22393cf65e48751ad9f6457fee8", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/open-policy-agent/opa/pull/4540", "source": "security-advisories@github.com", "tags": ["Exploit", "Patch", "Third Party Advisory"]}, {"url": "https://github.com/open-policy-agent/opa/pull/4616", "source": "security-advisories@github.com", "tags": ["Exploit", "Patch", "Third Party Advisory"]}, {"url": "https://github.com/open-policy-agent/opa/releases/tag/v0.43.1", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}, {"url": "https://github.com/open-policy-agent/opa/security/advisories/GHSA-f524-rf33-2jjr", "source": "security-advisories@github.com", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/open-policy-agent/opa/commit/25a597bc3f4985162e7f65f9c36599f4f8f55823"}}
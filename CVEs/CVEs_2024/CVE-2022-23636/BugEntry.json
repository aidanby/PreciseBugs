{"buggy_code": ["//! An `Instance` contains all the runtime state used by execution of a\n//! wasm module (except its callstack and register state). An\n//! `InstanceHandle` is a reference-counting handle for an `Instance`.\n\nuse crate::export::Export;\nuse crate::externref::VMExternRefActivationsTable;\nuse crate::memory::{Memory, RuntimeMemoryCreator};\nuse crate::table::{Table, TableElement, TableElementType};\nuse crate::traphandlers::Trap;\nuse crate::vmcontext::{\n    VMCallerCheckedAnyfunc, VMContext, VMFunctionImport, VMGlobalDefinition, VMGlobalImport,\n    VMInterrupts, VMMemoryDefinition, VMMemoryImport, VMTableDefinition, VMTableImport,\n};\nuse crate::{CompiledModuleId, ExportFunction, ExportGlobal, ExportMemory, ExportTable, Store};\nuse anyhow::Error;\nuse memoffset::offset_of;\nuse more_asserts::assert_lt;\nuse std::alloc::Layout;\nuse std::any::Any;\nuse std::convert::TryFrom;\nuse std::hash::Hash;\nuse std::ops::Range;\nuse std::ptr::NonNull;\nuse std::sync::atomic::AtomicU64;\nuse std::sync::Arc;\nuse std::{mem, ptr, slice};\nuse wasmtime_environ::{\n    packed_option::ReservedValue, DataIndex, DefinedGlobalIndex, DefinedMemoryIndex,\n    DefinedTableIndex, ElemIndex, EntityIndex, EntityRef, EntitySet, FuncIndex, GlobalIndex,\n    HostPtr, MemoryIndex, Module, PrimaryMap, TableIndex, TrapCode, VMOffsets, WasmType,\n};\n\nmod allocator;\n\npub use allocator::*;\n\n/// A type that roughly corresponds to a WebAssembly instance, but is also used\n/// for host-defined objects.\n///\n/// This structure is is never allocated directly but is instead managed through\n/// an `InstanceHandle`. This structure ends with a `VMContext` which has a\n/// dynamic size corresponding to the `module` configured within. Memory\n/// management of this structure is always externalized.\n///\n/// Instances here can correspond to actual instantiated modules, but it's also\n/// used ubiquitously for host-defined objects. For example creating a\n/// host-defined memory will have a `module` that looks like it exports a single\n/// memory (and similar for other constructs).\n///\n/// This `Instance` type is used as a ubiquitous representation for WebAssembly\n/// values, whether or not they were created on the host or through a module.\n#[repr(C)] // ensure that the vmctx field is last.\npub(crate) struct Instance {\n    /// The `Module` this `Instance` was instantiated from.\n    module: Arc<Module>,\n\n    /// The unique ID for the `Module` this `Instance` was instantiated from.\n    unique_id: Option<CompiledModuleId>,\n\n    /// Offsets in the `vmctx` region, precomputed from the `module` above.\n    offsets: VMOffsets<HostPtr>,\n\n    /// WebAssembly linear memory data.\n    ///\n    /// This is where all runtime information about defined linear memories in\n    /// this module lives.\n    memories: PrimaryMap<DefinedMemoryIndex, Memory>,\n\n    /// WebAssembly table data.\n    ///\n    /// Like memories, this is only for defined tables in the module and\n    /// contains all of their runtime state.\n    tables: PrimaryMap<DefinedTableIndex, Table>,\n\n    /// Stores the dropped passive element segments in this instantiation by index.\n    /// If the index is present in the set, the segment has been dropped.\n    dropped_elements: EntitySet<ElemIndex>,\n\n    /// Stores the dropped passive data segments in this instantiation by index.\n    /// If the index is present in the set, the segment has been dropped.\n    dropped_data: EntitySet<DataIndex>,\n\n    /// A slice pointing to all data that is referenced by this instance. This\n    /// data is managed externally so this is effectively an unsafe reference,\n    /// and this does not live for the `'static` lifetime so the API boundaries\n    /// here are careful to never hand out static references.\n    wasm_data: &'static [u8],\n\n    /// Hosts can store arbitrary per-instance information here.\n    ///\n    /// Most of the time from Wasmtime this is `Box::new(())`, a noop\n    /// allocation, but some host-defined objects will store their state here.\n    host_state: Box<dyn Any + Send + Sync>,\n\n    /// Additional context used by compiled wasm code. This field is last, and\n    /// represents a dynamically-sized array that extends beyond the nominal\n    /// end of the struct (similar to a flexible array member).\n    vmctx: VMContext,\n}\n\n#[allow(clippy::cast_ptr_alignment)]\nimpl Instance {\n    /// Helper for allocators; not a public API.\n    pub(crate) fn create_raw(\n        module: &Arc<Module>,\n        unique_id: Option<CompiledModuleId>,\n        wasm_data: &'static [u8],\n        memories: PrimaryMap<DefinedMemoryIndex, Memory>,\n        tables: PrimaryMap<DefinedTableIndex, Table>,\n        host_state: Box<dyn Any + Send + Sync>,\n    ) -> Instance {\n        Instance {\n            module: module.clone(),\n            unique_id,\n            offsets: VMOffsets::new(HostPtr, &module),\n            memories,\n            tables,\n            dropped_elements: EntitySet::with_capacity(module.passive_elements.len()),\n            dropped_data: EntitySet::with_capacity(module.passive_data_map.len()),\n            host_state,\n            wasm_data,\n            vmctx: VMContext {\n                _marker: std::marker::PhantomPinned,\n            },\n        }\n    }\n\n    /// Helper function to access various locations offset from our `*mut\n    /// VMContext` object.\n    unsafe fn vmctx_plus_offset<T>(&self, offset: u32) -> *mut T {\n        (self.vmctx_ptr().cast::<u8>())\n            .add(usize::try_from(offset).unwrap())\n            .cast()\n    }\n\n    pub(crate) fn module(&self) -> &Arc<Module> {\n        &self.module\n    }\n\n    /// Return the indexed `VMFunctionImport`.\n    fn imported_function(&self, index: FuncIndex) -> &VMFunctionImport {\n        unsafe { &*self.vmctx_plus_offset(self.offsets.vmctx_vmfunction_import(index)) }\n    }\n\n    /// Return the index `VMTableImport`.\n    fn imported_table(&self, index: TableIndex) -> &VMTableImport {\n        unsafe { &*self.vmctx_plus_offset(self.offsets.vmctx_vmtable_import(index)) }\n    }\n\n    /// Return the indexed `VMMemoryImport`.\n    fn imported_memory(&self, index: MemoryIndex) -> &VMMemoryImport {\n        unsafe { &*self.vmctx_plus_offset(self.offsets.vmctx_vmmemory_import(index)) }\n    }\n\n    /// Return the indexed `VMGlobalImport`.\n    fn imported_global(&self, index: GlobalIndex) -> &VMGlobalImport {\n        unsafe { &*self.vmctx_plus_offset(self.offsets.vmctx_vmglobal_import(index)) }\n    }\n\n    /// Return the indexed `VMTableDefinition`.\n    #[allow(dead_code)]\n    fn table(&self, index: DefinedTableIndex) -> VMTableDefinition {\n        unsafe { *self.table_ptr(index) }\n    }\n\n    /// Updates the value for a defined table to `VMTableDefinition`.\n    fn set_table(&self, index: DefinedTableIndex, table: VMTableDefinition) {\n        unsafe {\n            *self.table_ptr(index) = table;\n        }\n    }\n\n    /// Return the indexed `VMTableDefinition`.\n    fn table_ptr(&self, index: DefinedTableIndex) -> *mut VMTableDefinition {\n        unsafe { self.vmctx_plus_offset(self.offsets.vmctx_vmtable_definition(index)) }\n    }\n\n    /// Get a locally defined or imported memory.\n    pub(crate) fn get_memory(&self, index: MemoryIndex) -> VMMemoryDefinition {\n        if let Some(defined_index) = self.module.defined_memory_index(index) {\n            self.memory(defined_index)\n        } else {\n            let import = self.imported_memory(index);\n            *unsafe { import.from.as_ref().unwrap() }\n        }\n    }\n\n    /// Return the indexed `VMMemoryDefinition`.\n    fn memory(&self, index: DefinedMemoryIndex) -> VMMemoryDefinition {\n        unsafe { *self.memory_ptr(index) }\n    }\n\n    /// Set the indexed memory to `VMMemoryDefinition`.\n    fn set_memory(&self, index: DefinedMemoryIndex, mem: VMMemoryDefinition) {\n        unsafe {\n            *self.memory_ptr(index) = mem;\n        }\n    }\n\n    /// Return the indexed `VMMemoryDefinition`.\n    fn memory_ptr(&self, index: DefinedMemoryIndex) -> *mut VMMemoryDefinition {\n        unsafe { self.vmctx_plus_offset(self.offsets.vmctx_vmmemory_definition(index)) }\n    }\n\n    /// Return the indexed `VMGlobalDefinition`.\n    fn global(&self, index: DefinedGlobalIndex) -> &VMGlobalDefinition {\n        unsafe { &*self.global_ptr(index) }\n    }\n\n    /// Return the indexed `VMGlobalDefinition`.\n    fn global_ptr(&self, index: DefinedGlobalIndex) -> *mut VMGlobalDefinition {\n        unsafe { self.vmctx_plus_offset(self.offsets.vmctx_vmglobal_definition(index)) }\n    }\n\n    /// Get a raw pointer to the global at the given index regardless whether it\n    /// is defined locally or imported from another module.\n    ///\n    /// Panics if the index is out of bound or is the reserved value.\n    pub(crate) fn defined_or_imported_global_ptr(\n        &self,\n        index: GlobalIndex,\n    ) -> *mut VMGlobalDefinition {\n        if let Some(index) = self.module.defined_global_index(index) {\n            self.global_ptr(index)\n        } else {\n            self.imported_global(index).from\n        }\n    }\n\n    /// Return a pointer to the interrupts structure\n    pub fn interrupts(&self) -> *mut *const VMInterrupts {\n        unsafe { self.vmctx_plus_offset(self.offsets.vmctx_interrupts()) }\n    }\n\n    /// Return a pointer to the global epoch counter used by this instance.\n    pub fn epoch_ptr(&self) -> *mut *const AtomicU64 {\n        unsafe { self.vmctx_plus_offset(self.offsets.vmctx_epoch_ptr()) }\n    }\n\n    /// Return a pointer to the `VMExternRefActivationsTable`.\n    pub fn externref_activations_table(&self) -> *mut *mut VMExternRefActivationsTable {\n        unsafe { self.vmctx_plus_offset(self.offsets.vmctx_externref_activations_table()) }\n    }\n\n    /// Gets a pointer to this instance's `Store` which was originally\n    /// configured on creation.\n    ///\n    /// # Panics\n    ///\n    /// This will panic if the originally configured store was `None`. That can\n    /// happen for host functions so host functions can't be queried what their\n    /// original `Store` was since it's just retained as null (since host\n    /// functions are shared amongst threads and don't all share the same\n    /// store).\n    #[inline]\n    pub fn store(&self) -> *mut dyn Store {\n        let ptr = unsafe { *self.vmctx_plus_offset::<*mut dyn Store>(self.offsets.vmctx_store()) };\n        assert!(!ptr.is_null());\n        ptr\n    }\n\n    pub unsafe fn set_store(&mut self, store: *mut dyn Store) {\n        *self.vmctx_plus_offset(self.offsets.vmctx_store()) = store;\n    }\n\n    /// Return a reference to the vmctx used by compiled wasm code.\n    #[inline]\n    pub fn vmctx(&self) -> &VMContext {\n        &self.vmctx\n    }\n\n    /// Return a raw pointer to the vmctx used by compiled wasm code.\n    #[inline]\n    pub fn vmctx_ptr(&self) -> *mut VMContext {\n        self.vmctx() as *const VMContext as *mut VMContext\n    }\n\n    /// Lookup an export with the given export declaration.\n    pub fn lookup_by_declaration(&self, export: &EntityIndex) -> Export {\n        match export {\n            EntityIndex::Function(index) => {\n                let anyfunc = self.get_caller_checked_anyfunc(*index).unwrap();\n                let anyfunc =\n                    NonNull::new(anyfunc as *const VMCallerCheckedAnyfunc as *mut _).unwrap();\n                ExportFunction { anyfunc }.into()\n            }\n            EntityIndex::Table(index) => {\n                let (definition, vmctx) =\n                    if let Some(def_index) = self.module.defined_table_index(*index) {\n                        (self.table_ptr(def_index), self.vmctx_ptr())\n                    } else {\n                        let import = self.imported_table(*index);\n                        (import.from, import.vmctx)\n                    };\n                ExportTable {\n                    definition,\n                    vmctx,\n                    table: self.module.table_plans[*index].clone(),\n                }\n                .into()\n            }\n            EntityIndex::Memory(index) => {\n                let (definition, vmctx) =\n                    if let Some(def_index) = self.module.defined_memory_index(*index) {\n                        (self.memory_ptr(def_index), self.vmctx_ptr())\n                    } else {\n                        let import = self.imported_memory(*index);\n                        (import.from, import.vmctx)\n                    };\n                ExportMemory {\n                    definition,\n                    vmctx,\n                    memory: self.module.memory_plans[*index].clone(),\n                }\n                .into()\n            }\n            EntityIndex::Global(index) => ExportGlobal {\n                definition: if let Some(def_index) = self.module.defined_global_index(*index) {\n                    self.global_ptr(def_index)\n                } else {\n                    self.imported_global(*index).from\n                },\n                vmctx: self.vmctx_ptr(),\n                global: self.module.globals[*index],\n            }\n            .into(),\n\n            EntityIndex::Instance(_) | EntityIndex::Module(_) => {\n                panic!(\"can't use this api for modules/instances\")\n            }\n        }\n    }\n\n    /// Return an iterator over the exports of this instance.\n    ///\n    /// Specifically, it provides access to the key-value pairs, where the keys\n    /// are export names, and the values are export declarations which can be\n    /// resolved `lookup_by_declaration`.\n    pub fn exports(&self) -> indexmap::map::Iter<String, EntityIndex> {\n        self.module.exports.iter()\n    }\n\n    /// Return a reference to the custom state attached to this instance.\n    #[inline]\n    pub fn host_state(&self) -> &dyn Any {\n        &*self.host_state\n    }\n\n    /// Return the offset from the vmctx pointer to its containing Instance.\n    #[inline]\n    pub(crate) fn vmctx_offset() -> isize {\n        offset_of!(Self, vmctx) as isize\n    }\n\n    /// Return the table index for the given `VMTableDefinition`.\n    unsafe fn table_index(&self, table: &VMTableDefinition) -> DefinedTableIndex {\n        let index = DefinedTableIndex::new(\n            usize::try_from(\n                (table as *const VMTableDefinition)\n                    .offset_from(self.table_ptr(DefinedTableIndex::new(0))),\n            )\n            .unwrap(),\n        );\n        assert_lt!(index.index(), self.tables.len());\n        index\n    }\n\n    /// Return the memory index for the given `VMMemoryDefinition`.\n    unsafe fn memory_index(&self, memory: &VMMemoryDefinition) -> DefinedMemoryIndex {\n        let index = DefinedMemoryIndex::new(\n            usize::try_from(\n                (memory as *const VMMemoryDefinition)\n                    .offset_from(self.memory_ptr(DefinedMemoryIndex::new(0))),\n            )\n            .unwrap(),\n        );\n        assert_lt!(index.index(), self.memories.len());\n        index\n    }\n\n    /// Grow memory by the specified amount of pages.\n    ///\n    /// Returns `None` if memory can't be grown by the specified amount\n    /// of pages. Returns `Some` with the old size in bytes if growth was\n    /// successful.\n    pub(crate) fn memory_grow(\n        &mut self,\n        index: MemoryIndex,\n        delta: u64,\n    ) -> Result<Option<usize>, Error> {\n        let (idx, instance) = if let Some(idx) = self.module.defined_memory_index(index) {\n            (idx, self)\n        } else {\n            let import = self.imported_memory(index);\n            unsafe {\n                let foreign_instance = (*import.vmctx).instance_mut();\n                let foreign_memory_def = &*import.from;\n                let foreign_memory_index = foreign_instance.memory_index(foreign_memory_def);\n                (foreign_memory_index, foreign_instance)\n            }\n        };\n        let store = unsafe { &mut *instance.store() };\n        let memory = &mut instance.memories[idx];\n\n        let result = unsafe { memory.grow(delta, store) };\n        let vmmemory = memory.vmmemory();\n\n        // Update the state used by wasm code in case the base pointer and/or\n        // the length changed.\n        instance.set_memory(idx, vmmemory);\n\n        result\n    }\n\n    pub(crate) fn table_element_type(&mut self, table_index: TableIndex) -> TableElementType {\n        unsafe { (*self.get_table(table_index)).element_type() }\n    }\n\n    /// Grow table by the specified amount of elements, filling them with\n    /// `init_value`.\n    ///\n    /// Returns `None` if table can't be grown by the specified amount of\n    /// elements, or if `init_value` is the wrong type of table element.\n    pub(crate) fn table_grow(\n        &mut self,\n        table_index: TableIndex,\n        delta: u32,\n        init_value: TableElement,\n    ) -> Result<Option<u32>, Error> {\n        let (defined_table_index, instance) =\n            self.get_defined_table_index_and_instance(table_index);\n        instance.defined_table_grow(defined_table_index, delta, init_value)\n    }\n\n    fn defined_table_grow(\n        &mut self,\n        table_index: DefinedTableIndex,\n        delta: u32,\n        init_value: TableElement,\n    ) -> Result<Option<u32>, Error> {\n        let store = unsafe { &mut *self.store() };\n        let table = self\n            .tables\n            .get_mut(table_index)\n            .unwrap_or_else(|| panic!(\"no table for index {}\", table_index.index()));\n\n        let result = unsafe { table.grow(delta, init_value, store) };\n\n        // Keep the `VMContext` pointers used by compiled Wasm code up to\n        // date.\n        let element = self.tables[table_index].vmtable();\n        self.set_table(table_index, element);\n\n        result\n    }\n\n    fn alloc_layout(&self) -> Layout {\n        let size = mem::size_of_val(self)\n            .checked_add(usize::try_from(self.offsets.size_of_vmctx()).unwrap())\n            .unwrap();\n        let align = mem::align_of_val(self);\n        Layout::from_size_align(size, align).unwrap()\n    }\n\n    /// Get a `&VMCallerCheckedAnyfunc` for the given `FuncIndex`.\n    ///\n    /// Returns `None` if the index is the reserved index value.\n    ///\n    /// The returned reference is a stable reference that won't be moved and can\n    /// be passed into JIT code.\n    pub(crate) fn get_caller_checked_anyfunc(\n        &self,\n        index: FuncIndex,\n    ) -> Option<&VMCallerCheckedAnyfunc> {\n        if index == FuncIndex::reserved_value() {\n            return None;\n        }\n\n        unsafe { Some(&*self.vmctx_plus_offset(self.offsets.vmctx_anyfunc(index))) }\n    }\n\n    unsafe fn anyfunc_base(&self) -> *mut VMCallerCheckedAnyfunc {\n        self.vmctx_plus_offset(self.offsets.vmctx_anyfuncs_begin())\n    }\n\n    /// The `table.init` operation: initializes a portion of a table with a\n    /// passive element.\n    ///\n    /// # Errors\n    ///\n    /// Returns a `Trap` error when the range within the table is out of bounds\n    /// or the range within the passive element is out of bounds.\n    pub(crate) fn table_init(\n        &mut self,\n        table_index: TableIndex,\n        elem_index: ElemIndex,\n        dst: u32,\n        src: u32,\n        len: u32,\n    ) -> Result<(), Trap> {\n        // TODO: this `clone()` shouldn't be necessary but is used for now to\n        // inform `rustc` that the lifetime of the elements here are\n        // disconnected from the lifetime of `self`.\n        let module = self.module.clone();\n\n        let elements = match module.passive_elements_map.get(&elem_index) {\n            Some(index) if !self.dropped_elements.contains(elem_index) => {\n                module.passive_elements[*index].as_ref()\n            }\n            _ => &[],\n        };\n        self.table_init_segment(table_index, elements, dst, src, len)\n    }\n\n    pub(crate) fn table_init_segment(\n        &mut self,\n        table_index: TableIndex,\n        elements: &[FuncIndex],\n        dst: u32,\n        src: u32,\n        len: u32,\n    ) -> Result<(), Trap> {\n        // https://webassembly.github.io/bulk-memory-operations/core/exec/instructions.html#exec-table-init\n\n        let table = unsafe { &mut *self.get_table(table_index) };\n\n        let elements = match elements\n            .get(usize::try_from(src).unwrap()..)\n            .and_then(|s| s.get(..usize::try_from(len).unwrap()))\n        {\n            Some(elements) => elements,\n            None => return Err(Trap::wasm(TrapCode::TableOutOfBounds)),\n        };\n\n        match table.element_type() {\n            TableElementType::Func => unsafe {\n                let base = self.anyfunc_base();\n                table.init_funcs(\n                    dst,\n                    elements.iter().map(|idx| {\n                        if *idx == FuncIndex::reserved_value() {\n                            ptr::null_mut()\n                        } else {\n                            debug_assert!(idx.as_u32() < self.offsets.num_defined_functions);\n                            base.add(usize::try_from(idx.as_u32()).unwrap())\n                        }\n                    }),\n                )?;\n            },\n\n            TableElementType::Extern => {\n                debug_assert!(elements.iter().all(|e| *e == FuncIndex::reserved_value()));\n                table.fill(dst, TableElement::ExternRef(None), len)?;\n            }\n        }\n        Ok(())\n    }\n\n    /// Drop an element.\n    pub(crate) fn elem_drop(&mut self, elem_index: ElemIndex) {\n        // https://webassembly.github.io/reference-types/core/exec/instructions.html#exec-elem-drop\n\n        self.dropped_elements.insert(elem_index);\n\n        // Note that we don't check that we actually removed a segment because\n        // dropping a non-passive segment is a no-op (not a trap).\n    }\n\n    /// Get a locally-defined memory.\n    pub(crate) fn get_defined_memory(&mut self, index: DefinedMemoryIndex) -> *mut Memory {\n        ptr::addr_of_mut!(self.memories[index])\n    }\n\n    /// Do a `memory.copy`\n    ///\n    /// # Errors\n    ///\n    /// Returns a `Trap` error when the source or destination ranges are out of\n    /// bounds.\n    pub(crate) fn memory_copy(\n        &mut self,\n        dst_index: MemoryIndex,\n        dst: u64,\n        src_index: MemoryIndex,\n        src: u64,\n        len: u64,\n    ) -> Result<(), Trap> {\n        // https://webassembly.github.io/reference-types/core/exec/instructions.html#exec-memory-copy\n\n        let src_mem = self.get_memory(src_index);\n        let dst_mem = self.get_memory(dst_index);\n\n        let src = self.validate_inbounds(src_mem.current_length, src, len)?;\n        let dst = self.validate_inbounds(dst_mem.current_length, dst, len)?;\n\n        // Bounds and casts are checked above, by this point we know that\n        // everything is safe.\n        unsafe {\n            let dst = dst_mem.base.add(dst);\n            let src = src_mem.base.add(src);\n            ptr::copy(src, dst, len as usize);\n        }\n\n        Ok(())\n    }\n\n    fn validate_inbounds(&self, max: usize, ptr: u64, len: u64) -> Result<usize, Trap> {\n        let oob = || Trap::wasm(TrapCode::HeapOutOfBounds);\n        let end = ptr\n            .checked_add(len)\n            .and_then(|i| usize::try_from(i).ok())\n            .ok_or_else(oob)?;\n        if end > max {\n            Err(oob())\n        } else {\n            Ok(ptr as usize)\n        }\n    }\n\n    /// Perform the `memory.fill` operation on a locally defined memory.\n    ///\n    /// # Errors\n    ///\n    /// Returns a `Trap` error if the memory range is out of bounds.\n    pub(crate) fn memory_fill(\n        &mut self,\n        memory_index: MemoryIndex,\n        dst: u64,\n        val: u8,\n        len: u64,\n    ) -> Result<(), Trap> {\n        let memory = self.get_memory(memory_index);\n        let dst = self.validate_inbounds(memory.current_length, dst, len)?;\n\n        // Bounds and casts are checked above, by this point we know that\n        // everything is safe.\n        unsafe {\n            let dst = memory.base.add(dst);\n            ptr::write_bytes(dst, val, len as usize);\n        }\n\n        Ok(())\n    }\n\n    /// Performs the `memory.init` operation.\n    ///\n    /// # Errors\n    ///\n    /// Returns a `Trap` error if the destination range is out of this module's\n    /// memory's bounds or if the source range is outside the data segment's\n    /// bounds.\n    pub(crate) fn memory_init(\n        &mut self,\n        memory_index: MemoryIndex,\n        data_index: DataIndex,\n        dst: u64,\n        src: u32,\n        len: u32,\n    ) -> Result<(), Trap> {\n        let range = match self.module.passive_data_map.get(&data_index).cloned() {\n            Some(range) if !self.dropped_data.contains(data_index) => range,\n            _ => 0..0,\n        };\n        self.memory_init_segment(memory_index, range, dst, src, len)\n    }\n\n    pub(crate) fn wasm_data(&self, range: Range<u32>) -> &[u8] {\n        &self.wasm_data[range.start as usize..range.end as usize]\n    }\n\n    pub(crate) fn memory_init_segment(\n        &mut self,\n        memory_index: MemoryIndex,\n        range: Range<u32>,\n        dst: u64,\n        src: u32,\n        len: u32,\n    ) -> Result<(), Trap> {\n        // https://webassembly.github.io/bulk-memory-operations/core/exec/instructions.html#exec-memory-init\n\n        let memory = self.get_memory(memory_index);\n        let data = self.wasm_data(range);\n        let dst = self.validate_inbounds(memory.current_length, dst, len.into())?;\n        let src = self.validate_inbounds(data.len(), src.into(), len.into())?;\n        let len = len as usize;\n\n        let src_slice = &data[src..(src + len)];\n\n        unsafe {\n            let dst_start = memory.base.add(dst);\n            let dst_slice = slice::from_raw_parts_mut(dst_start, len);\n            dst_slice.copy_from_slice(src_slice);\n        }\n\n        Ok(())\n    }\n\n    /// Drop the given data segment, truncating its length to zero.\n    pub(crate) fn data_drop(&mut self, data_index: DataIndex) {\n        self.dropped_data.insert(data_index);\n\n        // Note that we don't check that we actually removed a segment because\n        // dropping a non-passive segment is a no-op (not a trap).\n    }\n\n    /// Get a table by index regardless of whether it is locally-defined or an\n    /// imported, foreign table.\n    pub(crate) fn get_table(&mut self, table_index: TableIndex) -> *mut Table {\n        let (idx, instance) = self.get_defined_table_index_and_instance(table_index);\n        ptr::addr_of_mut!(instance.tables[idx])\n    }\n\n    /// Get a locally-defined table.\n    pub(crate) fn get_defined_table(&mut self, index: DefinedTableIndex) -> *mut Table {\n        ptr::addr_of_mut!(self.tables[index])\n    }\n\n    pub(crate) fn get_defined_table_index_and_instance(\n        &mut self,\n        index: TableIndex,\n    ) -> (DefinedTableIndex, &mut Instance) {\n        if let Some(defined_table_index) = self.module.defined_table_index(index) {\n            (defined_table_index, self)\n        } else {\n            let import = self.imported_table(index);\n            unsafe {\n                let foreign_instance = (*import.vmctx).instance_mut();\n                let foreign_table_def = &*import.from;\n                let foreign_table_index = foreign_instance.table_index(foreign_table_def);\n                (foreign_table_index, foreign_instance)\n            }\n        }\n    }\n\n    fn drop_globals(&mut self) {\n        for (idx, global) in self.module.globals.iter() {\n            let idx = match self.module.defined_global_index(idx) {\n                Some(idx) => idx,\n                None => continue,\n            };\n            match global.wasm_ty {\n                // For now only externref gloabls need to get destroyed\n                WasmType::ExternRef => {}\n                _ => continue,\n            }\n            unsafe {\n                drop((*self.global_ptr(idx)).as_externref_mut().take());\n            }\n        }\n    }\n}\n\nimpl Drop for Instance {\n    fn drop(&mut self) {\n        self.drop_globals();\n    }\n}\n\n/// A handle holding an `Instance` of a WebAssembly module.\n#[derive(Hash, PartialEq, Eq)]\npub struct InstanceHandle {\n    instance: *mut Instance,\n}\n\n// These are only valid if the `Instance` type is send/sync, hence the\n// assertion below.\nunsafe impl Send for InstanceHandle {}\nunsafe impl Sync for InstanceHandle {}\n\nfn _assert_send_sync() {\n    fn _assert<T: Send + Sync>() {}\n    _assert::<Instance>();\n}\n\nimpl InstanceHandle {\n    /// Create a new `InstanceHandle` pointing at the instance\n    /// pointed to by the given `VMContext` pointer.\n    ///\n    /// # Safety\n    /// This is unsafe because it doesn't work on just any `VMContext`, it must\n    /// be a `VMContext` allocated as part of an `Instance`.\n    #[inline]\n    pub unsafe fn from_vmctx(vmctx: *mut VMContext) -> Self {\n        let instance = (&mut *vmctx).instance();\n        Self {\n            instance: instance as *const Instance as *mut Instance,\n        }\n    }\n\n    /// Return a reference to the vmctx used by compiled wasm code.\n    pub fn vmctx(&self) -> &VMContext {\n        self.instance().vmctx()\n    }\n\n    /// Return a raw pointer to the vmctx used by compiled wasm code.\n    #[inline]\n    pub fn vmctx_ptr(&self) -> *mut VMContext {\n        self.instance().vmctx_ptr()\n    }\n\n    /// Return a reference to a module.\n    pub fn module(&self) -> &Arc<Module> {\n        self.instance().module()\n    }\n\n    /// Lookup an export with the given export declaration.\n    pub fn lookup_by_declaration(&self, export: &EntityIndex) -> Export {\n        self.instance().lookup_by_declaration(export)\n    }\n\n    /// Return an iterator over the exports of this instance.\n    ///\n    /// Specifically, it provides access to the key-value pairs, where the keys\n    /// are export names, and the values are export declarations which can be\n    /// resolved `lookup_by_declaration`.\n    pub fn exports(&self) -> indexmap::map::Iter<String, EntityIndex> {\n        self.instance().exports()\n    }\n\n    /// Return a reference to the custom state attached to this instance.\n    pub fn host_state(&self) -> &dyn Any {\n        self.instance().host_state()\n    }\n\n    /// Return the memory index for the given `VMMemoryDefinition` in this instance.\n    pub unsafe fn memory_index(&self, memory: &VMMemoryDefinition) -> DefinedMemoryIndex {\n        self.instance().memory_index(memory)\n    }\n\n    /// Get a memory defined locally within this module.\n    pub fn get_defined_memory(&mut self, index: DefinedMemoryIndex) -> *mut Memory {\n        self.instance_mut().get_defined_memory(index)\n    }\n\n    /// Return the table index for the given `VMTableDefinition` in this instance.\n    pub unsafe fn table_index(&self, table: &VMTableDefinition) -> DefinedTableIndex {\n        self.instance().table_index(table)\n    }\n\n    /// Get a table defined locally within this module.\n    pub fn get_defined_table(&mut self, index: DefinedTableIndex) -> *mut Table {\n        self.instance_mut().get_defined_table(index)\n    }\n\n    /// Return a reference to the contained `Instance`.\n    #[inline]\n    pub(crate) fn instance(&self) -> &Instance {\n        unsafe { &*(self.instance as *const Instance) }\n    }\n\n    pub(crate) fn instance_mut(&mut self) -> &mut Instance {\n        unsafe { &mut *self.instance }\n    }\n\n    /// Returns the `Store` pointer that was stored on creation\n    #[inline]\n    pub fn store(&self) -> *mut dyn Store {\n        self.instance().store()\n    }\n\n    /// Configure the `*mut dyn Store` internal pointer after-the-fact.\n    ///\n    /// This is provided for the original `Store` itself to configure the first\n    /// self-pointer after the original `Box` has been initialized.\n    pub unsafe fn set_store(&mut self, store: *mut dyn Store) {\n        self.instance_mut().set_store(store);\n    }\n\n    /// Returns a clone of this instance.\n    ///\n    /// This is unsafe because the returned handle here is just a cheap clone\n    /// of the internals, there's no lifetime tracking around its validity.\n    /// You'll need to ensure that the returned handles all go out of scope at\n    /// the same time.\n    #[inline]\n    pub unsafe fn clone(&self) -> InstanceHandle {\n        InstanceHandle {\n            instance: self.instance,\n        }\n    }\n}\n", "use crate::imports::Imports;\nuse crate::instance::{Instance, InstanceHandle, RuntimeMemoryCreator};\nuse crate::memory::{DefaultMemoryCreator, Memory};\nuse crate::table::Table;\nuse crate::traphandlers::Trap;\nuse crate::vmcontext::{\n    VMBuiltinFunctionsArray, VMCallerCheckedAnyfunc, VMGlobalDefinition, VMSharedSignatureIndex,\n};\nuse crate::ModuleMemFds;\nuse crate::{CompiledModuleId, Store};\nuse anyhow::Result;\nuse std::alloc;\nuse std::any::Any;\nuse std::convert::TryFrom;\nuse std::ptr::{self, NonNull};\nuse std::slice;\nuse std::sync::Arc;\nuse thiserror::Error;\nuse wasmtime_environ::{\n    DefinedFuncIndex, DefinedMemoryIndex, DefinedTableIndex, EntityRef, FunctionInfo, GlobalInit,\n    InitMemory, MemoryInitialization, MemoryInitializer, Module, ModuleType, PrimaryMap,\n    SignatureIndex, TableInitializer, TrapCode, WasmType, WASM_PAGE_SIZE,\n};\n\n#[cfg(feature = \"pooling-allocator\")]\nmod pooling;\n\n#[cfg(feature = \"pooling-allocator\")]\npub use self::pooling::{\n    InstanceLimits, ModuleLimits, PoolingAllocationStrategy, PoolingInstanceAllocator,\n};\n\n/// Represents a request for a new runtime instance.\npub struct InstanceAllocationRequest<'a> {\n    /// The module being instantiated.\n    pub module: &'a Arc<Module>,\n\n    /// The unique ID of the module being allocated within this engine.\n    pub unique_id: Option<CompiledModuleId>,\n\n    /// The base address of where JIT functions are located.\n    pub image_base: usize,\n\n    /// If using MemFD-based memories, the backing MemFDs.\n    pub memfds: Option<&'a Arc<ModuleMemFds>>,\n\n    /// Descriptors about each compiled function, such as the offset from\n    /// `image_base`.\n    pub functions: &'a PrimaryMap<DefinedFuncIndex, FunctionInfo>,\n\n    /// The imports to use for the instantiation.\n    pub imports: Imports<'a>,\n\n    /// Translation from `SignatureIndex` to `VMSharedSignatureIndex`\n    pub shared_signatures: SharedSignatures<'a>,\n\n    /// The host state to associate with the instance.\n    pub host_state: Box<dyn Any + Send + Sync>,\n\n    /// A pointer to the \"store\" for this instance to be allocated. The store\n    /// correlates with the `Store` in wasmtime itself, and lots of contextual\n    /// information about the execution of wasm can be learned through the store.\n    ///\n    /// Note that this is a raw pointer and has a static lifetime, both of which\n    /// are a bit of a lie. This is done purely so a store can learn about\n    /// itself when it gets called as a host function, and additionally so this\n    /// runtime can access internals as necessary (such as the\n    /// VMExternRefActivationsTable or the resource limiter methods).\n    ///\n    /// Note that this ends up being a self-pointer to the instance when stored.\n    /// The reason is that the instance itself is then stored within the store.\n    /// We use a number of `PhantomPinned` declarations to indicate this to the\n    /// compiler. More info on this in `wasmtime/src/store.rs`\n    pub store: StorePtr,\n\n    /// A list of all wasm data that can be referenced by the module that\n    /// will be allocated. The `Module` given here has active/passive data\n    /// segments that are specified as relative indices into this list of bytes.\n    ///\n    /// Note that this is an unsafe pointer. The pointer is expected to live for\n    /// the entire duration of the instance at this time. It's the\n    /// responsibility of the callee when allocating to ensure that this data\n    /// outlives the instance.\n    pub wasm_data: *const [u8],\n}\n\n/// A pointer to a Store. This Option<*mut dyn Store> is wrapped in a struct\n/// so that the function to create a &mut dyn Store is a method on a member of\n/// InstanceAllocationRequest, rather than on a &mut InstanceAllocationRequest\n/// itself, because several use-sites require a split mut borrow on the\n/// InstanceAllocationRequest.\npub struct StorePtr(Option<*mut dyn Store>);\nimpl StorePtr {\n    /// A pointer to no Store.\n    pub fn empty() -> Self {\n        Self(None)\n    }\n    /// A pointer to a Store.\n    pub fn new(ptr: *mut dyn Store) -> Self {\n        Self(Some(ptr))\n    }\n    /// The raw contents of this struct\n    pub fn as_raw(&self) -> Option<*mut dyn Store> {\n        self.0.clone()\n    }\n    /// Use the StorePtr as a mut ref to the Store.\n    /// Safety: must not be used outside the original lifetime of the borrow.\n    pub(crate) unsafe fn get(&mut self) -> Option<&mut dyn Store> {\n        match self.0 {\n            Some(ptr) => Some(&mut *ptr),\n            None => None,\n        }\n    }\n}\n\n/// An link error while instantiating a module.\n#[derive(Error, Debug)]\n#[error(\"Link error: {0}\")]\npub struct LinkError(pub String);\n\n/// An error while instantiating a module.\n#[derive(Error, Debug)]\npub enum InstantiationError {\n    /// Insufficient resources available for execution.\n    #[error(\"Insufficient resources: {0}\")]\n    Resource(anyhow::Error),\n\n    /// A wasm link error occured.\n    #[error(\"Failed to link module\")]\n    Link(#[from] LinkError),\n\n    /// A trap ocurred during instantiation, after linking.\n    #[error(\"Trap occurred during instantiation\")]\n    Trap(Trap),\n\n    /// A limit on how many instances are supported has been reached.\n    #[error(\"Limit of {0} concurrent instances has been reached\")]\n    Limit(u32),\n}\n\n/// An error while creating a fiber stack.\n#[cfg(feature = \"async\")]\n#[derive(Error, Debug)]\npub enum FiberStackError {\n    /// Insufficient resources available for the request.\n    #[error(\"Insufficient resources: {0}\")]\n    Resource(anyhow::Error),\n    /// An error for when the allocator doesn't support fiber stacks.\n    #[error(\"fiber stacks are not supported by the allocator\")]\n    NotSupported,\n    /// A limit on how many fibers are supported has been reached.\n    #[error(\"Limit of {0} concurrent fibers has been reached\")]\n    Limit(u32),\n}\n\n/// Represents a runtime instance allocator.\n///\n/// # Safety\n///\n/// This trait is unsafe as it requires knowledge of Wasmtime's runtime internals to implement correctly.\npub unsafe trait InstanceAllocator: Send + Sync {\n    /// Validates that a module is supported by the allocator.\n    fn validate(&self, module: &Module) -> Result<()> {\n        drop(module);\n        Ok(())\n    }\n\n    /// Adjusts the tunables prior to creation of any JIT compiler.\n    ///\n    /// This method allows the instance allocator control over tunables passed to a `wasmtime_jit::Compiler`.\n    fn adjust_tunables(&self, tunables: &mut wasmtime_environ::Tunables) {\n        drop(tunables);\n    }\n\n    /// Allocates an instance for the given allocation request.\n    ///\n    /// # Safety\n    ///\n    /// This method is not inherently unsafe, but care must be made to ensure\n    /// pointers passed in the allocation request outlive the returned instance.\n    unsafe fn allocate(\n        &self,\n        req: InstanceAllocationRequest,\n    ) -> Result<InstanceHandle, InstantiationError>;\n\n    /// Finishes the instantiation process started by an instance allocator.\n    ///\n    /// # Safety\n    ///\n    /// This method is only safe to call immediately after an instance has been allocated.\n    unsafe fn initialize(\n        &self,\n        handle: &mut InstanceHandle,\n        module: &Module,\n        is_bulk_memory: bool,\n    ) -> Result<(), InstantiationError>;\n\n    /// Deallocates a previously allocated instance.\n    ///\n    /// # Safety\n    ///\n    /// This function is unsafe because there are no guarantees that the given handle\n    /// is the only owner of the underlying instance to deallocate.\n    ///\n    /// Use extreme care when deallocating an instance so that there are no dangling instance pointers.\n    unsafe fn deallocate(&self, handle: &InstanceHandle);\n\n    /// Allocates a fiber stack for calling async functions on.\n    #[cfg(feature = \"async\")]\n    fn allocate_fiber_stack(&self) -> Result<wasmtime_fiber::FiberStack, FiberStackError>;\n\n    /// Deallocates a fiber stack that was previously allocated with `allocate_fiber_stack`.\n    ///\n    /// # Safety\n    ///\n    /// The provided stack is required to have been allocated with `allocate_fiber_stack`.\n    #[cfg(feature = \"async\")]\n    unsafe fn deallocate_fiber_stack(&self, stack: &wasmtime_fiber::FiberStack);\n}\n\npub enum SharedSignatures<'a> {\n    /// Used for instantiating user-defined modules\n    Table(&'a PrimaryMap<SignatureIndex, VMSharedSignatureIndex>),\n    /// Used for instance creation that has only a single function\n    Always(VMSharedSignatureIndex),\n    /// Used for instance creation that has no functions\n    None,\n}\n\nimpl SharedSignatures<'_> {\n    fn lookup(&self, index: SignatureIndex) -> VMSharedSignatureIndex {\n        match self {\n            SharedSignatures::Table(table) => table[index],\n            SharedSignatures::Always(index) => *index,\n            SharedSignatures::None => unreachable!(),\n        }\n    }\n}\n\nimpl<'a> From<VMSharedSignatureIndex> for SharedSignatures<'a> {\n    fn from(val: VMSharedSignatureIndex) -> SharedSignatures<'a> {\n        SharedSignatures::Always(val)\n    }\n}\n\nimpl<'a> From<Option<VMSharedSignatureIndex>> for SharedSignatures<'a> {\n    fn from(val: Option<VMSharedSignatureIndex>) -> SharedSignatures<'a> {\n        match val {\n            Some(idx) => SharedSignatures::Always(idx),\n            None => SharedSignatures::None,\n        }\n    }\n}\n\nimpl<'a> From<&'a PrimaryMap<SignatureIndex, VMSharedSignatureIndex>> for SharedSignatures<'a> {\n    fn from(val: &'a PrimaryMap<SignatureIndex, VMSharedSignatureIndex>) -> SharedSignatures<'a> {\n        SharedSignatures::Table(val)\n    }\n}\n\nfn get_table_init_start(\n    init: &TableInitializer,\n    instance: &Instance,\n) -> Result<u32, InstantiationError> {\n    match init.base {\n        Some(base) => {\n            let val = unsafe {\n                if let Some(def_index) = instance.module.defined_global_index(base) {\n                    *instance.global(def_index).as_u32()\n                } else {\n                    *(*instance.imported_global(base).from).as_u32()\n                }\n            };\n\n            init.offset.checked_add(val).ok_or_else(|| {\n                InstantiationError::Link(LinkError(\n                    \"element segment global base overflows\".to_owned(),\n                ))\n            })\n        }\n        None => Ok(init.offset),\n    }\n}\n\nfn check_table_init_bounds(\n    instance: &mut Instance,\n    module: &Module,\n) -> Result<(), InstantiationError> {\n    for init in &module.table_initializers {\n        let table = unsafe { &*instance.get_table(init.table_index) };\n        let start = get_table_init_start(init, instance)?;\n        let start = usize::try_from(start).unwrap();\n        let end = start.checked_add(init.elements.len());\n\n        match end {\n            Some(end) if end <= table.size() as usize => {\n                // Initializer is in bounds\n            }\n            _ => {\n                return Err(InstantiationError::Link(LinkError(\n                    \"table out of bounds: elements segment does not fit\".to_owned(),\n                )))\n            }\n        }\n    }\n\n    Ok(())\n}\n\nfn initialize_tables(instance: &mut Instance, module: &Module) -> Result<(), InstantiationError> {\n    for init in &module.table_initializers {\n        instance\n            .table_init_segment(\n                init.table_index,\n                &init.elements,\n                get_table_init_start(init, instance)?,\n                0,\n                init.elements.len() as u32,\n            )\n            .map_err(InstantiationError::Trap)?;\n    }\n\n    Ok(())\n}\n\nfn get_memory_init_start(\n    init: &MemoryInitializer,\n    instance: &Instance,\n) -> Result<u64, InstantiationError> {\n    match init.base {\n        Some(base) => {\n            let mem64 = instance.module.memory_plans[init.memory_index]\n                .memory\n                .memory64;\n            let val = unsafe {\n                let global = if let Some(def_index) = instance.module.defined_global_index(base) {\n                    instance.global(def_index)\n                } else {\n                    &*instance.imported_global(base).from\n                };\n                if mem64 {\n                    *global.as_u64()\n                } else {\n                    u64::from(*global.as_u32())\n                }\n            };\n\n            init.offset.checked_add(val).ok_or_else(|| {\n                InstantiationError::Link(LinkError(\"data segment global base overflows\".to_owned()))\n            })\n        }\n        None => Ok(init.offset),\n    }\n}\n\nfn check_memory_init_bounds(\n    instance: &Instance,\n    initializers: &[MemoryInitializer],\n) -> Result<(), InstantiationError> {\n    for init in initializers {\n        let memory = instance.get_memory(init.memory_index);\n        let start = get_memory_init_start(init, instance)?;\n        let end = usize::try_from(start)\n            .ok()\n            .and_then(|start| start.checked_add(init.data.len()));\n\n        match end {\n            Some(end) if end <= memory.current_length => {\n                // Initializer is in bounds\n            }\n            _ => {\n                return Err(InstantiationError::Link(LinkError(\n                    \"memory out of bounds: data segment does not fit\".into(),\n                )))\n            }\n        }\n    }\n\n    Ok(())\n}\n\nfn initialize_memories(instance: &mut Instance, module: &Module) -> Result<(), InstantiationError> {\n    let memory_size_in_pages =\n        &|memory| (instance.get_memory(memory).current_length as u64) / u64::from(WASM_PAGE_SIZE);\n\n    // Loads the `global` value and returns it as a `u64`, but sign-extends\n    // 32-bit globals which can be used as the base for 32-bit memories.\n    let get_global_as_u64 = &|global| unsafe {\n        let def = if let Some(def_index) = instance.module.defined_global_index(global) {\n            instance.global(def_index)\n        } else {\n            &*instance.imported_global(global).from\n        };\n        if module.globals[global].wasm_ty == WasmType::I64 {\n            *def.as_u64()\n        } else {\n            u64::from(*def.as_u32())\n        }\n    };\n\n    // Delegates to the `init_memory` method which is sort of a duplicate of\n    // `instance.memory_init_segment` but is used at compile-time in other\n    // contexts so is shared here to have only one method of memory\n    // initialization.\n    //\n    // This call to `init_memory` notably implements all the bells and whistles\n    // so errors only happen if an out-of-bounds segment is found, in which case\n    // a trap is returned.\n    let ok = module.memory_initialization.init_memory(\n        InitMemory::Runtime {\n            memory_size_in_pages,\n            get_global_as_u64,\n        },\n        &mut |memory_index, offset, data| {\n            // If this initializer applies to a defined memory but that memory\n            // doesn't need initialization, due to something like uffd or memfd\n            // pre-initializing it via mmap magic, then this initializer can be\n            // skipped entirely.\n            if let Some(memory_index) = module.defined_memory_index(memory_index) {\n                if !instance.memories[memory_index].needs_init() {\n                    return true;\n                }\n            }\n            let memory = instance.get_memory(memory_index);\n            let dst_slice =\n                unsafe { slice::from_raw_parts_mut(memory.base, memory.current_length) };\n            let dst = &mut dst_slice[usize::try_from(offset).unwrap()..][..data.len()];\n            dst.copy_from_slice(instance.wasm_data(data.clone()));\n            true\n        },\n    );\n    if !ok {\n        return Err(InstantiationError::Trap(Trap::wasm(\n            TrapCode::HeapOutOfBounds,\n        )));\n    }\n\n    Ok(())\n}\n\nfn check_init_bounds(instance: &mut Instance, module: &Module) -> Result<(), InstantiationError> {\n    check_table_init_bounds(instance, module)?;\n\n    match &instance.module.memory_initialization {\n        MemoryInitialization::Segmented(initializers) => {\n            check_memory_init_bounds(instance, initializers)?;\n        }\n        // Statically validated already to have everything in-bounds.\n        MemoryInitialization::Paged { .. } => {}\n    }\n\n    Ok(())\n}\n\nfn initialize_instance(\n    instance: &mut Instance,\n    module: &Module,\n    is_bulk_memory: bool,\n) -> Result<(), InstantiationError> {\n    // If bulk memory is not enabled, bounds check the data and element segments before\n    // making any changes. With bulk memory enabled, initializers are processed\n    // in-order and side effects are observed up to the point of an out-of-bounds\n    // initializer, so the early checking is not desired.\n    if !is_bulk_memory {\n        check_init_bounds(instance, module)?;\n    }\n\n    // Initialize the tables\n    initialize_tables(instance, module)?;\n\n    // Initialize the memories\n    initialize_memories(instance, &module)?;\n\n    Ok(())\n}\n\nunsafe fn initialize_vmcontext(instance: &mut Instance, req: InstanceAllocationRequest) {\n    if let Some(store) = req.store.as_raw() {\n        *instance.interrupts() = (*store).vminterrupts();\n        *instance.epoch_ptr() = (*store).epoch_ptr();\n        *instance.externref_activations_table() = (*store).externref_activations_table().0;\n        instance.set_store(store);\n    }\n\n    let module = &instance.module;\n\n    // Initialize shared signatures\n    let mut ptr = instance.vmctx_plus_offset(instance.offsets.vmctx_signature_ids_begin());\n    for sig in module.types.values() {\n        *ptr = match sig {\n            ModuleType::Function(sig) => req.shared_signatures.lookup(*sig),\n            _ => VMSharedSignatureIndex::new(u32::max_value()),\n        };\n        ptr = ptr.add(1);\n    }\n\n    // Initialize the built-in functions\n    *instance.vmctx_plus_offset(instance.offsets.vmctx_builtin_functions()) =\n        &VMBuiltinFunctionsArray::INIT;\n\n    // Initialize the imports\n    debug_assert_eq!(req.imports.functions.len(), module.num_imported_funcs);\n    ptr::copy(\n        req.imports.functions.as_ptr(),\n        instance.vmctx_plus_offset(instance.offsets.vmctx_imported_functions_begin()),\n        req.imports.functions.len(),\n    );\n    debug_assert_eq!(req.imports.tables.len(), module.num_imported_tables);\n    ptr::copy(\n        req.imports.tables.as_ptr(),\n        instance.vmctx_plus_offset(instance.offsets.vmctx_imported_tables_begin()),\n        req.imports.tables.len(),\n    );\n    debug_assert_eq!(req.imports.memories.len(), module.num_imported_memories);\n    ptr::copy(\n        req.imports.memories.as_ptr(),\n        instance.vmctx_plus_offset(instance.offsets.vmctx_imported_memories_begin()),\n        req.imports.memories.len(),\n    );\n    debug_assert_eq!(req.imports.globals.len(), module.num_imported_globals);\n    ptr::copy(\n        req.imports.globals.as_ptr(),\n        instance.vmctx_plus_offset(instance.offsets.vmctx_imported_globals_begin()),\n        req.imports.globals.len(),\n    );\n\n    // Initialize the functions\n    let mut base = instance.anyfunc_base();\n    for (index, sig) in instance.module.functions.iter() {\n        let type_index = req.shared_signatures.lookup(*sig);\n\n        let (func_ptr, vmctx) = if let Some(def_index) = instance.module.defined_func_index(index) {\n            (\n                NonNull::new((req.image_base + req.functions[def_index].start as usize) as *mut _)\n                    .unwrap(),\n                instance.vmctx_ptr(),\n            )\n        } else {\n            let import = instance.imported_function(index);\n            (import.body, import.vmctx)\n        };\n\n        ptr::write(\n            base,\n            VMCallerCheckedAnyfunc {\n                func_ptr,\n                type_index,\n                vmctx,\n            },\n        );\n        base = base.add(1);\n    }\n\n    // Initialize the defined tables\n    let mut ptr = instance.vmctx_plus_offset(instance.offsets.vmctx_tables_begin());\n    for i in 0..module.table_plans.len() - module.num_imported_tables {\n        ptr::write(ptr, instance.tables[DefinedTableIndex::new(i)].vmtable());\n        ptr = ptr.add(1);\n    }\n\n    // Initialize the defined memories\n    let mut ptr = instance.vmctx_plus_offset(instance.offsets.vmctx_memories_begin());\n    for i in 0..module.memory_plans.len() - module.num_imported_memories {\n        ptr::write(\n            ptr,\n            instance.memories[DefinedMemoryIndex::new(i)].vmmemory(),\n        );\n        ptr = ptr.add(1);\n    }\n\n    // Initialize the defined globals\n    initialize_vmcontext_globals(instance);\n}\n\nunsafe fn initialize_vmcontext_globals(instance: &Instance) {\n    let module = &instance.module;\n    let num_imports = module.num_imported_globals;\n    for (index, global) in module.globals.iter().skip(num_imports) {\n        let def_index = module.defined_global_index(index).unwrap();\n        let to = instance.global_ptr(def_index);\n\n        // Initialize the global before writing to it\n        ptr::write(to, VMGlobalDefinition::new());\n\n        match global.initializer {\n            GlobalInit::I32Const(x) => *(*to).as_i32_mut() = x,\n            GlobalInit::I64Const(x) => *(*to).as_i64_mut() = x,\n            GlobalInit::F32Const(x) => *(*to).as_f32_bits_mut() = x,\n            GlobalInit::F64Const(x) => *(*to).as_f64_bits_mut() = x,\n            GlobalInit::V128Const(x) => *(*to).as_u128_mut() = x,\n            GlobalInit::GetGlobal(x) => {\n                let from = if let Some(def_x) = module.defined_global_index(x) {\n                    instance.global(def_x)\n                } else {\n                    &*instance.imported_global(x).from\n                };\n                // Globals of type `externref` need to manage the reference\n                // count as values move between globals, everything else is just\n                // copy-able bits.\n                match global.wasm_ty {\n                    WasmType::ExternRef => *(*to).as_externref_mut() = from.as_externref().clone(),\n                    _ => ptr::copy_nonoverlapping(from, to, 1),\n                }\n            }\n            GlobalInit::RefFunc(f) => {\n                *(*to).as_anyfunc_mut() = instance.get_caller_checked_anyfunc(f).unwrap()\n                    as *const VMCallerCheckedAnyfunc;\n            }\n            GlobalInit::RefNullConst => match global.wasm_ty {\n                // `VMGlobalDefinition::new()` already zeroed out the bits\n                WasmType::FuncRef => {}\n                WasmType::ExternRef => {}\n                ty => panic!(\"unsupported reference type for global: {:?}\", ty),\n            },\n            GlobalInit::Import => panic!(\"locally-defined global initialized as import\"),\n        }\n    }\n}\n\n/// Represents the on-demand instance allocator.\n#[derive(Clone)]\npub struct OnDemandInstanceAllocator {\n    mem_creator: Option<Arc<dyn RuntimeMemoryCreator>>,\n    #[cfg(feature = \"async\")]\n    stack_size: usize,\n}\n\nimpl OnDemandInstanceAllocator {\n    /// Creates a new on-demand instance allocator.\n    pub fn new(mem_creator: Option<Arc<dyn RuntimeMemoryCreator>>, stack_size: usize) -> Self {\n        drop(stack_size); // suppress unused warnings w/o async feature\n        Self {\n            mem_creator,\n            #[cfg(feature = \"async\")]\n            stack_size,\n        }\n    }\n\n    fn create_tables(\n        module: &Module,\n        store: &mut StorePtr,\n    ) -> Result<PrimaryMap<DefinedTableIndex, Table>, InstantiationError> {\n        let num_imports = module.num_imported_tables;\n        let mut tables: PrimaryMap<DefinedTableIndex, _> =\n            PrimaryMap::with_capacity(module.table_plans.len() - num_imports);\n        for table in &module.table_plans.values().as_slice()[num_imports..] {\n            tables.push(\n                Table::new_dynamic(table, unsafe {\n                    store\n                        .get()\n                        .expect(\"if module has table plans, store is not empty\")\n                })\n                .map_err(InstantiationError::Resource)?,\n            );\n        }\n        Ok(tables)\n    }\n\n    fn create_memories(\n        &self,\n        module: &Module,\n        store: &mut StorePtr,\n        memfds: Option<&Arc<ModuleMemFds>>,\n    ) -> Result<PrimaryMap<DefinedMemoryIndex, Memory>, InstantiationError> {\n        let creator = self\n            .mem_creator\n            .as_deref()\n            .unwrap_or_else(|| &DefaultMemoryCreator);\n        let num_imports = module.num_imported_memories;\n        let mut memories: PrimaryMap<DefinedMemoryIndex, _> =\n            PrimaryMap::with_capacity(module.memory_plans.len() - num_imports);\n        for (memory_idx, plan) in module.memory_plans.iter().skip(num_imports) {\n            // Create a MemFdSlot if there is an image for this memory.\n            let defined_memory_idx = module\n                .defined_memory_index(memory_idx)\n                .expect(\"Skipped imports, should never be None\");\n            let memfd_image = memfds.and_then(|memfds| memfds.get_memory_image(defined_memory_idx));\n\n            memories.push(\n                Memory::new_dynamic(\n                    plan,\n                    creator,\n                    unsafe {\n                        store\n                            .get()\n                            .expect(\"if module has memory plans, store is not empty\")\n                    },\n                    memfd_image,\n                )\n                .map_err(InstantiationError::Resource)?,\n            );\n        }\n        Ok(memories)\n    }\n}\n\nimpl Default for OnDemandInstanceAllocator {\n    fn default() -> Self {\n        Self {\n            mem_creator: None,\n            #[cfg(feature = \"async\")]\n            stack_size: 0,\n        }\n    }\n}\n\nunsafe impl InstanceAllocator for OnDemandInstanceAllocator {\n    unsafe fn allocate(\n        &self,\n        mut req: InstanceAllocationRequest,\n    ) -> Result<InstanceHandle, InstantiationError> {\n        let memories = self.create_memories(&req.module, &mut req.store, req.memfds)?;\n        let tables = Self::create_tables(&req.module, &mut req.store)?;\n\n        let host_state = std::mem::replace(&mut req.host_state, Box::new(()));\n\n        let mut handle = {\n            let instance = Instance::create_raw(\n                &req.module,\n                req.unique_id,\n                &*req.wasm_data,\n                memories,\n                tables,\n                host_state,\n            );\n            let layout = instance.alloc_layout();\n            let instance_ptr = alloc::alloc(layout) as *mut Instance;\n            if instance_ptr.is_null() {\n                alloc::handle_alloc_error(layout);\n            }\n            ptr::write(instance_ptr, instance);\n            InstanceHandle {\n                instance: instance_ptr,\n            }\n        };\n\n        initialize_vmcontext(handle.instance_mut(), req);\n\n        Ok(handle)\n    }\n\n    unsafe fn initialize(\n        &self,\n        handle: &mut InstanceHandle,\n        module: &Module,\n        is_bulk_memory: bool,\n    ) -> Result<(), InstantiationError> {\n        initialize_instance(handle.instance_mut(), module, is_bulk_memory)\n    }\n\n    unsafe fn deallocate(&self, handle: &InstanceHandle) {\n        let layout = handle.instance().alloc_layout();\n        ptr::drop_in_place(handle.instance);\n        alloc::dealloc(handle.instance.cast(), layout);\n    }\n\n    #[cfg(feature = \"async\")]\n    fn allocate_fiber_stack(&self) -> Result<wasmtime_fiber::FiberStack, FiberStackError> {\n        if self.stack_size == 0 {\n            return Err(FiberStackError::NotSupported);\n        }\n\n        wasmtime_fiber::FiberStack::new(self.stack_size)\n            .map_err(|e| FiberStackError::Resource(e.into()))\n    }\n\n    #[cfg(feature = \"async\")]\n    unsafe fn deallocate_fiber_stack(&self, _stack: &wasmtime_fiber::FiberStack) {\n        // The on-demand allocator has no further bookkeeping for fiber stacks\n    }\n}\n", "use super::skip_pooling_allocator_tests;\nuse anyhow::Result;\nuse wasmtime::*;\n\n#[test]\nfn successful_instantiation() -> Result<()> {\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling {\n        strategy: PoolingAllocationStrategy::NextAvailable,\n        module_limits: ModuleLimits {\n            memory_pages: 1,\n            table_elements: 10,\n            ..Default::default()\n        },\n        instance_limits: InstanceLimits { count: 1 },\n    });\n    config.dynamic_memory_guard_size(0);\n    config.static_memory_guard_size(0);\n    config.static_memory_maximum_size(65536);\n\n    let engine = Engine::new(&config)?;\n    let module = Module::new(&engine, r#\"(module (memory 1) (table 10 funcref))\"#)?;\n\n    // Module should instantiate\n    let mut store = Store::new(&engine, ());\n    Instance::new(&mut store, &module, &[])?;\n\n    Ok(())\n}\n\n#[test]\nfn memory_limit() -> Result<()> {\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling {\n        strategy: PoolingAllocationStrategy::NextAvailable,\n        module_limits: ModuleLimits {\n            memory_pages: 3,\n            table_elements: 10,\n            ..Default::default()\n        },\n        instance_limits: InstanceLimits { count: 1 },\n    });\n    config.dynamic_memory_guard_size(0);\n    config.static_memory_guard_size(65536);\n    config.static_memory_maximum_size(3 * 65536);\n\n    let engine = Engine::new(&config)?;\n\n    // Module should fail to validate because the minimum is greater than the configured limit\n    match Module::new(&engine, r#\"(module (memory 4))\"#) {\n        Ok(_) => panic!(\"module compilation should fail\"),\n        Err(e) => assert_eq!(\n            e.to_string(),\n            \"memory index 0 has a minimum page size of 4 which exceeds the limit of 3\"\n        ),\n    }\n\n    let module = Module::new(\n        &engine,\n        r#\"(module (memory (export \"m\") 0) (func (export \"f\") (result i32) (memory.grow (i32.const 1))))\"#,\n    )?;\n\n    // Instantiate the module and grow the memory via the `f` function\n    {\n        let mut store = Store::new(&engine, ());\n        let instance = Instance::new(&mut store, &module, &[])?;\n        let f = instance.get_typed_func::<(), i32, _>(&mut store, \"f\")?;\n\n        assert_eq!(f.call(&mut store, ()).expect(\"function should not trap\"), 0);\n        assert_eq!(f.call(&mut store, ()).expect(\"function should not trap\"), 1);\n        assert_eq!(f.call(&mut store, ()).expect(\"function should not trap\"), 2);\n        assert_eq!(\n            f.call(&mut store, ()).expect(\"function should not trap\"),\n            -1\n        );\n        assert_eq!(\n            f.call(&mut store, ()).expect(\"function should not trap\"),\n            -1\n        );\n    }\n\n    // Instantiate the module and grow the memory via the Wasmtime API\n    let mut store = Store::new(&engine, ());\n    let instance = Instance::new(&mut store, &module, &[])?;\n\n    let memory = instance.get_memory(&mut store, \"m\").unwrap();\n    assert_eq!(memory.size(&store), 0);\n    assert_eq!(memory.grow(&mut store, 1).expect(\"memory should grow\"), 0);\n    assert_eq!(memory.size(&store), 1);\n    assert_eq!(memory.grow(&mut store, 1).expect(\"memory should grow\"), 1);\n    assert_eq!(memory.size(&store), 2);\n    assert_eq!(memory.grow(&mut store, 1).expect(\"memory should grow\"), 2);\n    assert_eq!(memory.size(&store), 3);\n    assert!(memory.grow(&mut store, 1).is_err());\n\n    Ok(())\n}\n\n#[test]\nfn memory_init() -> Result<()> {\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling {\n        strategy: PoolingAllocationStrategy::NextAvailable,\n        module_limits: ModuleLimits {\n            memory_pages: 2,\n            table_elements: 0,\n            ..Default::default()\n        },\n        instance_limits: InstanceLimits {\n            count: 1,\n            ..Default::default()\n        },\n    });\n\n    let engine = Engine::new(&config)?;\n\n    let module = Module::new(\n        &engine,\n        r#\"(module (memory (export \"m\") 2) (data (i32.const 65530) \"this data spans multiple pages\") (data (i32.const 10) \"hello world\"))\"#,\n    )?;\n\n    let mut store = Store::new(&engine, ());\n    let instance = Instance::new(&mut store, &module, &[])?;\n    let memory = instance.get_memory(&mut store, \"m\").unwrap();\n\n    assert_eq!(\n        &memory.data(&store)[65530..65560],\n        b\"this data spans multiple pages\"\n    );\n    assert_eq!(&memory.data(&store)[10..21], b\"hello world\");\n\n    Ok(())\n}\n\n#[test]\nfn memory_guard_page_trap() -> Result<()> {\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling {\n        strategy: PoolingAllocationStrategy::NextAvailable,\n        module_limits: ModuleLimits {\n            memory_pages: 2,\n            table_elements: 0,\n            ..Default::default()\n        },\n        instance_limits: InstanceLimits {\n            count: 1,\n            ..Default::default()\n        },\n    });\n\n    let engine = Engine::new(&config)?;\n\n    let module = Module::new(\n        &engine,\n        r#\"(module (memory (export \"m\") 0) (func (export \"f\") (param i32) local.get 0 i32.load drop))\"#,\n    )?;\n\n    // Instantiate the module and check for out of bounds trap\n    for _ in 0..10 {\n        let mut store = Store::new(&engine, ());\n        let instance = Instance::new(&mut store, &module, &[])?;\n        let m = instance.get_memory(&mut store, \"m\").unwrap();\n        let f = instance.get_typed_func::<i32, (), _>(&mut store, \"f\")?;\n\n        let trap = f.call(&mut store, 0).expect_err(\"function should trap\");\n        assert!(trap.to_string().contains(\"out of bounds\"));\n\n        let trap = f.call(&mut store, 1).expect_err(\"function should trap\");\n        assert!(trap.to_string().contains(\"out of bounds\"));\n\n        m.grow(&mut store, 1).expect(\"memory should grow\");\n        f.call(&mut store, 0).expect(\"function should not trap\");\n\n        let trap = f.call(&mut store, 65536).expect_err(\"function should trap\");\n        assert!(trap.to_string().contains(\"out of bounds\"));\n\n        let trap = f.call(&mut store, 65537).expect_err(\"function should trap\");\n        assert!(trap.to_string().contains(\"out of bounds\"));\n\n        m.grow(&mut store, 1).expect(\"memory should grow\");\n        f.call(&mut store, 65536).expect(\"function should not trap\");\n\n        m.grow(&mut store, 1)\n            .expect_err(\"memory should be at the limit\");\n    }\n\n    Ok(())\n}\n\n#[test]\nfn memory_zeroed() -> Result<()> {\n    if skip_pooling_allocator_tests() {\n        return Ok(());\n    }\n\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling {\n        strategy: PoolingAllocationStrategy::NextAvailable,\n        module_limits: ModuleLimits {\n            memory_pages: 1,\n            table_elements: 0,\n            ..Default::default()\n        },\n        instance_limits: InstanceLimits { count: 1 },\n    });\n    config.dynamic_memory_guard_size(0);\n    config.static_memory_guard_size(0);\n    config.static_memory_maximum_size(65536);\n\n    let engine = Engine::new(&config)?;\n\n    let module = Module::new(&engine, r#\"(module (memory (export \"m\") 1))\"#)?;\n\n    // Instantiate the module repeatedly after writing data to the entire memory\n    for _ in 0..10 {\n        let mut store = Store::new(&engine, ());\n        let instance = Instance::new(&mut store, &module, &[])?;\n        let memory = instance.get_memory(&mut store, \"m\").unwrap();\n\n        assert_eq!(memory.size(&store,), 1);\n        assert_eq!(memory.data_size(&store), 65536);\n\n        let ptr = memory.data_mut(&mut store).as_mut_ptr();\n\n        unsafe {\n            for i in 0..8192 {\n                assert_eq!(*ptr.cast::<u64>().offset(i), 0);\n            }\n            std::ptr::write_bytes(ptr, 0xFE, memory.data_size(&store));\n        }\n    }\n\n    Ok(())\n}\n\n#[test]\nfn table_limit() -> Result<()> {\n    const TABLE_ELEMENTS: u32 = 10;\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling {\n        strategy: PoolingAllocationStrategy::NextAvailable,\n        module_limits: ModuleLimits {\n            memory_pages: 1,\n            table_elements: TABLE_ELEMENTS,\n            ..Default::default()\n        },\n        instance_limits: InstanceLimits { count: 1 },\n    });\n    config.dynamic_memory_guard_size(0);\n    config.static_memory_guard_size(0);\n    config.static_memory_maximum_size(65536);\n\n    let engine = Engine::new(&config)?;\n\n    // Module should fail to validate because the minimum is greater than the configured limit\n    match Module::new(&engine, r#\"(module (table 31 funcref))\"#) {\n        Ok(_) => panic!(\"module compilation should fail\"),\n        Err(e) => assert_eq!(\n            e.to_string(),\n            \"table index 0 has a minimum element size of 31 which exceeds the limit of 10\"\n        ),\n    }\n\n    let module = Module::new(\n        &engine,\n        r#\"(module (table (export \"t\") 0 funcref) (func (export \"f\") (result i32) (table.grow (ref.null func) (i32.const 1))))\"#,\n    )?;\n\n    // Instantiate the module and grow the table via the `f` function\n    {\n        let mut store = Store::new(&engine, ());\n        let instance = Instance::new(&mut store, &module, &[])?;\n        let f = instance.get_typed_func::<(), i32, _>(&mut store, \"f\")?;\n\n        for i in 0..TABLE_ELEMENTS {\n            assert_eq!(\n                f.call(&mut store, ()).expect(\"function should not trap\"),\n                i as i32\n            );\n        }\n\n        assert_eq!(\n            f.call(&mut store, ()).expect(\"function should not trap\"),\n            -1\n        );\n        assert_eq!(\n            f.call(&mut store, ()).expect(\"function should not trap\"),\n            -1\n        );\n    }\n\n    // Instantiate the module and grow the table via the Wasmtime API\n    let mut store = Store::new(&engine, ());\n    let instance = Instance::new(&mut store, &module, &[])?;\n\n    let table = instance.get_table(&mut store, \"t\").unwrap();\n\n    for i in 0..TABLE_ELEMENTS {\n        assert_eq!(table.size(&store), i);\n        assert_eq!(\n            table\n                .grow(&mut store, 1, Val::FuncRef(None))\n                .expect(\"table should grow\"),\n            i\n        );\n    }\n\n    assert_eq!(table.size(&store), TABLE_ELEMENTS);\n    assert!(table.grow(&mut store, 1, Val::FuncRef(None)).is_err());\n\n    Ok(())\n}\n\n#[test]\nfn table_init() -> Result<()> {\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling {\n        strategy: PoolingAllocationStrategy::NextAvailable,\n        module_limits: ModuleLimits {\n            memory_pages: 0,\n            table_elements: 6,\n            ..Default::default()\n        },\n        instance_limits: InstanceLimits {\n            count: 1,\n            ..Default::default()\n        },\n    });\n\n    let engine = Engine::new(&config)?;\n\n    let module = Module::new(\n        &engine,\n        r#\"(module (table (export \"t\") 6 funcref) (elem (i32.const 1) 1 2 3 4) (elem (i32.const 0) 0) (func) (func (param i32)) (func (param i32 i32)) (func (param i32 i32 i32)) (func (param i32 i32 i32 i32)))\"#,\n    )?;\n\n    let mut store = Store::new(&engine, ());\n    let instance = Instance::new(&mut store, &module, &[])?;\n    let table = instance.get_table(&mut store, \"t\").unwrap();\n\n    for i in 0..5 {\n        let v = table.get(&mut store, i).expect(\"table should have entry\");\n        let f = v\n            .funcref()\n            .expect(\"expected funcref\")\n            .expect(\"expected non-null value\");\n        assert_eq!(f.ty(&store).params().len(), i as usize);\n    }\n\n    assert!(\n        table\n            .get(&mut store, 5)\n            .expect(\"table should have entry\")\n            .funcref()\n            .expect(\"expected funcref\")\n            .is_none(),\n        \"funcref should be null\"\n    );\n\n    Ok(())\n}\n\n#[test]\nfn table_zeroed() -> Result<()> {\n    if skip_pooling_allocator_tests() {\n        return Ok(());\n    }\n\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling {\n        strategy: PoolingAllocationStrategy::NextAvailable,\n        module_limits: ModuleLimits {\n            memory_pages: 1,\n            table_elements: 10,\n            ..Default::default()\n        },\n        instance_limits: InstanceLimits { count: 1 },\n    });\n    config.dynamic_memory_guard_size(0);\n    config.static_memory_guard_size(0);\n    config.static_memory_maximum_size(65536);\n\n    let engine = Engine::new(&config)?;\n\n    let module = Module::new(&engine, r#\"(module (table (export \"t\") 10 funcref))\"#)?;\n\n    // Instantiate the module repeatedly after filling table elements\n    for _ in 0..10 {\n        let mut store = Store::new(&engine, ());\n        let instance = Instance::new(&mut store, &module, &[])?;\n        let table = instance.get_table(&mut store, \"t\").unwrap();\n        let f = Func::wrap(&mut store, || {});\n\n        assert_eq!(table.size(&store), 10);\n\n        for i in 0..10 {\n            match table.get(&mut store, i).unwrap() {\n                Val::FuncRef(r) => assert!(r.is_none()),\n                _ => panic!(\"expected a funcref\"),\n            }\n            table\n                .set(&mut store, i, Val::FuncRef(Some(f.clone())))\n                .unwrap();\n        }\n    }\n\n    Ok(())\n}\n\n#[test]\nfn instantiation_limit() -> Result<()> {\n    const INSTANCE_LIMIT: u32 = 10;\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling {\n        strategy: PoolingAllocationStrategy::NextAvailable,\n        module_limits: ModuleLimits {\n            memory_pages: 1,\n            table_elements: 10,\n            ..Default::default()\n        },\n        instance_limits: InstanceLimits {\n            count: INSTANCE_LIMIT,\n        },\n    });\n    config.dynamic_memory_guard_size(0);\n    config.static_memory_guard_size(0);\n    config.static_memory_maximum_size(65536);\n\n    let engine = Engine::new(&config)?;\n    let module = Module::new(&engine, r#\"(module)\"#)?;\n\n    // Instantiate to the limit\n    {\n        let mut store = Store::new(&engine, ());\n\n        for _ in 0..INSTANCE_LIMIT {\n            Instance::new(&mut store, &module, &[])?;\n        }\n\n        match Instance::new(&mut store, &module, &[]) {\n            Ok(_) => panic!(\"instantiation should fail\"),\n            Err(e) => assert_eq!(\n                e.to_string(),\n                format!(\n                    \"Limit of {} concurrent instances has been reached\",\n                    INSTANCE_LIMIT\n                )\n            ),\n        }\n    }\n\n    // With the above store dropped, ensure instantiations can be made\n\n    let mut store = Store::new(&engine, ());\n\n    for _ in 0..INSTANCE_LIMIT {\n        Instance::new(&mut store, &module, &[])?;\n    }\n\n    Ok(())\n}\n\n#[test]\nfn preserve_data_segments() -> Result<()> {\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling {\n        strategy: PoolingAllocationStrategy::NextAvailable,\n        module_limits: ModuleLimits {\n            memory_pages: 1,\n            table_elements: 10,\n            ..Default::default()\n        },\n        instance_limits: InstanceLimits { count: 2 },\n    });\n    let engine = Engine::new(&config)?;\n    let m = Module::new(\n        &engine,\n        r#\"\n            (module\n                (memory (export \"mem\") 1 1)\n                (data (i32.const 0) \"foo\"))\n        \"#,\n    )?;\n    let mut store = Store::new(&engine, ());\n    let i = Instance::new(&mut store, &m, &[])?;\n\n    // Drop the module. This should *not* drop the actual data referenced by the\n    // module, especially when uffd is enabled. If uffd is enabled we'll lazily\n    // fault in the memory of the module, which means it better still be alive\n    // after we drop this.\n    drop(m);\n\n    // Spray some stuff on the heap. If wasm data lived on the heap this should\n    // paper over things and help us catch use-after-free here if it would\n    // otherwise happen.\n    let mut strings = Vec::new();\n    for _ in 0..1000 {\n        let mut string = String::new();\n        for _ in 0..1000 {\n            string.push('g');\n        }\n        strings.push(string);\n    }\n    drop(strings);\n\n    let mem = i.get_memory(&mut store, \"mem\").unwrap();\n\n    // This will segfault with uffd enabled, and then the uffd will lazily\n    // initialize the memory. Hopefully it's still `foo`!\n    assert!(mem.data(&store).starts_with(b\"foo\"));\n\n    Ok(())\n}\n"], "fixing_code": ["//! An `Instance` contains all the runtime state used by execution of a\n//! wasm module (except its callstack and register state). An\n//! `InstanceHandle` is a reference-counting handle for an `Instance`.\n\nuse crate::export::Export;\nuse crate::externref::VMExternRefActivationsTable;\nuse crate::memory::{Memory, RuntimeMemoryCreator};\nuse crate::table::{Table, TableElement, TableElementType};\nuse crate::traphandlers::Trap;\nuse crate::vmcontext::{\n    VMCallerCheckedAnyfunc, VMContext, VMFunctionImport, VMGlobalDefinition, VMGlobalImport,\n    VMInterrupts, VMMemoryDefinition, VMMemoryImport, VMTableDefinition, VMTableImport,\n};\nuse crate::{CompiledModuleId, ExportFunction, ExportGlobal, ExportMemory, ExportTable, Store};\nuse anyhow::Error;\nuse memoffset::offset_of;\nuse more_asserts::assert_lt;\nuse std::alloc::Layout;\nuse std::any::Any;\nuse std::convert::TryFrom;\nuse std::hash::Hash;\nuse std::ops::Range;\nuse std::ptr::NonNull;\nuse std::sync::atomic::AtomicU64;\nuse std::sync::Arc;\nuse std::{mem, ptr, slice};\nuse wasmtime_environ::{\n    packed_option::ReservedValue, DataIndex, DefinedGlobalIndex, DefinedMemoryIndex,\n    DefinedTableIndex, ElemIndex, EntityIndex, EntityRef, EntitySet, FuncIndex, GlobalIndex,\n    HostPtr, MemoryIndex, Module, PrimaryMap, TableIndex, TrapCode, VMOffsets, WasmType,\n};\n\nmod allocator;\n\npub use allocator::*;\n\n/// A type that roughly corresponds to a WebAssembly instance, but is also used\n/// for host-defined objects.\n///\n/// This structure is is never allocated directly but is instead managed through\n/// an `InstanceHandle`. This structure ends with a `VMContext` which has a\n/// dynamic size corresponding to the `module` configured within. Memory\n/// management of this structure is always externalized.\n///\n/// Instances here can correspond to actual instantiated modules, but it's also\n/// used ubiquitously for host-defined objects. For example creating a\n/// host-defined memory will have a `module` that looks like it exports a single\n/// memory (and similar for other constructs).\n///\n/// This `Instance` type is used as a ubiquitous representation for WebAssembly\n/// values, whether or not they were created on the host or through a module.\n#[repr(C)] // ensure that the vmctx field is last.\npub(crate) struct Instance {\n    /// The `Module` this `Instance` was instantiated from.\n    module: Arc<Module>,\n\n    /// The unique ID for the `Module` this `Instance` was instantiated from.\n    unique_id: Option<CompiledModuleId>,\n\n    /// Offsets in the `vmctx` region, precomputed from the `module` above.\n    offsets: VMOffsets<HostPtr>,\n\n    /// WebAssembly linear memory data.\n    ///\n    /// This is where all runtime information about defined linear memories in\n    /// this module lives.\n    memories: PrimaryMap<DefinedMemoryIndex, Memory>,\n\n    /// WebAssembly table data.\n    ///\n    /// Like memories, this is only for defined tables in the module and\n    /// contains all of their runtime state.\n    tables: PrimaryMap<DefinedTableIndex, Table>,\n\n    /// Stores the dropped passive element segments in this instantiation by index.\n    /// If the index is present in the set, the segment has been dropped.\n    dropped_elements: EntitySet<ElemIndex>,\n\n    /// Stores the dropped passive data segments in this instantiation by index.\n    /// If the index is present in the set, the segment has been dropped.\n    dropped_data: EntitySet<DataIndex>,\n\n    /// A slice pointing to all data that is referenced by this instance. This\n    /// data is managed externally so this is effectively an unsafe reference,\n    /// and this does not live for the `'static` lifetime so the API boundaries\n    /// here are careful to never hand out static references.\n    wasm_data: &'static [u8],\n\n    /// Hosts can store arbitrary per-instance information here.\n    ///\n    /// Most of the time from Wasmtime this is `Box::new(())`, a noop\n    /// allocation, but some host-defined objects will store their state here.\n    host_state: Box<dyn Any + Send + Sync>,\n\n    /// Flag to track when the vmctx has been initialized.\n    /// The pooling allocator may drop an instance before `vmctx` is initialized.\n    vmctx_initialized: bool,\n\n    /// Additional context used by compiled wasm code. This field is last, and\n    /// represents a dynamically-sized array that extends beyond the nominal\n    /// end of the struct (similar to a flexible array member).\n    vmctx: VMContext,\n}\n\n#[allow(clippy::cast_ptr_alignment)]\nimpl Instance {\n    /// Helper for allocators; not a public API.\n    pub(crate) fn create_raw(\n        module: &Arc<Module>,\n        unique_id: Option<CompiledModuleId>,\n        wasm_data: &'static [u8],\n        memories: PrimaryMap<DefinedMemoryIndex, Memory>,\n        tables: PrimaryMap<DefinedTableIndex, Table>,\n        host_state: Box<dyn Any + Send + Sync>,\n    ) -> Instance {\n        Instance {\n            module: module.clone(),\n            unique_id,\n            offsets: VMOffsets::new(HostPtr, &module),\n            memories,\n            tables,\n            dropped_elements: EntitySet::with_capacity(module.passive_elements.len()),\n            dropped_data: EntitySet::with_capacity(module.passive_data_map.len()),\n            host_state,\n            wasm_data,\n            vmctx_initialized: false,\n            vmctx: VMContext {\n                _marker: std::marker::PhantomPinned,\n            },\n        }\n    }\n\n    /// Helper function to access various locations offset from our `*mut\n    /// VMContext` object.\n    unsafe fn vmctx_plus_offset<T>(&self, offset: u32) -> *mut T {\n        (self.vmctx_ptr().cast::<u8>())\n            .add(usize::try_from(offset).unwrap())\n            .cast()\n    }\n\n    pub(crate) fn module(&self) -> &Arc<Module> {\n        &self.module\n    }\n\n    /// Return the indexed `VMFunctionImport`.\n    fn imported_function(&self, index: FuncIndex) -> &VMFunctionImport {\n        unsafe { &*self.vmctx_plus_offset(self.offsets.vmctx_vmfunction_import(index)) }\n    }\n\n    /// Return the index `VMTableImport`.\n    fn imported_table(&self, index: TableIndex) -> &VMTableImport {\n        unsafe { &*self.vmctx_plus_offset(self.offsets.vmctx_vmtable_import(index)) }\n    }\n\n    /// Return the indexed `VMMemoryImport`.\n    fn imported_memory(&self, index: MemoryIndex) -> &VMMemoryImport {\n        unsafe { &*self.vmctx_plus_offset(self.offsets.vmctx_vmmemory_import(index)) }\n    }\n\n    /// Return the indexed `VMGlobalImport`.\n    fn imported_global(&self, index: GlobalIndex) -> &VMGlobalImport {\n        unsafe { &*self.vmctx_plus_offset(self.offsets.vmctx_vmglobal_import(index)) }\n    }\n\n    /// Return the indexed `VMTableDefinition`.\n    #[allow(dead_code)]\n    fn table(&self, index: DefinedTableIndex) -> VMTableDefinition {\n        unsafe { *self.table_ptr(index) }\n    }\n\n    /// Updates the value for a defined table to `VMTableDefinition`.\n    fn set_table(&self, index: DefinedTableIndex, table: VMTableDefinition) {\n        unsafe {\n            *self.table_ptr(index) = table;\n        }\n    }\n\n    /// Return the indexed `VMTableDefinition`.\n    fn table_ptr(&self, index: DefinedTableIndex) -> *mut VMTableDefinition {\n        unsafe { self.vmctx_plus_offset(self.offsets.vmctx_vmtable_definition(index)) }\n    }\n\n    /// Get a locally defined or imported memory.\n    pub(crate) fn get_memory(&self, index: MemoryIndex) -> VMMemoryDefinition {\n        if let Some(defined_index) = self.module.defined_memory_index(index) {\n            self.memory(defined_index)\n        } else {\n            let import = self.imported_memory(index);\n            *unsafe { import.from.as_ref().unwrap() }\n        }\n    }\n\n    /// Return the indexed `VMMemoryDefinition`.\n    fn memory(&self, index: DefinedMemoryIndex) -> VMMemoryDefinition {\n        unsafe { *self.memory_ptr(index) }\n    }\n\n    /// Set the indexed memory to `VMMemoryDefinition`.\n    fn set_memory(&self, index: DefinedMemoryIndex, mem: VMMemoryDefinition) {\n        unsafe {\n            *self.memory_ptr(index) = mem;\n        }\n    }\n\n    /// Return the indexed `VMMemoryDefinition`.\n    fn memory_ptr(&self, index: DefinedMemoryIndex) -> *mut VMMemoryDefinition {\n        unsafe { self.vmctx_plus_offset(self.offsets.vmctx_vmmemory_definition(index)) }\n    }\n\n    /// Return the indexed `VMGlobalDefinition`.\n    fn global(&self, index: DefinedGlobalIndex) -> &VMGlobalDefinition {\n        unsafe { &*self.global_ptr(index) }\n    }\n\n    /// Return the indexed `VMGlobalDefinition`.\n    fn global_ptr(&self, index: DefinedGlobalIndex) -> *mut VMGlobalDefinition {\n        unsafe { self.vmctx_plus_offset(self.offsets.vmctx_vmglobal_definition(index)) }\n    }\n\n    /// Get a raw pointer to the global at the given index regardless whether it\n    /// is defined locally or imported from another module.\n    ///\n    /// Panics if the index is out of bound or is the reserved value.\n    pub(crate) fn defined_or_imported_global_ptr(\n        &self,\n        index: GlobalIndex,\n    ) -> *mut VMGlobalDefinition {\n        if let Some(index) = self.module.defined_global_index(index) {\n            self.global_ptr(index)\n        } else {\n            self.imported_global(index).from\n        }\n    }\n\n    /// Return a pointer to the interrupts structure\n    pub fn interrupts(&self) -> *mut *const VMInterrupts {\n        unsafe { self.vmctx_plus_offset(self.offsets.vmctx_interrupts()) }\n    }\n\n    /// Return a pointer to the global epoch counter used by this instance.\n    pub fn epoch_ptr(&self) -> *mut *const AtomicU64 {\n        unsafe { self.vmctx_plus_offset(self.offsets.vmctx_epoch_ptr()) }\n    }\n\n    /// Return a pointer to the `VMExternRefActivationsTable`.\n    pub fn externref_activations_table(&self) -> *mut *mut VMExternRefActivationsTable {\n        unsafe { self.vmctx_plus_offset(self.offsets.vmctx_externref_activations_table()) }\n    }\n\n    /// Gets a pointer to this instance's `Store` which was originally\n    /// configured on creation.\n    ///\n    /// # Panics\n    ///\n    /// This will panic if the originally configured store was `None`. That can\n    /// happen for host functions so host functions can't be queried what their\n    /// original `Store` was since it's just retained as null (since host\n    /// functions are shared amongst threads and don't all share the same\n    /// store).\n    #[inline]\n    pub fn store(&self) -> *mut dyn Store {\n        let ptr = unsafe { *self.vmctx_plus_offset::<*mut dyn Store>(self.offsets.vmctx_store()) };\n        assert!(!ptr.is_null());\n        ptr\n    }\n\n    pub unsafe fn set_store(&mut self, store: *mut dyn Store) {\n        *self.vmctx_plus_offset(self.offsets.vmctx_store()) = store;\n    }\n\n    /// Return a reference to the vmctx used by compiled wasm code.\n    #[inline]\n    pub fn vmctx(&self) -> &VMContext {\n        &self.vmctx\n    }\n\n    /// Return a raw pointer to the vmctx used by compiled wasm code.\n    #[inline]\n    pub fn vmctx_ptr(&self) -> *mut VMContext {\n        self.vmctx() as *const VMContext as *mut VMContext\n    }\n\n    /// Lookup an export with the given export declaration.\n    pub fn lookup_by_declaration(&self, export: &EntityIndex) -> Export {\n        match export {\n            EntityIndex::Function(index) => {\n                let anyfunc = self.get_caller_checked_anyfunc(*index).unwrap();\n                let anyfunc =\n                    NonNull::new(anyfunc as *const VMCallerCheckedAnyfunc as *mut _).unwrap();\n                ExportFunction { anyfunc }.into()\n            }\n            EntityIndex::Table(index) => {\n                let (definition, vmctx) =\n                    if let Some(def_index) = self.module.defined_table_index(*index) {\n                        (self.table_ptr(def_index), self.vmctx_ptr())\n                    } else {\n                        let import = self.imported_table(*index);\n                        (import.from, import.vmctx)\n                    };\n                ExportTable {\n                    definition,\n                    vmctx,\n                    table: self.module.table_plans[*index].clone(),\n                }\n                .into()\n            }\n            EntityIndex::Memory(index) => {\n                let (definition, vmctx) =\n                    if let Some(def_index) = self.module.defined_memory_index(*index) {\n                        (self.memory_ptr(def_index), self.vmctx_ptr())\n                    } else {\n                        let import = self.imported_memory(*index);\n                        (import.from, import.vmctx)\n                    };\n                ExportMemory {\n                    definition,\n                    vmctx,\n                    memory: self.module.memory_plans[*index].clone(),\n                }\n                .into()\n            }\n            EntityIndex::Global(index) => ExportGlobal {\n                definition: if let Some(def_index) = self.module.defined_global_index(*index) {\n                    self.global_ptr(def_index)\n                } else {\n                    self.imported_global(*index).from\n                },\n                vmctx: self.vmctx_ptr(),\n                global: self.module.globals[*index],\n            }\n            .into(),\n\n            EntityIndex::Instance(_) | EntityIndex::Module(_) => {\n                panic!(\"can't use this api for modules/instances\")\n            }\n        }\n    }\n\n    /// Return an iterator over the exports of this instance.\n    ///\n    /// Specifically, it provides access to the key-value pairs, where the keys\n    /// are export names, and the values are export declarations which can be\n    /// resolved `lookup_by_declaration`.\n    pub fn exports(&self) -> indexmap::map::Iter<String, EntityIndex> {\n        self.module.exports.iter()\n    }\n\n    /// Return a reference to the custom state attached to this instance.\n    #[inline]\n    pub fn host_state(&self) -> &dyn Any {\n        &*self.host_state\n    }\n\n    /// Return the offset from the vmctx pointer to its containing Instance.\n    #[inline]\n    pub(crate) fn vmctx_offset() -> isize {\n        offset_of!(Self, vmctx) as isize\n    }\n\n    /// Return the table index for the given `VMTableDefinition`.\n    unsafe fn table_index(&self, table: &VMTableDefinition) -> DefinedTableIndex {\n        let index = DefinedTableIndex::new(\n            usize::try_from(\n                (table as *const VMTableDefinition)\n                    .offset_from(self.table_ptr(DefinedTableIndex::new(0))),\n            )\n            .unwrap(),\n        );\n        assert_lt!(index.index(), self.tables.len());\n        index\n    }\n\n    /// Return the memory index for the given `VMMemoryDefinition`.\n    unsafe fn memory_index(&self, memory: &VMMemoryDefinition) -> DefinedMemoryIndex {\n        let index = DefinedMemoryIndex::new(\n            usize::try_from(\n                (memory as *const VMMemoryDefinition)\n                    .offset_from(self.memory_ptr(DefinedMemoryIndex::new(0))),\n            )\n            .unwrap(),\n        );\n        assert_lt!(index.index(), self.memories.len());\n        index\n    }\n\n    /// Grow memory by the specified amount of pages.\n    ///\n    /// Returns `None` if memory can't be grown by the specified amount\n    /// of pages. Returns `Some` with the old size in bytes if growth was\n    /// successful.\n    pub(crate) fn memory_grow(\n        &mut self,\n        index: MemoryIndex,\n        delta: u64,\n    ) -> Result<Option<usize>, Error> {\n        let (idx, instance) = if let Some(idx) = self.module.defined_memory_index(index) {\n            (idx, self)\n        } else {\n            let import = self.imported_memory(index);\n            unsafe {\n                let foreign_instance = (*import.vmctx).instance_mut();\n                let foreign_memory_def = &*import.from;\n                let foreign_memory_index = foreign_instance.memory_index(foreign_memory_def);\n                (foreign_memory_index, foreign_instance)\n            }\n        };\n        let store = unsafe { &mut *instance.store() };\n        let memory = &mut instance.memories[idx];\n\n        let result = unsafe { memory.grow(delta, store) };\n        let vmmemory = memory.vmmemory();\n\n        // Update the state used by wasm code in case the base pointer and/or\n        // the length changed.\n        instance.set_memory(idx, vmmemory);\n\n        result\n    }\n\n    pub(crate) fn table_element_type(&mut self, table_index: TableIndex) -> TableElementType {\n        unsafe { (*self.get_table(table_index)).element_type() }\n    }\n\n    /// Grow table by the specified amount of elements, filling them with\n    /// `init_value`.\n    ///\n    /// Returns `None` if table can't be grown by the specified amount of\n    /// elements, or if `init_value` is the wrong type of table element.\n    pub(crate) fn table_grow(\n        &mut self,\n        table_index: TableIndex,\n        delta: u32,\n        init_value: TableElement,\n    ) -> Result<Option<u32>, Error> {\n        let (defined_table_index, instance) =\n            self.get_defined_table_index_and_instance(table_index);\n        instance.defined_table_grow(defined_table_index, delta, init_value)\n    }\n\n    fn defined_table_grow(\n        &mut self,\n        table_index: DefinedTableIndex,\n        delta: u32,\n        init_value: TableElement,\n    ) -> Result<Option<u32>, Error> {\n        let store = unsafe { &mut *self.store() };\n        let table = self\n            .tables\n            .get_mut(table_index)\n            .unwrap_or_else(|| panic!(\"no table for index {}\", table_index.index()));\n\n        let result = unsafe { table.grow(delta, init_value, store) };\n\n        // Keep the `VMContext` pointers used by compiled Wasm code up to\n        // date.\n        let element = self.tables[table_index].vmtable();\n        self.set_table(table_index, element);\n\n        result\n    }\n\n    fn alloc_layout(&self) -> Layout {\n        let size = mem::size_of_val(self)\n            .checked_add(usize::try_from(self.offsets.size_of_vmctx()).unwrap())\n            .unwrap();\n        let align = mem::align_of_val(self);\n        Layout::from_size_align(size, align).unwrap()\n    }\n\n    /// Get a `&VMCallerCheckedAnyfunc` for the given `FuncIndex`.\n    ///\n    /// Returns `None` if the index is the reserved index value.\n    ///\n    /// The returned reference is a stable reference that won't be moved and can\n    /// be passed into JIT code.\n    pub(crate) fn get_caller_checked_anyfunc(\n        &self,\n        index: FuncIndex,\n    ) -> Option<&VMCallerCheckedAnyfunc> {\n        if index == FuncIndex::reserved_value() {\n            return None;\n        }\n\n        unsafe { Some(&*self.vmctx_plus_offset(self.offsets.vmctx_anyfunc(index))) }\n    }\n\n    unsafe fn anyfunc_base(&self) -> *mut VMCallerCheckedAnyfunc {\n        self.vmctx_plus_offset(self.offsets.vmctx_anyfuncs_begin())\n    }\n\n    /// The `table.init` operation: initializes a portion of a table with a\n    /// passive element.\n    ///\n    /// # Errors\n    ///\n    /// Returns a `Trap` error when the range within the table is out of bounds\n    /// or the range within the passive element is out of bounds.\n    pub(crate) fn table_init(\n        &mut self,\n        table_index: TableIndex,\n        elem_index: ElemIndex,\n        dst: u32,\n        src: u32,\n        len: u32,\n    ) -> Result<(), Trap> {\n        // TODO: this `clone()` shouldn't be necessary but is used for now to\n        // inform `rustc` that the lifetime of the elements here are\n        // disconnected from the lifetime of `self`.\n        let module = self.module.clone();\n\n        let elements = match module.passive_elements_map.get(&elem_index) {\n            Some(index) if !self.dropped_elements.contains(elem_index) => {\n                module.passive_elements[*index].as_ref()\n            }\n            _ => &[],\n        };\n        self.table_init_segment(table_index, elements, dst, src, len)\n    }\n\n    pub(crate) fn table_init_segment(\n        &mut self,\n        table_index: TableIndex,\n        elements: &[FuncIndex],\n        dst: u32,\n        src: u32,\n        len: u32,\n    ) -> Result<(), Trap> {\n        // https://webassembly.github.io/bulk-memory-operations/core/exec/instructions.html#exec-table-init\n\n        let table = unsafe { &mut *self.get_table(table_index) };\n\n        let elements = match elements\n            .get(usize::try_from(src).unwrap()..)\n            .and_then(|s| s.get(..usize::try_from(len).unwrap()))\n        {\n            Some(elements) => elements,\n            None => return Err(Trap::wasm(TrapCode::TableOutOfBounds)),\n        };\n\n        match table.element_type() {\n            TableElementType::Func => unsafe {\n                let base = self.anyfunc_base();\n                table.init_funcs(\n                    dst,\n                    elements.iter().map(|idx| {\n                        if *idx == FuncIndex::reserved_value() {\n                            ptr::null_mut()\n                        } else {\n                            debug_assert!(idx.as_u32() < self.offsets.num_defined_functions);\n                            base.add(usize::try_from(idx.as_u32()).unwrap())\n                        }\n                    }),\n                )?;\n            },\n\n            TableElementType::Extern => {\n                debug_assert!(elements.iter().all(|e| *e == FuncIndex::reserved_value()));\n                table.fill(dst, TableElement::ExternRef(None), len)?;\n            }\n        }\n        Ok(())\n    }\n\n    /// Drop an element.\n    pub(crate) fn elem_drop(&mut self, elem_index: ElemIndex) {\n        // https://webassembly.github.io/reference-types/core/exec/instructions.html#exec-elem-drop\n\n        self.dropped_elements.insert(elem_index);\n\n        // Note that we don't check that we actually removed a segment because\n        // dropping a non-passive segment is a no-op (not a trap).\n    }\n\n    /// Get a locally-defined memory.\n    pub(crate) fn get_defined_memory(&mut self, index: DefinedMemoryIndex) -> *mut Memory {\n        ptr::addr_of_mut!(self.memories[index])\n    }\n\n    /// Do a `memory.copy`\n    ///\n    /// # Errors\n    ///\n    /// Returns a `Trap` error when the source or destination ranges are out of\n    /// bounds.\n    pub(crate) fn memory_copy(\n        &mut self,\n        dst_index: MemoryIndex,\n        dst: u64,\n        src_index: MemoryIndex,\n        src: u64,\n        len: u64,\n    ) -> Result<(), Trap> {\n        // https://webassembly.github.io/reference-types/core/exec/instructions.html#exec-memory-copy\n\n        let src_mem = self.get_memory(src_index);\n        let dst_mem = self.get_memory(dst_index);\n\n        let src = self.validate_inbounds(src_mem.current_length, src, len)?;\n        let dst = self.validate_inbounds(dst_mem.current_length, dst, len)?;\n\n        // Bounds and casts are checked above, by this point we know that\n        // everything is safe.\n        unsafe {\n            let dst = dst_mem.base.add(dst);\n            let src = src_mem.base.add(src);\n            ptr::copy(src, dst, len as usize);\n        }\n\n        Ok(())\n    }\n\n    fn validate_inbounds(&self, max: usize, ptr: u64, len: u64) -> Result<usize, Trap> {\n        let oob = || Trap::wasm(TrapCode::HeapOutOfBounds);\n        let end = ptr\n            .checked_add(len)\n            .and_then(|i| usize::try_from(i).ok())\n            .ok_or_else(oob)?;\n        if end > max {\n            Err(oob())\n        } else {\n            Ok(ptr as usize)\n        }\n    }\n\n    /// Perform the `memory.fill` operation on a locally defined memory.\n    ///\n    /// # Errors\n    ///\n    /// Returns a `Trap` error if the memory range is out of bounds.\n    pub(crate) fn memory_fill(\n        &mut self,\n        memory_index: MemoryIndex,\n        dst: u64,\n        val: u8,\n        len: u64,\n    ) -> Result<(), Trap> {\n        let memory = self.get_memory(memory_index);\n        let dst = self.validate_inbounds(memory.current_length, dst, len)?;\n\n        // Bounds and casts are checked above, by this point we know that\n        // everything is safe.\n        unsafe {\n            let dst = memory.base.add(dst);\n            ptr::write_bytes(dst, val, len as usize);\n        }\n\n        Ok(())\n    }\n\n    /// Performs the `memory.init` operation.\n    ///\n    /// # Errors\n    ///\n    /// Returns a `Trap` error if the destination range is out of this module's\n    /// memory's bounds or if the source range is outside the data segment's\n    /// bounds.\n    pub(crate) fn memory_init(\n        &mut self,\n        memory_index: MemoryIndex,\n        data_index: DataIndex,\n        dst: u64,\n        src: u32,\n        len: u32,\n    ) -> Result<(), Trap> {\n        let range = match self.module.passive_data_map.get(&data_index).cloned() {\n            Some(range) if !self.dropped_data.contains(data_index) => range,\n            _ => 0..0,\n        };\n        self.memory_init_segment(memory_index, range, dst, src, len)\n    }\n\n    pub(crate) fn wasm_data(&self, range: Range<u32>) -> &[u8] {\n        &self.wasm_data[range.start as usize..range.end as usize]\n    }\n\n    pub(crate) fn memory_init_segment(\n        &mut self,\n        memory_index: MemoryIndex,\n        range: Range<u32>,\n        dst: u64,\n        src: u32,\n        len: u32,\n    ) -> Result<(), Trap> {\n        // https://webassembly.github.io/bulk-memory-operations/core/exec/instructions.html#exec-memory-init\n\n        let memory = self.get_memory(memory_index);\n        let data = self.wasm_data(range);\n        let dst = self.validate_inbounds(memory.current_length, dst, len.into())?;\n        let src = self.validate_inbounds(data.len(), src.into(), len.into())?;\n        let len = len as usize;\n\n        let src_slice = &data[src..(src + len)];\n\n        unsafe {\n            let dst_start = memory.base.add(dst);\n            let dst_slice = slice::from_raw_parts_mut(dst_start, len);\n            dst_slice.copy_from_slice(src_slice);\n        }\n\n        Ok(())\n    }\n\n    /// Drop the given data segment, truncating its length to zero.\n    pub(crate) fn data_drop(&mut self, data_index: DataIndex) {\n        self.dropped_data.insert(data_index);\n\n        // Note that we don't check that we actually removed a segment because\n        // dropping a non-passive segment is a no-op (not a trap).\n    }\n\n    /// Get a table by index regardless of whether it is locally-defined or an\n    /// imported, foreign table.\n    pub(crate) fn get_table(&mut self, table_index: TableIndex) -> *mut Table {\n        let (idx, instance) = self.get_defined_table_index_and_instance(table_index);\n        ptr::addr_of_mut!(instance.tables[idx])\n    }\n\n    /// Get a locally-defined table.\n    pub(crate) fn get_defined_table(&mut self, index: DefinedTableIndex) -> *mut Table {\n        ptr::addr_of_mut!(self.tables[index])\n    }\n\n    pub(crate) fn get_defined_table_index_and_instance(\n        &mut self,\n        index: TableIndex,\n    ) -> (DefinedTableIndex, &mut Instance) {\n        if let Some(defined_table_index) = self.module.defined_table_index(index) {\n            (defined_table_index, self)\n        } else {\n            let import = self.imported_table(index);\n            unsafe {\n                let foreign_instance = (*import.vmctx).instance_mut();\n                let foreign_table_def = &*import.from;\n                let foreign_table_index = foreign_instance.table_index(foreign_table_def);\n                (foreign_table_index, foreign_instance)\n            }\n        }\n    }\n\n    fn drop_globals(&mut self) {\n        // Dropping globals requires that the vmctx be fully initialized\n        if !self.vmctx_initialized {\n            return;\n        }\n\n        for (idx, global) in self.module.globals.iter() {\n            let idx = match self.module.defined_global_index(idx) {\n                Some(idx) => idx,\n                None => continue,\n            };\n            match global.wasm_ty {\n                // For now only externref globals need to get destroyed\n                WasmType::ExternRef => {}\n                _ => continue,\n            }\n            unsafe {\n                drop((*self.global_ptr(idx)).as_externref_mut().take());\n            }\n        }\n    }\n}\n\nimpl Drop for Instance {\n    fn drop(&mut self) {\n        self.drop_globals();\n    }\n}\n\n/// A handle holding an `Instance` of a WebAssembly module.\n#[derive(Hash, PartialEq, Eq)]\npub struct InstanceHandle {\n    instance: *mut Instance,\n}\n\n// These are only valid if the `Instance` type is send/sync, hence the\n// assertion below.\nunsafe impl Send for InstanceHandle {}\nunsafe impl Sync for InstanceHandle {}\n\nfn _assert_send_sync() {\n    fn _assert<T: Send + Sync>() {}\n    _assert::<Instance>();\n}\n\nimpl InstanceHandle {\n    /// Create a new `InstanceHandle` pointing at the instance\n    /// pointed to by the given `VMContext` pointer.\n    ///\n    /// # Safety\n    /// This is unsafe because it doesn't work on just any `VMContext`, it must\n    /// be a `VMContext` allocated as part of an `Instance`.\n    #[inline]\n    pub unsafe fn from_vmctx(vmctx: *mut VMContext) -> Self {\n        let instance = (&mut *vmctx).instance();\n        Self {\n            instance: instance as *const Instance as *mut Instance,\n        }\n    }\n\n    /// Return a reference to the vmctx used by compiled wasm code.\n    pub fn vmctx(&self) -> &VMContext {\n        self.instance().vmctx()\n    }\n\n    /// Return a raw pointer to the vmctx used by compiled wasm code.\n    #[inline]\n    pub fn vmctx_ptr(&self) -> *mut VMContext {\n        self.instance().vmctx_ptr()\n    }\n\n    /// Return a reference to a module.\n    pub fn module(&self) -> &Arc<Module> {\n        self.instance().module()\n    }\n\n    /// Lookup an export with the given export declaration.\n    pub fn lookup_by_declaration(&self, export: &EntityIndex) -> Export {\n        self.instance().lookup_by_declaration(export)\n    }\n\n    /// Return an iterator over the exports of this instance.\n    ///\n    /// Specifically, it provides access to the key-value pairs, where the keys\n    /// are export names, and the values are export declarations which can be\n    /// resolved `lookup_by_declaration`.\n    pub fn exports(&self) -> indexmap::map::Iter<String, EntityIndex> {\n        self.instance().exports()\n    }\n\n    /// Return a reference to the custom state attached to this instance.\n    pub fn host_state(&self) -> &dyn Any {\n        self.instance().host_state()\n    }\n\n    /// Return the memory index for the given `VMMemoryDefinition` in this instance.\n    pub unsafe fn memory_index(&self, memory: &VMMemoryDefinition) -> DefinedMemoryIndex {\n        self.instance().memory_index(memory)\n    }\n\n    /// Get a memory defined locally within this module.\n    pub fn get_defined_memory(&mut self, index: DefinedMemoryIndex) -> *mut Memory {\n        self.instance_mut().get_defined_memory(index)\n    }\n\n    /// Return the table index for the given `VMTableDefinition` in this instance.\n    pub unsafe fn table_index(&self, table: &VMTableDefinition) -> DefinedTableIndex {\n        self.instance().table_index(table)\n    }\n\n    /// Get a table defined locally within this module.\n    pub fn get_defined_table(&mut self, index: DefinedTableIndex) -> *mut Table {\n        self.instance_mut().get_defined_table(index)\n    }\n\n    /// Return a reference to the contained `Instance`.\n    #[inline]\n    pub(crate) fn instance(&self) -> &Instance {\n        unsafe { &*(self.instance as *const Instance) }\n    }\n\n    pub(crate) fn instance_mut(&mut self) -> &mut Instance {\n        unsafe { &mut *self.instance }\n    }\n\n    /// Returns the `Store` pointer that was stored on creation\n    #[inline]\n    pub fn store(&self) -> *mut dyn Store {\n        self.instance().store()\n    }\n\n    /// Configure the `*mut dyn Store` internal pointer after-the-fact.\n    ///\n    /// This is provided for the original `Store` itself to configure the first\n    /// self-pointer after the original `Box` has been initialized.\n    pub unsafe fn set_store(&mut self, store: *mut dyn Store) {\n        self.instance_mut().set_store(store);\n    }\n\n    /// Returns a clone of this instance.\n    ///\n    /// This is unsafe because the returned handle here is just a cheap clone\n    /// of the internals, there's no lifetime tracking around its validity.\n    /// You'll need to ensure that the returned handles all go out of scope at\n    /// the same time.\n    #[inline]\n    pub unsafe fn clone(&self) -> InstanceHandle {\n        InstanceHandle {\n            instance: self.instance,\n        }\n    }\n}\n", "use crate::imports::Imports;\nuse crate::instance::{Instance, InstanceHandle, RuntimeMemoryCreator};\nuse crate::memory::{DefaultMemoryCreator, Memory};\nuse crate::table::Table;\nuse crate::traphandlers::Trap;\nuse crate::vmcontext::{\n    VMBuiltinFunctionsArray, VMCallerCheckedAnyfunc, VMGlobalDefinition, VMSharedSignatureIndex,\n};\nuse crate::ModuleMemFds;\nuse crate::{CompiledModuleId, Store};\nuse anyhow::Result;\nuse std::alloc;\nuse std::any::Any;\nuse std::convert::TryFrom;\nuse std::ptr::{self, NonNull};\nuse std::slice;\nuse std::sync::Arc;\nuse thiserror::Error;\nuse wasmtime_environ::{\n    DefinedFuncIndex, DefinedMemoryIndex, DefinedTableIndex, EntityRef, FunctionInfo, GlobalInit,\n    InitMemory, MemoryInitialization, MemoryInitializer, Module, ModuleType, PrimaryMap,\n    SignatureIndex, TableInitializer, TrapCode, WasmType, WASM_PAGE_SIZE,\n};\n\n#[cfg(feature = \"pooling-allocator\")]\nmod pooling;\n\n#[cfg(feature = \"pooling-allocator\")]\npub use self::pooling::{\n    InstanceLimits, ModuleLimits, PoolingAllocationStrategy, PoolingInstanceAllocator,\n};\n\n/// Represents a request for a new runtime instance.\npub struct InstanceAllocationRequest<'a> {\n    /// The module being instantiated.\n    pub module: &'a Arc<Module>,\n\n    /// The unique ID of the module being allocated within this engine.\n    pub unique_id: Option<CompiledModuleId>,\n\n    /// The base address of where JIT functions are located.\n    pub image_base: usize,\n\n    /// If using MemFD-based memories, the backing MemFDs.\n    pub memfds: Option<&'a Arc<ModuleMemFds>>,\n\n    /// Descriptors about each compiled function, such as the offset from\n    /// `image_base`.\n    pub functions: &'a PrimaryMap<DefinedFuncIndex, FunctionInfo>,\n\n    /// The imports to use for the instantiation.\n    pub imports: Imports<'a>,\n\n    /// Translation from `SignatureIndex` to `VMSharedSignatureIndex`\n    pub shared_signatures: SharedSignatures<'a>,\n\n    /// The host state to associate with the instance.\n    pub host_state: Box<dyn Any + Send + Sync>,\n\n    /// A pointer to the \"store\" for this instance to be allocated. The store\n    /// correlates with the `Store` in wasmtime itself, and lots of contextual\n    /// information about the execution of wasm can be learned through the store.\n    ///\n    /// Note that this is a raw pointer and has a static lifetime, both of which\n    /// are a bit of a lie. This is done purely so a store can learn about\n    /// itself when it gets called as a host function, and additionally so this\n    /// runtime can access internals as necessary (such as the\n    /// VMExternRefActivationsTable or the resource limiter methods).\n    ///\n    /// Note that this ends up being a self-pointer to the instance when stored.\n    /// The reason is that the instance itself is then stored within the store.\n    /// We use a number of `PhantomPinned` declarations to indicate this to the\n    /// compiler. More info on this in `wasmtime/src/store.rs`\n    pub store: StorePtr,\n\n    /// A list of all wasm data that can be referenced by the module that\n    /// will be allocated. The `Module` given here has active/passive data\n    /// segments that are specified as relative indices into this list of bytes.\n    ///\n    /// Note that this is an unsafe pointer. The pointer is expected to live for\n    /// the entire duration of the instance at this time. It's the\n    /// responsibility of the callee when allocating to ensure that this data\n    /// outlives the instance.\n    pub wasm_data: *const [u8],\n}\n\n/// A pointer to a Store. This Option<*mut dyn Store> is wrapped in a struct\n/// so that the function to create a &mut dyn Store is a method on a member of\n/// InstanceAllocationRequest, rather than on a &mut InstanceAllocationRequest\n/// itself, because several use-sites require a split mut borrow on the\n/// InstanceAllocationRequest.\npub struct StorePtr(Option<*mut dyn Store>);\nimpl StorePtr {\n    /// A pointer to no Store.\n    pub fn empty() -> Self {\n        Self(None)\n    }\n    /// A pointer to a Store.\n    pub fn new(ptr: *mut dyn Store) -> Self {\n        Self(Some(ptr))\n    }\n    /// The raw contents of this struct\n    pub fn as_raw(&self) -> Option<*mut dyn Store> {\n        self.0.clone()\n    }\n    /// Use the StorePtr as a mut ref to the Store.\n    /// Safety: must not be used outside the original lifetime of the borrow.\n    pub(crate) unsafe fn get(&mut self) -> Option<&mut dyn Store> {\n        match self.0 {\n            Some(ptr) => Some(&mut *ptr),\n            None => None,\n        }\n    }\n}\n\n/// An link error while instantiating a module.\n#[derive(Error, Debug)]\n#[error(\"Link error: {0}\")]\npub struct LinkError(pub String);\n\n/// An error while instantiating a module.\n#[derive(Error, Debug)]\npub enum InstantiationError {\n    /// Insufficient resources available for execution.\n    #[error(\"Insufficient resources: {0}\")]\n    Resource(anyhow::Error),\n\n    /// A wasm link error occured.\n    #[error(\"Failed to link module\")]\n    Link(#[from] LinkError),\n\n    /// A trap ocurred during instantiation, after linking.\n    #[error(\"Trap occurred during instantiation\")]\n    Trap(Trap),\n\n    /// A limit on how many instances are supported has been reached.\n    #[error(\"Limit of {0} concurrent instances has been reached\")]\n    Limit(u32),\n}\n\n/// An error while creating a fiber stack.\n#[cfg(feature = \"async\")]\n#[derive(Error, Debug)]\npub enum FiberStackError {\n    /// Insufficient resources available for the request.\n    #[error(\"Insufficient resources: {0}\")]\n    Resource(anyhow::Error),\n    /// An error for when the allocator doesn't support fiber stacks.\n    #[error(\"fiber stacks are not supported by the allocator\")]\n    NotSupported,\n    /// A limit on how many fibers are supported has been reached.\n    #[error(\"Limit of {0} concurrent fibers has been reached\")]\n    Limit(u32),\n}\n\n/// Represents a runtime instance allocator.\n///\n/// # Safety\n///\n/// This trait is unsafe as it requires knowledge of Wasmtime's runtime internals to implement correctly.\npub unsafe trait InstanceAllocator: Send + Sync {\n    /// Validates that a module is supported by the allocator.\n    fn validate(&self, module: &Module) -> Result<()> {\n        drop(module);\n        Ok(())\n    }\n\n    /// Adjusts the tunables prior to creation of any JIT compiler.\n    ///\n    /// This method allows the instance allocator control over tunables passed to a `wasmtime_jit::Compiler`.\n    fn adjust_tunables(&self, tunables: &mut wasmtime_environ::Tunables) {\n        drop(tunables);\n    }\n\n    /// Allocates an instance for the given allocation request.\n    ///\n    /// # Safety\n    ///\n    /// This method is not inherently unsafe, but care must be made to ensure\n    /// pointers passed in the allocation request outlive the returned instance.\n    unsafe fn allocate(\n        &self,\n        req: InstanceAllocationRequest,\n    ) -> Result<InstanceHandle, InstantiationError>;\n\n    /// Finishes the instantiation process started by an instance allocator.\n    ///\n    /// # Safety\n    ///\n    /// This method is only safe to call immediately after an instance has been allocated.\n    unsafe fn initialize(\n        &self,\n        handle: &mut InstanceHandle,\n        module: &Module,\n        is_bulk_memory: bool,\n    ) -> Result<(), InstantiationError>;\n\n    /// Deallocates a previously allocated instance.\n    ///\n    /// # Safety\n    ///\n    /// This function is unsafe because there are no guarantees that the given handle\n    /// is the only owner of the underlying instance to deallocate.\n    ///\n    /// Use extreme care when deallocating an instance so that there are no dangling instance pointers.\n    unsafe fn deallocate(&self, handle: &InstanceHandle);\n\n    /// Allocates a fiber stack for calling async functions on.\n    #[cfg(feature = \"async\")]\n    fn allocate_fiber_stack(&self) -> Result<wasmtime_fiber::FiberStack, FiberStackError>;\n\n    /// Deallocates a fiber stack that was previously allocated with `allocate_fiber_stack`.\n    ///\n    /// # Safety\n    ///\n    /// The provided stack is required to have been allocated with `allocate_fiber_stack`.\n    #[cfg(feature = \"async\")]\n    unsafe fn deallocate_fiber_stack(&self, stack: &wasmtime_fiber::FiberStack);\n}\n\npub enum SharedSignatures<'a> {\n    /// Used for instantiating user-defined modules\n    Table(&'a PrimaryMap<SignatureIndex, VMSharedSignatureIndex>),\n    /// Used for instance creation that has only a single function\n    Always(VMSharedSignatureIndex),\n    /// Used for instance creation that has no functions\n    None,\n}\n\nimpl SharedSignatures<'_> {\n    fn lookup(&self, index: SignatureIndex) -> VMSharedSignatureIndex {\n        match self {\n            SharedSignatures::Table(table) => table[index],\n            SharedSignatures::Always(index) => *index,\n            SharedSignatures::None => unreachable!(),\n        }\n    }\n}\n\nimpl<'a> From<VMSharedSignatureIndex> for SharedSignatures<'a> {\n    fn from(val: VMSharedSignatureIndex) -> SharedSignatures<'a> {\n        SharedSignatures::Always(val)\n    }\n}\n\nimpl<'a> From<Option<VMSharedSignatureIndex>> for SharedSignatures<'a> {\n    fn from(val: Option<VMSharedSignatureIndex>) -> SharedSignatures<'a> {\n        match val {\n            Some(idx) => SharedSignatures::Always(idx),\n            None => SharedSignatures::None,\n        }\n    }\n}\n\nimpl<'a> From<&'a PrimaryMap<SignatureIndex, VMSharedSignatureIndex>> for SharedSignatures<'a> {\n    fn from(val: &'a PrimaryMap<SignatureIndex, VMSharedSignatureIndex>) -> SharedSignatures<'a> {\n        SharedSignatures::Table(val)\n    }\n}\n\nfn get_table_init_start(\n    init: &TableInitializer,\n    instance: &Instance,\n) -> Result<u32, InstantiationError> {\n    match init.base {\n        Some(base) => {\n            let val = unsafe {\n                if let Some(def_index) = instance.module.defined_global_index(base) {\n                    *instance.global(def_index).as_u32()\n                } else {\n                    *(*instance.imported_global(base).from).as_u32()\n                }\n            };\n\n            init.offset.checked_add(val).ok_or_else(|| {\n                InstantiationError::Link(LinkError(\n                    \"element segment global base overflows\".to_owned(),\n                ))\n            })\n        }\n        None => Ok(init.offset),\n    }\n}\n\nfn check_table_init_bounds(\n    instance: &mut Instance,\n    module: &Module,\n) -> Result<(), InstantiationError> {\n    for init in &module.table_initializers {\n        let table = unsafe { &*instance.get_table(init.table_index) };\n        let start = get_table_init_start(init, instance)?;\n        let start = usize::try_from(start).unwrap();\n        let end = start.checked_add(init.elements.len());\n\n        match end {\n            Some(end) if end <= table.size() as usize => {\n                // Initializer is in bounds\n            }\n            _ => {\n                return Err(InstantiationError::Link(LinkError(\n                    \"table out of bounds: elements segment does not fit\".to_owned(),\n                )))\n            }\n        }\n    }\n\n    Ok(())\n}\n\nfn initialize_tables(instance: &mut Instance, module: &Module) -> Result<(), InstantiationError> {\n    for init in &module.table_initializers {\n        instance\n            .table_init_segment(\n                init.table_index,\n                &init.elements,\n                get_table_init_start(init, instance)?,\n                0,\n                init.elements.len() as u32,\n            )\n            .map_err(InstantiationError::Trap)?;\n    }\n\n    Ok(())\n}\n\nfn get_memory_init_start(\n    init: &MemoryInitializer,\n    instance: &Instance,\n) -> Result<u64, InstantiationError> {\n    match init.base {\n        Some(base) => {\n            let mem64 = instance.module.memory_plans[init.memory_index]\n                .memory\n                .memory64;\n            let val = unsafe {\n                let global = if let Some(def_index) = instance.module.defined_global_index(base) {\n                    instance.global(def_index)\n                } else {\n                    &*instance.imported_global(base).from\n                };\n                if mem64 {\n                    *global.as_u64()\n                } else {\n                    u64::from(*global.as_u32())\n                }\n            };\n\n            init.offset.checked_add(val).ok_or_else(|| {\n                InstantiationError::Link(LinkError(\"data segment global base overflows\".to_owned()))\n            })\n        }\n        None => Ok(init.offset),\n    }\n}\n\nfn check_memory_init_bounds(\n    instance: &Instance,\n    initializers: &[MemoryInitializer],\n) -> Result<(), InstantiationError> {\n    for init in initializers {\n        let memory = instance.get_memory(init.memory_index);\n        let start = get_memory_init_start(init, instance)?;\n        let end = usize::try_from(start)\n            .ok()\n            .and_then(|start| start.checked_add(init.data.len()));\n\n        match end {\n            Some(end) if end <= memory.current_length => {\n                // Initializer is in bounds\n            }\n            _ => {\n                return Err(InstantiationError::Link(LinkError(\n                    \"memory out of bounds: data segment does not fit\".into(),\n                )))\n            }\n        }\n    }\n\n    Ok(())\n}\n\nfn initialize_memories(instance: &mut Instance, module: &Module) -> Result<(), InstantiationError> {\n    let memory_size_in_pages =\n        &|memory| (instance.get_memory(memory).current_length as u64) / u64::from(WASM_PAGE_SIZE);\n\n    // Loads the `global` value and returns it as a `u64`, but sign-extends\n    // 32-bit globals which can be used as the base for 32-bit memories.\n    let get_global_as_u64 = &|global| unsafe {\n        let def = if let Some(def_index) = instance.module.defined_global_index(global) {\n            instance.global(def_index)\n        } else {\n            &*instance.imported_global(global).from\n        };\n        if module.globals[global].wasm_ty == WasmType::I64 {\n            *def.as_u64()\n        } else {\n            u64::from(*def.as_u32())\n        }\n    };\n\n    // Delegates to the `init_memory` method which is sort of a duplicate of\n    // `instance.memory_init_segment` but is used at compile-time in other\n    // contexts so is shared here to have only one method of memory\n    // initialization.\n    //\n    // This call to `init_memory` notably implements all the bells and whistles\n    // so errors only happen if an out-of-bounds segment is found, in which case\n    // a trap is returned.\n    let ok = module.memory_initialization.init_memory(\n        InitMemory::Runtime {\n            memory_size_in_pages,\n            get_global_as_u64,\n        },\n        &mut |memory_index, offset, data| {\n            // If this initializer applies to a defined memory but that memory\n            // doesn't need initialization, due to something like uffd or memfd\n            // pre-initializing it via mmap magic, then this initializer can be\n            // skipped entirely.\n            if let Some(memory_index) = module.defined_memory_index(memory_index) {\n                if !instance.memories[memory_index].needs_init() {\n                    return true;\n                }\n            }\n            let memory = instance.get_memory(memory_index);\n            let dst_slice =\n                unsafe { slice::from_raw_parts_mut(memory.base, memory.current_length) };\n            let dst = &mut dst_slice[usize::try_from(offset).unwrap()..][..data.len()];\n            dst.copy_from_slice(instance.wasm_data(data.clone()));\n            true\n        },\n    );\n    if !ok {\n        return Err(InstantiationError::Trap(Trap::wasm(\n            TrapCode::HeapOutOfBounds,\n        )));\n    }\n\n    Ok(())\n}\n\nfn check_init_bounds(instance: &mut Instance, module: &Module) -> Result<(), InstantiationError> {\n    check_table_init_bounds(instance, module)?;\n\n    match &instance.module.memory_initialization {\n        MemoryInitialization::Segmented(initializers) => {\n            check_memory_init_bounds(instance, initializers)?;\n        }\n        // Statically validated already to have everything in-bounds.\n        MemoryInitialization::Paged { .. } => {}\n    }\n\n    Ok(())\n}\n\nfn initialize_instance(\n    instance: &mut Instance,\n    module: &Module,\n    is_bulk_memory: bool,\n) -> Result<(), InstantiationError> {\n    // If bulk memory is not enabled, bounds check the data and element segments before\n    // making any changes. With bulk memory enabled, initializers are processed\n    // in-order and side effects are observed up to the point of an out-of-bounds\n    // initializer, so the early checking is not desired.\n    if !is_bulk_memory {\n        check_init_bounds(instance, module)?;\n    }\n\n    // Initialize the tables\n    initialize_tables(instance, module)?;\n\n    // Initialize the memories\n    initialize_memories(instance, &module)?;\n\n    Ok(())\n}\n\nunsafe fn initialize_vmcontext(instance: &mut Instance, req: InstanceAllocationRequest) {\n    assert!(!instance.vmctx_initialized);\n\n    if let Some(store) = req.store.as_raw() {\n        *instance.interrupts() = (*store).vminterrupts();\n        *instance.epoch_ptr() = (*store).epoch_ptr();\n        *instance.externref_activations_table() = (*store).externref_activations_table().0;\n        instance.set_store(store);\n    }\n\n    let module = &instance.module;\n\n    // Initialize shared signatures\n    let mut ptr = instance.vmctx_plus_offset(instance.offsets.vmctx_signature_ids_begin());\n    for sig in module.types.values() {\n        *ptr = match sig {\n            ModuleType::Function(sig) => req.shared_signatures.lookup(*sig),\n            _ => VMSharedSignatureIndex::new(u32::max_value()),\n        };\n        ptr = ptr.add(1);\n    }\n\n    // Initialize the built-in functions\n    *instance.vmctx_plus_offset(instance.offsets.vmctx_builtin_functions()) =\n        &VMBuiltinFunctionsArray::INIT;\n\n    // Initialize the imports\n    debug_assert_eq!(req.imports.functions.len(), module.num_imported_funcs);\n    ptr::copy(\n        req.imports.functions.as_ptr(),\n        instance.vmctx_plus_offset(instance.offsets.vmctx_imported_functions_begin()),\n        req.imports.functions.len(),\n    );\n    debug_assert_eq!(req.imports.tables.len(), module.num_imported_tables);\n    ptr::copy(\n        req.imports.tables.as_ptr(),\n        instance.vmctx_plus_offset(instance.offsets.vmctx_imported_tables_begin()),\n        req.imports.tables.len(),\n    );\n    debug_assert_eq!(req.imports.memories.len(), module.num_imported_memories);\n    ptr::copy(\n        req.imports.memories.as_ptr(),\n        instance.vmctx_plus_offset(instance.offsets.vmctx_imported_memories_begin()),\n        req.imports.memories.len(),\n    );\n    debug_assert_eq!(req.imports.globals.len(), module.num_imported_globals);\n    ptr::copy(\n        req.imports.globals.as_ptr(),\n        instance.vmctx_plus_offset(instance.offsets.vmctx_imported_globals_begin()),\n        req.imports.globals.len(),\n    );\n\n    // Initialize the functions\n    let mut base = instance.anyfunc_base();\n    for (index, sig) in instance.module.functions.iter() {\n        let type_index = req.shared_signatures.lookup(*sig);\n\n        let (func_ptr, vmctx) = if let Some(def_index) = instance.module.defined_func_index(index) {\n            (\n                NonNull::new((req.image_base + req.functions[def_index].start as usize) as *mut _)\n                    .unwrap(),\n                instance.vmctx_ptr(),\n            )\n        } else {\n            let import = instance.imported_function(index);\n            (import.body, import.vmctx)\n        };\n\n        ptr::write(\n            base,\n            VMCallerCheckedAnyfunc {\n                func_ptr,\n                type_index,\n                vmctx,\n            },\n        );\n        base = base.add(1);\n    }\n\n    // Initialize the defined tables\n    let mut ptr = instance.vmctx_plus_offset(instance.offsets.vmctx_tables_begin());\n    for i in 0..module.table_plans.len() - module.num_imported_tables {\n        ptr::write(ptr, instance.tables[DefinedTableIndex::new(i)].vmtable());\n        ptr = ptr.add(1);\n    }\n\n    // Initialize the defined memories\n    let mut ptr = instance.vmctx_plus_offset(instance.offsets.vmctx_memories_begin());\n    for i in 0..module.memory_plans.len() - module.num_imported_memories {\n        ptr::write(\n            ptr,\n            instance.memories[DefinedMemoryIndex::new(i)].vmmemory(),\n        );\n        ptr = ptr.add(1);\n    }\n\n    // Initialize the defined globals\n    initialize_vmcontext_globals(instance);\n\n    // Mark the vmctx as initialized\n    instance.vmctx_initialized = true;\n}\n\nunsafe fn initialize_vmcontext_globals(instance: &Instance) {\n    let module = &instance.module;\n    let num_imports = module.num_imported_globals;\n    for (index, global) in module.globals.iter().skip(num_imports) {\n        let def_index = module.defined_global_index(index).unwrap();\n        let to = instance.global_ptr(def_index);\n\n        // Initialize the global before writing to it\n        ptr::write(to, VMGlobalDefinition::new());\n\n        match global.initializer {\n            GlobalInit::I32Const(x) => *(*to).as_i32_mut() = x,\n            GlobalInit::I64Const(x) => *(*to).as_i64_mut() = x,\n            GlobalInit::F32Const(x) => *(*to).as_f32_bits_mut() = x,\n            GlobalInit::F64Const(x) => *(*to).as_f64_bits_mut() = x,\n            GlobalInit::V128Const(x) => *(*to).as_u128_mut() = x,\n            GlobalInit::GetGlobal(x) => {\n                let from = if let Some(def_x) = module.defined_global_index(x) {\n                    instance.global(def_x)\n                } else {\n                    &*instance.imported_global(x).from\n                };\n                // Globals of type `externref` need to manage the reference\n                // count as values move between globals, everything else is just\n                // copy-able bits.\n                match global.wasm_ty {\n                    WasmType::ExternRef => *(*to).as_externref_mut() = from.as_externref().clone(),\n                    _ => ptr::copy_nonoverlapping(from, to, 1),\n                }\n            }\n            GlobalInit::RefFunc(f) => {\n                *(*to).as_anyfunc_mut() = instance.get_caller_checked_anyfunc(f).unwrap()\n                    as *const VMCallerCheckedAnyfunc;\n            }\n            GlobalInit::RefNullConst => match global.wasm_ty {\n                // `VMGlobalDefinition::new()` already zeroed out the bits\n                WasmType::FuncRef => {}\n                WasmType::ExternRef => {}\n                ty => panic!(\"unsupported reference type for global: {:?}\", ty),\n            },\n            GlobalInit::Import => panic!(\"locally-defined global initialized as import\"),\n        }\n    }\n}\n\n/// Represents the on-demand instance allocator.\n#[derive(Clone)]\npub struct OnDemandInstanceAllocator {\n    mem_creator: Option<Arc<dyn RuntimeMemoryCreator>>,\n    #[cfg(feature = \"async\")]\n    stack_size: usize,\n}\n\nimpl OnDemandInstanceAllocator {\n    /// Creates a new on-demand instance allocator.\n    pub fn new(mem_creator: Option<Arc<dyn RuntimeMemoryCreator>>, stack_size: usize) -> Self {\n        drop(stack_size); // suppress unused warnings w/o async feature\n        Self {\n            mem_creator,\n            #[cfg(feature = \"async\")]\n            stack_size,\n        }\n    }\n\n    fn create_tables(\n        module: &Module,\n        store: &mut StorePtr,\n    ) -> Result<PrimaryMap<DefinedTableIndex, Table>, InstantiationError> {\n        let num_imports = module.num_imported_tables;\n        let mut tables: PrimaryMap<DefinedTableIndex, _> =\n            PrimaryMap::with_capacity(module.table_plans.len() - num_imports);\n        for table in &module.table_plans.values().as_slice()[num_imports..] {\n            tables.push(\n                Table::new_dynamic(table, unsafe {\n                    store\n                        .get()\n                        .expect(\"if module has table plans, store is not empty\")\n                })\n                .map_err(InstantiationError::Resource)?,\n            );\n        }\n        Ok(tables)\n    }\n\n    fn create_memories(\n        &self,\n        module: &Module,\n        store: &mut StorePtr,\n        memfds: Option<&Arc<ModuleMemFds>>,\n    ) -> Result<PrimaryMap<DefinedMemoryIndex, Memory>, InstantiationError> {\n        let creator = self\n            .mem_creator\n            .as_deref()\n            .unwrap_or_else(|| &DefaultMemoryCreator);\n        let num_imports = module.num_imported_memories;\n        let mut memories: PrimaryMap<DefinedMemoryIndex, _> =\n            PrimaryMap::with_capacity(module.memory_plans.len() - num_imports);\n        for (memory_idx, plan) in module.memory_plans.iter().skip(num_imports) {\n            // Create a MemFdSlot if there is an image for this memory.\n            let defined_memory_idx = module\n                .defined_memory_index(memory_idx)\n                .expect(\"Skipped imports, should never be None\");\n            let memfd_image = memfds.and_then(|memfds| memfds.get_memory_image(defined_memory_idx));\n\n            memories.push(\n                Memory::new_dynamic(\n                    plan,\n                    creator,\n                    unsafe {\n                        store\n                            .get()\n                            .expect(\"if module has memory plans, store is not empty\")\n                    },\n                    memfd_image,\n                )\n                .map_err(InstantiationError::Resource)?,\n            );\n        }\n        Ok(memories)\n    }\n}\n\nimpl Default for OnDemandInstanceAllocator {\n    fn default() -> Self {\n        Self {\n            mem_creator: None,\n            #[cfg(feature = \"async\")]\n            stack_size: 0,\n        }\n    }\n}\n\nunsafe impl InstanceAllocator for OnDemandInstanceAllocator {\n    unsafe fn allocate(\n        &self,\n        mut req: InstanceAllocationRequest,\n    ) -> Result<InstanceHandle, InstantiationError> {\n        let memories = self.create_memories(&req.module, &mut req.store, req.memfds)?;\n        let tables = Self::create_tables(&req.module, &mut req.store)?;\n\n        let host_state = std::mem::replace(&mut req.host_state, Box::new(()));\n\n        let mut handle = {\n            let instance = Instance::create_raw(\n                &req.module,\n                req.unique_id,\n                &*req.wasm_data,\n                memories,\n                tables,\n                host_state,\n            );\n            let layout = instance.alloc_layout();\n            let instance_ptr = alloc::alloc(layout) as *mut Instance;\n            if instance_ptr.is_null() {\n                alloc::handle_alloc_error(layout);\n            }\n            ptr::write(instance_ptr, instance);\n            InstanceHandle {\n                instance: instance_ptr,\n            }\n        };\n\n        initialize_vmcontext(handle.instance_mut(), req);\n\n        Ok(handle)\n    }\n\n    unsafe fn initialize(\n        &self,\n        handle: &mut InstanceHandle,\n        module: &Module,\n        is_bulk_memory: bool,\n    ) -> Result<(), InstantiationError> {\n        initialize_instance(handle.instance_mut(), module, is_bulk_memory)\n    }\n\n    unsafe fn deallocate(&self, handle: &InstanceHandle) {\n        let layout = handle.instance().alloc_layout();\n        ptr::drop_in_place(handle.instance);\n        alloc::dealloc(handle.instance.cast(), layout);\n    }\n\n    #[cfg(feature = \"async\")]\n    fn allocate_fiber_stack(&self) -> Result<wasmtime_fiber::FiberStack, FiberStackError> {\n        if self.stack_size == 0 {\n            return Err(FiberStackError::NotSupported);\n        }\n\n        wasmtime_fiber::FiberStack::new(self.stack_size)\n            .map_err(|e| FiberStackError::Resource(e.into()))\n    }\n\n    #[cfg(feature = \"async\")]\n    unsafe fn deallocate_fiber_stack(&self, _stack: &wasmtime_fiber::FiberStack) {\n        // The on-demand allocator has no further bookkeeping for fiber stacks\n    }\n}\n", "use super::skip_pooling_allocator_tests;\nuse anyhow::Result;\nuse wasmtime::*;\n\n#[test]\nfn successful_instantiation() -> Result<()> {\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling {\n        strategy: PoolingAllocationStrategy::NextAvailable,\n        module_limits: ModuleLimits {\n            memory_pages: 1,\n            table_elements: 10,\n            ..Default::default()\n        },\n        instance_limits: InstanceLimits { count: 1 },\n    });\n    config.dynamic_memory_guard_size(0);\n    config.static_memory_guard_size(0);\n    config.static_memory_maximum_size(65536);\n\n    let engine = Engine::new(&config)?;\n    let module = Module::new(&engine, r#\"(module (memory 1) (table 10 funcref))\"#)?;\n\n    // Module should instantiate\n    let mut store = Store::new(&engine, ());\n    Instance::new(&mut store, &module, &[])?;\n\n    Ok(())\n}\n\n#[test]\nfn memory_limit() -> Result<()> {\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling {\n        strategy: PoolingAllocationStrategy::NextAvailable,\n        module_limits: ModuleLimits {\n            memory_pages: 3,\n            table_elements: 10,\n            ..Default::default()\n        },\n        instance_limits: InstanceLimits { count: 1 },\n    });\n    config.dynamic_memory_guard_size(0);\n    config.static_memory_guard_size(65536);\n    config.static_memory_maximum_size(3 * 65536);\n\n    let engine = Engine::new(&config)?;\n\n    // Module should fail to validate because the minimum is greater than the configured limit\n    match Module::new(&engine, r#\"(module (memory 4))\"#) {\n        Ok(_) => panic!(\"module compilation should fail\"),\n        Err(e) => assert_eq!(\n            e.to_string(),\n            \"memory index 0 has a minimum page size of 4 which exceeds the limit of 3\"\n        ),\n    }\n\n    let module = Module::new(\n        &engine,\n        r#\"(module (memory (export \"m\") 0) (func (export \"f\") (result i32) (memory.grow (i32.const 1))))\"#,\n    )?;\n\n    // Instantiate the module and grow the memory via the `f` function\n    {\n        let mut store = Store::new(&engine, ());\n        let instance = Instance::new(&mut store, &module, &[])?;\n        let f = instance.get_typed_func::<(), i32, _>(&mut store, \"f\")?;\n\n        assert_eq!(f.call(&mut store, ()).expect(\"function should not trap\"), 0);\n        assert_eq!(f.call(&mut store, ()).expect(\"function should not trap\"), 1);\n        assert_eq!(f.call(&mut store, ()).expect(\"function should not trap\"), 2);\n        assert_eq!(\n            f.call(&mut store, ()).expect(\"function should not trap\"),\n            -1\n        );\n        assert_eq!(\n            f.call(&mut store, ()).expect(\"function should not trap\"),\n            -1\n        );\n    }\n\n    // Instantiate the module and grow the memory via the Wasmtime API\n    let mut store = Store::new(&engine, ());\n    let instance = Instance::new(&mut store, &module, &[])?;\n\n    let memory = instance.get_memory(&mut store, \"m\").unwrap();\n    assert_eq!(memory.size(&store), 0);\n    assert_eq!(memory.grow(&mut store, 1).expect(\"memory should grow\"), 0);\n    assert_eq!(memory.size(&store), 1);\n    assert_eq!(memory.grow(&mut store, 1).expect(\"memory should grow\"), 1);\n    assert_eq!(memory.size(&store), 2);\n    assert_eq!(memory.grow(&mut store, 1).expect(\"memory should grow\"), 2);\n    assert_eq!(memory.size(&store), 3);\n    assert!(memory.grow(&mut store, 1).is_err());\n\n    Ok(())\n}\n\n#[test]\nfn memory_init() -> Result<()> {\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling {\n        strategy: PoolingAllocationStrategy::NextAvailable,\n        module_limits: ModuleLimits {\n            memory_pages: 2,\n            table_elements: 0,\n            ..Default::default()\n        },\n        instance_limits: InstanceLimits {\n            count: 1,\n            ..Default::default()\n        },\n    });\n\n    let engine = Engine::new(&config)?;\n\n    let module = Module::new(\n        &engine,\n        r#\"(module (memory (export \"m\") 2) (data (i32.const 65530) \"this data spans multiple pages\") (data (i32.const 10) \"hello world\"))\"#,\n    )?;\n\n    let mut store = Store::new(&engine, ());\n    let instance = Instance::new(&mut store, &module, &[])?;\n    let memory = instance.get_memory(&mut store, \"m\").unwrap();\n\n    assert_eq!(\n        &memory.data(&store)[65530..65560],\n        b\"this data spans multiple pages\"\n    );\n    assert_eq!(&memory.data(&store)[10..21], b\"hello world\");\n\n    Ok(())\n}\n\n#[test]\nfn memory_guard_page_trap() -> Result<()> {\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling {\n        strategy: PoolingAllocationStrategy::NextAvailable,\n        module_limits: ModuleLimits {\n            memory_pages: 2,\n            table_elements: 0,\n            ..Default::default()\n        },\n        instance_limits: InstanceLimits {\n            count: 1,\n            ..Default::default()\n        },\n    });\n\n    let engine = Engine::new(&config)?;\n\n    let module = Module::new(\n        &engine,\n        r#\"(module (memory (export \"m\") 0) (func (export \"f\") (param i32) local.get 0 i32.load drop))\"#,\n    )?;\n\n    // Instantiate the module and check for out of bounds trap\n    for _ in 0..10 {\n        let mut store = Store::new(&engine, ());\n        let instance = Instance::new(&mut store, &module, &[])?;\n        let m = instance.get_memory(&mut store, \"m\").unwrap();\n        let f = instance.get_typed_func::<i32, (), _>(&mut store, \"f\")?;\n\n        let trap = f.call(&mut store, 0).expect_err(\"function should trap\");\n        assert!(trap.to_string().contains(\"out of bounds\"));\n\n        let trap = f.call(&mut store, 1).expect_err(\"function should trap\");\n        assert!(trap.to_string().contains(\"out of bounds\"));\n\n        m.grow(&mut store, 1).expect(\"memory should grow\");\n        f.call(&mut store, 0).expect(\"function should not trap\");\n\n        let trap = f.call(&mut store, 65536).expect_err(\"function should trap\");\n        assert!(trap.to_string().contains(\"out of bounds\"));\n\n        let trap = f.call(&mut store, 65537).expect_err(\"function should trap\");\n        assert!(trap.to_string().contains(\"out of bounds\"));\n\n        m.grow(&mut store, 1).expect(\"memory should grow\");\n        f.call(&mut store, 65536).expect(\"function should not trap\");\n\n        m.grow(&mut store, 1)\n            .expect_err(\"memory should be at the limit\");\n    }\n\n    Ok(())\n}\n\n#[test]\nfn memory_zeroed() -> Result<()> {\n    if skip_pooling_allocator_tests() {\n        return Ok(());\n    }\n\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling {\n        strategy: PoolingAllocationStrategy::NextAvailable,\n        module_limits: ModuleLimits {\n            memory_pages: 1,\n            table_elements: 0,\n            ..Default::default()\n        },\n        instance_limits: InstanceLimits { count: 1 },\n    });\n    config.dynamic_memory_guard_size(0);\n    config.static_memory_guard_size(0);\n    config.static_memory_maximum_size(65536);\n\n    let engine = Engine::new(&config)?;\n\n    let module = Module::new(&engine, r#\"(module (memory (export \"m\") 1))\"#)?;\n\n    // Instantiate the module repeatedly after writing data to the entire memory\n    for _ in 0..10 {\n        let mut store = Store::new(&engine, ());\n        let instance = Instance::new(&mut store, &module, &[])?;\n        let memory = instance.get_memory(&mut store, \"m\").unwrap();\n\n        assert_eq!(memory.size(&store,), 1);\n        assert_eq!(memory.data_size(&store), 65536);\n\n        let ptr = memory.data_mut(&mut store).as_mut_ptr();\n\n        unsafe {\n            for i in 0..8192 {\n                assert_eq!(*ptr.cast::<u64>().offset(i), 0);\n            }\n            std::ptr::write_bytes(ptr, 0xFE, memory.data_size(&store));\n        }\n    }\n\n    Ok(())\n}\n\n#[test]\nfn table_limit() -> Result<()> {\n    const TABLE_ELEMENTS: u32 = 10;\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling {\n        strategy: PoolingAllocationStrategy::NextAvailable,\n        module_limits: ModuleLimits {\n            memory_pages: 1,\n            table_elements: TABLE_ELEMENTS,\n            ..Default::default()\n        },\n        instance_limits: InstanceLimits { count: 1 },\n    });\n    config.dynamic_memory_guard_size(0);\n    config.static_memory_guard_size(0);\n    config.static_memory_maximum_size(65536);\n\n    let engine = Engine::new(&config)?;\n\n    // Module should fail to validate because the minimum is greater than the configured limit\n    match Module::new(&engine, r#\"(module (table 31 funcref))\"#) {\n        Ok(_) => panic!(\"module compilation should fail\"),\n        Err(e) => assert_eq!(\n            e.to_string(),\n            \"table index 0 has a minimum element size of 31 which exceeds the limit of 10\"\n        ),\n    }\n\n    let module = Module::new(\n        &engine,\n        r#\"(module (table (export \"t\") 0 funcref) (func (export \"f\") (result i32) (table.grow (ref.null func) (i32.const 1))))\"#,\n    )?;\n\n    // Instantiate the module and grow the table via the `f` function\n    {\n        let mut store = Store::new(&engine, ());\n        let instance = Instance::new(&mut store, &module, &[])?;\n        let f = instance.get_typed_func::<(), i32, _>(&mut store, \"f\")?;\n\n        for i in 0..TABLE_ELEMENTS {\n            assert_eq!(\n                f.call(&mut store, ()).expect(\"function should not trap\"),\n                i as i32\n            );\n        }\n\n        assert_eq!(\n            f.call(&mut store, ()).expect(\"function should not trap\"),\n            -1\n        );\n        assert_eq!(\n            f.call(&mut store, ()).expect(\"function should not trap\"),\n            -1\n        );\n    }\n\n    // Instantiate the module and grow the table via the Wasmtime API\n    let mut store = Store::new(&engine, ());\n    let instance = Instance::new(&mut store, &module, &[])?;\n\n    let table = instance.get_table(&mut store, \"t\").unwrap();\n\n    for i in 0..TABLE_ELEMENTS {\n        assert_eq!(table.size(&store), i);\n        assert_eq!(\n            table\n                .grow(&mut store, 1, Val::FuncRef(None))\n                .expect(\"table should grow\"),\n            i\n        );\n    }\n\n    assert_eq!(table.size(&store), TABLE_ELEMENTS);\n    assert!(table.grow(&mut store, 1, Val::FuncRef(None)).is_err());\n\n    Ok(())\n}\n\n#[test]\nfn table_init() -> Result<()> {\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling {\n        strategy: PoolingAllocationStrategy::NextAvailable,\n        module_limits: ModuleLimits {\n            memory_pages: 0,\n            table_elements: 6,\n            ..Default::default()\n        },\n        instance_limits: InstanceLimits {\n            count: 1,\n            ..Default::default()\n        },\n    });\n\n    let engine = Engine::new(&config)?;\n\n    let module = Module::new(\n        &engine,\n        r#\"(module (table (export \"t\") 6 funcref) (elem (i32.const 1) 1 2 3 4) (elem (i32.const 0) 0) (func) (func (param i32)) (func (param i32 i32)) (func (param i32 i32 i32)) (func (param i32 i32 i32 i32)))\"#,\n    )?;\n\n    let mut store = Store::new(&engine, ());\n    let instance = Instance::new(&mut store, &module, &[])?;\n    let table = instance.get_table(&mut store, \"t\").unwrap();\n\n    for i in 0..5 {\n        let v = table.get(&mut store, i).expect(\"table should have entry\");\n        let f = v\n            .funcref()\n            .expect(\"expected funcref\")\n            .expect(\"expected non-null value\");\n        assert_eq!(f.ty(&store).params().len(), i as usize);\n    }\n\n    assert!(\n        table\n            .get(&mut store, 5)\n            .expect(\"table should have entry\")\n            .funcref()\n            .expect(\"expected funcref\")\n            .is_none(),\n        \"funcref should be null\"\n    );\n\n    Ok(())\n}\n\n#[test]\nfn table_zeroed() -> Result<()> {\n    if skip_pooling_allocator_tests() {\n        return Ok(());\n    }\n\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling {\n        strategy: PoolingAllocationStrategy::NextAvailable,\n        module_limits: ModuleLimits {\n            memory_pages: 1,\n            table_elements: 10,\n            ..Default::default()\n        },\n        instance_limits: InstanceLimits { count: 1 },\n    });\n    config.dynamic_memory_guard_size(0);\n    config.static_memory_guard_size(0);\n    config.static_memory_maximum_size(65536);\n\n    let engine = Engine::new(&config)?;\n\n    let module = Module::new(&engine, r#\"(module (table (export \"t\") 10 funcref))\"#)?;\n\n    // Instantiate the module repeatedly after filling table elements\n    for _ in 0..10 {\n        let mut store = Store::new(&engine, ());\n        let instance = Instance::new(&mut store, &module, &[])?;\n        let table = instance.get_table(&mut store, \"t\").unwrap();\n        let f = Func::wrap(&mut store, || {});\n\n        assert_eq!(table.size(&store), 10);\n\n        for i in 0..10 {\n            match table.get(&mut store, i).unwrap() {\n                Val::FuncRef(r) => assert!(r.is_none()),\n                _ => panic!(\"expected a funcref\"),\n            }\n            table\n                .set(&mut store, i, Val::FuncRef(Some(f.clone())))\n                .unwrap();\n        }\n    }\n\n    Ok(())\n}\n\n#[test]\nfn instantiation_limit() -> Result<()> {\n    const INSTANCE_LIMIT: u32 = 10;\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling {\n        strategy: PoolingAllocationStrategy::NextAvailable,\n        module_limits: ModuleLimits {\n            memory_pages: 1,\n            table_elements: 10,\n            ..Default::default()\n        },\n        instance_limits: InstanceLimits {\n            count: INSTANCE_LIMIT,\n        },\n    });\n    config.dynamic_memory_guard_size(0);\n    config.static_memory_guard_size(0);\n    config.static_memory_maximum_size(65536);\n\n    let engine = Engine::new(&config)?;\n    let module = Module::new(&engine, r#\"(module)\"#)?;\n\n    // Instantiate to the limit\n    {\n        let mut store = Store::new(&engine, ());\n\n        for _ in 0..INSTANCE_LIMIT {\n            Instance::new(&mut store, &module, &[])?;\n        }\n\n        match Instance::new(&mut store, &module, &[]) {\n            Ok(_) => panic!(\"instantiation should fail\"),\n            Err(e) => assert_eq!(\n                e.to_string(),\n                format!(\n                    \"Limit of {} concurrent instances has been reached\",\n                    INSTANCE_LIMIT\n                )\n            ),\n        }\n    }\n\n    // With the above store dropped, ensure instantiations can be made\n\n    let mut store = Store::new(&engine, ());\n\n    for _ in 0..INSTANCE_LIMIT {\n        Instance::new(&mut store, &module, &[])?;\n    }\n\n    Ok(())\n}\n\n#[test]\nfn preserve_data_segments() -> Result<()> {\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling {\n        strategy: PoolingAllocationStrategy::NextAvailable,\n        module_limits: ModuleLimits {\n            memory_pages: 1,\n            table_elements: 10,\n            ..Default::default()\n        },\n        instance_limits: InstanceLimits { count: 2 },\n    });\n    let engine = Engine::new(&config)?;\n    let m = Module::new(\n        &engine,\n        r#\"\n            (module\n                (memory (export \"mem\") 1 1)\n                (data (i32.const 0) \"foo\"))\n        \"#,\n    )?;\n    let mut store = Store::new(&engine, ());\n    let i = Instance::new(&mut store, &m, &[])?;\n\n    // Drop the module. This should *not* drop the actual data referenced by the\n    // module, especially when uffd is enabled. If uffd is enabled we'll lazily\n    // fault in the memory of the module, which means it better still be alive\n    // after we drop this.\n    drop(m);\n\n    // Spray some stuff on the heap. If wasm data lived on the heap this should\n    // paper over things and help us catch use-after-free here if it would\n    // otherwise happen.\n    let mut strings = Vec::new();\n    for _ in 0..1000 {\n        let mut string = String::new();\n        for _ in 0..1000 {\n            string.push('g');\n        }\n        strings.push(string);\n    }\n    drop(strings);\n\n    let mem = i.get_memory(&mut store, \"mem\").unwrap();\n\n    // This will segfault with uffd enabled, and then the uffd will lazily\n    // initialize the memory. Hopefully it's still `foo`!\n    assert!(mem.data(&store).starts_with(b\"foo\"));\n\n    Ok(())\n}\n\n#[test]\nfn drop_externref_global_during_module_init() -> Result<()> {\n    struct Limiter;\n\n    impl ResourceLimiter for Limiter {\n        fn memory_growing(&mut self, _: usize, _: usize, _: Option<usize>) -> bool {\n            false\n        }\n\n        fn table_growing(&mut self, _: u32, _: u32, _: Option<u32>) -> bool {\n            false\n        }\n    }\n\n    let mut config = Config::new();\n    config.wasm_reference_types(true);\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling {\n        strategy: PoolingAllocationStrategy::NextAvailable,\n        module_limits: Default::default(),\n        instance_limits: InstanceLimits { count: 1 },\n    });\n\n    let engine = Engine::new(&config)?;\n\n    let module = Module::new(\n        &engine,\n        r#\"\n            (module\n                (global i32 (i32.const 1))\n                (global i32 (i32.const 2))\n                (global i32 (i32.const 3))\n                (global i32 (i32.const 4))\n                (global i32 (i32.const 5))\n            )\n        \"#,\n    )?;\n\n    let mut store = Store::new(&engine, Limiter);\n    drop(Instance::new(&mut store, &module, &[])?);\n    drop(store);\n\n    let module = Module::new(\n        &engine,\n        r#\"\n            (module\n                (memory 1)\n                (global (mut externref) (ref.null extern))\n            )\n        \"#,\n    )?;\n\n    let mut store = Store::new(&engine, Limiter);\n    store.limiter(|s| s);\n    assert!(Instance::new(&mut store, &module, &[]).is_err());\n\n    Ok(())\n}\n"], "filenames": ["crates/runtime/src/instance.rs", "crates/runtime/src/instance/allocator.rs", "tests/all/pooling_allocator.rs"], "buggy_code_start_loc": [94, 477, 513], "buggy_code_end_loc": [743, 572, 513], "fixing_code_start_loc": [95, 478, 514], "fixing_code_end_loc": [753, 578, 572], "type": "CWE-824", "message": "Wasmtime is an open source runtime for WebAssembly & WASI. Prior to versions 0.34.1 and 0.33.1, there exists a bug in the pooling instance allocator in Wasmtime's runtime where a failure to instantiate an instance for a module that defines an `externref` global will result in an invalid drop of a `VMExternRef` via an uninitialized pointer. A number of conditions listed in the GitHub Security Advisory must be true in order for an instance to be vulnerable to this issue. Maintainers believe that the effective impact of this bug is relatively small because the usage of `externref` is still uncommon and without a resource limiter configured on the `Store`, which is not the default configuration, it is only possible to trigger the bug from an error returned by `mprotect` or `VirtualAlloc`. Note that on Linux with the `uffd` feature enabled, it is only possible to trigger the bug from a resource limiter as the call to `mprotect` is skipped. The bug has been fixed in 0.34.1 and 0.33.1 and users are encouraged to upgrade as soon as possible. If it is not possible to upgrade to version 0.34.1 or 0.33.1 of the `wasmtime` crate, it is recommend that support for the reference types proposal be disabled by passing `false` to `Config::wasm_reference_types`. Doing so will prevent modules that use `externref` from being loaded entirely.", "other": {"cve": {"id": "CVE-2022-23636", "sourceIdentifier": "security-advisories@github.com", "published": "2022-02-16T22:15:07.820", "lastModified": "2022-02-25T20:03:50.603", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Wasmtime is an open source runtime for WebAssembly & WASI. Prior to versions 0.34.1 and 0.33.1, there exists a bug in the pooling instance allocator in Wasmtime's runtime where a failure to instantiate an instance for a module that defines an `externref` global will result in an invalid drop of a `VMExternRef` via an uninitialized pointer. A number of conditions listed in the GitHub Security Advisory must be true in order for an instance to be vulnerable to this issue. Maintainers believe that the effective impact of this bug is relatively small because the usage of `externref` is still uncommon and without a resource limiter configured on the `Store`, which is not the default configuration, it is only possible to trigger the bug from an error returned by `mprotect` or `VirtualAlloc`. Note that on Linux with the `uffd` feature enabled, it is only possible to trigger the bug from a resource limiter as the call to `mprotect` is skipped. The bug has been fixed in 0.34.1 and 0.33.1 and users are encouraged to upgrade as soon as possible. If it is not possible to upgrade to version 0.34.1 or 0.33.1 of the `wasmtime` crate, it is recommend that support for the reference types proposal be disabled by passing `false` to `Config::wasm_reference_types`. Doing so will prevent modules that use `externref` from being loaded entirely."}, {"lang": "es", "value": "Wasmtime es un tiempo de ejecuci\u00f3n de c\u00f3digo abierto para WebAssembly y WASI. En versiones anteriores a 0.34.1 y 0.33.1, se presenta un error en el asignador de instancias de pool en el tiempo de ejecuci\u00f3n de Wasmtime donde un fallo al instanciar una instancia para un m\u00f3dulo que define un \"externref\" global resultar\u00e1 en una ca\u00edda inv\u00e1lida de un \"VMExternRef\" por medio de un puntero no inicializado. Para que una instancia sea vulnerable a este problema deben cumplirse una serie de condiciones enumeradas en el aviso de seguridad de GitHub. Los mantenedores creen que el impacto efectivo de este bug es relativamente peque\u00f1o porque el uso de \"externref\" sigue siendo poco com\u00fan y sin un limitador de recursos configurado en el \"Store\", que no es la configuraci\u00f3n por defecto, s\u00f3lo es posible desencadenar el bug desde un error devuelto por \"mprotect\" o \"VirtualAlloc\". Tenga en cuenta que en Linux con la funcionalidad \"uffd\" habilitada, s\u00f3lo es posible desencadenar el fallo desde un limitador de recursos, ya que es omitida la llamada a \"mprotect\". El bug ha sido corregido en las versiones 0.34.1 y 0.33.1 y es recomendado a usuarios actualizar lo antes posible. Si no es posible actualizar a versi\u00f3n 0.34.1 o 0.33.1 del crate \"wasmtime\", es recomendado deshabilitar el soporte de la propuesta de tipos de referencia pasando \"false\" a \"Config::wasm_reference_types\". Esto evitar\u00e1 que los m\u00f3dulos que usan \"externref\" sean cargados por completo"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.1, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.2, "impactScore": 5.9}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:H/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.1, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.4, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:N/I:N/A:C", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "COMPLETE", "baseScore": 7.1}, "baseSeverity": "HIGH", "exploitabilityScore": 8.6, "impactScore": 6.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-824"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:bytecodealliance:wasmtime:*:*:*:*:*:rust:*:*", "versionEndExcluding": "0.33.1", "matchCriteriaId": "7068565A-7015-4201-9A72-641EE39C05E3"}, {"vulnerable": true, "criteria": "cpe:2.3:a:bytecodealliance:wasmtime:0.34.0:*:*:*:*:rust:*:*", "matchCriteriaId": "1F2D9A5E-8EBA-485C-B8BF-06EC20BE090D"}]}]}], "references": [{"url": "https://github.com/bytecodealliance/wasmtime/commit/886ecc562040bef61faf19438c22285c2d62403a", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-88xq-w8cq-xfg7", "source": "security-advisories@github.com", "tags": ["Mitigation", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/bytecodealliance/wasmtime/commit/886ecc562040bef61faf19438c22285c2d62403a"}}
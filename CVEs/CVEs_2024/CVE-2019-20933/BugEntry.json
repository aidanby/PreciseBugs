{"buggy_code": ["package httpd\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"expvar\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"math\"\n\t\"net/http\"\n\t\"os\"\n\t\"runtime/debug\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"github.com/bmizerany/pat\"\n\t\"github.com/dgrijalva/jwt-go\"\n\t\"github.com/gogo/protobuf/proto\"\n\t\"github.com/golang/snappy\"\n\t\"github.com/influxdata/flux\"\n\t\"github.com/influxdata/flux/lang\"\n\t\"github.com/influxdata/influxdb\"\n\t\"github.com/influxdata/influxdb/logger\"\n\t\"github.com/influxdata/influxdb/models\"\n\t\"github.com/influxdata/influxdb/monitor\"\n\t\"github.com/influxdata/influxdb/monitor/diagnostics\"\n\t\"github.com/influxdata/influxdb/prometheus\"\n\t\"github.com/influxdata/influxdb/prometheus/remote\"\n\t\"github.com/influxdata/influxdb/query\"\n\t\"github.com/influxdata/influxdb/services/meta\"\n\t\"github.com/influxdata/influxdb/services/storage\"\n\t\"github.com/influxdata/influxdb/storage/reads\"\n\t\"github.com/influxdata/influxdb/storage/reads/datatypes\"\n\t\"github.com/influxdata/influxdb/tsdb\"\n\t\"github.com/influxdata/influxdb/uuid\"\n\t\"github.com/influxdata/influxql\"\n\tprom \"github.com/prometheus/client_golang/prometheus\"\n\t\"github.com/prometheus/client_golang/prometheus/promhttp\"\n\t\"go.uber.org/zap\"\n)\n\nconst (\n\t// DefaultChunkSize specifies the maximum number of points that will\n\t// be read before sending results back to the engine.\n\t//\n\t// This has no relation to the number of bytes that are returned.\n\tDefaultChunkSize = 10000\n\n\tDefaultDebugRequestsInterval = 10 * time.Second\n\n\tMaxDebugRequestsInterval = 6 * time.Hour\n)\n\n// AuthenticationMethod defines the type of authentication used.\ntype AuthenticationMethod int\n\n// Supported authentication methods.\nconst (\n\t// Authenticate using basic authentication.\n\tUserAuthentication AuthenticationMethod = iota\n\n\t// Authenticate with jwt.\n\tBearerAuthentication\n)\n\n// TODO: Check HTTP response codes: 400, 401, 403, 409.\n\n// Route specifies how to handle a HTTP verb for a given endpoint.\ntype Route struct {\n\tName           string\n\tMethod         string\n\tPattern        string\n\tGzipped        bool\n\tLoggingEnabled bool\n\tHandlerFunc    interface{}\n}\n\n// Handler represents an HTTP handler for the InfluxDB server.\ntype Handler struct {\n\tmux       *pat.PatternServeMux\n\tVersion   string\n\tBuildType string\n\n\tMetaClient interface {\n\t\tDatabase(name string) *meta.DatabaseInfo\n\t\tDatabases() []meta.DatabaseInfo\n\t\tAuthenticate(username, password string) (ui meta.User, err error)\n\t\tUser(username string) (meta.User, error)\n\t\tAdminUserExists() bool\n\t}\n\n\tQueryAuthorizer interface {\n\t\tAuthorizeQuery(u meta.User, query *influxql.Query, database string) error\n\t}\n\n\tWriteAuthorizer interface {\n\t\tAuthorizeWrite(username, database string) error\n\t}\n\n\tQueryExecutor *query.Executor\n\n\tMonitor interface {\n\t\tStatistics(tags map[string]string) ([]*monitor.Statistic, error)\n\t\tDiagnostics() (map[string]*diagnostics.Diagnostics, error)\n\t}\n\n\tPointsWriter interface {\n\t\tWritePoints(database, retentionPolicy string, consistencyLevel models.ConsistencyLevel, user meta.User, points []models.Point) error\n\t}\n\n\tStore Store\n\n\t// Flux services\n\tController       Controller\n\tCompilerMappings flux.CompilerMappings\n\tregistered       bool\n\n\tConfig           *Config\n\tLogger           *zap.Logger\n\tCLFLogger        *log.Logger\n\taccessLog        *os.File\n\taccessLogFilters StatusFilters\n\tstats            *Statistics\n\n\trequestTracker *RequestTracker\n\twriteThrottler *Throttler\n}\n\n// NewHandler returns a new instance of handler with routes.\nfunc NewHandler(c Config) *Handler {\n\th := &Handler{\n\t\tmux:            pat.New(),\n\t\tConfig:         &c,\n\t\tLogger:         zap.NewNop(),\n\t\tCLFLogger:      log.New(os.Stderr, \"[httpd] \", 0),\n\t\tstats:          &Statistics{},\n\t\trequestTracker: NewRequestTracker(),\n\t}\n\n\t// Limit the number of concurrent & enqueued write requests.\n\th.writeThrottler = NewThrottler(c.MaxConcurrentWriteLimit, c.MaxEnqueuedWriteLimit)\n\th.writeThrottler.EnqueueTimeout = c.EnqueuedWriteTimeout\n\n\t// Disable the write log if they have been suppressed.\n\twriteLogEnabled := c.LogEnabled\n\tif c.SuppressWriteLog {\n\t\twriteLogEnabled = false\n\t}\n\n\th.AddRoutes([]Route{\n\t\tRoute{\n\t\t\t\"query-options\", // Satisfy CORS checks.\n\t\t\t\"OPTIONS\", \"/query\", false, true, h.serveOptions,\n\t\t},\n\t\tRoute{\n\t\t\t\"query\", // Query serving route.\n\t\t\t\"GET\", \"/query\", true, true, h.serveQuery,\n\t\t},\n\t\tRoute{\n\t\t\t\"query\", // Query serving route.\n\t\t\t\"POST\", \"/query\", true, true, h.serveQuery,\n\t\t},\n\t\tRoute{\n\t\t\t\"write-options\", // Satisfy CORS checks.\n\t\t\t\"OPTIONS\", \"/write\", false, true, h.serveOptions,\n\t\t},\n\t\tRoute{\n\t\t\t\"write\", // Data-ingest route.\n\t\t\t\"POST\", \"/write\", true, writeLogEnabled, h.serveWrite,\n\t\t},\n\t\tRoute{\n\t\t\t\"prometheus-write\", // Prometheus remote write\n\t\t\t\"POST\", \"/api/v1/prom/write\", false, true, h.servePromWrite,\n\t\t},\n\t\tRoute{\n\t\t\t\"prometheus-read\", // Prometheus remote read\n\t\t\t\"POST\", \"/api/v1/prom/read\", true, true, h.servePromRead,\n\t\t},\n\t\tRoute{ // Ping\n\t\t\t\"ping\",\n\t\t\t\"GET\", \"/ping\", false, true, h.servePing,\n\t\t},\n\t\tRoute{ // Ping\n\t\t\t\"ping-head\",\n\t\t\t\"HEAD\", \"/ping\", false, true, h.servePing,\n\t\t},\n\t\tRoute{ // Ping w/ status\n\t\t\t\"status\",\n\t\t\t\"GET\", \"/status\", false, true, h.serveStatus,\n\t\t},\n\t\tRoute{ // Ping w/ status\n\t\t\t\"status-head\",\n\t\t\t\"HEAD\", \"/status\", false, true, h.serveStatus,\n\t\t},\n\t\tRoute{\n\t\t\t\"prometheus-metrics\",\n\t\t\t\"GET\", \"/metrics\", false, true, promhttp.Handler().ServeHTTP,\n\t\t},\n\t}...)\n\n\tfluxRoute := Route{\n\t\t\"flux-read\",\n\t\t\"POST\", \"/api/v2/query\", true, true, nil,\n\t}\n\n\tif !c.FluxEnabled {\n\t\tfluxRoute.HandlerFunc = func(w http.ResponseWriter, r *http.Request) {\n\t\t\thttp.Error(w, \"Flux query service disabled. Verify flux-enabled=true in the [http] section of the InfluxDB config.\", http.StatusForbidden)\n\t\t}\n\t} else {\n\t\tfluxRoute.HandlerFunc = h.serveFluxQuery\n\t}\n\th.AddRoutes(fluxRoute)\n\n\treturn h\n}\n\nfunc (h *Handler) Open() {\n\tif h.Config.LogEnabled {\n\t\tpath := \"stderr\"\n\n\t\tif h.Config.AccessLogPath != \"\" {\n\t\t\tf, err := os.OpenFile(h.Config.AccessLogPath, os.O_WRONLY|os.O_APPEND|os.O_CREATE, 0666)\n\t\t\tif err != nil {\n\t\t\t\th.Logger.Error(\"unable to open access log, falling back to stderr\", zap.Error(err), zap.String(\"path\", h.Config.AccessLogPath))\n\t\t\t\treturn\n\t\t\t}\n\t\t\th.CLFLogger = log.New(f, \"\", 0) // [httpd] prefix stripped when logging to a file\n\t\t\th.accessLog = f\n\t\t\tpath = h.Config.AccessLogPath\n\t\t}\n\t\th.Logger.Info(\"opened HTTP access log\", zap.String(\"path\", path))\n\t}\n\th.accessLogFilters = StatusFilters(h.Config.AccessLogStatusFilters)\n\n\tif h.Config.FluxEnabled {\n\t\th.registered = true\n\t\tprom.MustRegister(h.Controller.PrometheusCollectors()...)\n\t}\n}\n\nfunc (h *Handler) Close() {\n\tif h.accessLog != nil {\n\t\th.accessLog.Close()\n\t\th.accessLog = nil\n\t\th.accessLogFilters = nil\n\t}\n\n\tif h.registered {\n\t\tfor _, col := range h.Controller.PrometheusCollectors() {\n\t\t\tprom.Unregister(col)\n\t\t}\n\t\th.registered = false\n\t}\n}\n\n// Statistics maintains statistics for the httpd service.\ntype Statistics struct {\n\tRequests                     int64\n\tCQRequests                   int64\n\tQueryRequests                int64\n\tWriteRequests                int64\n\tPingRequests                 int64\n\tStatusRequests               int64\n\tWriteRequestBytesReceived    int64\n\tQueryRequestBytesTransmitted int64\n\tPointsWrittenOK              int64\n\tPointsWrittenDropped         int64\n\tPointsWrittenFail            int64\n\tAuthenticationFailures       int64\n\tRequestDuration              int64\n\tQueryRequestDuration         int64\n\tWriteRequestDuration         int64\n\tActiveRequests               int64\n\tActiveWriteRequests          int64\n\tClientErrors                 int64\n\tServerErrors                 int64\n\tRecoveredPanics              int64\n\tPromWriteRequests            int64\n\tPromReadRequests             int64\n\tFluxQueryRequests            int64\n\tFluxQueryRequestDuration     int64\n}\n\n// Statistics returns statistics for periodic monitoring.\nfunc (h *Handler) Statistics(tags map[string]string) []models.Statistic {\n\treturn []models.Statistic{{\n\t\tName: \"httpd\",\n\t\tTags: tags,\n\t\tValues: map[string]interface{}{\n\t\t\tstatRequest:                      atomic.LoadInt64(&h.stats.Requests),\n\t\t\tstatQueryRequest:                 atomic.LoadInt64(&h.stats.QueryRequests),\n\t\t\tstatWriteRequest:                 atomic.LoadInt64(&h.stats.WriteRequests),\n\t\t\tstatPingRequest:                  atomic.LoadInt64(&h.stats.PingRequests),\n\t\t\tstatStatusRequest:                atomic.LoadInt64(&h.stats.StatusRequests),\n\t\t\tstatWriteRequestBytesReceived:    atomic.LoadInt64(&h.stats.WriteRequestBytesReceived),\n\t\t\tstatQueryRequestBytesTransmitted: atomic.LoadInt64(&h.stats.QueryRequestBytesTransmitted),\n\t\t\tstatPointsWrittenOK:              atomic.LoadInt64(&h.stats.PointsWrittenOK),\n\t\t\tstatPointsWrittenDropped:         atomic.LoadInt64(&h.stats.PointsWrittenDropped),\n\t\t\tstatPointsWrittenFail:            atomic.LoadInt64(&h.stats.PointsWrittenFail),\n\t\t\tstatAuthFail:                     atomic.LoadInt64(&h.stats.AuthenticationFailures),\n\t\t\tstatRequestDuration:              atomic.LoadInt64(&h.stats.RequestDuration),\n\t\t\tstatQueryRequestDuration:         atomic.LoadInt64(&h.stats.QueryRequestDuration),\n\t\t\tstatWriteRequestDuration:         atomic.LoadInt64(&h.stats.WriteRequestDuration),\n\t\t\tstatRequestsActive:               atomic.LoadInt64(&h.stats.ActiveRequests),\n\t\t\tstatWriteRequestsActive:          atomic.LoadInt64(&h.stats.ActiveWriteRequests),\n\t\t\tstatClientError:                  atomic.LoadInt64(&h.stats.ClientErrors),\n\t\t\tstatServerError:                  atomic.LoadInt64(&h.stats.ServerErrors),\n\t\t\tstatRecoveredPanics:              atomic.LoadInt64(&h.stats.RecoveredPanics),\n\t\t\tstatPromWriteRequest:             atomic.LoadInt64(&h.stats.PromWriteRequests),\n\t\t\tstatPromReadRequest:              atomic.LoadInt64(&h.stats.PromReadRequests),\n\t\t\tstatFluxQueryRequests:            atomic.LoadInt64(&h.stats.FluxQueryRequests),\n\t\t\tstatFluxQueryRequestDuration:     atomic.LoadInt64(&h.stats.FluxQueryRequestDuration),\n\t\t},\n\t}}\n}\n\n// AddRoutes sets the provided routes on the handler.\nfunc (h *Handler) AddRoutes(routes ...Route) {\n\tfor _, r := range routes {\n\t\tvar handler http.Handler\n\n\t\t// If it's a handler func that requires authorization, wrap it in authentication\n\t\tif hf, ok := r.HandlerFunc.(func(http.ResponseWriter, *http.Request, meta.User)); ok {\n\t\t\thandler = authenticate(hf, h, h.Config.AuthEnabled)\n\t\t}\n\n\t\t// This is a normal handler signature and does not require authentication\n\t\tif hf, ok := r.HandlerFunc.(func(http.ResponseWriter, *http.Request)); ok {\n\t\t\thandler = http.HandlerFunc(hf)\n\t\t}\n\n\t\t// Throttle route if this is a write endpoint.\n\t\tif r.Method == http.MethodPost {\n\t\t\tswitch r.Pattern {\n\t\t\tcase \"/write\", \"/api/v1/prom/write\":\n\t\t\t\thandler = h.writeThrottler.Handler(handler)\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\n\t\thandler = h.responseWriter(handler)\n\t\tif r.Gzipped {\n\t\t\thandler = gzipFilter(handler)\n\t\t}\n\t\thandler = cors(handler)\n\t\thandler = requestID(handler)\n\t\tif h.Config.LogEnabled && r.LoggingEnabled {\n\t\t\thandler = h.logging(handler, r.Name)\n\t\t}\n\t\thandler = h.recovery(handler, r.Name) // make sure recovery is always last\n\n\t\th.mux.Add(r.Method, r.Pattern, handler)\n\t}\n}\n\n// ServeHTTP responds to HTTP request to the handler.\nfunc (h *Handler) ServeHTTP(w http.ResponseWriter, r *http.Request) {\n\tatomic.AddInt64(&h.stats.Requests, 1)\n\tatomic.AddInt64(&h.stats.ActiveRequests, 1)\n\tdefer atomic.AddInt64(&h.stats.ActiveRequests, -1)\n\tstart := time.Now()\n\n\t// Add version and build header to all InfluxDB requests.\n\tw.Header().Add(\"X-Influxdb-Version\", h.Version)\n\tw.Header().Add(\"X-Influxdb-Build\", h.BuildType)\n\n\tif strings.HasPrefix(r.URL.Path, \"/debug/pprof\") && h.Config.PprofEnabled {\n\t\th.handleProfiles(w, r)\n\t} else if strings.HasPrefix(r.URL.Path, \"/debug/vars\") {\n\t\th.serveExpvar(w, r)\n\t} else if strings.HasPrefix(r.URL.Path, \"/debug/requests\") {\n\t\th.serveDebugRequests(w, r)\n\t} else {\n\t\th.mux.ServeHTTP(w, r)\n\t}\n\n\tatomic.AddInt64(&h.stats.RequestDuration, time.Since(start).Nanoseconds())\n}\n\n// writeHeader writes the provided status code in the response, and\n// updates relevant http error statistics.\nfunc (h *Handler) writeHeader(w http.ResponseWriter, code int) {\n\tswitch code / 100 {\n\tcase 4:\n\t\tatomic.AddInt64(&h.stats.ClientErrors, 1)\n\tcase 5:\n\t\tatomic.AddInt64(&h.stats.ServerErrors, 1)\n\t}\n\tw.WriteHeader(code)\n}\n\n// serveQuery parses an incoming query and, if valid, executes the query.\nfunc (h *Handler) serveQuery(w http.ResponseWriter, r *http.Request, user meta.User) {\n\tatomic.AddInt64(&h.stats.QueryRequests, 1)\n\tdefer func(start time.Time) {\n\t\tatomic.AddInt64(&h.stats.QueryRequestDuration, time.Since(start).Nanoseconds())\n\t}(time.Now())\n\th.requestTracker.Add(r, user)\n\n\t// Retrieve the underlying ResponseWriter or initialize our own.\n\trw, ok := w.(ResponseWriter)\n\tif !ok {\n\t\trw = NewResponseWriter(w, r)\n\t}\n\n\t// Retrieve the node id the query should be executed on.\n\tnodeID, _ := strconv.ParseUint(r.FormValue(\"node_id\"), 10, 64)\n\n\tvar qr io.Reader\n\t// Attempt to read the form value from the \"q\" form value.\n\tif qp := strings.TrimSpace(r.FormValue(\"q\")); qp != \"\" {\n\t\tqr = strings.NewReader(qp)\n\t} else if r.MultipartForm != nil && r.MultipartForm.File != nil {\n\t\t// If we have a multipart/form-data, try to retrieve a file from 'q'.\n\t\tif fhs := r.MultipartForm.File[\"q\"]; len(fhs) > 0 {\n\t\t\tf, err := fhs[0].Open()\n\t\t\tif err != nil {\n\t\t\t\th.httpError(rw, err.Error(), http.StatusBadRequest)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tdefer f.Close()\n\t\t\tqr = f\n\t\t}\n\t}\n\n\tif qr == nil {\n\t\th.httpError(rw, `missing required parameter \"q\"`, http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tepoch := strings.TrimSpace(r.FormValue(\"epoch\"))\n\n\tp := influxql.NewParser(qr)\n\tdb := r.FormValue(\"db\")\n\n\t// Sanitize the request query params so it doesn't show up in the response logger.\n\t// Do this before anything else so a parsing error doesn't leak passwords.\n\tsanitize(r)\n\n\t// Parse the parameters\n\trawParams := r.FormValue(\"params\")\n\tif rawParams != \"\" {\n\t\tvar params map[string]interface{}\n\t\tdecoder := json.NewDecoder(strings.NewReader(rawParams))\n\t\tdecoder.UseNumber()\n\t\tif err := decoder.Decode(&params); err != nil {\n\t\t\th.httpError(rw, \"error parsing query parameters: \"+err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\t// Convert json.Number into int64 and float64 values\n\t\tfor k, v := range params {\n\t\t\tif v, ok := v.(json.Number); ok {\n\t\t\t\tvar err error\n\t\t\t\tif strings.Contains(string(v), \".\") {\n\t\t\t\t\tparams[k], err = v.Float64()\n\t\t\t\t} else {\n\t\t\t\t\tparams[k], err = v.Int64()\n\t\t\t\t}\n\n\t\t\t\tif err != nil {\n\t\t\t\t\th.httpError(rw, \"error parsing json value: \"+err.Error(), http.StatusBadRequest)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tp.SetParams(params)\n\t}\n\n\t// Parse query from query string.\n\tq, err := p.ParseQuery()\n\tif err != nil {\n\t\th.httpError(rw, \"error parsing query: \"+err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\t// Check authorization.\n\tif h.Config.AuthEnabled {\n\t\tif err := h.QueryAuthorizer.AuthorizeQuery(user, q, db); err != nil {\n\t\t\tif err, ok := err.(meta.ErrAuthorize); ok {\n\t\t\t\th.Logger.Info(\"Unauthorized request\",\n\t\t\t\t\tzap.String(\"user\", err.User),\n\t\t\t\t\tzap.Stringer(\"query\", err.Query),\n\t\t\t\t\tlogger.Database(err.Database))\n\t\t\t}\n\t\t\th.httpError(rw, \"error authorizing query: \"+err.Error(), http.StatusForbidden)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Parse chunk size. Use default if not provided or unparsable.\n\tchunked := r.FormValue(\"chunked\") == \"true\"\n\tchunkSize := DefaultChunkSize\n\tif chunked {\n\t\tif n, err := strconv.ParseInt(r.FormValue(\"chunk_size\"), 10, 64); err == nil && int(n) > 0 {\n\t\t\tchunkSize = int(n)\n\t\t}\n\t}\n\n\t// Parse whether this is an async command.\n\tasync := r.FormValue(\"async\") == \"true\"\n\n\topts := query.ExecutionOptions{\n\t\tDatabase:        db,\n\t\tRetentionPolicy: r.FormValue(\"rp\"),\n\t\tChunkSize:       chunkSize,\n\t\tReadOnly:        r.Method == \"GET\",\n\t\tNodeID:          nodeID,\n\t}\n\n\tif h.Config.AuthEnabled {\n\t\tif user != nil && user.AuthorizeUnrestricted() {\n\t\t\topts.Authorizer = query.OpenAuthorizer\n\t\t} else {\n\t\t\t// The current user determines the authorized actions.\n\t\t\topts.Authorizer = user\n\t\t}\n\t} else {\n\t\t// Auth is disabled, so allow everything.\n\t\topts.Authorizer = query.OpenAuthorizer\n\t}\n\n\t// Make sure if the client disconnects we signal the query to abort\n\tvar closing chan struct{}\n\tif !async {\n\t\tclosing = make(chan struct{})\n\t\tif notifier, ok := w.(http.CloseNotifier); ok {\n\t\t\t// CloseNotify() is not guaranteed to send a notification when the query\n\t\t\t// is closed. Use this channel to signal that the query is finished to\n\t\t\t// prevent lingering goroutines that may be stuck.\n\t\t\tdone := make(chan struct{})\n\t\t\tdefer close(done)\n\n\t\t\tnotify := notifier.CloseNotify()\n\t\t\tgo func() {\n\t\t\t\t// Wait for either the request to finish\n\t\t\t\t// or for the client to disconnect\n\t\t\t\tselect {\n\t\t\t\tcase <-done:\n\t\t\t\tcase <-notify:\n\t\t\t\t\tclose(closing)\n\t\t\t\t}\n\t\t\t}()\n\t\t\topts.AbortCh = done\n\t\t} else {\n\t\t\tdefer close(closing)\n\t\t}\n\t}\n\n\t// Execute query.\n\tresults := h.QueryExecutor.ExecuteQuery(q, opts, closing)\n\n\t// If we are running in async mode, open a goroutine to drain the results\n\t// and return with a StatusNoContent.\n\tif async {\n\t\tgo h.async(q, results)\n\t\th.writeHeader(w, http.StatusNoContent)\n\t\treturn\n\t}\n\n\t// if we're not chunking, this will be the in memory buffer for all results before sending to client\n\tresp := Response{Results: make([]*query.Result, 0)}\n\n\t// Status header is OK once this point is reached.\n\t// Attempt to flush the header immediately so the client gets the header information\n\t// and knows the query was accepted.\n\th.writeHeader(rw, http.StatusOK)\n\tif w, ok := w.(http.Flusher); ok {\n\t\tw.Flush()\n\t}\n\n\t// pull all results from the channel\n\trows := 0\n\tfor r := range results {\n\t\t// Ignore nil results.\n\t\tif r == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\t// if requested, convert result timestamps to epoch\n\t\tif epoch != \"\" {\n\t\t\tconvertToEpoch(r, epoch)\n\t\t}\n\n\t\t// Write out result immediately if chunked.\n\t\tif chunked {\n\t\t\tn, _ := rw.WriteResponse(Response{\n\t\t\t\tResults: []*query.Result{r},\n\t\t\t})\n\t\t\tatomic.AddInt64(&h.stats.QueryRequestBytesTransmitted, int64(n))\n\t\t\tw.(http.Flusher).Flush()\n\t\t\tcontinue\n\t\t}\n\n\t\t// Limit the number of rows that can be returned in a non-chunked\n\t\t// response.  This is to prevent the server from going OOM when\n\t\t// returning a large response.  If you want to return more than the\n\t\t// default chunk size, then use chunking to process multiple blobs.\n\t\t// Iterate through the series in this result to count the rows and\n\t\t// truncate any rows we shouldn't return.\n\t\tif h.Config.MaxRowLimit > 0 {\n\t\t\tfor i, series := range r.Series {\n\t\t\t\tn := h.Config.MaxRowLimit - rows\n\t\t\t\tif n < len(series.Values) {\n\t\t\t\t\t// We have reached the maximum number of values. Truncate\n\t\t\t\t\t// the values within this row.\n\t\t\t\t\tseries.Values = series.Values[:n]\n\t\t\t\t\t// Since this was truncated, it will always be a partial return.\n\t\t\t\t\t// Add this so the client knows we truncated the response.\n\t\t\t\t\tseries.Partial = true\n\t\t\t\t}\n\t\t\t\trows += len(series.Values)\n\n\t\t\t\tif rows >= h.Config.MaxRowLimit {\n\t\t\t\t\t// Drop any remaining series since we have already reached the row limit.\n\t\t\t\t\tif i < len(r.Series) {\n\t\t\t\t\t\tr.Series = r.Series[:i+1]\n\t\t\t\t\t}\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// It's not chunked so buffer results in memory.\n\t\t// Results for statements need to be combined together.\n\t\t// We need to check if this new result is for the same statement as\n\t\t// the last result, or for the next statement\n\t\tl := len(resp.Results)\n\t\tif l == 0 {\n\t\t\tresp.Results = append(resp.Results, r)\n\t\t} else if resp.Results[l-1].StatementID == r.StatementID {\n\t\t\tif r.Err != nil {\n\t\t\t\tresp.Results[l-1] = r\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tcr := resp.Results[l-1]\n\t\t\trowsMerged := 0\n\t\t\tif len(cr.Series) > 0 {\n\t\t\t\tlastSeries := cr.Series[len(cr.Series)-1]\n\n\t\t\t\tfor _, row := range r.Series {\n\t\t\t\t\tif !lastSeries.SameSeries(row) {\n\t\t\t\t\t\t// Next row is for a different series than last.\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t\t// Values are for the same series, so append them.\n\t\t\t\t\tlastSeries.Values = append(lastSeries.Values, row.Values...)\n\t\t\t\t\trowsMerged++\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Append remaining rows as new rows.\n\t\t\tr.Series = r.Series[rowsMerged:]\n\t\t\tcr.Series = append(cr.Series, r.Series...)\n\t\t\tcr.Messages = append(cr.Messages, r.Messages...)\n\t\t\tcr.Partial = r.Partial\n\t\t} else {\n\t\t\tresp.Results = append(resp.Results, r)\n\t\t}\n\n\t\t// Drop out of this loop and do not process further results when we hit the row limit.\n\t\tif h.Config.MaxRowLimit > 0 && rows >= h.Config.MaxRowLimit {\n\t\t\t// If the result is marked as partial, remove that partial marking\n\t\t\t// here. While the series is partial and we would normally have\n\t\t\t// tried to return the rest in the next chunk, we are not using\n\t\t\t// chunking and are truncating the series so we don't want to\n\t\t\t// signal to the client that we plan on sending another JSON blob\n\t\t\t// with another result.  The series, on the other hand, still\n\t\t\t// returns partial true if it was truncated or had more data to\n\t\t\t// send in a future chunk.\n\t\t\tr.Partial = false\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// If it's not chunked we buffered everything in memory, so write it out\n\tif !chunked {\n\t\tn, _ := rw.WriteResponse(resp)\n\t\tatomic.AddInt64(&h.stats.QueryRequestBytesTransmitted, int64(n))\n\t}\n}\n\n// async drains the results from an async query and logs a message if it fails.\nfunc (h *Handler) async(q *influxql.Query, results <-chan *query.Result) {\n\tfor r := range results {\n\t\t// Drain the results and do nothing with them.\n\t\t// If it fails, log the failure so there is at least a record of it.\n\t\tif r.Err != nil {\n\t\t\t// Do not log when a statement was not executed since there would\n\t\t\t// have been an earlier error that was already logged.\n\t\t\tif r.Err == query.ErrNotExecuted {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\th.Logger.Info(\"Error while running async query\",\n\t\t\t\tzap.Stringer(\"query\", q),\n\t\t\t\tzap.Error(r.Err))\n\t\t}\n\t}\n}\n\n// serveWrite receives incoming series data in line protocol format and writes it to the database.\nfunc (h *Handler) serveWrite(w http.ResponseWriter, r *http.Request, user meta.User) {\n\tatomic.AddInt64(&h.stats.WriteRequests, 1)\n\tatomic.AddInt64(&h.stats.ActiveWriteRequests, 1)\n\tdefer func(start time.Time) {\n\t\tatomic.AddInt64(&h.stats.ActiveWriteRequests, -1)\n\t\tatomic.AddInt64(&h.stats.WriteRequestDuration, time.Since(start).Nanoseconds())\n\t}(time.Now())\n\th.requestTracker.Add(r, user)\n\n\tdatabase := r.URL.Query().Get(\"db\")\n\tif database == \"\" {\n\t\th.httpError(w, \"database is required\", http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tif di := h.MetaClient.Database(database); di == nil {\n\t\th.httpError(w, fmt.Sprintf(\"database not found: %q\", database), http.StatusNotFound)\n\t\treturn\n\t}\n\n\tif h.Config.AuthEnabled {\n\t\tif user == nil {\n\t\t\th.httpError(w, fmt.Sprintf(\"user is required to write to database %q\", database), http.StatusForbidden)\n\t\t\treturn\n\t\t}\n\n\t\tif err := h.WriteAuthorizer.AuthorizeWrite(user.ID(), database); err != nil {\n\t\t\th.httpError(w, fmt.Sprintf(\"%q user is not authorized to write to database %q\", user.ID(), database), http.StatusForbidden)\n\t\t\treturn\n\t\t}\n\t}\n\n\tbody := r.Body\n\tif h.Config.MaxBodySize > 0 {\n\t\tbody = truncateReader(body, int64(h.Config.MaxBodySize))\n\t}\n\n\t// Handle gzip decoding of the body\n\tif r.Header.Get(\"Content-Encoding\") == \"gzip\" {\n\t\tb, err := gzip.NewReader(r.Body)\n\t\tif err != nil {\n\t\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer b.Close()\n\t\tbody = b\n\t}\n\n\tvar bs []byte\n\tif r.ContentLength > 0 {\n\t\tif h.Config.MaxBodySize > 0 && r.ContentLength > int64(h.Config.MaxBodySize) {\n\t\t\th.httpError(w, http.StatusText(http.StatusRequestEntityTooLarge), http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\n\t\t// This will just be an initial hint for the gzip reader, as the\n\t\t// bytes.Buffer will grow as needed when ReadFrom is called\n\t\tbs = make([]byte, 0, r.ContentLength)\n\t}\n\tbuf := bytes.NewBuffer(bs)\n\n\t_, err := buf.ReadFrom(body)\n\tif err != nil {\n\t\tif err == errTruncated {\n\t\t\th.httpError(w, http.StatusText(http.StatusRequestEntityTooLarge), http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\n\t\tif h.Config.WriteTracing {\n\t\t\th.Logger.Info(\"Write handler unable to read bytes from request body\")\n\t\t}\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\tatomic.AddInt64(&h.stats.WriteRequestBytesReceived, int64(buf.Len()))\n\n\tif h.Config.WriteTracing {\n\t\th.Logger.Info(\"Write body received by handler\", zap.ByteString(\"body\", buf.Bytes()))\n\t}\n\n\tpoints, parseError := models.ParsePointsWithPrecision(buf.Bytes(), time.Now().UTC(), r.URL.Query().Get(\"precision\"))\n\t// Not points parsed correctly so return the error now\n\tif parseError != nil && len(points) == 0 {\n\t\tif parseError.Error() == \"EOF\" {\n\t\t\th.writeHeader(w, http.StatusOK)\n\t\t\treturn\n\t\t}\n\t\th.httpError(w, parseError.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\t// Determine required consistency level.\n\tlevel := r.URL.Query().Get(\"consistency\")\n\tconsistency := models.ConsistencyLevelOne\n\tif level != \"\" {\n\t\tvar err error\n\t\tconsistency, err = models.ParseConsistencyLevel(level)\n\t\tif err != nil {\n\t\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Write points.\n\tif err := h.PointsWriter.WritePoints(database, r.URL.Query().Get(\"rp\"), consistency, user, points); influxdb.IsClientError(err) {\n\t\tatomic.AddInt64(&h.stats.PointsWrittenFail, int64(len(points)))\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t} else if influxdb.IsAuthorizationError(err) {\n\t\tatomic.AddInt64(&h.stats.PointsWrittenFail, int64(len(points)))\n\t\th.httpError(w, err.Error(), http.StatusForbidden)\n\t\treturn\n\t} else if werr, ok := err.(tsdb.PartialWriteError); ok {\n\t\tatomic.AddInt64(&h.stats.PointsWrittenOK, int64(len(points)-werr.Dropped))\n\t\tatomic.AddInt64(&h.stats.PointsWrittenDropped, int64(werr.Dropped))\n\t\th.httpError(w, werr.Error(), http.StatusBadRequest)\n\t\treturn\n\t} else if err != nil {\n\t\tatomic.AddInt64(&h.stats.PointsWrittenFail, int64(len(points)))\n\t\th.httpError(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t} else if parseError != nil {\n\t\t// We wrote some of the points\n\t\tatomic.AddInt64(&h.stats.PointsWrittenOK, int64(len(points)))\n\t\t// The other points failed to parse which means the client sent invalid line protocol.  We return a 400\n\t\t// response code as well as the lines that failed to parse.\n\t\th.httpError(w, tsdb.PartialWriteError{Reason: parseError.Error()}.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tatomic.AddInt64(&h.stats.PointsWrittenOK, int64(len(points)))\n\th.writeHeader(w, http.StatusNoContent)\n}\n\n// serveOptions returns an empty response to comply with OPTIONS pre-flight requests\nfunc (h *Handler) serveOptions(w http.ResponseWriter, r *http.Request) {\n\th.writeHeader(w, http.StatusNoContent)\n}\n\n// servePing returns a simple response to let the client know the server is running.\nfunc (h *Handler) servePing(w http.ResponseWriter, r *http.Request) {\n\tverbose := r.URL.Query().Get(\"verbose\")\n\tatomic.AddInt64(&h.stats.PingRequests, 1)\n\n\tif verbose != \"\" && verbose != \"0\" && verbose != \"false\" {\n\t\th.writeHeader(w, http.StatusOK)\n\t\tb, _ := json.Marshal(map[string]string{\"version\": h.Version})\n\t\tw.Write(b)\n\t} else {\n\t\th.writeHeader(w, http.StatusNoContent)\n\t}\n}\n\n// serveStatus has been deprecated.\nfunc (h *Handler) serveStatus(w http.ResponseWriter, r *http.Request) {\n\th.Logger.Info(\"WARNING: /status has been deprecated.  Use /ping instead.\")\n\tatomic.AddInt64(&h.stats.StatusRequests, 1)\n\th.writeHeader(w, http.StatusNoContent)\n}\n\n// convertToEpoch converts result timestamps from time.Time to the specified epoch.\nfunc convertToEpoch(r *query.Result, epoch string) {\n\tdivisor := int64(1)\n\n\tswitch epoch {\n\tcase \"u\":\n\t\tdivisor = int64(time.Microsecond)\n\tcase \"ms\":\n\t\tdivisor = int64(time.Millisecond)\n\tcase \"s\":\n\t\tdivisor = int64(time.Second)\n\tcase \"m\":\n\t\tdivisor = int64(time.Minute)\n\tcase \"h\":\n\t\tdivisor = int64(time.Hour)\n\t}\n\n\tfor _, s := range r.Series {\n\t\tfor _, v := range s.Values {\n\t\t\tif ts, ok := v[0].(time.Time); ok {\n\t\t\t\tv[0] = ts.UnixNano() / divisor\n\t\t\t}\n\t\t}\n\t}\n}\n\n// servePromWrite receives data in the Prometheus remote write protocol and writes it\n// to the database\nfunc (h *Handler) servePromWrite(w http.ResponseWriter, r *http.Request, user meta.User) {\n\tatomic.AddInt64(&h.stats.WriteRequests, 1)\n\tatomic.AddInt64(&h.stats.ActiveWriteRequests, 1)\n\tatomic.AddInt64(&h.stats.PromWriteRequests, 1)\n\tdefer func(start time.Time) {\n\t\tatomic.AddInt64(&h.stats.ActiveWriteRequests, -1)\n\t\tatomic.AddInt64(&h.stats.WriteRequestDuration, time.Since(start).Nanoseconds())\n\t}(time.Now())\n\th.requestTracker.Add(r, user)\n\n\tdatabase := r.URL.Query().Get(\"db\")\n\tif database == \"\" {\n\t\th.httpError(w, \"database is required\", http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tif di := h.MetaClient.Database(database); di == nil {\n\t\th.httpError(w, fmt.Sprintf(\"database not found: %q\", database), http.StatusNotFound)\n\t\treturn\n\t}\n\n\tif h.Config.AuthEnabled {\n\t\tif user == nil {\n\t\t\th.httpError(w, fmt.Sprintf(\"user is required to write to database %q\", database), http.StatusForbidden)\n\t\t\treturn\n\t\t}\n\n\t\tif err := h.WriteAuthorizer.AuthorizeWrite(user.ID(), database); err != nil {\n\t\t\th.httpError(w, fmt.Sprintf(\"%q user is not authorized to write to database %q\", user.ID(), database), http.StatusForbidden)\n\t\t\treturn\n\t\t}\n\t}\n\n\tbody := r.Body\n\tif h.Config.MaxBodySize > 0 {\n\t\tbody = truncateReader(body, int64(h.Config.MaxBodySize))\n\t}\n\n\tvar bs []byte\n\tif r.ContentLength > 0 {\n\t\tif h.Config.MaxBodySize > 0 && r.ContentLength > int64(h.Config.MaxBodySize) {\n\t\t\th.httpError(w, http.StatusText(http.StatusRequestEntityTooLarge), http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\n\t\t// This will just be an initial hint for the reader, as the\n\t\t// bytes.Buffer will grow as needed when ReadFrom is called\n\t\tbs = make([]byte, 0, r.ContentLength)\n\t}\n\tbuf := bytes.NewBuffer(bs)\n\n\t_, err := buf.ReadFrom(body)\n\tif err != nil {\n\t\tif err == errTruncated {\n\t\t\th.httpError(w, http.StatusText(http.StatusRequestEntityTooLarge), http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\n\t\tif h.Config.WriteTracing {\n\t\t\th.Logger.Info(\"Prom write handler unable to read bytes from request body\")\n\t\t}\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\tatomic.AddInt64(&h.stats.WriteRequestBytesReceived, int64(buf.Len()))\n\n\tif h.Config.WriteTracing {\n\t\th.Logger.Info(\"Prom write body received by handler\", zap.ByteString(\"body\", buf.Bytes()))\n\t}\n\n\treqBuf, err := snappy.Decode(nil, buf.Bytes())\n\tif err != nil {\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\t// Convert the Prometheus remote write request to Influx Points\n\tvar req remote.WriteRequest\n\tif err := proto.Unmarshal(reqBuf, &req); err != nil {\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tpoints, err := prometheus.WriteRequestToPoints(&req)\n\tif err != nil {\n\t\tif h.Config.WriteTracing {\n\t\t\th.Logger.Info(\"Prom write handler\", zap.Error(err))\n\t\t}\n\n\t\tif err != prometheus.ErrNaNDropped {\n\t\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Determine required consistency level.\n\tlevel := r.URL.Query().Get(\"consistency\")\n\tconsistency := models.ConsistencyLevelOne\n\tif level != \"\" {\n\t\tconsistency, err = models.ParseConsistencyLevel(level)\n\t\tif err != nil {\n\t\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Write points.\n\tif err := h.PointsWriter.WritePoints(database, r.URL.Query().Get(\"rp\"), consistency, user, points); influxdb.IsClientError(err) {\n\t\tatomic.AddInt64(&h.stats.PointsWrittenFail, int64(len(points)))\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t} else if influxdb.IsAuthorizationError(err) {\n\t\tatomic.AddInt64(&h.stats.PointsWrittenFail, int64(len(points)))\n\t\th.httpError(w, err.Error(), http.StatusForbidden)\n\t\treturn\n\t} else if werr, ok := err.(tsdb.PartialWriteError); ok {\n\t\tatomic.AddInt64(&h.stats.PointsWrittenOK, int64(len(points)-werr.Dropped))\n\t\tatomic.AddInt64(&h.stats.PointsWrittenDropped, int64(werr.Dropped))\n\t\th.httpError(w, werr.Error(), http.StatusBadRequest)\n\t\treturn\n\t} else if err != nil {\n\t\tatomic.AddInt64(&h.stats.PointsWrittenFail, int64(len(points)))\n\t\th.httpError(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\tatomic.AddInt64(&h.stats.PointsWrittenOK, int64(len(points)))\n\th.writeHeader(w, http.StatusNoContent)\n}\n\n// servePromRead will convert a Prometheus remote read request into a storage\n// query and returns data in Prometheus remote read protobuf format.\nfunc (h *Handler) servePromRead(w http.ResponseWriter, r *http.Request, user meta.User) {\n\tcompressed, err := ioutil.ReadAll(r.Body)\n\tif err != nil {\n\t\th.httpError(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\treqBuf, err := snappy.Decode(nil, compressed)\n\tif err != nil {\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tvar req remote.ReadRequest\n\tif err := proto.Unmarshal(reqBuf, &req); err != nil {\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\t// Query the DB and create a ReadResponse for Prometheus\n\tdb := r.FormValue(\"db\")\n\trp := r.FormValue(\"rp\")\n\n\treadRequest, err := prometheus.ReadRequestToInfluxStorageRequest(&req, db, rp)\n\tif err != nil {\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tctx := context.Background()\n\trs, err := h.Store.Read(ctx, readRequest)\n\tif err != nil {\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\tdefer rs.Close()\n\n\tresp := &remote.ReadResponse{\n\t\tResults: []*remote.QueryResult{{}},\n\t}\n\tfor rs.Next() {\n\t\tcur := rs.Cursor()\n\t\tif cur == nil {\n\t\t\t// no data for series key + field combination\n\t\t\tcontinue\n\t\t}\n\n\t\ttags := prometheus.RemoveInfluxSystemTags(rs.Tags())\n\t\tvar unsupportedCursor string\n\t\tswitch cur := cur.(type) {\n\t\tcase tsdb.FloatArrayCursor:\n\t\t\tvar series *remote.TimeSeries\n\t\t\tfor {\n\t\t\t\ta := cur.Next()\n\t\t\t\tif a.Len() == 0 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\n\t\t\t\t// We have some data for this series.\n\t\t\t\tif series == nil {\n\t\t\t\t\tseries = &remote.TimeSeries{\n\t\t\t\t\t\tLabels: prometheus.ModelTagsToLabelPairs(tags),\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tfor i, ts := range a.Timestamps {\n\t\t\t\t\tseries.Samples = append(series.Samples, &remote.Sample{\n\t\t\t\t\t\tTimestampMs: ts / int64(time.Millisecond),\n\t\t\t\t\t\tValue:       a.Values[i],\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// There was data for the series.\n\t\t\tif series != nil {\n\t\t\t\tresp.Results[0].Timeseries = append(resp.Results[0].Timeseries, series)\n\t\t\t}\n\t\tcase tsdb.IntegerArrayCursor:\n\t\t\tunsupportedCursor = \"int64\"\n\t\tcase tsdb.UnsignedArrayCursor:\n\t\t\tunsupportedCursor = \"uint\"\n\t\tcase tsdb.BooleanArrayCursor:\n\t\t\tunsupportedCursor = \"bool\"\n\t\tcase tsdb.StringArrayCursor:\n\t\t\tunsupportedCursor = \"string\"\n\t\tdefault:\n\t\t\tpanic(fmt.Sprintf(\"unreachable: %T\", cur))\n\t\t}\n\t\tcur.Close()\n\n\t\tif len(unsupportedCursor) > 0 {\n\t\t\th.Logger.Info(\"Prometheus can't read cursor\",\n\t\t\t\tzap.String(\"cursor_type\", unsupportedCursor),\n\t\t\t\tzap.Stringer(\"series\", tags),\n\t\t\t)\n\t\t}\n\t}\n\tdata, err := proto.Marshal(resp)\n\tif err != nil {\n\t\th.httpError(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\tw.Header().Set(\"Content-Type\", \"application/x-protobuf\")\n\tw.Header().Set(\"Content-Encoding\", \"snappy\")\n\n\tcompressed = snappy.Encode(nil, data)\n\tif _, err := w.Write(compressed); err != nil {\n\t\th.httpError(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\tatomic.AddInt64(&h.stats.QueryRequestBytesTransmitted, int64(len(compressed)))\n}\n\nfunc (h *Handler) serveFluxQuery(w http.ResponseWriter, r *http.Request, user meta.User) {\n\tatomic.AddInt64(&h.stats.FluxQueryRequests, 1)\n\tdefer func(start time.Time) {\n\t\tatomic.AddInt64(&h.stats.FluxQueryRequestDuration, time.Since(start).Nanoseconds())\n\t}(time.Now())\n\n\treq, err := decodeQueryRequest(r)\n\tif err != nil {\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tctx := r.Context()\n\tif val := r.FormValue(\"node_id\"); val != \"\" {\n\t\tif nodeID, err := strconv.ParseUint(val, 10, 64); err == nil {\n\t\t\tctx = storage.NewContextWithReadOptions(ctx, &storage.ReadOptions{NodeID: nodeID})\n\t\t}\n\t}\n\n\tif h.Config.AuthEnabled {\n\t\tctx = meta.NewContextWithUser(ctx, user)\n\t}\n\n\tpr := req.ProxyRequest()\n\n\t// Logging\n\tvar (\n\t\tstats flux.Statistics\n\t\tn     int64\n\t)\n\tif h.Config.FluxLogEnabled {\n\t\tdefer func() {\n\t\t\th.logFluxQuery(n, stats, pr.Compiler, err)\n\t\t}()\n\t}\n\n\tq, err := h.Controller.Query(ctx, pr.Compiler)\n\tif err != nil {\n\t\th.httpError(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\tdefer func() {\n\t\tq.Cancel()\n\t\tq.Done()\n\t}()\n\n\t// NOTE: We do not write out the headers here.\n\t// It is possible that if the encoding step fails\n\t// that we can write an error header so long as\n\t// the encoder did not write anything.\n\t// As such we rely on the http.ResponseWriter behavior\n\t// to write an StatusOK header with the first write.\n\n\tswitch r.Header.Get(\"Accept\") {\n\tcase \"text/csv\":\n\t\tfallthrough\n\tdefault:\n\t\tif hd, ok := pr.Dialect.(httpDialect); !ok {\n\t\t\th.httpError(w, fmt.Sprintf(\"unsupported dialect over HTTP %T\", req.Dialect), http.StatusBadRequest)\n\t\t\treturn\n\t\t} else {\n\t\t\thd.SetHeaders(w)\n\t\t}\n\t\tencoder := pr.Dialect.Encoder()\n\t\tresults := flux.NewResultIteratorFromQuery(q)\n\t\tif h.Config.FluxLogEnabled {\n\t\t\tdefer func() {\n\t\t\t\tstats = results.Statistics()\n\t\t\t}()\n\t\t}\n\t\tdefer results.Release()\n\n\t\tn, err = encoder.Encode(w, results)\n\t\tif err != nil {\n\t\t\tif n == 0 {\n\t\t\t\t// If the encoder did not write anything, we can write an error header.\n\t\t\t\th.httpError(w, err.Error(), http.StatusInternalServerError)\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc (h *Handler) logFluxQuery(n int64, stats flux.Statistics, compiler flux.Compiler, err error) {\n\tvar q string\n\tswitch c := compiler.(type) {\n\tcase lang.SpecCompiler:\n\t\tq = fmt.Sprint(flux.Formatted(c.Spec))\n\tcase lang.FluxCompiler:\n\t\tq = c.Query\n\t}\n\n\th.Logger.Info(\"Executed Flux query\",\n\t\tzap.String(\"compiler_type\", string(compiler.CompilerType())),\n\t\tzap.Int64(\"response_size\", n),\n\t\tzap.String(\"query\", q),\n\t\tzap.Error(err),\n\t\tzap.Duration(\"stat_total_duration\", stats.TotalDuration),\n\t\tzap.Duration(\"stat_compile_duration\", stats.CompileDuration),\n\t\tzap.Duration(\"stat_queue_duration\", stats.QueueDuration),\n\t\tzap.Duration(\"stat_plan_duration\", stats.PlanDuration),\n\t\tzap.Duration(\"stat_requeue_duration\", stats.RequeueDuration),\n\t\tzap.Duration(\"stat_execute_duration\", stats.ExecuteDuration),\n\t\tzap.Int64(\"stat_max_allocated\", stats.MaxAllocated),\n\t\tzap.Int(\"stat_concurrency\", stats.Concurrency),\n\t)\n}\n\n// serveExpvar serves internal metrics in /debug/vars format over HTTP.\nfunc (h *Handler) serveExpvar(w http.ResponseWriter, r *http.Request) {\n\t// Retrieve statistics from the monitor.\n\tstats, err := h.Monitor.Statistics(nil)\n\tif err != nil {\n\t\th.httpError(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\t// Retrieve diagnostics from the monitor.\n\tdiags, err := h.Monitor.Diagnostics()\n\tif err != nil {\n\t\th.httpError(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\tw.Header().Set(\"Content-Type\", \"application/json; charset=utf-8\")\n\n\tfirst := true\n\tif val := diags[\"system\"]; val != nil {\n\t\tjv, err := parseSystemDiagnostics(val)\n\t\tif err != nil {\n\t\t\th.httpError(w, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\tdata, err := json.Marshal(jv)\n\t\tif err != nil {\n\t\t\th.httpError(w, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\tfirst = false\n\t\tfmt.Fprintln(w, \"{\")\n\t\tfmt.Fprintf(w, \"\\\"system\\\": %s\", data)\n\t} else {\n\t\tfmt.Fprintln(w, \"{\")\n\t}\n\n\tif val := expvar.Get(\"cmdline\"); val != nil {\n\t\tif !first {\n\t\t\tfmt.Fprintln(w, \",\")\n\t\t}\n\t\tfirst = false\n\t\tfmt.Fprintf(w, \"\\\"cmdline\\\": %s\", val)\n\t}\n\tif val := expvar.Get(\"memstats\"); val != nil {\n\t\tif !first {\n\t\t\tfmt.Fprintln(w, \",\")\n\t\t}\n\t\tfirst = false\n\t\tfmt.Fprintf(w, \"\\\"memstats\\\": %s\", val)\n\t}\n\n\tfor _, s := range stats {\n\t\tval, err := json.Marshal(s)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Very hackily create a unique key.\n\t\tbuf := bytes.NewBufferString(s.Name)\n\t\tif path, ok := s.Tags[\"path\"]; ok {\n\t\t\tfmt.Fprintf(buf, \":%s\", path)\n\t\t\tif id, ok := s.Tags[\"id\"]; ok {\n\t\t\t\tfmt.Fprintf(buf, \":%s\", id)\n\t\t\t}\n\t\t} else if bind, ok := s.Tags[\"bind\"]; ok {\n\t\t\tif proto, ok := s.Tags[\"proto\"]; ok {\n\t\t\t\tfmt.Fprintf(buf, \":%s\", proto)\n\t\t\t}\n\t\t\tfmt.Fprintf(buf, \":%s\", bind)\n\t\t} else if database, ok := s.Tags[\"database\"]; ok {\n\t\t\tfmt.Fprintf(buf, \":%s\", database)\n\t\t\tif rp, ok := s.Tags[\"retention_policy\"]; ok {\n\t\t\t\tfmt.Fprintf(buf, \":%s\", rp)\n\t\t\t\tif name, ok := s.Tags[\"name\"]; ok {\n\t\t\t\t\tfmt.Fprintf(buf, \":%s\", name)\n\t\t\t\t}\n\t\t\t\tif dest, ok := s.Tags[\"destination\"]; ok {\n\t\t\t\t\tfmt.Fprintf(buf, \":%s\", dest)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tkey := buf.String()\n\n\t\tif !first {\n\t\t\tfmt.Fprintln(w, \",\")\n\t\t}\n\t\tfirst = false\n\t\tfmt.Fprintf(w, \"%q: \", key)\n\t\tw.Write(bytes.TrimSpace(val))\n\t}\n\tfmt.Fprintln(w, \"\\n}\")\n}\n\n// serveDebugRequests will track requests for a period of time.\nfunc (h *Handler) serveDebugRequests(w http.ResponseWriter, r *http.Request) {\n\tvar d time.Duration\n\tif s := r.URL.Query().Get(\"seconds\"); s == \"\" {\n\t\td = DefaultDebugRequestsInterval\n\t} else if seconds, err := strconv.ParseInt(s, 10, 64); err != nil {\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t} else {\n\t\td = time.Duration(seconds) * time.Second\n\t\tif d > MaxDebugRequestsInterval {\n\t\t\th.httpError(w, fmt.Sprintf(\"exceeded maximum interval time: %s > %s\",\n\t\t\t\tinfluxql.FormatDuration(d),\n\t\t\t\tinfluxql.FormatDuration(MaxDebugRequestsInterval)),\n\t\t\t\thttp.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t}\n\n\tvar closing <-chan bool\n\tif notifier, ok := w.(http.CloseNotifier); ok {\n\t\tclosing = notifier.CloseNotify()\n\t}\n\n\tprofile := h.requestTracker.TrackRequests()\n\n\ttimer := time.NewTimer(d)\n\tselect {\n\tcase <-timer.C:\n\t\tprofile.Stop()\n\tcase <-closing:\n\t\t// Connection was closed early.\n\t\tprofile.Stop()\n\t\ttimer.Stop()\n\t\treturn\n\t}\n\n\tw.Header().Set(\"Content-Type\", \"application/json; charset=utf-8\")\n\tw.Header().Add(\"Connection\", \"close\")\n\n\tfmt.Fprintln(w, \"{\")\n\tfirst := true\n\tfor req, st := range profile.Requests {\n\t\tval, err := json.Marshal(st)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tif !first {\n\t\t\tfmt.Fprintln(w, \",\")\n\t\t}\n\t\tfirst = false\n\t\tfmt.Fprintf(w, \"%q: \", req.String())\n\t\tw.Write(bytes.TrimSpace(val))\n\t}\n\tfmt.Fprintln(w, \"\\n}\")\n}\n\n// parseSystemDiagnostics converts the system diagnostics into an appropriate\n// format for marshaling to JSON in the /debug/vars format.\nfunc parseSystemDiagnostics(d *diagnostics.Diagnostics) (map[string]interface{}, error) {\n\t// We don't need PID in this case.\n\tm := map[string]interface{}{\"currentTime\": nil, \"started\": nil, \"uptime\": nil}\n\tfor key := range m {\n\t\t// Find the associated column.\n\t\tci := -1\n\t\tfor i, col := range d.Columns {\n\t\t\tif col == key {\n\t\t\t\tci = i\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif ci == -1 {\n\t\t\treturn nil, fmt.Errorf(\"unable to find column %q\", key)\n\t\t}\n\n\t\tif len(d.Rows) < 1 || len(d.Rows[0]) <= ci {\n\t\t\treturn nil, fmt.Errorf(\"no data for column %q\", key)\n\t\t}\n\n\t\tvar res interface{}\n\t\tswitch v := d.Rows[0][ci].(type) {\n\t\tcase time.Time:\n\t\t\tres = v\n\t\tcase string:\n\t\t\t// Should be a string representation of a time.Duration\n\t\t\td, err := time.ParseDuration(v)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tres = int64(d.Seconds())\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"value for column %q is not parsable (got %T)\", key, v)\n\t\t}\n\t\tm[key] = res\n\t}\n\treturn m, nil\n}\n\n// httpError writes an error to the client in a standard format.\nfunc (h *Handler) httpError(w http.ResponseWriter, errmsg string, code int) {\n\tif code == http.StatusUnauthorized {\n\t\t// If an unauthorized header will be sent back, add a WWW-Authenticate header\n\t\t// as an authorization challenge.\n\t\tw.Header().Set(\"WWW-Authenticate\", fmt.Sprintf(\"Basic realm=\\\"%s\\\"\", h.Config.Realm))\n\t} else if code/100 != 2 {\n\t\tsz := math.Min(float64(len(errmsg)), 1024.0)\n\t\tw.Header().Set(\"X-InfluxDB-Error\", errmsg[:int(sz)])\n\t}\n\n\tresponse := Response{Err: errors.New(errmsg)}\n\tif rw, ok := w.(ResponseWriter); ok {\n\t\th.writeHeader(w, code)\n\t\trw.WriteResponse(response)\n\t\treturn\n\t}\n\n\t// Default implementation if the response writer hasn't been replaced\n\t// with our special response writer type.\n\tw.Header().Add(\"Content-Type\", \"application/json\")\n\th.writeHeader(w, code)\n\tb, _ := json.Marshal(response)\n\tw.Write(b)\n}\n\n// Filters and filter helpers\n\ntype credentials struct {\n\tMethod   AuthenticationMethod\n\tUsername string\n\tPassword string\n\tToken    string\n}\n\nfunc parseToken(token string) (user, pass string, ok bool) {\n\ts := strings.IndexByte(token, ':')\n\tif s < 0 {\n\t\treturn\n\t}\n\treturn token[:s], token[s+1:], true\n}\n\n// parseCredentials parses a request and returns the authentication credentials.\n// The credentials may be present as URL query params, or as a Basic\n// Authentication header.\n// As params: http://127.0.0.1/query?u=username&p=password\n// As basic auth: http://username:password@127.0.0.1\n// As Bearer token in Authorization header: Bearer <JWT_TOKEN_BLOB>\n// As Token in Authorization header: Token <username:password>\nfunc parseCredentials(r *http.Request) (*credentials, error) {\n\tq := r.URL.Query()\n\n\t// Check for username and password in URL params.\n\tif u, p := q.Get(\"u\"), q.Get(\"p\"); u != \"\" && p != \"\" {\n\t\treturn &credentials{\n\t\t\tMethod:   UserAuthentication,\n\t\t\tUsername: u,\n\t\t\tPassword: p,\n\t\t}, nil\n\t}\n\n\t// Check for the HTTP Authorization header.\n\tif s := r.Header.Get(\"Authorization\"); s != \"\" {\n\t\t// Check for Bearer token.\n\t\tstrs := strings.Split(s, \" \")\n\t\tif len(strs) == 2 {\n\t\t\tswitch strs[0] {\n\t\t\tcase \"Bearer\":\n\t\t\t\treturn &credentials{\n\t\t\t\t\tMethod: BearerAuthentication,\n\t\t\t\t\tToken:  strs[1],\n\t\t\t\t}, nil\n\t\t\tcase \"Token\":\n\t\t\t\tif u, p, ok := parseToken(strs[1]); ok {\n\t\t\t\t\treturn &credentials{\n\t\t\t\t\t\tMethod:   UserAuthentication,\n\t\t\t\t\t\tUsername: u,\n\t\t\t\t\t\tPassword: p,\n\t\t\t\t\t}, nil\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Check for basic auth.\n\t\tif u, p, ok := r.BasicAuth(); ok {\n\t\t\treturn &credentials{\n\t\t\t\tMethod:   UserAuthentication,\n\t\t\t\tUsername: u,\n\t\t\t\tPassword: p,\n\t\t\t}, nil\n\t\t}\n\t}\n\n\treturn nil, fmt.Errorf(\"unable to parse authentication credentials\")\n}\n\n// authenticate wraps a handler and ensures that if user credentials are passed in\n// an attempt is made to authenticate that user. If authentication fails, an error is returned.\n//\n// There is one exception: if there are no users in the system, authentication is not required. This\n// is to facilitate bootstrapping of a system with authentication enabled.\nfunc authenticate(inner func(http.ResponseWriter, *http.Request, meta.User), h *Handler, requireAuthentication bool) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t// Return early if we are not authenticating\n\t\tif !requireAuthentication {\n\t\t\tinner(w, r, nil)\n\t\t\treturn\n\t\t}\n\t\tvar user meta.User\n\n\t\t// TODO corylanou: never allow this in the future without users\n\t\tif requireAuthentication && h.MetaClient.AdminUserExists() {\n\t\t\tcreds, err := parseCredentials(r)\n\t\t\tif err != nil {\n\t\t\t\tatomic.AddInt64(&h.stats.AuthenticationFailures, 1)\n\t\t\t\th.httpError(w, err.Error(), http.StatusUnauthorized)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tswitch creds.Method {\n\t\t\tcase UserAuthentication:\n\t\t\t\tif creds.Username == \"\" {\n\t\t\t\t\tatomic.AddInt64(&h.stats.AuthenticationFailures, 1)\n\t\t\t\t\th.httpError(w, \"username required\", http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tuser, err = h.MetaClient.Authenticate(creds.Username, creds.Password)\n\t\t\t\tif err != nil {\n\t\t\t\t\tatomic.AddInt64(&h.stats.AuthenticationFailures, 1)\n\t\t\t\t\th.httpError(w, \"authorization failed\", http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\tcase BearerAuthentication:\n\t\t\t\tkeyLookupFn := func(token *jwt.Token) (interface{}, error) {\n\t\t\t\t\t// Check for expected signing method.\n\t\t\t\t\tif _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok {\n\t\t\t\t\t\treturn nil, fmt.Errorf(\"unexpected signing method: %v\", token.Header[\"alg\"])\n\t\t\t\t\t}\n\t\t\t\t\treturn []byte(h.Config.SharedSecret), nil\n\t\t\t\t}\n\n\t\t\t\t// Parse and validate the token.\n\t\t\t\ttoken, err := jwt.Parse(creds.Token, keyLookupFn)\n\t\t\t\tif err != nil {\n\t\t\t\t\th.httpError(w, err.Error(), http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t} else if !token.Valid {\n\t\t\t\t\th.httpError(w, \"invalid token\", http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tclaims, ok := token.Claims.(jwt.MapClaims)\n\t\t\t\tif !ok {\n\t\t\t\t\th.httpError(w, \"problem authenticating token\", http.StatusInternalServerError)\n\t\t\t\t\th.Logger.Info(\"Could not assert JWT token claims as jwt.MapClaims\")\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\t// Make sure an expiration was set on the token.\n\t\t\t\tif exp, ok := claims[\"exp\"].(float64); !ok || exp <= 0.0 {\n\t\t\t\t\th.httpError(w, \"token expiration required\", http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\t// Get the username from the token.\n\t\t\t\tusername, ok := claims[\"username\"].(string)\n\t\t\t\tif !ok {\n\t\t\t\t\th.httpError(w, \"username in token must be a string\", http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t} else if username == \"\" {\n\t\t\t\t\th.httpError(w, \"token must contain a username\", http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\t// Lookup user in the metastore.\n\t\t\t\tif user, err = h.MetaClient.User(username); err != nil {\n\t\t\t\t\th.httpError(w, err.Error(), http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t} else if user == nil {\n\t\t\t\t\th.httpError(w, meta.ErrUserNotFound.Error(), http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\th.httpError(w, \"unsupported authentication\", http.StatusUnauthorized)\n\t\t\t}\n\n\t\t}\n\t\tinner(w, r, user)\n\t})\n}\n\n// cors responds to incoming requests and adds the appropriate cors headers\n// TODO: corylanou: add the ability to configure this in our config\nfunc cors(inner http.Handler) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif origin := r.Header.Get(\"Origin\"); origin != \"\" {\n\t\t\tw.Header().Set(`Access-Control-Allow-Origin`, origin)\n\t\t\tw.Header().Set(`Access-Control-Allow-Methods`, strings.Join([]string{\n\t\t\t\t`DELETE`,\n\t\t\t\t`GET`,\n\t\t\t\t`OPTIONS`,\n\t\t\t\t`POST`,\n\t\t\t\t`PUT`,\n\t\t\t}, \", \"))\n\n\t\t\tw.Header().Set(`Access-Control-Allow-Headers`, strings.Join([]string{\n\t\t\t\t`Accept`,\n\t\t\t\t`Accept-Encoding`,\n\t\t\t\t`Authorization`,\n\t\t\t\t`Content-Length`,\n\t\t\t\t`Content-Type`,\n\t\t\t\t`X-CSRF-Token`,\n\t\t\t\t`X-HTTP-Method-Override`,\n\t\t\t}, \", \"))\n\n\t\t\tw.Header().Set(`Access-Control-Expose-Headers`, strings.Join([]string{\n\t\t\t\t`Date`,\n\t\t\t\t`X-InfluxDB-Version`,\n\t\t\t\t`X-InfluxDB-Build`,\n\t\t\t}, \", \"))\n\t\t}\n\n\t\tif r.Method == \"OPTIONS\" {\n\t\t\treturn\n\t\t}\n\n\t\tinner.ServeHTTP(w, r)\n\t})\n}\n\nfunc requestID(inner http.Handler) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t// X-Request-Id takes priority.\n\t\trid := r.Header.Get(\"X-Request-Id\")\n\n\t\t// If X-Request-Id is empty, then check Request-Id\n\t\tif rid == \"\" {\n\t\t\trid = r.Header.Get(\"Request-Id\")\n\t\t}\n\n\t\t// If Request-Id is empty then generate a v1 UUID.\n\t\tif rid == \"\" {\n\t\t\trid = uuid.TimeUUID().String()\n\t\t}\n\n\t\t// We read Request-Id in other handler code so we'll use that naming\n\t\t// convention from this point in the request cycle.\n\t\tr.Header.Set(\"Request-Id\", rid)\n\n\t\t// Set the request ID on the response headers.\n\t\t// X-Request-Id is the most common name for a request ID header.\n\t\tw.Header().Set(\"X-Request-Id\", rid)\n\n\t\t// We will also set Request-Id for backwards compatibility with previous\n\t\t// versions of InfluxDB.\n\t\tw.Header().Set(\"Request-Id\", rid)\n\n\t\tinner.ServeHTTP(w, r)\n\t})\n}\n\nfunc (h *Handler) logging(inner http.Handler, name string) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tl := &responseLogger{w: w}\n\t\tinner.ServeHTTP(l, r)\n\n\t\tif h.accessLogFilters.Match(l.Status()) {\n\t\t\th.CLFLogger.Println(buildLogLine(l, r, start))\n\t\t}\n\n\t\t// Log server errors.\n\t\tif l.Status()/100 == 5 {\n\t\t\terrStr := l.Header().Get(\"X-InfluxDB-Error\")\n\t\t\tif errStr != \"\" {\n\t\t\t\th.Logger.Error(fmt.Sprintf(\"[%d] - %q\", l.Status(), errStr))\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc (h *Handler) responseWriter(inner http.Handler) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw = NewResponseWriter(w, r)\n\t\tinner.ServeHTTP(w, r)\n\t})\n}\n\n// if the env var is set, and the value is truthy, then we will *not*\n// recover from a panic.\nvar willCrash bool\n\nfunc init() {\n\tvar err error\n\tif willCrash, err = strconv.ParseBool(os.Getenv(query.PanicCrashEnv)); err != nil {\n\t\twillCrash = false\n\t}\n}\n\nfunc (h *Handler) recovery(inner http.Handler, name string) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tl := &responseLogger{w: w}\n\n\t\tdefer func() {\n\t\t\tif err := recover(); err != nil {\n\t\t\t\tlogLine := buildLogLine(l, r, start)\n\t\t\t\tlogLine = fmt.Sprintf(\"%s [panic:%s] %s\", logLine, err, debug.Stack())\n\t\t\t\th.CLFLogger.Println(logLine)\n\t\t\t\thttp.Error(w, http.StatusText(http.StatusInternalServerError), 500)\n\t\t\t\tatomic.AddInt64(&h.stats.RecoveredPanics, 1) // Capture the panic in _internal stats.\n\n\t\t\t\tif willCrash {\n\t\t\t\t\th.CLFLogger.Println(\"\\n\\n=====\\nAll goroutines now follow:\")\n\t\t\t\t\tbuf := debug.Stack()\n\t\t\t\t\th.CLFLogger.Printf(\"%s\\n\", buf)\n\t\t\t\t\tos.Exit(1) // If we panic then the Go server will recover.\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\tinner.ServeHTTP(l, r)\n\t})\n}\n\n// Store describes the behaviour of the storage packages Store type.\ntype Store interface {\n\tRead(ctx context.Context, req *datatypes.ReadRequest) (reads.ResultSet, error)\n}\n\n// Response represents a list of statement results.\ntype Response struct {\n\tResults []*query.Result\n\tErr     error\n}\n\n// MarshalJSON encodes a Response struct into JSON.\nfunc (r Response) MarshalJSON() ([]byte, error) {\n\t// Define a struct that outputs \"error\" as a string.\n\tvar o struct {\n\t\tResults []*query.Result `json:\"results,omitempty\"`\n\t\tErr     string          `json:\"error,omitempty\"`\n\t}\n\n\t// Copy fields to output struct.\n\to.Results = r.Results\n\tif r.Err != nil {\n\t\to.Err = r.Err.Error()\n\t}\n\n\treturn json.Marshal(&o)\n}\n\n// UnmarshalJSON decodes the data into the Response struct.\nfunc (r *Response) UnmarshalJSON(b []byte) error {\n\tvar o struct {\n\t\tResults []*query.Result `json:\"results,omitempty\"`\n\t\tErr     string          `json:\"error,omitempty\"`\n\t}\n\n\terr := json.Unmarshal(b, &o)\n\tif err != nil {\n\t\treturn err\n\t}\n\tr.Results = o.Results\n\tif o.Err != \"\" {\n\t\tr.Err = errors.New(o.Err)\n\t}\n\treturn nil\n}\n\n// Error returns the first error from any statement.\n// Returns nil if no errors occurred on any statements.\nfunc (r *Response) Error() error {\n\tif r.Err != nil {\n\t\treturn r.Err\n\t}\n\tfor _, rr := range r.Results {\n\t\tif rr.Err != nil {\n\t\t\treturn rr.Err\n\t\t}\n\t}\n\treturn nil\n}\n\n// Throttler represents an HTTP throttler that limits the number of concurrent\n// requests being processed as well as the number of enqueued requests.\ntype Throttler struct {\n\tcurrent  chan struct{}\n\tenqueued chan struct{}\n\n\t// Maximum amount of time requests can wait in queue.\n\t// Must be set before adding middleware.\n\tEnqueueTimeout time.Duration\n\n\tLogger *zap.Logger\n}\n\n// NewThrottler returns a new instance of Throttler that limits to concurrentN.\n// requests processed at a time and maxEnqueueN requests waiting to be processed.\nfunc NewThrottler(concurrentN, maxEnqueueN int) *Throttler {\n\treturn &Throttler{\n\t\tcurrent:  make(chan struct{}, concurrentN),\n\t\tenqueued: make(chan struct{}, concurrentN+maxEnqueueN),\n\t\tLogger:   zap.NewNop(),\n\t}\n}\n\n// Handler wraps h in a middleware handler that throttles requests.\nfunc (t *Throttler) Handler(h http.Handler) http.Handler {\n\ttimeout := t.EnqueueTimeout\n\n\t// Return original handler if concurrent requests is zero.\n\tif cap(t.current) == 0 {\n\t\treturn h\n\t}\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t// Start a timer to limit enqueued request times.\n\t\tvar timerCh <-chan time.Time\n\t\tif timeout > 0 {\n\t\t\ttimer := time.NewTimer(timeout)\n\t\t\tdefer timer.Stop()\n\t\t\ttimerCh = timer.C\n\t\t}\n\n\t\t// Wait for a spot in the queue.\n\t\tif cap(t.enqueued) > cap(t.current) {\n\t\t\tselect {\n\t\t\tcase t.enqueued <- struct{}{}:\n\t\t\t\tdefer func() { <-t.enqueued }()\n\t\t\tdefault:\n\t\t\t\tt.Logger.Warn(\"request throttled, queue full\", zap.Duration(\"d\", timeout))\n\t\t\t\thttp.Error(w, \"request throttled, queue full\", http.StatusServiceUnavailable)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\t// First check if we can immediately send in to current because there is\n\t\t// available capacity. This helps reduce racyness in tests.\n\t\tselect {\n\t\tcase t.current <- struct{}{}:\n\t\tdefault:\n\t\t\t// Wait for a spot in the list of concurrent requests, but allow checking the timeout.\n\t\t\tselect {\n\t\t\tcase t.current <- struct{}{}:\n\t\t\tcase <-timerCh:\n\t\t\t\tt.Logger.Warn(\"request throttled, exceeds timeout\", zap.Duration(\"d\", timeout))\n\t\t\t\thttp.Error(w, \"request throttled, exceeds timeout\", http.StatusServiceUnavailable)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tdefer func() { <-t.current }()\n\n\t\t// Execute request.\n\t\th.ServeHTTP(w, r)\n\t})\n}\n", "package httpd_test\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"math\"\n\t\"mime/multipart\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"net/url\"\n\t\"os\"\n\t\"reflect\"\n\t\"strings\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/dgrijalva/jwt-go\"\n\t\"github.com/gogo/protobuf/proto\"\n\t\"github.com/golang/snappy\"\n\t\"github.com/google/go-cmp/cmp\"\n\t\"github.com/influxdata/flux\"\n\t\"github.com/influxdata/flux/lang\"\n\t\"github.com/influxdata/influxdb/flux/client\"\n\t\"github.com/influxdata/influxdb/internal\"\n\t\"github.com/influxdata/influxdb/logger\"\n\t\"github.com/influxdata/influxdb/models\"\n\t\"github.com/influxdata/influxdb/prometheus/remote\"\n\t\"github.com/influxdata/influxdb/query\"\n\t\"github.com/influxdata/influxdb/services/httpd\"\n\t\"github.com/influxdata/influxdb/services/meta\"\n\t\"github.com/influxdata/influxdb/tsdb\"\n\t\"github.com/influxdata/influxql\"\n)\n\n// Ensure the handler returns results from a query (including nil results).\nfunc TestHandler_Query(t *testing.T) {\n\th := NewHandler(false)\n\th.StatementExecutor.ExecuteStatementFn = func(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\t\tif stmt.String() != `SELECT * FROM bar` {\n\t\t\tt.Fatalf(\"unexpected query: %s\", stmt.String())\n\t\t} else if ctx.Database != `foo` {\n\t\t\tt.Fatalf(\"unexpected db: %s\", ctx.Database)\n\t\t}\n\t\tctx.Results <- &query.Result{StatementID: 1, Series: models.Rows([]*models.Row{{Name: \"series0\"}})}\n\t\tctx.Results <- &query.Result{StatementID: 2, Series: models.Rows([]*models.Row{{Name: \"series1\"}})}\n\t\treturn nil\n\t}\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewJSONRequest(\"GET\", \"/query?db=foo&q=SELECT+*+FROM+bar\", nil))\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"results\":[{\"statement_id\":1,\"series\":[{\"name\":\"series0\"}]},{\"statement_id\":2,\"series\":[{\"name\":\"series1\"}]}]}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n}\n\n// Ensure the handler returns results from a query passed as a file.\nfunc TestHandler_Query_File(t *testing.T) {\n\th := NewHandler(false)\n\th.StatementExecutor.ExecuteStatementFn = func(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\t\tif stmt.String() != `SELECT * FROM bar` {\n\t\t\tt.Fatalf(\"unexpected query: %s\", stmt.String())\n\t\t} else if ctx.Database != `foo` {\n\t\t\tt.Fatalf(\"unexpected db: %s\", ctx.Database)\n\t\t}\n\t\tctx.Results <- &query.Result{StatementID: 1, Series: models.Rows([]*models.Row{{Name: \"series0\"}})}\n\t\tctx.Results <- &query.Result{StatementID: 2, Series: models.Rows([]*models.Row{{Name: \"series1\"}})}\n\t\treturn nil\n\t}\n\n\tvar body bytes.Buffer\n\twriter := multipart.NewWriter(&body)\n\tpart, err := writer.CreateFormFile(\"q\", \"\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tio.WriteString(part, \"SELECT * FROM bar\")\n\n\tif err := writer.Close(); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tr := MustNewJSONRequest(\"POST\", \"/query?db=foo\", &body)\n\tr.Header.Set(\"Content-Type\", writer.FormDataContentType())\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"results\":[{\"statement_id\":1,\"series\":[{\"name\":\"series0\"}]},{\"statement_id\":2,\"series\":[{\"name\":\"series1\"}]}]}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n}\n\n// Test query with user authentication.\nfunc TestHandler_Query_Auth(t *testing.T) {\n\t// Create the handler to be tested.\n\th := NewHandler(true)\n\n\t// Set mock meta client functions for the handler to use.\n\th.MetaClient.AdminUserExistsFn = func() bool { return true }\n\n\th.MetaClient.UserFn = func(username string) (meta.User, error) {\n\t\tif username != \"user1\" {\n\t\t\treturn nil, meta.ErrUserNotFound\n\t\t}\n\t\treturn &meta.UserInfo{\n\t\t\tName:  \"user1\",\n\t\t\tHash:  \"abcd\",\n\t\t\tAdmin: true,\n\t\t}, nil\n\t}\n\n\th.MetaClient.AuthenticateFn = func(u, p string) (meta.User, error) {\n\t\tif u != \"user1\" {\n\t\t\treturn nil, fmt.Errorf(\"unexpected user: exp: user1, got: %s\", u)\n\t\t} else if p != \"abcd\" {\n\t\t\treturn nil, fmt.Errorf(\"unexpected password: exp: abcd, got: %s\", p)\n\t\t}\n\t\treturn h.MetaClient.User(u)\n\t}\n\n\t// Set mock query authorizer for handler to use.\n\th.QueryAuthorizer.AuthorizeQueryFn = func(u meta.User, query *influxql.Query, database string) error {\n\t\treturn nil\n\t}\n\n\t// Set mock statement executor for handler to use.\n\th.StatementExecutor.ExecuteStatementFn = func(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\t\tif stmt.String() != `SELECT * FROM bar` {\n\t\t\tt.Fatalf(\"unexpected query: %s\", stmt.String())\n\t\t} else if ctx.Database != `foo` {\n\t\t\tt.Fatalf(\"unexpected db: %s\", ctx.Database)\n\t\t}\n\t\tctx.Results <- &query.Result{StatementID: 1, Series: models.Rows([]*models.Row{{Name: \"series0\"}})}\n\t\tctx.Results <- &query.Result{StatementID: 2, Series: models.Rows([]*models.Row{{Name: \"series1\"}})}\n\t\treturn nil\n\t}\n\n\t// Test the handler with valid user and password in the URL parameters.\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewJSONRequest(\"GET\", \"/query?u=user1&p=abcd&db=foo&q=SELECT+*+FROM+bar\", nil))\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d: %s\", w.Code, w.Body.String())\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"results\":[{\"statement_id\":1,\"series\":[{\"name\":\"series0\"}]},{\"statement_id\":2,\"series\":[{\"name\":\"series1\"}]}]}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n\n\t// Test the handler with valid user and password using basic auth.\n\tw = httptest.NewRecorder()\n\tr := MustNewJSONRequest(\"GET\", \"/query?db=foo&q=SELECT+*+FROM+bar\", nil)\n\tr.SetBasicAuth(\"user1\", \"abcd\")\n\th.ServeHTTP(w, r)\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d: %s\", w.Code, w.Body.String())\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"results\":[{\"statement_id\":1,\"series\":[{\"name\":\"series0\"}]},{\"statement_id\":2,\"series\":[{\"name\":\"series1\"}]}]}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n\n\t// Test the handler with valid JWT bearer token.\n\treq := MustNewJSONRequest(\"GET\", \"/query?db=foo&q=SELECT+*+FROM+bar\", nil)\n\t// Create a signed JWT token string and add it to the request header.\n\t_, signedToken := MustJWTToken(\"user1\", h.Config.SharedSecret, false)\n\treq.Header.Set(\"Authorization\", fmt.Sprintf(\"Bearer %s\", signedToken))\n\n\tw = httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d: %s\", w.Code, w.Body.String())\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"results\":[{\"statement_id\":1,\"series\":[{\"name\":\"series0\"}]},{\"statement_id\":2,\"series\":[{\"name\":\"series1\"}]}]}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n\n\t// Test the handler with JWT token signed with invalid key.\n\treq = MustNewJSONRequest(\"GET\", \"/query?db=foo&q=SELECT+*+FROM+bar\", nil)\n\t// Create a signed JWT token string and add it to the request header.\n\t_, signedToken = MustJWTToken(\"user1\", \"invalid key\", false)\n\treq.Header.Set(\"Authorization\", fmt.Sprintf(\"Bearer %s\", signedToken))\n\n\tw = httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Code != http.StatusUnauthorized {\n\t\tt.Fatalf(\"unexpected status: %d: %s\", w.Code, w.Body.String())\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"error\":\"signature is invalid\"}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n\n\t// Test handler with valid JWT token carrying non-existant user.\n\t_, signedToken = MustJWTToken(\"bad_user\", h.Config.SharedSecret, false)\n\treq.Header.Set(\"Authorization\", fmt.Sprintf(\"Bearer %s\", signedToken))\n\n\tw = httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Code != http.StatusUnauthorized {\n\t\tt.Fatalf(\"unexpected status: %d: %s\", w.Code, w.Body.String())\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"error\":\"user not found\"}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n\n\t// Test handler with expired JWT token.\n\t_, signedToken = MustJWTToken(\"user1\", h.Config.SharedSecret, true)\n\treq.Header.Set(\"Authorization\", fmt.Sprintf(\"Bearer %s\", signedToken))\n\n\tw = httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Code != http.StatusUnauthorized {\n\t\tt.Fatalf(\"unexpected status: %d: %s\", w.Code, w.Body.String())\n\t} else if !strings.Contains(w.Body.String(), `{\"error\":\"Token is expired`) {\n\t\tt.Fatalf(\"unexpected body: %s\", w.Body.String())\n\t}\n\n\t// Test handler with JWT token that has no expiration set.\n\ttoken, _ := MustJWTToken(\"user1\", h.Config.SharedSecret, false)\n\tdelete(token.Claims.(jwt.MapClaims), \"exp\")\n\tsignedToken, err := token.SignedString([]byte(h.Config.SharedSecret))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\treq.Header.Set(\"Authorization\", fmt.Sprintf(\"Bearer %s\", signedToken))\n\tw = httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Code != http.StatusUnauthorized {\n\t\tt.Fatalf(\"unexpected status: %d: %s\", w.Code, w.Body.String())\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"error\":\"token expiration required\"}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n\n\t// Test the handler with valid user and password in the url and invalid in\n\t// basic auth (prioritize url).\n\tw = httptest.NewRecorder()\n\tr = MustNewJSONRequest(\"GET\", \"/query?u=user1&p=abcd&db=foo&q=SELECT+*+FROM+bar\", nil)\n\tr.SetBasicAuth(\"user1\", \"efgh\")\n\th.ServeHTTP(w, r)\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d: %s\", w.Code, w.Body.String())\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"results\":[{\"statement_id\":1,\"series\":[{\"name\":\"series0\"}]},{\"statement_id\":2,\"series\":[{\"name\":\"series1\"}]}]}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n}\n\n// Ensure the handler returns results from a query (including nil results).\nfunc TestHandler_QueryRegex(t *testing.T) {\n\th := NewHandler(false)\n\th.StatementExecutor.ExecuteStatementFn = func(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\t\tif stmt.String() != `SELECT * FROM test WHERE url =~ /http\\:\\/\\/www.akamai\\.com/` {\n\t\t\tt.Fatalf(\"unexpected query: %s\", stmt.String())\n\t\t} else if ctx.Database != `test` {\n\t\t\tt.Fatalf(\"unexpected db: %s\", ctx.Database)\n\t\t}\n\t\tctx.Results <- nil\n\t\treturn nil\n\t}\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewRequest(\"GET\", \"/query?db=test&q=SELECT%20%2A%20FROM%20test%20WHERE%20url%20%3D~%20%2Fhttp%5C%3A%5C%2F%5C%2Fwww.akamai%5C.com%2F\", nil))\n}\n\n// Ensure the handler merges results from the same statement.\nfunc TestHandler_Query_MergeResults(t *testing.T) {\n\th := NewHandler(false)\n\th.StatementExecutor.ExecuteStatementFn = func(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\t\tctx.Results <- &query.Result{StatementID: 1, Series: models.Rows([]*models.Row{{Name: \"series0\"}})}\n\t\tctx.Results <- &query.Result{StatementID: 1, Series: models.Rows([]*models.Row{{Name: \"series1\"}})}\n\t\treturn nil\n\t}\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewJSONRequest(\"GET\", \"/query?db=foo&q=SELECT+*+FROM+bar\", nil))\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"results\":[{\"statement_id\":1,\"series\":[{\"name\":\"series0\"},{\"name\":\"series1\"}]}]}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n}\n\n// Ensure the handler merges results from the same statement.\nfunc TestHandler_Query_MergeEmptyResults(t *testing.T) {\n\th := NewHandler(false)\n\th.StatementExecutor.ExecuteStatementFn = func(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\t\tctx.Results <- &query.Result{StatementID: 1, Series: models.Rows{}}\n\t\tctx.Results <- &query.Result{StatementID: 1, Series: models.Rows([]*models.Row{{Name: \"series1\"}})}\n\t\treturn nil\n\t}\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewJSONRequest(\"GET\", \"/query?db=foo&q=SELECT+*+FROM+bar\", nil))\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"results\":[{\"statement_id\":1,\"series\":[{\"name\":\"series1\"}]}]}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n}\n\n// Ensure the handler can parse chunked and chunk size query parameters.\nfunc TestHandler_Query_Chunked(t *testing.T) {\n\th := NewHandler(false)\n\th.StatementExecutor.ExecuteStatementFn = func(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\t\tif ctx.ChunkSize != 2 {\n\t\t\tt.Fatalf(\"unexpected chunk size: %d\", ctx.ChunkSize)\n\t\t}\n\t\tctx.Results <- &query.Result{StatementID: 1, Series: models.Rows([]*models.Row{{Name: \"series0\"}})}\n\t\tctx.Results <- &query.Result{StatementID: 1, Series: models.Rows([]*models.Row{{Name: \"series1\"}})}\n\t\treturn nil\n\t}\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewJSONRequest(\"GET\", \"/query?db=foo&q=SELECT+*+FROM+bar&chunked=true&chunk_size=2\", nil))\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t} else if w.Body.String() != `{\"results\":[{\"statement_id\":1,\"series\":[{\"name\":\"series0\"}]}]}\n{\"results\":[{\"statement_id\":1,\"series\":[{\"name\":\"series1\"}]}]}\n` {\n\t\tt.Fatalf(\"unexpected body: %s\", w.Body.String())\n\t}\n}\n\n// Ensure the handler can accept an async query.\nfunc TestHandler_Query_Async(t *testing.T) {\n\tdone := make(chan struct{})\n\th := NewHandler(false)\n\th.StatementExecutor.ExecuteStatementFn = func(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\t\tif stmt.String() != `SELECT * FROM bar` {\n\t\t\tt.Fatalf(\"unexpected query: %s\", stmt.String())\n\t\t} else if ctx.Database != `foo` {\n\t\t\tt.Fatalf(\"unexpected db: %s\", ctx.Database)\n\t\t}\n\t\tctx.Results <- &query.Result{StatementID: 1, Series: models.Rows([]*models.Row{{Name: \"series0\"}})}\n\t\tctx.Results <- &query.Result{StatementID: 2, Series: models.Rows([]*models.Row{{Name: \"series1\"}})}\n\t\tclose(done)\n\t\treturn nil\n\t}\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewJSONRequest(\"GET\", \"/query?db=foo&q=SELECT+*+FROM+bar&async=true\", nil))\n\tif w.Code != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n\n\t// Wait to make sure the async query runs and completes.\n\ttimer := time.NewTimer(100 * time.Millisecond)\n\tdefer timer.Stop()\n\n\tselect {\n\tcase <-timer.C:\n\t\tt.Fatal(\"timeout while waiting for async query to complete\")\n\tcase <-done:\n\t}\n}\n\n// Ensure the handler returns a status 400 if the query is not passed in.\nfunc TestHandler_Query_ErrQueryRequired(t *testing.T) {\n\th := NewHandler(false)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewJSONRequest(\"GET\", \"/query\", nil))\n\tif w.Code != http.StatusBadRequest {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"error\":\"missing required parameter \\\"q\\\"\"}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n}\n\n// Ensure the handler returns a status 400 if the query cannot be parsed.\nfunc TestHandler_Query_ErrInvalidQuery(t *testing.T) {\n\th := NewHandler(false)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewJSONRequest(\"GET\", \"/query?q=SELECT\", nil))\n\tif w.Code != http.StatusBadRequest {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"error\":\"error parsing query: found EOF, expected identifier, string, number, bool at line 1, char 8\"}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n}\n\n// Ensure the handler returns an appropriate 401 or 403 status when authentication or authorization fails.\nfunc TestHandler_Query_ErrAuthorize(t *testing.T) {\n\th := NewHandler(true)\n\th.QueryAuthorizer.AuthorizeQueryFn = func(u meta.User, q *influxql.Query, db string) error {\n\t\treturn errors.New(\"marker\")\n\t}\n\th.MetaClient.AdminUserExistsFn = func() bool { return true }\n\th.MetaClient.AuthenticateFn = func(u, p string) (meta.User, error) {\n\n\t\tusers := []meta.UserInfo{\n\t\t\t{\n\t\t\t\tName:  \"admin\",\n\t\t\t\tHash:  \"admin\",\n\t\t\t\tAdmin: true,\n\t\t\t},\n\t\t\t{\n\t\t\t\tName: \"user1\",\n\t\t\t\tHash: \"abcd\",\n\t\t\t\tPrivileges: map[string]influxql.Privilege{\n\t\t\t\t\t\"db0\": influxql.ReadPrivilege,\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\n\t\tfor _, user := range users {\n\t\t\tif u == user.Name {\n\t\t\t\tif p == user.Hash {\n\t\t\t\t\treturn &user, nil\n\t\t\t\t}\n\t\t\t\treturn nil, meta.ErrAuthenticate\n\t\t\t}\n\t\t}\n\t\treturn nil, meta.ErrUserNotFound\n\t}\n\n\tfor i, tt := range []struct {\n\t\tuser     string\n\t\tpassword string\n\t\tquery    string\n\t\tcode     int\n\t}{\n\t\t{\n\t\t\tquery: \"/query?q=SHOW+DATABASES\",\n\t\t\tcode:  http.StatusUnauthorized,\n\t\t},\n\t\t{\n\t\t\tuser:     \"user1\",\n\t\t\tpassword: \"abcd\",\n\t\t\tquery:    \"/query?q=SHOW+DATABASES\",\n\t\t\tcode:     http.StatusForbidden,\n\t\t},\n\t\t{\n\t\t\tuser:     \"user2\",\n\t\t\tpassword: \"abcd\",\n\t\t\tquery:    \"/query?q=SHOW+DATABASES\",\n\t\t\tcode:     http.StatusUnauthorized,\n\t\t},\n\t} {\n\t\tw := httptest.NewRecorder()\n\t\tr := MustNewJSONRequest(\"GET\", tt.query, nil)\n\t\tparams := r.URL.Query()\n\t\tif tt.user != \"\" {\n\t\t\tparams.Set(\"u\", tt.user)\n\t\t}\n\t\tif tt.password != \"\" {\n\t\t\tparams.Set(\"p\", tt.password)\n\t\t}\n\t\tr.URL.RawQuery = params.Encode()\n\n\t\th.ServeHTTP(w, r)\n\t\tif w.Code != tt.code {\n\t\t\tt.Errorf(\"%d. unexpected status: got=%d exp=%d\\noutput: %s\", i, w.Code, tt.code, w.Body.String())\n\t\t}\n\t}\n}\n\n// Ensure the handler returns a status 200 if an error is returned in the result.\nfunc TestHandler_Query_ErrResult(t *testing.T) {\n\th := NewHandler(false)\n\th.StatementExecutor.ExecuteStatementFn = func(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\t\treturn errors.New(\"measurement not found\")\n\t}\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewJSONRequest(\"GET\", \"/query?db=foo&q=SHOW+SERIES+from+bin\", nil))\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"results\":[{\"statement_id\":0,\"error\":\"measurement not found\"}]}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n}\n\n// Ensure that closing the HTTP connection causes the query to be interrupted.\nfunc TestHandler_Query_CloseNotify(t *testing.T) {\n\t// Avoid leaking a goroutine when this fails.\n\tdone := make(chan struct{})\n\tdefer close(done)\n\n\tinterrupted := make(chan struct{})\n\th := NewHandler(false)\n\th.StatementExecutor.ExecuteStatementFn = func(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\tcase <-done:\n\t\t}\n\t\tclose(interrupted)\n\t\treturn nil\n\t}\n\n\ts := httptest.NewServer(h)\n\tdefer s.Close()\n\n\t// Parse the URL and generate a query request.\n\tu, err := url.Parse(s.URL)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tu.Path = \"/query\"\n\n\tvalues := url.Values{}\n\tvalues.Set(\"q\", \"SELECT * FROM cpu\")\n\tvalues.Set(\"db\", \"db0\")\n\tvalues.Set(\"rp\", \"rp0\")\n\tvalues.Set(\"chunked\", \"true\")\n\tu.RawQuery = values.Encode()\n\n\treq, err := http.NewRequest(\"GET\", u.String(), nil)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// Perform the request and retrieve the response.\n\tresp, err := http.DefaultClient.Do(req)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// Validate that the interrupted channel has NOT been closed yet.\n\ttimer := time.NewTimer(100 * time.Millisecond)\n\tselect {\n\tcase <-interrupted:\n\t\ttimer.Stop()\n\t\tt.Fatal(\"query interrupted unexpectedly\")\n\tcase <-timer.C:\n\t}\n\n\t// Close the response body which should abort the query in the handler.\n\tresp.Body.Close()\n\n\t// The query should abort within 100 milliseconds.\n\ttimer.Reset(100 * time.Millisecond)\n\tselect {\n\tcase <-interrupted:\n\t\ttimer.Stop()\n\tcase <-timer.C:\n\t\tt.Fatal(\"timeout while waiting for query to abort\")\n\t}\n}\n\n// Ensure the prometheus remote write works\nfunc TestHandler_PromWrite(t *testing.T) {\n\treq := &remote.WriteRequest{\n\t\tTimeseries: []*remote.TimeSeries{\n\t\t\t{\n\t\t\t\tLabels: []*remote.LabelPair{\n\t\t\t\t\t{Name: \"host\", Value: \"a\"},\n\t\t\t\t\t{Name: \"region\", Value: \"west\"},\n\t\t\t\t},\n\t\t\t\tSamples: []*remote.Sample{\n\t\t\t\t\t{TimestampMs: 1, Value: 1.2},\n\t\t\t\t\t{TimestampMs: 2, Value: math.NaN()},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tdata, err := proto.Marshal(req)\n\tif err != nil {\n\t\tt.Fatal(\"couldn't marshal prometheus request\")\n\t}\n\tcompressed := snappy.Encode(nil, data)\n\n\tb := bytes.NewReader(compressed)\n\th := NewHandler(false)\n\th.MetaClient.DatabaseFn = func(name string) *meta.DatabaseInfo {\n\t\treturn &meta.DatabaseInfo{}\n\t}\n\tcalled := false\n\th.PointsWriter.WritePointsFn = func(db, rp string, _ models.ConsistencyLevel, _ meta.User, points []models.Point) error {\n\t\tcalled = true\n\t\tpoint := points[0]\n\t\tif point.UnixNano() != int64(time.Millisecond) {\n\t\t\tt.Fatalf(\"Exp point time %d but got %d\", int64(time.Millisecond), point.UnixNano())\n\t\t}\n\t\ttags := point.Tags()\n\t\texpectedTags := models.Tags{models.Tag{Key: []byte(\"host\"), Value: []byte(\"a\")}, models.Tag{Key: []byte(\"region\"), Value: []byte(\"west\")}}\n\t\tif !reflect.DeepEqual(tags, expectedTags) {\n\t\t\tt.Fatalf(\"tags don't match\\n\\texp: %v\\n\\tgot: %v\", expectedTags, tags)\n\t\t}\n\n\t\tfields, err := point.Fields()\n\t\tif err != nil {\n\t\t\tt.Fatal(err.Error())\n\t\t}\n\t\texpFields := models.Fields{\"value\": 1.2}\n\t\tif !reflect.DeepEqual(fields, expFields) {\n\t\t\tt.Fatalf(\"fields don't match\\n\\texp: %v\\n\\tgot: %v\", expFields, fields)\n\t\t}\n\t\treturn nil\n\t}\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewRequest(\"POST\", \"/api/v1/prom/write?db=foo\", b))\n\tif !called {\n\t\tt.Fatal(\"WritePoints: expected call\")\n\t}\n\tif w.Code != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n}\n\n// Ensure Prometheus remote read requests are converted to the correct InfluxQL query and\n// data is returned\nfunc TestHandler_PromRead(t *testing.T) {\n\treq := &remote.ReadRequest{\n\t\tQueries: []*remote.Query{{\n\t\t\tMatchers: []*remote.LabelMatcher{\n\t\t\t\t{\n\t\t\t\t\tType:  remote.MatchType_EQUAL,\n\t\t\t\t\tName:  \"__name__\",\n\t\t\t\t\tValue: \"value\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tStartTimestampMs: 1,\n\t\t\tEndTimestampMs:   2,\n\t\t}},\n\t}\n\tdata, err := proto.Marshal(req)\n\tif err != nil {\n\t\tt.Fatal(\"couldn't marshal prometheus request\")\n\t}\n\tcompressed := snappy.Encode(nil, data)\n\tb := bytes.NewReader(compressed)\n\th := NewHandler(false)\n\tw := httptest.NewRecorder()\n\n\t// Number of results in the result set\n\tvar i int64\n\th.Store.ResultSet.NextFn = func() bool {\n\t\ti++\n\t\treturn i <= 2\n\t}\n\n\t// data for each cursor.\n\th.Store.ResultSet.CursorFn = func() tsdb.Cursor {\n\t\tcursor := internal.NewFloatArrayCursorMock()\n\n\t\tvar i int64\n\t\tcursor.NextFn = func() *tsdb.FloatArray {\n\t\t\ti++\n\t\t\tts := []int64{22000000 * i, 10000000000 * i}\n\t\t\tvs := []float64{2.3, 2992.33}\n\t\t\tif i > 2 {\n\t\t\t\tts, vs = nil, nil\n\t\t\t}\n\t\t\treturn &tsdb.FloatArray{Timestamps: ts, Values: vs}\n\t\t}\n\n\t\treturn cursor\n\t}\n\n\t// Tags for each cursor.\n\th.Store.ResultSet.TagsFn = func() models.Tags {\n\t\treturn models.NewTags(map[string]string{\n\t\t\t\"host\":         fmt.Sprintf(\"server-%d\", i),\n\t\t\t\"_measurement\": \"mem\",\n\t\t})\n\t}\n\n\th.ServeHTTP(w, MustNewRequest(\"POST\", \"/api/v1/prom/read?db=foo&rp=bar\", b))\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n\n\treqBuf, err := snappy.Decode(nil, w.Body.Bytes())\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvar resp remote.ReadResponse\n\tif err := proto.Unmarshal(reqBuf, &resp); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\texpResults := []*remote.QueryResult{\n\t\t{\n\t\t\tTimeseries: []*remote.TimeSeries{\n\t\t\t\t{\n\t\t\t\t\tLabels: []*remote.LabelPair{\n\t\t\t\t\t\t{Name: \"host\", Value: \"server-1\"},\n\t\t\t\t\t},\n\t\t\t\t\tSamples: []*remote.Sample{\n\t\t\t\t\t\t{TimestampMs: 22, Value: 2.3},\n\t\t\t\t\t\t{TimestampMs: 10000, Value: 2992.33},\n\t\t\t\t\t\t{TimestampMs: 44, Value: 2.3},\n\t\t\t\t\t\t{TimestampMs: 20000, Value: 2992.33},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tLabels: []*remote.LabelPair{\n\t\t\t\t\t\t{Name: \"host\", Value: \"server-2\"},\n\t\t\t\t\t},\n\t\t\t\t\tSamples: []*remote.Sample{\n\t\t\t\t\t\t{TimestampMs: 22, Value: 2.3},\n\t\t\t\t\t\t{TimestampMs: 10000, Value: 2992.33},\n\t\t\t\t\t\t{TimestampMs: 44, Value: 2.3},\n\t\t\t\t\t\t{TimestampMs: 20000, Value: 2992.33},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tif !reflect.DeepEqual(resp.Results, expResults) {\n\t\tt.Fatalf(\"Results differ:\\n%v\", cmp.Diff(resp.Results, expResults))\n\t}\n}\n\nfunc TestHandler_PromRead_NoResults(t *testing.T) {\n\treq := &remote.ReadRequest{Queries: []*remote.Query{&remote.Query{\n\t\tMatchers: []*remote.LabelMatcher{\n\t\t\t{\n\t\t\t\tType:  remote.MatchType_EQUAL,\n\t\t\t\tName:  \"__name__\",\n\t\t\t\tValue: \"value\",\n\t\t\t},\n\t\t},\n\t\tStartTimestampMs: 0,\n\t\tEndTimestampMs:   models.MaxNanoTime / int64(time.Millisecond),\n\t}}}\n\tdata, err := proto.Marshal(req)\n\tif err != nil {\n\t\tt.Fatal(\"couldn't marshal prometheus request\")\n\t}\n\tcompressed := snappy.Encode(nil, data)\n\th := NewHandler(false)\n\tw := httptest.NewRecorder()\n\n\tb := bytes.NewReader(compressed)\n\th.ServeHTTP(w, MustNewJSONRequest(\"POST\", \"/api/v1/prom/read?db=foo\", b))\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n\treqBuf, err := snappy.Decode(nil, w.Body.Bytes())\n\tif err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n\n\tvar resp remote.ReadResponse\n\tif err := proto.Unmarshal(reqBuf, &resp); err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n}\n\nfunc TestHandler_PromRead_UnsupportedCursors(t *testing.T) {\n\treq := &remote.ReadRequest{Queries: []*remote.Query{&remote.Query{\n\t\tMatchers: []*remote.LabelMatcher{\n\t\t\t{\n\t\t\t\tType:  remote.MatchType_EQUAL,\n\t\t\t\tName:  \"__name__\",\n\t\t\t\tValue: \"value\",\n\t\t\t},\n\t\t},\n\t\tStartTimestampMs: 0,\n\t\tEndTimestampMs:   models.MaxNanoTime / int64(time.Millisecond),\n\t}}}\n\tdata, err := proto.Marshal(req)\n\tif err != nil {\n\t\tt.Fatal(\"couldn't marshal prometheus request\")\n\t}\n\tcompressed := snappy.Encode(nil, data)\n\n\tunsupported := []tsdb.Cursor{\n\t\tinternal.NewIntegerArrayCursorMock(),\n\t\tinternal.NewBooleanArrayCursorMock(),\n\t\tinternal.NewUnsignedArrayCursorMock(),\n\t\tinternal.NewStringArrayCursorMock(),\n\t}\n\n\tfor _, cursor := range unsupported {\n\t\th := NewHandler(false)\n\t\tw := httptest.NewRecorder()\n\t\tvar lb bytes.Buffer\n\t\th.Logger = logger.New(&lb)\n\n\t\tmore := true\n\t\th.Store.ResultSet.NextFn = func() bool { defer func() { more = false }(); return more }\n\n\t\t// Set the cursor type that will be returned while iterating over\n\t\t// the mock store.\n\t\th.Store.ResultSet.CursorFn = func() tsdb.Cursor {\n\t\t\treturn cursor\n\t\t}\n\n\t\tb := bytes.NewReader(compressed)\n\t\th.ServeHTTP(w, MustNewJSONRequest(\"POST\", \"/api/v1/prom/read?db=foo\", b))\n\t\tif w.Code != http.StatusOK {\n\t\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t\t}\n\t\treqBuf, err := snappy.Decode(nil, w.Body.Bytes())\n\t\tif err != nil {\n\t\t\tt.Fatal(err.Error())\n\t\t}\n\n\t\tvar resp remote.ReadResponse\n\t\tif err := proto.Unmarshal(reqBuf, &resp); err != nil {\n\t\t\tt.Fatal(err.Error())\n\t\t}\n\n\t\tif !strings.Contains(lb.String(), \"cursor_type=\") {\n\t\t\tt.Fatalf(\"got log message %q, expected to contain \\\"cursor_type\\\"\", lb.String())\n\t\t}\n\t}\n}\n\nfunc TestHandler_Flux_DisabledByDefault(t *testing.T) {\n\th := NewHandler(false)\n\tw := httptest.NewRecorder()\n\n\tbody := bytes.NewBufferString(`from(bucket:\"db/rp\") |> range(start:-1h) |> last()`)\n\th.ServeHTTP(w, MustNewRequest(\"POST\", \"/api/v2/query\", body))\n\tif got := w.Code; !cmp.Equal(got, http.StatusForbidden) {\n\t\tt.Fatalf(\"unexpected status: %d\", got)\n\t}\n\n\texp := \"Flux query service disabled. Verify flux-enabled=true in the [http] section of the InfluxDB config.\\n\"\n\tif got := string(w.Body.Bytes()); !cmp.Equal(got, exp) {\n\t\tt.Fatalf(\"unexpected body -got/+exp\\n%s\", cmp.Diff(got, exp))\n\t}\n}\n\nfunc TestHandler_Flux_QueryJSON(t *testing.T) {\n\th := NewHandlerWithConfig(NewHandlerConfig(WithFlux(), WithNoLog()))\n\tcalled := false\n\tqry := \"foo\"\n\th.Controller.QueryFn = func(ctx context.Context, compiler flux.Compiler) (i flux.Query, e error) {\n\t\tif exp := flux.CompilerType(lang.FluxCompilerType); compiler.CompilerType() != exp {\n\t\t\tt.Fatalf(\"unexpected compiler type -got/+exp\\n%s\", cmp.Diff(compiler.CompilerType(), exp))\n\t\t}\n\t\tif c, ok := compiler.(lang.FluxCompiler); !ok {\n\t\t\tt.Fatal(\"expected lang.FluxCompiler\")\n\t\t} else if exp := qry; c.Query != exp {\n\t\t\tt.Fatalf(\"unexpected query -got/+exp\\n%s\", cmp.Diff(c.Query, exp))\n\t\t}\n\t\tcalled = true\n\t\treturn internal.NewFluxQueryMock(), nil\n\t}\n\n\tq := client.QueryRequest{Query: qry}\n\tvar body bytes.Buffer\n\tif err := json.NewEncoder(&body).Encode(q); err != nil {\n\t\tt.Fatalf(\"unexpected JSON encoding error: %q\", err.Error())\n\t}\n\n\treq := MustNewRequest(\"POST\", \"/api/v2/query\", &body)\n\treq.Header.Add(\"content-type\", \"application/json\")\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif got := w.Code; !cmp.Equal(got, http.StatusOK) {\n\t\tt.Fatalf(\"unexpected status: %d\", got)\n\t}\n\n\tif !called {\n\t\tt.Fatalf(\"expected QueryFn to be called\")\n\t}\n}\n\nfunc TestHandler_Flux_SpecJSON(t *testing.T) {\n\th := NewHandlerWithConfig(NewHandlerConfig(WithFlux(), WithNoLog()))\n\tcalled := false\n\th.Controller.QueryFn = func(ctx context.Context, compiler flux.Compiler) (i flux.Query, e error) {\n\t\tif exp := flux.CompilerType(lang.SpecCompilerType); compiler.CompilerType() != exp {\n\t\t\tt.Fatalf(\"unexpected compiler type -got/+exp\\n%s\", cmp.Diff(compiler.CompilerType(), exp))\n\t\t}\n\t\tcalled = true\n\t\treturn internal.NewFluxQueryMock(), nil\n\t}\n\n\tq := client.QueryRequest{Spec: &flux.Spec{}}\n\tvar body bytes.Buffer\n\tif err := json.NewEncoder(&body).Encode(q); err != nil {\n\t\tt.Fatalf(\"unexpected JSON encoding error: %q\", err.Error())\n\t}\n\n\treq := MustNewRequest(\"POST\", \"/api/v2/query\", &body)\n\treq.Header.Add(\"content-type\", \"application/json\")\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif got := w.Code; !cmp.Equal(got, http.StatusOK) {\n\t\tt.Fatalf(\"unexpected status: %d\", got)\n\t}\n\n\tif !called {\n\t\tt.Fatalf(\"expected QueryFn to be called\")\n\t}\n}\n\nfunc TestHandler_Flux_QueryText(t *testing.T) {\n\th := NewHandlerWithConfig(NewHandlerConfig(WithFlux(), WithNoLog()))\n\tcalled := false\n\tqry := \"bar\"\n\th.Controller.QueryFn = func(ctx context.Context, compiler flux.Compiler) (i flux.Query, e error) {\n\t\tif exp := flux.CompilerType(lang.FluxCompilerType); compiler.CompilerType() != exp {\n\t\t\tt.Fatalf(\"unexpected compiler type -got/+exp\\n%s\", cmp.Diff(compiler.CompilerType(), exp))\n\t\t}\n\t\tif c, ok := compiler.(lang.FluxCompiler); !ok {\n\t\t\tt.Fatal(\"expected lang.FluxCompiler\")\n\t\t} else if exp := qry; c.Query != exp {\n\t\t\tt.Fatalf(\"unexpected query -got/+exp\\n%s\", cmp.Diff(c.Query, exp))\n\t\t}\n\t\tcalled = true\n\t\treturn internal.NewFluxQueryMock(), nil\n\t}\n\n\treq := MustNewRequest(\"POST\", \"/api/v2/query\", bytes.NewBufferString(qry))\n\treq.Header.Add(\"content-type\", \"application/vnd.flux\")\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif got := w.Code; !cmp.Equal(got, http.StatusOK) {\n\t\tt.Fatalf(\"unexpected status: %d\", got)\n\t}\n\n\tif !called {\n\t\tt.Fatalf(\"expected QueryFn to be called\")\n\t}\n}\n\nfunc TestHandler_Flux(t *testing.T) {\n\n\tqueryBytes := func(qs string) io.Reader {\n\t\tvar b bytes.Buffer\n\t\tq := &client.QueryRequest{Query: qs}\n\t\tif err := json.NewEncoder(&b).Encode(q); err != nil {\n\t\t\tt.Fatalf(\"unexpected JSON encoding error: %q\", err.Error())\n\t\t}\n\t\treturn &b\n\t}\n\n\ttests := []struct {\n\t\tname    string\n\t\treqFn   func() *http.Request\n\t\texpCode int\n\t\texpBody string\n\t}{\n\t\t{\n\t\t\tname: \"no media type\",\n\t\t\treqFn: func() *http.Request {\n\t\t\t\treturn MustNewRequest(\"POST\", \"/api/v2/query\", nil)\n\t\t\t},\n\t\t\texpCode: http.StatusBadRequest,\n\t\t\texpBody: \"{\\\"error\\\":\\\"mime: no media type\\\"}\\n\",\n\t\t},\n\t\t{\n\t\t\tname: \"200 OK\",\n\t\t\treqFn: func() *http.Request {\n\t\t\t\treq := MustNewRequest(\"POST\", \"/api/v2/query\", queryBytes(\"foo\"))\n\t\t\t\treq.Header.Add(\"content-type\", \"application/json\")\n\t\t\t\treturn req\n\t\t\t},\n\t\t\texpCode: http.StatusOK,\n\t\t},\n\t}\n\tfor _, test := range tests {\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\th := NewHandlerWithConfig(NewHandlerConfig(WithFlux(), WithNoLog()))\n\t\t\tw := httptest.NewRecorder()\n\t\t\th.ServeHTTP(w, test.reqFn())\n\t\t\tif got := w.Code; !cmp.Equal(got, test.expCode) {\n\t\t\t\tt.Fatalf(\"unexpected status: %d\", got)\n\t\t\t}\n\n\t\t\tif test.expBody != \"\" {\n\t\t\t\tif got := string(w.Body.Bytes()); !cmp.Equal(got, test.expBody) {\n\t\t\t\t\tt.Fatalf(\"unexpected body -got/+exp\\n%s\", cmp.Diff(got, test.expBody))\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestHandler_Flux_Auth(t *testing.T) {\n\t// Create the handler to be tested.\n\th := NewHandlerWithConfig(NewHandlerConfig(WithFlux(), WithNoLog(), WithAuthentication()))\n\th.MetaClient.AdminUserExistsFn = func() bool { return true }\n\th.MetaClient.UserFn = func(username string) (meta.User, error) {\n\t\tif username != \"user1\" {\n\t\t\treturn nil, meta.ErrUserNotFound\n\t\t}\n\t\treturn &meta.UserInfo{\n\t\t\tName:  \"user1\",\n\t\t\tHash:  \"abcd\",\n\t\t\tAdmin: true,\n\t\t}, nil\n\t}\n\th.MetaClient.AuthenticateFn = func(u, p string) (meta.User, error) {\n\t\tif u != \"user1\" {\n\t\t\treturn nil, fmt.Errorf(\"unexpected user: exp: user1, got: %s\", u)\n\t\t} else if p != \"abcd\" {\n\t\t\treturn nil, fmt.Errorf(\"unexpected password: exp: abcd, got: %s\", p)\n\t\t}\n\t\treturn h.MetaClient.User(u)\n\t}\n\n\th.Controller.QueryFn = func(ctx context.Context, compiler flux.Compiler) (i flux.Query, e error) {\n\t\treturn internal.NewFluxQueryMock(), nil\n\t}\n\n\treq := MustNewRequest(\"POST\", \"/api/v2/query\", bytes.NewBufferString(\"bar\"))\n\treq.Header.Set(\"content-type\", \"application/vnd.flux\")\n\treq.Header.Set(\"Authorization\", \"Token user1:abcd\")\n\t// Test the handler with valid user and password in the URL parameters.\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif got := w.Code; !cmp.Equal(got, http.StatusOK) {\n\t\tt.Fatalf(\"unexpected status: %d\", got)\n\t}\n\n\treq.Header.Set(\"Authorization\", \"Token user1:efgh\")\n\tw = httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif got := w.Code; !cmp.Equal(got, http.StatusUnauthorized) {\n\t\tt.Fatalf(\"unexpected status: %d\", got)\n\t}\n}\n\n// Ensure the handler handles ping requests correctly.\n// TODO: This should be expanded to verify the MetaClient check in servePing is working correctly\nfunc TestHandler_Ping(t *testing.T) {\n\th := NewHandler(false)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewRequest(\"GET\", \"/ping\", nil))\n\tif w.Code != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n\th.ServeHTTP(w, MustNewRequest(\"HEAD\", \"/ping\", nil))\n\tif w.Code != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n}\n\n// Ensure the handler returns the version correctly from the different endpoints.\nfunc TestHandler_Version(t *testing.T) {\n\th := NewHandler(false)\n\th.StatementExecutor.ExecuteStatementFn = func(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\t\treturn nil\n\t}\n\ttests := []struct {\n\t\tmethod   string\n\t\tendpoint string\n\t\tbody     io.Reader\n\t}{\n\t\t{\n\t\t\tmethod:   \"GET\",\n\t\t\tendpoint: \"/ping\",\n\t\t\tbody:     nil,\n\t\t},\n\t\t{\n\t\t\tmethod:   \"GET\",\n\t\t\tendpoint: \"/query?db=foo&q=SELECT+*+FROM+bar\",\n\t\t\tbody:     nil,\n\t\t},\n\t\t{\n\t\t\tmethod:   \"POST\",\n\t\t\tendpoint: \"/write\",\n\t\t\tbody:     bytes.NewReader(make([]byte, 10)),\n\t\t},\n\t\t{\n\t\t\tmethod:   \"GET\",\n\t\t\tendpoint: \"/notfound\",\n\t\t\tbody:     nil,\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, MustNewRequest(test.method, test.endpoint, test.body))\n\t\tif v := w.HeaderMap[\"X-Influxdb-Version\"]; len(v) > 0 {\n\t\t\tif v[0] != \"0.0.0\" {\n\t\t\t\tt.Fatalf(\"unexpected version: %s\", v)\n\t\t\t}\n\t\t} else {\n\t\t\tt.Fatalf(\"Header entry 'X-Influxdb-Version' not present\")\n\t\t}\n\n\t\tif v := w.HeaderMap[\"X-Influxdb-Build\"]; len(v) > 0 {\n\t\t\tif v[0] != \"OSS\" {\n\t\t\t\tt.Fatalf(\"unexpected BuildType: %s\", v)\n\t\t\t}\n\t\t} else {\n\t\t\tt.Fatalf(\"Header entry 'X-Influxdb-Build' not present\")\n\t\t}\n\t}\n}\n\n// Ensure the handler handles status requests correctly.\nfunc TestHandler_Status(t *testing.T) {\n\th := NewHandler(false)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewRequest(\"GET\", \"/status\", nil))\n\tif w.Code != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n\th.ServeHTTP(w, MustNewRequest(\"HEAD\", \"/status\", nil))\n\tif w.Code != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n}\n\n// Ensure write endpoint can handle bad requests\nfunc TestHandler_HandleBadRequestBody(t *testing.T) {\n\tb := bytes.NewReader(make([]byte, 10))\n\th := NewHandler(false)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewRequest(\"POST\", \"/write\", b))\n\tif w.Code != http.StatusBadRequest {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n}\n\nfunc TestHandler_Write_EntityTooLarge_ContentLength(t *testing.T) {\n\tb := bytes.NewReader(make([]byte, 100))\n\th := NewHandler(false)\n\th.Config.MaxBodySize = 5\n\th.MetaClient.DatabaseFn = func(name string) *meta.DatabaseInfo {\n\t\treturn &meta.DatabaseInfo{}\n\t}\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewRequest(\"POST\", \"/write?db=foo\", b))\n\tif w.Code != http.StatusRequestEntityTooLarge {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n}\n\nfunc TestHandler_Write_SuppressLog(t *testing.T) {\n\tvar buf bytes.Buffer\n\tc := httpd.NewConfig()\n\tc.SuppressWriteLog = true\n\th := NewHandlerWithConfig(c)\n\th.CLFLogger = log.New(&buf, \"\", log.LstdFlags)\n\th.MetaClient.DatabaseFn = func(name string) *meta.DatabaseInfo {\n\t\treturn &meta.DatabaseInfo{}\n\t}\n\th.PointsWriter.WritePointsFn = func(database, retentionPolicy string, consistencyLevel models.ConsistencyLevel, user meta.User, points []models.Point) error {\n\t\treturn nil\n\t}\n\n\tb := strings.NewReader(\"cpu,host=server01 value=2\\n\")\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewRequest(\"POST\", \"/write?db=foo\", b))\n\tif w.Code != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n\n\t// If the log has anything in it, this failed.\n\tif buf.Len() > 0 {\n\t\tt.Fatalf(\"expected no bytes to be written to the log, got %d\", buf.Len())\n\t}\n}\n\n// onlyReader implements io.Reader only to ensure Request.ContentLength is not set\ntype onlyReader struct {\n\tr io.Reader\n}\n\nfunc (o onlyReader) Read(p []byte) (n int, err error) {\n\treturn o.r.Read(p)\n}\n\nfunc TestHandler_Write_EntityTooLarge_NoContentLength(t *testing.T) {\n\tb := onlyReader{bytes.NewReader(make([]byte, 100))}\n\th := NewHandler(false)\n\th.Config.MaxBodySize = 5\n\th.MetaClient.DatabaseFn = func(name string) *meta.DatabaseInfo {\n\t\treturn &meta.DatabaseInfo{}\n\t}\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewRequest(\"POST\", \"/write?db=foo\", b))\n\tif w.Code != http.StatusRequestEntityTooLarge {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n}\n\n// TestHandler_Write_NegativeMaxBodySize verifies no error occurs if MaxBodySize is < 0\nfunc TestHandler_Write_NegativeMaxBodySize(t *testing.T) {\n\tb := bytes.NewReader([]byte(`foo n=1`))\n\th := NewHandler(false)\n\th.Config.MaxBodySize = -1\n\th.MetaClient.DatabaseFn = func(name string) *meta.DatabaseInfo {\n\t\treturn &meta.DatabaseInfo{}\n\t}\n\tcalled := false\n\th.PointsWriter.WritePointsFn = func(_, _ string, _ models.ConsistencyLevel, _ meta.User, _ []models.Point) error {\n\t\tcalled = true\n\t\treturn nil\n\t}\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewRequest(\"POST\", \"/write?db=foo\", b))\n\tif !called {\n\t\tt.Fatal(\"WritePoints: expected call\")\n\t}\n\tif w.Code != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n}\n\n// Ensure X-Forwarded-For header writes the correct log message.\nfunc TestHandler_XForwardedFor(t *testing.T) {\n\tvar buf bytes.Buffer\n\th := NewHandler(false)\n\th.CLFLogger = log.New(&buf, \"\", 0)\n\n\treq := MustNewRequest(\"GET\", \"/query\", nil)\n\treq.Header.Set(\"X-Forwarded-For\", \"192.168.0.1\")\n\treq.RemoteAddr = \"127.0.0.1\"\n\th.ServeHTTP(httptest.NewRecorder(), req)\n\n\tparts := strings.Split(buf.String(), \" \")\n\tif parts[0] != \"192.168.0.1,127.0.0.1\" {\n\t\tt.Errorf(\"unexpected host ip address: %s\", parts[0])\n\t}\n}\n\nfunc TestHandler_XRequestId(t *testing.T) {\n\tvar buf bytes.Buffer\n\th := NewHandler(false)\n\th.CLFLogger = log.New(&buf, \"\", 0)\n\n\tcases := []map[string]string{\n\t\t{\"X-Request-Id\": \"abc123\", \"Request-Id\": \"\"},          // X-Request-Id is used.\n\t\t{\"X-REQUEST-ID\": \"cde\", \"Request-Id\": \"\"},             // X-REQUEST-ID is used.\n\t\t{\"X-Request-Id\": \"\", \"Request-Id\": \"foobarzoo\"},       // Request-Id is used.\n\t\t{\"X-Request-Id\": \"abc123\", \"Request-Id\": \"foobarzoo\"}, // X-Request-Id takes precedence.\n\t\t{\"X-Request-Id\": \"\", \"Request-Id\": \"\"},                // v1 UUID generated.\n\t}\n\n\tfor _, c := range cases {\n\t\tt.Run(fmt.Sprint(c), func(t *testing.T) {\n\t\t\tbuf.Reset()\n\t\t\treq := MustNewRequest(\"GET\", \"/ping\", nil)\n\t\t\treq.RemoteAddr = \"127.0.0.1\"\n\n\t\t\t// Set the relevant request ID headers\n\t\t\tvar allEmpty = true\n\t\t\tfor k, v := range c {\n\t\t\t\treq.Header.Set(k, v)\n\t\t\t\tif v != \"\" {\n\t\t\t\t\tallEmpty = false\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tw := httptest.NewRecorder()\n\t\t\th.ServeHTTP(w, req)\n\n\t\t\t// Split up the HTTP log line. The request ID is currently located in\n\t\t\t// index 12. If the log line gets changed in the future, this test\n\t\t\t// will likely break and the index will need to be updated.\n\t\t\tparts := strings.Split(buf.String(), \" \")\n\t\t\ti := 12\n\n\t\t\t// If neither header is set then we expect a v1 UUID to be generated.\n\t\t\tif allEmpty {\n\t\t\t\tif got, exp := len(parts[i]), 36; got != exp {\n\t\t\t\t\tt.Fatalf(\"got ID of length %d, expected one of length %d\", got, exp)\n\t\t\t\t}\n\t\t\t} else if c[\"X-Request-Id\"] != \"\" {\n\t\t\t\tif got, exp := parts[i], c[\"X-Request-Id\"]; got != exp {\n\t\t\t\t\tt.Fatalf(\"got ID of %q, expected %q\", got, exp)\n\t\t\t\t}\n\t\t\t} else if c[\"X-REQUEST-ID\"] != \"\" {\n\t\t\t\tif got, exp := parts[i], c[\"X-REQUEST-ID\"]; got != exp {\n\t\t\t\t\tt.Fatalf(\"got ID of %q, expected %q\", got, exp)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif got, exp := parts[i], c[\"Request-Id\"]; got != exp {\n\t\t\t\t\tt.Fatalf(\"got ID of %q, expected %q\", got, exp)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Check response headers\n\t\t\tif got, exp := w.Header().Get(\"Request-Id\"), parts[i]; got != exp {\n\t\t\t\tt.Fatalf(\"Request-Id header was %s, expected %s\", got, exp)\n\t\t\t} else if got, exp := w.Header().Get(\"X-Request-Id\"), parts[i]; got != exp {\n\t\t\t\tt.Fatalf(\"X-Request-Id header was %s, expected %s\", got, exp)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestThrottler_Handler(t *testing.T) {\n\tt.Run(\"OK\", func(t *testing.T) {\n\t\tthrottler := httpd.NewThrottler(2, 98)\n\n\t\t// Send the total number of concurrent requests to the channel.\n\t\tvar concurrentN int32\n\t\tconcurrentCh := make(chan int)\n\n\t\th := throttler.Handler(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tatomic.AddInt32(&concurrentN, 1)\n\t\t\tconcurrentCh <- int(atomic.LoadInt32(&concurrentN))\n\t\t\ttime.Sleep(1 * time.Millisecond)\n\t\t\tatomic.AddInt32(&concurrentN, -1)\n\t\t}))\n\n\t\t// Execute requests concurrently.\n\t\tconst n = 100\n\t\tfor i := 0; i < n; i++ {\n\t\t\tgo func() { h.ServeHTTP(nil, nil) }()\n\t\t}\n\n\t\t// Read the number of concurrent requests for every execution.\n\t\tfor i := 0; i < n; i++ {\n\t\t\tif v := <-concurrentCh; v > 2 {\n\t\t\t\tt.Fatalf(\"concurrent requests exceed maximum: %d\", v)\n\t\t\t}\n\t\t}\n\t})\n\n\tt.Run(\"ErrTimeout\", func(t *testing.T) {\n\t\tthrottler := httpd.NewThrottler(2, 1)\n\t\tthrottler.EnqueueTimeout = 1 * time.Millisecond\n\n\t\tbegin, end := make(chan struct{}), make(chan struct{})\n\t\th := throttler.Handler(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tbegin <- struct{}{}\n\t\t\tend <- struct{}{}\n\t\t}))\n\n\t\t// First two requests should execute immediately.\n\t\tgo func() { h.ServeHTTP(nil, nil) }()\n\t\tgo func() { h.ServeHTTP(nil, nil) }()\n\n\t\t<-begin\n\t\t<-begin\n\n\t\t// Third request should be enqueued but timeout.\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, nil)\n\t\tif w.Code != http.StatusServiceUnavailable {\n\t\t\tt.Fatalf(\"unexpected status code: %d\", w.Code)\n\t\t} else if body := w.Body.String(); body != \"request throttled, exceeds timeout\\n\" {\n\t\t\tt.Fatalf(\"unexpected response body: %q\", body)\n\t\t}\n\n\t\t// Allow 2 existing requests to complete.\n\t\t<-end\n\t\t<-end\n\t})\n\n\tt.Run(\"ErrFull\", func(t *testing.T) {\n\t\tdelay := 100 * time.Millisecond\n\t\tif os.Getenv(\"CI\") != \"\" {\n\t\t\tdelay = 2 * time.Second\n\t\t}\n\n\t\tthrottler := httpd.NewThrottler(2, 1)\n\n\t\tresp := make(chan struct{})\n\t\th := throttler.Handler(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tresp <- struct{}{}\n\t\t}))\n\n\t\t// First two requests should execute immediately and third should be queued.\n\t\tgo func() { h.ServeHTTP(nil, nil) }()\n\t\tgo func() { h.ServeHTTP(nil, nil) }()\n\t\tgo func() { h.ServeHTTP(nil, nil) }()\n\t\ttime.Sleep(delay)\n\n\t\t// Fourth request should fail when trying to enqueue.\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, nil)\n\t\tif w.Code != http.StatusServiceUnavailable {\n\t\t\tt.Fatalf(\"unexpected status code: %d\", w.Code)\n\t\t} else if body := w.Body.String(); body != \"request throttled, queue full\\n\" {\n\t\t\tt.Fatalf(\"unexpected response body: %q\", body)\n\t\t}\n\n\t\t// Allow 3 existing requests to complete.\n\t\t<-resp\n\t\t<-resp\n\t\t<-resp\n\t})\n}\n\n// NewHandler represents a test wrapper for httpd.Handler.\ntype Handler struct {\n\t*httpd.Handler\n\tMetaClient        *internal.MetaClientMock\n\tStatementExecutor HandlerStatementExecutor\n\tQueryAuthorizer   HandlerQueryAuthorizer\n\tPointsWriter      HandlerPointsWriter\n\tStore             *internal.StorageStoreMock\n\tController        *internal.FluxControllerMock\n}\n\ntype configOption func(c *httpd.Config)\n\nfunc WithAuthentication() configOption {\n\treturn func(c *httpd.Config) {\n\t\tc.AuthEnabled = true\n\t\tc.SharedSecret = \"super secret key\"\n\t}\n}\n\nfunc WithFlux() configOption {\n\treturn func(c *httpd.Config) {\n\t\tc.FluxEnabled = true\n\t}\n}\n\nfunc WithNoLog() configOption {\n\treturn func(c *httpd.Config) {\n\t\tc.LogEnabled = false\n\t}\n}\n\n// NewHandlerConfig returns a new instance of httpd.Config with\n// authentication configured.\nfunc NewHandlerConfig(opts ...configOption) httpd.Config {\n\tconfig := httpd.NewConfig()\n\tfor _, opt := range opts {\n\t\topt(&config)\n\t}\n\treturn config\n}\n\n// NewHandler returns a new instance of Handler.\nfunc NewHandler(requireAuthentication bool) *Handler {\n\tvar opts []configOption\n\tif requireAuthentication {\n\t\topts = append(opts, WithAuthentication())\n\t}\n\n\treturn NewHandlerWithConfig(NewHandlerConfig(opts...))\n}\n\nfunc NewHandlerWithConfig(config httpd.Config) *Handler {\n\th := &Handler{\n\t\tHandler: httpd.NewHandler(config),\n\t}\n\n\th.MetaClient = &internal.MetaClientMock{}\n\th.Store = internal.NewStorageStoreMock()\n\th.Controller = internal.NewFluxControllerMock()\n\n\th.Handler.MetaClient = h.MetaClient\n\th.Handler.Store = h.Store\n\th.Handler.QueryExecutor = query.NewExecutor()\n\th.Handler.QueryExecutor.StatementExecutor = &h.StatementExecutor\n\th.Handler.QueryAuthorizer = &h.QueryAuthorizer\n\th.Handler.PointsWriter = &h.PointsWriter\n\th.Handler.Version = \"0.0.0\"\n\th.Handler.BuildType = \"OSS\"\n\th.Handler.Controller = h.Controller\n\n\tif testing.Verbose() {\n\t\tl := logger.New(os.Stdout)\n\t\th.Handler.Logger = l\n\t}\n\n\treturn h\n}\n\n// HandlerStatementExecutor is a mock implementation of Handler.StatementExecutor.\ntype HandlerStatementExecutor struct {\n\tExecuteStatementFn func(stmt influxql.Statement, ctx *query.ExecutionContext) error\n}\n\nfunc (e *HandlerStatementExecutor) ExecuteStatement(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\treturn e.ExecuteStatementFn(stmt, ctx)\n}\n\n// HandlerQueryAuthorizer is a mock implementation of Handler.QueryAuthorizer.\ntype HandlerQueryAuthorizer struct {\n\tAuthorizeQueryFn func(u meta.User, query *influxql.Query, database string) error\n}\n\nfunc (a *HandlerQueryAuthorizer) AuthorizeQuery(u meta.User, query *influxql.Query, database string) error {\n\treturn a.AuthorizeQueryFn(u, query, database)\n}\n\ntype HandlerPointsWriter struct {\n\tWritePointsFn func(database, retentionPolicy string, consistencyLevel models.ConsistencyLevel, user meta.User, points []models.Point) error\n}\n\nfunc (h *HandlerPointsWriter) WritePoints(database, retentionPolicy string, consistencyLevel models.ConsistencyLevel, user meta.User, points []models.Point) error {\n\treturn h.WritePointsFn(database, retentionPolicy, consistencyLevel, user, points)\n}\n\n// MustNewRequest returns a new HTTP request. Panic on error.\nfunc MustNewRequest(method, urlStr string, body io.Reader) *http.Request {\n\tr, err := http.NewRequest(method, urlStr, body)\n\tif err != nil {\n\t\tpanic(err.Error())\n\t}\n\treturn r\n}\n\n// MustNewRequest returns a new HTTP request with the content type set. Panic on error.\nfunc MustNewJSONRequest(method, urlStr string, body io.Reader) *http.Request {\n\tr := MustNewRequest(method, urlStr, body)\n\tr.Header.Set(\"Accept\", \"application/json\")\n\treturn r\n}\n\n// MustJWTToken returns a new JWT token and signed string or panics trying.\nfunc MustJWTToken(username, secret string, expired bool) (*jwt.Token, string) {\n\ttoken := jwt.New(jwt.GetSigningMethod(\"HS512\"))\n\ttoken.Claims.(jwt.MapClaims)[\"username\"] = username\n\tif expired {\n\t\ttoken.Claims.(jwt.MapClaims)[\"exp\"] = time.Now().Add(-time.Second).Unix()\n\t} else {\n\t\ttoken.Claims.(jwt.MapClaims)[\"exp\"] = time.Now().Add(time.Minute * 10).Unix()\n\t}\n\tsigned, err := token.SignedString([]byte(secret))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn token, signed\n}\n"], "fixing_code": ["package httpd\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"expvar\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"math\"\n\t\"net/http\"\n\t\"os\"\n\t\"runtime/debug\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"github.com/bmizerany/pat\"\n\t\"github.com/dgrijalva/jwt-go\"\n\t\"github.com/gogo/protobuf/proto\"\n\t\"github.com/golang/snappy\"\n\t\"github.com/influxdata/flux\"\n\t\"github.com/influxdata/flux/lang\"\n\t\"github.com/influxdata/influxdb\"\n\t\"github.com/influxdata/influxdb/logger\"\n\t\"github.com/influxdata/influxdb/models\"\n\t\"github.com/influxdata/influxdb/monitor\"\n\t\"github.com/influxdata/influxdb/monitor/diagnostics\"\n\t\"github.com/influxdata/influxdb/prometheus\"\n\t\"github.com/influxdata/influxdb/prometheus/remote\"\n\t\"github.com/influxdata/influxdb/query\"\n\t\"github.com/influxdata/influxdb/services/meta\"\n\t\"github.com/influxdata/influxdb/services/storage\"\n\t\"github.com/influxdata/influxdb/storage/reads\"\n\t\"github.com/influxdata/influxdb/storage/reads/datatypes\"\n\t\"github.com/influxdata/influxdb/tsdb\"\n\t\"github.com/influxdata/influxdb/uuid\"\n\t\"github.com/influxdata/influxql\"\n\tprom \"github.com/prometheus/client_golang/prometheus\"\n\t\"github.com/prometheus/client_golang/prometheus/promhttp\"\n\t\"go.uber.org/zap\"\n)\n\nconst (\n\t// DefaultChunkSize specifies the maximum number of points that will\n\t// be read before sending results back to the engine.\n\t//\n\t// This has no relation to the number of bytes that are returned.\n\tDefaultChunkSize = 10000\n\n\tDefaultDebugRequestsInterval = 10 * time.Second\n\n\tMaxDebugRequestsInterval = 6 * time.Hour\n)\n\n// AuthenticationMethod defines the type of authentication used.\ntype AuthenticationMethod int\n\n// Supported authentication methods.\nconst (\n\t// Authenticate using basic authentication.\n\tUserAuthentication AuthenticationMethod = iota\n\n\t// Authenticate with jwt.\n\tBearerAuthentication\n)\n\n// TODO: Check HTTP response codes: 400, 401, 403, 409.\n\n// Route specifies how to handle a HTTP verb for a given endpoint.\ntype Route struct {\n\tName           string\n\tMethod         string\n\tPattern        string\n\tGzipped        bool\n\tLoggingEnabled bool\n\tHandlerFunc    interface{}\n}\n\n// Handler represents an HTTP handler for the InfluxDB server.\ntype Handler struct {\n\tmux       *pat.PatternServeMux\n\tVersion   string\n\tBuildType string\n\n\tMetaClient interface {\n\t\tDatabase(name string) *meta.DatabaseInfo\n\t\tDatabases() []meta.DatabaseInfo\n\t\tAuthenticate(username, password string) (ui meta.User, err error)\n\t\tUser(username string) (meta.User, error)\n\t\tAdminUserExists() bool\n\t}\n\n\tQueryAuthorizer interface {\n\t\tAuthorizeQuery(u meta.User, query *influxql.Query, database string) error\n\t}\n\n\tWriteAuthorizer interface {\n\t\tAuthorizeWrite(username, database string) error\n\t}\n\n\tQueryExecutor *query.Executor\n\n\tMonitor interface {\n\t\tStatistics(tags map[string]string) ([]*monitor.Statistic, error)\n\t\tDiagnostics() (map[string]*diagnostics.Diagnostics, error)\n\t}\n\n\tPointsWriter interface {\n\t\tWritePoints(database, retentionPolicy string, consistencyLevel models.ConsistencyLevel, user meta.User, points []models.Point) error\n\t}\n\n\tStore Store\n\n\t// Flux services\n\tController       Controller\n\tCompilerMappings flux.CompilerMappings\n\tregistered       bool\n\n\tConfig           *Config\n\tLogger           *zap.Logger\n\tCLFLogger        *log.Logger\n\taccessLog        *os.File\n\taccessLogFilters StatusFilters\n\tstats            *Statistics\n\n\trequestTracker *RequestTracker\n\twriteThrottler *Throttler\n}\n\n// NewHandler returns a new instance of handler with routes.\nfunc NewHandler(c Config) *Handler {\n\th := &Handler{\n\t\tmux:            pat.New(),\n\t\tConfig:         &c,\n\t\tLogger:         zap.NewNop(),\n\t\tCLFLogger:      log.New(os.Stderr, \"[httpd] \", 0),\n\t\tstats:          &Statistics{},\n\t\trequestTracker: NewRequestTracker(),\n\t}\n\n\t// Limit the number of concurrent & enqueued write requests.\n\th.writeThrottler = NewThrottler(c.MaxConcurrentWriteLimit, c.MaxEnqueuedWriteLimit)\n\th.writeThrottler.EnqueueTimeout = c.EnqueuedWriteTimeout\n\n\t// Disable the write log if they have been suppressed.\n\twriteLogEnabled := c.LogEnabled\n\tif c.SuppressWriteLog {\n\t\twriteLogEnabled = false\n\t}\n\n\th.AddRoutes([]Route{\n\t\tRoute{\n\t\t\t\"query-options\", // Satisfy CORS checks.\n\t\t\t\"OPTIONS\", \"/query\", false, true, h.serveOptions,\n\t\t},\n\t\tRoute{\n\t\t\t\"query\", // Query serving route.\n\t\t\t\"GET\", \"/query\", true, true, h.serveQuery,\n\t\t},\n\t\tRoute{\n\t\t\t\"query\", // Query serving route.\n\t\t\t\"POST\", \"/query\", true, true, h.serveQuery,\n\t\t},\n\t\tRoute{\n\t\t\t\"write-options\", // Satisfy CORS checks.\n\t\t\t\"OPTIONS\", \"/write\", false, true, h.serveOptions,\n\t\t},\n\t\tRoute{\n\t\t\t\"write\", // Data-ingest route.\n\t\t\t\"POST\", \"/write\", true, writeLogEnabled, h.serveWrite,\n\t\t},\n\t\tRoute{\n\t\t\t\"prometheus-write\", // Prometheus remote write\n\t\t\t\"POST\", \"/api/v1/prom/write\", false, true, h.servePromWrite,\n\t\t},\n\t\tRoute{\n\t\t\t\"prometheus-read\", // Prometheus remote read\n\t\t\t\"POST\", \"/api/v1/prom/read\", true, true, h.servePromRead,\n\t\t},\n\t\tRoute{ // Ping\n\t\t\t\"ping\",\n\t\t\t\"GET\", \"/ping\", false, true, h.servePing,\n\t\t},\n\t\tRoute{ // Ping\n\t\t\t\"ping-head\",\n\t\t\t\"HEAD\", \"/ping\", false, true, h.servePing,\n\t\t},\n\t\tRoute{ // Ping w/ status\n\t\t\t\"status\",\n\t\t\t\"GET\", \"/status\", false, true, h.serveStatus,\n\t\t},\n\t\tRoute{ // Ping w/ status\n\t\t\t\"status-head\",\n\t\t\t\"HEAD\", \"/status\", false, true, h.serveStatus,\n\t\t},\n\t\tRoute{\n\t\t\t\"prometheus-metrics\",\n\t\t\t\"GET\", \"/metrics\", false, true, promhttp.Handler().ServeHTTP,\n\t\t},\n\t}...)\n\n\tfluxRoute := Route{\n\t\t\"flux-read\",\n\t\t\"POST\", \"/api/v2/query\", true, true, nil,\n\t}\n\n\tif !c.FluxEnabled {\n\t\tfluxRoute.HandlerFunc = func(w http.ResponseWriter, r *http.Request) {\n\t\t\thttp.Error(w, \"Flux query service disabled. Verify flux-enabled=true in the [http] section of the InfluxDB config.\", http.StatusForbidden)\n\t\t}\n\t} else {\n\t\tfluxRoute.HandlerFunc = h.serveFluxQuery\n\t}\n\th.AddRoutes(fluxRoute)\n\n\treturn h\n}\n\nfunc (h *Handler) Open() {\n\tif h.Config.LogEnabled {\n\t\tpath := \"stderr\"\n\n\t\tif h.Config.AccessLogPath != \"\" {\n\t\t\tf, err := os.OpenFile(h.Config.AccessLogPath, os.O_WRONLY|os.O_APPEND|os.O_CREATE, 0666)\n\t\t\tif err != nil {\n\t\t\t\th.Logger.Error(\"unable to open access log, falling back to stderr\", zap.Error(err), zap.String(\"path\", h.Config.AccessLogPath))\n\t\t\t\treturn\n\t\t\t}\n\t\t\th.CLFLogger = log.New(f, \"\", 0) // [httpd] prefix stripped when logging to a file\n\t\t\th.accessLog = f\n\t\t\tpath = h.Config.AccessLogPath\n\t\t}\n\t\th.Logger.Info(\"opened HTTP access log\", zap.String(\"path\", path))\n\t}\n\th.accessLogFilters = StatusFilters(h.Config.AccessLogStatusFilters)\n\n\tif h.Config.FluxEnabled {\n\t\th.registered = true\n\t\tprom.MustRegister(h.Controller.PrometheusCollectors()...)\n\t}\n}\n\nfunc (h *Handler) Close() {\n\tif h.accessLog != nil {\n\t\th.accessLog.Close()\n\t\th.accessLog = nil\n\t\th.accessLogFilters = nil\n\t}\n\n\tif h.registered {\n\t\tfor _, col := range h.Controller.PrometheusCollectors() {\n\t\t\tprom.Unregister(col)\n\t\t}\n\t\th.registered = false\n\t}\n}\n\n// Statistics maintains statistics for the httpd service.\ntype Statistics struct {\n\tRequests                     int64\n\tCQRequests                   int64\n\tQueryRequests                int64\n\tWriteRequests                int64\n\tPingRequests                 int64\n\tStatusRequests               int64\n\tWriteRequestBytesReceived    int64\n\tQueryRequestBytesTransmitted int64\n\tPointsWrittenOK              int64\n\tPointsWrittenDropped         int64\n\tPointsWrittenFail            int64\n\tAuthenticationFailures       int64\n\tRequestDuration              int64\n\tQueryRequestDuration         int64\n\tWriteRequestDuration         int64\n\tActiveRequests               int64\n\tActiveWriteRequests          int64\n\tClientErrors                 int64\n\tServerErrors                 int64\n\tRecoveredPanics              int64\n\tPromWriteRequests            int64\n\tPromReadRequests             int64\n\tFluxQueryRequests            int64\n\tFluxQueryRequestDuration     int64\n}\n\n// Statistics returns statistics for periodic monitoring.\nfunc (h *Handler) Statistics(tags map[string]string) []models.Statistic {\n\treturn []models.Statistic{{\n\t\tName: \"httpd\",\n\t\tTags: tags,\n\t\tValues: map[string]interface{}{\n\t\t\tstatRequest:                      atomic.LoadInt64(&h.stats.Requests),\n\t\t\tstatQueryRequest:                 atomic.LoadInt64(&h.stats.QueryRequests),\n\t\t\tstatWriteRequest:                 atomic.LoadInt64(&h.stats.WriteRequests),\n\t\t\tstatPingRequest:                  atomic.LoadInt64(&h.stats.PingRequests),\n\t\t\tstatStatusRequest:                atomic.LoadInt64(&h.stats.StatusRequests),\n\t\t\tstatWriteRequestBytesReceived:    atomic.LoadInt64(&h.stats.WriteRequestBytesReceived),\n\t\t\tstatQueryRequestBytesTransmitted: atomic.LoadInt64(&h.stats.QueryRequestBytesTransmitted),\n\t\t\tstatPointsWrittenOK:              atomic.LoadInt64(&h.stats.PointsWrittenOK),\n\t\t\tstatPointsWrittenDropped:         atomic.LoadInt64(&h.stats.PointsWrittenDropped),\n\t\t\tstatPointsWrittenFail:            atomic.LoadInt64(&h.stats.PointsWrittenFail),\n\t\t\tstatAuthFail:                     atomic.LoadInt64(&h.stats.AuthenticationFailures),\n\t\t\tstatRequestDuration:              atomic.LoadInt64(&h.stats.RequestDuration),\n\t\t\tstatQueryRequestDuration:         atomic.LoadInt64(&h.stats.QueryRequestDuration),\n\t\t\tstatWriteRequestDuration:         atomic.LoadInt64(&h.stats.WriteRequestDuration),\n\t\t\tstatRequestsActive:               atomic.LoadInt64(&h.stats.ActiveRequests),\n\t\t\tstatWriteRequestsActive:          atomic.LoadInt64(&h.stats.ActiveWriteRequests),\n\t\t\tstatClientError:                  atomic.LoadInt64(&h.stats.ClientErrors),\n\t\t\tstatServerError:                  atomic.LoadInt64(&h.stats.ServerErrors),\n\t\t\tstatRecoveredPanics:              atomic.LoadInt64(&h.stats.RecoveredPanics),\n\t\t\tstatPromWriteRequest:             atomic.LoadInt64(&h.stats.PromWriteRequests),\n\t\t\tstatPromReadRequest:              atomic.LoadInt64(&h.stats.PromReadRequests),\n\t\t\tstatFluxQueryRequests:            atomic.LoadInt64(&h.stats.FluxQueryRequests),\n\t\t\tstatFluxQueryRequestDuration:     atomic.LoadInt64(&h.stats.FluxQueryRequestDuration),\n\t\t},\n\t}}\n}\n\n// AddRoutes sets the provided routes on the handler.\nfunc (h *Handler) AddRoutes(routes ...Route) {\n\tfor _, r := range routes {\n\t\tvar handler http.Handler\n\n\t\t// If it's a handler func that requires authorization, wrap it in authentication\n\t\tif hf, ok := r.HandlerFunc.(func(http.ResponseWriter, *http.Request, meta.User)); ok {\n\t\t\thandler = authenticate(hf, h, h.Config.AuthEnabled)\n\t\t}\n\n\t\t// This is a normal handler signature and does not require authentication\n\t\tif hf, ok := r.HandlerFunc.(func(http.ResponseWriter, *http.Request)); ok {\n\t\t\thandler = http.HandlerFunc(hf)\n\t\t}\n\n\t\t// Throttle route if this is a write endpoint.\n\t\tif r.Method == http.MethodPost {\n\t\t\tswitch r.Pattern {\n\t\t\tcase \"/write\", \"/api/v1/prom/write\":\n\t\t\t\thandler = h.writeThrottler.Handler(handler)\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\n\t\thandler = h.responseWriter(handler)\n\t\tif r.Gzipped {\n\t\t\thandler = gzipFilter(handler)\n\t\t}\n\t\thandler = cors(handler)\n\t\thandler = requestID(handler)\n\t\tif h.Config.LogEnabled && r.LoggingEnabled {\n\t\t\thandler = h.logging(handler, r.Name)\n\t\t}\n\t\thandler = h.recovery(handler, r.Name) // make sure recovery is always last\n\n\t\th.mux.Add(r.Method, r.Pattern, handler)\n\t}\n}\n\n// ServeHTTP responds to HTTP request to the handler.\nfunc (h *Handler) ServeHTTP(w http.ResponseWriter, r *http.Request) {\n\tatomic.AddInt64(&h.stats.Requests, 1)\n\tatomic.AddInt64(&h.stats.ActiveRequests, 1)\n\tdefer atomic.AddInt64(&h.stats.ActiveRequests, -1)\n\tstart := time.Now()\n\n\t// Add version and build header to all InfluxDB requests.\n\tw.Header().Add(\"X-Influxdb-Version\", h.Version)\n\tw.Header().Add(\"X-Influxdb-Build\", h.BuildType)\n\n\tif strings.HasPrefix(r.URL.Path, \"/debug/pprof\") && h.Config.PprofEnabled {\n\t\th.handleProfiles(w, r)\n\t} else if strings.HasPrefix(r.URL.Path, \"/debug/vars\") {\n\t\th.serveExpvar(w, r)\n\t} else if strings.HasPrefix(r.URL.Path, \"/debug/requests\") {\n\t\th.serveDebugRequests(w, r)\n\t} else {\n\t\th.mux.ServeHTTP(w, r)\n\t}\n\n\tatomic.AddInt64(&h.stats.RequestDuration, time.Since(start).Nanoseconds())\n}\n\n// writeHeader writes the provided status code in the response, and\n// updates relevant http error statistics.\nfunc (h *Handler) writeHeader(w http.ResponseWriter, code int) {\n\tswitch code / 100 {\n\tcase 4:\n\t\tatomic.AddInt64(&h.stats.ClientErrors, 1)\n\tcase 5:\n\t\tatomic.AddInt64(&h.stats.ServerErrors, 1)\n\t}\n\tw.WriteHeader(code)\n}\n\n// serveQuery parses an incoming query and, if valid, executes the query.\nfunc (h *Handler) serveQuery(w http.ResponseWriter, r *http.Request, user meta.User) {\n\tatomic.AddInt64(&h.stats.QueryRequests, 1)\n\tdefer func(start time.Time) {\n\t\tatomic.AddInt64(&h.stats.QueryRequestDuration, time.Since(start).Nanoseconds())\n\t}(time.Now())\n\th.requestTracker.Add(r, user)\n\n\t// Retrieve the underlying ResponseWriter or initialize our own.\n\trw, ok := w.(ResponseWriter)\n\tif !ok {\n\t\trw = NewResponseWriter(w, r)\n\t}\n\n\t// Retrieve the node id the query should be executed on.\n\tnodeID, _ := strconv.ParseUint(r.FormValue(\"node_id\"), 10, 64)\n\n\tvar qr io.Reader\n\t// Attempt to read the form value from the \"q\" form value.\n\tif qp := strings.TrimSpace(r.FormValue(\"q\")); qp != \"\" {\n\t\tqr = strings.NewReader(qp)\n\t} else if r.MultipartForm != nil && r.MultipartForm.File != nil {\n\t\t// If we have a multipart/form-data, try to retrieve a file from 'q'.\n\t\tif fhs := r.MultipartForm.File[\"q\"]; len(fhs) > 0 {\n\t\t\tf, err := fhs[0].Open()\n\t\t\tif err != nil {\n\t\t\t\th.httpError(rw, err.Error(), http.StatusBadRequest)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tdefer f.Close()\n\t\t\tqr = f\n\t\t}\n\t}\n\n\tif qr == nil {\n\t\th.httpError(rw, `missing required parameter \"q\"`, http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tepoch := strings.TrimSpace(r.FormValue(\"epoch\"))\n\n\tp := influxql.NewParser(qr)\n\tdb := r.FormValue(\"db\")\n\n\t// Sanitize the request query params so it doesn't show up in the response logger.\n\t// Do this before anything else so a parsing error doesn't leak passwords.\n\tsanitize(r)\n\n\t// Parse the parameters\n\trawParams := r.FormValue(\"params\")\n\tif rawParams != \"\" {\n\t\tvar params map[string]interface{}\n\t\tdecoder := json.NewDecoder(strings.NewReader(rawParams))\n\t\tdecoder.UseNumber()\n\t\tif err := decoder.Decode(&params); err != nil {\n\t\t\th.httpError(rw, \"error parsing query parameters: \"+err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\t// Convert json.Number into int64 and float64 values\n\t\tfor k, v := range params {\n\t\t\tif v, ok := v.(json.Number); ok {\n\t\t\t\tvar err error\n\t\t\t\tif strings.Contains(string(v), \".\") {\n\t\t\t\t\tparams[k], err = v.Float64()\n\t\t\t\t} else {\n\t\t\t\t\tparams[k], err = v.Int64()\n\t\t\t\t}\n\n\t\t\t\tif err != nil {\n\t\t\t\t\th.httpError(rw, \"error parsing json value: \"+err.Error(), http.StatusBadRequest)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tp.SetParams(params)\n\t}\n\n\t// Parse query from query string.\n\tq, err := p.ParseQuery()\n\tif err != nil {\n\t\th.httpError(rw, \"error parsing query: \"+err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\t// Check authorization.\n\tif h.Config.AuthEnabled {\n\t\tif err := h.QueryAuthorizer.AuthorizeQuery(user, q, db); err != nil {\n\t\t\tif err, ok := err.(meta.ErrAuthorize); ok {\n\t\t\t\th.Logger.Info(\"Unauthorized request\",\n\t\t\t\t\tzap.String(\"user\", err.User),\n\t\t\t\t\tzap.Stringer(\"query\", err.Query),\n\t\t\t\t\tlogger.Database(err.Database))\n\t\t\t}\n\t\t\th.httpError(rw, \"error authorizing query: \"+err.Error(), http.StatusForbidden)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Parse chunk size. Use default if not provided or unparsable.\n\tchunked := r.FormValue(\"chunked\") == \"true\"\n\tchunkSize := DefaultChunkSize\n\tif chunked {\n\t\tif n, err := strconv.ParseInt(r.FormValue(\"chunk_size\"), 10, 64); err == nil && int(n) > 0 {\n\t\t\tchunkSize = int(n)\n\t\t}\n\t}\n\n\t// Parse whether this is an async command.\n\tasync := r.FormValue(\"async\") == \"true\"\n\n\topts := query.ExecutionOptions{\n\t\tDatabase:        db,\n\t\tRetentionPolicy: r.FormValue(\"rp\"),\n\t\tChunkSize:       chunkSize,\n\t\tReadOnly:        r.Method == \"GET\",\n\t\tNodeID:          nodeID,\n\t}\n\n\tif h.Config.AuthEnabled {\n\t\tif user != nil && user.AuthorizeUnrestricted() {\n\t\t\topts.Authorizer = query.OpenAuthorizer\n\t\t} else {\n\t\t\t// The current user determines the authorized actions.\n\t\t\topts.Authorizer = user\n\t\t}\n\t} else {\n\t\t// Auth is disabled, so allow everything.\n\t\topts.Authorizer = query.OpenAuthorizer\n\t}\n\n\t// Make sure if the client disconnects we signal the query to abort\n\tvar closing chan struct{}\n\tif !async {\n\t\tclosing = make(chan struct{})\n\t\tif notifier, ok := w.(http.CloseNotifier); ok {\n\t\t\t// CloseNotify() is not guaranteed to send a notification when the query\n\t\t\t// is closed. Use this channel to signal that the query is finished to\n\t\t\t// prevent lingering goroutines that may be stuck.\n\t\t\tdone := make(chan struct{})\n\t\t\tdefer close(done)\n\n\t\t\tnotify := notifier.CloseNotify()\n\t\t\tgo func() {\n\t\t\t\t// Wait for either the request to finish\n\t\t\t\t// or for the client to disconnect\n\t\t\t\tselect {\n\t\t\t\tcase <-done:\n\t\t\t\tcase <-notify:\n\t\t\t\t\tclose(closing)\n\t\t\t\t}\n\t\t\t}()\n\t\t\topts.AbortCh = done\n\t\t} else {\n\t\t\tdefer close(closing)\n\t\t}\n\t}\n\n\t// Execute query.\n\tresults := h.QueryExecutor.ExecuteQuery(q, opts, closing)\n\n\t// If we are running in async mode, open a goroutine to drain the results\n\t// and return with a StatusNoContent.\n\tif async {\n\t\tgo h.async(q, results)\n\t\th.writeHeader(w, http.StatusNoContent)\n\t\treturn\n\t}\n\n\t// if we're not chunking, this will be the in memory buffer for all results before sending to client\n\tresp := Response{Results: make([]*query.Result, 0)}\n\n\t// Status header is OK once this point is reached.\n\t// Attempt to flush the header immediately so the client gets the header information\n\t// and knows the query was accepted.\n\th.writeHeader(rw, http.StatusOK)\n\tif w, ok := w.(http.Flusher); ok {\n\t\tw.Flush()\n\t}\n\n\t// pull all results from the channel\n\trows := 0\n\tfor r := range results {\n\t\t// Ignore nil results.\n\t\tif r == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\t// if requested, convert result timestamps to epoch\n\t\tif epoch != \"\" {\n\t\t\tconvertToEpoch(r, epoch)\n\t\t}\n\n\t\t// Write out result immediately if chunked.\n\t\tif chunked {\n\t\t\tn, _ := rw.WriteResponse(Response{\n\t\t\t\tResults: []*query.Result{r},\n\t\t\t})\n\t\t\tatomic.AddInt64(&h.stats.QueryRequestBytesTransmitted, int64(n))\n\t\t\tw.(http.Flusher).Flush()\n\t\t\tcontinue\n\t\t}\n\n\t\t// Limit the number of rows that can be returned in a non-chunked\n\t\t// response.  This is to prevent the server from going OOM when\n\t\t// returning a large response.  If you want to return more than the\n\t\t// default chunk size, then use chunking to process multiple blobs.\n\t\t// Iterate through the series in this result to count the rows and\n\t\t// truncate any rows we shouldn't return.\n\t\tif h.Config.MaxRowLimit > 0 {\n\t\t\tfor i, series := range r.Series {\n\t\t\t\tn := h.Config.MaxRowLimit - rows\n\t\t\t\tif n < len(series.Values) {\n\t\t\t\t\t// We have reached the maximum number of values. Truncate\n\t\t\t\t\t// the values within this row.\n\t\t\t\t\tseries.Values = series.Values[:n]\n\t\t\t\t\t// Since this was truncated, it will always be a partial return.\n\t\t\t\t\t// Add this so the client knows we truncated the response.\n\t\t\t\t\tseries.Partial = true\n\t\t\t\t}\n\t\t\t\trows += len(series.Values)\n\n\t\t\t\tif rows >= h.Config.MaxRowLimit {\n\t\t\t\t\t// Drop any remaining series since we have already reached the row limit.\n\t\t\t\t\tif i < len(r.Series) {\n\t\t\t\t\t\tr.Series = r.Series[:i+1]\n\t\t\t\t\t}\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// It's not chunked so buffer results in memory.\n\t\t// Results for statements need to be combined together.\n\t\t// We need to check if this new result is for the same statement as\n\t\t// the last result, or for the next statement\n\t\tl := len(resp.Results)\n\t\tif l == 0 {\n\t\t\tresp.Results = append(resp.Results, r)\n\t\t} else if resp.Results[l-1].StatementID == r.StatementID {\n\t\t\tif r.Err != nil {\n\t\t\t\tresp.Results[l-1] = r\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tcr := resp.Results[l-1]\n\t\t\trowsMerged := 0\n\t\t\tif len(cr.Series) > 0 {\n\t\t\t\tlastSeries := cr.Series[len(cr.Series)-1]\n\n\t\t\t\tfor _, row := range r.Series {\n\t\t\t\t\tif !lastSeries.SameSeries(row) {\n\t\t\t\t\t\t// Next row is for a different series than last.\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t\t// Values are for the same series, so append them.\n\t\t\t\t\tlastSeries.Values = append(lastSeries.Values, row.Values...)\n\t\t\t\t\trowsMerged++\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Append remaining rows as new rows.\n\t\t\tr.Series = r.Series[rowsMerged:]\n\t\t\tcr.Series = append(cr.Series, r.Series...)\n\t\t\tcr.Messages = append(cr.Messages, r.Messages...)\n\t\t\tcr.Partial = r.Partial\n\t\t} else {\n\t\t\tresp.Results = append(resp.Results, r)\n\t\t}\n\n\t\t// Drop out of this loop and do not process further results when we hit the row limit.\n\t\tif h.Config.MaxRowLimit > 0 && rows >= h.Config.MaxRowLimit {\n\t\t\t// If the result is marked as partial, remove that partial marking\n\t\t\t// here. While the series is partial and we would normally have\n\t\t\t// tried to return the rest in the next chunk, we are not using\n\t\t\t// chunking and are truncating the series so we don't want to\n\t\t\t// signal to the client that we plan on sending another JSON blob\n\t\t\t// with another result.  The series, on the other hand, still\n\t\t\t// returns partial true if it was truncated or had more data to\n\t\t\t// send in a future chunk.\n\t\t\tr.Partial = false\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// If it's not chunked we buffered everything in memory, so write it out\n\tif !chunked {\n\t\tn, _ := rw.WriteResponse(resp)\n\t\tatomic.AddInt64(&h.stats.QueryRequestBytesTransmitted, int64(n))\n\t}\n}\n\n// async drains the results from an async query and logs a message if it fails.\nfunc (h *Handler) async(q *influxql.Query, results <-chan *query.Result) {\n\tfor r := range results {\n\t\t// Drain the results and do nothing with them.\n\t\t// If it fails, log the failure so there is at least a record of it.\n\t\tif r.Err != nil {\n\t\t\t// Do not log when a statement was not executed since there would\n\t\t\t// have been an earlier error that was already logged.\n\t\t\tif r.Err == query.ErrNotExecuted {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\th.Logger.Info(\"Error while running async query\",\n\t\t\t\tzap.Stringer(\"query\", q),\n\t\t\t\tzap.Error(r.Err))\n\t\t}\n\t}\n}\n\n// serveWrite receives incoming series data in line protocol format and writes it to the database.\nfunc (h *Handler) serveWrite(w http.ResponseWriter, r *http.Request, user meta.User) {\n\tatomic.AddInt64(&h.stats.WriteRequests, 1)\n\tatomic.AddInt64(&h.stats.ActiveWriteRequests, 1)\n\tdefer func(start time.Time) {\n\t\tatomic.AddInt64(&h.stats.ActiveWriteRequests, -1)\n\t\tatomic.AddInt64(&h.stats.WriteRequestDuration, time.Since(start).Nanoseconds())\n\t}(time.Now())\n\th.requestTracker.Add(r, user)\n\n\tdatabase := r.URL.Query().Get(\"db\")\n\tif database == \"\" {\n\t\th.httpError(w, \"database is required\", http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tif di := h.MetaClient.Database(database); di == nil {\n\t\th.httpError(w, fmt.Sprintf(\"database not found: %q\", database), http.StatusNotFound)\n\t\treturn\n\t}\n\n\tif h.Config.AuthEnabled {\n\t\tif user == nil {\n\t\t\th.httpError(w, fmt.Sprintf(\"user is required to write to database %q\", database), http.StatusForbidden)\n\t\t\treturn\n\t\t}\n\n\t\tif err := h.WriteAuthorizer.AuthorizeWrite(user.ID(), database); err != nil {\n\t\t\th.httpError(w, fmt.Sprintf(\"%q user is not authorized to write to database %q\", user.ID(), database), http.StatusForbidden)\n\t\t\treturn\n\t\t}\n\t}\n\n\tbody := r.Body\n\tif h.Config.MaxBodySize > 0 {\n\t\tbody = truncateReader(body, int64(h.Config.MaxBodySize))\n\t}\n\n\t// Handle gzip decoding of the body\n\tif r.Header.Get(\"Content-Encoding\") == \"gzip\" {\n\t\tb, err := gzip.NewReader(r.Body)\n\t\tif err != nil {\n\t\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\tdefer b.Close()\n\t\tbody = b\n\t}\n\n\tvar bs []byte\n\tif r.ContentLength > 0 {\n\t\tif h.Config.MaxBodySize > 0 && r.ContentLength > int64(h.Config.MaxBodySize) {\n\t\t\th.httpError(w, http.StatusText(http.StatusRequestEntityTooLarge), http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\n\t\t// This will just be an initial hint for the gzip reader, as the\n\t\t// bytes.Buffer will grow as needed when ReadFrom is called\n\t\tbs = make([]byte, 0, r.ContentLength)\n\t}\n\tbuf := bytes.NewBuffer(bs)\n\n\t_, err := buf.ReadFrom(body)\n\tif err != nil {\n\t\tif err == errTruncated {\n\t\t\th.httpError(w, http.StatusText(http.StatusRequestEntityTooLarge), http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\n\t\tif h.Config.WriteTracing {\n\t\t\th.Logger.Info(\"Write handler unable to read bytes from request body\")\n\t\t}\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\tatomic.AddInt64(&h.stats.WriteRequestBytesReceived, int64(buf.Len()))\n\n\tif h.Config.WriteTracing {\n\t\th.Logger.Info(\"Write body received by handler\", zap.ByteString(\"body\", buf.Bytes()))\n\t}\n\n\tpoints, parseError := models.ParsePointsWithPrecision(buf.Bytes(), time.Now().UTC(), r.URL.Query().Get(\"precision\"))\n\t// Not points parsed correctly so return the error now\n\tif parseError != nil && len(points) == 0 {\n\t\tif parseError.Error() == \"EOF\" {\n\t\t\th.writeHeader(w, http.StatusOK)\n\t\t\treturn\n\t\t}\n\t\th.httpError(w, parseError.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\t// Determine required consistency level.\n\tlevel := r.URL.Query().Get(\"consistency\")\n\tconsistency := models.ConsistencyLevelOne\n\tif level != \"\" {\n\t\tvar err error\n\t\tconsistency, err = models.ParseConsistencyLevel(level)\n\t\tif err != nil {\n\t\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Write points.\n\tif err := h.PointsWriter.WritePoints(database, r.URL.Query().Get(\"rp\"), consistency, user, points); influxdb.IsClientError(err) {\n\t\tatomic.AddInt64(&h.stats.PointsWrittenFail, int64(len(points)))\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t} else if influxdb.IsAuthorizationError(err) {\n\t\tatomic.AddInt64(&h.stats.PointsWrittenFail, int64(len(points)))\n\t\th.httpError(w, err.Error(), http.StatusForbidden)\n\t\treturn\n\t} else if werr, ok := err.(tsdb.PartialWriteError); ok {\n\t\tatomic.AddInt64(&h.stats.PointsWrittenOK, int64(len(points)-werr.Dropped))\n\t\tatomic.AddInt64(&h.stats.PointsWrittenDropped, int64(werr.Dropped))\n\t\th.httpError(w, werr.Error(), http.StatusBadRequest)\n\t\treturn\n\t} else if err != nil {\n\t\tatomic.AddInt64(&h.stats.PointsWrittenFail, int64(len(points)))\n\t\th.httpError(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t} else if parseError != nil {\n\t\t// We wrote some of the points\n\t\tatomic.AddInt64(&h.stats.PointsWrittenOK, int64(len(points)))\n\t\t// The other points failed to parse which means the client sent invalid line protocol.  We return a 400\n\t\t// response code as well as the lines that failed to parse.\n\t\th.httpError(w, tsdb.PartialWriteError{Reason: parseError.Error()}.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tatomic.AddInt64(&h.stats.PointsWrittenOK, int64(len(points)))\n\th.writeHeader(w, http.StatusNoContent)\n}\n\n// serveOptions returns an empty response to comply with OPTIONS pre-flight requests\nfunc (h *Handler) serveOptions(w http.ResponseWriter, r *http.Request) {\n\th.writeHeader(w, http.StatusNoContent)\n}\n\n// servePing returns a simple response to let the client know the server is running.\nfunc (h *Handler) servePing(w http.ResponseWriter, r *http.Request) {\n\tverbose := r.URL.Query().Get(\"verbose\")\n\tatomic.AddInt64(&h.stats.PingRequests, 1)\n\n\tif verbose != \"\" && verbose != \"0\" && verbose != \"false\" {\n\t\th.writeHeader(w, http.StatusOK)\n\t\tb, _ := json.Marshal(map[string]string{\"version\": h.Version})\n\t\tw.Write(b)\n\t} else {\n\t\th.writeHeader(w, http.StatusNoContent)\n\t}\n}\n\n// serveStatus has been deprecated.\nfunc (h *Handler) serveStatus(w http.ResponseWriter, r *http.Request) {\n\th.Logger.Info(\"WARNING: /status has been deprecated.  Use /ping instead.\")\n\tatomic.AddInt64(&h.stats.StatusRequests, 1)\n\th.writeHeader(w, http.StatusNoContent)\n}\n\n// convertToEpoch converts result timestamps from time.Time to the specified epoch.\nfunc convertToEpoch(r *query.Result, epoch string) {\n\tdivisor := int64(1)\n\n\tswitch epoch {\n\tcase \"u\":\n\t\tdivisor = int64(time.Microsecond)\n\tcase \"ms\":\n\t\tdivisor = int64(time.Millisecond)\n\tcase \"s\":\n\t\tdivisor = int64(time.Second)\n\tcase \"m\":\n\t\tdivisor = int64(time.Minute)\n\tcase \"h\":\n\t\tdivisor = int64(time.Hour)\n\t}\n\n\tfor _, s := range r.Series {\n\t\tfor _, v := range s.Values {\n\t\t\tif ts, ok := v[0].(time.Time); ok {\n\t\t\t\tv[0] = ts.UnixNano() / divisor\n\t\t\t}\n\t\t}\n\t}\n}\n\n// servePromWrite receives data in the Prometheus remote write protocol and writes it\n// to the database\nfunc (h *Handler) servePromWrite(w http.ResponseWriter, r *http.Request, user meta.User) {\n\tatomic.AddInt64(&h.stats.WriteRequests, 1)\n\tatomic.AddInt64(&h.stats.ActiveWriteRequests, 1)\n\tatomic.AddInt64(&h.stats.PromWriteRequests, 1)\n\tdefer func(start time.Time) {\n\t\tatomic.AddInt64(&h.stats.ActiveWriteRequests, -1)\n\t\tatomic.AddInt64(&h.stats.WriteRequestDuration, time.Since(start).Nanoseconds())\n\t}(time.Now())\n\th.requestTracker.Add(r, user)\n\n\tdatabase := r.URL.Query().Get(\"db\")\n\tif database == \"\" {\n\t\th.httpError(w, \"database is required\", http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tif di := h.MetaClient.Database(database); di == nil {\n\t\th.httpError(w, fmt.Sprintf(\"database not found: %q\", database), http.StatusNotFound)\n\t\treturn\n\t}\n\n\tif h.Config.AuthEnabled {\n\t\tif user == nil {\n\t\t\th.httpError(w, fmt.Sprintf(\"user is required to write to database %q\", database), http.StatusForbidden)\n\t\t\treturn\n\t\t}\n\n\t\tif err := h.WriteAuthorizer.AuthorizeWrite(user.ID(), database); err != nil {\n\t\t\th.httpError(w, fmt.Sprintf(\"%q user is not authorized to write to database %q\", user.ID(), database), http.StatusForbidden)\n\t\t\treturn\n\t\t}\n\t}\n\n\tbody := r.Body\n\tif h.Config.MaxBodySize > 0 {\n\t\tbody = truncateReader(body, int64(h.Config.MaxBodySize))\n\t}\n\n\tvar bs []byte\n\tif r.ContentLength > 0 {\n\t\tif h.Config.MaxBodySize > 0 && r.ContentLength > int64(h.Config.MaxBodySize) {\n\t\t\th.httpError(w, http.StatusText(http.StatusRequestEntityTooLarge), http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\n\t\t// This will just be an initial hint for the reader, as the\n\t\t// bytes.Buffer will grow as needed when ReadFrom is called\n\t\tbs = make([]byte, 0, r.ContentLength)\n\t}\n\tbuf := bytes.NewBuffer(bs)\n\n\t_, err := buf.ReadFrom(body)\n\tif err != nil {\n\t\tif err == errTruncated {\n\t\t\th.httpError(w, http.StatusText(http.StatusRequestEntityTooLarge), http.StatusRequestEntityTooLarge)\n\t\t\treturn\n\t\t}\n\n\t\tif h.Config.WriteTracing {\n\t\t\th.Logger.Info(\"Prom write handler unable to read bytes from request body\")\n\t\t}\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\tatomic.AddInt64(&h.stats.WriteRequestBytesReceived, int64(buf.Len()))\n\n\tif h.Config.WriteTracing {\n\t\th.Logger.Info(\"Prom write body received by handler\", zap.ByteString(\"body\", buf.Bytes()))\n\t}\n\n\treqBuf, err := snappy.Decode(nil, buf.Bytes())\n\tif err != nil {\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\t// Convert the Prometheus remote write request to Influx Points\n\tvar req remote.WriteRequest\n\tif err := proto.Unmarshal(reqBuf, &req); err != nil {\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tpoints, err := prometheus.WriteRequestToPoints(&req)\n\tif err != nil {\n\t\tif h.Config.WriteTracing {\n\t\t\th.Logger.Info(\"Prom write handler\", zap.Error(err))\n\t\t}\n\n\t\tif err != prometheus.ErrNaNDropped {\n\t\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Determine required consistency level.\n\tlevel := r.URL.Query().Get(\"consistency\")\n\tconsistency := models.ConsistencyLevelOne\n\tif level != \"\" {\n\t\tconsistency, err = models.ParseConsistencyLevel(level)\n\t\tif err != nil {\n\t\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Write points.\n\tif err := h.PointsWriter.WritePoints(database, r.URL.Query().Get(\"rp\"), consistency, user, points); influxdb.IsClientError(err) {\n\t\tatomic.AddInt64(&h.stats.PointsWrittenFail, int64(len(points)))\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t} else if influxdb.IsAuthorizationError(err) {\n\t\tatomic.AddInt64(&h.stats.PointsWrittenFail, int64(len(points)))\n\t\th.httpError(w, err.Error(), http.StatusForbidden)\n\t\treturn\n\t} else if werr, ok := err.(tsdb.PartialWriteError); ok {\n\t\tatomic.AddInt64(&h.stats.PointsWrittenOK, int64(len(points)-werr.Dropped))\n\t\tatomic.AddInt64(&h.stats.PointsWrittenDropped, int64(werr.Dropped))\n\t\th.httpError(w, werr.Error(), http.StatusBadRequest)\n\t\treturn\n\t} else if err != nil {\n\t\tatomic.AddInt64(&h.stats.PointsWrittenFail, int64(len(points)))\n\t\th.httpError(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\tatomic.AddInt64(&h.stats.PointsWrittenOK, int64(len(points)))\n\th.writeHeader(w, http.StatusNoContent)\n}\n\n// servePromRead will convert a Prometheus remote read request into a storage\n// query and returns data in Prometheus remote read protobuf format.\nfunc (h *Handler) servePromRead(w http.ResponseWriter, r *http.Request, user meta.User) {\n\tcompressed, err := ioutil.ReadAll(r.Body)\n\tif err != nil {\n\t\th.httpError(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\treqBuf, err := snappy.Decode(nil, compressed)\n\tif err != nil {\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tvar req remote.ReadRequest\n\tif err := proto.Unmarshal(reqBuf, &req); err != nil {\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\t// Query the DB and create a ReadResponse for Prometheus\n\tdb := r.FormValue(\"db\")\n\trp := r.FormValue(\"rp\")\n\n\treadRequest, err := prometheus.ReadRequestToInfluxStorageRequest(&req, db, rp)\n\tif err != nil {\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tctx := context.Background()\n\trs, err := h.Store.Read(ctx, readRequest)\n\tif err != nil {\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\tdefer rs.Close()\n\n\tresp := &remote.ReadResponse{\n\t\tResults: []*remote.QueryResult{{}},\n\t}\n\tfor rs.Next() {\n\t\tcur := rs.Cursor()\n\t\tif cur == nil {\n\t\t\t// no data for series key + field combination\n\t\t\tcontinue\n\t\t}\n\n\t\ttags := prometheus.RemoveInfluxSystemTags(rs.Tags())\n\t\tvar unsupportedCursor string\n\t\tswitch cur := cur.(type) {\n\t\tcase tsdb.FloatArrayCursor:\n\t\t\tvar series *remote.TimeSeries\n\t\t\tfor {\n\t\t\t\ta := cur.Next()\n\t\t\t\tif a.Len() == 0 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\n\t\t\t\t// We have some data for this series.\n\t\t\t\tif series == nil {\n\t\t\t\t\tseries = &remote.TimeSeries{\n\t\t\t\t\t\tLabels: prometheus.ModelTagsToLabelPairs(tags),\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tfor i, ts := range a.Timestamps {\n\t\t\t\t\tseries.Samples = append(series.Samples, &remote.Sample{\n\t\t\t\t\t\tTimestampMs: ts / int64(time.Millisecond),\n\t\t\t\t\t\tValue:       a.Values[i],\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// There was data for the series.\n\t\t\tif series != nil {\n\t\t\t\tresp.Results[0].Timeseries = append(resp.Results[0].Timeseries, series)\n\t\t\t}\n\t\tcase tsdb.IntegerArrayCursor:\n\t\t\tunsupportedCursor = \"int64\"\n\t\tcase tsdb.UnsignedArrayCursor:\n\t\t\tunsupportedCursor = \"uint\"\n\t\tcase tsdb.BooleanArrayCursor:\n\t\t\tunsupportedCursor = \"bool\"\n\t\tcase tsdb.StringArrayCursor:\n\t\t\tunsupportedCursor = \"string\"\n\t\tdefault:\n\t\t\tpanic(fmt.Sprintf(\"unreachable: %T\", cur))\n\t\t}\n\t\tcur.Close()\n\n\t\tif len(unsupportedCursor) > 0 {\n\t\t\th.Logger.Info(\"Prometheus can't read cursor\",\n\t\t\t\tzap.String(\"cursor_type\", unsupportedCursor),\n\t\t\t\tzap.Stringer(\"series\", tags),\n\t\t\t)\n\t\t}\n\t}\n\tdata, err := proto.Marshal(resp)\n\tif err != nil {\n\t\th.httpError(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\tw.Header().Set(\"Content-Type\", \"application/x-protobuf\")\n\tw.Header().Set(\"Content-Encoding\", \"snappy\")\n\n\tcompressed = snappy.Encode(nil, data)\n\tif _, err := w.Write(compressed); err != nil {\n\t\th.httpError(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\tatomic.AddInt64(&h.stats.QueryRequestBytesTransmitted, int64(len(compressed)))\n}\n\nfunc (h *Handler) serveFluxQuery(w http.ResponseWriter, r *http.Request, user meta.User) {\n\tatomic.AddInt64(&h.stats.FluxQueryRequests, 1)\n\tdefer func(start time.Time) {\n\t\tatomic.AddInt64(&h.stats.FluxQueryRequestDuration, time.Since(start).Nanoseconds())\n\t}(time.Now())\n\n\treq, err := decodeQueryRequest(r)\n\tif err != nil {\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tctx := r.Context()\n\tif val := r.FormValue(\"node_id\"); val != \"\" {\n\t\tif nodeID, err := strconv.ParseUint(val, 10, 64); err == nil {\n\t\t\tctx = storage.NewContextWithReadOptions(ctx, &storage.ReadOptions{NodeID: nodeID})\n\t\t}\n\t}\n\n\tif h.Config.AuthEnabled {\n\t\tctx = meta.NewContextWithUser(ctx, user)\n\t}\n\n\tpr := req.ProxyRequest()\n\n\t// Logging\n\tvar (\n\t\tstats flux.Statistics\n\t\tn     int64\n\t)\n\tif h.Config.FluxLogEnabled {\n\t\tdefer func() {\n\t\t\th.logFluxQuery(n, stats, pr.Compiler, err)\n\t\t}()\n\t}\n\n\tq, err := h.Controller.Query(ctx, pr.Compiler)\n\tif err != nil {\n\t\th.httpError(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\tdefer func() {\n\t\tq.Cancel()\n\t\tq.Done()\n\t}()\n\n\t// NOTE: We do not write out the headers here.\n\t// It is possible that if the encoding step fails\n\t// that we can write an error header so long as\n\t// the encoder did not write anything.\n\t// As such we rely on the http.ResponseWriter behavior\n\t// to write an StatusOK header with the first write.\n\n\tswitch r.Header.Get(\"Accept\") {\n\tcase \"text/csv\":\n\t\tfallthrough\n\tdefault:\n\t\tif hd, ok := pr.Dialect.(httpDialect); !ok {\n\t\t\th.httpError(w, fmt.Sprintf(\"unsupported dialect over HTTP %T\", req.Dialect), http.StatusBadRequest)\n\t\t\treturn\n\t\t} else {\n\t\t\thd.SetHeaders(w)\n\t\t}\n\t\tencoder := pr.Dialect.Encoder()\n\t\tresults := flux.NewResultIteratorFromQuery(q)\n\t\tif h.Config.FluxLogEnabled {\n\t\t\tdefer func() {\n\t\t\t\tstats = results.Statistics()\n\t\t\t}()\n\t\t}\n\t\tdefer results.Release()\n\n\t\tn, err = encoder.Encode(w, results)\n\t\tif err != nil {\n\t\t\tif n == 0 {\n\t\t\t\t// If the encoder did not write anything, we can write an error header.\n\t\t\t\th.httpError(w, err.Error(), http.StatusInternalServerError)\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc (h *Handler) logFluxQuery(n int64, stats flux.Statistics, compiler flux.Compiler, err error) {\n\tvar q string\n\tswitch c := compiler.(type) {\n\tcase lang.SpecCompiler:\n\t\tq = fmt.Sprint(flux.Formatted(c.Spec))\n\tcase lang.FluxCompiler:\n\t\tq = c.Query\n\t}\n\n\th.Logger.Info(\"Executed Flux query\",\n\t\tzap.String(\"compiler_type\", string(compiler.CompilerType())),\n\t\tzap.Int64(\"response_size\", n),\n\t\tzap.String(\"query\", q),\n\t\tzap.Error(err),\n\t\tzap.Duration(\"stat_total_duration\", stats.TotalDuration),\n\t\tzap.Duration(\"stat_compile_duration\", stats.CompileDuration),\n\t\tzap.Duration(\"stat_queue_duration\", stats.QueueDuration),\n\t\tzap.Duration(\"stat_plan_duration\", stats.PlanDuration),\n\t\tzap.Duration(\"stat_requeue_duration\", stats.RequeueDuration),\n\t\tzap.Duration(\"stat_execute_duration\", stats.ExecuteDuration),\n\t\tzap.Int64(\"stat_max_allocated\", stats.MaxAllocated),\n\t\tzap.Int(\"stat_concurrency\", stats.Concurrency),\n\t)\n}\n\n// serveExpvar serves internal metrics in /debug/vars format over HTTP.\nfunc (h *Handler) serveExpvar(w http.ResponseWriter, r *http.Request) {\n\t// Retrieve statistics from the monitor.\n\tstats, err := h.Monitor.Statistics(nil)\n\tif err != nil {\n\t\th.httpError(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\t// Retrieve diagnostics from the monitor.\n\tdiags, err := h.Monitor.Diagnostics()\n\tif err != nil {\n\t\th.httpError(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\tw.Header().Set(\"Content-Type\", \"application/json; charset=utf-8\")\n\n\tfirst := true\n\tif val := diags[\"system\"]; val != nil {\n\t\tjv, err := parseSystemDiagnostics(val)\n\t\tif err != nil {\n\t\t\th.httpError(w, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\tdata, err := json.Marshal(jv)\n\t\tif err != nil {\n\t\t\th.httpError(w, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\tfirst = false\n\t\tfmt.Fprintln(w, \"{\")\n\t\tfmt.Fprintf(w, \"\\\"system\\\": %s\", data)\n\t} else {\n\t\tfmt.Fprintln(w, \"{\")\n\t}\n\n\tif val := expvar.Get(\"cmdline\"); val != nil {\n\t\tif !first {\n\t\t\tfmt.Fprintln(w, \",\")\n\t\t}\n\t\tfirst = false\n\t\tfmt.Fprintf(w, \"\\\"cmdline\\\": %s\", val)\n\t}\n\tif val := expvar.Get(\"memstats\"); val != nil {\n\t\tif !first {\n\t\t\tfmt.Fprintln(w, \",\")\n\t\t}\n\t\tfirst = false\n\t\tfmt.Fprintf(w, \"\\\"memstats\\\": %s\", val)\n\t}\n\n\tfor _, s := range stats {\n\t\tval, err := json.Marshal(s)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Very hackily create a unique key.\n\t\tbuf := bytes.NewBufferString(s.Name)\n\t\tif path, ok := s.Tags[\"path\"]; ok {\n\t\t\tfmt.Fprintf(buf, \":%s\", path)\n\t\t\tif id, ok := s.Tags[\"id\"]; ok {\n\t\t\t\tfmt.Fprintf(buf, \":%s\", id)\n\t\t\t}\n\t\t} else if bind, ok := s.Tags[\"bind\"]; ok {\n\t\t\tif proto, ok := s.Tags[\"proto\"]; ok {\n\t\t\t\tfmt.Fprintf(buf, \":%s\", proto)\n\t\t\t}\n\t\t\tfmt.Fprintf(buf, \":%s\", bind)\n\t\t} else if database, ok := s.Tags[\"database\"]; ok {\n\t\t\tfmt.Fprintf(buf, \":%s\", database)\n\t\t\tif rp, ok := s.Tags[\"retention_policy\"]; ok {\n\t\t\t\tfmt.Fprintf(buf, \":%s\", rp)\n\t\t\t\tif name, ok := s.Tags[\"name\"]; ok {\n\t\t\t\t\tfmt.Fprintf(buf, \":%s\", name)\n\t\t\t\t}\n\t\t\t\tif dest, ok := s.Tags[\"destination\"]; ok {\n\t\t\t\t\tfmt.Fprintf(buf, \":%s\", dest)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tkey := buf.String()\n\n\t\tif !first {\n\t\t\tfmt.Fprintln(w, \",\")\n\t\t}\n\t\tfirst = false\n\t\tfmt.Fprintf(w, \"%q: \", key)\n\t\tw.Write(bytes.TrimSpace(val))\n\t}\n\tfmt.Fprintln(w, \"\\n}\")\n}\n\n// serveDebugRequests will track requests for a period of time.\nfunc (h *Handler) serveDebugRequests(w http.ResponseWriter, r *http.Request) {\n\tvar d time.Duration\n\tif s := r.URL.Query().Get(\"seconds\"); s == \"\" {\n\t\td = DefaultDebugRequestsInterval\n\t} else if seconds, err := strconv.ParseInt(s, 10, 64); err != nil {\n\t\th.httpError(w, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t} else {\n\t\td = time.Duration(seconds) * time.Second\n\t\tif d > MaxDebugRequestsInterval {\n\t\t\th.httpError(w, fmt.Sprintf(\"exceeded maximum interval time: %s > %s\",\n\t\t\t\tinfluxql.FormatDuration(d),\n\t\t\t\tinfluxql.FormatDuration(MaxDebugRequestsInterval)),\n\t\t\t\thttp.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t}\n\n\tvar closing <-chan bool\n\tif notifier, ok := w.(http.CloseNotifier); ok {\n\t\tclosing = notifier.CloseNotify()\n\t}\n\n\tprofile := h.requestTracker.TrackRequests()\n\n\ttimer := time.NewTimer(d)\n\tselect {\n\tcase <-timer.C:\n\t\tprofile.Stop()\n\tcase <-closing:\n\t\t// Connection was closed early.\n\t\tprofile.Stop()\n\t\ttimer.Stop()\n\t\treturn\n\t}\n\n\tw.Header().Set(\"Content-Type\", \"application/json; charset=utf-8\")\n\tw.Header().Add(\"Connection\", \"close\")\n\n\tfmt.Fprintln(w, \"{\")\n\tfirst := true\n\tfor req, st := range profile.Requests {\n\t\tval, err := json.Marshal(st)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tif !first {\n\t\t\tfmt.Fprintln(w, \",\")\n\t\t}\n\t\tfirst = false\n\t\tfmt.Fprintf(w, \"%q: \", req.String())\n\t\tw.Write(bytes.TrimSpace(val))\n\t}\n\tfmt.Fprintln(w, \"\\n}\")\n}\n\n// parseSystemDiagnostics converts the system diagnostics into an appropriate\n// format for marshaling to JSON in the /debug/vars format.\nfunc parseSystemDiagnostics(d *diagnostics.Diagnostics) (map[string]interface{}, error) {\n\t// We don't need PID in this case.\n\tm := map[string]interface{}{\"currentTime\": nil, \"started\": nil, \"uptime\": nil}\n\tfor key := range m {\n\t\t// Find the associated column.\n\t\tci := -1\n\t\tfor i, col := range d.Columns {\n\t\t\tif col == key {\n\t\t\t\tci = i\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif ci == -1 {\n\t\t\treturn nil, fmt.Errorf(\"unable to find column %q\", key)\n\t\t}\n\n\t\tif len(d.Rows) < 1 || len(d.Rows[0]) <= ci {\n\t\t\treturn nil, fmt.Errorf(\"no data for column %q\", key)\n\t\t}\n\n\t\tvar res interface{}\n\t\tswitch v := d.Rows[0][ci].(type) {\n\t\tcase time.Time:\n\t\t\tres = v\n\t\tcase string:\n\t\t\t// Should be a string representation of a time.Duration\n\t\t\td, err := time.ParseDuration(v)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tres = int64(d.Seconds())\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"value for column %q is not parsable (got %T)\", key, v)\n\t\t}\n\t\tm[key] = res\n\t}\n\treturn m, nil\n}\n\n// httpError writes an error to the client in a standard format.\nfunc (h *Handler) httpError(w http.ResponseWriter, errmsg string, code int) {\n\tif code == http.StatusUnauthorized {\n\t\t// If an unauthorized header will be sent back, add a WWW-Authenticate header\n\t\t// as an authorization challenge.\n\t\tw.Header().Set(\"WWW-Authenticate\", fmt.Sprintf(\"Basic realm=\\\"%s\\\"\", h.Config.Realm))\n\t} else if code/100 != 2 {\n\t\tsz := math.Min(float64(len(errmsg)), 1024.0)\n\t\tw.Header().Set(\"X-InfluxDB-Error\", errmsg[:int(sz)])\n\t}\n\n\tresponse := Response{Err: errors.New(errmsg)}\n\tif rw, ok := w.(ResponseWriter); ok {\n\t\th.writeHeader(w, code)\n\t\trw.WriteResponse(response)\n\t\treturn\n\t}\n\n\t// Default implementation if the response writer hasn't been replaced\n\t// with our special response writer type.\n\tw.Header().Add(\"Content-Type\", \"application/json\")\n\th.writeHeader(w, code)\n\tb, _ := json.Marshal(response)\n\tw.Write(b)\n}\n\n// Filters and filter helpers\n\ntype credentials struct {\n\tMethod   AuthenticationMethod\n\tUsername string\n\tPassword string\n\tToken    string\n}\n\nfunc parseToken(token string) (user, pass string, ok bool) {\n\ts := strings.IndexByte(token, ':')\n\tif s < 0 {\n\t\treturn\n\t}\n\treturn token[:s], token[s+1:], true\n}\n\n// parseCredentials parses a request and returns the authentication credentials.\n// The credentials may be present as URL query params, or as a Basic\n// Authentication header.\n// As params: http://127.0.0.1/query?u=username&p=password\n// As basic auth: http://username:password@127.0.0.1\n// As Bearer token in Authorization header: Bearer <JWT_TOKEN_BLOB>\n// As Token in Authorization header: Token <username:password>\nfunc parseCredentials(r *http.Request) (*credentials, error) {\n\tq := r.URL.Query()\n\n\t// Check for username and password in URL params.\n\tif u, p := q.Get(\"u\"), q.Get(\"p\"); u != \"\" && p != \"\" {\n\t\treturn &credentials{\n\t\t\tMethod:   UserAuthentication,\n\t\t\tUsername: u,\n\t\t\tPassword: p,\n\t\t}, nil\n\t}\n\n\t// Check for the HTTP Authorization header.\n\tif s := r.Header.Get(\"Authorization\"); s != \"\" {\n\t\t// Check for Bearer token.\n\t\tstrs := strings.Split(s, \" \")\n\t\tif len(strs) == 2 {\n\t\t\tswitch strs[0] {\n\t\t\tcase \"Bearer\":\n\t\t\t\treturn &credentials{\n\t\t\t\t\tMethod: BearerAuthentication,\n\t\t\t\t\tToken:  strs[1],\n\t\t\t\t}, nil\n\t\t\tcase \"Token\":\n\t\t\t\tif u, p, ok := parseToken(strs[1]); ok {\n\t\t\t\t\treturn &credentials{\n\t\t\t\t\t\tMethod:   UserAuthentication,\n\t\t\t\t\t\tUsername: u,\n\t\t\t\t\t\tPassword: p,\n\t\t\t\t\t}, nil\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Check for basic auth.\n\t\tif u, p, ok := r.BasicAuth(); ok {\n\t\t\treturn &credentials{\n\t\t\t\tMethod:   UserAuthentication,\n\t\t\t\tUsername: u,\n\t\t\t\tPassword: p,\n\t\t\t}, nil\n\t\t}\n\t}\n\n\treturn nil, fmt.Errorf(\"unable to parse authentication credentials\")\n}\n\n// authenticate wraps a handler and ensures that if user credentials are passed in\n// an attempt is made to authenticate that user. If authentication fails, an error is returned.\n//\n// There is one exception: if there are no users in the system, authentication is not required. This\n// is to facilitate bootstrapping of a system with authentication enabled.\nfunc authenticate(inner func(http.ResponseWriter, *http.Request, meta.User), h *Handler, requireAuthentication bool) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t// Return early if we are not authenticating\n\t\tif !requireAuthentication {\n\t\t\tinner(w, r, nil)\n\t\t\treturn\n\t\t}\n\t\tvar user meta.User\n\n\t\t// TODO corylanou: never allow this in the future without users\n\t\tif requireAuthentication && h.MetaClient.AdminUserExists() {\n\t\t\tcreds, err := parseCredentials(r)\n\t\t\tif err != nil {\n\t\t\t\tatomic.AddInt64(&h.stats.AuthenticationFailures, 1)\n\t\t\t\th.httpError(w, err.Error(), http.StatusUnauthorized)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tswitch creds.Method {\n\t\t\tcase UserAuthentication:\n\t\t\t\tif creds.Username == \"\" {\n\t\t\t\t\tatomic.AddInt64(&h.stats.AuthenticationFailures, 1)\n\t\t\t\t\th.httpError(w, \"username required\", http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tuser, err = h.MetaClient.Authenticate(creds.Username, creds.Password)\n\t\t\t\tif err != nil {\n\t\t\t\t\tatomic.AddInt64(&h.stats.AuthenticationFailures, 1)\n\t\t\t\t\th.httpError(w, \"authorization failed\", http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\tcase BearerAuthentication:\n\t\t\t\tif h.Config.SharedSecret == \"\" {\n\t\t\t\t\tatomic.AddInt64(&h.stats.AuthenticationFailures, 1)\n\t\t\t\t\th.httpError(w, \"bearer auth disabled\", http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tkeyLookupFn := func(token *jwt.Token) (interface{}, error) {\n\t\t\t\t\t// Check for expected signing method.\n\t\t\t\t\tif _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok {\n\t\t\t\t\t\treturn nil, fmt.Errorf(\"unexpected signing method: %v\", token.Header[\"alg\"])\n\t\t\t\t\t}\n\t\t\t\t\treturn []byte(h.Config.SharedSecret), nil\n\t\t\t\t}\n\n\t\t\t\t// Parse and validate the token.\n\t\t\t\ttoken, err := jwt.Parse(creds.Token, keyLookupFn)\n\t\t\t\tif err != nil {\n\t\t\t\t\th.httpError(w, err.Error(), http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t} else if !token.Valid {\n\t\t\t\t\th.httpError(w, \"invalid token\", http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tclaims, ok := token.Claims.(jwt.MapClaims)\n\t\t\t\tif !ok {\n\t\t\t\t\th.httpError(w, \"problem authenticating token\", http.StatusInternalServerError)\n\t\t\t\t\th.Logger.Info(\"Could not assert JWT token claims as jwt.MapClaims\")\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\t// Make sure an expiration was set on the token.\n\t\t\t\tif exp, ok := claims[\"exp\"].(float64); !ok || exp <= 0.0 {\n\t\t\t\t\th.httpError(w, \"token expiration required\", http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\t// Get the username from the token.\n\t\t\t\tusername, ok := claims[\"username\"].(string)\n\t\t\t\tif !ok {\n\t\t\t\t\th.httpError(w, \"username in token must be a string\", http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t} else if username == \"\" {\n\t\t\t\t\th.httpError(w, \"token must contain a username\", http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\t// Lookup user in the metastore.\n\t\t\t\tif user, err = h.MetaClient.User(username); err != nil {\n\t\t\t\t\th.httpError(w, err.Error(), http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t} else if user == nil {\n\t\t\t\t\th.httpError(w, meta.ErrUserNotFound.Error(), http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\th.httpError(w, \"unsupported authentication\", http.StatusUnauthorized)\n\t\t\t}\n\n\t\t}\n\t\tinner(w, r, user)\n\t})\n}\n\n// cors responds to incoming requests and adds the appropriate cors headers\n// TODO: corylanou: add the ability to configure this in our config\nfunc cors(inner http.Handler) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif origin := r.Header.Get(\"Origin\"); origin != \"\" {\n\t\t\tw.Header().Set(`Access-Control-Allow-Origin`, origin)\n\t\t\tw.Header().Set(`Access-Control-Allow-Methods`, strings.Join([]string{\n\t\t\t\t`DELETE`,\n\t\t\t\t`GET`,\n\t\t\t\t`OPTIONS`,\n\t\t\t\t`POST`,\n\t\t\t\t`PUT`,\n\t\t\t}, \", \"))\n\n\t\t\tw.Header().Set(`Access-Control-Allow-Headers`, strings.Join([]string{\n\t\t\t\t`Accept`,\n\t\t\t\t`Accept-Encoding`,\n\t\t\t\t`Authorization`,\n\t\t\t\t`Content-Length`,\n\t\t\t\t`Content-Type`,\n\t\t\t\t`X-CSRF-Token`,\n\t\t\t\t`X-HTTP-Method-Override`,\n\t\t\t}, \", \"))\n\n\t\t\tw.Header().Set(`Access-Control-Expose-Headers`, strings.Join([]string{\n\t\t\t\t`Date`,\n\t\t\t\t`X-InfluxDB-Version`,\n\t\t\t\t`X-InfluxDB-Build`,\n\t\t\t}, \", \"))\n\t\t}\n\n\t\tif r.Method == \"OPTIONS\" {\n\t\t\treturn\n\t\t}\n\n\t\tinner.ServeHTTP(w, r)\n\t})\n}\n\nfunc requestID(inner http.Handler) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t// X-Request-Id takes priority.\n\t\trid := r.Header.Get(\"X-Request-Id\")\n\n\t\t// If X-Request-Id is empty, then check Request-Id\n\t\tif rid == \"\" {\n\t\t\trid = r.Header.Get(\"Request-Id\")\n\t\t}\n\n\t\t// If Request-Id is empty then generate a v1 UUID.\n\t\tif rid == \"\" {\n\t\t\trid = uuid.TimeUUID().String()\n\t\t}\n\n\t\t// We read Request-Id in other handler code so we'll use that naming\n\t\t// convention from this point in the request cycle.\n\t\tr.Header.Set(\"Request-Id\", rid)\n\n\t\t// Set the request ID on the response headers.\n\t\t// X-Request-Id is the most common name for a request ID header.\n\t\tw.Header().Set(\"X-Request-Id\", rid)\n\n\t\t// We will also set Request-Id for backwards compatibility with previous\n\t\t// versions of InfluxDB.\n\t\tw.Header().Set(\"Request-Id\", rid)\n\n\t\tinner.ServeHTTP(w, r)\n\t})\n}\n\nfunc (h *Handler) logging(inner http.Handler, name string) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tl := &responseLogger{w: w}\n\t\tinner.ServeHTTP(l, r)\n\n\t\tif h.accessLogFilters.Match(l.Status()) {\n\t\t\th.CLFLogger.Println(buildLogLine(l, r, start))\n\t\t}\n\n\t\t// Log server errors.\n\t\tif l.Status()/100 == 5 {\n\t\t\terrStr := l.Header().Get(\"X-InfluxDB-Error\")\n\t\t\tif errStr != \"\" {\n\t\t\t\th.Logger.Error(fmt.Sprintf(\"[%d] - %q\", l.Status(), errStr))\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc (h *Handler) responseWriter(inner http.Handler) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw = NewResponseWriter(w, r)\n\t\tinner.ServeHTTP(w, r)\n\t})\n}\n\n// if the env var is set, and the value is truthy, then we will *not*\n// recover from a panic.\nvar willCrash bool\n\nfunc init() {\n\tvar err error\n\tif willCrash, err = strconv.ParseBool(os.Getenv(query.PanicCrashEnv)); err != nil {\n\t\twillCrash = false\n\t}\n}\n\nfunc (h *Handler) recovery(inner http.Handler, name string) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tl := &responseLogger{w: w}\n\n\t\tdefer func() {\n\t\t\tif err := recover(); err != nil {\n\t\t\t\tlogLine := buildLogLine(l, r, start)\n\t\t\t\tlogLine = fmt.Sprintf(\"%s [panic:%s] %s\", logLine, err, debug.Stack())\n\t\t\t\th.CLFLogger.Println(logLine)\n\t\t\t\thttp.Error(w, http.StatusText(http.StatusInternalServerError), 500)\n\t\t\t\tatomic.AddInt64(&h.stats.RecoveredPanics, 1) // Capture the panic in _internal stats.\n\n\t\t\t\tif willCrash {\n\t\t\t\t\th.CLFLogger.Println(\"\\n\\n=====\\nAll goroutines now follow:\")\n\t\t\t\t\tbuf := debug.Stack()\n\t\t\t\t\th.CLFLogger.Printf(\"%s\\n\", buf)\n\t\t\t\t\tos.Exit(1) // If we panic then the Go server will recover.\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\tinner.ServeHTTP(l, r)\n\t})\n}\n\n// Store describes the behaviour of the storage packages Store type.\ntype Store interface {\n\tRead(ctx context.Context, req *datatypes.ReadRequest) (reads.ResultSet, error)\n}\n\n// Response represents a list of statement results.\ntype Response struct {\n\tResults []*query.Result\n\tErr     error\n}\n\n// MarshalJSON encodes a Response struct into JSON.\nfunc (r Response) MarshalJSON() ([]byte, error) {\n\t// Define a struct that outputs \"error\" as a string.\n\tvar o struct {\n\t\tResults []*query.Result `json:\"results,omitempty\"`\n\t\tErr     string          `json:\"error,omitempty\"`\n\t}\n\n\t// Copy fields to output struct.\n\to.Results = r.Results\n\tif r.Err != nil {\n\t\to.Err = r.Err.Error()\n\t}\n\n\treturn json.Marshal(&o)\n}\n\n// UnmarshalJSON decodes the data into the Response struct.\nfunc (r *Response) UnmarshalJSON(b []byte) error {\n\tvar o struct {\n\t\tResults []*query.Result `json:\"results,omitempty\"`\n\t\tErr     string          `json:\"error,omitempty\"`\n\t}\n\n\terr := json.Unmarshal(b, &o)\n\tif err != nil {\n\t\treturn err\n\t}\n\tr.Results = o.Results\n\tif o.Err != \"\" {\n\t\tr.Err = errors.New(o.Err)\n\t}\n\treturn nil\n}\n\n// Error returns the first error from any statement.\n// Returns nil if no errors occurred on any statements.\nfunc (r *Response) Error() error {\n\tif r.Err != nil {\n\t\treturn r.Err\n\t}\n\tfor _, rr := range r.Results {\n\t\tif rr.Err != nil {\n\t\t\treturn rr.Err\n\t\t}\n\t}\n\treturn nil\n}\n\n// Throttler represents an HTTP throttler that limits the number of concurrent\n// requests being processed as well as the number of enqueued requests.\ntype Throttler struct {\n\tcurrent  chan struct{}\n\tenqueued chan struct{}\n\n\t// Maximum amount of time requests can wait in queue.\n\t// Must be set before adding middleware.\n\tEnqueueTimeout time.Duration\n\n\tLogger *zap.Logger\n}\n\n// NewThrottler returns a new instance of Throttler that limits to concurrentN.\n// requests processed at a time and maxEnqueueN requests waiting to be processed.\nfunc NewThrottler(concurrentN, maxEnqueueN int) *Throttler {\n\treturn &Throttler{\n\t\tcurrent:  make(chan struct{}, concurrentN),\n\t\tenqueued: make(chan struct{}, concurrentN+maxEnqueueN),\n\t\tLogger:   zap.NewNop(),\n\t}\n}\n\n// Handler wraps h in a middleware handler that throttles requests.\nfunc (t *Throttler) Handler(h http.Handler) http.Handler {\n\ttimeout := t.EnqueueTimeout\n\n\t// Return original handler if concurrent requests is zero.\n\tif cap(t.current) == 0 {\n\t\treturn h\n\t}\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t// Start a timer to limit enqueued request times.\n\t\tvar timerCh <-chan time.Time\n\t\tif timeout > 0 {\n\t\t\ttimer := time.NewTimer(timeout)\n\t\t\tdefer timer.Stop()\n\t\t\ttimerCh = timer.C\n\t\t}\n\n\t\t// Wait for a spot in the queue.\n\t\tif cap(t.enqueued) > cap(t.current) {\n\t\t\tselect {\n\t\t\tcase t.enqueued <- struct{}{}:\n\t\t\t\tdefer func() { <-t.enqueued }()\n\t\t\tdefault:\n\t\t\t\tt.Logger.Warn(\"request throttled, queue full\", zap.Duration(\"d\", timeout))\n\t\t\t\thttp.Error(w, \"request throttled, queue full\", http.StatusServiceUnavailable)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\t// First check if we can immediately send in to current because there is\n\t\t// available capacity. This helps reduce racyness in tests.\n\t\tselect {\n\t\tcase t.current <- struct{}{}:\n\t\tdefault:\n\t\t\t// Wait for a spot in the list of concurrent requests, but allow checking the timeout.\n\t\t\tselect {\n\t\t\tcase t.current <- struct{}{}:\n\t\t\tcase <-timerCh:\n\t\t\t\tt.Logger.Warn(\"request throttled, exceeds timeout\", zap.Duration(\"d\", timeout))\n\t\t\t\thttp.Error(w, \"request throttled, exceeds timeout\", http.StatusServiceUnavailable)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tdefer func() { <-t.current }()\n\n\t\t// Execute request.\n\t\th.ServeHTTP(w, r)\n\t})\n}\n", "package httpd_test\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"math\"\n\t\"mime/multipart\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"net/url\"\n\t\"os\"\n\t\"reflect\"\n\t\"strings\"\n\t\"sync/atomic\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/dgrijalva/jwt-go\"\n\t\"github.com/gogo/protobuf/proto\"\n\t\"github.com/golang/snappy\"\n\t\"github.com/google/go-cmp/cmp\"\n\t\"github.com/influxdata/flux\"\n\t\"github.com/influxdata/flux/lang\"\n\t\"github.com/influxdata/influxdb/flux/client\"\n\t\"github.com/influxdata/influxdb/internal\"\n\t\"github.com/influxdata/influxdb/logger\"\n\t\"github.com/influxdata/influxdb/models\"\n\t\"github.com/influxdata/influxdb/prometheus/remote\"\n\t\"github.com/influxdata/influxdb/query\"\n\t\"github.com/influxdata/influxdb/services/httpd\"\n\t\"github.com/influxdata/influxdb/services/meta\"\n\t\"github.com/influxdata/influxdb/tsdb\"\n\t\"github.com/influxdata/influxql\"\n)\n\n// Ensure the handler returns results from a query (including nil results).\nfunc TestHandler_Query(t *testing.T) {\n\th := NewHandler(false)\n\th.StatementExecutor.ExecuteStatementFn = func(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\t\tif stmt.String() != `SELECT * FROM bar` {\n\t\t\tt.Fatalf(\"unexpected query: %s\", stmt.String())\n\t\t} else if ctx.Database != `foo` {\n\t\t\tt.Fatalf(\"unexpected db: %s\", ctx.Database)\n\t\t}\n\t\tctx.Results <- &query.Result{StatementID: 1, Series: models.Rows([]*models.Row{{Name: \"series0\"}})}\n\t\tctx.Results <- &query.Result{StatementID: 2, Series: models.Rows([]*models.Row{{Name: \"series1\"}})}\n\t\treturn nil\n\t}\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewJSONRequest(\"GET\", \"/query?db=foo&q=SELECT+*+FROM+bar\", nil))\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"results\":[{\"statement_id\":1,\"series\":[{\"name\":\"series0\"}]},{\"statement_id\":2,\"series\":[{\"name\":\"series1\"}]}]}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n}\n\n// Ensure the handler returns results from a query passed as a file.\nfunc TestHandler_Query_File(t *testing.T) {\n\th := NewHandler(false)\n\th.StatementExecutor.ExecuteStatementFn = func(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\t\tif stmt.String() != `SELECT * FROM bar` {\n\t\t\tt.Fatalf(\"unexpected query: %s\", stmt.String())\n\t\t} else if ctx.Database != `foo` {\n\t\t\tt.Fatalf(\"unexpected db: %s\", ctx.Database)\n\t\t}\n\t\tctx.Results <- &query.Result{StatementID: 1, Series: models.Rows([]*models.Row{{Name: \"series0\"}})}\n\t\tctx.Results <- &query.Result{StatementID: 2, Series: models.Rows([]*models.Row{{Name: \"series1\"}})}\n\t\treturn nil\n\t}\n\n\tvar body bytes.Buffer\n\twriter := multipart.NewWriter(&body)\n\tpart, err := writer.CreateFormFile(\"q\", \"\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tio.WriteString(part, \"SELECT * FROM bar\")\n\n\tif err := writer.Close(); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tr := MustNewJSONRequest(\"POST\", \"/query?db=foo\", &body)\n\tr.Header.Set(\"Content-Type\", writer.FormDataContentType())\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, r)\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"results\":[{\"statement_id\":1,\"series\":[{\"name\":\"series0\"}]},{\"statement_id\":2,\"series\":[{\"name\":\"series1\"}]}]}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n}\n\n// Test query with user authentication.\nfunc TestHandler_Query_Auth(t *testing.T) {\n\t// Create the handler to be tested.\n\th := NewHandler(true)\n\n\t// Set mock meta client functions for the handler to use.\n\th.MetaClient.AdminUserExistsFn = func() bool { return true }\n\n\th.MetaClient.UserFn = func(username string) (meta.User, error) {\n\t\tif username != \"user1\" {\n\t\t\treturn nil, meta.ErrUserNotFound\n\t\t}\n\t\treturn &meta.UserInfo{\n\t\t\tName:  \"user1\",\n\t\t\tHash:  \"abcd\",\n\t\t\tAdmin: true,\n\t\t}, nil\n\t}\n\n\th.MetaClient.AuthenticateFn = func(u, p string) (meta.User, error) {\n\t\tif u != \"user1\" {\n\t\t\treturn nil, fmt.Errorf(\"unexpected user: exp: user1, got: %s\", u)\n\t\t} else if p != \"abcd\" {\n\t\t\treturn nil, fmt.Errorf(\"unexpected password: exp: abcd, got: %s\", p)\n\t\t}\n\t\treturn h.MetaClient.User(u)\n\t}\n\n\t// Set mock query authorizer for handler to use.\n\th.QueryAuthorizer.AuthorizeQueryFn = func(u meta.User, query *influxql.Query, database string) error {\n\t\treturn nil\n\t}\n\n\t// Set mock statement executor for handler to use.\n\th.StatementExecutor.ExecuteStatementFn = func(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\t\tif stmt.String() != `SELECT * FROM bar` {\n\t\t\tt.Fatalf(\"unexpected query: %s\", stmt.String())\n\t\t} else if ctx.Database != `foo` {\n\t\t\tt.Fatalf(\"unexpected db: %s\", ctx.Database)\n\t\t}\n\t\tctx.Results <- &query.Result{StatementID: 1, Series: models.Rows([]*models.Row{{Name: \"series0\"}})}\n\t\tctx.Results <- &query.Result{StatementID: 2, Series: models.Rows([]*models.Row{{Name: \"series1\"}})}\n\t\treturn nil\n\t}\n\n\t// Test the handler with valid user and password in the URL parameters.\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewJSONRequest(\"GET\", \"/query?u=user1&p=abcd&db=foo&q=SELECT+*+FROM+bar\", nil))\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d: %s\", w.Code, w.Body.String())\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"results\":[{\"statement_id\":1,\"series\":[{\"name\":\"series0\"}]},{\"statement_id\":2,\"series\":[{\"name\":\"series1\"}]}]}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n\n\t// Test the handler with valid user and password using basic auth.\n\tw = httptest.NewRecorder()\n\tr := MustNewJSONRequest(\"GET\", \"/query?db=foo&q=SELECT+*+FROM+bar\", nil)\n\tr.SetBasicAuth(\"user1\", \"abcd\")\n\th.ServeHTTP(w, r)\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d: %s\", w.Code, w.Body.String())\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"results\":[{\"statement_id\":1,\"series\":[{\"name\":\"series0\"}]},{\"statement_id\":2,\"series\":[{\"name\":\"series1\"}]}]}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n\n\t// Test the handler with valid JWT bearer token.\n\treq := MustNewJSONRequest(\"GET\", \"/query?db=foo&q=SELECT+*+FROM+bar\", nil)\n\t// Create a signed JWT token string and add it to the request header.\n\t_, signedToken := MustJWTToken(\"user1\", h.Config.SharedSecret, false)\n\treq.Header.Set(\"Authorization\", fmt.Sprintf(\"Bearer %s\", signedToken))\n\n\tw = httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d: %s\", w.Code, w.Body.String())\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"results\":[{\"statement_id\":1,\"series\":[{\"name\":\"series0\"}]},{\"statement_id\":2,\"series\":[{\"name\":\"series1\"}]}]}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n\n\t// Test the handler with JWT token signed with invalid key.\n\treq = MustNewJSONRequest(\"GET\", \"/query?db=foo&q=SELECT+*+FROM+bar\", nil)\n\t// Create a signed JWT token string and add it to the request header.\n\t_, signedToken = MustJWTToken(\"user1\", \"invalid key\", false)\n\treq.Header.Set(\"Authorization\", fmt.Sprintf(\"Bearer %s\", signedToken))\n\n\tw = httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Code != http.StatusUnauthorized {\n\t\tt.Fatalf(\"unexpected status: %d: %s\", w.Code, w.Body.String())\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"error\":\"signature is invalid\"}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n\n\t// Test handler with valid JWT token carrying non-existant user.\n\t_, signedToken = MustJWTToken(\"bad_user\", h.Config.SharedSecret, false)\n\treq.Header.Set(\"Authorization\", fmt.Sprintf(\"Bearer %s\", signedToken))\n\n\tw = httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Code != http.StatusUnauthorized {\n\t\tt.Fatalf(\"unexpected status: %d: %s\", w.Code, w.Body.String())\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"error\":\"user not found\"}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n\n\t// Test handler with expired JWT token.\n\t_, signedToken = MustJWTToken(\"user1\", h.Config.SharedSecret, true)\n\treq.Header.Set(\"Authorization\", fmt.Sprintf(\"Bearer %s\", signedToken))\n\n\tw = httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Code != http.StatusUnauthorized {\n\t\tt.Fatalf(\"unexpected status: %d: %s\", w.Code, w.Body.String())\n\t} else if !strings.Contains(w.Body.String(), `{\"error\":\"Token is expired`) {\n\t\tt.Fatalf(\"unexpected body: %s\", w.Body.String())\n\t}\n\n\t// Test handler with JWT token that has no expiration set.\n\ttoken, _ := MustJWTToken(\"user1\", h.Config.SharedSecret, false)\n\tdelete(token.Claims.(jwt.MapClaims), \"exp\")\n\tsignedToken, err := token.SignedString([]byte(h.Config.SharedSecret))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\treq.Header.Set(\"Authorization\", fmt.Sprintf(\"Bearer %s\", signedToken))\n\tw = httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Code != http.StatusUnauthorized {\n\t\tt.Fatalf(\"unexpected status: %d: %s\", w.Code, w.Body.String())\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"error\":\"token expiration required\"}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n\n\t// Test that auth fails if shared secret is blank.\n\torigSecret := h.Config.SharedSecret\n\th.Config.SharedSecret = \"\"\n\ttoken, _ = MustJWTToken(\"user1\", h.Config.SharedSecret, false)\n\tsignedToken, err = token.SignedString([]byte(h.Config.SharedSecret))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\treq.Header.Set(\"Authorization\", fmt.Sprintf(\"Bearer %s\", signedToken))\n\tw = httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif w.Code != http.StatusUnauthorized {\n\t\tt.Fatalf(\"unexpected status: %d: %s\", w.Code, w.Body.String())\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"error\":\"bearer auth disabled\"}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n\th.Config.SharedSecret = origSecret\n\n\t// Test the handler with valid user and password in the url and invalid in\n\t// basic auth (prioritize url).\n\tw = httptest.NewRecorder()\n\tr = MustNewJSONRequest(\"GET\", \"/query?u=user1&p=abcd&db=foo&q=SELECT+*+FROM+bar\", nil)\n\tr.SetBasicAuth(\"user1\", \"efgh\")\n\th.ServeHTTP(w, r)\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d: %s\", w.Code, w.Body.String())\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"results\":[{\"statement_id\":1,\"series\":[{\"name\":\"series0\"}]},{\"statement_id\":2,\"series\":[{\"name\":\"series1\"}]}]}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n}\n\n// Ensure the handler returns results from a query (including nil results).\nfunc TestHandler_QueryRegex(t *testing.T) {\n\th := NewHandler(false)\n\th.StatementExecutor.ExecuteStatementFn = func(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\t\tif stmt.String() != `SELECT * FROM test WHERE url =~ /http\\:\\/\\/www.akamai\\.com/` {\n\t\t\tt.Fatalf(\"unexpected query: %s\", stmt.String())\n\t\t} else if ctx.Database != `test` {\n\t\t\tt.Fatalf(\"unexpected db: %s\", ctx.Database)\n\t\t}\n\t\tctx.Results <- nil\n\t\treturn nil\n\t}\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewRequest(\"GET\", \"/query?db=test&q=SELECT%20%2A%20FROM%20test%20WHERE%20url%20%3D~%20%2Fhttp%5C%3A%5C%2F%5C%2Fwww.akamai%5C.com%2F\", nil))\n}\n\n// Ensure the handler merges results from the same statement.\nfunc TestHandler_Query_MergeResults(t *testing.T) {\n\th := NewHandler(false)\n\th.StatementExecutor.ExecuteStatementFn = func(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\t\tctx.Results <- &query.Result{StatementID: 1, Series: models.Rows([]*models.Row{{Name: \"series0\"}})}\n\t\tctx.Results <- &query.Result{StatementID: 1, Series: models.Rows([]*models.Row{{Name: \"series1\"}})}\n\t\treturn nil\n\t}\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewJSONRequest(\"GET\", \"/query?db=foo&q=SELECT+*+FROM+bar\", nil))\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"results\":[{\"statement_id\":1,\"series\":[{\"name\":\"series0\"},{\"name\":\"series1\"}]}]}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n}\n\n// Ensure the handler merges results from the same statement.\nfunc TestHandler_Query_MergeEmptyResults(t *testing.T) {\n\th := NewHandler(false)\n\th.StatementExecutor.ExecuteStatementFn = func(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\t\tctx.Results <- &query.Result{StatementID: 1, Series: models.Rows{}}\n\t\tctx.Results <- &query.Result{StatementID: 1, Series: models.Rows([]*models.Row{{Name: \"series1\"}})}\n\t\treturn nil\n\t}\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewJSONRequest(\"GET\", \"/query?db=foo&q=SELECT+*+FROM+bar\", nil))\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"results\":[{\"statement_id\":1,\"series\":[{\"name\":\"series1\"}]}]}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n}\n\n// Ensure the handler can parse chunked and chunk size query parameters.\nfunc TestHandler_Query_Chunked(t *testing.T) {\n\th := NewHandler(false)\n\th.StatementExecutor.ExecuteStatementFn = func(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\t\tif ctx.ChunkSize != 2 {\n\t\t\tt.Fatalf(\"unexpected chunk size: %d\", ctx.ChunkSize)\n\t\t}\n\t\tctx.Results <- &query.Result{StatementID: 1, Series: models.Rows([]*models.Row{{Name: \"series0\"}})}\n\t\tctx.Results <- &query.Result{StatementID: 1, Series: models.Rows([]*models.Row{{Name: \"series1\"}})}\n\t\treturn nil\n\t}\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewJSONRequest(\"GET\", \"/query?db=foo&q=SELECT+*+FROM+bar&chunked=true&chunk_size=2\", nil))\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t} else if w.Body.String() != `{\"results\":[{\"statement_id\":1,\"series\":[{\"name\":\"series0\"}]}]}\n{\"results\":[{\"statement_id\":1,\"series\":[{\"name\":\"series1\"}]}]}\n` {\n\t\tt.Fatalf(\"unexpected body: %s\", w.Body.String())\n\t}\n}\n\n// Ensure the handler can accept an async query.\nfunc TestHandler_Query_Async(t *testing.T) {\n\tdone := make(chan struct{})\n\th := NewHandler(false)\n\th.StatementExecutor.ExecuteStatementFn = func(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\t\tif stmt.String() != `SELECT * FROM bar` {\n\t\t\tt.Fatalf(\"unexpected query: %s\", stmt.String())\n\t\t} else if ctx.Database != `foo` {\n\t\t\tt.Fatalf(\"unexpected db: %s\", ctx.Database)\n\t\t}\n\t\tctx.Results <- &query.Result{StatementID: 1, Series: models.Rows([]*models.Row{{Name: \"series0\"}})}\n\t\tctx.Results <- &query.Result{StatementID: 2, Series: models.Rows([]*models.Row{{Name: \"series1\"}})}\n\t\tclose(done)\n\t\treturn nil\n\t}\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewJSONRequest(\"GET\", \"/query?db=foo&q=SELECT+*+FROM+bar&async=true\", nil))\n\tif w.Code != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n\n\t// Wait to make sure the async query runs and completes.\n\ttimer := time.NewTimer(100 * time.Millisecond)\n\tdefer timer.Stop()\n\n\tselect {\n\tcase <-timer.C:\n\t\tt.Fatal(\"timeout while waiting for async query to complete\")\n\tcase <-done:\n\t}\n}\n\n// Ensure the handler returns a status 400 if the query is not passed in.\nfunc TestHandler_Query_ErrQueryRequired(t *testing.T) {\n\th := NewHandler(false)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewJSONRequest(\"GET\", \"/query\", nil))\n\tif w.Code != http.StatusBadRequest {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"error\":\"missing required parameter \\\"q\\\"\"}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n}\n\n// Ensure the handler returns a status 400 if the query cannot be parsed.\nfunc TestHandler_Query_ErrInvalidQuery(t *testing.T) {\n\th := NewHandler(false)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewJSONRequest(\"GET\", \"/query?q=SELECT\", nil))\n\tif w.Code != http.StatusBadRequest {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"error\":\"error parsing query: found EOF, expected identifier, string, number, bool at line 1, char 8\"}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n}\n\n// Ensure the handler returns an appropriate 401 or 403 status when authentication or authorization fails.\nfunc TestHandler_Query_ErrAuthorize(t *testing.T) {\n\th := NewHandler(true)\n\th.QueryAuthorizer.AuthorizeQueryFn = func(u meta.User, q *influxql.Query, db string) error {\n\t\treturn errors.New(\"marker\")\n\t}\n\th.MetaClient.AdminUserExistsFn = func() bool { return true }\n\th.MetaClient.AuthenticateFn = func(u, p string) (meta.User, error) {\n\n\t\tusers := []meta.UserInfo{\n\t\t\t{\n\t\t\t\tName:  \"admin\",\n\t\t\t\tHash:  \"admin\",\n\t\t\t\tAdmin: true,\n\t\t\t},\n\t\t\t{\n\t\t\t\tName: \"user1\",\n\t\t\t\tHash: \"abcd\",\n\t\t\t\tPrivileges: map[string]influxql.Privilege{\n\t\t\t\t\t\"db0\": influxql.ReadPrivilege,\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\n\t\tfor _, user := range users {\n\t\t\tif u == user.Name {\n\t\t\t\tif p == user.Hash {\n\t\t\t\t\treturn &user, nil\n\t\t\t\t}\n\t\t\t\treturn nil, meta.ErrAuthenticate\n\t\t\t}\n\t\t}\n\t\treturn nil, meta.ErrUserNotFound\n\t}\n\n\tfor i, tt := range []struct {\n\t\tuser     string\n\t\tpassword string\n\t\tquery    string\n\t\tcode     int\n\t}{\n\t\t{\n\t\t\tquery: \"/query?q=SHOW+DATABASES\",\n\t\t\tcode:  http.StatusUnauthorized,\n\t\t},\n\t\t{\n\t\t\tuser:     \"user1\",\n\t\t\tpassword: \"abcd\",\n\t\t\tquery:    \"/query?q=SHOW+DATABASES\",\n\t\t\tcode:     http.StatusForbidden,\n\t\t},\n\t\t{\n\t\t\tuser:     \"user2\",\n\t\t\tpassword: \"abcd\",\n\t\t\tquery:    \"/query?q=SHOW+DATABASES\",\n\t\t\tcode:     http.StatusUnauthorized,\n\t\t},\n\t} {\n\t\tw := httptest.NewRecorder()\n\t\tr := MustNewJSONRequest(\"GET\", tt.query, nil)\n\t\tparams := r.URL.Query()\n\t\tif tt.user != \"\" {\n\t\t\tparams.Set(\"u\", tt.user)\n\t\t}\n\t\tif tt.password != \"\" {\n\t\t\tparams.Set(\"p\", tt.password)\n\t\t}\n\t\tr.URL.RawQuery = params.Encode()\n\n\t\th.ServeHTTP(w, r)\n\t\tif w.Code != tt.code {\n\t\t\tt.Errorf(\"%d. unexpected status: got=%d exp=%d\\noutput: %s\", i, w.Code, tt.code, w.Body.String())\n\t\t}\n\t}\n}\n\n// Ensure the handler returns a status 200 if an error is returned in the result.\nfunc TestHandler_Query_ErrResult(t *testing.T) {\n\th := NewHandler(false)\n\th.StatementExecutor.ExecuteStatementFn = func(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\t\treturn errors.New(\"measurement not found\")\n\t}\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewJSONRequest(\"GET\", \"/query?db=foo&q=SHOW+SERIES+from+bin\", nil))\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t} else if body := strings.TrimSpace(w.Body.String()); body != `{\"results\":[{\"statement_id\":0,\"error\":\"measurement not found\"}]}` {\n\t\tt.Fatalf(\"unexpected body: %s\", body)\n\t}\n}\n\n// Ensure that closing the HTTP connection causes the query to be interrupted.\nfunc TestHandler_Query_CloseNotify(t *testing.T) {\n\t// Avoid leaking a goroutine when this fails.\n\tdone := make(chan struct{})\n\tdefer close(done)\n\n\tinterrupted := make(chan struct{})\n\th := NewHandler(false)\n\th.StatementExecutor.ExecuteStatementFn = func(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\tcase <-done:\n\t\t}\n\t\tclose(interrupted)\n\t\treturn nil\n\t}\n\n\ts := httptest.NewServer(h)\n\tdefer s.Close()\n\n\t// Parse the URL and generate a query request.\n\tu, err := url.Parse(s.URL)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tu.Path = \"/query\"\n\n\tvalues := url.Values{}\n\tvalues.Set(\"q\", \"SELECT * FROM cpu\")\n\tvalues.Set(\"db\", \"db0\")\n\tvalues.Set(\"rp\", \"rp0\")\n\tvalues.Set(\"chunked\", \"true\")\n\tu.RawQuery = values.Encode()\n\n\treq, err := http.NewRequest(\"GET\", u.String(), nil)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// Perform the request and retrieve the response.\n\tresp, err := http.DefaultClient.Do(req)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// Validate that the interrupted channel has NOT been closed yet.\n\ttimer := time.NewTimer(100 * time.Millisecond)\n\tselect {\n\tcase <-interrupted:\n\t\ttimer.Stop()\n\t\tt.Fatal(\"query interrupted unexpectedly\")\n\tcase <-timer.C:\n\t}\n\n\t// Close the response body which should abort the query in the handler.\n\tresp.Body.Close()\n\n\t// The query should abort within 100 milliseconds.\n\ttimer.Reset(100 * time.Millisecond)\n\tselect {\n\tcase <-interrupted:\n\t\ttimer.Stop()\n\tcase <-timer.C:\n\t\tt.Fatal(\"timeout while waiting for query to abort\")\n\t}\n}\n\n// Ensure the prometheus remote write works\nfunc TestHandler_PromWrite(t *testing.T) {\n\treq := &remote.WriteRequest{\n\t\tTimeseries: []*remote.TimeSeries{\n\t\t\t{\n\t\t\t\tLabels: []*remote.LabelPair{\n\t\t\t\t\t{Name: \"host\", Value: \"a\"},\n\t\t\t\t\t{Name: \"region\", Value: \"west\"},\n\t\t\t\t},\n\t\t\t\tSamples: []*remote.Sample{\n\t\t\t\t\t{TimestampMs: 1, Value: 1.2},\n\t\t\t\t\t{TimestampMs: 2, Value: math.NaN()},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tdata, err := proto.Marshal(req)\n\tif err != nil {\n\t\tt.Fatal(\"couldn't marshal prometheus request\")\n\t}\n\tcompressed := snappy.Encode(nil, data)\n\n\tb := bytes.NewReader(compressed)\n\th := NewHandler(false)\n\th.MetaClient.DatabaseFn = func(name string) *meta.DatabaseInfo {\n\t\treturn &meta.DatabaseInfo{}\n\t}\n\tcalled := false\n\th.PointsWriter.WritePointsFn = func(db, rp string, _ models.ConsistencyLevel, _ meta.User, points []models.Point) error {\n\t\tcalled = true\n\t\tpoint := points[0]\n\t\tif point.UnixNano() != int64(time.Millisecond) {\n\t\t\tt.Fatalf(\"Exp point time %d but got %d\", int64(time.Millisecond), point.UnixNano())\n\t\t}\n\t\ttags := point.Tags()\n\t\texpectedTags := models.Tags{models.Tag{Key: []byte(\"host\"), Value: []byte(\"a\")}, models.Tag{Key: []byte(\"region\"), Value: []byte(\"west\")}}\n\t\tif !reflect.DeepEqual(tags, expectedTags) {\n\t\t\tt.Fatalf(\"tags don't match\\n\\texp: %v\\n\\tgot: %v\", expectedTags, tags)\n\t\t}\n\n\t\tfields, err := point.Fields()\n\t\tif err != nil {\n\t\t\tt.Fatal(err.Error())\n\t\t}\n\t\texpFields := models.Fields{\"value\": 1.2}\n\t\tif !reflect.DeepEqual(fields, expFields) {\n\t\t\tt.Fatalf(\"fields don't match\\n\\texp: %v\\n\\tgot: %v\", expFields, fields)\n\t\t}\n\t\treturn nil\n\t}\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewRequest(\"POST\", \"/api/v1/prom/write?db=foo\", b))\n\tif !called {\n\t\tt.Fatal(\"WritePoints: expected call\")\n\t}\n\tif w.Code != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n}\n\n// Ensure Prometheus remote read requests are converted to the correct InfluxQL query and\n// data is returned\nfunc TestHandler_PromRead(t *testing.T) {\n\treq := &remote.ReadRequest{\n\t\tQueries: []*remote.Query{{\n\t\t\tMatchers: []*remote.LabelMatcher{\n\t\t\t\t{\n\t\t\t\t\tType:  remote.MatchType_EQUAL,\n\t\t\t\t\tName:  \"__name__\",\n\t\t\t\t\tValue: \"value\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tStartTimestampMs: 1,\n\t\t\tEndTimestampMs:   2,\n\t\t}},\n\t}\n\tdata, err := proto.Marshal(req)\n\tif err != nil {\n\t\tt.Fatal(\"couldn't marshal prometheus request\")\n\t}\n\tcompressed := snappy.Encode(nil, data)\n\tb := bytes.NewReader(compressed)\n\th := NewHandler(false)\n\tw := httptest.NewRecorder()\n\n\t// Number of results in the result set\n\tvar i int64\n\th.Store.ResultSet.NextFn = func() bool {\n\t\ti++\n\t\treturn i <= 2\n\t}\n\n\t// data for each cursor.\n\th.Store.ResultSet.CursorFn = func() tsdb.Cursor {\n\t\tcursor := internal.NewFloatArrayCursorMock()\n\n\t\tvar i int64\n\t\tcursor.NextFn = func() *tsdb.FloatArray {\n\t\t\ti++\n\t\t\tts := []int64{22000000 * i, 10000000000 * i}\n\t\t\tvs := []float64{2.3, 2992.33}\n\t\t\tif i > 2 {\n\t\t\t\tts, vs = nil, nil\n\t\t\t}\n\t\t\treturn &tsdb.FloatArray{Timestamps: ts, Values: vs}\n\t\t}\n\n\t\treturn cursor\n\t}\n\n\t// Tags for each cursor.\n\th.Store.ResultSet.TagsFn = func() models.Tags {\n\t\treturn models.NewTags(map[string]string{\n\t\t\t\"host\":         fmt.Sprintf(\"server-%d\", i),\n\t\t\t\"_measurement\": \"mem\",\n\t\t})\n\t}\n\n\th.ServeHTTP(w, MustNewRequest(\"POST\", \"/api/v1/prom/read?db=foo&rp=bar\", b))\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n\n\treqBuf, err := snappy.Decode(nil, w.Body.Bytes())\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvar resp remote.ReadResponse\n\tif err := proto.Unmarshal(reqBuf, &resp); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\texpResults := []*remote.QueryResult{\n\t\t{\n\t\t\tTimeseries: []*remote.TimeSeries{\n\t\t\t\t{\n\t\t\t\t\tLabels: []*remote.LabelPair{\n\t\t\t\t\t\t{Name: \"host\", Value: \"server-1\"},\n\t\t\t\t\t},\n\t\t\t\t\tSamples: []*remote.Sample{\n\t\t\t\t\t\t{TimestampMs: 22, Value: 2.3},\n\t\t\t\t\t\t{TimestampMs: 10000, Value: 2992.33},\n\t\t\t\t\t\t{TimestampMs: 44, Value: 2.3},\n\t\t\t\t\t\t{TimestampMs: 20000, Value: 2992.33},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tLabels: []*remote.LabelPair{\n\t\t\t\t\t\t{Name: \"host\", Value: \"server-2\"},\n\t\t\t\t\t},\n\t\t\t\t\tSamples: []*remote.Sample{\n\t\t\t\t\t\t{TimestampMs: 22, Value: 2.3},\n\t\t\t\t\t\t{TimestampMs: 10000, Value: 2992.33},\n\t\t\t\t\t\t{TimestampMs: 44, Value: 2.3},\n\t\t\t\t\t\t{TimestampMs: 20000, Value: 2992.33},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tif !reflect.DeepEqual(resp.Results, expResults) {\n\t\tt.Fatalf(\"Results differ:\\n%v\", cmp.Diff(resp.Results, expResults))\n\t}\n}\n\nfunc TestHandler_PromRead_NoResults(t *testing.T) {\n\treq := &remote.ReadRequest{Queries: []*remote.Query{&remote.Query{\n\t\tMatchers: []*remote.LabelMatcher{\n\t\t\t{\n\t\t\t\tType:  remote.MatchType_EQUAL,\n\t\t\t\tName:  \"__name__\",\n\t\t\t\tValue: \"value\",\n\t\t\t},\n\t\t},\n\t\tStartTimestampMs: 0,\n\t\tEndTimestampMs:   models.MaxNanoTime / int64(time.Millisecond),\n\t}}}\n\tdata, err := proto.Marshal(req)\n\tif err != nil {\n\t\tt.Fatal(\"couldn't marshal prometheus request\")\n\t}\n\tcompressed := snappy.Encode(nil, data)\n\th := NewHandler(false)\n\tw := httptest.NewRecorder()\n\n\tb := bytes.NewReader(compressed)\n\th.ServeHTTP(w, MustNewJSONRequest(\"POST\", \"/api/v1/prom/read?db=foo\", b))\n\tif w.Code != http.StatusOK {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n\treqBuf, err := snappy.Decode(nil, w.Body.Bytes())\n\tif err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n\n\tvar resp remote.ReadResponse\n\tif err := proto.Unmarshal(reqBuf, &resp); err != nil {\n\t\tt.Fatal(err.Error())\n\t}\n}\n\nfunc TestHandler_PromRead_UnsupportedCursors(t *testing.T) {\n\treq := &remote.ReadRequest{Queries: []*remote.Query{&remote.Query{\n\t\tMatchers: []*remote.LabelMatcher{\n\t\t\t{\n\t\t\t\tType:  remote.MatchType_EQUAL,\n\t\t\t\tName:  \"__name__\",\n\t\t\t\tValue: \"value\",\n\t\t\t},\n\t\t},\n\t\tStartTimestampMs: 0,\n\t\tEndTimestampMs:   models.MaxNanoTime / int64(time.Millisecond),\n\t}}}\n\tdata, err := proto.Marshal(req)\n\tif err != nil {\n\t\tt.Fatal(\"couldn't marshal prometheus request\")\n\t}\n\tcompressed := snappy.Encode(nil, data)\n\n\tunsupported := []tsdb.Cursor{\n\t\tinternal.NewIntegerArrayCursorMock(),\n\t\tinternal.NewBooleanArrayCursorMock(),\n\t\tinternal.NewUnsignedArrayCursorMock(),\n\t\tinternal.NewStringArrayCursorMock(),\n\t}\n\n\tfor _, cursor := range unsupported {\n\t\th := NewHandler(false)\n\t\tw := httptest.NewRecorder()\n\t\tvar lb bytes.Buffer\n\t\th.Logger = logger.New(&lb)\n\n\t\tmore := true\n\t\th.Store.ResultSet.NextFn = func() bool { defer func() { more = false }(); return more }\n\n\t\t// Set the cursor type that will be returned while iterating over\n\t\t// the mock store.\n\t\th.Store.ResultSet.CursorFn = func() tsdb.Cursor {\n\t\t\treturn cursor\n\t\t}\n\n\t\tb := bytes.NewReader(compressed)\n\t\th.ServeHTTP(w, MustNewJSONRequest(\"POST\", \"/api/v1/prom/read?db=foo\", b))\n\t\tif w.Code != http.StatusOK {\n\t\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t\t}\n\t\treqBuf, err := snappy.Decode(nil, w.Body.Bytes())\n\t\tif err != nil {\n\t\t\tt.Fatal(err.Error())\n\t\t}\n\n\t\tvar resp remote.ReadResponse\n\t\tif err := proto.Unmarshal(reqBuf, &resp); err != nil {\n\t\t\tt.Fatal(err.Error())\n\t\t}\n\n\t\tif !strings.Contains(lb.String(), \"cursor_type=\") {\n\t\t\tt.Fatalf(\"got log message %q, expected to contain \\\"cursor_type\\\"\", lb.String())\n\t\t}\n\t}\n}\n\nfunc TestHandler_Flux_DisabledByDefault(t *testing.T) {\n\th := NewHandler(false)\n\tw := httptest.NewRecorder()\n\n\tbody := bytes.NewBufferString(`from(bucket:\"db/rp\") |> range(start:-1h) |> last()`)\n\th.ServeHTTP(w, MustNewRequest(\"POST\", \"/api/v2/query\", body))\n\tif got := w.Code; !cmp.Equal(got, http.StatusForbidden) {\n\t\tt.Fatalf(\"unexpected status: %d\", got)\n\t}\n\n\texp := \"Flux query service disabled. Verify flux-enabled=true in the [http] section of the InfluxDB config.\\n\"\n\tif got := string(w.Body.Bytes()); !cmp.Equal(got, exp) {\n\t\tt.Fatalf(\"unexpected body -got/+exp\\n%s\", cmp.Diff(got, exp))\n\t}\n}\n\nfunc TestHandler_Flux_QueryJSON(t *testing.T) {\n\th := NewHandlerWithConfig(NewHandlerConfig(WithFlux(), WithNoLog()))\n\tcalled := false\n\tqry := \"foo\"\n\th.Controller.QueryFn = func(ctx context.Context, compiler flux.Compiler) (i flux.Query, e error) {\n\t\tif exp := flux.CompilerType(lang.FluxCompilerType); compiler.CompilerType() != exp {\n\t\t\tt.Fatalf(\"unexpected compiler type -got/+exp\\n%s\", cmp.Diff(compiler.CompilerType(), exp))\n\t\t}\n\t\tif c, ok := compiler.(lang.FluxCompiler); !ok {\n\t\t\tt.Fatal(\"expected lang.FluxCompiler\")\n\t\t} else if exp := qry; c.Query != exp {\n\t\t\tt.Fatalf(\"unexpected query -got/+exp\\n%s\", cmp.Diff(c.Query, exp))\n\t\t}\n\t\tcalled = true\n\t\treturn internal.NewFluxQueryMock(), nil\n\t}\n\n\tq := client.QueryRequest{Query: qry}\n\tvar body bytes.Buffer\n\tif err := json.NewEncoder(&body).Encode(q); err != nil {\n\t\tt.Fatalf(\"unexpected JSON encoding error: %q\", err.Error())\n\t}\n\n\treq := MustNewRequest(\"POST\", \"/api/v2/query\", &body)\n\treq.Header.Add(\"content-type\", \"application/json\")\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif got := w.Code; !cmp.Equal(got, http.StatusOK) {\n\t\tt.Fatalf(\"unexpected status: %d\", got)\n\t}\n\n\tif !called {\n\t\tt.Fatalf(\"expected QueryFn to be called\")\n\t}\n}\n\nfunc TestHandler_Flux_SpecJSON(t *testing.T) {\n\th := NewHandlerWithConfig(NewHandlerConfig(WithFlux(), WithNoLog()))\n\tcalled := false\n\th.Controller.QueryFn = func(ctx context.Context, compiler flux.Compiler) (i flux.Query, e error) {\n\t\tif exp := flux.CompilerType(lang.SpecCompilerType); compiler.CompilerType() != exp {\n\t\t\tt.Fatalf(\"unexpected compiler type -got/+exp\\n%s\", cmp.Diff(compiler.CompilerType(), exp))\n\t\t}\n\t\tcalled = true\n\t\treturn internal.NewFluxQueryMock(), nil\n\t}\n\n\tq := client.QueryRequest{Spec: &flux.Spec{}}\n\tvar body bytes.Buffer\n\tif err := json.NewEncoder(&body).Encode(q); err != nil {\n\t\tt.Fatalf(\"unexpected JSON encoding error: %q\", err.Error())\n\t}\n\n\treq := MustNewRequest(\"POST\", \"/api/v2/query\", &body)\n\treq.Header.Add(\"content-type\", \"application/json\")\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif got := w.Code; !cmp.Equal(got, http.StatusOK) {\n\t\tt.Fatalf(\"unexpected status: %d\", got)\n\t}\n\n\tif !called {\n\t\tt.Fatalf(\"expected QueryFn to be called\")\n\t}\n}\n\nfunc TestHandler_Flux_QueryText(t *testing.T) {\n\th := NewHandlerWithConfig(NewHandlerConfig(WithFlux(), WithNoLog()))\n\tcalled := false\n\tqry := \"bar\"\n\th.Controller.QueryFn = func(ctx context.Context, compiler flux.Compiler) (i flux.Query, e error) {\n\t\tif exp := flux.CompilerType(lang.FluxCompilerType); compiler.CompilerType() != exp {\n\t\t\tt.Fatalf(\"unexpected compiler type -got/+exp\\n%s\", cmp.Diff(compiler.CompilerType(), exp))\n\t\t}\n\t\tif c, ok := compiler.(lang.FluxCompiler); !ok {\n\t\t\tt.Fatal(\"expected lang.FluxCompiler\")\n\t\t} else if exp := qry; c.Query != exp {\n\t\t\tt.Fatalf(\"unexpected query -got/+exp\\n%s\", cmp.Diff(c.Query, exp))\n\t\t}\n\t\tcalled = true\n\t\treturn internal.NewFluxQueryMock(), nil\n\t}\n\n\treq := MustNewRequest(\"POST\", \"/api/v2/query\", bytes.NewBufferString(qry))\n\treq.Header.Add(\"content-type\", \"application/vnd.flux\")\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif got := w.Code; !cmp.Equal(got, http.StatusOK) {\n\t\tt.Fatalf(\"unexpected status: %d\", got)\n\t}\n\n\tif !called {\n\t\tt.Fatalf(\"expected QueryFn to be called\")\n\t}\n}\n\nfunc TestHandler_Flux(t *testing.T) {\n\n\tqueryBytes := func(qs string) io.Reader {\n\t\tvar b bytes.Buffer\n\t\tq := &client.QueryRequest{Query: qs}\n\t\tif err := json.NewEncoder(&b).Encode(q); err != nil {\n\t\t\tt.Fatalf(\"unexpected JSON encoding error: %q\", err.Error())\n\t\t}\n\t\treturn &b\n\t}\n\n\ttests := []struct {\n\t\tname    string\n\t\treqFn   func() *http.Request\n\t\texpCode int\n\t\texpBody string\n\t}{\n\t\t{\n\t\t\tname: \"no media type\",\n\t\t\treqFn: func() *http.Request {\n\t\t\t\treturn MustNewRequest(\"POST\", \"/api/v2/query\", nil)\n\t\t\t},\n\t\t\texpCode: http.StatusBadRequest,\n\t\t\texpBody: \"{\\\"error\\\":\\\"mime: no media type\\\"}\\n\",\n\t\t},\n\t\t{\n\t\t\tname: \"200 OK\",\n\t\t\treqFn: func() *http.Request {\n\t\t\t\treq := MustNewRequest(\"POST\", \"/api/v2/query\", queryBytes(\"foo\"))\n\t\t\t\treq.Header.Add(\"content-type\", \"application/json\")\n\t\t\t\treturn req\n\t\t\t},\n\t\t\texpCode: http.StatusOK,\n\t\t},\n\t}\n\tfor _, test := range tests {\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\th := NewHandlerWithConfig(NewHandlerConfig(WithFlux(), WithNoLog()))\n\t\t\tw := httptest.NewRecorder()\n\t\t\th.ServeHTTP(w, test.reqFn())\n\t\t\tif got := w.Code; !cmp.Equal(got, test.expCode) {\n\t\t\t\tt.Fatalf(\"unexpected status: %d\", got)\n\t\t\t}\n\n\t\t\tif test.expBody != \"\" {\n\t\t\t\tif got := string(w.Body.Bytes()); !cmp.Equal(got, test.expBody) {\n\t\t\t\t\tt.Fatalf(\"unexpected body -got/+exp\\n%s\", cmp.Diff(got, test.expBody))\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestHandler_Flux_Auth(t *testing.T) {\n\t// Create the handler to be tested.\n\th := NewHandlerWithConfig(NewHandlerConfig(WithFlux(), WithNoLog(), WithAuthentication()))\n\th.MetaClient.AdminUserExistsFn = func() bool { return true }\n\th.MetaClient.UserFn = func(username string) (meta.User, error) {\n\t\tif username != \"user1\" {\n\t\t\treturn nil, meta.ErrUserNotFound\n\t\t}\n\t\treturn &meta.UserInfo{\n\t\t\tName:  \"user1\",\n\t\t\tHash:  \"abcd\",\n\t\t\tAdmin: true,\n\t\t}, nil\n\t}\n\th.MetaClient.AuthenticateFn = func(u, p string) (meta.User, error) {\n\t\tif u != \"user1\" {\n\t\t\treturn nil, fmt.Errorf(\"unexpected user: exp: user1, got: %s\", u)\n\t\t} else if p != \"abcd\" {\n\t\t\treturn nil, fmt.Errorf(\"unexpected password: exp: abcd, got: %s\", p)\n\t\t}\n\t\treturn h.MetaClient.User(u)\n\t}\n\n\th.Controller.QueryFn = func(ctx context.Context, compiler flux.Compiler) (i flux.Query, e error) {\n\t\treturn internal.NewFluxQueryMock(), nil\n\t}\n\n\treq := MustNewRequest(\"POST\", \"/api/v2/query\", bytes.NewBufferString(\"bar\"))\n\treq.Header.Set(\"content-type\", \"application/vnd.flux\")\n\treq.Header.Set(\"Authorization\", \"Token user1:abcd\")\n\t// Test the handler with valid user and password in the URL parameters.\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif got := w.Code; !cmp.Equal(got, http.StatusOK) {\n\t\tt.Fatalf(\"unexpected status: %d\", got)\n\t}\n\n\treq.Header.Set(\"Authorization\", \"Token user1:efgh\")\n\tw = httptest.NewRecorder()\n\th.ServeHTTP(w, req)\n\tif got := w.Code; !cmp.Equal(got, http.StatusUnauthorized) {\n\t\tt.Fatalf(\"unexpected status: %d\", got)\n\t}\n}\n\n// Ensure the handler handles ping requests correctly.\n// TODO: This should be expanded to verify the MetaClient check in servePing is working correctly\nfunc TestHandler_Ping(t *testing.T) {\n\th := NewHandler(false)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewRequest(\"GET\", \"/ping\", nil))\n\tif w.Code != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n\th.ServeHTTP(w, MustNewRequest(\"HEAD\", \"/ping\", nil))\n\tif w.Code != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n}\n\n// Ensure the handler returns the version correctly from the different endpoints.\nfunc TestHandler_Version(t *testing.T) {\n\th := NewHandler(false)\n\th.StatementExecutor.ExecuteStatementFn = func(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\t\treturn nil\n\t}\n\ttests := []struct {\n\t\tmethod   string\n\t\tendpoint string\n\t\tbody     io.Reader\n\t}{\n\t\t{\n\t\t\tmethod:   \"GET\",\n\t\t\tendpoint: \"/ping\",\n\t\t\tbody:     nil,\n\t\t},\n\t\t{\n\t\t\tmethod:   \"GET\",\n\t\t\tendpoint: \"/query?db=foo&q=SELECT+*+FROM+bar\",\n\t\t\tbody:     nil,\n\t\t},\n\t\t{\n\t\t\tmethod:   \"POST\",\n\t\t\tendpoint: \"/write\",\n\t\t\tbody:     bytes.NewReader(make([]byte, 10)),\n\t\t},\n\t\t{\n\t\t\tmethod:   \"GET\",\n\t\t\tendpoint: \"/notfound\",\n\t\t\tbody:     nil,\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, MustNewRequest(test.method, test.endpoint, test.body))\n\t\tif v := w.HeaderMap[\"X-Influxdb-Version\"]; len(v) > 0 {\n\t\t\tif v[0] != \"0.0.0\" {\n\t\t\t\tt.Fatalf(\"unexpected version: %s\", v)\n\t\t\t}\n\t\t} else {\n\t\t\tt.Fatalf(\"Header entry 'X-Influxdb-Version' not present\")\n\t\t}\n\n\t\tif v := w.HeaderMap[\"X-Influxdb-Build\"]; len(v) > 0 {\n\t\t\tif v[0] != \"OSS\" {\n\t\t\t\tt.Fatalf(\"unexpected BuildType: %s\", v)\n\t\t\t}\n\t\t} else {\n\t\t\tt.Fatalf(\"Header entry 'X-Influxdb-Build' not present\")\n\t\t}\n\t}\n}\n\n// Ensure the handler handles status requests correctly.\nfunc TestHandler_Status(t *testing.T) {\n\th := NewHandler(false)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewRequest(\"GET\", \"/status\", nil))\n\tif w.Code != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n\th.ServeHTTP(w, MustNewRequest(\"HEAD\", \"/status\", nil))\n\tif w.Code != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n}\n\n// Ensure write endpoint can handle bad requests\nfunc TestHandler_HandleBadRequestBody(t *testing.T) {\n\tb := bytes.NewReader(make([]byte, 10))\n\th := NewHandler(false)\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewRequest(\"POST\", \"/write\", b))\n\tif w.Code != http.StatusBadRequest {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n}\n\nfunc TestHandler_Write_EntityTooLarge_ContentLength(t *testing.T) {\n\tb := bytes.NewReader(make([]byte, 100))\n\th := NewHandler(false)\n\th.Config.MaxBodySize = 5\n\th.MetaClient.DatabaseFn = func(name string) *meta.DatabaseInfo {\n\t\treturn &meta.DatabaseInfo{}\n\t}\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewRequest(\"POST\", \"/write?db=foo\", b))\n\tif w.Code != http.StatusRequestEntityTooLarge {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n}\n\nfunc TestHandler_Write_SuppressLog(t *testing.T) {\n\tvar buf bytes.Buffer\n\tc := httpd.NewConfig()\n\tc.SuppressWriteLog = true\n\th := NewHandlerWithConfig(c)\n\th.CLFLogger = log.New(&buf, \"\", log.LstdFlags)\n\th.MetaClient.DatabaseFn = func(name string) *meta.DatabaseInfo {\n\t\treturn &meta.DatabaseInfo{}\n\t}\n\th.PointsWriter.WritePointsFn = func(database, retentionPolicy string, consistencyLevel models.ConsistencyLevel, user meta.User, points []models.Point) error {\n\t\treturn nil\n\t}\n\n\tb := strings.NewReader(\"cpu,host=server01 value=2\\n\")\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewRequest(\"POST\", \"/write?db=foo\", b))\n\tif w.Code != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n\n\t// If the log has anything in it, this failed.\n\tif buf.Len() > 0 {\n\t\tt.Fatalf(\"expected no bytes to be written to the log, got %d\", buf.Len())\n\t}\n}\n\n// onlyReader implements io.Reader only to ensure Request.ContentLength is not set\ntype onlyReader struct {\n\tr io.Reader\n}\n\nfunc (o onlyReader) Read(p []byte) (n int, err error) {\n\treturn o.r.Read(p)\n}\n\nfunc TestHandler_Write_EntityTooLarge_NoContentLength(t *testing.T) {\n\tb := onlyReader{bytes.NewReader(make([]byte, 100))}\n\th := NewHandler(false)\n\th.Config.MaxBodySize = 5\n\th.MetaClient.DatabaseFn = func(name string) *meta.DatabaseInfo {\n\t\treturn &meta.DatabaseInfo{}\n\t}\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewRequest(\"POST\", \"/write?db=foo\", b))\n\tif w.Code != http.StatusRequestEntityTooLarge {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n}\n\n// TestHandler_Write_NegativeMaxBodySize verifies no error occurs if MaxBodySize is < 0\nfunc TestHandler_Write_NegativeMaxBodySize(t *testing.T) {\n\tb := bytes.NewReader([]byte(`foo n=1`))\n\th := NewHandler(false)\n\th.Config.MaxBodySize = -1\n\th.MetaClient.DatabaseFn = func(name string) *meta.DatabaseInfo {\n\t\treturn &meta.DatabaseInfo{}\n\t}\n\tcalled := false\n\th.PointsWriter.WritePointsFn = func(_, _ string, _ models.ConsistencyLevel, _ meta.User, _ []models.Point) error {\n\t\tcalled = true\n\t\treturn nil\n\t}\n\n\tw := httptest.NewRecorder()\n\th.ServeHTTP(w, MustNewRequest(\"POST\", \"/write?db=foo\", b))\n\tif !called {\n\t\tt.Fatal(\"WritePoints: expected call\")\n\t}\n\tif w.Code != http.StatusNoContent {\n\t\tt.Fatalf(\"unexpected status: %d\", w.Code)\n\t}\n}\n\n// Ensure X-Forwarded-For header writes the correct log message.\nfunc TestHandler_XForwardedFor(t *testing.T) {\n\tvar buf bytes.Buffer\n\th := NewHandler(false)\n\th.CLFLogger = log.New(&buf, \"\", 0)\n\n\treq := MustNewRequest(\"GET\", \"/query\", nil)\n\treq.Header.Set(\"X-Forwarded-For\", \"192.168.0.1\")\n\treq.RemoteAddr = \"127.0.0.1\"\n\th.ServeHTTP(httptest.NewRecorder(), req)\n\n\tparts := strings.Split(buf.String(), \" \")\n\tif parts[0] != \"192.168.0.1,127.0.0.1\" {\n\t\tt.Errorf(\"unexpected host ip address: %s\", parts[0])\n\t}\n}\n\nfunc TestHandler_XRequestId(t *testing.T) {\n\tvar buf bytes.Buffer\n\th := NewHandler(false)\n\th.CLFLogger = log.New(&buf, \"\", 0)\n\n\tcases := []map[string]string{\n\t\t{\"X-Request-Id\": \"abc123\", \"Request-Id\": \"\"},          // X-Request-Id is used.\n\t\t{\"X-REQUEST-ID\": \"cde\", \"Request-Id\": \"\"},             // X-REQUEST-ID is used.\n\t\t{\"X-Request-Id\": \"\", \"Request-Id\": \"foobarzoo\"},       // Request-Id is used.\n\t\t{\"X-Request-Id\": \"abc123\", \"Request-Id\": \"foobarzoo\"}, // X-Request-Id takes precedence.\n\t\t{\"X-Request-Id\": \"\", \"Request-Id\": \"\"},                // v1 UUID generated.\n\t}\n\n\tfor _, c := range cases {\n\t\tt.Run(fmt.Sprint(c), func(t *testing.T) {\n\t\t\tbuf.Reset()\n\t\t\treq := MustNewRequest(\"GET\", \"/ping\", nil)\n\t\t\treq.RemoteAddr = \"127.0.0.1\"\n\n\t\t\t// Set the relevant request ID headers\n\t\t\tvar allEmpty = true\n\t\t\tfor k, v := range c {\n\t\t\t\treq.Header.Set(k, v)\n\t\t\t\tif v != \"\" {\n\t\t\t\t\tallEmpty = false\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tw := httptest.NewRecorder()\n\t\t\th.ServeHTTP(w, req)\n\n\t\t\t// Split up the HTTP log line. The request ID is currently located in\n\t\t\t// index 12. If the log line gets changed in the future, this test\n\t\t\t// will likely break and the index will need to be updated.\n\t\t\tparts := strings.Split(buf.String(), \" \")\n\t\t\ti := 12\n\n\t\t\t// If neither header is set then we expect a v1 UUID to be generated.\n\t\t\tif allEmpty {\n\t\t\t\tif got, exp := len(parts[i]), 36; got != exp {\n\t\t\t\t\tt.Fatalf(\"got ID of length %d, expected one of length %d\", got, exp)\n\t\t\t\t}\n\t\t\t} else if c[\"X-Request-Id\"] != \"\" {\n\t\t\t\tif got, exp := parts[i], c[\"X-Request-Id\"]; got != exp {\n\t\t\t\t\tt.Fatalf(\"got ID of %q, expected %q\", got, exp)\n\t\t\t\t}\n\t\t\t} else if c[\"X-REQUEST-ID\"] != \"\" {\n\t\t\t\tif got, exp := parts[i], c[\"X-REQUEST-ID\"]; got != exp {\n\t\t\t\t\tt.Fatalf(\"got ID of %q, expected %q\", got, exp)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif got, exp := parts[i], c[\"Request-Id\"]; got != exp {\n\t\t\t\t\tt.Fatalf(\"got ID of %q, expected %q\", got, exp)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Check response headers\n\t\t\tif got, exp := w.Header().Get(\"Request-Id\"), parts[i]; got != exp {\n\t\t\t\tt.Fatalf(\"Request-Id header was %s, expected %s\", got, exp)\n\t\t\t} else if got, exp := w.Header().Get(\"X-Request-Id\"), parts[i]; got != exp {\n\t\t\t\tt.Fatalf(\"X-Request-Id header was %s, expected %s\", got, exp)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestThrottler_Handler(t *testing.T) {\n\tt.Run(\"OK\", func(t *testing.T) {\n\t\tthrottler := httpd.NewThrottler(2, 98)\n\n\t\t// Send the total number of concurrent requests to the channel.\n\t\tvar concurrentN int32\n\t\tconcurrentCh := make(chan int)\n\n\t\th := throttler.Handler(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tatomic.AddInt32(&concurrentN, 1)\n\t\t\tconcurrentCh <- int(atomic.LoadInt32(&concurrentN))\n\t\t\ttime.Sleep(1 * time.Millisecond)\n\t\t\tatomic.AddInt32(&concurrentN, -1)\n\t\t}))\n\n\t\t// Execute requests concurrently.\n\t\tconst n = 100\n\t\tfor i := 0; i < n; i++ {\n\t\t\tgo func() { h.ServeHTTP(nil, nil) }()\n\t\t}\n\n\t\t// Read the number of concurrent requests for every execution.\n\t\tfor i := 0; i < n; i++ {\n\t\t\tif v := <-concurrentCh; v > 2 {\n\t\t\t\tt.Fatalf(\"concurrent requests exceed maximum: %d\", v)\n\t\t\t}\n\t\t}\n\t})\n\n\tt.Run(\"ErrTimeout\", func(t *testing.T) {\n\t\tthrottler := httpd.NewThrottler(2, 1)\n\t\tthrottler.EnqueueTimeout = 1 * time.Millisecond\n\n\t\tbegin, end := make(chan struct{}), make(chan struct{})\n\t\th := throttler.Handler(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tbegin <- struct{}{}\n\t\t\tend <- struct{}{}\n\t\t}))\n\n\t\t// First two requests should execute immediately.\n\t\tgo func() { h.ServeHTTP(nil, nil) }()\n\t\tgo func() { h.ServeHTTP(nil, nil) }()\n\n\t\t<-begin\n\t\t<-begin\n\n\t\t// Third request should be enqueued but timeout.\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, nil)\n\t\tif w.Code != http.StatusServiceUnavailable {\n\t\t\tt.Fatalf(\"unexpected status code: %d\", w.Code)\n\t\t} else if body := w.Body.String(); body != \"request throttled, exceeds timeout\\n\" {\n\t\t\tt.Fatalf(\"unexpected response body: %q\", body)\n\t\t}\n\n\t\t// Allow 2 existing requests to complete.\n\t\t<-end\n\t\t<-end\n\t})\n\n\tt.Run(\"ErrFull\", func(t *testing.T) {\n\t\tdelay := 100 * time.Millisecond\n\t\tif os.Getenv(\"CI\") != \"\" {\n\t\t\tdelay = 2 * time.Second\n\t\t}\n\n\t\tthrottler := httpd.NewThrottler(2, 1)\n\n\t\tresp := make(chan struct{})\n\t\th := throttler.Handler(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tresp <- struct{}{}\n\t\t}))\n\n\t\t// First two requests should execute immediately and third should be queued.\n\t\tgo func() { h.ServeHTTP(nil, nil) }()\n\t\tgo func() { h.ServeHTTP(nil, nil) }()\n\t\tgo func() { h.ServeHTTP(nil, nil) }()\n\t\ttime.Sleep(delay)\n\n\t\t// Fourth request should fail when trying to enqueue.\n\t\tw := httptest.NewRecorder()\n\t\th.ServeHTTP(w, nil)\n\t\tif w.Code != http.StatusServiceUnavailable {\n\t\t\tt.Fatalf(\"unexpected status code: %d\", w.Code)\n\t\t} else if body := w.Body.String(); body != \"request throttled, queue full\\n\" {\n\t\t\tt.Fatalf(\"unexpected response body: %q\", body)\n\t\t}\n\n\t\t// Allow 3 existing requests to complete.\n\t\t<-resp\n\t\t<-resp\n\t\t<-resp\n\t})\n}\n\n// NewHandler represents a test wrapper for httpd.Handler.\ntype Handler struct {\n\t*httpd.Handler\n\tMetaClient        *internal.MetaClientMock\n\tStatementExecutor HandlerStatementExecutor\n\tQueryAuthorizer   HandlerQueryAuthorizer\n\tPointsWriter      HandlerPointsWriter\n\tStore             *internal.StorageStoreMock\n\tController        *internal.FluxControllerMock\n}\n\ntype configOption func(c *httpd.Config)\n\nfunc WithAuthentication() configOption {\n\treturn func(c *httpd.Config) {\n\t\tc.AuthEnabled = true\n\t\tc.SharedSecret = \"super secret key\"\n\t}\n}\n\nfunc WithFlux() configOption {\n\treturn func(c *httpd.Config) {\n\t\tc.FluxEnabled = true\n\t}\n}\n\nfunc WithNoLog() configOption {\n\treturn func(c *httpd.Config) {\n\t\tc.LogEnabled = false\n\t}\n}\n\n// NewHandlerConfig returns a new instance of httpd.Config with\n// authentication configured.\nfunc NewHandlerConfig(opts ...configOption) httpd.Config {\n\tconfig := httpd.NewConfig()\n\tfor _, opt := range opts {\n\t\topt(&config)\n\t}\n\treturn config\n}\n\n// NewHandler returns a new instance of Handler.\nfunc NewHandler(requireAuthentication bool) *Handler {\n\tvar opts []configOption\n\tif requireAuthentication {\n\t\topts = append(opts, WithAuthentication())\n\t}\n\n\treturn NewHandlerWithConfig(NewHandlerConfig(opts...))\n}\n\nfunc NewHandlerWithConfig(config httpd.Config) *Handler {\n\th := &Handler{\n\t\tHandler: httpd.NewHandler(config),\n\t}\n\n\th.MetaClient = &internal.MetaClientMock{}\n\th.Store = internal.NewStorageStoreMock()\n\th.Controller = internal.NewFluxControllerMock()\n\n\th.Handler.MetaClient = h.MetaClient\n\th.Handler.Store = h.Store\n\th.Handler.QueryExecutor = query.NewExecutor()\n\th.Handler.QueryExecutor.StatementExecutor = &h.StatementExecutor\n\th.Handler.QueryAuthorizer = &h.QueryAuthorizer\n\th.Handler.PointsWriter = &h.PointsWriter\n\th.Handler.Version = \"0.0.0\"\n\th.Handler.BuildType = \"OSS\"\n\th.Handler.Controller = h.Controller\n\n\tif testing.Verbose() {\n\t\tl := logger.New(os.Stdout)\n\t\th.Handler.Logger = l\n\t}\n\n\treturn h\n}\n\n// HandlerStatementExecutor is a mock implementation of Handler.StatementExecutor.\ntype HandlerStatementExecutor struct {\n\tExecuteStatementFn func(stmt influxql.Statement, ctx *query.ExecutionContext) error\n}\n\nfunc (e *HandlerStatementExecutor) ExecuteStatement(stmt influxql.Statement, ctx *query.ExecutionContext) error {\n\treturn e.ExecuteStatementFn(stmt, ctx)\n}\n\n// HandlerQueryAuthorizer is a mock implementation of Handler.QueryAuthorizer.\ntype HandlerQueryAuthorizer struct {\n\tAuthorizeQueryFn func(u meta.User, query *influxql.Query, database string) error\n}\n\nfunc (a *HandlerQueryAuthorizer) AuthorizeQuery(u meta.User, query *influxql.Query, database string) error {\n\treturn a.AuthorizeQueryFn(u, query, database)\n}\n\ntype HandlerPointsWriter struct {\n\tWritePointsFn func(database, retentionPolicy string, consistencyLevel models.ConsistencyLevel, user meta.User, points []models.Point) error\n}\n\nfunc (h *HandlerPointsWriter) WritePoints(database, retentionPolicy string, consistencyLevel models.ConsistencyLevel, user meta.User, points []models.Point) error {\n\treturn h.WritePointsFn(database, retentionPolicy, consistencyLevel, user, points)\n}\n\n// MustNewRequest returns a new HTTP request. Panic on error.\nfunc MustNewRequest(method, urlStr string, body io.Reader) *http.Request {\n\tr, err := http.NewRequest(method, urlStr, body)\n\tif err != nil {\n\t\tpanic(err.Error())\n\t}\n\treturn r\n}\n\n// MustNewRequest returns a new HTTP request with the content type set. Panic on error.\nfunc MustNewJSONRequest(method, urlStr string, body io.Reader) *http.Request {\n\tr := MustNewRequest(method, urlStr, body)\n\tr.Header.Set(\"Accept\", \"application/json\")\n\treturn r\n}\n\n// MustJWTToken returns a new JWT token and signed string or panics trying.\nfunc MustJWTToken(username, secret string, expired bool) (*jwt.Token, string) {\n\ttoken := jwt.New(jwt.GetSigningMethod(\"HS512\"))\n\ttoken.Claims.(jwt.MapClaims)[\"username\"] = username\n\tif expired {\n\t\ttoken.Claims.(jwt.MapClaims)[\"exp\"] = time.Now().Add(-time.Second).Unix()\n\t} else {\n\t\ttoken.Claims.(jwt.MapClaims)[\"exp\"] = time.Now().Add(time.Minute * 10).Unix()\n\t}\n\tsigned, err := token.SignedString([]byte(secret))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn token, signed\n}\n"], "filenames": ["services/httpd/handler.go", "services/httpd/handler_test.go"], "buggy_code_start_loc": [1583, 233], "buggy_code_end_loc": [1583, 233], "fixing_code_start_loc": [1584, 234], "fixing_code_end_loc": [1589, 252], "type": "CWE-287", "message": "InfluxDB before 1.7.6 has an authentication bypass vulnerability in the authenticate function in services/httpd/handler.go because a JWT token may have an empty SharedSecret (aka shared secret).", "other": {"cve": {"id": "CVE-2019-20933", "sourceIdentifier": "cve@mitre.org", "published": "2020-11-19T02:15:11.913", "lastModified": "2022-10-19T14:52:11.963", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "InfluxDB before 1.7.6 has an authentication bypass vulnerability in the authenticate function in services/httpd/handler.go because a JWT token may have an empty SharedSecret (aka shared secret)."}, {"lang": "es", "value": "InfluxDB versiones anteriores a 1.7.6, presenta una vulnerabilidad de omisi\u00f3n de autenticaci\u00f3n en la funci\u00f3n de autenticaci\u00f3n en el archivo services/httpd/handler.go porque un token JWT puede tener un SharedSecret vac\u00edo (tambi\u00e9n se conoce como secreto compartido)"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.8, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:P/I:P/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 7.5}, "baseSeverity": "HIGH", "exploitabilityScore": 10.0, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-287"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:influxdata:influxdb:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.7.6", "matchCriteriaId": "8D5A0C08-23B3-4D32-9ECD-EDC9A5B73B17"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:9.0:*:*:*:*:*:*:*", "matchCriteriaId": "DEECE5FC-CACF-4496-A3E7-164736409252"}, {"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:10.0:*:*:*:*:*:*:*", "matchCriteriaId": "07B237A9-69A3-4A9C-9DA0-4E06BD37AE73"}]}]}], "references": [{"url": "https://github.com/influxdata/influxdb/commit/761b557315ff9c1642cf3b0e5797cd3d983a24c0", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/influxdata/influxdb/compare/v1.7.5...v1.7.6", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/influxdata/influxdb/issues/12927", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2020/12/msg00030.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://www.debian.org/security/2021/dsa-4823", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/influxdata/influxdb/commit/761b557315ff9c1642cf3b0e5797cd3d983a24c0"}}
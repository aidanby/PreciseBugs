{"buggy_code": ["1.22.0 (pending)\n================\n\nIncompatible Behavior Changes\n-----------------------------\n*Changes that are expected to cause an incompatibility if applicable; deployment changes are likely required*\n\n* tls: set TLS v1.2 as the default minimal version for servers. Users can still explicitly opt-in to 1.0 and 1.1 using :ref:`tls_minimum_protocol_version <envoy_v3_api_field_extensions.transport_sockets.tls.v3.TlsParameters.tls_minimum_protocol_version>`.\n\nMinor Behavior Changes\n----------------------\n*Changes that may cause incompatibilities for some users, but should not for most*\n\n* dynamic_forward_proxy: if a DNS resolution fails, failing immediately with a specific resolution error, rather than finishing up all local filters and failing to select an upstream host.\n* ext_authz: added requested server name in ext_authz network filter for auth review.\n* file: changed disk based files to truncate files which are not being appended to. This behavioral change can be temporarily reverted by setting runtime guard ``envoy.reloadable_features.append_or_truncate`` to false.\n* grpc: flip runtime guard ``envoy.reloadable_features.enable_grpc_async_client_cache`` to be default enabled. async grpc client created through getOrCreateRawAsyncClient will be cached by default.\n* http: avoiding delay-close for HTTP/1.0 responses framed by connection: close as well as HTTP/1.1 if the request is fully read. This means for responses to such requests, the FIN will be sent immediately after the response. This behavior can be temporarily reverted by setting ``envoy.reloadable_features.skip_delay_close`` to false.  If clients are are seen to be receiving sporadic partial responses and flipping this flag fixes it, please notify the project immediately.\n* http: now the max concurrent streams of http2 connection can not only be adjusted down according to the SETTINGS frame but also can be adjusted up, of course, it can not exceed the configured upper bounds. This fix is guarded by ``envoy.reloadable_features.http2_allow_capacity_increase_by_settings``.\n* http: when writing custom filters, `injectEncodedDataToFilterChain` and `injectDecodedDataToFilterChain` now trigger sending of headers if they were not yet sent due to `StopIteration`. Previously, calling one of the inject functions in that state would trigger an assertion. See issue #19891 for more details.\n* perf: ssl contexts are now tracked without scan based garbage collection and greatly improved the performance on secret update.\n\nBug Fixes\n---------\n*Changes expected to improve the state of the world and are unlikely to have negative effects*\n\n* access_log: fix memory leak when reopening an access log fails. Access logs will now try to be reopened on each subsequent flush attempt after a failure.\n* data plane: fixing error handling where writing to a socket failed while under the stack of processing. This should genreally affect HTTP/3. This behavioral change can be reverted by setting ``envoy.reloadable_features.allow_upstream_inline_write`` to false.\n* eds: fix the eds cluster update by allowing update on the locality of the cluster endpoints. This behavioral change can be temporarily reverted by setting runtime guard ``envoy.reloadable_features.support_locality_update_on_eds_cluster_endpoints`` to false.\n* tls: fix a bug while matching a certificate SAN with an exact value in ``match_typed_subject_alt_names`` of a listener where wildcard ``*`` character is not the only character of the dns label. Example, ``baz*.example.net`` and ``*baz.example.net`` and ``b*z.example.net`` will match ``baz1.example.net`` and ``foobaz.example.net`` and ``buzz.example.net``, respectively.\n* upstream: fix stack overflow when a cluster with large number of idle connections is removed.\n* xray: fix the AWS X-Ray tracer extension to not sample the trace if ``sampled=`` keyword is not present in the header ``x-amzn-trace-id``.\n\nRemoved Config or Runtime\n-------------------------\n*Normally occurs at the end of the* :ref:`deprecation period <deprecated>`\n\n* access_log: removed ``envoy.reloadable_features.unquote_log_string_values`` and legacy code paths.\n* grpc_bridge_filter: removed ``envoy.reloadable_features.grpc_bridge_stats_disabled`` and legacy code paths.\n* http: removed ``envoy.reloadable_features.hash_multiple_header_values`` and legacy code paths.\n* http: removed ``envoy.reloadable_features.no_chunked_encoding_header_for_304`` and legacy code paths.\n* http: removed ``envoy.reloadable_features.preserve_downstream_scheme`` and legacy code paths.\n* http: removed ``envoy.reloadable_features.require_strict_1xx_and_204_response_headers`` and ``envoy.reloadable_features.send_strict_1xx_and_204_response_headers`` and legacy code paths.\n* http: removed ``envoy.reloadable_features.strip_port_from_connect`` and legacy code paths.\n* http: removed ``envoy.reloadable_features.use_observable_cluster_name`` and legacy code paths.\n* http: removed ``envoy.reloadable_features.http_transport_failure_reason_in_body`` and legacy code paths.\n* http: removed ``envoy.reloadable_features.allow_response_for_timeout`` and legacy code paths.\n* http: removed ``envoy.reloadable_features.http2_consume_stream_refused_errors`` and legacy code paths.\n* http: removed ``envoy.reloadable_features.internal_redirects_with_body`` and legacy code paths.\n* udp: removed ``envoy.reloadable_features.udp_per_event_loop_read_limit`` and legacy code paths.\n* upstream: removed ``envoy.reloadable_features.health_check.graceful_goaway_handling`` and legacy code paths.\n* xds: removed ``envoy.reloadable_features.vhds_heartbeats`` and legacy code paths.\n\n\nNew Features\n------------\n* access_log: make consistent access_log format fields ``%(DOWN|DIRECT_DOWN|UP)STREAM_(LOCAL|REMOTE)_*%`` to provide all combinations of local & remote addresses for upstream & downstream connections.\n* admin: :http:post:`/logging` now accepts ``/logging?paths=name1:level1,name2:level2,...`` to change multiple log levels at once.\n* config: added new file based xDS configuration via :ref:`path_config_source <envoy_v3_api_field_config.core.v3.ConfigSource.path_config_source>`.\n  :ref:`watched_directory <envoy_v3_api_field_config.core.v3.PathConfigSource.watched_directory>` can\n  be used to setup an independent watch for when to reload the file path, for example when using\n  Kubernetes ConfigMaps to deliver configuration. See the linked documentation for more information.\n* cors: add dynamic support for headers ``access-control-allow-methods`` and ``access-control-allow-headers`` in cors.\n* http: added random_value_specifier in :ref:`weighted_clusters <envoy_v3_api_field_config.route.v3.RouteAction.weighted_clusters>` to allow random value to be specified from configuration proto.\n* http: added support for :ref:`proxy_status_config <envoy_v3_api_field_extensions.filters.network.http_connection_manager.v3.HttpConnectionManager.proxy_status_config>` for configuring `Proxy-Status <https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-proxy-status-08>`_ HTTP response header fields.\n* http: make consistent custom header format fields ``%(DOWN|DIRECT_DOWN|UP)STREAM_(LOCAL|REMOTE)_*%`` to provide all combinations of local & remote addresses for upstream & downstream connections.\n* http3: downstream HTTP/3 support is now GA! Upstream HTTP/3 also GA for specific deployments. See :ref:`here <arch_overview_http3>` for details.\n* http3: supports upstream HTTP/3 retries. Automatically retry `0-RTT safe requests <https://www.rfc-editor.org/rfc/rfc7231#section-4.2.1>`_ if they are rejected because they are sent `too early <https://datatracker.ietf.org/doc/html/rfc8470#section-5.2>`_. And automatically retry 0-RTT safe requests if connect attempt fails later on and the cluster is configured with TCP fallback. And add retry on ``http3-post-connect-failure`` policy which allows retry of failed HTTP/3 requests with TCP fallback even after handshake if the cluster is configured with TCP fallback. This feature is guarded by ``envoy.reloadable_features.conn_pool_new_stream_with_early_data_and_http3``.\n* matching: the matching API can now express a match tree that will always match by omitting a matcher at the top level.\n* outlier_detection: :ref:`max_ejection_time_jitter<envoy_v3_api_field_config.cluster.v3.OutlierDetection.base_ejection_time>` configuration added to allow adding a random value to the ejection time to prevent 'thundering herd' scenarios. Defaults to 0 so as to not break or change the behavior of existing deployments.\n\nDeprecated\n----------\n\n* config: deprecated :ref:`path <envoy_v3_api_field_config.core.v3.ConfigSource.path>` in favor of\n  :ref:`path_config_source <envoy_v3_api_field_config.core.v3.ConfigSource.path_config_source>`\n* http: removing support for long-deprecated old style filter names, e.g. envoy.router, envoy.lua.\n* re2: removed undocumented histograms ``re2.program_size`` and ``re2.exceeded_warn_level``.\n", "#include \"source/common/tcp_proxy/tcp_proxy.h\"\n\n#include <cstdint>\n#include <memory>\n#include <string>\n\n#include \"envoy/buffer/buffer.h\"\n#include \"envoy/config/accesslog/v3/accesslog.pb.h\"\n#include \"envoy/event/dispatcher.h\"\n#include \"envoy/event/timer.h\"\n#include \"envoy/extensions/filters/network/tcp_proxy/v3/tcp_proxy.pb.h\"\n#include \"envoy/stats/scope.h\"\n#include \"envoy/upstream/cluster_manager.h\"\n#include \"envoy/upstream/upstream.h\"\n\n#include \"source/common/access_log/access_log_impl.h\"\n#include \"source/common/common/assert.h\"\n#include \"source/common/common/empty_string.h\"\n#include \"source/common/common/enum_to_int.h\"\n#include \"source/common/common/fmt.h\"\n#include \"source/common/common/macros.h\"\n#include \"source/common/common/utility.h\"\n#include \"source/common/config/utility.h\"\n#include \"source/common/config/well_known_names.h\"\n#include \"source/common/network/application_protocol.h\"\n#include \"source/common/network/proxy_protocol_filter_state.h\"\n#include \"source/common/network/socket_option_factory.h\"\n#include \"source/common/network/transport_socket_options_impl.h\"\n#include \"source/common/network/upstream_server_name.h\"\n#include \"source/common/network/upstream_socket_options_filter_state.h\"\n#include \"source/common/router/metadatamatchcriteria_impl.h\"\n\nnamespace Envoy {\nnamespace TcpProxy {\n\nconst std::string& PerConnectionCluster::key() {\n  CONSTRUCT_ON_FIRST_USE(std::string, \"envoy.tcp_proxy.cluster\");\n}\n\nConfig::SimpleRouteImpl::SimpleRouteImpl(const Config& parent, absl::string_view cluster_name)\n    : parent_(parent), cluster_name_(cluster_name) {}\n\nConfig::WeightedClusterEntry::WeightedClusterEntry(\n    const Config& parent, const envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy::\n                              WeightedCluster::ClusterWeight& config)\n    : parent_(parent), cluster_name_(config.name()), cluster_weight_(config.weight()) {\n  if (config.has_metadata_match()) {\n    const auto filter_it = config.metadata_match().filter_metadata().find(\n        Envoy::Config::MetadataFilters::get().ENVOY_LB);\n    if (filter_it != config.metadata_match().filter_metadata().end()) {\n      if (parent.cluster_metadata_match_criteria_) {\n        metadata_match_criteria_ =\n            parent.cluster_metadata_match_criteria_->mergeMatchCriteria(filter_it->second);\n      } else {\n        metadata_match_criteria_ =\n            std::make_unique<Router::MetadataMatchCriteriaImpl>(filter_it->second);\n      }\n    }\n  }\n}\n\nConfig::SharedConfig::SharedConfig(\n    const envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy& config,\n    Server::Configuration::FactoryContext& context)\n    : stats_scope_(context.scope().createScope(fmt::format(\"tcp.{}\", config.stat_prefix()))),\n      stats_(generateStats(*stats_scope_)) {\n  if (config.has_idle_timeout()) {\n    const uint64_t timeout = DurationUtil::durationToMilliseconds(config.idle_timeout());\n    if (timeout > 0) {\n      idle_timeout_ = std::chrono::milliseconds(timeout);\n    }\n  } else {\n    idle_timeout_ = std::chrono::hours(1);\n  }\n  if (config.has_tunneling_config()) {\n    tunneling_config_helper_ =\n        std::make_unique<TunnelingConfigHelperImpl>(config.tunneling_config());\n  }\n  if (config.has_max_downstream_connection_duration()) {\n    const uint64_t connection_duration =\n        DurationUtil::durationToMilliseconds(config.max_downstream_connection_duration());\n    max_downstream_connection_duration_ = std::chrono::milliseconds(connection_duration);\n  }\n}\n\nConfig::Config(const envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy& config,\n               Server::Configuration::FactoryContext& context)\n    : max_connect_attempts_(PROTOBUF_GET_WRAPPED_OR_DEFAULT(config, max_connect_attempts, 1)),\n      upstream_drain_manager_slot_(context.threadLocal().allocateSlot()),\n      shared_config_(std::make_shared<SharedConfig>(config, context)),\n      random_generator_(context.api().randomGenerator()) {\n  upstream_drain_manager_slot_->set([](Event::Dispatcher&) {\n    ThreadLocal::ThreadLocalObjectSharedPtr drain_manager =\n        std::make_shared<UpstreamDrainManager>();\n    return drain_manager;\n  });\n\n  if (!config.cluster().empty()) {\n    default_route_ = std::make_shared<const SimpleRouteImpl>(*this, config.cluster());\n  }\n\n  if (config.has_metadata_match()) {\n    const auto& filter_metadata = config.metadata_match().filter_metadata();\n\n    const auto filter_it = filter_metadata.find(Envoy::Config::MetadataFilters::get().ENVOY_LB);\n\n    if (filter_it != filter_metadata.end()) {\n      cluster_metadata_match_criteria_ =\n          std::make_unique<Router::MetadataMatchCriteriaImpl>(filter_it->second);\n    }\n  }\n\n  // Weighted clusters will be enabled only if the default cluster is absent.\n  if (default_route_ == nullptr && config.has_weighted_clusters()) {\n    total_cluster_weight_ = 0;\n    for (const envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy::WeightedCluster::\n             ClusterWeight& cluster_desc : config.weighted_clusters().clusters()) {\n      WeightedClusterEntryConstSharedPtr cluster_entry(\n          std::make_shared<const WeightedClusterEntry>(*this, cluster_desc));\n      weighted_clusters_.emplace_back(std::move(cluster_entry));\n      total_cluster_weight_ += weighted_clusters_.back()->clusterWeight();\n    }\n  }\n\n  for (const envoy::config::accesslog::v3::AccessLog& log_config : config.access_log()) {\n    access_logs_.emplace_back(AccessLog::AccessLogFactory::fromProto(log_config, context));\n  }\n\n  if (!config.hash_policy().empty()) {\n    hash_policy_ = std::make_unique<Network::HashPolicyImpl>(config.hash_policy());\n  }\n}\n\nRouteConstSharedPtr Config::getRegularRouteFromEntries(Network::Connection& connection) {\n  // First check if the per-connection state to see if we need to route to a pre-selected cluster\n  if (const auto* per_connection_cluster =\n          connection.streamInfo().filterState()->getDataReadOnly<PerConnectionCluster>(\n              PerConnectionCluster::key());\n      per_connection_cluster != nullptr) {\n    return std::make_shared<const SimpleRouteImpl>(*this, per_connection_cluster->value());\n  }\n\n  if (default_route_ != nullptr) {\n    return default_route_;\n  }\n\n  // no match, no more routes to try\n  return nullptr;\n}\n\nRouteConstSharedPtr Config::getRouteFromEntries(Network::Connection& connection) {\n  if (weighted_clusters_.empty()) {\n    return getRegularRouteFromEntries(connection);\n  }\n  return WeightedClusterUtil::pickCluster(weighted_clusters_, total_cluster_weight_,\n                                          random_generator_.random(), false);\n}\n\nUpstreamDrainManager& Config::drainManager() {\n  return upstream_drain_manager_slot_->getTyped<UpstreamDrainManager>();\n}\n\nFilter::Filter(ConfigSharedPtr config, Upstream::ClusterManager& cluster_manager)\n    : config_(config), cluster_manager_(cluster_manager), downstream_callbacks_(*this),\n      upstream_callbacks_(new UpstreamCallbacks(this)) {\n  ASSERT(config != nullptr);\n}\n\nFilter::~Filter() {\n  for (const auto& access_log : config_->accessLogs()) {\n    access_log->log(nullptr, nullptr, nullptr, getStreamInfo());\n  }\n\n  ASSERT(generic_conn_pool_ == nullptr);\n  ASSERT(upstream_ == nullptr);\n}\n\nTcpProxyStats Config::SharedConfig::generateStats(Stats::Scope& scope) {\n  return {ALL_TCP_PROXY_STATS(POOL_COUNTER(scope), POOL_GAUGE(scope))};\n}\n\nvoid Filter::initializeReadFilterCallbacks(Network::ReadFilterCallbacks& callbacks) {\n  initialize(callbacks, true);\n}\n\nvoid Filter::initialize(Network::ReadFilterCallbacks& callbacks, bool set_connection_stats) {\n  read_callbacks_ = &callbacks;\n  ENVOY_CONN_LOG(debug, \"new tcp proxy session\", read_callbacks_->connection());\n\n  read_callbacks_->connection().addConnectionCallbacks(downstream_callbacks_);\n  read_callbacks_->connection().enableHalfClose(true);\n\n  // Need to disable reads so that we don't write to an upstream that might fail\n  // in onData(). This will get re-enabled when the upstream connection is\n  // established.\n  read_callbacks_->connection().readDisable(true);\n  getStreamInfo().setUpstreamInfo(std::make_shared<StreamInfo::UpstreamInfoImpl>());\n  config_->stats().downstream_cx_total_.inc();\n  if (set_connection_stats) {\n    read_callbacks_->connection().setConnectionStats(\n        {config_->stats().downstream_cx_rx_bytes_total_,\n         config_->stats().downstream_cx_rx_bytes_buffered_,\n         config_->stats().downstream_cx_tx_bytes_total_,\n         config_->stats().downstream_cx_tx_bytes_buffered_, nullptr, nullptr});\n  }\n}\n\nvoid Filter::readDisableUpstream(bool disable) {\n  bool success = false;\n  if (upstream_) {\n    success = upstream_->readDisable(disable);\n  }\n  if (!success) {\n    return;\n  }\n  if (disable) {\n    read_callbacks_->upstreamHost()\n        ->cluster()\n        .stats()\n        .upstream_flow_control_paused_reading_total_.inc();\n  } else {\n    read_callbacks_->upstreamHost()\n        ->cluster()\n        .stats()\n        .upstream_flow_control_resumed_reading_total_.inc();\n  }\n}\n\nvoid Filter::readDisableDownstream(bool disable) {\n  if (read_callbacks_->connection().state() != Network::Connection::State::Open) {\n    // During idle timeouts, we close both upstream and downstream with NoFlush.\n    // Envoy still does a best-effort flush which can case readDisableDownstream to be called\n    // despite the downstream connection being closed.\n    return;\n  }\n  read_callbacks_->connection().readDisable(disable);\n\n  if (disable) {\n    config_->stats().downstream_flow_control_paused_reading_total_.inc();\n  } else {\n    config_->stats().downstream_flow_control_resumed_reading_total_.inc();\n  }\n}\n\nStreamInfo::StreamInfo& Filter::getStreamInfo() {\n  return read_callbacks_->connection().streamInfo();\n}\n\nvoid Filter::DownstreamCallbacks::onAboveWriteBufferHighWatermark() {\n  ASSERT(!on_high_watermark_called_);\n  on_high_watermark_called_ = true;\n  // If downstream has too much data buffered, stop reading on the upstream connection.\n  parent_.readDisableUpstream(true);\n}\n\nvoid Filter::DownstreamCallbacks::onBelowWriteBufferLowWatermark() {\n  ASSERT(on_high_watermark_called_);\n  on_high_watermark_called_ = false;\n  // The downstream buffer has been drained. Resume reading from upstream.\n  parent_.readDisableUpstream(false);\n}\n\nvoid Filter::UpstreamCallbacks::onEvent(Network::ConnectionEvent event) {\n  if (event == Network::ConnectionEvent::Connected) {\n    return;\n  }\n  if (drainer_ == nullptr) {\n    parent_->onUpstreamEvent(event);\n  } else {\n    drainer_->onEvent(event);\n  }\n}\n\nvoid Filter::UpstreamCallbacks::onAboveWriteBufferHighWatermark() {\n  ASSERT(!on_high_watermark_called_);\n  on_high_watermark_called_ = true;\n\n  if (parent_ != nullptr) {\n    // There's too much data buffered in the upstream write buffer, so stop reading.\n    parent_->readDisableDownstream(true);\n  }\n}\n\nvoid Filter::UpstreamCallbacks::onBelowWriteBufferLowWatermark() {\n  ASSERT(on_high_watermark_called_);\n  on_high_watermark_called_ = false;\n\n  if (parent_ != nullptr) {\n    // The upstream write buffer is drained. Resume reading.\n    parent_->readDisableDownstream(false);\n  }\n}\n\nvoid Filter::UpstreamCallbacks::onUpstreamData(Buffer::Instance& data, bool end_stream) {\n  if (parent_) {\n    parent_->onUpstreamData(data, end_stream);\n  } else {\n    drainer_->onData(data, end_stream);\n  }\n}\n\nvoid Filter::UpstreamCallbacks::onBytesSent() {\n  if (drainer_ == nullptr) {\n    parent_->resetIdleTimer();\n  } else {\n    drainer_->onBytesSent();\n  }\n}\n\nvoid Filter::UpstreamCallbacks::onIdleTimeout() {\n  if (drainer_ == nullptr) {\n    parent_->onIdleTimeout();\n  } else {\n    drainer_->onIdleTimeout();\n  }\n}\n\nvoid Filter::UpstreamCallbacks::drain(Drainer& drainer) {\n  ASSERT(drainer_ == nullptr); // This should only get set once.\n  drainer_ = &drainer;\n  parent_ = nullptr;\n}\n\nNetwork::FilterStatus Filter::initializeUpstreamConnection() {\n  ASSERT(upstream_ == nullptr);\n\n  route_ = pickRoute();\n\n  const std::string& cluster_name = route_ ? route_->clusterName() : EMPTY_STRING;\n\n  Upstream::ThreadLocalCluster* thread_local_cluster =\n      cluster_manager_.getThreadLocalCluster(cluster_name);\n\n  if (thread_local_cluster) {\n    ENVOY_CONN_LOG(debug, \"Creating connection to cluster {}\", read_callbacks_->connection(),\n                   cluster_name);\n  } else {\n    ENVOY_CONN_LOG(debug, \"Cluster not found {}\", read_callbacks_->connection(), cluster_name);\n    config_->stats().downstream_cx_no_route_.inc();\n    getStreamInfo().setResponseFlag(StreamInfo::ResponseFlag::NoClusterFound);\n    onInitFailure(UpstreamFailureReason::NoRoute);\n    return Network::FilterStatus::StopIteration;\n  }\n\n  Upstream::ClusterInfoConstSharedPtr cluster = thread_local_cluster->info();\n  getStreamInfo().setUpstreamClusterInfo(cluster);\n\n  // Check this here because the TCP conn pool will queue our request waiting for a connection that\n  // will never be released.\n  if (!cluster->resourceManager(Upstream::ResourcePriority::Default).connections().canCreate()) {\n    getStreamInfo().setResponseFlag(StreamInfo::ResponseFlag::UpstreamOverflow);\n    cluster->stats().upstream_cx_overflow_.inc();\n    onInitFailure(UpstreamFailureReason::ResourceLimitExceeded);\n    return Network::FilterStatus::StopIteration;\n  }\n\n  const uint32_t max_connect_attempts = config_->maxConnectAttempts();\n  if (connect_attempts_ >= max_connect_attempts) {\n    getStreamInfo().setResponseFlag(StreamInfo::ResponseFlag::UpstreamRetryLimitExceeded);\n    cluster->stats().upstream_cx_connect_attempts_exceeded_.inc();\n    onInitFailure(UpstreamFailureReason::ConnectFailed);\n    return Network::FilterStatus::StopIteration;\n  }\n\n  if (auto downstream_connection = downstreamConnection(); downstream_connection != nullptr) {\n    if (!read_callbacks_->connection()\n             .streamInfo()\n             .filterState()\n             ->hasData<Network::ProxyProtocolFilterState>(\n                 Network::ProxyProtocolFilterState::key())) {\n      read_callbacks_->connection().streamInfo().filterState()->setData(\n          Network::ProxyProtocolFilterState::key(),\n          std::make_shared<Network::ProxyProtocolFilterState>(Network::ProxyProtocolData{\n              downstream_connection->connectionInfoProvider().remoteAddress(),\n              downstream_connection->connectionInfoProvider().localAddress()}),\n          StreamInfo::FilterState::StateType::ReadOnly,\n          StreamInfo::FilterState::LifeSpan::Connection);\n    }\n    transport_socket_options_ = Network::TransportSocketOptionsUtility::fromFilterState(\n        downstream_connection->streamInfo().filterState());\n\n    if (auto typed_state = downstream_connection->streamInfo()\n                               .filterState()\n                               .getDataReadOnly<Network::UpstreamSocketOptionsFilterState>(\n                                   Network::UpstreamSocketOptionsFilterState::key());\n        typed_state != nullptr) {\n      auto downstream_options = typed_state->value();\n      if (!upstream_options_) {\n        upstream_options_ = std::make_shared<Network::Socket::Options>();\n      }\n      Network::Socket::appendOptions(upstream_options_, downstream_options);\n    }\n  }\n\n  if (!maybeTunnel(*thread_local_cluster)) {\n    // Either cluster is unknown or there are no healthy hosts. tcpConnPool() increments\n    // cluster->stats().upstream_cx_none_healthy in the latter case.\n    getStreamInfo().setResponseFlag(StreamInfo::ResponseFlag::NoHealthyUpstream);\n    onInitFailure(UpstreamFailureReason::NoHealthyUpstream);\n  }\n  return Network::FilterStatus::StopIteration;\n}\n\nbool Filter::maybeTunnel(Upstream::ThreadLocalCluster& cluster) {\n  GenericConnPoolFactory* factory = nullptr;\n  if (cluster.info()->upstreamConfig().has_value()) {\n    factory = Envoy::Config::Utility::getFactory<GenericConnPoolFactory>(\n        cluster.info()->upstreamConfig().value());\n  } else {\n    factory = Envoy::Config::Utility::getFactoryByName<GenericConnPoolFactory>(\n        \"envoy.filters.connection_pools.tcp.generic\");\n  }\n  if (!factory) {\n    return false;\n  }\n\n  generic_conn_pool_ = factory->createGenericConnPool(cluster, config_->tunnelingConfigHelper(),\n                                                      this, *upstream_callbacks_);\n  if (generic_conn_pool_) {\n    connecting_ = true;\n    connect_attempts_++;\n    getStreamInfo().setAttemptCount(connect_attempts_);\n    generic_conn_pool_->newStream(*this);\n    // Because we never return open connections to the pool, this either has a handle waiting on\n    // connection completion, or onPoolFailure has been invoked. Either way, stop iteration.\n    return true;\n  }\n  return false;\n}\n\nvoid Filter::onGenericPoolFailure(ConnectionPool::PoolFailureReason reason,\n                                  Upstream::HostDescriptionConstSharedPtr host) {\n  generic_conn_pool_.reset();\n  read_callbacks_->upstreamHost(host);\n  getStreamInfo().upstreamInfo()->setUpstreamHost(host);\n\n  switch (reason) {\n  case ConnectionPool::PoolFailureReason::Overflow:\n  case ConnectionPool::PoolFailureReason::LocalConnectionFailure:\n    upstream_callbacks_->onEvent(Network::ConnectionEvent::LocalClose);\n    break;\n  case ConnectionPool::PoolFailureReason::RemoteConnectionFailure:\n    upstream_callbacks_->onEvent(Network::ConnectionEvent::RemoteClose);\n    break;\n  case ConnectionPool::PoolFailureReason::Timeout:\n    onConnectTimeout();\n    break;\n  }\n}\n\nvoid Filter::onGenericPoolReady(StreamInfo::StreamInfo* info,\n                                std::unique_ptr<GenericUpstream>&& upstream,\n                                Upstream::HostDescriptionConstSharedPtr& host,\n                                const Network::Address::InstanceConstSharedPtr& local_address,\n                                Ssl::ConnectionInfoConstSharedPtr ssl_info) {\n  upstream_ = std::move(upstream);\n  generic_conn_pool_.reset();\n  read_callbacks_->upstreamHost(host);\n  StreamInfo::UpstreamInfo& upstream_info = *getStreamInfo().upstreamInfo();\n  upstream_info.setUpstreamHost(host);\n  upstream_info.setUpstreamLocalAddress(local_address);\n  upstream_info.setUpstreamSslConnection(ssl_info);\n  onUpstreamConnection();\n  read_callbacks_->continueReading();\n  if (info) {\n    upstream_info.setUpstreamFilterState(info->filterState());\n  }\n}\n\nconst Router::MetadataMatchCriteria* Filter::metadataMatchCriteria() {\n  const Router::MetadataMatchCriteria* route_criteria =\n      (route_ != nullptr) ? route_->metadataMatchCriteria() : nullptr;\n\n  const auto& request_metadata = getStreamInfo().dynamicMetadata().filter_metadata();\n  const auto filter_it = request_metadata.find(Envoy::Config::MetadataFilters::get().ENVOY_LB);\n\n  if (filter_it != request_metadata.end() && route_criteria != nullptr) {\n    metadata_match_criteria_ = route_criteria->mergeMatchCriteria(filter_it->second);\n    return metadata_match_criteria_.get();\n  } else if (filter_it != request_metadata.end()) {\n    metadata_match_criteria_ =\n        std::make_unique<Router::MetadataMatchCriteriaImpl>(filter_it->second);\n    return metadata_match_criteria_.get();\n  } else {\n    return route_criteria;\n  }\n}\n\nvoid Filter::onConnectTimeout() {\n  ENVOY_CONN_LOG(debug, \"connect timeout\", read_callbacks_->connection());\n  read_callbacks_->upstreamHost()->outlierDetector().putResult(\n      Upstream::Outlier::Result::LocalOriginTimeout);\n  getStreamInfo().setResponseFlag(StreamInfo::ResponseFlag::UpstreamConnectionFailure);\n\n  // Raise LocalClose, which will trigger a reconnect if needed/configured.\n  upstream_callbacks_->onEvent(Network::ConnectionEvent::LocalClose);\n}\n\nNetwork::FilterStatus Filter::onData(Buffer::Instance& data, bool end_stream) {\n  ENVOY_CONN_LOG(trace, \"downstream connection received {} bytes, end_stream={}\",\n                 read_callbacks_->connection(), data.length(), end_stream);\n  if (upstream_) {\n    upstream_->encodeData(data, end_stream);\n  }\n  // The upstream should consume all of the data.\n  // Before there is an upstream the connection should be readDisabled. If the upstream is\n  // destroyed, there should be no further reads as well.\n  ASSERT(0 == data.length());\n  resetIdleTimer(); // TODO(ggreenway) PERF: do we need to reset timer on both send and receive?\n  return Network::FilterStatus::StopIteration;\n}\n\nNetwork::FilterStatus Filter::onNewConnection() {\n  if (config_->maxDownstreamConnectionDuration()) {\n    connection_duration_timer_ = read_callbacks_->connection().dispatcher().createTimer(\n        [this]() -> void { onMaxDownstreamConnectionDuration(); });\n    connection_duration_timer_->enableTimer(config_->maxDownstreamConnectionDuration().value());\n  }\n  return initializeUpstreamConnection();\n}\n\nvoid Filter::onDownstreamEvent(Network::ConnectionEvent event) {\n  ENVOY_CONN_LOG(trace, \"on downstream event {}, has upstream = {}\", read_callbacks_->connection(),\n                 static_cast<int>(event), upstream_ == nullptr);\n  if (upstream_) {\n    Tcp::ConnectionPool::ConnectionDataPtr conn_data(upstream_->onDownstreamEvent(event));\n    if (conn_data != nullptr &&\n        conn_data->connection().state() != Network::Connection::State::Closed) {\n      config_->drainManager().add(config_->sharedConfig(), std::move(conn_data),\n                                  std::move(upstream_callbacks_), std::move(idle_timer_),\n                                  read_callbacks_->upstreamHost());\n    }\n    if (event != Network::ConnectionEvent::Connected) {\n      upstream_.reset();\n      disableIdleTimer();\n    }\n  }\n  if (generic_conn_pool_) {\n    if (event == Network::ConnectionEvent::LocalClose ||\n        event == Network::ConnectionEvent::RemoteClose) {\n      // Cancel the conn pool request and close any excess pending requests.\n      generic_conn_pool_.reset();\n    }\n  }\n}\n\nvoid Filter::onUpstreamData(Buffer::Instance& data, bool end_stream) {\n  ENVOY_CONN_LOG(trace, \"upstream connection received {} bytes, end_stream={}\",\n                 read_callbacks_->connection(), data.length(), end_stream);\n  read_callbacks_->connection().write(data, end_stream);\n  ASSERT(0 == data.length());\n  resetIdleTimer(); // TODO(ggreenway) PERF: do we need to reset timer on both send and receive?\n}\n\nvoid Filter::onUpstreamEvent(Network::ConnectionEvent event) {\n  // Update the connecting flag before processing the event because we may start a new connection\n  // attempt in initializeUpstreamConnection.\n  bool connecting = connecting_;\n  connecting_ = false;\n\n  if (event == Network::ConnectionEvent::RemoteClose ||\n      event == Network::ConnectionEvent::LocalClose) {\n    upstream_.reset();\n    disableIdleTimer();\n\n    if (connecting) {\n      if (event == Network::ConnectionEvent::RemoteClose) {\n        getStreamInfo().setResponseFlag(StreamInfo::ResponseFlag::UpstreamConnectionFailure);\n        read_callbacks_->upstreamHost()->outlierDetector().putResult(\n            Upstream::Outlier::Result::LocalOriginConnectFailed);\n      }\n\n      initializeUpstreamConnection();\n    } else {\n      if (read_callbacks_->connection().state() == Network::Connection::State::Open) {\n        read_callbacks_->connection().close(Network::ConnectionCloseType::FlushWrite);\n      }\n    }\n  }\n}\n\nvoid Filter::onUpstreamConnection() {\n  connecting_ = false;\n  // Re-enable downstream reads now that the upstream connection is established\n  // so we have a place to send downstream data to.\n  read_callbacks_->connection().readDisable(false);\n\n  read_callbacks_->upstreamHost()->outlierDetector().putResult(\n      Upstream::Outlier::Result::LocalOriginConnectSuccessFinal);\n\n  ENVOY_CONN_LOG(debug, \"TCP:onUpstreamEvent(), requestedServerName: {}\",\n                 read_callbacks_->connection(),\n                 getStreamInfo().downstreamAddressProvider().requestedServerName());\n\n  if (config_->idleTimeout()) {\n    // The idle_timer_ can be moved to a Drainer, so related callbacks call into\n    // the UpstreamCallbacks, which has the same lifetime as the timer, and can dispatch\n    // the call to either TcpProxy or to Drainer, depending on the current state.\n    idle_timer_ = read_callbacks_->connection().dispatcher().createTimer(\n        [upstream_callbacks = upstream_callbacks_]() { upstream_callbacks->onIdleTimeout(); });\n    resetIdleTimer();\n    read_callbacks_->connection().addBytesSentCallback([this](uint64_t) {\n      resetIdleTimer();\n      return true;\n    });\n    if (upstream_) {\n      upstream_->addBytesSentCallback([upstream_callbacks = upstream_callbacks_](uint64_t) -> bool {\n        upstream_callbacks->onBytesSent();\n        return true;\n      });\n    }\n  }\n}\n\nvoid Filter::onIdleTimeout() {\n  ENVOY_CONN_LOG(debug, \"Session timed out\", read_callbacks_->connection());\n  config_->stats().idle_timeout_.inc();\n\n  // This results in also closing the upstream connection.\n  read_callbacks_->connection().close(Network::ConnectionCloseType::NoFlush);\n}\n\nvoid Filter::onMaxDownstreamConnectionDuration() {\n  ENVOY_CONN_LOG(debug, \"max connection duration reached\", read_callbacks_->connection());\n  getStreamInfo().setResponseFlag(StreamInfo::ResponseFlag::DurationTimeout);\n  config_->stats().max_downstream_connection_duration_.inc();\n  read_callbacks_->connection().close(Network::ConnectionCloseType::NoFlush);\n}\n\nvoid Filter::resetIdleTimer() {\n  if (idle_timer_ != nullptr) {\n    ASSERT(config_->idleTimeout());\n    idle_timer_->enableTimer(config_->idleTimeout().value());\n  }\n}\n\nvoid Filter::disableIdleTimer() {\n  if (idle_timer_ != nullptr) {\n    idle_timer_->disableTimer();\n    idle_timer_.reset();\n  }\n}\n\nUpstreamDrainManager::~UpstreamDrainManager() {\n  // If connections aren't closed before they are destructed an ASSERT fires,\n  // so cancel all pending drains, which causes the connections to be closed.\n  if (!drainers_.empty()) {\n    auto& dispatcher = drainers_.begin()->second->dispatcher();\n    while (!drainers_.empty()) {\n      auto begin = drainers_.begin();\n      Drainer* key = begin->first;\n      begin->second->cancelDrain();\n\n      // cancelDrain() should cause that drainer to be removed from drainers_.\n      // ASSERT so that we don't end up in an infinite loop.\n      ASSERT(drainers_.find(key) == drainers_.end());\n    }\n\n    // This destructor is run when shutting down `ThreadLocal`. The destructor of some objects use\n    // earlier `ThreadLocal` slots (for accessing the runtime snapshot) so they must run before that\n    // slot is destructed. Clear the list to enforce that ordering.\n    dispatcher.clearDeferredDeleteList();\n  }\n}\n\nvoid UpstreamDrainManager::add(const Config::SharedConfigSharedPtr& config,\n                               Tcp::ConnectionPool::ConnectionDataPtr&& upstream_conn_data,\n                               const std::shared_ptr<Filter::UpstreamCallbacks>& callbacks,\n                               Event::TimerPtr&& idle_timer,\n                               const Upstream::HostDescriptionConstSharedPtr& upstream_host) {\n  DrainerPtr drainer(new Drainer(*this, config, callbacks, std::move(upstream_conn_data),\n                                 std::move(idle_timer), upstream_host));\n  callbacks->drain(*drainer);\n\n  // Use temporary to ensure we get the pointer before we move it out of drainer\n  Drainer* ptr = drainer.get();\n  drainers_[ptr] = std::move(drainer);\n}\n\nvoid UpstreamDrainManager::remove(Drainer& drainer, Event::Dispatcher& dispatcher) {\n  auto it = drainers_.find(&drainer);\n  ASSERT(it != drainers_.end());\n  dispatcher.deferredDelete(std::move(it->second));\n  drainers_.erase(it);\n}\n\nDrainer::Drainer(UpstreamDrainManager& parent, const Config::SharedConfigSharedPtr& config,\n                 const std::shared_ptr<Filter::UpstreamCallbacks>& callbacks,\n                 Tcp::ConnectionPool::ConnectionDataPtr&& conn_data, Event::TimerPtr&& idle_timer,\n                 const Upstream::HostDescriptionConstSharedPtr& upstream_host)\n    : parent_(parent), callbacks_(callbacks), upstream_conn_data_(std::move(conn_data)),\n      timer_(std::move(idle_timer)), upstream_host_(upstream_host), config_(config) {\n  ENVOY_CONN_LOG(trace, \"draining the upstream connection\", upstream_conn_data_->connection());\n  config_->stats().upstream_flush_total_.inc();\n  config_->stats().upstream_flush_active_.inc();\n}\n\nvoid Drainer::onEvent(Network::ConnectionEvent event) {\n  if (event == Network::ConnectionEvent::RemoteClose ||\n      event == Network::ConnectionEvent::LocalClose) {\n    if (timer_ != nullptr) {\n      timer_->disableTimer();\n    }\n    config_->stats().upstream_flush_active_.dec();\n    parent_.remove(*this, upstream_conn_data_->connection().dispatcher());\n  }\n}\n\nvoid Drainer::onData(Buffer::Instance& data, bool) {\n  if (data.length() > 0) {\n    // There is no downstream connection to send any data to, but the upstream\n    // sent some data. Try to behave similar to what the kernel would do\n    // when it receives data on a connection where the application has closed\n    // the socket or ::shutdown(fd, SHUT_RD), and close/reset the connection.\n    cancelDrain();\n  }\n}\n\nvoid Drainer::onIdleTimeout() {\n  config_->stats().idle_timeout_.inc();\n  cancelDrain();\n}\n\nvoid Drainer::onBytesSent() {\n  if (timer_ != nullptr) {\n    timer_->enableTimer(config_->idleTimeout().value());\n  }\n}\n\nvoid Drainer::cancelDrain() {\n  // This sends onEvent(LocalClose).\n  upstream_conn_data_->connection().close(Network::ConnectionCloseType::NoFlush);\n}\n\nEvent::Dispatcher& Drainer::dispatcher() { return upstream_conn_data_->connection().dispatcher(); }\n\n} // namespace TcpProxy\n} // namespace Envoy\n", "#pragma once\n\n#include <cstdint>\n#include <memory>\n#include <string>\n#include <vector>\n\n#include \"envoy/access_log/access_log.h\"\n#include \"envoy/common/random_generator.h\"\n#include \"envoy/event/timer.h\"\n#include \"envoy/extensions/filters/network/tcp_proxy/v3/tcp_proxy.pb.h\"\n#include \"envoy/http/header_evaluator.h\"\n#include \"envoy/network/connection.h\"\n#include \"envoy/network/filter.h\"\n#include \"envoy/runtime/runtime.h\"\n#include \"envoy/server/filter_config.h\"\n#include \"envoy/stats/scope.h\"\n#include \"envoy/stats/stats_macros.h\"\n#include \"envoy/stats/timespan.h\"\n#include \"envoy/stream_info/filter_state.h\"\n#include \"envoy/upstream/cluster_manager.h\"\n#include \"envoy/upstream/upstream.h\"\n\n#include \"source/common/common/logger.h\"\n#include \"source/common/network/cidr_range.h\"\n#include \"source/common/network/filter_impl.h\"\n#include \"source/common/network/hash_policy.h\"\n#include \"source/common/network/utility.h\"\n#include \"source/common/stream_info/stream_info_impl.h\"\n#include \"source/common/tcp_proxy/upstream.h\"\n#include \"source/common/upstream/load_balancer_impl.h\"\n\n#include \"absl/container/node_hash_map.h\"\n\nnamespace Envoy {\nnamespace TcpProxy {\n\n/**\n * All tcp proxy stats. @see stats_macros.h\n */\n#define ALL_TCP_PROXY_STATS(COUNTER, GAUGE)                                                        \\\n  COUNTER(downstream_cx_no_route)                                                                  \\\n  COUNTER(downstream_cx_rx_bytes_total)                                                            \\\n  COUNTER(downstream_cx_total)                                                                     \\\n  COUNTER(downstream_cx_tx_bytes_total)                                                            \\\n  COUNTER(downstream_flow_control_paused_reading_total)                                            \\\n  COUNTER(downstream_flow_control_resumed_reading_total)                                           \\\n  COUNTER(idle_timeout)                                                                            \\\n  COUNTER(max_downstream_connection_duration)                                                      \\\n  COUNTER(upstream_flush_total)                                                                    \\\n  GAUGE(downstream_cx_rx_bytes_buffered, Accumulate)                                               \\\n  GAUGE(downstream_cx_tx_bytes_buffered, Accumulate)                                               \\\n  GAUGE(upstream_flush_active, Accumulate)\n\n/**\n * Struct definition for all tcp proxy stats. @see stats_macros.h\n */\nstruct TcpProxyStats {\n  ALL_TCP_PROXY_STATS(GENERATE_COUNTER_STRUCT, GENERATE_GAUGE_STRUCT)\n};\n\nclass Drainer;\nclass UpstreamDrainManager;\n\n/**\n * Route is an individual resolved route for a connection.\n */\nclass Route {\npublic:\n  virtual ~Route() = default;\n\n  /**\n   * Check whether this route matches a given connection.\n   * @param connection supplies the connection to test against.\n   * @return bool true if this route matches a given connection.\n   */\n  virtual bool matches(Network::Connection& connection) const PURE;\n\n  /**\n   * @return const std::string& the upstream cluster that owns the route.\n   */\n  virtual const std::string& clusterName() const PURE;\n\n  /**\n   * @return MetadataMatchCriteria* the metadata that a subset load balancer should match when\n   * selecting an upstream host\n   */\n  virtual const Router::MetadataMatchCriteria* metadataMatchCriteria() const PURE;\n};\n\nusing RouteConstSharedPtr = std::shared_ptr<const Route>;\nusing TunnelingConfig =\n    envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy_TunnelingConfig;\n\nclass TunnelingConfigHelperImpl : public TunnelingConfigHelper {\npublic:\n  TunnelingConfigHelperImpl(\n      const envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy_TunnelingConfig&\n          config_message)\n      : hostname_(config_message.hostname()), use_post_(config_message.use_post()),\n        header_parser_(Envoy::Router::HeaderParser::configure(config_message.headers_to_add())) {}\n  const std::string& hostname() const override { return hostname_; }\n  bool usePost() const override { return use_post_; }\n  Envoy::Http::HeaderEvaluator& headerEvaluator() const override { return *header_parser_; }\n\nprivate:\n  const std::string hostname_;\n  const bool use_post_;\n  std::unique_ptr<Envoy::Router::HeaderParser> header_parser_;\n};\n\n/**\n * Filter configuration.\n *\n * This configuration holds a TLS slot, and therefore it must be destructed\n * on the main thread.\n */\nclass Config {\npublic:\n  /**\n   * Configuration that can be shared and have an arbitrary lifetime safely.\n   */\n  class SharedConfig {\n  public:\n    SharedConfig(const envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy& config,\n                 Server::Configuration::FactoryContext& context);\n    const TcpProxyStats& stats() { return stats_; }\n    const absl::optional<std::chrono::milliseconds>& idleTimeout() { return idle_timeout_; }\n    const absl::optional<std::chrono::milliseconds>& maxDownstreamConnectinDuration() const {\n      return max_downstream_connection_duration_;\n    }\n    TunnelingConfigHelperOptConstRef tunnelingConfigHelper() {\n      if (tunneling_config_helper_) {\n        return TunnelingConfigHelperOptConstRef(*tunneling_config_helper_);\n      } else {\n        return TunnelingConfigHelperOptConstRef();\n      }\n    }\n\n  private:\n    static TcpProxyStats generateStats(Stats::Scope& scope);\n\n    // Hold a Scope for the lifetime of the configuration because connections in\n    // the UpstreamDrainManager can live longer than the listener.\n    const Stats::ScopePtr stats_scope_;\n\n    const TcpProxyStats stats_;\n    absl::optional<std::chrono::milliseconds> idle_timeout_;\n    absl::optional<std::chrono::milliseconds> max_downstream_connection_duration_;\n    std::unique_ptr<TunnelingConfigHelper> tunneling_config_helper_;\n  };\n\n  using SharedConfigSharedPtr = std::shared_ptr<SharedConfig>;\n\n  Config(const envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy& config,\n         Server::Configuration::FactoryContext& context);\n\n  /**\n   * Find out which cluster an upstream connection should be opened to based on the\n   * parameters of a downstream connection.\n   * @param connection supplies the parameters of the downstream connection for\n   * which the proxy needs to open the corresponding upstream.\n   * @return the route to be used for the upstream connection.\n   * If no route applies, returns nullptr.\n   */\n  RouteConstSharedPtr getRouteFromEntries(Network::Connection& connection);\n  RouteConstSharedPtr getRegularRouteFromEntries(Network::Connection& connection);\n\n  const TcpProxyStats& stats() { return shared_config_->stats(); }\n  const std::vector<AccessLog::InstanceSharedPtr>& accessLogs() { return access_logs_; }\n  uint32_t maxConnectAttempts() const { return max_connect_attempts_; }\n  const absl::optional<std::chrono::milliseconds>& idleTimeout() {\n    return shared_config_->idleTimeout();\n  }\n  const absl::optional<std::chrono::milliseconds>& maxDownstreamConnectionDuration() const {\n    return shared_config_->maxDownstreamConnectinDuration();\n  }\n  // Return nullptr if there is no tunneling config.\n  TunnelingConfigHelperOptConstRef tunnelingConfigHelper() {\n    return shared_config_->tunnelingConfigHelper();\n  }\n  UpstreamDrainManager& drainManager();\n  SharedConfigSharedPtr sharedConfig() { return shared_config_; }\n  const Router::MetadataMatchCriteria* metadataMatchCriteria() const {\n    return cluster_metadata_match_criteria_.get();\n  }\n  const Network::HashPolicy* hashPolicy() { return hash_policy_.get(); }\n\nprivate:\n  struct SimpleRouteImpl : public Route {\n    SimpleRouteImpl(const Config& parent, absl::string_view cluster_name);\n\n    // Route\n    bool matches(Network::Connection&) const override { return true; }\n    const std::string& clusterName() const override { return cluster_name_; }\n    const Router::MetadataMatchCriteria* metadataMatchCriteria() const override {\n      return parent_.metadataMatchCriteria();\n    }\n\n    const Config& parent_;\n    std::string cluster_name_;\n  };\n\n  class WeightedClusterEntry : public Route {\n  public:\n    WeightedClusterEntry(const Config& parent,\n                         const envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy::\n                             WeightedCluster::ClusterWeight& config);\n\n    uint64_t clusterWeight() const { return cluster_weight_; }\n\n    // Route\n    bool matches(Network::Connection&) const override { return false; }\n    const std::string& clusterName() const override { return cluster_name_; }\n    const Router::MetadataMatchCriteria* metadataMatchCriteria() const override {\n      if (metadata_match_criteria_) {\n        return metadata_match_criteria_.get();\n      }\n      return parent_.metadataMatchCriteria();\n    }\n\n  private:\n    const Config& parent_;\n    const std::string cluster_name_;\n    const uint64_t cluster_weight_;\n    Router::MetadataMatchCriteriaConstPtr metadata_match_criteria_;\n  };\n  using WeightedClusterEntryConstSharedPtr = std::shared_ptr<const WeightedClusterEntry>;\n\n  RouteConstSharedPtr default_route_;\n  std::vector<WeightedClusterEntryConstSharedPtr> weighted_clusters_;\n  uint64_t total_cluster_weight_;\n  std::vector<AccessLog::InstanceSharedPtr> access_logs_;\n  const uint32_t max_connect_attempts_;\n  ThreadLocal::SlotPtr upstream_drain_manager_slot_;\n  SharedConfigSharedPtr shared_config_;\n  std::unique_ptr<const Router::MetadataMatchCriteria> cluster_metadata_match_criteria_;\n  Random::RandomGenerator& random_generator_;\n  std::unique_ptr<const Network::HashPolicyImpl> hash_policy_;\n};\n\nusing ConfigSharedPtr = std::shared_ptr<Config>;\n\n/**\n * Per-connection TCP Proxy Cluster configuration.\n */\nclass PerConnectionCluster : public StreamInfo::FilterState::Object {\npublic:\n  PerConnectionCluster(absl::string_view cluster) : cluster_(cluster) {}\n  const std::string& value() const { return cluster_; }\n  static const std::string& key();\n\nprivate:\n  const std::string cluster_;\n};\n\n/**\n * An implementation of a TCP (L3/L4) proxy. This filter will instantiate a new outgoing TCP\n * connection using the defined load balancing proxy for the configured cluster. All data will\n * be proxied back and forth between the two connections.\n */\nclass Filter : public Network::ReadFilter,\n               public Upstream::LoadBalancerContextBase,\n               protected Logger::Loggable<Logger::Id::filter>,\n               public GenericConnectionPoolCallbacks {\npublic:\n  Filter(ConfigSharedPtr config, Upstream::ClusterManager& cluster_manager);\n  ~Filter() override;\n\n  // Network::ReadFilter\n  Network::FilterStatus onData(Buffer::Instance& data, bool end_stream) override;\n  Network::FilterStatus onNewConnection() override;\n  void initializeReadFilterCallbacks(Network::ReadFilterCallbacks& callbacks) override;\n\n  // GenericConnectionPoolCallbacks\n  void onGenericPoolReady(StreamInfo::StreamInfo* info, std::unique_ptr<GenericUpstream>&& upstream,\n                          Upstream::HostDescriptionConstSharedPtr& host,\n                          const Network::Address::InstanceConstSharedPtr& local_address,\n                          Ssl::ConnectionInfoConstSharedPtr ssl_info) override;\n  void onGenericPoolFailure(ConnectionPool::PoolFailureReason reason,\n                            Upstream::HostDescriptionConstSharedPtr host) override;\n\n  // Upstream::LoadBalancerContext\n  const Router::MetadataMatchCriteria* metadataMatchCriteria() override;\n  absl::optional<uint64_t> computeHashKey() override {\n    auto hash_policy = config_->hashPolicy();\n    if (hash_policy) {\n      return hash_policy->generateHash(*downstreamConnection());\n    }\n\n    return {};\n  }\n\n  const Network::Connection* downstreamConnection() const override {\n    return &read_callbacks_->connection();\n  }\n\n  Network::TransportSocketOptionsConstSharedPtr upstreamTransportSocketOptions() const override {\n    return transport_socket_options_;\n  }\n\n  Network::Socket::OptionsSharedPtr upstreamSocketOptions() const override {\n    return upstream_options_;\n  }\n\n  // These two functions allow enabling/disabling reads on the upstream and downstream connections.\n  // They are called by the Downstream/Upstream Watermark callbacks to limit buffering.\n  void readDisableUpstream(bool disable);\n  void readDisableDownstream(bool disable);\n\n  struct UpstreamCallbacks : public Tcp::ConnectionPool::UpstreamCallbacks {\n    UpstreamCallbacks(Filter* parent) : parent_(parent) {}\n\n    // Tcp::ConnectionPool::UpstreamCallbacks\n    void onUpstreamData(Buffer::Instance& data, bool end_stream) override;\n    void onEvent(Network::ConnectionEvent event) override;\n    void onAboveWriteBufferHighWatermark() override;\n    void onBelowWriteBufferLowWatermark() override;\n\n    void onBytesSent();\n    void onIdleTimeout();\n    void drain(Drainer& drainer);\n\n    // Either parent_ or drainer_ will be non-NULL, but never both. This could be\n    // logically be represented as a union, but saving one pointer of memory is\n    // outweighed by more type safety/better error handling.\n    //\n    // Parent starts out as non-NULL. If the downstream connection is closed while\n    // the upstream connection still has buffered data to flush, drainer_ becomes\n    // non-NULL and parent_ is set to NULL.\n    Filter* parent_{};\n    Drainer* drainer_{};\n\n    bool on_high_watermark_called_{false};\n  };\n\n  StreamInfo::StreamInfo& getStreamInfo();\n\nprotected:\n  struct DownstreamCallbacks : public Network::ConnectionCallbacks {\n    DownstreamCallbacks(Filter& parent) : parent_(parent) {}\n\n    // Network::ConnectionCallbacks\n    void onEvent(Network::ConnectionEvent event) override { parent_.onDownstreamEvent(event); }\n    void onAboveWriteBufferHighWatermark() override;\n    void onBelowWriteBufferLowWatermark() override;\n\n    Filter& parent_;\n    bool on_high_watermark_called_{false};\n  };\n\n  enum class UpstreamFailureReason {\n    ConnectFailed,\n    NoHealthyUpstream,\n    ResourceLimitExceeded,\n    NoRoute,\n  };\n\n  // Callbacks for different error and success states during connection establishment\n  virtual RouteConstSharedPtr pickRoute() {\n    return config_->getRouteFromEntries(read_callbacks_->connection());\n  }\n\n  virtual void onInitFailure(UpstreamFailureReason) {\n    read_callbacks_->connection().close(Network::ConnectionCloseType::NoFlush);\n  }\n\n  void initialize(Network::ReadFilterCallbacks& callbacks, bool set_connection_stats);\n  Network::FilterStatus initializeUpstreamConnection();\n  bool maybeTunnel(Upstream::ThreadLocalCluster& cluster);\n  void onConnectTimeout();\n  void onDownstreamEvent(Network::ConnectionEvent event);\n  void onUpstreamData(Buffer::Instance& data, bool end_stream);\n  void onUpstreamEvent(Network::ConnectionEvent event);\n  void onUpstreamConnection();\n  void onIdleTimeout();\n  void resetIdleTimer();\n  void disableIdleTimer();\n  void onMaxDownstreamConnectionDuration();\n\n  const ConfigSharedPtr config_;\n  Upstream::ClusterManager& cluster_manager_;\n  Network::ReadFilterCallbacks* read_callbacks_{};\n\n  DownstreamCallbacks downstream_callbacks_;\n  Event::TimerPtr idle_timer_;\n  Event::TimerPtr connection_duration_timer_;\n\n  std::shared_ptr<UpstreamCallbacks> upstream_callbacks_; // shared_ptr required for passing as a\n                                                          // read filter.\n  // The upstream handle (either TCP or HTTP). This is set in onGenericPoolReady and should persist\n  // until either the upstream or downstream connection is terminated.\n  std::unique_ptr<GenericUpstream> upstream_;\n  // The connection pool used to set up |upstream_|.\n  // This will be non-null from when an upstream connection is attempted until\n  // it either succeeds or fails.\n  std::unique_ptr<GenericConnPool> generic_conn_pool_;\n  RouteConstSharedPtr route_;\n  Router::MetadataMatchCriteriaConstPtr metadata_match_criteria_;\n  Network::TransportSocketOptionsConstSharedPtr transport_socket_options_;\n  Network::Socket::OptionsSharedPtr upstream_options_;\n  uint32_t connect_attempts_{};\n  bool connecting_{};\n};\n\n// This class deals with an upstream connection that needs to finish flushing, when the downstream\n// connection has been closed. The TcpProxy is destroyed when the downstream connection is closed,\n// so handling the upstream connection here allows it to finish draining or timeout.\nclass Drainer : public Event::DeferredDeletable, protected Logger::Loggable<Logger::Id::filter> {\npublic:\n  Drainer(UpstreamDrainManager& parent, const Config::SharedConfigSharedPtr& config,\n          const std::shared_ptr<Filter::UpstreamCallbacks>& callbacks,\n          Tcp::ConnectionPool::ConnectionDataPtr&& conn_data, Event::TimerPtr&& idle_timer,\n          const Upstream::HostDescriptionConstSharedPtr& upstream_host);\n\n  void onEvent(Network::ConnectionEvent event);\n  void onData(Buffer::Instance& data, bool end_stream);\n  void onIdleTimeout();\n  void onBytesSent();\n  void cancelDrain();\n  Event::Dispatcher& dispatcher();\n\nprivate:\n  UpstreamDrainManager& parent_;\n  std::shared_ptr<Filter::UpstreamCallbacks> callbacks_;\n  Tcp::ConnectionPool::ConnectionDataPtr upstream_conn_data_;\n  Event::TimerPtr timer_;\n  Upstream::HostDescriptionConstSharedPtr upstream_host_;\n  Config::SharedConfigSharedPtr config_;\n};\n\nusing DrainerPtr = std::unique_ptr<Drainer>;\n\nclass UpstreamDrainManager : public ThreadLocal::ThreadLocalObject {\npublic:\n  ~UpstreamDrainManager() override;\n  void add(const Config::SharedConfigSharedPtr& config,\n           Tcp::ConnectionPool::ConnectionDataPtr&& upstream_conn_data,\n           const std::shared_ptr<Filter::UpstreamCallbacks>& callbacks,\n           Event::TimerPtr&& idle_timer,\n           const Upstream::HostDescriptionConstSharedPtr& upstream_host);\n  void remove(Drainer& drainer, Event::Dispatcher& dispatcher);\n\nprivate:\n  // This must be a map instead of set because there is no way to move elements\n  // out of a set, and these elements get passed to deferredDelete() instead of\n  // being deleted in-place. The key and value will always be equal.\n  absl::node_hash_map<Drainer*, DrainerPtr> drainers_;\n};\n\n} // namespace TcpProxy\n} // namespace Envoy\n", "#include <memory>\n\n#include \"envoy/config/bootstrap/v3/bootstrap.pb.h\"\n#include \"envoy/extensions/filters/network/tcp_proxy/v3/tcp_proxy.pb.h\"\n\n#include \"test/integration/http_integration.h\"\n#include \"test/integration/http_protocol_integration.h\"\n\n#include \"gtest/gtest.h\"\n\nnamespace Envoy {\nnamespace {\n\n// Terminating CONNECT and sending raw TCP upstream.\nclass ConnectTerminationIntegrationTest : public HttpProtocolIntegrationTest {\npublic:\n  ConnectTerminationIntegrationTest() { enableHalfClose(true); }\n\n  void initialize() override {\n    config_helper_.addConfigModifier(\n        [&](envoy::extensions::filters::network::http_connection_manager::v3::HttpConnectionManager&\n                hcm) {\n          ConfigHelper::setConnectConfig(hcm, true, allow_post_,\n                                         downstream_protocol_ == Http::CodecType::HTTP3);\n\n          if (enable_timeout_) {\n            hcm.mutable_stream_idle_timeout()->set_seconds(0);\n            hcm.mutable_stream_idle_timeout()->set_nanos(200 * 1000 * 1000);\n          }\n          if (exact_match_) {\n            auto* route_config = hcm.mutable_route_config();\n            ASSERT_EQ(1, route_config->virtual_hosts_size());\n            route_config->mutable_virtual_hosts(0)->clear_domains();\n            route_config->mutable_virtual_hosts(0)->add_domains(\"host:80\");\n          }\n        });\n    HttpIntegrationTest::initialize();\n  }\n\n  void setUpConnection() {\n    codec_client_ = makeHttpConnection(lookupPort(\"http\"));\n    auto encoder_decoder = codec_client_->startRequest(connect_headers_);\n    request_encoder_ = &encoder_decoder.first;\n    response_ = std::move(encoder_decoder.second);\n    ASSERT_TRUE(fake_upstreams_[0]->waitForRawConnection(fake_raw_upstream_connection_));\n    response_->waitForHeaders();\n  }\n\n  void sendBidirectionalData(const char* downstream_send_data = \"hello\",\n                             const char* upstream_received_data = \"hello\",\n                             const char* upstream_send_data = \"there!\",\n                             const char* downstream_received_data = \"there!\") {\n    // Send some data upstream.\n    codec_client_->sendData(*request_encoder_, downstream_send_data, false);\n    ASSERT_TRUE(fake_raw_upstream_connection_->waitForData(\n        FakeRawConnection::waitForInexactMatch(upstream_received_data)));\n\n    // Send some data downstream.\n    ASSERT_TRUE(fake_raw_upstream_connection_->write(upstream_send_data));\n    response_->waitForBodyData(strlen(downstream_received_data));\n    EXPECT_EQ(downstream_received_data, response_->body());\n  }\n\n  Http::TestRequestHeaderMapImpl connect_headers_{{\":method\", \"CONNECT\"},\n                                                  {\":path\", \"/\"},\n                                                  {\":protocol\", \"bytestream\"},\n                                                  {\":scheme\", \"https\"},\n                                                  {\":authority\", \"host:80\"}};\n  void clearExtendedConnectHeaders() {\n    connect_headers_.removeProtocol();\n    connect_headers_.removePath();\n  }\n\n  void sendBidirectionalDataAndCleanShutdown() {\n    sendBidirectionalData(\"hello\", \"hello\", \"there!\", \"there!\");\n    // Send a second set of data to make sure for example headers are only sent once.\n    sendBidirectionalData(\",bye\", \"hello,bye\", \"ack\", \"there!ack\");\n\n    // Send an end stream. This should result in half close upstream.\n    codec_client_->sendData(*request_encoder_, \"\", true);\n    ASSERT_TRUE(fake_raw_upstream_connection_->waitForHalfClose());\n\n    // Now send a FIN from upstream. This should result in clean shutdown downstream.\n    ASSERT_TRUE(fake_raw_upstream_connection_->close());\n    if (downstream_protocol_ == Http::CodecType::HTTP1) {\n      ASSERT_TRUE(codec_client_->waitForDisconnect());\n    } else {\n      ASSERT_TRUE(response_->waitForEndStream());\n      ASSERT_FALSE(response_->reset());\n    }\n  }\n\n  FakeRawConnectionPtr fake_raw_upstream_connection_;\n  IntegrationStreamDecoderPtr response_;\n  bool enable_timeout_{};\n  bool exact_match_{};\n  bool allow_post_{};\n};\n\nTEST_P(ConnectTerminationIntegrationTest, OriginalStyle) {\n  initialize();\n  clearExtendedConnectHeaders();\n\n  setUpConnection();\n  sendBidirectionalDataAndCleanShutdown();\n}\n\nTEST_P(ConnectTerminationIntegrationTest, Basic) {\n  initialize();\n\n  setUpConnection();\n  sendBidirectionalDataAndCleanShutdown();\n}\n\nTEST_P(ConnectTerminationIntegrationTest, BasicAllowPost) {\n  allow_post_ = true;\n  initialize();\n\n  // Use POST request.\n  connect_headers_.setMethod(\"POST\");\n  connect_headers_.removeProtocol();\n\n  setUpConnection();\n  sendBidirectionalDataAndCleanShutdown();\n}\n\nTEST_P(ConnectTerminationIntegrationTest, UsingHostMatch) {\n  exact_match_ = true;\n  initialize();\n\n  connect_headers_.removePath();\n  connect_headers_.removeProtocol();\n\n  setUpConnection();\n  sendBidirectionalDataAndCleanShutdown();\n}\n\nTEST_P(ConnectTerminationIntegrationTest, DownstreamClose) {\n  initialize();\n\n  setUpConnection();\n  sendBidirectionalData();\n\n  // Tear down by closing the client connection.\n  codec_client_->close();\n  ASSERT_TRUE(fake_raw_upstream_connection_->waitForHalfClose());\n}\n\nTEST_P(ConnectTerminationIntegrationTest, DownstreamReset) {\n  if (downstream_protocol_ == Http::CodecType::HTTP1) {\n    // Resetting an individual stream requires HTTP/2 or later.\n    return;\n  }\n  initialize();\n\n  setUpConnection();\n  sendBidirectionalData();\n\n  // Tear down by resetting the client stream.\n  codec_client_->sendReset(*request_encoder_);\n  ASSERT_TRUE(fake_raw_upstream_connection_->waitForHalfClose());\n}\n\nTEST_P(ConnectTerminationIntegrationTest, UpstreamClose) {\n  initialize();\n\n  setUpConnection();\n  sendBidirectionalData();\n\n  // Tear down by closing the upstream connection.\n  ASSERT_TRUE(fake_raw_upstream_connection_->close());\n  if (downstream_protocol_ == Http::CodecType::HTTP3) {\n    // In HTTP/3 end stream will be sent when the upstream connection is closed, and\n    // STOP_SENDING frame sent instead of reset.\n    ASSERT_TRUE(response_->waitForEndStream());\n  } else {\n    ASSERT_TRUE(response_->waitForReset());\n  }\n}\n\nTEST_P(ConnectTerminationIntegrationTest, TestTimeout) {\n  enable_timeout_ = true;\n  initialize();\n\n  setUpConnection();\n\n  // Wait for the timeout to close the connection.\n  ASSERT_TRUE(response_->waitForReset());\n  ASSERT_TRUE(fake_raw_upstream_connection_->waitForHalfClose());\n}\n\nTEST_P(ConnectTerminationIntegrationTest, BuggyHeaders) {\n  if (downstream_protocol_ == Http::CodecType::HTTP1) {\n    return;\n  }\n  initialize();\n\n  // Sending a header-only request is probably buggy, but rather than having a\n  // special corner case it is treated as a regular half close.\n  codec_client_ = makeHttpConnection(lookupPort(\"http\"));\n  response_ = codec_client_->makeHeaderOnlyRequest(\n      Http::TestRequestHeaderMapImpl{{\":method\", \"CONNECT\"},\n                                     {\":path\", \"/\"},\n                                     {\":protocol\", \"bytestream\"},\n                                     {\":scheme\", \"https\"},\n                                     {\":authority\", \"host:80\"}});\n  // If the connection is established (created, set to half close, and then the\n  // FIN arrives), make sure the FIN arrives, and send a FIN from upstream.\n  if (fake_upstreams_[0]->waitForRawConnection(fake_raw_upstream_connection_) &&\n      fake_raw_upstream_connection_->connected()) {\n    ASSERT_TRUE(fake_raw_upstream_connection_->waitForHalfClose());\n    ASSERT_TRUE(fake_raw_upstream_connection_->close());\n  }\n\n  // Either with early close, or half close, the FIN from upstream should result\n  // in clean stream teardown.\n  ASSERT_TRUE(response_->waitForEndStream());\n  ASSERT_FALSE(response_->reset());\n}\n\nTEST_P(ConnectTerminationIntegrationTest, BasicMaxStreamDuration) {\n  setUpstreamProtocol(upstreamProtocol());\n  config_helper_.addConfigModifier([](envoy::config::bootstrap::v3::Bootstrap& bootstrap) {\n    ConfigHelper::HttpProtocolOptions protocol_options;\n    protocol_options.mutable_common_http_protocol_options()\n        ->mutable_max_stream_duration()\n        ->MergeFrom(ProtobufUtil::TimeUtil::MillisecondsToDuration(1000));\n    ConfigHelper::setProtocolOptions(*bootstrap.mutable_static_resources()->mutable_clusters(0),\n                                     protocol_options);\n  });\n\n  initialize();\n  setUpConnection();\n  sendBidirectionalData();\n\n  test_server_->waitForCounterGe(\"cluster.cluster_0.upstream_rq_max_duration_reached\", 1);\n\n  if (downstream_protocol_ == Http::CodecType::HTTP1) {\n    ASSERT_TRUE(codec_client_->waitForDisconnect());\n  } else {\n    ASSERT_TRUE(response_->waitForReset());\n    codec_client_->close();\n  }\n}\n\n// Verify Envoy ignores the Host field in HTTP/1.1 CONNECT message.\nTEST_P(ConnectTerminationIntegrationTest, IgnoreH11HostField) {\n  // This test is HTTP/1.1 specific.\n  if (downstream_protocol_ != Http::CodecType::HTTP1) {\n    return;\n  }\n  initialize();\n\n  std::string response;\n  const std::string full_request = \"CONNECT www.foo.com:443 HTTP/1.1\\r\\n\"\n                                   \"Host: www.bar.com:443\\r\\n\\r\\n\";\n  EXPECT_LOG_CONTAINS(\n      \"\",\n      \"':authority', 'www.foo.com:443'\\n\"\n      \"':method', 'CONNECT'\",\n      sendRawHttpAndWaitForResponse(lookupPort(\"http\"), full_request.c_str(), &response, false););\n}\n\n// For this class, forward the CONNECT request upstream\nclass ProxyingConnectIntegrationTest : public HttpProtocolIntegrationTest {\npublic:\n  void initialize() override {\n    config_helper_.addConfigModifier(\n        [&](envoy::extensions::filters::network::http_connection_manager::v3::HttpConnectionManager&\n                hcm) -> void {\n          ConfigHelper::setConnectConfig(hcm, false, false,\n                                         downstream_protocol_ == Http::CodecType::HTTP3);\n        });\n\n    HttpProtocolIntegrationTest::initialize();\n  }\n\n  Http::TestRequestHeaderMapImpl connect_headers_{{\":method\", \"CONNECT\"},\n                                                  {\":path\", \"/\"},\n                                                  {\":protocol\", \"bytestream\"},\n                                                  {\":scheme\", \"https\"},\n                                                  {\":authority\", \"host:80\"}};\n  IntegrationStreamDecoderPtr response_;\n};\n\nINSTANTIATE_TEST_SUITE_P(Protocols, ProxyingConnectIntegrationTest,\n                         testing::ValuesIn(HttpProtocolIntegrationTest::getProtocolTestParams(\n                             {Http::CodecType::HTTP1, Http::CodecType::HTTP2,\n                              Http::CodecType::HTTP3},\n                             {Http::CodecType::HTTP1})),\n                         HttpProtocolIntegrationTest::protocolTestParamsToString);\n\nTEST_P(ProxyingConnectIntegrationTest, ProxyConnect) {\n  initialize();\n\n  // Send request headers.\n  codec_client_ = makeHttpConnection(lookupPort(\"http\"));\n  auto encoder_decoder = codec_client_->startRequest(connect_headers_);\n  request_encoder_ = &encoder_decoder.first;\n  response_ = std::move(encoder_decoder.second);\n\n  // Wait for them to arrive upstream.\n  AssertionResult result =\n      fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_);\n  RELEASE_ASSERT(result, result.message());\n  result = fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_);\n  RELEASE_ASSERT(result, result.message());\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n  EXPECT_EQ(upstream_request_->headers().get(Http::Headers::get().Method)[0]->value(), \"CONNECT\");\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    EXPECT_TRUE(upstream_request_->headers().get(Http::Headers::get().Protocol).empty());\n  } else {\n    EXPECT_EQ(upstream_request_->headers().get(Http::Headers::get().Protocol)[0]->value(),\n              \"bytestream\");\n  }\n\n  // Send response headers\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  // Wait for them to arrive downstream.\n  response_->waitForHeaders();\n  EXPECT_EQ(\"200\", response_->headers().getStatusValue());\n\n  // Make sure that even once the response has started, that data can continue to go upstream.\n  codec_client_->sendData(*request_encoder_, \"hello\", false);\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, 5));\n\n  // Also test upstream to downstream data.\n  upstream_request_->encodeData(12, false);\n  response_->waitForBodyData(12);\n\n  cleanupUpstreamAndDownstream();\n}\n\nTEST_P(ProxyingConnectIntegrationTest, ProxyConnectWithPortStripping) {\n  config_helper_.addConfigModifier(\n      [&](envoy::extensions::filters::network::http_connection_manager::v3::HttpConnectionManager&\n              hcm) {\n        hcm.set_strip_any_host_port(true);\n        auto* route_config = hcm.mutable_route_config();\n        auto* header_value_option = route_config->mutable_request_headers_to_add()->Add();\n        auto* mutable_header = header_value_option->mutable_header();\n        mutable_header->set_key(\"Host-In-Envoy\");\n        mutable_header->set_value(\"%REQ(:AUTHORITY)%\");\n      });\n\n  initialize();\n\n  // Send request headers.\n  codec_client_ = makeHttpConnection(lookupPort(\"http\"));\n  auto encoder_decoder = codec_client_->startRequest(connect_headers_);\n  request_encoder_ = &encoder_decoder.first;\n  response_ = std::move(encoder_decoder.second);\n\n  // Wait for them to arrive upstream.\n  AssertionResult result =\n      fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_);\n  RELEASE_ASSERT(result, result.message());\n  result = fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_);\n  RELEASE_ASSERT(result, result.message());\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n  EXPECT_EQ(upstream_request_->headers().getMethodValue(), \"CONNECT\");\n  EXPECT_EQ(upstream_request_->headers().getHostValue(), \"host:80\");\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    EXPECT_TRUE(upstream_request_->headers().getProtocolValue().empty());\n  } else {\n    EXPECT_EQ(upstream_request_->headers().getProtocolValue(), \"bytestream\");\n  }\n  auto stripped_host = upstream_request_->headers().get(Http::LowerCaseString(\"host-in-envoy\"));\n  ASSERT_EQ(stripped_host.size(), 1);\n  EXPECT_EQ(stripped_host[0]->value(), \"host\");\n\n  // Send response headers\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  // Wait for them to arrive downstream.\n  response_->waitForHeaders();\n  EXPECT_EQ(\"200\", response_->headers().getStatusValue());\n\n  // Make sure that even once the response has started, that data can continue to go upstream.\n  codec_client_->sendData(*request_encoder_, \"hello\", false);\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, 5));\n\n  // Also test upstream to downstream data.\n  upstream_request_->encodeData(12, false);\n  response_->waitForBodyData(12);\n\n  cleanupUpstreamAndDownstream();\n}\n\nTEST_P(ProxyingConnectIntegrationTest, ProxyConnectWithIP) {\n  initialize();\n\n  // Send request headers.\n  codec_client_ = makeHttpConnection(lookupPort(\"http\"));\n  connect_headers_.setHost(\"1.2.3.4:80\");\n  auto encoder_decoder = codec_client_->startRequest(connect_headers_);\n  request_encoder_ = &encoder_decoder.first;\n  response_ = std::move(encoder_decoder.second);\n\n  // Wait for them to arrive upstream.\n  AssertionResult result =\n      fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_);\n  RELEASE_ASSERT(result, result.message());\n  result = fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_);\n  RELEASE_ASSERT(result, result.message());\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n  EXPECT_EQ(upstream_request_->headers().get(Http::Headers::get().Method)[0]->value(), \"CONNECT\");\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    EXPECT_TRUE(upstream_request_->headers().get(Http::Headers::get().Protocol).empty());\n  } else {\n    EXPECT_EQ(upstream_request_->headers().get(Http::Headers::get().Protocol)[0]->value(),\n              \"bytestream\");\n  }\n\n  // Send response headers\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  // Wait for them to arrive downstream.\n  response_->waitForHeaders();\n  EXPECT_EQ(\"200\", response_->headers().getStatusValue());\n\n  cleanupUpstreamAndDownstream();\n}\n\nINSTANTIATE_TEST_SUITE_P(HttpAndIpVersions, ConnectTerminationIntegrationTest,\n                         testing::ValuesIn(HttpProtocolIntegrationTest::getProtocolTestParams(\n                             {Http::CodecType::HTTP1, Http::CodecType::HTTP2,\n                              Http::CodecType::HTTP3},\n                             {Http::CodecType::HTTP1})),\n                         HttpProtocolIntegrationTest::protocolTestParamsToString);\n\nusing Params = std::tuple<Network::Address::IpVersion, Http::CodecType>;\n\n// Tunneling downstream TCP over an upstream HTTP CONNECT tunnel.\nclass TcpTunnelingIntegrationTest : public HttpProtocolIntegrationTest {\npublic:\n  void SetUp() override {\n    enableHalfClose(true);\n\n    config_helper_.addConfigModifier(\n        [&](envoy::config::bootstrap::v3::Bootstrap& bootstrap) -> void {\n          envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy proxy_config;\n          proxy_config.set_stat_prefix(\"tcp_stats\");\n          proxy_config.set_cluster(\"cluster_0\");\n          proxy_config.mutable_tunneling_config()->set_hostname(\"host.com:80\");\n\n          auto* listener = bootstrap.mutable_static_resources()->add_listeners();\n          listener->set_name(\"tcp_proxy\");\n          auto* socket_address = listener->mutable_address()->mutable_socket_address();\n          socket_address->set_address(Network::Test::getLoopbackAddressString(version_));\n          socket_address->set_port_value(0);\n\n          auto* filter_chain = listener->add_filter_chains();\n          auto* filter = filter_chain->add_filters();\n          filter->mutable_typed_config()->PackFrom(proxy_config);\n          filter->set_name(\"envoy.filters.network.tcp_proxy\");\n        });\n    HttpProtocolIntegrationTest::SetUp();\n  }\n\n  void setUpConnection(FakeHttpConnectionPtr& fake_upstream_connection) {\n    // Start a connection, and verify the upgrade headers are received upstream.\n    tcp_client_ = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n    if (!fake_upstream_connection) {\n      ASSERT_TRUE(\n          fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection));\n    }\n    ASSERT_TRUE(fake_upstream_connection->waitForNewStream(*dispatcher_, upstream_request_));\n    ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n\n    // Send upgrade headers downstream, fully establishing the connection.\n    upstream_request_->encodeHeaders(default_response_headers_, false);\n  }\n\n  void sendBidiData(FakeHttpConnectionPtr& fake_upstream_connection, bool send_goaway = false) {\n    // Send some data from downstream to upstream, and make sure it goes through.\n    ASSERT_TRUE(tcp_client_->write(\"hello\", false));\n    ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, 5));\n\n    if (send_goaway) {\n      fake_upstream_connection->encodeGoAway();\n    }\n    // Send data from upstream to downstream.\n    upstream_request_->encodeData(12, false);\n    ASSERT_TRUE(tcp_client_->waitForData(12));\n  }\n\n  void closeConnection(FakeHttpConnectionPtr& fake_upstream_connection) {\n    // Now send more data and close the TCP client. This should be treated as half close, so the\n    // data should go through.\n    ASSERT_TRUE(tcp_client_->write(\"hello\", false));\n    tcp_client_->close();\n    ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, 5));\n    if (upstreamProtocol() == Http::CodecType::HTTP1) {\n      ASSERT_TRUE(fake_upstream_connection->waitForDisconnect());\n    } else {\n      ASSERT_TRUE(upstream_request_->waitForEndStream(*dispatcher_));\n      // If the upstream now sends 'end stream' the connection is fully closed.\n      upstream_request_->encodeData(0, true);\n    }\n  }\n\n  IntegrationTcpClientPtr tcp_client_;\n};\n\nTEST_P(TcpTunnelingIntegrationTest, Basic) {\n  initialize();\n\n  setUpConnection(fake_upstream_connection_);\n  sendBidiData(fake_upstream_connection_);\n  closeConnection(fake_upstream_connection_);\n}\n\nTEST_P(TcpTunnelingIntegrationTest, SendDataUpstreamAfterUpstreamClose) {\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    // HTTP/1.1 can't frame with FIN bits.\n    return;\n  }\n  initialize();\n\n  setUpConnection(fake_upstream_connection_);\n  sendBidiData(fake_upstream_connection_);\n  // Close upstream.\n  upstream_request_->encodeData(2, true);\n  tcp_client_->waitForHalfClose();\n\n  // Now send data upstream.\n  ASSERT_TRUE(tcp_client_->write(\"hello\", false));\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, 5));\n\n  // Finally close and clean up.\n  tcp_client_->close();\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n  } else {\n    ASSERT_TRUE(upstream_request_->waitForEndStream(*dispatcher_));\n  }\n}\n\nTEST_P(TcpTunnelingIntegrationTest, BasicUsePost) {\n  // Enable using POST.\n  config_helper_.addConfigModifier([&](envoy::config::bootstrap::v3::Bootstrap& bootstrap) -> void {\n    envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy proxy_config;\n    proxy_config.set_stat_prefix(\"tcp_stats\");\n    proxy_config.set_cluster(\"cluster_0\");\n    proxy_config.mutable_tunneling_config()->set_hostname(\"host.com:80\");\n    proxy_config.mutable_tunneling_config()->set_use_post(true);\n\n    auto* listeners = bootstrap.mutable_static_resources()->mutable_listeners();\n    for (auto& listener : *listeners) {\n      if (listener.name() != \"tcp_proxy\") {\n        continue;\n      }\n      auto* filter_chain = listener.mutable_filter_chains(0);\n      auto* filter = filter_chain->mutable_filters(0);\n      filter->mutable_typed_config()->PackFrom(proxy_config);\n      break;\n    }\n  });\n\n  initialize();\n\n  // Start a connection, and verify the upgrade headers are received upstream.\n  tcp_client_ = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n  EXPECT_EQ(upstream_request_->headers().get(Http::Headers::get().Method)[0]->value(), \"POST\");\n\n  // Send upgrade headers downstream, fully establishing the connection.\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  sendBidiData(fake_upstream_connection_);\n  closeConnection(fake_upstream_connection_);\n}\n\nTEST_P(TcpTunnelingIntegrationTest, BasicHeaderEvaluationTunnelingConfig) {\n  // Set the \"downstream-local-ip\" header in the CONNECT request.\n  config_helper_.addConfigModifier([&](envoy::config::bootstrap::v3::Bootstrap& bootstrap) -> void {\n    envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy proxy_config;\n    proxy_config.set_stat_prefix(\"tcp_stats\");\n    proxy_config.set_cluster(\"cluster_0\");\n    proxy_config.mutable_tunneling_config()->set_hostname(\"host.com:80\");\n    auto new_header = proxy_config.mutable_tunneling_config()->mutable_headers_to_add()->Add();\n    new_header->mutable_header()->set_key(\"downstream-local-ip\");\n    new_header->mutable_header()->set_value(\"%DOWNSTREAM_LOCAL_ADDRESS_WITHOUT_PORT%\");\n\n    auto* listeners = bootstrap.mutable_static_resources()->mutable_listeners();\n    for (auto& listener : *listeners) {\n      if (listener.name() != \"tcp_proxy\") {\n        continue;\n      }\n      auto* filter_chain = listener.mutable_filter_chains(0);\n      auto* filter = filter_chain->mutable_filters(0);\n      filter->mutable_typed_config()->PackFrom(proxy_config);\n      break;\n    }\n  });\n\n  initialize();\n\n  // Start a connection, and verify the upgrade headers are received upstream.\n  tcp_client_ = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n  EXPECT_EQ(upstream_request_->headers().getMethodValue(), \"CONNECT\");\n\n  // Verify that the connect request has a \"downstream-local-ip\" header and its value is the\n  // loopback address.\n  EXPECT_EQ(\n      upstream_request_->headers().get(Envoy::Http::LowerCaseString(\"downstream-local-ip\")).size(),\n      1);\n  EXPECT_EQ(upstream_request_->headers()\n                .get(Envoy::Http::LowerCaseString(\"downstream-local-ip\"))[0]\n                ->value()\n                .getStringView(),\n            Network::Test::getLoopbackAddressString(version_));\n\n  // Send upgrade headers downstream, fully establishing the connection.\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n  sendBidiData(fake_upstream_connection_);\n  closeConnection(fake_upstream_connection_);\n}\n\n// Verify that the header evaluator is updated without lifetime issue.\nTEST_P(TcpTunnelingIntegrationTest, HeaderEvaluatorConfigUpdate) {\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    return;\n  }\n  envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy proxy_config;\n  config_helper_.addConfigModifier([&](envoy::config::bootstrap::v3::Bootstrap& bootstrap) -> void {\n    proxy_config.set_stat_prefix(\"tcp_stats\");\n    proxy_config.set_cluster(\"cluster_0\");\n    proxy_config.mutable_tunneling_config()->set_hostname(\"host.com:80\");\n    auto address_header = proxy_config.mutable_tunneling_config()->mutable_headers_to_add()->Add();\n    address_header->mutable_header()->set_key(\"config-version\");\n    address_header->mutable_header()->set_value(\"1\");\n\n    auto* listeners = bootstrap.mutable_static_resources()->mutable_listeners();\n    for (auto& listener : *listeners) {\n      if (listener.name() != \"tcp_proxy\") {\n        continue;\n      }\n      auto* filter_chain = listener.mutable_filter_chains(0);\n      auto* filter = filter_chain->mutable_filters(0);\n      filter->mutable_typed_config()->PackFrom(proxy_config);\n      break;\n    }\n  });\n\n  initialize();\n  // Start a connection, and verify the upgrade headers are received upstream.\n  tcp_client_ = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n  EXPECT_EQ(upstream_request_->headers().getMethodValue(), \"CONNECT\");\n\n  EXPECT_EQ(upstream_request_->headers()\n                .get(Envoy::Http::LowerCaseString(\"config-version\"))[0]\n                ->value()\n                .getStringView(),\n            \"1\");\n\n  // Send upgrade headers downstream, fully establishing the connection.\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n  ASSERT_TRUE(tcp_client_->write(\"hello\", false));\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, 5));\n\n  ConfigHelper new_config_helper(\n      version_, *api_, MessageUtil::getJsonStringFromMessageOrDie(config_helper_.bootstrap()));\n  new_config_helper.addConfigModifier(\n      [&](envoy::config::bootstrap::v3::Bootstrap& bootstrap) -> void {\n        auto* header =\n            proxy_config.mutable_tunneling_config()->mutable_headers_to_add()->Mutable(0);\n        header->mutable_header()->set_value(\"2\");\n\n        auto* listeners = bootstrap.mutable_static_resources()->mutable_listeners();\n        for (auto& listener : *listeners) {\n          if (listener.name() != \"tcp_proxy\") {\n            continue;\n          }\n          // trigger full listener update.\n          (*(*listener.mutable_metadata()->mutable_filter_metadata())[\"random_filter_name\"]\n                .mutable_fields())[\"random_key\"]\n              .set_number_value(2);\n          auto* filter_chain = listener.mutable_filter_chains(0);\n          auto* filter = filter_chain->mutable_filters(0);\n          filter->mutable_typed_config()->PackFrom(proxy_config);\n          break;\n        }\n      });\n  new_config_helper.setLds(\"1\");\n\n  test_server_->waitForCounterEq(\"listener_manager.listener_modified\", 1);\n  test_server_->waitForGaugeEq(\"listener_manager.total_listeners_draining\", 0);\n\n  // Start a connection, and verify the upgrade headers are received upstream.\n  auto tcp_client_2 = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n\n  // The upstream http2 or http3 connection is reused.\n  ASSERT_TRUE(fake_upstream_connection_ != nullptr);\n\n  FakeStreamPtr upstream_request_2;\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_2));\n  ASSERT_TRUE(upstream_request_2->waitForHeadersComplete());\n  // Verify the tcp proxy new header evaluator is applied.\n  EXPECT_EQ(upstream_request_2->headers()\n                .get(Envoy::Http::LowerCaseString(\"config-version\"))[0]\n                ->value()\n                .getStringView(),\n            \"2\");\n  upstream_request_2->encodeHeaders(default_response_headers_, false);\n\n  tcp_client_->close();\n  tcp_client_2->close();\n\n  ASSERT_TRUE(upstream_request_2->waitForEndStream(*dispatcher_));\n  // If the upstream now sends 'end stream' the connection is fully closed.\n  upstream_request_2->encodeData(0, true);\n  ASSERT_TRUE(fake_upstream_connection_->waitForNoPost());\n}\n\nTEST_P(TcpTunnelingIntegrationTest, Goaway) {\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    return;\n  }\n  initialize();\n\n  // Send bidirectional data, including a goaway.\n  // This should result in the first connection being torn down.\n  setUpConnection(fake_upstream_connection_);\n  sendBidiData(fake_upstream_connection_, true);\n  closeConnection(fake_upstream_connection_);\n  test_server_->waitForCounterGe(\"cluster.cluster_0.upstream_cx_destroy\", 1);\n\n  // Make sure a subsequent connection can be established successfully.\n  FakeHttpConnectionPtr fake_upstream_connection;\n  setUpConnection(fake_upstream_connection);\n  sendBidiData(fake_upstream_connection);\n  closeConnection(fake_upstream_connection_);\n\n  // Make sure the last stream is finished before doing test teardown.\n  fake_upstream_connection->encodeGoAway();\n  test_server_->waitForCounterGe(\"cluster.cluster_0.upstream_cx_destroy\", 2);\n}\n\nTEST_P(TcpTunnelingIntegrationTest, InvalidResponseHeaders) {\n  initialize();\n\n  // Start a connection, and verify the upgrade headers are received upstream.\n  tcp_client_ = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n\n  // Send invalid response_ headers, and verify that the client disconnects and\n  // upstream gets a stream reset.\n  default_response_headers_.setStatus(enumToInt(Http::Code::ServiceUnavailable));\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n  } else {\n    ASSERT_TRUE(upstream_request_->waitForReset());\n  }\n\n  // The connection should be fully closed, but the client has no way of knowing\n  // that. Ensure the FIN is read and clean up state.\n  tcp_client_->waitForHalfClose();\n  tcp_client_->close();\n}\n\nTEST_P(TcpTunnelingIntegrationTest, CloseUpstreamFirst) {\n  initialize();\n\n  setUpConnection(fake_upstream_connection_);\n  sendBidiData(fake_upstream_connection_);\n\n  // Send data from upstream to downstream with an end stream and make sure the data is received\n  // before the connection is half-closed.\n  upstream_request_->encodeData(12, true);\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    ASSERT_TRUE(fake_upstream_connection_->close());\n  }\n  ASSERT_TRUE(tcp_client_->waitForData(12));\n  tcp_client_->waitForHalfClose();\n\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n    tcp_client_->close();\n  } else {\n    // Attempt to send data upstream.\n    // should go through.\n    ASSERT_TRUE(tcp_client_->write(\"hello\", false));\n    ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, 5));\n\n    ASSERT_TRUE(tcp_client_->write(\"hello\", true));\n    ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, 5));\n    ASSERT_TRUE(upstream_request_->waitForEndStream(*dispatcher_));\n  }\n}\n\nTEST_P(TcpTunnelingIntegrationTest, ResetStreamTest) {\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    return;\n  }\n  enableHalfClose(false);\n  initialize();\n\n  setUpConnection(fake_upstream_connection_);\n\n  // Reset the stream.\n  upstream_request_->encodeResetStream();\n  tcp_client_->waitForDisconnect();\n}\n\nTEST_P(TcpTunnelingIntegrationTest, TestIdletimeoutWithLargeOutstandingData) {\n  enableHalfClose(false);\n  config_helper_.setBufferLimits(1024, 1024);\n  config_helper_.addConfigModifier([&](envoy::config::bootstrap::v3::Bootstrap& bootstrap) -> void {\n    auto* listener = bootstrap.mutable_static_resources()->mutable_listeners(1);\n    auto* filter_chain = listener->mutable_filter_chains(0);\n    auto* config_blob = filter_chain->mutable_filters(0)->mutable_typed_config();\n\n    ASSERT_TRUE(config_blob->Is<envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy>());\n    auto tcp_proxy_config =\n        MessageUtil::anyConvert<envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy>(\n            *config_blob);\n    tcp_proxy_config.mutable_idle_timeout()->set_nanos(\n        std::chrono::duration_cast<std::chrono::nanoseconds>(std::chrono::milliseconds(500))\n            .count());\n    config_blob->PackFrom(tcp_proxy_config);\n  });\n\n  initialize();\n\n  setUpConnection(fake_upstream_connection_);\n\n  std::string data(1024 * 16, 'a');\n  ASSERT_TRUE(tcp_client_->write(data));\n  upstream_request_->encodeData(data, false);\n\n  tcp_client_->waitForDisconnect();\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n    tcp_client_->close();\n  } else {\n    ASSERT_TRUE(upstream_request_->waitForReset());\n  }\n}\n\n// Test that a downstream flush works correctly (all data is flushed)\nTEST_P(TcpTunnelingIntegrationTest, TcpProxyDownstreamFlush) {\n  // Use a very large size to make sure it is larger than the kernel socket read buffer.\n  const uint32_t size = 50 * 1024 * 1024;\n  config_helper_.setBufferLimits(size / 4, size / 4);\n  initialize();\n\n  setUpConnection(fake_upstream_connection_);\n\n  tcp_client_->readDisable(true);\n  std::string data(size, 'a');\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    ASSERT_TRUE(tcp_client_->write(\"hello\", false));\n    ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, 5));\n\n    upstream_request_->encodeData(data, true);\n    ASSERT_TRUE(fake_upstream_connection_->close());\n  } else {\n    ASSERT_TRUE(tcp_client_->write(\"\", true));\n\n    // This ensures that readDisable(true) has been run on its thread\n    // before tcp_client_ starts writing.\n    ASSERT_TRUE(upstream_request_->waitForEndStream(*dispatcher_));\n\n    upstream_request_->encodeData(data, true);\n  }\n\n  test_server_->waitForCounterGe(\"cluster.cluster_0.upstream_flow_control_paused_reading_total\", 1);\n  tcp_client_->readDisable(false);\n  tcp_client_->waitForData(data);\n  tcp_client_->waitForHalfClose();\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    tcp_client_->close();\n  }\n}\n\n// Test that an upstream flush works correctly (all data is flushed)\nTEST_P(TcpTunnelingIntegrationTest, TcpProxyUpstreamFlush) {\n  if (upstreamProtocol() == Http::CodecType::HTTP3) {\n    // The payload data depends on having TCP buffers upstream and downstream.\n    // For HTTP/3, upstream, the flow control window will back up sooner, Envoy\n    // flow control will kick in, and the large write of |data| will fail to\n    // complete.\n    return;\n  }\n  // Use a very large size to make sure it is larger than the kernel socket read buffer.\n  const uint32_t size = 50 * 1024 * 1024;\n  config_helper_.setBufferLimits(size, size);\n  initialize();\n\n  setUpConnection(fake_upstream_connection_);\n\n  upstream_request_->readDisable(true);\n  upstream_request_->encodeData(\"hello\", false);\n\n  // This ensures that fake_upstream_connection->readDisable has been run on its thread\n  // before tcp_client_ starts writing.\n  ASSERT_TRUE(tcp_client_->waitForData(5));\n\n  std::string data(size, 'a');\n  ASSERT_TRUE(tcp_client_->write(data, true));\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    tcp_client_->close();\n\n    upstream_request_->readDisable(false);\n    ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, size));\n    ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n  } else {\n    // Note that upstream_flush_active will *not* be incremented for the HTTP\n    // tunneling case. The data is already written to the stream, so no drainer\n    // is necessary.\n    upstream_request_->readDisable(false);\n    ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, size));\n    ASSERT_TRUE(upstream_request_->waitForEndStream(*dispatcher_));\n    upstream_request_->encodeData(\"world\", true);\n    tcp_client_->waitForHalfClose();\n  }\n}\n\n// Test that h2/h3 connection is reused.\nTEST_P(TcpTunnelingIntegrationTest, ConnectionReuse) {\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    return;\n  }\n  initialize();\n\n  setUpConnection(fake_upstream_connection_);\n\n  // Send data in both directions.\n  ASSERT_TRUE(tcp_client_->write(\"hello1\", false));\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, \"hello1\"));\n\n  // Send data from upstream to downstream with an end stream and make sure the data is received\n  // before the connection is half-closed.\n  upstream_request_->encodeData(\"world1\", true);\n  tcp_client_->waitForData(\"world1\");\n  tcp_client_->waitForHalfClose();\n  tcp_client_->close();\n  ASSERT_TRUE(upstream_request_->waitForEndStream(*dispatcher_));\n\n  // Establish a new connection.\n  IntegrationTcpClientPtr tcp_client_2 = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n\n  // The new CONNECT stream is established in the existing h2 connection.\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  ASSERT_TRUE(tcp_client_2->write(\"hello2\", false));\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, \"hello2\"));\n\n  // Send data from upstream to downstream with an end stream and make sure the data is received\n  // before the connection is half-closed.\n  upstream_request_->encodeData(\"world2\", true);\n  tcp_client_2->waitForData(\"world2\");\n  tcp_client_2->waitForHalfClose();\n  tcp_client_2->close();\n  ASSERT_TRUE(upstream_request_->waitForEndStream(*dispatcher_));\n}\n\n// Test that with HTTP1 we have no connection reuse with downstream close.\nTEST_P(TcpTunnelingIntegrationTest, H1NoConnectionReuse) {\n  if (upstreamProtocol() != Http::CodecType::HTTP1) {\n    return;\n  }\n  initialize();\n\n  setUpConnection(fake_upstream_connection_);\n\n  // Send data in both directions.\n  ASSERT_TRUE(tcp_client_->write(\"hello1\", false));\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, \"hello1\"));\n\n  // Send data from upstream to downstream and close the connection\n  // from downstream.\n  upstream_request_->encodeData(\"world1\", false);\n  tcp_client_->waitForData(\"world1\");\n  tcp_client_->close();\n\n  ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n\n  // Establish a new connection.\n  IntegrationTcpClientPtr tcp_client_2 = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n  // A new connection is established\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  ASSERT_TRUE(tcp_client_2->write(\"hello1\", false));\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, \"hello1\"));\n  tcp_client_2->close();\n\n  ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n}\n\n// Test that with HTTP1 we have no connection with upstream close.\nTEST_P(TcpTunnelingIntegrationTest, H1UpstreamCloseNoConnectionReuse) {\n  if (upstreamProtocol() == Http::CodecType::HTTP2) {\n    return;\n  }\n  initialize();\n\n  // Establish a connection.\n  IntegrationTcpClientPtr tcp_client_1 = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  // Send data in both directions.\n  ASSERT_TRUE(tcp_client_1->write(\"hello1\", false));\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, \"hello1\"));\n\n  // Send data from upstream to downstream and close the connection\n  // from the upstream.\n  upstream_request_->encodeData(\"world1\", false);\n  tcp_client_1->waitForData(\"world1\");\n  ASSERT_TRUE(fake_upstream_connection_->close());\n\n  ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n  tcp_client_1->waitForHalfClose();\n  tcp_client_1->close();\n\n  // Establish a new connection.\n  IntegrationTcpClientPtr tcp_client_2 = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n  // A new connection is established\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  ASSERT_TRUE(tcp_client_2->write(\"hello2\", false));\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, \"hello2\"));\n  ASSERT_TRUE(fake_upstream_connection_->close());\n\n  ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n  tcp_client_2->waitForHalfClose();\n  tcp_client_2->close();\n}\n\nTEST_P(TcpTunnelingIntegrationTest, 2xxStatusCodeValidHttp1) {\n  if (upstreamProtocol() != Http::CodecType::HTTP1) {\n    return;\n  }\n  initialize();\n\n  // Start a connection, and verify the upgrade headers are received upstream.\n  tcp_client_ = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n\n  // Send valid response headers, in HTTP1 all status codes in the 2xx range\n  // are considered valid.\n  default_response_headers_.setStatus(enumToInt(Http::Code::Accepted));\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  sendBidiData(fake_upstream_connection_);\n\n  // Close the downstream connection and wait for upstream disconnect\n  tcp_client_->close();\n  ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n}\n\nTEST_P(TcpTunnelingIntegrationTest, ContentLengthHeaderIgnoredHttp1) {\n  if (upstreamProtocol() != Http::CodecType::HTTP1) {\n    return;\n  }\n  initialize();\n\n  // Start a connection, and verify the upgrade headers are received upstream.\n  tcp_client_ = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n\n  // Send upgrade headers downstream, including content-length that must be\n  // ignored.\n  default_response_headers_.setStatus(enumToInt(Http::Code::IMUsed));\n  default_response_headers_.setContentLength(10);\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  // Send data from upstream to downstream.\n  upstream_request_->encodeData(12, false);\n  ASSERT_TRUE(tcp_client_->waitForData(12));\n\n  // Now send some data and close the TCP client.\n  ASSERT_TRUE(tcp_client_->write(\"hello\", false));\n  tcp_client_->close();\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, 5));\n  ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n}\n\nTEST_P(TcpTunnelingIntegrationTest, TransferEncodingHeaderIgnoredHttp1) {\n  if (upstreamProtocol() != Http::CodecType::HTTP1) {\n    return;\n  }\n  initialize();\n\n  // Start a connection, and verify the upgrade headers are received upstream.\n  tcp_client_ = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n  // Using raw connection to be able to set Transfer-encoding header.\n  FakeRawConnectionPtr fake_upstream_connection;\n  ASSERT_TRUE(fake_upstreams_[0]->waitForRawConnection(fake_upstream_connection));\n  std::string data;\n  ASSERT_TRUE(fake_upstream_connection->waitForData(\n      FakeRawConnection::waitForInexactMatch(\"\\r\\n\\r\\n\"), &data));\n  ASSERT_THAT(data, testing::HasSubstr(\"CONNECT host.com:80 HTTP/1.1\"));\n\n  // Send upgrade headers downstream, fully establishing the connection.\n  ASSERT_TRUE(\n      fake_upstream_connection->write(\"HTTP/1.1 200 OK\\r\\nTransfer-encoding: chunked\\r\\n\\r\\n\"));\n\n  // Now send some data and close the TCP client.\n  ASSERT_TRUE(tcp_client_->write(\"hello\"));\n  ASSERT_TRUE(\n      fake_upstream_connection->waitForData(FakeRawConnection::waitForInexactMatch(\"hello\")));\n\n  // Close connections.\n  ASSERT_TRUE(fake_upstream_connection->close());\n  ASSERT_TRUE(fake_upstream_connection->waitForDisconnect());\n  tcp_client_->close();\n}\n\nTEST_P(TcpTunnelingIntegrationTest, DeferTransmitDataUntilSuccessConnectResponseIsReceived) {\n  initialize();\n\n  // Start a connection, and verify the upgrade headers are received upstream.\n  tcp_client_ = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n\n  // Send some data straight away.\n  ASSERT_TRUE(tcp_client_->write(\"hello\", false));\n\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n\n  // Wait a bit, no data should go through.\n  ASSERT_FALSE(upstream_request_->waitForData(*dispatcher_, 1, std::chrono::milliseconds(100)));\n\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, 5));\n\n  tcp_client_->close();\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n  } else {\n    ASSERT_TRUE(upstream_request_->waitForEndStream(*dispatcher_));\n    // If the upstream now sends 'end stream' the connection is fully closed.\n    upstream_request_->encodeData(0, true);\n  }\n}\n\nTEST_P(TcpTunnelingIntegrationTest, NoDataTransmittedIfConnectFailureResponseIsReceived) {\n  initialize();\n\n  // Start a connection, and verify the upgrade headers are received upstream.\n  tcp_client_ = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n\n  // Send some data straight away.\n  ASSERT_TRUE(tcp_client_->write(\"hello\", false));\n\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n\n  default_response_headers_.setStatus(enumToInt(Http::Code::ServiceUnavailable));\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  // Wait a bit, no data should go through.\n  ASSERT_FALSE(upstream_request_->waitForData(*dispatcher_, 1, std::chrono::milliseconds(100)));\n\n  tcp_client_->close();\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n  } else {\n    ASSERT_TRUE(upstream_request_->waitForReset());\n  }\n}\n\nTEST_P(TcpTunnelingIntegrationTest, UpstreamDisconnectBeforeResponseReceived) {\n  initialize();\n\n  // Start a connection, and verify the upgrade headers are received upstream.\n  tcp_client_ = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n\n  ASSERT_TRUE(fake_upstream_connection_->close());\n  tcp_client_->waitForHalfClose();\n  tcp_client_->close();\n}\n\nINSTANTIATE_TEST_SUITE_P(IpAndHttpVersions, TcpTunnelingIntegrationTest,\n                         testing::ValuesIn(HttpProtocolIntegrationTest::getProtocolTestParams(\n                             {Http::CodecType::HTTP1},\n                             {Http::CodecType::HTTP1, Http::CodecType::HTTP2,\n                              Http::CodecType::HTTP3})),\n                         HttpProtocolIntegrationTest::protocolTestParamsToString);\n} // namespace\n} // namespace Envoy\n"], "fixing_code": ["1.22.0 (pending)\n================\n\nIncompatible Behavior Changes\n-----------------------------\n*Changes that are expected to cause an incompatibility if applicable; deployment changes are likely required*\n\n* tls: set TLS v1.2 as the default minimal version for servers. Users can still explicitly opt-in to 1.0 and 1.1 using :ref:`tls_minimum_protocol_version <envoy_v3_api_field_extensions.transport_sockets.tls.v3.TlsParameters.tls_minimum_protocol_version>`.\n\nMinor Behavior Changes\n----------------------\n*Changes that may cause incompatibilities for some users, but should not for most*\n\n* dynamic_forward_proxy: if a DNS resolution fails, failing immediately with a specific resolution error, rather than finishing up all local filters and failing to select an upstream host.\n* ext_authz: added requested server name in ext_authz network filter for auth review.\n* file: changed disk based files to truncate files which are not being appended to. This behavioral change can be temporarily reverted by setting runtime guard ``envoy.reloadable_features.append_or_truncate`` to false.\n* grpc: flip runtime guard ``envoy.reloadable_features.enable_grpc_async_client_cache`` to be default enabled. async grpc client created through getOrCreateRawAsyncClient will be cached by default.\n* http: avoiding delay-close for HTTP/1.0 responses framed by connection: close as well as HTTP/1.1 if the request is fully read. This means for responses to such requests, the FIN will be sent immediately after the response. This behavior can be temporarily reverted by setting ``envoy.reloadable_features.skip_delay_close`` to false.  If clients are are seen to be receiving sporadic partial responses and flipping this flag fixes it, please notify the project immediately.\n* http: now the max concurrent streams of http2 connection can not only be adjusted down according to the SETTINGS frame but also can be adjusted up, of course, it can not exceed the configured upper bounds. This fix is guarded by ``envoy.reloadable_features.http2_allow_capacity_increase_by_settings``.\n* http: when writing custom filters, `injectEncodedDataToFilterChain` and `injectDecodedDataToFilterChain` now trigger sending of headers if they were not yet sent due to `StopIteration`. Previously, calling one of the inject functions in that state would trigger an assertion. See issue #19891 for more details.\n* perf: ssl contexts are now tracked without scan based garbage collection and greatly improved the performance on secret update.\n\nBug Fixes\n---------\n*Changes expected to improve the state of the world and are unlikely to have negative effects*\n\n* access_log: fix memory leak when reopening an access log fails. Access logs will now try to be reopened on each subsequent flush attempt after a failure.\n* data plane: fixing error handling where writing to a socket failed while under the stack of processing. This should genreally affect HTTP/3. This behavioral change can be reverted by setting ``envoy.reloadable_features.allow_upstream_inline_write`` to false.\n* eds: fix the eds cluster update by allowing update on the locality of the cluster endpoints. This behavioral change can be temporarily reverted by setting runtime guard ``envoy.reloadable_features.support_locality_update_on_eds_cluster_endpoints`` to false.\n* tcp_proxy: fix a crash that occurs when configured for :ref:`upstream tunneling <envoy_v3_api_field_extensions.filters.network.tcp_proxy.v3.TcpProxy.tunneling_config>` and the downstream connection disconnects while the the upstream connection or http/2 stream is still being established.\n* tls: fix a bug while matching a certificate SAN with an exact value in ``match_typed_subject_alt_names`` of a listener where wildcard ``*`` character is not the only character of the dns label. Example, ``baz*.example.net`` and ``*baz.example.net`` and ``b*z.example.net`` will match ``baz1.example.net`` and ``foobaz.example.net`` and ``buzz.example.net``, respectively.\n* upstream: fix stack overflow when a cluster with large number of idle connections is removed.\n* xray: fix the AWS X-Ray tracer extension to not sample the trace if ``sampled=`` keyword is not present in the header ``x-amzn-trace-id``.\n\nRemoved Config or Runtime\n-------------------------\n*Normally occurs at the end of the* :ref:`deprecation period <deprecated>`\n\n* access_log: removed ``envoy.reloadable_features.unquote_log_string_values`` and legacy code paths.\n* grpc_bridge_filter: removed ``envoy.reloadable_features.grpc_bridge_stats_disabled`` and legacy code paths.\n* http: removed ``envoy.reloadable_features.hash_multiple_header_values`` and legacy code paths.\n* http: removed ``envoy.reloadable_features.no_chunked_encoding_header_for_304`` and legacy code paths.\n* http: removed ``envoy.reloadable_features.preserve_downstream_scheme`` and legacy code paths.\n* http: removed ``envoy.reloadable_features.require_strict_1xx_and_204_response_headers`` and ``envoy.reloadable_features.send_strict_1xx_and_204_response_headers`` and legacy code paths.\n* http: removed ``envoy.reloadable_features.strip_port_from_connect`` and legacy code paths.\n* http: removed ``envoy.reloadable_features.use_observable_cluster_name`` and legacy code paths.\n* http: removed ``envoy.reloadable_features.http_transport_failure_reason_in_body`` and legacy code paths.\n* http: removed ``envoy.reloadable_features.allow_response_for_timeout`` and legacy code paths.\n* http: removed ``envoy.reloadable_features.http2_consume_stream_refused_errors`` and legacy code paths.\n* http: removed ``envoy.reloadable_features.internal_redirects_with_body`` and legacy code paths.\n* udp: removed ``envoy.reloadable_features.udp_per_event_loop_read_limit`` and legacy code paths.\n* upstream: removed ``envoy.reloadable_features.health_check.graceful_goaway_handling`` and legacy code paths.\n* xds: removed ``envoy.reloadable_features.vhds_heartbeats`` and legacy code paths.\n\n\nNew Features\n------------\n* access_log: make consistent access_log format fields ``%(DOWN|DIRECT_DOWN|UP)STREAM_(LOCAL|REMOTE)_*%`` to provide all combinations of local & remote addresses for upstream & downstream connections.\n* admin: :http:post:`/logging` now accepts ``/logging?paths=name1:level1,name2:level2,...`` to change multiple log levels at once.\n* config: added new file based xDS configuration via :ref:`path_config_source <envoy_v3_api_field_config.core.v3.ConfigSource.path_config_source>`.\n  :ref:`watched_directory <envoy_v3_api_field_config.core.v3.PathConfigSource.watched_directory>` can\n  be used to setup an independent watch for when to reload the file path, for example when using\n  Kubernetes ConfigMaps to deliver configuration. See the linked documentation for more information.\n* cors: add dynamic support for headers ``access-control-allow-methods`` and ``access-control-allow-headers`` in cors.\n* http: added random_value_specifier in :ref:`weighted_clusters <envoy_v3_api_field_config.route.v3.RouteAction.weighted_clusters>` to allow random value to be specified from configuration proto.\n* http: added support for :ref:`proxy_status_config <envoy_v3_api_field_extensions.filters.network.http_connection_manager.v3.HttpConnectionManager.proxy_status_config>` for configuring `Proxy-Status <https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-proxy-status-08>`_ HTTP response header fields.\n* http: make consistent custom header format fields ``%(DOWN|DIRECT_DOWN|UP)STREAM_(LOCAL|REMOTE)_*%`` to provide all combinations of local & remote addresses for upstream & downstream connections.\n* http3: downstream HTTP/3 support is now GA! Upstream HTTP/3 also GA for specific deployments. See :ref:`here <arch_overview_http3>` for details.\n* http3: supports upstream HTTP/3 retries. Automatically retry `0-RTT safe requests <https://www.rfc-editor.org/rfc/rfc7231#section-4.2.1>`_ if they are rejected because they are sent `too early <https://datatracker.ietf.org/doc/html/rfc8470#section-5.2>`_. And automatically retry 0-RTT safe requests if connect attempt fails later on and the cluster is configured with TCP fallback. And add retry on ``http3-post-connect-failure`` policy which allows retry of failed HTTP/3 requests with TCP fallback even after handshake if the cluster is configured with TCP fallback. This feature is guarded by ``envoy.reloadable_features.conn_pool_new_stream_with_early_data_and_http3``.\n* matching: the matching API can now express a match tree that will always match by omitting a matcher at the top level.\n* outlier_detection: :ref:`max_ejection_time_jitter<envoy_v3_api_field_config.cluster.v3.OutlierDetection.base_ejection_time>` configuration added to allow adding a random value to the ejection time to prevent 'thundering herd' scenarios. Defaults to 0 so as to not break or change the behavior of existing deployments.\n\nDeprecated\n----------\n\n* config: deprecated :ref:`path <envoy_v3_api_field_config.core.v3.ConfigSource.path>` in favor of\n  :ref:`path_config_source <envoy_v3_api_field_config.core.v3.ConfigSource.path_config_source>`\n* http: removing support for long-deprecated old style filter names, e.g. envoy.router, envoy.lua.\n* re2: removed undocumented histograms ``re2.program_size`` and ``re2.exceeded_warn_level``.\n", "#include \"source/common/tcp_proxy/tcp_proxy.h\"\n\n#include <cstdint>\n#include <memory>\n#include <string>\n\n#include \"envoy/buffer/buffer.h\"\n#include \"envoy/config/accesslog/v3/accesslog.pb.h\"\n#include \"envoy/event/dispatcher.h\"\n#include \"envoy/event/timer.h\"\n#include \"envoy/extensions/filters/network/tcp_proxy/v3/tcp_proxy.pb.h\"\n#include \"envoy/stats/scope.h\"\n#include \"envoy/upstream/cluster_manager.h\"\n#include \"envoy/upstream/upstream.h\"\n\n#include \"source/common/access_log/access_log_impl.h\"\n#include \"source/common/common/assert.h\"\n#include \"source/common/common/empty_string.h\"\n#include \"source/common/common/enum_to_int.h\"\n#include \"source/common/common/fmt.h\"\n#include \"source/common/common/macros.h\"\n#include \"source/common/common/utility.h\"\n#include \"source/common/config/utility.h\"\n#include \"source/common/config/well_known_names.h\"\n#include \"source/common/network/application_protocol.h\"\n#include \"source/common/network/proxy_protocol_filter_state.h\"\n#include \"source/common/network/socket_option_factory.h\"\n#include \"source/common/network/transport_socket_options_impl.h\"\n#include \"source/common/network/upstream_server_name.h\"\n#include \"source/common/network/upstream_socket_options_filter_state.h\"\n#include \"source/common/router/metadatamatchcriteria_impl.h\"\n\nnamespace Envoy {\nnamespace TcpProxy {\n\nconst std::string& PerConnectionCluster::key() {\n  CONSTRUCT_ON_FIRST_USE(std::string, \"envoy.tcp_proxy.cluster\");\n}\n\nConfig::SimpleRouteImpl::SimpleRouteImpl(const Config& parent, absl::string_view cluster_name)\n    : parent_(parent), cluster_name_(cluster_name) {}\n\nConfig::WeightedClusterEntry::WeightedClusterEntry(\n    const Config& parent, const envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy::\n                              WeightedCluster::ClusterWeight& config)\n    : parent_(parent), cluster_name_(config.name()), cluster_weight_(config.weight()) {\n  if (config.has_metadata_match()) {\n    const auto filter_it = config.metadata_match().filter_metadata().find(\n        Envoy::Config::MetadataFilters::get().ENVOY_LB);\n    if (filter_it != config.metadata_match().filter_metadata().end()) {\n      if (parent.cluster_metadata_match_criteria_) {\n        metadata_match_criteria_ =\n            parent.cluster_metadata_match_criteria_->mergeMatchCriteria(filter_it->second);\n      } else {\n        metadata_match_criteria_ =\n            std::make_unique<Router::MetadataMatchCriteriaImpl>(filter_it->second);\n      }\n    }\n  }\n}\n\nConfig::SharedConfig::SharedConfig(\n    const envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy& config,\n    Server::Configuration::FactoryContext& context)\n    : stats_scope_(context.scope().createScope(fmt::format(\"tcp.{}\", config.stat_prefix()))),\n      stats_(generateStats(*stats_scope_)) {\n  if (config.has_idle_timeout()) {\n    const uint64_t timeout = DurationUtil::durationToMilliseconds(config.idle_timeout());\n    if (timeout > 0) {\n      idle_timeout_ = std::chrono::milliseconds(timeout);\n    }\n  } else {\n    idle_timeout_ = std::chrono::hours(1);\n  }\n  if (config.has_tunneling_config()) {\n    tunneling_config_helper_ =\n        std::make_unique<TunnelingConfigHelperImpl>(config.tunneling_config());\n  }\n  if (config.has_max_downstream_connection_duration()) {\n    const uint64_t connection_duration =\n        DurationUtil::durationToMilliseconds(config.max_downstream_connection_duration());\n    max_downstream_connection_duration_ = std::chrono::milliseconds(connection_duration);\n  }\n}\n\nConfig::Config(const envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy& config,\n               Server::Configuration::FactoryContext& context)\n    : max_connect_attempts_(PROTOBUF_GET_WRAPPED_OR_DEFAULT(config, max_connect_attempts, 1)),\n      upstream_drain_manager_slot_(context.threadLocal().allocateSlot()),\n      shared_config_(std::make_shared<SharedConfig>(config, context)),\n      random_generator_(context.api().randomGenerator()) {\n  upstream_drain_manager_slot_->set([](Event::Dispatcher&) {\n    ThreadLocal::ThreadLocalObjectSharedPtr drain_manager =\n        std::make_shared<UpstreamDrainManager>();\n    return drain_manager;\n  });\n\n  if (!config.cluster().empty()) {\n    default_route_ = std::make_shared<const SimpleRouteImpl>(*this, config.cluster());\n  }\n\n  if (config.has_metadata_match()) {\n    const auto& filter_metadata = config.metadata_match().filter_metadata();\n\n    const auto filter_it = filter_metadata.find(Envoy::Config::MetadataFilters::get().ENVOY_LB);\n\n    if (filter_it != filter_metadata.end()) {\n      cluster_metadata_match_criteria_ =\n          std::make_unique<Router::MetadataMatchCriteriaImpl>(filter_it->second);\n    }\n  }\n\n  // Weighted clusters will be enabled only if the default cluster is absent.\n  if (default_route_ == nullptr && config.has_weighted_clusters()) {\n    total_cluster_weight_ = 0;\n    for (const envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy::WeightedCluster::\n             ClusterWeight& cluster_desc : config.weighted_clusters().clusters()) {\n      WeightedClusterEntryConstSharedPtr cluster_entry(\n          std::make_shared<const WeightedClusterEntry>(*this, cluster_desc));\n      weighted_clusters_.emplace_back(std::move(cluster_entry));\n      total_cluster_weight_ += weighted_clusters_.back()->clusterWeight();\n    }\n  }\n\n  for (const envoy::config::accesslog::v3::AccessLog& log_config : config.access_log()) {\n    access_logs_.emplace_back(AccessLog::AccessLogFactory::fromProto(log_config, context));\n  }\n\n  if (!config.hash_policy().empty()) {\n    hash_policy_ = std::make_unique<Network::HashPolicyImpl>(config.hash_policy());\n  }\n}\n\nRouteConstSharedPtr Config::getRegularRouteFromEntries(Network::Connection& connection) {\n  // First check if the per-connection state to see if we need to route to a pre-selected cluster\n  if (const auto* per_connection_cluster =\n          connection.streamInfo().filterState()->getDataReadOnly<PerConnectionCluster>(\n              PerConnectionCluster::key());\n      per_connection_cluster != nullptr) {\n    return std::make_shared<const SimpleRouteImpl>(*this, per_connection_cluster->value());\n  }\n\n  if (default_route_ != nullptr) {\n    return default_route_;\n  }\n\n  // no match, no more routes to try\n  return nullptr;\n}\n\nRouteConstSharedPtr Config::getRouteFromEntries(Network::Connection& connection) {\n  if (weighted_clusters_.empty()) {\n    return getRegularRouteFromEntries(connection);\n  }\n  return WeightedClusterUtil::pickCluster(weighted_clusters_, total_cluster_weight_,\n                                          random_generator_.random(), false);\n}\n\nUpstreamDrainManager& Config::drainManager() {\n  return upstream_drain_manager_slot_->getTyped<UpstreamDrainManager>();\n}\n\nFilter::Filter(ConfigSharedPtr config, Upstream::ClusterManager& cluster_manager)\n    : config_(config), cluster_manager_(cluster_manager), downstream_callbacks_(*this),\n      upstream_callbacks_(new UpstreamCallbacks(this)) {\n  ASSERT(config != nullptr);\n}\n\nFilter::~Filter() {\n  for (const auto& access_log : config_->accessLogs()) {\n    access_log->log(nullptr, nullptr, nullptr, getStreamInfo());\n  }\n\n  ASSERT(generic_conn_pool_ == nullptr);\n  ASSERT(upstream_ == nullptr);\n}\n\nTcpProxyStats Config::SharedConfig::generateStats(Stats::Scope& scope) {\n  return {ALL_TCP_PROXY_STATS(POOL_COUNTER(scope), POOL_GAUGE(scope))};\n}\n\nvoid Filter::initializeReadFilterCallbacks(Network::ReadFilterCallbacks& callbacks) {\n  initialize(callbacks, true);\n}\n\nvoid Filter::initialize(Network::ReadFilterCallbacks& callbacks, bool set_connection_stats) {\n  read_callbacks_ = &callbacks;\n  ENVOY_CONN_LOG(debug, \"new tcp proxy session\", read_callbacks_->connection());\n\n  read_callbacks_->connection().addConnectionCallbacks(downstream_callbacks_);\n  read_callbacks_->connection().enableHalfClose(true);\n\n  // Need to disable reads so that we don't write to an upstream that might fail\n  // in onData(). This will get re-enabled when the upstream connection is\n  // established.\n  read_callbacks_->connection().readDisable(true);\n  getStreamInfo().setUpstreamInfo(std::make_shared<StreamInfo::UpstreamInfoImpl>());\n  config_->stats().downstream_cx_total_.inc();\n  if (set_connection_stats) {\n    read_callbacks_->connection().setConnectionStats(\n        {config_->stats().downstream_cx_rx_bytes_total_,\n         config_->stats().downstream_cx_rx_bytes_buffered_,\n         config_->stats().downstream_cx_tx_bytes_total_,\n         config_->stats().downstream_cx_tx_bytes_buffered_, nullptr, nullptr});\n  }\n}\n\nvoid Filter::readDisableUpstream(bool disable) {\n  bool success = false;\n  if (upstream_) {\n    success = upstream_->readDisable(disable);\n  }\n  if (!success) {\n    return;\n  }\n  if (disable) {\n    read_callbacks_->upstreamHost()\n        ->cluster()\n        .stats()\n        .upstream_flow_control_paused_reading_total_.inc();\n  } else {\n    read_callbacks_->upstreamHost()\n        ->cluster()\n        .stats()\n        .upstream_flow_control_resumed_reading_total_.inc();\n  }\n}\n\nvoid Filter::readDisableDownstream(bool disable) {\n  if (read_callbacks_->connection().state() != Network::Connection::State::Open) {\n    // During idle timeouts, we close both upstream and downstream with NoFlush.\n    // Envoy still does a best-effort flush which can case readDisableDownstream to be called\n    // despite the downstream connection being closed.\n    return;\n  }\n  read_callbacks_->connection().readDisable(disable);\n\n  if (disable) {\n    config_->stats().downstream_flow_control_paused_reading_total_.inc();\n  } else {\n    config_->stats().downstream_flow_control_resumed_reading_total_.inc();\n  }\n}\n\nStreamInfo::StreamInfo& Filter::getStreamInfo() {\n  return read_callbacks_->connection().streamInfo();\n}\n\nvoid Filter::DownstreamCallbacks::onAboveWriteBufferHighWatermark() {\n  ASSERT(!on_high_watermark_called_);\n  on_high_watermark_called_ = true;\n  // If downstream has too much data buffered, stop reading on the upstream connection.\n  parent_.readDisableUpstream(true);\n}\n\nvoid Filter::DownstreamCallbacks::onBelowWriteBufferLowWatermark() {\n  ASSERT(on_high_watermark_called_);\n  on_high_watermark_called_ = false;\n  // The downstream buffer has been drained. Resume reading from upstream.\n  parent_.readDisableUpstream(false);\n}\n\nvoid Filter::UpstreamCallbacks::onEvent(Network::ConnectionEvent event) {\n  if (event == Network::ConnectionEvent::Connected) {\n    return;\n  }\n  if (drainer_ == nullptr) {\n    parent_->onUpstreamEvent(event);\n  } else {\n    drainer_->onEvent(event);\n  }\n}\n\nvoid Filter::UpstreamCallbacks::onAboveWriteBufferHighWatermark() {\n  ASSERT(!on_high_watermark_called_);\n  on_high_watermark_called_ = true;\n\n  if (parent_ != nullptr) {\n    // There's too much data buffered in the upstream write buffer, so stop reading.\n    parent_->readDisableDownstream(true);\n  }\n}\n\nvoid Filter::UpstreamCallbacks::onBelowWriteBufferLowWatermark() {\n  ASSERT(on_high_watermark_called_);\n  on_high_watermark_called_ = false;\n\n  if (parent_ != nullptr) {\n    // The upstream write buffer is drained. Resume reading.\n    parent_->readDisableDownstream(false);\n  }\n}\n\nvoid Filter::UpstreamCallbacks::onUpstreamData(Buffer::Instance& data, bool end_stream) {\n  if (parent_) {\n    parent_->onUpstreamData(data, end_stream);\n  } else {\n    drainer_->onData(data, end_stream);\n  }\n}\n\nvoid Filter::UpstreamCallbacks::onBytesSent() {\n  if (drainer_ == nullptr) {\n    parent_->resetIdleTimer();\n  } else {\n    drainer_->onBytesSent();\n  }\n}\n\nvoid Filter::UpstreamCallbacks::onIdleTimeout() {\n  if (drainer_ == nullptr) {\n    parent_->onIdleTimeout();\n  } else {\n    drainer_->onIdleTimeout();\n  }\n}\n\nvoid Filter::UpstreamCallbacks::drain(Drainer& drainer) {\n  ASSERT(drainer_ == nullptr); // This should only get set once.\n  drainer_ = &drainer;\n  parent_ = nullptr;\n}\n\nNetwork::FilterStatus Filter::initializeUpstreamConnection() {\n  ASSERT(upstream_ == nullptr);\n\n  route_ = pickRoute();\n\n  const std::string& cluster_name = route_ ? route_->clusterName() : EMPTY_STRING;\n\n  Upstream::ThreadLocalCluster* thread_local_cluster =\n      cluster_manager_.getThreadLocalCluster(cluster_name);\n\n  if (thread_local_cluster) {\n    ENVOY_CONN_LOG(debug, \"Creating connection to cluster {}\", read_callbacks_->connection(),\n                   cluster_name);\n  } else {\n    ENVOY_CONN_LOG(debug, \"Cluster not found {}\", read_callbacks_->connection(), cluster_name);\n    config_->stats().downstream_cx_no_route_.inc();\n    getStreamInfo().setResponseFlag(StreamInfo::ResponseFlag::NoClusterFound);\n    onInitFailure(UpstreamFailureReason::NoRoute);\n    return Network::FilterStatus::StopIteration;\n  }\n\n  Upstream::ClusterInfoConstSharedPtr cluster = thread_local_cluster->info();\n  getStreamInfo().setUpstreamClusterInfo(cluster);\n\n  // Check this here because the TCP conn pool will queue our request waiting for a connection that\n  // will never be released.\n  if (!cluster->resourceManager(Upstream::ResourcePriority::Default).connections().canCreate()) {\n    getStreamInfo().setResponseFlag(StreamInfo::ResponseFlag::UpstreamOverflow);\n    cluster->stats().upstream_cx_overflow_.inc();\n    onInitFailure(UpstreamFailureReason::ResourceLimitExceeded);\n    return Network::FilterStatus::StopIteration;\n  }\n\n  const uint32_t max_connect_attempts = config_->maxConnectAttempts();\n  if (connect_attempts_ >= max_connect_attempts) {\n    getStreamInfo().setResponseFlag(StreamInfo::ResponseFlag::UpstreamRetryLimitExceeded);\n    cluster->stats().upstream_cx_connect_attempts_exceeded_.inc();\n    onInitFailure(UpstreamFailureReason::ConnectFailed);\n    return Network::FilterStatus::StopIteration;\n  }\n\n  if (auto downstream_connection = downstreamConnection(); downstream_connection != nullptr) {\n    if (!read_callbacks_->connection()\n             .streamInfo()\n             .filterState()\n             ->hasData<Network::ProxyProtocolFilterState>(\n                 Network::ProxyProtocolFilterState::key())) {\n      read_callbacks_->connection().streamInfo().filterState()->setData(\n          Network::ProxyProtocolFilterState::key(),\n          std::make_shared<Network::ProxyProtocolFilterState>(Network::ProxyProtocolData{\n              downstream_connection->connectionInfoProvider().remoteAddress(),\n              downstream_connection->connectionInfoProvider().localAddress()}),\n          StreamInfo::FilterState::StateType::ReadOnly,\n          StreamInfo::FilterState::LifeSpan::Connection);\n    }\n    transport_socket_options_ = Network::TransportSocketOptionsUtility::fromFilterState(\n        downstream_connection->streamInfo().filterState());\n\n    if (auto typed_state = downstream_connection->streamInfo()\n                               .filterState()\n                               .getDataReadOnly<Network::UpstreamSocketOptionsFilterState>(\n                                   Network::UpstreamSocketOptionsFilterState::key());\n        typed_state != nullptr) {\n      auto downstream_options = typed_state->value();\n      if (!upstream_options_) {\n        upstream_options_ = std::make_shared<Network::Socket::Options>();\n      }\n      Network::Socket::appendOptions(upstream_options_, downstream_options);\n    }\n  }\n\n  if (!maybeTunnel(*thread_local_cluster)) {\n    // Either cluster is unknown or there are no healthy hosts. tcpConnPool() increments\n    // cluster->stats().upstream_cx_none_healthy in the latter case.\n    getStreamInfo().setResponseFlag(StreamInfo::ResponseFlag::NoHealthyUpstream);\n    onInitFailure(UpstreamFailureReason::NoHealthyUpstream);\n  }\n  return Network::FilterStatus::StopIteration;\n}\n\nbool Filter::maybeTunnel(Upstream::ThreadLocalCluster& cluster) {\n  GenericConnPoolFactory* factory = nullptr;\n  if (cluster.info()->upstreamConfig().has_value()) {\n    factory = Envoy::Config::Utility::getFactory<GenericConnPoolFactory>(\n        cluster.info()->upstreamConfig().value());\n  } else {\n    factory = Envoy::Config::Utility::getFactoryByName<GenericConnPoolFactory>(\n        \"envoy.filters.connection_pools.tcp.generic\");\n  }\n  if (!factory) {\n    return false;\n  }\n\n  generic_conn_pool_ = factory->createGenericConnPool(cluster, config_->tunnelingConfigHelper(),\n                                                      this, *upstream_callbacks_);\n  if (generic_conn_pool_) {\n    connecting_ = true;\n    connect_attempts_++;\n    getStreamInfo().setAttemptCount(connect_attempts_);\n    generic_conn_pool_->newStream(*this);\n    // Because we never return open connections to the pool, this either has a handle waiting on\n    // connection completion, or onPoolFailure has been invoked. Either way, stop iteration.\n    return true;\n  }\n  return false;\n}\n\nvoid Filter::onGenericPoolFailure(ConnectionPool::PoolFailureReason reason,\n                                  Upstream::HostDescriptionConstSharedPtr host) {\n  generic_conn_pool_.reset();\n  read_callbacks_->upstreamHost(host);\n  getStreamInfo().upstreamInfo()->setUpstreamHost(host);\n\n  switch (reason) {\n  case ConnectionPool::PoolFailureReason::Overflow:\n  case ConnectionPool::PoolFailureReason::LocalConnectionFailure:\n    upstream_callbacks_->onEvent(Network::ConnectionEvent::LocalClose);\n    break;\n  case ConnectionPool::PoolFailureReason::RemoteConnectionFailure:\n    upstream_callbacks_->onEvent(Network::ConnectionEvent::RemoteClose);\n    break;\n  case ConnectionPool::PoolFailureReason::Timeout:\n    onConnectTimeout();\n    break;\n  }\n}\n\nvoid Filter::onGenericPoolReady(StreamInfo::StreamInfo* info,\n                                std::unique_ptr<GenericUpstream>&& upstream,\n                                Upstream::HostDescriptionConstSharedPtr& host,\n                                const Network::Address::InstanceConstSharedPtr& local_address,\n                                Ssl::ConnectionInfoConstSharedPtr ssl_info) {\n  upstream_ = std::move(upstream);\n  generic_conn_pool_.reset();\n  read_callbacks_->upstreamHost(host);\n  StreamInfo::UpstreamInfo& upstream_info = *getStreamInfo().upstreamInfo();\n  upstream_info.setUpstreamHost(host);\n  upstream_info.setUpstreamLocalAddress(local_address);\n  upstream_info.setUpstreamSslConnection(ssl_info);\n  onUpstreamConnection();\n  read_callbacks_->continueReading();\n  if (info) {\n    upstream_info.setUpstreamFilterState(info->filterState());\n  }\n}\n\nconst Router::MetadataMatchCriteria* Filter::metadataMatchCriteria() {\n  const Router::MetadataMatchCriteria* route_criteria =\n      (route_ != nullptr) ? route_->metadataMatchCriteria() : nullptr;\n\n  const auto& request_metadata = getStreamInfo().dynamicMetadata().filter_metadata();\n  const auto filter_it = request_metadata.find(Envoy::Config::MetadataFilters::get().ENVOY_LB);\n\n  if (filter_it != request_metadata.end() && route_criteria != nullptr) {\n    metadata_match_criteria_ = route_criteria->mergeMatchCriteria(filter_it->second);\n    return metadata_match_criteria_.get();\n  } else if (filter_it != request_metadata.end()) {\n    metadata_match_criteria_ =\n        std::make_unique<Router::MetadataMatchCriteriaImpl>(filter_it->second);\n    return metadata_match_criteria_.get();\n  } else {\n    return route_criteria;\n  }\n}\n\nvoid Filter::onConnectTimeout() {\n  ENVOY_CONN_LOG(debug, \"connect timeout\", read_callbacks_->connection());\n  read_callbacks_->upstreamHost()->outlierDetector().putResult(\n      Upstream::Outlier::Result::LocalOriginTimeout);\n  getStreamInfo().setResponseFlag(StreamInfo::ResponseFlag::UpstreamConnectionFailure);\n\n  // Raise LocalClose, which will trigger a reconnect if needed/configured.\n  upstream_callbacks_->onEvent(Network::ConnectionEvent::LocalClose);\n}\n\nNetwork::FilterStatus Filter::onData(Buffer::Instance& data, bool end_stream) {\n  ENVOY_CONN_LOG(trace, \"downstream connection received {} bytes, end_stream={}\",\n                 read_callbacks_->connection(), data.length(), end_stream);\n  if (upstream_) {\n    upstream_->encodeData(data, end_stream);\n  }\n  // The upstream should consume all of the data.\n  // Before there is an upstream the connection should be readDisabled. If the upstream is\n  // destroyed, there should be no further reads as well.\n  ASSERT(0 == data.length());\n  resetIdleTimer(); // TODO(ggreenway) PERF: do we need to reset timer on both send and receive?\n  return Network::FilterStatus::StopIteration;\n}\n\nNetwork::FilterStatus Filter::onNewConnection() {\n  if (config_->maxDownstreamConnectionDuration()) {\n    connection_duration_timer_ = read_callbacks_->connection().dispatcher().createTimer(\n        [this]() -> void { onMaxDownstreamConnectionDuration(); });\n    connection_duration_timer_->enableTimer(config_->maxDownstreamConnectionDuration().value());\n  }\n  return initializeUpstreamConnection();\n}\n\nvoid Filter::onDownstreamEvent(Network::ConnectionEvent event) {\n  if (event == Network::ConnectionEvent::LocalClose ||\n      event == Network::ConnectionEvent::RemoteClose) {\n    downstream_closed_ = true;\n  }\n\n  ENVOY_CONN_LOG(trace, \"on downstream event {}, has upstream = {}\", read_callbacks_->connection(),\n                 static_cast<int>(event), upstream_ == nullptr);\n\n  if (upstream_) {\n    Tcp::ConnectionPool::ConnectionDataPtr conn_data(upstream_->onDownstreamEvent(event));\n    if (conn_data != nullptr &&\n        conn_data->connection().state() != Network::Connection::State::Closed) {\n      config_->drainManager().add(config_->sharedConfig(), std::move(conn_data),\n                                  std::move(upstream_callbacks_), std::move(idle_timer_),\n                                  read_callbacks_->upstreamHost());\n    }\n    if (event != Network::ConnectionEvent::Connected) {\n      upstream_.reset();\n      disableIdleTimer();\n    }\n  }\n  if (generic_conn_pool_) {\n    if (event == Network::ConnectionEvent::LocalClose ||\n        event == Network::ConnectionEvent::RemoteClose) {\n      // Cancel the conn pool request and close any excess pending requests.\n      generic_conn_pool_.reset();\n    }\n  }\n}\n\nvoid Filter::onUpstreamData(Buffer::Instance& data, bool end_stream) {\n  ENVOY_CONN_LOG(trace, \"upstream connection received {} bytes, end_stream={}\",\n                 read_callbacks_->connection(), data.length(), end_stream);\n  read_callbacks_->connection().write(data, end_stream);\n  ASSERT(0 == data.length());\n  resetIdleTimer(); // TODO(ggreenway) PERF: do we need to reset timer on both send and receive?\n}\n\nvoid Filter::onUpstreamEvent(Network::ConnectionEvent event) {\n  // Update the connecting flag before processing the event because we may start a new connection\n  // attempt in initializeUpstreamConnection.\n  bool connecting = connecting_;\n  connecting_ = false;\n\n  if (event == Network::ConnectionEvent::RemoteClose ||\n      event == Network::ConnectionEvent::LocalClose) {\n    upstream_.reset();\n    disableIdleTimer();\n\n    if (connecting) {\n      if (event == Network::ConnectionEvent::RemoteClose) {\n        getStreamInfo().setResponseFlag(StreamInfo::ResponseFlag::UpstreamConnectionFailure);\n        read_callbacks_->upstreamHost()->outlierDetector().putResult(\n            Upstream::Outlier::Result::LocalOriginConnectFailed);\n      }\n\n      if (!downstream_closed_) {\n        initializeUpstreamConnection();\n      }\n    } else {\n      if (read_callbacks_->connection().state() == Network::Connection::State::Open) {\n        read_callbacks_->connection().close(Network::ConnectionCloseType::FlushWrite);\n      }\n    }\n  }\n}\n\nvoid Filter::onUpstreamConnection() {\n  connecting_ = false;\n  // Re-enable downstream reads now that the upstream connection is established\n  // so we have a place to send downstream data to.\n  read_callbacks_->connection().readDisable(false);\n\n  read_callbacks_->upstreamHost()->outlierDetector().putResult(\n      Upstream::Outlier::Result::LocalOriginConnectSuccessFinal);\n\n  ENVOY_CONN_LOG(debug, \"TCP:onUpstreamEvent(), requestedServerName: {}\",\n                 read_callbacks_->connection(),\n                 getStreamInfo().downstreamAddressProvider().requestedServerName());\n\n  if (config_->idleTimeout()) {\n    // The idle_timer_ can be moved to a Drainer, so related callbacks call into\n    // the UpstreamCallbacks, which has the same lifetime as the timer, and can dispatch\n    // the call to either TcpProxy or to Drainer, depending on the current state.\n    idle_timer_ = read_callbacks_->connection().dispatcher().createTimer(\n        [upstream_callbacks = upstream_callbacks_]() { upstream_callbacks->onIdleTimeout(); });\n    resetIdleTimer();\n    read_callbacks_->connection().addBytesSentCallback([this](uint64_t) {\n      resetIdleTimer();\n      return true;\n    });\n    if (upstream_) {\n      upstream_->addBytesSentCallback([upstream_callbacks = upstream_callbacks_](uint64_t) -> bool {\n        upstream_callbacks->onBytesSent();\n        return true;\n      });\n    }\n  }\n}\n\nvoid Filter::onIdleTimeout() {\n  ENVOY_CONN_LOG(debug, \"Session timed out\", read_callbacks_->connection());\n  config_->stats().idle_timeout_.inc();\n\n  // This results in also closing the upstream connection.\n  read_callbacks_->connection().close(Network::ConnectionCloseType::NoFlush);\n}\n\nvoid Filter::onMaxDownstreamConnectionDuration() {\n  ENVOY_CONN_LOG(debug, \"max connection duration reached\", read_callbacks_->connection());\n  getStreamInfo().setResponseFlag(StreamInfo::ResponseFlag::DurationTimeout);\n  config_->stats().max_downstream_connection_duration_.inc();\n  read_callbacks_->connection().close(Network::ConnectionCloseType::NoFlush);\n}\n\nvoid Filter::resetIdleTimer() {\n  if (idle_timer_ != nullptr) {\n    ASSERT(config_->idleTimeout());\n    idle_timer_->enableTimer(config_->idleTimeout().value());\n  }\n}\n\nvoid Filter::disableIdleTimer() {\n  if (idle_timer_ != nullptr) {\n    idle_timer_->disableTimer();\n    idle_timer_.reset();\n  }\n}\n\nUpstreamDrainManager::~UpstreamDrainManager() {\n  // If connections aren't closed before they are destructed an ASSERT fires,\n  // so cancel all pending drains, which causes the connections to be closed.\n  if (!drainers_.empty()) {\n    auto& dispatcher = drainers_.begin()->second->dispatcher();\n    while (!drainers_.empty()) {\n      auto begin = drainers_.begin();\n      Drainer* key = begin->first;\n      begin->second->cancelDrain();\n\n      // cancelDrain() should cause that drainer to be removed from drainers_.\n      // ASSERT so that we don't end up in an infinite loop.\n      ASSERT(drainers_.find(key) == drainers_.end());\n    }\n\n    // This destructor is run when shutting down `ThreadLocal`. The destructor of some objects use\n    // earlier `ThreadLocal` slots (for accessing the runtime snapshot) so they must run before that\n    // slot is destructed. Clear the list to enforce that ordering.\n    dispatcher.clearDeferredDeleteList();\n  }\n}\n\nvoid UpstreamDrainManager::add(const Config::SharedConfigSharedPtr& config,\n                               Tcp::ConnectionPool::ConnectionDataPtr&& upstream_conn_data,\n                               const std::shared_ptr<Filter::UpstreamCallbacks>& callbacks,\n                               Event::TimerPtr&& idle_timer,\n                               const Upstream::HostDescriptionConstSharedPtr& upstream_host) {\n  DrainerPtr drainer(new Drainer(*this, config, callbacks, std::move(upstream_conn_data),\n                                 std::move(idle_timer), upstream_host));\n  callbacks->drain(*drainer);\n\n  // Use temporary to ensure we get the pointer before we move it out of drainer\n  Drainer* ptr = drainer.get();\n  drainers_[ptr] = std::move(drainer);\n}\n\nvoid UpstreamDrainManager::remove(Drainer& drainer, Event::Dispatcher& dispatcher) {\n  auto it = drainers_.find(&drainer);\n  ASSERT(it != drainers_.end());\n  dispatcher.deferredDelete(std::move(it->second));\n  drainers_.erase(it);\n}\n\nDrainer::Drainer(UpstreamDrainManager& parent, const Config::SharedConfigSharedPtr& config,\n                 const std::shared_ptr<Filter::UpstreamCallbacks>& callbacks,\n                 Tcp::ConnectionPool::ConnectionDataPtr&& conn_data, Event::TimerPtr&& idle_timer,\n                 const Upstream::HostDescriptionConstSharedPtr& upstream_host)\n    : parent_(parent), callbacks_(callbacks), upstream_conn_data_(std::move(conn_data)),\n      timer_(std::move(idle_timer)), upstream_host_(upstream_host), config_(config) {\n  ENVOY_CONN_LOG(trace, \"draining the upstream connection\", upstream_conn_data_->connection());\n  config_->stats().upstream_flush_total_.inc();\n  config_->stats().upstream_flush_active_.inc();\n}\n\nvoid Drainer::onEvent(Network::ConnectionEvent event) {\n  if (event == Network::ConnectionEvent::RemoteClose ||\n      event == Network::ConnectionEvent::LocalClose) {\n    if (timer_ != nullptr) {\n      timer_->disableTimer();\n    }\n    config_->stats().upstream_flush_active_.dec();\n    parent_.remove(*this, upstream_conn_data_->connection().dispatcher());\n  }\n}\n\nvoid Drainer::onData(Buffer::Instance& data, bool) {\n  if (data.length() > 0) {\n    // There is no downstream connection to send any data to, but the upstream\n    // sent some data. Try to behave similar to what the kernel would do\n    // when it receives data on a connection where the application has closed\n    // the socket or ::shutdown(fd, SHUT_RD), and close/reset the connection.\n    cancelDrain();\n  }\n}\n\nvoid Drainer::onIdleTimeout() {\n  config_->stats().idle_timeout_.inc();\n  cancelDrain();\n}\n\nvoid Drainer::onBytesSent() {\n  if (timer_ != nullptr) {\n    timer_->enableTimer(config_->idleTimeout().value());\n  }\n}\n\nvoid Drainer::cancelDrain() {\n  // This sends onEvent(LocalClose).\n  upstream_conn_data_->connection().close(Network::ConnectionCloseType::NoFlush);\n}\n\nEvent::Dispatcher& Drainer::dispatcher() { return upstream_conn_data_->connection().dispatcher(); }\n\n} // namespace TcpProxy\n} // namespace Envoy\n", "#pragma once\n\n#include <cstdint>\n#include <memory>\n#include <string>\n#include <vector>\n\n#include \"envoy/access_log/access_log.h\"\n#include \"envoy/common/random_generator.h\"\n#include \"envoy/event/timer.h\"\n#include \"envoy/extensions/filters/network/tcp_proxy/v3/tcp_proxy.pb.h\"\n#include \"envoy/http/header_evaluator.h\"\n#include \"envoy/network/connection.h\"\n#include \"envoy/network/filter.h\"\n#include \"envoy/runtime/runtime.h\"\n#include \"envoy/server/filter_config.h\"\n#include \"envoy/stats/scope.h\"\n#include \"envoy/stats/stats_macros.h\"\n#include \"envoy/stats/timespan.h\"\n#include \"envoy/stream_info/filter_state.h\"\n#include \"envoy/upstream/cluster_manager.h\"\n#include \"envoy/upstream/upstream.h\"\n\n#include \"source/common/common/logger.h\"\n#include \"source/common/network/cidr_range.h\"\n#include \"source/common/network/filter_impl.h\"\n#include \"source/common/network/hash_policy.h\"\n#include \"source/common/network/utility.h\"\n#include \"source/common/stream_info/stream_info_impl.h\"\n#include \"source/common/tcp_proxy/upstream.h\"\n#include \"source/common/upstream/load_balancer_impl.h\"\n\n#include \"absl/container/node_hash_map.h\"\n\nnamespace Envoy {\nnamespace TcpProxy {\n\n/**\n * All tcp proxy stats. @see stats_macros.h\n */\n#define ALL_TCP_PROXY_STATS(COUNTER, GAUGE)                                                        \\\n  COUNTER(downstream_cx_no_route)                                                                  \\\n  COUNTER(downstream_cx_rx_bytes_total)                                                            \\\n  COUNTER(downstream_cx_total)                                                                     \\\n  COUNTER(downstream_cx_tx_bytes_total)                                                            \\\n  COUNTER(downstream_flow_control_paused_reading_total)                                            \\\n  COUNTER(downstream_flow_control_resumed_reading_total)                                           \\\n  COUNTER(idle_timeout)                                                                            \\\n  COUNTER(max_downstream_connection_duration)                                                      \\\n  COUNTER(upstream_flush_total)                                                                    \\\n  GAUGE(downstream_cx_rx_bytes_buffered, Accumulate)                                               \\\n  GAUGE(downstream_cx_tx_bytes_buffered, Accumulate)                                               \\\n  GAUGE(upstream_flush_active, Accumulate)\n\n/**\n * Struct definition for all tcp proxy stats. @see stats_macros.h\n */\nstruct TcpProxyStats {\n  ALL_TCP_PROXY_STATS(GENERATE_COUNTER_STRUCT, GENERATE_GAUGE_STRUCT)\n};\n\nclass Drainer;\nclass UpstreamDrainManager;\n\n/**\n * Route is an individual resolved route for a connection.\n */\nclass Route {\npublic:\n  virtual ~Route() = default;\n\n  /**\n   * Check whether this route matches a given connection.\n   * @param connection supplies the connection to test against.\n   * @return bool true if this route matches a given connection.\n   */\n  virtual bool matches(Network::Connection& connection) const PURE;\n\n  /**\n   * @return const std::string& the upstream cluster that owns the route.\n   */\n  virtual const std::string& clusterName() const PURE;\n\n  /**\n   * @return MetadataMatchCriteria* the metadata that a subset load balancer should match when\n   * selecting an upstream host\n   */\n  virtual const Router::MetadataMatchCriteria* metadataMatchCriteria() const PURE;\n};\n\nusing RouteConstSharedPtr = std::shared_ptr<const Route>;\nusing TunnelingConfig =\n    envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy_TunnelingConfig;\n\nclass TunnelingConfigHelperImpl : public TunnelingConfigHelper {\npublic:\n  TunnelingConfigHelperImpl(\n      const envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy_TunnelingConfig&\n          config_message)\n      : hostname_(config_message.hostname()), use_post_(config_message.use_post()),\n        header_parser_(Envoy::Router::HeaderParser::configure(config_message.headers_to_add())) {}\n  const std::string& hostname() const override { return hostname_; }\n  bool usePost() const override { return use_post_; }\n  Envoy::Http::HeaderEvaluator& headerEvaluator() const override { return *header_parser_; }\n\nprivate:\n  const std::string hostname_;\n  const bool use_post_;\n  std::unique_ptr<Envoy::Router::HeaderParser> header_parser_;\n};\n\n/**\n * Filter configuration.\n *\n * This configuration holds a TLS slot, and therefore it must be destructed\n * on the main thread.\n */\nclass Config {\npublic:\n  /**\n   * Configuration that can be shared and have an arbitrary lifetime safely.\n   */\n  class SharedConfig {\n  public:\n    SharedConfig(const envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy& config,\n                 Server::Configuration::FactoryContext& context);\n    const TcpProxyStats& stats() { return stats_; }\n    const absl::optional<std::chrono::milliseconds>& idleTimeout() { return idle_timeout_; }\n    const absl::optional<std::chrono::milliseconds>& maxDownstreamConnectinDuration() const {\n      return max_downstream_connection_duration_;\n    }\n    TunnelingConfigHelperOptConstRef tunnelingConfigHelper() {\n      if (tunneling_config_helper_) {\n        return TunnelingConfigHelperOptConstRef(*tunneling_config_helper_);\n      } else {\n        return TunnelingConfigHelperOptConstRef();\n      }\n    }\n\n  private:\n    static TcpProxyStats generateStats(Stats::Scope& scope);\n\n    // Hold a Scope for the lifetime of the configuration because connections in\n    // the UpstreamDrainManager can live longer than the listener.\n    const Stats::ScopePtr stats_scope_;\n\n    const TcpProxyStats stats_;\n    absl::optional<std::chrono::milliseconds> idle_timeout_;\n    absl::optional<std::chrono::milliseconds> max_downstream_connection_duration_;\n    std::unique_ptr<TunnelingConfigHelper> tunneling_config_helper_;\n  };\n\n  using SharedConfigSharedPtr = std::shared_ptr<SharedConfig>;\n\n  Config(const envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy& config,\n         Server::Configuration::FactoryContext& context);\n\n  /**\n   * Find out which cluster an upstream connection should be opened to based on the\n   * parameters of a downstream connection.\n   * @param connection supplies the parameters of the downstream connection for\n   * which the proxy needs to open the corresponding upstream.\n   * @return the route to be used for the upstream connection.\n   * If no route applies, returns nullptr.\n   */\n  RouteConstSharedPtr getRouteFromEntries(Network::Connection& connection);\n  RouteConstSharedPtr getRegularRouteFromEntries(Network::Connection& connection);\n\n  const TcpProxyStats& stats() { return shared_config_->stats(); }\n  const std::vector<AccessLog::InstanceSharedPtr>& accessLogs() { return access_logs_; }\n  uint32_t maxConnectAttempts() const { return max_connect_attempts_; }\n  const absl::optional<std::chrono::milliseconds>& idleTimeout() {\n    return shared_config_->idleTimeout();\n  }\n  const absl::optional<std::chrono::milliseconds>& maxDownstreamConnectionDuration() const {\n    return shared_config_->maxDownstreamConnectinDuration();\n  }\n  // Return nullptr if there is no tunneling config.\n  TunnelingConfigHelperOptConstRef tunnelingConfigHelper() {\n    return shared_config_->tunnelingConfigHelper();\n  }\n  UpstreamDrainManager& drainManager();\n  SharedConfigSharedPtr sharedConfig() { return shared_config_; }\n  const Router::MetadataMatchCriteria* metadataMatchCriteria() const {\n    return cluster_metadata_match_criteria_.get();\n  }\n  const Network::HashPolicy* hashPolicy() { return hash_policy_.get(); }\n\nprivate:\n  struct SimpleRouteImpl : public Route {\n    SimpleRouteImpl(const Config& parent, absl::string_view cluster_name);\n\n    // Route\n    bool matches(Network::Connection&) const override { return true; }\n    const std::string& clusterName() const override { return cluster_name_; }\n    const Router::MetadataMatchCriteria* metadataMatchCriteria() const override {\n      return parent_.metadataMatchCriteria();\n    }\n\n    const Config& parent_;\n    std::string cluster_name_;\n  };\n\n  class WeightedClusterEntry : public Route {\n  public:\n    WeightedClusterEntry(const Config& parent,\n                         const envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy::\n                             WeightedCluster::ClusterWeight& config);\n\n    uint64_t clusterWeight() const { return cluster_weight_; }\n\n    // Route\n    bool matches(Network::Connection&) const override { return false; }\n    const std::string& clusterName() const override { return cluster_name_; }\n    const Router::MetadataMatchCriteria* metadataMatchCriteria() const override {\n      if (metadata_match_criteria_) {\n        return metadata_match_criteria_.get();\n      }\n      return parent_.metadataMatchCriteria();\n    }\n\n  private:\n    const Config& parent_;\n    const std::string cluster_name_;\n    const uint64_t cluster_weight_;\n    Router::MetadataMatchCriteriaConstPtr metadata_match_criteria_;\n  };\n  using WeightedClusterEntryConstSharedPtr = std::shared_ptr<const WeightedClusterEntry>;\n\n  RouteConstSharedPtr default_route_;\n  std::vector<WeightedClusterEntryConstSharedPtr> weighted_clusters_;\n  uint64_t total_cluster_weight_;\n  std::vector<AccessLog::InstanceSharedPtr> access_logs_;\n  const uint32_t max_connect_attempts_;\n  ThreadLocal::SlotPtr upstream_drain_manager_slot_;\n  SharedConfigSharedPtr shared_config_;\n  std::unique_ptr<const Router::MetadataMatchCriteria> cluster_metadata_match_criteria_;\n  Random::RandomGenerator& random_generator_;\n  std::unique_ptr<const Network::HashPolicyImpl> hash_policy_;\n};\n\nusing ConfigSharedPtr = std::shared_ptr<Config>;\n\n/**\n * Per-connection TCP Proxy Cluster configuration.\n */\nclass PerConnectionCluster : public StreamInfo::FilterState::Object {\npublic:\n  PerConnectionCluster(absl::string_view cluster) : cluster_(cluster) {}\n  const std::string& value() const { return cluster_; }\n  static const std::string& key();\n\nprivate:\n  const std::string cluster_;\n};\n\n/**\n * An implementation of a TCP (L3/L4) proxy. This filter will instantiate a new outgoing TCP\n * connection using the defined load balancing proxy for the configured cluster. All data will\n * be proxied back and forth between the two connections.\n */\nclass Filter : public Network::ReadFilter,\n               public Upstream::LoadBalancerContextBase,\n               protected Logger::Loggable<Logger::Id::filter>,\n               public GenericConnectionPoolCallbacks {\npublic:\n  Filter(ConfigSharedPtr config, Upstream::ClusterManager& cluster_manager);\n  ~Filter() override;\n\n  // Network::ReadFilter\n  Network::FilterStatus onData(Buffer::Instance& data, bool end_stream) override;\n  Network::FilterStatus onNewConnection() override;\n  void initializeReadFilterCallbacks(Network::ReadFilterCallbacks& callbacks) override;\n\n  // GenericConnectionPoolCallbacks\n  void onGenericPoolReady(StreamInfo::StreamInfo* info, std::unique_ptr<GenericUpstream>&& upstream,\n                          Upstream::HostDescriptionConstSharedPtr& host,\n                          const Network::Address::InstanceConstSharedPtr& local_address,\n                          Ssl::ConnectionInfoConstSharedPtr ssl_info) override;\n  void onGenericPoolFailure(ConnectionPool::PoolFailureReason reason,\n                            Upstream::HostDescriptionConstSharedPtr host) override;\n\n  // Upstream::LoadBalancerContext\n  const Router::MetadataMatchCriteria* metadataMatchCriteria() override;\n  absl::optional<uint64_t> computeHashKey() override {\n    auto hash_policy = config_->hashPolicy();\n    if (hash_policy) {\n      return hash_policy->generateHash(*downstreamConnection());\n    }\n\n    return {};\n  }\n\n  const Network::Connection* downstreamConnection() const override {\n    return &read_callbacks_->connection();\n  }\n\n  Network::TransportSocketOptionsConstSharedPtr upstreamTransportSocketOptions() const override {\n    return transport_socket_options_;\n  }\n\n  Network::Socket::OptionsSharedPtr upstreamSocketOptions() const override {\n    return upstream_options_;\n  }\n\n  // These two functions allow enabling/disabling reads on the upstream and downstream connections.\n  // They are called by the Downstream/Upstream Watermark callbacks to limit buffering.\n  void readDisableUpstream(bool disable);\n  void readDisableDownstream(bool disable);\n\n  struct UpstreamCallbacks : public Tcp::ConnectionPool::UpstreamCallbacks {\n    UpstreamCallbacks(Filter* parent) : parent_(parent) {}\n\n    // Tcp::ConnectionPool::UpstreamCallbacks\n    void onUpstreamData(Buffer::Instance& data, bool end_stream) override;\n    void onEvent(Network::ConnectionEvent event) override;\n    void onAboveWriteBufferHighWatermark() override;\n    void onBelowWriteBufferLowWatermark() override;\n\n    void onBytesSent();\n    void onIdleTimeout();\n    void drain(Drainer& drainer);\n\n    // Either parent_ or drainer_ will be non-NULL, but never both. This could be\n    // logically be represented as a union, but saving one pointer of memory is\n    // outweighed by more type safety/better error handling.\n    //\n    // Parent starts out as non-NULL. If the downstream connection is closed while\n    // the upstream connection still has buffered data to flush, drainer_ becomes\n    // non-NULL and parent_ is set to NULL.\n    Filter* parent_{};\n    Drainer* drainer_{};\n\n    bool on_high_watermark_called_{false};\n  };\n\n  StreamInfo::StreamInfo& getStreamInfo();\n\nprotected:\n  struct DownstreamCallbacks : public Network::ConnectionCallbacks {\n    DownstreamCallbacks(Filter& parent) : parent_(parent) {}\n\n    // Network::ConnectionCallbacks\n    void onEvent(Network::ConnectionEvent event) override { parent_.onDownstreamEvent(event); }\n    void onAboveWriteBufferHighWatermark() override;\n    void onBelowWriteBufferLowWatermark() override;\n\n    Filter& parent_;\n    bool on_high_watermark_called_{false};\n  };\n\n  enum class UpstreamFailureReason {\n    ConnectFailed,\n    NoHealthyUpstream,\n    ResourceLimitExceeded,\n    NoRoute,\n  };\n\n  // Callbacks for different error and success states during connection establishment\n  virtual RouteConstSharedPtr pickRoute() {\n    return config_->getRouteFromEntries(read_callbacks_->connection());\n  }\n\n  virtual void onInitFailure(UpstreamFailureReason) {\n    read_callbacks_->connection().close(Network::ConnectionCloseType::NoFlush);\n  }\n\n  void initialize(Network::ReadFilterCallbacks& callbacks, bool set_connection_stats);\n  Network::FilterStatus initializeUpstreamConnection();\n  bool maybeTunnel(Upstream::ThreadLocalCluster& cluster);\n  void onConnectTimeout();\n  void onDownstreamEvent(Network::ConnectionEvent event);\n  void onUpstreamData(Buffer::Instance& data, bool end_stream);\n  void onUpstreamEvent(Network::ConnectionEvent event);\n  void onUpstreamConnection();\n  void onIdleTimeout();\n  void resetIdleTimer();\n  void disableIdleTimer();\n  void onMaxDownstreamConnectionDuration();\n\n  const ConfigSharedPtr config_;\n  Upstream::ClusterManager& cluster_manager_;\n  Network::ReadFilterCallbacks* read_callbacks_{};\n\n  DownstreamCallbacks downstream_callbacks_;\n  Event::TimerPtr idle_timer_;\n  Event::TimerPtr connection_duration_timer_;\n\n  std::shared_ptr<UpstreamCallbacks> upstream_callbacks_; // shared_ptr required for passing as a\n                                                          // read filter.\n  // The upstream handle (either TCP or HTTP). This is set in onGenericPoolReady and should persist\n  // until either the upstream or downstream connection is terminated.\n  std::unique_ptr<GenericUpstream> upstream_;\n  // The connection pool used to set up |upstream_|.\n  // This will be non-null from when an upstream connection is attempted until\n  // it either succeeds or fails.\n  std::unique_ptr<GenericConnPool> generic_conn_pool_;\n  RouteConstSharedPtr route_;\n  Router::MetadataMatchCriteriaConstPtr metadata_match_criteria_;\n  Network::TransportSocketOptionsConstSharedPtr transport_socket_options_;\n  Network::Socket::OptionsSharedPtr upstream_options_;\n  uint32_t connect_attempts_{};\n  bool connecting_{};\n  bool downstream_closed_{};\n};\n\n// This class deals with an upstream connection that needs to finish flushing, when the downstream\n// connection has been closed. The TcpProxy is destroyed when the downstream connection is closed,\n// so handling the upstream connection here allows it to finish draining or timeout.\nclass Drainer : public Event::DeferredDeletable, protected Logger::Loggable<Logger::Id::filter> {\npublic:\n  Drainer(UpstreamDrainManager& parent, const Config::SharedConfigSharedPtr& config,\n          const std::shared_ptr<Filter::UpstreamCallbacks>& callbacks,\n          Tcp::ConnectionPool::ConnectionDataPtr&& conn_data, Event::TimerPtr&& idle_timer,\n          const Upstream::HostDescriptionConstSharedPtr& upstream_host);\n\n  void onEvent(Network::ConnectionEvent event);\n  void onData(Buffer::Instance& data, bool end_stream);\n  void onIdleTimeout();\n  void onBytesSent();\n  void cancelDrain();\n  Event::Dispatcher& dispatcher();\n\nprivate:\n  UpstreamDrainManager& parent_;\n  std::shared_ptr<Filter::UpstreamCallbacks> callbacks_;\n  Tcp::ConnectionPool::ConnectionDataPtr upstream_conn_data_;\n  Event::TimerPtr timer_;\n  Upstream::HostDescriptionConstSharedPtr upstream_host_;\n  Config::SharedConfigSharedPtr config_;\n};\n\nusing DrainerPtr = std::unique_ptr<Drainer>;\n\nclass UpstreamDrainManager : public ThreadLocal::ThreadLocalObject {\npublic:\n  ~UpstreamDrainManager() override;\n  void add(const Config::SharedConfigSharedPtr& config,\n           Tcp::ConnectionPool::ConnectionDataPtr&& upstream_conn_data,\n           const std::shared_ptr<Filter::UpstreamCallbacks>& callbacks,\n           Event::TimerPtr&& idle_timer,\n           const Upstream::HostDescriptionConstSharedPtr& upstream_host);\n  void remove(Drainer& drainer, Event::Dispatcher& dispatcher);\n\nprivate:\n  // This must be a map instead of set because there is no way to move elements\n  // out of a set, and these elements get passed to deferredDelete() instead of\n  // being deleted in-place. The key and value will always be equal.\n  absl::node_hash_map<Drainer*, DrainerPtr> drainers_;\n};\n\n} // namespace TcpProxy\n} // namespace Envoy\n", "#include <memory>\n\n#include \"envoy/config/bootstrap/v3/bootstrap.pb.h\"\n#include \"envoy/extensions/filters/network/tcp_proxy/v3/tcp_proxy.pb.h\"\n\n#include \"test/integration/http_integration.h\"\n#include \"test/integration/http_protocol_integration.h\"\n\n#include \"gtest/gtest.h\"\n\nnamespace Envoy {\nnamespace {\n\n// Terminating CONNECT and sending raw TCP upstream.\nclass ConnectTerminationIntegrationTest : public HttpProtocolIntegrationTest {\npublic:\n  ConnectTerminationIntegrationTest() { enableHalfClose(true); }\n\n  void initialize() override {\n    config_helper_.addConfigModifier(\n        [&](envoy::extensions::filters::network::http_connection_manager::v3::HttpConnectionManager&\n                hcm) {\n          ConfigHelper::setConnectConfig(hcm, true, allow_post_,\n                                         downstream_protocol_ == Http::CodecType::HTTP3);\n\n          if (enable_timeout_) {\n            hcm.mutable_stream_idle_timeout()->set_seconds(0);\n            hcm.mutable_stream_idle_timeout()->set_nanos(200 * 1000 * 1000);\n          }\n          if (exact_match_) {\n            auto* route_config = hcm.mutable_route_config();\n            ASSERT_EQ(1, route_config->virtual_hosts_size());\n            route_config->mutable_virtual_hosts(0)->clear_domains();\n            route_config->mutable_virtual_hosts(0)->add_domains(\"host:80\");\n          }\n        });\n    HttpIntegrationTest::initialize();\n  }\n\n  void setUpConnection() {\n    codec_client_ = makeHttpConnection(lookupPort(\"http\"));\n    auto encoder_decoder = codec_client_->startRequest(connect_headers_);\n    request_encoder_ = &encoder_decoder.first;\n    response_ = std::move(encoder_decoder.second);\n    ASSERT_TRUE(fake_upstreams_[0]->waitForRawConnection(fake_raw_upstream_connection_));\n    response_->waitForHeaders();\n  }\n\n  void sendBidirectionalData(const char* downstream_send_data = \"hello\",\n                             const char* upstream_received_data = \"hello\",\n                             const char* upstream_send_data = \"there!\",\n                             const char* downstream_received_data = \"there!\") {\n    // Send some data upstream.\n    codec_client_->sendData(*request_encoder_, downstream_send_data, false);\n    ASSERT_TRUE(fake_raw_upstream_connection_->waitForData(\n        FakeRawConnection::waitForInexactMatch(upstream_received_data)));\n\n    // Send some data downstream.\n    ASSERT_TRUE(fake_raw_upstream_connection_->write(upstream_send_data));\n    response_->waitForBodyData(strlen(downstream_received_data));\n    EXPECT_EQ(downstream_received_data, response_->body());\n  }\n\n  Http::TestRequestHeaderMapImpl connect_headers_{{\":method\", \"CONNECT\"},\n                                                  {\":path\", \"/\"},\n                                                  {\":protocol\", \"bytestream\"},\n                                                  {\":scheme\", \"https\"},\n                                                  {\":authority\", \"host:80\"}};\n  void clearExtendedConnectHeaders() {\n    connect_headers_.removeProtocol();\n    connect_headers_.removePath();\n  }\n\n  void sendBidirectionalDataAndCleanShutdown() {\n    sendBidirectionalData(\"hello\", \"hello\", \"there!\", \"there!\");\n    // Send a second set of data to make sure for example headers are only sent once.\n    sendBidirectionalData(\",bye\", \"hello,bye\", \"ack\", \"there!ack\");\n\n    // Send an end stream. This should result in half close upstream.\n    codec_client_->sendData(*request_encoder_, \"\", true);\n    ASSERT_TRUE(fake_raw_upstream_connection_->waitForHalfClose());\n\n    // Now send a FIN from upstream. This should result in clean shutdown downstream.\n    ASSERT_TRUE(fake_raw_upstream_connection_->close());\n    if (downstream_protocol_ == Http::CodecType::HTTP1) {\n      ASSERT_TRUE(codec_client_->waitForDisconnect());\n    } else {\n      ASSERT_TRUE(response_->waitForEndStream());\n      ASSERT_FALSE(response_->reset());\n    }\n  }\n\n  FakeRawConnectionPtr fake_raw_upstream_connection_;\n  IntegrationStreamDecoderPtr response_;\n  bool enable_timeout_{};\n  bool exact_match_{};\n  bool allow_post_{};\n};\n\nTEST_P(ConnectTerminationIntegrationTest, OriginalStyle) {\n  initialize();\n  clearExtendedConnectHeaders();\n\n  setUpConnection();\n  sendBidirectionalDataAndCleanShutdown();\n}\n\nTEST_P(ConnectTerminationIntegrationTest, Basic) {\n  initialize();\n\n  setUpConnection();\n  sendBidirectionalDataAndCleanShutdown();\n}\n\nTEST_P(ConnectTerminationIntegrationTest, BasicAllowPost) {\n  allow_post_ = true;\n  initialize();\n\n  // Use POST request.\n  connect_headers_.setMethod(\"POST\");\n  connect_headers_.removeProtocol();\n\n  setUpConnection();\n  sendBidirectionalDataAndCleanShutdown();\n}\n\nTEST_P(ConnectTerminationIntegrationTest, UsingHostMatch) {\n  exact_match_ = true;\n  initialize();\n\n  connect_headers_.removePath();\n  connect_headers_.removeProtocol();\n\n  setUpConnection();\n  sendBidirectionalDataAndCleanShutdown();\n}\n\nTEST_P(ConnectTerminationIntegrationTest, DownstreamClose) {\n  initialize();\n\n  setUpConnection();\n  sendBidirectionalData();\n\n  // Tear down by closing the client connection.\n  codec_client_->close();\n  ASSERT_TRUE(fake_raw_upstream_connection_->waitForHalfClose());\n}\n\nTEST_P(ConnectTerminationIntegrationTest, DownstreamReset) {\n  if (downstream_protocol_ == Http::CodecType::HTTP1) {\n    // Resetting an individual stream requires HTTP/2 or later.\n    return;\n  }\n  initialize();\n\n  setUpConnection();\n  sendBidirectionalData();\n\n  // Tear down by resetting the client stream.\n  codec_client_->sendReset(*request_encoder_);\n  ASSERT_TRUE(fake_raw_upstream_connection_->waitForHalfClose());\n}\n\nTEST_P(ConnectTerminationIntegrationTest, UpstreamClose) {\n  initialize();\n\n  setUpConnection();\n  sendBidirectionalData();\n\n  // Tear down by closing the upstream connection.\n  ASSERT_TRUE(fake_raw_upstream_connection_->close());\n  if (downstream_protocol_ == Http::CodecType::HTTP3) {\n    // In HTTP/3 end stream will be sent when the upstream connection is closed, and\n    // STOP_SENDING frame sent instead of reset.\n    ASSERT_TRUE(response_->waitForEndStream());\n  } else {\n    ASSERT_TRUE(response_->waitForReset());\n  }\n}\n\nTEST_P(ConnectTerminationIntegrationTest, TestTimeout) {\n  enable_timeout_ = true;\n  initialize();\n\n  setUpConnection();\n\n  // Wait for the timeout to close the connection.\n  ASSERT_TRUE(response_->waitForReset());\n  ASSERT_TRUE(fake_raw_upstream_connection_->waitForHalfClose());\n}\n\nTEST_P(ConnectTerminationIntegrationTest, BuggyHeaders) {\n  if (downstream_protocol_ == Http::CodecType::HTTP1) {\n    return;\n  }\n  initialize();\n\n  // Sending a header-only request is probably buggy, but rather than having a\n  // special corner case it is treated as a regular half close.\n  codec_client_ = makeHttpConnection(lookupPort(\"http\"));\n  response_ = codec_client_->makeHeaderOnlyRequest(\n      Http::TestRequestHeaderMapImpl{{\":method\", \"CONNECT\"},\n                                     {\":path\", \"/\"},\n                                     {\":protocol\", \"bytestream\"},\n                                     {\":scheme\", \"https\"},\n                                     {\":authority\", \"host:80\"}});\n  // If the connection is established (created, set to half close, and then the\n  // FIN arrives), make sure the FIN arrives, and send a FIN from upstream.\n  if (fake_upstreams_[0]->waitForRawConnection(fake_raw_upstream_connection_) &&\n      fake_raw_upstream_connection_->connected()) {\n    ASSERT_TRUE(fake_raw_upstream_connection_->waitForHalfClose());\n    ASSERT_TRUE(fake_raw_upstream_connection_->close());\n  }\n\n  // Either with early close, or half close, the FIN from upstream should result\n  // in clean stream teardown.\n  ASSERT_TRUE(response_->waitForEndStream());\n  ASSERT_FALSE(response_->reset());\n}\n\nTEST_P(ConnectTerminationIntegrationTest, BasicMaxStreamDuration) {\n  setUpstreamProtocol(upstreamProtocol());\n  config_helper_.addConfigModifier([](envoy::config::bootstrap::v3::Bootstrap& bootstrap) {\n    ConfigHelper::HttpProtocolOptions protocol_options;\n    protocol_options.mutable_common_http_protocol_options()\n        ->mutable_max_stream_duration()\n        ->MergeFrom(ProtobufUtil::TimeUtil::MillisecondsToDuration(1000));\n    ConfigHelper::setProtocolOptions(*bootstrap.mutable_static_resources()->mutable_clusters(0),\n                                     protocol_options);\n  });\n\n  initialize();\n  setUpConnection();\n  sendBidirectionalData();\n\n  test_server_->waitForCounterGe(\"cluster.cluster_0.upstream_rq_max_duration_reached\", 1);\n\n  if (downstream_protocol_ == Http::CodecType::HTTP1) {\n    ASSERT_TRUE(codec_client_->waitForDisconnect());\n  } else {\n    ASSERT_TRUE(response_->waitForReset());\n    codec_client_->close();\n  }\n}\n\n// Verify Envoy ignores the Host field in HTTP/1.1 CONNECT message.\nTEST_P(ConnectTerminationIntegrationTest, IgnoreH11HostField) {\n  // This test is HTTP/1.1 specific.\n  if (downstream_protocol_ != Http::CodecType::HTTP1) {\n    return;\n  }\n  initialize();\n\n  std::string response;\n  const std::string full_request = \"CONNECT www.foo.com:443 HTTP/1.1\\r\\n\"\n                                   \"Host: www.bar.com:443\\r\\n\\r\\n\";\n  EXPECT_LOG_CONTAINS(\n      \"\",\n      \"':authority', 'www.foo.com:443'\\n\"\n      \"':method', 'CONNECT'\",\n      sendRawHttpAndWaitForResponse(lookupPort(\"http\"), full_request.c_str(), &response, false););\n}\n\n// For this class, forward the CONNECT request upstream\nclass ProxyingConnectIntegrationTest : public HttpProtocolIntegrationTest {\npublic:\n  void initialize() override {\n    config_helper_.addConfigModifier(\n        [&](envoy::extensions::filters::network::http_connection_manager::v3::HttpConnectionManager&\n                hcm) -> void {\n          ConfigHelper::setConnectConfig(hcm, false, false,\n                                         downstream_protocol_ == Http::CodecType::HTTP3);\n        });\n\n    HttpProtocolIntegrationTest::initialize();\n  }\n\n  Http::TestRequestHeaderMapImpl connect_headers_{{\":method\", \"CONNECT\"},\n                                                  {\":path\", \"/\"},\n                                                  {\":protocol\", \"bytestream\"},\n                                                  {\":scheme\", \"https\"},\n                                                  {\":authority\", \"host:80\"}};\n  IntegrationStreamDecoderPtr response_;\n};\n\nINSTANTIATE_TEST_SUITE_P(Protocols, ProxyingConnectIntegrationTest,\n                         testing::ValuesIn(HttpProtocolIntegrationTest::getProtocolTestParams(\n                             {Http::CodecType::HTTP1, Http::CodecType::HTTP2,\n                              Http::CodecType::HTTP3},\n                             {Http::CodecType::HTTP1})),\n                         HttpProtocolIntegrationTest::protocolTestParamsToString);\n\nTEST_P(ProxyingConnectIntegrationTest, ProxyConnect) {\n  initialize();\n\n  // Send request headers.\n  codec_client_ = makeHttpConnection(lookupPort(\"http\"));\n  auto encoder_decoder = codec_client_->startRequest(connect_headers_);\n  request_encoder_ = &encoder_decoder.first;\n  response_ = std::move(encoder_decoder.second);\n\n  // Wait for them to arrive upstream.\n  AssertionResult result =\n      fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_);\n  RELEASE_ASSERT(result, result.message());\n  result = fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_);\n  RELEASE_ASSERT(result, result.message());\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n  EXPECT_EQ(upstream_request_->headers().get(Http::Headers::get().Method)[0]->value(), \"CONNECT\");\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    EXPECT_TRUE(upstream_request_->headers().get(Http::Headers::get().Protocol).empty());\n  } else {\n    EXPECT_EQ(upstream_request_->headers().get(Http::Headers::get().Protocol)[0]->value(),\n              \"bytestream\");\n  }\n\n  // Send response headers\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  // Wait for them to arrive downstream.\n  response_->waitForHeaders();\n  EXPECT_EQ(\"200\", response_->headers().getStatusValue());\n\n  // Make sure that even once the response has started, that data can continue to go upstream.\n  codec_client_->sendData(*request_encoder_, \"hello\", false);\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, 5));\n\n  // Also test upstream to downstream data.\n  upstream_request_->encodeData(12, false);\n  response_->waitForBodyData(12);\n\n  cleanupUpstreamAndDownstream();\n}\n\nTEST_P(ProxyingConnectIntegrationTest, ProxyConnectWithPortStripping) {\n  config_helper_.addConfigModifier(\n      [&](envoy::extensions::filters::network::http_connection_manager::v3::HttpConnectionManager&\n              hcm) {\n        hcm.set_strip_any_host_port(true);\n        auto* route_config = hcm.mutable_route_config();\n        auto* header_value_option = route_config->mutable_request_headers_to_add()->Add();\n        auto* mutable_header = header_value_option->mutable_header();\n        mutable_header->set_key(\"Host-In-Envoy\");\n        mutable_header->set_value(\"%REQ(:AUTHORITY)%\");\n      });\n\n  initialize();\n\n  // Send request headers.\n  codec_client_ = makeHttpConnection(lookupPort(\"http\"));\n  auto encoder_decoder = codec_client_->startRequest(connect_headers_);\n  request_encoder_ = &encoder_decoder.first;\n  response_ = std::move(encoder_decoder.second);\n\n  // Wait for them to arrive upstream.\n  AssertionResult result =\n      fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_);\n  RELEASE_ASSERT(result, result.message());\n  result = fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_);\n  RELEASE_ASSERT(result, result.message());\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n  EXPECT_EQ(upstream_request_->headers().getMethodValue(), \"CONNECT\");\n  EXPECT_EQ(upstream_request_->headers().getHostValue(), \"host:80\");\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    EXPECT_TRUE(upstream_request_->headers().getProtocolValue().empty());\n  } else {\n    EXPECT_EQ(upstream_request_->headers().getProtocolValue(), \"bytestream\");\n  }\n  auto stripped_host = upstream_request_->headers().get(Http::LowerCaseString(\"host-in-envoy\"));\n  ASSERT_EQ(stripped_host.size(), 1);\n  EXPECT_EQ(stripped_host[0]->value(), \"host\");\n\n  // Send response headers\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  // Wait for them to arrive downstream.\n  response_->waitForHeaders();\n  EXPECT_EQ(\"200\", response_->headers().getStatusValue());\n\n  // Make sure that even once the response has started, that data can continue to go upstream.\n  codec_client_->sendData(*request_encoder_, \"hello\", false);\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, 5));\n\n  // Also test upstream to downstream data.\n  upstream_request_->encodeData(12, false);\n  response_->waitForBodyData(12);\n\n  cleanupUpstreamAndDownstream();\n}\n\nTEST_P(ProxyingConnectIntegrationTest, ProxyConnectWithIP) {\n  initialize();\n\n  // Send request headers.\n  codec_client_ = makeHttpConnection(lookupPort(\"http\"));\n  connect_headers_.setHost(\"1.2.3.4:80\");\n  auto encoder_decoder = codec_client_->startRequest(connect_headers_);\n  request_encoder_ = &encoder_decoder.first;\n  response_ = std::move(encoder_decoder.second);\n\n  // Wait for them to arrive upstream.\n  AssertionResult result =\n      fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_);\n  RELEASE_ASSERT(result, result.message());\n  result = fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_);\n  RELEASE_ASSERT(result, result.message());\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n  EXPECT_EQ(upstream_request_->headers().get(Http::Headers::get().Method)[0]->value(), \"CONNECT\");\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    EXPECT_TRUE(upstream_request_->headers().get(Http::Headers::get().Protocol).empty());\n  } else {\n    EXPECT_EQ(upstream_request_->headers().get(Http::Headers::get().Protocol)[0]->value(),\n              \"bytestream\");\n  }\n\n  // Send response headers\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  // Wait for them to arrive downstream.\n  response_->waitForHeaders();\n  EXPECT_EQ(\"200\", response_->headers().getStatusValue());\n\n  cleanupUpstreamAndDownstream();\n}\n\nINSTANTIATE_TEST_SUITE_P(HttpAndIpVersions, ConnectTerminationIntegrationTest,\n                         testing::ValuesIn(HttpProtocolIntegrationTest::getProtocolTestParams(\n                             {Http::CodecType::HTTP1, Http::CodecType::HTTP2,\n                              Http::CodecType::HTTP3},\n                             {Http::CodecType::HTTP1})),\n                         HttpProtocolIntegrationTest::protocolTestParamsToString);\n\nusing Params = std::tuple<Network::Address::IpVersion, Http::CodecType>;\n\n// Tunneling downstream TCP over an upstream HTTP CONNECT tunnel.\nclass TcpTunnelingIntegrationTest : public HttpProtocolIntegrationTest {\npublic:\n  void SetUp() override {\n    enableHalfClose(true);\n\n    config_helper_.addConfigModifier(\n        [&](envoy::config::bootstrap::v3::Bootstrap& bootstrap) -> void {\n          envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy proxy_config;\n          proxy_config.set_stat_prefix(\"tcp_stats\");\n          proxy_config.set_cluster(\"cluster_0\");\n          proxy_config.mutable_tunneling_config()->set_hostname(\"host.com:80\");\n\n          auto* listener = bootstrap.mutable_static_resources()->add_listeners();\n          listener->set_name(\"tcp_proxy\");\n          auto* socket_address = listener->mutable_address()->mutable_socket_address();\n          socket_address->set_address(Network::Test::getLoopbackAddressString(version_));\n          socket_address->set_port_value(0);\n\n          auto* filter_chain = listener->add_filter_chains();\n          auto* filter = filter_chain->add_filters();\n          filter->mutable_typed_config()->PackFrom(proxy_config);\n          filter->set_name(\"envoy.filters.network.tcp_proxy\");\n        });\n    HttpProtocolIntegrationTest::SetUp();\n  }\n\n  void setUpConnection(FakeHttpConnectionPtr& fake_upstream_connection) {\n    // Start a connection, and verify the upgrade headers are received upstream.\n    tcp_client_ = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n    if (!fake_upstream_connection) {\n      ASSERT_TRUE(\n          fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection));\n    }\n    ASSERT_TRUE(fake_upstream_connection->waitForNewStream(*dispatcher_, upstream_request_));\n    ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n\n    // Send upgrade headers downstream, fully establishing the connection.\n    upstream_request_->encodeHeaders(default_response_headers_, false);\n  }\n\n  void sendBidiData(FakeHttpConnectionPtr& fake_upstream_connection, bool send_goaway = false) {\n    // Send some data from downstream to upstream, and make sure it goes through.\n    ASSERT_TRUE(tcp_client_->write(\"hello\", false));\n    ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, 5));\n\n    if (send_goaway) {\n      fake_upstream_connection->encodeGoAway();\n    }\n    // Send data from upstream to downstream.\n    upstream_request_->encodeData(12, false);\n    ASSERT_TRUE(tcp_client_->waitForData(12));\n  }\n\n  void closeConnection(FakeHttpConnectionPtr& fake_upstream_connection) {\n    // Now send more data and close the TCP client. This should be treated as half close, so the\n    // data should go through.\n    ASSERT_TRUE(tcp_client_->write(\"hello\", false));\n    tcp_client_->close();\n    ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, 5));\n    if (upstreamProtocol() == Http::CodecType::HTTP1) {\n      ASSERT_TRUE(fake_upstream_connection->waitForDisconnect());\n    } else {\n      ASSERT_TRUE(upstream_request_->waitForEndStream(*dispatcher_));\n      // If the upstream now sends 'end stream' the connection is fully closed.\n      upstream_request_->encodeData(0, true);\n    }\n  }\n\n  IntegrationTcpClientPtr tcp_client_;\n};\n\nTEST_P(TcpTunnelingIntegrationTest, Basic) {\n  initialize();\n\n  setUpConnection(fake_upstream_connection_);\n  sendBidiData(fake_upstream_connection_);\n  closeConnection(fake_upstream_connection_);\n}\n\nTEST_P(TcpTunnelingIntegrationTest, SendDataUpstreamAfterUpstreamClose) {\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    // HTTP/1.1 can't frame with FIN bits.\n    return;\n  }\n  initialize();\n\n  setUpConnection(fake_upstream_connection_);\n  sendBidiData(fake_upstream_connection_);\n  // Close upstream.\n  upstream_request_->encodeData(2, true);\n  tcp_client_->waitForHalfClose();\n\n  // Now send data upstream.\n  ASSERT_TRUE(tcp_client_->write(\"hello\", false));\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, 5));\n\n  // Finally close and clean up.\n  tcp_client_->close();\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n  } else {\n    ASSERT_TRUE(upstream_request_->waitForEndStream(*dispatcher_));\n  }\n}\n\nTEST_P(TcpTunnelingIntegrationTest, BasicUsePost) {\n  // Enable using POST.\n  config_helper_.addConfigModifier([&](envoy::config::bootstrap::v3::Bootstrap& bootstrap) -> void {\n    envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy proxy_config;\n    proxy_config.set_stat_prefix(\"tcp_stats\");\n    proxy_config.set_cluster(\"cluster_0\");\n    proxy_config.mutable_tunneling_config()->set_hostname(\"host.com:80\");\n    proxy_config.mutable_tunneling_config()->set_use_post(true);\n\n    auto* listeners = bootstrap.mutable_static_resources()->mutable_listeners();\n    for (auto& listener : *listeners) {\n      if (listener.name() != \"tcp_proxy\") {\n        continue;\n      }\n      auto* filter_chain = listener.mutable_filter_chains(0);\n      auto* filter = filter_chain->mutable_filters(0);\n      filter->mutable_typed_config()->PackFrom(proxy_config);\n      break;\n    }\n  });\n\n  initialize();\n\n  // Start a connection, and verify the upgrade headers are received upstream.\n  tcp_client_ = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n  EXPECT_EQ(upstream_request_->headers().get(Http::Headers::get().Method)[0]->value(), \"POST\");\n\n  // Send upgrade headers downstream, fully establishing the connection.\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  sendBidiData(fake_upstream_connection_);\n  closeConnection(fake_upstream_connection_);\n}\n\nTEST_P(TcpTunnelingIntegrationTest, BasicHeaderEvaluationTunnelingConfig) {\n  // Set the \"downstream-local-ip\" header in the CONNECT request.\n  config_helper_.addConfigModifier([&](envoy::config::bootstrap::v3::Bootstrap& bootstrap) -> void {\n    envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy proxy_config;\n    proxy_config.set_stat_prefix(\"tcp_stats\");\n    proxy_config.set_cluster(\"cluster_0\");\n    proxy_config.mutable_tunneling_config()->set_hostname(\"host.com:80\");\n    auto new_header = proxy_config.mutable_tunneling_config()->mutable_headers_to_add()->Add();\n    new_header->mutable_header()->set_key(\"downstream-local-ip\");\n    new_header->mutable_header()->set_value(\"%DOWNSTREAM_LOCAL_ADDRESS_WITHOUT_PORT%\");\n\n    auto* listeners = bootstrap.mutable_static_resources()->mutable_listeners();\n    for (auto& listener : *listeners) {\n      if (listener.name() != \"tcp_proxy\") {\n        continue;\n      }\n      auto* filter_chain = listener.mutable_filter_chains(0);\n      auto* filter = filter_chain->mutable_filters(0);\n      filter->mutable_typed_config()->PackFrom(proxy_config);\n      break;\n    }\n  });\n\n  initialize();\n\n  // Start a connection, and verify the upgrade headers are received upstream.\n  tcp_client_ = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n  EXPECT_EQ(upstream_request_->headers().getMethodValue(), \"CONNECT\");\n\n  // Verify that the connect request has a \"downstream-local-ip\" header and its value is the\n  // loopback address.\n  EXPECT_EQ(\n      upstream_request_->headers().get(Envoy::Http::LowerCaseString(\"downstream-local-ip\")).size(),\n      1);\n  EXPECT_EQ(upstream_request_->headers()\n                .get(Envoy::Http::LowerCaseString(\"downstream-local-ip\"))[0]\n                ->value()\n                .getStringView(),\n            Network::Test::getLoopbackAddressString(version_));\n\n  // Send upgrade headers downstream, fully establishing the connection.\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n  sendBidiData(fake_upstream_connection_);\n  closeConnection(fake_upstream_connection_);\n}\n\n// Verify that the header evaluator is updated without lifetime issue.\nTEST_P(TcpTunnelingIntegrationTest, HeaderEvaluatorConfigUpdate) {\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    return;\n  }\n  envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy proxy_config;\n  config_helper_.addConfigModifier([&](envoy::config::bootstrap::v3::Bootstrap& bootstrap) -> void {\n    proxy_config.set_stat_prefix(\"tcp_stats\");\n    proxy_config.set_cluster(\"cluster_0\");\n    proxy_config.mutable_tunneling_config()->set_hostname(\"host.com:80\");\n    auto address_header = proxy_config.mutable_tunneling_config()->mutable_headers_to_add()->Add();\n    address_header->mutable_header()->set_key(\"config-version\");\n    address_header->mutable_header()->set_value(\"1\");\n\n    auto* listeners = bootstrap.mutable_static_resources()->mutable_listeners();\n    for (auto& listener : *listeners) {\n      if (listener.name() != \"tcp_proxy\") {\n        continue;\n      }\n      auto* filter_chain = listener.mutable_filter_chains(0);\n      auto* filter = filter_chain->mutable_filters(0);\n      filter->mutable_typed_config()->PackFrom(proxy_config);\n      break;\n    }\n  });\n\n  initialize();\n  // Start a connection, and verify the upgrade headers are received upstream.\n  tcp_client_ = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n  EXPECT_EQ(upstream_request_->headers().getMethodValue(), \"CONNECT\");\n\n  EXPECT_EQ(upstream_request_->headers()\n                .get(Envoy::Http::LowerCaseString(\"config-version\"))[0]\n                ->value()\n                .getStringView(),\n            \"1\");\n\n  // Send upgrade headers downstream, fully establishing the connection.\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n  ASSERT_TRUE(tcp_client_->write(\"hello\", false));\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, 5));\n\n  ConfigHelper new_config_helper(\n      version_, *api_, MessageUtil::getJsonStringFromMessageOrDie(config_helper_.bootstrap()));\n  new_config_helper.addConfigModifier(\n      [&](envoy::config::bootstrap::v3::Bootstrap& bootstrap) -> void {\n        auto* header =\n            proxy_config.mutable_tunneling_config()->mutable_headers_to_add()->Mutable(0);\n        header->mutable_header()->set_value(\"2\");\n\n        auto* listeners = bootstrap.mutable_static_resources()->mutable_listeners();\n        for (auto& listener : *listeners) {\n          if (listener.name() != \"tcp_proxy\") {\n            continue;\n          }\n          // trigger full listener update.\n          (*(*listener.mutable_metadata()->mutable_filter_metadata())[\"random_filter_name\"]\n                .mutable_fields())[\"random_key\"]\n              .set_number_value(2);\n          auto* filter_chain = listener.mutable_filter_chains(0);\n          auto* filter = filter_chain->mutable_filters(0);\n          filter->mutable_typed_config()->PackFrom(proxy_config);\n          break;\n        }\n      });\n  new_config_helper.setLds(\"1\");\n\n  test_server_->waitForCounterEq(\"listener_manager.listener_modified\", 1);\n  test_server_->waitForGaugeEq(\"listener_manager.total_listeners_draining\", 0);\n\n  // Start a connection, and verify the upgrade headers are received upstream.\n  auto tcp_client_2 = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n\n  // The upstream http2 or http3 connection is reused.\n  ASSERT_TRUE(fake_upstream_connection_ != nullptr);\n\n  FakeStreamPtr upstream_request_2;\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_2));\n  ASSERT_TRUE(upstream_request_2->waitForHeadersComplete());\n  // Verify the tcp proxy new header evaluator is applied.\n  EXPECT_EQ(upstream_request_2->headers()\n                .get(Envoy::Http::LowerCaseString(\"config-version\"))[0]\n                ->value()\n                .getStringView(),\n            \"2\");\n  upstream_request_2->encodeHeaders(default_response_headers_, false);\n\n  tcp_client_->close();\n  tcp_client_2->close();\n\n  ASSERT_TRUE(upstream_request_2->waitForEndStream(*dispatcher_));\n  // If the upstream now sends 'end stream' the connection is fully closed.\n  upstream_request_2->encodeData(0, true);\n  ASSERT_TRUE(fake_upstream_connection_->waitForNoPost());\n}\n\nTEST_P(TcpTunnelingIntegrationTest, Goaway) {\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    return;\n  }\n  initialize();\n\n  // Send bidirectional data, including a goaway.\n  // This should result in the first connection being torn down.\n  setUpConnection(fake_upstream_connection_);\n  sendBidiData(fake_upstream_connection_, true);\n  closeConnection(fake_upstream_connection_);\n  test_server_->waitForCounterGe(\"cluster.cluster_0.upstream_cx_destroy\", 1);\n\n  // Make sure a subsequent connection can be established successfully.\n  FakeHttpConnectionPtr fake_upstream_connection;\n  setUpConnection(fake_upstream_connection);\n  sendBidiData(fake_upstream_connection);\n  closeConnection(fake_upstream_connection_);\n\n  // Make sure the last stream is finished before doing test teardown.\n  fake_upstream_connection->encodeGoAway();\n  test_server_->waitForCounterGe(\"cluster.cluster_0.upstream_cx_destroy\", 2);\n}\n\nTEST_P(TcpTunnelingIntegrationTest, InvalidResponseHeaders) {\n  initialize();\n\n  // Start a connection, and verify the upgrade headers are received upstream.\n  tcp_client_ = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n\n  // Send invalid response_ headers, and verify that the client disconnects and\n  // upstream gets a stream reset.\n  default_response_headers_.setStatus(enumToInt(Http::Code::ServiceUnavailable));\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n  } else {\n    ASSERT_TRUE(upstream_request_->waitForReset());\n  }\n\n  // The connection should be fully closed, but the client has no way of knowing\n  // that. Ensure the FIN is read and clean up state.\n  tcp_client_->waitForHalfClose();\n  tcp_client_->close();\n}\n\nTEST_P(TcpTunnelingIntegrationTest, CloseUpstreamFirst) {\n  initialize();\n\n  setUpConnection(fake_upstream_connection_);\n  sendBidiData(fake_upstream_connection_);\n\n  // Send data from upstream to downstream with an end stream and make sure the data is received\n  // before the connection is half-closed.\n  upstream_request_->encodeData(12, true);\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    ASSERT_TRUE(fake_upstream_connection_->close());\n  }\n  ASSERT_TRUE(tcp_client_->waitForData(12));\n  tcp_client_->waitForHalfClose();\n\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n    tcp_client_->close();\n  } else {\n    // Attempt to send data upstream.\n    // should go through.\n    ASSERT_TRUE(tcp_client_->write(\"hello\", false));\n    ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, 5));\n\n    ASSERT_TRUE(tcp_client_->write(\"hello\", true));\n    ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, 5));\n    ASSERT_TRUE(upstream_request_->waitForEndStream(*dispatcher_));\n  }\n}\n\nTEST_P(TcpTunnelingIntegrationTest, ResetStreamTest) {\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    return;\n  }\n  enableHalfClose(false);\n  initialize();\n\n  setUpConnection(fake_upstream_connection_);\n\n  // Reset the stream.\n  upstream_request_->encodeResetStream();\n  tcp_client_->waitForDisconnect();\n}\n\nTEST_P(TcpTunnelingIntegrationTest, UpstreamConnectingDownstreamDisconnect) {\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    return;\n  }\n\n#if defined(WIN32)\n  // TODO(ggreenway): figure out why this test fails on Windows and remove this disable.\n  // Failing tests:\n  // IpAndHttpVersions/TcpTunnelingIntegrationTest.UpstreamConnectingDownstreamDisconnect/IPv4_HttpDownstream_Http3UpstreamBareHttp2,\n  // IpAndHttpVersions/TcpTunnelingIntegrationTest.UpstreamConnectingDownstreamDisconnect/IPv6_HttpDownstream_Http2UpstreamWrappedHttp2,\n  // Times out at the end of the test on `ASSERT_TRUE(upstream_request_->waitForReset());`.\n  return;\n#endif\n\n  config_helper_.addConfigModifier([&](envoy::config::bootstrap::v3::Bootstrap& bootstrap) -> void {\n    envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy proxy_config;\n    proxy_config.set_stat_prefix(\"tcp_stats\");\n    proxy_config.set_cluster(\"cluster_0\");\n    proxy_config.mutable_tunneling_config()->set_hostname(\"host.com:80\");\n\n    // Enable retries. The crash is due to retrying after the downstream connection is closed, which\n    // can't occur if retries are not enabled.\n    proxy_config.mutable_max_connect_attempts()->set_value(2);\n\n    auto* listeners = bootstrap.mutable_static_resources()->mutable_listeners();\n    for (auto& listener : *listeners) {\n      if (listener.name() != \"tcp_proxy\") {\n        continue;\n      }\n      auto* filter_chain = listener.mutable_filter_chains(0);\n      auto* filter = filter_chain->mutable_filters(0);\n      filter->mutable_typed_config()->PackFrom(proxy_config);\n\n      // Use TLS because it will respond to a TCP half-close during handshake by closing the\n      // connection.\n      envoy::extensions::transport_sockets::tls::v3::DownstreamTlsContext tls_context;\n      ConfigHelper::initializeTls({}, *tls_context.mutable_common_tls_context());\n      filter_chain->mutable_transport_socket()->set_name(\"envoy.transport_sockets.tls\");\n      filter_chain->mutable_transport_socket()->mutable_typed_config()->PackFrom(tls_context);\n\n      break;\n    }\n  });\n\n  enableHalfClose(false);\n  initialize();\n\n  IntegrationTcpClientPtr tcp_client = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n\n  // Wait for the request for a connection, but don't send a response back yet. This ensures that\n  // tcp_proxy is stuck in `connecting_`.\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n\n  // Close the client connection. The TLS transport socket will detect this even while\n  // `readDisable(true)` on the connection, and will raise a `RemoteClose` event.\n  tcp_client->close();\n\n  ASSERT_TRUE(upstream_request_->waitForReset());\n  ASSERT_TRUE(fake_upstream_connection_->close());\n}\n\nTEST_P(TcpTunnelingIntegrationTest, TestIdletimeoutWithLargeOutstandingData) {\n  enableHalfClose(false);\n  config_helper_.setBufferLimits(1024, 1024);\n  config_helper_.addConfigModifier([&](envoy::config::bootstrap::v3::Bootstrap& bootstrap) -> void {\n    auto* listener = bootstrap.mutable_static_resources()->mutable_listeners(1);\n    auto* filter_chain = listener->mutable_filter_chains(0);\n    auto* config_blob = filter_chain->mutable_filters(0)->mutable_typed_config();\n\n    ASSERT_TRUE(config_blob->Is<envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy>());\n    auto tcp_proxy_config =\n        MessageUtil::anyConvert<envoy::extensions::filters::network::tcp_proxy::v3::TcpProxy>(\n            *config_blob);\n    tcp_proxy_config.mutable_idle_timeout()->set_nanos(\n        std::chrono::duration_cast<std::chrono::nanoseconds>(std::chrono::milliseconds(500))\n            .count());\n    config_blob->PackFrom(tcp_proxy_config);\n  });\n\n  initialize();\n\n  setUpConnection(fake_upstream_connection_);\n\n  std::string data(1024 * 16, 'a');\n  ASSERT_TRUE(tcp_client_->write(data));\n  upstream_request_->encodeData(data, false);\n\n  tcp_client_->waitForDisconnect();\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n    tcp_client_->close();\n  } else {\n    ASSERT_TRUE(upstream_request_->waitForReset());\n  }\n}\n\n// Test that a downstream flush works correctly (all data is flushed)\nTEST_P(TcpTunnelingIntegrationTest, TcpProxyDownstreamFlush) {\n  // Use a very large size to make sure it is larger than the kernel socket read buffer.\n  const uint32_t size = 50 * 1024 * 1024;\n  config_helper_.setBufferLimits(size / 4, size / 4);\n  initialize();\n\n  setUpConnection(fake_upstream_connection_);\n\n  tcp_client_->readDisable(true);\n  std::string data(size, 'a');\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    ASSERT_TRUE(tcp_client_->write(\"hello\", false));\n    ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, 5));\n\n    upstream_request_->encodeData(data, true);\n    ASSERT_TRUE(fake_upstream_connection_->close());\n  } else {\n    ASSERT_TRUE(tcp_client_->write(\"\", true));\n\n    // This ensures that readDisable(true) has been run on its thread\n    // before tcp_client_ starts writing.\n    ASSERT_TRUE(upstream_request_->waitForEndStream(*dispatcher_));\n\n    upstream_request_->encodeData(data, true);\n  }\n\n  test_server_->waitForCounterGe(\"cluster.cluster_0.upstream_flow_control_paused_reading_total\", 1);\n  tcp_client_->readDisable(false);\n  tcp_client_->waitForData(data);\n  tcp_client_->waitForHalfClose();\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    tcp_client_->close();\n  }\n}\n\n// Test that an upstream flush works correctly (all data is flushed)\nTEST_P(TcpTunnelingIntegrationTest, TcpProxyUpstreamFlush) {\n  if (upstreamProtocol() == Http::CodecType::HTTP3) {\n    // The payload data depends on having TCP buffers upstream and downstream.\n    // For HTTP/3, upstream, the flow control window will back up sooner, Envoy\n    // flow control will kick in, and the large write of |data| will fail to\n    // complete.\n    return;\n  }\n  // Use a very large size to make sure it is larger than the kernel socket read buffer.\n  const uint32_t size = 50 * 1024 * 1024;\n  config_helper_.setBufferLimits(size, size);\n  initialize();\n\n  setUpConnection(fake_upstream_connection_);\n\n  upstream_request_->readDisable(true);\n  upstream_request_->encodeData(\"hello\", false);\n\n  // This ensures that fake_upstream_connection->readDisable has been run on its thread\n  // before tcp_client_ starts writing.\n  ASSERT_TRUE(tcp_client_->waitForData(5));\n\n  std::string data(size, 'a');\n  ASSERT_TRUE(tcp_client_->write(data, true));\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    tcp_client_->close();\n\n    upstream_request_->readDisable(false);\n    ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, size));\n    ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n  } else {\n    // Note that upstream_flush_active will *not* be incremented for the HTTP\n    // tunneling case. The data is already written to the stream, so no drainer\n    // is necessary.\n    upstream_request_->readDisable(false);\n    ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, size));\n    ASSERT_TRUE(upstream_request_->waitForEndStream(*dispatcher_));\n    upstream_request_->encodeData(\"world\", true);\n    tcp_client_->waitForHalfClose();\n  }\n}\n\n// Test that h2/h3 connection is reused.\nTEST_P(TcpTunnelingIntegrationTest, ConnectionReuse) {\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    return;\n  }\n  initialize();\n\n  setUpConnection(fake_upstream_connection_);\n\n  // Send data in both directions.\n  ASSERT_TRUE(tcp_client_->write(\"hello1\", false));\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, \"hello1\"));\n\n  // Send data from upstream to downstream with an end stream and make sure the data is received\n  // before the connection is half-closed.\n  upstream_request_->encodeData(\"world1\", true);\n  tcp_client_->waitForData(\"world1\");\n  tcp_client_->waitForHalfClose();\n  tcp_client_->close();\n  ASSERT_TRUE(upstream_request_->waitForEndStream(*dispatcher_));\n\n  // Establish a new connection.\n  IntegrationTcpClientPtr tcp_client_2 = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n\n  // The new CONNECT stream is established in the existing h2 connection.\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  ASSERT_TRUE(tcp_client_2->write(\"hello2\", false));\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, \"hello2\"));\n\n  // Send data from upstream to downstream with an end stream and make sure the data is received\n  // before the connection is half-closed.\n  upstream_request_->encodeData(\"world2\", true);\n  tcp_client_2->waitForData(\"world2\");\n  tcp_client_2->waitForHalfClose();\n  tcp_client_2->close();\n  ASSERT_TRUE(upstream_request_->waitForEndStream(*dispatcher_));\n}\n\n// Test that with HTTP1 we have no connection reuse with downstream close.\nTEST_P(TcpTunnelingIntegrationTest, H1NoConnectionReuse) {\n  if (upstreamProtocol() != Http::CodecType::HTTP1) {\n    return;\n  }\n  initialize();\n\n  setUpConnection(fake_upstream_connection_);\n\n  // Send data in both directions.\n  ASSERT_TRUE(tcp_client_->write(\"hello1\", false));\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, \"hello1\"));\n\n  // Send data from upstream to downstream and close the connection\n  // from downstream.\n  upstream_request_->encodeData(\"world1\", false);\n  tcp_client_->waitForData(\"world1\");\n  tcp_client_->close();\n\n  ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n\n  // Establish a new connection.\n  IntegrationTcpClientPtr tcp_client_2 = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n  // A new connection is established\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  ASSERT_TRUE(tcp_client_2->write(\"hello1\", false));\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, \"hello1\"));\n  tcp_client_2->close();\n\n  ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n}\n\n// Test that with HTTP1 we have no connection with upstream close.\nTEST_P(TcpTunnelingIntegrationTest, H1UpstreamCloseNoConnectionReuse) {\n  if (upstreamProtocol() == Http::CodecType::HTTP2) {\n    return;\n  }\n  initialize();\n\n  // Establish a connection.\n  IntegrationTcpClientPtr tcp_client_1 = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  // Send data in both directions.\n  ASSERT_TRUE(tcp_client_1->write(\"hello1\", false));\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, \"hello1\"));\n\n  // Send data from upstream to downstream and close the connection\n  // from the upstream.\n  upstream_request_->encodeData(\"world1\", false);\n  tcp_client_1->waitForData(\"world1\");\n  ASSERT_TRUE(fake_upstream_connection_->close());\n\n  ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n  tcp_client_1->waitForHalfClose();\n  tcp_client_1->close();\n\n  // Establish a new connection.\n  IntegrationTcpClientPtr tcp_client_2 = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n  // A new connection is established\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  ASSERT_TRUE(tcp_client_2->write(\"hello2\", false));\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, \"hello2\"));\n  ASSERT_TRUE(fake_upstream_connection_->close());\n\n  ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n  tcp_client_2->waitForHalfClose();\n  tcp_client_2->close();\n}\n\nTEST_P(TcpTunnelingIntegrationTest, 2xxStatusCodeValidHttp1) {\n  if (upstreamProtocol() != Http::CodecType::HTTP1) {\n    return;\n  }\n  initialize();\n\n  // Start a connection, and verify the upgrade headers are received upstream.\n  tcp_client_ = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n\n  // Send valid response headers, in HTTP1 all status codes in the 2xx range\n  // are considered valid.\n  default_response_headers_.setStatus(enumToInt(Http::Code::Accepted));\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  sendBidiData(fake_upstream_connection_);\n\n  // Close the downstream connection and wait for upstream disconnect\n  tcp_client_->close();\n  ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n}\n\nTEST_P(TcpTunnelingIntegrationTest, ContentLengthHeaderIgnoredHttp1) {\n  if (upstreamProtocol() != Http::CodecType::HTTP1) {\n    return;\n  }\n  initialize();\n\n  // Start a connection, and verify the upgrade headers are received upstream.\n  tcp_client_ = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n\n  // Send upgrade headers downstream, including content-length that must be\n  // ignored.\n  default_response_headers_.setStatus(enumToInt(Http::Code::IMUsed));\n  default_response_headers_.setContentLength(10);\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  // Send data from upstream to downstream.\n  upstream_request_->encodeData(12, false);\n  ASSERT_TRUE(tcp_client_->waitForData(12));\n\n  // Now send some data and close the TCP client.\n  ASSERT_TRUE(tcp_client_->write(\"hello\", false));\n  tcp_client_->close();\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, 5));\n  ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n}\n\nTEST_P(TcpTunnelingIntegrationTest, TransferEncodingHeaderIgnoredHttp1) {\n  if (upstreamProtocol() != Http::CodecType::HTTP1) {\n    return;\n  }\n  initialize();\n\n  // Start a connection, and verify the upgrade headers are received upstream.\n  tcp_client_ = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n  // Using raw connection to be able to set Transfer-encoding header.\n  FakeRawConnectionPtr fake_upstream_connection;\n  ASSERT_TRUE(fake_upstreams_[0]->waitForRawConnection(fake_upstream_connection));\n  std::string data;\n  ASSERT_TRUE(fake_upstream_connection->waitForData(\n      FakeRawConnection::waitForInexactMatch(\"\\r\\n\\r\\n\"), &data));\n  ASSERT_THAT(data, testing::HasSubstr(\"CONNECT host.com:80 HTTP/1.1\"));\n\n  // Send upgrade headers downstream, fully establishing the connection.\n  ASSERT_TRUE(\n      fake_upstream_connection->write(\"HTTP/1.1 200 OK\\r\\nTransfer-encoding: chunked\\r\\n\\r\\n\"));\n\n  // Now send some data and close the TCP client.\n  ASSERT_TRUE(tcp_client_->write(\"hello\"));\n  ASSERT_TRUE(\n      fake_upstream_connection->waitForData(FakeRawConnection::waitForInexactMatch(\"hello\")));\n\n  // Close connections.\n  ASSERT_TRUE(fake_upstream_connection->close());\n  ASSERT_TRUE(fake_upstream_connection->waitForDisconnect());\n  tcp_client_->close();\n}\n\nTEST_P(TcpTunnelingIntegrationTest, DeferTransmitDataUntilSuccessConnectResponseIsReceived) {\n  initialize();\n\n  // Start a connection, and verify the upgrade headers are received upstream.\n  tcp_client_ = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n\n  // Send some data straight away.\n  ASSERT_TRUE(tcp_client_->write(\"hello\", false));\n\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n\n  // Wait a bit, no data should go through.\n  ASSERT_FALSE(upstream_request_->waitForData(*dispatcher_, 1, std::chrono::milliseconds(100)));\n\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  ASSERT_TRUE(upstream_request_->waitForData(*dispatcher_, 5));\n\n  tcp_client_->close();\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n  } else {\n    ASSERT_TRUE(upstream_request_->waitForEndStream(*dispatcher_));\n    // If the upstream now sends 'end stream' the connection is fully closed.\n    upstream_request_->encodeData(0, true);\n  }\n}\n\nTEST_P(TcpTunnelingIntegrationTest, NoDataTransmittedIfConnectFailureResponseIsReceived) {\n  initialize();\n\n  // Start a connection, and verify the upgrade headers are received upstream.\n  tcp_client_ = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n\n  // Send some data straight away.\n  ASSERT_TRUE(tcp_client_->write(\"hello\", false));\n\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n\n  default_response_headers_.setStatus(enumToInt(Http::Code::ServiceUnavailable));\n  upstream_request_->encodeHeaders(default_response_headers_, false);\n\n  // Wait a bit, no data should go through.\n  ASSERT_FALSE(upstream_request_->waitForData(*dispatcher_, 1, std::chrono::milliseconds(100)));\n\n  tcp_client_->close();\n  if (upstreamProtocol() == Http::CodecType::HTTP1) {\n    ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());\n  } else {\n    ASSERT_TRUE(upstream_request_->waitForReset());\n  }\n}\n\nTEST_P(TcpTunnelingIntegrationTest, UpstreamDisconnectBeforeResponseReceived) {\n  initialize();\n\n  // Start a connection, and verify the upgrade headers are received upstream.\n  tcp_client_ = makeTcpConnection(lookupPort(\"tcp_proxy\"));\n\n  ASSERT_TRUE(fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForHeadersComplete());\n\n  ASSERT_TRUE(fake_upstream_connection_->close());\n  tcp_client_->waitForHalfClose();\n  tcp_client_->close();\n}\n\nINSTANTIATE_TEST_SUITE_P(IpAndHttpVersions, TcpTunnelingIntegrationTest,\n                         testing::ValuesIn(HttpProtocolIntegrationTest::getProtocolTestParams(\n                             {Http::CodecType::HTTP1},\n                             {Http::CodecType::HTTP1, Http::CodecType::HTTP2,\n                              Http::CodecType::HTTP3})),\n                         HttpProtocolIntegrationTest::protocolTestParamsToString);\n} // namespace\n} // namespace Envoy\n"], "filenames": ["docs/root/version_history/current.rst", "source/common/tcp_proxy/tcp_proxy.cc", "source/common/tcp_proxy/tcp_proxy.h", "test/integration/tcp_tunneling_integration_test.cc"], "buggy_code_start_loc": [29, 522, 403, 818], "buggy_code_end_loc": [29, 574, 403, 818], "fixing_code_start_loc": [30, 523, 404, 819], "fixing_code_end_loc": [31, 582, 405, 882], "type": "CWE-416", "message": "Envoy is an open source edge and service proxy, designed for cloud-native applications. In affected versions of Envoy a crash occurs when configured for :ref:`upstream tunneling <envoy_v3_api_field_extensions.filters.network.tcp_proxy.v3.TcpProxy.tunneling_config>` and the downstream connection disconnects while the the upstream connection or http/2 stream is still being established. There are no workarounds for this issue. Users are advised to upgrade.", "other": {"cve": {"id": "CVE-2021-43826", "sourceIdentifier": "security-advisories@github.com", "published": "2022-02-22T23:15:10.957", "lastModified": "2022-03-02T15:23:00.960", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Envoy is an open source edge and service proxy, designed for cloud-native applications. In affected versions of Envoy a crash occurs when configured for :ref:`upstream tunneling <envoy_v3_api_field_extensions.filters.network.tcp_proxy.v3.TcpProxy.tunneling_config>` and the downstream connection disconnects while the the upstream connection or http/2 stream is still being established. There are no workarounds for this issue. Users are advised to upgrade."}, {"lang": "es", "value": "Envoy es un proxy de borde y servicio de c\u00f3digo abierto, dise\u00f1ado para aplicaciones nativas de la nube. En las versiones afectadas de Envoy se produce un bloqueo cuando es configurada para :ref:\"upstream tunneling (envoy_v3_api_field_extensions.filters.network.tcp_proxy.v3.TcpProxy.tunneling_config)\" y la conexi\u00f3n de bajada es desconectada mientras sigue estableciendo la conexi\u00f3n de subida o el flujo http/2. No se presentan medidas de mitigaci\u00f3n para este problema. Es recomendado a usuarios actualizar"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:N/I:N/A:P", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 4.3}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.6, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-416"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:envoyproxy:envoy:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.18.6", "matchCriteriaId": "0EFC93D0-C206-417C-81D0-F18145E3D768"}, {"vulnerable": true, "criteria": "cpe:2.3:a:envoyproxy:envoy:*:*:*:*:*:*:*:*", "versionStartIncluding": "1.19.0", "versionEndExcluding": "1.19.3", "matchCriteriaId": "2812AC62-44B5-4077-862D-A221CD88981D"}, {"vulnerable": true, "criteria": "cpe:2.3:a:envoyproxy:envoy:*:*:*:*:*:*:*:*", "versionStartIncluding": "1.20.0", "versionEndExcluding": "1.20.2", "matchCriteriaId": "F5441B2D-F807-4ED9-AFB9-ED4DE07CE5F8"}, {"vulnerable": true, "criteria": "cpe:2.3:a:envoyproxy:envoy:*:*:*:*:*:*:*:*", "versionStartIncluding": "1.21.0", "versionEndExcluding": "1.21.1", "matchCriteriaId": "83895D03-DAD1-4893-8A1C-F9143DEEC172"}]}]}], "references": [{"url": "https://github.com/envoyproxy/envoy/commit/ce0ae309057a216aba031aff81c445c90c6ef145", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/envoyproxy/envoy/security/advisories/GHSA-cmx3-fvgf-83mf", "source": "security-advisories@github.com", "tags": ["Issue Tracking", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/envoyproxy/envoy/commit/ce0ae309057a216aba031aff81c445c90c6ef145"}}
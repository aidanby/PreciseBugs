{"buggy_code": ["/*\n * Glue Code for the asm optimized version of the AES Cipher Algorithm\n */\n\n#include <linux/module.h>\n#include <linux/crypto.h>\n#include <crypto/aes.h>\n\n#include \"aes_glue.h\"\n\nEXPORT_SYMBOL(AES_encrypt);\nEXPORT_SYMBOL(AES_decrypt);\nEXPORT_SYMBOL(private_AES_set_encrypt_key);\nEXPORT_SYMBOL(private_AES_set_decrypt_key);\n\nstatic void aes_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct AES_CTX *ctx = crypto_tfm_ctx(tfm);\n\tAES_encrypt(src, dst, &ctx->enc_key);\n}\n\nstatic void aes_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct AES_CTX *ctx = crypto_tfm_ctx(tfm);\n\tAES_decrypt(src, dst, &ctx->dec_key);\n}\n\nstatic int aes_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\tunsigned int key_len)\n{\n\tstruct AES_CTX *ctx = crypto_tfm_ctx(tfm);\n\n\tswitch (key_len) {\n\tcase AES_KEYSIZE_128:\n\t\tkey_len = 128;\n\t\tbreak;\n\tcase AES_KEYSIZE_192:\n\t\tkey_len = 192;\n\t\tbreak;\n\tcase AES_KEYSIZE_256:\n\t\tkey_len = 256;\n\t\tbreak;\n\tdefault:\n\t\ttfm->crt_flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\tif (private_AES_set_encrypt_key(in_key, key_len, &ctx->enc_key) == -1) {\n\t\ttfm->crt_flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\t/* private_AES_set_decrypt_key expects an encryption key as input */\n\tctx->dec_key = ctx->enc_key;\n\tif (private_AES_set_decrypt_key(in_key, key_len, &ctx->dec_key) == -1) {\n\t\ttfm->crt_flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\nstatic struct crypto_alg aes_alg = {\n\t.cra_name\t\t= \"aes\",\n\t.cra_driver_name\t= \"aes-asm\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct AES_CTX),\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(aes_alg.cra_list),\n\t.cra_u\t= {\n\t\t.cipher\t= {\n\t\t\t.cia_min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t= aes_set_key,\n\t\t\t.cia_encrypt\t\t= aes_encrypt,\n\t\t\t.cia_decrypt\t\t= aes_decrypt\n\t\t}\n\t}\n};\n\nstatic int __init aes_init(void)\n{\n\treturn crypto_register_alg(&aes_alg);\n}\n\nstatic void __exit aes_fini(void)\n{\n\tcrypto_unregister_alg(&aes_alg);\n}\n\nmodule_init(aes_init);\nmodule_exit(aes_fini);\n\nMODULE_DESCRIPTION(\"Rijndael (AES) Cipher Algorithm (ASM)\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS(\"aes\");\nMODULE_ALIAS(\"aes-asm\");\nMODULE_AUTHOR(\"David McCullough <ucdevel@gmail.com>\");\n", "/*\n * Cryptographic API.\n * Glue code for the SHA1 Secure Hash Algorithm assembler implementation\n *\n * This file is based on sha1_generic.c and sha1_ssse3_glue.c\n *\n * Copyright (c) Alan Smithee.\n * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n * Copyright (c) Jean-Francois Dive <jef@linuxbe.org>\n * Copyright (c) Mathias Krause <minipli@googlemail.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n#include <asm/byteorder.h>\n#include <asm/crypto/sha1.h>\n\n\nasmlinkage void sha1_block_data_order(u32 *digest,\n\t\tconst unsigned char *data, unsigned int rounds);\n\n\nstatic int sha1_init(struct shash_desc *desc)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\t*sctx = (struct sha1_state){\n\t\t.state = { SHA1_H0, SHA1_H1, SHA1_H2, SHA1_H3, SHA1_H4 },\n\t};\n\n\treturn 0;\n}\n\n\nstatic int __sha1_update(struct sha1_state *sctx, const u8 *data,\n\t\t\t unsigned int len, unsigned int partial)\n{\n\tunsigned int done = 0;\n\n\tsctx->count += len;\n\n\tif (partial) {\n\t\tdone = SHA1_BLOCK_SIZE - partial;\n\t\tmemcpy(sctx->buffer + partial, data, done);\n\t\tsha1_block_data_order(sctx->state, sctx->buffer, 1);\n\t}\n\n\tif (len - done >= SHA1_BLOCK_SIZE) {\n\t\tconst unsigned int rounds = (len - done) / SHA1_BLOCK_SIZE;\n\t\tsha1_block_data_order(sctx->state, data + done, rounds);\n\t\tdone += rounds * SHA1_BLOCK_SIZE;\n\t}\n\n\tmemcpy(sctx->buffer, data + done, len - done);\n\treturn 0;\n}\n\n\nint sha1_update_arm(struct shash_desc *desc, const u8 *data,\n\t\t    unsigned int len)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial = sctx->count % SHA1_BLOCK_SIZE;\n\tint res;\n\n\t/* Handle the fast case right here */\n\tif (partial + len < SHA1_BLOCK_SIZE) {\n\t\tsctx->count += len;\n\t\tmemcpy(sctx->buffer + partial, data, len);\n\t\treturn 0;\n\t}\n\tres = __sha1_update(sctx, data, len, partial);\n\treturn res;\n}\nEXPORT_SYMBOL_GPL(sha1_update_arm);\n\n\n/* Add padding and return the message digest. */\nstatic int sha1_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int i, index, padlen;\n\t__be32 *dst = (__be32 *)out;\n\t__be64 bits;\n\tstatic const u8 padding[SHA1_BLOCK_SIZE] = { 0x80, };\n\n\tbits = cpu_to_be64(sctx->count << 3);\n\n\t/* Pad out to 56 mod 64 and append length */\n\tindex = sctx->count % SHA1_BLOCK_SIZE;\n\tpadlen = (index < 56) ? (56 - index) : ((SHA1_BLOCK_SIZE+56) - index);\n\t/* We need to fill a whole block for __sha1_update() */\n\tif (padlen <= 56) {\n\t\tsctx->count += padlen;\n\t\tmemcpy(sctx->buffer + index, padding, padlen);\n\t} else {\n\t\t__sha1_update(sctx, padding, padlen, index);\n\t}\n\t__sha1_update(sctx, (const u8 *)&bits, sizeof(bits), 56);\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 5; i++)\n\t\tdst[i] = cpu_to_be32(sctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof(*sctx));\n\treturn 0;\n}\n\n\nstatic int sha1_export(struct shash_desc *desc, void *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tmemcpy(out, sctx, sizeof(*sctx));\n\treturn 0;\n}\n\n\nstatic int sha1_import(struct shash_desc *desc, const void *in)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tmemcpy(sctx, in, sizeof(*sctx));\n\treturn 0;\n}\n\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tSHA1_DIGEST_SIZE,\n\t.init\t\t=\tsha1_init,\n\t.update\t\t=\tsha1_update_arm,\n\t.final\t\t=\tsha1_final,\n\t.export\t\t=\tsha1_export,\n\t.import\t\t=\tsha1_import,\n\t.descsize\t=\tsizeof(struct sha1_state),\n\t.statesize\t=\tsizeof(struct sha1_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha1\",\n\t\t.cra_driver_name=\t\"sha1-asm\",\n\t\t.cra_priority\t=\t150,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA1_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\n\nstatic int __init sha1_mod_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\n\nstatic void __exit sha1_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\n\nmodule_init(sha1_mod_init);\nmodule_exit(sha1_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA1 Secure Hash Algorithm (ARM)\");\nMODULE_ALIAS(\"sha1\");\nMODULE_AUTHOR(\"David McCullough <ucdevel@gmail.com>\");\n", "/*\n * Glue code for the SHA1 Secure Hash Algorithm assembler implementation using\n * ARM NEON instructions.\n *\n * Copyright \u00a9 2014 Jussi Kivilinna <jussi.kivilinna@iki.fi>\n *\n * This file is based on sha1_generic.c and sha1_ssse3_glue.c:\n *  Copyright (c) Alan Smithee.\n *  Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n *  Copyright (c) Jean-Francois Dive <jef@linuxbe.org>\n *  Copyright (c) Mathias Krause <minipli@googlemail.com>\n *  Copyright (c) Chandramouli Narayanan <mouli@linux.intel.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n#include <asm/byteorder.h>\n#include <asm/neon.h>\n#include <asm/simd.h>\n#include <asm/crypto/sha1.h>\n\n\nasmlinkage void sha1_transform_neon(void *state_h, const char *data,\n\t\t\t\t    unsigned int rounds);\n\n\nstatic int sha1_neon_init(struct shash_desc *desc)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\t*sctx = (struct sha1_state){\n\t\t.state = { SHA1_H0, SHA1_H1, SHA1_H2, SHA1_H3, SHA1_H4 },\n\t};\n\n\treturn 0;\n}\n\nstatic int __sha1_neon_update(struct shash_desc *desc, const u8 *data,\n\t\t\t       unsigned int len, unsigned int partial)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int done = 0;\n\n\tsctx->count += len;\n\n\tif (partial) {\n\t\tdone = SHA1_BLOCK_SIZE - partial;\n\t\tmemcpy(sctx->buffer + partial, data, done);\n\t\tsha1_transform_neon(sctx->state, sctx->buffer, 1);\n\t}\n\n\tif (len - done >= SHA1_BLOCK_SIZE) {\n\t\tconst unsigned int rounds = (len - done) / SHA1_BLOCK_SIZE;\n\n\t\tsha1_transform_neon(sctx->state, data + done, rounds);\n\t\tdone += rounds * SHA1_BLOCK_SIZE;\n\t}\n\n\tmemcpy(sctx->buffer, data + done, len - done);\n\n\treturn 0;\n}\n\nstatic int sha1_neon_update(struct shash_desc *desc, const u8 *data,\n\t\t\t     unsigned int len)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial = sctx->count % SHA1_BLOCK_SIZE;\n\tint res;\n\n\t/* Handle the fast case right here */\n\tif (partial + len < SHA1_BLOCK_SIZE) {\n\t\tsctx->count += len;\n\t\tmemcpy(sctx->buffer + partial, data, len);\n\n\t\treturn 0;\n\t}\n\n\tif (!may_use_simd()) {\n\t\tres = sha1_update_arm(desc, data, len);\n\t} else {\n\t\tkernel_neon_begin();\n\t\tres = __sha1_neon_update(desc, data, len, partial);\n\t\tkernel_neon_end();\n\t}\n\n\treturn res;\n}\n\n\n/* Add padding and return the message digest. */\nstatic int sha1_neon_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int i, index, padlen;\n\t__be32 *dst = (__be32 *)out;\n\t__be64 bits;\n\tstatic const u8 padding[SHA1_BLOCK_SIZE] = { 0x80, };\n\n\tbits = cpu_to_be64(sctx->count << 3);\n\n\t/* Pad out to 56 mod 64 and append length */\n\tindex = sctx->count % SHA1_BLOCK_SIZE;\n\tpadlen = (index < 56) ? (56 - index) : ((SHA1_BLOCK_SIZE+56) - index);\n\tif (!may_use_simd()) {\n\t\tsha1_update_arm(desc, padding, padlen);\n\t\tsha1_update_arm(desc, (const u8 *)&bits, sizeof(bits));\n\t} else {\n\t\tkernel_neon_begin();\n\t\t/* We need to fill a whole block for __sha1_neon_update() */\n\t\tif (padlen <= 56) {\n\t\t\tsctx->count += padlen;\n\t\t\tmemcpy(sctx->buffer + index, padding, padlen);\n\t\t} else {\n\t\t\t__sha1_neon_update(desc, padding, padlen, index);\n\t\t}\n\t\t__sha1_neon_update(desc, (const u8 *)&bits, sizeof(bits), 56);\n\t\tkernel_neon_end();\n\t}\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 5; i++)\n\t\tdst[i] = cpu_to_be32(sctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha1_neon_export(struct shash_desc *desc, void *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha1_neon_import(struct shash_desc *desc, const void *in)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tSHA1_DIGEST_SIZE,\n\t.init\t\t=\tsha1_neon_init,\n\t.update\t\t=\tsha1_neon_update,\n\t.final\t\t=\tsha1_neon_final,\n\t.export\t\t=\tsha1_neon_export,\n\t.import\t\t=\tsha1_neon_import,\n\t.descsize\t=\tsizeof(struct sha1_state),\n\t.statesize\t=\tsizeof(struct sha1_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t\t= \"sha1\",\n\t\t.cra_driver_name\t= \"sha1-neon\",\n\t\t.cra_priority\t\t= 250,\n\t\t.cra_flags\t\t= CRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t\t= SHA1_BLOCK_SIZE,\n\t\t.cra_module\t\t= THIS_MODULE,\n\t}\n};\n\nstatic int __init sha1_neon_mod_init(void)\n{\n\tif (!cpu_has_neon())\n\t\treturn -ENODEV;\n\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit sha1_neon_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(sha1_neon_mod_init);\nmodule_exit(sha1_neon_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA1 Secure Hash Algorithm, NEON accelerated\");\nMODULE_ALIAS(\"sha1\");\n", "/*\n * Glue code for the SHA512 Secure Hash Algorithm assembly implementation\n * using NEON instructions.\n *\n * Copyright \u00a9 2014 Jussi Kivilinna <jussi.kivilinna@iki.fi>\n *\n * This file is based on sha512_ssse3_glue.c:\n *   Copyright (C) 2013 Intel Corporation\n *   Author: Tim Chen <tim.c.chen@linux.intel.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <linux/string.h>\n#include <crypto/sha.h>\n#include <asm/byteorder.h>\n#include <asm/simd.h>\n#include <asm/neon.h>\n\n\nstatic const u64 sha512_k[] = {\n\t0x428a2f98d728ae22ULL, 0x7137449123ef65cdULL,\n\t0xb5c0fbcfec4d3b2fULL, 0xe9b5dba58189dbbcULL,\n\t0x3956c25bf348b538ULL, 0x59f111f1b605d019ULL,\n\t0x923f82a4af194f9bULL, 0xab1c5ed5da6d8118ULL,\n\t0xd807aa98a3030242ULL, 0x12835b0145706fbeULL,\n\t0x243185be4ee4b28cULL, 0x550c7dc3d5ffb4e2ULL,\n\t0x72be5d74f27b896fULL, 0x80deb1fe3b1696b1ULL,\n\t0x9bdc06a725c71235ULL, 0xc19bf174cf692694ULL,\n\t0xe49b69c19ef14ad2ULL, 0xefbe4786384f25e3ULL,\n\t0x0fc19dc68b8cd5b5ULL, 0x240ca1cc77ac9c65ULL,\n\t0x2de92c6f592b0275ULL, 0x4a7484aa6ea6e483ULL,\n\t0x5cb0a9dcbd41fbd4ULL, 0x76f988da831153b5ULL,\n\t0x983e5152ee66dfabULL, 0xa831c66d2db43210ULL,\n\t0xb00327c898fb213fULL, 0xbf597fc7beef0ee4ULL,\n\t0xc6e00bf33da88fc2ULL, 0xd5a79147930aa725ULL,\n\t0x06ca6351e003826fULL, 0x142929670a0e6e70ULL,\n\t0x27b70a8546d22ffcULL, 0x2e1b21385c26c926ULL,\n\t0x4d2c6dfc5ac42aedULL, 0x53380d139d95b3dfULL,\n\t0x650a73548baf63deULL, 0x766a0abb3c77b2a8ULL,\n\t0x81c2c92e47edaee6ULL, 0x92722c851482353bULL,\n\t0xa2bfe8a14cf10364ULL, 0xa81a664bbc423001ULL,\n\t0xc24b8b70d0f89791ULL, 0xc76c51a30654be30ULL,\n\t0xd192e819d6ef5218ULL, 0xd69906245565a910ULL,\n\t0xf40e35855771202aULL, 0x106aa07032bbd1b8ULL,\n\t0x19a4c116b8d2d0c8ULL, 0x1e376c085141ab53ULL,\n\t0x2748774cdf8eeb99ULL, 0x34b0bcb5e19b48a8ULL,\n\t0x391c0cb3c5c95a63ULL, 0x4ed8aa4ae3418acbULL,\n\t0x5b9cca4f7763e373ULL, 0x682e6ff3d6b2b8a3ULL,\n\t0x748f82ee5defb2fcULL, 0x78a5636f43172f60ULL,\n\t0x84c87814a1f0ab72ULL, 0x8cc702081a6439ecULL,\n\t0x90befffa23631e28ULL, 0xa4506cebde82bde9ULL,\n\t0xbef9a3f7b2c67915ULL, 0xc67178f2e372532bULL,\n\t0xca273eceea26619cULL, 0xd186b8c721c0c207ULL,\n\t0xeada7dd6cde0eb1eULL, 0xf57d4f7fee6ed178ULL,\n\t0x06f067aa72176fbaULL, 0x0a637dc5a2c898a6ULL,\n\t0x113f9804bef90daeULL, 0x1b710b35131c471bULL,\n\t0x28db77f523047d84ULL, 0x32caab7b40c72493ULL,\n\t0x3c9ebe0a15c9bebcULL, 0x431d67c49c100d4cULL,\n\t0x4cc5d4becb3e42b6ULL, 0x597f299cfc657e2aULL,\n\t0x5fcb6fab3ad6faecULL, 0x6c44198c4a475817ULL\n};\n\n\nasmlinkage void sha512_transform_neon(u64 *digest, const void *data,\n\t\t\t\t      const u64 k[], unsigned int num_blks);\n\n\nstatic int sha512_neon_init(struct shash_desc *desc)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\n\tsctx->state[0] = SHA512_H0;\n\tsctx->state[1] = SHA512_H1;\n\tsctx->state[2] = SHA512_H2;\n\tsctx->state[3] = SHA512_H3;\n\tsctx->state[4] = SHA512_H4;\n\tsctx->state[5] = SHA512_H5;\n\tsctx->state[6] = SHA512_H6;\n\tsctx->state[7] = SHA512_H7;\n\tsctx->count[0] = sctx->count[1] = 0;\n\n\treturn 0;\n}\n\nstatic int __sha512_neon_update(struct shash_desc *desc, const u8 *data,\n\t\t\t\tunsigned int len, unsigned int partial)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tunsigned int done = 0;\n\n\tsctx->count[0] += len;\n\tif (sctx->count[0] < len)\n\t\tsctx->count[1]++;\n\n\tif (partial) {\n\t\tdone = SHA512_BLOCK_SIZE - partial;\n\t\tmemcpy(sctx->buf + partial, data, done);\n\t\tsha512_transform_neon(sctx->state, sctx->buf, sha512_k, 1);\n\t}\n\n\tif (len - done >= SHA512_BLOCK_SIZE) {\n\t\tconst unsigned int rounds = (len - done) / SHA512_BLOCK_SIZE;\n\n\t\tsha512_transform_neon(sctx->state, data + done, sha512_k,\n\t\t\t\t      rounds);\n\n\t\tdone += rounds * SHA512_BLOCK_SIZE;\n\t}\n\n\tmemcpy(sctx->buf, data + done, len - done);\n\n\treturn 0;\n}\n\nstatic int sha512_neon_update(struct shash_desc *desc, const u8 *data,\n\t\t\t     unsigned int len)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial = sctx->count[0] % SHA512_BLOCK_SIZE;\n\tint res;\n\n\t/* Handle the fast case right here */\n\tif (partial + len < SHA512_BLOCK_SIZE) {\n\t\tsctx->count[0] += len;\n\t\tif (sctx->count[0] < len)\n\t\t\tsctx->count[1]++;\n\t\tmemcpy(sctx->buf + partial, data, len);\n\n\t\treturn 0;\n\t}\n\n\tif (!may_use_simd()) {\n\t\tres = crypto_sha512_update(desc, data, len);\n\t} else {\n\t\tkernel_neon_begin();\n\t\tres = __sha512_neon_update(desc, data, len, partial);\n\t\tkernel_neon_end();\n\t}\n\n\treturn res;\n}\n\n\n/* Add padding and return the message digest. */\nstatic int sha512_neon_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tunsigned int i, index, padlen;\n\t__be64 *dst = (__be64 *)out;\n\t__be64 bits[2];\n\tstatic const u8 padding[SHA512_BLOCK_SIZE] = { 0x80, };\n\n\t/* save number of bits */\n\tbits[1] = cpu_to_be64(sctx->count[0] << 3);\n\tbits[0] = cpu_to_be64(sctx->count[1] << 3 | sctx->count[0] >> 61);\n\n\t/* Pad out to 112 mod 128 and append length */\n\tindex = sctx->count[0] & 0x7f;\n\tpadlen = (index < 112) ? (112 - index) : ((128+112) - index);\n\n\tif (!may_use_simd()) {\n\t\tcrypto_sha512_update(desc, padding, padlen);\n\t\tcrypto_sha512_update(desc, (const u8 *)&bits, sizeof(bits));\n\t} else {\n\t\tkernel_neon_begin();\n\t\t/* We need to fill a whole block for __sha512_neon_update() */\n\t\tif (padlen <= 112) {\n\t\t\tsctx->count[0] += padlen;\n\t\t\tif (sctx->count[0] < padlen)\n\t\t\t\tsctx->count[1]++;\n\t\t\tmemcpy(sctx->buf + index, padding, padlen);\n\t\t} else {\n\t\t\t__sha512_neon_update(desc, padding, padlen, index);\n\t\t}\n\t\t__sha512_neon_update(desc, (const u8 *)&bits,\n\t\t\t\t\tsizeof(bits), 112);\n\t\tkernel_neon_end();\n\t}\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 8; i++)\n\t\tdst[i] = cpu_to_be64(sctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha512_neon_export(struct shash_desc *desc, void *out)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha512_neon_import(struct shash_desc *desc, const void *in)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha384_neon_init(struct shash_desc *desc)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\n\tsctx->state[0] = SHA384_H0;\n\tsctx->state[1] = SHA384_H1;\n\tsctx->state[2] = SHA384_H2;\n\tsctx->state[3] = SHA384_H3;\n\tsctx->state[4] = SHA384_H4;\n\tsctx->state[5] = SHA384_H5;\n\tsctx->state[6] = SHA384_H6;\n\tsctx->state[7] = SHA384_H7;\n\n\tsctx->count[0] = sctx->count[1] = 0;\n\n\treturn 0;\n}\n\nstatic int sha384_neon_final(struct shash_desc *desc, u8 *hash)\n{\n\tu8 D[SHA512_DIGEST_SIZE];\n\n\tsha512_neon_final(desc, D);\n\n\tmemcpy(hash, D, SHA384_DIGEST_SIZE);\n\tmemset(D, 0, SHA512_DIGEST_SIZE);\n\n\treturn 0;\n}\n\nstatic struct shash_alg algs[] = { {\n\t.digestsize\t=\tSHA512_DIGEST_SIZE,\n\t.init\t\t=\tsha512_neon_init,\n\t.update\t\t=\tsha512_neon_update,\n\t.final\t\t=\tsha512_neon_final,\n\t.export\t\t=\tsha512_neon_export,\n\t.import\t\t=\tsha512_neon_import,\n\t.descsize\t=\tsizeof(struct sha512_state),\n\t.statesize\t=\tsizeof(struct sha512_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha512\",\n\t\t.cra_driver_name =\t\"sha512-neon\",\n\t\t.cra_priority\t=\t250,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA512_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n},  {\n\t.digestsize\t=\tSHA384_DIGEST_SIZE,\n\t.init\t\t=\tsha384_neon_init,\n\t.update\t\t=\tsha512_neon_update,\n\t.final\t\t=\tsha384_neon_final,\n\t.export\t\t=\tsha512_neon_export,\n\t.import\t\t=\tsha512_neon_import,\n\t.descsize\t=\tsizeof(struct sha512_state),\n\t.statesize\t=\tsizeof(struct sha512_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha384\",\n\t\t.cra_driver_name =\t\"sha384-neon\",\n\t\t.cra_priority\t=\t250,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA384_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n} };\n\nstatic int __init sha512_neon_mod_init(void)\n{\n\tif (!cpu_has_neon())\n\t\treturn -ENODEV;\n\n\treturn crypto_register_shashes(algs, ARRAY_SIZE(algs));\n}\n\nstatic void __exit sha512_neon_mod_fini(void)\n{\n\tcrypto_unregister_shashes(algs, ARRAY_SIZE(algs));\n}\n\nmodule_init(sha512_neon_mod_init);\nmodule_exit(sha512_neon_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA512 Secure Hash Algorithm, NEON accelerated\");\n\nMODULE_ALIAS(\"sha512\");\nMODULE_ALIAS(\"sha384\");\n", "/*\n * aes-ccm-glue.c - AES-CCM transform for ARMv8 with Crypto Extensions\n *\n * Copyright (C) 2013 - 2014 Linaro Ltd <ard.biesheuvel@linaro.org>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License version 2 as\n * published by the Free Software Foundation.\n */\n\n#include <asm/neon.h>\n#include <asm/unaligned.h>\n#include <crypto/aes.h>\n#include <crypto/algapi.h>\n#include <crypto/scatterwalk.h>\n#include <linux/crypto.h>\n#include <linux/module.h>\n\nstatic int num_rounds(struct crypto_aes_ctx *ctx)\n{\n\t/*\n\t * # of rounds specified by AES:\n\t * 128 bit key\t\t10 rounds\n\t * 192 bit key\t\t12 rounds\n\t * 256 bit key\t\t14 rounds\n\t * => n byte key\t=> 6 + (n/4) rounds\n\t */\n\treturn 6 + ctx->key_length / 4;\n}\n\nasmlinkage void ce_aes_ccm_auth_data(u8 mac[], u8 const in[], u32 abytes,\n\t\t\t\t     u32 *macp, u32 const rk[], u32 rounds);\n\nasmlinkage void ce_aes_ccm_encrypt(u8 out[], u8 const in[], u32 cbytes,\n\t\t\t\t   u32 const rk[], u32 rounds, u8 mac[],\n\t\t\t\t   u8 ctr[]);\n\nasmlinkage void ce_aes_ccm_decrypt(u8 out[], u8 const in[], u32 cbytes,\n\t\t\t\t   u32 const rk[], u32 rounds, u8 mac[],\n\t\t\t\t   u8 ctr[]);\n\nasmlinkage void ce_aes_ccm_final(u8 mac[], u8 const ctr[], u32 const rk[],\n\t\t\t\t u32 rounds);\n\nstatic int ccm_setkey(struct crypto_aead *tfm, const u8 *in_key,\n\t\t      unsigned int key_len)\n{\n\tstruct crypto_aes_ctx *ctx = crypto_aead_ctx(tfm);\n\tint ret;\n\n\tret = crypto_aes_expand_key(ctx, in_key, key_len);\n\tif (!ret)\n\t\treturn 0;\n\n\ttfm->base.crt_flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\treturn -EINVAL;\n}\n\nstatic int ccm_setauthsize(struct crypto_aead *tfm, unsigned int authsize)\n{\n\tif ((authsize & 1) || authsize < 4)\n\t\treturn -EINVAL;\n\treturn 0;\n}\n\nstatic int ccm_init_mac(struct aead_request *req, u8 maciv[], u32 msglen)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\t__be32 *n = (__be32 *)&maciv[AES_BLOCK_SIZE - 8];\n\tu32 l = req->iv[0] + 1;\n\n\t/* verify that CCM dimension 'L' is set correctly in the IV */\n\tif (l < 2 || l > 8)\n\t\treturn -EINVAL;\n\n\t/* verify that msglen can in fact be represented in L bytes */\n\tif (l < 4 && msglen >> (8 * l))\n\t\treturn -EOVERFLOW;\n\n\t/*\n\t * Even if the CCM spec allows L values of up to 8, the Linux cryptoapi\n\t * uses a u32 type to represent msglen so the top 4 bytes are always 0.\n\t */\n\tn[0] = 0;\n\tn[1] = cpu_to_be32(msglen);\n\n\tmemcpy(maciv, req->iv, AES_BLOCK_SIZE - l);\n\n\t/*\n\t * Meaning of byte 0 according to CCM spec (RFC 3610/NIST 800-38C)\n\t * - bits 0..2\t: max # of bytes required to represent msglen, minus 1\n\t *                (already set by caller)\n\t * - bits 3..5\t: size of auth tag (1 => 4 bytes, 2 => 6 bytes, etc)\n\t * - bit 6\t: indicates presence of authenticate-only data\n\t */\n\tmaciv[0] |= (crypto_aead_authsize(aead) - 2) << 2;\n\tif (req->assoclen)\n\t\tmaciv[0] |= 0x40;\n\n\tmemset(&req->iv[AES_BLOCK_SIZE - l], 0, l);\n\treturn 0;\n}\n\nstatic void ccm_calculate_auth_mac(struct aead_request *req, u8 mac[])\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_aes_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct __packed { __be16 l; __be32 h; u16 len; } ltag;\n\tstruct scatter_walk walk;\n\tu32 len = req->assoclen;\n\tu32 macp = 0;\n\n\t/* prepend the AAD with a length tag */\n\tif (len < 0xff00) {\n\t\tltag.l = cpu_to_be16(len);\n\t\tltag.len = 2;\n\t} else  {\n\t\tltag.l = cpu_to_be16(0xfffe);\n\t\tput_unaligned_be32(len, &ltag.h);\n\t\tltag.len = 6;\n\t}\n\n\tce_aes_ccm_auth_data(mac, (u8 *)&ltag, ltag.len, &macp, ctx->key_enc,\n\t\t\t     num_rounds(ctx));\n\tscatterwalk_start(&walk, req->assoc);\n\n\tdo {\n\t\tu32 n = scatterwalk_clamp(&walk, len);\n\t\tu8 *p;\n\n\t\tif (!n) {\n\t\t\tscatterwalk_start(&walk, sg_next(walk.sg));\n\t\t\tn = scatterwalk_clamp(&walk, len);\n\t\t}\n\t\tp = scatterwalk_map(&walk);\n\t\tce_aes_ccm_auth_data(mac, p, n, &macp, ctx->key_enc,\n\t\t\t\t     num_rounds(ctx));\n\t\tlen -= n;\n\n\t\tscatterwalk_unmap(p);\n\t\tscatterwalk_advance(&walk, n);\n\t\tscatterwalk_done(&walk, 0, len);\n\t} while (len);\n}\n\nstatic int ccm_encrypt(struct aead_request *req)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_aes_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct blkcipher_desc desc = { .info = req->iv };\n\tstruct blkcipher_walk walk;\n\tu8 __aligned(8) mac[AES_BLOCK_SIZE];\n\tu8 buf[AES_BLOCK_SIZE];\n\tu32 len = req->cryptlen;\n\tint err;\n\n\terr = ccm_init_mac(req, mac, len);\n\tif (err)\n\t\treturn err;\n\n\tkernel_neon_begin_partial(6);\n\n\tif (req->assoclen)\n\t\tccm_calculate_auth_mac(req, mac);\n\n\t/* preserve the original iv for the final round */\n\tmemcpy(buf, req->iv, AES_BLOCK_SIZE);\n\n\tblkcipher_walk_init(&walk, req->dst, req->src, len);\n\terr = blkcipher_aead_walk_virt_block(&desc, &walk, aead,\n\t\t\t\t\t     AES_BLOCK_SIZE);\n\n\twhile (walk.nbytes) {\n\t\tu32 tail = walk.nbytes % AES_BLOCK_SIZE;\n\n\t\tif (walk.nbytes == len)\n\t\t\ttail = 0;\n\n\t\tce_aes_ccm_encrypt(walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t\t   walk.nbytes - tail, ctx->key_enc,\n\t\t\t\t   num_rounds(ctx), mac, walk.iv);\n\n\t\tlen -= walk.nbytes - tail;\n\t\terr = blkcipher_walk_done(&desc, &walk, tail);\n\t}\n\tif (!err)\n\t\tce_aes_ccm_final(mac, buf, ctx->key_enc, num_rounds(ctx));\n\n\tkernel_neon_end();\n\n\tif (err)\n\t\treturn err;\n\n\t/* copy authtag to end of dst */\n\tscatterwalk_map_and_copy(mac, req->dst, req->cryptlen,\n\t\t\t\t crypto_aead_authsize(aead), 1);\n\n\treturn 0;\n}\n\nstatic int ccm_decrypt(struct aead_request *req)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_aes_ctx *ctx = crypto_aead_ctx(aead);\n\tunsigned int authsize = crypto_aead_authsize(aead);\n\tstruct blkcipher_desc desc = { .info = req->iv };\n\tstruct blkcipher_walk walk;\n\tu8 __aligned(8) mac[AES_BLOCK_SIZE];\n\tu8 buf[AES_BLOCK_SIZE];\n\tu32 len = req->cryptlen - authsize;\n\tint err;\n\n\terr = ccm_init_mac(req, mac, len);\n\tif (err)\n\t\treturn err;\n\n\tkernel_neon_begin_partial(6);\n\n\tif (req->assoclen)\n\t\tccm_calculate_auth_mac(req, mac);\n\n\t/* preserve the original iv for the final round */\n\tmemcpy(buf, req->iv, AES_BLOCK_SIZE);\n\n\tblkcipher_walk_init(&walk, req->dst, req->src, len);\n\terr = blkcipher_aead_walk_virt_block(&desc, &walk, aead,\n\t\t\t\t\t     AES_BLOCK_SIZE);\n\n\twhile (walk.nbytes) {\n\t\tu32 tail = walk.nbytes % AES_BLOCK_SIZE;\n\n\t\tif (walk.nbytes == len)\n\t\t\ttail = 0;\n\n\t\tce_aes_ccm_decrypt(walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t\t   walk.nbytes - tail, ctx->key_enc,\n\t\t\t\t   num_rounds(ctx), mac, walk.iv);\n\n\t\tlen -= walk.nbytes - tail;\n\t\terr = blkcipher_walk_done(&desc, &walk, tail);\n\t}\n\tif (!err)\n\t\tce_aes_ccm_final(mac, buf, ctx->key_enc, num_rounds(ctx));\n\n\tkernel_neon_end();\n\n\tif (err)\n\t\treturn err;\n\n\t/* compare calculated auth tag with the stored one */\n\tscatterwalk_map_and_copy(buf, req->src, req->cryptlen - authsize,\n\t\t\t\t authsize, 0);\n\n\tif (memcmp(mac, buf, authsize))\n\t\treturn -EBADMSG;\n\treturn 0;\n}\n\nstatic struct crypto_alg ccm_aes_alg = {\n\t.cra_name\t\t= \"ccm(aes)\",\n\t.cra_driver_name\t= \"ccm-aes-ce\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_AEAD,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_aes_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_aead_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_aead = {\n\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t.maxauthsize\t= AES_BLOCK_SIZE,\n\t\t.setkey\t\t= ccm_setkey,\n\t\t.setauthsize\t= ccm_setauthsize,\n\t\t.encrypt\t= ccm_encrypt,\n\t\t.decrypt\t= ccm_decrypt,\n\t}\n};\n\nstatic int __init aes_mod_init(void)\n{\n\tif (!(elf_hwcap & HWCAP_AES))\n\t\treturn -ENODEV;\n\treturn crypto_register_alg(&ccm_aes_alg);\n}\n\nstatic void __exit aes_mod_exit(void)\n{\n\tcrypto_unregister_alg(&ccm_aes_alg);\n}\n\nmodule_init(aes_mod_init);\nmodule_exit(aes_mod_exit);\n\nMODULE_DESCRIPTION(\"Synchronous AES in CCM mode using ARMv8 Crypto Extensions\");\nMODULE_AUTHOR(\"Ard Biesheuvel <ard.biesheuvel@linaro.org>\");\nMODULE_LICENSE(\"GPL v2\");\nMODULE_ALIAS(\"ccm(aes)\");\n", "/*\n * linux/arch/arm64/crypto/aes-glue.c - wrapper code for ARMv8 AES\n *\n * Copyright (C) 2013 Linaro Ltd <ard.biesheuvel@linaro.org>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License version 2 as\n * published by the Free Software Foundation.\n */\n\n#include <asm/neon.h>\n#include <asm/hwcap.h>\n#include <crypto/aes.h>\n#include <crypto/ablk_helper.h>\n#include <crypto/algapi.h>\n#include <linux/module.h>\n#include <linux/cpufeature.h>\n\n#ifdef USE_V8_CRYPTO_EXTENSIONS\n#define MODE\t\t\t\"ce\"\n#define PRIO\t\t\t300\n#define aes_ecb_encrypt\t\tce_aes_ecb_encrypt\n#define aes_ecb_decrypt\t\tce_aes_ecb_decrypt\n#define aes_cbc_encrypt\t\tce_aes_cbc_encrypt\n#define aes_cbc_decrypt\t\tce_aes_cbc_decrypt\n#define aes_ctr_encrypt\t\tce_aes_ctr_encrypt\n#define aes_xts_encrypt\t\tce_aes_xts_encrypt\n#define aes_xts_decrypt\t\tce_aes_xts_decrypt\nMODULE_DESCRIPTION(\"AES-ECB/CBC/CTR/XTS using ARMv8 Crypto Extensions\");\n#else\n#define MODE\t\t\t\"neon\"\n#define PRIO\t\t\t200\n#define aes_ecb_encrypt\t\tneon_aes_ecb_encrypt\n#define aes_ecb_decrypt\t\tneon_aes_ecb_decrypt\n#define aes_cbc_encrypt\t\tneon_aes_cbc_encrypt\n#define aes_cbc_decrypt\t\tneon_aes_cbc_decrypt\n#define aes_ctr_encrypt\t\tneon_aes_ctr_encrypt\n#define aes_xts_encrypt\t\tneon_aes_xts_encrypt\n#define aes_xts_decrypt\t\tneon_aes_xts_decrypt\nMODULE_DESCRIPTION(\"AES-ECB/CBC/CTR/XTS using ARMv8 NEON\");\nMODULE_ALIAS(\"ecb(aes)\");\nMODULE_ALIAS(\"cbc(aes)\");\nMODULE_ALIAS(\"ctr(aes)\");\nMODULE_ALIAS(\"xts(aes)\");\n#endif\n\nMODULE_AUTHOR(\"Ard Biesheuvel <ard.biesheuvel@linaro.org>\");\nMODULE_LICENSE(\"GPL v2\");\n\n/* defined in aes-modes.S */\nasmlinkage void aes_ecb_encrypt(u8 out[], u8 const in[], u8 const rk[],\n\t\t\t\tint rounds, int blocks, int first);\nasmlinkage void aes_ecb_decrypt(u8 out[], u8 const in[], u8 const rk[],\n\t\t\t\tint rounds, int blocks, int first);\n\nasmlinkage void aes_cbc_encrypt(u8 out[], u8 const in[], u8 const rk[],\n\t\t\t\tint rounds, int blocks, u8 iv[], int first);\nasmlinkage void aes_cbc_decrypt(u8 out[], u8 const in[], u8 const rk[],\n\t\t\t\tint rounds, int blocks, u8 iv[], int first);\n\nasmlinkage void aes_ctr_encrypt(u8 out[], u8 const in[], u8 const rk[],\n\t\t\t\tint rounds, int blocks, u8 ctr[], int first);\n\nasmlinkage void aes_xts_encrypt(u8 out[], u8 const in[], u8 const rk1[],\n\t\t\t\tint rounds, int blocks, u8 const rk2[], u8 iv[],\n\t\t\t\tint first);\nasmlinkage void aes_xts_decrypt(u8 out[], u8 const in[], u8 const rk1[],\n\t\t\t\tint rounds, int blocks, u8 const rk2[], u8 iv[],\n\t\t\t\tint first);\n\nstruct crypto_aes_xts_ctx {\n\tstruct crypto_aes_ctx key1;\n\tstruct crypto_aes_ctx __aligned(8) key2;\n};\n\nstatic int xts_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t       unsigned int key_len)\n{\n\tstruct crypto_aes_xts_ctx *ctx = crypto_tfm_ctx(tfm);\n\tint ret;\n\n\tret = crypto_aes_expand_key(&ctx->key1, in_key, key_len / 2);\n\tif (!ret)\n\t\tret = crypto_aes_expand_key(&ctx->key2, &in_key[key_len / 2],\n\t\t\t\t\t    key_len / 2);\n\tif (!ret)\n\t\treturn 0;\n\n\ttfm->crt_flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\treturn -EINVAL;\n}\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct crypto_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tint err, first, rounds = 6 + ctx->key_length / 4;\n\tstruct blkcipher_walk walk;\n\tunsigned int blocks;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\tkernel_neon_begin();\n\tfor (first = 1; (blocks = (walk.nbytes / AES_BLOCK_SIZE)); first = 0) {\n\t\taes_ecb_encrypt(walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t\t(u8 *)ctx->key_enc, rounds, blocks, first);\n\t\terr = blkcipher_walk_done(desc, &walk, walk.nbytes % AES_BLOCK_SIZE);\n\t}\n\tkernel_neon_end();\n\treturn err;\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct crypto_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tint err, first, rounds = 6 + ctx->key_length / 4;\n\tstruct blkcipher_walk walk;\n\tunsigned int blocks;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\tkernel_neon_begin();\n\tfor (first = 1; (blocks = (walk.nbytes / AES_BLOCK_SIZE)); first = 0) {\n\t\taes_ecb_decrypt(walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t\t(u8 *)ctx->key_dec, rounds, blocks, first);\n\t\terr = blkcipher_walk_done(desc, &walk, walk.nbytes % AES_BLOCK_SIZE);\n\t}\n\tkernel_neon_end();\n\treturn err;\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct crypto_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tint err, first, rounds = 6 + ctx->key_length / 4;\n\tstruct blkcipher_walk walk;\n\tunsigned int blocks;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\tkernel_neon_begin();\n\tfor (first = 1; (blocks = (walk.nbytes / AES_BLOCK_SIZE)); first = 0) {\n\t\taes_cbc_encrypt(walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t\t(u8 *)ctx->key_enc, rounds, blocks, walk.iv,\n\t\t\t\tfirst);\n\t\terr = blkcipher_walk_done(desc, &walk, walk.nbytes % AES_BLOCK_SIZE);\n\t}\n\tkernel_neon_end();\n\treturn err;\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct crypto_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tint err, first, rounds = 6 + ctx->key_length / 4;\n\tstruct blkcipher_walk walk;\n\tunsigned int blocks;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\tkernel_neon_begin();\n\tfor (first = 1; (blocks = (walk.nbytes / AES_BLOCK_SIZE)); first = 0) {\n\t\taes_cbc_decrypt(walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t\t(u8 *)ctx->key_dec, rounds, blocks, walk.iv,\n\t\t\t\tfirst);\n\t\terr = blkcipher_walk_done(desc, &walk, walk.nbytes % AES_BLOCK_SIZE);\n\t}\n\tkernel_neon_end();\n\treturn err;\n}\n\nstatic int ctr_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct crypto_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tint err, first, rounds = 6 + ctx->key_length / 4;\n\tstruct blkcipher_walk walk;\n\tint blocks;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt_block(desc, &walk, AES_BLOCK_SIZE);\n\n\tfirst = 1;\n\tkernel_neon_begin();\n\twhile ((blocks = (walk.nbytes / AES_BLOCK_SIZE))) {\n\t\taes_ctr_encrypt(walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t\t(u8 *)ctx->key_enc, rounds, blocks, walk.iv,\n\t\t\t\tfirst);\n\t\tfirst = 0;\n\t\tnbytes -= blocks * AES_BLOCK_SIZE;\n\t\tif (nbytes && nbytes == walk.nbytes % AES_BLOCK_SIZE)\n\t\t\tbreak;\n\t\terr = blkcipher_walk_done(desc, &walk,\n\t\t\t\t\t  walk.nbytes % AES_BLOCK_SIZE);\n\t}\n\tif (nbytes) {\n\t\tu8 *tdst = walk.dst.virt.addr + blocks * AES_BLOCK_SIZE;\n\t\tu8 *tsrc = walk.src.virt.addr + blocks * AES_BLOCK_SIZE;\n\t\tu8 __aligned(8) tail[AES_BLOCK_SIZE];\n\n\t\t/*\n\t\t * Minimum alignment is 8 bytes, so if nbytes is <= 8, we need\n\t\t * to tell aes_ctr_encrypt() to only read half a block.\n\t\t */\n\t\tblocks = (nbytes <= 8) ? -1 : 1;\n\n\t\taes_ctr_encrypt(tail, tsrc, (u8 *)ctx->key_enc, rounds,\n\t\t\t\tblocks, walk.iv, first);\n\t\tmemcpy(tdst, tail, nbytes);\n\t\terr = blkcipher_walk_done(desc, &walk, 0);\n\t}\n\tkernel_neon_end();\n\n\treturn err;\n}\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct crypto_aes_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tint err, first, rounds = 6 + ctx->key1.key_length / 4;\n\tstruct blkcipher_walk walk;\n\tunsigned int blocks;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\tkernel_neon_begin();\n\tfor (first = 1; (blocks = (walk.nbytes / AES_BLOCK_SIZE)); first = 0) {\n\t\taes_xts_encrypt(walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t\t(u8 *)ctx->key1.key_enc, rounds, blocks,\n\t\t\t\t(u8 *)ctx->key2.key_enc, walk.iv, first);\n\t\terr = blkcipher_walk_done(desc, &walk, walk.nbytes % AES_BLOCK_SIZE);\n\t}\n\tkernel_neon_end();\n\n\treturn err;\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct crypto_aes_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tint err, first, rounds = 6 + ctx->key1.key_length / 4;\n\tstruct blkcipher_walk walk;\n\tunsigned int blocks;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\tkernel_neon_begin();\n\tfor (first = 1; (blocks = (walk.nbytes / AES_BLOCK_SIZE)); first = 0) {\n\t\taes_xts_decrypt(walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t\t(u8 *)ctx->key1.key_dec, rounds, blocks,\n\t\t\t\t(u8 *)ctx->key2.key_enc, walk.iv, first);\n\t\terr = blkcipher_walk_done(desc, &walk, walk.nbytes % AES_BLOCK_SIZE);\n\t}\n\tkernel_neon_end();\n\n\treturn err;\n}\n\nstatic struct crypto_alg aes_algs[] = { {\n\t.cra_name\t\t= \"__ecb-aes-\" MODE,\n\t.cra_driver_name\t= \"__driver-ecb-aes-\" MODE,\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_aes_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_blkcipher = {\n\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t.setkey\t\t= crypto_aes_set_key,\n\t\t.encrypt\t= ecb_encrypt,\n\t\t.decrypt\t= ecb_decrypt,\n\t},\n}, {\n\t.cra_name\t\t= \"__cbc-aes-\" MODE,\n\t.cra_driver_name\t= \"__driver-cbc-aes-\" MODE,\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_aes_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_blkcipher = {\n\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t.setkey\t\t= crypto_aes_set_key,\n\t\t.encrypt\t= cbc_encrypt,\n\t\t.decrypt\t= cbc_decrypt,\n\t},\n}, {\n\t.cra_name\t\t= \"__ctr-aes-\" MODE,\n\t.cra_driver_name\t= \"__driver-ctr-aes-\" MODE,\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_aes_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_blkcipher = {\n\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t.setkey\t\t= crypto_aes_set_key,\n\t\t.encrypt\t= ctr_encrypt,\n\t\t.decrypt\t= ctr_encrypt,\n\t},\n}, {\n\t.cra_name\t\t= \"__xts-aes-\" MODE,\n\t.cra_driver_name\t= \"__driver-xts-aes-\" MODE,\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_aes_xts_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_blkcipher = {\n\t\t.min_keysize\t= 2 * AES_MIN_KEY_SIZE,\n\t\t.max_keysize\t= 2 * AES_MAX_KEY_SIZE,\n\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t.setkey\t\t= xts_set_key,\n\t\t.encrypt\t= xts_encrypt,\n\t\t.decrypt\t= xts_decrypt,\n\t},\n}, {\n\t.cra_name\t\t= \"ecb(aes)\",\n\t.cra_driver_name\t= \"ecb-aes-\" MODE,\n\t.cra_priority\t\t= PRIO,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER|CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_ablkcipher = {\n\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t.setkey\t\t= ablk_set_key,\n\t\t.encrypt\t= ablk_encrypt,\n\t\t.decrypt\t= ablk_decrypt,\n\t}\n}, {\n\t.cra_name\t\t= \"cbc(aes)\",\n\t.cra_driver_name\t= \"cbc-aes-\" MODE,\n\t.cra_priority\t\t= PRIO,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER|CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_ablkcipher = {\n\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t.setkey\t\t= ablk_set_key,\n\t\t.encrypt\t= ablk_encrypt,\n\t\t.decrypt\t= ablk_decrypt,\n\t}\n}, {\n\t.cra_name\t\t= \"ctr(aes)\",\n\t.cra_driver_name\t= \"ctr-aes-\" MODE,\n\t.cra_priority\t\t= PRIO,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER|CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_ablkcipher = {\n\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t.setkey\t\t= ablk_set_key,\n\t\t.encrypt\t= ablk_encrypt,\n\t\t.decrypt\t= ablk_decrypt,\n\t}\n}, {\n\t.cra_name\t\t= \"xts(aes)\",\n\t.cra_driver_name\t= \"xts-aes-\" MODE,\n\t.cra_priority\t\t= PRIO,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER|CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_ablkcipher = {\n\t\t.min_keysize\t= 2 * AES_MIN_KEY_SIZE,\n\t\t.max_keysize\t= 2 * AES_MAX_KEY_SIZE,\n\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t.setkey\t\t= ablk_set_key,\n\t\t.encrypt\t= ablk_encrypt,\n\t\t.decrypt\t= ablk_decrypt,\n\t}\n} };\n\nstatic int __init aes_init(void)\n{\n\treturn crypto_register_algs(aes_algs, ARRAY_SIZE(aes_algs));\n}\n\nstatic void __exit aes_exit(void)\n{\n\tcrypto_unregister_algs(aes_algs, ARRAY_SIZE(aes_algs));\n}\n\n#ifdef USE_V8_CRYPTO_EXTENSIONS\nmodule_cpu_feature_match(AES, aes_init);\n#else\nmodule_init(aes_init);\n#endif\nmodule_exit(aes_exit);\n", "/*\n * Cryptographic API.\n *\n * powerpc implementation of the SHA1 Secure Hash Algorithm.\n *\n * Derived from cryptoapi implementation, adapted for in-place\n * scatterlist interface.\n *\n * Derived from \"crypto/sha1.c\"\n * Copyright (c) Alan Smithee.\n * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n * Copyright (c) Jean-Francois Dive <jef@linuxbe.org>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n#include <asm/byteorder.h>\n\nextern void powerpc_sha_transform(u32 *state, const u8 *src, u32 *temp);\n\nstatic int sha1_init(struct shash_desc *desc)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\t*sctx = (struct sha1_state){\n\t\t.state = { SHA1_H0, SHA1_H1, SHA1_H2, SHA1_H3, SHA1_H4 },\n\t};\n\n\treturn 0;\n}\n\nstatic int sha1_update(struct shash_desc *desc, const u8 *data,\n\t\t\tunsigned int len)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial, done;\n\tconst u8 *src;\n\n\tpartial = sctx->count & 0x3f;\n\tsctx->count += len;\n\tdone = 0;\n\tsrc = data;\n\n\tif ((partial + len) > 63) {\n\t\tu32 temp[SHA_WORKSPACE_WORDS];\n\n\t\tif (partial) {\n\t\t\tdone = -partial;\n\t\t\tmemcpy(sctx->buffer + partial, data, done + 64);\n\t\t\tsrc = sctx->buffer;\n\t\t}\n\n\t\tdo {\n\t\t\tpowerpc_sha_transform(sctx->state, src, temp);\n\t\t\tdone += 64;\n\t\t\tsrc = data + done;\n\t\t} while (done + 63 < len);\n\n\t\tmemset(temp, 0, sizeof(temp));\n\t\tpartial = 0;\n\t}\n\tmemcpy(sctx->buffer + partial, src, len - done);\n\n\treturn 0;\n}\n\n\n/* Add padding and return the message digest. */\nstatic int sha1_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\t__be32 *dst = (__be32 *)out;\n\tu32 i, index, padlen;\n\t__be64 bits;\n\tstatic const u8 padding[64] = { 0x80, };\n\n\tbits = cpu_to_be64(sctx->count << 3);\n\n\t/* Pad out to 56 mod 64 */\n\tindex = sctx->count & 0x3f;\n\tpadlen = (index < 56) ? (56 - index) : ((64+56) - index);\n\tsha1_update(desc, padding, padlen);\n\n\t/* Append length */\n\tsha1_update(desc, (const u8 *)&bits, sizeof(bits));\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 5; i++)\n\t\tdst[i] = cpu_to_be32(sctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof *sctx);\n\n\treturn 0;\n}\n\nstatic int sha1_export(struct shash_desc *desc, void *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, sizeof(*sctx));\n\treturn 0;\n}\n\nstatic int sha1_import(struct shash_desc *desc, const void *in)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, sizeof(*sctx));\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tSHA1_DIGEST_SIZE,\n\t.init\t\t=\tsha1_init,\n\t.update\t\t=\tsha1_update,\n\t.final\t\t=\tsha1_final,\n\t.export\t\t=\tsha1_export,\n\t.import\t\t=\tsha1_import,\n\t.descsize\t=\tsizeof(struct sha1_state),\n\t.statesize\t=\tsizeof(struct sha1_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha1\",\n\t\t.cra_driver_name=\t\"sha1-powerpc\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA1_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init sha1_powerpc_mod_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit sha1_powerpc_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(sha1_powerpc_mod_init);\nmodule_exit(sha1_powerpc_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA1 Secure Hash Algorithm\");\n\nMODULE_ALIAS(\"sha1-powerpc\");\n", "/*\n * Cryptographic API.\n *\n * s390 implementation of the AES Cipher Algorithm.\n *\n * s390 Version:\n *   Copyright IBM Corp. 2005, 2007\n *   Author(s): Jan Glauber (jang@de.ibm.com)\n *\t\tSebastian Siewior (sebastian@breakpoint.cc> SW-Fallback\n *\n * Derived from \"crypto/aes_generic.c\"\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#define KMSG_COMPONENT \"aes_s390\"\n#define pr_fmt(fmt) KMSG_COMPONENT \": \" fmt\n\n#include <crypto/aes.h>\n#include <crypto/algapi.h>\n#include <linux/err.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/spinlock.h>\n#include \"crypt_s390.h\"\n\n#define AES_KEYLEN_128\t\t1\n#define AES_KEYLEN_192\t\t2\n#define AES_KEYLEN_256\t\t4\n\nstatic u8 *ctrblk;\nstatic DEFINE_SPINLOCK(ctrblk_lock);\nstatic char keylen_flag;\n\nstruct s390_aes_ctx {\n\tu8 key[AES_MAX_KEY_SIZE];\n\tlong enc;\n\tlong dec;\n\tint key_len;\n\tunion {\n\t\tstruct crypto_blkcipher *blk;\n\t\tstruct crypto_cipher *cip;\n\t} fallback;\n};\n\nstruct pcc_param {\n\tu8 key[32];\n\tu8 tweak[16];\n\tu8 block[16];\n\tu8 bit[16];\n\tu8 xts[16];\n};\n\nstruct s390_xts_ctx {\n\tu8 key[32];\n\tu8 pcc_key[32];\n\tlong enc;\n\tlong dec;\n\tint key_len;\n\tstruct crypto_blkcipher *fallback;\n};\n\n/*\n * Check if the key_len is supported by the HW.\n * Returns 0 if it is, a positive number if it is not and software fallback is\n * required or a negative number in case the key size is not valid\n */\nstatic int need_fallback(unsigned int key_len)\n{\n\tswitch (key_len) {\n\tcase 16:\n\t\tif (!(keylen_flag & AES_KEYLEN_128))\n\t\t\treturn 1;\n\t\tbreak;\n\tcase 24:\n\t\tif (!(keylen_flag & AES_KEYLEN_192))\n\t\t\treturn 1;\n\t\tbreak;\n\tcase 32:\n\t\tif (!(keylen_flag & AES_KEYLEN_256))\n\t\t\treturn 1;\n\t\tbreak;\n\tdefault:\n\t\treturn -1;\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic int setkey_fallback_cip(struct crypto_tfm *tfm, const u8 *in_key,\n\t\tunsigned int key_len)\n{\n\tstruct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\tint ret;\n\n\tsctx->fallback.cip->base.crt_flags &= ~CRYPTO_TFM_REQ_MASK;\n\tsctx->fallback.cip->base.crt_flags |= (tfm->crt_flags &\n\t\t\tCRYPTO_TFM_REQ_MASK);\n\n\tret = crypto_cipher_setkey(sctx->fallback.cip, in_key, key_len);\n\tif (ret) {\n\t\ttfm->crt_flags &= ~CRYPTO_TFM_RES_MASK;\n\t\ttfm->crt_flags |= (sctx->fallback.cip->base.crt_flags &\n\t\t\t\tCRYPTO_TFM_RES_MASK);\n\t}\n\treturn ret;\n}\n\nstatic int aes_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t       unsigned int key_len)\n{\n\tstruct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tint ret;\n\n\tret = need_fallback(key_len);\n\tif (ret < 0) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\tsctx->key_len = key_len;\n\tif (!ret) {\n\t\tmemcpy(sctx->key, in_key, key_len);\n\t\treturn 0;\n\t}\n\n\treturn setkey_fallback_cip(tfm, in_key, key_len);\n}\n\nstatic void aes_encrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tconst struct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\n\tif (unlikely(need_fallback(sctx->key_len))) {\n\t\tcrypto_cipher_encrypt_one(sctx->fallback.cip, out, in);\n\t\treturn;\n\t}\n\n\tswitch (sctx->key_len) {\n\tcase 16:\n\t\tcrypt_s390_km(KM_AES_128_ENCRYPT, &sctx->key, out, in,\n\t\t\t      AES_BLOCK_SIZE);\n\t\tbreak;\n\tcase 24:\n\t\tcrypt_s390_km(KM_AES_192_ENCRYPT, &sctx->key, out, in,\n\t\t\t      AES_BLOCK_SIZE);\n\t\tbreak;\n\tcase 32:\n\t\tcrypt_s390_km(KM_AES_256_ENCRYPT, &sctx->key, out, in,\n\t\t\t      AES_BLOCK_SIZE);\n\t\tbreak;\n\t}\n}\n\nstatic void aes_decrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tconst struct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\n\tif (unlikely(need_fallback(sctx->key_len))) {\n\t\tcrypto_cipher_decrypt_one(sctx->fallback.cip, out, in);\n\t\treturn;\n\t}\n\n\tswitch (sctx->key_len) {\n\tcase 16:\n\t\tcrypt_s390_km(KM_AES_128_DECRYPT, &sctx->key, out, in,\n\t\t\t      AES_BLOCK_SIZE);\n\t\tbreak;\n\tcase 24:\n\t\tcrypt_s390_km(KM_AES_192_DECRYPT, &sctx->key, out, in,\n\t\t\t      AES_BLOCK_SIZE);\n\t\tbreak;\n\tcase 32:\n\t\tcrypt_s390_km(KM_AES_256_DECRYPT, &sctx->key, out, in,\n\t\t\t      AES_BLOCK_SIZE);\n\t\tbreak;\n\t}\n}\n\nstatic int fallback_init_cip(struct crypto_tfm *tfm)\n{\n\tconst char *name = tfm->__crt_alg->cra_name;\n\tstruct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\n\tsctx->fallback.cip = crypto_alloc_cipher(name, 0,\n\t\t\tCRYPTO_ALG_ASYNC | CRYPTO_ALG_NEED_FALLBACK);\n\n\tif (IS_ERR(sctx->fallback.cip)) {\n\t\tpr_err(\"Allocating AES fallback algorithm %s failed\\n\",\n\t\t       name);\n\t\treturn PTR_ERR(sctx->fallback.cip);\n\t}\n\n\treturn 0;\n}\n\nstatic void fallback_exit_cip(struct crypto_tfm *tfm)\n{\n\tstruct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_cipher(sctx->fallback.cip);\n\tsctx->fallback.cip = NULL;\n}\n\nstatic struct crypto_alg aes_alg = {\n\t.cra_name\t\t=\t\"aes\",\n\t.cra_driver_name\t=\t\"aes-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER |\n\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t.cra_blocksize\t\t=\tAES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_aes_ctx),\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_init               =       fallback_init_cip,\n\t.cra_exit               =       fallback_exit_cip,\n\t.cra_u\t\t\t=\t{\n\t\t.cipher = {\n\t\t\t.cia_min_keysize\t=\tAES_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t=\tAES_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t=\taes_set_key,\n\t\t\t.cia_encrypt\t\t=\taes_encrypt,\n\t\t\t.cia_decrypt\t\t=\taes_decrypt,\n\t\t}\n\t}\n};\n\nstatic int setkey_fallback_blk(struct crypto_tfm *tfm, const u8 *key,\n\t\tunsigned int len)\n{\n\tstruct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\tunsigned int ret;\n\n\tsctx->fallback.blk->base.crt_flags &= ~CRYPTO_TFM_REQ_MASK;\n\tsctx->fallback.blk->base.crt_flags |= (tfm->crt_flags &\n\t\t\tCRYPTO_TFM_REQ_MASK);\n\n\tret = crypto_blkcipher_setkey(sctx->fallback.blk, key, len);\n\tif (ret) {\n\t\ttfm->crt_flags &= ~CRYPTO_TFM_RES_MASK;\n\t\ttfm->crt_flags |= (sctx->fallback.blk->base.crt_flags &\n\t\t\t\tCRYPTO_TFM_RES_MASK);\n\t}\n\treturn ret;\n}\n\nstatic int fallback_blk_dec(struct blkcipher_desc *desc,\n\t\tstruct scatterlist *dst, struct scatterlist *src,\n\t\tunsigned int nbytes)\n{\n\tunsigned int ret;\n\tstruct crypto_blkcipher *tfm;\n\tstruct s390_aes_ctx *sctx = crypto_blkcipher_ctx(desc->tfm);\n\n\ttfm = desc->tfm;\n\tdesc->tfm = sctx->fallback.blk;\n\n\tret = crypto_blkcipher_decrypt_iv(desc, dst, src, nbytes);\n\n\tdesc->tfm = tfm;\n\treturn ret;\n}\n\nstatic int fallback_blk_enc(struct blkcipher_desc *desc,\n\t\tstruct scatterlist *dst, struct scatterlist *src,\n\t\tunsigned int nbytes)\n{\n\tunsigned int ret;\n\tstruct crypto_blkcipher *tfm;\n\tstruct s390_aes_ctx *sctx = crypto_blkcipher_ctx(desc->tfm);\n\n\ttfm = desc->tfm;\n\tdesc->tfm = sctx->fallback.blk;\n\n\tret = crypto_blkcipher_encrypt_iv(desc, dst, src, nbytes);\n\n\tdesc->tfm = tfm;\n\treturn ret;\n}\n\nstatic int ecb_aes_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t\t   unsigned int key_len)\n{\n\tstruct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\tint ret;\n\n\tret = need_fallback(key_len);\n\tif (ret > 0) {\n\t\tsctx->key_len = key_len;\n\t\treturn setkey_fallback_blk(tfm, in_key, key_len);\n\t}\n\n\tswitch (key_len) {\n\tcase 16:\n\t\tsctx->enc = KM_AES_128_ENCRYPT;\n\t\tsctx->dec = KM_AES_128_DECRYPT;\n\t\tbreak;\n\tcase 24:\n\t\tsctx->enc = KM_AES_192_ENCRYPT;\n\t\tsctx->dec = KM_AES_192_DECRYPT;\n\t\tbreak;\n\tcase 32:\n\t\tsctx->enc = KM_AES_256_ENCRYPT;\n\t\tsctx->dec = KM_AES_256_DECRYPT;\n\t\tbreak;\n\t}\n\n\treturn aes_set_key(tfm, in_key, key_len);\n}\n\nstatic int ecb_aes_crypt(struct blkcipher_desc *desc, long func, void *param,\n\t\t\t struct blkcipher_walk *walk)\n{\n\tint ret = blkcipher_walk_virt(desc, walk);\n\tunsigned int nbytes;\n\n\twhile ((nbytes = walk->nbytes)) {\n\t\t/* only use complete blocks */\n\t\tunsigned int n = nbytes & ~(AES_BLOCK_SIZE - 1);\n\t\tu8 *out = walk->dst.virt.addr;\n\t\tu8 *in = walk->src.virt.addr;\n\n\t\tret = crypt_s390_km(func, param, out, in, n);\n\t\tif (ret < 0 || ret != n)\n\t\t\treturn -EIO;\n\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\tret = blkcipher_walk_done(desc, walk, nbytes);\n\t}\n\n\treturn ret;\n}\n\nstatic int ecb_aes_encrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_aes_ctx *sctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tif (unlikely(need_fallback(sctx->key_len)))\n\t\treturn fallback_blk_enc(desc, dst, src, nbytes);\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_aes_crypt(desc, sctx->enc, sctx->key, &walk);\n}\n\nstatic int ecb_aes_decrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_aes_ctx *sctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tif (unlikely(need_fallback(sctx->key_len)))\n\t\treturn fallback_blk_dec(desc, dst, src, nbytes);\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_aes_crypt(desc, sctx->dec, sctx->key, &walk);\n}\n\nstatic int fallback_init_blk(struct crypto_tfm *tfm)\n{\n\tconst char *name = tfm->__crt_alg->cra_name;\n\tstruct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\n\tsctx->fallback.blk = crypto_alloc_blkcipher(name, 0,\n\t\t\tCRYPTO_ALG_ASYNC | CRYPTO_ALG_NEED_FALLBACK);\n\n\tif (IS_ERR(sctx->fallback.blk)) {\n\t\tpr_err(\"Allocating AES fallback algorithm %s failed\\n\",\n\t\t       name);\n\t\treturn PTR_ERR(sctx->fallback.blk);\n\t}\n\n\treturn 0;\n}\n\nstatic void fallback_exit_blk(struct crypto_tfm *tfm)\n{\n\tstruct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_blkcipher(sctx->fallback.blk);\n\tsctx->fallback.blk = NULL;\n}\n\nstatic struct crypto_alg ecb_aes_alg = {\n\t.cra_name\t\t=\t\"ecb(aes)\",\n\t.cra_driver_name\t=\t\"ecb-aes-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER |\n\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t.cra_blocksize\t\t=\tAES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_aes_ctx),\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_init\t\t=\tfallback_init_blk,\n\t.cra_exit\t\t=\tfallback_exit_blk,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\tAES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\tAES_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t\t=\tecb_aes_set_key,\n\t\t\t.encrypt\t\t=\tecb_aes_encrypt,\n\t\t\t.decrypt\t\t=\tecb_aes_decrypt,\n\t\t}\n\t}\n};\n\nstatic int cbc_aes_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t\t   unsigned int key_len)\n{\n\tstruct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\tint ret;\n\n\tret = need_fallback(key_len);\n\tif (ret > 0) {\n\t\tsctx->key_len = key_len;\n\t\treturn setkey_fallback_blk(tfm, in_key, key_len);\n\t}\n\n\tswitch (key_len) {\n\tcase 16:\n\t\tsctx->enc = KMC_AES_128_ENCRYPT;\n\t\tsctx->dec = KMC_AES_128_DECRYPT;\n\t\tbreak;\n\tcase 24:\n\t\tsctx->enc = KMC_AES_192_ENCRYPT;\n\t\tsctx->dec = KMC_AES_192_DECRYPT;\n\t\tbreak;\n\tcase 32:\n\t\tsctx->enc = KMC_AES_256_ENCRYPT;\n\t\tsctx->dec = KMC_AES_256_DECRYPT;\n\t\tbreak;\n\t}\n\n\treturn aes_set_key(tfm, in_key, key_len);\n}\n\nstatic int cbc_aes_crypt(struct blkcipher_desc *desc, long func,\n\t\t\t struct blkcipher_walk *walk)\n{\n\tstruct s390_aes_ctx *sctx = crypto_blkcipher_ctx(desc->tfm);\n\tint ret = blkcipher_walk_virt(desc, walk);\n\tunsigned int nbytes = walk->nbytes;\n\tstruct {\n\t\tu8 iv[AES_BLOCK_SIZE];\n\t\tu8 key[AES_MAX_KEY_SIZE];\n\t} param;\n\n\tif (!nbytes)\n\t\tgoto out;\n\n\tmemcpy(param.iv, walk->iv, AES_BLOCK_SIZE);\n\tmemcpy(param.key, sctx->key, sctx->key_len);\n\tdo {\n\t\t/* only use complete blocks */\n\t\tunsigned int n = nbytes & ~(AES_BLOCK_SIZE - 1);\n\t\tu8 *out = walk->dst.virt.addr;\n\t\tu8 *in = walk->src.virt.addr;\n\n\t\tret = crypt_s390_kmc(func, &param, out, in, n);\n\t\tif (ret < 0 || ret != n)\n\t\t\treturn -EIO;\n\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\tret = blkcipher_walk_done(desc, walk, nbytes);\n\t} while ((nbytes = walk->nbytes));\n\tmemcpy(walk->iv, param.iv, AES_BLOCK_SIZE);\n\nout:\n\treturn ret;\n}\n\nstatic int cbc_aes_encrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_aes_ctx *sctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tif (unlikely(need_fallback(sctx->key_len)))\n\t\treturn fallback_blk_enc(desc, dst, src, nbytes);\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn cbc_aes_crypt(desc, sctx->enc, &walk);\n}\n\nstatic int cbc_aes_decrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_aes_ctx *sctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tif (unlikely(need_fallback(sctx->key_len)))\n\t\treturn fallback_blk_dec(desc, dst, src, nbytes);\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn cbc_aes_crypt(desc, sctx->dec, &walk);\n}\n\nstatic struct crypto_alg cbc_aes_alg = {\n\t.cra_name\t\t=\t\"cbc(aes)\",\n\t.cra_driver_name\t=\t\"cbc-aes-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER |\n\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t.cra_blocksize\t\t=\tAES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_aes_ctx),\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_init\t\t=\tfallback_init_blk,\n\t.cra_exit\t\t=\tfallback_exit_blk,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\tAES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\tAES_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t\t=\tAES_BLOCK_SIZE,\n\t\t\t.setkey\t\t\t=\tcbc_aes_set_key,\n\t\t\t.encrypt\t\t=\tcbc_aes_encrypt,\n\t\t\t.decrypt\t\t=\tcbc_aes_decrypt,\n\t\t}\n\t}\n};\n\nstatic int xts_fallback_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\t\t   unsigned int len)\n{\n\tstruct s390_xts_ctx *xts_ctx = crypto_tfm_ctx(tfm);\n\tunsigned int ret;\n\n\txts_ctx->fallback->base.crt_flags &= ~CRYPTO_TFM_REQ_MASK;\n\txts_ctx->fallback->base.crt_flags |= (tfm->crt_flags &\n\t\t\tCRYPTO_TFM_REQ_MASK);\n\n\tret = crypto_blkcipher_setkey(xts_ctx->fallback, key, len);\n\tif (ret) {\n\t\ttfm->crt_flags &= ~CRYPTO_TFM_RES_MASK;\n\t\ttfm->crt_flags |= (xts_ctx->fallback->base.crt_flags &\n\t\t\t\tCRYPTO_TFM_RES_MASK);\n\t}\n\treturn ret;\n}\n\nstatic int xts_fallback_decrypt(struct blkcipher_desc *desc,\n\t\tstruct scatterlist *dst, struct scatterlist *src,\n\t\tunsigned int nbytes)\n{\n\tstruct s390_xts_ctx *xts_ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct crypto_blkcipher *tfm;\n\tunsigned int ret;\n\n\ttfm = desc->tfm;\n\tdesc->tfm = xts_ctx->fallback;\n\n\tret = crypto_blkcipher_decrypt_iv(desc, dst, src, nbytes);\n\n\tdesc->tfm = tfm;\n\treturn ret;\n}\n\nstatic int xts_fallback_encrypt(struct blkcipher_desc *desc,\n\t\tstruct scatterlist *dst, struct scatterlist *src,\n\t\tunsigned int nbytes)\n{\n\tstruct s390_xts_ctx *xts_ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct crypto_blkcipher *tfm;\n\tunsigned int ret;\n\n\ttfm = desc->tfm;\n\tdesc->tfm = xts_ctx->fallback;\n\n\tret = crypto_blkcipher_encrypt_iv(desc, dst, src, nbytes);\n\n\tdesc->tfm = tfm;\n\treturn ret;\n}\n\nstatic int xts_aes_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t\t   unsigned int key_len)\n{\n\tstruct s390_xts_ctx *xts_ctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\n\tswitch (key_len) {\n\tcase 32:\n\t\txts_ctx->enc = KM_XTS_128_ENCRYPT;\n\t\txts_ctx->dec = KM_XTS_128_DECRYPT;\n\t\tmemcpy(xts_ctx->key + 16, in_key, 16);\n\t\tmemcpy(xts_ctx->pcc_key + 16, in_key + 16, 16);\n\t\tbreak;\n\tcase 48:\n\t\txts_ctx->enc = 0;\n\t\txts_ctx->dec = 0;\n\t\txts_fallback_setkey(tfm, in_key, key_len);\n\t\tbreak;\n\tcase 64:\n\t\txts_ctx->enc = KM_XTS_256_ENCRYPT;\n\t\txts_ctx->dec = KM_XTS_256_DECRYPT;\n\t\tmemcpy(xts_ctx->key, in_key, 32);\n\t\tmemcpy(xts_ctx->pcc_key, in_key + 32, 32);\n\t\tbreak;\n\tdefault:\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\txts_ctx->key_len = key_len;\n\treturn 0;\n}\n\nstatic int xts_aes_crypt(struct blkcipher_desc *desc, long func,\n\t\t\t struct s390_xts_ctx *xts_ctx,\n\t\t\t struct blkcipher_walk *walk)\n{\n\tunsigned int offset = (xts_ctx->key_len >> 1) & 0x10;\n\tint ret = blkcipher_walk_virt(desc, walk);\n\tunsigned int nbytes = walk->nbytes;\n\tunsigned int n;\n\tu8 *in, *out;\n\tstruct pcc_param pcc_param;\n\tstruct {\n\t\tu8 key[32];\n\t\tu8 init[16];\n\t} xts_param;\n\n\tif (!nbytes)\n\t\tgoto out;\n\n\tmemset(pcc_param.block, 0, sizeof(pcc_param.block));\n\tmemset(pcc_param.bit, 0, sizeof(pcc_param.bit));\n\tmemset(pcc_param.xts, 0, sizeof(pcc_param.xts));\n\tmemcpy(pcc_param.tweak, walk->iv, sizeof(pcc_param.tweak));\n\tmemcpy(pcc_param.key, xts_ctx->pcc_key, 32);\n\tret = crypt_s390_pcc(func, &pcc_param.key[offset]);\n\tif (ret < 0)\n\t\treturn -EIO;\n\n\tmemcpy(xts_param.key, xts_ctx->key, 32);\n\tmemcpy(xts_param.init, pcc_param.xts, 16);\n\tdo {\n\t\t/* only use complete blocks */\n\t\tn = nbytes & ~(AES_BLOCK_SIZE - 1);\n\t\tout = walk->dst.virt.addr;\n\t\tin = walk->src.virt.addr;\n\n\t\tret = crypt_s390_km(func, &xts_param.key[offset], out, in, n);\n\t\tif (ret < 0 || ret != n)\n\t\t\treturn -EIO;\n\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\tret = blkcipher_walk_done(desc, walk, nbytes);\n\t} while ((nbytes = walk->nbytes));\nout:\n\treturn ret;\n}\n\nstatic int xts_aes_encrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_xts_ctx *xts_ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tif (unlikely(xts_ctx->key_len == 48))\n\t\treturn xts_fallback_encrypt(desc, dst, src, nbytes);\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn xts_aes_crypt(desc, xts_ctx->enc, xts_ctx, &walk);\n}\n\nstatic int xts_aes_decrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_xts_ctx *xts_ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tif (unlikely(xts_ctx->key_len == 48))\n\t\treturn xts_fallback_decrypt(desc, dst, src, nbytes);\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn xts_aes_crypt(desc, xts_ctx->dec, xts_ctx, &walk);\n}\n\nstatic int xts_fallback_init(struct crypto_tfm *tfm)\n{\n\tconst char *name = tfm->__crt_alg->cra_name;\n\tstruct s390_xts_ctx *xts_ctx = crypto_tfm_ctx(tfm);\n\n\txts_ctx->fallback = crypto_alloc_blkcipher(name, 0,\n\t\t\tCRYPTO_ALG_ASYNC | CRYPTO_ALG_NEED_FALLBACK);\n\n\tif (IS_ERR(xts_ctx->fallback)) {\n\t\tpr_err(\"Allocating XTS fallback algorithm %s failed\\n\",\n\t\t       name);\n\t\treturn PTR_ERR(xts_ctx->fallback);\n\t}\n\treturn 0;\n}\n\nstatic void xts_fallback_exit(struct crypto_tfm *tfm)\n{\n\tstruct s390_xts_ctx *xts_ctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_blkcipher(xts_ctx->fallback);\n\txts_ctx->fallback = NULL;\n}\n\nstatic struct crypto_alg xts_aes_alg = {\n\t.cra_name\t\t=\t\"xts(aes)\",\n\t.cra_driver_name\t=\t\"xts-aes-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER |\n\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t.cra_blocksize\t\t=\tAES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_xts_ctx),\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_init\t\t=\txts_fallback_init,\n\t.cra_exit\t\t=\txts_fallback_exit,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\t2 * AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\t2 * AES_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t\t=\tAES_BLOCK_SIZE,\n\t\t\t.setkey\t\t\t=\txts_aes_set_key,\n\t\t\t.encrypt\t\t=\txts_aes_encrypt,\n\t\t\t.decrypt\t\t=\txts_aes_decrypt,\n\t\t}\n\t}\n};\n\nstatic int xts_aes_alg_reg;\n\nstatic int ctr_aes_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t\t   unsigned int key_len)\n{\n\tstruct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\n\tswitch (key_len) {\n\tcase 16:\n\t\tsctx->enc = KMCTR_AES_128_ENCRYPT;\n\t\tsctx->dec = KMCTR_AES_128_DECRYPT;\n\t\tbreak;\n\tcase 24:\n\t\tsctx->enc = KMCTR_AES_192_ENCRYPT;\n\t\tsctx->dec = KMCTR_AES_192_DECRYPT;\n\t\tbreak;\n\tcase 32:\n\t\tsctx->enc = KMCTR_AES_256_ENCRYPT;\n\t\tsctx->dec = KMCTR_AES_256_DECRYPT;\n\t\tbreak;\n\t}\n\n\treturn aes_set_key(tfm, in_key, key_len);\n}\n\nstatic unsigned int __ctrblk_init(u8 *ctrptr, unsigned int nbytes)\n{\n\tunsigned int i, n;\n\n\t/* only use complete blocks, max. PAGE_SIZE */\n\tn = (nbytes > PAGE_SIZE) ? PAGE_SIZE : nbytes & ~(AES_BLOCK_SIZE - 1);\n\tfor (i = AES_BLOCK_SIZE; i < n; i += AES_BLOCK_SIZE) {\n\t\tmemcpy(ctrptr + i, ctrptr + i - AES_BLOCK_SIZE,\n\t\t       AES_BLOCK_SIZE);\n\t\tcrypto_inc(ctrptr + i, AES_BLOCK_SIZE);\n\t}\n\treturn n;\n}\n\nstatic int ctr_aes_crypt(struct blkcipher_desc *desc, long func,\n\t\t\t struct s390_aes_ctx *sctx, struct blkcipher_walk *walk)\n{\n\tint ret = blkcipher_walk_virt_block(desc, walk, AES_BLOCK_SIZE);\n\tunsigned int n, nbytes;\n\tu8 buf[AES_BLOCK_SIZE], ctrbuf[AES_BLOCK_SIZE];\n\tu8 *out, *in, *ctrptr = ctrbuf;\n\n\tif (!walk->nbytes)\n\t\treturn ret;\n\n\tif (spin_trylock(&ctrblk_lock))\n\t\tctrptr = ctrblk;\n\n\tmemcpy(ctrptr, walk->iv, AES_BLOCK_SIZE);\n\twhile ((nbytes = walk->nbytes) >= AES_BLOCK_SIZE) {\n\t\tout = walk->dst.virt.addr;\n\t\tin = walk->src.virt.addr;\n\t\twhile (nbytes >= AES_BLOCK_SIZE) {\n\t\t\tif (ctrptr == ctrblk)\n\t\t\t\tn = __ctrblk_init(ctrptr, nbytes);\n\t\t\telse\n\t\t\t\tn = AES_BLOCK_SIZE;\n\t\t\tret = crypt_s390_kmctr(func, sctx->key, out, in,\n\t\t\t\t\t       n, ctrptr);\n\t\t\tif (ret < 0 || ret != n) {\n\t\t\t\tif (ctrptr == ctrblk)\n\t\t\t\t\tspin_unlock(&ctrblk_lock);\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t\tif (n > AES_BLOCK_SIZE)\n\t\t\t\tmemcpy(ctrptr, ctrptr + n - AES_BLOCK_SIZE,\n\t\t\t\t       AES_BLOCK_SIZE);\n\t\t\tcrypto_inc(ctrptr, AES_BLOCK_SIZE);\n\t\t\tout += n;\n\t\t\tin += n;\n\t\t\tnbytes -= n;\n\t\t}\n\t\tret = blkcipher_walk_done(desc, walk, nbytes);\n\t}\n\tif (ctrptr == ctrblk) {\n\t\tif (nbytes)\n\t\t\tmemcpy(ctrbuf, ctrptr, AES_BLOCK_SIZE);\n\t\telse\n\t\t\tmemcpy(walk->iv, ctrptr, AES_BLOCK_SIZE);\n\t\tspin_unlock(&ctrblk_lock);\n\t} else {\n\t\tif (!nbytes)\n\t\t\tmemcpy(walk->iv, ctrptr, AES_BLOCK_SIZE);\n\t}\n\t/*\n\t * final block may be < AES_BLOCK_SIZE, copy only nbytes\n\t */\n\tif (nbytes) {\n\t\tout = walk->dst.virt.addr;\n\t\tin = walk->src.virt.addr;\n\t\tret = crypt_s390_kmctr(func, sctx->key, buf, in,\n\t\t\t\t       AES_BLOCK_SIZE, ctrbuf);\n\t\tif (ret < 0 || ret != AES_BLOCK_SIZE)\n\t\t\treturn -EIO;\n\t\tmemcpy(out, buf, nbytes);\n\t\tcrypto_inc(ctrbuf, AES_BLOCK_SIZE);\n\t\tret = blkcipher_walk_done(desc, walk, 0);\n\t\tmemcpy(walk->iv, ctrbuf, AES_BLOCK_SIZE);\n\t}\n\n\treturn ret;\n}\n\nstatic int ctr_aes_encrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_aes_ctx *sctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ctr_aes_crypt(desc, sctx->enc, sctx, &walk);\n}\n\nstatic int ctr_aes_decrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_aes_ctx *sctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ctr_aes_crypt(desc, sctx->dec, sctx, &walk);\n}\n\nstatic struct crypto_alg ctr_aes_alg = {\n\t.cra_name\t\t=\t\"ctr(aes)\",\n\t.cra_driver_name\t=\t\"ctr-aes-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t=\t1,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_aes_ctx),\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\tAES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\tAES_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t\t=\tAES_BLOCK_SIZE,\n\t\t\t.setkey\t\t\t=\tctr_aes_set_key,\n\t\t\t.encrypt\t\t=\tctr_aes_encrypt,\n\t\t\t.decrypt\t\t=\tctr_aes_decrypt,\n\t\t}\n\t}\n};\n\nstatic int ctr_aes_alg_reg;\n\nstatic int __init aes_s390_init(void)\n{\n\tint ret;\n\n\tif (crypt_s390_func_available(KM_AES_128_ENCRYPT, CRYPT_S390_MSA))\n\t\tkeylen_flag |= AES_KEYLEN_128;\n\tif (crypt_s390_func_available(KM_AES_192_ENCRYPT, CRYPT_S390_MSA))\n\t\tkeylen_flag |= AES_KEYLEN_192;\n\tif (crypt_s390_func_available(KM_AES_256_ENCRYPT, CRYPT_S390_MSA))\n\t\tkeylen_flag |= AES_KEYLEN_256;\n\n\tif (!keylen_flag)\n\t\treturn -EOPNOTSUPP;\n\n\t/* z9 109 and z9 BC/EC only support 128 bit key length */\n\tif (keylen_flag == AES_KEYLEN_128)\n\t\tpr_info(\"AES hardware acceleration is only available for\"\n\t\t\t\" 128-bit keys\\n\");\n\n\tret = crypto_register_alg(&aes_alg);\n\tif (ret)\n\t\tgoto aes_err;\n\n\tret = crypto_register_alg(&ecb_aes_alg);\n\tif (ret)\n\t\tgoto ecb_aes_err;\n\n\tret = crypto_register_alg(&cbc_aes_alg);\n\tif (ret)\n\t\tgoto cbc_aes_err;\n\n\tif (crypt_s390_func_available(KM_XTS_128_ENCRYPT,\n\t\t\tCRYPT_S390_MSA | CRYPT_S390_MSA4) &&\n\t    crypt_s390_func_available(KM_XTS_256_ENCRYPT,\n\t\t\tCRYPT_S390_MSA | CRYPT_S390_MSA4)) {\n\t\tret = crypto_register_alg(&xts_aes_alg);\n\t\tif (ret)\n\t\t\tgoto xts_aes_err;\n\t\txts_aes_alg_reg = 1;\n\t}\n\n\tif (crypt_s390_func_available(KMCTR_AES_128_ENCRYPT,\n\t\t\t\tCRYPT_S390_MSA | CRYPT_S390_MSA4) &&\n\t    crypt_s390_func_available(KMCTR_AES_192_ENCRYPT,\n\t\t\t\tCRYPT_S390_MSA | CRYPT_S390_MSA4) &&\n\t    crypt_s390_func_available(KMCTR_AES_256_ENCRYPT,\n\t\t\t\tCRYPT_S390_MSA | CRYPT_S390_MSA4)) {\n\t\tctrblk = (u8 *) __get_free_page(GFP_KERNEL);\n\t\tif (!ctrblk) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto ctr_aes_err;\n\t\t}\n\t\tret = crypto_register_alg(&ctr_aes_alg);\n\t\tif (ret) {\n\t\t\tfree_page((unsigned long) ctrblk);\n\t\t\tgoto ctr_aes_err;\n\t\t}\n\t\tctr_aes_alg_reg = 1;\n\t}\n\nout:\n\treturn ret;\n\nctr_aes_err:\n\tcrypto_unregister_alg(&xts_aes_alg);\nxts_aes_err:\n\tcrypto_unregister_alg(&cbc_aes_alg);\ncbc_aes_err:\n\tcrypto_unregister_alg(&ecb_aes_alg);\necb_aes_err:\n\tcrypto_unregister_alg(&aes_alg);\naes_err:\n\tgoto out;\n}\n\nstatic void __exit aes_s390_fini(void)\n{\n\tif (ctr_aes_alg_reg) {\n\t\tcrypto_unregister_alg(&ctr_aes_alg);\n\t\tfree_page((unsigned long) ctrblk);\n\t}\n\tif (xts_aes_alg_reg)\n\t\tcrypto_unregister_alg(&xts_aes_alg);\n\tcrypto_unregister_alg(&cbc_aes_alg);\n\tcrypto_unregister_alg(&ecb_aes_alg);\n\tcrypto_unregister_alg(&aes_alg);\n}\n\nmodule_init(aes_s390_init);\nmodule_exit(aes_s390_fini);\n\nMODULE_ALIAS(\"aes-all\");\n\nMODULE_DESCRIPTION(\"Rijndael (AES) Cipher Algorithm\");\nMODULE_LICENSE(\"GPL\");\n", "/*\n * Cryptographic API.\n *\n * s390 implementation of the DES Cipher Algorithm.\n *\n * Copyright IBM Corp. 2003, 2011\n * Author(s): Thomas Spatzier\n *\t      Jan Glauber (jan.glauber@de.ibm.com)\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/crypto.h>\n#include <crypto/algapi.h>\n#include <crypto/des.h>\n\n#include \"crypt_s390.h\"\n\n#define DES3_KEY_SIZE\t(3 * DES_KEY_SIZE)\n\nstatic u8 *ctrblk;\nstatic DEFINE_SPINLOCK(ctrblk_lock);\n\nstruct s390_des_ctx {\n\tu8 iv[DES_BLOCK_SIZE];\n\tu8 key[DES3_KEY_SIZE];\n};\n\nstatic int des_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t      unsigned int key_len)\n{\n\tstruct s390_des_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tu32 tmp[DES_EXPKEY_WORDS];\n\n\t/* check for weak keys */\n\tif (!des_ekey(tmp, key) && (*flags & CRYPTO_TFM_REQ_WEAK_KEY)) {\n\t\t*flags |= CRYPTO_TFM_RES_WEAK_KEY;\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(ctx->key, key, key_len);\n\treturn 0;\n}\n\nstatic void des_encrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tstruct s390_des_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypt_s390_km(KM_DEA_ENCRYPT, ctx->key, out, in, DES_BLOCK_SIZE);\n}\n\nstatic void des_decrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tstruct s390_des_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypt_s390_km(KM_DEA_DECRYPT, ctx->key, out, in, DES_BLOCK_SIZE);\n}\n\nstatic struct crypto_alg des_alg = {\n\t.cra_name\t\t=\t\"des\",\n\t.cra_driver_name\t=\t\"des-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tDES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_des_ctx),\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.cipher = {\n\t\t\t.cia_min_keysize\t=\tDES_KEY_SIZE,\n\t\t\t.cia_max_keysize\t=\tDES_KEY_SIZE,\n\t\t\t.cia_setkey\t\t=\tdes_setkey,\n\t\t\t.cia_encrypt\t\t=\tdes_encrypt,\n\t\t\t.cia_decrypt\t\t=\tdes_decrypt,\n\t\t}\n\t}\n};\n\nstatic int ecb_desall_crypt(struct blkcipher_desc *desc, long func,\n\t\t\t    u8 *key, struct blkcipher_walk *walk)\n{\n\tint ret = blkcipher_walk_virt(desc, walk);\n\tunsigned int nbytes;\n\n\twhile ((nbytes = walk->nbytes)) {\n\t\t/* only use complete blocks */\n\t\tunsigned int n = nbytes & ~(DES_BLOCK_SIZE - 1);\n\t\tu8 *out = walk->dst.virt.addr;\n\t\tu8 *in = walk->src.virt.addr;\n\n\t\tret = crypt_s390_km(func, key, out, in, n);\n\t\tif (ret < 0 || ret != n)\n\t\t\treturn -EIO;\n\n\t\tnbytes &= DES_BLOCK_SIZE - 1;\n\t\tret = blkcipher_walk_done(desc, walk, nbytes);\n\t}\n\n\treturn ret;\n}\n\nstatic int cbc_desall_crypt(struct blkcipher_desc *desc, long func,\n\t\t\t    struct blkcipher_walk *walk)\n{\n\tstruct s390_des_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tint ret = blkcipher_walk_virt(desc, walk);\n\tunsigned int nbytes = walk->nbytes;\n\tstruct {\n\t\tu8 iv[DES_BLOCK_SIZE];\n\t\tu8 key[DES3_KEY_SIZE];\n\t} param;\n\n\tif (!nbytes)\n\t\tgoto out;\n\n\tmemcpy(param.iv, walk->iv, DES_BLOCK_SIZE);\n\tmemcpy(param.key, ctx->key, DES3_KEY_SIZE);\n\tdo {\n\t\t/* only use complete blocks */\n\t\tunsigned int n = nbytes & ~(DES_BLOCK_SIZE - 1);\n\t\tu8 *out = walk->dst.virt.addr;\n\t\tu8 *in = walk->src.virt.addr;\n\n\t\tret = crypt_s390_kmc(func, &param, out, in, n);\n\t\tif (ret < 0 || ret != n)\n\t\t\treturn -EIO;\n\n\t\tnbytes &= DES_BLOCK_SIZE - 1;\n\t\tret = blkcipher_walk_done(desc, walk, nbytes);\n\t} while ((nbytes = walk->nbytes));\n\tmemcpy(walk->iv, param.iv, DES_BLOCK_SIZE);\n\nout:\n\treturn ret;\n}\n\nstatic int ecb_des_encrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_des_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_desall_crypt(desc, KM_DEA_ENCRYPT, ctx->key, &walk);\n}\n\nstatic int ecb_des_decrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_des_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_desall_crypt(desc, KM_DEA_DECRYPT, ctx->key, &walk);\n}\n\nstatic struct crypto_alg ecb_des_alg = {\n\t.cra_name\t\t=\t\"ecb(des)\",\n\t.cra_driver_name\t=\t\"ecb-des-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t=\tDES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_des_ctx),\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\tDES_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\tDES_KEY_SIZE,\n\t\t\t.setkey\t\t\t=\tdes_setkey,\n\t\t\t.encrypt\t\t=\tecb_des_encrypt,\n\t\t\t.decrypt\t\t=\tecb_des_decrypt,\n\t\t}\n\t}\n};\n\nstatic int cbc_des_encrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn cbc_desall_crypt(desc, KMC_DEA_ENCRYPT, &walk);\n}\n\nstatic int cbc_des_decrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn cbc_desall_crypt(desc, KMC_DEA_DECRYPT, &walk);\n}\n\nstatic struct crypto_alg cbc_des_alg = {\n\t.cra_name\t\t=\t\"cbc(des)\",\n\t.cra_driver_name\t=\t\"cbc-des-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t=\tDES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_des_ctx),\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\tDES_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\tDES_KEY_SIZE,\n\t\t\t.ivsize\t\t\t=\tDES_BLOCK_SIZE,\n\t\t\t.setkey\t\t\t=\tdes_setkey,\n\t\t\t.encrypt\t\t=\tcbc_des_encrypt,\n\t\t\t.decrypt\t\t=\tcbc_des_decrypt,\n\t\t}\n\t}\n};\n\n/*\n * RFC2451:\n *\n *   For DES-EDE3, there is no known need to reject weak or\n *   complementation keys.  Any weakness is obviated by the use of\n *   multiple keys.\n *\n *   However, if the first two or last two independent 64-bit keys are\n *   equal (k1 == k2 or k2 == k3), then the DES3 operation is simply the\n *   same as DES.  Implementers MUST reject keys that exhibit this\n *   property.\n *\n */\nstatic int des3_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t       unsigned int key_len)\n{\n\tstruct s390_des_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\n\tif (!(crypto_memneq(key, &key[DES_KEY_SIZE], DES_KEY_SIZE) &&\n\t    crypto_memneq(&key[DES_KEY_SIZE], &key[DES_KEY_SIZE * 2],\n\t\t\t  DES_KEY_SIZE)) &&\n\t    (*flags & CRYPTO_TFM_REQ_WEAK_KEY)) {\n\t\t*flags |= CRYPTO_TFM_RES_WEAK_KEY;\n\t\treturn -EINVAL;\n\t}\n\tmemcpy(ctx->key, key, key_len);\n\treturn 0;\n}\n\nstatic void des3_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct s390_des_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypt_s390_km(KM_TDEA_192_ENCRYPT, ctx->key, dst, src, DES_BLOCK_SIZE);\n}\n\nstatic void des3_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct s390_des_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypt_s390_km(KM_TDEA_192_DECRYPT, ctx->key, dst, src, DES_BLOCK_SIZE);\n}\n\nstatic struct crypto_alg des3_alg = {\n\t.cra_name\t\t=\t\"des3_ede\",\n\t.cra_driver_name\t=\t\"des3_ede-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tDES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_des_ctx),\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.cipher = {\n\t\t\t.cia_min_keysize\t=\tDES3_KEY_SIZE,\n\t\t\t.cia_max_keysize\t=\tDES3_KEY_SIZE,\n\t\t\t.cia_setkey\t\t=\tdes3_setkey,\n\t\t\t.cia_encrypt\t\t=\tdes3_encrypt,\n\t\t\t.cia_decrypt\t\t=\tdes3_decrypt,\n\t\t}\n\t}\n};\n\nstatic int ecb_des3_encrypt(struct blkcipher_desc *desc,\n\t\t\t    struct scatterlist *dst, struct scatterlist *src,\n\t\t\t    unsigned int nbytes)\n{\n\tstruct s390_des_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_desall_crypt(desc, KM_TDEA_192_ENCRYPT, ctx->key, &walk);\n}\n\nstatic int ecb_des3_decrypt(struct blkcipher_desc *desc,\n\t\t\t    struct scatterlist *dst, struct scatterlist *src,\n\t\t\t    unsigned int nbytes)\n{\n\tstruct s390_des_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_desall_crypt(desc, KM_TDEA_192_DECRYPT, ctx->key, &walk);\n}\n\nstatic struct crypto_alg ecb_des3_alg = {\n\t.cra_name\t\t=\t\"ecb(des3_ede)\",\n\t.cra_driver_name\t=\t\"ecb-des3_ede-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t=\tDES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_des_ctx),\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\tDES3_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\tDES3_KEY_SIZE,\n\t\t\t.setkey\t\t\t=\tdes3_setkey,\n\t\t\t.encrypt\t\t=\tecb_des3_encrypt,\n\t\t\t.decrypt\t\t=\tecb_des3_decrypt,\n\t\t}\n\t}\n};\n\nstatic int cbc_des3_encrypt(struct blkcipher_desc *desc,\n\t\t\t    struct scatterlist *dst, struct scatterlist *src,\n\t\t\t    unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn cbc_desall_crypt(desc, KMC_TDEA_192_ENCRYPT, &walk);\n}\n\nstatic int cbc_des3_decrypt(struct blkcipher_desc *desc,\n\t\t\t    struct scatterlist *dst, struct scatterlist *src,\n\t\t\t    unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn cbc_desall_crypt(desc, KMC_TDEA_192_DECRYPT, &walk);\n}\n\nstatic struct crypto_alg cbc_des3_alg = {\n\t.cra_name\t\t=\t\"cbc(des3_ede)\",\n\t.cra_driver_name\t=\t\"cbc-des3_ede-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t=\tDES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_des_ctx),\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\tDES3_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\tDES3_KEY_SIZE,\n\t\t\t.ivsize\t\t\t=\tDES_BLOCK_SIZE,\n\t\t\t.setkey\t\t\t=\tdes3_setkey,\n\t\t\t.encrypt\t\t=\tcbc_des3_encrypt,\n\t\t\t.decrypt\t\t=\tcbc_des3_decrypt,\n\t\t}\n\t}\n};\n\nstatic unsigned int __ctrblk_init(u8 *ctrptr, unsigned int nbytes)\n{\n\tunsigned int i, n;\n\n\t/* align to block size, max. PAGE_SIZE */\n\tn = (nbytes > PAGE_SIZE) ? PAGE_SIZE : nbytes & ~(DES_BLOCK_SIZE - 1);\n\tfor (i = DES_BLOCK_SIZE; i < n; i += DES_BLOCK_SIZE) {\n\t\tmemcpy(ctrptr + i, ctrptr + i - DES_BLOCK_SIZE, DES_BLOCK_SIZE);\n\t\tcrypto_inc(ctrptr + i, DES_BLOCK_SIZE);\n\t}\n\treturn n;\n}\n\nstatic int ctr_desall_crypt(struct blkcipher_desc *desc, long func,\n\t\t\t    struct s390_des_ctx *ctx,\n\t\t\t    struct blkcipher_walk *walk)\n{\n\tint ret = blkcipher_walk_virt_block(desc, walk, DES_BLOCK_SIZE);\n\tunsigned int n, nbytes;\n\tu8 buf[DES_BLOCK_SIZE], ctrbuf[DES_BLOCK_SIZE];\n\tu8 *out, *in, *ctrptr = ctrbuf;\n\n\tif (!walk->nbytes)\n\t\treturn ret;\n\n\tif (spin_trylock(&ctrblk_lock))\n\t\tctrptr = ctrblk;\n\n\tmemcpy(ctrptr, walk->iv, DES_BLOCK_SIZE);\n\twhile ((nbytes = walk->nbytes) >= DES_BLOCK_SIZE) {\n\t\tout = walk->dst.virt.addr;\n\t\tin = walk->src.virt.addr;\n\t\twhile (nbytes >= DES_BLOCK_SIZE) {\n\t\t\tif (ctrptr == ctrblk)\n\t\t\t\tn = __ctrblk_init(ctrptr, nbytes);\n\t\t\telse\n\t\t\t\tn = DES_BLOCK_SIZE;\n\t\t\tret = crypt_s390_kmctr(func, ctx->key, out, in,\n\t\t\t\t\t       n, ctrptr);\n\t\t\tif (ret < 0 || ret != n) {\n\t\t\t\tif (ctrptr == ctrblk)\n\t\t\t\t\tspin_unlock(&ctrblk_lock);\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t\tif (n > DES_BLOCK_SIZE)\n\t\t\t\tmemcpy(ctrptr, ctrptr + n - DES_BLOCK_SIZE,\n\t\t\t\t       DES_BLOCK_SIZE);\n\t\t\tcrypto_inc(ctrptr, DES_BLOCK_SIZE);\n\t\t\tout += n;\n\t\t\tin += n;\n\t\t\tnbytes -= n;\n\t\t}\n\t\tret = blkcipher_walk_done(desc, walk, nbytes);\n\t}\n\tif (ctrptr == ctrblk) {\n\t\tif (nbytes)\n\t\t\tmemcpy(ctrbuf, ctrptr, DES_BLOCK_SIZE);\n\t\telse\n\t\t\tmemcpy(walk->iv, ctrptr, DES_BLOCK_SIZE);\n\t\tspin_unlock(&ctrblk_lock);\n\t} else {\n\t\tif (!nbytes)\n\t\t\tmemcpy(walk->iv, ctrptr, DES_BLOCK_SIZE);\n\t}\n\t/* final block may be < DES_BLOCK_SIZE, copy only nbytes */\n\tif (nbytes) {\n\t\tout = walk->dst.virt.addr;\n\t\tin = walk->src.virt.addr;\n\t\tret = crypt_s390_kmctr(func, ctx->key, buf, in,\n\t\t\t\t       DES_BLOCK_SIZE, ctrbuf);\n\t\tif (ret < 0 || ret != DES_BLOCK_SIZE)\n\t\t\treturn -EIO;\n\t\tmemcpy(out, buf, nbytes);\n\t\tcrypto_inc(ctrbuf, DES_BLOCK_SIZE);\n\t\tret = blkcipher_walk_done(desc, walk, 0);\n\t\tmemcpy(walk->iv, ctrbuf, DES_BLOCK_SIZE);\n\t}\n\treturn ret;\n}\n\nstatic int ctr_des_encrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_des_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ctr_desall_crypt(desc, KMCTR_DEA_ENCRYPT, ctx, &walk);\n}\n\nstatic int ctr_des_decrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_des_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ctr_desall_crypt(desc, KMCTR_DEA_DECRYPT, ctx, &walk);\n}\n\nstatic struct crypto_alg ctr_des_alg = {\n\t.cra_name\t\t=\t\"ctr(des)\",\n\t.cra_driver_name\t=\t\"ctr-des-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t=\t1,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_des_ctx),\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\tDES_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\tDES_KEY_SIZE,\n\t\t\t.ivsize\t\t\t=\tDES_BLOCK_SIZE,\n\t\t\t.setkey\t\t\t=\tdes_setkey,\n\t\t\t.encrypt\t\t=\tctr_des_encrypt,\n\t\t\t.decrypt\t\t=\tctr_des_decrypt,\n\t\t}\n\t}\n};\n\nstatic int ctr_des3_encrypt(struct blkcipher_desc *desc,\n\t\t\t    struct scatterlist *dst, struct scatterlist *src,\n\t\t\t    unsigned int nbytes)\n{\n\tstruct s390_des_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ctr_desall_crypt(desc, KMCTR_TDEA_192_ENCRYPT, ctx, &walk);\n}\n\nstatic int ctr_des3_decrypt(struct blkcipher_desc *desc,\n\t\t\t    struct scatterlist *dst, struct scatterlist *src,\n\t\t\t    unsigned int nbytes)\n{\n\tstruct s390_des_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ctr_desall_crypt(desc, KMCTR_TDEA_192_DECRYPT, ctx, &walk);\n}\n\nstatic struct crypto_alg ctr_des3_alg = {\n\t.cra_name\t\t=\t\"ctr(des3_ede)\",\n\t.cra_driver_name\t=\t\"ctr-des3_ede-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t=\t1,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_des_ctx),\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\tDES3_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\tDES3_KEY_SIZE,\n\t\t\t.ivsize\t\t\t=\tDES_BLOCK_SIZE,\n\t\t\t.setkey\t\t\t=\tdes3_setkey,\n\t\t\t.encrypt\t\t=\tctr_des3_encrypt,\n\t\t\t.decrypt\t\t=\tctr_des3_decrypt,\n\t\t}\n\t}\n};\n\nstatic int __init des_s390_init(void)\n{\n\tint ret;\n\n\tif (!crypt_s390_func_available(KM_DEA_ENCRYPT, CRYPT_S390_MSA) ||\n\t    !crypt_s390_func_available(KM_TDEA_192_ENCRYPT, CRYPT_S390_MSA))\n\t\treturn -EOPNOTSUPP;\n\n\tret = crypto_register_alg(&des_alg);\n\tif (ret)\n\t\tgoto des_err;\n\tret = crypto_register_alg(&ecb_des_alg);\n\tif (ret)\n\t\tgoto ecb_des_err;\n\tret = crypto_register_alg(&cbc_des_alg);\n\tif (ret)\n\t\tgoto cbc_des_err;\n\tret = crypto_register_alg(&des3_alg);\n\tif (ret)\n\t\tgoto des3_err;\n\tret = crypto_register_alg(&ecb_des3_alg);\n\tif (ret)\n\t\tgoto ecb_des3_err;\n\tret = crypto_register_alg(&cbc_des3_alg);\n\tif (ret)\n\t\tgoto cbc_des3_err;\n\n\tif (crypt_s390_func_available(KMCTR_DEA_ENCRYPT,\n\t\t\tCRYPT_S390_MSA | CRYPT_S390_MSA4) &&\n\t    crypt_s390_func_available(KMCTR_TDEA_192_ENCRYPT,\n\t\t\tCRYPT_S390_MSA | CRYPT_S390_MSA4)) {\n\t\tret = crypto_register_alg(&ctr_des_alg);\n\t\tif (ret)\n\t\t\tgoto ctr_des_err;\n\t\tret = crypto_register_alg(&ctr_des3_alg);\n\t\tif (ret)\n\t\t\tgoto ctr_des3_err;\n\t\tctrblk = (u8 *) __get_free_page(GFP_KERNEL);\n\t\tif (!ctrblk) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto ctr_mem_err;\n\t\t}\n\t}\nout:\n\treturn ret;\n\nctr_mem_err:\n\tcrypto_unregister_alg(&ctr_des3_alg);\nctr_des3_err:\n\tcrypto_unregister_alg(&ctr_des_alg);\nctr_des_err:\n\tcrypto_unregister_alg(&cbc_des3_alg);\ncbc_des3_err:\n\tcrypto_unregister_alg(&ecb_des3_alg);\necb_des3_err:\n\tcrypto_unregister_alg(&des3_alg);\ndes3_err:\n\tcrypto_unregister_alg(&cbc_des_alg);\ncbc_des_err:\n\tcrypto_unregister_alg(&ecb_des_alg);\necb_des_err:\n\tcrypto_unregister_alg(&des_alg);\ndes_err:\n\tgoto out;\n}\n\nstatic void __exit des_s390_exit(void)\n{\n\tif (ctrblk) {\n\t\tcrypto_unregister_alg(&ctr_des_alg);\n\t\tcrypto_unregister_alg(&ctr_des3_alg);\n\t\tfree_page((unsigned long) ctrblk);\n\t}\n\tcrypto_unregister_alg(&cbc_des3_alg);\n\tcrypto_unregister_alg(&ecb_des3_alg);\n\tcrypto_unregister_alg(&des3_alg);\n\tcrypto_unregister_alg(&cbc_des_alg);\n\tcrypto_unregister_alg(&ecb_des_alg);\n\tcrypto_unregister_alg(&des_alg);\n}\n\nmodule_init(des_s390_init);\nmodule_exit(des_s390_exit);\n\nMODULE_ALIAS(\"des\");\nMODULE_ALIAS(\"des3_ede\");\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"DES & Triple DES EDE Cipher Algorithms\");\n", "/*\n * Cryptographic API.\n *\n * s390 implementation of the GHASH algorithm for GCM (Galois/Counter Mode).\n *\n * Copyright IBM Corp. 2011\n * Author(s): Gerald Schaefer <gerald.schaefer@de.ibm.com>\n */\n\n#include <crypto/internal/hash.h>\n#include <linux/module.h>\n\n#include \"crypt_s390.h\"\n\n#define GHASH_BLOCK_SIZE\t16\n#define GHASH_DIGEST_SIZE\t16\n\nstruct ghash_ctx {\n\tu8 icv[16];\n\tu8 key[16];\n};\n\nstruct ghash_desc_ctx {\n\tu8 buffer[GHASH_BLOCK_SIZE];\n\tu32 bytes;\n};\n\nstatic int ghash_init(struct shash_desc *desc)\n{\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\n\tmemset(dctx, 0, sizeof(*dctx));\n\n\treturn 0;\n}\n\nstatic int ghash_setkey(struct crypto_shash *tfm,\n\t\t\tconst u8 *key, unsigned int keylen)\n{\n\tstruct ghash_ctx *ctx = crypto_shash_ctx(tfm);\n\n\tif (keylen != GHASH_BLOCK_SIZE) {\n\t\tcrypto_shash_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(ctx->key, key, GHASH_BLOCK_SIZE);\n\tmemset(ctx->icv, 0, GHASH_BLOCK_SIZE);\n\n\treturn 0;\n}\n\nstatic int ghash_update(struct shash_desc *desc,\n\t\t\t const u8 *src, unsigned int srclen)\n{\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\tstruct ghash_ctx *ctx = crypto_shash_ctx(desc->tfm);\n\tunsigned int n;\n\tu8 *buf = dctx->buffer;\n\tint ret;\n\n\tif (dctx->bytes) {\n\t\tu8 *pos = buf + (GHASH_BLOCK_SIZE - dctx->bytes);\n\n\t\tn = min(srclen, dctx->bytes);\n\t\tdctx->bytes -= n;\n\t\tsrclen -= n;\n\n\t\tmemcpy(pos, src, n);\n\t\tsrc += n;\n\n\t\tif (!dctx->bytes) {\n\t\t\tret = crypt_s390_kimd(KIMD_GHASH, ctx, buf,\n\t\t\t\t\t      GHASH_BLOCK_SIZE);\n\t\t\tif (ret != GHASH_BLOCK_SIZE)\n\t\t\t\treturn -EIO;\n\t\t}\n\t}\n\n\tn = srclen & ~(GHASH_BLOCK_SIZE - 1);\n\tif (n) {\n\t\tret = crypt_s390_kimd(KIMD_GHASH, ctx, src, n);\n\t\tif (ret != n)\n\t\t\treturn -EIO;\n\t\tsrc += n;\n\t\tsrclen -= n;\n\t}\n\n\tif (srclen) {\n\t\tdctx->bytes = GHASH_BLOCK_SIZE - srclen;\n\t\tmemcpy(buf, src, srclen);\n\t}\n\n\treturn 0;\n}\n\nstatic int ghash_flush(struct ghash_ctx *ctx, struct ghash_desc_ctx *dctx)\n{\n\tu8 *buf = dctx->buffer;\n\tint ret;\n\n\tif (dctx->bytes) {\n\t\tu8 *pos = buf + (GHASH_BLOCK_SIZE - dctx->bytes);\n\n\t\tmemset(pos, 0, dctx->bytes);\n\n\t\tret = crypt_s390_kimd(KIMD_GHASH, ctx, buf, GHASH_BLOCK_SIZE);\n\t\tif (ret != GHASH_BLOCK_SIZE)\n\t\t\treturn -EIO;\n\t}\n\n\tdctx->bytes = 0;\n\treturn 0;\n}\n\nstatic int ghash_final(struct shash_desc *desc, u8 *dst)\n{\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\tstruct ghash_ctx *ctx = crypto_shash_ctx(desc->tfm);\n\tint ret;\n\n\tret = ghash_flush(ctx, dctx);\n\tif (!ret)\n\t\tmemcpy(dst, ctx->icv, GHASH_BLOCK_SIZE);\n\treturn ret;\n}\n\nstatic struct shash_alg ghash_alg = {\n\t.digestsize\t= GHASH_DIGEST_SIZE,\n\t.init\t\t= ghash_init,\n\t.update\t\t= ghash_update,\n\t.final\t\t= ghash_final,\n\t.setkey\t\t= ghash_setkey,\n\t.descsize\t= sizeof(struct ghash_desc_ctx),\n\t.base\t\t= {\n\t\t.cra_name\t\t= \"ghash\",\n\t\t.cra_driver_name\t= \"ghash-s390\",\n\t\t.cra_priority\t\t= CRYPT_S390_PRIORITY,\n\t\t.cra_flags\t\t= CRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t\t= GHASH_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t= sizeof(struct ghash_ctx),\n\t\t.cra_module\t\t= THIS_MODULE,\n\t},\n};\n\nstatic int __init ghash_mod_init(void)\n{\n\tif (!crypt_s390_func_available(KIMD_GHASH,\n\t\t\t\t       CRYPT_S390_MSA | CRYPT_S390_MSA4))\n\t\treturn -EOPNOTSUPP;\n\n\treturn crypto_register_shash(&ghash_alg);\n}\n\nstatic void __exit ghash_mod_exit(void)\n{\n\tcrypto_unregister_shash(&ghash_alg);\n}\n\nmodule_init(ghash_mod_init);\nmodule_exit(ghash_mod_exit);\n\nMODULE_ALIAS(\"ghash\");\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"GHASH Message Digest Algorithm, s390 implementation\");\n", "/*\n * Cryptographic API.\n *\n * s390 implementation of the SHA1 Secure Hash Algorithm.\n *\n * Derived from cryptoapi implementation, adapted for in-place\n * scatterlist interface.  Originally based on the public domain\n * implementation written by Steve Reid.\n *\n * s390 Version:\n *   Copyright IBM Corp. 2003, 2007\n *   Author(s): Thomas Spatzier\n *\t\tJan Glauber (jan.glauber@de.ibm.com)\n *\n * Derived from \"crypto/sha1_generic.c\"\n *   Copyright (c) Alan Smithee.\n *   Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n *   Copyright (c) Jean-Francois Dive <jef@linuxbe.org>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <crypto/sha.h>\n\n#include \"crypt_s390.h\"\n#include \"sha.h\"\n\nstatic int sha1_init(struct shash_desc *desc)\n{\n\tstruct s390_sha_ctx *sctx = shash_desc_ctx(desc);\n\n\tsctx->state[0] = SHA1_H0;\n\tsctx->state[1] = SHA1_H1;\n\tsctx->state[2] = SHA1_H2;\n\tsctx->state[3] = SHA1_H3;\n\tsctx->state[4] = SHA1_H4;\n\tsctx->count = 0;\n\tsctx->func = KIMD_SHA_1;\n\n\treturn 0;\n}\n\nstatic int sha1_export(struct shash_desc *desc, void *out)\n{\n\tstruct s390_sha_ctx *sctx = shash_desc_ctx(desc);\n\tstruct sha1_state *octx = out;\n\n\toctx->count = sctx->count;\n\tmemcpy(octx->state, sctx->state, sizeof(octx->state));\n\tmemcpy(octx->buffer, sctx->buf, sizeof(octx->buffer));\n\treturn 0;\n}\n\nstatic int sha1_import(struct shash_desc *desc, const void *in)\n{\n\tstruct s390_sha_ctx *sctx = shash_desc_ctx(desc);\n\tconst struct sha1_state *ictx = in;\n\n\tsctx->count = ictx->count;\n\tmemcpy(sctx->state, ictx->state, sizeof(ictx->state));\n\tmemcpy(sctx->buf, ictx->buffer, sizeof(ictx->buffer));\n\tsctx->func = KIMD_SHA_1;\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tSHA1_DIGEST_SIZE,\n\t.init\t\t=\tsha1_init,\n\t.update\t\t=\ts390_sha_update,\n\t.final\t\t=\ts390_sha_final,\n\t.export\t\t=\tsha1_export,\n\t.import\t\t=\tsha1_import,\n\t.descsize\t=\tsizeof(struct s390_sha_ctx),\n\t.statesize\t=\tsizeof(struct sha1_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha1\",\n\t\t.cra_driver_name=\t\"sha1-s390\",\n\t\t.cra_priority\t=\tCRYPT_S390_PRIORITY,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA1_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init sha1_s390_init(void)\n{\n\tif (!crypt_s390_func_available(KIMD_SHA_1, CRYPT_S390_MSA))\n\t\treturn -EOPNOTSUPP;\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit sha1_s390_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(sha1_s390_init);\nmodule_exit(sha1_s390_fini);\n\nMODULE_ALIAS(\"sha1\");\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA1 Secure Hash Algorithm\");\n", "/*\n * Cryptographic API.\n *\n * s390 implementation of the SHA256 and SHA224 Secure Hash Algorithm.\n *\n * s390 Version:\n *   Copyright IBM Corp. 2005, 2011\n *   Author(s): Jan Glauber (jang@de.ibm.com)\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <crypto/sha.h>\n\n#include \"crypt_s390.h\"\n#include \"sha.h\"\n\nstatic int sha256_init(struct shash_desc *desc)\n{\n\tstruct s390_sha_ctx *sctx = shash_desc_ctx(desc);\n\n\tsctx->state[0] = SHA256_H0;\n\tsctx->state[1] = SHA256_H1;\n\tsctx->state[2] = SHA256_H2;\n\tsctx->state[3] = SHA256_H3;\n\tsctx->state[4] = SHA256_H4;\n\tsctx->state[5] = SHA256_H5;\n\tsctx->state[6] = SHA256_H6;\n\tsctx->state[7] = SHA256_H7;\n\tsctx->count = 0;\n\tsctx->func = KIMD_SHA_256;\n\n\treturn 0;\n}\n\nstatic int sha256_export(struct shash_desc *desc, void *out)\n{\n\tstruct s390_sha_ctx *sctx = shash_desc_ctx(desc);\n\tstruct sha256_state *octx = out;\n\n\toctx->count = sctx->count;\n\tmemcpy(octx->state, sctx->state, sizeof(octx->state));\n\tmemcpy(octx->buf, sctx->buf, sizeof(octx->buf));\n\treturn 0;\n}\n\nstatic int sha256_import(struct shash_desc *desc, const void *in)\n{\n\tstruct s390_sha_ctx *sctx = shash_desc_ctx(desc);\n\tconst struct sha256_state *ictx = in;\n\n\tsctx->count = ictx->count;\n\tmemcpy(sctx->state, ictx->state, sizeof(ictx->state));\n\tmemcpy(sctx->buf, ictx->buf, sizeof(ictx->buf));\n\tsctx->func = KIMD_SHA_256;\n\treturn 0;\n}\n\nstatic struct shash_alg sha256_alg = {\n\t.digestsize\t=\tSHA256_DIGEST_SIZE,\n\t.init\t\t=\tsha256_init,\n\t.update\t\t=\ts390_sha_update,\n\t.final\t\t=\ts390_sha_final,\n\t.export\t\t=\tsha256_export,\n\t.import\t\t=\tsha256_import,\n\t.descsize\t=\tsizeof(struct s390_sha_ctx),\n\t.statesize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha256\",\n\t\t.cra_driver_name=\t\"sha256-s390\",\n\t\t.cra_priority\t=\tCRYPT_S390_PRIORITY,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA256_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic int sha224_init(struct shash_desc *desc)\n{\n\tstruct s390_sha_ctx *sctx = shash_desc_ctx(desc);\n\n\tsctx->state[0] = SHA224_H0;\n\tsctx->state[1] = SHA224_H1;\n\tsctx->state[2] = SHA224_H2;\n\tsctx->state[3] = SHA224_H3;\n\tsctx->state[4] = SHA224_H4;\n\tsctx->state[5] = SHA224_H5;\n\tsctx->state[6] = SHA224_H6;\n\tsctx->state[7] = SHA224_H7;\n\tsctx->count = 0;\n\tsctx->func = KIMD_SHA_256;\n\n\treturn 0;\n}\n\nstatic struct shash_alg sha224_alg = {\n\t.digestsize\t=\tSHA224_DIGEST_SIZE,\n\t.init\t\t=\tsha224_init,\n\t.update\t\t=\ts390_sha_update,\n\t.final\t\t=\ts390_sha_final,\n\t.export\t\t=\tsha256_export,\n\t.import\t\t=\tsha256_import,\n\t.descsize\t=\tsizeof(struct s390_sha_ctx),\n\t.statesize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha224\",\n\t\t.cra_driver_name=\t\"sha224-s390\",\n\t\t.cra_priority\t=\tCRYPT_S390_PRIORITY,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA224_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init sha256_s390_init(void)\n{\n\tint ret;\n\n\tif (!crypt_s390_func_available(KIMD_SHA_256, CRYPT_S390_MSA))\n\t\treturn -EOPNOTSUPP;\n\tret = crypto_register_shash(&sha256_alg);\n\tif (ret < 0)\n\t\tgoto out;\n\tret = crypto_register_shash(&sha224_alg);\n\tif (ret < 0)\n\t\tcrypto_unregister_shash(&sha256_alg);\nout:\n\treturn ret;\n}\n\nstatic void __exit sha256_s390_fini(void)\n{\n\tcrypto_unregister_shash(&sha224_alg);\n\tcrypto_unregister_shash(&sha256_alg);\n}\n\nmodule_init(sha256_s390_init);\nmodule_exit(sha256_s390_fini);\n\nMODULE_ALIAS(\"sha256\");\nMODULE_ALIAS(\"sha224\");\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA256 and SHA224 Secure Hash Algorithm\");\n", "/*\n * Cryptographic API.\n *\n * s390 implementation of the SHA512 and SHA38 Secure Hash Algorithm.\n *\n * Copyright IBM Corp. 2007\n * Author(s): Jan Glauber (jang@de.ibm.com)\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <crypto/sha.h>\n#include <linux/errno.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n\n#include \"sha.h\"\n#include \"crypt_s390.h\"\n\nstatic int sha512_init(struct shash_desc *desc)\n{\n\tstruct s390_sha_ctx *ctx = shash_desc_ctx(desc);\n\n\t*(__u64 *)&ctx->state[0] = 0x6a09e667f3bcc908ULL;\n\t*(__u64 *)&ctx->state[2] = 0xbb67ae8584caa73bULL;\n\t*(__u64 *)&ctx->state[4] = 0x3c6ef372fe94f82bULL;\n\t*(__u64 *)&ctx->state[6] = 0xa54ff53a5f1d36f1ULL;\n\t*(__u64 *)&ctx->state[8] = 0x510e527fade682d1ULL;\n\t*(__u64 *)&ctx->state[10] = 0x9b05688c2b3e6c1fULL;\n\t*(__u64 *)&ctx->state[12] = 0x1f83d9abfb41bd6bULL;\n\t*(__u64 *)&ctx->state[14] = 0x5be0cd19137e2179ULL;\n\tctx->count = 0;\n\tctx->func = KIMD_SHA_512;\n\n\treturn 0;\n}\n\nstatic int sha512_export(struct shash_desc *desc, void *out)\n{\n\tstruct s390_sha_ctx *sctx = shash_desc_ctx(desc);\n\tstruct sha512_state *octx = out;\n\n\toctx->count[0] = sctx->count;\n\toctx->count[1] = 0;\n\tmemcpy(octx->state, sctx->state, sizeof(octx->state));\n\tmemcpy(octx->buf, sctx->buf, sizeof(octx->buf));\n\treturn 0;\n}\n\nstatic int sha512_import(struct shash_desc *desc, const void *in)\n{\n\tstruct s390_sha_ctx *sctx = shash_desc_ctx(desc);\n\tconst struct sha512_state *ictx = in;\n\n\tif (unlikely(ictx->count[1]))\n\t\treturn -ERANGE;\n\tsctx->count = ictx->count[0];\n\n\tmemcpy(sctx->state, ictx->state, sizeof(ictx->state));\n\tmemcpy(sctx->buf, ictx->buf, sizeof(ictx->buf));\n\tsctx->func = KIMD_SHA_512;\n\treturn 0;\n}\n\nstatic struct shash_alg sha512_alg = {\n\t.digestsize\t=\tSHA512_DIGEST_SIZE,\n\t.init\t\t=\tsha512_init,\n\t.update\t\t=\ts390_sha_update,\n\t.final\t\t=\ts390_sha_final,\n\t.export\t\t=\tsha512_export,\n\t.import\t\t=\tsha512_import,\n\t.descsize\t=\tsizeof(struct s390_sha_ctx),\n\t.statesize\t=\tsizeof(struct sha512_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha512\",\n\t\t.cra_driver_name=\t\"sha512-s390\",\n\t\t.cra_priority\t=\tCRYPT_S390_PRIORITY,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA512_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nMODULE_ALIAS(\"sha512\");\n\nstatic int sha384_init(struct shash_desc *desc)\n{\n\tstruct s390_sha_ctx *ctx = shash_desc_ctx(desc);\n\n\t*(__u64 *)&ctx->state[0] = 0xcbbb9d5dc1059ed8ULL;\n\t*(__u64 *)&ctx->state[2] = 0x629a292a367cd507ULL;\n\t*(__u64 *)&ctx->state[4] = 0x9159015a3070dd17ULL;\n\t*(__u64 *)&ctx->state[6] = 0x152fecd8f70e5939ULL;\n\t*(__u64 *)&ctx->state[8] = 0x67332667ffc00b31ULL;\n\t*(__u64 *)&ctx->state[10] = 0x8eb44a8768581511ULL;\n\t*(__u64 *)&ctx->state[12] = 0xdb0c2e0d64f98fa7ULL;\n\t*(__u64 *)&ctx->state[14] = 0x47b5481dbefa4fa4ULL;\n\tctx->count = 0;\n\tctx->func = KIMD_SHA_512;\n\n\treturn 0;\n}\n\nstatic struct shash_alg sha384_alg = {\n\t.digestsize\t=\tSHA384_DIGEST_SIZE,\n\t.init\t\t=\tsha384_init,\n\t.update\t\t=\ts390_sha_update,\n\t.final\t\t=\ts390_sha_final,\n\t.export\t\t=\tsha512_export,\n\t.import\t\t=\tsha512_import,\n\t.descsize\t=\tsizeof(struct s390_sha_ctx),\n\t.statesize\t=\tsizeof(struct sha512_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha384\",\n\t\t.cra_driver_name=\t\"sha384-s390\",\n\t\t.cra_priority\t=\tCRYPT_S390_PRIORITY,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA384_BLOCK_SIZE,\n\t\t.cra_ctxsize\t=\tsizeof(struct s390_sha_ctx),\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nMODULE_ALIAS(\"sha384\");\n\nstatic int __init init(void)\n{\n\tint ret;\n\n\tif (!crypt_s390_func_available(KIMD_SHA_512, CRYPT_S390_MSA))\n\t\treturn -EOPNOTSUPP;\n\tif ((ret = crypto_register_shash(&sha512_alg)) < 0)\n\t\tgoto out;\n\tif ((ret = crypto_register_shash(&sha384_alg)) < 0)\n\t\tcrypto_unregister_shash(&sha512_alg);\nout:\n\treturn ret;\n}\n\nstatic void __exit fini(void)\n{\n\tcrypto_unregister_shash(&sha512_alg);\n\tcrypto_unregister_shash(&sha384_alg);\n}\n\nmodule_init(init);\nmodule_exit(fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA512 and SHA-384 Secure Hash Algorithm\");\n", "/* Glue code for AES encryption optimized for sparc64 crypto opcodes.\n *\n * This is based largely upon arch/x86/crypto/aesni-intel_glue.c\n *\n * Copyright (C) 2008, Intel Corp.\n *    Author: Huang Ying <ying.huang@intel.com>\n *\n * Added RFC4106 AES-GCM support for 128-bit keys under the AEAD\n * interface for 64-bit kernels.\n *    Authors: Adrian Hoban <adrian.hoban@intel.com>\n *             Gabriele Paoloni <gabriele.paoloni@intel.com>\n *             Tadeusz Struk (tadeusz.struk@intel.com)\n *             Aidan O'Mahony (aidan.o.mahony@intel.com)\n *    Copyright (c) 2010, Intel Corporation.\n */\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <linux/crypto.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/types.h>\n#include <crypto/algapi.h>\n#include <crypto/aes.h>\n\n#include <asm/fpumacro.h>\n#include <asm/pstate.h>\n#include <asm/elf.h>\n\n#include \"opcodes.h\"\n\nstruct aes_ops {\n\tvoid (*encrypt)(const u64 *key, const u32 *input, u32 *output);\n\tvoid (*decrypt)(const u64 *key, const u32 *input, u32 *output);\n\tvoid (*load_encrypt_keys)(const u64 *key);\n\tvoid (*load_decrypt_keys)(const u64 *key);\n\tvoid (*ecb_encrypt)(const u64 *key, const u64 *input, u64 *output,\n\t\t\t    unsigned int len);\n\tvoid (*ecb_decrypt)(const u64 *key, const u64 *input, u64 *output,\n\t\t\t    unsigned int len);\n\tvoid (*cbc_encrypt)(const u64 *key, const u64 *input, u64 *output,\n\t\t\t    unsigned int len, u64 *iv);\n\tvoid (*cbc_decrypt)(const u64 *key, const u64 *input, u64 *output,\n\t\t\t    unsigned int len, u64 *iv);\n\tvoid (*ctr_crypt)(const u64 *key, const u64 *input, u64 *output,\n\t\t\t  unsigned int len, u64 *iv);\n};\n\nstruct crypto_sparc64_aes_ctx {\n\tstruct aes_ops *ops;\n\tu64 key[AES_MAX_KEYLENGTH / sizeof(u64)];\n\tu32 key_length;\n\tu32 expanded_key_length;\n};\n\nextern void aes_sparc64_encrypt_128(const u64 *key, const u32 *input,\n\t\t\t\t    u32 *output);\nextern void aes_sparc64_encrypt_192(const u64 *key, const u32 *input,\n\t\t\t\t    u32 *output);\nextern void aes_sparc64_encrypt_256(const u64 *key, const u32 *input,\n\t\t\t\t    u32 *output);\n\nextern void aes_sparc64_decrypt_128(const u64 *key, const u32 *input,\n\t\t\t\t    u32 *output);\nextern void aes_sparc64_decrypt_192(const u64 *key, const u32 *input,\n\t\t\t\t    u32 *output);\nextern void aes_sparc64_decrypt_256(const u64 *key, const u32 *input,\n\t\t\t\t    u32 *output);\n\nextern void aes_sparc64_load_encrypt_keys_128(const u64 *key);\nextern void aes_sparc64_load_encrypt_keys_192(const u64 *key);\nextern void aes_sparc64_load_encrypt_keys_256(const u64 *key);\n\nextern void aes_sparc64_load_decrypt_keys_128(const u64 *key);\nextern void aes_sparc64_load_decrypt_keys_192(const u64 *key);\nextern void aes_sparc64_load_decrypt_keys_256(const u64 *key);\n\nextern void aes_sparc64_ecb_encrypt_128(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len);\nextern void aes_sparc64_ecb_encrypt_192(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len);\nextern void aes_sparc64_ecb_encrypt_256(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len);\n\nextern void aes_sparc64_ecb_decrypt_128(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len);\nextern void aes_sparc64_ecb_decrypt_192(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len);\nextern void aes_sparc64_ecb_decrypt_256(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len);\n\nextern void aes_sparc64_cbc_encrypt_128(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len,\n\t\t\t\t\tu64 *iv);\n\nextern void aes_sparc64_cbc_encrypt_192(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len,\n\t\t\t\t\tu64 *iv);\n\nextern void aes_sparc64_cbc_encrypt_256(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len,\n\t\t\t\t\tu64 *iv);\n\nextern void aes_sparc64_cbc_decrypt_128(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len,\n\t\t\t\t\tu64 *iv);\n\nextern void aes_sparc64_cbc_decrypt_192(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len,\n\t\t\t\t\tu64 *iv);\n\nextern void aes_sparc64_cbc_decrypt_256(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len,\n\t\t\t\t\tu64 *iv);\n\nextern void aes_sparc64_ctr_crypt_128(const u64 *key, const u64 *input,\n\t\t\t\t      u64 *output, unsigned int len,\n\t\t\t\t      u64 *iv);\nextern void aes_sparc64_ctr_crypt_192(const u64 *key, const u64 *input,\n\t\t\t\t      u64 *output, unsigned int len,\n\t\t\t\t      u64 *iv);\nextern void aes_sparc64_ctr_crypt_256(const u64 *key, const u64 *input,\n\t\t\t\t      u64 *output, unsigned int len,\n\t\t\t\t      u64 *iv);\n\nstatic struct aes_ops aes128_ops = {\n\t.encrypt\t\t= aes_sparc64_encrypt_128,\n\t.decrypt\t\t= aes_sparc64_decrypt_128,\n\t.load_encrypt_keys\t= aes_sparc64_load_encrypt_keys_128,\n\t.load_decrypt_keys\t= aes_sparc64_load_decrypt_keys_128,\n\t.ecb_encrypt\t\t= aes_sparc64_ecb_encrypt_128,\n\t.ecb_decrypt\t\t= aes_sparc64_ecb_decrypt_128,\n\t.cbc_encrypt\t\t= aes_sparc64_cbc_encrypt_128,\n\t.cbc_decrypt\t\t= aes_sparc64_cbc_decrypt_128,\n\t.ctr_crypt\t\t= aes_sparc64_ctr_crypt_128,\n};\n\nstatic struct aes_ops aes192_ops = {\n\t.encrypt\t\t= aes_sparc64_encrypt_192,\n\t.decrypt\t\t= aes_sparc64_decrypt_192,\n\t.load_encrypt_keys\t= aes_sparc64_load_encrypt_keys_192,\n\t.load_decrypt_keys\t= aes_sparc64_load_decrypt_keys_192,\n\t.ecb_encrypt\t\t= aes_sparc64_ecb_encrypt_192,\n\t.ecb_decrypt\t\t= aes_sparc64_ecb_decrypt_192,\n\t.cbc_encrypt\t\t= aes_sparc64_cbc_encrypt_192,\n\t.cbc_decrypt\t\t= aes_sparc64_cbc_decrypt_192,\n\t.ctr_crypt\t\t= aes_sparc64_ctr_crypt_192,\n};\n\nstatic struct aes_ops aes256_ops = {\n\t.encrypt\t\t= aes_sparc64_encrypt_256,\n\t.decrypt\t\t= aes_sparc64_decrypt_256,\n\t.load_encrypt_keys\t= aes_sparc64_load_encrypt_keys_256,\n\t.load_decrypt_keys\t= aes_sparc64_load_decrypt_keys_256,\n\t.ecb_encrypt\t\t= aes_sparc64_ecb_encrypt_256,\n\t.ecb_decrypt\t\t= aes_sparc64_ecb_decrypt_256,\n\t.cbc_encrypt\t\t= aes_sparc64_cbc_encrypt_256,\n\t.cbc_decrypt\t\t= aes_sparc64_cbc_decrypt_256,\n\t.ctr_crypt\t\t= aes_sparc64_ctr_crypt_256,\n};\n\nextern void aes_sparc64_key_expand(const u32 *in_key, u64 *output_key,\n\t\t\t\t   unsigned int key_len);\n\nstatic int aes_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t       unsigned int key_len)\n{\n\tstruct crypto_sparc64_aes_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\n\tswitch (key_len) {\n\tcase AES_KEYSIZE_128:\n\t\tctx->expanded_key_length = 0xb0;\n\t\tctx->ops = &aes128_ops;\n\t\tbreak;\n\n\tcase AES_KEYSIZE_192:\n\t\tctx->expanded_key_length = 0xd0;\n\t\tctx->ops = &aes192_ops;\n\t\tbreak;\n\n\tcase AES_KEYSIZE_256:\n\t\tctx->expanded_key_length = 0xf0;\n\t\tctx->ops = &aes256_ops;\n\t\tbreak;\n\n\tdefault:\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\taes_sparc64_key_expand((const u32 *)in_key, &ctx->key[0], key_len);\n\tctx->key_length = key_len;\n\n\treturn 0;\n}\n\nstatic void aes_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct crypto_sparc64_aes_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tctx->ops->encrypt(&ctx->key[0], (const u32 *) src, (u32 *) dst);\n}\n\nstatic void aes_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct crypto_sparc64_aes_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tctx->ops->decrypt(&ctx->key[0], (const u32 *) src, (u32 *) dst);\n}\n\n#define AES_BLOCK_MASK\t(~(AES_BLOCK_SIZE-1))\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct crypto_sparc64_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tctx->ops->load_encrypt_keys(&ctx->key[0]);\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & AES_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tctx->ops->ecb_encrypt(&ctx->key[0],\n\t\t\t\t\t      (const u64 *)walk.src.virt.addr,\n\t\t\t\t\t      (u64 *) walk.dst.virt.addr,\n\t\t\t\t\t      block_len);\n\t\t}\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct crypto_sparc64_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tu64 *key_end;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tctx->ops->load_decrypt_keys(&ctx->key[0]);\n\tkey_end = &ctx->key[ctx->expanded_key_length / sizeof(u64)];\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & AES_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tctx->ops->ecb_decrypt(key_end,\n\t\t\t\t\t      (const u64 *) walk.src.virt.addr,\n\t\t\t\t\t      (u64 *) walk.dst.virt.addr, block_len);\n\t\t}\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\n\treturn err;\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct crypto_sparc64_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tctx->ops->load_encrypt_keys(&ctx->key[0]);\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & AES_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tctx->ops->cbc_encrypt(&ctx->key[0],\n\t\t\t\t\t      (const u64 *)walk.src.virt.addr,\n\t\t\t\t\t      (u64 *) walk.dst.virt.addr,\n\t\t\t\t\t      block_len, (u64 *) walk.iv);\n\t\t}\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct crypto_sparc64_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tu64 *key_end;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tctx->ops->load_decrypt_keys(&ctx->key[0]);\n\tkey_end = &ctx->key[ctx->expanded_key_length / sizeof(u64)];\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & AES_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tctx->ops->cbc_decrypt(key_end,\n\t\t\t\t\t      (const u64 *) walk.src.virt.addr,\n\t\t\t\t\t      (u64 *) walk.dst.virt.addr,\n\t\t\t\t\t      block_len, (u64 *) walk.iv);\n\t\t}\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\n\treturn err;\n}\n\nstatic void ctr_crypt_final(struct crypto_sparc64_aes_ctx *ctx,\n\t\t\t    struct blkcipher_walk *walk)\n{\n\tu8 *ctrblk = walk->iv;\n\tu64 keystream[AES_BLOCK_SIZE / sizeof(u64)];\n\tu8 *src = walk->src.virt.addr;\n\tu8 *dst = walk->dst.virt.addr;\n\tunsigned int nbytes = walk->nbytes;\n\n\tctx->ops->ecb_encrypt(&ctx->key[0], (const u64 *)ctrblk,\n\t\t\t      keystream, AES_BLOCK_SIZE);\n\tcrypto_xor((u8 *) keystream, src, nbytes);\n\tmemcpy(dst, keystream, nbytes);\n\tcrypto_inc(ctrblk, AES_BLOCK_SIZE);\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc,\n\t\t     struct scatterlist *dst, struct scatterlist *src,\n\t\t     unsigned int nbytes)\n{\n\tstruct crypto_sparc64_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt_block(desc, &walk, AES_BLOCK_SIZE);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tctx->ops->load_encrypt_keys(&ctx->key[0]);\n\twhile ((nbytes = walk.nbytes) >= AES_BLOCK_SIZE) {\n\t\tunsigned int block_len = nbytes & AES_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tctx->ops->ctr_crypt(&ctx->key[0],\n\t\t\t\t\t    (const u64 *)walk.src.virt.addr,\n\t\t\t\t\t    (u64 *) walk.dst.virt.addr,\n\t\t\t\t\t    block_len, (u64 *) walk.iv);\n\t\t}\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tif (walk.nbytes) {\n\t\tctr_crypt_final(ctx, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, 0);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nstatic struct crypto_alg algs[] = { {\n\t.cra_name\t\t= \"aes\",\n\t.cra_driver_name\t= \"aes-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_sparc64_aes_ctx),\n\t.cra_alignmask\t\t= 3,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u\t= {\n\t\t.cipher\t= {\n\t\t\t.cia_min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t= aes_set_key,\n\t\t\t.cia_encrypt\t\t= aes_encrypt,\n\t\t\t.cia_decrypt\t\t= aes_decrypt\n\t\t}\n\t}\n}, {\n\t.cra_name\t\t= \"ecb(aes)\",\n\t.cra_driver_name\t= \"ecb-aes-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_sparc64_aes_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= aes_set_key,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(aes)\",\n\t.cra_driver_name\t= \"cbc-aes-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_sparc64_aes_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= aes_set_key,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(aes)\",\n\t.cra_driver_name\t= \"ctr-aes-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_sparc64_aes_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= aes_set_key,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n} };\n\nstatic bool __init sparc64_has_aes_opcode(void)\n{\n\tunsigned long cfr;\n\n\tif (!(sparc64_elf_hwcap & HWCAP_SPARC_CRYPTO))\n\t\treturn false;\n\n\t__asm__ __volatile__(\"rd %%asr26, %0\" : \"=r\" (cfr));\n\tif (!(cfr & CFR_AES))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int __init aes_sparc64_mod_init(void)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(algs); i++)\n\t\tINIT_LIST_HEAD(&algs[i].cra_list);\n\n\tif (sparc64_has_aes_opcode()) {\n\t\tpr_info(\"Using sparc64 aes opcodes optimized AES implementation\\n\");\n\t\treturn crypto_register_algs(algs, ARRAY_SIZE(algs));\n\t}\n\tpr_info(\"sparc64 aes opcodes not available.\\n\");\n\treturn -ENODEV;\n}\n\nstatic void __exit aes_sparc64_mod_fini(void)\n{\n\tcrypto_unregister_algs(algs, ARRAY_SIZE(algs));\n}\n\nmodule_init(aes_sparc64_mod_init);\nmodule_exit(aes_sparc64_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"AES Secure Hash Algorithm, sparc64 aes opcode accelerated\");\n\nMODULE_ALIAS(\"aes\");\n\n#include \"crop_devid.c\"\n", "/* Glue code for CAMELLIA encryption optimized for sparc64 crypto opcodes.\n *\n * Copyright (C) 2012 David S. Miller <davem@davemloft.net>\n */\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <linux/crypto.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/types.h>\n#include <crypto/algapi.h>\n\n#include <asm/fpumacro.h>\n#include <asm/pstate.h>\n#include <asm/elf.h>\n\n#include \"opcodes.h\"\n\n#define CAMELLIA_MIN_KEY_SIZE        16\n#define CAMELLIA_MAX_KEY_SIZE        32\n#define CAMELLIA_BLOCK_SIZE          16\n#define CAMELLIA_TABLE_BYTE_LEN     272\n\nstruct camellia_sparc64_ctx {\n\tu64 encrypt_key[CAMELLIA_TABLE_BYTE_LEN / sizeof(u64)];\n\tu64 decrypt_key[CAMELLIA_TABLE_BYTE_LEN / sizeof(u64)];\n\tint key_len;\n};\n\nextern void camellia_sparc64_key_expand(const u32 *in_key, u64 *encrypt_key,\n\t\t\t\t\tunsigned int key_len, u64 *decrypt_key);\n\nstatic int camellia_set_key(struct crypto_tfm *tfm, const u8 *_in_key,\n\t\t\t    unsigned int key_len)\n{\n\tstruct camellia_sparc64_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst u32 *in_key = (const u32 *) _in_key;\n\tu32 *flags = &tfm->crt_flags;\n\n\tif (key_len != 16 && key_len != 24 && key_len != 32) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\tctx->key_len = key_len;\n\n\tcamellia_sparc64_key_expand(in_key, &ctx->encrypt_key[0],\n\t\t\t\t    key_len, &ctx->decrypt_key[0]);\n\treturn 0;\n}\n\nextern void camellia_sparc64_crypt(const u64 *key, const u32 *input,\n\t\t\t\t   u32 *output, unsigned int key_len);\n\nstatic void camellia_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct camellia_sparc64_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcamellia_sparc64_crypt(&ctx->encrypt_key[0],\n\t\t\t       (const u32 *) src,\n\t\t\t       (u32 *) dst, ctx->key_len);\n}\n\nstatic void camellia_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct camellia_sparc64_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcamellia_sparc64_crypt(&ctx->decrypt_key[0],\n\t\t\t       (const u32 *) src,\n\t\t\t       (u32 *) dst, ctx->key_len);\n}\n\nextern void camellia_sparc64_load_keys(const u64 *key, unsigned int key_len);\n\ntypedef void ecb_crypt_op(const u64 *input, u64 *output, unsigned int len,\n\t\t\t  const u64 *key);\n\nextern ecb_crypt_op camellia_sparc64_ecb_crypt_3_grand_rounds;\nextern ecb_crypt_op camellia_sparc64_ecb_crypt_4_grand_rounds;\n\n#define CAMELLIA_BLOCK_MASK\t(~(CAMELLIA_BLOCK_SIZE - 1))\n\nstatic int __ecb_crypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes, bool encrypt)\n{\n\tstruct camellia_sparc64_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tecb_crypt_op *op;\n\tconst u64 *key;\n\tint err;\n\n\top = camellia_sparc64_ecb_crypt_3_grand_rounds;\n\tif (ctx->key_len != 16)\n\t\top = camellia_sparc64_ecb_crypt_4_grand_rounds;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tif (encrypt)\n\t\tkey = &ctx->encrypt_key[0];\n\telse\n\t\tkey = &ctx->decrypt_key[0];\n\tcamellia_sparc64_load_keys(key, ctx->key_len);\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & CAMELLIA_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tconst u64 *src64;\n\t\t\tu64 *dst64;\n\n\t\t\tsrc64 = (const u64 *)walk.src.virt.addr;\n\t\t\tdst64 = (u64 *) walk.dst.virt.addr;\n\t\t\top(src64, dst64, block_len, key);\n\t\t}\n\t\tnbytes &= CAMELLIA_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\treturn __ecb_crypt(desc, dst, src, nbytes, true);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\treturn __ecb_crypt(desc, dst, src, nbytes, false);\n}\n\ntypedef void cbc_crypt_op(const u64 *input, u64 *output, unsigned int len,\n\t\t\t  const u64 *key, u64 *iv);\n\nextern cbc_crypt_op camellia_sparc64_cbc_encrypt_3_grand_rounds;\nextern cbc_crypt_op camellia_sparc64_cbc_encrypt_4_grand_rounds;\nextern cbc_crypt_op camellia_sparc64_cbc_decrypt_3_grand_rounds;\nextern cbc_crypt_op camellia_sparc64_cbc_decrypt_4_grand_rounds;\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct camellia_sparc64_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tcbc_crypt_op *op;\n\tconst u64 *key;\n\tint err;\n\n\top = camellia_sparc64_cbc_encrypt_3_grand_rounds;\n\tif (ctx->key_len != 16)\n\t\top = camellia_sparc64_cbc_encrypt_4_grand_rounds;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tkey = &ctx->encrypt_key[0];\n\tcamellia_sparc64_load_keys(key, ctx->key_len);\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & CAMELLIA_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tconst u64 *src64;\n\t\t\tu64 *dst64;\n\n\t\t\tsrc64 = (const u64 *)walk.src.virt.addr;\n\t\t\tdst64 = (u64 *) walk.dst.virt.addr;\n\t\t\top(src64, dst64, block_len, key,\n\t\t\t   (u64 *) walk.iv);\n\t\t}\n\t\tnbytes &= CAMELLIA_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct camellia_sparc64_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tcbc_crypt_op *op;\n\tconst u64 *key;\n\tint err;\n\n\top = camellia_sparc64_cbc_decrypt_3_grand_rounds;\n\tif (ctx->key_len != 16)\n\t\top = camellia_sparc64_cbc_decrypt_4_grand_rounds;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tkey = &ctx->decrypt_key[0];\n\tcamellia_sparc64_load_keys(key, ctx->key_len);\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & CAMELLIA_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tconst u64 *src64;\n\t\t\tu64 *dst64;\n\n\t\t\tsrc64 = (const u64 *)walk.src.virt.addr;\n\t\t\tdst64 = (u64 *) walk.dst.virt.addr;\n\t\t\top(src64, dst64, block_len, key,\n\t\t\t   (u64 *) walk.iv);\n\t\t}\n\t\tnbytes &= CAMELLIA_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nstatic struct crypto_alg algs[] = { {\n\t.cra_name\t\t= \"camellia\",\n\t.cra_driver_name\t= \"camellia-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_sparc64_ctx),\n\t.cra_alignmask\t\t= 3,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u\t= {\n\t\t.cipher\t= {\n\t\t\t.cia_min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t= camellia_set_key,\n\t\t\t.cia_encrypt\t\t= camellia_encrypt,\n\t\t\t.cia_decrypt\t\t= camellia_decrypt\n\t\t}\n\t}\n}, {\n\t.cra_name\t\t= \"ecb(camellia)\",\n\t.cra_driver_name\t= \"ecb-camellia-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_sparc64_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= camellia_set_key,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(camellia)\",\n\t.cra_driver_name\t= \"cbc-camellia-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_sparc64_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= camellia_set_key,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}\n};\n\nstatic bool __init sparc64_has_camellia_opcode(void)\n{\n\tunsigned long cfr;\n\n\tif (!(sparc64_elf_hwcap & HWCAP_SPARC_CRYPTO))\n\t\treturn false;\n\n\t__asm__ __volatile__(\"rd %%asr26, %0\" : \"=r\" (cfr));\n\tif (!(cfr & CFR_CAMELLIA))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int __init camellia_sparc64_mod_init(void)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(algs); i++)\n\t\tINIT_LIST_HEAD(&algs[i].cra_list);\n\n\tif (sparc64_has_camellia_opcode()) {\n\t\tpr_info(\"Using sparc64 camellia opcodes optimized CAMELLIA implementation\\n\");\n\t\treturn crypto_register_algs(algs, ARRAY_SIZE(algs));\n\t}\n\tpr_info(\"sparc64 camellia opcodes not available.\\n\");\n\treturn -ENODEV;\n}\n\nstatic void __exit camellia_sparc64_mod_fini(void)\n{\n\tcrypto_unregister_algs(algs, ARRAY_SIZE(algs));\n}\n\nmodule_init(camellia_sparc64_mod_init);\nmodule_exit(camellia_sparc64_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Camellia Cipher Algorithm, sparc64 camellia opcode accelerated\");\n\nMODULE_ALIAS(\"aes\");\n\n#include \"crop_devid.c\"\n", "/* Glue code for CRC32C optimized for sparc64 crypto opcodes.\n *\n * This is based largely upon arch/x86/crypto/crc32c-intel.c\n *\n * Copyright (C) 2008 Intel Corporation\n * Authors: Austin Zhang <austin_zhang@linux.intel.com>\n *          Kent Liu <kent.liu@intel.com>\n */\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n#include <linux/crc32.h>\n\n#include <crypto/internal/hash.h>\n\n#include <asm/pstate.h>\n#include <asm/elf.h>\n\n#include \"opcodes.h\"\n\n/*\n * Setting the seed allows arbitrary accumulators and flexible XOR policy\n * If your algorithm starts with ~0, then XOR with ~0 before you set\n * the seed.\n */\nstatic int crc32c_sparc64_setkey(struct crypto_shash *hash, const u8 *key,\n\t\t\t\t unsigned int keylen)\n{\n\tu32 *mctx = crypto_shash_ctx(hash);\n\n\tif (keylen != sizeof(u32)) {\n\t\tcrypto_shash_set_flags(hash, CRYPTO_TFM_RES_BAD_KEY_LEN);\n\t\treturn -EINVAL;\n\t}\n\t*(__le32 *)mctx = le32_to_cpup((__le32 *)key);\n\treturn 0;\n}\n\nstatic int crc32c_sparc64_init(struct shash_desc *desc)\n{\n\tu32 *mctx = crypto_shash_ctx(desc->tfm);\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t*crcp = *mctx;\n\n\treturn 0;\n}\n\nextern void crc32c_sparc64(u32 *crcp, const u64 *data, unsigned int len);\n\nstatic void crc32c_compute(u32 *crcp, const u64 *data, unsigned int len)\n{\n\tunsigned int asm_len;\n\n\tasm_len = len & ~7U;\n\tif (asm_len) {\n\t\tcrc32c_sparc64(crcp, data, asm_len);\n\t\tdata += asm_len / 8;\n\t\tlen -= asm_len;\n\t}\n\tif (len)\n\t\t*crcp = __crc32c_le(*crcp, (const unsigned char *) data, len);\n}\n\nstatic int crc32c_sparc64_update(struct shash_desc *desc, const u8 *data,\n\t\t\t\t unsigned int len)\n{\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\tcrc32c_compute(crcp, (const u64 *) data, len);\n\n\treturn 0;\n}\n\nstatic int __crc32c_sparc64_finup(u32 *crcp, const u8 *data, unsigned int len,\n\t\t\t\t  u8 *out)\n{\n\tu32 tmp = *crcp;\n\n\tcrc32c_compute(&tmp, (const u64 *) data, len);\n\n\t*(__le32 *) out = ~cpu_to_le32(tmp);\n\treturn 0;\n}\n\nstatic int crc32c_sparc64_finup(struct shash_desc *desc, const u8 *data,\n\t\t\t\tunsigned int len, u8 *out)\n{\n\treturn __crc32c_sparc64_finup(shash_desc_ctx(desc), data, len, out);\n}\n\nstatic int crc32c_sparc64_final(struct shash_desc *desc, u8 *out)\n{\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t*(__le32 *) out = ~cpu_to_le32p(crcp);\n\treturn 0;\n}\n\nstatic int crc32c_sparc64_digest(struct shash_desc *desc, const u8 *data,\n\t\t\t\t unsigned int len, u8 *out)\n{\n\treturn __crc32c_sparc64_finup(crypto_shash_ctx(desc->tfm), data, len,\n\t\t\t\t      out);\n}\n\nstatic int crc32c_sparc64_cra_init(struct crypto_tfm *tfm)\n{\n\tu32 *key = crypto_tfm_ctx(tfm);\n\n\t*key = ~0;\n\n\treturn 0;\n}\n\n#define CHKSUM_BLOCK_SIZE\t1\n#define CHKSUM_DIGEST_SIZE\t4\n\nstatic struct shash_alg alg = {\n\t.setkey\t\t\t=\tcrc32c_sparc64_setkey,\n\t.init\t\t\t=\tcrc32c_sparc64_init,\n\t.update\t\t\t=\tcrc32c_sparc64_update,\n\t.final\t\t\t=\tcrc32c_sparc64_final,\n\t.finup\t\t\t=\tcrc32c_sparc64_finup,\n\t.digest\t\t\t=\tcrc32c_sparc64_digest,\n\t.descsize\t\t=\tsizeof(u32),\n\t.digestsize\t\t=\tCHKSUM_DIGEST_SIZE,\n\t.base\t\t\t=\t{\n\t\t.cra_name\t\t=\t\"crc32c\",\n\t\t.cra_driver_name\t=\t\"crc32c-sparc64\",\n\t\t.cra_priority\t\t=\tSPARC_CR_OPCODE_PRIORITY,\n\t\t.cra_blocksize\t\t=\tCHKSUM_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t=\tsizeof(u32),\n\t\t.cra_alignmask\t\t=\t7,\n\t\t.cra_module\t\t=\tTHIS_MODULE,\n\t\t.cra_init\t\t=\tcrc32c_sparc64_cra_init,\n\t}\n};\n\nstatic bool __init sparc64_has_crc32c_opcode(void)\n{\n\tunsigned long cfr;\n\n\tif (!(sparc64_elf_hwcap & HWCAP_SPARC_CRYPTO))\n\t\treturn false;\n\n\t__asm__ __volatile__(\"rd %%asr26, %0\" : \"=r\" (cfr));\n\tif (!(cfr & CFR_CRC32C))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int __init crc32c_sparc64_mod_init(void)\n{\n\tif (sparc64_has_crc32c_opcode()) {\n\t\tpr_info(\"Using sparc64 crc32c opcode optimized CRC32C implementation\\n\");\n\t\treturn crypto_register_shash(&alg);\n\t}\n\tpr_info(\"sparc64 crc32c opcode not available.\\n\");\n\treturn -ENODEV;\n}\n\nstatic void __exit crc32c_sparc64_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(crc32c_sparc64_mod_init);\nmodule_exit(crc32c_sparc64_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"CRC32c (Castagnoli), sparc64 crc32c opcode accelerated\");\n\nMODULE_ALIAS(\"crc32c\");\n\n#include \"crop_devid.c\"\n", "/* Glue code for DES encryption optimized for sparc64 crypto opcodes.\n *\n * Copyright (C) 2012 David S. Miller <davem@davemloft.net>\n */\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <linux/crypto.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/types.h>\n#include <crypto/algapi.h>\n#include <crypto/des.h>\n\n#include <asm/fpumacro.h>\n#include <asm/pstate.h>\n#include <asm/elf.h>\n\n#include \"opcodes.h\"\n\nstruct des_sparc64_ctx {\n\tu64 encrypt_expkey[DES_EXPKEY_WORDS / 2];\n\tu64 decrypt_expkey[DES_EXPKEY_WORDS / 2];\n};\n\nstruct des3_ede_sparc64_ctx {\n\tu64 encrypt_expkey[DES3_EDE_EXPKEY_WORDS / 2];\n\tu64 decrypt_expkey[DES3_EDE_EXPKEY_WORDS / 2];\n};\n\nstatic void encrypt_to_decrypt(u64 *d, const u64 *e)\n{\n\tconst u64 *s = e + (DES_EXPKEY_WORDS / 2) - 1;\n\tint i;\n\n\tfor (i = 0; i < DES_EXPKEY_WORDS / 2; i++)\n\t\t*d++ = *s--;\n}\n\nextern void des_sparc64_key_expand(const u32 *input_key, u64 *key);\n\nstatic int des_set_key(struct crypto_tfm *tfm, const u8 *key,\n\t\t       unsigned int keylen)\n{\n\tstruct des_sparc64_ctx *dctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tu32 tmp[DES_EXPKEY_WORDS];\n\tint ret;\n\n\t/* Even though we have special instructions for key expansion,\n\t * we call des_ekey() so that we don't have to write our own\n\t * weak key detection code.\n\t */\n\tret = des_ekey(tmp, key);\n\tif (unlikely(ret == 0) && (*flags & CRYPTO_TFM_REQ_WEAK_KEY)) {\n\t\t*flags |= CRYPTO_TFM_RES_WEAK_KEY;\n\t\treturn -EINVAL;\n\t}\n\n\tdes_sparc64_key_expand((const u32 *) key, &dctx->encrypt_expkey[0]);\n\tencrypt_to_decrypt(&dctx->decrypt_expkey[0], &dctx->encrypt_expkey[0]);\n\n\treturn 0;\n}\n\nextern void des_sparc64_crypt(const u64 *key, const u64 *input,\n\t\t\t      u64 *output);\n\nstatic void des_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct des_sparc64_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst u64 *K = ctx->encrypt_expkey;\n\n\tdes_sparc64_crypt(K, (const u64 *) src, (u64 *) dst);\n}\n\nstatic void des_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct des_sparc64_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst u64 *K = ctx->decrypt_expkey;\n\n\tdes_sparc64_crypt(K, (const u64 *) src, (u64 *) dst);\n}\n\nextern void des_sparc64_load_keys(const u64 *key);\n\nextern void des_sparc64_ecb_crypt(const u64 *input, u64 *output,\n\t\t\t\t  unsigned int len);\n\n#define DES_BLOCK_MASK\t(~(DES_BLOCK_SIZE - 1))\n\nstatic int __ecb_crypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes, bool encrypt)\n{\n\tstruct des_sparc64_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tif (encrypt)\n\t\tdes_sparc64_load_keys(&ctx->encrypt_expkey[0]);\n\telse\n\t\tdes_sparc64_load_keys(&ctx->decrypt_expkey[0]);\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & DES_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tdes_sparc64_ecb_crypt((const u64 *)walk.src.virt.addr,\n\t\t\t\t\t      (u64 *) walk.dst.virt.addr,\n\t\t\t\t\t      block_len);\n\t\t}\n\t\tnbytes &= DES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\treturn __ecb_crypt(desc, dst, src, nbytes, true);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\treturn __ecb_crypt(desc, dst, src, nbytes, false);\n}\n\nextern void des_sparc64_cbc_encrypt(const u64 *input, u64 *output,\n\t\t\t\t    unsigned int len, u64 *iv);\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct des_sparc64_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tdes_sparc64_load_keys(&ctx->encrypt_expkey[0]);\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & DES_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tdes_sparc64_cbc_encrypt((const u64 *)walk.src.virt.addr,\n\t\t\t\t\t\t(u64 *) walk.dst.virt.addr,\n\t\t\t\t\t\tblock_len, (u64 *) walk.iv);\n\t\t}\n\t\tnbytes &= DES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nextern void des_sparc64_cbc_decrypt(const u64 *input, u64 *output,\n\t\t\t\t    unsigned int len, u64 *iv);\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct des_sparc64_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tdes_sparc64_load_keys(&ctx->decrypt_expkey[0]);\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & DES_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tdes_sparc64_cbc_decrypt((const u64 *)walk.src.virt.addr,\n\t\t\t\t\t\t(u64 *) walk.dst.virt.addr,\n\t\t\t\t\t\tblock_len, (u64 *) walk.iv);\n\t\t}\n\t\tnbytes &= DES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nstatic int des3_ede_set_key(struct crypto_tfm *tfm, const u8 *key,\n\t\t\t    unsigned int keylen)\n{\n\tstruct des3_ede_sparc64_ctx *dctx = crypto_tfm_ctx(tfm);\n\tconst u32 *K = (const u32 *)key;\n\tu32 *flags = &tfm->crt_flags;\n\tu64 k1[DES_EXPKEY_WORDS / 2];\n\tu64 k2[DES_EXPKEY_WORDS / 2];\n\tu64 k3[DES_EXPKEY_WORDS / 2];\n\n\tif (unlikely(!((K[0] ^ K[2]) | (K[1] ^ K[3])) ||\n\t\t     !((K[2] ^ K[4]) | (K[3] ^ K[5]))) &&\n\t\t     (*flags & CRYPTO_TFM_REQ_WEAK_KEY)) {\n\t\t*flags |= CRYPTO_TFM_RES_WEAK_KEY;\n\t\treturn -EINVAL;\n\t}\n\n\tdes_sparc64_key_expand((const u32 *)key, k1);\n\tkey += DES_KEY_SIZE;\n\tdes_sparc64_key_expand((const u32 *)key, k2);\n\tkey += DES_KEY_SIZE;\n\tdes_sparc64_key_expand((const u32 *)key, k3);\n\n\tmemcpy(&dctx->encrypt_expkey[0], &k1[0], sizeof(k1));\n\tencrypt_to_decrypt(&dctx->encrypt_expkey[DES_EXPKEY_WORDS / 2], &k2[0]);\n\tmemcpy(&dctx->encrypt_expkey[(DES_EXPKEY_WORDS / 2) * 2],\n\t       &k3[0], sizeof(k3));\n\n\tencrypt_to_decrypt(&dctx->decrypt_expkey[0], &k3[0]);\n\tmemcpy(&dctx->decrypt_expkey[DES_EXPKEY_WORDS / 2],\n\t       &k2[0], sizeof(k2));\n\tencrypt_to_decrypt(&dctx->decrypt_expkey[(DES_EXPKEY_WORDS / 2) * 2],\n\t\t\t   &k1[0]);\n\n\treturn 0;\n}\n\nextern void des3_ede_sparc64_crypt(const u64 *key, const u64 *input,\n\t\t\t\t   u64 *output);\n\nstatic void des3_ede_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct des3_ede_sparc64_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst u64 *K = ctx->encrypt_expkey;\n\n\tdes3_ede_sparc64_crypt(K, (const u64 *) src, (u64 *) dst);\n}\n\nstatic void des3_ede_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct des3_ede_sparc64_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst u64 *K = ctx->decrypt_expkey;\n\n\tdes3_ede_sparc64_crypt(K, (const u64 *) src, (u64 *) dst);\n}\n\nextern void des3_ede_sparc64_load_keys(const u64 *key);\n\nextern void des3_ede_sparc64_ecb_crypt(const u64 *expkey, const u64 *input,\n\t\t\t\t       u64 *output, unsigned int len);\n\nstatic int __ecb3_crypt(struct blkcipher_desc *desc,\n\t\t\tstruct scatterlist *dst, struct scatterlist *src,\n\t\t\tunsigned int nbytes, bool encrypt)\n{\n\tstruct des3_ede_sparc64_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tconst u64 *K;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tif (encrypt)\n\t\tK = &ctx->encrypt_expkey[0];\n\telse\n\t\tK = &ctx->decrypt_expkey[0];\n\tdes3_ede_sparc64_load_keys(K);\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & DES_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tconst u64 *src64 = (const u64 *)walk.src.virt.addr;\n\t\t\tdes3_ede_sparc64_ecb_crypt(K, src64,\n\t\t\t\t\t\t   (u64 *) walk.dst.virt.addr,\n\t\t\t\t\t\t   block_len);\n\t\t}\n\t\tnbytes &= DES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nstatic int ecb3_encrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\treturn __ecb3_crypt(desc, dst, src, nbytes, true);\n}\n\nstatic int ecb3_decrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\treturn __ecb3_crypt(desc, dst, src, nbytes, false);\n}\n\nextern void des3_ede_sparc64_cbc_encrypt(const u64 *expkey, const u64 *input,\n\t\t\t\t\t u64 *output, unsigned int len,\n\t\t\t\t\t u64 *iv);\n\nstatic int cbc3_encrypt(struct blkcipher_desc *desc,\n\t\t\tstruct scatterlist *dst, struct scatterlist *src,\n\t\t\tunsigned int nbytes)\n{\n\tstruct des3_ede_sparc64_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tconst u64 *K;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tK = &ctx->encrypt_expkey[0];\n\tdes3_ede_sparc64_load_keys(K);\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & DES_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tconst u64 *src64 = (const u64 *)walk.src.virt.addr;\n\t\t\tdes3_ede_sparc64_cbc_encrypt(K, src64,\n\t\t\t\t\t\t     (u64 *) walk.dst.virt.addr,\n\t\t\t\t\t\t     block_len,\n\t\t\t\t\t\t     (u64 *) walk.iv);\n\t\t}\n\t\tnbytes &= DES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nextern void des3_ede_sparc64_cbc_decrypt(const u64 *expkey, const u64 *input,\n\t\t\t\t\t u64 *output, unsigned int len,\n\t\t\t\t\t u64 *iv);\n\nstatic int cbc3_decrypt(struct blkcipher_desc *desc,\n\t\t\tstruct scatterlist *dst, struct scatterlist *src,\n\t\t\tunsigned int nbytes)\n{\n\tstruct des3_ede_sparc64_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tconst u64 *K;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tK = &ctx->decrypt_expkey[0];\n\tdes3_ede_sparc64_load_keys(K);\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & DES_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tconst u64 *src64 = (const u64 *)walk.src.virt.addr;\n\t\t\tdes3_ede_sparc64_cbc_decrypt(K, src64,\n\t\t\t\t\t\t     (u64 *) walk.dst.virt.addr,\n\t\t\t\t\t\t     block_len,\n\t\t\t\t\t\t     (u64 *) walk.iv);\n\t\t}\n\t\tnbytes &= DES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nstatic struct crypto_alg algs[] = { {\n\t.cra_name\t\t= \"des\",\n\t.cra_driver_name\t= \"des-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= DES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct des_sparc64_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u\t= {\n\t\t.cipher\t= {\n\t\t\t.cia_min_keysize\t= DES_KEY_SIZE,\n\t\t\t.cia_max_keysize\t= DES_KEY_SIZE,\n\t\t\t.cia_setkey\t\t= des_set_key,\n\t\t\t.cia_encrypt\t\t= des_encrypt,\n\t\t\t.cia_decrypt\t\t= des_decrypt\n\t\t}\n\t}\n}, {\n\t.cra_name\t\t= \"ecb(des)\",\n\t.cra_driver_name\t= \"ecb-des-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= DES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct des_sparc64_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= DES_KEY_SIZE,\n\t\t\t.max_keysize\t= DES_KEY_SIZE,\n\t\t\t.setkey\t\t= des_set_key,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(des)\",\n\t.cra_driver_name\t= \"cbc-des-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= DES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct des_sparc64_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= DES_KEY_SIZE,\n\t\t\t.max_keysize\t= DES_KEY_SIZE,\n\t\t\t.setkey\t\t= des_set_key,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"des3_ede\",\n\t.cra_driver_name\t= \"des3_ede-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= DES3_EDE_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct des3_ede_sparc64_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u\t= {\n\t\t.cipher\t= {\n\t\t\t.cia_min_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.cia_max_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.cia_setkey\t\t= des3_ede_set_key,\n\t\t\t.cia_encrypt\t\t= des3_ede_encrypt,\n\t\t\t.cia_decrypt\t\t= des3_ede_decrypt\n\t\t}\n\t}\n}, {\n\t.cra_name\t\t= \"ecb(des3_ede)\",\n\t.cra_driver_name\t= \"ecb-des3_ede-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= DES3_EDE_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct des3_ede_sparc64_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.max_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.setkey\t\t= des3_ede_set_key,\n\t\t\t.encrypt\t= ecb3_encrypt,\n\t\t\t.decrypt\t= ecb3_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(des3_ede)\",\n\t.cra_driver_name\t= \"cbc-des3_ede-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= DES3_EDE_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct des3_ede_sparc64_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.max_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.setkey\t\t= des3_ede_set_key,\n\t\t\t.encrypt\t= cbc3_encrypt,\n\t\t\t.decrypt\t= cbc3_decrypt,\n\t\t},\n\t},\n} };\n\nstatic bool __init sparc64_has_des_opcode(void)\n{\n\tunsigned long cfr;\n\n\tif (!(sparc64_elf_hwcap & HWCAP_SPARC_CRYPTO))\n\t\treturn false;\n\n\t__asm__ __volatile__(\"rd %%asr26, %0\" : \"=r\" (cfr));\n\tif (!(cfr & CFR_DES))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int __init des_sparc64_mod_init(void)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(algs); i++)\n\t\tINIT_LIST_HEAD(&algs[i].cra_list);\n\n\tif (sparc64_has_des_opcode()) {\n\t\tpr_info(\"Using sparc64 des opcodes optimized DES implementation\\n\");\n\t\treturn crypto_register_algs(algs, ARRAY_SIZE(algs));\n\t}\n\tpr_info(\"sparc64 des opcodes not available.\\n\");\n\treturn -ENODEV;\n}\n\nstatic void __exit des_sparc64_mod_fini(void)\n{\n\tcrypto_unregister_algs(algs, ARRAY_SIZE(algs));\n}\n\nmodule_init(des_sparc64_mod_init);\nmodule_exit(des_sparc64_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"DES & Triple DES EDE Cipher Algorithms, sparc64 des opcode accelerated\");\n\nMODULE_ALIAS(\"des\");\n\n#include \"crop_devid.c\"\n", "/* Glue code for MD5 hashing optimized for sparc64 crypto opcodes.\n *\n * This is based largely upon arch/x86/crypto/sha1_ssse3_glue.c\n * and crypto/md5.c which are:\n *\n * Copyright (c) Alan Smithee.\n * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n * Copyright (c) Jean-Francois Dive <jef@linuxbe.org>\n * Copyright (c) Mathias Krause <minipli@googlemail.com>\n * Copyright (c) Cryptoapi developers.\n * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>\n */\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <crypto/md5.h>\n\n#include <asm/pstate.h>\n#include <asm/elf.h>\n\n#include \"opcodes.h\"\n\nasmlinkage void md5_sparc64_transform(u32 *digest, const char *data,\n\t\t\t\t      unsigned int rounds);\n\nstatic int md5_sparc64_init(struct shash_desc *desc)\n{\n\tstruct md5_state *mctx = shash_desc_ctx(desc);\n\n\tmctx->hash[0] = cpu_to_le32(0x67452301);\n\tmctx->hash[1] = cpu_to_le32(0xefcdab89);\n\tmctx->hash[2] = cpu_to_le32(0x98badcfe);\n\tmctx->hash[3] = cpu_to_le32(0x10325476);\n\tmctx->byte_count = 0;\n\n\treturn 0;\n}\n\nstatic void __md5_sparc64_update(struct md5_state *sctx, const u8 *data,\n\t\t\t\t unsigned int len, unsigned int partial)\n{\n\tunsigned int done = 0;\n\n\tsctx->byte_count += len;\n\tif (partial) {\n\t\tdone = MD5_HMAC_BLOCK_SIZE - partial;\n\t\tmemcpy((u8 *)sctx->block + partial, data, done);\n\t\tmd5_sparc64_transform(sctx->hash, (u8 *)sctx->block, 1);\n\t}\n\tif (len - done >= MD5_HMAC_BLOCK_SIZE) {\n\t\tconst unsigned int rounds = (len - done) / MD5_HMAC_BLOCK_SIZE;\n\n\t\tmd5_sparc64_transform(sctx->hash, data + done, rounds);\n\t\tdone += rounds * MD5_HMAC_BLOCK_SIZE;\n\t}\n\n\tmemcpy(sctx->block, data + done, len - done);\n}\n\nstatic int md5_sparc64_update(struct shash_desc *desc, const u8 *data,\n\t\t\t      unsigned int len)\n{\n\tstruct md5_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial = sctx->byte_count % MD5_HMAC_BLOCK_SIZE;\n\n\t/* Handle the fast case right here */\n\tif (partial + len < MD5_HMAC_BLOCK_SIZE) {\n\t\tsctx->byte_count += len;\n\t\tmemcpy((u8 *)sctx->block + partial, data, len);\n\t} else\n\t\t__md5_sparc64_update(sctx, data, len, partial);\n\n\treturn 0;\n}\n\n/* Add padding and return the message digest. */\nstatic int md5_sparc64_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct md5_state *sctx = shash_desc_ctx(desc);\n\tunsigned int i, index, padlen;\n\tu32 *dst = (u32 *)out;\n\t__le64 bits;\n\tstatic const u8 padding[MD5_HMAC_BLOCK_SIZE] = { 0x80, };\n\n\tbits = cpu_to_le64(sctx->byte_count << 3);\n\n\t/* Pad out to 56 mod 64 and append length */\n\tindex = sctx->byte_count % MD5_HMAC_BLOCK_SIZE;\n\tpadlen = (index < 56) ? (56 - index) : ((MD5_HMAC_BLOCK_SIZE+56) - index);\n\n\t/* We need to fill a whole block for __md5_sparc64_update() */\n\tif (padlen <= 56) {\n\t\tsctx->byte_count += padlen;\n\t\tmemcpy((u8 *)sctx->block + index, padding, padlen);\n\t} else {\n\t\t__md5_sparc64_update(sctx, padding, padlen, index);\n\t}\n\t__md5_sparc64_update(sctx, (const u8 *)&bits, sizeof(bits), 56);\n\n\t/* Store state in digest */\n\tfor (i = 0; i < MD5_HASH_WORDS; i++)\n\t\tdst[i] = sctx->hash[i];\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int md5_sparc64_export(struct shash_desc *desc, void *out)\n{\n\tstruct md5_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int md5_sparc64_import(struct shash_desc *desc, const void *in)\n{\n\tstruct md5_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tMD5_DIGEST_SIZE,\n\t.init\t\t=\tmd5_sparc64_init,\n\t.update\t\t=\tmd5_sparc64_update,\n\t.final\t\t=\tmd5_sparc64_final,\n\t.export\t\t=\tmd5_sparc64_export,\n\t.import\t\t=\tmd5_sparc64_import,\n\t.descsize\t=\tsizeof(struct md5_state),\n\t.statesize\t=\tsizeof(struct md5_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"md5\",\n\t\t.cra_driver_name=\t\"md5-sparc64\",\n\t\t.cra_priority\t=\tSPARC_CR_OPCODE_PRIORITY,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tMD5_HMAC_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic bool __init sparc64_has_md5_opcode(void)\n{\n\tunsigned long cfr;\n\n\tif (!(sparc64_elf_hwcap & HWCAP_SPARC_CRYPTO))\n\t\treturn false;\n\n\t__asm__ __volatile__(\"rd %%asr26, %0\" : \"=r\" (cfr));\n\tif (!(cfr & CFR_MD5))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int __init md5_sparc64_mod_init(void)\n{\n\tif (sparc64_has_md5_opcode()) {\n\t\tpr_info(\"Using sparc64 md5 opcode optimized MD5 implementation\\n\");\n\t\treturn crypto_register_shash(&alg);\n\t}\n\tpr_info(\"sparc64 md5 opcode not available.\\n\");\n\treturn -ENODEV;\n}\n\nstatic void __exit md5_sparc64_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(md5_sparc64_mod_init);\nmodule_exit(md5_sparc64_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"MD5 Secure Hash Algorithm, sparc64 md5 opcode accelerated\");\n\nMODULE_ALIAS(\"md5\");\n\n#include \"crop_devid.c\"\n", "/* Glue code for SHA1 hashing optimized for sparc64 crypto opcodes.\n *\n * This is based largely upon arch/x86/crypto/sha1_ssse3_glue.c\n *\n * Copyright (c) Alan Smithee.\n * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n * Copyright (c) Jean-Francois Dive <jef@linuxbe.org>\n * Copyright (c) Mathias Krause <minipli@googlemail.com>\n */\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n\n#include <asm/pstate.h>\n#include <asm/elf.h>\n\n#include \"opcodes.h\"\n\nasmlinkage void sha1_sparc64_transform(u32 *digest, const char *data,\n\t\t\t\t       unsigned int rounds);\n\nstatic int sha1_sparc64_init(struct shash_desc *desc)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\t*sctx = (struct sha1_state){\n\t\t.state = { SHA1_H0, SHA1_H1, SHA1_H2, SHA1_H3, SHA1_H4 },\n\t};\n\n\treturn 0;\n}\n\nstatic void __sha1_sparc64_update(struct sha1_state *sctx, const u8 *data,\n\t\t\t\t  unsigned int len, unsigned int partial)\n{\n\tunsigned int done = 0;\n\n\tsctx->count += len;\n\tif (partial) {\n\t\tdone = SHA1_BLOCK_SIZE - partial;\n\t\tmemcpy(sctx->buffer + partial, data, done);\n\t\tsha1_sparc64_transform(sctx->state, sctx->buffer, 1);\n\t}\n\tif (len - done >= SHA1_BLOCK_SIZE) {\n\t\tconst unsigned int rounds = (len - done) / SHA1_BLOCK_SIZE;\n\n\t\tsha1_sparc64_transform(sctx->state, data + done, rounds);\n\t\tdone += rounds * SHA1_BLOCK_SIZE;\n\t}\n\n\tmemcpy(sctx->buffer, data + done, len - done);\n}\n\nstatic int sha1_sparc64_update(struct shash_desc *desc, const u8 *data,\n\t\t\t       unsigned int len)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial = sctx->count % SHA1_BLOCK_SIZE;\n\n\t/* Handle the fast case right here */\n\tif (partial + len < SHA1_BLOCK_SIZE) {\n\t\tsctx->count += len;\n\t\tmemcpy(sctx->buffer + partial, data, len);\n\t} else\n\t\t__sha1_sparc64_update(sctx, data, len, partial);\n\n\treturn 0;\n}\n\n/* Add padding and return the message digest. */\nstatic int sha1_sparc64_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int i, index, padlen;\n\t__be32 *dst = (__be32 *)out;\n\t__be64 bits;\n\tstatic const u8 padding[SHA1_BLOCK_SIZE] = { 0x80, };\n\n\tbits = cpu_to_be64(sctx->count << 3);\n\n\t/* Pad out to 56 mod 64 and append length */\n\tindex = sctx->count % SHA1_BLOCK_SIZE;\n\tpadlen = (index < 56) ? (56 - index) : ((SHA1_BLOCK_SIZE+56) - index);\n\n\t/* We need to fill a whole block for __sha1_sparc64_update() */\n\tif (padlen <= 56) {\n\t\tsctx->count += padlen;\n\t\tmemcpy(sctx->buffer + index, padding, padlen);\n\t} else {\n\t\t__sha1_sparc64_update(sctx, padding, padlen, index);\n\t}\n\t__sha1_sparc64_update(sctx, (const u8 *)&bits, sizeof(bits), 56);\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 5; i++)\n\t\tdst[i] = cpu_to_be32(sctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha1_sparc64_export(struct shash_desc *desc, void *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha1_sparc64_import(struct shash_desc *desc, const void *in)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tSHA1_DIGEST_SIZE,\n\t.init\t\t=\tsha1_sparc64_init,\n\t.update\t\t=\tsha1_sparc64_update,\n\t.final\t\t=\tsha1_sparc64_final,\n\t.export\t\t=\tsha1_sparc64_export,\n\t.import\t\t=\tsha1_sparc64_import,\n\t.descsize\t=\tsizeof(struct sha1_state),\n\t.statesize\t=\tsizeof(struct sha1_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha1\",\n\t\t.cra_driver_name=\t\"sha1-sparc64\",\n\t\t.cra_priority\t=\tSPARC_CR_OPCODE_PRIORITY,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA1_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic bool __init sparc64_has_sha1_opcode(void)\n{\n\tunsigned long cfr;\n\n\tif (!(sparc64_elf_hwcap & HWCAP_SPARC_CRYPTO))\n\t\treturn false;\n\n\t__asm__ __volatile__(\"rd %%asr26, %0\" : \"=r\" (cfr));\n\tif (!(cfr & CFR_SHA1))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int __init sha1_sparc64_mod_init(void)\n{\n\tif (sparc64_has_sha1_opcode()) {\n\t\tpr_info(\"Using sparc64 sha1 opcode optimized SHA-1 implementation\\n\");\n\t\treturn crypto_register_shash(&alg);\n\t}\n\tpr_info(\"sparc64 sha1 opcode not available.\\n\");\n\treturn -ENODEV;\n}\n\nstatic void __exit sha1_sparc64_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(sha1_sparc64_mod_init);\nmodule_exit(sha1_sparc64_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA1 Secure Hash Algorithm, sparc64 sha1 opcode accelerated\");\n\nMODULE_ALIAS(\"sha1\");\n\n#include \"crop_devid.c\"\n", "/* Glue code for SHA256 hashing optimized for sparc64 crypto opcodes.\n *\n * This is based largely upon crypto/sha256_generic.c\n *\n * Copyright (c) Jean-Luc Cooke <jlcooke@certainkey.com>\n * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>\n * SHA224 Support Copyright 2007 Intel Corporation <jonathan.lynch@intel.com>\n */\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n\n#include <asm/pstate.h>\n#include <asm/elf.h>\n\n#include \"opcodes.h\"\n\nasmlinkage void sha256_sparc64_transform(u32 *digest, const char *data,\n\t\t\t\t\t unsigned int rounds);\n\nstatic int sha224_sparc64_init(struct shash_desc *desc)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\tsctx->state[0] = SHA224_H0;\n\tsctx->state[1] = SHA224_H1;\n\tsctx->state[2] = SHA224_H2;\n\tsctx->state[3] = SHA224_H3;\n\tsctx->state[4] = SHA224_H4;\n\tsctx->state[5] = SHA224_H5;\n\tsctx->state[6] = SHA224_H6;\n\tsctx->state[7] = SHA224_H7;\n\tsctx->count = 0;\n\n\treturn 0;\n}\n\nstatic int sha256_sparc64_init(struct shash_desc *desc)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\tsctx->state[0] = SHA256_H0;\n\tsctx->state[1] = SHA256_H1;\n\tsctx->state[2] = SHA256_H2;\n\tsctx->state[3] = SHA256_H3;\n\tsctx->state[4] = SHA256_H4;\n\tsctx->state[5] = SHA256_H5;\n\tsctx->state[6] = SHA256_H6;\n\tsctx->state[7] = SHA256_H7;\n\tsctx->count = 0;\n\n\treturn 0;\n}\n\nstatic void __sha256_sparc64_update(struct sha256_state *sctx, const u8 *data,\n\t\t\t\t    unsigned int len, unsigned int partial)\n{\n\tunsigned int done = 0;\n\n\tsctx->count += len;\n\tif (partial) {\n\t\tdone = SHA256_BLOCK_SIZE - partial;\n\t\tmemcpy(sctx->buf + partial, data, done);\n\t\tsha256_sparc64_transform(sctx->state, sctx->buf, 1);\n\t}\n\tif (len - done >= SHA256_BLOCK_SIZE) {\n\t\tconst unsigned int rounds = (len - done) / SHA256_BLOCK_SIZE;\n\n\t\tsha256_sparc64_transform(sctx->state, data + done, rounds);\n\t\tdone += rounds * SHA256_BLOCK_SIZE;\n\t}\n\n\tmemcpy(sctx->buf, data + done, len - done);\n}\n\nstatic int sha256_sparc64_update(struct shash_desc *desc, const u8 *data,\n\t\t\t\t unsigned int len)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial = sctx->count % SHA256_BLOCK_SIZE;\n\n\t/* Handle the fast case right here */\n\tif (partial + len < SHA256_BLOCK_SIZE) {\n\t\tsctx->count += len;\n\t\tmemcpy(sctx->buf + partial, data, len);\n\t} else\n\t\t__sha256_sparc64_update(sctx, data, len, partial);\n\n\treturn 0;\n}\n\nstatic int sha256_sparc64_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\tunsigned int i, index, padlen;\n\t__be32 *dst = (__be32 *)out;\n\t__be64 bits;\n\tstatic const u8 padding[SHA256_BLOCK_SIZE] = { 0x80, };\n\n\tbits = cpu_to_be64(sctx->count << 3);\n\n\t/* Pad out to 56 mod 64 and append length */\n\tindex = sctx->count % SHA256_BLOCK_SIZE;\n\tpadlen = (index < 56) ? (56 - index) : ((SHA256_BLOCK_SIZE+56) - index);\n\n\t/* We need to fill a whole block for __sha256_sparc64_update() */\n\tif (padlen <= 56) {\n\t\tsctx->count += padlen;\n\t\tmemcpy(sctx->buf + index, padding, padlen);\n\t} else {\n\t\t__sha256_sparc64_update(sctx, padding, padlen, index);\n\t}\n\t__sha256_sparc64_update(sctx, (const u8 *)&bits, sizeof(bits), 56);\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 8; i++)\n\t\tdst[i] = cpu_to_be32(sctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha224_sparc64_final(struct shash_desc *desc, u8 *hash)\n{\n\tu8 D[SHA256_DIGEST_SIZE];\n\n\tsha256_sparc64_final(desc, D);\n\n\tmemcpy(hash, D, SHA224_DIGEST_SIZE);\n\tmemset(D, 0, SHA256_DIGEST_SIZE);\n\n\treturn 0;\n}\n\nstatic int sha256_sparc64_export(struct shash_desc *desc, void *out)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, sizeof(*sctx));\n\treturn 0;\n}\n\nstatic int sha256_sparc64_import(struct shash_desc *desc, const void *in)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, sizeof(*sctx));\n\treturn 0;\n}\n\nstatic struct shash_alg sha256 = {\n\t.digestsize\t=\tSHA256_DIGEST_SIZE,\n\t.init\t\t=\tsha256_sparc64_init,\n\t.update\t\t=\tsha256_sparc64_update,\n\t.final\t\t=\tsha256_sparc64_final,\n\t.export\t\t=\tsha256_sparc64_export,\n\t.import\t\t=\tsha256_sparc64_import,\n\t.descsize\t=\tsizeof(struct sha256_state),\n\t.statesize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha256\",\n\t\t.cra_driver_name=\t\"sha256-sparc64\",\n\t\t.cra_priority\t=\tSPARC_CR_OPCODE_PRIORITY,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA256_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic struct shash_alg sha224 = {\n\t.digestsize\t=\tSHA224_DIGEST_SIZE,\n\t.init\t\t=\tsha224_sparc64_init,\n\t.update\t\t=\tsha256_sparc64_update,\n\t.final\t\t=\tsha224_sparc64_final,\n\t.descsize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha224\",\n\t\t.cra_driver_name=\t\"sha224-sparc64\",\n\t\t.cra_priority\t=\tSPARC_CR_OPCODE_PRIORITY,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA224_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic bool __init sparc64_has_sha256_opcode(void)\n{\n\tunsigned long cfr;\n\n\tif (!(sparc64_elf_hwcap & HWCAP_SPARC_CRYPTO))\n\t\treturn false;\n\n\t__asm__ __volatile__(\"rd %%asr26, %0\" : \"=r\" (cfr));\n\tif (!(cfr & CFR_SHA256))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int __init sha256_sparc64_mod_init(void)\n{\n\tif (sparc64_has_sha256_opcode()) {\n\t\tint ret = crypto_register_shash(&sha224);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tret = crypto_register_shash(&sha256);\n\t\tif (ret < 0) {\n\t\t\tcrypto_unregister_shash(&sha224);\n\t\t\treturn ret;\n\t\t}\n\n\t\tpr_info(\"Using sparc64 sha256 opcode optimized SHA-256/SHA-224 implementation\\n\");\n\t\treturn 0;\n\t}\n\tpr_info(\"sparc64 sha256 opcode not available.\\n\");\n\treturn -ENODEV;\n}\n\nstatic void __exit sha256_sparc64_mod_fini(void)\n{\n\tcrypto_unregister_shash(&sha224);\n\tcrypto_unregister_shash(&sha256);\n}\n\nmodule_init(sha256_sparc64_mod_init);\nmodule_exit(sha256_sparc64_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA-224 and SHA-256 Secure Hash Algorithm, sparc64 sha256 opcode accelerated\");\n\nMODULE_ALIAS(\"sha224\");\nMODULE_ALIAS(\"sha256\");\n\n#include \"crop_devid.c\"\n", "/* Glue code for SHA512 hashing optimized for sparc64 crypto opcodes.\n *\n * This is based largely upon crypto/sha512_generic.c\n *\n * Copyright (c) Jean-Luc Cooke <jlcooke@certainkey.com>\n * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n * Copyright (c) 2003 Kyle McMartin <kyle@debian.org>\n */\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n\n#include <asm/pstate.h>\n#include <asm/elf.h>\n\n#include \"opcodes.h\"\n\nasmlinkage void sha512_sparc64_transform(u64 *digest, const char *data,\n\t\t\t\t\t unsigned int rounds);\n\nstatic int sha512_sparc64_init(struct shash_desc *desc)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tsctx->state[0] = SHA512_H0;\n\tsctx->state[1] = SHA512_H1;\n\tsctx->state[2] = SHA512_H2;\n\tsctx->state[3] = SHA512_H3;\n\tsctx->state[4] = SHA512_H4;\n\tsctx->state[5] = SHA512_H5;\n\tsctx->state[6] = SHA512_H6;\n\tsctx->state[7] = SHA512_H7;\n\tsctx->count[0] = sctx->count[1] = 0;\n\n\treturn 0;\n}\n\nstatic int sha384_sparc64_init(struct shash_desc *desc)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tsctx->state[0] = SHA384_H0;\n\tsctx->state[1] = SHA384_H1;\n\tsctx->state[2] = SHA384_H2;\n\tsctx->state[3] = SHA384_H3;\n\tsctx->state[4] = SHA384_H4;\n\tsctx->state[5] = SHA384_H5;\n\tsctx->state[6] = SHA384_H6;\n\tsctx->state[7] = SHA384_H7;\n\tsctx->count[0] = sctx->count[1] = 0;\n\n\treturn 0;\n}\n\nstatic void __sha512_sparc64_update(struct sha512_state *sctx, const u8 *data,\n\t\t\t\t    unsigned int len, unsigned int partial)\n{\n\tunsigned int done = 0;\n\n\tif ((sctx->count[0] += len) < len)\n\t\tsctx->count[1]++;\n\tif (partial) {\n\t\tdone = SHA512_BLOCK_SIZE - partial;\n\t\tmemcpy(sctx->buf + partial, data, done);\n\t\tsha512_sparc64_transform(sctx->state, sctx->buf, 1);\n\t}\n\tif (len - done >= SHA512_BLOCK_SIZE) {\n\t\tconst unsigned int rounds = (len - done) / SHA512_BLOCK_SIZE;\n\n\t\tsha512_sparc64_transform(sctx->state, data + done, rounds);\n\t\tdone += rounds * SHA512_BLOCK_SIZE;\n\t}\n\n\tmemcpy(sctx->buf, data + done, len - done);\n}\n\nstatic int sha512_sparc64_update(struct shash_desc *desc, const u8 *data,\n\t\t\t\t unsigned int len)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial = sctx->count[0] % SHA512_BLOCK_SIZE;\n\n\t/* Handle the fast case right here */\n\tif (partial + len < SHA512_BLOCK_SIZE) {\n\t\tif ((sctx->count[0] += len) < len)\n\t\t\tsctx->count[1]++;\n\t\tmemcpy(sctx->buf + partial, data, len);\n\t} else\n\t\t__sha512_sparc64_update(sctx, data, len, partial);\n\n\treturn 0;\n}\n\nstatic int sha512_sparc64_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tunsigned int i, index, padlen;\n\t__be64 *dst = (__be64 *)out;\n\t__be64 bits[2];\n\tstatic const u8 padding[SHA512_BLOCK_SIZE] = { 0x80, };\n\n\t/* Save number of bits */\n\tbits[1] = cpu_to_be64(sctx->count[0] << 3);\n\tbits[0] = cpu_to_be64(sctx->count[1] << 3 | sctx->count[0] >> 61);\n\n\t/* Pad out to 112 mod 128 and append length */\n\tindex = sctx->count[0] % SHA512_BLOCK_SIZE;\n\tpadlen = (index < 112) ? (112 - index) : ((SHA512_BLOCK_SIZE+112) - index);\n\n\t/* We need to fill a whole block for __sha512_sparc64_update() */\n\tif (padlen <= 112) {\n\t\tif ((sctx->count[0] += padlen) < padlen)\n\t\t\tsctx->count[1]++;\n\t\tmemcpy(sctx->buf + index, padding, padlen);\n\t} else {\n\t\t__sha512_sparc64_update(sctx, padding, padlen, index);\n\t}\n\t__sha512_sparc64_update(sctx, (const u8 *)&bits, sizeof(bits), 112);\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 8; i++)\n\t\tdst[i] = cpu_to_be64(sctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha384_sparc64_final(struct shash_desc *desc, u8 *hash)\n{\n\tu8 D[64];\n\n\tsha512_sparc64_final(desc, D);\n\n\tmemcpy(hash, D, 48);\n\tmemset(D, 0, 64);\n\n\treturn 0;\n}\n\nstatic struct shash_alg sha512 = {\n\t.digestsize\t=\tSHA512_DIGEST_SIZE,\n\t.init\t\t=\tsha512_sparc64_init,\n\t.update\t\t=\tsha512_sparc64_update,\n\t.final\t\t=\tsha512_sparc64_final,\n\t.descsize\t=\tsizeof(struct sha512_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha512\",\n\t\t.cra_driver_name=\t\"sha512-sparc64\",\n\t\t.cra_priority\t=\tSPARC_CR_OPCODE_PRIORITY,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA512_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic struct shash_alg sha384 = {\n\t.digestsize\t=\tSHA384_DIGEST_SIZE,\n\t.init\t\t=\tsha384_sparc64_init,\n\t.update\t\t=\tsha512_sparc64_update,\n\t.final\t\t=\tsha384_sparc64_final,\n\t.descsize\t=\tsizeof(struct sha512_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha384\",\n\t\t.cra_driver_name=\t\"sha384-sparc64\",\n\t\t.cra_priority\t=\tSPARC_CR_OPCODE_PRIORITY,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA384_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic bool __init sparc64_has_sha512_opcode(void)\n{\n\tunsigned long cfr;\n\n\tif (!(sparc64_elf_hwcap & HWCAP_SPARC_CRYPTO))\n\t\treturn false;\n\n\t__asm__ __volatile__(\"rd %%asr26, %0\" : \"=r\" (cfr));\n\tif (!(cfr & CFR_SHA512))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int __init sha512_sparc64_mod_init(void)\n{\n\tif (sparc64_has_sha512_opcode()) {\n\t\tint ret = crypto_register_shash(&sha384);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tret = crypto_register_shash(&sha512);\n\t\tif (ret < 0) {\n\t\t\tcrypto_unregister_shash(&sha384);\n\t\t\treturn ret;\n\t\t}\n\n\t\tpr_info(\"Using sparc64 sha512 opcode optimized SHA-512/SHA-384 implementation\\n\");\n\t\treturn 0;\n\t}\n\tpr_info(\"sparc64 sha512 opcode not available.\\n\");\n\treturn -ENODEV;\n}\n\nstatic void __exit sha512_sparc64_mod_fini(void)\n{\n\tcrypto_unregister_shash(&sha384);\n\tcrypto_unregister_shash(&sha512);\n}\n\nmodule_init(sha512_sparc64_mod_init);\nmodule_exit(sha512_sparc64_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA-384 and SHA-512 Secure Hash Algorithm, sparc64 sha512 opcode accelerated\");\n\nMODULE_ALIAS(\"sha384\");\nMODULE_ALIAS(\"sha512\");\n\n#include \"crop_devid.c\"\n", "/*\n * Glue Code for the asm optimized version of the AES Cipher Algorithm\n *\n */\n\n#include <linux/module.h>\n#include <crypto/aes.h>\n#include <asm/crypto/aes.h>\n\nasmlinkage void aes_enc_blk(struct crypto_aes_ctx *ctx, u8 *out, const u8 *in);\nasmlinkage void aes_dec_blk(struct crypto_aes_ctx *ctx, u8 *out, const u8 *in);\n\nvoid crypto_aes_encrypt_x86(struct crypto_aes_ctx *ctx, u8 *dst, const u8 *src)\n{\n\taes_enc_blk(ctx, dst, src);\n}\nEXPORT_SYMBOL_GPL(crypto_aes_encrypt_x86);\n\nvoid crypto_aes_decrypt_x86(struct crypto_aes_ctx *ctx, u8 *dst, const u8 *src)\n{\n\taes_dec_blk(ctx, dst, src);\n}\nEXPORT_SYMBOL_GPL(crypto_aes_decrypt_x86);\n\nstatic void aes_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\taes_enc_blk(crypto_tfm_ctx(tfm), dst, src);\n}\n\nstatic void aes_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\taes_dec_blk(crypto_tfm_ctx(tfm), dst, src);\n}\n\nstatic struct crypto_alg aes_alg = {\n\t.cra_name\t\t= \"aes\",\n\t.cra_driver_name\t= \"aes-asm\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_aes_ctx),\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u\t= {\n\t\t.cipher\t= {\n\t\t\t.cia_min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t= crypto_aes_set_key,\n\t\t\t.cia_encrypt\t\t= aes_encrypt,\n\t\t\t.cia_decrypt\t\t= aes_decrypt\n\t\t}\n\t}\n};\n\nstatic int __init aes_init(void)\n{\n\treturn crypto_register_alg(&aes_alg);\n}\n\nstatic void __exit aes_fini(void)\n{\n\tcrypto_unregister_alg(&aes_alg);\n}\n\nmodule_init(aes_init);\nmodule_exit(aes_fini);\n\nMODULE_DESCRIPTION(\"Rijndael (AES) Cipher Algorithm, asm optimized\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS(\"aes\");\nMODULE_ALIAS(\"aes-asm\");\n", "/*\n * Support for Intel AES-NI instructions. This file contains glue\n * code, the real AES implementation is in intel-aes_asm.S.\n *\n * Copyright (C) 2008, Intel Corp.\n *    Author: Huang Ying <ying.huang@intel.com>\n *\n * Added RFC4106 AES-GCM support for 128-bit keys under the AEAD\n * interface for 64-bit kernels.\n *    Authors: Adrian Hoban <adrian.hoban@intel.com>\n *             Gabriele Paoloni <gabriele.paoloni@intel.com>\n *             Tadeusz Struk (tadeusz.struk@intel.com)\n *             Aidan O'Mahony (aidan.o.mahony@intel.com)\n *    Copyright (c) 2010, Intel Corporation.\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n */\n\n#include <linux/hardirq.h>\n#include <linux/types.h>\n#include <linux/crypto.h>\n#include <linux/module.h>\n#include <linux/err.h>\n#include <crypto/algapi.h>\n#include <crypto/aes.h>\n#include <crypto/cryptd.h>\n#include <crypto/ctr.h>\n#include <crypto/b128ops.h>\n#include <crypto/lrw.h>\n#include <crypto/xts.h>\n#include <asm/cpu_device_id.h>\n#include <asm/i387.h>\n#include <asm/crypto/aes.h>\n#include <crypto/ablk_helper.h>\n#include <crypto/scatterwalk.h>\n#include <crypto/internal/aead.h>\n#include <linux/workqueue.h>\n#include <linux/spinlock.h>\n#ifdef CONFIG_X86_64\n#include <asm/crypto/glue_helper.h>\n#endif\n\n/* This data is stored at the end of the crypto_tfm struct.\n * It's a type of per \"session\" data storage location.\n * This needs to be 16 byte aligned.\n */\nstruct aesni_rfc4106_gcm_ctx {\n\tu8 hash_subkey[16];\n\tstruct crypto_aes_ctx aes_key_expanded;\n\tu8 nonce[4];\n\tstruct cryptd_aead *cryptd_tfm;\n};\n\nstruct aesni_gcm_set_hash_subkey_result {\n\tint err;\n\tstruct completion completion;\n};\n\nstruct aesni_hash_subkey_req_data {\n\tu8 iv[16];\n\tstruct aesni_gcm_set_hash_subkey_result result;\n\tstruct scatterlist sg;\n};\n\n#define AESNI_ALIGN\t(16)\n#define AES_BLOCK_MASK\t(~(AES_BLOCK_SIZE-1))\n#define RFC4106_HASH_SUBKEY_SIZE 16\n\nstruct aesni_lrw_ctx {\n\tstruct lrw_table_ctx lrw_table;\n\tu8 raw_aes_ctx[sizeof(struct crypto_aes_ctx) + AESNI_ALIGN - 1];\n};\n\nstruct aesni_xts_ctx {\n\tu8 raw_tweak_ctx[sizeof(struct crypto_aes_ctx) + AESNI_ALIGN - 1];\n\tu8 raw_crypt_ctx[sizeof(struct crypto_aes_ctx) + AESNI_ALIGN - 1];\n};\n\nasmlinkage int aesni_set_key(struct crypto_aes_ctx *ctx, const u8 *in_key,\n\t\t\t     unsigned int key_len);\nasmlinkage void aesni_enc(struct crypto_aes_ctx *ctx, u8 *out,\n\t\t\t  const u8 *in);\nasmlinkage void aesni_dec(struct crypto_aes_ctx *ctx, u8 *out,\n\t\t\t  const u8 *in);\nasmlinkage void aesni_ecb_enc(struct crypto_aes_ctx *ctx, u8 *out,\n\t\t\t      const u8 *in, unsigned int len);\nasmlinkage void aesni_ecb_dec(struct crypto_aes_ctx *ctx, u8 *out,\n\t\t\t      const u8 *in, unsigned int len);\nasmlinkage void aesni_cbc_enc(struct crypto_aes_ctx *ctx, u8 *out,\n\t\t\t      const u8 *in, unsigned int len, u8 *iv);\nasmlinkage void aesni_cbc_dec(struct crypto_aes_ctx *ctx, u8 *out,\n\t\t\t      const u8 *in, unsigned int len, u8 *iv);\n\nint crypto_fpu_init(void);\nvoid crypto_fpu_exit(void);\n\n#define AVX_GEN2_OPTSIZE 640\n#define AVX_GEN4_OPTSIZE 4096\n\n#ifdef CONFIG_X86_64\n\nstatic void (*aesni_ctr_enc_tfm)(struct crypto_aes_ctx *ctx, u8 *out,\n\t\t\t      const u8 *in, unsigned int len, u8 *iv);\nasmlinkage void aesni_ctr_enc(struct crypto_aes_ctx *ctx, u8 *out,\n\t\t\t      const u8 *in, unsigned int len, u8 *iv);\n\nasmlinkage void aesni_xts_crypt8(struct crypto_aes_ctx *ctx, u8 *out,\n\t\t\t\t const u8 *in, bool enc, u8 *iv);\n\n/* asmlinkage void aesni_gcm_enc()\n * void *ctx,  AES Key schedule. Starts on a 16 byte boundary.\n * u8 *out, Ciphertext output. Encrypt in-place is allowed.\n * const u8 *in, Plaintext input\n * unsigned long plaintext_len, Length of data in bytes for encryption.\n * u8 *iv, Pre-counter block j0: 4 byte salt (from Security Association)\n *         concatenated with 8 byte Initialisation Vector (from IPSec ESP\n *         Payload) concatenated with 0x00000001. 16-byte aligned pointer.\n * u8 *hash_subkey, the Hash sub key input. Data starts on a 16-byte boundary.\n * const u8 *aad, Additional Authentication Data (AAD)\n * unsigned long aad_len, Length of AAD in bytes. With RFC4106 this\n *          is going to be 8 or 12 bytes\n * u8 *auth_tag, Authenticated Tag output.\n * unsigned long auth_tag_len), Authenticated Tag Length in bytes.\n *          Valid values are 16 (most likely), 12 or 8.\n */\nasmlinkage void aesni_gcm_enc(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long plaintext_len, u8 *iv,\n\t\t\tu8 *hash_subkey, const u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len);\n\n/* asmlinkage void aesni_gcm_dec()\n * void *ctx, AES Key schedule. Starts on a 16 byte boundary.\n * u8 *out, Plaintext output. Decrypt in-place is allowed.\n * const u8 *in, Ciphertext input\n * unsigned long ciphertext_len, Length of data in bytes for decryption.\n * u8 *iv, Pre-counter block j0: 4 byte salt (from Security Association)\n *         concatenated with 8 byte Initialisation Vector (from IPSec ESP\n *         Payload) concatenated with 0x00000001. 16-byte aligned pointer.\n * u8 *hash_subkey, the Hash sub key input. Data starts on a 16-byte boundary.\n * const u8 *aad, Additional Authentication Data (AAD)\n * unsigned long aad_len, Length of AAD in bytes. With RFC4106 this is going\n * to be 8 or 12 bytes\n * u8 *auth_tag, Authenticated Tag output.\n * unsigned long auth_tag_len) Authenticated Tag Length in bytes.\n * Valid values are 16 (most likely), 12 or 8.\n */\nasmlinkage void aesni_gcm_dec(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long ciphertext_len, u8 *iv,\n\t\t\tu8 *hash_subkey, const u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len);\n\n\n#ifdef CONFIG_AS_AVX\nasmlinkage void aes_ctr_enc_128_avx_by8(const u8 *in, u8 *iv,\n\t\tvoid *keys, u8 *out, unsigned int num_bytes);\nasmlinkage void aes_ctr_enc_192_avx_by8(const u8 *in, u8 *iv,\n\t\tvoid *keys, u8 *out, unsigned int num_bytes);\nasmlinkage void aes_ctr_enc_256_avx_by8(const u8 *in, u8 *iv,\n\t\tvoid *keys, u8 *out, unsigned int num_bytes);\n/*\n * asmlinkage void aesni_gcm_precomp_avx_gen2()\n * gcm_data *my_ctx_data, context data\n * u8 *hash_subkey,  the Hash sub key input. Data starts on a 16-byte boundary.\n */\nasmlinkage void aesni_gcm_precomp_avx_gen2(void *my_ctx_data, u8 *hash_subkey);\n\nasmlinkage void aesni_gcm_enc_avx_gen2(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long plaintext_len, u8 *iv,\n\t\t\tconst u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len);\n\nasmlinkage void aesni_gcm_dec_avx_gen2(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long ciphertext_len, u8 *iv,\n\t\t\tconst u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len);\n\nstatic void aesni_gcm_enc_avx(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long plaintext_len, u8 *iv,\n\t\t\tu8 *hash_subkey, const u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len)\n{\n\tif (plaintext_len < AVX_GEN2_OPTSIZE) {\n\t\taesni_gcm_enc(ctx, out, in, plaintext_len, iv, hash_subkey, aad,\n\t\t\t\taad_len, auth_tag, auth_tag_len);\n\t} else {\n\t\taesni_gcm_precomp_avx_gen2(ctx, hash_subkey);\n\t\taesni_gcm_enc_avx_gen2(ctx, out, in, plaintext_len, iv, aad,\n\t\t\t\t\taad_len, auth_tag, auth_tag_len);\n\t}\n}\n\nstatic void aesni_gcm_dec_avx(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long ciphertext_len, u8 *iv,\n\t\t\tu8 *hash_subkey, const u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len)\n{\n\tif (ciphertext_len < AVX_GEN2_OPTSIZE) {\n\t\taesni_gcm_dec(ctx, out, in, ciphertext_len, iv, hash_subkey, aad,\n\t\t\t\taad_len, auth_tag, auth_tag_len);\n\t} else {\n\t\taesni_gcm_precomp_avx_gen2(ctx, hash_subkey);\n\t\taesni_gcm_dec_avx_gen2(ctx, out, in, ciphertext_len, iv, aad,\n\t\t\t\t\taad_len, auth_tag, auth_tag_len);\n\t}\n}\n#endif\n\n#ifdef CONFIG_AS_AVX2\n/*\n * asmlinkage void aesni_gcm_precomp_avx_gen4()\n * gcm_data *my_ctx_data, context data\n * u8 *hash_subkey,  the Hash sub key input. Data starts on a 16-byte boundary.\n */\nasmlinkage void aesni_gcm_precomp_avx_gen4(void *my_ctx_data, u8 *hash_subkey);\n\nasmlinkage void aesni_gcm_enc_avx_gen4(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long plaintext_len, u8 *iv,\n\t\t\tconst u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len);\n\nasmlinkage void aesni_gcm_dec_avx_gen4(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long ciphertext_len, u8 *iv,\n\t\t\tconst u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len);\n\nstatic void aesni_gcm_enc_avx2(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long plaintext_len, u8 *iv,\n\t\t\tu8 *hash_subkey, const u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len)\n{\n\tif (plaintext_len < AVX_GEN2_OPTSIZE) {\n\t\taesni_gcm_enc(ctx, out, in, plaintext_len, iv, hash_subkey, aad,\n\t\t\t\taad_len, auth_tag, auth_tag_len);\n\t} else if (plaintext_len < AVX_GEN4_OPTSIZE) {\n\t\taesni_gcm_precomp_avx_gen2(ctx, hash_subkey);\n\t\taesni_gcm_enc_avx_gen2(ctx, out, in, plaintext_len, iv, aad,\n\t\t\t\t\taad_len, auth_tag, auth_tag_len);\n\t} else {\n\t\taesni_gcm_precomp_avx_gen4(ctx, hash_subkey);\n\t\taesni_gcm_enc_avx_gen4(ctx, out, in, plaintext_len, iv, aad,\n\t\t\t\t\taad_len, auth_tag, auth_tag_len);\n\t}\n}\n\nstatic void aesni_gcm_dec_avx2(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long ciphertext_len, u8 *iv,\n\t\t\tu8 *hash_subkey, const u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len)\n{\n\tif (ciphertext_len < AVX_GEN2_OPTSIZE) {\n\t\taesni_gcm_dec(ctx, out, in, ciphertext_len, iv, hash_subkey,\n\t\t\t\taad, aad_len, auth_tag, auth_tag_len);\n\t} else if (ciphertext_len < AVX_GEN4_OPTSIZE) {\n\t\taesni_gcm_precomp_avx_gen2(ctx, hash_subkey);\n\t\taesni_gcm_dec_avx_gen2(ctx, out, in, ciphertext_len, iv, aad,\n\t\t\t\t\taad_len, auth_tag, auth_tag_len);\n\t} else {\n\t\taesni_gcm_precomp_avx_gen4(ctx, hash_subkey);\n\t\taesni_gcm_dec_avx_gen4(ctx, out, in, ciphertext_len, iv, aad,\n\t\t\t\t\taad_len, auth_tag, auth_tag_len);\n\t}\n}\n#endif\n\nstatic void (*aesni_gcm_enc_tfm)(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long plaintext_len, u8 *iv,\n\t\t\tu8 *hash_subkey, const u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len);\n\nstatic void (*aesni_gcm_dec_tfm)(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long ciphertext_len, u8 *iv,\n\t\t\tu8 *hash_subkey, const u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len);\n\nstatic inline struct\naesni_rfc4106_gcm_ctx *aesni_rfc4106_gcm_ctx_get(struct crypto_aead *tfm)\n{\n\treturn\n\t\t(struct aesni_rfc4106_gcm_ctx *)\n\t\tPTR_ALIGN((u8 *)\n\t\tcrypto_tfm_ctx(crypto_aead_tfm(tfm)), AESNI_ALIGN);\n}\n#endif\n\nstatic inline struct crypto_aes_ctx *aes_ctx(void *raw_ctx)\n{\n\tunsigned long addr = (unsigned long)raw_ctx;\n\tunsigned long align = AESNI_ALIGN;\n\n\tif (align <= crypto_tfm_ctx_alignment())\n\t\talign = 1;\n\treturn (struct crypto_aes_ctx *)ALIGN(addr, align);\n}\n\nstatic int aes_set_key_common(struct crypto_tfm *tfm, void *raw_ctx,\n\t\t\t      const u8 *in_key, unsigned int key_len)\n{\n\tstruct crypto_aes_ctx *ctx = aes_ctx(raw_ctx);\n\tu32 *flags = &tfm->crt_flags;\n\tint err;\n\n\tif (key_len != AES_KEYSIZE_128 && key_len != AES_KEYSIZE_192 &&\n\t    key_len != AES_KEYSIZE_256) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\tif (!irq_fpu_usable())\n\t\terr = crypto_aes_expand_key(ctx, in_key, key_len);\n\telse {\n\t\tkernel_fpu_begin();\n\t\terr = aesni_set_key(ctx, in_key, key_len);\n\t\tkernel_fpu_end();\n\t}\n\n\treturn err;\n}\n\nstatic int aes_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t       unsigned int key_len)\n{\n\treturn aes_set_key_common(tfm, crypto_tfm_ctx(tfm), in_key, key_len);\n}\n\nstatic void aes_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct crypto_aes_ctx *ctx = aes_ctx(crypto_tfm_ctx(tfm));\n\n\tif (!irq_fpu_usable())\n\t\tcrypto_aes_encrypt_x86(ctx, dst, src);\n\telse {\n\t\tkernel_fpu_begin();\n\t\taesni_enc(ctx, dst, src);\n\t\tkernel_fpu_end();\n\t}\n}\n\nstatic void aes_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct crypto_aes_ctx *ctx = aes_ctx(crypto_tfm_ctx(tfm));\n\n\tif (!irq_fpu_usable())\n\t\tcrypto_aes_decrypt_x86(ctx, dst, src);\n\telse {\n\t\tkernel_fpu_begin();\n\t\taesni_dec(ctx, dst, src);\n\t\tkernel_fpu_end();\n\t}\n}\n\nstatic void __aes_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct crypto_aes_ctx *ctx = aes_ctx(crypto_tfm_ctx(tfm));\n\n\taesni_enc(ctx, dst, src);\n}\n\nstatic void __aes_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct crypto_aes_ctx *ctx = aes_ctx(crypto_tfm_ctx(tfm));\n\n\taesni_dec(ctx, dst, src);\n}\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct crypto_aes_ctx *ctx = aes_ctx(crypto_blkcipher_ctx(desc->tfm));\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tkernel_fpu_begin();\n\twhile ((nbytes = walk.nbytes)) {\n\t\taesni_ecb_enc(ctx, walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t      nbytes & AES_BLOCK_MASK);\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tkernel_fpu_end();\n\n\treturn err;\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct crypto_aes_ctx *ctx = aes_ctx(crypto_blkcipher_ctx(desc->tfm));\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tkernel_fpu_begin();\n\twhile ((nbytes = walk.nbytes)) {\n\t\taesni_ecb_dec(ctx, walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t      nbytes & AES_BLOCK_MASK);\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tkernel_fpu_end();\n\n\treturn err;\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct crypto_aes_ctx *ctx = aes_ctx(crypto_blkcipher_ctx(desc->tfm));\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tkernel_fpu_begin();\n\twhile ((nbytes = walk.nbytes)) {\n\t\taesni_cbc_enc(ctx, walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t      nbytes & AES_BLOCK_MASK, walk.iv);\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tkernel_fpu_end();\n\n\treturn err;\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct crypto_aes_ctx *ctx = aes_ctx(crypto_blkcipher_ctx(desc->tfm));\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tkernel_fpu_begin();\n\twhile ((nbytes = walk.nbytes)) {\n\t\taesni_cbc_dec(ctx, walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t      nbytes & AES_BLOCK_MASK, walk.iv);\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tkernel_fpu_end();\n\n\treturn err;\n}\n\n#ifdef CONFIG_X86_64\nstatic void ctr_crypt_final(struct crypto_aes_ctx *ctx,\n\t\t\t    struct blkcipher_walk *walk)\n{\n\tu8 *ctrblk = walk->iv;\n\tu8 keystream[AES_BLOCK_SIZE];\n\tu8 *src = walk->src.virt.addr;\n\tu8 *dst = walk->dst.virt.addr;\n\tunsigned int nbytes = walk->nbytes;\n\n\taesni_enc(ctx, keystream, ctrblk);\n\tcrypto_xor(keystream, src, nbytes);\n\tmemcpy(dst, keystream, nbytes);\n\tcrypto_inc(ctrblk, AES_BLOCK_SIZE);\n}\n\n#ifdef CONFIG_AS_AVX\nstatic void aesni_ctr_enc_avx_tfm(struct crypto_aes_ctx *ctx, u8 *out,\n\t\t\t      const u8 *in, unsigned int len, u8 *iv)\n{\n\t/*\n\t * based on key length, override with the by8 version\n\t * of ctr mode encryption/decryption for improved performance\n\t * aes_set_key_common() ensures that key length is one of\n\t * {128,192,256}\n\t */\n\tif (ctx->key_length == AES_KEYSIZE_128)\n\t\taes_ctr_enc_128_avx_by8(in, iv, (void *)ctx, out, len);\n\telse if (ctx->key_length == AES_KEYSIZE_192)\n\t\taes_ctr_enc_192_avx_by8(in, iv, (void *)ctx, out, len);\n\telse\n\t\taes_ctr_enc_256_avx_by8(in, iv, (void *)ctx, out, len);\n}\n#endif\n\nstatic int ctr_crypt(struct blkcipher_desc *desc,\n\t\t     struct scatterlist *dst, struct scatterlist *src,\n\t\t     unsigned int nbytes)\n{\n\tstruct crypto_aes_ctx *ctx = aes_ctx(crypto_blkcipher_ctx(desc->tfm));\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt_block(desc, &walk, AES_BLOCK_SIZE);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tkernel_fpu_begin();\n\twhile ((nbytes = walk.nbytes) >= AES_BLOCK_SIZE) {\n\t\taesni_ctr_enc_tfm(ctx, walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t\t  nbytes & AES_BLOCK_MASK, walk.iv);\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tif (walk.nbytes) {\n\t\tctr_crypt_final(ctx, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, 0);\n\t}\n\tkernel_fpu_end();\n\n\treturn err;\n}\n#endif\n\nstatic int ablk_ecb_init(struct crypto_tfm *tfm)\n{\n\treturn ablk_init_common(tfm, \"__driver-ecb-aes-aesni\");\n}\n\nstatic int ablk_cbc_init(struct crypto_tfm *tfm)\n{\n\treturn ablk_init_common(tfm, \"__driver-cbc-aes-aesni\");\n}\n\n#ifdef CONFIG_X86_64\nstatic int ablk_ctr_init(struct crypto_tfm *tfm)\n{\n\treturn ablk_init_common(tfm, \"__driver-ctr-aes-aesni\");\n}\n\n#endif\n\n#if IS_ENABLED(CONFIG_CRYPTO_PCBC)\nstatic int ablk_pcbc_init(struct crypto_tfm *tfm)\n{\n\treturn ablk_init_common(tfm, \"fpu(pcbc(__driver-aes-aesni))\");\n}\n#endif\n\nstatic void lrw_xts_encrypt_callback(void *ctx, u8 *blks, unsigned int nbytes)\n{\n\taesni_ecb_enc(ctx, blks, blks, nbytes);\n}\n\nstatic void lrw_xts_decrypt_callback(void *ctx, u8 *blks, unsigned int nbytes)\n{\n\taesni_ecb_dec(ctx, blks, blks, nbytes);\n}\n\nstatic int lrw_aesni_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\t    unsigned int keylen)\n{\n\tstruct aesni_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\tint err;\n\n\terr = aes_set_key_common(tfm, ctx->raw_aes_ctx, key,\n\t\t\t\t keylen - AES_BLOCK_SIZE);\n\tif (err)\n\t\treturn err;\n\n\treturn lrw_init_table(&ctx->lrw_table, key + keylen - AES_BLOCK_SIZE);\n}\n\nstatic void lrw_aesni_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct aesni_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tlrw_free_table(&ctx->lrw_table);\n}\n\nstatic int lrw_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct aesni_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[8];\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = aes_ctx(ctx->raw_aes_ctx),\n\t\t.crypt_fn = lrw_xts_encrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tkernel_fpu_begin();\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tkernel_fpu_end();\n\n\treturn ret;\n}\n\nstatic int lrw_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct aesni_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[8];\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = aes_ctx(ctx->raw_aes_ctx),\n\t\t.crypt_fn = lrw_xts_decrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tkernel_fpu_begin();\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tkernel_fpu_end();\n\n\treturn ret;\n}\n\nstatic int xts_aesni_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\t    unsigned int keylen)\n{\n\tstruct aesni_xts_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tint err;\n\n\t/* key consists of keys of equal size concatenated, therefore\n\t * the length must be even\n\t */\n\tif (keylen % 2) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\t/* first half of xts-key is for crypt */\n\terr = aes_set_key_common(tfm, ctx->raw_crypt_ctx, key, keylen / 2);\n\tif (err)\n\t\treturn err;\n\n\t/* second half of xts-key is for tweak */\n\treturn aes_set_key_common(tfm, ctx->raw_tweak_ctx, key + keylen / 2,\n\t\t\t\t  keylen / 2);\n}\n\n\nstatic void aesni_xts_tweak(void *ctx, u8 *out, const u8 *in)\n{\n\taesni_enc(ctx, out, in);\n}\n\n#ifdef CONFIG_X86_64\n\nstatic void aesni_xts_enc(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tglue_xts_crypt_128bit_one(ctx, dst, src, iv, GLUE_FUNC_CAST(aesni_enc));\n}\n\nstatic void aesni_xts_dec(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tglue_xts_crypt_128bit_one(ctx, dst, src, iv, GLUE_FUNC_CAST(aesni_dec));\n}\n\nstatic void aesni_xts_enc8(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\taesni_xts_crypt8(ctx, (u8 *)dst, (const u8 *)src, true, (u8 *)iv);\n}\n\nstatic void aesni_xts_dec8(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\taesni_xts_crypt8(ctx, (u8 *)dst, (const u8 *)src, false, (u8 *)iv);\n}\n\nstatic const struct common_glue_ctx aesni_enc_xts = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = 1,\n\n\t.funcs = { {\n\t\t.num_blocks = 8,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(aesni_xts_enc8) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(aesni_xts_enc) }\n\t} }\n};\n\nstatic const struct common_glue_ctx aesni_dec_xts = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = 1,\n\n\t.funcs = { {\n\t\t.num_blocks = 8,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(aesni_xts_dec8) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(aesni_xts_dec) }\n\t} }\n};\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct aesni_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&aesni_enc_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(aesni_xts_tweak),\n\t\t\t\t     aes_ctx(ctx->raw_tweak_ctx),\n\t\t\t\t     aes_ctx(ctx->raw_crypt_ctx));\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct aesni_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&aesni_dec_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(aesni_xts_tweak),\n\t\t\t\t     aes_ctx(ctx->raw_tweak_ctx),\n\t\t\t\t     aes_ctx(ctx->raw_crypt_ctx));\n}\n\n#else\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct aesni_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[8];\n\tstruct xts_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.tweak_ctx = aes_ctx(ctx->raw_tweak_ctx),\n\t\t.tweak_fn = aesni_xts_tweak,\n\t\t.crypt_ctx = aes_ctx(ctx->raw_crypt_ctx),\n\t\t.crypt_fn = lrw_xts_encrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tkernel_fpu_begin();\n\tret = xts_crypt(desc, dst, src, nbytes, &req);\n\tkernel_fpu_end();\n\n\treturn ret;\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct aesni_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[8];\n\tstruct xts_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.tweak_ctx = aes_ctx(ctx->raw_tweak_ctx),\n\t\t.tweak_fn = aesni_xts_tweak,\n\t\t.crypt_ctx = aes_ctx(ctx->raw_crypt_ctx),\n\t\t.crypt_fn = lrw_xts_decrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tkernel_fpu_begin();\n\tret = xts_crypt(desc, dst, src, nbytes, &req);\n\tkernel_fpu_end();\n\n\treturn ret;\n}\n\n#endif\n\n#ifdef CONFIG_X86_64\nstatic int rfc4106_init(struct crypto_tfm *tfm)\n{\n\tstruct cryptd_aead *cryptd_tfm;\n\tstruct aesni_rfc4106_gcm_ctx *ctx = (struct aesni_rfc4106_gcm_ctx *)\n\t\tPTR_ALIGN((u8 *)crypto_tfm_ctx(tfm), AESNI_ALIGN);\n\tstruct crypto_aead *cryptd_child;\n\tstruct aesni_rfc4106_gcm_ctx *child_ctx;\n\tcryptd_tfm = cryptd_alloc_aead(\"__driver-gcm-aes-aesni\", 0, 0);\n\tif (IS_ERR(cryptd_tfm))\n\t\treturn PTR_ERR(cryptd_tfm);\n\n\tcryptd_child = cryptd_aead_child(cryptd_tfm);\n\tchild_ctx = aesni_rfc4106_gcm_ctx_get(cryptd_child);\n\tmemcpy(child_ctx, ctx, sizeof(*ctx));\n\tctx->cryptd_tfm = cryptd_tfm;\n\ttfm->crt_aead.reqsize = sizeof(struct aead_request)\n\t\t+ crypto_aead_reqsize(&cryptd_tfm->base);\n\treturn 0;\n}\n\nstatic void rfc4106_exit(struct crypto_tfm *tfm)\n{\n\tstruct aesni_rfc4106_gcm_ctx *ctx =\n\t\t(struct aesni_rfc4106_gcm_ctx *)\n\t\tPTR_ALIGN((u8 *)crypto_tfm_ctx(tfm), AESNI_ALIGN);\n\tif (!IS_ERR(ctx->cryptd_tfm))\n\t\tcryptd_free_aead(ctx->cryptd_tfm);\n\treturn;\n}\n\nstatic void\nrfc4106_set_hash_subkey_done(struct crypto_async_request *req, int err)\n{\n\tstruct aesni_gcm_set_hash_subkey_result *result = req->data;\n\n\tif (err == -EINPROGRESS)\n\t\treturn;\n\tresult->err = err;\n\tcomplete(&result->completion);\n}\n\nstatic int\nrfc4106_set_hash_subkey(u8 *hash_subkey, const u8 *key, unsigned int key_len)\n{\n\tstruct crypto_ablkcipher *ctr_tfm;\n\tstruct ablkcipher_request *req;\n\tint ret = -EINVAL;\n\tstruct aesni_hash_subkey_req_data *req_data;\n\n\tctr_tfm = crypto_alloc_ablkcipher(\"ctr(aes)\", 0, 0);\n\tif (IS_ERR(ctr_tfm))\n\t\treturn PTR_ERR(ctr_tfm);\n\n\tcrypto_ablkcipher_clear_flags(ctr_tfm, ~0);\n\n\tret = crypto_ablkcipher_setkey(ctr_tfm, key, key_len);\n\tif (ret)\n\t\tgoto out_free_ablkcipher;\n\n\tret = -ENOMEM;\n\treq = ablkcipher_request_alloc(ctr_tfm, GFP_KERNEL);\n\tif (!req)\n\t\tgoto out_free_ablkcipher;\n\n\treq_data = kmalloc(sizeof(*req_data), GFP_KERNEL);\n\tif (!req_data)\n\t\tgoto out_free_request;\n\n\tmemset(req_data->iv, 0, sizeof(req_data->iv));\n\n\t/* Clear the data in the hash sub key container to zero.*/\n\t/* We want to cipher all zeros to create the hash sub key. */\n\tmemset(hash_subkey, 0, RFC4106_HASH_SUBKEY_SIZE);\n\n\tinit_completion(&req_data->result.completion);\n\tsg_init_one(&req_data->sg, hash_subkey, RFC4106_HASH_SUBKEY_SIZE);\n\tablkcipher_request_set_tfm(req, ctr_tfm);\n\tablkcipher_request_set_callback(req, CRYPTO_TFM_REQ_MAY_SLEEP |\n\t\t\t\t\tCRYPTO_TFM_REQ_MAY_BACKLOG,\n\t\t\t\t\trfc4106_set_hash_subkey_done,\n\t\t\t\t\t&req_data->result);\n\n\tablkcipher_request_set_crypt(req, &req_data->sg,\n\t\t&req_data->sg, RFC4106_HASH_SUBKEY_SIZE, req_data->iv);\n\n\tret = crypto_ablkcipher_encrypt(req);\n\tif (ret == -EINPROGRESS || ret == -EBUSY) {\n\t\tret = wait_for_completion_interruptible\n\t\t\t(&req_data->result.completion);\n\t\tif (!ret)\n\t\t\tret = req_data->result.err;\n\t}\n\tkfree(req_data);\nout_free_request:\n\tablkcipher_request_free(req);\nout_free_ablkcipher:\n\tcrypto_free_ablkcipher(ctr_tfm);\n\treturn ret;\n}\n\nstatic int rfc4106_set_key(struct crypto_aead *parent, const u8 *key,\n\t\t\t\t\t\t   unsigned int key_len)\n{\n\tint ret = 0;\n\tstruct crypto_tfm *tfm = crypto_aead_tfm(parent);\n\tstruct aesni_rfc4106_gcm_ctx *ctx = aesni_rfc4106_gcm_ctx_get(parent);\n\tstruct crypto_aead *cryptd_child = cryptd_aead_child(ctx->cryptd_tfm);\n\tstruct aesni_rfc4106_gcm_ctx *child_ctx =\n                                 aesni_rfc4106_gcm_ctx_get(cryptd_child);\n\tu8 *new_key_align, *new_key_mem = NULL;\n\n\tif (key_len < 4) {\n\t\tcrypto_tfm_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);\n\t\treturn -EINVAL;\n\t}\n\t/*Account for 4 byte nonce at the end.*/\n\tkey_len -= 4;\n\tif (key_len != AES_KEYSIZE_128) {\n\t\tcrypto_tfm_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(ctx->nonce, key + key_len, sizeof(ctx->nonce));\n\t/*This must be on a 16 byte boundary!*/\n\tif ((unsigned long)(&(ctx->aes_key_expanded.key_enc[0])) % AESNI_ALIGN)\n\t\treturn -EINVAL;\n\n\tif ((unsigned long)key % AESNI_ALIGN) {\n\t\t/*key is not aligned: use an auxuliar aligned pointer*/\n\t\tnew_key_mem = kmalloc(key_len+AESNI_ALIGN, GFP_KERNEL);\n\t\tif (!new_key_mem)\n\t\t\treturn -ENOMEM;\n\n\t\tnew_key_align = PTR_ALIGN(new_key_mem, AESNI_ALIGN);\n\t\tmemcpy(new_key_align, key, key_len);\n\t\tkey = new_key_align;\n\t}\n\n\tif (!irq_fpu_usable())\n\t\tret = crypto_aes_expand_key(&(ctx->aes_key_expanded),\n\t\tkey, key_len);\n\telse {\n\t\tkernel_fpu_begin();\n\t\tret = aesni_set_key(&(ctx->aes_key_expanded), key, key_len);\n\t\tkernel_fpu_end();\n\t}\n\t/*This must be on a 16 byte boundary!*/\n\tif ((unsigned long)(&(ctx->hash_subkey[0])) % AESNI_ALIGN) {\n\t\tret = -EINVAL;\n\t\tgoto exit;\n\t}\n\tret = rfc4106_set_hash_subkey(ctx->hash_subkey, key, key_len);\n\tmemcpy(child_ctx, ctx, sizeof(*ctx));\nexit:\n\tkfree(new_key_mem);\n\treturn ret;\n}\n\n/* This is the Integrity Check Value (aka the authentication tag length and can\n * be 8, 12 or 16 bytes long. */\nstatic int rfc4106_set_authsize(struct crypto_aead *parent,\n\t\t\t\tunsigned int authsize)\n{\n\tstruct aesni_rfc4106_gcm_ctx *ctx = aesni_rfc4106_gcm_ctx_get(parent);\n\tstruct crypto_aead *cryptd_child = cryptd_aead_child(ctx->cryptd_tfm);\n\n\tswitch (authsize) {\n\tcase 8:\n\tcase 12:\n\tcase 16:\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\tcrypto_aead_crt(parent)->authsize = authsize;\n\tcrypto_aead_crt(cryptd_child)->authsize = authsize;\n\treturn 0;\n}\n\nstatic int rfc4106_encrypt(struct aead_request *req)\n{\n\tint ret;\n\tstruct crypto_aead *tfm = crypto_aead_reqtfm(req);\n\tstruct aesni_rfc4106_gcm_ctx *ctx = aesni_rfc4106_gcm_ctx_get(tfm);\n\n\tif (!irq_fpu_usable()) {\n\t\tstruct aead_request *cryptd_req =\n\t\t\t(struct aead_request *) aead_request_ctx(req);\n\t\tmemcpy(cryptd_req, req, sizeof(*req));\n\t\taead_request_set_tfm(cryptd_req, &ctx->cryptd_tfm->base);\n\t\treturn crypto_aead_encrypt(cryptd_req);\n\t} else {\n\t\tstruct crypto_aead *cryptd_child = cryptd_aead_child(ctx->cryptd_tfm);\n\t\tkernel_fpu_begin();\n\t\tret = cryptd_child->base.crt_aead.encrypt(req);\n\t\tkernel_fpu_end();\n\t\treturn ret;\n\t}\n}\n\nstatic int rfc4106_decrypt(struct aead_request *req)\n{\n\tint ret;\n\tstruct crypto_aead *tfm = crypto_aead_reqtfm(req);\n\tstruct aesni_rfc4106_gcm_ctx *ctx = aesni_rfc4106_gcm_ctx_get(tfm);\n\n\tif (!irq_fpu_usable()) {\n\t\tstruct aead_request *cryptd_req =\n\t\t\t(struct aead_request *) aead_request_ctx(req);\n\t\tmemcpy(cryptd_req, req, sizeof(*req));\n\t\taead_request_set_tfm(cryptd_req, &ctx->cryptd_tfm->base);\n\t\treturn crypto_aead_decrypt(cryptd_req);\n\t} else {\n\t\tstruct crypto_aead *cryptd_child = cryptd_aead_child(ctx->cryptd_tfm);\n\t\tkernel_fpu_begin();\n\t\tret = cryptd_child->base.crt_aead.decrypt(req);\n\t\tkernel_fpu_end();\n\t\treturn ret;\n\t}\n}\n\nstatic int __driver_rfc4106_encrypt(struct aead_request *req)\n{\n\tu8 one_entry_in_sg = 0;\n\tu8 *src, *dst, *assoc;\n\t__be32 counter = cpu_to_be32(1);\n\tstruct crypto_aead *tfm = crypto_aead_reqtfm(req);\n\tstruct aesni_rfc4106_gcm_ctx *ctx = aesni_rfc4106_gcm_ctx_get(tfm);\n\tvoid *aes_ctx = &(ctx->aes_key_expanded);\n\tunsigned long auth_tag_len = crypto_aead_authsize(tfm);\n\tu8 iv_tab[16+AESNI_ALIGN];\n\tu8* iv = (u8 *) PTR_ALIGN((u8 *)iv_tab, AESNI_ALIGN);\n\tstruct scatter_walk src_sg_walk;\n\tstruct scatter_walk assoc_sg_walk;\n\tstruct scatter_walk dst_sg_walk;\n\tunsigned int i;\n\n\t/* Assuming we are supporting rfc4106 64-bit extended */\n\t/* sequence numbers We need to have the AAD length equal */\n\t/* to 8 or 12 bytes */\n\tif (unlikely(req->assoclen != 8 && req->assoclen != 12))\n\t\treturn -EINVAL;\n\t/* IV below built */\n\tfor (i = 0; i < 4; i++)\n\t\t*(iv+i) = ctx->nonce[i];\n\tfor (i = 0; i < 8; i++)\n\t\t*(iv+4+i) = req->iv[i];\n\t*((__be32 *)(iv+12)) = counter;\n\n\tif ((sg_is_last(req->src)) && (sg_is_last(req->assoc))) {\n\t\tone_entry_in_sg = 1;\n\t\tscatterwalk_start(&src_sg_walk, req->src);\n\t\tscatterwalk_start(&assoc_sg_walk, req->assoc);\n\t\tsrc = scatterwalk_map(&src_sg_walk);\n\t\tassoc = scatterwalk_map(&assoc_sg_walk);\n\t\tdst = src;\n\t\tif (unlikely(req->src != req->dst)) {\n\t\t\tscatterwalk_start(&dst_sg_walk, req->dst);\n\t\t\tdst = scatterwalk_map(&dst_sg_walk);\n\t\t}\n\n\t} else {\n\t\t/* Allocate memory for src, dst, assoc */\n\t\tsrc = kmalloc(req->cryptlen + auth_tag_len + req->assoclen,\n\t\t\tGFP_ATOMIC);\n\t\tif (unlikely(!src))\n\t\t\treturn -ENOMEM;\n\t\tassoc = (src + req->cryptlen + auth_tag_len);\n\t\tscatterwalk_map_and_copy(src, req->src, 0, req->cryptlen, 0);\n\t\tscatterwalk_map_and_copy(assoc, req->assoc, 0,\n\t\t\t\t\treq->assoclen, 0);\n\t\tdst = src;\n\t}\n\n\taesni_gcm_enc_tfm(aes_ctx, dst, src, (unsigned long)req->cryptlen, iv,\n\t\tctx->hash_subkey, assoc, (unsigned long)req->assoclen, dst\n\t\t+ ((unsigned long)req->cryptlen), auth_tag_len);\n\n\t/* The authTag (aka the Integrity Check Value) needs to be written\n\t * back to the packet. */\n\tif (one_entry_in_sg) {\n\t\tif (unlikely(req->src != req->dst)) {\n\t\t\tscatterwalk_unmap(dst);\n\t\t\tscatterwalk_done(&dst_sg_walk, 0, 0);\n\t\t}\n\t\tscatterwalk_unmap(src);\n\t\tscatterwalk_unmap(assoc);\n\t\tscatterwalk_done(&src_sg_walk, 0, 0);\n\t\tscatterwalk_done(&assoc_sg_walk, 0, 0);\n\t} else {\n\t\tscatterwalk_map_and_copy(dst, req->dst, 0,\n\t\t\treq->cryptlen + auth_tag_len, 1);\n\t\tkfree(src);\n\t}\n\treturn 0;\n}\n\nstatic int __driver_rfc4106_decrypt(struct aead_request *req)\n{\n\tu8 one_entry_in_sg = 0;\n\tu8 *src, *dst, *assoc;\n\tunsigned long tempCipherLen = 0;\n\t__be32 counter = cpu_to_be32(1);\n\tint retval = 0;\n\tstruct crypto_aead *tfm = crypto_aead_reqtfm(req);\n\tstruct aesni_rfc4106_gcm_ctx *ctx = aesni_rfc4106_gcm_ctx_get(tfm);\n\tvoid *aes_ctx = &(ctx->aes_key_expanded);\n\tunsigned long auth_tag_len = crypto_aead_authsize(tfm);\n\tu8 iv_and_authTag[32+AESNI_ALIGN];\n\tu8 *iv = (u8 *) PTR_ALIGN((u8 *)iv_and_authTag, AESNI_ALIGN);\n\tu8 *authTag = iv + 16;\n\tstruct scatter_walk src_sg_walk;\n\tstruct scatter_walk assoc_sg_walk;\n\tstruct scatter_walk dst_sg_walk;\n\tunsigned int i;\n\n\tif (unlikely((req->cryptlen < auth_tag_len) ||\n\t\t(req->assoclen != 8 && req->assoclen != 12)))\n\t\treturn -EINVAL;\n\t/* Assuming we are supporting rfc4106 64-bit extended */\n\t/* sequence numbers We need to have the AAD length */\n\t/* equal to 8 or 12 bytes */\n\n\ttempCipherLen = (unsigned long)(req->cryptlen - auth_tag_len);\n\t/* IV below built */\n\tfor (i = 0; i < 4; i++)\n\t\t*(iv+i) = ctx->nonce[i];\n\tfor (i = 0; i < 8; i++)\n\t\t*(iv+4+i) = req->iv[i];\n\t*((__be32 *)(iv+12)) = counter;\n\n\tif ((sg_is_last(req->src)) && (sg_is_last(req->assoc))) {\n\t\tone_entry_in_sg = 1;\n\t\tscatterwalk_start(&src_sg_walk, req->src);\n\t\tscatterwalk_start(&assoc_sg_walk, req->assoc);\n\t\tsrc = scatterwalk_map(&src_sg_walk);\n\t\tassoc = scatterwalk_map(&assoc_sg_walk);\n\t\tdst = src;\n\t\tif (unlikely(req->src != req->dst)) {\n\t\t\tscatterwalk_start(&dst_sg_walk, req->dst);\n\t\t\tdst = scatterwalk_map(&dst_sg_walk);\n\t\t}\n\n\t} else {\n\t\t/* Allocate memory for src, dst, assoc */\n\t\tsrc = kmalloc(req->cryptlen + req->assoclen, GFP_ATOMIC);\n\t\tif (!src)\n\t\t\treturn -ENOMEM;\n\t\tassoc = (src + req->cryptlen + auth_tag_len);\n\t\tscatterwalk_map_and_copy(src, req->src, 0, req->cryptlen, 0);\n\t\tscatterwalk_map_and_copy(assoc, req->assoc, 0,\n\t\t\treq->assoclen, 0);\n\t\tdst = src;\n\t}\n\n\taesni_gcm_dec_tfm(aes_ctx, dst, src, tempCipherLen, iv,\n\t\tctx->hash_subkey, assoc, (unsigned long)req->assoclen,\n\t\tauthTag, auth_tag_len);\n\n\t/* Compare generated tag with passed in tag. */\n\tretval = crypto_memneq(src + tempCipherLen, authTag, auth_tag_len) ?\n\t\t-EBADMSG : 0;\n\n\tif (one_entry_in_sg) {\n\t\tif (unlikely(req->src != req->dst)) {\n\t\t\tscatterwalk_unmap(dst);\n\t\t\tscatterwalk_done(&dst_sg_walk, 0, 0);\n\t\t}\n\t\tscatterwalk_unmap(src);\n\t\tscatterwalk_unmap(assoc);\n\t\tscatterwalk_done(&src_sg_walk, 0, 0);\n\t\tscatterwalk_done(&assoc_sg_walk, 0, 0);\n\t} else {\n\t\tscatterwalk_map_and_copy(dst, req->dst, 0, req->cryptlen, 1);\n\t\tkfree(src);\n\t}\n\treturn retval;\n}\n#endif\n\nstatic struct crypto_alg aesni_algs[] = { {\n\t.cra_name\t\t= \"aes\",\n\t.cra_driver_name\t= \"aes-aesni\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_aes_ctx) +\n\t\t\t\t  AESNI_ALIGN - 1,\n\t.cra_alignmask\t\t= 0,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u\t= {\n\t\t.cipher\t= {\n\t\t\t.cia_min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t= aes_set_key,\n\t\t\t.cia_encrypt\t\t= aes_encrypt,\n\t\t\t.cia_decrypt\t\t= aes_decrypt\n\t\t}\n\t}\n}, {\n\t.cra_name\t\t= \"__aes-aesni\",\n\t.cra_driver_name\t= \"__driver-aes-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_aes_ctx) +\n\t\t\t\t  AESNI_ALIGN - 1,\n\t.cra_alignmask\t\t= 0,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u\t= {\n\t\t.cipher\t= {\n\t\t\t.cia_min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t= aes_set_key,\n\t\t\t.cia_encrypt\t\t= __aes_encrypt,\n\t\t\t.cia_decrypt\t\t= __aes_decrypt\n\t\t}\n\t}\n}, {\n\t.cra_name\t\t= \"__ecb-aes-aesni\",\n\t.cra_driver_name\t= \"__driver-ecb-aes-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_aes_ctx) +\n\t\t\t\t  AESNI_ALIGN - 1,\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= aes_set_key,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__cbc-aes-aesni\",\n\t.cra_driver_name\t= \"__driver-cbc-aes-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_aes_ctx) +\n\t\t\t\t  AESNI_ALIGN - 1,\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= aes_set_key,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ecb(aes)\",\n\t.cra_driver_name\t= \"ecb-aes-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_ecb_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(aes)\",\n\t.cra_driver_name\t= \"cbc-aes-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_cbc_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n#ifdef CONFIG_X86_64\n}, {\n\t.cra_name\t\t= \"__ctr-aes-aesni\",\n\t.cra_driver_name\t= \"__driver-ctr-aes-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_aes_ctx) +\n\t\t\t\t  AESNI_ALIGN - 1,\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t\t.setkey\t\t= aes_set_key,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(aes)\",\n\t.cra_driver_name\t= \"ctr-aes-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_ctr_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_encrypt,\n\t\t\t.geniv\t\t= \"chainiv\",\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__gcm-aes-aesni\",\n\t.cra_driver_name\t= \"__driver-gcm-aes-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_AEAD,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct aesni_rfc4106_gcm_ctx) +\n\t\t\t\t  AESNI_ALIGN,\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_aead_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.aead = {\n\t\t\t.encrypt\t= __driver_rfc4106_encrypt,\n\t\t\t.decrypt\t= __driver_rfc4106_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"rfc4106(gcm(aes))\",\n\t.cra_driver_name\t= \"rfc4106-gcm-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_AEAD | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct aesni_rfc4106_gcm_ctx) +\n\t\t\t\t  AESNI_ALIGN,\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_nivaead_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= rfc4106_init,\n\t.cra_exit\t\t= rfc4106_exit,\n\t.cra_u = {\n\t\t.aead = {\n\t\t\t.setkey\t\t= rfc4106_set_key,\n\t\t\t.setauthsize\t= rfc4106_set_authsize,\n\t\t\t.encrypt\t= rfc4106_encrypt,\n\t\t\t.decrypt\t= rfc4106_decrypt,\n\t\t\t.geniv\t\t= \"seqiv\",\n\t\t\t.ivsize\t\t= 8,\n\t\t\t.maxauthsize\t= 16,\n\t\t},\n\t},\n#endif\n#if IS_ENABLED(CONFIG_CRYPTO_PCBC)\n}, {\n\t.cra_name\t\t= \"pcbc(aes)\",\n\t.cra_driver_name\t= \"pcbc-aes-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_pcbc_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n#endif\n}, {\n\t.cra_name\t\t= \"__lrw-aes-aesni\",\n\t.cra_driver_name\t= \"__driver-lrw-aes-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct aesni_lrw_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_exit\t\t= lrw_aesni_exit_tfm,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE + AES_BLOCK_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE + AES_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t\t.setkey\t\t= lrw_aesni_setkey,\n\t\t\t.encrypt\t= lrw_encrypt,\n\t\t\t.decrypt\t= lrw_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__xts-aes-aesni\",\n\t.cra_driver_name\t= \"__driver-xts-aes-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct aesni_xts_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= 2 * AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= 2 * AES_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t\t.setkey\t\t= xts_aesni_setkey,\n\t\t\t.encrypt\t= xts_encrypt,\n\t\t\t.decrypt\t= xts_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"lrw(aes)\",\n\t.cra_driver_name\t= \"lrw-aes-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE + AES_BLOCK_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE + AES_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"xts(aes)\",\n\t.cra_driver_name\t= \"xts-aes-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= 2 * AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= 2 * AES_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n} };\n\n\nstatic const struct x86_cpu_id aesni_cpu_id[] = {\n\tX86_FEATURE_MATCH(X86_FEATURE_AES),\n\t{}\n};\nMODULE_DEVICE_TABLE(x86cpu, aesni_cpu_id);\n\nstatic int __init aesni_init(void)\n{\n\tint err;\n\n\tif (!x86_match_cpu(aesni_cpu_id))\n\t\treturn -ENODEV;\n#ifdef CONFIG_X86_64\n#ifdef CONFIG_AS_AVX2\n\tif (boot_cpu_has(X86_FEATURE_AVX2)) {\n\t\tpr_info(\"AVX2 version of gcm_enc/dec engaged.\\n\");\n\t\taesni_gcm_enc_tfm = aesni_gcm_enc_avx2;\n\t\taesni_gcm_dec_tfm = aesni_gcm_dec_avx2;\n\t} else\n#endif\n#ifdef CONFIG_AS_AVX\n\tif (boot_cpu_has(X86_FEATURE_AVX)) {\n\t\tpr_info(\"AVX version of gcm_enc/dec engaged.\\n\");\n\t\taesni_gcm_enc_tfm = aesni_gcm_enc_avx;\n\t\taesni_gcm_dec_tfm = aesni_gcm_dec_avx;\n\t} else\n#endif\n\t{\n\t\tpr_info(\"SSE version of gcm_enc/dec engaged.\\n\");\n\t\taesni_gcm_enc_tfm = aesni_gcm_enc;\n\t\taesni_gcm_dec_tfm = aesni_gcm_dec;\n\t}\n\taesni_ctr_enc_tfm = aesni_ctr_enc;\n#ifdef CONFIG_AS_AVX\n\tif (cpu_has_avx) {\n\t\t/* optimize performance of ctr mode encryption transform */\n\t\taesni_ctr_enc_tfm = aesni_ctr_enc_avx_tfm;\n\t\tpr_info(\"AES CTR mode by8 optimization enabled\\n\");\n\t}\n#endif\n#endif\n\n\terr = crypto_fpu_init();\n\tif (err)\n\t\treturn err;\n\n\treturn crypto_register_algs(aesni_algs, ARRAY_SIZE(aesni_algs));\n}\n\nstatic void __exit aesni_exit(void)\n{\n\tcrypto_unregister_algs(aesni_algs, ARRAY_SIZE(aesni_algs));\n\n\tcrypto_fpu_exit();\n}\n\nmodule_init(aesni_init);\nmodule_exit(aesni_exit);\n\nMODULE_DESCRIPTION(\"Rijndael (AES) Cipher Algorithm, Intel AES-NI instructions optimized\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS(\"aes\");\n", "/*\n * Glue Code for assembler optimized version of Blowfish\n *\n * Copyright (c) 2011 Jussi Kivilinna <jussi.kivilinna@mbnet.fi>\n *\n * CBC & ECB parts based on code (crypto/cbc.c,ecb.c) by:\n *   Copyright (c) 2006 Herbert Xu <herbert@gondor.apana.org.au>\n * CTR part based on code (crypto/ctr.c) by:\n *   (C) Copyright IBM Corp. 2007 - Joy Latten <latten@us.ibm.com>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307\n * USA\n *\n */\n\n#include <asm/processor.h>\n#include <crypto/blowfish.h>\n#include <linux/crypto.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/types.h>\n#include <crypto/algapi.h>\n\n/* regular block cipher functions */\nasmlinkage void __blowfish_enc_blk(struct bf_ctx *ctx, u8 *dst, const u8 *src,\n\t\t\t\t   bool xor);\nasmlinkage void blowfish_dec_blk(struct bf_ctx *ctx, u8 *dst, const u8 *src);\n\n/* 4-way parallel cipher functions */\nasmlinkage void __blowfish_enc_blk_4way(struct bf_ctx *ctx, u8 *dst,\n\t\t\t\t\tconst u8 *src, bool xor);\nasmlinkage void blowfish_dec_blk_4way(struct bf_ctx *ctx, u8 *dst,\n\t\t\t\t      const u8 *src);\n\nstatic inline void blowfish_enc_blk(struct bf_ctx *ctx, u8 *dst, const u8 *src)\n{\n\t__blowfish_enc_blk(ctx, dst, src, false);\n}\n\nstatic inline void blowfish_enc_blk_xor(struct bf_ctx *ctx, u8 *dst,\n\t\t\t\t\tconst u8 *src)\n{\n\t__blowfish_enc_blk(ctx, dst, src, true);\n}\n\nstatic inline void blowfish_enc_blk_4way(struct bf_ctx *ctx, u8 *dst,\n\t\t\t\t\t const u8 *src)\n{\n\t__blowfish_enc_blk_4way(ctx, dst, src, false);\n}\n\nstatic inline void blowfish_enc_blk_xor_4way(struct bf_ctx *ctx, u8 *dst,\n\t\t\t\t      const u8 *src)\n{\n\t__blowfish_enc_blk_4way(ctx, dst, src, true);\n}\n\nstatic void blowfish_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tblowfish_enc_blk(crypto_tfm_ctx(tfm), dst, src);\n}\n\nstatic void blowfish_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tblowfish_dec_blk(crypto_tfm_ctx(tfm), dst, src);\n}\n\nstatic int ecb_crypt(struct blkcipher_desc *desc, struct blkcipher_walk *walk,\n\t\t     void (*fn)(struct bf_ctx *, u8 *, const u8 *),\n\t\t     void (*fn_4way)(struct bf_ctx *, u8 *, const u8 *))\n{\n\tstruct bf_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tunsigned int bsize = BF_BLOCK_SIZE;\n\tunsigned int nbytes;\n\tint err;\n\n\terr = blkcipher_walk_virt(desc, walk);\n\n\twhile ((nbytes = walk->nbytes)) {\n\t\tu8 *wsrc = walk->src.virt.addr;\n\t\tu8 *wdst = walk->dst.virt.addr;\n\n\t\t/* Process four block batch */\n\t\tif (nbytes >= bsize * 4) {\n\t\t\tdo {\n\t\t\t\tfn_4way(ctx, wdst, wsrc);\n\n\t\t\t\twsrc += bsize * 4;\n\t\t\t\twdst += bsize * 4;\n\t\t\t\tnbytes -= bsize * 4;\n\t\t\t} while (nbytes >= bsize * 4);\n\n\t\t\tif (nbytes < bsize)\n\t\t\t\tgoto done;\n\t\t}\n\n\t\t/* Handle leftovers */\n\t\tdo {\n\t\t\tfn(ctx, wdst, wsrc);\n\n\t\t\twsrc += bsize;\n\t\t\twdst += bsize;\n\t\t\tnbytes -= bsize;\n\t\t} while (nbytes >= bsize);\n\ndone:\n\t\terr = blkcipher_walk_done(desc, walk, nbytes);\n\t}\n\n\treturn err;\n}\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_crypt(desc, &walk, blowfish_enc_blk, blowfish_enc_blk_4way);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_crypt(desc, &walk, blowfish_dec_blk, blowfish_dec_blk_4way);\n}\n\nstatic unsigned int __cbc_encrypt(struct blkcipher_desc *desc,\n\t\t\t\t  struct blkcipher_walk *walk)\n{\n\tstruct bf_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tunsigned int bsize = BF_BLOCK_SIZE;\n\tunsigned int nbytes = walk->nbytes;\n\tu64 *src = (u64 *)walk->src.virt.addr;\n\tu64 *dst = (u64 *)walk->dst.virt.addr;\n\tu64 *iv = (u64 *)walk->iv;\n\n\tdo {\n\t\t*dst = *src ^ *iv;\n\t\tblowfish_enc_blk(ctx, (u8 *)dst, (u8 *)dst);\n\t\tiv = dst;\n\n\t\tsrc += 1;\n\t\tdst += 1;\n\t\tnbytes -= bsize;\n\t} while (nbytes >= bsize);\n\n\t*(u64 *)walk->iv = *iv;\n\treturn nbytes;\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\twhile ((nbytes = walk.nbytes)) {\n\t\tnbytes = __cbc_encrypt(desc, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\n\treturn err;\n}\n\nstatic unsigned int __cbc_decrypt(struct blkcipher_desc *desc,\n\t\t\t\t  struct blkcipher_walk *walk)\n{\n\tstruct bf_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tunsigned int bsize = BF_BLOCK_SIZE;\n\tunsigned int nbytes = walk->nbytes;\n\tu64 *src = (u64 *)walk->src.virt.addr;\n\tu64 *dst = (u64 *)walk->dst.virt.addr;\n\tu64 ivs[4 - 1];\n\tu64 last_iv;\n\n\t/* Start of the last block. */\n\tsrc += nbytes / bsize - 1;\n\tdst += nbytes / bsize - 1;\n\n\tlast_iv = *src;\n\n\t/* Process four block batch */\n\tif (nbytes >= bsize * 4) {\n\t\tdo {\n\t\t\tnbytes -= bsize * 4 - bsize;\n\t\t\tsrc -= 4 - 1;\n\t\t\tdst -= 4 - 1;\n\n\t\t\tivs[0] = src[0];\n\t\t\tivs[1] = src[1];\n\t\t\tivs[2] = src[2];\n\n\t\t\tblowfish_dec_blk_4way(ctx, (u8 *)dst, (u8 *)src);\n\n\t\t\tdst[1] ^= ivs[0];\n\t\t\tdst[2] ^= ivs[1];\n\t\t\tdst[3] ^= ivs[2];\n\n\t\t\tnbytes -= bsize;\n\t\t\tif (nbytes < bsize)\n\t\t\t\tgoto done;\n\n\t\t\t*dst ^= *(src - 1);\n\t\t\tsrc -= 1;\n\t\t\tdst -= 1;\n\t\t} while (nbytes >= bsize * 4);\n\t}\n\n\t/* Handle leftovers */\n\tfor (;;) {\n\t\tblowfish_dec_blk(ctx, (u8 *)dst, (u8 *)src);\n\n\t\tnbytes -= bsize;\n\t\tif (nbytes < bsize)\n\t\t\tbreak;\n\n\t\t*dst ^= *(src - 1);\n\t\tsrc -= 1;\n\t\tdst -= 1;\n\t}\n\ndone:\n\t*dst ^= *(u64 *)walk->iv;\n\t*(u64 *)walk->iv = last_iv;\n\n\treturn nbytes;\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\twhile ((nbytes = walk.nbytes)) {\n\t\tnbytes = __cbc_decrypt(desc, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\n\treturn err;\n}\n\nstatic void ctr_crypt_final(struct bf_ctx *ctx, struct blkcipher_walk *walk)\n{\n\tu8 *ctrblk = walk->iv;\n\tu8 keystream[BF_BLOCK_SIZE];\n\tu8 *src = walk->src.virt.addr;\n\tu8 *dst = walk->dst.virt.addr;\n\tunsigned int nbytes = walk->nbytes;\n\n\tblowfish_enc_blk(ctx, keystream, ctrblk);\n\tcrypto_xor(keystream, src, nbytes);\n\tmemcpy(dst, keystream, nbytes);\n\n\tcrypto_inc(ctrblk, BF_BLOCK_SIZE);\n}\n\nstatic unsigned int __ctr_crypt(struct blkcipher_desc *desc,\n\t\t\t\tstruct blkcipher_walk *walk)\n{\n\tstruct bf_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tunsigned int bsize = BF_BLOCK_SIZE;\n\tunsigned int nbytes = walk->nbytes;\n\tu64 *src = (u64 *)walk->src.virt.addr;\n\tu64 *dst = (u64 *)walk->dst.virt.addr;\n\tu64 ctrblk = be64_to_cpu(*(__be64 *)walk->iv);\n\t__be64 ctrblocks[4];\n\n\t/* Process four block batch */\n\tif (nbytes >= bsize * 4) {\n\t\tdo {\n\t\t\tif (dst != src) {\n\t\t\t\tdst[0] = src[0];\n\t\t\t\tdst[1] = src[1];\n\t\t\t\tdst[2] = src[2];\n\t\t\t\tdst[3] = src[3];\n\t\t\t}\n\n\t\t\t/* create ctrblks for parallel encrypt */\n\t\t\tctrblocks[0] = cpu_to_be64(ctrblk++);\n\t\t\tctrblocks[1] = cpu_to_be64(ctrblk++);\n\t\t\tctrblocks[2] = cpu_to_be64(ctrblk++);\n\t\t\tctrblocks[3] = cpu_to_be64(ctrblk++);\n\n\t\t\tblowfish_enc_blk_xor_4way(ctx, (u8 *)dst,\n\t\t\t\t\t\t  (u8 *)ctrblocks);\n\n\t\t\tsrc += 4;\n\t\t\tdst += 4;\n\t\t} while ((nbytes -= bsize * 4) >= bsize * 4);\n\n\t\tif (nbytes < bsize)\n\t\t\tgoto done;\n\t}\n\n\t/* Handle leftovers */\n\tdo {\n\t\tif (dst != src)\n\t\t\t*dst = *src;\n\n\t\tctrblocks[0] = cpu_to_be64(ctrblk++);\n\n\t\tblowfish_enc_blk_xor(ctx, (u8 *)dst, (u8 *)ctrblocks);\n\n\t\tsrc += 1;\n\t\tdst += 1;\n\t} while ((nbytes -= bsize) >= bsize);\n\ndone:\n\t*(__be64 *)walk->iv = cpu_to_be64(ctrblk);\n\treturn nbytes;\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt_block(desc, &walk, BF_BLOCK_SIZE);\n\n\twhile ((nbytes = walk.nbytes) >= BF_BLOCK_SIZE) {\n\t\tnbytes = __ctr_crypt(desc, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\n\tif (walk.nbytes) {\n\t\tctr_crypt_final(crypto_blkcipher_ctx(desc->tfm), &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, 0);\n\t}\n\n\treturn err;\n}\n\nstatic struct crypto_alg bf_algs[4] = { {\n\t.cra_name\t\t= \"blowfish\",\n\t.cra_driver_name\t= \"blowfish-asm\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= BF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct bf_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.cipher = {\n\t\t\t.cia_min_keysize\t= BF_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t= BF_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t= blowfish_setkey,\n\t\t\t.cia_encrypt\t\t= blowfish_encrypt,\n\t\t\t.cia_decrypt\t\t= blowfish_decrypt,\n\t\t}\n\t}\n}, {\n\t.cra_name\t\t= \"ecb(blowfish)\",\n\t.cra_driver_name\t= \"ecb-blowfish-asm\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= BF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct bf_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= BF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= BF_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= blowfish_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(blowfish)\",\n\t.cra_driver_name\t= \"cbc-blowfish-asm\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= BF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct bf_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= BF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= BF_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= BF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= blowfish_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(blowfish)\",\n\t.cra_driver_name\t= \"ctr-blowfish-asm\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct bf_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= BF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= BF_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= BF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= blowfish_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n} };\n\nstatic bool is_blacklisted_cpu(void)\n{\n\tif (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL)\n\t\treturn false;\n\n\tif (boot_cpu_data.x86 == 0x0f) {\n\t\t/*\n\t\t * On Pentium 4, blowfish-x86_64 is slower than generic C\n\t\t * implementation because use of 64bit rotates (which are really\n\t\t * slow on P4). Therefore blacklist P4s.\n\t\t */\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic int force;\nmodule_param(force, int, 0);\nMODULE_PARM_DESC(force, \"Force module load, ignore CPU blacklist\");\n\nstatic int __init init(void)\n{\n\tif (!force && is_blacklisted_cpu()) {\n\t\tprintk(KERN_INFO\n\t\t\t\"blowfish-x86_64: performance on this CPU \"\n\t\t\t\"would be suboptimal: disabling \"\n\t\t\t\"blowfish-x86_64.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(bf_algs, ARRAY_SIZE(bf_algs));\n}\n\nstatic void __exit fini(void)\n{\n\tcrypto_unregister_algs(bf_algs, ARRAY_SIZE(bf_algs));\n}\n\nmodule_init(init);\nmodule_exit(fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Blowfish Cipher Algorithm, asm optimized\");\nMODULE_ALIAS(\"blowfish\");\nMODULE_ALIAS(\"blowfish-asm\");\n", "/*\n * Glue Code for x86_64/AVX2/AES-NI assembler optimized version of Camellia\n *\n * Copyright \u00a9 2013 Jussi Kivilinna <jussi.kivilinna@mbnet.fi>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n\n#include <linux/module.h>\n#include <linux/types.h>\n#include <linux/crypto.h>\n#include <linux/err.h>\n#include <crypto/ablk_helper.h>\n#include <crypto/algapi.h>\n#include <crypto/ctr.h>\n#include <crypto/lrw.h>\n#include <crypto/xts.h>\n#include <asm/xcr.h>\n#include <asm/xsave.h>\n#include <asm/crypto/camellia.h>\n#include <asm/crypto/glue_helper.h>\n\n#define CAMELLIA_AESNI_PARALLEL_BLOCKS 16\n#define CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS 32\n\n/* 32-way AVX2/AES-NI parallel cipher functions */\nasmlinkage void camellia_ecb_enc_32way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t       const u8 *src);\nasmlinkage void camellia_ecb_dec_32way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t       const u8 *src);\n\nasmlinkage void camellia_cbc_dec_32way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t       const u8 *src);\nasmlinkage void camellia_ctr_32way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t   const u8 *src, le128 *iv);\n\nasmlinkage void camellia_xts_enc_32way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t       const u8 *src, le128 *iv);\nasmlinkage void camellia_xts_dec_32way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t       const u8 *src, le128 *iv);\n\nstatic const struct common_glue_ctx camellia_enc = {\n\t.num_funcs = 4,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_ecb_enc_32way) }\n\t}, {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_ecb_enc_16way) }\n\t}, {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_enc_blk_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_enc_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_ctr = {\n\t.num_funcs = 4,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(camellia_ctr_32way) }\n\t}, {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(camellia_ctr_16way) }\n\t}, {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(camellia_crypt_ctr_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(camellia_crypt_ctr) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_enc_xts = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(camellia_xts_enc_32way) }\n\t}, {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(camellia_xts_enc_16way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(camellia_xts_enc) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_dec = {\n\t.num_funcs = 4,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_ecb_dec_32way) }\n\t}, {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_ecb_dec_16way) }\n\t}, {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_dec_blk_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_dec_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_dec_cbc = {\n\t.num_funcs = 4,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(camellia_cbc_dec_32way) }\n\t}, {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(camellia_cbc_dec_16way) }\n\t}, {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(camellia_decrypt_cbc_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(camellia_dec_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_dec_xts = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(camellia_xts_dec_32way) }\n\t}, {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(camellia_xts_dec_16way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(camellia_xts_dec) }\n\t} }\n};\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&camellia_enc, desc, dst, src, nbytes);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&camellia_dec, desc, dst, src, nbytes);\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_encrypt_128bit(GLUE_FUNC_CAST(camellia_enc_blk), desc,\n\t\t\t\t       dst, src, nbytes);\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_decrypt_128bit(&camellia_dec_cbc, desc, dst, src,\n\t\t\t\t       nbytes);\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ctr_crypt_128bit(&camellia_ctr, desc, dst, src, nbytes);\n}\n\nstatic inline bool camellia_fpu_begin(bool fpu_enabled, unsigned int nbytes)\n{\n\treturn glue_fpu_begin(CAMELLIA_BLOCK_SIZE,\n\t\t\t      CAMELLIA_AESNI_PARALLEL_BLOCKS, NULL, fpu_enabled,\n\t\t\t      nbytes);\n}\n\nstatic inline void camellia_fpu_end(bool fpu_enabled)\n{\n\tglue_fpu_end(fpu_enabled);\n}\n\nstatic int camellia_setkey(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t\t   unsigned int key_len)\n{\n\treturn __camellia_setkey(crypto_tfm_ctx(tfm), in_key, key_len,\n\t\t\t\t &tfm->crt_flags);\n}\n\nstruct crypt_priv {\n\tstruct camellia_ctx *ctx;\n\tbool fpu_enabled;\n};\n\nstatic void encrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = CAMELLIA_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = camellia_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes >= CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS * bsize) {\n\t\tcamellia_ecb_enc_32way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS;\n\t}\n\n\tif (nbytes >= CAMELLIA_AESNI_PARALLEL_BLOCKS * bsize) {\n\t\tcamellia_ecb_enc_16way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * CAMELLIA_AESNI_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * CAMELLIA_AESNI_PARALLEL_BLOCKS;\n\t}\n\n\twhile (nbytes >= CAMELLIA_PARALLEL_BLOCKS * bsize) {\n\t\tcamellia_enc_blk_2way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * CAMELLIA_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * CAMELLIA_PARALLEL_BLOCKS;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\tcamellia_enc_blk(ctx->ctx, srcdst, srcdst);\n}\n\nstatic void decrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = CAMELLIA_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = camellia_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes >= CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS * bsize) {\n\t\tcamellia_ecb_dec_32way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS;\n\t}\n\n\tif (nbytes >= CAMELLIA_AESNI_PARALLEL_BLOCKS * bsize) {\n\t\tcamellia_ecb_dec_16way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * CAMELLIA_AESNI_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * CAMELLIA_AESNI_PARALLEL_BLOCKS;\n\t}\n\n\twhile (nbytes >= CAMELLIA_PARALLEL_BLOCKS * bsize) {\n\t\tcamellia_dec_blk_2way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * CAMELLIA_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * CAMELLIA_PARALLEL_BLOCKS;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\tcamellia_dec_blk(ctx->ctx, srcdst, srcdst);\n}\n\nstatic int lrw_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->camellia_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tcamellia_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int lrw_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->camellia_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tcamellia_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&camellia_enc_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(camellia_enc_blk),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&camellia_dec_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(camellia_enc_blk),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic struct crypto_alg cmll_algs[10] = { {\n\t.cra_name\t\t= \"__ecb-camellia-aesni-avx2\",\n\t.cra_driver_name\t= \"__driver-ecb-camellia-aesni-avx2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= camellia_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__cbc-camellia-aesni-avx2\",\n\t.cra_driver_name\t= \"__driver-cbc-camellia-aesni-avx2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= camellia_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__ctr-camellia-aesni-avx2\",\n\t.cra_driver_name\t= \"__driver-ctr-camellia-aesni-avx2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= camellia_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__lrw-camellia-aesni-avx2\",\n\t.cra_driver_name\t= \"__driver-lrw-camellia-aesni-avx2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_lrw_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_exit\t\t= lrw_camellia_exit_tfm,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE +\n\t\t\t\t\t  CAMELLIA_BLOCK_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE +\n\t\t\t\t\t  CAMELLIA_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= lrw_camellia_setkey,\n\t\t\t.encrypt\t= lrw_encrypt,\n\t\t\t.decrypt\t= lrw_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__xts-camellia-aesni-avx2\",\n\t.cra_driver_name\t= \"__driver-xts-camellia-aesni-avx2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_xts_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= xts_camellia_setkey,\n\t\t\t.encrypt\t= xts_encrypt,\n\t\t\t.decrypt\t= xts_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ecb(camellia)\",\n\t.cra_driver_name\t= \"ecb-camellia-aesni-avx2\",\n\t.cra_priority\t\t= 500,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(camellia)\",\n\t.cra_driver_name\t= \"cbc-camellia-aesni-avx2\",\n\t.cra_priority\t\t= 500,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= __ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(camellia)\",\n\t.cra_driver_name\t= \"ctr-camellia-aesni-avx2\",\n\t.cra_priority\t\t= 500,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_encrypt,\n\t\t\t.geniv\t\t= \"chainiv\",\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"lrw(camellia)\",\n\t.cra_driver_name\t= \"lrw-camellia-aesni-avx2\",\n\t.cra_priority\t\t= 500,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE +\n\t\t\t\t\t  CAMELLIA_BLOCK_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE +\n\t\t\t\t\t  CAMELLIA_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"xts(camellia)\",\n\t.cra_driver_name\t= \"xts-camellia-aesni-avx2\",\n\t.cra_priority\t\t= 500,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n} };\n\nstatic int __init camellia_aesni_init(void)\n{\n\tu64 xcr0;\n\n\tif (!cpu_has_avx2 || !cpu_has_avx || !cpu_has_aes || !cpu_has_osxsave) {\n\t\tpr_info(\"AVX2 or AES-NI instructions are not detected.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\txcr0 = xgetbv(XCR_XFEATURE_ENABLED_MASK);\n\tif ((xcr0 & (XSTATE_SSE | XSTATE_YMM)) != (XSTATE_SSE | XSTATE_YMM)) {\n\t\tpr_info(\"AVX2 detected but unusable.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(cmll_algs, ARRAY_SIZE(cmll_algs));\n}\n\nstatic void __exit camellia_aesni_fini(void)\n{\n\tcrypto_unregister_algs(cmll_algs, ARRAY_SIZE(cmll_algs));\n}\n\nmodule_init(camellia_aesni_init);\nmodule_exit(camellia_aesni_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Camellia Cipher Algorithm, AES-NI/AVX2 optimized\");\nMODULE_ALIAS(\"camellia\");\nMODULE_ALIAS(\"camellia-asm\");\n", "/*\n * Glue Code for x86_64/AVX/AES-NI assembler optimized version of Camellia\n *\n * Copyright \u00a9 2012-2013 Jussi Kivilinna <jussi.kivilinna@iki.fi>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n\n#include <linux/module.h>\n#include <linux/types.h>\n#include <linux/crypto.h>\n#include <linux/err.h>\n#include <crypto/ablk_helper.h>\n#include <crypto/algapi.h>\n#include <crypto/ctr.h>\n#include <crypto/lrw.h>\n#include <crypto/xts.h>\n#include <asm/xcr.h>\n#include <asm/xsave.h>\n#include <asm/crypto/camellia.h>\n#include <asm/crypto/glue_helper.h>\n\n#define CAMELLIA_AESNI_PARALLEL_BLOCKS 16\n\n/* 16-way parallel cipher functions (avx/aes-ni) */\nasmlinkage void camellia_ecb_enc_16way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t       const u8 *src);\nEXPORT_SYMBOL_GPL(camellia_ecb_enc_16way);\n\nasmlinkage void camellia_ecb_dec_16way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t       const u8 *src);\nEXPORT_SYMBOL_GPL(camellia_ecb_dec_16way);\n\nasmlinkage void camellia_cbc_dec_16way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t       const u8 *src);\nEXPORT_SYMBOL_GPL(camellia_cbc_dec_16way);\n\nasmlinkage void camellia_ctr_16way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t   const u8 *src, le128 *iv);\nEXPORT_SYMBOL_GPL(camellia_ctr_16way);\n\nasmlinkage void camellia_xts_enc_16way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t       const u8 *src, le128 *iv);\nEXPORT_SYMBOL_GPL(camellia_xts_enc_16way);\n\nasmlinkage void camellia_xts_dec_16way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t       const u8 *src, le128 *iv);\nEXPORT_SYMBOL_GPL(camellia_xts_dec_16way);\n\nvoid camellia_xts_enc(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tglue_xts_crypt_128bit_one(ctx, dst, src, iv,\n\t\t\t\t  GLUE_FUNC_CAST(camellia_enc_blk));\n}\nEXPORT_SYMBOL_GPL(camellia_xts_enc);\n\nvoid camellia_xts_dec(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tglue_xts_crypt_128bit_one(ctx, dst, src, iv,\n\t\t\t\t  GLUE_FUNC_CAST(camellia_dec_blk));\n}\nEXPORT_SYMBOL_GPL(camellia_xts_dec);\n\nstatic const struct common_glue_ctx camellia_enc = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_ecb_enc_16way) }\n\t}, {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_enc_blk_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_enc_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_ctr = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(camellia_ctr_16way) }\n\t}, {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(camellia_crypt_ctr_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(camellia_crypt_ctr) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_enc_xts = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(camellia_xts_enc_16way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(camellia_xts_enc) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_dec = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_ecb_dec_16way) }\n\t}, {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_dec_blk_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_dec_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_dec_cbc = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(camellia_cbc_dec_16way) }\n\t}, {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(camellia_decrypt_cbc_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(camellia_dec_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_dec_xts = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(camellia_xts_dec_16way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(camellia_xts_dec) }\n\t} }\n};\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&camellia_enc, desc, dst, src, nbytes);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&camellia_dec, desc, dst, src, nbytes);\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_encrypt_128bit(GLUE_FUNC_CAST(camellia_enc_blk), desc,\n\t\t\t\t       dst, src, nbytes);\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_decrypt_128bit(&camellia_dec_cbc, desc, dst, src,\n\t\t\t\t       nbytes);\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ctr_crypt_128bit(&camellia_ctr, desc, dst, src, nbytes);\n}\n\nstatic inline bool camellia_fpu_begin(bool fpu_enabled, unsigned int nbytes)\n{\n\treturn glue_fpu_begin(CAMELLIA_BLOCK_SIZE,\n\t\t\t      CAMELLIA_AESNI_PARALLEL_BLOCKS, NULL, fpu_enabled,\n\t\t\t      nbytes);\n}\n\nstatic inline void camellia_fpu_end(bool fpu_enabled)\n{\n\tglue_fpu_end(fpu_enabled);\n}\n\nstatic int camellia_setkey(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t\t   unsigned int key_len)\n{\n\treturn __camellia_setkey(crypto_tfm_ctx(tfm), in_key, key_len,\n\t\t\t\t &tfm->crt_flags);\n}\n\nstruct crypt_priv {\n\tstruct camellia_ctx *ctx;\n\tbool fpu_enabled;\n};\n\nstatic void encrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = CAMELLIA_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = camellia_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes >= CAMELLIA_AESNI_PARALLEL_BLOCKS * bsize) {\n\t\tcamellia_ecb_enc_16way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * CAMELLIA_AESNI_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * CAMELLIA_AESNI_PARALLEL_BLOCKS;\n\t}\n\n\twhile (nbytes >= CAMELLIA_PARALLEL_BLOCKS * bsize) {\n\t\tcamellia_enc_blk_2way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * CAMELLIA_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * CAMELLIA_PARALLEL_BLOCKS;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\tcamellia_enc_blk(ctx->ctx, srcdst, srcdst);\n}\n\nstatic void decrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = CAMELLIA_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = camellia_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes >= CAMELLIA_AESNI_PARALLEL_BLOCKS * bsize) {\n\t\tcamellia_ecb_dec_16way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * CAMELLIA_AESNI_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * CAMELLIA_AESNI_PARALLEL_BLOCKS;\n\t}\n\n\twhile (nbytes >= CAMELLIA_PARALLEL_BLOCKS * bsize) {\n\t\tcamellia_dec_blk_2way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * CAMELLIA_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * CAMELLIA_PARALLEL_BLOCKS;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\tcamellia_dec_blk(ctx->ctx, srcdst, srcdst);\n}\n\nstatic int lrw_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[CAMELLIA_AESNI_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->camellia_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tcamellia_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int lrw_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[CAMELLIA_AESNI_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->camellia_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tcamellia_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&camellia_enc_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(camellia_enc_blk),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&camellia_dec_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(camellia_enc_blk),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic struct crypto_alg cmll_algs[10] = { {\n\t.cra_name\t\t= \"__ecb-camellia-aesni\",\n\t.cra_driver_name\t= \"__driver-ecb-camellia-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= camellia_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__cbc-camellia-aesni\",\n\t.cra_driver_name\t= \"__driver-cbc-camellia-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= camellia_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__ctr-camellia-aesni\",\n\t.cra_driver_name\t= \"__driver-ctr-camellia-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= camellia_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__lrw-camellia-aesni\",\n\t.cra_driver_name\t= \"__driver-lrw-camellia-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_lrw_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_exit\t\t= lrw_camellia_exit_tfm,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE +\n\t\t\t\t\t  CAMELLIA_BLOCK_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE +\n\t\t\t\t\t  CAMELLIA_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= lrw_camellia_setkey,\n\t\t\t.encrypt\t= lrw_encrypt,\n\t\t\t.decrypt\t= lrw_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__xts-camellia-aesni\",\n\t.cra_driver_name\t= \"__driver-xts-camellia-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_xts_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= xts_camellia_setkey,\n\t\t\t.encrypt\t= xts_encrypt,\n\t\t\t.decrypt\t= xts_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ecb(camellia)\",\n\t.cra_driver_name\t= \"ecb-camellia-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(camellia)\",\n\t.cra_driver_name\t= \"cbc-camellia-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= __ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(camellia)\",\n\t.cra_driver_name\t= \"ctr-camellia-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_encrypt,\n\t\t\t.geniv\t\t= \"chainiv\",\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"lrw(camellia)\",\n\t.cra_driver_name\t= \"lrw-camellia-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE +\n\t\t\t\t\t  CAMELLIA_BLOCK_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE +\n\t\t\t\t\t  CAMELLIA_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"xts(camellia)\",\n\t.cra_driver_name\t= \"xts-camellia-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n} };\n\nstatic int __init camellia_aesni_init(void)\n{\n\tu64 xcr0;\n\n\tif (!cpu_has_avx || !cpu_has_aes || !cpu_has_osxsave) {\n\t\tpr_info(\"AVX or AES-NI instructions are not detected.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\txcr0 = xgetbv(XCR_XFEATURE_ENABLED_MASK);\n\tif ((xcr0 & (XSTATE_SSE | XSTATE_YMM)) != (XSTATE_SSE | XSTATE_YMM)) {\n\t\tpr_info(\"AVX detected but unusable.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(cmll_algs, ARRAY_SIZE(cmll_algs));\n}\n\nstatic void __exit camellia_aesni_fini(void)\n{\n\tcrypto_unregister_algs(cmll_algs, ARRAY_SIZE(cmll_algs));\n}\n\nmodule_init(camellia_aesni_init);\nmodule_exit(camellia_aesni_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Camellia Cipher Algorithm, AES-NI/AVX optimized\");\nMODULE_ALIAS(\"camellia\");\nMODULE_ALIAS(\"camellia-asm\");\n", "/*\n * Glue Code for assembler optimized version of Camellia\n *\n * Copyright (c) 2012 Jussi Kivilinna <jussi.kivilinna@mbnet.fi>\n *\n * Camellia parts based on code by:\n *  Copyright (C) 2006 NTT (Nippon Telegraph and Telephone Corporation)\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307\n * USA\n *\n */\n\n#include <asm/processor.h>\n#include <asm/unaligned.h>\n#include <linux/crypto.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/types.h>\n#include <crypto/algapi.h>\n#include <crypto/lrw.h>\n#include <crypto/xts.h>\n#include <asm/crypto/camellia.h>\n#include <asm/crypto/glue_helper.h>\n\n/* regular block cipher functions */\nasmlinkage void __camellia_enc_blk(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t   const u8 *src, bool xor);\nEXPORT_SYMBOL_GPL(__camellia_enc_blk);\nasmlinkage void camellia_dec_blk(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t const u8 *src);\nEXPORT_SYMBOL_GPL(camellia_dec_blk);\n\n/* 2-way parallel cipher functions */\nasmlinkage void __camellia_enc_blk_2way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t\tconst u8 *src, bool xor);\nEXPORT_SYMBOL_GPL(__camellia_enc_blk_2way);\nasmlinkage void camellia_dec_blk_2way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t      const u8 *src);\nEXPORT_SYMBOL_GPL(camellia_dec_blk_2way);\n\nstatic void camellia_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tcamellia_enc_blk(crypto_tfm_ctx(tfm), dst, src);\n}\n\nstatic void camellia_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tcamellia_dec_blk(crypto_tfm_ctx(tfm), dst, src);\n}\n\n/* camellia sboxes */\n__visible const u64 camellia_sp10011110[256] = {\n\t0x7000007070707000ULL, 0x8200008282828200ULL, 0x2c00002c2c2c2c00ULL,\n\t0xec0000ecececec00ULL, 0xb30000b3b3b3b300ULL, 0x2700002727272700ULL,\n\t0xc00000c0c0c0c000ULL, 0xe50000e5e5e5e500ULL, 0xe40000e4e4e4e400ULL,\n\t0x8500008585858500ULL, 0x5700005757575700ULL, 0x3500003535353500ULL,\n\t0xea0000eaeaeaea00ULL, 0x0c00000c0c0c0c00ULL, 0xae0000aeaeaeae00ULL,\n\t0x4100004141414100ULL, 0x2300002323232300ULL, 0xef0000efefefef00ULL,\n\t0x6b00006b6b6b6b00ULL, 0x9300009393939300ULL, 0x4500004545454500ULL,\n\t0x1900001919191900ULL, 0xa50000a5a5a5a500ULL, 0x2100002121212100ULL,\n\t0xed0000edededed00ULL, 0x0e00000e0e0e0e00ULL, 0x4f00004f4f4f4f00ULL,\n\t0x4e00004e4e4e4e00ULL, 0x1d00001d1d1d1d00ULL, 0x6500006565656500ULL,\n\t0x9200009292929200ULL, 0xbd0000bdbdbdbd00ULL, 0x8600008686868600ULL,\n\t0xb80000b8b8b8b800ULL, 0xaf0000afafafaf00ULL, 0x8f00008f8f8f8f00ULL,\n\t0x7c00007c7c7c7c00ULL, 0xeb0000ebebebeb00ULL, 0x1f00001f1f1f1f00ULL,\n\t0xce0000cececece00ULL, 0x3e00003e3e3e3e00ULL, 0x3000003030303000ULL,\n\t0xdc0000dcdcdcdc00ULL, 0x5f00005f5f5f5f00ULL, 0x5e00005e5e5e5e00ULL,\n\t0xc50000c5c5c5c500ULL, 0x0b00000b0b0b0b00ULL, 0x1a00001a1a1a1a00ULL,\n\t0xa60000a6a6a6a600ULL, 0xe10000e1e1e1e100ULL, 0x3900003939393900ULL,\n\t0xca0000cacacaca00ULL, 0xd50000d5d5d5d500ULL, 0x4700004747474700ULL,\n\t0x5d00005d5d5d5d00ULL, 0x3d00003d3d3d3d00ULL, 0xd90000d9d9d9d900ULL,\n\t0x0100000101010100ULL, 0x5a00005a5a5a5a00ULL, 0xd60000d6d6d6d600ULL,\n\t0x5100005151515100ULL, 0x5600005656565600ULL, 0x6c00006c6c6c6c00ULL,\n\t0x4d00004d4d4d4d00ULL, 0x8b00008b8b8b8b00ULL, 0x0d00000d0d0d0d00ULL,\n\t0x9a00009a9a9a9a00ULL, 0x6600006666666600ULL, 0xfb0000fbfbfbfb00ULL,\n\t0xcc0000cccccccc00ULL, 0xb00000b0b0b0b000ULL, 0x2d00002d2d2d2d00ULL,\n\t0x7400007474747400ULL, 0x1200001212121200ULL, 0x2b00002b2b2b2b00ULL,\n\t0x2000002020202000ULL, 0xf00000f0f0f0f000ULL, 0xb10000b1b1b1b100ULL,\n\t0x8400008484848400ULL, 0x9900009999999900ULL, 0xdf0000dfdfdfdf00ULL,\n\t0x4c00004c4c4c4c00ULL, 0xcb0000cbcbcbcb00ULL, 0xc20000c2c2c2c200ULL,\n\t0x3400003434343400ULL, 0x7e00007e7e7e7e00ULL, 0x7600007676767600ULL,\n\t0x0500000505050500ULL, 0x6d00006d6d6d6d00ULL, 0xb70000b7b7b7b700ULL,\n\t0xa90000a9a9a9a900ULL, 0x3100003131313100ULL, 0xd10000d1d1d1d100ULL,\n\t0x1700001717171700ULL, 0x0400000404040400ULL, 0xd70000d7d7d7d700ULL,\n\t0x1400001414141400ULL, 0x5800005858585800ULL, 0x3a00003a3a3a3a00ULL,\n\t0x6100006161616100ULL, 0xde0000dededede00ULL, 0x1b00001b1b1b1b00ULL,\n\t0x1100001111111100ULL, 0x1c00001c1c1c1c00ULL, 0x3200003232323200ULL,\n\t0x0f00000f0f0f0f00ULL, 0x9c00009c9c9c9c00ULL, 0x1600001616161600ULL,\n\t0x5300005353535300ULL, 0x1800001818181800ULL, 0xf20000f2f2f2f200ULL,\n\t0x2200002222222200ULL, 0xfe0000fefefefe00ULL, 0x4400004444444400ULL,\n\t0xcf0000cfcfcfcf00ULL, 0xb20000b2b2b2b200ULL, 0xc30000c3c3c3c300ULL,\n\t0xb50000b5b5b5b500ULL, 0x7a00007a7a7a7a00ULL, 0x9100009191919100ULL,\n\t0x2400002424242400ULL, 0x0800000808080800ULL, 0xe80000e8e8e8e800ULL,\n\t0xa80000a8a8a8a800ULL, 0x6000006060606000ULL, 0xfc0000fcfcfcfc00ULL,\n\t0x6900006969696900ULL, 0x5000005050505000ULL, 0xaa0000aaaaaaaa00ULL,\n\t0xd00000d0d0d0d000ULL, 0xa00000a0a0a0a000ULL, 0x7d00007d7d7d7d00ULL,\n\t0xa10000a1a1a1a100ULL, 0x8900008989898900ULL, 0x6200006262626200ULL,\n\t0x9700009797979700ULL, 0x5400005454545400ULL, 0x5b00005b5b5b5b00ULL,\n\t0x1e00001e1e1e1e00ULL, 0x9500009595959500ULL, 0xe00000e0e0e0e000ULL,\n\t0xff0000ffffffff00ULL, 0x6400006464646400ULL, 0xd20000d2d2d2d200ULL,\n\t0x1000001010101000ULL, 0xc40000c4c4c4c400ULL, 0x0000000000000000ULL,\n\t0x4800004848484800ULL, 0xa30000a3a3a3a300ULL, 0xf70000f7f7f7f700ULL,\n\t0x7500007575757500ULL, 0xdb0000dbdbdbdb00ULL, 0x8a00008a8a8a8a00ULL,\n\t0x0300000303030300ULL, 0xe60000e6e6e6e600ULL, 0xda0000dadadada00ULL,\n\t0x0900000909090900ULL, 0x3f00003f3f3f3f00ULL, 0xdd0000dddddddd00ULL,\n\t0x9400009494949400ULL, 0x8700008787878700ULL, 0x5c00005c5c5c5c00ULL,\n\t0x8300008383838300ULL, 0x0200000202020200ULL, 0xcd0000cdcdcdcd00ULL,\n\t0x4a00004a4a4a4a00ULL, 0x9000009090909000ULL, 0x3300003333333300ULL,\n\t0x7300007373737300ULL, 0x6700006767676700ULL, 0xf60000f6f6f6f600ULL,\n\t0xf30000f3f3f3f300ULL, 0x9d00009d9d9d9d00ULL, 0x7f00007f7f7f7f00ULL,\n\t0xbf0000bfbfbfbf00ULL, 0xe20000e2e2e2e200ULL, 0x5200005252525200ULL,\n\t0x9b00009b9b9b9b00ULL, 0xd80000d8d8d8d800ULL, 0x2600002626262600ULL,\n\t0xc80000c8c8c8c800ULL, 0x3700003737373700ULL, 0xc60000c6c6c6c600ULL,\n\t0x3b00003b3b3b3b00ULL, 0x8100008181818100ULL, 0x9600009696969600ULL,\n\t0x6f00006f6f6f6f00ULL, 0x4b00004b4b4b4b00ULL, 0x1300001313131300ULL,\n\t0xbe0000bebebebe00ULL, 0x6300006363636300ULL, 0x2e00002e2e2e2e00ULL,\n\t0xe90000e9e9e9e900ULL, 0x7900007979797900ULL, 0xa70000a7a7a7a700ULL,\n\t0x8c00008c8c8c8c00ULL, 0x9f00009f9f9f9f00ULL, 0x6e00006e6e6e6e00ULL,\n\t0xbc0000bcbcbcbc00ULL, 0x8e00008e8e8e8e00ULL, 0x2900002929292900ULL,\n\t0xf50000f5f5f5f500ULL, 0xf90000f9f9f9f900ULL, 0xb60000b6b6b6b600ULL,\n\t0x2f00002f2f2f2f00ULL, 0xfd0000fdfdfdfd00ULL, 0xb40000b4b4b4b400ULL,\n\t0x5900005959595900ULL, 0x7800007878787800ULL, 0x9800009898989800ULL,\n\t0x0600000606060600ULL, 0x6a00006a6a6a6a00ULL, 0xe70000e7e7e7e700ULL,\n\t0x4600004646464600ULL, 0x7100007171717100ULL, 0xba0000babababa00ULL,\n\t0xd40000d4d4d4d400ULL, 0x2500002525252500ULL, 0xab0000abababab00ULL,\n\t0x4200004242424200ULL, 0x8800008888888800ULL, 0xa20000a2a2a2a200ULL,\n\t0x8d00008d8d8d8d00ULL, 0xfa0000fafafafa00ULL, 0x7200007272727200ULL,\n\t0x0700000707070700ULL, 0xb90000b9b9b9b900ULL, 0x5500005555555500ULL,\n\t0xf80000f8f8f8f800ULL, 0xee0000eeeeeeee00ULL, 0xac0000acacacac00ULL,\n\t0x0a00000a0a0a0a00ULL, 0x3600003636363600ULL, 0x4900004949494900ULL,\n\t0x2a00002a2a2a2a00ULL, 0x6800006868686800ULL, 0x3c00003c3c3c3c00ULL,\n\t0x3800003838383800ULL, 0xf10000f1f1f1f100ULL, 0xa40000a4a4a4a400ULL,\n\t0x4000004040404000ULL, 0x2800002828282800ULL, 0xd30000d3d3d3d300ULL,\n\t0x7b00007b7b7b7b00ULL, 0xbb0000bbbbbbbb00ULL, 0xc90000c9c9c9c900ULL,\n\t0x4300004343434300ULL, 0xc10000c1c1c1c100ULL, 0x1500001515151500ULL,\n\t0xe30000e3e3e3e300ULL, 0xad0000adadadad00ULL, 0xf40000f4f4f4f400ULL,\n\t0x7700007777777700ULL, 0xc70000c7c7c7c700ULL, 0x8000008080808000ULL,\n\t0x9e00009e9e9e9e00ULL,\n};\n\n__visible const u64 camellia_sp22000222[256] = {\n\t0xe0e0000000e0e0e0ULL, 0x0505000000050505ULL, 0x5858000000585858ULL,\n\t0xd9d9000000d9d9d9ULL, 0x6767000000676767ULL, 0x4e4e0000004e4e4eULL,\n\t0x8181000000818181ULL, 0xcbcb000000cbcbcbULL, 0xc9c9000000c9c9c9ULL,\n\t0x0b0b0000000b0b0bULL, 0xaeae000000aeaeaeULL, 0x6a6a0000006a6a6aULL,\n\t0xd5d5000000d5d5d5ULL, 0x1818000000181818ULL, 0x5d5d0000005d5d5dULL,\n\t0x8282000000828282ULL, 0x4646000000464646ULL, 0xdfdf000000dfdfdfULL,\n\t0xd6d6000000d6d6d6ULL, 0x2727000000272727ULL, 0x8a8a0000008a8a8aULL,\n\t0x3232000000323232ULL, 0x4b4b0000004b4b4bULL, 0x4242000000424242ULL,\n\t0xdbdb000000dbdbdbULL, 0x1c1c0000001c1c1cULL, 0x9e9e0000009e9e9eULL,\n\t0x9c9c0000009c9c9cULL, 0x3a3a0000003a3a3aULL, 0xcaca000000cacacaULL,\n\t0x2525000000252525ULL, 0x7b7b0000007b7b7bULL, 0x0d0d0000000d0d0dULL,\n\t0x7171000000717171ULL, 0x5f5f0000005f5f5fULL, 0x1f1f0000001f1f1fULL,\n\t0xf8f8000000f8f8f8ULL, 0xd7d7000000d7d7d7ULL, 0x3e3e0000003e3e3eULL,\n\t0x9d9d0000009d9d9dULL, 0x7c7c0000007c7c7cULL, 0x6060000000606060ULL,\n\t0xb9b9000000b9b9b9ULL, 0xbebe000000bebebeULL, 0xbcbc000000bcbcbcULL,\n\t0x8b8b0000008b8b8bULL, 0x1616000000161616ULL, 0x3434000000343434ULL,\n\t0x4d4d0000004d4d4dULL, 0xc3c3000000c3c3c3ULL, 0x7272000000727272ULL,\n\t0x9595000000959595ULL, 0xabab000000abababULL, 0x8e8e0000008e8e8eULL,\n\t0xbaba000000bababaULL, 0x7a7a0000007a7a7aULL, 0xb3b3000000b3b3b3ULL,\n\t0x0202000000020202ULL, 0xb4b4000000b4b4b4ULL, 0xadad000000adadadULL,\n\t0xa2a2000000a2a2a2ULL, 0xacac000000acacacULL, 0xd8d8000000d8d8d8ULL,\n\t0x9a9a0000009a9a9aULL, 0x1717000000171717ULL, 0x1a1a0000001a1a1aULL,\n\t0x3535000000353535ULL, 0xcccc000000ccccccULL, 0xf7f7000000f7f7f7ULL,\n\t0x9999000000999999ULL, 0x6161000000616161ULL, 0x5a5a0000005a5a5aULL,\n\t0xe8e8000000e8e8e8ULL, 0x2424000000242424ULL, 0x5656000000565656ULL,\n\t0x4040000000404040ULL, 0xe1e1000000e1e1e1ULL, 0x6363000000636363ULL,\n\t0x0909000000090909ULL, 0x3333000000333333ULL, 0xbfbf000000bfbfbfULL,\n\t0x9898000000989898ULL, 0x9797000000979797ULL, 0x8585000000858585ULL,\n\t0x6868000000686868ULL, 0xfcfc000000fcfcfcULL, 0xecec000000ecececULL,\n\t0x0a0a0000000a0a0aULL, 0xdada000000dadadaULL, 0x6f6f0000006f6f6fULL,\n\t0x5353000000535353ULL, 0x6262000000626262ULL, 0xa3a3000000a3a3a3ULL,\n\t0x2e2e0000002e2e2eULL, 0x0808000000080808ULL, 0xafaf000000afafafULL,\n\t0x2828000000282828ULL, 0xb0b0000000b0b0b0ULL, 0x7474000000747474ULL,\n\t0xc2c2000000c2c2c2ULL, 0xbdbd000000bdbdbdULL, 0x3636000000363636ULL,\n\t0x2222000000222222ULL, 0x3838000000383838ULL, 0x6464000000646464ULL,\n\t0x1e1e0000001e1e1eULL, 0x3939000000393939ULL, 0x2c2c0000002c2c2cULL,\n\t0xa6a6000000a6a6a6ULL, 0x3030000000303030ULL, 0xe5e5000000e5e5e5ULL,\n\t0x4444000000444444ULL, 0xfdfd000000fdfdfdULL, 0x8888000000888888ULL,\n\t0x9f9f0000009f9f9fULL, 0x6565000000656565ULL, 0x8787000000878787ULL,\n\t0x6b6b0000006b6b6bULL, 0xf4f4000000f4f4f4ULL, 0x2323000000232323ULL,\n\t0x4848000000484848ULL, 0x1010000000101010ULL, 0xd1d1000000d1d1d1ULL,\n\t0x5151000000515151ULL, 0xc0c0000000c0c0c0ULL, 0xf9f9000000f9f9f9ULL,\n\t0xd2d2000000d2d2d2ULL, 0xa0a0000000a0a0a0ULL, 0x5555000000555555ULL,\n\t0xa1a1000000a1a1a1ULL, 0x4141000000414141ULL, 0xfafa000000fafafaULL,\n\t0x4343000000434343ULL, 0x1313000000131313ULL, 0xc4c4000000c4c4c4ULL,\n\t0x2f2f0000002f2f2fULL, 0xa8a8000000a8a8a8ULL, 0xb6b6000000b6b6b6ULL,\n\t0x3c3c0000003c3c3cULL, 0x2b2b0000002b2b2bULL, 0xc1c1000000c1c1c1ULL,\n\t0xffff000000ffffffULL, 0xc8c8000000c8c8c8ULL, 0xa5a5000000a5a5a5ULL,\n\t0x2020000000202020ULL, 0x8989000000898989ULL, 0x0000000000000000ULL,\n\t0x9090000000909090ULL, 0x4747000000474747ULL, 0xefef000000efefefULL,\n\t0xeaea000000eaeaeaULL, 0xb7b7000000b7b7b7ULL, 0x1515000000151515ULL,\n\t0x0606000000060606ULL, 0xcdcd000000cdcdcdULL, 0xb5b5000000b5b5b5ULL,\n\t0x1212000000121212ULL, 0x7e7e0000007e7e7eULL, 0xbbbb000000bbbbbbULL,\n\t0x2929000000292929ULL, 0x0f0f0000000f0f0fULL, 0xb8b8000000b8b8b8ULL,\n\t0x0707000000070707ULL, 0x0404000000040404ULL, 0x9b9b0000009b9b9bULL,\n\t0x9494000000949494ULL, 0x2121000000212121ULL, 0x6666000000666666ULL,\n\t0xe6e6000000e6e6e6ULL, 0xcece000000cececeULL, 0xeded000000edededULL,\n\t0xe7e7000000e7e7e7ULL, 0x3b3b0000003b3b3bULL, 0xfefe000000fefefeULL,\n\t0x7f7f0000007f7f7fULL, 0xc5c5000000c5c5c5ULL, 0xa4a4000000a4a4a4ULL,\n\t0x3737000000373737ULL, 0xb1b1000000b1b1b1ULL, 0x4c4c0000004c4c4cULL,\n\t0x9191000000919191ULL, 0x6e6e0000006e6e6eULL, 0x8d8d0000008d8d8dULL,\n\t0x7676000000767676ULL, 0x0303000000030303ULL, 0x2d2d0000002d2d2dULL,\n\t0xdede000000dededeULL, 0x9696000000969696ULL, 0x2626000000262626ULL,\n\t0x7d7d0000007d7d7dULL, 0xc6c6000000c6c6c6ULL, 0x5c5c0000005c5c5cULL,\n\t0xd3d3000000d3d3d3ULL, 0xf2f2000000f2f2f2ULL, 0x4f4f0000004f4f4fULL,\n\t0x1919000000191919ULL, 0x3f3f0000003f3f3fULL, 0xdcdc000000dcdcdcULL,\n\t0x7979000000797979ULL, 0x1d1d0000001d1d1dULL, 0x5252000000525252ULL,\n\t0xebeb000000ebebebULL, 0xf3f3000000f3f3f3ULL, 0x6d6d0000006d6d6dULL,\n\t0x5e5e0000005e5e5eULL, 0xfbfb000000fbfbfbULL, 0x6969000000696969ULL,\n\t0xb2b2000000b2b2b2ULL, 0xf0f0000000f0f0f0ULL, 0x3131000000313131ULL,\n\t0x0c0c0000000c0c0cULL, 0xd4d4000000d4d4d4ULL, 0xcfcf000000cfcfcfULL,\n\t0x8c8c0000008c8c8cULL, 0xe2e2000000e2e2e2ULL, 0x7575000000757575ULL,\n\t0xa9a9000000a9a9a9ULL, 0x4a4a0000004a4a4aULL, 0x5757000000575757ULL,\n\t0x8484000000848484ULL, 0x1111000000111111ULL, 0x4545000000454545ULL,\n\t0x1b1b0000001b1b1bULL, 0xf5f5000000f5f5f5ULL, 0xe4e4000000e4e4e4ULL,\n\t0x0e0e0000000e0e0eULL, 0x7373000000737373ULL, 0xaaaa000000aaaaaaULL,\n\t0xf1f1000000f1f1f1ULL, 0xdddd000000ddddddULL, 0x5959000000595959ULL,\n\t0x1414000000141414ULL, 0x6c6c0000006c6c6cULL, 0x9292000000929292ULL,\n\t0x5454000000545454ULL, 0xd0d0000000d0d0d0ULL, 0x7878000000787878ULL,\n\t0x7070000000707070ULL, 0xe3e3000000e3e3e3ULL, 0x4949000000494949ULL,\n\t0x8080000000808080ULL, 0x5050000000505050ULL, 0xa7a7000000a7a7a7ULL,\n\t0xf6f6000000f6f6f6ULL, 0x7777000000777777ULL, 0x9393000000939393ULL,\n\t0x8686000000868686ULL, 0x8383000000838383ULL, 0x2a2a0000002a2a2aULL,\n\t0xc7c7000000c7c7c7ULL, 0x5b5b0000005b5b5bULL, 0xe9e9000000e9e9e9ULL,\n\t0xeeee000000eeeeeeULL, 0x8f8f0000008f8f8fULL, 0x0101000000010101ULL,\n\t0x3d3d0000003d3d3dULL,\n};\n\n__visible const u64 camellia_sp03303033[256] = {\n\t0x0038380038003838ULL, 0x0041410041004141ULL, 0x0016160016001616ULL,\n\t0x0076760076007676ULL, 0x00d9d900d900d9d9ULL, 0x0093930093009393ULL,\n\t0x0060600060006060ULL, 0x00f2f200f200f2f2ULL, 0x0072720072007272ULL,\n\t0x00c2c200c200c2c2ULL, 0x00abab00ab00ababULL, 0x009a9a009a009a9aULL,\n\t0x0075750075007575ULL, 0x0006060006000606ULL, 0x0057570057005757ULL,\n\t0x00a0a000a000a0a0ULL, 0x0091910091009191ULL, 0x00f7f700f700f7f7ULL,\n\t0x00b5b500b500b5b5ULL, 0x00c9c900c900c9c9ULL, 0x00a2a200a200a2a2ULL,\n\t0x008c8c008c008c8cULL, 0x00d2d200d200d2d2ULL, 0x0090900090009090ULL,\n\t0x00f6f600f600f6f6ULL, 0x0007070007000707ULL, 0x00a7a700a700a7a7ULL,\n\t0x0027270027002727ULL, 0x008e8e008e008e8eULL, 0x00b2b200b200b2b2ULL,\n\t0x0049490049004949ULL, 0x00dede00de00dedeULL, 0x0043430043004343ULL,\n\t0x005c5c005c005c5cULL, 0x00d7d700d700d7d7ULL, 0x00c7c700c700c7c7ULL,\n\t0x003e3e003e003e3eULL, 0x00f5f500f500f5f5ULL, 0x008f8f008f008f8fULL,\n\t0x0067670067006767ULL, 0x001f1f001f001f1fULL, 0x0018180018001818ULL,\n\t0x006e6e006e006e6eULL, 0x00afaf00af00afafULL, 0x002f2f002f002f2fULL,\n\t0x00e2e200e200e2e2ULL, 0x0085850085008585ULL, 0x000d0d000d000d0dULL,\n\t0x0053530053005353ULL, 0x00f0f000f000f0f0ULL, 0x009c9c009c009c9cULL,\n\t0x0065650065006565ULL, 0x00eaea00ea00eaeaULL, 0x00a3a300a300a3a3ULL,\n\t0x00aeae00ae00aeaeULL, 0x009e9e009e009e9eULL, 0x00ecec00ec00ececULL,\n\t0x0080800080008080ULL, 0x002d2d002d002d2dULL, 0x006b6b006b006b6bULL,\n\t0x00a8a800a800a8a8ULL, 0x002b2b002b002b2bULL, 0x0036360036003636ULL,\n\t0x00a6a600a600a6a6ULL, 0x00c5c500c500c5c5ULL, 0x0086860086008686ULL,\n\t0x004d4d004d004d4dULL, 0x0033330033003333ULL, 0x00fdfd00fd00fdfdULL,\n\t0x0066660066006666ULL, 0x0058580058005858ULL, 0x0096960096009696ULL,\n\t0x003a3a003a003a3aULL, 0x0009090009000909ULL, 0x0095950095009595ULL,\n\t0x0010100010001010ULL, 0x0078780078007878ULL, 0x00d8d800d800d8d8ULL,\n\t0x0042420042004242ULL, 0x00cccc00cc00ccccULL, 0x00efef00ef00efefULL,\n\t0x0026260026002626ULL, 0x00e5e500e500e5e5ULL, 0x0061610061006161ULL,\n\t0x001a1a001a001a1aULL, 0x003f3f003f003f3fULL, 0x003b3b003b003b3bULL,\n\t0x0082820082008282ULL, 0x00b6b600b600b6b6ULL, 0x00dbdb00db00dbdbULL,\n\t0x00d4d400d400d4d4ULL, 0x0098980098009898ULL, 0x00e8e800e800e8e8ULL,\n\t0x008b8b008b008b8bULL, 0x0002020002000202ULL, 0x00ebeb00eb00ebebULL,\n\t0x000a0a000a000a0aULL, 0x002c2c002c002c2cULL, 0x001d1d001d001d1dULL,\n\t0x00b0b000b000b0b0ULL, 0x006f6f006f006f6fULL, 0x008d8d008d008d8dULL,\n\t0x0088880088008888ULL, 0x000e0e000e000e0eULL, 0x0019190019001919ULL,\n\t0x0087870087008787ULL, 0x004e4e004e004e4eULL, 0x000b0b000b000b0bULL,\n\t0x00a9a900a900a9a9ULL, 0x000c0c000c000c0cULL, 0x0079790079007979ULL,\n\t0x0011110011001111ULL, 0x007f7f007f007f7fULL, 0x0022220022002222ULL,\n\t0x00e7e700e700e7e7ULL, 0x0059590059005959ULL, 0x00e1e100e100e1e1ULL,\n\t0x00dada00da00dadaULL, 0x003d3d003d003d3dULL, 0x00c8c800c800c8c8ULL,\n\t0x0012120012001212ULL, 0x0004040004000404ULL, 0x0074740074007474ULL,\n\t0x0054540054005454ULL, 0x0030300030003030ULL, 0x007e7e007e007e7eULL,\n\t0x00b4b400b400b4b4ULL, 0x0028280028002828ULL, 0x0055550055005555ULL,\n\t0x0068680068006868ULL, 0x0050500050005050ULL, 0x00bebe00be00bebeULL,\n\t0x00d0d000d000d0d0ULL, 0x00c4c400c400c4c4ULL, 0x0031310031003131ULL,\n\t0x00cbcb00cb00cbcbULL, 0x002a2a002a002a2aULL, 0x00adad00ad00adadULL,\n\t0x000f0f000f000f0fULL, 0x00caca00ca00cacaULL, 0x0070700070007070ULL,\n\t0x00ffff00ff00ffffULL, 0x0032320032003232ULL, 0x0069690069006969ULL,\n\t0x0008080008000808ULL, 0x0062620062006262ULL, 0x0000000000000000ULL,\n\t0x0024240024002424ULL, 0x00d1d100d100d1d1ULL, 0x00fbfb00fb00fbfbULL,\n\t0x00baba00ba00babaULL, 0x00eded00ed00ededULL, 0x0045450045004545ULL,\n\t0x0081810081008181ULL, 0x0073730073007373ULL, 0x006d6d006d006d6dULL,\n\t0x0084840084008484ULL, 0x009f9f009f009f9fULL, 0x00eeee00ee00eeeeULL,\n\t0x004a4a004a004a4aULL, 0x00c3c300c300c3c3ULL, 0x002e2e002e002e2eULL,\n\t0x00c1c100c100c1c1ULL, 0x0001010001000101ULL, 0x00e6e600e600e6e6ULL,\n\t0x0025250025002525ULL, 0x0048480048004848ULL, 0x0099990099009999ULL,\n\t0x00b9b900b900b9b9ULL, 0x00b3b300b300b3b3ULL, 0x007b7b007b007b7bULL,\n\t0x00f9f900f900f9f9ULL, 0x00cece00ce00ceceULL, 0x00bfbf00bf00bfbfULL,\n\t0x00dfdf00df00dfdfULL, 0x0071710071007171ULL, 0x0029290029002929ULL,\n\t0x00cdcd00cd00cdcdULL, 0x006c6c006c006c6cULL, 0x0013130013001313ULL,\n\t0x0064640064006464ULL, 0x009b9b009b009b9bULL, 0x0063630063006363ULL,\n\t0x009d9d009d009d9dULL, 0x00c0c000c000c0c0ULL, 0x004b4b004b004b4bULL,\n\t0x00b7b700b700b7b7ULL, 0x00a5a500a500a5a5ULL, 0x0089890089008989ULL,\n\t0x005f5f005f005f5fULL, 0x00b1b100b100b1b1ULL, 0x0017170017001717ULL,\n\t0x00f4f400f400f4f4ULL, 0x00bcbc00bc00bcbcULL, 0x00d3d300d300d3d3ULL,\n\t0x0046460046004646ULL, 0x00cfcf00cf00cfcfULL, 0x0037370037003737ULL,\n\t0x005e5e005e005e5eULL, 0x0047470047004747ULL, 0x0094940094009494ULL,\n\t0x00fafa00fa00fafaULL, 0x00fcfc00fc00fcfcULL, 0x005b5b005b005b5bULL,\n\t0x0097970097009797ULL, 0x00fefe00fe00fefeULL, 0x005a5a005a005a5aULL,\n\t0x00acac00ac00acacULL, 0x003c3c003c003c3cULL, 0x004c4c004c004c4cULL,\n\t0x0003030003000303ULL, 0x0035350035003535ULL, 0x00f3f300f300f3f3ULL,\n\t0x0023230023002323ULL, 0x00b8b800b800b8b8ULL, 0x005d5d005d005d5dULL,\n\t0x006a6a006a006a6aULL, 0x0092920092009292ULL, 0x00d5d500d500d5d5ULL,\n\t0x0021210021002121ULL, 0x0044440044004444ULL, 0x0051510051005151ULL,\n\t0x00c6c600c600c6c6ULL, 0x007d7d007d007d7dULL, 0x0039390039003939ULL,\n\t0x0083830083008383ULL, 0x00dcdc00dc00dcdcULL, 0x00aaaa00aa00aaaaULL,\n\t0x007c7c007c007c7cULL, 0x0077770077007777ULL, 0x0056560056005656ULL,\n\t0x0005050005000505ULL, 0x001b1b001b001b1bULL, 0x00a4a400a400a4a4ULL,\n\t0x0015150015001515ULL, 0x0034340034003434ULL, 0x001e1e001e001e1eULL,\n\t0x001c1c001c001c1cULL, 0x00f8f800f800f8f8ULL, 0x0052520052005252ULL,\n\t0x0020200020002020ULL, 0x0014140014001414ULL, 0x00e9e900e900e9e9ULL,\n\t0x00bdbd00bd00bdbdULL, 0x00dddd00dd00ddddULL, 0x00e4e400e400e4e4ULL,\n\t0x00a1a100a100a1a1ULL, 0x00e0e000e000e0e0ULL, 0x008a8a008a008a8aULL,\n\t0x00f1f100f100f1f1ULL, 0x00d6d600d600d6d6ULL, 0x007a7a007a007a7aULL,\n\t0x00bbbb00bb00bbbbULL, 0x00e3e300e300e3e3ULL, 0x0040400040004040ULL,\n\t0x004f4f004f004f4fULL,\n};\n\n__visible const u64 camellia_sp00444404[256] = {\n\t0x0000707070700070ULL, 0x00002c2c2c2c002cULL, 0x0000b3b3b3b300b3ULL,\n\t0x0000c0c0c0c000c0ULL, 0x0000e4e4e4e400e4ULL, 0x0000575757570057ULL,\n\t0x0000eaeaeaea00eaULL, 0x0000aeaeaeae00aeULL, 0x0000232323230023ULL,\n\t0x00006b6b6b6b006bULL, 0x0000454545450045ULL, 0x0000a5a5a5a500a5ULL,\n\t0x0000edededed00edULL, 0x00004f4f4f4f004fULL, 0x00001d1d1d1d001dULL,\n\t0x0000929292920092ULL, 0x0000868686860086ULL, 0x0000afafafaf00afULL,\n\t0x00007c7c7c7c007cULL, 0x00001f1f1f1f001fULL, 0x00003e3e3e3e003eULL,\n\t0x0000dcdcdcdc00dcULL, 0x00005e5e5e5e005eULL, 0x00000b0b0b0b000bULL,\n\t0x0000a6a6a6a600a6ULL, 0x0000393939390039ULL, 0x0000d5d5d5d500d5ULL,\n\t0x00005d5d5d5d005dULL, 0x0000d9d9d9d900d9ULL, 0x00005a5a5a5a005aULL,\n\t0x0000515151510051ULL, 0x00006c6c6c6c006cULL, 0x00008b8b8b8b008bULL,\n\t0x00009a9a9a9a009aULL, 0x0000fbfbfbfb00fbULL, 0x0000b0b0b0b000b0ULL,\n\t0x0000747474740074ULL, 0x00002b2b2b2b002bULL, 0x0000f0f0f0f000f0ULL,\n\t0x0000848484840084ULL, 0x0000dfdfdfdf00dfULL, 0x0000cbcbcbcb00cbULL,\n\t0x0000343434340034ULL, 0x0000767676760076ULL, 0x00006d6d6d6d006dULL,\n\t0x0000a9a9a9a900a9ULL, 0x0000d1d1d1d100d1ULL, 0x0000040404040004ULL,\n\t0x0000141414140014ULL, 0x00003a3a3a3a003aULL, 0x0000dededede00deULL,\n\t0x0000111111110011ULL, 0x0000323232320032ULL, 0x00009c9c9c9c009cULL,\n\t0x0000535353530053ULL, 0x0000f2f2f2f200f2ULL, 0x0000fefefefe00feULL,\n\t0x0000cfcfcfcf00cfULL, 0x0000c3c3c3c300c3ULL, 0x00007a7a7a7a007aULL,\n\t0x0000242424240024ULL, 0x0000e8e8e8e800e8ULL, 0x0000606060600060ULL,\n\t0x0000696969690069ULL, 0x0000aaaaaaaa00aaULL, 0x0000a0a0a0a000a0ULL,\n\t0x0000a1a1a1a100a1ULL, 0x0000626262620062ULL, 0x0000545454540054ULL,\n\t0x00001e1e1e1e001eULL, 0x0000e0e0e0e000e0ULL, 0x0000646464640064ULL,\n\t0x0000101010100010ULL, 0x0000000000000000ULL, 0x0000a3a3a3a300a3ULL,\n\t0x0000757575750075ULL, 0x00008a8a8a8a008aULL, 0x0000e6e6e6e600e6ULL,\n\t0x0000090909090009ULL, 0x0000dddddddd00ddULL, 0x0000878787870087ULL,\n\t0x0000838383830083ULL, 0x0000cdcdcdcd00cdULL, 0x0000909090900090ULL,\n\t0x0000737373730073ULL, 0x0000f6f6f6f600f6ULL, 0x00009d9d9d9d009dULL,\n\t0x0000bfbfbfbf00bfULL, 0x0000525252520052ULL, 0x0000d8d8d8d800d8ULL,\n\t0x0000c8c8c8c800c8ULL, 0x0000c6c6c6c600c6ULL, 0x0000818181810081ULL,\n\t0x00006f6f6f6f006fULL, 0x0000131313130013ULL, 0x0000636363630063ULL,\n\t0x0000e9e9e9e900e9ULL, 0x0000a7a7a7a700a7ULL, 0x00009f9f9f9f009fULL,\n\t0x0000bcbcbcbc00bcULL, 0x0000292929290029ULL, 0x0000f9f9f9f900f9ULL,\n\t0x00002f2f2f2f002fULL, 0x0000b4b4b4b400b4ULL, 0x0000787878780078ULL,\n\t0x0000060606060006ULL, 0x0000e7e7e7e700e7ULL, 0x0000717171710071ULL,\n\t0x0000d4d4d4d400d4ULL, 0x0000abababab00abULL, 0x0000888888880088ULL,\n\t0x00008d8d8d8d008dULL, 0x0000727272720072ULL, 0x0000b9b9b9b900b9ULL,\n\t0x0000f8f8f8f800f8ULL, 0x0000acacacac00acULL, 0x0000363636360036ULL,\n\t0x00002a2a2a2a002aULL, 0x00003c3c3c3c003cULL, 0x0000f1f1f1f100f1ULL,\n\t0x0000404040400040ULL, 0x0000d3d3d3d300d3ULL, 0x0000bbbbbbbb00bbULL,\n\t0x0000434343430043ULL, 0x0000151515150015ULL, 0x0000adadadad00adULL,\n\t0x0000777777770077ULL, 0x0000808080800080ULL, 0x0000828282820082ULL,\n\t0x0000ecececec00ecULL, 0x0000272727270027ULL, 0x0000e5e5e5e500e5ULL,\n\t0x0000858585850085ULL, 0x0000353535350035ULL, 0x00000c0c0c0c000cULL,\n\t0x0000414141410041ULL, 0x0000efefefef00efULL, 0x0000939393930093ULL,\n\t0x0000191919190019ULL, 0x0000212121210021ULL, 0x00000e0e0e0e000eULL,\n\t0x00004e4e4e4e004eULL, 0x0000656565650065ULL, 0x0000bdbdbdbd00bdULL,\n\t0x0000b8b8b8b800b8ULL, 0x00008f8f8f8f008fULL, 0x0000ebebebeb00ebULL,\n\t0x0000cececece00ceULL, 0x0000303030300030ULL, 0x00005f5f5f5f005fULL,\n\t0x0000c5c5c5c500c5ULL, 0x00001a1a1a1a001aULL, 0x0000e1e1e1e100e1ULL,\n\t0x0000cacacaca00caULL, 0x0000474747470047ULL, 0x00003d3d3d3d003dULL,\n\t0x0000010101010001ULL, 0x0000d6d6d6d600d6ULL, 0x0000565656560056ULL,\n\t0x00004d4d4d4d004dULL, 0x00000d0d0d0d000dULL, 0x0000666666660066ULL,\n\t0x0000cccccccc00ccULL, 0x00002d2d2d2d002dULL, 0x0000121212120012ULL,\n\t0x0000202020200020ULL, 0x0000b1b1b1b100b1ULL, 0x0000999999990099ULL,\n\t0x00004c4c4c4c004cULL, 0x0000c2c2c2c200c2ULL, 0x00007e7e7e7e007eULL,\n\t0x0000050505050005ULL, 0x0000b7b7b7b700b7ULL, 0x0000313131310031ULL,\n\t0x0000171717170017ULL, 0x0000d7d7d7d700d7ULL, 0x0000585858580058ULL,\n\t0x0000616161610061ULL, 0x00001b1b1b1b001bULL, 0x00001c1c1c1c001cULL,\n\t0x00000f0f0f0f000fULL, 0x0000161616160016ULL, 0x0000181818180018ULL,\n\t0x0000222222220022ULL, 0x0000444444440044ULL, 0x0000b2b2b2b200b2ULL,\n\t0x0000b5b5b5b500b5ULL, 0x0000919191910091ULL, 0x0000080808080008ULL,\n\t0x0000a8a8a8a800a8ULL, 0x0000fcfcfcfc00fcULL, 0x0000505050500050ULL,\n\t0x0000d0d0d0d000d0ULL, 0x00007d7d7d7d007dULL, 0x0000898989890089ULL,\n\t0x0000979797970097ULL, 0x00005b5b5b5b005bULL, 0x0000959595950095ULL,\n\t0x0000ffffffff00ffULL, 0x0000d2d2d2d200d2ULL, 0x0000c4c4c4c400c4ULL,\n\t0x0000484848480048ULL, 0x0000f7f7f7f700f7ULL, 0x0000dbdbdbdb00dbULL,\n\t0x0000030303030003ULL, 0x0000dadadada00daULL, 0x00003f3f3f3f003fULL,\n\t0x0000949494940094ULL, 0x00005c5c5c5c005cULL, 0x0000020202020002ULL,\n\t0x00004a4a4a4a004aULL, 0x0000333333330033ULL, 0x0000676767670067ULL,\n\t0x0000f3f3f3f300f3ULL, 0x00007f7f7f7f007fULL, 0x0000e2e2e2e200e2ULL,\n\t0x00009b9b9b9b009bULL, 0x0000262626260026ULL, 0x0000373737370037ULL,\n\t0x00003b3b3b3b003bULL, 0x0000969696960096ULL, 0x00004b4b4b4b004bULL,\n\t0x0000bebebebe00beULL, 0x00002e2e2e2e002eULL, 0x0000797979790079ULL,\n\t0x00008c8c8c8c008cULL, 0x00006e6e6e6e006eULL, 0x00008e8e8e8e008eULL,\n\t0x0000f5f5f5f500f5ULL, 0x0000b6b6b6b600b6ULL, 0x0000fdfdfdfd00fdULL,\n\t0x0000595959590059ULL, 0x0000989898980098ULL, 0x00006a6a6a6a006aULL,\n\t0x0000464646460046ULL, 0x0000babababa00baULL, 0x0000252525250025ULL,\n\t0x0000424242420042ULL, 0x0000a2a2a2a200a2ULL, 0x0000fafafafa00faULL,\n\t0x0000070707070007ULL, 0x0000555555550055ULL, 0x0000eeeeeeee00eeULL,\n\t0x00000a0a0a0a000aULL, 0x0000494949490049ULL, 0x0000686868680068ULL,\n\t0x0000383838380038ULL, 0x0000a4a4a4a400a4ULL, 0x0000282828280028ULL,\n\t0x00007b7b7b7b007bULL, 0x0000c9c9c9c900c9ULL, 0x0000c1c1c1c100c1ULL,\n\t0x0000e3e3e3e300e3ULL, 0x0000f4f4f4f400f4ULL, 0x0000c7c7c7c700c7ULL,\n\t0x00009e9e9e9e009eULL,\n};\n\n__visible const u64 camellia_sp02220222[256] = {\n\t0x00e0e0e000e0e0e0ULL, 0x0005050500050505ULL, 0x0058585800585858ULL,\n\t0x00d9d9d900d9d9d9ULL, 0x0067676700676767ULL, 0x004e4e4e004e4e4eULL,\n\t0x0081818100818181ULL, 0x00cbcbcb00cbcbcbULL, 0x00c9c9c900c9c9c9ULL,\n\t0x000b0b0b000b0b0bULL, 0x00aeaeae00aeaeaeULL, 0x006a6a6a006a6a6aULL,\n\t0x00d5d5d500d5d5d5ULL, 0x0018181800181818ULL, 0x005d5d5d005d5d5dULL,\n\t0x0082828200828282ULL, 0x0046464600464646ULL, 0x00dfdfdf00dfdfdfULL,\n\t0x00d6d6d600d6d6d6ULL, 0x0027272700272727ULL, 0x008a8a8a008a8a8aULL,\n\t0x0032323200323232ULL, 0x004b4b4b004b4b4bULL, 0x0042424200424242ULL,\n\t0x00dbdbdb00dbdbdbULL, 0x001c1c1c001c1c1cULL, 0x009e9e9e009e9e9eULL,\n\t0x009c9c9c009c9c9cULL, 0x003a3a3a003a3a3aULL, 0x00cacaca00cacacaULL,\n\t0x0025252500252525ULL, 0x007b7b7b007b7b7bULL, 0x000d0d0d000d0d0dULL,\n\t0x0071717100717171ULL, 0x005f5f5f005f5f5fULL, 0x001f1f1f001f1f1fULL,\n\t0x00f8f8f800f8f8f8ULL, 0x00d7d7d700d7d7d7ULL, 0x003e3e3e003e3e3eULL,\n\t0x009d9d9d009d9d9dULL, 0x007c7c7c007c7c7cULL, 0x0060606000606060ULL,\n\t0x00b9b9b900b9b9b9ULL, 0x00bebebe00bebebeULL, 0x00bcbcbc00bcbcbcULL,\n\t0x008b8b8b008b8b8bULL, 0x0016161600161616ULL, 0x0034343400343434ULL,\n\t0x004d4d4d004d4d4dULL, 0x00c3c3c300c3c3c3ULL, 0x0072727200727272ULL,\n\t0x0095959500959595ULL, 0x00ababab00abababULL, 0x008e8e8e008e8e8eULL,\n\t0x00bababa00bababaULL, 0x007a7a7a007a7a7aULL, 0x00b3b3b300b3b3b3ULL,\n\t0x0002020200020202ULL, 0x00b4b4b400b4b4b4ULL, 0x00adadad00adadadULL,\n\t0x00a2a2a200a2a2a2ULL, 0x00acacac00acacacULL, 0x00d8d8d800d8d8d8ULL,\n\t0x009a9a9a009a9a9aULL, 0x0017171700171717ULL, 0x001a1a1a001a1a1aULL,\n\t0x0035353500353535ULL, 0x00cccccc00ccccccULL, 0x00f7f7f700f7f7f7ULL,\n\t0x0099999900999999ULL, 0x0061616100616161ULL, 0x005a5a5a005a5a5aULL,\n\t0x00e8e8e800e8e8e8ULL, 0x0024242400242424ULL, 0x0056565600565656ULL,\n\t0x0040404000404040ULL, 0x00e1e1e100e1e1e1ULL, 0x0063636300636363ULL,\n\t0x0009090900090909ULL, 0x0033333300333333ULL, 0x00bfbfbf00bfbfbfULL,\n\t0x0098989800989898ULL, 0x0097979700979797ULL, 0x0085858500858585ULL,\n\t0x0068686800686868ULL, 0x00fcfcfc00fcfcfcULL, 0x00ececec00ecececULL,\n\t0x000a0a0a000a0a0aULL, 0x00dadada00dadadaULL, 0x006f6f6f006f6f6fULL,\n\t0x0053535300535353ULL, 0x0062626200626262ULL, 0x00a3a3a300a3a3a3ULL,\n\t0x002e2e2e002e2e2eULL, 0x0008080800080808ULL, 0x00afafaf00afafafULL,\n\t0x0028282800282828ULL, 0x00b0b0b000b0b0b0ULL, 0x0074747400747474ULL,\n\t0x00c2c2c200c2c2c2ULL, 0x00bdbdbd00bdbdbdULL, 0x0036363600363636ULL,\n\t0x0022222200222222ULL, 0x0038383800383838ULL, 0x0064646400646464ULL,\n\t0x001e1e1e001e1e1eULL, 0x0039393900393939ULL, 0x002c2c2c002c2c2cULL,\n\t0x00a6a6a600a6a6a6ULL, 0x0030303000303030ULL, 0x00e5e5e500e5e5e5ULL,\n\t0x0044444400444444ULL, 0x00fdfdfd00fdfdfdULL, 0x0088888800888888ULL,\n\t0x009f9f9f009f9f9fULL, 0x0065656500656565ULL, 0x0087878700878787ULL,\n\t0x006b6b6b006b6b6bULL, 0x00f4f4f400f4f4f4ULL, 0x0023232300232323ULL,\n\t0x0048484800484848ULL, 0x0010101000101010ULL, 0x00d1d1d100d1d1d1ULL,\n\t0x0051515100515151ULL, 0x00c0c0c000c0c0c0ULL, 0x00f9f9f900f9f9f9ULL,\n\t0x00d2d2d200d2d2d2ULL, 0x00a0a0a000a0a0a0ULL, 0x0055555500555555ULL,\n\t0x00a1a1a100a1a1a1ULL, 0x0041414100414141ULL, 0x00fafafa00fafafaULL,\n\t0x0043434300434343ULL, 0x0013131300131313ULL, 0x00c4c4c400c4c4c4ULL,\n\t0x002f2f2f002f2f2fULL, 0x00a8a8a800a8a8a8ULL, 0x00b6b6b600b6b6b6ULL,\n\t0x003c3c3c003c3c3cULL, 0x002b2b2b002b2b2bULL, 0x00c1c1c100c1c1c1ULL,\n\t0x00ffffff00ffffffULL, 0x00c8c8c800c8c8c8ULL, 0x00a5a5a500a5a5a5ULL,\n\t0x0020202000202020ULL, 0x0089898900898989ULL, 0x0000000000000000ULL,\n\t0x0090909000909090ULL, 0x0047474700474747ULL, 0x00efefef00efefefULL,\n\t0x00eaeaea00eaeaeaULL, 0x00b7b7b700b7b7b7ULL, 0x0015151500151515ULL,\n\t0x0006060600060606ULL, 0x00cdcdcd00cdcdcdULL, 0x00b5b5b500b5b5b5ULL,\n\t0x0012121200121212ULL, 0x007e7e7e007e7e7eULL, 0x00bbbbbb00bbbbbbULL,\n\t0x0029292900292929ULL, 0x000f0f0f000f0f0fULL, 0x00b8b8b800b8b8b8ULL,\n\t0x0007070700070707ULL, 0x0004040400040404ULL, 0x009b9b9b009b9b9bULL,\n\t0x0094949400949494ULL, 0x0021212100212121ULL, 0x0066666600666666ULL,\n\t0x00e6e6e600e6e6e6ULL, 0x00cecece00cececeULL, 0x00ededed00edededULL,\n\t0x00e7e7e700e7e7e7ULL, 0x003b3b3b003b3b3bULL, 0x00fefefe00fefefeULL,\n\t0x007f7f7f007f7f7fULL, 0x00c5c5c500c5c5c5ULL, 0x00a4a4a400a4a4a4ULL,\n\t0x0037373700373737ULL, 0x00b1b1b100b1b1b1ULL, 0x004c4c4c004c4c4cULL,\n\t0x0091919100919191ULL, 0x006e6e6e006e6e6eULL, 0x008d8d8d008d8d8dULL,\n\t0x0076767600767676ULL, 0x0003030300030303ULL, 0x002d2d2d002d2d2dULL,\n\t0x00dedede00dededeULL, 0x0096969600969696ULL, 0x0026262600262626ULL,\n\t0x007d7d7d007d7d7dULL, 0x00c6c6c600c6c6c6ULL, 0x005c5c5c005c5c5cULL,\n\t0x00d3d3d300d3d3d3ULL, 0x00f2f2f200f2f2f2ULL, 0x004f4f4f004f4f4fULL,\n\t0x0019191900191919ULL, 0x003f3f3f003f3f3fULL, 0x00dcdcdc00dcdcdcULL,\n\t0x0079797900797979ULL, 0x001d1d1d001d1d1dULL, 0x0052525200525252ULL,\n\t0x00ebebeb00ebebebULL, 0x00f3f3f300f3f3f3ULL, 0x006d6d6d006d6d6dULL,\n\t0x005e5e5e005e5e5eULL, 0x00fbfbfb00fbfbfbULL, 0x0069696900696969ULL,\n\t0x00b2b2b200b2b2b2ULL, 0x00f0f0f000f0f0f0ULL, 0x0031313100313131ULL,\n\t0x000c0c0c000c0c0cULL, 0x00d4d4d400d4d4d4ULL, 0x00cfcfcf00cfcfcfULL,\n\t0x008c8c8c008c8c8cULL, 0x00e2e2e200e2e2e2ULL, 0x0075757500757575ULL,\n\t0x00a9a9a900a9a9a9ULL, 0x004a4a4a004a4a4aULL, 0x0057575700575757ULL,\n\t0x0084848400848484ULL, 0x0011111100111111ULL, 0x0045454500454545ULL,\n\t0x001b1b1b001b1b1bULL, 0x00f5f5f500f5f5f5ULL, 0x00e4e4e400e4e4e4ULL,\n\t0x000e0e0e000e0e0eULL, 0x0073737300737373ULL, 0x00aaaaaa00aaaaaaULL,\n\t0x00f1f1f100f1f1f1ULL, 0x00dddddd00ddddddULL, 0x0059595900595959ULL,\n\t0x0014141400141414ULL, 0x006c6c6c006c6c6cULL, 0x0092929200929292ULL,\n\t0x0054545400545454ULL, 0x00d0d0d000d0d0d0ULL, 0x0078787800787878ULL,\n\t0x0070707000707070ULL, 0x00e3e3e300e3e3e3ULL, 0x0049494900494949ULL,\n\t0x0080808000808080ULL, 0x0050505000505050ULL, 0x00a7a7a700a7a7a7ULL,\n\t0x00f6f6f600f6f6f6ULL, 0x0077777700777777ULL, 0x0093939300939393ULL,\n\t0x0086868600868686ULL, 0x0083838300838383ULL, 0x002a2a2a002a2a2aULL,\n\t0x00c7c7c700c7c7c7ULL, 0x005b5b5b005b5b5bULL, 0x00e9e9e900e9e9e9ULL,\n\t0x00eeeeee00eeeeeeULL, 0x008f8f8f008f8f8fULL, 0x0001010100010101ULL,\n\t0x003d3d3d003d3d3dULL,\n};\n\n__visible const u64 camellia_sp30333033[256] = {\n\t0x3800383838003838ULL, 0x4100414141004141ULL, 0x1600161616001616ULL,\n\t0x7600767676007676ULL, 0xd900d9d9d900d9d9ULL, 0x9300939393009393ULL,\n\t0x6000606060006060ULL, 0xf200f2f2f200f2f2ULL, 0x7200727272007272ULL,\n\t0xc200c2c2c200c2c2ULL, 0xab00ababab00ababULL, 0x9a009a9a9a009a9aULL,\n\t0x7500757575007575ULL, 0x0600060606000606ULL, 0x5700575757005757ULL,\n\t0xa000a0a0a000a0a0ULL, 0x9100919191009191ULL, 0xf700f7f7f700f7f7ULL,\n\t0xb500b5b5b500b5b5ULL, 0xc900c9c9c900c9c9ULL, 0xa200a2a2a200a2a2ULL,\n\t0x8c008c8c8c008c8cULL, 0xd200d2d2d200d2d2ULL, 0x9000909090009090ULL,\n\t0xf600f6f6f600f6f6ULL, 0x0700070707000707ULL, 0xa700a7a7a700a7a7ULL,\n\t0x2700272727002727ULL, 0x8e008e8e8e008e8eULL, 0xb200b2b2b200b2b2ULL,\n\t0x4900494949004949ULL, 0xde00dedede00dedeULL, 0x4300434343004343ULL,\n\t0x5c005c5c5c005c5cULL, 0xd700d7d7d700d7d7ULL, 0xc700c7c7c700c7c7ULL,\n\t0x3e003e3e3e003e3eULL, 0xf500f5f5f500f5f5ULL, 0x8f008f8f8f008f8fULL,\n\t0x6700676767006767ULL, 0x1f001f1f1f001f1fULL, 0x1800181818001818ULL,\n\t0x6e006e6e6e006e6eULL, 0xaf00afafaf00afafULL, 0x2f002f2f2f002f2fULL,\n\t0xe200e2e2e200e2e2ULL, 0x8500858585008585ULL, 0x0d000d0d0d000d0dULL,\n\t0x5300535353005353ULL, 0xf000f0f0f000f0f0ULL, 0x9c009c9c9c009c9cULL,\n\t0x6500656565006565ULL, 0xea00eaeaea00eaeaULL, 0xa300a3a3a300a3a3ULL,\n\t0xae00aeaeae00aeaeULL, 0x9e009e9e9e009e9eULL, 0xec00ececec00ececULL,\n\t0x8000808080008080ULL, 0x2d002d2d2d002d2dULL, 0x6b006b6b6b006b6bULL,\n\t0xa800a8a8a800a8a8ULL, 0x2b002b2b2b002b2bULL, 0x3600363636003636ULL,\n\t0xa600a6a6a600a6a6ULL, 0xc500c5c5c500c5c5ULL, 0x8600868686008686ULL,\n\t0x4d004d4d4d004d4dULL, 0x3300333333003333ULL, 0xfd00fdfdfd00fdfdULL,\n\t0x6600666666006666ULL, 0x5800585858005858ULL, 0x9600969696009696ULL,\n\t0x3a003a3a3a003a3aULL, 0x0900090909000909ULL, 0x9500959595009595ULL,\n\t0x1000101010001010ULL, 0x7800787878007878ULL, 0xd800d8d8d800d8d8ULL,\n\t0x4200424242004242ULL, 0xcc00cccccc00ccccULL, 0xef00efefef00efefULL,\n\t0x2600262626002626ULL, 0xe500e5e5e500e5e5ULL, 0x6100616161006161ULL,\n\t0x1a001a1a1a001a1aULL, 0x3f003f3f3f003f3fULL, 0x3b003b3b3b003b3bULL,\n\t0x8200828282008282ULL, 0xb600b6b6b600b6b6ULL, 0xdb00dbdbdb00dbdbULL,\n\t0xd400d4d4d400d4d4ULL, 0x9800989898009898ULL, 0xe800e8e8e800e8e8ULL,\n\t0x8b008b8b8b008b8bULL, 0x0200020202000202ULL, 0xeb00ebebeb00ebebULL,\n\t0x0a000a0a0a000a0aULL, 0x2c002c2c2c002c2cULL, 0x1d001d1d1d001d1dULL,\n\t0xb000b0b0b000b0b0ULL, 0x6f006f6f6f006f6fULL, 0x8d008d8d8d008d8dULL,\n\t0x8800888888008888ULL, 0x0e000e0e0e000e0eULL, 0x1900191919001919ULL,\n\t0x8700878787008787ULL, 0x4e004e4e4e004e4eULL, 0x0b000b0b0b000b0bULL,\n\t0xa900a9a9a900a9a9ULL, 0x0c000c0c0c000c0cULL, 0x7900797979007979ULL,\n\t0x1100111111001111ULL, 0x7f007f7f7f007f7fULL, 0x2200222222002222ULL,\n\t0xe700e7e7e700e7e7ULL, 0x5900595959005959ULL, 0xe100e1e1e100e1e1ULL,\n\t0xda00dadada00dadaULL, 0x3d003d3d3d003d3dULL, 0xc800c8c8c800c8c8ULL,\n\t0x1200121212001212ULL, 0x0400040404000404ULL, 0x7400747474007474ULL,\n\t0x5400545454005454ULL, 0x3000303030003030ULL, 0x7e007e7e7e007e7eULL,\n\t0xb400b4b4b400b4b4ULL, 0x2800282828002828ULL, 0x5500555555005555ULL,\n\t0x6800686868006868ULL, 0x5000505050005050ULL, 0xbe00bebebe00bebeULL,\n\t0xd000d0d0d000d0d0ULL, 0xc400c4c4c400c4c4ULL, 0x3100313131003131ULL,\n\t0xcb00cbcbcb00cbcbULL, 0x2a002a2a2a002a2aULL, 0xad00adadad00adadULL,\n\t0x0f000f0f0f000f0fULL, 0xca00cacaca00cacaULL, 0x7000707070007070ULL,\n\t0xff00ffffff00ffffULL, 0x3200323232003232ULL, 0x6900696969006969ULL,\n\t0x0800080808000808ULL, 0x6200626262006262ULL, 0x0000000000000000ULL,\n\t0x2400242424002424ULL, 0xd100d1d1d100d1d1ULL, 0xfb00fbfbfb00fbfbULL,\n\t0xba00bababa00babaULL, 0xed00ededed00ededULL, 0x4500454545004545ULL,\n\t0x8100818181008181ULL, 0x7300737373007373ULL, 0x6d006d6d6d006d6dULL,\n\t0x8400848484008484ULL, 0x9f009f9f9f009f9fULL, 0xee00eeeeee00eeeeULL,\n\t0x4a004a4a4a004a4aULL, 0xc300c3c3c300c3c3ULL, 0x2e002e2e2e002e2eULL,\n\t0xc100c1c1c100c1c1ULL, 0x0100010101000101ULL, 0xe600e6e6e600e6e6ULL,\n\t0x2500252525002525ULL, 0x4800484848004848ULL, 0x9900999999009999ULL,\n\t0xb900b9b9b900b9b9ULL, 0xb300b3b3b300b3b3ULL, 0x7b007b7b7b007b7bULL,\n\t0xf900f9f9f900f9f9ULL, 0xce00cecece00ceceULL, 0xbf00bfbfbf00bfbfULL,\n\t0xdf00dfdfdf00dfdfULL, 0x7100717171007171ULL, 0x2900292929002929ULL,\n\t0xcd00cdcdcd00cdcdULL, 0x6c006c6c6c006c6cULL, 0x1300131313001313ULL,\n\t0x6400646464006464ULL, 0x9b009b9b9b009b9bULL, 0x6300636363006363ULL,\n\t0x9d009d9d9d009d9dULL, 0xc000c0c0c000c0c0ULL, 0x4b004b4b4b004b4bULL,\n\t0xb700b7b7b700b7b7ULL, 0xa500a5a5a500a5a5ULL, 0x8900898989008989ULL,\n\t0x5f005f5f5f005f5fULL, 0xb100b1b1b100b1b1ULL, 0x1700171717001717ULL,\n\t0xf400f4f4f400f4f4ULL, 0xbc00bcbcbc00bcbcULL, 0xd300d3d3d300d3d3ULL,\n\t0x4600464646004646ULL, 0xcf00cfcfcf00cfcfULL, 0x3700373737003737ULL,\n\t0x5e005e5e5e005e5eULL, 0x4700474747004747ULL, 0x9400949494009494ULL,\n\t0xfa00fafafa00fafaULL, 0xfc00fcfcfc00fcfcULL, 0x5b005b5b5b005b5bULL,\n\t0x9700979797009797ULL, 0xfe00fefefe00fefeULL, 0x5a005a5a5a005a5aULL,\n\t0xac00acacac00acacULL, 0x3c003c3c3c003c3cULL, 0x4c004c4c4c004c4cULL,\n\t0x0300030303000303ULL, 0x3500353535003535ULL, 0xf300f3f3f300f3f3ULL,\n\t0x2300232323002323ULL, 0xb800b8b8b800b8b8ULL, 0x5d005d5d5d005d5dULL,\n\t0x6a006a6a6a006a6aULL, 0x9200929292009292ULL, 0xd500d5d5d500d5d5ULL,\n\t0x2100212121002121ULL, 0x4400444444004444ULL, 0x5100515151005151ULL,\n\t0xc600c6c6c600c6c6ULL, 0x7d007d7d7d007d7dULL, 0x3900393939003939ULL,\n\t0x8300838383008383ULL, 0xdc00dcdcdc00dcdcULL, 0xaa00aaaaaa00aaaaULL,\n\t0x7c007c7c7c007c7cULL, 0x7700777777007777ULL, 0x5600565656005656ULL,\n\t0x0500050505000505ULL, 0x1b001b1b1b001b1bULL, 0xa400a4a4a400a4a4ULL,\n\t0x1500151515001515ULL, 0x3400343434003434ULL, 0x1e001e1e1e001e1eULL,\n\t0x1c001c1c1c001c1cULL, 0xf800f8f8f800f8f8ULL, 0x5200525252005252ULL,\n\t0x2000202020002020ULL, 0x1400141414001414ULL, 0xe900e9e9e900e9e9ULL,\n\t0xbd00bdbdbd00bdbdULL, 0xdd00dddddd00ddddULL, 0xe400e4e4e400e4e4ULL,\n\t0xa100a1a1a100a1a1ULL, 0xe000e0e0e000e0e0ULL, 0x8a008a8a8a008a8aULL,\n\t0xf100f1f1f100f1f1ULL, 0xd600d6d6d600d6d6ULL, 0x7a007a7a7a007a7aULL,\n\t0xbb00bbbbbb00bbbbULL, 0xe300e3e3e300e3e3ULL, 0x4000404040004040ULL,\n\t0x4f004f4f4f004f4fULL,\n};\n\n__visible const u64 camellia_sp44044404[256] = {\n\t0x7070007070700070ULL, 0x2c2c002c2c2c002cULL, 0xb3b300b3b3b300b3ULL,\n\t0xc0c000c0c0c000c0ULL, 0xe4e400e4e4e400e4ULL, 0x5757005757570057ULL,\n\t0xeaea00eaeaea00eaULL, 0xaeae00aeaeae00aeULL, 0x2323002323230023ULL,\n\t0x6b6b006b6b6b006bULL, 0x4545004545450045ULL, 0xa5a500a5a5a500a5ULL,\n\t0xeded00ededed00edULL, 0x4f4f004f4f4f004fULL, 0x1d1d001d1d1d001dULL,\n\t0x9292009292920092ULL, 0x8686008686860086ULL, 0xafaf00afafaf00afULL,\n\t0x7c7c007c7c7c007cULL, 0x1f1f001f1f1f001fULL, 0x3e3e003e3e3e003eULL,\n\t0xdcdc00dcdcdc00dcULL, 0x5e5e005e5e5e005eULL, 0x0b0b000b0b0b000bULL,\n\t0xa6a600a6a6a600a6ULL, 0x3939003939390039ULL, 0xd5d500d5d5d500d5ULL,\n\t0x5d5d005d5d5d005dULL, 0xd9d900d9d9d900d9ULL, 0x5a5a005a5a5a005aULL,\n\t0x5151005151510051ULL, 0x6c6c006c6c6c006cULL, 0x8b8b008b8b8b008bULL,\n\t0x9a9a009a9a9a009aULL, 0xfbfb00fbfbfb00fbULL, 0xb0b000b0b0b000b0ULL,\n\t0x7474007474740074ULL, 0x2b2b002b2b2b002bULL, 0xf0f000f0f0f000f0ULL,\n\t0x8484008484840084ULL, 0xdfdf00dfdfdf00dfULL, 0xcbcb00cbcbcb00cbULL,\n\t0x3434003434340034ULL, 0x7676007676760076ULL, 0x6d6d006d6d6d006dULL,\n\t0xa9a900a9a9a900a9ULL, 0xd1d100d1d1d100d1ULL, 0x0404000404040004ULL,\n\t0x1414001414140014ULL, 0x3a3a003a3a3a003aULL, 0xdede00dedede00deULL,\n\t0x1111001111110011ULL, 0x3232003232320032ULL, 0x9c9c009c9c9c009cULL,\n\t0x5353005353530053ULL, 0xf2f200f2f2f200f2ULL, 0xfefe00fefefe00feULL,\n\t0xcfcf00cfcfcf00cfULL, 0xc3c300c3c3c300c3ULL, 0x7a7a007a7a7a007aULL,\n\t0x2424002424240024ULL, 0xe8e800e8e8e800e8ULL, 0x6060006060600060ULL,\n\t0x6969006969690069ULL, 0xaaaa00aaaaaa00aaULL, 0xa0a000a0a0a000a0ULL,\n\t0xa1a100a1a1a100a1ULL, 0x6262006262620062ULL, 0x5454005454540054ULL,\n\t0x1e1e001e1e1e001eULL, 0xe0e000e0e0e000e0ULL, 0x6464006464640064ULL,\n\t0x1010001010100010ULL, 0x0000000000000000ULL, 0xa3a300a3a3a300a3ULL,\n\t0x7575007575750075ULL, 0x8a8a008a8a8a008aULL, 0xe6e600e6e6e600e6ULL,\n\t0x0909000909090009ULL, 0xdddd00dddddd00ddULL, 0x8787008787870087ULL,\n\t0x8383008383830083ULL, 0xcdcd00cdcdcd00cdULL, 0x9090009090900090ULL,\n\t0x7373007373730073ULL, 0xf6f600f6f6f600f6ULL, 0x9d9d009d9d9d009dULL,\n\t0xbfbf00bfbfbf00bfULL, 0x5252005252520052ULL, 0xd8d800d8d8d800d8ULL,\n\t0xc8c800c8c8c800c8ULL, 0xc6c600c6c6c600c6ULL, 0x8181008181810081ULL,\n\t0x6f6f006f6f6f006fULL, 0x1313001313130013ULL, 0x6363006363630063ULL,\n\t0xe9e900e9e9e900e9ULL, 0xa7a700a7a7a700a7ULL, 0x9f9f009f9f9f009fULL,\n\t0xbcbc00bcbcbc00bcULL, 0x2929002929290029ULL, 0xf9f900f9f9f900f9ULL,\n\t0x2f2f002f2f2f002fULL, 0xb4b400b4b4b400b4ULL, 0x7878007878780078ULL,\n\t0x0606000606060006ULL, 0xe7e700e7e7e700e7ULL, 0x7171007171710071ULL,\n\t0xd4d400d4d4d400d4ULL, 0xabab00ababab00abULL, 0x8888008888880088ULL,\n\t0x8d8d008d8d8d008dULL, 0x7272007272720072ULL, 0xb9b900b9b9b900b9ULL,\n\t0xf8f800f8f8f800f8ULL, 0xacac00acacac00acULL, 0x3636003636360036ULL,\n\t0x2a2a002a2a2a002aULL, 0x3c3c003c3c3c003cULL, 0xf1f100f1f1f100f1ULL,\n\t0x4040004040400040ULL, 0xd3d300d3d3d300d3ULL, 0xbbbb00bbbbbb00bbULL,\n\t0x4343004343430043ULL, 0x1515001515150015ULL, 0xadad00adadad00adULL,\n\t0x7777007777770077ULL, 0x8080008080800080ULL, 0x8282008282820082ULL,\n\t0xecec00ececec00ecULL, 0x2727002727270027ULL, 0xe5e500e5e5e500e5ULL,\n\t0x8585008585850085ULL, 0x3535003535350035ULL, 0x0c0c000c0c0c000cULL,\n\t0x4141004141410041ULL, 0xefef00efefef00efULL, 0x9393009393930093ULL,\n\t0x1919001919190019ULL, 0x2121002121210021ULL, 0x0e0e000e0e0e000eULL,\n\t0x4e4e004e4e4e004eULL, 0x6565006565650065ULL, 0xbdbd00bdbdbd00bdULL,\n\t0xb8b800b8b8b800b8ULL, 0x8f8f008f8f8f008fULL, 0xebeb00ebebeb00ebULL,\n\t0xcece00cecece00ceULL, 0x3030003030300030ULL, 0x5f5f005f5f5f005fULL,\n\t0xc5c500c5c5c500c5ULL, 0x1a1a001a1a1a001aULL, 0xe1e100e1e1e100e1ULL,\n\t0xcaca00cacaca00caULL, 0x4747004747470047ULL, 0x3d3d003d3d3d003dULL,\n\t0x0101000101010001ULL, 0xd6d600d6d6d600d6ULL, 0x5656005656560056ULL,\n\t0x4d4d004d4d4d004dULL, 0x0d0d000d0d0d000dULL, 0x6666006666660066ULL,\n\t0xcccc00cccccc00ccULL, 0x2d2d002d2d2d002dULL, 0x1212001212120012ULL,\n\t0x2020002020200020ULL, 0xb1b100b1b1b100b1ULL, 0x9999009999990099ULL,\n\t0x4c4c004c4c4c004cULL, 0xc2c200c2c2c200c2ULL, 0x7e7e007e7e7e007eULL,\n\t0x0505000505050005ULL, 0xb7b700b7b7b700b7ULL, 0x3131003131310031ULL,\n\t0x1717001717170017ULL, 0xd7d700d7d7d700d7ULL, 0x5858005858580058ULL,\n\t0x6161006161610061ULL, 0x1b1b001b1b1b001bULL, 0x1c1c001c1c1c001cULL,\n\t0x0f0f000f0f0f000fULL, 0x1616001616160016ULL, 0x1818001818180018ULL,\n\t0x2222002222220022ULL, 0x4444004444440044ULL, 0xb2b200b2b2b200b2ULL,\n\t0xb5b500b5b5b500b5ULL, 0x9191009191910091ULL, 0x0808000808080008ULL,\n\t0xa8a800a8a8a800a8ULL, 0xfcfc00fcfcfc00fcULL, 0x5050005050500050ULL,\n\t0xd0d000d0d0d000d0ULL, 0x7d7d007d7d7d007dULL, 0x8989008989890089ULL,\n\t0x9797009797970097ULL, 0x5b5b005b5b5b005bULL, 0x9595009595950095ULL,\n\t0xffff00ffffff00ffULL, 0xd2d200d2d2d200d2ULL, 0xc4c400c4c4c400c4ULL,\n\t0x4848004848480048ULL, 0xf7f700f7f7f700f7ULL, 0xdbdb00dbdbdb00dbULL,\n\t0x0303000303030003ULL, 0xdada00dadada00daULL, 0x3f3f003f3f3f003fULL,\n\t0x9494009494940094ULL, 0x5c5c005c5c5c005cULL, 0x0202000202020002ULL,\n\t0x4a4a004a4a4a004aULL, 0x3333003333330033ULL, 0x6767006767670067ULL,\n\t0xf3f300f3f3f300f3ULL, 0x7f7f007f7f7f007fULL, 0xe2e200e2e2e200e2ULL,\n\t0x9b9b009b9b9b009bULL, 0x2626002626260026ULL, 0x3737003737370037ULL,\n\t0x3b3b003b3b3b003bULL, 0x9696009696960096ULL, 0x4b4b004b4b4b004bULL,\n\t0xbebe00bebebe00beULL, 0x2e2e002e2e2e002eULL, 0x7979007979790079ULL,\n\t0x8c8c008c8c8c008cULL, 0x6e6e006e6e6e006eULL, 0x8e8e008e8e8e008eULL,\n\t0xf5f500f5f5f500f5ULL, 0xb6b600b6b6b600b6ULL, 0xfdfd00fdfdfd00fdULL,\n\t0x5959005959590059ULL, 0x9898009898980098ULL, 0x6a6a006a6a6a006aULL,\n\t0x4646004646460046ULL, 0xbaba00bababa00baULL, 0x2525002525250025ULL,\n\t0x4242004242420042ULL, 0xa2a200a2a2a200a2ULL, 0xfafa00fafafa00faULL,\n\t0x0707000707070007ULL, 0x5555005555550055ULL, 0xeeee00eeeeee00eeULL,\n\t0x0a0a000a0a0a000aULL, 0x4949004949490049ULL, 0x6868006868680068ULL,\n\t0x3838003838380038ULL, 0xa4a400a4a4a400a4ULL, 0x2828002828280028ULL,\n\t0x7b7b007b7b7b007bULL, 0xc9c900c9c9c900c9ULL, 0xc1c100c1c1c100c1ULL,\n\t0xe3e300e3e3e300e3ULL, 0xf4f400f4f4f400f4ULL, 0xc7c700c7c7c700c7ULL,\n\t0x9e9e009e9e9e009eULL,\n};\n\n__visible const u64 camellia_sp11101110[256] = {\n\t0x7070700070707000ULL, 0x8282820082828200ULL, 0x2c2c2c002c2c2c00ULL,\n\t0xececec00ececec00ULL, 0xb3b3b300b3b3b300ULL, 0x2727270027272700ULL,\n\t0xc0c0c000c0c0c000ULL, 0xe5e5e500e5e5e500ULL, 0xe4e4e400e4e4e400ULL,\n\t0x8585850085858500ULL, 0x5757570057575700ULL, 0x3535350035353500ULL,\n\t0xeaeaea00eaeaea00ULL, 0x0c0c0c000c0c0c00ULL, 0xaeaeae00aeaeae00ULL,\n\t0x4141410041414100ULL, 0x2323230023232300ULL, 0xefefef00efefef00ULL,\n\t0x6b6b6b006b6b6b00ULL, 0x9393930093939300ULL, 0x4545450045454500ULL,\n\t0x1919190019191900ULL, 0xa5a5a500a5a5a500ULL, 0x2121210021212100ULL,\n\t0xededed00ededed00ULL, 0x0e0e0e000e0e0e00ULL, 0x4f4f4f004f4f4f00ULL,\n\t0x4e4e4e004e4e4e00ULL, 0x1d1d1d001d1d1d00ULL, 0x6565650065656500ULL,\n\t0x9292920092929200ULL, 0xbdbdbd00bdbdbd00ULL, 0x8686860086868600ULL,\n\t0xb8b8b800b8b8b800ULL, 0xafafaf00afafaf00ULL, 0x8f8f8f008f8f8f00ULL,\n\t0x7c7c7c007c7c7c00ULL, 0xebebeb00ebebeb00ULL, 0x1f1f1f001f1f1f00ULL,\n\t0xcecece00cecece00ULL, 0x3e3e3e003e3e3e00ULL, 0x3030300030303000ULL,\n\t0xdcdcdc00dcdcdc00ULL, 0x5f5f5f005f5f5f00ULL, 0x5e5e5e005e5e5e00ULL,\n\t0xc5c5c500c5c5c500ULL, 0x0b0b0b000b0b0b00ULL, 0x1a1a1a001a1a1a00ULL,\n\t0xa6a6a600a6a6a600ULL, 0xe1e1e100e1e1e100ULL, 0x3939390039393900ULL,\n\t0xcacaca00cacaca00ULL, 0xd5d5d500d5d5d500ULL, 0x4747470047474700ULL,\n\t0x5d5d5d005d5d5d00ULL, 0x3d3d3d003d3d3d00ULL, 0xd9d9d900d9d9d900ULL,\n\t0x0101010001010100ULL, 0x5a5a5a005a5a5a00ULL, 0xd6d6d600d6d6d600ULL,\n\t0x5151510051515100ULL, 0x5656560056565600ULL, 0x6c6c6c006c6c6c00ULL,\n\t0x4d4d4d004d4d4d00ULL, 0x8b8b8b008b8b8b00ULL, 0x0d0d0d000d0d0d00ULL,\n\t0x9a9a9a009a9a9a00ULL, 0x6666660066666600ULL, 0xfbfbfb00fbfbfb00ULL,\n\t0xcccccc00cccccc00ULL, 0xb0b0b000b0b0b000ULL, 0x2d2d2d002d2d2d00ULL,\n\t0x7474740074747400ULL, 0x1212120012121200ULL, 0x2b2b2b002b2b2b00ULL,\n\t0x2020200020202000ULL, 0xf0f0f000f0f0f000ULL, 0xb1b1b100b1b1b100ULL,\n\t0x8484840084848400ULL, 0x9999990099999900ULL, 0xdfdfdf00dfdfdf00ULL,\n\t0x4c4c4c004c4c4c00ULL, 0xcbcbcb00cbcbcb00ULL, 0xc2c2c200c2c2c200ULL,\n\t0x3434340034343400ULL, 0x7e7e7e007e7e7e00ULL, 0x7676760076767600ULL,\n\t0x0505050005050500ULL, 0x6d6d6d006d6d6d00ULL, 0xb7b7b700b7b7b700ULL,\n\t0xa9a9a900a9a9a900ULL, 0x3131310031313100ULL, 0xd1d1d100d1d1d100ULL,\n\t0x1717170017171700ULL, 0x0404040004040400ULL, 0xd7d7d700d7d7d700ULL,\n\t0x1414140014141400ULL, 0x5858580058585800ULL, 0x3a3a3a003a3a3a00ULL,\n\t0x6161610061616100ULL, 0xdedede00dedede00ULL, 0x1b1b1b001b1b1b00ULL,\n\t0x1111110011111100ULL, 0x1c1c1c001c1c1c00ULL, 0x3232320032323200ULL,\n\t0x0f0f0f000f0f0f00ULL, 0x9c9c9c009c9c9c00ULL, 0x1616160016161600ULL,\n\t0x5353530053535300ULL, 0x1818180018181800ULL, 0xf2f2f200f2f2f200ULL,\n\t0x2222220022222200ULL, 0xfefefe00fefefe00ULL, 0x4444440044444400ULL,\n\t0xcfcfcf00cfcfcf00ULL, 0xb2b2b200b2b2b200ULL, 0xc3c3c300c3c3c300ULL,\n\t0xb5b5b500b5b5b500ULL, 0x7a7a7a007a7a7a00ULL, 0x9191910091919100ULL,\n\t0x2424240024242400ULL, 0x0808080008080800ULL, 0xe8e8e800e8e8e800ULL,\n\t0xa8a8a800a8a8a800ULL, 0x6060600060606000ULL, 0xfcfcfc00fcfcfc00ULL,\n\t0x6969690069696900ULL, 0x5050500050505000ULL, 0xaaaaaa00aaaaaa00ULL,\n\t0xd0d0d000d0d0d000ULL, 0xa0a0a000a0a0a000ULL, 0x7d7d7d007d7d7d00ULL,\n\t0xa1a1a100a1a1a100ULL, 0x8989890089898900ULL, 0x6262620062626200ULL,\n\t0x9797970097979700ULL, 0x5454540054545400ULL, 0x5b5b5b005b5b5b00ULL,\n\t0x1e1e1e001e1e1e00ULL, 0x9595950095959500ULL, 0xe0e0e000e0e0e000ULL,\n\t0xffffff00ffffff00ULL, 0x6464640064646400ULL, 0xd2d2d200d2d2d200ULL,\n\t0x1010100010101000ULL, 0xc4c4c400c4c4c400ULL, 0x0000000000000000ULL,\n\t0x4848480048484800ULL, 0xa3a3a300a3a3a300ULL, 0xf7f7f700f7f7f700ULL,\n\t0x7575750075757500ULL, 0xdbdbdb00dbdbdb00ULL, 0x8a8a8a008a8a8a00ULL,\n\t0x0303030003030300ULL, 0xe6e6e600e6e6e600ULL, 0xdadada00dadada00ULL,\n\t0x0909090009090900ULL, 0x3f3f3f003f3f3f00ULL, 0xdddddd00dddddd00ULL,\n\t0x9494940094949400ULL, 0x8787870087878700ULL, 0x5c5c5c005c5c5c00ULL,\n\t0x8383830083838300ULL, 0x0202020002020200ULL, 0xcdcdcd00cdcdcd00ULL,\n\t0x4a4a4a004a4a4a00ULL, 0x9090900090909000ULL, 0x3333330033333300ULL,\n\t0x7373730073737300ULL, 0x6767670067676700ULL, 0xf6f6f600f6f6f600ULL,\n\t0xf3f3f300f3f3f300ULL, 0x9d9d9d009d9d9d00ULL, 0x7f7f7f007f7f7f00ULL,\n\t0xbfbfbf00bfbfbf00ULL, 0xe2e2e200e2e2e200ULL, 0x5252520052525200ULL,\n\t0x9b9b9b009b9b9b00ULL, 0xd8d8d800d8d8d800ULL, 0x2626260026262600ULL,\n\t0xc8c8c800c8c8c800ULL, 0x3737370037373700ULL, 0xc6c6c600c6c6c600ULL,\n\t0x3b3b3b003b3b3b00ULL, 0x8181810081818100ULL, 0x9696960096969600ULL,\n\t0x6f6f6f006f6f6f00ULL, 0x4b4b4b004b4b4b00ULL, 0x1313130013131300ULL,\n\t0xbebebe00bebebe00ULL, 0x6363630063636300ULL, 0x2e2e2e002e2e2e00ULL,\n\t0xe9e9e900e9e9e900ULL, 0x7979790079797900ULL, 0xa7a7a700a7a7a700ULL,\n\t0x8c8c8c008c8c8c00ULL, 0x9f9f9f009f9f9f00ULL, 0x6e6e6e006e6e6e00ULL,\n\t0xbcbcbc00bcbcbc00ULL, 0x8e8e8e008e8e8e00ULL, 0x2929290029292900ULL,\n\t0xf5f5f500f5f5f500ULL, 0xf9f9f900f9f9f900ULL, 0xb6b6b600b6b6b600ULL,\n\t0x2f2f2f002f2f2f00ULL, 0xfdfdfd00fdfdfd00ULL, 0xb4b4b400b4b4b400ULL,\n\t0x5959590059595900ULL, 0x7878780078787800ULL, 0x9898980098989800ULL,\n\t0x0606060006060600ULL, 0x6a6a6a006a6a6a00ULL, 0xe7e7e700e7e7e700ULL,\n\t0x4646460046464600ULL, 0x7171710071717100ULL, 0xbababa00bababa00ULL,\n\t0xd4d4d400d4d4d400ULL, 0x2525250025252500ULL, 0xababab00ababab00ULL,\n\t0x4242420042424200ULL, 0x8888880088888800ULL, 0xa2a2a200a2a2a200ULL,\n\t0x8d8d8d008d8d8d00ULL, 0xfafafa00fafafa00ULL, 0x7272720072727200ULL,\n\t0x0707070007070700ULL, 0xb9b9b900b9b9b900ULL, 0x5555550055555500ULL,\n\t0xf8f8f800f8f8f800ULL, 0xeeeeee00eeeeee00ULL, 0xacacac00acacac00ULL,\n\t0x0a0a0a000a0a0a00ULL, 0x3636360036363600ULL, 0x4949490049494900ULL,\n\t0x2a2a2a002a2a2a00ULL, 0x6868680068686800ULL, 0x3c3c3c003c3c3c00ULL,\n\t0x3838380038383800ULL, 0xf1f1f100f1f1f100ULL, 0xa4a4a400a4a4a400ULL,\n\t0x4040400040404000ULL, 0x2828280028282800ULL, 0xd3d3d300d3d3d300ULL,\n\t0x7b7b7b007b7b7b00ULL, 0xbbbbbb00bbbbbb00ULL, 0xc9c9c900c9c9c900ULL,\n\t0x4343430043434300ULL, 0xc1c1c100c1c1c100ULL, 0x1515150015151500ULL,\n\t0xe3e3e300e3e3e300ULL, 0xadadad00adadad00ULL, 0xf4f4f400f4f4f400ULL,\n\t0x7777770077777700ULL, 0xc7c7c700c7c7c700ULL, 0x8080800080808000ULL,\n\t0x9e9e9e009e9e9e00ULL,\n};\n\n/* key constants */\n#define CAMELLIA_SIGMA1L (0xA09E667FL)\n#define CAMELLIA_SIGMA1R (0x3BCC908BL)\n#define CAMELLIA_SIGMA2L (0xB67AE858L)\n#define CAMELLIA_SIGMA2R (0x4CAA73B2L)\n#define CAMELLIA_SIGMA3L (0xC6EF372FL)\n#define CAMELLIA_SIGMA3R (0xE94F82BEL)\n#define CAMELLIA_SIGMA4L (0x54FF53A5L)\n#define CAMELLIA_SIGMA4R (0xF1D36F1CL)\n#define CAMELLIA_SIGMA5L (0x10E527FAL)\n#define CAMELLIA_SIGMA5R (0xDE682D1DL)\n#define CAMELLIA_SIGMA6L (0xB05688C2L)\n#define CAMELLIA_SIGMA6R (0xB3E6C1FDL)\n\n/* macros */\n#define ROLDQ(l, r, bits) ({ \\\n\tu64 t = l;\t\t\t\t\t\\\n\tl = (l << bits) | (r >> (64 - bits));\t\t\\\n\tr = (r << bits) | (t >> (64 - bits));\t\t\\\n})\n\n#define CAMELLIA_F(x, kl, kr, y) ({ \\\n\tu64 ii = x ^ (((u64)kl << 32) | kr);\t\t\t\t\\\n\ty = camellia_sp11101110[(uint8_t)ii];\t\t\t\t\\\n\ty ^= camellia_sp44044404[(uint8_t)(ii >> 8)];\t\t\t\\\n\tii >>= 16;\t\t\t\t\t\t\t\\\n\ty ^= camellia_sp30333033[(uint8_t)ii];\t\t\t\t\\\n\ty ^= camellia_sp02220222[(uint8_t)(ii >> 8)];\t\t\t\\\n\tii >>= 16;\t\t\t\t\t\t\t\\\n\ty ^= camellia_sp00444404[(uint8_t)ii];\t\t\t\t\\\n\ty ^= camellia_sp03303033[(uint8_t)(ii >> 8)];\t\t\t\\\n\tii >>= 16;\t\t\t\t\t\t\t\\\n\ty ^= camellia_sp22000222[(uint8_t)ii];\t\t\t\t\\\n\ty ^= camellia_sp10011110[(uint8_t)(ii >> 8)];\t\t\t\\\n\ty = ror64(y, 32);\t\t\t\t\t\t\\\n})\n\n#define SET_SUBKEY_LR(INDEX, sRL) (subkey[(INDEX)] = ror64((sRL), 32))\n\nstatic void camellia_setup_tail(u64 *subkey, u64 *subRL, int max)\n{\n\tu64 kw4, tt;\n\tu32 dw, tl, tr;\n\n\t/* absorb kw2 to other subkeys */\n\t/* round 2 */\n\tsubRL[3] ^= subRL[1];\n\t/* round 4 */\n\tsubRL[5] ^= subRL[1];\n\t/* round 6 */\n\tsubRL[7] ^= subRL[1];\n\n\tsubRL[1] ^= (subRL[1] & ~subRL[9]) << 32;\n\t/* modified for FLinv(kl2) */\n\tdw = (subRL[1] & subRL[9]) >> 32;\n\tsubRL[1] ^= rol32(dw, 1);\n\n\t/* round 8 */\n\tsubRL[11] ^= subRL[1];\n\t/* round 10 */\n\tsubRL[13] ^= subRL[1];\n\t/* round 12 */\n\tsubRL[15] ^= subRL[1];\n\n\tsubRL[1] ^= (subRL[1] & ~subRL[17]) << 32;\n\t/* modified for FLinv(kl4) */\n\tdw = (subRL[1] & subRL[17]) >> 32;\n\tsubRL[1] ^= rol32(dw, 1);\n\n\t/* round 14 */\n\tsubRL[19] ^= subRL[1];\n\t/* round 16 */\n\tsubRL[21] ^= subRL[1];\n\t/* round 18 */\n\tsubRL[23] ^= subRL[1];\n\n\tif (max == 24) {\n\t\t/* kw3 */\n\t\tsubRL[24] ^= subRL[1];\n\n\t\t/* absorb kw4 to other subkeys */\n\t\tkw4 = subRL[25];\n\t} else {\n\t\tsubRL[1] ^= (subRL[1] & ~subRL[25]) << 32;\n\t\t/* modified for FLinv(kl6) */\n\t\tdw = (subRL[1] & subRL[25]) >> 32;\n\t\tsubRL[1] ^= rol32(dw, 1);\n\n\t\t/* round 20 */\n\t\tsubRL[27] ^= subRL[1];\n\t\t/* round 22 */\n\t\tsubRL[29] ^= subRL[1];\n\t\t/* round 24 */\n\t\tsubRL[31] ^= subRL[1];\n\t\t/* kw3 */\n\t\tsubRL[32] ^= subRL[1];\n\n\t\t/* absorb kw4 to other subkeys */\n\t\tkw4 = subRL[33];\n\t\t/* round 23 */\n\t\tsubRL[30] ^= kw4;\n\t\t/* round 21 */\n\t\tsubRL[28] ^= kw4;\n\t\t/* round 19 */\n\t\tsubRL[26] ^= kw4;\n\n\t\tkw4 ^= (kw4 & ~subRL[24]) << 32;\n\t\t/* modified for FL(kl5) */\n\t\tdw = (kw4 & subRL[24]) >> 32;\n\t\tkw4 ^= rol32(dw, 1);\n\t}\n\n\t/* round 17 */\n\tsubRL[22] ^= kw4;\n\t/* round 15 */\n\tsubRL[20] ^= kw4;\n\t/* round 13 */\n\tsubRL[18] ^= kw4;\n\n\tkw4 ^= (kw4 & ~subRL[16]) << 32;\n\t/* modified for FL(kl3) */\n\tdw = (kw4 & subRL[16]) >> 32;\n\tkw4 ^= rol32(dw, 1);\n\n\t/* round 11 */\n\tsubRL[14] ^= kw4;\n\t/* round 9 */\n\tsubRL[12] ^= kw4;\n\t/* round 7 */\n\tsubRL[10] ^= kw4;\n\n\tkw4 ^= (kw4 & ~subRL[8]) << 32;\n\t/* modified for FL(kl1) */\n\tdw = (kw4 & subRL[8]) >> 32;\n\tkw4 ^= rol32(dw, 1);\n\n\t/* round 5 */\n\tsubRL[6] ^= kw4;\n\t/* round 3 */\n\tsubRL[4] ^= kw4;\n\t/* round 1 */\n\tsubRL[2] ^= kw4;\n\t/* kw1 */\n\tsubRL[0] ^= kw4;\n\n\t/* key XOR is end of F-function */\n\tSET_SUBKEY_LR(0, subRL[0] ^ subRL[2]);\t\t\t/* kw1 */\n\tSET_SUBKEY_LR(2, subRL[3]);\t\t\t\t/* round 1 */\n\tSET_SUBKEY_LR(3, subRL[2] ^ subRL[4]);\t\t\t/* round 2 */\n\tSET_SUBKEY_LR(4, subRL[3] ^ subRL[5]);\t\t\t/* round 3 */\n\tSET_SUBKEY_LR(5, subRL[4] ^ subRL[6]);\t\t\t/* round 4 */\n\tSET_SUBKEY_LR(6, subRL[5] ^ subRL[7]);\t\t\t/* round 5 */\n\n\ttl = (subRL[10] >> 32) ^ (subRL[10] & ~subRL[8]);\n\tdw = tl & (subRL[8] >> 32);\t\t\t\t/* FL(kl1) */\n\ttr = subRL[10] ^ rol32(dw, 1);\n\ttt = (tr | ((u64)tl << 32));\n\n\tSET_SUBKEY_LR(7, subRL[6] ^ tt);\t\t\t/* round 6 */\n\tSET_SUBKEY_LR(8, subRL[8]);\t\t\t\t/* FL(kl1) */\n\tSET_SUBKEY_LR(9, subRL[9]);\t\t\t\t/* FLinv(kl2) */\n\n\ttl = (subRL[7] >> 32) ^ (subRL[7] & ~subRL[9]);\n\tdw = tl & (subRL[9] >> 32);\t\t\t\t/* FLinv(kl2) */\n\ttr = subRL[7] ^ rol32(dw, 1);\n\ttt = (tr | ((u64)tl << 32));\n\n\tSET_SUBKEY_LR(10, subRL[11] ^ tt);\t\t\t/* round 7 */\n\tSET_SUBKEY_LR(11, subRL[10] ^ subRL[12]);\t\t/* round 8 */\n\tSET_SUBKEY_LR(12, subRL[11] ^ subRL[13]);\t\t/* round 9 */\n\tSET_SUBKEY_LR(13, subRL[12] ^ subRL[14]);\t\t/* round 10 */\n\tSET_SUBKEY_LR(14, subRL[13] ^ subRL[15]);\t\t/* round 11 */\n\n\ttl = (subRL[18] >> 32) ^ (subRL[18] & ~subRL[16]);\n\tdw = tl & (subRL[16] >> 32);\t\t\t\t/* FL(kl3) */\n\ttr = subRL[18] ^ rol32(dw, 1);\n\ttt = (tr | ((u64)tl << 32));\n\n\tSET_SUBKEY_LR(15, subRL[14] ^ tt);\t\t\t/* round 12 */\n\tSET_SUBKEY_LR(16, subRL[16]);\t\t\t\t/* FL(kl3) */\n\tSET_SUBKEY_LR(17, subRL[17]);\t\t\t\t/* FLinv(kl4) */\n\n\ttl = (subRL[15] >> 32) ^ (subRL[15] & ~subRL[17]);\n\tdw = tl & (subRL[17] >> 32);\t\t\t\t/* FLinv(kl4) */\n\ttr = subRL[15] ^ rol32(dw, 1);\n\ttt = (tr | ((u64)tl << 32));\n\n\tSET_SUBKEY_LR(18, subRL[19] ^ tt);\t\t\t/* round 13 */\n\tSET_SUBKEY_LR(19, subRL[18] ^ subRL[20]);\t\t/* round 14 */\n\tSET_SUBKEY_LR(20, subRL[19] ^ subRL[21]);\t\t/* round 15 */\n\tSET_SUBKEY_LR(21, subRL[20] ^ subRL[22]);\t\t/* round 16 */\n\tSET_SUBKEY_LR(22, subRL[21] ^ subRL[23]);\t\t/* round 17 */\n\n\tif (max == 24) {\n\t\tSET_SUBKEY_LR(23, subRL[22]);\t\t\t/* round 18 */\n\t\tSET_SUBKEY_LR(24, subRL[24] ^ subRL[23]);\t/* kw3 */\n\t} else {\n\t\ttl = (subRL[26] >> 32) ^ (subRL[26] & ~subRL[24]);\n\t\tdw = tl & (subRL[24] >> 32);\t\t\t/* FL(kl5) */\n\t\ttr = subRL[26] ^ rol32(dw, 1);\n\t\ttt = (tr | ((u64)tl << 32));\n\n\t\tSET_SUBKEY_LR(23, subRL[22] ^ tt);\t\t/* round 18 */\n\t\tSET_SUBKEY_LR(24, subRL[24]);\t\t\t/* FL(kl5) */\n\t\tSET_SUBKEY_LR(25, subRL[25]);\t\t\t/* FLinv(kl6) */\n\n\t\ttl = (subRL[23] >> 32) ^ (subRL[23] & ~subRL[25]);\n\t\tdw = tl & (subRL[25] >> 32);\t\t\t/* FLinv(kl6) */\n\t\ttr = subRL[23] ^ rol32(dw, 1);\n\t\ttt = (tr | ((u64)tl << 32));\n\n\t\tSET_SUBKEY_LR(26, subRL[27] ^ tt);\t\t/* round 19 */\n\t\tSET_SUBKEY_LR(27, subRL[26] ^ subRL[28]);\t/* round 20 */\n\t\tSET_SUBKEY_LR(28, subRL[27] ^ subRL[29]);\t/* round 21 */\n\t\tSET_SUBKEY_LR(29, subRL[28] ^ subRL[30]);\t/* round 22 */\n\t\tSET_SUBKEY_LR(30, subRL[29] ^ subRL[31]);\t/* round 23 */\n\t\tSET_SUBKEY_LR(31, subRL[30]);\t\t\t/* round 24 */\n\t\tSET_SUBKEY_LR(32, subRL[32] ^ subRL[31]);\t/* kw3 */\n\t}\n}\n\nstatic void camellia_setup128(const unsigned char *key, u64 *subkey)\n{\n\tu64 kl, kr, ww;\n\tu64 subRL[26];\n\n\t/**\n\t *  k == kl || kr (|| is concatenation)\n\t */\n\tkl = get_unaligned_be64(key);\n\tkr = get_unaligned_be64(key + 8);\n\n\t/* generate KL dependent subkeys */\n\t/* kw1 */\n\tsubRL[0] = kl;\n\t/* kw2 */\n\tsubRL[1] = kr;\n\n\t/* rotation left shift 15bit */\n\tROLDQ(kl, kr, 15);\n\n\t/* k3 */\n\tsubRL[4] = kl;\n\t/* k4 */\n\tsubRL[5] = kr;\n\n\t/* rotation left shift 15+30bit */\n\tROLDQ(kl, kr, 30);\n\n\t/* k7 */\n\tsubRL[10] = kl;\n\t/* k8 */\n\tsubRL[11] = kr;\n\n\t/* rotation left shift 15+30+15bit */\n\tROLDQ(kl, kr, 15);\n\n\t/* k10 */\n\tsubRL[13] = kr;\n\t/* rotation left shift 15+30+15+17 bit */\n\tROLDQ(kl, kr, 17);\n\n\t/* kl3 */\n\tsubRL[16] = kl;\n\t/* kl4 */\n\tsubRL[17] = kr;\n\n\t/* rotation left shift 15+30+15+17+17 bit */\n\tROLDQ(kl, kr, 17);\n\n\t/* k13 */\n\tsubRL[18] = kl;\n\t/* k14 */\n\tsubRL[19] = kr;\n\n\t/* rotation left shift 15+30+15+17+17+17 bit */\n\tROLDQ(kl, kr, 17);\n\n\t/* k17 */\n\tsubRL[22] = kl;\n\t/* k18 */\n\tsubRL[23] = kr;\n\n\t/* generate KA */\n\tkl = subRL[0];\n\tkr = subRL[1];\n\tCAMELLIA_F(kl, CAMELLIA_SIGMA1L, CAMELLIA_SIGMA1R, ww);\n\tkr ^= ww;\n\tCAMELLIA_F(kr, CAMELLIA_SIGMA2L, CAMELLIA_SIGMA2R, kl);\n\n\t/* current status == (kll, klr, w0, w1) */\n\tCAMELLIA_F(kl, CAMELLIA_SIGMA3L, CAMELLIA_SIGMA3R, kr);\n\tkr ^= ww;\n\tCAMELLIA_F(kr, CAMELLIA_SIGMA4L, CAMELLIA_SIGMA4R, ww);\n\tkl ^= ww;\n\n\t/* generate KA dependent subkeys */\n\t/* k1, k2 */\n\tsubRL[2] = kl;\n\tsubRL[3] = kr;\n\tROLDQ(kl, kr, 15);\n\t/* k5,k6 */\n\tsubRL[6] = kl;\n\tsubRL[7] = kr;\n\tROLDQ(kl, kr, 15);\n\t/* kl1, kl2 */\n\tsubRL[8] = kl;\n\tsubRL[9] = kr;\n\tROLDQ(kl, kr, 15);\n\t/* k9 */\n\tsubRL[12] = kl;\n\tROLDQ(kl, kr, 15);\n\t/* k11, k12 */\n\tsubRL[14] = kl;\n\tsubRL[15] = kr;\n\tROLDQ(kl, kr, 34);\n\t/* k15, k16 */\n\tsubRL[20] = kl;\n\tsubRL[21] = kr;\n\tROLDQ(kl, kr, 17);\n\t/* kw3, kw4 */\n\tsubRL[24] = kl;\n\tsubRL[25] = kr;\n\n\tcamellia_setup_tail(subkey, subRL, 24);\n}\n\nstatic void camellia_setup256(const unsigned char *key, u64 *subkey)\n{\n\tu64 kl, kr;\t\t\t/* left half of key */\n\tu64 krl, krr;\t\t\t/* right half of key */\n\tu64 ww;\t\t\t\t/* temporary variables */\n\tu64 subRL[34];\n\n\t/**\n\t *  key = (kl || kr || krl || krr) (|| is concatenation)\n\t */\n\tkl = get_unaligned_be64(key);\n\tkr = get_unaligned_be64(key + 8);\n\tkrl = get_unaligned_be64(key + 16);\n\tkrr = get_unaligned_be64(key + 24);\n\n\t/* generate KL dependent subkeys */\n\t/* kw1 */\n\tsubRL[0] = kl;\n\t/* kw2 */\n\tsubRL[1] = kr;\n\tROLDQ(kl, kr, 45);\n\t/* k9 */\n\tsubRL[12] = kl;\n\t/* k10 */\n\tsubRL[13] = kr;\n\tROLDQ(kl, kr, 15);\n\t/* kl3 */\n\tsubRL[16] = kl;\n\t/* kl4 */\n\tsubRL[17] = kr;\n\tROLDQ(kl, kr, 17);\n\t/* k17 */\n\tsubRL[22] = kl;\n\t/* k18 */\n\tsubRL[23] = kr;\n\tROLDQ(kl, kr, 34);\n\t/* k23 */\n\tsubRL[30] = kl;\n\t/* k24 */\n\tsubRL[31] = kr;\n\n\t/* generate KR dependent subkeys */\n\tROLDQ(krl, krr, 15);\n\t/* k3 */\n\tsubRL[4] = krl;\n\t/* k4 */\n\tsubRL[5] = krr;\n\tROLDQ(krl, krr, 15);\n\t/* kl1 */\n\tsubRL[8] = krl;\n\t/* kl2 */\n\tsubRL[9] = krr;\n\tROLDQ(krl, krr, 30);\n\t/* k13 */\n\tsubRL[18] = krl;\n\t/* k14 */\n\tsubRL[19] = krr;\n\tROLDQ(krl, krr, 34);\n\t/* k19 */\n\tsubRL[26] = krl;\n\t/* k20 */\n\tsubRL[27] = krr;\n\tROLDQ(krl, krr, 34);\n\n\t/* generate KA */\n\tkl = subRL[0] ^ krl;\n\tkr = subRL[1] ^ krr;\n\n\tCAMELLIA_F(kl, CAMELLIA_SIGMA1L, CAMELLIA_SIGMA1R, ww);\n\tkr ^= ww;\n\tCAMELLIA_F(kr, CAMELLIA_SIGMA2L, CAMELLIA_SIGMA2R, kl);\n\tkl ^= krl;\n\tCAMELLIA_F(kl, CAMELLIA_SIGMA3L, CAMELLIA_SIGMA3R, kr);\n\tkr ^= ww ^ krr;\n\tCAMELLIA_F(kr, CAMELLIA_SIGMA4L, CAMELLIA_SIGMA4R, ww);\n\tkl ^= ww;\n\n\t/* generate KB */\n\tkrl ^= kl;\n\tkrr ^= kr;\n\tCAMELLIA_F(krl, CAMELLIA_SIGMA5L, CAMELLIA_SIGMA5R, ww);\n\tkrr ^= ww;\n\tCAMELLIA_F(krr, CAMELLIA_SIGMA6L, CAMELLIA_SIGMA6R, ww);\n\tkrl ^= ww;\n\n\t/* generate KA dependent subkeys */\n\tROLDQ(kl, kr, 15);\n\t/* k5 */\n\tsubRL[6] = kl;\n\t/* k6 */\n\tsubRL[7] = kr;\n\tROLDQ(kl, kr, 30);\n\t/* k11 */\n\tsubRL[14] = kl;\n\t/* k12 */\n\tsubRL[15] = kr;\n\t/* rotation left shift 32bit */\n\tROLDQ(kl, kr, 32);\n\t/* kl5 */\n\tsubRL[24] = kl;\n\t/* kl6 */\n\tsubRL[25] = kr;\n\t/* rotation left shift 17 from k11,k12 -> k21,k22 */\n\tROLDQ(kl, kr, 17);\n\t/* k21 */\n\tsubRL[28] = kl;\n\t/* k22 */\n\tsubRL[29] = kr;\n\n\t/* generate KB dependent subkeys */\n\t/* k1 */\n\tsubRL[2] = krl;\n\t/* k2 */\n\tsubRL[3] = krr;\n\tROLDQ(krl, krr, 30);\n\t/* k7 */\n\tsubRL[10] = krl;\n\t/* k8 */\n\tsubRL[11] = krr;\n\tROLDQ(krl, krr, 30);\n\t/* k15 */\n\tsubRL[20] = krl;\n\t/* k16 */\n\tsubRL[21] = krr;\n\tROLDQ(krl, krr, 51);\n\t/* kw3 */\n\tsubRL[32] = krl;\n\t/* kw4 */\n\tsubRL[33] = krr;\n\n\tcamellia_setup_tail(subkey, subRL, 32);\n}\n\nstatic void camellia_setup192(const unsigned char *key, u64 *subkey)\n{\n\tunsigned char kk[32];\n\tu64 krl, krr;\n\n\tmemcpy(kk, key, 24);\n\tmemcpy((unsigned char *)&krl, key+16, 8);\n\tkrr = ~krl;\n\tmemcpy(kk+24, (unsigned char *)&krr, 8);\n\tcamellia_setup256(kk, subkey);\n}\n\nint __camellia_setkey(struct camellia_ctx *cctx, const unsigned char *key,\n\t\t      unsigned int key_len, u32 *flags)\n{\n\tif (key_len != 16 && key_len != 24 && key_len != 32) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\tcctx->key_length = key_len;\n\n\tswitch (key_len) {\n\tcase 16:\n\t\tcamellia_setup128(key, cctx->key_table);\n\t\tbreak;\n\tcase 24:\n\t\tcamellia_setup192(key, cctx->key_table);\n\t\tbreak;\n\tcase 32:\n\t\tcamellia_setup256(key, cctx->key_table);\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(__camellia_setkey);\n\nstatic int camellia_setkey(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t\t   unsigned int key_len)\n{\n\treturn __camellia_setkey(crypto_tfm_ctx(tfm), in_key, key_len,\n\t\t\t\t &tfm->crt_flags);\n}\n\nvoid camellia_decrypt_cbc_2way(void *ctx, u128 *dst, const u128 *src)\n{\n\tu128 iv = *src;\n\n\tcamellia_dec_blk_2way(ctx, (u8 *)dst, (u8 *)src);\n\n\tu128_xor(&dst[1], &dst[1], &iv);\n}\nEXPORT_SYMBOL_GPL(camellia_decrypt_cbc_2way);\n\nvoid camellia_crypt_ctr(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tbe128 ctrblk;\n\n\tif (dst != src)\n\t\t*dst = *src;\n\n\tle128_to_be128(&ctrblk, iv);\n\tle128_inc(iv);\n\n\tcamellia_enc_blk_xor(ctx, (u8 *)dst, (u8 *)&ctrblk);\n}\nEXPORT_SYMBOL_GPL(camellia_crypt_ctr);\n\nvoid camellia_crypt_ctr_2way(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tbe128 ctrblks[2];\n\n\tif (dst != src) {\n\t\tdst[0] = src[0];\n\t\tdst[1] = src[1];\n\t}\n\n\tle128_to_be128(&ctrblks[0], iv);\n\tle128_inc(iv);\n\tle128_to_be128(&ctrblks[1], iv);\n\tle128_inc(iv);\n\n\tcamellia_enc_blk_xor_2way(ctx, (u8 *)dst, (u8 *)ctrblks);\n}\nEXPORT_SYMBOL_GPL(camellia_crypt_ctr_2way);\n\nstatic const struct common_glue_ctx camellia_enc = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = -1,\n\n\t.funcs = { {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_enc_blk_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_enc_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_ctr = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = -1,\n\n\t.funcs = { {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(camellia_crypt_ctr_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(camellia_crypt_ctr) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_dec = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = -1,\n\n\t.funcs = { {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_dec_blk_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_dec_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_dec_cbc = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = -1,\n\n\t.funcs = { {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(camellia_decrypt_cbc_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(camellia_dec_blk) }\n\t} }\n};\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&camellia_enc, desc, dst, src, nbytes);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&camellia_dec, desc, dst, src, nbytes);\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_encrypt_128bit(GLUE_FUNC_CAST(camellia_enc_blk), desc,\n\t\t\t\t       dst, src, nbytes);\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_decrypt_128bit(&camellia_dec_cbc, desc, dst, src,\n\t\t\t\t       nbytes);\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ctr_crypt_128bit(&camellia_ctr, desc, dst, src, nbytes);\n}\n\nstatic void encrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = CAMELLIA_BLOCK_SIZE;\n\tstruct camellia_ctx *ctx = priv;\n\tint i;\n\n\twhile (nbytes >= 2 * bsize) {\n\t\tcamellia_enc_blk_2way(ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * 2;\n\t\tnbytes -= bsize * 2;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\tcamellia_enc_blk(ctx, srcdst, srcdst);\n}\n\nstatic void decrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = CAMELLIA_BLOCK_SIZE;\n\tstruct camellia_ctx *ctx = priv;\n\tint i;\n\n\twhile (nbytes >= 2 * bsize) {\n\t\tcamellia_dec_blk_2way(ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * 2;\n\t\tnbytes -= bsize * 2;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\tcamellia_dec_blk(ctx, srcdst, srcdst);\n}\n\nint lrw_camellia_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\tunsigned int keylen)\n{\n\tstruct camellia_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\tint err;\n\n\terr = __camellia_setkey(&ctx->camellia_ctx, key,\n\t\t\t\tkeylen - CAMELLIA_BLOCK_SIZE,\n\t\t\t\t&tfm->crt_flags);\n\tif (err)\n\t\treturn err;\n\n\treturn lrw_init_table(&ctx->lrw_table,\n\t\t\t      key + keylen - CAMELLIA_BLOCK_SIZE);\n}\nEXPORT_SYMBOL_GPL(lrw_camellia_setkey);\n\nstatic int lrw_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[2 * 4];\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &ctx->camellia_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\n\treturn lrw_crypt(desc, dst, src, nbytes, &req);\n}\n\nstatic int lrw_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[2 * 4];\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &ctx->camellia_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\n\treturn lrw_crypt(desc, dst, src, nbytes, &req);\n}\n\nvoid lrw_camellia_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct camellia_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tlrw_free_table(&ctx->lrw_table);\n}\nEXPORT_SYMBOL_GPL(lrw_camellia_exit_tfm);\n\nint xts_camellia_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\tunsigned int keylen)\n{\n\tstruct camellia_xts_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tint err;\n\n\t/* key consists of keys of equal size concatenated, therefore\n\t * the length must be even\n\t */\n\tif (keylen % 2) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\t/* first half of xts-key is for crypt */\n\terr = __camellia_setkey(&ctx->crypt_ctx, key, keylen / 2, flags);\n\tif (err)\n\t\treturn err;\n\n\t/* second half of xts-key is for tweak */\n\treturn __camellia_setkey(&ctx->tweak_ctx, key + keylen / 2, keylen / 2,\n\t\t\t\tflags);\n}\nEXPORT_SYMBOL_GPL(xts_camellia_setkey);\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[2 * 4];\n\tstruct xts_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.tweak_ctx = &ctx->tweak_ctx,\n\t\t.tweak_fn = XTS_TWEAK_CAST(camellia_enc_blk),\n\t\t.crypt_ctx = &ctx->crypt_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\n\treturn xts_crypt(desc, dst, src, nbytes, &req);\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[2 * 4];\n\tstruct xts_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.tweak_ctx = &ctx->tweak_ctx,\n\t\t.tweak_fn = XTS_TWEAK_CAST(camellia_enc_blk),\n\t\t.crypt_ctx = &ctx->crypt_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\n\treturn xts_crypt(desc, dst, src, nbytes, &req);\n}\n\nstatic struct crypto_alg camellia_algs[6] = { {\n\t.cra_name\t\t= \"camellia\",\n\t.cra_driver_name\t= \"camellia-asm\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u\t\t\t= {\n\t\t.cipher = {\n\t\t\t.cia_min_keysize = CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize = CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t = camellia_setkey,\n\t\t\t.cia_encrypt\t = camellia_encrypt,\n\t\t\t.cia_decrypt\t = camellia_decrypt\n\t\t}\n\t}\n}, {\n\t.cra_name\t\t= \"ecb(camellia)\",\n\t.cra_driver_name\t= \"ecb-camellia-asm\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= camellia_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(camellia)\",\n\t.cra_driver_name\t= \"cbc-camellia-asm\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= camellia_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(camellia)\",\n\t.cra_driver_name\t= \"ctr-camellia-asm\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= camellia_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"lrw(camellia)\",\n\t.cra_driver_name\t= \"lrw-camellia-asm\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_lrw_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_exit\t\t= lrw_camellia_exit_tfm,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE +\n\t\t\t\t\t\tCAMELLIA_BLOCK_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE +\n\t\t\t\t\t\tCAMELLIA_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= lrw_camellia_setkey,\n\t\t\t.encrypt\t= lrw_encrypt,\n\t\t\t.decrypt\t= lrw_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"xts(camellia)\",\n\t.cra_driver_name\t= \"xts-camellia-asm\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_xts_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= xts_camellia_setkey,\n\t\t\t.encrypt\t= xts_encrypt,\n\t\t\t.decrypt\t= xts_decrypt,\n\t\t},\n\t},\n} };\n\nstatic bool is_blacklisted_cpu(void)\n{\n\tif (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL)\n\t\treturn false;\n\n\tif (boot_cpu_data.x86 == 0x0f) {\n\t\t/*\n\t\t * On Pentium 4, camellia-asm is slower than original assembler\n\t\t * implementation because excessive uses of 64bit rotate and\n\t\t * left-shifts (which are really slow on P4) needed to store and\n\t\t * handle 128bit block in two 64bit registers.\n\t\t */\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic int force;\nmodule_param(force, int, 0);\nMODULE_PARM_DESC(force, \"Force module load, ignore CPU blacklist\");\n\nstatic int __init init(void)\n{\n\tif (!force && is_blacklisted_cpu()) {\n\t\tprintk(KERN_INFO\n\t\t\t\"camellia-x86_64: performance on this CPU \"\n\t\t\t\"would be suboptimal: disabling \"\n\t\t\t\"camellia-x86_64.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(camellia_algs, ARRAY_SIZE(camellia_algs));\n}\n\nstatic void __exit fini(void)\n{\n\tcrypto_unregister_algs(camellia_algs, ARRAY_SIZE(camellia_algs));\n}\n\nmodule_init(init);\nmodule_exit(fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Camellia Cipher Algorithm, asm optimized\");\nMODULE_ALIAS(\"camellia\");\nMODULE_ALIAS(\"camellia-asm\");\n", "/*\n * Glue Code for the AVX assembler implemention of the Cast5 Cipher\n *\n * Copyright (C) 2012 Johannes Goetzfried\n *     <Johannes.Goetzfried@informatik.stud.uni-erlangen.de>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307\n * USA\n *\n */\n\n#include <linux/module.h>\n#include <linux/hardirq.h>\n#include <linux/types.h>\n#include <linux/crypto.h>\n#include <linux/err.h>\n#include <crypto/ablk_helper.h>\n#include <crypto/algapi.h>\n#include <crypto/cast5.h>\n#include <crypto/cryptd.h>\n#include <crypto/ctr.h>\n#include <asm/xcr.h>\n#include <asm/xsave.h>\n#include <asm/crypto/glue_helper.h>\n\n#define CAST5_PARALLEL_BLOCKS 16\n\nasmlinkage void cast5_ecb_enc_16way(struct cast5_ctx *ctx, u8 *dst,\n\t\t\t\t    const u8 *src);\nasmlinkage void cast5_ecb_dec_16way(struct cast5_ctx *ctx, u8 *dst,\n\t\t\t\t    const u8 *src);\nasmlinkage void cast5_cbc_dec_16way(struct cast5_ctx *ctx, u8 *dst,\n\t\t\t\t    const u8 *src);\nasmlinkage void cast5_ctr_16way(struct cast5_ctx *ctx, u8 *dst, const u8 *src,\n\t\t\t\t__be64 *iv);\n\nstatic inline bool cast5_fpu_begin(bool fpu_enabled, unsigned int nbytes)\n{\n\treturn glue_fpu_begin(CAST5_BLOCK_SIZE, CAST5_PARALLEL_BLOCKS,\n\t\t\t      NULL, fpu_enabled, nbytes);\n}\n\nstatic inline void cast5_fpu_end(bool fpu_enabled)\n{\n\treturn glue_fpu_end(fpu_enabled);\n}\n\nstatic int ecb_crypt(struct blkcipher_desc *desc, struct blkcipher_walk *walk,\n\t\t     bool enc)\n{\n\tbool fpu_enabled = false;\n\tstruct cast5_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tconst unsigned int bsize = CAST5_BLOCK_SIZE;\n\tunsigned int nbytes;\n\tvoid (*fn)(struct cast5_ctx *ctx, u8 *dst, const u8 *src);\n\tint err;\n\n\tfn = (enc) ? cast5_ecb_enc_16way : cast5_ecb_dec_16way;\n\n\terr = blkcipher_walk_virt(desc, walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\twhile ((nbytes = walk->nbytes)) {\n\t\tu8 *wsrc = walk->src.virt.addr;\n\t\tu8 *wdst = walk->dst.virt.addr;\n\n\t\tfpu_enabled = cast5_fpu_begin(fpu_enabled, nbytes);\n\n\t\t/* Process multi-block batch */\n\t\tif (nbytes >= bsize * CAST5_PARALLEL_BLOCKS) {\n\t\t\tdo {\n\t\t\t\tfn(ctx, wdst, wsrc);\n\n\t\t\t\twsrc += bsize * CAST5_PARALLEL_BLOCKS;\n\t\t\t\twdst += bsize * CAST5_PARALLEL_BLOCKS;\n\t\t\t\tnbytes -= bsize * CAST5_PARALLEL_BLOCKS;\n\t\t\t} while (nbytes >= bsize * CAST5_PARALLEL_BLOCKS);\n\n\t\t\tif (nbytes < bsize)\n\t\t\t\tgoto done;\n\t\t}\n\n\t\tfn = (enc) ? __cast5_encrypt : __cast5_decrypt;\n\n\t\t/* Handle leftovers */\n\t\tdo {\n\t\t\tfn(ctx, wdst, wsrc);\n\n\t\t\twsrc += bsize;\n\t\t\twdst += bsize;\n\t\t\tnbytes -= bsize;\n\t\t} while (nbytes >= bsize);\n\ndone:\n\t\terr = blkcipher_walk_done(desc, walk, nbytes);\n\t}\n\n\tcast5_fpu_end(fpu_enabled);\n\treturn err;\n}\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_crypt(desc, &walk, true);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_crypt(desc, &walk, false);\n}\n\nstatic unsigned int __cbc_encrypt(struct blkcipher_desc *desc,\n\t\t\t\t  struct blkcipher_walk *walk)\n{\n\tstruct cast5_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tconst unsigned int bsize = CAST5_BLOCK_SIZE;\n\tunsigned int nbytes = walk->nbytes;\n\tu64 *src = (u64 *)walk->src.virt.addr;\n\tu64 *dst = (u64 *)walk->dst.virt.addr;\n\tu64 *iv = (u64 *)walk->iv;\n\n\tdo {\n\t\t*dst = *src ^ *iv;\n\t\t__cast5_encrypt(ctx, (u8 *)dst, (u8 *)dst);\n\t\tiv = dst;\n\n\t\tsrc += 1;\n\t\tdst += 1;\n\t\tnbytes -= bsize;\n\t} while (nbytes >= bsize);\n\n\t*(u64 *)walk->iv = *iv;\n\treturn nbytes;\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\twhile ((nbytes = walk.nbytes)) {\n\t\tnbytes = __cbc_encrypt(desc, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\n\treturn err;\n}\n\nstatic unsigned int __cbc_decrypt(struct blkcipher_desc *desc,\n\t\t\t\t  struct blkcipher_walk *walk)\n{\n\tstruct cast5_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tconst unsigned int bsize = CAST5_BLOCK_SIZE;\n\tunsigned int nbytes = walk->nbytes;\n\tu64 *src = (u64 *)walk->src.virt.addr;\n\tu64 *dst = (u64 *)walk->dst.virt.addr;\n\tu64 last_iv;\n\n\t/* Start of the last block. */\n\tsrc += nbytes / bsize - 1;\n\tdst += nbytes / bsize - 1;\n\n\tlast_iv = *src;\n\n\t/* Process multi-block batch */\n\tif (nbytes >= bsize * CAST5_PARALLEL_BLOCKS) {\n\t\tdo {\n\t\t\tnbytes -= bsize * (CAST5_PARALLEL_BLOCKS - 1);\n\t\t\tsrc -= CAST5_PARALLEL_BLOCKS - 1;\n\t\t\tdst -= CAST5_PARALLEL_BLOCKS - 1;\n\n\t\t\tcast5_cbc_dec_16way(ctx, (u8 *)dst, (u8 *)src);\n\n\t\t\tnbytes -= bsize;\n\t\t\tif (nbytes < bsize)\n\t\t\t\tgoto done;\n\n\t\t\t*dst ^= *(src - 1);\n\t\t\tsrc -= 1;\n\t\t\tdst -= 1;\n\t\t} while (nbytes >= bsize * CAST5_PARALLEL_BLOCKS);\n\t}\n\n\t/* Handle leftovers */\n\tfor (;;) {\n\t\t__cast5_decrypt(ctx, (u8 *)dst, (u8 *)src);\n\n\t\tnbytes -= bsize;\n\t\tif (nbytes < bsize)\n\t\t\tbreak;\n\n\t\t*dst ^= *(src - 1);\n\t\tsrc -= 1;\n\t\tdst -= 1;\n\t}\n\ndone:\n\t*dst ^= *(u64 *)walk->iv;\n\t*(u64 *)walk->iv = last_iv;\n\n\treturn nbytes;\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tbool fpu_enabled = false;\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\twhile ((nbytes = walk.nbytes)) {\n\t\tfpu_enabled = cast5_fpu_begin(fpu_enabled, nbytes);\n\t\tnbytes = __cbc_decrypt(desc, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\n\tcast5_fpu_end(fpu_enabled);\n\treturn err;\n}\n\nstatic void ctr_crypt_final(struct blkcipher_desc *desc,\n\t\t\t    struct blkcipher_walk *walk)\n{\n\tstruct cast5_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tu8 *ctrblk = walk->iv;\n\tu8 keystream[CAST5_BLOCK_SIZE];\n\tu8 *src = walk->src.virt.addr;\n\tu8 *dst = walk->dst.virt.addr;\n\tunsigned int nbytes = walk->nbytes;\n\n\t__cast5_encrypt(ctx, keystream, ctrblk);\n\tcrypto_xor(keystream, src, nbytes);\n\tmemcpy(dst, keystream, nbytes);\n\n\tcrypto_inc(ctrblk, CAST5_BLOCK_SIZE);\n}\n\nstatic unsigned int __ctr_crypt(struct blkcipher_desc *desc,\n\t\t\t\tstruct blkcipher_walk *walk)\n{\n\tstruct cast5_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tconst unsigned int bsize = CAST5_BLOCK_SIZE;\n\tunsigned int nbytes = walk->nbytes;\n\tu64 *src = (u64 *)walk->src.virt.addr;\n\tu64 *dst = (u64 *)walk->dst.virt.addr;\n\n\t/* Process multi-block batch */\n\tif (nbytes >= bsize * CAST5_PARALLEL_BLOCKS) {\n\t\tdo {\n\t\t\tcast5_ctr_16way(ctx, (u8 *)dst, (u8 *)src,\n\t\t\t\t\t(__be64 *)walk->iv);\n\n\t\t\tsrc += CAST5_PARALLEL_BLOCKS;\n\t\t\tdst += CAST5_PARALLEL_BLOCKS;\n\t\t\tnbytes -= bsize * CAST5_PARALLEL_BLOCKS;\n\t\t} while (nbytes >= bsize * CAST5_PARALLEL_BLOCKS);\n\n\t\tif (nbytes < bsize)\n\t\t\tgoto done;\n\t}\n\n\t/* Handle leftovers */\n\tdo {\n\t\tu64 ctrblk;\n\n\t\tif (dst != src)\n\t\t\t*dst = *src;\n\n\t\tctrblk = *(u64 *)walk->iv;\n\t\tbe64_add_cpu((__be64 *)walk->iv, 1);\n\n\t\t__cast5_encrypt(ctx, (u8 *)&ctrblk, (u8 *)&ctrblk);\n\t\t*dst ^= ctrblk;\n\n\t\tsrc += 1;\n\t\tdst += 1;\n\t\tnbytes -= bsize;\n\t} while (nbytes >= bsize);\n\ndone:\n\treturn nbytes;\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\tbool fpu_enabled = false;\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt_block(desc, &walk, CAST5_BLOCK_SIZE);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\twhile ((nbytes = walk.nbytes) >= CAST5_BLOCK_SIZE) {\n\t\tfpu_enabled = cast5_fpu_begin(fpu_enabled, nbytes);\n\t\tnbytes = __ctr_crypt(desc, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\n\tcast5_fpu_end(fpu_enabled);\n\n\tif (walk.nbytes) {\n\t\tctr_crypt_final(desc, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, 0);\n\t}\n\n\treturn err;\n}\n\n\nstatic struct crypto_alg cast5_algs[6] = { {\n\t.cra_name\t\t= \"__ecb-cast5-avx\",\n\t.cra_driver_name\t= \"__driver-ecb-cast5-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAST5_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct cast5_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAST5_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST5_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= cast5_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__cbc-cast5-avx\",\n\t.cra_driver_name\t= \"__driver-cbc-cast5-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAST5_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct cast5_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAST5_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST5_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= cast5_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__ctr-cast5-avx\",\n\t.cra_driver_name\t= \"__driver-ctr-cast5-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct cast5_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAST5_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST5_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAST5_BLOCK_SIZE,\n\t\t\t.setkey\t\t= cast5_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ecb(cast5)\",\n\t.cra_driver_name\t= \"ecb-cast5-avx\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAST5_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAST5_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST5_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(cast5)\",\n\t.cra_driver_name\t= \"cbc-cast5-avx\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAST5_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAST5_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST5_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAST5_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= __ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(cast5)\",\n\t.cra_driver_name\t= \"ctr-cast5-avx\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAST5_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST5_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAST5_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_encrypt,\n\t\t\t.geniv\t\t= \"chainiv\",\n\t\t},\n\t},\n} };\n\nstatic int __init cast5_init(void)\n{\n\tu64 xcr0;\n\n\tif (!cpu_has_avx || !cpu_has_osxsave) {\n\t\tpr_info(\"AVX instructions are not detected.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\txcr0 = xgetbv(XCR_XFEATURE_ENABLED_MASK);\n\tif ((xcr0 & (XSTATE_SSE | XSTATE_YMM)) != (XSTATE_SSE | XSTATE_YMM)) {\n\t\tpr_info(\"AVX detected but unusable.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(cast5_algs, ARRAY_SIZE(cast5_algs));\n}\n\nstatic void __exit cast5_exit(void)\n{\n\tcrypto_unregister_algs(cast5_algs, ARRAY_SIZE(cast5_algs));\n}\n\nmodule_init(cast5_init);\nmodule_exit(cast5_exit);\n\nMODULE_DESCRIPTION(\"Cast5 Cipher Algorithm, AVX optimized\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS(\"cast5\");\n", "/*\n * Glue Code for the AVX assembler implemention of the Cast6 Cipher\n *\n * Copyright (C) 2012 Johannes Goetzfried\n *     <Johannes.Goetzfried@informatik.stud.uni-erlangen.de>\n *\n * Copyright \u00a9 2013 Jussi Kivilinna <jussi.kivilinna@iki.fi>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307\n * USA\n *\n */\n\n#include <linux/module.h>\n#include <linux/hardirq.h>\n#include <linux/types.h>\n#include <linux/crypto.h>\n#include <linux/err.h>\n#include <crypto/ablk_helper.h>\n#include <crypto/algapi.h>\n#include <crypto/cast6.h>\n#include <crypto/cryptd.h>\n#include <crypto/b128ops.h>\n#include <crypto/ctr.h>\n#include <crypto/lrw.h>\n#include <crypto/xts.h>\n#include <asm/xcr.h>\n#include <asm/xsave.h>\n#include <asm/crypto/glue_helper.h>\n\n#define CAST6_PARALLEL_BLOCKS 8\n\nasmlinkage void cast6_ecb_enc_8way(struct cast6_ctx *ctx, u8 *dst,\n\t\t\t\t   const u8 *src);\nasmlinkage void cast6_ecb_dec_8way(struct cast6_ctx *ctx, u8 *dst,\n\t\t\t\t   const u8 *src);\n\nasmlinkage void cast6_cbc_dec_8way(struct cast6_ctx *ctx, u8 *dst,\n\t\t\t\t   const u8 *src);\nasmlinkage void cast6_ctr_8way(struct cast6_ctx *ctx, u8 *dst, const u8 *src,\n\t\t\t       le128 *iv);\n\nasmlinkage void cast6_xts_enc_8way(struct cast6_ctx *ctx, u8 *dst,\n\t\t\t\t   const u8 *src, le128 *iv);\nasmlinkage void cast6_xts_dec_8way(struct cast6_ctx *ctx, u8 *dst,\n\t\t\t\t   const u8 *src, le128 *iv);\n\nstatic void cast6_xts_enc(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tglue_xts_crypt_128bit_one(ctx, dst, src, iv,\n\t\t\t\t  GLUE_FUNC_CAST(__cast6_encrypt));\n}\n\nstatic void cast6_xts_dec(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tglue_xts_crypt_128bit_one(ctx, dst, src, iv,\n\t\t\t\t  GLUE_FUNC_CAST(__cast6_decrypt));\n}\n\nstatic void cast6_crypt_ctr(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tbe128 ctrblk;\n\n\tle128_to_be128(&ctrblk, iv);\n\tle128_inc(iv);\n\n\t__cast6_encrypt(ctx, (u8 *)&ctrblk, (u8 *)&ctrblk);\n\tu128_xor(dst, src, (u128 *)&ctrblk);\n}\n\nstatic const struct common_glue_ctx cast6_enc = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = CAST6_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAST6_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(cast6_ecb_enc_8way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(__cast6_encrypt) }\n\t} }\n};\n\nstatic const struct common_glue_ctx cast6_ctr = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = CAST6_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAST6_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(cast6_ctr_8way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(cast6_crypt_ctr) }\n\t} }\n};\n\nstatic const struct common_glue_ctx cast6_enc_xts = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = CAST6_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAST6_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(cast6_xts_enc_8way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(cast6_xts_enc) }\n\t} }\n};\n\nstatic const struct common_glue_ctx cast6_dec = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = CAST6_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAST6_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(cast6_ecb_dec_8way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(__cast6_decrypt) }\n\t} }\n};\n\nstatic const struct common_glue_ctx cast6_dec_cbc = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = CAST6_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAST6_PARALLEL_BLOCKS,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(cast6_cbc_dec_8way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(__cast6_decrypt) }\n\t} }\n};\n\nstatic const struct common_glue_ctx cast6_dec_xts = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = CAST6_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAST6_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(cast6_xts_dec_8way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(cast6_xts_dec) }\n\t} }\n};\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&cast6_enc, desc, dst, src, nbytes);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&cast6_dec, desc, dst, src, nbytes);\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_encrypt_128bit(GLUE_FUNC_CAST(__cast6_encrypt), desc,\n\t\t\t\t       dst, src, nbytes);\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_decrypt_128bit(&cast6_dec_cbc, desc, dst, src,\n\t\t\t\t       nbytes);\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ctr_crypt_128bit(&cast6_ctr, desc, dst, src, nbytes);\n}\n\nstatic inline bool cast6_fpu_begin(bool fpu_enabled, unsigned int nbytes)\n{\n\treturn glue_fpu_begin(CAST6_BLOCK_SIZE, CAST6_PARALLEL_BLOCKS,\n\t\t\t      NULL, fpu_enabled, nbytes);\n}\n\nstatic inline void cast6_fpu_end(bool fpu_enabled)\n{\n\tglue_fpu_end(fpu_enabled);\n}\n\nstruct crypt_priv {\n\tstruct cast6_ctx *ctx;\n\tbool fpu_enabled;\n};\n\nstatic void encrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = CAST6_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = cast6_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes == bsize * CAST6_PARALLEL_BLOCKS) {\n\t\tcast6_ecb_enc_8way(ctx->ctx, srcdst, srcdst);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\t__cast6_encrypt(ctx->ctx, srcdst, srcdst);\n}\n\nstatic void decrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = CAST6_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = cast6_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes == bsize * CAST6_PARALLEL_BLOCKS) {\n\t\tcast6_ecb_dec_8way(ctx->ctx, srcdst, srcdst);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\t__cast6_decrypt(ctx->ctx, srcdst, srcdst);\n}\n\nstruct cast6_lrw_ctx {\n\tstruct lrw_table_ctx lrw_table;\n\tstruct cast6_ctx cast6_ctx;\n};\n\nstatic int lrw_cast6_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\t      unsigned int keylen)\n{\n\tstruct cast6_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\tint err;\n\n\terr = __cast6_setkey(&ctx->cast6_ctx, key, keylen - CAST6_BLOCK_SIZE,\n\t\t\t     &tfm->crt_flags);\n\tif (err)\n\t\treturn err;\n\n\treturn lrw_init_table(&ctx->lrw_table, key + keylen - CAST6_BLOCK_SIZE);\n}\n\nstatic int lrw_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct cast6_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[CAST6_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->cast6_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tcast6_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int lrw_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct cast6_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[CAST6_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->cast6_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tcast6_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic void lrw_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct cast6_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tlrw_free_table(&ctx->lrw_table);\n}\n\nstruct cast6_xts_ctx {\n\tstruct cast6_ctx tweak_ctx;\n\tstruct cast6_ctx crypt_ctx;\n};\n\nstatic int xts_cast6_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\t      unsigned int keylen)\n{\n\tstruct cast6_xts_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tint err;\n\n\t/* key consists of keys of equal size concatenated, therefore\n\t * the length must be even\n\t */\n\tif (keylen % 2) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\t/* first half of xts-key is for crypt */\n\terr = __cast6_setkey(&ctx->crypt_ctx, key, keylen / 2, flags);\n\tif (err)\n\t\treturn err;\n\n\t/* second half of xts-key is for tweak */\n\treturn __cast6_setkey(&ctx->tweak_ctx, key + keylen / 2, keylen / 2,\n\t\t\t      flags);\n}\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct cast6_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&cast6_enc_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(__cast6_encrypt),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct cast6_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&cast6_dec_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(__cast6_encrypt),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic struct crypto_alg cast6_algs[10] = { {\n\t.cra_name\t\t= \"__ecb-cast6-avx\",\n\t.cra_driver_name\t= \"__driver-ecb-cast6-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAST6_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct cast6_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAST6_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST6_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= cast6_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__cbc-cast6-avx\",\n\t.cra_driver_name\t= \"__driver-cbc-cast6-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAST6_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct cast6_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAST6_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST6_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= cast6_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__ctr-cast6-avx\",\n\t.cra_driver_name\t= \"__driver-ctr-cast6-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct cast6_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAST6_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST6_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAST6_BLOCK_SIZE,\n\t\t\t.setkey\t\t= cast6_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__lrw-cast6-avx\",\n\t.cra_driver_name\t= \"__driver-lrw-cast6-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAST6_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct cast6_lrw_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_exit\t\t= lrw_exit_tfm,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAST6_MIN_KEY_SIZE +\n\t\t\t\t\t  CAST6_BLOCK_SIZE,\n\t\t\t.max_keysize\t= CAST6_MAX_KEY_SIZE +\n\t\t\t\t\t  CAST6_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= CAST6_BLOCK_SIZE,\n\t\t\t.setkey\t\t= lrw_cast6_setkey,\n\t\t\t.encrypt\t= lrw_encrypt,\n\t\t\t.decrypt\t= lrw_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__xts-cast6-avx\",\n\t.cra_driver_name\t= \"__driver-xts-cast6-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAST6_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct cast6_xts_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAST6_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= CAST6_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= CAST6_BLOCK_SIZE,\n\t\t\t.setkey\t\t= xts_cast6_setkey,\n\t\t\t.encrypt\t= xts_encrypt,\n\t\t\t.decrypt\t= xts_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ecb(cast6)\",\n\t.cra_driver_name\t= \"ecb-cast6-avx\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAST6_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAST6_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST6_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(cast6)\",\n\t.cra_driver_name\t= \"cbc-cast6-avx\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAST6_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAST6_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST6_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAST6_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= __ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(cast6)\",\n\t.cra_driver_name\t= \"ctr-cast6-avx\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAST6_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST6_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAST6_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_encrypt,\n\t\t\t.geniv\t\t= \"chainiv\",\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"lrw(cast6)\",\n\t.cra_driver_name\t= \"lrw-cast6-avx\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAST6_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAST6_MIN_KEY_SIZE +\n\t\t\t\t\t  CAST6_BLOCK_SIZE,\n\t\t\t.max_keysize\t= CAST6_MAX_KEY_SIZE +\n\t\t\t\t\t  CAST6_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= CAST6_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"xts(cast6)\",\n\t.cra_driver_name\t= \"xts-cast6-avx\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAST6_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAST6_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= CAST6_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= CAST6_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n} };\n\nstatic int __init cast6_init(void)\n{\n\tu64 xcr0;\n\n\tif (!cpu_has_avx || !cpu_has_osxsave) {\n\t\tpr_info(\"AVX instructions are not detected.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\txcr0 = xgetbv(XCR_XFEATURE_ENABLED_MASK);\n\tif ((xcr0 & (XSTATE_SSE | XSTATE_YMM)) != (XSTATE_SSE | XSTATE_YMM)) {\n\t\tpr_info(\"AVX detected but unusable.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(cast6_algs, ARRAY_SIZE(cast6_algs));\n}\n\nstatic void __exit cast6_exit(void)\n{\n\tcrypto_unregister_algs(cast6_algs, ARRAY_SIZE(cast6_algs));\n}\n\nmodule_init(cast6_init);\nmodule_exit(cast6_exit);\n\nMODULE_DESCRIPTION(\"Cast6 Cipher Algorithm, AVX optimized\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS(\"cast6\");\n", "/* GPL HEADER START\n *\n * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License version 2 only,\n * as published by the Free Software Foundation.\n *\n * This program is distributed in the hope that it will be useful, but\n * WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * General Public License version 2 for more details (a copy is included\n * in the LICENSE file that accompanied this code).\n *\n * You should have received a copy of the GNU General Public License\n * version 2 along with this program; If not, see http://www.gnu.org/licenses\n *\n * Please  visit http://www.xyratex.com/contact if you need additional\n * information or have any questions.\n *\n * GPL HEADER END\n */\n\n/*\n * Copyright 2012 Xyratex Technology Limited\n *\n * Wrappers for kernel crypto shash api to pclmulqdq crc32 imlementation.\n */\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n#include <linux/crc32.h>\n#include <crypto/internal/hash.h>\n\n#include <asm/cpufeature.h>\n#include <asm/cpu_device_id.h>\n#include <asm/i387.h>\n\n#define CHKSUM_BLOCK_SIZE\t1\n#define CHKSUM_DIGEST_SIZE\t4\n\n#define PCLMUL_MIN_LEN\t\t64L     /* minimum size of buffer\n\t\t\t\t\t * for crc32_pclmul_le_16 */\n#define SCALE_F\t\t\t16L\t/* size of xmm register */\n#define SCALE_F_MASK\t\t(SCALE_F - 1)\n\nu32 crc32_pclmul_le_16(unsigned char const *buffer, size_t len, u32 crc32);\n\nstatic u32 __attribute__((pure))\n\tcrc32_pclmul_le(u32 crc, unsigned char const *p, size_t len)\n{\n\tunsigned int iquotient;\n\tunsigned int iremainder;\n\tunsigned int prealign;\n\n\tif (len < PCLMUL_MIN_LEN + SCALE_F_MASK || !irq_fpu_usable())\n\t\treturn crc32_le(crc, p, len);\n\n\tif ((long)p & SCALE_F_MASK) {\n\t\t/* align p to 16 byte */\n\t\tprealign = SCALE_F - ((long)p & SCALE_F_MASK);\n\n\t\tcrc = crc32_le(crc, p, prealign);\n\t\tlen -= prealign;\n\t\tp = (unsigned char *)(((unsigned long)p + SCALE_F_MASK) &\n\t\t\t\t     ~SCALE_F_MASK);\n\t}\n\tiquotient = len & (~SCALE_F_MASK);\n\tiremainder = len & SCALE_F_MASK;\n\n\tkernel_fpu_begin();\n\tcrc = crc32_pclmul_le_16(p, iquotient, crc);\n\tkernel_fpu_end();\n\n\tif (iremainder)\n\t\tcrc = crc32_le(crc, p + iquotient, iremainder);\n\n\treturn crc;\n}\n\nstatic int crc32_pclmul_cra_init(struct crypto_tfm *tfm)\n{\n\tu32 *key = crypto_tfm_ctx(tfm);\n\n\t*key = 0;\n\n\treturn 0;\n}\n\nstatic int crc32_pclmul_setkey(struct crypto_shash *hash, const u8 *key,\n\t\t\tunsigned int keylen)\n{\n\tu32 *mctx = crypto_shash_ctx(hash);\n\n\tif (keylen != sizeof(u32)) {\n\t\tcrypto_shash_set_flags(hash, CRYPTO_TFM_RES_BAD_KEY_LEN);\n\t\treturn -EINVAL;\n\t}\n\t*mctx = le32_to_cpup((__le32 *)key);\n\treturn 0;\n}\n\nstatic int crc32_pclmul_init(struct shash_desc *desc)\n{\n\tu32 *mctx = crypto_shash_ctx(desc->tfm);\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t*crcp = *mctx;\n\n\treturn 0;\n}\n\nstatic int crc32_pclmul_update(struct shash_desc *desc, const u8 *data,\n\t\t\t       unsigned int len)\n{\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t*crcp = crc32_pclmul_le(*crcp, data, len);\n\treturn 0;\n}\n\n/* No final XOR 0xFFFFFFFF, like crc32_le */\nstatic int __crc32_pclmul_finup(u32 *crcp, const u8 *data, unsigned int len,\n\t\t\t\tu8 *out)\n{\n\t*(__le32 *)out = cpu_to_le32(crc32_pclmul_le(*crcp, data, len));\n\treturn 0;\n}\n\nstatic int crc32_pclmul_finup(struct shash_desc *desc, const u8 *data,\n\t\t\t      unsigned int len, u8 *out)\n{\n\treturn __crc32_pclmul_finup(shash_desc_ctx(desc), data, len, out);\n}\n\nstatic int crc32_pclmul_final(struct shash_desc *desc, u8 *out)\n{\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t*(__le32 *)out = cpu_to_le32p(crcp);\n\treturn 0;\n}\n\nstatic int crc32_pclmul_digest(struct shash_desc *desc, const u8 *data,\n\t\t\t       unsigned int len, u8 *out)\n{\n\treturn __crc32_pclmul_finup(crypto_shash_ctx(desc->tfm), data, len,\n\t\t\t\t    out);\n}\n\nstatic struct shash_alg alg = {\n\t.setkey\t\t= crc32_pclmul_setkey,\n\t.init\t\t= crc32_pclmul_init,\n\t.update\t\t= crc32_pclmul_update,\n\t.final\t\t= crc32_pclmul_final,\n\t.finup\t\t= crc32_pclmul_finup,\n\t.digest\t\t= crc32_pclmul_digest,\n\t.descsize\t= sizeof(u32),\n\t.digestsize\t= CHKSUM_DIGEST_SIZE,\n\t.base\t\t= {\n\t\t\t.cra_name\t\t= \"crc32\",\n\t\t\t.cra_driver_name\t= \"crc32-pclmul\",\n\t\t\t.cra_priority\t\t= 200,\n\t\t\t.cra_blocksize\t\t= CHKSUM_BLOCK_SIZE,\n\t\t\t.cra_ctxsize\t\t= sizeof(u32),\n\t\t\t.cra_module\t\t= THIS_MODULE,\n\t\t\t.cra_init\t\t= crc32_pclmul_cra_init,\n\t}\n};\n\nstatic const struct x86_cpu_id crc32pclmul_cpu_id[] = {\n\tX86_FEATURE_MATCH(X86_FEATURE_PCLMULQDQ),\n\t{}\n};\nMODULE_DEVICE_TABLE(x86cpu, crc32pclmul_cpu_id);\n\n\nstatic int __init crc32_pclmul_mod_init(void)\n{\n\n\tif (!x86_match_cpu(crc32pclmul_cpu_id)) {\n\t\tpr_info(\"PCLMULQDQ-NI instructions are not detected.\\n\");\n\t\treturn -ENODEV;\n\t}\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit crc32_pclmul_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(crc32_pclmul_mod_init);\nmodule_exit(crc32_pclmul_mod_fini);\n\nMODULE_AUTHOR(\"Alexander Boyko <alexander_boyko@xyratex.com>\");\nMODULE_LICENSE(\"GPL\");\n\nMODULE_ALIAS(\"crc32\");\nMODULE_ALIAS(\"crc32-pclmul\");\n", "/*\n * Using hardware provided CRC32 instruction to accelerate the CRC32 disposal.\n * CRC32C polynomial:0x1EDC6F41(BE)/0x82F63B78(LE)\n * CRC32 is a new instruction in Intel SSE4.2, the reference can be found at:\n * http://www.intel.com/products/processor/manuals/\n * Intel(R) 64 and IA-32 Architectures Software Developer's Manual\n * Volume 2A: Instruction Set Reference, A-M\n *\n * Copyright (C) 2008 Intel Corporation\n * Authors: Austin Zhang <austin_zhang@linux.intel.com>\n *          Kent Liu <kent.liu@intel.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms and conditions of the GNU General Public License,\n * version 2, as published by the Free Software Foundation.\n *\n * This program is distributed in the hope it will be useful, but WITHOUT\n * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for\n * more details.\n *\n * You should have received a copy of the GNU General Public License along with\n * this program; if not, write to the Free Software Foundation, Inc.,\n * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.\n *\n */\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n#include <crypto/internal/hash.h>\n\n#include <asm/cpufeature.h>\n#include <asm/cpu_device_id.h>\n#include <asm/i387.h>\n#include <asm/fpu-internal.h>\n\n#define CHKSUM_BLOCK_SIZE\t1\n#define CHKSUM_DIGEST_SIZE\t4\n\n#define SCALE_F\tsizeof(unsigned long)\n\n#ifdef CONFIG_X86_64\n#define REX_PRE \"0x48, \"\n#else\n#define REX_PRE\n#endif\n\n#ifdef CONFIG_X86_64\n/*\n * use carryless multiply version of crc32c when buffer\n * size is >= 512 (when eager fpu is enabled) or\n * >= 1024 (when eager fpu is disabled) to account\n * for fpu state save/restore overhead.\n */\n#define CRC32C_PCL_BREAKEVEN_EAGERFPU\t512\n#define CRC32C_PCL_BREAKEVEN_NOEAGERFPU\t1024\n\nasmlinkage unsigned int crc_pcl(const u8 *buffer, int len,\n\t\t\t\tunsigned int crc_init);\nstatic int crc32c_pcl_breakeven = CRC32C_PCL_BREAKEVEN_EAGERFPU;\n#if defined(X86_FEATURE_EAGER_FPU)\n#define set_pcl_breakeven_point()\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tif (!use_eager_fpu())\t\t\t\t\t\t\\\n\t\tcrc32c_pcl_breakeven = CRC32C_PCL_BREAKEVEN_NOEAGERFPU;\t\\\n} while (0)\n#else\n#define set_pcl_breakeven_point()\t\t\t\t\t\\\n\t(crc32c_pcl_breakeven = CRC32C_PCL_BREAKEVEN_NOEAGERFPU)\n#endif\n#endif /* CONFIG_X86_64 */\n\nstatic u32 crc32c_intel_le_hw_byte(u32 crc, unsigned char const *data, size_t length)\n{\n\twhile (length--) {\n\t\t__asm__ __volatile__(\n\t\t\t\".byte 0xf2, 0xf, 0x38, 0xf0, 0xf1\"\n\t\t\t:\"=S\"(crc)\n\t\t\t:\"0\"(crc), \"c\"(*data)\n\t\t);\n\t\tdata++;\n\t}\n\n\treturn crc;\n}\n\nstatic u32 __pure crc32c_intel_le_hw(u32 crc, unsigned char const *p, size_t len)\n{\n\tunsigned int iquotient = len / SCALE_F;\n\tunsigned int iremainder = len % SCALE_F;\n\tunsigned long *ptmp = (unsigned long *)p;\n\n\twhile (iquotient--) {\n\t\t__asm__ __volatile__(\n\t\t\t\".byte 0xf2, \" REX_PRE \"0xf, 0x38, 0xf1, 0xf1;\"\n\t\t\t:\"=S\"(crc)\n\t\t\t:\"0\"(crc), \"c\"(*ptmp)\n\t\t);\n\t\tptmp++;\n\t}\n\n\tif (iremainder)\n\t\tcrc = crc32c_intel_le_hw_byte(crc, (unsigned char *)ptmp,\n\t\t\t\t iremainder);\n\n\treturn crc;\n}\n\n/*\n * Setting the seed allows arbitrary accumulators and flexible XOR policy\n * If your algorithm starts with ~0, then XOR with ~0 before you set\n * the seed.\n */\nstatic int crc32c_intel_setkey(struct crypto_shash *hash, const u8 *key,\n\t\t\tunsigned int keylen)\n{\n\tu32 *mctx = crypto_shash_ctx(hash);\n\n\tif (keylen != sizeof(u32)) {\n\t\tcrypto_shash_set_flags(hash, CRYPTO_TFM_RES_BAD_KEY_LEN);\n\t\treturn -EINVAL;\n\t}\n\t*mctx = le32_to_cpup((__le32 *)key);\n\treturn 0;\n}\n\nstatic int crc32c_intel_init(struct shash_desc *desc)\n{\n\tu32 *mctx = crypto_shash_ctx(desc->tfm);\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t*crcp = *mctx;\n\n\treturn 0;\n}\n\nstatic int crc32c_intel_update(struct shash_desc *desc, const u8 *data,\n\t\t\t       unsigned int len)\n{\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t*crcp = crc32c_intel_le_hw(*crcp, data, len);\n\treturn 0;\n}\n\nstatic int __crc32c_intel_finup(u32 *crcp, const u8 *data, unsigned int len,\n\t\t\t\tu8 *out)\n{\n\t*(__le32 *)out = ~cpu_to_le32(crc32c_intel_le_hw(*crcp, data, len));\n\treturn 0;\n}\n\nstatic int crc32c_intel_finup(struct shash_desc *desc, const u8 *data,\n\t\t\t      unsigned int len, u8 *out)\n{\n\treturn __crc32c_intel_finup(shash_desc_ctx(desc), data, len, out);\n}\n\nstatic int crc32c_intel_final(struct shash_desc *desc, u8 *out)\n{\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t*(__le32 *)out = ~cpu_to_le32p(crcp);\n\treturn 0;\n}\n\nstatic int crc32c_intel_digest(struct shash_desc *desc, const u8 *data,\n\t\t\t       unsigned int len, u8 *out)\n{\n\treturn __crc32c_intel_finup(crypto_shash_ctx(desc->tfm), data, len,\n\t\t\t\t    out);\n}\n\nstatic int crc32c_intel_cra_init(struct crypto_tfm *tfm)\n{\n\tu32 *key = crypto_tfm_ctx(tfm);\n\n\t*key = ~0;\n\n\treturn 0;\n}\n\n#ifdef CONFIG_X86_64\nstatic int crc32c_pcl_intel_update(struct shash_desc *desc, const u8 *data,\n\t\t\t       unsigned int len)\n{\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t/*\n\t * use faster PCL version if datasize is large enough to\n\t * overcome kernel fpu state save/restore overhead\n\t */\n\tif (len >= crc32c_pcl_breakeven && irq_fpu_usable()) {\n\t\tkernel_fpu_begin();\n\t\t*crcp = crc_pcl(data, len, *crcp);\n\t\tkernel_fpu_end();\n\t} else\n\t\t*crcp = crc32c_intel_le_hw(*crcp, data, len);\n\treturn 0;\n}\n\nstatic int __crc32c_pcl_intel_finup(u32 *crcp, const u8 *data, unsigned int len,\n\t\t\t\tu8 *out)\n{\n\tif (len >= crc32c_pcl_breakeven && irq_fpu_usable()) {\n\t\tkernel_fpu_begin();\n\t\t*(__le32 *)out = ~cpu_to_le32(crc_pcl(data, len, *crcp));\n\t\tkernel_fpu_end();\n\t} else\n\t\t*(__le32 *)out =\n\t\t\t~cpu_to_le32(crc32c_intel_le_hw(*crcp, data, len));\n\treturn 0;\n}\n\nstatic int crc32c_pcl_intel_finup(struct shash_desc *desc, const u8 *data,\n\t\t\t      unsigned int len, u8 *out)\n{\n\treturn __crc32c_pcl_intel_finup(shash_desc_ctx(desc), data, len, out);\n}\n\nstatic int crc32c_pcl_intel_digest(struct shash_desc *desc, const u8 *data,\n\t\t\t       unsigned int len, u8 *out)\n{\n\treturn __crc32c_pcl_intel_finup(crypto_shash_ctx(desc->tfm), data, len,\n\t\t\t\t    out);\n}\n#endif /* CONFIG_X86_64 */\n\nstatic struct shash_alg alg = {\n\t.setkey\t\t\t=\tcrc32c_intel_setkey,\n\t.init\t\t\t=\tcrc32c_intel_init,\n\t.update\t\t\t=\tcrc32c_intel_update,\n\t.final\t\t\t=\tcrc32c_intel_final,\n\t.finup\t\t\t=\tcrc32c_intel_finup,\n\t.digest\t\t\t=\tcrc32c_intel_digest,\n\t.descsize\t\t=\tsizeof(u32),\n\t.digestsize\t\t=\tCHKSUM_DIGEST_SIZE,\n\t.base\t\t\t=\t{\n\t\t.cra_name\t\t=\t\"crc32c\",\n\t\t.cra_driver_name\t=\t\"crc32c-intel\",\n\t\t.cra_priority\t\t=\t200,\n\t\t.cra_blocksize\t\t=\tCHKSUM_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t=\tsizeof(u32),\n\t\t.cra_module\t\t=\tTHIS_MODULE,\n\t\t.cra_init\t\t=\tcrc32c_intel_cra_init,\n\t}\n};\n\nstatic const struct x86_cpu_id crc32c_cpu_id[] = {\n\tX86_FEATURE_MATCH(X86_FEATURE_XMM4_2),\n\t{}\n};\nMODULE_DEVICE_TABLE(x86cpu, crc32c_cpu_id);\n\nstatic int __init crc32c_intel_mod_init(void)\n{\n\tif (!x86_match_cpu(crc32c_cpu_id))\n\t\treturn -ENODEV;\n#ifdef CONFIG_X86_64\n\tif (cpu_has_pclmulqdq) {\n\t\talg.update = crc32c_pcl_intel_update;\n\t\talg.finup = crc32c_pcl_intel_finup;\n\t\talg.digest = crc32c_pcl_intel_digest;\n\t\tset_pcl_breakeven_point();\n\t}\n#endif\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit crc32c_intel_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(crc32c_intel_mod_init);\nmodule_exit(crc32c_intel_mod_fini);\n\nMODULE_AUTHOR(\"Austin Zhang <austin.zhang@intel.com>, Kent Liu <kent.liu@intel.com>\");\nMODULE_DESCRIPTION(\"CRC32c (Castagnoli) optimization using Intel Hardware.\");\nMODULE_LICENSE(\"GPL\");\n\nMODULE_ALIAS(\"crc32c\");\nMODULE_ALIAS(\"crc32c-intel\");\n", "/*\n * Cryptographic API.\n *\n * T10 Data Integrity Field CRC16 Crypto Transform using PCLMULQDQ Instructions\n *\n * Copyright (C) 2013 Intel Corporation\n * Author: Tim Chen <tim.c.chen@linux.intel.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS\n * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n * SOFTWARE.\n *\n */\n\n#include <linux/types.h>\n#include <linux/module.h>\n#include <linux/crc-t10dif.h>\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n#include <asm/i387.h>\n#include <asm/cpufeature.h>\n#include <asm/cpu_device_id.h>\n\nasmlinkage __u16 crc_t10dif_pcl(__u16 crc, const unsigned char *buf,\n\t\t\t\tsize_t len);\n\nstruct chksum_desc_ctx {\n\t__u16 crc;\n};\n\n/*\n * Steps through buffer one byte at at time, calculates reflected\n * crc using table.\n */\n\nstatic int chksum_init(struct shash_desc *desc)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\tctx->crc = 0;\n\n\treturn 0;\n}\n\nstatic int chksum_update(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int length)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\tif (irq_fpu_usable()) {\n\t\tkernel_fpu_begin();\n\t\tctx->crc = crc_t10dif_pcl(ctx->crc, data, length);\n\t\tkernel_fpu_end();\n\t} else\n\t\tctx->crc = crc_t10dif_generic(ctx->crc, data, length);\n\treturn 0;\n}\n\nstatic int chksum_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\t*(__u16 *)out = ctx->crc;\n\treturn 0;\n}\n\nstatic int __chksum_finup(__u16 *crcp, const u8 *data, unsigned int len,\n\t\t\tu8 *out)\n{\n\tif (irq_fpu_usable()) {\n\t\tkernel_fpu_begin();\n\t\t*(__u16 *)out = crc_t10dif_pcl(*crcp, data, len);\n\t\tkernel_fpu_end();\n\t} else\n\t\t*(__u16 *)out = crc_t10dif_generic(*crcp, data, len);\n\treturn 0;\n}\n\nstatic int chksum_finup(struct shash_desc *desc, const u8 *data,\n\t\t\tunsigned int len, u8 *out)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\treturn __chksum_finup(&ctx->crc, data, len, out);\n}\n\nstatic int chksum_digest(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int length, u8 *out)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\treturn __chksum_finup(&ctx->crc, data, length, out);\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t\t=\tCRC_T10DIF_DIGEST_SIZE,\n\t.init\t\t=\tchksum_init,\n\t.update\t\t=\tchksum_update,\n\t.final\t\t=\tchksum_final,\n\t.finup\t\t=\tchksum_finup,\n\t.digest\t\t=\tchksum_digest,\n\t.descsize\t\t=\tsizeof(struct chksum_desc_ctx),\n\t.base\t\t\t=\t{\n\t\t.cra_name\t\t=\t\"crct10dif\",\n\t\t.cra_driver_name\t=\t\"crct10dif-pclmul\",\n\t\t.cra_priority\t\t=\t200,\n\t\t.cra_blocksize\t\t=\tCRC_T10DIF_BLOCK_SIZE,\n\t\t.cra_module\t\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic const struct x86_cpu_id crct10dif_cpu_id[] = {\n\tX86_FEATURE_MATCH(X86_FEATURE_PCLMULQDQ),\n\t{}\n};\nMODULE_DEVICE_TABLE(x86cpu, crct10dif_cpu_id);\n\nstatic int __init crct10dif_intel_mod_init(void)\n{\n\tif (!x86_match_cpu(crct10dif_cpu_id))\n\t\treturn -ENODEV;\n\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit crct10dif_intel_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(crct10dif_intel_mod_init);\nmodule_exit(crct10dif_intel_mod_fini);\n\nMODULE_AUTHOR(\"Tim Chen <tim.c.chen@linux.intel.com>\");\nMODULE_DESCRIPTION(\"T10 DIF CRC calculation accelerated with PCLMULQDQ.\");\nMODULE_LICENSE(\"GPL\");\n\nMODULE_ALIAS(\"crct10dif\");\nMODULE_ALIAS(\"crct10dif-pclmul\");\n", "/*\n * Glue Code for assembler optimized version of 3DES\n *\n * Copyright \u00a9 2014 Jussi Kivilinna <jussi.kivilinna@mbnet.fi>\n *\n * CBC & ECB parts based on code (crypto/cbc.c,ecb.c) by:\n *   Copyright (c) 2006 Herbert Xu <herbert@gondor.apana.org.au>\n * CTR part based on code (crypto/ctr.c) by:\n *   (C) Copyright IBM Corp. 2007 - Joy Latten <latten@us.ibm.com>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n */\n\n#include <asm/processor.h>\n#include <crypto/des.h>\n#include <linux/crypto.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/types.h>\n#include <crypto/algapi.h>\n\nstruct des3_ede_x86_ctx {\n\tu32 enc_expkey[DES3_EDE_EXPKEY_WORDS];\n\tu32 dec_expkey[DES3_EDE_EXPKEY_WORDS];\n};\n\n/* regular block cipher functions */\nasmlinkage void des3_ede_x86_64_crypt_blk(const u32 *expkey, u8 *dst,\n\t\t\t\t\t  const u8 *src);\n\n/* 3-way parallel cipher functions */\nasmlinkage void des3_ede_x86_64_crypt_blk_3way(const u32 *expkey, u8 *dst,\n\t\t\t\t\t       const u8 *src);\n\nstatic inline void des3_ede_enc_blk(struct des3_ede_x86_ctx *ctx, u8 *dst,\n\t\t\t\t    const u8 *src)\n{\n\tu32 *enc_ctx = ctx->enc_expkey;\n\n\tdes3_ede_x86_64_crypt_blk(enc_ctx, dst, src);\n}\n\nstatic inline void des3_ede_dec_blk(struct des3_ede_x86_ctx *ctx, u8 *dst,\n\t\t\t\t    const u8 *src)\n{\n\tu32 *dec_ctx = ctx->dec_expkey;\n\n\tdes3_ede_x86_64_crypt_blk(dec_ctx, dst, src);\n}\n\nstatic inline void des3_ede_enc_blk_3way(struct des3_ede_x86_ctx *ctx, u8 *dst,\n\t\t\t\t\t const u8 *src)\n{\n\tu32 *enc_ctx = ctx->enc_expkey;\n\n\tdes3_ede_x86_64_crypt_blk_3way(enc_ctx, dst, src);\n}\n\nstatic inline void des3_ede_dec_blk_3way(struct des3_ede_x86_ctx *ctx, u8 *dst,\n\t\t\t\t\t const u8 *src)\n{\n\tu32 *dec_ctx = ctx->dec_expkey;\n\n\tdes3_ede_x86_64_crypt_blk_3way(dec_ctx, dst, src);\n}\n\nstatic void des3_ede_x86_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tdes3_ede_enc_blk(crypto_tfm_ctx(tfm), dst, src);\n}\n\nstatic void des3_ede_x86_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tdes3_ede_dec_blk(crypto_tfm_ctx(tfm), dst, src);\n}\n\nstatic int ecb_crypt(struct blkcipher_desc *desc, struct blkcipher_walk *walk,\n\t\t     const u32 *expkey)\n{\n\tunsigned int bsize = DES3_EDE_BLOCK_SIZE;\n\tunsigned int nbytes;\n\tint err;\n\n\terr = blkcipher_walk_virt(desc, walk);\n\n\twhile ((nbytes = walk->nbytes)) {\n\t\tu8 *wsrc = walk->src.virt.addr;\n\t\tu8 *wdst = walk->dst.virt.addr;\n\n\t\t/* Process four block batch */\n\t\tif (nbytes >= bsize * 3) {\n\t\t\tdo {\n\t\t\t\tdes3_ede_x86_64_crypt_blk_3way(expkey, wdst,\n\t\t\t\t\t\t\t       wsrc);\n\n\t\t\t\twsrc += bsize * 3;\n\t\t\t\twdst += bsize * 3;\n\t\t\t\tnbytes -= bsize * 3;\n\t\t\t} while (nbytes >= bsize * 3);\n\n\t\t\tif (nbytes < bsize)\n\t\t\t\tgoto done;\n\t\t}\n\n\t\t/* Handle leftovers */\n\t\tdo {\n\t\t\tdes3_ede_x86_64_crypt_blk(expkey, wdst, wsrc);\n\n\t\t\twsrc += bsize;\n\t\t\twdst += bsize;\n\t\t\tnbytes -= bsize;\n\t\t} while (nbytes >= bsize);\n\ndone:\n\t\terr = blkcipher_walk_done(desc, walk, nbytes);\n\t}\n\n\treturn err;\n}\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct des3_ede_x86_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_crypt(desc, &walk, ctx->enc_expkey);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct des3_ede_x86_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_crypt(desc, &walk, ctx->dec_expkey);\n}\n\nstatic unsigned int __cbc_encrypt(struct blkcipher_desc *desc,\n\t\t\t\t  struct blkcipher_walk *walk)\n{\n\tstruct des3_ede_x86_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tunsigned int bsize = DES3_EDE_BLOCK_SIZE;\n\tunsigned int nbytes = walk->nbytes;\n\tu64 *src = (u64 *)walk->src.virt.addr;\n\tu64 *dst = (u64 *)walk->dst.virt.addr;\n\tu64 *iv = (u64 *)walk->iv;\n\n\tdo {\n\t\t*dst = *src ^ *iv;\n\t\tdes3_ede_enc_blk(ctx, (u8 *)dst, (u8 *)dst);\n\t\tiv = dst;\n\n\t\tsrc += 1;\n\t\tdst += 1;\n\t\tnbytes -= bsize;\n\t} while (nbytes >= bsize);\n\n\t*(u64 *)walk->iv = *iv;\n\treturn nbytes;\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\twhile ((nbytes = walk.nbytes)) {\n\t\tnbytes = __cbc_encrypt(desc, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\n\treturn err;\n}\n\nstatic unsigned int __cbc_decrypt(struct blkcipher_desc *desc,\n\t\t\t\t  struct blkcipher_walk *walk)\n{\n\tstruct des3_ede_x86_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tunsigned int bsize = DES3_EDE_BLOCK_SIZE;\n\tunsigned int nbytes = walk->nbytes;\n\tu64 *src = (u64 *)walk->src.virt.addr;\n\tu64 *dst = (u64 *)walk->dst.virt.addr;\n\tu64 ivs[3 - 1];\n\tu64 last_iv;\n\n\t/* Start of the last block. */\n\tsrc += nbytes / bsize - 1;\n\tdst += nbytes / bsize - 1;\n\n\tlast_iv = *src;\n\n\t/* Process four block batch */\n\tif (nbytes >= bsize * 3) {\n\t\tdo {\n\t\t\tnbytes -= bsize * 3 - bsize;\n\t\t\tsrc -= 3 - 1;\n\t\t\tdst -= 3 - 1;\n\n\t\t\tivs[0] = src[0];\n\t\t\tivs[1] = src[1];\n\n\t\t\tdes3_ede_dec_blk_3way(ctx, (u8 *)dst, (u8 *)src);\n\n\t\t\tdst[1] ^= ivs[0];\n\t\t\tdst[2] ^= ivs[1];\n\n\t\t\tnbytes -= bsize;\n\t\t\tif (nbytes < bsize)\n\t\t\t\tgoto done;\n\n\t\t\t*dst ^= *(src - 1);\n\t\t\tsrc -= 1;\n\t\t\tdst -= 1;\n\t\t} while (nbytes >= bsize * 3);\n\t}\n\n\t/* Handle leftovers */\n\tfor (;;) {\n\t\tdes3_ede_dec_blk(ctx, (u8 *)dst, (u8 *)src);\n\n\t\tnbytes -= bsize;\n\t\tif (nbytes < bsize)\n\t\t\tbreak;\n\n\t\t*dst ^= *(src - 1);\n\t\tsrc -= 1;\n\t\tdst -= 1;\n\t}\n\ndone:\n\t*dst ^= *(u64 *)walk->iv;\n\t*(u64 *)walk->iv = last_iv;\n\n\treturn nbytes;\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\twhile ((nbytes = walk.nbytes)) {\n\t\tnbytes = __cbc_decrypt(desc, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\n\treturn err;\n}\n\nstatic void ctr_crypt_final(struct des3_ede_x86_ctx *ctx,\n\t\t\t    struct blkcipher_walk *walk)\n{\n\tu8 *ctrblk = walk->iv;\n\tu8 keystream[DES3_EDE_BLOCK_SIZE];\n\tu8 *src = walk->src.virt.addr;\n\tu8 *dst = walk->dst.virt.addr;\n\tunsigned int nbytes = walk->nbytes;\n\n\tdes3_ede_enc_blk(ctx, keystream, ctrblk);\n\tcrypto_xor(keystream, src, nbytes);\n\tmemcpy(dst, keystream, nbytes);\n\n\tcrypto_inc(ctrblk, DES3_EDE_BLOCK_SIZE);\n}\n\nstatic unsigned int __ctr_crypt(struct blkcipher_desc *desc,\n\t\t\t\tstruct blkcipher_walk *walk)\n{\n\tstruct des3_ede_x86_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tunsigned int bsize = DES3_EDE_BLOCK_SIZE;\n\tunsigned int nbytes = walk->nbytes;\n\t__be64 *src = (__be64 *)walk->src.virt.addr;\n\t__be64 *dst = (__be64 *)walk->dst.virt.addr;\n\tu64 ctrblk = be64_to_cpu(*(__be64 *)walk->iv);\n\t__be64 ctrblocks[3];\n\n\t/* Process four block batch */\n\tif (nbytes >= bsize * 3) {\n\t\tdo {\n\t\t\t/* create ctrblks for parallel encrypt */\n\t\t\tctrblocks[0] = cpu_to_be64(ctrblk++);\n\t\t\tctrblocks[1] = cpu_to_be64(ctrblk++);\n\t\t\tctrblocks[2] = cpu_to_be64(ctrblk++);\n\n\t\t\tdes3_ede_enc_blk_3way(ctx, (u8 *)ctrblocks,\n\t\t\t\t\t      (u8 *)ctrblocks);\n\n\t\t\tdst[0] = src[0] ^ ctrblocks[0];\n\t\t\tdst[1] = src[1] ^ ctrblocks[1];\n\t\t\tdst[2] = src[2] ^ ctrblocks[2];\n\n\t\t\tsrc += 3;\n\t\t\tdst += 3;\n\t\t} while ((nbytes -= bsize * 3) >= bsize * 3);\n\n\t\tif (nbytes < bsize)\n\t\t\tgoto done;\n\t}\n\n\t/* Handle leftovers */\n\tdo {\n\t\tctrblocks[0] = cpu_to_be64(ctrblk++);\n\n\t\tdes3_ede_enc_blk(ctx, (u8 *)ctrblocks, (u8 *)ctrblocks);\n\n\t\tdst[0] = src[0] ^ ctrblocks[0];\n\n\t\tsrc += 1;\n\t\tdst += 1;\n\t} while ((nbytes -= bsize) >= bsize);\n\ndone:\n\t*(__be64 *)walk->iv = cpu_to_be64(ctrblk);\n\treturn nbytes;\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt_block(desc, &walk, DES3_EDE_BLOCK_SIZE);\n\n\twhile ((nbytes = walk.nbytes) >= DES3_EDE_BLOCK_SIZE) {\n\t\tnbytes = __ctr_crypt(desc, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\n\tif (walk.nbytes) {\n\t\tctr_crypt_final(crypto_blkcipher_ctx(desc->tfm), &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, 0);\n\t}\n\n\treturn err;\n}\n\nstatic int des3_ede_x86_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\t       unsigned int keylen)\n{\n\tstruct des3_ede_x86_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 i, j, tmp;\n\tint err;\n\n\t/* Generate encryption context using generic implementation. */\n\terr = __des3_ede_setkey(ctx->enc_expkey, &tfm->crt_flags, key, keylen);\n\tif (err < 0)\n\t\treturn err;\n\n\t/* Fix encryption context for this implementation and form decryption\n\t * context. */\n\tj = DES3_EDE_EXPKEY_WORDS - 2;\n\tfor (i = 0; i < DES3_EDE_EXPKEY_WORDS; i += 2, j -= 2) {\n\t\ttmp = ror32(ctx->enc_expkey[i + 1], 4);\n\t\tctx->enc_expkey[i + 1] = tmp;\n\n\t\tctx->dec_expkey[j + 0] = ctx->enc_expkey[i + 0];\n\t\tctx->dec_expkey[j + 1] = tmp;\n\t}\n\n\treturn 0;\n}\n\nstatic struct crypto_alg des3_ede_algs[4] = { {\n\t.cra_name\t\t= \"des3_ede\",\n\t.cra_driver_name\t= \"des3_ede-asm\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= DES3_EDE_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct des3_ede_x86_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.cipher = {\n\t\t\t.cia_min_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.cia_max_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.cia_setkey\t\t= des3_ede_x86_setkey,\n\t\t\t.cia_encrypt\t\t= des3_ede_x86_encrypt,\n\t\t\t.cia_decrypt\t\t= des3_ede_x86_decrypt,\n\t\t}\n\t}\n}, {\n\t.cra_name\t\t= \"ecb(des3_ede)\",\n\t.cra_driver_name\t= \"ecb-des3_ede-asm\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= DES3_EDE_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct des3_ede_x86_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.max_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.setkey\t\t= des3_ede_x86_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(des3_ede)\",\n\t.cra_driver_name\t= \"cbc-des3_ede-asm\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= DES3_EDE_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct des3_ede_x86_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.max_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.ivsize\t\t= DES3_EDE_BLOCK_SIZE,\n\t\t\t.setkey\t\t= des3_ede_x86_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(des3_ede)\",\n\t.cra_driver_name\t= \"ctr-des3_ede-asm\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct des3_ede_x86_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.max_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.ivsize\t\t= DES3_EDE_BLOCK_SIZE,\n\t\t\t.setkey\t\t= des3_ede_x86_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n} };\n\nstatic bool is_blacklisted_cpu(void)\n{\n\tif (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL)\n\t\treturn false;\n\n\tif (boot_cpu_data.x86 == 0x0f) {\n\t\t/*\n\t\t * On Pentium 4, des3_ede-x86_64 is slower than generic C\n\t\t * implementation because use of 64bit rotates (which are really\n\t\t * slow on P4). Therefore blacklist P4s.\n\t\t */\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic int force;\nmodule_param(force, int, 0);\nMODULE_PARM_DESC(force, \"Force module load, ignore CPU blacklist\");\n\nstatic int __init des3_ede_x86_init(void)\n{\n\tif (!force && is_blacklisted_cpu()) {\n\t\tpr_info(\"des3_ede-x86_64: performance on this CPU would be suboptimal: disabling des3_ede-x86_64.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(des3_ede_algs, ARRAY_SIZE(des3_ede_algs));\n}\n\nstatic void __exit des3_ede_x86_fini(void)\n{\n\tcrypto_unregister_algs(des3_ede_algs, ARRAY_SIZE(des3_ede_algs));\n}\n\nmodule_init(des3_ede_x86_init);\nmodule_exit(des3_ede_x86_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Triple DES EDE Cipher Algorithm, asm optimized\");\nMODULE_ALIAS(\"des3_ede\");\nMODULE_ALIAS(\"des3_ede-asm\");\nMODULE_ALIAS(\"des\");\nMODULE_ALIAS(\"des-asm\");\nMODULE_AUTHOR(\"Jussi Kivilinna <jussi.kivilinna@iki.fi>\");\n", "/*\n * Accelerated GHASH implementation with Intel PCLMULQDQ-NI\n * instructions. This file contains glue code.\n *\n * Copyright (c) 2009 Intel Corp.\n *   Author: Huang Ying <ying.huang@intel.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License version 2 as published\n * by the Free Software Foundation.\n */\n\n#include <linux/err.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/crypto.h>\n#include <crypto/algapi.h>\n#include <crypto/cryptd.h>\n#include <crypto/gf128mul.h>\n#include <crypto/internal/hash.h>\n#include <asm/i387.h>\n#include <asm/cpu_device_id.h>\n\n#define GHASH_BLOCK_SIZE\t16\n#define GHASH_DIGEST_SIZE\t16\n\nvoid clmul_ghash_mul(char *dst, const u128 *shash);\n\nvoid clmul_ghash_update(char *dst, const char *src, unsigned int srclen,\n\t\t\tconst u128 *shash);\n\nstruct ghash_async_ctx {\n\tstruct cryptd_ahash *cryptd_tfm;\n};\n\nstruct ghash_ctx {\n\tu128 shash;\n};\n\nstruct ghash_desc_ctx {\n\tu8 buffer[GHASH_BLOCK_SIZE];\n\tu32 bytes;\n};\n\nstatic int ghash_init(struct shash_desc *desc)\n{\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\n\tmemset(dctx, 0, sizeof(*dctx));\n\n\treturn 0;\n}\n\nstatic int ghash_setkey(struct crypto_shash *tfm,\n\t\t\tconst u8 *key, unsigned int keylen)\n{\n\tstruct ghash_ctx *ctx = crypto_shash_ctx(tfm);\n\tbe128 *x = (be128 *)key;\n\tu64 a, b;\n\n\tif (keylen != GHASH_BLOCK_SIZE) {\n\t\tcrypto_shash_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);\n\t\treturn -EINVAL;\n\t}\n\n\t/* perform multiplication by 'x' in GF(2^128) */\n\ta = be64_to_cpu(x->a);\n\tb = be64_to_cpu(x->b);\n\n\tctx->shash.a = (b << 1) | (a >> 63);\n\tctx->shash.b = (a << 1) | (b >> 63);\n\n\tif (a >> 63)\n\t\tctx->shash.b ^= ((u64)0xc2) << 56;\n\n\treturn 0;\n}\n\nstatic int ghash_update(struct shash_desc *desc,\n\t\t\t const u8 *src, unsigned int srclen)\n{\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\tstruct ghash_ctx *ctx = crypto_shash_ctx(desc->tfm);\n\tu8 *dst = dctx->buffer;\n\n\tkernel_fpu_begin();\n\tif (dctx->bytes) {\n\t\tint n = min(srclen, dctx->bytes);\n\t\tu8 *pos = dst + (GHASH_BLOCK_SIZE - dctx->bytes);\n\n\t\tdctx->bytes -= n;\n\t\tsrclen -= n;\n\n\t\twhile (n--)\n\t\t\t*pos++ ^= *src++;\n\n\t\tif (!dctx->bytes)\n\t\t\tclmul_ghash_mul(dst, &ctx->shash);\n\t}\n\n\tclmul_ghash_update(dst, src, srclen, &ctx->shash);\n\tkernel_fpu_end();\n\n\tif (srclen & 0xf) {\n\t\tsrc += srclen - (srclen & 0xf);\n\t\tsrclen &= 0xf;\n\t\tdctx->bytes = GHASH_BLOCK_SIZE - srclen;\n\t\twhile (srclen--)\n\t\t\t*dst++ ^= *src++;\n\t}\n\n\treturn 0;\n}\n\nstatic void ghash_flush(struct ghash_ctx *ctx, struct ghash_desc_ctx *dctx)\n{\n\tu8 *dst = dctx->buffer;\n\n\tif (dctx->bytes) {\n\t\tu8 *tmp = dst + (GHASH_BLOCK_SIZE - dctx->bytes);\n\n\t\twhile (dctx->bytes--)\n\t\t\t*tmp++ ^= 0;\n\n\t\tkernel_fpu_begin();\n\t\tclmul_ghash_mul(dst, &ctx->shash);\n\t\tkernel_fpu_end();\n\t}\n\n\tdctx->bytes = 0;\n}\n\nstatic int ghash_final(struct shash_desc *desc, u8 *dst)\n{\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\tstruct ghash_ctx *ctx = crypto_shash_ctx(desc->tfm);\n\tu8 *buf = dctx->buffer;\n\n\tghash_flush(ctx, dctx);\n\tmemcpy(dst, buf, GHASH_BLOCK_SIZE);\n\n\treturn 0;\n}\n\nstatic struct shash_alg ghash_alg = {\n\t.digestsize\t= GHASH_DIGEST_SIZE,\n\t.init\t\t= ghash_init,\n\t.update\t\t= ghash_update,\n\t.final\t\t= ghash_final,\n\t.setkey\t\t= ghash_setkey,\n\t.descsize\t= sizeof(struct ghash_desc_ctx),\n\t.base\t\t= {\n\t\t.cra_name\t\t= \"__ghash\",\n\t\t.cra_driver_name\t= \"__ghash-pclmulqdqni\",\n\t\t.cra_priority\t\t= 0,\n\t\t.cra_flags\t\t= CRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t\t= GHASH_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t= sizeof(struct ghash_ctx),\n\t\t.cra_module\t\t= THIS_MODULE,\n\t},\n};\n\nstatic int ghash_async_init(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct ghash_async_ctx *ctx = crypto_ahash_ctx(tfm);\n\tstruct ahash_request *cryptd_req = ahash_request_ctx(req);\n\tstruct cryptd_ahash *cryptd_tfm = ctx->cryptd_tfm;\n\n\tif (!irq_fpu_usable()) {\n\t\tmemcpy(cryptd_req, req, sizeof(*req));\n\t\tahash_request_set_tfm(cryptd_req, &cryptd_tfm->base);\n\t\treturn crypto_ahash_init(cryptd_req);\n\t} else {\n\t\tstruct shash_desc *desc = cryptd_shash_desc(cryptd_req);\n\t\tstruct crypto_shash *child = cryptd_ahash_child(cryptd_tfm);\n\n\t\tdesc->tfm = child;\n\t\tdesc->flags = req->base.flags;\n\t\treturn crypto_shash_init(desc);\n\t}\n}\n\nstatic int ghash_async_update(struct ahash_request *req)\n{\n\tstruct ahash_request *cryptd_req = ahash_request_ctx(req);\n\n\tif (!irq_fpu_usable()) {\n\t\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\t\tstruct ghash_async_ctx *ctx = crypto_ahash_ctx(tfm);\n\t\tstruct cryptd_ahash *cryptd_tfm = ctx->cryptd_tfm;\n\n\t\tmemcpy(cryptd_req, req, sizeof(*req));\n\t\tahash_request_set_tfm(cryptd_req, &cryptd_tfm->base);\n\t\treturn crypto_ahash_update(cryptd_req);\n\t} else {\n\t\tstruct shash_desc *desc = cryptd_shash_desc(cryptd_req);\n\t\treturn shash_ahash_update(req, desc);\n\t}\n}\n\nstatic int ghash_async_final(struct ahash_request *req)\n{\n\tstruct ahash_request *cryptd_req = ahash_request_ctx(req);\n\n\tif (!irq_fpu_usable()) {\n\t\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\t\tstruct ghash_async_ctx *ctx = crypto_ahash_ctx(tfm);\n\t\tstruct cryptd_ahash *cryptd_tfm = ctx->cryptd_tfm;\n\n\t\tmemcpy(cryptd_req, req, sizeof(*req));\n\t\tahash_request_set_tfm(cryptd_req, &cryptd_tfm->base);\n\t\treturn crypto_ahash_final(cryptd_req);\n\t} else {\n\t\tstruct shash_desc *desc = cryptd_shash_desc(cryptd_req);\n\t\treturn crypto_shash_final(desc, req->result);\n\t}\n}\n\nstatic int ghash_async_digest(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct ghash_async_ctx *ctx = crypto_ahash_ctx(tfm);\n\tstruct ahash_request *cryptd_req = ahash_request_ctx(req);\n\tstruct cryptd_ahash *cryptd_tfm = ctx->cryptd_tfm;\n\n\tif (!irq_fpu_usable()) {\n\t\tmemcpy(cryptd_req, req, sizeof(*req));\n\t\tahash_request_set_tfm(cryptd_req, &cryptd_tfm->base);\n\t\treturn crypto_ahash_digest(cryptd_req);\n\t} else {\n\t\tstruct shash_desc *desc = cryptd_shash_desc(cryptd_req);\n\t\tstruct crypto_shash *child = cryptd_ahash_child(cryptd_tfm);\n\n\t\tdesc->tfm = child;\n\t\tdesc->flags = req->base.flags;\n\t\treturn shash_ahash_digest(req, desc);\n\t}\n}\n\nstatic int ghash_async_setkey(struct crypto_ahash *tfm, const u8 *key,\n\t\t\t      unsigned int keylen)\n{\n\tstruct ghash_async_ctx *ctx = crypto_ahash_ctx(tfm);\n\tstruct crypto_ahash *child = &ctx->cryptd_tfm->base;\n\tint err;\n\n\tcrypto_ahash_clear_flags(child, CRYPTO_TFM_REQ_MASK);\n\tcrypto_ahash_set_flags(child, crypto_ahash_get_flags(tfm)\n\t\t\t       & CRYPTO_TFM_REQ_MASK);\n\terr = crypto_ahash_setkey(child, key, keylen);\n\tcrypto_ahash_set_flags(tfm, crypto_ahash_get_flags(child)\n\t\t\t       & CRYPTO_TFM_RES_MASK);\n\n\treturn err;\n}\n\nstatic int ghash_async_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct cryptd_ahash *cryptd_tfm;\n\tstruct ghash_async_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcryptd_tfm = cryptd_alloc_ahash(\"__ghash-pclmulqdqni\", 0, 0);\n\tif (IS_ERR(cryptd_tfm))\n\t\treturn PTR_ERR(cryptd_tfm);\n\tctx->cryptd_tfm = cryptd_tfm;\n\tcrypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),\n\t\t\t\t sizeof(struct ahash_request) +\n\t\t\t\t crypto_ahash_reqsize(&cryptd_tfm->base));\n\n\treturn 0;\n}\n\nstatic void ghash_async_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct ghash_async_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcryptd_free_ahash(ctx->cryptd_tfm);\n}\n\nstatic struct ahash_alg ghash_async_alg = {\n\t.init\t\t= ghash_async_init,\n\t.update\t\t= ghash_async_update,\n\t.final\t\t= ghash_async_final,\n\t.setkey\t\t= ghash_async_setkey,\n\t.digest\t\t= ghash_async_digest,\n\t.halg = {\n\t\t.digestsize\t= GHASH_DIGEST_SIZE,\n\t\t.base = {\n\t\t\t.cra_name\t\t= \"ghash\",\n\t\t\t.cra_driver_name\t= \"ghash-clmulni\",\n\t\t\t.cra_priority\t\t= 400,\n\t\t\t.cra_flags\t\t= CRYPTO_ALG_TYPE_AHASH | CRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize\t\t= GHASH_BLOCK_SIZE,\n\t\t\t.cra_type\t\t= &crypto_ahash_type,\n\t\t\t.cra_module\t\t= THIS_MODULE,\n\t\t\t.cra_init\t\t= ghash_async_init_tfm,\n\t\t\t.cra_exit\t\t= ghash_async_exit_tfm,\n\t\t},\n\t},\n};\n\nstatic const struct x86_cpu_id pcmul_cpu_id[] = {\n\tX86_FEATURE_MATCH(X86_FEATURE_PCLMULQDQ), /* Pickle-Mickle-Duck */\n\t{}\n};\nMODULE_DEVICE_TABLE(x86cpu, pcmul_cpu_id);\n\nstatic int __init ghash_pclmulqdqni_mod_init(void)\n{\n\tint err;\n\n\tif (!x86_match_cpu(pcmul_cpu_id))\n\t\treturn -ENODEV;\n\n\terr = crypto_register_shash(&ghash_alg);\n\tif (err)\n\t\tgoto err_out;\n\terr = crypto_register_ahash(&ghash_async_alg);\n\tif (err)\n\t\tgoto err_shash;\n\n\treturn 0;\n\nerr_shash:\n\tcrypto_unregister_shash(&ghash_alg);\nerr_out:\n\treturn err;\n}\n\nstatic void __exit ghash_pclmulqdqni_mod_exit(void)\n{\n\tcrypto_unregister_ahash(&ghash_async_alg);\n\tcrypto_unregister_shash(&ghash_alg);\n}\n\nmodule_init(ghash_pclmulqdqni_mod_init);\nmodule_exit(ghash_pclmulqdqni_mod_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"GHASH Message Digest Algorithm, \"\n\t\t   \"acclerated by PCLMULQDQ-NI\");\nMODULE_ALIAS(\"ghash\");\n", "/*\n * Glue code for optimized assembly version of  Salsa20.\n *\n * Copyright (c) 2007 Tan Swee Heng <thesweeheng@gmail.com>\n *\n * The assembly codes are public domain assembly codes written by Daniel. J.\n * Bernstein <djb@cr.yp.to>. The codes are modified to include indentation\n * and to remove extraneous comments and functions that are not needed.\n * - i586 version, renamed as salsa20-i586-asm_32.S\n *   available from <http://cr.yp.to/snuffle/salsa20/x86-pm/salsa20.s>\n * - x86-64 version, renamed as salsa20-x86_64-asm_64.S\n *   available from <http://cr.yp.to/snuffle/salsa20/amd64-3/salsa20.s>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#include <crypto/algapi.h>\n#include <linux/module.h>\n#include <linux/crypto.h>\n\n#define SALSA20_IV_SIZE        8U\n#define SALSA20_MIN_KEY_SIZE  16U\n#define SALSA20_MAX_KEY_SIZE  32U\n\nstruct salsa20_ctx\n{\n\tu32 input[16];\n};\n\nasmlinkage void salsa20_keysetup(struct salsa20_ctx *ctx, const u8 *k,\n\t\t\t\t u32 keysize, u32 ivsize);\nasmlinkage void salsa20_ivsetup(struct salsa20_ctx *ctx, const u8 *iv);\nasmlinkage void salsa20_encrypt_bytes(struct salsa20_ctx *ctx,\n\t\t\t\t      const u8 *src, u8 *dst, u32 bytes);\n\nstatic int setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t  unsigned int keysize)\n{\n\tstruct salsa20_ctx *ctx = crypto_tfm_ctx(tfm);\n\tsalsa20_keysetup(ctx, key, keysize*8, SALSA20_IV_SIZE*8);\n\treturn 0;\n}\n\nstatic int encrypt(struct blkcipher_desc *desc,\n\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t   unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\tstruct crypto_blkcipher *tfm = desc->tfm;\n\tstruct salsa20_ctx *ctx = crypto_blkcipher_ctx(tfm);\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt_block(desc, &walk, 64);\n\n\tsalsa20_ivsetup(ctx, walk.iv);\n\n\tif (likely(walk.nbytes == nbytes))\n\t{\n\t\tsalsa20_encrypt_bytes(ctx, walk.src.virt.addr,\n\t\t\t\t      walk.dst.virt.addr, nbytes);\n\t\treturn blkcipher_walk_done(desc, &walk, 0);\n\t}\n\n\twhile (walk.nbytes >= 64) {\n\t\tsalsa20_encrypt_bytes(ctx, walk.src.virt.addr,\n\t\t\t\t      walk.dst.virt.addr,\n\t\t\t\t      walk.nbytes - (walk.nbytes % 64));\n\t\terr = blkcipher_walk_done(desc, &walk, walk.nbytes % 64);\n\t}\n\n\tif (walk.nbytes) {\n\t\tsalsa20_encrypt_bytes(ctx, walk.src.virt.addr,\n\t\t\t\t      walk.dst.virt.addr, walk.nbytes);\n\t\terr = blkcipher_walk_done(desc, &walk, 0);\n\t}\n\n\treturn err;\n}\n\nstatic struct crypto_alg alg = {\n\t.cra_name           =   \"salsa20\",\n\t.cra_driver_name    =   \"salsa20-asm\",\n\t.cra_priority       =   200,\n\t.cra_flags          =   CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_type           =   &crypto_blkcipher_type,\n\t.cra_blocksize      =   1,\n\t.cra_ctxsize        =   sizeof(struct salsa20_ctx),\n\t.cra_alignmask      =\t3,\n\t.cra_module         =   THIS_MODULE,\n\t.cra_u              =   {\n\t\t.blkcipher = {\n\t\t\t.setkey         =   setkey,\n\t\t\t.encrypt        =   encrypt,\n\t\t\t.decrypt        =   encrypt,\n\t\t\t.min_keysize    =   SALSA20_MIN_KEY_SIZE,\n\t\t\t.max_keysize    =   SALSA20_MAX_KEY_SIZE,\n\t\t\t.ivsize         =   SALSA20_IV_SIZE,\n\t\t}\n\t}\n};\n\nstatic int __init init(void)\n{\n\treturn crypto_register_alg(&alg);\n}\n\nstatic void __exit fini(void)\n{\n\tcrypto_unregister_alg(&alg);\n}\n\nmodule_init(init);\nmodule_exit(fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION (\"Salsa20 stream cipher algorithm (optimized assembly version)\");\nMODULE_ALIAS(\"salsa20\");\nMODULE_ALIAS(\"salsa20-asm\");\n", "/*\n * Glue Code for x86_64/AVX2 assembler optimized version of Serpent\n *\n * Copyright \u00a9 2012-2013 Jussi Kivilinna <jussi.kivilinna@mbnet.fi>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n\n#include <linux/module.h>\n#include <linux/types.h>\n#include <linux/crypto.h>\n#include <linux/err.h>\n#include <crypto/ablk_helper.h>\n#include <crypto/algapi.h>\n#include <crypto/ctr.h>\n#include <crypto/lrw.h>\n#include <crypto/xts.h>\n#include <crypto/serpent.h>\n#include <asm/xcr.h>\n#include <asm/xsave.h>\n#include <asm/crypto/serpent-avx.h>\n#include <asm/crypto/glue_helper.h>\n\n#define SERPENT_AVX2_PARALLEL_BLOCKS 16\n\n/* 16-way AVX2 parallel cipher functions */\nasmlinkage void serpent_ecb_enc_16way(struct serpent_ctx *ctx, u8 *dst,\n\t\t\t\t      const u8 *src);\nasmlinkage void serpent_ecb_dec_16way(struct serpent_ctx *ctx, u8 *dst,\n\t\t\t\t      const u8 *src);\nasmlinkage void serpent_cbc_dec_16way(void *ctx, u128 *dst, const u128 *src);\n\nasmlinkage void serpent_ctr_16way(void *ctx, u128 *dst, const u128 *src,\n\t\t\t\t  le128 *iv);\nasmlinkage void serpent_xts_enc_16way(struct serpent_ctx *ctx, u8 *dst,\n\t\t\t\t      const u8 *src, le128 *iv);\nasmlinkage void serpent_xts_dec_16way(struct serpent_ctx *ctx, u8 *dst,\n\t\t\t\t      const u8 *src, le128 *iv);\n\nstatic const struct common_glue_ctx serpent_enc = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = 8,\n\n\t.funcs = { {\n\t\t.num_blocks = 16,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(serpent_ecb_enc_16way) }\n\t}, {\n\t\t.num_blocks = 8,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(serpent_ecb_enc_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(__serpent_encrypt) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_ctr = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = 8,\n\n\t.funcs = { {\n\t\t.num_blocks = 16,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(serpent_ctr_16way) }\n\t},  {\n\t\t.num_blocks = 8,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(serpent_ctr_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(__serpent_crypt_ctr) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_enc_xts = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = 8,\n\n\t.funcs = { {\n\t\t.num_blocks = 16,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(serpent_xts_enc_16way) }\n\t}, {\n\t\t.num_blocks = 8,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(serpent_xts_enc_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(serpent_xts_enc) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_dec = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = 8,\n\n\t.funcs = { {\n\t\t.num_blocks = 16,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(serpent_ecb_dec_16way) }\n\t}, {\n\t\t.num_blocks = 8,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(serpent_ecb_dec_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(__serpent_decrypt) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_dec_cbc = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = 8,\n\n\t.funcs = { {\n\t\t.num_blocks = 16,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(serpent_cbc_dec_16way) }\n\t}, {\n\t\t.num_blocks = 8,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(serpent_cbc_dec_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(__serpent_decrypt) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_dec_xts = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = 8,\n\n\t.funcs = { {\n\t\t.num_blocks = 16,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(serpent_xts_dec_16way) }\n\t}, {\n\t\t.num_blocks = 8,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(serpent_xts_dec_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(serpent_xts_dec) }\n\t} }\n};\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&serpent_enc, desc, dst, src, nbytes);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&serpent_dec, desc, dst, src, nbytes);\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_encrypt_128bit(GLUE_FUNC_CAST(__serpent_encrypt), desc,\n\t\t\t\t       dst, src, nbytes);\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_decrypt_128bit(&serpent_dec_cbc, desc, dst, src,\n\t\t\t\t       nbytes);\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ctr_crypt_128bit(&serpent_ctr, desc, dst, src, nbytes);\n}\n\nstatic inline bool serpent_fpu_begin(bool fpu_enabled, unsigned int nbytes)\n{\n\t/* since reusing AVX functions, starts using FPU at 8 parallel blocks */\n\treturn glue_fpu_begin(SERPENT_BLOCK_SIZE, 8, NULL, fpu_enabled, nbytes);\n}\n\nstatic inline void serpent_fpu_end(bool fpu_enabled)\n{\n\tglue_fpu_end(fpu_enabled);\n}\n\nstruct crypt_priv {\n\tstruct serpent_ctx *ctx;\n\tbool fpu_enabled;\n};\n\nstatic void encrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = SERPENT_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = serpent_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes >= SERPENT_AVX2_PARALLEL_BLOCKS * bsize) {\n\t\tserpent_ecb_enc_16way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * SERPENT_AVX2_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * SERPENT_AVX2_PARALLEL_BLOCKS;\n\t}\n\n\twhile (nbytes >= SERPENT_PARALLEL_BLOCKS * bsize) {\n\t\tserpent_ecb_enc_8way_avx(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * SERPENT_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * SERPENT_PARALLEL_BLOCKS;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\t__serpent_encrypt(ctx->ctx, srcdst, srcdst);\n}\n\nstatic void decrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = SERPENT_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = serpent_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes >= SERPENT_AVX2_PARALLEL_BLOCKS * bsize) {\n\t\tserpent_ecb_dec_16way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * SERPENT_AVX2_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * SERPENT_AVX2_PARALLEL_BLOCKS;\n\t}\n\n\twhile (nbytes >= SERPENT_PARALLEL_BLOCKS * bsize) {\n\t\tserpent_ecb_dec_8way_avx(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * SERPENT_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * SERPENT_PARALLEL_BLOCKS;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\t__serpent_decrypt(ctx->ctx, srcdst, srcdst);\n}\n\nstatic int lrw_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[SERPENT_AVX2_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->serpent_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tserpent_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int lrw_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[SERPENT_AVX2_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->serpent_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tserpent_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&serpent_enc_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(__serpent_encrypt),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&serpent_dec_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(__serpent_encrypt),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic struct crypto_alg srp_algs[10] = { {\n\t.cra_name\t\t= \"__ecb-serpent-avx2\",\n\t.cra_driver_name\t= \"__driver-ecb-serpent-avx2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(srp_algs[0].cra_list),\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= serpent_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__cbc-serpent-avx2\",\n\t.cra_driver_name\t= \"__driver-cbc-serpent-avx2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(srp_algs[1].cra_list),\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= serpent_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__ctr-serpent-avx2\",\n\t.cra_driver_name\t= \"__driver-ctr-serpent-avx2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(srp_algs[2].cra_list),\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= serpent_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__lrw-serpent-avx2\",\n\t.cra_driver_name\t= \"__driver-lrw-serpent-avx2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_lrw_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(srp_algs[3].cra_list),\n\t.cra_exit\t\t= lrw_serpent_exit_tfm,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= lrw_serpent_setkey,\n\t\t\t.encrypt\t= lrw_encrypt,\n\t\t\t.decrypt\t= lrw_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__xts-serpent-avx2\",\n\t.cra_driver_name\t= \"__driver-xts-serpent-avx2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_xts_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(srp_algs[4].cra_list),\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= xts_serpent_setkey,\n\t\t\t.encrypt\t= xts_encrypt,\n\t\t\t.decrypt\t= xts_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ecb(serpent)\",\n\t.cra_driver_name\t= \"ecb-serpent-avx2\",\n\t.cra_priority\t\t= 600,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(srp_algs[5].cra_list),\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(serpent)\",\n\t.cra_driver_name\t= \"cbc-serpent-avx2\",\n\t.cra_priority\t\t= 600,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(srp_algs[6].cra_list),\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= __ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(serpent)\",\n\t.cra_driver_name\t= \"ctr-serpent-avx2\",\n\t.cra_priority\t\t= 600,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(srp_algs[7].cra_list),\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_encrypt,\n\t\t\t.geniv\t\t= \"chainiv\",\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"lrw(serpent)\",\n\t.cra_driver_name\t= \"lrw-serpent-avx2\",\n\t.cra_priority\t\t= 600,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(srp_algs[8].cra_list),\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"xts(serpent)\",\n\t.cra_driver_name\t= \"xts-serpent-avx2\",\n\t.cra_priority\t\t= 600,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(srp_algs[9].cra_list),\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n} };\n\nstatic int __init init(void)\n{\n\tu64 xcr0;\n\n\tif (!cpu_has_avx2 || !cpu_has_osxsave) {\n\t\tpr_info(\"AVX2 instructions are not detected.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\txcr0 = xgetbv(XCR_XFEATURE_ENABLED_MASK);\n\tif ((xcr0 & (XSTATE_SSE | XSTATE_YMM)) != (XSTATE_SSE | XSTATE_YMM)) {\n\t\tpr_info(\"AVX detected but unusable.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(srp_algs, ARRAY_SIZE(srp_algs));\n}\n\nstatic void __exit fini(void)\n{\n\tcrypto_unregister_algs(srp_algs, ARRAY_SIZE(srp_algs));\n}\n\nmodule_init(init);\nmodule_exit(fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Serpent Cipher Algorithm, AVX2 optimized\");\nMODULE_ALIAS(\"serpent\");\nMODULE_ALIAS(\"serpent-asm\");\n", "/*\n * Glue Code for AVX assembler versions of Serpent Cipher\n *\n * Copyright (C) 2012 Johannes Goetzfried\n *     <Johannes.Goetzfried@informatik.stud.uni-erlangen.de>\n *\n * Copyright \u00a9 2011-2013 Jussi Kivilinna <jussi.kivilinna@iki.fi>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307\n * USA\n *\n */\n\n#include <linux/module.h>\n#include <linux/hardirq.h>\n#include <linux/types.h>\n#include <linux/crypto.h>\n#include <linux/err.h>\n#include <crypto/ablk_helper.h>\n#include <crypto/algapi.h>\n#include <crypto/serpent.h>\n#include <crypto/cryptd.h>\n#include <crypto/b128ops.h>\n#include <crypto/ctr.h>\n#include <crypto/lrw.h>\n#include <crypto/xts.h>\n#include <asm/xcr.h>\n#include <asm/xsave.h>\n#include <asm/crypto/serpent-avx.h>\n#include <asm/crypto/glue_helper.h>\n\n/* 8-way parallel cipher functions */\nasmlinkage void serpent_ecb_enc_8way_avx(struct serpent_ctx *ctx, u8 *dst,\n\t\t\t\t\t const u8 *src);\nEXPORT_SYMBOL_GPL(serpent_ecb_enc_8way_avx);\n\nasmlinkage void serpent_ecb_dec_8way_avx(struct serpent_ctx *ctx, u8 *dst,\n\t\t\t\t\t const u8 *src);\nEXPORT_SYMBOL_GPL(serpent_ecb_dec_8way_avx);\n\nasmlinkage void serpent_cbc_dec_8way_avx(struct serpent_ctx *ctx, u8 *dst,\n\t\t\t\t\t const u8 *src);\nEXPORT_SYMBOL_GPL(serpent_cbc_dec_8way_avx);\n\nasmlinkage void serpent_ctr_8way_avx(struct serpent_ctx *ctx, u8 *dst,\n\t\t\t\t     const u8 *src, le128 *iv);\nEXPORT_SYMBOL_GPL(serpent_ctr_8way_avx);\n\nasmlinkage void serpent_xts_enc_8way_avx(struct serpent_ctx *ctx, u8 *dst,\n\t\t\t\t\t const u8 *src, le128 *iv);\nEXPORT_SYMBOL_GPL(serpent_xts_enc_8way_avx);\n\nasmlinkage void serpent_xts_dec_8way_avx(struct serpent_ctx *ctx, u8 *dst,\n\t\t\t\t\t const u8 *src, le128 *iv);\nEXPORT_SYMBOL_GPL(serpent_xts_dec_8way_avx);\n\nvoid __serpent_crypt_ctr(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tbe128 ctrblk;\n\n\tle128_to_be128(&ctrblk, iv);\n\tle128_inc(iv);\n\n\t__serpent_encrypt(ctx, (u8 *)&ctrblk, (u8 *)&ctrblk);\n\tu128_xor(dst, src, (u128 *)&ctrblk);\n}\nEXPORT_SYMBOL_GPL(__serpent_crypt_ctr);\n\nvoid serpent_xts_enc(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tglue_xts_crypt_128bit_one(ctx, dst, src, iv,\n\t\t\t\t  GLUE_FUNC_CAST(__serpent_encrypt));\n}\nEXPORT_SYMBOL_GPL(serpent_xts_enc);\n\nvoid serpent_xts_dec(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tglue_xts_crypt_128bit_one(ctx, dst, src, iv,\n\t\t\t\t  GLUE_FUNC_CAST(__serpent_decrypt));\n}\nEXPORT_SYMBOL_GPL(serpent_xts_dec);\n\n\nstatic const struct common_glue_ctx serpent_enc = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = SERPENT_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = SERPENT_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(serpent_ecb_enc_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(__serpent_encrypt) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_ctr = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = SERPENT_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = SERPENT_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(serpent_ctr_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(__serpent_crypt_ctr) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_enc_xts = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = SERPENT_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = SERPENT_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(serpent_xts_enc_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(serpent_xts_enc) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_dec = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = SERPENT_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = SERPENT_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(serpent_ecb_dec_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(__serpent_decrypt) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_dec_cbc = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = SERPENT_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = SERPENT_PARALLEL_BLOCKS,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(serpent_cbc_dec_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(__serpent_decrypt) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_dec_xts = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = SERPENT_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = SERPENT_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(serpent_xts_dec_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(serpent_xts_dec) }\n\t} }\n};\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&serpent_enc, desc, dst, src, nbytes);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&serpent_dec, desc, dst, src, nbytes);\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_encrypt_128bit(GLUE_FUNC_CAST(__serpent_encrypt), desc,\n\t\t\t\t     dst, src, nbytes);\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_decrypt_128bit(&serpent_dec_cbc, desc, dst, src,\n\t\t\t\t       nbytes);\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ctr_crypt_128bit(&serpent_ctr, desc, dst, src, nbytes);\n}\n\nstatic inline bool serpent_fpu_begin(bool fpu_enabled, unsigned int nbytes)\n{\n\treturn glue_fpu_begin(SERPENT_BLOCK_SIZE, SERPENT_PARALLEL_BLOCKS,\n\t\t\t      NULL, fpu_enabled, nbytes);\n}\n\nstatic inline void serpent_fpu_end(bool fpu_enabled)\n{\n\tglue_fpu_end(fpu_enabled);\n}\n\nstruct crypt_priv {\n\tstruct serpent_ctx *ctx;\n\tbool fpu_enabled;\n};\n\nstatic void encrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = SERPENT_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = serpent_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes == bsize * SERPENT_PARALLEL_BLOCKS) {\n\t\tserpent_ecb_enc_8way_avx(ctx->ctx, srcdst, srcdst);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\t__serpent_encrypt(ctx->ctx, srcdst, srcdst);\n}\n\nstatic void decrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = SERPENT_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = serpent_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes == bsize * SERPENT_PARALLEL_BLOCKS) {\n\t\tserpent_ecb_dec_8way_avx(ctx->ctx, srcdst, srcdst);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\t__serpent_decrypt(ctx->ctx, srcdst, srcdst);\n}\n\nint lrw_serpent_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t       unsigned int keylen)\n{\n\tstruct serpent_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\tint err;\n\n\terr = __serpent_setkey(&ctx->serpent_ctx, key, keylen -\n\t\t\t\t\t\t\tSERPENT_BLOCK_SIZE);\n\tif (err)\n\t\treturn err;\n\n\treturn lrw_init_table(&ctx->lrw_table, key + keylen -\n\t\t\t\t\t\tSERPENT_BLOCK_SIZE);\n}\nEXPORT_SYMBOL_GPL(lrw_serpent_setkey);\n\nstatic int lrw_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[SERPENT_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->serpent_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tserpent_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int lrw_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[SERPENT_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->serpent_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tserpent_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nvoid lrw_serpent_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct serpent_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tlrw_free_table(&ctx->lrw_table);\n}\nEXPORT_SYMBOL_GPL(lrw_serpent_exit_tfm);\n\nint xts_serpent_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t       unsigned int keylen)\n{\n\tstruct serpent_xts_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tint err;\n\n\t/* key consists of keys of equal size concatenated, therefore\n\t * the length must be even\n\t */\n\tif (keylen % 2) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\t/* first half of xts-key is for crypt */\n\terr = __serpent_setkey(&ctx->crypt_ctx, key, keylen / 2);\n\tif (err)\n\t\treturn err;\n\n\t/* second half of xts-key is for tweak */\n\treturn __serpent_setkey(&ctx->tweak_ctx, key + keylen / 2, keylen / 2);\n}\nEXPORT_SYMBOL_GPL(xts_serpent_setkey);\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&serpent_enc_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(__serpent_encrypt),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&serpent_dec_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(__serpent_encrypt),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic struct crypto_alg serpent_algs[10] = { {\n\t.cra_name\t\t= \"__ecb-serpent-avx\",\n\t.cra_driver_name\t= \"__driver-ecb-serpent-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= serpent_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__cbc-serpent-avx\",\n\t.cra_driver_name\t= \"__driver-cbc-serpent-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= serpent_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__ctr-serpent-avx\",\n\t.cra_driver_name\t= \"__driver-ctr-serpent-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= serpent_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__lrw-serpent-avx\",\n\t.cra_driver_name\t= \"__driver-lrw-serpent-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_lrw_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_exit\t\t= lrw_serpent_exit_tfm,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= lrw_serpent_setkey,\n\t\t\t.encrypt\t= lrw_encrypt,\n\t\t\t.decrypt\t= lrw_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__xts-serpent-avx\",\n\t.cra_driver_name\t= \"__driver-xts-serpent-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_xts_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= xts_serpent_setkey,\n\t\t\t.encrypt\t= xts_encrypt,\n\t\t\t.decrypt\t= xts_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ecb(serpent)\",\n\t.cra_driver_name\t= \"ecb-serpent-avx\",\n\t.cra_priority\t\t= 500,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(serpent)\",\n\t.cra_driver_name\t= \"cbc-serpent-avx\",\n\t.cra_priority\t\t= 500,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= __ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(serpent)\",\n\t.cra_driver_name\t= \"ctr-serpent-avx\",\n\t.cra_priority\t\t= 500,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_encrypt,\n\t\t\t.geniv\t\t= \"chainiv\",\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"lrw(serpent)\",\n\t.cra_driver_name\t= \"lrw-serpent-avx\",\n\t.cra_priority\t\t= 500,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"xts(serpent)\",\n\t.cra_driver_name\t= \"xts-serpent-avx\",\n\t.cra_priority\t\t= 500,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n} };\n\nstatic int __init serpent_init(void)\n{\n\tu64 xcr0;\n\n\tif (!cpu_has_avx || !cpu_has_osxsave) {\n\t\tprintk(KERN_INFO \"AVX instructions are not detected.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\txcr0 = xgetbv(XCR_XFEATURE_ENABLED_MASK);\n\tif ((xcr0 & (XSTATE_SSE | XSTATE_YMM)) != (XSTATE_SSE | XSTATE_YMM)) {\n\t\tprintk(KERN_INFO \"AVX detected but unusable.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(serpent_algs, ARRAY_SIZE(serpent_algs));\n}\n\nstatic void __exit serpent_exit(void)\n{\n\tcrypto_unregister_algs(serpent_algs, ARRAY_SIZE(serpent_algs));\n}\n\nmodule_init(serpent_init);\nmodule_exit(serpent_exit);\n\nMODULE_DESCRIPTION(\"Serpent Cipher Algorithm, AVX optimized\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS(\"serpent\");\n", "/*\n * Glue Code for SSE2 assembler versions of Serpent Cipher\n *\n * Copyright (c) 2011 Jussi Kivilinna <jussi.kivilinna@mbnet.fi>\n *\n * Glue code based on aesni-intel_glue.c by:\n *  Copyright (C) 2008, Intel Corp.\n *    Author: Huang Ying <ying.huang@intel.com>\n *\n * CBC & ECB parts based on code (crypto/cbc.c,ecb.c) by:\n *   Copyright (c) 2006 Herbert Xu <herbert@gondor.apana.org.au>\n * CTR part based on code (crypto/ctr.c) by:\n *   (C) Copyright IBM Corp. 2007 - Joy Latten <latten@us.ibm.com>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307\n * USA\n *\n */\n\n#include <linux/module.h>\n#include <linux/hardirq.h>\n#include <linux/types.h>\n#include <linux/crypto.h>\n#include <linux/err.h>\n#include <crypto/ablk_helper.h>\n#include <crypto/algapi.h>\n#include <crypto/serpent.h>\n#include <crypto/cryptd.h>\n#include <crypto/b128ops.h>\n#include <crypto/ctr.h>\n#include <crypto/lrw.h>\n#include <crypto/xts.h>\n#include <asm/crypto/serpent-sse2.h>\n#include <asm/crypto/glue_helper.h>\n\nstatic void serpent_decrypt_cbc_xway(void *ctx, u128 *dst, const u128 *src)\n{\n\tu128 ivs[SERPENT_PARALLEL_BLOCKS - 1];\n\tunsigned int j;\n\n\tfor (j = 0; j < SERPENT_PARALLEL_BLOCKS - 1; j++)\n\t\tivs[j] = src[j];\n\n\tserpent_dec_blk_xway(ctx, (u8 *)dst, (u8 *)src);\n\n\tfor (j = 0; j < SERPENT_PARALLEL_BLOCKS - 1; j++)\n\t\tu128_xor(dst + (j + 1), dst + (j + 1), ivs + j);\n}\n\nstatic void serpent_crypt_ctr(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tbe128 ctrblk;\n\n\tle128_to_be128(&ctrblk, iv);\n\tle128_inc(iv);\n\n\t__serpent_encrypt(ctx, (u8 *)&ctrblk, (u8 *)&ctrblk);\n\tu128_xor(dst, src, (u128 *)&ctrblk);\n}\n\nstatic void serpent_crypt_ctr_xway(void *ctx, u128 *dst, const u128 *src,\n\t\t\t\t   le128 *iv)\n{\n\tbe128 ctrblks[SERPENT_PARALLEL_BLOCKS];\n\tunsigned int i;\n\n\tfor (i = 0; i < SERPENT_PARALLEL_BLOCKS; i++) {\n\t\tif (dst != src)\n\t\t\tdst[i] = src[i];\n\n\t\tle128_to_be128(&ctrblks[i], iv);\n\t\tle128_inc(iv);\n\t}\n\n\tserpent_enc_blk_xway_xor(ctx, (u8 *)dst, (u8 *)ctrblks);\n}\n\nstatic const struct common_glue_ctx serpent_enc = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = SERPENT_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = SERPENT_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(serpent_enc_blk_xway) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(__serpent_encrypt) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_ctr = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = SERPENT_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = SERPENT_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(serpent_crypt_ctr_xway) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(serpent_crypt_ctr) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_dec = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = SERPENT_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = SERPENT_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(serpent_dec_blk_xway) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(__serpent_decrypt) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_dec_cbc = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = SERPENT_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = SERPENT_PARALLEL_BLOCKS,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(serpent_decrypt_cbc_xway) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(__serpent_decrypt) }\n\t} }\n};\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&serpent_enc, desc, dst, src, nbytes);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&serpent_dec, desc, dst, src, nbytes);\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_encrypt_128bit(GLUE_FUNC_CAST(__serpent_encrypt), desc,\n\t\t\t\t     dst, src, nbytes);\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_decrypt_128bit(&serpent_dec_cbc, desc, dst, src,\n\t\t\t\t       nbytes);\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ctr_crypt_128bit(&serpent_ctr, desc, dst, src, nbytes);\n}\n\nstatic inline bool serpent_fpu_begin(bool fpu_enabled, unsigned int nbytes)\n{\n\treturn glue_fpu_begin(SERPENT_BLOCK_SIZE, SERPENT_PARALLEL_BLOCKS,\n\t\t\t      NULL, fpu_enabled, nbytes);\n}\n\nstatic inline void serpent_fpu_end(bool fpu_enabled)\n{\n\tglue_fpu_end(fpu_enabled);\n}\n\nstruct crypt_priv {\n\tstruct serpent_ctx *ctx;\n\tbool fpu_enabled;\n};\n\nstatic void encrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = SERPENT_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = serpent_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes == bsize * SERPENT_PARALLEL_BLOCKS) {\n\t\tserpent_enc_blk_xway(ctx->ctx, srcdst, srcdst);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\t__serpent_encrypt(ctx->ctx, srcdst, srcdst);\n}\n\nstatic void decrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = SERPENT_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = serpent_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes == bsize * SERPENT_PARALLEL_BLOCKS) {\n\t\tserpent_dec_blk_xway(ctx->ctx, srcdst, srcdst);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\t__serpent_decrypt(ctx->ctx, srcdst, srcdst);\n}\n\nstruct serpent_lrw_ctx {\n\tstruct lrw_table_ctx lrw_table;\n\tstruct serpent_ctx serpent_ctx;\n};\n\nstatic int lrw_serpent_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\t      unsigned int keylen)\n{\n\tstruct serpent_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\tint err;\n\n\terr = __serpent_setkey(&ctx->serpent_ctx, key, keylen -\n\t\t\t\t\t\t\tSERPENT_BLOCK_SIZE);\n\tif (err)\n\t\treturn err;\n\n\treturn lrw_init_table(&ctx->lrw_table, key + keylen -\n\t\t\t\t\t\tSERPENT_BLOCK_SIZE);\n}\n\nstatic int lrw_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[SERPENT_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->serpent_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tserpent_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int lrw_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[SERPENT_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->serpent_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tserpent_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic void lrw_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct serpent_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tlrw_free_table(&ctx->lrw_table);\n}\n\nstruct serpent_xts_ctx {\n\tstruct serpent_ctx tweak_ctx;\n\tstruct serpent_ctx crypt_ctx;\n};\n\nstatic int xts_serpent_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\t      unsigned int keylen)\n{\n\tstruct serpent_xts_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tint err;\n\n\t/* key consists of keys of equal size concatenated, therefore\n\t * the length must be even\n\t */\n\tif (keylen % 2) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\t/* first half of xts-key is for crypt */\n\terr = __serpent_setkey(&ctx->crypt_ctx, key, keylen / 2);\n\tif (err)\n\t\treturn err;\n\n\t/* second half of xts-key is for tweak */\n\treturn __serpent_setkey(&ctx->tweak_ctx, key + keylen / 2, keylen / 2);\n}\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[SERPENT_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->crypt_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct xts_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.tweak_ctx = &ctx->tweak_ctx,\n\t\t.tweak_fn = XTS_TWEAK_CAST(__serpent_encrypt),\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = xts_crypt(desc, dst, src, nbytes, &req);\n\tserpent_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[SERPENT_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->crypt_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct xts_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.tweak_ctx = &ctx->tweak_ctx,\n\t\t.tweak_fn = XTS_TWEAK_CAST(__serpent_encrypt),\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = xts_crypt(desc, dst, src, nbytes, &req);\n\tserpent_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic struct crypto_alg serpent_algs[10] = { {\n\t.cra_name\t\t= \"__ecb-serpent-sse2\",\n\t.cra_driver_name\t= \"__driver-ecb-serpent-sse2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= serpent_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__cbc-serpent-sse2\",\n\t.cra_driver_name\t= \"__driver-cbc-serpent-sse2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= serpent_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__ctr-serpent-sse2\",\n\t.cra_driver_name\t= \"__driver-ctr-serpent-sse2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= serpent_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__lrw-serpent-sse2\",\n\t.cra_driver_name\t= \"__driver-lrw-serpent-sse2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_lrw_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_exit\t\t= lrw_exit_tfm,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= lrw_serpent_setkey,\n\t\t\t.encrypt\t= lrw_encrypt,\n\t\t\t.decrypt\t= lrw_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__xts-serpent-sse2\",\n\t.cra_driver_name\t= \"__driver-xts-serpent-sse2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_xts_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= xts_serpent_setkey,\n\t\t\t.encrypt\t= xts_encrypt,\n\t\t\t.decrypt\t= xts_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ecb(serpent)\",\n\t.cra_driver_name\t= \"ecb-serpent-sse2\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(serpent)\",\n\t.cra_driver_name\t= \"cbc-serpent-sse2\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= __ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(serpent)\",\n\t.cra_driver_name\t= \"ctr-serpent-sse2\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_encrypt,\n\t\t\t.geniv\t\t= \"chainiv\",\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"lrw(serpent)\",\n\t.cra_driver_name\t= \"lrw-serpent-sse2\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"xts(serpent)\",\n\t.cra_driver_name\t= \"xts-serpent-sse2\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n} };\n\nstatic int __init serpent_sse2_init(void)\n{\n\tif (!cpu_has_xmm2) {\n\t\tprintk(KERN_INFO \"SSE2 instructions are not detected.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(serpent_algs, ARRAY_SIZE(serpent_algs));\n}\n\nstatic void __exit serpent_sse2_exit(void)\n{\n\tcrypto_unregister_algs(serpent_algs, ARRAY_SIZE(serpent_algs));\n}\n\nmodule_init(serpent_sse2_init);\nmodule_exit(serpent_sse2_exit);\n\nMODULE_DESCRIPTION(\"Serpent Cipher Algorithm, SSE2 optimized\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS(\"serpent\");\n", "/*\n * Cryptographic API.\n *\n * Glue code for the SHA1 Secure Hash Algorithm assembler implementation using\n * Supplemental SSE3 instructions.\n *\n * This file is based on sha1_generic.c\n *\n * Copyright (c) Alan Smithee.\n * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n * Copyright (c) Jean-Francois Dive <jef@linuxbe.org>\n * Copyright (c) Mathias Krause <minipli@googlemail.com>\n * Copyright (c) Chandramouli Narayanan <mouli@linux.intel.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n#include <asm/byteorder.h>\n#include <asm/i387.h>\n#include <asm/xcr.h>\n#include <asm/xsave.h>\n\n\nasmlinkage void sha1_transform_ssse3(u32 *digest, const char *data,\n\t\t\t\t     unsigned int rounds);\n#ifdef CONFIG_AS_AVX\nasmlinkage void sha1_transform_avx(u32 *digest, const char *data,\n\t\t\t\t   unsigned int rounds);\n#endif\n#ifdef CONFIG_AS_AVX2\n#define SHA1_AVX2_BLOCK_OPTSIZE\t4\t/* optimal 4*64 bytes of SHA1 blocks */\n\nasmlinkage void sha1_transform_avx2(u32 *digest, const char *data,\n\t\t\t\tunsigned int rounds);\n#endif\n\nstatic asmlinkage void (*sha1_transform_asm)(u32 *, const char *, unsigned int);\n\n\nstatic int sha1_ssse3_init(struct shash_desc *desc)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\t*sctx = (struct sha1_state){\n\t\t.state = { SHA1_H0, SHA1_H1, SHA1_H2, SHA1_H3, SHA1_H4 },\n\t};\n\n\treturn 0;\n}\n\nstatic int __sha1_ssse3_update(struct shash_desc *desc, const u8 *data,\n\t\t\t       unsigned int len, unsigned int partial)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int done = 0;\n\n\tsctx->count += len;\n\n\tif (partial) {\n\t\tdone = SHA1_BLOCK_SIZE - partial;\n\t\tmemcpy(sctx->buffer + partial, data, done);\n\t\tsha1_transform_asm(sctx->state, sctx->buffer, 1);\n\t}\n\n\tif (len - done >= SHA1_BLOCK_SIZE) {\n\t\tconst unsigned int rounds = (len - done) / SHA1_BLOCK_SIZE;\n\n\t\tsha1_transform_asm(sctx->state, data + done, rounds);\n\t\tdone += rounds * SHA1_BLOCK_SIZE;\n\t}\n\n\tmemcpy(sctx->buffer, data + done, len - done);\n\n\treturn 0;\n}\n\nstatic int sha1_ssse3_update(struct shash_desc *desc, const u8 *data,\n\t\t\t     unsigned int len)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial = sctx->count % SHA1_BLOCK_SIZE;\n\tint res;\n\n\t/* Handle the fast case right here */\n\tif (partial + len < SHA1_BLOCK_SIZE) {\n\t\tsctx->count += len;\n\t\tmemcpy(sctx->buffer + partial, data, len);\n\n\t\treturn 0;\n\t}\n\n\tif (!irq_fpu_usable()) {\n\t\tres = crypto_sha1_update(desc, data, len);\n\t} else {\n\t\tkernel_fpu_begin();\n\t\tres = __sha1_ssse3_update(desc, data, len, partial);\n\t\tkernel_fpu_end();\n\t}\n\n\treturn res;\n}\n\n\n/* Add padding and return the message digest. */\nstatic int sha1_ssse3_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int i, index, padlen;\n\t__be32 *dst = (__be32 *)out;\n\t__be64 bits;\n\tstatic const u8 padding[SHA1_BLOCK_SIZE] = { 0x80, };\n\n\tbits = cpu_to_be64(sctx->count << 3);\n\n\t/* Pad out to 56 mod 64 and append length */\n\tindex = sctx->count % SHA1_BLOCK_SIZE;\n\tpadlen = (index < 56) ? (56 - index) : ((SHA1_BLOCK_SIZE+56) - index);\n\tif (!irq_fpu_usable()) {\n\t\tcrypto_sha1_update(desc, padding, padlen);\n\t\tcrypto_sha1_update(desc, (const u8 *)&bits, sizeof(bits));\n\t} else {\n\t\tkernel_fpu_begin();\n\t\t/* We need to fill a whole block for __sha1_ssse3_update() */\n\t\tif (padlen <= 56) {\n\t\t\tsctx->count += padlen;\n\t\t\tmemcpy(sctx->buffer + index, padding, padlen);\n\t\t} else {\n\t\t\t__sha1_ssse3_update(desc, padding, padlen, index);\n\t\t}\n\t\t__sha1_ssse3_update(desc, (const u8 *)&bits, sizeof(bits), 56);\n\t\tkernel_fpu_end();\n\t}\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 5; i++)\n\t\tdst[i] = cpu_to_be32(sctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha1_ssse3_export(struct shash_desc *desc, void *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha1_ssse3_import(struct shash_desc *desc, const void *in)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, sizeof(*sctx));\n\n\treturn 0;\n}\n\n#ifdef CONFIG_AS_AVX2\nstatic void sha1_apply_transform_avx2(u32 *digest, const char *data,\n\t\t\t\tunsigned int rounds)\n{\n\t/* Select the optimal transform based on data block size */\n\tif (rounds >= SHA1_AVX2_BLOCK_OPTSIZE)\n\t\tsha1_transform_avx2(digest, data, rounds);\n\telse\n\t\tsha1_transform_avx(digest, data, rounds);\n}\n#endif\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tSHA1_DIGEST_SIZE,\n\t.init\t\t=\tsha1_ssse3_init,\n\t.update\t\t=\tsha1_ssse3_update,\n\t.final\t\t=\tsha1_ssse3_final,\n\t.export\t\t=\tsha1_ssse3_export,\n\t.import\t\t=\tsha1_ssse3_import,\n\t.descsize\t=\tsizeof(struct sha1_state),\n\t.statesize\t=\tsizeof(struct sha1_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha1\",\n\t\t.cra_driver_name=\t\"sha1-ssse3\",\n\t\t.cra_priority\t=\t150,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA1_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\n#ifdef CONFIG_AS_AVX\nstatic bool __init avx_usable(void)\n{\n\tu64 xcr0;\n\n\tif (!cpu_has_avx || !cpu_has_osxsave)\n\t\treturn false;\n\n\txcr0 = xgetbv(XCR_XFEATURE_ENABLED_MASK);\n\tif ((xcr0 & (XSTATE_SSE | XSTATE_YMM)) != (XSTATE_SSE | XSTATE_YMM)) {\n\t\tpr_info(\"AVX detected but unusable.\\n\");\n\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n#ifdef CONFIG_AS_AVX2\nstatic bool __init avx2_usable(void)\n{\n\tif (avx_usable() && cpu_has_avx2 && boot_cpu_has(X86_FEATURE_BMI1) &&\n\t    boot_cpu_has(X86_FEATURE_BMI2))\n\t\treturn true;\n\n\treturn false;\n}\n#endif\n#endif\n\nstatic int __init sha1_ssse3_mod_init(void)\n{\n\tchar *algo_name;\n\n\t/* test for SSSE3 first */\n\tif (cpu_has_ssse3) {\n\t\tsha1_transform_asm = sha1_transform_ssse3;\n\t\talgo_name = \"SSSE3\";\n\t}\n\n#ifdef CONFIG_AS_AVX\n\t/* allow AVX to override SSSE3, it's a little faster */\n\tif (avx_usable()) {\n\t\tsha1_transform_asm = sha1_transform_avx;\n\t\talgo_name = \"AVX\";\n#ifdef CONFIG_AS_AVX2\n\t\t/* allow AVX2 to override AVX, it's a little faster */\n\t\tif (avx2_usable()) {\n\t\t\tsha1_transform_asm = sha1_apply_transform_avx2;\n\t\t\talgo_name = \"AVX2\";\n\t\t}\n#endif\n\t}\n#endif\n\n\tif (sha1_transform_asm) {\n\t\tpr_info(\"Using %s optimized SHA-1 implementation\\n\", algo_name);\n\t\treturn crypto_register_shash(&alg);\n\t}\n\tpr_info(\"Neither AVX nor AVX2 nor SSSE3 is available/usable.\\n\");\n\n\treturn -ENODEV;\n}\n\nstatic void __exit sha1_ssse3_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(sha1_ssse3_mod_init);\nmodule_exit(sha1_ssse3_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA1 Secure Hash Algorithm, Supplemental SSE3 accelerated\");\n\nMODULE_ALIAS(\"sha1\");\n", "/*\n * Cryptographic API.\n *\n * Glue code for the SHA256 Secure Hash Algorithm assembler\n * implementation using supplemental SSE3 / AVX / AVX2 instructions.\n *\n * This file is based on sha256_generic.c\n *\n * Copyright (C) 2013 Intel Corporation.\n *\n * Author:\n *     Tim Chen <tim.c.chen@linux.intel.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS\n * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n * SOFTWARE.\n */\n\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n#include <asm/byteorder.h>\n#include <asm/i387.h>\n#include <asm/xcr.h>\n#include <asm/xsave.h>\n#include <linux/string.h>\n\nasmlinkage void sha256_transform_ssse3(const char *data, u32 *digest,\n\t\t\t\t     u64 rounds);\n#ifdef CONFIG_AS_AVX\nasmlinkage void sha256_transform_avx(const char *data, u32 *digest,\n\t\t\t\t     u64 rounds);\n#endif\n#ifdef CONFIG_AS_AVX2\nasmlinkage void sha256_transform_rorx(const char *data, u32 *digest,\n\t\t\t\t     u64 rounds);\n#endif\n\nstatic asmlinkage void (*sha256_transform_asm)(const char *, u32 *, u64);\n\n\nstatic int sha256_ssse3_init(struct shash_desc *desc)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\n\tsctx->state[0] = SHA256_H0;\n\tsctx->state[1] = SHA256_H1;\n\tsctx->state[2] = SHA256_H2;\n\tsctx->state[3] = SHA256_H3;\n\tsctx->state[4] = SHA256_H4;\n\tsctx->state[5] = SHA256_H5;\n\tsctx->state[6] = SHA256_H6;\n\tsctx->state[7] = SHA256_H7;\n\tsctx->count = 0;\n\n\treturn 0;\n}\n\nstatic int __sha256_ssse3_update(struct shash_desc *desc, const u8 *data,\n\t\t\t       unsigned int len, unsigned int partial)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\tunsigned int done = 0;\n\n\tsctx->count += len;\n\n\tif (partial) {\n\t\tdone = SHA256_BLOCK_SIZE - partial;\n\t\tmemcpy(sctx->buf + partial, data, done);\n\t\tsha256_transform_asm(sctx->buf, sctx->state, 1);\n\t}\n\n\tif (len - done >= SHA256_BLOCK_SIZE) {\n\t\tconst unsigned int rounds = (len - done) / SHA256_BLOCK_SIZE;\n\n\t\tsha256_transform_asm(data + done, sctx->state, (u64) rounds);\n\n\t\tdone += rounds * SHA256_BLOCK_SIZE;\n\t}\n\n\tmemcpy(sctx->buf, data + done, len - done);\n\n\treturn 0;\n}\n\nstatic int sha256_ssse3_update(struct shash_desc *desc, const u8 *data,\n\t\t\t     unsigned int len)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial = sctx->count % SHA256_BLOCK_SIZE;\n\tint res;\n\n\t/* Handle the fast case right here */\n\tif (partial + len < SHA256_BLOCK_SIZE) {\n\t\tsctx->count += len;\n\t\tmemcpy(sctx->buf + partial, data, len);\n\n\t\treturn 0;\n\t}\n\n\tif (!irq_fpu_usable()) {\n\t\tres = crypto_sha256_update(desc, data, len);\n\t} else {\n\t\tkernel_fpu_begin();\n\t\tres = __sha256_ssse3_update(desc, data, len, partial);\n\t\tkernel_fpu_end();\n\t}\n\n\treturn res;\n}\n\n\n/* Add padding and return the message digest. */\nstatic int sha256_ssse3_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\tunsigned int i, index, padlen;\n\t__be32 *dst = (__be32 *)out;\n\t__be64 bits;\n\tstatic const u8 padding[SHA256_BLOCK_SIZE] = { 0x80, };\n\n\tbits = cpu_to_be64(sctx->count << 3);\n\n\t/* Pad out to 56 mod 64 and append length */\n\tindex = sctx->count % SHA256_BLOCK_SIZE;\n\tpadlen = (index < 56) ? (56 - index) : ((SHA256_BLOCK_SIZE+56)-index);\n\n\tif (!irq_fpu_usable()) {\n\t\tcrypto_sha256_update(desc, padding, padlen);\n\t\tcrypto_sha256_update(desc, (const u8 *)&bits, sizeof(bits));\n\t} else {\n\t\tkernel_fpu_begin();\n\t\t/* We need to fill a whole block for __sha256_ssse3_update() */\n\t\tif (padlen <= 56) {\n\t\t\tsctx->count += padlen;\n\t\t\tmemcpy(sctx->buf + index, padding, padlen);\n\t\t} else {\n\t\t\t__sha256_ssse3_update(desc, padding, padlen, index);\n\t\t}\n\t\t__sha256_ssse3_update(desc, (const u8 *)&bits,\n\t\t\t\t\tsizeof(bits), 56);\n\t\tkernel_fpu_end();\n\t}\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 8; i++)\n\t\tdst[i] = cpu_to_be32(sctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha256_ssse3_export(struct shash_desc *desc, void *out)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha256_ssse3_import(struct shash_desc *desc, const void *in)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha224_ssse3_init(struct shash_desc *desc)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\n\tsctx->state[0] = SHA224_H0;\n\tsctx->state[1] = SHA224_H1;\n\tsctx->state[2] = SHA224_H2;\n\tsctx->state[3] = SHA224_H3;\n\tsctx->state[4] = SHA224_H4;\n\tsctx->state[5] = SHA224_H5;\n\tsctx->state[6] = SHA224_H6;\n\tsctx->state[7] = SHA224_H7;\n\tsctx->count = 0;\n\n\treturn 0;\n}\n\nstatic int sha224_ssse3_final(struct shash_desc *desc, u8 *hash)\n{\n\tu8 D[SHA256_DIGEST_SIZE];\n\n\tsha256_ssse3_final(desc, D);\n\n\tmemcpy(hash, D, SHA224_DIGEST_SIZE);\n\tmemset(D, 0, SHA256_DIGEST_SIZE);\n\n\treturn 0;\n}\n\nstatic struct shash_alg algs[] = { {\n\t.digestsize\t=\tSHA256_DIGEST_SIZE,\n\t.init\t\t=\tsha256_ssse3_init,\n\t.update\t\t=\tsha256_ssse3_update,\n\t.final\t\t=\tsha256_ssse3_final,\n\t.export\t\t=\tsha256_ssse3_export,\n\t.import\t\t=\tsha256_ssse3_import,\n\t.descsize\t=\tsizeof(struct sha256_state),\n\t.statesize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha256\",\n\t\t.cra_driver_name =\t\"sha256-ssse3\",\n\t\t.cra_priority\t=\t150,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA256_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n}, {\n\t.digestsize\t=\tSHA224_DIGEST_SIZE,\n\t.init\t\t=\tsha224_ssse3_init,\n\t.update\t\t=\tsha256_ssse3_update,\n\t.final\t\t=\tsha224_ssse3_final,\n\t.export\t\t=\tsha256_ssse3_export,\n\t.import\t\t=\tsha256_ssse3_import,\n\t.descsize\t=\tsizeof(struct sha256_state),\n\t.statesize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha224\",\n\t\t.cra_driver_name =\t\"sha224-ssse3\",\n\t\t.cra_priority\t=\t150,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA224_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n} };\n\n#ifdef CONFIG_AS_AVX\nstatic bool __init avx_usable(void)\n{\n\tu64 xcr0;\n\n\tif (!cpu_has_avx || !cpu_has_osxsave)\n\t\treturn false;\n\n\txcr0 = xgetbv(XCR_XFEATURE_ENABLED_MASK);\n\tif ((xcr0 & (XSTATE_SSE | XSTATE_YMM)) != (XSTATE_SSE | XSTATE_YMM)) {\n\t\tpr_info(\"AVX detected but unusable.\\n\");\n\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n#endif\n\nstatic int __init sha256_ssse3_mod_init(void)\n{\n\t/* test for SSSE3 first */\n\tif (cpu_has_ssse3)\n\t\tsha256_transform_asm = sha256_transform_ssse3;\n\n#ifdef CONFIG_AS_AVX\n\t/* allow AVX to override SSSE3, it's a little faster */\n\tif (avx_usable()) {\n#ifdef CONFIG_AS_AVX2\n\t\tif (boot_cpu_has(X86_FEATURE_AVX2) && boot_cpu_has(X86_FEATURE_BMI2))\n\t\t\tsha256_transform_asm = sha256_transform_rorx;\n\t\telse\n#endif\n\t\t\tsha256_transform_asm = sha256_transform_avx;\n\t}\n#endif\n\n\tif (sha256_transform_asm) {\n#ifdef CONFIG_AS_AVX\n\t\tif (sha256_transform_asm == sha256_transform_avx)\n\t\t\tpr_info(\"Using AVX optimized SHA-256 implementation\\n\");\n#ifdef CONFIG_AS_AVX2\n\t\telse if (sha256_transform_asm == sha256_transform_rorx)\n\t\t\tpr_info(\"Using AVX2 optimized SHA-256 implementation\\n\");\n#endif\n\t\telse\n#endif\n\t\t\tpr_info(\"Using SSSE3 optimized SHA-256 implementation\\n\");\n\t\treturn crypto_register_shashes(algs, ARRAY_SIZE(algs));\n\t}\n\tpr_info(\"Neither AVX nor SSSE3 is available/usable.\\n\");\n\n\treturn -ENODEV;\n}\n\nstatic void __exit sha256_ssse3_mod_fini(void)\n{\n\tcrypto_unregister_shashes(algs, ARRAY_SIZE(algs));\n}\n\nmodule_init(sha256_ssse3_mod_init);\nmodule_exit(sha256_ssse3_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA256 Secure Hash Algorithm, Supplemental SSE3 accelerated\");\n\nMODULE_ALIAS(\"sha256\");\nMODULE_ALIAS(\"sha224\");\n", "/*\n * Cryptographic API.\n *\n * Glue code for the SHA512 Secure Hash Algorithm assembler\n * implementation using supplemental SSE3 / AVX / AVX2 instructions.\n *\n * This file is based on sha512_generic.c\n *\n * Copyright (C) 2013 Intel Corporation\n * Author: Tim Chen <tim.c.chen@linux.intel.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS\n * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n * SOFTWARE.\n *\n */\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n#include <asm/byteorder.h>\n#include <asm/i387.h>\n#include <asm/xcr.h>\n#include <asm/xsave.h>\n\n#include <linux/string.h>\n\nasmlinkage void sha512_transform_ssse3(const char *data, u64 *digest,\n\t\t\t\t     u64 rounds);\n#ifdef CONFIG_AS_AVX\nasmlinkage void sha512_transform_avx(const char *data, u64 *digest,\n\t\t\t\t     u64 rounds);\n#endif\n#ifdef CONFIG_AS_AVX2\nasmlinkage void sha512_transform_rorx(const char *data, u64 *digest,\n\t\t\t\t     u64 rounds);\n#endif\n\nstatic asmlinkage void (*sha512_transform_asm)(const char *, u64 *, u64);\n\n\nstatic int sha512_ssse3_init(struct shash_desc *desc)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\n\tsctx->state[0] = SHA512_H0;\n\tsctx->state[1] = SHA512_H1;\n\tsctx->state[2] = SHA512_H2;\n\tsctx->state[3] = SHA512_H3;\n\tsctx->state[4] = SHA512_H4;\n\tsctx->state[5] = SHA512_H5;\n\tsctx->state[6] = SHA512_H6;\n\tsctx->state[7] = SHA512_H7;\n\tsctx->count[0] = sctx->count[1] = 0;\n\n\treturn 0;\n}\n\nstatic int __sha512_ssse3_update(struct shash_desc *desc, const u8 *data,\n\t\t\t       unsigned int len, unsigned int partial)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tunsigned int done = 0;\n\n\tsctx->count[0] += len;\n\tif (sctx->count[0] < len)\n\t\tsctx->count[1]++;\n\n\tif (partial) {\n\t\tdone = SHA512_BLOCK_SIZE - partial;\n\t\tmemcpy(sctx->buf + partial, data, done);\n\t\tsha512_transform_asm(sctx->buf, sctx->state, 1);\n\t}\n\n\tif (len - done >= SHA512_BLOCK_SIZE) {\n\t\tconst unsigned int rounds = (len - done) / SHA512_BLOCK_SIZE;\n\n\t\tsha512_transform_asm(data + done, sctx->state, (u64) rounds);\n\n\t\tdone += rounds * SHA512_BLOCK_SIZE;\n\t}\n\n\tmemcpy(sctx->buf, data + done, len - done);\n\n\treturn 0;\n}\n\nstatic int sha512_ssse3_update(struct shash_desc *desc, const u8 *data,\n\t\t\t     unsigned int len)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial = sctx->count[0] % SHA512_BLOCK_SIZE;\n\tint res;\n\n\t/* Handle the fast case right here */\n\tif (partial + len < SHA512_BLOCK_SIZE) {\n\t\tsctx->count[0] += len;\n\t\tif (sctx->count[0] < len)\n\t\t\tsctx->count[1]++;\n\t\tmemcpy(sctx->buf + partial, data, len);\n\n\t\treturn 0;\n\t}\n\n\tif (!irq_fpu_usable()) {\n\t\tres = crypto_sha512_update(desc, data, len);\n\t} else {\n\t\tkernel_fpu_begin();\n\t\tres = __sha512_ssse3_update(desc, data, len, partial);\n\t\tkernel_fpu_end();\n\t}\n\n\treturn res;\n}\n\n\n/* Add padding and return the message digest. */\nstatic int sha512_ssse3_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tunsigned int i, index, padlen;\n\t__be64 *dst = (__be64 *)out;\n\t__be64 bits[2];\n\tstatic const u8 padding[SHA512_BLOCK_SIZE] = { 0x80, };\n\n\t/* save number of bits */\n\tbits[1] = cpu_to_be64(sctx->count[0] << 3);\n\tbits[0] = cpu_to_be64(sctx->count[1] << 3 | sctx->count[0] >> 61);\n\n\t/* Pad out to 112 mod 128 and append length */\n\tindex = sctx->count[0] & 0x7f;\n\tpadlen = (index < 112) ? (112 - index) : ((128+112) - index);\n\n\tif (!irq_fpu_usable()) {\n\t\tcrypto_sha512_update(desc, padding, padlen);\n\t\tcrypto_sha512_update(desc, (const u8 *)&bits, sizeof(bits));\n\t} else {\n\t\tkernel_fpu_begin();\n\t\t/* We need to fill a whole block for __sha512_ssse3_update() */\n\t\tif (padlen <= 112) {\n\t\t\tsctx->count[0] += padlen;\n\t\t\tif (sctx->count[0] < padlen)\n\t\t\t\tsctx->count[1]++;\n\t\t\tmemcpy(sctx->buf + index, padding, padlen);\n\t\t} else {\n\t\t\t__sha512_ssse3_update(desc, padding, padlen, index);\n\t\t}\n\t\t__sha512_ssse3_update(desc, (const u8 *)&bits,\n\t\t\t\t\tsizeof(bits), 112);\n\t\tkernel_fpu_end();\n\t}\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 8; i++)\n\t\tdst[i] = cpu_to_be64(sctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha512_ssse3_export(struct shash_desc *desc, void *out)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha512_ssse3_import(struct shash_desc *desc, const void *in)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha384_ssse3_init(struct shash_desc *desc)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\n\tsctx->state[0] = SHA384_H0;\n\tsctx->state[1] = SHA384_H1;\n\tsctx->state[2] = SHA384_H2;\n\tsctx->state[3] = SHA384_H3;\n\tsctx->state[4] = SHA384_H4;\n\tsctx->state[5] = SHA384_H5;\n\tsctx->state[6] = SHA384_H6;\n\tsctx->state[7] = SHA384_H7;\n\n\tsctx->count[0] = sctx->count[1] = 0;\n\n\treturn 0;\n}\n\nstatic int sha384_ssse3_final(struct shash_desc *desc, u8 *hash)\n{\n\tu8 D[SHA512_DIGEST_SIZE];\n\n\tsha512_ssse3_final(desc, D);\n\n\tmemcpy(hash, D, SHA384_DIGEST_SIZE);\n\tmemset(D, 0, SHA512_DIGEST_SIZE);\n\n\treturn 0;\n}\n\nstatic struct shash_alg algs[] = { {\n\t.digestsize\t=\tSHA512_DIGEST_SIZE,\n\t.init\t\t=\tsha512_ssse3_init,\n\t.update\t\t=\tsha512_ssse3_update,\n\t.final\t\t=\tsha512_ssse3_final,\n\t.export\t\t=\tsha512_ssse3_export,\n\t.import\t\t=\tsha512_ssse3_import,\n\t.descsize\t=\tsizeof(struct sha512_state),\n\t.statesize\t=\tsizeof(struct sha512_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha512\",\n\t\t.cra_driver_name =\t\"sha512-ssse3\",\n\t\t.cra_priority\t=\t150,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA512_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n},  {\n\t.digestsize\t=\tSHA384_DIGEST_SIZE,\n\t.init\t\t=\tsha384_ssse3_init,\n\t.update\t\t=\tsha512_ssse3_update,\n\t.final\t\t=\tsha384_ssse3_final,\n\t.export\t\t=\tsha512_ssse3_export,\n\t.import\t\t=\tsha512_ssse3_import,\n\t.descsize\t=\tsizeof(struct sha512_state),\n\t.statesize\t=\tsizeof(struct sha512_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha384\",\n\t\t.cra_driver_name =\t\"sha384-ssse3\",\n\t\t.cra_priority\t=\t150,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA384_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n} };\n\n#ifdef CONFIG_AS_AVX\nstatic bool __init avx_usable(void)\n{\n\tu64 xcr0;\n\n\tif (!cpu_has_avx || !cpu_has_osxsave)\n\t\treturn false;\n\n\txcr0 = xgetbv(XCR_XFEATURE_ENABLED_MASK);\n\tif ((xcr0 & (XSTATE_SSE | XSTATE_YMM)) != (XSTATE_SSE | XSTATE_YMM)) {\n\t\tpr_info(\"AVX detected but unusable.\\n\");\n\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n#endif\n\nstatic int __init sha512_ssse3_mod_init(void)\n{\n\t/* test for SSSE3 first */\n\tif (cpu_has_ssse3)\n\t\tsha512_transform_asm = sha512_transform_ssse3;\n\n#ifdef CONFIG_AS_AVX\n\t/* allow AVX to override SSSE3, it's a little faster */\n\tif (avx_usable()) {\n#ifdef CONFIG_AS_AVX2\n\t\tif (boot_cpu_has(X86_FEATURE_AVX2))\n\t\t\tsha512_transform_asm = sha512_transform_rorx;\n\t\telse\n#endif\n\t\t\tsha512_transform_asm = sha512_transform_avx;\n\t}\n#endif\n\n\tif (sha512_transform_asm) {\n#ifdef CONFIG_AS_AVX\n\t\tif (sha512_transform_asm == sha512_transform_avx)\n\t\t\tpr_info(\"Using AVX optimized SHA-512 implementation\\n\");\n#ifdef CONFIG_AS_AVX2\n\t\telse if (sha512_transform_asm == sha512_transform_rorx)\n\t\t\tpr_info(\"Using AVX2 optimized SHA-512 implementation\\n\");\n#endif\n\t\telse\n#endif\n\t\t\tpr_info(\"Using SSSE3 optimized SHA-512 implementation\\n\");\n\t\treturn crypto_register_shashes(algs, ARRAY_SIZE(algs));\n\t}\n\tpr_info(\"Neither AVX nor SSSE3 is available/usable.\\n\");\n\n\treturn -ENODEV;\n}\n\nstatic void __exit sha512_ssse3_mod_fini(void)\n{\n\tcrypto_unregister_shashes(algs, ARRAY_SIZE(algs));\n}\n\nmodule_init(sha512_ssse3_mod_init);\nmodule_exit(sha512_ssse3_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA512 Secure Hash Algorithm, Supplemental SSE3 accelerated\");\n\nMODULE_ALIAS(\"sha512\");\nMODULE_ALIAS(\"sha384\");\n", "/*\n * Glue Code for AVX assembler version of Twofish Cipher\n *\n * Copyright (C) 2012 Johannes Goetzfried\n *     <Johannes.Goetzfried@informatik.stud.uni-erlangen.de>\n *\n * Copyright \u00a9 2013 Jussi Kivilinna <jussi.kivilinna@iki.fi>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307\n * USA\n *\n */\n\n#include <linux/module.h>\n#include <linux/hardirq.h>\n#include <linux/types.h>\n#include <linux/crypto.h>\n#include <linux/err.h>\n#include <crypto/ablk_helper.h>\n#include <crypto/algapi.h>\n#include <crypto/twofish.h>\n#include <crypto/cryptd.h>\n#include <crypto/b128ops.h>\n#include <crypto/ctr.h>\n#include <crypto/lrw.h>\n#include <crypto/xts.h>\n#include <asm/i387.h>\n#include <asm/xcr.h>\n#include <asm/xsave.h>\n#include <asm/crypto/twofish.h>\n#include <asm/crypto/glue_helper.h>\n#include <crypto/scatterwalk.h>\n#include <linux/workqueue.h>\n#include <linux/spinlock.h>\n\n#define TWOFISH_PARALLEL_BLOCKS 8\n\n/* 8-way parallel cipher functions */\nasmlinkage void twofish_ecb_enc_8way(struct twofish_ctx *ctx, u8 *dst,\n\t\t\t\t     const u8 *src);\nasmlinkage void twofish_ecb_dec_8way(struct twofish_ctx *ctx, u8 *dst,\n\t\t\t\t     const u8 *src);\n\nasmlinkage void twofish_cbc_dec_8way(struct twofish_ctx *ctx, u8 *dst,\n\t\t\t\t     const u8 *src);\nasmlinkage void twofish_ctr_8way(struct twofish_ctx *ctx, u8 *dst,\n\t\t\t\t const u8 *src, le128 *iv);\n\nasmlinkage void twofish_xts_enc_8way(struct twofish_ctx *ctx, u8 *dst,\n\t\t\t\t     const u8 *src, le128 *iv);\nasmlinkage void twofish_xts_dec_8way(struct twofish_ctx *ctx, u8 *dst,\n\t\t\t\t     const u8 *src, le128 *iv);\n\nstatic inline void twofish_enc_blk_3way(struct twofish_ctx *ctx, u8 *dst,\n\t\t\t\t\tconst u8 *src)\n{\n\t__twofish_enc_blk_3way(ctx, dst, src, false);\n}\n\nstatic void twofish_xts_enc(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tglue_xts_crypt_128bit_one(ctx, dst, src, iv,\n\t\t\t\t  GLUE_FUNC_CAST(twofish_enc_blk));\n}\n\nstatic void twofish_xts_dec(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tglue_xts_crypt_128bit_one(ctx, dst, src, iv,\n\t\t\t\t  GLUE_FUNC_CAST(twofish_dec_blk));\n}\n\n\nstatic const struct common_glue_ctx twofish_enc = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = TWOFISH_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = TWOFISH_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_ecb_enc_8way) }\n\t}, {\n\t\t.num_blocks = 3,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_enc_blk_3way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_enc_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx twofish_ctr = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = TWOFISH_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = TWOFISH_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(twofish_ctr_8way) }\n\t}, {\n\t\t.num_blocks = 3,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(twofish_enc_blk_ctr_3way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(twofish_enc_blk_ctr) }\n\t} }\n};\n\nstatic const struct common_glue_ctx twofish_enc_xts = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = TWOFISH_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = TWOFISH_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(twofish_xts_enc_8way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(twofish_xts_enc) }\n\t} }\n};\n\nstatic const struct common_glue_ctx twofish_dec = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = TWOFISH_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = TWOFISH_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_ecb_dec_8way) }\n\t}, {\n\t\t.num_blocks = 3,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_dec_blk_3way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_dec_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx twofish_dec_cbc = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = TWOFISH_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = TWOFISH_PARALLEL_BLOCKS,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(twofish_cbc_dec_8way) }\n\t}, {\n\t\t.num_blocks = 3,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(twofish_dec_blk_cbc_3way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(twofish_dec_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx twofish_dec_xts = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = TWOFISH_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = TWOFISH_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(twofish_xts_dec_8way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(twofish_xts_dec) }\n\t} }\n};\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&twofish_enc, desc, dst, src, nbytes);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&twofish_dec, desc, dst, src, nbytes);\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_encrypt_128bit(GLUE_FUNC_CAST(twofish_enc_blk), desc,\n\t\t\t\t       dst, src, nbytes);\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_decrypt_128bit(&twofish_dec_cbc, desc, dst, src,\n\t\t\t\t       nbytes);\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ctr_crypt_128bit(&twofish_ctr, desc, dst, src, nbytes);\n}\n\nstatic inline bool twofish_fpu_begin(bool fpu_enabled, unsigned int nbytes)\n{\n\treturn glue_fpu_begin(TF_BLOCK_SIZE, TWOFISH_PARALLEL_BLOCKS, NULL,\n\t\t\t      fpu_enabled, nbytes);\n}\n\nstatic inline void twofish_fpu_end(bool fpu_enabled)\n{\n\tglue_fpu_end(fpu_enabled);\n}\n\nstruct crypt_priv {\n\tstruct twofish_ctx *ctx;\n\tbool fpu_enabled;\n};\n\nstatic void encrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = TF_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = twofish_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes == bsize * TWOFISH_PARALLEL_BLOCKS) {\n\t\ttwofish_ecb_enc_8way(ctx->ctx, srcdst, srcdst);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < nbytes / (bsize * 3); i++, srcdst += bsize * 3)\n\t\ttwofish_enc_blk_3way(ctx->ctx, srcdst, srcdst);\n\n\tnbytes %= bsize * 3;\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\ttwofish_enc_blk(ctx->ctx, srcdst, srcdst);\n}\n\nstatic void decrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = TF_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = twofish_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes == bsize * TWOFISH_PARALLEL_BLOCKS) {\n\t\ttwofish_ecb_dec_8way(ctx->ctx, srcdst, srcdst);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < nbytes / (bsize * 3); i++, srcdst += bsize * 3)\n\t\ttwofish_dec_blk_3way(ctx->ctx, srcdst, srcdst);\n\n\tnbytes %= bsize * 3;\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\ttwofish_dec_blk(ctx->ctx, srcdst, srcdst);\n}\n\nstatic int lrw_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct twofish_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[TWOFISH_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->twofish_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\ttwofish_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int lrw_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct twofish_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[TWOFISH_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->twofish_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\ttwofish_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct twofish_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&twofish_enc_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(twofish_enc_blk),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct twofish_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&twofish_dec_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(twofish_enc_blk),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic struct crypto_alg twofish_algs[10] = { {\n\t.cra_name\t\t= \"__ecb-twofish-avx\",\n\t.cra_driver_name\t= \"__driver-ecb-twofish-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct twofish_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= twofish_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__cbc-twofish-avx\",\n\t.cra_driver_name\t= \"__driver-cbc-twofish-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct twofish_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= twofish_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__ctr-twofish-avx\",\n\t.cra_driver_name\t= \"__driver-ctr-twofish-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct twofish_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= TF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= twofish_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__lrw-twofish-avx\",\n\t.cra_driver_name\t= \"__driver-lrw-twofish-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct twofish_lrw_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_exit\t\t= lrw_twofish_exit_tfm,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE +\n\t\t\t\t\t  TF_BLOCK_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE +\n\t\t\t\t\t  TF_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= TF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= lrw_twofish_setkey,\n\t\t\t.encrypt\t= lrw_encrypt,\n\t\t\t.decrypt\t= lrw_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__xts-twofish-avx\",\n\t.cra_driver_name\t= \"__driver-xts-twofish-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct twofish_xts_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= TF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= xts_twofish_setkey,\n\t\t\t.encrypt\t= xts_encrypt,\n\t\t\t.decrypt\t= xts_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ecb(twofish)\",\n\t.cra_driver_name\t= \"ecb-twofish-avx\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(twofish)\",\n\t.cra_driver_name\t= \"cbc-twofish-avx\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= TF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= __ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(twofish)\",\n\t.cra_driver_name\t= \"ctr-twofish-avx\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= TF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_encrypt,\n\t\t\t.geniv\t\t= \"chainiv\",\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"lrw(twofish)\",\n\t.cra_driver_name\t= \"lrw-twofish-avx\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE +\n\t\t\t\t\t  TF_BLOCK_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE +\n\t\t\t\t\t  TF_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= TF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"xts(twofish)\",\n\t.cra_driver_name\t= \"xts-twofish-avx\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= TF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n} };\n\nstatic int __init twofish_init(void)\n{\n\tu64 xcr0;\n\n\tif (!cpu_has_avx || !cpu_has_osxsave) {\n\t\tprintk(KERN_INFO \"AVX instructions are not detected.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\txcr0 = xgetbv(XCR_XFEATURE_ENABLED_MASK);\n\tif ((xcr0 & (XSTATE_SSE | XSTATE_YMM)) != (XSTATE_SSE | XSTATE_YMM)) {\n\t\tprintk(KERN_INFO \"AVX detected but unusable.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(twofish_algs, ARRAY_SIZE(twofish_algs));\n}\n\nstatic void __exit twofish_exit(void)\n{\n\tcrypto_unregister_algs(twofish_algs, ARRAY_SIZE(twofish_algs));\n}\n\nmodule_init(twofish_init);\nmodule_exit(twofish_exit);\n\nMODULE_DESCRIPTION(\"Twofish Cipher Algorithm, AVX optimized\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS(\"twofish\");\n", "/*\n * Glue Code for assembler optimized version of TWOFISH\n *\n * Originally Twofish for GPG\n * By Matthew Skala <mskala@ansuz.sooke.bc.ca>, July 26, 1998\n * 256-bit key length added March 20, 1999\n * Some modifications to reduce the text size by Werner Koch, April, 1998\n * Ported to the kerneli patch by Marc Mutz <Marc@Mutz.com>\n * Ported to CryptoAPI by Colin Slater <hoho@tacomeat.net>\n *\n * The original author has disclaimed all copyright interest in this\n * code and thus put it in the public domain. The subsequent authors\n * have put this under the GNU General Public License.\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307\n * USA\n *\n * This code is a \"clean room\" implementation, written from the paper\n * _Twofish: A 128-Bit Block Cipher_ by Bruce Schneier, John Kelsey,\n * Doug Whiting, David Wagner, Chris Hall, and Niels Ferguson, available\n * through http://www.counterpane.com/twofish.html\n *\n * For background information on multiplication in finite fields, used for\n * the matrix operations in the key schedule, see the book _Contemporary\n * Abstract Algebra_ by Joseph A. Gallian, especially chapter 22 in the\n * Third Edition.\n */\n\n#include <crypto/twofish.h>\n#include <linux/crypto.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/types.h>\n\nasmlinkage void twofish_enc_blk(struct twofish_ctx *ctx, u8 *dst,\n\t\t\t\tconst u8 *src);\nEXPORT_SYMBOL_GPL(twofish_enc_blk);\nasmlinkage void twofish_dec_blk(struct twofish_ctx *ctx, u8 *dst,\n\t\t\t\tconst u8 *src);\nEXPORT_SYMBOL_GPL(twofish_dec_blk);\n\nstatic void twofish_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\ttwofish_enc_blk(crypto_tfm_ctx(tfm), dst, src);\n}\n\nstatic void twofish_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\ttwofish_dec_blk(crypto_tfm_ctx(tfm), dst, src);\n}\n\nstatic struct crypto_alg alg = {\n\t.cra_name\t\t=\t\"twofish\",\n\t.cra_driver_name\t=\t\"twofish-asm\",\n\t.cra_priority\t\t=\t200,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tTF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct twofish_ctx),\n\t.cra_alignmask\t\t=\t0,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.cipher = {\n\t\t\t.cia_min_keysize\t=\tTF_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t=\tTF_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t=\ttwofish_setkey,\n\t\t\t.cia_encrypt\t\t=\ttwofish_encrypt,\n\t\t\t.cia_decrypt\t\t=\ttwofish_decrypt\n\t\t}\n\t}\n};\n\nstatic int __init init(void)\n{\n\treturn crypto_register_alg(&alg);\n}\n\nstatic void __exit fini(void)\n{\n\tcrypto_unregister_alg(&alg);\n}\n\nmodule_init(init);\nmodule_exit(fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION (\"Twofish Cipher Algorithm, asm optimized\");\nMODULE_ALIAS(\"twofish\");\nMODULE_ALIAS(\"twofish-asm\");\n", "/*\n * Glue Code for 3-way parallel assembler optimized version of Twofish\n *\n * Copyright (c) 2011 Jussi Kivilinna <jussi.kivilinna@mbnet.fi>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307\n * USA\n *\n */\n\n#include <asm/processor.h>\n#include <linux/crypto.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/types.h>\n#include <crypto/algapi.h>\n#include <crypto/twofish.h>\n#include <crypto/b128ops.h>\n#include <asm/crypto/twofish.h>\n#include <asm/crypto/glue_helper.h>\n#include <crypto/lrw.h>\n#include <crypto/xts.h>\n\nEXPORT_SYMBOL_GPL(__twofish_enc_blk_3way);\nEXPORT_SYMBOL_GPL(twofish_dec_blk_3way);\n\nstatic inline void twofish_enc_blk_3way(struct twofish_ctx *ctx, u8 *dst,\n\t\t\t\t\tconst u8 *src)\n{\n\t__twofish_enc_blk_3way(ctx, dst, src, false);\n}\n\nstatic inline void twofish_enc_blk_xor_3way(struct twofish_ctx *ctx, u8 *dst,\n\t\t\t\t\t    const u8 *src)\n{\n\t__twofish_enc_blk_3way(ctx, dst, src, true);\n}\n\nvoid twofish_dec_blk_cbc_3way(void *ctx, u128 *dst, const u128 *src)\n{\n\tu128 ivs[2];\n\n\tivs[0] = src[0];\n\tivs[1] = src[1];\n\n\ttwofish_dec_blk_3way(ctx, (u8 *)dst, (u8 *)src);\n\n\tu128_xor(&dst[1], &dst[1], &ivs[0]);\n\tu128_xor(&dst[2], &dst[2], &ivs[1]);\n}\nEXPORT_SYMBOL_GPL(twofish_dec_blk_cbc_3way);\n\nvoid twofish_enc_blk_ctr(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tbe128 ctrblk;\n\n\tif (dst != src)\n\t\t*dst = *src;\n\n\tle128_to_be128(&ctrblk, iv);\n\tle128_inc(iv);\n\n\ttwofish_enc_blk(ctx, (u8 *)&ctrblk, (u8 *)&ctrblk);\n\tu128_xor(dst, dst, (u128 *)&ctrblk);\n}\nEXPORT_SYMBOL_GPL(twofish_enc_blk_ctr);\n\nvoid twofish_enc_blk_ctr_3way(void *ctx, u128 *dst, const u128 *src,\n\t\t\t      le128 *iv)\n{\n\tbe128 ctrblks[3];\n\n\tif (dst != src) {\n\t\tdst[0] = src[0];\n\t\tdst[1] = src[1];\n\t\tdst[2] = src[2];\n\t}\n\n\tle128_to_be128(&ctrblks[0], iv);\n\tle128_inc(iv);\n\tle128_to_be128(&ctrblks[1], iv);\n\tle128_inc(iv);\n\tle128_to_be128(&ctrblks[2], iv);\n\tle128_inc(iv);\n\n\ttwofish_enc_blk_xor_3way(ctx, (u8 *)dst, (u8 *)ctrblks);\n}\nEXPORT_SYMBOL_GPL(twofish_enc_blk_ctr_3way);\n\nstatic const struct common_glue_ctx twofish_enc = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = -1,\n\n\t.funcs = { {\n\t\t.num_blocks = 3,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_enc_blk_3way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_enc_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx twofish_ctr = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = -1,\n\n\t.funcs = { {\n\t\t.num_blocks = 3,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_enc_blk_ctr_3way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_enc_blk_ctr) }\n\t} }\n};\n\nstatic const struct common_glue_ctx twofish_dec = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = -1,\n\n\t.funcs = { {\n\t\t.num_blocks = 3,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_dec_blk_3way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_dec_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx twofish_dec_cbc = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = -1,\n\n\t.funcs = { {\n\t\t.num_blocks = 3,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(twofish_dec_blk_cbc_3way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(twofish_dec_blk) }\n\t} }\n};\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&twofish_enc, desc, dst, src, nbytes);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&twofish_dec, desc, dst, src, nbytes);\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_encrypt_128bit(GLUE_FUNC_CAST(twofish_enc_blk), desc,\n\t\t\t\t       dst, src, nbytes);\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_decrypt_128bit(&twofish_dec_cbc, desc, dst, src,\n\t\t\t\t       nbytes);\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ctr_crypt_128bit(&twofish_ctr, desc, dst, src, nbytes);\n}\n\nstatic void encrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = TF_BLOCK_SIZE;\n\tstruct twofish_ctx *ctx = priv;\n\tint i;\n\n\tif (nbytes == 3 * bsize) {\n\t\ttwofish_enc_blk_3way(ctx, srcdst, srcdst);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\ttwofish_enc_blk(ctx, srcdst, srcdst);\n}\n\nstatic void decrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = TF_BLOCK_SIZE;\n\tstruct twofish_ctx *ctx = priv;\n\tint i;\n\n\tif (nbytes == 3 * bsize) {\n\t\ttwofish_dec_blk_3way(ctx, srcdst, srcdst);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\ttwofish_dec_blk(ctx, srcdst, srcdst);\n}\n\nint lrw_twofish_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t       unsigned int keylen)\n{\n\tstruct twofish_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\tint err;\n\n\terr = __twofish_setkey(&ctx->twofish_ctx, key, keylen - TF_BLOCK_SIZE,\n\t\t\t       &tfm->crt_flags);\n\tif (err)\n\t\treturn err;\n\n\treturn lrw_init_table(&ctx->lrw_table, key + keylen - TF_BLOCK_SIZE);\n}\nEXPORT_SYMBOL_GPL(lrw_twofish_setkey);\n\nstatic int lrw_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct twofish_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[3];\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &ctx->twofish_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\n\treturn lrw_crypt(desc, dst, src, nbytes, &req);\n}\n\nstatic int lrw_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct twofish_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[3];\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &ctx->twofish_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\n\treturn lrw_crypt(desc, dst, src, nbytes, &req);\n}\n\nvoid lrw_twofish_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct twofish_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tlrw_free_table(&ctx->lrw_table);\n}\nEXPORT_SYMBOL_GPL(lrw_twofish_exit_tfm);\n\nint xts_twofish_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t       unsigned int keylen)\n{\n\tstruct twofish_xts_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tint err;\n\n\t/* key consists of keys of equal size concatenated, therefore\n\t * the length must be even\n\t */\n\tif (keylen % 2) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\t/* first half of xts-key is for crypt */\n\terr = __twofish_setkey(&ctx->crypt_ctx, key, keylen / 2, flags);\n\tif (err)\n\t\treturn err;\n\n\t/* second half of xts-key is for tweak */\n\treturn __twofish_setkey(&ctx->tweak_ctx, key + keylen / 2, keylen / 2,\n\t\t\t\tflags);\n}\nEXPORT_SYMBOL_GPL(xts_twofish_setkey);\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct twofish_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[3];\n\tstruct xts_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.tweak_ctx = &ctx->tweak_ctx,\n\t\t.tweak_fn = XTS_TWEAK_CAST(twofish_enc_blk),\n\t\t.crypt_ctx = &ctx->crypt_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\n\treturn xts_crypt(desc, dst, src, nbytes, &req);\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct twofish_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[3];\n\tstruct xts_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.tweak_ctx = &ctx->tweak_ctx,\n\t\t.tweak_fn = XTS_TWEAK_CAST(twofish_enc_blk),\n\t\t.crypt_ctx = &ctx->crypt_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\n\treturn xts_crypt(desc, dst, src, nbytes, &req);\n}\n\nstatic struct crypto_alg tf_algs[5] = { {\n\t.cra_name\t\t= \"ecb(twofish)\",\n\t.cra_driver_name\t= \"ecb-twofish-3way\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct twofish_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= twofish_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(twofish)\",\n\t.cra_driver_name\t= \"cbc-twofish-3way\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct twofish_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= TF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= twofish_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(twofish)\",\n\t.cra_driver_name\t= \"ctr-twofish-3way\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct twofish_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= TF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= twofish_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"lrw(twofish)\",\n\t.cra_driver_name\t= \"lrw-twofish-3way\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct twofish_lrw_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_exit\t\t= lrw_twofish_exit_tfm,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE + TF_BLOCK_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE + TF_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= TF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= lrw_twofish_setkey,\n\t\t\t.encrypt\t= lrw_encrypt,\n\t\t\t.decrypt\t= lrw_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"xts(twofish)\",\n\t.cra_driver_name\t= \"xts-twofish-3way\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct twofish_xts_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= TF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= xts_twofish_setkey,\n\t\t\t.encrypt\t= xts_encrypt,\n\t\t\t.decrypt\t= xts_decrypt,\n\t\t},\n\t},\n} };\n\nstatic bool is_blacklisted_cpu(void)\n{\n\tif (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL)\n\t\treturn false;\n\n\tif (boot_cpu_data.x86 == 0x06 &&\n\t\t(boot_cpu_data.x86_model == 0x1c ||\n\t\t boot_cpu_data.x86_model == 0x26 ||\n\t\t boot_cpu_data.x86_model == 0x36)) {\n\t\t/*\n\t\t * On Atom, twofish-3way is slower than original assembler\n\t\t * implementation. Twofish-3way trades off some performance in\n\t\t * storing blocks in 64bit registers to allow three blocks to\n\t\t * be processed parallel. Parallel operation then allows gaining\n\t\t * more performance than was trade off, on out-of-order CPUs.\n\t\t * However Atom does not benefit from this parallellism and\n\t\t * should be blacklisted.\n\t\t */\n\t\treturn true;\n\t}\n\n\tif (boot_cpu_data.x86 == 0x0f) {\n\t\t/*\n\t\t * On Pentium 4, twofish-3way is slower than original assembler\n\t\t * implementation because excessive uses of 64bit rotate and\n\t\t * left-shifts (which are really slow on P4) needed to store and\n\t\t * handle 128bit block in two 64bit registers.\n\t\t */\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic int force;\nmodule_param(force, int, 0);\nMODULE_PARM_DESC(force, \"Force module load, ignore CPU blacklist\");\n\nstatic int __init init(void)\n{\n\tif (!force && is_blacklisted_cpu()) {\n\t\tprintk(KERN_INFO\n\t\t\t\"twofish-x86_64-3way: performance on this CPU \"\n\t\t\t\"would be suboptimal: disabling \"\n\t\t\t\"twofish-x86_64-3way.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(tf_algs, ARRAY_SIZE(tf_algs));\n}\n\nstatic void __exit fini(void)\n{\n\tcrypto_unregister_algs(tf_algs, ARRAY_SIZE(tf_algs));\n}\n\nmodule_init(init);\nmodule_exit(fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Twofish Cipher Algorithm, 3-way parallel asm optimized\");\nMODULE_ALIAS(\"twofish\");\nMODULE_ALIAS(\"twofish-asm\");\n", "/*\n * Cryptographic API for the 842 compression algorithm.\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.\n *\n * Copyright (C) IBM Corporation, 2011\n *\n * Authors: Robert Jennings <rcj@linux.vnet.ibm.com>\n *          Seth Jennings <sjenning@linux.vnet.ibm.com>\n */\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/crypto.h>\n#include <linux/vmalloc.h>\n#include <linux/nx842.h>\n#include <linux/lzo.h>\n#include <linux/timer.h>\n\nstatic int nx842_uselzo;\n\nstruct nx842_ctx {\n\tvoid *nx842_wmem; /* working memory for 842/lzo */\n};\n\nenum nx842_crypto_type {\n\tNX842_CRYPTO_TYPE_842,\n\tNX842_CRYPTO_TYPE_LZO\n};\n\n#define NX842_SENTINEL 0xdeadbeef\n\nstruct nx842_crypto_header {\n\tunsigned int sentinel; /* debug */\n\tenum nx842_crypto_type type;\n};\n\nstatic int nx842_init(struct crypto_tfm *tfm)\n{\n\tstruct nx842_ctx *ctx = crypto_tfm_ctx(tfm);\n\tint wmemsize;\n\n\twmemsize = max_t(int, nx842_get_workmem_size(), LZO1X_MEM_COMPRESS);\n\tctx->nx842_wmem = kmalloc(wmemsize, GFP_NOFS);\n\tif (!ctx->nx842_wmem)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic void nx842_exit(struct crypto_tfm *tfm)\n{\n\tstruct nx842_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tkfree(ctx->nx842_wmem);\n}\n\nstatic void nx842_reset_uselzo(unsigned long data)\n{\n\tnx842_uselzo = 0;\n}\n\nstatic DEFINE_TIMER(failover_timer, nx842_reset_uselzo, 0, 0);\n\nstatic int nx842_crypto_compress(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t    unsigned int slen, u8 *dst, unsigned int *dlen)\n{\n\tstruct nx842_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct nx842_crypto_header *hdr;\n\tunsigned int tmp_len = *dlen;\n\tsize_t lzodlen; /* needed for lzo */\n\tint err;\n\n\t*dlen = 0;\n\thdr = (struct nx842_crypto_header *)dst;\n\thdr->sentinel = NX842_SENTINEL; /* debug */\n\tdst += sizeof(struct nx842_crypto_header);\n\ttmp_len -= sizeof(struct nx842_crypto_header);\n\tlzodlen = tmp_len;\n\n\tif (likely(!nx842_uselzo)) {\n\t\terr = nx842_compress(src, slen, dst, &tmp_len, ctx->nx842_wmem);\n\n\t\tif (likely(!err)) {\n\t\t\thdr->type = NX842_CRYPTO_TYPE_842;\n\t\t\t*dlen = tmp_len + sizeof(struct nx842_crypto_header);\n\t\t\treturn 0;\n\t\t}\n\n\t\t/* hardware failed */\n\t\tnx842_uselzo = 1;\n\n\t\t/* set timer to check for hardware again in 1 second */\n\t\tmod_timer(&failover_timer, jiffies + msecs_to_jiffies(1000));\n\t}\n\n\t/* no hardware, use lzo */\n\terr = lzo1x_1_compress(src, slen, dst, &lzodlen, ctx->nx842_wmem);\n\tif (err != LZO_E_OK)\n\t\treturn -EINVAL;\n\n\thdr->type = NX842_CRYPTO_TYPE_LZO;\n\t*dlen = lzodlen + sizeof(struct nx842_crypto_header);\n\treturn 0;\n}\n\nstatic int nx842_crypto_decompress(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t      unsigned int slen, u8 *dst, unsigned int *dlen)\n{\n\tstruct nx842_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct nx842_crypto_header *hdr;\n\tunsigned int tmp_len = *dlen;\n\tsize_t lzodlen; /* needed for lzo */\n\tint err;\n\n\t*dlen = 0;\n\thdr = (struct nx842_crypto_header *)src;\n\n\tif (unlikely(hdr->sentinel != NX842_SENTINEL))\n\t\treturn -EINVAL;\n\n\tsrc += sizeof(struct nx842_crypto_header);\n\tslen -= sizeof(struct nx842_crypto_header);\n\n\tif (likely(hdr->type == NX842_CRYPTO_TYPE_842)) {\n\t\terr = nx842_decompress(src, slen, dst, &tmp_len,\n\t\t\tctx->nx842_wmem);\n\t\tif (err)\n\t\t\treturn -EINVAL;\n\t\t*dlen = tmp_len;\n\t} else if (hdr->type == NX842_CRYPTO_TYPE_LZO) {\n\t\tlzodlen = tmp_len;\n\t\terr = lzo1x_decompress_safe(src, slen, dst, &lzodlen);\n\t\tif (err != LZO_E_OK)\n\t\t\treturn -EINVAL;\n\t\t*dlen = lzodlen;\n\t} else\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic struct crypto_alg alg = {\n\t.cra_name\t\t= \"842\",\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_COMPRESS,\n\t.cra_ctxsize\t\t= sizeof(struct nx842_ctx),\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= nx842_init,\n\t.cra_exit\t\t= nx842_exit,\n\t.cra_u\t\t\t= { .compress = {\n\t.coa_compress\t\t= nx842_crypto_compress,\n\t.coa_decompress\t\t= nx842_crypto_decompress } }\n};\n\nstatic int __init nx842_mod_init(void)\n{\n\tdel_timer(&failover_timer);\n\treturn crypto_register_alg(&alg);\n}\n\nstatic void __exit nx842_mod_exit(void)\n{\n\tcrypto_unregister_alg(&alg);\n}\n\nmodule_init(nx842_mod_init);\nmodule_exit(nx842_mod_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"842 Compression Algorithm\");\n", "/*\n * Cryptographic API.\n *\n * AES Cipher Algorithm.\n *\n * Based on Brian Gladman's code.\n *\n * Linux developers:\n *  Alexander Kjeldaas <astor@fast.no>\n *  Herbert Valerio Riedel <hvr@hvrlab.org>\n *  Kyle McMartin <kyle@debian.org>\n *  Adam J. Richter <adam@yggdrasil.com> (conversion to 2.5 API).\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * ---------------------------------------------------------------------------\n * Copyright (c) 2002, Dr Brian Gladman <brg@gladman.me.uk>, Worcester, UK.\n * All rights reserved.\n *\n * LICENSE TERMS\n *\n * The free distribution and use of this software in both source and binary\n * form is allowed (with or without changes) provided that:\n *\n *   1. distributions of this source code include the above copyright\n *      notice, this list of conditions and the following disclaimer;\n *\n *   2. distributions in binary form include the above copyright\n *      notice, this list of conditions and the following disclaimer\n *      in the documentation and/or other associated materials;\n *\n *   3. the copyright holder's name is not used to endorse products\n *      built using this software without specific written permission.\n *\n * ALTERNATIVELY, provided that this notice is retained in full, this product\n * may be distributed under the terms of the GNU General Public License (GPL),\n * in which case the provisions of the GPL apply INSTEAD OF those given above.\n *\n * DISCLAIMER\n *\n * This software is provided 'as is' with no explicit or implied warranties\n * in respect of its properties, including, but not limited to, correctness\n * and/or fitness for purpose.\n * ---------------------------------------------------------------------------\n */\n\n#include <crypto/aes.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/types.h>\n#include <linux/errno.h>\n#include <linux/crypto.h>\n#include <asm/byteorder.h>\n\nstatic inline u8 byte(const u32 x, const unsigned n)\n{\n\treturn x >> (n << 3);\n}\n\nstatic const u32 rco_tab[10] = { 1, 2, 4, 8, 16, 32, 64, 128, 27, 54 };\n\n__visible const u32 crypto_ft_tab[4][256] = {\n\t{\n\t\t0xa56363c6, 0x847c7cf8, 0x997777ee, 0x8d7b7bf6,\n\t\t0x0df2f2ff, 0xbd6b6bd6, 0xb16f6fde, 0x54c5c591,\n\t\t0x50303060, 0x03010102, 0xa96767ce, 0x7d2b2b56,\n\t\t0x19fefee7, 0x62d7d7b5, 0xe6abab4d, 0x9a7676ec,\n\t\t0x45caca8f, 0x9d82821f, 0x40c9c989, 0x877d7dfa,\n\t\t0x15fafaef, 0xeb5959b2, 0xc947478e, 0x0bf0f0fb,\n\t\t0xecadad41, 0x67d4d4b3, 0xfda2a25f, 0xeaafaf45,\n\t\t0xbf9c9c23, 0xf7a4a453, 0x967272e4, 0x5bc0c09b,\n\t\t0xc2b7b775, 0x1cfdfde1, 0xae93933d, 0x6a26264c,\n\t\t0x5a36366c, 0x413f3f7e, 0x02f7f7f5, 0x4fcccc83,\n\t\t0x5c343468, 0xf4a5a551, 0x34e5e5d1, 0x08f1f1f9,\n\t\t0x937171e2, 0x73d8d8ab, 0x53313162, 0x3f15152a,\n\t\t0x0c040408, 0x52c7c795, 0x65232346, 0x5ec3c39d,\n\t\t0x28181830, 0xa1969637, 0x0f05050a, 0xb59a9a2f,\n\t\t0x0907070e, 0x36121224, 0x9b80801b, 0x3de2e2df,\n\t\t0x26ebebcd, 0x6927274e, 0xcdb2b27f, 0x9f7575ea,\n\t\t0x1b090912, 0x9e83831d, 0x742c2c58, 0x2e1a1a34,\n\t\t0x2d1b1b36, 0xb26e6edc, 0xee5a5ab4, 0xfba0a05b,\n\t\t0xf65252a4, 0x4d3b3b76, 0x61d6d6b7, 0xceb3b37d,\n\t\t0x7b292952, 0x3ee3e3dd, 0x712f2f5e, 0x97848413,\n\t\t0xf55353a6, 0x68d1d1b9, 0x00000000, 0x2cededc1,\n\t\t0x60202040, 0x1ffcfce3, 0xc8b1b179, 0xed5b5bb6,\n\t\t0xbe6a6ad4, 0x46cbcb8d, 0xd9bebe67, 0x4b393972,\n\t\t0xde4a4a94, 0xd44c4c98, 0xe85858b0, 0x4acfcf85,\n\t\t0x6bd0d0bb, 0x2aefefc5, 0xe5aaaa4f, 0x16fbfbed,\n\t\t0xc5434386, 0xd74d4d9a, 0x55333366, 0x94858511,\n\t\t0xcf45458a, 0x10f9f9e9, 0x06020204, 0x817f7ffe,\n\t\t0xf05050a0, 0x443c3c78, 0xba9f9f25, 0xe3a8a84b,\n\t\t0xf35151a2, 0xfea3a35d, 0xc0404080, 0x8a8f8f05,\n\t\t0xad92923f, 0xbc9d9d21, 0x48383870, 0x04f5f5f1,\n\t\t0xdfbcbc63, 0xc1b6b677, 0x75dadaaf, 0x63212142,\n\t\t0x30101020, 0x1affffe5, 0x0ef3f3fd, 0x6dd2d2bf,\n\t\t0x4ccdcd81, 0x140c0c18, 0x35131326, 0x2fececc3,\n\t\t0xe15f5fbe, 0xa2979735, 0xcc444488, 0x3917172e,\n\t\t0x57c4c493, 0xf2a7a755, 0x827e7efc, 0x473d3d7a,\n\t\t0xac6464c8, 0xe75d5dba, 0x2b191932, 0x957373e6,\n\t\t0xa06060c0, 0x98818119, 0xd14f4f9e, 0x7fdcdca3,\n\t\t0x66222244, 0x7e2a2a54, 0xab90903b, 0x8388880b,\n\t\t0xca46468c, 0x29eeeec7, 0xd3b8b86b, 0x3c141428,\n\t\t0x79dedea7, 0xe25e5ebc, 0x1d0b0b16, 0x76dbdbad,\n\t\t0x3be0e0db, 0x56323264, 0x4e3a3a74, 0x1e0a0a14,\n\t\t0xdb494992, 0x0a06060c, 0x6c242448, 0xe45c5cb8,\n\t\t0x5dc2c29f, 0x6ed3d3bd, 0xefacac43, 0xa66262c4,\n\t\t0xa8919139, 0xa4959531, 0x37e4e4d3, 0x8b7979f2,\n\t\t0x32e7e7d5, 0x43c8c88b, 0x5937376e, 0xb76d6dda,\n\t\t0x8c8d8d01, 0x64d5d5b1, 0xd24e4e9c, 0xe0a9a949,\n\t\t0xb46c6cd8, 0xfa5656ac, 0x07f4f4f3, 0x25eaeacf,\n\t\t0xaf6565ca, 0x8e7a7af4, 0xe9aeae47, 0x18080810,\n\t\t0xd5baba6f, 0x887878f0, 0x6f25254a, 0x722e2e5c,\n\t\t0x241c1c38, 0xf1a6a657, 0xc7b4b473, 0x51c6c697,\n\t\t0x23e8e8cb, 0x7cdddda1, 0x9c7474e8, 0x211f1f3e,\n\t\t0xdd4b4b96, 0xdcbdbd61, 0x868b8b0d, 0x858a8a0f,\n\t\t0x907070e0, 0x423e3e7c, 0xc4b5b571, 0xaa6666cc,\n\t\t0xd8484890, 0x05030306, 0x01f6f6f7, 0x120e0e1c,\n\t\t0xa36161c2, 0x5f35356a, 0xf95757ae, 0xd0b9b969,\n\t\t0x91868617, 0x58c1c199, 0x271d1d3a, 0xb99e9e27,\n\t\t0x38e1e1d9, 0x13f8f8eb, 0xb398982b, 0x33111122,\n\t\t0xbb6969d2, 0x70d9d9a9, 0x898e8e07, 0xa7949433,\n\t\t0xb69b9b2d, 0x221e1e3c, 0x92878715, 0x20e9e9c9,\n\t\t0x49cece87, 0xff5555aa, 0x78282850, 0x7adfdfa5,\n\t\t0x8f8c8c03, 0xf8a1a159, 0x80898909, 0x170d0d1a,\n\t\t0xdabfbf65, 0x31e6e6d7, 0xc6424284, 0xb86868d0,\n\t\t0xc3414182, 0xb0999929, 0x772d2d5a, 0x110f0f1e,\n\t\t0xcbb0b07b, 0xfc5454a8, 0xd6bbbb6d, 0x3a16162c,\n\t}, {\n\t\t0x6363c6a5, 0x7c7cf884, 0x7777ee99, 0x7b7bf68d,\n\t\t0xf2f2ff0d, 0x6b6bd6bd, 0x6f6fdeb1, 0xc5c59154,\n\t\t0x30306050, 0x01010203, 0x6767cea9, 0x2b2b567d,\n\t\t0xfefee719, 0xd7d7b562, 0xabab4de6, 0x7676ec9a,\n\t\t0xcaca8f45, 0x82821f9d, 0xc9c98940, 0x7d7dfa87,\n\t\t0xfafaef15, 0x5959b2eb, 0x47478ec9, 0xf0f0fb0b,\n\t\t0xadad41ec, 0xd4d4b367, 0xa2a25ffd, 0xafaf45ea,\n\t\t0x9c9c23bf, 0xa4a453f7, 0x7272e496, 0xc0c09b5b,\n\t\t0xb7b775c2, 0xfdfde11c, 0x93933dae, 0x26264c6a,\n\t\t0x36366c5a, 0x3f3f7e41, 0xf7f7f502, 0xcccc834f,\n\t\t0x3434685c, 0xa5a551f4, 0xe5e5d134, 0xf1f1f908,\n\t\t0x7171e293, 0xd8d8ab73, 0x31316253, 0x15152a3f,\n\t\t0x0404080c, 0xc7c79552, 0x23234665, 0xc3c39d5e,\n\t\t0x18183028, 0x969637a1, 0x05050a0f, 0x9a9a2fb5,\n\t\t0x07070e09, 0x12122436, 0x80801b9b, 0xe2e2df3d,\n\t\t0xebebcd26, 0x27274e69, 0xb2b27fcd, 0x7575ea9f,\n\t\t0x0909121b, 0x83831d9e, 0x2c2c5874, 0x1a1a342e,\n\t\t0x1b1b362d, 0x6e6edcb2, 0x5a5ab4ee, 0xa0a05bfb,\n\t\t0x5252a4f6, 0x3b3b764d, 0xd6d6b761, 0xb3b37dce,\n\t\t0x2929527b, 0xe3e3dd3e, 0x2f2f5e71, 0x84841397,\n\t\t0x5353a6f5, 0xd1d1b968, 0x00000000, 0xededc12c,\n\t\t0x20204060, 0xfcfce31f, 0xb1b179c8, 0x5b5bb6ed,\n\t\t0x6a6ad4be, 0xcbcb8d46, 0xbebe67d9, 0x3939724b,\n\t\t0x4a4a94de, 0x4c4c98d4, 0x5858b0e8, 0xcfcf854a,\n\t\t0xd0d0bb6b, 0xefefc52a, 0xaaaa4fe5, 0xfbfbed16,\n\t\t0x434386c5, 0x4d4d9ad7, 0x33336655, 0x85851194,\n\t\t0x45458acf, 0xf9f9e910, 0x02020406, 0x7f7ffe81,\n\t\t0x5050a0f0, 0x3c3c7844, 0x9f9f25ba, 0xa8a84be3,\n\t\t0x5151a2f3, 0xa3a35dfe, 0x404080c0, 0x8f8f058a,\n\t\t0x92923fad, 0x9d9d21bc, 0x38387048, 0xf5f5f104,\n\t\t0xbcbc63df, 0xb6b677c1, 0xdadaaf75, 0x21214263,\n\t\t0x10102030, 0xffffe51a, 0xf3f3fd0e, 0xd2d2bf6d,\n\t\t0xcdcd814c, 0x0c0c1814, 0x13132635, 0xececc32f,\n\t\t0x5f5fbee1, 0x979735a2, 0x444488cc, 0x17172e39,\n\t\t0xc4c49357, 0xa7a755f2, 0x7e7efc82, 0x3d3d7a47,\n\t\t0x6464c8ac, 0x5d5dbae7, 0x1919322b, 0x7373e695,\n\t\t0x6060c0a0, 0x81811998, 0x4f4f9ed1, 0xdcdca37f,\n\t\t0x22224466, 0x2a2a547e, 0x90903bab, 0x88880b83,\n\t\t0x46468cca, 0xeeeec729, 0xb8b86bd3, 0x1414283c,\n\t\t0xdedea779, 0x5e5ebce2, 0x0b0b161d, 0xdbdbad76,\n\t\t0xe0e0db3b, 0x32326456, 0x3a3a744e, 0x0a0a141e,\n\t\t0x494992db, 0x06060c0a, 0x2424486c, 0x5c5cb8e4,\n\t\t0xc2c29f5d, 0xd3d3bd6e, 0xacac43ef, 0x6262c4a6,\n\t\t0x919139a8, 0x959531a4, 0xe4e4d337, 0x7979f28b,\n\t\t0xe7e7d532, 0xc8c88b43, 0x37376e59, 0x6d6ddab7,\n\t\t0x8d8d018c, 0xd5d5b164, 0x4e4e9cd2, 0xa9a949e0,\n\t\t0x6c6cd8b4, 0x5656acfa, 0xf4f4f307, 0xeaeacf25,\n\t\t0x6565caaf, 0x7a7af48e, 0xaeae47e9, 0x08081018,\n\t\t0xbaba6fd5, 0x7878f088, 0x25254a6f, 0x2e2e5c72,\n\t\t0x1c1c3824, 0xa6a657f1, 0xb4b473c7, 0xc6c69751,\n\t\t0xe8e8cb23, 0xdddda17c, 0x7474e89c, 0x1f1f3e21,\n\t\t0x4b4b96dd, 0xbdbd61dc, 0x8b8b0d86, 0x8a8a0f85,\n\t\t0x7070e090, 0x3e3e7c42, 0xb5b571c4, 0x6666ccaa,\n\t\t0x484890d8, 0x03030605, 0xf6f6f701, 0x0e0e1c12,\n\t\t0x6161c2a3, 0x35356a5f, 0x5757aef9, 0xb9b969d0,\n\t\t0x86861791, 0xc1c19958, 0x1d1d3a27, 0x9e9e27b9,\n\t\t0xe1e1d938, 0xf8f8eb13, 0x98982bb3, 0x11112233,\n\t\t0x6969d2bb, 0xd9d9a970, 0x8e8e0789, 0x949433a7,\n\t\t0x9b9b2db6, 0x1e1e3c22, 0x87871592, 0xe9e9c920,\n\t\t0xcece8749, 0x5555aaff, 0x28285078, 0xdfdfa57a,\n\t\t0x8c8c038f, 0xa1a159f8, 0x89890980, 0x0d0d1a17,\n\t\t0xbfbf65da, 0xe6e6d731, 0x424284c6, 0x6868d0b8,\n\t\t0x414182c3, 0x999929b0, 0x2d2d5a77, 0x0f0f1e11,\n\t\t0xb0b07bcb, 0x5454a8fc, 0xbbbb6dd6, 0x16162c3a,\n\t}, {\n\t\t0x63c6a563, 0x7cf8847c, 0x77ee9977, 0x7bf68d7b,\n\t\t0xf2ff0df2, 0x6bd6bd6b, 0x6fdeb16f, 0xc59154c5,\n\t\t0x30605030, 0x01020301, 0x67cea967, 0x2b567d2b,\n\t\t0xfee719fe, 0xd7b562d7, 0xab4de6ab, 0x76ec9a76,\n\t\t0xca8f45ca, 0x821f9d82, 0xc98940c9, 0x7dfa877d,\n\t\t0xfaef15fa, 0x59b2eb59, 0x478ec947, 0xf0fb0bf0,\n\t\t0xad41ecad, 0xd4b367d4, 0xa25ffda2, 0xaf45eaaf,\n\t\t0x9c23bf9c, 0xa453f7a4, 0x72e49672, 0xc09b5bc0,\n\t\t0xb775c2b7, 0xfde11cfd, 0x933dae93, 0x264c6a26,\n\t\t0x366c5a36, 0x3f7e413f, 0xf7f502f7, 0xcc834fcc,\n\t\t0x34685c34, 0xa551f4a5, 0xe5d134e5, 0xf1f908f1,\n\t\t0x71e29371, 0xd8ab73d8, 0x31625331, 0x152a3f15,\n\t\t0x04080c04, 0xc79552c7, 0x23466523, 0xc39d5ec3,\n\t\t0x18302818, 0x9637a196, 0x050a0f05, 0x9a2fb59a,\n\t\t0x070e0907, 0x12243612, 0x801b9b80, 0xe2df3de2,\n\t\t0xebcd26eb, 0x274e6927, 0xb27fcdb2, 0x75ea9f75,\n\t\t0x09121b09, 0x831d9e83, 0x2c58742c, 0x1a342e1a,\n\t\t0x1b362d1b, 0x6edcb26e, 0x5ab4ee5a, 0xa05bfba0,\n\t\t0x52a4f652, 0x3b764d3b, 0xd6b761d6, 0xb37dceb3,\n\t\t0x29527b29, 0xe3dd3ee3, 0x2f5e712f, 0x84139784,\n\t\t0x53a6f553, 0xd1b968d1, 0x00000000, 0xedc12ced,\n\t\t0x20406020, 0xfce31ffc, 0xb179c8b1, 0x5bb6ed5b,\n\t\t0x6ad4be6a, 0xcb8d46cb, 0xbe67d9be, 0x39724b39,\n\t\t0x4a94de4a, 0x4c98d44c, 0x58b0e858, 0xcf854acf,\n\t\t0xd0bb6bd0, 0xefc52aef, 0xaa4fe5aa, 0xfbed16fb,\n\t\t0x4386c543, 0x4d9ad74d, 0x33665533, 0x85119485,\n\t\t0x458acf45, 0xf9e910f9, 0x02040602, 0x7ffe817f,\n\t\t0x50a0f050, 0x3c78443c, 0x9f25ba9f, 0xa84be3a8,\n\t\t0x51a2f351, 0xa35dfea3, 0x4080c040, 0x8f058a8f,\n\t\t0x923fad92, 0x9d21bc9d, 0x38704838, 0xf5f104f5,\n\t\t0xbc63dfbc, 0xb677c1b6, 0xdaaf75da, 0x21426321,\n\t\t0x10203010, 0xffe51aff, 0xf3fd0ef3, 0xd2bf6dd2,\n\t\t0xcd814ccd, 0x0c18140c, 0x13263513, 0xecc32fec,\n\t\t0x5fbee15f, 0x9735a297, 0x4488cc44, 0x172e3917,\n\t\t0xc49357c4, 0xa755f2a7, 0x7efc827e, 0x3d7a473d,\n\t\t0x64c8ac64, 0x5dbae75d, 0x19322b19, 0x73e69573,\n\t\t0x60c0a060, 0x81199881, 0x4f9ed14f, 0xdca37fdc,\n\t\t0x22446622, 0x2a547e2a, 0x903bab90, 0x880b8388,\n\t\t0x468cca46, 0xeec729ee, 0xb86bd3b8, 0x14283c14,\n\t\t0xdea779de, 0x5ebce25e, 0x0b161d0b, 0xdbad76db,\n\t\t0xe0db3be0, 0x32645632, 0x3a744e3a, 0x0a141e0a,\n\t\t0x4992db49, 0x060c0a06, 0x24486c24, 0x5cb8e45c,\n\t\t0xc29f5dc2, 0xd3bd6ed3, 0xac43efac, 0x62c4a662,\n\t\t0x9139a891, 0x9531a495, 0xe4d337e4, 0x79f28b79,\n\t\t0xe7d532e7, 0xc88b43c8, 0x376e5937, 0x6ddab76d,\n\t\t0x8d018c8d, 0xd5b164d5, 0x4e9cd24e, 0xa949e0a9,\n\t\t0x6cd8b46c, 0x56acfa56, 0xf4f307f4, 0xeacf25ea,\n\t\t0x65caaf65, 0x7af48e7a, 0xae47e9ae, 0x08101808,\n\t\t0xba6fd5ba, 0x78f08878, 0x254a6f25, 0x2e5c722e,\n\t\t0x1c38241c, 0xa657f1a6, 0xb473c7b4, 0xc69751c6,\n\t\t0xe8cb23e8, 0xdda17cdd, 0x74e89c74, 0x1f3e211f,\n\t\t0x4b96dd4b, 0xbd61dcbd, 0x8b0d868b, 0x8a0f858a,\n\t\t0x70e09070, 0x3e7c423e, 0xb571c4b5, 0x66ccaa66,\n\t\t0x4890d848, 0x03060503, 0xf6f701f6, 0x0e1c120e,\n\t\t0x61c2a361, 0x356a5f35, 0x57aef957, 0xb969d0b9,\n\t\t0x86179186, 0xc19958c1, 0x1d3a271d, 0x9e27b99e,\n\t\t0xe1d938e1, 0xf8eb13f8, 0x982bb398, 0x11223311,\n\t\t0x69d2bb69, 0xd9a970d9, 0x8e07898e, 0x9433a794,\n\t\t0x9b2db69b, 0x1e3c221e, 0x87159287, 0xe9c920e9,\n\t\t0xce8749ce, 0x55aaff55, 0x28507828, 0xdfa57adf,\n\t\t0x8c038f8c, 0xa159f8a1, 0x89098089, 0x0d1a170d,\n\t\t0xbf65dabf, 0xe6d731e6, 0x4284c642, 0x68d0b868,\n\t\t0x4182c341, 0x9929b099, 0x2d5a772d, 0x0f1e110f,\n\t\t0xb07bcbb0, 0x54a8fc54, 0xbb6dd6bb, 0x162c3a16,\n\t}, {\n\t\t0xc6a56363, 0xf8847c7c, 0xee997777, 0xf68d7b7b,\n\t\t0xff0df2f2, 0xd6bd6b6b, 0xdeb16f6f, 0x9154c5c5,\n\t\t0x60503030, 0x02030101, 0xcea96767, 0x567d2b2b,\n\t\t0xe719fefe, 0xb562d7d7, 0x4de6abab, 0xec9a7676,\n\t\t0x8f45caca, 0x1f9d8282, 0x8940c9c9, 0xfa877d7d,\n\t\t0xef15fafa, 0xb2eb5959, 0x8ec94747, 0xfb0bf0f0,\n\t\t0x41ecadad, 0xb367d4d4, 0x5ffda2a2, 0x45eaafaf,\n\t\t0x23bf9c9c, 0x53f7a4a4, 0xe4967272, 0x9b5bc0c0,\n\t\t0x75c2b7b7, 0xe11cfdfd, 0x3dae9393, 0x4c6a2626,\n\t\t0x6c5a3636, 0x7e413f3f, 0xf502f7f7, 0x834fcccc,\n\t\t0x685c3434, 0x51f4a5a5, 0xd134e5e5, 0xf908f1f1,\n\t\t0xe2937171, 0xab73d8d8, 0x62533131, 0x2a3f1515,\n\t\t0x080c0404, 0x9552c7c7, 0x46652323, 0x9d5ec3c3,\n\t\t0x30281818, 0x37a19696, 0x0a0f0505, 0x2fb59a9a,\n\t\t0x0e090707, 0x24361212, 0x1b9b8080, 0xdf3de2e2,\n\t\t0xcd26ebeb, 0x4e692727, 0x7fcdb2b2, 0xea9f7575,\n\t\t0x121b0909, 0x1d9e8383, 0x58742c2c, 0x342e1a1a,\n\t\t0x362d1b1b, 0xdcb26e6e, 0xb4ee5a5a, 0x5bfba0a0,\n\t\t0xa4f65252, 0x764d3b3b, 0xb761d6d6, 0x7dceb3b3,\n\t\t0x527b2929, 0xdd3ee3e3, 0x5e712f2f, 0x13978484,\n\t\t0xa6f55353, 0xb968d1d1, 0x00000000, 0xc12ceded,\n\t\t0x40602020, 0xe31ffcfc, 0x79c8b1b1, 0xb6ed5b5b,\n\t\t0xd4be6a6a, 0x8d46cbcb, 0x67d9bebe, 0x724b3939,\n\t\t0x94de4a4a, 0x98d44c4c, 0xb0e85858, 0x854acfcf,\n\t\t0xbb6bd0d0, 0xc52aefef, 0x4fe5aaaa, 0xed16fbfb,\n\t\t0x86c54343, 0x9ad74d4d, 0x66553333, 0x11948585,\n\t\t0x8acf4545, 0xe910f9f9, 0x04060202, 0xfe817f7f,\n\t\t0xa0f05050, 0x78443c3c, 0x25ba9f9f, 0x4be3a8a8,\n\t\t0xa2f35151, 0x5dfea3a3, 0x80c04040, 0x058a8f8f,\n\t\t0x3fad9292, 0x21bc9d9d, 0x70483838, 0xf104f5f5,\n\t\t0x63dfbcbc, 0x77c1b6b6, 0xaf75dada, 0x42632121,\n\t\t0x20301010, 0xe51affff, 0xfd0ef3f3, 0xbf6dd2d2,\n\t\t0x814ccdcd, 0x18140c0c, 0x26351313, 0xc32fecec,\n\t\t0xbee15f5f, 0x35a29797, 0x88cc4444, 0x2e391717,\n\t\t0x9357c4c4, 0x55f2a7a7, 0xfc827e7e, 0x7a473d3d,\n\t\t0xc8ac6464, 0xbae75d5d, 0x322b1919, 0xe6957373,\n\t\t0xc0a06060, 0x19988181, 0x9ed14f4f, 0xa37fdcdc,\n\t\t0x44662222, 0x547e2a2a, 0x3bab9090, 0x0b838888,\n\t\t0x8cca4646, 0xc729eeee, 0x6bd3b8b8, 0x283c1414,\n\t\t0xa779dede, 0xbce25e5e, 0x161d0b0b, 0xad76dbdb,\n\t\t0xdb3be0e0, 0x64563232, 0x744e3a3a, 0x141e0a0a,\n\t\t0x92db4949, 0x0c0a0606, 0x486c2424, 0xb8e45c5c,\n\t\t0x9f5dc2c2, 0xbd6ed3d3, 0x43efacac, 0xc4a66262,\n\t\t0x39a89191, 0x31a49595, 0xd337e4e4, 0xf28b7979,\n\t\t0xd532e7e7, 0x8b43c8c8, 0x6e593737, 0xdab76d6d,\n\t\t0x018c8d8d, 0xb164d5d5, 0x9cd24e4e, 0x49e0a9a9,\n\t\t0xd8b46c6c, 0xacfa5656, 0xf307f4f4, 0xcf25eaea,\n\t\t0xcaaf6565, 0xf48e7a7a, 0x47e9aeae, 0x10180808,\n\t\t0x6fd5baba, 0xf0887878, 0x4a6f2525, 0x5c722e2e,\n\t\t0x38241c1c, 0x57f1a6a6, 0x73c7b4b4, 0x9751c6c6,\n\t\t0xcb23e8e8, 0xa17cdddd, 0xe89c7474, 0x3e211f1f,\n\t\t0x96dd4b4b, 0x61dcbdbd, 0x0d868b8b, 0x0f858a8a,\n\t\t0xe0907070, 0x7c423e3e, 0x71c4b5b5, 0xccaa6666,\n\t\t0x90d84848, 0x06050303, 0xf701f6f6, 0x1c120e0e,\n\t\t0xc2a36161, 0x6a5f3535, 0xaef95757, 0x69d0b9b9,\n\t\t0x17918686, 0x9958c1c1, 0x3a271d1d, 0x27b99e9e,\n\t\t0xd938e1e1, 0xeb13f8f8, 0x2bb39898, 0x22331111,\n\t\t0xd2bb6969, 0xa970d9d9, 0x07898e8e, 0x33a79494,\n\t\t0x2db69b9b, 0x3c221e1e, 0x15928787, 0xc920e9e9,\n\t\t0x8749cece, 0xaaff5555, 0x50782828, 0xa57adfdf,\n\t\t0x038f8c8c, 0x59f8a1a1, 0x09808989, 0x1a170d0d,\n\t\t0x65dabfbf, 0xd731e6e6, 0x84c64242, 0xd0b86868,\n\t\t0x82c34141, 0x29b09999, 0x5a772d2d, 0x1e110f0f,\n\t\t0x7bcbb0b0, 0xa8fc5454, 0x6dd6bbbb, 0x2c3a1616,\n\t}\n};\n\n__visible const u32 crypto_fl_tab[4][256] = {\n\t{\n\t\t0x00000063, 0x0000007c, 0x00000077, 0x0000007b,\n\t\t0x000000f2, 0x0000006b, 0x0000006f, 0x000000c5,\n\t\t0x00000030, 0x00000001, 0x00000067, 0x0000002b,\n\t\t0x000000fe, 0x000000d7, 0x000000ab, 0x00000076,\n\t\t0x000000ca, 0x00000082, 0x000000c9, 0x0000007d,\n\t\t0x000000fa, 0x00000059, 0x00000047, 0x000000f0,\n\t\t0x000000ad, 0x000000d4, 0x000000a2, 0x000000af,\n\t\t0x0000009c, 0x000000a4, 0x00000072, 0x000000c0,\n\t\t0x000000b7, 0x000000fd, 0x00000093, 0x00000026,\n\t\t0x00000036, 0x0000003f, 0x000000f7, 0x000000cc,\n\t\t0x00000034, 0x000000a5, 0x000000e5, 0x000000f1,\n\t\t0x00000071, 0x000000d8, 0x00000031, 0x00000015,\n\t\t0x00000004, 0x000000c7, 0x00000023, 0x000000c3,\n\t\t0x00000018, 0x00000096, 0x00000005, 0x0000009a,\n\t\t0x00000007, 0x00000012, 0x00000080, 0x000000e2,\n\t\t0x000000eb, 0x00000027, 0x000000b2, 0x00000075,\n\t\t0x00000009, 0x00000083, 0x0000002c, 0x0000001a,\n\t\t0x0000001b, 0x0000006e, 0x0000005a, 0x000000a0,\n\t\t0x00000052, 0x0000003b, 0x000000d6, 0x000000b3,\n\t\t0x00000029, 0x000000e3, 0x0000002f, 0x00000084,\n\t\t0x00000053, 0x000000d1, 0x00000000, 0x000000ed,\n\t\t0x00000020, 0x000000fc, 0x000000b1, 0x0000005b,\n\t\t0x0000006a, 0x000000cb, 0x000000be, 0x00000039,\n\t\t0x0000004a, 0x0000004c, 0x00000058, 0x000000cf,\n\t\t0x000000d0, 0x000000ef, 0x000000aa, 0x000000fb,\n\t\t0x00000043, 0x0000004d, 0x00000033, 0x00000085,\n\t\t0x00000045, 0x000000f9, 0x00000002, 0x0000007f,\n\t\t0x00000050, 0x0000003c, 0x0000009f, 0x000000a8,\n\t\t0x00000051, 0x000000a3, 0x00000040, 0x0000008f,\n\t\t0x00000092, 0x0000009d, 0x00000038, 0x000000f5,\n\t\t0x000000bc, 0x000000b6, 0x000000da, 0x00000021,\n\t\t0x00000010, 0x000000ff, 0x000000f3, 0x000000d2,\n\t\t0x000000cd, 0x0000000c, 0x00000013, 0x000000ec,\n\t\t0x0000005f, 0x00000097, 0x00000044, 0x00000017,\n\t\t0x000000c4, 0x000000a7, 0x0000007e, 0x0000003d,\n\t\t0x00000064, 0x0000005d, 0x00000019, 0x00000073,\n\t\t0x00000060, 0x00000081, 0x0000004f, 0x000000dc,\n\t\t0x00000022, 0x0000002a, 0x00000090, 0x00000088,\n\t\t0x00000046, 0x000000ee, 0x000000b8, 0x00000014,\n\t\t0x000000de, 0x0000005e, 0x0000000b, 0x000000db,\n\t\t0x000000e0, 0x00000032, 0x0000003a, 0x0000000a,\n\t\t0x00000049, 0x00000006, 0x00000024, 0x0000005c,\n\t\t0x000000c2, 0x000000d3, 0x000000ac, 0x00000062,\n\t\t0x00000091, 0x00000095, 0x000000e4, 0x00000079,\n\t\t0x000000e7, 0x000000c8, 0x00000037, 0x0000006d,\n\t\t0x0000008d, 0x000000d5, 0x0000004e, 0x000000a9,\n\t\t0x0000006c, 0x00000056, 0x000000f4, 0x000000ea,\n\t\t0x00000065, 0x0000007a, 0x000000ae, 0x00000008,\n\t\t0x000000ba, 0x00000078, 0x00000025, 0x0000002e,\n\t\t0x0000001c, 0x000000a6, 0x000000b4, 0x000000c6,\n\t\t0x000000e8, 0x000000dd, 0x00000074, 0x0000001f,\n\t\t0x0000004b, 0x000000bd, 0x0000008b, 0x0000008a,\n\t\t0x00000070, 0x0000003e, 0x000000b5, 0x00000066,\n\t\t0x00000048, 0x00000003, 0x000000f6, 0x0000000e,\n\t\t0x00000061, 0x00000035, 0x00000057, 0x000000b9,\n\t\t0x00000086, 0x000000c1, 0x0000001d, 0x0000009e,\n\t\t0x000000e1, 0x000000f8, 0x00000098, 0x00000011,\n\t\t0x00000069, 0x000000d9, 0x0000008e, 0x00000094,\n\t\t0x0000009b, 0x0000001e, 0x00000087, 0x000000e9,\n\t\t0x000000ce, 0x00000055, 0x00000028, 0x000000df,\n\t\t0x0000008c, 0x000000a1, 0x00000089, 0x0000000d,\n\t\t0x000000bf, 0x000000e6, 0x00000042, 0x00000068,\n\t\t0x00000041, 0x00000099, 0x0000002d, 0x0000000f,\n\t\t0x000000b0, 0x00000054, 0x000000bb, 0x00000016,\n\t}, {\n\t\t0x00006300, 0x00007c00, 0x00007700, 0x00007b00,\n\t\t0x0000f200, 0x00006b00, 0x00006f00, 0x0000c500,\n\t\t0x00003000, 0x00000100, 0x00006700, 0x00002b00,\n\t\t0x0000fe00, 0x0000d700, 0x0000ab00, 0x00007600,\n\t\t0x0000ca00, 0x00008200, 0x0000c900, 0x00007d00,\n\t\t0x0000fa00, 0x00005900, 0x00004700, 0x0000f000,\n\t\t0x0000ad00, 0x0000d400, 0x0000a200, 0x0000af00,\n\t\t0x00009c00, 0x0000a400, 0x00007200, 0x0000c000,\n\t\t0x0000b700, 0x0000fd00, 0x00009300, 0x00002600,\n\t\t0x00003600, 0x00003f00, 0x0000f700, 0x0000cc00,\n\t\t0x00003400, 0x0000a500, 0x0000e500, 0x0000f100,\n\t\t0x00007100, 0x0000d800, 0x00003100, 0x00001500,\n\t\t0x00000400, 0x0000c700, 0x00002300, 0x0000c300,\n\t\t0x00001800, 0x00009600, 0x00000500, 0x00009a00,\n\t\t0x00000700, 0x00001200, 0x00008000, 0x0000e200,\n\t\t0x0000eb00, 0x00002700, 0x0000b200, 0x00007500,\n\t\t0x00000900, 0x00008300, 0x00002c00, 0x00001a00,\n\t\t0x00001b00, 0x00006e00, 0x00005a00, 0x0000a000,\n\t\t0x00005200, 0x00003b00, 0x0000d600, 0x0000b300,\n\t\t0x00002900, 0x0000e300, 0x00002f00, 0x00008400,\n\t\t0x00005300, 0x0000d100, 0x00000000, 0x0000ed00,\n\t\t0x00002000, 0x0000fc00, 0x0000b100, 0x00005b00,\n\t\t0x00006a00, 0x0000cb00, 0x0000be00, 0x00003900,\n\t\t0x00004a00, 0x00004c00, 0x00005800, 0x0000cf00,\n\t\t0x0000d000, 0x0000ef00, 0x0000aa00, 0x0000fb00,\n\t\t0x00004300, 0x00004d00, 0x00003300, 0x00008500,\n\t\t0x00004500, 0x0000f900, 0x00000200, 0x00007f00,\n\t\t0x00005000, 0x00003c00, 0x00009f00, 0x0000a800,\n\t\t0x00005100, 0x0000a300, 0x00004000, 0x00008f00,\n\t\t0x00009200, 0x00009d00, 0x00003800, 0x0000f500,\n\t\t0x0000bc00, 0x0000b600, 0x0000da00, 0x00002100,\n\t\t0x00001000, 0x0000ff00, 0x0000f300, 0x0000d200,\n\t\t0x0000cd00, 0x00000c00, 0x00001300, 0x0000ec00,\n\t\t0x00005f00, 0x00009700, 0x00004400, 0x00001700,\n\t\t0x0000c400, 0x0000a700, 0x00007e00, 0x00003d00,\n\t\t0x00006400, 0x00005d00, 0x00001900, 0x00007300,\n\t\t0x00006000, 0x00008100, 0x00004f00, 0x0000dc00,\n\t\t0x00002200, 0x00002a00, 0x00009000, 0x00008800,\n\t\t0x00004600, 0x0000ee00, 0x0000b800, 0x00001400,\n\t\t0x0000de00, 0x00005e00, 0x00000b00, 0x0000db00,\n\t\t0x0000e000, 0x00003200, 0x00003a00, 0x00000a00,\n\t\t0x00004900, 0x00000600, 0x00002400, 0x00005c00,\n\t\t0x0000c200, 0x0000d300, 0x0000ac00, 0x00006200,\n\t\t0x00009100, 0x00009500, 0x0000e400, 0x00007900,\n\t\t0x0000e700, 0x0000c800, 0x00003700, 0x00006d00,\n\t\t0x00008d00, 0x0000d500, 0x00004e00, 0x0000a900,\n\t\t0x00006c00, 0x00005600, 0x0000f400, 0x0000ea00,\n\t\t0x00006500, 0x00007a00, 0x0000ae00, 0x00000800,\n\t\t0x0000ba00, 0x00007800, 0x00002500, 0x00002e00,\n\t\t0x00001c00, 0x0000a600, 0x0000b400, 0x0000c600,\n\t\t0x0000e800, 0x0000dd00, 0x00007400, 0x00001f00,\n\t\t0x00004b00, 0x0000bd00, 0x00008b00, 0x00008a00,\n\t\t0x00007000, 0x00003e00, 0x0000b500, 0x00006600,\n\t\t0x00004800, 0x00000300, 0x0000f600, 0x00000e00,\n\t\t0x00006100, 0x00003500, 0x00005700, 0x0000b900,\n\t\t0x00008600, 0x0000c100, 0x00001d00, 0x00009e00,\n\t\t0x0000e100, 0x0000f800, 0x00009800, 0x00001100,\n\t\t0x00006900, 0x0000d900, 0x00008e00, 0x00009400,\n\t\t0x00009b00, 0x00001e00, 0x00008700, 0x0000e900,\n\t\t0x0000ce00, 0x00005500, 0x00002800, 0x0000df00,\n\t\t0x00008c00, 0x0000a100, 0x00008900, 0x00000d00,\n\t\t0x0000bf00, 0x0000e600, 0x00004200, 0x00006800,\n\t\t0x00004100, 0x00009900, 0x00002d00, 0x00000f00,\n\t\t0x0000b000, 0x00005400, 0x0000bb00, 0x00001600,\n\t}, {\n\t\t0x00630000, 0x007c0000, 0x00770000, 0x007b0000,\n\t\t0x00f20000, 0x006b0000, 0x006f0000, 0x00c50000,\n\t\t0x00300000, 0x00010000, 0x00670000, 0x002b0000,\n\t\t0x00fe0000, 0x00d70000, 0x00ab0000, 0x00760000,\n\t\t0x00ca0000, 0x00820000, 0x00c90000, 0x007d0000,\n\t\t0x00fa0000, 0x00590000, 0x00470000, 0x00f00000,\n\t\t0x00ad0000, 0x00d40000, 0x00a20000, 0x00af0000,\n\t\t0x009c0000, 0x00a40000, 0x00720000, 0x00c00000,\n\t\t0x00b70000, 0x00fd0000, 0x00930000, 0x00260000,\n\t\t0x00360000, 0x003f0000, 0x00f70000, 0x00cc0000,\n\t\t0x00340000, 0x00a50000, 0x00e50000, 0x00f10000,\n\t\t0x00710000, 0x00d80000, 0x00310000, 0x00150000,\n\t\t0x00040000, 0x00c70000, 0x00230000, 0x00c30000,\n\t\t0x00180000, 0x00960000, 0x00050000, 0x009a0000,\n\t\t0x00070000, 0x00120000, 0x00800000, 0x00e20000,\n\t\t0x00eb0000, 0x00270000, 0x00b20000, 0x00750000,\n\t\t0x00090000, 0x00830000, 0x002c0000, 0x001a0000,\n\t\t0x001b0000, 0x006e0000, 0x005a0000, 0x00a00000,\n\t\t0x00520000, 0x003b0000, 0x00d60000, 0x00b30000,\n\t\t0x00290000, 0x00e30000, 0x002f0000, 0x00840000,\n\t\t0x00530000, 0x00d10000, 0x00000000, 0x00ed0000,\n\t\t0x00200000, 0x00fc0000, 0x00b10000, 0x005b0000,\n\t\t0x006a0000, 0x00cb0000, 0x00be0000, 0x00390000,\n\t\t0x004a0000, 0x004c0000, 0x00580000, 0x00cf0000,\n\t\t0x00d00000, 0x00ef0000, 0x00aa0000, 0x00fb0000,\n\t\t0x00430000, 0x004d0000, 0x00330000, 0x00850000,\n\t\t0x00450000, 0x00f90000, 0x00020000, 0x007f0000,\n\t\t0x00500000, 0x003c0000, 0x009f0000, 0x00a80000,\n\t\t0x00510000, 0x00a30000, 0x00400000, 0x008f0000,\n\t\t0x00920000, 0x009d0000, 0x00380000, 0x00f50000,\n\t\t0x00bc0000, 0x00b60000, 0x00da0000, 0x00210000,\n\t\t0x00100000, 0x00ff0000, 0x00f30000, 0x00d20000,\n\t\t0x00cd0000, 0x000c0000, 0x00130000, 0x00ec0000,\n\t\t0x005f0000, 0x00970000, 0x00440000, 0x00170000,\n\t\t0x00c40000, 0x00a70000, 0x007e0000, 0x003d0000,\n\t\t0x00640000, 0x005d0000, 0x00190000, 0x00730000,\n\t\t0x00600000, 0x00810000, 0x004f0000, 0x00dc0000,\n\t\t0x00220000, 0x002a0000, 0x00900000, 0x00880000,\n\t\t0x00460000, 0x00ee0000, 0x00b80000, 0x00140000,\n\t\t0x00de0000, 0x005e0000, 0x000b0000, 0x00db0000,\n\t\t0x00e00000, 0x00320000, 0x003a0000, 0x000a0000,\n\t\t0x00490000, 0x00060000, 0x00240000, 0x005c0000,\n\t\t0x00c20000, 0x00d30000, 0x00ac0000, 0x00620000,\n\t\t0x00910000, 0x00950000, 0x00e40000, 0x00790000,\n\t\t0x00e70000, 0x00c80000, 0x00370000, 0x006d0000,\n\t\t0x008d0000, 0x00d50000, 0x004e0000, 0x00a90000,\n\t\t0x006c0000, 0x00560000, 0x00f40000, 0x00ea0000,\n\t\t0x00650000, 0x007a0000, 0x00ae0000, 0x00080000,\n\t\t0x00ba0000, 0x00780000, 0x00250000, 0x002e0000,\n\t\t0x001c0000, 0x00a60000, 0x00b40000, 0x00c60000,\n\t\t0x00e80000, 0x00dd0000, 0x00740000, 0x001f0000,\n\t\t0x004b0000, 0x00bd0000, 0x008b0000, 0x008a0000,\n\t\t0x00700000, 0x003e0000, 0x00b50000, 0x00660000,\n\t\t0x00480000, 0x00030000, 0x00f60000, 0x000e0000,\n\t\t0x00610000, 0x00350000, 0x00570000, 0x00b90000,\n\t\t0x00860000, 0x00c10000, 0x001d0000, 0x009e0000,\n\t\t0x00e10000, 0x00f80000, 0x00980000, 0x00110000,\n\t\t0x00690000, 0x00d90000, 0x008e0000, 0x00940000,\n\t\t0x009b0000, 0x001e0000, 0x00870000, 0x00e90000,\n\t\t0x00ce0000, 0x00550000, 0x00280000, 0x00df0000,\n\t\t0x008c0000, 0x00a10000, 0x00890000, 0x000d0000,\n\t\t0x00bf0000, 0x00e60000, 0x00420000, 0x00680000,\n\t\t0x00410000, 0x00990000, 0x002d0000, 0x000f0000,\n\t\t0x00b00000, 0x00540000, 0x00bb0000, 0x00160000,\n\t}, {\n\t\t0x63000000, 0x7c000000, 0x77000000, 0x7b000000,\n\t\t0xf2000000, 0x6b000000, 0x6f000000, 0xc5000000,\n\t\t0x30000000, 0x01000000, 0x67000000, 0x2b000000,\n\t\t0xfe000000, 0xd7000000, 0xab000000, 0x76000000,\n\t\t0xca000000, 0x82000000, 0xc9000000, 0x7d000000,\n\t\t0xfa000000, 0x59000000, 0x47000000, 0xf0000000,\n\t\t0xad000000, 0xd4000000, 0xa2000000, 0xaf000000,\n\t\t0x9c000000, 0xa4000000, 0x72000000, 0xc0000000,\n\t\t0xb7000000, 0xfd000000, 0x93000000, 0x26000000,\n\t\t0x36000000, 0x3f000000, 0xf7000000, 0xcc000000,\n\t\t0x34000000, 0xa5000000, 0xe5000000, 0xf1000000,\n\t\t0x71000000, 0xd8000000, 0x31000000, 0x15000000,\n\t\t0x04000000, 0xc7000000, 0x23000000, 0xc3000000,\n\t\t0x18000000, 0x96000000, 0x05000000, 0x9a000000,\n\t\t0x07000000, 0x12000000, 0x80000000, 0xe2000000,\n\t\t0xeb000000, 0x27000000, 0xb2000000, 0x75000000,\n\t\t0x09000000, 0x83000000, 0x2c000000, 0x1a000000,\n\t\t0x1b000000, 0x6e000000, 0x5a000000, 0xa0000000,\n\t\t0x52000000, 0x3b000000, 0xd6000000, 0xb3000000,\n\t\t0x29000000, 0xe3000000, 0x2f000000, 0x84000000,\n\t\t0x53000000, 0xd1000000, 0x00000000, 0xed000000,\n\t\t0x20000000, 0xfc000000, 0xb1000000, 0x5b000000,\n\t\t0x6a000000, 0xcb000000, 0xbe000000, 0x39000000,\n\t\t0x4a000000, 0x4c000000, 0x58000000, 0xcf000000,\n\t\t0xd0000000, 0xef000000, 0xaa000000, 0xfb000000,\n\t\t0x43000000, 0x4d000000, 0x33000000, 0x85000000,\n\t\t0x45000000, 0xf9000000, 0x02000000, 0x7f000000,\n\t\t0x50000000, 0x3c000000, 0x9f000000, 0xa8000000,\n\t\t0x51000000, 0xa3000000, 0x40000000, 0x8f000000,\n\t\t0x92000000, 0x9d000000, 0x38000000, 0xf5000000,\n\t\t0xbc000000, 0xb6000000, 0xda000000, 0x21000000,\n\t\t0x10000000, 0xff000000, 0xf3000000, 0xd2000000,\n\t\t0xcd000000, 0x0c000000, 0x13000000, 0xec000000,\n\t\t0x5f000000, 0x97000000, 0x44000000, 0x17000000,\n\t\t0xc4000000, 0xa7000000, 0x7e000000, 0x3d000000,\n\t\t0x64000000, 0x5d000000, 0x19000000, 0x73000000,\n\t\t0x60000000, 0x81000000, 0x4f000000, 0xdc000000,\n\t\t0x22000000, 0x2a000000, 0x90000000, 0x88000000,\n\t\t0x46000000, 0xee000000, 0xb8000000, 0x14000000,\n\t\t0xde000000, 0x5e000000, 0x0b000000, 0xdb000000,\n\t\t0xe0000000, 0x32000000, 0x3a000000, 0x0a000000,\n\t\t0x49000000, 0x06000000, 0x24000000, 0x5c000000,\n\t\t0xc2000000, 0xd3000000, 0xac000000, 0x62000000,\n\t\t0x91000000, 0x95000000, 0xe4000000, 0x79000000,\n\t\t0xe7000000, 0xc8000000, 0x37000000, 0x6d000000,\n\t\t0x8d000000, 0xd5000000, 0x4e000000, 0xa9000000,\n\t\t0x6c000000, 0x56000000, 0xf4000000, 0xea000000,\n\t\t0x65000000, 0x7a000000, 0xae000000, 0x08000000,\n\t\t0xba000000, 0x78000000, 0x25000000, 0x2e000000,\n\t\t0x1c000000, 0xa6000000, 0xb4000000, 0xc6000000,\n\t\t0xe8000000, 0xdd000000, 0x74000000, 0x1f000000,\n\t\t0x4b000000, 0xbd000000, 0x8b000000, 0x8a000000,\n\t\t0x70000000, 0x3e000000, 0xb5000000, 0x66000000,\n\t\t0x48000000, 0x03000000, 0xf6000000, 0x0e000000,\n\t\t0x61000000, 0x35000000, 0x57000000, 0xb9000000,\n\t\t0x86000000, 0xc1000000, 0x1d000000, 0x9e000000,\n\t\t0xe1000000, 0xf8000000, 0x98000000, 0x11000000,\n\t\t0x69000000, 0xd9000000, 0x8e000000, 0x94000000,\n\t\t0x9b000000, 0x1e000000, 0x87000000, 0xe9000000,\n\t\t0xce000000, 0x55000000, 0x28000000, 0xdf000000,\n\t\t0x8c000000, 0xa1000000, 0x89000000, 0x0d000000,\n\t\t0xbf000000, 0xe6000000, 0x42000000, 0x68000000,\n\t\t0x41000000, 0x99000000, 0x2d000000, 0x0f000000,\n\t\t0xb0000000, 0x54000000, 0xbb000000, 0x16000000,\n\t}\n};\n\n__visible const u32 crypto_it_tab[4][256] = {\n\t{\n\t\t0x50a7f451, 0x5365417e, 0xc3a4171a, 0x965e273a,\n\t\t0xcb6bab3b, 0xf1459d1f, 0xab58faac, 0x9303e34b,\n\t\t0x55fa3020, 0xf66d76ad, 0x9176cc88, 0x254c02f5,\n\t\t0xfcd7e54f, 0xd7cb2ac5, 0x80443526, 0x8fa362b5,\n\t\t0x495ab1de, 0x671bba25, 0x980eea45, 0xe1c0fe5d,\n\t\t0x02752fc3, 0x12f04c81, 0xa397468d, 0xc6f9d36b,\n\t\t0xe75f8f03, 0x959c9215, 0xeb7a6dbf, 0xda595295,\n\t\t0x2d83bed4, 0xd3217458, 0x2969e049, 0x44c8c98e,\n\t\t0x6a89c275, 0x78798ef4, 0x6b3e5899, 0xdd71b927,\n\t\t0xb64fe1be, 0x17ad88f0, 0x66ac20c9, 0xb43ace7d,\n\t\t0x184adf63, 0x82311ae5, 0x60335197, 0x457f5362,\n\t\t0xe07764b1, 0x84ae6bbb, 0x1ca081fe, 0x942b08f9,\n\t\t0x58684870, 0x19fd458f, 0x876cde94, 0xb7f87b52,\n\t\t0x23d373ab, 0xe2024b72, 0x578f1fe3, 0x2aab5566,\n\t\t0x0728ebb2, 0x03c2b52f, 0x9a7bc586, 0xa50837d3,\n\t\t0xf2872830, 0xb2a5bf23, 0xba6a0302, 0x5c8216ed,\n\t\t0x2b1ccf8a, 0x92b479a7, 0xf0f207f3, 0xa1e2694e,\n\t\t0xcdf4da65, 0xd5be0506, 0x1f6234d1, 0x8afea6c4,\n\t\t0x9d532e34, 0xa055f3a2, 0x32e18a05, 0x75ebf6a4,\n\t\t0x39ec830b, 0xaaef6040, 0x069f715e, 0x51106ebd,\n\t\t0xf98a213e, 0x3d06dd96, 0xae053edd, 0x46bde64d,\n\t\t0xb58d5491, 0x055dc471, 0x6fd40604, 0xff155060,\n\t\t0x24fb9819, 0x97e9bdd6, 0xcc434089, 0x779ed967,\n\t\t0xbd42e8b0, 0x888b8907, 0x385b19e7, 0xdbeec879,\n\t\t0x470a7ca1, 0xe90f427c, 0xc91e84f8, 0x00000000,\n\t\t0x83868009, 0x48ed2b32, 0xac70111e, 0x4e725a6c,\n\t\t0xfbff0efd, 0x5638850f, 0x1ed5ae3d, 0x27392d36,\n\t\t0x64d90f0a, 0x21a65c68, 0xd1545b9b, 0x3a2e3624,\n\t\t0xb1670a0c, 0x0fe75793, 0xd296eeb4, 0x9e919b1b,\n\t\t0x4fc5c080, 0xa220dc61, 0x694b775a, 0x161a121c,\n\t\t0x0aba93e2, 0xe52aa0c0, 0x43e0223c, 0x1d171b12,\n\t\t0x0b0d090e, 0xadc78bf2, 0xb9a8b62d, 0xc8a91e14,\n\t\t0x8519f157, 0x4c0775af, 0xbbdd99ee, 0xfd607fa3,\n\t\t0x9f2601f7, 0xbcf5725c, 0xc53b6644, 0x347efb5b,\n\t\t0x7629438b, 0xdcc623cb, 0x68fcedb6, 0x63f1e4b8,\n\t\t0xcadc31d7, 0x10856342, 0x40229713, 0x2011c684,\n\t\t0x7d244a85, 0xf83dbbd2, 0x1132f9ae, 0x6da129c7,\n\t\t0x4b2f9e1d, 0xf330b2dc, 0xec52860d, 0xd0e3c177,\n\t\t0x6c16b32b, 0x99b970a9, 0xfa489411, 0x2264e947,\n\t\t0xc48cfca8, 0x1a3ff0a0, 0xd82c7d56, 0xef903322,\n\t\t0xc74e4987, 0xc1d138d9, 0xfea2ca8c, 0x360bd498,\n\t\t0xcf81f5a6, 0x28de7aa5, 0x268eb7da, 0xa4bfad3f,\n\t\t0xe49d3a2c, 0x0d927850, 0x9bcc5f6a, 0x62467e54,\n\t\t0xc2138df6, 0xe8b8d890, 0x5ef7392e, 0xf5afc382,\n\t\t0xbe805d9f, 0x7c93d069, 0xa92dd56f, 0xb31225cf,\n\t\t0x3b99acc8, 0xa77d1810, 0x6e639ce8, 0x7bbb3bdb,\n\t\t0x097826cd, 0xf418596e, 0x01b79aec, 0xa89a4f83,\n\t\t0x656e95e6, 0x7ee6ffaa, 0x08cfbc21, 0xe6e815ef,\n\t\t0xd99be7ba, 0xce366f4a, 0xd4099fea, 0xd67cb029,\n\t\t0xafb2a431, 0x31233f2a, 0x3094a5c6, 0xc066a235,\n\t\t0x37bc4e74, 0xa6ca82fc, 0xb0d090e0, 0x15d8a733,\n\t\t0x4a9804f1, 0xf7daec41, 0x0e50cd7f, 0x2ff69117,\n\t\t0x8dd64d76, 0x4db0ef43, 0x544daacc, 0xdf0496e4,\n\t\t0xe3b5d19e, 0x1b886a4c, 0xb81f2cc1, 0x7f516546,\n\t\t0x04ea5e9d, 0x5d358c01, 0x737487fa, 0x2e410bfb,\n\t\t0x5a1d67b3, 0x52d2db92, 0x335610e9, 0x1347d66d,\n\t\t0x8c61d79a, 0x7a0ca137, 0x8e14f859, 0x893c13eb,\n\t\t0xee27a9ce, 0x35c961b7, 0xede51ce1, 0x3cb1477a,\n\t\t0x59dfd29c, 0x3f73f255, 0x79ce1418, 0xbf37c773,\n\t\t0xeacdf753, 0x5baafd5f, 0x146f3ddf, 0x86db4478,\n\t\t0x81f3afca, 0x3ec468b9, 0x2c342438, 0x5f40a3c2,\n\t\t0x72c31d16, 0x0c25e2bc, 0x8b493c28, 0x41950dff,\n\t\t0x7101a839, 0xdeb30c08, 0x9ce4b4d8, 0x90c15664,\n\t\t0x6184cb7b, 0x70b632d5, 0x745c6c48, 0x4257b8d0,\n\t}, {\n\t\t0xa7f45150, 0x65417e53, 0xa4171ac3, 0x5e273a96,\n\t\t0x6bab3bcb, 0x459d1ff1, 0x58faacab, 0x03e34b93,\n\t\t0xfa302055, 0x6d76adf6, 0x76cc8891, 0x4c02f525,\n\t\t0xd7e54ffc, 0xcb2ac5d7, 0x44352680, 0xa362b58f,\n\t\t0x5ab1de49, 0x1bba2567, 0x0eea4598, 0xc0fe5de1,\n\t\t0x752fc302, 0xf04c8112, 0x97468da3, 0xf9d36bc6,\n\t\t0x5f8f03e7, 0x9c921595, 0x7a6dbfeb, 0x595295da,\n\t\t0x83bed42d, 0x217458d3, 0x69e04929, 0xc8c98e44,\n\t\t0x89c2756a, 0x798ef478, 0x3e58996b, 0x71b927dd,\n\t\t0x4fe1beb6, 0xad88f017, 0xac20c966, 0x3ace7db4,\n\t\t0x4adf6318, 0x311ae582, 0x33519760, 0x7f536245,\n\t\t0x7764b1e0, 0xae6bbb84, 0xa081fe1c, 0x2b08f994,\n\t\t0x68487058, 0xfd458f19, 0x6cde9487, 0xf87b52b7,\n\t\t0xd373ab23, 0x024b72e2, 0x8f1fe357, 0xab55662a,\n\t\t0x28ebb207, 0xc2b52f03, 0x7bc5869a, 0x0837d3a5,\n\t\t0x872830f2, 0xa5bf23b2, 0x6a0302ba, 0x8216ed5c,\n\t\t0x1ccf8a2b, 0xb479a792, 0xf207f3f0, 0xe2694ea1,\n\t\t0xf4da65cd, 0xbe0506d5, 0x6234d11f, 0xfea6c48a,\n\t\t0x532e349d, 0x55f3a2a0, 0xe18a0532, 0xebf6a475,\n\t\t0xec830b39, 0xef6040aa, 0x9f715e06, 0x106ebd51,\n\t\t0x8a213ef9, 0x06dd963d, 0x053eddae, 0xbde64d46,\n\t\t0x8d5491b5, 0x5dc47105, 0xd406046f, 0x155060ff,\n\t\t0xfb981924, 0xe9bdd697, 0x434089cc, 0x9ed96777,\n\t\t0x42e8b0bd, 0x8b890788, 0x5b19e738, 0xeec879db,\n\t\t0x0a7ca147, 0x0f427ce9, 0x1e84f8c9, 0x00000000,\n\t\t0x86800983, 0xed2b3248, 0x70111eac, 0x725a6c4e,\n\t\t0xff0efdfb, 0x38850f56, 0xd5ae3d1e, 0x392d3627,\n\t\t0xd90f0a64, 0xa65c6821, 0x545b9bd1, 0x2e36243a,\n\t\t0x670a0cb1, 0xe757930f, 0x96eeb4d2, 0x919b1b9e,\n\t\t0xc5c0804f, 0x20dc61a2, 0x4b775a69, 0x1a121c16,\n\t\t0xba93e20a, 0x2aa0c0e5, 0xe0223c43, 0x171b121d,\n\t\t0x0d090e0b, 0xc78bf2ad, 0xa8b62db9, 0xa91e14c8,\n\t\t0x19f15785, 0x0775af4c, 0xdd99eebb, 0x607fa3fd,\n\t\t0x2601f79f, 0xf5725cbc, 0x3b6644c5, 0x7efb5b34,\n\t\t0x29438b76, 0xc623cbdc, 0xfcedb668, 0xf1e4b863,\n\t\t0xdc31d7ca, 0x85634210, 0x22971340, 0x11c68420,\n\t\t0x244a857d, 0x3dbbd2f8, 0x32f9ae11, 0xa129c76d,\n\t\t0x2f9e1d4b, 0x30b2dcf3, 0x52860dec, 0xe3c177d0,\n\t\t0x16b32b6c, 0xb970a999, 0x489411fa, 0x64e94722,\n\t\t0x8cfca8c4, 0x3ff0a01a, 0x2c7d56d8, 0x903322ef,\n\t\t0x4e4987c7, 0xd138d9c1, 0xa2ca8cfe, 0x0bd49836,\n\t\t0x81f5a6cf, 0xde7aa528, 0x8eb7da26, 0xbfad3fa4,\n\t\t0x9d3a2ce4, 0x9278500d, 0xcc5f6a9b, 0x467e5462,\n\t\t0x138df6c2, 0xb8d890e8, 0xf7392e5e, 0xafc382f5,\n\t\t0x805d9fbe, 0x93d0697c, 0x2dd56fa9, 0x1225cfb3,\n\t\t0x99acc83b, 0x7d1810a7, 0x639ce86e, 0xbb3bdb7b,\n\t\t0x7826cd09, 0x18596ef4, 0xb79aec01, 0x9a4f83a8,\n\t\t0x6e95e665, 0xe6ffaa7e, 0xcfbc2108, 0xe815efe6,\n\t\t0x9be7bad9, 0x366f4ace, 0x099fead4, 0x7cb029d6,\n\t\t0xb2a431af, 0x233f2a31, 0x94a5c630, 0x66a235c0,\n\t\t0xbc4e7437, 0xca82fca6, 0xd090e0b0, 0xd8a73315,\n\t\t0x9804f14a, 0xdaec41f7, 0x50cd7f0e, 0xf691172f,\n\t\t0xd64d768d, 0xb0ef434d, 0x4daacc54, 0x0496e4df,\n\t\t0xb5d19ee3, 0x886a4c1b, 0x1f2cc1b8, 0x5165467f,\n\t\t0xea5e9d04, 0x358c015d, 0x7487fa73, 0x410bfb2e,\n\t\t0x1d67b35a, 0xd2db9252, 0x5610e933, 0x47d66d13,\n\t\t0x61d79a8c, 0x0ca1377a, 0x14f8598e, 0x3c13eb89,\n\t\t0x27a9ceee, 0xc961b735, 0xe51ce1ed, 0xb1477a3c,\n\t\t0xdfd29c59, 0x73f2553f, 0xce141879, 0x37c773bf,\n\t\t0xcdf753ea, 0xaafd5f5b, 0x6f3ddf14, 0xdb447886,\n\t\t0xf3afca81, 0xc468b93e, 0x3424382c, 0x40a3c25f,\n\t\t0xc31d1672, 0x25e2bc0c, 0x493c288b, 0x950dff41,\n\t\t0x01a83971, 0xb30c08de, 0xe4b4d89c, 0xc1566490,\n\t\t0x84cb7b61, 0xb632d570, 0x5c6c4874, 0x57b8d042,\n\t}, {\n\t\t0xf45150a7, 0x417e5365, 0x171ac3a4, 0x273a965e,\n\t\t0xab3bcb6b, 0x9d1ff145, 0xfaacab58, 0xe34b9303,\n\t\t0x302055fa, 0x76adf66d, 0xcc889176, 0x02f5254c,\n\t\t0xe54ffcd7, 0x2ac5d7cb, 0x35268044, 0x62b58fa3,\n\t\t0xb1de495a, 0xba25671b, 0xea45980e, 0xfe5de1c0,\n\t\t0x2fc30275, 0x4c8112f0, 0x468da397, 0xd36bc6f9,\n\t\t0x8f03e75f, 0x9215959c, 0x6dbfeb7a, 0x5295da59,\n\t\t0xbed42d83, 0x7458d321, 0xe0492969, 0xc98e44c8,\n\t\t0xc2756a89, 0x8ef47879, 0x58996b3e, 0xb927dd71,\n\t\t0xe1beb64f, 0x88f017ad, 0x20c966ac, 0xce7db43a,\n\t\t0xdf63184a, 0x1ae58231, 0x51976033, 0x5362457f,\n\t\t0x64b1e077, 0x6bbb84ae, 0x81fe1ca0, 0x08f9942b,\n\t\t0x48705868, 0x458f19fd, 0xde94876c, 0x7b52b7f8,\n\t\t0x73ab23d3, 0x4b72e202, 0x1fe3578f, 0x55662aab,\n\t\t0xebb20728, 0xb52f03c2, 0xc5869a7b, 0x37d3a508,\n\t\t0x2830f287, 0xbf23b2a5, 0x0302ba6a, 0x16ed5c82,\n\t\t0xcf8a2b1c, 0x79a792b4, 0x07f3f0f2, 0x694ea1e2,\n\t\t0xda65cdf4, 0x0506d5be, 0x34d11f62, 0xa6c48afe,\n\t\t0x2e349d53, 0xf3a2a055, 0x8a0532e1, 0xf6a475eb,\n\t\t0x830b39ec, 0x6040aaef, 0x715e069f, 0x6ebd5110,\n\t\t0x213ef98a, 0xdd963d06, 0x3eddae05, 0xe64d46bd,\n\t\t0x5491b58d, 0xc471055d, 0x06046fd4, 0x5060ff15,\n\t\t0x981924fb, 0xbdd697e9, 0x4089cc43, 0xd967779e,\n\t\t0xe8b0bd42, 0x8907888b, 0x19e7385b, 0xc879dbee,\n\t\t0x7ca1470a, 0x427ce90f, 0x84f8c91e, 0x00000000,\n\t\t0x80098386, 0x2b3248ed, 0x111eac70, 0x5a6c4e72,\n\t\t0x0efdfbff, 0x850f5638, 0xae3d1ed5, 0x2d362739,\n\t\t0x0f0a64d9, 0x5c6821a6, 0x5b9bd154, 0x36243a2e,\n\t\t0x0a0cb167, 0x57930fe7, 0xeeb4d296, 0x9b1b9e91,\n\t\t0xc0804fc5, 0xdc61a220, 0x775a694b, 0x121c161a,\n\t\t0x93e20aba, 0xa0c0e52a, 0x223c43e0, 0x1b121d17,\n\t\t0x090e0b0d, 0x8bf2adc7, 0xb62db9a8, 0x1e14c8a9,\n\t\t0xf1578519, 0x75af4c07, 0x99eebbdd, 0x7fa3fd60,\n\t\t0x01f79f26, 0x725cbcf5, 0x6644c53b, 0xfb5b347e,\n\t\t0x438b7629, 0x23cbdcc6, 0xedb668fc, 0xe4b863f1,\n\t\t0x31d7cadc, 0x63421085, 0x97134022, 0xc6842011,\n\t\t0x4a857d24, 0xbbd2f83d, 0xf9ae1132, 0x29c76da1,\n\t\t0x9e1d4b2f, 0xb2dcf330, 0x860dec52, 0xc177d0e3,\n\t\t0xb32b6c16, 0x70a999b9, 0x9411fa48, 0xe9472264,\n\t\t0xfca8c48c, 0xf0a01a3f, 0x7d56d82c, 0x3322ef90,\n\t\t0x4987c74e, 0x38d9c1d1, 0xca8cfea2, 0xd498360b,\n\t\t0xf5a6cf81, 0x7aa528de, 0xb7da268e, 0xad3fa4bf,\n\t\t0x3a2ce49d, 0x78500d92, 0x5f6a9bcc, 0x7e546246,\n\t\t0x8df6c213, 0xd890e8b8, 0x392e5ef7, 0xc382f5af,\n\t\t0x5d9fbe80, 0xd0697c93, 0xd56fa92d, 0x25cfb312,\n\t\t0xacc83b99, 0x1810a77d, 0x9ce86e63, 0x3bdb7bbb,\n\t\t0x26cd0978, 0x596ef418, 0x9aec01b7, 0x4f83a89a,\n\t\t0x95e6656e, 0xffaa7ee6, 0xbc2108cf, 0x15efe6e8,\n\t\t0xe7bad99b, 0x6f4ace36, 0x9fead409, 0xb029d67c,\n\t\t0xa431afb2, 0x3f2a3123, 0xa5c63094, 0xa235c066,\n\t\t0x4e7437bc, 0x82fca6ca, 0x90e0b0d0, 0xa73315d8,\n\t\t0x04f14a98, 0xec41f7da, 0xcd7f0e50, 0x91172ff6,\n\t\t0x4d768dd6, 0xef434db0, 0xaacc544d, 0x96e4df04,\n\t\t0xd19ee3b5, 0x6a4c1b88, 0x2cc1b81f, 0x65467f51,\n\t\t0x5e9d04ea, 0x8c015d35, 0x87fa7374, 0x0bfb2e41,\n\t\t0x67b35a1d, 0xdb9252d2, 0x10e93356, 0xd66d1347,\n\t\t0xd79a8c61, 0xa1377a0c, 0xf8598e14, 0x13eb893c,\n\t\t0xa9ceee27, 0x61b735c9, 0x1ce1ede5, 0x477a3cb1,\n\t\t0xd29c59df, 0xf2553f73, 0x141879ce, 0xc773bf37,\n\t\t0xf753eacd, 0xfd5f5baa, 0x3ddf146f, 0x447886db,\n\t\t0xafca81f3, 0x68b93ec4, 0x24382c34, 0xa3c25f40,\n\t\t0x1d1672c3, 0xe2bc0c25, 0x3c288b49, 0x0dff4195,\n\t\t0xa8397101, 0x0c08deb3, 0xb4d89ce4, 0x566490c1,\n\t\t0xcb7b6184, 0x32d570b6, 0x6c48745c, 0xb8d04257,\n\t}, {\n\t\t0x5150a7f4, 0x7e536541, 0x1ac3a417, 0x3a965e27,\n\t\t0x3bcb6bab, 0x1ff1459d, 0xacab58fa, 0x4b9303e3,\n\t\t0x2055fa30, 0xadf66d76, 0x889176cc, 0xf5254c02,\n\t\t0x4ffcd7e5, 0xc5d7cb2a, 0x26804435, 0xb58fa362,\n\t\t0xde495ab1, 0x25671bba, 0x45980eea, 0x5de1c0fe,\n\t\t0xc302752f, 0x8112f04c, 0x8da39746, 0x6bc6f9d3,\n\t\t0x03e75f8f, 0x15959c92, 0xbfeb7a6d, 0x95da5952,\n\t\t0xd42d83be, 0x58d32174, 0x492969e0, 0x8e44c8c9,\n\t\t0x756a89c2, 0xf478798e, 0x996b3e58, 0x27dd71b9,\n\t\t0xbeb64fe1, 0xf017ad88, 0xc966ac20, 0x7db43ace,\n\t\t0x63184adf, 0xe582311a, 0x97603351, 0x62457f53,\n\t\t0xb1e07764, 0xbb84ae6b, 0xfe1ca081, 0xf9942b08,\n\t\t0x70586848, 0x8f19fd45, 0x94876cde, 0x52b7f87b,\n\t\t0xab23d373, 0x72e2024b, 0xe3578f1f, 0x662aab55,\n\t\t0xb20728eb, 0x2f03c2b5, 0x869a7bc5, 0xd3a50837,\n\t\t0x30f28728, 0x23b2a5bf, 0x02ba6a03, 0xed5c8216,\n\t\t0x8a2b1ccf, 0xa792b479, 0xf3f0f207, 0x4ea1e269,\n\t\t0x65cdf4da, 0x06d5be05, 0xd11f6234, 0xc48afea6,\n\t\t0x349d532e, 0xa2a055f3, 0x0532e18a, 0xa475ebf6,\n\t\t0x0b39ec83, 0x40aaef60, 0x5e069f71, 0xbd51106e,\n\t\t0x3ef98a21, 0x963d06dd, 0xddae053e, 0x4d46bde6,\n\t\t0x91b58d54, 0x71055dc4, 0x046fd406, 0x60ff1550,\n\t\t0x1924fb98, 0xd697e9bd, 0x89cc4340, 0x67779ed9,\n\t\t0xb0bd42e8, 0x07888b89, 0xe7385b19, 0x79dbeec8,\n\t\t0xa1470a7c, 0x7ce90f42, 0xf8c91e84, 0x00000000,\n\t\t0x09838680, 0x3248ed2b, 0x1eac7011, 0x6c4e725a,\n\t\t0xfdfbff0e, 0x0f563885, 0x3d1ed5ae, 0x3627392d,\n\t\t0x0a64d90f, 0x6821a65c, 0x9bd1545b, 0x243a2e36,\n\t\t0x0cb1670a, 0x930fe757, 0xb4d296ee, 0x1b9e919b,\n\t\t0x804fc5c0, 0x61a220dc, 0x5a694b77, 0x1c161a12,\n\t\t0xe20aba93, 0xc0e52aa0, 0x3c43e022, 0x121d171b,\n\t\t0x0e0b0d09, 0xf2adc78b, 0x2db9a8b6, 0x14c8a91e,\n\t\t0x578519f1, 0xaf4c0775, 0xeebbdd99, 0xa3fd607f,\n\t\t0xf79f2601, 0x5cbcf572, 0x44c53b66, 0x5b347efb,\n\t\t0x8b762943, 0xcbdcc623, 0xb668fced, 0xb863f1e4,\n\t\t0xd7cadc31, 0x42108563, 0x13402297, 0x842011c6,\n\t\t0x857d244a, 0xd2f83dbb, 0xae1132f9, 0xc76da129,\n\t\t0x1d4b2f9e, 0xdcf330b2, 0x0dec5286, 0x77d0e3c1,\n\t\t0x2b6c16b3, 0xa999b970, 0x11fa4894, 0x472264e9,\n\t\t0xa8c48cfc, 0xa01a3ff0, 0x56d82c7d, 0x22ef9033,\n\t\t0x87c74e49, 0xd9c1d138, 0x8cfea2ca, 0x98360bd4,\n\t\t0xa6cf81f5, 0xa528de7a, 0xda268eb7, 0x3fa4bfad,\n\t\t0x2ce49d3a, 0x500d9278, 0x6a9bcc5f, 0x5462467e,\n\t\t0xf6c2138d, 0x90e8b8d8, 0x2e5ef739, 0x82f5afc3,\n\t\t0x9fbe805d, 0x697c93d0, 0x6fa92dd5, 0xcfb31225,\n\t\t0xc83b99ac, 0x10a77d18, 0xe86e639c, 0xdb7bbb3b,\n\t\t0xcd097826, 0x6ef41859, 0xec01b79a, 0x83a89a4f,\n\t\t0xe6656e95, 0xaa7ee6ff, 0x2108cfbc, 0xefe6e815,\n\t\t0xbad99be7, 0x4ace366f, 0xead4099f, 0x29d67cb0,\n\t\t0x31afb2a4, 0x2a31233f, 0xc63094a5, 0x35c066a2,\n\t\t0x7437bc4e, 0xfca6ca82, 0xe0b0d090, 0x3315d8a7,\n\t\t0xf14a9804, 0x41f7daec, 0x7f0e50cd, 0x172ff691,\n\t\t0x768dd64d, 0x434db0ef, 0xcc544daa, 0xe4df0496,\n\t\t0x9ee3b5d1, 0x4c1b886a, 0xc1b81f2c, 0x467f5165,\n\t\t0x9d04ea5e, 0x015d358c, 0xfa737487, 0xfb2e410b,\n\t\t0xb35a1d67, 0x9252d2db, 0xe9335610, 0x6d1347d6,\n\t\t0x9a8c61d7, 0x377a0ca1, 0x598e14f8, 0xeb893c13,\n\t\t0xceee27a9, 0xb735c961, 0xe1ede51c, 0x7a3cb147,\n\t\t0x9c59dfd2, 0x553f73f2, 0x1879ce14, 0x73bf37c7,\n\t\t0x53eacdf7, 0x5f5baafd, 0xdf146f3d, 0x7886db44,\n\t\t0xca81f3af, 0xb93ec468, 0x382c3424, 0xc25f40a3,\n\t\t0x1672c31d, 0xbc0c25e2, 0x288b493c, 0xff41950d,\n\t\t0x397101a8, 0x08deb30c, 0xd89ce4b4, 0x6490c156,\n\t\t0x7b6184cb, 0xd570b632, 0x48745c6c, 0xd04257b8,\n\t}\n};\n\n__visible const u32 crypto_il_tab[4][256] = {\n\t{\n\t\t0x00000052, 0x00000009, 0x0000006a, 0x000000d5,\n\t\t0x00000030, 0x00000036, 0x000000a5, 0x00000038,\n\t\t0x000000bf, 0x00000040, 0x000000a3, 0x0000009e,\n\t\t0x00000081, 0x000000f3, 0x000000d7, 0x000000fb,\n\t\t0x0000007c, 0x000000e3, 0x00000039, 0x00000082,\n\t\t0x0000009b, 0x0000002f, 0x000000ff, 0x00000087,\n\t\t0x00000034, 0x0000008e, 0x00000043, 0x00000044,\n\t\t0x000000c4, 0x000000de, 0x000000e9, 0x000000cb,\n\t\t0x00000054, 0x0000007b, 0x00000094, 0x00000032,\n\t\t0x000000a6, 0x000000c2, 0x00000023, 0x0000003d,\n\t\t0x000000ee, 0x0000004c, 0x00000095, 0x0000000b,\n\t\t0x00000042, 0x000000fa, 0x000000c3, 0x0000004e,\n\t\t0x00000008, 0x0000002e, 0x000000a1, 0x00000066,\n\t\t0x00000028, 0x000000d9, 0x00000024, 0x000000b2,\n\t\t0x00000076, 0x0000005b, 0x000000a2, 0x00000049,\n\t\t0x0000006d, 0x0000008b, 0x000000d1, 0x00000025,\n\t\t0x00000072, 0x000000f8, 0x000000f6, 0x00000064,\n\t\t0x00000086, 0x00000068, 0x00000098, 0x00000016,\n\t\t0x000000d4, 0x000000a4, 0x0000005c, 0x000000cc,\n\t\t0x0000005d, 0x00000065, 0x000000b6, 0x00000092,\n\t\t0x0000006c, 0x00000070, 0x00000048, 0x00000050,\n\t\t0x000000fd, 0x000000ed, 0x000000b9, 0x000000da,\n\t\t0x0000005e, 0x00000015, 0x00000046, 0x00000057,\n\t\t0x000000a7, 0x0000008d, 0x0000009d, 0x00000084,\n\t\t0x00000090, 0x000000d8, 0x000000ab, 0x00000000,\n\t\t0x0000008c, 0x000000bc, 0x000000d3, 0x0000000a,\n\t\t0x000000f7, 0x000000e4, 0x00000058, 0x00000005,\n\t\t0x000000b8, 0x000000b3, 0x00000045, 0x00000006,\n\t\t0x000000d0, 0x0000002c, 0x0000001e, 0x0000008f,\n\t\t0x000000ca, 0x0000003f, 0x0000000f, 0x00000002,\n\t\t0x000000c1, 0x000000af, 0x000000bd, 0x00000003,\n\t\t0x00000001, 0x00000013, 0x0000008a, 0x0000006b,\n\t\t0x0000003a, 0x00000091, 0x00000011, 0x00000041,\n\t\t0x0000004f, 0x00000067, 0x000000dc, 0x000000ea,\n\t\t0x00000097, 0x000000f2, 0x000000cf, 0x000000ce,\n\t\t0x000000f0, 0x000000b4, 0x000000e6, 0x00000073,\n\t\t0x00000096, 0x000000ac, 0x00000074, 0x00000022,\n\t\t0x000000e7, 0x000000ad, 0x00000035, 0x00000085,\n\t\t0x000000e2, 0x000000f9, 0x00000037, 0x000000e8,\n\t\t0x0000001c, 0x00000075, 0x000000df, 0x0000006e,\n\t\t0x00000047, 0x000000f1, 0x0000001a, 0x00000071,\n\t\t0x0000001d, 0x00000029, 0x000000c5, 0x00000089,\n\t\t0x0000006f, 0x000000b7, 0x00000062, 0x0000000e,\n\t\t0x000000aa, 0x00000018, 0x000000be, 0x0000001b,\n\t\t0x000000fc, 0x00000056, 0x0000003e, 0x0000004b,\n\t\t0x000000c6, 0x000000d2, 0x00000079, 0x00000020,\n\t\t0x0000009a, 0x000000db, 0x000000c0, 0x000000fe,\n\t\t0x00000078, 0x000000cd, 0x0000005a, 0x000000f4,\n\t\t0x0000001f, 0x000000dd, 0x000000a8, 0x00000033,\n\t\t0x00000088, 0x00000007, 0x000000c7, 0x00000031,\n\t\t0x000000b1, 0x00000012, 0x00000010, 0x00000059,\n\t\t0x00000027, 0x00000080, 0x000000ec, 0x0000005f,\n\t\t0x00000060, 0x00000051, 0x0000007f, 0x000000a9,\n\t\t0x00000019, 0x000000b5, 0x0000004a, 0x0000000d,\n\t\t0x0000002d, 0x000000e5, 0x0000007a, 0x0000009f,\n\t\t0x00000093, 0x000000c9, 0x0000009c, 0x000000ef,\n\t\t0x000000a0, 0x000000e0, 0x0000003b, 0x0000004d,\n\t\t0x000000ae, 0x0000002a, 0x000000f5, 0x000000b0,\n\t\t0x000000c8, 0x000000eb, 0x000000bb, 0x0000003c,\n\t\t0x00000083, 0x00000053, 0x00000099, 0x00000061,\n\t\t0x00000017, 0x0000002b, 0x00000004, 0x0000007e,\n\t\t0x000000ba, 0x00000077, 0x000000d6, 0x00000026,\n\t\t0x000000e1, 0x00000069, 0x00000014, 0x00000063,\n\t\t0x00000055, 0x00000021, 0x0000000c, 0x0000007d,\n\t}, {\n\t\t0x00005200, 0x00000900, 0x00006a00, 0x0000d500,\n\t\t0x00003000, 0x00003600, 0x0000a500, 0x00003800,\n\t\t0x0000bf00, 0x00004000, 0x0000a300, 0x00009e00,\n\t\t0x00008100, 0x0000f300, 0x0000d700, 0x0000fb00,\n\t\t0x00007c00, 0x0000e300, 0x00003900, 0x00008200,\n\t\t0x00009b00, 0x00002f00, 0x0000ff00, 0x00008700,\n\t\t0x00003400, 0x00008e00, 0x00004300, 0x00004400,\n\t\t0x0000c400, 0x0000de00, 0x0000e900, 0x0000cb00,\n\t\t0x00005400, 0x00007b00, 0x00009400, 0x00003200,\n\t\t0x0000a600, 0x0000c200, 0x00002300, 0x00003d00,\n\t\t0x0000ee00, 0x00004c00, 0x00009500, 0x00000b00,\n\t\t0x00004200, 0x0000fa00, 0x0000c300, 0x00004e00,\n\t\t0x00000800, 0x00002e00, 0x0000a100, 0x00006600,\n\t\t0x00002800, 0x0000d900, 0x00002400, 0x0000b200,\n\t\t0x00007600, 0x00005b00, 0x0000a200, 0x00004900,\n\t\t0x00006d00, 0x00008b00, 0x0000d100, 0x00002500,\n\t\t0x00007200, 0x0000f800, 0x0000f600, 0x00006400,\n\t\t0x00008600, 0x00006800, 0x00009800, 0x00001600,\n\t\t0x0000d400, 0x0000a400, 0x00005c00, 0x0000cc00,\n\t\t0x00005d00, 0x00006500, 0x0000b600, 0x00009200,\n\t\t0x00006c00, 0x00007000, 0x00004800, 0x00005000,\n\t\t0x0000fd00, 0x0000ed00, 0x0000b900, 0x0000da00,\n\t\t0x00005e00, 0x00001500, 0x00004600, 0x00005700,\n\t\t0x0000a700, 0x00008d00, 0x00009d00, 0x00008400,\n\t\t0x00009000, 0x0000d800, 0x0000ab00, 0x00000000,\n\t\t0x00008c00, 0x0000bc00, 0x0000d300, 0x00000a00,\n\t\t0x0000f700, 0x0000e400, 0x00005800, 0x00000500,\n\t\t0x0000b800, 0x0000b300, 0x00004500, 0x00000600,\n\t\t0x0000d000, 0x00002c00, 0x00001e00, 0x00008f00,\n\t\t0x0000ca00, 0x00003f00, 0x00000f00, 0x00000200,\n\t\t0x0000c100, 0x0000af00, 0x0000bd00, 0x00000300,\n\t\t0x00000100, 0x00001300, 0x00008a00, 0x00006b00,\n\t\t0x00003a00, 0x00009100, 0x00001100, 0x00004100,\n\t\t0x00004f00, 0x00006700, 0x0000dc00, 0x0000ea00,\n\t\t0x00009700, 0x0000f200, 0x0000cf00, 0x0000ce00,\n\t\t0x0000f000, 0x0000b400, 0x0000e600, 0x00007300,\n\t\t0x00009600, 0x0000ac00, 0x00007400, 0x00002200,\n\t\t0x0000e700, 0x0000ad00, 0x00003500, 0x00008500,\n\t\t0x0000e200, 0x0000f900, 0x00003700, 0x0000e800,\n\t\t0x00001c00, 0x00007500, 0x0000df00, 0x00006e00,\n\t\t0x00004700, 0x0000f100, 0x00001a00, 0x00007100,\n\t\t0x00001d00, 0x00002900, 0x0000c500, 0x00008900,\n\t\t0x00006f00, 0x0000b700, 0x00006200, 0x00000e00,\n\t\t0x0000aa00, 0x00001800, 0x0000be00, 0x00001b00,\n\t\t0x0000fc00, 0x00005600, 0x00003e00, 0x00004b00,\n\t\t0x0000c600, 0x0000d200, 0x00007900, 0x00002000,\n\t\t0x00009a00, 0x0000db00, 0x0000c000, 0x0000fe00,\n\t\t0x00007800, 0x0000cd00, 0x00005a00, 0x0000f400,\n\t\t0x00001f00, 0x0000dd00, 0x0000a800, 0x00003300,\n\t\t0x00008800, 0x00000700, 0x0000c700, 0x00003100,\n\t\t0x0000b100, 0x00001200, 0x00001000, 0x00005900,\n\t\t0x00002700, 0x00008000, 0x0000ec00, 0x00005f00,\n\t\t0x00006000, 0x00005100, 0x00007f00, 0x0000a900,\n\t\t0x00001900, 0x0000b500, 0x00004a00, 0x00000d00,\n\t\t0x00002d00, 0x0000e500, 0x00007a00, 0x00009f00,\n\t\t0x00009300, 0x0000c900, 0x00009c00, 0x0000ef00,\n\t\t0x0000a000, 0x0000e000, 0x00003b00, 0x00004d00,\n\t\t0x0000ae00, 0x00002a00, 0x0000f500, 0x0000b000,\n\t\t0x0000c800, 0x0000eb00, 0x0000bb00, 0x00003c00,\n\t\t0x00008300, 0x00005300, 0x00009900, 0x00006100,\n\t\t0x00001700, 0x00002b00, 0x00000400, 0x00007e00,\n\t\t0x0000ba00, 0x00007700, 0x0000d600, 0x00002600,\n\t\t0x0000e100, 0x00006900, 0x00001400, 0x00006300,\n\t\t0x00005500, 0x00002100, 0x00000c00, 0x00007d00,\n\t}, {\n\t\t0x00520000, 0x00090000, 0x006a0000, 0x00d50000,\n\t\t0x00300000, 0x00360000, 0x00a50000, 0x00380000,\n\t\t0x00bf0000, 0x00400000, 0x00a30000, 0x009e0000,\n\t\t0x00810000, 0x00f30000, 0x00d70000, 0x00fb0000,\n\t\t0x007c0000, 0x00e30000, 0x00390000, 0x00820000,\n\t\t0x009b0000, 0x002f0000, 0x00ff0000, 0x00870000,\n\t\t0x00340000, 0x008e0000, 0x00430000, 0x00440000,\n\t\t0x00c40000, 0x00de0000, 0x00e90000, 0x00cb0000,\n\t\t0x00540000, 0x007b0000, 0x00940000, 0x00320000,\n\t\t0x00a60000, 0x00c20000, 0x00230000, 0x003d0000,\n\t\t0x00ee0000, 0x004c0000, 0x00950000, 0x000b0000,\n\t\t0x00420000, 0x00fa0000, 0x00c30000, 0x004e0000,\n\t\t0x00080000, 0x002e0000, 0x00a10000, 0x00660000,\n\t\t0x00280000, 0x00d90000, 0x00240000, 0x00b20000,\n\t\t0x00760000, 0x005b0000, 0x00a20000, 0x00490000,\n\t\t0x006d0000, 0x008b0000, 0x00d10000, 0x00250000,\n\t\t0x00720000, 0x00f80000, 0x00f60000, 0x00640000,\n\t\t0x00860000, 0x00680000, 0x00980000, 0x00160000,\n\t\t0x00d40000, 0x00a40000, 0x005c0000, 0x00cc0000,\n\t\t0x005d0000, 0x00650000, 0x00b60000, 0x00920000,\n\t\t0x006c0000, 0x00700000, 0x00480000, 0x00500000,\n\t\t0x00fd0000, 0x00ed0000, 0x00b90000, 0x00da0000,\n\t\t0x005e0000, 0x00150000, 0x00460000, 0x00570000,\n\t\t0x00a70000, 0x008d0000, 0x009d0000, 0x00840000,\n\t\t0x00900000, 0x00d80000, 0x00ab0000, 0x00000000,\n\t\t0x008c0000, 0x00bc0000, 0x00d30000, 0x000a0000,\n\t\t0x00f70000, 0x00e40000, 0x00580000, 0x00050000,\n\t\t0x00b80000, 0x00b30000, 0x00450000, 0x00060000,\n\t\t0x00d00000, 0x002c0000, 0x001e0000, 0x008f0000,\n\t\t0x00ca0000, 0x003f0000, 0x000f0000, 0x00020000,\n\t\t0x00c10000, 0x00af0000, 0x00bd0000, 0x00030000,\n\t\t0x00010000, 0x00130000, 0x008a0000, 0x006b0000,\n\t\t0x003a0000, 0x00910000, 0x00110000, 0x00410000,\n\t\t0x004f0000, 0x00670000, 0x00dc0000, 0x00ea0000,\n\t\t0x00970000, 0x00f20000, 0x00cf0000, 0x00ce0000,\n\t\t0x00f00000, 0x00b40000, 0x00e60000, 0x00730000,\n\t\t0x00960000, 0x00ac0000, 0x00740000, 0x00220000,\n\t\t0x00e70000, 0x00ad0000, 0x00350000, 0x00850000,\n\t\t0x00e20000, 0x00f90000, 0x00370000, 0x00e80000,\n\t\t0x001c0000, 0x00750000, 0x00df0000, 0x006e0000,\n\t\t0x00470000, 0x00f10000, 0x001a0000, 0x00710000,\n\t\t0x001d0000, 0x00290000, 0x00c50000, 0x00890000,\n\t\t0x006f0000, 0x00b70000, 0x00620000, 0x000e0000,\n\t\t0x00aa0000, 0x00180000, 0x00be0000, 0x001b0000,\n\t\t0x00fc0000, 0x00560000, 0x003e0000, 0x004b0000,\n\t\t0x00c60000, 0x00d20000, 0x00790000, 0x00200000,\n\t\t0x009a0000, 0x00db0000, 0x00c00000, 0x00fe0000,\n\t\t0x00780000, 0x00cd0000, 0x005a0000, 0x00f40000,\n\t\t0x001f0000, 0x00dd0000, 0x00a80000, 0x00330000,\n\t\t0x00880000, 0x00070000, 0x00c70000, 0x00310000,\n\t\t0x00b10000, 0x00120000, 0x00100000, 0x00590000,\n\t\t0x00270000, 0x00800000, 0x00ec0000, 0x005f0000,\n\t\t0x00600000, 0x00510000, 0x007f0000, 0x00a90000,\n\t\t0x00190000, 0x00b50000, 0x004a0000, 0x000d0000,\n\t\t0x002d0000, 0x00e50000, 0x007a0000, 0x009f0000,\n\t\t0x00930000, 0x00c90000, 0x009c0000, 0x00ef0000,\n\t\t0x00a00000, 0x00e00000, 0x003b0000, 0x004d0000,\n\t\t0x00ae0000, 0x002a0000, 0x00f50000, 0x00b00000,\n\t\t0x00c80000, 0x00eb0000, 0x00bb0000, 0x003c0000,\n\t\t0x00830000, 0x00530000, 0x00990000, 0x00610000,\n\t\t0x00170000, 0x002b0000, 0x00040000, 0x007e0000,\n\t\t0x00ba0000, 0x00770000, 0x00d60000, 0x00260000,\n\t\t0x00e10000, 0x00690000, 0x00140000, 0x00630000,\n\t\t0x00550000, 0x00210000, 0x000c0000, 0x007d0000,\n\t}, {\n\t\t0x52000000, 0x09000000, 0x6a000000, 0xd5000000,\n\t\t0x30000000, 0x36000000, 0xa5000000, 0x38000000,\n\t\t0xbf000000, 0x40000000, 0xa3000000, 0x9e000000,\n\t\t0x81000000, 0xf3000000, 0xd7000000, 0xfb000000,\n\t\t0x7c000000, 0xe3000000, 0x39000000, 0x82000000,\n\t\t0x9b000000, 0x2f000000, 0xff000000, 0x87000000,\n\t\t0x34000000, 0x8e000000, 0x43000000, 0x44000000,\n\t\t0xc4000000, 0xde000000, 0xe9000000, 0xcb000000,\n\t\t0x54000000, 0x7b000000, 0x94000000, 0x32000000,\n\t\t0xa6000000, 0xc2000000, 0x23000000, 0x3d000000,\n\t\t0xee000000, 0x4c000000, 0x95000000, 0x0b000000,\n\t\t0x42000000, 0xfa000000, 0xc3000000, 0x4e000000,\n\t\t0x08000000, 0x2e000000, 0xa1000000, 0x66000000,\n\t\t0x28000000, 0xd9000000, 0x24000000, 0xb2000000,\n\t\t0x76000000, 0x5b000000, 0xa2000000, 0x49000000,\n\t\t0x6d000000, 0x8b000000, 0xd1000000, 0x25000000,\n\t\t0x72000000, 0xf8000000, 0xf6000000, 0x64000000,\n\t\t0x86000000, 0x68000000, 0x98000000, 0x16000000,\n\t\t0xd4000000, 0xa4000000, 0x5c000000, 0xcc000000,\n\t\t0x5d000000, 0x65000000, 0xb6000000, 0x92000000,\n\t\t0x6c000000, 0x70000000, 0x48000000, 0x50000000,\n\t\t0xfd000000, 0xed000000, 0xb9000000, 0xda000000,\n\t\t0x5e000000, 0x15000000, 0x46000000, 0x57000000,\n\t\t0xa7000000, 0x8d000000, 0x9d000000, 0x84000000,\n\t\t0x90000000, 0xd8000000, 0xab000000, 0x00000000,\n\t\t0x8c000000, 0xbc000000, 0xd3000000, 0x0a000000,\n\t\t0xf7000000, 0xe4000000, 0x58000000, 0x05000000,\n\t\t0xb8000000, 0xb3000000, 0x45000000, 0x06000000,\n\t\t0xd0000000, 0x2c000000, 0x1e000000, 0x8f000000,\n\t\t0xca000000, 0x3f000000, 0x0f000000, 0x02000000,\n\t\t0xc1000000, 0xaf000000, 0xbd000000, 0x03000000,\n\t\t0x01000000, 0x13000000, 0x8a000000, 0x6b000000,\n\t\t0x3a000000, 0x91000000, 0x11000000, 0x41000000,\n\t\t0x4f000000, 0x67000000, 0xdc000000, 0xea000000,\n\t\t0x97000000, 0xf2000000, 0xcf000000, 0xce000000,\n\t\t0xf0000000, 0xb4000000, 0xe6000000, 0x73000000,\n\t\t0x96000000, 0xac000000, 0x74000000, 0x22000000,\n\t\t0xe7000000, 0xad000000, 0x35000000, 0x85000000,\n\t\t0xe2000000, 0xf9000000, 0x37000000, 0xe8000000,\n\t\t0x1c000000, 0x75000000, 0xdf000000, 0x6e000000,\n\t\t0x47000000, 0xf1000000, 0x1a000000, 0x71000000,\n\t\t0x1d000000, 0x29000000, 0xc5000000, 0x89000000,\n\t\t0x6f000000, 0xb7000000, 0x62000000, 0x0e000000,\n\t\t0xaa000000, 0x18000000, 0xbe000000, 0x1b000000,\n\t\t0xfc000000, 0x56000000, 0x3e000000, 0x4b000000,\n\t\t0xc6000000, 0xd2000000, 0x79000000, 0x20000000,\n\t\t0x9a000000, 0xdb000000, 0xc0000000, 0xfe000000,\n\t\t0x78000000, 0xcd000000, 0x5a000000, 0xf4000000,\n\t\t0x1f000000, 0xdd000000, 0xa8000000, 0x33000000,\n\t\t0x88000000, 0x07000000, 0xc7000000, 0x31000000,\n\t\t0xb1000000, 0x12000000, 0x10000000, 0x59000000,\n\t\t0x27000000, 0x80000000, 0xec000000, 0x5f000000,\n\t\t0x60000000, 0x51000000, 0x7f000000, 0xa9000000,\n\t\t0x19000000, 0xb5000000, 0x4a000000, 0x0d000000,\n\t\t0x2d000000, 0xe5000000, 0x7a000000, 0x9f000000,\n\t\t0x93000000, 0xc9000000, 0x9c000000, 0xef000000,\n\t\t0xa0000000, 0xe0000000, 0x3b000000, 0x4d000000,\n\t\t0xae000000, 0x2a000000, 0xf5000000, 0xb0000000,\n\t\t0xc8000000, 0xeb000000, 0xbb000000, 0x3c000000,\n\t\t0x83000000, 0x53000000, 0x99000000, 0x61000000,\n\t\t0x17000000, 0x2b000000, 0x04000000, 0x7e000000,\n\t\t0xba000000, 0x77000000, 0xd6000000, 0x26000000,\n\t\t0xe1000000, 0x69000000, 0x14000000, 0x63000000,\n\t\t0x55000000, 0x21000000, 0x0c000000, 0x7d000000,\n\t}\n};\n\nEXPORT_SYMBOL_GPL(crypto_ft_tab);\nEXPORT_SYMBOL_GPL(crypto_fl_tab);\nEXPORT_SYMBOL_GPL(crypto_it_tab);\nEXPORT_SYMBOL_GPL(crypto_il_tab);\n\n/* initialise the key schedule from the user supplied key */\n\n#define star_x(x) (((x) & 0x7f7f7f7f) << 1) ^ ((((x) & 0x80808080) >> 7) * 0x1b)\n\n#define imix_col(y, x)\tdo {\t\t\\\n\tu\t= star_x(x);\t\t\\\n\tv\t= star_x(u);\t\t\\\n\tw\t= star_x(v);\t\t\\\n\tt\t= w ^ (x);\t\t\\\n\t(y)\t= u ^ v ^ w;\t\t\\\n\t(y)\t^= ror32(u ^ t, 8) ^\t\\\n\t\tror32(v ^ t, 16) ^\t\\\n\t\tror32(t, 24);\t\t\\\n} while (0)\n\n#define ls_box(x)\t\t\\\n\tcrypto_fl_tab[0][byte(x, 0)] ^\t\\\n\tcrypto_fl_tab[1][byte(x, 1)] ^\t\\\n\tcrypto_fl_tab[2][byte(x, 2)] ^\t\\\n\tcrypto_fl_tab[3][byte(x, 3)]\n\n#define loop4(i)\tdo {\t\t\\\n\tt = ror32(t, 8);\t\t\\\n\tt = ls_box(t) ^ rco_tab[i];\t\\\n\tt ^= ctx->key_enc[4 * i];\t\t\\\n\tctx->key_enc[4 * i + 4] = t;\t\t\\\n\tt ^= ctx->key_enc[4 * i + 1];\t\t\\\n\tctx->key_enc[4 * i + 5] = t;\t\t\\\n\tt ^= ctx->key_enc[4 * i + 2];\t\t\\\n\tctx->key_enc[4 * i + 6] = t;\t\t\\\n\tt ^= ctx->key_enc[4 * i + 3];\t\t\\\n\tctx->key_enc[4 * i + 7] = t;\t\t\\\n} while (0)\n\n#define loop6(i)\tdo {\t\t\\\n\tt = ror32(t, 8);\t\t\\\n\tt = ls_box(t) ^ rco_tab[i];\t\\\n\tt ^= ctx->key_enc[6 * i];\t\t\\\n\tctx->key_enc[6 * i + 6] = t;\t\t\\\n\tt ^= ctx->key_enc[6 * i + 1];\t\t\\\n\tctx->key_enc[6 * i + 7] = t;\t\t\\\n\tt ^= ctx->key_enc[6 * i + 2];\t\t\\\n\tctx->key_enc[6 * i + 8] = t;\t\t\\\n\tt ^= ctx->key_enc[6 * i + 3];\t\t\\\n\tctx->key_enc[6 * i + 9] = t;\t\t\\\n\tt ^= ctx->key_enc[6 * i + 4];\t\t\\\n\tctx->key_enc[6 * i + 10] = t;\t\t\\\n\tt ^= ctx->key_enc[6 * i + 5];\t\t\\\n\tctx->key_enc[6 * i + 11] = t;\t\t\\\n} while (0)\n\n#define loop8tophalf(i)\tdo {\t\t\t\\\n\tt = ror32(t, 8);\t\t\t\\\n\tt = ls_box(t) ^ rco_tab[i];\t\t\\\n\tt ^= ctx->key_enc[8 * i];\t\t\t\\\n\tctx->key_enc[8 * i + 8] = t;\t\t\t\\\n\tt ^= ctx->key_enc[8 * i + 1];\t\t\t\\\n\tctx->key_enc[8 * i + 9] = t;\t\t\t\\\n\tt ^= ctx->key_enc[8 * i + 2];\t\t\t\\\n\tctx->key_enc[8 * i + 10] = t;\t\t\t\\\n\tt ^= ctx->key_enc[8 * i + 3];\t\t\t\\\n\tctx->key_enc[8 * i + 11] = t;\t\t\t\\\n} while (0)\n\n#define loop8(i)\tdo {\t\t\t\t\\\n\tloop8tophalf(i);\t\t\t\t\\\n\tt  = ctx->key_enc[8 * i + 4] ^ ls_box(t);\t\\\n\tctx->key_enc[8 * i + 12] = t;\t\t\t\\\n\tt ^= ctx->key_enc[8 * i + 5];\t\t\t\\\n\tctx->key_enc[8 * i + 13] = t;\t\t\t\\\n\tt ^= ctx->key_enc[8 * i + 6];\t\t\t\\\n\tctx->key_enc[8 * i + 14] = t;\t\t\t\\\n\tt ^= ctx->key_enc[8 * i + 7];\t\t\t\\\n\tctx->key_enc[8 * i + 15] = t;\t\t\t\\\n} while (0)\n\n/**\n * crypto_aes_expand_key - Expands the AES key as described in FIPS-197\n * @ctx:\tThe location where the computed key will be stored.\n * @in_key:\tThe supplied key.\n * @key_len:\tThe length of the supplied key.\n *\n * Returns 0 on success. The function fails only if an invalid key size (or\n * pointer) is supplied.\n * The expanded key size is 240 bytes (max of 14 rounds with a unique 16 bytes\n * key schedule plus a 16 bytes key which is used before the first round).\n * The decryption key is prepared for the \"Equivalent Inverse Cipher\" as\n * described in FIPS-197. The first slot (16 bytes) of each key (enc or dec) is\n * for the initial combination, the second slot for the first round and so on.\n */\nint crypto_aes_expand_key(struct crypto_aes_ctx *ctx, const u8 *in_key,\n\t\tunsigned int key_len)\n{\n\tconst __le32 *key = (const __le32 *)in_key;\n\tu32 i, t, u, v, w, j;\n\n\tif (key_len != AES_KEYSIZE_128 && key_len != AES_KEYSIZE_192 &&\n\t\t\tkey_len != AES_KEYSIZE_256)\n\t\treturn -EINVAL;\n\n\tctx->key_length = key_len;\n\n\tctx->key_dec[key_len + 24] = ctx->key_enc[0] = le32_to_cpu(key[0]);\n\tctx->key_dec[key_len + 25] = ctx->key_enc[1] = le32_to_cpu(key[1]);\n\tctx->key_dec[key_len + 26] = ctx->key_enc[2] = le32_to_cpu(key[2]);\n\tctx->key_dec[key_len + 27] = ctx->key_enc[3] = le32_to_cpu(key[3]);\n\n\tswitch (key_len) {\n\tcase AES_KEYSIZE_128:\n\t\tt = ctx->key_enc[3];\n\t\tfor (i = 0; i < 10; ++i)\n\t\t\tloop4(i);\n\t\tbreak;\n\n\tcase AES_KEYSIZE_192:\n\t\tctx->key_enc[4] = le32_to_cpu(key[4]);\n\t\tt = ctx->key_enc[5] = le32_to_cpu(key[5]);\n\t\tfor (i = 0; i < 8; ++i)\n\t\t\tloop6(i);\n\t\tbreak;\n\n\tcase AES_KEYSIZE_256:\n\t\tctx->key_enc[4] = le32_to_cpu(key[4]);\n\t\tctx->key_enc[5] = le32_to_cpu(key[5]);\n\t\tctx->key_enc[6] = le32_to_cpu(key[6]);\n\t\tt = ctx->key_enc[7] = le32_to_cpu(key[7]);\n\t\tfor (i = 0; i < 6; ++i)\n\t\t\tloop8(i);\n\t\tloop8tophalf(i);\n\t\tbreak;\n\t}\n\n\tctx->key_dec[0] = ctx->key_enc[key_len + 24];\n\tctx->key_dec[1] = ctx->key_enc[key_len + 25];\n\tctx->key_dec[2] = ctx->key_enc[key_len + 26];\n\tctx->key_dec[3] = ctx->key_enc[key_len + 27];\n\n\tfor (i = 4; i < key_len + 24; ++i) {\n\t\tj = key_len + 24 - (i & ~3) + (i & 3);\n\t\timix_col(ctx->key_dec[j], ctx->key_enc[i]);\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(crypto_aes_expand_key);\n\n/**\n * crypto_aes_set_key - Set the AES key.\n * @tfm:\tThe %crypto_tfm that is used in the context.\n * @in_key:\tThe input key.\n * @key_len:\tThe size of the key.\n *\n * Returns 0 on success, on failure the %CRYPTO_TFM_RES_BAD_KEY_LEN flag in tfm\n * is set. The function uses crypto_aes_expand_key() to expand the key.\n * &crypto_aes_ctx _must_ be the private data embedded in @tfm which is\n * retrieved with crypto_tfm_ctx().\n */\nint crypto_aes_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\tunsigned int key_len)\n{\n\tstruct crypto_aes_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tint ret;\n\n\tret = crypto_aes_expand_key(ctx, in_key, key_len);\n\tif (!ret)\n\t\treturn 0;\n\n\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\treturn -EINVAL;\n}\nEXPORT_SYMBOL_GPL(crypto_aes_set_key);\n\n/* encrypt a block of text */\n\n#define f_rn(bo, bi, n, k)\tdo {\t\t\t\t\\\n\tbo[n] = crypto_ft_tab[0][byte(bi[n], 0)] ^\t\t\t\\\n\t\tcrypto_ft_tab[1][byte(bi[(n + 1) & 3], 1)] ^\t\t\\\n\t\tcrypto_ft_tab[2][byte(bi[(n + 2) & 3], 2)] ^\t\t\\\n\t\tcrypto_ft_tab[3][byte(bi[(n + 3) & 3], 3)] ^ *(k + n);\t\\\n} while (0)\n\n#define f_nround(bo, bi, k)\tdo {\\\n\tf_rn(bo, bi, 0, k);\t\\\n\tf_rn(bo, bi, 1, k);\t\\\n\tf_rn(bo, bi, 2, k);\t\\\n\tf_rn(bo, bi, 3, k);\t\\\n\tk += 4;\t\t\t\\\n} while (0)\n\n#define f_rl(bo, bi, n, k)\tdo {\t\t\t\t\\\n\tbo[n] = crypto_fl_tab[0][byte(bi[n], 0)] ^\t\t\t\\\n\t\tcrypto_fl_tab[1][byte(bi[(n + 1) & 3], 1)] ^\t\t\\\n\t\tcrypto_fl_tab[2][byte(bi[(n + 2) & 3], 2)] ^\t\t\\\n\t\tcrypto_fl_tab[3][byte(bi[(n + 3) & 3], 3)] ^ *(k + n);\t\\\n} while (0)\n\n#define f_lround(bo, bi, k)\tdo {\\\n\tf_rl(bo, bi, 0, k);\t\\\n\tf_rl(bo, bi, 1, k);\t\\\n\tf_rl(bo, bi, 2, k);\t\\\n\tf_rl(bo, bi, 3, k);\t\\\n} while (0)\n\nstatic void aes_encrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tconst struct crypto_aes_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *src = (const __le32 *)in;\n\t__le32 *dst = (__le32 *)out;\n\tu32 b0[4], b1[4];\n\tconst u32 *kp = ctx->key_enc + 4;\n\tconst int key_len = ctx->key_length;\n\n\tb0[0] = le32_to_cpu(src[0]) ^ ctx->key_enc[0];\n\tb0[1] = le32_to_cpu(src[1]) ^ ctx->key_enc[1];\n\tb0[2] = le32_to_cpu(src[2]) ^ ctx->key_enc[2];\n\tb0[3] = le32_to_cpu(src[3]) ^ ctx->key_enc[3];\n\n\tif (key_len > 24) {\n\t\tf_nround(b1, b0, kp);\n\t\tf_nround(b0, b1, kp);\n\t}\n\n\tif (key_len > 16) {\n\t\tf_nround(b1, b0, kp);\n\t\tf_nround(b0, b1, kp);\n\t}\n\n\tf_nround(b1, b0, kp);\n\tf_nround(b0, b1, kp);\n\tf_nround(b1, b0, kp);\n\tf_nround(b0, b1, kp);\n\tf_nround(b1, b0, kp);\n\tf_nround(b0, b1, kp);\n\tf_nround(b1, b0, kp);\n\tf_nround(b0, b1, kp);\n\tf_nround(b1, b0, kp);\n\tf_lround(b0, b1, kp);\n\n\tdst[0] = cpu_to_le32(b0[0]);\n\tdst[1] = cpu_to_le32(b0[1]);\n\tdst[2] = cpu_to_le32(b0[2]);\n\tdst[3] = cpu_to_le32(b0[3]);\n}\n\n/* decrypt a block of text */\n\n#define i_rn(bo, bi, n, k)\tdo {\t\t\t\t\\\n\tbo[n] = crypto_it_tab[0][byte(bi[n], 0)] ^\t\t\t\\\n\t\tcrypto_it_tab[1][byte(bi[(n + 3) & 3], 1)] ^\t\t\\\n\t\tcrypto_it_tab[2][byte(bi[(n + 2) & 3], 2)] ^\t\t\\\n\t\tcrypto_it_tab[3][byte(bi[(n + 1) & 3], 3)] ^ *(k + n);\t\\\n} while (0)\n\n#define i_nround(bo, bi, k)\tdo {\\\n\ti_rn(bo, bi, 0, k);\t\\\n\ti_rn(bo, bi, 1, k);\t\\\n\ti_rn(bo, bi, 2, k);\t\\\n\ti_rn(bo, bi, 3, k);\t\\\n\tk += 4;\t\t\t\\\n} while (0)\n\n#define i_rl(bo, bi, n, k)\tdo {\t\t\t\\\n\tbo[n] = crypto_il_tab[0][byte(bi[n], 0)] ^\t\t\\\n\tcrypto_il_tab[1][byte(bi[(n + 3) & 3], 1)] ^\t\t\\\n\tcrypto_il_tab[2][byte(bi[(n + 2) & 3], 2)] ^\t\t\\\n\tcrypto_il_tab[3][byte(bi[(n + 1) & 3], 3)] ^ *(k + n);\t\\\n} while (0)\n\n#define i_lround(bo, bi, k)\tdo {\\\n\ti_rl(bo, bi, 0, k);\t\\\n\ti_rl(bo, bi, 1, k);\t\\\n\ti_rl(bo, bi, 2, k);\t\\\n\ti_rl(bo, bi, 3, k);\t\\\n} while (0)\n\nstatic void aes_decrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tconst struct crypto_aes_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *src = (const __le32 *)in;\n\t__le32 *dst = (__le32 *)out;\n\tu32 b0[4], b1[4];\n\tconst int key_len = ctx->key_length;\n\tconst u32 *kp = ctx->key_dec + 4;\n\n\tb0[0] = le32_to_cpu(src[0]) ^  ctx->key_dec[0];\n\tb0[1] = le32_to_cpu(src[1]) ^  ctx->key_dec[1];\n\tb0[2] = le32_to_cpu(src[2]) ^  ctx->key_dec[2];\n\tb0[3] = le32_to_cpu(src[3]) ^  ctx->key_dec[3];\n\n\tif (key_len > 24) {\n\t\ti_nround(b1, b0, kp);\n\t\ti_nround(b0, b1, kp);\n\t}\n\n\tif (key_len > 16) {\n\t\ti_nround(b1, b0, kp);\n\t\ti_nround(b0, b1, kp);\n\t}\n\n\ti_nround(b1, b0, kp);\n\ti_nround(b0, b1, kp);\n\ti_nround(b1, b0, kp);\n\ti_nround(b0, b1, kp);\n\ti_nround(b1, b0, kp);\n\ti_nround(b0, b1, kp);\n\ti_nround(b1, b0, kp);\n\ti_nround(b0, b1, kp);\n\ti_nround(b1, b0, kp);\n\ti_lround(b0, b1, kp);\n\n\tdst[0] = cpu_to_le32(b0[0]);\n\tdst[1] = cpu_to_le32(b0[1]);\n\tdst[2] = cpu_to_le32(b0[2]);\n\tdst[3] = cpu_to_le32(b0[3]);\n}\n\nstatic struct crypto_alg aes_alg = {\n\t.cra_name\t\t=\t\"aes\",\n\t.cra_driver_name\t=\t\"aes-generic\",\n\t.cra_priority\t\t=\t100,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tAES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct crypto_aes_ctx),\n\t.cra_alignmask\t\t=\t3,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.cipher = {\n\t\t\t.cia_min_keysize\t=\tAES_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t=\tAES_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t=\tcrypto_aes_set_key,\n\t\t\t.cia_encrypt\t\t=\taes_encrypt,\n\t\t\t.cia_decrypt\t\t=\taes_decrypt\n\t\t}\n\t}\n};\n\nstatic int __init aes_init(void)\n{\n\treturn crypto_register_alg(&aes_alg);\n}\n\nstatic void __exit aes_fini(void)\n{\n\tcrypto_unregister_alg(&aes_alg);\n}\n\nmodule_init(aes_init);\nmodule_exit(aes_fini);\n\nMODULE_DESCRIPTION(\"Rijndael (AES) Cipher Algorithm\");\nMODULE_LICENSE(\"Dual BSD/GPL\");\nMODULE_ALIAS(\"aes\");\n", "/*\n * PRNG: Pseudo Random Number Generator\n *       Based on NIST Recommended PRNG From ANSI X9.31 Appendix A.2.4 using\n *       AES 128 cipher\n *\n *  (C) Neil Horman <nhorman@tuxdriver.com>\n *\n *  This program is free software; you can redistribute it and/or modify it\n *  under the terms of the GNU General Public License as published by the\n *  Free Software Foundation; either version 2 of the License, or (at your\n *  any later version.\n *\n *\n */\n\n#include <crypto/internal/rng.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/moduleparam.h>\n#include <linux/string.h>\n\n#include \"internal.h\"\n\n#define DEFAULT_PRNG_KEY \"0123456789abcdef\"\n#define DEFAULT_PRNG_KSZ 16\n#define DEFAULT_BLK_SZ 16\n#define DEFAULT_V_SEED \"zaybxcwdveuftgsh\"\n\n/*\n * Flags for the prng_context flags field\n */\n\n#define PRNG_FIXED_SIZE 0x1\n#define PRNG_NEED_RESET 0x2\n\n/*\n * Note: DT is our counter value\n *\t I is our intermediate value\n *\t V is our seed vector\n * See http://csrc.nist.gov/groups/STM/cavp/documents/rng/931rngext.pdf\n * for implementation details\n */\n\n\nstruct prng_context {\n\tspinlock_t prng_lock;\n\tunsigned char rand_data[DEFAULT_BLK_SZ];\n\tunsigned char last_rand_data[DEFAULT_BLK_SZ];\n\tunsigned char DT[DEFAULT_BLK_SZ];\n\tunsigned char I[DEFAULT_BLK_SZ];\n\tunsigned char V[DEFAULT_BLK_SZ];\n\tu32 rand_data_valid;\n\tstruct crypto_cipher *tfm;\n\tu32 flags;\n};\n\nstatic int dbg;\n\nstatic void hexdump(char *note, unsigned char *buf, unsigned int len)\n{\n\tif (dbg) {\n\t\tprintk(KERN_CRIT \"%s\", note);\n\t\tprint_hex_dump(KERN_CONT, \"\", DUMP_PREFIX_OFFSET,\n\t\t\t\t16, 1,\n\t\t\t\tbuf, len, false);\n\t}\n}\n\n#define dbgprint(format, args...) do {\\\nif (dbg)\\\n\tprintk(format, ##args);\\\n} while (0)\n\nstatic void xor_vectors(unsigned char *in1, unsigned char *in2,\n\t\t\tunsigned char *out, unsigned int size)\n{\n\tint i;\n\n\tfor (i = 0; i < size; i++)\n\t\tout[i] = in1[i] ^ in2[i];\n\n}\n/*\n * Returns DEFAULT_BLK_SZ bytes of random data per call\n * returns 0 if generation succeeded, <0 if something went wrong\n */\nstatic int _get_more_prng_bytes(struct prng_context *ctx, int cont_test)\n{\n\tint i;\n\tunsigned char tmp[DEFAULT_BLK_SZ];\n\tunsigned char *output = NULL;\n\n\n\tdbgprint(KERN_CRIT \"Calling _get_more_prng_bytes for context %p\\n\",\n\t\tctx);\n\n\thexdump(\"Input DT: \", ctx->DT, DEFAULT_BLK_SZ);\n\thexdump(\"Input I: \", ctx->I, DEFAULT_BLK_SZ);\n\thexdump(\"Input V: \", ctx->V, DEFAULT_BLK_SZ);\n\n\t/*\n\t * This algorithm is a 3 stage state machine\n\t */\n\tfor (i = 0; i < 3; i++) {\n\n\t\tswitch (i) {\n\t\tcase 0:\n\t\t\t/*\n\t\t\t * Start by encrypting the counter value\n\t\t\t * This gives us an intermediate value I\n\t\t\t */\n\t\t\tmemcpy(tmp, ctx->DT, DEFAULT_BLK_SZ);\n\t\t\toutput = ctx->I;\n\t\t\thexdump(\"tmp stage 0: \", tmp, DEFAULT_BLK_SZ);\n\t\t\tbreak;\n\t\tcase 1:\n\n\t\t\t/*\n\t\t\t * Next xor I with our secret vector V\n\t\t\t * encrypt that result to obtain our\n\t\t\t * pseudo random data which we output\n\t\t\t */\n\t\t\txor_vectors(ctx->I, ctx->V, tmp, DEFAULT_BLK_SZ);\n\t\t\thexdump(\"tmp stage 1: \", tmp, DEFAULT_BLK_SZ);\n\t\t\toutput = ctx->rand_data;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\t/*\n\t\t\t * First check that we didn't produce the same\n\t\t\t * random data that we did last time around through this\n\t\t\t */\n\t\t\tif (!memcmp(ctx->rand_data, ctx->last_rand_data,\n\t\t\t\t\tDEFAULT_BLK_SZ)) {\n\t\t\t\tif (cont_test) {\n\t\t\t\t\tpanic(\"cprng %p Failed repetition check!\\n\",\n\t\t\t\t\t\tctx);\n\t\t\t\t}\n\n\t\t\t\tprintk(KERN_ERR\n\t\t\t\t\t\"ctx %p Failed repetition check!\\n\",\n\t\t\t\t\tctx);\n\n\t\t\t\tctx->flags |= PRNG_NEED_RESET;\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tmemcpy(ctx->last_rand_data, ctx->rand_data,\n\t\t\t\tDEFAULT_BLK_SZ);\n\n\t\t\t/*\n\t\t\t * Lastly xor the random data with I\n\t\t\t * and encrypt that to obtain a new secret vector V\n\t\t\t */\n\t\t\txor_vectors(ctx->rand_data, ctx->I, tmp,\n\t\t\t\tDEFAULT_BLK_SZ);\n\t\t\toutput = ctx->V;\n\t\t\thexdump(\"tmp stage 2: \", tmp, DEFAULT_BLK_SZ);\n\t\t\tbreak;\n\t\t}\n\n\n\t\t/* do the encryption */\n\t\tcrypto_cipher_encrypt_one(ctx->tfm, output, tmp);\n\n\t}\n\n\t/*\n\t * Now update our DT value\n\t */\n\tfor (i = DEFAULT_BLK_SZ - 1; i >= 0; i--) {\n\t\tctx->DT[i] += 1;\n\t\tif (ctx->DT[i] != 0)\n\t\t\tbreak;\n\t}\n\n\tdbgprint(\"Returning new block for context %p\\n\", ctx);\n\tctx->rand_data_valid = 0;\n\n\thexdump(\"Output DT: \", ctx->DT, DEFAULT_BLK_SZ);\n\thexdump(\"Output I: \", ctx->I, DEFAULT_BLK_SZ);\n\thexdump(\"Output V: \", ctx->V, DEFAULT_BLK_SZ);\n\thexdump(\"New Random Data: \", ctx->rand_data, DEFAULT_BLK_SZ);\n\n\treturn 0;\n}\n\n/* Our exported functions */\nstatic int get_prng_bytes(char *buf, size_t nbytes, struct prng_context *ctx,\n\t\t\t\tint do_cont_test)\n{\n\tunsigned char *ptr = buf;\n\tunsigned int byte_count = (unsigned int)nbytes;\n\tint err;\n\n\n\tspin_lock_bh(&ctx->prng_lock);\n\n\terr = -EINVAL;\n\tif (ctx->flags & PRNG_NEED_RESET)\n\t\tgoto done;\n\n\t/*\n\t * If the FIXED_SIZE flag is on, only return whole blocks of\n\t * pseudo random data\n\t */\n\terr = -EINVAL;\n\tif (ctx->flags & PRNG_FIXED_SIZE) {\n\t\tif (nbytes < DEFAULT_BLK_SZ)\n\t\t\tgoto done;\n\t\tbyte_count = DEFAULT_BLK_SZ;\n\t}\n\n\terr = byte_count;\n\n\tdbgprint(KERN_CRIT \"getting %d random bytes for context %p\\n\",\n\t\tbyte_count, ctx);\n\n\nremainder:\n\tif (ctx->rand_data_valid == DEFAULT_BLK_SZ) {\n\t\tif (_get_more_prng_bytes(ctx, do_cont_test) < 0) {\n\t\t\tmemset(buf, 0, nbytes);\n\t\t\terr = -EINVAL;\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\t/*\n\t * Copy any data less than an entire block\n\t */\n\tif (byte_count < DEFAULT_BLK_SZ) {\nempty_rbuf:\n\t\twhile (ctx->rand_data_valid < DEFAULT_BLK_SZ) {\n\t\t\t*ptr = ctx->rand_data[ctx->rand_data_valid];\n\t\t\tptr++;\n\t\t\tbyte_count--;\n\t\t\tctx->rand_data_valid++;\n\t\t\tif (byte_count == 0)\n\t\t\t\tgoto done;\n\t\t}\n\t}\n\n\t/*\n\t * Now copy whole blocks\n\t */\n\tfor (; byte_count >= DEFAULT_BLK_SZ; byte_count -= DEFAULT_BLK_SZ) {\n\t\tif (ctx->rand_data_valid == DEFAULT_BLK_SZ) {\n\t\t\tif (_get_more_prng_bytes(ctx, do_cont_test) < 0) {\n\t\t\t\tmemset(buf, 0, nbytes);\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t\tif (ctx->rand_data_valid > 0)\n\t\t\tgoto empty_rbuf;\n\t\tmemcpy(ptr, ctx->rand_data, DEFAULT_BLK_SZ);\n\t\tctx->rand_data_valid += DEFAULT_BLK_SZ;\n\t\tptr += DEFAULT_BLK_SZ;\n\t}\n\n\t/*\n\t * Now go back and get any remaining partial block\n\t */\n\tif (byte_count)\n\t\tgoto remainder;\n\ndone:\n\tspin_unlock_bh(&ctx->prng_lock);\n\tdbgprint(KERN_CRIT \"returning %d from get_prng_bytes in context %p\\n\",\n\t\terr, ctx);\n\treturn err;\n}\n\nstatic void free_prng_context(struct prng_context *ctx)\n{\n\tcrypto_free_cipher(ctx->tfm);\n}\n\nstatic int reset_prng_context(struct prng_context *ctx,\n\t\t\t      unsigned char *key, size_t klen,\n\t\t\t      unsigned char *V, unsigned char *DT)\n{\n\tint ret;\n\tunsigned char *prng_key;\n\n\tspin_lock_bh(&ctx->prng_lock);\n\tctx->flags |= PRNG_NEED_RESET;\n\n\tprng_key = (key != NULL) ? key : (unsigned char *)DEFAULT_PRNG_KEY;\n\n\tif (!key)\n\t\tklen = DEFAULT_PRNG_KSZ;\n\n\tif (V)\n\t\tmemcpy(ctx->V, V, DEFAULT_BLK_SZ);\n\telse\n\t\tmemcpy(ctx->V, DEFAULT_V_SEED, DEFAULT_BLK_SZ);\n\n\tif (DT)\n\t\tmemcpy(ctx->DT, DT, DEFAULT_BLK_SZ);\n\telse\n\t\tmemset(ctx->DT, 0, DEFAULT_BLK_SZ);\n\n\tmemset(ctx->rand_data, 0, DEFAULT_BLK_SZ);\n\tmemset(ctx->last_rand_data, 0, DEFAULT_BLK_SZ);\n\n\tctx->rand_data_valid = DEFAULT_BLK_SZ;\n\n\tret = crypto_cipher_setkey(ctx->tfm, prng_key, klen);\n\tif (ret) {\n\t\tdbgprint(KERN_CRIT \"PRNG: setkey() failed flags=%x\\n\",\n\t\t\tcrypto_cipher_get_flags(ctx->tfm));\n\t\tgoto out;\n\t}\n\n\tret = 0;\n\tctx->flags &= ~PRNG_NEED_RESET;\nout:\n\tspin_unlock_bh(&ctx->prng_lock);\n\treturn ret;\n}\n\nstatic int cprng_init(struct crypto_tfm *tfm)\n{\n\tstruct prng_context *ctx = crypto_tfm_ctx(tfm);\n\n\tspin_lock_init(&ctx->prng_lock);\n\tctx->tfm = crypto_alloc_cipher(\"aes\", 0, 0);\n\tif (IS_ERR(ctx->tfm)) {\n\t\tdbgprint(KERN_CRIT \"Failed to alloc tfm for context %p\\n\",\n\t\t\t\tctx);\n\t\treturn PTR_ERR(ctx->tfm);\n\t}\n\n\tif (reset_prng_context(ctx, NULL, DEFAULT_PRNG_KSZ, NULL, NULL) < 0)\n\t\treturn -EINVAL;\n\n\t/*\n\t * after allocation, we should always force the user to reset\n\t * so they don't inadvertently use the insecure default values\n\t * without specifying them intentially\n\t */\n\tctx->flags |= PRNG_NEED_RESET;\n\treturn 0;\n}\n\nstatic void cprng_exit(struct crypto_tfm *tfm)\n{\n\tfree_prng_context(crypto_tfm_ctx(tfm));\n}\n\nstatic int cprng_get_random(struct crypto_rng *tfm, u8 *rdata,\n\t\t\t    unsigned int dlen)\n{\n\tstruct prng_context *prng = crypto_rng_ctx(tfm);\n\n\treturn get_prng_bytes(rdata, dlen, prng, 0);\n}\n\n/*\n *  This is the cprng_registered reset method the seed value is\n *  interpreted as the tuple { V KEY DT}\n *  V and KEY are required during reset, and DT is optional, detected\n *  as being present by testing the length of the seed\n */\nstatic int cprng_reset(struct crypto_rng *tfm, u8 *seed, unsigned int slen)\n{\n\tstruct prng_context *prng = crypto_rng_ctx(tfm);\n\tu8 *key = seed + DEFAULT_BLK_SZ;\n\tu8 *dt = NULL;\n\n\tif (slen < DEFAULT_PRNG_KSZ + DEFAULT_BLK_SZ)\n\t\treturn -EINVAL;\n\n\tif (slen >= (2 * DEFAULT_BLK_SZ + DEFAULT_PRNG_KSZ))\n\t\tdt = key + DEFAULT_PRNG_KSZ;\n\n\treset_prng_context(prng, key, DEFAULT_PRNG_KSZ, seed, dt);\n\n\tif (prng->flags & PRNG_NEED_RESET)\n\t\treturn -EINVAL;\n\treturn 0;\n}\n\n#ifdef CONFIG_CRYPTO_FIPS\nstatic int fips_cprng_get_random(struct crypto_rng *tfm, u8 *rdata,\n\t\t\t    unsigned int dlen)\n{\n\tstruct prng_context *prng = crypto_rng_ctx(tfm);\n\n\treturn get_prng_bytes(rdata, dlen, prng, 1);\n}\n\nstatic int fips_cprng_reset(struct crypto_rng *tfm, u8 *seed, unsigned int slen)\n{\n\tu8 rdata[DEFAULT_BLK_SZ];\n\tu8 *key = seed + DEFAULT_BLK_SZ;\n\tint rc;\n\n\tstruct prng_context *prng = crypto_rng_ctx(tfm);\n\n\tif (slen < DEFAULT_PRNG_KSZ + DEFAULT_BLK_SZ)\n\t\treturn -EINVAL;\n\n\t/* fips strictly requires seed != key */\n\tif (!memcmp(seed, key, DEFAULT_PRNG_KSZ))\n\t\treturn -EINVAL;\n\n\trc = cprng_reset(tfm, seed, slen);\n\n\tif (!rc)\n\t\tgoto out;\n\n\t/* this primes our continuity test */\n\trc = get_prng_bytes(rdata, DEFAULT_BLK_SZ, prng, 0);\n\tprng->rand_data_valid = DEFAULT_BLK_SZ;\n\nout:\n\treturn rc;\n}\n#endif\n\nstatic struct crypto_alg rng_algs[] = { {\n\t.cra_name\t\t= \"stdrng\",\n\t.cra_driver_name\t= \"ansi_cprng\",\n\t.cra_priority\t\t= 100,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_RNG,\n\t.cra_ctxsize\t\t= sizeof(struct prng_context),\n\t.cra_type\t\t= &crypto_rng_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= cprng_init,\n\t.cra_exit\t\t= cprng_exit,\n\t.cra_u\t\t\t= {\n\t\t.rng = {\n\t\t\t.rng_make_random\t= cprng_get_random,\n\t\t\t.rng_reset\t\t= cprng_reset,\n\t\t\t.seedsize = DEFAULT_PRNG_KSZ + 2*DEFAULT_BLK_SZ,\n\t\t}\n\t}\n#ifdef CONFIG_CRYPTO_FIPS\n}, {\n\t.cra_name\t\t= \"fips(ansi_cprng)\",\n\t.cra_driver_name\t= \"fips_ansi_cprng\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_RNG,\n\t.cra_ctxsize\t\t= sizeof(struct prng_context),\n\t.cra_type\t\t= &crypto_rng_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= cprng_init,\n\t.cra_exit\t\t= cprng_exit,\n\t.cra_u\t\t\t= {\n\t\t.rng = {\n\t\t\t.rng_make_random\t= fips_cprng_get_random,\n\t\t\t.rng_reset\t\t= fips_cprng_reset,\n\t\t\t.seedsize = DEFAULT_PRNG_KSZ + 2*DEFAULT_BLK_SZ,\n\t\t}\n\t}\n#endif\n} };\n\n/* Module initalization */\nstatic int __init prng_mod_init(void)\n{\n\treturn crypto_register_algs(rng_algs, ARRAY_SIZE(rng_algs));\n}\n\nstatic void __exit prng_mod_fini(void)\n{\n\tcrypto_unregister_algs(rng_algs, ARRAY_SIZE(rng_algs));\n}\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Software Pseudo Random Number Generator\");\nMODULE_AUTHOR(\"Neil Horman <nhorman@tuxdriver.com>\");\nmodule_param(dbg, int, 0);\nMODULE_PARM_DESC(dbg, \"Boolean to enable debugging (0/1 == off/on)\");\nmodule_init(prng_mod_init);\nmodule_exit(prng_mod_fini);\nMODULE_ALIAS(\"stdrng\");\n", "/*\n * Cryptographic API.\n *\n * Anubis Algorithm\n *\n * The Anubis algorithm was developed by Paulo S. L. M. Barreto and\n * Vincent Rijmen.\n *\n * See\n *\n *\tP.S.L.M. Barreto, V. Rijmen,\n *\t``The Anubis block cipher,''\n *\tNESSIE submission, 2000.\n *\n * This software implements the \"tweaked\" version of Anubis.\n * Only the S-box and (consequently) the rounds constants have been\n * changed.\n *\n * The original authors have disclaimed all copyright interest in this\n * code and thus put it in the public domain. The subsequent authors\n * have put this under the GNU General Public License.\n *\n * By Aaron Grothe ajgrothe@yahoo.com, October 28, 2004\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <asm/byteorder.h>\n#include <linux/crypto.h>\n#include <linux/types.h>\n\n#define ANUBIS_MIN_KEY_SIZE\t16\n#define ANUBIS_MAX_KEY_SIZE\t40\n#define ANUBIS_BLOCK_SIZE\t16\n#define ANUBIS_MAX_N\t\t10\n#define ANUBIS_MAX_ROUNDS\t(8 + ANUBIS_MAX_N)\n\nstruct anubis_ctx {\n\tint key_len; // in bits\n\tint R;\n\tu32 E[ANUBIS_MAX_ROUNDS + 1][4];\n\tu32 D[ANUBIS_MAX_ROUNDS + 1][4];\n};\n\nstatic const u32 T0[256] = {\n\t0xba69d2bbU, 0x54a84de5U, 0x2f5ebce2U, 0x74e8cd25U,\n\t0x53a651f7U, 0xd3bb6bd0U, 0xd2b96fd6U, 0x4d9a29b3U,\n\t0x50a05dfdU, 0xac458acfU, 0x8d070e09U, 0xbf63c6a5U,\n\t0x70e0dd3dU, 0x52a455f1U, 0x9a29527bU, 0x4c982db5U,\n\t0xeac98f46U, 0xd5b773c4U, 0x97336655U, 0xd1bf63dcU,\n\t0x3366ccaaU, 0x51a259fbU, 0x5bb671c7U, 0xa651a2f3U,\n\t0xdea15ffeU, 0x48903dadU, 0xa84d9ad7U, 0x992f5e71U,\n\t0xdbab4be0U, 0x3264c8acU, 0xb773e695U, 0xfce5d732U,\n\t0xe3dbab70U, 0x9e214263U, 0x913f7e41U, 0x9b2b567dU,\n\t0xe2d9af76U, 0xbb6bd6bdU, 0x4182199bU, 0x6edca579U,\n\t0xa557aef9U, 0xcb8b0b80U, 0x6bd6b167U, 0x95376e59U,\n\t0xa15fbee1U, 0xf3fbeb10U, 0xb17ffe81U, 0x0204080cU,\n\t0xcc851792U, 0xc49537a2U, 0x1d3a744eU, 0x14285078U,\n\t0xc39b2bb0U, 0x63c69157U, 0xdaa94fe6U, 0x5dba69d3U,\n\t0x5fbe61dfU, 0xdca557f2U, 0x7dfae913U, 0xcd871394U,\n\t0x7ffee11fU, 0x5ab475c1U, 0x6cd8ad75U, 0x5cb86dd5U,\n\t0xf7f3fb08U, 0x264c98d4U, 0xffe3db38U, 0xedc79354U,\n\t0xe8cd874aU, 0x9d274e69U, 0x6fdea17fU, 0x8e010203U,\n\t0x19326456U, 0xa05dbae7U, 0xf0fde71aU, 0x890f1e11U,\n\t0x0f1e3c22U, 0x070e1c12U, 0xaf4386c5U, 0xfbebcb20U,\n\t0x08102030U, 0x152a547eU, 0x0d1a342eU, 0x04081018U,\n\t0x01020406U, 0x64c88d45U, 0xdfa35bf8U, 0x76ecc529U,\n\t0x79f2f90bU, 0xdda753f4U, 0x3d7af48eU, 0x162c5874U,\n\t0x3f7efc82U, 0x376edcb2U, 0x6ddaa973U, 0x3870e090U,\n\t0xb96fdeb1U, 0x73e6d137U, 0xe9cf834cU, 0x356ad4beU,\n\t0x55aa49e3U, 0x71e2d93bU, 0x7bf6f107U, 0x8c050a0fU,\n\t0x72e4d531U, 0x880d1a17U, 0xf6f1ff0eU, 0x2a54a8fcU,\n\t0x3e7cf884U, 0x5ebc65d9U, 0x274e9cd2U, 0x468c0589U,\n\t0x0c183028U, 0x65ca8943U, 0x68d0bd6dU, 0x61c2995bU,\n\t0x03060c0aU, 0xc19f23bcU, 0x57ae41efU, 0xd6b17fceU,\n\t0xd9af43ecU, 0x58b07dcdU, 0xd8ad47eaU, 0x66cc8549U,\n\t0xd7b37bc8U, 0x3a74e89cU, 0xc88d078aU, 0x3c78f088U,\n\t0xfae9cf26U, 0x96316253U, 0xa753a6f5U, 0x982d5a77U,\n\t0xecc59752U, 0xb86ddab7U, 0xc7933ba8U, 0xae4182c3U,\n\t0x69d2b96bU, 0x4b9631a7U, 0xab4b96ddU, 0xa94f9ed1U,\n\t0x67ce814fU, 0x0a14283cU, 0x478e018fU, 0xf2f9ef16U,\n\t0xb577ee99U, 0x224488ccU, 0xe5d7b364U, 0xeec19f5eU,\n\t0xbe61c2a3U, 0x2b56acfaU, 0x811f3e21U, 0x1224486cU,\n\t0x831b362dU, 0x1b366c5aU, 0x0e1c3824U, 0x23468ccaU,\n\t0xf5f7f304U, 0x458a0983U, 0x214284c6U, 0xce811f9eU,\n\t0x499239abU, 0x2c58b0e8U, 0xf9efc32cU, 0xe6d1bf6eU,\n\t0xb671e293U, 0x2850a0f0U, 0x172e5c72U, 0x8219322bU,\n\t0x1a34685cU, 0x8b0b161dU, 0xfee1df3eU, 0x8a09121bU,\n\t0x09122436U, 0xc98f038cU, 0x87132635U, 0x4e9c25b9U,\n\t0xe1dfa37cU, 0x2e5cb8e4U, 0xe4d5b762U, 0xe0dda77aU,\n\t0xebcb8b40U, 0x903d7a47U, 0xa455aaffU, 0x1e3c7844U,\n\t0x85172e39U, 0x60c09d5dU, 0x00000000U, 0x254a94deU,\n\t0xf4f5f702U, 0xf1ffe31cU, 0x94356a5fU, 0x0b162c3aU,\n\t0xe7d3bb68U, 0x75eac923U, 0xefc39b58U, 0x3468d0b8U,\n\t0x3162c4a6U, 0xd4b577c2U, 0xd0bd67daU, 0x86112233U,\n\t0x7efce519U, 0xad478ec9U, 0xfde7d334U, 0x2952a4f6U,\n\t0x3060c0a0U, 0x3b76ec9aU, 0x9f234665U, 0xf8edc72aU,\n\t0xc6913faeU, 0x13264c6aU, 0x060c1814U, 0x050a141eU,\n\t0xc59733a4U, 0x11224466U, 0x77eec12fU, 0x7cf8ed15U,\n\t0x7af4f501U, 0x78f0fd0dU, 0x366cd8b4U, 0x1c387048U,\n\t0x3972e496U, 0x59b279cbU, 0x18306050U, 0x56ac45e9U,\n\t0xb37bf68dU, 0xb07dfa87U, 0x244890d8U, 0x204080c0U,\n\t0xb279f28bU, 0x9239724bU, 0xa35bb6edU, 0xc09d27baU,\n\t0x44880d85U, 0x62c49551U, 0x10204060U, 0xb475ea9fU,\n\t0x84152a3fU, 0x43861197U, 0x933b764dU, 0xc2992fb6U,\n\t0x4a9435a1U, 0xbd67cea9U, 0x8f030605U, 0x2d5ab4eeU,\n\t0xbc65caafU, 0x9c254a6fU, 0x6ad4b561U, 0x40801d9dU,\n\t0xcf831b98U, 0xa259b2ebU, 0x801d3a27U, 0x4f9e21bfU,\n\t0x1f3e7c42U, 0xca890f86U, 0xaa4992dbU, 0x42841591U,\n};\n\nstatic const u32 T1[256] = {\n\t0x69babbd2U, 0xa854e54dU, 0x5e2fe2bcU, 0xe87425cdU,\n\t0xa653f751U, 0xbbd3d06bU, 0xb9d2d66fU, 0x9a4db329U,\n\t0xa050fd5dU, 0x45accf8aU, 0x078d090eU, 0x63bfa5c6U,\n\t0xe0703dddU, 0xa452f155U, 0x299a7b52U, 0x984cb52dU,\n\t0xc9ea468fU, 0xb7d5c473U, 0x33975566U, 0xbfd1dc63U,\n\t0x6633aaccU, 0xa251fb59U, 0xb65bc771U, 0x51a6f3a2U,\n\t0xa1defe5fU, 0x9048ad3dU, 0x4da8d79aU, 0x2f99715eU,\n\t0xabdbe04bU, 0x6432acc8U, 0x73b795e6U, 0xe5fc32d7U,\n\t0xdbe370abU, 0x219e6342U, 0x3f91417eU, 0x2b9b7d56U,\n\t0xd9e276afU, 0x6bbbbdd6U, 0x82419b19U, 0xdc6e79a5U,\n\t0x57a5f9aeU, 0x8bcb800bU, 0xd66b67b1U, 0x3795596eU,\n\t0x5fa1e1beU, 0xfbf310ebU, 0x7fb181feU, 0x04020c08U,\n\t0x85cc9217U, 0x95c4a237U, 0x3a1d4e74U, 0x28147850U,\n\t0x9bc3b02bU, 0xc6635791U, 0xa9dae64fU, 0xba5dd369U,\n\t0xbe5fdf61U, 0xa5dcf257U, 0xfa7d13e9U, 0x87cd9413U,\n\t0xfe7f1fe1U, 0xb45ac175U, 0xd86c75adU, 0xb85cd56dU,\n\t0xf3f708fbU, 0x4c26d498U, 0xe3ff38dbU, 0xc7ed5493U,\n\t0xcde84a87U, 0x279d694eU, 0xde6f7fa1U, 0x018e0302U,\n\t0x32195664U, 0x5da0e7baU, 0xfdf01ae7U, 0x0f89111eU,\n\t0x1e0f223cU, 0x0e07121cU, 0x43afc586U, 0xebfb20cbU,\n\t0x10083020U, 0x2a157e54U, 0x1a0d2e34U, 0x08041810U,\n\t0x02010604U, 0xc864458dU, 0xa3dff85bU, 0xec7629c5U,\n\t0xf2790bf9U, 0xa7ddf453U, 0x7a3d8ef4U, 0x2c167458U,\n\t0x7e3f82fcU, 0x6e37b2dcU, 0xda6d73a9U, 0x703890e0U,\n\t0x6fb9b1deU, 0xe67337d1U, 0xcfe94c83U, 0x6a35bed4U,\n\t0xaa55e349U, 0xe2713bd9U, 0xf67b07f1U, 0x058c0f0aU,\n\t0xe47231d5U, 0x0d88171aU, 0xf1f60effU, 0x542afca8U,\n\t0x7c3e84f8U, 0xbc5ed965U, 0x4e27d29cU, 0x8c468905U,\n\t0x180c2830U, 0xca654389U, 0xd0686dbdU, 0xc2615b99U,\n\t0x06030a0cU, 0x9fc1bc23U, 0xae57ef41U, 0xb1d6ce7fU,\n\t0xafd9ec43U, 0xb058cd7dU, 0xadd8ea47U, 0xcc664985U,\n\t0xb3d7c87bU, 0x743a9ce8U, 0x8dc88a07U, 0x783c88f0U,\n\t0xe9fa26cfU, 0x31965362U, 0x53a7f5a6U, 0x2d98775aU,\n\t0xc5ec5297U, 0x6db8b7daU, 0x93c7a83bU, 0x41aec382U,\n\t0xd2696bb9U, 0x964ba731U, 0x4babdd96U, 0x4fa9d19eU,\n\t0xce674f81U, 0x140a3c28U, 0x8e478f01U, 0xf9f216efU,\n\t0x77b599eeU, 0x4422cc88U, 0xd7e564b3U, 0xc1ee5e9fU,\n\t0x61bea3c2U, 0x562bfaacU, 0x1f81213eU, 0x24126c48U,\n\t0x1b832d36U, 0x361b5a6cU, 0x1c0e2438U, 0x4623ca8cU,\n\t0xf7f504f3U, 0x8a458309U, 0x4221c684U, 0x81ce9e1fU,\n\t0x9249ab39U, 0x582ce8b0U, 0xeff92cc3U, 0xd1e66ebfU,\n\t0x71b693e2U, 0x5028f0a0U, 0x2e17725cU, 0x19822b32U,\n\t0x341a5c68U, 0x0b8b1d16U, 0xe1fe3edfU, 0x098a1b12U,\n\t0x12093624U, 0x8fc98c03U, 0x13873526U, 0x9c4eb925U,\n\t0xdfe17ca3U, 0x5c2ee4b8U, 0xd5e462b7U, 0xdde07aa7U,\n\t0xcbeb408bU, 0x3d90477aU, 0x55a4ffaaU, 0x3c1e4478U,\n\t0x1785392eU, 0xc0605d9dU, 0x00000000U, 0x4a25de94U,\n\t0xf5f402f7U, 0xfff11ce3U, 0x35945f6aU, 0x160b3a2cU,\n\t0xd3e768bbU, 0xea7523c9U, 0xc3ef589bU, 0x6834b8d0U,\n\t0x6231a6c4U, 0xb5d4c277U, 0xbdd0da67U, 0x11863322U,\n\t0xfc7e19e5U, 0x47adc98eU, 0xe7fd34d3U, 0x5229f6a4U,\n\t0x6030a0c0U, 0x763b9aecU, 0x239f6546U, 0xedf82ac7U,\n\t0x91c6ae3fU, 0x26136a4cU, 0x0c061418U, 0x0a051e14U,\n\t0x97c5a433U, 0x22116644U, 0xee772fc1U, 0xf87c15edU,\n\t0xf47a01f5U, 0xf0780dfdU, 0x6c36b4d8U, 0x381c4870U,\n\t0x723996e4U, 0xb259cb79U, 0x30185060U, 0xac56e945U,\n\t0x7bb38df6U, 0x7db087faU, 0x4824d890U, 0x4020c080U,\n\t0x79b28bf2U, 0x39924b72U, 0x5ba3edb6U, 0x9dc0ba27U,\n\t0x8844850dU, 0xc4625195U, 0x20106040U, 0x75b49feaU,\n\t0x15843f2aU, 0x86439711U, 0x3b934d76U, 0x99c2b62fU,\n\t0x944aa135U, 0x67bda9ceU, 0x038f0506U, 0x5a2deeb4U,\n\t0x65bcafcaU, 0x259c6f4aU, 0xd46a61b5U, 0x80409d1dU,\n\t0x83cf981bU, 0x59a2ebb2U, 0x1d80273aU, 0x9e4fbf21U,\n\t0x3e1f427cU, 0x89ca860fU, 0x49aadb92U, 0x84429115U,\n};\n\nstatic const u32 T2[256] = {\n\t0xd2bbba69U, 0x4de554a8U, 0xbce22f5eU, 0xcd2574e8U,\n\t0x51f753a6U, 0x6bd0d3bbU, 0x6fd6d2b9U, 0x29b34d9aU,\n\t0x5dfd50a0U, 0x8acfac45U, 0x0e098d07U, 0xc6a5bf63U,\n\t0xdd3d70e0U, 0x55f152a4U, 0x527b9a29U, 0x2db54c98U,\n\t0x8f46eac9U, 0x73c4d5b7U, 0x66559733U, 0x63dcd1bfU,\n\t0xccaa3366U, 0x59fb51a2U, 0x71c75bb6U, 0xa2f3a651U,\n\t0x5ffedea1U, 0x3dad4890U, 0x9ad7a84dU, 0x5e71992fU,\n\t0x4be0dbabU, 0xc8ac3264U, 0xe695b773U, 0xd732fce5U,\n\t0xab70e3dbU, 0x42639e21U, 0x7e41913fU, 0x567d9b2bU,\n\t0xaf76e2d9U, 0xd6bdbb6bU, 0x199b4182U, 0xa5796edcU,\n\t0xaef9a557U, 0x0b80cb8bU, 0xb1676bd6U, 0x6e599537U,\n\t0xbee1a15fU, 0xeb10f3fbU, 0xfe81b17fU, 0x080c0204U,\n\t0x1792cc85U, 0x37a2c495U, 0x744e1d3aU, 0x50781428U,\n\t0x2bb0c39bU, 0x915763c6U, 0x4fe6daa9U, 0x69d35dbaU,\n\t0x61df5fbeU, 0x57f2dca5U, 0xe9137dfaU, 0x1394cd87U,\n\t0xe11f7ffeU, 0x75c15ab4U, 0xad756cd8U, 0x6dd55cb8U,\n\t0xfb08f7f3U, 0x98d4264cU, 0xdb38ffe3U, 0x9354edc7U,\n\t0x874ae8cdU, 0x4e699d27U, 0xa17f6fdeU, 0x02038e01U,\n\t0x64561932U, 0xbae7a05dU, 0xe71af0fdU, 0x1e11890fU,\n\t0x3c220f1eU, 0x1c12070eU, 0x86c5af43U, 0xcb20fbebU,\n\t0x20300810U, 0x547e152aU, 0x342e0d1aU, 0x10180408U,\n\t0x04060102U, 0x8d4564c8U, 0x5bf8dfa3U, 0xc52976ecU,\n\t0xf90b79f2U, 0x53f4dda7U, 0xf48e3d7aU, 0x5874162cU,\n\t0xfc823f7eU, 0xdcb2376eU, 0xa9736ddaU, 0xe0903870U,\n\t0xdeb1b96fU, 0xd13773e6U, 0x834ce9cfU, 0xd4be356aU,\n\t0x49e355aaU, 0xd93b71e2U, 0xf1077bf6U, 0x0a0f8c05U,\n\t0xd53172e4U, 0x1a17880dU, 0xff0ef6f1U, 0xa8fc2a54U,\n\t0xf8843e7cU, 0x65d95ebcU, 0x9cd2274eU, 0x0589468cU,\n\t0x30280c18U, 0x894365caU, 0xbd6d68d0U, 0x995b61c2U,\n\t0x0c0a0306U, 0x23bcc19fU, 0x41ef57aeU, 0x7fced6b1U,\n\t0x43ecd9afU, 0x7dcd58b0U, 0x47ead8adU, 0x854966ccU,\n\t0x7bc8d7b3U, 0xe89c3a74U, 0x078ac88dU, 0xf0883c78U,\n\t0xcf26fae9U, 0x62539631U, 0xa6f5a753U, 0x5a77982dU,\n\t0x9752ecc5U, 0xdab7b86dU, 0x3ba8c793U, 0x82c3ae41U,\n\t0xb96b69d2U, 0x31a74b96U, 0x96ddab4bU, 0x9ed1a94fU,\n\t0x814f67ceU, 0x283c0a14U, 0x018f478eU, 0xef16f2f9U,\n\t0xee99b577U, 0x88cc2244U, 0xb364e5d7U, 0x9f5eeec1U,\n\t0xc2a3be61U, 0xacfa2b56U, 0x3e21811fU, 0x486c1224U,\n\t0x362d831bU, 0x6c5a1b36U, 0x38240e1cU, 0x8cca2346U,\n\t0xf304f5f7U, 0x0983458aU, 0x84c62142U, 0x1f9ece81U,\n\t0x39ab4992U, 0xb0e82c58U, 0xc32cf9efU, 0xbf6ee6d1U,\n\t0xe293b671U, 0xa0f02850U, 0x5c72172eU, 0x322b8219U,\n\t0x685c1a34U, 0x161d8b0bU, 0xdf3efee1U, 0x121b8a09U,\n\t0x24360912U, 0x038cc98fU, 0x26358713U, 0x25b94e9cU,\n\t0xa37ce1dfU, 0xb8e42e5cU, 0xb762e4d5U, 0xa77ae0ddU,\n\t0x8b40ebcbU, 0x7a47903dU, 0xaaffa455U, 0x78441e3cU,\n\t0x2e398517U, 0x9d5d60c0U, 0x00000000U, 0x94de254aU,\n\t0xf702f4f5U, 0xe31cf1ffU, 0x6a5f9435U, 0x2c3a0b16U,\n\t0xbb68e7d3U, 0xc92375eaU, 0x9b58efc3U, 0xd0b83468U,\n\t0xc4a63162U, 0x77c2d4b5U, 0x67dad0bdU, 0x22338611U,\n\t0xe5197efcU, 0x8ec9ad47U, 0xd334fde7U, 0xa4f62952U,\n\t0xc0a03060U, 0xec9a3b76U, 0x46659f23U, 0xc72af8edU,\n\t0x3faec691U, 0x4c6a1326U, 0x1814060cU, 0x141e050aU,\n\t0x33a4c597U, 0x44661122U, 0xc12f77eeU, 0xed157cf8U,\n\t0xf5017af4U, 0xfd0d78f0U, 0xd8b4366cU, 0x70481c38U,\n\t0xe4963972U, 0x79cb59b2U, 0x60501830U, 0x45e956acU,\n\t0xf68db37bU, 0xfa87b07dU, 0x90d82448U, 0x80c02040U,\n\t0xf28bb279U, 0x724b9239U, 0xb6eda35bU, 0x27bac09dU,\n\t0x0d854488U, 0x955162c4U, 0x40601020U, 0xea9fb475U,\n\t0x2a3f8415U, 0x11974386U, 0x764d933bU, 0x2fb6c299U,\n\t0x35a14a94U, 0xcea9bd67U, 0x06058f03U, 0xb4ee2d5aU,\n\t0xcaafbc65U, 0x4a6f9c25U, 0xb5616ad4U, 0x1d9d4080U,\n\t0x1b98cf83U, 0xb2eba259U, 0x3a27801dU, 0x21bf4f9eU,\n\t0x7c421f3eU, 0x0f86ca89U, 0x92dbaa49U, 0x15914284U,\n};\n\nstatic const u32 T3[256] = {\n\t0xbbd269baU, 0xe54da854U, 0xe2bc5e2fU, 0x25cde874U,\n\t0xf751a653U, 0xd06bbbd3U, 0xd66fb9d2U, 0xb3299a4dU,\n\t0xfd5da050U, 0xcf8a45acU, 0x090e078dU, 0xa5c663bfU,\n\t0x3ddde070U, 0xf155a452U, 0x7b52299aU, 0xb52d984cU,\n\t0x468fc9eaU, 0xc473b7d5U, 0x55663397U, 0xdc63bfd1U,\n\t0xaacc6633U, 0xfb59a251U, 0xc771b65bU, 0xf3a251a6U,\n\t0xfe5fa1deU, 0xad3d9048U, 0xd79a4da8U, 0x715e2f99U,\n\t0xe04babdbU, 0xacc86432U, 0x95e673b7U, 0x32d7e5fcU,\n\t0x70abdbe3U, 0x6342219eU, 0x417e3f91U, 0x7d562b9bU,\n\t0x76afd9e2U, 0xbdd66bbbU, 0x9b198241U, 0x79a5dc6eU,\n\t0xf9ae57a5U, 0x800b8bcbU, 0x67b1d66bU, 0x596e3795U,\n\t0xe1be5fa1U, 0x10ebfbf3U, 0x81fe7fb1U, 0x0c080402U,\n\t0x921785ccU, 0xa23795c4U, 0x4e743a1dU, 0x78502814U,\n\t0xb02b9bc3U, 0x5791c663U, 0xe64fa9daU, 0xd369ba5dU,\n\t0xdf61be5fU, 0xf257a5dcU, 0x13e9fa7dU, 0x941387cdU,\n\t0x1fe1fe7fU, 0xc175b45aU, 0x75add86cU, 0xd56db85cU,\n\t0x08fbf3f7U, 0xd4984c26U, 0x38dbe3ffU, 0x5493c7edU,\n\t0x4a87cde8U, 0x694e279dU, 0x7fa1de6fU, 0x0302018eU,\n\t0x56643219U, 0xe7ba5da0U, 0x1ae7fdf0U, 0x111e0f89U,\n\t0x223c1e0fU, 0x121c0e07U, 0xc58643afU, 0x20cbebfbU,\n\t0x30201008U, 0x7e542a15U, 0x2e341a0dU, 0x18100804U,\n\t0x06040201U, 0x458dc864U, 0xf85ba3dfU, 0x29c5ec76U,\n\t0x0bf9f279U, 0xf453a7ddU, 0x8ef47a3dU, 0x74582c16U,\n\t0x82fc7e3fU, 0xb2dc6e37U, 0x73a9da6dU, 0x90e07038U,\n\t0xb1de6fb9U, 0x37d1e673U, 0x4c83cfe9U, 0xbed46a35U,\n\t0xe349aa55U, 0x3bd9e271U, 0x07f1f67bU, 0x0f0a058cU,\n\t0x31d5e472U, 0x171a0d88U, 0x0efff1f6U, 0xfca8542aU,\n\t0x84f87c3eU, 0xd965bc5eU, 0xd29c4e27U, 0x89058c46U,\n\t0x2830180cU, 0x4389ca65U, 0x6dbdd068U, 0x5b99c261U,\n\t0x0a0c0603U, 0xbc239fc1U, 0xef41ae57U, 0xce7fb1d6U,\n\t0xec43afd9U, 0xcd7db058U, 0xea47add8U, 0x4985cc66U,\n\t0xc87bb3d7U, 0x9ce8743aU, 0x8a078dc8U, 0x88f0783cU,\n\t0x26cfe9faU, 0x53623196U, 0xf5a653a7U, 0x775a2d98U,\n\t0x5297c5ecU, 0xb7da6db8U, 0xa83b93c7U, 0xc38241aeU,\n\t0x6bb9d269U, 0xa731964bU, 0xdd964babU, 0xd19e4fa9U,\n\t0x4f81ce67U, 0x3c28140aU, 0x8f018e47U, 0x16eff9f2U,\n\t0x99ee77b5U, 0xcc884422U, 0x64b3d7e5U, 0x5e9fc1eeU,\n\t0xa3c261beU, 0xfaac562bU, 0x213e1f81U, 0x6c482412U,\n\t0x2d361b83U, 0x5a6c361bU, 0x24381c0eU, 0xca8c4623U,\n\t0x04f3f7f5U, 0x83098a45U, 0xc6844221U, 0x9e1f81ceU,\n\t0xab399249U, 0xe8b0582cU, 0x2cc3eff9U, 0x6ebfd1e6U,\n\t0x93e271b6U, 0xf0a05028U, 0x725c2e17U, 0x2b321982U,\n\t0x5c68341aU, 0x1d160b8bU, 0x3edfe1feU, 0x1b12098aU,\n\t0x36241209U, 0x8c038fc9U, 0x35261387U, 0xb9259c4eU,\n\t0x7ca3dfe1U, 0xe4b85c2eU, 0x62b7d5e4U, 0x7aa7dde0U,\n\t0x408bcbebU, 0x477a3d90U, 0xffaa55a4U, 0x44783c1eU,\n\t0x392e1785U, 0x5d9dc060U, 0x00000000U, 0xde944a25U,\n\t0x02f7f5f4U, 0x1ce3fff1U, 0x5f6a3594U, 0x3a2c160bU,\n\t0x68bbd3e7U, 0x23c9ea75U, 0x589bc3efU, 0xb8d06834U,\n\t0xa6c46231U, 0xc277b5d4U, 0xda67bdd0U, 0x33221186U,\n\t0x19e5fc7eU, 0xc98e47adU, 0x34d3e7fdU, 0xf6a45229U,\n\t0xa0c06030U, 0x9aec763bU, 0x6546239fU, 0x2ac7edf8U,\n\t0xae3f91c6U, 0x6a4c2613U, 0x14180c06U, 0x1e140a05U,\n\t0xa43397c5U, 0x66442211U, 0x2fc1ee77U, 0x15edf87cU,\n\t0x01f5f47aU, 0x0dfdf078U, 0xb4d86c36U, 0x4870381cU,\n\t0x96e47239U, 0xcb79b259U, 0x50603018U, 0xe945ac56U,\n\t0x8df67bb3U, 0x87fa7db0U, 0xd8904824U, 0xc0804020U,\n\t0x8bf279b2U, 0x4b723992U, 0xedb65ba3U, 0xba279dc0U,\n\t0x850d8844U, 0x5195c462U, 0x60402010U, 0x9fea75b4U,\n\t0x3f2a1584U, 0x97118643U, 0x4d763b93U, 0xb62f99c2U,\n\t0xa135944aU, 0xa9ce67bdU, 0x0506038fU, 0xeeb45a2dU,\n\t0xafca65bcU, 0x6f4a259cU, 0x61b5d46aU, 0x9d1d8040U,\n\t0x981b83cfU, 0xebb259a2U, 0x273a1d80U, 0xbf219e4fU,\n\t0x427c3e1fU, 0x860f89caU, 0xdb9249aaU, 0x91158442U,\n};\n\nstatic const u32 T4[256] = {\n\t0xbabababaU, 0x54545454U, 0x2f2f2f2fU, 0x74747474U,\n\t0x53535353U, 0xd3d3d3d3U, 0xd2d2d2d2U, 0x4d4d4d4dU,\n\t0x50505050U, 0xacacacacU, 0x8d8d8d8dU, 0xbfbfbfbfU,\n\t0x70707070U, 0x52525252U, 0x9a9a9a9aU, 0x4c4c4c4cU,\n\t0xeaeaeaeaU, 0xd5d5d5d5U, 0x97979797U, 0xd1d1d1d1U,\n\t0x33333333U, 0x51515151U, 0x5b5b5b5bU, 0xa6a6a6a6U,\n\t0xdedededeU, 0x48484848U, 0xa8a8a8a8U, 0x99999999U,\n\t0xdbdbdbdbU, 0x32323232U, 0xb7b7b7b7U, 0xfcfcfcfcU,\n\t0xe3e3e3e3U, 0x9e9e9e9eU, 0x91919191U, 0x9b9b9b9bU,\n\t0xe2e2e2e2U, 0xbbbbbbbbU, 0x41414141U, 0x6e6e6e6eU,\n\t0xa5a5a5a5U, 0xcbcbcbcbU, 0x6b6b6b6bU, 0x95959595U,\n\t0xa1a1a1a1U, 0xf3f3f3f3U, 0xb1b1b1b1U, 0x02020202U,\n\t0xccccccccU, 0xc4c4c4c4U, 0x1d1d1d1dU, 0x14141414U,\n\t0xc3c3c3c3U, 0x63636363U, 0xdadadadaU, 0x5d5d5d5dU,\n\t0x5f5f5f5fU, 0xdcdcdcdcU, 0x7d7d7d7dU, 0xcdcdcdcdU,\n\t0x7f7f7f7fU, 0x5a5a5a5aU, 0x6c6c6c6cU, 0x5c5c5c5cU,\n\t0xf7f7f7f7U, 0x26262626U, 0xffffffffU, 0xededededU,\n\t0xe8e8e8e8U, 0x9d9d9d9dU, 0x6f6f6f6fU, 0x8e8e8e8eU,\n\t0x19191919U, 0xa0a0a0a0U, 0xf0f0f0f0U, 0x89898989U,\n\t0x0f0f0f0fU, 0x07070707U, 0xafafafafU, 0xfbfbfbfbU,\n\t0x08080808U, 0x15151515U, 0x0d0d0d0dU, 0x04040404U,\n\t0x01010101U, 0x64646464U, 0xdfdfdfdfU, 0x76767676U,\n\t0x79797979U, 0xddddddddU, 0x3d3d3d3dU, 0x16161616U,\n\t0x3f3f3f3fU, 0x37373737U, 0x6d6d6d6dU, 0x38383838U,\n\t0xb9b9b9b9U, 0x73737373U, 0xe9e9e9e9U, 0x35353535U,\n\t0x55555555U, 0x71717171U, 0x7b7b7b7bU, 0x8c8c8c8cU,\n\t0x72727272U, 0x88888888U, 0xf6f6f6f6U, 0x2a2a2a2aU,\n\t0x3e3e3e3eU, 0x5e5e5e5eU, 0x27272727U, 0x46464646U,\n\t0x0c0c0c0cU, 0x65656565U, 0x68686868U, 0x61616161U,\n\t0x03030303U, 0xc1c1c1c1U, 0x57575757U, 0xd6d6d6d6U,\n\t0xd9d9d9d9U, 0x58585858U, 0xd8d8d8d8U, 0x66666666U,\n\t0xd7d7d7d7U, 0x3a3a3a3aU, 0xc8c8c8c8U, 0x3c3c3c3cU,\n\t0xfafafafaU, 0x96969696U, 0xa7a7a7a7U, 0x98989898U,\n\t0xececececU, 0xb8b8b8b8U, 0xc7c7c7c7U, 0xaeaeaeaeU,\n\t0x69696969U, 0x4b4b4b4bU, 0xababababU, 0xa9a9a9a9U,\n\t0x67676767U, 0x0a0a0a0aU, 0x47474747U, 0xf2f2f2f2U,\n\t0xb5b5b5b5U, 0x22222222U, 0xe5e5e5e5U, 0xeeeeeeeeU,\n\t0xbebebebeU, 0x2b2b2b2bU, 0x81818181U, 0x12121212U,\n\t0x83838383U, 0x1b1b1b1bU, 0x0e0e0e0eU, 0x23232323U,\n\t0xf5f5f5f5U, 0x45454545U, 0x21212121U, 0xcecececeU,\n\t0x49494949U, 0x2c2c2c2cU, 0xf9f9f9f9U, 0xe6e6e6e6U,\n\t0xb6b6b6b6U, 0x28282828U, 0x17171717U, 0x82828282U,\n\t0x1a1a1a1aU, 0x8b8b8b8bU, 0xfefefefeU, 0x8a8a8a8aU,\n\t0x09090909U, 0xc9c9c9c9U, 0x87878787U, 0x4e4e4e4eU,\n\t0xe1e1e1e1U, 0x2e2e2e2eU, 0xe4e4e4e4U, 0xe0e0e0e0U,\n\t0xebebebebU, 0x90909090U, 0xa4a4a4a4U, 0x1e1e1e1eU,\n\t0x85858585U, 0x60606060U, 0x00000000U, 0x25252525U,\n\t0xf4f4f4f4U, 0xf1f1f1f1U, 0x94949494U, 0x0b0b0b0bU,\n\t0xe7e7e7e7U, 0x75757575U, 0xefefefefU, 0x34343434U,\n\t0x31313131U, 0xd4d4d4d4U, 0xd0d0d0d0U, 0x86868686U,\n\t0x7e7e7e7eU, 0xadadadadU, 0xfdfdfdfdU, 0x29292929U,\n\t0x30303030U, 0x3b3b3b3bU, 0x9f9f9f9fU, 0xf8f8f8f8U,\n\t0xc6c6c6c6U, 0x13131313U, 0x06060606U, 0x05050505U,\n\t0xc5c5c5c5U, 0x11111111U, 0x77777777U, 0x7c7c7c7cU,\n\t0x7a7a7a7aU, 0x78787878U, 0x36363636U, 0x1c1c1c1cU,\n\t0x39393939U, 0x59595959U, 0x18181818U, 0x56565656U,\n\t0xb3b3b3b3U, 0xb0b0b0b0U, 0x24242424U, 0x20202020U,\n\t0xb2b2b2b2U, 0x92929292U, 0xa3a3a3a3U, 0xc0c0c0c0U,\n\t0x44444444U, 0x62626262U, 0x10101010U, 0xb4b4b4b4U,\n\t0x84848484U, 0x43434343U, 0x93939393U, 0xc2c2c2c2U,\n\t0x4a4a4a4aU, 0xbdbdbdbdU, 0x8f8f8f8fU, 0x2d2d2d2dU,\n\t0xbcbcbcbcU, 0x9c9c9c9cU, 0x6a6a6a6aU, 0x40404040U,\n\t0xcfcfcfcfU, 0xa2a2a2a2U, 0x80808080U, 0x4f4f4f4fU,\n\t0x1f1f1f1fU, 0xcacacacaU, 0xaaaaaaaaU, 0x42424242U,\n};\n\nstatic const u32 T5[256] = {\n\t0x00000000U, 0x01020608U, 0x02040c10U, 0x03060a18U,\n\t0x04081820U, 0x050a1e28U, 0x060c1430U, 0x070e1238U,\n\t0x08103040U, 0x09123648U, 0x0a143c50U, 0x0b163a58U,\n\t0x0c182860U, 0x0d1a2e68U, 0x0e1c2470U, 0x0f1e2278U,\n\t0x10206080U, 0x11226688U, 0x12246c90U, 0x13266a98U,\n\t0x142878a0U, 0x152a7ea8U, 0x162c74b0U, 0x172e72b8U,\n\t0x183050c0U, 0x193256c8U, 0x1a345cd0U, 0x1b365ad8U,\n\t0x1c3848e0U, 0x1d3a4ee8U, 0x1e3c44f0U, 0x1f3e42f8U,\n\t0x2040c01dU, 0x2142c615U, 0x2244cc0dU, 0x2346ca05U,\n\t0x2448d83dU, 0x254ade35U, 0x264cd42dU, 0x274ed225U,\n\t0x2850f05dU, 0x2952f655U, 0x2a54fc4dU, 0x2b56fa45U,\n\t0x2c58e87dU, 0x2d5aee75U, 0x2e5ce46dU, 0x2f5ee265U,\n\t0x3060a09dU, 0x3162a695U, 0x3264ac8dU, 0x3366aa85U,\n\t0x3468b8bdU, 0x356abeb5U, 0x366cb4adU, 0x376eb2a5U,\n\t0x387090ddU, 0x397296d5U, 0x3a749ccdU, 0x3b769ac5U,\n\t0x3c7888fdU, 0x3d7a8ef5U, 0x3e7c84edU, 0x3f7e82e5U,\n\t0x40809d3aU, 0x41829b32U, 0x4284912aU, 0x43869722U,\n\t0x4488851aU, 0x458a8312U, 0x468c890aU, 0x478e8f02U,\n\t0x4890ad7aU, 0x4992ab72U, 0x4a94a16aU, 0x4b96a762U,\n\t0x4c98b55aU, 0x4d9ab352U, 0x4e9cb94aU, 0x4f9ebf42U,\n\t0x50a0fdbaU, 0x51a2fbb2U, 0x52a4f1aaU, 0x53a6f7a2U,\n\t0x54a8e59aU, 0x55aae392U, 0x56ace98aU, 0x57aeef82U,\n\t0x58b0cdfaU, 0x59b2cbf2U, 0x5ab4c1eaU, 0x5bb6c7e2U,\n\t0x5cb8d5daU, 0x5dbad3d2U, 0x5ebcd9caU, 0x5fbedfc2U,\n\t0x60c05d27U, 0x61c25b2fU, 0x62c45137U, 0x63c6573fU,\n\t0x64c84507U, 0x65ca430fU, 0x66cc4917U, 0x67ce4f1fU,\n\t0x68d06d67U, 0x69d26b6fU, 0x6ad46177U, 0x6bd6677fU,\n\t0x6cd87547U, 0x6dda734fU, 0x6edc7957U, 0x6fde7f5fU,\n\t0x70e03da7U, 0x71e23bafU, 0x72e431b7U, 0x73e637bfU,\n\t0x74e82587U, 0x75ea238fU, 0x76ec2997U, 0x77ee2f9fU,\n\t0x78f00de7U, 0x79f20befU, 0x7af401f7U, 0x7bf607ffU,\n\t0x7cf815c7U, 0x7dfa13cfU, 0x7efc19d7U, 0x7ffe1fdfU,\n\t0x801d2774U, 0x811f217cU, 0x82192b64U, 0x831b2d6cU,\n\t0x84153f54U, 0x8517395cU, 0x86113344U, 0x8713354cU,\n\t0x880d1734U, 0x890f113cU, 0x8a091b24U, 0x8b0b1d2cU,\n\t0x8c050f14U, 0x8d07091cU, 0x8e010304U, 0x8f03050cU,\n\t0x903d47f4U, 0x913f41fcU, 0x92394be4U, 0x933b4decU,\n\t0x94355fd4U, 0x953759dcU, 0x963153c4U, 0x973355ccU,\n\t0x982d77b4U, 0x992f71bcU, 0x9a297ba4U, 0x9b2b7dacU,\n\t0x9c256f94U, 0x9d27699cU, 0x9e216384U, 0x9f23658cU,\n\t0xa05de769U, 0xa15fe161U, 0xa259eb79U, 0xa35bed71U,\n\t0xa455ff49U, 0xa557f941U, 0xa651f359U, 0xa753f551U,\n\t0xa84dd729U, 0xa94fd121U, 0xaa49db39U, 0xab4bdd31U,\n\t0xac45cf09U, 0xad47c901U, 0xae41c319U, 0xaf43c511U,\n\t0xb07d87e9U, 0xb17f81e1U, 0xb2798bf9U, 0xb37b8df1U,\n\t0xb4759fc9U, 0xb57799c1U, 0xb67193d9U, 0xb77395d1U,\n\t0xb86db7a9U, 0xb96fb1a1U, 0xba69bbb9U, 0xbb6bbdb1U,\n\t0xbc65af89U, 0xbd67a981U, 0xbe61a399U, 0xbf63a591U,\n\t0xc09dba4eU, 0xc19fbc46U, 0xc299b65eU, 0xc39bb056U,\n\t0xc495a26eU, 0xc597a466U, 0xc691ae7eU, 0xc793a876U,\n\t0xc88d8a0eU, 0xc98f8c06U, 0xca89861eU, 0xcb8b8016U,\n\t0xcc85922eU, 0xcd879426U, 0xce819e3eU, 0xcf839836U,\n\t0xd0bddaceU, 0xd1bfdcc6U, 0xd2b9d6deU, 0xd3bbd0d6U,\n\t0xd4b5c2eeU, 0xd5b7c4e6U, 0xd6b1cefeU, 0xd7b3c8f6U,\n\t0xd8adea8eU, 0xd9afec86U, 0xdaa9e69eU, 0xdbabe096U,\n\t0xdca5f2aeU, 0xdda7f4a6U, 0xdea1febeU, 0xdfa3f8b6U,\n\t0xe0dd7a53U, 0xe1df7c5bU, 0xe2d97643U, 0xe3db704bU,\n\t0xe4d56273U, 0xe5d7647bU, 0xe6d16e63U, 0xe7d3686bU,\n\t0xe8cd4a13U, 0xe9cf4c1bU, 0xeac94603U, 0xebcb400bU,\n\t0xecc55233U, 0xedc7543bU, 0xeec15e23U, 0xefc3582bU,\n\t0xf0fd1ad3U, 0xf1ff1cdbU, 0xf2f916c3U, 0xf3fb10cbU,\n\t0xf4f502f3U, 0xf5f704fbU, 0xf6f10ee3U, 0xf7f308ebU,\n\t0xf8ed2a93U, 0xf9ef2c9bU, 0xfae92683U, 0xfbeb208bU,\n\t0xfce532b3U, 0xfde734bbU, 0xfee13ea3U, 0xffe338abU,\n};\n\nstatic const u32 rc[] = {\n\t0xba542f74U, 0x53d3d24dU, 0x50ac8dbfU, 0x70529a4cU,\n\t0xead597d1U, 0x33515ba6U, 0xde48a899U, 0xdb32b7fcU,\n\t0xe39e919bU, 0xe2bb416eU, 0xa5cb6b95U, 0xa1f3b102U,\n\t0xccc41d14U, 0xc363da5dU, 0x5fdc7dcdU, 0x7f5a6c5cU,\n\t0xf726ffedU, 0xe89d6f8eU, 0x19a0f089U,\n};\n\nstatic int anubis_setkey(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t\t unsigned int key_len)\n{\n\tstruct anubis_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __be32 *key = (const __be32 *)in_key;\n\tu32 *flags = &tfm->crt_flags;\n\tint N, R, i, r;\n\tu32 kappa[ANUBIS_MAX_N];\n\tu32 inter[ANUBIS_MAX_N];\n\n\tswitch (key_len) {\n\t\tcase 16: case 20: case 24: case 28:\n\t\tcase 32: case 36: case 40:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\t\treturn -EINVAL;\n\t}\n\n\tctx->key_len = key_len * 8;\n\tN = ctx->key_len >> 5;\n\tctx->R = R = 8 + N;\n\n\t/* * map cipher key to initial key state (mu): */\n\tfor (i = 0; i < N; i++)\n\t\tkappa[i] = be32_to_cpu(key[i]);\n\n\t/*\n\t * generate R + 1 round keys:\n\t */\n\tfor (r = 0; r <= R; r++) {\n\t\tu32 K0, K1, K2, K3;\n\t\t/*\n\t\t * generate r-th round key K^r:\n\t\t */\n\t\tK0 = T4[(kappa[N - 1] >> 24)       ];\n\t\tK1 = T4[(kappa[N - 1] >> 16) & 0xff];\n\t\tK2 = T4[(kappa[N - 1] >>  8) & 0xff];\n\t\tK3 = T4[(kappa[N - 1]      ) & 0xff];\n\t\tfor (i = N - 2; i >= 0; i--) {\n\t\t\tK0 = T4[(kappa[i] >> 24)       ] ^\n\t\t\t\t(T5[(K0 >> 24)       ] & 0xff000000U) ^\n\t\t\t\t(T5[(K0 >> 16) & 0xff] & 0x00ff0000U) ^\n\t\t\t\t(T5[(K0 >>  8) & 0xff] & 0x0000ff00U) ^\n\t\t\t\t(T5[(K0      ) & 0xff] & 0x000000ffU);\n\t\t\tK1 = T4[(kappa[i] >> 16) & 0xff] ^\n\t\t\t\t(T5[(K1 >> 24)       ] & 0xff000000U) ^\n\t\t\t\t(T5[(K1 >> 16) & 0xff] & 0x00ff0000U) ^\n\t\t\t\t(T5[(K1 >>  8) & 0xff] & 0x0000ff00U) ^\n\t\t\t\t(T5[(K1      ) & 0xff] & 0x000000ffU);\n\t\t\tK2 = T4[(kappa[i] >>  8) & 0xff] ^\n\t\t\t\t(T5[(K2 >> 24)       ] & 0xff000000U) ^\n\t\t\t\t(T5[(K2 >> 16) & 0xff] & 0x00ff0000U) ^\n\t\t\t\t(T5[(K2 >>  8) & 0xff] & 0x0000ff00U) ^\n\t\t\t\t(T5[(K2      ) & 0xff] & 0x000000ffU);\n\t\t\tK3 = T4[(kappa[i]      ) & 0xff] ^\n\t\t\t\t(T5[(K3 >> 24)       ] & 0xff000000U) ^\n\t\t\t\t(T5[(K3 >> 16) & 0xff] & 0x00ff0000U) ^\n\t\t\t\t(T5[(K3 >>  8) & 0xff] & 0x0000ff00U) ^\n\t\t\t\t(T5[(K3      ) & 0xff] & 0x000000ffU);\n\t\t}\n\n\t\tctx->E[r][0] = K0;\n\t\tctx->E[r][1] = K1;\n\t\tctx->E[r][2] = K2;\n\t\tctx->E[r][3] = K3;\n\n\t\t/*\n\t\t * compute kappa^{r+1} from kappa^r:\n\t\t */\n\t\tif (r == R)\n\t\t\tbreak;\n\t\tfor (i = 0; i < N; i++) {\n\t\t\tint j = i;\n\t\t\tinter[i]  = T0[(kappa[j--] >> 24)       ];\n\t\t\tif (j < 0)\n\t\t\t\tj = N - 1;\n\t\t\tinter[i] ^= T1[(kappa[j--] >> 16) & 0xff];\n\t\t\tif (j < 0)\n\t\t\t\tj = N - 1;\n\t\t\tinter[i] ^= T2[(kappa[j--] >>  8) & 0xff];\n\t\t\tif (j < 0)\n\t\t\t\tj = N - 1;\n\t\t\tinter[i] ^= T3[(kappa[j  ]      ) & 0xff];\n\t\t}\n\t\tkappa[0] = inter[0] ^ rc[r];\n\t\tfor (i = 1; i < N; i++)\n\t\t\tkappa[i] = inter[i];\n\t}\n\n\t/*\n\t * generate inverse key schedule: K'^0 = K^R, K'^R =\n\t * \t\t\t\t  K^0, K'^r = theta(K^{R-r}):\n\t */\n\tfor (i = 0; i < 4; i++) {\n\t\tctx->D[0][i] = ctx->E[R][i];\n\t\tctx->D[R][i] = ctx->E[0][i];\n\t}\n\tfor (r = 1; r < R; r++) {\n\t\tfor (i = 0; i < 4; i++) {\n\t\t\tu32 v = ctx->E[R - r][i];\n\t\t\tctx->D[r][i] =\n\t\t\t\tT0[T4[(v >> 24)       ] & 0xff] ^\n\t\t\t\tT1[T4[(v >> 16) & 0xff] & 0xff] ^\n\t\t\t\tT2[T4[(v >>  8) & 0xff] & 0xff] ^\n\t\t\t\tT3[T4[(v      ) & 0xff] & 0xff];\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void anubis_crypt(u32 roundKey[ANUBIS_MAX_ROUNDS + 1][4],\n\t\tu8 *ciphertext, const u8 *plaintext, const int R)\n{\n\tconst __be32 *src = (const __be32 *)plaintext;\n\t__be32 *dst = (__be32 *)ciphertext;\n\tint i, r;\n\tu32 state[4];\n\tu32 inter[4];\n\n\t/*\n\t * map plaintext block to cipher state (mu)\n\t * and add initial round key (sigma[K^0]):\n\t */\n\tfor (i = 0; i < 4; i++)\n\t\tstate[i] = be32_to_cpu(src[i]) ^ roundKey[0][i];\n\n\t/*\n\t * R - 1 full rounds:\n\t */\n\n\tfor (r = 1; r < R; r++) {\n\t\tinter[0] =\n\t\t\tT0[(state[0] >> 24)       ] ^\n\t\t\tT1[(state[1] >> 24)       ] ^\n\t\t\tT2[(state[2] >> 24)       ] ^\n\t\t\tT3[(state[3] >> 24)       ] ^\n\t\t\troundKey[r][0];\n\t\tinter[1] =\n\t\t\tT0[(state[0] >> 16) & 0xff] ^\n\t\t\tT1[(state[1] >> 16) & 0xff] ^\n\t\t\tT2[(state[2] >> 16) & 0xff] ^\n\t\t\tT3[(state[3] >> 16) & 0xff] ^\n\t\t\troundKey[r][1];\n\t\tinter[2] =\n\t\t\tT0[(state[0] >>  8) & 0xff] ^\n\t\t\tT1[(state[1] >>  8) & 0xff] ^\n\t\t\tT2[(state[2] >>  8) & 0xff] ^\n\t\t\tT3[(state[3] >>  8) & 0xff] ^\n\t\t\troundKey[r][2];\n\t\tinter[3] =\n\t\t\tT0[(state[0]      ) & 0xff] ^\n\t\t\tT1[(state[1]      ) & 0xff] ^\n\t\t\tT2[(state[2]      ) & 0xff] ^\n\t\t\tT3[(state[3]      ) & 0xff] ^\n\t\t\troundKey[r][3];\n\t\tstate[0] = inter[0];\n\t\tstate[1] = inter[1];\n\t\tstate[2] = inter[2];\n\t\tstate[3] = inter[3];\n\t}\n\n\t/*\n\t * last round:\n\t */\n\n\tinter[0] =\n\t\t(T0[(state[0] >> 24)       ] & 0xff000000U) ^\n\t\t(T1[(state[1] >> 24)       ] & 0x00ff0000U) ^\n\t\t(T2[(state[2] >> 24)       ] & 0x0000ff00U) ^\n\t\t(T3[(state[3] >> 24)       ] & 0x000000ffU) ^\n\t\troundKey[R][0];\n\tinter[1] =\n\t\t(T0[(state[0] >> 16) & 0xff] & 0xff000000U) ^\n\t\t(T1[(state[1] >> 16) & 0xff] & 0x00ff0000U) ^\n\t\t(T2[(state[2] >> 16) & 0xff] & 0x0000ff00U) ^\n\t\t(T3[(state[3] >> 16) & 0xff] & 0x000000ffU) ^\n\t\troundKey[R][1];\n\tinter[2] =\n\t\t(T0[(state[0] >>  8) & 0xff] & 0xff000000U) ^\n\t\t(T1[(state[1] >>  8) & 0xff] & 0x00ff0000U) ^\n\t\t(T2[(state[2] >>  8) & 0xff] & 0x0000ff00U) ^\n\t\t(T3[(state[3] >>  8) & 0xff] & 0x000000ffU) ^\n\t\troundKey[R][2];\n\tinter[3] =\n\t\t(T0[(state[0]      ) & 0xff] & 0xff000000U) ^\n\t\t(T1[(state[1]      ) & 0xff] & 0x00ff0000U) ^\n\t\t(T2[(state[2]      ) & 0xff] & 0x0000ff00U) ^\n\t\t(T3[(state[3]      ) & 0xff] & 0x000000ffU) ^\n\t\troundKey[R][3];\n\n\t/*\n\t * map cipher state to ciphertext block (mu^{-1}):\n\t */\n\n\tfor (i = 0; i < 4; i++)\n\t\tdst[i] = cpu_to_be32(inter[i]);\n}\n\nstatic void anubis_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct anubis_ctx *ctx = crypto_tfm_ctx(tfm);\n\tanubis_crypt(ctx->E, dst, src, ctx->R);\n}\n\nstatic void anubis_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct anubis_ctx *ctx = crypto_tfm_ctx(tfm);\n\tanubis_crypt(ctx->D, dst, src, ctx->R);\n}\n\nstatic struct crypto_alg anubis_alg = {\n\t.cra_name\t\t=\t\"anubis\",\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tANUBIS_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof (struct anubis_ctx),\n\t.cra_alignmask\t\t=\t3,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\tANUBIS_MIN_KEY_SIZE,\n\t.cia_max_keysize\t=\tANUBIS_MAX_KEY_SIZE,\n\t.cia_setkey\t\t= \tanubis_setkey,\n\t.cia_encrypt\t\t=\tanubis_encrypt,\n\t.cia_decrypt\t\t=\tanubis_decrypt } }\n};\n\nstatic int __init anubis_mod_init(void)\n{\n\tint ret = 0;\n\n\tret = crypto_register_alg(&anubis_alg);\n\treturn ret;\n}\n\nstatic void __exit anubis_mod_fini(void)\n{\n\tcrypto_unregister_alg(&anubis_alg);\n}\n\nmodule_init(anubis_mod_init);\nmodule_exit(anubis_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Anubis Cryptographic Algorithm\");\n", "/*\n * Scatterlist Cryptographic API.\n *\n * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>\n * Copyright (c) 2002 David S. Miller (davem@redhat.com)\n * Copyright (c) 2005 Herbert Xu <herbert@gondor.apana.org.au>\n *\n * Portions derived from Cryptoapi, by Alexander Kjeldaas <astor@fast.no>\n * and Nettle, by Niels M\u00f6ller.\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#include <linux/err.h>\n#include <linux/errno.h>\n#include <linux/kernel.h>\n#include <linux/kmod.h>\n#include <linux/module.h>\n#include <linux/param.h>\n#include <linux/sched.h>\n#include <linux/slab.h>\n#include <linux/string.h>\n#include \"internal.h\"\n\nLIST_HEAD(crypto_alg_list);\nEXPORT_SYMBOL_GPL(crypto_alg_list);\nDECLARE_RWSEM(crypto_alg_sem);\nEXPORT_SYMBOL_GPL(crypto_alg_sem);\n\nBLOCKING_NOTIFIER_HEAD(crypto_chain);\nEXPORT_SYMBOL_GPL(crypto_chain);\n\nstatic struct crypto_alg *crypto_larval_wait(struct crypto_alg *alg);\n\nstruct crypto_alg *crypto_mod_get(struct crypto_alg *alg)\n{\n\treturn try_module_get(alg->cra_module) ? crypto_alg_get(alg) : NULL;\n}\nEXPORT_SYMBOL_GPL(crypto_mod_get);\n\nvoid crypto_mod_put(struct crypto_alg *alg)\n{\n\tstruct module *module = alg->cra_module;\n\n\tcrypto_alg_put(alg);\n\tmodule_put(module);\n}\nEXPORT_SYMBOL_GPL(crypto_mod_put);\n\nstatic inline int crypto_is_test_larval(struct crypto_larval *larval)\n{\n\treturn larval->alg.cra_driver_name[0];\n}\n\nstatic struct crypto_alg *__crypto_alg_lookup(const char *name, u32 type,\n\t\t\t\t\t      u32 mask)\n{\n\tstruct crypto_alg *q, *alg = NULL;\n\tint best = -2;\n\n\tlist_for_each_entry(q, &crypto_alg_list, cra_list) {\n\t\tint exact, fuzzy;\n\n\t\tif (crypto_is_moribund(q))\n\t\t\tcontinue;\n\n\t\tif ((q->cra_flags ^ type) & mask)\n\t\t\tcontinue;\n\n\t\tif (crypto_is_larval(q) &&\n\t\t    !crypto_is_test_larval((struct crypto_larval *)q) &&\n\t\t    ((struct crypto_larval *)q)->mask != mask)\n\t\t\tcontinue;\n\n\t\texact = !strcmp(q->cra_driver_name, name);\n\t\tfuzzy = !strcmp(q->cra_name, name);\n\t\tif (!exact && !(fuzzy && q->cra_priority > best))\n\t\t\tcontinue;\n\n\t\tif (unlikely(!crypto_mod_get(q)))\n\t\t\tcontinue;\n\n\t\tbest = q->cra_priority;\n\t\tif (alg)\n\t\t\tcrypto_mod_put(alg);\n\t\talg = q;\n\n\t\tif (exact)\n\t\t\tbreak;\n\t}\n\n\treturn alg;\n}\n\nstatic void crypto_larval_destroy(struct crypto_alg *alg)\n{\n\tstruct crypto_larval *larval = (void *)alg;\n\n\tBUG_ON(!crypto_is_larval(alg));\n\tif (larval->adult)\n\t\tcrypto_mod_put(larval->adult);\n\tkfree(larval);\n}\n\nstruct crypto_larval *crypto_larval_alloc(const char *name, u32 type, u32 mask)\n{\n\tstruct crypto_larval *larval;\n\n\tlarval = kzalloc(sizeof(*larval), GFP_KERNEL);\n\tif (!larval)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tlarval->mask = mask;\n\tlarval->alg.cra_flags = CRYPTO_ALG_LARVAL | type;\n\tlarval->alg.cra_priority = -1;\n\tlarval->alg.cra_destroy = crypto_larval_destroy;\n\n\tstrlcpy(larval->alg.cra_name, name, CRYPTO_MAX_ALG_NAME);\n\tinit_completion(&larval->completion);\n\n\treturn larval;\n}\nEXPORT_SYMBOL_GPL(crypto_larval_alloc);\n\nstatic struct crypto_alg *crypto_larval_add(const char *name, u32 type,\n\t\t\t\t\t    u32 mask)\n{\n\tstruct crypto_alg *alg;\n\tstruct crypto_larval *larval;\n\n\tlarval = crypto_larval_alloc(name, type, mask);\n\tif (IS_ERR(larval))\n\t\treturn ERR_CAST(larval);\n\n\tatomic_set(&larval->alg.cra_refcnt, 2);\n\n\tdown_write(&crypto_alg_sem);\n\talg = __crypto_alg_lookup(name, type, mask);\n\tif (!alg) {\n\t\talg = &larval->alg;\n\t\tlist_add(&alg->cra_list, &crypto_alg_list);\n\t}\n\tup_write(&crypto_alg_sem);\n\n\tif (alg != &larval->alg) {\n\t\tkfree(larval);\n\t\tif (crypto_is_larval(alg))\n\t\t\talg = crypto_larval_wait(alg);\n\t}\n\n\treturn alg;\n}\n\nvoid crypto_larval_kill(struct crypto_alg *alg)\n{\n\tstruct crypto_larval *larval = (void *)alg;\n\n\tdown_write(&crypto_alg_sem);\n\tlist_del(&alg->cra_list);\n\tup_write(&crypto_alg_sem);\n\tcomplete_all(&larval->completion);\n\tcrypto_alg_put(alg);\n}\nEXPORT_SYMBOL_GPL(crypto_larval_kill);\n\nstatic struct crypto_alg *crypto_larval_wait(struct crypto_alg *alg)\n{\n\tstruct crypto_larval *larval = (void *)alg;\n\tlong timeout;\n\n\ttimeout = wait_for_completion_interruptible_timeout(\n\t\t&larval->completion, 60 * HZ);\n\n\talg = larval->adult;\n\tif (timeout < 0)\n\t\talg = ERR_PTR(-EINTR);\n\telse if (!timeout)\n\t\talg = ERR_PTR(-ETIMEDOUT);\n\telse if (!alg)\n\t\talg = ERR_PTR(-ENOENT);\n\telse if (crypto_is_test_larval(larval) &&\n\t\t !(alg->cra_flags & CRYPTO_ALG_TESTED))\n\t\talg = ERR_PTR(-EAGAIN);\n\telse if (!crypto_mod_get(alg))\n\t\talg = ERR_PTR(-EAGAIN);\n\tcrypto_mod_put(&larval->alg);\n\n\treturn alg;\n}\n\nstruct crypto_alg *crypto_alg_lookup(const char *name, u32 type, u32 mask)\n{\n\tstruct crypto_alg *alg;\n\n\tdown_read(&crypto_alg_sem);\n\talg = __crypto_alg_lookup(name, type, mask);\n\tup_read(&crypto_alg_sem);\n\n\treturn alg;\n}\nEXPORT_SYMBOL_GPL(crypto_alg_lookup);\n\nstruct crypto_alg *crypto_larval_lookup(const char *name, u32 type, u32 mask)\n{\n\tstruct crypto_alg *alg;\n\n\tif (!name)\n\t\treturn ERR_PTR(-ENOENT);\n\n\tmask &= ~(CRYPTO_ALG_LARVAL | CRYPTO_ALG_DEAD);\n\ttype &= mask;\n\n\talg = crypto_alg_lookup(name, type, mask);\n\tif (!alg) {\n\t\trequest_module(\"%s\", name);\n\n\t\tif (!((type ^ CRYPTO_ALG_NEED_FALLBACK) & mask &\n\t\t      CRYPTO_ALG_NEED_FALLBACK))\n\t\t\trequest_module(\"%s-all\", name);\n\n\t\talg = crypto_alg_lookup(name, type, mask);\n\t}\n\n\tif (alg)\n\t\treturn crypto_is_larval(alg) ? crypto_larval_wait(alg) : alg;\n\n\treturn crypto_larval_add(name, type, mask);\n}\nEXPORT_SYMBOL_GPL(crypto_larval_lookup);\n\nint crypto_probing_notify(unsigned long val, void *v)\n{\n\tint ok;\n\n\tok = blocking_notifier_call_chain(&crypto_chain, val, v);\n\tif (ok == NOTIFY_DONE) {\n\t\trequest_module(\"cryptomgr\");\n\t\tok = blocking_notifier_call_chain(&crypto_chain, val, v);\n\t}\n\n\treturn ok;\n}\nEXPORT_SYMBOL_GPL(crypto_probing_notify);\n\nstruct crypto_alg *crypto_alg_mod_lookup(const char *name, u32 type, u32 mask)\n{\n\tstruct crypto_alg *alg;\n\tstruct crypto_alg *larval;\n\tint ok;\n\n\tif (!((type | mask) & CRYPTO_ALG_TESTED)) {\n\t\ttype |= CRYPTO_ALG_TESTED;\n\t\tmask |= CRYPTO_ALG_TESTED;\n\t}\n\n\tlarval = crypto_larval_lookup(name, type, mask);\n\tif (IS_ERR(larval) || !crypto_is_larval(larval))\n\t\treturn larval;\n\n\tok = crypto_probing_notify(CRYPTO_MSG_ALG_REQUEST, larval);\n\n\tif (ok == NOTIFY_STOP)\n\t\talg = crypto_larval_wait(larval);\n\telse {\n\t\tcrypto_mod_put(larval);\n\t\talg = ERR_PTR(-ENOENT);\n\t}\n\tcrypto_larval_kill(larval);\n\treturn alg;\n}\nEXPORT_SYMBOL_GPL(crypto_alg_mod_lookup);\n\nstatic int crypto_init_ops(struct crypto_tfm *tfm, u32 type, u32 mask)\n{\n\tconst struct crypto_type *type_obj = tfm->__crt_alg->cra_type;\n\n\tif (type_obj)\n\t\treturn type_obj->init(tfm, type, mask);\n\n\tswitch (crypto_tfm_alg_type(tfm)) {\n\tcase CRYPTO_ALG_TYPE_CIPHER:\n\t\treturn crypto_init_cipher_ops(tfm);\n\n\tcase CRYPTO_ALG_TYPE_COMPRESS:\n\t\treturn crypto_init_compress_ops(tfm);\n\n\tdefault:\n\t\tbreak;\n\t}\n\n\tBUG();\n\treturn -EINVAL;\n}\n\nstatic void crypto_exit_ops(struct crypto_tfm *tfm)\n{\n\tconst struct crypto_type *type = tfm->__crt_alg->cra_type;\n\n\tif (type) {\n\t\tif (tfm->exit)\n\t\t\ttfm->exit(tfm);\n\t\treturn;\n\t}\n\n\tswitch (crypto_tfm_alg_type(tfm)) {\n\tcase CRYPTO_ALG_TYPE_CIPHER:\n\t\tcrypto_exit_cipher_ops(tfm);\n\t\tbreak;\n\n\tcase CRYPTO_ALG_TYPE_COMPRESS:\n\t\tcrypto_exit_compress_ops(tfm);\n\t\tbreak;\n\n\tdefault:\n\t\tBUG();\n\t}\n}\n\nstatic unsigned int crypto_ctxsize(struct crypto_alg *alg, u32 type, u32 mask)\n{\n\tconst struct crypto_type *type_obj = alg->cra_type;\n\tunsigned int len;\n\n\tlen = alg->cra_alignmask & ~(crypto_tfm_ctx_alignment() - 1);\n\tif (type_obj)\n\t\treturn len + type_obj->ctxsize(alg, type, mask);\n\n\tswitch (alg->cra_flags & CRYPTO_ALG_TYPE_MASK) {\n\tdefault:\n\t\tBUG();\n\n\tcase CRYPTO_ALG_TYPE_CIPHER:\n\t\tlen += crypto_cipher_ctxsize(alg);\n\t\tbreak;\n\n\tcase CRYPTO_ALG_TYPE_COMPRESS:\n\t\tlen += crypto_compress_ctxsize(alg);\n\t\tbreak;\n\t}\n\n\treturn len;\n}\n\nvoid crypto_shoot_alg(struct crypto_alg *alg)\n{\n\tdown_write(&crypto_alg_sem);\n\talg->cra_flags |= CRYPTO_ALG_DYING;\n\tup_write(&crypto_alg_sem);\n}\nEXPORT_SYMBOL_GPL(crypto_shoot_alg);\n\nstruct crypto_tfm *__crypto_alloc_tfm(struct crypto_alg *alg, u32 type,\n\t\t\t\t      u32 mask)\n{\n\tstruct crypto_tfm *tfm = NULL;\n\tunsigned int tfm_size;\n\tint err = -ENOMEM;\n\n\ttfm_size = sizeof(*tfm) + crypto_ctxsize(alg, type, mask);\n\ttfm = kzalloc(tfm_size, GFP_KERNEL);\n\tif (tfm == NULL)\n\t\tgoto out_err;\n\n\ttfm->__crt_alg = alg;\n\n\terr = crypto_init_ops(tfm, type, mask);\n\tif (err)\n\t\tgoto out_free_tfm;\n\n\tif (!tfm->exit && alg->cra_init && (err = alg->cra_init(tfm)))\n\t\tgoto cra_init_failed;\n\n\tgoto out;\n\ncra_init_failed:\n\tcrypto_exit_ops(tfm);\nout_free_tfm:\n\tif (err == -EAGAIN)\n\t\tcrypto_shoot_alg(alg);\n\tkfree(tfm);\nout_err:\n\ttfm = ERR_PTR(err);\nout:\n\treturn tfm;\n}\nEXPORT_SYMBOL_GPL(__crypto_alloc_tfm);\n\n/*\n *\tcrypto_alloc_base - Locate algorithm and allocate transform\n *\t@alg_name: Name of algorithm\n *\t@type: Type of algorithm\n *\t@mask: Mask for type comparison\n *\n *\tThis function should not be used by new algorithm types.\n *\tPlease use crypto_alloc_tfm instead.\n *\n *\tcrypto_alloc_base() will first attempt to locate an already loaded\n *\talgorithm.  If that fails and the kernel supports dynamically loadable\n *\tmodules, it will then attempt to load a module of the same name or\n *\talias.  If that fails it will send a query to any loaded crypto manager\n *\tto construct an algorithm on the fly.  A refcount is grabbed on the\n *\talgorithm which is then associated with the new transform.\n *\n *\tThe returned transform is of a non-determinate type.  Most people\n *\tshould use one of the more specific allocation functions such as\n *\tcrypto_alloc_blkcipher.\n *\n *\tIn case of error the return value is an error pointer.\n */\nstruct crypto_tfm *crypto_alloc_base(const char *alg_name, u32 type, u32 mask)\n{\n\tstruct crypto_tfm *tfm;\n\tint err;\n\n\tfor (;;) {\n\t\tstruct crypto_alg *alg;\n\n\t\talg = crypto_alg_mod_lookup(alg_name, type, mask);\n\t\tif (IS_ERR(alg)) {\n\t\t\terr = PTR_ERR(alg);\n\t\t\tgoto err;\n\t\t}\n\n\t\ttfm = __crypto_alloc_tfm(alg, type, mask);\n\t\tif (!IS_ERR(tfm))\n\t\t\treturn tfm;\n\n\t\tcrypto_mod_put(alg);\n\t\terr = PTR_ERR(tfm);\n\nerr:\n\t\tif (err != -EAGAIN)\n\t\t\tbreak;\n\t\tif (signal_pending(current)) {\n\t\t\terr = -EINTR;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn ERR_PTR(err);\n}\nEXPORT_SYMBOL_GPL(crypto_alloc_base);\n\nvoid *crypto_create_tfm(struct crypto_alg *alg,\n\t\t\tconst struct crypto_type *frontend)\n{\n\tchar *mem;\n\tstruct crypto_tfm *tfm = NULL;\n\tunsigned int tfmsize;\n\tunsigned int total;\n\tint err = -ENOMEM;\n\n\ttfmsize = frontend->tfmsize;\n\ttotal = tfmsize + sizeof(*tfm) + frontend->extsize(alg);\n\n\tmem = kzalloc(total, GFP_KERNEL);\n\tif (mem == NULL)\n\t\tgoto out_err;\n\n\ttfm = (struct crypto_tfm *)(mem + tfmsize);\n\ttfm->__crt_alg = alg;\n\n\terr = frontend->init_tfm(tfm);\n\tif (err)\n\t\tgoto out_free_tfm;\n\n\tif (!tfm->exit && alg->cra_init && (err = alg->cra_init(tfm)))\n\t\tgoto cra_init_failed;\n\n\tgoto out;\n\ncra_init_failed:\n\tcrypto_exit_ops(tfm);\nout_free_tfm:\n\tif (err == -EAGAIN)\n\t\tcrypto_shoot_alg(alg);\n\tkfree(mem);\nout_err:\n\tmem = ERR_PTR(err);\nout:\n\treturn mem;\n}\nEXPORT_SYMBOL_GPL(crypto_create_tfm);\n\nstruct crypto_alg *crypto_find_alg(const char *alg_name,\n\t\t\t\t   const struct crypto_type *frontend,\n\t\t\t\t   u32 type, u32 mask)\n{\n\tstruct crypto_alg *(*lookup)(const char *name, u32 type, u32 mask) =\n\t\tcrypto_alg_mod_lookup;\n\n\tif (frontend) {\n\t\ttype &= frontend->maskclear;\n\t\tmask &= frontend->maskclear;\n\t\ttype |= frontend->type;\n\t\tmask |= frontend->maskset;\n\n\t\tif (frontend->lookup)\n\t\t\tlookup = frontend->lookup;\n\t}\n\n\treturn lookup(alg_name, type, mask);\n}\nEXPORT_SYMBOL_GPL(crypto_find_alg);\n\n/*\n *\tcrypto_alloc_tfm - Locate algorithm and allocate transform\n *\t@alg_name: Name of algorithm\n *\t@frontend: Frontend algorithm type\n *\t@type: Type of algorithm\n *\t@mask: Mask for type comparison\n *\n *\tcrypto_alloc_tfm() will first attempt to locate an already loaded\n *\talgorithm.  If that fails and the kernel supports dynamically loadable\n *\tmodules, it will then attempt to load a module of the same name or\n *\talias.  If that fails it will send a query to any loaded crypto manager\n *\tto construct an algorithm on the fly.  A refcount is grabbed on the\n *\talgorithm which is then associated with the new transform.\n *\n *\tThe returned transform is of a non-determinate type.  Most people\n *\tshould use one of the more specific allocation functions such as\n *\tcrypto_alloc_blkcipher.\n *\n *\tIn case of error the return value is an error pointer.\n */\nvoid *crypto_alloc_tfm(const char *alg_name,\n\t\t       const struct crypto_type *frontend, u32 type, u32 mask)\n{\n\tvoid *tfm;\n\tint err;\n\n\tfor (;;) {\n\t\tstruct crypto_alg *alg;\n\n\t\talg = crypto_find_alg(alg_name, frontend, type, mask);\n\t\tif (IS_ERR(alg)) {\n\t\t\terr = PTR_ERR(alg);\n\t\t\tgoto err;\n\t\t}\n\n\t\ttfm = crypto_create_tfm(alg, frontend);\n\t\tif (!IS_ERR(tfm))\n\t\t\treturn tfm;\n\n\t\tcrypto_mod_put(alg);\n\t\terr = PTR_ERR(tfm);\n\nerr:\n\t\tif (err != -EAGAIN)\n\t\t\tbreak;\n\t\tif (signal_pending(current)) {\n\t\t\terr = -EINTR;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn ERR_PTR(err);\n}\nEXPORT_SYMBOL_GPL(crypto_alloc_tfm);\n\n/*\n *\tcrypto_destroy_tfm - Free crypto transform\n *\t@mem: Start of tfm slab\n *\t@tfm: Transform to free\n *\n *\tThis function frees up the transform and any associated resources,\n *\tthen drops the refcount on the associated algorithm.\n */\nvoid crypto_destroy_tfm(void *mem, struct crypto_tfm *tfm)\n{\n\tstruct crypto_alg *alg;\n\n\tif (unlikely(!mem))\n\t\treturn;\n\n\talg = tfm->__crt_alg;\n\n\tif (!tfm->exit && alg->cra_exit)\n\t\talg->cra_exit(tfm);\n\tcrypto_exit_ops(tfm);\n\tcrypto_mod_put(alg);\n\tkzfree(mem);\n}\nEXPORT_SYMBOL_GPL(crypto_destroy_tfm);\n\nint crypto_has_alg(const char *name, u32 type, u32 mask)\n{\n\tint ret = 0;\n\tstruct crypto_alg *alg = crypto_alg_mod_lookup(name, type, mask);\n\n\tif (!IS_ERR(alg)) {\n\t\tcrypto_mod_put(alg);\n\t\tret = 1;\n\t}\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(crypto_has_alg);\n\nMODULE_DESCRIPTION(\"Cryptographic core API\");\nMODULE_LICENSE(\"GPL\");\n", "/*\n * Cryptographic API\n *\n * ARC4 Cipher Algorithm\n *\n * Jon Oberheide <jon@oberheide.org>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/crypto.h>\n#include <crypto/algapi.h>\n\n#define ARC4_MIN_KEY_SIZE\t1\n#define ARC4_MAX_KEY_SIZE\t256\n#define ARC4_BLOCK_SIZE\t\t1\n\nstruct arc4_ctx {\n\tu32 S[256];\n\tu32 x, y;\n};\n\nstatic int arc4_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t\tunsigned int key_len)\n{\n\tstruct arc4_ctx *ctx = crypto_tfm_ctx(tfm);\n\tint i, j = 0, k = 0;\n\n\tctx->x = 1;\n\tctx->y = 0;\n\n\tfor (i = 0; i < 256; i++)\n\t\tctx->S[i] = i;\n\n\tfor (i = 0; i < 256; i++) {\n\t\tu32 a = ctx->S[i];\n\t\tj = (j + in_key[k] + a) & 0xff;\n\t\tctx->S[i] = ctx->S[j];\n\t\tctx->S[j] = a;\n\t\tif (++k >= key_len)\n\t\t\tk = 0;\n\t}\n\n\treturn 0;\n}\n\nstatic void arc4_crypt(struct arc4_ctx *ctx, u8 *out, const u8 *in,\n\t\t       unsigned int len)\n{\n\tu32 *const S = ctx->S;\n\tu32 x, y, a, b;\n\tu32 ty, ta, tb;\n\n\tif (len == 0)\n\t\treturn;\n\n\tx = ctx->x;\n\ty = ctx->y;\n\n\ta = S[x];\n\ty = (y + a) & 0xff;\n\tb = S[y];\n\n\tdo {\n\t\tS[y] = a;\n\t\ta = (a + b) & 0xff;\n\t\tS[x] = b;\n\t\tx = (x + 1) & 0xff;\n\t\tta = S[x];\n\t\tty = (y + ta) & 0xff;\n\t\ttb = S[ty];\n\t\t*out++ = *in++ ^ S[a];\n\t\tif (--len == 0)\n\t\t\tbreak;\n\t\ty = ty;\n\t\ta = ta;\n\t\tb = tb;\n\t} while (true);\n\n\tctx->x = x;\n\tctx->y = y;\n}\n\nstatic void arc4_crypt_one(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tarc4_crypt(crypto_tfm_ctx(tfm), out, in, 1);\n}\n\nstatic int ecb_arc4_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t\t  struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct arc4_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\twhile (walk.nbytes > 0) {\n\t\tu8 *wsrc = walk.src.virt.addr;\n\t\tu8 *wdst = walk.dst.virt.addr;\n\n\t\tarc4_crypt(ctx, wdst, wsrc, walk.nbytes);\n\n\t\terr = blkcipher_walk_done(desc, &walk, 0);\n\t}\n\n\treturn err;\n}\n\nstatic struct crypto_alg arc4_algs[2] = { {\n\t.cra_name\t\t=\t\"arc4\",\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tARC4_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct arc4_ctx),\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.cipher = {\n\t\t\t.cia_min_keysize\t=\tARC4_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t=\tARC4_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t=\tarc4_set_key,\n\t\t\t.cia_encrypt\t\t=\tarc4_crypt_one,\n\t\t\t.cia_decrypt\t\t=\tarc4_crypt_one,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t=\t\"ecb(arc4)\",\n\t.cra_priority\t\t=\t100,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t=\tARC4_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct arc4_ctx),\n\t.cra_alignmask\t\t=\t0,\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t=\tARC4_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t=\tARC4_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t=\tarc4_set_key,\n\t\t\t.encrypt\t=\tecb_arc4_crypt,\n\t\t\t.decrypt\t=\tecb_arc4_crypt,\n\t\t},\n\t},\n} };\n\nstatic int __init arc4_init(void)\n{\n\treturn crypto_register_algs(arc4_algs, ARRAY_SIZE(arc4_algs));\n}\n\nstatic void __exit arc4_exit(void)\n{\n\tcrypto_unregister_algs(arc4_algs, ARRAY_SIZE(arc4_algs));\n}\n\nmodule_init(arc4_init);\nmodule_exit(arc4_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"ARC4 Cipher Algorithm\");\nMODULE_AUTHOR(\"Jon Oberheide <jon@oberheide.org>\");\n", "/*\n * Cryptographic API.\n *\n * Blowfish Cipher Algorithm, by Bruce Schneier.\n * http://www.counterpane.com/blowfish.html\n *\n * Adapted from Kerneli implementation.\n *\n * Copyright (c) Herbert Valerio Riedel <hvr@hvrlab.org>\n * Copyright (c) Kyle McMartin <kyle@debian.org>\n * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <asm/byteorder.h>\n#include <linux/crypto.h>\n#include <linux/types.h>\n#include <crypto/blowfish.h>\n\n/*\n * Round loop unrolling macros, S is a pointer to a S-Box array\n * organized in 4 unsigned longs at a row.\n */\n#define GET32_3(x) (((x) & 0xff))\n#define GET32_2(x) (((x) >> (8)) & (0xff))\n#define GET32_1(x) (((x) >> (16)) & (0xff))\n#define GET32_0(x) (((x) >> (24)) & (0xff))\n\n#define bf_F(x) (((S[GET32_0(x)] + S[256 + GET32_1(x)]) ^ \\\n\t\tS[512 + GET32_2(x)]) + S[768 + GET32_3(x)])\n\n#define ROUND(a, b, n) ({ b ^= P[n]; a ^= bf_F(b); })\n\nstatic void bf_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct bf_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __be32 *in_blk = (const __be32 *)src;\n\t__be32 *const out_blk = (__be32 *)dst;\n\tconst u32 *P = ctx->p;\n\tconst u32 *S = ctx->s;\n\tu32 yl = be32_to_cpu(in_blk[0]);\n\tu32 yr = be32_to_cpu(in_blk[1]);\n\n\tROUND(yr, yl, 0);\n\tROUND(yl, yr, 1);\n\tROUND(yr, yl, 2);\n\tROUND(yl, yr, 3);\n\tROUND(yr, yl, 4);\n\tROUND(yl, yr, 5);\n\tROUND(yr, yl, 6);\n\tROUND(yl, yr, 7);\n\tROUND(yr, yl, 8);\n\tROUND(yl, yr, 9);\n\tROUND(yr, yl, 10);\n\tROUND(yl, yr, 11);\n\tROUND(yr, yl, 12);\n\tROUND(yl, yr, 13);\n\tROUND(yr, yl, 14);\n\tROUND(yl, yr, 15);\n\n\tyl ^= P[16];\n\tyr ^= P[17];\n\n\tout_blk[0] = cpu_to_be32(yr);\n\tout_blk[1] = cpu_to_be32(yl);\n}\n\nstatic void bf_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct bf_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __be32 *in_blk = (const __be32 *)src;\n\t__be32 *const out_blk = (__be32 *)dst;\n\tconst u32 *P = ctx->p;\n\tconst u32 *S = ctx->s;\n\tu32 yl = be32_to_cpu(in_blk[0]);\n\tu32 yr = be32_to_cpu(in_blk[1]);\n\n\tROUND(yr, yl, 17);\n\tROUND(yl, yr, 16);\n\tROUND(yr, yl, 15);\n\tROUND(yl, yr, 14);\n\tROUND(yr, yl, 13);\n\tROUND(yl, yr, 12);\n\tROUND(yr, yl, 11);\n\tROUND(yl, yr, 10);\n\tROUND(yr, yl, 9);\n\tROUND(yl, yr, 8);\n\tROUND(yr, yl, 7);\n\tROUND(yl, yr, 6);\n\tROUND(yr, yl, 5);\n\tROUND(yl, yr, 4);\n\tROUND(yr, yl, 3);\n\tROUND(yl, yr, 2);\n\n\tyl ^= P[1];\n\tyr ^= P[0];\n\n\tout_blk[0] = cpu_to_be32(yr);\n\tout_blk[1] = cpu_to_be32(yl);\n}\n\nstatic struct crypto_alg alg = {\n\t.cra_name\t\t=\t\"blowfish\",\n\t.cra_driver_name\t=\t\"blowfish-generic\",\n\t.cra_priority\t\t=\t100,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tBF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct bf_ctx),\n\t.cra_alignmask\t\t=\t3,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\tBF_MIN_KEY_SIZE,\n\t.cia_max_keysize\t=\tBF_MAX_KEY_SIZE,\n\t.cia_setkey\t\t=\tblowfish_setkey,\n\t.cia_encrypt\t\t=\tbf_encrypt,\n\t.cia_decrypt\t\t=\tbf_decrypt } }\n};\n\nstatic int __init blowfish_mod_init(void)\n{\n\treturn crypto_register_alg(&alg);\n}\n\nstatic void __exit blowfish_mod_fini(void)\n{\n\tcrypto_unregister_alg(&alg);\n}\n\nmodule_init(blowfish_mod_init);\nmodule_exit(blowfish_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Blowfish Cipher Algorithm\");\nMODULE_ALIAS(\"blowfish\");\n", "/*\n * Copyright (C) 2006\n * NTT (Nippon Telegraph and Telephone Corporation).\n *\n * This program is free software; you can redistribute it and/or\n * modify it under the terms of the GNU General Public License\n * as published by the Free Software Foundation; either version 2\n * of the License, or (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.\n */\n\n/*\n * Algorithm Specification\n *  http://info.isl.ntt.co.jp/crypt/eng/camellia/specifications.html\n */\n\n/*\n *\n * NOTE --- NOTE --- NOTE --- NOTE\n * This implementation assumes that all memory addresses passed\n * as parameters are four-byte aligned.\n *\n */\n\n#include <linux/crypto.h>\n#include <linux/errno.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/bitops.h>\n#include <asm/unaligned.h>\n\nstatic const u32 camellia_sp1110[256] = {\n\t0x70707000, 0x82828200, 0x2c2c2c00, 0xececec00,\n\t0xb3b3b300, 0x27272700, 0xc0c0c000, 0xe5e5e500,\n\t0xe4e4e400, 0x85858500, 0x57575700, 0x35353500,\n\t0xeaeaea00, 0x0c0c0c00, 0xaeaeae00, 0x41414100,\n\t0x23232300, 0xefefef00, 0x6b6b6b00, 0x93939300,\n\t0x45454500, 0x19191900, 0xa5a5a500, 0x21212100,\n\t0xededed00, 0x0e0e0e00, 0x4f4f4f00, 0x4e4e4e00,\n\t0x1d1d1d00, 0x65656500, 0x92929200, 0xbdbdbd00,\n\t0x86868600, 0xb8b8b800, 0xafafaf00, 0x8f8f8f00,\n\t0x7c7c7c00, 0xebebeb00, 0x1f1f1f00, 0xcecece00,\n\t0x3e3e3e00, 0x30303000, 0xdcdcdc00, 0x5f5f5f00,\n\t0x5e5e5e00, 0xc5c5c500, 0x0b0b0b00, 0x1a1a1a00,\n\t0xa6a6a600, 0xe1e1e100, 0x39393900, 0xcacaca00,\n\t0xd5d5d500, 0x47474700, 0x5d5d5d00, 0x3d3d3d00,\n\t0xd9d9d900, 0x01010100, 0x5a5a5a00, 0xd6d6d600,\n\t0x51515100, 0x56565600, 0x6c6c6c00, 0x4d4d4d00,\n\t0x8b8b8b00, 0x0d0d0d00, 0x9a9a9a00, 0x66666600,\n\t0xfbfbfb00, 0xcccccc00, 0xb0b0b000, 0x2d2d2d00,\n\t0x74747400, 0x12121200, 0x2b2b2b00, 0x20202000,\n\t0xf0f0f000, 0xb1b1b100, 0x84848400, 0x99999900,\n\t0xdfdfdf00, 0x4c4c4c00, 0xcbcbcb00, 0xc2c2c200,\n\t0x34343400, 0x7e7e7e00, 0x76767600, 0x05050500,\n\t0x6d6d6d00, 0xb7b7b700, 0xa9a9a900, 0x31313100,\n\t0xd1d1d100, 0x17171700, 0x04040400, 0xd7d7d700,\n\t0x14141400, 0x58585800, 0x3a3a3a00, 0x61616100,\n\t0xdedede00, 0x1b1b1b00, 0x11111100, 0x1c1c1c00,\n\t0x32323200, 0x0f0f0f00, 0x9c9c9c00, 0x16161600,\n\t0x53535300, 0x18181800, 0xf2f2f200, 0x22222200,\n\t0xfefefe00, 0x44444400, 0xcfcfcf00, 0xb2b2b200,\n\t0xc3c3c300, 0xb5b5b500, 0x7a7a7a00, 0x91919100,\n\t0x24242400, 0x08080800, 0xe8e8e800, 0xa8a8a800,\n\t0x60606000, 0xfcfcfc00, 0x69696900, 0x50505000,\n\t0xaaaaaa00, 0xd0d0d000, 0xa0a0a000, 0x7d7d7d00,\n\t0xa1a1a100, 0x89898900, 0x62626200, 0x97979700,\n\t0x54545400, 0x5b5b5b00, 0x1e1e1e00, 0x95959500,\n\t0xe0e0e000, 0xffffff00, 0x64646400, 0xd2d2d200,\n\t0x10101000, 0xc4c4c400, 0x00000000, 0x48484800,\n\t0xa3a3a300, 0xf7f7f700, 0x75757500, 0xdbdbdb00,\n\t0x8a8a8a00, 0x03030300, 0xe6e6e600, 0xdadada00,\n\t0x09090900, 0x3f3f3f00, 0xdddddd00, 0x94949400,\n\t0x87878700, 0x5c5c5c00, 0x83838300, 0x02020200,\n\t0xcdcdcd00, 0x4a4a4a00, 0x90909000, 0x33333300,\n\t0x73737300, 0x67676700, 0xf6f6f600, 0xf3f3f300,\n\t0x9d9d9d00, 0x7f7f7f00, 0xbfbfbf00, 0xe2e2e200,\n\t0x52525200, 0x9b9b9b00, 0xd8d8d800, 0x26262600,\n\t0xc8c8c800, 0x37373700, 0xc6c6c600, 0x3b3b3b00,\n\t0x81818100, 0x96969600, 0x6f6f6f00, 0x4b4b4b00,\n\t0x13131300, 0xbebebe00, 0x63636300, 0x2e2e2e00,\n\t0xe9e9e900, 0x79797900, 0xa7a7a700, 0x8c8c8c00,\n\t0x9f9f9f00, 0x6e6e6e00, 0xbcbcbc00, 0x8e8e8e00,\n\t0x29292900, 0xf5f5f500, 0xf9f9f900, 0xb6b6b600,\n\t0x2f2f2f00, 0xfdfdfd00, 0xb4b4b400, 0x59595900,\n\t0x78787800, 0x98989800, 0x06060600, 0x6a6a6a00,\n\t0xe7e7e700, 0x46464600, 0x71717100, 0xbababa00,\n\t0xd4d4d400, 0x25252500, 0xababab00, 0x42424200,\n\t0x88888800, 0xa2a2a200, 0x8d8d8d00, 0xfafafa00,\n\t0x72727200, 0x07070700, 0xb9b9b900, 0x55555500,\n\t0xf8f8f800, 0xeeeeee00, 0xacacac00, 0x0a0a0a00,\n\t0x36363600, 0x49494900, 0x2a2a2a00, 0x68686800,\n\t0x3c3c3c00, 0x38383800, 0xf1f1f100, 0xa4a4a400,\n\t0x40404000, 0x28282800, 0xd3d3d300, 0x7b7b7b00,\n\t0xbbbbbb00, 0xc9c9c900, 0x43434300, 0xc1c1c100,\n\t0x15151500, 0xe3e3e300, 0xadadad00, 0xf4f4f400,\n\t0x77777700, 0xc7c7c700, 0x80808000, 0x9e9e9e00,\n};\n\nstatic const u32 camellia_sp0222[256] = {\n\t0x00e0e0e0, 0x00050505, 0x00585858, 0x00d9d9d9,\n\t0x00676767, 0x004e4e4e, 0x00818181, 0x00cbcbcb,\n\t0x00c9c9c9, 0x000b0b0b, 0x00aeaeae, 0x006a6a6a,\n\t0x00d5d5d5, 0x00181818, 0x005d5d5d, 0x00828282,\n\t0x00464646, 0x00dfdfdf, 0x00d6d6d6, 0x00272727,\n\t0x008a8a8a, 0x00323232, 0x004b4b4b, 0x00424242,\n\t0x00dbdbdb, 0x001c1c1c, 0x009e9e9e, 0x009c9c9c,\n\t0x003a3a3a, 0x00cacaca, 0x00252525, 0x007b7b7b,\n\t0x000d0d0d, 0x00717171, 0x005f5f5f, 0x001f1f1f,\n\t0x00f8f8f8, 0x00d7d7d7, 0x003e3e3e, 0x009d9d9d,\n\t0x007c7c7c, 0x00606060, 0x00b9b9b9, 0x00bebebe,\n\t0x00bcbcbc, 0x008b8b8b, 0x00161616, 0x00343434,\n\t0x004d4d4d, 0x00c3c3c3, 0x00727272, 0x00959595,\n\t0x00ababab, 0x008e8e8e, 0x00bababa, 0x007a7a7a,\n\t0x00b3b3b3, 0x00020202, 0x00b4b4b4, 0x00adadad,\n\t0x00a2a2a2, 0x00acacac, 0x00d8d8d8, 0x009a9a9a,\n\t0x00171717, 0x001a1a1a, 0x00353535, 0x00cccccc,\n\t0x00f7f7f7, 0x00999999, 0x00616161, 0x005a5a5a,\n\t0x00e8e8e8, 0x00242424, 0x00565656, 0x00404040,\n\t0x00e1e1e1, 0x00636363, 0x00090909, 0x00333333,\n\t0x00bfbfbf, 0x00989898, 0x00979797, 0x00858585,\n\t0x00686868, 0x00fcfcfc, 0x00ececec, 0x000a0a0a,\n\t0x00dadada, 0x006f6f6f, 0x00535353, 0x00626262,\n\t0x00a3a3a3, 0x002e2e2e, 0x00080808, 0x00afafaf,\n\t0x00282828, 0x00b0b0b0, 0x00747474, 0x00c2c2c2,\n\t0x00bdbdbd, 0x00363636, 0x00222222, 0x00383838,\n\t0x00646464, 0x001e1e1e, 0x00393939, 0x002c2c2c,\n\t0x00a6a6a6, 0x00303030, 0x00e5e5e5, 0x00444444,\n\t0x00fdfdfd, 0x00888888, 0x009f9f9f, 0x00656565,\n\t0x00878787, 0x006b6b6b, 0x00f4f4f4, 0x00232323,\n\t0x00484848, 0x00101010, 0x00d1d1d1, 0x00515151,\n\t0x00c0c0c0, 0x00f9f9f9, 0x00d2d2d2, 0x00a0a0a0,\n\t0x00555555, 0x00a1a1a1, 0x00414141, 0x00fafafa,\n\t0x00434343, 0x00131313, 0x00c4c4c4, 0x002f2f2f,\n\t0x00a8a8a8, 0x00b6b6b6, 0x003c3c3c, 0x002b2b2b,\n\t0x00c1c1c1, 0x00ffffff, 0x00c8c8c8, 0x00a5a5a5,\n\t0x00202020, 0x00898989, 0x00000000, 0x00909090,\n\t0x00474747, 0x00efefef, 0x00eaeaea, 0x00b7b7b7,\n\t0x00151515, 0x00060606, 0x00cdcdcd, 0x00b5b5b5,\n\t0x00121212, 0x007e7e7e, 0x00bbbbbb, 0x00292929,\n\t0x000f0f0f, 0x00b8b8b8, 0x00070707, 0x00040404,\n\t0x009b9b9b, 0x00949494, 0x00212121, 0x00666666,\n\t0x00e6e6e6, 0x00cecece, 0x00ededed, 0x00e7e7e7,\n\t0x003b3b3b, 0x00fefefe, 0x007f7f7f, 0x00c5c5c5,\n\t0x00a4a4a4, 0x00373737, 0x00b1b1b1, 0x004c4c4c,\n\t0x00919191, 0x006e6e6e, 0x008d8d8d, 0x00767676,\n\t0x00030303, 0x002d2d2d, 0x00dedede, 0x00969696,\n\t0x00262626, 0x007d7d7d, 0x00c6c6c6, 0x005c5c5c,\n\t0x00d3d3d3, 0x00f2f2f2, 0x004f4f4f, 0x00191919,\n\t0x003f3f3f, 0x00dcdcdc, 0x00797979, 0x001d1d1d,\n\t0x00525252, 0x00ebebeb, 0x00f3f3f3, 0x006d6d6d,\n\t0x005e5e5e, 0x00fbfbfb, 0x00696969, 0x00b2b2b2,\n\t0x00f0f0f0, 0x00313131, 0x000c0c0c, 0x00d4d4d4,\n\t0x00cfcfcf, 0x008c8c8c, 0x00e2e2e2, 0x00757575,\n\t0x00a9a9a9, 0x004a4a4a, 0x00575757, 0x00848484,\n\t0x00111111, 0x00454545, 0x001b1b1b, 0x00f5f5f5,\n\t0x00e4e4e4, 0x000e0e0e, 0x00737373, 0x00aaaaaa,\n\t0x00f1f1f1, 0x00dddddd, 0x00595959, 0x00141414,\n\t0x006c6c6c, 0x00929292, 0x00545454, 0x00d0d0d0,\n\t0x00787878, 0x00707070, 0x00e3e3e3, 0x00494949,\n\t0x00808080, 0x00505050, 0x00a7a7a7, 0x00f6f6f6,\n\t0x00777777, 0x00939393, 0x00868686, 0x00838383,\n\t0x002a2a2a, 0x00c7c7c7, 0x005b5b5b, 0x00e9e9e9,\n\t0x00eeeeee, 0x008f8f8f, 0x00010101, 0x003d3d3d,\n};\n\nstatic const u32 camellia_sp3033[256] = {\n\t0x38003838, 0x41004141, 0x16001616, 0x76007676,\n\t0xd900d9d9, 0x93009393, 0x60006060, 0xf200f2f2,\n\t0x72007272, 0xc200c2c2, 0xab00abab, 0x9a009a9a,\n\t0x75007575, 0x06000606, 0x57005757, 0xa000a0a0,\n\t0x91009191, 0xf700f7f7, 0xb500b5b5, 0xc900c9c9,\n\t0xa200a2a2, 0x8c008c8c, 0xd200d2d2, 0x90009090,\n\t0xf600f6f6, 0x07000707, 0xa700a7a7, 0x27002727,\n\t0x8e008e8e, 0xb200b2b2, 0x49004949, 0xde00dede,\n\t0x43004343, 0x5c005c5c, 0xd700d7d7, 0xc700c7c7,\n\t0x3e003e3e, 0xf500f5f5, 0x8f008f8f, 0x67006767,\n\t0x1f001f1f, 0x18001818, 0x6e006e6e, 0xaf00afaf,\n\t0x2f002f2f, 0xe200e2e2, 0x85008585, 0x0d000d0d,\n\t0x53005353, 0xf000f0f0, 0x9c009c9c, 0x65006565,\n\t0xea00eaea, 0xa300a3a3, 0xae00aeae, 0x9e009e9e,\n\t0xec00ecec, 0x80008080, 0x2d002d2d, 0x6b006b6b,\n\t0xa800a8a8, 0x2b002b2b, 0x36003636, 0xa600a6a6,\n\t0xc500c5c5, 0x86008686, 0x4d004d4d, 0x33003333,\n\t0xfd00fdfd, 0x66006666, 0x58005858, 0x96009696,\n\t0x3a003a3a, 0x09000909, 0x95009595, 0x10001010,\n\t0x78007878, 0xd800d8d8, 0x42004242, 0xcc00cccc,\n\t0xef00efef, 0x26002626, 0xe500e5e5, 0x61006161,\n\t0x1a001a1a, 0x3f003f3f, 0x3b003b3b, 0x82008282,\n\t0xb600b6b6, 0xdb00dbdb, 0xd400d4d4, 0x98009898,\n\t0xe800e8e8, 0x8b008b8b, 0x02000202, 0xeb00ebeb,\n\t0x0a000a0a, 0x2c002c2c, 0x1d001d1d, 0xb000b0b0,\n\t0x6f006f6f, 0x8d008d8d, 0x88008888, 0x0e000e0e,\n\t0x19001919, 0x87008787, 0x4e004e4e, 0x0b000b0b,\n\t0xa900a9a9, 0x0c000c0c, 0x79007979, 0x11001111,\n\t0x7f007f7f, 0x22002222, 0xe700e7e7, 0x59005959,\n\t0xe100e1e1, 0xda00dada, 0x3d003d3d, 0xc800c8c8,\n\t0x12001212, 0x04000404, 0x74007474, 0x54005454,\n\t0x30003030, 0x7e007e7e, 0xb400b4b4, 0x28002828,\n\t0x55005555, 0x68006868, 0x50005050, 0xbe00bebe,\n\t0xd000d0d0, 0xc400c4c4, 0x31003131, 0xcb00cbcb,\n\t0x2a002a2a, 0xad00adad, 0x0f000f0f, 0xca00caca,\n\t0x70007070, 0xff00ffff, 0x32003232, 0x69006969,\n\t0x08000808, 0x62006262, 0x00000000, 0x24002424,\n\t0xd100d1d1, 0xfb00fbfb, 0xba00baba, 0xed00eded,\n\t0x45004545, 0x81008181, 0x73007373, 0x6d006d6d,\n\t0x84008484, 0x9f009f9f, 0xee00eeee, 0x4a004a4a,\n\t0xc300c3c3, 0x2e002e2e, 0xc100c1c1, 0x01000101,\n\t0xe600e6e6, 0x25002525, 0x48004848, 0x99009999,\n\t0xb900b9b9, 0xb300b3b3, 0x7b007b7b, 0xf900f9f9,\n\t0xce00cece, 0xbf00bfbf, 0xdf00dfdf, 0x71007171,\n\t0x29002929, 0xcd00cdcd, 0x6c006c6c, 0x13001313,\n\t0x64006464, 0x9b009b9b, 0x63006363, 0x9d009d9d,\n\t0xc000c0c0, 0x4b004b4b, 0xb700b7b7, 0xa500a5a5,\n\t0x89008989, 0x5f005f5f, 0xb100b1b1, 0x17001717,\n\t0xf400f4f4, 0xbc00bcbc, 0xd300d3d3, 0x46004646,\n\t0xcf00cfcf, 0x37003737, 0x5e005e5e, 0x47004747,\n\t0x94009494, 0xfa00fafa, 0xfc00fcfc, 0x5b005b5b,\n\t0x97009797, 0xfe00fefe, 0x5a005a5a, 0xac00acac,\n\t0x3c003c3c, 0x4c004c4c, 0x03000303, 0x35003535,\n\t0xf300f3f3, 0x23002323, 0xb800b8b8, 0x5d005d5d,\n\t0x6a006a6a, 0x92009292, 0xd500d5d5, 0x21002121,\n\t0x44004444, 0x51005151, 0xc600c6c6, 0x7d007d7d,\n\t0x39003939, 0x83008383, 0xdc00dcdc, 0xaa00aaaa,\n\t0x7c007c7c, 0x77007777, 0x56005656, 0x05000505,\n\t0x1b001b1b, 0xa400a4a4, 0x15001515, 0x34003434,\n\t0x1e001e1e, 0x1c001c1c, 0xf800f8f8, 0x52005252,\n\t0x20002020, 0x14001414, 0xe900e9e9, 0xbd00bdbd,\n\t0xdd00dddd, 0xe400e4e4, 0xa100a1a1, 0xe000e0e0,\n\t0x8a008a8a, 0xf100f1f1, 0xd600d6d6, 0x7a007a7a,\n\t0xbb00bbbb, 0xe300e3e3, 0x40004040, 0x4f004f4f,\n};\n\nstatic const u32 camellia_sp4404[256] = {\n\t0x70700070, 0x2c2c002c, 0xb3b300b3, 0xc0c000c0,\n\t0xe4e400e4, 0x57570057, 0xeaea00ea, 0xaeae00ae,\n\t0x23230023, 0x6b6b006b, 0x45450045, 0xa5a500a5,\n\t0xeded00ed, 0x4f4f004f, 0x1d1d001d, 0x92920092,\n\t0x86860086, 0xafaf00af, 0x7c7c007c, 0x1f1f001f,\n\t0x3e3e003e, 0xdcdc00dc, 0x5e5e005e, 0x0b0b000b,\n\t0xa6a600a6, 0x39390039, 0xd5d500d5, 0x5d5d005d,\n\t0xd9d900d9, 0x5a5a005a, 0x51510051, 0x6c6c006c,\n\t0x8b8b008b, 0x9a9a009a, 0xfbfb00fb, 0xb0b000b0,\n\t0x74740074, 0x2b2b002b, 0xf0f000f0, 0x84840084,\n\t0xdfdf00df, 0xcbcb00cb, 0x34340034, 0x76760076,\n\t0x6d6d006d, 0xa9a900a9, 0xd1d100d1, 0x04040004,\n\t0x14140014, 0x3a3a003a, 0xdede00de, 0x11110011,\n\t0x32320032, 0x9c9c009c, 0x53530053, 0xf2f200f2,\n\t0xfefe00fe, 0xcfcf00cf, 0xc3c300c3, 0x7a7a007a,\n\t0x24240024, 0xe8e800e8, 0x60600060, 0x69690069,\n\t0xaaaa00aa, 0xa0a000a0, 0xa1a100a1, 0x62620062,\n\t0x54540054, 0x1e1e001e, 0xe0e000e0, 0x64640064,\n\t0x10100010, 0x00000000, 0xa3a300a3, 0x75750075,\n\t0x8a8a008a, 0xe6e600e6, 0x09090009, 0xdddd00dd,\n\t0x87870087, 0x83830083, 0xcdcd00cd, 0x90900090,\n\t0x73730073, 0xf6f600f6, 0x9d9d009d, 0xbfbf00bf,\n\t0x52520052, 0xd8d800d8, 0xc8c800c8, 0xc6c600c6,\n\t0x81810081, 0x6f6f006f, 0x13130013, 0x63630063,\n\t0xe9e900e9, 0xa7a700a7, 0x9f9f009f, 0xbcbc00bc,\n\t0x29290029, 0xf9f900f9, 0x2f2f002f, 0xb4b400b4,\n\t0x78780078, 0x06060006, 0xe7e700e7, 0x71710071,\n\t0xd4d400d4, 0xabab00ab, 0x88880088, 0x8d8d008d,\n\t0x72720072, 0xb9b900b9, 0xf8f800f8, 0xacac00ac,\n\t0x36360036, 0x2a2a002a, 0x3c3c003c, 0xf1f100f1,\n\t0x40400040, 0xd3d300d3, 0xbbbb00bb, 0x43430043,\n\t0x15150015, 0xadad00ad, 0x77770077, 0x80800080,\n\t0x82820082, 0xecec00ec, 0x27270027, 0xe5e500e5,\n\t0x85850085, 0x35350035, 0x0c0c000c, 0x41410041,\n\t0xefef00ef, 0x93930093, 0x19190019, 0x21210021,\n\t0x0e0e000e, 0x4e4e004e, 0x65650065, 0xbdbd00bd,\n\t0xb8b800b8, 0x8f8f008f, 0xebeb00eb, 0xcece00ce,\n\t0x30300030, 0x5f5f005f, 0xc5c500c5, 0x1a1a001a,\n\t0xe1e100e1, 0xcaca00ca, 0x47470047, 0x3d3d003d,\n\t0x01010001, 0xd6d600d6, 0x56560056, 0x4d4d004d,\n\t0x0d0d000d, 0x66660066, 0xcccc00cc, 0x2d2d002d,\n\t0x12120012, 0x20200020, 0xb1b100b1, 0x99990099,\n\t0x4c4c004c, 0xc2c200c2, 0x7e7e007e, 0x05050005,\n\t0xb7b700b7, 0x31310031, 0x17170017, 0xd7d700d7,\n\t0x58580058, 0x61610061, 0x1b1b001b, 0x1c1c001c,\n\t0x0f0f000f, 0x16160016, 0x18180018, 0x22220022,\n\t0x44440044, 0xb2b200b2, 0xb5b500b5, 0x91910091,\n\t0x08080008, 0xa8a800a8, 0xfcfc00fc, 0x50500050,\n\t0xd0d000d0, 0x7d7d007d, 0x89890089, 0x97970097,\n\t0x5b5b005b, 0x95950095, 0xffff00ff, 0xd2d200d2,\n\t0xc4c400c4, 0x48480048, 0xf7f700f7, 0xdbdb00db,\n\t0x03030003, 0xdada00da, 0x3f3f003f, 0x94940094,\n\t0x5c5c005c, 0x02020002, 0x4a4a004a, 0x33330033,\n\t0x67670067, 0xf3f300f3, 0x7f7f007f, 0xe2e200e2,\n\t0x9b9b009b, 0x26260026, 0x37370037, 0x3b3b003b,\n\t0x96960096, 0x4b4b004b, 0xbebe00be, 0x2e2e002e,\n\t0x79790079, 0x8c8c008c, 0x6e6e006e, 0x8e8e008e,\n\t0xf5f500f5, 0xb6b600b6, 0xfdfd00fd, 0x59590059,\n\t0x98980098, 0x6a6a006a, 0x46460046, 0xbaba00ba,\n\t0x25250025, 0x42420042, 0xa2a200a2, 0xfafa00fa,\n\t0x07070007, 0x55550055, 0xeeee00ee, 0x0a0a000a,\n\t0x49490049, 0x68680068, 0x38380038, 0xa4a400a4,\n\t0x28280028, 0x7b7b007b, 0xc9c900c9, 0xc1c100c1,\n\t0xe3e300e3, 0xf4f400f4, 0xc7c700c7, 0x9e9e009e,\n};\n\n\n#define CAMELLIA_MIN_KEY_SIZE        16\n#define CAMELLIA_MAX_KEY_SIZE        32\n#define CAMELLIA_BLOCK_SIZE          16\n#define CAMELLIA_TABLE_BYTE_LEN     272\n\n/*\n * NB: L and R below stand for 'left' and 'right' as in written numbers.\n * That is, in (xxxL,xxxR) pair xxxL holds most significant digits,\n * _not_ least significant ones!\n */\n\n\n/* key constants */\n\n#define CAMELLIA_SIGMA1L (0xA09E667FL)\n#define CAMELLIA_SIGMA1R (0x3BCC908BL)\n#define CAMELLIA_SIGMA2L (0xB67AE858L)\n#define CAMELLIA_SIGMA2R (0x4CAA73B2L)\n#define CAMELLIA_SIGMA3L (0xC6EF372FL)\n#define CAMELLIA_SIGMA3R (0xE94F82BEL)\n#define CAMELLIA_SIGMA4L (0x54FF53A5L)\n#define CAMELLIA_SIGMA4R (0xF1D36F1CL)\n#define CAMELLIA_SIGMA5L (0x10E527FAL)\n#define CAMELLIA_SIGMA5R (0xDE682D1DL)\n#define CAMELLIA_SIGMA6L (0xB05688C2L)\n#define CAMELLIA_SIGMA6R (0xB3E6C1FDL)\n\n/*\n *  macros\n */\n#define ROLDQ(ll, lr, rl, rr, w0, w1, bits) ({\t\t\\\n\tw0 = ll;\t\t\t\t\t\\\n\tll = (ll << bits) + (lr >> (32 - bits));\t\\\n\tlr = (lr << bits) + (rl >> (32 - bits));\t\\\n\trl = (rl << bits) + (rr >> (32 - bits));\t\\\n\trr = (rr << bits) + (w0 >> (32 - bits));\t\\\n})\n\n#define ROLDQo32(ll, lr, rl, rr, w0, w1, bits) ({\t\\\n\tw0 = ll;\t\t\t\t\t\\\n\tw1 = lr;\t\t\t\t\t\\\n\tll = (lr << (bits - 32)) + (rl >> (64 - bits));\t\\\n\tlr = (rl << (bits - 32)) + (rr >> (64 - bits));\t\\\n\trl = (rr << (bits - 32)) + (w0 >> (64 - bits));\t\\\n\trr = (w0 << (bits - 32)) + (w1 >> (64 - bits));\t\\\n})\n\n#define CAMELLIA_F(xl, xr, kl, kr, yl, yr, il, ir, t0, t1) ({\t\\\n\til = xl ^ kl;\t\t\t\t\t\t\\\n\tir = xr ^ kr;\t\t\t\t\t\t\\\n\tt0 = il >> 16;\t\t\t\t\t\t\\\n\tt1 = ir >> 16;\t\t\t\t\t\t\\\n\tyl = camellia_sp1110[(u8)(ir)]\t\t\t\t\\\n\t   ^ camellia_sp0222[(u8)(t1 >> 8)]\t\t\t\\\n\t   ^ camellia_sp3033[(u8)(t1)]\t\t\t\t\\\n\t   ^ camellia_sp4404[(u8)(ir >> 8)];\t\t\t\\\n\tyr = camellia_sp1110[(u8)(t0 >> 8)]\t\t\t\\\n\t   ^ camellia_sp0222[(u8)(t0)]\t\t\t\t\\\n\t   ^ camellia_sp3033[(u8)(il >> 8)]\t\t\t\\\n\t   ^ camellia_sp4404[(u8)(il)];\t\t\t\t\\\n\tyl ^= yr;\t\t\t\t\t\t\\\n\tyr = ror32(yr, 8);\t\t\t\t\t\\\n\tyr ^= yl;\t\t\t\t\t\t\\\n})\n\n#define SUBKEY_L(INDEX) (subkey[(INDEX)*2])\n#define SUBKEY_R(INDEX) (subkey[(INDEX)*2 + 1])\n\nstatic void camellia_setup_tail(u32 *subkey, u32 *subL, u32 *subR, int max)\n{\n\tu32 dw, tl, tr;\n\tu32 kw4l, kw4r;\n\n\t/* absorb kw2 to other subkeys */\n\t/* round 2 */\n\tsubL[3] ^= subL[1]; subR[3] ^= subR[1];\n\t/* round 4 */\n\tsubL[5] ^= subL[1]; subR[5] ^= subR[1];\n\t/* round 6 */\n\tsubL[7] ^= subL[1]; subR[7] ^= subR[1];\n\tsubL[1] ^= subR[1] & ~subR[9];\n\tdw = subL[1] & subL[9];\n\tsubR[1] ^= rol32(dw, 1); /* modified for FLinv(kl2) */\n\t/* round 8 */\n\tsubL[11] ^= subL[1]; subR[11] ^= subR[1];\n\t/* round 10 */\n\tsubL[13] ^= subL[1]; subR[13] ^= subR[1];\n\t/* round 12 */\n\tsubL[15] ^= subL[1]; subR[15] ^= subR[1];\n\tsubL[1] ^= subR[1] & ~subR[17];\n\tdw = subL[1] & subL[17];\n\tsubR[1] ^= rol32(dw, 1); /* modified for FLinv(kl4) */\n\t/* round 14 */\n\tsubL[19] ^= subL[1]; subR[19] ^= subR[1];\n\t/* round 16 */\n\tsubL[21] ^= subL[1]; subR[21] ^= subR[1];\n\t/* round 18 */\n\tsubL[23] ^= subL[1]; subR[23] ^= subR[1];\n\tif (max == 24) {\n\t\t/* kw3 */\n\t\tsubL[24] ^= subL[1]; subR[24] ^= subR[1];\n\n\t/* absorb kw4 to other subkeys */\n\t\tkw4l = subL[25]; kw4r = subR[25];\n\t} else {\n\t\tsubL[1] ^= subR[1] & ~subR[25];\n\t\tdw = subL[1] & subL[25];\n\t\tsubR[1] ^= rol32(dw, 1); /* modified for FLinv(kl6) */\n\t\t/* round 20 */\n\t\tsubL[27] ^= subL[1]; subR[27] ^= subR[1];\n\t\t/* round 22 */\n\t\tsubL[29] ^= subL[1]; subR[29] ^= subR[1];\n\t\t/* round 24 */\n\t\tsubL[31] ^= subL[1]; subR[31] ^= subR[1];\n\t\t/* kw3 */\n\t\tsubL[32] ^= subL[1]; subR[32] ^= subR[1];\n\n\t/* absorb kw4 to other subkeys */\n\t\tkw4l = subL[33]; kw4r = subR[33];\n\t\t/* round 23 */\n\t\tsubL[30] ^= kw4l; subR[30] ^= kw4r;\n\t\t/* round 21 */\n\t\tsubL[28] ^= kw4l; subR[28] ^= kw4r;\n\t\t/* round 19 */\n\t\tsubL[26] ^= kw4l; subR[26] ^= kw4r;\n\t\tkw4l ^= kw4r & ~subR[24];\n\t\tdw = kw4l & subL[24];\n\t\tkw4r ^= rol32(dw, 1); /* modified for FL(kl5) */\n\t}\n\t/* round 17 */\n\tsubL[22] ^= kw4l; subR[22] ^= kw4r;\n\t/* round 15 */\n\tsubL[20] ^= kw4l; subR[20] ^= kw4r;\n\t/* round 13 */\n\tsubL[18] ^= kw4l; subR[18] ^= kw4r;\n\tkw4l ^= kw4r & ~subR[16];\n\tdw = kw4l & subL[16];\n\tkw4r ^= rol32(dw, 1); /* modified for FL(kl3) */\n\t/* round 11 */\n\tsubL[14] ^= kw4l; subR[14] ^= kw4r;\n\t/* round 9 */\n\tsubL[12] ^= kw4l; subR[12] ^= kw4r;\n\t/* round 7 */\n\tsubL[10] ^= kw4l; subR[10] ^= kw4r;\n\tkw4l ^= kw4r & ~subR[8];\n\tdw = kw4l & subL[8];\n\tkw4r ^= rol32(dw, 1); /* modified for FL(kl1) */\n\t/* round 5 */\n\tsubL[6] ^= kw4l; subR[6] ^= kw4r;\n\t/* round 3 */\n\tsubL[4] ^= kw4l; subR[4] ^= kw4r;\n\t/* round 1 */\n\tsubL[2] ^= kw4l; subR[2] ^= kw4r;\n\t/* kw1 */\n\tsubL[0] ^= kw4l; subR[0] ^= kw4r;\n\n\t/* key XOR is end of F-function */\n\tSUBKEY_L(0) = subL[0] ^ subL[2];/* kw1 */\n\tSUBKEY_R(0) = subR[0] ^ subR[2];\n\tSUBKEY_L(2) = subL[3];       /* round 1 */\n\tSUBKEY_R(2) = subR[3];\n\tSUBKEY_L(3) = subL[2] ^ subL[4]; /* round 2 */\n\tSUBKEY_R(3) = subR[2] ^ subR[4];\n\tSUBKEY_L(4) = subL[3] ^ subL[5]; /* round 3 */\n\tSUBKEY_R(4) = subR[3] ^ subR[5];\n\tSUBKEY_L(5) = subL[4] ^ subL[6]; /* round 4 */\n\tSUBKEY_R(5) = subR[4] ^ subR[6];\n\tSUBKEY_L(6) = subL[5] ^ subL[7]; /* round 5 */\n\tSUBKEY_R(6) = subR[5] ^ subR[7];\n\ttl = subL[10] ^ (subR[10] & ~subR[8]);\n\tdw = tl & subL[8];  /* FL(kl1) */\n\ttr = subR[10] ^ rol32(dw, 1);\n\tSUBKEY_L(7) = subL[6] ^ tl; /* round 6 */\n\tSUBKEY_R(7) = subR[6] ^ tr;\n\tSUBKEY_L(8) = subL[8];       /* FL(kl1) */\n\tSUBKEY_R(8) = subR[8];\n\tSUBKEY_L(9) = subL[9];       /* FLinv(kl2) */\n\tSUBKEY_R(9) = subR[9];\n\ttl = subL[7] ^ (subR[7] & ~subR[9]);\n\tdw = tl & subL[9];  /* FLinv(kl2) */\n\ttr = subR[7] ^ rol32(dw, 1);\n\tSUBKEY_L(10) = tl ^ subL[11]; /* round 7 */\n\tSUBKEY_R(10) = tr ^ subR[11];\n\tSUBKEY_L(11) = subL[10] ^ subL[12]; /* round 8 */\n\tSUBKEY_R(11) = subR[10] ^ subR[12];\n\tSUBKEY_L(12) = subL[11] ^ subL[13]; /* round 9 */\n\tSUBKEY_R(12) = subR[11] ^ subR[13];\n\tSUBKEY_L(13) = subL[12] ^ subL[14]; /* round 10 */\n\tSUBKEY_R(13) = subR[12] ^ subR[14];\n\tSUBKEY_L(14) = subL[13] ^ subL[15]; /* round 11 */\n\tSUBKEY_R(14) = subR[13] ^ subR[15];\n\ttl = subL[18] ^ (subR[18] & ~subR[16]);\n\tdw = tl & subL[16]; /* FL(kl3) */\n\ttr = subR[18] ^ rol32(dw, 1);\n\tSUBKEY_L(15) = subL[14] ^ tl; /* round 12 */\n\tSUBKEY_R(15) = subR[14] ^ tr;\n\tSUBKEY_L(16) = subL[16];     /* FL(kl3) */\n\tSUBKEY_R(16) = subR[16];\n\tSUBKEY_L(17) = subL[17];     /* FLinv(kl4) */\n\tSUBKEY_R(17) = subR[17];\n\ttl = subL[15] ^ (subR[15] & ~subR[17]);\n\tdw = tl & subL[17]; /* FLinv(kl4) */\n\ttr = subR[15] ^ rol32(dw, 1);\n\tSUBKEY_L(18) = tl ^ subL[19]; /* round 13 */\n\tSUBKEY_R(18) = tr ^ subR[19];\n\tSUBKEY_L(19) = subL[18] ^ subL[20]; /* round 14 */\n\tSUBKEY_R(19) = subR[18] ^ subR[20];\n\tSUBKEY_L(20) = subL[19] ^ subL[21]; /* round 15 */\n\tSUBKEY_R(20) = subR[19] ^ subR[21];\n\tSUBKEY_L(21) = subL[20] ^ subL[22]; /* round 16 */\n\tSUBKEY_R(21) = subR[20] ^ subR[22];\n\tSUBKEY_L(22) = subL[21] ^ subL[23]; /* round 17 */\n\tSUBKEY_R(22) = subR[21] ^ subR[23];\n\tif (max == 24) {\n\t\tSUBKEY_L(23) = subL[22];     /* round 18 */\n\t\tSUBKEY_R(23) = subR[22];\n\t\tSUBKEY_L(24) = subL[24] ^ subL[23]; /* kw3 */\n\t\tSUBKEY_R(24) = subR[24] ^ subR[23];\n\t} else {\n\t\ttl = subL[26] ^ (subR[26] & ~subR[24]);\n\t\tdw = tl & subL[24]; /* FL(kl5) */\n\t\ttr = subR[26] ^ rol32(dw, 1);\n\t\tSUBKEY_L(23) = subL[22] ^ tl; /* round 18 */\n\t\tSUBKEY_R(23) = subR[22] ^ tr;\n\t\tSUBKEY_L(24) = subL[24];     /* FL(kl5) */\n\t\tSUBKEY_R(24) = subR[24];\n\t\tSUBKEY_L(25) = subL[25];     /* FLinv(kl6) */\n\t\tSUBKEY_R(25) = subR[25];\n\t\ttl = subL[23] ^ (subR[23] & ~subR[25]);\n\t\tdw = tl & subL[25]; /* FLinv(kl6) */\n\t\ttr = subR[23] ^ rol32(dw, 1);\n\t\tSUBKEY_L(26) = tl ^ subL[27]; /* round 19 */\n\t\tSUBKEY_R(26) = tr ^ subR[27];\n\t\tSUBKEY_L(27) = subL[26] ^ subL[28]; /* round 20 */\n\t\tSUBKEY_R(27) = subR[26] ^ subR[28];\n\t\tSUBKEY_L(28) = subL[27] ^ subL[29]; /* round 21 */\n\t\tSUBKEY_R(28) = subR[27] ^ subR[29];\n\t\tSUBKEY_L(29) = subL[28] ^ subL[30]; /* round 22 */\n\t\tSUBKEY_R(29) = subR[28] ^ subR[30];\n\t\tSUBKEY_L(30) = subL[29] ^ subL[31]; /* round 23 */\n\t\tSUBKEY_R(30) = subR[29] ^ subR[31];\n\t\tSUBKEY_L(31) = subL[30];     /* round 24 */\n\t\tSUBKEY_R(31) = subR[30];\n\t\tSUBKEY_L(32) = subL[32] ^ subL[31]; /* kw3 */\n\t\tSUBKEY_R(32) = subR[32] ^ subR[31];\n\t}\n}\n\nstatic void camellia_setup128(const unsigned char *key, u32 *subkey)\n{\n\tu32 kll, klr, krl, krr;\n\tu32 il, ir, t0, t1, w0, w1;\n\tu32 subL[26];\n\tu32 subR[26];\n\n\t/**\n\t *  k == kll || klr || krl || krr (|| is concatenation)\n\t */\n\tkll = get_unaligned_be32(key);\n\tklr = get_unaligned_be32(key + 4);\n\tkrl = get_unaligned_be32(key + 8);\n\tkrr = get_unaligned_be32(key + 12);\n\n\t/* generate KL dependent subkeys */\n\t/* kw1 */\n\tsubL[0] = kll; subR[0] = klr;\n\t/* kw2 */\n\tsubL[1] = krl; subR[1] = krr;\n\t/* rotation left shift 15bit */\n\tROLDQ(kll, klr, krl, krr, w0, w1, 15);\n\t/* k3 */\n\tsubL[4] = kll; subR[4] = klr;\n\t/* k4 */\n\tsubL[5] = krl; subR[5] = krr;\n\t/* rotation left shift 15+30bit */\n\tROLDQ(kll, klr, krl, krr, w0, w1, 30);\n\t/* k7 */\n\tsubL[10] = kll; subR[10] = klr;\n\t/* k8 */\n\tsubL[11] = krl; subR[11] = krr;\n\t/* rotation left shift 15+30+15bit */\n\tROLDQ(kll, klr, krl, krr, w0, w1, 15);\n\t/* k10 */\n\tsubL[13] = krl; subR[13] = krr;\n\t/* rotation left shift 15+30+15+17 bit */\n\tROLDQ(kll, klr, krl, krr, w0, w1, 17);\n\t/* kl3 */\n\tsubL[16] = kll; subR[16] = klr;\n\t/* kl4 */\n\tsubL[17] = krl; subR[17] = krr;\n\t/* rotation left shift 15+30+15+17+17 bit */\n\tROLDQ(kll, klr, krl, krr, w0, w1, 17);\n\t/* k13 */\n\tsubL[18] = kll; subR[18] = klr;\n\t/* k14 */\n\tsubL[19] = krl; subR[19] = krr;\n\t/* rotation left shift 15+30+15+17+17+17 bit */\n\tROLDQ(kll, klr, krl, krr, w0, w1, 17);\n\t/* k17 */\n\tsubL[22] = kll; subR[22] = klr;\n\t/* k18 */\n\tsubL[23] = krl; subR[23] = krr;\n\n\t/* generate KA */\n\tkll = subL[0]; klr = subR[0];\n\tkrl = subL[1]; krr = subR[1];\n\tCAMELLIA_F(kll, klr,\n\t\t   CAMELLIA_SIGMA1L, CAMELLIA_SIGMA1R,\n\t\t   w0, w1, il, ir, t0, t1);\n\tkrl ^= w0; krr ^= w1;\n\tCAMELLIA_F(krl, krr,\n\t\t   CAMELLIA_SIGMA2L, CAMELLIA_SIGMA2R,\n\t\t   kll, klr, il, ir, t0, t1);\n\t/* current status == (kll, klr, w0, w1) */\n\tCAMELLIA_F(kll, klr,\n\t\t   CAMELLIA_SIGMA3L, CAMELLIA_SIGMA3R,\n\t\t   krl, krr, il, ir, t0, t1);\n\tkrl ^= w0; krr ^= w1;\n\tCAMELLIA_F(krl, krr,\n\t\t   CAMELLIA_SIGMA4L, CAMELLIA_SIGMA4R,\n\t\t   w0, w1, il, ir, t0, t1);\n\tkll ^= w0; klr ^= w1;\n\n\t/* generate KA dependent subkeys */\n\t/* k1, k2 */\n\tsubL[2] = kll; subR[2] = klr;\n\tsubL[3] = krl; subR[3] = krr;\n\tROLDQ(kll, klr, krl, krr, w0, w1, 15);\n\t/* k5,k6 */\n\tsubL[6] = kll; subR[6] = klr;\n\tsubL[7] = krl; subR[7] = krr;\n\tROLDQ(kll, klr, krl, krr, w0, w1, 15);\n\t/* kl1, kl2 */\n\tsubL[8] = kll; subR[8] = klr;\n\tsubL[9] = krl; subR[9] = krr;\n\tROLDQ(kll, klr, krl, krr, w0, w1, 15);\n\t/* k9 */\n\tsubL[12] = kll; subR[12] = klr;\n\tROLDQ(kll, klr, krl, krr, w0, w1, 15);\n\t/* k11, k12 */\n\tsubL[14] = kll; subR[14] = klr;\n\tsubL[15] = krl; subR[15] = krr;\n\tROLDQo32(kll, klr, krl, krr, w0, w1, 34);\n\t/* k15, k16 */\n\tsubL[20] = kll; subR[20] = klr;\n\tsubL[21] = krl; subR[21] = krr;\n\tROLDQ(kll, klr, krl, krr, w0, w1, 17);\n\t/* kw3, kw4 */\n\tsubL[24] = kll; subR[24] = klr;\n\tsubL[25] = krl; subR[25] = krr;\n\n\tcamellia_setup_tail(subkey, subL, subR, 24);\n}\n\nstatic void camellia_setup256(const unsigned char *key, u32 *subkey)\n{\n\tu32 kll, klr, krl, krr;        /* left half of key */\n\tu32 krll, krlr, krrl, krrr;    /* right half of key */\n\tu32 il, ir, t0, t1, w0, w1;    /* temporary variables */\n\tu32 subL[34];\n\tu32 subR[34];\n\n\t/**\n\t *  key = (kll || klr || krl || krr || krll || krlr || krrl || krrr)\n\t *  (|| is concatenation)\n\t */\n\tkll = get_unaligned_be32(key);\n\tklr = get_unaligned_be32(key + 4);\n\tkrl = get_unaligned_be32(key + 8);\n\tkrr = get_unaligned_be32(key + 12);\n\tkrll = get_unaligned_be32(key + 16);\n\tkrlr = get_unaligned_be32(key + 20);\n\tkrrl = get_unaligned_be32(key + 24);\n\tkrrr = get_unaligned_be32(key + 28);\n\n\t/* generate KL dependent subkeys */\n\t/* kw1 */\n\tsubL[0] = kll; subR[0] = klr;\n\t/* kw2 */\n\tsubL[1] = krl; subR[1] = krr;\n\tROLDQo32(kll, klr, krl, krr, w0, w1, 45);\n\t/* k9 */\n\tsubL[12] = kll; subR[12] = klr;\n\t/* k10 */\n\tsubL[13] = krl; subR[13] = krr;\n\tROLDQ(kll, klr, krl, krr, w0, w1, 15);\n\t/* kl3 */\n\tsubL[16] = kll; subR[16] = klr;\n\t/* kl4 */\n\tsubL[17] = krl; subR[17] = krr;\n\tROLDQ(kll, klr, krl, krr, w0, w1, 17);\n\t/* k17 */\n\tsubL[22] = kll; subR[22] = klr;\n\t/* k18 */\n\tsubL[23] = krl; subR[23] = krr;\n\tROLDQo32(kll, klr, krl, krr, w0, w1, 34);\n\t/* k23 */\n\tsubL[30] = kll; subR[30] = klr;\n\t/* k24 */\n\tsubL[31] = krl; subR[31] = krr;\n\n\t/* generate KR dependent subkeys */\n\tROLDQ(krll, krlr, krrl, krrr, w0, w1, 15);\n\t/* k3 */\n\tsubL[4] = krll; subR[4] = krlr;\n\t/* k4 */\n\tsubL[5] = krrl; subR[5] = krrr;\n\tROLDQ(krll, krlr, krrl, krrr, w0, w1, 15);\n\t/* kl1 */\n\tsubL[8] = krll; subR[8] = krlr;\n\t/* kl2 */\n\tsubL[9] = krrl; subR[9] = krrr;\n\tROLDQ(krll, krlr, krrl, krrr, w0, w1, 30);\n\t/* k13 */\n\tsubL[18] = krll; subR[18] = krlr;\n\t/* k14 */\n\tsubL[19] = krrl; subR[19] = krrr;\n\tROLDQo32(krll, krlr, krrl, krrr, w0, w1, 34);\n\t/* k19 */\n\tsubL[26] = krll; subR[26] = krlr;\n\t/* k20 */\n\tsubL[27] = krrl; subR[27] = krrr;\n\tROLDQo32(krll, krlr, krrl, krrr, w0, w1, 34);\n\n\t/* generate KA */\n\tkll = subL[0] ^ krll; klr = subR[0] ^ krlr;\n\tkrl = subL[1] ^ krrl; krr = subR[1] ^ krrr;\n\tCAMELLIA_F(kll, klr,\n\t\t   CAMELLIA_SIGMA1L, CAMELLIA_SIGMA1R,\n\t\t   w0, w1, il, ir, t0, t1);\n\tkrl ^= w0; krr ^= w1;\n\tCAMELLIA_F(krl, krr,\n\t\t   CAMELLIA_SIGMA2L, CAMELLIA_SIGMA2R,\n\t\t   kll, klr, il, ir, t0, t1);\n\tkll ^= krll; klr ^= krlr;\n\tCAMELLIA_F(kll, klr,\n\t\t   CAMELLIA_SIGMA3L, CAMELLIA_SIGMA3R,\n\t\t   krl, krr, il, ir, t0, t1);\n\tkrl ^= w0 ^ krrl; krr ^= w1 ^ krrr;\n\tCAMELLIA_F(krl, krr,\n\t\t   CAMELLIA_SIGMA4L, CAMELLIA_SIGMA4R,\n\t\t   w0, w1, il, ir, t0, t1);\n\tkll ^= w0; klr ^= w1;\n\n\t/* generate KB */\n\tkrll ^= kll; krlr ^= klr;\n\tkrrl ^= krl; krrr ^= krr;\n\tCAMELLIA_F(krll, krlr,\n\t\t   CAMELLIA_SIGMA5L, CAMELLIA_SIGMA5R,\n\t\t   w0, w1, il, ir, t0, t1);\n\tkrrl ^= w0; krrr ^= w1;\n\tCAMELLIA_F(krrl, krrr,\n\t\t   CAMELLIA_SIGMA6L, CAMELLIA_SIGMA6R,\n\t\t   w0, w1, il, ir, t0, t1);\n\tkrll ^= w0; krlr ^= w1;\n\n\t/* generate KA dependent subkeys */\n\tROLDQ(kll, klr, krl, krr, w0, w1, 15);\n\t/* k5 */\n\tsubL[6] = kll; subR[6] = klr;\n\t/* k6 */\n\tsubL[7] = krl; subR[7] = krr;\n\tROLDQ(kll, klr, krl, krr, w0, w1, 30);\n\t/* k11 */\n\tsubL[14] = kll; subR[14] = klr;\n\t/* k12 */\n\tsubL[15] = krl; subR[15] = krr;\n\t/* rotation left shift 32bit */\n\t/* kl5 */\n\tsubL[24] = klr; subR[24] = krl;\n\t/* kl6 */\n\tsubL[25] = krr; subR[25] = kll;\n\t/* rotation left shift 49 from k11,k12 -> k21,k22 */\n\tROLDQo32(kll, klr, krl, krr, w0, w1, 49);\n\t/* k21 */\n\tsubL[28] = kll; subR[28] = klr;\n\t/* k22 */\n\tsubL[29] = krl; subR[29] = krr;\n\n\t/* generate KB dependent subkeys */\n\t/* k1 */\n\tsubL[2] = krll; subR[2] = krlr;\n\t/* k2 */\n\tsubL[3] = krrl; subR[3] = krrr;\n\tROLDQ(krll, krlr, krrl, krrr, w0, w1, 30);\n\t/* k7 */\n\tsubL[10] = krll; subR[10] = krlr;\n\t/* k8 */\n\tsubL[11] = krrl; subR[11] = krrr;\n\tROLDQ(krll, krlr, krrl, krrr, w0, w1, 30);\n\t/* k15 */\n\tsubL[20] = krll; subR[20] = krlr;\n\t/* k16 */\n\tsubL[21] = krrl; subR[21] = krrr;\n\tROLDQo32(krll, krlr, krrl, krrr, w0, w1, 51);\n\t/* kw3 */\n\tsubL[32] = krll; subR[32] = krlr;\n\t/* kw4 */\n\tsubL[33] = krrl; subR[33] = krrr;\n\n\tcamellia_setup_tail(subkey, subL, subR, 32);\n}\n\nstatic void camellia_setup192(const unsigned char *key, u32 *subkey)\n{\n\tunsigned char kk[32];\n\tu32 krll, krlr, krrl, krrr;\n\n\tmemcpy(kk, key, 24);\n\tmemcpy((unsigned char *)&krll, key+16, 4);\n\tmemcpy((unsigned char *)&krlr, key+20, 4);\n\tkrrl = ~krll;\n\tkrrr = ~krlr;\n\tmemcpy(kk+24, (unsigned char *)&krrl, 4);\n\tmemcpy(kk+28, (unsigned char *)&krrr, 4);\n\tcamellia_setup256(kk, subkey);\n}\n\n\n/*\n * Encrypt/decrypt\n */\n#define CAMELLIA_FLS(ll, lr, rl, rr, kll, klr, krl, krr, t0, t1, t2, t3) ({ \\\n\tt0 = kll;\t\t\t\t\t\t\t\\\n\tt2 = krr;\t\t\t\t\t\t\t\\\n\tt0 &= ll;\t\t\t\t\t\t\t\\\n\tt2 |= rr;\t\t\t\t\t\t\t\\\n\trl ^= t2;\t\t\t\t\t\t\t\\\n\tlr ^= rol32(t0, 1);\t\t\t\t\t\t\\\n\tt3 = krl;\t\t\t\t\t\t\t\\\n\tt1 = klr;\t\t\t\t\t\t\t\\\n\tt3 &= rl;\t\t\t\t\t\t\t\\\n\tt1 |= lr;\t\t\t\t\t\t\t\\\n\tll ^= t1;\t\t\t\t\t\t\t\\\n\trr ^= rol32(t3, 1);\t\t\t\t\t\t\\\n})\n\n#define CAMELLIA_ROUNDSM(xl, xr, kl, kr, yl, yr, il, ir) ({\t\t\\\n\tyl ^= kl;\t\t\t\t\t\t\t\\\n\tyr ^= kr;\t\t\t\t\t\t\t\\\n\tir =  camellia_sp1110[(u8)xr];\t\t\t\t\t\\\n\til =  camellia_sp1110[(u8)(xl >> 24)];\t\t\t\t\\\n\tir ^= camellia_sp0222[(u8)(xr >> 24)];\t\t\t\t\\\n\til ^= camellia_sp0222[(u8)(xl >> 16)];\t\t\t\t\\\n\tir ^= camellia_sp3033[(u8)(xr >> 16)];\t\t\t\t\\\n\til ^= camellia_sp3033[(u8)(xl >> 8)];\t\t\t\t\\\n\tir ^= camellia_sp4404[(u8)(xr >> 8)];\t\t\t\t\\\n\til ^= camellia_sp4404[(u8)xl];\t\t\t\t\t\\\n\tir ^= il;\t\t\t\t\t\t\t\\\n\tyl ^= ir;\t\t\t\t\t\t\t\\\n\tyr ^= ror32(il, 8) ^ ir;\t\t\t\t\t\\\n})\n\n/* max = 24: 128bit encrypt, max = 32: 256bit encrypt */\nstatic void camellia_do_encrypt(const u32 *subkey, u32 *io, unsigned max)\n{\n\tu32 il, ir, t0, t1;            /* temporary variables */\n\n\t/* pre whitening but absorb kw2 */\n\tio[0] ^= SUBKEY_L(0);\n\tio[1] ^= SUBKEY_R(0);\n\n\t/* main iteration */\n#define ROUNDS(i) ({ \\\n\tCAMELLIA_ROUNDSM(io[0], io[1], \\\n\t\t\t SUBKEY_L(i + 2), SUBKEY_R(i + 2), \\\n\t\t\t io[2], io[3], il, ir); \\\n\tCAMELLIA_ROUNDSM(io[2], io[3], \\\n\t\t\t SUBKEY_L(i + 3), SUBKEY_R(i + 3), \\\n\t\t\t io[0], io[1], il, ir); \\\n\tCAMELLIA_ROUNDSM(io[0], io[1], \\\n\t\t\t SUBKEY_L(i + 4), SUBKEY_R(i + 4), \\\n\t\t\t io[2], io[3], il, ir); \\\n\tCAMELLIA_ROUNDSM(io[2], io[3], \\\n\t\t\t SUBKEY_L(i + 5), SUBKEY_R(i + 5), \\\n\t\t\t io[0], io[1], il, ir); \\\n\tCAMELLIA_ROUNDSM(io[0], io[1], \\\n\t\t\t SUBKEY_L(i + 6), SUBKEY_R(i + 6), \\\n\t\t\t io[2], io[3], il, ir); \\\n\tCAMELLIA_ROUNDSM(io[2], io[3], \\\n\t\t\t SUBKEY_L(i + 7), SUBKEY_R(i + 7), \\\n\t\t\t io[0], io[1], il, ir); \\\n})\n#define FLS(i) ({ \\\n\tCAMELLIA_FLS(io[0], io[1], io[2], io[3], \\\n\t\t     SUBKEY_L(i + 0), SUBKEY_R(i + 0), \\\n\t\t     SUBKEY_L(i + 1), SUBKEY_R(i + 1), \\\n\t\t     t0, t1, il, ir); \\\n})\n\n\tROUNDS(0);\n\tFLS(8);\n\tROUNDS(8);\n\tFLS(16);\n\tROUNDS(16);\n\tif (max == 32) {\n\t\tFLS(24);\n\t\tROUNDS(24);\n\t}\n\n#undef ROUNDS\n#undef FLS\n\n\t/* post whitening but kw4 */\n\tio[2] ^= SUBKEY_L(max);\n\tio[3] ^= SUBKEY_R(max);\n\t/* NB: io[0],[1] should be swapped with [2],[3] by caller! */\n}\n\nstatic void camellia_do_decrypt(const u32 *subkey, u32 *io, unsigned i)\n{\n\tu32 il, ir, t0, t1;            /* temporary variables */\n\n\t/* pre whitening but absorb kw2 */\n\tio[0] ^= SUBKEY_L(i);\n\tio[1] ^= SUBKEY_R(i);\n\n\t/* main iteration */\n#define ROUNDS(i) ({ \\\n\tCAMELLIA_ROUNDSM(io[0], io[1], \\\n\t\t\t SUBKEY_L(i + 7), SUBKEY_R(i + 7), \\\n\t\t\t io[2], io[3], il, ir); \\\n\tCAMELLIA_ROUNDSM(io[2], io[3], \\\n\t\t\t SUBKEY_L(i + 6), SUBKEY_R(i + 6), \\\n\t\t\t io[0], io[1], il, ir); \\\n\tCAMELLIA_ROUNDSM(io[0], io[1], \\\n\t\t\t SUBKEY_L(i + 5), SUBKEY_R(i + 5), \\\n\t\t\t io[2], io[3], il, ir); \\\n\tCAMELLIA_ROUNDSM(io[2], io[3], \\\n\t\t\t SUBKEY_L(i + 4), SUBKEY_R(i + 4), \\\n\t\t\t io[0], io[1], il, ir); \\\n\tCAMELLIA_ROUNDSM(io[0], io[1], \\\n\t\t\t SUBKEY_L(i + 3), SUBKEY_R(i + 3), \\\n\t\t\t io[2], io[3], il, ir); \\\n\tCAMELLIA_ROUNDSM(io[2], io[3], \\\n\t\t\t SUBKEY_L(i + 2), SUBKEY_R(i + 2), \\\n\t\t\t io[0], io[1], il, ir); \\\n})\n#define FLS(i) ({ \\\n\tCAMELLIA_FLS(io[0], io[1], io[2], io[3], \\\n\t\t     SUBKEY_L(i + 1), SUBKEY_R(i + 1), \\\n\t\t     SUBKEY_L(i + 0), SUBKEY_R(i + 0), \\\n\t\t     t0, t1, il, ir); \\\n})\n\n\tif (i == 32) {\n\t\tROUNDS(24);\n\t\tFLS(24);\n\t}\n\tROUNDS(16);\n\tFLS(16);\n\tROUNDS(8);\n\tFLS(8);\n\tROUNDS(0);\n\n#undef ROUNDS\n#undef FLS\n\n\t/* post whitening but kw4 */\n\tio[2] ^= SUBKEY_L(0);\n\tio[3] ^= SUBKEY_R(0);\n\t/* NB: 0,1 should be swapped with 2,3 by caller! */\n}\n\n\nstruct camellia_ctx {\n\tint key_length;\n\tu32 key_table[CAMELLIA_TABLE_BYTE_LEN / sizeof(u32)];\n};\n\nstatic int\ncamellia_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t unsigned int key_len)\n{\n\tstruct camellia_ctx *cctx = crypto_tfm_ctx(tfm);\n\tconst unsigned char *key = (const unsigned char *)in_key;\n\tu32 *flags = &tfm->crt_flags;\n\n\tif (key_len != 16 && key_len != 24 && key_len != 32) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\tcctx->key_length = key_len;\n\n\tswitch (key_len) {\n\tcase 16:\n\t\tcamellia_setup128(key, cctx->key_table);\n\t\tbreak;\n\tcase 24:\n\t\tcamellia_setup192(key, cctx->key_table);\n\t\tbreak;\n\tcase 32:\n\t\tcamellia_setup256(key, cctx->key_table);\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nstatic void camellia_encrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tconst struct camellia_ctx *cctx = crypto_tfm_ctx(tfm);\n\tconst __be32 *src = (const __be32 *)in;\n\t__be32 *dst = (__be32 *)out;\n\tunsigned int max;\n\n\tu32 tmp[4];\n\n\ttmp[0] = be32_to_cpu(src[0]);\n\ttmp[1] = be32_to_cpu(src[1]);\n\ttmp[2] = be32_to_cpu(src[2]);\n\ttmp[3] = be32_to_cpu(src[3]);\n\n\tif (cctx->key_length == 16)\n\t\tmax = 24;\n\telse\n\t\tmax = 32; /* for key lengths of 24 and 32 */\n\n\tcamellia_do_encrypt(cctx->key_table, tmp, max);\n\n\t/* do_encrypt returns 0,1 swapped with 2,3 */\n\tdst[0] = cpu_to_be32(tmp[2]);\n\tdst[1] = cpu_to_be32(tmp[3]);\n\tdst[2] = cpu_to_be32(tmp[0]);\n\tdst[3] = cpu_to_be32(tmp[1]);\n}\n\nstatic void camellia_decrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tconst struct camellia_ctx *cctx = crypto_tfm_ctx(tfm);\n\tconst __be32 *src = (const __be32 *)in;\n\t__be32 *dst = (__be32 *)out;\n\tunsigned int max;\n\n\tu32 tmp[4];\n\n\ttmp[0] = be32_to_cpu(src[0]);\n\ttmp[1] = be32_to_cpu(src[1]);\n\ttmp[2] = be32_to_cpu(src[2]);\n\ttmp[3] = be32_to_cpu(src[3]);\n\n\tif (cctx->key_length == 16)\n\t\tmax = 24;\n\telse\n\t\tmax = 32; /* for key lengths of 24 and 32 */\n\n\tcamellia_do_decrypt(cctx->key_table, tmp, max);\n\n\t/* do_decrypt returns 0,1 swapped with 2,3 */\n\tdst[0] = cpu_to_be32(tmp[2]);\n\tdst[1] = cpu_to_be32(tmp[3]);\n\tdst[2] = cpu_to_be32(tmp[0]);\n\tdst[3] = cpu_to_be32(tmp[1]);\n}\n\nstatic struct crypto_alg camellia_alg = {\n\t.cra_name\t\t=\t\"camellia\",\n\t.cra_driver_name\t=\t\"camellia-generic\",\n\t.cra_priority\t\t=\t100,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tCAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct camellia_ctx),\n\t.cra_alignmask\t\t=\t3,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.cipher = {\n\t\t\t.cia_min_keysize\t=\tCAMELLIA_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t=\tCAMELLIA_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t=\tcamellia_set_key,\n\t\t\t.cia_encrypt\t\t=\tcamellia_encrypt,\n\t\t\t.cia_decrypt\t\t=\tcamellia_decrypt\n\t\t}\n\t}\n};\n\nstatic int __init camellia_init(void)\n{\n\treturn crypto_register_alg(&camellia_alg);\n}\n\nstatic void __exit camellia_fini(void)\n{\n\tcrypto_unregister_alg(&camellia_alg);\n}\n\nmodule_init(camellia_init);\nmodule_exit(camellia_fini);\n\nMODULE_DESCRIPTION(\"Camellia Cipher Algorithm\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS(\"camellia\");\n", "/* Kernel cryptographic api.\n* cast5.c - Cast5 cipher algorithm (rfc2144).\n*\n* Derived from GnuPG implementation of cast5.\n*\n* Major Changes.\n*\tComplete conformance to rfc2144.\n*\tSupports key size from 40 to 128 bits.\n*\n* Copyright (C) 1998, 1999, 2000, 2001 Free Software Foundation, Inc.\n* Copyright (C) 2003 Kartikey Mahendra Bhatt <kartik_me@hotmail.com>.\n*\n* This program is free software; you can redistribute it and/or modify it\n* under the terms of GNU General Public License as published by the Free\n* Software Foundation; either version 2 of the License, or (at your option)\n* any later version.\n*\n* You should have received a copy of the GNU General Public License\n* along with this program; if not, write to the Free Software\n* Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA\n*/\n\n\n#include <asm/byteorder.h>\n#include <linux/init.h>\n#include <linux/crypto.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <crypto/cast5.h>\n\nstatic const u32 s5[256] = {\n\t0x7ec90c04, 0x2c6e74b9, 0x9b0e66df, 0xa6337911, 0xb86a7fff,\n\t0x1dd358f5, 0x44dd9d44, 0x1731167f,\n\t0x08fbf1fa, 0xe7f511cc, 0xd2051b00, 0x735aba00, 0x2ab722d8,\n\t0x386381cb, 0xacf6243a, 0x69befd7a,\n\t0xe6a2e77f, 0xf0c720cd, 0xc4494816, 0xccf5c180, 0x38851640,\n\t0x15b0a848, 0xe68b18cb, 0x4caadeff,\n\t0x5f480a01, 0x0412b2aa, 0x259814fc, 0x41d0efe2, 0x4e40b48d,\n\t0x248eb6fb, 0x8dba1cfe, 0x41a99b02,\n\t0x1a550a04, 0xba8f65cb, 0x7251f4e7, 0x95a51725, 0xc106ecd7,\n\t0x97a5980a, 0xc539b9aa, 0x4d79fe6a,\n\t0xf2f3f763, 0x68af8040, 0xed0c9e56, 0x11b4958b, 0xe1eb5a88,\n\t0x8709e6b0, 0xd7e07156, 0x4e29fea7,\n\t0x6366e52d, 0x02d1c000, 0xc4ac8e05, 0x9377f571, 0x0c05372a,\n\t0x578535f2, 0x2261be02, 0xd642a0c9,\n\t0xdf13a280, 0x74b55bd2, 0x682199c0, 0xd421e5ec, 0x53fb3ce8,\n\t0xc8adedb3, 0x28a87fc9, 0x3d959981,\n\t0x5c1ff900, 0xfe38d399, 0x0c4eff0b, 0x062407ea, 0xaa2f4fb1,\n\t0x4fb96976, 0x90c79505, 0xb0a8a774,\n\t0xef55a1ff, 0xe59ca2c2, 0xa6b62d27, 0xe66a4263, 0xdf65001f,\n\t0x0ec50966, 0xdfdd55bc, 0x29de0655,\n\t0x911e739a, 0x17af8975, 0x32c7911c, 0x89f89468, 0x0d01e980,\n\t0x524755f4, 0x03b63cc9, 0x0cc844b2,\n\t0xbcf3f0aa, 0x87ac36e9, 0xe53a7426, 0x01b3d82b, 0x1a9e7449,\n\t0x64ee2d7e, 0xcddbb1da, 0x01c94910,\n\t0xb868bf80, 0x0d26f3fd, 0x9342ede7, 0x04a5c284, 0x636737b6,\n\t0x50f5b616, 0xf24766e3, 0x8eca36c1,\n\t0x136e05db, 0xfef18391, 0xfb887a37, 0xd6e7f7d4, 0xc7fb7dc9,\n\t0x3063fcdf, 0xb6f589de, 0xec2941da,\n\t0x26e46695, 0xb7566419, 0xf654efc5, 0xd08d58b7, 0x48925401,\n\t0xc1bacb7f, 0xe5ff550f, 0xb6083049,\n\t0x5bb5d0e8, 0x87d72e5a, 0xab6a6ee1, 0x223a66ce, 0xc62bf3cd,\n\t0x9e0885f9, 0x68cb3e47, 0x086c010f,\n\t0xa21de820, 0xd18b69de, 0xf3f65777, 0xfa02c3f6, 0x407edac3,\n\t0xcbb3d550, 0x1793084d, 0xb0d70eba,\n\t0x0ab378d5, 0xd951fb0c, 0xded7da56, 0x4124bbe4, 0x94ca0b56,\n\t0x0f5755d1, 0xe0e1e56e, 0x6184b5be,\n\t0x580a249f, 0x94f74bc0, 0xe327888e, 0x9f7b5561, 0xc3dc0280,\n\t0x05687715, 0x646c6bd7, 0x44904db3,\n\t0x66b4f0a3, 0xc0f1648a, 0x697ed5af, 0x49e92ff6, 0x309e374f,\n\t0x2cb6356a, 0x85808573, 0x4991f840,\n\t0x76f0ae02, 0x083be84d, 0x28421c9a, 0x44489406, 0x736e4cb8,\n\t0xc1092910, 0x8bc95fc6, 0x7d869cf4,\n\t0x134f616f, 0x2e77118d, 0xb31b2be1, 0xaa90b472, 0x3ca5d717,\n\t0x7d161bba, 0x9cad9010, 0xaf462ba2,\n\t0x9fe459d2, 0x45d34559, 0xd9f2da13, 0xdbc65487, 0xf3e4f94e,\n\t0x176d486f, 0x097c13ea, 0x631da5c7,\n\t0x445f7382, 0x175683f4, 0xcdc66a97, 0x70be0288, 0xb3cdcf72,\n\t0x6e5dd2f3, 0x20936079, 0x459b80a5,\n\t0xbe60e2db, 0xa9c23101, 0xeba5315c, 0x224e42f2, 0x1c5c1572,\n\t0xf6721b2c, 0x1ad2fff3, 0x8c25404e,\n\t0x324ed72f, 0x4067b7fd, 0x0523138e, 0x5ca3bc78, 0xdc0fd66e,\n\t0x75922283, 0x784d6b17, 0x58ebb16e,\n\t0x44094f85, 0x3f481d87, 0xfcfeae7b, 0x77b5ff76, 0x8c2302bf,\n\t0xaaf47556, 0x5f46b02a, 0x2b092801,\n\t0x3d38f5f7, 0x0ca81f36, 0x52af4a8a, 0x66d5e7c0, 0xdf3b0874,\n\t0x95055110, 0x1b5ad7a8, 0xf61ed5ad,\n\t0x6cf6e479, 0x20758184, 0xd0cefa65, 0x88f7be58, 0x4a046826,\n\t0x0ff6f8f3, 0xa09c7f70, 0x5346aba0,\n\t0x5ce96c28, 0xe176eda3, 0x6bac307f, 0x376829d2, 0x85360fa9,\n\t0x17e3fe2a, 0x24b79767, 0xf5a96b20,\n\t0xd6cd2595, 0x68ff1ebf, 0x7555442c, 0xf19f06be, 0xf9e0659a,\n\t0xeeb9491d, 0x34010718, 0xbb30cab8,\n\t0xe822fe15, 0x88570983, 0x750e6249, 0xda627e55, 0x5e76ffa8,\n\t0xb1534546, 0x6d47de08, 0xefe9e7d4\n};\nstatic const u32 s6[256] = {\n\t0xf6fa8f9d, 0x2cac6ce1, 0x4ca34867, 0xe2337f7c, 0x95db08e7,\n\t0x016843b4, 0xeced5cbc, 0x325553ac,\n\t0xbf9f0960, 0xdfa1e2ed, 0x83f0579d, 0x63ed86b9, 0x1ab6a6b8,\n\t0xde5ebe39, 0xf38ff732, 0x8989b138,\n\t0x33f14961, 0xc01937bd, 0xf506c6da, 0xe4625e7e, 0xa308ea99,\n\t0x4e23e33c, 0x79cbd7cc, 0x48a14367,\n\t0xa3149619, 0xfec94bd5, 0xa114174a, 0xeaa01866, 0xa084db2d,\n\t0x09a8486f, 0xa888614a, 0x2900af98,\n\t0x01665991, 0xe1992863, 0xc8f30c60, 0x2e78ef3c, 0xd0d51932,\n\t0xcf0fec14, 0xf7ca07d2, 0xd0a82072,\n\t0xfd41197e, 0x9305a6b0, 0xe86be3da, 0x74bed3cd, 0x372da53c,\n\t0x4c7f4448, 0xdab5d440, 0x6dba0ec3,\n\t0x083919a7, 0x9fbaeed9, 0x49dbcfb0, 0x4e670c53, 0x5c3d9c01,\n\t0x64bdb941, 0x2c0e636a, 0xba7dd9cd,\n\t0xea6f7388, 0xe70bc762, 0x35f29adb, 0x5c4cdd8d, 0xf0d48d8c,\n\t0xb88153e2, 0x08a19866, 0x1ae2eac8,\n\t0x284caf89, 0xaa928223, 0x9334be53, 0x3b3a21bf, 0x16434be3,\n\t0x9aea3906, 0xefe8c36e, 0xf890cdd9,\n\t0x80226dae, 0xc340a4a3, 0xdf7e9c09, 0xa694a807, 0x5b7c5ecc,\n\t0x221db3a6, 0x9a69a02f, 0x68818a54,\n\t0xceb2296f, 0x53c0843a, 0xfe893655, 0x25bfe68a, 0xb4628abc,\n\t0xcf222ebf, 0x25ac6f48, 0xa9a99387,\n\t0x53bddb65, 0xe76ffbe7, 0xe967fd78, 0x0ba93563, 0x8e342bc1,\n\t0xe8a11be9, 0x4980740d, 0xc8087dfc,\n\t0x8de4bf99, 0xa11101a0, 0x7fd37975, 0xda5a26c0, 0xe81f994f,\n\t0x9528cd89, 0xfd339fed, 0xb87834bf,\n\t0x5f04456d, 0x22258698, 0xc9c4c83b, 0x2dc156be, 0x4f628daa,\n\t0x57f55ec5, 0xe2220abe, 0xd2916ebf,\n\t0x4ec75b95, 0x24f2c3c0, 0x42d15d99, 0xcd0d7fa0, 0x7b6e27ff,\n\t0xa8dc8af0, 0x7345c106, 0xf41e232f,\n\t0x35162386, 0xe6ea8926, 0x3333b094, 0x157ec6f2, 0x372b74af,\n\t0x692573e4, 0xe9a9d848, 0xf3160289,\n\t0x3a62ef1d, 0xa787e238, 0xf3a5f676, 0x74364853, 0x20951063,\n\t0x4576698d, 0xb6fad407, 0x592af950,\n\t0x36f73523, 0x4cfb6e87, 0x7da4cec0, 0x6c152daa, 0xcb0396a8,\n\t0xc50dfe5d, 0xfcd707ab, 0x0921c42f,\n\t0x89dff0bb, 0x5fe2be78, 0x448f4f33, 0x754613c9, 0x2b05d08d,\n\t0x48b9d585, 0xdc049441, 0xc8098f9b,\n\t0x7dede786, 0xc39a3373, 0x42410005, 0x6a091751, 0x0ef3c8a6,\n\t0x890072d6, 0x28207682, 0xa9a9f7be,\n\t0xbf32679d, 0xd45b5b75, 0xb353fd00, 0xcbb0e358, 0x830f220a,\n\t0x1f8fb214, 0xd372cf08, 0xcc3c4a13,\n\t0x8cf63166, 0x061c87be, 0x88c98f88, 0x6062e397, 0x47cf8e7a,\n\t0xb6c85283, 0x3cc2acfb, 0x3fc06976,\n\t0x4e8f0252, 0x64d8314d, 0xda3870e3, 0x1e665459, 0xc10908f0,\n\t0x513021a5, 0x6c5b68b7, 0x822f8aa0,\n\t0x3007cd3e, 0x74719eef, 0xdc872681, 0x073340d4, 0x7e432fd9,\n\t0x0c5ec241, 0x8809286c, 0xf592d891,\n\t0x08a930f6, 0x957ef305, 0xb7fbffbd, 0xc266e96f, 0x6fe4ac98,\n\t0xb173ecc0, 0xbc60b42a, 0x953498da,\n\t0xfba1ae12, 0x2d4bd736, 0x0f25faab, 0xa4f3fceb, 0xe2969123,\n\t0x257f0c3d, 0x9348af49, 0x361400bc,\n\t0xe8816f4a, 0x3814f200, 0xa3f94043, 0x9c7a54c2, 0xbc704f57,\n\t0xda41e7f9, 0xc25ad33a, 0x54f4a084,\n\t0xb17f5505, 0x59357cbe, 0xedbd15c8, 0x7f97c5ab, 0xba5ac7b5,\n\t0xb6f6deaf, 0x3a479c3a, 0x5302da25,\n\t0x653d7e6a, 0x54268d49, 0x51a477ea, 0x5017d55b, 0xd7d25d88,\n\t0x44136c76, 0x0404a8c8, 0xb8e5a121,\n\t0xb81a928a, 0x60ed5869, 0x97c55b96, 0xeaec991b, 0x29935913,\n\t0x01fdb7f1, 0x088e8dfa, 0x9ab6f6f5,\n\t0x3b4cbf9f, 0x4a5de3ab, 0xe6051d35, 0xa0e1d855, 0xd36b4cf1,\n\t0xf544edeb, 0xb0e93524, 0xbebb8fbd,\n\t0xa2d762cf, 0x49c92f54, 0x38b5f331, 0x7128a454, 0x48392905,\n\t0xa65b1db8, 0x851c97bd, 0xd675cf2f\n};\nstatic const u32 s7[256] = {\n\t0x85e04019, 0x332bf567, 0x662dbfff, 0xcfc65693, 0x2a8d7f6f,\n\t0xab9bc912, 0xde6008a1, 0x2028da1f,\n\t0x0227bce7, 0x4d642916, 0x18fac300, 0x50f18b82, 0x2cb2cb11,\n\t0xb232e75c, 0x4b3695f2, 0xb28707de,\n\t0xa05fbcf6, 0xcd4181e9, 0xe150210c, 0xe24ef1bd, 0xb168c381,\n\t0xfde4e789, 0x5c79b0d8, 0x1e8bfd43,\n\t0x4d495001, 0x38be4341, 0x913cee1d, 0x92a79c3f, 0x089766be,\n\t0xbaeeadf4, 0x1286becf, 0xb6eacb19,\n\t0x2660c200, 0x7565bde4, 0x64241f7a, 0x8248dca9, 0xc3b3ad66,\n\t0x28136086, 0x0bd8dfa8, 0x356d1cf2,\n\t0x107789be, 0xb3b2e9ce, 0x0502aa8f, 0x0bc0351e, 0x166bf52a,\n\t0xeb12ff82, 0xe3486911, 0xd34d7516,\n\t0x4e7b3aff, 0x5f43671b, 0x9cf6e037, 0x4981ac83, 0x334266ce,\n\t0x8c9341b7, 0xd0d854c0, 0xcb3a6c88,\n\t0x47bc2829, 0x4725ba37, 0xa66ad22b, 0x7ad61f1e, 0x0c5cbafa,\n\t0x4437f107, 0xb6e79962, 0x42d2d816,\n\t0x0a961288, 0xe1a5c06e, 0x13749e67, 0x72fc081a, 0xb1d139f7,\n\t0xf9583745, 0xcf19df58, 0xbec3f756,\n\t0xc06eba30, 0x07211b24, 0x45c28829, 0xc95e317f, 0xbc8ec511,\n\t0x38bc46e9, 0xc6e6fa14, 0xbae8584a,\n\t0xad4ebc46, 0x468f508b, 0x7829435f, 0xf124183b, 0x821dba9f,\n\t0xaff60ff4, 0xea2c4e6d, 0x16e39264,\n\t0x92544a8b, 0x009b4fc3, 0xaba68ced, 0x9ac96f78, 0x06a5b79a,\n\t0xb2856e6e, 0x1aec3ca9, 0xbe838688,\n\t0x0e0804e9, 0x55f1be56, 0xe7e5363b, 0xb3a1f25d, 0xf7debb85,\n\t0x61fe033c, 0x16746233, 0x3c034c28,\n\t0xda6d0c74, 0x79aac56c, 0x3ce4e1ad, 0x51f0c802, 0x98f8f35a,\n\t0x1626a49f, 0xeed82b29, 0x1d382fe3,\n\t0x0c4fb99a, 0xbb325778, 0x3ec6d97b, 0x6e77a6a9, 0xcb658b5c,\n\t0xd45230c7, 0x2bd1408b, 0x60c03eb7,\n\t0xb9068d78, 0xa33754f4, 0xf430c87d, 0xc8a71302, 0xb96d8c32,\n\t0xebd4e7be, 0xbe8b9d2d, 0x7979fb06,\n\t0xe7225308, 0x8b75cf77, 0x11ef8da4, 0xe083c858, 0x8d6b786f,\n\t0x5a6317a6, 0xfa5cf7a0, 0x5dda0033,\n\t0xf28ebfb0, 0xf5b9c310, 0xa0eac280, 0x08b9767a, 0xa3d9d2b0,\n\t0x79d34217, 0x021a718d, 0x9ac6336a,\n\t0x2711fd60, 0x438050e3, 0x069908a8, 0x3d7fedc4, 0x826d2bef,\n\t0x4eeb8476, 0x488dcf25, 0x36c9d566,\n\t0x28e74e41, 0xc2610aca, 0x3d49a9cf, 0xbae3b9df, 0xb65f8de6,\n\t0x92aeaf64, 0x3ac7d5e6, 0x9ea80509,\n\t0xf22b017d, 0xa4173f70, 0xdd1e16c3, 0x15e0d7f9, 0x50b1b887,\n\t0x2b9f4fd5, 0x625aba82, 0x6a017962,\n\t0x2ec01b9c, 0x15488aa9, 0xd716e740, 0x40055a2c, 0x93d29a22,\n\t0xe32dbf9a, 0x058745b9, 0x3453dc1e,\n\t0xd699296e, 0x496cff6f, 0x1c9f4986, 0xdfe2ed07, 0xb87242d1,\n\t0x19de7eae, 0x053e561a, 0x15ad6f8c,\n\t0x66626c1c, 0x7154c24c, 0xea082b2a, 0x93eb2939, 0x17dcb0f0,\n\t0x58d4f2ae, 0x9ea294fb, 0x52cf564c,\n\t0x9883fe66, 0x2ec40581, 0x763953c3, 0x01d6692e, 0xd3a0c108,\n\t0xa1e7160e, 0xe4f2dfa6, 0x693ed285,\n\t0x74904698, 0x4c2b0edd, 0x4f757656, 0x5d393378, 0xa132234f,\n\t0x3d321c5d, 0xc3f5e194, 0x4b269301,\n\t0xc79f022f, 0x3c997e7e, 0x5e4f9504, 0x3ffafbbd, 0x76f7ad0e,\n\t0x296693f4, 0x3d1fce6f, 0xc61e45be,\n\t0xd3b5ab34, 0xf72bf9b7, 0x1b0434c0, 0x4e72b567, 0x5592a33d,\n\t0xb5229301, 0xcfd2a87f, 0x60aeb767,\n\t0x1814386b, 0x30bcc33d, 0x38a0c07d, 0xfd1606f2, 0xc363519b,\n\t0x589dd390, 0x5479f8e6, 0x1cb8d647,\n\t0x97fd61a9, 0xea7759f4, 0x2d57539d, 0x569a58cf, 0xe84e63ad,\n\t0x462e1b78, 0x6580f87e, 0xf3817914,\n\t0x91da55f4, 0x40a230f3, 0xd1988f35, 0xb6e318d2, 0x3ffa50bc,\n\t0x3d40f021, 0xc3c0bdae, 0x4958c24c,\n\t0x518f36b2, 0x84b1d370, 0x0fedce83, 0x878ddada, 0xf2a279c7,\n\t0x94e01be8, 0x90716f4b, 0x954b8aa3\n};\nstatic const u32 sb8[256] = {\n\t0xe216300d, 0xbbddfffc, 0xa7ebdabd, 0x35648095, 0x7789f8b7,\n\t0xe6c1121b, 0x0e241600, 0x052ce8b5,\n\t0x11a9cfb0, 0xe5952f11, 0xece7990a, 0x9386d174, 0x2a42931c,\n\t0x76e38111, 0xb12def3a, 0x37ddddfc,\n\t0xde9adeb1, 0x0a0cc32c, 0xbe197029, 0x84a00940, 0xbb243a0f,\n\t0xb4d137cf, 0xb44e79f0, 0x049eedfd,\n\t0x0b15a15d, 0x480d3168, 0x8bbbde5a, 0x669ded42, 0xc7ece831,\n\t0x3f8f95e7, 0x72df191b, 0x7580330d,\n\t0x94074251, 0x5c7dcdfa, 0xabbe6d63, 0xaa402164, 0xb301d40a,\n\t0x02e7d1ca, 0x53571dae, 0x7a3182a2,\n\t0x12a8ddec, 0xfdaa335d, 0x176f43e8, 0x71fb46d4, 0x38129022,\n\t0xce949ad4, 0xb84769ad, 0x965bd862,\n\t0x82f3d055, 0x66fb9767, 0x15b80b4e, 0x1d5b47a0, 0x4cfde06f,\n\t0xc28ec4b8, 0x57e8726e, 0x647a78fc,\n\t0x99865d44, 0x608bd593, 0x6c200e03, 0x39dc5ff6, 0x5d0b00a3,\n\t0xae63aff2, 0x7e8bd632, 0x70108c0c,\n\t0xbbd35049, 0x2998df04, 0x980cf42a, 0x9b6df491, 0x9e7edd53,\n\t0x06918548, 0x58cb7e07, 0x3b74ef2e,\n\t0x522fffb1, 0xd24708cc, 0x1c7e27cd, 0xa4eb215b, 0x3cf1d2e2,\n\t0x19b47a38, 0x424f7618, 0x35856039,\n\t0x9d17dee7, 0x27eb35e6, 0xc9aff67b, 0x36baf5b8, 0x09c467cd,\n\t0xc18910b1, 0xe11dbf7b, 0x06cd1af8,\n\t0x7170c608, 0x2d5e3354, 0xd4de495a, 0x64c6d006, 0xbcc0c62c,\n\t0x3dd00db3, 0x708f8f34, 0x77d51b42,\n\t0x264f620f, 0x24b8d2bf, 0x15c1b79e, 0x46a52564, 0xf8d7e54e,\n\t0x3e378160, 0x7895cda5, 0x859c15a5,\n\t0xe6459788, 0xc37bc75f, 0xdb07ba0c, 0x0676a3ab, 0x7f229b1e,\n\t0x31842e7b, 0x24259fd7, 0xf8bef472,\n\t0x835ffcb8, 0x6df4c1f2, 0x96f5b195, 0xfd0af0fc, 0xb0fe134c,\n\t0xe2506d3d, 0x4f9b12ea, 0xf215f225,\n\t0xa223736f, 0x9fb4c428, 0x25d04979, 0x34c713f8, 0xc4618187,\n\t0xea7a6e98, 0x7cd16efc, 0x1436876c,\n\t0xf1544107, 0xbedeee14, 0x56e9af27, 0xa04aa441, 0x3cf7c899,\n\t0x92ecbae6, 0xdd67016d, 0x151682eb,\n\t0xa842eedf, 0xfdba60b4, 0xf1907b75, 0x20e3030f, 0x24d8c29e,\n\t0xe139673b, 0xefa63fb8, 0x71873054,\n\t0xb6f2cf3b, 0x9f326442, 0xcb15a4cc, 0xb01a4504, 0xf1e47d8d,\n\t0x844a1be5, 0xbae7dfdc, 0x42cbda70,\n\t0xcd7dae0a, 0x57e85b7a, 0xd53f5af6, 0x20cf4d8c, 0xcea4d428,\n\t0x79d130a4, 0x3486ebfb, 0x33d3cddc,\n\t0x77853b53, 0x37effcb5, 0xc5068778, 0xe580b3e6, 0x4e68b8f4,\n\t0xc5c8b37e, 0x0d809ea2, 0x398feb7c,\n\t0x132a4f94, 0x43b7950e, 0x2fee7d1c, 0x223613bd, 0xdd06caa2,\n\t0x37df932b, 0xc4248289, 0xacf3ebc3,\n\t0x5715f6b7, 0xef3478dd, 0xf267616f, 0xc148cbe4, 0x9052815e,\n\t0x5e410fab, 0xb48a2465, 0x2eda7fa4,\n\t0xe87b40e4, 0xe98ea084, 0x5889e9e1, 0xefd390fc, 0xdd07d35b,\n\t0xdb485694, 0x38d7e5b2, 0x57720101,\n\t0x730edebc, 0x5b643113, 0x94917e4f, 0x503c2fba, 0x646f1282,\n\t0x7523d24a, 0xe0779695, 0xf9c17a8f,\n\t0x7a5b2121, 0xd187b896, 0x29263a4d, 0xba510cdf, 0x81f47c9f,\n\t0xad1163ed, 0xea7b5965, 0x1a00726e,\n\t0x11403092, 0x00da6d77, 0x4a0cdd61, 0xad1f4603, 0x605bdfb0,\n\t0x9eedc364, 0x22ebe6a8, 0xcee7d28a,\n\t0xa0e736a0, 0x5564a6b9, 0x10853209, 0xc7eb8f37, 0x2de705ca,\n\t0x8951570f, 0xdf09822b, 0xbd691a6c,\n\t0xaa12e4f2, 0x87451c0f, 0xe0f6a27a, 0x3ada4819, 0x4cf1764f,\n\t0x0d771c2b, 0x67cdb156, 0x350d8384,\n\t0x5938fa0f, 0x42399ef3, 0x36997b07, 0x0e84093d, 0x4aa93e61,\n\t0x8360d87b, 0x1fa98b0c, 0x1149382c,\n\t0xe97625a5, 0x0614d1b7, 0x0e25244b, 0x0c768347, 0x589e8d82,\n\t0x0d2059d1, 0xa466bb1e, 0xf8da0a82,\n\t0x04f19130, 0xba6e4ec0, 0x99265164, 0x1ee7230d, 0x50b2ad80,\n\t0xeaee6801, 0x8db2a283, 0xea8bf59e\n};\n\n#define s1 cast_s1\n#define s2 cast_s2\n#define s3 cast_s3\n#define s4 cast_s4\n\n#define F1(D, m, r)  ((I = ((m) + (D))), (I = rol32(I, (r))),   \\\n\t(((s1[I >> 24] ^ s2[(I>>16)&0xff]) - s3[(I>>8)&0xff]) + s4[I&0xff]))\n#define F2(D, m, r)  ((I = ((m) ^ (D))), (I = rol32(I, (r))),   \\\n\t(((s1[I >> 24] - s2[(I>>16)&0xff]) + s3[(I>>8)&0xff]) ^ s4[I&0xff]))\n#define F3(D, m, r)  ((I = ((m) - (D))), (I = rol32(I, (r))),   \\\n\t(((s1[I >> 24] + s2[(I>>16)&0xff]) ^ s3[(I>>8)&0xff]) - s4[I&0xff]))\n\n\nvoid __cast5_encrypt(struct cast5_ctx *c, u8 *outbuf, const u8 *inbuf)\n{\n\tconst __be32 *src = (const __be32 *)inbuf;\n\t__be32 *dst = (__be32 *)outbuf;\n\tu32 l, r, t;\n\tu32 I;\t\t\t/* used by the Fx macros */\n\tu32 *Km;\n\tu8 *Kr;\n\n\tKm = c->Km;\n\tKr = c->Kr;\n\n\t/* (L0,R0) <-- (m1...m64).  (Split the plaintext into left and\n\t * right 32-bit halves L0 = m1...m32 and R0 = m33...m64.)\n\t */\n\tl = be32_to_cpu(src[0]);\n\tr = be32_to_cpu(src[1]);\n\n\t/* (16 rounds) for i from 1 to 16, compute Li and Ri as follows:\n\t *  Li = Ri-1;\n\t *  Ri = Li-1 ^ f(Ri-1,Kmi,Kri), where f is defined in Section 2.2\n\t * Rounds 1, 4, 7, 10, 13, and 16 use f function Type 1.\n\t * Rounds 2, 5, 8, 11, and 14 use f function Type 2.\n\t * Rounds 3, 6, 9, 12, and 15 use f function Type 3.\n\t */\n\n\tt = l; l = r; r = t ^ F1(r, Km[0], Kr[0]);\n\tt = l; l = r; r = t ^ F2(r, Km[1], Kr[1]);\n\tt = l; l = r; r = t ^ F3(r, Km[2], Kr[2]);\n\tt = l; l = r; r = t ^ F1(r, Km[3], Kr[3]);\n\tt = l; l = r; r = t ^ F2(r, Km[4], Kr[4]);\n\tt = l; l = r; r = t ^ F3(r, Km[5], Kr[5]);\n\tt = l; l = r; r = t ^ F1(r, Km[6], Kr[6]);\n\tt = l; l = r; r = t ^ F2(r, Km[7], Kr[7]);\n\tt = l; l = r; r = t ^ F3(r, Km[8], Kr[8]);\n\tt = l; l = r; r = t ^ F1(r, Km[9], Kr[9]);\n\tt = l; l = r; r = t ^ F2(r, Km[10], Kr[10]);\n\tt = l; l = r; r = t ^ F3(r, Km[11], Kr[11]);\n\tif (!(c->rr)) {\n\t\tt = l; l = r; r = t ^ F1(r, Km[12], Kr[12]);\n\t\tt = l; l = r; r = t ^ F2(r, Km[13], Kr[13]);\n\t\tt = l; l = r; r = t ^ F3(r, Km[14], Kr[14]);\n\t\tt = l; l = r; r = t ^ F1(r, Km[15], Kr[15]);\n\t}\n\n\t/* c1...c64 <-- (R16,L16).  (Exchange final blocks L16, R16 and\n\t *  concatenate to form the ciphertext.) */\n\tdst[0] = cpu_to_be32(r);\n\tdst[1] = cpu_to_be32(l);\n}\nEXPORT_SYMBOL_GPL(__cast5_encrypt);\n\nstatic void cast5_encrypt(struct crypto_tfm *tfm, u8 *outbuf, const u8 *inbuf)\n{\n\t__cast5_encrypt(crypto_tfm_ctx(tfm), outbuf, inbuf);\n}\n\nvoid __cast5_decrypt(struct cast5_ctx *c, u8 *outbuf, const u8 *inbuf)\n{\n\tconst __be32 *src = (const __be32 *)inbuf;\n\t__be32 *dst = (__be32 *)outbuf;\n\tu32 l, r, t;\n\tu32 I;\n\tu32 *Km;\n\tu8 *Kr;\n\n\tKm = c->Km;\n\tKr = c->Kr;\n\n\tl = be32_to_cpu(src[0]);\n\tr = be32_to_cpu(src[1]);\n\n\tif (!(c->rr)) {\n\t\tt = l; l = r; r = t ^ F1(r, Km[15], Kr[15]);\n\t\tt = l; l = r; r = t ^ F3(r, Km[14], Kr[14]);\n\t\tt = l; l = r; r = t ^ F2(r, Km[13], Kr[13]);\n\t\tt = l; l = r; r = t ^ F1(r, Km[12], Kr[12]);\n\t}\n\tt = l; l = r; r = t ^ F3(r, Km[11], Kr[11]);\n\tt = l; l = r; r = t ^ F2(r, Km[10], Kr[10]);\n\tt = l; l = r; r = t ^ F1(r, Km[9], Kr[9]);\n\tt = l; l = r; r = t ^ F3(r, Km[8], Kr[8]);\n\tt = l; l = r; r = t ^ F2(r, Km[7], Kr[7]);\n\tt = l; l = r; r = t ^ F1(r, Km[6], Kr[6]);\n\tt = l; l = r; r = t ^ F3(r, Km[5], Kr[5]);\n\tt = l; l = r; r = t ^ F2(r, Km[4], Kr[4]);\n\tt = l; l = r; r = t ^ F1(r, Km[3], Kr[3]);\n\tt = l; l = r; r = t ^ F3(r, Km[2], Kr[2]);\n\tt = l; l = r; r = t ^ F2(r, Km[1], Kr[1]);\n\tt = l; l = r; r = t ^ F1(r, Km[0], Kr[0]);\n\n\tdst[0] = cpu_to_be32(r);\n\tdst[1] = cpu_to_be32(l);\n}\nEXPORT_SYMBOL_GPL(__cast5_decrypt);\n\nstatic void cast5_decrypt(struct crypto_tfm *tfm, u8 *outbuf, const u8 *inbuf)\n{\n\t__cast5_decrypt(crypto_tfm_ctx(tfm), outbuf, inbuf);\n}\n\nstatic void key_schedule(u32 *x, u32 *z, u32 *k)\n{\n\n#define xi(i)   ((x[(i)/4] >> (8*(3-((i)%4)))) & 0xff)\n#define zi(i)   ((z[(i)/4] >> (8*(3-((i)%4)))) & 0xff)\n\n\tz[0] = x[0] ^ s5[xi(13)] ^ s6[xi(15)] ^ s7[xi(12)] ^ sb8[xi(14)] ^\n\t    s7[xi(8)];\n\tz[1] = x[2] ^ s5[zi(0)] ^ s6[zi(2)] ^ s7[zi(1)] ^ sb8[zi(3)] ^\n\t    sb8[xi(10)];\n\tz[2] = x[3] ^ s5[zi(7)] ^ s6[zi(6)] ^ s7[zi(5)] ^ sb8[zi(4)] ^\n\t    s5[xi(9)];\n\tz[3] = x[1] ^ s5[zi(10)] ^ s6[zi(9)] ^ s7[zi(11)] ^ sb8[zi(8)] ^\n\t    s6[xi(11)];\n\tk[0] = s5[zi(8)] ^ s6[zi(9)] ^ s7[zi(7)] ^ sb8[zi(6)] ^ s5[zi(2)];\n\tk[1] = s5[zi(10)] ^ s6[zi(11)] ^ s7[zi(5)] ^ sb8[zi(4)] ^\n\t    s6[zi(6)];\n\tk[2] = s5[zi(12)] ^ s6[zi(13)] ^ s7[zi(3)] ^ sb8[zi(2)] ^\n\t    s7[zi(9)];\n\tk[3] = s5[zi(14)] ^ s6[zi(15)] ^ s7[zi(1)] ^ sb8[zi(0)] ^\n\t    sb8[zi(12)];\n\n\tx[0] = z[2] ^ s5[zi(5)] ^ s6[zi(7)] ^ s7[zi(4)] ^ sb8[zi(6)] ^\n\t    s7[zi(0)];\n\tx[1] = z[0] ^ s5[xi(0)] ^ s6[xi(2)] ^ s7[xi(1)] ^ sb8[xi(3)] ^\n\t    sb8[zi(2)];\n\tx[2] = z[1] ^ s5[xi(7)] ^ s6[xi(6)] ^ s7[xi(5)] ^ sb8[xi(4)] ^\n\t    s5[zi(1)];\n\tx[3] = z[3] ^ s5[xi(10)] ^ s6[xi(9)] ^ s7[xi(11)] ^ sb8[xi(8)] ^\n\t    s6[zi(3)];\n\tk[4] = s5[xi(3)] ^ s6[xi(2)] ^ s7[xi(12)] ^ sb8[xi(13)] ^\n\t    s5[xi(8)];\n\tk[5] = s5[xi(1)] ^ s6[xi(0)] ^ s7[xi(14)] ^ sb8[xi(15)] ^\n\t    s6[xi(13)];\n\tk[6] = s5[xi(7)] ^ s6[xi(6)] ^ s7[xi(8)] ^ sb8[xi(9)] ^ s7[xi(3)];\n\tk[7] = s5[xi(5)] ^ s6[xi(4)] ^ s7[xi(10)] ^ sb8[xi(11)] ^\n\t    sb8[xi(7)];\n\n\tz[0] = x[0] ^ s5[xi(13)] ^ s6[xi(15)] ^ s7[xi(12)] ^ sb8[xi(14)] ^\n\t    s7[xi(8)];\n\tz[1] = x[2] ^ s5[zi(0)] ^ s6[zi(2)] ^ s7[zi(1)] ^ sb8[zi(3)] ^\n\t    sb8[xi(10)];\n\tz[2] = x[3] ^ s5[zi(7)] ^ s6[zi(6)] ^ s7[zi(5)] ^ sb8[zi(4)] ^\n\t    s5[xi(9)];\n\tz[3] = x[1] ^ s5[zi(10)] ^ s6[zi(9)] ^ s7[zi(11)] ^ sb8[zi(8)] ^\n\t    s6[xi(11)];\n\tk[8] = s5[zi(3)] ^ s6[zi(2)] ^ s7[zi(12)] ^ sb8[zi(13)] ^\n\t    s5[zi(9)];\n\tk[9] = s5[zi(1)] ^ s6[zi(0)] ^ s7[zi(14)] ^ sb8[zi(15)] ^\n\t    s6[zi(12)];\n\tk[10] = s5[zi(7)] ^ s6[zi(6)] ^ s7[zi(8)] ^ sb8[zi(9)] ^ s7[zi(2)];\n\tk[11] = s5[zi(5)] ^ s6[zi(4)] ^ s7[zi(10)] ^ sb8[zi(11)] ^\n\t    sb8[zi(6)];\n\n\tx[0] = z[2] ^ s5[zi(5)] ^ s6[zi(7)] ^ s7[zi(4)] ^ sb8[zi(6)] ^\n\t    s7[zi(0)];\n\tx[1] = z[0] ^ s5[xi(0)] ^ s6[xi(2)] ^ s7[xi(1)] ^ sb8[xi(3)] ^\n\t    sb8[zi(2)];\n\tx[2] = z[1] ^ s5[xi(7)] ^ s6[xi(6)] ^ s7[xi(5)] ^ sb8[xi(4)] ^\n\t    s5[zi(1)];\n\tx[3] = z[3] ^ s5[xi(10)] ^ s6[xi(9)] ^ s7[xi(11)] ^ sb8[xi(8)] ^\n\t    s6[zi(3)];\n\tk[12] = s5[xi(8)] ^ s6[xi(9)] ^ s7[xi(7)] ^ sb8[xi(6)] ^ s5[xi(3)];\n\tk[13] = s5[xi(10)] ^ s6[xi(11)] ^ s7[xi(5)] ^ sb8[xi(4)] ^\n\t    s6[xi(7)];\n\tk[14] = s5[xi(12)] ^ s6[xi(13)] ^ s7[xi(3)] ^ sb8[xi(2)] ^\n\t    s7[xi(8)];\n\tk[15] = s5[xi(14)] ^ s6[xi(15)] ^ s7[xi(1)] ^ sb8[xi(0)] ^\n\t    sb8[xi(13)];\n\n#undef xi\n#undef zi\n}\n\n\nint cast5_setkey(struct crypto_tfm *tfm, const u8 *key, unsigned int key_len)\n{\n\tstruct cast5_ctx *c = crypto_tfm_ctx(tfm);\n\tint i;\n\tu32 x[4];\n\tu32 z[4];\n\tu32 k[16];\n\t__be32 p_key[4];\n\n\tc->rr = key_len <= 10 ? 1 : 0;\n\n\tmemset(p_key, 0, 16);\n\tmemcpy(p_key, key, key_len);\n\n\n\tx[0] = be32_to_cpu(p_key[0]);\n\tx[1] = be32_to_cpu(p_key[1]);\n\tx[2] = be32_to_cpu(p_key[2]);\n\tx[3] = be32_to_cpu(p_key[3]);\n\n\tkey_schedule(x, z, k);\n\tfor (i = 0; i < 16; i++)\n\t\tc->Km[i] = k[i];\n\tkey_schedule(x, z, k);\n\tfor (i = 0; i < 16; i++)\n\t\tc->Kr[i] = k[i] & 0x1f;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(cast5_setkey);\n\nstatic struct crypto_alg alg = {\n\t.cra_name\t\t= \"cast5\",\n\t.cra_driver_name\t= \"cast5-generic\",\n\t.cra_priority\t\t= 100,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= CAST5_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct cast5_ctx),\n\t.cra_alignmask\t\t= 3,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u\t\t\t= {\n\t\t.cipher = {\n\t\t\t.cia_min_keysize = CAST5_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize = CAST5_MAX_KEY_SIZE,\n\t\t\t.cia_setkey  = cast5_setkey,\n\t\t\t.cia_encrypt = cast5_encrypt,\n\t\t\t.cia_decrypt = cast5_decrypt\n\t\t}\n\t}\n};\n\nstatic int __init cast5_mod_init(void)\n{\n\treturn crypto_register_alg(&alg);\n}\n\nstatic void __exit cast5_mod_fini(void)\n{\n\tcrypto_unregister_alg(&alg);\n}\n\nmodule_init(cast5_mod_init);\nmodule_exit(cast5_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Cast5 Cipher Algorithm\");\nMODULE_ALIAS(\"cast5\");\n", "/* Kernel cryptographic api.\n * cast6.c - Cast6 cipher algorithm [rfc2612].\n *\n * CAST-256 (*cast6*) is a DES like Substitution-Permutation Network (SPN)\n * cryptosystem built upon the CAST-128 (*cast5*) [rfc2144] encryption\n * algorithm.\n *\n * Copyright (C) 2003 Kartikey Mahendra Bhatt <kartik_me@hotmail.com>.\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA\n */\n\n\n#include <asm/byteorder.h>\n#include <linux/init.h>\n#include <linux/crypto.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <crypto/cast6.h>\n\n#define s1 cast_s1\n#define s2 cast_s2\n#define s3 cast_s3\n#define s4 cast_s4\n\n#define F1(D, r, m)  ((I = ((m) + (D))), (I = rol32(I, (r))),   \\\n\t(((s1[I >> 24] ^ s2[(I>>16)&0xff]) - s3[(I>>8)&0xff]) + s4[I&0xff]))\n#define F2(D, r, m)  ((I = ((m) ^ (D))), (I = rol32(I, (r))),   \\\n\t(((s1[I >> 24] - s2[(I>>16)&0xff]) + s3[(I>>8)&0xff]) ^ s4[I&0xff]))\n#define F3(D, r, m)  ((I = ((m) - (D))), (I = rol32(I, (r))),   \\\n\t(((s1[I >> 24] + s2[(I>>16)&0xff]) ^ s3[(I>>8)&0xff]) - s4[I&0xff]))\n\nstatic const u32 Tm[24][8] = {\n\t{ 0x5a827999, 0xc95c653a, 0x383650db, 0xa7103c7c, 0x15ea281d,\n\t\t0x84c413be, 0xf39dff5f, 0x6277eb00 } ,\n\t{ 0xd151d6a1, 0x402bc242, 0xaf05ade3, 0x1ddf9984, 0x8cb98525,\n\t\t0xfb9370c6, 0x6a6d5c67, 0xd9474808 } ,\n\t{ 0x482133a9, 0xb6fb1f4a, 0x25d50aeb, 0x94aef68c, 0x0388e22d,\n\t\t0x7262cdce, 0xe13cb96f, 0x5016a510 } ,\n\t{ 0xbef090b1, 0x2dca7c52, 0x9ca467f3, 0x0b7e5394, 0x7a583f35,\n\t\t0xe9322ad6, 0x580c1677, 0xc6e60218 } ,\n\t{ 0x35bfedb9, 0xa499d95a, 0x1373c4fb, 0x824db09c, 0xf1279c3d,\n\t\t0x600187de, 0xcedb737f, 0x3db55f20 } ,\n\t{ 0xac8f4ac1, 0x1b693662, 0x8a432203, 0xf91d0da4, 0x67f6f945,\n\t\t0xd6d0e4e6, 0x45aad087, 0xb484bc28 } ,\n\t{ 0x235ea7c9, 0x9238936a, 0x01127f0b, 0x6fec6aac, 0xdec6564d,\n\t\t0x4da041ee, 0xbc7a2d8f, 0x2b541930 } ,\n\t{ 0x9a2e04d1, 0x0907f072, 0x77e1dc13, 0xe6bbc7b4, 0x5595b355,\n\t\t0xc46f9ef6, 0x33498a97, 0xa2237638 } ,\n\t{ 0x10fd61d9, 0x7fd74d7a, 0xeeb1391b, 0x5d8b24bc, 0xcc65105d,\n\t\t0x3b3efbfe, 0xaa18e79f, 0x18f2d340 } ,\n\t{ 0x87ccbee1, 0xf6a6aa82, 0x65809623, 0xd45a81c4, 0x43346d65,\n\t\t0xb20e5906, 0x20e844a7, 0x8fc23048 } ,\n\t{ 0xfe9c1be9, 0x6d76078a, 0xdc4ff32b, 0x4b29decc, 0xba03ca6d,\n\t\t0x28ddb60e, 0x97b7a1af, 0x06918d50 } ,\n\t{ 0x756b78f1, 0xe4456492, 0x531f5033, 0xc1f93bd4, 0x30d32775,\n\t\t0x9fad1316, 0x0e86feb7, 0x7d60ea58 } ,\n\t{ 0xec3ad5f9, 0x5b14c19a, 0xc9eead3b, 0x38c898dc, 0xa7a2847d,\n\t\t0x167c701e, 0x85565bbf, 0xf4304760 } ,\n\t{ 0x630a3301, 0xd1e41ea2, 0x40be0a43, 0xaf97f5e4, 0x1e71e185,\n\t\t0x8d4bcd26, 0xfc25b8c7, 0x6affa468 } ,\n\t{ 0xd9d99009, 0x48b37baa, 0xb78d674b, 0x266752ec, 0x95413e8d,\n\t\t0x041b2a2e, 0x72f515cf, 0xe1cf0170 } ,\n\t{ 0x50a8ed11, 0xbf82d8b2, 0x2e5cc453, 0x9d36aff4, 0x0c109b95,\n\t\t0x7aea8736, 0xe9c472d7, 0x589e5e78 } ,\n\t{ 0xc7784a19, 0x365235ba, 0xa52c215b, 0x14060cfc, 0x82dff89d,\n\t\t0xf1b9e43e, 0x6093cfdf, 0xcf6dbb80 } ,\n\t{ 0x3e47a721, 0xad2192c2, 0x1bfb7e63, 0x8ad56a04, 0xf9af55a5,\n\t\t0x68894146, 0xd7632ce7, 0x463d1888 } ,\n\t{ 0xb5170429, 0x23f0efca, 0x92cadb6b, 0x01a4c70c, 0x707eb2ad,\n\t\t0xdf589e4e, 0x4e3289ef, 0xbd0c7590 } ,\n\t{ 0x2be66131, 0x9ac04cd2, 0x099a3873, 0x78742414, 0xe74e0fb5,\n\t\t0x5627fb56, 0xc501e6f7, 0x33dbd298 } ,\n\t{ 0xa2b5be39, 0x118fa9da, 0x8069957b, 0xef43811c, 0x5e1d6cbd,\n\t\t0xccf7585e, 0x3bd143ff, 0xaaab2fa0 } ,\n\t{ 0x19851b41, 0x885f06e2, 0xf738f283, 0x6612de24, 0xd4ecc9c5,\n\t\t0x43c6b566, 0xb2a0a107, 0x217a8ca8 } ,\n\t{ 0x90547849, 0xff2e63ea, 0x6e084f8b, 0xdce23b2c, 0x4bbc26cd,\n\t\t0xba96126e, 0x296ffe0f, 0x9849e9b0 } ,\n\t{ 0x0723d551, 0x75fdc0f2, 0xe4d7ac93, 0x53b19834, 0xc28b83d5,\n\t\t0x31656f76, 0xa03f5b17, 0x0f1946b8 }\n};\n\nstatic const u8 Tr[4][8] = {\n\t{ 0x13, 0x04, 0x15, 0x06, 0x17, 0x08, 0x19, 0x0a } ,\n\t{ 0x1b, 0x0c, 0x1d, 0x0e, 0x1f, 0x10, 0x01, 0x12 } ,\n\t{ 0x03, 0x14, 0x05, 0x16, 0x07, 0x18, 0x09, 0x1a } ,\n\t{ 0x0b, 0x1c, 0x0d, 0x1e, 0x0f, 0x00, 0x11, 0x02 }\n};\n\n/* forward octave */\nstatic inline void W(u32 *key, unsigned int i)\n{\n\tu32 I;\n\tkey[6] ^= F1(key[7], Tr[i % 4][0], Tm[i][0]);\n\tkey[5] ^= F2(key[6], Tr[i % 4][1], Tm[i][1]);\n\tkey[4] ^= F3(key[5], Tr[i % 4][2], Tm[i][2]);\n\tkey[3] ^= F1(key[4], Tr[i % 4][3], Tm[i][3]);\n\tkey[2] ^= F2(key[3], Tr[i % 4][4], Tm[i][4]);\n\tkey[1] ^= F3(key[2], Tr[i % 4][5], Tm[i][5]);\n\tkey[0] ^= F1(key[1], Tr[i % 4][6], Tm[i][6]);\n\tkey[7] ^= F2(key[0], Tr[i % 4][7], Tm[i][7]);\n}\n\nint __cast6_setkey(struct cast6_ctx *c, const u8 *in_key,\n\t\t   unsigned key_len, u32 *flags)\n{\n\tint i;\n\tu32 key[8];\n\t__be32 p_key[8]; /* padded key */\n\n\tif (key_len % 4 != 0) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\tmemset(p_key, 0, 32);\n\tmemcpy(p_key, in_key, key_len);\n\n\tkey[0] = be32_to_cpu(p_key[0]);\t\t/* A */\n\tkey[1] = be32_to_cpu(p_key[1]);\t\t/* B */\n\tkey[2] = be32_to_cpu(p_key[2]);\t\t/* C */\n\tkey[3] = be32_to_cpu(p_key[3]);\t\t/* D */\n\tkey[4] = be32_to_cpu(p_key[4]);\t\t/* E */\n\tkey[5] = be32_to_cpu(p_key[5]);\t\t/* F */\n\tkey[6] = be32_to_cpu(p_key[6]);\t\t/* G */\n\tkey[7] = be32_to_cpu(p_key[7]);\t\t/* H */\n\n\tfor (i = 0; i < 12; i++) {\n\t\tW(key, 2 * i);\n\t\tW(key, 2 * i + 1);\n\n\t\tc->Kr[i][0] = key[0] & 0x1f;\n\t\tc->Kr[i][1] = key[2] & 0x1f;\n\t\tc->Kr[i][2] = key[4] & 0x1f;\n\t\tc->Kr[i][3] = key[6] & 0x1f;\n\n\t\tc->Km[i][0] = key[7];\n\t\tc->Km[i][1] = key[5];\n\t\tc->Km[i][2] = key[3];\n\t\tc->Km[i][3] = key[1];\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(__cast6_setkey);\n\nint cast6_setkey(struct crypto_tfm *tfm, const u8 *key, unsigned int keylen)\n{\n\treturn __cast6_setkey(crypto_tfm_ctx(tfm), key, keylen,\n\t\t\t      &tfm->crt_flags);\n}\nEXPORT_SYMBOL_GPL(cast6_setkey);\n\n/*forward quad round*/\nstatic inline void Q(u32 *block, u8 *Kr, u32 *Km)\n{\n\tu32 I;\n\tblock[2] ^= F1(block[3], Kr[0], Km[0]);\n\tblock[1] ^= F2(block[2], Kr[1], Km[1]);\n\tblock[0] ^= F3(block[1], Kr[2], Km[2]);\n\tblock[3] ^= F1(block[0], Kr[3], Km[3]);\n}\n\n/*reverse quad round*/\nstatic inline void QBAR(u32 *block, u8 *Kr, u32 *Km)\n{\n\tu32 I;\n\tblock[3] ^= F1(block[0], Kr[3], Km[3]);\n\tblock[0] ^= F3(block[1], Kr[2], Km[2]);\n\tblock[1] ^= F2(block[2], Kr[1], Km[1]);\n\tblock[2] ^= F1(block[3], Kr[0], Km[0]);\n}\n\nvoid __cast6_encrypt(struct cast6_ctx *c, u8 *outbuf, const u8 *inbuf)\n{\n\tconst __be32 *src = (const __be32 *)inbuf;\n\t__be32 *dst = (__be32 *)outbuf;\n\tu32 block[4];\n\tu32 *Km;\n\tu8 *Kr;\n\n\tblock[0] = be32_to_cpu(src[0]);\n\tblock[1] = be32_to_cpu(src[1]);\n\tblock[2] = be32_to_cpu(src[2]);\n\tblock[3] = be32_to_cpu(src[3]);\n\n\tKm = c->Km[0]; Kr = c->Kr[0]; Q(block, Kr, Km);\n\tKm = c->Km[1]; Kr = c->Kr[1]; Q(block, Kr, Km);\n\tKm = c->Km[2]; Kr = c->Kr[2]; Q(block, Kr, Km);\n\tKm = c->Km[3]; Kr = c->Kr[3]; Q(block, Kr, Km);\n\tKm = c->Km[4]; Kr = c->Kr[4]; Q(block, Kr, Km);\n\tKm = c->Km[5]; Kr = c->Kr[5]; Q(block, Kr, Km);\n\tKm = c->Km[6]; Kr = c->Kr[6]; QBAR(block, Kr, Km);\n\tKm = c->Km[7]; Kr = c->Kr[7]; QBAR(block, Kr, Km);\n\tKm = c->Km[8]; Kr = c->Kr[8]; QBAR(block, Kr, Km);\n\tKm = c->Km[9]; Kr = c->Kr[9]; QBAR(block, Kr, Km);\n\tKm = c->Km[10]; Kr = c->Kr[10]; QBAR(block, Kr, Km);\n\tKm = c->Km[11]; Kr = c->Kr[11]; QBAR(block, Kr, Km);\n\n\tdst[0] = cpu_to_be32(block[0]);\n\tdst[1] = cpu_to_be32(block[1]);\n\tdst[2] = cpu_to_be32(block[2]);\n\tdst[3] = cpu_to_be32(block[3]);\n}\nEXPORT_SYMBOL_GPL(__cast6_encrypt);\n\nstatic void cast6_encrypt(struct crypto_tfm *tfm, u8 *outbuf, const u8 *inbuf)\n{\n\t__cast6_encrypt(crypto_tfm_ctx(tfm), outbuf, inbuf);\n}\n\nvoid __cast6_decrypt(struct cast6_ctx *c, u8 *outbuf, const u8 *inbuf)\n{\n\tconst __be32 *src = (const __be32 *)inbuf;\n\t__be32 *dst = (__be32 *)outbuf;\n\tu32 block[4];\n\tu32 *Km;\n\tu8 *Kr;\n\n\tblock[0] = be32_to_cpu(src[0]);\n\tblock[1] = be32_to_cpu(src[1]);\n\tblock[2] = be32_to_cpu(src[2]);\n\tblock[3] = be32_to_cpu(src[3]);\n\n\tKm = c->Km[11]; Kr = c->Kr[11]; Q(block, Kr, Km);\n\tKm = c->Km[10]; Kr = c->Kr[10]; Q(block, Kr, Km);\n\tKm = c->Km[9]; Kr = c->Kr[9]; Q(block, Kr, Km);\n\tKm = c->Km[8]; Kr = c->Kr[8]; Q(block, Kr, Km);\n\tKm = c->Km[7]; Kr = c->Kr[7]; Q(block, Kr, Km);\n\tKm = c->Km[6]; Kr = c->Kr[6]; Q(block, Kr, Km);\n\tKm = c->Km[5]; Kr = c->Kr[5]; QBAR(block, Kr, Km);\n\tKm = c->Km[4]; Kr = c->Kr[4]; QBAR(block, Kr, Km);\n\tKm = c->Km[3]; Kr = c->Kr[3]; QBAR(block, Kr, Km);\n\tKm = c->Km[2]; Kr = c->Kr[2]; QBAR(block, Kr, Km);\n\tKm = c->Km[1]; Kr = c->Kr[1]; QBAR(block, Kr, Km);\n\tKm = c->Km[0]; Kr = c->Kr[0]; QBAR(block, Kr, Km);\n\n\tdst[0] = cpu_to_be32(block[0]);\n\tdst[1] = cpu_to_be32(block[1]);\n\tdst[2] = cpu_to_be32(block[2]);\n\tdst[3] = cpu_to_be32(block[3]);\n}\nEXPORT_SYMBOL_GPL(__cast6_decrypt);\n\nstatic void cast6_decrypt(struct crypto_tfm *tfm, u8 *outbuf, const u8 *inbuf)\n{\n\t__cast6_decrypt(crypto_tfm_ctx(tfm), outbuf, inbuf);\n}\n\nstatic struct crypto_alg alg = {\n\t.cra_name = \"cast6\",\n\t.cra_driver_name = \"cast6-generic\",\n\t.cra_priority = 100,\n\t.cra_flags = CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize = CAST6_BLOCK_SIZE,\n\t.cra_ctxsize = sizeof(struct cast6_ctx),\n\t.cra_alignmask = 3,\n\t.cra_module = THIS_MODULE,\n\t.cra_u = {\n\t\t  .cipher = {\n\t\t\t     .cia_min_keysize = CAST6_MIN_KEY_SIZE,\n\t\t\t     .cia_max_keysize = CAST6_MAX_KEY_SIZE,\n\t\t\t     .cia_setkey = cast6_setkey,\n\t\t\t     .cia_encrypt = cast6_encrypt,\n\t\t\t     .cia_decrypt = cast6_decrypt}\n\t\t  }\n};\n\nstatic int __init cast6_mod_init(void)\n{\n\treturn crypto_register_alg(&alg);\n}\n\nstatic void __exit cast6_mod_fini(void)\n{\n\tcrypto_unregister_alg(&alg);\n}\n\nmodule_init(cast6_mod_init);\nmodule_exit(cast6_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Cast6 Cipher Algorithm\");\nMODULE_ALIAS(\"cast6\");\n", "/*\n * CCM: Counter with CBC-MAC\n *\n * (C) Copyright IBM Corp. 2007 - Joy Latten <latten@us.ibm.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#include <crypto/internal/aead.h>\n#include <crypto/internal/skcipher.h>\n#include <crypto/scatterwalk.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/slab.h>\n\n#include \"internal.h\"\n\nstruct ccm_instance_ctx {\n\tstruct crypto_skcipher_spawn ctr;\n\tstruct crypto_spawn cipher;\n};\n\nstruct crypto_ccm_ctx {\n\tstruct crypto_cipher *cipher;\n\tstruct crypto_ablkcipher *ctr;\n};\n\nstruct crypto_rfc4309_ctx {\n\tstruct crypto_aead *child;\n\tu8 nonce[3];\n};\n\nstruct crypto_ccm_req_priv_ctx {\n\tu8 odata[16];\n\tu8 idata[16];\n\tu8 auth_tag[16];\n\tu32 ilen;\n\tu32 flags;\n\tstruct scatterlist src[2];\n\tstruct scatterlist dst[2];\n\tstruct ablkcipher_request abreq;\n};\n\nstatic inline struct crypto_ccm_req_priv_ctx *crypto_ccm_reqctx(\n\tstruct aead_request *req)\n{\n\tunsigned long align = crypto_aead_alignmask(crypto_aead_reqtfm(req));\n\n\treturn (void *)PTR_ALIGN((u8 *)aead_request_ctx(req), align + 1);\n}\n\nstatic int set_msg_len(u8 *block, unsigned int msglen, int csize)\n{\n\t__be32 data;\n\n\tmemset(block, 0, csize);\n\tblock += csize;\n\n\tif (csize >= 4)\n\t\tcsize = 4;\n\telse if (msglen > (1 << (8 * csize)))\n\t\treturn -EOVERFLOW;\n\n\tdata = cpu_to_be32(msglen);\n\tmemcpy(block - csize, (u8 *)&data + 4 - csize, csize);\n\n\treturn 0;\n}\n\nstatic int crypto_ccm_setkey(struct crypto_aead *aead, const u8 *key,\n\t\t\t     unsigned int keylen)\n{\n\tstruct crypto_ccm_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct crypto_ablkcipher *ctr = ctx->ctr;\n\tstruct crypto_cipher *tfm = ctx->cipher;\n\tint err = 0;\n\n\tcrypto_ablkcipher_clear_flags(ctr, CRYPTO_TFM_REQ_MASK);\n\tcrypto_ablkcipher_set_flags(ctr, crypto_aead_get_flags(aead) &\n\t\t\t\t    CRYPTO_TFM_REQ_MASK);\n\terr = crypto_ablkcipher_setkey(ctr, key, keylen);\n\tcrypto_aead_set_flags(aead, crypto_ablkcipher_get_flags(ctr) &\n\t\t\t      CRYPTO_TFM_RES_MASK);\n\tif (err)\n\t\tgoto out;\n\n\tcrypto_cipher_clear_flags(tfm, CRYPTO_TFM_REQ_MASK);\n\tcrypto_cipher_set_flags(tfm, crypto_aead_get_flags(aead) &\n\t\t\t\t    CRYPTO_TFM_REQ_MASK);\n\terr = crypto_cipher_setkey(tfm, key, keylen);\n\tcrypto_aead_set_flags(aead, crypto_cipher_get_flags(tfm) &\n\t\t\t      CRYPTO_TFM_RES_MASK);\n\nout:\n\treturn err;\n}\n\nstatic int crypto_ccm_setauthsize(struct crypto_aead *tfm,\n\t\t\t\t  unsigned int authsize)\n{\n\tswitch (authsize) {\n\tcase 4:\n\tcase 6:\n\tcase 8:\n\tcase 10:\n\tcase 12:\n\tcase 14:\n\tcase 16:\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int format_input(u8 *info, struct aead_request *req,\n\t\t\tunsigned int cryptlen)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tunsigned int lp = req->iv[0];\n\tunsigned int l = lp + 1;\n\tunsigned int m;\n\n\tm = crypto_aead_authsize(aead);\n\n\tmemcpy(info, req->iv, 16);\n\n\t/* format control info per RFC 3610 and\n\t * NIST Special Publication 800-38C\n\t */\n\t*info |= (8 * ((m - 2) / 2));\n\tif (req->assoclen)\n\t\t*info |= 64;\n\n\treturn set_msg_len(info + 16 - l, cryptlen, l);\n}\n\nstatic int format_adata(u8 *adata, unsigned int a)\n{\n\tint len = 0;\n\n\t/* add control info for associated data\n\t * RFC 3610 and NIST Special Publication 800-38C\n\t */\n\tif (a < 65280) {\n\t\t*(__be16 *)adata = cpu_to_be16(a);\n\t\tlen = 2;\n\t} else  {\n\t\t*(__be16 *)adata = cpu_to_be16(0xfffe);\n\t\t*(__be32 *)&adata[2] = cpu_to_be32(a);\n\t\tlen = 6;\n\t}\n\n\treturn len;\n}\n\nstatic void compute_mac(struct crypto_cipher *tfm, u8 *data, int n,\n\t\t       struct crypto_ccm_req_priv_ctx *pctx)\n{\n\tunsigned int bs = 16;\n\tu8 *odata = pctx->odata;\n\tu8 *idata = pctx->idata;\n\tint datalen, getlen;\n\n\tdatalen = n;\n\n\t/* first time in here, block may be partially filled. */\n\tgetlen = bs - pctx->ilen;\n\tif (datalen >= getlen) {\n\t\tmemcpy(idata + pctx->ilen, data, getlen);\n\t\tcrypto_xor(odata, idata, bs);\n\t\tcrypto_cipher_encrypt_one(tfm, odata, odata);\n\t\tdatalen -= getlen;\n\t\tdata += getlen;\n\t\tpctx->ilen = 0;\n\t}\n\n\t/* now encrypt rest of data */\n\twhile (datalen >= bs) {\n\t\tcrypto_xor(odata, data, bs);\n\t\tcrypto_cipher_encrypt_one(tfm, odata, odata);\n\n\t\tdatalen -= bs;\n\t\tdata += bs;\n\t}\n\n\t/* check and see if there's leftover data that wasn't\n\t * enough to fill a block.\n\t */\n\tif (datalen) {\n\t\tmemcpy(idata + pctx->ilen, data, datalen);\n\t\tpctx->ilen += datalen;\n\t}\n}\n\nstatic void get_data_to_compute(struct crypto_cipher *tfm,\n\t\t\t       struct crypto_ccm_req_priv_ctx *pctx,\n\t\t\t       struct scatterlist *sg, unsigned int len)\n{\n\tstruct scatter_walk walk;\n\tu8 *data_src;\n\tint n;\n\n\tscatterwalk_start(&walk, sg);\n\n\twhile (len) {\n\t\tn = scatterwalk_clamp(&walk, len);\n\t\tif (!n) {\n\t\t\tscatterwalk_start(&walk, sg_next(walk.sg));\n\t\t\tn = scatterwalk_clamp(&walk, len);\n\t\t}\n\t\tdata_src = scatterwalk_map(&walk);\n\n\t\tcompute_mac(tfm, data_src, n, pctx);\n\t\tlen -= n;\n\n\t\tscatterwalk_unmap(data_src);\n\t\tscatterwalk_advance(&walk, n);\n\t\tscatterwalk_done(&walk, 0, len);\n\t\tif (len)\n\t\t\tcrypto_yield(pctx->flags);\n\t}\n\n\t/* any leftover needs padding and then encrypted */\n\tif (pctx->ilen) {\n\t\tint padlen;\n\t\tu8 *odata = pctx->odata;\n\t\tu8 *idata = pctx->idata;\n\n\t\tpadlen = 16 - pctx->ilen;\n\t\tmemset(idata + pctx->ilen, 0, padlen);\n\t\tcrypto_xor(odata, idata, 16);\n\t\tcrypto_cipher_encrypt_one(tfm, odata, odata);\n\t\tpctx->ilen = 0;\n\t}\n}\n\nstatic int crypto_ccm_auth(struct aead_request *req, struct scatterlist *plain,\n\t\t\t   unsigned int cryptlen)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_ccm_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct crypto_ccm_req_priv_ctx *pctx = crypto_ccm_reqctx(req);\n\tstruct crypto_cipher *cipher = ctx->cipher;\n\tunsigned int assoclen = req->assoclen;\n\tu8 *odata = pctx->odata;\n\tu8 *idata = pctx->idata;\n\tint err;\n\n\t/* format control data for input */\n\terr = format_input(odata, req, cryptlen);\n\tif (err)\n\t\tgoto out;\n\n\t/* encrypt first block to use as start in computing mac  */\n\tcrypto_cipher_encrypt_one(cipher, odata, odata);\n\n\t/* format associated data and compute into mac */\n\tif (assoclen) {\n\t\tpctx->ilen = format_adata(idata, assoclen);\n\t\tget_data_to_compute(cipher, pctx, req->assoc, req->assoclen);\n\t} else {\n\t\tpctx->ilen = 0;\n\t}\n\n\t/* compute plaintext into mac */\n\tif (cryptlen)\n\t\tget_data_to_compute(cipher, pctx, plain, cryptlen);\n\nout:\n\treturn err;\n}\n\nstatic void crypto_ccm_encrypt_done(struct crypto_async_request *areq, int err)\n{\n\tstruct aead_request *req = areq->data;\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_ccm_req_priv_ctx *pctx = crypto_ccm_reqctx(req);\n\tu8 *odata = pctx->odata;\n\n\tif (!err)\n\t\tscatterwalk_map_and_copy(odata, req->dst, req->cryptlen,\n\t\t\t\t\t crypto_aead_authsize(aead), 1);\n\taead_request_complete(req, err);\n}\n\nstatic inline int crypto_ccm_check_iv(const u8 *iv)\n{\n\t/* 2 <= L <= 8, so 1 <= L' <= 7. */\n\tif (1 > iv[0] || iv[0] > 7)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int crypto_ccm_encrypt(struct aead_request *req)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_ccm_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct crypto_ccm_req_priv_ctx *pctx = crypto_ccm_reqctx(req);\n\tstruct ablkcipher_request *abreq = &pctx->abreq;\n\tstruct scatterlist *dst;\n\tunsigned int cryptlen = req->cryptlen;\n\tu8 *odata = pctx->odata;\n\tu8 *iv = req->iv;\n\tint err;\n\n\terr = crypto_ccm_check_iv(iv);\n\tif (err)\n\t\treturn err;\n\n\tpctx->flags = aead_request_flags(req);\n\n\terr = crypto_ccm_auth(req, req->src, cryptlen);\n\tif (err)\n\t\treturn err;\n\n\t /* Note: rfc 3610 and NIST 800-38C require counter of\n\t * zero to encrypt auth tag.\n\t */\n\tmemset(iv + 15 - iv[0], 0, iv[0] + 1);\n\n\tsg_init_table(pctx->src, 2);\n\tsg_set_buf(pctx->src, odata, 16);\n\tscatterwalk_sg_chain(pctx->src, 2, req->src);\n\n\tdst = pctx->src;\n\tif (req->src != req->dst) {\n\t\tsg_init_table(pctx->dst, 2);\n\t\tsg_set_buf(pctx->dst, odata, 16);\n\t\tscatterwalk_sg_chain(pctx->dst, 2, req->dst);\n\t\tdst = pctx->dst;\n\t}\n\n\tablkcipher_request_set_tfm(abreq, ctx->ctr);\n\tablkcipher_request_set_callback(abreq, pctx->flags,\n\t\t\t\t\tcrypto_ccm_encrypt_done, req);\n\tablkcipher_request_set_crypt(abreq, pctx->src, dst, cryptlen + 16, iv);\n\terr = crypto_ablkcipher_encrypt(abreq);\n\tif (err)\n\t\treturn err;\n\n\t/* copy authtag to end of dst */\n\tscatterwalk_map_and_copy(odata, req->dst, cryptlen,\n\t\t\t\t crypto_aead_authsize(aead), 1);\n\treturn err;\n}\n\nstatic void crypto_ccm_decrypt_done(struct crypto_async_request *areq,\n\t\t\t\t   int err)\n{\n\tstruct aead_request *req = areq->data;\n\tstruct crypto_ccm_req_priv_ctx *pctx = crypto_ccm_reqctx(req);\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tunsigned int authsize = crypto_aead_authsize(aead);\n\tunsigned int cryptlen = req->cryptlen - authsize;\n\n\tif (!err) {\n\t\terr = crypto_ccm_auth(req, req->dst, cryptlen);\n\t\tif (!err && crypto_memneq(pctx->auth_tag, pctx->odata, authsize))\n\t\t\terr = -EBADMSG;\n\t}\n\taead_request_complete(req, err);\n}\n\nstatic int crypto_ccm_decrypt(struct aead_request *req)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_ccm_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct crypto_ccm_req_priv_ctx *pctx = crypto_ccm_reqctx(req);\n\tstruct ablkcipher_request *abreq = &pctx->abreq;\n\tstruct scatterlist *dst;\n\tunsigned int authsize = crypto_aead_authsize(aead);\n\tunsigned int cryptlen = req->cryptlen;\n\tu8 *authtag = pctx->auth_tag;\n\tu8 *odata = pctx->odata;\n\tu8 *iv = req->iv;\n\tint err;\n\n\tif (cryptlen < authsize)\n\t\treturn -EINVAL;\n\tcryptlen -= authsize;\n\n\terr = crypto_ccm_check_iv(iv);\n\tif (err)\n\t\treturn err;\n\n\tpctx->flags = aead_request_flags(req);\n\n\tscatterwalk_map_and_copy(authtag, req->src, cryptlen, authsize, 0);\n\n\tmemset(iv + 15 - iv[0], 0, iv[0] + 1);\n\n\tsg_init_table(pctx->src, 2);\n\tsg_set_buf(pctx->src, authtag, 16);\n\tscatterwalk_sg_chain(pctx->src, 2, req->src);\n\n\tdst = pctx->src;\n\tif (req->src != req->dst) {\n\t\tsg_init_table(pctx->dst, 2);\n\t\tsg_set_buf(pctx->dst, authtag, 16);\n\t\tscatterwalk_sg_chain(pctx->dst, 2, req->dst);\n\t\tdst = pctx->dst;\n\t}\n\n\tablkcipher_request_set_tfm(abreq, ctx->ctr);\n\tablkcipher_request_set_callback(abreq, pctx->flags,\n\t\t\t\t\tcrypto_ccm_decrypt_done, req);\n\tablkcipher_request_set_crypt(abreq, pctx->src, dst, cryptlen + 16, iv);\n\terr = crypto_ablkcipher_decrypt(abreq);\n\tif (err)\n\t\treturn err;\n\n\terr = crypto_ccm_auth(req, req->dst, cryptlen);\n\tif (err)\n\t\treturn err;\n\n\t/* verify */\n\tif (crypto_memneq(authtag, odata, authsize))\n\t\treturn -EBADMSG;\n\n\treturn err;\n}\n\nstatic int crypto_ccm_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_instance *inst = (void *)tfm->__crt_alg;\n\tstruct ccm_instance_ctx *ictx = crypto_instance_ctx(inst);\n\tstruct crypto_ccm_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_cipher *cipher;\n\tstruct crypto_ablkcipher *ctr;\n\tunsigned long align;\n\tint err;\n\n\tcipher = crypto_spawn_cipher(&ictx->cipher);\n\tif (IS_ERR(cipher))\n\t\treturn PTR_ERR(cipher);\n\n\tctr = crypto_spawn_skcipher(&ictx->ctr);\n\terr = PTR_ERR(ctr);\n\tif (IS_ERR(ctr))\n\t\tgoto err_free_cipher;\n\n\tctx->cipher = cipher;\n\tctx->ctr = ctr;\n\n\talign = crypto_tfm_alg_alignmask(tfm);\n\talign &= ~(crypto_tfm_ctx_alignment() - 1);\n\ttfm->crt_aead.reqsize = align +\n\t\t\t\tsizeof(struct crypto_ccm_req_priv_ctx) +\n\t\t\t\tcrypto_ablkcipher_reqsize(ctr);\n\n\treturn 0;\n\nerr_free_cipher:\n\tcrypto_free_cipher(cipher);\n\treturn err;\n}\n\nstatic void crypto_ccm_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_ccm_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_cipher(ctx->cipher);\n\tcrypto_free_ablkcipher(ctx->ctr);\n}\n\nstatic struct crypto_instance *crypto_ccm_alloc_common(struct rtattr **tb,\n\t\t\t\t\t\t       const char *full_name,\n\t\t\t\t\t\t       const char *ctr_name,\n\t\t\t\t\t\t       const char *cipher_name)\n{\n\tstruct crypto_attr_type *algt;\n\tstruct crypto_instance *inst;\n\tstruct crypto_alg *ctr;\n\tstruct crypto_alg *cipher;\n\tstruct ccm_instance_ctx *ictx;\n\tint err;\n\n\talgt = crypto_get_attr_type(tb);\n\tif (IS_ERR(algt))\n\t\treturn ERR_CAST(algt);\n\n\tif ((algt->type ^ CRYPTO_ALG_TYPE_AEAD) & algt->mask)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tcipher = crypto_alg_mod_lookup(cipher_name,  CRYPTO_ALG_TYPE_CIPHER,\n\t\t\t\t       CRYPTO_ALG_TYPE_MASK);\n\tif (IS_ERR(cipher))\n\t\treturn ERR_CAST(cipher);\n\n\terr = -EINVAL;\n\tif (cipher->cra_blocksize != 16)\n\t\tgoto out_put_cipher;\n\n\tinst = kzalloc(sizeof(*inst) + sizeof(*ictx), GFP_KERNEL);\n\terr = -ENOMEM;\n\tif (!inst)\n\t\tgoto out_put_cipher;\n\n\tictx = crypto_instance_ctx(inst);\n\n\terr = crypto_init_spawn(&ictx->cipher, cipher, inst,\n\t\t\t\tCRYPTO_ALG_TYPE_MASK);\n\tif (err)\n\t\tgoto err_free_inst;\n\n\tcrypto_set_skcipher_spawn(&ictx->ctr, inst);\n\terr = crypto_grab_skcipher(&ictx->ctr, ctr_name, 0,\n\t\t\t\t   crypto_requires_sync(algt->type,\n\t\t\t\t\t\t\talgt->mask));\n\tif (err)\n\t\tgoto err_drop_cipher;\n\n\tctr = crypto_skcipher_spawn_alg(&ictx->ctr);\n\n\t/* Not a stream cipher? */\n\terr = -EINVAL;\n\tif (ctr->cra_blocksize != 1)\n\t\tgoto err_drop_ctr;\n\n\t/* We want the real thing! */\n\tif (ctr->cra_ablkcipher.ivsize != 16)\n\t\tgoto err_drop_ctr;\n\n\terr = -ENAMETOOLONG;\n\tif (snprintf(inst->alg.cra_driver_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"ccm_base(%s,%s)\", ctr->cra_driver_name,\n\t\t     cipher->cra_driver_name) >= CRYPTO_MAX_ALG_NAME)\n\t\tgoto err_drop_ctr;\n\n\tmemcpy(inst->alg.cra_name, full_name, CRYPTO_MAX_ALG_NAME);\n\n\tinst->alg.cra_flags = CRYPTO_ALG_TYPE_AEAD;\n\tinst->alg.cra_flags |= ctr->cra_flags & CRYPTO_ALG_ASYNC;\n\tinst->alg.cra_priority = cipher->cra_priority + ctr->cra_priority;\n\tinst->alg.cra_blocksize = 1;\n\tinst->alg.cra_alignmask = cipher->cra_alignmask | ctr->cra_alignmask |\n\t\t\t\t  (__alignof__(u32) - 1);\n\tinst->alg.cra_type = &crypto_aead_type;\n\tinst->alg.cra_aead.ivsize = 16;\n\tinst->alg.cra_aead.maxauthsize = 16;\n\tinst->alg.cra_ctxsize = sizeof(struct crypto_ccm_ctx);\n\tinst->alg.cra_init = crypto_ccm_init_tfm;\n\tinst->alg.cra_exit = crypto_ccm_exit_tfm;\n\tinst->alg.cra_aead.setkey = crypto_ccm_setkey;\n\tinst->alg.cra_aead.setauthsize = crypto_ccm_setauthsize;\n\tinst->alg.cra_aead.encrypt = crypto_ccm_encrypt;\n\tinst->alg.cra_aead.decrypt = crypto_ccm_decrypt;\n\nout:\n\tcrypto_mod_put(cipher);\n\treturn inst;\n\nerr_drop_ctr:\n\tcrypto_drop_skcipher(&ictx->ctr);\nerr_drop_cipher:\n\tcrypto_drop_spawn(&ictx->cipher);\nerr_free_inst:\n\tkfree(inst);\nout_put_cipher:\n\tinst = ERR_PTR(err);\n\tgoto out;\n}\n\nstatic struct crypto_instance *crypto_ccm_alloc(struct rtattr **tb)\n{\n\tconst char *cipher_name;\n\tchar ctr_name[CRYPTO_MAX_ALG_NAME];\n\tchar full_name[CRYPTO_MAX_ALG_NAME];\n\n\tcipher_name = crypto_attr_alg_name(tb[1]);\n\tif (IS_ERR(cipher_name))\n\t\treturn ERR_CAST(cipher_name);\n\n\tif (snprintf(ctr_name, CRYPTO_MAX_ALG_NAME, \"ctr(%s)\",\n\t\t     cipher_name) >= CRYPTO_MAX_ALG_NAME)\n\t\treturn ERR_PTR(-ENAMETOOLONG);\n\n\tif (snprintf(full_name, CRYPTO_MAX_ALG_NAME, \"ccm(%s)\", cipher_name) >=\n\t    CRYPTO_MAX_ALG_NAME)\n\t\treturn ERR_PTR(-ENAMETOOLONG);\n\n\treturn crypto_ccm_alloc_common(tb, full_name, ctr_name, cipher_name);\n}\n\nstatic void crypto_ccm_free(struct crypto_instance *inst)\n{\n\tstruct ccm_instance_ctx *ctx = crypto_instance_ctx(inst);\n\n\tcrypto_drop_spawn(&ctx->cipher);\n\tcrypto_drop_skcipher(&ctx->ctr);\n\tkfree(inst);\n}\n\nstatic struct crypto_template crypto_ccm_tmpl = {\n\t.name = \"ccm\",\n\t.alloc = crypto_ccm_alloc,\n\t.free = crypto_ccm_free,\n\t.module = THIS_MODULE,\n};\n\nstatic struct crypto_instance *crypto_ccm_base_alloc(struct rtattr **tb)\n{\n\tconst char *ctr_name;\n\tconst char *cipher_name;\n\tchar full_name[CRYPTO_MAX_ALG_NAME];\n\n\tctr_name = crypto_attr_alg_name(tb[1]);\n\tif (IS_ERR(ctr_name))\n\t\treturn ERR_CAST(ctr_name);\n\n\tcipher_name = crypto_attr_alg_name(tb[2]);\n\tif (IS_ERR(cipher_name))\n\t\treturn ERR_CAST(cipher_name);\n\n\tif (snprintf(full_name, CRYPTO_MAX_ALG_NAME, \"ccm_base(%s,%s)\",\n\t\t     ctr_name, cipher_name) >= CRYPTO_MAX_ALG_NAME)\n\t\treturn ERR_PTR(-ENAMETOOLONG);\n\n\treturn crypto_ccm_alloc_common(tb, full_name, ctr_name, cipher_name);\n}\n\nstatic struct crypto_template crypto_ccm_base_tmpl = {\n\t.name = \"ccm_base\",\n\t.alloc = crypto_ccm_base_alloc,\n\t.free = crypto_ccm_free,\n\t.module = THIS_MODULE,\n};\n\nstatic int crypto_rfc4309_setkey(struct crypto_aead *parent, const u8 *key,\n\t\t\t\t unsigned int keylen)\n{\n\tstruct crypto_rfc4309_ctx *ctx = crypto_aead_ctx(parent);\n\tstruct crypto_aead *child = ctx->child;\n\tint err;\n\n\tif (keylen < 3)\n\t\treturn -EINVAL;\n\n\tkeylen -= 3;\n\tmemcpy(ctx->nonce, key + keylen, 3);\n\n\tcrypto_aead_clear_flags(child, CRYPTO_TFM_REQ_MASK);\n\tcrypto_aead_set_flags(child, crypto_aead_get_flags(parent) &\n\t\t\t\t     CRYPTO_TFM_REQ_MASK);\n\terr = crypto_aead_setkey(child, key, keylen);\n\tcrypto_aead_set_flags(parent, crypto_aead_get_flags(child) &\n\t\t\t\t      CRYPTO_TFM_RES_MASK);\n\n\treturn err;\n}\n\nstatic int crypto_rfc4309_setauthsize(struct crypto_aead *parent,\n\t\t\t\t      unsigned int authsize)\n{\n\tstruct crypto_rfc4309_ctx *ctx = crypto_aead_ctx(parent);\n\n\tswitch (authsize) {\n\tcase 8:\n\tcase 12:\n\tcase 16:\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn crypto_aead_setauthsize(ctx->child, authsize);\n}\n\nstatic struct aead_request *crypto_rfc4309_crypt(struct aead_request *req)\n{\n\tstruct aead_request *subreq = aead_request_ctx(req);\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_rfc4309_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct crypto_aead *child = ctx->child;\n\tu8 *iv = PTR_ALIGN((u8 *)(subreq + 1) + crypto_aead_reqsize(child),\n\t\t\t   crypto_aead_alignmask(child) + 1);\n\n\t/* L' */\n\tiv[0] = 3;\n\n\tmemcpy(iv + 1, ctx->nonce, 3);\n\tmemcpy(iv + 4, req->iv, 8);\n\n\taead_request_set_tfm(subreq, child);\n\taead_request_set_callback(subreq, req->base.flags, req->base.complete,\n\t\t\t\t  req->base.data);\n\taead_request_set_crypt(subreq, req->src, req->dst, req->cryptlen, iv);\n\taead_request_set_assoc(subreq, req->assoc, req->assoclen);\n\n\treturn subreq;\n}\n\nstatic int crypto_rfc4309_encrypt(struct aead_request *req)\n{\n\treq = crypto_rfc4309_crypt(req);\n\n\treturn crypto_aead_encrypt(req);\n}\n\nstatic int crypto_rfc4309_decrypt(struct aead_request *req)\n{\n\treq = crypto_rfc4309_crypt(req);\n\n\treturn crypto_aead_decrypt(req);\n}\n\nstatic int crypto_rfc4309_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_instance *inst = (void *)tfm->__crt_alg;\n\tstruct crypto_aead_spawn *spawn = crypto_instance_ctx(inst);\n\tstruct crypto_rfc4309_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_aead *aead;\n\tunsigned long align;\n\n\taead = crypto_spawn_aead(spawn);\n\tif (IS_ERR(aead))\n\t\treturn PTR_ERR(aead);\n\n\tctx->child = aead;\n\n\talign = crypto_aead_alignmask(aead);\n\talign &= ~(crypto_tfm_ctx_alignment() - 1);\n\ttfm->crt_aead.reqsize = sizeof(struct aead_request) +\n\t\t\t\tALIGN(crypto_aead_reqsize(aead),\n\t\t\t\t      crypto_tfm_ctx_alignment()) +\n\t\t\t\talign + 16;\n\n\treturn 0;\n}\n\nstatic void crypto_rfc4309_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_rfc4309_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_aead(ctx->child);\n}\n\nstatic struct crypto_instance *crypto_rfc4309_alloc(struct rtattr **tb)\n{\n\tstruct crypto_attr_type *algt;\n\tstruct crypto_instance *inst;\n\tstruct crypto_aead_spawn *spawn;\n\tstruct crypto_alg *alg;\n\tconst char *ccm_name;\n\tint err;\n\n\talgt = crypto_get_attr_type(tb);\n\tif (IS_ERR(algt))\n\t\treturn ERR_CAST(algt);\n\n\tif ((algt->type ^ CRYPTO_ALG_TYPE_AEAD) & algt->mask)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tccm_name = crypto_attr_alg_name(tb[1]);\n\tif (IS_ERR(ccm_name))\n\t\treturn ERR_CAST(ccm_name);\n\n\tinst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);\n\tif (!inst)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tspawn = crypto_instance_ctx(inst);\n\tcrypto_set_aead_spawn(spawn, inst);\n\terr = crypto_grab_aead(spawn, ccm_name, 0,\n\t\t\t       crypto_requires_sync(algt->type, algt->mask));\n\tif (err)\n\t\tgoto out_free_inst;\n\n\talg = crypto_aead_spawn_alg(spawn);\n\n\terr = -EINVAL;\n\n\t/* We only support 16-byte blocks. */\n\tif (alg->cra_aead.ivsize != 16)\n\t\tgoto out_drop_alg;\n\n\t/* Not a stream cipher? */\n\tif (alg->cra_blocksize != 1)\n\t\tgoto out_drop_alg;\n\n\terr = -ENAMETOOLONG;\n\tif (snprintf(inst->alg.cra_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"rfc4309(%s)\", alg->cra_name) >= CRYPTO_MAX_ALG_NAME ||\n\t    snprintf(inst->alg.cra_driver_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"rfc4309(%s)\", alg->cra_driver_name) >=\n\t    CRYPTO_MAX_ALG_NAME)\n\t\tgoto out_drop_alg;\n\n\tinst->alg.cra_flags = CRYPTO_ALG_TYPE_AEAD;\n\tinst->alg.cra_flags |= alg->cra_flags & CRYPTO_ALG_ASYNC;\n\tinst->alg.cra_priority = alg->cra_priority;\n\tinst->alg.cra_blocksize = 1;\n\tinst->alg.cra_alignmask = alg->cra_alignmask;\n\tinst->alg.cra_type = &crypto_nivaead_type;\n\n\tinst->alg.cra_aead.ivsize = 8;\n\tinst->alg.cra_aead.maxauthsize = 16;\n\n\tinst->alg.cra_ctxsize = sizeof(struct crypto_rfc4309_ctx);\n\n\tinst->alg.cra_init = crypto_rfc4309_init_tfm;\n\tinst->alg.cra_exit = crypto_rfc4309_exit_tfm;\n\n\tinst->alg.cra_aead.setkey = crypto_rfc4309_setkey;\n\tinst->alg.cra_aead.setauthsize = crypto_rfc4309_setauthsize;\n\tinst->alg.cra_aead.encrypt = crypto_rfc4309_encrypt;\n\tinst->alg.cra_aead.decrypt = crypto_rfc4309_decrypt;\n\n\tinst->alg.cra_aead.geniv = \"seqiv\";\n\nout:\n\treturn inst;\n\nout_drop_alg:\n\tcrypto_drop_aead(spawn);\nout_free_inst:\n\tkfree(inst);\n\tinst = ERR_PTR(err);\n\tgoto out;\n}\n\nstatic void crypto_rfc4309_free(struct crypto_instance *inst)\n{\n\tcrypto_drop_spawn(crypto_instance_ctx(inst));\n\tkfree(inst);\n}\n\nstatic struct crypto_template crypto_rfc4309_tmpl = {\n\t.name = \"rfc4309\",\n\t.alloc = crypto_rfc4309_alloc,\n\t.free = crypto_rfc4309_free,\n\t.module = THIS_MODULE,\n};\n\nstatic int __init crypto_ccm_module_init(void)\n{\n\tint err;\n\n\terr = crypto_register_template(&crypto_ccm_base_tmpl);\n\tif (err)\n\t\tgoto out;\n\n\terr = crypto_register_template(&crypto_ccm_tmpl);\n\tif (err)\n\t\tgoto out_undo_base;\n\n\terr = crypto_register_template(&crypto_rfc4309_tmpl);\n\tif (err)\n\t\tgoto out_undo_ccm;\n\nout:\n\treturn err;\n\nout_undo_ccm:\n\tcrypto_unregister_template(&crypto_ccm_tmpl);\nout_undo_base:\n\tcrypto_unregister_template(&crypto_ccm_base_tmpl);\n\tgoto out;\n}\n\nstatic void __exit crypto_ccm_module_exit(void)\n{\n\tcrypto_unregister_template(&crypto_rfc4309_tmpl);\n\tcrypto_unregister_template(&crypto_ccm_tmpl);\n\tcrypto_unregister_template(&crypto_ccm_base_tmpl);\n}\n\nmodule_init(crypto_ccm_module_init);\nmodule_exit(crypto_ccm_module_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Counter with CBC MAC\");\nMODULE_ALIAS(\"ccm_base\");\nMODULE_ALIAS(\"rfc4309\");\n", "/* GPL HEADER START\n *\n * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License version 2 only,\n * as published by the Free Software Foundation.\n *\n * This program is distributed in the hope that it will be useful, but\n * WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * General Public License version 2 for more details (a copy is included\n * in the LICENSE file that accompanied this code).\n *\n * You should have received a copy of the GNU General Public License\n * version 2 along with this program; If not, see http://www.gnu.org/licenses\n *\n * Please  visit http://www.xyratex.com/contact if you need additional\n * information or have any questions.\n *\n * GPL HEADER END\n */\n\n/*\n * Copyright 2012 Xyratex Technology Limited\n */\n\n/*\n * This is crypto api shash wrappers to crc32_le.\n */\n\n#include <linux/crc32.h>\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\n#define CHKSUM_BLOCK_SIZE\t1\n#define CHKSUM_DIGEST_SIZE\t4\n\nstatic u32 __crc32_le(u32 crc, unsigned char const *p, size_t len)\n{\n\treturn crc32_le(crc, p, len);\n}\n\n/** No default init with ~0 */\nstatic int crc32_cra_init(struct crypto_tfm *tfm)\n{\n\tu32 *key = crypto_tfm_ctx(tfm);\n\n\t*key = 0;\n\n\treturn 0;\n}\n\n\n/*\n * Setting the seed allows arbitrary accumulators and flexible XOR policy\n * If your algorithm starts with ~0, then XOR with ~0 before you set\n * the seed.\n */\nstatic int crc32_setkey(struct crypto_shash *hash, const u8 *key,\n\t\t\tunsigned int keylen)\n{\n\tu32 *mctx = crypto_shash_ctx(hash);\n\n\tif (keylen != sizeof(u32)) {\n\t\tcrypto_shash_set_flags(hash, CRYPTO_TFM_RES_BAD_KEY_LEN);\n\t\treturn -EINVAL;\n\t}\n\t*mctx = le32_to_cpup((__le32 *)key);\n\treturn 0;\n}\n\nstatic int crc32_init(struct shash_desc *desc)\n{\n\tu32 *mctx = crypto_shash_ctx(desc->tfm);\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t*crcp = *mctx;\n\n\treturn 0;\n}\n\nstatic int crc32_update(struct shash_desc *desc, const u8 *data,\n\t\t\tunsigned int len)\n{\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t*crcp = __crc32_le(*crcp, data, len);\n\treturn 0;\n}\n\n/* No final XOR 0xFFFFFFFF, like crc32_le */\nstatic int __crc32_finup(u32 *crcp, const u8 *data, unsigned int len,\n\t\t\t u8 *out)\n{\n\t*(__le32 *)out = cpu_to_le32(__crc32_le(*crcp, data, len));\n\treturn 0;\n}\n\nstatic int crc32_finup(struct shash_desc *desc, const u8 *data,\n\t\t       unsigned int len, u8 *out)\n{\n\treturn __crc32_finup(shash_desc_ctx(desc), data, len, out);\n}\n\nstatic int crc32_final(struct shash_desc *desc, u8 *out)\n{\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t*(__le32 *)out = cpu_to_le32p(crcp);\n\treturn 0;\n}\n\nstatic int crc32_digest(struct shash_desc *desc, const u8 *data,\n\t\t\tunsigned int len, u8 *out)\n{\n\treturn __crc32_finup(crypto_shash_ctx(desc->tfm), data, len,\n\t\t\t     out);\n}\nstatic struct shash_alg alg = {\n\t.setkey\t\t= crc32_setkey,\n\t.init\t\t= crc32_init,\n\t.update\t\t= crc32_update,\n\t.final\t\t= crc32_final,\n\t.finup\t\t= crc32_finup,\n\t.digest\t\t= crc32_digest,\n\t.descsize\t= sizeof(u32),\n\t.digestsize\t= CHKSUM_DIGEST_SIZE,\n\t.base\t\t= {\n\t\t.cra_name\t\t= \"crc32\",\n\t\t.cra_driver_name\t= \"crc32-table\",\n\t\t.cra_priority\t\t= 100,\n\t\t.cra_blocksize\t\t= CHKSUM_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t= sizeof(u32),\n\t\t.cra_module\t\t= THIS_MODULE,\n\t\t.cra_init\t\t= crc32_cra_init,\n\t}\n};\n\nstatic int __init crc32_mod_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit crc32_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(crc32_mod_init);\nmodule_exit(crc32_mod_fini);\n\nMODULE_AUTHOR(\"Alexander Boyko <alexander_boyko@xyratex.com>\");\nMODULE_DESCRIPTION(\"CRC32 calculations wrapper for lib/crc32\");\nMODULE_LICENSE(\"GPL\");\n", "/*\n * Cryptographic API.\n *\n * CRC32C chksum\n *\n *@Article{castagnoli-crc,\n * author =       { Guy Castagnoli and Stefan Braeuer and Martin Herrman},\n * title =        {{Optimization of Cyclic Redundancy-Check Codes with 24\n *                 and 32 Parity Bits}},\n * journal =      IEEE Transactions on Communication,\n * year =         {1993},\n * volume =       {41},\n * number =       {6},\n * pages =        {},\n * month =        {June},\n *}\n * Used by the iSCSI driver, possibly others, and derived from the\n * the iscsi-crc.c module of the linux-iscsi driver at\n * http://linux-iscsi.sourceforge.net.\n *\n * Following the example of lib/crc32, this function is intended to be\n * flexible and useful for all users.  Modules that currently have their\n * own crc32c, but hopefully may be able to use this one are:\n *  net/sctp (please add all your doco to here if you change to\n *            use this one!)\n *  <endoflist>\n *\n * Copyright (c) 2004 Cisco Systems, Inc.\n * Copyright (c) 2008 Herbert Xu <herbert@gondor.apana.org.au>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n#include <linux/crc32.h>\n\n#define CHKSUM_BLOCK_SIZE\t1\n#define CHKSUM_DIGEST_SIZE\t4\n\nstruct chksum_ctx {\n\tu32 key;\n};\n\nstruct chksum_desc_ctx {\n\tu32 crc;\n};\n\n/*\n * Steps through buffer one byte at at time, calculates reflected\n * crc using table.\n */\n\nstatic int chksum_init(struct shash_desc *desc)\n{\n\tstruct chksum_ctx *mctx = crypto_shash_ctx(desc->tfm);\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\tctx->crc = mctx->key;\n\n\treturn 0;\n}\n\n/*\n * Setting the seed allows arbitrary accumulators and flexible XOR policy\n * If your algorithm starts with ~0, then XOR with ~0 before you set\n * the seed.\n */\nstatic int chksum_setkey(struct crypto_shash *tfm, const u8 *key,\n\t\t\t unsigned int keylen)\n{\n\tstruct chksum_ctx *mctx = crypto_shash_ctx(tfm);\n\n\tif (keylen != sizeof(mctx->key)) {\n\t\tcrypto_shash_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);\n\t\treturn -EINVAL;\n\t}\n\tmctx->key = le32_to_cpu(*(__le32 *)key);\n\treturn 0;\n}\n\nstatic int chksum_update(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int length)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\tctx->crc = __crc32c_le(ctx->crc, data, length);\n\treturn 0;\n}\n\nstatic int chksum_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\t*(__le32 *)out = ~cpu_to_le32p(&ctx->crc);\n\treturn 0;\n}\n\nstatic int __chksum_finup(u32 *crcp, const u8 *data, unsigned int len, u8 *out)\n{\n\t*(__le32 *)out = ~cpu_to_le32(__crc32c_le(*crcp, data, len));\n\treturn 0;\n}\n\nstatic int chksum_finup(struct shash_desc *desc, const u8 *data,\n\t\t\tunsigned int len, u8 *out)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\treturn __chksum_finup(&ctx->crc, data, len, out);\n}\n\nstatic int chksum_digest(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int length, u8 *out)\n{\n\tstruct chksum_ctx *mctx = crypto_shash_ctx(desc->tfm);\n\n\treturn __chksum_finup(&mctx->key, data, length, out);\n}\n\nstatic int crc32c_cra_init(struct crypto_tfm *tfm)\n{\n\tstruct chksum_ctx *mctx = crypto_tfm_ctx(tfm);\n\n\tmctx->key = ~0;\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t\t=\tCHKSUM_DIGEST_SIZE,\n\t.setkey\t\t\t=\tchksum_setkey,\n\t.init\t\t=\tchksum_init,\n\t.update\t\t=\tchksum_update,\n\t.final\t\t=\tchksum_final,\n\t.finup\t\t=\tchksum_finup,\n\t.digest\t\t=\tchksum_digest,\n\t.descsize\t\t=\tsizeof(struct chksum_desc_ctx),\n\t.base\t\t\t=\t{\n\t\t.cra_name\t\t=\t\"crc32c\",\n\t\t.cra_driver_name\t=\t\"crc32c-generic\",\n\t\t.cra_priority\t\t=\t100,\n\t\t.cra_blocksize\t\t=\tCHKSUM_BLOCK_SIZE,\n\t\t.cra_alignmask\t\t=\t3,\n\t\t.cra_ctxsize\t\t=\tsizeof(struct chksum_ctx),\n\t\t.cra_module\t\t=\tTHIS_MODULE,\n\t\t.cra_init\t\t=\tcrc32c_cra_init,\n\t}\n};\n\nstatic int __init crc32c_mod_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit crc32c_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(crc32c_mod_init);\nmodule_exit(crc32c_mod_fini);\n\nMODULE_AUTHOR(\"Clay Haapala <chaapala@cisco.com>\");\nMODULE_DESCRIPTION(\"CRC32c (Castagnoli) calculations wrapper for lib/crc32c\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS(\"crc32c\");\nMODULE_SOFTDEP(\"pre: crc32c\");\n", "/*\n * Cryptographic API.\n *\n * T10 Data Integrity Field CRC16 Crypto Transform\n *\n * Copyright (c) 2007 Oracle Corporation.  All rights reserved.\n * Written by Martin K. Petersen <martin.petersen@oracle.com>\n * Copyright (C) 2013 Intel Corporation\n * Author: Tim Chen <tim.c.chen@linux.intel.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS\n * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n * SOFTWARE.\n *\n */\n\n#include <linux/module.h>\n#include <linux/crc-t10dif.h>\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n\nstruct chksum_desc_ctx {\n\t__u16 crc;\n};\n\n/*\n * Steps through buffer one byte at at time, calculates reflected\n * crc using table.\n */\n\nstatic int chksum_init(struct shash_desc *desc)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\tctx->crc = 0;\n\n\treturn 0;\n}\n\nstatic int chksum_update(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int length)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\tctx->crc = crc_t10dif_generic(ctx->crc, data, length);\n\treturn 0;\n}\n\nstatic int chksum_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\t*(__u16 *)out = ctx->crc;\n\treturn 0;\n}\n\nstatic int __chksum_finup(__u16 *crcp, const u8 *data, unsigned int len,\n\t\t\tu8 *out)\n{\n\t*(__u16 *)out = crc_t10dif_generic(*crcp, data, len);\n\treturn 0;\n}\n\nstatic int chksum_finup(struct shash_desc *desc, const u8 *data,\n\t\t\tunsigned int len, u8 *out)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\treturn __chksum_finup(&ctx->crc, data, len, out);\n}\n\nstatic int chksum_digest(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int length, u8 *out)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\treturn __chksum_finup(&ctx->crc, data, length, out);\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t\t=\tCRC_T10DIF_DIGEST_SIZE,\n\t.init\t\t=\tchksum_init,\n\t.update\t\t=\tchksum_update,\n\t.final\t\t=\tchksum_final,\n\t.finup\t\t=\tchksum_finup,\n\t.digest\t\t=\tchksum_digest,\n\t.descsize\t\t=\tsizeof(struct chksum_desc_ctx),\n\t.base\t\t\t=\t{\n\t\t.cra_name\t\t=\t\"crct10dif\",\n\t\t.cra_driver_name\t=\t\"crct10dif-generic\",\n\t\t.cra_priority\t\t=\t100,\n\t\t.cra_blocksize\t\t=\tCRC_T10DIF_BLOCK_SIZE,\n\t\t.cra_module\t\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init crct10dif_mod_init(void)\n{\n\tint ret;\n\n\tret = crypto_register_shash(&alg);\n\treturn ret;\n}\n\nstatic void __exit crct10dif_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(crct10dif_mod_init);\nmodule_exit(crct10dif_mod_fini);\n\nMODULE_AUTHOR(\"Tim Chen <tim.c.chen@linux.intel.com>\");\nMODULE_DESCRIPTION(\"T10 DIF CRC calculation.\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS(\"crct10dif\");\n", "/*\n * Cryptographic API.\n *\n * Null algorithms, aka Much Ado About Nothing.\n *\n * These are needed for IPsec, and may be useful in general for\n * testing & debugging.\n *\n * The null cipher is compliant with RFC2410.\n *\n * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n\n#include <crypto/null.h>\n#include <crypto/internal/hash.h>\n#include <crypto/internal/skcipher.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n\nstatic int null_compress(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t unsigned int slen, u8 *dst, unsigned int *dlen)\n{\n\tif (slen > *dlen)\n\t\treturn -EINVAL;\n\tmemcpy(dst, src, slen);\n\t*dlen = slen;\n\treturn 0;\n}\n\nstatic int null_init(struct shash_desc *desc)\n{\n\treturn 0;\n}\n\nstatic int null_update(struct shash_desc *desc, const u8 *data,\n\t\t       unsigned int len)\n{\n\treturn 0;\n}\n\nstatic int null_final(struct shash_desc *desc, u8 *out)\n{\n\treturn 0;\n}\n\nstatic int null_digest(struct shash_desc *desc, const u8 *data,\n\t\t       unsigned int len, u8 *out)\n{\n\treturn 0;\n}\n\nstatic int null_hash_setkey(struct crypto_shash *tfm, const u8 *key,\n\t\t\t    unsigned int keylen)\n{ return 0; }\n\nstatic int null_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t       unsigned int keylen)\n{ return 0; }\n\nstatic void null_crypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tmemcpy(dst, src, NULL_BLOCK_SIZE);\n}\n\nstatic int skcipher_null_crypt(struct blkcipher_desc *desc,\n\t\t\t       struct scatterlist *dst,\n\t\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\twhile (walk.nbytes) {\n\t\tif (walk.src.virt.addr != walk.dst.virt.addr)\n\t\t\tmemcpy(walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t       walk.nbytes);\n\t\terr = blkcipher_walk_done(desc, &walk, 0);\n\t}\n\n\treturn err;\n}\n\nstatic struct shash_alg digest_null = {\n\t.digestsize\t\t=\tNULL_DIGEST_SIZE,\n\t.setkey   \t\t=\tnull_hash_setkey,\n\t.init   \t\t=\tnull_init,\n\t.update \t\t=\tnull_update,\n\t.finup \t\t\t=\tnull_digest,\n\t.digest \t\t=\tnull_digest,\n\t.final  \t\t=\tnull_final,\n\t.base\t\t\t=\t{\n\t\t.cra_name\t\t=\t\"digest_null\",\n\t\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t\t=\tNULL_BLOCK_SIZE,\n\t\t.cra_module\t\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic struct crypto_alg null_algs[3] = { {\n\t.cra_name\t\t=\t\"cipher_null\",\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tNULL_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\t0,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\tNULL_KEY_SIZE,\n\t.cia_max_keysize\t=\tNULL_KEY_SIZE,\n\t.cia_setkey\t\t= \tnull_setkey,\n\t.cia_encrypt\t\t=\tnull_crypt,\n\t.cia_decrypt\t\t=\tnull_crypt } }\n}, {\n\t.cra_name\t\t=\t\"ecb(cipher_null)\",\n\t.cra_driver_name\t=\t\"ecb-cipher_null\",\n\t.cra_priority\t\t=\t100,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t=\tNULL_BLOCK_SIZE,\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_ctxsize\t\t=\t0,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{ .blkcipher = {\n\t.min_keysize\t\t=\tNULL_KEY_SIZE,\n\t.max_keysize\t\t=\tNULL_KEY_SIZE,\n\t.ivsize\t\t\t=\tNULL_IV_SIZE,\n\t.setkey\t\t\t= \tnull_setkey,\n\t.encrypt\t\t=\tskcipher_null_crypt,\n\t.decrypt\t\t=\tskcipher_null_crypt } }\n}, {\n\t.cra_name\t\t=\t\"compress_null\",\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_COMPRESS,\n\t.cra_blocksize\t\t=\tNULL_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\t0,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{ .compress = {\n\t.coa_compress\t\t=\tnull_compress,\n\t.coa_decompress\t\t=\tnull_compress } }\n} };\n\nMODULE_ALIAS(\"compress_null\");\nMODULE_ALIAS(\"digest_null\");\nMODULE_ALIAS(\"cipher_null\");\n\nstatic int __init crypto_null_mod_init(void)\n{\n\tint ret = 0;\n\n\tret = crypto_register_algs(null_algs, ARRAY_SIZE(null_algs));\n\tif (ret < 0)\n\t\tgoto out;\n\n\tret = crypto_register_shash(&digest_null);\n\tif (ret < 0)\n\t\tgoto out_unregister_algs;\n\n\treturn 0;\n\nout_unregister_algs:\n\tcrypto_unregister_algs(null_algs, ARRAY_SIZE(null_algs));\nout:\n\treturn ret;\n}\n\nstatic void __exit crypto_null_mod_fini(void)\n{\n\tcrypto_unregister_shash(&digest_null);\n\tcrypto_unregister_algs(null_algs, ARRAY_SIZE(null_algs));\n}\n\nmodule_init(crypto_null_mod_init);\nmodule_exit(crypto_null_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Null Cryptographic Algorithms\");\n", "/*\n * CTR: Counter mode\n *\n * (C) Copyright IBM Corp. 2007 - Joy Latten <latten@us.ibm.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#include <crypto/algapi.h>\n#include <crypto/ctr.h>\n#include <crypto/internal/skcipher.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/random.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n\nstruct crypto_ctr_ctx {\n\tstruct crypto_cipher *child;\n};\n\nstruct crypto_rfc3686_ctx {\n\tstruct crypto_ablkcipher *child;\n\tu8 nonce[CTR_RFC3686_NONCE_SIZE];\n};\n\nstruct crypto_rfc3686_req_ctx {\n\tu8 iv[CTR_RFC3686_BLOCK_SIZE];\n\tstruct ablkcipher_request subreq CRYPTO_MINALIGN_ATTR;\n};\n\nstatic int crypto_ctr_setkey(struct crypto_tfm *parent, const u8 *key,\n\t\t\t     unsigned int keylen)\n{\n\tstruct crypto_ctr_ctx *ctx = crypto_tfm_ctx(parent);\n\tstruct crypto_cipher *child = ctx->child;\n\tint err;\n\n\tcrypto_cipher_clear_flags(child, CRYPTO_TFM_REQ_MASK);\n\tcrypto_cipher_set_flags(child, crypto_tfm_get_flags(parent) &\n\t\t\t\tCRYPTO_TFM_REQ_MASK);\n\terr = crypto_cipher_setkey(child, key, keylen);\n\tcrypto_tfm_set_flags(parent, crypto_cipher_get_flags(child) &\n\t\t\t     CRYPTO_TFM_RES_MASK);\n\n\treturn err;\n}\n\nstatic void crypto_ctr_crypt_final(struct blkcipher_walk *walk,\n\t\t\t\t   struct crypto_cipher *tfm)\n{\n\tunsigned int bsize = crypto_cipher_blocksize(tfm);\n\tunsigned long alignmask = crypto_cipher_alignmask(tfm);\n\tu8 *ctrblk = walk->iv;\n\tu8 tmp[bsize + alignmask];\n\tu8 *keystream = PTR_ALIGN(tmp + 0, alignmask + 1);\n\tu8 *src = walk->src.virt.addr;\n\tu8 *dst = walk->dst.virt.addr;\n\tunsigned int nbytes = walk->nbytes;\n\n\tcrypto_cipher_encrypt_one(tfm, keystream, ctrblk);\n\tcrypto_xor(keystream, src, nbytes);\n\tmemcpy(dst, keystream, nbytes);\n\n\tcrypto_inc(ctrblk, bsize);\n}\n\nstatic int crypto_ctr_crypt_segment(struct blkcipher_walk *walk,\n\t\t\t\t    struct crypto_cipher *tfm)\n{\n\tvoid (*fn)(struct crypto_tfm *, u8 *, const u8 *) =\n\t\t   crypto_cipher_alg(tfm)->cia_encrypt;\n\tunsigned int bsize = crypto_cipher_blocksize(tfm);\n\tu8 *ctrblk = walk->iv;\n\tu8 *src = walk->src.virt.addr;\n\tu8 *dst = walk->dst.virt.addr;\n\tunsigned int nbytes = walk->nbytes;\n\n\tdo {\n\t\t/* create keystream */\n\t\tfn(crypto_cipher_tfm(tfm), dst, ctrblk);\n\t\tcrypto_xor(dst, src, bsize);\n\n\t\t/* increment counter in counterblock */\n\t\tcrypto_inc(ctrblk, bsize);\n\n\t\tsrc += bsize;\n\t\tdst += bsize;\n\t} while ((nbytes -= bsize) >= bsize);\n\n\treturn nbytes;\n}\n\nstatic int crypto_ctr_crypt_inplace(struct blkcipher_walk *walk,\n\t\t\t\t    struct crypto_cipher *tfm)\n{\n\tvoid (*fn)(struct crypto_tfm *, u8 *, const u8 *) =\n\t\t   crypto_cipher_alg(tfm)->cia_encrypt;\n\tunsigned int bsize = crypto_cipher_blocksize(tfm);\n\tunsigned long alignmask = crypto_cipher_alignmask(tfm);\n\tunsigned int nbytes = walk->nbytes;\n\tu8 *ctrblk = walk->iv;\n\tu8 *src = walk->src.virt.addr;\n\tu8 tmp[bsize + alignmask];\n\tu8 *keystream = PTR_ALIGN(tmp + 0, alignmask + 1);\n\n\tdo {\n\t\t/* create keystream */\n\t\tfn(crypto_cipher_tfm(tfm), keystream, ctrblk);\n\t\tcrypto_xor(src, keystream, bsize);\n\n\t\t/* increment counter in counterblock */\n\t\tcrypto_inc(ctrblk, bsize);\n\n\t\tsrc += bsize;\n\t} while ((nbytes -= bsize) >= bsize);\n\n\treturn nbytes;\n}\n\nstatic int crypto_ctr_crypt(struct blkcipher_desc *desc,\n\t\t\t      struct scatterlist *dst, struct scatterlist *src,\n\t\t\t      unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\tstruct crypto_blkcipher *tfm = desc->tfm;\n\tstruct crypto_ctr_ctx *ctx = crypto_blkcipher_ctx(tfm);\n\tstruct crypto_cipher *child = ctx->child;\n\tunsigned int bsize = crypto_cipher_blocksize(child);\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt_block(desc, &walk, bsize);\n\n\twhile (walk.nbytes >= bsize) {\n\t\tif (walk.src.virt.addr == walk.dst.virt.addr)\n\t\t\tnbytes = crypto_ctr_crypt_inplace(&walk, child);\n\t\telse\n\t\t\tnbytes = crypto_ctr_crypt_segment(&walk, child);\n\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\n\tif (walk.nbytes) {\n\t\tcrypto_ctr_crypt_final(&walk, child);\n\t\terr = blkcipher_walk_done(desc, &walk, 0);\n\t}\n\n\treturn err;\n}\n\nstatic int crypto_ctr_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_instance *inst = (void *)tfm->__crt_alg;\n\tstruct crypto_spawn *spawn = crypto_instance_ctx(inst);\n\tstruct crypto_ctr_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_cipher *cipher;\n\n\tcipher = crypto_spawn_cipher(spawn);\n\tif (IS_ERR(cipher))\n\t\treturn PTR_ERR(cipher);\n\n\tctx->child = cipher;\n\n\treturn 0;\n}\n\nstatic void crypto_ctr_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_ctr_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_cipher(ctx->child);\n}\n\nstatic struct crypto_instance *crypto_ctr_alloc(struct rtattr **tb)\n{\n\tstruct crypto_instance *inst;\n\tstruct crypto_alg *alg;\n\tint err;\n\n\terr = crypto_check_attr_type(tb, CRYPTO_ALG_TYPE_BLKCIPHER);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\talg = crypto_attr_alg(tb[1], CRYPTO_ALG_TYPE_CIPHER,\n\t\t\t\t  CRYPTO_ALG_TYPE_MASK);\n\tif (IS_ERR(alg))\n\t\treturn ERR_CAST(alg);\n\n\t/* Block size must be >= 4 bytes. */\n\terr = -EINVAL;\n\tif (alg->cra_blocksize < 4)\n\t\tgoto out_put_alg;\n\n\t/* If this is false we'd fail the alignment of crypto_inc. */\n\tif (alg->cra_blocksize % 4)\n\t\tgoto out_put_alg;\n\n\tinst = crypto_alloc_instance(\"ctr\", alg);\n\tif (IS_ERR(inst))\n\t\tgoto out;\n\n\tinst->alg.cra_flags = CRYPTO_ALG_TYPE_BLKCIPHER;\n\tinst->alg.cra_priority = alg->cra_priority;\n\tinst->alg.cra_blocksize = 1;\n\tinst->alg.cra_alignmask = alg->cra_alignmask | (__alignof__(u32) - 1);\n\tinst->alg.cra_type = &crypto_blkcipher_type;\n\n\tinst->alg.cra_blkcipher.ivsize = alg->cra_blocksize;\n\tinst->alg.cra_blkcipher.min_keysize = alg->cra_cipher.cia_min_keysize;\n\tinst->alg.cra_blkcipher.max_keysize = alg->cra_cipher.cia_max_keysize;\n\n\tinst->alg.cra_ctxsize = sizeof(struct crypto_ctr_ctx);\n\n\tinst->alg.cra_init = crypto_ctr_init_tfm;\n\tinst->alg.cra_exit = crypto_ctr_exit_tfm;\n\n\tinst->alg.cra_blkcipher.setkey = crypto_ctr_setkey;\n\tinst->alg.cra_blkcipher.encrypt = crypto_ctr_crypt;\n\tinst->alg.cra_blkcipher.decrypt = crypto_ctr_crypt;\n\n\tinst->alg.cra_blkcipher.geniv = \"chainiv\";\n\nout:\n\tcrypto_mod_put(alg);\n\treturn inst;\n\nout_put_alg:\n\tinst = ERR_PTR(err);\n\tgoto out;\n}\n\nstatic void crypto_ctr_free(struct crypto_instance *inst)\n{\n\tcrypto_drop_spawn(crypto_instance_ctx(inst));\n\tkfree(inst);\n}\n\nstatic struct crypto_template crypto_ctr_tmpl = {\n\t.name = \"ctr\",\n\t.alloc = crypto_ctr_alloc,\n\t.free = crypto_ctr_free,\n\t.module = THIS_MODULE,\n};\n\nstatic int crypto_rfc3686_setkey(struct crypto_ablkcipher *parent,\n\t\t\t\t const u8 *key, unsigned int keylen)\n{\n\tstruct crypto_rfc3686_ctx *ctx = crypto_ablkcipher_ctx(parent);\n\tstruct crypto_ablkcipher *child = ctx->child;\n\tint err;\n\n\t/* the nonce is stored in bytes at end of key */\n\tif (keylen < CTR_RFC3686_NONCE_SIZE)\n\t\treturn -EINVAL;\n\n\tmemcpy(ctx->nonce, key + (keylen - CTR_RFC3686_NONCE_SIZE),\n\t       CTR_RFC3686_NONCE_SIZE);\n\n\tkeylen -= CTR_RFC3686_NONCE_SIZE;\n\n\tcrypto_ablkcipher_clear_flags(child, CRYPTO_TFM_REQ_MASK);\n\tcrypto_ablkcipher_set_flags(child, crypto_ablkcipher_get_flags(parent) &\n\t\t\t\t    CRYPTO_TFM_REQ_MASK);\n\terr = crypto_ablkcipher_setkey(child, key, keylen);\n\tcrypto_ablkcipher_set_flags(parent, crypto_ablkcipher_get_flags(child) &\n\t\t\t\t    CRYPTO_TFM_RES_MASK);\n\n\treturn err;\n}\n\nstatic int crypto_rfc3686_crypt(struct ablkcipher_request *req)\n{\n\tstruct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);\n\tstruct crypto_rfc3686_ctx *ctx = crypto_ablkcipher_ctx(tfm);\n\tstruct crypto_ablkcipher *child = ctx->child;\n\tunsigned long align = crypto_ablkcipher_alignmask(tfm);\n\tstruct crypto_rfc3686_req_ctx *rctx =\n\t\t(void *)PTR_ALIGN((u8 *)ablkcipher_request_ctx(req), align + 1);\n\tstruct ablkcipher_request *subreq = &rctx->subreq;\n\tu8 *iv = rctx->iv;\n\n\t/* set up counter block */\n\tmemcpy(iv, ctx->nonce, CTR_RFC3686_NONCE_SIZE);\n\tmemcpy(iv + CTR_RFC3686_NONCE_SIZE, req->info, CTR_RFC3686_IV_SIZE);\n\n\t/* initialize counter portion of counter block */\n\t*(__be32 *)(iv + CTR_RFC3686_NONCE_SIZE + CTR_RFC3686_IV_SIZE) =\n\t\tcpu_to_be32(1);\n\n\tablkcipher_request_set_tfm(subreq, child);\n\tablkcipher_request_set_callback(subreq, req->base.flags,\n\t\t\t\t\treq->base.complete, req->base.data);\n\tablkcipher_request_set_crypt(subreq, req->src, req->dst, req->nbytes,\n\t\t\t\t     iv);\n\n\treturn crypto_ablkcipher_encrypt(subreq);\n}\n\nstatic int crypto_rfc3686_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_instance *inst = (void *)tfm->__crt_alg;\n\tstruct crypto_skcipher_spawn *spawn = crypto_instance_ctx(inst);\n\tstruct crypto_rfc3686_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_ablkcipher *cipher;\n\tunsigned long align;\n\n\tcipher = crypto_spawn_skcipher(spawn);\n\tif (IS_ERR(cipher))\n\t\treturn PTR_ERR(cipher);\n\n\tctx->child = cipher;\n\n\talign = crypto_tfm_alg_alignmask(tfm);\n\talign &= ~(crypto_tfm_ctx_alignment() - 1);\n\ttfm->crt_ablkcipher.reqsize = align +\n\t\tsizeof(struct crypto_rfc3686_req_ctx) +\n\t\tcrypto_ablkcipher_reqsize(cipher);\n\n\treturn 0;\n}\n\nstatic void crypto_rfc3686_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_rfc3686_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_ablkcipher(ctx->child);\n}\n\nstatic struct crypto_instance *crypto_rfc3686_alloc(struct rtattr **tb)\n{\n\tstruct crypto_attr_type *algt;\n\tstruct crypto_instance *inst;\n\tstruct crypto_alg *alg;\n\tstruct crypto_skcipher_spawn *spawn;\n\tconst char *cipher_name;\n\tint err;\n\n\talgt = crypto_get_attr_type(tb);\n\tif (IS_ERR(algt))\n\t\treturn ERR_CAST(algt);\n\n\tif ((algt->type ^ CRYPTO_ALG_TYPE_BLKCIPHER) & algt->mask)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tcipher_name = crypto_attr_alg_name(tb[1]);\n\tif (IS_ERR(cipher_name))\n\t\treturn ERR_CAST(cipher_name);\n\n\tinst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);\n\tif (!inst)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tspawn = crypto_instance_ctx(inst);\n\n\tcrypto_set_skcipher_spawn(spawn, inst);\n\terr = crypto_grab_skcipher(spawn, cipher_name, 0,\n\t\t\t\t   crypto_requires_sync(algt->type,\n\t\t\t\t\t\t\talgt->mask));\n\tif (err)\n\t\tgoto err_free_inst;\n\n\talg = crypto_skcipher_spawn_alg(spawn);\n\n\t/* We only support 16-byte blocks. */\n\terr = -EINVAL;\n\tif (alg->cra_ablkcipher.ivsize != CTR_RFC3686_BLOCK_SIZE)\n\t\tgoto err_drop_spawn;\n\n\t/* Not a stream cipher? */\n\tif (alg->cra_blocksize != 1)\n\t\tgoto err_drop_spawn;\n\n\terr = -ENAMETOOLONG;\n\tif (snprintf(inst->alg.cra_name, CRYPTO_MAX_ALG_NAME, \"rfc3686(%s)\",\n\t\t     alg->cra_name) >= CRYPTO_MAX_ALG_NAME)\n\t\tgoto err_drop_spawn;\n\tif (snprintf(inst->alg.cra_driver_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"rfc3686(%s)\", alg->cra_driver_name) >=\n\t\t\tCRYPTO_MAX_ALG_NAME)\n\t\tgoto err_drop_spawn;\n\n\tinst->alg.cra_priority = alg->cra_priority;\n\tinst->alg.cra_blocksize = 1;\n\tinst->alg.cra_alignmask = alg->cra_alignmask;\n\n\tinst->alg.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\n\t\t\t      (alg->cra_flags & CRYPTO_ALG_ASYNC);\n\tinst->alg.cra_type = &crypto_ablkcipher_type;\n\n\tinst->alg.cra_ablkcipher.ivsize = CTR_RFC3686_IV_SIZE;\n\tinst->alg.cra_ablkcipher.min_keysize =\n\t\talg->cra_ablkcipher.min_keysize + CTR_RFC3686_NONCE_SIZE;\n\tinst->alg.cra_ablkcipher.max_keysize =\n\t\talg->cra_ablkcipher.max_keysize + CTR_RFC3686_NONCE_SIZE;\n\n\tinst->alg.cra_ablkcipher.geniv = \"seqiv\";\n\n\tinst->alg.cra_ablkcipher.setkey = crypto_rfc3686_setkey;\n\tinst->alg.cra_ablkcipher.encrypt = crypto_rfc3686_crypt;\n\tinst->alg.cra_ablkcipher.decrypt = crypto_rfc3686_crypt;\n\n\tinst->alg.cra_ctxsize = sizeof(struct crypto_rfc3686_ctx);\n\n\tinst->alg.cra_init = crypto_rfc3686_init_tfm;\n\tinst->alg.cra_exit = crypto_rfc3686_exit_tfm;\n\n\treturn inst;\n\nerr_drop_spawn:\n\tcrypto_drop_skcipher(spawn);\nerr_free_inst:\n\tkfree(inst);\n\treturn ERR_PTR(err);\n}\n\nstatic void crypto_rfc3686_free(struct crypto_instance *inst)\n{\n\tstruct crypto_skcipher_spawn *spawn = crypto_instance_ctx(inst);\n\n\tcrypto_drop_skcipher(spawn);\n\tkfree(inst);\n}\n\nstatic struct crypto_template crypto_rfc3686_tmpl = {\n\t.name = \"rfc3686\",\n\t.alloc = crypto_rfc3686_alloc,\n\t.free = crypto_rfc3686_free,\n\t.module = THIS_MODULE,\n};\n\nstatic int __init crypto_ctr_module_init(void)\n{\n\tint err;\n\n\terr = crypto_register_template(&crypto_ctr_tmpl);\n\tif (err)\n\t\tgoto out;\n\n\terr = crypto_register_template(&crypto_rfc3686_tmpl);\n\tif (err)\n\t\tgoto out_drop_ctr;\n\nout:\n\treturn err;\n\nout_drop_ctr:\n\tcrypto_unregister_template(&crypto_ctr_tmpl);\n\tgoto out;\n}\n\nstatic void __exit crypto_ctr_module_exit(void)\n{\n\tcrypto_unregister_template(&crypto_rfc3686_tmpl);\n\tcrypto_unregister_template(&crypto_ctr_tmpl);\n}\n\nmodule_init(crypto_ctr_module_init);\nmodule_exit(crypto_ctr_module_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"CTR Counter block mode\");\nMODULE_ALIAS(\"rfc3686\");\n", "/*\n * Cryptographic API.\n *\n * Deflate algorithm (RFC 1951), implemented here primarily for use\n * by IPCOMP (RFC 3173 & RFC 2394).\n *\n * Copyright (c) 2003 James Morris <jmorris@intercode.com.au>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n * FIXME: deflate transforms will require up to a total of about 436k of kernel\n * memory on i386 (390k for compression, the rest for decompression), as the\n * current zlib kernel code uses a worst case pre-allocation system by default.\n * This needs to be fixed so that the amount of memory required is properly\n * related to the  winbits and memlevel parameters.\n *\n * The default winbits of 11 should suit most packets, and it may be something\n * to configure on a per-tfm basis in the future.\n *\n * Currently, compression history is not maintained between tfm calls, as\n * it is not needed for IPCOMP and keeps the code simpler.  It can be\n * implemented if someone wants it.\n */\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/crypto.h>\n#include <linux/zlib.h>\n#include <linux/vmalloc.h>\n#include <linux/interrupt.h>\n#include <linux/mm.h>\n#include <linux/net.h>\n\n#define DEFLATE_DEF_LEVEL\t\tZ_DEFAULT_COMPRESSION\n#define DEFLATE_DEF_WINBITS\t\t11\n#define DEFLATE_DEF_MEMLEVEL\t\tMAX_MEM_LEVEL\n\nstruct deflate_ctx {\n\tstruct z_stream_s comp_stream;\n\tstruct z_stream_s decomp_stream;\n};\n\nstatic int deflate_comp_init(struct deflate_ctx *ctx)\n{\n\tint ret = 0;\n\tstruct z_stream_s *stream = &ctx->comp_stream;\n\n\tstream->workspace = vzalloc(zlib_deflate_workspacesize(\n\t\t\t\t-DEFLATE_DEF_WINBITS, DEFLATE_DEF_MEMLEVEL));\n\tif (!stream->workspace) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tret = zlib_deflateInit2(stream, DEFLATE_DEF_LEVEL, Z_DEFLATED,\n\t                        -DEFLATE_DEF_WINBITS, DEFLATE_DEF_MEMLEVEL,\n\t                        Z_DEFAULT_STRATEGY);\n\tif (ret != Z_OK) {\n\t\tret = -EINVAL;\n\t\tgoto out_free;\n\t}\nout:\n\treturn ret;\nout_free:\n\tvfree(stream->workspace);\n\tgoto out;\n}\n\nstatic int deflate_decomp_init(struct deflate_ctx *ctx)\n{\n\tint ret = 0;\n\tstruct z_stream_s *stream = &ctx->decomp_stream;\n\n\tstream->workspace = vzalloc(zlib_inflate_workspacesize());\n\tif (!stream->workspace) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tret = zlib_inflateInit2(stream, -DEFLATE_DEF_WINBITS);\n\tif (ret != Z_OK) {\n\t\tret = -EINVAL;\n\t\tgoto out_free;\n\t}\nout:\n\treturn ret;\nout_free:\n\tvfree(stream->workspace);\n\tgoto out;\n}\n\nstatic void deflate_comp_exit(struct deflate_ctx *ctx)\n{\n\tzlib_deflateEnd(&ctx->comp_stream);\n\tvfree(ctx->comp_stream.workspace);\n}\n\nstatic void deflate_decomp_exit(struct deflate_ctx *ctx)\n{\n\tzlib_inflateEnd(&ctx->decomp_stream);\n\tvfree(ctx->decomp_stream.workspace);\n}\n\nstatic int deflate_init(struct crypto_tfm *tfm)\n{\n\tstruct deflate_ctx *ctx = crypto_tfm_ctx(tfm);\n\tint ret;\n\n\tret = deflate_comp_init(ctx);\n\tif (ret)\n\t\tgoto out;\n\tret = deflate_decomp_init(ctx);\n\tif (ret)\n\t\tdeflate_comp_exit(ctx);\nout:\n\treturn ret;\n}\n\nstatic void deflate_exit(struct crypto_tfm *tfm)\n{\n\tstruct deflate_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tdeflate_comp_exit(ctx);\n\tdeflate_decomp_exit(ctx);\n}\n\nstatic int deflate_compress(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t    unsigned int slen, u8 *dst, unsigned int *dlen)\n{\n\tint ret = 0;\n\tstruct deflate_ctx *dctx = crypto_tfm_ctx(tfm);\n\tstruct z_stream_s *stream = &dctx->comp_stream;\n\n\tret = zlib_deflateReset(stream);\n\tif (ret != Z_OK) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tstream->next_in = (u8 *)src;\n\tstream->avail_in = slen;\n\tstream->next_out = (u8 *)dst;\n\tstream->avail_out = *dlen;\n\n\tret = zlib_deflate(stream, Z_FINISH);\n\tif (ret != Z_STREAM_END) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\tret = 0;\n\t*dlen = stream->total_out;\nout:\n\treturn ret;\n}\n\nstatic int deflate_decompress(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t      unsigned int slen, u8 *dst, unsigned int *dlen)\n{\n\n\tint ret = 0;\n\tstruct deflate_ctx *dctx = crypto_tfm_ctx(tfm);\n\tstruct z_stream_s *stream = &dctx->decomp_stream;\n\n\tret = zlib_inflateReset(stream);\n\tif (ret != Z_OK) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tstream->next_in = (u8 *)src;\n\tstream->avail_in = slen;\n\tstream->next_out = (u8 *)dst;\n\tstream->avail_out = *dlen;\n\n\tret = zlib_inflate(stream, Z_SYNC_FLUSH);\n\t/*\n\t * Work around a bug in zlib, which sometimes wants to taste an extra\n\t * byte when being used in the (undocumented) raw deflate mode.\n\t * (From USAGI).\n\t */\n\tif (ret == Z_OK && !stream->avail_in && stream->avail_out) {\n\t\tu8 zerostuff = 0;\n\t\tstream->next_in = &zerostuff;\n\t\tstream->avail_in = 1;\n\t\tret = zlib_inflate(stream, Z_FINISH);\n\t}\n\tif (ret != Z_STREAM_END) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\tret = 0;\n\t*dlen = stream->total_out;\nout:\n\treturn ret;\n}\n\nstatic struct crypto_alg alg = {\n\t.cra_name\t\t= \"deflate\",\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_COMPRESS,\n\t.cra_ctxsize\t\t= sizeof(struct deflate_ctx),\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= deflate_init,\n\t.cra_exit\t\t= deflate_exit,\n\t.cra_u\t\t\t= { .compress = {\n\t.coa_compress \t\t= deflate_compress,\n\t.coa_decompress  \t= deflate_decompress } }\n};\n\nstatic int __init deflate_mod_init(void)\n{\n\treturn crypto_register_alg(&alg);\n}\n\nstatic void __exit deflate_mod_fini(void)\n{\n\tcrypto_unregister_alg(&alg);\n}\n\nmodule_init(deflate_mod_init);\nmodule_exit(deflate_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Deflate Compression Algorithm for IPCOMP\");\nMODULE_AUTHOR(\"James Morris <jmorris@intercode.com.au>\");\n\n", "/*\n * Cryptographic API.\n *\n * DES & Triple DES EDE Cipher Algorithms.\n *\n * Copyright (c) 2005 Dag Arne Osvik <da@osvik.no>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n\n#include <asm/byteorder.h>\n#include <linux/bitops.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/crypto.h>\n#include <linux/types.h>\n\n#include <crypto/des.h>\n\n#define ROL(x, r) ((x) = rol32((x), (r)))\n#define ROR(x, r) ((x) = ror32((x), (r)))\n\nstruct des_ctx {\n\tu32 expkey[DES_EXPKEY_WORDS];\n};\n\nstruct des3_ede_ctx {\n\tu32 expkey[DES3_EDE_EXPKEY_WORDS];\n};\n\n/* Lookup tables for key expansion */\n\nstatic const u8 pc1[256] = {\n\t0x00, 0x00, 0x40, 0x04, 0x10, 0x10, 0x50, 0x14,\n\t0x04, 0x40, 0x44, 0x44, 0x14, 0x50, 0x54, 0x54,\n\t0x02, 0x02, 0x42, 0x06, 0x12, 0x12, 0x52, 0x16,\n\t0x06, 0x42, 0x46, 0x46, 0x16, 0x52, 0x56, 0x56,\n\t0x80, 0x08, 0xc0, 0x0c, 0x90, 0x18, 0xd0, 0x1c,\n\t0x84, 0x48, 0xc4, 0x4c, 0x94, 0x58, 0xd4, 0x5c,\n\t0x82, 0x0a, 0xc2, 0x0e, 0x92, 0x1a, 0xd2, 0x1e,\n\t0x86, 0x4a, 0xc6, 0x4e, 0x96, 0x5a, 0xd6, 0x5e,\n\t0x20, 0x20, 0x60, 0x24, 0x30, 0x30, 0x70, 0x34,\n\t0x24, 0x60, 0x64, 0x64, 0x34, 0x70, 0x74, 0x74,\n\t0x22, 0x22, 0x62, 0x26, 0x32, 0x32, 0x72, 0x36,\n\t0x26, 0x62, 0x66, 0x66, 0x36, 0x72, 0x76, 0x76,\n\t0xa0, 0x28, 0xe0, 0x2c, 0xb0, 0x38, 0xf0, 0x3c,\n\t0xa4, 0x68, 0xe4, 0x6c, 0xb4, 0x78, 0xf4, 0x7c,\n\t0xa2, 0x2a, 0xe2, 0x2e, 0xb2, 0x3a, 0xf2, 0x3e,\n\t0xa6, 0x6a, 0xe6, 0x6e, 0xb6, 0x7a, 0xf6, 0x7e,\n\t0x08, 0x80, 0x48, 0x84, 0x18, 0x90, 0x58, 0x94,\n\t0x0c, 0xc0, 0x4c, 0xc4, 0x1c, 0xd0, 0x5c, 0xd4,\n\t0x0a, 0x82, 0x4a, 0x86, 0x1a, 0x92, 0x5a, 0x96,\n\t0x0e, 0xc2, 0x4e, 0xc6, 0x1e, 0xd2, 0x5e, 0xd6,\n\t0x88, 0x88, 0xc8, 0x8c, 0x98, 0x98, 0xd8, 0x9c,\n\t0x8c, 0xc8, 0xcc, 0xcc, 0x9c, 0xd8, 0xdc, 0xdc,\n\t0x8a, 0x8a, 0xca, 0x8e, 0x9a, 0x9a, 0xda, 0x9e,\n\t0x8e, 0xca, 0xce, 0xce, 0x9e, 0xda, 0xde, 0xde,\n\t0x28, 0xa0, 0x68, 0xa4, 0x38, 0xb0, 0x78, 0xb4,\n\t0x2c, 0xe0, 0x6c, 0xe4, 0x3c, 0xf0, 0x7c, 0xf4,\n\t0x2a, 0xa2, 0x6a, 0xa6, 0x3a, 0xb2, 0x7a, 0xb6,\n\t0x2e, 0xe2, 0x6e, 0xe6, 0x3e, 0xf2, 0x7e, 0xf6,\n\t0xa8, 0xa8, 0xe8, 0xac, 0xb8, 0xb8, 0xf8, 0xbc,\n\t0xac, 0xe8, 0xec, 0xec, 0xbc, 0xf8, 0xfc, 0xfc,\n\t0xaa, 0xaa, 0xea, 0xae, 0xba, 0xba, 0xfa, 0xbe,\n\t0xae, 0xea, 0xee, 0xee, 0xbe, 0xfa, 0xfe, 0xfe\n};\n\nstatic const u8 rs[256] = {\n\t0x00, 0x00, 0x80, 0x80, 0x02, 0x02, 0x82, 0x82,\n\t0x04, 0x04, 0x84, 0x84, 0x06, 0x06, 0x86, 0x86,\n\t0x08, 0x08, 0x88, 0x88, 0x0a, 0x0a, 0x8a, 0x8a,\n\t0x0c, 0x0c, 0x8c, 0x8c, 0x0e, 0x0e, 0x8e, 0x8e,\n\t0x10, 0x10, 0x90, 0x90, 0x12, 0x12, 0x92, 0x92,\n\t0x14, 0x14, 0x94, 0x94, 0x16, 0x16, 0x96, 0x96,\n\t0x18, 0x18, 0x98, 0x98, 0x1a, 0x1a, 0x9a, 0x9a,\n\t0x1c, 0x1c, 0x9c, 0x9c, 0x1e, 0x1e, 0x9e, 0x9e,\n\t0x20, 0x20, 0xa0, 0xa0, 0x22, 0x22, 0xa2, 0xa2,\n\t0x24, 0x24, 0xa4, 0xa4, 0x26, 0x26, 0xa6, 0xa6,\n\t0x28, 0x28, 0xa8, 0xa8, 0x2a, 0x2a, 0xaa, 0xaa,\n\t0x2c, 0x2c, 0xac, 0xac, 0x2e, 0x2e, 0xae, 0xae,\n\t0x30, 0x30, 0xb0, 0xb0, 0x32, 0x32, 0xb2, 0xb2,\n\t0x34, 0x34, 0xb4, 0xb4, 0x36, 0x36, 0xb6, 0xb6,\n\t0x38, 0x38, 0xb8, 0xb8, 0x3a, 0x3a, 0xba, 0xba,\n\t0x3c, 0x3c, 0xbc, 0xbc, 0x3e, 0x3e, 0xbe, 0xbe,\n\t0x40, 0x40, 0xc0, 0xc0, 0x42, 0x42, 0xc2, 0xc2,\n\t0x44, 0x44, 0xc4, 0xc4, 0x46, 0x46, 0xc6, 0xc6,\n\t0x48, 0x48, 0xc8, 0xc8, 0x4a, 0x4a, 0xca, 0xca,\n\t0x4c, 0x4c, 0xcc, 0xcc, 0x4e, 0x4e, 0xce, 0xce,\n\t0x50, 0x50, 0xd0, 0xd0, 0x52, 0x52, 0xd2, 0xd2,\n\t0x54, 0x54, 0xd4, 0xd4, 0x56, 0x56, 0xd6, 0xd6,\n\t0x58, 0x58, 0xd8, 0xd8, 0x5a, 0x5a, 0xda, 0xda,\n\t0x5c, 0x5c, 0xdc, 0xdc, 0x5e, 0x5e, 0xde, 0xde,\n\t0x60, 0x60, 0xe0, 0xe0, 0x62, 0x62, 0xe2, 0xe2,\n\t0x64, 0x64, 0xe4, 0xe4, 0x66, 0x66, 0xe6, 0xe6,\n\t0x68, 0x68, 0xe8, 0xe8, 0x6a, 0x6a, 0xea, 0xea,\n\t0x6c, 0x6c, 0xec, 0xec, 0x6e, 0x6e, 0xee, 0xee,\n\t0x70, 0x70, 0xf0, 0xf0, 0x72, 0x72, 0xf2, 0xf2,\n\t0x74, 0x74, 0xf4, 0xf4, 0x76, 0x76, 0xf6, 0xf6,\n\t0x78, 0x78, 0xf8, 0xf8, 0x7a, 0x7a, 0xfa, 0xfa,\n\t0x7c, 0x7c, 0xfc, 0xfc, 0x7e, 0x7e, 0xfe, 0xfe\n};\n\nstatic const u32 pc2[1024] = {\n\t0x00000000, 0x00000000, 0x00000000, 0x00000000,\n\t0x00040000, 0x00000000, 0x04000000, 0x00100000,\n\t0x00400000, 0x00000008, 0x00000800, 0x40000000,\n\t0x00440000, 0x00000008, 0x04000800, 0x40100000,\n\t0x00000400, 0x00000020, 0x08000000, 0x00000100,\n\t0x00040400, 0x00000020, 0x0c000000, 0x00100100,\n\t0x00400400, 0x00000028, 0x08000800, 0x40000100,\n\t0x00440400, 0x00000028, 0x0c000800, 0x40100100,\n\t0x80000000, 0x00000010, 0x00000000, 0x00800000,\n\t0x80040000, 0x00000010, 0x04000000, 0x00900000,\n\t0x80400000, 0x00000018, 0x00000800, 0x40800000,\n\t0x80440000, 0x00000018, 0x04000800, 0x40900000,\n\t0x80000400, 0x00000030, 0x08000000, 0x00800100,\n\t0x80040400, 0x00000030, 0x0c000000, 0x00900100,\n\t0x80400400, 0x00000038, 0x08000800, 0x40800100,\n\t0x80440400, 0x00000038, 0x0c000800, 0x40900100,\n\t0x10000000, 0x00000000, 0x00200000, 0x00001000,\n\t0x10040000, 0x00000000, 0x04200000, 0x00101000,\n\t0x10400000, 0x00000008, 0x00200800, 0x40001000,\n\t0x10440000, 0x00000008, 0x04200800, 0x40101000,\n\t0x10000400, 0x00000020, 0x08200000, 0x00001100,\n\t0x10040400, 0x00000020, 0x0c200000, 0x00101100,\n\t0x10400400, 0x00000028, 0x08200800, 0x40001100,\n\t0x10440400, 0x00000028, 0x0c200800, 0x40101100,\n\t0x90000000, 0x00000010, 0x00200000, 0x00801000,\n\t0x90040000, 0x00000010, 0x04200000, 0x00901000,\n\t0x90400000, 0x00000018, 0x00200800, 0x40801000,\n\t0x90440000, 0x00000018, 0x04200800, 0x40901000,\n\t0x90000400, 0x00000030, 0x08200000, 0x00801100,\n\t0x90040400, 0x00000030, 0x0c200000, 0x00901100,\n\t0x90400400, 0x00000038, 0x08200800, 0x40801100,\n\t0x90440400, 0x00000038, 0x0c200800, 0x40901100,\n\t0x00000200, 0x00080000, 0x00000000, 0x00000004,\n\t0x00040200, 0x00080000, 0x04000000, 0x00100004,\n\t0x00400200, 0x00080008, 0x00000800, 0x40000004,\n\t0x00440200, 0x00080008, 0x04000800, 0x40100004,\n\t0x00000600, 0x00080020, 0x08000000, 0x00000104,\n\t0x00040600, 0x00080020, 0x0c000000, 0x00100104,\n\t0x00400600, 0x00080028, 0x08000800, 0x40000104,\n\t0x00440600, 0x00080028, 0x0c000800, 0x40100104,\n\t0x80000200, 0x00080010, 0x00000000, 0x00800004,\n\t0x80040200, 0x00080010, 0x04000000, 0x00900004,\n\t0x80400200, 0x00080018, 0x00000800, 0x40800004,\n\t0x80440200, 0x00080018, 0x04000800, 0x40900004,\n\t0x80000600, 0x00080030, 0x08000000, 0x00800104,\n\t0x80040600, 0x00080030, 0x0c000000, 0x00900104,\n\t0x80400600, 0x00080038, 0x08000800, 0x40800104,\n\t0x80440600, 0x00080038, 0x0c000800, 0x40900104,\n\t0x10000200, 0x00080000, 0x00200000, 0x00001004,\n\t0x10040200, 0x00080000, 0x04200000, 0x00101004,\n\t0x10400200, 0x00080008, 0x00200800, 0x40001004,\n\t0x10440200, 0x00080008, 0x04200800, 0x40101004,\n\t0x10000600, 0x00080020, 0x08200000, 0x00001104,\n\t0x10040600, 0x00080020, 0x0c200000, 0x00101104,\n\t0x10400600, 0x00080028, 0x08200800, 0x40001104,\n\t0x10440600, 0x00080028, 0x0c200800, 0x40101104,\n\t0x90000200, 0x00080010, 0x00200000, 0x00801004,\n\t0x90040200, 0x00080010, 0x04200000, 0x00901004,\n\t0x90400200, 0x00080018, 0x00200800, 0x40801004,\n\t0x90440200, 0x00080018, 0x04200800, 0x40901004,\n\t0x90000600, 0x00080030, 0x08200000, 0x00801104,\n\t0x90040600, 0x00080030, 0x0c200000, 0x00901104,\n\t0x90400600, 0x00080038, 0x08200800, 0x40801104,\n\t0x90440600, 0x00080038, 0x0c200800, 0x40901104,\n\t0x00000002, 0x00002000, 0x20000000, 0x00000001,\n\t0x00040002, 0x00002000, 0x24000000, 0x00100001,\n\t0x00400002, 0x00002008, 0x20000800, 0x40000001,\n\t0x00440002, 0x00002008, 0x24000800, 0x40100001,\n\t0x00000402, 0x00002020, 0x28000000, 0x00000101,\n\t0x00040402, 0x00002020, 0x2c000000, 0x00100101,\n\t0x00400402, 0x00002028, 0x28000800, 0x40000101,\n\t0x00440402, 0x00002028, 0x2c000800, 0x40100101,\n\t0x80000002, 0x00002010, 0x20000000, 0x00800001,\n\t0x80040002, 0x00002010, 0x24000000, 0x00900001,\n\t0x80400002, 0x00002018, 0x20000800, 0x40800001,\n\t0x80440002, 0x00002018, 0x24000800, 0x40900001,\n\t0x80000402, 0x00002030, 0x28000000, 0x00800101,\n\t0x80040402, 0x00002030, 0x2c000000, 0x00900101,\n\t0x80400402, 0x00002038, 0x28000800, 0x40800101,\n\t0x80440402, 0x00002038, 0x2c000800, 0x40900101,\n\t0x10000002, 0x00002000, 0x20200000, 0x00001001,\n\t0x10040002, 0x00002000, 0x24200000, 0x00101001,\n\t0x10400002, 0x00002008, 0x20200800, 0x40001001,\n\t0x10440002, 0x00002008, 0x24200800, 0x40101001,\n\t0x10000402, 0x00002020, 0x28200000, 0x00001101,\n\t0x10040402, 0x00002020, 0x2c200000, 0x00101101,\n\t0x10400402, 0x00002028, 0x28200800, 0x40001101,\n\t0x10440402, 0x00002028, 0x2c200800, 0x40101101,\n\t0x90000002, 0x00002010, 0x20200000, 0x00801001,\n\t0x90040002, 0x00002010, 0x24200000, 0x00901001,\n\t0x90400002, 0x00002018, 0x20200800, 0x40801001,\n\t0x90440002, 0x00002018, 0x24200800, 0x40901001,\n\t0x90000402, 0x00002030, 0x28200000, 0x00801101,\n\t0x90040402, 0x00002030, 0x2c200000, 0x00901101,\n\t0x90400402, 0x00002038, 0x28200800, 0x40801101,\n\t0x90440402, 0x00002038, 0x2c200800, 0x40901101,\n\t0x00000202, 0x00082000, 0x20000000, 0x00000005,\n\t0x00040202, 0x00082000, 0x24000000, 0x00100005,\n\t0x00400202, 0x00082008, 0x20000800, 0x40000005,\n\t0x00440202, 0x00082008, 0x24000800, 0x40100005,\n\t0x00000602, 0x00082020, 0x28000000, 0x00000105,\n\t0x00040602, 0x00082020, 0x2c000000, 0x00100105,\n\t0x00400602, 0x00082028, 0x28000800, 0x40000105,\n\t0x00440602, 0x00082028, 0x2c000800, 0x40100105,\n\t0x80000202, 0x00082010, 0x20000000, 0x00800005,\n\t0x80040202, 0x00082010, 0x24000000, 0x00900005,\n\t0x80400202, 0x00082018, 0x20000800, 0x40800005,\n\t0x80440202, 0x00082018, 0x24000800, 0x40900005,\n\t0x80000602, 0x00082030, 0x28000000, 0x00800105,\n\t0x80040602, 0x00082030, 0x2c000000, 0x00900105,\n\t0x80400602, 0x00082038, 0x28000800, 0x40800105,\n\t0x80440602, 0x00082038, 0x2c000800, 0x40900105,\n\t0x10000202, 0x00082000, 0x20200000, 0x00001005,\n\t0x10040202, 0x00082000, 0x24200000, 0x00101005,\n\t0x10400202, 0x00082008, 0x20200800, 0x40001005,\n\t0x10440202, 0x00082008, 0x24200800, 0x40101005,\n\t0x10000602, 0x00082020, 0x28200000, 0x00001105,\n\t0x10040602, 0x00082020, 0x2c200000, 0x00101105,\n\t0x10400602, 0x00082028, 0x28200800, 0x40001105,\n\t0x10440602, 0x00082028, 0x2c200800, 0x40101105,\n\t0x90000202, 0x00082010, 0x20200000, 0x00801005,\n\t0x90040202, 0x00082010, 0x24200000, 0x00901005,\n\t0x90400202, 0x00082018, 0x20200800, 0x40801005,\n\t0x90440202, 0x00082018, 0x24200800, 0x40901005,\n\t0x90000602, 0x00082030, 0x28200000, 0x00801105,\n\t0x90040602, 0x00082030, 0x2c200000, 0x00901105,\n\t0x90400602, 0x00082038, 0x28200800, 0x40801105,\n\t0x90440602, 0x00082038, 0x2c200800, 0x40901105,\n\n\t0x00000000, 0x00000000, 0x00000000, 0x00000000,\n\t0x00000000, 0x00000008, 0x00080000, 0x10000000,\n\t0x02000000, 0x00000000, 0x00000080, 0x00001000,\n\t0x02000000, 0x00000008, 0x00080080, 0x10001000,\n\t0x00004000, 0x00000000, 0x00000040, 0x00040000,\n\t0x00004000, 0x00000008, 0x00080040, 0x10040000,\n\t0x02004000, 0x00000000, 0x000000c0, 0x00041000,\n\t0x02004000, 0x00000008, 0x000800c0, 0x10041000,\n\t0x00020000, 0x00008000, 0x08000000, 0x00200000,\n\t0x00020000, 0x00008008, 0x08080000, 0x10200000,\n\t0x02020000, 0x00008000, 0x08000080, 0x00201000,\n\t0x02020000, 0x00008008, 0x08080080, 0x10201000,\n\t0x00024000, 0x00008000, 0x08000040, 0x00240000,\n\t0x00024000, 0x00008008, 0x08080040, 0x10240000,\n\t0x02024000, 0x00008000, 0x080000c0, 0x00241000,\n\t0x02024000, 0x00008008, 0x080800c0, 0x10241000,\n\t0x00000000, 0x01000000, 0x00002000, 0x00000020,\n\t0x00000000, 0x01000008, 0x00082000, 0x10000020,\n\t0x02000000, 0x01000000, 0x00002080, 0x00001020,\n\t0x02000000, 0x01000008, 0x00082080, 0x10001020,\n\t0x00004000, 0x01000000, 0x00002040, 0x00040020,\n\t0x00004000, 0x01000008, 0x00082040, 0x10040020,\n\t0x02004000, 0x01000000, 0x000020c0, 0x00041020,\n\t0x02004000, 0x01000008, 0x000820c0, 0x10041020,\n\t0x00020000, 0x01008000, 0x08002000, 0x00200020,\n\t0x00020000, 0x01008008, 0x08082000, 0x10200020,\n\t0x02020000, 0x01008000, 0x08002080, 0x00201020,\n\t0x02020000, 0x01008008, 0x08082080, 0x10201020,\n\t0x00024000, 0x01008000, 0x08002040, 0x00240020,\n\t0x00024000, 0x01008008, 0x08082040, 0x10240020,\n\t0x02024000, 0x01008000, 0x080020c0, 0x00241020,\n\t0x02024000, 0x01008008, 0x080820c0, 0x10241020,\n\t0x00000400, 0x04000000, 0x00100000, 0x00000004,\n\t0x00000400, 0x04000008, 0x00180000, 0x10000004,\n\t0x02000400, 0x04000000, 0x00100080, 0x00001004,\n\t0x02000400, 0x04000008, 0x00180080, 0x10001004,\n\t0x00004400, 0x04000000, 0x00100040, 0x00040004,\n\t0x00004400, 0x04000008, 0x00180040, 0x10040004,\n\t0x02004400, 0x04000000, 0x001000c0, 0x00041004,\n\t0x02004400, 0x04000008, 0x001800c0, 0x10041004,\n\t0x00020400, 0x04008000, 0x08100000, 0x00200004,\n\t0x00020400, 0x04008008, 0x08180000, 0x10200004,\n\t0x02020400, 0x04008000, 0x08100080, 0x00201004,\n\t0x02020400, 0x04008008, 0x08180080, 0x10201004,\n\t0x00024400, 0x04008000, 0x08100040, 0x00240004,\n\t0x00024400, 0x04008008, 0x08180040, 0x10240004,\n\t0x02024400, 0x04008000, 0x081000c0, 0x00241004,\n\t0x02024400, 0x04008008, 0x081800c0, 0x10241004,\n\t0x00000400, 0x05000000, 0x00102000, 0x00000024,\n\t0x00000400, 0x05000008, 0x00182000, 0x10000024,\n\t0x02000400, 0x05000000, 0x00102080, 0x00001024,\n\t0x02000400, 0x05000008, 0x00182080, 0x10001024,\n\t0x00004400, 0x05000000, 0x00102040, 0x00040024,\n\t0x00004400, 0x05000008, 0x00182040, 0x10040024,\n\t0x02004400, 0x05000000, 0x001020c0, 0x00041024,\n\t0x02004400, 0x05000008, 0x001820c0, 0x10041024,\n\t0x00020400, 0x05008000, 0x08102000, 0x00200024,\n\t0x00020400, 0x05008008, 0x08182000, 0x10200024,\n\t0x02020400, 0x05008000, 0x08102080, 0x00201024,\n\t0x02020400, 0x05008008, 0x08182080, 0x10201024,\n\t0x00024400, 0x05008000, 0x08102040, 0x00240024,\n\t0x00024400, 0x05008008, 0x08182040, 0x10240024,\n\t0x02024400, 0x05008000, 0x081020c0, 0x00241024,\n\t0x02024400, 0x05008008, 0x081820c0, 0x10241024,\n\t0x00000800, 0x00010000, 0x20000000, 0x00000010,\n\t0x00000800, 0x00010008, 0x20080000, 0x10000010,\n\t0x02000800, 0x00010000, 0x20000080, 0x00001010,\n\t0x02000800, 0x00010008, 0x20080080, 0x10001010,\n\t0x00004800, 0x00010000, 0x20000040, 0x00040010,\n\t0x00004800, 0x00010008, 0x20080040, 0x10040010,\n\t0x02004800, 0x00010000, 0x200000c0, 0x00041010,\n\t0x02004800, 0x00010008, 0x200800c0, 0x10041010,\n\t0x00020800, 0x00018000, 0x28000000, 0x00200010,\n\t0x00020800, 0x00018008, 0x28080000, 0x10200010,\n\t0x02020800, 0x00018000, 0x28000080, 0x00201010,\n\t0x02020800, 0x00018008, 0x28080080, 0x10201010,\n\t0x00024800, 0x00018000, 0x28000040, 0x00240010,\n\t0x00024800, 0x00018008, 0x28080040, 0x10240010,\n\t0x02024800, 0x00018000, 0x280000c0, 0x00241010,\n\t0x02024800, 0x00018008, 0x280800c0, 0x10241010,\n\t0x00000800, 0x01010000, 0x20002000, 0x00000030,\n\t0x00000800, 0x01010008, 0x20082000, 0x10000030,\n\t0x02000800, 0x01010000, 0x20002080, 0x00001030,\n\t0x02000800, 0x01010008, 0x20082080, 0x10001030,\n\t0x00004800, 0x01010000, 0x20002040, 0x00040030,\n\t0x00004800, 0x01010008, 0x20082040, 0x10040030,\n\t0x02004800, 0x01010000, 0x200020c0, 0x00041030,\n\t0x02004800, 0x01010008, 0x200820c0, 0x10041030,\n\t0x00020800, 0x01018000, 0x28002000, 0x00200030,\n\t0x00020800, 0x01018008, 0x28082000, 0x10200030,\n\t0x02020800, 0x01018000, 0x28002080, 0x00201030,\n\t0x02020800, 0x01018008, 0x28082080, 0x10201030,\n\t0x00024800, 0x01018000, 0x28002040, 0x00240030,\n\t0x00024800, 0x01018008, 0x28082040, 0x10240030,\n\t0x02024800, 0x01018000, 0x280020c0, 0x00241030,\n\t0x02024800, 0x01018008, 0x280820c0, 0x10241030,\n\t0x00000c00, 0x04010000, 0x20100000, 0x00000014,\n\t0x00000c00, 0x04010008, 0x20180000, 0x10000014,\n\t0x02000c00, 0x04010000, 0x20100080, 0x00001014,\n\t0x02000c00, 0x04010008, 0x20180080, 0x10001014,\n\t0x00004c00, 0x04010000, 0x20100040, 0x00040014,\n\t0x00004c00, 0x04010008, 0x20180040, 0x10040014,\n\t0x02004c00, 0x04010000, 0x201000c0, 0x00041014,\n\t0x02004c00, 0x04010008, 0x201800c0, 0x10041014,\n\t0x00020c00, 0x04018000, 0x28100000, 0x00200014,\n\t0x00020c00, 0x04018008, 0x28180000, 0x10200014,\n\t0x02020c00, 0x04018000, 0x28100080, 0x00201014,\n\t0x02020c00, 0x04018008, 0x28180080, 0x10201014,\n\t0x00024c00, 0x04018000, 0x28100040, 0x00240014,\n\t0x00024c00, 0x04018008, 0x28180040, 0x10240014,\n\t0x02024c00, 0x04018000, 0x281000c0, 0x00241014,\n\t0x02024c00, 0x04018008, 0x281800c0, 0x10241014,\n\t0x00000c00, 0x05010000, 0x20102000, 0x00000034,\n\t0x00000c00, 0x05010008, 0x20182000, 0x10000034,\n\t0x02000c00, 0x05010000, 0x20102080, 0x00001034,\n\t0x02000c00, 0x05010008, 0x20182080, 0x10001034,\n\t0x00004c00, 0x05010000, 0x20102040, 0x00040034,\n\t0x00004c00, 0x05010008, 0x20182040, 0x10040034,\n\t0x02004c00, 0x05010000, 0x201020c0, 0x00041034,\n\t0x02004c00, 0x05010008, 0x201820c0, 0x10041034,\n\t0x00020c00, 0x05018000, 0x28102000, 0x00200034,\n\t0x00020c00, 0x05018008, 0x28182000, 0x10200034,\n\t0x02020c00, 0x05018000, 0x28102080, 0x00201034,\n\t0x02020c00, 0x05018008, 0x28182080, 0x10201034,\n\t0x00024c00, 0x05018000, 0x28102040, 0x00240034,\n\t0x00024c00, 0x05018008, 0x28182040, 0x10240034,\n\t0x02024c00, 0x05018000, 0x281020c0, 0x00241034,\n\t0x02024c00, 0x05018008, 0x281820c0, 0x10241034\n};\n\n/* S-box lookup tables */\n\nstatic const u32 S1[64] = {\n\t0x01010400, 0x00000000, 0x00010000, 0x01010404,\n\t0x01010004, 0x00010404, 0x00000004, 0x00010000,\n\t0x00000400, 0x01010400, 0x01010404, 0x00000400,\n\t0x01000404, 0x01010004, 0x01000000, 0x00000004,\n\t0x00000404, 0x01000400, 0x01000400, 0x00010400,\n\t0x00010400, 0x01010000, 0x01010000, 0x01000404,\n\t0x00010004, 0x01000004, 0x01000004, 0x00010004,\n\t0x00000000, 0x00000404, 0x00010404, 0x01000000,\n\t0x00010000, 0x01010404, 0x00000004, 0x01010000,\n\t0x01010400, 0x01000000, 0x01000000, 0x00000400,\n\t0x01010004, 0x00010000, 0x00010400, 0x01000004,\n\t0x00000400, 0x00000004, 0x01000404, 0x00010404,\n\t0x01010404, 0x00010004, 0x01010000, 0x01000404,\n\t0x01000004, 0x00000404, 0x00010404, 0x01010400,\n\t0x00000404, 0x01000400, 0x01000400, 0x00000000,\n\t0x00010004, 0x00010400, 0x00000000, 0x01010004\n};\n\nstatic const u32 S2[64] = {\n\t0x80108020, 0x80008000, 0x00008000, 0x00108020,\n\t0x00100000, 0x00000020, 0x80100020, 0x80008020,\n\t0x80000020, 0x80108020, 0x80108000, 0x80000000,\n\t0x80008000, 0x00100000, 0x00000020, 0x80100020,\n\t0x00108000, 0x00100020, 0x80008020, 0x00000000,\n\t0x80000000, 0x00008000, 0x00108020, 0x80100000,\n\t0x00100020, 0x80000020, 0x00000000, 0x00108000,\n\t0x00008020, 0x80108000, 0x80100000, 0x00008020,\n\t0x00000000, 0x00108020, 0x80100020, 0x00100000,\n\t0x80008020, 0x80100000, 0x80108000, 0x00008000,\n\t0x80100000, 0x80008000, 0x00000020, 0x80108020,\n\t0x00108020, 0x00000020, 0x00008000, 0x80000000,\n\t0x00008020, 0x80108000, 0x00100000, 0x80000020,\n\t0x00100020, 0x80008020, 0x80000020, 0x00100020,\n\t0x00108000, 0x00000000, 0x80008000, 0x00008020,\n\t0x80000000, 0x80100020, 0x80108020, 0x00108000\n};\n\nstatic const u32 S3[64] = {\n\t0x00000208, 0x08020200, 0x00000000, 0x08020008,\n\t0x08000200, 0x00000000, 0x00020208, 0x08000200,\n\t0x00020008, 0x08000008, 0x08000008, 0x00020000,\n\t0x08020208, 0x00020008, 0x08020000, 0x00000208,\n\t0x08000000, 0x00000008, 0x08020200, 0x00000200,\n\t0x00020200, 0x08020000, 0x08020008, 0x00020208,\n\t0x08000208, 0x00020200, 0x00020000, 0x08000208,\n\t0x00000008, 0x08020208, 0x00000200, 0x08000000,\n\t0x08020200, 0x08000000, 0x00020008, 0x00000208,\n\t0x00020000, 0x08020200, 0x08000200, 0x00000000,\n\t0x00000200, 0x00020008, 0x08020208, 0x08000200,\n\t0x08000008, 0x00000200, 0x00000000, 0x08020008,\n\t0x08000208, 0x00020000, 0x08000000, 0x08020208,\n\t0x00000008, 0x00020208, 0x00020200, 0x08000008,\n\t0x08020000, 0x08000208, 0x00000208, 0x08020000,\n\t0x00020208, 0x00000008, 0x08020008, 0x00020200\n};\n\nstatic const u32 S4[64] = {\n\t0x00802001, 0x00002081, 0x00002081, 0x00000080,\n\t0x00802080, 0x00800081, 0x00800001, 0x00002001,\n\t0x00000000, 0x00802000, 0x00802000, 0x00802081,\n\t0x00000081, 0x00000000, 0x00800080, 0x00800001,\n\t0x00000001, 0x00002000, 0x00800000, 0x00802001,\n\t0x00000080, 0x00800000, 0x00002001, 0x00002080,\n\t0x00800081, 0x00000001, 0x00002080, 0x00800080,\n\t0x00002000, 0x00802080, 0x00802081, 0x00000081,\n\t0x00800080, 0x00800001, 0x00802000, 0x00802081,\n\t0x00000081, 0x00000000, 0x00000000, 0x00802000,\n\t0x00002080, 0x00800080, 0x00800081, 0x00000001,\n\t0x00802001, 0x00002081, 0x00002081, 0x00000080,\n\t0x00802081, 0x00000081, 0x00000001, 0x00002000,\n\t0x00800001, 0x00002001, 0x00802080, 0x00800081,\n\t0x00002001, 0x00002080, 0x00800000, 0x00802001,\n\t0x00000080, 0x00800000, 0x00002000, 0x00802080\n};\n\nstatic const u32 S5[64] = {\n\t0x00000100, 0x02080100, 0x02080000, 0x42000100,\n\t0x00080000, 0x00000100, 0x40000000, 0x02080000,\n\t0x40080100, 0x00080000, 0x02000100, 0x40080100,\n\t0x42000100, 0x42080000, 0x00080100, 0x40000000,\n\t0x02000000, 0x40080000, 0x40080000, 0x00000000,\n\t0x40000100, 0x42080100, 0x42080100, 0x02000100,\n\t0x42080000, 0x40000100, 0x00000000, 0x42000000,\n\t0x02080100, 0x02000000, 0x42000000, 0x00080100,\n\t0x00080000, 0x42000100, 0x00000100, 0x02000000,\n\t0x40000000, 0x02080000, 0x42000100, 0x40080100,\n\t0x02000100, 0x40000000, 0x42080000, 0x02080100,\n\t0x40080100, 0x00000100, 0x02000000, 0x42080000,\n\t0x42080100, 0x00080100, 0x42000000, 0x42080100,\n\t0x02080000, 0x00000000, 0x40080000, 0x42000000,\n\t0x00080100, 0x02000100, 0x40000100, 0x00080000,\n\t0x00000000, 0x40080000, 0x02080100, 0x40000100\n};\n\nstatic const u32 S6[64] = {\n\t0x20000010, 0x20400000, 0x00004000, 0x20404010,\n\t0x20400000, 0x00000010, 0x20404010, 0x00400000,\n\t0x20004000, 0x00404010, 0x00400000, 0x20000010,\n\t0x00400010, 0x20004000, 0x20000000, 0x00004010,\n\t0x00000000, 0x00400010, 0x20004010, 0x00004000,\n\t0x00404000, 0x20004010, 0x00000010, 0x20400010,\n\t0x20400010, 0x00000000, 0x00404010, 0x20404000,\n\t0x00004010, 0x00404000, 0x20404000, 0x20000000,\n\t0x20004000, 0x00000010, 0x20400010, 0x00404000,\n\t0x20404010, 0x00400000, 0x00004010, 0x20000010,\n\t0x00400000, 0x20004000, 0x20000000, 0x00004010,\n\t0x20000010, 0x20404010, 0x00404000, 0x20400000,\n\t0x00404010, 0x20404000, 0x00000000, 0x20400010,\n\t0x00000010, 0x00004000, 0x20400000, 0x00404010,\n\t0x00004000, 0x00400010, 0x20004010, 0x00000000,\n\t0x20404000, 0x20000000, 0x00400010, 0x20004010\n};\n\nstatic const u32 S7[64] = {\n\t0x00200000, 0x04200002, 0x04000802, 0x00000000,\n\t0x00000800, 0x04000802, 0x00200802, 0x04200800,\n\t0x04200802, 0x00200000, 0x00000000, 0x04000002,\n\t0x00000002, 0x04000000, 0x04200002, 0x00000802,\n\t0x04000800, 0x00200802, 0x00200002, 0x04000800,\n\t0x04000002, 0x04200000, 0x04200800, 0x00200002,\n\t0x04200000, 0x00000800, 0x00000802, 0x04200802,\n\t0x00200800, 0x00000002, 0x04000000, 0x00200800,\n\t0x04000000, 0x00200800, 0x00200000, 0x04000802,\n\t0x04000802, 0x04200002, 0x04200002, 0x00000002,\n\t0x00200002, 0x04000000, 0x04000800, 0x00200000,\n\t0x04200800, 0x00000802, 0x00200802, 0x04200800,\n\t0x00000802, 0x04000002, 0x04200802, 0x04200000,\n\t0x00200800, 0x00000000, 0x00000002, 0x04200802,\n\t0x00000000, 0x00200802, 0x04200000, 0x00000800,\n\t0x04000002, 0x04000800, 0x00000800, 0x00200002\n};\n\nstatic const u32 S8[64] = {\n\t0x10001040, 0x00001000, 0x00040000, 0x10041040,\n\t0x10000000, 0x10001040, 0x00000040, 0x10000000,\n\t0x00040040, 0x10040000, 0x10041040, 0x00041000,\n\t0x10041000, 0x00041040, 0x00001000, 0x00000040,\n\t0x10040000, 0x10000040, 0x10001000, 0x00001040,\n\t0x00041000, 0x00040040, 0x10040040, 0x10041000,\n\t0x00001040, 0x00000000, 0x00000000, 0x10040040,\n\t0x10000040, 0x10001000, 0x00041040, 0x00040000,\n\t0x00041040, 0x00040000, 0x10041000, 0x00001000,\n\t0x00000040, 0x10040040, 0x00001000, 0x00041040,\n\t0x10001000, 0x00000040, 0x10000040, 0x10040000,\n\t0x10040040, 0x10000000, 0x00040000, 0x10001040,\n\t0x00000000, 0x10041040, 0x00040040, 0x10000040,\n\t0x10040000, 0x10001000, 0x10001040, 0x00000000,\n\t0x10041040, 0x00041000, 0x00041000, 0x00001040,\n\t0x00001040, 0x00040040, 0x10000000, 0x10041000\n};\n\n/* Encryption components: IP, FP, and round function */\n\n#define IP(L, R, T)\t\t\\\n\tROL(R, 4);\t\t\\\n\tT  = L;\t\t\t\\\n\tL ^= R;\t\t\t\\\n\tL &= 0xf0f0f0f0;\t\\\n\tR ^= L;\t\t\t\\\n\tL ^= T;\t\t\t\\\n\tROL(R, 12);\t\t\\\n\tT  = L;\t\t\t\\\n\tL ^= R;\t\t\t\\\n\tL &= 0xffff0000;\t\\\n\tR ^= L;\t\t\t\\\n\tL ^= T;\t\t\t\\\n\tROR(R, 14);\t\t\\\n\tT  = L;\t\t\t\\\n\tL ^= R;\t\t\t\\\n\tL &= 0xcccccccc;\t\\\n\tR ^= L;\t\t\t\\\n\tL ^= T;\t\t\t\\\n\tROL(R, 6);\t\t\\\n\tT  = L;\t\t\t\\\n\tL ^= R;\t\t\t\\\n\tL &= 0xff00ff00;\t\\\n\tR ^= L;\t\t\t\\\n\tL ^= T;\t\t\t\\\n\tROR(R, 7);\t\t\\\n\tT  = L;\t\t\t\\\n\tL ^= R;\t\t\t\\\n\tL &= 0xaaaaaaaa;\t\\\n\tR ^= L;\t\t\t\\\n\tL ^= T;\t\t\t\\\n\tROL(L, 1);\n\n#define FP(L, R, T)\t\t\\\n\tROR(L, 1);\t\t\\\n\tT  = L;\t\t\t\\\n\tL ^= R;\t\t\t\\\n\tL &= 0xaaaaaaaa;\t\\\n\tR ^= L;\t\t\t\\\n\tL ^= T;\t\t\t\\\n\tROL(R, 7);\t\t\\\n\tT  = L;\t\t\t\\\n\tL ^= R;\t\t\t\\\n\tL &= 0xff00ff00;\t\\\n\tR ^= L;\t\t\t\\\n\tL ^= T;\t\t\t\\\n\tROR(R, 6);\t\t\\\n\tT  = L;\t\t\t\\\n\tL ^= R;\t\t\t\\\n\tL &= 0xcccccccc;\t\\\n\tR ^= L;\t\t\t\\\n\tL ^= T;\t\t\t\\\n\tROL(R, 14);\t\t\\\n\tT  = L;\t\t\t\\\n\tL ^= R;\t\t\t\\\n\tL &= 0xffff0000;\t\\\n\tR ^= L;\t\t\t\\\n\tL ^= T;\t\t\t\\\n\tROR(R, 12);\t\t\\\n\tT  = L;\t\t\t\\\n\tL ^= R;\t\t\t\\\n\tL &= 0xf0f0f0f0;\t\\\n\tR ^= L;\t\t\t\\\n\tL ^= T;\t\t\t\\\n\tROR(R, 4);\n\n#define ROUND(L, R, A, B, K, d)\t\t\t\t\t\\\n\tB = K[0];\t\t\tA = K[1];\tK += d;\t\\\n\tB ^= R;\t\t\t\tA ^= R;\t\t\t\\\n\tB &= 0x3f3f3f3f;\t\tROR(A, 4);\t\t\\\n\tL ^= S8[0xff & B];\t\tA &= 0x3f3f3f3f;\t\\\n\tL ^= S6[0xff & (B >> 8)];\tB >>= 16;\t\t\\\n\tL ^= S7[0xff & A];\t\t\t\t\t\\\n\tL ^= S5[0xff & (A >> 8)];\tA >>= 16;\t\t\\\n\tL ^= S4[0xff & B];\t\t\t\t\t\\\n\tL ^= S2[0xff & (B >> 8)];\t\t\t\t\\\n\tL ^= S3[0xff & A];\t\t\t\t\t\\\n\tL ^= S1[0xff & (A >> 8)];\n\n/*\n * PC2 lookup tables are organized as 2 consecutive sets of 4 interleaved\n * tables of 128 elements.  One set is for C_i and the other for D_i, while\n * the 4 interleaved tables correspond to four 7-bit subsets of C_i or D_i.\n *\n * After PC1 each of the variables a,b,c,d contains a 7 bit subset of C_i\n * or D_i in bits 7-1 (bit 0 being the least significant).\n */\n\n#define T1(x) pt[2 * (x) + 0]\n#define T2(x) pt[2 * (x) + 1]\n#define T3(x) pt[2 * (x) + 2]\n#define T4(x) pt[2 * (x) + 3]\n\n#define DES_PC2(a, b, c, d) (T4(d) | T3(c) | T2(b) | T1(a))\n\n/*\n * Encryption key expansion\n *\n * RFC2451: Weak key checks SHOULD be performed.\n *\n * FIPS 74:\n *\n *   Keys having duals are keys which produce all zeros, all ones, or\n *   alternating zero-one patterns in the C and D registers after Permuted\n *   Choice 1 has operated on the key.\n *\n */\nunsigned long des_ekey(u32 *pe, const u8 *k)\n{\n\t/* K&R: long is at least 32 bits */\n\tunsigned long a, b, c, d, w;\n\tconst u32 *pt = pc2;\n\n\td = k[4]; d &= 0x0e; d <<= 4; d |= k[0] & 0x1e; d = pc1[d];\n\tc = k[5]; c &= 0x0e; c <<= 4; c |= k[1] & 0x1e; c = pc1[c];\n\tb = k[6]; b &= 0x0e; b <<= 4; b |= k[2] & 0x1e; b = pc1[b];\n\ta = k[7]; a &= 0x0e; a <<= 4; a |= k[3] & 0x1e; a = pc1[a];\n\n\tpe[15 * 2 + 0] = DES_PC2(a, b, c, d); d = rs[d];\n\tpe[14 * 2 + 0] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[13 * 2 + 0] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[12 * 2 + 0] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[11 * 2 + 0] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[10 * 2 + 0] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[ 9 * 2 + 0] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[ 8 * 2 + 0] = DES_PC2(d, a, b, c); c = rs[c];\n\tpe[ 7 * 2 + 0] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[ 6 * 2 + 0] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[ 5 * 2 + 0] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[ 4 * 2 + 0] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[ 3 * 2 + 0] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[ 2 * 2 + 0] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[ 1 * 2 + 0] = DES_PC2(c, d, a, b); b = rs[b];\n\tpe[ 0 * 2 + 0] = DES_PC2(b, c, d, a);\n\n\t/* Check if first half is weak */\n\tw  = (a ^ c) | (b ^ d) | (rs[a] ^ c) | (b ^ rs[d]);\n\n\t/* Skip to next table set */\n\tpt += 512;\n\n\td = k[0]; d &= 0xe0; d >>= 4; d |= k[4] & 0xf0; d = pc1[d + 1];\n\tc = k[1]; c &= 0xe0; c >>= 4; c |= k[5] & 0xf0; c = pc1[c + 1];\n\tb = k[2]; b &= 0xe0; b >>= 4; b |= k[6] & 0xf0; b = pc1[b + 1];\n\ta = k[3]; a &= 0xe0; a >>= 4; a |= k[7] & 0xf0; a = pc1[a + 1];\n\n\t/* Check if second half is weak */\n\tw |= (a ^ c) | (b ^ d) | (rs[a] ^ c) | (b ^ rs[d]);\n\n\tpe[15 * 2 + 1] = DES_PC2(a, b, c, d); d = rs[d];\n\tpe[14 * 2 + 1] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[13 * 2 + 1] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[12 * 2 + 1] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[11 * 2 + 1] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[10 * 2 + 1] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[ 9 * 2 + 1] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[ 8 * 2 + 1] = DES_PC2(d, a, b, c); c = rs[c];\n\tpe[ 7 * 2 + 1] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[ 6 * 2 + 1] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[ 5 * 2 + 1] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[ 4 * 2 + 1] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[ 3 * 2 + 1] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[ 2 * 2 + 1] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[ 1 * 2 + 1] = DES_PC2(c, d, a, b); b = rs[b];\n\tpe[ 0 * 2 + 1] = DES_PC2(b, c, d, a);\n\n\t/* Fixup: 2413 5768 -> 1357 2468 */\n\tfor (d = 0; d < 16; ++d) {\n\t\ta = pe[2 * d];\n\t\tb = pe[2 * d + 1];\n\t\tc = a ^ b;\n\t\tc &= 0xffff0000;\n\t\ta ^= c;\n\t\tb ^= c;\n\t\tROL(b, 18);\n\t\tpe[2 * d] = a;\n\t\tpe[2 * d + 1] = b;\n\t}\n\n\t/* Zero if weak key */\n\treturn w;\n}\nEXPORT_SYMBOL_GPL(des_ekey);\n\n/*\n * Decryption key expansion\n *\n * No weak key checking is performed, as this is only used by triple DES\n *\n */\nstatic void dkey(u32 *pe, const u8 *k)\n{\n\t/* K&R: long is at least 32 bits */\n\tunsigned long a, b, c, d;\n\tconst u32 *pt = pc2;\n\n\td = k[4]; d &= 0x0e; d <<= 4; d |= k[0] & 0x1e; d = pc1[d];\n\tc = k[5]; c &= 0x0e; c <<= 4; c |= k[1] & 0x1e; c = pc1[c];\n\tb = k[6]; b &= 0x0e; b <<= 4; b |= k[2] & 0x1e; b = pc1[b];\n\ta = k[7]; a &= 0x0e; a <<= 4; a |= k[3] & 0x1e; a = pc1[a];\n\n\tpe[ 0 * 2] = DES_PC2(a, b, c, d); d = rs[d];\n\tpe[ 1 * 2] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[ 2 * 2] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[ 3 * 2] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[ 4 * 2] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[ 5 * 2] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[ 6 * 2] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[ 7 * 2] = DES_PC2(d, a, b, c); c = rs[c];\n\tpe[ 8 * 2] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[ 9 * 2] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[10 * 2] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[11 * 2] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[12 * 2] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[13 * 2] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[14 * 2] = DES_PC2(c, d, a, b); b = rs[b];\n\tpe[15 * 2] = DES_PC2(b, c, d, a);\n\n\t/* Skip to next table set */\n\tpt += 512;\n\n\td = k[0]; d &= 0xe0; d >>= 4; d |= k[4] & 0xf0; d = pc1[d + 1];\n\tc = k[1]; c &= 0xe0; c >>= 4; c |= k[5] & 0xf0; c = pc1[c + 1];\n\tb = k[2]; b &= 0xe0; b >>= 4; b |= k[6] & 0xf0; b = pc1[b + 1];\n\ta = k[3]; a &= 0xe0; a >>= 4; a |= k[7] & 0xf0; a = pc1[a + 1];\n\n\tpe[ 0 * 2 + 1] = DES_PC2(a, b, c, d); d = rs[d];\n\tpe[ 1 * 2 + 1] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[ 2 * 2 + 1] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[ 3 * 2 + 1] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[ 4 * 2 + 1] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[ 5 * 2 + 1] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[ 6 * 2 + 1] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[ 7 * 2 + 1] = DES_PC2(d, a, b, c); c = rs[c];\n\tpe[ 8 * 2 + 1] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[ 9 * 2 + 1] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[10 * 2 + 1] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[11 * 2 + 1] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[12 * 2 + 1] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[13 * 2 + 1] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[14 * 2 + 1] = DES_PC2(c, d, a, b); b = rs[b];\n\tpe[15 * 2 + 1] = DES_PC2(b, c, d, a);\n\n\t/* Fixup: 2413 5768 -> 1357 2468 */\n\tfor (d = 0; d < 16; ++d) {\n\t\ta = pe[2 * d];\n\t\tb = pe[2 * d + 1];\n\t\tc = a ^ b;\n\t\tc &= 0xffff0000;\n\t\ta ^= c;\n\t\tb ^= c;\n\t\tROL(b, 18);\n\t\tpe[2 * d] = a;\n\t\tpe[2 * d + 1] = b;\n\t}\n}\n\nstatic int des_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t      unsigned int keylen)\n{\n\tstruct des_ctx *dctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tu32 tmp[DES_EXPKEY_WORDS];\n\tint ret;\n\n\t/* Expand to tmp */\n\tret = des_ekey(tmp, key);\n\n\tif (unlikely(ret == 0) && (*flags & CRYPTO_TFM_REQ_WEAK_KEY)) {\n\t\t*flags |= CRYPTO_TFM_RES_WEAK_KEY;\n\t\treturn -EINVAL;\n\t}\n\n\t/* Copy to output */\n\tmemcpy(dctx->expkey, tmp, sizeof(dctx->expkey));\n\n\treturn 0;\n}\n\nstatic void des_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct des_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst u32 *K = ctx->expkey;\n\tconst __le32 *s = (const __le32 *)src;\n\t__le32 *d = (__le32 *)dst;\n\tu32 L, R, A, B;\n\tint i;\n\n\tL = le32_to_cpu(s[0]);\n\tR = le32_to_cpu(s[1]);\n\n\tIP(L, R, A);\n\tfor (i = 0; i < 8; i++) {\n\t\tROUND(L, R, A, B, K, 2);\n\t\tROUND(R, L, A, B, K, 2);\n\t}\n\tFP(R, L, A);\n\n\td[0] = cpu_to_le32(R);\n\td[1] = cpu_to_le32(L);\n}\n\nstatic void des_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct des_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst u32 *K = ctx->expkey + DES_EXPKEY_WORDS - 2;\n\tconst __le32 *s = (const __le32 *)src;\n\t__le32 *d = (__le32 *)dst;\n\tu32 L, R, A, B;\n\tint i;\n\n\tL = le32_to_cpu(s[0]);\n\tR = le32_to_cpu(s[1]);\n\n\tIP(L, R, A);\n\tfor (i = 0; i < 8; i++) {\n\t\tROUND(L, R, A, B, K, -2);\n\t\tROUND(R, L, A, B, K, -2);\n\t}\n\tFP(R, L, A);\n\n\td[0] = cpu_to_le32(R);\n\td[1] = cpu_to_le32(L);\n}\n\n/*\n * RFC2451:\n *\n *   For DES-EDE3, there is no known need to reject weak or\n *   complementation keys.  Any weakness is obviated by the use of\n *   multiple keys.\n *\n *   However, if the first two or last two independent 64-bit keys are\n *   equal (k1 == k2 or k2 == k3), then the DES3 operation is simply the\n *   same as DES.  Implementers MUST reject keys that exhibit this\n *   property.\n *\n */\nint __des3_ede_setkey(u32 *expkey, u32 *flags, const u8 *key,\n\t\t      unsigned int keylen)\n{\n\tconst u32 *K = (const u32 *)key;\n\n\tif (unlikely(!((K[0] ^ K[2]) | (K[1] ^ K[3])) ||\n\t\t     !((K[2] ^ K[4]) | (K[3] ^ K[5]))) &&\n\t\t     (*flags & CRYPTO_TFM_REQ_WEAK_KEY)) {\n\t\t*flags |= CRYPTO_TFM_RES_WEAK_KEY;\n\t\treturn -EINVAL;\n\t}\n\n\tdes_ekey(expkey, key); expkey += DES_EXPKEY_WORDS; key += DES_KEY_SIZE;\n\tdkey(expkey, key); expkey += DES_EXPKEY_WORDS; key += DES_KEY_SIZE;\n\tdes_ekey(expkey, key);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(__des3_ede_setkey);\n\nstatic int des3_ede_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\t   unsigned int keylen)\n{\n\tstruct des3_ede_ctx *dctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tu32 *expkey = dctx->expkey;\n\n\treturn __des3_ede_setkey(expkey, flags, key, keylen);\n}\n\nstatic void des3_ede_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct des3_ede_ctx *dctx = crypto_tfm_ctx(tfm);\n\tconst u32 *K = dctx->expkey;\n\tconst __le32 *s = (const __le32 *)src;\n\t__le32 *d = (__le32 *)dst;\n\tu32 L, R, A, B;\n\tint i;\n\n\tL = le32_to_cpu(s[0]);\n\tR = le32_to_cpu(s[1]);\n\n\tIP(L, R, A);\n\tfor (i = 0; i < 8; i++) {\n\t\tROUND(L, R, A, B, K, 2);\n\t\tROUND(R, L, A, B, K, 2);\n\t}\n\tfor (i = 0; i < 8; i++) {\n\t\tROUND(R, L, A, B, K, 2);\n\t\tROUND(L, R, A, B, K, 2);\n\t}\n\tfor (i = 0; i < 8; i++) {\n\t\tROUND(L, R, A, B, K, 2);\n\t\tROUND(R, L, A, B, K, 2);\n\t}\n\tFP(R, L, A);\n\n\td[0] = cpu_to_le32(R);\n\td[1] = cpu_to_le32(L);\n}\n\nstatic void des3_ede_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct des3_ede_ctx *dctx = crypto_tfm_ctx(tfm);\n\tconst u32 *K = dctx->expkey + DES3_EDE_EXPKEY_WORDS - 2;\n\tconst __le32 *s = (const __le32 *)src;\n\t__le32 *d = (__le32 *)dst;\n\tu32 L, R, A, B;\n\tint i;\n\n\tL = le32_to_cpu(s[0]);\n\tR = le32_to_cpu(s[1]);\n\n\tIP(L, R, A);\n\tfor (i = 0; i < 8; i++) {\n\t\tROUND(L, R, A, B, K, -2);\n\t\tROUND(R, L, A, B, K, -2);\n\t}\n\tfor (i = 0; i < 8; i++) {\n\t\tROUND(R, L, A, B, K, -2);\n\t\tROUND(L, R, A, B, K, -2);\n\t}\n\tfor (i = 0; i < 8; i++) {\n\t\tROUND(L, R, A, B, K, -2);\n\t\tROUND(R, L, A, B, K, -2);\n\t}\n\tFP(R, L, A);\n\n\td[0] = cpu_to_le32(R);\n\td[1] = cpu_to_le32(L);\n}\n\nstatic struct crypto_alg des_algs[2] = { {\n\t.cra_name\t\t=\t\"des\",\n\t.cra_driver_name\t=\t\"des-generic\",\n\t.cra_priority\t\t=\t100,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tDES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct des_ctx),\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_alignmask\t\t=\t3,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\tDES_KEY_SIZE,\n\t.cia_max_keysize\t=\tDES_KEY_SIZE,\n\t.cia_setkey\t\t=\tdes_setkey,\n\t.cia_encrypt\t\t=\tdes_encrypt,\n\t.cia_decrypt\t\t=\tdes_decrypt } }\n}, {\n\t.cra_name\t\t=\t\"des3_ede\",\n\t.cra_driver_name\t=\t\"des3_ede-generic\",\n\t.cra_priority\t\t=\t100,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tDES3_EDE_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct des3_ede_ctx),\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_alignmask\t\t=\t3,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\tDES3_EDE_KEY_SIZE,\n\t.cia_max_keysize\t=\tDES3_EDE_KEY_SIZE,\n\t.cia_setkey\t\t=\tdes3_ede_setkey,\n\t.cia_encrypt\t\t=\tdes3_ede_encrypt,\n\t.cia_decrypt\t\t=\tdes3_ede_decrypt } }\n} };\n\nMODULE_ALIAS(\"des3_ede\");\n\nstatic int __init des_generic_mod_init(void)\n{\n\treturn crypto_register_algs(des_algs, ARRAY_SIZE(des_algs));\n}\n\nstatic void __exit des_generic_mod_fini(void)\n{\n\tcrypto_unregister_algs(des_algs, ARRAY_SIZE(des_algs));\n}\n\nmodule_init(des_generic_mod_init);\nmodule_exit(des_generic_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"DES & Triple DES EDE Cipher Algorithms\");\nMODULE_AUTHOR(\"Dag Arne Osvik <da@osvik.no>\");\nMODULE_ALIAS(\"des\");\n", "/* FCrypt encryption algorithm\n *\n * Copyright (C) 2006 Red Hat, Inc. All Rights Reserved.\n * Written by David Howells (dhowells@redhat.com)\n *\n * This program is free software; you can redistribute it and/or\n * modify it under the terms of the GNU General Public License\n * as published by the Free Software Foundation; either version\n * 2 of the License, or (at your option) any later version.\n *\n * Based on code:\n *\n * Copyright (c) 1995 - 2000 Kungliga Tekniska H\u00f6gskolan\n * (Royal Institute of Technology, Stockholm, Sweden).\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n *\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n *\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n *\n * 3. Neither the name of the Institute nor the names of its contributors\n *    may be used to endorse or promote products derived from this software\n *    without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE INSTITUTE AND CONTRIBUTORS ``AS IS'' AND\n * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED.  IN NO EVENT SHALL THE INSTITUTE OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\n * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n * SUCH DAMAGE.\n */\n\n#include <asm/byteorder.h>\n#include <linux/bitops.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/crypto.h>\n\n#define ROUNDS 16\n\nstruct fcrypt_ctx {\n\t__be32 sched[ROUNDS];\n};\n\n/* Rotate right two 32 bit numbers as a 56 bit number */\n#define ror56(hi, lo, n)\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\\\n\tu32 t = lo & ((1 << n) - 1);\t\t\t\t\\\n\tlo = (lo >> n) | ((hi & ((1 << n) - 1)) << (32 - n));\t\\\n\thi = (hi >> n) | (t << (24-n));\t\t\t\t\\\n} while (0)\n\n/* Rotate right one 64 bit number as a 56 bit number */\n#define ror56_64(k, n)\t\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\\\n\tk = (k >> n) | ((k & ((1 << n) - 1)) << (56 - n));\t\\\n} while (0)\n\n/*\n * Sboxes for Feistel network derived from\n * /afs/transarc.com/public/afsps/afs.rel31b.export-src/rxkad/sboxes.h\n */\n#undef Z\n#define Z(x) cpu_to_be32(x << 3)\nstatic const __be32 sbox0[256] = {\n\tZ(0xea), Z(0x7f), Z(0xb2), Z(0x64), Z(0x9d), Z(0xb0), Z(0xd9), Z(0x11),\n\tZ(0xcd), Z(0x86), Z(0x86), Z(0x91), Z(0x0a), Z(0xb2), Z(0x93), Z(0x06),\n\tZ(0x0e), Z(0x06), Z(0xd2), Z(0x65), Z(0x73), Z(0xc5), Z(0x28), Z(0x60),\n\tZ(0xf2), Z(0x20), Z(0xb5), Z(0x38), Z(0x7e), Z(0xda), Z(0x9f), Z(0xe3),\n\tZ(0xd2), Z(0xcf), Z(0xc4), Z(0x3c), Z(0x61), Z(0xff), Z(0x4a), Z(0x4a),\n\tZ(0x35), Z(0xac), Z(0xaa), Z(0x5f), Z(0x2b), Z(0xbb), Z(0xbc), Z(0x53),\n\tZ(0x4e), Z(0x9d), Z(0x78), Z(0xa3), Z(0xdc), Z(0x09), Z(0x32), Z(0x10),\n\tZ(0xc6), Z(0x6f), Z(0x66), Z(0xd6), Z(0xab), Z(0xa9), Z(0xaf), Z(0xfd),\n\tZ(0x3b), Z(0x95), Z(0xe8), Z(0x34), Z(0x9a), Z(0x81), Z(0x72), Z(0x80),\n\tZ(0x9c), Z(0xf3), Z(0xec), Z(0xda), Z(0x9f), Z(0x26), Z(0x76), Z(0x15),\n\tZ(0x3e), Z(0x55), Z(0x4d), Z(0xde), Z(0x84), Z(0xee), Z(0xad), Z(0xc7),\n\tZ(0xf1), Z(0x6b), Z(0x3d), Z(0xd3), Z(0x04), Z(0x49), Z(0xaa), Z(0x24),\n\tZ(0x0b), Z(0x8a), Z(0x83), Z(0xba), Z(0xfa), Z(0x85), Z(0xa0), Z(0xa8),\n\tZ(0xb1), Z(0xd4), Z(0x01), Z(0xd8), Z(0x70), Z(0x64), Z(0xf0), Z(0x51),\n\tZ(0xd2), Z(0xc3), Z(0xa7), Z(0x75), Z(0x8c), Z(0xa5), Z(0x64), Z(0xef),\n\tZ(0x10), Z(0x4e), Z(0xb7), Z(0xc6), Z(0x61), Z(0x03), Z(0xeb), Z(0x44),\n\tZ(0x3d), Z(0xe5), Z(0xb3), Z(0x5b), Z(0xae), Z(0xd5), Z(0xad), Z(0x1d),\n\tZ(0xfa), Z(0x5a), Z(0x1e), Z(0x33), Z(0xab), Z(0x93), Z(0xa2), Z(0xb7),\n\tZ(0xe7), Z(0xa8), Z(0x45), Z(0xa4), Z(0xcd), Z(0x29), Z(0x63), Z(0x44),\n\tZ(0xb6), Z(0x69), Z(0x7e), Z(0x2e), Z(0x62), Z(0x03), Z(0xc8), Z(0xe0),\n\tZ(0x17), Z(0xbb), Z(0xc7), Z(0xf3), Z(0x3f), Z(0x36), Z(0xba), Z(0x71),\n\tZ(0x8e), Z(0x97), Z(0x65), Z(0x60), Z(0x69), Z(0xb6), Z(0xf6), Z(0xe6),\n\tZ(0x6e), Z(0xe0), Z(0x81), Z(0x59), Z(0xe8), Z(0xaf), Z(0xdd), Z(0x95),\n\tZ(0x22), Z(0x99), Z(0xfd), Z(0x63), Z(0x19), Z(0x74), Z(0x61), Z(0xb1),\n\tZ(0xb6), Z(0x5b), Z(0xae), Z(0x54), Z(0xb3), Z(0x70), Z(0xff), Z(0xc6),\n\tZ(0x3b), Z(0x3e), Z(0xc1), Z(0xd7), Z(0xe1), Z(0x0e), Z(0x76), Z(0xe5),\n\tZ(0x36), Z(0x4f), Z(0x59), Z(0xc7), Z(0x08), Z(0x6e), Z(0x82), Z(0xa6),\n\tZ(0x93), Z(0xc4), Z(0xaa), Z(0x26), Z(0x49), Z(0xe0), Z(0x21), Z(0x64),\n\tZ(0x07), Z(0x9f), Z(0x64), Z(0x81), Z(0x9c), Z(0xbf), Z(0xf9), Z(0xd1),\n\tZ(0x43), Z(0xf8), Z(0xb6), Z(0xb9), Z(0xf1), Z(0x24), Z(0x75), Z(0x03),\n\tZ(0xe4), Z(0xb0), Z(0x99), Z(0x46), Z(0x3d), Z(0xf5), Z(0xd1), Z(0x39),\n\tZ(0x72), Z(0x12), Z(0xf6), Z(0xba), Z(0x0c), Z(0x0d), Z(0x42), Z(0x2e)\n};\n\n#undef Z\n#define Z(x) cpu_to_be32(((x & 0x1f) << 27) | (x >> 5))\nstatic const __be32 sbox1[256] = {\n\tZ(0x77), Z(0x14), Z(0xa6), Z(0xfe), Z(0xb2), Z(0x5e), Z(0x8c), Z(0x3e),\n\tZ(0x67), Z(0x6c), Z(0xa1), Z(0x0d), Z(0xc2), Z(0xa2), Z(0xc1), Z(0x85),\n\tZ(0x6c), Z(0x7b), Z(0x67), Z(0xc6), Z(0x23), Z(0xe3), Z(0xf2), Z(0x89),\n\tZ(0x50), Z(0x9c), Z(0x03), Z(0xb7), Z(0x73), Z(0xe6), Z(0xe1), Z(0x39),\n\tZ(0x31), Z(0x2c), Z(0x27), Z(0x9f), Z(0xa5), Z(0x69), Z(0x44), Z(0xd6),\n\tZ(0x23), Z(0x83), Z(0x98), Z(0x7d), Z(0x3c), Z(0xb4), Z(0x2d), Z(0x99),\n\tZ(0x1c), Z(0x1f), Z(0x8c), Z(0x20), Z(0x03), Z(0x7c), Z(0x5f), Z(0xad),\n\tZ(0xf4), Z(0xfa), Z(0x95), Z(0xca), Z(0x76), Z(0x44), Z(0xcd), Z(0xb6),\n\tZ(0xb8), Z(0xa1), Z(0xa1), Z(0xbe), Z(0x9e), Z(0x54), Z(0x8f), Z(0x0b),\n\tZ(0x16), Z(0x74), Z(0x31), Z(0x8a), Z(0x23), Z(0x17), Z(0x04), Z(0xfa),\n\tZ(0x79), Z(0x84), Z(0xb1), Z(0xf5), Z(0x13), Z(0xab), Z(0xb5), Z(0x2e),\n\tZ(0xaa), Z(0x0c), Z(0x60), Z(0x6b), Z(0x5b), Z(0xc4), Z(0x4b), Z(0xbc),\n\tZ(0xe2), Z(0xaf), Z(0x45), Z(0x73), Z(0xfa), Z(0xc9), Z(0x49), Z(0xcd),\n\tZ(0x00), Z(0x92), Z(0x7d), Z(0x97), Z(0x7a), Z(0x18), Z(0x60), Z(0x3d),\n\tZ(0xcf), Z(0x5b), Z(0xde), Z(0xc6), Z(0xe2), Z(0xe6), Z(0xbb), Z(0x8b),\n\tZ(0x06), Z(0xda), Z(0x08), Z(0x15), Z(0x1b), Z(0x88), Z(0x6a), Z(0x17),\n\tZ(0x89), Z(0xd0), Z(0xa9), Z(0xc1), Z(0xc9), Z(0x70), Z(0x6b), Z(0xe5),\n\tZ(0x43), Z(0xf4), Z(0x68), Z(0xc8), Z(0xd3), Z(0x84), Z(0x28), Z(0x0a),\n\tZ(0x52), Z(0x66), Z(0xa3), Z(0xca), Z(0xf2), Z(0xe3), Z(0x7f), Z(0x7a),\n\tZ(0x31), Z(0xf7), Z(0x88), Z(0x94), Z(0x5e), Z(0x9c), Z(0x63), Z(0xd5),\n\tZ(0x24), Z(0x66), Z(0xfc), Z(0xb3), Z(0x57), Z(0x25), Z(0xbe), Z(0x89),\n\tZ(0x44), Z(0xc4), Z(0xe0), Z(0x8f), Z(0x23), Z(0x3c), Z(0x12), Z(0x52),\n\tZ(0xf5), Z(0x1e), Z(0xf4), Z(0xcb), Z(0x18), Z(0x33), Z(0x1f), Z(0xf8),\n\tZ(0x69), Z(0x10), Z(0x9d), Z(0xd3), Z(0xf7), Z(0x28), Z(0xf8), Z(0x30),\n\tZ(0x05), Z(0x5e), Z(0x32), Z(0xc0), Z(0xd5), Z(0x19), Z(0xbd), Z(0x45),\n\tZ(0x8b), Z(0x5b), Z(0xfd), Z(0xbc), Z(0xe2), Z(0x5c), Z(0xa9), Z(0x96),\n\tZ(0xef), Z(0x70), Z(0xcf), Z(0xc2), Z(0x2a), Z(0xb3), Z(0x61), Z(0xad),\n\tZ(0x80), Z(0x48), Z(0x81), Z(0xb7), Z(0x1d), Z(0x43), Z(0xd9), Z(0xd7),\n\tZ(0x45), Z(0xf0), Z(0xd8), Z(0x8a), Z(0x59), Z(0x7c), Z(0x57), Z(0xc1),\n\tZ(0x79), Z(0xc7), Z(0x34), Z(0xd6), Z(0x43), Z(0xdf), Z(0xe4), Z(0x78),\n\tZ(0x16), Z(0x06), Z(0xda), Z(0x92), Z(0x76), Z(0x51), Z(0xe1), Z(0xd4),\n\tZ(0x70), Z(0x03), Z(0xe0), Z(0x2f), Z(0x96), Z(0x91), Z(0x82), Z(0x80)\n};\n\n#undef Z\n#define Z(x) cpu_to_be32(x << 11)\nstatic const __be32 sbox2[256] = {\n\tZ(0xf0), Z(0x37), Z(0x24), Z(0x53), Z(0x2a), Z(0x03), Z(0x83), Z(0x86),\n\tZ(0xd1), Z(0xec), Z(0x50), Z(0xf0), Z(0x42), Z(0x78), Z(0x2f), Z(0x6d),\n\tZ(0xbf), Z(0x80), Z(0x87), Z(0x27), Z(0x95), Z(0xe2), Z(0xc5), Z(0x5d),\n\tZ(0xf9), Z(0x6f), Z(0xdb), Z(0xb4), Z(0x65), Z(0x6e), Z(0xe7), Z(0x24),\n\tZ(0xc8), Z(0x1a), Z(0xbb), Z(0x49), Z(0xb5), Z(0x0a), Z(0x7d), Z(0xb9),\n\tZ(0xe8), Z(0xdc), Z(0xb7), Z(0xd9), Z(0x45), Z(0x20), Z(0x1b), Z(0xce),\n\tZ(0x59), Z(0x9d), Z(0x6b), Z(0xbd), Z(0x0e), Z(0x8f), Z(0xa3), Z(0xa9),\n\tZ(0xbc), Z(0x74), Z(0xa6), Z(0xf6), Z(0x7f), Z(0x5f), Z(0xb1), Z(0x68),\n\tZ(0x84), Z(0xbc), Z(0xa9), Z(0xfd), Z(0x55), Z(0x50), Z(0xe9), Z(0xb6),\n\tZ(0x13), Z(0x5e), Z(0x07), Z(0xb8), Z(0x95), Z(0x02), Z(0xc0), Z(0xd0),\n\tZ(0x6a), Z(0x1a), Z(0x85), Z(0xbd), Z(0xb6), Z(0xfd), Z(0xfe), Z(0x17),\n\tZ(0x3f), Z(0x09), Z(0xa3), Z(0x8d), Z(0xfb), Z(0xed), Z(0xda), Z(0x1d),\n\tZ(0x6d), Z(0x1c), Z(0x6c), Z(0x01), Z(0x5a), Z(0xe5), Z(0x71), Z(0x3e),\n\tZ(0x8b), Z(0x6b), Z(0xbe), Z(0x29), Z(0xeb), Z(0x12), Z(0x19), Z(0x34),\n\tZ(0xcd), Z(0xb3), Z(0xbd), Z(0x35), Z(0xea), Z(0x4b), Z(0xd5), Z(0xae),\n\tZ(0x2a), Z(0x79), Z(0x5a), Z(0xa5), Z(0x32), Z(0x12), Z(0x7b), Z(0xdc),\n\tZ(0x2c), Z(0xd0), Z(0x22), Z(0x4b), Z(0xb1), Z(0x85), Z(0x59), Z(0x80),\n\tZ(0xc0), Z(0x30), Z(0x9f), Z(0x73), Z(0xd3), Z(0x14), Z(0x48), Z(0x40),\n\tZ(0x07), Z(0x2d), Z(0x8f), Z(0x80), Z(0x0f), Z(0xce), Z(0x0b), Z(0x5e),\n\tZ(0xb7), Z(0x5e), Z(0xac), Z(0x24), Z(0x94), Z(0x4a), Z(0x18), Z(0x15),\n\tZ(0x05), Z(0xe8), Z(0x02), Z(0x77), Z(0xa9), Z(0xc7), Z(0x40), Z(0x45),\n\tZ(0x89), Z(0xd1), Z(0xea), Z(0xde), Z(0x0c), Z(0x79), Z(0x2a), Z(0x99),\n\tZ(0x6c), Z(0x3e), Z(0x95), Z(0xdd), Z(0x8c), Z(0x7d), Z(0xad), Z(0x6f),\n\tZ(0xdc), Z(0xff), Z(0xfd), Z(0x62), Z(0x47), Z(0xb3), Z(0x21), Z(0x8a),\n\tZ(0xec), Z(0x8e), Z(0x19), Z(0x18), Z(0xb4), Z(0x6e), Z(0x3d), Z(0xfd),\n\tZ(0x74), Z(0x54), Z(0x1e), Z(0x04), Z(0x85), Z(0xd8), Z(0xbc), Z(0x1f),\n\tZ(0x56), Z(0xe7), Z(0x3a), Z(0x56), Z(0x67), Z(0xd6), Z(0xc8), Z(0xa5),\n\tZ(0xf3), Z(0x8e), Z(0xde), Z(0xae), Z(0x37), Z(0x49), Z(0xb7), Z(0xfa),\n\tZ(0xc8), Z(0xf4), Z(0x1f), Z(0xe0), Z(0x2a), Z(0x9b), Z(0x15), Z(0xd1),\n\tZ(0x34), Z(0x0e), Z(0xb5), Z(0xe0), Z(0x44), Z(0x78), Z(0x84), Z(0x59),\n\tZ(0x56), Z(0x68), Z(0x77), Z(0xa5), Z(0x14), Z(0x06), Z(0xf5), Z(0x2f),\n\tZ(0x8c), Z(0x8a), Z(0x73), Z(0x80), Z(0x76), Z(0xb4), Z(0x10), Z(0x86)\n};\n\n#undef Z\n#define Z(x) cpu_to_be32(x << 19)\nstatic const __be32 sbox3[256] = {\n\tZ(0xa9), Z(0x2a), Z(0x48), Z(0x51), Z(0x84), Z(0x7e), Z(0x49), Z(0xe2),\n\tZ(0xb5), Z(0xb7), Z(0x42), Z(0x33), Z(0x7d), Z(0x5d), Z(0xa6), Z(0x12),\n\tZ(0x44), Z(0x48), Z(0x6d), Z(0x28), Z(0xaa), Z(0x20), Z(0x6d), Z(0x57),\n\tZ(0xd6), Z(0x6b), Z(0x5d), Z(0x72), Z(0xf0), Z(0x92), Z(0x5a), Z(0x1b),\n\tZ(0x53), Z(0x80), Z(0x24), Z(0x70), Z(0x9a), Z(0xcc), Z(0xa7), Z(0x66),\n\tZ(0xa1), Z(0x01), Z(0xa5), Z(0x41), Z(0x97), Z(0x41), Z(0x31), Z(0x82),\n\tZ(0xf1), Z(0x14), Z(0xcf), Z(0x53), Z(0x0d), Z(0xa0), Z(0x10), Z(0xcc),\n\tZ(0x2a), Z(0x7d), Z(0xd2), Z(0xbf), Z(0x4b), Z(0x1a), Z(0xdb), Z(0x16),\n\tZ(0x47), Z(0xf6), Z(0x51), Z(0x36), Z(0xed), Z(0xf3), Z(0xb9), Z(0x1a),\n\tZ(0xa7), Z(0xdf), Z(0x29), Z(0x43), Z(0x01), Z(0x54), Z(0x70), Z(0xa4),\n\tZ(0xbf), Z(0xd4), Z(0x0b), Z(0x53), Z(0x44), Z(0x60), Z(0x9e), Z(0x23),\n\tZ(0xa1), Z(0x18), Z(0x68), Z(0x4f), Z(0xf0), Z(0x2f), Z(0x82), Z(0xc2),\n\tZ(0x2a), Z(0x41), Z(0xb2), Z(0x42), Z(0x0c), Z(0xed), Z(0x0c), Z(0x1d),\n\tZ(0x13), Z(0x3a), Z(0x3c), Z(0x6e), Z(0x35), Z(0xdc), Z(0x60), Z(0x65),\n\tZ(0x85), Z(0xe9), Z(0x64), Z(0x02), Z(0x9a), Z(0x3f), Z(0x9f), Z(0x87),\n\tZ(0x96), Z(0xdf), Z(0xbe), Z(0xf2), Z(0xcb), Z(0xe5), Z(0x6c), Z(0xd4),\n\tZ(0x5a), Z(0x83), Z(0xbf), Z(0x92), Z(0x1b), Z(0x94), Z(0x00), Z(0x42),\n\tZ(0xcf), Z(0x4b), Z(0x00), Z(0x75), Z(0xba), Z(0x8f), Z(0x76), Z(0x5f),\n\tZ(0x5d), Z(0x3a), Z(0x4d), Z(0x09), Z(0x12), Z(0x08), Z(0x38), Z(0x95),\n\tZ(0x17), Z(0xe4), Z(0x01), Z(0x1d), Z(0x4c), Z(0xa9), Z(0xcc), Z(0x85),\n\tZ(0x82), Z(0x4c), Z(0x9d), Z(0x2f), Z(0x3b), Z(0x66), Z(0xa1), Z(0x34),\n\tZ(0x10), Z(0xcd), Z(0x59), Z(0x89), Z(0xa5), Z(0x31), Z(0xcf), Z(0x05),\n\tZ(0xc8), Z(0x84), Z(0xfa), Z(0xc7), Z(0xba), Z(0x4e), Z(0x8b), Z(0x1a),\n\tZ(0x19), Z(0xf1), Z(0xa1), Z(0x3b), Z(0x18), Z(0x12), Z(0x17), Z(0xb0),\n\tZ(0x98), Z(0x8d), Z(0x0b), Z(0x23), Z(0xc3), Z(0x3a), Z(0x2d), Z(0x20),\n\tZ(0xdf), Z(0x13), Z(0xa0), Z(0xa8), Z(0x4c), Z(0x0d), Z(0x6c), Z(0x2f),\n\tZ(0x47), Z(0x13), Z(0x13), Z(0x52), Z(0x1f), Z(0x2d), Z(0xf5), Z(0x79),\n\tZ(0x3d), Z(0xa2), Z(0x54), Z(0xbd), Z(0x69), Z(0xc8), Z(0x6b), Z(0xf3),\n\tZ(0x05), Z(0x28), Z(0xf1), Z(0x16), Z(0x46), Z(0x40), Z(0xb0), Z(0x11),\n\tZ(0xd3), Z(0xb7), Z(0x95), Z(0x49), Z(0xcf), Z(0xc3), Z(0x1d), Z(0x8f),\n\tZ(0xd8), Z(0xe1), Z(0x73), Z(0xdb), Z(0xad), Z(0xc8), Z(0xc9), Z(0xa9),\n\tZ(0xa1), Z(0xc2), Z(0xc5), Z(0xe3), Z(0xba), Z(0xfc), Z(0x0e), Z(0x25)\n};\n\n/*\n * This is a 16 round Feistel network with permutation F_ENCRYPT\n */\n#define F_ENCRYPT(R, L, sched)\t\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tunion lc4 { __be32 l; u8 c[4]; } u;\t\t\t\t\\\n\tu.l = sched ^ R;\t\t\t\t\t\t\\\n\tL ^= sbox0[u.c[0]] ^ sbox1[u.c[1]] ^ sbox2[u.c[2]] ^ sbox3[u.c[3]]; \\\n} while (0)\n\n/*\n * encryptor\n */\nstatic void fcrypt_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tconst struct fcrypt_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct {\n\t\t__be32 l, r;\n\t} X;\n\n\tmemcpy(&X, src, sizeof(X));\n\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0x0]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0x1]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0x2]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0x3]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0x4]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0x5]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0x6]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0x7]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0x8]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0x9]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0xa]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0xb]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0xc]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0xd]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0xe]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0xf]);\n\n\tmemcpy(dst, &X, sizeof(X));\n}\n\n/*\n * decryptor\n */\nstatic void fcrypt_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tconst struct fcrypt_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct {\n\t\t__be32 l, r;\n\t} X;\n\n\tmemcpy(&X, src, sizeof(X));\n\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0xf]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0xe]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0xd]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0xc]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0xb]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0xa]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0x9]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0x8]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0x7]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0x6]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0x5]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0x4]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0x3]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0x2]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0x1]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0x0]);\n\n\tmemcpy(dst, &X, sizeof(X));\n}\n\n/*\n * Generate a key schedule from key, the least significant bit in each key byte\n * is parity and shall be ignored. This leaves 56 significant bits in the key\n * to scatter over the 16 key schedules. For each schedule extract the low\n * order 32 bits and use as schedule, then rotate right by 11 bits.\n */\nstatic int fcrypt_setkey(struct crypto_tfm *tfm, const u8 *key, unsigned int keylen)\n{\n\tstruct fcrypt_ctx *ctx = crypto_tfm_ctx(tfm);\n\n#if BITS_PER_LONG == 64  /* the 64-bit version can also be used for 32-bit\n\t\t\t  * kernels - it seems to be faster but the code is\n\t\t\t  * larger */\n\n\tu64 k;\t/* k holds all 56 non-parity bits */\n\n\t/* discard the parity bits */\n\tk = (*key++) >> 1;\n\tk <<= 7;\n\tk |= (*key++) >> 1;\n\tk <<= 7;\n\tk |= (*key++) >> 1;\n\tk <<= 7;\n\tk |= (*key++) >> 1;\n\tk <<= 7;\n\tk |= (*key++) >> 1;\n\tk <<= 7;\n\tk |= (*key++) >> 1;\n\tk <<= 7;\n\tk |= (*key++) >> 1;\n\tk <<= 7;\n\tk |= (*key) >> 1;\n\n\t/* Use lower 32 bits for schedule, rotate by 11 each round (16 times) */\n\tctx->sched[0x0] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0x1] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0x2] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0x3] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0x4] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0x5] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0x6] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0x7] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0x8] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0x9] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0xa] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0xb] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0xc] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0xd] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0xe] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0xf] = cpu_to_be32(k);\n\n\treturn 0;\n#else\n\tu32 hi, lo;\t\t/* hi is upper 24 bits and lo lower 32, total 56 */\n\n\t/* discard the parity bits */\n\tlo = (*key++) >> 1;\n\tlo <<= 7;\n\tlo |= (*key++) >> 1;\n\tlo <<= 7;\n\tlo |= (*key++) >> 1;\n\tlo <<= 7;\n\tlo |= (*key++) >> 1;\n\thi = lo >> 4;\n\tlo &= 0xf;\n\tlo <<= 7;\n\tlo |= (*key++) >> 1;\n\tlo <<= 7;\n\tlo |= (*key++) >> 1;\n\tlo <<= 7;\n\tlo |= (*key++) >> 1;\n\tlo <<= 7;\n\tlo |= (*key) >> 1;\n\n\t/* Use lower 32 bits for schedule, rotate by 11 each round (16 times) */\n\tctx->sched[0x0] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0x1] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0x2] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0x3] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0x4] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0x5] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0x6] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0x7] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0x8] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0x9] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0xa] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0xb] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0xc] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0xd] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0xe] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0xf] = cpu_to_be32(lo);\n\treturn 0;\n#endif\n}\n\nstatic struct crypto_alg fcrypt_alg = {\n\t.cra_name\t\t=\t\"fcrypt\",\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\t8,\n\t.cra_ctxsize\t\t=\tsizeof(struct fcrypt_ctx),\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_alignmask\t\t=\t3,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\t8,\n\t.cia_max_keysize\t=\t8,\n\t.cia_setkey\t\t=\tfcrypt_setkey,\n\t.cia_encrypt\t\t=\tfcrypt_encrypt,\n\t.cia_decrypt\t\t=\tfcrypt_decrypt } }\n};\n\nstatic int __init fcrypt_mod_init(void)\n{\n\treturn crypto_register_alg(&fcrypt_alg);\n}\n\nstatic void __exit fcrypt_mod_fini(void)\n{\n\tcrypto_unregister_alg(&fcrypt_alg);\n}\n\nmodule_init(fcrypt_mod_init);\nmodule_exit(fcrypt_mod_fini);\n\nMODULE_LICENSE(\"Dual BSD/GPL\");\nMODULE_DESCRIPTION(\"FCrypt Cipher Algorithm\");\nMODULE_AUTHOR(\"David Howells <dhowells@redhat.com>\");\n", "/*\n * GCM: Galois/Counter Mode.\n *\n * Copyright (c) 2007 Nokia Siemens Networks - Mikko Herranen <mh1@iki.fi>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License version 2 as published\n * by the Free Software Foundation.\n */\n\n#include <crypto/gf128mul.h>\n#include <crypto/internal/aead.h>\n#include <crypto/internal/skcipher.h>\n#include <crypto/internal/hash.h>\n#include <crypto/scatterwalk.h>\n#include <crypto/hash.h>\n#include \"internal.h\"\n#include <linux/completion.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/slab.h>\n\nstruct gcm_instance_ctx {\n\tstruct crypto_skcipher_spawn ctr;\n\tstruct crypto_ahash_spawn ghash;\n};\n\nstruct crypto_gcm_ctx {\n\tstruct crypto_ablkcipher *ctr;\n\tstruct crypto_ahash *ghash;\n};\n\nstruct crypto_rfc4106_ctx {\n\tstruct crypto_aead *child;\n\tu8 nonce[4];\n};\n\nstruct crypto_rfc4543_instance_ctx {\n\tstruct crypto_aead_spawn aead;\n\tstruct crypto_skcipher_spawn null;\n};\n\nstruct crypto_rfc4543_ctx {\n\tstruct crypto_aead *child;\n\tstruct crypto_blkcipher *null;\n\tu8 nonce[4];\n};\n\nstruct crypto_rfc4543_req_ctx {\n\tu8 auth_tag[16];\n\tu8 assocbuf[32];\n\tstruct scatterlist cipher[1];\n\tstruct scatterlist payload[2];\n\tstruct scatterlist assoc[2];\n\tstruct aead_request subreq;\n};\n\nstruct crypto_gcm_ghash_ctx {\n\tunsigned int cryptlen;\n\tstruct scatterlist *src;\n\tvoid (*complete)(struct aead_request *req, int err);\n};\n\nstruct crypto_gcm_req_priv_ctx {\n\tu8 auth_tag[16];\n\tu8 iauth_tag[16];\n\tstruct scatterlist src[2];\n\tstruct scatterlist dst[2];\n\tstruct crypto_gcm_ghash_ctx ghash_ctx;\n\tunion {\n\t\tstruct ahash_request ahreq;\n\t\tstruct ablkcipher_request abreq;\n\t} u;\n};\n\nstruct crypto_gcm_setkey_result {\n\tint err;\n\tstruct completion completion;\n};\n\nstatic void *gcm_zeroes;\n\nstatic inline struct crypto_gcm_req_priv_ctx *crypto_gcm_reqctx(\n\tstruct aead_request *req)\n{\n\tunsigned long align = crypto_aead_alignmask(crypto_aead_reqtfm(req));\n\n\treturn (void *)PTR_ALIGN((u8 *)aead_request_ctx(req), align + 1);\n}\n\nstatic void crypto_gcm_setkey_done(struct crypto_async_request *req, int err)\n{\n\tstruct crypto_gcm_setkey_result *result = req->data;\n\n\tif (err == -EINPROGRESS)\n\t\treturn;\n\n\tresult->err = err;\n\tcomplete(&result->completion);\n}\n\nstatic int crypto_gcm_setkey(struct crypto_aead *aead, const u8 *key,\n\t\t\t     unsigned int keylen)\n{\n\tstruct crypto_gcm_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct crypto_ahash *ghash = ctx->ghash;\n\tstruct crypto_ablkcipher *ctr = ctx->ctr;\n\tstruct {\n\t\tbe128 hash;\n\t\tu8 iv[8];\n\n\t\tstruct crypto_gcm_setkey_result result;\n\n\t\tstruct scatterlist sg[1];\n\t\tstruct ablkcipher_request req;\n\t} *data;\n\tint err;\n\n\tcrypto_ablkcipher_clear_flags(ctr, CRYPTO_TFM_REQ_MASK);\n\tcrypto_ablkcipher_set_flags(ctr, crypto_aead_get_flags(aead) &\n\t\t\t\t   CRYPTO_TFM_REQ_MASK);\n\n\terr = crypto_ablkcipher_setkey(ctr, key, keylen);\n\tif (err)\n\t\treturn err;\n\n\tcrypto_aead_set_flags(aead, crypto_ablkcipher_get_flags(ctr) &\n\t\t\t\t       CRYPTO_TFM_RES_MASK);\n\n\tdata = kzalloc(sizeof(*data) + crypto_ablkcipher_reqsize(ctr),\n\t\t       GFP_KERNEL);\n\tif (!data)\n\t\treturn -ENOMEM;\n\n\tinit_completion(&data->result.completion);\n\tsg_init_one(data->sg, &data->hash, sizeof(data->hash));\n\tablkcipher_request_set_tfm(&data->req, ctr);\n\tablkcipher_request_set_callback(&data->req, CRYPTO_TFM_REQ_MAY_SLEEP |\n\t\t\t\t\t\t    CRYPTO_TFM_REQ_MAY_BACKLOG,\n\t\t\t\t\tcrypto_gcm_setkey_done,\n\t\t\t\t\t&data->result);\n\tablkcipher_request_set_crypt(&data->req, data->sg, data->sg,\n\t\t\t\t     sizeof(data->hash), data->iv);\n\n\terr = crypto_ablkcipher_encrypt(&data->req);\n\tif (err == -EINPROGRESS || err == -EBUSY) {\n\t\terr = wait_for_completion_interruptible(\n\t\t\t&data->result.completion);\n\t\tif (!err)\n\t\t\terr = data->result.err;\n\t}\n\n\tif (err)\n\t\tgoto out;\n\n\tcrypto_ahash_clear_flags(ghash, CRYPTO_TFM_REQ_MASK);\n\tcrypto_ahash_set_flags(ghash, crypto_aead_get_flags(aead) &\n\t\t\t       CRYPTO_TFM_REQ_MASK);\n\terr = crypto_ahash_setkey(ghash, (u8 *)&data->hash, sizeof(be128));\n\tcrypto_aead_set_flags(aead, crypto_ahash_get_flags(ghash) &\n\t\t\t      CRYPTO_TFM_RES_MASK);\n\nout:\n\tkfree(data);\n\treturn err;\n}\n\nstatic int crypto_gcm_setauthsize(struct crypto_aead *tfm,\n\t\t\t\t  unsigned int authsize)\n{\n\tswitch (authsize) {\n\tcase 4:\n\tcase 8:\n\tcase 12:\n\tcase 13:\n\tcase 14:\n\tcase 15:\n\tcase 16:\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic void crypto_gcm_init_crypt(struct ablkcipher_request *ablk_req,\n\t\t\t\t  struct aead_request *req,\n\t\t\t\t  unsigned int cryptlen)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_gcm_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct scatterlist *dst;\n\t__be32 counter = cpu_to_be32(1);\n\n\tmemset(pctx->auth_tag, 0, sizeof(pctx->auth_tag));\n\tmemcpy(req->iv + 12, &counter, 4);\n\n\tsg_init_table(pctx->src, 2);\n\tsg_set_buf(pctx->src, pctx->auth_tag, sizeof(pctx->auth_tag));\n\tscatterwalk_sg_chain(pctx->src, 2, req->src);\n\n\tdst = pctx->src;\n\tif (req->src != req->dst) {\n\t\tsg_init_table(pctx->dst, 2);\n\t\tsg_set_buf(pctx->dst, pctx->auth_tag, sizeof(pctx->auth_tag));\n\t\tscatterwalk_sg_chain(pctx->dst, 2, req->dst);\n\t\tdst = pctx->dst;\n\t}\n\n\tablkcipher_request_set_tfm(ablk_req, ctx->ctr);\n\tablkcipher_request_set_crypt(ablk_req, pctx->src, dst,\n\t\t\t\t     cryptlen + sizeof(pctx->auth_tag),\n\t\t\t\t     req->iv);\n}\n\nstatic inline unsigned int gcm_remain(unsigned int len)\n{\n\tlen &= 0xfU;\n\treturn len ? 16 - len : 0;\n}\n\nstatic void gcm_hash_len_done(struct crypto_async_request *areq, int err);\nstatic void gcm_hash_final_done(struct crypto_async_request *areq, int err);\n\nstatic int gcm_hash_update(struct aead_request *req,\n\t\t\t   struct crypto_gcm_req_priv_ctx *pctx,\n\t\t\t   crypto_completion_t compl,\n\t\t\t   struct scatterlist *src,\n\t\t\t   unsigned int len)\n{\n\tstruct ahash_request *ahreq = &pctx->u.ahreq;\n\n\tahash_request_set_callback(ahreq, aead_request_flags(req),\n\t\t\t\t   compl, req);\n\tahash_request_set_crypt(ahreq, src, NULL, len);\n\n\treturn crypto_ahash_update(ahreq);\n}\n\nstatic int gcm_hash_remain(struct aead_request *req,\n\t\t\t   struct crypto_gcm_req_priv_ctx *pctx,\n\t\t\t   unsigned int remain,\n\t\t\t   crypto_completion_t compl)\n{\n\tstruct ahash_request *ahreq = &pctx->u.ahreq;\n\n\tahash_request_set_callback(ahreq, aead_request_flags(req),\n\t\t\t\t   compl, req);\n\tsg_init_one(pctx->src, gcm_zeroes, remain);\n\tahash_request_set_crypt(ahreq, pctx->src, NULL, remain);\n\n\treturn crypto_ahash_update(ahreq);\n}\n\nstatic int gcm_hash_len(struct aead_request *req,\n\t\t\tstruct crypto_gcm_req_priv_ctx *pctx)\n{\n\tstruct ahash_request *ahreq = &pctx->u.ahreq;\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\tu128 lengths;\n\n\tlengths.a = cpu_to_be64(req->assoclen * 8);\n\tlengths.b = cpu_to_be64(gctx->cryptlen * 8);\n\tmemcpy(pctx->iauth_tag, &lengths, 16);\n\tsg_init_one(pctx->src, pctx->iauth_tag, 16);\n\tahash_request_set_callback(ahreq, aead_request_flags(req),\n\t\t\t\t   gcm_hash_len_done, req);\n\tahash_request_set_crypt(ahreq, pctx->src,\n\t\t\t\tNULL, sizeof(lengths));\n\n\treturn crypto_ahash_update(ahreq);\n}\n\nstatic int gcm_hash_final(struct aead_request *req,\n\t\t\t  struct crypto_gcm_req_priv_ctx *pctx)\n{\n\tstruct ahash_request *ahreq = &pctx->u.ahreq;\n\n\tahash_request_set_callback(ahreq, aead_request_flags(req),\n\t\t\t\t   gcm_hash_final_done, req);\n\tahash_request_set_crypt(ahreq, NULL, pctx->iauth_tag, 0);\n\n\treturn crypto_ahash_final(ahreq);\n}\n\nstatic void __gcm_hash_final_done(struct aead_request *req, int err)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\n\tif (!err)\n\t\tcrypto_xor(pctx->auth_tag, pctx->iauth_tag, 16);\n\n\tgctx->complete(req, err);\n}\n\nstatic void gcm_hash_final_done(struct crypto_async_request *areq, int err)\n{\n\tstruct aead_request *req = areq->data;\n\n\t__gcm_hash_final_done(req, err);\n}\n\nstatic void __gcm_hash_len_done(struct aead_request *req, int err)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\n\tif (!err) {\n\t\terr = gcm_hash_final(req, pctx);\n\t\tif (err == -EINPROGRESS || err == -EBUSY)\n\t\t\treturn;\n\t}\n\n\t__gcm_hash_final_done(req, err);\n}\n\nstatic void gcm_hash_len_done(struct crypto_async_request *areq, int err)\n{\n\tstruct aead_request *req = areq->data;\n\n\t__gcm_hash_len_done(req, err);\n}\n\nstatic void __gcm_hash_crypt_remain_done(struct aead_request *req, int err)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\n\tif (!err) {\n\t\terr = gcm_hash_len(req, pctx);\n\t\tif (err == -EINPROGRESS || err == -EBUSY)\n\t\t\treturn;\n\t}\n\n\t__gcm_hash_len_done(req, err);\n}\n\nstatic void gcm_hash_crypt_remain_done(struct crypto_async_request *areq,\n\t\t\t\t       int err)\n{\n\tstruct aead_request *req = areq->data;\n\n\t__gcm_hash_crypt_remain_done(req, err);\n}\n\nstatic void __gcm_hash_crypt_done(struct aead_request *req, int err)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\tunsigned int remain;\n\n\tif (!err) {\n\t\tremain = gcm_remain(gctx->cryptlen);\n\t\tBUG_ON(!remain);\n\t\terr = gcm_hash_remain(req, pctx, remain,\n\t\t\t\t      gcm_hash_crypt_remain_done);\n\t\tif (err == -EINPROGRESS || err == -EBUSY)\n\t\t\treturn;\n\t}\n\n\t__gcm_hash_crypt_remain_done(req, err);\n}\n\nstatic void gcm_hash_crypt_done(struct crypto_async_request *areq, int err)\n{\n\tstruct aead_request *req = areq->data;\n\n\t__gcm_hash_crypt_done(req, err);\n}\n\nstatic void __gcm_hash_assoc_remain_done(struct aead_request *req, int err)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\tcrypto_completion_t compl;\n\tunsigned int remain = 0;\n\n\tif (!err && gctx->cryptlen) {\n\t\tremain = gcm_remain(gctx->cryptlen);\n\t\tcompl = remain ? gcm_hash_crypt_done :\n\t\t\tgcm_hash_crypt_remain_done;\n\t\terr = gcm_hash_update(req, pctx, compl,\n\t\t\t\t      gctx->src, gctx->cryptlen);\n\t\tif (err == -EINPROGRESS || err == -EBUSY)\n\t\t\treturn;\n\t}\n\n\tif (remain)\n\t\t__gcm_hash_crypt_done(req, err);\n\telse\n\t\t__gcm_hash_crypt_remain_done(req, err);\n}\n\nstatic void gcm_hash_assoc_remain_done(struct crypto_async_request *areq,\n\t\t\t\t       int err)\n{\n\tstruct aead_request *req = areq->data;\n\n\t__gcm_hash_assoc_remain_done(req, err);\n}\n\nstatic void __gcm_hash_assoc_done(struct aead_request *req, int err)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tunsigned int remain;\n\n\tif (!err) {\n\t\tremain = gcm_remain(req->assoclen);\n\t\tBUG_ON(!remain);\n\t\terr = gcm_hash_remain(req, pctx, remain,\n\t\t\t\t      gcm_hash_assoc_remain_done);\n\t\tif (err == -EINPROGRESS || err == -EBUSY)\n\t\t\treturn;\n\t}\n\n\t__gcm_hash_assoc_remain_done(req, err);\n}\n\nstatic void gcm_hash_assoc_done(struct crypto_async_request *areq, int err)\n{\n\tstruct aead_request *req = areq->data;\n\n\t__gcm_hash_assoc_done(req, err);\n}\n\nstatic void __gcm_hash_init_done(struct aead_request *req, int err)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tcrypto_completion_t compl;\n\tunsigned int remain = 0;\n\n\tif (!err && req->assoclen) {\n\t\tremain = gcm_remain(req->assoclen);\n\t\tcompl = remain ? gcm_hash_assoc_done :\n\t\t\tgcm_hash_assoc_remain_done;\n\t\terr = gcm_hash_update(req, pctx, compl,\n\t\t\t\t      req->assoc, req->assoclen);\n\t\tif (err == -EINPROGRESS || err == -EBUSY)\n\t\t\treturn;\n\t}\n\n\tif (remain)\n\t\t__gcm_hash_assoc_done(req, err);\n\telse\n\t\t__gcm_hash_assoc_remain_done(req, err);\n}\n\nstatic void gcm_hash_init_done(struct crypto_async_request *areq, int err)\n{\n\tstruct aead_request *req = areq->data;\n\n\t__gcm_hash_init_done(req, err);\n}\n\nstatic int gcm_hash(struct aead_request *req,\n\t\t    struct crypto_gcm_req_priv_ctx *pctx)\n{\n\tstruct ahash_request *ahreq = &pctx->u.ahreq;\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\tstruct crypto_gcm_ctx *ctx = crypto_tfm_ctx(req->base.tfm);\n\tunsigned int remain;\n\tcrypto_completion_t compl;\n\tint err;\n\n\tahash_request_set_tfm(ahreq, ctx->ghash);\n\n\tahash_request_set_callback(ahreq, aead_request_flags(req),\n\t\t\t\t   gcm_hash_init_done, req);\n\terr = crypto_ahash_init(ahreq);\n\tif (err)\n\t\treturn err;\n\tremain = gcm_remain(req->assoclen);\n\tcompl = remain ? gcm_hash_assoc_done : gcm_hash_assoc_remain_done;\n\terr = gcm_hash_update(req, pctx, compl, req->assoc, req->assoclen);\n\tif (err)\n\t\treturn err;\n\tif (remain) {\n\t\terr = gcm_hash_remain(req, pctx, remain,\n\t\t\t\t      gcm_hash_assoc_remain_done);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\tremain = gcm_remain(gctx->cryptlen);\n\tcompl = remain ? gcm_hash_crypt_done : gcm_hash_crypt_remain_done;\n\terr = gcm_hash_update(req, pctx, compl, gctx->src, gctx->cryptlen);\n\tif (err)\n\t\treturn err;\n\tif (remain) {\n\t\terr = gcm_hash_remain(req, pctx, remain,\n\t\t\t\t      gcm_hash_crypt_remain_done);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\terr = gcm_hash_len(req, pctx);\n\tif (err)\n\t\treturn err;\n\terr = gcm_hash_final(req, pctx);\n\tif (err)\n\t\treturn err;\n\n\treturn 0;\n}\n\nstatic void gcm_enc_copy_hash(struct aead_request *req,\n\t\t\t      struct crypto_gcm_req_priv_ctx *pctx)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tu8 *auth_tag = pctx->auth_tag;\n\n\tscatterwalk_map_and_copy(auth_tag, req->dst, req->cryptlen,\n\t\t\t\t crypto_aead_authsize(aead), 1);\n}\n\nstatic void gcm_enc_hash_done(struct aead_request *req, int err)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\n\tif (!err)\n\t\tgcm_enc_copy_hash(req, pctx);\n\n\taead_request_complete(req, err);\n}\n\nstatic void gcm_encrypt_done(struct crypto_async_request *areq, int err)\n{\n\tstruct aead_request *req = areq->data;\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\n\tif (!err) {\n\t\terr = gcm_hash(req, pctx);\n\t\tif (err == -EINPROGRESS || err == -EBUSY)\n\t\t\treturn;\n\t\telse if (!err) {\n\t\t\tcrypto_xor(pctx->auth_tag, pctx->iauth_tag, 16);\n\t\t\tgcm_enc_copy_hash(req, pctx);\n\t\t}\n\t}\n\n\taead_request_complete(req, err);\n}\n\nstatic int crypto_gcm_encrypt(struct aead_request *req)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct ablkcipher_request *abreq = &pctx->u.abreq;\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\tint err;\n\n\tcrypto_gcm_init_crypt(abreq, req, req->cryptlen);\n\tablkcipher_request_set_callback(abreq, aead_request_flags(req),\n\t\t\t\t\tgcm_encrypt_done, req);\n\n\tgctx->src = req->dst;\n\tgctx->cryptlen = req->cryptlen;\n\tgctx->complete = gcm_enc_hash_done;\n\n\terr = crypto_ablkcipher_encrypt(abreq);\n\tif (err)\n\t\treturn err;\n\n\terr = gcm_hash(req, pctx);\n\tif (err)\n\t\treturn err;\n\n\tcrypto_xor(pctx->auth_tag, pctx->iauth_tag, 16);\n\tgcm_enc_copy_hash(req, pctx);\n\n\treturn 0;\n}\n\nstatic int crypto_gcm_verify(struct aead_request *req,\n\t\t\t     struct crypto_gcm_req_priv_ctx *pctx)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tu8 *auth_tag = pctx->auth_tag;\n\tu8 *iauth_tag = pctx->iauth_tag;\n\tunsigned int authsize = crypto_aead_authsize(aead);\n\tunsigned int cryptlen = req->cryptlen - authsize;\n\n\tcrypto_xor(auth_tag, iauth_tag, 16);\n\tscatterwalk_map_and_copy(iauth_tag, req->src, cryptlen, authsize, 0);\n\treturn crypto_memneq(iauth_tag, auth_tag, authsize) ? -EBADMSG : 0;\n}\n\nstatic void gcm_decrypt_done(struct crypto_async_request *areq, int err)\n{\n\tstruct aead_request *req = areq->data;\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\n\tif (!err)\n\t\terr = crypto_gcm_verify(req, pctx);\n\n\taead_request_complete(req, err);\n}\n\nstatic void gcm_dec_hash_done(struct aead_request *req, int err)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct ablkcipher_request *abreq = &pctx->u.abreq;\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\n\tif (!err) {\n\t\tablkcipher_request_set_callback(abreq, aead_request_flags(req),\n\t\t\t\t\t\tgcm_decrypt_done, req);\n\t\tcrypto_gcm_init_crypt(abreq, req, gctx->cryptlen);\n\t\terr = crypto_ablkcipher_decrypt(abreq);\n\t\tif (err == -EINPROGRESS || err == -EBUSY)\n\t\t\treturn;\n\t\telse if (!err)\n\t\t\terr = crypto_gcm_verify(req, pctx);\n\t}\n\n\taead_request_complete(req, err);\n}\n\nstatic int crypto_gcm_decrypt(struct aead_request *req)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct ablkcipher_request *abreq = &pctx->u.abreq;\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\tunsigned int authsize = crypto_aead_authsize(aead);\n\tunsigned int cryptlen = req->cryptlen;\n\tint err;\n\n\tif (cryptlen < authsize)\n\t\treturn -EINVAL;\n\tcryptlen -= authsize;\n\n\tgctx->src = req->src;\n\tgctx->cryptlen = cryptlen;\n\tgctx->complete = gcm_dec_hash_done;\n\n\terr = gcm_hash(req, pctx);\n\tif (err)\n\t\treturn err;\n\n\tablkcipher_request_set_callback(abreq, aead_request_flags(req),\n\t\t\t\t\tgcm_decrypt_done, req);\n\tcrypto_gcm_init_crypt(abreq, req, cryptlen);\n\terr = crypto_ablkcipher_decrypt(abreq);\n\tif (err)\n\t\treturn err;\n\n\treturn crypto_gcm_verify(req, pctx);\n}\n\nstatic int crypto_gcm_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_instance *inst = (void *)tfm->__crt_alg;\n\tstruct gcm_instance_ctx *ictx = crypto_instance_ctx(inst);\n\tstruct crypto_gcm_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_ablkcipher *ctr;\n\tstruct crypto_ahash *ghash;\n\tunsigned long align;\n\tint err;\n\n\tghash = crypto_spawn_ahash(&ictx->ghash);\n\tif (IS_ERR(ghash))\n\t\treturn PTR_ERR(ghash);\n\n\tctr = crypto_spawn_skcipher(&ictx->ctr);\n\terr = PTR_ERR(ctr);\n\tif (IS_ERR(ctr))\n\t\tgoto err_free_hash;\n\n\tctx->ctr = ctr;\n\tctx->ghash = ghash;\n\n\talign = crypto_tfm_alg_alignmask(tfm);\n\talign &= ~(crypto_tfm_ctx_alignment() - 1);\n\ttfm->crt_aead.reqsize = align +\n\t\toffsetof(struct crypto_gcm_req_priv_ctx, u) +\n\t\tmax(sizeof(struct ablkcipher_request) +\n\t\t    crypto_ablkcipher_reqsize(ctr),\n\t\t    sizeof(struct ahash_request) +\n\t\t    crypto_ahash_reqsize(ghash));\n\n\treturn 0;\n\nerr_free_hash:\n\tcrypto_free_ahash(ghash);\n\treturn err;\n}\n\nstatic void crypto_gcm_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_gcm_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_ahash(ctx->ghash);\n\tcrypto_free_ablkcipher(ctx->ctr);\n}\n\nstatic struct crypto_instance *crypto_gcm_alloc_common(struct rtattr **tb,\n\t\t\t\t\t\t       const char *full_name,\n\t\t\t\t\t\t       const char *ctr_name,\n\t\t\t\t\t\t       const char *ghash_name)\n{\n\tstruct crypto_attr_type *algt;\n\tstruct crypto_instance *inst;\n\tstruct crypto_alg *ctr;\n\tstruct crypto_alg *ghash_alg;\n\tstruct ahash_alg *ghash_ahash_alg;\n\tstruct gcm_instance_ctx *ctx;\n\tint err;\n\n\talgt = crypto_get_attr_type(tb);\n\tif (IS_ERR(algt))\n\t\treturn ERR_CAST(algt);\n\n\tif ((algt->type ^ CRYPTO_ALG_TYPE_AEAD) & algt->mask)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tghash_alg = crypto_find_alg(ghash_name, &crypto_ahash_type,\n\t\t\t\t    CRYPTO_ALG_TYPE_HASH,\n\t\t\t\t    CRYPTO_ALG_TYPE_AHASH_MASK);\n\tif (IS_ERR(ghash_alg))\n\t\treturn ERR_CAST(ghash_alg);\n\n\terr = -ENOMEM;\n\tinst = kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);\n\tif (!inst)\n\t\tgoto out_put_ghash;\n\n\tctx = crypto_instance_ctx(inst);\n\tghash_ahash_alg = container_of(ghash_alg, struct ahash_alg, halg.base);\n\terr = crypto_init_ahash_spawn(&ctx->ghash, &ghash_ahash_alg->halg,\n\t\t\t\t      inst);\n\tif (err)\n\t\tgoto err_free_inst;\n\n\tcrypto_set_skcipher_spawn(&ctx->ctr, inst);\n\terr = crypto_grab_skcipher(&ctx->ctr, ctr_name, 0,\n\t\t\t\t   crypto_requires_sync(algt->type,\n\t\t\t\t\t\t\talgt->mask));\n\tif (err)\n\t\tgoto err_drop_ghash;\n\n\tctr = crypto_skcipher_spawn_alg(&ctx->ctr);\n\n\t/* We only support 16-byte blocks. */\n\tif (ctr->cra_ablkcipher.ivsize != 16)\n\t\tgoto out_put_ctr;\n\n\t/* Not a stream cipher? */\n\terr = -EINVAL;\n\tif (ctr->cra_blocksize != 1)\n\t\tgoto out_put_ctr;\n\n\terr = -ENAMETOOLONG;\n\tif (snprintf(inst->alg.cra_driver_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"gcm_base(%s,%s)\", ctr->cra_driver_name,\n\t\t     ghash_alg->cra_driver_name) >=\n\t    CRYPTO_MAX_ALG_NAME)\n\t\tgoto out_put_ctr;\n\n\tmemcpy(inst->alg.cra_name, full_name, CRYPTO_MAX_ALG_NAME);\n\n\tinst->alg.cra_flags = CRYPTO_ALG_TYPE_AEAD;\n\tinst->alg.cra_flags |= ctr->cra_flags & CRYPTO_ALG_ASYNC;\n\tinst->alg.cra_priority = ctr->cra_priority;\n\tinst->alg.cra_blocksize = 1;\n\tinst->alg.cra_alignmask = ctr->cra_alignmask | (__alignof__(u64) - 1);\n\tinst->alg.cra_type = &crypto_aead_type;\n\tinst->alg.cra_aead.ivsize = 16;\n\tinst->alg.cra_aead.maxauthsize = 16;\n\tinst->alg.cra_ctxsize = sizeof(struct crypto_gcm_ctx);\n\tinst->alg.cra_init = crypto_gcm_init_tfm;\n\tinst->alg.cra_exit = crypto_gcm_exit_tfm;\n\tinst->alg.cra_aead.setkey = crypto_gcm_setkey;\n\tinst->alg.cra_aead.setauthsize = crypto_gcm_setauthsize;\n\tinst->alg.cra_aead.encrypt = crypto_gcm_encrypt;\n\tinst->alg.cra_aead.decrypt = crypto_gcm_decrypt;\n\nout:\n\tcrypto_mod_put(ghash_alg);\n\treturn inst;\n\nout_put_ctr:\n\tcrypto_drop_skcipher(&ctx->ctr);\nerr_drop_ghash:\n\tcrypto_drop_ahash(&ctx->ghash);\nerr_free_inst:\n\tkfree(inst);\nout_put_ghash:\n\tinst = ERR_PTR(err);\n\tgoto out;\n}\n\nstatic struct crypto_instance *crypto_gcm_alloc(struct rtattr **tb)\n{\n\tconst char *cipher_name;\n\tchar ctr_name[CRYPTO_MAX_ALG_NAME];\n\tchar full_name[CRYPTO_MAX_ALG_NAME];\n\n\tcipher_name = crypto_attr_alg_name(tb[1]);\n\tif (IS_ERR(cipher_name))\n\t\treturn ERR_CAST(cipher_name);\n\n\tif (snprintf(ctr_name, CRYPTO_MAX_ALG_NAME, \"ctr(%s)\", cipher_name) >=\n\t    CRYPTO_MAX_ALG_NAME)\n\t\treturn ERR_PTR(-ENAMETOOLONG);\n\n\tif (snprintf(full_name, CRYPTO_MAX_ALG_NAME, \"gcm(%s)\", cipher_name) >=\n\t    CRYPTO_MAX_ALG_NAME)\n\t\treturn ERR_PTR(-ENAMETOOLONG);\n\n\treturn crypto_gcm_alloc_common(tb, full_name, ctr_name, \"ghash\");\n}\n\nstatic void crypto_gcm_free(struct crypto_instance *inst)\n{\n\tstruct gcm_instance_ctx *ctx = crypto_instance_ctx(inst);\n\n\tcrypto_drop_skcipher(&ctx->ctr);\n\tcrypto_drop_ahash(&ctx->ghash);\n\tkfree(inst);\n}\n\nstatic struct crypto_template crypto_gcm_tmpl = {\n\t.name = \"gcm\",\n\t.alloc = crypto_gcm_alloc,\n\t.free = crypto_gcm_free,\n\t.module = THIS_MODULE,\n};\n\nstatic struct crypto_instance *crypto_gcm_base_alloc(struct rtattr **tb)\n{\n\tconst char *ctr_name;\n\tconst char *ghash_name;\n\tchar full_name[CRYPTO_MAX_ALG_NAME];\n\n\tctr_name = crypto_attr_alg_name(tb[1]);\n\tif (IS_ERR(ctr_name))\n\t\treturn ERR_CAST(ctr_name);\n\n\tghash_name = crypto_attr_alg_name(tb[2]);\n\tif (IS_ERR(ghash_name))\n\t\treturn ERR_CAST(ghash_name);\n\n\tif (snprintf(full_name, CRYPTO_MAX_ALG_NAME, \"gcm_base(%s,%s)\",\n\t\t     ctr_name, ghash_name) >= CRYPTO_MAX_ALG_NAME)\n\t\treturn ERR_PTR(-ENAMETOOLONG);\n\n\treturn crypto_gcm_alloc_common(tb, full_name, ctr_name, ghash_name);\n}\n\nstatic struct crypto_template crypto_gcm_base_tmpl = {\n\t.name = \"gcm_base\",\n\t.alloc = crypto_gcm_base_alloc,\n\t.free = crypto_gcm_free,\n\t.module = THIS_MODULE,\n};\n\nstatic int crypto_rfc4106_setkey(struct crypto_aead *parent, const u8 *key,\n\t\t\t\t unsigned int keylen)\n{\n\tstruct crypto_rfc4106_ctx *ctx = crypto_aead_ctx(parent);\n\tstruct crypto_aead *child = ctx->child;\n\tint err;\n\n\tif (keylen < 4)\n\t\treturn -EINVAL;\n\n\tkeylen -= 4;\n\tmemcpy(ctx->nonce, key + keylen, 4);\n\n\tcrypto_aead_clear_flags(child, CRYPTO_TFM_REQ_MASK);\n\tcrypto_aead_set_flags(child, crypto_aead_get_flags(parent) &\n\t\t\t\t     CRYPTO_TFM_REQ_MASK);\n\terr = crypto_aead_setkey(child, key, keylen);\n\tcrypto_aead_set_flags(parent, crypto_aead_get_flags(child) &\n\t\t\t\t      CRYPTO_TFM_RES_MASK);\n\n\treturn err;\n}\n\nstatic int crypto_rfc4106_setauthsize(struct crypto_aead *parent,\n\t\t\t\t      unsigned int authsize)\n{\n\tstruct crypto_rfc4106_ctx *ctx = crypto_aead_ctx(parent);\n\n\tswitch (authsize) {\n\tcase 8:\n\tcase 12:\n\tcase 16:\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn crypto_aead_setauthsize(ctx->child, authsize);\n}\n\nstatic struct aead_request *crypto_rfc4106_crypt(struct aead_request *req)\n{\n\tstruct aead_request *subreq = aead_request_ctx(req);\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_rfc4106_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct crypto_aead *child = ctx->child;\n\tu8 *iv = PTR_ALIGN((u8 *)(subreq + 1) + crypto_aead_reqsize(child),\n\t\t\t   crypto_aead_alignmask(child) + 1);\n\n\tmemcpy(iv, ctx->nonce, 4);\n\tmemcpy(iv + 4, req->iv, 8);\n\n\taead_request_set_tfm(subreq, child);\n\taead_request_set_callback(subreq, req->base.flags, req->base.complete,\n\t\t\t\t  req->base.data);\n\taead_request_set_crypt(subreq, req->src, req->dst, req->cryptlen, iv);\n\taead_request_set_assoc(subreq, req->assoc, req->assoclen);\n\n\treturn subreq;\n}\n\nstatic int crypto_rfc4106_encrypt(struct aead_request *req)\n{\n\treq = crypto_rfc4106_crypt(req);\n\n\treturn crypto_aead_encrypt(req);\n}\n\nstatic int crypto_rfc4106_decrypt(struct aead_request *req)\n{\n\treq = crypto_rfc4106_crypt(req);\n\n\treturn crypto_aead_decrypt(req);\n}\n\nstatic int crypto_rfc4106_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_instance *inst = (void *)tfm->__crt_alg;\n\tstruct crypto_aead_spawn *spawn = crypto_instance_ctx(inst);\n\tstruct crypto_rfc4106_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_aead *aead;\n\tunsigned long align;\n\n\taead = crypto_spawn_aead(spawn);\n\tif (IS_ERR(aead))\n\t\treturn PTR_ERR(aead);\n\n\tctx->child = aead;\n\n\talign = crypto_aead_alignmask(aead);\n\talign &= ~(crypto_tfm_ctx_alignment() - 1);\n\ttfm->crt_aead.reqsize = sizeof(struct aead_request) +\n\t\t\t\tALIGN(crypto_aead_reqsize(aead),\n\t\t\t\t      crypto_tfm_ctx_alignment()) +\n\t\t\t\talign + 16;\n\n\treturn 0;\n}\n\nstatic void crypto_rfc4106_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_rfc4106_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_aead(ctx->child);\n}\n\nstatic struct crypto_instance *crypto_rfc4106_alloc(struct rtattr **tb)\n{\n\tstruct crypto_attr_type *algt;\n\tstruct crypto_instance *inst;\n\tstruct crypto_aead_spawn *spawn;\n\tstruct crypto_alg *alg;\n\tconst char *ccm_name;\n\tint err;\n\n\talgt = crypto_get_attr_type(tb);\n\tif (IS_ERR(algt))\n\t\treturn ERR_CAST(algt);\n\n\tif ((algt->type ^ CRYPTO_ALG_TYPE_AEAD) & algt->mask)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tccm_name = crypto_attr_alg_name(tb[1]);\n\tif (IS_ERR(ccm_name))\n\t\treturn ERR_CAST(ccm_name);\n\n\tinst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);\n\tif (!inst)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tspawn = crypto_instance_ctx(inst);\n\tcrypto_set_aead_spawn(spawn, inst);\n\terr = crypto_grab_aead(spawn, ccm_name, 0,\n\t\t\t       crypto_requires_sync(algt->type, algt->mask));\n\tif (err)\n\t\tgoto out_free_inst;\n\n\talg = crypto_aead_spawn_alg(spawn);\n\n\terr = -EINVAL;\n\n\t/* We only support 16-byte blocks. */\n\tif (alg->cra_aead.ivsize != 16)\n\t\tgoto out_drop_alg;\n\n\t/* Not a stream cipher? */\n\tif (alg->cra_blocksize != 1)\n\t\tgoto out_drop_alg;\n\n\terr = -ENAMETOOLONG;\n\tif (snprintf(inst->alg.cra_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"rfc4106(%s)\", alg->cra_name) >= CRYPTO_MAX_ALG_NAME ||\n\t    snprintf(inst->alg.cra_driver_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"rfc4106(%s)\", alg->cra_driver_name) >=\n\t    CRYPTO_MAX_ALG_NAME)\n\t\tgoto out_drop_alg;\n\n\tinst->alg.cra_flags = CRYPTO_ALG_TYPE_AEAD;\n\tinst->alg.cra_flags |= alg->cra_flags & CRYPTO_ALG_ASYNC;\n\tinst->alg.cra_priority = alg->cra_priority;\n\tinst->alg.cra_blocksize = 1;\n\tinst->alg.cra_alignmask = alg->cra_alignmask;\n\tinst->alg.cra_type = &crypto_nivaead_type;\n\n\tinst->alg.cra_aead.ivsize = 8;\n\tinst->alg.cra_aead.maxauthsize = 16;\n\n\tinst->alg.cra_ctxsize = sizeof(struct crypto_rfc4106_ctx);\n\n\tinst->alg.cra_init = crypto_rfc4106_init_tfm;\n\tinst->alg.cra_exit = crypto_rfc4106_exit_tfm;\n\n\tinst->alg.cra_aead.setkey = crypto_rfc4106_setkey;\n\tinst->alg.cra_aead.setauthsize = crypto_rfc4106_setauthsize;\n\tinst->alg.cra_aead.encrypt = crypto_rfc4106_encrypt;\n\tinst->alg.cra_aead.decrypt = crypto_rfc4106_decrypt;\n\n\tinst->alg.cra_aead.geniv = \"seqiv\";\n\nout:\n\treturn inst;\n\nout_drop_alg:\n\tcrypto_drop_aead(spawn);\nout_free_inst:\n\tkfree(inst);\n\tinst = ERR_PTR(err);\n\tgoto out;\n}\n\nstatic void crypto_rfc4106_free(struct crypto_instance *inst)\n{\n\tcrypto_drop_spawn(crypto_instance_ctx(inst));\n\tkfree(inst);\n}\n\nstatic struct crypto_template crypto_rfc4106_tmpl = {\n\t.name = \"rfc4106\",\n\t.alloc = crypto_rfc4106_alloc,\n\t.free = crypto_rfc4106_free,\n\t.module = THIS_MODULE,\n};\n\nstatic inline struct crypto_rfc4543_req_ctx *crypto_rfc4543_reqctx(\n\tstruct aead_request *req)\n{\n\tunsigned long align = crypto_aead_alignmask(crypto_aead_reqtfm(req));\n\n\treturn (void *)PTR_ALIGN((u8 *)aead_request_ctx(req), align + 1);\n}\n\nstatic int crypto_rfc4543_setkey(struct crypto_aead *parent, const u8 *key,\n\t\t\t\t unsigned int keylen)\n{\n\tstruct crypto_rfc4543_ctx *ctx = crypto_aead_ctx(parent);\n\tstruct crypto_aead *child = ctx->child;\n\tint err;\n\n\tif (keylen < 4)\n\t\treturn -EINVAL;\n\n\tkeylen -= 4;\n\tmemcpy(ctx->nonce, key + keylen, 4);\n\n\tcrypto_aead_clear_flags(child, CRYPTO_TFM_REQ_MASK);\n\tcrypto_aead_set_flags(child, crypto_aead_get_flags(parent) &\n\t\t\t\t     CRYPTO_TFM_REQ_MASK);\n\terr = crypto_aead_setkey(child, key, keylen);\n\tcrypto_aead_set_flags(parent, crypto_aead_get_flags(child) &\n\t\t\t\t      CRYPTO_TFM_RES_MASK);\n\n\treturn err;\n}\n\nstatic int crypto_rfc4543_setauthsize(struct crypto_aead *parent,\n\t\t\t\t      unsigned int authsize)\n{\n\tstruct crypto_rfc4543_ctx *ctx = crypto_aead_ctx(parent);\n\n\tif (authsize != 16)\n\t\treturn -EINVAL;\n\n\treturn crypto_aead_setauthsize(ctx->child, authsize);\n}\n\nstatic void crypto_rfc4543_done(struct crypto_async_request *areq, int err)\n{\n\tstruct aead_request *req = areq->data;\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_rfc4543_req_ctx *rctx = crypto_rfc4543_reqctx(req);\n\n\tif (!err) {\n\t\tscatterwalk_map_and_copy(rctx->auth_tag, req->dst,\n\t\t\t\t\t req->cryptlen,\n\t\t\t\t\t crypto_aead_authsize(aead), 1);\n\t}\n\n\taead_request_complete(req, err);\n}\n\nstatic struct aead_request *crypto_rfc4543_crypt(struct aead_request *req,\n\t\t\t\t\t\t bool enc)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_rfc4543_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct crypto_rfc4543_req_ctx *rctx = crypto_rfc4543_reqctx(req);\n\tstruct aead_request *subreq = &rctx->subreq;\n\tstruct scatterlist *src = req->src;\n\tstruct scatterlist *cipher = rctx->cipher;\n\tstruct scatterlist *payload = rctx->payload;\n\tstruct scatterlist *assoc = rctx->assoc;\n\tunsigned int authsize = crypto_aead_authsize(aead);\n\tunsigned int assoclen = req->assoclen;\n\tstruct page *srcp;\n\tu8 *vsrc;\n\tu8 *iv = PTR_ALIGN((u8 *)(rctx + 1) + crypto_aead_reqsize(ctx->child),\n\t\t\t   crypto_aead_alignmask(ctx->child) + 1);\n\n\tmemcpy(iv, ctx->nonce, 4);\n\tmemcpy(iv + 4, req->iv, 8);\n\n\t/* construct cipher/plaintext */\n\tif (enc)\n\t\tmemset(rctx->auth_tag, 0, authsize);\n\telse\n\t\tscatterwalk_map_and_copy(rctx->auth_tag, src,\n\t\t\t\t\t req->cryptlen - authsize,\n\t\t\t\t\t authsize, 0);\n\n\tsg_init_one(cipher, rctx->auth_tag, authsize);\n\n\t/* construct the aad */\n\tsrcp = sg_page(src);\n\tvsrc = PageHighMem(srcp) ? NULL : page_address(srcp) + src->offset;\n\n\tsg_init_table(payload, 2);\n\tsg_set_buf(payload, req->iv, 8);\n\tscatterwalk_crypto_chain(payload, src, vsrc == req->iv + 8, 2);\n\tassoclen += 8 + req->cryptlen - (enc ? 0 : authsize);\n\n\tif (req->assoc->length == req->assoclen) {\n\t\tsg_init_table(assoc, 2);\n\t\tsg_set_page(assoc, sg_page(req->assoc), req->assoc->length,\n\t\t\t    req->assoc->offset);\n\t} else {\n\t\tBUG_ON(req->assoclen > sizeof(rctx->assocbuf));\n\n\t\tscatterwalk_map_and_copy(rctx->assocbuf, req->assoc, 0,\n\t\t\t\t\t req->assoclen, 0);\n\n\t\tsg_init_table(assoc, 2);\n\t\tsg_set_buf(assoc, rctx->assocbuf, req->assoclen);\n\t}\n\tscatterwalk_crypto_chain(assoc, payload, 0, 2);\n\n\taead_request_set_tfm(subreq, ctx->child);\n\taead_request_set_callback(subreq, req->base.flags, crypto_rfc4543_done,\n\t\t\t\t  req);\n\taead_request_set_crypt(subreq, cipher, cipher, enc ? 0 : authsize, iv);\n\taead_request_set_assoc(subreq, assoc, assoclen);\n\n\treturn subreq;\n}\n\nstatic int crypto_rfc4543_copy_src_to_dst(struct aead_request *req, bool enc)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_rfc4543_ctx *ctx = crypto_aead_ctx(aead);\n\tunsigned int authsize = crypto_aead_authsize(aead);\n\tunsigned int nbytes = req->cryptlen - (enc ? 0 : authsize);\n\tstruct blkcipher_desc desc = {\n\t\t.tfm = ctx->null,\n\t};\n\n\treturn crypto_blkcipher_encrypt(&desc, req->dst, req->src, nbytes);\n}\n\nstatic int crypto_rfc4543_encrypt(struct aead_request *req)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_rfc4543_req_ctx *rctx = crypto_rfc4543_reqctx(req);\n\tstruct aead_request *subreq;\n\tint err;\n\n\tif (req->src != req->dst) {\n\t\terr = crypto_rfc4543_copy_src_to_dst(req, true);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tsubreq = crypto_rfc4543_crypt(req, true);\n\terr = crypto_aead_encrypt(subreq);\n\tif (err)\n\t\treturn err;\n\n\tscatterwalk_map_and_copy(rctx->auth_tag, req->dst, req->cryptlen,\n\t\t\t\t crypto_aead_authsize(aead), 1);\n\n\treturn 0;\n}\n\nstatic int crypto_rfc4543_decrypt(struct aead_request *req)\n{\n\tint err;\n\n\tif (req->src != req->dst) {\n\t\terr = crypto_rfc4543_copy_src_to_dst(req, false);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treq = crypto_rfc4543_crypt(req, false);\n\n\treturn crypto_aead_decrypt(req);\n}\n\nstatic int crypto_rfc4543_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_instance *inst = (void *)tfm->__crt_alg;\n\tstruct crypto_rfc4543_instance_ctx *ictx = crypto_instance_ctx(inst);\n\tstruct crypto_aead_spawn *spawn = &ictx->aead;\n\tstruct crypto_rfc4543_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_aead *aead;\n\tstruct crypto_blkcipher *null;\n\tunsigned long align;\n\tint err = 0;\n\n\taead = crypto_spawn_aead(spawn);\n\tif (IS_ERR(aead))\n\t\treturn PTR_ERR(aead);\n\n\tnull = crypto_spawn_blkcipher(&ictx->null.base);\n\terr = PTR_ERR(null);\n\tif (IS_ERR(null))\n\t\tgoto err_free_aead;\n\n\tctx->child = aead;\n\tctx->null = null;\n\n\talign = crypto_aead_alignmask(aead);\n\talign &= ~(crypto_tfm_ctx_alignment() - 1);\n\ttfm->crt_aead.reqsize = sizeof(struct crypto_rfc4543_req_ctx) +\n\t\t\t\tALIGN(crypto_aead_reqsize(aead),\n\t\t\t\t      crypto_tfm_ctx_alignment()) +\n\t\t\t\talign + 16;\n\n\treturn 0;\n\nerr_free_aead:\n\tcrypto_free_aead(aead);\n\treturn err;\n}\n\nstatic void crypto_rfc4543_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_rfc4543_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_aead(ctx->child);\n\tcrypto_free_blkcipher(ctx->null);\n}\n\nstatic struct crypto_instance *crypto_rfc4543_alloc(struct rtattr **tb)\n{\n\tstruct crypto_attr_type *algt;\n\tstruct crypto_instance *inst;\n\tstruct crypto_aead_spawn *spawn;\n\tstruct crypto_alg *alg;\n\tstruct crypto_rfc4543_instance_ctx *ctx;\n\tconst char *ccm_name;\n\tint err;\n\n\talgt = crypto_get_attr_type(tb);\n\tif (IS_ERR(algt))\n\t\treturn ERR_CAST(algt);\n\n\tif ((algt->type ^ CRYPTO_ALG_TYPE_AEAD) & algt->mask)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tccm_name = crypto_attr_alg_name(tb[1]);\n\tif (IS_ERR(ccm_name))\n\t\treturn ERR_CAST(ccm_name);\n\n\tinst = kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);\n\tif (!inst)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tctx = crypto_instance_ctx(inst);\n\tspawn = &ctx->aead;\n\tcrypto_set_aead_spawn(spawn, inst);\n\terr = crypto_grab_aead(spawn, ccm_name, 0,\n\t\t\t       crypto_requires_sync(algt->type, algt->mask));\n\tif (err)\n\t\tgoto out_free_inst;\n\n\talg = crypto_aead_spawn_alg(spawn);\n\n\tcrypto_set_skcipher_spawn(&ctx->null, inst);\n\terr = crypto_grab_skcipher(&ctx->null, \"ecb(cipher_null)\", 0,\n\t\t\t\t   CRYPTO_ALG_ASYNC);\n\tif (err)\n\t\tgoto out_drop_alg;\n\n\tcrypto_skcipher_spawn_alg(&ctx->null);\n\n\terr = -EINVAL;\n\n\t/* We only support 16-byte blocks. */\n\tif (alg->cra_aead.ivsize != 16)\n\t\tgoto out_drop_ecbnull;\n\n\t/* Not a stream cipher? */\n\tif (alg->cra_blocksize != 1)\n\t\tgoto out_drop_ecbnull;\n\n\terr = -ENAMETOOLONG;\n\tif (snprintf(inst->alg.cra_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"rfc4543(%s)\", alg->cra_name) >= CRYPTO_MAX_ALG_NAME ||\n\t    snprintf(inst->alg.cra_driver_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"rfc4543(%s)\", alg->cra_driver_name) >=\n\t    CRYPTO_MAX_ALG_NAME)\n\t\tgoto out_drop_ecbnull;\n\n\tinst->alg.cra_flags = CRYPTO_ALG_TYPE_AEAD;\n\tinst->alg.cra_flags |= alg->cra_flags & CRYPTO_ALG_ASYNC;\n\tinst->alg.cra_priority = alg->cra_priority;\n\tinst->alg.cra_blocksize = 1;\n\tinst->alg.cra_alignmask = alg->cra_alignmask;\n\tinst->alg.cra_type = &crypto_nivaead_type;\n\n\tinst->alg.cra_aead.ivsize = 8;\n\tinst->alg.cra_aead.maxauthsize = 16;\n\n\tinst->alg.cra_ctxsize = sizeof(struct crypto_rfc4543_ctx);\n\n\tinst->alg.cra_init = crypto_rfc4543_init_tfm;\n\tinst->alg.cra_exit = crypto_rfc4543_exit_tfm;\n\n\tinst->alg.cra_aead.setkey = crypto_rfc4543_setkey;\n\tinst->alg.cra_aead.setauthsize = crypto_rfc4543_setauthsize;\n\tinst->alg.cra_aead.encrypt = crypto_rfc4543_encrypt;\n\tinst->alg.cra_aead.decrypt = crypto_rfc4543_decrypt;\n\n\tinst->alg.cra_aead.geniv = \"seqiv\";\n\nout:\n\treturn inst;\n\nout_drop_ecbnull:\n\tcrypto_drop_skcipher(&ctx->null);\nout_drop_alg:\n\tcrypto_drop_aead(spawn);\nout_free_inst:\n\tkfree(inst);\n\tinst = ERR_PTR(err);\n\tgoto out;\n}\n\nstatic void crypto_rfc4543_free(struct crypto_instance *inst)\n{\n\tstruct crypto_rfc4543_instance_ctx *ctx = crypto_instance_ctx(inst);\n\n\tcrypto_drop_aead(&ctx->aead);\n\tcrypto_drop_skcipher(&ctx->null);\n\n\tkfree(inst);\n}\n\nstatic struct crypto_template crypto_rfc4543_tmpl = {\n\t.name = \"rfc4543\",\n\t.alloc = crypto_rfc4543_alloc,\n\t.free = crypto_rfc4543_free,\n\t.module = THIS_MODULE,\n};\n\nstatic int __init crypto_gcm_module_init(void)\n{\n\tint err;\n\n\tgcm_zeroes = kzalloc(16, GFP_KERNEL);\n\tif (!gcm_zeroes)\n\t\treturn -ENOMEM;\n\n\terr = crypto_register_template(&crypto_gcm_base_tmpl);\n\tif (err)\n\t\tgoto out;\n\n\terr = crypto_register_template(&crypto_gcm_tmpl);\n\tif (err)\n\t\tgoto out_undo_base;\n\n\terr = crypto_register_template(&crypto_rfc4106_tmpl);\n\tif (err)\n\t\tgoto out_undo_gcm;\n\n\terr = crypto_register_template(&crypto_rfc4543_tmpl);\n\tif (err)\n\t\tgoto out_undo_rfc4106;\n\n\treturn 0;\n\nout_undo_rfc4106:\n\tcrypto_unregister_template(&crypto_rfc4106_tmpl);\nout_undo_gcm:\n\tcrypto_unregister_template(&crypto_gcm_tmpl);\nout_undo_base:\n\tcrypto_unregister_template(&crypto_gcm_base_tmpl);\nout:\n\tkfree(gcm_zeroes);\n\treturn err;\n}\n\nstatic void __exit crypto_gcm_module_exit(void)\n{\n\tkfree(gcm_zeroes);\n\tcrypto_unregister_template(&crypto_rfc4543_tmpl);\n\tcrypto_unregister_template(&crypto_rfc4106_tmpl);\n\tcrypto_unregister_template(&crypto_gcm_tmpl);\n\tcrypto_unregister_template(&crypto_gcm_base_tmpl);\n}\n\nmodule_init(crypto_gcm_module_init);\nmodule_exit(crypto_gcm_module_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Galois/Counter Mode\");\nMODULE_AUTHOR(\"Mikko Herranen <mh1@iki.fi>\");\nMODULE_ALIAS(\"gcm_base\");\nMODULE_ALIAS(\"rfc4106\");\nMODULE_ALIAS(\"rfc4543\");\n", "/*\n * GHASH: digest algorithm for GCM (Galois/Counter Mode).\n *\n * Copyright (c) 2007 Nokia Siemens Networks - Mikko Herranen <mh1@iki.fi>\n * Copyright (c) 2009 Intel Corp.\n *   Author: Huang Ying <ying.huang@intel.com>\n *\n * The algorithm implementation is copied from gcm.c.\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License version 2 as published\n * by the Free Software Foundation.\n */\n\n#include <crypto/algapi.h>\n#include <crypto/gf128mul.h>\n#include <crypto/internal/hash.h>\n#include <linux/crypto.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n\n#define GHASH_BLOCK_SIZE\t16\n#define GHASH_DIGEST_SIZE\t16\n\nstruct ghash_ctx {\n\tstruct gf128mul_4k *gf128;\n};\n\nstruct ghash_desc_ctx {\n\tu8 buffer[GHASH_BLOCK_SIZE];\n\tu32 bytes;\n};\n\nstatic int ghash_init(struct shash_desc *desc)\n{\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\n\tmemset(dctx, 0, sizeof(*dctx));\n\n\treturn 0;\n}\n\nstatic int ghash_setkey(struct crypto_shash *tfm,\n\t\t\tconst u8 *key, unsigned int keylen)\n{\n\tstruct ghash_ctx *ctx = crypto_shash_ctx(tfm);\n\n\tif (keylen != GHASH_BLOCK_SIZE) {\n\t\tcrypto_shash_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);\n\t\treturn -EINVAL;\n\t}\n\n\tif (ctx->gf128)\n\t\tgf128mul_free_4k(ctx->gf128);\n\tctx->gf128 = gf128mul_init_4k_lle((be128 *)key);\n\tif (!ctx->gf128)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic int ghash_update(struct shash_desc *desc,\n\t\t\t const u8 *src, unsigned int srclen)\n{\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\tstruct ghash_ctx *ctx = crypto_shash_ctx(desc->tfm);\n\tu8 *dst = dctx->buffer;\n\n\tif (!ctx->gf128)\n\t\treturn -ENOKEY;\n\n\tif (dctx->bytes) {\n\t\tint n = min(srclen, dctx->bytes);\n\t\tu8 *pos = dst + (GHASH_BLOCK_SIZE - dctx->bytes);\n\n\t\tdctx->bytes -= n;\n\t\tsrclen -= n;\n\n\t\twhile (n--)\n\t\t\t*pos++ ^= *src++;\n\n\t\tif (!dctx->bytes)\n\t\t\tgf128mul_4k_lle((be128 *)dst, ctx->gf128);\n\t}\n\n\twhile (srclen >= GHASH_BLOCK_SIZE) {\n\t\tcrypto_xor(dst, src, GHASH_BLOCK_SIZE);\n\t\tgf128mul_4k_lle((be128 *)dst, ctx->gf128);\n\t\tsrc += GHASH_BLOCK_SIZE;\n\t\tsrclen -= GHASH_BLOCK_SIZE;\n\t}\n\n\tif (srclen) {\n\t\tdctx->bytes = GHASH_BLOCK_SIZE - srclen;\n\t\twhile (srclen--)\n\t\t\t*dst++ ^= *src++;\n\t}\n\n\treturn 0;\n}\n\nstatic void ghash_flush(struct ghash_ctx *ctx, struct ghash_desc_ctx *dctx)\n{\n\tu8 *dst = dctx->buffer;\n\n\tif (dctx->bytes) {\n\t\tu8 *tmp = dst + (GHASH_BLOCK_SIZE - dctx->bytes);\n\n\t\twhile (dctx->bytes--)\n\t\t\t*tmp++ ^= 0;\n\n\t\tgf128mul_4k_lle((be128 *)dst, ctx->gf128);\n\t}\n\n\tdctx->bytes = 0;\n}\n\nstatic int ghash_final(struct shash_desc *desc, u8 *dst)\n{\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\tstruct ghash_ctx *ctx = crypto_shash_ctx(desc->tfm);\n\tu8 *buf = dctx->buffer;\n\n\tif (!ctx->gf128)\n\t\treturn -ENOKEY;\n\n\tghash_flush(ctx, dctx);\n\tmemcpy(dst, buf, GHASH_BLOCK_SIZE);\n\n\treturn 0;\n}\n\nstatic void ghash_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct ghash_ctx *ctx = crypto_tfm_ctx(tfm);\n\tif (ctx->gf128)\n\t\tgf128mul_free_4k(ctx->gf128);\n}\n\nstatic struct shash_alg ghash_alg = {\n\t.digestsize\t= GHASH_DIGEST_SIZE,\n\t.init\t\t= ghash_init,\n\t.update\t\t= ghash_update,\n\t.final\t\t= ghash_final,\n\t.setkey\t\t= ghash_setkey,\n\t.descsize\t= sizeof(struct ghash_desc_ctx),\n\t.base\t\t= {\n\t\t.cra_name\t\t= \"ghash\",\n\t\t.cra_driver_name\t= \"ghash-generic\",\n\t\t.cra_priority\t\t= 100,\n\t\t.cra_flags\t\t= CRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t\t= GHASH_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t= sizeof(struct ghash_ctx),\n\t\t.cra_module\t\t= THIS_MODULE,\n\t\t.cra_exit\t\t= ghash_exit_tfm,\n\t},\n};\n\nstatic int __init ghash_mod_init(void)\n{\n\treturn crypto_register_shash(&ghash_alg);\n}\n\nstatic void __exit ghash_mod_exit(void)\n{\n\tcrypto_unregister_shash(&ghash_alg);\n}\n\nmodule_init(ghash_mod_init);\nmodule_exit(ghash_mod_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"GHASH Message Digest Algorithm\");\nMODULE_ALIAS(\"ghash\");\n", "/*\n * Cryptographic API.\n *\n * Khazad Algorithm\n *\n * The Khazad algorithm was developed by Paulo S. L. M. Barreto and\n * Vincent Rijmen.  It was a finalist in the NESSIE encryption contest.\n *\n * The original authors have disclaimed all copyright interest in this\n * code and thus put it in the public domain. The subsequent authors\n * have put this under the GNU General Public License.\n *\n * By Aaron Grothe ajgrothe@yahoo.com, August 1, 2004\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <asm/byteorder.h>\n#include <linux/crypto.h>\n#include <linux/types.h>\n\n#define KHAZAD_KEY_SIZE\t\t16\n#define KHAZAD_BLOCK_SIZE\t8\n#define KHAZAD_ROUNDS\t\t8\n\nstruct khazad_ctx {\n\tu64 E[KHAZAD_ROUNDS + 1];\n\tu64 D[KHAZAD_ROUNDS + 1];\n};\n\nstatic const u64 T0[256] = {\n\t0xbad3d268bbb96a01ULL, 0x54fc4d19e59a66b1ULL, 0x2f71bc93e26514cdULL,\n\t0x749ccdb925871b51ULL, 0x53f55102f7a257a4ULL, 0xd3686bb8d0d6be03ULL,\n\t0xd26b6fbdd6deb504ULL, 0x4dd72964b35285feULL, 0x50f05d0dfdba4aadULL,\n\t0xace98a26cf09e063ULL, 0x8d8a0e83091c9684ULL, 0xbfdcc679a5914d1aULL,\n\t0x7090ddad3da7374dULL, 0x52f65507f1aa5ca3ULL, 0x9ab352c87ba417e1ULL,\n\t0x4cd42d61b55a8ef9ULL, 0xea238f65460320acULL, 0xd56273a6c4e68411ULL,\n\t0x97a466f155cc68c2ULL, 0xd16e63b2dcc6a80dULL, 0x3355ccffaa85d099ULL,\n\t0x51f35908fbb241aaULL, 0x5bed712ac7e20f9cULL, 0xa6f7a204f359ae55ULL,\n\t0xde7f5f81febec120ULL, 0x48d83d75ad7aa2e5ULL, 0xa8e59a32d729cc7fULL,\n\t0x99b65ec771bc0ae8ULL, 0xdb704b90e096e63bULL, 0x3256c8faac8ddb9eULL,\n\t0xb7c4e65195d11522ULL, 0xfc19d72b32b3aaceULL, 0xe338ab48704b7393ULL,\n\t0x9ebf42dc63843bfdULL, 0x91ae7eef41fc52d0ULL, 0x9bb056cd7dac1ce6ULL,\n\t0xe23baf4d76437894ULL, 0xbbd0d66dbdb16106ULL, 0x41c319589b32f1daULL,\n\t0x6eb2a5cb7957e517ULL, 0xa5f2ae0bf941b35cULL, 0xcb400bc08016564bULL,\n\t0x6bbdb1da677fc20cULL, 0x95a26efb59dc7eccULL, 0xa1febe1fe1619f40ULL,\n\t0xf308eb1810cbc3e3ULL, 0xb1cefe4f81e12f30ULL, 0x0206080a0c10160eULL,\n\t0xcc4917db922e675eULL, 0xc45137f3a26e3f66ULL, 0x1d2774694ee8cf53ULL,\n\t0x143c504478a09c6cULL, 0xc3582be8b0560e73ULL, 0x63a591f2573f9a34ULL,\n\t0xda734f95e69eed3cULL, 0x5de76934d3d2358eULL, 0x5fe1613edfc22380ULL,\n\t0xdc79578bf2aed72eULL, 0x7d87e99413cf486eULL, 0xcd4a13de94266c59ULL,\n\t0x7f81e19e1fdf5e60ULL, 0x5aee752fc1ea049bULL, 0x6cb4adc17547f319ULL,\n\t0x5ce46d31d5da3e89ULL, 0xf704fb0c08ebefffULL, 0x266a98bed42d47f2ULL,\n\t0xff1cdb2438abb7c7ULL, 0xed2a937e543b11b9ULL, 0xe825876f4a1336a2ULL,\n\t0x9dba4ed3699c26f4ULL, 0x6fb1a1ce7f5fee10ULL, 0x8e8f028c03048b8dULL,\n\t0x192b647d56c8e34fULL, 0xa0fdba1ae7699447ULL, 0xf00de7171ad3deeaULL,\n\t0x89861e97113cba98ULL, 0x0f113c332278692dULL, 0x07091c1b12383115ULL,\n\t0xafec8629c511fd6aULL, 0xfb10cb30208b9bdbULL, 0x0818202830405838ULL,\n\t0x153f54417ea8976bULL, 0x0d1734392e687f23ULL, 0x040c101418202c1cULL,\n\t0x0103040506080b07ULL, 0x64ac8de94507ab21ULL, 0xdf7c5b84f8b6ca27ULL,\n\t0x769ac5b329970d5fULL, 0x798bf9800bef6472ULL, 0xdd7a538ef4a6dc29ULL,\n\t0x3d47f4c98ef5b2b3ULL, 0x163a584e74b08a62ULL, 0x3f41fcc382e5a4bdULL,\n\t0x3759dcebb2a5fc85ULL, 0x6db7a9c4734ff81eULL, 0x3848e0d890dd95a8ULL,\n\t0xb9d6de67b1a17708ULL, 0x7395d1a237bf2a44ULL, 0xe926836a4c1b3da5ULL,\n\t0x355fd4e1beb5ea8bULL, 0x55ff491ce3926db6ULL, 0x7193d9a83baf3c4aULL,\n\t0x7b8df18a07ff727cULL, 0x8c890a860f149d83ULL, 0x7296d5a731b72143ULL,\n\t0x88851a921734b19fULL, 0xf607ff090ee3e4f8ULL, 0x2a7ea882fc4d33d6ULL,\n\t0x3e42f8c684edafbaULL, 0x5ee2653bd9ca2887ULL, 0x27699cbbd2254cf5ULL,\n\t0x46ca0543890ac0cfULL, 0x0c14303c28607424ULL, 0x65af89ec430fa026ULL,\n\t0x68b8bdd56d67df05ULL, 0x61a399f85b2f8c3aULL, 0x03050c0f0a181d09ULL,\n\t0xc15e23e2bc46187dULL, 0x57f94116ef827bb8ULL, 0xd6677fa9cefe9918ULL,\n\t0xd976439aec86f035ULL, 0x58e87d25cdfa1295ULL, 0xd875479fea8efb32ULL,\n\t0x66aa85e34917bd2fULL, 0xd7647bacc8f6921fULL, 0x3a4ee8d29ccd83a6ULL,\n\t0xc84507cf8a0e4b42ULL, 0x3c44f0cc88fdb9b4ULL, 0xfa13cf35268390dcULL,\n\t0x96a762f453c463c5ULL, 0xa7f4a601f551a552ULL, 0x98b55ac277b401efULL,\n\t0xec29977b52331abeULL, 0xb8d5da62b7a97c0fULL, 0xc7543bfca876226fULL,\n\t0xaeef822cc319f66dULL, 0x69bbb9d06b6fd402ULL, 0x4bdd317aa762bfecULL,\n\t0xabe0963ddd31d176ULL, 0xa9e69e37d121c778ULL, 0x67a981e64f1fb628ULL,\n\t0x0a1e28223c504e36ULL, 0x47c901468f02cbc8ULL, 0xf20bef1d16c3c8e4ULL,\n\t0xb5c2ee5b99c1032cULL, 0x226688aacc0d6beeULL, 0xe532b356647b4981ULL,\n\t0xee2f9f715e230cb0ULL, 0xbedfc27ca399461dULL, 0x2b7dac87fa4538d1ULL,\n\t0x819e3ebf217ce2a0ULL, 0x1236485a6c90a67eULL, 0x839836b52d6cf4aeULL,\n\t0x1b2d6c775ad8f541ULL, 0x0e1238362470622aULL, 0x23658cafca0560e9ULL,\n\t0xf502f30604fbf9f1ULL, 0x45cf094c8312ddc6ULL, 0x216384a5c61576e7ULL,\n\t0xce4f1fd19e3e7150ULL, 0x49db3970ab72a9e2ULL, 0x2c74b09ce87d09c4ULL,\n\t0xf916c33a2c9b8dd5ULL, 0xe637bf596e635488ULL, 0xb6c7e25493d91e25ULL,\n\t0x2878a088f05d25d8ULL, 0x17395c4b72b88165ULL, 0x829b32b02b64ffa9ULL,\n\t0x1a2e68725cd0fe46ULL, 0x8b80169d1d2cac96ULL, 0xfe1fdf213ea3bcc0ULL,\n\t0x8a8312981b24a791ULL, 0x091b242d3648533fULL, 0xc94603ca8c064045ULL,\n\t0x879426a1354cd8b2ULL, 0x4ed2256bb94a98f7ULL, 0xe13ea3427c5b659dULL,\n\t0x2e72b896e46d1fcaULL, 0xe431b75362734286ULL, 0xe03da7477a536e9aULL,\n\t0xeb208b60400b2babULL, 0x90ad7aea47f459d7ULL, 0xa4f1aa0eff49b85bULL,\n\t0x1e22786644f0d25aULL, 0x85922eab395ccebcULL, 0x60a09dfd5d27873dULL,\n\t0x0000000000000000ULL, 0x256f94b1de355afbULL, 0xf401f70302f3f2f6ULL,\n\t0xf10ee3121cdbd5edULL, 0x94a16afe5fd475cbULL, 0x0b1d2c273a584531ULL,\n\t0xe734bb5c686b5f8fULL, 0x759fc9bc238f1056ULL, 0xef2c9b74582b07b7ULL,\n\t0x345cd0e4b8bde18cULL, 0x3153c4f5a695c697ULL, 0xd46177a3c2ee8f16ULL,\n\t0xd06d67b7dacea30aULL, 0x869722a43344d3b5ULL, 0x7e82e59b19d75567ULL,\n\t0xadea8e23c901eb64ULL, 0xfd1ad32e34bba1c9ULL, 0x297ba48df6552edfULL,\n\t0x3050c0f0a09dcd90ULL, 0x3b4decd79ac588a1ULL, 0x9fbc46d9658c30faULL,\n\t0xf815c73f2a9386d2ULL, 0xc6573ff9ae7e2968ULL, 0x13354c5f6a98ad79ULL,\n\t0x060a181e14303a12ULL, 0x050f14111e28271bULL, 0xc55233f6a4663461ULL,\n\t0x113344556688bb77ULL, 0x7799c1b62f9f0658ULL, 0x7c84ed9115c74369ULL,\n\t0x7a8ef58f01f7797bULL, 0x7888fd850de76f75ULL, 0x365ad8eeb4adf782ULL,\n\t0x1c24706c48e0c454ULL, 0x394be4dd96d59eafULL, 0x59eb7920cbf21992ULL,\n\t0x1828607850c0e848ULL, 0x56fa4513e98a70bfULL, 0xb3c8f6458df1393eULL,\n\t0xb0cdfa4a87e92437ULL, 0x246c90b4d83d51fcULL, 0x206080a0c01d7de0ULL,\n\t0xb2cbf2408bf93239ULL, 0x92ab72e04be44fd9ULL, 0xa3f8b615ed71894eULL,\n\t0xc05d27e7ba4e137aULL, 0x44cc0d49851ad6c1ULL, 0x62a695f751379133ULL,\n\t0x103040506080b070ULL, 0xb4c1ea5e9fc9082bULL, 0x84912aae3f54c5bbULL,\n\t0x43c511529722e7d4ULL, 0x93a876e54dec44deULL, 0xc25b2fedb65e0574ULL,\n\t0x4ade357fa16ab4ebULL, 0xbddace73a9815b14ULL, 0x8f8c0689050c808aULL,\n\t0x2d77b499ee7502c3ULL, 0xbcd9ca76af895013ULL, 0x9cb94ad66f942df3ULL,\n\t0x6abeb5df6177c90bULL, 0x40c01d5d9d3afaddULL, 0xcf4c1bd498367a57ULL,\n\t0xa2fbb210eb798249ULL, 0x809d3aba2774e9a7ULL, 0x4fd1216ebf4293f0ULL,\n\t0x1f217c6342f8d95dULL, 0xca430fc5861e5d4cULL, 0xaae39238db39da71ULL,\n\t0x42c61557912aecd3ULL\n};\n\nstatic const u64 T1[256] = {\n\t0xd3ba68d2b9bb016aULL, 0xfc54194d9ae5b166ULL, 0x712f93bc65e2cd14ULL,\n\t0x9c74b9cd8725511bULL, 0xf5530251a2f7a457ULL, 0x68d3b86bd6d003beULL,\n\t0x6bd2bd6fded604b5ULL, 0xd74d642952b3fe85ULL, 0xf0500d5dbafdad4aULL,\n\t0xe9ac268a09cf63e0ULL, 0x8a8d830e1c098496ULL, 0xdcbf79c691a51a4dULL,\n\t0x9070addda73d4d37ULL, 0xf6520755aaf1a35cULL, 0xb39ac852a47be117ULL,\n\t0xd44c612d5ab5f98eULL, 0x23ea658f0346ac20ULL, 0x62d5a673e6c41184ULL,\n\t0xa497f166cc55c268ULL, 0x6ed1b263c6dc0da8ULL, 0x5533ffcc85aa99d0ULL,\n\t0xf3510859b2fbaa41ULL, 0xed5b2a71e2c79c0fULL, 0xf7a604a259f355aeULL,\n\t0x7fde815fbefe20c1ULL, 0xd848753d7aade5a2ULL, 0xe5a8329a29d77fccULL,\n\t0xb699c75ebc71e80aULL, 0x70db904b96e03be6ULL, 0x5632fac88dac9edbULL,\n\t0xc4b751e6d1952215ULL, 0x19fc2bd7b332ceaaULL, 0x38e348ab4b709373ULL,\n\t0xbf9edc428463fd3bULL, 0xae91ef7efc41d052ULL, 0xb09bcd56ac7de61cULL,\n\t0x3be24daf43769478ULL, 0xd0bb6dd6b1bd0661ULL, 0xc3415819329bdaf1ULL,\n\t0xb26ecba5577917e5ULL, 0xf2a50bae41f95cb3ULL, 0x40cbc00b16804b56ULL,\n\t0xbd6bdab17f670cc2ULL, 0xa295fb6edc59cc7eULL, 0xfea11fbe61e1409fULL,\n\t0x08f318ebcb10e3c3ULL, 0xceb14ffee181302fULL, 0x06020a08100c0e16ULL,\n\t0x49ccdb172e925e67ULL, 0x51c4f3376ea2663fULL, 0x271d6974e84e53cfULL,\n\t0x3c144450a0786c9cULL, 0x58c3e82b56b0730eULL, 0xa563f2913f57349aULL,\n\t0x73da954f9ee63cedULL, 0xe75d3469d2d38e35ULL, 0xe15f3e61c2df8023ULL,\n\t0x79dc8b57aef22ed7ULL, 0x877d94e9cf136e48ULL, 0x4acdde132694596cULL,\n\t0x817f9ee1df1f605eULL, 0xee5a2f75eac19b04ULL, 0xb46cc1ad477519f3ULL,\n\t0xe45c316ddad5893eULL, 0x04f70cfbeb08ffefULL, 0x6a26be982dd4f247ULL,\n\t0x1cff24dbab38c7b7ULL, 0x2aed7e933b54b911ULL, 0x25e86f87134aa236ULL,\n\t0xba9dd34e9c69f426ULL, 0xb16fcea15f7f10eeULL, 0x8f8e8c0204038d8bULL,\n\t0x2b197d64c8564fe3ULL, 0xfda01aba69e74794ULL, 0x0df017e7d31aeadeULL,\n\t0x8689971e3c1198baULL, 0x110f333c78222d69ULL, 0x09071b1c38121531ULL,\n\t0xecaf298611c56afdULL, 0x10fb30cb8b20db9bULL, 0x1808282040303858ULL,\n\t0x3f154154a87e6b97ULL, 0x170d3934682e237fULL, 0x0c04141020181c2cULL,\n\t0x030105040806070bULL, 0xac64e98d074521abULL, 0x7cdf845bb6f827caULL,\n\t0x9a76b3c597295f0dULL, 0x8b7980f9ef0b7264ULL, 0x7add8e53a6f429dcULL,\n\t0x473dc9f4f58eb3b2ULL, 0x3a164e58b074628aULL, 0x413fc3fce582bda4ULL,\n\t0x5937ebdca5b285fcULL, 0xb76dc4a94f731ef8ULL, 0x4838d8e0dd90a895ULL,\n\t0xd6b967dea1b10877ULL, 0x9573a2d1bf37442aULL, 0x26e96a831b4ca53dULL,\n\t0x5f35e1d4b5be8beaULL, 0xff551c4992e3b66dULL, 0x9371a8d9af3b4a3cULL,\n\t0x8d7b8af1ff077c72ULL, 0x898c860a140f839dULL, 0x9672a7d5b7314321ULL,\n\t0x8588921a34179fb1ULL, 0x07f609ffe30ef8e4ULL, 0x7e2a82a84dfcd633ULL,\n\t0x423ec6f8ed84baafULL, 0xe25e3b65cad98728ULL, 0x6927bb9c25d2f54cULL,\n\t0xca4643050a89cfc0ULL, 0x140c3c3060282474ULL, 0xaf65ec890f4326a0ULL,\n\t0xb868d5bd676d05dfULL, 0xa361f8992f5b3a8cULL, 0x05030f0c180a091dULL,\n\t0x5ec1e22346bc7d18ULL, 0xf957164182efb87bULL, 0x67d6a97ffece1899ULL,\n\t0x76d99a4386ec35f0ULL, 0xe858257dfacd9512ULL, 0x75d89f478eea32fbULL,\n\t0xaa66e38517492fbdULL, 0x64d7ac7bf6c81f92ULL, 0x4e3ad2e8cd9ca683ULL,\n\t0x45c8cf070e8a424bULL, 0x443cccf0fd88b4b9ULL, 0x13fa35cf8326dc90ULL,\n\t0xa796f462c453c563ULL, 0xf4a701a651f552a5ULL, 0xb598c25ab477ef01ULL,\n\t0x29ec7b973352be1aULL, 0xd5b862daa9b70f7cULL, 0x54c7fc3b76a86f22ULL,\n\t0xefae2c8219c36df6ULL, 0xbb69d0b96f6b02d4ULL, 0xdd4b7a3162a7ecbfULL,\n\t0xe0ab3d9631dd76d1ULL, 0xe6a9379e21d178c7ULL, 0xa967e6811f4f28b6ULL,\n\t0x1e0a2228503c364eULL, 0xc9474601028fc8cbULL, 0x0bf21defc316e4c8ULL,\n\t0xc2b55beec1992c03ULL, 0x6622aa880dccee6bULL, 0x32e556b37b648149ULL,\n\t0x2fee719f235eb00cULL, 0xdfbe7cc299a31d46ULL, 0x7d2b87ac45fad138ULL,\n\t0x9e81bf3e7c21a0e2ULL, 0x36125a48906c7ea6ULL, 0x9883b5366c2daef4ULL,\n\t0x2d1b776cd85a41f5ULL, 0x120e363870242a62ULL, 0x6523af8c05cae960ULL,\n\t0x02f506f3fb04f1f9ULL, 0xcf454c091283c6ddULL, 0x6321a58415c6e776ULL,\n\t0x4fced11f3e9e5071ULL, 0xdb49703972abe2a9ULL, 0x742c9cb07de8c409ULL,\n\t0x16f93ac39b2cd58dULL, 0x37e659bf636e8854ULL, 0xc7b654e2d993251eULL,\n\t0x782888a05df0d825ULL, 0x39174b5cb8726581ULL, 0x9b82b032642ba9ffULL,\n\t0x2e1a7268d05c46feULL, 0x808b9d162c1d96acULL, 0x1ffe21dfa33ec0bcULL,\n\t0x838a9812241b91a7ULL, 0x1b092d2448363f53ULL, 0x46c9ca03068c4540ULL,\n\t0x9487a1264c35b2d8ULL, 0xd24e6b254ab9f798ULL, 0x3ee142a35b7c9d65ULL,\n\t0x722e96b86de4ca1fULL, 0x31e453b773628642ULL, 0x3de047a7537a9a6eULL,\n\t0x20eb608b0b40ab2bULL, 0xad90ea7af447d759ULL, 0xf1a40eaa49ff5bb8ULL,\n\t0x221e6678f0445ad2ULL, 0x9285ab2e5c39bcceULL, 0xa060fd9d275d3d87ULL,\n\t0x0000000000000000ULL, 0x6f25b19435defb5aULL, 0x01f403f7f302f6f2ULL,\n\t0x0ef112e3db1cedd5ULL, 0xa194fe6ad45fcb75ULL, 0x1d0b272c583a3145ULL,\n\t0x34e75cbb6b688f5fULL, 0x9f75bcc98f235610ULL, 0x2cef749b2b58b707ULL,\n\t0x5c34e4d0bdb88ce1ULL, 0x5331f5c495a697c6ULL, 0x61d4a377eec2168fULL,\n\t0x6dd0b767ceda0aa3ULL, 0x9786a4224433b5d3ULL, 0x827e9be5d7196755ULL,\n\t0xeaad238e01c964ebULL, 0x1afd2ed3bb34c9a1ULL, 0x7b298da455f6df2eULL,\n\t0x5030f0c09da090cdULL, 0x4d3bd7ecc59aa188ULL, 0xbc9fd9468c65fa30ULL,\n\t0x15f83fc7932ad286ULL, 0x57c6f93f7eae6829ULL, 0x35135f4c986a79adULL,\n\t0x0a061e183014123aULL, 0x0f051114281e1b27ULL, 0x52c5f63366a46134ULL,\n\t0x33115544886677bbULL, 0x9977b6c19f2f5806ULL, 0x847c91edc7156943ULL,\n\t0x8e7a8ff5f7017b79ULL, 0x887885fde70d756fULL, 0x5a36eed8adb482f7ULL,\n\t0x241c6c70e04854c4ULL, 0x4b39dde4d596af9eULL, 0xeb592079f2cb9219ULL,\n\t0x28187860c05048e8ULL, 0xfa5613458ae9bf70ULL, 0xc8b345f6f18d3e39ULL,\n\t0xcdb04afae9873724ULL, 0x6c24b4903dd8fc51ULL, 0x6020a0801dc0e07dULL,\n\t0xcbb240f2f98b3932ULL, 0xab92e072e44bd94fULL, 0xf8a315b671ed4e89ULL,\n\t0x5dc0e7274eba7a13ULL, 0xcc44490d1a85c1d6ULL, 0xa662f79537513391ULL,\n\t0x30105040806070b0ULL, 0xc1b45eeac99f2b08ULL, 0x9184ae2a543fbbc5ULL,\n\t0xc54352112297d4e7ULL, 0xa893e576ec4dde44ULL, 0x5bc2ed2f5eb67405ULL,\n\t0xde4a7f356aa1ebb4ULL, 0xdabd73ce81a9145bULL, 0x8c8f89060c058a80ULL,\n\t0x772d99b475eec302ULL, 0xd9bc76ca89af1350ULL, 0xb99cd64a946ff32dULL,\n\t0xbe6adfb577610bc9ULL, 0xc0405d1d3a9dddfaULL, 0x4ccfd41b3698577aULL,\n\t0xfba210b279eb4982ULL, 0x9d80ba3a7427a7e9ULL, 0xd14f6e2142bff093ULL,\n\t0x211f637cf8425dd9ULL, 0x43cac50f1e864c5dULL, 0xe3aa389239db71daULL,\n\t0xc64257152a91d3ecULL\n};\n\nstatic const u64 T2[256] = {\n\t0xd268bad36a01bbb9ULL, 0x4d1954fc66b1e59aULL, 0xbc932f7114cde265ULL,\n\t0xcdb9749c1b512587ULL, 0x510253f557a4f7a2ULL, 0x6bb8d368be03d0d6ULL,\n\t0x6fbdd26bb504d6deULL, 0x29644dd785feb352ULL, 0x5d0d50f04aadfdbaULL,\n\t0x8a26ace9e063cf09ULL, 0x0e838d8a9684091cULL, 0xc679bfdc4d1aa591ULL,\n\t0xddad7090374d3da7ULL, 0x550752f65ca3f1aaULL, 0x52c89ab317e17ba4ULL,\n\t0x2d614cd48ef9b55aULL, 0x8f65ea2320ac4603ULL, 0x73a6d5628411c4e6ULL,\n\t0x66f197a468c255ccULL, 0x63b2d16ea80ddcc6ULL, 0xccff3355d099aa85ULL,\n\t0x590851f341aafbb2ULL, 0x712a5bed0f9cc7e2ULL, 0xa204a6f7ae55f359ULL,\n\t0x5f81de7fc120febeULL, 0x3d7548d8a2e5ad7aULL, 0x9a32a8e5cc7fd729ULL,\n\t0x5ec799b60ae871bcULL, 0x4b90db70e63be096ULL, 0xc8fa3256db9eac8dULL,\n\t0xe651b7c4152295d1ULL, 0xd72bfc19aace32b3ULL, 0xab48e3387393704bULL,\n\t0x42dc9ebf3bfd6384ULL, 0x7eef91ae52d041fcULL, 0x56cd9bb01ce67dacULL,\n\t0xaf4de23b78947643ULL, 0xd66dbbd06106bdb1ULL, 0x195841c3f1da9b32ULL,\n\t0xa5cb6eb2e5177957ULL, 0xae0ba5f2b35cf941ULL, 0x0bc0cb40564b8016ULL,\n\t0xb1da6bbdc20c677fULL, 0x6efb95a27ecc59dcULL, 0xbe1fa1fe9f40e161ULL,\n\t0xeb18f308c3e310cbULL, 0xfe4fb1ce2f3081e1ULL, 0x080a0206160e0c10ULL,\n\t0x17dbcc49675e922eULL, 0x37f3c4513f66a26eULL, 0x74691d27cf534ee8ULL,\n\t0x5044143c9c6c78a0ULL, 0x2be8c3580e73b056ULL, 0x91f263a59a34573fULL,\n\t0x4f95da73ed3ce69eULL, 0x69345de7358ed3d2ULL, 0x613e5fe12380dfc2ULL,\n\t0x578bdc79d72ef2aeULL, 0xe9947d87486e13cfULL, 0x13decd4a6c599426ULL,\n\t0xe19e7f815e601fdfULL, 0x752f5aee049bc1eaULL, 0xadc16cb4f3197547ULL,\n\t0x6d315ce43e89d5daULL, 0xfb0cf704efff08ebULL, 0x98be266a47f2d42dULL,\n\t0xdb24ff1cb7c738abULL, 0x937eed2a11b9543bULL, 0x876fe82536a24a13ULL,\n\t0x4ed39dba26f4699cULL, 0xa1ce6fb1ee107f5fULL, 0x028c8e8f8b8d0304ULL,\n\t0x647d192be34f56c8ULL, 0xba1aa0fd9447e769ULL, 0xe717f00ddeea1ad3ULL,\n\t0x1e978986ba98113cULL, 0x3c330f11692d2278ULL, 0x1c1b070931151238ULL,\n\t0x8629afecfd6ac511ULL, 0xcb30fb109bdb208bULL, 0x2028081858383040ULL,\n\t0x5441153f976b7ea8ULL, 0x34390d177f232e68ULL, 0x1014040c2c1c1820ULL,\n\t0x040501030b070608ULL, 0x8de964acab214507ULL, 0x5b84df7cca27f8b6ULL,\n\t0xc5b3769a0d5f2997ULL, 0xf980798b64720befULL, 0x538edd7adc29f4a6ULL,\n\t0xf4c93d47b2b38ef5ULL, 0x584e163a8a6274b0ULL, 0xfcc33f41a4bd82e5ULL,\n\t0xdceb3759fc85b2a5ULL, 0xa9c46db7f81e734fULL, 0xe0d8384895a890ddULL,\n\t0xde67b9d67708b1a1ULL, 0xd1a273952a4437bfULL, 0x836ae9263da54c1bULL,\n\t0xd4e1355fea8bbeb5ULL, 0x491c55ff6db6e392ULL, 0xd9a871933c4a3bafULL,\n\t0xf18a7b8d727c07ffULL, 0x0a868c899d830f14ULL, 0xd5a77296214331b7ULL,\n\t0x1a928885b19f1734ULL, 0xff09f607e4f80ee3ULL, 0xa8822a7e33d6fc4dULL,\n\t0xf8c63e42afba84edULL, 0x653b5ee22887d9caULL, 0x9cbb27694cf5d225ULL,\n\t0x054346cac0cf890aULL, 0x303c0c1474242860ULL, 0x89ec65afa026430fULL,\n\t0xbdd568b8df056d67ULL, 0x99f861a38c3a5b2fULL, 0x0c0f03051d090a18ULL,\n\t0x23e2c15e187dbc46ULL, 0x411657f97bb8ef82ULL, 0x7fa9d6679918cefeULL,\n\t0x439ad976f035ec86ULL, 0x7d2558e81295cdfaULL, 0x479fd875fb32ea8eULL,\n\t0x85e366aabd2f4917ULL, 0x7bacd764921fc8f6ULL, 0xe8d23a4e83a69ccdULL,\n\t0x07cfc8454b428a0eULL, 0xf0cc3c44b9b488fdULL, 0xcf35fa1390dc2683ULL,\n\t0x62f496a763c553c4ULL, 0xa601a7f4a552f551ULL, 0x5ac298b501ef77b4ULL,\n\t0x977bec291abe5233ULL, 0xda62b8d57c0fb7a9ULL, 0x3bfcc754226fa876ULL,\n\t0x822caeeff66dc319ULL, 0xb9d069bbd4026b6fULL, 0x317a4bddbfeca762ULL,\n\t0x963dabe0d176dd31ULL, 0x9e37a9e6c778d121ULL, 0x81e667a9b6284f1fULL,\n\t0x28220a1e4e363c50ULL, 0x014647c9cbc88f02ULL, 0xef1df20bc8e416c3ULL,\n\t0xee5bb5c2032c99c1ULL, 0x88aa22666beecc0dULL, 0xb356e5324981647bULL,\n\t0x9f71ee2f0cb05e23ULL, 0xc27cbedf461da399ULL, 0xac872b7d38d1fa45ULL,\n\t0x3ebf819ee2a0217cULL, 0x485a1236a67e6c90ULL, 0x36b58398f4ae2d6cULL,\n\t0x6c771b2df5415ad8ULL, 0x38360e12622a2470ULL, 0x8caf236560e9ca05ULL,\n\t0xf306f502f9f104fbULL, 0x094c45cfddc68312ULL, 0x84a5216376e7c615ULL,\n\t0x1fd1ce4f71509e3eULL, 0x397049dba9e2ab72ULL, 0xb09c2c7409c4e87dULL,\n\t0xc33af9168dd52c9bULL, 0xbf59e63754886e63ULL, 0xe254b6c71e2593d9ULL,\n\t0xa088287825d8f05dULL, 0x5c4b1739816572b8ULL, 0x32b0829bffa92b64ULL,\n\t0x68721a2efe465cd0ULL, 0x169d8b80ac961d2cULL, 0xdf21fe1fbcc03ea3ULL,\n\t0x12988a83a7911b24ULL, 0x242d091b533f3648ULL, 0x03cac94640458c06ULL,\n\t0x26a18794d8b2354cULL, 0x256b4ed298f7b94aULL, 0xa342e13e659d7c5bULL,\n\t0xb8962e721fcae46dULL, 0xb753e43142866273ULL, 0xa747e03d6e9a7a53ULL,\n\t0x8b60eb202bab400bULL, 0x7aea90ad59d747f4ULL, 0xaa0ea4f1b85bff49ULL,\n\t0x78661e22d25a44f0ULL, 0x2eab8592cebc395cULL, 0x9dfd60a0873d5d27ULL,\n\t0x0000000000000000ULL, 0x94b1256f5afbde35ULL, 0xf703f401f2f602f3ULL,\n\t0xe312f10ed5ed1cdbULL, 0x6afe94a175cb5fd4ULL, 0x2c270b1d45313a58ULL,\n\t0xbb5ce7345f8f686bULL, 0xc9bc759f1056238fULL, 0x9b74ef2c07b7582bULL,\n\t0xd0e4345ce18cb8bdULL, 0xc4f53153c697a695ULL, 0x77a3d4618f16c2eeULL,\n\t0x67b7d06da30adaceULL, 0x22a48697d3b53344ULL, 0xe59b7e82556719d7ULL,\n\t0x8e23adeaeb64c901ULL, 0xd32efd1aa1c934bbULL, 0xa48d297b2edff655ULL,\n\t0xc0f03050cd90a09dULL, 0xecd73b4d88a19ac5ULL, 0x46d99fbc30fa658cULL,\n\t0xc73ff81586d22a93ULL, 0x3ff9c6572968ae7eULL, 0x4c5f1335ad796a98ULL,\n\t0x181e060a3a121430ULL, 0x1411050f271b1e28ULL, 0x33f6c5523461a466ULL,\n\t0x44551133bb776688ULL, 0xc1b6779906582f9fULL, 0xed917c84436915c7ULL,\n\t0xf58f7a8e797b01f7ULL, 0xfd8578886f750de7ULL, 0xd8ee365af782b4adULL,\n\t0x706c1c24c45448e0ULL, 0xe4dd394b9eaf96d5ULL, 0x792059eb1992cbf2ULL,\n\t0x60781828e84850c0ULL, 0x451356fa70bfe98aULL, 0xf645b3c8393e8df1ULL,\n\t0xfa4ab0cd243787e9ULL, 0x90b4246c51fcd83dULL, 0x80a020607de0c01dULL,\n\t0xf240b2cb32398bf9ULL, 0x72e092ab4fd94be4ULL, 0xb615a3f8894eed71ULL,\n\t0x27e7c05d137aba4eULL, 0x0d4944ccd6c1851aULL, 0x95f762a691335137ULL,\n\t0x40501030b0706080ULL, 0xea5eb4c1082b9fc9ULL, 0x2aae8491c5bb3f54ULL,\n\t0x115243c5e7d49722ULL, 0x76e593a844de4decULL, 0x2fedc25b0574b65eULL,\n\t0x357f4adeb4eba16aULL, 0xce73bdda5b14a981ULL, 0x06898f8c808a050cULL,\n\t0xb4992d7702c3ee75ULL, 0xca76bcd95013af89ULL, 0x4ad69cb92df36f94ULL,\n\t0xb5df6abec90b6177ULL, 0x1d5d40c0fadd9d3aULL, 0x1bd4cf4c7a579836ULL,\n\t0xb210a2fb8249eb79ULL, 0x3aba809de9a72774ULL, 0x216e4fd193f0bf42ULL,\n\t0x7c631f21d95d42f8ULL, 0x0fc5ca435d4c861eULL, 0x9238aae3da71db39ULL,\n\t0x155742c6ecd3912aULL\n};\n\nstatic const u64 T3[256] = {\n\t0x68d2d3ba016ab9bbULL, 0x194dfc54b1669ae5ULL, 0x93bc712fcd1465e2ULL,\n\t0xb9cd9c74511b8725ULL, 0x0251f553a457a2f7ULL, 0xb86b68d303bed6d0ULL,\n\t0xbd6f6bd204b5ded6ULL, 0x6429d74dfe8552b3ULL, 0x0d5df050ad4abafdULL,\n\t0x268ae9ac63e009cfULL, 0x830e8a8d84961c09ULL, 0x79c6dcbf1a4d91a5ULL,\n\t0xaddd90704d37a73dULL, 0x0755f652a35caaf1ULL, 0xc852b39ae117a47bULL,\n\t0x612dd44cf98e5ab5ULL, 0x658f23eaac200346ULL, 0xa67362d51184e6c4ULL,\n\t0xf166a497c268cc55ULL, 0xb2636ed10da8c6dcULL, 0xffcc553399d085aaULL,\n\t0x0859f351aa41b2fbULL, 0x2a71ed5b9c0fe2c7ULL, 0x04a2f7a655ae59f3ULL,\n\t0x815f7fde20c1befeULL, 0x753dd848e5a27aadULL, 0x329ae5a87fcc29d7ULL,\n\t0xc75eb699e80abc71ULL, 0x904b70db3be696e0ULL, 0xfac856329edb8dacULL,\n\t0x51e6c4b72215d195ULL, 0x2bd719fcceaab332ULL, 0x48ab38e393734b70ULL,\n\t0xdc42bf9efd3b8463ULL, 0xef7eae91d052fc41ULL, 0xcd56b09be61cac7dULL,\n\t0x4daf3be294784376ULL, 0x6dd6d0bb0661b1bdULL, 0x5819c341daf1329bULL,\n\t0xcba5b26e17e55779ULL, 0x0baef2a55cb341f9ULL, 0xc00b40cb4b561680ULL,\n\t0xdab1bd6b0cc27f67ULL, 0xfb6ea295cc7edc59ULL, 0x1fbefea1409f61e1ULL,\n\t0x18eb08f3e3c3cb10ULL, 0x4ffeceb1302fe181ULL, 0x0a0806020e16100cULL,\n\t0xdb1749cc5e672e92ULL, 0xf33751c4663f6ea2ULL, 0x6974271d53cfe84eULL,\n\t0x44503c146c9ca078ULL, 0xe82b58c3730e56b0ULL, 0xf291a563349a3f57ULL,\n\t0x954f73da3ced9ee6ULL, 0x3469e75d8e35d2d3ULL, 0x3e61e15f8023c2dfULL,\n\t0x8b5779dc2ed7aef2ULL, 0x94e9877d6e48cf13ULL, 0xde134acd596c2694ULL,\n\t0x9ee1817f605edf1fULL, 0x2f75ee5a9b04eac1ULL, 0xc1adb46c19f34775ULL,\n\t0x316de45c893edad5ULL, 0x0cfb04f7ffefeb08ULL, 0xbe986a26f2472dd4ULL,\n\t0x24db1cffc7b7ab38ULL, 0x7e932aedb9113b54ULL, 0x6f8725e8a236134aULL,\n\t0xd34eba9df4269c69ULL, 0xcea1b16f10ee5f7fULL, 0x8c028f8e8d8b0403ULL,\n\t0x7d642b194fe3c856ULL, 0x1abafda0479469e7ULL, 0x17e70df0eaded31aULL,\n\t0x971e868998ba3c11ULL, 0x333c110f2d697822ULL, 0x1b1c090715313812ULL,\n\t0x2986ecaf6afd11c5ULL, 0x30cb10fbdb9b8b20ULL, 0x2820180838584030ULL,\n\t0x41543f156b97a87eULL, 0x3934170d237f682eULL, 0x14100c041c2c2018ULL,\n\t0x05040301070b0806ULL, 0xe98dac6421ab0745ULL, 0x845b7cdf27cab6f8ULL,\n\t0xb3c59a765f0d9729ULL, 0x80f98b797264ef0bULL, 0x8e537add29dca6f4ULL,\n\t0xc9f4473db3b2f58eULL, 0x4e583a16628ab074ULL, 0xc3fc413fbda4e582ULL,\n\t0xebdc593785fca5b2ULL, 0xc4a9b76d1ef84f73ULL, 0xd8e04838a895dd90ULL,\n\t0x67ded6b90877a1b1ULL, 0xa2d19573442abf37ULL, 0x6a8326e9a53d1b4cULL,\n\t0xe1d45f358beab5beULL, 0x1c49ff55b66d92e3ULL, 0xa8d993714a3caf3bULL,\n\t0x8af18d7b7c72ff07ULL, 0x860a898c839d140fULL, 0xa7d596724321b731ULL,\n\t0x921a85889fb13417ULL, 0x09ff07f6f8e4e30eULL, 0x82a87e2ad6334dfcULL,\n\t0xc6f8423ebaafed84ULL, 0x3b65e25e8728cad9ULL, 0xbb9c6927f54c25d2ULL,\n\t0x4305ca46cfc00a89ULL, 0x3c30140c24746028ULL, 0xec89af6526a00f43ULL,\n\t0xd5bdb86805df676dULL, 0xf899a3613a8c2f5bULL, 0x0f0c0503091d180aULL,\n\t0xe2235ec17d1846bcULL, 0x1641f957b87b82efULL, 0xa97f67d61899feceULL,\n\t0x9a4376d935f086ecULL, 0x257de8589512facdULL, 0x9f4775d832fb8eeaULL,\n\t0xe385aa662fbd1749ULL, 0xac7b64d71f92f6c8ULL, 0xd2e84e3aa683cd9cULL,\n\t0xcf0745c8424b0e8aULL, 0xccf0443cb4b9fd88ULL, 0x35cf13fadc908326ULL,\n\t0xf462a796c563c453ULL, 0x01a6f4a752a551f5ULL, 0xc25ab598ef01b477ULL,\n\t0x7b9729ecbe1a3352ULL, 0x62dad5b80f7ca9b7ULL, 0xfc3b54c76f2276a8ULL,\n\t0x2c82efae6df619c3ULL, 0xd0b9bb6902d46f6bULL, 0x7a31dd4becbf62a7ULL,\n\t0x3d96e0ab76d131ddULL, 0x379ee6a978c721d1ULL, 0xe681a96728b61f4fULL,\n\t0x22281e0a364e503cULL, 0x4601c947c8cb028fULL, 0x1def0bf2e4c8c316ULL,\n\t0x5beec2b52c03c199ULL, 0xaa886622ee6b0dccULL, 0x56b332e581497b64ULL,\n\t0x719f2feeb00c235eULL, 0x7cc2dfbe1d4699a3ULL, 0x87ac7d2bd13845faULL,\n\t0xbf3e9e81a0e27c21ULL, 0x5a4836127ea6906cULL, 0xb5369883aef46c2dULL,\n\t0x776c2d1b41f5d85aULL, 0x3638120e2a627024ULL, 0xaf8c6523e96005caULL,\n\t0x06f302f5f1f9fb04ULL, 0x4c09cf45c6dd1283ULL, 0xa5846321e77615c6ULL,\n\t0xd11f4fce50713e9eULL, 0x7039db49e2a972abULL, 0x9cb0742cc4097de8ULL,\n\t0x3ac316f9d58d9b2cULL, 0x59bf37e68854636eULL, 0x54e2c7b6251ed993ULL,\n\t0x88a07828d8255df0ULL, 0x4b5c39176581b872ULL, 0xb0329b82a9ff642bULL,\n\t0x72682e1a46fed05cULL, 0x9d16808b96ac2c1dULL, 0x21df1ffec0bca33eULL,\n\t0x9812838a91a7241bULL, 0x2d241b093f534836ULL, 0xca0346c94540068cULL,\n\t0xa1269487b2d84c35ULL, 0x6b25d24ef7984ab9ULL, 0x42a33ee19d655b7cULL,\n\t0x96b8722eca1f6de4ULL, 0x53b731e486427362ULL, 0x47a73de09a6e537aULL,\n\t0x608b20ebab2b0b40ULL, 0xea7aad90d759f447ULL, 0x0eaaf1a45bb849ffULL,\n\t0x6678221e5ad2f044ULL, 0xab2e9285bcce5c39ULL, 0xfd9da0603d87275dULL,\n\t0x0000000000000000ULL, 0xb1946f25fb5a35deULL, 0x03f701f4f6f2f302ULL,\n\t0x12e30ef1edd5db1cULL, 0xfe6aa194cb75d45fULL, 0x272c1d0b3145583aULL,\n\t0x5cbb34e78f5f6b68ULL, 0xbcc99f7556108f23ULL, 0x749b2cefb7072b58ULL,\n\t0xe4d05c348ce1bdb8ULL, 0xf5c4533197c695a6ULL, 0xa37761d4168feec2ULL,\n\t0xb7676dd00aa3cedaULL, 0xa4229786b5d34433ULL, 0x9be5827e6755d719ULL,\n\t0x238eeaad64eb01c9ULL, 0x2ed31afdc9a1bb34ULL, 0x8da47b29df2e55f6ULL,\n\t0xf0c0503090cd9da0ULL, 0xd7ec4d3ba188c59aULL, 0xd946bc9ffa308c65ULL,\n\t0x3fc715f8d286932aULL, 0xf93f57c668297eaeULL, 0x5f4c351379ad986aULL,\n\t0x1e180a06123a3014ULL, 0x11140f051b27281eULL, 0xf63352c5613466a4ULL,\n\t0x5544331177bb8866ULL, 0xb6c1997758069f2fULL, 0x91ed847c6943c715ULL,\n\t0x8ff58e7a7b79f701ULL, 0x85fd8878756fe70dULL, 0xeed85a3682f7adb4ULL,\n\t0x6c70241c54c4e048ULL, 0xdde44b39af9ed596ULL, 0x2079eb599219f2cbULL,\n\t0x7860281848e8c050ULL, 0x1345fa56bf708ae9ULL, 0x45f6c8b33e39f18dULL,\n\t0x4afacdb03724e987ULL, 0xb4906c24fc513dd8ULL, 0xa0806020e07d1dc0ULL,\n\t0x40f2cbb23932f98bULL, 0xe072ab92d94fe44bULL, 0x15b6f8a34e8971edULL,\n\t0xe7275dc07a134ebaULL, 0x490dcc44c1d61a85ULL, 0xf795a66233913751ULL,\n\t0x5040301070b08060ULL, 0x5eeac1b42b08c99fULL, 0xae2a9184bbc5543fULL,\n\t0x5211c543d4e72297ULL, 0xe576a893de44ec4dULL, 0xed2f5bc274055eb6ULL,\n\t0x7f35de4aebb46aa1ULL, 0x73cedabd145b81a9ULL, 0x89068c8f8a800c05ULL,\n\t0x99b4772dc30275eeULL, 0x76cad9bc135089afULL, 0xd64ab99cf32d946fULL,\n\t0xdfb5be6a0bc97761ULL, 0x5d1dc040ddfa3a9dULL, 0xd41b4ccf577a3698ULL,\n\t0x10b2fba2498279ebULL, 0xba3a9d80a7e97427ULL, 0x6e21d14ff09342bfULL,\n\t0x637c211f5dd9f842ULL, 0xc50f43ca4c5d1e86ULL, 0x3892e3aa71da39dbULL,\n\t0x5715c642d3ec2a91ULL\n};\n\nstatic const u64 T4[256] = {\n\t0xbbb96a01bad3d268ULL, 0xe59a66b154fc4d19ULL, 0xe26514cd2f71bc93ULL,\n\t0x25871b51749ccdb9ULL, 0xf7a257a453f55102ULL, 0xd0d6be03d3686bb8ULL,\n\t0xd6deb504d26b6fbdULL, 0xb35285fe4dd72964ULL, 0xfdba4aad50f05d0dULL,\n\t0xcf09e063ace98a26ULL, 0x091c96848d8a0e83ULL, 0xa5914d1abfdcc679ULL,\n\t0x3da7374d7090ddadULL, 0xf1aa5ca352f65507ULL, 0x7ba417e19ab352c8ULL,\n\t0xb55a8ef94cd42d61ULL, 0x460320acea238f65ULL, 0xc4e68411d56273a6ULL,\n\t0x55cc68c297a466f1ULL, 0xdcc6a80dd16e63b2ULL, 0xaa85d0993355ccffULL,\n\t0xfbb241aa51f35908ULL, 0xc7e20f9c5bed712aULL, 0xf359ae55a6f7a204ULL,\n\t0xfebec120de7f5f81ULL, 0xad7aa2e548d83d75ULL, 0xd729cc7fa8e59a32ULL,\n\t0x71bc0ae899b65ec7ULL, 0xe096e63bdb704b90ULL, 0xac8ddb9e3256c8faULL,\n\t0x95d11522b7c4e651ULL, 0x32b3aacefc19d72bULL, 0x704b7393e338ab48ULL,\n\t0x63843bfd9ebf42dcULL, 0x41fc52d091ae7eefULL, 0x7dac1ce69bb056cdULL,\n\t0x76437894e23baf4dULL, 0xbdb16106bbd0d66dULL, 0x9b32f1da41c31958ULL,\n\t0x7957e5176eb2a5cbULL, 0xf941b35ca5f2ae0bULL, 0x8016564bcb400bc0ULL,\n\t0x677fc20c6bbdb1daULL, 0x59dc7ecc95a26efbULL, 0xe1619f40a1febe1fULL,\n\t0x10cbc3e3f308eb18ULL, 0x81e12f30b1cefe4fULL, 0x0c10160e0206080aULL,\n\t0x922e675ecc4917dbULL, 0xa26e3f66c45137f3ULL, 0x4ee8cf531d277469ULL,\n\t0x78a09c6c143c5044ULL, 0xb0560e73c3582be8ULL, 0x573f9a3463a591f2ULL,\n\t0xe69eed3cda734f95ULL, 0xd3d2358e5de76934ULL, 0xdfc223805fe1613eULL,\n\t0xf2aed72edc79578bULL, 0x13cf486e7d87e994ULL, 0x94266c59cd4a13deULL,\n\t0x1fdf5e607f81e19eULL, 0xc1ea049b5aee752fULL, 0x7547f3196cb4adc1ULL,\n\t0xd5da3e895ce46d31ULL, 0x08ebeffff704fb0cULL, 0xd42d47f2266a98beULL,\n\t0x38abb7c7ff1cdb24ULL, 0x543b11b9ed2a937eULL, 0x4a1336a2e825876fULL,\n\t0x699c26f49dba4ed3ULL, 0x7f5fee106fb1a1ceULL, 0x03048b8d8e8f028cULL,\n\t0x56c8e34f192b647dULL, 0xe7699447a0fdba1aULL, 0x1ad3deeaf00de717ULL,\n\t0x113cba9889861e97ULL, 0x2278692d0f113c33ULL, 0x1238311507091c1bULL,\n\t0xc511fd6aafec8629ULL, 0x208b9bdbfb10cb30ULL, 0x3040583808182028ULL,\n\t0x7ea8976b153f5441ULL, 0x2e687f230d173439ULL, 0x18202c1c040c1014ULL,\n\t0x06080b0701030405ULL, 0x4507ab2164ac8de9ULL, 0xf8b6ca27df7c5b84ULL,\n\t0x29970d5f769ac5b3ULL, 0x0bef6472798bf980ULL, 0xf4a6dc29dd7a538eULL,\n\t0x8ef5b2b33d47f4c9ULL, 0x74b08a62163a584eULL, 0x82e5a4bd3f41fcc3ULL,\n\t0xb2a5fc853759dcebULL, 0x734ff81e6db7a9c4ULL, 0x90dd95a83848e0d8ULL,\n\t0xb1a17708b9d6de67ULL, 0x37bf2a447395d1a2ULL, 0x4c1b3da5e926836aULL,\n\t0xbeb5ea8b355fd4e1ULL, 0xe3926db655ff491cULL, 0x3baf3c4a7193d9a8ULL,\n\t0x07ff727c7b8df18aULL, 0x0f149d838c890a86ULL, 0x31b721437296d5a7ULL,\n\t0x1734b19f88851a92ULL, 0x0ee3e4f8f607ff09ULL, 0xfc4d33d62a7ea882ULL,\n\t0x84edafba3e42f8c6ULL, 0xd9ca28875ee2653bULL, 0xd2254cf527699cbbULL,\n\t0x890ac0cf46ca0543ULL, 0x286074240c14303cULL, 0x430fa02665af89ecULL,\n\t0x6d67df0568b8bdd5ULL, 0x5b2f8c3a61a399f8ULL, 0x0a181d0903050c0fULL,\n\t0xbc46187dc15e23e2ULL, 0xef827bb857f94116ULL, 0xcefe9918d6677fa9ULL,\n\t0xec86f035d976439aULL, 0xcdfa129558e87d25ULL, 0xea8efb32d875479fULL,\n\t0x4917bd2f66aa85e3ULL, 0xc8f6921fd7647bacULL, 0x9ccd83a63a4ee8d2ULL,\n\t0x8a0e4b42c84507cfULL, 0x88fdb9b43c44f0ccULL, 0x268390dcfa13cf35ULL,\n\t0x53c463c596a762f4ULL, 0xf551a552a7f4a601ULL, 0x77b401ef98b55ac2ULL,\n\t0x52331abeec29977bULL, 0xb7a97c0fb8d5da62ULL, 0xa876226fc7543bfcULL,\n\t0xc319f66daeef822cULL, 0x6b6fd40269bbb9d0ULL, 0xa762bfec4bdd317aULL,\n\t0xdd31d176abe0963dULL, 0xd121c778a9e69e37ULL, 0x4f1fb62867a981e6ULL,\n\t0x3c504e360a1e2822ULL, 0x8f02cbc847c90146ULL, 0x16c3c8e4f20bef1dULL,\n\t0x99c1032cb5c2ee5bULL, 0xcc0d6bee226688aaULL, 0x647b4981e532b356ULL,\n\t0x5e230cb0ee2f9f71ULL, 0xa399461dbedfc27cULL, 0xfa4538d12b7dac87ULL,\n\t0x217ce2a0819e3ebfULL, 0x6c90a67e1236485aULL, 0x2d6cf4ae839836b5ULL,\n\t0x5ad8f5411b2d6c77ULL, 0x2470622a0e123836ULL, 0xca0560e923658cafULL,\n\t0x04fbf9f1f502f306ULL, 0x8312ddc645cf094cULL, 0xc61576e7216384a5ULL,\n\t0x9e3e7150ce4f1fd1ULL, 0xab72a9e249db3970ULL, 0xe87d09c42c74b09cULL,\n\t0x2c9b8dd5f916c33aULL, 0x6e635488e637bf59ULL, 0x93d91e25b6c7e254ULL,\n\t0xf05d25d82878a088ULL, 0x72b8816517395c4bULL, 0x2b64ffa9829b32b0ULL,\n\t0x5cd0fe461a2e6872ULL, 0x1d2cac968b80169dULL, 0x3ea3bcc0fe1fdf21ULL,\n\t0x1b24a7918a831298ULL, 0x3648533f091b242dULL, 0x8c064045c94603caULL,\n\t0x354cd8b2879426a1ULL, 0xb94a98f74ed2256bULL, 0x7c5b659de13ea342ULL,\n\t0xe46d1fca2e72b896ULL, 0x62734286e431b753ULL, 0x7a536e9ae03da747ULL,\n\t0x400b2babeb208b60ULL, 0x47f459d790ad7aeaULL, 0xff49b85ba4f1aa0eULL,\n\t0x44f0d25a1e227866ULL, 0x395ccebc85922eabULL, 0x5d27873d60a09dfdULL,\n\t0x0000000000000000ULL, 0xde355afb256f94b1ULL, 0x02f3f2f6f401f703ULL,\n\t0x1cdbd5edf10ee312ULL, 0x5fd475cb94a16afeULL, 0x3a5845310b1d2c27ULL,\n\t0x686b5f8fe734bb5cULL, 0x238f1056759fc9bcULL, 0x582b07b7ef2c9b74ULL,\n\t0xb8bde18c345cd0e4ULL, 0xa695c6973153c4f5ULL, 0xc2ee8f16d46177a3ULL,\n\t0xdacea30ad06d67b7ULL, 0x3344d3b5869722a4ULL, 0x19d755677e82e59bULL,\n\t0xc901eb64adea8e23ULL, 0x34bba1c9fd1ad32eULL, 0xf6552edf297ba48dULL,\n\t0xa09dcd903050c0f0ULL, 0x9ac588a13b4decd7ULL, 0x658c30fa9fbc46d9ULL,\n\t0x2a9386d2f815c73fULL, 0xae7e2968c6573ff9ULL, 0x6a98ad7913354c5fULL,\n\t0x14303a12060a181eULL, 0x1e28271b050f1411ULL, 0xa4663461c55233f6ULL,\n\t0x6688bb7711334455ULL, 0x2f9f06587799c1b6ULL, 0x15c743697c84ed91ULL,\n\t0x01f7797b7a8ef58fULL, 0x0de76f757888fd85ULL, 0xb4adf782365ad8eeULL,\n\t0x48e0c4541c24706cULL, 0x96d59eaf394be4ddULL, 0xcbf2199259eb7920ULL,\n\t0x50c0e84818286078ULL, 0xe98a70bf56fa4513ULL, 0x8df1393eb3c8f645ULL,\n\t0x87e92437b0cdfa4aULL, 0xd83d51fc246c90b4ULL, 0xc01d7de0206080a0ULL,\n\t0x8bf93239b2cbf240ULL, 0x4be44fd992ab72e0ULL, 0xed71894ea3f8b615ULL,\n\t0xba4e137ac05d27e7ULL, 0x851ad6c144cc0d49ULL, 0x5137913362a695f7ULL,\n\t0x6080b07010304050ULL, 0x9fc9082bb4c1ea5eULL, 0x3f54c5bb84912aaeULL,\n\t0x9722e7d443c51152ULL, 0x4dec44de93a876e5ULL, 0xb65e0574c25b2fedULL,\n\t0xa16ab4eb4ade357fULL, 0xa9815b14bddace73ULL, 0x050c808a8f8c0689ULL,\n\t0xee7502c32d77b499ULL, 0xaf895013bcd9ca76ULL, 0x6f942df39cb94ad6ULL,\n\t0x6177c90b6abeb5dfULL, 0x9d3afadd40c01d5dULL, 0x98367a57cf4c1bd4ULL,\n\t0xeb798249a2fbb210ULL, 0x2774e9a7809d3abaULL, 0xbf4293f04fd1216eULL,\n\t0x42f8d95d1f217c63ULL, 0x861e5d4cca430fc5ULL, 0xdb39da71aae39238ULL,\n\t0x912aecd342c61557ULL\n};\n\nstatic const u64 T5[256] = {\n\t0xb9bb016ad3ba68d2ULL, 0x9ae5b166fc54194dULL, 0x65e2cd14712f93bcULL,\n\t0x8725511b9c74b9cdULL, 0xa2f7a457f5530251ULL, 0xd6d003be68d3b86bULL,\n\t0xded604b56bd2bd6fULL, 0x52b3fe85d74d6429ULL, 0xbafdad4af0500d5dULL,\n\t0x09cf63e0e9ac268aULL, 0x1c0984968a8d830eULL, 0x91a51a4ddcbf79c6ULL,\n\t0xa73d4d379070adddULL, 0xaaf1a35cf6520755ULL, 0xa47be117b39ac852ULL,\n\t0x5ab5f98ed44c612dULL, 0x0346ac2023ea658fULL, 0xe6c4118462d5a673ULL,\n\t0xcc55c268a497f166ULL, 0xc6dc0da86ed1b263ULL, 0x85aa99d05533ffccULL,\n\t0xb2fbaa41f3510859ULL, 0xe2c79c0fed5b2a71ULL, 0x59f355aef7a604a2ULL,\n\t0xbefe20c17fde815fULL, 0x7aade5a2d848753dULL, 0x29d77fcce5a8329aULL,\n\t0xbc71e80ab699c75eULL, 0x96e03be670db904bULL, 0x8dac9edb5632fac8ULL,\n\t0xd1952215c4b751e6ULL, 0xb332ceaa19fc2bd7ULL, 0x4b70937338e348abULL,\n\t0x8463fd3bbf9edc42ULL, 0xfc41d052ae91ef7eULL, 0xac7de61cb09bcd56ULL,\n\t0x437694783be24dafULL, 0xb1bd0661d0bb6dd6ULL, 0x329bdaf1c3415819ULL,\n\t0x577917e5b26ecba5ULL, 0x41f95cb3f2a50baeULL, 0x16804b5640cbc00bULL,\n\t0x7f670cc2bd6bdab1ULL, 0xdc59cc7ea295fb6eULL, 0x61e1409ffea11fbeULL,\n\t0xcb10e3c308f318ebULL, 0xe181302fceb14ffeULL, 0x100c0e1606020a08ULL,\n\t0x2e925e6749ccdb17ULL, 0x6ea2663f51c4f337ULL, 0xe84e53cf271d6974ULL,\n\t0xa0786c9c3c144450ULL, 0x56b0730e58c3e82bULL, 0x3f57349aa563f291ULL,\n\t0x9ee63ced73da954fULL, 0xd2d38e35e75d3469ULL, 0xc2df8023e15f3e61ULL,\n\t0xaef22ed779dc8b57ULL, 0xcf136e48877d94e9ULL, 0x2694596c4acdde13ULL,\n\t0xdf1f605e817f9ee1ULL, 0xeac19b04ee5a2f75ULL, 0x477519f3b46cc1adULL,\n\t0xdad5893ee45c316dULL, 0xeb08ffef04f70cfbULL, 0x2dd4f2476a26be98ULL,\n\t0xab38c7b71cff24dbULL, 0x3b54b9112aed7e93ULL, 0x134aa23625e86f87ULL,\n\t0x9c69f426ba9dd34eULL, 0x5f7f10eeb16fcea1ULL, 0x04038d8b8f8e8c02ULL,\n\t0xc8564fe32b197d64ULL, 0x69e74794fda01abaULL, 0xd31aeade0df017e7ULL,\n\t0x3c1198ba8689971eULL, 0x78222d69110f333cULL, 0x3812153109071b1cULL,\n\t0x11c56afdecaf2986ULL, 0x8b20db9b10fb30cbULL, 0x4030385818082820ULL,\n\t0xa87e6b973f154154ULL, 0x682e237f170d3934ULL, 0x20181c2c0c041410ULL,\n\t0x0806070b03010504ULL, 0x074521abac64e98dULL, 0xb6f827ca7cdf845bULL,\n\t0x97295f0d9a76b3c5ULL, 0xef0b72648b7980f9ULL, 0xa6f429dc7add8e53ULL,\n\t0xf58eb3b2473dc9f4ULL, 0xb074628a3a164e58ULL, 0xe582bda4413fc3fcULL,\n\t0xa5b285fc5937ebdcULL, 0x4f731ef8b76dc4a9ULL, 0xdd90a8954838d8e0ULL,\n\t0xa1b10877d6b967deULL, 0xbf37442a9573a2d1ULL, 0x1b4ca53d26e96a83ULL,\n\t0xb5be8bea5f35e1d4ULL, 0x92e3b66dff551c49ULL, 0xaf3b4a3c9371a8d9ULL,\n\t0xff077c728d7b8af1ULL, 0x140f839d898c860aULL, 0xb73143219672a7d5ULL,\n\t0x34179fb18588921aULL, 0xe30ef8e407f609ffULL, 0x4dfcd6337e2a82a8ULL,\n\t0xed84baaf423ec6f8ULL, 0xcad98728e25e3b65ULL, 0x25d2f54c6927bb9cULL,\n\t0x0a89cfc0ca464305ULL, 0x60282474140c3c30ULL, 0x0f4326a0af65ec89ULL,\n\t0x676d05dfb868d5bdULL, 0x2f5b3a8ca361f899ULL, 0x180a091d05030f0cULL,\n\t0x46bc7d185ec1e223ULL, 0x82efb87bf9571641ULL, 0xfece189967d6a97fULL,\n\t0x86ec35f076d99a43ULL, 0xfacd9512e858257dULL, 0x8eea32fb75d89f47ULL,\n\t0x17492fbdaa66e385ULL, 0xf6c81f9264d7ac7bULL, 0xcd9ca6834e3ad2e8ULL,\n\t0x0e8a424b45c8cf07ULL, 0xfd88b4b9443cccf0ULL, 0x8326dc9013fa35cfULL,\n\t0xc453c563a796f462ULL, 0x51f552a5f4a701a6ULL, 0xb477ef01b598c25aULL,\n\t0x3352be1a29ec7b97ULL, 0xa9b70f7cd5b862daULL, 0x76a86f2254c7fc3bULL,\n\t0x19c36df6efae2c82ULL, 0x6f6b02d4bb69d0b9ULL, 0x62a7ecbfdd4b7a31ULL,\n\t0x31dd76d1e0ab3d96ULL, 0x21d178c7e6a9379eULL, 0x1f4f28b6a967e681ULL,\n\t0x503c364e1e0a2228ULL, 0x028fc8cbc9474601ULL, 0xc316e4c80bf21defULL,\n\t0xc1992c03c2b55beeULL, 0x0dccee6b6622aa88ULL, 0x7b64814932e556b3ULL,\n\t0x235eb00c2fee719fULL, 0x99a31d46dfbe7cc2ULL, 0x45fad1387d2b87acULL,\n\t0x7c21a0e29e81bf3eULL, 0x906c7ea636125a48ULL, 0x6c2daef49883b536ULL,\n\t0xd85a41f52d1b776cULL, 0x70242a62120e3638ULL, 0x05cae9606523af8cULL,\n\t0xfb04f1f902f506f3ULL, 0x1283c6ddcf454c09ULL, 0x15c6e7766321a584ULL,\n\t0x3e9e50714fced11fULL, 0x72abe2a9db497039ULL, 0x7de8c409742c9cb0ULL,\n\t0x9b2cd58d16f93ac3ULL, 0x636e885437e659bfULL, 0xd993251ec7b654e2ULL,\n\t0x5df0d825782888a0ULL, 0xb872658139174b5cULL, 0x642ba9ff9b82b032ULL,\n\t0xd05c46fe2e1a7268ULL, 0x2c1d96ac808b9d16ULL, 0xa33ec0bc1ffe21dfULL,\n\t0x241b91a7838a9812ULL, 0x48363f531b092d24ULL, 0x068c454046c9ca03ULL,\n\t0x4c35b2d89487a126ULL, 0x4ab9f798d24e6b25ULL, 0x5b7c9d653ee142a3ULL,\n\t0x6de4ca1f722e96b8ULL, 0x7362864231e453b7ULL, 0x537a9a6e3de047a7ULL,\n\t0x0b40ab2b20eb608bULL, 0xf447d759ad90ea7aULL, 0x49ff5bb8f1a40eaaULL,\n\t0xf0445ad2221e6678ULL, 0x5c39bcce9285ab2eULL, 0x275d3d87a060fd9dULL,\n\t0x0000000000000000ULL, 0x35defb5a6f25b194ULL, 0xf302f6f201f403f7ULL,\n\t0xdb1cedd50ef112e3ULL, 0xd45fcb75a194fe6aULL, 0x583a31451d0b272cULL,\n\t0x6b688f5f34e75cbbULL, 0x8f2356109f75bcc9ULL, 0x2b58b7072cef749bULL,\n\t0xbdb88ce15c34e4d0ULL, 0x95a697c65331f5c4ULL, 0xeec2168f61d4a377ULL,\n\t0xceda0aa36dd0b767ULL, 0x4433b5d39786a422ULL, 0xd7196755827e9be5ULL,\n\t0x01c964ebeaad238eULL, 0xbb34c9a11afd2ed3ULL, 0x55f6df2e7b298da4ULL,\n\t0x9da090cd5030f0c0ULL, 0xc59aa1884d3bd7ecULL, 0x8c65fa30bc9fd946ULL,\n\t0x932ad28615f83fc7ULL, 0x7eae682957c6f93fULL, 0x986a79ad35135f4cULL,\n\t0x3014123a0a061e18ULL, 0x281e1b270f051114ULL, 0x66a4613452c5f633ULL,\n\t0x886677bb33115544ULL, 0x9f2f58069977b6c1ULL, 0xc7156943847c91edULL,\n\t0xf7017b798e7a8ff5ULL, 0xe70d756f887885fdULL, 0xadb482f75a36eed8ULL,\n\t0xe04854c4241c6c70ULL, 0xd596af9e4b39dde4ULL, 0xf2cb9219eb592079ULL,\n\t0xc05048e828187860ULL, 0x8ae9bf70fa561345ULL, 0xf18d3e39c8b345f6ULL,\n\t0xe9873724cdb04afaULL, 0x3dd8fc516c24b490ULL, 0x1dc0e07d6020a080ULL,\n\t0xf98b3932cbb240f2ULL, 0xe44bd94fab92e072ULL, 0x71ed4e89f8a315b6ULL,\n\t0x4eba7a135dc0e727ULL, 0x1a85c1d6cc44490dULL, 0x37513391a662f795ULL,\n\t0x806070b030105040ULL, 0xc99f2b08c1b45eeaULL, 0x543fbbc59184ae2aULL,\n\t0x2297d4e7c5435211ULL, 0xec4dde44a893e576ULL, 0x5eb674055bc2ed2fULL,\n\t0x6aa1ebb4de4a7f35ULL, 0x81a9145bdabd73ceULL, 0x0c058a808c8f8906ULL,\n\t0x75eec302772d99b4ULL, 0x89af1350d9bc76caULL, 0x946ff32db99cd64aULL,\n\t0x77610bc9be6adfb5ULL, 0x3a9dddfac0405d1dULL, 0x3698577a4ccfd41bULL,\n\t0x79eb4982fba210b2ULL, 0x7427a7e99d80ba3aULL, 0x42bff093d14f6e21ULL,\n\t0xf8425dd9211f637cULL, 0x1e864c5d43cac50fULL, 0x39db71dae3aa3892ULL,\n\t0x2a91d3ecc6425715ULL\n};\n\nstatic const u64 T6[256] = {\n\t0x6a01bbb9d268bad3ULL, 0x66b1e59a4d1954fcULL, 0x14cde265bc932f71ULL,\n\t0x1b512587cdb9749cULL, 0x57a4f7a2510253f5ULL, 0xbe03d0d66bb8d368ULL,\n\t0xb504d6de6fbdd26bULL, 0x85feb35229644dd7ULL, 0x4aadfdba5d0d50f0ULL,\n\t0xe063cf098a26ace9ULL, 0x9684091c0e838d8aULL, 0x4d1aa591c679bfdcULL,\n\t0x374d3da7ddad7090ULL, 0x5ca3f1aa550752f6ULL, 0x17e17ba452c89ab3ULL,\n\t0x8ef9b55a2d614cd4ULL, 0x20ac46038f65ea23ULL, 0x8411c4e673a6d562ULL,\n\t0x68c255cc66f197a4ULL, 0xa80ddcc663b2d16eULL, 0xd099aa85ccff3355ULL,\n\t0x41aafbb2590851f3ULL, 0x0f9cc7e2712a5bedULL, 0xae55f359a204a6f7ULL,\n\t0xc120febe5f81de7fULL, 0xa2e5ad7a3d7548d8ULL, 0xcc7fd7299a32a8e5ULL,\n\t0x0ae871bc5ec799b6ULL, 0xe63be0964b90db70ULL, 0xdb9eac8dc8fa3256ULL,\n\t0x152295d1e651b7c4ULL, 0xaace32b3d72bfc19ULL, 0x7393704bab48e338ULL,\n\t0x3bfd638442dc9ebfULL, 0x52d041fc7eef91aeULL, 0x1ce67dac56cd9bb0ULL,\n\t0x78947643af4de23bULL, 0x6106bdb1d66dbbd0ULL, 0xf1da9b32195841c3ULL,\n\t0xe5177957a5cb6eb2ULL, 0xb35cf941ae0ba5f2ULL, 0x564b80160bc0cb40ULL,\n\t0xc20c677fb1da6bbdULL, 0x7ecc59dc6efb95a2ULL, 0x9f40e161be1fa1feULL,\n\t0xc3e310cbeb18f308ULL, 0x2f3081e1fe4fb1ceULL, 0x160e0c10080a0206ULL,\n\t0x675e922e17dbcc49ULL, 0x3f66a26e37f3c451ULL, 0xcf534ee874691d27ULL,\n\t0x9c6c78a05044143cULL, 0x0e73b0562be8c358ULL, 0x9a34573f91f263a5ULL,\n\t0xed3ce69e4f95da73ULL, 0x358ed3d269345de7ULL, 0x2380dfc2613e5fe1ULL,\n\t0xd72ef2ae578bdc79ULL, 0x486e13cfe9947d87ULL, 0x6c59942613decd4aULL,\n\t0x5e601fdfe19e7f81ULL, 0x049bc1ea752f5aeeULL, 0xf3197547adc16cb4ULL,\n\t0x3e89d5da6d315ce4ULL, 0xefff08ebfb0cf704ULL, 0x47f2d42d98be266aULL,\n\t0xb7c738abdb24ff1cULL, 0x11b9543b937eed2aULL, 0x36a24a13876fe825ULL,\n\t0x26f4699c4ed39dbaULL, 0xee107f5fa1ce6fb1ULL, 0x8b8d0304028c8e8fULL,\n\t0xe34f56c8647d192bULL, 0x9447e769ba1aa0fdULL, 0xdeea1ad3e717f00dULL,\n\t0xba98113c1e978986ULL, 0x692d22783c330f11ULL, 0x311512381c1b0709ULL,\n\t0xfd6ac5118629afecULL, 0x9bdb208bcb30fb10ULL, 0x5838304020280818ULL,\n\t0x976b7ea85441153fULL, 0x7f232e6834390d17ULL, 0x2c1c18201014040cULL,\n\t0x0b07060804050103ULL, 0xab2145078de964acULL, 0xca27f8b65b84df7cULL,\n\t0x0d5f2997c5b3769aULL, 0x64720beff980798bULL, 0xdc29f4a6538edd7aULL,\n\t0xb2b38ef5f4c93d47ULL, 0x8a6274b0584e163aULL, 0xa4bd82e5fcc33f41ULL,\n\t0xfc85b2a5dceb3759ULL, 0xf81e734fa9c46db7ULL, 0x95a890dde0d83848ULL,\n\t0x7708b1a1de67b9d6ULL, 0x2a4437bfd1a27395ULL, 0x3da54c1b836ae926ULL,\n\t0xea8bbeb5d4e1355fULL, 0x6db6e392491c55ffULL, 0x3c4a3bafd9a87193ULL,\n\t0x727c07fff18a7b8dULL, 0x9d830f140a868c89ULL, 0x214331b7d5a77296ULL,\n\t0xb19f17341a928885ULL, 0xe4f80ee3ff09f607ULL, 0x33d6fc4da8822a7eULL,\n\t0xafba84edf8c63e42ULL, 0x2887d9ca653b5ee2ULL, 0x4cf5d2259cbb2769ULL,\n\t0xc0cf890a054346caULL, 0x74242860303c0c14ULL, 0xa026430f89ec65afULL,\n\t0xdf056d67bdd568b8ULL, 0x8c3a5b2f99f861a3ULL, 0x1d090a180c0f0305ULL,\n\t0x187dbc4623e2c15eULL, 0x7bb8ef82411657f9ULL, 0x9918cefe7fa9d667ULL,\n\t0xf035ec86439ad976ULL, 0x1295cdfa7d2558e8ULL, 0xfb32ea8e479fd875ULL,\n\t0xbd2f491785e366aaULL, 0x921fc8f67bacd764ULL, 0x83a69ccde8d23a4eULL,\n\t0x4b428a0e07cfc845ULL, 0xb9b488fdf0cc3c44ULL, 0x90dc2683cf35fa13ULL,\n\t0x63c553c462f496a7ULL, 0xa552f551a601a7f4ULL, 0x01ef77b45ac298b5ULL,\n\t0x1abe5233977bec29ULL, 0x7c0fb7a9da62b8d5ULL, 0x226fa8763bfcc754ULL,\n\t0xf66dc319822caeefULL, 0xd4026b6fb9d069bbULL, 0xbfeca762317a4bddULL,\n\t0xd176dd31963dabe0ULL, 0xc778d1219e37a9e6ULL, 0xb6284f1f81e667a9ULL,\n\t0x4e363c5028220a1eULL, 0xcbc88f02014647c9ULL, 0xc8e416c3ef1df20bULL,\n\t0x032c99c1ee5bb5c2ULL, 0x6beecc0d88aa2266ULL, 0x4981647bb356e532ULL,\n\t0x0cb05e239f71ee2fULL, 0x461da399c27cbedfULL, 0x38d1fa45ac872b7dULL,\n\t0xe2a0217c3ebf819eULL, 0xa67e6c90485a1236ULL, 0xf4ae2d6c36b58398ULL,\n\t0xf5415ad86c771b2dULL, 0x622a247038360e12ULL, 0x60e9ca058caf2365ULL,\n\t0xf9f104fbf306f502ULL, 0xddc68312094c45cfULL, 0x76e7c61584a52163ULL,\n\t0x71509e3e1fd1ce4fULL, 0xa9e2ab72397049dbULL, 0x09c4e87db09c2c74ULL,\n\t0x8dd52c9bc33af916ULL, 0x54886e63bf59e637ULL, 0x1e2593d9e254b6c7ULL,\n\t0x25d8f05da0882878ULL, 0x816572b85c4b1739ULL, 0xffa92b6432b0829bULL,\n\t0xfe465cd068721a2eULL, 0xac961d2c169d8b80ULL, 0xbcc03ea3df21fe1fULL,\n\t0xa7911b2412988a83ULL, 0x533f3648242d091bULL, 0x40458c0603cac946ULL,\n\t0xd8b2354c26a18794ULL, 0x98f7b94a256b4ed2ULL, 0x659d7c5ba342e13eULL,\n\t0x1fcae46db8962e72ULL, 0x42866273b753e431ULL, 0x6e9a7a53a747e03dULL,\n\t0x2bab400b8b60eb20ULL, 0x59d747f47aea90adULL, 0xb85bff49aa0ea4f1ULL,\n\t0xd25a44f078661e22ULL, 0xcebc395c2eab8592ULL, 0x873d5d279dfd60a0ULL,\n\t0x0000000000000000ULL, 0x5afbde3594b1256fULL, 0xf2f602f3f703f401ULL,\n\t0xd5ed1cdbe312f10eULL, 0x75cb5fd46afe94a1ULL, 0x45313a582c270b1dULL,\n\t0x5f8f686bbb5ce734ULL, 0x1056238fc9bc759fULL, 0x07b7582b9b74ef2cULL,\n\t0xe18cb8bdd0e4345cULL, 0xc697a695c4f53153ULL, 0x8f16c2ee77a3d461ULL,\n\t0xa30adace67b7d06dULL, 0xd3b5334422a48697ULL, 0x556719d7e59b7e82ULL,\n\t0xeb64c9018e23adeaULL, 0xa1c934bbd32efd1aULL, 0x2edff655a48d297bULL,\n\t0xcd90a09dc0f03050ULL, 0x88a19ac5ecd73b4dULL, 0x30fa658c46d99fbcULL,\n\t0x86d22a93c73ff815ULL, 0x2968ae7e3ff9c657ULL, 0xad796a984c5f1335ULL,\n\t0x3a121430181e060aULL, 0x271b1e281411050fULL, 0x3461a46633f6c552ULL,\n\t0xbb77668844551133ULL, 0x06582f9fc1b67799ULL, 0x436915c7ed917c84ULL,\n\t0x797b01f7f58f7a8eULL, 0x6f750de7fd857888ULL, 0xf782b4add8ee365aULL,\n\t0xc45448e0706c1c24ULL, 0x9eaf96d5e4dd394bULL, 0x1992cbf2792059ebULL,\n\t0xe84850c060781828ULL, 0x70bfe98a451356faULL, 0x393e8df1f645b3c8ULL,\n\t0x243787e9fa4ab0cdULL, 0x51fcd83d90b4246cULL, 0x7de0c01d80a02060ULL,\n\t0x32398bf9f240b2cbULL, 0x4fd94be472e092abULL, 0x894eed71b615a3f8ULL,\n\t0x137aba4e27e7c05dULL, 0xd6c1851a0d4944ccULL, 0x9133513795f762a6ULL,\n\t0xb070608040501030ULL, 0x082b9fc9ea5eb4c1ULL, 0xc5bb3f542aae8491ULL,\n\t0xe7d49722115243c5ULL, 0x44de4dec76e593a8ULL, 0x0574b65e2fedc25bULL,\n\t0xb4eba16a357f4adeULL, 0x5b14a981ce73bddaULL, 0x808a050c06898f8cULL,\n\t0x02c3ee75b4992d77ULL, 0x5013af89ca76bcd9ULL, 0x2df36f944ad69cb9ULL,\n\t0xc90b6177b5df6abeULL, 0xfadd9d3a1d5d40c0ULL, 0x7a5798361bd4cf4cULL,\n\t0x8249eb79b210a2fbULL, 0xe9a727743aba809dULL, 0x93f0bf42216e4fd1ULL,\n\t0xd95d42f87c631f21ULL, 0x5d4c861e0fc5ca43ULL, 0xda71db399238aae3ULL,\n\t0xecd3912a155742c6ULL\n};\n\nstatic const u64 T7[256] = {\n\t0x016ab9bb68d2d3baULL, 0xb1669ae5194dfc54ULL, 0xcd1465e293bc712fULL,\n\t0x511b8725b9cd9c74ULL, 0xa457a2f70251f553ULL, 0x03bed6d0b86b68d3ULL,\n\t0x04b5ded6bd6f6bd2ULL, 0xfe8552b36429d74dULL, 0xad4abafd0d5df050ULL,\n\t0x63e009cf268ae9acULL, 0x84961c09830e8a8dULL, 0x1a4d91a579c6dcbfULL,\n\t0x4d37a73daddd9070ULL, 0xa35caaf10755f652ULL, 0xe117a47bc852b39aULL,\n\t0xf98e5ab5612dd44cULL, 0xac200346658f23eaULL, 0x1184e6c4a67362d5ULL,\n\t0xc268cc55f166a497ULL, 0x0da8c6dcb2636ed1ULL, 0x99d085aaffcc5533ULL,\n\t0xaa41b2fb0859f351ULL, 0x9c0fe2c72a71ed5bULL, 0x55ae59f304a2f7a6ULL,\n\t0x20c1befe815f7fdeULL, 0xe5a27aad753dd848ULL, 0x7fcc29d7329ae5a8ULL,\n\t0xe80abc71c75eb699ULL, 0x3be696e0904b70dbULL, 0x9edb8dacfac85632ULL,\n\t0x2215d19551e6c4b7ULL, 0xceaab3322bd719fcULL, 0x93734b7048ab38e3ULL,\n\t0xfd3b8463dc42bf9eULL, 0xd052fc41ef7eae91ULL, 0xe61cac7dcd56b09bULL,\n\t0x947843764daf3be2ULL, 0x0661b1bd6dd6d0bbULL, 0xdaf1329b5819c341ULL,\n\t0x17e55779cba5b26eULL, 0x5cb341f90baef2a5ULL, 0x4b561680c00b40cbULL,\n\t0x0cc27f67dab1bd6bULL, 0xcc7edc59fb6ea295ULL, 0x409f61e11fbefea1ULL,\n\t0xe3c3cb1018eb08f3ULL, 0x302fe1814ffeceb1ULL, 0x0e16100c0a080602ULL,\n\t0x5e672e92db1749ccULL, 0x663f6ea2f33751c4ULL, 0x53cfe84e6974271dULL,\n\t0x6c9ca07844503c14ULL, 0x730e56b0e82b58c3ULL, 0x349a3f57f291a563ULL,\n\t0x3ced9ee6954f73daULL, 0x8e35d2d33469e75dULL, 0x8023c2df3e61e15fULL,\n\t0x2ed7aef28b5779dcULL, 0x6e48cf1394e9877dULL, 0x596c2694de134acdULL,\n\t0x605edf1f9ee1817fULL, 0x9b04eac12f75ee5aULL, 0x19f34775c1adb46cULL,\n\t0x893edad5316de45cULL, 0xffefeb080cfb04f7ULL, 0xf2472dd4be986a26ULL,\n\t0xc7b7ab3824db1cffULL, 0xb9113b547e932aedULL, 0xa236134a6f8725e8ULL,\n\t0xf4269c69d34eba9dULL, 0x10ee5f7fcea1b16fULL, 0x8d8b04038c028f8eULL,\n\t0x4fe3c8567d642b19ULL, 0x479469e71abafda0ULL, 0xeaded31a17e70df0ULL,\n\t0x98ba3c11971e8689ULL, 0x2d697822333c110fULL, 0x153138121b1c0907ULL,\n\t0x6afd11c52986ecafULL, 0xdb9b8b2030cb10fbULL, 0x3858403028201808ULL,\n\t0x6b97a87e41543f15ULL, 0x237f682e3934170dULL, 0x1c2c201814100c04ULL,\n\t0x070b080605040301ULL, 0x21ab0745e98dac64ULL, 0x27cab6f8845b7cdfULL,\n\t0x5f0d9729b3c59a76ULL, 0x7264ef0b80f98b79ULL, 0x29dca6f48e537addULL,\n\t0xb3b2f58ec9f4473dULL, 0x628ab0744e583a16ULL, 0xbda4e582c3fc413fULL,\n\t0x85fca5b2ebdc5937ULL, 0x1ef84f73c4a9b76dULL, 0xa895dd90d8e04838ULL,\n\t0x0877a1b167ded6b9ULL, 0x442abf37a2d19573ULL, 0xa53d1b4c6a8326e9ULL,\n\t0x8beab5bee1d45f35ULL, 0xb66d92e31c49ff55ULL, 0x4a3caf3ba8d99371ULL,\n\t0x7c72ff078af18d7bULL, 0x839d140f860a898cULL, 0x4321b731a7d59672ULL,\n\t0x9fb13417921a8588ULL, 0xf8e4e30e09ff07f6ULL, 0xd6334dfc82a87e2aULL,\n\t0xbaafed84c6f8423eULL, 0x8728cad93b65e25eULL, 0xf54c25d2bb9c6927ULL,\n\t0xcfc00a894305ca46ULL, 0x247460283c30140cULL, 0x26a00f43ec89af65ULL,\n\t0x05df676dd5bdb868ULL, 0x3a8c2f5bf899a361ULL, 0x091d180a0f0c0503ULL,\n\t0x7d1846bce2235ec1ULL, 0xb87b82ef1641f957ULL, 0x1899fecea97f67d6ULL,\n\t0x35f086ec9a4376d9ULL, 0x9512facd257de858ULL, 0x32fb8eea9f4775d8ULL,\n\t0x2fbd1749e385aa66ULL, 0x1f92f6c8ac7b64d7ULL, 0xa683cd9cd2e84e3aULL,\n\t0x424b0e8acf0745c8ULL, 0xb4b9fd88ccf0443cULL, 0xdc90832635cf13faULL,\n\t0xc563c453f462a796ULL, 0x52a551f501a6f4a7ULL, 0xef01b477c25ab598ULL,\n\t0xbe1a33527b9729ecULL, 0x0f7ca9b762dad5b8ULL, 0x6f2276a8fc3b54c7ULL,\n\t0x6df619c32c82efaeULL, 0x02d46f6bd0b9bb69ULL, 0xecbf62a77a31dd4bULL,\n\t0x76d131dd3d96e0abULL, 0x78c721d1379ee6a9ULL, 0x28b61f4fe681a967ULL,\n\t0x364e503c22281e0aULL, 0xc8cb028f4601c947ULL, 0xe4c8c3161def0bf2ULL,\n\t0x2c03c1995beec2b5ULL, 0xee6b0dccaa886622ULL, 0x81497b6456b332e5ULL,\n\t0xb00c235e719f2feeULL, 0x1d4699a37cc2dfbeULL, 0xd13845fa87ac7d2bULL,\n\t0xa0e27c21bf3e9e81ULL, 0x7ea6906c5a483612ULL, 0xaef46c2db5369883ULL,\n\t0x41f5d85a776c2d1bULL, 0x2a6270243638120eULL, 0xe96005caaf8c6523ULL,\n\t0xf1f9fb0406f302f5ULL, 0xc6dd12834c09cf45ULL, 0xe77615c6a5846321ULL,\n\t0x50713e9ed11f4fceULL, 0xe2a972ab7039db49ULL, 0xc4097de89cb0742cULL,\n\t0xd58d9b2c3ac316f9ULL, 0x8854636e59bf37e6ULL, 0x251ed99354e2c7b6ULL,\n\t0xd8255df088a07828ULL, 0x6581b8724b5c3917ULL, 0xa9ff642bb0329b82ULL,\n\t0x46fed05c72682e1aULL, 0x96ac2c1d9d16808bULL, 0xc0bca33e21df1ffeULL,\n\t0x91a7241b9812838aULL, 0x3f5348362d241b09ULL, 0x4540068cca0346c9ULL,\n\t0xb2d84c35a1269487ULL, 0xf7984ab96b25d24eULL, 0x9d655b7c42a33ee1ULL,\n\t0xca1f6de496b8722eULL, 0x8642736253b731e4ULL, 0x9a6e537a47a73de0ULL,\n\t0xab2b0b40608b20ebULL, 0xd759f447ea7aad90ULL, 0x5bb849ff0eaaf1a4ULL,\n\t0x5ad2f0446678221eULL, 0xbcce5c39ab2e9285ULL, 0x3d87275dfd9da060ULL,\n\t0x0000000000000000ULL, 0xfb5a35deb1946f25ULL, 0xf6f2f30203f701f4ULL,\n\t0xedd5db1c12e30ef1ULL, 0xcb75d45ffe6aa194ULL, 0x3145583a272c1d0bULL,\n\t0x8f5f6b685cbb34e7ULL, 0x56108f23bcc99f75ULL, 0xb7072b58749b2cefULL,\n\t0x8ce1bdb8e4d05c34ULL, 0x97c695a6f5c45331ULL, 0x168feec2a37761d4ULL,\n\t0x0aa3cedab7676dd0ULL, 0xb5d34433a4229786ULL, 0x6755d7199be5827eULL,\n\t0x64eb01c9238eeaadULL, 0xc9a1bb342ed31afdULL, 0xdf2e55f68da47b29ULL,\n\t0x90cd9da0f0c05030ULL, 0xa188c59ad7ec4d3bULL, 0xfa308c65d946bc9fULL,\n\t0xd286932a3fc715f8ULL, 0x68297eaef93f57c6ULL, 0x79ad986a5f4c3513ULL,\n\t0x123a30141e180a06ULL, 0x1b27281e11140f05ULL, 0x613466a4f63352c5ULL,\n\t0x77bb886655443311ULL, 0x58069f2fb6c19977ULL, 0x6943c71591ed847cULL,\n\t0x7b79f7018ff58e7aULL, 0x756fe70d85fd8878ULL, 0x82f7adb4eed85a36ULL,\n\t0x54c4e0486c70241cULL, 0xaf9ed596dde44b39ULL, 0x9219f2cb2079eb59ULL,\n\t0x48e8c05078602818ULL, 0xbf708ae91345fa56ULL, 0x3e39f18d45f6c8b3ULL,\n\t0x3724e9874afacdb0ULL, 0xfc513dd8b4906c24ULL, 0xe07d1dc0a0806020ULL,\n\t0x3932f98b40f2cbb2ULL, 0xd94fe44be072ab92ULL, 0x4e8971ed15b6f8a3ULL,\n\t0x7a134ebae7275dc0ULL, 0xc1d61a85490dcc44ULL, 0x33913751f795a662ULL,\n\t0x70b0806050403010ULL, 0x2b08c99f5eeac1b4ULL, 0xbbc5543fae2a9184ULL,\n\t0xd4e722975211c543ULL, 0xde44ec4de576a893ULL, 0x74055eb6ed2f5bc2ULL,\n\t0xebb46aa17f35de4aULL, 0x145b81a973cedabdULL, 0x8a800c0589068c8fULL,\n\t0xc30275ee99b4772dULL, 0x135089af76cad9bcULL, 0xf32d946fd64ab99cULL,\n\t0x0bc97761dfb5be6aULL, 0xddfa3a9d5d1dc040ULL, 0x577a3698d41b4ccfULL,\n\t0x498279eb10b2fba2ULL, 0xa7e97427ba3a9d80ULL, 0xf09342bf6e21d14fULL,\n\t0x5dd9f842637c211fULL, 0x4c5d1e86c50f43caULL, 0x71da39db3892e3aaULL,\n\t0xd3ec2a915715c642ULL\n};\n\nstatic const u64 c[KHAZAD_ROUNDS + 1] = {\n\t0xba542f7453d3d24dULL, 0x50ac8dbf70529a4cULL, 0xead597d133515ba6ULL,\n\t0xde48a899db32b7fcULL, 0xe39e919be2bb416eULL, 0xa5cb6b95a1f3b102ULL,\n\t0xccc41d14c363da5dULL, 0x5fdc7dcd7f5a6c5cULL, 0xf726ffede89d6f8eULL\n};\n\nstatic int khazad_setkey(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t\t unsigned int key_len)\n{\n\tstruct khazad_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __be32 *key = (const __be32 *)in_key;\n\tint r;\n\tconst u64 *S = T7;\n\tu64 K2, K1;\n\n\t/* key is supposed to be 32-bit aligned */\n\tK2 = ((u64)be32_to_cpu(key[0]) << 32) | be32_to_cpu(key[1]);\n\tK1 = ((u64)be32_to_cpu(key[2]) << 32) | be32_to_cpu(key[3]);\n\n\t/* setup the encrypt key */\n\tfor (r = 0; r <= KHAZAD_ROUNDS; r++) {\n\t\tctx->E[r] = T0[(int)(K1 >> 56)       ] ^\n\t\t\t    T1[(int)(K1 >> 48) & 0xff] ^\n\t\t\t    T2[(int)(K1 >> 40) & 0xff] ^\n\t\t\t    T3[(int)(K1 >> 32) & 0xff] ^\n\t\t\t    T4[(int)(K1 >> 24) & 0xff] ^\n\t\t\t    T5[(int)(K1 >> 16) & 0xff] ^\n\t\t\t    T6[(int)(K1 >>  8) & 0xff] ^\n\t\t\t    T7[(int)(K1      ) & 0xff] ^\n\t\t\t    c[r] ^ K2;\n\t\tK2 = K1; \n\t\tK1 = ctx->E[r];\n\t}\n\t/* Setup the decrypt key */\n\tctx->D[0] = ctx->E[KHAZAD_ROUNDS];\n\tfor (r = 1; r < KHAZAD_ROUNDS; r++) {\n\t\tK1 = ctx->E[KHAZAD_ROUNDS - r];\n\t\tctx->D[r] = T0[(int)S[(int)(K1 >> 56)       ] & 0xff] ^\n\t\t\t    T1[(int)S[(int)(K1 >> 48) & 0xff] & 0xff] ^\n\t\t\t    T2[(int)S[(int)(K1 >> 40) & 0xff] & 0xff] ^\n\t\t\t    T3[(int)S[(int)(K1 >> 32) & 0xff] & 0xff] ^\n\t\t\t    T4[(int)S[(int)(K1 >> 24) & 0xff] & 0xff] ^\n\t\t\t    T5[(int)S[(int)(K1 >> 16) & 0xff] & 0xff] ^\n\t\t\t    T6[(int)S[(int)(K1 >>  8) & 0xff] & 0xff] ^\n\t\t\t    T7[(int)S[(int)(K1      ) & 0xff] & 0xff];\n\t}\n\tctx->D[KHAZAD_ROUNDS] = ctx->E[0];\n\n\treturn 0;\n\n}\n\nstatic void khazad_crypt(const u64 roundKey[KHAZAD_ROUNDS + 1],\n\t\tu8 *ciphertext, const u8 *plaintext)\n{\n\tconst __be64 *src = (const __be64 *)plaintext;\n\t__be64 *dst = (__be64 *)ciphertext;\n\tint r;\n\tu64 state;\n\n\tstate = be64_to_cpu(*src) ^ roundKey[0];\n\n\tfor (r = 1; r < KHAZAD_ROUNDS; r++) {\n\t\tstate = T0[(int)(state >> 56)       ] ^\n\t\t\tT1[(int)(state >> 48) & 0xff] ^\n\t\t\tT2[(int)(state >> 40) & 0xff] ^\n\t\t\tT3[(int)(state >> 32) & 0xff] ^\n\t\t\tT4[(int)(state >> 24) & 0xff] ^\n\t\t\tT5[(int)(state >> 16) & 0xff] ^\n\t\t\tT6[(int)(state >>  8) & 0xff] ^\n\t\t\tT7[(int)(state      ) & 0xff] ^\n\t\t\troundKey[r];\n    \t}\n\n\tstate = (T0[(int)(state >> 56)       ] & 0xff00000000000000ULL) ^\n\t\t(T1[(int)(state >> 48) & 0xff] & 0x00ff000000000000ULL) ^\n\t\t(T2[(int)(state >> 40) & 0xff] & 0x0000ff0000000000ULL) ^\n\t\t(T3[(int)(state >> 32) & 0xff] & 0x000000ff00000000ULL) ^\n\t\t(T4[(int)(state >> 24) & 0xff] & 0x00000000ff000000ULL) ^\n\t\t(T5[(int)(state >> 16) & 0xff] & 0x0000000000ff0000ULL) ^\n\t\t(T6[(int)(state >>  8) & 0xff] & 0x000000000000ff00ULL) ^\n\t\t(T7[(int)(state      ) & 0xff] & 0x00000000000000ffULL) ^\n\t\troundKey[KHAZAD_ROUNDS];\n\n\t*dst = cpu_to_be64(state);\n}\n\nstatic void khazad_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct khazad_ctx *ctx = crypto_tfm_ctx(tfm);\n\tkhazad_crypt(ctx->E, dst, src);\n}\n\nstatic void khazad_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct khazad_ctx *ctx = crypto_tfm_ctx(tfm);\n\tkhazad_crypt(ctx->D, dst, src);\n}\n\nstatic struct crypto_alg khazad_alg = {\n\t.cra_name\t\t=\t\"khazad\",\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tKHAZAD_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof (struct khazad_ctx),\n\t.cra_alignmask\t\t=\t7,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\tKHAZAD_KEY_SIZE,\n\t.cia_max_keysize\t=\tKHAZAD_KEY_SIZE,\n\t.cia_setkey\t\t= \tkhazad_setkey,\n\t.cia_encrypt\t\t=\tkhazad_encrypt,\n\t.cia_decrypt\t\t=\tkhazad_decrypt } }\n};\n\nstatic int __init khazad_mod_init(void)\n{\n\tint ret = 0;\n\t\n\tret = crypto_register_alg(&khazad_alg);\n\treturn ret;\n}\n\nstatic void __exit khazad_mod_fini(void)\n{\n\tcrypto_unregister_alg(&khazad_alg);\n}\n\n\nmodule_init(khazad_mod_init);\nmodule_exit(khazad_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Khazad Cryptographic Algorithm\");\n", "/*\n * RNG implementation using standard kernel RNG.\n *\n * Copyright (c) 2008 Herbert Xu <herbert@gondor.apana.org.au>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the\n * Free Software Foundation; either version 2 of the License, or (at your\n * any later version.\n *\n */\n\n#include <crypto/internal/rng.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/random.h>\n\nstatic int krng_get_random(struct crypto_rng *tfm, u8 *rdata, unsigned int dlen)\n{\n\tget_random_bytes(rdata, dlen);\n\treturn 0;\n}\n\nstatic int krng_reset(struct crypto_rng *tfm, u8 *seed, unsigned int slen)\n{\n\treturn 0;\n}\n\nstatic struct crypto_alg krng_alg = {\n\t.cra_name\t\t= \"stdrng\",\n\t.cra_driver_name\t= \"krng\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_RNG,\n\t.cra_ctxsize\t\t= 0,\n\t.cra_type\t\t= &crypto_rng_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u\t\t\t= {\n\t\t.rng = {\n\t\t\t.rng_make_random\t= krng_get_random,\n\t\t\t.rng_reset\t\t= krng_reset,\n\t\t\t.seedsize\t\t= 0,\n\t\t}\n\t}\n};\n\n\n/* Module initalization */\nstatic int __init krng_mod_init(void)\n{\n\treturn crypto_register_alg(&krng_alg);\n}\n\nstatic void __exit krng_mod_fini(void)\n{\n\tcrypto_unregister_alg(&krng_alg);\n\treturn;\n}\n\nmodule_init(krng_mod_init);\nmodule_exit(krng_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Kernel Random Number Generator\");\nMODULE_ALIAS(\"stdrng\");\n", "/*\n * Cryptographic API.\n *\n * Copyright (c) 2013 Chanho Min <chanho.min@lge.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License version 2 as published by\n * the Free Software Foundation.\n *\n * This program is distributed in the hope that it will be useful, but WITHOUT\n * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for\n * more details.\n *\n * You should have received a copy of the GNU General Public License along with\n * this program; if not, write to the Free Software Foundation, Inc., 51\n * Franklin St, Fifth Floor, Boston, MA 02110-1301 USA\n *\n */\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/crypto.h>\n#include <linux/vmalloc.h>\n#include <linux/lz4.h>\n\nstruct lz4_ctx {\n\tvoid *lz4_comp_mem;\n};\n\nstatic int lz4_init(struct crypto_tfm *tfm)\n{\n\tstruct lz4_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tctx->lz4_comp_mem = vmalloc(LZ4_MEM_COMPRESS);\n\tif (!ctx->lz4_comp_mem)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic void lz4_exit(struct crypto_tfm *tfm)\n{\n\tstruct lz4_ctx *ctx = crypto_tfm_ctx(tfm);\n\tvfree(ctx->lz4_comp_mem);\n}\n\nstatic int lz4_compress_crypto(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t    unsigned int slen, u8 *dst, unsigned int *dlen)\n{\n\tstruct lz4_ctx *ctx = crypto_tfm_ctx(tfm);\n\tsize_t tmp_len = *dlen;\n\tint err;\n\n\terr = lz4_compress(src, slen, dst, &tmp_len, ctx->lz4_comp_mem);\n\n\tif (err < 0)\n\t\treturn -EINVAL;\n\n\t*dlen = tmp_len;\n\treturn 0;\n}\n\nstatic int lz4_decompress_crypto(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t      unsigned int slen, u8 *dst, unsigned int *dlen)\n{\n\tint err;\n\tsize_t tmp_len = *dlen;\n\tsize_t __slen = slen;\n\n\terr = lz4_decompress_unknownoutputsize(src, __slen, dst, &tmp_len);\n\tif (err < 0)\n\t\treturn -EINVAL;\n\n\t*dlen = tmp_len;\n\treturn err;\n}\n\nstatic struct crypto_alg alg_lz4 = {\n\t.cra_name\t\t= \"lz4\",\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_COMPRESS,\n\t.cra_ctxsize\t\t= sizeof(struct lz4_ctx),\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(alg_lz4.cra_list),\n\t.cra_init\t\t= lz4_init,\n\t.cra_exit\t\t= lz4_exit,\n\t.cra_u\t\t\t= { .compress = {\n\t.coa_compress\t\t= lz4_compress_crypto,\n\t.coa_decompress\t\t= lz4_decompress_crypto } }\n};\n\nstatic int __init lz4_mod_init(void)\n{\n\treturn crypto_register_alg(&alg_lz4);\n}\n\nstatic void __exit lz4_mod_fini(void)\n{\n\tcrypto_unregister_alg(&alg_lz4);\n}\n\nmodule_init(lz4_mod_init);\nmodule_exit(lz4_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"LZ4 Compression Algorithm\");\n", "/*\n * Cryptographic API.\n *\n * Copyright (c) 2013 Chanho Min <chanho.min@lge.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License version 2 as published by\n * the Free Software Foundation.\n *\n * This program is distributed in the hope that it will be useful, but WITHOUT\n * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for\n * more details.\n *\n * You should have received a copy of the GNU General Public License along with\n * this program; if not, write to the Free Software Foundation, Inc., 51\n * Franklin St, Fifth Floor, Boston, MA 02110-1301 USA\n *\n */\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/crypto.h>\n#include <linux/vmalloc.h>\n#include <linux/lz4.h>\n\nstruct lz4hc_ctx {\n\tvoid *lz4hc_comp_mem;\n};\n\nstatic int lz4hc_init(struct crypto_tfm *tfm)\n{\n\tstruct lz4hc_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tctx->lz4hc_comp_mem = vmalloc(LZ4HC_MEM_COMPRESS);\n\tif (!ctx->lz4hc_comp_mem)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic void lz4hc_exit(struct crypto_tfm *tfm)\n{\n\tstruct lz4hc_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tvfree(ctx->lz4hc_comp_mem);\n}\n\nstatic int lz4hc_compress_crypto(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t    unsigned int slen, u8 *dst, unsigned int *dlen)\n{\n\tstruct lz4hc_ctx *ctx = crypto_tfm_ctx(tfm);\n\tsize_t tmp_len = *dlen;\n\tint err;\n\n\terr = lz4hc_compress(src, slen, dst, &tmp_len, ctx->lz4hc_comp_mem);\n\n\tif (err < 0)\n\t\treturn -EINVAL;\n\n\t*dlen = tmp_len;\n\treturn 0;\n}\n\nstatic int lz4hc_decompress_crypto(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t      unsigned int slen, u8 *dst, unsigned int *dlen)\n{\n\tint err;\n\tsize_t tmp_len = *dlen;\n\tsize_t __slen = slen;\n\n\terr = lz4_decompress_unknownoutputsize(src, __slen, dst, &tmp_len);\n\tif (err < 0)\n\t\treturn -EINVAL;\n\n\t*dlen = tmp_len;\n\treturn err;\n}\n\nstatic struct crypto_alg alg_lz4hc = {\n\t.cra_name\t\t= \"lz4hc\",\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_COMPRESS,\n\t.cra_ctxsize\t\t= sizeof(struct lz4hc_ctx),\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(alg_lz4hc.cra_list),\n\t.cra_init\t\t= lz4hc_init,\n\t.cra_exit\t\t= lz4hc_exit,\n\t.cra_u\t\t\t= { .compress = {\n\t.coa_compress\t\t= lz4hc_compress_crypto,\n\t.coa_decompress\t\t= lz4hc_decompress_crypto } }\n};\n\nstatic int __init lz4hc_mod_init(void)\n{\n\treturn crypto_register_alg(&alg_lz4hc);\n}\n\nstatic void __exit lz4hc_mod_fini(void)\n{\n\tcrypto_unregister_alg(&alg_lz4hc);\n}\n\nmodule_init(lz4hc_mod_init);\nmodule_exit(lz4hc_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"LZ4HC Compression Algorithm\");\n", "/*\n * Cryptographic API.\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License version 2 as published by\n * the Free Software Foundation.\n *\n * This program is distributed in the hope that it will be useful, but WITHOUT\n * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for\n * more details.\n *\n * You should have received a copy of the GNU General Public License along with\n * this program; if not, write to the Free Software Foundation, Inc., 51\n * Franklin St, Fifth Floor, Boston, MA 02110-1301 USA\n *\n */\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/crypto.h>\n#include <linux/vmalloc.h>\n#include <linux/mm.h>\n#include <linux/lzo.h>\n\nstruct lzo_ctx {\n\tvoid *lzo_comp_mem;\n};\n\nstatic int lzo_init(struct crypto_tfm *tfm)\n{\n\tstruct lzo_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tctx->lzo_comp_mem = kmalloc(LZO1X_MEM_COMPRESS,\n\t\t\t\t    GFP_KERNEL | __GFP_NOWARN | __GFP_REPEAT);\n\tif (!ctx->lzo_comp_mem)\n\t\tctx->lzo_comp_mem = vmalloc(LZO1X_MEM_COMPRESS);\n\tif (!ctx->lzo_comp_mem)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic void lzo_exit(struct crypto_tfm *tfm)\n{\n\tstruct lzo_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tkvfree(ctx->lzo_comp_mem);\n}\n\nstatic int lzo_compress(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t    unsigned int slen, u8 *dst, unsigned int *dlen)\n{\n\tstruct lzo_ctx *ctx = crypto_tfm_ctx(tfm);\n\tsize_t tmp_len = *dlen; /* size_t(ulong) <-> uint on 64 bit */\n\tint err;\n\n\terr = lzo1x_1_compress(src, slen, dst, &tmp_len, ctx->lzo_comp_mem);\n\n\tif (err != LZO_E_OK)\n\t\treturn -EINVAL;\n\n\t*dlen = tmp_len;\n\treturn 0;\n}\n\nstatic int lzo_decompress(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t      unsigned int slen, u8 *dst, unsigned int *dlen)\n{\n\tint err;\n\tsize_t tmp_len = *dlen; /* size_t(ulong) <-> uint on 64 bit */\n\n\terr = lzo1x_decompress_safe(src, slen, dst, &tmp_len);\n\n\tif (err != LZO_E_OK)\n\t\treturn -EINVAL;\n\n\t*dlen = tmp_len;\n\treturn 0;\n\n}\n\nstatic struct crypto_alg alg = {\n\t.cra_name\t\t= \"lzo\",\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_COMPRESS,\n\t.cra_ctxsize\t\t= sizeof(struct lzo_ctx),\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= lzo_init,\n\t.cra_exit\t\t= lzo_exit,\n\t.cra_u\t\t\t= { .compress = {\n\t.coa_compress \t\t= lzo_compress,\n\t.coa_decompress  \t= lzo_decompress } }\n};\n\nstatic int __init lzo_mod_init(void)\n{\n\treturn crypto_register_alg(&alg);\n}\n\nstatic void __exit lzo_mod_fini(void)\n{\n\tcrypto_unregister_alg(&alg);\n}\n\nmodule_init(lzo_mod_init);\nmodule_exit(lzo_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"LZO Compression Algorithm\");\n", "/* \n * Cryptographic API.\n *\n * MD4 Message Digest Algorithm (RFC1320).\n *\n * Implementation derived from Andrew Tridgell and Steve French's\n * CIFS MD4 implementation, and the cryptoapi implementation\n * originally based on the public domain implementation written\n * by Colin Plumb in 1993.\n *\n * Copyright (c) Andrew Tridgell 1997-1998.\n * Modified by Steve French (sfrench@us.ibm.com) 2002\n * Copyright (c) Cryptoapi developers.\n * Copyright (c) 2002 David S. Miller (davem@redhat.com)\n * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <asm/byteorder.h>\n\n#define MD4_DIGEST_SIZE\t\t16\n#define MD4_HMAC_BLOCK_SIZE\t64\n#define MD4_BLOCK_WORDS\t\t16\n#define MD4_HASH_WORDS\t\t4\n\nstruct md4_ctx {\n\tu32 hash[MD4_HASH_WORDS];\n\tu32 block[MD4_BLOCK_WORDS];\n\tu64 byte_count;\n};\n\nstatic inline u32 lshift(u32 x, unsigned int s)\n{\n\tx &= 0xFFFFFFFF;\n\treturn ((x << s) & 0xFFFFFFFF) | (x >> (32 - s));\n}\n\nstatic inline u32 F(u32 x, u32 y, u32 z)\n{\n\treturn (x & y) | ((~x) & z);\n}\n\nstatic inline u32 G(u32 x, u32 y, u32 z)\n{\n\treturn (x & y) | (x & z) | (y & z);\n}\n\nstatic inline u32 H(u32 x, u32 y, u32 z)\n{\n\treturn x ^ y ^ z;\n}\n\n#define ROUND1(a,b,c,d,k,s) (a = lshift(a + F(b,c,d) + k, s))\n#define ROUND2(a,b,c,d,k,s) (a = lshift(a + G(b,c,d) + k + (u32)0x5A827999,s))\n#define ROUND3(a,b,c,d,k,s) (a = lshift(a + H(b,c,d) + k + (u32)0x6ED9EBA1,s))\n\n/* XXX: this stuff can be optimized */\nstatic inline void le32_to_cpu_array(u32 *buf, unsigned int words)\n{\n\twhile (words--) {\n\t\t__le32_to_cpus(buf);\n\t\tbuf++;\n\t}\n}\n\nstatic inline void cpu_to_le32_array(u32 *buf, unsigned int words)\n{\n\twhile (words--) {\n\t\t__cpu_to_le32s(buf);\n\t\tbuf++;\n\t}\n}\n\nstatic void md4_transform(u32 *hash, u32 const *in)\n{\n\tu32 a, b, c, d;\n\n\ta = hash[0];\n\tb = hash[1];\n\tc = hash[2];\n\td = hash[3];\n\n\tROUND1(a, b, c, d, in[0], 3);\n\tROUND1(d, a, b, c, in[1], 7);\n\tROUND1(c, d, a, b, in[2], 11);\n\tROUND1(b, c, d, a, in[3], 19);\n\tROUND1(a, b, c, d, in[4], 3);\n\tROUND1(d, a, b, c, in[5], 7);\n\tROUND1(c, d, a, b, in[6], 11);\n\tROUND1(b, c, d, a, in[7], 19);\n\tROUND1(a, b, c, d, in[8], 3);\n\tROUND1(d, a, b, c, in[9], 7);\n\tROUND1(c, d, a, b, in[10], 11);\n\tROUND1(b, c, d, a, in[11], 19);\n\tROUND1(a, b, c, d, in[12], 3);\n\tROUND1(d, a, b, c, in[13], 7);\n\tROUND1(c, d, a, b, in[14], 11);\n\tROUND1(b, c, d, a, in[15], 19);\n\n\tROUND2(a, b, c, d,in[ 0], 3);\n\tROUND2(d, a, b, c, in[4], 5);\n\tROUND2(c, d, a, b, in[8], 9);\n\tROUND2(b, c, d, a, in[12], 13);\n\tROUND2(a, b, c, d, in[1], 3);\n\tROUND2(d, a, b, c, in[5], 5);\n\tROUND2(c, d, a, b, in[9], 9);\n\tROUND2(b, c, d, a, in[13], 13);\n\tROUND2(a, b, c, d, in[2], 3);\n\tROUND2(d, a, b, c, in[6], 5);\n\tROUND2(c, d, a, b, in[10], 9);\n\tROUND2(b, c, d, a, in[14], 13);\n\tROUND2(a, b, c, d, in[3], 3);\n\tROUND2(d, a, b, c, in[7], 5);\n\tROUND2(c, d, a, b, in[11], 9);\n\tROUND2(b, c, d, a, in[15], 13);\n\n\tROUND3(a, b, c, d,in[ 0], 3);\n\tROUND3(d, a, b, c, in[8], 9);\n\tROUND3(c, d, a, b, in[4], 11);\n\tROUND3(b, c, d, a, in[12], 15);\n\tROUND3(a, b, c, d, in[2], 3);\n\tROUND3(d, a, b, c, in[10], 9);\n\tROUND3(c, d, a, b, in[6], 11);\n\tROUND3(b, c, d, a, in[14], 15);\n\tROUND3(a, b, c, d, in[1], 3);\n\tROUND3(d, a, b, c, in[9], 9);\n\tROUND3(c, d, a, b, in[5], 11);\n\tROUND3(b, c, d, a, in[13], 15);\n\tROUND3(a, b, c, d, in[3], 3);\n\tROUND3(d, a, b, c, in[11], 9);\n\tROUND3(c, d, a, b, in[7], 11);\n\tROUND3(b, c, d, a, in[15], 15);\n\n\thash[0] += a;\n\thash[1] += b;\n\thash[2] += c;\n\thash[3] += d;\n}\n\nstatic inline void md4_transform_helper(struct md4_ctx *ctx)\n{\n\tle32_to_cpu_array(ctx->block, ARRAY_SIZE(ctx->block));\n\tmd4_transform(ctx->hash, ctx->block);\n}\n\nstatic int md4_init(struct shash_desc *desc)\n{\n\tstruct md4_ctx *mctx = shash_desc_ctx(desc);\n\n\tmctx->hash[0] = 0x67452301;\n\tmctx->hash[1] = 0xefcdab89;\n\tmctx->hash[2] = 0x98badcfe;\n\tmctx->hash[3] = 0x10325476;\n\tmctx->byte_count = 0;\n\n\treturn 0;\n}\n\nstatic int md4_update(struct shash_desc *desc, const u8 *data, unsigned int len)\n{\n\tstruct md4_ctx *mctx = shash_desc_ctx(desc);\n\tconst u32 avail = sizeof(mctx->block) - (mctx->byte_count & 0x3f);\n\n\tmctx->byte_count += len;\n\n\tif (avail > len) {\n\t\tmemcpy((char *)mctx->block + (sizeof(mctx->block) - avail),\n\t\t       data, len);\n\t\treturn 0;\n\t}\n\n\tmemcpy((char *)mctx->block + (sizeof(mctx->block) - avail),\n\t       data, avail);\n\n\tmd4_transform_helper(mctx);\n\tdata += avail;\n\tlen -= avail;\n\n\twhile (len >= sizeof(mctx->block)) {\n\t\tmemcpy(mctx->block, data, sizeof(mctx->block));\n\t\tmd4_transform_helper(mctx);\n\t\tdata += sizeof(mctx->block);\n\t\tlen -= sizeof(mctx->block);\n\t}\n\n\tmemcpy(mctx->block, data, len);\n\n\treturn 0;\n}\n\nstatic int md4_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct md4_ctx *mctx = shash_desc_ctx(desc);\n\tconst unsigned int offset = mctx->byte_count & 0x3f;\n\tchar *p = (char *)mctx->block + offset;\n\tint padding = 56 - (offset + 1);\n\n\t*p++ = 0x80;\n\tif (padding < 0) {\n\t\tmemset(p, 0x00, padding + sizeof (u64));\n\t\tmd4_transform_helper(mctx);\n\t\tp = (char *)mctx->block;\n\t\tpadding = 56;\n\t}\n\n\tmemset(p, 0, padding);\n\tmctx->block[14] = mctx->byte_count << 3;\n\tmctx->block[15] = mctx->byte_count >> 29;\n\tle32_to_cpu_array(mctx->block, (sizeof(mctx->block) -\n\t                  sizeof(u64)) / sizeof(u32));\n\tmd4_transform(mctx->hash, mctx->block);\n\tcpu_to_le32_array(mctx->hash, ARRAY_SIZE(mctx->hash));\n\tmemcpy(out, mctx->hash, sizeof(mctx->hash));\n\tmemset(mctx, 0, sizeof(*mctx));\n\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tMD4_DIGEST_SIZE,\n\t.init\t\t=\tmd4_init,\n\t.update\t\t=\tmd4_update,\n\t.final\t\t=\tmd4_final,\n\t.descsize\t=\tsizeof(struct md4_ctx),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"md4\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tMD4_HMAC_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init md4_mod_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit md4_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(md4_mod_init);\nmodule_exit(md4_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"MD4 Message Digest Algorithm\");\n\n", "/* \n * Cryptographic API.\n *\n * MD5 Message Digest Algorithm (RFC1321).\n *\n * Derived from cryptoapi implementation, originally based on the\n * public domain implementation written by Colin Plumb in 1993.\n *\n * Copyright (c) Cryptoapi developers.\n * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>\n * \n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option) \n * any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <crypto/md5.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/cryptohash.h>\n#include <asm/byteorder.h>\n\n/* XXX: this stuff can be optimized */\nstatic inline void le32_to_cpu_array(u32 *buf, unsigned int words)\n{\n\twhile (words--) {\n\t\t__le32_to_cpus(buf);\n\t\tbuf++;\n\t}\n}\n\nstatic inline void cpu_to_le32_array(u32 *buf, unsigned int words)\n{\n\twhile (words--) {\n\t\t__cpu_to_le32s(buf);\n\t\tbuf++;\n\t}\n}\n\nstatic inline void md5_transform_helper(struct md5_state *ctx)\n{\n\tle32_to_cpu_array(ctx->block, sizeof(ctx->block) / sizeof(u32));\n\tmd5_transform(ctx->hash, ctx->block);\n}\n\nstatic int md5_init(struct shash_desc *desc)\n{\n\tstruct md5_state *mctx = shash_desc_ctx(desc);\n\n\tmctx->hash[0] = 0x67452301;\n\tmctx->hash[1] = 0xefcdab89;\n\tmctx->hash[2] = 0x98badcfe;\n\tmctx->hash[3] = 0x10325476;\n\tmctx->byte_count = 0;\n\n\treturn 0;\n}\n\nstatic int md5_update(struct shash_desc *desc, const u8 *data, unsigned int len)\n{\n\tstruct md5_state *mctx = shash_desc_ctx(desc);\n\tconst u32 avail = sizeof(mctx->block) - (mctx->byte_count & 0x3f);\n\n\tmctx->byte_count += len;\n\n\tif (avail > len) {\n\t\tmemcpy((char *)mctx->block + (sizeof(mctx->block) - avail),\n\t\t       data, len);\n\t\treturn 0;\n\t}\n\n\tmemcpy((char *)mctx->block + (sizeof(mctx->block) - avail),\n\t       data, avail);\n\n\tmd5_transform_helper(mctx);\n\tdata += avail;\n\tlen -= avail;\n\n\twhile (len >= sizeof(mctx->block)) {\n\t\tmemcpy(mctx->block, data, sizeof(mctx->block));\n\t\tmd5_transform_helper(mctx);\n\t\tdata += sizeof(mctx->block);\n\t\tlen -= sizeof(mctx->block);\n\t}\n\n\tmemcpy(mctx->block, data, len);\n\n\treturn 0;\n}\n\nstatic int md5_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct md5_state *mctx = shash_desc_ctx(desc);\n\tconst unsigned int offset = mctx->byte_count & 0x3f;\n\tchar *p = (char *)mctx->block + offset;\n\tint padding = 56 - (offset + 1);\n\n\t*p++ = 0x80;\n\tif (padding < 0) {\n\t\tmemset(p, 0x00, padding + sizeof (u64));\n\t\tmd5_transform_helper(mctx);\n\t\tp = (char *)mctx->block;\n\t\tpadding = 56;\n\t}\n\n\tmemset(p, 0, padding);\n\tmctx->block[14] = mctx->byte_count << 3;\n\tmctx->block[15] = mctx->byte_count >> 29;\n\tle32_to_cpu_array(mctx->block, (sizeof(mctx->block) -\n\t                  sizeof(u64)) / sizeof(u32));\n\tmd5_transform(mctx->hash, mctx->block);\n\tcpu_to_le32_array(mctx->hash, sizeof(mctx->hash) / sizeof(u32));\n\tmemcpy(out, mctx->hash, sizeof(mctx->hash));\n\tmemset(mctx, 0, sizeof(*mctx));\n\n\treturn 0;\n}\n\nstatic int md5_export(struct shash_desc *desc, void *out)\n{\n\tstruct md5_state *ctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, ctx, sizeof(*ctx));\n\treturn 0;\n}\n\nstatic int md5_import(struct shash_desc *desc, const void *in)\n{\n\tstruct md5_state *ctx = shash_desc_ctx(desc);\n\n\tmemcpy(ctx, in, sizeof(*ctx));\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tMD5_DIGEST_SIZE,\n\t.init\t\t=\tmd5_init,\n\t.update\t\t=\tmd5_update,\n\t.final\t\t=\tmd5_final,\n\t.export\t\t=\tmd5_export,\n\t.import\t\t=\tmd5_import,\n\t.descsize\t=\tsizeof(struct md5_state),\n\t.statesize\t=\tsizeof(struct md5_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"md5\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tMD5_HMAC_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init md5_mod_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit md5_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(md5_mod_init);\nmodule_exit(md5_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"MD5 Message Digest Algorithm\");\n", "/*\n * Cryptographic API\n *\n * Michael MIC (IEEE 802.11i/TKIP) keyed digest\n *\n * Copyright (c) 2004 Jouni Malinen <j@w1.fi>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License version 2 as\n * published by the Free Software Foundation.\n */\n#include <crypto/internal/hash.h>\n#include <asm/byteorder.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/string.h>\n#include <linux/types.h>\n\n\nstruct michael_mic_ctx {\n\tu32 l, r;\n};\n\nstruct michael_mic_desc_ctx {\n\tu8 pending[4];\n\tsize_t pending_len;\n\n\tu32 l, r;\n};\n\nstatic inline u32 xswap(u32 val)\n{\n\treturn ((val & 0x00ff00ff) << 8) | ((val & 0xff00ff00) >> 8);\n}\n\n\n#define michael_block(l, r)\t\\\ndo {\t\t\t\t\\\n\tr ^= rol32(l, 17);\t\\\n\tl += r;\t\t\t\\\n\tr ^= xswap(l);\t\t\\\n\tl += r;\t\t\t\\\n\tr ^= rol32(l, 3);\t\\\n\tl += r;\t\t\t\\\n\tr ^= ror32(l, 2);\t\\\n\tl += r;\t\t\t\\\n} while (0)\n\n\nstatic int michael_init(struct shash_desc *desc)\n{\n\tstruct michael_mic_desc_ctx *mctx = shash_desc_ctx(desc);\n\tstruct michael_mic_ctx *ctx = crypto_shash_ctx(desc->tfm);\n\tmctx->pending_len = 0;\n\tmctx->l = ctx->l;\n\tmctx->r = ctx->r;\n\n\treturn 0;\n}\n\n\nstatic int michael_update(struct shash_desc *desc, const u8 *data,\n\t\t\t   unsigned int len)\n{\n\tstruct michael_mic_desc_ctx *mctx = shash_desc_ctx(desc);\n\tconst __le32 *src;\n\n\tif (mctx->pending_len) {\n\t\tint flen = 4 - mctx->pending_len;\n\t\tif (flen > len)\n\t\t\tflen = len;\n\t\tmemcpy(&mctx->pending[mctx->pending_len], data, flen);\n\t\tmctx->pending_len += flen;\n\t\tdata += flen;\n\t\tlen -= flen;\n\n\t\tif (mctx->pending_len < 4)\n\t\t\treturn 0;\n\n\t\tsrc = (const __le32 *)mctx->pending;\n\t\tmctx->l ^= le32_to_cpup(src);\n\t\tmichael_block(mctx->l, mctx->r);\n\t\tmctx->pending_len = 0;\n\t}\n\n\tsrc = (const __le32 *)data;\n\n\twhile (len >= 4) {\n\t\tmctx->l ^= le32_to_cpup(src++);\n\t\tmichael_block(mctx->l, mctx->r);\n\t\tlen -= 4;\n\t}\n\n\tif (len > 0) {\n\t\tmctx->pending_len = len;\n\t\tmemcpy(mctx->pending, src, len);\n\t}\n\n\treturn 0;\n}\n\n\nstatic int michael_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct michael_mic_desc_ctx *mctx = shash_desc_ctx(desc);\n\tu8 *data = mctx->pending;\n\t__le32 *dst = (__le32 *)out;\n\n\t/* Last block and padding (0x5a, 4..7 x 0) */\n\tswitch (mctx->pending_len) {\n\tcase 0:\n\t\tmctx->l ^= 0x5a;\n\t\tbreak;\n\tcase 1:\n\t\tmctx->l ^= data[0] | 0x5a00;\n\t\tbreak;\n\tcase 2:\n\t\tmctx->l ^= data[0] | (data[1] << 8) | 0x5a0000;\n\t\tbreak;\n\tcase 3:\n\t\tmctx->l ^= data[0] | (data[1] << 8) | (data[2] << 16) |\n\t\t\t0x5a000000;\n\t\tbreak;\n\t}\n\tmichael_block(mctx->l, mctx->r);\n\t/* l ^= 0; */\n\tmichael_block(mctx->l, mctx->r);\n\n\tdst[0] = cpu_to_le32(mctx->l);\n\tdst[1] = cpu_to_le32(mctx->r);\n\n\treturn 0;\n}\n\n\nstatic int michael_setkey(struct crypto_shash *tfm, const u8 *key,\n\t\t\t  unsigned int keylen)\n{\n\tstruct michael_mic_ctx *mctx = crypto_shash_ctx(tfm);\n\n\tconst __le32 *data = (const __le32 *)key;\n\n\tif (keylen != 8) {\n\t\tcrypto_shash_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);\n\t\treturn -EINVAL;\n\t}\n\n\tmctx->l = le32_to_cpu(data[0]);\n\tmctx->r = le32_to_cpu(data[1]);\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t\t=\t8,\n\t.setkey\t\t\t=\tmichael_setkey,\n\t.init\t\t\t=\tmichael_init,\n\t.update\t\t\t=\tmichael_update,\n\t.final\t\t\t=\tmichael_final,\n\t.descsize\t\t=\tsizeof(struct michael_mic_desc_ctx),\n\t.base\t\t\t=\t{\n\t\t.cra_name\t\t=\t\"michael_mic\",\n\t\t.cra_blocksize\t\t=\t8,\n\t\t.cra_alignmask\t\t=\t3,\n\t\t.cra_ctxsize\t\t=\tsizeof(struct michael_mic_ctx),\n\t\t.cra_module\t\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init michael_mic_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\n\nstatic void __exit michael_mic_exit(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\n\nmodule_init(michael_mic_init);\nmodule_exit(michael_mic_exit);\n\nMODULE_LICENSE(\"GPL v2\");\nMODULE_DESCRIPTION(\"Michael MIC\");\nMODULE_AUTHOR(\"Jouni Malinen <j@w1.fi>\");\n", "/*\n * Cryptographic API.\n *\n * RIPEMD-128 - RACE Integrity Primitives Evaluation Message Digest.\n *\n * Based on the reference implementation by Antoon Bosselaers, ESAT-COSIC\n *\n * Copyright (c) 2008 Adrian-Ken Rueegsegger <ken@codelabs.ch>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/types.h>\n#include <asm/byteorder.h>\n\n#include \"ripemd.h\"\n\nstruct rmd128_ctx {\n\tu64 byte_count;\n\tu32 state[4];\n\t__le32 buffer[16];\n};\n\n#define K1  RMD_K1\n#define K2  RMD_K2\n#define K3  RMD_K3\n#define K4  RMD_K4\n#define KK1 RMD_K6\n#define KK2 RMD_K7\n#define KK3 RMD_K8\n#define KK4 RMD_K1\n\n#define F1(x, y, z) (x ^ y ^ z)\t\t/* XOR */\n#define F2(x, y, z) (z ^ (x & (y ^ z)))\t/* x ? y : z */\n#define F3(x, y, z) ((x | ~y) ^ z)\n#define F4(x, y, z) (y ^ (z & (x ^ y)))\t/* z ? x : y */\n\n#define ROUND(a, b, c, d, f, k, x, s)  { \\\n\t(a) += f((b), (c), (d)) + le32_to_cpup(&(x)) + (k);\t\\\n\t(a) = rol32((a), (s)); \\\n}\n\nstatic void rmd128_transform(u32 *state, const __le32 *in)\n{\n\tu32 aa, bb, cc, dd, aaa, bbb, ccc, ddd;\n\n\t/* Initialize left lane */\n\taa = state[0];\n\tbb = state[1];\n\tcc = state[2];\n\tdd = state[3];\n\n\t/* Initialize right lane */\n\taaa = state[0];\n\tbbb = state[1];\n\tccc = state[2];\n\tddd = state[3];\n\n\t/* round 1: left lane */\n\tROUND(aa, bb, cc, dd, F1, K1, in[0],  11);\n\tROUND(dd, aa, bb, cc, F1, K1, in[1],  14);\n\tROUND(cc, dd, aa, bb, F1, K1, in[2],  15);\n\tROUND(bb, cc, dd, aa, F1, K1, in[3],  12);\n\tROUND(aa, bb, cc, dd, F1, K1, in[4],   5);\n\tROUND(dd, aa, bb, cc, F1, K1, in[5],   8);\n\tROUND(cc, dd, aa, bb, F1, K1, in[6],   7);\n\tROUND(bb, cc, dd, aa, F1, K1, in[7],   9);\n\tROUND(aa, bb, cc, dd, F1, K1, in[8],  11);\n\tROUND(dd, aa, bb, cc, F1, K1, in[9],  13);\n\tROUND(cc, dd, aa, bb, F1, K1, in[10], 14);\n\tROUND(bb, cc, dd, aa, F1, K1, in[11], 15);\n\tROUND(aa, bb, cc, dd, F1, K1, in[12],  6);\n\tROUND(dd, aa, bb, cc, F1, K1, in[13],  7);\n\tROUND(cc, dd, aa, bb, F1, K1, in[14],  9);\n\tROUND(bb, cc, dd, aa, F1, K1, in[15],  8);\n\n\t/* round 2: left lane */\n\tROUND(aa, bb, cc, dd, F2, K2, in[7],   7);\n\tROUND(dd, aa, bb, cc, F2, K2, in[4],   6);\n\tROUND(cc, dd, aa, bb, F2, K2, in[13],  8);\n\tROUND(bb, cc, dd, aa, F2, K2, in[1],  13);\n\tROUND(aa, bb, cc, dd, F2, K2, in[10], 11);\n\tROUND(dd, aa, bb, cc, F2, K2, in[6],   9);\n\tROUND(cc, dd, aa, bb, F2, K2, in[15],  7);\n\tROUND(bb, cc, dd, aa, F2, K2, in[3],  15);\n\tROUND(aa, bb, cc, dd, F2, K2, in[12],  7);\n\tROUND(dd, aa, bb, cc, F2, K2, in[0],  12);\n\tROUND(cc, dd, aa, bb, F2, K2, in[9],  15);\n\tROUND(bb, cc, dd, aa, F2, K2, in[5],   9);\n\tROUND(aa, bb, cc, dd, F2, K2, in[2],  11);\n\tROUND(dd, aa, bb, cc, F2, K2, in[14],  7);\n\tROUND(cc, dd, aa, bb, F2, K2, in[11], 13);\n\tROUND(bb, cc, dd, aa, F2, K2, in[8],  12);\n\n\t/* round 3: left lane */\n\tROUND(aa, bb, cc, dd, F3, K3, in[3],  11);\n\tROUND(dd, aa, bb, cc, F3, K3, in[10], 13);\n\tROUND(cc, dd, aa, bb, F3, K3, in[14],  6);\n\tROUND(bb, cc, dd, aa, F3, K3, in[4],   7);\n\tROUND(aa, bb, cc, dd, F3, K3, in[9],  14);\n\tROUND(dd, aa, bb, cc, F3, K3, in[15],  9);\n\tROUND(cc, dd, aa, bb, F3, K3, in[8],  13);\n\tROUND(bb, cc, dd, aa, F3, K3, in[1],  15);\n\tROUND(aa, bb, cc, dd, F3, K3, in[2],  14);\n\tROUND(dd, aa, bb, cc, F3, K3, in[7],   8);\n\tROUND(cc, dd, aa, bb, F3, K3, in[0],  13);\n\tROUND(bb, cc, dd, aa, F3, K3, in[6],   6);\n\tROUND(aa, bb, cc, dd, F3, K3, in[13],  5);\n\tROUND(dd, aa, bb, cc, F3, K3, in[11], 12);\n\tROUND(cc, dd, aa, bb, F3, K3, in[5],   7);\n\tROUND(bb, cc, dd, aa, F3, K3, in[12],  5);\n\n\t/* round 4: left lane */\n\tROUND(aa, bb, cc, dd, F4, K4, in[1],  11);\n\tROUND(dd, aa, bb, cc, F4, K4, in[9],  12);\n\tROUND(cc, dd, aa, bb, F4, K4, in[11], 14);\n\tROUND(bb, cc, dd, aa, F4, K4, in[10], 15);\n\tROUND(aa, bb, cc, dd, F4, K4, in[0],  14);\n\tROUND(dd, aa, bb, cc, F4, K4, in[8],  15);\n\tROUND(cc, dd, aa, bb, F4, K4, in[12],  9);\n\tROUND(bb, cc, dd, aa, F4, K4, in[4],   8);\n\tROUND(aa, bb, cc, dd, F4, K4, in[13],  9);\n\tROUND(dd, aa, bb, cc, F4, K4, in[3],  14);\n\tROUND(cc, dd, aa, bb, F4, K4, in[7],   5);\n\tROUND(bb, cc, dd, aa, F4, K4, in[15],  6);\n\tROUND(aa, bb, cc, dd, F4, K4, in[14],  8);\n\tROUND(dd, aa, bb, cc, F4, K4, in[5],   6);\n\tROUND(cc, dd, aa, bb, F4, K4, in[6],   5);\n\tROUND(bb, cc, dd, aa, F4, K4, in[2],  12);\n\n\t/* round 1: right lane */\n\tROUND(aaa, bbb, ccc, ddd, F4, KK1, in[5],   8);\n\tROUND(ddd, aaa, bbb, ccc, F4, KK1, in[14],  9);\n\tROUND(ccc, ddd, aaa, bbb, F4, KK1, in[7],   9);\n\tROUND(bbb, ccc, ddd, aaa, F4, KK1, in[0],  11);\n\tROUND(aaa, bbb, ccc, ddd, F4, KK1, in[9],  13);\n\tROUND(ddd, aaa, bbb, ccc, F4, KK1, in[2],  15);\n\tROUND(ccc, ddd, aaa, bbb, F4, KK1, in[11], 15);\n\tROUND(bbb, ccc, ddd, aaa, F4, KK1, in[4],   5);\n\tROUND(aaa, bbb, ccc, ddd, F4, KK1, in[13],  7);\n\tROUND(ddd, aaa, bbb, ccc, F4, KK1, in[6],   7);\n\tROUND(ccc, ddd, aaa, bbb, F4, KK1, in[15],  8);\n\tROUND(bbb, ccc, ddd, aaa, F4, KK1, in[8],  11);\n\tROUND(aaa, bbb, ccc, ddd, F4, KK1, in[1],  14);\n\tROUND(ddd, aaa, bbb, ccc, F4, KK1, in[10], 14);\n\tROUND(ccc, ddd, aaa, bbb, F4, KK1, in[3],  12);\n\tROUND(bbb, ccc, ddd, aaa, F4, KK1, in[12],  6);\n\n\t/* round 2: right lane */\n\tROUND(aaa, bbb, ccc, ddd, F3, KK2, in[6],   9);\n\tROUND(ddd, aaa, bbb, ccc, F3, KK2, in[11], 13);\n\tROUND(ccc, ddd, aaa, bbb, F3, KK2, in[3],  15);\n\tROUND(bbb, ccc, ddd, aaa, F3, KK2, in[7],   7);\n\tROUND(aaa, bbb, ccc, ddd, F3, KK2, in[0],  12);\n\tROUND(ddd, aaa, bbb, ccc, F3, KK2, in[13],  8);\n\tROUND(ccc, ddd, aaa, bbb, F3, KK2, in[5],   9);\n\tROUND(bbb, ccc, ddd, aaa, F3, KK2, in[10], 11);\n\tROUND(aaa, bbb, ccc, ddd, F3, KK2, in[14],  7);\n\tROUND(ddd, aaa, bbb, ccc, F3, KK2, in[15],  7);\n\tROUND(ccc, ddd, aaa, bbb, F3, KK2, in[8],  12);\n\tROUND(bbb, ccc, ddd, aaa, F3, KK2, in[12],  7);\n\tROUND(aaa, bbb, ccc, ddd, F3, KK2, in[4],   6);\n\tROUND(ddd, aaa, bbb, ccc, F3, KK2, in[9],  15);\n\tROUND(ccc, ddd, aaa, bbb, F3, KK2, in[1],  13);\n\tROUND(bbb, ccc, ddd, aaa, F3, KK2, in[2],  11);\n\n\t/* round 3: right lane */\n\tROUND(aaa, bbb, ccc, ddd, F2, KK3, in[15],  9);\n\tROUND(ddd, aaa, bbb, ccc, F2, KK3, in[5],   7);\n\tROUND(ccc, ddd, aaa, bbb, F2, KK3, in[1],  15);\n\tROUND(bbb, ccc, ddd, aaa, F2, KK3, in[3],  11);\n\tROUND(aaa, bbb, ccc, ddd, F2, KK3, in[7],   8);\n\tROUND(ddd, aaa, bbb, ccc, F2, KK3, in[14],  6);\n\tROUND(ccc, ddd, aaa, bbb, F2, KK3, in[6],   6);\n\tROUND(bbb, ccc, ddd, aaa, F2, KK3, in[9],  14);\n\tROUND(aaa, bbb, ccc, ddd, F2, KK3, in[11], 12);\n\tROUND(ddd, aaa, bbb, ccc, F2, KK3, in[8],  13);\n\tROUND(ccc, ddd, aaa, bbb, F2, KK3, in[12],  5);\n\tROUND(bbb, ccc, ddd, aaa, F2, KK3, in[2],  14);\n\tROUND(aaa, bbb, ccc, ddd, F2, KK3, in[10], 13);\n\tROUND(ddd, aaa, bbb, ccc, F2, KK3, in[0],  13);\n\tROUND(ccc, ddd, aaa, bbb, F2, KK3, in[4],   7);\n\tROUND(bbb, ccc, ddd, aaa, F2, KK3, in[13],  5);\n\n\t/* round 4: right lane */\n\tROUND(aaa, bbb, ccc, ddd, F1, KK4, in[8],  15);\n\tROUND(ddd, aaa, bbb, ccc, F1, KK4, in[6],   5);\n\tROUND(ccc, ddd, aaa, bbb, F1, KK4, in[4],   8);\n\tROUND(bbb, ccc, ddd, aaa, F1, KK4, in[1],  11);\n\tROUND(aaa, bbb, ccc, ddd, F1, KK4, in[3],  14);\n\tROUND(ddd, aaa, bbb, ccc, F1, KK4, in[11], 14);\n\tROUND(ccc, ddd, aaa, bbb, F1, KK4, in[15],  6);\n\tROUND(bbb, ccc, ddd, aaa, F1, KK4, in[0],  14);\n\tROUND(aaa, bbb, ccc, ddd, F1, KK4, in[5],   6);\n\tROUND(ddd, aaa, bbb, ccc, F1, KK4, in[12],  9);\n\tROUND(ccc, ddd, aaa, bbb, F1, KK4, in[2],  12);\n\tROUND(bbb, ccc, ddd, aaa, F1, KK4, in[13],  9);\n\tROUND(aaa, bbb, ccc, ddd, F1, KK4, in[9],  12);\n\tROUND(ddd, aaa, bbb, ccc, F1, KK4, in[7],   5);\n\tROUND(ccc, ddd, aaa, bbb, F1, KK4, in[10], 15);\n\tROUND(bbb, ccc, ddd, aaa, F1, KK4, in[14],  8);\n\n\t/* combine results */\n\tddd += cc + state[1];\t\t/* final result for state[0] */\n\tstate[1] = state[2] + dd + aaa;\n\tstate[2] = state[3] + aa + bbb;\n\tstate[3] = state[0] + bb + ccc;\n\tstate[0] = ddd;\n\n\treturn;\n}\n\nstatic int rmd128_init(struct shash_desc *desc)\n{\n\tstruct rmd128_ctx *rctx = shash_desc_ctx(desc);\n\n\trctx->byte_count = 0;\n\n\trctx->state[0] = RMD_H0;\n\trctx->state[1] = RMD_H1;\n\trctx->state[2] = RMD_H2;\n\trctx->state[3] = RMD_H3;\n\n\tmemset(rctx->buffer, 0, sizeof(rctx->buffer));\n\n\treturn 0;\n}\n\nstatic int rmd128_update(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int len)\n{\n\tstruct rmd128_ctx *rctx = shash_desc_ctx(desc);\n\tconst u32 avail = sizeof(rctx->buffer) - (rctx->byte_count & 0x3f);\n\n\trctx->byte_count += len;\n\n\t/* Enough space in buffer? If so copy and we're done */\n\tif (avail > len) {\n\t\tmemcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),\n\t\t       data, len);\n\t\tgoto out;\n\t}\n\n\tmemcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),\n\t       data, avail);\n\n\trmd128_transform(rctx->state, rctx->buffer);\n\tdata += avail;\n\tlen -= avail;\n\n\twhile (len >= sizeof(rctx->buffer)) {\n\t\tmemcpy(rctx->buffer, data, sizeof(rctx->buffer));\n\t\trmd128_transform(rctx->state, rctx->buffer);\n\t\tdata += sizeof(rctx->buffer);\n\t\tlen -= sizeof(rctx->buffer);\n\t}\n\n\tmemcpy(rctx->buffer, data, len);\n\nout:\n\treturn 0;\n}\n\n/* Add padding and return the message digest. */\nstatic int rmd128_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct rmd128_ctx *rctx = shash_desc_ctx(desc);\n\tu32 i, index, padlen;\n\t__le64 bits;\n\t__le32 *dst = (__le32 *)out;\n\tstatic const u8 padding[64] = { 0x80, };\n\n\tbits = cpu_to_le64(rctx->byte_count << 3);\n\n\t/* Pad out to 56 mod 64 */\n\tindex = rctx->byte_count & 0x3f;\n\tpadlen = (index < 56) ? (56 - index) : ((64+56) - index);\n\trmd128_update(desc, padding, padlen);\n\n\t/* Append length */\n\trmd128_update(desc, (const u8 *)&bits, sizeof(bits));\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 4; i++)\n\t\tdst[i] = cpu_to_le32p(&rctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(rctx, 0, sizeof(*rctx));\n\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tRMD128_DIGEST_SIZE,\n\t.init\t\t=\trmd128_init,\n\t.update\t\t=\trmd128_update,\n\t.final\t\t=\trmd128_final,\n\t.descsize\t=\tsizeof(struct rmd128_ctx),\n\t.base\t\t=\t{\n\t\t.cra_name\t =\t\"rmd128\",\n\t\t.cra_flags\t =\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t =\tRMD128_BLOCK_SIZE,\n\t\t.cra_module\t =\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init rmd128_mod_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit rmd128_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(rmd128_mod_init);\nmodule_exit(rmd128_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Adrian-Ken Rueegsegger <ken@codelabs.ch>\");\nMODULE_DESCRIPTION(\"RIPEMD-128 Message Digest\");\n", "/*\n * Cryptographic API.\n *\n * RIPEMD-160 - RACE Integrity Primitives Evaluation Message Digest.\n *\n * Based on the reference implementation by Antoon Bosselaers, ESAT-COSIC\n *\n * Copyright (c) 2008 Adrian-Ken Rueegsegger <ken@codelabs.ch>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/types.h>\n#include <asm/byteorder.h>\n\n#include \"ripemd.h\"\n\nstruct rmd160_ctx {\n\tu64 byte_count;\n\tu32 state[5];\n\t__le32 buffer[16];\n};\n\n#define K1  RMD_K1\n#define K2  RMD_K2\n#define K3  RMD_K3\n#define K4  RMD_K4\n#define K5  RMD_K5\n#define KK1 RMD_K6\n#define KK2 RMD_K7\n#define KK3 RMD_K8\n#define KK4 RMD_K9\n#define KK5 RMD_K1\n\n#define F1(x, y, z) (x ^ y ^ z)\t\t/* XOR */\n#define F2(x, y, z) (z ^ (x & (y ^ z)))\t/* x ? y : z */\n#define F3(x, y, z) ((x | ~y) ^ z)\n#define F4(x, y, z) (y ^ (z & (x ^ y)))\t/* z ? x : y */\n#define F5(x, y, z) (x ^ (y | ~z))\n\n#define ROUND(a, b, c, d, e, f, k, x, s)  { \\\n\t(a) += f((b), (c), (d)) + le32_to_cpup(&(x)) + (k); \\\n\t(a) = rol32((a), (s)) + (e); \\\n\t(c) = rol32((c), 10); \\\n}\n\nstatic void rmd160_transform(u32 *state, const __le32 *in)\n{\n\tu32 aa, bb, cc, dd, ee, aaa, bbb, ccc, ddd, eee;\n\n\t/* Initialize left lane */\n\taa = state[0];\n\tbb = state[1];\n\tcc = state[2];\n\tdd = state[3];\n\tee = state[4];\n\n\t/* Initialize right lane */\n\taaa = state[0];\n\tbbb = state[1];\n\tccc = state[2];\n\tddd = state[3];\n\teee = state[4];\n\n\t/* round 1: left lane */\n\tROUND(aa, bb, cc, dd, ee, F1, K1, in[0],  11);\n\tROUND(ee, aa, bb, cc, dd, F1, K1, in[1],  14);\n\tROUND(dd, ee, aa, bb, cc, F1, K1, in[2],  15);\n\tROUND(cc, dd, ee, aa, bb, F1, K1, in[3],  12);\n\tROUND(bb, cc, dd, ee, aa, F1, K1, in[4],   5);\n\tROUND(aa, bb, cc, dd, ee, F1, K1, in[5],   8);\n\tROUND(ee, aa, bb, cc, dd, F1, K1, in[6],   7);\n\tROUND(dd, ee, aa, bb, cc, F1, K1, in[7],   9);\n\tROUND(cc, dd, ee, aa, bb, F1, K1, in[8],  11);\n\tROUND(bb, cc, dd, ee, aa, F1, K1, in[9],  13);\n\tROUND(aa, bb, cc, dd, ee, F1, K1, in[10], 14);\n\tROUND(ee, aa, bb, cc, dd, F1, K1, in[11], 15);\n\tROUND(dd, ee, aa, bb, cc, F1, K1, in[12],  6);\n\tROUND(cc, dd, ee, aa, bb, F1, K1, in[13],  7);\n\tROUND(bb, cc, dd, ee, aa, F1, K1, in[14],  9);\n\tROUND(aa, bb, cc, dd, ee, F1, K1, in[15],  8);\n\n\t/* round 2: left lane\" */\n\tROUND(ee, aa, bb, cc, dd, F2, K2, in[7],   7);\n\tROUND(dd, ee, aa, bb, cc, F2, K2, in[4],   6);\n\tROUND(cc, dd, ee, aa, bb, F2, K2, in[13],  8);\n\tROUND(bb, cc, dd, ee, aa, F2, K2, in[1],  13);\n\tROUND(aa, bb, cc, dd, ee, F2, K2, in[10], 11);\n\tROUND(ee, aa, bb, cc, dd, F2, K2, in[6],   9);\n\tROUND(dd, ee, aa, bb, cc, F2, K2, in[15],  7);\n\tROUND(cc, dd, ee, aa, bb, F2, K2, in[3],  15);\n\tROUND(bb, cc, dd, ee, aa, F2, K2, in[12],  7);\n\tROUND(aa, bb, cc, dd, ee, F2, K2, in[0],  12);\n\tROUND(ee, aa, bb, cc, dd, F2, K2, in[9],  15);\n\tROUND(dd, ee, aa, bb, cc, F2, K2, in[5],   9);\n\tROUND(cc, dd, ee, aa, bb, F2, K2, in[2],  11);\n\tROUND(bb, cc, dd, ee, aa, F2, K2, in[14],  7);\n\tROUND(aa, bb, cc, dd, ee, F2, K2, in[11], 13);\n\tROUND(ee, aa, bb, cc, dd, F2, K2, in[8],  12);\n\n\t/* round 3: left lane\" */\n\tROUND(dd, ee, aa, bb, cc, F3, K3, in[3],  11);\n\tROUND(cc, dd, ee, aa, bb, F3, K3, in[10], 13);\n\tROUND(bb, cc, dd, ee, aa, F3, K3, in[14],  6);\n\tROUND(aa, bb, cc, dd, ee, F3, K3, in[4],   7);\n\tROUND(ee, aa, bb, cc, dd, F3, K3, in[9],  14);\n\tROUND(dd, ee, aa, bb, cc, F3, K3, in[15],  9);\n\tROUND(cc, dd, ee, aa, bb, F3, K3, in[8],  13);\n\tROUND(bb, cc, dd, ee, aa, F3, K3, in[1],  15);\n\tROUND(aa, bb, cc, dd, ee, F3, K3, in[2],  14);\n\tROUND(ee, aa, bb, cc, dd, F3, K3, in[7],   8);\n\tROUND(dd, ee, aa, bb, cc, F3, K3, in[0],  13);\n\tROUND(cc, dd, ee, aa, bb, F3, K3, in[6],   6);\n\tROUND(bb, cc, dd, ee, aa, F3, K3, in[13],  5);\n\tROUND(aa, bb, cc, dd, ee, F3, K3, in[11], 12);\n\tROUND(ee, aa, bb, cc, dd, F3, K3, in[5],   7);\n\tROUND(dd, ee, aa, bb, cc, F3, K3, in[12],  5);\n\n\t/* round 4: left lane\" */\n\tROUND(cc, dd, ee, aa, bb, F4, K4, in[1],  11);\n\tROUND(bb, cc, dd, ee, aa, F4, K4, in[9],  12);\n\tROUND(aa, bb, cc, dd, ee, F4, K4, in[11], 14);\n\tROUND(ee, aa, bb, cc, dd, F4, K4, in[10], 15);\n\tROUND(dd, ee, aa, bb, cc, F4, K4, in[0],  14);\n\tROUND(cc, dd, ee, aa, bb, F4, K4, in[8],  15);\n\tROUND(bb, cc, dd, ee, aa, F4, K4, in[12],  9);\n\tROUND(aa, bb, cc, dd, ee, F4, K4, in[4],   8);\n\tROUND(ee, aa, bb, cc, dd, F4, K4, in[13],  9);\n\tROUND(dd, ee, aa, bb, cc, F4, K4, in[3],  14);\n\tROUND(cc, dd, ee, aa, bb, F4, K4, in[7],   5);\n\tROUND(bb, cc, dd, ee, aa, F4, K4, in[15],  6);\n\tROUND(aa, bb, cc, dd, ee, F4, K4, in[14],  8);\n\tROUND(ee, aa, bb, cc, dd, F4, K4, in[5],   6);\n\tROUND(dd, ee, aa, bb, cc, F4, K4, in[6],   5);\n\tROUND(cc, dd, ee, aa, bb, F4, K4, in[2],  12);\n\n\t/* round 5: left lane\" */\n\tROUND(bb, cc, dd, ee, aa, F5, K5, in[4],   9);\n\tROUND(aa, bb, cc, dd, ee, F5, K5, in[0],  15);\n\tROUND(ee, aa, bb, cc, dd, F5, K5, in[5],   5);\n\tROUND(dd, ee, aa, bb, cc, F5, K5, in[9],  11);\n\tROUND(cc, dd, ee, aa, bb, F5, K5, in[7],   6);\n\tROUND(bb, cc, dd, ee, aa, F5, K5, in[12],  8);\n\tROUND(aa, bb, cc, dd, ee, F5, K5, in[2],  13);\n\tROUND(ee, aa, bb, cc, dd, F5, K5, in[10], 12);\n\tROUND(dd, ee, aa, bb, cc, F5, K5, in[14],  5);\n\tROUND(cc, dd, ee, aa, bb, F5, K5, in[1],  12);\n\tROUND(bb, cc, dd, ee, aa, F5, K5, in[3],  13);\n\tROUND(aa, bb, cc, dd, ee, F5, K5, in[8],  14);\n\tROUND(ee, aa, bb, cc, dd, F5, K5, in[11], 11);\n\tROUND(dd, ee, aa, bb, cc, F5, K5, in[6],   8);\n\tROUND(cc, dd, ee, aa, bb, F5, K5, in[15],  5);\n\tROUND(bb, cc, dd, ee, aa, F5, K5, in[13],  6);\n\n\t/* round 1: right lane */\n\tROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[5],   8);\n\tROUND(eee, aaa, bbb, ccc, ddd, F5, KK1, in[14],  9);\n\tROUND(ddd, eee, aaa, bbb, ccc, F5, KK1, in[7],   9);\n\tROUND(ccc, ddd, eee, aaa, bbb, F5, KK1, in[0],  11);\n\tROUND(bbb, ccc, ddd, eee, aaa, F5, KK1, in[9],  13);\n\tROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[2],  15);\n\tROUND(eee, aaa, bbb, ccc, ddd, F5, KK1, in[11], 15);\n\tROUND(ddd, eee, aaa, bbb, ccc, F5, KK1, in[4],   5);\n\tROUND(ccc, ddd, eee, aaa, bbb, F5, KK1, in[13],  7);\n\tROUND(bbb, ccc, ddd, eee, aaa, F5, KK1, in[6],   7);\n\tROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[15],  8);\n\tROUND(eee, aaa, bbb, ccc, ddd, F5, KK1, in[8],  11);\n\tROUND(ddd, eee, aaa, bbb, ccc, F5, KK1, in[1],  14);\n\tROUND(ccc, ddd, eee, aaa, bbb, F5, KK1, in[10], 14);\n\tROUND(bbb, ccc, ddd, eee, aaa, F5, KK1, in[3],  12);\n\tROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[12],  6);\n\n\t/* round 2: right lane */\n\tROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[6],   9);\n\tROUND(ddd, eee, aaa, bbb, ccc, F4, KK2, in[11], 13);\n\tROUND(ccc, ddd, eee, aaa, bbb, F4, KK2, in[3],  15);\n\tROUND(bbb, ccc, ddd, eee, aaa, F4, KK2, in[7],   7);\n\tROUND(aaa, bbb, ccc, ddd, eee, F4, KK2, in[0],  12);\n\tROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[13],  8);\n\tROUND(ddd, eee, aaa, bbb, ccc, F4, KK2, in[5],   9);\n\tROUND(ccc, ddd, eee, aaa, bbb, F4, KK2, in[10], 11);\n\tROUND(bbb, ccc, ddd, eee, aaa, F4, KK2, in[14],  7);\n\tROUND(aaa, bbb, ccc, ddd, eee, F4, KK2, in[15],  7);\n\tROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[8],  12);\n\tROUND(ddd, eee, aaa, bbb, ccc, F4, KK2, in[12],  7);\n\tROUND(ccc, ddd, eee, aaa, bbb, F4, KK2, in[4],   6);\n\tROUND(bbb, ccc, ddd, eee, aaa, F4, KK2, in[9],  15);\n\tROUND(aaa, bbb, ccc, ddd, eee, F4, KK2, in[1],  13);\n\tROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[2],  11);\n\n\t/* round 3: right lane */\n\tROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[15],  9);\n\tROUND(ccc, ddd, eee, aaa, bbb, F3, KK3, in[5],   7);\n\tROUND(bbb, ccc, ddd, eee, aaa, F3, KK3, in[1],  15);\n\tROUND(aaa, bbb, ccc, ddd, eee, F3, KK3, in[3],  11);\n\tROUND(eee, aaa, bbb, ccc, ddd, F3, KK3, in[7],   8);\n\tROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[14],  6);\n\tROUND(ccc, ddd, eee, aaa, bbb, F3, KK3, in[6],   6);\n\tROUND(bbb, ccc, ddd, eee, aaa, F3, KK3, in[9],  14);\n\tROUND(aaa, bbb, ccc, ddd, eee, F3, KK3, in[11], 12);\n\tROUND(eee, aaa, bbb, ccc, ddd, F3, KK3, in[8],  13);\n\tROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[12],  5);\n\tROUND(ccc, ddd, eee, aaa, bbb, F3, KK3, in[2],  14);\n\tROUND(bbb, ccc, ddd, eee, aaa, F3, KK3, in[10], 13);\n\tROUND(aaa, bbb, ccc, ddd, eee, F3, KK3, in[0],  13);\n\tROUND(eee, aaa, bbb, ccc, ddd, F3, KK3, in[4],   7);\n\tROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[13],  5);\n\n\t/* round 4: right lane */\n\tROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[8],  15);\n\tROUND(bbb, ccc, ddd, eee, aaa, F2, KK4, in[6],   5);\n\tROUND(aaa, bbb, ccc, ddd, eee, F2, KK4, in[4],   8);\n\tROUND(eee, aaa, bbb, ccc, ddd, F2, KK4, in[1],  11);\n\tROUND(ddd, eee, aaa, bbb, ccc, F2, KK4, in[3],  14);\n\tROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[11], 14);\n\tROUND(bbb, ccc, ddd, eee, aaa, F2, KK4, in[15],  6);\n\tROUND(aaa, bbb, ccc, ddd, eee, F2, KK4, in[0],  14);\n\tROUND(eee, aaa, bbb, ccc, ddd, F2, KK4, in[5],   6);\n\tROUND(ddd, eee, aaa, bbb, ccc, F2, KK4, in[12],  9);\n\tROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[2],  12);\n\tROUND(bbb, ccc, ddd, eee, aaa, F2, KK4, in[13],  9);\n\tROUND(aaa, bbb, ccc, ddd, eee, F2, KK4, in[9],  12);\n\tROUND(eee, aaa, bbb, ccc, ddd, F2, KK4, in[7],   5);\n\tROUND(ddd, eee, aaa, bbb, ccc, F2, KK4, in[10], 15);\n\tROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[14],  8);\n\n\t/* round 5: right lane */\n\tROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[12],  8);\n\tROUND(aaa, bbb, ccc, ddd, eee, F1, KK5, in[15],  5);\n\tROUND(eee, aaa, bbb, ccc, ddd, F1, KK5, in[10], 12);\n\tROUND(ddd, eee, aaa, bbb, ccc, F1, KK5, in[4],   9);\n\tROUND(ccc, ddd, eee, aaa, bbb, F1, KK5, in[1],  12);\n\tROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[5],   5);\n\tROUND(aaa, bbb, ccc, ddd, eee, F1, KK5, in[8],  14);\n\tROUND(eee, aaa, bbb, ccc, ddd, F1, KK5, in[7],   6);\n\tROUND(ddd, eee, aaa, bbb, ccc, F1, KK5, in[6],   8);\n\tROUND(ccc, ddd, eee, aaa, bbb, F1, KK5, in[2],  13);\n\tROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[13],  6);\n\tROUND(aaa, bbb, ccc, ddd, eee, F1, KK5, in[14],  5);\n\tROUND(eee, aaa, bbb, ccc, ddd, F1, KK5, in[0],  15);\n\tROUND(ddd, eee, aaa, bbb, ccc, F1, KK5, in[3],  13);\n\tROUND(ccc, ddd, eee, aaa, bbb, F1, KK5, in[9],  11);\n\tROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[11], 11);\n\n\t/* combine results */\n\tddd += cc + state[1];\t\t/* final result for state[0] */\n\tstate[1] = state[2] + dd + eee;\n\tstate[2] = state[3] + ee + aaa;\n\tstate[3] = state[4] + aa + bbb;\n\tstate[4] = state[0] + bb + ccc;\n\tstate[0] = ddd;\n\n\treturn;\n}\n\nstatic int rmd160_init(struct shash_desc *desc)\n{\n\tstruct rmd160_ctx *rctx = shash_desc_ctx(desc);\n\n\trctx->byte_count = 0;\n\n\trctx->state[0] = RMD_H0;\n\trctx->state[1] = RMD_H1;\n\trctx->state[2] = RMD_H2;\n\trctx->state[3] = RMD_H3;\n\trctx->state[4] = RMD_H4;\n\n\tmemset(rctx->buffer, 0, sizeof(rctx->buffer));\n\n\treturn 0;\n}\n\nstatic int rmd160_update(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int len)\n{\n\tstruct rmd160_ctx *rctx = shash_desc_ctx(desc);\n\tconst u32 avail = sizeof(rctx->buffer) - (rctx->byte_count & 0x3f);\n\n\trctx->byte_count += len;\n\n\t/* Enough space in buffer? If so copy and we're done */\n\tif (avail > len) {\n\t\tmemcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),\n\t\t       data, len);\n\t\tgoto out;\n\t}\n\n\tmemcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),\n\t       data, avail);\n\n\trmd160_transform(rctx->state, rctx->buffer);\n\tdata += avail;\n\tlen -= avail;\n\n\twhile (len >= sizeof(rctx->buffer)) {\n\t\tmemcpy(rctx->buffer, data, sizeof(rctx->buffer));\n\t\trmd160_transform(rctx->state, rctx->buffer);\n\t\tdata += sizeof(rctx->buffer);\n\t\tlen -= sizeof(rctx->buffer);\n\t}\n\n\tmemcpy(rctx->buffer, data, len);\n\nout:\n\treturn 0;\n}\n\n/* Add padding and return the message digest. */\nstatic int rmd160_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct rmd160_ctx *rctx = shash_desc_ctx(desc);\n\tu32 i, index, padlen;\n\t__le64 bits;\n\t__le32 *dst = (__le32 *)out;\n\tstatic const u8 padding[64] = { 0x80, };\n\n\tbits = cpu_to_le64(rctx->byte_count << 3);\n\n\t/* Pad out to 56 mod 64 */\n\tindex = rctx->byte_count & 0x3f;\n\tpadlen = (index < 56) ? (56 - index) : ((64+56) - index);\n\trmd160_update(desc, padding, padlen);\n\n\t/* Append length */\n\trmd160_update(desc, (const u8 *)&bits, sizeof(bits));\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 5; i++)\n\t\tdst[i] = cpu_to_le32p(&rctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(rctx, 0, sizeof(*rctx));\n\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tRMD160_DIGEST_SIZE,\n\t.init\t\t=\trmd160_init,\n\t.update\t\t=\trmd160_update,\n\t.final\t\t=\trmd160_final,\n\t.descsize\t=\tsizeof(struct rmd160_ctx),\n\t.base\t\t=\t{\n\t\t.cra_name\t =\t\"rmd160\",\n\t\t.cra_flags\t =\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t =\tRMD160_BLOCK_SIZE,\n\t\t.cra_module\t =\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init rmd160_mod_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit rmd160_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(rmd160_mod_init);\nmodule_exit(rmd160_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Adrian-Ken Rueegsegger <ken@codelabs.ch>\");\nMODULE_DESCRIPTION(\"RIPEMD-160 Message Digest\");\n", "/*\n * Cryptographic API.\n *\n * RIPEMD-256 - RACE Integrity Primitives Evaluation Message Digest.\n *\n * Based on the reference implementation by Antoon Bosselaers, ESAT-COSIC\n *\n * Copyright (c) 2008 Adrian-Ken Rueegsegger <ken@codelabs.ch>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/types.h>\n#include <asm/byteorder.h>\n\n#include \"ripemd.h\"\n\nstruct rmd256_ctx {\n\tu64 byte_count;\n\tu32 state[8];\n\t__le32 buffer[16];\n};\n\n#define K1  RMD_K1\n#define K2  RMD_K2\n#define K3  RMD_K3\n#define K4  RMD_K4\n#define KK1 RMD_K6\n#define KK2 RMD_K7\n#define KK3 RMD_K8\n#define KK4 RMD_K1\n\n#define F1(x, y, z) (x ^ y ^ z)\t\t/* XOR */\n#define F2(x, y, z) (z ^ (x & (y ^ z)))\t/* x ? y : z */\n#define F3(x, y, z) ((x | ~y) ^ z)\n#define F4(x, y, z) (y ^ (z & (x ^ y)))\t/* z ? x : y */\n\n#define ROUND(a, b, c, d, f, k, x, s)  { \\\n\t(a) += f((b), (c), (d)) + le32_to_cpup(&(x)) + (k); \\\n\t(a) = rol32((a), (s)); \\\n}\n\nstatic void rmd256_transform(u32 *state, const __le32 *in)\n{\n\tu32 aa, bb, cc, dd, aaa, bbb, ccc, ddd, tmp;\n\n\t/* Initialize left lane */\n\taa = state[0];\n\tbb = state[1];\n\tcc = state[2];\n\tdd = state[3];\n\n\t/* Initialize right lane */\n\taaa = state[4];\n\tbbb = state[5];\n\tccc = state[6];\n\tddd = state[7];\n\n\t/* round 1: left lane */\n\tROUND(aa, bb, cc, dd, F1, K1, in[0],  11);\n\tROUND(dd, aa, bb, cc, F1, K1, in[1],  14);\n\tROUND(cc, dd, aa, bb, F1, K1, in[2],  15);\n\tROUND(bb, cc, dd, aa, F1, K1, in[3],  12);\n\tROUND(aa, bb, cc, dd, F1, K1, in[4],   5);\n\tROUND(dd, aa, bb, cc, F1, K1, in[5],   8);\n\tROUND(cc, dd, aa, bb, F1, K1, in[6],   7);\n\tROUND(bb, cc, dd, aa, F1, K1, in[7],   9);\n\tROUND(aa, bb, cc, dd, F1, K1, in[8],  11);\n\tROUND(dd, aa, bb, cc, F1, K1, in[9],  13);\n\tROUND(cc, dd, aa, bb, F1, K1, in[10], 14);\n\tROUND(bb, cc, dd, aa, F1, K1, in[11], 15);\n\tROUND(aa, bb, cc, dd, F1, K1, in[12],  6);\n\tROUND(dd, aa, bb, cc, F1, K1, in[13],  7);\n\tROUND(cc, dd, aa, bb, F1, K1, in[14],  9);\n\tROUND(bb, cc, dd, aa, F1, K1, in[15],  8);\n\n\t/* round 1: right lane */\n\tROUND(aaa, bbb, ccc, ddd, F4, KK1, in[5],   8);\n\tROUND(ddd, aaa, bbb, ccc, F4, KK1, in[14],  9);\n\tROUND(ccc, ddd, aaa, bbb, F4, KK1, in[7],   9);\n\tROUND(bbb, ccc, ddd, aaa, F4, KK1, in[0],  11);\n\tROUND(aaa, bbb, ccc, ddd, F4, KK1, in[9],  13);\n\tROUND(ddd, aaa, bbb, ccc, F4, KK1, in[2],  15);\n\tROUND(ccc, ddd, aaa, bbb, F4, KK1, in[11], 15);\n\tROUND(bbb, ccc, ddd, aaa, F4, KK1, in[4],   5);\n\tROUND(aaa, bbb, ccc, ddd, F4, KK1, in[13],  7);\n\tROUND(ddd, aaa, bbb, ccc, F4, KK1, in[6],   7);\n\tROUND(ccc, ddd, aaa, bbb, F4, KK1, in[15],  8);\n\tROUND(bbb, ccc, ddd, aaa, F4, KK1, in[8],  11);\n\tROUND(aaa, bbb, ccc, ddd, F4, KK1, in[1],  14);\n\tROUND(ddd, aaa, bbb, ccc, F4, KK1, in[10], 14);\n\tROUND(ccc, ddd, aaa, bbb, F4, KK1, in[3],  12);\n\tROUND(bbb, ccc, ddd, aaa, F4, KK1, in[12],  6);\n\n\t/* Swap contents of \"a\" registers */\n\ttmp = aa; aa = aaa; aaa = tmp;\n\n\t/* round 2: left lane */\n\tROUND(aa, bb, cc, dd, F2, K2, in[7],   7);\n\tROUND(dd, aa, bb, cc, F2, K2, in[4],   6);\n\tROUND(cc, dd, aa, bb, F2, K2, in[13],  8);\n\tROUND(bb, cc, dd, aa, F2, K2, in[1],  13);\n\tROUND(aa, bb, cc, dd, F2, K2, in[10], 11);\n\tROUND(dd, aa, bb, cc, F2, K2, in[6],   9);\n\tROUND(cc, dd, aa, bb, F2, K2, in[15],  7);\n\tROUND(bb, cc, dd, aa, F2, K2, in[3],  15);\n\tROUND(aa, bb, cc, dd, F2, K2, in[12],  7);\n\tROUND(dd, aa, bb, cc, F2, K2, in[0],  12);\n\tROUND(cc, dd, aa, bb, F2, K2, in[9],  15);\n\tROUND(bb, cc, dd, aa, F2, K2, in[5],   9);\n\tROUND(aa, bb, cc, dd, F2, K2, in[2],  11);\n\tROUND(dd, aa, bb, cc, F2, K2, in[14],  7);\n\tROUND(cc, dd, aa, bb, F2, K2, in[11], 13);\n\tROUND(bb, cc, dd, aa, F2, K2, in[8],  12);\n\n\t/* round 2: right lane */\n\tROUND(aaa, bbb, ccc, ddd, F3, KK2, in[6],   9);\n\tROUND(ddd, aaa, bbb, ccc, F3, KK2, in[11], 13);\n\tROUND(ccc, ddd, aaa, bbb, F3, KK2, in[3],  15);\n\tROUND(bbb, ccc, ddd, aaa, F3, KK2, in[7],   7);\n\tROUND(aaa, bbb, ccc, ddd, F3, KK2, in[0],  12);\n\tROUND(ddd, aaa, bbb, ccc, F3, KK2, in[13],  8);\n\tROUND(ccc, ddd, aaa, bbb, F3, KK2, in[5],   9);\n\tROUND(bbb, ccc, ddd, aaa, F3, KK2, in[10], 11);\n\tROUND(aaa, bbb, ccc, ddd, F3, KK2, in[14],  7);\n\tROUND(ddd, aaa, bbb, ccc, F3, KK2, in[15],  7);\n\tROUND(ccc, ddd, aaa, bbb, F3, KK2, in[8],  12);\n\tROUND(bbb, ccc, ddd, aaa, F3, KK2, in[12],  7);\n\tROUND(aaa, bbb, ccc, ddd, F3, KK2, in[4],   6);\n\tROUND(ddd, aaa, bbb, ccc, F3, KK2, in[9],  15);\n\tROUND(ccc, ddd, aaa, bbb, F3, KK2, in[1],  13);\n\tROUND(bbb, ccc, ddd, aaa, F3, KK2, in[2],  11);\n\n\t/* Swap contents of \"b\" registers */\n\ttmp = bb; bb = bbb; bbb = tmp;\n\n\t/* round 3: left lane */\n\tROUND(aa, bb, cc, dd, F3, K3, in[3],  11);\n\tROUND(dd, aa, bb, cc, F3, K3, in[10], 13);\n\tROUND(cc, dd, aa, bb, F3, K3, in[14],  6);\n\tROUND(bb, cc, dd, aa, F3, K3, in[4],   7);\n\tROUND(aa, bb, cc, dd, F3, K3, in[9],  14);\n\tROUND(dd, aa, bb, cc, F3, K3, in[15],  9);\n\tROUND(cc, dd, aa, bb, F3, K3, in[8],  13);\n\tROUND(bb, cc, dd, aa, F3, K3, in[1],  15);\n\tROUND(aa, bb, cc, dd, F3, K3, in[2],  14);\n\tROUND(dd, aa, bb, cc, F3, K3, in[7],   8);\n\tROUND(cc, dd, aa, bb, F3, K3, in[0],  13);\n\tROUND(bb, cc, dd, aa, F3, K3, in[6],   6);\n\tROUND(aa, bb, cc, dd, F3, K3, in[13],  5);\n\tROUND(dd, aa, bb, cc, F3, K3, in[11], 12);\n\tROUND(cc, dd, aa, bb, F3, K3, in[5],   7);\n\tROUND(bb, cc, dd, aa, F3, K3, in[12],  5);\n\n\t/* round 3: right lane */\n\tROUND(aaa, bbb, ccc, ddd, F2, KK3, in[15],  9);\n\tROUND(ddd, aaa, bbb, ccc, F2, KK3, in[5],   7);\n\tROUND(ccc, ddd, aaa, bbb, F2, KK3, in[1],  15);\n\tROUND(bbb, ccc, ddd, aaa, F2, KK3, in[3],  11);\n\tROUND(aaa, bbb, ccc, ddd, F2, KK3, in[7],   8);\n\tROUND(ddd, aaa, bbb, ccc, F2, KK3, in[14],  6);\n\tROUND(ccc, ddd, aaa, bbb, F2, KK3, in[6],   6);\n\tROUND(bbb, ccc, ddd, aaa, F2, KK3, in[9],  14);\n\tROUND(aaa, bbb, ccc, ddd, F2, KK3, in[11], 12);\n\tROUND(ddd, aaa, bbb, ccc, F2, KK3, in[8],  13);\n\tROUND(ccc, ddd, aaa, bbb, F2, KK3, in[12],  5);\n\tROUND(bbb, ccc, ddd, aaa, F2, KK3, in[2],  14);\n\tROUND(aaa, bbb, ccc, ddd, F2, KK3, in[10], 13);\n\tROUND(ddd, aaa, bbb, ccc, F2, KK3, in[0],  13);\n\tROUND(ccc, ddd, aaa, bbb, F2, KK3, in[4],   7);\n\tROUND(bbb, ccc, ddd, aaa, F2, KK3, in[13],  5);\n\n\t/* Swap contents of \"c\" registers */\n\ttmp = cc; cc = ccc; ccc = tmp;\n\n\t/* round 4: left lane */\n\tROUND(aa, bb, cc, dd, F4, K4, in[1],  11);\n\tROUND(dd, aa, bb, cc, F4, K4, in[9],  12);\n\tROUND(cc, dd, aa, bb, F4, K4, in[11], 14);\n\tROUND(bb, cc, dd, aa, F4, K4, in[10], 15);\n\tROUND(aa, bb, cc, dd, F4, K4, in[0],  14);\n\tROUND(dd, aa, bb, cc, F4, K4, in[8],  15);\n\tROUND(cc, dd, aa, bb, F4, K4, in[12],  9);\n\tROUND(bb, cc, dd, aa, F4, K4, in[4],   8);\n\tROUND(aa, bb, cc, dd, F4, K4, in[13],  9);\n\tROUND(dd, aa, bb, cc, F4, K4, in[3],  14);\n\tROUND(cc, dd, aa, bb, F4, K4, in[7],   5);\n\tROUND(bb, cc, dd, aa, F4, K4, in[15],  6);\n\tROUND(aa, bb, cc, dd, F4, K4, in[14],  8);\n\tROUND(dd, aa, bb, cc, F4, K4, in[5],   6);\n\tROUND(cc, dd, aa, bb, F4, K4, in[6],   5);\n\tROUND(bb, cc, dd, aa, F4, K4, in[2],  12);\n\n\t/* round 4: right lane */\n\tROUND(aaa, bbb, ccc, ddd, F1, KK4, in[8],  15);\n\tROUND(ddd, aaa, bbb, ccc, F1, KK4, in[6],   5);\n\tROUND(ccc, ddd, aaa, bbb, F1, KK4, in[4],   8);\n\tROUND(bbb, ccc, ddd, aaa, F1, KK4, in[1],  11);\n\tROUND(aaa, bbb, ccc, ddd, F1, KK4, in[3],  14);\n\tROUND(ddd, aaa, bbb, ccc, F1, KK4, in[11], 14);\n\tROUND(ccc, ddd, aaa, bbb, F1, KK4, in[15],  6);\n\tROUND(bbb, ccc, ddd, aaa, F1, KK4, in[0],  14);\n\tROUND(aaa, bbb, ccc, ddd, F1, KK4, in[5],   6);\n\tROUND(ddd, aaa, bbb, ccc, F1, KK4, in[12],  9);\n\tROUND(ccc, ddd, aaa, bbb, F1, KK4, in[2],  12);\n\tROUND(bbb, ccc, ddd, aaa, F1, KK4, in[13],  9);\n\tROUND(aaa, bbb, ccc, ddd, F1, KK4, in[9],  12);\n\tROUND(ddd, aaa, bbb, ccc, F1, KK4, in[7],   5);\n\tROUND(ccc, ddd, aaa, bbb, F1, KK4, in[10], 15);\n\tROUND(bbb, ccc, ddd, aaa, F1, KK4, in[14],  8);\n\n\t/* Swap contents of \"d\" registers */\n\ttmp = dd; dd = ddd; ddd = tmp;\n\n\t/* combine results */\n\tstate[0] += aa;\n\tstate[1] += bb;\n\tstate[2] += cc;\n\tstate[3] += dd;\n\tstate[4] += aaa;\n\tstate[5] += bbb;\n\tstate[6] += ccc;\n\tstate[7] += ddd;\n\n\treturn;\n}\n\nstatic int rmd256_init(struct shash_desc *desc)\n{\n\tstruct rmd256_ctx *rctx = shash_desc_ctx(desc);\n\n\trctx->byte_count = 0;\n\n\trctx->state[0] = RMD_H0;\n\trctx->state[1] = RMD_H1;\n\trctx->state[2] = RMD_H2;\n\trctx->state[3] = RMD_H3;\n\trctx->state[4] = RMD_H5;\n\trctx->state[5] = RMD_H6;\n\trctx->state[6] = RMD_H7;\n\trctx->state[7] = RMD_H8;\n\n\tmemset(rctx->buffer, 0, sizeof(rctx->buffer));\n\n\treturn 0;\n}\n\nstatic int rmd256_update(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int len)\n{\n\tstruct rmd256_ctx *rctx = shash_desc_ctx(desc);\n\tconst u32 avail = sizeof(rctx->buffer) - (rctx->byte_count & 0x3f);\n\n\trctx->byte_count += len;\n\n\t/* Enough space in buffer? If so copy and we're done */\n\tif (avail > len) {\n\t\tmemcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),\n\t\t       data, len);\n\t\tgoto out;\n\t}\n\n\tmemcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),\n\t       data, avail);\n\n\trmd256_transform(rctx->state, rctx->buffer);\n\tdata += avail;\n\tlen -= avail;\n\n\twhile (len >= sizeof(rctx->buffer)) {\n\t\tmemcpy(rctx->buffer, data, sizeof(rctx->buffer));\n\t\trmd256_transform(rctx->state, rctx->buffer);\n\t\tdata += sizeof(rctx->buffer);\n\t\tlen -= sizeof(rctx->buffer);\n\t}\n\n\tmemcpy(rctx->buffer, data, len);\n\nout:\n\treturn 0;\n}\n\n/* Add padding and return the message digest. */\nstatic int rmd256_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct rmd256_ctx *rctx = shash_desc_ctx(desc);\n\tu32 i, index, padlen;\n\t__le64 bits;\n\t__le32 *dst = (__le32 *)out;\n\tstatic const u8 padding[64] = { 0x80, };\n\n\tbits = cpu_to_le64(rctx->byte_count << 3);\n\n\t/* Pad out to 56 mod 64 */\n\tindex = rctx->byte_count & 0x3f;\n\tpadlen = (index < 56) ? (56 - index) : ((64+56) - index);\n\trmd256_update(desc, padding, padlen);\n\n\t/* Append length */\n\trmd256_update(desc, (const u8 *)&bits, sizeof(bits));\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 8; i++)\n\t\tdst[i] = cpu_to_le32p(&rctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(rctx, 0, sizeof(*rctx));\n\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tRMD256_DIGEST_SIZE,\n\t.init\t\t=\trmd256_init,\n\t.update\t\t=\trmd256_update,\n\t.final\t\t=\trmd256_final,\n\t.descsize\t=\tsizeof(struct rmd256_ctx),\n\t.base\t\t=\t{\n\t\t.cra_name\t =\t\"rmd256\",\n\t\t.cra_flags\t =\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t =\tRMD256_BLOCK_SIZE,\n\t\t.cra_module\t =\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init rmd256_mod_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit rmd256_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(rmd256_mod_init);\nmodule_exit(rmd256_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Adrian-Ken Rueegsegger <ken@codelabs.ch>\");\nMODULE_DESCRIPTION(\"RIPEMD-256 Message Digest\");\n", "/*\n * Cryptographic API.\n *\n * RIPEMD-320 - RACE Integrity Primitives Evaluation Message Digest.\n *\n * Based on the reference implementation by Antoon Bosselaers, ESAT-COSIC\n *\n * Copyright (c) 2008 Adrian-Ken Rueegsegger <ken@codelabs.ch>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/types.h>\n#include <asm/byteorder.h>\n\n#include \"ripemd.h\"\n\nstruct rmd320_ctx {\n\tu64 byte_count;\n\tu32 state[10];\n\t__le32 buffer[16];\n};\n\n#define K1  RMD_K1\n#define K2  RMD_K2\n#define K3  RMD_K3\n#define K4  RMD_K4\n#define K5  RMD_K5\n#define KK1 RMD_K6\n#define KK2 RMD_K7\n#define KK3 RMD_K8\n#define KK4 RMD_K9\n#define KK5 RMD_K1\n\n#define F1(x, y, z) (x ^ y ^ z)\t\t/* XOR */\n#define F2(x, y, z) (z ^ (x & (y ^ z)))\t/* x ? y : z */\n#define F3(x, y, z) ((x | ~y) ^ z)\n#define F4(x, y, z) (y ^ (z & (x ^ y)))\t/* z ? x : y */\n#define F5(x, y, z) (x ^ (y | ~z))\n\n#define ROUND(a, b, c, d, e, f, k, x, s)  { \\\n\t(a) += f((b), (c), (d)) + le32_to_cpup(&(x)) + (k); \\\n\t(a) = rol32((a), (s)) + (e); \\\n\t(c) = rol32((c), 10); \\\n}\n\nstatic void rmd320_transform(u32 *state, const __le32 *in)\n{\n\tu32 aa, bb, cc, dd, ee, aaa, bbb, ccc, ddd, eee, tmp;\n\n\t/* Initialize left lane */\n\taa = state[0];\n\tbb = state[1];\n\tcc = state[2];\n\tdd = state[3];\n\tee = state[4];\n\n\t/* Initialize right lane */\n\taaa = state[5];\n\tbbb = state[6];\n\tccc = state[7];\n\tddd = state[8];\n\teee = state[9];\n\n\t/* round 1: left lane */\n\tROUND(aa, bb, cc, dd, ee, F1, K1, in[0],  11);\n\tROUND(ee, aa, bb, cc, dd, F1, K1, in[1],  14);\n\tROUND(dd, ee, aa, bb, cc, F1, K1, in[2],  15);\n\tROUND(cc, dd, ee, aa, bb, F1, K1, in[3],  12);\n\tROUND(bb, cc, dd, ee, aa, F1, K1, in[4],   5);\n\tROUND(aa, bb, cc, dd, ee, F1, K1, in[5],   8);\n\tROUND(ee, aa, bb, cc, dd, F1, K1, in[6],   7);\n\tROUND(dd, ee, aa, bb, cc, F1, K1, in[7],   9);\n\tROUND(cc, dd, ee, aa, bb, F1, K1, in[8],  11);\n\tROUND(bb, cc, dd, ee, aa, F1, K1, in[9],  13);\n\tROUND(aa, bb, cc, dd, ee, F1, K1, in[10], 14);\n\tROUND(ee, aa, bb, cc, dd, F1, K1, in[11], 15);\n\tROUND(dd, ee, aa, bb, cc, F1, K1, in[12],  6);\n\tROUND(cc, dd, ee, aa, bb, F1, K1, in[13],  7);\n\tROUND(bb, cc, dd, ee, aa, F1, K1, in[14],  9);\n\tROUND(aa, bb, cc, dd, ee, F1, K1, in[15],  8);\n\n\t/* round 1: right lane */\n\tROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[5],   8);\n\tROUND(eee, aaa, bbb, ccc, ddd, F5, KK1, in[14],  9);\n\tROUND(ddd, eee, aaa, bbb, ccc, F5, KK1, in[7],   9);\n\tROUND(ccc, ddd, eee, aaa, bbb, F5, KK1, in[0],  11);\n\tROUND(bbb, ccc, ddd, eee, aaa, F5, KK1, in[9],  13);\n\tROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[2],  15);\n\tROUND(eee, aaa, bbb, ccc, ddd, F5, KK1, in[11], 15);\n\tROUND(ddd, eee, aaa, bbb, ccc, F5, KK1, in[4],   5);\n\tROUND(ccc, ddd, eee, aaa, bbb, F5, KK1, in[13],  7);\n\tROUND(bbb, ccc, ddd, eee, aaa, F5, KK1, in[6],   7);\n\tROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[15],  8);\n\tROUND(eee, aaa, bbb, ccc, ddd, F5, KK1, in[8],  11);\n\tROUND(ddd, eee, aaa, bbb, ccc, F5, KK1, in[1],  14);\n\tROUND(ccc, ddd, eee, aaa, bbb, F5, KK1, in[10], 14);\n\tROUND(bbb, ccc, ddd, eee, aaa, F5, KK1, in[3],  12);\n\tROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[12],  6);\n\n\t/* Swap contents of \"a\" registers */\n\ttmp = aa; aa = aaa; aaa = tmp;\n\n\t/* round 2: left lane\" */\n\tROUND(ee, aa, bb, cc, dd, F2, K2, in[7],   7);\n\tROUND(dd, ee, aa, bb, cc, F2, K2, in[4],   6);\n\tROUND(cc, dd, ee, aa, bb, F2, K2, in[13],  8);\n\tROUND(bb, cc, dd, ee, aa, F2, K2, in[1],  13);\n\tROUND(aa, bb, cc, dd, ee, F2, K2, in[10], 11);\n\tROUND(ee, aa, bb, cc, dd, F2, K2, in[6],   9);\n\tROUND(dd, ee, aa, bb, cc, F2, K2, in[15],  7);\n\tROUND(cc, dd, ee, aa, bb, F2, K2, in[3],  15);\n\tROUND(bb, cc, dd, ee, aa, F2, K2, in[12],  7);\n\tROUND(aa, bb, cc, dd, ee, F2, K2, in[0],  12);\n\tROUND(ee, aa, bb, cc, dd, F2, K2, in[9],  15);\n\tROUND(dd, ee, aa, bb, cc, F2, K2, in[5],   9);\n\tROUND(cc, dd, ee, aa, bb, F2, K2, in[2],  11);\n\tROUND(bb, cc, dd, ee, aa, F2, K2, in[14],  7);\n\tROUND(aa, bb, cc, dd, ee, F2, K2, in[11], 13);\n\tROUND(ee, aa, bb, cc, dd, F2, K2, in[8],  12);\n\n\t/* round 2: right lane */\n\tROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[6],   9);\n\tROUND(ddd, eee, aaa, bbb, ccc, F4, KK2, in[11], 13);\n\tROUND(ccc, ddd, eee, aaa, bbb, F4, KK2, in[3],  15);\n\tROUND(bbb, ccc, ddd, eee, aaa, F4, KK2, in[7],   7);\n\tROUND(aaa, bbb, ccc, ddd, eee, F4, KK2, in[0],  12);\n\tROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[13],  8);\n\tROUND(ddd, eee, aaa, bbb, ccc, F4, KK2, in[5],   9);\n\tROUND(ccc, ddd, eee, aaa, bbb, F4, KK2, in[10], 11);\n\tROUND(bbb, ccc, ddd, eee, aaa, F4, KK2, in[14],  7);\n\tROUND(aaa, bbb, ccc, ddd, eee, F4, KK2, in[15],  7);\n\tROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[8],  12);\n\tROUND(ddd, eee, aaa, bbb, ccc, F4, KK2, in[12],  7);\n\tROUND(ccc, ddd, eee, aaa, bbb, F4, KK2, in[4],   6);\n\tROUND(bbb, ccc, ddd, eee, aaa, F4, KK2, in[9],  15);\n\tROUND(aaa, bbb, ccc, ddd, eee, F4, KK2, in[1],  13);\n\tROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[2],  11);\n\n\t/* Swap contents of \"b\" registers */\n\ttmp = bb; bb = bbb; bbb = tmp;\n\n\t/* round 3: left lane\" */\n\tROUND(dd, ee, aa, bb, cc, F3, K3, in[3],  11);\n\tROUND(cc, dd, ee, aa, bb, F3, K3, in[10], 13);\n\tROUND(bb, cc, dd, ee, aa, F3, K3, in[14],  6);\n\tROUND(aa, bb, cc, dd, ee, F3, K3, in[4],   7);\n\tROUND(ee, aa, bb, cc, dd, F3, K3, in[9],  14);\n\tROUND(dd, ee, aa, bb, cc, F3, K3, in[15],  9);\n\tROUND(cc, dd, ee, aa, bb, F3, K3, in[8],  13);\n\tROUND(bb, cc, dd, ee, aa, F3, K3, in[1],  15);\n\tROUND(aa, bb, cc, dd, ee, F3, K3, in[2],  14);\n\tROUND(ee, aa, bb, cc, dd, F3, K3, in[7],   8);\n\tROUND(dd, ee, aa, bb, cc, F3, K3, in[0],  13);\n\tROUND(cc, dd, ee, aa, bb, F3, K3, in[6],   6);\n\tROUND(bb, cc, dd, ee, aa, F3, K3, in[13],  5);\n\tROUND(aa, bb, cc, dd, ee, F3, K3, in[11], 12);\n\tROUND(ee, aa, bb, cc, dd, F3, K3, in[5],   7);\n\tROUND(dd, ee, aa, bb, cc, F3, K3, in[12],  5);\n\n\t/* round 3: right lane */\n\tROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[15],  9);\n\tROUND(ccc, ddd, eee, aaa, bbb, F3, KK3, in[5],   7);\n\tROUND(bbb, ccc, ddd, eee, aaa, F3, KK3, in[1],  15);\n\tROUND(aaa, bbb, ccc, ddd, eee, F3, KK3, in[3],  11);\n\tROUND(eee, aaa, bbb, ccc, ddd, F3, KK3, in[7],   8);\n\tROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[14],  6);\n\tROUND(ccc, ddd, eee, aaa, bbb, F3, KK3, in[6],   6);\n\tROUND(bbb, ccc, ddd, eee, aaa, F3, KK3, in[9],  14);\n\tROUND(aaa, bbb, ccc, ddd, eee, F3, KK3, in[11], 12);\n\tROUND(eee, aaa, bbb, ccc, ddd, F3, KK3, in[8],  13);\n\tROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[12],  5);\n\tROUND(ccc, ddd, eee, aaa, bbb, F3, KK3, in[2],  14);\n\tROUND(bbb, ccc, ddd, eee, aaa, F3, KK3, in[10], 13);\n\tROUND(aaa, bbb, ccc, ddd, eee, F3, KK3, in[0],  13);\n\tROUND(eee, aaa, bbb, ccc, ddd, F3, KK3, in[4],   7);\n\tROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[13],  5);\n\n\t/* Swap contents of \"c\" registers */\n\ttmp = cc; cc = ccc; ccc = tmp;\n\n\t/* round 4: left lane\" */\n\tROUND(cc, dd, ee, aa, bb, F4, K4, in[1],  11);\n\tROUND(bb, cc, dd, ee, aa, F4, K4, in[9],  12);\n\tROUND(aa, bb, cc, dd, ee, F4, K4, in[11], 14);\n\tROUND(ee, aa, bb, cc, dd, F4, K4, in[10], 15);\n\tROUND(dd, ee, aa, bb, cc, F4, K4, in[0],  14);\n\tROUND(cc, dd, ee, aa, bb, F4, K4, in[8],  15);\n\tROUND(bb, cc, dd, ee, aa, F4, K4, in[12],  9);\n\tROUND(aa, bb, cc, dd, ee, F4, K4, in[4],   8);\n\tROUND(ee, aa, bb, cc, dd, F4, K4, in[13],  9);\n\tROUND(dd, ee, aa, bb, cc, F4, K4, in[3],  14);\n\tROUND(cc, dd, ee, aa, bb, F4, K4, in[7],   5);\n\tROUND(bb, cc, dd, ee, aa, F4, K4, in[15],  6);\n\tROUND(aa, bb, cc, dd, ee, F4, K4, in[14],  8);\n\tROUND(ee, aa, bb, cc, dd, F4, K4, in[5],   6);\n\tROUND(dd, ee, aa, bb, cc, F4, K4, in[6],   5);\n\tROUND(cc, dd, ee, aa, bb, F4, K4, in[2],  12);\n\n\t/* round 4: right lane */\n\tROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[8],  15);\n\tROUND(bbb, ccc, ddd, eee, aaa, F2, KK4, in[6],   5);\n\tROUND(aaa, bbb, ccc, ddd, eee, F2, KK4, in[4],   8);\n\tROUND(eee, aaa, bbb, ccc, ddd, F2, KK4, in[1],  11);\n\tROUND(ddd, eee, aaa, bbb, ccc, F2, KK4, in[3],  14);\n\tROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[11], 14);\n\tROUND(bbb, ccc, ddd, eee, aaa, F2, KK4, in[15],  6);\n\tROUND(aaa, bbb, ccc, ddd, eee, F2, KK4, in[0],  14);\n\tROUND(eee, aaa, bbb, ccc, ddd, F2, KK4, in[5],   6);\n\tROUND(ddd, eee, aaa, bbb, ccc, F2, KK4, in[12],  9);\n\tROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[2],  12);\n\tROUND(bbb, ccc, ddd, eee, aaa, F2, KK4, in[13],  9);\n\tROUND(aaa, bbb, ccc, ddd, eee, F2, KK4, in[9],  12);\n\tROUND(eee, aaa, bbb, ccc, ddd, F2, KK4, in[7],   5);\n\tROUND(ddd, eee, aaa, bbb, ccc, F2, KK4, in[10], 15);\n\tROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[14],  8);\n\n\t/* Swap contents of \"d\" registers */\n\ttmp = dd; dd = ddd; ddd = tmp;\n\n\t/* round 5: left lane\" */\n\tROUND(bb, cc, dd, ee, aa, F5, K5, in[4],   9);\n\tROUND(aa, bb, cc, dd, ee, F5, K5, in[0],  15);\n\tROUND(ee, aa, bb, cc, dd, F5, K5, in[5],   5);\n\tROUND(dd, ee, aa, bb, cc, F5, K5, in[9],  11);\n\tROUND(cc, dd, ee, aa, bb, F5, K5, in[7],   6);\n\tROUND(bb, cc, dd, ee, aa, F5, K5, in[12],  8);\n\tROUND(aa, bb, cc, dd, ee, F5, K5, in[2],  13);\n\tROUND(ee, aa, bb, cc, dd, F5, K5, in[10], 12);\n\tROUND(dd, ee, aa, bb, cc, F5, K5, in[14],  5);\n\tROUND(cc, dd, ee, aa, bb, F5, K5, in[1],  12);\n\tROUND(bb, cc, dd, ee, aa, F5, K5, in[3],  13);\n\tROUND(aa, bb, cc, dd, ee, F5, K5, in[8],  14);\n\tROUND(ee, aa, bb, cc, dd, F5, K5, in[11], 11);\n\tROUND(dd, ee, aa, bb, cc, F5, K5, in[6],   8);\n\tROUND(cc, dd, ee, aa, bb, F5, K5, in[15],  5);\n\tROUND(bb, cc, dd, ee, aa, F5, K5, in[13],  6);\n\n\t/* round 5: right lane */\n\tROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[12],  8);\n\tROUND(aaa, bbb, ccc, ddd, eee, F1, KK5, in[15],  5);\n\tROUND(eee, aaa, bbb, ccc, ddd, F1, KK5, in[10], 12);\n\tROUND(ddd, eee, aaa, bbb, ccc, F1, KK5, in[4],   9);\n\tROUND(ccc, ddd, eee, aaa, bbb, F1, KK5, in[1],  12);\n\tROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[5],   5);\n\tROUND(aaa, bbb, ccc, ddd, eee, F1, KK5, in[8],  14);\n\tROUND(eee, aaa, bbb, ccc, ddd, F1, KK5, in[7],   6);\n\tROUND(ddd, eee, aaa, bbb, ccc, F1, KK5, in[6],   8);\n\tROUND(ccc, ddd, eee, aaa, bbb, F1, KK5, in[2],  13);\n\tROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[13],  6);\n\tROUND(aaa, bbb, ccc, ddd, eee, F1, KK5, in[14],  5);\n\tROUND(eee, aaa, bbb, ccc, ddd, F1, KK5, in[0],  15);\n\tROUND(ddd, eee, aaa, bbb, ccc, F1, KK5, in[3],  13);\n\tROUND(ccc, ddd, eee, aaa, bbb, F1, KK5, in[9],  11);\n\tROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[11], 11);\n\n\t/* Swap contents of \"e\" registers */\n\ttmp = ee; ee = eee; eee = tmp;\n\n\t/* combine results */\n\tstate[0] += aa;\n\tstate[1] += bb;\n\tstate[2] += cc;\n\tstate[3] += dd;\n\tstate[4] += ee;\n\tstate[5] += aaa;\n\tstate[6] += bbb;\n\tstate[7] += ccc;\n\tstate[8] += ddd;\n\tstate[9] += eee;\n\n\treturn;\n}\n\nstatic int rmd320_init(struct shash_desc *desc)\n{\n\tstruct rmd320_ctx *rctx = shash_desc_ctx(desc);\n\n\trctx->byte_count = 0;\n\n\trctx->state[0] = RMD_H0;\n\trctx->state[1] = RMD_H1;\n\trctx->state[2] = RMD_H2;\n\trctx->state[3] = RMD_H3;\n\trctx->state[4] = RMD_H4;\n\trctx->state[5] = RMD_H5;\n\trctx->state[6] = RMD_H6;\n\trctx->state[7] = RMD_H7;\n\trctx->state[8] = RMD_H8;\n\trctx->state[9] = RMD_H9;\n\n\tmemset(rctx->buffer, 0, sizeof(rctx->buffer));\n\n\treturn 0;\n}\n\nstatic int rmd320_update(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int len)\n{\n\tstruct rmd320_ctx *rctx = shash_desc_ctx(desc);\n\tconst u32 avail = sizeof(rctx->buffer) - (rctx->byte_count & 0x3f);\n\n\trctx->byte_count += len;\n\n\t/* Enough space in buffer? If so copy and we're done */\n\tif (avail > len) {\n\t\tmemcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),\n\t\t       data, len);\n\t\tgoto out;\n\t}\n\n\tmemcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),\n\t       data, avail);\n\n\trmd320_transform(rctx->state, rctx->buffer);\n\tdata += avail;\n\tlen -= avail;\n\n\twhile (len >= sizeof(rctx->buffer)) {\n\t\tmemcpy(rctx->buffer, data, sizeof(rctx->buffer));\n\t\trmd320_transform(rctx->state, rctx->buffer);\n\t\tdata += sizeof(rctx->buffer);\n\t\tlen -= sizeof(rctx->buffer);\n\t}\n\n\tmemcpy(rctx->buffer, data, len);\n\nout:\n\treturn 0;\n}\n\n/* Add padding and return the message digest. */\nstatic int rmd320_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct rmd320_ctx *rctx = shash_desc_ctx(desc);\n\tu32 i, index, padlen;\n\t__le64 bits;\n\t__le32 *dst = (__le32 *)out;\n\tstatic const u8 padding[64] = { 0x80, };\n\n\tbits = cpu_to_le64(rctx->byte_count << 3);\n\n\t/* Pad out to 56 mod 64 */\n\tindex = rctx->byte_count & 0x3f;\n\tpadlen = (index < 56) ? (56 - index) : ((64+56) - index);\n\trmd320_update(desc, padding, padlen);\n\n\t/* Append length */\n\trmd320_update(desc, (const u8 *)&bits, sizeof(bits));\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 10; i++)\n\t\tdst[i] = cpu_to_le32p(&rctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(rctx, 0, sizeof(*rctx));\n\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tRMD320_DIGEST_SIZE,\n\t.init\t\t=\trmd320_init,\n\t.update\t\t=\trmd320_update,\n\t.final\t\t=\trmd320_final,\n\t.descsize\t=\tsizeof(struct rmd320_ctx),\n\t.base\t\t=\t{\n\t\t.cra_name\t =\t\"rmd320\",\n\t\t.cra_flags\t =\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t =\tRMD320_BLOCK_SIZE,\n\t\t.cra_module\t =\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init rmd320_mod_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit rmd320_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(rmd320_mod_init);\nmodule_exit(rmd320_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Adrian-Ken Rueegsegger <ken@codelabs.ch>\");\nMODULE_DESCRIPTION(\"RIPEMD-320 Message Digest\");\n", "/*\n * Salsa20: Salsa20 stream cipher algorithm\n *\n * Copyright (c) 2007 Tan Swee Heng <thesweeheng@gmail.com>\n *\n * Derived from:\n * - salsa20.c: Public domain C code by Daniel J. Bernstein <djb@cr.yp.to>\n *\n * Salsa20 is a stream cipher candidate in eSTREAM, the ECRYPT Stream\n * Cipher Project. It is designed by Daniel J. Bernstein <djb@cr.yp.to>.\n * More information about eSTREAM and Salsa20 can be found here:\n *   http://www.ecrypt.eu.org/stream/\n *   http://cr.yp.to/snuffle.html\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/crypto.h>\n#include <linux/types.h>\n#include <linux/bitops.h>\n#include <crypto/algapi.h>\n#include <asm/byteorder.h>\n\n#define SALSA20_IV_SIZE        8U\n#define SALSA20_MIN_KEY_SIZE  16U\n#define SALSA20_MAX_KEY_SIZE  32U\n\n/*\n * Start of code taken from D. J. Bernstein's reference implementation.\n * With some modifications and optimizations made to suit our needs.\n */\n\n/*\nsalsa20-ref.c version 20051118\nD. J. Bernstein\nPublic domain.\n*/\n\n#define U32TO8_LITTLE(p, v) \\\n\t{ (p)[0] = (v >>  0) & 0xff; (p)[1] = (v >>  8) & 0xff; \\\n\t  (p)[2] = (v >> 16) & 0xff; (p)[3] = (v >> 24) & 0xff; }\n#define U8TO32_LITTLE(p)   \\\n\t(((u32)((p)[0])      ) | ((u32)((p)[1]) <<  8) | \\\n\t ((u32)((p)[2]) << 16) | ((u32)((p)[3]) << 24)   )\n\nstruct salsa20_ctx\n{\n\tu32 input[16];\n};\n\nstatic void salsa20_wordtobyte(u8 output[64], const u32 input[16])\n{\n\tu32 x[16];\n\tint i;\n\n\tmemcpy(x, input, sizeof(x));\n\tfor (i = 20; i > 0; i -= 2) {\n\t\tx[ 4] ^= rol32((x[ 0] + x[12]),  7);\n\t\tx[ 8] ^= rol32((x[ 4] + x[ 0]),  9);\n\t\tx[12] ^= rol32((x[ 8] + x[ 4]), 13);\n\t\tx[ 0] ^= rol32((x[12] + x[ 8]), 18);\n\t\tx[ 9] ^= rol32((x[ 5] + x[ 1]),  7);\n\t\tx[13] ^= rol32((x[ 9] + x[ 5]),  9);\n\t\tx[ 1] ^= rol32((x[13] + x[ 9]), 13);\n\t\tx[ 5] ^= rol32((x[ 1] + x[13]), 18);\n\t\tx[14] ^= rol32((x[10] + x[ 6]),  7);\n\t\tx[ 2] ^= rol32((x[14] + x[10]),  9);\n\t\tx[ 6] ^= rol32((x[ 2] + x[14]), 13);\n\t\tx[10] ^= rol32((x[ 6] + x[ 2]), 18);\n\t\tx[ 3] ^= rol32((x[15] + x[11]),  7);\n\t\tx[ 7] ^= rol32((x[ 3] + x[15]),  9);\n\t\tx[11] ^= rol32((x[ 7] + x[ 3]), 13);\n\t\tx[15] ^= rol32((x[11] + x[ 7]), 18);\n\t\tx[ 1] ^= rol32((x[ 0] + x[ 3]),  7);\n\t\tx[ 2] ^= rol32((x[ 1] + x[ 0]),  9);\n\t\tx[ 3] ^= rol32((x[ 2] + x[ 1]), 13);\n\t\tx[ 0] ^= rol32((x[ 3] + x[ 2]), 18);\n\t\tx[ 6] ^= rol32((x[ 5] + x[ 4]),  7);\n\t\tx[ 7] ^= rol32((x[ 6] + x[ 5]),  9);\n\t\tx[ 4] ^= rol32((x[ 7] + x[ 6]), 13);\n\t\tx[ 5] ^= rol32((x[ 4] + x[ 7]), 18);\n\t\tx[11] ^= rol32((x[10] + x[ 9]),  7);\n\t\tx[ 8] ^= rol32((x[11] + x[10]),  9);\n\t\tx[ 9] ^= rol32((x[ 8] + x[11]), 13);\n\t\tx[10] ^= rol32((x[ 9] + x[ 8]), 18);\n\t\tx[12] ^= rol32((x[15] + x[14]),  7);\n\t\tx[13] ^= rol32((x[12] + x[15]),  9);\n\t\tx[14] ^= rol32((x[13] + x[12]), 13);\n\t\tx[15] ^= rol32((x[14] + x[13]), 18);\n\t}\n\tfor (i = 0; i < 16; ++i)\n\t\tx[i] += input[i];\n\tfor (i = 0; i < 16; ++i)\n\t\tU32TO8_LITTLE(output + 4 * i,x[i]);\n}\n\nstatic const char sigma[16] = \"expand 32-byte k\";\nstatic const char tau[16] = \"expand 16-byte k\";\n\nstatic void salsa20_keysetup(struct salsa20_ctx *ctx, const u8 *k, u32 kbytes)\n{\n\tconst char *constants;\n\n\tctx->input[1] = U8TO32_LITTLE(k + 0);\n\tctx->input[2] = U8TO32_LITTLE(k + 4);\n\tctx->input[3] = U8TO32_LITTLE(k + 8);\n\tctx->input[4] = U8TO32_LITTLE(k + 12);\n\tif (kbytes == 32) { /* recommended */\n\t\tk += 16;\n\t\tconstants = sigma;\n\t} else { /* kbytes == 16 */\n\t\tconstants = tau;\n\t}\n\tctx->input[11] = U8TO32_LITTLE(k + 0);\n\tctx->input[12] = U8TO32_LITTLE(k + 4);\n\tctx->input[13] = U8TO32_LITTLE(k + 8);\n\tctx->input[14] = U8TO32_LITTLE(k + 12);\n\tctx->input[0] = U8TO32_LITTLE(constants + 0);\n\tctx->input[5] = U8TO32_LITTLE(constants + 4);\n\tctx->input[10] = U8TO32_LITTLE(constants + 8);\n\tctx->input[15] = U8TO32_LITTLE(constants + 12);\n}\n\nstatic void salsa20_ivsetup(struct salsa20_ctx *ctx, const u8 *iv)\n{\n\tctx->input[6] = U8TO32_LITTLE(iv + 0);\n\tctx->input[7] = U8TO32_LITTLE(iv + 4);\n\tctx->input[8] = 0;\n\tctx->input[9] = 0;\n}\n\nstatic void salsa20_encrypt_bytes(struct salsa20_ctx *ctx, u8 *dst,\n\t\t\t\t  const u8 *src, unsigned int bytes)\n{\n\tu8 buf[64];\n\n\tif (dst != src)\n\t\tmemcpy(dst, src, bytes);\n\n\twhile (bytes) {\n\t\tsalsa20_wordtobyte(buf, ctx->input);\n\n\t\tctx->input[8]++;\n\t\tif (!ctx->input[8])\n\t\t\tctx->input[9]++;\n\n\t\tif (bytes <= 64) {\n\t\t\tcrypto_xor(dst, buf, bytes);\n\t\t\treturn;\n\t\t}\n\n\t\tcrypto_xor(dst, buf, 64);\n\t\tbytes -= 64;\n\t\tdst += 64;\n\t}\n}\n\n/*\n * End of code taken from D. J. Bernstein's reference implementation.\n */\n\nstatic int setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t  unsigned int keysize)\n{\n\tstruct salsa20_ctx *ctx = crypto_tfm_ctx(tfm);\n\tsalsa20_keysetup(ctx, key, keysize);\n\treturn 0;\n}\n\nstatic int encrypt(struct blkcipher_desc *desc,\n\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t   unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\tstruct crypto_blkcipher *tfm = desc->tfm;\n\tstruct salsa20_ctx *ctx = crypto_blkcipher_ctx(tfm);\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt_block(desc, &walk, 64);\n\n\tsalsa20_ivsetup(ctx, walk.iv);\n\n\tif (likely(walk.nbytes == nbytes))\n\t{\n\t\tsalsa20_encrypt_bytes(ctx, walk.dst.virt.addr,\n\t\t\t\t      walk.src.virt.addr, nbytes);\n\t\treturn blkcipher_walk_done(desc, &walk, 0);\n\t}\n\n\twhile (walk.nbytes >= 64) {\n\t\tsalsa20_encrypt_bytes(ctx, walk.dst.virt.addr,\n\t\t\t\t      walk.src.virt.addr,\n\t\t\t\t      walk.nbytes - (walk.nbytes % 64));\n\t\terr = blkcipher_walk_done(desc, &walk, walk.nbytes % 64);\n\t}\n\n\tif (walk.nbytes) {\n\t\tsalsa20_encrypt_bytes(ctx, walk.dst.virt.addr,\n\t\t\t\t      walk.src.virt.addr, walk.nbytes);\n\t\terr = blkcipher_walk_done(desc, &walk, 0);\n\t}\n\n\treturn err;\n}\n\nstatic struct crypto_alg alg = {\n\t.cra_name           =   \"salsa20\",\n\t.cra_driver_name    =   \"salsa20-generic\",\n\t.cra_priority       =   100,\n\t.cra_flags          =   CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_type           =   &crypto_blkcipher_type,\n\t.cra_blocksize      =   1,\n\t.cra_ctxsize        =   sizeof(struct salsa20_ctx),\n\t.cra_alignmask      =\t3,\n\t.cra_module         =   THIS_MODULE,\n\t.cra_u              =   {\n\t\t.blkcipher = {\n\t\t\t.setkey         =   setkey,\n\t\t\t.encrypt        =   encrypt,\n\t\t\t.decrypt        =   encrypt,\n\t\t\t.min_keysize    =   SALSA20_MIN_KEY_SIZE,\n\t\t\t.max_keysize    =   SALSA20_MAX_KEY_SIZE,\n\t\t\t.ivsize         =   SALSA20_IV_SIZE,\n\t\t}\n\t}\n};\n\nstatic int __init salsa20_generic_mod_init(void)\n{\n\treturn crypto_register_alg(&alg);\n}\n\nstatic void __exit salsa20_generic_mod_fini(void)\n{\n\tcrypto_unregister_alg(&alg);\n}\n\nmodule_init(salsa20_generic_mod_init);\nmodule_exit(salsa20_generic_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION (\"Salsa20 stream cipher algorithm\");\nMODULE_ALIAS(\"salsa20\");\n", "/*\n * Cryptographic API.\n *\n * SEED Cipher Algorithm.\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * Documentation of SEED can be found in RFC 4269.\n * Copyright (C) 2007 Korea Information Security Agency (KISA).\n */\n\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/types.h>\n#include <linux/errno.h>\n#include <linux/crypto.h>\n#include <asm/byteorder.h>\n\n#define SEED_NUM_KCONSTANTS\t16\n#define SEED_KEY_SIZE\t\t16\n#define SEED_BLOCK_SIZE\t\t16\n#define SEED_KEYSCHED_LEN\t32\n\n/*\n * #define byte(x, nr) ((unsigned char)((x) >> (nr*8)))\n */\nstatic inline u8\nbyte(const u32 x, const unsigned n)\n{\n\treturn x >> (n << 3);\n}\n\nstruct seed_ctx {\n\tu32 keysched[SEED_KEYSCHED_LEN];\n};\n\nstatic const u32 SS0[256] = {\n\t0x2989a1a8, 0x05858184, 0x16c6d2d4, 0x13c3d3d0,\n\t0x14445054, 0x1d0d111c, 0x2c8ca0ac, 0x25052124,\n\t0x1d4d515c, 0x03434340, 0x18081018, 0x1e0e121c,\n\t0x11415150, 0x3cccf0fc, 0x0acac2c8, 0x23436360,\n\t0x28082028, 0x04444044, 0x20002020, 0x1d8d919c,\n\t0x20c0e0e0, 0x22c2e2e0, 0x08c8c0c8, 0x17071314,\n\t0x2585a1a4, 0x0f8f838c, 0x03030300, 0x3b4b7378,\n\t0x3b8bb3b8, 0x13031310, 0x12c2d2d0, 0x2ecee2ec,\n\t0x30407070, 0x0c8c808c, 0x3f0f333c, 0x2888a0a8,\n\t0x32023230, 0x1dcdd1dc, 0x36c6f2f4, 0x34447074,\n\t0x2ccce0ec, 0x15859194, 0x0b0b0308, 0x17475354,\n\t0x1c4c505c, 0x1b4b5358, 0x3d8db1bc, 0x01010100,\n\t0x24042024, 0x1c0c101c, 0x33437370, 0x18889098,\n\t0x10001010, 0x0cccc0cc, 0x32c2f2f0, 0x19c9d1d8,\n\t0x2c0c202c, 0x27c7e3e4, 0x32427270, 0x03838380,\n\t0x1b8b9398, 0x11c1d1d0, 0x06868284, 0x09c9c1c8,\n\t0x20406060, 0x10405050, 0x2383a3a0, 0x2bcbe3e8,\n\t0x0d0d010c, 0x3686b2b4, 0x1e8e929c, 0x0f4f434c,\n\t0x3787b3b4, 0x1a4a5258, 0x06c6c2c4, 0x38487078,\n\t0x2686a2a4, 0x12021210, 0x2f8fa3ac, 0x15c5d1d4,\n\t0x21416160, 0x03c3c3c0, 0x3484b0b4, 0x01414140,\n\t0x12425250, 0x3d4d717c, 0x0d8d818c, 0x08080008,\n\t0x1f0f131c, 0x19899198, 0x00000000, 0x19091118,\n\t0x04040004, 0x13435350, 0x37c7f3f4, 0x21c1e1e0,\n\t0x3dcdf1fc, 0x36467274, 0x2f0f232c, 0x27072324,\n\t0x3080b0b0, 0x0b8b8388, 0x0e0e020c, 0x2b8ba3a8,\n\t0x2282a2a0, 0x2e4e626c, 0x13839390, 0x0d4d414c,\n\t0x29496168, 0x3c4c707c, 0x09090108, 0x0a0a0208,\n\t0x3f8fb3bc, 0x2fcfe3ec, 0x33c3f3f0, 0x05c5c1c4,\n\t0x07878384, 0x14041014, 0x3ecef2fc, 0x24446064,\n\t0x1eced2dc, 0x2e0e222c, 0x0b4b4348, 0x1a0a1218,\n\t0x06060204, 0x21012120, 0x2b4b6368, 0x26466264,\n\t0x02020200, 0x35c5f1f4, 0x12829290, 0x0a8a8288,\n\t0x0c0c000c, 0x3383b3b0, 0x3e4e727c, 0x10c0d0d0,\n\t0x3a4a7278, 0x07474344, 0x16869294, 0x25c5e1e4,\n\t0x26062224, 0x00808080, 0x2d8da1ac, 0x1fcfd3dc,\n\t0x2181a1a0, 0x30003030, 0x37073334, 0x2e8ea2ac,\n\t0x36063234, 0x15051114, 0x22022220, 0x38083038,\n\t0x34c4f0f4, 0x2787a3a4, 0x05454144, 0x0c4c404c,\n\t0x01818180, 0x29c9e1e8, 0x04848084, 0x17879394,\n\t0x35053134, 0x0bcbc3c8, 0x0ecec2cc, 0x3c0c303c,\n\t0x31417170, 0x11011110, 0x07c7c3c4, 0x09898188,\n\t0x35457174, 0x3bcbf3f8, 0x1acad2d8, 0x38c8f0f8,\n\t0x14849094, 0x19495158, 0x02828280, 0x04c4c0c4,\n\t0x3fcff3fc, 0x09494148, 0x39093138, 0x27476364,\n\t0x00c0c0c0, 0x0fcfc3cc, 0x17c7d3d4, 0x3888b0b8,\n\t0x0f0f030c, 0x0e8e828c, 0x02424240, 0x23032320,\n\t0x11819190, 0x2c4c606c, 0x1bcbd3d8, 0x2484a0a4,\n\t0x34043034, 0x31c1f1f0, 0x08484048, 0x02c2c2c0,\n\t0x2f4f636c, 0x3d0d313c, 0x2d0d212c, 0x00404040,\n\t0x3e8eb2bc, 0x3e0e323c, 0x3c8cb0bc, 0x01c1c1c0,\n\t0x2a8aa2a8, 0x3a8ab2b8, 0x0e4e424c, 0x15455154,\n\t0x3b0b3338, 0x1cccd0dc, 0x28486068, 0x3f4f737c,\n\t0x1c8c909c, 0x18c8d0d8, 0x0a4a4248, 0x16465254,\n\t0x37477374, 0x2080a0a0, 0x2dcde1ec, 0x06464244,\n\t0x3585b1b4, 0x2b0b2328, 0x25456164, 0x3acaf2f8,\n\t0x23c3e3e0, 0x3989b1b8, 0x3181b1b0, 0x1f8f939c,\n\t0x1e4e525c, 0x39c9f1f8, 0x26c6e2e4, 0x3282b2b0,\n\t0x31013130, 0x2acae2e8, 0x2d4d616c, 0x1f4f535c,\n\t0x24c4e0e4, 0x30c0f0f0, 0x0dcdc1cc, 0x08888088,\n\t0x16061214, 0x3a0a3238, 0x18485058, 0x14c4d0d4,\n\t0x22426260, 0x29092128, 0x07070304, 0x33033330,\n\t0x28c8e0e8, 0x1b0b1318, 0x05050104, 0x39497178,\n\t0x10809090, 0x2a4a6268, 0x2a0a2228, 0x1a8a9298,\n};\n\nstatic const u32 SS1[256] = {\n\t0x38380830, 0xe828c8e0, 0x2c2d0d21, 0xa42686a2,\n\t0xcc0fcfc3, 0xdc1eced2, 0xb03383b3, 0xb83888b0,\n\t0xac2f8fa3, 0x60204060, 0x54154551, 0xc407c7c3,\n\t0x44044440, 0x6c2f4f63, 0x682b4b63, 0x581b4b53,\n\t0xc003c3c3, 0x60224262, 0x30330333, 0xb43585b1,\n\t0x28290921, 0xa02080a0, 0xe022c2e2, 0xa42787a3,\n\t0xd013c3d3, 0x90118191, 0x10110111, 0x04060602,\n\t0x1c1c0c10, 0xbc3c8cb0, 0x34360632, 0x480b4b43,\n\t0xec2fcfe3, 0x88088880, 0x6c2c4c60, 0xa82888a0,\n\t0x14170713, 0xc404c4c0, 0x14160612, 0xf434c4f0,\n\t0xc002c2c2, 0x44054541, 0xe021c1e1, 0xd416c6d2,\n\t0x3c3f0f33, 0x3c3d0d31, 0x8c0e8e82, 0x98188890,\n\t0x28280820, 0x4c0e4e42, 0xf436c6f2, 0x3c3e0e32,\n\t0xa42585a1, 0xf839c9f1, 0x0c0d0d01, 0xdc1fcfd3,\n\t0xd818c8d0, 0x282b0b23, 0x64264662, 0x783a4a72,\n\t0x24270723, 0x2c2f0f23, 0xf031c1f1, 0x70324272,\n\t0x40024242, 0xd414c4d0, 0x40014141, 0xc000c0c0,\n\t0x70334373, 0x64274763, 0xac2c8ca0, 0x880b8b83,\n\t0xf437c7f3, 0xac2d8da1, 0x80008080, 0x1c1f0f13,\n\t0xc80acac2, 0x2c2c0c20, 0xa82a8aa2, 0x34340430,\n\t0xd012c2d2, 0x080b0b03, 0xec2ecee2, 0xe829c9e1,\n\t0x5c1d4d51, 0x94148490, 0x18180810, 0xf838c8f0,\n\t0x54174753, 0xac2e8ea2, 0x08080800, 0xc405c5c1,\n\t0x10130313, 0xcc0dcdc1, 0x84068682, 0xb83989b1,\n\t0xfc3fcff3, 0x7c3d4d71, 0xc001c1c1, 0x30310131,\n\t0xf435c5f1, 0x880a8a82, 0x682a4a62, 0xb03181b1,\n\t0xd011c1d1, 0x20200020, 0xd417c7d3, 0x00020202,\n\t0x20220222, 0x04040400, 0x68284860, 0x70314171,\n\t0x04070703, 0xd81bcbd3, 0x9c1d8d91, 0x98198991,\n\t0x60214161, 0xbc3e8eb2, 0xe426c6e2, 0x58194951,\n\t0xdc1dcdd1, 0x50114151, 0x90108090, 0xdc1cccd0,\n\t0x981a8a92, 0xa02383a3, 0xa82b8ba3, 0xd010c0d0,\n\t0x80018181, 0x0c0f0f03, 0x44074743, 0x181a0a12,\n\t0xe023c3e3, 0xec2ccce0, 0x8c0d8d81, 0xbc3f8fb3,\n\t0x94168692, 0x783b4b73, 0x5c1c4c50, 0xa02282a2,\n\t0xa02181a1, 0x60234363, 0x20230323, 0x4c0d4d41,\n\t0xc808c8c0, 0x9c1e8e92, 0x9c1c8c90, 0x383a0a32,\n\t0x0c0c0c00, 0x2c2e0e22, 0xb83a8ab2, 0x6c2e4e62,\n\t0x9c1f8f93, 0x581a4a52, 0xf032c2f2, 0x90128292,\n\t0xf033c3f3, 0x48094941, 0x78384870, 0xcc0cccc0,\n\t0x14150511, 0xf83bcbf3, 0x70304070, 0x74354571,\n\t0x7c3f4f73, 0x34350531, 0x10100010, 0x00030303,\n\t0x64244460, 0x6c2d4d61, 0xc406c6c2, 0x74344470,\n\t0xd415c5d1, 0xb43484b0, 0xe82acae2, 0x08090901,\n\t0x74364672, 0x18190911, 0xfc3ecef2, 0x40004040,\n\t0x10120212, 0xe020c0e0, 0xbc3d8db1, 0x04050501,\n\t0xf83acaf2, 0x00010101, 0xf030c0f0, 0x282a0a22,\n\t0x5c1e4e52, 0xa82989a1, 0x54164652, 0x40034343,\n\t0x84058581, 0x14140410, 0x88098981, 0x981b8b93,\n\t0xb03080b0, 0xe425c5e1, 0x48084840, 0x78394971,\n\t0x94178793, 0xfc3cccf0, 0x1c1e0e12, 0x80028282,\n\t0x20210121, 0x8c0c8c80, 0x181b0b13, 0x5c1f4f53,\n\t0x74374773, 0x54144450, 0xb03282b2, 0x1c1d0d11,\n\t0x24250521, 0x4c0f4f43, 0x00000000, 0x44064642,\n\t0xec2dcde1, 0x58184850, 0x50124252, 0xe82bcbe3,\n\t0x7c3e4e72, 0xd81acad2, 0xc809c9c1, 0xfc3dcdf1,\n\t0x30300030, 0x94158591, 0x64254561, 0x3c3c0c30,\n\t0xb43686b2, 0xe424c4e0, 0xb83b8bb3, 0x7c3c4c70,\n\t0x0c0e0e02, 0x50104050, 0x38390931, 0x24260622,\n\t0x30320232, 0x84048480, 0x68294961, 0x90138393,\n\t0x34370733, 0xe427c7e3, 0x24240420, 0xa42484a0,\n\t0xc80bcbc3, 0x50134353, 0x080a0a02, 0x84078783,\n\t0xd819c9d1, 0x4c0c4c40, 0x80038383, 0x8c0f8f83,\n\t0xcc0ecec2, 0x383b0b33, 0x480a4a42, 0xb43787b3,\n};\n\nstatic const u32 SS2[256] = {\n\t0xa1a82989, 0x81840585, 0xd2d416c6, 0xd3d013c3,\n\t0x50541444, 0x111c1d0d, 0xa0ac2c8c, 0x21242505,\n\t0x515c1d4d, 0x43400343, 0x10181808, 0x121c1e0e,\n\t0x51501141, 0xf0fc3ccc, 0xc2c80aca, 0x63602343,\n\t0x20282808, 0x40440444, 0x20202000, 0x919c1d8d,\n\t0xe0e020c0, 0xe2e022c2, 0xc0c808c8, 0x13141707,\n\t0xa1a42585, 0x838c0f8f, 0x03000303, 0x73783b4b,\n\t0xb3b83b8b, 0x13101303, 0xd2d012c2, 0xe2ec2ece,\n\t0x70703040, 0x808c0c8c, 0x333c3f0f, 0xa0a82888,\n\t0x32303202, 0xd1dc1dcd, 0xf2f436c6, 0x70743444,\n\t0xe0ec2ccc, 0x91941585, 0x03080b0b, 0x53541747,\n\t0x505c1c4c, 0x53581b4b, 0xb1bc3d8d, 0x01000101,\n\t0x20242404, 0x101c1c0c, 0x73703343, 0x90981888,\n\t0x10101000, 0xc0cc0ccc, 0xf2f032c2, 0xd1d819c9,\n\t0x202c2c0c, 0xe3e427c7, 0x72703242, 0x83800383,\n\t0x93981b8b, 0xd1d011c1, 0x82840686, 0xc1c809c9,\n\t0x60602040, 0x50501040, 0xa3a02383, 0xe3e82bcb,\n\t0x010c0d0d, 0xb2b43686, 0x929c1e8e, 0x434c0f4f,\n\t0xb3b43787, 0x52581a4a, 0xc2c406c6, 0x70783848,\n\t0xa2a42686, 0x12101202, 0xa3ac2f8f, 0xd1d415c5,\n\t0x61602141, 0xc3c003c3, 0xb0b43484, 0x41400141,\n\t0x52501242, 0x717c3d4d, 0x818c0d8d, 0x00080808,\n\t0x131c1f0f, 0x91981989, 0x00000000, 0x11181909,\n\t0x00040404, 0x53501343, 0xf3f437c7, 0xe1e021c1,\n\t0xf1fc3dcd, 0x72743646, 0x232c2f0f, 0x23242707,\n\t0xb0b03080, 0x83880b8b, 0x020c0e0e, 0xa3a82b8b,\n\t0xa2a02282, 0x626c2e4e, 0x93901383, 0x414c0d4d,\n\t0x61682949, 0x707c3c4c, 0x01080909, 0x02080a0a,\n\t0xb3bc3f8f, 0xe3ec2fcf, 0xf3f033c3, 0xc1c405c5,\n\t0x83840787, 0x10141404, 0xf2fc3ece, 0x60642444,\n\t0xd2dc1ece, 0x222c2e0e, 0x43480b4b, 0x12181a0a,\n\t0x02040606, 0x21202101, 0x63682b4b, 0x62642646,\n\t0x02000202, 0xf1f435c5, 0x92901282, 0x82880a8a,\n\t0x000c0c0c, 0xb3b03383, 0x727c3e4e, 0xd0d010c0,\n\t0x72783a4a, 0x43440747, 0x92941686, 0xe1e425c5,\n\t0x22242606, 0x80800080, 0xa1ac2d8d, 0xd3dc1fcf,\n\t0xa1a02181, 0x30303000, 0x33343707, 0xa2ac2e8e,\n\t0x32343606, 0x11141505, 0x22202202, 0x30383808,\n\t0xf0f434c4, 0xa3a42787, 0x41440545, 0x404c0c4c,\n\t0x81800181, 0xe1e829c9, 0x80840484, 0x93941787,\n\t0x31343505, 0xc3c80bcb, 0xc2cc0ece, 0x303c3c0c,\n\t0x71703141, 0x11101101, 0xc3c407c7, 0x81880989,\n\t0x71743545, 0xf3f83bcb, 0xd2d81aca, 0xf0f838c8,\n\t0x90941484, 0x51581949, 0x82800282, 0xc0c404c4,\n\t0xf3fc3fcf, 0x41480949, 0x31383909, 0x63642747,\n\t0xc0c000c0, 0xc3cc0fcf, 0xd3d417c7, 0xb0b83888,\n\t0x030c0f0f, 0x828c0e8e, 0x42400242, 0x23202303,\n\t0x91901181, 0x606c2c4c, 0xd3d81bcb, 0xa0a42484,\n\t0x30343404, 0xf1f031c1, 0x40480848, 0xc2c002c2,\n\t0x636c2f4f, 0x313c3d0d, 0x212c2d0d, 0x40400040,\n\t0xb2bc3e8e, 0x323c3e0e, 0xb0bc3c8c, 0xc1c001c1,\n\t0xa2a82a8a, 0xb2b83a8a, 0x424c0e4e, 0x51541545,\n\t0x33383b0b, 0xd0dc1ccc, 0x60682848, 0x737c3f4f,\n\t0x909c1c8c, 0xd0d818c8, 0x42480a4a, 0x52541646,\n\t0x73743747, 0xa0a02080, 0xe1ec2dcd, 0x42440646,\n\t0xb1b43585, 0x23282b0b, 0x61642545, 0xf2f83aca,\n\t0xe3e023c3, 0xb1b83989, 0xb1b03181, 0x939c1f8f,\n\t0x525c1e4e, 0xf1f839c9, 0xe2e426c6, 0xb2b03282,\n\t0x31303101, 0xe2e82aca, 0x616c2d4d, 0x535c1f4f,\n\t0xe0e424c4, 0xf0f030c0, 0xc1cc0dcd, 0x80880888,\n\t0x12141606, 0x32383a0a, 0x50581848, 0xd0d414c4,\n\t0x62602242, 0x21282909, 0x03040707, 0x33303303,\n\t0xe0e828c8, 0x13181b0b, 0x01040505, 0x71783949,\n\t0x90901080, 0x62682a4a, 0x22282a0a, 0x92981a8a,\n};\n\nstatic const u32 SS3[256] = {\n\t0x08303838, 0xc8e0e828, 0x0d212c2d, 0x86a2a426,\n\t0xcfc3cc0f, 0xced2dc1e, 0x83b3b033, 0x88b0b838,\n\t0x8fa3ac2f, 0x40606020, 0x45515415, 0xc7c3c407,\n\t0x44404404, 0x4f636c2f, 0x4b63682b, 0x4b53581b,\n\t0xc3c3c003, 0x42626022, 0x03333033, 0x85b1b435,\n\t0x09212829, 0x80a0a020, 0xc2e2e022, 0x87a3a427,\n\t0xc3d3d013, 0x81919011, 0x01111011, 0x06020406,\n\t0x0c101c1c, 0x8cb0bc3c, 0x06323436, 0x4b43480b,\n\t0xcfe3ec2f, 0x88808808, 0x4c606c2c, 0x88a0a828,\n\t0x07131417, 0xc4c0c404, 0x06121416, 0xc4f0f434,\n\t0xc2c2c002, 0x45414405, 0xc1e1e021, 0xc6d2d416,\n\t0x0f333c3f, 0x0d313c3d, 0x8e828c0e, 0x88909818,\n\t0x08202828, 0x4e424c0e, 0xc6f2f436, 0x0e323c3e,\n\t0x85a1a425, 0xc9f1f839, 0x0d010c0d, 0xcfd3dc1f,\n\t0xc8d0d818, 0x0b23282b, 0x46626426, 0x4a72783a,\n\t0x07232427, 0x0f232c2f, 0xc1f1f031, 0x42727032,\n\t0x42424002, 0xc4d0d414, 0x41414001, 0xc0c0c000,\n\t0x43737033, 0x47636427, 0x8ca0ac2c, 0x8b83880b,\n\t0xc7f3f437, 0x8da1ac2d, 0x80808000, 0x0f131c1f,\n\t0xcac2c80a, 0x0c202c2c, 0x8aa2a82a, 0x04303434,\n\t0xc2d2d012, 0x0b03080b, 0xcee2ec2e, 0xc9e1e829,\n\t0x4d515c1d, 0x84909414, 0x08101818, 0xc8f0f838,\n\t0x47535417, 0x8ea2ac2e, 0x08000808, 0xc5c1c405,\n\t0x03131013, 0xcdc1cc0d, 0x86828406, 0x89b1b839,\n\t0xcff3fc3f, 0x4d717c3d, 0xc1c1c001, 0x01313031,\n\t0xc5f1f435, 0x8a82880a, 0x4a62682a, 0x81b1b031,\n\t0xc1d1d011, 0x00202020, 0xc7d3d417, 0x02020002,\n\t0x02222022, 0x04000404, 0x48606828, 0x41717031,\n\t0x07030407, 0xcbd3d81b, 0x8d919c1d, 0x89919819,\n\t0x41616021, 0x8eb2bc3e, 0xc6e2e426, 0x49515819,\n\t0xcdd1dc1d, 0x41515011, 0x80909010, 0xccd0dc1c,\n\t0x8a92981a, 0x83a3a023, 0x8ba3a82b, 0xc0d0d010,\n\t0x81818001, 0x0f030c0f, 0x47434407, 0x0a12181a,\n\t0xc3e3e023, 0xcce0ec2c, 0x8d818c0d, 0x8fb3bc3f,\n\t0x86929416, 0x4b73783b, 0x4c505c1c, 0x82a2a022,\n\t0x81a1a021, 0x43636023, 0x03232023, 0x4d414c0d,\n\t0xc8c0c808, 0x8e929c1e, 0x8c909c1c, 0x0a32383a,\n\t0x0c000c0c, 0x0e222c2e, 0x8ab2b83a, 0x4e626c2e,\n\t0x8f939c1f, 0x4a52581a, 0xc2f2f032, 0x82929012,\n\t0xc3f3f033, 0x49414809, 0x48707838, 0xccc0cc0c,\n\t0x05111415, 0xcbf3f83b, 0x40707030, 0x45717435,\n\t0x4f737c3f, 0x05313435, 0x00101010, 0x03030003,\n\t0x44606424, 0x4d616c2d, 0xc6c2c406, 0x44707434,\n\t0xc5d1d415, 0x84b0b434, 0xcae2e82a, 0x09010809,\n\t0x46727436, 0x09111819, 0xcef2fc3e, 0x40404000,\n\t0x02121012, 0xc0e0e020, 0x8db1bc3d, 0x05010405,\n\t0xcaf2f83a, 0x01010001, 0xc0f0f030, 0x0a22282a,\n\t0x4e525c1e, 0x89a1a829, 0x46525416, 0x43434003,\n\t0x85818405, 0x04101414, 0x89818809, 0x8b93981b,\n\t0x80b0b030, 0xc5e1e425, 0x48404808, 0x49717839,\n\t0x87939417, 0xccf0fc3c, 0x0e121c1e, 0x82828002,\n\t0x01212021, 0x8c808c0c, 0x0b13181b, 0x4f535c1f,\n\t0x47737437, 0x44505414, 0x82b2b032, 0x0d111c1d,\n\t0x05212425, 0x4f434c0f, 0x00000000, 0x46424406,\n\t0xcde1ec2d, 0x48505818, 0x42525012, 0xcbe3e82b,\n\t0x4e727c3e, 0xcad2d81a, 0xc9c1c809, 0xcdf1fc3d,\n\t0x00303030, 0x85919415, 0x45616425, 0x0c303c3c,\n\t0x86b2b436, 0xc4e0e424, 0x8bb3b83b, 0x4c707c3c,\n\t0x0e020c0e, 0x40505010, 0x09313839, 0x06222426,\n\t0x02323032, 0x84808404, 0x49616829, 0x83939013,\n\t0x07333437, 0xc7e3e427, 0x04202424, 0x84a0a424,\n\t0xcbc3c80b, 0x43535013, 0x0a02080a, 0x87838407,\n\t0xc9d1d819, 0x4c404c0c, 0x83838003, 0x8f838c0f,\n\t0xcec2cc0e, 0x0b33383b, 0x4a42480a, 0x87b3b437,\n};\n\nstatic const u32 KC[SEED_NUM_KCONSTANTS] = {\n\t0x9e3779b9, 0x3c6ef373, 0x78dde6e6, 0xf1bbcdcc,\n\t0xe3779b99, 0xc6ef3733, 0x8dde6e67, 0x1bbcdccf,\n\t0x3779b99e, 0x6ef3733c, 0xdde6e678, 0xbbcdccf1,\n\t0x779b99e3, 0xef3733c6, 0xde6e678d, 0xbcdccf1b,\n};\n\n#define OP(X1, X2, X3, X4, rbase)\t\t\t\\\n\tt0 = X3 ^ ks[rbase];\t\t\t\t\\\n\tt1 = X4 ^ ks[rbase+1];\t\t\t\t\\\n\tt1 ^= t0;\t\t\t\t\t\\\n\tt1 = SS0[byte(t1, 0)] ^ SS1[byte(t1, 1)] ^\t\\\n\t\tSS2[byte(t1, 2)] ^ SS3[byte(t1, 3)];\t\\\n\tt0 += t1;\t\t\t\t\t\\\n\tt0 = SS0[byte(t0, 0)] ^ SS1[byte(t0, 1)] ^\t\\\n\t\tSS2[byte(t0, 2)] ^ SS3[byte(t0, 3)];\t\\\n\tt1 += t0;\t\t\t\t\t\\\n\tt1 = SS0[byte(t1, 0)] ^ SS1[byte(t1, 1)] ^\t\\\n\t\tSS2[byte(t1, 2)] ^ SS3[byte(t1, 3)];\t\\\n\tt0 += t1;\t\t\t\t\t\\\n\tX1 ^= t0;\t\t\t\t\t\\\n\tX2 ^= t1;\n\nstatic int seed_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t        unsigned int key_len)\n{\n\tstruct seed_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 *keyout = ctx->keysched;\n\tconst __be32 *key = (const __be32 *)in_key;\n\tu32 i, t0, t1, x1, x2, x3, x4;\n\n\tx1 = be32_to_cpu(key[0]);\n\tx2 = be32_to_cpu(key[1]);\n\tx3 = be32_to_cpu(key[2]);\n\tx4 = be32_to_cpu(key[3]);\n\n\tfor (i = 0; i < SEED_NUM_KCONSTANTS; i++) {\n\t\tt0 = x1 + x3 - KC[i];\n\t\tt1 = x2 + KC[i] - x4;\n\t\t*(keyout++) = SS0[byte(t0, 0)] ^ SS1[byte(t0, 1)] ^\n\t\t\t\tSS2[byte(t0, 2)] ^ SS3[byte(t0, 3)];\n\t\t*(keyout++) = SS0[byte(t1, 0)] ^ SS1[byte(t1, 1)] ^\n\t\t\t\tSS2[byte(t1, 2)] ^ SS3[byte(t1, 3)];\n\n\t\tif (i % 2 == 0) {\n\t\t\tt0 = x1;\n\t\t\tx1 = (x1 >> 8) ^ (x2 << 24);\n\t\t\tx2 = (x2 >> 8) ^ (t0 << 24);\n\t\t} else {\n\t\t\tt0 = x3;\n\t\t\tx3 = (x3 << 8) ^ (x4 >> 24);\n\t\t\tx4 = (x4 << 8) ^ (t0 >> 24);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/* encrypt a block of text */\n\nstatic void seed_encrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tconst struct seed_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __be32 *src = (const __be32 *)in;\n\t__be32 *dst = (__be32 *)out;\n\tu32 x1, x2, x3, x4, t0, t1;\n\tconst u32 *ks = ctx->keysched;\n\n\tx1 = be32_to_cpu(src[0]);\n\tx2 = be32_to_cpu(src[1]);\n\tx3 = be32_to_cpu(src[2]);\n\tx4 = be32_to_cpu(src[3]);\n\n\tOP(x1, x2, x3, x4, 0);\n\tOP(x3, x4, x1, x2, 2);\n\tOP(x1, x2, x3, x4, 4);\n\tOP(x3, x4, x1, x2, 6);\n\tOP(x1, x2, x3, x4, 8);\n\tOP(x3, x4, x1, x2, 10);\n\tOP(x1, x2, x3, x4, 12);\n\tOP(x3, x4, x1, x2, 14);\n\tOP(x1, x2, x3, x4, 16);\n\tOP(x3, x4, x1, x2, 18);\n\tOP(x1, x2, x3, x4, 20);\n\tOP(x3, x4, x1, x2, 22);\n\tOP(x1, x2, x3, x4, 24);\n\tOP(x3, x4, x1, x2, 26);\n\tOP(x1, x2, x3, x4, 28);\n\tOP(x3, x4, x1, x2, 30);\n\n\tdst[0] = cpu_to_be32(x3);\n\tdst[1] = cpu_to_be32(x4);\n\tdst[2] = cpu_to_be32(x1);\n\tdst[3] = cpu_to_be32(x2);\n}\n\n/* decrypt a block of text */\n\nstatic void seed_decrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tconst struct seed_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __be32 *src = (const __be32 *)in;\n\t__be32 *dst = (__be32 *)out;\n\tu32 x1, x2, x3, x4, t0, t1;\n\tconst u32 *ks = ctx->keysched;\n\n\tx1 = be32_to_cpu(src[0]);\n\tx2 = be32_to_cpu(src[1]);\n\tx3 = be32_to_cpu(src[2]);\n\tx4 = be32_to_cpu(src[3]);\n\n\tOP(x1, x2, x3, x4, 30);\n\tOP(x3, x4, x1, x2, 28);\n\tOP(x1, x2, x3, x4, 26);\n\tOP(x3, x4, x1, x2, 24);\n\tOP(x1, x2, x3, x4, 22);\n\tOP(x3, x4, x1, x2, 20);\n\tOP(x1, x2, x3, x4, 18);\n\tOP(x3, x4, x1, x2, 16);\n\tOP(x1, x2, x3, x4, 14);\n\tOP(x3, x4, x1, x2, 12);\n\tOP(x1, x2, x3, x4, 10);\n\tOP(x3, x4, x1, x2, 8);\n\tOP(x1, x2, x3, x4, 6);\n\tOP(x3, x4, x1, x2, 4);\n\tOP(x1, x2, x3, x4, 2);\n\tOP(x3, x4, x1, x2, 0);\n\n\tdst[0] = cpu_to_be32(x3);\n\tdst[1] = cpu_to_be32(x4);\n\tdst[2] = cpu_to_be32(x1);\n\tdst[3] = cpu_to_be32(x2);\n}\n\n\nstatic struct crypto_alg seed_alg = {\n\t.cra_name\t\t=\t\"seed\",\n\t.cra_driver_name\t=\t\"seed-generic\",\n\t.cra_priority\t\t=\t100,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tSEED_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct seed_ctx),\n\t.cra_alignmask\t\t=\t3,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.cipher = {\n\t\t\t.cia_min_keysize\t=\tSEED_KEY_SIZE,\n\t\t\t.cia_max_keysize\t=\tSEED_KEY_SIZE,\n\t\t\t.cia_setkey\t\t=\tseed_set_key,\n\t\t\t.cia_encrypt\t\t=\tseed_encrypt,\n\t\t\t.cia_decrypt\t\t=\tseed_decrypt\n\t\t}\n\t}\n};\n\nstatic int __init seed_init(void)\n{\n\treturn crypto_register_alg(&seed_alg);\n}\n\nstatic void __exit seed_fini(void)\n{\n\tcrypto_unregister_alg(&seed_alg);\n}\n\nmodule_init(seed_init);\nmodule_exit(seed_fini);\n\nMODULE_DESCRIPTION(\"SEED Cipher Algorithm\");\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Hye-Shik Chang <perky@FreeBSD.org>, Kim Hyun <hkim@kisa.or.kr>\");\n", "/*\n * Cryptographic API.\n *\n * Serpent Cipher Algorithm.\n *\n * Copyright (C) 2002 Dag Arne Osvik <osvik@ii.uib.no>\n *               2003 Herbert Valerio Riedel <hvr@gnu.org>\n *\n * Added tnepres support:\n *\t\tRuben Jesus Garcia Hernandez <ruben@ugr.es>, 18.10.2004\n *              Based on code by hvr\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n */\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <asm/byteorder.h>\n#include <linux/crypto.h>\n#include <linux/types.h>\n#include <crypto/serpent.h>\n\n/* Key is padded to the maximum of 256 bits before round key generation.\n * Any key length <= 256 bits (32 bytes) is allowed by the algorithm.\n */\n\n#define PHI 0x9e3779b9UL\n\n#define keyiter(a, b, c, d, i, j) \\\n\t({ b ^= d; b ^= c; b ^= a; b ^= PHI ^ i; b = rol32(b, 11); k[j] = b; })\n\n#define loadkeys(x0, x1, x2, x3, i) \\\n\t({ x0 = k[i]; x1 = k[i+1]; x2 = k[i+2]; x3 = k[i+3]; })\n\n#define storekeys(x0, x1, x2, x3, i) \\\n\t({ k[i] = x0; k[i+1] = x1; k[i+2] = x2; k[i+3] = x3; })\n\n#define store_and_load_keys(x0, x1, x2, x3, s, l) \\\n\t({ storekeys(x0, x1, x2, x3, s); loadkeys(x0, x1, x2, x3, l); })\n\n#define K(x0, x1, x2, x3, i) ({\t\t\t\t\\\n\tx3 ^= k[4*(i)+3];        x2 ^= k[4*(i)+2];\t\\\n\tx1 ^= k[4*(i)+1];        x0 ^= k[4*(i)+0];\t\\\n\t})\n\n#define LK(x0, x1, x2, x3, x4, i) ({\t\t\t\t\t   \\\n\t\t\t\t\t\t\tx0 = rol32(x0, 13);\\\n\tx2 = rol32(x2, 3);\tx1 ^= x0;\t\tx4  = x0 << 3;\t   \\\n\tx3 ^= x2;\t\tx1 ^= x2;\t\t\t\t   \\\n\tx1 = rol32(x1, 1);\tx3 ^= x4;\t\t\t\t   \\\n\tx3 = rol32(x3, 7);\tx4  = x1;\t\t\t\t   \\\n\tx0 ^= x1;\t\tx4 <<= 7;\t\tx2 ^= x3;\t   \\\n\tx0 ^= x3;\t\tx2 ^= x4;\t\tx3 ^= k[4*i+3];\t   \\\n\tx1 ^= k[4*i+1];\t\tx0 = rol32(x0, 5);\tx2 = rol32(x2, 22);\\\n\tx0 ^= k[4*i+0];\t\tx2 ^= k[4*i+2];\t\t\t\t   \\\n\t})\n\n#define KL(x0, x1, x2, x3, x4, i) ({\t\t\t\t\t   \\\n\tx0 ^= k[4*i+0];\t\tx1 ^= k[4*i+1];\t\tx2 ^= k[4*i+2];\t   \\\n\tx3 ^= k[4*i+3];\t\tx0 = ror32(x0, 5);\tx2 = ror32(x2, 22);\\\n\tx4 =  x1;\t\tx2 ^= x3;\t\tx0 ^= x3;\t   \\\n\tx4 <<= 7;\t\tx0 ^= x1;\t\tx1 = ror32(x1, 1); \\\n\tx2 ^= x4;\t\tx3 = ror32(x3, 7);\tx4 = x0 << 3;\t   \\\n\tx1 ^= x0;\t\tx3 ^= x4;\t\tx0 = ror32(x0, 13);\\\n\tx1 ^= x2;\t\tx3 ^= x2;\t\tx2 = ror32(x2, 3); \\\n\t})\n\n#define S0(x0, x1, x2, x3, x4) ({\t\t\t\\\n\t\t\t\t\tx4  = x3;\t\\\n\tx3 |= x0;\tx0 ^= x4;\tx4 ^= x2;\t\\\n\tx4 = ~x4;\tx3 ^= x1;\tx1 &= x0;\t\\\n\tx1 ^= x4;\tx2 ^= x0;\tx0 ^= x3;\t\\\n\tx4 |= x0;\tx0 ^= x2;\tx2 &= x1;\t\\\n\tx3 ^= x2;\tx1 = ~x1;\tx2 ^= x4;\t\\\n\tx1 ^= x2;\t\t\t\t\t\\\n\t})\n\n#define S1(x0, x1, x2, x3, x4) ({\t\t\t\\\n\t\t\t\t\tx4  = x1;\t\\\n\tx1 ^= x0;\tx0 ^= x3;\tx3 = ~x3;\t\\\n\tx4 &= x1;\tx0 |= x1;\tx3 ^= x2;\t\\\n\tx0 ^= x3;\tx1 ^= x3;\tx3 ^= x4;\t\\\n\tx1 |= x4;\tx4 ^= x2;\tx2 &= x0;\t\\\n\tx2 ^= x1;\tx1 |= x0;\tx0 = ~x0;\t\\\n\tx0 ^= x2;\tx4 ^= x1;\t\t\t\\\n\t})\n\n#define S2(x0, x1, x2, x3, x4) ({\t\t\t\\\n\t\t\t\t\tx3 = ~x3;\t\\\n\tx1 ^= x0;\tx4  = x0;\tx0 &= x2;\t\\\n\tx0 ^= x3;\tx3 |= x4;\tx2 ^= x1;\t\\\n\tx3 ^= x1;\tx1 &= x0;\tx0 ^= x2;\t\\\n\tx2 &= x3;\tx3 |= x1;\tx0 = ~x0;\t\\\n\tx3 ^= x0;\tx4 ^= x0;\tx0 ^= x2;\t\\\n\tx1 |= x2;\t\t\t\t\t\\\n\t})\n\n#define S3(x0, x1, x2, x3, x4) ({\t\t\t\\\n\t\t\t\t\tx4  = x1;\t\\\n\tx1 ^= x3;\tx3 |= x0;\tx4 &= x0;\t\\\n\tx0 ^= x2;\tx2 ^= x1;\tx1 &= x3;\t\\\n\tx2 ^= x3;\tx0 |= x4;\tx4 ^= x3;\t\\\n\tx1 ^= x0;\tx0 &= x3;\tx3 &= x4;\t\\\n\tx3 ^= x2;\tx4 |= x1;\tx2 &= x1;\t\\\n\tx4 ^= x3;\tx0 ^= x3;\tx3 ^= x2;\t\\\n\t})\n\n#define S4(x0, x1, x2, x3, x4) ({\t\t\t\\\n\t\t\t\t\tx4  = x3;\t\\\n\tx3 &= x0;\tx0 ^= x4;\t\t\t\\\n\tx3 ^= x2;\tx2 |= x4;\tx0 ^= x1;\t\\\n\tx4 ^= x3;\tx2 |= x0;\t\t\t\\\n\tx2 ^= x1;\tx1 &= x0;\t\t\t\\\n\tx1 ^= x4;\tx4 &= x2;\tx2 ^= x3;\t\\\n\tx4 ^= x0;\tx3 |= x1;\tx1 = ~x1;\t\\\n\tx3 ^= x0;\t\t\t\t\t\\\n\t})\n\n#define S5(x0, x1, x2, x3, x4) ({\t\t\t\\\n\tx4  = x1;\tx1 |= x0;\t\t\t\\\n\tx2 ^= x1;\tx3 = ~x3;\tx4 ^= x0;\t\\\n\tx0 ^= x2;\tx1 &= x4;\tx4 |= x3;\t\\\n\tx4 ^= x0;\tx0 &= x3;\tx1 ^= x3;\t\\\n\tx3 ^= x2;\tx0 ^= x1;\tx2 &= x4;\t\\\n\tx1 ^= x2;\tx2 &= x0;\t\t\t\\\n\tx3 ^= x2;\t\t\t\t\t\\\n\t})\n\n#define S6(x0, x1, x2, x3, x4) ({\t\t\t\\\n\t\t\t\t\tx4  = x1;\t\\\n\tx3 ^= x0;\tx1 ^= x2;\tx2 ^= x0;\t\\\n\tx0 &= x3;\tx1 |= x3;\tx4 = ~x4;\t\\\n\tx0 ^= x1;\tx1 ^= x2;\t\t\t\\\n\tx3 ^= x4;\tx4 ^= x0;\tx2 &= x0;\t\\\n\tx4 ^= x1;\tx2 ^= x3;\tx3 &= x1;\t\\\n\tx3 ^= x0;\tx1 ^= x2;\t\t\t\\\n\t})\n\n#define S7(x0, x1, x2, x3, x4) ({\t\t\t\\\n\t\t\t\t\tx1 = ~x1;\t\\\n\tx4  = x1;\tx0 = ~x0;\tx1 &= x2;\t\\\n\tx1 ^= x3;\tx3 |= x4;\tx4 ^= x2;\t\\\n\tx2 ^= x3;\tx3 ^= x0;\tx0 |= x1;\t\\\n\tx2 &= x0;\tx0 ^= x4;\tx4 ^= x3;\t\\\n\tx3 &= x0;\tx4 ^= x1;\t\t\t\\\n\tx2 ^= x4;\tx3 ^= x1;\tx4 |= x0;\t\\\n\tx4 ^= x1;\t\t\t\t\t\\\n\t})\n\n#define SI0(x0, x1, x2, x3, x4) ({\t\t\t\\\n\t\t\tx4  = x3;\tx1 ^= x0;\t\\\n\tx3 |= x1;\tx4 ^= x1;\tx0 = ~x0;\t\\\n\tx2 ^= x3;\tx3 ^= x0;\tx0 &= x1;\t\\\n\tx0 ^= x2;\tx2 &= x3;\tx3 ^= x4;\t\\\n\tx2 ^= x3;\tx1 ^= x3;\tx3 &= x0;\t\\\n\tx1 ^= x0;\tx0 ^= x2;\tx4 ^= x3;\t\\\n\t})\n\n#define SI1(x0, x1, x2, x3, x4) ({\t\t\t\\\n\tx1 ^= x3;\tx4  = x0;\t\t\t\\\n\tx0 ^= x2;\tx2 = ~x2;\tx4 |= x1;\t\\\n\tx4 ^= x3;\tx3 &= x1;\tx1 ^= x2;\t\\\n\tx2 &= x4;\tx4 ^= x1;\tx1 |= x3;\t\\\n\tx3 ^= x0;\tx2 ^= x0;\tx0 |= x4;\t\\\n\tx2 ^= x4;\tx1 ^= x0;\t\t\t\\\n\tx4 ^= x1;\t\t\t\t\t\\\n\t})\n\n#define SI2(x0, x1, x2, x3, x4) ({\t\t\t\\\n\tx2 ^= x1;\tx4  = x3;\tx3 = ~x3;\t\\\n\tx3 |= x2;\tx2 ^= x4;\tx4 ^= x0;\t\\\n\tx3 ^= x1;\tx1 |= x2;\tx2 ^= x0;\t\\\n\tx1 ^= x4;\tx4 |= x3;\tx2 ^= x3;\t\\\n\tx4 ^= x2;\tx2 &= x1;\t\t\t\\\n\tx2 ^= x3;\tx3 ^= x4;\tx4 ^= x0;\t\\\n\t})\n\n#define SI3(x0, x1, x2, x3, x4) ({\t\t\t\\\n\t\t\t\t\tx2 ^= x1;\t\\\n\tx4  = x1;\tx1 &= x2;\t\t\t\\\n\tx1 ^= x0;\tx0 |= x4;\tx4 ^= x3;\t\\\n\tx0 ^= x3;\tx3 |= x1;\tx1 ^= x2;\t\\\n\tx1 ^= x3;\tx0 ^= x2;\tx2 ^= x3;\t\\\n\tx3 &= x1;\tx1 ^= x0;\tx0 &= x2;\t\\\n\tx4 ^= x3;\tx3 ^= x0;\tx0 ^= x1;\t\\\n\t})\n\n#define SI4(x0, x1, x2, x3, x4) ({\t\t\t\\\n\tx2 ^= x3;\tx4  = x0;\tx0 &= x1;\t\\\n\tx0 ^= x2;\tx2 |= x3;\tx4 = ~x4;\t\\\n\tx1 ^= x0;\tx0 ^= x2;\tx2 &= x4;\t\\\n\tx2 ^= x0;\tx0 |= x4;\t\t\t\\\n\tx0 ^= x3;\tx3 &= x2;\t\t\t\\\n\tx4 ^= x3;\tx3 ^= x1;\tx1 &= x0;\t\\\n\tx4 ^= x1;\tx0 ^= x3;\t\t\t\\\n\t})\n\n#define SI5(x0, x1, x2, x3, x4) ({\t\t\t\\\n\t\t\tx4  = x1;\tx1 |= x2;\t\\\n\tx2 ^= x4;\tx1 ^= x3;\tx3 &= x4;\t\\\n\tx2 ^= x3;\tx3 |= x0;\tx0 = ~x0;\t\\\n\tx3 ^= x2;\tx2 |= x0;\tx4 ^= x1;\t\\\n\tx2 ^= x4;\tx4 &= x0;\tx0 ^= x1;\t\\\n\tx1 ^= x3;\tx0 &= x2;\tx2 ^= x3;\t\\\n\tx0 ^= x2;\tx2 ^= x4;\tx4 ^= x3;\t\\\n\t})\n\n#define SI6(x0, x1, x2, x3, x4) ({\t\t\t\\\n\t\t\tx0 ^= x2;\t\t\t\\\n\tx4  = x0;\tx0 &= x3;\tx2 ^= x3;\t\\\n\tx0 ^= x2;\tx3 ^= x1;\tx2 |= x4;\t\\\n\tx2 ^= x3;\tx3 &= x0;\tx0 = ~x0;\t\\\n\tx3 ^= x1;\tx1 &= x2;\tx4 ^= x0;\t\\\n\tx3 ^= x4;\tx4 ^= x2;\tx0 ^= x1;\t\\\n\tx2 ^= x0;\t\t\t\t\t\\\n\t})\n\n#define SI7(x0, x1, x2, x3, x4) ({\t\t\t\\\n\tx4  = x3;\tx3 &= x0;\tx0 ^= x2;\t\\\n\tx2 |= x4;\tx4 ^= x1;\tx0 = ~x0;\t\\\n\tx1 |= x3;\tx4 ^= x0;\tx0 &= x2;\t\\\n\tx0 ^= x1;\tx1 &= x2;\tx3 ^= x2;\t\\\n\tx4 ^= x3;\tx2 &= x3;\tx3 |= x0;\t\\\n\tx1 ^= x4;\tx3 ^= x4;\tx4 &= x0;\t\\\n\tx4 ^= x2;\t\t\t\t\t\\\n\t})\n\nint __serpent_setkey(struct serpent_ctx *ctx, const u8 *key,\n\t\t     unsigned int keylen)\n{\n\tu32 *k = ctx->expkey;\n\tu8  *k8 = (u8 *)k;\n\tu32 r0, r1, r2, r3, r4;\n\tint i;\n\n\t/* Copy key, add padding */\n\n\tfor (i = 0; i < keylen; ++i)\n\t\tk8[i] = key[i];\n\tif (i < SERPENT_MAX_KEY_SIZE)\n\t\tk8[i++] = 1;\n\twhile (i < SERPENT_MAX_KEY_SIZE)\n\t\tk8[i++] = 0;\n\n\t/* Expand key using polynomial */\n\n\tr0 = le32_to_cpu(k[3]);\n\tr1 = le32_to_cpu(k[4]);\n\tr2 = le32_to_cpu(k[5]);\n\tr3 = le32_to_cpu(k[6]);\n\tr4 = le32_to_cpu(k[7]);\n\n\tkeyiter(le32_to_cpu(k[0]), r0, r4, r2, 0, 0);\n\tkeyiter(le32_to_cpu(k[1]), r1, r0, r3, 1, 1);\n\tkeyiter(le32_to_cpu(k[2]), r2, r1, r4, 2, 2);\n\tkeyiter(le32_to_cpu(k[3]), r3, r2, r0, 3, 3);\n\tkeyiter(le32_to_cpu(k[4]), r4, r3, r1, 4, 4);\n\tkeyiter(le32_to_cpu(k[5]), r0, r4, r2, 5, 5);\n\tkeyiter(le32_to_cpu(k[6]), r1, r0, r3, 6, 6);\n\tkeyiter(le32_to_cpu(k[7]), r2, r1, r4, 7, 7);\n\n\tkeyiter(k[0], r3, r2, r0, 8, 8);\n\tkeyiter(k[1], r4, r3, r1, 9, 9);\n\tkeyiter(k[2], r0, r4, r2, 10, 10);\n\tkeyiter(k[3], r1, r0, r3, 11, 11);\n\tkeyiter(k[4], r2, r1, r4, 12, 12);\n\tkeyiter(k[5], r3, r2, r0, 13, 13);\n\tkeyiter(k[6], r4, r3, r1, 14, 14);\n\tkeyiter(k[7], r0, r4, r2, 15, 15);\n\tkeyiter(k[8], r1, r0, r3, 16, 16);\n\tkeyiter(k[9], r2, r1, r4, 17, 17);\n\tkeyiter(k[10], r3, r2, r0, 18, 18);\n\tkeyiter(k[11], r4, r3, r1, 19, 19);\n\tkeyiter(k[12], r0, r4, r2, 20, 20);\n\tkeyiter(k[13], r1, r0, r3, 21, 21);\n\tkeyiter(k[14], r2, r1, r4, 22, 22);\n\tkeyiter(k[15], r3, r2, r0, 23, 23);\n\tkeyiter(k[16], r4, r3, r1, 24, 24);\n\tkeyiter(k[17], r0, r4, r2, 25, 25);\n\tkeyiter(k[18], r1, r0, r3, 26, 26);\n\tkeyiter(k[19], r2, r1, r4, 27, 27);\n\tkeyiter(k[20], r3, r2, r0, 28, 28);\n\tkeyiter(k[21], r4, r3, r1, 29, 29);\n\tkeyiter(k[22], r0, r4, r2, 30, 30);\n\tkeyiter(k[23], r1, r0, r3, 31, 31);\n\n\tk += 50;\n\n\tkeyiter(k[-26], r2, r1, r4, 32, -18);\n\tkeyiter(k[-25], r3, r2, r0, 33, -17);\n\tkeyiter(k[-24], r4, r3, r1, 34, -16);\n\tkeyiter(k[-23], r0, r4, r2, 35, -15);\n\tkeyiter(k[-22], r1, r0, r3, 36, -14);\n\tkeyiter(k[-21], r2, r1, r4, 37, -13);\n\tkeyiter(k[-20], r3, r2, r0, 38, -12);\n\tkeyiter(k[-19], r4, r3, r1, 39, -11);\n\tkeyiter(k[-18], r0, r4, r2, 40, -10);\n\tkeyiter(k[-17], r1, r0, r3, 41, -9);\n\tkeyiter(k[-16], r2, r1, r4, 42, -8);\n\tkeyiter(k[-15], r3, r2, r0, 43, -7);\n\tkeyiter(k[-14], r4, r3, r1, 44, -6);\n\tkeyiter(k[-13], r0, r4, r2, 45, -5);\n\tkeyiter(k[-12], r1, r0, r3, 46, -4);\n\tkeyiter(k[-11], r2, r1, r4, 47, -3);\n\tkeyiter(k[-10], r3, r2, r0, 48, -2);\n\tkeyiter(k[-9], r4, r3, r1, 49, -1);\n\tkeyiter(k[-8], r0, r4, r2, 50, 0);\n\tkeyiter(k[-7], r1, r0, r3, 51, 1);\n\tkeyiter(k[-6], r2, r1, r4, 52, 2);\n\tkeyiter(k[-5], r3, r2, r0, 53, 3);\n\tkeyiter(k[-4], r4, r3, r1, 54, 4);\n\tkeyiter(k[-3], r0, r4, r2, 55, 5);\n\tkeyiter(k[-2], r1, r0, r3, 56, 6);\n\tkeyiter(k[-1], r2, r1, r4, 57, 7);\n\tkeyiter(k[0], r3, r2, r0, 58, 8);\n\tkeyiter(k[1], r4, r3, r1, 59, 9);\n\tkeyiter(k[2], r0, r4, r2, 60, 10);\n\tkeyiter(k[3], r1, r0, r3, 61, 11);\n\tkeyiter(k[4], r2, r1, r4, 62, 12);\n\tkeyiter(k[5], r3, r2, r0, 63, 13);\n\tkeyiter(k[6], r4, r3, r1, 64, 14);\n\tkeyiter(k[7], r0, r4, r2, 65, 15);\n\tkeyiter(k[8], r1, r0, r3, 66, 16);\n\tkeyiter(k[9], r2, r1, r4, 67, 17);\n\tkeyiter(k[10], r3, r2, r0, 68, 18);\n\tkeyiter(k[11], r4, r3, r1, 69, 19);\n\tkeyiter(k[12], r0, r4, r2, 70, 20);\n\tkeyiter(k[13], r1, r0, r3, 71, 21);\n\tkeyiter(k[14], r2, r1, r4, 72, 22);\n\tkeyiter(k[15], r3, r2, r0, 73, 23);\n\tkeyiter(k[16], r4, r3, r1, 74, 24);\n\tkeyiter(k[17], r0, r4, r2, 75, 25);\n\tkeyiter(k[18], r1, r0, r3, 76, 26);\n\tkeyiter(k[19], r2, r1, r4, 77, 27);\n\tkeyiter(k[20], r3, r2, r0, 78, 28);\n\tkeyiter(k[21], r4, r3, r1, 79, 29);\n\tkeyiter(k[22], r0, r4, r2, 80, 30);\n\tkeyiter(k[23], r1, r0, r3, 81, 31);\n\n\tk += 50;\n\n\tkeyiter(k[-26], r2, r1, r4, 82, -18);\n\tkeyiter(k[-25], r3, r2, r0, 83, -17);\n\tkeyiter(k[-24], r4, r3, r1, 84, -16);\n\tkeyiter(k[-23], r0, r4, r2, 85, -15);\n\tkeyiter(k[-22], r1, r0, r3, 86, -14);\n\tkeyiter(k[-21], r2, r1, r4, 87, -13);\n\tkeyiter(k[-20], r3, r2, r0, 88, -12);\n\tkeyiter(k[-19], r4, r3, r1, 89, -11);\n\tkeyiter(k[-18], r0, r4, r2, 90, -10);\n\tkeyiter(k[-17], r1, r0, r3, 91, -9);\n\tkeyiter(k[-16], r2, r1, r4, 92, -8);\n\tkeyiter(k[-15], r3, r2, r0, 93, -7);\n\tkeyiter(k[-14], r4, r3, r1, 94, -6);\n\tkeyiter(k[-13], r0, r4, r2, 95, -5);\n\tkeyiter(k[-12], r1, r0, r3, 96, -4);\n\tkeyiter(k[-11], r2, r1, r4, 97, -3);\n\tkeyiter(k[-10], r3, r2, r0, 98, -2);\n\tkeyiter(k[-9], r4, r3, r1, 99, -1);\n\tkeyiter(k[-8], r0, r4, r2, 100, 0);\n\tkeyiter(k[-7], r1, r0, r3, 101, 1);\n\tkeyiter(k[-6], r2, r1, r4, 102, 2);\n\tkeyiter(k[-5], r3, r2, r0, 103, 3);\n\tkeyiter(k[-4], r4, r3, r1, 104, 4);\n\tkeyiter(k[-3], r0, r4, r2, 105, 5);\n\tkeyiter(k[-2], r1, r0, r3, 106, 6);\n\tkeyiter(k[-1], r2, r1, r4, 107, 7);\n\tkeyiter(k[0], r3, r2, r0, 108, 8);\n\tkeyiter(k[1], r4, r3, r1, 109, 9);\n\tkeyiter(k[2], r0, r4, r2, 110, 10);\n\tkeyiter(k[3], r1, r0, r3, 111, 11);\n\tkeyiter(k[4], r2, r1, r4, 112, 12);\n\tkeyiter(k[5], r3, r2, r0, 113, 13);\n\tkeyiter(k[6], r4, r3, r1, 114, 14);\n\tkeyiter(k[7], r0, r4, r2, 115, 15);\n\tkeyiter(k[8], r1, r0, r3, 116, 16);\n\tkeyiter(k[9], r2, r1, r4, 117, 17);\n\tkeyiter(k[10], r3, r2, r0, 118, 18);\n\tkeyiter(k[11], r4, r3, r1, 119, 19);\n\tkeyiter(k[12], r0, r4, r2, 120, 20);\n\tkeyiter(k[13], r1, r0, r3, 121, 21);\n\tkeyiter(k[14], r2, r1, r4, 122, 22);\n\tkeyiter(k[15], r3, r2, r0, 123, 23);\n\tkeyiter(k[16], r4, r3, r1, 124, 24);\n\tkeyiter(k[17], r0, r4, r2, 125, 25);\n\tkeyiter(k[18], r1, r0, r3, 126, 26);\n\tkeyiter(k[19], r2, r1, r4, 127, 27);\n\tkeyiter(k[20], r3, r2, r0, 128, 28);\n\tkeyiter(k[21], r4, r3, r1, 129, 29);\n\tkeyiter(k[22], r0, r4, r2, 130, 30);\n\tkeyiter(k[23], r1, r0, r3, 131, 31);\n\n\t/* Apply S-boxes */\n\n\tS3(r3, r4, r0, r1, r2); store_and_load_keys(r1, r2, r4, r3, 28, 24);\n\tS4(r1, r2, r4, r3, r0); store_and_load_keys(r2, r4, r3, r0, 24, 20);\n\tS5(r2, r4, r3, r0, r1); store_and_load_keys(r1, r2, r4, r0, 20, 16);\n\tS6(r1, r2, r4, r0, r3); store_and_load_keys(r4, r3, r2, r0, 16, 12);\n\tS7(r4, r3, r2, r0, r1); store_and_load_keys(r1, r2, r0, r4, 12, 8);\n\tS0(r1, r2, r0, r4, r3); store_and_load_keys(r0, r2, r4, r1, 8, 4);\n\tS1(r0, r2, r4, r1, r3); store_and_load_keys(r3, r4, r1, r0, 4, 0);\n\tS2(r3, r4, r1, r0, r2); store_and_load_keys(r2, r4, r3, r0, 0, -4);\n\tS3(r2, r4, r3, r0, r1); store_and_load_keys(r0, r1, r4, r2, -4, -8);\n\tS4(r0, r1, r4, r2, r3); store_and_load_keys(r1, r4, r2, r3, -8, -12);\n\tS5(r1, r4, r2, r3, r0); store_and_load_keys(r0, r1, r4, r3, -12, -16);\n\tS6(r0, r1, r4, r3, r2); store_and_load_keys(r4, r2, r1, r3, -16, -20);\n\tS7(r4, r2, r1, r3, r0); store_and_load_keys(r0, r1, r3, r4, -20, -24);\n\tS0(r0, r1, r3, r4, r2); store_and_load_keys(r3, r1, r4, r0, -24, -28);\n\tk -= 50;\n\tS1(r3, r1, r4, r0, r2); store_and_load_keys(r2, r4, r0, r3, 22, 18);\n\tS2(r2, r4, r0, r3, r1); store_and_load_keys(r1, r4, r2, r3, 18, 14);\n\tS3(r1, r4, r2, r3, r0); store_and_load_keys(r3, r0, r4, r1, 14, 10);\n\tS4(r3, r0, r4, r1, r2); store_and_load_keys(r0, r4, r1, r2, 10, 6);\n\tS5(r0, r4, r1, r2, r3); store_and_load_keys(r3, r0, r4, r2, 6, 2);\n\tS6(r3, r0, r4, r2, r1); store_and_load_keys(r4, r1, r0, r2, 2, -2);\n\tS7(r4, r1, r0, r2, r3); store_and_load_keys(r3, r0, r2, r4, -2, -6);\n\tS0(r3, r0, r2, r4, r1); store_and_load_keys(r2, r0, r4, r3, -6, -10);\n\tS1(r2, r0, r4, r3, r1); store_and_load_keys(r1, r4, r3, r2, -10, -14);\n\tS2(r1, r4, r3, r2, r0); store_and_load_keys(r0, r4, r1, r2, -14, -18);\n\tS3(r0, r4, r1, r2, r3); store_and_load_keys(r2, r3, r4, r0, -18, -22);\n\tk -= 50;\n\tS4(r2, r3, r4, r0, r1); store_and_load_keys(r3, r4, r0, r1, 28, 24);\n\tS5(r3, r4, r0, r1, r2); store_and_load_keys(r2, r3, r4, r1, 24, 20);\n\tS6(r2, r3, r4, r1, r0); store_and_load_keys(r4, r0, r3, r1, 20, 16);\n\tS7(r4, r0, r3, r1, r2); store_and_load_keys(r2, r3, r1, r4, 16, 12);\n\tS0(r2, r3, r1, r4, r0); store_and_load_keys(r1, r3, r4, r2, 12, 8);\n\tS1(r1, r3, r4, r2, r0); store_and_load_keys(r0, r4, r2, r1, 8, 4);\n\tS2(r0, r4, r2, r1, r3); store_and_load_keys(r3, r4, r0, r1, 4, 0);\n\tS3(r3, r4, r0, r1, r2); storekeys(r1, r2, r4, r3, 0);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(__serpent_setkey);\n\nint serpent_setkey(struct crypto_tfm *tfm, const u8 *key, unsigned int keylen)\n{\n\treturn __serpent_setkey(crypto_tfm_ctx(tfm), key, keylen);\n}\nEXPORT_SYMBOL_GPL(serpent_setkey);\n\nvoid __serpent_encrypt(struct serpent_ctx *ctx, u8 *dst, const u8 *src)\n{\n\tconst u32 *k = ctx->expkey;\n\tconst __le32 *s = (const __le32 *)src;\n\t__le32\t*d = (__le32 *)dst;\n\tu32\tr0, r1, r2, r3, r4;\n\n/*\n * Note: The conversions between u8* and u32* might cause trouble\n * on architectures with stricter alignment rules than x86\n */\n\n\tr0 = le32_to_cpu(s[0]);\n\tr1 = le32_to_cpu(s[1]);\n\tr2 = le32_to_cpu(s[2]);\n\tr3 = le32_to_cpu(s[3]);\n\n\t\t\t\t\tK(r0, r1, r2, r3, 0);\n\tS0(r0, r1, r2, r3, r4);\t\tLK(r2, r1, r3, r0, r4, 1);\n\tS1(r2, r1, r3, r0, r4);\t\tLK(r4, r3, r0, r2, r1, 2);\n\tS2(r4, r3, r0, r2, r1);\t\tLK(r1, r3, r4, r2, r0, 3);\n\tS3(r1, r3, r4, r2, r0);\t\tLK(r2, r0, r3, r1, r4, 4);\n\tS4(r2, r0, r3, r1, r4);\t\tLK(r0, r3, r1, r4, r2, 5);\n\tS5(r0, r3, r1, r4, r2);\t\tLK(r2, r0, r3, r4, r1, 6);\n\tS6(r2, r0, r3, r4, r1);\t\tLK(r3, r1, r0, r4, r2, 7);\n\tS7(r3, r1, r0, r4, r2);\t\tLK(r2, r0, r4, r3, r1, 8);\n\tS0(r2, r0, r4, r3, r1);\t\tLK(r4, r0, r3, r2, r1, 9);\n\tS1(r4, r0, r3, r2, r1);\t\tLK(r1, r3, r2, r4, r0, 10);\n\tS2(r1, r3, r2, r4, r0);\t\tLK(r0, r3, r1, r4, r2, 11);\n\tS3(r0, r3, r1, r4, r2);\t\tLK(r4, r2, r3, r0, r1, 12);\n\tS4(r4, r2, r3, r0, r1);\t\tLK(r2, r3, r0, r1, r4, 13);\n\tS5(r2, r3, r0, r1, r4);\t\tLK(r4, r2, r3, r1, r0, 14);\n\tS6(r4, r2, r3, r1, r0);\t\tLK(r3, r0, r2, r1, r4, 15);\n\tS7(r3, r0, r2, r1, r4);\t\tLK(r4, r2, r1, r3, r0, 16);\n\tS0(r4, r2, r1, r3, r0);\t\tLK(r1, r2, r3, r4, r0, 17);\n\tS1(r1, r2, r3, r4, r0);\t\tLK(r0, r3, r4, r1, r2, 18);\n\tS2(r0, r3, r4, r1, r2);\t\tLK(r2, r3, r0, r1, r4, 19);\n\tS3(r2, r3, r0, r1, r4);\t\tLK(r1, r4, r3, r2, r0, 20);\n\tS4(r1, r4, r3, r2, r0);\t\tLK(r4, r3, r2, r0, r1, 21);\n\tS5(r4, r3, r2, r0, r1);\t\tLK(r1, r4, r3, r0, r2, 22);\n\tS6(r1, r4, r3, r0, r2);\t\tLK(r3, r2, r4, r0, r1, 23);\n\tS7(r3, r2, r4, r0, r1);\t\tLK(r1, r4, r0, r3, r2, 24);\n\tS0(r1, r4, r0, r3, r2);\t\tLK(r0, r4, r3, r1, r2, 25);\n\tS1(r0, r4, r3, r1, r2);\t\tLK(r2, r3, r1, r0, r4, 26);\n\tS2(r2, r3, r1, r0, r4);\t\tLK(r4, r3, r2, r0, r1, 27);\n\tS3(r4, r3, r2, r0, r1);\t\tLK(r0, r1, r3, r4, r2, 28);\n\tS4(r0, r1, r3, r4, r2);\t\tLK(r1, r3, r4, r2, r0, 29);\n\tS5(r1, r3, r4, r2, r0);\t\tLK(r0, r1, r3, r2, r4, 30);\n\tS6(r0, r1, r3, r2, r4);\t\tLK(r3, r4, r1, r2, r0, 31);\n\tS7(r3, r4, r1, r2, r0);\t\tK(r0, r1, r2, r3, 32);\n\n\td[0] = cpu_to_le32(r0);\n\td[1] = cpu_to_le32(r1);\n\td[2] = cpu_to_le32(r2);\n\td[3] = cpu_to_le32(r3);\n}\nEXPORT_SYMBOL_GPL(__serpent_encrypt);\n\nstatic void serpent_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct serpent_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\t__serpent_encrypt(ctx, dst, src);\n}\n\nvoid __serpent_decrypt(struct serpent_ctx *ctx, u8 *dst, const u8 *src)\n{\n\tconst u32 *k = ctx->expkey;\n\tconst __le32 *s = (const __le32 *)src;\n\t__le32\t*d = (__le32 *)dst;\n\tu32\tr0, r1, r2, r3, r4;\n\n\tr0 = le32_to_cpu(s[0]);\n\tr1 = le32_to_cpu(s[1]);\n\tr2 = le32_to_cpu(s[2]);\n\tr3 = le32_to_cpu(s[3]);\n\n\t\t\t\t\tK(r0, r1, r2, r3, 32);\n\tSI7(r0, r1, r2, r3, r4);\tKL(r1, r3, r0, r4, r2, 31);\n\tSI6(r1, r3, r0, r4, r2);\tKL(r0, r2, r4, r1, r3, 30);\n\tSI5(r0, r2, r4, r1, r3);\tKL(r2, r3, r0, r4, r1, 29);\n\tSI4(r2, r3, r0, r4, r1);\tKL(r2, r0, r1, r4, r3, 28);\n\tSI3(r2, r0, r1, r4, r3);\tKL(r1, r2, r3, r4, r0, 27);\n\tSI2(r1, r2, r3, r4, r0);\tKL(r2, r0, r4, r3, r1, 26);\n\tSI1(r2, r0, r4, r3, r1);\tKL(r1, r0, r4, r3, r2, 25);\n\tSI0(r1, r0, r4, r3, r2);\tKL(r4, r2, r0, r1, r3, 24);\n\tSI7(r4, r2, r0, r1, r3);\tKL(r2, r1, r4, r3, r0, 23);\n\tSI6(r2, r1, r4, r3, r0);\tKL(r4, r0, r3, r2, r1, 22);\n\tSI5(r4, r0, r3, r2, r1);\tKL(r0, r1, r4, r3, r2, 21);\n\tSI4(r0, r1, r4, r3, r2);\tKL(r0, r4, r2, r3, r1, 20);\n\tSI3(r0, r4, r2, r3, r1);\tKL(r2, r0, r1, r3, r4, 19);\n\tSI2(r2, r0, r1, r3, r4);\tKL(r0, r4, r3, r1, r2, 18);\n\tSI1(r0, r4, r3, r1, r2);\tKL(r2, r4, r3, r1, r0, 17);\n\tSI0(r2, r4, r3, r1, r0);\tKL(r3, r0, r4, r2, r1, 16);\n\tSI7(r3, r0, r4, r2, r1);\tKL(r0, r2, r3, r1, r4, 15);\n\tSI6(r0, r2, r3, r1, r4);\tKL(r3, r4, r1, r0, r2, 14);\n\tSI5(r3, r4, r1, r0, r2);\tKL(r4, r2, r3, r1, r0, 13);\n\tSI4(r4, r2, r3, r1, r0);\tKL(r4, r3, r0, r1, r2, 12);\n\tSI3(r4, r3, r0, r1, r2);\tKL(r0, r4, r2, r1, r3, 11);\n\tSI2(r0, r4, r2, r1, r3);\tKL(r4, r3, r1, r2, r0, 10);\n\tSI1(r4, r3, r1, r2, r0);\tKL(r0, r3, r1, r2, r4, 9);\n\tSI0(r0, r3, r1, r2, r4);\tKL(r1, r4, r3, r0, r2, 8);\n\tSI7(r1, r4, r3, r0, r2);\tKL(r4, r0, r1, r2, r3, 7);\n\tSI6(r4, r0, r1, r2, r3);\tKL(r1, r3, r2, r4, r0, 6);\n\tSI5(r1, r3, r2, r4, r0);\tKL(r3, r0, r1, r2, r4, 5);\n\tSI4(r3, r0, r1, r2, r4);\tKL(r3, r1, r4, r2, r0, 4);\n\tSI3(r3, r1, r4, r2, r0);\tKL(r4, r3, r0, r2, r1, 3);\n\tSI2(r4, r3, r0, r2, r1);\tKL(r3, r1, r2, r0, r4, 2);\n\tSI1(r3, r1, r2, r0, r4);\tKL(r4, r1, r2, r0, r3, 1);\n\tSI0(r4, r1, r2, r0, r3);\tK(r2, r3, r1, r4, 0);\n\n\td[0] = cpu_to_le32(r2);\n\td[1] = cpu_to_le32(r3);\n\td[2] = cpu_to_le32(r1);\n\td[3] = cpu_to_le32(r4);\n}\nEXPORT_SYMBOL_GPL(__serpent_decrypt);\n\nstatic void serpent_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct serpent_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\t__serpent_decrypt(ctx, dst, src);\n}\n\nstatic int tnepres_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\t  unsigned int keylen)\n{\n\tu8 rev_key[SERPENT_MAX_KEY_SIZE];\n\tint i;\n\n\tfor (i = 0; i < keylen; ++i)\n\t\trev_key[keylen - i - 1] = key[i];\n\n\treturn serpent_setkey(tfm, rev_key, keylen);\n}\n\nstatic void tnepres_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tconst u32 * const s = (const u32 * const)src;\n\tu32 * const d = (u32 * const)dst;\n\n\tu32 rs[4], rd[4];\n\n\trs[0] = swab32(s[3]);\n\trs[1] = swab32(s[2]);\n\trs[2] = swab32(s[1]);\n\trs[3] = swab32(s[0]);\n\n\tserpent_encrypt(tfm, (u8 *)rd, (u8 *)rs);\n\n\td[0] = swab32(rd[3]);\n\td[1] = swab32(rd[2]);\n\td[2] = swab32(rd[1]);\n\td[3] = swab32(rd[0]);\n}\n\nstatic void tnepres_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tconst u32 * const s = (const u32 * const)src;\n\tu32 * const d = (u32 * const)dst;\n\n\tu32 rs[4], rd[4];\n\n\trs[0] = swab32(s[3]);\n\trs[1] = swab32(s[2]);\n\trs[2] = swab32(s[1]);\n\trs[3] = swab32(s[0]);\n\n\tserpent_decrypt(tfm, (u8 *)rd, (u8 *)rs);\n\n\td[0] = swab32(rd[3]);\n\td[1] = swab32(rd[2]);\n\td[2] = swab32(rd[1]);\n\td[3] = swab32(rd[0]);\n}\n\nstatic struct crypto_alg srp_algs[2] = { {\n\t.cra_name\t\t=\t\"serpent\",\n\t.cra_driver_name\t=\t\"serpent-generic\",\n\t.cra_priority\t\t=\t100,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tSERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct serpent_ctx),\n\t.cra_alignmask\t\t=\t3,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\tSERPENT_MIN_KEY_SIZE,\n\t.cia_max_keysize\t=\tSERPENT_MAX_KEY_SIZE,\n\t.cia_setkey\t\t=\tserpent_setkey,\n\t.cia_encrypt\t\t=\tserpent_encrypt,\n\t.cia_decrypt\t\t=\tserpent_decrypt } }\n}, {\n\t.cra_name\t\t=\t\"tnepres\",\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tSERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct serpent_ctx),\n\t.cra_alignmask\t\t=\t3,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\tSERPENT_MIN_KEY_SIZE,\n\t.cia_max_keysize\t=\tSERPENT_MAX_KEY_SIZE,\n\t.cia_setkey\t\t=\ttnepres_setkey,\n\t.cia_encrypt\t\t=\ttnepres_encrypt,\n\t.cia_decrypt\t\t=\ttnepres_decrypt } }\n} };\n\nstatic int __init serpent_mod_init(void)\n{\n\treturn crypto_register_algs(srp_algs, ARRAY_SIZE(srp_algs));\n}\n\nstatic void __exit serpent_mod_fini(void)\n{\n\tcrypto_unregister_algs(srp_algs, ARRAY_SIZE(srp_algs));\n}\n\nmodule_init(serpent_mod_init);\nmodule_exit(serpent_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Serpent and tnepres (kerneli compatible serpent reversed) Cipher Algorithm\");\nMODULE_AUTHOR(\"Dag Arne Osvik <osvik@ii.uib.no>\");\nMODULE_ALIAS(\"tnepres\");\nMODULE_ALIAS(\"serpent\");\n", "/*\n * Cryptographic API.\n *\n * SHA1 Secure Hash Algorithm.\n *\n * Derived from cryptoapi implementation, adapted for in-place\n * scatterlist interface.\n *\n * Copyright (c) Alan Smithee.\n * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n * Copyright (c) Jean-Francois Dive <jef@linuxbe.org>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n#include <asm/byteorder.h>\n\nstatic int sha1_init(struct shash_desc *desc)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\t*sctx = (struct sha1_state){\n\t\t.state = { SHA1_H0, SHA1_H1, SHA1_H2, SHA1_H3, SHA1_H4 },\n\t};\n\n\treturn 0;\n}\n\nint crypto_sha1_update(struct shash_desc *desc, const u8 *data,\n\t\t\tunsigned int len)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial, done;\n\tconst u8 *src;\n\n\tpartial = sctx->count % SHA1_BLOCK_SIZE;\n\tsctx->count += len;\n\tdone = 0;\n\tsrc = data;\n\n\tif ((partial + len) >= SHA1_BLOCK_SIZE) {\n\t\tu32 temp[SHA_WORKSPACE_WORDS];\n\n\t\tif (partial) {\n\t\t\tdone = -partial;\n\t\t\tmemcpy(sctx->buffer + partial, data,\n\t\t\t       done + SHA1_BLOCK_SIZE);\n\t\t\tsrc = sctx->buffer;\n\t\t}\n\n\t\tdo {\n\t\t\tsha_transform(sctx->state, src, temp);\n\t\t\tdone += SHA1_BLOCK_SIZE;\n\t\t\tsrc = data + done;\n\t\t} while (done + SHA1_BLOCK_SIZE <= len);\n\n\t\tmemzero_explicit(temp, sizeof(temp));\n\t\tpartial = 0;\n\t}\n\tmemcpy(sctx->buffer + partial, src, len - done);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(crypto_sha1_update);\n\n\n/* Add padding and return the message digest. */\nstatic int sha1_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\t__be32 *dst = (__be32 *)out;\n\tu32 i, index, padlen;\n\t__be64 bits;\n\tstatic const u8 padding[64] = { 0x80, };\n\n\tbits = cpu_to_be64(sctx->count << 3);\n\n\t/* Pad out to 56 mod 64 */\n\tindex = sctx->count & 0x3f;\n\tpadlen = (index < 56) ? (56 - index) : ((64+56) - index);\n\tcrypto_sha1_update(desc, padding, padlen);\n\n\t/* Append length */\n\tcrypto_sha1_update(desc, (const u8 *)&bits, sizeof(bits));\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 5; i++)\n\t\tdst[i] = cpu_to_be32(sctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof *sctx);\n\n\treturn 0;\n}\n\nstatic int sha1_export(struct shash_desc *desc, void *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, sizeof(*sctx));\n\treturn 0;\n}\n\nstatic int sha1_import(struct shash_desc *desc, const void *in)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, sizeof(*sctx));\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tSHA1_DIGEST_SIZE,\n\t.init\t\t=\tsha1_init,\n\t.update\t\t=\tcrypto_sha1_update,\n\t.final\t\t=\tsha1_final,\n\t.export\t\t=\tsha1_export,\n\t.import\t\t=\tsha1_import,\n\t.descsize\t=\tsizeof(struct sha1_state),\n\t.statesize\t=\tsizeof(struct sha1_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha1\",\n\t\t.cra_driver_name=\t\"sha1-generic\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA1_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init sha1_generic_mod_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit sha1_generic_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(sha1_generic_mod_init);\nmodule_exit(sha1_generic_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA1 Secure Hash Algorithm\");\n\nMODULE_ALIAS(\"sha1\");\n", "/*\n * Cryptographic API.\n *\n * SHA-256, as specified in\n * http://csrc.nist.gov/groups/STM/cavp/documents/shs/sha256-384-512.pdf\n *\n * SHA-256 code by Jean-Luc Cooke <jlcooke@certainkey.com>.\n *\n * Copyright (c) Jean-Luc Cooke <jlcooke@certainkey.com>\n * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>\n * SHA224 Support Copyright 2007 Intel Corporation <jonathan.lynch@intel.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option) \n * any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n#include <asm/byteorder.h>\n#include <asm/unaligned.h>\n\nstatic inline u32 Ch(u32 x, u32 y, u32 z)\n{\n\treturn z ^ (x & (y ^ z));\n}\n\nstatic inline u32 Maj(u32 x, u32 y, u32 z)\n{\n\treturn (x & y) | (z & (x | y));\n}\n\n#define e0(x)       (ror32(x, 2) ^ ror32(x,13) ^ ror32(x,22))\n#define e1(x)       (ror32(x, 6) ^ ror32(x,11) ^ ror32(x,25))\n#define s0(x)       (ror32(x, 7) ^ ror32(x,18) ^ (x >> 3))\n#define s1(x)       (ror32(x,17) ^ ror32(x,19) ^ (x >> 10))\n\nstatic inline void LOAD_OP(int I, u32 *W, const u8 *input)\n{\n\tW[I] = get_unaligned_be32((__u32 *)input + I);\n}\n\nstatic inline void BLEND_OP(int I, u32 *W)\n{\n\tW[I] = s1(W[I-2]) + W[I-7] + s0(W[I-15]) + W[I-16];\n}\n\nstatic void sha256_transform(u32 *state, const u8 *input)\n{\n\tu32 a, b, c, d, e, f, g, h, t1, t2;\n\tu32 W[64];\n\tint i;\n\n\t/* load the input */\n\tfor (i = 0; i < 16; i++)\n\t\tLOAD_OP(i, W, input);\n\n\t/* now blend */\n\tfor (i = 16; i < 64; i++)\n\t\tBLEND_OP(i, W);\n\n\t/* load the state into our registers */\n\ta=state[0];  b=state[1];  c=state[2];  d=state[3];\n\te=state[4];  f=state[5];  g=state[6];  h=state[7];\n\n\t/* now iterate */\n\tt1 = h + e1(e) + Ch(e,f,g) + 0x428a2f98 + W[ 0];\n\tt2 = e0(a) + Maj(a,b,c);    d+=t1;    h=t1+t2;\n\tt1 = g + e1(d) + Ch(d,e,f) + 0x71374491 + W[ 1];\n\tt2 = e0(h) + Maj(h,a,b);    c+=t1;    g=t1+t2;\n\tt1 = f + e1(c) + Ch(c,d,e) + 0xb5c0fbcf + W[ 2];\n\tt2 = e0(g) + Maj(g,h,a);    b+=t1;    f=t1+t2;\n\tt1 = e + e1(b) + Ch(b,c,d) + 0xe9b5dba5 + W[ 3];\n\tt2 = e0(f) + Maj(f,g,h);    a+=t1;    e=t1+t2;\n\tt1 = d + e1(a) + Ch(a,b,c) + 0x3956c25b + W[ 4];\n\tt2 = e0(e) + Maj(e,f,g);    h+=t1;    d=t1+t2;\n\tt1 = c + e1(h) + Ch(h,a,b) + 0x59f111f1 + W[ 5];\n\tt2 = e0(d) + Maj(d,e,f);    g+=t1;    c=t1+t2;\n\tt1 = b + e1(g) + Ch(g,h,a) + 0x923f82a4 + W[ 6];\n\tt2 = e0(c) + Maj(c,d,e);    f+=t1;    b=t1+t2;\n\tt1 = a + e1(f) + Ch(f,g,h) + 0xab1c5ed5 + W[ 7];\n\tt2 = e0(b) + Maj(b,c,d);    e+=t1;    a=t1+t2;\n\n\tt1 = h + e1(e) + Ch(e,f,g) + 0xd807aa98 + W[ 8];\n\tt2 = e0(a) + Maj(a,b,c);    d+=t1;    h=t1+t2;\n\tt1 = g + e1(d) + Ch(d,e,f) + 0x12835b01 + W[ 9];\n\tt2 = e0(h) + Maj(h,a,b);    c+=t1;    g=t1+t2;\n\tt1 = f + e1(c) + Ch(c,d,e) + 0x243185be + W[10];\n\tt2 = e0(g) + Maj(g,h,a);    b+=t1;    f=t1+t2;\n\tt1 = e + e1(b) + Ch(b,c,d) + 0x550c7dc3 + W[11];\n\tt2 = e0(f) + Maj(f,g,h);    a+=t1;    e=t1+t2;\n\tt1 = d + e1(a) + Ch(a,b,c) + 0x72be5d74 + W[12];\n\tt2 = e0(e) + Maj(e,f,g);    h+=t1;    d=t1+t2;\n\tt1 = c + e1(h) + Ch(h,a,b) + 0x80deb1fe + W[13];\n\tt2 = e0(d) + Maj(d,e,f);    g+=t1;    c=t1+t2;\n\tt1 = b + e1(g) + Ch(g,h,a) + 0x9bdc06a7 + W[14];\n\tt2 = e0(c) + Maj(c,d,e);    f+=t1;    b=t1+t2;\n\tt1 = a + e1(f) + Ch(f,g,h) + 0xc19bf174 + W[15];\n\tt2 = e0(b) + Maj(b,c,d);    e+=t1;    a=t1+t2;\n\n\tt1 = h + e1(e) + Ch(e,f,g) + 0xe49b69c1 + W[16];\n\tt2 = e0(a) + Maj(a,b,c);    d+=t1;    h=t1+t2;\n\tt1 = g + e1(d) + Ch(d,e,f) + 0xefbe4786 + W[17];\n\tt2 = e0(h) + Maj(h,a,b);    c+=t1;    g=t1+t2;\n\tt1 = f + e1(c) + Ch(c,d,e) + 0x0fc19dc6 + W[18];\n\tt2 = e0(g) + Maj(g,h,a);    b+=t1;    f=t1+t2;\n\tt1 = e + e1(b) + Ch(b,c,d) + 0x240ca1cc + W[19];\n\tt2 = e0(f) + Maj(f,g,h);    a+=t1;    e=t1+t2;\n\tt1 = d + e1(a) + Ch(a,b,c) + 0x2de92c6f + W[20];\n\tt2 = e0(e) + Maj(e,f,g);    h+=t1;    d=t1+t2;\n\tt1 = c + e1(h) + Ch(h,a,b) + 0x4a7484aa + W[21];\n\tt2 = e0(d) + Maj(d,e,f);    g+=t1;    c=t1+t2;\n\tt1 = b + e1(g) + Ch(g,h,a) + 0x5cb0a9dc + W[22];\n\tt2 = e0(c) + Maj(c,d,e);    f+=t1;    b=t1+t2;\n\tt1 = a + e1(f) + Ch(f,g,h) + 0x76f988da + W[23];\n\tt2 = e0(b) + Maj(b,c,d);    e+=t1;    a=t1+t2;\n\n\tt1 = h + e1(e) + Ch(e,f,g) + 0x983e5152 + W[24];\n\tt2 = e0(a) + Maj(a,b,c);    d+=t1;    h=t1+t2;\n\tt1 = g + e1(d) + Ch(d,e,f) + 0xa831c66d + W[25];\n\tt2 = e0(h) + Maj(h,a,b);    c+=t1;    g=t1+t2;\n\tt1 = f + e1(c) + Ch(c,d,e) + 0xb00327c8 + W[26];\n\tt2 = e0(g) + Maj(g,h,a);    b+=t1;    f=t1+t2;\n\tt1 = e + e1(b) + Ch(b,c,d) + 0xbf597fc7 + W[27];\n\tt2 = e0(f) + Maj(f,g,h);    a+=t1;    e=t1+t2;\n\tt1 = d + e1(a) + Ch(a,b,c) + 0xc6e00bf3 + W[28];\n\tt2 = e0(e) + Maj(e,f,g);    h+=t1;    d=t1+t2;\n\tt1 = c + e1(h) + Ch(h,a,b) + 0xd5a79147 + W[29];\n\tt2 = e0(d) + Maj(d,e,f);    g+=t1;    c=t1+t2;\n\tt1 = b + e1(g) + Ch(g,h,a) + 0x06ca6351 + W[30];\n\tt2 = e0(c) + Maj(c,d,e);    f+=t1;    b=t1+t2;\n\tt1 = a + e1(f) + Ch(f,g,h) + 0x14292967 + W[31];\n\tt2 = e0(b) + Maj(b,c,d);    e+=t1;    a=t1+t2;\n\n\tt1 = h + e1(e) + Ch(e,f,g) + 0x27b70a85 + W[32];\n\tt2 = e0(a) + Maj(a,b,c);    d+=t1;    h=t1+t2;\n\tt1 = g + e1(d) + Ch(d,e,f) + 0x2e1b2138 + W[33];\n\tt2 = e0(h) + Maj(h,a,b);    c+=t1;    g=t1+t2;\n\tt1 = f + e1(c) + Ch(c,d,e) + 0x4d2c6dfc + W[34];\n\tt2 = e0(g) + Maj(g,h,a);    b+=t1;    f=t1+t2;\n\tt1 = e + e1(b) + Ch(b,c,d) + 0x53380d13 + W[35];\n\tt2 = e0(f) + Maj(f,g,h);    a+=t1;    e=t1+t2;\n\tt1 = d + e1(a) + Ch(a,b,c) + 0x650a7354 + W[36];\n\tt2 = e0(e) + Maj(e,f,g);    h+=t1;    d=t1+t2;\n\tt1 = c + e1(h) + Ch(h,a,b) + 0x766a0abb + W[37];\n\tt2 = e0(d) + Maj(d,e,f);    g+=t1;    c=t1+t2;\n\tt1 = b + e1(g) + Ch(g,h,a) + 0x81c2c92e + W[38];\n\tt2 = e0(c) + Maj(c,d,e);    f+=t1;    b=t1+t2;\n\tt1 = a + e1(f) + Ch(f,g,h) + 0x92722c85 + W[39];\n\tt2 = e0(b) + Maj(b,c,d);    e+=t1;    a=t1+t2;\n\n\tt1 = h + e1(e) + Ch(e,f,g) + 0xa2bfe8a1 + W[40];\n\tt2 = e0(a) + Maj(a,b,c);    d+=t1;    h=t1+t2;\n\tt1 = g + e1(d) + Ch(d,e,f) + 0xa81a664b + W[41];\n\tt2 = e0(h) + Maj(h,a,b);    c+=t1;    g=t1+t2;\n\tt1 = f + e1(c) + Ch(c,d,e) + 0xc24b8b70 + W[42];\n\tt2 = e0(g) + Maj(g,h,a);    b+=t1;    f=t1+t2;\n\tt1 = e + e1(b) + Ch(b,c,d) + 0xc76c51a3 + W[43];\n\tt2 = e0(f) + Maj(f,g,h);    a+=t1;    e=t1+t2;\n\tt1 = d + e1(a) + Ch(a,b,c) + 0xd192e819 + W[44];\n\tt2 = e0(e) + Maj(e,f,g);    h+=t1;    d=t1+t2;\n\tt1 = c + e1(h) + Ch(h,a,b) + 0xd6990624 + W[45];\n\tt2 = e0(d) + Maj(d,e,f);    g+=t1;    c=t1+t2;\n\tt1 = b + e1(g) + Ch(g,h,a) + 0xf40e3585 + W[46];\n\tt2 = e0(c) + Maj(c,d,e);    f+=t1;    b=t1+t2;\n\tt1 = a + e1(f) + Ch(f,g,h) + 0x106aa070 + W[47];\n\tt2 = e0(b) + Maj(b,c,d);    e+=t1;    a=t1+t2;\n\n\tt1 = h + e1(e) + Ch(e,f,g) + 0x19a4c116 + W[48];\n\tt2 = e0(a) + Maj(a,b,c);    d+=t1;    h=t1+t2;\n\tt1 = g + e1(d) + Ch(d,e,f) + 0x1e376c08 + W[49];\n\tt2 = e0(h) + Maj(h,a,b);    c+=t1;    g=t1+t2;\n\tt1 = f + e1(c) + Ch(c,d,e) + 0x2748774c + W[50];\n\tt2 = e0(g) + Maj(g,h,a);    b+=t1;    f=t1+t2;\n\tt1 = e + e1(b) + Ch(b,c,d) + 0x34b0bcb5 + W[51];\n\tt2 = e0(f) + Maj(f,g,h);    a+=t1;    e=t1+t2;\n\tt1 = d + e1(a) + Ch(a,b,c) + 0x391c0cb3 + W[52];\n\tt2 = e0(e) + Maj(e,f,g);    h+=t1;    d=t1+t2;\n\tt1 = c + e1(h) + Ch(h,a,b) + 0x4ed8aa4a + W[53];\n\tt2 = e0(d) + Maj(d,e,f);    g+=t1;    c=t1+t2;\n\tt1 = b + e1(g) + Ch(g,h,a) + 0x5b9cca4f + W[54];\n\tt2 = e0(c) + Maj(c,d,e);    f+=t1;    b=t1+t2;\n\tt1 = a + e1(f) + Ch(f,g,h) + 0x682e6ff3 + W[55];\n\tt2 = e0(b) + Maj(b,c,d);    e+=t1;    a=t1+t2;\n\n\tt1 = h + e1(e) + Ch(e,f,g) + 0x748f82ee + W[56];\n\tt2 = e0(a) + Maj(a,b,c);    d+=t1;    h=t1+t2;\n\tt1 = g + e1(d) + Ch(d,e,f) + 0x78a5636f + W[57];\n\tt2 = e0(h) + Maj(h,a,b);    c+=t1;    g=t1+t2;\n\tt1 = f + e1(c) + Ch(c,d,e) + 0x84c87814 + W[58];\n\tt2 = e0(g) + Maj(g,h,a);    b+=t1;    f=t1+t2;\n\tt1 = e + e1(b) + Ch(b,c,d) + 0x8cc70208 + W[59];\n\tt2 = e0(f) + Maj(f,g,h);    a+=t1;    e=t1+t2;\n\tt1 = d + e1(a) + Ch(a,b,c) + 0x90befffa + W[60];\n\tt2 = e0(e) + Maj(e,f,g);    h+=t1;    d=t1+t2;\n\tt1 = c + e1(h) + Ch(h,a,b) + 0xa4506ceb + W[61];\n\tt2 = e0(d) + Maj(d,e,f);    g+=t1;    c=t1+t2;\n\tt1 = b + e1(g) + Ch(g,h,a) + 0xbef9a3f7 + W[62];\n\tt2 = e0(c) + Maj(c,d,e);    f+=t1;    b=t1+t2;\n\tt1 = a + e1(f) + Ch(f,g,h) + 0xc67178f2 + W[63];\n\tt2 = e0(b) + Maj(b,c,d);    e+=t1;    a=t1+t2;\n\n\tstate[0] += a; state[1] += b; state[2] += c; state[3] += d;\n\tstate[4] += e; state[5] += f; state[6] += g; state[7] += h;\n\n\t/* clear any sensitive info... */\n\ta = b = c = d = e = f = g = h = t1 = t2 = 0;\n\tmemzero_explicit(W, 64 * sizeof(u32));\n}\n\nstatic int sha224_init(struct shash_desc *desc)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\tsctx->state[0] = SHA224_H0;\n\tsctx->state[1] = SHA224_H1;\n\tsctx->state[2] = SHA224_H2;\n\tsctx->state[3] = SHA224_H3;\n\tsctx->state[4] = SHA224_H4;\n\tsctx->state[5] = SHA224_H5;\n\tsctx->state[6] = SHA224_H6;\n\tsctx->state[7] = SHA224_H7;\n\tsctx->count = 0;\n\n\treturn 0;\n}\n\nstatic int sha256_init(struct shash_desc *desc)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\tsctx->state[0] = SHA256_H0;\n\tsctx->state[1] = SHA256_H1;\n\tsctx->state[2] = SHA256_H2;\n\tsctx->state[3] = SHA256_H3;\n\tsctx->state[4] = SHA256_H4;\n\tsctx->state[5] = SHA256_H5;\n\tsctx->state[6] = SHA256_H6;\n\tsctx->state[7] = SHA256_H7;\n\tsctx->count = 0;\n\n\treturn 0;\n}\n\nint crypto_sha256_update(struct shash_desc *desc, const u8 *data,\n\t\t\t  unsigned int len)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial, done;\n\tconst u8 *src;\n\n\tpartial = sctx->count & 0x3f;\n\tsctx->count += len;\n\tdone = 0;\n\tsrc = data;\n\n\tif ((partial + len) > 63) {\n\t\tif (partial) {\n\t\t\tdone = -partial;\n\t\t\tmemcpy(sctx->buf + partial, data, done + 64);\n\t\t\tsrc = sctx->buf;\n\t\t}\n\n\t\tdo {\n\t\t\tsha256_transform(sctx->state, src);\n\t\t\tdone += 64;\n\t\t\tsrc = data + done;\n\t\t} while (done + 63 < len);\n\n\t\tpartial = 0;\n\t}\n\tmemcpy(sctx->buf + partial, src, len - done);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(crypto_sha256_update);\n\nstatic int sha256_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\t__be32 *dst = (__be32 *)out;\n\t__be64 bits;\n\tunsigned int index, pad_len;\n\tint i;\n\tstatic const u8 padding[64] = { 0x80, };\n\n\t/* Save number of bits */\n\tbits = cpu_to_be64(sctx->count << 3);\n\n\t/* Pad out to 56 mod 64. */\n\tindex = sctx->count & 0x3f;\n\tpad_len = (index < 56) ? (56 - index) : ((64+56) - index);\n\tcrypto_sha256_update(desc, padding, pad_len);\n\n\t/* Append length (before padding) */\n\tcrypto_sha256_update(desc, (const u8 *)&bits, sizeof(bits));\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 8; i++)\n\t\tdst[i] = cpu_to_be32(sctx->state[i]);\n\n\t/* Zeroize sensitive information. */\n\tmemset(sctx, 0, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha224_final(struct shash_desc *desc, u8 *hash)\n{\n\tu8 D[SHA256_DIGEST_SIZE];\n\n\tsha256_final(desc, D);\n\n\tmemcpy(hash, D, SHA224_DIGEST_SIZE);\n\tmemzero_explicit(D, SHA256_DIGEST_SIZE);\n\n\treturn 0;\n}\n\nstatic int sha256_export(struct shash_desc *desc, void *out)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, sizeof(*sctx));\n\treturn 0;\n}\n\nstatic int sha256_import(struct shash_desc *desc, const void *in)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, sizeof(*sctx));\n\treturn 0;\n}\n\nstatic struct shash_alg sha256_algs[2] = { {\n\t.digestsize\t=\tSHA256_DIGEST_SIZE,\n\t.init\t\t=\tsha256_init,\n\t.update\t\t=\tcrypto_sha256_update,\n\t.final\t\t=\tsha256_final,\n\t.export\t\t=\tsha256_export,\n\t.import\t\t=\tsha256_import,\n\t.descsize\t=\tsizeof(struct sha256_state),\n\t.statesize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha256\",\n\t\t.cra_driver_name=\t\"sha256-generic\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA256_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n}, {\n\t.digestsize\t=\tSHA224_DIGEST_SIZE,\n\t.init\t\t=\tsha224_init,\n\t.update\t\t=\tcrypto_sha256_update,\n\t.final\t\t=\tsha224_final,\n\t.descsize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha224\",\n\t\t.cra_driver_name=\t\"sha224-generic\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA224_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n} };\n\nstatic int __init sha256_generic_mod_init(void)\n{\n\treturn crypto_register_shashes(sha256_algs, ARRAY_SIZE(sha256_algs));\n}\n\nstatic void __exit sha256_generic_mod_fini(void)\n{\n\tcrypto_unregister_shashes(sha256_algs, ARRAY_SIZE(sha256_algs));\n}\n\nmodule_init(sha256_generic_mod_init);\nmodule_exit(sha256_generic_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA-224 and SHA-256 Secure Hash Algorithm\");\n\nMODULE_ALIAS(\"sha224\");\nMODULE_ALIAS(\"sha256\");\n", "/* SHA-512 code by Jean-Luc Cooke <jlcooke@certainkey.com>\n *\n * Copyright (c) Jean-Luc Cooke <jlcooke@certainkey.com>\n * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n * Copyright (c) 2003 Kyle McMartin <kyle@debian.org>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the\n * Free Software Foundation; either version 2, or (at your option) any\n * later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/init.h>\n#include <linux/crypto.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n#include <linux/percpu.h>\n#include <asm/byteorder.h>\n#include <asm/unaligned.h>\n\nstatic inline u64 Ch(u64 x, u64 y, u64 z)\n{\n        return z ^ (x & (y ^ z));\n}\n\nstatic inline u64 Maj(u64 x, u64 y, u64 z)\n{\n        return (x & y) | (z & (x | y));\n}\n\nstatic const u64 sha512_K[80] = {\n        0x428a2f98d728ae22ULL, 0x7137449123ef65cdULL, 0xb5c0fbcfec4d3b2fULL,\n        0xe9b5dba58189dbbcULL, 0x3956c25bf348b538ULL, 0x59f111f1b605d019ULL,\n        0x923f82a4af194f9bULL, 0xab1c5ed5da6d8118ULL, 0xd807aa98a3030242ULL,\n        0x12835b0145706fbeULL, 0x243185be4ee4b28cULL, 0x550c7dc3d5ffb4e2ULL,\n        0x72be5d74f27b896fULL, 0x80deb1fe3b1696b1ULL, 0x9bdc06a725c71235ULL,\n        0xc19bf174cf692694ULL, 0xe49b69c19ef14ad2ULL, 0xefbe4786384f25e3ULL,\n        0x0fc19dc68b8cd5b5ULL, 0x240ca1cc77ac9c65ULL, 0x2de92c6f592b0275ULL,\n        0x4a7484aa6ea6e483ULL, 0x5cb0a9dcbd41fbd4ULL, 0x76f988da831153b5ULL,\n        0x983e5152ee66dfabULL, 0xa831c66d2db43210ULL, 0xb00327c898fb213fULL,\n        0xbf597fc7beef0ee4ULL, 0xc6e00bf33da88fc2ULL, 0xd5a79147930aa725ULL,\n        0x06ca6351e003826fULL, 0x142929670a0e6e70ULL, 0x27b70a8546d22ffcULL,\n        0x2e1b21385c26c926ULL, 0x4d2c6dfc5ac42aedULL, 0x53380d139d95b3dfULL,\n        0x650a73548baf63deULL, 0x766a0abb3c77b2a8ULL, 0x81c2c92e47edaee6ULL,\n        0x92722c851482353bULL, 0xa2bfe8a14cf10364ULL, 0xa81a664bbc423001ULL,\n        0xc24b8b70d0f89791ULL, 0xc76c51a30654be30ULL, 0xd192e819d6ef5218ULL,\n        0xd69906245565a910ULL, 0xf40e35855771202aULL, 0x106aa07032bbd1b8ULL,\n        0x19a4c116b8d2d0c8ULL, 0x1e376c085141ab53ULL, 0x2748774cdf8eeb99ULL,\n        0x34b0bcb5e19b48a8ULL, 0x391c0cb3c5c95a63ULL, 0x4ed8aa4ae3418acbULL,\n        0x5b9cca4f7763e373ULL, 0x682e6ff3d6b2b8a3ULL, 0x748f82ee5defb2fcULL,\n        0x78a5636f43172f60ULL, 0x84c87814a1f0ab72ULL, 0x8cc702081a6439ecULL,\n        0x90befffa23631e28ULL, 0xa4506cebde82bde9ULL, 0xbef9a3f7b2c67915ULL,\n        0xc67178f2e372532bULL, 0xca273eceea26619cULL, 0xd186b8c721c0c207ULL,\n        0xeada7dd6cde0eb1eULL, 0xf57d4f7fee6ed178ULL, 0x06f067aa72176fbaULL,\n        0x0a637dc5a2c898a6ULL, 0x113f9804bef90daeULL, 0x1b710b35131c471bULL,\n        0x28db77f523047d84ULL, 0x32caab7b40c72493ULL, 0x3c9ebe0a15c9bebcULL,\n        0x431d67c49c100d4cULL, 0x4cc5d4becb3e42b6ULL, 0x597f299cfc657e2aULL,\n        0x5fcb6fab3ad6faecULL, 0x6c44198c4a475817ULL,\n};\n\n#define e0(x)       (ror64(x,28) ^ ror64(x,34) ^ ror64(x,39))\n#define e1(x)       (ror64(x,14) ^ ror64(x,18) ^ ror64(x,41))\n#define s0(x)       (ror64(x, 1) ^ ror64(x, 8) ^ (x >> 7))\n#define s1(x)       (ror64(x,19) ^ ror64(x,61) ^ (x >> 6))\n\nstatic inline void LOAD_OP(int I, u64 *W, const u8 *input)\n{\n\tW[I] = get_unaligned_be64((__u64 *)input + I);\n}\n\nstatic inline void BLEND_OP(int I, u64 *W)\n{\n\tW[I & 15] += s1(W[(I-2) & 15]) + W[(I-7) & 15] + s0(W[(I-15) & 15]);\n}\n\nstatic void\nsha512_transform(u64 *state, const u8 *input)\n{\n\tu64 a, b, c, d, e, f, g, h, t1, t2;\n\n\tint i;\n\tu64 W[16];\n\n\t/* load the state into our registers */\n\ta=state[0];   b=state[1];   c=state[2];   d=state[3];\n\te=state[4];   f=state[5];   g=state[6];   h=state[7];\n\n\t/* now iterate */\n\tfor (i=0; i<80; i+=8) {\n\t\tif (!(i & 8)) {\n\t\t\tint j;\n\n\t\t\tif (i < 16) {\n\t\t\t\t/* load the input */\n\t\t\t\tfor (j = 0; j < 16; j++)\n\t\t\t\t\tLOAD_OP(i + j, W, input);\n\t\t\t} else {\n\t\t\t\tfor (j = 0; j < 16; j++) {\n\t\t\t\t\tBLEND_OP(i + j, W);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tt1 = h + e1(e) + Ch(e,f,g) + sha512_K[i  ] + W[(i & 15)];\n\t\tt2 = e0(a) + Maj(a,b,c);    d+=t1;    h=t1+t2;\n\t\tt1 = g + e1(d) + Ch(d,e,f) + sha512_K[i+1] + W[(i & 15) + 1];\n\t\tt2 = e0(h) + Maj(h,a,b);    c+=t1;    g=t1+t2;\n\t\tt1 = f + e1(c) + Ch(c,d,e) + sha512_K[i+2] + W[(i & 15) + 2];\n\t\tt2 = e0(g) + Maj(g,h,a);    b+=t1;    f=t1+t2;\n\t\tt1 = e + e1(b) + Ch(b,c,d) + sha512_K[i+3] + W[(i & 15) + 3];\n\t\tt2 = e0(f) + Maj(f,g,h);    a+=t1;    e=t1+t2;\n\t\tt1 = d + e1(a) + Ch(a,b,c) + sha512_K[i+4] + W[(i & 15) + 4];\n\t\tt2 = e0(e) + Maj(e,f,g);    h+=t1;    d=t1+t2;\n\t\tt1 = c + e1(h) + Ch(h,a,b) + sha512_K[i+5] + W[(i & 15) + 5];\n\t\tt2 = e0(d) + Maj(d,e,f);    g+=t1;    c=t1+t2;\n\t\tt1 = b + e1(g) + Ch(g,h,a) + sha512_K[i+6] + W[(i & 15) + 6];\n\t\tt2 = e0(c) + Maj(c,d,e);    f+=t1;    b=t1+t2;\n\t\tt1 = a + e1(f) + Ch(f,g,h) + sha512_K[i+7] + W[(i & 15) + 7];\n\t\tt2 = e0(b) + Maj(b,c,d);    e+=t1;    a=t1+t2;\n\t}\n\n\tstate[0] += a; state[1] += b; state[2] += c; state[3] += d;\n\tstate[4] += e; state[5] += f; state[6] += g; state[7] += h;\n\n\t/* erase our data */\n\ta = b = c = d = e = f = g = h = t1 = t2 = 0;\n}\n\nstatic int\nsha512_init(struct shash_desc *desc)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tsctx->state[0] = SHA512_H0;\n\tsctx->state[1] = SHA512_H1;\n\tsctx->state[2] = SHA512_H2;\n\tsctx->state[3] = SHA512_H3;\n\tsctx->state[4] = SHA512_H4;\n\tsctx->state[5] = SHA512_H5;\n\tsctx->state[6] = SHA512_H6;\n\tsctx->state[7] = SHA512_H7;\n\tsctx->count[0] = sctx->count[1] = 0;\n\n\treturn 0;\n}\n\nstatic int\nsha384_init(struct shash_desc *desc)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tsctx->state[0] = SHA384_H0;\n\tsctx->state[1] = SHA384_H1;\n\tsctx->state[2] = SHA384_H2;\n\tsctx->state[3] = SHA384_H3;\n\tsctx->state[4] = SHA384_H4;\n\tsctx->state[5] = SHA384_H5;\n\tsctx->state[6] = SHA384_H6;\n\tsctx->state[7] = SHA384_H7;\n\tsctx->count[0] = sctx->count[1] = 0;\n\n\treturn 0;\n}\n\nint crypto_sha512_update(struct shash_desc *desc, const u8 *data,\n\t\t\tunsigned int len)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\n\tunsigned int i, index, part_len;\n\n\t/* Compute number of bytes mod 128 */\n\tindex = sctx->count[0] & 0x7f;\n\n\t/* Update number of bytes */\n\tif ((sctx->count[0] += len) < len)\n\t\tsctx->count[1]++;\n\n        part_len = 128 - index;\n\n\t/* Transform as many times as possible. */\n\tif (len >= part_len) {\n\t\tmemcpy(&sctx->buf[index], data, part_len);\n\t\tsha512_transform(sctx->state, sctx->buf);\n\n\t\tfor (i = part_len; i + 127 < len; i+=128)\n\t\t\tsha512_transform(sctx->state, &data[i]);\n\n\t\tindex = 0;\n\t} else {\n\t\ti = 0;\n\t}\n\n\t/* Buffer remaining input */\n\tmemcpy(&sctx->buf[index], &data[i], len - i);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(crypto_sha512_update);\n\nstatic int\nsha512_final(struct shash_desc *desc, u8 *hash)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n        static u8 padding[128] = { 0x80, };\n\t__be64 *dst = (__be64 *)hash;\n\t__be64 bits[2];\n\tunsigned int index, pad_len;\n\tint i;\n\n\t/* Save number of bits */\n\tbits[1] = cpu_to_be64(sctx->count[0] << 3);\n\tbits[0] = cpu_to_be64(sctx->count[1] << 3 | sctx->count[0] >> 61);\n\n\t/* Pad out to 112 mod 128. */\n\tindex = sctx->count[0] & 0x7f;\n\tpad_len = (index < 112) ? (112 - index) : ((128+112) - index);\n\tcrypto_sha512_update(desc, padding, pad_len);\n\n\t/* Append length (before padding) */\n\tcrypto_sha512_update(desc, (const u8 *)bits, sizeof(bits));\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 8; i++)\n\t\tdst[i] = cpu_to_be64(sctx->state[i]);\n\n\t/* Zeroize sensitive information. */\n\tmemset(sctx, 0, sizeof(struct sha512_state));\n\n\treturn 0;\n}\n\nstatic int sha384_final(struct shash_desc *desc, u8 *hash)\n{\n\tu8 D[64];\n\n\tsha512_final(desc, D);\n\n\tmemcpy(hash, D, 48);\n\tmemzero_explicit(D, 64);\n\n\treturn 0;\n}\n\nstatic struct shash_alg sha512_algs[2] = { {\n\t.digestsize\t=\tSHA512_DIGEST_SIZE,\n\t.init\t\t=\tsha512_init,\n\t.update\t\t=\tcrypto_sha512_update,\n\t.final\t\t=\tsha512_final,\n\t.descsize\t=\tsizeof(struct sha512_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha512\",\n\t\t.cra_driver_name =\t\"sha512-generic\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA512_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n}, {\n\t.digestsize\t=\tSHA384_DIGEST_SIZE,\n\t.init\t\t=\tsha384_init,\n\t.update\t\t=\tcrypto_sha512_update,\n\t.final\t\t=\tsha384_final,\n\t.descsize\t=\tsizeof(struct sha512_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha384\",\n\t\t.cra_driver_name =\t\"sha384-generic\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA384_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n} };\n\nstatic int __init sha512_generic_mod_init(void)\n{\n\treturn crypto_register_shashes(sha512_algs, ARRAY_SIZE(sha512_algs));\n}\n\nstatic void __exit sha512_generic_mod_fini(void)\n{\n\tcrypto_unregister_shashes(sha512_algs, ARRAY_SIZE(sha512_algs));\n}\n\nmodule_init(sha512_generic_mod_init);\nmodule_exit(sha512_generic_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA-512 and SHA-384 Secure Hash Algorithms\");\n\nMODULE_ALIAS(\"sha384\");\nMODULE_ALIAS(\"sha512\");\n", "/* \n * Cryptographic API.\n *\n * TEA, XTEA, and XETA crypto alogrithms\n *\n * The TEA and Xtended TEA algorithms were developed by David Wheeler \n * and Roger Needham at the Computer Laboratory of Cambridge University.\n *\n * Due to the order of evaluation in XTEA many people have incorrectly\n * implemented it.  XETA (XTEA in the wrong order), exists for\n * compatibility with these implementations.\n *\n * Copyright (c) 2004 Aaron Grothe ajgrothe@yahoo.com\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <asm/byteorder.h>\n#include <linux/crypto.h>\n#include <linux/types.h>\n\n#define TEA_KEY_SIZE\t\t16\n#define TEA_BLOCK_SIZE\t\t8\n#define TEA_ROUNDS\t\t32\n#define TEA_DELTA\t\t0x9e3779b9\n\n#define XTEA_KEY_SIZE\t\t16\n#define XTEA_BLOCK_SIZE\t\t8\n#define XTEA_ROUNDS\t\t32\n#define XTEA_DELTA\t\t0x9e3779b9\n\nstruct tea_ctx {\n\tu32 KEY[4];\n};\n\nstruct xtea_ctx {\n\tu32 KEY[4];\n};\n\nstatic int tea_setkey(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t      unsigned int key_len)\n{\n\tstruct tea_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *key = (const __le32 *)in_key;\n\n\tctx->KEY[0] = le32_to_cpu(key[0]);\n\tctx->KEY[1] = le32_to_cpu(key[1]);\n\tctx->KEY[2] = le32_to_cpu(key[2]);\n\tctx->KEY[3] = le32_to_cpu(key[3]);\n\n\treturn 0; \n\n}\n\nstatic void tea_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tu32 y, z, n, sum = 0;\n\tu32 k0, k1, k2, k3;\n\tstruct tea_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *in = (const __le32 *)src;\n\t__le32 *out = (__le32 *)dst;\n\n\ty = le32_to_cpu(in[0]);\n\tz = le32_to_cpu(in[1]);\n\n\tk0 = ctx->KEY[0];\n\tk1 = ctx->KEY[1];\n\tk2 = ctx->KEY[2];\n\tk3 = ctx->KEY[3];\n\n\tn = TEA_ROUNDS;\n\n\twhile (n-- > 0) {\n\t\tsum += TEA_DELTA;\n\t\ty += ((z << 4) + k0) ^ (z + sum) ^ ((z >> 5) + k1);\n\t\tz += ((y << 4) + k2) ^ (y + sum) ^ ((y >> 5) + k3);\n\t}\n\t\n\tout[0] = cpu_to_le32(y);\n\tout[1] = cpu_to_le32(z);\n}\n\nstatic void tea_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tu32 y, z, n, sum;\n\tu32 k0, k1, k2, k3;\n\tstruct tea_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *in = (const __le32 *)src;\n\t__le32 *out = (__le32 *)dst;\n\n\ty = le32_to_cpu(in[0]);\n\tz = le32_to_cpu(in[1]);\n\n\tk0 = ctx->KEY[0];\n\tk1 = ctx->KEY[1];\n\tk2 = ctx->KEY[2];\n\tk3 = ctx->KEY[3];\n\n\tsum = TEA_DELTA << 5;\n\n\tn = TEA_ROUNDS;\n\n\twhile (n-- > 0) {\n\t\tz -= ((y << 4) + k2) ^ (y + sum) ^ ((y >> 5) + k3);\n\t\ty -= ((z << 4) + k0) ^ (z + sum) ^ ((z >> 5) + k1);\n\t\tsum -= TEA_DELTA;\n\t}\n\t\n\tout[0] = cpu_to_le32(y);\n\tout[1] = cpu_to_le32(z);\n}\n\nstatic int xtea_setkey(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t       unsigned int key_len)\n{\n\tstruct xtea_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *key = (const __le32 *)in_key;\n\n\tctx->KEY[0] = le32_to_cpu(key[0]);\n\tctx->KEY[1] = le32_to_cpu(key[1]);\n\tctx->KEY[2] = le32_to_cpu(key[2]);\n\tctx->KEY[3] = le32_to_cpu(key[3]);\n\n\treturn 0; \n\n}\n\nstatic void xtea_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tu32 y, z, sum = 0;\n\tu32 limit = XTEA_DELTA * XTEA_ROUNDS;\n\tstruct xtea_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *in = (const __le32 *)src;\n\t__le32 *out = (__le32 *)dst;\n\n\ty = le32_to_cpu(in[0]);\n\tz = le32_to_cpu(in[1]);\n\n\twhile (sum != limit) {\n\t\ty += ((z << 4 ^ z >> 5) + z) ^ (sum + ctx->KEY[sum&3]); \n\t\tsum += XTEA_DELTA;\n\t\tz += ((y << 4 ^ y >> 5) + y) ^ (sum + ctx->KEY[sum>>11 &3]); \n\t}\n\t\n\tout[0] = cpu_to_le32(y);\n\tout[1] = cpu_to_le32(z);\n}\n\nstatic void xtea_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tu32 y, z, sum;\n\tstruct tea_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *in = (const __le32 *)src;\n\t__le32 *out = (__le32 *)dst;\n\n\ty = le32_to_cpu(in[0]);\n\tz = le32_to_cpu(in[1]);\n\n\tsum = XTEA_DELTA * XTEA_ROUNDS;\n\n\twhile (sum) {\n\t\tz -= ((y << 4 ^ y >> 5) + y) ^ (sum + ctx->KEY[sum>>11 & 3]);\n\t\tsum -= XTEA_DELTA;\n\t\ty -= ((z << 4 ^ z >> 5) + z) ^ (sum + ctx->KEY[sum & 3]);\n\t}\n\t\n\tout[0] = cpu_to_le32(y);\n\tout[1] = cpu_to_le32(z);\n}\n\n\nstatic void xeta_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tu32 y, z, sum = 0;\n\tu32 limit = XTEA_DELTA * XTEA_ROUNDS;\n\tstruct xtea_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *in = (const __le32 *)src;\n\t__le32 *out = (__le32 *)dst;\n\n\ty = le32_to_cpu(in[0]);\n\tz = le32_to_cpu(in[1]);\n\n\twhile (sum != limit) {\n\t\ty += (z << 4 ^ z >> 5) + (z ^ sum) + ctx->KEY[sum&3];\n\t\tsum += XTEA_DELTA;\n\t\tz += (y << 4 ^ y >> 5) + (y ^ sum) + ctx->KEY[sum>>11 &3];\n\t}\n\t\n\tout[0] = cpu_to_le32(y);\n\tout[1] = cpu_to_le32(z);\n}\n\nstatic void xeta_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tu32 y, z, sum;\n\tstruct tea_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *in = (const __le32 *)src;\n\t__le32 *out = (__le32 *)dst;\n\n\ty = le32_to_cpu(in[0]);\n\tz = le32_to_cpu(in[1]);\n\n\tsum = XTEA_DELTA * XTEA_ROUNDS;\n\n\twhile (sum) {\n\t\tz -= (y << 4 ^ y >> 5) + (y ^ sum) + ctx->KEY[sum>>11 & 3];\n\t\tsum -= XTEA_DELTA;\n\t\ty -= (z << 4 ^ z >> 5) + (z ^ sum) + ctx->KEY[sum & 3];\n\t}\n\t\n\tout[0] = cpu_to_le32(y);\n\tout[1] = cpu_to_le32(z);\n}\n\nstatic struct crypto_alg tea_algs[3] = { {\n\t.cra_name\t\t=\t\"tea\",\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tTEA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof (struct tea_ctx),\n\t.cra_alignmask\t\t=\t3,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\tTEA_KEY_SIZE,\n\t.cia_max_keysize\t=\tTEA_KEY_SIZE,\n\t.cia_setkey\t\t= \ttea_setkey,\n\t.cia_encrypt\t\t=\ttea_encrypt,\n\t.cia_decrypt\t\t=\ttea_decrypt } }\n}, {\n\t.cra_name\t\t=\t\"xtea\",\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tXTEA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof (struct xtea_ctx),\n\t.cra_alignmask\t\t=\t3,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\tXTEA_KEY_SIZE,\n\t.cia_max_keysize\t=\tXTEA_KEY_SIZE,\n\t.cia_setkey\t\t= \txtea_setkey,\n\t.cia_encrypt\t\t=\txtea_encrypt,\n\t.cia_decrypt\t\t=\txtea_decrypt } }\n}, {\n\t.cra_name\t\t=\t\"xeta\",\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tXTEA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof (struct xtea_ctx),\n\t.cra_alignmask\t\t=\t3,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\tXTEA_KEY_SIZE,\n\t.cia_max_keysize\t=\tXTEA_KEY_SIZE,\n\t.cia_setkey\t\t= \txtea_setkey,\n\t.cia_encrypt\t\t=\txeta_encrypt,\n\t.cia_decrypt\t\t=\txeta_decrypt } }\n} };\n\nstatic int __init tea_mod_init(void)\n{\n\treturn crypto_register_algs(tea_algs, ARRAY_SIZE(tea_algs));\n}\n\nstatic void __exit tea_mod_fini(void)\n{\n\tcrypto_unregister_algs(tea_algs, ARRAY_SIZE(tea_algs));\n}\n\nMODULE_ALIAS(\"xtea\");\nMODULE_ALIAS(\"xeta\");\n\nmodule_init(tea_mod_init);\nmodule_exit(tea_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"TEA, XTEA & XETA Cryptographic Algorithms\");\n", "/*\n * Cryptographic API.\n *\n * Tiger hashing Algorithm\n *\n *      Copyright (C) 1998 Free Software Foundation, Inc.\n *\n * The Tiger algorithm was developed by Ross Anderson and Eli Biham.\n * It was optimized for 64-bit processors while still delievering\n * decent performance on 32 and 16-bit processors.\n *\n * This version is derived from the GnuPG implementation and the\n * Tiger-Perl interface written by Rafael Sevilla\n *\n * Adapted for Linux Kernel Crypto  by Aaron Grothe \n * ajgrothe@yahoo.com, February 22, 2005\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <asm/byteorder.h>\n#include <linux/types.h>\n\n#define TGR192_DIGEST_SIZE 24\n#define TGR160_DIGEST_SIZE 20\n#define TGR128_DIGEST_SIZE 16\n\n#define TGR192_BLOCK_SIZE  64\n\nstruct tgr192_ctx {\n\tu64 a, b, c;\n\tu8 hash[64];\n\tint count;\n\tu32 nblocks;\n};\n\nstatic const u64 sbox1[256] = {\n\t0x02aab17cf7e90c5eULL, 0xac424b03e243a8ecULL, 0x72cd5be30dd5fcd3ULL,\n\t0x6d019b93f6f97f3aULL, 0xcd9978ffd21f9193ULL, 0x7573a1c9708029e2ULL,\n\t0xb164326b922a83c3ULL, 0x46883eee04915870ULL, 0xeaace3057103ece6ULL,\n\t0xc54169b808a3535cULL, 0x4ce754918ddec47cULL, 0x0aa2f4dfdc0df40cULL,\n\t0x10b76f18a74dbefaULL, 0xc6ccb6235ad1ab6aULL, 0x13726121572fe2ffULL,\n\t0x1a488c6f199d921eULL, 0x4bc9f9f4da0007caULL, 0x26f5e6f6e85241c7ULL,\n\t0x859079dbea5947b6ULL, 0x4f1885c5c99e8c92ULL, 0xd78e761ea96f864bULL,\n\t0x8e36428c52b5c17dULL, 0x69cf6827373063c1ULL, 0xb607c93d9bb4c56eULL,\n\t0x7d820e760e76b5eaULL, 0x645c9cc6f07fdc42ULL, 0xbf38a078243342e0ULL,\n\t0x5f6b343c9d2e7d04ULL, 0xf2c28aeb600b0ec6ULL, 0x6c0ed85f7254bcacULL,\n\t0x71592281a4db4fe5ULL, 0x1967fa69ce0fed9fULL, 0xfd5293f8b96545dbULL,\n\t0xc879e9d7f2a7600bULL, 0x860248920193194eULL, 0xa4f9533b2d9cc0b3ULL,\n\t0x9053836c15957613ULL, 0xdb6dcf8afc357bf1ULL, 0x18beea7a7a370f57ULL,\n\t0x037117ca50b99066ULL, 0x6ab30a9774424a35ULL, 0xf4e92f02e325249bULL,\n\t0x7739db07061ccae1ULL, 0xd8f3b49ceca42a05ULL, 0xbd56be3f51382f73ULL,\n\t0x45faed5843b0bb28ULL, 0x1c813d5c11bf1f83ULL, 0x8af0e4b6d75fa169ULL,\n\t0x33ee18a487ad9999ULL, 0x3c26e8eab1c94410ULL, 0xb510102bc0a822f9ULL,\n\t0x141eef310ce6123bULL, 0xfc65b90059ddb154ULL, 0xe0158640c5e0e607ULL,\n\t0x884e079826c3a3cfULL, 0x930d0d9523c535fdULL, 0x35638d754e9a2b00ULL,\n\t0x4085fccf40469dd5ULL, 0xc4b17ad28be23a4cULL, 0xcab2f0fc6a3e6a2eULL,\n\t0x2860971a6b943fcdULL, 0x3dde6ee212e30446ULL, 0x6222f32ae01765aeULL,\n\t0x5d550bb5478308feULL, 0xa9efa98da0eda22aULL, 0xc351a71686c40da7ULL,\n\t0x1105586d9c867c84ULL, 0xdcffee85fda22853ULL, 0xccfbd0262c5eef76ULL,\n\t0xbaf294cb8990d201ULL, 0xe69464f52afad975ULL, 0x94b013afdf133e14ULL,\n\t0x06a7d1a32823c958ULL, 0x6f95fe5130f61119ULL, 0xd92ab34e462c06c0ULL,\n\t0xed7bde33887c71d2ULL, 0x79746d6e6518393eULL, 0x5ba419385d713329ULL,\n\t0x7c1ba6b948a97564ULL, 0x31987c197bfdac67ULL, 0xde6c23c44b053d02ULL,\n\t0x581c49fed002d64dULL, 0xdd474d6338261571ULL, 0xaa4546c3e473d062ULL,\n\t0x928fce349455f860ULL, 0x48161bbacaab94d9ULL, 0x63912430770e6f68ULL,\n\t0x6ec8a5e602c6641cULL, 0x87282515337ddd2bULL, 0x2cda6b42034b701bULL,\n\t0xb03d37c181cb096dULL, 0xe108438266c71c6fULL, 0x2b3180c7eb51b255ULL,\n\t0xdf92b82f96c08bbcULL, 0x5c68c8c0a632f3baULL, 0x5504cc861c3d0556ULL,\n\t0xabbfa4e55fb26b8fULL, 0x41848b0ab3baceb4ULL, 0xb334a273aa445d32ULL,\n\t0xbca696f0a85ad881ULL, 0x24f6ec65b528d56cULL, 0x0ce1512e90f4524aULL,\n\t0x4e9dd79d5506d35aULL, 0x258905fac6ce9779ULL, 0x2019295b3e109b33ULL,\n\t0xf8a9478b73a054ccULL, 0x2924f2f934417eb0ULL, 0x3993357d536d1bc4ULL,\n\t0x38a81ac21db6ff8bULL, 0x47c4fbf17d6016bfULL, 0x1e0faadd7667e3f5ULL,\n\t0x7abcff62938beb96ULL, 0xa78dad948fc179c9ULL, 0x8f1f98b72911e50dULL,\n\t0x61e48eae27121a91ULL, 0x4d62f7ad31859808ULL, 0xeceba345ef5ceaebULL,\n\t0xf5ceb25ebc9684ceULL, 0xf633e20cb7f76221ULL, 0xa32cdf06ab8293e4ULL,\n\t0x985a202ca5ee2ca4ULL, 0xcf0b8447cc8a8fb1ULL, 0x9f765244979859a3ULL,\n\t0xa8d516b1a1240017ULL, 0x0bd7ba3ebb5dc726ULL, 0xe54bca55b86adb39ULL,\n\t0x1d7a3afd6c478063ULL, 0x519ec608e7669eddULL, 0x0e5715a2d149aa23ULL,\n\t0x177d4571848ff194ULL, 0xeeb55f3241014c22ULL, 0x0f5e5ca13a6e2ec2ULL,\n\t0x8029927b75f5c361ULL, 0xad139fabc3d6e436ULL, 0x0d5df1a94ccf402fULL,\n\t0x3e8bd948bea5dfc8ULL, 0xa5a0d357bd3ff77eULL, 0xa2d12e251f74f645ULL,\n\t0x66fd9e525e81a082ULL, 0x2e0c90ce7f687a49ULL, 0xc2e8bcbeba973bc5ULL,\n\t0x000001bce509745fULL, 0x423777bbe6dab3d6ULL, 0xd1661c7eaef06eb5ULL,\n\t0xa1781f354daacfd8ULL, 0x2d11284a2b16affcULL, 0xf1fc4f67fa891d1fULL,\n\t0x73ecc25dcb920adaULL, 0xae610c22c2a12651ULL, 0x96e0a810d356b78aULL,\n\t0x5a9a381f2fe7870fULL, 0xd5ad62ede94e5530ULL, 0xd225e5e8368d1427ULL,\n\t0x65977b70c7af4631ULL, 0x99f889b2de39d74fULL, 0x233f30bf54e1d143ULL,\n\t0x9a9675d3d9a63c97ULL, 0x5470554ff334f9a8ULL, 0x166acb744a4f5688ULL,\n\t0x70c74caab2e4aeadULL, 0xf0d091646f294d12ULL, 0x57b82a89684031d1ULL,\n\t0xefd95a5a61be0b6bULL, 0x2fbd12e969f2f29aULL, 0x9bd37013feff9fe8ULL,\n\t0x3f9b0404d6085a06ULL, 0x4940c1f3166cfe15ULL, 0x09542c4dcdf3defbULL,\n\t0xb4c5218385cd5ce3ULL, 0xc935b7dc4462a641ULL, 0x3417f8a68ed3b63fULL,\n\t0xb80959295b215b40ULL, 0xf99cdaef3b8c8572ULL, 0x018c0614f8fcb95dULL,\n\t0x1b14accd1a3acdf3ULL, 0x84d471f200bb732dULL, 0xc1a3110e95e8da16ULL,\n\t0x430a7220bf1a82b8ULL, 0xb77e090d39df210eULL, 0x5ef4bd9f3cd05e9dULL,\n\t0x9d4ff6da7e57a444ULL, 0xda1d60e183d4a5f8ULL, 0xb287c38417998e47ULL,\n\t0xfe3edc121bb31886ULL, 0xc7fe3ccc980ccbefULL, 0xe46fb590189bfd03ULL,\n\t0x3732fd469a4c57dcULL, 0x7ef700a07cf1ad65ULL, 0x59c64468a31d8859ULL,\n\t0x762fb0b4d45b61f6ULL, 0x155baed099047718ULL, 0x68755e4c3d50baa6ULL,\n\t0xe9214e7f22d8b4dfULL, 0x2addbf532eac95f4ULL, 0x32ae3909b4bd0109ULL,\n\t0x834df537b08e3450ULL, 0xfa209da84220728dULL, 0x9e691d9b9efe23f7ULL,\n\t0x0446d288c4ae8d7fULL, 0x7b4cc524e169785bULL, 0x21d87f0135ca1385ULL,\n\t0xcebb400f137b8aa5ULL, 0x272e2b66580796beULL, 0x3612264125c2b0deULL,\n\t0x057702bdad1efbb2ULL, 0xd4babb8eacf84be9ULL, 0x91583139641bc67bULL,\n\t0x8bdc2de08036e024ULL, 0x603c8156f49f68edULL, 0xf7d236f7dbef5111ULL,\n\t0x9727c4598ad21e80ULL, 0xa08a0896670a5fd7ULL, 0xcb4a8f4309eba9cbULL,\n\t0x81af564b0f7036a1ULL, 0xc0b99aa778199abdULL, 0x959f1ec83fc8e952ULL,\n\t0x8c505077794a81b9ULL, 0x3acaaf8f056338f0ULL, 0x07b43f50627a6778ULL,\n\t0x4a44ab49f5eccc77ULL, 0x3bc3d6e4b679ee98ULL, 0x9cc0d4d1cf14108cULL,\n\t0x4406c00b206bc8a0ULL, 0x82a18854c8d72d89ULL, 0x67e366b35c3c432cULL,\n\t0xb923dd61102b37f2ULL, 0x56ab2779d884271dULL, 0xbe83e1b0ff1525afULL,\n\t0xfb7c65d4217e49a9ULL, 0x6bdbe0e76d48e7d4ULL, 0x08df828745d9179eULL,\n\t0x22ea6a9add53bd34ULL, 0xe36e141c5622200aULL, 0x7f805d1b8cb750eeULL,\n\t0xafe5c7a59f58e837ULL, 0xe27f996a4fb1c23cULL, 0xd3867dfb0775f0d0ULL,\n\t0xd0e673de6e88891aULL, 0x123aeb9eafb86c25ULL, 0x30f1d5d5c145b895ULL,\n\t0xbb434a2dee7269e7ULL, 0x78cb67ecf931fa38ULL, 0xf33b0372323bbf9cULL,\n\t0x52d66336fb279c74ULL, 0x505f33ac0afb4eaaULL, 0xe8a5cd99a2cce187ULL,\n\t0x534974801e2d30bbULL, 0x8d2d5711d5876d90ULL, 0x1f1a412891bc038eULL,\n\t0xd6e2e71d82e56648ULL, 0x74036c3a497732b7ULL, 0x89b67ed96361f5abULL,\n\t0xffed95d8f1ea02a2ULL, 0xe72b3bd61464d43dULL, 0xa6300f170bdc4820ULL,\n\t0xebc18760ed78a77aULL\n};\n\nstatic const u64 sbox2[256] = {\n\t0xe6a6be5a05a12138ULL, 0xb5a122a5b4f87c98ULL, 0x563c6089140b6990ULL,\n\t0x4c46cb2e391f5dd5ULL, 0xd932addbc9b79434ULL, 0x08ea70e42015aff5ULL,\n\t0xd765a6673e478cf1ULL, 0xc4fb757eab278d99ULL, 0xdf11c6862d6e0692ULL,\n\t0xddeb84f10d7f3b16ULL, 0x6f2ef604a665ea04ULL, 0x4a8e0f0ff0e0dfb3ULL,\n\t0xa5edeef83dbcba51ULL, 0xfc4f0a2a0ea4371eULL, 0xe83e1da85cb38429ULL,\n\t0xdc8ff882ba1b1ce2ULL, 0xcd45505e8353e80dULL, 0x18d19a00d4db0717ULL,\n\t0x34a0cfeda5f38101ULL, 0x0be77e518887caf2ULL, 0x1e341438b3c45136ULL,\n\t0xe05797f49089ccf9ULL, 0xffd23f9df2591d14ULL, 0x543dda228595c5cdULL,\n\t0x661f81fd99052a33ULL, 0x8736e641db0f7b76ULL, 0x15227725418e5307ULL,\n\t0xe25f7f46162eb2faULL, 0x48a8b2126c13d9feULL, 0xafdc541792e76eeaULL,\n\t0x03d912bfc6d1898fULL, 0x31b1aafa1b83f51bULL, 0xf1ac2796e42ab7d9ULL,\n\t0x40a3a7d7fcd2ebacULL, 0x1056136d0afbbcc5ULL, 0x7889e1dd9a6d0c85ULL,\n\t0xd33525782a7974aaULL, 0xa7e25d09078ac09bULL, 0xbd4138b3eac6edd0ULL,\n\t0x920abfbe71eb9e70ULL, 0xa2a5d0f54fc2625cULL, 0xc054e36b0b1290a3ULL,\n\t0xf6dd59ff62fe932bULL, 0x3537354511a8ac7dULL, 0xca845e9172fadcd4ULL,\n\t0x84f82b60329d20dcULL, 0x79c62ce1cd672f18ULL, 0x8b09a2add124642cULL,\n\t0xd0c1e96a19d9e726ULL, 0x5a786a9b4ba9500cULL, 0x0e020336634c43f3ULL,\n\t0xc17b474aeb66d822ULL, 0x6a731ae3ec9baac2ULL, 0x8226667ae0840258ULL,\n\t0x67d4567691caeca5ULL, 0x1d94155c4875adb5ULL, 0x6d00fd985b813fdfULL,\n\t0x51286efcb774cd06ULL, 0x5e8834471fa744afULL, 0xf72ca0aee761ae2eULL,\n\t0xbe40e4cdaee8e09aULL, 0xe9970bbb5118f665ULL, 0x726e4beb33df1964ULL,\n\t0x703b000729199762ULL, 0x4631d816f5ef30a7ULL, 0xb880b5b51504a6beULL,\n\t0x641793c37ed84b6cULL, 0x7b21ed77f6e97d96ULL, 0x776306312ef96b73ULL,\n\t0xae528948e86ff3f4ULL, 0x53dbd7f286a3f8f8ULL, 0x16cadce74cfc1063ULL,\n\t0x005c19bdfa52c6ddULL, 0x68868f5d64d46ad3ULL, 0x3a9d512ccf1e186aULL,\n\t0x367e62c2385660aeULL, 0xe359e7ea77dcb1d7ULL, 0x526c0773749abe6eULL,\n\t0x735ae5f9d09f734bULL, 0x493fc7cc8a558ba8ULL, 0xb0b9c1533041ab45ULL,\n\t0x321958ba470a59bdULL, 0x852db00b5f46c393ULL, 0x91209b2bd336b0e5ULL,\n\t0x6e604f7d659ef19fULL, 0xb99a8ae2782ccb24ULL, 0xccf52ab6c814c4c7ULL,\n\t0x4727d9afbe11727bULL, 0x7e950d0c0121b34dULL, 0x756f435670ad471fULL,\n\t0xf5add442615a6849ULL, 0x4e87e09980b9957aULL, 0x2acfa1df50aee355ULL,\n\t0xd898263afd2fd556ULL, 0xc8f4924dd80c8fd6ULL, 0xcf99ca3d754a173aULL,\n\t0xfe477bacaf91bf3cULL, 0xed5371f6d690c12dULL, 0x831a5c285e687094ULL,\n\t0xc5d3c90a3708a0a4ULL, 0x0f7f903717d06580ULL, 0x19f9bb13b8fdf27fULL,\n\t0xb1bd6f1b4d502843ULL, 0x1c761ba38fff4012ULL, 0x0d1530c4e2e21f3bULL,\n\t0x8943ce69a7372c8aULL, 0xe5184e11feb5ce66ULL, 0x618bdb80bd736621ULL,\n\t0x7d29bad68b574d0bULL, 0x81bb613e25e6fe5bULL, 0x071c9c10bc07913fULL,\n\t0xc7beeb7909ac2d97ULL, 0xc3e58d353bc5d757ULL, 0xeb017892f38f61e8ULL,\n\t0xd4effb9c9b1cc21aULL, 0x99727d26f494f7abULL, 0xa3e063a2956b3e03ULL,\n\t0x9d4a8b9a4aa09c30ULL, 0x3f6ab7d500090fb4ULL, 0x9cc0f2a057268ac0ULL,\n\t0x3dee9d2dedbf42d1ULL, 0x330f49c87960a972ULL, 0xc6b2720287421b41ULL,\n\t0x0ac59ec07c00369cULL, 0xef4eac49cb353425ULL, 0xf450244eef0129d8ULL,\n\t0x8acc46e5caf4deb6ULL, 0x2ffeab63989263f7ULL, 0x8f7cb9fe5d7a4578ULL,\n\t0x5bd8f7644e634635ULL, 0x427a7315bf2dc900ULL, 0x17d0c4aa2125261cULL,\n\t0x3992486c93518e50ULL, 0xb4cbfee0a2d7d4c3ULL, 0x7c75d6202c5ddd8dULL,\n\t0xdbc295d8e35b6c61ULL, 0x60b369d302032b19ULL, 0xce42685fdce44132ULL,\n\t0x06f3ddb9ddf65610ULL, 0x8ea4d21db5e148f0ULL, 0x20b0fce62fcd496fULL,\n\t0x2c1b912358b0ee31ULL, 0xb28317b818f5a308ULL, 0xa89c1e189ca6d2cfULL,\n\t0x0c6b18576aaadbc8ULL, 0xb65deaa91299fae3ULL, 0xfb2b794b7f1027e7ULL,\n\t0x04e4317f443b5bebULL, 0x4b852d325939d0a6ULL, 0xd5ae6beefb207ffcULL,\n\t0x309682b281c7d374ULL, 0xbae309a194c3b475ULL, 0x8cc3f97b13b49f05ULL,\n\t0x98a9422ff8293967ULL, 0x244b16b01076ff7cULL, 0xf8bf571c663d67eeULL,\n\t0x1f0d6758eee30da1ULL, 0xc9b611d97adeb9b7ULL, 0xb7afd5887b6c57a2ULL,\n\t0x6290ae846b984fe1ULL, 0x94df4cdeacc1a5fdULL, 0x058a5bd1c5483affULL,\n\t0x63166cc142ba3c37ULL, 0x8db8526eb2f76f40ULL, 0xe10880036f0d6d4eULL,\n\t0x9e0523c9971d311dULL, 0x45ec2824cc7cd691ULL, 0x575b8359e62382c9ULL,\n\t0xfa9e400dc4889995ULL, 0xd1823ecb45721568ULL, 0xdafd983b8206082fULL,\n\t0xaa7d29082386a8cbULL, 0x269fcd4403b87588ULL, 0x1b91f5f728bdd1e0ULL,\n\t0xe4669f39040201f6ULL, 0x7a1d7c218cf04adeULL, 0x65623c29d79ce5ceULL,\n\t0x2368449096c00bb1ULL, 0xab9bf1879da503baULL, 0xbc23ecb1a458058eULL,\n\t0x9a58df01bb401eccULL, 0xa070e868a85f143dULL, 0x4ff188307df2239eULL,\n\t0x14d565b41a641183ULL, 0xee13337452701602ULL, 0x950e3dcf3f285e09ULL,\n\t0x59930254b9c80953ULL, 0x3bf299408930da6dULL, 0xa955943f53691387ULL,\n\t0xa15edecaa9cb8784ULL, 0x29142127352be9a0ULL, 0x76f0371fff4e7afbULL,\n\t0x0239f450274f2228ULL, 0xbb073af01d5e868bULL, 0xbfc80571c10e96c1ULL,\n\t0xd267088568222e23ULL, 0x9671a3d48e80b5b0ULL, 0x55b5d38ae193bb81ULL,\n\t0x693ae2d0a18b04b8ULL, 0x5c48b4ecadd5335fULL, 0xfd743b194916a1caULL,\n\t0x2577018134be98c4ULL, 0xe77987e83c54a4adULL, 0x28e11014da33e1b9ULL,\n\t0x270cc59e226aa213ULL, 0x71495f756d1a5f60ULL, 0x9be853fb60afef77ULL,\n\t0xadc786a7f7443dbfULL, 0x0904456173b29a82ULL, 0x58bc7a66c232bd5eULL,\n\t0xf306558c673ac8b2ULL, 0x41f639c6b6c9772aULL, 0x216defe99fda35daULL,\n\t0x11640cc71c7be615ULL, 0x93c43694565c5527ULL, 0xea038e6246777839ULL,\n\t0xf9abf3ce5a3e2469ULL, 0x741e768d0fd312d2ULL, 0x0144b883ced652c6ULL,\n\t0xc20b5a5ba33f8552ULL, 0x1ae69633c3435a9dULL, 0x97a28ca4088cfdecULL,\n\t0x8824a43c1e96f420ULL, 0x37612fa66eeea746ULL, 0x6b4cb165f9cf0e5aULL,\n\t0x43aa1c06a0abfb4aULL, 0x7f4dc26ff162796bULL, 0x6cbacc8e54ed9b0fULL,\n\t0xa6b7ffefd2bb253eULL, 0x2e25bc95b0a29d4fULL, 0x86d6a58bdef1388cULL,\n\t0xded74ac576b6f054ULL, 0x8030bdbc2b45805dULL, 0x3c81af70e94d9289ULL,\n\t0x3eff6dda9e3100dbULL, 0xb38dc39fdfcc8847ULL, 0x123885528d17b87eULL,\n\t0xf2da0ed240b1b642ULL, 0x44cefadcd54bf9a9ULL, 0x1312200e433c7ee6ULL,\n\t0x9ffcc84f3a78c748ULL, 0xf0cd1f72248576bbULL, 0xec6974053638cfe4ULL,\n\t0x2ba7b67c0cec4e4cULL, 0xac2f4df3e5ce32edULL, 0xcb33d14326ea4c11ULL,\n\t0xa4e9044cc77e58bcULL, 0x5f513293d934fcefULL, 0x5dc9645506e55444ULL,\n\t0x50de418f317de40aULL, 0x388cb31a69dde259ULL, 0x2db4a83455820a86ULL,\n\t0x9010a91e84711ae9ULL, 0x4df7f0b7b1498371ULL, 0xd62a2eabc0977179ULL,\n\t0x22fac097aa8d5c0eULL\n};\n\nstatic const u64 sbox3[256] = {\n\t0xf49fcc2ff1daf39bULL, 0x487fd5c66ff29281ULL, 0xe8a30667fcdca83fULL,\n\t0x2c9b4be3d2fcce63ULL, 0xda3ff74b93fbbbc2ULL, 0x2fa165d2fe70ba66ULL,\n\t0xa103e279970e93d4ULL, 0xbecdec77b0e45e71ULL, 0xcfb41e723985e497ULL,\n\t0xb70aaa025ef75017ULL, 0xd42309f03840b8e0ULL, 0x8efc1ad035898579ULL,\n\t0x96c6920be2b2abc5ULL, 0x66af4163375a9172ULL, 0x2174abdcca7127fbULL,\n\t0xb33ccea64a72ff41ULL, 0xf04a4933083066a5ULL, 0x8d970acdd7289af5ULL,\n\t0x8f96e8e031c8c25eULL, 0xf3fec02276875d47ULL, 0xec7bf310056190ddULL,\n\t0xf5adb0aebb0f1491ULL, 0x9b50f8850fd58892ULL, 0x4975488358b74de8ULL,\n\t0xa3354ff691531c61ULL, 0x0702bbe481d2c6eeULL, 0x89fb24057deded98ULL,\n\t0xac3075138596e902ULL, 0x1d2d3580172772edULL, 0xeb738fc28e6bc30dULL,\n\t0x5854ef8f63044326ULL, 0x9e5c52325add3bbeULL, 0x90aa53cf325c4623ULL,\n\t0xc1d24d51349dd067ULL, 0x2051cfeea69ea624ULL, 0x13220f0a862e7e4fULL,\n\t0xce39399404e04864ULL, 0xd9c42ca47086fcb7ULL, 0x685ad2238a03e7ccULL,\n\t0x066484b2ab2ff1dbULL, 0xfe9d5d70efbf79ecULL, 0x5b13b9dd9c481854ULL,\n\t0x15f0d475ed1509adULL, 0x0bebcd060ec79851ULL, 0xd58c6791183ab7f8ULL,\n\t0xd1187c5052f3eee4ULL, 0xc95d1192e54e82ffULL, 0x86eea14cb9ac6ca2ULL,\n\t0x3485beb153677d5dULL, 0xdd191d781f8c492aULL, 0xf60866baa784ebf9ULL,\n\t0x518f643ba2d08c74ULL, 0x8852e956e1087c22ULL, 0xa768cb8dc410ae8dULL,\n\t0x38047726bfec8e1aULL, 0xa67738b4cd3b45aaULL, 0xad16691cec0dde19ULL,\n\t0xc6d4319380462e07ULL, 0xc5a5876d0ba61938ULL, 0x16b9fa1fa58fd840ULL,\n\t0x188ab1173ca74f18ULL, 0xabda2f98c99c021fULL, 0x3e0580ab134ae816ULL,\n\t0x5f3b05b773645abbULL, 0x2501a2be5575f2f6ULL, 0x1b2f74004e7e8ba9ULL,\n\t0x1cd7580371e8d953ULL, 0x7f6ed89562764e30ULL, 0xb15926ff596f003dULL,\n\t0x9f65293da8c5d6b9ULL, 0x6ecef04dd690f84cULL, 0x4782275fff33af88ULL,\n\t0xe41433083f820801ULL, 0xfd0dfe409a1af9b5ULL, 0x4325a3342cdb396bULL,\n\t0x8ae77e62b301b252ULL, 0xc36f9e9f6655615aULL, 0x85455a2d92d32c09ULL,\n\t0xf2c7dea949477485ULL, 0x63cfb4c133a39ebaULL, 0x83b040cc6ebc5462ULL,\n\t0x3b9454c8fdb326b0ULL, 0x56f56a9e87ffd78cULL, 0x2dc2940d99f42bc6ULL,\n\t0x98f7df096b096e2dULL, 0x19a6e01e3ad852bfULL, 0x42a99ccbdbd4b40bULL,\n\t0xa59998af45e9c559ULL, 0x366295e807d93186ULL, 0x6b48181bfaa1f773ULL,\n\t0x1fec57e2157a0a1dULL, 0x4667446af6201ad5ULL, 0xe615ebcacfb0f075ULL,\n\t0xb8f31f4f68290778ULL, 0x22713ed6ce22d11eULL, 0x3057c1a72ec3c93bULL,\n\t0xcb46acc37c3f1f2fULL, 0xdbb893fd02aaf50eULL, 0x331fd92e600b9fcfULL,\n\t0xa498f96148ea3ad6ULL, 0xa8d8426e8b6a83eaULL, 0xa089b274b7735cdcULL,\n\t0x87f6b3731e524a11ULL, 0x118808e5cbc96749ULL, 0x9906e4c7b19bd394ULL,\n\t0xafed7f7e9b24a20cULL, 0x6509eadeeb3644a7ULL, 0x6c1ef1d3e8ef0edeULL,\n\t0xb9c97d43e9798fb4ULL, 0xa2f2d784740c28a3ULL, 0x7b8496476197566fULL,\n\t0x7a5be3e6b65f069dULL, 0xf96330ed78be6f10ULL, 0xeee60de77a076a15ULL,\n\t0x2b4bee4aa08b9bd0ULL, 0x6a56a63ec7b8894eULL, 0x02121359ba34fef4ULL,\n\t0x4cbf99f8283703fcULL, 0x398071350caf30c8ULL, 0xd0a77a89f017687aULL,\n\t0xf1c1a9eb9e423569ULL, 0x8c7976282dee8199ULL, 0x5d1737a5dd1f7abdULL,\n\t0x4f53433c09a9fa80ULL, 0xfa8b0c53df7ca1d9ULL, 0x3fd9dcbc886ccb77ULL,\n\t0xc040917ca91b4720ULL, 0x7dd00142f9d1dcdfULL, 0x8476fc1d4f387b58ULL,\n\t0x23f8e7c5f3316503ULL, 0x032a2244e7e37339ULL, 0x5c87a5d750f5a74bULL,\n\t0x082b4cc43698992eULL, 0xdf917becb858f63cULL, 0x3270b8fc5bf86ddaULL,\n\t0x10ae72bb29b5dd76ULL, 0x576ac94e7700362bULL, 0x1ad112dac61efb8fULL,\n\t0x691bc30ec5faa427ULL, 0xff246311cc327143ULL, 0x3142368e30e53206ULL,\n\t0x71380e31e02ca396ULL, 0x958d5c960aad76f1ULL, 0xf8d6f430c16da536ULL,\n\t0xc8ffd13f1be7e1d2ULL, 0x7578ae66004ddbe1ULL, 0x05833f01067be646ULL,\n\t0xbb34b5ad3bfe586dULL, 0x095f34c9a12b97f0ULL, 0x247ab64525d60ca8ULL,\n\t0xdcdbc6f3017477d1ULL, 0x4a2e14d4decad24dULL, 0xbdb5e6d9be0a1eebULL,\n\t0x2a7e70f7794301abULL, 0xdef42d8a270540fdULL, 0x01078ec0a34c22c1ULL,\n\t0xe5de511af4c16387ULL, 0x7ebb3a52bd9a330aULL, 0x77697857aa7d6435ULL,\n\t0x004e831603ae4c32ULL, 0xe7a21020ad78e312ULL, 0x9d41a70c6ab420f2ULL,\n\t0x28e06c18ea1141e6ULL, 0xd2b28cbd984f6b28ULL, 0x26b75f6c446e9d83ULL,\n\t0xba47568c4d418d7fULL, 0xd80badbfe6183d8eULL, 0x0e206d7f5f166044ULL,\n\t0xe258a43911cbca3eULL, 0x723a1746b21dc0bcULL, 0xc7caa854f5d7cdd3ULL,\n\t0x7cac32883d261d9cULL, 0x7690c26423ba942cULL, 0x17e55524478042b8ULL,\n\t0xe0be477656a2389fULL, 0x4d289b5e67ab2da0ULL, 0x44862b9c8fbbfd31ULL,\n\t0xb47cc8049d141365ULL, 0x822c1b362b91c793ULL, 0x4eb14655fb13dfd8ULL,\n\t0x1ecbba0714e2a97bULL, 0x6143459d5cde5f14ULL, 0x53a8fbf1d5f0ac89ULL,\n\t0x97ea04d81c5e5b00ULL, 0x622181a8d4fdb3f3ULL, 0xe9bcd341572a1208ULL,\n\t0x1411258643cce58aULL, 0x9144c5fea4c6e0a4ULL, 0x0d33d06565cf620fULL,\n\t0x54a48d489f219ca1ULL, 0xc43e5eac6d63c821ULL, 0xa9728b3a72770dafULL,\n\t0xd7934e7b20df87efULL, 0xe35503b61a3e86e5ULL, 0xcae321fbc819d504ULL,\n\t0x129a50b3ac60bfa6ULL, 0xcd5e68ea7e9fb6c3ULL, 0xb01c90199483b1c7ULL,\n\t0x3de93cd5c295376cULL, 0xaed52edf2ab9ad13ULL, 0x2e60f512c0a07884ULL,\n\t0xbc3d86a3e36210c9ULL, 0x35269d9b163951ceULL, 0x0c7d6e2ad0cdb5faULL,\n\t0x59e86297d87f5733ULL, 0x298ef221898db0e7ULL, 0x55000029d1a5aa7eULL,\n\t0x8bc08ae1b5061b45ULL, 0xc2c31c2b6c92703aULL, 0x94cc596baf25ef42ULL,\n\t0x0a1d73db22540456ULL, 0x04b6a0f9d9c4179aULL, 0xeffdafa2ae3d3c60ULL,\n\t0xf7c8075bb49496c4ULL, 0x9cc5c7141d1cd4e3ULL, 0x78bd1638218e5534ULL,\n\t0xb2f11568f850246aULL, 0xedfabcfa9502bc29ULL, 0x796ce5f2da23051bULL,\n\t0xaae128b0dc93537cULL, 0x3a493da0ee4b29aeULL, 0xb5df6b2c416895d7ULL,\n\t0xfcabbd25122d7f37ULL, 0x70810b58105dc4b1ULL, 0xe10fdd37f7882a90ULL,\n\t0x524dcab5518a3f5cULL, 0x3c9e85878451255bULL, 0x4029828119bd34e2ULL,\n\t0x74a05b6f5d3ceccbULL, 0xb610021542e13ecaULL, 0x0ff979d12f59e2acULL,\n\t0x6037da27e4f9cc50ULL, 0x5e92975a0df1847dULL, 0xd66de190d3e623feULL,\n\t0x5032d6b87b568048ULL, 0x9a36b7ce8235216eULL, 0x80272a7a24f64b4aULL,\n\t0x93efed8b8c6916f7ULL, 0x37ddbff44cce1555ULL, 0x4b95db5d4b99bd25ULL,\n\t0x92d3fda169812fc0ULL, 0xfb1a4a9a90660bb6ULL, 0x730c196946a4b9b2ULL,\n\t0x81e289aa7f49da68ULL, 0x64669a0f83b1a05fULL, 0x27b3ff7d9644f48bULL,\n\t0xcc6b615c8db675b3ULL, 0x674f20b9bcebbe95ULL, 0x6f31238275655982ULL,\n\t0x5ae488713e45cf05ULL, 0xbf619f9954c21157ULL, 0xeabac46040a8eae9ULL,\n\t0x454c6fe9f2c0c1cdULL, 0x419cf6496412691cULL, 0xd3dc3bef265b0f70ULL,\n\t0x6d0e60f5c3578a9eULL\n};\n\nstatic const u64 sbox4[256] = {\n\t0x5b0e608526323c55ULL, 0x1a46c1a9fa1b59f5ULL, 0xa9e245a17c4c8ffaULL,\n\t0x65ca5159db2955d7ULL, 0x05db0a76ce35afc2ULL, 0x81eac77ea9113d45ULL,\n\t0x528ef88ab6ac0a0dULL, 0xa09ea253597be3ffULL, 0x430ddfb3ac48cd56ULL,\n\t0xc4b3a67af45ce46fULL, 0x4ececfd8fbe2d05eULL, 0x3ef56f10b39935f0ULL,\n\t0x0b22d6829cd619c6ULL, 0x17fd460a74df2069ULL, 0x6cf8cc8e8510ed40ULL,\n\t0xd6c824bf3a6ecaa7ULL, 0x61243d581a817049ULL, 0x048bacb6bbc163a2ULL,\n\t0xd9a38ac27d44cc32ULL, 0x7fddff5baaf410abULL, 0xad6d495aa804824bULL,\n\t0xe1a6a74f2d8c9f94ULL, 0xd4f7851235dee8e3ULL, 0xfd4b7f886540d893ULL,\n\t0x247c20042aa4bfdaULL, 0x096ea1c517d1327cULL, 0xd56966b4361a6685ULL,\n\t0x277da5c31221057dULL, 0x94d59893a43acff7ULL, 0x64f0c51ccdc02281ULL,\n\t0x3d33bcc4ff6189dbULL, 0xe005cb184ce66af1ULL, 0xff5ccd1d1db99beaULL,\n\t0xb0b854a7fe42980fULL, 0x7bd46a6a718d4b9fULL, 0xd10fa8cc22a5fd8cULL,\n\t0xd31484952be4bd31ULL, 0xc7fa975fcb243847ULL, 0x4886ed1e5846c407ULL,\n\t0x28cddb791eb70b04ULL, 0xc2b00be2f573417fULL, 0x5c9590452180f877ULL,\n\t0x7a6bddfff370eb00ULL, 0xce509e38d6d9d6a4ULL, 0xebeb0f00647fa702ULL,\n\t0x1dcc06cf76606f06ULL, 0xe4d9f28ba286ff0aULL, 0xd85a305dc918c262ULL,\n\t0x475b1d8732225f54ULL, 0x2d4fb51668ccb5feULL, 0xa679b9d9d72bba20ULL,\n\t0x53841c0d912d43a5ULL, 0x3b7eaa48bf12a4e8ULL, 0x781e0e47f22f1ddfULL,\n\t0xeff20ce60ab50973ULL, 0x20d261d19dffb742ULL, 0x16a12b03062a2e39ULL,\n\t0x1960eb2239650495ULL, 0x251c16fed50eb8b8ULL, 0x9ac0c330f826016eULL,\n\t0xed152665953e7671ULL, 0x02d63194a6369570ULL, 0x5074f08394b1c987ULL,\n\t0x70ba598c90b25ce1ULL, 0x794a15810b9742f6ULL, 0x0d5925e9fcaf8c6cULL,\n\t0x3067716cd868744eULL, 0x910ab077e8d7731bULL, 0x6a61bbdb5ac42f61ULL,\n\t0x93513efbf0851567ULL, 0xf494724b9e83e9d5ULL, 0xe887e1985c09648dULL,\n\t0x34b1d3c675370cfdULL, 0xdc35e433bc0d255dULL, 0xd0aab84234131be0ULL,\n\t0x08042a50b48b7eafULL, 0x9997c4ee44a3ab35ULL, 0x829a7b49201799d0ULL,\n\t0x263b8307b7c54441ULL, 0x752f95f4fd6a6ca6ULL, 0x927217402c08c6e5ULL,\n\t0x2a8ab754a795d9eeULL, 0xa442f7552f72943dULL, 0x2c31334e19781208ULL,\n\t0x4fa98d7ceaee6291ULL, 0x55c3862f665db309ULL, 0xbd0610175d53b1f3ULL,\n\t0x46fe6cb840413f27ULL, 0x3fe03792df0cfa59ULL, 0xcfe700372eb85e8fULL,\n\t0xa7be29e7adbce118ULL, 0xe544ee5cde8431ddULL, 0x8a781b1b41f1873eULL,\n\t0xa5c94c78a0d2f0e7ULL, 0x39412e2877b60728ULL, 0xa1265ef3afc9a62cULL,\n\t0xbcc2770c6a2506c5ULL, 0x3ab66dd5dce1ce12ULL, 0xe65499d04a675b37ULL,\n\t0x7d8f523481bfd216ULL, 0x0f6f64fcec15f389ULL, 0x74efbe618b5b13c8ULL,\n\t0xacdc82b714273e1dULL, 0xdd40bfe003199d17ULL, 0x37e99257e7e061f8ULL,\n\t0xfa52626904775aaaULL, 0x8bbbf63a463d56f9ULL, 0xf0013f1543a26e64ULL,\n\t0xa8307e9f879ec898ULL, 0xcc4c27a4150177ccULL, 0x1b432f2cca1d3348ULL,\n\t0xde1d1f8f9f6fa013ULL, 0x606602a047a7ddd6ULL, 0xd237ab64cc1cb2c7ULL,\n\t0x9b938e7225fcd1d3ULL, 0xec4e03708e0ff476ULL, 0xfeb2fbda3d03c12dULL,\n\t0xae0bced2ee43889aULL, 0x22cb8923ebfb4f43ULL, 0x69360d013cf7396dULL,\n\t0x855e3602d2d4e022ULL, 0x073805bad01f784cULL, 0x33e17a133852f546ULL,\n\t0xdf4874058ac7b638ULL, 0xba92b29c678aa14aULL, 0x0ce89fc76cfaadcdULL,\n\t0x5f9d4e0908339e34ULL, 0xf1afe9291f5923b9ULL, 0x6e3480f60f4a265fULL,\n\t0xeebf3a2ab29b841cULL, 0xe21938a88f91b4adULL, 0x57dfeff845c6d3c3ULL,\n\t0x2f006b0bf62caaf2ULL, 0x62f479ef6f75ee78ULL, 0x11a55ad41c8916a9ULL,\n\t0xf229d29084fed453ULL, 0x42f1c27b16b000e6ULL, 0x2b1f76749823c074ULL,\n\t0x4b76eca3c2745360ULL, 0x8c98f463b91691bdULL, 0x14bcc93cf1ade66aULL,\n\t0x8885213e6d458397ULL, 0x8e177df0274d4711ULL, 0xb49b73b5503f2951ULL,\n\t0x10168168c3f96b6bULL, 0x0e3d963b63cab0aeULL, 0x8dfc4b5655a1db14ULL,\n\t0xf789f1356e14de5cULL, 0x683e68af4e51dac1ULL, 0xc9a84f9d8d4b0fd9ULL,\n\t0x3691e03f52a0f9d1ULL, 0x5ed86e46e1878e80ULL, 0x3c711a0e99d07150ULL,\n\t0x5a0865b20c4e9310ULL, 0x56fbfc1fe4f0682eULL, 0xea8d5de3105edf9bULL,\n\t0x71abfdb12379187aULL, 0x2eb99de1bee77b9cULL, 0x21ecc0ea33cf4523ULL,\n\t0x59a4d7521805c7a1ULL, 0x3896f5eb56ae7c72ULL, 0xaa638f3db18f75dcULL,\n\t0x9f39358dabe9808eULL, 0xb7defa91c00b72acULL, 0x6b5541fd62492d92ULL,\n\t0x6dc6dee8f92e4d5bULL, 0x353f57abc4beea7eULL, 0x735769d6da5690ceULL,\n\t0x0a234aa642391484ULL, 0xf6f9508028f80d9dULL, 0xb8e319a27ab3f215ULL,\n\t0x31ad9c1151341a4dULL, 0x773c22a57bef5805ULL, 0x45c7561a07968633ULL,\n\t0xf913da9e249dbe36ULL, 0xda652d9b78a64c68ULL, 0x4c27a97f3bc334efULL,\n\t0x76621220e66b17f4ULL, 0x967743899acd7d0bULL, 0xf3ee5bcae0ed6782ULL,\n\t0x409f753600c879fcULL, 0x06d09a39b5926db6ULL, 0x6f83aeb0317ac588ULL,\n\t0x01e6ca4a86381f21ULL, 0x66ff3462d19f3025ULL, 0x72207c24ddfd3bfbULL,\n\t0x4af6b6d3e2ece2ebULL, 0x9c994dbec7ea08deULL, 0x49ace597b09a8bc4ULL,\n\t0xb38c4766cf0797baULL, 0x131b9373c57c2a75ULL, 0xb1822cce61931e58ULL,\n\t0x9d7555b909ba1c0cULL, 0x127fafdd937d11d2ULL, 0x29da3badc66d92e4ULL,\n\t0xa2c1d57154c2ecbcULL, 0x58c5134d82f6fe24ULL, 0x1c3ae3515b62274fULL,\n\t0xe907c82e01cb8126ULL, 0xf8ed091913e37fcbULL, 0x3249d8f9c80046c9ULL,\n\t0x80cf9bede388fb63ULL, 0x1881539a116cf19eULL, 0x5103f3f76bd52457ULL,\n\t0x15b7e6f5ae47f7a8ULL, 0xdbd7c6ded47e9ccfULL, 0x44e55c410228bb1aULL,\n\t0xb647d4255edb4e99ULL, 0x5d11882bb8aafc30ULL, 0xf5098bbb29d3212aULL,\n\t0x8fb5ea14e90296b3ULL, 0x677b942157dd025aULL, 0xfb58e7c0a390acb5ULL,\n\t0x89d3674c83bd4a01ULL, 0x9e2da4df4bf3b93bULL, 0xfcc41e328cab4829ULL,\n\t0x03f38c96ba582c52ULL, 0xcad1bdbd7fd85db2ULL, 0xbbb442c16082ae83ULL,\n\t0xb95fe86ba5da9ab0ULL, 0xb22e04673771a93fULL, 0x845358c9493152d8ULL,\n\t0xbe2a488697b4541eULL, 0x95a2dc2dd38e6966ULL, 0xc02c11ac923c852bULL,\n\t0x2388b1990df2a87bULL, 0x7c8008fa1b4f37beULL, 0x1f70d0c84d54e503ULL,\n\t0x5490adec7ece57d4ULL, 0x002b3c27d9063a3aULL, 0x7eaea3848030a2bfULL,\n\t0xc602326ded2003c0ULL, 0x83a7287d69a94086ULL, 0xc57a5fcb30f57a8aULL,\n\t0xb56844e479ebe779ULL, 0xa373b40f05dcbce9ULL, 0xd71a786e88570ee2ULL,\n\t0x879cbacdbde8f6a0ULL, 0x976ad1bcc164a32fULL, 0xab21e25e9666d78bULL,\n\t0x901063aae5e5c33cULL, 0x9818b34448698d90ULL, 0xe36487ae3e1e8abbULL,\n\t0xafbdf931893bdcb4ULL, 0x6345a0dc5fbbd519ULL, 0x8628fe269b9465caULL,\n\t0x1e5d01603f9c51ecULL, 0x4de44006a15049b7ULL, 0xbf6c70e5f776cbb1ULL,\n\t0x411218f2ef552bedULL, 0xcb0c0708705a36a3ULL, 0xe74d14754f986044ULL,\n\t0xcd56d9430ea8280eULL, 0xc12591d7535f5065ULL, 0xc83223f1720aef96ULL,\n\t0xc3a0396f7363a51fULL\n};\n\n\nstatic void tgr192_round(u64 * ra, u64 * rb, u64 * rc, u64 x, int mul)\n{\n\tu64 a = *ra;\n\tu64 b = *rb;\n\tu64 c = *rc;\n\n\tc ^= x;\n\ta -= sbox1[c         & 0xff] ^ sbox2[(c >> 16) & 0xff]\n\t   ^ sbox3[(c >> 32) & 0xff] ^ sbox4[(c >> 48) & 0xff];\n\tb += sbox4[(c >>  8) & 0xff] ^ sbox3[(c >> 24) & 0xff]\n\t   ^ sbox2[(c >> 40) & 0xff] ^ sbox1[(c >> 56) & 0xff];\n\tb *= mul;\n\n\t*ra = a;\n\t*rb = b;\n\t*rc = c;\n}\n\n\nstatic void tgr192_pass(u64 * ra, u64 * rb, u64 * rc, u64 * x, int mul)\n{\n\tu64 a = *ra;\n\tu64 b = *rb;\n\tu64 c = *rc;\n\n\ttgr192_round(&a, &b, &c, x[0], mul);\n\ttgr192_round(&b, &c, &a, x[1], mul);\n\ttgr192_round(&c, &a, &b, x[2], mul);\n\ttgr192_round(&a, &b, &c, x[3], mul);\n\ttgr192_round(&b, &c, &a, x[4], mul);\n\ttgr192_round(&c, &a, &b, x[5], mul);\n\ttgr192_round(&a, &b, &c, x[6], mul);\n\ttgr192_round(&b, &c, &a, x[7], mul);\n\n\t*ra = a;\n\t*rb = b;\n\t*rc = c;\n}\n\n\nstatic void tgr192_key_schedule(u64 * x)\n{\n\tx[0] -= x[7] ^ 0xa5a5a5a5a5a5a5a5ULL;\n\tx[1] ^= x[0];\n\tx[2] += x[1];\n\tx[3] -= x[2] ^ ((~x[1]) << 19);\n\tx[4] ^= x[3];\n\tx[5] += x[4];\n\tx[6] -= x[5] ^ ((~x[4]) >> 23);\n\tx[7] ^= x[6];\n\tx[0] += x[7];\n\tx[1] -= x[0] ^ ((~x[7]) << 19);\n\tx[2] ^= x[1];\n\tx[3] += x[2];\n\tx[4] -= x[3] ^ ((~x[2]) >> 23);\n\tx[5] ^= x[4];\n\tx[6] += x[5];\n\tx[7] -= x[6] ^ 0x0123456789abcdefULL;\n}\n\n\n/****************\n * Transform the message DATA which consists of 512 bytes (8 words)\n */\n\nstatic void tgr192_transform(struct tgr192_ctx *tctx, const u8 * data)\n{\n\tu64 a, b, c, aa, bb, cc;\n\tu64 x[8];\n\tint i;\n\tconst __le64 *ptr = (const __le64 *)data;\n\n\tfor (i = 0; i < 8; i++)\n\t\tx[i] = le64_to_cpu(ptr[i]);\n\n\t/* save */\n\ta = aa = tctx->a;\n\tb = bb = tctx->b;\n\tc = cc = tctx->c;\n\n\ttgr192_pass(&a, &b, &c, x, 5);\n\ttgr192_key_schedule(x);\n\ttgr192_pass(&c, &a, &b, x, 7);\n\ttgr192_key_schedule(x);\n\ttgr192_pass(&b, &c, &a, x, 9);\n\n\n\t/* feedforward */\n\ta ^= aa;\n\tb -= bb;\n\tc += cc;\n\t/* store */\n\ttctx->a = a;\n\ttctx->b = b;\n\ttctx->c = c;\n}\n\nstatic int tgr192_init(struct shash_desc *desc)\n{\n\tstruct tgr192_ctx *tctx = shash_desc_ctx(desc);\n\n\ttctx->a = 0x0123456789abcdefULL;\n\ttctx->b = 0xfedcba9876543210ULL;\n\ttctx->c = 0xf096a5b4c3b2e187ULL;\n\ttctx->nblocks = 0;\n\ttctx->count = 0;\n\n\treturn 0;\n}\n\n\n/* Update the message digest with the contents\n * of INBUF with length INLEN. */\nstatic int tgr192_update(struct shash_desc *desc, const u8 *inbuf,\n\t\t\t  unsigned int len)\n{\n\tstruct tgr192_ctx *tctx = shash_desc_ctx(desc);\n\n\tif (tctx->count == 64) {\t/* flush the buffer */\n\t\ttgr192_transform(tctx, tctx->hash);\n\t\ttctx->count = 0;\n\t\ttctx->nblocks++;\n\t}\n\tif (!inbuf) {\n\t\treturn 0;\n\t}\n\tif (tctx->count) {\n\t\tfor (; len && tctx->count < 64; len--) {\n\t\t\ttctx->hash[tctx->count++] = *inbuf++;\n\t\t}\n\t\ttgr192_update(desc, NULL, 0);\n\t\tif (!len) {\n\t\t\treturn 0;\n\t\t}\n\n\t}\n\n\twhile (len >= 64) {\n\t\ttgr192_transform(tctx, inbuf);\n\t\ttctx->count = 0;\n\t\ttctx->nblocks++;\n\t\tlen -= 64;\n\t\tinbuf += 64;\n\t}\n\tfor (; len && tctx->count < 64; len--) {\n\t\ttctx->hash[tctx->count++] = *inbuf++;\n\t}\n\n\treturn 0;\n}\n\n\n\n/* The routine terminates the computation */\nstatic int tgr192_final(struct shash_desc *desc, u8 * out)\n{\n\tstruct tgr192_ctx *tctx = shash_desc_ctx(desc);\n\t__be64 *dst = (__be64 *)out;\n\t__be64 *be64p;\n\t__le32 *le32p;\n\tu32 t, msb, lsb;\n\n\ttgr192_update(desc, NULL, 0); /* flush */ ;\n\n\tmsb = 0;\n\tt = tctx->nblocks;\n\tif ((lsb = t << 6) < t) { /* multiply by 64 to make a byte count */\n\t\tmsb++;\n\t}\n\tmsb += t >> 26;\n\tt = lsb;\n\tif ((lsb = t + tctx->count) < t) {\t/* add the count */\n\t\tmsb++;\n\t}\n\tt = lsb;\n\tif ((lsb = t << 3) < t)\t{ /* multiply by 8 to make a bit count */\n\t\tmsb++;\n\t}\n\tmsb += t >> 29;\n\n\tif (tctx->count < 56) {\t/* enough room */\n\t\ttctx->hash[tctx->count++] = 0x01;\t/* pad */\n\t\twhile (tctx->count < 56) {\n\t\t\ttctx->hash[tctx->count++] = 0;\t/* pad */\n\t\t}\n\t} else {\t\t/* need one extra block */\n\t\ttctx->hash[tctx->count++] = 0x01;\t/* pad character */\n\t\twhile (tctx->count < 64) {\n\t\t\ttctx->hash[tctx->count++] = 0;\n\t\t}\n\t\ttgr192_update(desc, NULL, 0); /* flush */ ;\n\t\tmemset(tctx->hash, 0, 56);    /* fill next block with zeroes */\n\t}\n\t/* append the 64 bit count */\n\tle32p = (__le32 *)&tctx->hash[56];\n\tle32p[0] = cpu_to_le32(lsb);\n\tle32p[1] = cpu_to_le32(msb);\n\n\ttgr192_transform(tctx, tctx->hash);\n\n\tbe64p = (__be64 *)tctx->hash;\n\tdst[0] = be64p[0] = cpu_to_be64(tctx->a);\n\tdst[1] = be64p[1] = cpu_to_be64(tctx->b);\n\tdst[2] = be64p[2] = cpu_to_be64(tctx->c);\n\n\treturn 0;\n}\n\nstatic int tgr160_final(struct shash_desc *desc, u8 * out)\n{\n\tu8 D[64];\n\n\ttgr192_final(desc, D);\n\tmemcpy(out, D, TGR160_DIGEST_SIZE);\n\tmemzero_explicit(D, TGR192_DIGEST_SIZE);\n\n\treturn 0;\n}\n\nstatic int tgr128_final(struct shash_desc *desc, u8 * out)\n{\n\tu8 D[64];\n\n\ttgr192_final(desc, D);\n\tmemcpy(out, D, TGR128_DIGEST_SIZE);\n\tmemzero_explicit(D, TGR192_DIGEST_SIZE);\n\n\treturn 0;\n}\n\nstatic struct shash_alg tgr_algs[3] = { {\n\t.digestsize\t=\tTGR192_DIGEST_SIZE,\n\t.init\t\t=\ttgr192_init,\n\t.update\t\t=\ttgr192_update,\n\t.final\t\t=\ttgr192_final,\n\t.descsize\t=\tsizeof(struct tgr192_ctx),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"tgr192\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tTGR192_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n}, {\n\t.digestsize\t=\tTGR160_DIGEST_SIZE,\n\t.init\t\t=\ttgr192_init,\n\t.update\t\t=\ttgr192_update,\n\t.final\t\t=\ttgr160_final,\n\t.descsize\t=\tsizeof(struct tgr192_ctx),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"tgr160\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tTGR192_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n}, {\n\t.digestsize\t=\tTGR128_DIGEST_SIZE,\n\t.init\t\t=\ttgr192_init,\n\t.update\t\t=\ttgr192_update,\n\t.final\t\t=\ttgr128_final,\n\t.descsize\t=\tsizeof(struct tgr192_ctx),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"tgr128\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tTGR192_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n} };\n\nstatic int __init tgr192_mod_init(void)\n{\n\treturn crypto_register_shashes(tgr_algs, ARRAY_SIZE(tgr_algs));\n}\n\nstatic void __exit tgr192_mod_fini(void)\n{\n\tcrypto_unregister_shashes(tgr_algs, ARRAY_SIZE(tgr_algs));\n}\n\nMODULE_ALIAS(\"tgr160\");\nMODULE_ALIAS(\"tgr128\");\n\nmodule_init(tgr192_mod_init);\nmodule_exit(tgr192_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Tiger Message Digest Algorithm\");\n", "/*\n * Twofish for CryptoAPI\n *\n * Originally Twofish for GPG\n * By Matthew Skala <mskala@ansuz.sooke.bc.ca>, July 26, 1998\n * 256-bit key length added March 20, 1999\n * Some modifications to reduce the text size by Werner Koch, April, 1998\n * Ported to the kerneli patch by Marc Mutz <Marc@Mutz.com>\n * Ported to CryptoAPI by Colin Slater <hoho@tacomeat.net>\n *\n * The original author has disclaimed all copyright interest in this\n * code and thus put it in the public domain. The subsequent authors \n * have put this under the GNU General Public License.\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n * \n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307\n * USA\n *\n * This code is a \"clean room\" implementation, written from the paper\n * _Twofish: A 128-Bit Block Cipher_ by Bruce Schneier, John Kelsey,\n * Doug Whiting, David Wagner, Chris Hall, and Niels Ferguson, available\n * through http://www.counterpane.com/twofish.html\n *\n * For background information on multiplication in finite fields, used for\n * the matrix operations in the key schedule, see the book _Contemporary\n * Abstract Algebra_ by Joseph A. Gallian, especially chapter 22 in the\n * Third Edition.\n */\n\n#include <asm/byteorder.h>\n#include <crypto/twofish.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/types.h>\n#include <linux/errno.h>\n#include <linux/crypto.h>\n#include <linux/bitops.h>\n\n/* Macros to compute the g() function in the encryption and decryption\n * rounds.  G1 is the straight g() function; G2 includes the 8-bit\n * rotation for the high 32-bit word. */\n\n#define G1(a) \\\n     (ctx->s[0][(a) & 0xFF]) ^ (ctx->s[1][((a) >> 8) & 0xFF]) \\\n   ^ (ctx->s[2][((a) >> 16) & 0xFF]) ^ (ctx->s[3][(a) >> 24])\n\n#define G2(b) \\\n     (ctx->s[1][(b) & 0xFF]) ^ (ctx->s[2][((b) >> 8) & 0xFF]) \\\n   ^ (ctx->s[3][((b) >> 16) & 0xFF]) ^ (ctx->s[0][(b) >> 24])\n\n/* Encryption and decryption Feistel rounds.  Each one calls the two g()\n * macros, does the PHT, and performs the XOR and the appropriate bit\n * rotations.  The parameters are the round number (used to select subkeys),\n * and the four 32-bit chunks of the text. */\n\n#define ENCROUND(n, a, b, c, d) \\\n   x = G1 (a); y = G2 (b); \\\n   x += y; y += x + ctx->k[2 * (n) + 1]; \\\n   (c) ^= x + ctx->k[2 * (n)]; \\\n   (c) = ror32((c), 1); \\\n   (d) = rol32((d), 1) ^ y\n\n#define DECROUND(n, a, b, c, d) \\\n   x = G1 (a); y = G2 (b); \\\n   x += y; y += x; \\\n   (d) ^= y + ctx->k[2 * (n) + 1]; \\\n   (d) = ror32((d), 1); \\\n   (c) = rol32((c), 1); \\\n   (c) ^= (x + ctx->k[2 * (n)])\n\n/* Encryption and decryption cycles; each one is simply two Feistel rounds\n * with the 32-bit chunks re-ordered to simulate the \"swap\" */\n\n#define ENCCYCLE(n) \\\n   ENCROUND (2 * (n), a, b, c, d); \\\n   ENCROUND (2 * (n) + 1, c, d, a, b)\n\n#define DECCYCLE(n) \\\n   DECROUND (2 * (n) + 1, c, d, a, b); \\\n   DECROUND (2 * (n), a, b, c, d)\n\n/* Macros to convert the input and output bytes into 32-bit words,\n * and simultaneously perform the whitening step.  INPACK packs word\n * number n into the variable named by x, using whitening subkey number m.\n * OUTUNPACK unpacks word number n from the variable named by x, using\n * whitening subkey number m. */\n\n#define INPACK(n, x, m) \\\n   x = le32_to_cpu(src[n]) ^ ctx->w[m]\n\n#define OUTUNPACK(n, x, m) \\\n   x ^= ctx->w[m]; \\\n   dst[n] = cpu_to_le32(x)\n\n\n\n/* Encrypt one block.  in and out may be the same. */\nstatic void twofish_encrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tstruct twofish_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *src = (const __le32 *)in;\n\t__le32 *dst = (__le32 *)out;\n\n\t/* The four 32-bit chunks of the text. */\n\tu32 a, b, c, d;\n\t\n\t/* Temporaries used by the round function. */\n\tu32 x, y;\n\n\t/* Input whitening and packing. */\n\tINPACK (0, a, 0);\n\tINPACK (1, b, 1);\n\tINPACK (2, c, 2);\n\tINPACK (3, d, 3);\n\t\n\t/* Encryption Feistel cycles. */\n\tENCCYCLE (0);\n\tENCCYCLE (1);\n\tENCCYCLE (2);\n\tENCCYCLE (3);\n\tENCCYCLE (4);\n\tENCCYCLE (5);\n\tENCCYCLE (6);\n\tENCCYCLE (7);\n\t\n\t/* Output whitening and unpacking. */\n\tOUTUNPACK (0, c, 4);\n\tOUTUNPACK (1, d, 5);\n\tOUTUNPACK (2, a, 6);\n\tOUTUNPACK (3, b, 7);\n\t\n}\n\n/* Decrypt one block.  in and out may be the same. */\nstatic void twofish_decrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tstruct twofish_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *src = (const __le32 *)in;\n\t__le32 *dst = (__le32 *)out;\n  \n\t/* The four 32-bit chunks of the text. */\n\tu32 a, b, c, d;\n\t\n\t/* Temporaries used by the round function. */\n\tu32 x, y;\n\t\n\t/* Input whitening and packing. */\n\tINPACK (0, c, 4);\n\tINPACK (1, d, 5);\n\tINPACK (2, a, 6);\n\tINPACK (3, b, 7);\n\t\n\t/* Encryption Feistel cycles. */\n\tDECCYCLE (7);\n\tDECCYCLE (6);\n\tDECCYCLE (5);\n\tDECCYCLE (4);\n\tDECCYCLE (3);\n\tDECCYCLE (2);\n\tDECCYCLE (1);\n\tDECCYCLE (0);\n\n\t/* Output whitening and unpacking. */\n\tOUTUNPACK (0, a, 0);\n\tOUTUNPACK (1, b, 1);\n\tOUTUNPACK (2, c, 2);\n\tOUTUNPACK (3, d, 3);\n\n}\n\nstatic struct crypto_alg alg = {\n\t.cra_name           =   \"twofish\",\n\t.cra_driver_name    =   \"twofish-generic\",\n\t.cra_priority       =   100,\n\t.cra_flags          =   CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize      =   TF_BLOCK_SIZE,\n\t.cra_ctxsize        =   sizeof(struct twofish_ctx),\n\t.cra_alignmask      =\t3,\n\t.cra_module         =   THIS_MODULE,\n\t.cra_u              =   { .cipher = {\n\t.cia_min_keysize    =   TF_MIN_KEY_SIZE,\n\t.cia_max_keysize    =   TF_MAX_KEY_SIZE,\n\t.cia_setkey         =   twofish_setkey,\n\t.cia_encrypt        =   twofish_encrypt,\n\t.cia_decrypt        =   twofish_decrypt } }\n};\n\nstatic int __init twofish_mod_init(void)\n{\n\treturn crypto_register_alg(&alg);\n}\n\nstatic void __exit twofish_mod_fini(void)\n{\n\tcrypto_unregister_alg(&alg);\n}\n\nmodule_init(twofish_mod_init);\nmodule_exit(twofish_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION (\"Twofish Cipher Algorithm\");\nMODULE_ALIAS(\"twofish\");\n", "/*\n * Cryptographic API.\n *\n * Whirlpool hashing Algorithm\n *\n * The Whirlpool algorithm was developed by Paulo S. L. M. Barreto and\n * Vincent Rijmen.  It has been selected as one of cryptographic\n * primitives by the NESSIE project http://www.cryptonessie.org/\n *\n * The original authors have disclaimed all copyright interest in this\n * code and thus put it in the public domain. The subsequent authors\n * have put this under the GNU General Public License.\n *\n * By Aaron Grothe ajgrothe@yahoo.com, August 23, 2004\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <asm/byteorder.h>\n#include <linux/types.h>\n\n#define WP512_DIGEST_SIZE 64\n#define WP384_DIGEST_SIZE 48\n#define WP256_DIGEST_SIZE 32\n\n#define WP512_BLOCK_SIZE  64\n#define WP512_LENGTHBYTES 32\n\n#define WHIRLPOOL_ROUNDS 10\n\nstruct wp512_ctx {\n\tu8  bitLength[WP512_LENGTHBYTES];\n\tu8  buffer[WP512_BLOCK_SIZE];\n\tint bufferBits;\n\tint bufferPos;\n\tu64 hash[WP512_DIGEST_SIZE/8];\n};\n\n/*\n * Though Whirlpool is endianness-neutral, the encryption tables are listed\n * in BIG-ENDIAN format, which is adopted throughout this implementation\n * (but little-endian notation would be equally suitable if consistently\n * employed).\n */\n\nstatic const u64 C0[256] = {\n\t0x18186018c07830d8ULL, 0x23238c2305af4626ULL, 0xc6c63fc67ef991b8ULL,\n\t0xe8e887e8136fcdfbULL, 0x878726874ca113cbULL, 0xb8b8dab8a9626d11ULL,\n\t0x0101040108050209ULL, 0x4f4f214f426e9e0dULL, 0x3636d836adee6c9bULL,\n\t0xa6a6a2a6590451ffULL, 0xd2d26fd2debdb90cULL, 0xf5f5f3f5fb06f70eULL,\n\t0x7979f979ef80f296ULL, 0x6f6fa16f5fcede30ULL, 0x91917e91fcef3f6dULL,\n\t0x52525552aa07a4f8ULL, 0x60609d6027fdc047ULL, 0xbcbccabc89766535ULL,\n\t0x9b9b569baccd2b37ULL, 0x8e8e028e048c018aULL, 0xa3a3b6a371155bd2ULL,\n\t0x0c0c300c603c186cULL, 0x7b7bf17bff8af684ULL, 0x3535d435b5e16a80ULL,\n\t0x1d1d741de8693af5ULL, 0xe0e0a7e05347ddb3ULL, 0xd7d77bd7f6acb321ULL,\n\t0xc2c22fc25eed999cULL, 0x2e2eb82e6d965c43ULL, 0x4b4b314b627a9629ULL,\n\t0xfefedffea321e15dULL, 0x575741578216aed5ULL, 0x15155415a8412abdULL,\n\t0x7777c1779fb6eee8ULL, 0x3737dc37a5eb6e92ULL, 0xe5e5b3e57b56d79eULL,\n\t0x9f9f469f8cd92313ULL, 0xf0f0e7f0d317fd23ULL, 0x4a4a354a6a7f9420ULL,\n\t0xdada4fda9e95a944ULL, 0x58587d58fa25b0a2ULL, 0xc9c903c906ca8fcfULL,\n\t0x2929a429558d527cULL, 0x0a0a280a5022145aULL, 0xb1b1feb1e14f7f50ULL,\n\t0xa0a0baa0691a5dc9ULL, 0x6b6bb16b7fdad614ULL, 0x85852e855cab17d9ULL,\n\t0xbdbdcebd8173673cULL, 0x5d5d695dd234ba8fULL, 0x1010401080502090ULL,\n\t0xf4f4f7f4f303f507ULL, 0xcbcb0bcb16c08bddULL, 0x3e3ef83eedc67cd3ULL,\n\t0x0505140528110a2dULL, 0x676781671fe6ce78ULL, 0xe4e4b7e47353d597ULL,\n\t0x27279c2725bb4e02ULL, 0x4141194132588273ULL, 0x8b8b168b2c9d0ba7ULL,\n\t0xa7a7a6a7510153f6ULL, 0x7d7de97dcf94fab2ULL, 0x95956e95dcfb3749ULL,\n\t0xd8d847d88e9fad56ULL, 0xfbfbcbfb8b30eb70ULL, 0xeeee9fee2371c1cdULL,\n\t0x7c7ced7cc791f8bbULL, 0x6666856617e3cc71ULL, 0xdddd53dda68ea77bULL,\n\t0x17175c17b84b2eafULL, 0x4747014702468e45ULL, 0x9e9e429e84dc211aULL,\n\t0xcaca0fca1ec589d4ULL, 0x2d2db42d75995a58ULL, 0xbfbfc6bf9179632eULL,\n\t0x07071c07381b0e3fULL, 0xadad8ead012347acULL, 0x5a5a755aea2fb4b0ULL,\n\t0x838336836cb51befULL, 0x3333cc3385ff66b6ULL, 0x636391633ff2c65cULL,\n\t0x02020802100a0412ULL, 0xaaaa92aa39384993ULL, 0x7171d971afa8e2deULL,\n\t0xc8c807c80ecf8dc6ULL, 0x19196419c87d32d1ULL, 0x494939497270923bULL,\n\t0xd9d943d9869aaf5fULL, 0xf2f2eff2c31df931ULL, 0xe3e3abe34b48dba8ULL,\n\t0x5b5b715be22ab6b9ULL, 0x88881a8834920dbcULL, 0x9a9a529aa4c8293eULL,\n\t0x262698262dbe4c0bULL, 0x3232c8328dfa64bfULL, 0xb0b0fab0e94a7d59ULL,\n\t0xe9e983e91b6acff2ULL, 0x0f0f3c0f78331e77ULL, 0xd5d573d5e6a6b733ULL,\n\t0x80803a8074ba1df4ULL, 0xbebec2be997c6127ULL, 0xcdcd13cd26de87ebULL,\n\t0x3434d034bde46889ULL, 0x48483d487a759032ULL, 0xffffdbffab24e354ULL,\n\t0x7a7af57af78ff48dULL, 0x90907a90f4ea3d64ULL, 0x5f5f615fc23ebe9dULL,\n\t0x202080201da0403dULL, 0x6868bd6867d5d00fULL, 0x1a1a681ad07234caULL,\n\t0xaeae82ae192c41b7ULL, 0xb4b4eab4c95e757dULL, 0x54544d549a19a8ceULL,\n\t0x93937693ece53b7fULL, 0x222288220daa442fULL, 0x64648d6407e9c863ULL,\n\t0xf1f1e3f1db12ff2aULL, 0x7373d173bfa2e6ccULL, 0x12124812905a2482ULL,\n\t0x40401d403a5d807aULL, 0x0808200840281048ULL, 0xc3c32bc356e89b95ULL,\n\t0xecec97ec337bc5dfULL, 0xdbdb4bdb9690ab4dULL, 0xa1a1bea1611f5fc0ULL,\n\t0x8d8d0e8d1c830791ULL, 0x3d3df43df5c97ac8ULL, 0x97976697ccf1335bULL,\n\t0x0000000000000000ULL, 0xcfcf1bcf36d483f9ULL, 0x2b2bac2b4587566eULL,\n\t0x7676c57697b3ece1ULL, 0x8282328264b019e6ULL, 0xd6d67fd6fea9b128ULL,\n\t0x1b1b6c1bd87736c3ULL, 0xb5b5eeb5c15b7774ULL, 0xafaf86af112943beULL,\n\t0x6a6ab56a77dfd41dULL, 0x50505d50ba0da0eaULL, 0x45450945124c8a57ULL,\n\t0xf3f3ebf3cb18fb38ULL, 0x3030c0309df060adULL, 0xefef9bef2b74c3c4ULL,\n\t0x3f3ffc3fe5c37edaULL, 0x55554955921caac7ULL, 0xa2a2b2a2791059dbULL,\n\t0xeaea8fea0365c9e9ULL, 0x656589650fecca6aULL, 0xbabad2bab9686903ULL,\n\t0x2f2fbc2f65935e4aULL, 0xc0c027c04ee79d8eULL, 0xdede5fdebe81a160ULL,\n\t0x1c1c701ce06c38fcULL, 0xfdfdd3fdbb2ee746ULL, 0x4d4d294d52649a1fULL,\n\t0x92927292e4e03976ULL, 0x7575c9758fbceafaULL, 0x06061806301e0c36ULL,\n\t0x8a8a128a249809aeULL, 0xb2b2f2b2f940794bULL, 0xe6e6bfe66359d185ULL,\n\t0x0e0e380e70361c7eULL, 0x1f1f7c1ff8633ee7ULL, 0x6262956237f7c455ULL,\n\t0xd4d477d4eea3b53aULL, 0xa8a89aa829324d81ULL, 0x96966296c4f43152ULL,\n\t0xf9f9c3f99b3aef62ULL, 0xc5c533c566f697a3ULL, 0x2525942535b14a10ULL,\n\t0x59597959f220b2abULL, 0x84842a8454ae15d0ULL, 0x7272d572b7a7e4c5ULL,\n\t0x3939e439d5dd72ecULL, 0x4c4c2d4c5a619816ULL, 0x5e5e655eca3bbc94ULL,\n\t0x7878fd78e785f09fULL, 0x3838e038ddd870e5ULL, 0x8c8c0a8c14860598ULL,\n\t0xd1d163d1c6b2bf17ULL, 0xa5a5aea5410b57e4ULL, 0xe2e2afe2434dd9a1ULL,\n\t0x616199612ff8c24eULL, 0xb3b3f6b3f1457b42ULL, 0x2121842115a54234ULL,\n\t0x9c9c4a9c94d62508ULL, 0x1e1e781ef0663ceeULL, 0x4343114322528661ULL,\n\t0xc7c73bc776fc93b1ULL, 0xfcfcd7fcb32be54fULL, 0x0404100420140824ULL,\n\t0x51515951b208a2e3ULL, 0x99995e99bcc72f25ULL, 0x6d6da96d4fc4da22ULL,\n\t0x0d0d340d68391a65ULL, 0xfafacffa8335e979ULL, 0xdfdf5bdfb684a369ULL,\n\t0x7e7ee57ed79bfca9ULL, 0x242490243db44819ULL, 0x3b3bec3bc5d776feULL,\n\t0xabab96ab313d4b9aULL, 0xcece1fce3ed181f0ULL, 0x1111441188552299ULL,\n\t0x8f8f068f0c890383ULL, 0x4e4e254e4a6b9c04ULL, 0xb7b7e6b7d1517366ULL,\n\t0xebeb8beb0b60cbe0ULL, 0x3c3cf03cfdcc78c1ULL, 0x81813e817cbf1ffdULL,\n\t0x94946a94d4fe3540ULL, 0xf7f7fbf7eb0cf31cULL, 0xb9b9deb9a1676f18ULL,\n\t0x13134c13985f268bULL, 0x2c2cb02c7d9c5851ULL, 0xd3d36bd3d6b8bb05ULL,\n\t0xe7e7bbe76b5cd38cULL, 0x6e6ea56e57cbdc39ULL, 0xc4c437c46ef395aaULL,\n\t0x03030c03180f061bULL, 0x565645568a13acdcULL, 0x44440d441a49885eULL,\n\t0x7f7fe17fdf9efea0ULL, 0xa9a99ea921374f88ULL, 0x2a2aa82a4d825467ULL,\n\t0xbbbbd6bbb16d6b0aULL, 0xc1c123c146e29f87ULL, 0x53535153a202a6f1ULL,\n\t0xdcdc57dcae8ba572ULL, 0x0b0b2c0b58271653ULL, 0x9d9d4e9d9cd32701ULL,\n\t0x6c6cad6c47c1d82bULL, 0x3131c43195f562a4ULL, 0x7474cd7487b9e8f3ULL,\n\t0xf6f6fff6e309f115ULL, 0x464605460a438c4cULL, 0xacac8aac092645a5ULL,\n\t0x89891e893c970fb5ULL, 0x14145014a04428b4ULL, 0xe1e1a3e15b42dfbaULL,\n\t0x16165816b04e2ca6ULL, 0x3a3ae83acdd274f7ULL, 0x6969b9696fd0d206ULL,\n\t0x09092409482d1241ULL, 0x7070dd70a7ade0d7ULL, 0xb6b6e2b6d954716fULL,\n\t0xd0d067d0ceb7bd1eULL, 0xeded93ed3b7ec7d6ULL, 0xcccc17cc2edb85e2ULL,\n\t0x424215422a578468ULL, 0x98985a98b4c22d2cULL, 0xa4a4aaa4490e55edULL,\n\t0x2828a0285d885075ULL, 0x5c5c6d5cda31b886ULL, 0xf8f8c7f8933fed6bULL,\n\t0x8686228644a411c2ULL,\n};\n\nstatic const u64 C1[256] = {\n\t0xd818186018c07830ULL, 0x2623238c2305af46ULL, 0xb8c6c63fc67ef991ULL,\n\t0xfbe8e887e8136fcdULL, 0xcb878726874ca113ULL, 0x11b8b8dab8a9626dULL,\n\t0x0901010401080502ULL, 0x0d4f4f214f426e9eULL, 0x9b3636d836adee6cULL,\n\t0xffa6a6a2a6590451ULL, 0x0cd2d26fd2debdb9ULL, 0x0ef5f5f3f5fb06f7ULL,\n\t0x967979f979ef80f2ULL, 0x306f6fa16f5fcedeULL, 0x6d91917e91fcef3fULL,\n\t0xf852525552aa07a4ULL, 0x4760609d6027fdc0ULL, 0x35bcbccabc897665ULL,\n\t0x379b9b569baccd2bULL, 0x8a8e8e028e048c01ULL, 0xd2a3a3b6a371155bULL,\n\t0x6c0c0c300c603c18ULL, 0x847b7bf17bff8af6ULL, 0x803535d435b5e16aULL,\n\t0xf51d1d741de8693aULL, 0xb3e0e0a7e05347ddULL, 0x21d7d77bd7f6acb3ULL,\n\t0x9cc2c22fc25eed99ULL, 0x432e2eb82e6d965cULL, 0x294b4b314b627a96ULL,\n\t0x5dfefedffea321e1ULL, 0xd5575741578216aeULL, 0xbd15155415a8412aULL,\n\t0xe87777c1779fb6eeULL, 0x923737dc37a5eb6eULL, 0x9ee5e5b3e57b56d7ULL,\n\t0x139f9f469f8cd923ULL, 0x23f0f0e7f0d317fdULL, 0x204a4a354a6a7f94ULL,\n\t0x44dada4fda9e95a9ULL, 0xa258587d58fa25b0ULL, 0xcfc9c903c906ca8fULL,\n\t0x7c2929a429558d52ULL, 0x5a0a0a280a502214ULL, 0x50b1b1feb1e14f7fULL,\n\t0xc9a0a0baa0691a5dULL, 0x146b6bb16b7fdad6ULL, 0xd985852e855cab17ULL,\n\t0x3cbdbdcebd817367ULL, 0x8f5d5d695dd234baULL, 0x9010104010805020ULL,\n\t0x07f4f4f7f4f303f5ULL, 0xddcbcb0bcb16c08bULL, 0xd33e3ef83eedc67cULL,\n\t0x2d0505140528110aULL, 0x78676781671fe6ceULL, 0x97e4e4b7e47353d5ULL,\n\t0x0227279c2725bb4eULL, 0x7341411941325882ULL, 0xa78b8b168b2c9d0bULL,\n\t0xf6a7a7a6a7510153ULL, 0xb27d7de97dcf94faULL, 0x4995956e95dcfb37ULL,\n\t0x56d8d847d88e9fadULL, 0x70fbfbcbfb8b30ebULL, 0xcdeeee9fee2371c1ULL,\n\t0xbb7c7ced7cc791f8ULL, 0x716666856617e3ccULL, 0x7bdddd53dda68ea7ULL,\n\t0xaf17175c17b84b2eULL, 0x454747014702468eULL, 0x1a9e9e429e84dc21ULL,\n\t0xd4caca0fca1ec589ULL, 0x582d2db42d75995aULL, 0x2ebfbfc6bf917963ULL,\n\t0x3f07071c07381b0eULL, 0xacadad8ead012347ULL, 0xb05a5a755aea2fb4ULL,\n\t0xef838336836cb51bULL, 0xb63333cc3385ff66ULL, 0x5c636391633ff2c6ULL,\n\t0x1202020802100a04ULL, 0x93aaaa92aa393849ULL, 0xde7171d971afa8e2ULL,\n\t0xc6c8c807c80ecf8dULL, 0xd119196419c87d32ULL, 0x3b49493949727092ULL,\n\t0x5fd9d943d9869aafULL, 0x31f2f2eff2c31df9ULL, 0xa8e3e3abe34b48dbULL,\n\t0xb95b5b715be22ab6ULL, 0xbc88881a8834920dULL, 0x3e9a9a529aa4c829ULL,\n\t0x0b262698262dbe4cULL, 0xbf3232c8328dfa64ULL, 0x59b0b0fab0e94a7dULL,\n\t0xf2e9e983e91b6acfULL, 0x770f0f3c0f78331eULL, 0x33d5d573d5e6a6b7ULL,\n\t0xf480803a8074ba1dULL, 0x27bebec2be997c61ULL, 0xebcdcd13cd26de87ULL,\n\t0x893434d034bde468ULL, 0x3248483d487a7590ULL, 0x54ffffdbffab24e3ULL,\n\t0x8d7a7af57af78ff4ULL, 0x6490907a90f4ea3dULL, 0x9d5f5f615fc23ebeULL,\n\t0x3d202080201da040ULL, 0x0f6868bd6867d5d0ULL, 0xca1a1a681ad07234ULL,\n\t0xb7aeae82ae192c41ULL, 0x7db4b4eab4c95e75ULL, 0xce54544d549a19a8ULL,\n\t0x7f93937693ece53bULL, 0x2f222288220daa44ULL, 0x6364648d6407e9c8ULL,\n\t0x2af1f1e3f1db12ffULL, 0xcc7373d173bfa2e6ULL, 0x8212124812905a24ULL,\n\t0x7a40401d403a5d80ULL, 0x4808082008402810ULL, 0x95c3c32bc356e89bULL,\n\t0xdfecec97ec337bc5ULL, 0x4ddbdb4bdb9690abULL, 0xc0a1a1bea1611f5fULL,\n\t0x918d8d0e8d1c8307ULL, 0xc83d3df43df5c97aULL, 0x5b97976697ccf133ULL,\n\t0x0000000000000000ULL, 0xf9cfcf1bcf36d483ULL, 0x6e2b2bac2b458756ULL,\n\t0xe17676c57697b3ecULL, 0xe68282328264b019ULL, 0x28d6d67fd6fea9b1ULL,\n\t0xc31b1b6c1bd87736ULL, 0x74b5b5eeb5c15b77ULL, 0xbeafaf86af112943ULL,\n\t0x1d6a6ab56a77dfd4ULL, 0xea50505d50ba0da0ULL, 0x5745450945124c8aULL,\n\t0x38f3f3ebf3cb18fbULL, 0xad3030c0309df060ULL, 0xc4efef9bef2b74c3ULL,\n\t0xda3f3ffc3fe5c37eULL, 0xc755554955921caaULL, 0xdba2a2b2a2791059ULL,\n\t0xe9eaea8fea0365c9ULL, 0x6a656589650feccaULL, 0x03babad2bab96869ULL,\n\t0x4a2f2fbc2f65935eULL, 0x8ec0c027c04ee79dULL, 0x60dede5fdebe81a1ULL,\n\t0xfc1c1c701ce06c38ULL, 0x46fdfdd3fdbb2ee7ULL, 0x1f4d4d294d52649aULL,\n\t0x7692927292e4e039ULL, 0xfa7575c9758fbceaULL, 0x3606061806301e0cULL,\n\t0xae8a8a128a249809ULL, 0x4bb2b2f2b2f94079ULL, 0x85e6e6bfe66359d1ULL,\n\t0x7e0e0e380e70361cULL, 0xe71f1f7c1ff8633eULL, 0x556262956237f7c4ULL,\n\t0x3ad4d477d4eea3b5ULL, 0x81a8a89aa829324dULL, 0x5296966296c4f431ULL,\n\t0x62f9f9c3f99b3aefULL, 0xa3c5c533c566f697ULL, 0x102525942535b14aULL,\n\t0xab59597959f220b2ULL, 0xd084842a8454ae15ULL, 0xc57272d572b7a7e4ULL,\n\t0xec3939e439d5dd72ULL, 0x164c4c2d4c5a6198ULL, 0x945e5e655eca3bbcULL,\n\t0x9f7878fd78e785f0ULL, 0xe53838e038ddd870ULL, 0x988c8c0a8c148605ULL,\n\t0x17d1d163d1c6b2bfULL, 0xe4a5a5aea5410b57ULL, 0xa1e2e2afe2434dd9ULL,\n\t0x4e616199612ff8c2ULL, 0x42b3b3f6b3f1457bULL, 0x342121842115a542ULL,\n\t0x089c9c4a9c94d625ULL, 0xee1e1e781ef0663cULL, 0x6143431143225286ULL,\n\t0xb1c7c73bc776fc93ULL, 0x4ffcfcd7fcb32be5ULL, 0x2404041004201408ULL,\n\t0xe351515951b208a2ULL, 0x2599995e99bcc72fULL, 0x226d6da96d4fc4daULL,\n\t0x650d0d340d68391aULL, 0x79fafacffa8335e9ULL, 0x69dfdf5bdfb684a3ULL,\n\t0xa97e7ee57ed79bfcULL, 0x19242490243db448ULL, 0xfe3b3bec3bc5d776ULL,\n\t0x9aabab96ab313d4bULL, 0xf0cece1fce3ed181ULL, 0x9911114411885522ULL,\n\t0x838f8f068f0c8903ULL, 0x044e4e254e4a6b9cULL, 0x66b7b7e6b7d15173ULL,\n\t0xe0ebeb8beb0b60cbULL, 0xc13c3cf03cfdcc78ULL, 0xfd81813e817cbf1fULL,\n\t0x4094946a94d4fe35ULL, 0x1cf7f7fbf7eb0cf3ULL, 0x18b9b9deb9a1676fULL,\n\t0x8b13134c13985f26ULL, 0x512c2cb02c7d9c58ULL, 0x05d3d36bd3d6b8bbULL,\n\t0x8ce7e7bbe76b5cd3ULL, 0x396e6ea56e57cbdcULL, 0xaac4c437c46ef395ULL,\n\t0x1b03030c03180f06ULL, 0xdc565645568a13acULL, 0x5e44440d441a4988ULL,\n\t0xa07f7fe17fdf9efeULL, 0x88a9a99ea921374fULL, 0x672a2aa82a4d8254ULL,\n\t0x0abbbbd6bbb16d6bULL, 0x87c1c123c146e29fULL, 0xf153535153a202a6ULL,\n\t0x72dcdc57dcae8ba5ULL, 0x530b0b2c0b582716ULL, 0x019d9d4e9d9cd327ULL,\n\t0x2b6c6cad6c47c1d8ULL, 0xa43131c43195f562ULL, 0xf37474cd7487b9e8ULL,\n\t0x15f6f6fff6e309f1ULL, 0x4c464605460a438cULL, 0xa5acac8aac092645ULL,\n\t0xb589891e893c970fULL, 0xb414145014a04428ULL, 0xbae1e1a3e15b42dfULL,\n\t0xa616165816b04e2cULL, 0xf73a3ae83acdd274ULL, 0x066969b9696fd0d2ULL,\n\t0x4109092409482d12ULL, 0xd77070dd70a7ade0ULL, 0x6fb6b6e2b6d95471ULL,\n\t0x1ed0d067d0ceb7bdULL, 0xd6eded93ed3b7ec7ULL, 0xe2cccc17cc2edb85ULL,\n\t0x68424215422a5784ULL, 0x2c98985a98b4c22dULL, 0xeda4a4aaa4490e55ULL,\n\t0x752828a0285d8850ULL, 0x865c5c6d5cda31b8ULL, 0x6bf8f8c7f8933fedULL,\n\t0xc28686228644a411ULL,\n};\n\nstatic const u64 C2[256] = {\n\t0x30d818186018c078ULL, 0x462623238c2305afULL, 0x91b8c6c63fc67ef9ULL,\n\t0xcdfbe8e887e8136fULL, 0x13cb878726874ca1ULL, 0x6d11b8b8dab8a962ULL,\n\t0x0209010104010805ULL, 0x9e0d4f4f214f426eULL, 0x6c9b3636d836adeeULL,\n\t0x51ffa6a6a2a65904ULL, 0xb90cd2d26fd2debdULL, 0xf70ef5f5f3f5fb06ULL,\n\t0xf2967979f979ef80ULL, 0xde306f6fa16f5fceULL, 0x3f6d91917e91fcefULL,\n\t0xa4f852525552aa07ULL, 0xc04760609d6027fdULL, 0x6535bcbccabc8976ULL,\n\t0x2b379b9b569baccdULL, 0x018a8e8e028e048cULL, 0x5bd2a3a3b6a37115ULL,\n\t0x186c0c0c300c603cULL, 0xf6847b7bf17bff8aULL, 0x6a803535d435b5e1ULL,\n\t0x3af51d1d741de869ULL, 0xddb3e0e0a7e05347ULL, 0xb321d7d77bd7f6acULL,\n\t0x999cc2c22fc25eedULL, 0x5c432e2eb82e6d96ULL, 0x96294b4b314b627aULL,\n\t0xe15dfefedffea321ULL, 0xaed5575741578216ULL, 0x2abd15155415a841ULL,\n\t0xeee87777c1779fb6ULL, 0x6e923737dc37a5ebULL, 0xd79ee5e5b3e57b56ULL,\n\t0x23139f9f469f8cd9ULL, 0xfd23f0f0e7f0d317ULL, 0x94204a4a354a6a7fULL,\n\t0xa944dada4fda9e95ULL, 0xb0a258587d58fa25ULL, 0x8fcfc9c903c906caULL,\n\t0x527c2929a429558dULL, 0x145a0a0a280a5022ULL, 0x7f50b1b1feb1e14fULL,\n\t0x5dc9a0a0baa0691aULL, 0xd6146b6bb16b7fdaULL, 0x17d985852e855cabULL,\n\t0x673cbdbdcebd8173ULL, 0xba8f5d5d695dd234ULL, 0x2090101040108050ULL,\n\t0xf507f4f4f7f4f303ULL, 0x8bddcbcb0bcb16c0ULL, 0x7cd33e3ef83eedc6ULL,\n\t0x0a2d050514052811ULL, 0xce78676781671fe6ULL, 0xd597e4e4b7e47353ULL,\n\t0x4e0227279c2725bbULL, 0x8273414119413258ULL, 0x0ba78b8b168b2c9dULL,\n\t0x53f6a7a7a6a75101ULL, 0xfab27d7de97dcf94ULL, 0x374995956e95dcfbULL,\n\t0xad56d8d847d88e9fULL, 0xeb70fbfbcbfb8b30ULL, 0xc1cdeeee9fee2371ULL,\n\t0xf8bb7c7ced7cc791ULL, 0xcc716666856617e3ULL, 0xa77bdddd53dda68eULL,\n\t0x2eaf17175c17b84bULL, 0x8e45474701470246ULL, 0x211a9e9e429e84dcULL,\n\t0x89d4caca0fca1ec5ULL, 0x5a582d2db42d7599ULL, 0x632ebfbfc6bf9179ULL,\n\t0x0e3f07071c07381bULL, 0x47acadad8ead0123ULL, 0xb4b05a5a755aea2fULL,\n\t0x1bef838336836cb5ULL, 0x66b63333cc3385ffULL, 0xc65c636391633ff2ULL,\n\t0x041202020802100aULL, 0x4993aaaa92aa3938ULL, 0xe2de7171d971afa8ULL,\n\t0x8dc6c8c807c80ecfULL, 0x32d119196419c87dULL, 0x923b494939497270ULL,\n\t0xaf5fd9d943d9869aULL, 0xf931f2f2eff2c31dULL, 0xdba8e3e3abe34b48ULL,\n\t0xb6b95b5b715be22aULL, 0x0dbc88881a883492ULL, 0x293e9a9a529aa4c8ULL,\n\t0x4c0b262698262dbeULL, 0x64bf3232c8328dfaULL, 0x7d59b0b0fab0e94aULL,\n\t0xcff2e9e983e91b6aULL, 0x1e770f0f3c0f7833ULL, 0xb733d5d573d5e6a6ULL,\n\t0x1df480803a8074baULL, 0x6127bebec2be997cULL, 0x87ebcdcd13cd26deULL,\n\t0x68893434d034bde4ULL, 0x903248483d487a75ULL, 0xe354ffffdbffab24ULL,\n\t0xf48d7a7af57af78fULL, 0x3d6490907a90f4eaULL, 0xbe9d5f5f615fc23eULL,\n\t0x403d202080201da0ULL, 0xd00f6868bd6867d5ULL, 0x34ca1a1a681ad072ULL,\n\t0x41b7aeae82ae192cULL, 0x757db4b4eab4c95eULL, 0xa8ce54544d549a19ULL,\n\t0x3b7f93937693ece5ULL, 0x442f222288220daaULL, 0xc86364648d6407e9ULL,\n\t0xff2af1f1e3f1db12ULL, 0xe6cc7373d173bfa2ULL, 0x248212124812905aULL,\n\t0x807a40401d403a5dULL, 0x1048080820084028ULL, 0x9b95c3c32bc356e8ULL,\n\t0xc5dfecec97ec337bULL, 0xab4ddbdb4bdb9690ULL, 0x5fc0a1a1bea1611fULL,\n\t0x07918d8d0e8d1c83ULL, 0x7ac83d3df43df5c9ULL, 0x335b97976697ccf1ULL,\n\t0x0000000000000000ULL, 0x83f9cfcf1bcf36d4ULL, 0x566e2b2bac2b4587ULL,\n\t0xece17676c57697b3ULL, 0x19e68282328264b0ULL, 0xb128d6d67fd6fea9ULL,\n\t0x36c31b1b6c1bd877ULL, 0x7774b5b5eeb5c15bULL, 0x43beafaf86af1129ULL,\n\t0xd41d6a6ab56a77dfULL, 0xa0ea50505d50ba0dULL, 0x8a5745450945124cULL,\n\t0xfb38f3f3ebf3cb18ULL, 0x60ad3030c0309df0ULL, 0xc3c4efef9bef2b74ULL,\n\t0x7eda3f3ffc3fe5c3ULL, 0xaac755554955921cULL, 0x59dba2a2b2a27910ULL,\n\t0xc9e9eaea8fea0365ULL, 0xca6a656589650fecULL, 0x6903babad2bab968ULL,\n\t0x5e4a2f2fbc2f6593ULL, 0x9d8ec0c027c04ee7ULL, 0xa160dede5fdebe81ULL,\n\t0x38fc1c1c701ce06cULL, 0xe746fdfdd3fdbb2eULL, 0x9a1f4d4d294d5264ULL,\n\t0x397692927292e4e0ULL, 0xeafa7575c9758fbcULL, 0x0c3606061806301eULL,\n\t0x09ae8a8a128a2498ULL, 0x794bb2b2f2b2f940ULL, 0xd185e6e6bfe66359ULL,\n\t0x1c7e0e0e380e7036ULL, 0x3ee71f1f7c1ff863ULL, 0xc4556262956237f7ULL,\n\t0xb53ad4d477d4eea3ULL, 0x4d81a8a89aa82932ULL, 0x315296966296c4f4ULL,\n\t0xef62f9f9c3f99b3aULL, 0x97a3c5c533c566f6ULL, 0x4a102525942535b1ULL,\n\t0xb2ab59597959f220ULL, 0x15d084842a8454aeULL, 0xe4c57272d572b7a7ULL,\n\t0x72ec3939e439d5ddULL, 0x98164c4c2d4c5a61ULL, 0xbc945e5e655eca3bULL,\n\t0xf09f7878fd78e785ULL, 0x70e53838e038ddd8ULL, 0x05988c8c0a8c1486ULL,\n\t0xbf17d1d163d1c6b2ULL, 0x57e4a5a5aea5410bULL, 0xd9a1e2e2afe2434dULL,\n\t0xc24e616199612ff8ULL, 0x7b42b3b3f6b3f145ULL, 0x42342121842115a5ULL,\n\t0x25089c9c4a9c94d6ULL, 0x3cee1e1e781ef066ULL, 0x8661434311432252ULL,\n\t0x93b1c7c73bc776fcULL, 0xe54ffcfcd7fcb32bULL, 0x0824040410042014ULL,\n\t0xa2e351515951b208ULL, 0x2f2599995e99bcc7ULL, 0xda226d6da96d4fc4ULL,\n\t0x1a650d0d340d6839ULL, 0xe979fafacffa8335ULL, 0xa369dfdf5bdfb684ULL,\n\t0xfca97e7ee57ed79bULL, 0x4819242490243db4ULL, 0x76fe3b3bec3bc5d7ULL,\n\t0x4b9aabab96ab313dULL, 0x81f0cece1fce3ed1ULL, 0x2299111144118855ULL,\n\t0x03838f8f068f0c89ULL, 0x9c044e4e254e4a6bULL, 0x7366b7b7e6b7d151ULL,\n\t0xcbe0ebeb8beb0b60ULL, 0x78c13c3cf03cfdccULL, 0x1ffd81813e817cbfULL,\n\t0x354094946a94d4feULL, 0xf31cf7f7fbf7eb0cULL, 0x6f18b9b9deb9a167ULL,\n\t0x268b13134c13985fULL, 0x58512c2cb02c7d9cULL, 0xbb05d3d36bd3d6b8ULL,\n\t0xd38ce7e7bbe76b5cULL, 0xdc396e6ea56e57cbULL, 0x95aac4c437c46ef3ULL,\n\t0x061b03030c03180fULL, 0xacdc565645568a13ULL, 0x885e44440d441a49ULL,\n\t0xfea07f7fe17fdf9eULL, 0x4f88a9a99ea92137ULL, 0x54672a2aa82a4d82ULL,\n\t0x6b0abbbbd6bbb16dULL, 0x9f87c1c123c146e2ULL, 0xa6f153535153a202ULL,\n\t0xa572dcdc57dcae8bULL, 0x16530b0b2c0b5827ULL, 0x27019d9d4e9d9cd3ULL,\n\t0xd82b6c6cad6c47c1ULL, 0x62a43131c43195f5ULL, 0xe8f37474cd7487b9ULL,\n\t0xf115f6f6fff6e309ULL, 0x8c4c464605460a43ULL, 0x45a5acac8aac0926ULL,\n\t0x0fb589891e893c97ULL, 0x28b414145014a044ULL, 0xdfbae1e1a3e15b42ULL,\n\t0x2ca616165816b04eULL, 0x74f73a3ae83acdd2ULL, 0xd2066969b9696fd0ULL,\n\t0x124109092409482dULL, 0xe0d77070dd70a7adULL, 0x716fb6b6e2b6d954ULL,\n\t0xbd1ed0d067d0ceb7ULL, 0xc7d6eded93ed3b7eULL, 0x85e2cccc17cc2edbULL,\n\t0x8468424215422a57ULL, 0x2d2c98985a98b4c2ULL, 0x55eda4a4aaa4490eULL,\n\t0x50752828a0285d88ULL, 0xb8865c5c6d5cda31ULL, 0xed6bf8f8c7f8933fULL,\n\t0x11c28686228644a4ULL,\n};\n\nstatic const u64 C3[256] = {\n\t0x7830d818186018c0ULL, 0xaf462623238c2305ULL, 0xf991b8c6c63fc67eULL,\n\t0x6fcdfbe8e887e813ULL, 0xa113cb878726874cULL, 0x626d11b8b8dab8a9ULL,\n\t0x0502090101040108ULL, 0x6e9e0d4f4f214f42ULL, 0xee6c9b3636d836adULL,\n\t0x0451ffa6a6a2a659ULL, 0xbdb90cd2d26fd2deULL, 0x06f70ef5f5f3f5fbULL,\n\t0x80f2967979f979efULL, 0xcede306f6fa16f5fULL, 0xef3f6d91917e91fcULL,\n\t0x07a4f852525552aaULL, 0xfdc04760609d6027ULL, 0x766535bcbccabc89ULL,\n\t0xcd2b379b9b569bacULL, 0x8c018a8e8e028e04ULL, 0x155bd2a3a3b6a371ULL,\n\t0x3c186c0c0c300c60ULL, 0x8af6847b7bf17bffULL, 0xe16a803535d435b5ULL,\n\t0x693af51d1d741de8ULL, 0x47ddb3e0e0a7e053ULL, 0xacb321d7d77bd7f6ULL,\n\t0xed999cc2c22fc25eULL, 0x965c432e2eb82e6dULL, 0x7a96294b4b314b62ULL,\n\t0x21e15dfefedffea3ULL, 0x16aed55757415782ULL, 0x412abd15155415a8ULL,\n\t0xb6eee87777c1779fULL, 0xeb6e923737dc37a5ULL, 0x56d79ee5e5b3e57bULL,\n\t0xd923139f9f469f8cULL, 0x17fd23f0f0e7f0d3ULL, 0x7f94204a4a354a6aULL,\n\t0x95a944dada4fda9eULL, 0x25b0a258587d58faULL, 0xca8fcfc9c903c906ULL,\n\t0x8d527c2929a42955ULL, 0x22145a0a0a280a50ULL, 0x4f7f50b1b1feb1e1ULL,\n\t0x1a5dc9a0a0baa069ULL, 0xdad6146b6bb16b7fULL, 0xab17d985852e855cULL,\n\t0x73673cbdbdcebd81ULL, 0x34ba8f5d5d695dd2ULL, 0x5020901010401080ULL,\n\t0x03f507f4f4f7f4f3ULL, 0xc08bddcbcb0bcb16ULL, 0xc67cd33e3ef83eedULL,\n\t0x110a2d0505140528ULL, 0xe6ce78676781671fULL, 0x53d597e4e4b7e473ULL,\n\t0xbb4e0227279c2725ULL, 0x5882734141194132ULL, 0x9d0ba78b8b168b2cULL,\n\t0x0153f6a7a7a6a751ULL, 0x94fab27d7de97dcfULL, 0xfb374995956e95dcULL,\n\t0x9fad56d8d847d88eULL, 0x30eb70fbfbcbfb8bULL, 0x71c1cdeeee9fee23ULL,\n\t0x91f8bb7c7ced7cc7ULL, 0xe3cc716666856617ULL, 0x8ea77bdddd53dda6ULL,\n\t0x4b2eaf17175c17b8ULL, 0x468e454747014702ULL, 0xdc211a9e9e429e84ULL,\n\t0xc589d4caca0fca1eULL, 0x995a582d2db42d75ULL, 0x79632ebfbfc6bf91ULL,\n\t0x1b0e3f07071c0738ULL, 0x2347acadad8ead01ULL, 0x2fb4b05a5a755aeaULL,\n\t0xb51bef838336836cULL, 0xff66b63333cc3385ULL, 0xf2c65c636391633fULL,\n\t0x0a04120202080210ULL, 0x384993aaaa92aa39ULL, 0xa8e2de7171d971afULL,\n\t0xcf8dc6c8c807c80eULL, 0x7d32d119196419c8ULL, 0x70923b4949394972ULL,\n\t0x9aaf5fd9d943d986ULL, 0x1df931f2f2eff2c3ULL, 0x48dba8e3e3abe34bULL,\n\t0x2ab6b95b5b715be2ULL, 0x920dbc88881a8834ULL, 0xc8293e9a9a529aa4ULL,\n\t0xbe4c0b262698262dULL, 0xfa64bf3232c8328dULL, 0x4a7d59b0b0fab0e9ULL,\n\t0x6acff2e9e983e91bULL, 0x331e770f0f3c0f78ULL, 0xa6b733d5d573d5e6ULL,\n\t0xba1df480803a8074ULL, 0x7c6127bebec2be99ULL, 0xde87ebcdcd13cd26ULL,\n\t0xe468893434d034bdULL, 0x75903248483d487aULL, 0x24e354ffffdbffabULL,\n\t0x8ff48d7a7af57af7ULL, 0xea3d6490907a90f4ULL, 0x3ebe9d5f5f615fc2ULL,\n\t0xa0403d202080201dULL, 0xd5d00f6868bd6867ULL, 0x7234ca1a1a681ad0ULL,\n\t0x2c41b7aeae82ae19ULL, 0x5e757db4b4eab4c9ULL, 0x19a8ce54544d549aULL,\n\t0xe53b7f93937693ecULL, 0xaa442f222288220dULL, 0xe9c86364648d6407ULL,\n\t0x12ff2af1f1e3f1dbULL, 0xa2e6cc7373d173bfULL, 0x5a24821212481290ULL,\n\t0x5d807a40401d403aULL, 0x2810480808200840ULL, 0xe89b95c3c32bc356ULL,\n\t0x7bc5dfecec97ec33ULL, 0x90ab4ddbdb4bdb96ULL, 0x1f5fc0a1a1bea161ULL,\n\t0x8307918d8d0e8d1cULL, 0xc97ac83d3df43df5ULL, 0xf1335b97976697ccULL,\n\t0x0000000000000000ULL, 0xd483f9cfcf1bcf36ULL, 0x87566e2b2bac2b45ULL,\n\t0xb3ece17676c57697ULL, 0xb019e68282328264ULL, 0xa9b128d6d67fd6feULL,\n\t0x7736c31b1b6c1bd8ULL, 0x5b7774b5b5eeb5c1ULL, 0x2943beafaf86af11ULL,\n\t0xdfd41d6a6ab56a77ULL, 0x0da0ea50505d50baULL, 0x4c8a574545094512ULL,\n\t0x18fb38f3f3ebf3cbULL, 0xf060ad3030c0309dULL, 0x74c3c4efef9bef2bULL,\n\t0xc37eda3f3ffc3fe5ULL, 0x1caac75555495592ULL, 0x1059dba2a2b2a279ULL,\n\t0x65c9e9eaea8fea03ULL, 0xecca6a656589650fULL, 0x686903babad2bab9ULL,\n\t0x935e4a2f2fbc2f65ULL, 0xe79d8ec0c027c04eULL, 0x81a160dede5fdebeULL,\n\t0x6c38fc1c1c701ce0ULL, 0x2ee746fdfdd3fdbbULL, 0x649a1f4d4d294d52ULL,\n\t0xe0397692927292e4ULL, 0xbceafa7575c9758fULL, 0x1e0c360606180630ULL,\n\t0x9809ae8a8a128a24ULL, 0x40794bb2b2f2b2f9ULL, 0x59d185e6e6bfe663ULL,\n\t0x361c7e0e0e380e70ULL, 0x633ee71f1f7c1ff8ULL, 0xf7c4556262956237ULL,\n\t0xa3b53ad4d477d4eeULL, 0x324d81a8a89aa829ULL, 0xf4315296966296c4ULL,\n\t0x3aef62f9f9c3f99bULL, 0xf697a3c5c533c566ULL, 0xb14a102525942535ULL,\n\t0x20b2ab59597959f2ULL, 0xae15d084842a8454ULL, 0xa7e4c57272d572b7ULL,\n\t0xdd72ec3939e439d5ULL, 0x6198164c4c2d4c5aULL, 0x3bbc945e5e655ecaULL,\n\t0x85f09f7878fd78e7ULL, 0xd870e53838e038ddULL, 0x8605988c8c0a8c14ULL,\n\t0xb2bf17d1d163d1c6ULL, 0x0b57e4a5a5aea541ULL, 0x4dd9a1e2e2afe243ULL,\n\t0xf8c24e616199612fULL, 0x457b42b3b3f6b3f1ULL, 0xa542342121842115ULL,\n\t0xd625089c9c4a9c94ULL, 0x663cee1e1e781ef0ULL, 0x5286614343114322ULL,\n\t0xfc93b1c7c73bc776ULL, 0x2be54ffcfcd7fcb3ULL, 0x1408240404100420ULL,\n\t0x08a2e351515951b2ULL, 0xc72f2599995e99bcULL, 0xc4da226d6da96d4fULL,\n\t0x391a650d0d340d68ULL, 0x35e979fafacffa83ULL, 0x84a369dfdf5bdfb6ULL,\n\t0x9bfca97e7ee57ed7ULL, 0xb44819242490243dULL, 0xd776fe3b3bec3bc5ULL,\n\t0x3d4b9aabab96ab31ULL, 0xd181f0cece1fce3eULL, 0x5522991111441188ULL,\n\t0x8903838f8f068f0cULL, 0x6b9c044e4e254e4aULL, 0x517366b7b7e6b7d1ULL,\n\t0x60cbe0ebeb8beb0bULL, 0xcc78c13c3cf03cfdULL, 0xbf1ffd81813e817cULL,\n\t0xfe354094946a94d4ULL, 0x0cf31cf7f7fbf7ebULL, 0x676f18b9b9deb9a1ULL,\n\t0x5f268b13134c1398ULL, 0x9c58512c2cb02c7dULL, 0xb8bb05d3d36bd3d6ULL,\n\t0x5cd38ce7e7bbe76bULL, 0xcbdc396e6ea56e57ULL, 0xf395aac4c437c46eULL,\n\t0x0f061b03030c0318ULL, 0x13acdc565645568aULL, 0x49885e44440d441aULL,\n\t0x9efea07f7fe17fdfULL, 0x374f88a9a99ea921ULL, 0x8254672a2aa82a4dULL,\n\t0x6d6b0abbbbd6bbb1ULL, 0xe29f87c1c123c146ULL, 0x02a6f153535153a2ULL,\n\t0x8ba572dcdc57dcaeULL, 0x2716530b0b2c0b58ULL, 0xd327019d9d4e9d9cULL,\n\t0xc1d82b6c6cad6c47ULL, 0xf562a43131c43195ULL, 0xb9e8f37474cd7487ULL,\n\t0x09f115f6f6fff6e3ULL, 0x438c4c464605460aULL, 0x2645a5acac8aac09ULL,\n\t0x970fb589891e893cULL, 0x4428b414145014a0ULL, 0x42dfbae1e1a3e15bULL,\n\t0x4e2ca616165816b0ULL, 0xd274f73a3ae83acdULL, 0xd0d2066969b9696fULL,\n\t0x2d12410909240948ULL, 0xade0d77070dd70a7ULL, 0x54716fb6b6e2b6d9ULL,\n\t0xb7bd1ed0d067d0ceULL, 0x7ec7d6eded93ed3bULL, 0xdb85e2cccc17cc2eULL,\n\t0x578468424215422aULL, 0xc22d2c98985a98b4ULL, 0x0e55eda4a4aaa449ULL,\n\t0x8850752828a0285dULL, 0x31b8865c5c6d5cdaULL, 0x3fed6bf8f8c7f893ULL,\n\t0xa411c28686228644ULL,\n};\n\nstatic const u64 C4[256] = {\n\t0xc07830d818186018ULL, 0x05af462623238c23ULL, 0x7ef991b8c6c63fc6ULL,\n\t0x136fcdfbe8e887e8ULL, 0x4ca113cb87872687ULL, 0xa9626d11b8b8dab8ULL,\n\t0x0805020901010401ULL, 0x426e9e0d4f4f214fULL, 0xadee6c9b3636d836ULL,\n\t0x590451ffa6a6a2a6ULL, 0xdebdb90cd2d26fd2ULL, 0xfb06f70ef5f5f3f5ULL,\n\t0xef80f2967979f979ULL, 0x5fcede306f6fa16fULL, 0xfcef3f6d91917e91ULL,\n\t0xaa07a4f852525552ULL, 0x27fdc04760609d60ULL, 0x89766535bcbccabcULL,\n\t0xaccd2b379b9b569bULL, 0x048c018a8e8e028eULL, 0x71155bd2a3a3b6a3ULL,\n\t0x603c186c0c0c300cULL, 0xff8af6847b7bf17bULL, 0xb5e16a803535d435ULL,\n\t0xe8693af51d1d741dULL, 0x5347ddb3e0e0a7e0ULL, 0xf6acb321d7d77bd7ULL,\n\t0x5eed999cc2c22fc2ULL, 0x6d965c432e2eb82eULL, 0x627a96294b4b314bULL,\n\t0xa321e15dfefedffeULL, 0x8216aed557574157ULL, 0xa8412abd15155415ULL,\n\t0x9fb6eee87777c177ULL, 0xa5eb6e923737dc37ULL, 0x7b56d79ee5e5b3e5ULL,\n\t0x8cd923139f9f469fULL, 0xd317fd23f0f0e7f0ULL, 0x6a7f94204a4a354aULL,\n\t0x9e95a944dada4fdaULL, 0xfa25b0a258587d58ULL, 0x06ca8fcfc9c903c9ULL,\n\t0x558d527c2929a429ULL, 0x5022145a0a0a280aULL, 0xe14f7f50b1b1feb1ULL,\n\t0x691a5dc9a0a0baa0ULL, 0x7fdad6146b6bb16bULL, 0x5cab17d985852e85ULL,\n\t0x8173673cbdbdcebdULL, 0xd234ba8f5d5d695dULL, 0x8050209010104010ULL,\n\t0xf303f507f4f4f7f4ULL, 0x16c08bddcbcb0bcbULL, 0xedc67cd33e3ef83eULL,\n\t0x28110a2d05051405ULL, 0x1fe6ce7867678167ULL, 0x7353d597e4e4b7e4ULL,\n\t0x25bb4e0227279c27ULL, 0x3258827341411941ULL, 0x2c9d0ba78b8b168bULL,\n\t0x510153f6a7a7a6a7ULL, 0xcf94fab27d7de97dULL, 0xdcfb374995956e95ULL,\n\t0x8e9fad56d8d847d8ULL, 0x8b30eb70fbfbcbfbULL, 0x2371c1cdeeee9feeULL,\n\t0xc791f8bb7c7ced7cULL, 0x17e3cc7166668566ULL, 0xa68ea77bdddd53ddULL,\n\t0xb84b2eaf17175c17ULL, 0x02468e4547470147ULL, 0x84dc211a9e9e429eULL,\n\t0x1ec589d4caca0fcaULL, 0x75995a582d2db42dULL, 0x9179632ebfbfc6bfULL,\n\t0x381b0e3f07071c07ULL, 0x012347acadad8eadULL, 0xea2fb4b05a5a755aULL,\n\t0x6cb51bef83833683ULL, 0x85ff66b63333cc33ULL, 0x3ff2c65c63639163ULL,\n\t0x100a041202020802ULL, 0x39384993aaaa92aaULL, 0xafa8e2de7171d971ULL,\n\t0x0ecf8dc6c8c807c8ULL, 0xc87d32d119196419ULL, 0x7270923b49493949ULL,\n\t0x869aaf5fd9d943d9ULL, 0xc31df931f2f2eff2ULL, 0x4b48dba8e3e3abe3ULL,\n\t0xe22ab6b95b5b715bULL, 0x34920dbc88881a88ULL, 0xa4c8293e9a9a529aULL,\n\t0x2dbe4c0b26269826ULL, 0x8dfa64bf3232c832ULL, 0xe94a7d59b0b0fab0ULL,\n\t0x1b6acff2e9e983e9ULL, 0x78331e770f0f3c0fULL, 0xe6a6b733d5d573d5ULL,\n\t0x74ba1df480803a80ULL, 0x997c6127bebec2beULL, 0x26de87ebcdcd13cdULL,\n\t0xbde468893434d034ULL, 0x7a75903248483d48ULL, 0xab24e354ffffdbffULL,\n\t0xf78ff48d7a7af57aULL, 0xf4ea3d6490907a90ULL, 0xc23ebe9d5f5f615fULL,\n\t0x1da0403d20208020ULL, 0x67d5d00f6868bd68ULL, 0xd07234ca1a1a681aULL,\n\t0x192c41b7aeae82aeULL, 0xc95e757db4b4eab4ULL, 0x9a19a8ce54544d54ULL,\n\t0xece53b7f93937693ULL, 0x0daa442f22228822ULL, 0x07e9c86364648d64ULL,\n\t0xdb12ff2af1f1e3f1ULL, 0xbfa2e6cc7373d173ULL, 0x905a248212124812ULL,\n\t0x3a5d807a40401d40ULL, 0x4028104808082008ULL, 0x56e89b95c3c32bc3ULL,\n\t0x337bc5dfecec97ecULL, 0x9690ab4ddbdb4bdbULL, 0x611f5fc0a1a1bea1ULL,\n\t0x1c8307918d8d0e8dULL, 0xf5c97ac83d3df43dULL, 0xccf1335b97976697ULL,\n\t0x0000000000000000ULL, 0x36d483f9cfcf1bcfULL, 0x4587566e2b2bac2bULL,\n\t0x97b3ece17676c576ULL, 0x64b019e682823282ULL, 0xfea9b128d6d67fd6ULL,\n\t0xd87736c31b1b6c1bULL, 0xc15b7774b5b5eeb5ULL, 0x112943beafaf86afULL,\n\t0x77dfd41d6a6ab56aULL, 0xba0da0ea50505d50ULL, 0x124c8a5745450945ULL,\n\t0xcb18fb38f3f3ebf3ULL, 0x9df060ad3030c030ULL, 0x2b74c3c4efef9befULL,\n\t0xe5c37eda3f3ffc3fULL, 0x921caac755554955ULL, 0x791059dba2a2b2a2ULL,\n\t0x0365c9e9eaea8feaULL, 0x0fecca6a65658965ULL, 0xb9686903babad2baULL,\n\t0x65935e4a2f2fbc2fULL, 0x4ee79d8ec0c027c0ULL, 0xbe81a160dede5fdeULL,\n\t0xe06c38fc1c1c701cULL, 0xbb2ee746fdfdd3fdULL, 0x52649a1f4d4d294dULL,\n\t0xe4e0397692927292ULL, 0x8fbceafa7575c975ULL, 0x301e0c3606061806ULL,\n\t0x249809ae8a8a128aULL, 0xf940794bb2b2f2b2ULL, 0x6359d185e6e6bfe6ULL,\n\t0x70361c7e0e0e380eULL, 0xf8633ee71f1f7c1fULL, 0x37f7c45562629562ULL,\n\t0xeea3b53ad4d477d4ULL, 0x29324d81a8a89aa8ULL, 0xc4f4315296966296ULL,\n\t0x9b3aef62f9f9c3f9ULL, 0x66f697a3c5c533c5ULL, 0x35b14a1025259425ULL,\n\t0xf220b2ab59597959ULL, 0x54ae15d084842a84ULL, 0xb7a7e4c57272d572ULL,\n\t0xd5dd72ec3939e439ULL, 0x5a6198164c4c2d4cULL, 0xca3bbc945e5e655eULL,\n\t0xe785f09f7878fd78ULL, 0xddd870e53838e038ULL, 0x148605988c8c0a8cULL,\n\t0xc6b2bf17d1d163d1ULL, 0x410b57e4a5a5aea5ULL, 0x434dd9a1e2e2afe2ULL,\n\t0x2ff8c24e61619961ULL, 0xf1457b42b3b3f6b3ULL, 0x15a5423421218421ULL,\n\t0x94d625089c9c4a9cULL, 0xf0663cee1e1e781eULL, 0x2252866143431143ULL,\n\t0x76fc93b1c7c73bc7ULL, 0xb32be54ffcfcd7fcULL, 0x2014082404041004ULL,\n\t0xb208a2e351515951ULL, 0xbcc72f2599995e99ULL, 0x4fc4da226d6da96dULL,\n\t0x68391a650d0d340dULL, 0x8335e979fafacffaULL, 0xb684a369dfdf5bdfULL,\n\t0xd79bfca97e7ee57eULL, 0x3db4481924249024ULL, 0xc5d776fe3b3bec3bULL,\n\t0x313d4b9aabab96abULL, 0x3ed181f0cece1fceULL, 0x8855229911114411ULL,\n\t0x0c8903838f8f068fULL, 0x4a6b9c044e4e254eULL, 0xd1517366b7b7e6b7ULL,\n\t0x0b60cbe0ebeb8bebULL, 0xfdcc78c13c3cf03cULL, 0x7cbf1ffd81813e81ULL,\n\t0xd4fe354094946a94ULL, 0xeb0cf31cf7f7fbf7ULL, 0xa1676f18b9b9deb9ULL,\n\t0x985f268b13134c13ULL, 0x7d9c58512c2cb02cULL, 0xd6b8bb05d3d36bd3ULL,\n\t0x6b5cd38ce7e7bbe7ULL, 0x57cbdc396e6ea56eULL, 0x6ef395aac4c437c4ULL,\n\t0x180f061b03030c03ULL, 0x8a13acdc56564556ULL, 0x1a49885e44440d44ULL,\n\t0xdf9efea07f7fe17fULL, 0x21374f88a9a99ea9ULL, 0x4d8254672a2aa82aULL,\n\t0xb16d6b0abbbbd6bbULL, 0x46e29f87c1c123c1ULL, 0xa202a6f153535153ULL,\n\t0xae8ba572dcdc57dcULL, 0x582716530b0b2c0bULL, 0x9cd327019d9d4e9dULL,\n\t0x47c1d82b6c6cad6cULL, 0x95f562a43131c431ULL, 0x87b9e8f37474cd74ULL,\n\t0xe309f115f6f6fff6ULL, 0x0a438c4c46460546ULL, 0x092645a5acac8aacULL,\n\t0x3c970fb589891e89ULL, 0xa04428b414145014ULL, 0x5b42dfbae1e1a3e1ULL,\n\t0xb04e2ca616165816ULL, 0xcdd274f73a3ae83aULL, 0x6fd0d2066969b969ULL,\n\t0x482d124109092409ULL, 0xa7ade0d77070dd70ULL, 0xd954716fb6b6e2b6ULL,\n\t0xceb7bd1ed0d067d0ULL, 0x3b7ec7d6eded93edULL, 0x2edb85e2cccc17ccULL,\n\t0x2a57846842421542ULL, 0xb4c22d2c98985a98ULL, 0x490e55eda4a4aaa4ULL,\n\t0x5d8850752828a028ULL, 0xda31b8865c5c6d5cULL, 0x933fed6bf8f8c7f8ULL,\n\t0x44a411c286862286ULL,\n};\n\nstatic const u64 C5[256] = {\n\t0x18c07830d8181860ULL, 0x2305af462623238cULL, 0xc67ef991b8c6c63fULL,\n\t0xe8136fcdfbe8e887ULL, 0x874ca113cb878726ULL, 0xb8a9626d11b8b8daULL,\n\t0x0108050209010104ULL, 0x4f426e9e0d4f4f21ULL, 0x36adee6c9b3636d8ULL,\n\t0xa6590451ffa6a6a2ULL, 0xd2debdb90cd2d26fULL, 0xf5fb06f70ef5f5f3ULL,\n\t0x79ef80f2967979f9ULL, 0x6f5fcede306f6fa1ULL, 0x91fcef3f6d91917eULL,\n\t0x52aa07a4f8525255ULL, 0x6027fdc04760609dULL, 0xbc89766535bcbccaULL,\n\t0x9baccd2b379b9b56ULL, 0x8e048c018a8e8e02ULL, 0xa371155bd2a3a3b6ULL,\n\t0x0c603c186c0c0c30ULL, 0x7bff8af6847b7bf1ULL, 0x35b5e16a803535d4ULL,\n\t0x1de8693af51d1d74ULL, 0xe05347ddb3e0e0a7ULL, 0xd7f6acb321d7d77bULL,\n\t0xc25eed999cc2c22fULL, 0x2e6d965c432e2eb8ULL, 0x4b627a96294b4b31ULL,\n\t0xfea321e15dfefedfULL, 0x578216aed5575741ULL, 0x15a8412abd151554ULL,\n\t0x779fb6eee87777c1ULL, 0x37a5eb6e923737dcULL, 0xe57b56d79ee5e5b3ULL,\n\t0x9f8cd923139f9f46ULL, 0xf0d317fd23f0f0e7ULL, 0x4a6a7f94204a4a35ULL,\n\t0xda9e95a944dada4fULL, 0x58fa25b0a258587dULL, 0xc906ca8fcfc9c903ULL,\n\t0x29558d527c2929a4ULL, 0x0a5022145a0a0a28ULL, 0xb1e14f7f50b1b1feULL,\n\t0xa0691a5dc9a0a0baULL, 0x6b7fdad6146b6bb1ULL, 0x855cab17d985852eULL,\n\t0xbd8173673cbdbdceULL, 0x5dd234ba8f5d5d69ULL, 0x1080502090101040ULL,\n\t0xf4f303f507f4f4f7ULL, 0xcb16c08bddcbcb0bULL, 0x3eedc67cd33e3ef8ULL,\n\t0x0528110a2d050514ULL, 0x671fe6ce78676781ULL, 0xe47353d597e4e4b7ULL,\n\t0x2725bb4e0227279cULL, 0x4132588273414119ULL, 0x8b2c9d0ba78b8b16ULL,\n\t0xa7510153f6a7a7a6ULL, 0x7dcf94fab27d7de9ULL, 0x95dcfb374995956eULL,\n\t0xd88e9fad56d8d847ULL, 0xfb8b30eb70fbfbcbULL, 0xee2371c1cdeeee9fULL,\n\t0x7cc791f8bb7c7cedULL, 0x6617e3cc71666685ULL, 0xdda68ea77bdddd53ULL,\n\t0x17b84b2eaf17175cULL, 0x4702468e45474701ULL, 0x9e84dc211a9e9e42ULL,\n\t0xca1ec589d4caca0fULL, 0x2d75995a582d2db4ULL, 0xbf9179632ebfbfc6ULL,\n\t0x07381b0e3f07071cULL, 0xad012347acadad8eULL, 0x5aea2fb4b05a5a75ULL,\n\t0x836cb51bef838336ULL, 0x3385ff66b63333ccULL, 0x633ff2c65c636391ULL,\n\t0x02100a0412020208ULL, 0xaa39384993aaaa92ULL, 0x71afa8e2de7171d9ULL,\n\t0xc80ecf8dc6c8c807ULL, 0x19c87d32d1191964ULL, 0x497270923b494939ULL,\n\t0xd9869aaf5fd9d943ULL, 0xf2c31df931f2f2efULL, 0xe34b48dba8e3e3abULL,\n\t0x5be22ab6b95b5b71ULL, 0x8834920dbc88881aULL, 0x9aa4c8293e9a9a52ULL,\n\t0x262dbe4c0b262698ULL, 0x328dfa64bf3232c8ULL, 0xb0e94a7d59b0b0faULL,\n\t0xe91b6acff2e9e983ULL, 0x0f78331e770f0f3cULL, 0xd5e6a6b733d5d573ULL,\n\t0x8074ba1df480803aULL, 0xbe997c6127bebec2ULL, 0xcd26de87ebcdcd13ULL,\n\t0x34bde468893434d0ULL, 0x487a75903248483dULL, 0xffab24e354ffffdbULL,\n\t0x7af78ff48d7a7af5ULL, 0x90f4ea3d6490907aULL, 0x5fc23ebe9d5f5f61ULL,\n\t0x201da0403d202080ULL, 0x6867d5d00f6868bdULL, 0x1ad07234ca1a1a68ULL,\n\t0xae192c41b7aeae82ULL, 0xb4c95e757db4b4eaULL, 0x549a19a8ce54544dULL,\n\t0x93ece53b7f939376ULL, 0x220daa442f222288ULL, 0x6407e9c86364648dULL,\n\t0xf1db12ff2af1f1e3ULL, 0x73bfa2e6cc7373d1ULL, 0x12905a2482121248ULL,\n\t0x403a5d807a40401dULL, 0x0840281048080820ULL, 0xc356e89b95c3c32bULL,\n\t0xec337bc5dfecec97ULL, 0xdb9690ab4ddbdb4bULL, 0xa1611f5fc0a1a1beULL,\n\t0x8d1c8307918d8d0eULL, 0x3df5c97ac83d3df4ULL, 0x97ccf1335b979766ULL,\n\t0x0000000000000000ULL, 0xcf36d483f9cfcf1bULL, 0x2b4587566e2b2bacULL,\n\t0x7697b3ece17676c5ULL, 0x8264b019e6828232ULL, 0xd6fea9b128d6d67fULL,\n\t0x1bd87736c31b1b6cULL, 0xb5c15b7774b5b5eeULL, 0xaf112943beafaf86ULL,\n\t0x6a77dfd41d6a6ab5ULL, 0x50ba0da0ea50505dULL, 0x45124c8a57454509ULL,\n\t0xf3cb18fb38f3f3ebULL, 0x309df060ad3030c0ULL, 0xef2b74c3c4efef9bULL,\n\t0x3fe5c37eda3f3ffcULL, 0x55921caac7555549ULL, 0xa2791059dba2a2b2ULL,\n\t0xea0365c9e9eaea8fULL, 0x650fecca6a656589ULL, 0xbab9686903babad2ULL,\n\t0x2f65935e4a2f2fbcULL, 0xc04ee79d8ec0c027ULL, 0xdebe81a160dede5fULL,\n\t0x1ce06c38fc1c1c70ULL, 0xfdbb2ee746fdfdd3ULL, 0x4d52649a1f4d4d29ULL,\n\t0x92e4e03976929272ULL, 0x758fbceafa7575c9ULL, 0x06301e0c36060618ULL,\n\t0x8a249809ae8a8a12ULL, 0xb2f940794bb2b2f2ULL, 0xe66359d185e6e6bfULL,\n\t0x0e70361c7e0e0e38ULL, 0x1ff8633ee71f1f7cULL, 0x6237f7c455626295ULL,\n\t0xd4eea3b53ad4d477ULL, 0xa829324d81a8a89aULL, 0x96c4f43152969662ULL,\n\t0xf99b3aef62f9f9c3ULL, 0xc566f697a3c5c533ULL, 0x2535b14a10252594ULL,\n\t0x59f220b2ab595979ULL, 0x8454ae15d084842aULL, 0x72b7a7e4c57272d5ULL,\n\t0x39d5dd72ec3939e4ULL, 0x4c5a6198164c4c2dULL, 0x5eca3bbc945e5e65ULL,\n\t0x78e785f09f7878fdULL, 0x38ddd870e53838e0ULL, 0x8c148605988c8c0aULL,\n\t0xd1c6b2bf17d1d163ULL, 0xa5410b57e4a5a5aeULL, 0xe2434dd9a1e2e2afULL,\n\t0x612ff8c24e616199ULL, 0xb3f1457b42b3b3f6ULL, 0x2115a54234212184ULL,\n\t0x9c94d625089c9c4aULL, 0x1ef0663cee1e1e78ULL, 0x4322528661434311ULL,\n\t0xc776fc93b1c7c73bULL, 0xfcb32be54ffcfcd7ULL, 0x0420140824040410ULL,\n\t0x51b208a2e3515159ULL, 0x99bcc72f2599995eULL, 0x6d4fc4da226d6da9ULL,\n\t0x0d68391a650d0d34ULL, 0xfa8335e979fafacfULL, 0xdfb684a369dfdf5bULL,\n\t0x7ed79bfca97e7ee5ULL, 0x243db44819242490ULL, 0x3bc5d776fe3b3becULL,\n\t0xab313d4b9aabab96ULL, 0xce3ed181f0cece1fULL, 0x1188552299111144ULL,\n\t0x8f0c8903838f8f06ULL, 0x4e4a6b9c044e4e25ULL, 0xb7d1517366b7b7e6ULL,\n\t0xeb0b60cbe0ebeb8bULL, 0x3cfdcc78c13c3cf0ULL, 0x817cbf1ffd81813eULL,\n\t0x94d4fe354094946aULL, 0xf7eb0cf31cf7f7fbULL, 0xb9a1676f18b9b9deULL,\n\t0x13985f268b13134cULL, 0x2c7d9c58512c2cb0ULL, 0xd3d6b8bb05d3d36bULL,\n\t0xe76b5cd38ce7e7bbULL, 0x6e57cbdc396e6ea5ULL, 0xc46ef395aac4c437ULL,\n\t0x03180f061b03030cULL, 0x568a13acdc565645ULL, 0x441a49885e44440dULL,\n\t0x7fdf9efea07f7fe1ULL, 0xa921374f88a9a99eULL, 0x2a4d8254672a2aa8ULL,\n\t0xbbb16d6b0abbbbd6ULL, 0xc146e29f87c1c123ULL, 0x53a202a6f1535351ULL,\n\t0xdcae8ba572dcdc57ULL, 0x0b582716530b0b2cULL, 0x9d9cd327019d9d4eULL,\n\t0x6c47c1d82b6c6cadULL, 0x3195f562a43131c4ULL, 0x7487b9e8f37474cdULL,\n\t0xf6e309f115f6f6ffULL, 0x460a438c4c464605ULL, 0xac092645a5acac8aULL,\n\t0x893c970fb589891eULL, 0x14a04428b4141450ULL, 0xe15b42dfbae1e1a3ULL,\n\t0x16b04e2ca6161658ULL, 0x3acdd274f73a3ae8ULL, 0x696fd0d2066969b9ULL,\n\t0x09482d1241090924ULL, 0x70a7ade0d77070ddULL, 0xb6d954716fb6b6e2ULL,\n\t0xd0ceb7bd1ed0d067ULL, 0xed3b7ec7d6eded93ULL, 0xcc2edb85e2cccc17ULL,\n\t0x422a578468424215ULL, 0x98b4c22d2c98985aULL, 0xa4490e55eda4a4aaULL,\n\t0x285d8850752828a0ULL, 0x5cda31b8865c5c6dULL, 0xf8933fed6bf8f8c7ULL,\n\t0x8644a411c2868622ULL,\n};\n\nstatic const u64 C6[256] = {\n\t0x6018c07830d81818ULL, 0x8c2305af46262323ULL, 0x3fc67ef991b8c6c6ULL,\n\t0x87e8136fcdfbe8e8ULL, 0x26874ca113cb8787ULL, 0xdab8a9626d11b8b8ULL,\n\t0x0401080502090101ULL, 0x214f426e9e0d4f4fULL, 0xd836adee6c9b3636ULL,\n\t0xa2a6590451ffa6a6ULL, 0x6fd2debdb90cd2d2ULL, 0xf3f5fb06f70ef5f5ULL,\n\t0xf979ef80f2967979ULL, 0xa16f5fcede306f6fULL, 0x7e91fcef3f6d9191ULL,\n\t0x5552aa07a4f85252ULL, 0x9d6027fdc0476060ULL, 0xcabc89766535bcbcULL,\n\t0x569baccd2b379b9bULL, 0x028e048c018a8e8eULL, 0xb6a371155bd2a3a3ULL,\n\t0x300c603c186c0c0cULL, 0xf17bff8af6847b7bULL, 0xd435b5e16a803535ULL,\n\t0x741de8693af51d1dULL, 0xa7e05347ddb3e0e0ULL, 0x7bd7f6acb321d7d7ULL,\n\t0x2fc25eed999cc2c2ULL, 0xb82e6d965c432e2eULL, 0x314b627a96294b4bULL,\n\t0xdffea321e15dfefeULL, 0x41578216aed55757ULL, 0x5415a8412abd1515ULL,\n\t0xc1779fb6eee87777ULL, 0xdc37a5eb6e923737ULL, 0xb3e57b56d79ee5e5ULL,\n\t0x469f8cd923139f9fULL, 0xe7f0d317fd23f0f0ULL, 0x354a6a7f94204a4aULL,\n\t0x4fda9e95a944dadaULL, 0x7d58fa25b0a25858ULL, 0x03c906ca8fcfc9c9ULL,\n\t0xa429558d527c2929ULL, 0x280a5022145a0a0aULL, 0xfeb1e14f7f50b1b1ULL,\n\t0xbaa0691a5dc9a0a0ULL, 0xb16b7fdad6146b6bULL, 0x2e855cab17d98585ULL,\n\t0xcebd8173673cbdbdULL, 0x695dd234ba8f5d5dULL, 0x4010805020901010ULL,\n\t0xf7f4f303f507f4f4ULL, 0x0bcb16c08bddcbcbULL, 0xf83eedc67cd33e3eULL,\n\t0x140528110a2d0505ULL, 0x81671fe6ce786767ULL, 0xb7e47353d597e4e4ULL,\n\t0x9c2725bb4e022727ULL, 0x1941325882734141ULL, 0x168b2c9d0ba78b8bULL,\n\t0xa6a7510153f6a7a7ULL, 0xe97dcf94fab27d7dULL, 0x6e95dcfb37499595ULL,\n\t0x47d88e9fad56d8d8ULL, 0xcbfb8b30eb70fbfbULL, 0x9fee2371c1cdeeeeULL,\n\t0xed7cc791f8bb7c7cULL, 0x856617e3cc716666ULL, 0x53dda68ea77bddddULL,\n\t0x5c17b84b2eaf1717ULL, 0x014702468e454747ULL, 0x429e84dc211a9e9eULL,\n\t0x0fca1ec589d4cacaULL, 0xb42d75995a582d2dULL, 0xc6bf9179632ebfbfULL,\n\t0x1c07381b0e3f0707ULL, 0x8ead012347acadadULL, 0x755aea2fb4b05a5aULL,\n\t0x36836cb51bef8383ULL, 0xcc3385ff66b63333ULL, 0x91633ff2c65c6363ULL,\n\t0x0802100a04120202ULL, 0x92aa39384993aaaaULL, 0xd971afa8e2de7171ULL,\n\t0x07c80ecf8dc6c8c8ULL, 0x6419c87d32d11919ULL, 0x39497270923b4949ULL,\n\t0x43d9869aaf5fd9d9ULL, 0xeff2c31df931f2f2ULL, 0xabe34b48dba8e3e3ULL,\n\t0x715be22ab6b95b5bULL, 0x1a8834920dbc8888ULL, 0x529aa4c8293e9a9aULL,\n\t0x98262dbe4c0b2626ULL, 0xc8328dfa64bf3232ULL, 0xfab0e94a7d59b0b0ULL,\n\t0x83e91b6acff2e9e9ULL, 0x3c0f78331e770f0fULL, 0x73d5e6a6b733d5d5ULL,\n\t0x3a8074ba1df48080ULL, 0xc2be997c6127bebeULL, 0x13cd26de87ebcdcdULL,\n\t0xd034bde468893434ULL, 0x3d487a7590324848ULL, 0xdbffab24e354ffffULL,\n\t0xf57af78ff48d7a7aULL, 0x7a90f4ea3d649090ULL, 0x615fc23ebe9d5f5fULL,\n\t0x80201da0403d2020ULL, 0xbd6867d5d00f6868ULL, 0x681ad07234ca1a1aULL,\n\t0x82ae192c41b7aeaeULL, 0xeab4c95e757db4b4ULL, 0x4d549a19a8ce5454ULL,\n\t0x7693ece53b7f9393ULL, 0x88220daa442f2222ULL, 0x8d6407e9c8636464ULL,\n\t0xe3f1db12ff2af1f1ULL, 0xd173bfa2e6cc7373ULL, 0x4812905a24821212ULL,\n\t0x1d403a5d807a4040ULL, 0x2008402810480808ULL, 0x2bc356e89b95c3c3ULL,\n\t0x97ec337bc5dfececULL, 0x4bdb9690ab4ddbdbULL, 0xbea1611f5fc0a1a1ULL,\n\t0x0e8d1c8307918d8dULL, 0xf43df5c97ac83d3dULL, 0x6697ccf1335b9797ULL,\n\t0x0000000000000000ULL, 0x1bcf36d483f9cfcfULL, 0xac2b4587566e2b2bULL,\n\t0xc57697b3ece17676ULL, 0x328264b019e68282ULL, 0x7fd6fea9b128d6d6ULL,\n\t0x6c1bd87736c31b1bULL, 0xeeb5c15b7774b5b5ULL, 0x86af112943beafafULL,\n\t0xb56a77dfd41d6a6aULL, 0x5d50ba0da0ea5050ULL, 0x0945124c8a574545ULL,\n\t0xebf3cb18fb38f3f3ULL, 0xc0309df060ad3030ULL, 0x9bef2b74c3c4efefULL,\n\t0xfc3fe5c37eda3f3fULL, 0x4955921caac75555ULL, 0xb2a2791059dba2a2ULL,\n\t0x8fea0365c9e9eaeaULL, 0x89650fecca6a6565ULL, 0xd2bab9686903babaULL,\n\t0xbc2f65935e4a2f2fULL, 0x27c04ee79d8ec0c0ULL, 0x5fdebe81a160dedeULL,\n\t0x701ce06c38fc1c1cULL, 0xd3fdbb2ee746fdfdULL, 0x294d52649a1f4d4dULL,\n\t0x7292e4e039769292ULL, 0xc9758fbceafa7575ULL, 0x1806301e0c360606ULL,\n\t0x128a249809ae8a8aULL, 0xf2b2f940794bb2b2ULL, 0xbfe66359d185e6e6ULL,\n\t0x380e70361c7e0e0eULL, 0x7c1ff8633ee71f1fULL, 0x956237f7c4556262ULL,\n\t0x77d4eea3b53ad4d4ULL, 0x9aa829324d81a8a8ULL, 0x6296c4f431529696ULL,\n\t0xc3f99b3aef62f9f9ULL, 0x33c566f697a3c5c5ULL, 0x942535b14a102525ULL,\n\t0x7959f220b2ab5959ULL, 0x2a8454ae15d08484ULL, 0xd572b7a7e4c57272ULL,\n\t0xe439d5dd72ec3939ULL, 0x2d4c5a6198164c4cULL, 0x655eca3bbc945e5eULL,\n\t0xfd78e785f09f7878ULL, 0xe038ddd870e53838ULL, 0x0a8c148605988c8cULL,\n\t0x63d1c6b2bf17d1d1ULL, 0xaea5410b57e4a5a5ULL, 0xafe2434dd9a1e2e2ULL,\n\t0x99612ff8c24e6161ULL, 0xf6b3f1457b42b3b3ULL, 0x842115a542342121ULL,\n\t0x4a9c94d625089c9cULL, 0x781ef0663cee1e1eULL, 0x1143225286614343ULL,\n\t0x3bc776fc93b1c7c7ULL, 0xd7fcb32be54ffcfcULL, 0x1004201408240404ULL,\n\t0x5951b208a2e35151ULL, 0x5e99bcc72f259999ULL, 0xa96d4fc4da226d6dULL,\n\t0x340d68391a650d0dULL, 0xcffa8335e979fafaULL, 0x5bdfb684a369dfdfULL,\n\t0xe57ed79bfca97e7eULL, 0x90243db448192424ULL, 0xec3bc5d776fe3b3bULL,\n\t0x96ab313d4b9aababULL, 0x1fce3ed181f0ceceULL, 0x4411885522991111ULL,\n\t0x068f0c8903838f8fULL, 0x254e4a6b9c044e4eULL, 0xe6b7d1517366b7b7ULL,\n\t0x8beb0b60cbe0ebebULL, 0xf03cfdcc78c13c3cULL, 0x3e817cbf1ffd8181ULL,\n\t0x6a94d4fe35409494ULL, 0xfbf7eb0cf31cf7f7ULL, 0xdeb9a1676f18b9b9ULL,\n\t0x4c13985f268b1313ULL, 0xb02c7d9c58512c2cULL, 0x6bd3d6b8bb05d3d3ULL,\n\t0xbbe76b5cd38ce7e7ULL, 0xa56e57cbdc396e6eULL, 0x37c46ef395aac4c4ULL,\n\t0x0c03180f061b0303ULL, 0x45568a13acdc5656ULL, 0x0d441a49885e4444ULL,\n\t0xe17fdf9efea07f7fULL, 0x9ea921374f88a9a9ULL, 0xa82a4d8254672a2aULL,\n\t0xd6bbb16d6b0abbbbULL, 0x23c146e29f87c1c1ULL, 0x5153a202a6f15353ULL,\n\t0x57dcae8ba572dcdcULL, 0x2c0b582716530b0bULL, 0x4e9d9cd327019d9dULL,\n\t0xad6c47c1d82b6c6cULL, 0xc43195f562a43131ULL, 0xcd7487b9e8f37474ULL,\n\t0xfff6e309f115f6f6ULL, 0x05460a438c4c4646ULL, 0x8aac092645a5acacULL,\n\t0x1e893c970fb58989ULL, 0x5014a04428b41414ULL, 0xa3e15b42dfbae1e1ULL,\n\t0x5816b04e2ca61616ULL, 0xe83acdd274f73a3aULL, 0xb9696fd0d2066969ULL,\n\t0x2409482d12410909ULL, 0xdd70a7ade0d77070ULL, 0xe2b6d954716fb6b6ULL,\n\t0x67d0ceb7bd1ed0d0ULL, 0x93ed3b7ec7d6ededULL, 0x17cc2edb85e2ccccULL,\n\t0x15422a5784684242ULL, 0x5a98b4c22d2c9898ULL, 0xaaa4490e55eda4a4ULL,\n\t0xa0285d8850752828ULL, 0x6d5cda31b8865c5cULL, 0xc7f8933fed6bf8f8ULL,\n\t0x228644a411c28686ULL,\n};\n\nstatic const u64 C7[256] = {\n\t0x186018c07830d818ULL, 0x238c2305af462623ULL, 0xc63fc67ef991b8c6ULL,\n\t0xe887e8136fcdfbe8ULL, 0x8726874ca113cb87ULL, 0xb8dab8a9626d11b8ULL,\n\t0x0104010805020901ULL, 0x4f214f426e9e0d4fULL, 0x36d836adee6c9b36ULL,\n\t0xa6a2a6590451ffa6ULL, 0xd26fd2debdb90cd2ULL, 0xf5f3f5fb06f70ef5ULL,\n\t0x79f979ef80f29679ULL, 0x6fa16f5fcede306fULL, 0x917e91fcef3f6d91ULL,\n\t0x525552aa07a4f852ULL, 0x609d6027fdc04760ULL, 0xbccabc89766535bcULL,\n\t0x9b569baccd2b379bULL, 0x8e028e048c018a8eULL, 0xa3b6a371155bd2a3ULL,\n\t0x0c300c603c186c0cULL, 0x7bf17bff8af6847bULL, 0x35d435b5e16a8035ULL,\n\t0x1d741de8693af51dULL, 0xe0a7e05347ddb3e0ULL, 0xd77bd7f6acb321d7ULL,\n\t0xc22fc25eed999cc2ULL, 0x2eb82e6d965c432eULL, 0x4b314b627a96294bULL,\n\t0xfedffea321e15dfeULL, 0x5741578216aed557ULL, 0x155415a8412abd15ULL,\n\t0x77c1779fb6eee877ULL, 0x37dc37a5eb6e9237ULL, 0xe5b3e57b56d79ee5ULL,\n\t0x9f469f8cd923139fULL, 0xf0e7f0d317fd23f0ULL, 0x4a354a6a7f94204aULL,\n\t0xda4fda9e95a944daULL, 0x587d58fa25b0a258ULL, 0xc903c906ca8fcfc9ULL,\n\t0x29a429558d527c29ULL, 0x0a280a5022145a0aULL, 0xb1feb1e14f7f50b1ULL,\n\t0xa0baa0691a5dc9a0ULL, 0x6bb16b7fdad6146bULL, 0x852e855cab17d985ULL,\n\t0xbdcebd8173673cbdULL, 0x5d695dd234ba8f5dULL, 0x1040108050209010ULL,\n\t0xf4f7f4f303f507f4ULL, 0xcb0bcb16c08bddcbULL, 0x3ef83eedc67cd33eULL,\n\t0x05140528110a2d05ULL, 0x6781671fe6ce7867ULL, 0xe4b7e47353d597e4ULL,\n\t0x279c2725bb4e0227ULL, 0x4119413258827341ULL, 0x8b168b2c9d0ba78bULL,\n\t0xa7a6a7510153f6a7ULL, 0x7de97dcf94fab27dULL, 0x956e95dcfb374995ULL,\n\t0xd847d88e9fad56d8ULL, 0xfbcbfb8b30eb70fbULL, 0xee9fee2371c1cdeeULL,\n\t0x7ced7cc791f8bb7cULL, 0x66856617e3cc7166ULL, 0xdd53dda68ea77bddULL,\n\t0x175c17b84b2eaf17ULL, 0x47014702468e4547ULL, 0x9e429e84dc211a9eULL,\n\t0xca0fca1ec589d4caULL, 0x2db42d75995a582dULL, 0xbfc6bf9179632ebfULL,\n\t0x071c07381b0e3f07ULL, 0xad8ead012347acadULL, 0x5a755aea2fb4b05aULL,\n\t0x8336836cb51bef83ULL, 0x33cc3385ff66b633ULL, 0x6391633ff2c65c63ULL,\n\t0x020802100a041202ULL, 0xaa92aa39384993aaULL, 0x71d971afa8e2de71ULL,\n\t0xc807c80ecf8dc6c8ULL, 0x196419c87d32d119ULL, 0x4939497270923b49ULL,\n\t0xd943d9869aaf5fd9ULL, 0xf2eff2c31df931f2ULL, 0xe3abe34b48dba8e3ULL,\n\t0x5b715be22ab6b95bULL, 0x881a8834920dbc88ULL, 0x9a529aa4c8293e9aULL,\n\t0x2698262dbe4c0b26ULL, 0x32c8328dfa64bf32ULL, 0xb0fab0e94a7d59b0ULL,\n\t0xe983e91b6acff2e9ULL, 0x0f3c0f78331e770fULL, 0xd573d5e6a6b733d5ULL,\n\t0x803a8074ba1df480ULL, 0xbec2be997c6127beULL, 0xcd13cd26de87ebcdULL,\n\t0x34d034bde4688934ULL, 0x483d487a75903248ULL, 0xffdbffab24e354ffULL,\n\t0x7af57af78ff48d7aULL, 0x907a90f4ea3d6490ULL, 0x5f615fc23ebe9d5fULL,\n\t0x2080201da0403d20ULL, 0x68bd6867d5d00f68ULL, 0x1a681ad07234ca1aULL,\n\t0xae82ae192c41b7aeULL, 0xb4eab4c95e757db4ULL, 0x544d549a19a8ce54ULL,\n\t0x937693ece53b7f93ULL, 0x2288220daa442f22ULL, 0x648d6407e9c86364ULL,\n\t0xf1e3f1db12ff2af1ULL, 0x73d173bfa2e6cc73ULL, 0x124812905a248212ULL,\n\t0x401d403a5d807a40ULL, 0x0820084028104808ULL, 0xc32bc356e89b95c3ULL,\n\t0xec97ec337bc5dfecULL, 0xdb4bdb9690ab4ddbULL, 0xa1bea1611f5fc0a1ULL,\n\t0x8d0e8d1c8307918dULL, 0x3df43df5c97ac83dULL, 0x976697ccf1335b97ULL,\n\t0x0000000000000000ULL, 0xcf1bcf36d483f9cfULL, 0x2bac2b4587566e2bULL,\n\t0x76c57697b3ece176ULL, 0x82328264b019e682ULL, 0xd67fd6fea9b128d6ULL,\n\t0x1b6c1bd87736c31bULL, 0xb5eeb5c15b7774b5ULL, 0xaf86af112943beafULL,\n\t0x6ab56a77dfd41d6aULL, 0x505d50ba0da0ea50ULL, 0x450945124c8a5745ULL,\n\t0xf3ebf3cb18fb38f3ULL, 0x30c0309df060ad30ULL, 0xef9bef2b74c3c4efULL,\n\t0x3ffc3fe5c37eda3fULL, 0x554955921caac755ULL, 0xa2b2a2791059dba2ULL,\n\t0xea8fea0365c9e9eaULL, 0x6589650fecca6a65ULL, 0xbad2bab9686903baULL,\n\t0x2fbc2f65935e4a2fULL, 0xc027c04ee79d8ec0ULL, 0xde5fdebe81a160deULL,\n\t0x1c701ce06c38fc1cULL, 0xfdd3fdbb2ee746fdULL, 0x4d294d52649a1f4dULL,\n\t0x927292e4e0397692ULL, 0x75c9758fbceafa75ULL, 0x061806301e0c3606ULL,\n\t0x8a128a249809ae8aULL, 0xb2f2b2f940794bb2ULL, 0xe6bfe66359d185e6ULL,\n\t0x0e380e70361c7e0eULL, 0x1f7c1ff8633ee71fULL, 0x62956237f7c45562ULL,\n\t0xd477d4eea3b53ad4ULL, 0xa89aa829324d81a8ULL, 0x966296c4f4315296ULL,\n\t0xf9c3f99b3aef62f9ULL, 0xc533c566f697a3c5ULL, 0x25942535b14a1025ULL,\n\t0x597959f220b2ab59ULL, 0x842a8454ae15d084ULL, 0x72d572b7a7e4c572ULL,\n\t0x39e439d5dd72ec39ULL, 0x4c2d4c5a6198164cULL, 0x5e655eca3bbc945eULL,\n\t0x78fd78e785f09f78ULL, 0x38e038ddd870e538ULL, 0x8c0a8c148605988cULL,\n\t0xd163d1c6b2bf17d1ULL, 0xa5aea5410b57e4a5ULL, 0xe2afe2434dd9a1e2ULL,\n\t0x6199612ff8c24e61ULL, 0xb3f6b3f1457b42b3ULL, 0x21842115a5423421ULL,\n\t0x9c4a9c94d625089cULL, 0x1e781ef0663cee1eULL, 0x4311432252866143ULL,\n\t0xc73bc776fc93b1c7ULL, 0xfcd7fcb32be54ffcULL, 0x0410042014082404ULL,\n\t0x515951b208a2e351ULL, 0x995e99bcc72f2599ULL, 0x6da96d4fc4da226dULL,\n\t0x0d340d68391a650dULL, 0xfacffa8335e979faULL, 0xdf5bdfb684a369dfULL,\n\t0x7ee57ed79bfca97eULL, 0x2490243db4481924ULL, 0x3bec3bc5d776fe3bULL,\n\t0xab96ab313d4b9aabULL, 0xce1fce3ed181f0ceULL, 0x1144118855229911ULL,\n\t0x8f068f0c8903838fULL, 0x4e254e4a6b9c044eULL, 0xb7e6b7d1517366b7ULL,\n\t0xeb8beb0b60cbe0ebULL, 0x3cf03cfdcc78c13cULL, 0x813e817cbf1ffd81ULL,\n\t0x946a94d4fe354094ULL, 0xf7fbf7eb0cf31cf7ULL, 0xb9deb9a1676f18b9ULL,\n\t0x134c13985f268b13ULL, 0x2cb02c7d9c58512cULL, 0xd36bd3d6b8bb05d3ULL,\n\t0xe7bbe76b5cd38ce7ULL, 0x6ea56e57cbdc396eULL, 0xc437c46ef395aac4ULL,\n\t0x030c03180f061b03ULL, 0x5645568a13acdc56ULL, 0x440d441a49885e44ULL,\n\t0x7fe17fdf9efea07fULL, 0xa99ea921374f88a9ULL, 0x2aa82a4d8254672aULL,\n\t0xbbd6bbb16d6b0abbULL, 0xc123c146e29f87c1ULL, 0x535153a202a6f153ULL,\n\t0xdc57dcae8ba572dcULL, 0x0b2c0b582716530bULL, 0x9d4e9d9cd327019dULL,\n\t0x6cad6c47c1d82b6cULL, 0x31c43195f562a431ULL, 0x74cd7487b9e8f374ULL,\n\t0xf6fff6e309f115f6ULL, 0x4605460a438c4c46ULL, 0xac8aac092645a5acULL,\n\t0x891e893c970fb589ULL, 0x145014a04428b414ULL, 0xe1a3e15b42dfbae1ULL,\n\t0x165816b04e2ca616ULL, 0x3ae83acdd274f73aULL, 0x69b9696fd0d20669ULL,\n\t0x092409482d124109ULL, 0x70dd70a7ade0d770ULL, 0xb6e2b6d954716fb6ULL,\n\t0xd067d0ceb7bd1ed0ULL, 0xed93ed3b7ec7d6edULL, 0xcc17cc2edb85e2ccULL,\n\t0x4215422a57846842ULL, 0x985a98b4c22d2c98ULL, 0xa4aaa4490e55eda4ULL,\n\t0x28a0285d88507528ULL, 0x5c6d5cda31b8865cULL, 0xf8c7f8933fed6bf8ULL,\n\t0x86228644a411c286ULL,\n};\n\nstatic const u64 rc[WHIRLPOOL_ROUNDS] = {\n\t0x1823c6e887b8014fULL,\n\t0x36a6d2f5796f9152ULL,\n\t0x60bc9b8ea30c7b35ULL,\n\t0x1de0d7c22e4bfe57ULL,\n\t0x157737e59ff04adaULL,\n\t0x58c9290ab1a06b85ULL,\n\t0xbd5d10f4cb3e0567ULL,\n\t0xe427418ba77d95d8ULL,\n\t0xfbee7c66dd17479eULL,\n\t0xca2dbf07ad5a8333ULL,\n};\n\n/**\n * The core Whirlpool transform.\n */\n\nstatic void wp512_process_buffer(struct wp512_ctx *wctx) {\n\tint i, r;\n\tu64 K[8];        /* the round key */\n\tu64 block[8];    /* mu(buffer) */\n\tu64 state[8];    /* the cipher state */\n\tu64 L[8];\n\tconst __be64 *buffer = (const __be64 *)wctx->buffer;\n\n\tfor (i = 0; i < 8; i++)\n\t\tblock[i] = be64_to_cpu(buffer[i]);\n\n\tstate[0] = block[0] ^ (K[0] = wctx->hash[0]);\n\tstate[1] = block[1] ^ (K[1] = wctx->hash[1]);\n\tstate[2] = block[2] ^ (K[2] = wctx->hash[2]);\n\tstate[3] = block[3] ^ (K[3] = wctx->hash[3]);\n\tstate[4] = block[4] ^ (K[4] = wctx->hash[4]);\n\tstate[5] = block[5] ^ (K[5] = wctx->hash[5]);\n\tstate[6] = block[6] ^ (K[6] = wctx->hash[6]);\n\tstate[7] = block[7] ^ (K[7] = wctx->hash[7]);\n\n\tfor (r = 0; r < WHIRLPOOL_ROUNDS; r++) {\n\n\t\tL[0] = C0[(int)(K[0] >> 56)       ] ^\n\t\t\t   C1[(int)(K[7] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(K[6] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(K[5] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(K[4] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(K[3] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(K[2] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(K[1]      ) & 0xff] ^\n\t\t\t   rc[r];\n\n\t\tL[1] = C0[(int)(K[1] >> 56)       ] ^\n\t\t\t   C1[(int)(K[0] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(K[7] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(K[6] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(K[5] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(K[4] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(K[3] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(K[2]      ) & 0xff];\n\n\t\tL[2] = C0[(int)(K[2] >> 56)       ] ^\n\t\t\t   C1[(int)(K[1] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(K[0] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(K[7] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(K[6] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(K[5] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(K[4] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(K[3]      ) & 0xff];\n\n\t\tL[3] = C0[(int)(K[3] >> 56)       ] ^\n\t\t\t   C1[(int)(K[2] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(K[1] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(K[0] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(K[7] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(K[6] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(K[5] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(K[4]      ) & 0xff];\n\n\t\tL[4] = C0[(int)(K[4] >> 56)       ] ^\n\t\t\t   C1[(int)(K[3] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(K[2] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(K[1] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(K[0] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(K[7] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(K[6] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(K[5]      ) & 0xff];\n\n\t\tL[5] = C0[(int)(K[5] >> 56)       ] ^\n\t\t\t   C1[(int)(K[4] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(K[3] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(K[2] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(K[1] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(K[0] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(K[7] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(K[6]      ) & 0xff];\n\n\t\tL[6] = C0[(int)(K[6] >> 56)       ] ^\n\t\t\t   C1[(int)(K[5] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(K[4] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(K[3] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(K[2] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(K[1] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(K[0] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(K[7]      ) & 0xff];\n\n\t\tL[7] = C0[(int)(K[7] >> 56)       ] ^\n\t\t\t   C1[(int)(K[6] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(K[5] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(K[4] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(K[3] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(K[2] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(K[1] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(K[0]      ) & 0xff];\n\n\t\tK[0] = L[0];\n\t\tK[1] = L[1];\n\t\tK[2] = L[2];\n\t\tK[3] = L[3];\n\t\tK[4] = L[4];\n\t\tK[5] = L[5];\n\t\tK[6] = L[6];\n\t\tK[7] = L[7];\n\n\t\tL[0] = C0[(int)(state[0] >> 56)       ] ^\n\t\t\t   C1[(int)(state[7] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(state[6] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(state[5] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(state[4] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(state[3] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(state[2] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(state[1]      ) & 0xff] ^\n\t\t\t   K[0];\n\n\t\tL[1] = C0[(int)(state[1] >> 56)       ] ^\n\t\t\t   C1[(int)(state[0] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(state[7] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(state[6] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(state[5] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(state[4] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(state[3] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(state[2]      ) & 0xff] ^\n\t\t\t   K[1];\n\n\t\tL[2] = C0[(int)(state[2] >> 56)       ] ^\n\t\t\t   C1[(int)(state[1] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(state[0] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(state[7] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(state[6] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(state[5] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(state[4] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(state[3]      ) & 0xff] ^\n\t\t\t   K[2];\n\n\t\tL[3] = C0[(int)(state[3] >> 56)       ] ^\n\t\t\t   C1[(int)(state[2] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(state[1] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(state[0] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(state[7] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(state[6] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(state[5] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(state[4]      ) & 0xff] ^\n\t\t\t   K[3];\n\n\t\tL[4] = C0[(int)(state[4] >> 56)       ] ^\n\t\t\t   C1[(int)(state[3] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(state[2] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(state[1] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(state[0] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(state[7] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(state[6] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(state[5]      ) & 0xff] ^\n\t\t\t   K[4];\n\n\t\tL[5] = C0[(int)(state[5] >> 56)       ] ^\n\t\t\t   C1[(int)(state[4] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(state[3] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(state[2] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(state[1] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(state[0] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(state[7] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(state[6]      ) & 0xff] ^\n\t\t\t   K[5];\n\n\t\tL[6] = C0[(int)(state[6] >> 56)       ] ^\n\t\t\t   C1[(int)(state[5] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(state[4] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(state[3] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(state[2] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(state[1] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(state[0] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(state[7]      ) & 0xff] ^\n\t\t\t   K[6];\n\n\t\tL[7] = C0[(int)(state[7] >> 56)       ] ^\n\t\t\t   C1[(int)(state[6] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(state[5] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(state[4] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(state[3] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(state[2] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(state[1] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(state[0]      ) & 0xff] ^\n\t\t\t   K[7];\n\n\t\tstate[0] = L[0];\n\t\tstate[1] = L[1];\n\t\tstate[2] = L[2];\n\t\tstate[3] = L[3];\n\t\tstate[4] = L[4];\n\t\tstate[5] = L[5];\n\t\tstate[6] = L[6];\n\t\tstate[7] = L[7];\n\t}\n\t/*\n\t* apply the Miyaguchi-Preneel compression function:\n\t*/\n\twctx->hash[0] ^= state[0] ^ block[0];\n\twctx->hash[1] ^= state[1] ^ block[1];\n\twctx->hash[2] ^= state[2] ^ block[2];\n\twctx->hash[3] ^= state[3] ^ block[3];\n\twctx->hash[4] ^= state[4] ^ block[4];\n\twctx->hash[5] ^= state[5] ^ block[5];\n\twctx->hash[6] ^= state[6] ^ block[6];\n\twctx->hash[7] ^= state[7] ^ block[7];\n\n}\n\nstatic int wp512_init(struct shash_desc *desc) {\n\tstruct wp512_ctx *wctx = shash_desc_ctx(desc);\n\tint i;\n\n\tmemset(wctx->bitLength, 0, 32);\n\twctx->bufferBits = wctx->bufferPos = 0;\n\twctx->buffer[0] = 0;\n\tfor (i = 0; i < 8; i++) {\n\t\twctx->hash[i] = 0L;\n\t}\n\n\treturn 0;\n}\n\nstatic int wp512_update(struct shash_desc *desc, const u8 *source,\n\t\t\t unsigned int len)\n{\n\tstruct wp512_ctx *wctx = shash_desc_ctx(desc);\n\tint sourcePos    = 0;\n\tunsigned int bits_len = len * 8; // convert to number of bits\n\tint sourceGap    = (8 - ((int)bits_len & 7)) & 7;\n\tint bufferRem    = wctx->bufferBits & 7;\n\tint i;\n\tu32 b, carry;\n\tu8 *buffer       = wctx->buffer;\n\tu8 *bitLength    = wctx->bitLength;\n\tint bufferBits   = wctx->bufferBits;\n\tint bufferPos    = wctx->bufferPos;\n\n\tu64 value = bits_len;\n\tfor (i = 31, carry = 0; i >= 0 && (carry != 0 || value != 0ULL); i--) {\n\t\tcarry += bitLength[i] + ((u32)value & 0xff);\n\t\tbitLength[i] = (u8)carry;\n\t\tcarry >>= 8;\n\t\tvalue >>= 8;\n\t}\n\twhile (bits_len > 8) {\n\t\tb = ((source[sourcePos] << sourceGap) & 0xff) |\n\t\t((source[sourcePos + 1] & 0xff) >> (8 - sourceGap));\n\t\tbuffer[bufferPos++] |= (u8)(b >> bufferRem);\n\t\tbufferBits += 8 - bufferRem;\n\t\tif (bufferBits == WP512_BLOCK_SIZE * 8) {\n\t\t\twp512_process_buffer(wctx);\n\t\t\tbufferBits = bufferPos = 0;\n\t\t}\n\t\tbuffer[bufferPos] = b << (8 - bufferRem);\n\t\tbufferBits += bufferRem;\n\t\tbits_len -= 8;\n\t\tsourcePos++;\n\t}\n\tif (bits_len > 0) {\n\t\tb = (source[sourcePos] << sourceGap) & 0xff;\n\t\tbuffer[bufferPos] |= b >> bufferRem;\n\t} else {\n\t\tb = 0;\n\t}\n\tif (bufferRem + bits_len < 8) {\n\t\tbufferBits += bits_len;\n\t} else {\n\t\tbufferPos++;\n\t\tbufferBits += 8 - bufferRem;\n\t\tbits_len -= 8 - bufferRem;\n\t\tif (bufferBits == WP512_BLOCK_SIZE * 8) {\n\t\t\twp512_process_buffer(wctx);\n\t\t\tbufferBits = bufferPos = 0;\n\t\t}\n\t\tbuffer[bufferPos] = b << (8 - bufferRem);\n\t\tbufferBits += (int)bits_len;\n\t}\n\n\twctx->bufferBits   = bufferBits;\n\twctx->bufferPos    = bufferPos;\n\n\treturn 0;\n}\n\nstatic int wp512_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct wp512_ctx *wctx = shash_desc_ctx(desc);\n\tint i;\n   \tu8 *buffer      = wctx->buffer;\n   \tu8 *bitLength   = wctx->bitLength;\n   \tint bufferBits  = wctx->bufferBits;\n   \tint bufferPos   = wctx->bufferPos;\n\t__be64 *digest  = (__be64 *)out;\n\n   \tbuffer[bufferPos] |= 0x80U >> (bufferBits & 7);\n   \tbufferPos++;\n   \tif (bufferPos > WP512_BLOCK_SIZE - WP512_LENGTHBYTES) {\n   \t\tif (bufferPos < WP512_BLOCK_SIZE) {\n\t   \tmemset(&buffer[bufferPos], 0, WP512_BLOCK_SIZE - bufferPos);\n   \t\t}\n   \t\twp512_process_buffer(wctx);\n   \t\tbufferPos = 0;\n   \t}\n   \tif (bufferPos < WP512_BLOCK_SIZE - WP512_LENGTHBYTES) {\n   \t\tmemset(&buffer[bufferPos], 0,\n\t\t\t  (WP512_BLOCK_SIZE - WP512_LENGTHBYTES) - bufferPos);\n   \t}\n   \tbufferPos = WP512_BLOCK_SIZE - WP512_LENGTHBYTES;\n   \tmemcpy(&buffer[WP512_BLOCK_SIZE - WP512_LENGTHBYTES],\n\t\t   bitLength, WP512_LENGTHBYTES);\n   \twp512_process_buffer(wctx);\n\tfor (i = 0; i < WP512_DIGEST_SIZE/8; i++)\n\t\tdigest[i] = cpu_to_be64(wctx->hash[i]);\n   \twctx->bufferBits   = bufferBits;\n   \twctx->bufferPos    = bufferPos;\n\n\treturn 0;\n}\n\nstatic int wp384_final(struct shash_desc *desc, u8 *out)\n{\n\tu8 D[64];\n\n\twp512_final(desc, D);\n\tmemcpy(out, D, WP384_DIGEST_SIZE);\n\tmemzero_explicit(D, WP512_DIGEST_SIZE);\n\n\treturn 0;\n}\n\nstatic int wp256_final(struct shash_desc *desc, u8 *out)\n{\n\tu8 D[64];\n\n\twp512_final(desc, D);\n\tmemcpy(out, D, WP256_DIGEST_SIZE);\n\tmemzero_explicit(D, WP512_DIGEST_SIZE);\n\n\treturn 0;\n}\n\nstatic struct shash_alg wp_algs[3] = { {\n\t.digestsize\t=\tWP512_DIGEST_SIZE,\n\t.init\t\t=\twp512_init,\n\t.update\t\t=\twp512_update,\n\t.final\t\t=\twp512_final,\n\t.descsize\t=\tsizeof(struct wp512_ctx),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"wp512\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tWP512_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n}, {\n\t.digestsize\t=\tWP384_DIGEST_SIZE,\n\t.init\t\t=\twp512_init,\n\t.update\t\t=\twp512_update,\n\t.final\t\t=\twp384_final,\n\t.descsize\t=\tsizeof(struct wp512_ctx),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"wp384\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tWP512_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n}, {\n\t.digestsize\t=\tWP256_DIGEST_SIZE,\n\t.init\t\t=\twp512_init,\n\t.update\t\t=\twp512_update,\n\t.final\t\t=\twp256_final,\n\t.descsize\t=\tsizeof(struct wp512_ctx),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"wp256\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tWP512_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n} };\n\nstatic int __init wp512_mod_init(void)\n{\n\treturn crypto_register_shashes(wp_algs, ARRAY_SIZE(wp_algs));\n}\n\nstatic void __exit wp512_mod_fini(void)\n{\n\tcrypto_unregister_shashes(wp_algs, ARRAY_SIZE(wp_algs));\n}\n\nMODULE_ALIAS(\"wp384\");\nMODULE_ALIAS(\"wp256\");\n\nmodule_init(wp512_mod_init);\nmodule_exit(wp512_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Whirlpool Message Digest Algorithm\");\n", "/*\n * Cryptographic API.\n *\n * Zlib algorithm\n *\n * Copyright 2008 Sony Corporation\n *\n * Based on deflate.c, which is\n * Copyright (c) 2003 James Morris <jmorris@intercode.com.au>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n * FIXME: deflate transforms will require up to a total of about 436k of kernel\n * memory on i386 (390k for compression, the rest for decompression), as the\n * current zlib kernel code uses a worst case pre-allocation system by default.\n * This needs to be fixed so that the amount of memory required is properly\n * related to the winbits and memlevel parameters.\n */\n\n#define pr_fmt(fmt)\t\"%s: \" fmt, __func__\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/zlib.h>\n#include <linux/vmalloc.h>\n#include <linux/interrupt.h>\n#include <linux/mm.h>\n#include <linux/net.h>\n\n#include <crypto/internal/compress.h>\n\n#include <net/netlink.h>\n\n\nstruct zlib_ctx {\n\tstruct z_stream_s comp_stream;\n\tstruct z_stream_s decomp_stream;\n\tint decomp_windowBits;\n};\n\n\nstatic void zlib_comp_exit(struct zlib_ctx *ctx)\n{\n\tstruct z_stream_s *stream = &ctx->comp_stream;\n\n\tif (stream->workspace) {\n\t\tzlib_deflateEnd(stream);\n\t\tvfree(stream->workspace);\n\t\tstream->workspace = NULL;\n\t}\n}\n\nstatic void zlib_decomp_exit(struct zlib_ctx *ctx)\n{\n\tstruct z_stream_s *stream = &ctx->decomp_stream;\n\n\tif (stream->workspace) {\n\t\tzlib_inflateEnd(stream);\n\t\tvfree(stream->workspace);\n\t\tstream->workspace = NULL;\n\t}\n}\n\nstatic int zlib_init(struct crypto_tfm *tfm)\n{\n\treturn 0;\n}\n\nstatic void zlib_exit(struct crypto_tfm *tfm)\n{\n\tstruct zlib_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tzlib_comp_exit(ctx);\n\tzlib_decomp_exit(ctx);\n}\n\n\nstatic int zlib_compress_setup(struct crypto_pcomp *tfm, void *params,\n\t\t\t       unsigned int len)\n{\n\tstruct zlib_ctx *ctx = crypto_tfm_ctx(crypto_pcomp_tfm(tfm));\n\tstruct z_stream_s *stream = &ctx->comp_stream;\n\tstruct nlattr *tb[ZLIB_COMP_MAX + 1];\n\tint window_bits, mem_level;\n\tsize_t workspacesize;\n\tint ret;\n\n\tret = nla_parse(tb, ZLIB_COMP_MAX, params, len, NULL);\n\tif (ret)\n\t\treturn ret;\n\n\tzlib_comp_exit(ctx);\n\n\twindow_bits = tb[ZLIB_COMP_WINDOWBITS]\n\t\t\t\t\t? nla_get_u32(tb[ZLIB_COMP_WINDOWBITS])\n\t\t\t\t\t: MAX_WBITS;\n\tmem_level = tb[ZLIB_COMP_MEMLEVEL]\n\t\t\t\t\t? nla_get_u32(tb[ZLIB_COMP_MEMLEVEL])\n\t\t\t\t\t: DEF_MEM_LEVEL;\n\n\tworkspacesize = zlib_deflate_workspacesize(window_bits, mem_level);\n\tstream->workspace = vzalloc(workspacesize);\n\tif (!stream->workspace)\n\t\treturn -ENOMEM;\n\n\tret = zlib_deflateInit2(stream,\n\t\t\t\ttb[ZLIB_COMP_LEVEL]\n\t\t\t\t\t? nla_get_u32(tb[ZLIB_COMP_LEVEL])\n\t\t\t\t\t: Z_DEFAULT_COMPRESSION,\n\t\t\t\ttb[ZLIB_COMP_METHOD]\n\t\t\t\t\t? nla_get_u32(tb[ZLIB_COMP_METHOD])\n\t\t\t\t\t: Z_DEFLATED,\n\t\t\t\twindow_bits,\n\t\t\t\tmem_level,\n\t\t\t\ttb[ZLIB_COMP_STRATEGY]\n\t\t\t\t\t? nla_get_u32(tb[ZLIB_COMP_STRATEGY])\n\t\t\t\t\t: Z_DEFAULT_STRATEGY);\n\tif (ret != Z_OK) {\n\t\tvfree(stream->workspace);\n\t\tstream->workspace = NULL;\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int zlib_compress_init(struct crypto_pcomp *tfm)\n{\n\tint ret;\n\tstruct zlib_ctx *dctx = crypto_tfm_ctx(crypto_pcomp_tfm(tfm));\n\tstruct z_stream_s *stream = &dctx->comp_stream;\n\n\tret = zlib_deflateReset(stream);\n\tif (ret != Z_OK)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int zlib_compress_update(struct crypto_pcomp *tfm,\n\t\t\t\tstruct comp_request *req)\n{\n\tint ret;\n\tstruct zlib_ctx *dctx = crypto_tfm_ctx(crypto_pcomp_tfm(tfm));\n\tstruct z_stream_s *stream = &dctx->comp_stream;\n\n\tpr_debug(\"avail_in %u, avail_out %u\\n\", req->avail_in, req->avail_out);\n\tstream->next_in = req->next_in;\n\tstream->avail_in = req->avail_in;\n\tstream->next_out = req->next_out;\n\tstream->avail_out = req->avail_out;\n\n\tret = zlib_deflate(stream, Z_NO_FLUSH);\n\tswitch (ret) {\n\tcase Z_OK:\n\t\tbreak;\n\n\tcase Z_BUF_ERROR:\n\t\tpr_debug(\"zlib_deflate could not make progress\\n\");\n\t\treturn -EAGAIN;\n\n\tdefault:\n\t\tpr_debug(\"zlib_deflate failed %d\\n\", ret);\n\t\treturn -EINVAL;\n\t}\n\n\tret = req->avail_out - stream->avail_out;\n\tpr_debug(\"avail_in %lu, avail_out %lu (consumed %lu, produced %u)\\n\",\n\t\t stream->avail_in, stream->avail_out,\n\t\t req->avail_in - stream->avail_in, ret);\n\treq->next_in = stream->next_in;\n\treq->avail_in = stream->avail_in;\n\treq->next_out = stream->next_out;\n\treq->avail_out = stream->avail_out;\n\treturn ret;\n}\n\nstatic int zlib_compress_final(struct crypto_pcomp *tfm,\n\t\t\t       struct comp_request *req)\n{\n\tint ret;\n\tstruct zlib_ctx *dctx = crypto_tfm_ctx(crypto_pcomp_tfm(tfm));\n\tstruct z_stream_s *stream = &dctx->comp_stream;\n\n\tpr_debug(\"avail_in %u, avail_out %u\\n\", req->avail_in, req->avail_out);\n\tstream->next_in = req->next_in;\n\tstream->avail_in = req->avail_in;\n\tstream->next_out = req->next_out;\n\tstream->avail_out = req->avail_out;\n\n\tret = zlib_deflate(stream, Z_FINISH);\n\tif (ret != Z_STREAM_END) {\n\t\tpr_debug(\"zlib_deflate failed %d\\n\", ret);\n\t\treturn -EINVAL;\n\t}\n\n\tret = req->avail_out - stream->avail_out;\n\tpr_debug(\"avail_in %lu, avail_out %lu (consumed %lu, produced %u)\\n\",\n\t\t stream->avail_in, stream->avail_out,\n\t\t req->avail_in - stream->avail_in, ret);\n\treq->next_in = stream->next_in;\n\treq->avail_in = stream->avail_in;\n\treq->next_out = stream->next_out;\n\treq->avail_out = stream->avail_out;\n\treturn ret;\n}\n\n\nstatic int zlib_decompress_setup(struct crypto_pcomp *tfm, void *params,\n\t\t\t\t unsigned int len)\n{\n\tstruct zlib_ctx *ctx = crypto_tfm_ctx(crypto_pcomp_tfm(tfm));\n\tstruct z_stream_s *stream = &ctx->decomp_stream;\n\tstruct nlattr *tb[ZLIB_DECOMP_MAX + 1];\n\tint ret = 0;\n\n\tret = nla_parse(tb, ZLIB_DECOMP_MAX, params, len, NULL);\n\tif (ret)\n\t\treturn ret;\n\n\tzlib_decomp_exit(ctx);\n\n\tctx->decomp_windowBits = tb[ZLIB_DECOMP_WINDOWBITS]\n\t\t\t\t ? nla_get_u32(tb[ZLIB_DECOMP_WINDOWBITS])\n\t\t\t\t : DEF_WBITS;\n\n\tstream->workspace = vzalloc(zlib_inflate_workspacesize());\n\tif (!stream->workspace)\n\t\treturn -ENOMEM;\n\n\tret = zlib_inflateInit2(stream, ctx->decomp_windowBits);\n\tif (ret != Z_OK) {\n\t\tvfree(stream->workspace);\n\t\tstream->workspace = NULL;\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int zlib_decompress_init(struct crypto_pcomp *tfm)\n{\n\tint ret;\n\tstruct zlib_ctx *dctx = crypto_tfm_ctx(crypto_pcomp_tfm(tfm));\n\tstruct z_stream_s *stream = &dctx->decomp_stream;\n\n\tret = zlib_inflateReset(stream);\n\tif (ret != Z_OK)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int zlib_decompress_update(struct crypto_pcomp *tfm,\n\t\t\t\t  struct comp_request *req)\n{\n\tint ret;\n\tstruct zlib_ctx *dctx = crypto_tfm_ctx(crypto_pcomp_tfm(tfm));\n\tstruct z_stream_s *stream = &dctx->decomp_stream;\n\n\tpr_debug(\"avail_in %u, avail_out %u\\n\", req->avail_in, req->avail_out);\n\tstream->next_in = req->next_in;\n\tstream->avail_in = req->avail_in;\n\tstream->next_out = req->next_out;\n\tstream->avail_out = req->avail_out;\n\n\tret = zlib_inflate(stream, Z_SYNC_FLUSH);\n\tswitch (ret) {\n\tcase Z_OK:\n\tcase Z_STREAM_END:\n\t\tbreak;\n\n\tcase Z_BUF_ERROR:\n\t\tpr_debug(\"zlib_inflate could not make progress\\n\");\n\t\treturn -EAGAIN;\n\n\tdefault:\n\t\tpr_debug(\"zlib_inflate failed %d\\n\", ret);\n\t\treturn -EINVAL;\n\t}\n\n\tret = req->avail_out - stream->avail_out;\n\tpr_debug(\"avail_in %lu, avail_out %lu (consumed %lu, produced %u)\\n\",\n\t\t stream->avail_in, stream->avail_out,\n\t\t req->avail_in - stream->avail_in, ret);\n\treq->next_in = stream->next_in;\n\treq->avail_in = stream->avail_in;\n\treq->next_out = stream->next_out;\n\treq->avail_out = stream->avail_out;\n\treturn ret;\n}\n\nstatic int zlib_decompress_final(struct crypto_pcomp *tfm,\n\t\t\t\t struct comp_request *req)\n{\n\tint ret;\n\tstruct zlib_ctx *dctx = crypto_tfm_ctx(crypto_pcomp_tfm(tfm));\n\tstruct z_stream_s *stream = &dctx->decomp_stream;\n\n\tpr_debug(\"avail_in %u, avail_out %u\\n\", req->avail_in, req->avail_out);\n\tstream->next_in = req->next_in;\n\tstream->avail_in = req->avail_in;\n\tstream->next_out = req->next_out;\n\tstream->avail_out = req->avail_out;\n\n\tif (dctx->decomp_windowBits < 0) {\n\t\tret = zlib_inflate(stream, Z_SYNC_FLUSH);\n\t\t/*\n\t\t * Work around a bug in zlib, which sometimes wants to taste an\n\t\t * extra byte when being used in the (undocumented) raw deflate\n\t\t * mode. (From USAGI).\n\t\t */\n\t\tif (ret == Z_OK && !stream->avail_in && stream->avail_out) {\n\t\t\tconst void *saved_next_in = stream->next_in;\n\t\t\tu8 zerostuff = 0;\n\n\t\t\tstream->next_in = &zerostuff;\n\t\t\tstream->avail_in = 1;\n\t\t\tret = zlib_inflate(stream, Z_FINISH);\n\t\t\tstream->next_in = saved_next_in;\n\t\t\tstream->avail_in = 0;\n\t\t}\n\t} else\n\t\tret = zlib_inflate(stream, Z_FINISH);\n\tif (ret != Z_STREAM_END) {\n\t\tpr_debug(\"zlib_inflate failed %d\\n\", ret);\n\t\treturn -EINVAL;\n\t}\n\n\tret = req->avail_out - stream->avail_out;\n\tpr_debug(\"avail_in %lu, avail_out %lu (consumed %lu, produced %u)\\n\",\n\t\t stream->avail_in, stream->avail_out,\n\t\t req->avail_in - stream->avail_in, ret);\n\treq->next_in = stream->next_in;\n\treq->avail_in = stream->avail_in;\n\treq->next_out = stream->next_out;\n\treq->avail_out = stream->avail_out;\n\treturn ret;\n}\n\n\nstatic struct pcomp_alg zlib_alg = {\n\t.compress_setup\t\t= zlib_compress_setup,\n\t.compress_init\t\t= zlib_compress_init,\n\t.compress_update\t= zlib_compress_update,\n\t.compress_final\t\t= zlib_compress_final,\n\t.decompress_setup\t= zlib_decompress_setup,\n\t.decompress_init\t= zlib_decompress_init,\n\t.decompress_update\t= zlib_decompress_update,\n\t.decompress_final\t= zlib_decompress_final,\n\n\t.base\t\t\t= {\n\t\t.cra_name\t= \"zlib\",\n\t\t.cra_flags\t= CRYPTO_ALG_TYPE_PCOMPRESS,\n\t\t.cra_ctxsize\t= sizeof(struct zlib_ctx),\n\t\t.cra_module\t= THIS_MODULE,\n\t\t.cra_init\t= zlib_init,\n\t\t.cra_exit\t= zlib_exit,\n\t}\n};\n\nstatic int __init zlib_mod_init(void)\n{\n\treturn crypto_register_pcomp(&zlib_alg);\n}\n\nstatic void __exit zlib_mod_fini(void)\n{\n\tcrypto_unregister_pcomp(&zlib_alg);\n}\n\nmodule_init(zlib_mod_init);\nmodule_exit(zlib_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Zlib Compression Algorithm\");\nMODULE_AUTHOR(\"Sony Corporation\");\n", "/* \n * Cryptographic API.\n *\n * Support for VIA PadLock hardware crypto engine.\n *\n * Copyright (c) 2004  Michal Ludvig <michal@logix.cz>\n *\n */\n\n#include <crypto/algapi.h>\n#include <crypto/aes.h>\n#include <crypto/padlock.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/types.h>\n#include <linux/errno.h>\n#include <linux/interrupt.h>\n#include <linux/kernel.h>\n#include <linux/percpu.h>\n#include <linux/smp.h>\n#include <linux/slab.h>\n#include <asm/cpu_device_id.h>\n#include <asm/byteorder.h>\n#include <asm/processor.h>\n#include <asm/i387.h>\n\n/*\n * Number of data blocks actually fetched for each xcrypt insn.\n * Processors with prefetch errata will fetch extra blocks.\n */\nstatic unsigned int ecb_fetch_blocks = 2;\n#define MAX_ECB_FETCH_BLOCKS (8)\n#define ecb_fetch_bytes (ecb_fetch_blocks * AES_BLOCK_SIZE)\n\nstatic unsigned int cbc_fetch_blocks = 1;\n#define MAX_CBC_FETCH_BLOCKS (4)\n#define cbc_fetch_bytes (cbc_fetch_blocks * AES_BLOCK_SIZE)\n\n/* Control word. */\nstruct cword {\n\tunsigned int __attribute__ ((__packed__))\n\t\trounds:4,\n\t\talgo:3,\n\t\tkeygen:1,\n\t\tinterm:1,\n\t\tencdec:1,\n\t\tksize:2;\n} __attribute__ ((__aligned__(PADLOCK_ALIGNMENT)));\n\n/* Whenever making any changes to the following\n * structure *make sure* you keep E, d_data\n * and cword aligned on 16 Bytes boundaries and\n * the Hardware can access 16 * 16 bytes of E and d_data\n * (only the first 15 * 16 bytes matter but the HW reads\n * more).\n */\nstruct aes_ctx {\n\tu32 E[AES_MAX_KEYLENGTH_U32]\n\t\t__attribute__ ((__aligned__(PADLOCK_ALIGNMENT)));\n\tu32 d_data[AES_MAX_KEYLENGTH_U32]\n\t\t__attribute__ ((__aligned__(PADLOCK_ALIGNMENT)));\n\tstruct {\n\t\tstruct cword encrypt;\n\t\tstruct cword decrypt;\n\t} cword;\n\tu32 *D;\n};\n\nstatic DEFINE_PER_CPU(struct cword *, paes_last_cword);\n\n/* Tells whether the ACE is capable to generate\n   the extended key for a given key_len. */\nstatic inline int\naes_hw_extkey_available(uint8_t key_len)\n{\n\t/* TODO: We should check the actual CPU model/stepping\n\t         as it's possible that the capability will be\n\t         added in the next CPU revisions. */\n\tif (key_len == 16)\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic inline struct aes_ctx *aes_ctx_common(void *ctx)\n{\n\tunsigned long addr = (unsigned long)ctx;\n\tunsigned long align = PADLOCK_ALIGNMENT;\n\n\tif (align <= crypto_tfm_ctx_alignment())\n\t\talign = 1;\n\treturn (struct aes_ctx *)ALIGN(addr, align);\n}\n\nstatic inline struct aes_ctx *aes_ctx(struct crypto_tfm *tfm)\n{\n\treturn aes_ctx_common(crypto_tfm_ctx(tfm));\n}\n\nstatic inline struct aes_ctx *blk_aes_ctx(struct crypto_blkcipher *tfm)\n{\n\treturn aes_ctx_common(crypto_blkcipher_ctx(tfm));\n}\n\nstatic int aes_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t       unsigned int key_len)\n{\n\tstruct aes_ctx *ctx = aes_ctx(tfm);\n\tconst __le32 *key = (const __le32 *)in_key;\n\tu32 *flags = &tfm->crt_flags;\n\tstruct crypto_aes_ctx gen_aes;\n\tint cpu;\n\n\tif (key_len % 8) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\t/*\n\t * If the hardware is capable of generating the extended key\n\t * itself we must supply the plain key for both encryption\n\t * and decryption.\n\t */\n\tctx->D = ctx->E;\n\n\tctx->E[0] = le32_to_cpu(key[0]);\n\tctx->E[1] = le32_to_cpu(key[1]);\n\tctx->E[2] = le32_to_cpu(key[2]);\n\tctx->E[3] = le32_to_cpu(key[3]);\n\n\t/* Prepare control words. */\n\tmemset(&ctx->cword, 0, sizeof(ctx->cword));\n\n\tctx->cword.decrypt.encdec = 1;\n\tctx->cword.encrypt.rounds = 10 + (key_len - 16) / 4;\n\tctx->cword.decrypt.rounds = ctx->cword.encrypt.rounds;\n\tctx->cword.encrypt.ksize = (key_len - 16) / 8;\n\tctx->cword.decrypt.ksize = ctx->cword.encrypt.ksize;\n\n\t/* Don't generate extended keys if the hardware can do it. */\n\tif (aes_hw_extkey_available(key_len))\n\t\tgoto ok;\n\n\tctx->D = ctx->d_data;\n\tctx->cword.encrypt.keygen = 1;\n\tctx->cword.decrypt.keygen = 1;\n\n\tif (crypto_aes_expand_key(&gen_aes, in_key, key_len)) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(ctx->E, gen_aes.key_enc, AES_MAX_KEYLENGTH);\n\tmemcpy(ctx->D, gen_aes.key_dec, AES_MAX_KEYLENGTH);\n\nok:\n\tfor_each_online_cpu(cpu)\n\t\tif (&ctx->cword.encrypt == per_cpu(paes_last_cword, cpu) ||\n\t\t    &ctx->cword.decrypt == per_cpu(paes_last_cword, cpu))\n\t\t\tper_cpu(paes_last_cword, cpu) = NULL;\n\n\treturn 0;\n}\n\n/* ====== Encryption/decryption routines ====== */\n\n/* These are the real call to PadLock. */\nstatic inline void padlock_reset_key(struct cword *cword)\n{\n\tint cpu = raw_smp_processor_id();\n\n\tif (cword != per_cpu(paes_last_cword, cpu))\n#ifndef CONFIG_X86_64\n\t\tasm volatile (\"pushfl; popfl\");\n#else\n\t\tasm volatile (\"pushfq; popfq\");\n#endif\n}\n\nstatic inline void padlock_store_cword(struct cword *cword)\n{\n\tper_cpu(paes_last_cword, raw_smp_processor_id()) = cword;\n}\n\n/*\n * While the padlock instructions don't use FP/SSE registers, they\n * generate a spurious DNA fault when cr0.ts is '1'. These instructions\n * should be used only inside the irq_ts_save/restore() context\n */\n\nstatic inline void rep_xcrypt_ecb(const u8 *input, u8 *output, void *key,\n\t\t\t\t  struct cword *control_word, int count)\n{\n\tasm volatile (\".byte 0xf3,0x0f,0xa7,0xc8\"\t/* rep xcryptecb */\n\t\t      : \"+S\"(input), \"+D\"(output)\n\t\t      : \"d\"(control_word), \"b\"(key), \"c\"(count));\n}\n\nstatic inline u8 *rep_xcrypt_cbc(const u8 *input, u8 *output, void *key,\n\t\t\t\t u8 *iv, struct cword *control_word, int count)\n{\n\tasm volatile (\".byte 0xf3,0x0f,0xa7,0xd0\"\t/* rep xcryptcbc */\n\t\t      : \"+S\" (input), \"+D\" (output), \"+a\" (iv)\n\t\t      : \"d\" (control_word), \"b\" (key), \"c\" (count));\n\treturn iv;\n}\n\nstatic void ecb_crypt_copy(const u8 *in, u8 *out, u32 *key,\n\t\t\t   struct cword *cword, int count)\n{\n\t/*\n\t * Padlock prefetches extra data so we must provide mapped input buffers.\n\t * Assume there are at least 16 bytes of stack already in use.\n\t */\n\tu8 buf[AES_BLOCK_SIZE * (MAX_ECB_FETCH_BLOCKS - 1) + PADLOCK_ALIGNMENT - 1];\n\tu8 *tmp = PTR_ALIGN(&buf[0], PADLOCK_ALIGNMENT);\n\n\tmemcpy(tmp, in, count * AES_BLOCK_SIZE);\n\trep_xcrypt_ecb(tmp, out, key, cword, count);\n}\n\nstatic u8 *cbc_crypt_copy(const u8 *in, u8 *out, u32 *key,\n\t\t\t   u8 *iv, struct cword *cword, int count)\n{\n\t/*\n\t * Padlock prefetches extra data so we must provide mapped input buffers.\n\t * Assume there are at least 16 bytes of stack already in use.\n\t */\n\tu8 buf[AES_BLOCK_SIZE * (MAX_CBC_FETCH_BLOCKS - 1) + PADLOCK_ALIGNMENT - 1];\n\tu8 *tmp = PTR_ALIGN(&buf[0], PADLOCK_ALIGNMENT);\n\n\tmemcpy(tmp, in, count * AES_BLOCK_SIZE);\n\treturn rep_xcrypt_cbc(tmp, out, key, iv, cword, count);\n}\n\nstatic inline void ecb_crypt(const u8 *in, u8 *out, u32 *key,\n\t\t\t     struct cword *cword, int count)\n{\n\t/* Padlock in ECB mode fetches at least ecb_fetch_bytes of data.\n\t * We could avoid some copying here but it's probably not worth it.\n\t */\n\tif (unlikely(((unsigned long)in & ~PAGE_MASK) + ecb_fetch_bytes > PAGE_SIZE)) {\n\t\tecb_crypt_copy(in, out, key, cword, count);\n\t\treturn;\n\t}\n\n\trep_xcrypt_ecb(in, out, key, cword, count);\n}\n\nstatic inline u8 *cbc_crypt(const u8 *in, u8 *out, u32 *key,\n\t\t\t    u8 *iv, struct cword *cword, int count)\n{\n\t/* Padlock in CBC mode fetches at least cbc_fetch_bytes of data. */\n\tif (unlikely(((unsigned long)in & ~PAGE_MASK) + cbc_fetch_bytes > PAGE_SIZE))\n\t\treturn cbc_crypt_copy(in, out, key, iv, cword, count);\n\n\treturn rep_xcrypt_cbc(in, out, key, iv, cword, count);\n}\n\nstatic inline void padlock_xcrypt_ecb(const u8 *input, u8 *output, void *key,\n\t\t\t\t      void *control_word, u32 count)\n{\n\tu32 initial = count & (ecb_fetch_blocks - 1);\n\n\tif (count < ecb_fetch_blocks) {\n\t\tecb_crypt(input, output, key, control_word, count);\n\t\treturn;\n\t}\n\n\tif (initial)\n\t\tasm volatile (\".byte 0xf3,0x0f,0xa7,0xc8\"\t/* rep xcryptecb */\n\t\t\t      : \"+S\"(input), \"+D\"(output)\n\t\t\t      : \"d\"(control_word), \"b\"(key), \"c\"(initial));\n\n\tasm volatile (\".byte 0xf3,0x0f,0xa7,0xc8\"\t/* rep xcryptecb */\n\t\t      : \"+S\"(input), \"+D\"(output)\n\t\t      : \"d\"(control_word), \"b\"(key), \"c\"(count - initial));\n}\n\nstatic inline u8 *padlock_xcrypt_cbc(const u8 *input, u8 *output, void *key,\n\t\t\t\t     u8 *iv, void *control_word, u32 count)\n{\n\tu32 initial = count & (cbc_fetch_blocks - 1);\n\n\tif (count < cbc_fetch_blocks)\n\t\treturn cbc_crypt(input, output, key, iv, control_word, count);\n\n\tif (initial)\n\t\tasm volatile (\".byte 0xf3,0x0f,0xa7,0xd0\"\t/* rep xcryptcbc */\n\t\t\t      : \"+S\" (input), \"+D\" (output), \"+a\" (iv)\n\t\t\t      : \"d\" (control_word), \"b\" (key), \"c\" (initial));\n\n\tasm volatile (\".byte 0xf3,0x0f,0xa7,0xd0\"\t/* rep xcryptcbc */\n\t\t      : \"+S\" (input), \"+D\" (output), \"+a\" (iv)\n\t\t      : \"d\" (control_word), \"b\" (key), \"c\" (count-initial));\n\treturn iv;\n}\n\nstatic void aes_encrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tstruct aes_ctx *ctx = aes_ctx(tfm);\n\tint ts_state;\n\n\tpadlock_reset_key(&ctx->cword.encrypt);\n\tts_state = irq_ts_save();\n\tecb_crypt(in, out, ctx->E, &ctx->cword.encrypt, 1);\n\tirq_ts_restore(ts_state);\n\tpadlock_store_cword(&ctx->cword.encrypt);\n}\n\nstatic void aes_decrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tstruct aes_ctx *ctx = aes_ctx(tfm);\n\tint ts_state;\n\n\tpadlock_reset_key(&ctx->cword.encrypt);\n\tts_state = irq_ts_save();\n\tecb_crypt(in, out, ctx->D, &ctx->cword.decrypt, 1);\n\tirq_ts_restore(ts_state);\n\tpadlock_store_cword(&ctx->cword.encrypt);\n}\n\nstatic struct crypto_alg aes_alg = {\n\t.cra_name\t\t=\t\"aes\",\n\t.cra_driver_name\t=\t\"aes-padlock\",\n\t.cra_priority\t\t=\tPADLOCK_CRA_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tAES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct aes_ctx),\n\t.cra_alignmask\t\t=\tPADLOCK_ALIGNMENT - 1,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.cipher = {\n\t\t\t.cia_min_keysize\t=\tAES_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t=\tAES_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t   \t= \taes_set_key,\n\t\t\t.cia_encrypt\t \t=\taes_encrypt,\n\t\t\t.cia_decrypt\t  \t=\taes_decrypt,\n\t\t}\n\t}\n};\n\nstatic int ecb_aes_encrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct aes_ctx *ctx = blk_aes_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tint err;\n\tint ts_state;\n\n\tpadlock_reset_key(&ctx->cword.encrypt);\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\tts_state = irq_ts_save();\n\twhile ((nbytes = walk.nbytes)) {\n\t\tpadlock_xcrypt_ecb(walk.src.virt.addr, walk.dst.virt.addr,\n\t\t\t\t   ctx->E, &ctx->cword.encrypt,\n\t\t\t\t   nbytes / AES_BLOCK_SIZE);\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tirq_ts_restore(ts_state);\n\n\tpadlock_store_cword(&ctx->cword.encrypt);\n\n\treturn err;\n}\n\nstatic int ecb_aes_decrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct aes_ctx *ctx = blk_aes_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tint err;\n\tint ts_state;\n\n\tpadlock_reset_key(&ctx->cword.decrypt);\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\tts_state = irq_ts_save();\n\twhile ((nbytes = walk.nbytes)) {\n\t\tpadlock_xcrypt_ecb(walk.src.virt.addr, walk.dst.virt.addr,\n\t\t\t\t   ctx->D, &ctx->cword.decrypt,\n\t\t\t\t   nbytes / AES_BLOCK_SIZE);\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tirq_ts_restore(ts_state);\n\n\tpadlock_store_cword(&ctx->cword.encrypt);\n\n\treturn err;\n}\n\nstatic struct crypto_alg ecb_aes_alg = {\n\t.cra_name\t\t=\t\"ecb(aes)\",\n\t.cra_driver_name\t=\t\"ecb-aes-padlock\",\n\t.cra_priority\t\t=\tPADLOCK_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t=\tAES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct aes_ctx),\n\t.cra_alignmask\t\t=\tPADLOCK_ALIGNMENT - 1,\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\tAES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\tAES_MAX_KEY_SIZE,\n\t\t\t.setkey\t   \t\t= \taes_set_key,\n\t\t\t.encrypt\t\t=\tecb_aes_encrypt,\n\t\t\t.decrypt\t\t=\tecb_aes_decrypt,\n\t\t}\n\t}\n};\n\nstatic int cbc_aes_encrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct aes_ctx *ctx = blk_aes_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tint err;\n\tint ts_state;\n\n\tpadlock_reset_key(&ctx->cword.encrypt);\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\tts_state = irq_ts_save();\n\twhile ((nbytes = walk.nbytes)) {\n\t\tu8 *iv = padlock_xcrypt_cbc(walk.src.virt.addr,\n\t\t\t\t\t    walk.dst.virt.addr, ctx->E,\n\t\t\t\t\t    walk.iv, &ctx->cword.encrypt,\n\t\t\t\t\t    nbytes / AES_BLOCK_SIZE);\n\t\tmemcpy(walk.iv, iv, AES_BLOCK_SIZE);\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tirq_ts_restore(ts_state);\n\n\tpadlock_store_cword(&ctx->cword.decrypt);\n\n\treturn err;\n}\n\nstatic int cbc_aes_decrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct aes_ctx *ctx = blk_aes_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tint err;\n\tint ts_state;\n\n\tpadlock_reset_key(&ctx->cword.encrypt);\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\tts_state = irq_ts_save();\n\twhile ((nbytes = walk.nbytes)) {\n\t\tpadlock_xcrypt_cbc(walk.src.virt.addr, walk.dst.virt.addr,\n\t\t\t\t   ctx->D, walk.iv, &ctx->cword.decrypt,\n\t\t\t\t   nbytes / AES_BLOCK_SIZE);\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\n\tirq_ts_restore(ts_state);\n\n\tpadlock_store_cword(&ctx->cword.encrypt);\n\n\treturn err;\n}\n\nstatic struct crypto_alg cbc_aes_alg = {\n\t.cra_name\t\t=\t\"cbc(aes)\",\n\t.cra_driver_name\t=\t\"cbc-aes-padlock\",\n\t.cra_priority\t\t=\tPADLOCK_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t=\tAES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct aes_ctx),\n\t.cra_alignmask\t\t=\tPADLOCK_ALIGNMENT - 1,\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\tAES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\tAES_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t\t=\tAES_BLOCK_SIZE,\n\t\t\t.setkey\t   \t\t= \taes_set_key,\n\t\t\t.encrypt\t\t=\tcbc_aes_encrypt,\n\t\t\t.decrypt\t\t=\tcbc_aes_decrypt,\n\t\t}\n\t}\n};\n\nstatic struct x86_cpu_id padlock_cpu_id[] = {\n\tX86_FEATURE_MATCH(X86_FEATURE_XCRYPT),\n\t{}\n};\nMODULE_DEVICE_TABLE(x86cpu, padlock_cpu_id);\n\nstatic int __init padlock_init(void)\n{\n\tint ret;\n\tstruct cpuinfo_x86 *c = &cpu_data(0);\n\n\tif (!x86_match_cpu(padlock_cpu_id))\n\t\treturn -ENODEV;\n\n\tif (!cpu_has_xcrypt_enabled) {\n\t\tprintk(KERN_NOTICE PFX \"VIA PadLock detected, but not enabled. Hmm, strange...\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif ((ret = crypto_register_alg(&aes_alg)))\n\t\tgoto aes_err;\n\n\tif ((ret = crypto_register_alg(&ecb_aes_alg)))\n\t\tgoto ecb_aes_err;\n\n\tif ((ret = crypto_register_alg(&cbc_aes_alg)))\n\t\tgoto cbc_aes_err;\n\n\tprintk(KERN_NOTICE PFX \"Using VIA PadLock ACE for AES algorithm.\\n\");\n\n\tif (c->x86 == 6 && c->x86_model == 15 && c->x86_mask == 2) {\n\t\tecb_fetch_blocks = MAX_ECB_FETCH_BLOCKS;\n\t\tcbc_fetch_blocks = MAX_CBC_FETCH_BLOCKS;\n\t\tprintk(KERN_NOTICE PFX \"VIA Nano stepping 2 detected: enabling workaround.\\n\");\n\t}\n\nout:\n\treturn ret;\n\ncbc_aes_err:\n\tcrypto_unregister_alg(&ecb_aes_alg);\necb_aes_err:\n\tcrypto_unregister_alg(&aes_alg);\naes_err:\n\tprintk(KERN_ERR PFX \"VIA PadLock AES initialization failed.\\n\");\n\tgoto out;\n}\n\nstatic void __exit padlock_fini(void)\n{\n\tcrypto_unregister_alg(&cbc_aes_alg);\n\tcrypto_unregister_alg(&ecb_aes_alg);\n\tcrypto_unregister_alg(&aes_alg);\n}\n\nmodule_init(padlock_init);\nmodule_exit(padlock_fini);\n\nMODULE_DESCRIPTION(\"VIA PadLock AES algorithm support\");\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Michal Ludvig\");\n\nMODULE_ALIAS(\"aes\");\n", "/*\n * Cryptographic API.\n *\n * Support for VIA PadLock hardware crypto engine.\n *\n * Copyright (c) 2006  Michal Ludvig <michal@logix.cz>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n\n#include <crypto/internal/hash.h>\n#include <crypto/padlock.h>\n#include <crypto/sha.h>\n#include <linux/err.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/errno.h>\n#include <linux/interrupt.h>\n#include <linux/kernel.h>\n#include <linux/scatterlist.h>\n#include <asm/cpu_device_id.h>\n#include <asm/i387.h>\n\nstruct padlock_sha_desc {\n\tstruct shash_desc fallback;\n};\n\nstruct padlock_sha_ctx {\n\tstruct crypto_shash *fallback;\n};\n\nstatic int padlock_sha_init(struct shash_desc *desc)\n{\n\tstruct padlock_sha_desc *dctx = shash_desc_ctx(desc);\n\tstruct padlock_sha_ctx *ctx = crypto_shash_ctx(desc->tfm);\n\n\tdctx->fallback.tfm = ctx->fallback;\n\tdctx->fallback.flags = desc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\treturn crypto_shash_init(&dctx->fallback);\n}\n\nstatic int padlock_sha_update(struct shash_desc *desc,\n\t\t\t      const u8 *data, unsigned int length)\n{\n\tstruct padlock_sha_desc *dctx = shash_desc_ctx(desc);\n\n\tdctx->fallback.flags = desc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\treturn crypto_shash_update(&dctx->fallback, data, length);\n}\n\nstatic int padlock_sha_export(struct shash_desc *desc, void *out)\n{\n\tstruct padlock_sha_desc *dctx = shash_desc_ctx(desc);\n\n\treturn crypto_shash_export(&dctx->fallback, out);\n}\n\nstatic int padlock_sha_import(struct shash_desc *desc, const void *in)\n{\n\tstruct padlock_sha_desc *dctx = shash_desc_ctx(desc);\n\tstruct padlock_sha_ctx *ctx = crypto_shash_ctx(desc->tfm);\n\n\tdctx->fallback.tfm = ctx->fallback;\n\tdctx->fallback.flags = desc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\treturn crypto_shash_import(&dctx->fallback, in);\n}\n\nstatic inline void padlock_output_block(uint32_t *src,\n\t\t \tuint32_t *dst, size_t count)\n{\n\twhile (count--)\n\t\t*dst++ = swab32(*src++);\n}\n\nstatic int padlock_sha1_finup(struct shash_desc *desc, const u8 *in,\n\t\t\t      unsigned int count, u8 *out)\n{\n\t/* We can't store directly to *out as it may be unaligned. */\n\t/* BTW Don't reduce the buffer size below 128 Bytes!\n\t *     PadLock microcode needs it that big. */\n\tchar buf[128 + PADLOCK_ALIGNMENT - STACK_ALIGN] __attribute__\n\t\t((aligned(STACK_ALIGN)));\n\tchar *result = PTR_ALIGN(&buf[0], PADLOCK_ALIGNMENT);\n\tstruct padlock_sha_desc *dctx = shash_desc_ctx(desc);\n\tstruct sha1_state state;\n\tunsigned int space;\n\tunsigned int leftover;\n\tint ts_state;\n\tint err;\n\n\tdctx->fallback.flags = desc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\terr = crypto_shash_export(&dctx->fallback, &state);\n\tif (err)\n\t\tgoto out;\n\n\tif (state.count + count > ULONG_MAX)\n\t\treturn crypto_shash_finup(&dctx->fallback, in, count, out);\n\n\tleftover = ((state.count - 1) & (SHA1_BLOCK_SIZE - 1)) + 1;\n\tspace =  SHA1_BLOCK_SIZE - leftover;\n\tif (space) {\n\t\tif (count > space) {\n\t\t\terr = crypto_shash_update(&dctx->fallback, in, space) ?:\n\t\t\t      crypto_shash_export(&dctx->fallback, &state);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\t\t\tcount -= space;\n\t\t\tin += space;\n\t\t} else {\n\t\t\tmemcpy(state.buffer + leftover, in, count);\n\t\t\tin = state.buffer;\n\t\t\tcount += leftover;\n\t\t\tstate.count &= ~(SHA1_BLOCK_SIZE - 1);\n\t\t}\n\t}\n\n\tmemcpy(result, &state.state, SHA1_DIGEST_SIZE);\n\n\t/* prevent taking the spurious DNA fault with padlock. */\n\tts_state = irq_ts_save();\n\tasm volatile (\".byte 0xf3,0x0f,0xa6,0xc8\" /* rep xsha1 */\n\t\t      : \\\n\t\t      : \"c\"((unsigned long)state.count + count), \\\n\t\t\t\"a\"((unsigned long)state.count), \\\n\t\t\t\"S\"(in), \"D\"(result));\n\tirq_ts_restore(ts_state);\n\n\tpadlock_output_block((uint32_t *)result, (uint32_t *)out, 5);\n\nout:\n\treturn err;\n}\n\nstatic int padlock_sha1_final(struct shash_desc *desc, u8 *out)\n{\n\tu8 buf[4];\n\n\treturn padlock_sha1_finup(desc, buf, 0, out);\n}\n\nstatic int padlock_sha256_finup(struct shash_desc *desc, const u8 *in,\n\t\t\t\tunsigned int count, u8 *out)\n{\n\t/* We can't store directly to *out as it may be unaligned. */\n\t/* BTW Don't reduce the buffer size below 128 Bytes!\n\t *     PadLock microcode needs it that big. */\n\tchar buf[128 + PADLOCK_ALIGNMENT - STACK_ALIGN] __attribute__\n\t\t((aligned(STACK_ALIGN)));\n\tchar *result = PTR_ALIGN(&buf[0], PADLOCK_ALIGNMENT);\n\tstruct padlock_sha_desc *dctx = shash_desc_ctx(desc);\n\tstruct sha256_state state;\n\tunsigned int space;\n\tunsigned int leftover;\n\tint ts_state;\n\tint err;\n\n\tdctx->fallback.flags = desc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\terr = crypto_shash_export(&dctx->fallback, &state);\n\tif (err)\n\t\tgoto out;\n\n\tif (state.count + count > ULONG_MAX)\n\t\treturn crypto_shash_finup(&dctx->fallback, in, count, out);\n\n\tleftover = ((state.count - 1) & (SHA256_BLOCK_SIZE - 1)) + 1;\n\tspace =  SHA256_BLOCK_SIZE - leftover;\n\tif (space) {\n\t\tif (count > space) {\n\t\t\terr = crypto_shash_update(&dctx->fallback, in, space) ?:\n\t\t\t      crypto_shash_export(&dctx->fallback, &state);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\t\t\tcount -= space;\n\t\t\tin += space;\n\t\t} else {\n\t\t\tmemcpy(state.buf + leftover, in, count);\n\t\t\tin = state.buf;\n\t\t\tcount += leftover;\n\t\t\tstate.count &= ~(SHA1_BLOCK_SIZE - 1);\n\t\t}\n\t}\n\n\tmemcpy(result, &state.state, SHA256_DIGEST_SIZE);\n\n\t/* prevent taking the spurious DNA fault with padlock. */\n\tts_state = irq_ts_save();\n\tasm volatile (\".byte 0xf3,0x0f,0xa6,0xd0\" /* rep xsha256 */\n\t\t      : \\\n\t\t      : \"c\"((unsigned long)state.count + count), \\\n\t\t\t\"a\"((unsigned long)state.count), \\\n\t\t\t\"S\"(in), \"D\"(result));\n\tirq_ts_restore(ts_state);\n\n\tpadlock_output_block((uint32_t *)result, (uint32_t *)out, 8);\n\nout:\n\treturn err;\n}\n\nstatic int padlock_sha256_final(struct shash_desc *desc, u8 *out)\n{\n\tu8 buf[4];\n\n\treturn padlock_sha256_finup(desc, buf, 0, out);\n}\n\nstatic int padlock_cra_init(struct crypto_tfm *tfm)\n{\n\tstruct crypto_shash *hash = __crypto_shash_cast(tfm);\n\tconst char *fallback_driver_name = crypto_tfm_alg_name(tfm);\n\tstruct padlock_sha_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_shash *fallback_tfm;\n\tint err = -ENOMEM;\n\n\t/* Allocate a fallback and abort if it failed. */\n\tfallback_tfm = crypto_alloc_shash(fallback_driver_name, 0,\n\t\t\t\t\t  CRYPTO_ALG_NEED_FALLBACK);\n\tif (IS_ERR(fallback_tfm)) {\n\t\tprintk(KERN_WARNING PFX \"Fallback driver '%s' could not be loaded!\\n\",\n\t\t       fallback_driver_name);\n\t\terr = PTR_ERR(fallback_tfm);\n\t\tgoto out;\n\t}\n\n\tctx->fallback = fallback_tfm;\n\thash->descsize += crypto_shash_descsize(fallback_tfm);\n\treturn 0;\n\nout:\n\treturn err;\n}\n\nstatic void padlock_cra_exit(struct crypto_tfm *tfm)\n{\n\tstruct padlock_sha_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_shash(ctx->fallback);\n}\n\nstatic struct shash_alg sha1_alg = {\n\t.digestsize\t=\tSHA1_DIGEST_SIZE,\n\t.init   \t= \tpadlock_sha_init,\n\t.update \t=\tpadlock_sha_update,\n\t.finup  \t=\tpadlock_sha1_finup,\n\t.final  \t=\tpadlock_sha1_final,\n\t.export\t\t=\tpadlock_sha_export,\n\t.import\t\t=\tpadlock_sha_import,\n\t.descsize\t=\tsizeof(struct padlock_sha_desc),\n\t.statesize\t=\tsizeof(struct sha1_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t\t=\t\"sha1\",\n\t\t.cra_driver_name\t=\t\"sha1-padlock\",\n\t\t.cra_priority\t\t=\tPADLOCK_CRA_PRIORITY,\n\t\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_SHASH |\n\t\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t\t.cra_blocksize\t\t=\tSHA1_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t=\tsizeof(struct padlock_sha_ctx),\n\t\t.cra_module\t\t=\tTHIS_MODULE,\n\t\t.cra_init\t\t=\tpadlock_cra_init,\n\t\t.cra_exit\t\t=\tpadlock_cra_exit,\n\t}\n};\n\nstatic struct shash_alg sha256_alg = {\n\t.digestsize\t=\tSHA256_DIGEST_SIZE,\n\t.init   \t= \tpadlock_sha_init,\n\t.update \t=\tpadlock_sha_update,\n\t.finup  \t=\tpadlock_sha256_finup,\n\t.final  \t=\tpadlock_sha256_final,\n\t.export\t\t=\tpadlock_sha_export,\n\t.import\t\t=\tpadlock_sha_import,\n\t.descsize\t=\tsizeof(struct padlock_sha_desc),\n\t.statesize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t\t=\t\"sha256\",\n\t\t.cra_driver_name\t=\t\"sha256-padlock\",\n\t\t.cra_priority\t\t=\tPADLOCK_CRA_PRIORITY,\n\t\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_SHASH |\n\t\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t\t.cra_blocksize\t\t=\tSHA256_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t=\tsizeof(struct padlock_sha_ctx),\n\t\t.cra_module\t\t=\tTHIS_MODULE,\n\t\t.cra_init\t\t=\tpadlock_cra_init,\n\t\t.cra_exit\t\t=\tpadlock_cra_exit,\n\t}\n};\n\n/* Add two shash_alg instance for hardware-implemented *\n* multiple-parts hash supported by VIA Nano Processor.*/\nstatic int padlock_sha1_init_nano(struct shash_desc *desc)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\t*sctx = (struct sha1_state){\n\t\t.state = { SHA1_H0, SHA1_H1, SHA1_H2, SHA1_H3, SHA1_H4 },\n\t};\n\n\treturn 0;\n}\n\nstatic int padlock_sha1_update_nano(struct shash_desc *desc,\n\t\t\tconst u8 *data,\tunsigned int len)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial, done;\n\tconst u8 *src;\n\t/*The PHE require the out buffer must 128 bytes and 16-bytes aligned*/\n\tu8 buf[128 + PADLOCK_ALIGNMENT - STACK_ALIGN] __attribute__\n\t\t((aligned(STACK_ALIGN)));\n\tu8 *dst = PTR_ALIGN(&buf[0], PADLOCK_ALIGNMENT);\n\tint ts_state;\n\n\tpartial = sctx->count & 0x3f;\n\tsctx->count += len;\n\tdone = 0;\n\tsrc = data;\n\tmemcpy(dst, (u8 *)(sctx->state), SHA1_DIGEST_SIZE);\n\n\tif ((partial + len) >= SHA1_BLOCK_SIZE) {\n\n\t\t/* Append the bytes in state's buffer to a block to handle */\n\t\tif (partial) {\n\t\t\tdone = -partial;\n\t\t\tmemcpy(sctx->buffer + partial, data,\n\t\t\t\tdone + SHA1_BLOCK_SIZE);\n\t\t\tsrc = sctx->buffer;\n\t\t\tts_state = irq_ts_save();\n\t\t\tasm volatile (\".byte 0xf3,0x0f,0xa6,0xc8\"\n\t\t\t: \"+S\"(src), \"+D\"(dst) \\\n\t\t\t: \"a\"((long)-1), \"c\"((unsigned long)1));\n\t\t\tirq_ts_restore(ts_state);\n\t\t\tdone += SHA1_BLOCK_SIZE;\n\t\t\tsrc = data + done;\n\t\t}\n\n\t\t/* Process the left bytes from the input data */\n\t\tif (len - done >= SHA1_BLOCK_SIZE) {\n\t\t\tts_state = irq_ts_save();\n\t\t\tasm volatile (\".byte 0xf3,0x0f,0xa6,0xc8\"\n\t\t\t: \"+S\"(src), \"+D\"(dst)\n\t\t\t: \"a\"((long)-1),\n\t\t\t\"c\"((unsigned long)((len - done) / SHA1_BLOCK_SIZE)));\n\t\t\tirq_ts_restore(ts_state);\n\t\t\tdone += ((len - done) - (len - done) % SHA1_BLOCK_SIZE);\n\t\t\tsrc = data + done;\n\t\t}\n\t\tpartial = 0;\n\t}\n\tmemcpy((u8 *)(sctx->state), dst, SHA1_DIGEST_SIZE);\n\tmemcpy(sctx->buffer + partial, src, len - done);\n\n\treturn 0;\n}\n\nstatic int padlock_sha1_final_nano(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha1_state *state = (struct sha1_state *)shash_desc_ctx(desc);\n\tunsigned int partial, padlen;\n\t__be64 bits;\n\tstatic const u8 padding[64] = { 0x80, };\n\n\tbits = cpu_to_be64(state->count << 3);\n\n\t/* Pad out to 56 mod 64 */\n\tpartial = state->count & 0x3f;\n\tpadlen = (partial < 56) ? (56 - partial) : ((64+56) - partial);\n\tpadlock_sha1_update_nano(desc, padding, padlen);\n\n\t/* Append length field bytes */\n\tpadlock_sha1_update_nano(desc, (const u8 *)&bits, sizeof(bits));\n\n\t/* Swap to output */\n\tpadlock_output_block((uint32_t *)(state->state), (uint32_t *)out, 5);\n\n\treturn 0;\n}\n\nstatic int padlock_sha256_init_nano(struct shash_desc *desc)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\n\t*sctx = (struct sha256_state){\n\t\t.state = { SHA256_H0, SHA256_H1, SHA256_H2, SHA256_H3, \\\n\t\t\t\tSHA256_H4, SHA256_H5, SHA256_H6, SHA256_H7},\n\t};\n\n\treturn 0;\n}\n\nstatic int padlock_sha256_update_nano(struct shash_desc *desc, const u8 *data,\n\t\t\t  unsigned int len)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial, done;\n\tconst u8 *src;\n\t/*The PHE require the out buffer must 128 bytes and 16-bytes aligned*/\n\tu8 buf[128 + PADLOCK_ALIGNMENT - STACK_ALIGN] __attribute__\n\t\t((aligned(STACK_ALIGN)));\n\tu8 *dst = PTR_ALIGN(&buf[0], PADLOCK_ALIGNMENT);\n\tint ts_state;\n\n\tpartial = sctx->count & 0x3f;\n\tsctx->count += len;\n\tdone = 0;\n\tsrc = data;\n\tmemcpy(dst, (u8 *)(sctx->state), SHA256_DIGEST_SIZE);\n\n\tif ((partial + len) >= SHA256_BLOCK_SIZE) {\n\n\t\t/* Append the bytes in state's buffer to a block to handle */\n\t\tif (partial) {\n\t\t\tdone = -partial;\n\t\t\tmemcpy(sctx->buf + partial, data,\n\t\t\t\tdone + SHA256_BLOCK_SIZE);\n\t\t\tsrc = sctx->buf;\n\t\t\tts_state = irq_ts_save();\n\t\t\tasm volatile (\".byte 0xf3,0x0f,0xa6,0xd0\"\n\t\t\t: \"+S\"(src), \"+D\"(dst)\n\t\t\t: \"a\"((long)-1), \"c\"((unsigned long)1));\n\t\t\tirq_ts_restore(ts_state);\n\t\t\tdone += SHA256_BLOCK_SIZE;\n\t\t\tsrc = data + done;\n\t\t}\n\n\t\t/* Process the left bytes from input data*/\n\t\tif (len - done >= SHA256_BLOCK_SIZE) {\n\t\t\tts_state = irq_ts_save();\n\t\t\tasm volatile (\".byte 0xf3,0x0f,0xa6,0xd0\"\n\t\t\t: \"+S\"(src), \"+D\"(dst)\n\t\t\t: \"a\"((long)-1),\n\t\t\t\"c\"((unsigned long)((len - done) / 64)));\n\t\t\tirq_ts_restore(ts_state);\n\t\t\tdone += ((len - done) - (len - done) % 64);\n\t\t\tsrc = data + done;\n\t\t}\n\t\tpartial = 0;\n\t}\n\tmemcpy((u8 *)(sctx->state), dst, SHA256_DIGEST_SIZE);\n\tmemcpy(sctx->buf + partial, src, len - done);\n\n\treturn 0;\n}\n\nstatic int padlock_sha256_final_nano(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha256_state *state =\n\t\t(struct sha256_state *)shash_desc_ctx(desc);\n\tunsigned int partial, padlen;\n\t__be64 bits;\n\tstatic const u8 padding[64] = { 0x80, };\n\n\tbits = cpu_to_be64(state->count << 3);\n\n\t/* Pad out to 56 mod 64 */\n\tpartial = state->count & 0x3f;\n\tpadlen = (partial < 56) ? (56 - partial) : ((64+56) - partial);\n\tpadlock_sha256_update_nano(desc, padding, padlen);\n\n\t/* Append length field bytes */\n\tpadlock_sha256_update_nano(desc, (const u8 *)&bits, sizeof(bits));\n\n\t/* Swap to output */\n\tpadlock_output_block((uint32_t *)(state->state), (uint32_t *)out, 8);\n\n\treturn 0;\n}\n\nstatic int padlock_sha_export_nano(struct shash_desc *desc,\n\t\t\t\tvoid *out)\n{\n\tint statesize = crypto_shash_statesize(desc->tfm);\n\tvoid *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, statesize);\n\treturn 0;\n}\n\nstatic int padlock_sha_import_nano(struct shash_desc *desc,\n\t\t\t\tconst void *in)\n{\n\tint statesize = crypto_shash_statesize(desc->tfm);\n\tvoid *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, statesize);\n\treturn 0;\n}\n\nstatic struct shash_alg sha1_alg_nano = {\n\t.digestsize\t=\tSHA1_DIGEST_SIZE,\n\t.init\t\t=\tpadlock_sha1_init_nano,\n\t.update\t\t=\tpadlock_sha1_update_nano,\n\t.final\t\t=\tpadlock_sha1_final_nano,\n\t.export\t\t=\tpadlock_sha_export_nano,\n\t.import\t\t=\tpadlock_sha_import_nano,\n\t.descsize\t=\tsizeof(struct sha1_state),\n\t.statesize\t=\tsizeof(struct sha1_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t\t=\t\"sha1\",\n\t\t.cra_driver_name\t=\t\"sha1-padlock-nano\",\n\t\t.cra_priority\t\t=\tPADLOCK_CRA_PRIORITY,\n\t\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t\t=\tSHA1_BLOCK_SIZE,\n\t\t.cra_module\t\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic struct shash_alg sha256_alg_nano = {\n\t.digestsize\t=\tSHA256_DIGEST_SIZE,\n\t.init\t\t=\tpadlock_sha256_init_nano,\n\t.update\t\t=\tpadlock_sha256_update_nano,\n\t.final\t\t=\tpadlock_sha256_final_nano,\n\t.export\t\t=\tpadlock_sha_export_nano,\n\t.import\t\t=\tpadlock_sha_import_nano,\n\t.descsize\t=\tsizeof(struct sha256_state),\n\t.statesize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t\t=\t\"sha256\",\n\t\t.cra_driver_name\t=\t\"sha256-padlock-nano\",\n\t\t.cra_priority\t\t=\tPADLOCK_CRA_PRIORITY,\n\t\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t\t=\tSHA256_BLOCK_SIZE,\n\t\t.cra_module\t\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic struct x86_cpu_id padlock_sha_ids[] = {\n\tX86_FEATURE_MATCH(X86_FEATURE_PHE),\n\t{}\n};\nMODULE_DEVICE_TABLE(x86cpu, padlock_sha_ids);\n\nstatic int __init padlock_init(void)\n{\n\tint rc = -ENODEV;\n\tstruct cpuinfo_x86 *c = &cpu_data(0);\n\tstruct shash_alg *sha1;\n\tstruct shash_alg *sha256;\n\n\tif (!x86_match_cpu(padlock_sha_ids) || !cpu_has_phe_enabled)\n\t\treturn -ENODEV;\n\n\t/* Register the newly added algorithm module if on *\n\t* VIA Nano processor, or else just do as before */\n\tif (c->x86_model < 0x0f) {\n\t\tsha1 = &sha1_alg;\n\t\tsha256 = &sha256_alg;\n\t} else {\n\t\tsha1 = &sha1_alg_nano;\n\t\tsha256 = &sha256_alg_nano;\n\t}\n\n\trc = crypto_register_shash(sha1);\n\tif (rc)\n\t\tgoto out;\n\n\trc = crypto_register_shash(sha256);\n\tif (rc)\n\t\tgoto out_unreg1;\n\n\tprintk(KERN_NOTICE PFX \"Using VIA PadLock ACE for SHA1/SHA256 algorithms.\\n\");\n\n\treturn 0;\n\nout_unreg1:\n\tcrypto_unregister_shash(sha1);\n\nout:\n\tprintk(KERN_ERR PFX \"VIA PadLock SHA1/SHA256 initialization failed.\\n\");\n\treturn rc;\n}\n\nstatic void __exit padlock_fini(void)\n{\n\tstruct cpuinfo_x86 *c = &cpu_data(0);\n\n\tif (c->x86_model >= 0x0f) {\n\t\tcrypto_unregister_shash(&sha1_alg_nano);\n\t\tcrypto_unregister_shash(&sha256_alg_nano);\n\t} else {\n\t\tcrypto_unregister_shash(&sha1_alg);\n\t\tcrypto_unregister_shash(&sha256_alg);\n\t}\n}\n\nmodule_init(padlock_init);\nmodule_exit(padlock_fini);\n\nMODULE_DESCRIPTION(\"VIA PadLock SHA1/SHA256 algorithms support.\");\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Michal Ludvig\");\n\nMODULE_ALIAS(\"sha1-all\");\nMODULE_ALIAS(\"sha256-all\");\nMODULE_ALIAS(\"sha1-padlock\");\nMODULE_ALIAS(\"sha256-padlock\");\n", "/*\n  This file is provided under a dual BSD/GPLv2 license.  When using or\n  redistributing this file, you may do so under either license.\n\n  GPL LICENSE SUMMARY\n  Copyright(c) 2014 Intel Corporation.\n  This program is free software; you can redistribute it and/or modify\n  it under the terms of version 2 of the GNU General Public License as\n  published by the Free Software Foundation.\n\n  This program is distributed in the hope that it will be useful, but\n  WITHOUT ANY WARRANTY; without even the implied warranty of\n  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n  General Public License for more details.\n\n  Contact Information:\n  qat-linux@intel.com\n\n  BSD LICENSE\n  Copyright(c) 2014 Intel Corporation.\n  Redistribution and use in source and binary forms, with or without\n  modification, are permitted provided that the following conditions\n  are met:\n\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n    * Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in\n      the documentation and/or other materials provided with the\n      distribution.\n    * Neither the name of Intel Corporation nor the names of its\n      contributors may be used to endorse or promote products derived\n      from this software without specific prior written permission.\n\n  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n  \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n*/\n#include <linux/module.h>\n#include <linux/mutex.h>\n#include <linux/slab.h>\n#include <linux/fs.h>\n#include <linux/bitops.h>\n#include <linux/pci.h>\n#include <linux/cdev.h>\n#include <linux/uaccess.h>\n\n#include \"adf_accel_devices.h\"\n#include \"adf_common_drv.h\"\n#include \"adf_cfg.h\"\n#include \"adf_cfg_common.h\"\n#include \"adf_cfg_user.h\"\n\n#define DEVICE_NAME \"qat_adf_ctl\"\n\nstatic DEFINE_MUTEX(adf_ctl_lock);\nstatic long adf_ctl_ioctl(struct file *fp, unsigned int cmd, unsigned long arg);\n\nstatic const struct file_operations adf_ctl_ops = {\n\t.owner = THIS_MODULE,\n\t.unlocked_ioctl = adf_ctl_ioctl,\n\t.compat_ioctl = adf_ctl_ioctl,\n};\n\nstruct adf_ctl_drv_info {\n\tunsigned int major;\n\tstruct cdev drv_cdev;\n\tstruct class *drv_class;\n};\n\nstatic struct adf_ctl_drv_info adt_ctl_drv;\n\nstatic void adf_chr_drv_destroy(void)\n{\n\tdevice_destroy(adt_ctl_drv.drv_class, MKDEV(adt_ctl_drv.major, 0));\n\tcdev_del(&adt_ctl_drv.drv_cdev);\n\tclass_destroy(adt_ctl_drv.drv_class);\n\tunregister_chrdev_region(MKDEV(adt_ctl_drv.major, 0), 1);\n}\n\nstatic int adf_chr_drv_create(void)\n{\n\tdev_t dev_id;\n\tstruct device *drv_device;\n\n\tif (alloc_chrdev_region(&dev_id, 0, 1, DEVICE_NAME)) {\n\t\tpr_err(\"QAT: unable to allocate chrdev region\\n\");\n\t\treturn -EFAULT;\n\t}\n\n\tadt_ctl_drv.drv_class = class_create(THIS_MODULE, DEVICE_NAME);\n\tif (IS_ERR(adt_ctl_drv.drv_class)) {\n\t\tpr_err(\"QAT: class_create failed for adf_ctl\\n\");\n\t\tgoto err_chrdev_unreg;\n\t}\n\tadt_ctl_drv.major = MAJOR(dev_id);\n\tcdev_init(&adt_ctl_drv.drv_cdev, &adf_ctl_ops);\n\tif (cdev_add(&adt_ctl_drv.drv_cdev, dev_id, 1)) {\n\t\tpr_err(\"QAT: cdev add failed\\n\");\n\t\tgoto err_class_destr;\n\t}\n\n\tdrv_device = device_create(adt_ctl_drv.drv_class, NULL,\n\t\t\t\t   MKDEV(adt_ctl_drv.major, 0),\n\t\t\t\t   NULL, DEVICE_NAME);\n\tif (IS_ERR(drv_device)) {\n\t\tpr_err(\"QAT: failed to create device\\n\");\n\t\tgoto err_cdev_del;\n\t}\n\treturn 0;\nerr_cdev_del:\n\tcdev_del(&adt_ctl_drv.drv_cdev);\nerr_class_destr:\n\tclass_destroy(adt_ctl_drv.drv_class);\nerr_chrdev_unreg:\n\tunregister_chrdev_region(dev_id, 1);\n\treturn -EFAULT;\n}\n\nstatic int adf_ctl_alloc_resources(struct adf_user_cfg_ctl_data **ctl_data,\n\t\t\t\t   unsigned long arg)\n{\n\tstruct adf_user_cfg_ctl_data *cfg_data;\n\n\tcfg_data = kzalloc(sizeof(*cfg_data), GFP_KERNEL);\n\tif (!cfg_data)\n\t\treturn -ENOMEM;\n\n\t/* Initialize device id to NO DEVICE as 0 is a valid device id */\n\tcfg_data->device_id = ADF_CFG_NO_DEVICE;\n\n\tif (copy_from_user(cfg_data, (void __user *)arg, sizeof(*cfg_data))) {\n\t\tpr_err(\"QAT: failed to copy from user cfg_data.\\n\");\n\t\tkfree(cfg_data);\n\t\treturn -EIO;\n\t}\n\n\t*ctl_data = cfg_data;\n\treturn 0;\n}\n\nstatic int adf_add_key_value_data(struct adf_accel_dev *accel_dev,\n\t\t\t\t  const char *section,\n\t\t\t\t  const struct adf_user_cfg_key_val *key_val)\n{\n\tif (key_val->type == ADF_HEX) {\n\t\tlong *ptr = (long *)key_val->val;\n\t\tlong val = *ptr;\n\n\t\tif (adf_cfg_add_key_value_param(accel_dev, section,\n\t\t\t\t\t\tkey_val->key, (void *)val,\n\t\t\t\t\t\tkey_val->type)) {\n\t\t\tpr_err(\"QAT: failed to add keyvalue.\\n\");\n\t\t\treturn -EFAULT;\n\t\t}\n\t} else {\n\t\tif (adf_cfg_add_key_value_param(accel_dev, section,\n\t\t\t\t\t\tkey_val->key, key_val->val,\n\t\t\t\t\t\tkey_val->type)) {\n\t\t\tpr_err(\"QAT: failed to add keyvalue.\\n\");\n\t\t\treturn -EFAULT;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int adf_copy_key_value_data(struct adf_accel_dev *accel_dev,\n\t\t\t\t   struct adf_user_cfg_ctl_data *ctl_data)\n{\n\tstruct adf_user_cfg_key_val key_val;\n\tstruct adf_user_cfg_key_val *params_head;\n\tstruct adf_user_cfg_section section, *section_head;\n\n\tsection_head = ctl_data->config_section;\n\n\twhile (section_head) {\n\t\tif (copy_from_user(&section, (void __user *)section_head,\n\t\t\t\t   sizeof(*section_head))) {\n\t\t\tpr_err(\"QAT: failed to copy section info\\n\");\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tif (adf_cfg_section_add(accel_dev, section.name)) {\n\t\t\tpr_err(\"QAT: failed to add section.\\n\");\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tparams_head = section_head->params;\n\n\t\twhile (params_head) {\n\t\t\tif (copy_from_user(&key_val, (void __user *)params_head,\n\t\t\t\t\t   sizeof(key_val))) {\n\t\t\t\tpr_err(\"QAT: Failed to copy keyvalue.\\n\");\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t\tif (adf_add_key_value_data(accel_dev, section.name,\n\t\t\t\t\t\t   &key_val)) {\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t\tparams_head = key_val.next;\n\t\t}\n\t\tsection_head = section.next;\n\t}\n\treturn 0;\nout_err:\n\tadf_cfg_del_all(accel_dev);\n\treturn -EFAULT;\n}\n\nstatic int adf_ctl_ioctl_dev_config(struct file *fp, unsigned int cmd,\n\t\t\t\t    unsigned long arg)\n{\n\tint ret;\n\tstruct adf_user_cfg_ctl_data *ctl_data;\n\tstruct adf_accel_dev *accel_dev;\n\n\tret = adf_ctl_alloc_resources(&ctl_data, arg);\n\tif (ret)\n\t\treturn ret;\n\n\taccel_dev = adf_devmgr_get_dev_by_id(ctl_data->device_id);\n\tif (!accel_dev) {\n\t\tret = -EFAULT;\n\t\tgoto out;\n\t}\n\n\tif (adf_dev_started(accel_dev)) {\n\t\tret = -EFAULT;\n\t\tgoto out;\n\t}\n\n\tif (adf_copy_key_value_data(accel_dev, ctl_data)) {\n\t\tret = -EFAULT;\n\t\tgoto out;\n\t}\n\tset_bit(ADF_STATUS_CONFIGURED, &accel_dev->status);\nout:\n\tkfree(ctl_data);\n\treturn ret;\n}\n\nstatic int adf_ctl_is_device_in_use(int id)\n{\n\tstruct list_head *itr, *head = adf_devmgr_get_head();\n\n\tlist_for_each(itr, head) {\n\t\tstruct adf_accel_dev *dev =\n\t\t\t\tlist_entry(itr, struct adf_accel_dev, list);\n\n\t\tif (id == dev->accel_id || id == ADF_CFG_ALL_DEVICES) {\n\t\t\tif (adf_devmgr_in_reset(dev) || adf_dev_in_use(dev)) {\n\t\t\t\tpr_info(\"QAT: device qat_dev%d is busy\\n\",\n\t\t\t\t\tdev->accel_id);\n\t\t\t\treturn -EBUSY;\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int adf_ctl_stop_devices(uint32_t id)\n{\n\tstruct list_head *itr, *head = adf_devmgr_get_head();\n\tint ret = 0;\n\n\tlist_for_each(itr, head) {\n\t\tstruct adf_accel_dev *accel_dev =\n\t\t\t\tlist_entry(itr, struct adf_accel_dev, list);\n\t\tif (id == accel_dev->accel_id || id == ADF_CFG_ALL_DEVICES) {\n\t\t\tif (!adf_dev_started(accel_dev))\n\t\t\t\tcontinue;\n\n\t\t\tif (adf_dev_stop(accel_dev)) {\n\t\t\t\tpr_err(\"QAT: Failed to stop qat_dev%d\\n\", id);\n\t\t\t\tret = -EFAULT;\n\t\t\t}\n\t\t}\n\t}\n\treturn ret;\n}\n\nstatic int adf_ctl_ioctl_dev_stop(struct file *fp, unsigned int cmd,\n\t\t\t\t  unsigned long arg)\n{\n\tint ret;\n\tstruct adf_user_cfg_ctl_data *ctl_data;\n\n\tret = adf_ctl_alloc_resources(&ctl_data, arg);\n\tif (ret)\n\t\treturn ret;\n\n\tif (adf_devmgr_verify_id(ctl_data->device_id)) {\n\t\tpr_err(\"QAT: Device %d not found\\n\", ctl_data->device_id);\n\t\tret = -ENODEV;\n\t\tgoto out;\n\t}\n\n\tret = adf_ctl_is_device_in_use(ctl_data->device_id);\n\tif (ret)\n\t\tgoto out;\n\n\tif (ctl_data->device_id == ADF_CFG_ALL_DEVICES)\n\t\tpr_info(\"QAT: Stopping all acceleration devices.\\n\");\n\telse\n\t\tpr_info(\"QAT: Stopping acceleration device qat_dev%d.\\n\",\n\t\t\tctl_data->device_id);\n\n\tret = adf_ctl_stop_devices(ctl_data->device_id);\n\tif (ret)\n\t\tpr_err(\"QAT: failed to stop device.\\n\");\nout:\n\tkfree(ctl_data);\n\treturn ret;\n}\n\nstatic int adf_ctl_ioctl_dev_start(struct file *fp, unsigned int cmd,\n\t\t\t\t   unsigned long arg)\n{\n\tint ret;\n\tstruct adf_user_cfg_ctl_data *ctl_data;\n\tstruct adf_accel_dev *accel_dev;\n\n\tret = adf_ctl_alloc_resources(&ctl_data, arg);\n\tif (ret)\n\t\treturn ret;\n\n\taccel_dev = adf_devmgr_get_dev_by_id(ctl_data->device_id);\n\tif (!accel_dev) {\n\t\tpr_err(\"QAT: Device %d not found\\n\", ctl_data->device_id);\n\t\tret = -ENODEV;\n\t\tgoto out;\n\t}\n\n\tif (!adf_dev_started(accel_dev)) {\n\t\tpr_info(\"QAT: Starting acceleration device qat_dev%d.\\n\",\n\t\t\tctl_data->device_id);\n\t\tret = adf_dev_start(accel_dev);\n\t} else {\n\t\tpr_info(\"QAT: Acceleration device qat_dev%d already started.\\n\",\n\t\t\tctl_data->device_id);\n\t}\n\tif (ret) {\n\t\tpr_err(\"QAT: Failed to start qat_dev%d\\n\", ctl_data->device_id);\n\t\tadf_dev_stop(accel_dev);\n\t}\nout:\n\tkfree(ctl_data);\n\treturn ret;\n}\n\nstatic int adf_ctl_ioctl_get_num_devices(struct file *fp, unsigned int cmd,\n\t\t\t\t\t unsigned long arg)\n{\n\tuint32_t num_devices = 0;\n\n\tadf_devmgr_get_num_dev(&num_devices);\n\tif (copy_to_user((void __user *)arg, &num_devices, sizeof(num_devices)))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n\nstatic int adf_ctl_ioctl_get_status(struct file *fp, unsigned int cmd,\n\t\t\t\t    unsigned long arg)\n{\n\tstruct adf_hw_device_data *hw_data;\n\tstruct adf_dev_status_info dev_info;\n\tstruct adf_accel_dev *accel_dev;\n\n\tif (copy_from_user(&dev_info, (void __user *)arg,\n\t\t\t   sizeof(struct adf_dev_status_info))) {\n\t\tpr_err(\"QAT: failed to copy from user.\\n\");\n\t\treturn -EFAULT;\n\t}\n\n\taccel_dev = adf_devmgr_get_dev_by_id(dev_info.accel_id);\n\tif (!accel_dev) {\n\t\tpr_err(\"QAT: Device %d not found\\n\", dev_info.accel_id);\n\t\treturn -ENODEV;\n\t}\n\thw_data = accel_dev->hw_device;\n\tdev_info.state = adf_dev_started(accel_dev) ? DEV_UP : DEV_DOWN;\n\tdev_info.num_ae = hw_data->get_num_aes(hw_data);\n\tdev_info.num_accel = hw_data->get_num_accels(hw_data);\n\tdev_info.num_logical_accel = hw_data->num_logical_accel;\n\tdev_info.banks_per_accel = hw_data->num_banks\n\t\t\t\t\t/ hw_data->num_logical_accel;\n\tstrlcpy(dev_info.name, hw_data->dev_class->name, sizeof(dev_info.name));\n\tdev_info.instance_id = hw_data->instance_id;\n\tdev_info.type = hw_data->dev_class->type;\n\tdev_info.bus = accel_to_pci_dev(accel_dev)->bus->number;\n\tdev_info.dev = PCI_SLOT(accel_to_pci_dev(accel_dev)->devfn);\n\tdev_info.fun = PCI_FUNC(accel_to_pci_dev(accel_dev)->devfn);\n\n\tif (copy_to_user((void __user *)arg, &dev_info,\n\t\t\t sizeof(struct adf_dev_status_info))) {\n\t\tpr_err(\"QAT: failed to copy status.\\n\");\n\t\treturn -EFAULT;\n\t}\n\treturn 0;\n}\n\nstatic long adf_ctl_ioctl(struct file *fp, unsigned int cmd, unsigned long arg)\n{\n\tint ret;\n\n\tif (mutex_lock_interruptible(&adf_ctl_lock))\n\t\treturn -EFAULT;\n\n\tswitch (cmd) {\n\tcase IOCTL_CONFIG_SYS_RESOURCE_PARAMETERS:\n\t\tret = adf_ctl_ioctl_dev_config(fp, cmd, arg);\n\t\tbreak;\n\n\tcase IOCTL_STOP_ACCEL_DEV:\n\t\tret = adf_ctl_ioctl_dev_stop(fp, cmd, arg);\n\t\tbreak;\n\n\tcase IOCTL_START_ACCEL_DEV:\n\t\tret = adf_ctl_ioctl_dev_start(fp, cmd, arg);\n\t\tbreak;\n\n\tcase IOCTL_GET_NUM_DEVICES:\n\t\tret = adf_ctl_ioctl_get_num_devices(fp, cmd, arg);\n\t\tbreak;\n\n\tcase IOCTL_STATUS_ACCEL_DEV:\n\t\tret = adf_ctl_ioctl_get_status(fp, cmd, arg);\n\t\tbreak;\n\tdefault:\n\t\tpr_err(\"QAT: Invalid ioctl\\n\");\n\t\tret = -EFAULT;\n\t\tbreak;\n\t}\n\tmutex_unlock(&adf_ctl_lock);\n\treturn ret;\n}\n\nstatic int __init adf_register_ctl_device_driver(void)\n{\n\tmutex_init(&adf_ctl_lock);\n\n\tif (qat_algs_init())\n\t\tgoto err_algs_init;\n\n\tif (adf_chr_drv_create())\n\t\tgoto err_chr_dev;\n\n\tif (adf_init_aer())\n\t\tgoto err_aer;\n\n\tif (qat_crypto_register())\n\t\tgoto err_crypto_register;\n\n\treturn 0;\n\nerr_crypto_register:\n\tadf_exit_aer();\nerr_aer:\n\tadf_chr_drv_destroy();\nerr_chr_dev:\n\tqat_algs_exit();\nerr_algs_init:\n\tmutex_destroy(&adf_ctl_lock);\n\treturn -EFAULT;\n}\n\nstatic void __exit adf_unregister_ctl_device_driver(void)\n{\n\tadf_chr_drv_destroy();\n\tadf_exit_aer();\n\tqat_crypto_unregister();\n\tqat_algs_exit();\n\tmutex_destroy(&adf_ctl_lock);\n}\n\nmodule_init(adf_register_ctl_device_driver);\nmodule_exit(adf_unregister_ctl_device_driver);\nMODULE_LICENSE(\"Dual BSD/GPL\");\nMODULE_AUTHOR(\"Intel\");\nMODULE_DESCRIPTION(\"Intel(R) QuickAssist Technology\");\nMODULE_ALIAS(\"intel_qat\");\n", "/**\n * Copyright (C) ST-Ericsson SA 2010\n * Author: Shujuan Chen <shujuan.chen@stericsson.com> for ST-Ericsson.\n * Author: Joakim Bech <joakim.xx.bech@stericsson.com> for ST-Ericsson.\n * Author: Berne Hebark <berne.herbark@stericsson.com> for ST-Ericsson.\n * Author: Niklas Hernaeus <niklas.hernaeus@stericsson.com> for ST-Ericsson.\n * Author: Jonas Linde <jonas.linde@stericsson.com> for ST-Ericsson.\n * Author: Andreas Westin <andreas.westin@stericsson.com> for ST-Ericsson.\n * License terms: GNU General Public License (GPL) version 2\n */\n\n#include <linux/clk.h>\n#include <linux/completion.h>\n#include <linux/crypto.h>\n#include <linux/dmaengine.h>\n#include <linux/err.h>\n#include <linux/errno.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/irqreturn.h>\n#include <linux/klist.h>\n#include <linux/module.h>\n#include <linux/platform_device.h>\n#include <linux/regulator/consumer.h>\n#include <linux/semaphore.h>\n#include <linux/platform_data/dma-ste-dma40.h>\n\n#include <crypto/aes.h>\n#include <crypto/algapi.h>\n#include <crypto/ctr.h>\n#include <crypto/des.h>\n#include <crypto/scatterwalk.h>\n\n#include <linux/platform_data/crypto-ux500.h>\n\n#include \"cryp_p.h\"\n#include \"cryp.h\"\n\n#define CRYP_MAX_KEY_SIZE\t32\n#define BYTES_PER_WORD\t\t4\n\nstatic int cryp_mode;\nstatic atomic_t session_id;\n\nstatic struct stedma40_chan_cfg *mem_to_engine;\nstatic struct stedma40_chan_cfg *engine_to_mem;\n\n/**\n * struct cryp_driver_data - data specific to the driver.\n *\n * @device_list: A list of registered devices to choose from.\n * @device_allocation: A semaphore initialized with number of devices.\n */\nstruct cryp_driver_data {\n\tstruct klist device_list;\n\tstruct semaphore device_allocation;\n};\n\n/**\n * struct cryp_ctx - Crypto context\n * @config: Crypto mode.\n * @key[CRYP_MAX_KEY_SIZE]: Key.\n * @keylen: Length of key.\n * @iv: Pointer to initialization vector.\n * @indata: Pointer to indata.\n * @outdata: Pointer to outdata.\n * @datalen: Length of indata.\n * @outlen: Length of outdata.\n * @blocksize: Size of blocks.\n * @updated: Updated flag.\n * @dev_ctx: Device dependent context.\n * @device: Pointer to the device.\n */\nstruct cryp_ctx {\n\tstruct cryp_config config;\n\tu8 key[CRYP_MAX_KEY_SIZE];\n\tu32 keylen;\n\tu8 *iv;\n\tconst u8 *indata;\n\tu8 *outdata;\n\tu32 datalen;\n\tu32 outlen;\n\tu32 blocksize;\n\tu8 updated;\n\tstruct cryp_device_context dev_ctx;\n\tstruct cryp_device_data *device;\n\tu32 session_id;\n};\n\nstatic struct cryp_driver_data driver_data;\n\n/**\n * uint8p_to_uint32_be - 4*uint8 to uint32 big endian\n * @in: Data to convert.\n */\nstatic inline u32 uint8p_to_uint32_be(u8 *in)\n{\n\tu32 *data = (u32 *)in;\n\n\treturn cpu_to_be32p(data);\n}\n\n/**\n * swap_bits_in_byte - mirror the bits in a byte\n * @b: the byte to be mirrored\n *\n * The bits are swapped the following way:\n *  Byte b include bits 0-7, nibble 1 (n1) include bits 0-3 and\n *  nibble 2 (n2) bits 4-7.\n *\n *  Nibble 1 (n1):\n *  (The \"old\" (moved) bit is replaced with a zero)\n *  1. Move bit 6 and 7, 4 positions to the left.\n *  2. Move bit 3 and 5, 2 positions to the left.\n *  3. Move bit 1-4, 1 position to the left.\n *\n *  Nibble 2 (n2):\n *  1. Move bit 0 and 1, 4 positions to the right.\n *  2. Move bit 2 and 4, 2 positions to the right.\n *  3. Move bit 3-6, 1 position to the right.\n *\n *  Combine the two nibbles to a complete and swapped byte.\n */\n\nstatic inline u8 swap_bits_in_byte(u8 b)\n{\n#define R_SHIFT_4_MASK  0xc0 /* Bits 6 and 7, right shift 4 */\n#define R_SHIFT_2_MASK  0x28 /* (After right shift 4) Bits 3 and 5,\n\t\t\t\t  right shift 2 */\n#define R_SHIFT_1_MASK  0x1e /* (After right shift 2) Bits 1-4,\n\t\t\t\t  right shift 1 */\n#define L_SHIFT_4_MASK  0x03 /* Bits 0 and 1, left shift 4 */\n#define L_SHIFT_2_MASK  0x14 /* (After left shift 4) Bits 2 and 4,\n\t\t\t\t  left shift 2 */\n#define L_SHIFT_1_MASK  0x78 /* (After left shift 1) Bits 3-6,\n\t\t\t\t  left shift 1 */\n\n\tu8 n1;\n\tu8 n2;\n\n\t/* Swap most significant nibble */\n\t/* Right shift 4, bits 6 and 7 */\n\tn1 = ((b  & R_SHIFT_4_MASK) >> 4) | (b  & ~(R_SHIFT_4_MASK >> 4));\n\t/* Right shift 2, bits 3 and 5 */\n\tn1 = ((n1 & R_SHIFT_2_MASK) >> 2) | (n1 & ~(R_SHIFT_2_MASK >> 2));\n\t/* Right shift 1, bits 1-4 */\n\tn1 = (n1  & R_SHIFT_1_MASK) >> 1;\n\n\t/* Swap least significant nibble */\n\t/* Left shift 4, bits 0 and 1 */\n\tn2 = ((b  & L_SHIFT_4_MASK) << 4) | (b  & ~(L_SHIFT_4_MASK << 4));\n\t/* Left shift 2, bits 2 and 4 */\n\tn2 = ((n2 & L_SHIFT_2_MASK) << 2) | (n2 & ~(L_SHIFT_2_MASK << 2));\n\t/* Left shift 1, bits 3-6 */\n\tn2 = (n2  & L_SHIFT_1_MASK) << 1;\n\n\treturn n1 | n2;\n}\n\nstatic inline void swap_words_in_key_and_bits_in_byte(const u8 *in,\n\t\t\t\t\t\t      u8 *out, u32 len)\n{\n\tunsigned int i = 0;\n\tint j;\n\tint index = 0;\n\n\tj = len - BYTES_PER_WORD;\n\twhile (j >= 0) {\n\t\tfor (i = 0; i < BYTES_PER_WORD; i++) {\n\t\t\tindex = len - j - BYTES_PER_WORD + i;\n\t\t\tout[j + i] =\n\t\t\t\tswap_bits_in_byte(in[index]);\n\t\t}\n\t\tj -= BYTES_PER_WORD;\n\t}\n}\n\nstatic void add_session_id(struct cryp_ctx *ctx)\n{\n\t/*\n\t * We never want 0 to be a valid value, since this is the default value\n\t * for the software context.\n\t */\n\tif (unlikely(atomic_inc_and_test(&session_id)))\n\t\tatomic_inc(&session_id);\n\n\tctx->session_id = atomic_read(&session_id);\n}\n\nstatic irqreturn_t cryp_interrupt_handler(int irq, void *param)\n{\n\tstruct cryp_ctx *ctx;\n\tint count;\n\tstruct cryp_device_data *device_data;\n\n\tif (param == NULL) {\n\t\tBUG_ON(!param);\n\t\treturn IRQ_HANDLED;\n\t}\n\n\t/* The device is coming from the one found in hw_crypt_noxts. */\n\tdevice_data = (struct cryp_device_data *)param;\n\n\tctx = device_data->current_ctx;\n\n\tif (ctx == NULL) {\n\t\tBUG_ON(!ctx);\n\t\treturn IRQ_HANDLED;\n\t}\n\n\tdev_dbg(ctx->device->dev, \"[%s] (len: %d) %s, \", __func__, ctx->outlen,\n\t\tcryp_pending_irq_src(device_data, CRYP_IRQ_SRC_OUTPUT_FIFO) ?\n\t\t\"out\" : \"in\");\n\n\tif (cryp_pending_irq_src(device_data,\n\t\t\t\t CRYP_IRQ_SRC_OUTPUT_FIFO)) {\n\t\tif (ctx->outlen / ctx->blocksize > 0) {\n\t\t\tcount = ctx->blocksize / 4;\n\n\t\t\treadsl(&device_data->base->dout, ctx->outdata, count);\n\t\t\tctx->outdata += count;\n\t\t\tctx->outlen -= count;\n\n\t\t\tif (ctx->outlen == 0) {\n\t\t\t\tcryp_disable_irq_src(device_data,\n\t\t\t\t\t\t     CRYP_IRQ_SRC_OUTPUT_FIFO);\n\t\t\t}\n\t\t}\n\t} else if (cryp_pending_irq_src(device_data,\n\t\t\t\t\tCRYP_IRQ_SRC_INPUT_FIFO)) {\n\t\tif (ctx->datalen / ctx->blocksize > 0) {\n\t\t\tcount = ctx->blocksize / 4;\n\n\t\t\twritesl(&device_data->base->din, ctx->indata, count);\n\n\t\t\tctx->indata += count;\n\t\t\tctx->datalen -= count;\n\n\t\t\tif (ctx->datalen == 0)\n\t\t\t\tcryp_disable_irq_src(device_data,\n\t\t\t\t\t\t   CRYP_IRQ_SRC_INPUT_FIFO);\n\n\t\t\tif (ctx->config.algomode == CRYP_ALGO_AES_XTS) {\n\t\t\t\tCRYP_PUT_BITS(&device_data->base->cr,\n\t\t\t\t\t      CRYP_START_ENABLE,\n\t\t\t\t\t      CRYP_CR_START_POS,\n\t\t\t\t\t      CRYP_CR_START_MASK);\n\n\t\t\t\tcryp_wait_until_done(device_data);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int mode_is_aes(enum cryp_algo_mode mode)\n{\n\treturn\tCRYP_ALGO_AES_ECB == mode ||\n\t\tCRYP_ALGO_AES_CBC == mode ||\n\t\tCRYP_ALGO_AES_CTR == mode ||\n\t\tCRYP_ALGO_AES_XTS == mode;\n}\n\nstatic int cfg_iv(struct cryp_device_data *device_data, u32 left, u32 right,\n\t\t  enum cryp_init_vector_index index)\n{\n\tstruct cryp_init_vector_value vector_value;\n\n\tdev_dbg(device_data->dev, \"[%s]\", __func__);\n\n\tvector_value.init_value_left = left;\n\tvector_value.init_value_right = right;\n\n\treturn cryp_configure_init_vector(device_data,\n\t\t\t\t\t  index,\n\t\t\t\t\t  vector_value);\n}\n\nstatic int cfg_ivs(struct cryp_device_data *device_data, struct cryp_ctx *ctx)\n{\n\tint i;\n\tint status = 0;\n\tint num_of_regs = ctx->blocksize / 8;\n\tu32 iv[AES_BLOCK_SIZE / 4];\n\n\tdev_dbg(device_data->dev, \"[%s]\", __func__);\n\n\t/*\n\t * Since we loop on num_of_regs we need to have a check in case\n\t * someone provides an incorrect blocksize which would force calling\n\t * cfg_iv with i greater than 2 which is an error.\n\t */\n\tif (num_of_regs > 2) {\n\t\tdev_err(device_data->dev, \"[%s] Incorrect blocksize %d\",\n\t\t\t__func__, ctx->blocksize);\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < ctx->blocksize / 4; i++)\n\t\tiv[i] = uint8p_to_uint32_be(ctx->iv + i*4);\n\n\tfor (i = 0; i < num_of_regs; i++) {\n\t\tstatus = cfg_iv(device_data, iv[i*2], iv[i*2+1],\n\t\t\t\t(enum cryp_init_vector_index) i);\n\t\tif (status != 0)\n\t\t\treturn status;\n\t}\n\treturn status;\n}\n\nstatic int set_key(struct cryp_device_data *device_data,\n\t\t   u32 left_key,\n\t\t   u32 right_key,\n\t\t   enum cryp_key_reg_index index)\n{\n\tstruct cryp_key_value key_value;\n\tint cryp_error;\n\n\tdev_dbg(device_data->dev, \"[%s]\", __func__);\n\n\tkey_value.key_value_left = left_key;\n\tkey_value.key_value_right = right_key;\n\n\tcryp_error = cryp_configure_key_values(device_data,\n\t\t\t\t\t       index,\n\t\t\t\t\t       key_value);\n\tif (cryp_error != 0)\n\t\tdev_err(device_data->dev, \"[%s]: \"\n\t\t\t\"cryp_configure_key_values() failed!\", __func__);\n\n\treturn cryp_error;\n}\n\nstatic int cfg_keys(struct cryp_ctx *ctx)\n{\n\tint i;\n\tint num_of_regs = ctx->keylen / 8;\n\tu32 swapped_key[CRYP_MAX_KEY_SIZE / 4];\n\tint cryp_error = 0;\n\n\tdev_dbg(ctx->device->dev, \"[%s]\", __func__);\n\n\tif (mode_is_aes(ctx->config.algomode)) {\n\t\tswap_words_in_key_and_bits_in_byte((u8 *)ctx->key,\n\t\t\t\t\t\t   (u8 *)swapped_key,\n\t\t\t\t\t\t   ctx->keylen);\n\t} else {\n\t\tfor (i = 0; i < ctx->keylen / 4; i++)\n\t\t\tswapped_key[i] = uint8p_to_uint32_be(ctx->key + i*4);\n\t}\n\n\tfor (i = 0; i < num_of_regs; i++) {\n\t\tcryp_error = set_key(ctx->device,\n\t\t\t\t     *(((u32 *)swapped_key)+i*2),\n\t\t\t\t     *(((u32 *)swapped_key)+i*2+1),\n\t\t\t\t     (enum cryp_key_reg_index) i);\n\n\t\tif (cryp_error != 0) {\n\t\t\tdev_err(ctx->device->dev, \"[%s]: set_key() failed!\",\n\t\t\t\t\t__func__);\n\t\t\treturn cryp_error;\n\t\t}\n\t}\n\treturn cryp_error;\n}\n\nstatic int cryp_setup_context(struct cryp_ctx *ctx,\n\t\t\t      struct cryp_device_data *device_data)\n{\n\tu32 control_register = CRYP_CR_DEFAULT;\n\n\tswitch (cryp_mode) {\n\tcase CRYP_MODE_INTERRUPT:\n\t\twritel_relaxed(CRYP_IMSC_DEFAULT, &device_data->base->imsc);\n\t\tbreak;\n\n\tcase CRYP_MODE_DMA:\n\t\twritel_relaxed(CRYP_DMACR_DEFAULT, &device_data->base->dmacr);\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (ctx->updated == 0) {\n\t\tcryp_flush_inoutfifo(device_data);\n\t\tif (cfg_keys(ctx) != 0) {\n\t\t\tdev_err(ctx->device->dev, \"[%s]: cfg_keys failed!\",\n\t\t\t\t__func__);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (ctx->iv &&\n\t\t    CRYP_ALGO_AES_ECB != ctx->config.algomode &&\n\t\t    CRYP_ALGO_DES_ECB != ctx->config.algomode &&\n\t\t    CRYP_ALGO_TDES_ECB != ctx->config.algomode) {\n\t\t\tif (cfg_ivs(device_data, ctx) != 0)\n\t\t\t\treturn -EPERM;\n\t\t}\n\n\t\tcryp_set_configuration(device_data, &ctx->config,\n\t\t\t\t       &control_register);\n\t\tadd_session_id(ctx);\n\t} else if (ctx->updated == 1 &&\n\t\t   ctx->session_id != atomic_read(&session_id)) {\n\t\tcryp_flush_inoutfifo(device_data);\n\t\tcryp_restore_device_context(device_data, &ctx->dev_ctx);\n\n\t\tadd_session_id(ctx);\n\t\tcontrol_register = ctx->dev_ctx.cr;\n\t} else\n\t\tcontrol_register = ctx->dev_ctx.cr;\n\n\twritel(control_register |\n\t       (CRYP_CRYPEN_ENABLE << CRYP_CR_CRYPEN_POS),\n\t       &device_data->base->cr);\n\n\treturn 0;\n}\n\nstatic int cryp_get_device_data(struct cryp_ctx *ctx,\n\t\t\t\tstruct cryp_device_data **device_data)\n{\n\tint ret;\n\tstruct klist_iter device_iterator;\n\tstruct klist_node *device_node;\n\tstruct cryp_device_data *local_device_data = NULL;\n\tpr_debug(DEV_DBG_NAME \" [%s]\", __func__);\n\n\t/* Wait until a device is available */\n\tret = down_interruptible(&driver_data.device_allocation);\n\tif (ret)\n\t\treturn ret;  /* Interrupted */\n\n\t/* Select a device */\n\tklist_iter_init(&driver_data.device_list, &device_iterator);\n\n\tdevice_node = klist_next(&device_iterator);\n\twhile (device_node) {\n\t\tlocal_device_data = container_of(device_node,\n\t\t\t\t\t   struct cryp_device_data, list_node);\n\t\tspin_lock(&local_device_data->ctx_lock);\n\t\t/* current_ctx allocates a device, NULL = unallocated */\n\t\tif (local_device_data->current_ctx) {\n\t\t\tdevice_node = klist_next(&device_iterator);\n\t\t} else {\n\t\t\tlocal_device_data->current_ctx = ctx;\n\t\t\tctx->device = local_device_data;\n\t\t\tspin_unlock(&local_device_data->ctx_lock);\n\t\t\tbreak;\n\t\t}\n\t\tspin_unlock(&local_device_data->ctx_lock);\n\t}\n\tklist_iter_exit(&device_iterator);\n\n\tif (!device_node) {\n\t\t/**\n\t\t * No free device found.\n\t\t * Since we allocated a device with down_interruptible, this\n\t\t * should not be able to happen.\n\t\t * Number of available devices, which are contained in\n\t\t * device_allocation, is therefore decremented by not doing\n\t\t * an up(device_allocation).\n\t\t */\n\t\treturn -EBUSY;\n\t}\n\n\t*device_data = local_device_data;\n\n\treturn 0;\n}\n\nstatic void cryp_dma_setup_channel(struct cryp_device_data *device_data,\n\t\t\t\t   struct device *dev)\n{\n\tstruct dma_slave_config mem2cryp = {\n\t\t.direction = DMA_MEM_TO_DEV,\n\t\t.dst_addr = device_data->phybase + CRYP_DMA_TX_FIFO,\n\t\t.dst_addr_width = DMA_SLAVE_BUSWIDTH_2_BYTES,\n\t\t.dst_maxburst = 4,\n        };\n\tstruct dma_slave_config cryp2mem = {\n\t\t.direction = DMA_DEV_TO_MEM,\n\t\t.src_addr = device_data->phybase + CRYP_DMA_RX_FIFO,\n\t\t.src_addr_width = DMA_SLAVE_BUSWIDTH_2_BYTES,\n\t\t.src_maxburst = 4,\n        };\n\n\tdma_cap_zero(device_data->dma.mask);\n\tdma_cap_set(DMA_SLAVE, device_data->dma.mask);\n\n\tdevice_data->dma.cfg_mem2cryp = mem_to_engine;\n\tdevice_data->dma.chan_mem2cryp =\n\t\tdma_request_channel(device_data->dma.mask,\n\t\t\t\t    stedma40_filter,\n\t\t\t\t    device_data->dma.cfg_mem2cryp);\n\n\tdevice_data->dma.cfg_cryp2mem = engine_to_mem;\n\tdevice_data->dma.chan_cryp2mem =\n\t\tdma_request_channel(device_data->dma.mask,\n\t\t\t\t    stedma40_filter,\n\t\t\t\t    device_data->dma.cfg_cryp2mem);\n\n\tdmaengine_slave_config(device_data->dma.chan_mem2cryp, &mem2cryp);\n\tdmaengine_slave_config(device_data->dma.chan_cryp2mem, &cryp2mem);\n\n\tinit_completion(&device_data->dma.cryp_dma_complete);\n}\n\nstatic void cryp_dma_out_callback(void *data)\n{\n\tstruct cryp_ctx *ctx = (struct cryp_ctx *) data;\n\tdev_dbg(ctx->device->dev, \"[%s]: \", __func__);\n\n\tcomplete(&ctx->device->dma.cryp_dma_complete);\n}\n\nstatic int cryp_set_dma_transfer(struct cryp_ctx *ctx,\n\t\t\t\t struct scatterlist *sg,\n\t\t\t\t int len,\n\t\t\t\t enum dma_data_direction direction)\n{\n\tstruct dma_async_tx_descriptor *desc;\n\tstruct dma_chan *channel = NULL;\n\tdma_cookie_t cookie;\n\n\tdev_dbg(ctx->device->dev, \"[%s]: \", __func__);\n\n\tif (unlikely(!IS_ALIGNED((u32)sg, 4))) {\n\t\tdev_err(ctx->device->dev, \"[%s]: Data in sg list isn't \"\n\t\t\t\"aligned! Addr: 0x%08x\", __func__, (u32)sg);\n\t\treturn -EFAULT;\n\t}\n\n\tswitch (direction) {\n\tcase DMA_TO_DEVICE:\n\t\tchannel = ctx->device->dma.chan_mem2cryp;\n\t\tctx->device->dma.sg_src = sg;\n\t\tctx->device->dma.sg_src_len = dma_map_sg(channel->device->dev,\n\t\t\t\t\t\t ctx->device->dma.sg_src,\n\t\t\t\t\t\t ctx->device->dma.nents_src,\n\t\t\t\t\t\t direction);\n\n\t\tif (!ctx->device->dma.sg_src_len) {\n\t\t\tdev_dbg(ctx->device->dev,\n\t\t\t\t\"[%s]: Could not map the sg list (TO_DEVICE)\",\n\t\t\t\t__func__);\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\tdev_dbg(ctx->device->dev, \"[%s]: Setting up DMA for buffer \"\n\t\t\t\"(TO_DEVICE)\", __func__);\n\n\t\tdesc = dmaengine_prep_slave_sg(channel,\n\t\t\t\tctx->device->dma.sg_src,\n\t\t\t\tctx->device->dma.sg_src_len,\n\t\t\t\tdirection, DMA_CTRL_ACK);\n\t\tbreak;\n\n\tcase DMA_FROM_DEVICE:\n\t\tchannel = ctx->device->dma.chan_cryp2mem;\n\t\tctx->device->dma.sg_dst = sg;\n\t\tctx->device->dma.sg_dst_len = dma_map_sg(channel->device->dev,\n\t\t\t\t\t\t ctx->device->dma.sg_dst,\n\t\t\t\t\t\t ctx->device->dma.nents_dst,\n\t\t\t\t\t\t direction);\n\n\t\tif (!ctx->device->dma.sg_dst_len) {\n\t\t\tdev_dbg(ctx->device->dev,\n\t\t\t\t\"[%s]: Could not map the sg list (FROM_DEVICE)\",\n\t\t\t\t__func__);\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\tdev_dbg(ctx->device->dev, \"[%s]: Setting up DMA for buffer \"\n\t\t\t\"(FROM_DEVICE)\", __func__);\n\n\t\tdesc = dmaengine_prep_slave_sg(channel,\n\t\t\t\tctx->device->dma.sg_dst,\n\t\t\t\tctx->device->dma.sg_dst_len,\n\t\t\t\tdirection,\n\t\t\t\tDMA_CTRL_ACK |\n\t\t\t\tDMA_PREP_INTERRUPT);\n\n\t\tdesc->callback = cryp_dma_out_callback;\n\t\tdesc->callback_param = ctx;\n\t\tbreak;\n\n\tdefault:\n\t\tdev_dbg(ctx->device->dev, \"[%s]: Invalid DMA direction\",\n\t\t\t__func__);\n\t\treturn -EFAULT;\n\t}\n\n\tcookie = dmaengine_submit(desc);\n\tdma_async_issue_pending(channel);\n\n\treturn 0;\n}\n\nstatic void cryp_dma_done(struct cryp_ctx *ctx)\n{\n\tstruct dma_chan *chan;\n\n\tdev_dbg(ctx->device->dev, \"[%s]: \", __func__);\n\n\tchan = ctx->device->dma.chan_mem2cryp;\n\tdmaengine_device_control(chan, DMA_TERMINATE_ALL, 0);\n\tdma_unmap_sg(chan->device->dev, ctx->device->dma.sg_src,\n\t\t     ctx->device->dma.sg_src_len, DMA_TO_DEVICE);\n\n\tchan = ctx->device->dma.chan_cryp2mem;\n\tdmaengine_device_control(chan, DMA_TERMINATE_ALL, 0);\n\tdma_unmap_sg(chan->device->dev, ctx->device->dma.sg_dst,\n\t\t     ctx->device->dma.sg_dst_len, DMA_FROM_DEVICE);\n}\n\nstatic int cryp_dma_write(struct cryp_ctx *ctx, struct scatterlist *sg,\n\t\t\t  int len)\n{\n\tint error = cryp_set_dma_transfer(ctx, sg, len, DMA_TO_DEVICE);\n\tdev_dbg(ctx->device->dev, \"[%s]: \", __func__);\n\n\tif (error) {\n\t\tdev_dbg(ctx->device->dev, \"[%s]: cryp_set_dma_transfer() \"\n\t\t\t\"failed\", __func__);\n\t\treturn error;\n\t}\n\n\treturn len;\n}\n\nstatic int cryp_dma_read(struct cryp_ctx *ctx, struct scatterlist *sg, int len)\n{\n\tint error = cryp_set_dma_transfer(ctx, sg, len, DMA_FROM_DEVICE);\n\tif (error) {\n\t\tdev_dbg(ctx->device->dev, \"[%s]: cryp_set_dma_transfer() \"\n\t\t\t\"failed\", __func__);\n\t\treturn error;\n\t}\n\n\treturn len;\n}\n\nstatic void cryp_polling_mode(struct cryp_ctx *ctx,\n\t\t\t      struct cryp_device_data *device_data)\n{\n\tint len = ctx->blocksize / BYTES_PER_WORD;\n\tint remaining_length = ctx->datalen;\n\tu32 *indata = (u32 *)ctx->indata;\n\tu32 *outdata = (u32 *)ctx->outdata;\n\n\twhile (remaining_length > 0) {\n\t\twritesl(&device_data->base->din, indata, len);\n\t\tindata += len;\n\t\tremaining_length -= (len * BYTES_PER_WORD);\n\t\tcryp_wait_until_done(device_data);\n\n\t\treadsl(&device_data->base->dout, outdata, len);\n\t\toutdata += len;\n\t\tcryp_wait_until_done(device_data);\n\t}\n}\n\nstatic int cryp_disable_power(struct device *dev,\n\t\t\t      struct cryp_device_data *device_data,\n\t\t\t      bool save_device_context)\n{\n\tint ret = 0;\n\n\tdev_dbg(dev, \"[%s]\", __func__);\n\n\tspin_lock(&device_data->power_state_spinlock);\n\tif (!device_data->power_state)\n\t\tgoto out;\n\n\tspin_lock(&device_data->ctx_lock);\n\tif (save_device_context && device_data->current_ctx) {\n\t\tcryp_save_device_context(device_data,\n\t\t\t\t&device_data->current_ctx->dev_ctx,\n\t\t\t\tcryp_mode);\n\t\tdevice_data->restore_dev_ctx = true;\n\t}\n\tspin_unlock(&device_data->ctx_lock);\n\n\tclk_disable(device_data->clk);\n\tret = regulator_disable(device_data->pwr_regulator);\n\tif (ret)\n\t\tdev_err(dev, \"[%s]: \"\n\t\t\t\t\"regulator_disable() failed!\",\n\t\t\t\t__func__);\n\n\tdevice_data->power_state = false;\n\nout:\n\tspin_unlock(&device_data->power_state_spinlock);\n\n\treturn ret;\n}\n\nstatic int cryp_enable_power(\n\t\tstruct device *dev,\n\t\tstruct cryp_device_data *device_data,\n\t\tbool restore_device_context)\n{\n\tint ret = 0;\n\n\tdev_dbg(dev, \"[%s]\", __func__);\n\n\tspin_lock(&device_data->power_state_spinlock);\n\tif (!device_data->power_state) {\n\t\tret = regulator_enable(device_data->pwr_regulator);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"[%s]: regulator_enable() failed!\",\n\t\t\t\t\t__func__);\n\t\t\tgoto out;\n\t\t}\n\n\t\tret = clk_enable(device_data->clk);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"[%s]: clk_enable() failed!\",\n\t\t\t\t\t__func__);\n\t\t\tregulator_disable(device_data->pwr_regulator);\n\t\t\tgoto out;\n\t\t}\n\t\tdevice_data->power_state = true;\n\t}\n\n\tif (device_data->restore_dev_ctx) {\n\t\tspin_lock(&device_data->ctx_lock);\n\t\tif (restore_device_context && device_data->current_ctx) {\n\t\t\tdevice_data->restore_dev_ctx = false;\n\t\t\tcryp_restore_device_context(device_data,\n\t\t\t\t\t&device_data->current_ctx->dev_ctx);\n\t\t}\n\t\tspin_unlock(&device_data->ctx_lock);\n\t}\nout:\n\tspin_unlock(&device_data->power_state_spinlock);\n\n\treturn ret;\n}\n\nstatic int hw_crypt_noxts(struct cryp_ctx *ctx,\n\t\t\t  struct cryp_device_data *device_data)\n{\n\tint ret = 0;\n\n\tconst u8 *indata = ctx->indata;\n\tu8 *outdata = ctx->outdata;\n\tu32 datalen = ctx->datalen;\n\tu32 outlen = datalen;\n\n\tpr_debug(DEV_DBG_NAME \" [%s]\", __func__);\n\n\tctx->outlen = ctx->datalen;\n\n\tif (unlikely(!IS_ALIGNED((u32)indata, 4))) {\n\t\tpr_debug(DEV_DBG_NAME \" [%s]: Data isn't aligned! Addr: \"\n\t\t\t \"0x%08x\", __func__, (u32)indata);\n\t\treturn -EINVAL;\n\t}\n\n\tret = cryp_setup_context(ctx, device_data);\n\n\tif (ret)\n\t\tgoto out;\n\n\tif (cryp_mode == CRYP_MODE_INTERRUPT) {\n\t\tcryp_enable_irq_src(device_data, CRYP_IRQ_SRC_INPUT_FIFO |\n\t\t\t\t    CRYP_IRQ_SRC_OUTPUT_FIFO);\n\n\t\t/*\n\t\t * ctx->outlen is decremented in the cryp_interrupt_handler\n\t\t * function. We had to add cpu_relax() (barrier) to make sure\n\t\t * that gcc didn't optimze away this variable.\n\t\t */\n\t\twhile (ctx->outlen > 0)\n\t\t\tcpu_relax();\n\t} else if (cryp_mode == CRYP_MODE_POLLING ||\n\t\t   cryp_mode == CRYP_MODE_DMA) {\n\t\t/*\n\t\t * The reason for having DMA in this if case is that if we are\n\t\t * running cryp_mode = 2, then we separate DMA routines for\n\t\t * handling cipher/plaintext > blocksize, except when\n\t\t * running the normal CRYPTO_ALG_TYPE_CIPHER, then we still use\n\t\t * the polling mode. Overhead of doing DMA setup eats up the\n\t\t * benefits using it.\n\t\t */\n\t\tcryp_polling_mode(ctx, device_data);\n\t} else {\n\t\tdev_err(ctx->device->dev, \"[%s]: Invalid operation mode!\",\n\t\t\t__func__);\n\t\tret = -EPERM;\n\t\tgoto out;\n\t}\n\n\tcryp_save_device_context(device_data, &ctx->dev_ctx, cryp_mode);\n\tctx->updated = 1;\n\nout:\n\tctx->indata = indata;\n\tctx->outdata = outdata;\n\tctx->datalen = datalen;\n\tctx->outlen = outlen;\n\n\treturn ret;\n}\n\nstatic int get_nents(struct scatterlist *sg, int nbytes)\n{\n\tint nents = 0;\n\n\twhile (nbytes > 0) {\n\t\tnbytes -= sg->length;\n\t\tsg = scatterwalk_sg_next(sg);\n\t\tnents++;\n\t}\n\n\treturn nents;\n}\n\nstatic int ablk_dma_crypt(struct ablkcipher_request *areq)\n{\n\tstruct crypto_ablkcipher *cipher = crypto_ablkcipher_reqtfm(areq);\n\tstruct cryp_ctx *ctx = crypto_ablkcipher_ctx(cipher);\n\tstruct cryp_device_data *device_data;\n\n\tint bytes_written = 0;\n\tint bytes_read = 0;\n\tint ret;\n\n\tpr_debug(DEV_DBG_NAME \" [%s]\", __func__);\n\n\tctx->datalen = areq->nbytes;\n\tctx->outlen = areq->nbytes;\n\n\tret = cryp_get_device_data(ctx, &device_data);\n\tif (ret)\n\t\treturn ret;\n\n\tret = cryp_setup_context(ctx, device_data);\n\tif (ret)\n\t\tgoto out;\n\n\t/* We have the device now, so store the nents in the dma struct. */\n\tctx->device->dma.nents_src = get_nents(areq->src, ctx->datalen);\n\tctx->device->dma.nents_dst = get_nents(areq->dst, ctx->outlen);\n\n\t/* Enable DMA in- and output. */\n\tcryp_configure_for_dma(device_data, CRYP_DMA_ENABLE_BOTH_DIRECTIONS);\n\n\tbytes_written = cryp_dma_write(ctx, areq->src, ctx->datalen);\n\tbytes_read = cryp_dma_read(ctx, areq->dst, bytes_written);\n\n\twait_for_completion(&ctx->device->dma.cryp_dma_complete);\n\tcryp_dma_done(ctx);\n\n\tcryp_save_device_context(device_data, &ctx->dev_ctx, cryp_mode);\n\tctx->updated = 1;\n\nout:\n\tspin_lock(&device_data->ctx_lock);\n\tdevice_data->current_ctx = NULL;\n\tctx->device = NULL;\n\tspin_unlock(&device_data->ctx_lock);\n\n\t/*\n\t * The down_interruptible part for this semaphore is called in\n\t * cryp_get_device_data.\n\t */\n\tup(&driver_data.device_allocation);\n\n\tif (unlikely(bytes_written != bytes_read))\n\t\treturn -EPERM;\n\n\treturn 0;\n}\n\nstatic int ablk_crypt(struct ablkcipher_request *areq)\n{\n\tstruct ablkcipher_walk walk;\n\tstruct crypto_ablkcipher *cipher = crypto_ablkcipher_reqtfm(areq);\n\tstruct cryp_ctx *ctx = crypto_ablkcipher_ctx(cipher);\n\tstruct cryp_device_data *device_data;\n\tunsigned long src_paddr;\n\tunsigned long dst_paddr;\n\tint ret;\n\tint nbytes;\n\n\tpr_debug(DEV_DBG_NAME \" [%s]\", __func__);\n\n\tret = cryp_get_device_data(ctx, &device_data);\n\tif (ret)\n\t\tgoto out;\n\n\tablkcipher_walk_init(&walk, areq->dst, areq->src, areq->nbytes);\n\tret = ablkcipher_walk_phys(areq, &walk);\n\n\tif (ret) {\n\t\tpr_err(DEV_DBG_NAME \"[%s]: ablkcipher_walk_phys() failed!\",\n\t\t\t__func__);\n\t\tgoto out;\n\t}\n\n\twhile ((nbytes = walk.nbytes) > 0) {\n\t\tctx->iv = walk.iv;\n\t\tsrc_paddr = (page_to_phys(walk.src.page) + walk.src.offset);\n\t\tctx->indata = phys_to_virt(src_paddr);\n\n\t\tdst_paddr = (page_to_phys(walk.dst.page) + walk.dst.offset);\n\t\tctx->outdata = phys_to_virt(dst_paddr);\n\n\t\tctx->datalen = nbytes - (nbytes % ctx->blocksize);\n\n\t\tret = hw_crypt_noxts(ctx, device_data);\n\t\tif (ret)\n\t\t\tgoto out;\n\n\t\tnbytes -= ctx->datalen;\n\t\tret = ablkcipher_walk_done(areq, &walk, nbytes);\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\tablkcipher_walk_complete(&walk);\n\nout:\n\t/* Release the device */\n\tspin_lock(&device_data->ctx_lock);\n\tdevice_data->current_ctx = NULL;\n\tctx->device = NULL;\n\tspin_unlock(&device_data->ctx_lock);\n\n\t/*\n\t * The down_interruptible part for this semaphore is called in\n\t * cryp_get_device_data.\n\t */\n\tup(&driver_data.device_allocation);\n\n\treturn ret;\n}\n\nstatic int aes_ablkcipher_setkey(struct crypto_ablkcipher *cipher,\n\t\t\t\t const u8 *key, unsigned int keylen)\n{\n\tstruct cryp_ctx *ctx = crypto_ablkcipher_ctx(cipher);\n\tu32 *flags = &cipher->base.crt_flags;\n\n\tpr_debug(DEV_DBG_NAME \" [%s]\", __func__);\n\n\tswitch (keylen) {\n\tcase AES_KEYSIZE_128:\n\t\tctx->config.keysize = CRYP_KEY_SIZE_128;\n\t\tbreak;\n\n\tcase AES_KEYSIZE_192:\n\t\tctx->config.keysize = CRYP_KEY_SIZE_192;\n\t\tbreak;\n\n\tcase AES_KEYSIZE_256:\n\t\tctx->config.keysize = CRYP_KEY_SIZE_256;\n\t\tbreak;\n\n\tdefault:\n\t\tpr_err(DEV_DBG_NAME \"[%s]: Unknown keylen!\", __func__);\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(ctx->key, key, keylen);\n\tctx->keylen = keylen;\n\n\tctx->updated = 0;\n\n\treturn 0;\n}\n\nstatic int des_ablkcipher_setkey(struct crypto_ablkcipher *cipher,\n\t\t\t\t const u8 *key, unsigned int keylen)\n{\n\tstruct cryp_ctx *ctx = crypto_ablkcipher_ctx(cipher);\n\tu32 *flags = &cipher->base.crt_flags;\n\tu32 tmp[DES_EXPKEY_WORDS];\n\tint ret;\n\n\tpr_debug(DEV_DBG_NAME \" [%s]\", __func__);\n\tif (keylen != DES_KEY_SIZE) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\tpr_debug(DEV_DBG_NAME \" [%s]: CRYPTO_TFM_RES_BAD_KEY_LEN\",\n\t\t\t\t__func__);\n\t\treturn -EINVAL;\n\t}\n\n\tret = des_ekey(tmp, key);\n\tif (unlikely(ret == 0) && (*flags & CRYPTO_TFM_REQ_WEAK_KEY)) {\n\t\t*flags |= CRYPTO_TFM_RES_WEAK_KEY;\n\t\tpr_debug(DEV_DBG_NAME \" [%s]: CRYPTO_TFM_REQ_WEAK_KEY\",\n\t\t\t\t__func__);\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(ctx->key, key, keylen);\n\tctx->keylen = keylen;\n\n\tctx->updated = 0;\n\treturn 0;\n}\n\nstatic int des3_ablkcipher_setkey(struct crypto_ablkcipher *cipher,\n\t\t\t\t  const u8 *key, unsigned int keylen)\n{\n\tstruct cryp_ctx *ctx = crypto_ablkcipher_ctx(cipher);\n\tu32 *flags = &cipher->base.crt_flags;\n\tconst u32 *K = (const u32 *)key;\n\tu32 tmp[DES3_EDE_EXPKEY_WORDS];\n\tint i, ret;\n\n\tpr_debug(DEV_DBG_NAME \" [%s]\", __func__);\n\tif (keylen != DES3_EDE_KEY_SIZE) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\tpr_debug(DEV_DBG_NAME \" [%s]: CRYPTO_TFM_RES_BAD_KEY_LEN\",\n\t\t\t\t__func__);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Checking key interdependency for weak key detection. */\n\tif (unlikely(!((K[0] ^ K[2]) | (K[1] ^ K[3])) ||\n\t\t\t\t!((K[2] ^ K[4]) | (K[3] ^ K[5]))) &&\n\t\t\t(*flags & CRYPTO_TFM_REQ_WEAK_KEY)) {\n\t\t*flags |= CRYPTO_TFM_RES_WEAK_KEY;\n\t\tpr_debug(DEV_DBG_NAME \" [%s]: CRYPTO_TFM_REQ_WEAK_KEY\",\n\t\t\t\t__func__);\n\t\treturn -EINVAL;\n\t}\n\tfor (i = 0; i < 3; i++) {\n\t\tret = des_ekey(tmp, key + i*DES_KEY_SIZE);\n\t\tif (unlikely(ret == 0) && (*flags & CRYPTO_TFM_REQ_WEAK_KEY)) {\n\t\t\t*flags |= CRYPTO_TFM_RES_WEAK_KEY;\n\t\t\tpr_debug(DEV_DBG_NAME \" [%s]: \"\n\t\t\t\t\t\"CRYPTO_TFM_REQ_WEAK_KEY\", __func__);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tmemcpy(ctx->key, key, keylen);\n\tctx->keylen = keylen;\n\n\tctx->updated = 0;\n\treturn 0;\n}\n\nstatic int cryp_blk_encrypt(struct ablkcipher_request *areq)\n{\n\tstruct crypto_ablkcipher *cipher = crypto_ablkcipher_reqtfm(areq);\n\tstruct cryp_ctx *ctx = crypto_ablkcipher_ctx(cipher);\n\n\tpr_debug(DEV_DBG_NAME \" [%s]\", __func__);\n\n\tctx->config.algodir = CRYP_ALGORITHM_ENCRYPT;\n\n\t/*\n\t * DMA does not work for DES due to a hw bug */\n\tif (cryp_mode == CRYP_MODE_DMA && mode_is_aes(ctx->config.algomode))\n\t\treturn ablk_dma_crypt(areq);\n\n\t/* For everything except DMA, we run the non DMA version. */\n\treturn ablk_crypt(areq);\n}\n\nstatic int cryp_blk_decrypt(struct ablkcipher_request *areq)\n{\n\tstruct crypto_ablkcipher *cipher = crypto_ablkcipher_reqtfm(areq);\n\tstruct cryp_ctx *ctx = crypto_ablkcipher_ctx(cipher);\n\n\tpr_debug(DEV_DBG_NAME \" [%s]\", __func__);\n\n\tctx->config.algodir = CRYP_ALGORITHM_DECRYPT;\n\n\t/* DMA does not work for DES due to a hw bug */\n\tif (cryp_mode == CRYP_MODE_DMA && mode_is_aes(ctx->config.algomode))\n\t\treturn ablk_dma_crypt(areq);\n\n\t/* For everything except DMA, we run the non DMA version. */\n\treturn ablk_crypt(areq);\n}\n\nstruct cryp_algo_template {\n\tenum cryp_algo_mode algomode;\n\tstruct crypto_alg crypto;\n};\n\nstatic int cryp_cra_init(struct crypto_tfm *tfm)\n{\n\tstruct cryp_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_alg *alg = tfm->__crt_alg;\n\tstruct cryp_algo_template *cryp_alg = container_of(alg,\n\t\t\tstruct cryp_algo_template,\n\t\t\tcrypto);\n\n\tctx->config.algomode = cryp_alg->algomode;\n\tctx->blocksize = crypto_tfm_alg_blocksize(tfm);\n\n\treturn 0;\n}\n\nstatic struct cryp_algo_template cryp_algs[] = {\n\t{\n\t\t.algomode = CRYP_ALGO_AES_ECB,\n\t\t.crypto = {\n\t\t\t.cra_name = \"aes\",\n\t\t\t.cra_driver_name = \"aes-ux500\",\n\t\t\t.cra_priority =\t300,\n\t\t\t.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\n\t\t\t\t\tCRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct cryp_ctx),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_type = &crypto_ablkcipher_type,\n\t\t\t.cra_init = cryp_cra_init,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_u = {\n\t\t\t\t.ablkcipher = {\n\t\t\t\t\t.min_keysize = AES_MIN_KEY_SIZE,\n\t\t\t\t\t.max_keysize = AES_MAX_KEY_SIZE,\n\t\t\t\t\t.setkey = aes_ablkcipher_setkey,\n\t\t\t\t\t.encrypt = cryp_blk_encrypt,\n\t\t\t\t\t.decrypt = cryp_blk_decrypt\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\t.algomode = CRYP_ALGO_AES_ECB,\n\t\t.crypto = {\n\t\t\t.cra_name = \"ecb(aes)\",\n\t\t\t.cra_driver_name = \"ecb-aes-ux500\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\n\t\t\t\t\tCRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct cryp_ctx),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_type = &crypto_ablkcipher_type,\n\t\t\t.cra_init = cryp_cra_init,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_u = {\n\t\t\t\t.ablkcipher = {\n\t\t\t\t\t.min_keysize = AES_MIN_KEY_SIZE,\n\t\t\t\t\t.max_keysize = AES_MAX_KEY_SIZE,\n\t\t\t\t\t.setkey = aes_ablkcipher_setkey,\n\t\t\t\t\t.encrypt = cryp_blk_encrypt,\n\t\t\t\t\t.decrypt = cryp_blk_decrypt,\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\t.algomode = CRYP_ALGO_AES_CBC,\n\t\t.crypto = {\n\t\t\t.cra_name = \"cbc(aes)\",\n\t\t\t.cra_driver_name = \"cbc-aes-ux500\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\n\t\t\t\t\tCRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct cryp_ctx),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_type = &crypto_ablkcipher_type,\n\t\t\t.cra_init = cryp_cra_init,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_u = {\n\t\t\t\t.ablkcipher = {\n\t\t\t\t\t.min_keysize = AES_MIN_KEY_SIZE,\n\t\t\t\t\t.max_keysize = AES_MAX_KEY_SIZE,\n\t\t\t\t\t.setkey = aes_ablkcipher_setkey,\n\t\t\t\t\t.encrypt = cryp_blk_encrypt,\n\t\t\t\t\t.decrypt = cryp_blk_decrypt,\n\t\t\t\t\t.ivsize = AES_BLOCK_SIZE,\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\t.algomode = CRYP_ALGO_AES_CTR,\n\t\t.crypto = {\n\t\t\t.cra_name = \"ctr(aes)\",\n\t\t\t.cra_driver_name = \"ctr-aes-ux500\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\n\t\t\t\t\t\tCRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct cryp_ctx),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_type = &crypto_ablkcipher_type,\n\t\t\t.cra_init = cryp_cra_init,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_u = {\n\t\t\t\t.ablkcipher = {\n\t\t\t\t\t.min_keysize = AES_MIN_KEY_SIZE,\n\t\t\t\t\t.max_keysize = AES_MAX_KEY_SIZE,\n\t\t\t\t\t.setkey = aes_ablkcipher_setkey,\n\t\t\t\t\t.encrypt = cryp_blk_encrypt,\n\t\t\t\t\t.decrypt = cryp_blk_decrypt,\n\t\t\t\t\t.ivsize = AES_BLOCK_SIZE,\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\t.algomode = CRYP_ALGO_DES_ECB,\n\t\t.crypto = {\n\t\t\t.cra_name = \"des\",\n\t\t\t.cra_driver_name = \"des-ux500\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\n\t\t\t\t\t\tCRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize = DES_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct cryp_ctx),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_type = &crypto_ablkcipher_type,\n\t\t\t.cra_init = cryp_cra_init,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_u = {\n\t\t\t\t.ablkcipher = {\n\t\t\t\t\t.min_keysize = DES_KEY_SIZE,\n\t\t\t\t\t.max_keysize = DES_KEY_SIZE,\n\t\t\t\t\t.setkey = des_ablkcipher_setkey,\n\t\t\t\t\t.encrypt = cryp_blk_encrypt,\n\t\t\t\t\t.decrypt = cryp_blk_decrypt\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t},\n\t{\n\t\t.algomode = CRYP_ALGO_TDES_ECB,\n\t\t.crypto = {\n\t\t\t.cra_name = \"des3_ede\",\n\t\t\t.cra_driver_name = \"des3_ede-ux500\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\n\t\t\t\t\t\tCRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize = DES3_EDE_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct cryp_ctx),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_type = &crypto_ablkcipher_type,\n\t\t\t.cra_init = cryp_cra_init,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_u = {\n\t\t\t\t.ablkcipher = {\n\t\t\t\t\t.min_keysize = DES3_EDE_KEY_SIZE,\n\t\t\t\t\t.max_keysize = DES3_EDE_KEY_SIZE,\n\t\t\t\t\t.setkey = des_ablkcipher_setkey,\n\t\t\t\t\t.encrypt = cryp_blk_encrypt,\n\t\t\t\t\t.decrypt = cryp_blk_decrypt\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\t.algomode = CRYP_ALGO_DES_ECB,\n\t\t.crypto = {\n\t\t\t.cra_name = \"ecb(des)\",\n\t\t\t.cra_driver_name = \"ecb-des-ux500\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\n\t\t\t\t\tCRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize = DES_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct cryp_ctx),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_type = &crypto_ablkcipher_type,\n\t\t\t.cra_init = cryp_cra_init,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_u = {\n\t\t\t\t.ablkcipher = {\n\t\t\t\t\t.min_keysize = DES_KEY_SIZE,\n\t\t\t\t\t.max_keysize = DES_KEY_SIZE,\n\t\t\t\t\t.setkey = des_ablkcipher_setkey,\n\t\t\t\t\t.encrypt = cryp_blk_encrypt,\n\t\t\t\t\t.decrypt = cryp_blk_decrypt,\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\t.algomode = CRYP_ALGO_TDES_ECB,\n\t\t.crypto = {\n\t\t\t.cra_name = \"ecb(des3_ede)\",\n\t\t\t.cra_driver_name = \"ecb-des3_ede-ux500\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\n\t\t\t\t\tCRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize = DES3_EDE_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct cryp_ctx),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_type = &crypto_ablkcipher_type,\n\t\t\t.cra_init = cryp_cra_init,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_u = {\n\t\t\t\t.ablkcipher = {\n\t\t\t\t\t.min_keysize = DES3_EDE_KEY_SIZE,\n\t\t\t\t\t.max_keysize = DES3_EDE_KEY_SIZE,\n\t\t\t\t\t.setkey = des3_ablkcipher_setkey,\n\t\t\t\t\t.encrypt = cryp_blk_encrypt,\n\t\t\t\t\t.decrypt = cryp_blk_decrypt,\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\t.algomode = CRYP_ALGO_DES_CBC,\n\t\t.crypto = {\n\t\t\t.cra_name = \"cbc(des)\",\n\t\t\t.cra_driver_name = \"cbc-des-ux500\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\n\t\t\t\t\tCRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize = DES_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct cryp_ctx),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_type = &crypto_ablkcipher_type,\n\t\t\t.cra_init = cryp_cra_init,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_u = {\n\t\t\t\t.ablkcipher = {\n\t\t\t\t\t.min_keysize = DES_KEY_SIZE,\n\t\t\t\t\t.max_keysize = DES_KEY_SIZE,\n\t\t\t\t\t.setkey = des_ablkcipher_setkey,\n\t\t\t\t\t.encrypt = cryp_blk_encrypt,\n\t\t\t\t\t.decrypt = cryp_blk_decrypt,\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\t.algomode = CRYP_ALGO_TDES_CBC,\n\t\t.crypto = {\n\t\t\t.cra_name = \"cbc(des3_ede)\",\n\t\t\t.cra_driver_name = \"cbc-des3_ede-ux500\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\n\t\t\t\t\tCRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize = DES3_EDE_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct cryp_ctx),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_type = &crypto_ablkcipher_type,\n\t\t\t.cra_init = cryp_cra_init,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_u = {\n\t\t\t\t.ablkcipher = {\n\t\t\t\t\t.min_keysize = DES3_EDE_KEY_SIZE,\n\t\t\t\t\t.max_keysize = DES3_EDE_KEY_SIZE,\n\t\t\t\t\t.setkey = des3_ablkcipher_setkey,\n\t\t\t\t\t.encrypt = cryp_blk_encrypt,\n\t\t\t\t\t.decrypt = cryp_blk_decrypt,\n\t\t\t\t\t.ivsize = DES3_EDE_BLOCK_SIZE,\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n};\n\n/**\n * cryp_algs_register_all -\n */\nstatic int cryp_algs_register_all(void)\n{\n\tint ret;\n\tint i;\n\tint count;\n\n\tpr_debug(\"[%s]\", __func__);\n\n\tfor (i = 0; i < ARRAY_SIZE(cryp_algs); i++) {\n\t\tret = crypto_register_alg(&cryp_algs[i].crypto);\n\t\tif (ret) {\n\t\t\tcount = i;\n\t\t\tpr_err(\"[%s] alg registration failed\",\n\t\t\t\t\tcryp_algs[i].crypto.cra_driver_name);\n\t\t\tgoto unreg;\n\t\t}\n\t}\n\treturn 0;\nunreg:\n\tfor (i = 0; i < count; i++)\n\t\tcrypto_unregister_alg(&cryp_algs[i].crypto);\n\treturn ret;\n}\n\n/**\n * cryp_algs_unregister_all -\n */\nstatic void cryp_algs_unregister_all(void)\n{\n\tint i;\n\n\tpr_debug(DEV_DBG_NAME \" [%s]\", __func__);\n\n\tfor (i = 0; i < ARRAY_SIZE(cryp_algs); i++)\n\t\tcrypto_unregister_alg(&cryp_algs[i].crypto);\n}\n\nstatic int ux500_cryp_probe(struct platform_device *pdev)\n{\n\tint ret;\n\tint cryp_error = 0;\n\tstruct resource *res = NULL;\n\tstruct resource *res_irq = NULL;\n\tstruct cryp_device_data *device_data;\n\tstruct cryp_protection_config prot = {\n\t\t.privilege_access = CRYP_STATE_ENABLE\n\t};\n\tstruct device *dev = &pdev->dev;\n\n\tdev_dbg(dev, \"[%s]\", __func__);\n\tdevice_data = kzalloc(sizeof(struct cryp_device_data), GFP_ATOMIC);\n\tif (!device_data) {\n\t\tdev_err(dev, \"[%s]: kzalloc() failed!\", __func__);\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tdevice_data->dev = dev;\n\tdevice_data->current_ctx = NULL;\n\n\t/* Grab the DMA configuration from platform data. */\n\tmem_to_engine = &((struct cryp_platform_data *)\n\t\t\t dev->platform_data)->mem_to_engine;\n\tengine_to_mem = &((struct cryp_platform_data *)\n\t\t\t dev->platform_data)->engine_to_mem;\n\n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tif (!res) {\n\t\tdev_err(dev, \"[%s]: platform_get_resource() failed\",\n\t\t\t\t__func__);\n\t\tret = -ENODEV;\n\t\tgoto out_kfree;\n\t}\n\n\tres = request_mem_region(res->start, resource_size(res), pdev->name);\n\tif (res == NULL) {\n\t\tdev_err(dev, \"[%s]: request_mem_region() failed\",\n\t\t\t\t__func__);\n\t\tret = -EBUSY;\n\t\tgoto out_kfree;\n\t}\n\n\tdevice_data->phybase = res->start;\n\tdevice_data->base = ioremap(res->start, resource_size(res));\n\tif (!device_data->base) {\n\t\tdev_err(dev, \"[%s]: ioremap failed!\", __func__);\n\t\tret = -ENOMEM;\n\t\tgoto out_free_mem;\n\t}\n\n\tspin_lock_init(&device_data->ctx_lock);\n\tspin_lock_init(&device_data->power_state_spinlock);\n\n\t/* Enable power for CRYP hardware block */\n\tdevice_data->pwr_regulator = regulator_get(&pdev->dev, \"v-ape\");\n\tif (IS_ERR(device_data->pwr_regulator)) {\n\t\tdev_err(dev, \"[%s]: could not get cryp regulator\", __func__);\n\t\tret = PTR_ERR(device_data->pwr_regulator);\n\t\tdevice_data->pwr_regulator = NULL;\n\t\tgoto out_unmap;\n\t}\n\n\t/* Enable the clk for CRYP hardware block */\n\tdevice_data->clk = clk_get(&pdev->dev, NULL);\n\tif (IS_ERR(device_data->clk)) {\n\t\tdev_err(dev, \"[%s]: clk_get() failed!\", __func__);\n\t\tret = PTR_ERR(device_data->clk);\n\t\tgoto out_regulator;\n\t}\n\n\tret = clk_prepare(device_data->clk);\n\tif (ret) {\n\t\tdev_err(dev, \"[%s]: clk_prepare() failed!\", __func__);\n\t\tgoto out_clk;\n\t}\n\n\t/* Enable device power (and clock) */\n\tret = cryp_enable_power(device_data->dev, device_data, false);\n\tif (ret) {\n\t\tdev_err(dev, \"[%s]: cryp_enable_power() failed!\", __func__);\n\t\tgoto out_clk_unprepare;\n\t}\n\n\tcryp_error = cryp_check(device_data);\n\tif (cryp_error != 0) {\n\t\tdev_err(dev, \"[%s]: cryp_init() failed!\", __func__);\n\t\tret = -EINVAL;\n\t\tgoto out_power;\n\t}\n\n\tcryp_error = cryp_configure_protection(device_data, &prot);\n\tif (cryp_error != 0) {\n\t\tdev_err(dev, \"[%s]: cryp_configure_protection() failed!\",\n\t\t\t__func__);\n\t\tret = -EINVAL;\n\t\tgoto out_power;\n\t}\n\n\tres_irq = platform_get_resource(pdev, IORESOURCE_IRQ, 0);\n\tif (!res_irq) {\n\t\tdev_err(dev, \"[%s]: IORESOURCE_IRQ unavailable\",\n\t\t\t__func__);\n\t\tret = -ENODEV;\n\t\tgoto out_power;\n\t}\n\n\tret = request_irq(res_irq->start,\n\t\t\t  cryp_interrupt_handler,\n\t\t\t  0,\n\t\t\t  \"cryp1\",\n\t\t\t  device_data);\n\tif (ret) {\n\t\tdev_err(dev, \"[%s]: Unable to request IRQ\", __func__);\n\t\tgoto out_power;\n\t}\n\n\tif (cryp_mode == CRYP_MODE_DMA)\n\t\tcryp_dma_setup_channel(device_data, dev);\n\n\tplatform_set_drvdata(pdev, device_data);\n\n\t/* Put the new device into the device list... */\n\tklist_add_tail(&device_data->list_node, &driver_data.device_list);\n\n\t/* ... and signal that a new device is available. */\n\tup(&driver_data.device_allocation);\n\n\tatomic_set(&session_id, 1);\n\n\tret = cryp_algs_register_all();\n\tif (ret) {\n\t\tdev_err(dev, \"[%s]: cryp_algs_register_all() failed!\",\n\t\t\t__func__);\n\t\tgoto out_power;\n\t}\n\n\tdev_info(dev, \"successfully registered\\n\");\n\n\treturn 0;\n\nout_power:\n\tcryp_disable_power(device_data->dev, device_data, false);\n\nout_clk_unprepare:\n\tclk_unprepare(device_data->clk);\n\nout_clk:\n\tclk_put(device_data->clk);\n\nout_regulator:\n\tregulator_put(device_data->pwr_regulator);\n\nout_unmap:\n\tiounmap(device_data->base);\n\nout_free_mem:\n\trelease_mem_region(res->start, resource_size(res));\n\nout_kfree:\n\tkfree(device_data);\nout:\n\treturn ret;\n}\n\nstatic int ux500_cryp_remove(struct platform_device *pdev)\n{\n\tstruct resource *res = NULL;\n\tstruct resource *res_irq = NULL;\n\tstruct cryp_device_data *device_data;\n\n\tdev_dbg(&pdev->dev, \"[%s]\", __func__);\n\tdevice_data = platform_get_drvdata(pdev);\n\tif (!device_data) {\n\t\tdev_err(&pdev->dev, \"[%s]: platform_get_drvdata() failed!\",\n\t\t\t__func__);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* Try to decrease the number of available devices. */\n\tif (down_trylock(&driver_data.device_allocation))\n\t\treturn -EBUSY;\n\n\t/* Check that the device is free */\n\tspin_lock(&device_data->ctx_lock);\n\t/* current_ctx allocates a device, NULL = unallocated */\n\tif (device_data->current_ctx) {\n\t\t/* The device is busy */\n\t\tspin_unlock(&device_data->ctx_lock);\n\t\t/* Return the device to the pool. */\n\t\tup(&driver_data.device_allocation);\n\t\treturn -EBUSY;\n\t}\n\n\tspin_unlock(&device_data->ctx_lock);\n\n\t/* Remove the device from the list */\n\tif (klist_node_attached(&device_data->list_node))\n\t\tklist_remove(&device_data->list_node);\n\n\t/* If this was the last device, remove the services */\n\tif (list_empty(&driver_data.device_list.k_list))\n\t\tcryp_algs_unregister_all();\n\n\tres_irq = platform_get_resource(pdev, IORESOURCE_IRQ, 0);\n\tif (!res_irq)\n\t\tdev_err(&pdev->dev, \"[%s]: IORESOURCE_IRQ, unavailable\",\n\t\t\t__func__);\n\telse {\n\t\tdisable_irq(res_irq->start);\n\t\tfree_irq(res_irq->start, device_data);\n\t}\n\n\tif (cryp_disable_power(&pdev->dev, device_data, false))\n\t\tdev_err(&pdev->dev, \"[%s]: cryp_disable_power() failed\",\n\t\t\t__func__);\n\n\tclk_unprepare(device_data->clk);\n\tclk_put(device_data->clk);\n\tregulator_put(device_data->pwr_regulator);\n\n\tiounmap(device_data->base);\n\n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tif (res)\n\t\trelease_mem_region(res->start, resource_size(res));\n\n\tkfree(device_data);\n\n\treturn 0;\n}\n\nstatic void ux500_cryp_shutdown(struct platform_device *pdev)\n{\n\tstruct resource *res_irq = NULL;\n\tstruct cryp_device_data *device_data;\n\n\tdev_dbg(&pdev->dev, \"[%s]\", __func__);\n\n\tdevice_data = platform_get_drvdata(pdev);\n\tif (!device_data) {\n\t\tdev_err(&pdev->dev, \"[%s]: platform_get_drvdata() failed!\",\n\t\t\t__func__);\n\t\treturn;\n\t}\n\n\t/* Check that the device is free */\n\tspin_lock(&device_data->ctx_lock);\n\t/* current_ctx allocates a device, NULL = unallocated */\n\tif (!device_data->current_ctx) {\n\t\tif (down_trylock(&driver_data.device_allocation))\n\t\t\tdev_dbg(&pdev->dev, \"[%s]: Cryp still in use!\"\n\t\t\t\t\"Shutting down anyway...\", __func__);\n\t\t/**\n\t\t * (Allocate the device)\n\t\t * Need to set this to non-null (dummy) value,\n\t\t * to avoid usage if context switching.\n\t\t */\n\t\tdevice_data->current_ctx++;\n\t}\n\tspin_unlock(&device_data->ctx_lock);\n\n\t/* Remove the device from the list */\n\tif (klist_node_attached(&device_data->list_node))\n\t\tklist_remove(&device_data->list_node);\n\n\t/* If this was the last device, remove the services */\n\tif (list_empty(&driver_data.device_list.k_list))\n\t\tcryp_algs_unregister_all();\n\n\tres_irq = platform_get_resource(pdev, IORESOURCE_IRQ, 0);\n\tif (!res_irq)\n\t\tdev_err(&pdev->dev, \"[%s]: IORESOURCE_IRQ, unavailable\",\n\t\t\t__func__);\n\telse {\n\t\tdisable_irq(res_irq->start);\n\t\tfree_irq(res_irq->start, device_data);\n\t}\n\n\tif (cryp_disable_power(&pdev->dev, device_data, false))\n\t\tdev_err(&pdev->dev, \"[%s]: cryp_disable_power() failed\",\n\t\t\t__func__);\n\n}\n\n#ifdef CONFIG_PM_SLEEP\nstatic int ux500_cryp_suspend(struct device *dev)\n{\n\tint ret;\n\tstruct platform_device *pdev = to_platform_device(dev);\n\tstruct cryp_device_data *device_data;\n\tstruct resource *res_irq;\n\tstruct cryp_ctx *temp_ctx = NULL;\n\n\tdev_dbg(dev, \"[%s]\", __func__);\n\n\t/* Handle state? */\n\tdevice_data = platform_get_drvdata(pdev);\n\tif (!device_data) {\n\t\tdev_err(dev, \"[%s]: platform_get_drvdata() failed!\", __func__);\n\t\treturn -ENOMEM;\n\t}\n\n\tres_irq = platform_get_resource(pdev, IORESOURCE_IRQ, 0);\n\tif (!res_irq)\n\t\tdev_err(dev, \"[%s]: IORESOURCE_IRQ, unavailable\", __func__);\n\telse\n\t\tdisable_irq(res_irq->start);\n\n\tspin_lock(&device_data->ctx_lock);\n\tif (!device_data->current_ctx)\n\t\tdevice_data->current_ctx++;\n\tspin_unlock(&device_data->ctx_lock);\n\n\tif (device_data->current_ctx == ++temp_ctx) {\n\t\tif (down_interruptible(&driver_data.device_allocation))\n\t\t\tdev_dbg(dev, \"[%s]: down_interruptible() failed\",\n\t\t\t\t__func__);\n\t\tret = cryp_disable_power(dev, device_data, false);\n\n\t} else\n\t\tret = cryp_disable_power(dev, device_data, true);\n\n\tif (ret)\n\t\tdev_err(dev, \"[%s]: cryp_disable_power()\", __func__);\n\n\treturn ret;\n}\n\nstatic int ux500_cryp_resume(struct device *dev)\n{\n\tint ret = 0;\n\tstruct platform_device *pdev = to_platform_device(dev);\n\tstruct cryp_device_data *device_data;\n\tstruct resource *res_irq;\n\tstruct cryp_ctx *temp_ctx = NULL;\n\n\tdev_dbg(dev, \"[%s]\", __func__);\n\n\tdevice_data = platform_get_drvdata(pdev);\n\tif (!device_data) {\n\t\tdev_err(dev, \"[%s]: platform_get_drvdata() failed!\", __func__);\n\t\treturn -ENOMEM;\n\t}\n\n\tspin_lock(&device_data->ctx_lock);\n\tif (device_data->current_ctx == ++temp_ctx)\n\t\tdevice_data->current_ctx = NULL;\n\tspin_unlock(&device_data->ctx_lock);\n\n\n\tif (!device_data->current_ctx)\n\t\tup(&driver_data.device_allocation);\n\telse\n\t\tret = cryp_enable_power(dev, device_data, true);\n\n\tif (ret)\n\t\tdev_err(dev, \"[%s]: cryp_enable_power() failed!\", __func__);\n\telse {\n\t\tres_irq = platform_get_resource(pdev, IORESOURCE_IRQ, 0);\n\t\tif (res_irq)\n\t\t\tenable_irq(res_irq->start);\n\t}\n\n\treturn ret;\n}\n#endif\n\nstatic SIMPLE_DEV_PM_OPS(ux500_cryp_pm, ux500_cryp_suspend, ux500_cryp_resume);\n\nstatic const struct of_device_id ux500_cryp_match[] = {\n        { .compatible = \"stericsson,ux500-cryp\" },\n        { },\n};\n\nstatic struct platform_driver cryp_driver = {\n\t.probe  = ux500_cryp_probe,\n\t.remove = ux500_cryp_remove,\n\t.shutdown = ux500_cryp_shutdown,\n\t.driver = {\n\t\t.owner = THIS_MODULE,\n\t\t.name  = \"cryp1\",\n\t\t.of_match_table = ux500_cryp_match,\n\t\t.pm    = &ux500_cryp_pm,\n\t}\n};\n\nstatic int __init ux500_cryp_mod_init(void)\n{\n\tpr_debug(\"[%s] is called!\", __func__);\n\tklist_init(&driver_data.device_list, NULL, NULL);\n\t/* Initialize the semaphore to 0 devices (locked state) */\n\tsema_init(&driver_data.device_allocation, 0);\n\treturn platform_driver_register(&cryp_driver);\n}\n\nstatic void __exit ux500_cryp_mod_fini(void)\n{\n\tpr_debug(\"[%s] is called!\", __func__);\n\tplatform_driver_unregister(&cryp_driver);\n\treturn;\n}\n\nmodule_init(ux500_cryp_mod_init);\nmodule_exit(ux500_cryp_mod_fini);\n\nmodule_param(cryp_mode, int, 0);\n\nMODULE_DESCRIPTION(\"Driver for ST-Ericsson UX500 CRYP crypto engine.\");\nMODULE_ALIAS(\"aes-all\");\nMODULE_ALIAS(\"des-all\");\n\nMODULE_LICENSE(\"GPL\");\n", "/*\n * Cryptographic API.\n * Support for Nomadik hardware crypto engine.\n\n * Copyright (C) ST-Ericsson SA 2010\n * Author: Shujuan Chen <shujuan.chen@stericsson.com> for ST-Ericsson\n * Author: Joakim Bech <joakim.xx.bech@stericsson.com> for ST-Ericsson\n * Author: Berne Hebark <berne.herbark@stericsson.com> for ST-Ericsson.\n * Author: Niklas Hernaeus <niklas.hernaeus@stericsson.com> for ST-Ericsson.\n * Author: Andreas Westin <andreas.westin@stericsson.com> for ST-Ericsson.\n * License terms: GNU General Public License (GPL) version 2\n */\n\n#define pr_fmt(fmt) \"hashX hashX: \" fmt\n\n#include <linux/clk.h>\n#include <linux/device.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/io.h>\n#include <linux/klist.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/platform_device.h>\n#include <linux/crypto.h>\n\n#include <linux/regulator/consumer.h>\n#include <linux/dmaengine.h>\n#include <linux/bitops.h>\n\n#include <crypto/internal/hash.h>\n#include <crypto/sha.h>\n#include <crypto/scatterwalk.h>\n#include <crypto/algapi.h>\n\n#include <linux/platform_data/crypto-ux500.h>\n\n#include \"hash_alg.h\"\n\nstatic int hash_mode;\nmodule_param(hash_mode, int, 0);\nMODULE_PARM_DESC(hash_mode, \"CPU or DMA mode. CPU = 0 (default), DMA = 1\");\n\n/**\n * Pre-calculated empty message digests.\n */\nstatic const u8 zero_message_hash_sha1[SHA1_DIGEST_SIZE] = {\n\t0xda, 0x39, 0xa3, 0xee, 0x5e, 0x6b, 0x4b, 0x0d,\n\t0x32, 0x55, 0xbf, 0xef, 0x95, 0x60, 0x18, 0x90,\n\t0xaf, 0xd8, 0x07, 0x09\n};\n\nstatic const u8 zero_message_hash_sha256[SHA256_DIGEST_SIZE] = {\n\t0xe3, 0xb0, 0xc4, 0x42, 0x98, 0xfc, 0x1c, 0x14,\n\t0x9a, 0xfb, 0xf4, 0xc8, 0x99, 0x6f, 0xb9, 0x24,\n\t0x27, 0xae, 0x41, 0xe4, 0x64, 0x9b, 0x93, 0x4c,\n\t0xa4, 0x95, 0x99, 0x1b, 0x78, 0x52, 0xb8, 0x55\n};\n\n/* HMAC-SHA1, no key */\nstatic const u8 zero_message_hmac_sha1[SHA1_DIGEST_SIZE] = {\n\t0xfb, 0xdb, 0x1d, 0x1b, 0x18, 0xaa, 0x6c, 0x08,\n\t0x32, 0x4b, 0x7d, 0x64, 0xb7, 0x1f, 0xb7, 0x63,\n\t0x70, 0x69, 0x0e, 0x1d\n};\n\n/* HMAC-SHA256, no key */\nstatic const u8 zero_message_hmac_sha256[SHA256_DIGEST_SIZE] = {\n\t0xb6, 0x13, 0x67, 0x9a, 0x08, 0x14, 0xd9, 0xec,\n\t0x77, 0x2f, 0x95, 0xd7, 0x78, 0xc3, 0x5f, 0xc5,\n\t0xff, 0x16, 0x97, 0xc4, 0x93, 0x71, 0x56, 0x53,\n\t0xc6, 0xc7, 0x12, 0x14, 0x42, 0x92, 0xc5, 0xad\n};\n\n/**\n * struct hash_driver_data - data specific to the driver.\n *\n * @device_list:\tA list of registered devices to choose from.\n * @device_allocation:\tA semaphore initialized with number of devices.\n */\nstruct hash_driver_data {\n\tstruct klist\t\tdevice_list;\n\tstruct semaphore\tdevice_allocation;\n};\n\nstatic struct hash_driver_data\tdriver_data;\n\n/* Declaration of functions */\n/**\n * hash_messagepad - Pads a message and write the nblw bits.\n * @device_data:\tStructure for the hash device.\n * @message:\t\tLast word of a message\n * @index_bytes:\tThe number of bytes in the last message\n *\n * This function manages the final part of the digest calculation, when less\n * than 512 bits (64 bytes) remain in message. This means index_bytes < 64.\n *\n */\nstatic void hash_messagepad(struct hash_device_data *device_data,\n\t\t\t    const u32 *message, u8 index_bytes);\n\n/**\n * release_hash_device - Releases a previously allocated hash device.\n * @device_data:\tStructure for the hash device.\n *\n */\nstatic void release_hash_device(struct hash_device_data *device_data)\n{\n\tspin_lock(&device_data->ctx_lock);\n\tdevice_data->current_ctx->device = NULL;\n\tdevice_data->current_ctx = NULL;\n\tspin_unlock(&device_data->ctx_lock);\n\n\t/*\n\t * The down_interruptible part for this semaphore is called in\n\t * cryp_get_device_data.\n\t */\n\tup(&driver_data.device_allocation);\n}\n\nstatic void hash_dma_setup_channel(struct hash_device_data *device_data,\n\t\t\t\t   struct device *dev)\n{\n\tstruct hash_platform_data *platform_data = dev->platform_data;\n\tstruct dma_slave_config conf = {\n\t\t.direction = DMA_MEM_TO_DEV,\n\t\t.dst_addr = device_data->phybase + HASH_DMA_FIFO,\n\t\t.dst_addr_width = DMA_SLAVE_BUSWIDTH_2_BYTES,\n\t\t.dst_maxburst = 16,\n\t};\n\n\tdma_cap_zero(device_data->dma.mask);\n\tdma_cap_set(DMA_SLAVE, device_data->dma.mask);\n\n\tdevice_data->dma.cfg_mem2hash = platform_data->mem_to_engine;\n\tdevice_data->dma.chan_mem2hash =\n\t\tdma_request_channel(device_data->dma.mask,\n\t\t\t\t    platform_data->dma_filter,\n\t\t\t\t    device_data->dma.cfg_mem2hash);\n\n\tdmaengine_slave_config(device_data->dma.chan_mem2hash, &conf);\n\n\tinit_completion(&device_data->dma.complete);\n}\n\nstatic void hash_dma_callback(void *data)\n{\n\tstruct hash_ctx *ctx = data;\n\n\tcomplete(&ctx->device->dma.complete);\n}\n\nstatic int hash_set_dma_transfer(struct hash_ctx *ctx, struct scatterlist *sg,\n\t\t\t\t int len, enum dma_data_direction direction)\n{\n\tstruct dma_async_tx_descriptor *desc = NULL;\n\tstruct dma_chan *channel = NULL;\n\tdma_cookie_t cookie;\n\n\tif (direction != DMA_TO_DEVICE) {\n\t\tdev_err(ctx->device->dev, \"%s: Invalid DMA direction\\n\",\n\t\t\t__func__);\n\t\treturn -EFAULT;\n\t}\n\n\tsg->length = ALIGN(sg->length, HASH_DMA_ALIGN_SIZE);\n\n\tchannel = ctx->device->dma.chan_mem2hash;\n\tctx->device->dma.sg = sg;\n\tctx->device->dma.sg_len = dma_map_sg(channel->device->dev,\n\t\t\tctx->device->dma.sg, ctx->device->dma.nents,\n\t\t\tdirection);\n\n\tif (!ctx->device->dma.sg_len) {\n\t\tdev_err(ctx->device->dev, \"%s: Could not map the sg list (TO_DEVICE)\\n\",\n\t\t\t__func__);\n\t\treturn -EFAULT;\n\t}\n\n\tdev_dbg(ctx->device->dev, \"%s: Setting up DMA for buffer (TO_DEVICE)\\n\",\n\t\t__func__);\n\tdesc = dmaengine_prep_slave_sg(channel,\n\t\t\tctx->device->dma.sg, ctx->device->dma.sg_len,\n\t\t\tdirection, DMA_CTRL_ACK | DMA_PREP_INTERRUPT);\n\tif (!desc) {\n\t\tdev_err(ctx->device->dev,\n\t\t\t\"%s: device_prep_slave_sg() failed!\\n\", __func__);\n\t\treturn -EFAULT;\n\t}\n\n\tdesc->callback = hash_dma_callback;\n\tdesc->callback_param = ctx;\n\n\tcookie = dmaengine_submit(desc);\n\tdma_async_issue_pending(channel);\n\n\treturn 0;\n}\n\nstatic void hash_dma_done(struct hash_ctx *ctx)\n{\n\tstruct dma_chan *chan;\n\n\tchan = ctx->device->dma.chan_mem2hash;\n\tdmaengine_device_control(chan, DMA_TERMINATE_ALL, 0);\n\tdma_unmap_sg(chan->device->dev, ctx->device->dma.sg,\n\t\t     ctx->device->dma.sg_len, DMA_TO_DEVICE);\n}\n\nstatic int hash_dma_write(struct hash_ctx *ctx,\n\t\t\t  struct scatterlist *sg, int len)\n{\n\tint error = hash_set_dma_transfer(ctx, sg, len, DMA_TO_DEVICE);\n\tif (error) {\n\t\tdev_dbg(ctx->device->dev,\n\t\t\t\"%s: hash_set_dma_transfer() failed\\n\", __func__);\n\t\treturn error;\n\t}\n\n\treturn len;\n}\n\n/**\n * get_empty_message_digest - Returns a pre-calculated digest for\n * the empty message.\n * @device_data:\tStructure for the hash device.\n * @zero_hash:\t\tBuffer to return the empty message digest.\n * @zero_hash_size:\tHash size of the empty message digest.\n * @zero_digest:\tTrue if zero_digest returned.\n */\nstatic int get_empty_message_digest(\n\t\tstruct hash_device_data *device_data,\n\t\tu8 *zero_hash, u32 *zero_hash_size, bool *zero_digest)\n{\n\tint ret = 0;\n\tstruct hash_ctx *ctx = device_data->current_ctx;\n\t*zero_digest = false;\n\n\t/**\n\t * Caller responsible for ctx != NULL.\n\t */\n\n\tif (HASH_OPER_MODE_HASH == ctx->config.oper_mode) {\n\t\tif (HASH_ALGO_SHA1 == ctx->config.algorithm) {\n\t\t\tmemcpy(zero_hash, &zero_message_hash_sha1[0],\n\t\t\t       SHA1_DIGEST_SIZE);\n\t\t\t*zero_hash_size = SHA1_DIGEST_SIZE;\n\t\t\t*zero_digest = true;\n\t\t} else if (HASH_ALGO_SHA256 ==\n\t\t\t\tctx->config.algorithm) {\n\t\t\tmemcpy(zero_hash, &zero_message_hash_sha256[0],\n\t\t\t       SHA256_DIGEST_SIZE);\n\t\t\t*zero_hash_size = SHA256_DIGEST_SIZE;\n\t\t\t*zero_digest = true;\n\t\t} else {\n\t\t\tdev_err(device_data->dev, \"%s: Incorrect algorithm!\\n\",\n\t\t\t\t__func__);\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t} else if (HASH_OPER_MODE_HMAC == ctx->config.oper_mode) {\n\t\tif (!ctx->keylen) {\n\t\t\tif (HASH_ALGO_SHA1 == ctx->config.algorithm) {\n\t\t\t\tmemcpy(zero_hash, &zero_message_hmac_sha1[0],\n\t\t\t\t       SHA1_DIGEST_SIZE);\n\t\t\t\t*zero_hash_size = SHA1_DIGEST_SIZE;\n\t\t\t\t*zero_digest = true;\n\t\t\t} else if (HASH_ALGO_SHA256 == ctx->config.algorithm) {\n\t\t\t\tmemcpy(zero_hash, &zero_message_hmac_sha256[0],\n\t\t\t\t       SHA256_DIGEST_SIZE);\n\t\t\t\t*zero_hash_size = SHA256_DIGEST_SIZE;\n\t\t\t\t*zero_digest = true;\n\t\t\t} else {\n\t\t\t\tdev_err(device_data->dev, \"%s: Incorrect algorithm!\\n\",\n\t\t\t\t\t__func__);\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t} else {\n\t\t\tdev_dbg(device_data->dev,\n\t\t\t\t\"%s: Continue hash calculation, since hmac key available\\n\",\n\t\t\t\t__func__);\n\t\t}\n\t}\nout:\n\n\treturn ret;\n}\n\n/**\n * hash_disable_power - Request to disable power and clock.\n * @device_data:\tStructure for the hash device.\n * @save_device_state:\tIf true, saves the current hw state.\n *\n * This function request for disabling power (regulator) and clock,\n * and could also save current hw state.\n */\nstatic int hash_disable_power(struct hash_device_data *device_data,\n\t\t\t      bool save_device_state)\n{\n\tint ret = 0;\n\tstruct device *dev = device_data->dev;\n\n\tspin_lock(&device_data->power_state_lock);\n\tif (!device_data->power_state)\n\t\tgoto out;\n\n\tif (save_device_state) {\n\t\thash_save_state(device_data,\n\t\t\t\t&device_data->state);\n\t\tdevice_data->restore_dev_state = true;\n\t}\n\n\tclk_disable(device_data->clk);\n\tret = regulator_disable(device_data->regulator);\n\tif (ret)\n\t\tdev_err(dev, \"%s: regulator_disable() failed!\\n\", __func__);\n\n\tdevice_data->power_state = false;\n\nout:\n\tspin_unlock(&device_data->power_state_lock);\n\n\treturn ret;\n}\n\n/**\n * hash_enable_power - Request to enable power and clock.\n * @device_data:\t\tStructure for the hash device.\n * @restore_device_state:\tIf true, restores a previous saved hw state.\n *\n * This function request for enabling power (regulator) and clock,\n * and could also restore a previously saved hw state.\n */\nstatic int hash_enable_power(struct hash_device_data *device_data,\n\t\t\t     bool restore_device_state)\n{\n\tint ret = 0;\n\tstruct device *dev = device_data->dev;\n\n\tspin_lock(&device_data->power_state_lock);\n\tif (!device_data->power_state) {\n\t\tret = regulator_enable(device_data->regulator);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"%s: regulator_enable() failed!\\n\",\n\t\t\t\t__func__);\n\t\t\tgoto out;\n\t\t}\n\t\tret = clk_enable(device_data->clk);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"%s: clk_enable() failed!\\n\", __func__);\n\t\t\tret = regulator_disable(\n\t\t\t\t\tdevice_data->regulator);\n\t\t\tgoto out;\n\t\t}\n\t\tdevice_data->power_state = true;\n\t}\n\n\tif (device_data->restore_dev_state) {\n\t\tif (restore_device_state) {\n\t\t\tdevice_data->restore_dev_state = false;\n\t\t\thash_resume_state(device_data, &device_data->state);\n\t\t}\n\t}\nout:\n\tspin_unlock(&device_data->power_state_lock);\n\n\treturn ret;\n}\n\n/**\n * hash_get_device_data - Checks for an available hash device and return it.\n * @hash_ctx:\t\tStructure for the hash context.\n * @device_data:\tStructure for the hash device.\n *\n * This function check for an available hash device and return it to\n * the caller.\n * Note! Caller need to release the device, calling up().\n */\nstatic int hash_get_device_data(struct hash_ctx *ctx,\n\t\t\t\tstruct hash_device_data **device_data)\n{\n\tint\t\t\tret;\n\tstruct klist_iter\tdevice_iterator;\n\tstruct klist_node\t*device_node;\n\tstruct hash_device_data *local_device_data = NULL;\n\n\t/* Wait until a device is available */\n\tret = down_interruptible(&driver_data.device_allocation);\n\tif (ret)\n\t\treturn ret;  /* Interrupted */\n\n\t/* Select a device */\n\tklist_iter_init(&driver_data.device_list, &device_iterator);\n\tdevice_node = klist_next(&device_iterator);\n\twhile (device_node) {\n\t\tlocal_device_data = container_of(device_node,\n\t\t\t\t\t   struct hash_device_data, list_node);\n\t\tspin_lock(&local_device_data->ctx_lock);\n\t\t/* current_ctx allocates a device, NULL = unallocated */\n\t\tif (local_device_data->current_ctx) {\n\t\t\tdevice_node = klist_next(&device_iterator);\n\t\t} else {\n\t\t\tlocal_device_data->current_ctx = ctx;\n\t\t\tctx->device = local_device_data;\n\t\t\tspin_unlock(&local_device_data->ctx_lock);\n\t\t\tbreak;\n\t\t}\n\t\tspin_unlock(&local_device_data->ctx_lock);\n\t}\n\tklist_iter_exit(&device_iterator);\n\n\tif (!device_node) {\n\t\t/**\n\t\t * No free device found.\n\t\t * Since we allocated a device with down_interruptible, this\n\t\t * should not be able to happen.\n\t\t * Number of available devices, which are contained in\n\t\t * device_allocation, is therefore decremented by not doing\n\t\t * an up(device_allocation).\n\t\t */\n\t\treturn -EBUSY;\n\t}\n\n\t*device_data = local_device_data;\n\n\treturn 0;\n}\n\n/**\n * hash_hw_write_key - Writes the key to the hardware registries.\n *\n * @device_data:\tStructure for the hash device.\n * @key:\t\tKey to be written.\n * @keylen:\t\tThe lengt of the key.\n *\n * Note! This function DOES NOT write to the NBLW registry, even though\n * specified in the the hw design spec. Either due to incorrect info in the\n * spec or due to a bug in the hw.\n */\nstatic void hash_hw_write_key(struct hash_device_data *device_data,\n\t\t\t      const u8 *key, unsigned int keylen)\n{\n\tu32 word = 0;\n\tint nwords = 1;\n\n\tHASH_CLEAR_BITS(&device_data->base->str, HASH_STR_NBLW_MASK);\n\n\twhile (keylen >= 4) {\n\t\tu32 *key_word = (u32 *)key;\n\n\t\tHASH_SET_DIN(key_word, nwords);\n\t\tkeylen -= 4;\n\t\tkey += 4;\n\t}\n\n\t/* Take care of the remaining bytes in the last word */\n\tif (keylen) {\n\t\tword = 0;\n\t\twhile (keylen) {\n\t\t\tword |= (key[keylen - 1] << (8 * (keylen - 1)));\n\t\t\tkeylen--;\n\t\t}\n\n\t\tHASH_SET_DIN(&word, nwords);\n\t}\n\n\twhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\n\t\tcpu_relax();\n\n\tHASH_SET_DCAL;\n\n\twhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\n\t\tcpu_relax();\n}\n\n/**\n * init_hash_hw - Initialise the hash hardware for a new calculation.\n * @device_data:\tStructure for the hash device.\n * @ctx:\t\tThe hash context.\n *\n * This function will enable the bits needed to clear and start a new\n * calculation.\n */\nstatic int init_hash_hw(struct hash_device_data *device_data,\n\t\t\tstruct hash_ctx *ctx)\n{\n\tint ret = 0;\n\n\tret = hash_setconfiguration(device_data, &ctx->config);\n\tif (ret) {\n\t\tdev_err(device_data->dev, \"%s: hash_setconfiguration() failed!\\n\",\n\t\t\t__func__);\n\t\treturn ret;\n\t}\n\n\thash_begin(device_data, ctx);\n\n\tif (ctx->config.oper_mode == HASH_OPER_MODE_HMAC)\n\t\thash_hw_write_key(device_data, ctx->key, ctx->keylen);\n\n\treturn ret;\n}\n\n/**\n * hash_get_nents - Return number of entries (nents) in scatterlist (sg).\n *\n * @sg:\t\tScatterlist.\n * @size:\tSize in bytes.\n * @aligned:\tTrue if sg data aligned to work in DMA mode.\n *\n */\nstatic int hash_get_nents(struct scatterlist *sg, int size, bool *aligned)\n{\n\tint nents = 0;\n\tbool aligned_data = true;\n\n\twhile (size > 0 && sg) {\n\t\tnents++;\n\t\tsize -= sg->length;\n\n\t\t/* hash_set_dma_transfer will align last nent */\n\t\tif ((aligned && !IS_ALIGNED(sg->offset, HASH_DMA_ALIGN_SIZE)) ||\n\t\t    (!IS_ALIGNED(sg->length, HASH_DMA_ALIGN_SIZE) && size > 0))\n\t\t\taligned_data = false;\n\n\t\tsg = sg_next(sg);\n\t}\n\n\tif (aligned)\n\t\t*aligned = aligned_data;\n\n\tif (size != 0)\n\t\treturn -EFAULT;\n\n\treturn nents;\n}\n\n/**\n * hash_dma_valid_data - checks for dma valid sg data.\n * @sg:\t\tScatterlist.\n * @datasize:\tDatasize in bytes.\n *\n * NOTE! This function checks for dma valid sg data, since dma\n * only accept datasizes of even wordsize.\n */\nstatic bool hash_dma_valid_data(struct scatterlist *sg, int datasize)\n{\n\tbool aligned;\n\n\t/* Need to include at least one nent, else error */\n\tif (hash_get_nents(sg, datasize, &aligned) < 1)\n\t\treturn false;\n\n\treturn aligned;\n}\n\n/**\n * hash_init - Common hash init function for SHA1/SHA2 (SHA256).\n * @req: The hash request for the job.\n *\n * Initialize structures.\n */\nstatic int hash_init(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\n\tstruct hash_req_ctx *req_ctx = ahash_request_ctx(req);\n\n\tif (!ctx->key)\n\t\tctx->keylen = 0;\n\n\tmemset(&req_ctx->state, 0, sizeof(struct hash_state));\n\treq_ctx->updated = 0;\n\tif (hash_mode == HASH_MODE_DMA) {\n\t\tif (req->nbytes < HASH_DMA_ALIGN_SIZE) {\n\t\t\treq_ctx->dma_mode = false; /* Don't use DMA */\n\n\t\t\tpr_debug(\"%s: DMA mode, but direct to CPU mode for data size < %d\\n\",\n\t\t\t\t __func__, HASH_DMA_ALIGN_SIZE);\n\t\t} else {\n\t\t\tif (req->nbytes >= HASH_DMA_PERFORMANCE_MIN_SIZE &&\n\t\t\t    hash_dma_valid_data(req->src, req->nbytes)) {\n\t\t\t\treq_ctx->dma_mode = true;\n\t\t\t} else {\n\t\t\t\treq_ctx->dma_mode = false;\n\t\t\t\tpr_debug(\"%s: DMA mode, but use CPU mode for datalength < %d or non-aligned data, except in last nent\\n\",\n\t\t\t\t\t __func__,\n\t\t\t\t\t HASH_DMA_PERFORMANCE_MIN_SIZE);\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n\n/**\n * hash_processblock - This function processes a single block of 512 bits (64\n *                     bytes), word aligned, starting at message.\n * @device_data:\tStructure for the hash device.\n * @message:\t\tBlock (512 bits) of message to be written to\n *\t\t\tthe HASH hardware.\n *\n */\nstatic void hash_processblock(struct hash_device_data *device_data,\n\t\t\t      const u32 *message, int length)\n{\n\tint len = length / HASH_BYTES_PER_WORD;\n\t/*\n\t * NBLW bits. Reset the number of bits in last word (NBLW).\n\t */\n\tHASH_CLEAR_BITS(&device_data->base->str, HASH_STR_NBLW_MASK);\n\n\t/*\n\t * Write message data to the HASH_DIN register.\n\t */\n\tHASH_SET_DIN(message, len);\n}\n\n/**\n * hash_messagepad - Pads a message and write the nblw bits.\n * @device_data:\tStructure for the hash device.\n * @message:\t\tLast word of a message.\n * @index_bytes:\tThe number of bytes in the last message.\n *\n * This function manages the final part of the digest calculation, when less\n * than 512 bits (64 bytes) remain in message. This means index_bytes < 64.\n *\n */\nstatic void hash_messagepad(struct hash_device_data *device_data,\n\t\t\t    const u32 *message, u8 index_bytes)\n{\n\tint nwords = 1;\n\n\t/*\n\t * Clear hash str register, only clear NBLW\n\t * since DCAL will be reset by hardware.\n\t */\n\tHASH_CLEAR_BITS(&device_data->base->str, HASH_STR_NBLW_MASK);\n\n\t/* Main loop */\n\twhile (index_bytes >= 4) {\n\t\tHASH_SET_DIN(message, nwords);\n\t\tindex_bytes -= 4;\n\t\tmessage++;\n\t}\n\n\tif (index_bytes)\n\t\tHASH_SET_DIN(message, nwords);\n\n\twhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\n\t\tcpu_relax();\n\n\t/* num_of_bytes == 0 => NBLW <- 0 (32 bits valid in DATAIN) */\n\tHASH_SET_NBLW(index_bytes * 8);\n\tdev_dbg(device_data->dev, \"%s: DIN=0x%08x NBLW=%lu\\n\",\n\t\t__func__, readl_relaxed(&device_data->base->din),\n\t\treadl_relaxed(&device_data->base->str) & HASH_STR_NBLW_MASK);\n\tHASH_SET_DCAL;\n\tdev_dbg(device_data->dev, \"%s: after dcal -> DIN=0x%08x NBLW=%lu\\n\",\n\t\t__func__, readl_relaxed(&device_data->base->din),\n\t\treadl_relaxed(&device_data->base->str) & HASH_STR_NBLW_MASK);\n\n\twhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\n\t\tcpu_relax();\n}\n\n/**\n * hash_incrementlength - Increments the length of the current message.\n * @ctx: Hash context\n * @incr: Length of message processed already\n *\n * Overflow cannot occur, because conditions for overflow are checked in\n * hash_hw_update.\n */\nstatic void hash_incrementlength(struct hash_req_ctx *ctx, u32 incr)\n{\n\tctx->state.length.low_word += incr;\n\n\t/* Check for wrap-around */\n\tif (ctx->state.length.low_word < incr)\n\t\tctx->state.length.high_word++;\n}\n\n/**\n * hash_setconfiguration - Sets the required configuration for the hash\n *                         hardware.\n * @device_data:\tStructure for the hash device.\n * @config:\t\tPointer to a configuration structure.\n */\nint hash_setconfiguration(struct hash_device_data *device_data,\n\t\t\t  struct hash_config *config)\n{\n\tint ret = 0;\n\n\tif (config->algorithm != HASH_ALGO_SHA1 &&\n\t    config->algorithm != HASH_ALGO_SHA256)\n\t\treturn -EPERM;\n\n\t/*\n\t * DATAFORM bits. Set the DATAFORM bits to 0b11, which means the data\n\t * to be written to HASH_DIN is considered as 32 bits.\n\t */\n\tHASH_SET_DATA_FORMAT(config->data_format);\n\n\t/*\n\t * ALGO bit. Set to 0b1 for SHA-1 and 0b0 for SHA-256\n\t */\n\tswitch (config->algorithm) {\n\tcase HASH_ALGO_SHA1:\n\t\tHASH_SET_BITS(&device_data->base->cr, HASH_CR_ALGO_MASK);\n\t\tbreak;\n\n\tcase HASH_ALGO_SHA256:\n\t\tHASH_CLEAR_BITS(&device_data->base->cr, HASH_CR_ALGO_MASK);\n\t\tbreak;\n\n\tdefault:\n\t\tdev_err(device_data->dev, \"%s: Incorrect algorithm\\n\",\n\t\t\t__func__);\n\t\treturn -EPERM;\n\t}\n\n\t/*\n\t * MODE bit. This bit selects between HASH or HMAC mode for the\n\t * selected algorithm. 0b0 = HASH and 0b1 = HMAC.\n\t */\n\tif (HASH_OPER_MODE_HASH == config->oper_mode)\n\t\tHASH_CLEAR_BITS(&device_data->base->cr,\n\t\t\t\tHASH_CR_MODE_MASK);\n\telse if (HASH_OPER_MODE_HMAC == config->oper_mode) {\n\t\tHASH_SET_BITS(&device_data->base->cr, HASH_CR_MODE_MASK);\n\t\tif (device_data->current_ctx->keylen > HASH_BLOCK_SIZE) {\n\t\t\t/* Truncate key to blocksize */\n\t\t\tdev_dbg(device_data->dev, \"%s: LKEY set\\n\", __func__);\n\t\t\tHASH_SET_BITS(&device_data->base->cr,\n\t\t\t\t      HASH_CR_LKEY_MASK);\n\t\t} else {\n\t\t\tdev_dbg(device_data->dev, \"%s: LKEY cleared\\n\",\n\t\t\t\t__func__);\n\t\t\tHASH_CLEAR_BITS(&device_data->base->cr,\n\t\t\t\t\tHASH_CR_LKEY_MASK);\n\t\t}\n\t} else {\t/* Wrong hash mode */\n\t\tret = -EPERM;\n\t\tdev_err(device_data->dev, \"%s: HASH_INVALID_PARAMETER!\\n\",\n\t\t\t__func__);\n\t}\n\treturn ret;\n}\n\n/**\n * hash_begin - This routine resets some globals and initializes the hash\n *              hardware.\n * @device_data:\tStructure for the hash device.\n * @ctx:\t\tHash context.\n */\nvoid hash_begin(struct hash_device_data *device_data, struct hash_ctx *ctx)\n{\n\t/* HW and SW initializations */\n\t/* Note: there is no need to initialize buffer and digest members */\n\n\twhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\n\t\tcpu_relax();\n\n\t/*\n\t * INIT bit. Set this bit to 0b1 to reset the HASH processor core and\n\t * prepare the initialize the HASH accelerator to compute the message\n\t * digest of a new message.\n\t */\n\tHASH_INITIALIZE;\n\n\t/*\n\t * NBLW bits. Reset the number of bits in last word (NBLW).\n\t */\n\tHASH_CLEAR_BITS(&device_data->base->str, HASH_STR_NBLW_MASK);\n}\n\nstatic int hash_process_data(struct hash_device_data *device_data,\n\t\t\t     struct hash_ctx *ctx, struct hash_req_ctx *req_ctx,\n\t\t\t     int msg_length, u8 *data_buffer, u8 *buffer,\n\t\t\t     u8 *index)\n{\n\tint ret = 0;\n\tu32 count;\n\n\tdo {\n\t\tif ((*index + msg_length) < HASH_BLOCK_SIZE) {\n\t\t\tfor (count = 0; count < msg_length; count++) {\n\t\t\t\tbuffer[*index + count] =\n\t\t\t\t\t*(data_buffer + count);\n\t\t\t}\n\t\t\t*index += msg_length;\n\t\t\tmsg_length = 0;\n\t\t} else {\n\t\t\tif (req_ctx->updated) {\n\t\t\t\tret = hash_resume_state(device_data,\n\t\t\t\t\t\t&device_data->state);\n\t\t\t\tmemmove(req_ctx->state.buffer,\n\t\t\t\t\tdevice_data->state.buffer,\n\t\t\t\t\tHASH_BLOCK_SIZE / sizeof(u32));\n\t\t\t\tif (ret) {\n\t\t\t\t\tdev_err(device_data->dev,\n\t\t\t\t\t\t\"%s: hash_resume_state() failed!\\n\",\n\t\t\t\t\t\t__func__);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tret = init_hash_hw(device_data, ctx);\n\t\t\t\tif (ret) {\n\t\t\t\t\tdev_err(device_data->dev,\n\t\t\t\t\t\t\"%s: init_hash_hw() failed!\\n\",\n\t\t\t\t\t\t__func__);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t\treq_ctx->updated = 1;\n\t\t\t}\n\t\t\t/*\n\t\t\t * If 'data_buffer' is four byte aligned and\n\t\t\t * local buffer does not have any data, we can\n\t\t\t * write data directly from 'data_buffer' to\n\t\t\t * HW peripheral, otherwise we first copy data\n\t\t\t * to a local buffer\n\t\t\t */\n\t\t\tif ((0 == (((u32)data_buffer) % 4)) &&\n\t\t\t    (0 == *index))\n\t\t\t\thash_processblock(device_data,\n\t\t\t\t\t\t  (const u32 *)data_buffer,\n\t\t\t\t\t\t  HASH_BLOCK_SIZE);\n\t\t\telse {\n\t\t\t\tfor (count = 0;\n\t\t\t\t     count < (u32)(HASH_BLOCK_SIZE - *index);\n\t\t\t\t     count++) {\n\t\t\t\t\tbuffer[*index + count] =\n\t\t\t\t\t\t*(data_buffer + count);\n\t\t\t\t}\n\t\t\t\thash_processblock(device_data,\n\t\t\t\t\t\t  (const u32 *)buffer,\n\t\t\t\t\t\t  HASH_BLOCK_SIZE);\n\t\t\t}\n\t\t\thash_incrementlength(req_ctx, HASH_BLOCK_SIZE);\n\t\t\tdata_buffer += (HASH_BLOCK_SIZE - *index);\n\n\t\t\tmsg_length -= (HASH_BLOCK_SIZE - *index);\n\t\t\t*index = 0;\n\n\t\t\tret = hash_save_state(device_data,\n\t\t\t\t\t&device_data->state);\n\n\t\t\tmemmove(device_data->state.buffer,\n\t\t\t\treq_ctx->state.buffer,\n\t\t\t\tHASH_BLOCK_SIZE / sizeof(u32));\n\t\t\tif (ret) {\n\t\t\t\tdev_err(device_data->dev, \"%s: hash_save_state() failed!\\n\",\n\t\t\t\t\t__func__);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t} while (msg_length != 0);\nout:\n\n\treturn ret;\n}\n\n/**\n * hash_dma_final - The hash dma final function for SHA1/SHA256.\n * @req:\tThe hash request for the job.\n */\nstatic int hash_dma_final(struct ahash_request *req)\n{\n\tint ret = 0;\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\n\tstruct hash_req_ctx *req_ctx = ahash_request_ctx(req);\n\tstruct hash_device_data *device_data;\n\tu8 digest[SHA256_DIGEST_SIZE];\n\tint bytes_written = 0;\n\n\tret = hash_get_device_data(ctx, &device_data);\n\tif (ret)\n\t\treturn ret;\n\n\tdev_dbg(device_data->dev, \"%s: (ctx=0x%x)!\\n\", __func__, (u32) ctx);\n\n\tif (req_ctx->updated) {\n\t\tret = hash_resume_state(device_data, &device_data->state);\n\n\t\tif (ret) {\n\t\t\tdev_err(device_data->dev, \"%s: hash_resume_state() failed!\\n\",\n\t\t\t\t__func__);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (!req_ctx->updated) {\n\t\tret = hash_setconfiguration(device_data, &ctx->config);\n\t\tif (ret) {\n\t\t\tdev_err(device_data->dev,\n\t\t\t\t\"%s: hash_setconfiguration() failed!\\n\",\n\t\t\t\t__func__);\n\t\t\tgoto out;\n\t\t}\n\n\t\t/* Enable DMA input */\n\t\tif (hash_mode != HASH_MODE_DMA || !req_ctx->dma_mode) {\n\t\t\tHASH_CLEAR_BITS(&device_data->base->cr,\n\t\t\t\t\tHASH_CR_DMAE_MASK);\n\t\t} else {\n\t\t\tHASH_SET_BITS(&device_data->base->cr,\n\t\t\t\t      HASH_CR_DMAE_MASK);\n\t\t\tHASH_SET_BITS(&device_data->base->cr,\n\t\t\t\t      HASH_CR_PRIVN_MASK);\n\t\t}\n\n\t\tHASH_INITIALIZE;\n\n\t\tif (ctx->config.oper_mode == HASH_OPER_MODE_HMAC)\n\t\t\thash_hw_write_key(device_data, ctx->key, ctx->keylen);\n\n\t\t/* Number of bits in last word = (nbytes * 8) % 32 */\n\t\tHASH_SET_NBLW((req->nbytes * 8) % 32);\n\t\treq_ctx->updated = 1;\n\t}\n\n\t/* Store the nents in the dma struct. */\n\tctx->device->dma.nents = hash_get_nents(req->src, req->nbytes, NULL);\n\tif (!ctx->device->dma.nents) {\n\t\tdev_err(device_data->dev, \"%s: ctx->device->dma.nents = 0\\n\",\n\t\t\t__func__);\n\t\tret = ctx->device->dma.nents;\n\t\tgoto out;\n\t}\n\n\tbytes_written = hash_dma_write(ctx, req->src, req->nbytes);\n\tif (bytes_written != req->nbytes) {\n\t\tdev_err(device_data->dev, \"%s: hash_dma_write() failed!\\n\",\n\t\t\t__func__);\n\t\tret = bytes_written;\n\t\tgoto out;\n\t}\n\n\twait_for_completion(&ctx->device->dma.complete);\n\thash_dma_done(ctx);\n\n\twhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\n\t\tcpu_relax();\n\n\tif (ctx->config.oper_mode == HASH_OPER_MODE_HMAC && ctx->key) {\n\t\tunsigned int keylen = ctx->keylen;\n\t\tu8 *key = ctx->key;\n\n\t\tdev_dbg(device_data->dev, \"%s: keylen: %d\\n\",\n\t\t\t__func__, ctx->keylen);\n\t\thash_hw_write_key(device_data, key, keylen);\n\t}\n\n\thash_get_digest(device_data, digest, ctx->config.algorithm);\n\tmemcpy(req->result, digest, ctx->digestsize);\n\nout:\n\trelease_hash_device(device_data);\n\n\t/**\n\t * Allocated in setkey, and only used in HMAC.\n\t */\n\tkfree(ctx->key);\n\n\treturn ret;\n}\n\n/**\n * hash_hw_final - The final hash calculation function\n * @req:\tThe hash request for the job.\n */\nstatic int hash_hw_final(struct ahash_request *req)\n{\n\tint ret = 0;\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\n\tstruct hash_req_ctx *req_ctx = ahash_request_ctx(req);\n\tstruct hash_device_data *device_data;\n\tu8 digest[SHA256_DIGEST_SIZE];\n\n\tret = hash_get_device_data(ctx, &device_data);\n\tif (ret)\n\t\treturn ret;\n\n\tdev_dbg(device_data->dev, \"%s: (ctx=0x%x)!\\n\", __func__, (u32) ctx);\n\n\tif (req_ctx->updated) {\n\t\tret = hash_resume_state(device_data, &device_data->state);\n\n\t\tif (ret) {\n\t\t\tdev_err(device_data->dev,\n\t\t\t\t\"%s: hash_resume_state() failed!\\n\", __func__);\n\t\t\tgoto out;\n\t\t}\n\t} else if (req->nbytes == 0 && ctx->keylen == 0) {\n\t\tu8 zero_hash[SHA256_DIGEST_SIZE];\n\t\tu32 zero_hash_size = 0;\n\t\tbool zero_digest = false;\n\t\t/**\n\t\t * Use a pre-calculated empty message digest\n\t\t * (workaround since hw return zeroes, hw bug!?)\n\t\t */\n\t\tret = get_empty_message_digest(device_data, &zero_hash[0],\n\t\t\t\t&zero_hash_size, &zero_digest);\n\t\tif (!ret && likely(zero_hash_size == ctx->digestsize) &&\n\t\t    zero_digest) {\n\t\t\tmemcpy(req->result, &zero_hash[0], ctx->digestsize);\n\t\t\tgoto out;\n\t\t} else if (!ret && !zero_digest) {\n\t\t\tdev_dbg(device_data->dev,\n\t\t\t\t\"%s: HMAC zero msg with key, continue...\\n\",\n\t\t\t\t__func__);\n\t\t} else {\n\t\t\tdev_err(device_data->dev,\n\t\t\t\t\"%s: ret=%d, or wrong digest size? %s\\n\",\n\t\t\t\t__func__, ret,\n\t\t\t\tzero_hash_size == ctx->digestsize ?\n\t\t\t\t\"true\" : \"false\");\n\t\t\t/* Return error */\n\t\t\tgoto out;\n\t\t}\n\t} else if (req->nbytes == 0 && ctx->keylen > 0) {\n\t\tdev_err(device_data->dev, \"%s: Empty message with keylength > 0, NOT supported\\n\",\n\t\t\t__func__);\n\t\tgoto out;\n\t}\n\n\tif (!req_ctx->updated) {\n\t\tret = init_hash_hw(device_data, ctx);\n\t\tif (ret) {\n\t\t\tdev_err(device_data->dev,\n\t\t\t\t\"%s: init_hash_hw() failed!\\n\", __func__);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (req_ctx->state.index) {\n\t\thash_messagepad(device_data, req_ctx->state.buffer,\n\t\t\t\treq_ctx->state.index);\n\t} else {\n\t\tHASH_SET_DCAL;\n\t\twhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\n\t\t\tcpu_relax();\n\t}\n\n\tif (ctx->config.oper_mode == HASH_OPER_MODE_HMAC && ctx->key) {\n\t\tunsigned int keylen = ctx->keylen;\n\t\tu8 *key = ctx->key;\n\n\t\tdev_dbg(device_data->dev, \"%s: keylen: %d\\n\",\n\t\t\t__func__, ctx->keylen);\n\t\thash_hw_write_key(device_data, key, keylen);\n\t}\n\n\thash_get_digest(device_data, digest, ctx->config.algorithm);\n\tmemcpy(req->result, digest, ctx->digestsize);\n\nout:\n\trelease_hash_device(device_data);\n\n\t/**\n\t * Allocated in setkey, and only used in HMAC.\n\t */\n\tkfree(ctx->key);\n\n\treturn ret;\n}\n\n/**\n * hash_hw_update - Updates current HASH computation hashing another part of\n *                  the message.\n * @req:\tByte array containing the message to be hashed (caller\n *\t\tallocated).\n */\nint hash_hw_update(struct ahash_request *req)\n{\n\tint ret = 0;\n\tu8 index = 0;\n\tu8 *buffer;\n\tstruct hash_device_data *device_data;\n\tu8 *data_buffer;\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\n\tstruct hash_req_ctx *req_ctx = ahash_request_ctx(req);\n\tstruct crypto_hash_walk walk;\n\tint msg_length = crypto_hash_walk_first(req, &walk);\n\n\t/* Empty message (\"\") is correct indata */\n\tif (msg_length == 0)\n\t\treturn ret;\n\n\tindex = req_ctx->state.index;\n\tbuffer = (u8 *)req_ctx->state.buffer;\n\n\t/* Check if ctx->state.length + msg_length\n\t   overflows */\n\tif (msg_length > (req_ctx->state.length.low_word + msg_length) &&\n\t    HASH_HIGH_WORD_MAX_VAL == req_ctx->state.length.high_word) {\n\t\tpr_err(\"%s: HASH_MSG_LENGTH_OVERFLOW!\\n\", __func__);\n\t\treturn -EPERM;\n\t}\n\n\tret = hash_get_device_data(ctx, &device_data);\n\tif (ret)\n\t\treturn ret;\n\n\t/* Main loop */\n\twhile (0 != msg_length) {\n\t\tdata_buffer = walk.data;\n\t\tret = hash_process_data(device_data, ctx, req_ctx, msg_length,\n\t\t\t\tdata_buffer, buffer, &index);\n\n\t\tif (ret) {\n\t\t\tdev_err(device_data->dev, \"%s: hash_internal_hw_update() failed!\\n\",\n\t\t\t\t__func__);\n\t\t\tgoto out;\n\t\t}\n\n\t\tmsg_length = crypto_hash_walk_done(&walk, 0);\n\t}\n\n\treq_ctx->state.index = index;\n\tdev_dbg(device_data->dev, \"%s: indata length=%d, bin=%d\\n\",\n\t\t__func__, req_ctx->state.index, req_ctx->state.bit_index);\n\nout:\n\trelease_hash_device(device_data);\n\n\treturn ret;\n}\n\n/**\n * hash_resume_state - Function that resumes the state of an calculation.\n * @device_data:\tPointer to the device structure.\n * @device_state:\tThe state to be restored in the hash hardware\n */\nint hash_resume_state(struct hash_device_data *device_data,\n\t\t      const struct hash_state *device_state)\n{\n\tu32 temp_cr;\n\ts32 count;\n\tint hash_mode = HASH_OPER_MODE_HASH;\n\n\tif (NULL == device_state) {\n\t\tdev_err(device_data->dev, \"%s: HASH_INVALID_PARAMETER!\\n\",\n\t\t\t__func__);\n\t\treturn -EPERM;\n\t}\n\n\t/* Check correctness of index and length members */\n\tif (device_state->index > HASH_BLOCK_SIZE ||\n\t    (device_state->length.low_word % HASH_BLOCK_SIZE) != 0) {\n\t\tdev_err(device_data->dev, \"%s: HASH_INVALID_PARAMETER!\\n\",\n\t\t\t__func__);\n\t\treturn -EPERM;\n\t}\n\n\t/*\n\t * INIT bit. Set this bit to 0b1 to reset the HASH processor core and\n\t * prepare the initialize the HASH accelerator to compute the message\n\t * digest of a new message.\n\t */\n\tHASH_INITIALIZE;\n\n\ttemp_cr = device_state->temp_cr;\n\twritel_relaxed(temp_cr & HASH_CR_RESUME_MASK, &device_data->base->cr);\n\n\tif (readl(&device_data->base->cr) & HASH_CR_MODE_MASK)\n\t\thash_mode = HASH_OPER_MODE_HMAC;\n\telse\n\t\thash_mode = HASH_OPER_MODE_HASH;\n\n\tfor (count = 0; count < HASH_CSR_COUNT; count++) {\n\t\tif ((count >= 36) && (hash_mode == HASH_OPER_MODE_HASH))\n\t\t\tbreak;\n\n\t\twritel_relaxed(device_state->csr[count],\n\t\t\t       &device_data->base->csrx[count]);\n\t}\n\n\twritel_relaxed(device_state->csfull, &device_data->base->csfull);\n\twritel_relaxed(device_state->csdatain, &device_data->base->csdatain);\n\n\twritel_relaxed(device_state->str_reg, &device_data->base->str);\n\twritel_relaxed(temp_cr, &device_data->base->cr);\n\n\treturn 0;\n}\n\n/**\n * hash_save_state - Function that saves the state of hardware.\n * @device_data:\tPointer to the device structure.\n * @device_state:\tThe strucure where the hardware state should be saved.\n */\nint hash_save_state(struct hash_device_data *device_data,\n\t\t    struct hash_state *device_state)\n{\n\tu32 temp_cr;\n\tu32 count;\n\tint hash_mode = HASH_OPER_MODE_HASH;\n\n\tif (NULL == device_state) {\n\t\tdev_err(device_data->dev, \"%s: HASH_INVALID_PARAMETER!\\n\",\n\t\t\t__func__);\n\t\treturn -ENOTSUPP;\n\t}\n\n\t/* Write dummy value to force digest intermediate calculation. This\n\t * actually makes sure that there isn't any ongoing calculation in the\n\t * hardware.\n\t */\n\twhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\n\t\tcpu_relax();\n\n\ttemp_cr = readl_relaxed(&device_data->base->cr);\n\n\tdevice_state->str_reg = readl_relaxed(&device_data->base->str);\n\n\tdevice_state->din_reg = readl_relaxed(&device_data->base->din);\n\n\tif (readl(&device_data->base->cr) & HASH_CR_MODE_MASK)\n\t\thash_mode = HASH_OPER_MODE_HMAC;\n\telse\n\t\thash_mode = HASH_OPER_MODE_HASH;\n\n\tfor (count = 0; count < HASH_CSR_COUNT; count++) {\n\t\tif ((count >= 36) && (hash_mode == HASH_OPER_MODE_HASH))\n\t\t\tbreak;\n\n\t\tdevice_state->csr[count] =\n\t\t\treadl_relaxed(&device_data->base->csrx[count]);\n\t}\n\n\tdevice_state->csfull = readl_relaxed(&device_data->base->csfull);\n\tdevice_state->csdatain = readl_relaxed(&device_data->base->csdatain);\n\n\tdevice_state->temp_cr = temp_cr;\n\n\treturn 0;\n}\n\n/**\n * hash_check_hw - This routine checks for peripheral Ids and PCell Ids.\n * @device_data:\n *\n */\nint hash_check_hw(struct hash_device_data *device_data)\n{\n\t/* Checking Peripheral Ids  */\n\tif (HASH_P_ID0 == readl_relaxed(&device_data->base->periphid0) &&\n\t    HASH_P_ID1 == readl_relaxed(&device_data->base->periphid1) &&\n\t    HASH_P_ID2 == readl_relaxed(&device_data->base->periphid2) &&\n\t    HASH_P_ID3 == readl_relaxed(&device_data->base->periphid3) &&\n\t    HASH_CELL_ID0 == readl_relaxed(&device_data->base->cellid0) &&\n\t    HASH_CELL_ID1 == readl_relaxed(&device_data->base->cellid1) &&\n\t    HASH_CELL_ID2 == readl_relaxed(&device_data->base->cellid2) &&\n\t    HASH_CELL_ID3 == readl_relaxed(&device_data->base->cellid3)) {\n\t\treturn 0;\n\t}\n\n\tdev_err(device_data->dev, \"%s: HASH_UNSUPPORTED_HW!\\n\", __func__);\n\treturn -ENOTSUPP;\n}\n\n/**\n * hash_get_digest - Gets the digest.\n * @device_data:\tPointer to the device structure.\n * @digest:\t\tUser allocated byte array for the calculated digest.\n * @algorithm:\t\tThe algorithm in use.\n */\nvoid hash_get_digest(struct hash_device_data *device_data,\n\t\t     u8 *digest, int algorithm)\n{\n\tu32 temp_hx_val, count;\n\tint loop_ctr;\n\n\tif (algorithm != HASH_ALGO_SHA1 && algorithm != HASH_ALGO_SHA256) {\n\t\tdev_err(device_data->dev, \"%s: Incorrect algorithm %d\\n\",\n\t\t\t__func__, algorithm);\n\t\treturn;\n\t}\n\n\tif (algorithm == HASH_ALGO_SHA1)\n\t\tloop_ctr = SHA1_DIGEST_SIZE / sizeof(u32);\n\telse\n\t\tloop_ctr = SHA256_DIGEST_SIZE / sizeof(u32);\n\n\tdev_dbg(device_data->dev, \"%s: digest array:(0x%x)\\n\",\n\t\t__func__, (u32) digest);\n\n\t/* Copy result into digest array */\n\tfor (count = 0; count < loop_ctr; count++) {\n\t\ttemp_hx_val = readl_relaxed(&device_data->base->hx[count]);\n\t\tdigest[count * 4] = (u8) ((temp_hx_val >> 24) & 0xFF);\n\t\tdigest[count * 4 + 1] = (u8) ((temp_hx_val >> 16) & 0xFF);\n\t\tdigest[count * 4 + 2] = (u8) ((temp_hx_val >> 8) & 0xFF);\n\t\tdigest[count * 4 + 3] = (u8) ((temp_hx_val >> 0) & 0xFF);\n\t}\n}\n\n/**\n * hash_update - The hash update function for SHA1/SHA2 (SHA256).\n * @req: The hash request for the job.\n */\nstatic int ahash_update(struct ahash_request *req)\n{\n\tint ret = 0;\n\tstruct hash_req_ctx *req_ctx = ahash_request_ctx(req);\n\n\tif (hash_mode != HASH_MODE_DMA || !req_ctx->dma_mode)\n\t\tret = hash_hw_update(req);\n\t/* Skip update for DMA, all data will be passed to DMA in final */\n\n\tif (ret) {\n\t\tpr_err(\"%s: hash_hw_update() failed!\\n\", __func__);\n\t}\n\n\treturn ret;\n}\n\n/**\n * hash_final - The hash final function for SHA1/SHA2 (SHA256).\n * @req:\tThe hash request for the job.\n */\nstatic int ahash_final(struct ahash_request *req)\n{\n\tint ret = 0;\n\tstruct hash_req_ctx *req_ctx = ahash_request_ctx(req);\n\n\tpr_debug(\"%s: data size: %d\\n\", __func__, req->nbytes);\n\n\tif ((hash_mode == HASH_MODE_DMA) && req_ctx->dma_mode)\n\t\tret = hash_dma_final(req);\n\telse\n\t\tret = hash_hw_final(req);\n\n\tif (ret) {\n\t\tpr_err(\"%s: hash_hw/dma_final() failed\\n\", __func__);\n\t}\n\n\treturn ret;\n}\n\nstatic int hash_setkey(struct crypto_ahash *tfm,\n\t\t       const u8 *key, unsigned int keylen, int alg)\n{\n\tint ret = 0;\n\tstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\n\n\t/**\n\t * Freed in final.\n\t */\n\tctx->key = kmemdup(key, keylen, GFP_KERNEL);\n\tif (!ctx->key) {\n\t\tpr_err(\"%s: Failed to allocate ctx->key for %d\\n\",\n\t\t       __func__, alg);\n\t\treturn -ENOMEM;\n\t}\n\tctx->keylen = keylen;\n\n\treturn ret;\n}\n\nstatic int ahash_sha1_init(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\n\n\tctx->config.data_format = HASH_DATA_8_BITS;\n\tctx->config.algorithm = HASH_ALGO_SHA1;\n\tctx->config.oper_mode = HASH_OPER_MODE_HASH;\n\tctx->digestsize = SHA1_DIGEST_SIZE;\n\n\treturn hash_init(req);\n}\n\nstatic int ahash_sha256_init(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\n\n\tctx->config.data_format = HASH_DATA_8_BITS;\n\tctx->config.algorithm = HASH_ALGO_SHA256;\n\tctx->config.oper_mode = HASH_OPER_MODE_HASH;\n\tctx->digestsize = SHA256_DIGEST_SIZE;\n\n\treturn hash_init(req);\n}\n\nstatic int ahash_sha1_digest(struct ahash_request *req)\n{\n\tint ret2, ret1;\n\n\tret1 = ahash_sha1_init(req);\n\tif (ret1)\n\t\tgoto out;\n\n\tret1 = ahash_update(req);\n\tret2 = ahash_final(req);\n\nout:\n\treturn ret1 ? ret1 : ret2;\n}\n\nstatic int ahash_sha256_digest(struct ahash_request *req)\n{\n\tint ret2, ret1;\n\n\tret1 = ahash_sha256_init(req);\n\tif (ret1)\n\t\tgoto out;\n\n\tret1 = ahash_update(req);\n\tret2 = ahash_final(req);\n\nout:\n\treturn ret1 ? ret1 : ret2;\n}\n\nstatic int hmac_sha1_init(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\n\n\tctx->config.data_format\t= HASH_DATA_8_BITS;\n\tctx->config.algorithm\t= HASH_ALGO_SHA1;\n\tctx->config.oper_mode\t= HASH_OPER_MODE_HMAC;\n\tctx->digestsize\t\t= SHA1_DIGEST_SIZE;\n\n\treturn hash_init(req);\n}\n\nstatic int hmac_sha256_init(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\n\n\tctx->config.data_format\t= HASH_DATA_8_BITS;\n\tctx->config.algorithm\t= HASH_ALGO_SHA256;\n\tctx->config.oper_mode\t= HASH_OPER_MODE_HMAC;\n\tctx->digestsize\t\t= SHA256_DIGEST_SIZE;\n\n\treturn hash_init(req);\n}\n\nstatic int hmac_sha1_digest(struct ahash_request *req)\n{\n\tint ret2, ret1;\n\n\tret1 = hmac_sha1_init(req);\n\tif (ret1)\n\t\tgoto out;\n\n\tret1 = ahash_update(req);\n\tret2 = ahash_final(req);\n\nout:\n\treturn ret1 ? ret1 : ret2;\n}\n\nstatic int hmac_sha256_digest(struct ahash_request *req)\n{\n\tint ret2, ret1;\n\n\tret1 = hmac_sha256_init(req);\n\tif (ret1)\n\t\tgoto out;\n\n\tret1 = ahash_update(req);\n\tret2 = ahash_final(req);\n\nout:\n\treturn ret1 ? ret1 : ret2;\n}\n\nstatic int hmac_sha1_setkey(struct crypto_ahash *tfm,\n\t\t\t    const u8 *key, unsigned int keylen)\n{\n\treturn hash_setkey(tfm, key, keylen, HASH_ALGO_SHA1);\n}\n\nstatic int hmac_sha256_setkey(struct crypto_ahash *tfm,\n\t\t\t      const u8 *key, unsigned int keylen)\n{\n\treturn hash_setkey(tfm, key, keylen, HASH_ALGO_SHA256);\n}\n\nstruct hash_algo_template {\n\tstruct hash_config conf;\n\tstruct ahash_alg hash;\n};\n\nstatic int hash_cra_init(struct crypto_tfm *tfm)\n{\n\tstruct hash_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_alg *alg = tfm->__crt_alg;\n\tstruct hash_algo_template *hash_alg;\n\n\thash_alg = container_of(__crypto_ahash_alg(alg),\n\t\t\tstruct hash_algo_template,\n\t\t\thash);\n\n\tcrypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),\n\t\t\t\t sizeof(struct hash_req_ctx));\n\n\tctx->config.data_format = HASH_DATA_8_BITS;\n\tctx->config.algorithm = hash_alg->conf.algorithm;\n\tctx->config.oper_mode = hash_alg->conf.oper_mode;\n\n\tctx->digestsize = hash_alg->hash.halg.digestsize;\n\n\treturn 0;\n}\n\nstatic struct hash_algo_template hash_algs[] = {\n\t{\n\t\t.conf.algorithm = HASH_ALGO_SHA1,\n\t\t.conf.oper_mode = HASH_OPER_MODE_HASH,\n\t\t.hash = {\n\t\t\t.init = hash_init,\n\t\t\t.update = ahash_update,\n\t\t\t.final = ahash_final,\n\t\t\t.digest = ahash_sha1_digest,\n\t\t\t.halg.digestsize = SHA1_DIGEST_SIZE,\n\t\t\t.halg.statesize = sizeof(struct hash_ctx),\n\t\t\t.halg.base = {\n\t\t\t\t.cra_name = \"sha1\",\n\t\t\t\t.cra_driver_name = \"sha1-ux500\",\n\t\t\t\t.cra_flags = (CRYPTO_ALG_TYPE_AHASH |\n\t\t\t\t\t      CRYPTO_ALG_ASYNC),\n\t\t\t\t.cra_blocksize = SHA1_BLOCK_SIZE,\n\t\t\t\t.cra_ctxsize = sizeof(struct hash_ctx),\n\t\t\t\t.cra_init = hash_cra_init,\n\t\t\t\t.cra_module = THIS_MODULE,\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\t.conf.algorithm\t= HASH_ALGO_SHA256,\n\t\t.conf.oper_mode\t= HASH_OPER_MODE_HASH,\n\t\t.hash = {\n\t\t\t.init = hash_init,\n\t\t\t.update\t= ahash_update,\n\t\t\t.final = ahash_final,\n\t\t\t.digest = ahash_sha256_digest,\n\t\t\t.halg.digestsize = SHA256_DIGEST_SIZE,\n\t\t\t.halg.statesize = sizeof(struct hash_ctx),\n\t\t\t.halg.base = {\n\t\t\t\t.cra_name = \"sha256\",\n\t\t\t\t.cra_driver_name = \"sha256-ux500\",\n\t\t\t\t.cra_flags = (CRYPTO_ALG_TYPE_AHASH |\n\t\t\t\t\t      CRYPTO_ALG_ASYNC),\n\t\t\t\t.cra_blocksize = SHA256_BLOCK_SIZE,\n\t\t\t\t.cra_ctxsize = sizeof(struct hash_ctx),\n\t\t\t\t.cra_type = &crypto_ahash_type,\n\t\t\t\t.cra_init = hash_cra_init,\n\t\t\t\t.cra_module = THIS_MODULE,\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\t.conf.algorithm = HASH_ALGO_SHA1,\n\t\t.conf.oper_mode = HASH_OPER_MODE_HMAC,\n\t\t\t.hash = {\n\t\t\t.init = hash_init,\n\t\t\t.update = ahash_update,\n\t\t\t.final = ahash_final,\n\t\t\t.digest = hmac_sha1_digest,\n\t\t\t.setkey = hmac_sha1_setkey,\n\t\t\t.halg.digestsize = SHA1_DIGEST_SIZE,\n\t\t\t.halg.statesize = sizeof(struct hash_ctx),\n\t\t\t.halg.base = {\n\t\t\t\t.cra_name = \"hmac(sha1)\",\n\t\t\t\t.cra_driver_name = \"hmac-sha1-ux500\",\n\t\t\t\t.cra_flags = (CRYPTO_ALG_TYPE_AHASH |\n\t\t\t\t\t      CRYPTO_ALG_ASYNC),\n\t\t\t\t.cra_blocksize = SHA1_BLOCK_SIZE,\n\t\t\t\t.cra_ctxsize = sizeof(struct hash_ctx),\n\t\t\t\t.cra_type = &crypto_ahash_type,\n\t\t\t\t.cra_init = hash_cra_init,\n\t\t\t\t.cra_module = THIS_MODULE,\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\t.conf.algorithm = HASH_ALGO_SHA256,\n\t\t.conf.oper_mode = HASH_OPER_MODE_HMAC,\n\t\t.hash = {\n\t\t\t.init = hash_init,\n\t\t\t.update = ahash_update,\n\t\t\t.final = ahash_final,\n\t\t\t.digest = hmac_sha256_digest,\n\t\t\t.setkey = hmac_sha256_setkey,\n\t\t\t.halg.digestsize = SHA256_DIGEST_SIZE,\n\t\t\t.halg.statesize = sizeof(struct hash_ctx),\n\t\t\t.halg.base = {\n\t\t\t\t.cra_name = \"hmac(sha256)\",\n\t\t\t\t.cra_driver_name = \"hmac-sha256-ux500\",\n\t\t\t\t.cra_flags = (CRYPTO_ALG_TYPE_AHASH |\n\t\t\t\t\t      CRYPTO_ALG_ASYNC),\n\t\t\t\t.cra_blocksize = SHA256_BLOCK_SIZE,\n\t\t\t\t.cra_ctxsize = sizeof(struct hash_ctx),\n\t\t\t\t.cra_type = &crypto_ahash_type,\n\t\t\t\t.cra_init = hash_cra_init,\n\t\t\t\t.cra_module = THIS_MODULE,\n\t\t\t}\n\t\t}\n\t}\n};\n\n/**\n * hash_algs_register_all -\n */\nstatic int ahash_algs_register_all(struct hash_device_data *device_data)\n{\n\tint ret;\n\tint i;\n\tint count;\n\n\tfor (i = 0; i < ARRAY_SIZE(hash_algs); i++) {\n\t\tret = crypto_register_ahash(&hash_algs[i].hash);\n\t\tif (ret) {\n\t\t\tcount = i;\n\t\t\tdev_err(device_data->dev, \"%s: alg registration failed\\n\",\n\t\t\t\thash_algs[i].hash.halg.base.cra_driver_name);\n\t\t\tgoto unreg;\n\t\t}\n\t}\n\treturn 0;\nunreg:\n\tfor (i = 0; i < count; i++)\n\t\tcrypto_unregister_ahash(&hash_algs[i].hash);\n\treturn ret;\n}\n\n/**\n * hash_algs_unregister_all -\n */\nstatic void ahash_algs_unregister_all(struct hash_device_data *device_data)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(hash_algs); i++)\n\t\tcrypto_unregister_ahash(&hash_algs[i].hash);\n}\n\n/**\n * ux500_hash_probe - Function that probes the hash hardware.\n * @pdev: The platform device.\n */\nstatic int ux500_hash_probe(struct platform_device *pdev)\n{\n\tint\t\t\tret = 0;\n\tstruct resource\t\t*res = NULL;\n\tstruct hash_device_data *device_data;\n\tstruct device\t\t*dev = &pdev->dev;\n\n\tdevice_data = kzalloc(sizeof(*device_data), GFP_ATOMIC);\n\tif (!device_data) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tdevice_data->dev = dev;\n\tdevice_data->current_ctx = NULL;\n\n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tif (!res) {\n\t\tdev_dbg(dev, \"%s: platform_get_resource() failed!\\n\", __func__);\n\t\tret = -ENODEV;\n\t\tgoto out_kfree;\n\t}\n\n\tres = request_mem_region(res->start, resource_size(res), pdev->name);\n\tif (res == NULL) {\n\t\tdev_dbg(dev, \"%s: request_mem_region() failed!\\n\", __func__);\n\t\tret = -EBUSY;\n\t\tgoto out_kfree;\n\t}\n\n\tdevice_data->phybase = res->start;\n\tdevice_data->base = ioremap(res->start, resource_size(res));\n\tif (!device_data->base) {\n\t\tdev_err(dev, \"%s: ioremap() failed!\\n\", __func__);\n\t\tret = -ENOMEM;\n\t\tgoto out_free_mem;\n\t}\n\tspin_lock_init(&device_data->ctx_lock);\n\tspin_lock_init(&device_data->power_state_lock);\n\n\t/* Enable power for HASH1 hardware block */\n\tdevice_data->regulator = regulator_get(dev, \"v-ape\");\n\tif (IS_ERR(device_data->regulator)) {\n\t\tdev_err(dev, \"%s: regulator_get() failed!\\n\", __func__);\n\t\tret = PTR_ERR(device_data->regulator);\n\t\tdevice_data->regulator = NULL;\n\t\tgoto out_unmap;\n\t}\n\n\t/* Enable the clock for HASH1 hardware block */\n\tdevice_data->clk = clk_get(dev, NULL);\n\tif (IS_ERR(device_data->clk)) {\n\t\tdev_err(dev, \"%s: clk_get() failed!\\n\", __func__);\n\t\tret = PTR_ERR(device_data->clk);\n\t\tgoto out_regulator;\n\t}\n\n\tret = clk_prepare(device_data->clk);\n\tif (ret) {\n\t\tdev_err(dev, \"%s: clk_prepare() failed!\\n\", __func__);\n\t\tgoto out_clk;\n\t}\n\n\t/* Enable device power (and clock) */\n\tret = hash_enable_power(device_data, false);\n\tif (ret) {\n\t\tdev_err(dev, \"%s: hash_enable_power() failed!\\n\", __func__);\n\t\tgoto out_clk_unprepare;\n\t}\n\n\tret = hash_check_hw(device_data);\n\tif (ret) {\n\t\tdev_err(dev, \"%s: hash_check_hw() failed!\\n\", __func__);\n\t\tgoto out_power;\n\t}\n\n\tif (hash_mode == HASH_MODE_DMA)\n\t\thash_dma_setup_channel(device_data, dev);\n\n\tplatform_set_drvdata(pdev, device_data);\n\n\t/* Put the new device into the device list... */\n\tklist_add_tail(&device_data->list_node, &driver_data.device_list);\n\t/* ... and signal that a new device is available. */\n\tup(&driver_data.device_allocation);\n\n\tret = ahash_algs_register_all(device_data);\n\tif (ret) {\n\t\tdev_err(dev, \"%s: ahash_algs_register_all() failed!\\n\",\n\t\t\t__func__);\n\t\tgoto out_power;\n\t}\n\n\tdev_info(dev, \"successfully registered\\n\");\n\treturn 0;\n\nout_power:\n\thash_disable_power(device_data, false);\n\nout_clk_unprepare:\n\tclk_unprepare(device_data->clk);\n\nout_clk:\n\tclk_put(device_data->clk);\n\nout_regulator:\n\tregulator_put(device_data->regulator);\n\nout_unmap:\n\tiounmap(device_data->base);\n\nout_free_mem:\n\trelease_mem_region(res->start, resource_size(res));\n\nout_kfree:\n\tkfree(device_data);\nout:\n\treturn ret;\n}\n\n/**\n * ux500_hash_remove - Function that removes the hash device from the platform.\n * @pdev: The platform device.\n */\nstatic int ux500_hash_remove(struct platform_device *pdev)\n{\n\tstruct resource\t\t*res;\n\tstruct hash_device_data *device_data;\n\tstruct device\t\t*dev = &pdev->dev;\n\n\tdevice_data = platform_get_drvdata(pdev);\n\tif (!device_data) {\n\t\tdev_err(dev, \"%s: platform_get_drvdata() failed!\\n\", __func__);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* Try to decrease the number of available devices. */\n\tif (down_trylock(&driver_data.device_allocation))\n\t\treturn -EBUSY;\n\n\t/* Check that the device is free */\n\tspin_lock(&device_data->ctx_lock);\n\t/* current_ctx allocates a device, NULL = unallocated */\n\tif (device_data->current_ctx) {\n\t\t/* The device is busy */\n\t\tspin_unlock(&device_data->ctx_lock);\n\t\t/* Return the device to the pool. */\n\t\tup(&driver_data.device_allocation);\n\t\treturn -EBUSY;\n\t}\n\n\tspin_unlock(&device_data->ctx_lock);\n\n\t/* Remove the device from the list */\n\tif (klist_node_attached(&device_data->list_node))\n\t\tklist_remove(&device_data->list_node);\n\n\t/* If this was the last device, remove the services */\n\tif (list_empty(&driver_data.device_list.k_list))\n\t\tahash_algs_unregister_all(device_data);\n\n\tif (hash_disable_power(device_data, false))\n\t\tdev_err(dev, \"%s: hash_disable_power() failed\\n\",\n\t\t\t__func__);\n\n\tclk_unprepare(device_data->clk);\n\tclk_put(device_data->clk);\n\tregulator_put(device_data->regulator);\n\n\tiounmap(device_data->base);\n\n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tif (res)\n\t\trelease_mem_region(res->start, resource_size(res));\n\n\tkfree(device_data);\n\n\treturn 0;\n}\n\n/**\n * ux500_hash_shutdown - Function that shutdown the hash device.\n * @pdev: The platform device\n */\nstatic void ux500_hash_shutdown(struct platform_device *pdev)\n{\n\tstruct resource *res = NULL;\n\tstruct hash_device_data *device_data;\n\n\tdevice_data = platform_get_drvdata(pdev);\n\tif (!device_data) {\n\t\tdev_err(&pdev->dev, \"%s: platform_get_drvdata() failed!\\n\",\n\t\t\t__func__);\n\t\treturn;\n\t}\n\n\t/* Check that the device is free */\n\tspin_lock(&device_data->ctx_lock);\n\t/* current_ctx allocates a device, NULL = unallocated */\n\tif (!device_data->current_ctx) {\n\t\tif (down_trylock(&driver_data.device_allocation))\n\t\t\tdev_dbg(&pdev->dev, \"%s: Cryp still in use! Shutting down anyway...\\n\",\n\t\t\t\t__func__);\n\t\t/**\n\t\t * (Allocate the device)\n\t\t * Need to set this to non-null (dummy) value,\n\t\t * to avoid usage if context switching.\n\t\t */\n\t\tdevice_data->current_ctx++;\n\t}\n\tspin_unlock(&device_data->ctx_lock);\n\n\t/* Remove the device from the list */\n\tif (klist_node_attached(&device_data->list_node))\n\t\tklist_remove(&device_data->list_node);\n\n\t/* If this was the last device, remove the services */\n\tif (list_empty(&driver_data.device_list.k_list))\n\t\tahash_algs_unregister_all(device_data);\n\n\tiounmap(device_data->base);\n\n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tif (res)\n\t\trelease_mem_region(res->start, resource_size(res));\n\n\tif (hash_disable_power(device_data, false))\n\t\tdev_err(&pdev->dev, \"%s: hash_disable_power() failed\\n\",\n\t\t\t__func__);\n}\n\n#ifdef CONFIG_PM_SLEEP\n/**\n * ux500_hash_suspend - Function that suspends the hash device.\n * @dev:\tDevice to suspend.\n */\nstatic int ux500_hash_suspend(struct device *dev)\n{\n\tint ret;\n\tstruct hash_device_data *device_data;\n\tstruct hash_ctx *temp_ctx = NULL;\n\n\tdevice_data = dev_get_drvdata(dev);\n\tif (!device_data) {\n\t\tdev_err(dev, \"%s: platform_get_drvdata() failed!\\n\", __func__);\n\t\treturn -ENOMEM;\n\t}\n\n\tspin_lock(&device_data->ctx_lock);\n\tif (!device_data->current_ctx)\n\t\tdevice_data->current_ctx++;\n\tspin_unlock(&device_data->ctx_lock);\n\n\tif (device_data->current_ctx == ++temp_ctx) {\n\t\tif (down_interruptible(&driver_data.device_allocation))\n\t\t\tdev_dbg(dev, \"%s: down_interruptible() failed\\n\",\n\t\t\t\t__func__);\n\t\tret = hash_disable_power(device_data, false);\n\n\t} else {\n\t\tret = hash_disable_power(device_data, true);\n\t}\n\n\tif (ret)\n\t\tdev_err(dev, \"%s: hash_disable_power()\\n\", __func__);\n\n\treturn ret;\n}\n\n/**\n * ux500_hash_resume - Function that resume the hash device.\n * @dev:\tDevice to resume.\n */\nstatic int ux500_hash_resume(struct device *dev)\n{\n\tint ret = 0;\n\tstruct hash_device_data *device_data;\n\tstruct hash_ctx *temp_ctx = NULL;\n\n\tdevice_data = dev_get_drvdata(dev);\n\tif (!device_data) {\n\t\tdev_err(dev, \"%s: platform_get_drvdata() failed!\\n\", __func__);\n\t\treturn -ENOMEM;\n\t}\n\n\tspin_lock(&device_data->ctx_lock);\n\tif (device_data->current_ctx == ++temp_ctx)\n\t\tdevice_data->current_ctx = NULL;\n\tspin_unlock(&device_data->ctx_lock);\n\n\tif (!device_data->current_ctx)\n\t\tup(&driver_data.device_allocation);\n\telse\n\t\tret = hash_enable_power(device_data, true);\n\n\tif (ret)\n\t\tdev_err(dev, \"%s: hash_enable_power() failed!\\n\", __func__);\n\n\treturn ret;\n}\n#endif\n\nstatic SIMPLE_DEV_PM_OPS(ux500_hash_pm, ux500_hash_suspend, ux500_hash_resume);\n\nstatic const struct of_device_id ux500_hash_match[] = {\n\t{ .compatible = \"stericsson,ux500-hash\" },\n\t{ },\n};\n\nstatic struct platform_driver hash_driver = {\n\t.probe  = ux500_hash_probe,\n\t.remove = ux500_hash_remove,\n\t.shutdown = ux500_hash_shutdown,\n\t.driver = {\n\t\t.owner = THIS_MODULE,\n\t\t.name  = \"hash1\",\n\t\t.of_match_table = ux500_hash_match,\n\t\t.pm    = &ux500_hash_pm,\n\t}\n};\n\n/**\n * ux500_hash_mod_init - The kernel module init function.\n */\nstatic int __init ux500_hash_mod_init(void)\n{\n\tklist_init(&driver_data.device_list, NULL, NULL);\n\t/* Initialize the semaphore to 0 devices (locked state) */\n\tsema_init(&driver_data.device_allocation, 0);\n\n\treturn platform_driver_register(&hash_driver);\n}\n\n/**\n * ux500_hash_mod_fini - The kernel module exit function.\n */\nstatic void __exit ux500_hash_mod_fini(void)\n{\n\tplatform_driver_unregister(&hash_driver);\n}\n\nmodule_init(ux500_hash_mod_init);\nmodule_exit(ux500_hash_mod_fini);\n\nMODULE_DESCRIPTION(\"Driver for ST-Ericsson UX500 HASH engine.\");\nMODULE_LICENSE(\"GPL\");\n\nMODULE_ALIAS(\"sha1-all\");\nMODULE_ALIAS(\"sha256-all\");\nMODULE_ALIAS(\"hmac-sha1-all\");\nMODULE_ALIAS(\"hmac-sha256-all\");\n", "/*\n * Copyright IBM Corp. 2006, 2012\n * Author(s): Cornelia Huck <cornelia.huck@de.ibm.com>\n *\t      Martin Schwidefsky <schwidefsky@de.ibm.com>\n *\t      Ralph Wuerthner <rwuerthn@de.ibm.com>\n *\t      Felix Beck <felix.beck@de.ibm.com>\n *\t      Holger Dengler <hd@linux.vnet.ibm.com>\n *\n * Adjunct processor bus.\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2, or (at your option)\n * any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.\n */\n\n#define KMSG_COMPONENT \"ap\"\n#define pr_fmt(fmt) KMSG_COMPONENT \": \" fmt\n\n#include <linux/kernel_stat.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/delay.h>\n#include <linux/err.h>\n#include <linux/interrupt.h>\n#include <linux/workqueue.h>\n#include <linux/slab.h>\n#include <linux/notifier.h>\n#include <linux/kthread.h>\n#include <linux/mutex.h>\n#include <asm/reset.h>\n#include <asm/airq.h>\n#include <linux/atomic.h>\n#include <asm/isc.h>\n#include <linux/hrtimer.h>\n#include <linux/ktime.h>\n#include <asm/facility.h>\n\n#include \"ap_bus.h\"\n\n/* Some prototypes. */\nstatic void ap_scan_bus(struct work_struct *);\nstatic void ap_poll_all(unsigned long);\nstatic enum hrtimer_restart ap_poll_timeout(struct hrtimer *);\nstatic int ap_poll_thread_start(void);\nstatic void ap_poll_thread_stop(void);\nstatic void ap_request_timeout(unsigned long);\nstatic inline void ap_schedule_poll_timer(void);\nstatic int __ap_poll_device(struct ap_device *ap_dev, unsigned long *flags);\nstatic int ap_device_remove(struct device *dev);\nstatic int ap_device_probe(struct device *dev);\nstatic void ap_interrupt_handler(struct airq_struct *airq);\nstatic void ap_reset(struct ap_device *ap_dev);\nstatic void ap_config_timeout(unsigned long ptr);\nstatic int ap_select_domain(void);\nstatic void ap_query_configuration(void);\n\n/*\n * Module description.\n */\nMODULE_AUTHOR(\"IBM Corporation\");\nMODULE_DESCRIPTION(\"Adjunct Processor Bus driver, \" \\\n\t\t   \"Copyright IBM Corp. 2006, 2012\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS(\"z90crypt\");\n\n/*\n * Module parameter\n */\nint ap_domain_index = -1;\t/* Adjunct Processor Domain Index */\nmodule_param_named(domain, ap_domain_index, int, S_IRUSR|S_IRGRP);\nMODULE_PARM_DESC(domain, \"domain index for ap devices\");\nEXPORT_SYMBOL(ap_domain_index);\n\nstatic int ap_thread_flag = 0;\nmodule_param_named(poll_thread, ap_thread_flag, int, S_IRUSR|S_IRGRP);\nMODULE_PARM_DESC(poll_thread, \"Turn on/off poll thread, default is 0 (off).\");\n\nstatic struct device *ap_root_device = NULL;\nstatic struct ap_config_info *ap_configuration;\nstatic DEFINE_SPINLOCK(ap_device_list_lock);\nstatic LIST_HEAD(ap_device_list);\n\n/*\n * Workqueue & timer for bus rescan.\n */\nstatic struct workqueue_struct *ap_work_queue;\nstatic struct timer_list ap_config_timer;\nstatic int ap_config_time = AP_CONFIG_TIME;\nstatic DECLARE_WORK(ap_config_work, ap_scan_bus);\n\n/*\n * Tasklet & timer for AP request polling and interrupts\n */\nstatic DECLARE_TASKLET(ap_tasklet, ap_poll_all, 0);\nstatic atomic_t ap_poll_requests = ATOMIC_INIT(0);\nstatic DECLARE_WAIT_QUEUE_HEAD(ap_poll_wait);\nstatic struct task_struct *ap_poll_kthread = NULL;\nstatic DEFINE_MUTEX(ap_poll_thread_mutex);\nstatic DEFINE_SPINLOCK(ap_poll_timer_lock);\nstatic struct hrtimer ap_poll_timer;\n/* In LPAR poll with 4kHz frequency. Poll every 250000 nanoseconds.\n * If z/VM change to 1500000 nanoseconds to adjust to z/VM polling.*/\nstatic unsigned long long poll_timeout = 250000;\n\n/* Suspend flag */\nstatic int ap_suspend_flag;\n/* Flag to check if domain was set through module parameter domain=. This is\n * important when supsend and resume is done in a z/VM environment where the\n * domain might change. */\nstatic int user_set_domain = 0;\nstatic struct bus_type ap_bus_type;\n\n/* Adapter interrupt definitions */\nstatic int ap_airq_flag;\n\nstatic struct airq_struct ap_airq = {\n\t.handler = ap_interrupt_handler,\n\t.isc = AP_ISC,\n};\n\n/**\n * ap_using_interrupts() - Returns non-zero if interrupt support is\n * available.\n */\nstatic inline int ap_using_interrupts(void)\n{\n\treturn ap_airq_flag;\n}\n\n/**\n * ap_intructions_available() - Test if AP instructions are available.\n *\n * Returns 0 if the AP instructions are installed.\n */\nstatic inline int ap_instructions_available(void)\n{\n\tregister unsigned long reg0 asm (\"0\") = AP_MKQID(0,0);\n\tregister unsigned long reg1 asm (\"1\") = -ENODEV;\n\tregister unsigned long reg2 asm (\"2\") = 0UL;\n\n\tasm volatile(\n\t\t\"   .long 0xb2af0000\\n\"\t\t/* PQAP(TAPQ) */\n\t\t\"0: la    %1,0\\n\"\n\t\t\"1:\\n\"\n\t\tEX_TABLE(0b, 1b)\n\t\t: \"+d\" (reg0), \"+d\" (reg1), \"+d\" (reg2) : : \"cc\" );\n\treturn reg1;\n}\n\n/**\n * ap_interrupts_available(): Test if AP interrupts are available.\n *\n * Returns 1 if AP interrupts are available.\n */\nstatic int ap_interrupts_available(void)\n{\n\treturn test_facility(2) && test_facility(65);\n}\n\n/**\n * ap_configuration_available(): Test if AP configuration\n * information is available.\n *\n * Returns 1 if AP configuration information is available.\n */\n#ifdef CONFIG_64BIT\nstatic int ap_configuration_available(void)\n{\n\treturn test_facility(2) && test_facility(12);\n}\n#endif\n\n/**\n * ap_test_queue(): Test adjunct processor queue.\n * @qid: The AP queue number\n * @queue_depth: Pointer to queue depth value\n * @device_type: Pointer to device type value\n *\n * Returns AP queue status structure.\n */\nstatic inline struct ap_queue_status\nap_test_queue(ap_qid_t qid, int *queue_depth, int *device_type)\n{\n\tregister unsigned long reg0 asm (\"0\") = qid;\n\tregister struct ap_queue_status reg1 asm (\"1\");\n\tregister unsigned long reg2 asm (\"2\") = 0UL;\n\n\tasm volatile(\".long 0xb2af0000\"\t\t/* PQAP(TAPQ) */\n\t\t     : \"+d\" (reg0), \"=d\" (reg1), \"+d\" (reg2) : : \"cc\");\n\t*device_type = (int) (reg2 >> 24);\n\t*queue_depth = (int) (reg2 & 0xff);\n\treturn reg1;\n}\n\n/**\n * ap_reset_queue(): Reset adjunct processor queue.\n * @qid: The AP queue number\n *\n * Returns AP queue status structure.\n */\nstatic inline struct ap_queue_status ap_reset_queue(ap_qid_t qid)\n{\n\tregister unsigned long reg0 asm (\"0\") = qid | 0x01000000UL;\n\tregister struct ap_queue_status reg1 asm (\"1\");\n\tregister unsigned long reg2 asm (\"2\") = 0UL;\n\n\tasm volatile(\n\t\t\".long 0xb2af0000\"\t\t/* PQAP(RAPQ) */\n\t\t: \"+d\" (reg0), \"=d\" (reg1), \"+d\" (reg2) : : \"cc\");\n\treturn reg1;\n}\n\n#ifdef CONFIG_64BIT\n/**\n * ap_queue_interruption_control(): Enable interruption for a specific AP.\n * @qid: The AP queue number\n * @ind: The notification indicator byte\n *\n * Returns AP queue status.\n */\nstatic inline struct ap_queue_status\nap_queue_interruption_control(ap_qid_t qid, void *ind)\n{\n\tregister unsigned long reg0 asm (\"0\") = qid | 0x03000000UL;\n\tregister unsigned long reg1_in asm (\"1\") = 0x0000800000000000UL | AP_ISC;\n\tregister struct ap_queue_status reg1_out asm (\"1\");\n\tregister void *reg2 asm (\"2\") = ind;\n\tasm volatile(\n\t\t\".long 0xb2af0000\"\t\t/* PQAP(AQIC) */\n\t\t: \"+d\" (reg0), \"+d\" (reg1_in), \"=d\" (reg1_out), \"+d\" (reg2)\n\t\t:\n\t\t: \"cc\" );\n\treturn reg1_out;\n}\n#endif\n\n#ifdef CONFIG_64BIT\nstatic inline struct ap_queue_status\n__ap_query_functions(ap_qid_t qid, unsigned int *functions)\n{\n\tregister unsigned long reg0 asm (\"0\") = 0UL | qid | (1UL << 23);\n\tregister struct ap_queue_status reg1 asm (\"1\") = AP_QUEUE_STATUS_INVALID;\n\tregister unsigned long reg2 asm (\"2\");\n\n\tasm volatile(\n\t\t\".long 0xb2af0000\\n\"\t\t/* PQAP(TAPQ) */\n\t\t\"0:\\n\"\n\t\tEX_TABLE(0b, 0b)\n\t\t: \"+d\" (reg0), \"+d\" (reg1), \"=d\" (reg2)\n\t\t:\n\t\t: \"cc\");\n\n\t*functions = (unsigned int)(reg2 >> 32);\n\treturn reg1;\n}\n#endif\n\n#ifdef CONFIG_64BIT\nstatic inline int __ap_query_configuration(struct ap_config_info *config)\n{\n\tregister unsigned long reg0 asm (\"0\") = 0x04000000UL;\n\tregister unsigned long reg1 asm (\"1\") = -EINVAL;\n\tregister unsigned char *reg2 asm (\"2\") = (unsigned char *)config;\n\n\tasm volatile(\n\t\t\".long 0xb2af0000\\n\"\t\t/* PQAP(QCI) */\n\t\t\"0: la    %1,0\\n\"\n\t\t\"1:\\n\"\n\t\tEX_TABLE(0b, 1b)\n\t\t: \"+d\" (reg0), \"+d\" (reg1), \"+d\" (reg2)\n\t\t:\n\t\t: \"cc\");\n\n\treturn reg1;\n}\n#endif\n\n/**\n * ap_query_functions(): Query supported functions.\n * @qid: The AP queue number\n * @functions: Pointer to functions field.\n *\n * Returns\n *   0\t     on success.\n *   -ENODEV  if queue not valid.\n *   -EBUSY   if device busy.\n *   -EINVAL  if query function is not supported\n */\nstatic int ap_query_functions(ap_qid_t qid, unsigned int *functions)\n{\n#ifdef CONFIG_64BIT\n\tstruct ap_queue_status status;\n\tint i;\n\tstatus = __ap_query_functions(qid, functions);\n\n\tfor (i = 0; i < AP_MAX_RESET; i++) {\n\t\tif (ap_queue_status_invalid_test(&status))\n\t\t\treturn -ENODEV;\n\n\t\tswitch (status.response_code) {\n\t\tcase AP_RESPONSE_NORMAL:\n\t\t\treturn 0;\n\t\tcase AP_RESPONSE_RESET_IN_PROGRESS:\n\t\tcase AP_RESPONSE_BUSY:\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_Q_NOT_AVAIL:\n\t\tcase AP_RESPONSE_DECONFIGURED:\n\t\tcase AP_RESPONSE_CHECKSTOPPED:\n\t\tcase AP_RESPONSE_INVALID_ADDRESS:\n\t\t\treturn -ENODEV;\n\t\tcase AP_RESPONSE_OTHERWISE_CHANGED:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\tif (i < AP_MAX_RESET - 1) {\n\t\t\tudelay(5);\n\t\t\tstatus = __ap_query_functions(qid, functions);\n\t\t}\n\t}\n\treturn -EBUSY;\n#else\n\treturn -EINVAL;\n#endif\n}\n\n/**\n * ap_queue_enable_interruption(): Enable interruption on an AP.\n * @qid: The AP queue number\n * @ind: the notification indicator byte\n *\n * Enables interruption on AP queue via ap_queue_interruption_control(). Based\n * on the return value it waits a while and tests the AP queue if interrupts\n * have been switched on using ap_test_queue().\n */\nstatic int ap_queue_enable_interruption(ap_qid_t qid, void *ind)\n{\n#ifdef CONFIG_64BIT\n\tstruct ap_queue_status status;\n\tint t_depth, t_device_type, rc, i;\n\n\trc = -EBUSY;\n\tstatus = ap_queue_interruption_control(qid, ind);\n\n\tfor (i = 0; i < AP_MAX_RESET; i++) {\n\t\tswitch (status.response_code) {\n\t\tcase AP_RESPONSE_NORMAL:\n\t\t\tif (status.int_enabled)\n\t\t\t\treturn 0;\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_RESET_IN_PROGRESS:\n\t\tcase AP_RESPONSE_BUSY:\n\t\t\tif (i < AP_MAX_RESET - 1) {\n\t\t\t\tudelay(5);\n\t\t\t\tstatus = ap_queue_interruption_control(qid,\n\t\t\t\t\t\t\t\t       ind);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_Q_NOT_AVAIL:\n\t\tcase AP_RESPONSE_DECONFIGURED:\n\t\tcase AP_RESPONSE_CHECKSTOPPED:\n\t\tcase AP_RESPONSE_INVALID_ADDRESS:\n\t\t\treturn -ENODEV;\n\t\tcase AP_RESPONSE_OTHERWISE_CHANGED:\n\t\t\tif (status.int_enabled)\n\t\t\t\treturn 0;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\tif (i < AP_MAX_RESET - 1) {\n\t\t\tudelay(5);\n\t\t\tstatus = ap_test_queue(qid, &t_depth, &t_device_type);\n\t\t}\n\t}\n\treturn rc;\n#else\n\treturn -EINVAL;\n#endif\n}\n\n/**\n * __ap_send(): Send message to adjunct processor queue.\n * @qid: The AP queue number\n * @psmid: The program supplied message identifier\n * @msg: The message text\n * @length: The message length\n * @special: Special Bit\n *\n * Returns AP queue status structure.\n * Condition code 1 on NQAP can't happen because the L bit is 1.\n * Condition code 2 on NQAP also means the send is incomplete,\n * because a segment boundary was reached. The NQAP is repeated.\n */\nstatic inline struct ap_queue_status\n__ap_send(ap_qid_t qid, unsigned long long psmid, void *msg, size_t length,\n\t  unsigned int special)\n{\n\ttypedef struct { char _[length]; } msgblock;\n\tregister unsigned long reg0 asm (\"0\") = qid | 0x40000000UL;\n\tregister struct ap_queue_status reg1 asm (\"1\");\n\tregister unsigned long reg2 asm (\"2\") = (unsigned long) msg;\n\tregister unsigned long reg3 asm (\"3\") = (unsigned long) length;\n\tregister unsigned long reg4 asm (\"4\") = (unsigned int) (psmid >> 32);\n\tregister unsigned long reg5 asm (\"5\") = psmid & 0xffffffff;\n\n\tif (special == 1)\n\t\treg0 |= 0x400000UL;\n\n\tasm volatile (\n\t\t\"0: .long 0xb2ad0042\\n\"\t\t/* NQAP */\n\t\t\"   brc   2,0b\"\n\t\t: \"+d\" (reg0), \"=d\" (reg1), \"+d\" (reg2), \"+d\" (reg3)\n\t\t: \"d\" (reg4), \"d\" (reg5), \"m\" (*(msgblock *) msg)\n\t\t: \"cc\" );\n\treturn reg1;\n}\n\nint ap_send(ap_qid_t qid, unsigned long long psmid, void *msg, size_t length)\n{\n\tstruct ap_queue_status status;\n\n\tstatus = __ap_send(qid, psmid, msg, length, 0);\n\tswitch (status.response_code) {\n\tcase AP_RESPONSE_NORMAL:\n\t\treturn 0;\n\tcase AP_RESPONSE_Q_FULL:\n\tcase AP_RESPONSE_RESET_IN_PROGRESS:\n\t\treturn -EBUSY;\n\tcase AP_RESPONSE_REQ_FAC_NOT_INST:\n\t\treturn -EINVAL;\n\tdefault:\t/* Device is gone. */\n\t\treturn -ENODEV;\n\t}\n}\nEXPORT_SYMBOL(ap_send);\n\n/**\n * __ap_recv(): Receive message from adjunct processor queue.\n * @qid: The AP queue number\n * @psmid: Pointer to program supplied message identifier\n * @msg: The message text\n * @length: The message length\n *\n * Returns AP queue status structure.\n * Condition code 1 on DQAP means the receive has taken place\n * but only partially.\tThe response is incomplete, hence the\n * DQAP is repeated.\n * Condition code 2 on DQAP also means the receive is incomplete,\n * this time because a segment boundary was reached. Again, the\n * DQAP is repeated.\n * Note that gpr2 is used by the DQAP instruction to keep track of\n * any 'residual' length, in case the instruction gets interrupted.\n * Hence it gets zeroed before the instruction.\n */\nstatic inline struct ap_queue_status\n__ap_recv(ap_qid_t qid, unsigned long long *psmid, void *msg, size_t length)\n{\n\ttypedef struct { char _[length]; } msgblock;\n\tregister unsigned long reg0 asm(\"0\") = qid | 0x80000000UL;\n\tregister struct ap_queue_status reg1 asm (\"1\");\n\tregister unsigned long reg2 asm(\"2\") = 0UL;\n\tregister unsigned long reg4 asm(\"4\") = (unsigned long) msg;\n\tregister unsigned long reg5 asm(\"5\") = (unsigned long) length;\n\tregister unsigned long reg6 asm(\"6\") = 0UL;\n\tregister unsigned long reg7 asm(\"7\") = 0UL;\n\n\n\tasm volatile(\n\t\t\"0: .long 0xb2ae0064\\n\"\t\t/* DQAP */\n\t\t\"   brc   6,0b\\n\"\n\t\t: \"+d\" (reg0), \"=d\" (reg1), \"+d\" (reg2),\n\t\t\"+d\" (reg4), \"+d\" (reg5), \"+d\" (reg6), \"+d\" (reg7),\n\t\t\"=m\" (*(msgblock *) msg) : : \"cc\" );\n\t*psmid = (((unsigned long long) reg6) << 32) + reg7;\n\treturn reg1;\n}\n\nint ap_recv(ap_qid_t qid, unsigned long long *psmid, void *msg, size_t length)\n{\n\tstruct ap_queue_status status;\n\n\tstatus = __ap_recv(qid, psmid, msg, length);\n\tswitch (status.response_code) {\n\tcase AP_RESPONSE_NORMAL:\n\t\treturn 0;\n\tcase AP_RESPONSE_NO_PENDING_REPLY:\n\t\tif (status.queue_empty)\n\t\t\treturn -ENOENT;\n\t\treturn -EBUSY;\n\tcase AP_RESPONSE_RESET_IN_PROGRESS:\n\t\treturn -EBUSY;\n\tdefault:\n\t\treturn -ENODEV;\n\t}\n}\nEXPORT_SYMBOL(ap_recv);\n\n/**\n * ap_query_queue(): Check if an AP queue is available.\n * @qid: The AP queue number\n * @queue_depth: Pointer to queue depth value\n * @device_type: Pointer to device type value\n *\n * The test is repeated for AP_MAX_RESET times.\n */\nstatic int ap_query_queue(ap_qid_t qid, int *queue_depth, int *device_type)\n{\n\tstruct ap_queue_status status;\n\tint t_depth, t_device_type, rc, i;\n\n\trc = -EBUSY;\n\tfor (i = 0; i < AP_MAX_RESET; i++) {\n\t\tstatus = ap_test_queue(qid, &t_depth, &t_device_type);\n\t\tswitch (status.response_code) {\n\t\tcase AP_RESPONSE_NORMAL:\n\t\t\t*queue_depth = t_depth + 1;\n\t\t\t*device_type = t_device_type;\n\t\t\trc = 0;\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_Q_NOT_AVAIL:\n\t\t\trc = -ENODEV;\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_RESET_IN_PROGRESS:\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_DECONFIGURED:\n\t\t\trc = -ENODEV;\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_CHECKSTOPPED:\n\t\t\trc = -ENODEV;\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_INVALID_ADDRESS:\n\t\t\trc = -ENODEV;\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_OTHERWISE_CHANGED:\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_BUSY:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tBUG();\n\t\t}\n\t\tif (rc != -EBUSY)\n\t\t\tbreak;\n\t\tif (i < AP_MAX_RESET - 1)\n\t\t\tudelay(5);\n\t}\n\treturn rc;\n}\n\n/**\n * ap_init_queue(): Reset an AP queue.\n * @qid: The AP queue number\n *\n * Reset an AP queue and wait for it to become available again.\n */\nstatic int ap_init_queue(ap_qid_t qid)\n{\n\tstruct ap_queue_status status;\n\tint rc, dummy, i;\n\n\trc = -ENODEV;\n\tstatus = ap_reset_queue(qid);\n\tfor (i = 0; i < AP_MAX_RESET; i++) {\n\t\tswitch (status.response_code) {\n\t\tcase AP_RESPONSE_NORMAL:\n\t\t\tif (status.queue_empty)\n\t\t\t\trc = 0;\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_Q_NOT_AVAIL:\n\t\tcase AP_RESPONSE_DECONFIGURED:\n\t\tcase AP_RESPONSE_CHECKSTOPPED:\n\t\t\ti = AP_MAX_RESET;\t/* return with -ENODEV */\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_RESET_IN_PROGRESS:\n\t\t\trc = -EBUSY;\n\t\tcase AP_RESPONSE_BUSY:\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\tif (rc != -ENODEV && rc != -EBUSY)\n\t\t\tbreak;\n\t\tif (i < AP_MAX_RESET - 1) {\n\t\t\t/* Time we are waiting until we give up (0.7sec * 90).\n\t\t\t * Since the actual request (in progress) will not\n\t\t\t * interrupted immediately for the reset command,\n\t\t\t * we have to be patient. In worst case we have to\n\t\t\t * wait 60sec + reset time (some msec).\n\t\t\t */\n\t\t\tschedule_timeout(AP_RESET_TIMEOUT);\n\t\t\tstatus = ap_test_queue(qid, &dummy, &dummy);\n\t\t}\n\t}\n\tif (rc == 0 && ap_using_interrupts()) {\n\t\trc = ap_queue_enable_interruption(qid, ap_airq.lsi_ptr);\n\t\t/* If interruption mode is supported by the machine,\n\t\t* but an AP can not be enabled for interruption then\n\t\t* the AP will be discarded.    */\n\t\tif (rc)\n\t\t\tpr_err(\"Registering adapter interrupts for \"\n\t\t\t       \"AP %d failed\\n\", AP_QID_DEVICE(qid));\n\t}\n\treturn rc;\n}\n\n/**\n * ap_increase_queue_count(): Arm request timeout.\n * @ap_dev: Pointer to an AP device.\n *\n * Arm request timeout if an AP device was idle and a new request is submitted.\n */\nstatic void ap_increase_queue_count(struct ap_device *ap_dev)\n{\n\tint timeout = ap_dev->drv->request_timeout;\n\n\tap_dev->queue_count++;\n\tif (ap_dev->queue_count == 1) {\n\t\tmod_timer(&ap_dev->timeout, jiffies + timeout);\n\t\tap_dev->reset = AP_RESET_ARMED;\n\t}\n}\n\n/**\n * ap_decrease_queue_count(): Decrease queue count.\n * @ap_dev: Pointer to an AP device.\n *\n * If AP device is still alive, re-schedule request timeout if there are still\n * pending requests.\n */\nstatic void ap_decrease_queue_count(struct ap_device *ap_dev)\n{\n\tint timeout = ap_dev->drv->request_timeout;\n\n\tap_dev->queue_count--;\n\tif (ap_dev->queue_count > 0)\n\t\tmod_timer(&ap_dev->timeout, jiffies + timeout);\n\telse\n\t\t/*\n\t\t * The timeout timer should to be disabled now - since\n\t\t * del_timer_sync() is very expensive, we just tell via the\n\t\t * reset flag to ignore the pending timeout timer.\n\t\t */\n\t\tap_dev->reset = AP_RESET_IGNORE;\n}\n\n/*\n * AP device related attributes.\n */\nstatic ssize_t ap_hwtype_show(struct device *dev,\n\t\t\t      struct device_attribute *attr, char *buf)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", ap_dev->device_type);\n}\n\nstatic DEVICE_ATTR(hwtype, 0444, ap_hwtype_show, NULL);\n\nstatic ssize_t ap_raw_hwtype_show(struct device *dev,\n\t\t\t      struct device_attribute *attr, char *buf)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", ap_dev->raw_hwtype);\n}\n\nstatic DEVICE_ATTR(raw_hwtype, 0444, ap_raw_hwtype_show, NULL);\n\nstatic ssize_t ap_depth_show(struct device *dev, struct device_attribute *attr,\n\t\t\t     char *buf)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", ap_dev->queue_depth);\n}\n\nstatic DEVICE_ATTR(depth, 0444, ap_depth_show, NULL);\nstatic ssize_t ap_request_count_show(struct device *dev,\n\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t     char *buf)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\tint rc;\n\n\tspin_lock_bh(&ap_dev->lock);\n\trc = snprintf(buf, PAGE_SIZE, \"%d\\n\", ap_dev->total_request_count);\n\tspin_unlock_bh(&ap_dev->lock);\n\treturn rc;\n}\n\nstatic DEVICE_ATTR(request_count, 0444, ap_request_count_show, NULL);\n\nstatic ssize_t ap_requestq_count_show(struct device *dev,\n\t\t\t\t      struct device_attribute *attr, char *buf)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\tint rc;\n\n\tspin_lock_bh(&ap_dev->lock);\n\trc = snprintf(buf, PAGE_SIZE, \"%d\\n\", ap_dev->requestq_count);\n\tspin_unlock_bh(&ap_dev->lock);\n\treturn rc;\n}\n\nstatic DEVICE_ATTR(requestq_count, 0444, ap_requestq_count_show, NULL);\n\nstatic ssize_t ap_pendingq_count_show(struct device *dev,\n\t\t\t\t      struct device_attribute *attr, char *buf)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\tint rc;\n\n\tspin_lock_bh(&ap_dev->lock);\n\trc = snprintf(buf, PAGE_SIZE, \"%d\\n\", ap_dev->pendingq_count);\n\tspin_unlock_bh(&ap_dev->lock);\n\treturn rc;\n}\n\nstatic DEVICE_ATTR(pendingq_count, 0444, ap_pendingq_count_show, NULL);\n\nstatic ssize_t ap_modalias_show(struct device *dev,\n\t\t\t\tstruct device_attribute *attr, char *buf)\n{\n\treturn sprintf(buf, \"ap:t%02X\", to_ap_dev(dev)->device_type);\n}\n\nstatic DEVICE_ATTR(modalias, 0444, ap_modalias_show, NULL);\n\nstatic ssize_t ap_functions_show(struct device *dev,\n\t\t\t\t struct device_attribute *attr, char *buf)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\treturn snprintf(buf, PAGE_SIZE, \"0x%08X\\n\", ap_dev->functions);\n}\n\nstatic DEVICE_ATTR(ap_functions, 0444, ap_functions_show, NULL);\n\nstatic struct attribute *ap_dev_attrs[] = {\n\t&dev_attr_hwtype.attr,\n\t&dev_attr_raw_hwtype.attr,\n\t&dev_attr_depth.attr,\n\t&dev_attr_request_count.attr,\n\t&dev_attr_requestq_count.attr,\n\t&dev_attr_pendingq_count.attr,\n\t&dev_attr_modalias.attr,\n\t&dev_attr_ap_functions.attr,\n\tNULL\n};\nstatic struct attribute_group ap_dev_attr_group = {\n\t.attrs = ap_dev_attrs\n};\n\n/**\n * ap_bus_match()\n * @dev: Pointer to device\n * @drv: Pointer to device_driver\n *\n * AP bus driver registration/unregistration.\n */\nstatic int ap_bus_match(struct device *dev, struct device_driver *drv)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\tstruct ap_driver *ap_drv = to_ap_drv(drv);\n\tstruct ap_device_id *id;\n\n\t/*\n\t * Compare device type of the device with the list of\n\t * supported types of the device_driver.\n\t */\n\tfor (id = ap_drv->ids; id->match_flags; id++) {\n\t\tif ((id->match_flags & AP_DEVICE_ID_MATCH_DEVICE_TYPE) &&\n\t\t    (id->dev_type != ap_dev->device_type))\n\t\t\tcontinue;\n\t\treturn 1;\n\t}\n\treturn 0;\n}\n\n/**\n * ap_uevent(): Uevent function for AP devices.\n * @dev: Pointer to device\n * @env: Pointer to kobj_uevent_env\n *\n * It sets up a single environment variable DEV_TYPE which contains the\n * hardware device type.\n */\nstatic int ap_uevent (struct device *dev, struct kobj_uevent_env *env)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\tint retval = 0;\n\n\tif (!ap_dev)\n\t\treturn -ENODEV;\n\n\t/* Set up DEV_TYPE environment variable. */\n\tretval = add_uevent_var(env, \"DEV_TYPE=%04X\", ap_dev->device_type);\n\tif (retval)\n\t\treturn retval;\n\n\t/* Add MODALIAS= */\n\tretval = add_uevent_var(env, \"MODALIAS=ap:t%02X\", ap_dev->device_type);\n\n\treturn retval;\n}\n\nstatic int ap_bus_suspend(struct device *dev, pm_message_t state)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\tunsigned long flags;\n\n\tif (!ap_suspend_flag) {\n\t\tap_suspend_flag = 1;\n\n\t\t/* Disable scanning for devices, thus we do not want to scan\n\t\t * for them after removing.\n\t\t */\n\t\tdel_timer_sync(&ap_config_timer);\n\t\tif (ap_work_queue != NULL) {\n\t\t\tdestroy_workqueue(ap_work_queue);\n\t\t\tap_work_queue = NULL;\n\t\t}\n\n\t\ttasklet_disable(&ap_tasklet);\n\t}\n\t/* Poll on the device until all requests are finished. */\n\tdo {\n\t\tflags = 0;\n\t\tspin_lock_bh(&ap_dev->lock);\n\t\t__ap_poll_device(ap_dev, &flags);\n\t\tspin_unlock_bh(&ap_dev->lock);\n\t} while ((flags & 1) || (flags & 2));\n\n\tspin_lock_bh(&ap_dev->lock);\n\tap_dev->unregistered = 1;\n\tspin_unlock_bh(&ap_dev->lock);\n\n\treturn 0;\n}\n\nstatic int ap_bus_resume(struct device *dev)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\tint rc;\n\n\tif (ap_suspend_flag) {\n\t\tap_suspend_flag = 0;\n\t\tif (ap_interrupts_available()) {\n\t\t\tif (!ap_using_interrupts()) {\n\t\t\t\trc = register_adapter_interrupt(&ap_airq);\n\t\t\t\tap_airq_flag = (rc == 0);\n\t\t\t}\n\t\t} else {\n\t\t\tif (ap_using_interrupts()) {\n\t\t\t\tunregister_adapter_interrupt(&ap_airq);\n\t\t\t\tap_airq_flag = 0;\n\t\t\t}\n\t\t}\n\t\tap_query_configuration();\n\t\tif (!user_set_domain) {\n\t\t\tap_domain_index = -1;\n\t\t\tap_select_domain();\n\t\t}\n\t\tinit_timer(&ap_config_timer);\n\t\tap_config_timer.function = ap_config_timeout;\n\t\tap_config_timer.data = 0;\n\t\tap_config_timer.expires = jiffies + ap_config_time * HZ;\n\t\tadd_timer(&ap_config_timer);\n\t\tap_work_queue = create_singlethread_workqueue(\"kapwork\");\n\t\tif (!ap_work_queue)\n\t\t\treturn -ENOMEM;\n\t\ttasklet_enable(&ap_tasklet);\n\t\tif (!ap_using_interrupts())\n\t\t\tap_schedule_poll_timer();\n\t\telse\n\t\t\ttasklet_schedule(&ap_tasklet);\n\t\tif (ap_thread_flag)\n\t\t\trc = ap_poll_thread_start();\n\t\telse\n\t\t\trc = 0;\n\t} else\n\t\trc = 0;\n\tif (AP_QID_QUEUE(ap_dev->qid) != ap_domain_index) {\n\t\tspin_lock_bh(&ap_dev->lock);\n\t\tap_dev->qid = AP_MKQID(AP_QID_DEVICE(ap_dev->qid),\n\t\t\t\t       ap_domain_index);\n\t\tspin_unlock_bh(&ap_dev->lock);\n\t}\n\tqueue_work(ap_work_queue, &ap_config_work);\n\n\treturn rc;\n}\n\nstatic struct bus_type ap_bus_type = {\n\t.name = \"ap\",\n\t.match = &ap_bus_match,\n\t.uevent = &ap_uevent,\n\t.suspend = ap_bus_suspend,\n\t.resume = ap_bus_resume\n};\n\nstatic int ap_device_probe(struct device *dev)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\tstruct ap_driver *ap_drv = to_ap_drv(dev->driver);\n\tint rc;\n\n\tap_dev->drv = ap_drv;\n\n\tspin_lock_bh(&ap_device_list_lock);\n\tlist_add(&ap_dev->list, &ap_device_list);\n\tspin_unlock_bh(&ap_device_list_lock);\n\n\trc = ap_drv->probe ? ap_drv->probe(ap_dev) : -ENODEV;\n\tif (rc) {\n\t\tspin_lock_bh(&ap_device_list_lock);\n\t\tlist_del_init(&ap_dev->list);\n\t\tspin_unlock_bh(&ap_device_list_lock);\n\t}\n\treturn rc;\n}\n\n/**\n * __ap_flush_queue(): Flush requests.\n * @ap_dev: Pointer to the AP device\n *\n * Flush all requests from the request/pending queue of an AP device.\n */\nstatic void __ap_flush_queue(struct ap_device *ap_dev)\n{\n\tstruct ap_message *ap_msg, *next;\n\n\tlist_for_each_entry_safe(ap_msg, next, &ap_dev->pendingq, list) {\n\t\tlist_del_init(&ap_msg->list);\n\t\tap_dev->pendingq_count--;\n\t\tap_msg->receive(ap_dev, ap_msg, ERR_PTR(-ENODEV));\n\t}\n\tlist_for_each_entry_safe(ap_msg, next, &ap_dev->requestq, list) {\n\t\tlist_del_init(&ap_msg->list);\n\t\tap_dev->requestq_count--;\n\t\tap_msg->receive(ap_dev, ap_msg, ERR_PTR(-ENODEV));\n\t}\n}\n\nvoid ap_flush_queue(struct ap_device *ap_dev)\n{\n\tspin_lock_bh(&ap_dev->lock);\n\t__ap_flush_queue(ap_dev);\n\tspin_unlock_bh(&ap_dev->lock);\n}\nEXPORT_SYMBOL(ap_flush_queue);\n\nstatic int ap_device_remove(struct device *dev)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\tstruct ap_driver *ap_drv = ap_dev->drv;\n\n\tap_flush_queue(ap_dev);\n\tdel_timer_sync(&ap_dev->timeout);\n\tspin_lock_bh(&ap_device_list_lock);\n\tlist_del_init(&ap_dev->list);\n\tspin_unlock_bh(&ap_device_list_lock);\n\tif (ap_drv->remove)\n\t\tap_drv->remove(ap_dev);\n\tspin_lock_bh(&ap_dev->lock);\n\tatomic_sub(ap_dev->queue_count, &ap_poll_requests);\n\tspin_unlock_bh(&ap_dev->lock);\n\treturn 0;\n}\n\nint ap_driver_register(struct ap_driver *ap_drv, struct module *owner,\n\t\t       char *name)\n{\n\tstruct device_driver *drv = &ap_drv->driver;\n\n\tdrv->bus = &ap_bus_type;\n\tdrv->probe = ap_device_probe;\n\tdrv->remove = ap_device_remove;\n\tdrv->owner = owner;\n\tdrv->name = name;\n\treturn driver_register(drv);\n}\nEXPORT_SYMBOL(ap_driver_register);\n\nvoid ap_driver_unregister(struct ap_driver *ap_drv)\n{\n\tdriver_unregister(&ap_drv->driver);\n}\nEXPORT_SYMBOL(ap_driver_unregister);\n\nvoid ap_bus_force_rescan(void)\n{\n\t/* reconfigure the AP bus rescan timer. */\n\tmod_timer(&ap_config_timer, jiffies + ap_config_time * HZ);\n\t/* processing a asynchronous bus rescan */\n\tqueue_work(ap_work_queue, &ap_config_work);\n\tflush_work(&ap_config_work);\n}\nEXPORT_SYMBOL(ap_bus_force_rescan);\n\n/*\n * AP bus attributes.\n */\nstatic ssize_t ap_domain_show(struct bus_type *bus, char *buf)\n{\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", ap_domain_index);\n}\n\nstatic BUS_ATTR(ap_domain, 0444, ap_domain_show, NULL);\n\nstatic ssize_t ap_control_domain_mask_show(struct bus_type *bus, char *buf)\n{\n\tif (ap_configuration != NULL) { /* QCI not supported */\n\t\tif (test_facility(76)) { /* format 1 - 256 bit domain field */\n\t\t\treturn snprintf(buf, PAGE_SIZE,\n\t\t\t\t\"0x%08x%08x%08x%08x%08x%08x%08x%08x\\n\",\n\t\t\tap_configuration->adm[0], ap_configuration->adm[1],\n\t\t\tap_configuration->adm[2], ap_configuration->adm[3],\n\t\t\tap_configuration->adm[4], ap_configuration->adm[5],\n\t\t\tap_configuration->adm[6], ap_configuration->adm[7]);\n\t\t} else { /* format 0 - 16 bit domain field */\n\t\t\treturn snprintf(buf, PAGE_SIZE, \"%08x%08x\\n\",\n\t\t\tap_configuration->adm[0], ap_configuration->adm[1]);\n\t\t  }\n\t} else {\n\t\treturn snprintf(buf, PAGE_SIZE, \"not supported\\n\");\n\t  }\n}\n\nstatic BUS_ATTR(ap_control_domain_mask, 0444,\n\t\tap_control_domain_mask_show, NULL);\n\nstatic ssize_t ap_config_time_show(struct bus_type *bus, char *buf)\n{\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", ap_config_time);\n}\n\nstatic ssize_t ap_interrupts_show(struct bus_type *bus, char *buf)\n{\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\",\n\t\t\tap_using_interrupts() ? 1 : 0);\n}\n\nstatic BUS_ATTR(ap_interrupts, 0444, ap_interrupts_show, NULL);\n\nstatic ssize_t ap_config_time_store(struct bus_type *bus,\n\t\t\t\t    const char *buf, size_t count)\n{\n\tint time;\n\n\tif (sscanf(buf, \"%d\\n\", &time) != 1 || time < 5 || time > 120)\n\t\treturn -EINVAL;\n\tap_config_time = time;\n\tif (!timer_pending(&ap_config_timer) ||\n\t    !mod_timer(&ap_config_timer, jiffies + ap_config_time * HZ)) {\n\t\tap_config_timer.expires = jiffies + ap_config_time * HZ;\n\t\tadd_timer(&ap_config_timer);\n\t}\n\treturn count;\n}\n\nstatic BUS_ATTR(config_time, 0644, ap_config_time_show, ap_config_time_store);\n\nstatic ssize_t ap_poll_thread_show(struct bus_type *bus, char *buf)\n{\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", ap_poll_kthread ? 1 : 0);\n}\n\nstatic ssize_t ap_poll_thread_store(struct bus_type *bus,\n\t\t\t\t    const char *buf, size_t count)\n{\n\tint flag, rc;\n\n\tif (sscanf(buf, \"%d\\n\", &flag) != 1)\n\t\treturn -EINVAL;\n\tif (flag) {\n\t\trc = ap_poll_thread_start();\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\telse\n\t\tap_poll_thread_stop();\n\treturn count;\n}\n\nstatic BUS_ATTR(poll_thread, 0644, ap_poll_thread_show, ap_poll_thread_store);\n\nstatic ssize_t poll_timeout_show(struct bus_type *bus, char *buf)\n{\n\treturn snprintf(buf, PAGE_SIZE, \"%llu\\n\", poll_timeout);\n}\n\nstatic ssize_t poll_timeout_store(struct bus_type *bus, const char *buf,\n\t\t\t\t  size_t count)\n{\n\tunsigned long long time;\n\tktime_t hr_time;\n\n\t/* 120 seconds = maximum poll interval */\n\tif (sscanf(buf, \"%llu\\n\", &time) != 1 || time < 1 ||\n\t    time > 120000000000ULL)\n\t\treturn -EINVAL;\n\tpoll_timeout = time;\n\thr_time = ktime_set(0, poll_timeout);\n\n\tif (!hrtimer_is_queued(&ap_poll_timer) ||\n\t    !hrtimer_forward(&ap_poll_timer, hrtimer_get_expires(&ap_poll_timer), hr_time)) {\n\t\thrtimer_set_expires(&ap_poll_timer, hr_time);\n\t\thrtimer_start_expires(&ap_poll_timer, HRTIMER_MODE_ABS);\n\t}\n\treturn count;\n}\n\nstatic BUS_ATTR(poll_timeout, 0644, poll_timeout_show, poll_timeout_store);\n\nstatic struct bus_attribute *const ap_bus_attrs[] = {\n\t&bus_attr_ap_domain,\n\t&bus_attr_ap_control_domain_mask,\n\t&bus_attr_config_time,\n\t&bus_attr_poll_thread,\n\t&bus_attr_ap_interrupts,\n\t&bus_attr_poll_timeout,\n\tNULL,\n};\n\nstatic inline int ap_test_config(unsigned int *field, unsigned int nr)\n{\n\tif (nr > 0xFFu)\n\t\treturn 0;\n\treturn ap_test_bit((field + (nr >> 5)), (nr & 0x1f));\n}\n\n/*\n * ap_test_config_card_id(): Test, whether an AP card ID is configured.\n * @id AP card ID\n *\n * Returns 0 if the card is not configured\n *\t   1 if the card is configured or\n *\t     if the configuration information is not available\n */\nstatic inline int ap_test_config_card_id(unsigned int id)\n{\n\tif (!ap_configuration)\n\t\treturn 1;\n\treturn ap_test_config(ap_configuration->apm, id);\n}\n\n/*\n * ap_test_config_domain(): Test, whether an AP usage domain is configured.\n * @domain AP usage domain ID\n *\n * Returns 0 if the usage domain is not configured\n *\t   1 if the usage domain is configured or\n *\t     if the configuration information is not available\n */\nstatic inline int ap_test_config_domain(unsigned int domain)\n{\n\tif (!ap_configuration)\n\t\treturn 1;\n\treturn ap_test_config(ap_configuration->aqm, domain);\n}\n\n/**\n * ap_query_configuration(): Query AP configuration information.\n *\n * Query information of installed cards and configured domains from AP.\n */\nstatic void ap_query_configuration(void)\n{\n#ifdef CONFIG_64BIT\n\tif (ap_configuration_available()) {\n\t\tif (!ap_configuration)\n\t\t\tap_configuration =\n\t\t\t\tkzalloc(sizeof(struct ap_config_info),\n\t\t\t\t\tGFP_KERNEL);\n\t\tif (ap_configuration)\n\t\t\t__ap_query_configuration(ap_configuration);\n\t} else\n\t\tap_configuration = NULL;\n#else\n\tap_configuration = NULL;\n#endif\n}\n\n/**\n * ap_select_domain(): Select an AP domain.\n *\n * Pick one of the 16 AP domains.\n */\nstatic int ap_select_domain(void)\n{\n\tint queue_depth, device_type, count, max_count, best_domain;\n\tap_qid_t qid;\n\tint rc, i, j;\n\n\t/* IF APXA isn't installed, only 16 domains could be defined */\n\tif (!ap_configuration->ap_extended && (ap_domain_index > 15))\n\t\treturn -EINVAL;\n\n\t/*\n\t * We want to use a single domain. Either the one specified with\n\t * the \"domain=\" parameter or the domain with the maximum number\n\t * of devices.\n\t */\n\tif (ap_domain_index >= 0 && ap_domain_index < AP_DOMAINS)\n\t\t/* Domain has already been selected. */\n\t\treturn 0;\n\tbest_domain = -1;\n\tmax_count = 0;\n\tfor (i = 0; i < AP_DOMAINS; i++) {\n\t\tif (!ap_test_config_domain(i))\n\t\t\tcontinue;\n\t\tcount = 0;\n\t\tfor (j = 0; j < AP_DEVICES; j++) {\n\t\t\tif (!ap_test_config_card_id(j))\n\t\t\t\tcontinue;\n\t\t\tqid = AP_MKQID(j, i);\n\t\t\trc = ap_query_queue(qid, &queue_depth, &device_type);\n\t\t\tif (rc)\n\t\t\t\tcontinue;\n\t\t\tcount++;\n\t\t}\n\t\tif (count > max_count) {\n\t\t\tmax_count = count;\n\t\t\tbest_domain = i;\n\t\t}\n\t}\n\tif (best_domain >= 0){\n\t\tap_domain_index = best_domain;\n\t\treturn 0;\n\t}\n\treturn -ENODEV;\n}\n\n/**\n * ap_probe_device_type(): Find the device type of an AP.\n * @ap_dev: pointer to the AP device.\n *\n * Find the device type if query queue returned a device type of 0.\n */\nstatic int ap_probe_device_type(struct ap_device *ap_dev)\n{\n\tstatic unsigned char msg[] = {\n\t\t0x00,0x06,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x58,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x01,0x00,0x43,0x43,0x41,0x2d,0x41,0x50,\n\t\t0x50,0x4c,0x20,0x20,0x20,0x01,0x01,0x01,\n\t\t0x00,0x00,0x00,0x00,0x50,0x4b,0x00,0x00,\n\t\t0x00,0x00,0x01,0x1c,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x05,0xb8,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x70,0x00,0x41,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x54,0x32,0x01,0x00,0xa0,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0xb8,0x05,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x0a,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x08,0x00,\n\t\t0x49,0x43,0x53,0x46,0x20,0x20,0x20,0x20,\n\t\t0x50,0x4b,0x0a,0x00,0x50,0x4b,0x43,0x53,\n\t\t0x2d,0x31,0x2e,0x32,0x37,0x00,0x11,0x22,\n\t\t0x33,0x44,0x55,0x66,0x77,0x88,0x99,0x00,\n\t\t0x11,0x22,0x33,0x44,0x55,0x66,0x77,0x88,\n\t\t0x99,0x00,0x11,0x22,0x33,0x44,0x55,0x66,\n\t\t0x77,0x88,0x99,0x00,0x11,0x22,0x33,0x44,\n\t\t0x55,0x66,0x77,0x88,0x99,0x00,0x11,0x22,\n\t\t0x33,0x44,0x55,0x66,0x77,0x88,0x99,0x00,\n\t\t0x11,0x22,0x33,0x5d,0x00,0x5b,0x00,0x77,\n\t\t0x88,0x1e,0x00,0x00,0x57,0x00,0x00,0x00,\n\t\t0x00,0x04,0x00,0x00,0x4f,0x00,0x00,0x00,\n\t\t0x03,0x02,0x00,0x00,0x40,0x01,0x00,0x01,\n\t\t0xce,0x02,0x68,0x2d,0x5f,0xa9,0xde,0x0c,\n\t\t0xf6,0xd2,0x7b,0x58,0x4b,0xf9,0x28,0x68,\n\t\t0x3d,0xb4,0xf4,0xef,0x78,0xd5,0xbe,0x66,\n\t\t0x63,0x42,0xef,0xf8,0xfd,0xa4,0xf8,0xb0,\n\t\t0x8e,0x29,0xc2,0xc9,0x2e,0xd8,0x45,0xb8,\n\t\t0x53,0x8c,0x6f,0x4e,0x72,0x8f,0x6c,0x04,\n\t\t0x9c,0x88,0xfc,0x1e,0xc5,0x83,0x55,0x57,\n\t\t0xf7,0xdd,0xfd,0x4f,0x11,0x36,0x95,0x5d,\n\t};\n\tstruct ap_queue_status status;\n\tunsigned long long psmid;\n\tchar *reply;\n\tint rc, i;\n\n\treply = (void *) get_zeroed_page(GFP_KERNEL);\n\tif (!reply) {\n\t\trc = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tstatus = __ap_send(ap_dev->qid, 0x0102030405060708ULL,\n\t\t\t   msg, sizeof(msg), 0);\n\tif (status.response_code != AP_RESPONSE_NORMAL) {\n\t\trc = -ENODEV;\n\t\tgoto out_free;\n\t}\n\n\t/* Wait for the test message to complete. */\n\tfor (i = 0; i < 6; i++) {\n\t\tmdelay(300);\n\t\tstatus = __ap_recv(ap_dev->qid, &psmid, reply, 4096);\n\t\tif (status.response_code == AP_RESPONSE_NORMAL &&\n\t\t    psmid == 0x0102030405060708ULL)\n\t\t\tbreak;\n\t}\n\tif (i < 6) {\n\t\t/* Got an answer. */\n\t\tif (reply[0] == 0x00 && reply[1] == 0x86)\n\t\t\tap_dev->device_type = AP_DEVICE_TYPE_PCICC;\n\t\telse\n\t\t\tap_dev->device_type = AP_DEVICE_TYPE_PCICA;\n\t\trc = 0;\n\t} else\n\t\trc = -ENODEV;\n\nout_free:\n\tfree_page((unsigned long) reply);\nout:\n\treturn rc;\n}\n\nstatic void ap_interrupt_handler(struct airq_struct *airq)\n{\n\tinc_irq_stat(IRQIO_APB);\n\ttasklet_schedule(&ap_tasklet);\n}\n\n/**\n * __ap_scan_bus(): Scan the AP bus.\n * @dev: Pointer to device\n * @data: Pointer to data\n *\n * Scan the AP bus for new devices.\n */\nstatic int __ap_scan_bus(struct device *dev, void *data)\n{\n\treturn to_ap_dev(dev)->qid == (ap_qid_t)(unsigned long) data;\n}\n\nstatic void ap_device_release(struct device *dev)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\n\tkfree(ap_dev);\n}\n\nstatic void ap_scan_bus(struct work_struct *unused)\n{\n\tstruct ap_device *ap_dev;\n\tstruct device *dev;\n\tap_qid_t qid;\n\tint queue_depth, device_type;\n\tunsigned int device_functions;\n\tint rc, i;\n\n\tap_query_configuration();\n\tif (ap_select_domain() != 0) {\n\t\treturn;\n\t}\n\tfor (i = 0; i < AP_DEVICES; i++) {\n\t\tqid = AP_MKQID(i, ap_domain_index);\n\t\tdev = bus_find_device(&ap_bus_type, NULL,\n\t\t\t\t      (void *)(unsigned long)qid,\n\t\t\t\t      __ap_scan_bus);\n\t\tif (ap_test_config_card_id(i))\n\t\t\trc = ap_query_queue(qid, &queue_depth, &device_type);\n\t\telse\n\t\t\trc = -ENODEV;\n\t\tif (dev) {\n\t\t\tif (rc == -EBUSY) {\n\t\t\t\tset_current_state(TASK_UNINTERRUPTIBLE);\n\t\t\t\tschedule_timeout(AP_RESET_TIMEOUT);\n\t\t\t\trc = ap_query_queue(qid, &queue_depth,\n\t\t\t\t\t\t    &device_type);\n\t\t\t}\n\t\t\tap_dev = to_ap_dev(dev);\n\t\t\tspin_lock_bh(&ap_dev->lock);\n\t\t\tif (rc || ap_dev->unregistered) {\n\t\t\t\tspin_unlock_bh(&ap_dev->lock);\n\t\t\t\tif (ap_dev->unregistered)\n\t\t\t\t\ti--;\n\t\t\t\tdevice_unregister(dev);\n\t\t\t\tput_device(dev);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tspin_unlock_bh(&ap_dev->lock);\n\t\t\tput_device(dev);\n\t\t\tcontinue;\n\t\t}\n\t\tif (rc)\n\t\t\tcontinue;\n\t\trc = ap_init_queue(qid);\n\t\tif (rc)\n\t\t\tcontinue;\n\t\tap_dev = kzalloc(sizeof(*ap_dev), GFP_KERNEL);\n\t\tif (!ap_dev)\n\t\t\tbreak;\n\t\tap_dev->qid = qid;\n\t\tap_dev->queue_depth = queue_depth;\n\t\tap_dev->unregistered = 1;\n\t\tspin_lock_init(&ap_dev->lock);\n\t\tINIT_LIST_HEAD(&ap_dev->pendingq);\n\t\tINIT_LIST_HEAD(&ap_dev->requestq);\n\t\tINIT_LIST_HEAD(&ap_dev->list);\n\t\tsetup_timer(&ap_dev->timeout, ap_request_timeout,\n\t\t\t    (unsigned long) ap_dev);\n\t\tswitch (device_type) {\n\t\tcase 0:\n\t\t\t/* device type probing for old cards */\n\t\t\tif (ap_probe_device_type(ap_dev)) {\n\t\t\t\tkfree(ap_dev);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 11:\n\t\t\tap_dev->device_type = 10;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tap_dev->device_type = device_type;\n\t\t}\n\t\tap_dev->raw_hwtype = device_type;\n\n\t\trc = ap_query_functions(qid, &device_functions);\n\t\tif (!rc)\n\t\t\tap_dev->functions = device_functions;\n\t\telse\n\t\t\tap_dev->functions = 0u;\n\n\t\tap_dev->device.bus = &ap_bus_type;\n\t\tap_dev->device.parent = ap_root_device;\n\t\tif (dev_set_name(&ap_dev->device, \"card%02x\",\n\t\t\t\t AP_QID_DEVICE(ap_dev->qid))) {\n\t\t\tkfree(ap_dev);\n\t\t\tcontinue;\n\t\t}\n\t\tap_dev->device.release = ap_device_release;\n\t\trc = device_register(&ap_dev->device);\n\t\tif (rc) {\n\t\t\tput_device(&ap_dev->device);\n\t\t\tcontinue;\n\t\t}\n\t\t/* Add device attributes. */\n\t\trc = sysfs_create_group(&ap_dev->device.kobj,\n\t\t\t\t\t&ap_dev_attr_group);\n\t\tif (!rc) {\n\t\t\tspin_lock_bh(&ap_dev->lock);\n\t\t\tap_dev->unregistered = 0;\n\t\t\tspin_unlock_bh(&ap_dev->lock);\n\t\t}\n\t\telse\n\t\t\tdevice_unregister(&ap_dev->device);\n\t}\n}\n\nstatic void\nap_config_timeout(unsigned long ptr)\n{\n\tqueue_work(ap_work_queue, &ap_config_work);\n\tap_config_timer.expires = jiffies + ap_config_time * HZ;\n\tadd_timer(&ap_config_timer);\n}\n\n/**\n * __ap_schedule_poll_timer(): Schedule poll timer.\n *\n * Set up the timer to run the poll tasklet\n */\nstatic inline void __ap_schedule_poll_timer(void)\n{\n\tktime_t hr_time;\n\n\tspin_lock_bh(&ap_poll_timer_lock);\n\tif (hrtimer_is_queued(&ap_poll_timer) || ap_suspend_flag)\n\t\tgoto out;\n\tif (ktime_to_ns(hrtimer_expires_remaining(&ap_poll_timer)) <= 0) {\n\t\thr_time = ktime_set(0, poll_timeout);\n\t\thrtimer_forward_now(&ap_poll_timer, hr_time);\n\t\thrtimer_restart(&ap_poll_timer);\n\t}\nout:\n\tspin_unlock_bh(&ap_poll_timer_lock);\n}\n\n/**\n * ap_schedule_poll_timer(): Schedule poll timer.\n *\n * Set up the timer to run the poll tasklet\n */\nstatic inline void ap_schedule_poll_timer(void)\n{\n\tif (ap_using_interrupts())\n\t\treturn;\n\t__ap_schedule_poll_timer();\n}\n\n/**\n * ap_poll_read(): Receive pending reply messages from an AP device.\n * @ap_dev: pointer to the AP device\n * @flags: pointer to control flags, bit 2^0 is set if another poll is\n *\t   required, bit 2^1 is set if the poll timer needs to get armed\n *\n * Returns 0 if the device is still present, -ENODEV if not.\n */\nstatic int ap_poll_read(struct ap_device *ap_dev, unsigned long *flags)\n{\n\tstruct ap_queue_status status;\n\tstruct ap_message *ap_msg;\n\n\tif (ap_dev->queue_count <= 0)\n\t\treturn 0;\n\tstatus = __ap_recv(ap_dev->qid, &ap_dev->reply->psmid,\n\t\t\t   ap_dev->reply->message, ap_dev->reply->length);\n\tswitch (status.response_code) {\n\tcase AP_RESPONSE_NORMAL:\n\t\tatomic_dec(&ap_poll_requests);\n\t\tap_decrease_queue_count(ap_dev);\n\t\tlist_for_each_entry(ap_msg, &ap_dev->pendingq, list) {\n\t\t\tif (ap_msg->psmid != ap_dev->reply->psmid)\n\t\t\t\tcontinue;\n\t\t\tlist_del_init(&ap_msg->list);\n\t\t\tap_dev->pendingq_count--;\n\t\t\tap_msg->receive(ap_dev, ap_msg, ap_dev->reply);\n\t\t\tbreak;\n\t\t}\n\t\tif (ap_dev->queue_count > 0)\n\t\t\t*flags |= 1;\n\t\tbreak;\n\tcase AP_RESPONSE_NO_PENDING_REPLY:\n\t\tif (status.queue_empty) {\n\t\t\t/* The card shouldn't forget requests but who knows. */\n\t\t\tatomic_sub(ap_dev->queue_count, &ap_poll_requests);\n\t\t\tap_dev->queue_count = 0;\n\t\t\tlist_splice_init(&ap_dev->pendingq, &ap_dev->requestq);\n\t\t\tap_dev->requestq_count += ap_dev->pendingq_count;\n\t\t\tap_dev->pendingq_count = 0;\n\t\t} else\n\t\t\t*flags |= 2;\n\t\tbreak;\n\tdefault:\n\t\treturn -ENODEV;\n\t}\n\treturn 0;\n}\n\n/**\n * ap_poll_write(): Send messages from the request queue to an AP device.\n * @ap_dev: pointer to the AP device\n * @flags: pointer to control flags, bit 2^0 is set if another poll is\n *\t   required, bit 2^1 is set if the poll timer needs to get armed\n *\n * Returns 0 if the device is still present, -ENODEV if not.\n */\nstatic int ap_poll_write(struct ap_device *ap_dev, unsigned long *flags)\n{\n\tstruct ap_queue_status status;\n\tstruct ap_message *ap_msg;\n\n\tif (ap_dev->requestq_count <= 0 ||\n\t    ap_dev->queue_count >= ap_dev->queue_depth)\n\t\treturn 0;\n\t/* Start the next request on the queue. */\n\tap_msg = list_entry(ap_dev->requestq.next, struct ap_message, list);\n\tstatus = __ap_send(ap_dev->qid, ap_msg->psmid,\n\t\t\t   ap_msg->message, ap_msg->length, ap_msg->special);\n\tswitch (status.response_code) {\n\tcase AP_RESPONSE_NORMAL:\n\t\tatomic_inc(&ap_poll_requests);\n\t\tap_increase_queue_count(ap_dev);\n\t\tlist_move_tail(&ap_msg->list, &ap_dev->pendingq);\n\t\tap_dev->requestq_count--;\n\t\tap_dev->pendingq_count++;\n\t\tif (ap_dev->queue_count < ap_dev->queue_depth &&\n\t\t    ap_dev->requestq_count > 0)\n\t\t\t*flags |= 1;\n\t\t*flags |= 2;\n\t\tbreak;\n\tcase AP_RESPONSE_RESET_IN_PROGRESS:\n\t\t__ap_schedule_poll_timer();\n\tcase AP_RESPONSE_Q_FULL:\n\t\t*flags |= 2;\n\t\tbreak;\n\tcase AP_RESPONSE_MESSAGE_TOO_BIG:\n\tcase AP_RESPONSE_REQ_FAC_NOT_INST:\n\t\treturn -EINVAL;\n\tdefault:\n\t\treturn -ENODEV;\n\t}\n\treturn 0;\n}\n\n/**\n * ap_poll_queue(): Poll AP device for pending replies and send new messages.\n * @ap_dev: pointer to the bus device\n * @flags: pointer to control flags, bit 2^0 is set if another poll is\n *\t   required, bit 2^1 is set if the poll timer needs to get armed\n *\n * Poll AP device for pending replies and send new messages. If either\n * ap_poll_read or ap_poll_write returns -ENODEV unregister the device.\n * Returns 0.\n */\nstatic inline int ap_poll_queue(struct ap_device *ap_dev, unsigned long *flags)\n{\n\tint rc;\n\n\trc = ap_poll_read(ap_dev, flags);\n\tif (rc)\n\t\treturn rc;\n\treturn ap_poll_write(ap_dev, flags);\n}\n\n/**\n * __ap_queue_message(): Queue a message to a device.\n * @ap_dev: pointer to the AP device\n * @ap_msg: the message to be queued\n *\n * Queue a message to a device. Returns 0 if successful.\n */\nstatic int __ap_queue_message(struct ap_device *ap_dev, struct ap_message *ap_msg)\n{\n\tstruct ap_queue_status status;\n\n\tif (list_empty(&ap_dev->requestq) &&\n\t    ap_dev->queue_count < ap_dev->queue_depth) {\n\t\tstatus = __ap_send(ap_dev->qid, ap_msg->psmid,\n\t\t\t\t   ap_msg->message, ap_msg->length,\n\t\t\t\t   ap_msg->special);\n\t\tswitch (status.response_code) {\n\t\tcase AP_RESPONSE_NORMAL:\n\t\t\tlist_add_tail(&ap_msg->list, &ap_dev->pendingq);\n\t\t\tatomic_inc(&ap_poll_requests);\n\t\t\tap_dev->pendingq_count++;\n\t\t\tap_increase_queue_count(ap_dev);\n\t\t\tap_dev->total_request_count++;\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_Q_FULL:\n\t\tcase AP_RESPONSE_RESET_IN_PROGRESS:\n\t\t\tlist_add_tail(&ap_msg->list, &ap_dev->requestq);\n\t\t\tap_dev->requestq_count++;\n\t\t\tap_dev->total_request_count++;\n\t\t\treturn -EBUSY;\n\t\tcase AP_RESPONSE_REQ_FAC_NOT_INST:\n\t\tcase AP_RESPONSE_MESSAGE_TOO_BIG:\n\t\t\tap_msg->receive(ap_dev, ap_msg, ERR_PTR(-EINVAL));\n\t\t\treturn -EINVAL;\n\t\tdefault:\t/* Device is gone. */\n\t\t\tap_msg->receive(ap_dev, ap_msg, ERR_PTR(-ENODEV));\n\t\t\treturn -ENODEV;\n\t\t}\n\t} else {\n\t\tlist_add_tail(&ap_msg->list, &ap_dev->requestq);\n\t\tap_dev->requestq_count++;\n\t\tap_dev->total_request_count++;\n\t\treturn -EBUSY;\n\t}\n\tap_schedule_poll_timer();\n\treturn 0;\n}\n\nvoid ap_queue_message(struct ap_device *ap_dev, struct ap_message *ap_msg)\n{\n\tunsigned long flags;\n\tint rc;\n\n\t/* For asynchronous message handling a valid receive-callback\n\t * is required. */\n\tBUG_ON(!ap_msg->receive);\n\n\tspin_lock_bh(&ap_dev->lock);\n\tif (!ap_dev->unregistered) {\n\t\t/* Make room on the queue by polling for finished requests. */\n\t\trc = ap_poll_queue(ap_dev, &flags);\n\t\tif (!rc)\n\t\t\trc = __ap_queue_message(ap_dev, ap_msg);\n\t\tif (!rc)\n\t\t\twake_up(&ap_poll_wait);\n\t\tif (rc == -ENODEV)\n\t\t\tap_dev->unregistered = 1;\n\t} else {\n\t\tap_msg->receive(ap_dev, ap_msg, ERR_PTR(-ENODEV));\n\t\trc = -ENODEV;\n\t}\n\tspin_unlock_bh(&ap_dev->lock);\n\tif (rc == -ENODEV)\n\t\tdevice_unregister(&ap_dev->device);\n}\nEXPORT_SYMBOL(ap_queue_message);\n\n/**\n * ap_cancel_message(): Cancel a crypto request.\n * @ap_dev: The AP device that has the message queued\n * @ap_msg: The message that is to be removed\n *\n * Cancel a crypto request. This is done by removing the request\n * from the device pending or request queue. Note that the\n * request stays on the AP queue. When it finishes the message\n * reply will be discarded because the psmid can't be found.\n */\nvoid ap_cancel_message(struct ap_device *ap_dev, struct ap_message *ap_msg)\n{\n\tstruct ap_message *tmp;\n\n\tspin_lock_bh(&ap_dev->lock);\n\tif (!list_empty(&ap_msg->list)) {\n\t\tlist_for_each_entry(tmp, &ap_dev->pendingq, list)\n\t\t\tif (tmp->psmid == ap_msg->psmid) {\n\t\t\t\tap_dev->pendingq_count--;\n\t\t\t\tgoto found;\n\t\t\t}\n\t\tap_dev->requestq_count--;\n\tfound:\n\t\tlist_del_init(&ap_msg->list);\n\t}\n\tspin_unlock_bh(&ap_dev->lock);\n}\nEXPORT_SYMBOL(ap_cancel_message);\n\n/**\n * ap_poll_timeout(): AP receive polling for finished AP requests.\n * @unused: Unused pointer.\n *\n * Schedules the AP tasklet using a high resolution timer.\n */\nstatic enum hrtimer_restart ap_poll_timeout(struct hrtimer *unused)\n{\n\ttasklet_schedule(&ap_tasklet);\n\treturn HRTIMER_NORESTART;\n}\n\n/**\n * ap_reset(): Reset a not responding AP device.\n * @ap_dev: Pointer to the AP device\n *\n * Reset a not responding AP device and move all requests from the\n * pending queue to the request queue.\n */\nstatic void ap_reset(struct ap_device *ap_dev)\n{\n\tint rc;\n\n\tap_dev->reset = AP_RESET_IGNORE;\n\tatomic_sub(ap_dev->queue_count, &ap_poll_requests);\n\tap_dev->queue_count = 0;\n\tlist_splice_init(&ap_dev->pendingq, &ap_dev->requestq);\n\tap_dev->requestq_count += ap_dev->pendingq_count;\n\tap_dev->pendingq_count = 0;\n\trc = ap_init_queue(ap_dev->qid);\n\tif (rc == -ENODEV)\n\t\tap_dev->unregistered = 1;\n\telse\n\t\t__ap_schedule_poll_timer();\n}\n\nstatic int __ap_poll_device(struct ap_device *ap_dev, unsigned long *flags)\n{\n\tif (!ap_dev->unregistered) {\n\t\tif (ap_poll_queue(ap_dev, flags))\n\t\t\tap_dev->unregistered = 1;\n\t\tif (ap_dev->reset == AP_RESET_DO)\n\t\t\tap_reset(ap_dev);\n\t}\n\treturn 0;\n}\n\n/**\n * ap_poll_all(): Poll all AP devices.\n * @dummy: Unused variable\n *\n * Poll all AP devices on the bus in a round robin fashion. Continue\n * polling until bit 2^0 of the control flags is not set. If bit 2^1\n * of the control flags has been set arm the poll timer.\n */\nstatic void ap_poll_all(unsigned long dummy)\n{\n\tunsigned long flags;\n\tstruct ap_device *ap_dev;\n\n\t/* Reset the indicator if interrupts are used. Thus new interrupts can\n\t * be received. Doing it in the beginning of the tasklet is therefor\n\t * important that no requests on any AP get lost.\n\t */\n\tif (ap_using_interrupts())\n\t\txchg(ap_airq.lsi_ptr, 0);\n\tdo {\n\t\tflags = 0;\n\t\tspin_lock(&ap_device_list_lock);\n\t\tlist_for_each_entry(ap_dev, &ap_device_list, list) {\n\t\t\tspin_lock(&ap_dev->lock);\n\t\t\t__ap_poll_device(ap_dev, &flags);\n\t\t\tspin_unlock(&ap_dev->lock);\n\t\t}\n\t\tspin_unlock(&ap_device_list_lock);\n\t} while (flags & 1);\n\tif (flags & 2)\n\t\tap_schedule_poll_timer();\n}\n\n/**\n * ap_poll_thread(): Thread that polls for finished requests.\n * @data: Unused pointer\n *\n * AP bus poll thread. The purpose of this thread is to poll for\n * finished requests in a loop if there is a \"free\" cpu - that is\n * a cpu that doesn't have anything better to do. The polling stops\n * as soon as there is another task or if all messages have been\n * delivered.\n */\nstatic int ap_poll_thread(void *data)\n{\n\tDECLARE_WAITQUEUE(wait, current);\n\tunsigned long flags;\n\tint requests;\n\tstruct ap_device *ap_dev;\n\n\tset_user_nice(current, MAX_NICE);\n\twhile (1) {\n\t\tif (ap_suspend_flag)\n\t\t\treturn 0;\n\t\tif (need_resched()) {\n\t\t\tschedule();\n\t\t\tcontinue;\n\t\t}\n\t\tadd_wait_queue(&ap_poll_wait, &wait);\n\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\tif (kthread_should_stop())\n\t\t\tbreak;\n\t\trequests = atomic_read(&ap_poll_requests);\n\t\tif (requests <= 0)\n\t\t\tschedule();\n\t\tset_current_state(TASK_RUNNING);\n\t\tremove_wait_queue(&ap_poll_wait, &wait);\n\n\t\tflags = 0;\n\t\tspin_lock_bh(&ap_device_list_lock);\n\t\tlist_for_each_entry(ap_dev, &ap_device_list, list) {\n\t\t\tspin_lock(&ap_dev->lock);\n\t\t\t__ap_poll_device(ap_dev, &flags);\n\t\t\tspin_unlock(&ap_dev->lock);\n\t\t}\n\t\tspin_unlock_bh(&ap_device_list_lock);\n\t}\n\tset_current_state(TASK_RUNNING);\n\tremove_wait_queue(&ap_poll_wait, &wait);\n\treturn 0;\n}\n\nstatic int ap_poll_thread_start(void)\n{\n\tint rc;\n\n\tif (ap_using_interrupts() || ap_suspend_flag)\n\t\treturn 0;\n\tmutex_lock(&ap_poll_thread_mutex);\n\tif (!ap_poll_kthread) {\n\t\tap_poll_kthread = kthread_run(ap_poll_thread, NULL, \"appoll\");\n\t\trc = PTR_RET(ap_poll_kthread);\n\t\tif (rc)\n\t\t\tap_poll_kthread = NULL;\n\t}\n\telse\n\t\trc = 0;\n\tmutex_unlock(&ap_poll_thread_mutex);\n\treturn rc;\n}\n\nstatic void ap_poll_thread_stop(void)\n{\n\tmutex_lock(&ap_poll_thread_mutex);\n\tif (ap_poll_kthread) {\n\t\tkthread_stop(ap_poll_kthread);\n\t\tap_poll_kthread = NULL;\n\t}\n\tmutex_unlock(&ap_poll_thread_mutex);\n}\n\n/**\n * ap_request_timeout(): Handling of request timeouts\n * @data: Holds the AP device.\n *\n * Handles request timeouts.\n */\nstatic void ap_request_timeout(unsigned long data)\n{\n\tstruct ap_device *ap_dev = (struct ap_device *) data;\n\n\tif (ap_dev->reset == AP_RESET_ARMED) {\n\t\tap_dev->reset = AP_RESET_DO;\n\n\t\tif (ap_using_interrupts())\n\t\t\ttasklet_schedule(&ap_tasklet);\n\t}\n}\n\nstatic void ap_reset_domain(void)\n{\n\tint i;\n\n\tif (ap_domain_index != -1)\n\t\tfor (i = 0; i < AP_DEVICES; i++)\n\t\t\tap_reset_queue(AP_MKQID(i, ap_domain_index));\n}\n\nstatic void ap_reset_all(void)\n{\n\tint i, j;\n\n\tfor (i = 0; i < AP_DOMAINS; i++) {\n\t\tif (!ap_test_config_domain(i))\n\t\t\tcontinue;\n\t\tfor (j = 0; j < AP_DEVICES; j++) {\n\t\t\tif (!ap_test_config_card_id(j))\n\t\t\t\tcontinue;\n\t\t\tap_reset_queue(AP_MKQID(j, i));\n\t\t}\n\t}\n}\n\nstatic struct reset_call ap_reset_call = {\n\t.fn = ap_reset_all,\n};\n\n/**\n * ap_module_init(): The module initialization code.\n *\n * Initializes the module.\n */\nint __init ap_module_init(void)\n{\n\tint rc, i;\n\n\tif (ap_domain_index < -1 || ap_domain_index >= AP_DOMAINS) {\n\t\tpr_warning(\"%d is not a valid cryptographic domain\\n\",\n\t\t\t   ap_domain_index);\n\t\treturn -EINVAL;\n\t}\n\t/* In resume callback we need to know if the user had set the domain.\n\t * If so, we can not just reset it.\n\t */\n\tif (ap_domain_index >= 0)\n\t\tuser_set_domain = 1;\n\n\tif (ap_instructions_available() != 0) {\n\t\tpr_warning(\"The hardware system does not support \"\n\t\t\t   \"AP instructions\\n\");\n\t\treturn -ENODEV;\n\t}\n\tif (ap_interrupts_available()) {\n\t\trc = register_adapter_interrupt(&ap_airq);\n\t\tap_airq_flag = (rc == 0);\n\t}\n\n\tregister_reset_call(&ap_reset_call);\n\n\t/* Create /sys/bus/ap. */\n\trc = bus_register(&ap_bus_type);\n\tif (rc)\n\t\tgoto out;\n\tfor (i = 0; ap_bus_attrs[i]; i++) {\n\t\trc = bus_create_file(&ap_bus_type, ap_bus_attrs[i]);\n\t\tif (rc)\n\t\t\tgoto out_bus;\n\t}\n\n\t/* Create /sys/devices/ap. */\n\tap_root_device = root_device_register(\"ap\");\n\trc = PTR_RET(ap_root_device);\n\tif (rc)\n\t\tgoto out_bus;\n\n\tap_work_queue = create_singlethread_workqueue(\"kapwork\");\n\tif (!ap_work_queue) {\n\t\trc = -ENOMEM;\n\t\tgoto out_root;\n\t}\n\n\tap_query_configuration();\n\tif (ap_select_domain() == 0)\n\t\tap_scan_bus(NULL);\n\n\t/* Setup the AP bus rescan timer. */\n\tinit_timer(&ap_config_timer);\n\tap_config_timer.function = ap_config_timeout;\n\tap_config_timer.data = 0;\n\tap_config_timer.expires = jiffies + ap_config_time * HZ;\n\tadd_timer(&ap_config_timer);\n\n\t/* Setup the high resultion poll timer.\n\t * If we are running under z/VM adjust polling to z/VM polling rate.\n\t */\n\tif (MACHINE_IS_VM)\n\t\tpoll_timeout = 1500000;\n\tspin_lock_init(&ap_poll_timer_lock);\n\thrtimer_init(&ap_poll_timer, CLOCK_MONOTONIC, HRTIMER_MODE_ABS);\n\tap_poll_timer.function = ap_poll_timeout;\n\n\t/* Start the low priority AP bus poll thread. */\n\tif (ap_thread_flag) {\n\t\trc = ap_poll_thread_start();\n\t\tif (rc)\n\t\t\tgoto out_work;\n\t}\n\n\treturn 0;\n\nout_work:\n\tdel_timer_sync(&ap_config_timer);\n\thrtimer_cancel(&ap_poll_timer);\n\tdestroy_workqueue(ap_work_queue);\nout_root:\n\troot_device_unregister(ap_root_device);\nout_bus:\n\twhile (i--)\n\t\tbus_remove_file(&ap_bus_type, ap_bus_attrs[i]);\n\tbus_unregister(&ap_bus_type);\nout:\n\tunregister_reset_call(&ap_reset_call);\n\tif (ap_using_interrupts())\n\t\tunregister_adapter_interrupt(&ap_airq);\n\treturn rc;\n}\n\nstatic int __ap_match_all(struct device *dev, void *data)\n{\n\treturn 1;\n}\n\n/**\n * ap_modules_exit(): The module termination code\n *\n * Terminates the module.\n */\nvoid ap_module_exit(void)\n{\n\tint i;\n\tstruct device *dev;\n\n\tap_reset_domain();\n\tap_poll_thread_stop();\n\tdel_timer_sync(&ap_config_timer);\n\thrtimer_cancel(&ap_poll_timer);\n\tdestroy_workqueue(ap_work_queue);\n\ttasklet_kill(&ap_tasklet);\n\troot_device_unregister(ap_root_device);\n\twhile ((dev = bus_find_device(&ap_bus_type, NULL, NULL,\n\t\t    __ap_match_all)))\n\t{\n\t\tdevice_unregister(dev);\n\t\tput_device(dev);\n\t}\n\tfor (i = 0; ap_bus_attrs[i]; i++)\n\t\tbus_remove_file(&ap_bus_type, ap_bus_attrs[i]);\n\tbus_unregister(&ap_bus_type);\n\tunregister_reset_call(&ap_reset_call);\n\tif (ap_using_interrupts())\n\t\tunregister_adapter_interrupt(&ap_airq);\n}\n\nmodule_init(ap_module_init);\nmodule_exit(ap_module_exit);\n", "/*\n * Scatterlist Cryptographic API.\n *\n * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>\n * Copyright (c) 2002 David S. Miller (davem@redhat.com)\n * Copyright (c) 2005 Herbert Xu <herbert@gondor.apana.org.au>\n *\n * Portions derived from Cryptoapi, by Alexander Kjeldaas <astor@fast.no>\n * and Nettle, by Niels M\u00f6ller.\n * \n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option) \n * any later version.\n *\n */\n#ifndef _LINUX_CRYPTO_H\n#define _LINUX_CRYPTO_H\n\n#include <linux/atomic.h>\n#include <linux/kernel.h>\n#include <linux/list.h>\n#include <linux/bug.h>\n#include <linux/slab.h>\n#include <linux/string.h>\n#include <linux/uaccess.h>\n\n/*\n * Algorithm masks and types.\n */\n#define CRYPTO_ALG_TYPE_MASK\t\t0x0000000f\n#define CRYPTO_ALG_TYPE_CIPHER\t\t0x00000001\n#define CRYPTO_ALG_TYPE_COMPRESS\t0x00000002\n#define CRYPTO_ALG_TYPE_AEAD\t\t0x00000003\n#define CRYPTO_ALG_TYPE_BLKCIPHER\t0x00000004\n#define CRYPTO_ALG_TYPE_ABLKCIPHER\t0x00000005\n#define CRYPTO_ALG_TYPE_GIVCIPHER\t0x00000006\n#define CRYPTO_ALG_TYPE_DIGEST\t\t0x00000008\n#define CRYPTO_ALG_TYPE_HASH\t\t0x00000008\n#define CRYPTO_ALG_TYPE_SHASH\t\t0x00000009\n#define CRYPTO_ALG_TYPE_AHASH\t\t0x0000000a\n#define CRYPTO_ALG_TYPE_RNG\t\t0x0000000c\n#define CRYPTO_ALG_TYPE_PCOMPRESS\t0x0000000f\n\n#define CRYPTO_ALG_TYPE_HASH_MASK\t0x0000000e\n#define CRYPTO_ALG_TYPE_AHASH_MASK\t0x0000000c\n#define CRYPTO_ALG_TYPE_BLKCIPHER_MASK\t0x0000000c\n\n#define CRYPTO_ALG_LARVAL\t\t0x00000010\n#define CRYPTO_ALG_DEAD\t\t\t0x00000020\n#define CRYPTO_ALG_DYING\t\t0x00000040\n#define CRYPTO_ALG_ASYNC\t\t0x00000080\n\n/*\n * Set this bit if and only if the algorithm requires another algorithm of\n * the same type to handle corner cases.\n */\n#define CRYPTO_ALG_NEED_FALLBACK\t0x00000100\n\n/*\n * This bit is set for symmetric key ciphers that have already been wrapped\n * with a generic IV generator to prevent them from being wrapped again.\n */\n#define CRYPTO_ALG_GENIV\t\t0x00000200\n\n/*\n * Set if the algorithm has passed automated run-time testing.  Note that\n * if there is no run-time testing for a given algorithm it is considered\n * to have passed.\n */\n\n#define CRYPTO_ALG_TESTED\t\t0x00000400\n\n/*\n * Set if the algorithm is an instance that is build from templates.\n */\n#define CRYPTO_ALG_INSTANCE\t\t0x00000800\n\n/* Set this bit if the algorithm provided is hardware accelerated but\n * not available to userspace via instruction set or so.\n */\n#define CRYPTO_ALG_KERN_DRIVER_ONLY\t0x00001000\n\n/*\n * Transform masks and values (for crt_flags).\n */\n#define CRYPTO_TFM_REQ_MASK\t\t0x000fff00\n#define CRYPTO_TFM_RES_MASK\t\t0xfff00000\n\n#define CRYPTO_TFM_REQ_WEAK_KEY\t\t0x00000100\n#define CRYPTO_TFM_REQ_MAY_SLEEP\t0x00000200\n#define CRYPTO_TFM_REQ_MAY_BACKLOG\t0x00000400\n#define CRYPTO_TFM_RES_WEAK_KEY\t\t0x00100000\n#define CRYPTO_TFM_RES_BAD_KEY_LEN   \t0x00200000\n#define CRYPTO_TFM_RES_BAD_KEY_SCHED \t0x00400000\n#define CRYPTO_TFM_RES_BAD_BLOCK_LEN \t0x00800000\n#define CRYPTO_TFM_RES_BAD_FLAGS \t0x01000000\n\n/*\n * Miscellaneous stuff.\n */\n#define CRYPTO_MAX_ALG_NAME\t\t64\n\n/*\n * The macro CRYPTO_MINALIGN_ATTR (along with the void * type in the actual\n * declaration) is used to ensure that the crypto_tfm context structure is\n * aligned correctly for the given architecture so that there are no alignment\n * faults for C data types.  In particular, this is required on platforms such\n * as arm where pointers are 32-bit aligned but there are data types such as\n * u64 which require 64-bit alignment.\n */\n#define CRYPTO_MINALIGN ARCH_KMALLOC_MINALIGN\n\n#define CRYPTO_MINALIGN_ATTR __attribute__ ((__aligned__(CRYPTO_MINALIGN)))\n\nstruct scatterlist;\nstruct crypto_ablkcipher;\nstruct crypto_async_request;\nstruct crypto_aead;\nstruct crypto_blkcipher;\nstruct crypto_hash;\nstruct crypto_rng;\nstruct crypto_tfm;\nstruct crypto_type;\nstruct aead_givcrypt_request;\nstruct skcipher_givcrypt_request;\n\ntypedef void (*crypto_completion_t)(struct crypto_async_request *req, int err);\n\n/**\n * DOC: Block Cipher Context Data Structures\n *\n * These data structures define the operating context for each block cipher\n * type.\n */\n\nstruct crypto_async_request {\n\tstruct list_head list;\n\tcrypto_completion_t complete;\n\tvoid *data;\n\tstruct crypto_tfm *tfm;\n\n\tu32 flags;\n};\n\nstruct ablkcipher_request {\n\tstruct crypto_async_request base;\n\n\tunsigned int nbytes;\n\n\tvoid *info;\n\n\tstruct scatterlist *src;\n\tstruct scatterlist *dst;\n\n\tvoid *__ctx[] CRYPTO_MINALIGN_ATTR;\n};\n\n/**\n *\tstruct aead_request - AEAD request\n *\t@base: Common attributes for async crypto requests\n *\t@assoclen: Length in bytes of associated data for authentication\n *\t@cryptlen: Length of data to be encrypted or decrypted\n *\t@iv: Initialisation vector\n *\t@assoc: Associated data\n *\t@src: Source data\n *\t@dst: Destination data\n *\t@__ctx: Start of private context data\n */\nstruct aead_request {\n\tstruct crypto_async_request base;\n\n\tunsigned int assoclen;\n\tunsigned int cryptlen;\n\n\tu8 *iv;\n\n\tstruct scatterlist *assoc;\n\tstruct scatterlist *src;\n\tstruct scatterlist *dst;\n\n\tvoid *__ctx[] CRYPTO_MINALIGN_ATTR;\n};\n\nstruct blkcipher_desc {\n\tstruct crypto_blkcipher *tfm;\n\tvoid *info;\n\tu32 flags;\n};\n\nstruct cipher_desc {\n\tstruct crypto_tfm *tfm;\n\tvoid (*crfn)(struct crypto_tfm *tfm, u8 *dst, const u8 *src);\n\tunsigned int (*prfn)(const struct cipher_desc *desc, u8 *dst,\n\t\t\t     const u8 *src, unsigned int nbytes);\n\tvoid *info;\n};\n\nstruct hash_desc {\n\tstruct crypto_hash *tfm;\n\tu32 flags;\n};\n\n/**\n * DOC: Block Cipher Algorithm Definitions\n *\n * These data structures define modular crypto algorithm implementations,\n * managed via crypto_register_alg() and crypto_unregister_alg().\n */\n\n/**\n * struct ablkcipher_alg - asynchronous block cipher definition\n * @min_keysize: Minimum key size supported by the transformation. This is the\n *\t\t smallest key length supported by this transformation algorithm.\n *\t\t This must be set to one of the pre-defined values as this is\n *\t\t not hardware specific. Possible values for this field can be\n *\t\t found via git grep \"_MIN_KEY_SIZE\" include/crypto/\n * @max_keysize: Maximum key size supported by the transformation. This is the\n *\t\t largest key length supported by this transformation algorithm.\n *\t\t This must be set to one of the pre-defined values as this is\n *\t\t not hardware specific. Possible values for this field can be\n *\t\t found via git grep \"_MAX_KEY_SIZE\" include/crypto/\n * @setkey: Set key for the transformation. This function is used to either\n *\t    program a supplied key into the hardware or store the key in the\n *\t    transformation context for programming it later. Note that this\n *\t    function does modify the transformation context. This function can\n *\t    be called multiple times during the existence of the transformation\n *\t    object, so one must make sure the key is properly reprogrammed into\n *\t    the hardware. This function is also responsible for checking the key\n *\t    length for validity. In case a software fallback was put in place in\n *\t    the @cra_init call, this function might need to use the fallback if\n *\t    the algorithm doesn't support all of the key sizes.\n * @encrypt: Encrypt a scatterlist of blocks. This function is used to encrypt\n *\t     the supplied scatterlist containing the blocks of data. The crypto\n *\t     API consumer is responsible for aligning the entries of the\n *\t     scatterlist properly and making sure the chunks are correctly\n *\t     sized. In case a software fallback was put in place in the\n *\t     @cra_init call, this function might need to use the fallback if\n *\t     the algorithm doesn't support all of the key sizes. In case the\n *\t     key was stored in transformation context, the key might need to be\n *\t     re-programmed into the hardware in this function. This function\n *\t     shall not modify the transformation context, as this function may\n *\t     be called in parallel with the same transformation object.\n * @decrypt: Decrypt a single block. This is a reverse counterpart to @encrypt\n *\t     and the conditions are exactly the same.\n * @givencrypt: Update the IV for encryption. With this function, a cipher\n *\t        implementation may provide the function on how to update the IV\n *\t        for encryption.\n * @givdecrypt: Update the IV for decryption. This is the reverse of\n *\t        @givencrypt .\n * @geniv: The transformation implementation may use an \"IV generator\" provided\n *\t   by the kernel crypto API. Several use cases have a predefined\n *\t   approach how IVs are to be updated. For such use cases, the kernel\n *\t   crypto API provides ready-to-use implementations that can be\n *\t   referenced with this variable.\n * @ivsize: IV size applicable for transformation. The consumer must provide an\n *\t    IV of exactly that size to perform the encrypt or decrypt operation.\n *\n * All fields except @givencrypt , @givdecrypt , @geniv and @ivsize are\n * mandatory and must be filled.\n */\nstruct ablkcipher_alg {\n\tint (*setkey)(struct crypto_ablkcipher *tfm, const u8 *key,\n\t              unsigned int keylen);\n\tint (*encrypt)(struct ablkcipher_request *req);\n\tint (*decrypt)(struct ablkcipher_request *req);\n\tint (*givencrypt)(struct skcipher_givcrypt_request *req);\n\tint (*givdecrypt)(struct skcipher_givcrypt_request *req);\n\n\tconst char *geniv;\n\n\tunsigned int min_keysize;\n\tunsigned int max_keysize;\n\tunsigned int ivsize;\n};\n\n/**\n * struct aead_alg - AEAD cipher definition\n * @maxauthsize: Set the maximum authentication tag size supported by the\n *\t\t transformation. A transformation may support smaller tag sizes.\n *\t\t As the authentication tag is a message digest to ensure the\n *\t\t integrity of the encrypted data, a consumer typically wants the\n *\t\t largest authentication tag possible as defined by this\n *\t\t variable.\n * @setauthsize: Set authentication size for the AEAD transformation. This\n *\t\t function is used to specify the consumer requested size of the\n * \t\t authentication tag to be either generated by the transformation\n *\t\t during encryption or the size of the authentication tag to be\n *\t\t supplied during the decryption operation. This function is also\n *\t\t responsible for checking the authentication tag size for\n *\t\t validity.\n * @setkey: see struct ablkcipher_alg\n * @encrypt: see struct ablkcipher_alg\n * @decrypt: see struct ablkcipher_alg\n * @givencrypt: see struct ablkcipher_alg\n * @givdecrypt: see struct ablkcipher_alg\n * @geniv: see struct ablkcipher_alg\n * @ivsize: see struct ablkcipher_alg\n *\n * All fields except @givencrypt , @givdecrypt , @geniv and @ivsize are\n * mandatory and must be filled.\n */\nstruct aead_alg {\n\tint (*setkey)(struct crypto_aead *tfm, const u8 *key,\n\t              unsigned int keylen);\n\tint (*setauthsize)(struct crypto_aead *tfm, unsigned int authsize);\n\tint (*encrypt)(struct aead_request *req);\n\tint (*decrypt)(struct aead_request *req);\n\tint (*givencrypt)(struct aead_givcrypt_request *req);\n\tint (*givdecrypt)(struct aead_givcrypt_request *req);\n\n\tconst char *geniv;\n\n\tunsigned int ivsize;\n\tunsigned int maxauthsize;\n};\n\n/**\n * struct blkcipher_alg - synchronous block cipher definition\n * @min_keysize: see struct ablkcipher_alg\n * @max_keysize: see struct ablkcipher_alg\n * @setkey: see struct ablkcipher_alg\n * @encrypt: see struct ablkcipher_alg\n * @decrypt: see struct ablkcipher_alg\n * @geniv: see struct ablkcipher_alg\n * @ivsize: see struct ablkcipher_alg\n *\n * All fields except @geniv and @ivsize are mandatory and must be filled.\n */\nstruct blkcipher_alg {\n\tint (*setkey)(struct crypto_tfm *tfm, const u8 *key,\n\t              unsigned int keylen);\n\tint (*encrypt)(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes);\n\tint (*decrypt)(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes);\n\n\tconst char *geniv;\n\n\tunsigned int min_keysize;\n\tunsigned int max_keysize;\n\tunsigned int ivsize;\n};\n\n/**\n * struct cipher_alg - single-block symmetric ciphers definition\n * @cia_min_keysize: Minimum key size supported by the transformation. This is\n *\t\t     the smallest key length supported by this transformation\n *\t\t     algorithm. This must be set to one of the pre-defined\n *\t\t     values as this is not hardware specific. Possible values\n *\t\t     for this field can be found via git grep \"_MIN_KEY_SIZE\"\n *\t\t     include/crypto/\n * @cia_max_keysize: Maximum key size supported by the transformation. This is\n *\t\t    the largest key length supported by this transformation\n *\t\t    algorithm. This must be set to one of the pre-defined values\n *\t\t    as this is not hardware specific. Possible values for this\n *\t\t    field can be found via git grep \"_MAX_KEY_SIZE\"\n *\t\t    include/crypto/\n * @cia_setkey: Set key for the transformation. This function is used to either\n *\t        program a supplied key into the hardware or store the key in the\n *\t        transformation context for programming it later. Note that this\n *\t        function does modify the transformation context. This function\n *\t        can be called multiple times during the existence of the\n *\t        transformation object, so one must make sure the key is properly\n *\t        reprogrammed into the hardware. This function is also\n *\t        responsible for checking the key length for validity.\n * @cia_encrypt: Encrypt a single block. This function is used to encrypt a\n *\t\t single block of data, which must be @cra_blocksize big. This\n *\t\t always operates on a full @cra_blocksize and it is not possible\n *\t\t to encrypt a block of smaller size. The supplied buffers must\n *\t\t therefore also be at least of @cra_blocksize size. Both the\n *\t\t input and output buffers are always aligned to @cra_alignmask.\n *\t\t In case either of the input or output buffer supplied by user\n *\t\t of the crypto API is not aligned to @cra_alignmask, the crypto\n *\t\t API will re-align the buffers. The re-alignment means that a\n *\t\t new buffer will be allocated, the data will be copied into the\n *\t\t new buffer, then the processing will happen on the new buffer,\n *\t\t then the data will be copied back into the original buffer and\n *\t\t finally the new buffer will be freed. In case a software\n *\t\t fallback was put in place in the @cra_init call, this function\n *\t\t might need to use the fallback if the algorithm doesn't support\n *\t\t all of the key sizes. In case the key was stored in\n *\t\t transformation context, the key might need to be re-programmed\n *\t\t into the hardware in this function. This function shall not\n *\t\t modify the transformation context, as this function may be\n *\t\t called in parallel with the same transformation object.\n * @cia_decrypt: Decrypt a single block. This is a reverse counterpart to\n *\t\t @cia_encrypt, and the conditions are exactly the same.\n *\n * All fields are mandatory and must be filled.\n */\nstruct cipher_alg {\n\tunsigned int cia_min_keysize;\n\tunsigned int cia_max_keysize;\n\tint (*cia_setkey)(struct crypto_tfm *tfm, const u8 *key,\n\t                  unsigned int keylen);\n\tvoid (*cia_encrypt)(struct crypto_tfm *tfm, u8 *dst, const u8 *src);\n\tvoid (*cia_decrypt)(struct crypto_tfm *tfm, u8 *dst, const u8 *src);\n};\n\nstruct compress_alg {\n\tint (*coa_compress)(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t    unsigned int slen, u8 *dst, unsigned int *dlen);\n\tint (*coa_decompress)(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t      unsigned int slen, u8 *dst, unsigned int *dlen);\n};\n\n/**\n * struct rng_alg - random number generator definition\n * @rng_make_random: The function defined by this variable obtains a random\n *\t\t     number. The random number generator transform must generate\n *\t\t     the random number out of the context provided with this\n *\t\t     call.\n * @rng_reset: Reset of the random number generator by clearing the entire state.\n *\t       With the invocation of this function call, the random number\n *             generator shall completely reinitialize its state. If the random\n *\t       number generator requires a seed for setting up a new state,\n *\t       the seed must be provided by the consumer while invoking this\n *\t       function. The required size of the seed is defined with\n *\t       @seedsize .\n * @seedsize: The seed size required for a random number generator\n *\t      initialization defined with this variable. Some random number\n *\t      generators like the SP800-90A DRBG does not require a seed as the\n *\t      seeding is implemented internally without the need of support by\n *\t      the consumer. In this case, the seed size is set to zero.\n */\nstruct rng_alg {\n\tint (*rng_make_random)(struct crypto_rng *tfm, u8 *rdata,\n\t\t\t       unsigned int dlen);\n\tint (*rng_reset)(struct crypto_rng *tfm, u8 *seed, unsigned int slen);\n\n\tunsigned int seedsize;\n};\n\n\n#define cra_ablkcipher\tcra_u.ablkcipher\n#define cra_aead\tcra_u.aead\n#define cra_blkcipher\tcra_u.blkcipher\n#define cra_cipher\tcra_u.cipher\n#define cra_compress\tcra_u.compress\n#define cra_rng\t\tcra_u.rng\n\n/**\n * struct crypto_alg - definition of a cryptograpic cipher algorithm\n * @cra_flags: Flags describing this transformation. See include/linux/crypto.h\n *\t       CRYPTO_ALG_* flags for the flags which go in here. Those are\n *\t       used for fine-tuning the description of the transformation\n *\t       algorithm.\n * @cra_blocksize: Minimum block size of this transformation. The size in bytes\n *\t\t   of the smallest possible unit which can be transformed with\n *\t\t   this algorithm. The users must respect this value.\n *\t\t   In case of HASH transformation, it is possible for a smaller\n *\t\t   block than @cra_blocksize to be passed to the crypto API for\n *\t\t   transformation, in case of any other transformation type, an\n * \t\t   error will be returned upon any attempt to transform smaller\n *\t\t   than @cra_blocksize chunks.\n * @cra_ctxsize: Size of the operational context of the transformation. This\n *\t\t value informs the kernel crypto API about the memory size\n *\t\t needed to be allocated for the transformation context.\n * @cra_alignmask: Alignment mask for the input and output data buffer. The data\n *\t\t   buffer containing the input data for the algorithm must be\n *\t\t   aligned to this alignment mask. The data buffer for the\n *\t\t   output data must be aligned to this alignment mask. Note that\n *\t\t   the Crypto API will do the re-alignment in software, but\n *\t\t   only under special conditions and there is a performance hit.\n *\t\t   The re-alignment happens at these occasions for different\n *\t\t   @cra_u types: cipher -- For both input data and output data\n *\t\t   buffer; ahash -- For output hash destination buf; shash --\n *\t\t   For output hash destination buf.\n *\t\t   This is needed on hardware which is flawed by design and\n *\t\t   cannot pick data from arbitrary addresses.\n * @cra_priority: Priority of this transformation implementation. In case\n *\t\t  multiple transformations with same @cra_name are available to\n *\t\t  the Crypto API, the kernel will use the one with highest\n *\t\t  @cra_priority.\n * @cra_name: Generic name (usable by multiple implementations) of the\n *\t      transformation algorithm. This is the name of the transformation\n *\t      itself. This field is used by the kernel when looking up the\n *\t      providers of particular transformation.\n * @cra_driver_name: Unique name of the transformation provider. This is the\n *\t\t     name of the provider of the transformation. This can be any\n *\t\t     arbitrary value, but in the usual case, this contains the\n *\t\t     name of the chip or provider and the name of the\n *\t\t     transformation algorithm.\n * @cra_type: Type of the cryptographic transformation. This is a pointer to\n *\t      struct crypto_type, which implements callbacks common for all\n *\t      trasnformation types. There are multiple options:\n *\t      &crypto_blkcipher_type, &crypto_ablkcipher_type,\n *\t      &crypto_ahash_type, &crypto_aead_type, &crypto_rng_type.\n *\t      This field might be empty. In that case, there are no common\n *\t      callbacks. This is the case for: cipher, compress, shash.\n * @cra_u: Callbacks implementing the transformation. This is a union of\n *\t   multiple structures. Depending on the type of transformation selected\n *\t   by @cra_type and @cra_flags above, the associated structure must be\n *\t   filled with callbacks. This field might be empty. This is the case\n *\t   for ahash, shash.\n * @cra_init: Initialize the cryptographic transformation object. This function\n *\t      is used to initialize the cryptographic transformation object.\n *\t      This function is called only once at the instantiation time, right\n *\t      after the transformation context was allocated. In case the\n *\t      cryptographic hardware has some special requirements which need to\n *\t      be handled by software, this function shall check for the precise\n *\t      requirement of the transformation and put any software fallbacks\n *\t      in place.\n * @cra_exit: Deinitialize the cryptographic transformation object. This is a\n *\t      counterpart to @cra_init, used to remove various changes set in\n *\t      @cra_init.\n * @cra_module: Owner of this transformation implementation. Set to THIS_MODULE\n * @cra_list: internally used\n * @cra_users: internally used\n * @cra_refcnt: internally used\n * @cra_destroy: internally used\n *\n * The struct crypto_alg describes a generic Crypto API algorithm and is common\n * for all of the transformations. Any variable not documented here shall not\n * be used by a cipher implementation as it is internal to the Crypto API.\n */\nstruct crypto_alg {\n\tstruct list_head cra_list;\n\tstruct list_head cra_users;\n\n\tu32 cra_flags;\n\tunsigned int cra_blocksize;\n\tunsigned int cra_ctxsize;\n\tunsigned int cra_alignmask;\n\n\tint cra_priority;\n\tatomic_t cra_refcnt;\n\n\tchar cra_name[CRYPTO_MAX_ALG_NAME];\n\tchar cra_driver_name[CRYPTO_MAX_ALG_NAME];\n\n\tconst struct crypto_type *cra_type;\n\n\tunion {\n\t\tstruct ablkcipher_alg ablkcipher;\n\t\tstruct aead_alg aead;\n\t\tstruct blkcipher_alg blkcipher;\n\t\tstruct cipher_alg cipher;\n\t\tstruct compress_alg compress;\n\t\tstruct rng_alg rng;\n\t} cra_u;\n\n\tint (*cra_init)(struct crypto_tfm *tfm);\n\tvoid (*cra_exit)(struct crypto_tfm *tfm);\n\tvoid (*cra_destroy)(struct crypto_alg *alg);\n\t\n\tstruct module *cra_module;\n};\n\n/*\n * Algorithm registration interface.\n */\nint crypto_register_alg(struct crypto_alg *alg);\nint crypto_unregister_alg(struct crypto_alg *alg);\nint crypto_register_algs(struct crypto_alg *algs, int count);\nint crypto_unregister_algs(struct crypto_alg *algs, int count);\n\n/*\n * Algorithm query interface.\n */\nint crypto_has_alg(const char *name, u32 type, u32 mask);\n\n/*\n * Transforms: user-instantiated objects which encapsulate algorithms\n * and core processing logic.  Managed via crypto_alloc_*() and\n * crypto_free_*(), as well as the various helpers below.\n */\n\nstruct ablkcipher_tfm {\n\tint (*setkey)(struct crypto_ablkcipher *tfm, const u8 *key,\n\t              unsigned int keylen);\n\tint (*encrypt)(struct ablkcipher_request *req);\n\tint (*decrypt)(struct ablkcipher_request *req);\n\tint (*givencrypt)(struct skcipher_givcrypt_request *req);\n\tint (*givdecrypt)(struct skcipher_givcrypt_request *req);\n\n\tstruct crypto_ablkcipher *base;\n\n\tunsigned int ivsize;\n\tunsigned int reqsize;\n};\n\nstruct aead_tfm {\n\tint (*setkey)(struct crypto_aead *tfm, const u8 *key,\n\t              unsigned int keylen);\n\tint (*encrypt)(struct aead_request *req);\n\tint (*decrypt)(struct aead_request *req);\n\tint (*givencrypt)(struct aead_givcrypt_request *req);\n\tint (*givdecrypt)(struct aead_givcrypt_request *req);\n\n\tstruct crypto_aead *base;\n\n\tunsigned int ivsize;\n\tunsigned int authsize;\n\tunsigned int reqsize;\n};\n\nstruct blkcipher_tfm {\n\tvoid *iv;\n\tint (*setkey)(struct crypto_tfm *tfm, const u8 *key,\n\t\t      unsigned int keylen);\n\tint (*encrypt)(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes);\n\tint (*decrypt)(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes);\n};\n\nstruct cipher_tfm {\n\tint (*cit_setkey)(struct crypto_tfm *tfm,\n\t                  const u8 *key, unsigned int keylen);\n\tvoid (*cit_encrypt_one)(struct crypto_tfm *tfm, u8 *dst, const u8 *src);\n\tvoid (*cit_decrypt_one)(struct crypto_tfm *tfm, u8 *dst, const u8 *src);\n};\n\nstruct hash_tfm {\n\tint (*init)(struct hash_desc *desc);\n\tint (*update)(struct hash_desc *desc,\n\t\t      struct scatterlist *sg, unsigned int nsg);\n\tint (*final)(struct hash_desc *desc, u8 *out);\n\tint (*digest)(struct hash_desc *desc, struct scatterlist *sg,\n\t\t      unsigned int nsg, u8 *out);\n\tint (*setkey)(struct crypto_hash *tfm, const u8 *key,\n\t\t      unsigned int keylen);\n\tunsigned int digestsize;\n};\n\nstruct compress_tfm {\n\tint (*cot_compress)(struct crypto_tfm *tfm,\n\t                    const u8 *src, unsigned int slen,\n\t                    u8 *dst, unsigned int *dlen);\n\tint (*cot_decompress)(struct crypto_tfm *tfm,\n\t                      const u8 *src, unsigned int slen,\n\t                      u8 *dst, unsigned int *dlen);\n};\n\nstruct rng_tfm {\n\tint (*rng_gen_random)(struct crypto_rng *tfm, u8 *rdata,\n\t\t\t      unsigned int dlen);\n\tint (*rng_reset)(struct crypto_rng *tfm, u8 *seed, unsigned int slen);\n};\n\n#define crt_ablkcipher\tcrt_u.ablkcipher\n#define crt_aead\tcrt_u.aead\n#define crt_blkcipher\tcrt_u.blkcipher\n#define crt_cipher\tcrt_u.cipher\n#define crt_hash\tcrt_u.hash\n#define crt_compress\tcrt_u.compress\n#define crt_rng\t\tcrt_u.rng\n\nstruct crypto_tfm {\n\n\tu32 crt_flags;\n\t\n\tunion {\n\t\tstruct ablkcipher_tfm ablkcipher;\n\t\tstruct aead_tfm aead;\n\t\tstruct blkcipher_tfm blkcipher;\n\t\tstruct cipher_tfm cipher;\n\t\tstruct hash_tfm hash;\n\t\tstruct compress_tfm compress;\n\t\tstruct rng_tfm rng;\n\t} crt_u;\n\n\tvoid (*exit)(struct crypto_tfm *tfm);\n\t\n\tstruct crypto_alg *__crt_alg;\n\n\tvoid *__crt_ctx[] CRYPTO_MINALIGN_ATTR;\n};\n\nstruct crypto_ablkcipher {\n\tstruct crypto_tfm base;\n};\n\nstruct crypto_aead {\n\tstruct crypto_tfm base;\n};\n\nstruct crypto_blkcipher {\n\tstruct crypto_tfm base;\n};\n\nstruct crypto_cipher {\n\tstruct crypto_tfm base;\n};\n\nstruct crypto_comp {\n\tstruct crypto_tfm base;\n};\n\nstruct crypto_hash {\n\tstruct crypto_tfm base;\n};\n\nstruct crypto_rng {\n\tstruct crypto_tfm base;\n};\n\nenum {\n\tCRYPTOA_UNSPEC,\n\tCRYPTOA_ALG,\n\tCRYPTOA_TYPE,\n\tCRYPTOA_U32,\n\t__CRYPTOA_MAX,\n};\n\n#define CRYPTOA_MAX (__CRYPTOA_MAX - 1)\n\n/* Maximum number of (rtattr) parameters for each template. */\n#define CRYPTO_MAX_ATTRS 32\n\nstruct crypto_attr_alg {\n\tchar name[CRYPTO_MAX_ALG_NAME];\n};\n\nstruct crypto_attr_type {\n\tu32 type;\n\tu32 mask;\n};\n\nstruct crypto_attr_u32 {\n\tu32 num;\n};\n\n/* \n * Transform user interface.\n */\n \nstruct crypto_tfm *crypto_alloc_base(const char *alg_name, u32 type, u32 mask);\nvoid crypto_destroy_tfm(void *mem, struct crypto_tfm *tfm);\n\nstatic inline void crypto_free_tfm(struct crypto_tfm *tfm)\n{\n\treturn crypto_destroy_tfm(tfm, tfm);\n}\n\nint alg_test(const char *driver, const char *alg, u32 type, u32 mask);\n\n/*\n * Transform helpers which query the underlying algorithm.\n */\nstatic inline const char *crypto_tfm_alg_name(struct crypto_tfm *tfm)\n{\n\treturn tfm->__crt_alg->cra_name;\n}\n\nstatic inline const char *crypto_tfm_alg_driver_name(struct crypto_tfm *tfm)\n{\n\treturn tfm->__crt_alg->cra_driver_name;\n}\n\nstatic inline int crypto_tfm_alg_priority(struct crypto_tfm *tfm)\n{\n\treturn tfm->__crt_alg->cra_priority;\n}\n\nstatic inline u32 crypto_tfm_alg_type(struct crypto_tfm *tfm)\n{\n\treturn tfm->__crt_alg->cra_flags & CRYPTO_ALG_TYPE_MASK;\n}\n\nstatic inline unsigned int crypto_tfm_alg_blocksize(struct crypto_tfm *tfm)\n{\n\treturn tfm->__crt_alg->cra_blocksize;\n}\n\nstatic inline unsigned int crypto_tfm_alg_alignmask(struct crypto_tfm *tfm)\n{\n\treturn tfm->__crt_alg->cra_alignmask;\n}\n\nstatic inline u32 crypto_tfm_get_flags(struct crypto_tfm *tfm)\n{\n\treturn tfm->crt_flags;\n}\n\nstatic inline void crypto_tfm_set_flags(struct crypto_tfm *tfm, u32 flags)\n{\n\ttfm->crt_flags |= flags;\n}\n\nstatic inline void crypto_tfm_clear_flags(struct crypto_tfm *tfm, u32 flags)\n{\n\ttfm->crt_flags &= ~flags;\n}\n\nstatic inline void *crypto_tfm_ctx(struct crypto_tfm *tfm)\n{\n\treturn tfm->__crt_ctx;\n}\n\nstatic inline unsigned int crypto_tfm_ctx_alignment(void)\n{\n\tstruct crypto_tfm *tfm;\n\treturn __alignof__(tfm->__crt_ctx);\n}\n\n/*\n * API wrappers.\n */\nstatic inline struct crypto_ablkcipher *__crypto_ablkcipher_cast(\n\tstruct crypto_tfm *tfm)\n{\n\treturn (struct crypto_ablkcipher *)tfm;\n}\n\nstatic inline u32 crypto_skcipher_type(u32 type)\n{\n\ttype &= ~(CRYPTO_ALG_TYPE_MASK | CRYPTO_ALG_GENIV);\n\ttype |= CRYPTO_ALG_TYPE_BLKCIPHER;\n\treturn type;\n}\n\nstatic inline u32 crypto_skcipher_mask(u32 mask)\n{\n\tmask &= ~(CRYPTO_ALG_TYPE_MASK | CRYPTO_ALG_GENIV);\n\tmask |= CRYPTO_ALG_TYPE_BLKCIPHER_MASK;\n\treturn mask;\n}\n\n/**\n * DOC: Asynchronous Block Cipher API\n *\n * Asynchronous block cipher API is used with the ciphers of type\n * CRYPTO_ALG_TYPE_ABLKCIPHER (listed as type \"ablkcipher\" in /proc/crypto).\n *\n * Asynchronous cipher operations imply that the function invocation for a\n * cipher request returns immediately before the completion of the operation.\n * The cipher request is scheduled as a separate kernel thread and therefore\n * load-balanced on the different CPUs via the process scheduler. To allow\n * the kernel crypto API to inform the caller about the completion of a cipher\n * request, the caller must provide a callback function. That function is\n * invoked with the cipher handle when the request completes.\n *\n * To support the asynchronous operation, additional information than just the\n * cipher handle must be supplied to the kernel crypto API. That additional\n * information is given by filling in the ablkcipher_request data structure.\n *\n * For the asynchronous block cipher API, the state is maintained with the tfm\n * cipher handle. A single tfm can be used across multiple calls and in\n * parallel. For asynchronous block cipher calls, context data supplied and\n * only used by the caller can be referenced the request data structure in\n * addition to the IV used for the cipher request. The maintenance of such\n * state information would be important for a crypto driver implementer to\n * have, because when calling the callback function upon completion of the\n * cipher operation, that callback function may need some information about\n * which operation just finished if it invoked multiple in parallel. This\n * state information is unused by the kernel crypto API.\n */\n\n/**\n * crypto_alloc_ablkcipher() - allocate asynchronous block cipher handle\n * @alg_name: is the cra_name / name or cra_driver_name / driver name of the\n *\t      ablkcipher cipher\n * @type: specifies the type of the cipher\n * @mask: specifies the mask for the cipher\n *\n * Allocate a cipher handle for an ablkcipher. The returned struct\n * crypto_ablkcipher is the cipher handle that is required for any subsequent\n * API invocation for that ablkcipher.\n *\n * Return: allocated cipher handle in case of success; IS_ERR() is true in case\n *\t   of an error, PTR_ERR() returns the error code.\n */\nstruct crypto_ablkcipher *crypto_alloc_ablkcipher(const char *alg_name,\n\t\t\t\t\t\t  u32 type, u32 mask);\n\nstatic inline struct crypto_tfm *crypto_ablkcipher_tfm(\n\tstruct crypto_ablkcipher *tfm)\n{\n\treturn &tfm->base;\n}\n\n/**\n * crypto_free_ablkcipher() - zeroize and free cipher handle\n * @tfm: cipher handle to be freed\n */\nstatic inline void crypto_free_ablkcipher(struct crypto_ablkcipher *tfm)\n{\n\tcrypto_free_tfm(crypto_ablkcipher_tfm(tfm));\n}\n\n/**\n * crypto_has_ablkcipher() - Search for the availability of an ablkcipher.\n * @alg_name: is the cra_name / name or cra_driver_name / driver name of the\n *\t      ablkcipher\n * @type: specifies the type of the cipher\n * @mask: specifies the mask for the cipher\n *\n * Return: true when the ablkcipher is known to the kernel crypto API; false\n *\t   otherwise\n */\nstatic inline int crypto_has_ablkcipher(const char *alg_name, u32 type,\n\t\t\t\t\tu32 mask)\n{\n\treturn crypto_has_alg(alg_name, crypto_skcipher_type(type),\n\t\t\t      crypto_skcipher_mask(mask));\n}\n\nstatic inline struct ablkcipher_tfm *crypto_ablkcipher_crt(\n\tstruct crypto_ablkcipher *tfm)\n{\n\treturn &crypto_ablkcipher_tfm(tfm)->crt_ablkcipher;\n}\n\n/**\n * crypto_ablkcipher_ivsize() - obtain IV size\n * @tfm: cipher handle\n *\n * The size of the IV for the ablkcipher referenced by the cipher handle is\n * returned. This IV size may be zero if the cipher does not need an IV.\n *\n * Return: IV size in bytes\n */\nstatic inline unsigned int crypto_ablkcipher_ivsize(\n\tstruct crypto_ablkcipher *tfm)\n{\n\treturn crypto_ablkcipher_crt(tfm)->ivsize;\n}\n\n/**\n * crypto_ablkcipher_blocksize() - obtain block size of cipher\n * @tfm: cipher handle\n *\n * The block size for the ablkcipher referenced with the cipher handle is\n * returned. The caller may use that information to allocate appropriate\n * memory for the data returned by the encryption or decryption operation\n *\n * Return: block size of cipher\n */\nstatic inline unsigned int crypto_ablkcipher_blocksize(\n\tstruct crypto_ablkcipher *tfm)\n{\n\treturn crypto_tfm_alg_blocksize(crypto_ablkcipher_tfm(tfm));\n}\n\nstatic inline unsigned int crypto_ablkcipher_alignmask(\n\tstruct crypto_ablkcipher *tfm)\n{\n\treturn crypto_tfm_alg_alignmask(crypto_ablkcipher_tfm(tfm));\n}\n\nstatic inline u32 crypto_ablkcipher_get_flags(struct crypto_ablkcipher *tfm)\n{\n\treturn crypto_tfm_get_flags(crypto_ablkcipher_tfm(tfm));\n}\n\nstatic inline void crypto_ablkcipher_set_flags(struct crypto_ablkcipher *tfm,\n\t\t\t\t\t       u32 flags)\n{\n\tcrypto_tfm_set_flags(crypto_ablkcipher_tfm(tfm), flags);\n}\n\nstatic inline void crypto_ablkcipher_clear_flags(struct crypto_ablkcipher *tfm,\n\t\t\t\t\t\t u32 flags)\n{\n\tcrypto_tfm_clear_flags(crypto_ablkcipher_tfm(tfm), flags);\n}\n\n/**\n * crypto_ablkcipher_setkey() - set key for cipher\n * @tfm: cipher handle\n * @key: buffer holding the key\n * @keylen: length of the key in bytes\n *\n * The caller provided key is set for the ablkcipher referenced by the cipher\n * handle.\n *\n * Note, the key length determines the cipher type. Many block ciphers implement\n * different cipher modes depending on the key size, such as AES-128 vs AES-192\n * vs. AES-256. When providing a 16 byte key for an AES cipher handle, AES-128\n * is performed.\n *\n * Return: 0 if the setting of the key was successful; < 0 if an error occurred\n */\nstatic inline int crypto_ablkcipher_setkey(struct crypto_ablkcipher *tfm,\n\t\t\t\t\t   const u8 *key, unsigned int keylen)\n{\n\tstruct ablkcipher_tfm *crt = crypto_ablkcipher_crt(tfm);\n\n\treturn crt->setkey(crt->base, key, keylen);\n}\n\n/**\n * crypto_ablkcipher_reqtfm() - obtain cipher handle from request\n * @req: ablkcipher_request out of which the cipher handle is to be obtained\n *\n * Return the crypto_ablkcipher handle when furnishing an ablkcipher_request\n * data structure.\n *\n * Return: crypto_ablkcipher handle\n */\nstatic inline struct crypto_ablkcipher *crypto_ablkcipher_reqtfm(\n\tstruct ablkcipher_request *req)\n{\n\treturn __crypto_ablkcipher_cast(req->base.tfm);\n}\n\n/**\n * crypto_ablkcipher_encrypt() - encrypt plaintext\n * @req: reference to the ablkcipher_request handle that holds all information\n *\t needed to perform the cipher operation\n *\n * Encrypt plaintext data using the ablkcipher_request handle. That data\n * structure and how it is filled with data is discussed with the\n * ablkcipher_request_* functions.\n *\n * Return: 0 if the cipher operation was successful; < 0 if an error occurred\n */\nstatic inline int crypto_ablkcipher_encrypt(struct ablkcipher_request *req)\n{\n\tstruct ablkcipher_tfm *crt =\n\t\tcrypto_ablkcipher_crt(crypto_ablkcipher_reqtfm(req));\n\treturn crt->encrypt(req);\n}\n\n/**\n * crypto_ablkcipher_decrypt() - decrypt ciphertext\n * @req: reference to the ablkcipher_request handle that holds all information\n *\t needed to perform the cipher operation\n *\n * Decrypt ciphertext data using the ablkcipher_request handle. That data\n * structure and how it is filled with data is discussed with the\n * ablkcipher_request_* functions.\n *\n * Return: 0 if the cipher operation was successful; < 0 if an error occurred\n */\nstatic inline int crypto_ablkcipher_decrypt(struct ablkcipher_request *req)\n{\n\tstruct ablkcipher_tfm *crt =\n\t\tcrypto_ablkcipher_crt(crypto_ablkcipher_reqtfm(req));\n\treturn crt->decrypt(req);\n}\n\n/**\n * DOC: Asynchronous Cipher Request Handle\n *\n * The ablkcipher_request data structure contains all pointers to data\n * required for the asynchronous cipher operation. This includes the cipher\n * handle (which can be used by multiple ablkcipher_request instances), pointer\n * to plaintext and ciphertext, asynchronous callback function, etc. It acts\n * as a handle to the ablkcipher_request_* API calls in a similar way as\n * ablkcipher handle to the crypto_ablkcipher_* API calls.\n */\n\n/**\n * crypto_ablkcipher_reqsize() - obtain size of the request data structure\n * @tfm: cipher handle\n *\n * Return: number of bytes\n */\nstatic inline unsigned int crypto_ablkcipher_reqsize(\n\tstruct crypto_ablkcipher *tfm)\n{\n\treturn crypto_ablkcipher_crt(tfm)->reqsize;\n}\n\n/**\n * ablkcipher_request_set_tfm() - update cipher handle reference in request\n * @req: request handle to be modified\n * @tfm: cipher handle that shall be added to the request handle\n *\n * Allow the caller to replace the existing ablkcipher handle in the request\n * data structure with a different one.\n */\nstatic inline void ablkcipher_request_set_tfm(\n\tstruct ablkcipher_request *req, struct crypto_ablkcipher *tfm)\n{\n\treq->base.tfm = crypto_ablkcipher_tfm(crypto_ablkcipher_crt(tfm)->base);\n}\n\nstatic inline struct ablkcipher_request *ablkcipher_request_cast(\n\tstruct crypto_async_request *req)\n{\n\treturn container_of(req, struct ablkcipher_request, base);\n}\n\n/**\n * ablkcipher_request_alloc() - allocate request data structure\n * @tfm: cipher handle to be registered with the request\n * @gfp: memory allocation flag that is handed to kmalloc by the API call.\n *\n * Allocate the request data structure that must be used with the ablkcipher\n * encrypt and decrypt API calls. During the allocation, the provided ablkcipher\n * handle is registered in the request data structure.\n *\n * Return: allocated request handle in case of success; IS_ERR() is true in case\n *\t   of an error, PTR_ERR() returns the error code.\n */\nstatic inline struct ablkcipher_request *ablkcipher_request_alloc(\n\tstruct crypto_ablkcipher *tfm, gfp_t gfp)\n{\n\tstruct ablkcipher_request *req;\n\n\treq = kmalloc(sizeof(struct ablkcipher_request) +\n\t\t      crypto_ablkcipher_reqsize(tfm), gfp);\n\n\tif (likely(req))\n\t\tablkcipher_request_set_tfm(req, tfm);\n\n\treturn req;\n}\n\n/**\n * ablkcipher_request_free() - zeroize and free request data structure\n * @req: request data structure cipher handle to be freed\n */\nstatic inline void ablkcipher_request_free(struct ablkcipher_request *req)\n{\n\tkzfree(req);\n}\n\n/**\n * ablkcipher_request_set_callback() - set asynchronous callback function\n * @req: request handle\n * @flags: specify zero or an ORing of the flags\n *         CRYPTO_TFM_REQ_MAY_BACKLOG the request queue may back log and\n *\t   increase the wait queue beyond the initial maximum size;\n *\t   CRYPTO_TFM_REQ_MAY_SLEEP the request processing may sleep\n * @compl: callback function pointer to be registered with the request handle\n * @data: The data pointer refers to memory that is not used by the kernel\n *\t  crypto API, but provided to the callback function for it to use. Here,\n *\t  the caller can provide a reference to memory the callback function can\n *\t  operate on. As the callback function is invoked asynchronously to the\n *\t  related functionality, it may need to access data structures of the\n *\t  related functionality which can be referenced using this pointer. The\n *\t  callback function can access the memory via the \"data\" field in the\n *\t  crypto_async_request data structure provided to the callback function.\n *\n * This function allows setting the callback function that is triggered once the\n * cipher operation completes.\n *\n * The callback function is registered with the ablkcipher_request handle and\n * must comply with the following template:\n *\n *\tvoid callback_function(struct crypto_async_request *req, int error)\n */\nstatic inline void ablkcipher_request_set_callback(\n\tstruct ablkcipher_request *req,\n\tu32 flags, crypto_completion_t compl, void *data)\n{\n\treq->base.complete = compl;\n\treq->base.data = data;\n\treq->base.flags = flags;\n}\n\n/**\n * ablkcipher_request_set_crypt() - set data buffers\n * @req: request handle\n * @src: source scatter / gather list\n * @dst: destination scatter / gather list\n * @nbytes: number of bytes to process from @src\n * @iv: IV for the cipher operation which must comply with the IV size defined\n *      by crypto_ablkcipher_ivsize\n *\n * This function allows setting of the source data and destination data\n * scatter / gather lists.\n *\n * For encryption, the source is treated as the plaintext and the\n * destination is the ciphertext. For a decryption operation, the use is\n * reversed: the source is the ciphertext and the destination is the plaintext.\n */\nstatic inline void ablkcipher_request_set_crypt(\n\tstruct ablkcipher_request *req,\n\tstruct scatterlist *src, struct scatterlist *dst,\n\tunsigned int nbytes, void *iv)\n{\n\treq->src = src;\n\treq->dst = dst;\n\treq->nbytes = nbytes;\n\treq->info = iv;\n}\n\n/**\n * DOC: Authenticated Encryption With Associated Data (AEAD) Cipher API\n *\n * The AEAD cipher API is used with the ciphers of type CRYPTO_ALG_TYPE_AEAD\n * (listed as type \"aead\" in /proc/crypto)\n *\n * The most prominent examples for this type of encryption is GCM and CCM.\n * However, the kernel supports other types of AEAD ciphers which are defined\n * with the following cipher string:\n *\n *\tauthenc(keyed message digest, block cipher)\n *\n * For example: authenc(hmac(sha256), cbc(aes))\n *\n * The example code provided for the asynchronous block cipher operation\n * applies here as well. Naturally all *ablkcipher* symbols must be exchanged\n * the *aead* pendants discussed in the following. In addtion, for the AEAD\n * operation, the aead_request_set_assoc function must be used to set the\n * pointer to the associated data memory location before performing the\n * encryption or decryption operation. In case of an encryption, the associated\n * data memory is filled during the encryption operation. For decryption, the\n * associated data memory must contain data that is used to verify the integrity\n * of the decrypted data. Another deviation from the asynchronous block cipher\n * operation is that the caller should explicitly check for -EBADMSG of the\n * crypto_aead_decrypt. That error indicates an authentication error, i.e.\n * a breach in the integrity of the message. In essence, that -EBADMSG error\n * code is the key bonus an AEAD cipher has over \"standard\" block chaining\n * modes.\n */\n\nstatic inline struct crypto_aead *__crypto_aead_cast(struct crypto_tfm *tfm)\n{\n\treturn (struct crypto_aead *)tfm;\n}\n\n/**\n * crypto_alloc_aead() - allocate AEAD cipher handle\n * @alg_name: is the cra_name / name or cra_driver_name / driver name of the\n *\t     AEAD cipher\n * @type: specifies the type of the cipher\n * @mask: specifies the mask for the cipher\n *\n * Allocate a cipher handle for an AEAD. The returned struct\n * crypto_aead is the cipher handle that is required for any subsequent\n * API invocation for that AEAD.\n *\n * Return: allocated cipher handle in case of success; IS_ERR() is true in case\n *\t   of an error, PTR_ERR() returns the error code.\n */\nstruct crypto_aead *crypto_alloc_aead(const char *alg_name, u32 type, u32 mask);\n\nstatic inline struct crypto_tfm *crypto_aead_tfm(struct crypto_aead *tfm)\n{\n\treturn &tfm->base;\n}\n\n/**\n * crypto_free_aead() - zeroize and free aead handle\n * @tfm: cipher handle to be freed\n */\nstatic inline void crypto_free_aead(struct crypto_aead *tfm)\n{\n\tcrypto_free_tfm(crypto_aead_tfm(tfm));\n}\n\nstatic inline struct aead_tfm *crypto_aead_crt(struct crypto_aead *tfm)\n{\n\treturn &crypto_aead_tfm(tfm)->crt_aead;\n}\n\n/**\n * crypto_aead_ivsize() - obtain IV size\n * @tfm: cipher handle\n *\n * The size of the IV for the aead referenced by the cipher handle is\n * returned. This IV size may be zero if the cipher does not need an IV.\n *\n * Return: IV size in bytes\n */\nstatic inline unsigned int crypto_aead_ivsize(struct crypto_aead *tfm)\n{\n\treturn crypto_aead_crt(tfm)->ivsize;\n}\n\n/**\n * crypto_aead_authsize() - obtain maximum authentication data size\n * @tfm: cipher handle\n *\n * The maximum size of the authentication data for the AEAD cipher referenced\n * by the AEAD cipher handle is returned. The authentication data size may be\n * zero if the cipher implements a hard-coded maximum.\n *\n * The authentication data may also be known as \"tag value\".\n *\n * Return: authentication data size / tag size in bytes\n */\nstatic inline unsigned int crypto_aead_authsize(struct crypto_aead *tfm)\n{\n\treturn crypto_aead_crt(tfm)->authsize;\n}\n\n/**\n * crypto_aead_blocksize() - obtain block size of cipher\n * @tfm: cipher handle\n *\n * The block size for the AEAD referenced with the cipher handle is returned.\n * The caller may use that information to allocate appropriate memory for the\n * data returned by the encryption or decryption operation\n *\n * Return: block size of cipher\n */\nstatic inline unsigned int crypto_aead_blocksize(struct crypto_aead *tfm)\n{\n\treturn crypto_tfm_alg_blocksize(crypto_aead_tfm(tfm));\n}\n\nstatic inline unsigned int crypto_aead_alignmask(struct crypto_aead *tfm)\n{\n\treturn crypto_tfm_alg_alignmask(crypto_aead_tfm(tfm));\n}\n\nstatic inline u32 crypto_aead_get_flags(struct crypto_aead *tfm)\n{\n\treturn crypto_tfm_get_flags(crypto_aead_tfm(tfm));\n}\n\nstatic inline void crypto_aead_set_flags(struct crypto_aead *tfm, u32 flags)\n{\n\tcrypto_tfm_set_flags(crypto_aead_tfm(tfm), flags);\n}\n\nstatic inline void crypto_aead_clear_flags(struct crypto_aead *tfm, u32 flags)\n{\n\tcrypto_tfm_clear_flags(crypto_aead_tfm(tfm), flags);\n}\n\n/**\n * crypto_aead_setkey() - set key for cipher\n * @tfm: cipher handle\n * @key: buffer holding the key\n * @keylen: length of the key in bytes\n *\n * The caller provided key is set for the AEAD referenced by the cipher\n * handle.\n *\n * Note, the key length determines the cipher type. Many block ciphers implement\n * different cipher modes depending on the key size, such as AES-128 vs AES-192\n * vs. AES-256. When providing a 16 byte key for an AES cipher handle, AES-128\n * is performed.\n *\n * Return: 0 if the setting of the key was successful; < 0 if an error occurred\n */\nstatic inline int crypto_aead_setkey(struct crypto_aead *tfm, const u8 *key,\n\t\t\t\t     unsigned int keylen)\n{\n\tstruct aead_tfm *crt = crypto_aead_crt(tfm);\n\n\treturn crt->setkey(crt->base, key, keylen);\n}\n\n/**\n * crypto_aead_setauthsize() - set authentication data size\n * @tfm: cipher handle\n * @authsize: size of the authentication data / tag in bytes\n *\n * Set the authentication data size / tag size. AEAD requires an authentication\n * tag (or MAC) in addition to the associated data.\n *\n * Return: 0 if the setting of the key was successful; < 0 if an error occurred\n */\nint crypto_aead_setauthsize(struct crypto_aead *tfm, unsigned int authsize);\n\nstatic inline struct crypto_aead *crypto_aead_reqtfm(struct aead_request *req)\n{\n\treturn __crypto_aead_cast(req->base.tfm);\n}\n\n/**\n * crypto_aead_encrypt() - encrypt plaintext\n * @req: reference to the aead_request handle that holds all information\n *\t needed to perform the cipher operation\n *\n * Encrypt plaintext data using the aead_request handle. That data structure\n * and how it is filled with data is discussed with the aead_request_*\n * functions.\n *\n * IMPORTANT NOTE The encryption operation creates the authentication data /\n *\t\t  tag. That data is concatenated with the created ciphertext.\n *\t\t  The ciphertext memory size is therefore the given number of\n *\t\t  block cipher blocks + the size defined by the\n *\t\t  crypto_aead_setauthsize invocation. The caller must ensure\n *\t\t  that sufficient memory is available for the ciphertext and\n *\t\t  the authentication tag.\n *\n * Return: 0 if the cipher operation was successful; < 0 if an error occurred\n */\nstatic inline int crypto_aead_encrypt(struct aead_request *req)\n{\n\treturn crypto_aead_crt(crypto_aead_reqtfm(req))->encrypt(req);\n}\n\n/**\n * crypto_aead_decrypt() - decrypt ciphertext\n * @req: reference to the ablkcipher_request handle that holds all information\n *\t needed to perform the cipher operation\n *\n * Decrypt ciphertext data using the aead_request handle. That data structure\n * and how it is filled with data is discussed with the aead_request_*\n * functions.\n *\n * IMPORTANT NOTE The caller must concatenate the ciphertext followed by the\n *\t\t  authentication data / tag. That authentication data / tag\n *\t\t  must have the size defined by the crypto_aead_setauthsize\n *\t\t  invocation.\n *\n *\n * Return: 0 if the cipher operation was successful; -EBADMSG: The AEAD\n *\t   cipher operation performs the authentication of the data during the\n *\t   decryption operation. Therefore, the function returns this error if\n *\t   the authentication of the ciphertext was unsuccessful (i.e. the\n *\t   integrity of the ciphertext or the associated data was violated);\n *\t   < 0 if an error occurred.\n */\nstatic inline int crypto_aead_decrypt(struct aead_request *req)\n{\n\treturn crypto_aead_crt(crypto_aead_reqtfm(req))->decrypt(req);\n}\n\n/**\n * DOC: Asynchronous AEAD Request Handle\n *\n * The aead_request data structure contains all pointers to data required for\n * the AEAD cipher operation. This includes the cipher handle (which can be\n * used by multiple aead_request instances), pointer to plaintext and\n * ciphertext, asynchronous callback function, etc. It acts as a handle to the\n * aead_request_* API calls in a similar way as AEAD handle to the\n * crypto_aead_* API calls.\n */\n\n/**\n * crypto_aead_reqsize() - obtain size of the request data structure\n * @tfm: cipher handle\n *\n * Return: number of bytes\n */\nstatic inline unsigned int crypto_aead_reqsize(struct crypto_aead *tfm)\n{\n\treturn crypto_aead_crt(tfm)->reqsize;\n}\n\n/**\n * aead_request_set_tfm() - update cipher handle reference in request\n * @req: request handle to be modified\n * @tfm: cipher handle that shall be added to the request handle\n *\n * Allow the caller to replace the existing aead handle in the request\n * data structure with a different one.\n */\nstatic inline void aead_request_set_tfm(struct aead_request *req,\n\t\t\t\t\tstruct crypto_aead *tfm)\n{\n\treq->base.tfm = crypto_aead_tfm(crypto_aead_crt(tfm)->base);\n}\n\n/**\n * aead_request_alloc() - allocate request data structure\n * @tfm: cipher handle to be registered with the request\n * @gfp: memory allocation flag that is handed to kmalloc by the API call.\n *\n * Allocate the request data structure that must be used with the AEAD\n * encrypt and decrypt API calls. During the allocation, the provided aead\n * handle is registered in the request data structure.\n *\n * Return: allocated request handle in case of success; IS_ERR() is true in case\n *\t   of an error, PTR_ERR() returns the error code.\n */\nstatic inline struct aead_request *aead_request_alloc(struct crypto_aead *tfm,\n\t\t\t\t\t\t      gfp_t gfp)\n{\n\tstruct aead_request *req;\n\n\treq = kmalloc(sizeof(*req) + crypto_aead_reqsize(tfm), gfp);\n\n\tif (likely(req))\n\t\taead_request_set_tfm(req, tfm);\n\n\treturn req;\n}\n\n/**\n * aead_request_free() - zeroize and free request data structure\n * @req: request data structure cipher handle to be freed\n */\nstatic inline void aead_request_free(struct aead_request *req)\n{\n\tkzfree(req);\n}\n\n/**\n * aead_request_set_callback() - set asynchronous callback function\n * @req: request handle\n * @flags: specify zero or an ORing of the flags\n *\t   CRYPTO_TFM_REQ_MAY_BACKLOG the request queue may back log and\n *\t   increase the wait queue beyond the initial maximum size;\n *\t   CRYPTO_TFM_REQ_MAY_SLEEP the request processing may sleep\n * @compl: callback function pointer to be registered with the request handle\n * @data: The data pointer refers to memory that is not used by the kernel\n *\t  crypto API, but provided to the callback function for it to use. Here,\n *\t  the caller can provide a reference to memory the callback function can\n *\t  operate on. As the callback function is invoked asynchronously to the\n *\t  related functionality, it may need to access data structures of the\n *\t  related functionality which can be referenced using this pointer. The\n *\t  callback function can access the memory via the \"data\" field in the\n *\t  crypto_async_request data structure provided to the callback function.\n *\n * Setting the callback function that is triggered once the cipher operation\n * completes\n *\n * The callback function is registered with the aead_request handle and\n * must comply with the following template:\n *\n *\tvoid callback_function(struct crypto_async_request *req, int error)\n */\nstatic inline void aead_request_set_callback(struct aead_request *req,\n\t\t\t\t\t     u32 flags,\n\t\t\t\t\t     crypto_completion_t compl,\n\t\t\t\t\t     void *data)\n{\n\treq->base.complete = compl;\n\treq->base.data = data;\n\treq->base.flags = flags;\n}\n\n/**\n * aead_request_set_crypt - set data buffers\n * @req: request handle\n * @src: source scatter / gather list\n * @dst: destination scatter / gather list\n * @cryptlen: number of bytes to process from @src\n * @iv: IV for the cipher operation which must comply with the IV size defined\n *      by crypto_aead_ivsize()\n *\n * Setting the source data and destination data scatter / gather lists.\n *\n * For encryption, the source is treated as the plaintext and the\n * destination is the ciphertext. For a decryption operation, the use is\n * reversed: the source is the ciphertext and the destination is the plaintext.\n *\n * IMPORTANT NOTE AEAD requires an authentication tag (MAC). For decryption,\n *\t\t  the caller must concatenate the ciphertext followed by the\n *\t\t  authentication tag and provide the entire data stream to the\n *\t\t  decryption operation (i.e. the data length used for the\n *\t\t  initialization of the scatterlist and the data length for the\n *\t\t  decryption operation is identical). For encryption, however,\n *\t\t  the authentication tag is created while encrypting the data.\n *\t\t  The destination buffer must hold sufficient space for the\n *\t\t  ciphertext and the authentication tag while the encryption\n *\t\t  invocation must only point to the plaintext data size. The\n *\t\t  following code snippet illustrates the memory usage\n *\t\t  buffer = kmalloc(ptbuflen + (enc ? authsize : 0));\n *\t\t  sg_init_one(&sg, buffer, ptbuflen + (enc ? authsize : 0));\n *\t\t  aead_request_set_crypt(req, &sg, &sg, ptbuflen, iv);\n */\nstatic inline void aead_request_set_crypt(struct aead_request *req,\n\t\t\t\t\t  struct scatterlist *src,\n\t\t\t\t\t  struct scatterlist *dst,\n\t\t\t\t\t  unsigned int cryptlen, u8 *iv)\n{\n\treq->src = src;\n\treq->dst = dst;\n\treq->cryptlen = cryptlen;\n\treq->iv = iv;\n}\n\n/**\n * aead_request_set_assoc() - set the associated data scatter / gather list\n * @req: request handle\n * @assoc: associated data scatter / gather list\n * @assoclen: number of bytes to process from @assoc\n *\n * For encryption, the memory is filled with the associated data. For\n * decryption, the memory must point to the associated data.\n */\nstatic inline void aead_request_set_assoc(struct aead_request *req,\n\t\t\t\t\t  struct scatterlist *assoc,\n\t\t\t\t\t  unsigned int assoclen)\n{\n\treq->assoc = assoc;\n\treq->assoclen = assoclen;\n}\n\n/**\n * DOC: Synchronous Block Cipher API\n *\n * The synchronous block cipher API is used with the ciphers of type\n * CRYPTO_ALG_TYPE_BLKCIPHER (listed as type \"blkcipher\" in /proc/crypto)\n *\n * Synchronous calls, have a context in the tfm. But since a single tfm can be\n * used in multiple calls and in parallel, this info should not be changeable\n * (unless a lock is used). This applies, for example, to the symmetric key.\n * However, the IV is changeable, so there is an iv field in blkcipher_tfm\n * structure for synchronous blkcipher api. So, its the only state info that can\n * be kept for synchronous calls without using a big lock across a tfm.\n *\n * The block cipher API allows the use of a complete cipher, i.e. a cipher\n * consisting of a template (a block chaining mode) and a single block cipher\n * primitive (e.g. AES).\n *\n * The plaintext data buffer and the ciphertext data buffer are pointed to\n * by using scatter/gather lists. The cipher operation is performed\n * on all segments of the provided scatter/gather lists.\n *\n * The kernel crypto API supports a cipher operation \"in-place\" which means that\n * the caller may provide the same scatter/gather list for the plaintext and\n * cipher text. After the completion of the cipher operation, the plaintext\n * data is replaced with the ciphertext data in case of an encryption and vice\n * versa for a decryption. The caller must ensure that the scatter/gather lists\n * for the output data point to sufficiently large buffers, i.e. multiples of\n * the block size of the cipher.\n */\n\nstatic inline struct crypto_blkcipher *__crypto_blkcipher_cast(\n\tstruct crypto_tfm *tfm)\n{\n\treturn (struct crypto_blkcipher *)tfm;\n}\n\nstatic inline struct crypto_blkcipher *crypto_blkcipher_cast(\n\tstruct crypto_tfm *tfm)\n{\n\tBUG_ON(crypto_tfm_alg_type(tfm) != CRYPTO_ALG_TYPE_BLKCIPHER);\n\treturn __crypto_blkcipher_cast(tfm);\n}\n\n/**\n * crypto_alloc_blkcipher() - allocate synchronous block cipher handle\n * @alg_name: is the cra_name / name or cra_driver_name / driver name of the\n *\t      blkcipher cipher\n * @type: specifies the type of the cipher\n * @mask: specifies the mask for the cipher\n *\n * Allocate a cipher handle for a block cipher. The returned struct\n * crypto_blkcipher is the cipher handle that is required for any subsequent\n * API invocation for that block cipher.\n *\n * Return: allocated cipher handle in case of success; IS_ERR() is true in case\n *\t   of an error, PTR_ERR() returns the error code.\n */\nstatic inline struct crypto_blkcipher *crypto_alloc_blkcipher(\n\tconst char *alg_name, u32 type, u32 mask)\n{\n\ttype &= ~CRYPTO_ALG_TYPE_MASK;\n\ttype |= CRYPTO_ALG_TYPE_BLKCIPHER;\n\tmask |= CRYPTO_ALG_TYPE_MASK;\n\n\treturn __crypto_blkcipher_cast(crypto_alloc_base(alg_name, type, mask));\n}\n\nstatic inline struct crypto_tfm *crypto_blkcipher_tfm(\n\tstruct crypto_blkcipher *tfm)\n{\n\treturn &tfm->base;\n}\n\n/**\n * crypto_free_blkcipher() - zeroize and free the block cipher handle\n * @tfm: cipher handle to be freed\n */\nstatic inline void crypto_free_blkcipher(struct crypto_blkcipher *tfm)\n{\n\tcrypto_free_tfm(crypto_blkcipher_tfm(tfm));\n}\n\n/**\n * crypto_has_blkcipher() - Search for the availability of a block cipher\n * @alg_name: is the cra_name / name or cra_driver_name / driver name of the\n *\t      block cipher\n * @type: specifies the type of the cipher\n * @mask: specifies the mask for the cipher\n *\n * Return: true when the block cipher is known to the kernel crypto API; false\n *\t   otherwise\n */\nstatic inline int crypto_has_blkcipher(const char *alg_name, u32 type, u32 mask)\n{\n\ttype &= ~CRYPTO_ALG_TYPE_MASK;\n\ttype |= CRYPTO_ALG_TYPE_BLKCIPHER;\n\tmask |= CRYPTO_ALG_TYPE_MASK;\n\n\treturn crypto_has_alg(alg_name, type, mask);\n}\n\n/**\n * crypto_blkcipher_name() - return the name / cra_name from the cipher handle\n * @tfm: cipher handle\n *\n * Return: The character string holding the name of the cipher\n */\nstatic inline const char *crypto_blkcipher_name(struct crypto_blkcipher *tfm)\n{\n\treturn crypto_tfm_alg_name(crypto_blkcipher_tfm(tfm));\n}\n\nstatic inline struct blkcipher_tfm *crypto_blkcipher_crt(\n\tstruct crypto_blkcipher *tfm)\n{\n\treturn &crypto_blkcipher_tfm(tfm)->crt_blkcipher;\n}\n\nstatic inline struct blkcipher_alg *crypto_blkcipher_alg(\n\tstruct crypto_blkcipher *tfm)\n{\n\treturn &crypto_blkcipher_tfm(tfm)->__crt_alg->cra_blkcipher;\n}\n\n/**\n * crypto_blkcipher_ivsize() - obtain IV size\n * @tfm: cipher handle\n *\n * The size of the IV for the block cipher referenced by the cipher handle is\n * returned. This IV size may be zero if the cipher does not need an IV.\n *\n * Return: IV size in bytes\n */\nstatic inline unsigned int crypto_blkcipher_ivsize(struct crypto_blkcipher *tfm)\n{\n\treturn crypto_blkcipher_alg(tfm)->ivsize;\n}\n\n/**\n * crypto_blkcipher_blocksize() - obtain block size of cipher\n * @tfm: cipher handle\n *\n * The block size for the block cipher referenced with the cipher handle is\n * returned. The caller may use that information to allocate appropriate\n * memory for the data returned by the encryption or decryption operation.\n *\n * Return: block size of cipher\n */\nstatic inline unsigned int crypto_blkcipher_blocksize(\n\tstruct crypto_blkcipher *tfm)\n{\n\treturn crypto_tfm_alg_blocksize(crypto_blkcipher_tfm(tfm));\n}\n\nstatic inline unsigned int crypto_blkcipher_alignmask(\n\tstruct crypto_blkcipher *tfm)\n{\n\treturn crypto_tfm_alg_alignmask(crypto_blkcipher_tfm(tfm));\n}\n\nstatic inline u32 crypto_blkcipher_get_flags(struct crypto_blkcipher *tfm)\n{\n\treturn crypto_tfm_get_flags(crypto_blkcipher_tfm(tfm));\n}\n\nstatic inline void crypto_blkcipher_set_flags(struct crypto_blkcipher *tfm,\n\t\t\t\t\t      u32 flags)\n{\n\tcrypto_tfm_set_flags(crypto_blkcipher_tfm(tfm), flags);\n}\n\nstatic inline void crypto_blkcipher_clear_flags(struct crypto_blkcipher *tfm,\n\t\t\t\t\t\tu32 flags)\n{\n\tcrypto_tfm_clear_flags(crypto_blkcipher_tfm(tfm), flags);\n}\n\n/**\n * crypto_blkcipher_setkey() - set key for cipher\n * @tfm: cipher handle\n * @key: buffer holding the key\n * @keylen: length of the key in bytes\n *\n * The caller provided key is set for the block cipher referenced by the cipher\n * handle.\n *\n * Note, the key length determines the cipher type. Many block ciphers implement\n * different cipher modes depending on the key size, such as AES-128 vs AES-192\n * vs. AES-256. When providing a 16 byte key for an AES cipher handle, AES-128\n * is performed.\n *\n * Return: 0 if the setting of the key was successful; < 0 if an error occurred\n */\nstatic inline int crypto_blkcipher_setkey(struct crypto_blkcipher *tfm,\n\t\t\t\t\t  const u8 *key, unsigned int keylen)\n{\n\treturn crypto_blkcipher_crt(tfm)->setkey(crypto_blkcipher_tfm(tfm),\n\t\t\t\t\t\t key, keylen);\n}\n\n/**\n * crypto_blkcipher_encrypt() - encrypt plaintext\n * @desc: reference to the block cipher handle with meta data\n * @dst: scatter/gather list that is filled by the cipher operation with the\n *\tciphertext\n * @src: scatter/gather list that holds the plaintext\n * @nbytes: number of bytes of the plaintext to encrypt.\n *\n * Encrypt plaintext data using the IV set by the caller with a preceding\n * call of crypto_blkcipher_set_iv.\n *\n * The blkcipher_desc data structure must be filled by the caller and can\n * reside on the stack. The caller must fill desc as follows: desc.tfm is filled\n * with the block cipher handle; desc.flags is filled with either\n * CRYPTO_TFM_REQ_MAY_SLEEP or 0.\n *\n * Return: 0 if the cipher operation was successful; < 0 if an error occurred\n */\nstatic inline int crypto_blkcipher_encrypt(struct blkcipher_desc *desc,\n\t\t\t\t\t   struct scatterlist *dst,\n\t\t\t\t\t   struct scatterlist *src,\n\t\t\t\t\t   unsigned int nbytes)\n{\n\tdesc->info = crypto_blkcipher_crt(desc->tfm)->iv;\n\treturn crypto_blkcipher_crt(desc->tfm)->encrypt(desc, dst, src, nbytes);\n}\n\n/**\n * crypto_blkcipher_encrypt_iv() - encrypt plaintext with dedicated IV\n * @desc: reference to the block cipher handle with meta data\n * @dst: scatter/gather list that is filled by the cipher operation with the\n *\tciphertext\n * @src: scatter/gather list that holds the plaintext\n * @nbytes: number of bytes of the plaintext to encrypt.\n *\n * Encrypt plaintext data with the use of an IV that is solely used for this\n * cipher operation. Any previously set IV is not used.\n *\n * The blkcipher_desc data structure must be filled by the caller and can\n * reside on the stack. The caller must fill desc as follows: desc.tfm is filled\n * with the block cipher handle; desc.info is filled with the IV to be used for\n * the current operation; desc.flags is filled with either\n * CRYPTO_TFM_REQ_MAY_SLEEP or 0.\n *\n * Return: 0 if the cipher operation was successful; < 0 if an error occurred\n */\nstatic inline int crypto_blkcipher_encrypt_iv(struct blkcipher_desc *desc,\n\t\t\t\t\t      struct scatterlist *dst,\n\t\t\t\t\t      struct scatterlist *src,\n\t\t\t\t\t      unsigned int nbytes)\n{\n\treturn crypto_blkcipher_crt(desc->tfm)->encrypt(desc, dst, src, nbytes);\n}\n\n/**\n * crypto_blkcipher_decrypt() - decrypt ciphertext\n * @desc: reference to the block cipher handle with meta data\n * @dst: scatter/gather list that is filled by the cipher operation with the\n *\tplaintext\n * @src: scatter/gather list that holds the ciphertext\n * @nbytes: number of bytes of the ciphertext to decrypt.\n *\n * Decrypt ciphertext data using the IV set by the caller with a preceding\n * call of crypto_blkcipher_set_iv.\n *\n * The blkcipher_desc data structure must be filled by the caller as documented\n * for the crypto_blkcipher_encrypt call above.\n *\n * Return: 0 if the cipher operation was successful; < 0 if an error occurred\n *\n */\nstatic inline int crypto_blkcipher_decrypt(struct blkcipher_desc *desc,\n\t\t\t\t\t   struct scatterlist *dst,\n\t\t\t\t\t   struct scatterlist *src,\n\t\t\t\t\t   unsigned int nbytes)\n{\n\tdesc->info = crypto_blkcipher_crt(desc->tfm)->iv;\n\treturn crypto_blkcipher_crt(desc->tfm)->decrypt(desc, dst, src, nbytes);\n}\n\n/**\n * crypto_blkcipher_decrypt_iv() - decrypt ciphertext with dedicated IV\n * @desc: reference to the block cipher handle with meta data\n * @dst: scatter/gather list that is filled by the cipher operation with the\n *\tplaintext\n * @src: scatter/gather list that holds the ciphertext\n * @nbytes: number of bytes of the ciphertext to decrypt.\n *\n * Decrypt ciphertext data with the use of an IV that is solely used for this\n * cipher operation. Any previously set IV is not used.\n *\n * The blkcipher_desc data structure must be filled by the caller as documented\n * for the crypto_blkcipher_encrypt_iv call above.\n *\n * Return: 0 if the cipher operation was successful; < 0 if an error occurred\n */\nstatic inline int crypto_blkcipher_decrypt_iv(struct blkcipher_desc *desc,\n\t\t\t\t\t      struct scatterlist *dst,\n\t\t\t\t\t      struct scatterlist *src,\n\t\t\t\t\t      unsigned int nbytes)\n{\n\treturn crypto_blkcipher_crt(desc->tfm)->decrypt(desc, dst, src, nbytes);\n}\n\n/**\n * crypto_blkcipher_set_iv() - set IV for cipher\n * @tfm: cipher handle\n * @src: buffer holding the IV\n * @len: length of the IV in bytes\n *\n * The caller provided IV is set for the block cipher referenced by the cipher\n * handle.\n */\nstatic inline void crypto_blkcipher_set_iv(struct crypto_blkcipher *tfm,\n\t\t\t\t\t   const u8 *src, unsigned int len)\n{\n\tmemcpy(crypto_blkcipher_crt(tfm)->iv, src, len);\n}\n\n/**\n * crypto_blkcipher_get_iv() - obtain IV from cipher\n * @tfm: cipher handle\n * @dst: buffer filled with the IV\n * @len: length of the buffer dst\n *\n * The caller can obtain the IV set for the block cipher referenced by the\n * cipher handle and store it into the user-provided buffer. If the buffer\n * has an insufficient space, the IV is truncated to fit the buffer.\n */\nstatic inline void crypto_blkcipher_get_iv(struct crypto_blkcipher *tfm,\n\t\t\t\t\t   u8 *dst, unsigned int len)\n{\n\tmemcpy(dst, crypto_blkcipher_crt(tfm)->iv, len);\n}\n\n/**\n * DOC: Single Block Cipher API\n *\n * The single block cipher API is used with the ciphers of type\n * CRYPTO_ALG_TYPE_CIPHER (listed as type \"cipher\" in /proc/crypto).\n *\n * Using the single block cipher API calls, operations with the basic cipher\n * primitive can be implemented. These cipher primitives exclude any block\n * chaining operations including IV handling.\n *\n * The purpose of this single block cipher API is to support the implementation\n * of templates or other concepts that only need to perform the cipher operation\n * on one block at a time. Templates invoke the underlying cipher primitive\n * block-wise and process either the input or the output data of these cipher\n * operations.\n */\n\nstatic inline struct crypto_cipher *__crypto_cipher_cast(struct crypto_tfm *tfm)\n{\n\treturn (struct crypto_cipher *)tfm;\n}\n\nstatic inline struct crypto_cipher *crypto_cipher_cast(struct crypto_tfm *tfm)\n{\n\tBUG_ON(crypto_tfm_alg_type(tfm) != CRYPTO_ALG_TYPE_CIPHER);\n\treturn __crypto_cipher_cast(tfm);\n}\n\n/**\n * crypto_alloc_cipher() - allocate single block cipher handle\n * @alg_name: is the cra_name / name or cra_driver_name / driver name of the\n *\t     single block cipher\n * @type: specifies the type of the cipher\n * @mask: specifies the mask for the cipher\n *\n * Allocate a cipher handle for a single block cipher. The returned struct\n * crypto_cipher is the cipher handle that is required for any subsequent API\n * invocation for that single block cipher.\n *\n * Return: allocated cipher handle in case of success; IS_ERR() is true in case\n *\t   of an error, PTR_ERR() returns the error code.\n */\nstatic inline struct crypto_cipher *crypto_alloc_cipher(const char *alg_name,\n\t\t\t\t\t\t\tu32 type, u32 mask)\n{\n\ttype &= ~CRYPTO_ALG_TYPE_MASK;\n\ttype |= CRYPTO_ALG_TYPE_CIPHER;\n\tmask |= CRYPTO_ALG_TYPE_MASK;\n\n\treturn __crypto_cipher_cast(crypto_alloc_base(alg_name, type, mask));\n}\n\nstatic inline struct crypto_tfm *crypto_cipher_tfm(struct crypto_cipher *tfm)\n{\n\treturn &tfm->base;\n}\n\n/**\n * crypto_free_cipher() - zeroize and free the single block cipher handle\n * @tfm: cipher handle to be freed\n */\nstatic inline void crypto_free_cipher(struct crypto_cipher *tfm)\n{\n\tcrypto_free_tfm(crypto_cipher_tfm(tfm));\n}\n\n/**\n * crypto_has_cipher() - Search for the availability of a single block cipher\n * @alg_name: is the cra_name / name or cra_driver_name / driver name of the\n *\t     single block cipher\n * @type: specifies the type of the cipher\n * @mask: specifies the mask for the cipher\n *\n * Return: true when the single block cipher is known to the kernel crypto API;\n *\t   false otherwise\n */\nstatic inline int crypto_has_cipher(const char *alg_name, u32 type, u32 mask)\n{\n\ttype &= ~CRYPTO_ALG_TYPE_MASK;\n\ttype |= CRYPTO_ALG_TYPE_CIPHER;\n\tmask |= CRYPTO_ALG_TYPE_MASK;\n\n\treturn crypto_has_alg(alg_name, type, mask);\n}\n\nstatic inline struct cipher_tfm *crypto_cipher_crt(struct crypto_cipher *tfm)\n{\n\treturn &crypto_cipher_tfm(tfm)->crt_cipher;\n}\n\n/**\n * crypto_cipher_blocksize() - obtain block size for cipher\n * @tfm: cipher handle\n *\n * The block size for the single block cipher referenced with the cipher handle\n * tfm is returned. The caller may use that information to allocate appropriate\n * memory for the data returned by the encryption or decryption operation\n *\n * Return: block size of cipher\n */\nstatic inline unsigned int crypto_cipher_blocksize(struct crypto_cipher *tfm)\n{\n\treturn crypto_tfm_alg_blocksize(crypto_cipher_tfm(tfm));\n}\n\nstatic inline unsigned int crypto_cipher_alignmask(struct crypto_cipher *tfm)\n{\n\treturn crypto_tfm_alg_alignmask(crypto_cipher_tfm(tfm));\n}\n\nstatic inline u32 crypto_cipher_get_flags(struct crypto_cipher *tfm)\n{\n\treturn crypto_tfm_get_flags(crypto_cipher_tfm(tfm));\n}\n\nstatic inline void crypto_cipher_set_flags(struct crypto_cipher *tfm,\n\t\t\t\t\t   u32 flags)\n{\n\tcrypto_tfm_set_flags(crypto_cipher_tfm(tfm), flags);\n}\n\nstatic inline void crypto_cipher_clear_flags(struct crypto_cipher *tfm,\n\t\t\t\t\t     u32 flags)\n{\n\tcrypto_tfm_clear_flags(crypto_cipher_tfm(tfm), flags);\n}\n\n/**\n * crypto_cipher_setkey() - set key for cipher\n * @tfm: cipher handle\n * @key: buffer holding the key\n * @keylen: length of the key in bytes\n *\n * The caller provided key is set for the single block cipher referenced by the\n * cipher handle.\n *\n * Note, the key length determines the cipher type. Many block ciphers implement\n * different cipher modes depending on the key size, such as AES-128 vs AES-192\n * vs. AES-256. When providing a 16 byte key for an AES cipher handle, AES-128\n * is performed.\n *\n * Return: 0 if the setting of the key was successful; < 0 if an error occurred\n */\nstatic inline int crypto_cipher_setkey(struct crypto_cipher *tfm,\n                                       const u8 *key, unsigned int keylen)\n{\n\treturn crypto_cipher_crt(tfm)->cit_setkey(crypto_cipher_tfm(tfm),\n\t\t\t\t\t\t  key, keylen);\n}\n\n/**\n * crypto_cipher_encrypt_one() - encrypt one block of plaintext\n * @tfm: cipher handle\n * @dst: points to the buffer that will be filled with the ciphertext\n * @src: buffer holding the plaintext to be encrypted\n *\n * Invoke the encryption operation of one block. The caller must ensure that\n * the plaintext and ciphertext buffers are at least one block in size.\n */\nstatic inline void crypto_cipher_encrypt_one(struct crypto_cipher *tfm,\n\t\t\t\t\t     u8 *dst, const u8 *src)\n{\n\tcrypto_cipher_crt(tfm)->cit_encrypt_one(crypto_cipher_tfm(tfm),\n\t\t\t\t\t\tdst, src);\n}\n\n/**\n * crypto_cipher_decrypt_one() - decrypt one block of ciphertext\n * @tfm: cipher handle\n * @dst: points to the buffer that will be filled with the plaintext\n * @src: buffer holding the ciphertext to be decrypted\n *\n * Invoke the decryption operation of one block. The caller must ensure that\n * the plaintext and ciphertext buffers are at least one block in size.\n */\nstatic inline void crypto_cipher_decrypt_one(struct crypto_cipher *tfm,\n\t\t\t\t\t     u8 *dst, const u8 *src)\n{\n\tcrypto_cipher_crt(tfm)->cit_decrypt_one(crypto_cipher_tfm(tfm),\n\t\t\t\t\t\tdst, src);\n}\n\n/**\n * DOC: Synchronous Message Digest API\n *\n * The synchronous message digest API is used with the ciphers of type\n * CRYPTO_ALG_TYPE_HASH (listed as type \"hash\" in /proc/crypto)\n */\n\nstatic inline struct crypto_hash *__crypto_hash_cast(struct crypto_tfm *tfm)\n{\n\treturn (struct crypto_hash *)tfm;\n}\n\nstatic inline struct crypto_hash *crypto_hash_cast(struct crypto_tfm *tfm)\n{\n\tBUG_ON((crypto_tfm_alg_type(tfm) ^ CRYPTO_ALG_TYPE_HASH) &\n\t       CRYPTO_ALG_TYPE_HASH_MASK);\n\treturn __crypto_hash_cast(tfm);\n}\n\n/**\n * crypto_alloc_hash() - allocate synchronous message digest handle\n * @alg_name: is the cra_name / name or cra_driver_name / driver name of the\n *\t      message digest cipher\n * @type: specifies the type of the cipher\n * @mask: specifies the mask for the cipher\n *\n * Allocate a cipher handle for a message digest. The returned struct\n * crypto_hash is the cipher handle that is required for any subsequent\n * API invocation for that message digest.\n *\n * Return: allocated cipher handle in case of success; IS_ERR() is true in case\n * of an error, PTR_ERR() returns the error code.\n */\nstatic inline struct crypto_hash *crypto_alloc_hash(const char *alg_name,\n\t\t\t\t\t\t    u32 type, u32 mask)\n{\n\ttype &= ~CRYPTO_ALG_TYPE_MASK;\n\tmask &= ~CRYPTO_ALG_TYPE_MASK;\n\ttype |= CRYPTO_ALG_TYPE_HASH;\n\tmask |= CRYPTO_ALG_TYPE_HASH_MASK;\n\n\treturn __crypto_hash_cast(crypto_alloc_base(alg_name, type, mask));\n}\n\nstatic inline struct crypto_tfm *crypto_hash_tfm(struct crypto_hash *tfm)\n{\n\treturn &tfm->base;\n}\n\n/**\n * crypto_free_hash() - zeroize and free message digest handle\n * @tfm: cipher handle to be freed\n */\nstatic inline void crypto_free_hash(struct crypto_hash *tfm)\n{\n\tcrypto_free_tfm(crypto_hash_tfm(tfm));\n}\n\n/**\n * crypto_has_hash() - Search for the availability of a message digest\n * @alg_name: is the cra_name / name or cra_driver_name / driver name of the\n *\t      message digest cipher\n * @type: specifies the type of the cipher\n * @mask: specifies the mask for the cipher\n *\n * Return: true when the message digest cipher is known to the kernel crypto\n *\t   API; false otherwise\n */\nstatic inline int crypto_has_hash(const char *alg_name, u32 type, u32 mask)\n{\n\ttype &= ~CRYPTO_ALG_TYPE_MASK;\n\tmask &= ~CRYPTO_ALG_TYPE_MASK;\n\ttype |= CRYPTO_ALG_TYPE_HASH;\n\tmask |= CRYPTO_ALG_TYPE_HASH_MASK;\n\n\treturn crypto_has_alg(alg_name, type, mask);\n}\n\nstatic inline struct hash_tfm *crypto_hash_crt(struct crypto_hash *tfm)\n{\n\treturn &crypto_hash_tfm(tfm)->crt_hash;\n}\n\n/**\n * crypto_hash_blocksize() - obtain block size for message digest\n * @tfm: cipher handle\n *\n * The block size for the message digest cipher referenced with the cipher\n * handle is returned.\n *\n * Return: block size of cipher\n */\nstatic inline unsigned int crypto_hash_blocksize(struct crypto_hash *tfm)\n{\n\treturn crypto_tfm_alg_blocksize(crypto_hash_tfm(tfm));\n}\n\nstatic inline unsigned int crypto_hash_alignmask(struct crypto_hash *tfm)\n{\n\treturn crypto_tfm_alg_alignmask(crypto_hash_tfm(tfm));\n}\n\n/**\n * crypto_hash_digestsize() - obtain message digest size\n * @tfm: cipher handle\n *\n * The size for the message digest created by the message digest cipher\n * referenced with the cipher handle is returned.\n *\n * Return: message digest size\n */\nstatic inline unsigned int crypto_hash_digestsize(struct crypto_hash *tfm)\n{\n\treturn crypto_hash_crt(tfm)->digestsize;\n}\n\nstatic inline u32 crypto_hash_get_flags(struct crypto_hash *tfm)\n{\n\treturn crypto_tfm_get_flags(crypto_hash_tfm(tfm));\n}\n\nstatic inline void crypto_hash_set_flags(struct crypto_hash *tfm, u32 flags)\n{\n\tcrypto_tfm_set_flags(crypto_hash_tfm(tfm), flags);\n}\n\nstatic inline void crypto_hash_clear_flags(struct crypto_hash *tfm, u32 flags)\n{\n\tcrypto_tfm_clear_flags(crypto_hash_tfm(tfm), flags);\n}\n\n/**\n * crypto_hash_init() - (re)initialize message digest handle\n * @desc: cipher request handle that to be filled by caller --\n *\t  desc.tfm is filled with the hash cipher handle;\n *\t  desc.flags is filled with either CRYPTO_TFM_REQ_MAY_SLEEP or 0.\n *\n * The call (re-)initializes the message digest referenced by the hash cipher\n * request handle. Any potentially existing state created by previous\n * operations is discarded.\n *\n * Return: 0 if the message digest initialization was successful; < 0 if an\n *\t   error occurred\n */\nstatic inline int crypto_hash_init(struct hash_desc *desc)\n{\n\treturn crypto_hash_crt(desc->tfm)->init(desc);\n}\n\n/**\n * crypto_hash_update() - add data to message digest for processing\n * @desc: cipher request handle\n * @sg: scatter / gather list pointing to the data to be added to the message\n *      digest\n * @nbytes: number of bytes to be processed from @sg\n *\n * Updates the message digest state of the cipher handle pointed to by the\n * hash cipher request handle with the input data pointed to by the\n * scatter/gather list.\n *\n * Return: 0 if the message digest update was successful; < 0 if an error\n *\t   occurred\n */\nstatic inline int crypto_hash_update(struct hash_desc *desc,\n\t\t\t\t     struct scatterlist *sg,\n\t\t\t\t     unsigned int nbytes)\n{\n\treturn crypto_hash_crt(desc->tfm)->update(desc, sg, nbytes);\n}\n\n/**\n * crypto_hash_final() - calculate message digest\n * @desc: cipher request handle\n * @out: message digest output buffer -- The caller must ensure that the out\n *\t buffer has a sufficient size (e.g. by using the crypto_hash_digestsize\n *\t function).\n *\n * Finalize the message digest operation and create the message digest\n * based on all data added to the cipher handle. The message digest is placed\n * into the output buffer.\n *\n * Return: 0 if the message digest creation was successful; < 0 if an error\n *\t   occurred\n */\nstatic inline int crypto_hash_final(struct hash_desc *desc, u8 *out)\n{\n\treturn crypto_hash_crt(desc->tfm)->final(desc, out);\n}\n\n/**\n * crypto_hash_digest() - calculate message digest for a buffer\n * @desc: see crypto_hash_final()\n * @sg: see crypto_hash_update()\n * @nbytes:  see crypto_hash_update()\n * @out: see crypto_hash_final()\n *\n * This function is a \"short-hand\" for the function calls of crypto_hash_init,\n * crypto_hash_update and crypto_hash_final. The parameters have the same\n * meaning as discussed for those separate three functions.\n *\n * Return: 0 if the message digest creation was successful; < 0 if an error\n *\t   occurred\n */\nstatic inline int crypto_hash_digest(struct hash_desc *desc,\n\t\t\t\t     struct scatterlist *sg,\n\t\t\t\t     unsigned int nbytes, u8 *out)\n{\n\treturn crypto_hash_crt(desc->tfm)->digest(desc, sg, nbytes, out);\n}\n\n/**\n * crypto_hash_setkey() - set key for message digest\n * @hash: cipher handle\n * @key: buffer holding the key\n * @keylen: length of the key in bytes\n *\n * The caller provided key is set for the message digest cipher. The cipher\n * handle must point to a keyed hash in order for this function to succeed.\n *\n * Return: 0 if the setting of the key was successful; < 0 if an error occurred\n */\nstatic inline int crypto_hash_setkey(struct crypto_hash *hash,\n\t\t\t\t     const u8 *key, unsigned int keylen)\n{\n\treturn crypto_hash_crt(hash)->setkey(hash, key, keylen);\n}\n\nstatic inline struct crypto_comp *__crypto_comp_cast(struct crypto_tfm *tfm)\n{\n\treturn (struct crypto_comp *)tfm;\n}\n\nstatic inline struct crypto_comp *crypto_comp_cast(struct crypto_tfm *tfm)\n{\n\tBUG_ON((crypto_tfm_alg_type(tfm) ^ CRYPTO_ALG_TYPE_COMPRESS) &\n\t       CRYPTO_ALG_TYPE_MASK);\n\treturn __crypto_comp_cast(tfm);\n}\n\nstatic inline struct crypto_comp *crypto_alloc_comp(const char *alg_name,\n\t\t\t\t\t\t    u32 type, u32 mask)\n{\n\ttype &= ~CRYPTO_ALG_TYPE_MASK;\n\ttype |= CRYPTO_ALG_TYPE_COMPRESS;\n\tmask |= CRYPTO_ALG_TYPE_MASK;\n\n\treturn __crypto_comp_cast(crypto_alloc_base(alg_name, type, mask));\n}\n\nstatic inline struct crypto_tfm *crypto_comp_tfm(struct crypto_comp *tfm)\n{\n\treturn &tfm->base;\n}\n\nstatic inline void crypto_free_comp(struct crypto_comp *tfm)\n{\n\tcrypto_free_tfm(crypto_comp_tfm(tfm));\n}\n\nstatic inline int crypto_has_comp(const char *alg_name, u32 type, u32 mask)\n{\n\ttype &= ~CRYPTO_ALG_TYPE_MASK;\n\ttype |= CRYPTO_ALG_TYPE_COMPRESS;\n\tmask |= CRYPTO_ALG_TYPE_MASK;\n\n\treturn crypto_has_alg(alg_name, type, mask);\n}\n\nstatic inline const char *crypto_comp_name(struct crypto_comp *tfm)\n{\n\treturn crypto_tfm_alg_name(crypto_comp_tfm(tfm));\n}\n\nstatic inline struct compress_tfm *crypto_comp_crt(struct crypto_comp *tfm)\n{\n\treturn &crypto_comp_tfm(tfm)->crt_compress;\n}\n\nstatic inline int crypto_comp_compress(struct crypto_comp *tfm,\n                                       const u8 *src, unsigned int slen,\n                                       u8 *dst, unsigned int *dlen)\n{\n\treturn crypto_comp_crt(tfm)->cot_compress(crypto_comp_tfm(tfm),\n\t\t\t\t\t\t  src, slen, dst, dlen);\n}\n\nstatic inline int crypto_comp_decompress(struct crypto_comp *tfm,\n                                         const u8 *src, unsigned int slen,\n                                         u8 *dst, unsigned int *dlen)\n{\n\treturn crypto_comp_crt(tfm)->cot_decompress(crypto_comp_tfm(tfm),\n\t\t\t\t\t\t    src, slen, dst, dlen);\n}\n\n#endif\t/* _LINUX_CRYPTO_H */\n\n"], "fixing_code": ["/*\n * Glue Code for the asm optimized version of the AES Cipher Algorithm\n */\n\n#include <linux/module.h>\n#include <linux/crypto.h>\n#include <crypto/aes.h>\n\n#include \"aes_glue.h\"\n\nEXPORT_SYMBOL(AES_encrypt);\nEXPORT_SYMBOL(AES_decrypt);\nEXPORT_SYMBOL(private_AES_set_encrypt_key);\nEXPORT_SYMBOL(private_AES_set_decrypt_key);\n\nstatic void aes_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct AES_CTX *ctx = crypto_tfm_ctx(tfm);\n\tAES_encrypt(src, dst, &ctx->enc_key);\n}\n\nstatic void aes_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct AES_CTX *ctx = crypto_tfm_ctx(tfm);\n\tAES_decrypt(src, dst, &ctx->dec_key);\n}\n\nstatic int aes_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\tunsigned int key_len)\n{\n\tstruct AES_CTX *ctx = crypto_tfm_ctx(tfm);\n\n\tswitch (key_len) {\n\tcase AES_KEYSIZE_128:\n\t\tkey_len = 128;\n\t\tbreak;\n\tcase AES_KEYSIZE_192:\n\t\tkey_len = 192;\n\t\tbreak;\n\tcase AES_KEYSIZE_256:\n\t\tkey_len = 256;\n\t\tbreak;\n\tdefault:\n\t\ttfm->crt_flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\tif (private_AES_set_encrypt_key(in_key, key_len, &ctx->enc_key) == -1) {\n\t\ttfm->crt_flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\t/* private_AES_set_decrypt_key expects an encryption key as input */\n\tctx->dec_key = ctx->enc_key;\n\tif (private_AES_set_decrypt_key(in_key, key_len, &ctx->dec_key) == -1) {\n\t\ttfm->crt_flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\nstatic struct crypto_alg aes_alg = {\n\t.cra_name\t\t= \"aes\",\n\t.cra_driver_name\t= \"aes-asm\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct AES_CTX),\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(aes_alg.cra_list),\n\t.cra_u\t= {\n\t\t.cipher\t= {\n\t\t\t.cia_min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t= aes_set_key,\n\t\t\t.cia_encrypt\t\t= aes_encrypt,\n\t\t\t.cia_decrypt\t\t= aes_decrypt\n\t\t}\n\t}\n};\n\nstatic int __init aes_init(void)\n{\n\treturn crypto_register_alg(&aes_alg);\n}\n\nstatic void __exit aes_fini(void)\n{\n\tcrypto_unregister_alg(&aes_alg);\n}\n\nmodule_init(aes_init);\nmodule_exit(aes_fini);\n\nMODULE_DESCRIPTION(\"Rijndael (AES) Cipher Algorithm (ASM)\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_CRYPTO(\"aes\");\nMODULE_ALIAS_CRYPTO(\"aes-asm\");\nMODULE_AUTHOR(\"David McCullough <ucdevel@gmail.com>\");\n", "/*\n * Cryptographic API.\n * Glue code for the SHA1 Secure Hash Algorithm assembler implementation\n *\n * This file is based on sha1_generic.c and sha1_ssse3_glue.c\n *\n * Copyright (c) Alan Smithee.\n * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n * Copyright (c) Jean-Francois Dive <jef@linuxbe.org>\n * Copyright (c) Mathias Krause <minipli@googlemail.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n#include <asm/byteorder.h>\n#include <asm/crypto/sha1.h>\n\n\nasmlinkage void sha1_block_data_order(u32 *digest,\n\t\tconst unsigned char *data, unsigned int rounds);\n\n\nstatic int sha1_init(struct shash_desc *desc)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\t*sctx = (struct sha1_state){\n\t\t.state = { SHA1_H0, SHA1_H1, SHA1_H2, SHA1_H3, SHA1_H4 },\n\t};\n\n\treturn 0;\n}\n\n\nstatic int __sha1_update(struct sha1_state *sctx, const u8 *data,\n\t\t\t unsigned int len, unsigned int partial)\n{\n\tunsigned int done = 0;\n\n\tsctx->count += len;\n\n\tif (partial) {\n\t\tdone = SHA1_BLOCK_SIZE - partial;\n\t\tmemcpy(sctx->buffer + partial, data, done);\n\t\tsha1_block_data_order(sctx->state, sctx->buffer, 1);\n\t}\n\n\tif (len - done >= SHA1_BLOCK_SIZE) {\n\t\tconst unsigned int rounds = (len - done) / SHA1_BLOCK_SIZE;\n\t\tsha1_block_data_order(sctx->state, data + done, rounds);\n\t\tdone += rounds * SHA1_BLOCK_SIZE;\n\t}\n\n\tmemcpy(sctx->buffer, data + done, len - done);\n\treturn 0;\n}\n\n\nint sha1_update_arm(struct shash_desc *desc, const u8 *data,\n\t\t    unsigned int len)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial = sctx->count % SHA1_BLOCK_SIZE;\n\tint res;\n\n\t/* Handle the fast case right here */\n\tif (partial + len < SHA1_BLOCK_SIZE) {\n\t\tsctx->count += len;\n\t\tmemcpy(sctx->buffer + partial, data, len);\n\t\treturn 0;\n\t}\n\tres = __sha1_update(sctx, data, len, partial);\n\treturn res;\n}\nEXPORT_SYMBOL_GPL(sha1_update_arm);\n\n\n/* Add padding and return the message digest. */\nstatic int sha1_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int i, index, padlen;\n\t__be32 *dst = (__be32 *)out;\n\t__be64 bits;\n\tstatic const u8 padding[SHA1_BLOCK_SIZE] = { 0x80, };\n\n\tbits = cpu_to_be64(sctx->count << 3);\n\n\t/* Pad out to 56 mod 64 and append length */\n\tindex = sctx->count % SHA1_BLOCK_SIZE;\n\tpadlen = (index < 56) ? (56 - index) : ((SHA1_BLOCK_SIZE+56) - index);\n\t/* We need to fill a whole block for __sha1_update() */\n\tif (padlen <= 56) {\n\t\tsctx->count += padlen;\n\t\tmemcpy(sctx->buffer + index, padding, padlen);\n\t} else {\n\t\t__sha1_update(sctx, padding, padlen, index);\n\t}\n\t__sha1_update(sctx, (const u8 *)&bits, sizeof(bits), 56);\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 5; i++)\n\t\tdst[i] = cpu_to_be32(sctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof(*sctx));\n\treturn 0;\n}\n\n\nstatic int sha1_export(struct shash_desc *desc, void *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tmemcpy(out, sctx, sizeof(*sctx));\n\treturn 0;\n}\n\n\nstatic int sha1_import(struct shash_desc *desc, const void *in)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tmemcpy(sctx, in, sizeof(*sctx));\n\treturn 0;\n}\n\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tSHA1_DIGEST_SIZE,\n\t.init\t\t=\tsha1_init,\n\t.update\t\t=\tsha1_update_arm,\n\t.final\t\t=\tsha1_final,\n\t.export\t\t=\tsha1_export,\n\t.import\t\t=\tsha1_import,\n\t.descsize\t=\tsizeof(struct sha1_state),\n\t.statesize\t=\tsizeof(struct sha1_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha1\",\n\t\t.cra_driver_name=\t\"sha1-asm\",\n\t\t.cra_priority\t=\t150,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA1_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\n\nstatic int __init sha1_mod_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\n\nstatic void __exit sha1_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\n\nmodule_init(sha1_mod_init);\nmodule_exit(sha1_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA1 Secure Hash Algorithm (ARM)\");\nMODULE_ALIAS_CRYPTO(\"sha1\");\nMODULE_AUTHOR(\"David McCullough <ucdevel@gmail.com>\");\n", "/*\n * Glue code for the SHA1 Secure Hash Algorithm assembler implementation using\n * ARM NEON instructions.\n *\n * Copyright \u00a9 2014 Jussi Kivilinna <jussi.kivilinna@iki.fi>\n *\n * This file is based on sha1_generic.c and sha1_ssse3_glue.c:\n *  Copyright (c) Alan Smithee.\n *  Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n *  Copyright (c) Jean-Francois Dive <jef@linuxbe.org>\n *  Copyright (c) Mathias Krause <minipli@googlemail.com>\n *  Copyright (c) Chandramouli Narayanan <mouli@linux.intel.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n#include <asm/byteorder.h>\n#include <asm/neon.h>\n#include <asm/simd.h>\n#include <asm/crypto/sha1.h>\n\n\nasmlinkage void sha1_transform_neon(void *state_h, const char *data,\n\t\t\t\t    unsigned int rounds);\n\n\nstatic int sha1_neon_init(struct shash_desc *desc)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\t*sctx = (struct sha1_state){\n\t\t.state = { SHA1_H0, SHA1_H1, SHA1_H2, SHA1_H3, SHA1_H4 },\n\t};\n\n\treturn 0;\n}\n\nstatic int __sha1_neon_update(struct shash_desc *desc, const u8 *data,\n\t\t\t       unsigned int len, unsigned int partial)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int done = 0;\n\n\tsctx->count += len;\n\n\tif (partial) {\n\t\tdone = SHA1_BLOCK_SIZE - partial;\n\t\tmemcpy(sctx->buffer + partial, data, done);\n\t\tsha1_transform_neon(sctx->state, sctx->buffer, 1);\n\t}\n\n\tif (len - done >= SHA1_BLOCK_SIZE) {\n\t\tconst unsigned int rounds = (len - done) / SHA1_BLOCK_SIZE;\n\n\t\tsha1_transform_neon(sctx->state, data + done, rounds);\n\t\tdone += rounds * SHA1_BLOCK_SIZE;\n\t}\n\n\tmemcpy(sctx->buffer, data + done, len - done);\n\n\treturn 0;\n}\n\nstatic int sha1_neon_update(struct shash_desc *desc, const u8 *data,\n\t\t\t     unsigned int len)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial = sctx->count % SHA1_BLOCK_SIZE;\n\tint res;\n\n\t/* Handle the fast case right here */\n\tif (partial + len < SHA1_BLOCK_SIZE) {\n\t\tsctx->count += len;\n\t\tmemcpy(sctx->buffer + partial, data, len);\n\n\t\treturn 0;\n\t}\n\n\tif (!may_use_simd()) {\n\t\tres = sha1_update_arm(desc, data, len);\n\t} else {\n\t\tkernel_neon_begin();\n\t\tres = __sha1_neon_update(desc, data, len, partial);\n\t\tkernel_neon_end();\n\t}\n\n\treturn res;\n}\n\n\n/* Add padding and return the message digest. */\nstatic int sha1_neon_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int i, index, padlen;\n\t__be32 *dst = (__be32 *)out;\n\t__be64 bits;\n\tstatic const u8 padding[SHA1_BLOCK_SIZE] = { 0x80, };\n\n\tbits = cpu_to_be64(sctx->count << 3);\n\n\t/* Pad out to 56 mod 64 and append length */\n\tindex = sctx->count % SHA1_BLOCK_SIZE;\n\tpadlen = (index < 56) ? (56 - index) : ((SHA1_BLOCK_SIZE+56) - index);\n\tif (!may_use_simd()) {\n\t\tsha1_update_arm(desc, padding, padlen);\n\t\tsha1_update_arm(desc, (const u8 *)&bits, sizeof(bits));\n\t} else {\n\t\tkernel_neon_begin();\n\t\t/* We need to fill a whole block for __sha1_neon_update() */\n\t\tif (padlen <= 56) {\n\t\t\tsctx->count += padlen;\n\t\t\tmemcpy(sctx->buffer + index, padding, padlen);\n\t\t} else {\n\t\t\t__sha1_neon_update(desc, padding, padlen, index);\n\t\t}\n\t\t__sha1_neon_update(desc, (const u8 *)&bits, sizeof(bits), 56);\n\t\tkernel_neon_end();\n\t}\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 5; i++)\n\t\tdst[i] = cpu_to_be32(sctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha1_neon_export(struct shash_desc *desc, void *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha1_neon_import(struct shash_desc *desc, const void *in)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tSHA1_DIGEST_SIZE,\n\t.init\t\t=\tsha1_neon_init,\n\t.update\t\t=\tsha1_neon_update,\n\t.final\t\t=\tsha1_neon_final,\n\t.export\t\t=\tsha1_neon_export,\n\t.import\t\t=\tsha1_neon_import,\n\t.descsize\t=\tsizeof(struct sha1_state),\n\t.statesize\t=\tsizeof(struct sha1_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t\t= \"sha1\",\n\t\t.cra_driver_name\t= \"sha1-neon\",\n\t\t.cra_priority\t\t= 250,\n\t\t.cra_flags\t\t= CRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t\t= SHA1_BLOCK_SIZE,\n\t\t.cra_module\t\t= THIS_MODULE,\n\t}\n};\n\nstatic int __init sha1_neon_mod_init(void)\n{\n\tif (!cpu_has_neon())\n\t\treturn -ENODEV;\n\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit sha1_neon_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(sha1_neon_mod_init);\nmodule_exit(sha1_neon_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA1 Secure Hash Algorithm, NEON accelerated\");\nMODULE_ALIAS_CRYPTO(\"sha1\");\n", "/*\n * Glue code for the SHA512 Secure Hash Algorithm assembly implementation\n * using NEON instructions.\n *\n * Copyright \u00a9 2014 Jussi Kivilinna <jussi.kivilinna@iki.fi>\n *\n * This file is based on sha512_ssse3_glue.c:\n *   Copyright (C) 2013 Intel Corporation\n *   Author: Tim Chen <tim.c.chen@linux.intel.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <linux/string.h>\n#include <crypto/sha.h>\n#include <asm/byteorder.h>\n#include <asm/simd.h>\n#include <asm/neon.h>\n\n\nstatic const u64 sha512_k[] = {\n\t0x428a2f98d728ae22ULL, 0x7137449123ef65cdULL,\n\t0xb5c0fbcfec4d3b2fULL, 0xe9b5dba58189dbbcULL,\n\t0x3956c25bf348b538ULL, 0x59f111f1b605d019ULL,\n\t0x923f82a4af194f9bULL, 0xab1c5ed5da6d8118ULL,\n\t0xd807aa98a3030242ULL, 0x12835b0145706fbeULL,\n\t0x243185be4ee4b28cULL, 0x550c7dc3d5ffb4e2ULL,\n\t0x72be5d74f27b896fULL, 0x80deb1fe3b1696b1ULL,\n\t0x9bdc06a725c71235ULL, 0xc19bf174cf692694ULL,\n\t0xe49b69c19ef14ad2ULL, 0xefbe4786384f25e3ULL,\n\t0x0fc19dc68b8cd5b5ULL, 0x240ca1cc77ac9c65ULL,\n\t0x2de92c6f592b0275ULL, 0x4a7484aa6ea6e483ULL,\n\t0x5cb0a9dcbd41fbd4ULL, 0x76f988da831153b5ULL,\n\t0x983e5152ee66dfabULL, 0xa831c66d2db43210ULL,\n\t0xb00327c898fb213fULL, 0xbf597fc7beef0ee4ULL,\n\t0xc6e00bf33da88fc2ULL, 0xd5a79147930aa725ULL,\n\t0x06ca6351e003826fULL, 0x142929670a0e6e70ULL,\n\t0x27b70a8546d22ffcULL, 0x2e1b21385c26c926ULL,\n\t0x4d2c6dfc5ac42aedULL, 0x53380d139d95b3dfULL,\n\t0x650a73548baf63deULL, 0x766a0abb3c77b2a8ULL,\n\t0x81c2c92e47edaee6ULL, 0x92722c851482353bULL,\n\t0xa2bfe8a14cf10364ULL, 0xa81a664bbc423001ULL,\n\t0xc24b8b70d0f89791ULL, 0xc76c51a30654be30ULL,\n\t0xd192e819d6ef5218ULL, 0xd69906245565a910ULL,\n\t0xf40e35855771202aULL, 0x106aa07032bbd1b8ULL,\n\t0x19a4c116b8d2d0c8ULL, 0x1e376c085141ab53ULL,\n\t0x2748774cdf8eeb99ULL, 0x34b0bcb5e19b48a8ULL,\n\t0x391c0cb3c5c95a63ULL, 0x4ed8aa4ae3418acbULL,\n\t0x5b9cca4f7763e373ULL, 0x682e6ff3d6b2b8a3ULL,\n\t0x748f82ee5defb2fcULL, 0x78a5636f43172f60ULL,\n\t0x84c87814a1f0ab72ULL, 0x8cc702081a6439ecULL,\n\t0x90befffa23631e28ULL, 0xa4506cebde82bde9ULL,\n\t0xbef9a3f7b2c67915ULL, 0xc67178f2e372532bULL,\n\t0xca273eceea26619cULL, 0xd186b8c721c0c207ULL,\n\t0xeada7dd6cde0eb1eULL, 0xf57d4f7fee6ed178ULL,\n\t0x06f067aa72176fbaULL, 0x0a637dc5a2c898a6ULL,\n\t0x113f9804bef90daeULL, 0x1b710b35131c471bULL,\n\t0x28db77f523047d84ULL, 0x32caab7b40c72493ULL,\n\t0x3c9ebe0a15c9bebcULL, 0x431d67c49c100d4cULL,\n\t0x4cc5d4becb3e42b6ULL, 0x597f299cfc657e2aULL,\n\t0x5fcb6fab3ad6faecULL, 0x6c44198c4a475817ULL\n};\n\n\nasmlinkage void sha512_transform_neon(u64 *digest, const void *data,\n\t\t\t\t      const u64 k[], unsigned int num_blks);\n\n\nstatic int sha512_neon_init(struct shash_desc *desc)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\n\tsctx->state[0] = SHA512_H0;\n\tsctx->state[1] = SHA512_H1;\n\tsctx->state[2] = SHA512_H2;\n\tsctx->state[3] = SHA512_H3;\n\tsctx->state[4] = SHA512_H4;\n\tsctx->state[5] = SHA512_H5;\n\tsctx->state[6] = SHA512_H6;\n\tsctx->state[7] = SHA512_H7;\n\tsctx->count[0] = sctx->count[1] = 0;\n\n\treturn 0;\n}\n\nstatic int __sha512_neon_update(struct shash_desc *desc, const u8 *data,\n\t\t\t\tunsigned int len, unsigned int partial)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tunsigned int done = 0;\n\n\tsctx->count[0] += len;\n\tif (sctx->count[0] < len)\n\t\tsctx->count[1]++;\n\n\tif (partial) {\n\t\tdone = SHA512_BLOCK_SIZE - partial;\n\t\tmemcpy(sctx->buf + partial, data, done);\n\t\tsha512_transform_neon(sctx->state, sctx->buf, sha512_k, 1);\n\t}\n\n\tif (len - done >= SHA512_BLOCK_SIZE) {\n\t\tconst unsigned int rounds = (len - done) / SHA512_BLOCK_SIZE;\n\n\t\tsha512_transform_neon(sctx->state, data + done, sha512_k,\n\t\t\t\t      rounds);\n\n\t\tdone += rounds * SHA512_BLOCK_SIZE;\n\t}\n\n\tmemcpy(sctx->buf, data + done, len - done);\n\n\treturn 0;\n}\n\nstatic int sha512_neon_update(struct shash_desc *desc, const u8 *data,\n\t\t\t     unsigned int len)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial = sctx->count[0] % SHA512_BLOCK_SIZE;\n\tint res;\n\n\t/* Handle the fast case right here */\n\tif (partial + len < SHA512_BLOCK_SIZE) {\n\t\tsctx->count[0] += len;\n\t\tif (sctx->count[0] < len)\n\t\t\tsctx->count[1]++;\n\t\tmemcpy(sctx->buf + partial, data, len);\n\n\t\treturn 0;\n\t}\n\n\tif (!may_use_simd()) {\n\t\tres = crypto_sha512_update(desc, data, len);\n\t} else {\n\t\tkernel_neon_begin();\n\t\tres = __sha512_neon_update(desc, data, len, partial);\n\t\tkernel_neon_end();\n\t}\n\n\treturn res;\n}\n\n\n/* Add padding and return the message digest. */\nstatic int sha512_neon_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tunsigned int i, index, padlen;\n\t__be64 *dst = (__be64 *)out;\n\t__be64 bits[2];\n\tstatic const u8 padding[SHA512_BLOCK_SIZE] = { 0x80, };\n\n\t/* save number of bits */\n\tbits[1] = cpu_to_be64(sctx->count[0] << 3);\n\tbits[0] = cpu_to_be64(sctx->count[1] << 3 | sctx->count[0] >> 61);\n\n\t/* Pad out to 112 mod 128 and append length */\n\tindex = sctx->count[0] & 0x7f;\n\tpadlen = (index < 112) ? (112 - index) : ((128+112) - index);\n\n\tif (!may_use_simd()) {\n\t\tcrypto_sha512_update(desc, padding, padlen);\n\t\tcrypto_sha512_update(desc, (const u8 *)&bits, sizeof(bits));\n\t} else {\n\t\tkernel_neon_begin();\n\t\t/* We need to fill a whole block for __sha512_neon_update() */\n\t\tif (padlen <= 112) {\n\t\t\tsctx->count[0] += padlen;\n\t\t\tif (sctx->count[0] < padlen)\n\t\t\t\tsctx->count[1]++;\n\t\t\tmemcpy(sctx->buf + index, padding, padlen);\n\t\t} else {\n\t\t\t__sha512_neon_update(desc, padding, padlen, index);\n\t\t}\n\t\t__sha512_neon_update(desc, (const u8 *)&bits,\n\t\t\t\t\tsizeof(bits), 112);\n\t\tkernel_neon_end();\n\t}\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 8; i++)\n\t\tdst[i] = cpu_to_be64(sctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha512_neon_export(struct shash_desc *desc, void *out)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha512_neon_import(struct shash_desc *desc, const void *in)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha384_neon_init(struct shash_desc *desc)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\n\tsctx->state[0] = SHA384_H0;\n\tsctx->state[1] = SHA384_H1;\n\tsctx->state[2] = SHA384_H2;\n\tsctx->state[3] = SHA384_H3;\n\tsctx->state[4] = SHA384_H4;\n\tsctx->state[5] = SHA384_H5;\n\tsctx->state[6] = SHA384_H6;\n\tsctx->state[7] = SHA384_H7;\n\n\tsctx->count[0] = sctx->count[1] = 0;\n\n\treturn 0;\n}\n\nstatic int sha384_neon_final(struct shash_desc *desc, u8 *hash)\n{\n\tu8 D[SHA512_DIGEST_SIZE];\n\n\tsha512_neon_final(desc, D);\n\n\tmemcpy(hash, D, SHA384_DIGEST_SIZE);\n\tmemset(D, 0, SHA512_DIGEST_SIZE);\n\n\treturn 0;\n}\n\nstatic struct shash_alg algs[] = { {\n\t.digestsize\t=\tSHA512_DIGEST_SIZE,\n\t.init\t\t=\tsha512_neon_init,\n\t.update\t\t=\tsha512_neon_update,\n\t.final\t\t=\tsha512_neon_final,\n\t.export\t\t=\tsha512_neon_export,\n\t.import\t\t=\tsha512_neon_import,\n\t.descsize\t=\tsizeof(struct sha512_state),\n\t.statesize\t=\tsizeof(struct sha512_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha512\",\n\t\t.cra_driver_name =\t\"sha512-neon\",\n\t\t.cra_priority\t=\t250,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA512_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n},  {\n\t.digestsize\t=\tSHA384_DIGEST_SIZE,\n\t.init\t\t=\tsha384_neon_init,\n\t.update\t\t=\tsha512_neon_update,\n\t.final\t\t=\tsha384_neon_final,\n\t.export\t\t=\tsha512_neon_export,\n\t.import\t\t=\tsha512_neon_import,\n\t.descsize\t=\tsizeof(struct sha512_state),\n\t.statesize\t=\tsizeof(struct sha512_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha384\",\n\t\t.cra_driver_name =\t\"sha384-neon\",\n\t\t.cra_priority\t=\t250,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA384_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n} };\n\nstatic int __init sha512_neon_mod_init(void)\n{\n\tif (!cpu_has_neon())\n\t\treturn -ENODEV;\n\n\treturn crypto_register_shashes(algs, ARRAY_SIZE(algs));\n}\n\nstatic void __exit sha512_neon_mod_fini(void)\n{\n\tcrypto_unregister_shashes(algs, ARRAY_SIZE(algs));\n}\n\nmodule_init(sha512_neon_mod_init);\nmodule_exit(sha512_neon_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA512 Secure Hash Algorithm, NEON accelerated\");\n\nMODULE_ALIAS_CRYPTO(\"sha512\");\nMODULE_ALIAS_CRYPTO(\"sha384\");\n", "/*\n * aes-ccm-glue.c - AES-CCM transform for ARMv8 with Crypto Extensions\n *\n * Copyright (C) 2013 - 2014 Linaro Ltd <ard.biesheuvel@linaro.org>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License version 2 as\n * published by the Free Software Foundation.\n */\n\n#include <asm/neon.h>\n#include <asm/unaligned.h>\n#include <crypto/aes.h>\n#include <crypto/algapi.h>\n#include <crypto/scatterwalk.h>\n#include <linux/crypto.h>\n#include <linux/module.h>\n\nstatic int num_rounds(struct crypto_aes_ctx *ctx)\n{\n\t/*\n\t * # of rounds specified by AES:\n\t * 128 bit key\t\t10 rounds\n\t * 192 bit key\t\t12 rounds\n\t * 256 bit key\t\t14 rounds\n\t * => n byte key\t=> 6 + (n/4) rounds\n\t */\n\treturn 6 + ctx->key_length / 4;\n}\n\nasmlinkage void ce_aes_ccm_auth_data(u8 mac[], u8 const in[], u32 abytes,\n\t\t\t\t     u32 *macp, u32 const rk[], u32 rounds);\n\nasmlinkage void ce_aes_ccm_encrypt(u8 out[], u8 const in[], u32 cbytes,\n\t\t\t\t   u32 const rk[], u32 rounds, u8 mac[],\n\t\t\t\t   u8 ctr[]);\n\nasmlinkage void ce_aes_ccm_decrypt(u8 out[], u8 const in[], u32 cbytes,\n\t\t\t\t   u32 const rk[], u32 rounds, u8 mac[],\n\t\t\t\t   u8 ctr[]);\n\nasmlinkage void ce_aes_ccm_final(u8 mac[], u8 const ctr[], u32 const rk[],\n\t\t\t\t u32 rounds);\n\nstatic int ccm_setkey(struct crypto_aead *tfm, const u8 *in_key,\n\t\t      unsigned int key_len)\n{\n\tstruct crypto_aes_ctx *ctx = crypto_aead_ctx(tfm);\n\tint ret;\n\n\tret = crypto_aes_expand_key(ctx, in_key, key_len);\n\tif (!ret)\n\t\treturn 0;\n\n\ttfm->base.crt_flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\treturn -EINVAL;\n}\n\nstatic int ccm_setauthsize(struct crypto_aead *tfm, unsigned int authsize)\n{\n\tif ((authsize & 1) || authsize < 4)\n\t\treturn -EINVAL;\n\treturn 0;\n}\n\nstatic int ccm_init_mac(struct aead_request *req, u8 maciv[], u32 msglen)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\t__be32 *n = (__be32 *)&maciv[AES_BLOCK_SIZE - 8];\n\tu32 l = req->iv[0] + 1;\n\n\t/* verify that CCM dimension 'L' is set correctly in the IV */\n\tif (l < 2 || l > 8)\n\t\treturn -EINVAL;\n\n\t/* verify that msglen can in fact be represented in L bytes */\n\tif (l < 4 && msglen >> (8 * l))\n\t\treturn -EOVERFLOW;\n\n\t/*\n\t * Even if the CCM spec allows L values of up to 8, the Linux cryptoapi\n\t * uses a u32 type to represent msglen so the top 4 bytes are always 0.\n\t */\n\tn[0] = 0;\n\tn[1] = cpu_to_be32(msglen);\n\n\tmemcpy(maciv, req->iv, AES_BLOCK_SIZE - l);\n\n\t/*\n\t * Meaning of byte 0 according to CCM spec (RFC 3610/NIST 800-38C)\n\t * - bits 0..2\t: max # of bytes required to represent msglen, minus 1\n\t *                (already set by caller)\n\t * - bits 3..5\t: size of auth tag (1 => 4 bytes, 2 => 6 bytes, etc)\n\t * - bit 6\t: indicates presence of authenticate-only data\n\t */\n\tmaciv[0] |= (crypto_aead_authsize(aead) - 2) << 2;\n\tif (req->assoclen)\n\t\tmaciv[0] |= 0x40;\n\n\tmemset(&req->iv[AES_BLOCK_SIZE - l], 0, l);\n\treturn 0;\n}\n\nstatic void ccm_calculate_auth_mac(struct aead_request *req, u8 mac[])\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_aes_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct __packed { __be16 l; __be32 h; u16 len; } ltag;\n\tstruct scatter_walk walk;\n\tu32 len = req->assoclen;\n\tu32 macp = 0;\n\n\t/* prepend the AAD with a length tag */\n\tif (len < 0xff00) {\n\t\tltag.l = cpu_to_be16(len);\n\t\tltag.len = 2;\n\t} else  {\n\t\tltag.l = cpu_to_be16(0xfffe);\n\t\tput_unaligned_be32(len, &ltag.h);\n\t\tltag.len = 6;\n\t}\n\n\tce_aes_ccm_auth_data(mac, (u8 *)&ltag, ltag.len, &macp, ctx->key_enc,\n\t\t\t     num_rounds(ctx));\n\tscatterwalk_start(&walk, req->assoc);\n\n\tdo {\n\t\tu32 n = scatterwalk_clamp(&walk, len);\n\t\tu8 *p;\n\n\t\tif (!n) {\n\t\t\tscatterwalk_start(&walk, sg_next(walk.sg));\n\t\t\tn = scatterwalk_clamp(&walk, len);\n\t\t}\n\t\tp = scatterwalk_map(&walk);\n\t\tce_aes_ccm_auth_data(mac, p, n, &macp, ctx->key_enc,\n\t\t\t\t     num_rounds(ctx));\n\t\tlen -= n;\n\n\t\tscatterwalk_unmap(p);\n\t\tscatterwalk_advance(&walk, n);\n\t\tscatterwalk_done(&walk, 0, len);\n\t} while (len);\n}\n\nstatic int ccm_encrypt(struct aead_request *req)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_aes_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct blkcipher_desc desc = { .info = req->iv };\n\tstruct blkcipher_walk walk;\n\tu8 __aligned(8) mac[AES_BLOCK_SIZE];\n\tu8 buf[AES_BLOCK_SIZE];\n\tu32 len = req->cryptlen;\n\tint err;\n\n\terr = ccm_init_mac(req, mac, len);\n\tif (err)\n\t\treturn err;\n\n\tkernel_neon_begin_partial(6);\n\n\tif (req->assoclen)\n\t\tccm_calculate_auth_mac(req, mac);\n\n\t/* preserve the original iv for the final round */\n\tmemcpy(buf, req->iv, AES_BLOCK_SIZE);\n\n\tblkcipher_walk_init(&walk, req->dst, req->src, len);\n\terr = blkcipher_aead_walk_virt_block(&desc, &walk, aead,\n\t\t\t\t\t     AES_BLOCK_SIZE);\n\n\twhile (walk.nbytes) {\n\t\tu32 tail = walk.nbytes % AES_BLOCK_SIZE;\n\n\t\tif (walk.nbytes == len)\n\t\t\ttail = 0;\n\n\t\tce_aes_ccm_encrypt(walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t\t   walk.nbytes - tail, ctx->key_enc,\n\t\t\t\t   num_rounds(ctx), mac, walk.iv);\n\n\t\tlen -= walk.nbytes - tail;\n\t\terr = blkcipher_walk_done(&desc, &walk, tail);\n\t}\n\tif (!err)\n\t\tce_aes_ccm_final(mac, buf, ctx->key_enc, num_rounds(ctx));\n\n\tkernel_neon_end();\n\n\tif (err)\n\t\treturn err;\n\n\t/* copy authtag to end of dst */\n\tscatterwalk_map_and_copy(mac, req->dst, req->cryptlen,\n\t\t\t\t crypto_aead_authsize(aead), 1);\n\n\treturn 0;\n}\n\nstatic int ccm_decrypt(struct aead_request *req)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_aes_ctx *ctx = crypto_aead_ctx(aead);\n\tunsigned int authsize = crypto_aead_authsize(aead);\n\tstruct blkcipher_desc desc = { .info = req->iv };\n\tstruct blkcipher_walk walk;\n\tu8 __aligned(8) mac[AES_BLOCK_SIZE];\n\tu8 buf[AES_BLOCK_SIZE];\n\tu32 len = req->cryptlen - authsize;\n\tint err;\n\n\terr = ccm_init_mac(req, mac, len);\n\tif (err)\n\t\treturn err;\n\n\tkernel_neon_begin_partial(6);\n\n\tif (req->assoclen)\n\t\tccm_calculate_auth_mac(req, mac);\n\n\t/* preserve the original iv for the final round */\n\tmemcpy(buf, req->iv, AES_BLOCK_SIZE);\n\n\tblkcipher_walk_init(&walk, req->dst, req->src, len);\n\terr = blkcipher_aead_walk_virt_block(&desc, &walk, aead,\n\t\t\t\t\t     AES_BLOCK_SIZE);\n\n\twhile (walk.nbytes) {\n\t\tu32 tail = walk.nbytes % AES_BLOCK_SIZE;\n\n\t\tif (walk.nbytes == len)\n\t\t\ttail = 0;\n\n\t\tce_aes_ccm_decrypt(walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t\t   walk.nbytes - tail, ctx->key_enc,\n\t\t\t\t   num_rounds(ctx), mac, walk.iv);\n\n\t\tlen -= walk.nbytes - tail;\n\t\terr = blkcipher_walk_done(&desc, &walk, tail);\n\t}\n\tif (!err)\n\t\tce_aes_ccm_final(mac, buf, ctx->key_enc, num_rounds(ctx));\n\n\tkernel_neon_end();\n\n\tif (err)\n\t\treturn err;\n\n\t/* compare calculated auth tag with the stored one */\n\tscatterwalk_map_and_copy(buf, req->src, req->cryptlen - authsize,\n\t\t\t\t authsize, 0);\n\n\tif (memcmp(mac, buf, authsize))\n\t\treturn -EBADMSG;\n\treturn 0;\n}\n\nstatic struct crypto_alg ccm_aes_alg = {\n\t.cra_name\t\t= \"ccm(aes)\",\n\t.cra_driver_name\t= \"ccm-aes-ce\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_AEAD,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_aes_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_aead_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_aead = {\n\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t.maxauthsize\t= AES_BLOCK_SIZE,\n\t\t.setkey\t\t= ccm_setkey,\n\t\t.setauthsize\t= ccm_setauthsize,\n\t\t.encrypt\t= ccm_encrypt,\n\t\t.decrypt\t= ccm_decrypt,\n\t}\n};\n\nstatic int __init aes_mod_init(void)\n{\n\tif (!(elf_hwcap & HWCAP_AES))\n\t\treturn -ENODEV;\n\treturn crypto_register_alg(&ccm_aes_alg);\n}\n\nstatic void __exit aes_mod_exit(void)\n{\n\tcrypto_unregister_alg(&ccm_aes_alg);\n}\n\nmodule_init(aes_mod_init);\nmodule_exit(aes_mod_exit);\n\nMODULE_DESCRIPTION(\"Synchronous AES in CCM mode using ARMv8 Crypto Extensions\");\nMODULE_AUTHOR(\"Ard Biesheuvel <ard.biesheuvel@linaro.org>\");\nMODULE_LICENSE(\"GPL v2\");\nMODULE_ALIAS_CRYPTO(\"ccm(aes)\");\n", "/*\n * linux/arch/arm64/crypto/aes-glue.c - wrapper code for ARMv8 AES\n *\n * Copyright (C) 2013 Linaro Ltd <ard.biesheuvel@linaro.org>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License version 2 as\n * published by the Free Software Foundation.\n */\n\n#include <asm/neon.h>\n#include <asm/hwcap.h>\n#include <crypto/aes.h>\n#include <crypto/ablk_helper.h>\n#include <crypto/algapi.h>\n#include <linux/module.h>\n#include <linux/cpufeature.h>\n\n#ifdef USE_V8_CRYPTO_EXTENSIONS\n#define MODE\t\t\t\"ce\"\n#define PRIO\t\t\t300\n#define aes_ecb_encrypt\t\tce_aes_ecb_encrypt\n#define aes_ecb_decrypt\t\tce_aes_ecb_decrypt\n#define aes_cbc_encrypt\t\tce_aes_cbc_encrypt\n#define aes_cbc_decrypt\t\tce_aes_cbc_decrypt\n#define aes_ctr_encrypt\t\tce_aes_ctr_encrypt\n#define aes_xts_encrypt\t\tce_aes_xts_encrypt\n#define aes_xts_decrypt\t\tce_aes_xts_decrypt\nMODULE_DESCRIPTION(\"AES-ECB/CBC/CTR/XTS using ARMv8 Crypto Extensions\");\n#else\n#define MODE\t\t\t\"neon\"\n#define PRIO\t\t\t200\n#define aes_ecb_encrypt\t\tneon_aes_ecb_encrypt\n#define aes_ecb_decrypt\t\tneon_aes_ecb_decrypt\n#define aes_cbc_encrypt\t\tneon_aes_cbc_encrypt\n#define aes_cbc_decrypt\t\tneon_aes_cbc_decrypt\n#define aes_ctr_encrypt\t\tneon_aes_ctr_encrypt\n#define aes_xts_encrypt\t\tneon_aes_xts_encrypt\n#define aes_xts_decrypt\t\tneon_aes_xts_decrypt\nMODULE_DESCRIPTION(\"AES-ECB/CBC/CTR/XTS using ARMv8 NEON\");\nMODULE_ALIAS_CRYPTO(\"ecb(aes)\");\nMODULE_ALIAS_CRYPTO(\"cbc(aes)\");\nMODULE_ALIAS_CRYPTO(\"ctr(aes)\");\nMODULE_ALIAS_CRYPTO(\"xts(aes)\");\n#endif\n\nMODULE_AUTHOR(\"Ard Biesheuvel <ard.biesheuvel@linaro.org>\");\nMODULE_LICENSE(\"GPL v2\");\n\n/* defined in aes-modes.S */\nasmlinkage void aes_ecb_encrypt(u8 out[], u8 const in[], u8 const rk[],\n\t\t\t\tint rounds, int blocks, int first);\nasmlinkage void aes_ecb_decrypt(u8 out[], u8 const in[], u8 const rk[],\n\t\t\t\tint rounds, int blocks, int first);\n\nasmlinkage void aes_cbc_encrypt(u8 out[], u8 const in[], u8 const rk[],\n\t\t\t\tint rounds, int blocks, u8 iv[], int first);\nasmlinkage void aes_cbc_decrypt(u8 out[], u8 const in[], u8 const rk[],\n\t\t\t\tint rounds, int blocks, u8 iv[], int first);\n\nasmlinkage void aes_ctr_encrypt(u8 out[], u8 const in[], u8 const rk[],\n\t\t\t\tint rounds, int blocks, u8 ctr[], int first);\n\nasmlinkage void aes_xts_encrypt(u8 out[], u8 const in[], u8 const rk1[],\n\t\t\t\tint rounds, int blocks, u8 const rk2[], u8 iv[],\n\t\t\t\tint first);\nasmlinkage void aes_xts_decrypt(u8 out[], u8 const in[], u8 const rk1[],\n\t\t\t\tint rounds, int blocks, u8 const rk2[], u8 iv[],\n\t\t\t\tint first);\n\nstruct crypto_aes_xts_ctx {\n\tstruct crypto_aes_ctx key1;\n\tstruct crypto_aes_ctx __aligned(8) key2;\n};\n\nstatic int xts_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t       unsigned int key_len)\n{\n\tstruct crypto_aes_xts_ctx *ctx = crypto_tfm_ctx(tfm);\n\tint ret;\n\n\tret = crypto_aes_expand_key(&ctx->key1, in_key, key_len / 2);\n\tif (!ret)\n\t\tret = crypto_aes_expand_key(&ctx->key2, &in_key[key_len / 2],\n\t\t\t\t\t    key_len / 2);\n\tif (!ret)\n\t\treturn 0;\n\n\ttfm->crt_flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\treturn -EINVAL;\n}\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct crypto_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tint err, first, rounds = 6 + ctx->key_length / 4;\n\tstruct blkcipher_walk walk;\n\tunsigned int blocks;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\tkernel_neon_begin();\n\tfor (first = 1; (blocks = (walk.nbytes / AES_BLOCK_SIZE)); first = 0) {\n\t\taes_ecb_encrypt(walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t\t(u8 *)ctx->key_enc, rounds, blocks, first);\n\t\terr = blkcipher_walk_done(desc, &walk, walk.nbytes % AES_BLOCK_SIZE);\n\t}\n\tkernel_neon_end();\n\treturn err;\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct crypto_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tint err, first, rounds = 6 + ctx->key_length / 4;\n\tstruct blkcipher_walk walk;\n\tunsigned int blocks;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\tkernel_neon_begin();\n\tfor (first = 1; (blocks = (walk.nbytes / AES_BLOCK_SIZE)); first = 0) {\n\t\taes_ecb_decrypt(walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t\t(u8 *)ctx->key_dec, rounds, blocks, first);\n\t\terr = blkcipher_walk_done(desc, &walk, walk.nbytes % AES_BLOCK_SIZE);\n\t}\n\tkernel_neon_end();\n\treturn err;\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct crypto_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tint err, first, rounds = 6 + ctx->key_length / 4;\n\tstruct blkcipher_walk walk;\n\tunsigned int blocks;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\tkernel_neon_begin();\n\tfor (first = 1; (blocks = (walk.nbytes / AES_BLOCK_SIZE)); first = 0) {\n\t\taes_cbc_encrypt(walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t\t(u8 *)ctx->key_enc, rounds, blocks, walk.iv,\n\t\t\t\tfirst);\n\t\terr = blkcipher_walk_done(desc, &walk, walk.nbytes % AES_BLOCK_SIZE);\n\t}\n\tkernel_neon_end();\n\treturn err;\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct crypto_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tint err, first, rounds = 6 + ctx->key_length / 4;\n\tstruct blkcipher_walk walk;\n\tunsigned int blocks;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\tkernel_neon_begin();\n\tfor (first = 1; (blocks = (walk.nbytes / AES_BLOCK_SIZE)); first = 0) {\n\t\taes_cbc_decrypt(walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t\t(u8 *)ctx->key_dec, rounds, blocks, walk.iv,\n\t\t\t\tfirst);\n\t\terr = blkcipher_walk_done(desc, &walk, walk.nbytes % AES_BLOCK_SIZE);\n\t}\n\tkernel_neon_end();\n\treturn err;\n}\n\nstatic int ctr_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct crypto_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tint err, first, rounds = 6 + ctx->key_length / 4;\n\tstruct blkcipher_walk walk;\n\tint blocks;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt_block(desc, &walk, AES_BLOCK_SIZE);\n\n\tfirst = 1;\n\tkernel_neon_begin();\n\twhile ((blocks = (walk.nbytes / AES_BLOCK_SIZE))) {\n\t\taes_ctr_encrypt(walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t\t(u8 *)ctx->key_enc, rounds, blocks, walk.iv,\n\t\t\t\tfirst);\n\t\tfirst = 0;\n\t\tnbytes -= blocks * AES_BLOCK_SIZE;\n\t\tif (nbytes && nbytes == walk.nbytes % AES_BLOCK_SIZE)\n\t\t\tbreak;\n\t\terr = blkcipher_walk_done(desc, &walk,\n\t\t\t\t\t  walk.nbytes % AES_BLOCK_SIZE);\n\t}\n\tif (nbytes) {\n\t\tu8 *tdst = walk.dst.virt.addr + blocks * AES_BLOCK_SIZE;\n\t\tu8 *tsrc = walk.src.virt.addr + blocks * AES_BLOCK_SIZE;\n\t\tu8 __aligned(8) tail[AES_BLOCK_SIZE];\n\n\t\t/*\n\t\t * Minimum alignment is 8 bytes, so if nbytes is <= 8, we need\n\t\t * to tell aes_ctr_encrypt() to only read half a block.\n\t\t */\n\t\tblocks = (nbytes <= 8) ? -1 : 1;\n\n\t\taes_ctr_encrypt(tail, tsrc, (u8 *)ctx->key_enc, rounds,\n\t\t\t\tblocks, walk.iv, first);\n\t\tmemcpy(tdst, tail, nbytes);\n\t\terr = blkcipher_walk_done(desc, &walk, 0);\n\t}\n\tkernel_neon_end();\n\n\treturn err;\n}\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct crypto_aes_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tint err, first, rounds = 6 + ctx->key1.key_length / 4;\n\tstruct blkcipher_walk walk;\n\tunsigned int blocks;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\tkernel_neon_begin();\n\tfor (first = 1; (blocks = (walk.nbytes / AES_BLOCK_SIZE)); first = 0) {\n\t\taes_xts_encrypt(walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t\t(u8 *)ctx->key1.key_enc, rounds, blocks,\n\t\t\t\t(u8 *)ctx->key2.key_enc, walk.iv, first);\n\t\terr = blkcipher_walk_done(desc, &walk, walk.nbytes % AES_BLOCK_SIZE);\n\t}\n\tkernel_neon_end();\n\n\treturn err;\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct crypto_aes_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tint err, first, rounds = 6 + ctx->key1.key_length / 4;\n\tstruct blkcipher_walk walk;\n\tunsigned int blocks;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\tkernel_neon_begin();\n\tfor (first = 1; (blocks = (walk.nbytes / AES_BLOCK_SIZE)); first = 0) {\n\t\taes_xts_decrypt(walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t\t(u8 *)ctx->key1.key_dec, rounds, blocks,\n\t\t\t\t(u8 *)ctx->key2.key_enc, walk.iv, first);\n\t\terr = blkcipher_walk_done(desc, &walk, walk.nbytes % AES_BLOCK_SIZE);\n\t}\n\tkernel_neon_end();\n\n\treturn err;\n}\n\nstatic struct crypto_alg aes_algs[] = { {\n\t.cra_name\t\t= \"__ecb-aes-\" MODE,\n\t.cra_driver_name\t= \"__driver-ecb-aes-\" MODE,\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_aes_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_blkcipher = {\n\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t.setkey\t\t= crypto_aes_set_key,\n\t\t.encrypt\t= ecb_encrypt,\n\t\t.decrypt\t= ecb_decrypt,\n\t},\n}, {\n\t.cra_name\t\t= \"__cbc-aes-\" MODE,\n\t.cra_driver_name\t= \"__driver-cbc-aes-\" MODE,\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_aes_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_blkcipher = {\n\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t.setkey\t\t= crypto_aes_set_key,\n\t\t.encrypt\t= cbc_encrypt,\n\t\t.decrypt\t= cbc_decrypt,\n\t},\n}, {\n\t.cra_name\t\t= \"__ctr-aes-\" MODE,\n\t.cra_driver_name\t= \"__driver-ctr-aes-\" MODE,\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_aes_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_blkcipher = {\n\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t.setkey\t\t= crypto_aes_set_key,\n\t\t.encrypt\t= ctr_encrypt,\n\t\t.decrypt\t= ctr_encrypt,\n\t},\n}, {\n\t.cra_name\t\t= \"__xts-aes-\" MODE,\n\t.cra_driver_name\t= \"__driver-xts-aes-\" MODE,\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_aes_xts_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_blkcipher = {\n\t\t.min_keysize\t= 2 * AES_MIN_KEY_SIZE,\n\t\t.max_keysize\t= 2 * AES_MAX_KEY_SIZE,\n\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t.setkey\t\t= xts_set_key,\n\t\t.encrypt\t= xts_encrypt,\n\t\t.decrypt\t= xts_decrypt,\n\t},\n}, {\n\t.cra_name\t\t= \"ecb(aes)\",\n\t.cra_driver_name\t= \"ecb-aes-\" MODE,\n\t.cra_priority\t\t= PRIO,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER|CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_ablkcipher = {\n\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t.setkey\t\t= ablk_set_key,\n\t\t.encrypt\t= ablk_encrypt,\n\t\t.decrypt\t= ablk_decrypt,\n\t}\n}, {\n\t.cra_name\t\t= \"cbc(aes)\",\n\t.cra_driver_name\t= \"cbc-aes-\" MODE,\n\t.cra_priority\t\t= PRIO,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER|CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_ablkcipher = {\n\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t.setkey\t\t= ablk_set_key,\n\t\t.encrypt\t= ablk_encrypt,\n\t\t.decrypt\t= ablk_decrypt,\n\t}\n}, {\n\t.cra_name\t\t= \"ctr(aes)\",\n\t.cra_driver_name\t= \"ctr-aes-\" MODE,\n\t.cra_priority\t\t= PRIO,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER|CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_ablkcipher = {\n\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t.setkey\t\t= ablk_set_key,\n\t\t.encrypt\t= ablk_encrypt,\n\t\t.decrypt\t= ablk_decrypt,\n\t}\n}, {\n\t.cra_name\t\t= \"xts(aes)\",\n\t.cra_driver_name\t= \"xts-aes-\" MODE,\n\t.cra_priority\t\t= PRIO,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER|CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_ablkcipher = {\n\t\t.min_keysize\t= 2 * AES_MIN_KEY_SIZE,\n\t\t.max_keysize\t= 2 * AES_MAX_KEY_SIZE,\n\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t.setkey\t\t= ablk_set_key,\n\t\t.encrypt\t= ablk_encrypt,\n\t\t.decrypt\t= ablk_decrypt,\n\t}\n} };\n\nstatic int __init aes_init(void)\n{\n\treturn crypto_register_algs(aes_algs, ARRAY_SIZE(aes_algs));\n}\n\nstatic void __exit aes_exit(void)\n{\n\tcrypto_unregister_algs(aes_algs, ARRAY_SIZE(aes_algs));\n}\n\n#ifdef USE_V8_CRYPTO_EXTENSIONS\nmodule_cpu_feature_match(AES, aes_init);\n#else\nmodule_init(aes_init);\n#endif\nmodule_exit(aes_exit);\n", "/*\n * Cryptographic API.\n *\n * powerpc implementation of the SHA1 Secure Hash Algorithm.\n *\n * Derived from cryptoapi implementation, adapted for in-place\n * scatterlist interface.\n *\n * Derived from \"crypto/sha1.c\"\n * Copyright (c) Alan Smithee.\n * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n * Copyright (c) Jean-Francois Dive <jef@linuxbe.org>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n#include <asm/byteorder.h>\n\nextern void powerpc_sha_transform(u32 *state, const u8 *src, u32 *temp);\n\nstatic int sha1_init(struct shash_desc *desc)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\t*sctx = (struct sha1_state){\n\t\t.state = { SHA1_H0, SHA1_H1, SHA1_H2, SHA1_H3, SHA1_H4 },\n\t};\n\n\treturn 0;\n}\n\nstatic int sha1_update(struct shash_desc *desc, const u8 *data,\n\t\t\tunsigned int len)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial, done;\n\tconst u8 *src;\n\n\tpartial = sctx->count & 0x3f;\n\tsctx->count += len;\n\tdone = 0;\n\tsrc = data;\n\n\tif ((partial + len) > 63) {\n\t\tu32 temp[SHA_WORKSPACE_WORDS];\n\n\t\tif (partial) {\n\t\t\tdone = -partial;\n\t\t\tmemcpy(sctx->buffer + partial, data, done + 64);\n\t\t\tsrc = sctx->buffer;\n\t\t}\n\n\t\tdo {\n\t\t\tpowerpc_sha_transform(sctx->state, src, temp);\n\t\t\tdone += 64;\n\t\t\tsrc = data + done;\n\t\t} while (done + 63 < len);\n\n\t\tmemset(temp, 0, sizeof(temp));\n\t\tpartial = 0;\n\t}\n\tmemcpy(sctx->buffer + partial, src, len - done);\n\n\treturn 0;\n}\n\n\n/* Add padding and return the message digest. */\nstatic int sha1_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\t__be32 *dst = (__be32 *)out;\n\tu32 i, index, padlen;\n\t__be64 bits;\n\tstatic const u8 padding[64] = { 0x80, };\n\n\tbits = cpu_to_be64(sctx->count << 3);\n\n\t/* Pad out to 56 mod 64 */\n\tindex = sctx->count & 0x3f;\n\tpadlen = (index < 56) ? (56 - index) : ((64+56) - index);\n\tsha1_update(desc, padding, padlen);\n\n\t/* Append length */\n\tsha1_update(desc, (const u8 *)&bits, sizeof(bits));\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 5; i++)\n\t\tdst[i] = cpu_to_be32(sctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof *sctx);\n\n\treturn 0;\n}\n\nstatic int sha1_export(struct shash_desc *desc, void *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, sizeof(*sctx));\n\treturn 0;\n}\n\nstatic int sha1_import(struct shash_desc *desc, const void *in)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, sizeof(*sctx));\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tSHA1_DIGEST_SIZE,\n\t.init\t\t=\tsha1_init,\n\t.update\t\t=\tsha1_update,\n\t.final\t\t=\tsha1_final,\n\t.export\t\t=\tsha1_export,\n\t.import\t\t=\tsha1_import,\n\t.descsize\t=\tsizeof(struct sha1_state),\n\t.statesize\t=\tsizeof(struct sha1_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha1\",\n\t\t.cra_driver_name=\t\"sha1-powerpc\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA1_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init sha1_powerpc_mod_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit sha1_powerpc_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(sha1_powerpc_mod_init);\nmodule_exit(sha1_powerpc_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA1 Secure Hash Algorithm\");\n\nMODULE_ALIAS_CRYPTO(\"sha1-powerpc\");\n", "/*\n * Cryptographic API.\n *\n * s390 implementation of the AES Cipher Algorithm.\n *\n * s390 Version:\n *   Copyright IBM Corp. 2005, 2007\n *   Author(s): Jan Glauber (jang@de.ibm.com)\n *\t\tSebastian Siewior (sebastian@breakpoint.cc> SW-Fallback\n *\n * Derived from \"crypto/aes_generic.c\"\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#define KMSG_COMPONENT \"aes_s390\"\n#define pr_fmt(fmt) KMSG_COMPONENT \": \" fmt\n\n#include <crypto/aes.h>\n#include <crypto/algapi.h>\n#include <linux/err.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/spinlock.h>\n#include \"crypt_s390.h\"\n\n#define AES_KEYLEN_128\t\t1\n#define AES_KEYLEN_192\t\t2\n#define AES_KEYLEN_256\t\t4\n\nstatic u8 *ctrblk;\nstatic DEFINE_SPINLOCK(ctrblk_lock);\nstatic char keylen_flag;\n\nstruct s390_aes_ctx {\n\tu8 key[AES_MAX_KEY_SIZE];\n\tlong enc;\n\tlong dec;\n\tint key_len;\n\tunion {\n\t\tstruct crypto_blkcipher *blk;\n\t\tstruct crypto_cipher *cip;\n\t} fallback;\n};\n\nstruct pcc_param {\n\tu8 key[32];\n\tu8 tweak[16];\n\tu8 block[16];\n\tu8 bit[16];\n\tu8 xts[16];\n};\n\nstruct s390_xts_ctx {\n\tu8 key[32];\n\tu8 pcc_key[32];\n\tlong enc;\n\tlong dec;\n\tint key_len;\n\tstruct crypto_blkcipher *fallback;\n};\n\n/*\n * Check if the key_len is supported by the HW.\n * Returns 0 if it is, a positive number if it is not and software fallback is\n * required or a negative number in case the key size is not valid\n */\nstatic int need_fallback(unsigned int key_len)\n{\n\tswitch (key_len) {\n\tcase 16:\n\t\tif (!(keylen_flag & AES_KEYLEN_128))\n\t\t\treturn 1;\n\t\tbreak;\n\tcase 24:\n\t\tif (!(keylen_flag & AES_KEYLEN_192))\n\t\t\treturn 1;\n\t\tbreak;\n\tcase 32:\n\t\tif (!(keylen_flag & AES_KEYLEN_256))\n\t\t\treturn 1;\n\t\tbreak;\n\tdefault:\n\t\treturn -1;\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic int setkey_fallback_cip(struct crypto_tfm *tfm, const u8 *in_key,\n\t\tunsigned int key_len)\n{\n\tstruct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\tint ret;\n\n\tsctx->fallback.cip->base.crt_flags &= ~CRYPTO_TFM_REQ_MASK;\n\tsctx->fallback.cip->base.crt_flags |= (tfm->crt_flags &\n\t\t\tCRYPTO_TFM_REQ_MASK);\n\n\tret = crypto_cipher_setkey(sctx->fallback.cip, in_key, key_len);\n\tif (ret) {\n\t\ttfm->crt_flags &= ~CRYPTO_TFM_RES_MASK;\n\t\ttfm->crt_flags |= (sctx->fallback.cip->base.crt_flags &\n\t\t\t\tCRYPTO_TFM_RES_MASK);\n\t}\n\treturn ret;\n}\n\nstatic int aes_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t       unsigned int key_len)\n{\n\tstruct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tint ret;\n\n\tret = need_fallback(key_len);\n\tif (ret < 0) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\tsctx->key_len = key_len;\n\tif (!ret) {\n\t\tmemcpy(sctx->key, in_key, key_len);\n\t\treturn 0;\n\t}\n\n\treturn setkey_fallback_cip(tfm, in_key, key_len);\n}\n\nstatic void aes_encrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tconst struct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\n\tif (unlikely(need_fallback(sctx->key_len))) {\n\t\tcrypto_cipher_encrypt_one(sctx->fallback.cip, out, in);\n\t\treturn;\n\t}\n\n\tswitch (sctx->key_len) {\n\tcase 16:\n\t\tcrypt_s390_km(KM_AES_128_ENCRYPT, &sctx->key, out, in,\n\t\t\t      AES_BLOCK_SIZE);\n\t\tbreak;\n\tcase 24:\n\t\tcrypt_s390_km(KM_AES_192_ENCRYPT, &sctx->key, out, in,\n\t\t\t      AES_BLOCK_SIZE);\n\t\tbreak;\n\tcase 32:\n\t\tcrypt_s390_km(KM_AES_256_ENCRYPT, &sctx->key, out, in,\n\t\t\t      AES_BLOCK_SIZE);\n\t\tbreak;\n\t}\n}\n\nstatic void aes_decrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tconst struct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\n\tif (unlikely(need_fallback(sctx->key_len))) {\n\t\tcrypto_cipher_decrypt_one(sctx->fallback.cip, out, in);\n\t\treturn;\n\t}\n\n\tswitch (sctx->key_len) {\n\tcase 16:\n\t\tcrypt_s390_km(KM_AES_128_DECRYPT, &sctx->key, out, in,\n\t\t\t      AES_BLOCK_SIZE);\n\t\tbreak;\n\tcase 24:\n\t\tcrypt_s390_km(KM_AES_192_DECRYPT, &sctx->key, out, in,\n\t\t\t      AES_BLOCK_SIZE);\n\t\tbreak;\n\tcase 32:\n\t\tcrypt_s390_km(KM_AES_256_DECRYPT, &sctx->key, out, in,\n\t\t\t      AES_BLOCK_SIZE);\n\t\tbreak;\n\t}\n}\n\nstatic int fallback_init_cip(struct crypto_tfm *tfm)\n{\n\tconst char *name = tfm->__crt_alg->cra_name;\n\tstruct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\n\tsctx->fallback.cip = crypto_alloc_cipher(name, 0,\n\t\t\tCRYPTO_ALG_ASYNC | CRYPTO_ALG_NEED_FALLBACK);\n\n\tif (IS_ERR(sctx->fallback.cip)) {\n\t\tpr_err(\"Allocating AES fallback algorithm %s failed\\n\",\n\t\t       name);\n\t\treturn PTR_ERR(sctx->fallback.cip);\n\t}\n\n\treturn 0;\n}\n\nstatic void fallback_exit_cip(struct crypto_tfm *tfm)\n{\n\tstruct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_cipher(sctx->fallback.cip);\n\tsctx->fallback.cip = NULL;\n}\n\nstatic struct crypto_alg aes_alg = {\n\t.cra_name\t\t=\t\"aes\",\n\t.cra_driver_name\t=\t\"aes-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER |\n\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t.cra_blocksize\t\t=\tAES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_aes_ctx),\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_init               =       fallback_init_cip,\n\t.cra_exit               =       fallback_exit_cip,\n\t.cra_u\t\t\t=\t{\n\t\t.cipher = {\n\t\t\t.cia_min_keysize\t=\tAES_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t=\tAES_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t=\taes_set_key,\n\t\t\t.cia_encrypt\t\t=\taes_encrypt,\n\t\t\t.cia_decrypt\t\t=\taes_decrypt,\n\t\t}\n\t}\n};\n\nstatic int setkey_fallback_blk(struct crypto_tfm *tfm, const u8 *key,\n\t\tunsigned int len)\n{\n\tstruct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\tunsigned int ret;\n\n\tsctx->fallback.blk->base.crt_flags &= ~CRYPTO_TFM_REQ_MASK;\n\tsctx->fallback.blk->base.crt_flags |= (tfm->crt_flags &\n\t\t\tCRYPTO_TFM_REQ_MASK);\n\n\tret = crypto_blkcipher_setkey(sctx->fallback.blk, key, len);\n\tif (ret) {\n\t\ttfm->crt_flags &= ~CRYPTO_TFM_RES_MASK;\n\t\ttfm->crt_flags |= (sctx->fallback.blk->base.crt_flags &\n\t\t\t\tCRYPTO_TFM_RES_MASK);\n\t}\n\treturn ret;\n}\n\nstatic int fallback_blk_dec(struct blkcipher_desc *desc,\n\t\tstruct scatterlist *dst, struct scatterlist *src,\n\t\tunsigned int nbytes)\n{\n\tunsigned int ret;\n\tstruct crypto_blkcipher *tfm;\n\tstruct s390_aes_ctx *sctx = crypto_blkcipher_ctx(desc->tfm);\n\n\ttfm = desc->tfm;\n\tdesc->tfm = sctx->fallback.blk;\n\n\tret = crypto_blkcipher_decrypt_iv(desc, dst, src, nbytes);\n\n\tdesc->tfm = tfm;\n\treturn ret;\n}\n\nstatic int fallback_blk_enc(struct blkcipher_desc *desc,\n\t\tstruct scatterlist *dst, struct scatterlist *src,\n\t\tunsigned int nbytes)\n{\n\tunsigned int ret;\n\tstruct crypto_blkcipher *tfm;\n\tstruct s390_aes_ctx *sctx = crypto_blkcipher_ctx(desc->tfm);\n\n\ttfm = desc->tfm;\n\tdesc->tfm = sctx->fallback.blk;\n\n\tret = crypto_blkcipher_encrypt_iv(desc, dst, src, nbytes);\n\n\tdesc->tfm = tfm;\n\treturn ret;\n}\n\nstatic int ecb_aes_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t\t   unsigned int key_len)\n{\n\tstruct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\tint ret;\n\n\tret = need_fallback(key_len);\n\tif (ret > 0) {\n\t\tsctx->key_len = key_len;\n\t\treturn setkey_fallback_blk(tfm, in_key, key_len);\n\t}\n\n\tswitch (key_len) {\n\tcase 16:\n\t\tsctx->enc = KM_AES_128_ENCRYPT;\n\t\tsctx->dec = KM_AES_128_DECRYPT;\n\t\tbreak;\n\tcase 24:\n\t\tsctx->enc = KM_AES_192_ENCRYPT;\n\t\tsctx->dec = KM_AES_192_DECRYPT;\n\t\tbreak;\n\tcase 32:\n\t\tsctx->enc = KM_AES_256_ENCRYPT;\n\t\tsctx->dec = KM_AES_256_DECRYPT;\n\t\tbreak;\n\t}\n\n\treturn aes_set_key(tfm, in_key, key_len);\n}\n\nstatic int ecb_aes_crypt(struct blkcipher_desc *desc, long func, void *param,\n\t\t\t struct blkcipher_walk *walk)\n{\n\tint ret = blkcipher_walk_virt(desc, walk);\n\tunsigned int nbytes;\n\n\twhile ((nbytes = walk->nbytes)) {\n\t\t/* only use complete blocks */\n\t\tunsigned int n = nbytes & ~(AES_BLOCK_SIZE - 1);\n\t\tu8 *out = walk->dst.virt.addr;\n\t\tu8 *in = walk->src.virt.addr;\n\n\t\tret = crypt_s390_km(func, param, out, in, n);\n\t\tif (ret < 0 || ret != n)\n\t\t\treturn -EIO;\n\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\tret = blkcipher_walk_done(desc, walk, nbytes);\n\t}\n\n\treturn ret;\n}\n\nstatic int ecb_aes_encrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_aes_ctx *sctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tif (unlikely(need_fallback(sctx->key_len)))\n\t\treturn fallback_blk_enc(desc, dst, src, nbytes);\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_aes_crypt(desc, sctx->enc, sctx->key, &walk);\n}\n\nstatic int ecb_aes_decrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_aes_ctx *sctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tif (unlikely(need_fallback(sctx->key_len)))\n\t\treturn fallback_blk_dec(desc, dst, src, nbytes);\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_aes_crypt(desc, sctx->dec, sctx->key, &walk);\n}\n\nstatic int fallback_init_blk(struct crypto_tfm *tfm)\n{\n\tconst char *name = tfm->__crt_alg->cra_name;\n\tstruct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\n\tsctx->fallback.blk = crypto_alloc_blkcipher(name, 0,\n\t\t\tCRYPTO_ALG_ASYNC | CRYPTO_ALG_NEED_FALLBACK);\n\n\tif (IS_ERR(sctx->fallback.blk)) {\n\t\tpr_err(\"Allocating AES fallback algorithm %s failed\\n\",\n\t\t       name);\n\t\treturn PTR_ERR(sctx->fallback.blk);\n\t}\n\n\treturn 0;\n}\n\nstatic void fallback_exit_blk(struct crypto_tfm *tfm)\n{\n\tstruct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_blkcipher(sctx->fallback.blk);\n\tsctx->fallback.blk = NULL;\n}\n\nstatic struct crypto_alg ecb_aes_alg = {\n\t.cra_name\t\t=\t\"ecb(aes)\",\n\t.cra_driver_name\t=\t\"ecb-aes-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER |\n\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t.cra_blocksize\t\t=\tAES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_aes_ctx),\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_init\t\t=\tfallback_init_blk,\n\t.cra_exit\t\t=\tfallback_exit_blk,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\tAES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\tAES_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t\t=\tecb_aes_set_key,\n\t\t\t.encrypt\t\t=\tecb_aes_encrypt,\n\t\t\t.decrypt\t\t=\tecb_aes_decrypt,\n\t\t}\n\t}\n};\n\nstatic int cbc_aes_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t\t   unsigned int key_len)\n{\n\tstruct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\tint ret;\n\n\tret = need_fallback(key_len);\n\tif (ret > 0) {\n\t\tsctx->key_len = key_len;\n\t\treturn setkey_fallback_blk(tfm, in_key, key_len);\n\t}\n\n\tswitch (key_len) {\n\tcase 16:\n\t\tsctx->enc = KMC_AES_128_ENCRYPT;\n\t\tsctx->dec = KMC_AES_128_DECRYPT;\n\t\tbreak;\n\tcase 24:\n\t\tsctx->enc = KMC_AES_192_ENCRYPT;\n\t\tsctx->dec = KMC_AES_192_DECRYPT;\n\t\tbreak;\n\tcase 32:\n\t\tsctx->enc = KMC_AES_256_ENCRYPT;\n\t\tsctx->dec = KMC_AES_256_DECRYPT;\n\t\tbreak;\n\t}\n\n\treturn aes_set_key(tfm, in_key, key_len);\n}\n\nstatic int cbc_aes_crypt(struct blkcipher_desc *desc, long func,\n\t\t\t struct blkcipher_walk *walk)\n{\n\tstruct s390_aes_ctx *sctx = crypto_blkcipher_ctx(desc->tfm);\n\tint ret = blkcipher_walk_virt(desc, walk);\n\tunsigned int nbytes = walk->nbytes;\n\tstruct {\n\t\tu8 iv[AES_BLOCK_SIZE];\n\t\tu8 key[AES_MAX_KEY_SIZE];\n\t} param;\n\n\tif (!nbytes)\n\t\tgoto out;\n\n\tmemcpy(param.iv, walk->iv, AES_BLOCK_SIZE);\n\tmemcpy(param.key, sctx->key, sctx->key_len);\n\tdo {\n\t\t/* only use complete blocks */\n\t\tunsigned int n = nbytes & ~(AES_BLOCK_SIZE - 1);\n\t\tu8 *out = walk->dst.virt.addr;\n\t\tu8 *in = walk->src.virt.addr;\n\n\t\tret = crypt_s390_kmc(func, &param, out, in, n);\n\t\tif (ret < 0 || ret != n)\n\t\t\treturn -EIO;\n\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\tret = blkcipher_walk_done(desc, walk, nbytes);\n\t} while ((nbytes = walk->nbytes));\n\tmemcpy(walk->iv, param.iv, AES_BLOCK_SIZE);\n\nout:\n\treturn ret;\n}\n\nstatic int cbc_aes_encrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_aes_ctx *sctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tif (unlikely(need_fallback(sctx->key_len)))\n\t\treturn fallback_blk_enc(desc, dst, src, nbytes);\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn cbc_aes_crypt(desc, sctx->enc, &walk);\n}\n\nstatic int cbc_aes_decrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_aes_ctx *sctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tif (unlikely(need_fallback(sctx->key_len)))\n\t\treturn fallback_blk_dec(desc, dst, src, nbytes);\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn cbc_aes_crypt(desc, sctx->dec, &walk);\n}\n\nstatic struct crypto_alg cbc_aes_alg = {\n\t.cra_name\t\t=\t\"cbc(aes)\",\n\t.cra_driver_name\t=\t\"cbc-aes-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER |\n\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t.cra_blocksize\t\t=\tAES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_aes_ctx),\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_init\t\t=\tfallback_init_blk,\n\t.cra_exit\t\t=\tfallback_exit_blk,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\tAES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\tAES_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t\t=\tAES_BLOCK_SIZE,\n\t\t\t.setkey\t\t\t=\tcbc_aes_set_key,\n\t\t\t.encrypt\t\t=\tcbc_aes_encrypt,\n\t\t\t.decrypt\t\t=\tcbc_aes_decrypt,\n\t\t}\n\t}\n};\n\nstatic int xts_fallback_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\t\t   unsigned int len)\n{\n\tstruct s390_xts_ctx *xts_ctx = crypto_tfm_ctx(tfm);\n\tunsigned int ret;\n\n\txts_ctx->fallback->base.crt_flags &= ~CRYPTO_TFM_REQ_MASK;\n\txts_ctx->fallback->base.crt_flags |= (tfm->crt_flags &\n\t\t\tCRYPTO_TFM_REQ_MASK);\n\n\tret = crypto_blkcipher_setkey(xts_ctx->fallback, key, len);\n\tif (ret) {\n\t\ttfm->crt_flags &= ~CRYPTO_TFM_RES_MASK;\n\t\ttfm->crt_flags |= (xts_ctx->fallback->base.crt_flags &\n\t\t\t\tCRYPTO_TFM_RES_MASK);\n\t}\n\treturn ret;\n}\n\nstatic int xts_fallback_decrypt(struct blkcipher_desc *desc,\n\t\tstruct scatterlist *dst, struct scatterlist *src,\n\t\tunsigned int nbytes)\n{\n\tstruct s390_xts_ctx *xts_ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct crypto_blkcipher *tfm;\n\tunsigned int ret;\n\n\ttfm = desc->tfm;\n\tdesc->tfm = xts_ctx->fallback;\n\n\tret = crypto_blkcipher_decrypt_iv(desc, dst, src, nbytes);\n\n\tdesc->tfm = tfm;\n\treturn ret;\n}\n\nstatic int xts_fallback_encrypt(struct blkcipher_desc *desc,\n\t\tstruct scatterlist *dst, struct scatterlist *src,\n\t\tunsigned int nbytes)\n{\n\tstruct s390_xts_ctx *xts_ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct crypto_blkcipher *tfm;\n\tunsigned int ret;\n\n\ttfm = desc->tfm;\n\tdesc->tfm = xts_ctx->fallback;\n\n\tret = crypto_blkcipher_encrypt_iv(desc, dst, src, nbytes);\n\n\tdesc->tfm = tfm;\n\treturn ret;\n}\n\nstatic int xts_aes_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t\t   unsigned int key_len)\n{\n\tstruct s390_xts_ctx *xts_ctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\n\tswitch (key_len) {\n\tcase 32:\n\t\txts_ctx->enc = KM_XTS_128_ENCRYPT;\n\t\txts_ctx->dec = KM_XTS_128_DECRYPT;\n\t\tmemcpy(xts_ctx->key + 16, in_key, 16);\n\t\tmemcpy(xts_ctx->pcc_key + 16, in_key + 16, 16);\n\t\tbreak;\n\tcase 48:\n\t\txts_ctx->enc = 0;\n\t\txts_ctx->dec = 0;\n\t\txts_fallback_setkey(tfm, in_key, key_len);\n\t\tbreak;\n\tcase 64:\n\t\txts_ctx->enc = KM_XTS_256_ENCRYPT;\n\t\txts_ctx->dec = KM_XTS_256_DECRYPT;\n\t\tmemcpy(xts_ctx->key, in_key, 32);\n\t\tmemcpy(xts_ctx->pcc_key, in_key + 32, 32);\n\t\tbreak;\n\tdefault:\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\txts_ctx->key_len = key_len;\n\treturn 0;\n}\n\nstatic int xts_aes_crypt(struct blkcipher_desc *desc, long func,\n\t\t\t struct s390_xts_ctx *xts_ctx,\n\t\t\t struct blkcipher_walk *walk)\n{\n\tunsigned int offset = (xts_ctx->key_len >> 1) & 0x10;\n\tint ret = blkcipher_walk_virt(desc, walk);\n\tunsigned int nbytes = walk->nbytes;\n\tunsigned int n;\n\tu8 *in, *out;\n\tstruct pcc_param pcc_param;\n\tstruct {\n\t\tu8 key[32];\n\t\tu8 init[16];\n\t} xts_param;\n\n\tif (!nbytes)\n\t\tgoto out;\n\n\tmemset(pcc_param.block, 0, sizeof(pcc_param.block));\n\tmemset(pcc_param.bit, 0, sizeof(pcc_param.bit));\n\tmemset(pcc_param.xts, 0, sizeof(pcc_param.xts));\n\tmemcpy(pcc_param.tweak, walk->iv, sizeof(pcc_param.tweak));\n\tmemcpy(pcc_param.key, xts_ctx->pcc_key, 32);\n\tret = crypt_s390_pcc(func, &pcc_param.key[offset]);\n\tif (ret < 0)\n\t\treturn -EIO;\n\n\tmemcpy(xts_param.key, xts_ctx->key, 32);\n\tmemcpy(xts_param.init, pcc_param.xts, 16);\n\tdo {\n\t\t/* only use complete blocks */\n\t\tn = nbytes & ~(AES_BLOCK_SIZE - 1);\n\t\tout = walk->dst.virt.addr;\n\t\tin = walk->src.virt.addr;\n\n\t\tret = crypt_s390_km(func, &xts_param.key[offset], out, in, n);\n\t\tif (ret < 0 || ret != n)\n\t\t\treturn -EIO;\n\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\tret = blkcipher_walk_done(desc, walk, nbytes);\n\t} while ((nbytes = walk->nbytes));\nout:\n\treturn ret;\n}\n\nstatic int xts_aes_encrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_xts_ctx *xts_ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tif (unlikely(xts_ctx->key_len == 48))\n\t\treturn xts_fallback_encrypt(desc, dst, src, nbytes);\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn xts_aes_crypt(desc, xts_ctx->enc, xts_ctx, &walk);\n}\n\nstatic int xts_aes_decrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_xts_ctx *xts_ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tif (unlikely(xts_ctx->key_len == 48))\n\t\treturn xts_fallback_decrypt(desc, dst, src, nbytes);\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn xts_aes_crypt(desc, xts_ctx->dec, xts_ctx, &walk);\n}\n\nstatic int xts_fallback_init(struct crypto_tfm *tfm)\n{\n\tconst char *name = tfm->__crt_alg->cra_name;\n\tstruct s390_xts_ctx *xts_ctx = crypto_tfm_ctx(tfm);\n\n\txts_ctx->fallback = crypto_alloc_blkcipher(name, 0,\n\t\t\tCRYPTO_ALG_ASYNC | CRYPTO_ALG_NEED_FALLBACK);\n\n\tif (IS_ERR(xts_ctx->fallback)) {\n\t\tpr_err(\"Allocating XTS fallback algorithm %s failed\\n\",\n\t\t       name);\n\t\treturn PTR_ERR(xts_ctx->fallback);\n\t}\n\treturn 0;\n}\n\nstatic void xts_fallback_exit(struct crypto_tfm *tfm)\n{\n\tstruct s390_xts_ctx *xts_ctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_blkcipher(xts_ctx->fallback);\n\txts_ctx->fallback = NULL;\n}\n\nstatic struct crypto_alg xts_aes_alg = {\n\t.cra_name\t\t=\t\"xts(aes)\",\n\t.cra_driver_name\t=\t\"xts-aes-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER |\n\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t.cra_blocksize\t\t=\tAES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_xts_ctx),\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_init\t\t=\txts_fallback_init,\n\t.cra_exit\t\t=\txts_fallback_exit,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\t2 * AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\t2 * AES_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t\t=\tAES_BLOCK_SIZE,\n\t\t\t.setkey\t\t\t=\txts_aes_set_key,\n\t\t\t.encrypt\t\t=\txts_aes_encrypt,\n\t\t\t.decrypt\t\t=\txts_aes_decrypt,\n\t\t}\n\t}\n};\n\nstatic int xts_aes_alg_reg;\n\nstatic int ctr_aes_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t\t   unsigned int key_len)\n{\n\tstruct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);\n\n\tswitch (key_len) {\n\tcase 16:\n\t\tsctx->enc = KMCTR_AES_128_ENCRYPT;\n\t\tsctx->dec = KMCTR_AES_128_DECRYPT;\n\t\tbreak;\n\tcase 24:\n\t\tsctx->enc = KMCTR_AES_192_ENCRYPT;\n\t\tsctx->dec = KMCTR_AES_192_DECRYPT;\n\t\tbreak;\n\tcase 32:\n\t\tsctx->enc = KMCTR_AES_256_ENCRYPT;\n\t\tsctx->dec = KMCTR_AES_256_DECRYPT;\n\t\tbreak;\n\t}\n\n\treturn aes_set_key(tfm, in_key, key_len);\n}\n\nstatic unsigned int __ctrblk_init(u8 *ctrptr, unsigned int nbytes)\n{\n\tunsigned int i, n;\n\n\t/* only use complete blocks, max. PAGE_SIZE */\n\tn = (nbytes > PAGE_SIZE) ? PAGE_SIZE : nbytes & ~(AES_BLOCK_SIZE - 1);\n\tfor (i = AES_BLOCK_SIZE; i < n; i += AES_BLOCK_SIZE) {\n\t\tmemcpy(ctrptr + i, ctrptr + i - AES_BLOCK_SIZE,\n\t\t       AES_BLOCK_SIZE);\n\t\tcrypto_inc(ctrptr + i, AES_BLOCK_SIZE);\n\t}\n\treturn n;\n}\n\nstatic int ctr_aes_crypt(struct blkcipher_desc *desc, long func,\n\t\t\t struct s390_aes_ctx *sctx, struct blkcipher_walk *walk)\n{\n\tint ret = blkcipher_walk_virt_block(desc, walk, AES_BLOCK_SIZE);\n\tunsigned int n, nbytes;\n\tu8 buf[AES_BLOCK_SIZE], ctrbuf[AES_BLOCK_SIZE];\n\tu8 *out, *in, *ctrptr = ctrbuf;\n\n\tif (!walk->nbytes)\n\t\treturn ret;\n\n\tif (spin_trylock(&ctrblk_lock))\n\t\tctrptr = ctrblk;\n\n\tmemcpy(ctrptr, walk->iv, AES_BLOCK_SIZE);\n\twhile ((nbytes = walk->nbytes) >= AES_BLOCK_SIZE) {\n\t\tout = walk->dst.virt.addr;\n\t\tin = walk->src.virt.addr;\n\t\twhile (nbytes >= AES_BLOCK_SIZE) {\n\t\t\tif (ctrptr == ctrblk)\n\t\t\t\tn = __ctrblk_init(ctrptr, nbytes);\n\t\t\telse\n\t\t\t\tn = AES_BLOCK_SIZE;\n\t\t\tret = crypt_s390_kmctr(func, sctx->key, out, in,\n\t\t\t\t\t       n, ctrptr);\n\t\t\tif (ret < 0 || ret != n) {\n\t\t\t\tif (ctrptr == ctrblk)\n\t\t\t\t\tspin_unlock(&ctrblk_lock);\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t\tif (n > AES_BLOCK_SIZE)\n\t\t\t\tmemcpy(ctrptr, ctrptr + n - AES_BLOCK_SIZE,\n\t\t\t\t       AES_BLOCK_SIZE);\n\t\t\tcrypto_inc(ctrptr, AES_BLOCK_SIZE);\n\t\t\tout += n;\n\t\t\tin += n;\n\t\t\tnbytes -= n;\n\t\t}\n\t\tret = blkcipher_walk_done(desc, walk, nbytes);\n\t}\n\tif (ctrptr == ctrblk) {\n\t\tif (nbytes)\n\t\t\tmemcpy(ctrbuf, ctrptr, AES_BLOCK_SIZE);\n\t\telse\n\t\t\tmemcpy(walk->iv, ctrptr, AES_BLOCK_SIZE);\n\t\tspin_unlock(&ctrblk_lock);\n\t} else {\n\t\tif (!nbytes)\n\t\t\tmemcpy(walk->iv, ctrptr, AES_BLOCK_SIZE);\n\t}\n\t/*\n\t * final block may be < AES_BLOCK_SIZE, copy only nbytes\n\t */\n\tif (nbytes) {\n\t\tout = walk->dst.virt.addr;\n\t\tin = walk->src.virt.addr;\n\t\tret = crypt_s390_kmctr(func, sctx->key, buf, in,\n\t\t\t\t       AES_BLOCK_SIZE, ctrbuf);\n\t\tif (ret < 0 || ret != AES_BLOCK_SIZE)\n\t\t\treturn -EIO;\n\t\tmemcpy(out, buf, nbytes);\n\t\tcrypto_inc(ctrbuf, AES_BLOCK_SIZE);\n\t\tret = blkcipher_walk_done(desc, walk, 0);\n\t\tmemcpy(walk->iv, ctrbuf, AES_BLOCK_SIZE);\n\t}\n\n\treturn ret;\n}\n\nstatic int ctr_aes_encrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_aes_ctx *sctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ctr_aes_crypt(desc, sctx->enc, sctx, &walk);\n}\n\nstatic int ctr_aes_decrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_aes_ctx *sctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ctr_aes_crypt(desc, sctx->dec, sctx, &walk);\n}\n\nstatic struct crypto_alg ctr_aes_alg = {\n\t.cra_name\t\t=\t\"ctr(aes)\",\n\t.cra_driver_name\t=\t\"ctr-aes-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t=\t1,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_aes_ctx),\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\tAES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\tAES_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t\t=\tAES_BLOCK_SIZE,\n\t\t\t.setkey\t\t\t=\tctr_aes_set_key,\n\t\t\t.encrypt\t\t=\tctr_aes_encrypt,\n\t\t\t.decrypt\t\t=\tctr_aes_decrypt,\n\t\t}\n\t}\n};\n\nstatic int ctr_aes_alg_reg;\n\nstatic int __init aes_s390_init(void)\n{\n\tint ret;\n\n\tif (crypt_s390_func_available(KM_AES_128_ENCRYPT, CRYPT_S390_MSA))\n\t\tkeylen_flag |= AES_KEYLEN_128;\n\tif (crypt_s390_func_available(KM_AES_192_ENCRYPT, CRYPT_S390_MSA))\n\t\tkeylen_flag |= AES_KEYLEN_192;\n\tif (crypt_s390_func_available(KM_AES_256_ENCRYPT, CRYPT_S390_MSA))\n\t\tkeylen_flag |= AES_KEYLEN_256;\n\n\tif (!keylen_flag)\n\t\treturn -EOPNOTSUPP;\n\n\t/* z9 109 and z9 BC/EC only support 128 bit key length */\n\tif (keylen_flag == AES_KEYLEN_128)\n\t\tpr_info(\"AES hardware acceleration is only available for\"\n\t\t\t\" 128-bit keys\\n\");\n\n\tret = crypto_register_alg(&aes_alg);\n\tif (ret)\n\t\tgoto aes_err;\n\n\tret = crypto_register_alg(&ecb_aes_alg);\n\tif (ret)\n\t\tgoto ecb_aes_err;\n\n\tret = crypto_register_alg(&cbc_aes_alg);\n\tif (ret)\n\t\tgoto cbc_aes_err;\n\n\tif (crypt_s390_func_available(KM_XTS_128_ENCRYPT,\n\t\t\tCRYPT_S390_MSA | CRYPT_S390_MSA4) &&\n\t    crypt_s390_func_available(KM_XTS_256_ENCRYPT,\n\t\t\tCRYPT_S390_MSA | CRYPT_S390_MSA4)) {\n\t\tret = crypto_register_alg(&xts_aes_alg);\n\t\tif (ret)\n\t\t\tgoto xts_aes_err;\n\t\txts_aes_alg_reg = 1;\n\t}\n\n\tif (crypt_s390_func_available(KMCTR_AES_128_ENCRYPT,\n\t\t\t\tCRYPT_S390_MSA | CRYPT_S390_MSA4) &&\n\t    crypt_s390_func_available(KMCTR_AES_192_ENCRYPT,\n\t\t\t\tCRYPT_S390_MSA | CRYPT_S390_MSA4) &&\n\t    crypt_s390_func_available(KMCTR_AES_256_ENCRYPT,\n\t\t\t\tCRYPT_S390_MSA | CRYPT_S390_MSA4)) {\n\t\tctrblk = (u8 *) __get_free_page(GFP_KERNEL);\n\t\tif (!ctrblk) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto ctr_aes_err;\n\t\t}\n\t\tret = crypto_register_alg(&ctr_aes_alg);\n\t\tif (ret) {\n\t\t\tfree_page((unsigned long) ctrblk);\n\t\t\tgoto ctr_aes_err;\n\t\t}\n\t\tctr_aes_alg_reg = 1;\n\t}\n\nout:\n\treturn ret;\n\nctr_aes_err:\n\tcrypto_unregister_alg(&xts_aes_alg);\nxts_aes_err:\n\tcrypto_unregister_alg(&cbc_aes_alg);\ncbc_aes_err:\n\tcrypto_unregister_alg(&ecb_aes_alg);\necb_aes_err:\n\tcrypto_unregister_alg(&aes_alg);\naes_err:\n\tgoto out;\n}\n\nstatic void __exit aes_s390_fini(void)\n{\n\tif (ctr_aes_alg_reg) {\n\t\tcrypto_unregister_alg(&ctr_aes_alg);\n\t\tfree_page((unsigned long) ctrblk);\n\t}\n\tif (xts_aes_alg_reg)\n\t\tcrypto_unregister_alg(&xts_aes_alg);\n\tcrypto_unregister_alg(&cbc_aes_alg);\n\tcrypto_unregister_alg(&ecb_aes_alg);\n\tcrypto_unregister_alg(&aes_alg);\n}\n\nmodule_init(aes_s390_init);\nmodule_exit(aes_s390_fini);\n\nMODULE_ALIAS_CRYPTO(\"aes-all\");\n\nMODULE_DESCRIPTION(\"Rijndael (AES) Cipher Algorithm\");\nMODULE_LICENSE(\"GPL\");\n", "/*\n * Cryptographic API.\n *\n * s390 implementation of the DES Cipher Algorithm.\n *\n * Copyright IBM Corp. 2003, 2011\n * Author(s): Thomas Spatzier\n *\t      Jan Glauber (jan.glauber@de.ibm.com)\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/crypto.h>\n#include <crypto/algapi.h>\n#include <crypto/des.h>\n\n#include \"crypt_s390.h\"\n\n#define DES3_KEY_SIZE\t(3 * DES_KEY_SIZE)\n\nstatic u8 *ctrblk;\nstatic DEFINE_SPINLOCK(ctrblk_lock);\n\nstruct s390_des_ctx {\n\tu8 iv[DES_BLOCK_SIZE];\n\tu8 key[DES3_KEY_SIZE];\n};\n\nstatic int des_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t      unsigned int key_len)\n{\n\tstruct s390_des_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tu32 tmp[DES_EXPKEY_WORDS];\n\n\t/* check for weak keys */\n\tif (!des_ekey(tmp, key) && (*flags & CRYPTO_TFM_REQ_WEAK_KEY)) {\n\t\t*flags |= CRYPTO_TFM_RES_WEAK_KEY;\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(ctx->key, key, key_len);\n\treturn 0;\n}\n\nstatic void des_encrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tstruct s390_des_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypt_s390_km(KM_DEA_ENCRYPT, ctx->key, out, in, DES_BLOCK_SIZE);\n}\n\nstatic void des_decrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tstruct s390_des_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypt_s390_km(KM_DEA_DECRYPT, ctx->key, out, in, DES_BLOCK_SIZE);\n}\n\nstatic struct crypto_alg des_alg = {\n\t.cra_name\t\t=\t\"des\",\n\t.cra_driver_name\t=\t\"des-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tDES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_des_ctx),\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.cipher = {\n\t\t\t.cia_min_keysize\t=\tDES_KEY_SIZE,\n\t\t\t.cia_max_keysize\t=\tDES_KEY_SIZE,\n\t\t\t.cia_setkey\t\t=\tdes_setkey,\n\t\t\t.cia_encrypt\t\t=\tdes_encrypt,\n\t\t\t.cia_decrypt\t\t=\tdes_decrypt,\n\t\t}\n\t}\n};\n\nstatic int ecb_desall_crypt(struct blkcipher_desc *desc, long func,\n\t\t\t    u8 *key, struct blkcipher_walk *walk)\n{\n\tint ret = blkcipher_walk_virt(desc, walk);\n\tunsigned int nbytes;\n\n\twhile ((nbytes = walk->nbytes)) {\n\t\t/* only use complete blocks */\n\t\tunsigned int n = nbytes & ~(DES_BLOCK_SIZE - 1);\n\t\tu8 *out = walk->dst.virt.addr;\n\t\tu8 *in = walk->src.virt.addr;\n\n\t\tret = crypt_s390_km(func, key, out, in, n);\n\t\tif (ret < 0 || ret != n)\n\t\t\treturn -EIO;\n\n\t\tnbytes &= DES_BLOCK_SIZE - 1;\n\t\tret = blkcipher_walk_done(desc, walk, nbytes);\n\t}\n\n\treturn ret;\n}\n\nstatic int cbc_desall_crypt(struct blkcipher_desc *desc, long func,\n\t\t\t    struct blkcipher_walk *walk)\n{\n\tstruct s390_des_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tint ret = blkcipher_walk_virt(desc, walk);\n\tunsigned int nbytes = walk->nbytes;\n\tstruct {\n\t\tu8 iv[DES_BLOCK_SIZE];\n\t\tu8 key[DES3_KEY_SIZE];\n\t} param;\n\n\tif (!nbytes)\n\t\tgoto out;\n\n\tmemcpy(param.iv, walk->iv, DES_BLOCK_SIZE);\n\tmemcpy(param.key, ctx->key, DES3_KEY_SIZE);\n\tdo {\n\t\t/* only use complete blocks */\n\t\tunsigned int n = nbytes & ~(DES_BLOCK_SIZE - 1);\n\t\tu8 *out = walk->dst.virt.addr;\n\t\tu8 *in = walk->src.virt.addr;\n\n\t\tret = crypt_s390_kmc(func, &param, out, in, n);\n\t\tif (ret < 0 || ret != n)\n\t\t\treturn -EIO;\n\n\t\tnbytes &= DES_BLOCK_SIZE - 1;\n\t\tret = blkcipher_walk_done(desc, walk, nbytes);\n\t} while ((nbytes = walk->nbytes));\n\tmemcpy(walk->iv, param.iv, DES_BLOCK_SIZE);\n\nout:\n\treturn ret;\n}\n\nstatic int ecb_des_encrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_des_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_desall_crypt(desc, KM_DEA_ENCRYPT, ctx->key, &walk);\n}\n\nstatic int ecb_des_decrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_des_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_desall_crypt(desc, KM_DEA_DECRYPT, ctx->key, &walk);\n}\n\nstatic struct crypto_alg ecb_des_alg = {\n\t.cra_name\t\t=\t\"ecb(des)\",\n\t.cra_driver_name\t=\t\"ecb-des-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t=\tDES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_des_ctx),\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\tDES_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\tDES_KEY_SIZE,\n\t\t\t.setkey\t\t\t=\tdes_setkey,\n\t\t\t.encrypt\t\t=\tecb_des_encrypt,\n\t\t\t.decrypt\t\t=\tecb_des_decrypt,\n\t\t}\n\t}\n};\n\nstatic int cbc_des_encrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn cbc_desall_crypt(desc, KMC_DEA_ENCRYPT, &walk);\n}\n\nstatic int cbc_des_decrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn cbc_desall_crypt(desc, KMC_DEA_DECRYPT, &walk);\n}\n\nstatic struct crypto_alg cbc_des_alg = {\n\t.cra_name\t\t=\t\"cbc(des)\",\n\t.cra_driver_name\t=\t\"cbc-des-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t=\tDES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_des_ctx),\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\tDES_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\tDES_KEY_SIZE,\n\t\t\t.ivsize\t\t\t=\tDES_BLOCK_SIZE,\n\t\t\t.setkey\t\t\t=\tdes_setkey,\n\t\t\t.encrypt\t\t=\tcbc_des_encrypt,\n\t\t\t.decrypt\t\t=\tcbc_des_decrypt,\n\t\t}\n\t}\n};\n\n/*\n * RFC2451:\n *\n *   For DES-EDE3, there is no known need to reject weak or\n *   complementation keys.  Any weakness is obviated by the use of\n *   multiple keys.\n *\n *   However, if the first two or last two independent 64-bit keys are\n *   equal (k1 == k2 or k2 == k3), then the DES3 operation is simply the\n *   same as DES.  Implementers MUST reject keys that exhibit this\n *   property.\n *\n */\nstatic int des3_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t       unsigned int key_len)\n{\n\tstruct s390_des_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\n\tif (!(crypto_memneq(key, &key[DES_KEY_SIZE], DES_KEY_SIZE) &&\n\t    crypto_memneq(&key[DES_KEY_SIZE], &key[DES_KEY_SIZE * 2],\n\t\t\t  DES_KEY_SIZE)) &&\n\t    (*flags & CRYPTO_TFM_REQ_WEAK_KEY)) {\n\t\t*flags |= CRYPTO_TFM_RES_WEAK_KEY;\n\t\treturn -EINVAL;\n\t}\n\tmemcpy(ctx->key, key, key_len);\n\treturn 0;\n}\n\nstatic void des3_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct s390_des_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypt_s390_km(KM_TDEA_192_ENCRYPT, ctx->key, dst, src, DES_BLOCK_SIZE);\n}\n\nstatic void des3_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct s390_des_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypt_s390_km(KM_TDEA_192_DECRYPT, ctx->key, dst, src, DES_BLOCK_SIZE);\n}\n\nstatic struct crypto_alg des3_alg = {\n\t.cra_name\t\t=\t\"des3_ede\",\n\t.cra_driver_name\t=\t\"des3_ede-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tDES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_des_ctx),\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.cipher = {\n\t\t\t.cia_min_keysize\t=\tDES3_KEY_SIZE,\n\t\t\t.cia_max_keysize\t=\tDES3_KEY_SIZE,\n\t\t\t.cia_setkey\t\t=\tdes3_setkey,\n\t\t\t.cia_encrypt\t\t=\tdes3_encrypt,\n\t\t\t.cia_decrypt\t\t=\tdes3_decrypt,\n\t\t}\n\t}\n};\n\nstatic int ecb_des3_encrypt(struct blkcipher_desc *desc,\n\t\t\t    struct scatterlist *dst, struct scatterlist *src,\n\t\t\t    unsigned int nbytes)\n{\n\tstruct s390_des_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_desall_crypt(desc, KM_TDEA_192_ENCRYPT, ctx->key, &walk);\n}\n\nstatic int ecb_des3_decrypt(struct blkcipher_desc *desc,\n\t\t\t    struct scatterlist *dst, struct scatterlist *src,\n\t\t\t    unsigned int nbytes)\n{\n\tstruct s390_des_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_desall_crypt(desc, KM_TDEA_192_DECRYPT, ctx->key, &walk);\n}\n\nstatic struct crypto_alg ecb_des3_alg = {\n\t.cra_name\t\t=\t\"ecb(des3_ede)\",\n\t.cra_driver_name\t=\t\"ecb-des3_ede-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t=\tDES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_des_ctx),\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\tDES3_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\tDES3_KEY_SIZE,\n\t\t\t.setkey\t\t\t=\tdes3_setkey,\n\t\t\t.encrypt\t\t=\tecb_des3_encrypt,\n\t\t\t.decrypt\t\t=\tecb_des3_decrypt,\n\t\t}\n\t}\n};\n\nstatic int cbc_des3_encrypt(struct blkcipher_desc *desc,\n\t\t\t    struct scatterlist *dst, struct scatterlist *src,\n\t\t\t    unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn cbc_desall_crypt(desc, KMC_TDEA_192_ENCRYPT, &walk);\n}\n\nstatic int cbc_des3_decrypt(struct blkcipher_desc *desc,\n\t\t\t    struct scatterlist *dst, struct scatterlist *src,\n\t\t\t    unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn cbc_desall_crypt(desc, KMC_TDEA_192_DECRYPT, &walk);\n}\n\nstatic struct crypto_alg cbc_des3_alg = {\n\t.cra_name\t\t=\t\"cbc(des3_ede)\",\n\t.cra_driver_name\t=\t\"cbc-des3_ede-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t=\tDES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_des_ctx),\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\tDES3_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\tDES3_KEY_SIZE,\n\t\t\t.ivsize\t\t\t=\tDES_BLOCK_SIZE,\n\t\t\t.setkey\t\t\t=\tdes3_setkey,\n\t\t\t.encrypt\t\t=\tcbc_des3_encrypt,\n\t\t\t.decrypt\t\t=\tcbc_des3_decrypt,\n\t\t}\n\t}\n};\n\nstatic unsigned int __ctrblk_init(u8 *ctrptr, unsigned int nbytes)\n{\n\tunsigned int i, n;\n\n\t/* align to block size, max. PAGE_SIZE */\n\tn = (nbytes > PAGE_SIZE) ? PAGE_SIZE : nbytes & ~(DES_BLOCK_SIZE - 1);\n\tfor (i = DES_BLOCK_SIZE; i < n; i += DES_BLOCK_SIZE) {\n\t\tmemcpy(ctrptr + i, ctrptr + i - DES_BLOCK_SIZE, DES_BLOCK_SIZE);\n\t\tcrypto_inc(ctrptr + i, DES_BLOCK_SIZE);\n\t}\n\treturn n;\n}\n\nstatic int ctr_desall_crypt(struct blkcipher_desc *desc, long func,\n\t\t\t    struct s390_des_ctx *ctx,\n\t\t\t    struct blkcipher_walk *walk)\n{\n\tint ret = blkcipher_walk_virt_block(desc, walk, DES_BLOCK_SIZE);\n\tunsigned int n, nbytes;\n\tu8 buf[DES_BLOCK_SIZE], ctrbuf[DES_BLOCK_SIZE];\n\tu8 *out, *in, *ctrptr = ctrbuf;\n\n\tif (!walk->nbytes)\n\t\treturn ret;\n\n\tif (spin_trylock(&ctrblk_lock))\n\t\tctrptr = ctrblk;\n\n\tmemcpy(ctrptr, walk->iv, DES_BLOCK_SIZE);\n\twhile ((nbytes = walk->nbytes) >= DES_BLOCK_SIZE) {\n\t\tout = walk->dst.virt.addr;\n\t\tin = walk->src.virt.addr;\n\t\twhile (nbytes >= DES_BLOCK_SIZE) {\n\t\t\tif (ctrptr == ctrblk)\n\t\t\t\tn = __ctrblk_init(ctrptr, nbytes);\n\t\t\telse\n\t\t\t\tn = DES_BLOCK_SIZE;\n\t\t\tret = crypt_s390_kmctr(func, ctx->key, out, in,\n\t\t\t\t\t       n, ctrptr);\n\t\t\tif (ret < 0 || ret != n) {\n\t\t\t\tif (ctrptr == ctrblk)\n\t\t\t\t\tspin_unlock(&ctrblk_lock);\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t\tif (n > DES_BLOCK_SIZE)\n\t\t\t\tmemcpy(ctrptr, ctrptr + n - DES_BLOCK_SIZE,\n\t\t\t\t       DES_BLOCK_SIZE);\n\t\t\tcrypto_inc(ctrptr, DES_BLOCK_SIZE);\n\t\t\tout += n;\n\t\t\tin += n;\n\t\t\tnbytes -= n;\n\t\t}\n\t\tret = blkcipher_walk_done(desc, walk, nbytes);\n\t}\n\tif (ctrptr == ctrblk) {\n\t\tif (nbytes)\n\t\t\tmemcpy(ctrbuf, ctrptr, DES_BLOCK_SIZE);\n\t\telse\n\t\t\tmemcpy(walk->iv, ctrptr, DES_BLOCK_SIZE);\n\t\tspin_unlock(&ctrblk_lock);\n\t} else {\n\t\tif (!nbytes)\n\t\t\tmemcpy(walk->iv, ctrptr, DES_BLOCK_SIZE);\n\t}\n\t/* final block may be < DES_BLOCK_SIZE, copy only nbytes */\n\tif (nbytes) {\n\t\tout = walk->dst.virt.addr;\n\t\tin = walk->src.virt.addr;\n\t\tret = crypt_s390_kmctr(func, ctx->key, buf, in,\n\t\t\t\t       DES_BLOCK_SIZE, ctrbuf);\n\t\tif (ret < 0 || ret != DES_BLOCK_SIZE)\n\t\t\treturn -EIO;\n\t\tmemcpy(out, buf, nbytes);\n\t\tcrypto_inc(ctrbuf, DES_BLOCK_SIZE);\n\t\tret = blkcipher_walk_done(desc, walk, 0);\n\t\tmemcpy(walk->iv, ctrbuf, DES_BLOCK_SIZE);\n\t}\n\treturn ret;\n}\n\nstatic int ctr_des_encrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_des_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ctr_desall_crypt(desc, KMCTR_DEA_ENCRYPT, ctx, &walk);\n}\n\nstatic int ctr_des_decrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct s390_des_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ctr_desall_crypt(desc, KMCTR_DEA_DECRYPT, ctx, &walk);\n}\n\nstatic struct crypto_alg ctr_des_alg = {\n\t.cra_name\t\t=\t\"ctr(des)\",\n\t.cra_driver_name\t=\t\"ctr-des-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t=\t1,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_des_ctx),\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\tDES_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\tDES_KEY_SIZE,\n\t\t\t.ivsize\t\t\t=\tDES_BLOCK_SIZE,\n\t\t\t.setkey\t\t\t=\tdes_setkey,\n\t\t\t.encrypt\t\t=\tctr_des_encrypt,\n\t\t\t.decrypt\t\t=\tctr_des_decrypt,\n\t\t}\n\t}\n};\n\nstatic int ctr_des3_encrypt(struct blkcipher_desc *desc,\n\t\t\t    struct scatterlist *dst, struct scatterlist *src,\n\t\t\t    unsigned int nbytes)\n{\n\tstruct s390_des_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ctr_desall_crypt(desc, KMCTR_TDEA_192_ENCRYPT, ctx, &walk);\n}\n\nstatic int ctr_des3_decrypt(struct blkcipher_desc *desc,\n\t\t\t    struct scatterlist *dst, struct scatterlist *src,\n\t\t\t    unsigned int nbytes)\n{\n\tstruct s390_des_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ctr_desall_crypt(desc, KMCTR_TDEA_192_DECRYPT, ctx, &walk);\n}\n\nstatic struct crypto_alg ctr_des3_alg = {\n\t.cra_name\t\t=\t\"ctr(des3_ede)\",\n\t.cra_driver_name\t=\t\"ctr-des3_ede-s390\",\n\t.cra_priority\t\t=\tCRYPT_S390_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t=\t1,\n\t.cra_ctxsize\t\t=\tsizeof(struct s390_des_ctx),\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\tDES3_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\tDES3_KEY_SIZE,\n\t\t\t.ivsize\t\t\t=\tDES_BLOCK_SIZE,\n\t\t\t.setkey\t\t\t=\tdes3_setkey,\n\t\t\t.encrypt\t\t=\tctr_des3_encrypt,\n\t\t\t.decrypt\t\t=\tctr_des3_decrypt,\n\t\t}\n\t}\n};\n\nstatic int __init des_s390_init(void)\n{\n\tint ret;\n\n\tif (!crypt_s390_func_available(KM_DEA_ENCRYPT, CRYPT_S390_MSA) ||\n\t    !crypt_s390_func_available(KM_TDEA_192_ENCRYPT, CRYPT_S390_MSA))\n\t\treturn -EOPNOTSUPP;\n\n\tret = crypto_register_alg(&des_alg);\n\tif (ret)\n\t\tgoto des_err;\n\tret = crypto_register_alg(&ecb_des_alg);\n\tif (ret)\n\t\tgoto ecb_des_err;\n\tret = crypto_register_alg(&cbc_des_alg);\n\tif (ret)\n\t\tgoto cbc_des_err;\n\tret = crypto_register_alg(&des3_alg);\n\tif (ret)\n\t\tgoto des3_err;\n\tret = crypto_register_alg(&ecb_des3_alg);\n\tif (ret)\n\t\tgoto ecb_des3_err;\n\tret = crypto_register_alg(&cbc_des3_alg);\n\tif (ret)\n\t\tgoto cbc_des3_err;\n\n\tif (crypt_s390_func_available(KMCTR_DEA_ENCRYPT,\n\t\t\tCRYPT_S390_MSA | CRYPT_S390_MSA4) &&\n\t    crypt_s390_func_available(KMCTR_TDEA_192_ENCRYPT,\n\t\t\tCRYPT_S390_MSA | CRYPT_S390_MSA4)) {\n\t\tret = crypto_register_alg(&ctr_des_alg);\n\t\tif (ret)\n\t\t\tgoto ctr_des_err;\n\t\tret = crypto_register_alg(&ctr_des3_alg);\n\t\tif (ret)\n\t\t\tgoto ctr_des3_err;\n\t\tctrblk = (u8 *) __get_free_page(GFP_KERNEL);\n\t\tif (!ctrblk) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto ctr_mem_err;\n\t\t}\n\t}\nout:\n\treturn ret;\n\nctr_mem_err:\n\tcrypto_unregister_alg(&ctr_des3_alg);\nctr_des3_err:\n\tcrypto_unregister_alg(&ctr_des_alg);\nctr_des_err:\n\tcrypto_unregister_alg(&cbc_des3_alg);\ncbc_des3_err:\n\tcrypto_unregister_alg(&ecb_des3_alg);\necb_des3_err:\n\tcrypto_unregister_alg(&des3_alg);\ndes3_err:\n\tcrypto_unregister_alg(&cbc_des_alg);\ncbc_des_err:\n\tcrypto_unregister_alg(&ecb_des_alg);\necb_des_err:\n\tcrypto_unregister_alg(&des_alg);\ndes_err:\n\tgoto out;\n}\n\nstatic void __exit des_s390_exit(void)\n{\n\tif (ctrblk) {\n\t\tcrypto_unregister_alg(&ctr_des_alg);\n\t\tcrypto_unregister_alg(&ctr_des3_alg);\n\t\tfree_page((unsigned long) ctrblk);\n\t}\n\tcrypto_unregister_alg(&cbc_des3_alg);\n\tcrypto_unregister_alg(&ecb_des3_alg);\n\tcrypto_unregister_alg(&des3_alg);\n\tcrypto_unregister_alg(&cbc_des_alg);\n\tcrypto_unregister_alg(&ecb_des_alg);\n\tcrypto_unregister_alg(&des_alg);\n}\n\nmodule_init(des_s390_init);\nmodule_exit(des_s390_exit);\n\nMODULE_ALIAS_CRYPTO(\"des\");\nMODULE_ALIAS_CRYPTO(\"des3_ede\");\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"DES & Triple DES EDE Cipher Algorithms\");\n", "/*\n * Cryptographic API.\n *\n * s390 implementation of the GHASH algorithm for GCM (Galois/Counter Mode).\n *\n * Copyright IBM Corp. 2011\n * Author(s): Gerald Schaefer <gerald.schaefer@de.ibm.com>\n */\n\n#include <crypto/internal/hash.h>\n#include <linux/module.h>\n\n#include \"crypt_s390.h\"\n\n#define GHASH_BLOCK_SIZE\t16\n#define GHASH_DIGEST_SIZE\t16\n\nstruct ghash_ctx {\n\tu8 icv[16];\n\tu8 key[16];\n};\n\nstruct ghash_desc_ctx {\n\tu8 buffer[GHASH_BLOCK_SIZE];\n\tu32 bytes;\n};\n\nstatic int ghash_init(struct shash_desc *desc)\n{\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\n\tmemset(dctx, 0, sizeof(*dctx));\n\n\treturn 0;\n}\n\nstatic int ghash_setkey(struct crypto_shash *tfm,\n\t\t\tconst u8 *key, unsigned int keylen)\n{\n\tstruct ghash_ctx *ctx = crypto_shash_ctx(tfm);\n\n\tif (keylen != GHASH_BLOCK_SIZE) {\n\t\tcrypto_shash_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(ctx->key, key, GHASH_BLOCK_SIZE);\n\tmemset(ctx->icv, 0, GHASH_BLOCK_SIZE);\n\n\treturn 0;\n}\n\nstatic int ghash_update(struct shash_desc *desc,\n\t\t\t const u8 *src, unsigned int srclen)\n{\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\tstruct ghash_ctx *ctx = crypto_shash_ctx(desc->tfm);\n\tunsigned int n;\n\tu8 *buf = dctx->buffer;\n\tint ret;\n\n\tif (dctx->bytes) {\n\t\tu8 *pos = buf + (GHASH_BLOCK_SIZE - dctx->bytes);\n\n\t\tn = min(srclen, dctx->bytes);\n\t\tdctx->bytes -= n;\n\t\tsrclen -= n;\n\n\t\tmemcpy(pos, src, n);\n\t\tsrc += n;\n\n\t\tif (!dctx->bytes) {\n\t\t\tret = crypt_s390_kimd(KIMD_GHASH, ctx, buf,\n\t\t\t\t\t      GHASH_BLOCK_SIZE);\n\t\t\tif (ret != GHASH_BLOCK_SIZE)\n\t\t\t\treturn -EIO;\n\t\t}\n\t}\n\n\tn = srclen & ~(GHASH_BLOCK_SIZE - 1);\n\tif (n) {\n\t\tret = crypt_s390_kimd(KIMD_GHASH, ctx, src, n);\n\t\tif (ret != n)\n\t\t\treturn -EIO;\n\t\tsrc += n;\n\t\tsrclen -= n;\n\t}\n\n\tif (srclen) {\n\t\tdctx->bytes = GHASH_BLOCK_SIZE - srclen;\n\t\tmemcpy(buf, src, srclen);\n\t}\n\n\treturn 0;\n}\n\nstatic int ghash_flush(struct ghash_ctx *ctx, struct ghash_desc_ctx *dctx)\n{\n\tu8 *buf = dctx->buffer;\n\tint ret;\n\n\tif (dctx->bytes) {\n\t\tu8 *pos = buf + (GHASH_BLOCK_SIZE - dctx->bytes);\n\n\t\tmemset(pos, 0, dctx->bytes);\n\n\t\tret = crypt_s390_kimd(KIMD_GHASH, ctx, buf, GHASH_BLOCK_SIZE);\n\t\tif (ret != GHASH_BLOCK_SIZE)\n\t\t\treturn -EIO;\n\t}\n\n\tdctx->bytes = 0;\n\treturn 0;\n}\n\nstatic int ghash_final(struct shash_desc *desc, u8 *dst)\n{\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\tstruct ghash_ctx *ctx = crypto_shash_ctx(desc->tfm);\n\tint ret;\n\n\tret = ghash_flush(ctx, dctx);\n\tif (!ret)\n\t\tmemcpy(dst, ctx->icv, GHASH_BLOCK_SIZE);\n\treturn ret;\n}\n\nstatic struct shash_alg ghash_alg = {\n\t.digestsize\t= GHASH_DIGEST_SIZE,\n\t.init\t\t= ghash_init,\n\t.update\t\t= ghash_update,\n\t.final\t\t= ghash_final,\n\t.setkey\t\t= ghash_setkey,\n\t.descsize\t= sizeof(struct ghash_desc_ctx),\n\t.base\t\t= {\n\t\t.cra_name\t\t= \"ghash\",\n\t\t.cra_driver_name\t= \"ghash-s390\",\n\t\t.cra_priority\t\t= CRYPT_S390_PRIORITY,\n\t\t.cra_flags\t\t= CRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t\t= GHASH_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t= sizeof(struct ghash_ctx),\n\t\t.cra_module\t\t= THIS_MODULE,\n\t},\n};\n\nstatic int __init ghash_mod_init(void)\n{\n\tif (!crypt_s390_func_available(KIMD_GHASH,\n\t\t\t\t       CRYPT_S390_MSA | CRYPT_S390_MSA4))\n\t\treturn -EOPNOTSUPP;\n\n\treturn crypto_register_shash(&ghash_alg);\n}\n\nstatic void __exit ghash_mod_exit(void)\n{\n\tcrypto_unregister_shash(&ghash_alg);\n}\n\nmodule_init(ghash_mod_init);\nmodule_exit(ghash_mod_exit);\n\nMODULE_ALIAS_CRYPTO(\"ghash\");\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"GHASH Message Digest Algorithm, s390 implementation\");\n", "/*\n * Cryptographic API.\n *\n * s390 implementation of the SHA1 Secure Hash Algorithm.\n *\n * Derived from cryptoapi implementation, adapted for in-place\n * scatterlist interface.  Originally based on the public domain\n * implementation written by Steve Reid.\n *\n * s390 Version:\n *   Copyright IBM Corp. 2003, 2007\n *   Author(s): Thomas Spatzier\n *\t\tJan Glauber (jan.glauber@de.ibm.com)\n *\n * Derived from \"crypto/sha1_generic.c\"\n *   Copyright (c) Alan Smithee.\n *   Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n *   Copyright (c) Jean-Francois Dive <jef@linuxbe.org>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <crypto/sha.h>\n\n#include \"crypt_s390.h\"\n#include \"sha.h\"\n\nstatic int sha1_init(struct shash_desc *desc)\n{\n\tstruct s390_sha_ctx *sctx = shash_desc_ctx(desc);\n\n\tsctx->state[0] = SHA1_H0;\n\tsctx->state[1] = SHA1_H1;\n\tsctx->state[2] = SHA1_H2;\n\tsctx->state[3] = SHA1_H3;\n\tsctx->state[4] = SHA1_H4;\n\tsctx->count = 0;\n\tsctx->func = KIMD_SHA_1;\n\n\treturn 0;\n}\n\nstatic int sha1_export(struct shash_desc *desc, void *out)\n{\n\tstruct s390_sha_ctx *sctx = shash_desc_ctx(desc);\n\tstruct sha1_state *octx = out;\n\n\toctx->count = sctx->count;\n\tmemcpy(octx->state, sctx->state, sizeof(octx->state));\n\tmemcpy(octx->buffer, sctx->buf, sizeof(octx->buffer));\n\treturn 0;\n}\n\nstatic int sha1_import(struct shash_desc *desc, const void *in)\n{\n\tstruct s390_sha_ctx *sctx = shash_desc_ctx(desc);\n\tconst struct sha1_state *ictx = in;\n\n\tsctx->count = ictx->count;\n\tmemcpy(sctx->state, ictx->state, sizeof(ictx->state));\n\tmemcpy(sctx->buf, ictx->buffer, sizeof(ictx->buffer));\n\tsctx->func = KIMD_SHA_1;\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tSHA1_DIGEST_SIZE,\n\t.init\t\t=\tsha1_init,\n\t.update\t\t=\ts390_sha_update,\n\t.final\t\t=\ts390_sha_final,\n\t.export\t\t=\tsha1_export,\n\t.import\t\t=\tsha1_import,\n\t.descsize\t=\tsizeof(struct s390_sha_ctx),\n\t.statesize\t=\tsizeof(struct sha1_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha1\",\n\t\t.cra_driver_name=\t\"sha1-s390\",\n\t\t.cra_priority\t=\tCRYPT_S390_PRIORITY,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA1_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init sha1_s390_init(void)\n{\n\tif (!crypt_s390_func_available(KIMD_SHA_1, CRYPT_S390_MSA))\n\t\treturn -EOPNOTSUPP;\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit sha1_s390_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(sha1_s390_init);\nmodule_exit(sha1_s390_fini);\n\nMODULE_ALIAS_CRYPTO(\"sha1\");\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA1 Secure Hash Algorithm\");\n", "/*\n * Cryptographic API.\n *\n * s390 implementation of the SHA256 and SHA224 Secure Hash Algorithm.\n *\n * s390 Version:\n *   Copyright IBM Corp. 2005, 2011\n *   Author(s): Jan Glauber (jang@de.ibm.com)\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <crypto/sha.h>\n\n#include \"crypt_s390.h\"\n#include \"sha.h\"\n\nstatic int sha256_init(struct shash_desc *desc)\n{\n\tstruct s390_sha_ctx *sctx = shash_desc_ctx(desc);\n\n\tsctx->state[0] = SHA256_H0;\n\tsctx->state[1] = SHA256_H1;\n\tsctx->state[2] = SHA256_H2;\n\tsctx->state[3] = SHA256_H3;\n\tsctx->state[4] = SHA256_H4;\n\tsctx->state[5] = SHA256_H5;\n\tsctx->state[6] = SHA256_H6;\n\tsctx->state[7] = SHA256_H7;\n\tsctx->count = 0;\n\tsctx->func = KIMD_SHA_256;\n\n\treturn 0;\n}\n\nstatic int sha256_export(struct shash_desc *desc, void *out)\n{\n\tstruct s390_sha_ctx *sctx = shash_desc_ctx(desc);\n\tstruct sha256_state *octx = out;\n\n\toctx->count = sctx->count;\n\tmemcpy(octx->state, sctx->state, sizeof(octx->state));\n\tmemcpy(octx->buf, sctx->buf, sizeof(octx->buf));\n\treturn 0;\n}\n\nstatic int sha256_import(struct shash_desc *desc, const void *in)\n{\n\tstruct s390_sha_ctx *sctx = shash_desc_ctx(desc);\n\tconst struct sha256_state *ictx = in;\n\n\tsctx->count = ictx->count;\n\tmemcpy(sctx->state, ictx->state, sizeof(ictx->state));\n\tmemcpy(sctx->buf, ictx->buf, sizeof(ictx->buf));\n\tsctx->func = KIMD_SHA_256;\n\treturn 0;\n}\n\nstatic struct shash_alg sha256_alg = {\n\t.digestsize\t=\tSHA256_DIGEST_SIZE,\n\t.init\t\t=\tsha256_init,\n\t.update\t\t=\ts390_sha_update,\n\t.final\t\t=\ts390_sha_final,\n\t.export\t\t=\tsha256_export,\n\t.import\t\t=\tsha256_import,\n\t.descsize\t=\tsizeof(struct s390_sha_ctx),\n\t.statesize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha256\",\n\t\t.cra_driver_name=\t\"sha256-s390\",\n\t\t.cra_priority\t=\tCRYPT_S390_PRIORITY,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA256_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic int sha224_init(struct shash_desc *desc)\n{\n\tstruct s390_sha_ctx *sctx = shash_desc_ctx(desc);\n\n\tsctx->state[0] = SHA224_H0;\n\tsctx->state[1] = SHA224_H1;\n\tsctx->state[2] = SHA224_H2;\n\tsctx->state[3] = SHA224_H3;\n\tsctx->state[4] = SHA224_H4;\n\tsctx->state[5] = SHA224_H5;\n\tsctx->state[6] = SHA224_H6;\n\tsctx->state[7] = SHA224_H7;\n\tsctx->count = 0;\n\tsctx->func = KIMD_SHA_256;\n\n\treturn 0;\n}\n\nstatic struct shash_alg sha224_alg = {\n\t.digestsize\t=\tSHA224_DIGEST_SIZE,\n\t.init\t\t=\tsha224_init,\n\t.update\t\t=\ts390_sha_update,\n\t.final\t\t=\ts390_sha_final,\n\t.export\t\t=\tsha256_export,\n\t.import\t\t=\tsha256_import,\n\t.descsize\t=\tsizeof(struct s390_sha_ctx),\n\t.statesize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha224\",\n\t\t.cra_driver_name=\t\"sha224-s390\",\n\t\t.cra_priority\t=\tCRYPT_S390_PRIORITY,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA224_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init sha256_s390_init(void)\n{\n\tint ret;\n\n\tif (!crypt_s390_func_available(KIMD_SHA_256, CRYPT_S390_MSA))\n\t\treturn -EOPNOTSUPP;\n\tret = crypto_register_shash(&sha256_alg);\n\tif (ret < 0)\n\t\tgoto out;\n\tret = crypto_register_shash(&sha224_alg);\n\tif (ret < 0)\n\t\tcrypto_unregister_shash(&sha256_alg);\nout:\n\treturn ret;\n}\n\nstatic void __exit sha256_s390_fini(void)\n{\n\tcrypto_unregister_shash(&sha224_alg);\n\tcrypto_unregister_shash(&sha256_alg);\n}\n\nmodule_init(sha256_s390_init);\nmodule_exit(sha256_s390_fini);\n\nMODULE_ALIAS_CRYPTO(\"sha256\");\nMODULE_ALIAS_CRYPTO(\"sha224\");\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA256 and SHA224 Secure Hash Algorithm\");\n", "/*\n * Cryptographic API.\n *\n * s390 implementation of the SHA512 and SHA38 Secure Hash Algorithm.\n *\n * Copyright IBM Corp. 2007\n * Author(s): Jan Glauber (jang@de.ibm.com)\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <crypto/sha.h>\n#include <linux/errno.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n\n#include \"sha.h\"\n#include \"crypt_s390.h\"\n\nstatic int sha512_init(struct shash_desc *desc)\n{\n\tstruct s390_sha_ctx *ctx = shash_desc_ctx(desc);\n\n\t*(__u64 *)&ctx->state[0] = 0x6a09e667f3bcc908ULL;\n\t*(__u64 *)&ctx->state[2] = 0xbb67ae8584caa73bULL;\n\t*(__u64 *)&ctx->state[4] = 0x3c6ef372fe94f82bULL;\n\t*(__u64 *)&ctx->state[6] = 0xa54ff53a5f1d36f1ULL;\n\t*(__u64 *)&ctx->state[8] = 0x510e527fade682d1ULL;\n\t*(__u64 *)&ctx->state[10] = 0x9b05688c2b3e6c1fULL;\n\t*(__u64 *)&ctx->state[12] = 0x1f83d9abfb41bd6bULL;\n\t*(__u64 *)&ctx->state[14] = 0x5be0cd19137e2179ULL;\n\tctx->count = 0;\n\tctx->func = KIMD_SHA_512;\n\n\treturn 0;\n}\n\nstatic int sha512_export(struct shash_desc *desc, void *out)\n{\n\tstruct s390_sha_ctx *sctx = shash_desc_ctx(desc);\n\tstruct sha512_state *octx = out;\n\n\toctx->count[0] = sctx->count;\n\toctx->count[1] = 0;\n\tmemcpy(octx->state, sctx->state, sizeof(octx->state));\n\tmemcpy(octx->buf, sctx->buf, sizeof(octx->buf));\n\treturn 0;\n}\n\nstatic int sha512_import(struct shash_desc *desc, const void *in)\n{\n\tstruct s390_sha_ctx *sctx = shash_desc_ctx(desc);\n\tconst struct sha512_state *ictx = in;\n\n\tif (unlikely(ictx->count[1]))\n\t\treturn -ERANGE;\n\tsctx->count = ictx->count[0];\n\n\tmemcpy(sctx->state, ictx->state, sizeof(ictx->state));\n\tmemcpy(sctx->buf, ictx->buf, sizeof(ictx->buf));\n\tsctx->func = KIMD_SHA_512;\n\treturn 0;\n}\n\nstatic struct shash_alg sha512_alg = {\n\t.digestsize\t=\tSHA512_DIGEST_SIZE,\n\t.init\t\t=\tsha512_init,\n\t.update\t\t=\ts390_sha_update,\n\t.final\t\t=\ts390_sha_final,\n\t.export\t\t=\tsha512_export,\n\t.import\t\t=\tsha512_import,\n\t.descsize\t=\tsizeof(struct s390_sha_ctx),\n\t.statesize\t=\tsizeof(struct sha512_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha512\",\n\t\t.cra_driver_name=\t\"sha512-s390\",\n\t\t.cra_priority\t=\tCRYPT_S390_PRIORITY,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA512_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nMODULE_ALIAS_CRYPTO(\"sha512\");\n\nstatic int sha384_init(struct shash_desc *desc)\n{\n\tstruct s390_sha_ctx *ctx = shash_desc_ctx(desc);\n\n\t*(__u64 *)&ctx->state[0] = 0xcbbb9d5dc1059ed8ULL;\n\t*(__u64 *)&ctx->state[2] = 0x629a292a367cd507ULL;\n\t*(__u64 *)&ctx->state[4] = 0x9159015a3070dd17ULL;\n\t*(__u64 *)&ctx->state[6] = 0x152fecd8f70e5939ULL;\n\t*(__u64 *)&ctx->state[8] = 0x67332667ffc00b31ULL;\n\t*(__u64 *)&ctx->state[10] = 0x8eb44a8768581511ULL;\n\t*(__u64 *)&ctx->state[12] = 0xdb0c2e0d64f98fa7ULL;\n\t*(__u64 *)&ctx->state[14] = 0x47b5481dbefa4fa4ULL;\n\tctx->count = 0;\n\tctx->func = KIMD_SHA_512;\n\n\treturn 0;\n}\n\nstatic struct shash_alg sha384_alg = {\n\t.digestsize\t=\tSHA384_DIGEST_SIZE,\n\t.init\t\t=\tsha384_init,\n\t.update\t\t=\ts390_sha_update,\n\t.final\t\t=\ts390_sha_final,\n\t.export\t\t=\tsha512_export,\n\t.import\t\t=\tsha512_import,\n\t.descsize\t=\tsizeof(struct s390_sha_ctx),\n\t.statesize\t=\tsizeof(struct sha512_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha384\",\n\t\t.cra_driver_name=\t\"sha384-s390\",\n\t\t.cra_priority\t=\tCRYPT_S390_PRIORITY,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA384_BLOCK_SIZE,\n\t\t.cra_ctxsize\t=\tsizeof(struct s390_sha_ctx),\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nMODULE_ALIAS_CRYPTO(\"sha384\");\n\nstatic int __init init(void)\n{\n\tint ret;\n\n\tif (!crypt_s390_func_available(KIMD_SHA_512, CRYPT_S390_MSA))\n\t\treturn -EOPNOTSUPP;\n\tif ((ret = crypto_register_shash(&sha512_alg)) < 0)\n\t\tgoto out;\n\tif ((ret = crypto_register_shash(&sha384_alg)) < 0)\n\t\tcrypto_unregister_shash(&sha512_alg);\nout:\n\treturn ret;\n}\n\nstatic void __exit fini(void)\n{\n\tcrypto_unregister_shash(&sha512_alg);\n\tcrypto_unregister_shash(&sha384_alg);\n}\n\nmodule_init(init);\nmodule_exit(fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA512 and SHA-384 Secure Hash Algorithm\");\n", "/* Glue code for AES encryption optimized for sparc64 crypto opcodes.\n *\n * This is based largely upon arch/x86/crypto/aesni-intel_glue.c\n *\n * Copyright (C) 2008, Intel Corp.\n *    Author: Huang Ying <ying.huang@intel.com>\n *\n * Added RFC4106 AES-GCM support for 128-bit keys under the AEAD\n * interface for 64-bit kernels.\n *    Authors: Adrian Hoban <adrian.hoban@intel.com>\n *             Gabriele Paoloni <gabriele.paoloni@intel.com>\n *             Tadeusz Struk (tadeusz.struk@intel.com)\n *             Aidan O'Mahony (aidan.o.mahony@intel.com)\n *    Copyright (c) 2010, Intel Corporation.\n */\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <linux/crypto.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/types.h>\n#include <crypto/algapi.h>\n#include <crypto/aes.h>\n\n#include <asm/fpumacro.h>\n#include <asm/pstate.h>\n#include <asm/elf.h>\n\n#include \"opcodes.h\"\n\nstruct aes_ops {\n\tvoid (*encrypt)(const u64 *key, const u32 *input, u32 *output);\n\tvoid (*decrypt)(const u64 *key, const u32 *input, u32 *output);\n\tvoid (*load_encrypt_keys)(const u64 *key);\n\tvoid (*load_decrypt_keys)(const u64 *key);\n\tvoid (*ecb_encrypt)(const u64 *key, const u64 *input, u64 *output,\n\t\t\t    unsigned int len);\n\tvoid (*ecb_decrypt)(const u64 *key, const u64 *input, u64 *output,\n\t\t\t    unsigned int len);\n\tvoid (*cbc_encrypt)(const u64 *key, const u64 *input, u64 *output,\n\t\t\t    unsigned int len, u64 *iv);\n\tvoid (*cbc_decrypt)(const u64 *key, const u64 *input, u64 *output,\n\t\t\t    unsigned int len, u64 *iv);\n\tvoid (*ctr_crypt)(const u64 *key, const u64 *input, u64 *output,\n\t\t\t  unsigned int len, u64 *iv);\n};\n\nstruct crypto_sparc64_aes_ctx {\n\tstruct aes_ops *ops;\n\tu64 key[AES_MAX_KEYLENGTH / sizeof(u64)];\n\tu32 key_length;\n\tu32 expanded_key_length;\n};\n\nextern void aes_sparc64_encrypt_128(const u64 *key, const u32 *input,\n\t\t\t\t    u32 *output);\nextern void aes_sparc64_encrypt_192(const u64 *key, const u32 *input,\n\t\t\t\t    u32 *output);\nextern void aes_sparc64_encrypt_256(const u64 *key, const u32 *input,\n\t\t\t\t    u32 *output);\n\nextern void aes_sparc64_decrypt_128(const u64 *key, const u32 *input,\n\t\t\t\t    u32 *output);\nextern void aes_sparc64_decrypt_192(const u64 *key, const u32 *input,\n\t\t\t\t    u32 *output);\nextern void aes_sparc64_decrypt_256(const u64 *key, const u32 *input,\n\t\t\t\t    u32 *output);\n\nextern void aes_sparc64_load_encrypt_keys_128(const u64 *key);\nextern void aes_sparc64_load_encrypt_keys_192(const u64 *key);\nextern void aes_sparc64_load_encrypt_keys_256(const u64 *key);\n\nextern void aes_sparc64_load_decrypt_keys_128(const u64 *key);\nextern void aes_sparc64_load_decrypt_keys_192(const u64 *key);\nextern void aes_sparc64_load_decrypt_keys_256(const u64 *key);\n\nextern void aes_sparc64_ecb_encrypt_128(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len);\nextern void aes_sparc64_ecb_encrypt_192(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len);\nextern void aes_sparc64_ecb_encrypt_256(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len);\n\nextern void aes_sparc64_ecb_decrypt_128(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len);\nextern void aes_sparc64_ecb_decrypt_192(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len);\nextern void aes_sparc64_ecb_decrypt_256(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len);\n\nextern void aes_sparc64_cbc_encrypt_128(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len,\n\t\t\t\t\tu64 *iv);\n\nextern void aes_sparc64_cbc_encrypt_192(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len,\n\t\t\t\t\tu64 *iv);\n\nextern void aes_sparc64_cbc_encrypt_256(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len,\n\t\t\t\t\tu64 *iv);\n\nextern void aes_sparc64_cbc_decrypt_128(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len,\n\t\t\t\t\tu64 *iv);\n\nextern void aes_sparc64_cbc_decrypt_192(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len,\n\t\t\t\t\tu64 *iv);\n\nextern void aes_sparc64_cbc_decrypt_256(const u64 *key, const u64 *input,\n\t\t\t\t\tu64 *output, unsigned int len,\n\t\t\t\t\tu64 *iv);\n\nextern void aes_sparc64_ctr_crypt_128(const u64 *key, const u64 *input,\n\t\t\t\t      u64 *output, unsigned int len,\n\t\t\t\t      u64 *iv);\nextern void aes_sparc64_ctr_crypt_192(const u64 *key, const u64 *input,\n\t\t\t\t      u64 *output, unsigned int len,\n\t\t\t\t      u64 *iv);\nextern void aes_sparc64_ctr_crypt_256(const u64 *key, const u64 *input,\n\t\t\t\t      u64 *output, unsigned int len,\n\t\t\t\t      u64 *iv);\n\nstatic struct aes_ops aes128_ops = {\n\t.encrypt\t\t= aes_sparc64_encrypt_128,\n\t.decrypt\t\t= aes_sparc64_decrypt_128,\n\t.load_encrypt_keys\t= aes_sparc64_load_encrypt_keys_128,\n\t.load_decrypt_keys\t= aes_sparc64_load_decrypt_keys_128,\n\t.ecb_encrypt\t\t= aes_sparc64_ecb_encrypt_128,\n\t.ecb_decrypt\t\t= aes_sparc64_ecb_decrypt_128,\n\t.cbc_encrypt\t\t= aes_sparc64_cbc_encrypt_128,\n\t.cbc_decrypt\t\t= aes_sparc64_cbc_decrypt_128,\n\t.ctr_crypt\t\t= aes_sparc64_ctr_crypt_128,\n};\n\nstatic struct aes_ops aes192_ops = {\n\t.encrypt\t\t= aes_sparc64_encrypt_192,\n\t.decrypt\t\t= aes_sparc64_decrypt_192,\n\t.load_encrypt_keys\t= aes_sparc64_load_encrypt_keys_192,\n\t.load_decrypt_keys\t= aes_sparc64_load_decrypt_keys_192,\n\t.ecb_encrypt\t\t= aes_sparc64_ecb_encrypt_192,\n\t.ecb_decrypt\t\t= aes_sparc64_ecb_decrypt_192,\n\t.cbc_encrypt\t\t= aes_sparc64_cbc_encrypt_192,\n\t.cbc_decrypt\t\t= aes_sparc64_cbc_decrypt_192,\n\t.ctr_crypt\t\t= aes_sparc64_ctr_crypt_192,\n};\n\nstatic struct aes_ops aes256_ops = {\n\t.encrypt\t\t= aes_sparc64_encrypt_256,\n\t.decrypt\t\t= aes_sparc64_decrypt_256,\n\t.load_encrypt_keys\t= aes_sparc64_load_encrypt_keys_256,\n\t.load_decrypt_keys\t= aes_sparc64_load_decrypt_keys_256,\n\t.ecb_encrypt\t\t= aes_sparc64_ecb_encrypt_256,\n\t.ecb_decrypt\t\t= aes_sparc64_ecb_decrypt_256,\n\t.cbc_encrypt\t\t= aes_sparc64_cbc_encrypt_256,\n\t.cbc_decrypt\t\t= aes_sparc64_cbc_decrypt_256,\n\t.ctr_crypt\t\t= aes_sparc64_ctr_crypt_256,\n};\n\nextern void aes_sparc64_key_expand(const u32 *in_key, u64 *output_key,\n\t\t\t\t   unsigned int key_len);\n\nstatic int aes_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t       unsigned int key_len)\n{\n\tstruct crypto_sparc64_aes_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\n\tswitch (key_len) {\n\tcase AES_KEYSIZE_128:\n\t\tctx->expanded_key_length = 0xb0;\n\t\tctx->ops = &aes128_ops;\n\t\tbreak;\n\n\tcase AES_KEYSIZE_192:\n\t\tctx->expanded_key_length = 0xd0;\n\t\tctx->ops = &aes192_ops;\n\t\tbreak;\n\n\tcase AES_KEYSIZE_256:\n\t\tctx->expanded_key_length = 0xf0;\n\t\tctx->ops = &aes256_ops;\n\t\tbreak;\n\n\tdefault:\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\taes_sparc64_key_expand((const u32 *)in_key, &ctx->key[0], key_len);\n\tctx->key_length = key_len;\n\n\treturn 0;\n}\n\nstatic void aes_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct crypto_sparc64_aes_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tctx->ops->encrypt(&ctx->key[0], (const u32 *) src, (u32 *) dst);\n}\n\nstatic void aes_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct crypto_sparc64_aes_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tctx->ops->decrypt(&ctx->key[0], (const u32 *) src, (u32 *) dst);\n}\n\n#define AES_BLOCK_MASK\t(~(AES_BLOCK_SIZE-1))\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct crypto_sparc64_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tctx->ops->load_encrypt_keys(&ctx->key[0]);\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & AES_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tctx->ops->ecb_encrypt(&ctx->key[0],\n\t\t\t\t\t      (const u64 *)walk.src.virt.addr,\n\t\t\t\t\t      (u64 *) walk.dst.virt.addr,\n\t\t\t\t\t      block_len);\n\t\t}\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct crypto_sparc64_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tu64 *key_end;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tctx->ops->load_decrypt_keys(&ctx->key[0]);\n\tkey_end = &ctx->key[ctx->expanded_key_length / sizeof(u64)];\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & AES_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tctx->ops->ecb_decrypt(key_end,\n\t\t\t\t\t      (const u64 *) walk.src.virt.addr,\n\t\t\t\t\t      (u64 *) walk.dst.virt.addr, block_len);\n\t\t}\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\n\treturn err;\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct crypto_sparc64_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tctx->ops->load_encrypt_keys(&ctx->key[0]);\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & AES_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tctx->ops->cbc_encrypt(&ctx->key[0],\n\t\t\t\t\t      (const u64 *)walk.src.virt.addr,\n\t\t\t\t\t      (u64 *) walk.dst.virt.addr,\n\t\t\t\t\t      block_len, (u64 *) walk.iv);\n\t\t}\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct crypto_sparc64_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tu64 *key_end;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tctx->ops->load_decrypt_keys(&ctx->key[0]);\n\tkey_end = &ctx->key[ctx->expanded_key_length / sizeof(u64)];\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & AES_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tctx->ops->cbc_decrypt(key_end,\n\t\t\t\t\t      (const u64 *) walk.src.virt.addr,\n\t\t\t\t\t      (u64 *) walk.dst.virt.addr,\n\t\t\t\t\t      block_len, (u64 *) walk.iv);\n\t\t}\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\n\treturn err;\n}\n\nstatic void ctr_crypt_final(struct crypto_sparc64_aes_ctx *ctx,\n\t\t\t    struct blkcipher_walk *walk)\n{\n\tu8 *ctrblk = walk->iv;\n\tu64 keystream[AES_BLOCK_SIZE / sizeof(u64)];\n\tu8 *src = walk->src.virt.addr;\n\tu8 *dst = walk->dst.virt.addr;\n\tunsigned int nbytes = walk->nbytes;\n\n\tctx->ops->ecb_encrypt(&ctx->key[0], (const u64 *)ctrblk,\n\t\t\t      keystream, AES_BLOCK_SIZE);\n\tcrypto_xor((u8 *) keystream, src, nbytes);\n\tmemcpy(dst, keystream, nbytes);\n\tcrypto_inc(ctrblk, AES_BLOCK_SIZE);\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc,\n\t\t     struct scatterlist *dst, struct scatterlist *src,\n\t\t     unsigned int nbytes)\n{\n\tstruct crypto_sparc64_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt_block(desc, &walk, AES_BLOCK_SIZE);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tctx->ops->load_encrypt_keys(&ctx->key[0]);\n\twhile ((nbytes = walk.nbytes) >= AES_BLOCK_SIZE) {\n\t\tunsigned int block_len = nbytes & AES_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tctx->ops->ctr_crypt(&ctx->key[0],\n\t\t\t\t\t    (const u64 *)walk.src.virt.addr,\n\t\t\t\t\t    (u64 *) walk.dst.virt.addr,\n\t\t\t\t\t    block_len, (u64 *) walk.iv);\n\t\t}\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tif (walk.nbytes) {\n\t\tctr_crypt_final(ctx, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, 0);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nstatic struct crypto_alg algs[] = { {\n\t.cra_name\t\t= \"aes\",\n\t.cra_driver_name\t= \"aes-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_sparc64_aes_ctx),\n\t.cra_alignmask\t\t= 3,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u\t= {\n\t\t.cipher\t= {\n\t\t\t.cia_min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t= aes_set_key,\n\t\t\t.cia_encrypt\t\t= aes_encrypt,\n\t\t\t.cia_decrypt\t\t= aes_decrypt\n\t\t}\n\t}\n}, {\n\t.cra_name\t\t= \"ecb(aes)\",\n\t.cra_driver_name\t= \"ecb-aes-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_sparc64_aes_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= aes_set_key,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(aes)\",\n\t.cra_driver_name\t= \"cbc-aes-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_sparc64_aes_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= aes_set_key,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(aes)\",\n\t.cra_driver_name\t= \"ctr-aes-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_sparc64_aes_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= aes_set_key,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n} };\n\nstatic bool __init sparc64_has_aes_opcode(void)\n{\n\tunsigned long cfr;\n\n\tif (!(sparc64_elf_hwcap & HWCAP_SPARC_CRYPTO))\n\t\treturn false;\n\n\t__asm__ __volatile__(\"rd %%asr26, %0\" : \"=r\" (cfr));\n\tif (!(cfr & CFR_AES))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int __init aes_sparc64_mod_init(void)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(algs); i++)\n\t\tINIT_LIST_HEAD(&algs[i].cra_list);\n\n\tif (sparc64_has_aes_opcode()) {\n\t\tpr_info(\"Using sparc64 aes opcodes optimized AES implementation\\n\");\n\t\treturn crypto_register_algs(algs, ARRAY_SIZE(algs));\n\t}\n\tpr_info(\"sparc64 aes opcodes not available.\\n\");\n\treturn -ENODEV;\n}\n\nstatic void __exit aes_sparc64_mod_fini(void)\n{\n\tcrypto_unregister_algs(algs, ARRAY_SIZE(algs));\n}\n\nmodule_init(aes_sparc64_mod_init);\nmodule_exit(aes_sparc64_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"AES Secure Hash Algorithm, sparc64 aes opcode accelerated\");\n\nMODULE_ALIAS_CRYPTO(\"aes\");\n\n#include \"crop_devid.c\"\n", "/* Glue code for CAMELLIA encryption optimized for sparc64 crypto opcodes.\n *\n * Copyright (C) 2012 David S. Miller <davem@davemloft.net>\n */\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <linux/crypto.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/types.h>\n#include <crypto/algapi.h>\n\n#include <asm/fpumacro.h>\n#include <asm/pstate.h>\n#include <asm/elf.h>\n\n#include \"opcodes.h\"\n\n#define CAMELLIA_MIN_KEY_SIZE        16\n#define CAMELLIA_MAX_KEY_SIZE        32\n#define CAMELLIA_BLOCK_SIZE          16\n#define CAMELLIA_TABLE_BYTE_LEN     272\n\nstruct camellia_sparc64_ctx {\n\tu64 encrypt_key[CAMELLIA_TABLE_BYTE_LEN / sizeof(u64)];\n\tu64 decrypt_key[CAMELLIA_TABLE_BYTE_LEN / sizeof(u64)];\n\tint key_len;\n};\n\nextern void camellia_sparc64_key_expand(const u32 *in_key, u64 *encrypt_key,\n\t\t\t\t\tunsigned int key_len, u64 *decrypt_key);\n\nstatic int camellia_set_key(struct crypto_tfm *tfm, const u8 *_in_key,\n\t\t\t    unsigned int key_len)\n{\n\tstruct camellia_sparc64_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst u32 *in_key = (const u32 *) _in_key;\n\tu32 *flags = &tfm->crt_flags;\n\n\tif (key_len != 16 && key_len != 24 && key_len != 32) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\tctx->key_len = key_len;\n\n\tcamellia_sparc64_key_expand(in_key, &ctx->encrypt_key[0],\n\t\t\t\t    key_len, &ctx->decrypt_key[0]);\n\treturn 0;\n}\n\nextern void camellia_sparc64_crypt(const u64 *key, const u32 *input,\n\t\t\t\t   u32 *output, unsigned int key_len);\n\nstatic void camellia_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct camellia_sparc64_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcamellia_sparc64_crypt(&ctx->encrypt_key[0],\n\t\t\t       (const u32 *) src,\n\t\t\t       (u32 *) dst, ctx->key_len);\n}\n\nstatic void camellia_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct camellia_sparc64_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcamellia_sparc64_crypt(&ctx->decrypt_key[0],\n\t\t\t       (const u32 *) src,\n\t\t\t       (u32 *) dst, ctx->key_len);\n}\n\nextern void camellia_sparc64_load_keys(const u64 *key, unsigned int key_len);\n\ntypedef void ecb_crypt_op(const u64 *input, u64 *output, unsigned int len,\n\t\t\t  const u64 *key);\n\nextern ecb_crypt_op camellia_sparc64_ecb_crypt_3_grand_rounds;\nextern ecb_crypt_op camellia_sparc64_ecb_crypt_4_grand_rounds;\n\n#define CAMELLIA_BLOCK_MASK\t(~(CAMELLIA_BLOCK_SIZE - 1))\n\nstatic int __ecb_crypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes, bool encrypt)\n{\n\tstruct camellia_sparc64_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tecb_crypt_op *op;\n\tconst u64 *key;\n\tint err;\n\n\top = camellia_sparc64_ecb_crypt_3_grand_rounds;\n\tif (ctx->key_len != 16)\n\t\top = camellia_sparc64_ecb_crypt_4_grand_rounds;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tif (encrypt)\n\t\tkey = &ctx->encrypt_key[0];\n\telse\n\t\tkey = &ctx->decrypt_key[0];\n\tcamellia_sparc64_load_keys(key, ctx->key_len);\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & CAMELLIA_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tconst u64 *src64;\n\t\t\tu64 *dst64;\n\n\t\t\tsrc64 = (const u64 *)walk.src.virt.addr;\n\t\t\tdst64 = (u64 *) walk.dst.virt.addr;\n\t\t\top(src64, dst64, block_len, key);\n\t\t}\n\t\tnbytes &= CAMELLIA_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\treturn __ecb_crypt(desc, dst, src, nbytes, true);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\treturn __ecb_crypt(desc, dst, src, nbytes, false);\n}\n\ntypedef void cbc_crypt_op(const u64 *input, u64 *output, unsigned int len,\n\t\t\t  const u64 *key, u64 *iv);\n\nextern cbc_crypt_op camellia_sparc64_cbc_encrypt_3_grand_rounds;\nextern cbc_crypt_op camellia_sparc64_cbc_encrypt_4_grand_rounds;\nextern cbc_crypt_op camellia_sparc64_cbc_decrypt_3_grand_rounds;\nextern cbc_crypt_op camellia_sparc64_cbc_decrypt_4_grand_rounds;\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct camellia_sparc64_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tcbc_crypt_op *op;\n\tconst u64 *key;\n\tint err;\n\n\top = camellia_sparc64_cbc_encrypt_3_grand_rounds;\n\tif (ctx->key_len != 16)\n\t\top = camellia_sparc64_cbc_encrypt_4_grand_rounds;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tkey = &ctx->encrypt_key[0];\n\tcamellia_sparc64_load_keys(key, ctx->key_len);\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & CAMELLIA_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tconst u64 *src64;\n\t\t\tu64 *dst64;\n\n\t\t\tsrc64 = (const u64 *)walk.src.virt.addr;\n\t\t\tdst64 = (u64 *) walk.dst.virt.addr;\n\t\t\top(src64, dst64, block_len, key,\n\t\t\t   (u64 *) walk.iv);\n\t\t}\n\t\tnbytes &= CAMELLIA_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct camellia_sparc64_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tcbc_crypt_op *op;\n\tconst u64 *key;\n\tint err;\n\n\top = camellia_sparc64_cbc_decrypt_3_grand_rounds;\n\tif (ctx->key_len != 16)\n\t\top = camellia_sparc64_cbc_decrypt_4_grand_rounds;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tkey = &ctx->decrypt_key[0];\n\tcamellia_sparc64_load_keys(key, ctx->key_len);\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & CAMELLIA_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tconst u64 *src64;\n\t\t\tu64 *dst64;\n\n\t\t\tsrc64 = (const u64 *)walk.src.virt.addr;\n\t\t\tdst64 = (u64 *) walk.dst.virt.addr;\n\t\t\top(src64, dst64, block_len, key,\n\t\t\t   (u64 *) walk.iv);\n\t\t}\n\t\tnbytes &= CAMELLIA_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nstatic struct crypto_alg algs[] = { {\n\t.cra_name\t\t= \"camellia\",\n\t.cra_driver_name\t= \"camellia-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_sparc64_ctx),\n\t.cra_alignmask\t\t= 3,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u\t= {\n\t\t.cipher\t= {\n\t\t\t.cia_min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t= camellia_set_key,\n\t\t\t.cia_encrypt\t\t= camellia_encrypt,\n\t\t\t.cia_decrypt\t\t= camellia_decrypt\n\t\t}\n\t}\n}, {\n\t.cra_name\t\t= \"ecb(camellia)\",\n\t.cra_driver_name\t= \"ecb-camellia-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_sparc64_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= camellia_set_key,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(camellia)\",\n\t.cra_driver_name\t= \"cbc-camellia-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_sparc64_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= camellia_set_key,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}\n};\n\nstatic bool __init sparc64_has_camellia_opcode(void)\n{\n\tunsigned long cfr;\n\n\tif (!(sparc64_elf_hwcap & HWCAP_SPARC_CRYPTO))\n\t\treturn false;\n\n\t__asm__ __volatile__(\"rd %%asr26, %0\" : \"=r\" (cfr));\n\tif (!(cfr & CFR_CAMELLIA))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int __init camellia_sparc64_mod_init(void)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(algs); i++)\n\t\tINIT_LIST_HEAD(&algs[i].cra_list);\n\n\tif (sparc64_has_camellia_opcode()) {\n\t\tpr_info(\"Using sparc64 camellia opcodes optimized CAMELLIA implementation\\n\");\n\t\treturn crypto_register_algs(algs, ARRAY_SIZE(algs));\n\t}\n\tpr_info(\"sparc64 camellia opcodes not available.\\n\");\n\treturn -ENODEV;\n}\n\nstatic void __exit camellia_sparc64_mod_fini(void)\n{\n\tcrypto_unregister_algs(algs, ARRAY_SIZE(algs));\n}\n\nmodule_init(camellia_sparc64_mod_init);\nmodule_exit(camellia_sparc64_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Camellia Cipher Algorithm, sparc64 camellia opcode accelerated\");\n\nMODULE_ALIAS_CRYPTO(\"aes\");\n\n#include \"crop_devid.c\"\n", "/* Glue code for CRC32C optimized for sparc64 crypto opcodes.\n *\n * This is based largely upon arch/x86/crypto/crc32c-intel.c\n *\n * Copyright (C) 2008 Intel Corporation\n * Authors: Austin Zhang <austin_zhang@linux.intel.com>\n *          Kent Liu <kent.liu@intel.com>\n */\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n#include <linux/crc32.h>\n\n#include <crypto/internal/hash.h>\n\n#include <asm/pstate.h>\n#include <asm/elf.h>\n\n#include \"opcodes.h\"\n\n/*\n * Setting the seed allows arbitrary accumulators and flexible XOR policy\n * If your algorithm starts with ~0, then XOR with ~0 before you set\n * the seed.\n */\nstatic int crc32c_sparc64_setkey(struct crypto_shash *hash, const u8 *key,\n\t\t\t\t unsigned int keylen)\n{\n\tu32 *mctx = crypto_shash_ctx(hash);\n\n\tif (keylen != sizeof(u32)) {\n\t\tcrypto_shash_set_flags(hash, CRYPTO_TFM_RES_BAD_KEY_LEN);\n\t\treturn -EINVAL;\n\t}\n\t*(__le32 *)mctx = le32_to_cpup((__le32 *)key);\n\treturn 0;\n}\n\nstatic int crc32c_sparc64_init(struct shash_desc *desc)\n{\n\tu32 *mctx = crypto_shash_ctx(desc->tfm);\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t*crcp = *mctx;\n\n\treturn 0;\n}\n\nextern void crc32c_sparc64(u32 *crcp, const u64 *data, unsigned int len);\n\nstatic void crc32c_compute(u32 *crcp, const u64 *data, unsigned int len)\n{\n\tunsigned int asm_len;\n\n\tasm_len = len & ~7U;\n\tif (asm_len) {\n\t\tcrc32c_sparc64(crcp, data, asm_len);\n\t\tdata += asm_len / 8;\n\t\tlen -= asm_len;\n\t}\n\tif (len)\n\t\t*crcp = __crc32c_le(*crcp, (const unsigned char *) data, len);\n}\n\nstatic int crc32c_sparc64_update(struct shash_desc *desc, const u8 *data,\n\t\t\t\t unsigned int len)\n{\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\tcrc32c_compute(crcp, (const u64 *) data, len);\n\n\treturn 0;\n}\n\nstatic int __crc32c_sparc64_finup(u32 *crcp, const u8 *data, unsigned int len,\n\t\t\t\t  u8 *out)\n{\n\tu32 tmp = *crcp;\n\n\tcrc32c_compute(&tmp, (const u64 *) data, len);\n\n\t*(__le32 *) out = ~cpu_to_le32(tmp);\n\treturn 0;\n}\n\nstatic int crc32c_sparc64_finup(struct shash_desc *desc, const u8 *data,\n\t\t\t\tunsigned int len, u8 *out)\n{\n\treturn __crc32c_sparc64_finup(shash_desc_ctx(desc), data, len, out);\n}\n\nstatic int crc32c_sparc64_final(struct shash_desc *desc, u8 *out)\n{\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t*(__le32 *) out = ~cpu_to_le32p(crcp);\n\treturn 0;\n}\n\nstatic int crc32c_sparc64_digest(struct shash_desc *desc, const u8 *data,\n\t\t\t\t unsigned int len, u8 *out)\n{\n\treturn __crc32c_sparc64_finup(crypto_shash_ctx(desc->tfm), data, len,\n\t\t\t\t      out);\n}\n\nstatic int crc32c_sparc64_cra_init(struct crypto_tfm *tfm)\n{\n\tu32 *key = crypto_tfm_ctx(tfm);\n\n\t*key = ~0;\n\n\treturn 0;\n}\n\n#define CHKSUM_BLOCK_SIZE\t1\n#define CHKSUM_DIGEST_SIZE\t4\n\nstatic struct shash_alg alg = {\n\t.setkey\t\t\t=\tcrc32c_sparc64_setkey,\n\t.init\t\t\t=\tcrc32c_sparc64_init,\n\t.update\t\t\t=\tcrc32c_sparc64_update,\n\t.final\t\t\t=\tcrc32c_sparc64_final,\n\t.finup\t\t\t=\tcrc32c_sparc64_finup,\n\t.digest\t\t\t=\tcrc32c_sparc64_digest,\n\t.descsize\t\t=\tsizeof(u32),\n\t.digestsize\t\t=\tCHKSUM_DIGEST_SIZE,\n\t.base\t\t\t=\t{\n\t\t.cra_name\t\t=\t\"crc32c\",\n\t\t.cra_driver_name\t=\t\"crc32c-sparc64\",\n\t\t.cra_priority\t\t=\tSPARC_CR_OPCODE_PRIORITY,\n\t\t.cra_blocksize\t\t=\tCHKSUM_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t=\tsizeof(u32),\n\t\t.cra_alignmask\t\t=\t7,\n\t\t.cra_module\t\t=\tTHIS_MODULE,\n\t\t.cra_init\t\t=\tcrc32c_sparc64_cra_init,\n\t}\n};\n\nstatic bool __init sparc64_has_crc32c_opcode(void)\n{\n\tunsigned long cfr;\n\n\tif (!(sparc64_elf_hwcap & HWCAP_SPARC_CRYPTO))\n\t\treturn false;\n\n\t__asm__ __volatile__(\"rd %%asr26, %0\" : \"=r\" (cfr));\n\tif (!(cfr & CFR_CRC32C))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int __init crc32c_sparc64_mod_init(void)\n{\n\tif (sparc64_has_crc32c_opcode()) {\n\t\tpr_info(\"Using sparc64 crc32c opcode optimized CRC32C implementation\\n\");\n\t\treturn crypto_register_shash(&alg);\n\t}\n\tpr_info(\"sparc64 crc32c opcode not available.\\n\");\n\treturn -ENODEV;\n}\n\nstatic void __exit crc32c_sparc64_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(crc32c_sparc64_mod_init);\nmodule_exit(crc32c_sparc64_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"CRC32c (Castagnoli), sparc64 crc32c opcode accelerated\");\n\nMODULE_ALIAS_CRYPTO(\"crc32c\");\n\n#include \"crop_devid.c\"\n", "/* Glue code for DES encryption optimized for sparc64 crypto opcodes.\n *\n * Copyright (C) 2012 David S. Miller <davem@davemloft.net>\n */\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <linux/crypto.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/types.h>\n#include <crypto/algapi.h>\n#include <crypto/des.h>\n\n#include <asm/fpumacro.h>\n#include <asm/pstate.h>\n#include <asm/elf.h>\n\n#include \"opcodes.h\"\n\nstruct des_sparc64_ctx {\n\tu64 encrypt_expkey[DES_EXPKEY_WORDS / 2];\n\tu64 decrypt_expkey[DES_EXPKEY_WORDS / 2];\n};\n\nstruct des3_ede_sparc64_ctx {\n\tu64 encrypt_expkey[DES3_EDE_EXPKEY_WORDS / 2];\n\tu64 decrypt_expkey[DES3_EDE_EXPKEY_WORDS / 2];\n};\n\nstatic void encrypt_to_decrypt(u64 *d, const u64 *e)\n{\n\tconst u64 *s = e + (DES_EXPKEY_WORDS / 2) - 1;\n\tint i;\n\n\tfor (i = 0; i < DES_EXPKEY_WORDS / 2; i++)\n\t\t*d++ = *s--;\n}\n\nextern void des_sparc64_key_expand(const u32 *input_key, u64 *key);\n\nstatic int des_set_key(struct crypto_tfm *tfm, const u8 *key,\n\t\t       unsigned int keylen)\n{\n\tstruct des_sparc64_ctx *dctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tu32 tmp[DES_EXPKEY_WORDS];\n\tint ret;\n\n\t/* Even though we have special instructions for key expansion,\n\t * we call des_ekey() so that we don't have to write our own\n\t * weak key detection code.\n\t */\n\tret = des_ekey(tmp, key);\n\tif (unlikely(ret == 0) && (*flags & CRYPTO_TFM_REQ_WEAK_KEY)) {\n\t\t*flags |= CRYPTO_TFM_RES_WEAK_KEY;\n\t\treturn -EINVAL;\n\t}\n\n\tdes_sparc64_key_expand((const u32 *) key, &dctx->encrypt_expkey[0]);\n\tencrypt_to_decrypt(&dctx->decrypt_expkey[0], &dctx->encrypt_expkey[0]);\n\n\treturn 0;\n}\n\nextern void des_sparc64_crypt(const u64 *key, const u64 *input,\n\t\t\t      u64 *output);\n\nstatic void des_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct des_sparc64_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst u64 *K = ctx->encrypt_expkey;\n\n\tdes_sparc64_crypt(K, (const u64 *) src, (u64 *) dst);\n}\n\nstatic void des_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct des_sparc64_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst u64 *K = ctx->decrypt_expkey;\n\n\tdes_sparc64_crypt(K, (const u64 *) src, (u64 *) dst);\n}\n\nextern void des_sparc64_load_keys(const u64 *key);\n\nextern void des_sparc64_ecb_crypt(const u64 *input, u64 *output,\n\t\t\t\t  unsigned int len);\n\n#define DES_BLOCK_MASK\t(~(DES_BLOCK_SIZE - 1))\n\nstatic int __ecb_crypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes, bool encrypt)\n{\n\tstruct des_sparc64_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tif (encrypt)\n\t\tdes_sparc64_load_keys(&ctx->encrypt_expkey[0]);\n\telse\n\t\tdes_sparc64_load_keys(&ctx->decrypt_expkey[0]);\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & DES_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tdes_sparc64_ecb_crypt((const u64 *)walk.src.virt.addr,\n\t\t\t\t\t      (u64 *) walk.dst.virt.addr,\n\t\t\t\t\t      block_len);\n\t\t}\n\t\tnbytes &= DES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\treturn __ecb_crypt(desc, dst, src, nbytes, true);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\treturn __ecb_crypt(desc, dst, src, nbytes, false);\n}\n\nextern void des_sparc64_cbc_encrypt(const u64 *input, u64 *output,\n\t\t\t\t    unsigned int len, u64 *iv);\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct des_sparc64_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tdes_sparc64_load_keys(&ctx->encrypt_expkey[0]);\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & DES_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tdes_sparc64_cbc_encrypt((const u64 *)walk.src.virt.addr,\n\t\t\t\t\t\t(u64 *) walk.dst.virt.addr,\n\t\t\t\t\t\tblock_len, (u64 *) walk.iv);\n\t\t}\n\t\tnbytes &= DES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nextern void des_sparc64_cbc_decrypt(const u64 *input, u64 *output,\n\t\t\t\t    unsigned int len, u64 *iv);\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct des_sparc64_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tdes_sparc64_load_keys(&ctx->decrypt_expkey[0]);\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & DES_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tdes_sparc64_cbc_decrypt((const u64 *)walk.src.virt.addr,\n\t\t\t\t\t\t(u64 *) walk.dst.virt.addr,\n\t\t\t\t\t\tblock_len, (u64 *) walk.iv);\n\t\t}\n\t\tnbytes &= DES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nstatic int des3_ede_set_key(struct crypto_tfm *tfm, const u8 *key,\n\t\t\t    unsigned int keylen)\n{\n\tstruct des3_ede_sparc64_ctx *dctx = crypto_tfm_ctx(tfm);\n\tconst u32 *K = (const u32 *)key;\n\tu32 *flags = &tfm->crt_flags;\n\tu64 k1[DES_EXPKEY_WORDS / 2];\n\tu64 k2[DES_EXPKEY_WORDS / 2];\n\tu64 k3[DES_EXPKEY_WORDS / 2];\n\n\tif (unlikely(!((K[0] ^ K[2]) | (K[1] ^ K[3])) ||\n\t\t     !((K[2] ^ K[4]) | (K[3] ^ K[5]))) &&\n\t\t     (*flags & CRYPTO_TFM_REQ_WEAK_KEY)) {\n\t\t*flags |= CRYPTO_TFM_RES_WEAK_KEY;\n\t\treturn -EINVAL;\n\t}\n\n\tdes_sparc64_key_expand((const u32 *)key, k1);\n\tkey += DES_KEY_SIZE;\n\tdes_sparc64_key_expand((const u32 *)key, k2);\n\tkey += DES_KEY_SIZE;\n\tdes_sparc64_key_expand((const u32 *)key, k3);\n\n\tmemcpy(&dctx->encrypt_expkey[0], &k1[0], sizeof(k1));\n\tencrypt_to_decrypt(&dctx->encrypt_expkey[DES_EXPKEY_WORDS / 2], &k2[0]);\n\tmemcpy(&dctx->encrypt_expkey[(DES_EXPKEY_WORDS / 2) * 2],\n\t       &k3[0], sizeof(k3));\n\n\tencrypt_to_decrypt(&dctx->decrypt_expkey[0], &k3[0]);\n\tmemcpy(&dctx->decrypt_expkey[DES_EXPKEY_WORDS / 2],\n\t       &k2[0], sizeof(k2));\n\tencrypt_to_decrypt(&dctx->decrypt_expkey[(DES_EXPKEY_WORDS / 2) * 2],\n\t\t\t   &k1[0]);\n\n\treturn 0;\n}\n\nextern void des3_ede_sparc64_crypt(const u64 *key, const u64 *input,\n\t\t\t\t   u64 *output);\n\nstatic void des3_ede_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct des3_ede_sparc64_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst u64 *K = ctx->encrypt_expkey;\n\n\tdes3_ede_sparc64_crypt(K, (const u64 *) src, (u64 *) dst);\n}\n\nstatic void des3_ede_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct des3_ede_sparc64_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst u64 *K = ctx->decrypt_expkey;\n\n\tdes3_ede_sparc64_crypt(K, (const u64 *) src, (u64 *) dst);\n}\n\nextern void des3_ede_sparc64_load_keys(const u64 *key);\n\nextern void des3_ede_sparc64_ecb_crypt(const u64 *expkey, const u64 *input,\n\t\t\t\t       u64 *output, unsigned int len);\n\nstatic int __ecb3_crypt(struct blkcipher_desc *desc,\n\t\t\tstruct scatterlist *dst, struct scatterlist *src,\n\t\t\tunsigned int nbytes, bool encrypt)\n{\n\tstruct des3_ede_sparc64_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tconst u64 *K;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tif (encrypt)\n\t\tK = &ctx->encrypt_expkey[0];\n\telse\n\t\tK = &ctx->decrypt_expkey[0];\n\tdes3_ede_sparc64_load_keys(K);\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & DES_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tconst u64 *src64 = (const u64 *)walk.src.virt.addr;\n\t\t\tdes3_ede_sparc64_ecb_crypt(K, src64,\n\t\t\t\t\t\t   (u64 *) walk.dst.virt.addr,\n\t\t\t\t\t\t   block_len);\n\t\t}\n\t\tnbytes &= DES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nstatic int ecb3_encrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\treturn __ecb3_crypt(desc, dst, src, nbytes, true);\n}\n\nstatic int ecb3_decrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\treturn __ecb3_crypt(desc, dst, src, nbytes, false);\n}\n\nextern void des3_ede_sparc64_cbc_encrypt(const u64 *expkey, const u64 *input,\n\t\t\t\t\t u64 *output, unsigned int len,\n\t\t\t\t\t u64 *iv);\n\nstatic int cbc3_encrypt(struct blkcipher_desc *desc,\n\t\t\tstruct scatterlist *dst, struct scatterlist *src,\n\t\t\tunsigned int nbytes)\n{\n\tstruct des3_ede_sparc64_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tconst u64 *K;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tK = &ctx->encrypt_expkey[0];\n\tdes3_ede_sparc64_load_keys(K);\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & DES_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tconst u64 *src64 = (const u64 *)walk.src.virt.addr;\n\t\t\tdes3_ede_sparc64_cbc_encrypt(K, src64,\n\t\t\t\t\t\t     (u64 *) walk.dst.virt.addr,\n\t\t\t\t\t\t     block_len,\n\t\t\t\t\t\t     (u64 *) walk.iv);\n\t\t}\n\t\tnbytes &= DES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nextern void des3_ede_sparc64_cbc_decrypt(const u64 *expkey, const u64 *input,\n\t\t\t\t\t u64 *output, unsigned int len,\n\t\t\t\t\t u64 *iv);\n\nstatic int cbc3_decrypt(struct blkcipher_desc *desc,\n\t\t\tstruct scatterlist *dst, struct scatterlist *src,\n\t\t\tunsigned int nbytes)\n{\n\tstruct des3_ede_sparc64_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tconst u64 *K;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tK = &ctx->decrypt_expkey[0];\n\tdes3_ede_sparc64_load_keys(K);\n\twhile ((nbytes = walk.nbytes)) {\n\t\tunsigned int block_len = nbytes & DES_BLOCK_MASK;\n\n\t\tif (likely(block_len)) {\n\t\t\tconst u64 *src64 = (const u64 *)walk.src.virt.addr;\n\t\t\tdes3_ede_sparc64_cbc_decrypt(K, src64,\n\t\t\t\t\t\t     (u64 *) walk.dst.virt.addr,\n\t\t\t\t\t\t     block_len,\n\t\t\t\t\t\t     (u64 *) walk.iv);\n\t\t}\n\t\tnbytes &= DES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tfprs_write(0);\n\treturn err;\n}\n\nstatic struct crypto_alg algs[] = { {\n\t.cra_name\t\t= \"des\",\n\t.cra_driver_name\t= \"des-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= DES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct des_sparc64_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u\t= {\n\t\t.cipher\t= {\n\t\t\t.cia_min_keysize\t= DES_KEY_SIZE,\n\t\t\t.cia_max_keysize\t= DES_KEY_SIZE,\n\t\t\t.cia_setkey\t\t= des_set_key,\n\t\t\t.cia_encrypt\t\t= des_encrypt,\n\t\t\t.cia_decrypt\t\t= des_decrypt\n\t\t}\n\t}\n}, {\n\t.cra_name\t\t= \"ecb(des)\",\n\t.cra_driver_name\t= \"ecb-des-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= DES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct des_sparc64_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= DES_KEY_SIZE,\n\t\t\t.max_keysize\t= DES_KEY_SIZE,\n\t\t\t.setkey\t\t= des_set_key,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(des)\",\n\t.cra_driver_name\t= \"cbc-des-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= DES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct des_sparc64_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= DES_KEY_SIZE,\n\t\t\t.max_keysize\t= DES_KEY_SIZE,\n\t\t\t.setkey\t\t= des_set_key,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"des3_ede\",\n\t.cra_driver_name\t= \"des3_ede-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= DES3_EDE_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct des3_ede_sparc64_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u\t= {\n\t\t.cipher\t= {\n\t\t\t.cia_min_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.cia_max_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.cia_setkey\t\t= des3_ede_set_key,\n\t\t\t.cia_encrypt\t\t= des3_ede_encrypt,\n\t\t\t.cia_decrypt\t\t= des3_ede_decrypt\n\t\t}\n\t}\n}, {\n\t.cra_name\t\t= \"ecb(des3_ede)\",\n\t.cra_driver_name\t= \"ecb-des3_ede-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= DES3_EDE_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct des3_ede_sparc64_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.max_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.setkey\t\t= des3_ede_set_key,\n\t\t\t.encrypt\t= ecb3_encrypt,\n\t\t\t.decrypt\t= ecb3_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(des3_ede)\",\n\t.cra_driver_name\t= \"cbc-des3_ede-sparc64\",\n\t.cra_priority\t\t= SPARC_CR_OPCODE_PRIORITY,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= DES3_EDE_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct des3_ede_sparc64_ctx),\n\t.cra_alignmask\t\t= 7,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.max_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.setkey\t\t= des3_ede_set_key,\n\t\t\t.encrypt\t= cbc3_encrypt,\n\t\t\t.decrypt\t= cbc3_decrypt,\n\t\t},\n\t},\n} };\n\nstatic bool __init sparc64_has_des_opcode(void)\n{\n\tunsigned long cfr;\n\n\tif (!(sparc64_elf_hwcap & HWCAP_SPARC_CRYPTO))\n\t\treturn false;\n\n\t__asm__ __volatile__(\"rd %%asr26, %0\" : \"=r\" (cfr));\n\tif (!(cfr & CFR_DES))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int __init des_sparc64_mod_init(void)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(algs); i++)\n\t\tINIT_LIST_HEAD(&algs[i].cra_list);\n\n\tif (sparc64_has_des_opcode()) {\n\t\tpr_info(\"Using sparc64 des opcodes optimized DES implementation\\n\");\n\t\treturn crypto_register_algs(algs, ARRAY_SIZE(algs));\n\t}\n\tpr_info(\"sparc64 des opcodes not available.\\n\");\n\treturn -ENODEV;\n}\n\nstatic void __exit des_sparc64_mod_fini(void)\n{\n\tcrypto_unregister_algs(algs, ARRAY_SIZE(algs));\n}\n\nmodule_init(des_sparc64_mod_init);\nmodule_exit(des_sparc64_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"DES & Triple DES EDE Cipher Algorithms, sparc64 des opcode accelerated\");\n\nMODULE_ALIAS_CRYPTO(\"des\");\n\n#include \"crop_devid.c\"\n", "/* Glue code for MD5 hashing optimized for sparc64 crypto opcodes.\n *\n * This is based largely upon arch/x86/crypto/sha1_ssse3_glue.c\n * and crypto/md5.c which are:\n *\n * Copyright (c) Alan Smithee.\n * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n * Copyright (c) Jean-Francois Dive <jef@linuxbe.org>\n * Copyright (c) Mathias Krause <minipli@googlemail.com>\n * Copyright (c) Cryptoapi developers.\n * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>\n */\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <crypto/md5.h>\n\n#include <asm/pstate.h>\n#include <asm/elf.h>\n\n#include \"opcodes.h\"\n\nasmlinkage void md5_sparc64_transform(u32 *digest, const char *data,\n\t\t\t\t      unsigned int rounds);\n\nstatic int md5_sparc64_init(struct shash_desc *desc)\n{\n\tstruct md5_state *mctx = shash_desc_ctx(desc);\n\n\tmctx->hash[0] = cpu_to_le32(0x67452301);\n\tmctx->hash[1] = cpu_to_le32(0xefcdab89);\n\tmctx->hash[2] = cpu_to_le32(0x98badcfe);\n\tmctx->hash[3] = cpu_to_le32(0x10325476);\n\tmctx->byte_count = 0;\n\n\treturn 0;\n}\n\nstatic void __md5_sparc64_update(struct md5_state *sctx, const u8 *data,\n\t\t\t\t unsigned int len, unsigned int partial)\n{\n\tunsigned int done = 0;\n\n\tsctx->byte_count += len;\n\tif (partial) {\n\t\tdone = MD5_HMAC_BLOCK_SIZE - partial;\n\t\tmemcpy((u8 *)sctx->block + partial, data, done);\n\t\tmd5_sparc64_transform(sctx->hash, (u8 *)sctx->block, 1);\n\t}\n\tif (len - done >= MD5_HMAC_BLOCK_SIZE) {\n\t\tconst unsigned int rounds = (len - done) / MD5_HMAC_BLOCK_SIZE;\n\n\t\tmd5_sparc64_transform(sctx->hash, data + done, rounds);\n\t\tdone += rounds * MD5_HMAC_BLOCK_SIZE;\n\t}\n\n\tmemcpy(sctx->block, data + done, len - done);\n}\n\nstatic int md5_sparc64_update(struct shash_desc *desc, const u8 *data,\n\t\t\t      unsigned int len)\n{\n\tstruct md5_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial = sctx->byte_count % MD5_HMAC_BLOCK_SIZE;\n\n\t/* Handle the fast case right here */\n\tif (partial + len < MD5_HMAC_BLOCK_SIZE) {\n\t\tsctx->byte_count += len;\n\t\tmemcpy((u8 *)sctx->block + partial, data, len);\n\t} else\n\t\t__md5_sparc64_update(sctx, data, len, partial);\n\n\treturn 0;\n}\n\n/* Add padding and return the message digest. */\nstatic int md5_sparc64_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct md5_state *sctx = shash_desc_ctx(desc);\n\tunsigned int i, index, padlen;\n\tu32 *dst = (u32 *)out;\n\t__le64 bits;\n\tstatic const u8 padding[MD5_HMAC_BLOCK_SIZE] = { 0x80, };\n\n\tbits = cpu_to_le64(sctx->byte_count << 3);\n\n\t/* Pad out to 56 mod 64 and append length */\n\tindex = sctx->byte_count % MD5_HMAC_BLOCK_SIZE;\n\tpadlen = (index < 56) ? (56 - index) : ((MD5_HMAC_BLOCK_SIZE+56) - index);\n\n\t/* We need to fill a whole block for __md5_sparc64_update() */\n\tif (padlen <= 56) {\n\t\tsctx->byte_count += padlen;\n\t\tmemcpy((u8 *)sctx->block + index, padding, padlen);\n\t} else {\n\t\t__md5_sparc64_update(sctx, padding, padlen, index);\n\t}\n\t__md5_sparc64_update(sctx, (const u8 *)&bits, sizeof(bits), 56);\n\n\t/* Store state in digest */\n\tfor (i = 0; i < MD5_HASH_WORDS; i++)\n\t\tdst[i] = sctx->hash[i];\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int md5_sparc64_export(struct shash_desc *desc, void *out)\n{\n\tstruct md5_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int md5_sparc64_import(struct shash_desc *desc, const void *in)\n{\n\tstruct md5_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tMD5_DIGEST_SIZE,\n\t.init\t\t=\tmd5_sparc64_init,\n\t.update\t\t=\tmd5_sparc64_update,\n\t.final\t\t=\tmd5_sparc64_final,\n\t.export\t\t=\tmd5_sparc64_export,\n\t.import\t\t=\tmd5_sparc64_import,\n\t.descsize\t=\tsizeof(struct md5_state),\n\t.statesize\t=\tsizeof(struct md5_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"md5\",\n\t\t.cra_driver_name=\t\"md5-sparc64\",\n\t\t.cra_priority\t=\tSPARC_CR_OPCODE_PRIORITY,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tMD5_HMAC_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic bool __init sparc64_has_md5_opcode(void)\n{\n\tunsigned long cfr;\n\n\tif (!(sparc64_elf_hwcap & HWCAP_SPARC_CRYPTO))\n\t\treturn false;\n\n\t__asm__ __volatile__(\"rd %%asr26, %0\" : \"=r\" (cfr));\n\tif (!(cfr & CFR_MD5))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int __init md5_sparc64_mod_init(void)\n{\n\tif (sparc64_has_md5_opcode()) {\n\t\tpr_info(\"Using sparc64 md5 opcode optimized MD5 implementation\\n\");\n\t\treturn crypto_register_shash(&alg);\n\t}\n\tpr_info(\"sparc64 md5 opcode not available.\\n\");\n\treturn -ENODEV;\n}\n\nstatic void __exit md5_sparc64_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(md5_sparc64_mod_init);\nmodule_exit(md5_sparc64_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"MD5 Secure Hash Algorithm, sparc64 md5 opcode accelerated\");\n\nMODULE_ALIAS_CRYPTO(\"md5\");\n\n#include \"crop_devid.c\"\n", "/* Glue code for SHA1 hashing optimized for sparc64 crypto opcodes.\n *\n * This is based largely upon arch/x86/crypto/sha1_ssse3_glue.c\n *\n * Copyright (c) Alan Smithee.\n * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n * Copyright (c) Jean-Francois Dive <jef@linuxbe.org>\n * Copyright (c) Mathias Krause <minipli@googlemail.com>\n */\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n\n#include <asm/pstate.h>\n#include <asm/elf.h>\n\n#include \"opcodes.h\"\n\nasmlinkage void sha1_sparc64_transform(u32 *digest, const char *data,\n\t\t\t\t       unsigned int rounds);\n\nstatic int sha1_sparc64_init(struct shash_desc *desc)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\t*sctx = (struct sha1_state){\n\t\t.state = { SHA1_H0, SHA1_H1, SHA1_H2, SHA1_H3, SHA1_H4 },\n\t};\n\n\treturn 0;\n}\n\nstatic void __sha1_sparc64_update(struct sha1_state *sctx, const u8 *data,\n\t\t\t\t  unsigned int len, unsigned int partial)\n{\n\tunsigned int done = 0;\n\n\tsctx->count += len;\n\tif (partial) {\n\t\tdone = SHA1_BLOCK_SIZE - partial;\n\t\tmemcpy(sctx->buffer + partial, data, done);\n\t\tsha1_sparc64_transform(sctx->state, sctx->buffer, 1);\n\t}\n\tif (len - done >= SHA1_BLOCK_SIZE) {\n\t\tconst unsigned int rounds = (len - done) / SHA1_BLOCK_SIZE;\n\n\t\tsha1_sparc64_transform(sctx->state, data + done, rounds);\n\t\tdone += rounds * SHA1_BLOCK_SIZE;\n\t}\n\n\tmemcpy(sctx->buffer, data + done, len - done);\n}\n\nstatic int sha1_sparc64_update(struct shash_desc *desc, const u8 *data,\n\t\t\t       unsigned int len)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial = sctx->count % SHA1_BLOCK_SIZE;\n\n\t/* Handle the fast case right here */\n\tif (partial + len < SHA1_BLOCK_SIZE) {\n\t\tsctx->count += len;\n\t\tmemcpy(sctx->buffer + partial, data, len);\n\t} else\n\t\t__sha1_sparc64_update(sctx, data, len, partial);\n\n\treturn 0;\n}\n\n/* Add padding and return the message digest. */\nstatic int sha1_sparc64_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int i, index, padlen;\n\t__be32 *dst = (__be32 *)out;\n\t__be64 bits;\n\tstatic const u8 padding[SHA1_BLOCK_SIZE] = { 0x80, };\n\n\tbits = cpu_to_be64(sctx->count << 3);\n\n\t/* Pad out to 56 mod 64 and append length */\n\tindex = sctx->count % SHA1_BLOCK_SIZE;\n\tpadlen = (index < 56) ? (56 - index) : ((SHA1_BLOCK_SIZE+56) - index);\n\n\t/* We need to fill a whole block for __sha1_sparc64_update() */\n\tif (padlen <= 56) {\n\t\tsctx->count += padlen;\n\t\tmemcpy(sctx->buffer + index, padding, padlen);\n\t} else {\n\t\t__sha1_sparc64_update(sctx, padding, padlen, index);\n\t}\n\t__sha1_sparc64_update(sctx, (const u8 *)&bits, sizeof(bits), 56);\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 5; i++)\n\t\tdst[i] = cpu_to_be32(sctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha1_sparc64_export(struct shash_desc *desc, void *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha1_sparc64_import(struct shash_desc *desc, const void *in)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tSHA1_DIGEST_SIZE,\n\t.init\t\t=\tsha1_sparc64_init,\n\t.update\t\t=\tsha1_sparc64_update,\n\t.final\t\t=\tsha1_sparc64_final,\n\t.export\t\t=\tsha1_sparc64_export,\n\t.import\t\t=\tsha1_sparc64_import,\n\t.descsize\t=\tsizeof(struct sha1_state),\n\t.statesize\t=\tsizeof(struct sha1_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha1\",\n\t\t.cra_driver_name=\t\"sha1-sparc64\",\n\t\t.cra_priority\t=\tSPARC_CR_OPCODE_PRIORITY,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA1_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic bool __init sparc64_has_sha1_opcode(void)\n{\n\tunsigned long cfr;\n\n\tif (!(sparc64_elf_hwcap & HWCAP_SPARC_CRYPTO))\n\t\treturn false;\n\n\t__asm__ __volatile__(\"rd %%asr26, %0\" : \"=r\" (cfr));\n\tif (!(cfr & CFR_SHA1))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int __init sha1_sparc64_mod_init(void)\n{\n\tif (sparc64_has_sha1_opcode()) {\n\t\tpr_info(\"Using sparc64 sha1 opcode optimized SHA-1 implementation\\n\");\n\t\treturn crypto_register_shash(&alg);\n\t}\n\tpr_info(\"sparc64 sha1 opcode not available.\\n\");\n\treturn -ENODEV;\n}\n\nstatic void __exit sha1_sparc64_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(sha1_sparc64_mod_init);\nmodule_exit(sha1_sparc64_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA1 Secure Hash Algorithm, sparc64 sha1 opcode accelerated\");\n\nMODULE_ALIAS_CRYPTO(\"sha1\");\n\n#include \"crop_devid.c\"\n", "/* Glue code for SHA256 hashing optimized for sparc64 crypto opcodes.\n *\n * This is based largely upon crypto/sha256_generic.c\n *\n * Copyright (c) Jean-Luc Cooke <jlcooke@certainkey.com>\n * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>\n * SHA224 Support Copyright 2007 Intel Corporation <jonathan.lynch@intel.com>\n */\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n\n#include <asm/pstate.h>\n#include <asm/elf.h>\n\n#include \"opcodes.h\"\n\nasmlinkage void sha256_sparc64_transform(u32 *digest, const char *data,\n\t\t\t\t\t unsigned int rounds);\n\nstatic int sha224_sparc64_init(struct shash_desc *desc)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\tsctx->state[0] = SHA224_H0;\n\tsctx->state[1] = SHA224_H1;\n\tsctx->state[2] = SHA224_H2;\n\tsctx->state[3] = SHA224_H3;\n\tsctx->state[4] = SHA224_H4;\n\tsctx->state[5] = SHA224_H5;\n\tsctx->state[6] = SHA224_H6;\n\tsctx->state[7] = SHA224_H7;\n\tsctx->count = 0;\n\n\treturn 0;\n}\n\nstatic int sha256_sparc64_init(struct shash_desc *desc)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\tsctx->state[0] = SHA256_H0;\n\tsctx->state[1] = SHA256_H1;\n\tsctx->state[2] = SHA256_H2;\n\tsctx->state[3] = SHA256_H3;\n\tsctx->state[4] = SHA256_H4;\n\tsctx->state[5] = SHA256_H5;\n\tsctx->state[6] = SHA256_H6;\n\tsctx->state[7] = SHA256_H7;\n\tsctx->count = 0;\n\n\treturn 0;\n}\n\nstatic void __sha256_sparc64_update(struct sha256_state *sctx, const u8 *data,\n\t\t\t\t    unsigned int len, unsigned int partial)\n{\n\tunsigned int done = 0;\n\n\tsctx->count += len;\n\tif (partial) {\n\t\tdone = SHA256_BLOCK_SIZE - partial;\n\t\tmemcpy(sctx->buf + partial, data, done);\n\t\tsha256_sparc64_transform(sctx->state, sctx->buf, 1);\n\t}\n\tif (len - done >= SHA256_BLOCK_SIZE) {\n\t\tconst unsigned int rounds = (len - done) / SHA256_BLOCK_SIZE;\n\n\t\tsha256_sparc64_transform(sctx->state, data + done, rounds);\n\t\tdone += rounds * SHA256_BLOCK_SIZE;\n\t}\n\n\tmemcpy(sctx->buf, data + done, len - done);\n}\n\nstatic int sha256_sparc64_update(struct shash_desc *desc, const u8 *data,\n\t\t\t\t unsigned int len)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial = sctx->count % SHA256_BLOCK_SIZE;\n\n\t/* Handle the fast case right here */\n\tif (partial + len < SHA256_BLOCK_SIZE) {\n\t\tsctx->count += len;\n\t\tmemcpy(sctx->buf + partial, data, len);\n\t} else\n\t\t__sha256_sparc64_update(sctx, data, len, partial);\n\n\treturn 0;\n}\n\nstatic int sha256_sparc64_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\tunsigned int i, index, padlen;\n\t__be32 *dst = (__be32 *)out;\n\t__be64 bits;\n\tstatic const u8 padding[SHA256_BLOCK_SIZE] = { 0x80, };\n\n\tbits = cpu_to_be64(sctx->count << 3);\n\n\t/* Pad out to 56 mod 64 and append length */\n\tindex = sctx->count % SHA256_BLOCK_SIZE;\n\tpadlen = (index < 56) ? (56 - index) : ((SHA256_BLOCK_SIZE+56) - index);\n\n\t/* We need to fill a whole block for __sha256_sparc64_update() */\n\tif (padlen <= 56) {\n\t\tsctx->count += padlen;\n\t\tmemcpy(sctx->buf + index, padding, padlen);\n\t} else {\n\t\t__sha256_sparc64_update(sctx, padding, padlen, index);\n\t}\n\t__sha256_sparc64_update(sctx, (const u8 *)&bits, sizeof(bits), 56);\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 8; i++)\n\t\tdst[i] = cpu_to_be32(sctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha224_sparc64_final(struct shash_desc *desc, u8 *hash)\n{\n\tu8 D[SHA256_DIGEST_SIZE];\n\n\tsha256_sparc64_final(desc, D);\n\n\tmemcpy(hash, D, SHA224_DIGEST_SIZE);\n\tmemset(D, 0, SHA256_DIGEST_SIZE);\n\n\treturn 0;\n}\n\nstatic int sha256_sparc64_export(struct shash_desc *desc, void *out)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, sizeof(*sctx));\n\treturn 0;\n}\n\nstatic int sha256_sparc64_import(struct shash_desc *desc, const void *in)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, sizeof(*sctx));\n\treturn 0;\n}\n\nstatic struct shash_alg sha256 = {\n\t.digestsize\t=\tSHA256_DIGEST_SIZE,\n\t.init\t\t=\tsha256_sparc64_init,\n\t.update\t\t=\tsha256_sparc64_update,\n\t.final\t\t=\tsha256_sparc64_final,\n\t.export\t\t=\tsha256_sparc64_export,\n\t.import\t\t=\tsha256_sparc64_import,\n\t.descsize\t=\tsizeof(struct sha256_state),\n\t.statesize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha256\",\n\t\t.cra_driver_name=\t\"sha256-sparc64\",\n\t\t.cra_priority\t=\tSPARC_CR_OPCODE_PRIORITY,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA256_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic struct shash_alg sha224 = {\n\t.digestsize\t=\tSHA224_DIGEST_SIZE,\n\t.init\t\t=\tsha224_sparc64_init,\n\t.update\t\t=\tsha256_sparc64_update,\n\t.final\t\t=\tsha224_sparc64_final,\n\t.descsize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha224\",\n\t\t.cra_driver_name=\t\"sha224-sparc64\",\n\t\t.cra_priority\t=\tSPARC_CR_OPCODE_PRIORITY,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA224_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic bool __init sparc64_has_sha256_opcode(void)\n{\n\tunsigned long cfr;\n\n\tif (!(sparc64_elf_hwcap & HWCAP_SPARC_CRYPTO))\n\t\treturn false;\n\n\t__asm__ __volatile__(\"rd %%asr26, %0\" : \"=r\" (cfr));\n\tif (!(cfr & CFR_SHA256))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int __init sha256_sparc64_mod_init(void)\n{\n\tif (sparc64_has_sha256_opcode()) {\n\t\tint ret = crypto_register_shash(&sha224);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tret = crypto_register_shash(&sha256);\n\t\tif (ret < 0) {\n\t\t\tcrypto_unregister_shash(&sha224);\n\t\t\treturn ret;\n\t\t}\n\n\t\tpr_info(\"Using sparc64 sha256 opcode optimized SHA-256/SHA-224 implementation\\n\");\n\t\treturn 0;\n\t}\n\tpr_info(\"sparc64 sha256 opcode not available.\\n\");\n\treturn -ENODEV;\n}\n\nstatic void __exit sha256_sparc64_mod_fini(void)\n{\n\tcrypto_unregister_shash(&sha224);\n\tcrypto_unregister_shash(&sha256);\n}\n\nmodule_init(sha256_sparc64_mod_init);\nmodule_exit(sha256_sparc64_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA-224 and SHA-256 Secure Hash Algorithm, sparc64 sha256 opcode accelerated\");\n\nMODULE_ALIAS_CRYPTO(\"sha224\");\nMODULE_ALIAS_CRYPTO(\"sha256\");\n\n#include \"crop_devid.c\"\n", "/* Glue code for SHA512 hashing optimized for sparc64 crypto opcodes.\n *\n * This is based largely upon crypto/sha512_generic.c\n *\n * Copyright (c) Jean-Luc Cooke <jlcooke@certainkey.com>\n * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n * Copyright (c) 2003 Kyle McMartin <kyle@debian.org>\n */\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n\n#include <asm/pstate.h>\n#include <asm/elf.h>\n\n#include \"opcodes.h\"\n\nasmlinkage void sha512_sparc64_transform(u64 *digest, const char *data,\n\t\t\t\t\t unsigned int rounds);\n\nstatic int sha512_sparc64_init(struct shash_desc *desc)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tsctx->state[0] = SHA512_H0;\n\tsctx->state[1] = SHA512_H1;\n\tsctx->state[2] = SHA512_H2;\n\tsctx->state[3] = SHA512_H3;\n\tsctx->state[4] = SHA512_H4;\n\tsctx->state[5] = SHA512_H5;\n\tsctx->state[6] = SHA512_H6;\n\tsctx->state[7] = SHA512_H7;\n\tsctx->count[0] = sctx->count[1] = 0;\n\n\treturn 0;\n}\n\nstatic int sha384_sparc64_init(struct shash_desc *desc)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tsctx->state[0] = SHA384_H0;\n\tsctx->state[1] = SHA384_H1;\n\tsctx->state[2] = SHA384_H2;\n\tsctx->state[3] = SHA384_H3;\n\tsctx->state[4] = SHA384_H4;\n\tsctx->state[5] = SHA384_H5;\n\tsctx->state[6] = SHA384_H6;\n\tsctx->state[7] = SHA384_H7;\n\tsctx->count[0] = sctx->count[1] = 0;\n\n\treturn 0;\n}\n\nstatic void __sha512_sparc64_update(struct sha512_state *sctx, const u8 *data,\n\t\t\t\t    unsigned int len, unsigned int partial)\n{\n\tunsigned int done = 0;\n\n\tif ((sctx->count[0] += len) < len)\n\t\tsctx->count[1]++;\n\tif (partial) {\n\t\tdone = SHA512_BLOCK_SIZE - partial;\n\t\tmemcpy(sctx->buf + partial, data, done);\n\t\tsha512_sparc64_transform(sctx->state, sctx->buf, 1);\n\t}\n\tif (len - done >= SHA512_BLOCK_SIZE) {\n\t\tconst unsigned int rounds = (len - done) / SHA512_BLOCK_SIZE;\n\n\t\tsha512_sparc64_transform(sctx->state, data + done, rounds);\n\t\tdone += rounds * SHA512_BLOCK_SIZE;\n\t}\n\n\tmemcpy(sctx->buf, data + done, len - done);\n}\n\nstatic int sha512_sparc64_update(struct shash_desc *desc, const u8 *data,\n\t\t\t\t unsigned int len)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial = sctx->count[0] % SHA512_BLOCK_SIZE;\n\n\t/* Handle the fast case right here */\n\tif (partial + len < SHA512_BLOCK_SIZE) {\n\t\tif ((sctx->count[0] += len) < len)\n\t\t\tsctx->count[1]++;\n\t\tmemcpy(sctx->buf + partial, data, len);\n\t} else\n\t\t__sha512_sparc64_update(sctx, data, len, partial);\n\n\treturn 0;\n}\n\nstatic int sha512_sparc64_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tunsigned int i, index, padlen;\n\t__be64 *dst = (__be64 *)out;\n\t__be64 bits[2];\n\tstatic const u8 padding[SHA512_BLOCK_SIZE] = { 0x80, };\n\n\t/* Save number of bits */\n\tbits[1] = cpu_to_be64(sctx->count[0] << 3);\n\tbits[0] = cpu_to_be64(sctx->count[1] << 3 | sctx->count[0] >> 61);\n\n\t/* Pad out to 112 mod 128 and append length */\n\tindex = sctx->count[0] % SHA512_BLOCK_SIZE;\n\tpadlen = (index < 112) ? (112 - index) : ((SHA512_BLOCK_SIZE+112) - index);\n\n\t/* We need to fill a whole block for __sha512_sparc64_update() */\n\tif (padlen <= 112) {\n\t\tif ((sctx->count[0] += padlen) < padlen)\n\t\t\tsctx->count[1]++;\n\t\tmemcpy(sctx->buf + index, padding, padlen);\n\t} else {\n\t\t__sha512_sparc64_update(sctx, padding, padlen, index);\n\t}\n\t__sha512_sparc64_update(sctx, (const u8 *)&bits, sizeof(bits), 112);\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 8; i++)\n\t\tdst[i] = cpu_to_be64(sctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha384_sparc64_final(struct shash_desc *desc, u8 *hash)\n{\n\tu8 D[64];\n\n\tsha512_sparc64_final(desc, D);\n\n\tmemcpy(hash, D, 48);\n\tmemset(D, 0, 64);\n\n\treturn 0;\n}\n\nstatic struct shash_alg sha512 = {\n\t.digestsize\t=\tSHA512_DIGEST_SIZE,\n\t.init\t\t=\tsha512_sparc64_init,\n\t.update\t\t=\tsha512_sparc64_update,\n\t.final\t\t=\tsha512_sparc64_final,\n\t.descsize\t=\tsizeof(struct sha512_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha512\",\n\t\t.cra_driver_name=\t\"sha512-sparc64\",\n\t\t.cra_priority\t=\tSPARC_CR_OPCODE_PRIORITY,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA512_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic struct shash_alg sha384 = {\n\t.digestsize\t=\tSHA384_DIGEST_SIZE,\n\t.init\t\t=\tsha384_sparc64_init,\n\t.update\t\t=\tsha512_sparc64_update,\n\t.final\t\t=\tsha384_sparc64_final,\n\t.descsize\t=\tsizeof(struct sha512_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha384\",\n\t\t.cra_driver_name=\t\"sha384-sparc64\",\n\t\t.cra_priority\t=\tSPARC_CR_OPCODE_PRIORITY,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA384_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic bool __init sparc64_has_sha512_opcode(void)\n{\n\tunsigned long cfr;\n\n\tif (!(sparc64_elf_hwcap & HWCAP_SPARC_CRYPTO))\n\t\treturn false;\n\n\t__asm__ __volatile__(\"rd %%asr26, %0\" : \"=r\" (cfr));\n\tif (!(cfr & CFR_SHA512))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int __init sha512_sparc64_mod_init(void)\n{\n\tif (sparc64_has_sha512_opcode()) {\n\t\tint ret = crypto_register_shash(&sha384);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tret = crypto_register_shash(&sha512);\n\t\tif (ret < 0) {\n\t\t\tcrypto_unregister_shash(&sha384);\n\t\t\treturn ret;\n\t\t}\n\n\t\tpr_info(\"Using sparc64 sha512 opcode optimized SHA-512/SHA-384 implementation\\n\");\n\t\treturn 0;\n\t}\n\tpr_info(\"sparc64 sha512 opcode not available.\\n\");\n\treturn -ENODEV;\n}\n\nstatic void __exit sha512_sparc64_mod_fini(void)\n{\n\tcrypto_unregister_shash(&sha384);\n\tcrypto_unregister_shash(&sha512);\n}\n\nmodule_init(sha512_sparc64_mod_init);\nmodule_exit(sha512_sparc64_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA-384 and SHA-512 Secure Hash Algorithm, sparc64 sha512 opcode accelerated\");\n\nMODULE_ALIAS_CRYPTO(\"sha384\");\nMODULE_ALIAS_CRYPTO(\"sha512\");\n\n#include \"crop_devid.c\"\n", "/*\n * Glue Code for the asm optimized version of the AES Cipher Algorithm\n *\n */\n\n#include <linux/module.h>\n#include <crypto/aes.h>\n#include <asm/crypto/aes.h>\n\nasmlinkage void aes_enc_blk(struct crypto_aes_ctx *ctx, u8 *out, const u8 *in);\nasmlinkage void aes_dec_blk(struct crypto_aes_ctx *ctx, u8 *out, const u8 *in);\n\nvoid crypto_aes_encrypt_x86(struct crypto_aes_ctx *ctx, u8 *dst, const u8 *src)\n{\n\taes_enc_blk(ctx, dst, src);\n}\nEXPORT_SYMBOL_GPL(crypto_aes_encrypt_x86);\n\nvoid crypto_aes_decrypt_x86(struct crypto_aes_ctx *ctx, u8 *dst, const u8 *src)\n{\n\taes_dec_blk(ctx, dst, src);\n}\nEXPORT_SYMBOL_GPL(crypto_aes_decrypt_x86);\n\nstatic void aes_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\taes_enc_blk(crypto_tfm_ctx(tfm), dst, src);\n}\n\nstatic void aes_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\taes_dec_blk(crypto_tfm_ctx(tfm), dst, src);\n}\n\nstatic struct crypto_alg aes_alg = {\n\t.cra_name\t\t= \"aes\",\n\t.cra_driver_name\t= \"aes-asm\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_aes_ctx),\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u\t= {\n\t\t.cipher\t= {\n\t\t\t.cia_min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t= crypto_aes_set_key,\n\t\t\t.cia_encrypt\t\t= aes_encrypt,\n\t\t\t.cia_decrypt\t\t= aes_decrypt\n\t\t}\n\t}\n};\n\nstatic int __init aes_init(void)\n{\n\treturn crypto_register_alg(&aes_alg);\n}\n\nstatic void __exit aes_fini(void)\n{\n\tcrypto_unregister_alg(&aes_alg);\n}\n\nmodule_init(aes_init);\nmodule_exit(aes_fini);\n\nMODULE_DESCRIPTION(\"Rijndael (AES) Cipher Algorithm, asm optimized\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_CRYPTO(\"aes\");\nMODULE_ALIAS_CRYPTO(\"aes-asm\");\n", "/*\n * Support for Intel AES-NI instructions. This file contains glue\n * code, the real AES implementation is in intel-aes_asm.S.\n *\n * Copyright (C) 2008, Intel Corp.\n *    Author: Huang Ying <ying.huang@intel.com>\n *\n * Added RFC4106 AES-GCM support for 128-bit keys under the AEAD\n * interface for 64-bit kernels.\n *    Authors: Adrian Hoban <adrian.hoban@intel.com>\n *             Gabriele Paoloni <gabriele.paoloni@intel.com>\n *             Tadeusz Struk (tadeusz.struk@intel.com)\n *             Aidan O'Mahony (aidan.o.mahony@intel.com)\n *    Copyright (c) 2010, Intel Corporation.\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n */\n\n#include <linux/hardirq.h>\n#include <linux/types.h>\n#include <linux/crypto.h>\n#include <linux/module.h>\n#include <linux/err.h>\n#include <crypto/algapi.h>\n#include <crypto/aes.h>\n#include <crypto/cryptd.h>\n#include <crypto/ctr.h>\n#include <crypto/b128ops.h>\n#include <crypto/lrw.h>\n#include <crypto/xts.h>\n#include <asm/cpu_device_id.h>\n#include <asm/i387.h>\n#include <asm/crypto/aes.h>\n#include <crypto/ablk_helper.h>\n#include <crypto/scatterwalk.h>\n#include <crypto/internal/aead.h>\n#include <linux/workqueue.h>\n#include <linux/spinlock.h>\n#ifdef CONFIG_X86_64\n#include <asm/crypto/glue_helper.h>\n#endif\n\n/* This data is stored at the end of the crypto_tfm struct.\n * It's a type of per \"session\" data storage location.\n * This needs to be 16 byte aligned.\n */\nstruct aesni_rfc4106_gcm_ctx {\n\tu8 hash_subkey[16];\n\tstruct crypto_aes_ctx aes_key_expanded;\n\tu8 nonce[4];\n\tstruct cryptd_aead *cryptd_tfm;\n};\n\nstruct aesni_gcm_set_hash_subkey_result {\n\tint err;\n\tstruct completion completion;\n};\n\nstruct aesni_hash_subkey_req_data {\n\tu8 iv[16];\n\tstruct aesni_gcm_set_hash_subkey_result result;\n\tstruct scatterlist sg;\n};\n\n#define AESNI_ALIGN\t(16)\n#define AES_BLOCK_MASK\t(~(AES_BLOCK_SIZE-1))\n#define RFC4106_HASH_SUBKEY_SIZE 16\n\nstruct aesni_lrw_ctx {\n\tstruct lrw_table_ctx lrw_table;\n\tu8 raw_aes_ctx[sizeof(struct crypto_aes_ctx) + AESNI_ALIGN - 1];\n};\n\nstruct aesni_xts_ctx {\n\tu8 raw_tweak_ctx[sizeof(struct crypto_aes_ctx) + AESNI_ALIGN - 1];\n\tu8 raw_crypt_ctx[sizeof(struct crypto_aes_ctx) + AESNI_ALIGN - 1];\n};\n\nasmlinkage int aesni_set_key(struct crypto_aes_ctx *ctx, const u8 *in_key,\n\t\t\t     unsigned int key_len);\nasmlinkage void aesni_enc(struct crypto_aes_ctx *ctx, u8 *out,\n\t\t\t  const u8 *in);\nasmlinkage void aesni_dec(struct crypto_aes_ctx *ctx, u8 *out,\n\t\t\t  const u8 *in);\nasmlinkage void aesni_ecb_enc(struct crypto_aes_ctx *ctx, u8 *out,\n\t\t\t      const u8 *in, unsigned int len);\nasmlinkage void aesni_ecb_dec(struct crypto_aes_ctx *ctx, u8 *out,\n\t\t\t      const u8 *in, unsigned int len);\nasmlinkage void aesni_cbc_enc(struct crypto_aes_ctx *ctx, u8 *out,\n\t\t\t      const u8 *in, unsigned int len, u8 *iv);\nasmlinkage void aesni_cbc_dec(struct crypto_aes_ctx *ctx, u8 *out,\n\t\t\t      const u8 *in, unsigned int len, u8 *iv);\n\nint crypto_fpu_init(void);\nvoid crypto_fpu_exit(void);\n\n#define AVX_GEN2_OPTSIZE 640\n#define AVX_GEN4_OPTSIZE 4096\n\n#ifdef CONFIG_X86_64\n\nstatic void (*aesni_ctr_enc_tfm)(struct crypto_aes_ctx *ctx, u8 *out,\n\t\t\t      const u8 *in, unsigned int len, u8 *iv);\nasmlinkage void aesni_ctr_enc(struct crypto_aes_ctx *ctx, u8 *out,\n\t\t\t      const u8 *in, unsigned int len, u8 *iv);\n\nasmlinkage void aesni_xts_crypt8(struct crypto_aes_ctx *ctx, u8 *out,\n\t\t\t\t const u8 *in, bool enc, u8 *iv);\n\n/* asmlinkage void aesni_gcm_enc()\n * void *ctx,  AES Key schedule. Starts on a 16 byte boundary.\n * u8 *out, Ciphertext output. Encrypt in-place is allowed.\n * const u8 *in, Plaintext input\n * unsigned long plaintext_len, Length of data in bytes for encryption.\n * u8 *iv, Pre-counter block j0: 4 byte salt (from Security Association)\n *         concatenated with 8 byte Initialisation Vector (from IPSec ESP\n *         Payload) concatenated with 0x00000001. 16-byte aligned pointer.\n * u8 *hash_subkey, the Hash sub key input. Data starts on a 16-byte boundary.\n * const u8 *aad, Additional Authentication Data (AAD)\n * unsigned long aad_len, Length of AAD in bytes. With RFC4106 this\n *          is going to be 8 or 12 bytes\n * u8 *auth_tag, Authenticated Tag output.\n * unsigned long auth_tag_len), Authenticated Tag Length in bytes.\n *          Valid values are 16 (most likely), 12 or 8.\n */\nasmlinkage void aesni_gcm_enc(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long plaintext_len, u8 *iv,\n\t\t\tu8 *hash_subkey, const u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len);\n\n/* asmlinkage void aesni_gcm_dec()\n * void *ctx, AES Key schedule. Starts on a 16 byte boundary.\n * u8 *out, Plaintext output. Decrypt in-place is allowed.\n * const u8 *in, Ciphertext input\n * unsigned long ciphertext_len, Length of data in bytes for decryption.\n * u8 *iv, Pre-counter block j0: 4 byte salt (from Security Association)\n *         concatenated with 8 byte Initialisation Vector (from IPSec ESP\n *         Payload) concatenated with 0x00000001. 16-byte aligned pointer.\n * u8 *hash_subkey, the Hash sub key input. Data starts on a 16-byte boundary.\n * const u8 *aad, Additional Authentication Data (AAD)\n * unsigned long aad_len, Length of AAD in bytes. With RFC4106 this is going\n * to be 8 or 12 bytes\n * u8 *auth_tag, Authenticated Tag output.\n * unsigned long auth_tag_len) Authenticated Tag Length in bytes.\n * Valid values are 16 (most likely), 12 or 8.\n */\nasmlinkage void aesni_gcm_dec(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long ciphertext_len, u8 *iv,\n\t\t\tu8 *hash_subkey, const u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len);\n\n\n#ifdef CONFIG_AS_AVX\nasmlinkage void aes_ctr_enc_128_avx_by8(const u8 *in, u8 *iv,\n\t\tvoid *keys, u8 *out, unsigned int num_bytes);\nasmlinkage void aes_ctr_enc_192_avx_by8(const u8 *in, u8 *iv,\n\t\tvoid *keys, u8 *out, unsigned int num_bytes);\nasmlinkage void aes_ctr_enc_256_avx_by8(const u8 *in, u8 *iv,\n\t\tvoid *keys, u8 *out, unsigned int num_bytes);\n/*\n * asmlinkage void aesni_gcm_precomp_avx_gen2()\n * gcm_data *my_ctx_data, context data\n * u8 *hash_subkey,  the Hash sub key input. Data starts on a 16-byte boundary.\n */\nasmlinkage void aesni_gcm_precomp_avx_gen2(void *my_ctx_data, u8 *hash_subkey);\n\nasmlinkage void aesni_gcm_enc_avx_gen2(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long plaintext_len, u8 *iv,\n\t\t\tconst u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len);\n\nasmlinkage void aesni_gcm_dec_avx_gen2(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long ciphertext_len, u8 *iv,\n\t\t\tconst u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len);\n\nstatic void aesni_gcm_enc_avx(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long plaintext_len, u8 *iv,\n\t\t\tu8 *hash_subkey, const u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len)\n{\n\tif (plaintext_len < AVX_GEN2_OPTSIZE) {\n\t\taesni_gcm_enc(ctx, out, in, plaintext_len, iv, hash_subkey, aad,\n\t\t\t\taad_len, auth_tag, auth_tag_len);\n\t} else {\n\t\taesni_gcm_precomp_avx_gen2(ctx, hash_subkey);\n\t\taesni_gcm_enc_avx_gen2(ctx, out, in, plaintext_len, iv, aad,\n\t\t\t\t\taad_len, auth_tag, auth_tag_len);\n\t}\n}\n\nstatic void aesni_gcm_dec_avx(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long ciphertext_len, u8 *iv,\n\t\t\tu8 *hash_subkey, const u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len)\n{\n\tif (ciphertext_len < AVX_GEN2_OPTSIZE) {\n\t\taesni_gcm_dec(ctx, out, in, ciphertext_len, iv, hash_subkey, aad,\n\t\t\t\taad_len, auth_tag, auth_tag_len);\n\t} else {\n\t\taesni_gcm_precomp_avx_gen2(ctx, hash_subkey);\n\t\taesni_gcm_dec_avx_gen2(ctx, out, in, ciphertext_len, iv, aad,\n\t\t\t\t\taad_len, auth_tag, auth_tag_len);\n\t}\n}\n#endif\n\n#ifdef CONFIG_AS_AVX2\n/*\n * asmlinkage void aesni_gcm_precomp_avx_gen4()\n * gcm_data *my_ctx_data, context data\n * u8 *hash_subkey,  the Hash sub key input. Data starts on a 16-byte boundary.\n */\nasmlinkage void aesni_gcm_precomp_avx_gen4(void *my_ctx_data, u8 *hash_subkey);\n\nasmlinkage void aesni_gcm_enc_avx_gen4(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long plaintext_len, u8 *iv,\n\t\t\tconst u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len);\n\nasmlinkage void aesni_gcm_dec_avx_gen4(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long ciphertext_len, u8 *iv,\n\t\t\tconst u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len);\n\nstatic void aesni_gcm_enc_avx2(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long plaintext_len, u8 *iv,\n\t\t\tu8 *hash_subkey, const u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len)\n{\n\tif (plaintext_len < AVX_GEN2_OPTSIZE) {\n\t\taesni_gcm_enc(ctx, out, in, plaintext_len, iv, hash_subkey, aad,\n\t\t\t\taad_len, auth_tag, auth_tag_len);\n\t} else if (plaintext_len < AVX_GEN4_OPTSIZE) {\n\t\taesni_gcm_precomp_avx_gen2(ctx, hash_subkey);\n\t\taesni_gcm_enc_avx_gen2(ctx, out, in, plaintext_len, iv, aad,\n\t\t\t\t\taad_len, auth_tag, auth_tag_len);\n\t} else {\n\t\taesni_gcm_precomp_avx_gen4(ctx, hash_subkey);\n\t\taesni_gcm_enc_avx_gen4(ctx, out, in, plaintext_len, iv, aad,\n\t\t\t\t\taad_len, auth_tag, auth_tag_len);\n\t}\n}\n\nstatic void aesni_gcm_dec_avx2(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long ciphertext_len, u8 *iv,\n\t\t\tu8 *hash_subkey, const u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len)\n{\n\tif (ciphertext_len < AVX_GEN2_OPTSIZE) {\n\t\taesni_gcm_dec(ctx, out, in, ciphertext_len, iv, hash_subkey,\n\t\t\t\taad, aad_len, auth_tag, auth_tag_len);\n\t} else if (ciphertext_len < AVX_GEN4_OPTSIZE) {\n\t\taesni_gcm_precomp_avx_gen2(ctx, hash_subkey);\n\t\taesni_gcm_dec_avx_gen2(ctx, out, in, ciphertext_len, iv, aad,\n\t\t\t\t\taad_len, auth_tag, auth_tag_len);\n\t} else {\n\t\taesni_gcm_precomp_avx_gen4(ctx, hash_subkey);\n\t\taesni_gcm_dec_avx_gen4(ctx, out, in, ciphertext_len, iv, aad,\n\t\t\t\t\taad_len, auth_tag, auth_tag_len);\n\t}\n}\n#endif\n\nstatic void (*aesni_gcm_enc_tfm)(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long plaintext_len, u8 *iv,\n\t\t\tu8 *hash_subkey, const u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len);\n\nstatic void (*aesni_gcm_dec_tfm)(void *ctx, u8 *out,\n\t\t\tconst u8 *in, unsigned long ciphertext_len, u8 *iv,\n\t\t\tu8 *hash_subkey, const u8 *aad, unsigned long aad_len,\n\t\t\tu8 *auth_tag, unsigned long auth_tag_len);\n\nstatic inline struct\naesni_rfc4106_gcm_ctx *aesni_rfc4106_gcm_ctx_get(struct crypto_aead *tfm)\n{\n\treturn\n\t\t(struct aesni_rfc4106_gcm_ctx *)\n\t\tPTR_ALIGN((u8 *)\n\t\tcrypto_tfm_ctx(crypto_aead_tfm(tfm)), AESNI_ALIGN);\n}\n#endif\n\nstatic inline struct crypto_aes_ctx *aes_ctx(void *raw_ctx)\n{\n\tunsigned long addr = (unsigned long)raw_ctx;\n\tunsigned long align = AESNI_ALIGN;\n\n\tif (align <= crypto_tfm_ctx_alignment())\n\t\talign = 1;\n\treturn (struct crypto_aes_ctx *)ALIGN(addr, align);\n}\n\nstatic int aes_set_key_common(struct crypto_tfm *tfm, void *raw_ctx,\n\t\t\t      const u8 *in_key, unsigned int key_len)\n{\n\tstruct crypto_aes_ctx *ctx = aes_ctx(raw_ctx);\n\tu32 *flags = &tfm->crt_flags;\n\tint err;\n\n\tif (key_len != AES_KEYSIZE_128 && key_len != AES_KEYSIZE_192 &&\n\t    key_len != AES_KEYSIZE_256) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\tif (!irq_fpu_usable())\n\t\terr = crypto_aes_expand_key(ctx, in_key, key_len);\n\telse {\n\t\tkernel_fpu_begin();\n\t\terr = aesni_set_key(ctx, in_key, key_len);\n\t\tkernel_fpu_end();\n\t}\n\n\treturn err;\n}\n\nstatic int aes_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t       unsigned int key_len)\n{\n\treturn aes_set_key_common(tfm, crypto_tfm_ctx(tfm), in_key, key_len);\n}\n\nstatic void aes_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct crypto_aes_ctx *ctx = aes_ctx(crypto_tfm_ctx(tfm));\n\n\tif (!irq_fpu_usable())\n\t\tcrypto_aes_encrypt_x86(ctx, dst, src);\n\telse {\n\t\tkernel_fpu_begin();\n\t\taesni_enc(ctx, dst, src);\n\t\tkernel_fpu_end();\n\t}\n}\n\nstatic void aes_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct crypto_aes_ctx *ctx = aes_ctx(crypto_tfm_ctx(tfm));\n\n\tif (!irq_fpu_usable())\n\t\tcrypto_aes_decrypt_x86(ctx, dst, src);\n\telse {\n\t\tkernel_fpu_begin();\n\t\taesni_dec(ctx, dst, src);\n\t\tkernel_fpu_end();\n\t}\n}\n\nstatic void __aes_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct crypto_aes_ctx *ctx = aes_ctx(crypto_tfm_ctx(tfm));\n\n\taesni_enc(ctx, dst, src);\n}\n\nstatic void __aes_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct crypto_aes_ctx *ctx = aes_ctx(crypto_tfm_ctx(tfm));\n\n\taesni_dec(ctx, dst, src);\n}\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct crypto_aes_ctx *ctx = aes_ctx(crypto_blkcipher_ctx(desc->tfm));\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tkernel_fpu_begin();\n\twhile ((nbytes = walk.nbytes)) {\n\t\taesni_ecb_enc(ctx, walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t      nbytes & AES_BLOCK_MASK);\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tkernel_fpu_end();\n\n\treturn err;\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct crypto_aes_ctx *ctx = aes_ctx(crypto_blkcipher_ctx(desc->tfm));\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tkernel_fpu_begin();\n\twhile ((nbytes = walk.nbytes)) {\n\t\taesni_ecb_dec(ctx, walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t      nbytes & AES_BLOCK_MASK);\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tkernel_fpu_end();\n\n\treturn err;\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct crypto_aes_ctx *ctx = aes_ctx(crypto_blkcipher_ctx(desc->tfm));\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tkernel_fpu_begin();\n\twhile ((nbytes = walk.nbytes)) {\n\t\taesni_cbc_enc(ctx, walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t      nbytes & AES_BLOCK_MASK, walk.iv);\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tkernel_fpu_end();\n\n\treturn err;\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes)\n{\n\tstruct crypto_aes_ctx *ctx = aes_ctx(crypto_blkcipher_ctx(desc->tfm));\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tkernel_fpu_begin();\n\twhile ((nbytes = walk.nbytes)) {\n\t\taesni_cbc_dec(ctx, walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t      nbytes & AES_BLOCK_MASK, walk.iv);\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tkernel_fpu_end();\n\n\treturn err;\n}\n\n#ifdef CONFIG_X86_64\nstatic void ctr_crypt_final(struct crypto_aes_ctx *ctx,\n\t\t\t    struct blkcipher_walk *walk)\n{\n\tu8 *ctrblk = walk->iv;\n\tu8 keystream[AES_BLOCK_SIZE];\n\tu8 *src = walk->src.virt.addr;\n\tu8 *dst = walk->dst.virt.addr;\n\tunsigned int nbytes = walk->nbytes;\n\n\taesni_enc(ctx, keystream, ctrblk);\n\tcrypto_xor(keystream, src, nbytes);\n\tmemcpy(dst, keystream, nbytes);\n\tcrypto_inc(ctrblk, AES_BLOCK_SIZE);\n}\n\n#ifdef CONFIG_AS_AVX\nstatic void aesni_ctr_enc_avx_tfm(struct crypto_aes_ctx *ctx, u8 *out,\n\t\t\t      const u8 *in, unsigned int len, u8 *iv)\n{\n\t/*\n\t * based on key length, override with the by8 version\n\t * of ctr mode encryption/decryption for improved performance\n\t * aes_set_key_common() ensures that key length is one of\n\t * {128,192,256}\n\t */\n\tif (ctx->key_length == AES_KEYSIZE_128)\n\t\taes_ctr_enc_128_avx_by8(in, iv, (void *)ctx, out, len);\n\telse if (ctx->key_length == AES_KEYSIZE_192)\n\t\taes_ctr_enc_192_avx_by8(in, iv, (void *)ctx, out, len);\n\telse\n\t\taes_ctr_enc_256_avx_by8(in, iv, (void *)ctx, out, len);\n}\n#endif\n\nstatic int ctr_crypt(struct blkcipher_desc *desc,\n\t\t     struct scatterlist *dst, struct scatterlist *src,\n\t\t     unsigned int nbytes)\n{\n\tstruct crypto_aes_ctx *ctx = aes_ctx(crypto_blkcipher_ctx(desc->tfm));\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt_block(desc, &walk, AES_BLOCK_SIZE);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tkernel_fpu_begin();\n\twhile ((nbytes = walk.nbytes) >= AES_BLOCK_SIZE) {\n\t\taesni_ctr_enc_tfm(ctx, walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t\t  nbytes & AES_BLOCK_MASK, walk.iv);\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tif (walk.nbytes) {\n\t\tctr_crypt_final(ctx, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, 0);\n\t}\n\tkernel_fpu_end();\n\n\treturn err;\n}\n#endif\n\nstatic int ablk_ecb_init(struct crypto_tfm *tfm)\n{\n\treturn ablk_init_common(tfm, \"__driver-ecb-aes-aesni\");\n}\n\nstatic int ablk_cbc_init(struct crypto_tfm *tfm)\n{\n\treturn ablk_init_common(tfm, \"__driver-cbc-aes-aesni\");\n}\n\n#ifdef CONFIG_X86_64\nstatic int ablk_ctr_init(struct crypto_tfm *tfm)\n{\n\treturn ablk_init_common(tfm, \"__driver-ctr-aes-aesni\");\n}\n\n#endif\n\n#if IS_ENABLED(CONFIG_CRYPTO_PCBC)\nstatic int ablk_pcbc_init(struct crypto_tfm *tfm)\n{\n\treturn ablk_init_common(tfm, \"fpu(pcbc(__driver-aes-aesni))\");\n}\n#endif\n\nstatic void lrw_xts_encrypt_callback(void *ctx, u8 *blks, unsigned int nbytes)\n{\n\taesni_ecb_enc(ctx, blks, blks, nbytes);\n}\n\nstatic void lrw_xts_decrypt_callback(void *ctx, u8 *blks, unsigned int nbytes)\n{\n\taesni_ecb_dec(ctx, blks, blks, nbytes);\n}\n\nstatic int lrw_aesni_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\t    unsigned int keylen)\n{\n\tstruct aesni_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\tint err;\n\n\terr = aes_set_key_common(tfm, ctx->raw_aes_ctx, key,\n\t\t\t\t keylen - AES_BLOCK_SIZE);\n\tif (err)\n\t\treturn err;\n\n\treturn lrw_init_table(&ctx->lrw_table, key + keylen - AES_BLOCK_SIZE);\n}\n\nstatic void lrw_aesni_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct aesni_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tlrw_free_table(&ctx->lrw_table);\n}\n\nstatic int lrw_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct aesni_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[8];\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = aes_ctx(ctx->raw_aes_ctx),\n\t\t.crypt_fn = lrw_xts_encrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tkernel_fpu_begin();\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tkernel_fpu_end();\n\n\treturn ret;\n}\n\nstatic int lrw_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct aesni_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[8];\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = aes_ctx(ctx->raw_aes_ctx),\n\t\t.crypt_fn = lrw_xts_decrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tkernel_fpu_begin();\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tkernel_fpu_end();\n\n\treturn ret;\n}\n\nstatic int xts_aesni_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\t    unsigned int keylen)\n{\n\tstruct aesni_xts_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tint err;\n\n\t/* key consists of keys of equal size concatenated, therefore\n\t * the length must be even\n\t */\n\tif (keylen % 2) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\t/* first half of xts-key is for crypt */\n\terr = aes_set_key_common(tfm, ctx->raw_crypt_ctx, key, keylen / 2);\n\tif (err)\n\t\treturn err;\n\n\t/* second half of xts-key is for tweak */\n\treturn aes_set_key_common(tfm, ctx->raw_tweak_ctx, key + keylen / 2,\n\t\t\t\t  keylen / 2);\n}\n\n\nstatic void aesni_xts_tweak(void *ctx, u8 *out, const u8 *in)\n{\n\taesni_enc(ctx, out, in);\n}\n\n#ifdef CONFIG_X86_64\n\nstatic void aesni_xts_enc(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tglue_xts_crypt_128bit_one(ctx, dst, src, iv, GLUE_FUNC_CAST(aesni_enc));\n}\n\nstatic void aesni_xts_dec(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tglue_xts_crypt_128bit_one(ctx, dst, src, iv, GLUE_FUNC_CAST(aesni_dec));\n}\n\nstatic void aesni_xts_enc8(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\taesni_xts_crypt8(ctx, (u8 *)dst, (const u8 *)src, true, (u8 *)iv);\n}\n\nstatic void aesni_xts_dec8(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\taesni_xts_crypt8(ctx, (u8 *)dst, (const u8 *)src, false, (u8 *)iv);\n}\n\nstatic const struct common_glue_ctx aesni_enc_xts = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = 1,\n\n\t.funcs = { {\n\t\t.num_blocks = 8,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(aesni_xts_enc8) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(aesni_xts_enc) }\n\t} }\n};\n\nstatic const struct common_glue_ctx aesni_dec_xts = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = 1,\n\n\t.funcs = { {\n\t\t.num_blocks = 8,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(aesni_xts_dec8) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(aesni_xts_dec) }\n\t} }\n};\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct aesni_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&aesni_enc_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(aesni_xts_tweak),\n\t\t\t\t     aes_ctx(ctx->raw_tweak_ctx),\n\t\t\t\t     aes_ctx(ctx->raw_crypt_ctx));\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct aesni_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&aesni_dec_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(aesni_xts_tweak),\n\t\t\t\t     aes_ctx(ctx->raw_tweak_ctx),\n\t\t\t\t     aes_ctx(ctx->raw_crypt_ctx));\n}\n\n#else\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct aesni_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[8];\n\tstruct xts_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.tweak_ctx = aes_ctx(ctx->raw_tweak_ctx),\n\t\t.tweak_fn = aesni_xts_tweak,\n\t\t.crypt_ctx = aes_ctx(ctx->raw_crypt_ctx),\n\t\t.crypt_fn = lrw_xts_encrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tkernel_fpu_begin();\n\tret = xts_crypt(desc, dst, src, nbytes, &req);\n\tkernel_fpu_end();\n\n\treturn ret;\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct aesni_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[8];\n\tstruct xts_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.tweak_ctx = aes_ctx(ctx->raw_tweak_ctx),\n\t\t.tweak_fn = aesni_xts_tweak,\n\t\t.crypt_ctx = aes_ctx(ctx->raw_crypt_ctx),\n\t\t.crypt_fn = lrw_xts_decrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tkernel_fpu_begin();\n\tret = xts_crypt(desc, dst, src, nbytes, &req);\n\tkernel_fpu_end();\n\n\treturn ret;\n}\n\n#endif\n\n#ifdef CONFIG_X86_64\nstatic int rfc4106_init(struct crypto_tfm *tfm)\n{\n\tstruct cryptd_aead *cryptd_tfm;\n\tstruct aesni_rfc4106_gcm_ctx *ctx = (struct aesni_rfc4106_gcm_ctx *)\n\t\tPTR_ALIGN((u8 *)crypto_tfm_ctx(tfm), AESNI_ALIGN);\n\tstruct crypto_aead *cryptd_child;\n\tstruct aesni_rfc4106_gcm_ctx *child_ctx;\n\tcryptd_tfm = cryptd_alloc_aead(\"__driver-gcm-aes-aesni\", 0, 0);\n\tif (IS_ERR(cryptd_tfm))\n\t\treturn PTR_ERR(cryptd_tfm);\n\n\tcryptd_child = cryptd_aead_child(cryptd_tfm);\n\tchild_ctx = aesni_rfc4106_gcm_ctx_get(cryptd_child);\n\tmemcpy(child_ctx, ctx, sizeof(*ctx));\n\tctx->cryptd_tfm = cryptd_tfm;\n\ttfm->crt_aead.reqsize = sizeof(struct aead_request)\n\t\t+ crypto_aead_reqsize(&cryptd_tfm->base);\n\treturn 0;\n}\n\nstatic void rfc4106_exit(struct crypto_tfm *tfm)\n{\n\tstruct aesni_rfc4106_gcm_ctx *ctx =\n\t\t(struct aesni_rfc4106_gcm_ctx *)\n\t\tPTR_ALIGN((u8 *)crypto_tfm_ctx(tfm), AESNI_ALIGN);\n\tif (!IS_ERR(ctx->cryptd_tfm))\n\t\tcryptd_free_aead(ctx->cryptd_tfm);\n\treturn;\n}\n\nstatic void\nrfc4106_set_hash_subkey_done(struct crypto_async_request *req, int err)\n{\n\tstruct aesni_gcm_set_hash_subkey_result *result = req->data;\n\n\tif (err == -EINPROGRESS)\n\t\treturn;\n\tresult->err = err;\n\tcomplete(&result->completion);\n}\n\nstatic int\nrfc4106_set_hash_subkey(u8 *hash_subkey, const u8 *key, unsigned int key_len)\n{\n\tstruct crypto_ablkcipher *ctr_tfm;\n\tstruct ablkcipher_request *req;\n\tint ret = -EINVAL;\n\tstruct aesni_hash_subkey_req_data *req_data;\n\n\tctr_tfm = crypto_alloc_ablkcipher(\"ctr(aes)\", 0, 0);\n\tif (IS_ERR(ctr_tfm))\n\t\treturn PTR_ERR(ctr_tfm);\n\n\tcrypto_ablkcipher_clear_flags(ctr_tfm, ~0);\n\n\tret = crypto_ablkcipher_setkey(ctr_tfm, key, key_len);\n\tif (ret)\n\t\tgoto out_free_ablkcipher;\n\n\tret = -ENOMEM;\n\treq = ablkcipher_request_alloc(ctr_tfm, GFP_KERNEL);\n\tif (!req)\n\t\tgoto out_free_ablkcipher;\n\n\treq_data = kmalloc(sizeof(*req_data), GFP_KERNEL);\n\tif (!req_data)\n\t\tgoto out_free_request;\n\n\tmemset(req_data->iv, 0, sizeof(req_data->iv));\n\n\t/* Clear the data in the hash sub key container to zero.*/\n\t/* We want to cipher all zeros to create the hash sub key. */\n\tmemset(hash_subkey, 0, RFC4106_HASH_SUBKEY_SIZE);\n\n\tinit_completion(&req_data->result.completion);\n\tsg_init_one(&req_data->sg, hash_subkey, RFC4106_HASH_SUBKEY_SIZE);\n\tablkcipher_request_set_tfm(req, ctr_tfm);\n\tablkcipher_request_set_callback(req, CRYPTO_TFM_REQ_MAY_SLEEP |\n\t\t\t\t\tCRYPTO_TFM_REQ_MAY_BACKLOG,\n\t\t\t\t\trfc4106_set_hash_subkey_done,\n\t\t\t\t\t&req_data->result);\n\n\tablkcipher_request_set_crypt(req, &req_data->sg,\n\t\t&req_data->sg, RFC4106_HASH_SUBKEY_SIZE, req_data->iv);\n\n\tret = crypto_ablkcipher_encrypt(req);\n\tif (ret == -EINPROGRESS || ret == -EBUSY) {\n\t\tret = wait_for_completion_interruptible\n\t\t\t(&req_data->result.completion);\n\t\tif (!ret)\n\t\t\tret = req_data->result.err;\n\t}\n\tkfree(req_data);\nout_free_request:\n\tablkcipher_request_free(req);\nout_free_ablkcipher:\n\tcrypto_free_ablkcipher(ctr_tfm);\n\treturn ret;\n}\n\nstatic int rfc4106_set_key(struct crypto_aead *parent, const u8 *key,\n\t\t\t\t\t\t   unsigned int key_len)\n{\n\tint ret = 0;\n\tstruct crypto_tfm *tfm = crypto_aead_tfm(parent);\n\tstruct aesni_rfc4106_gcm_ctx *ctx = aesni_rfc4106_gcm_ctx_get(parent);\n\tstruct crypto_aead *cryptd_child = cryptd_aead_child(ctx->cryptd_tfm);\n\tstruct aesni_rfc4106_gcm_ctx *child_ctx =\n                                 aesni_rfc4106_gcm_ctx_get(cryptd_child);\n\tu8 *new_key_align, *new_key_mem = NULL;\n\n\tif (key_len < 4) {\n\t\tcrypto_tfm_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);\n\t\treturn -EINVAL;\n\t}\n\t/*Account for 4 byte nonce at the end.*/\n\tkey_len -= 4;\n\tif (key_len != AES_KEYSIZE_128) {\n\t\tcrypto_tfm_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(ctx->nonce, key + key_len, sizeof(ctx->nonce));\n\t/*This must be on a 16 byte boundary!*/\n\tif ((unsigned long)(&(ctx->aes_key_expanded.key_enc[0])) % AESNI_ALIGN)\n\t\treturn -EINVAL;\n\n\tif ((unsigned long)key % AESNI_ALIGN) {\n\t\t/*key is not aligned: use an auxuliar aligned pointer*/\n\t\tnew_key_mem = kmalloc(key_len+AESNI_ALIGN, GFP_KERNEL);\n\t\tif (!new_key_mem)\n\t\t\treturn -ENOMEM;\n\n\t\tnew_key_align = PTR_ALIGN(new_key_mem, AESNI_ALIGN);\n\t\tmemcpy(new_key_align, key, key_len);\n\t\tkey = new_key_align;\n\t}\n\n\tif (!irq_fpu_usable())\n\t\tret = crypto_aes_expand_key(&(ctx->aes_key_expanded),\n\t\tkey, key_len);\n\telse {\n\t\tkernel_fpu_begin();\n\t\tret = aesni_set_key(&(ctx->aes_key_expanded), key, key_len);\n\t\tkernel_fpu_end();\n\t}\n\t/*This must be on a 16 byte boundary!*/\n\tif ((unsigned long)(&(ctx->hash_subkey[0])) % AESNI_ALIGN) {\n\t\tret = -EINVAL;\n\t\tgoto exit;\n\t}\n\tret = rfc4106_set_hash_subkey(ctx->hash_subkey, key, key_len);\n\tmemcpy(child_ctx, ctx, sizeof(*ctx));\nexit:\n\tkfree(new_key_mem);\n\treturn ret;\n}\n\n/* This is the Integrity Check Value (aka the authentication tag length and can\n * be 8, 12 or 16 bytes long. */\nstatic int rfc4106_set_authsize(struct crypto_aead *parent,\n\t\t\t\tunsigned int authsize)\n{\n\tstruct aesni_rfc4106_gcm_ctx *ctx = aesni_rfc4106_gcm_ctx_get(parent);\n\tstruct crypto_aead *cryptd_child = cryptd_aead_child(ctx->cryptd_tfm);\n\n\tswitch (authsize) {\n\tcase 8:\n\tcase 12:\n\tcase 16:\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\tcrypto_aead_crt(parent)->authsize = authsize;\n\tcrypto_aead_crt(cryptd_child)->authsize = authsize;\n\treturn 0;\n}\n\nstatic int rfc4106_encrypt(struct aead_request *req)\n{\n\tint ret;\n\tstruct crypto_aead *tfm = crypto_aead_reqtfm(req);\n\tstruct aesni_rfc4106_gcm_ctx *ctx = aesni_rfc4106_gcm_ctx_get(tfm);\n\n\tif (!irq_fpu_usable()) {\n\t\tstruct aead_request *cryptd_req =\n\t\t\t(struct aead_request *) aead_request_ctx(req);\n\t\tmemcpy(cryptd_req, req, sizeof(*req));\n\t\taead_request_set_tfm(cryptd_req, &ctx->cryptd_tfm->base);\n\t\treturn crypto_aead_encrypt(cryptd_req);\n\t} else {\n\t\tstruct crypto_aead *cryptd_child = cryptd_aead_child(ctx->cryptd_tfm);\n\t\tkernel_fpu_begin();\n\t\tret = cryptd_child->base.crt_aead.encrypt(req);\n\t\tkernel_fpu_end();\n\t\treturn ret;\n\t}\n}\n\nstatic int rfc4106_decrypt(struct aead_request *req)\n{\n\tint ret;\n\tstruct crypto_aead *tfm = crypto_aead_reqtfm(req);\n\tstruct aesni_rfc4106_gcm_ctx *ctx = aesni_rfc4106_gcm_ctx_get(tfm);\n\n\tif (!irq_fpu_usable()) {\n\t\tstruct aead_request *cryptd_req =\n\t\t\t(struct aead_request *) aead_request_ctx(req);\n\t\tmemcpy(cryptd_req, req, sizeof(*req));\n\t\taead_request_set_tfm(cryptd_req, &ctx->cryptd_tfm->base);\n\t\treturn crypto_aead_decrypt(cryptd_req);\n\t} else {\n\t\tstruct crypto_aead *cryptd_child = cryptd_aead_child(ctx->cryptd_tfm);\n\t\tkernel_fpu_begin();\n\t\tret = cryptd_child->base.crt_aead.decrypt(req);\n\t\tkernel_fpu_end();\n\t\treturn ret;\n\t}\n}\n\nstatic int __driver_rfc4106_encrypt(struct aead_request *req)\n{\n\tu8 one_entry_in_sg = 0;\n\tu8 *src, *dst, *assoc;\n\t__be32 counter = cpu_to_be32(1);\n\tstruct crypto_aead *tfm = crypto_aead_reqtfm(req);\n\tstruct aesni_rfc4106_gcm_ctx *ctx = aesni_rfc4106_gcm_ctx_get(tfm);\n\tvoid *aes_ctx = &(ctx->aes_key_expanded);\n\tunsigned long auth_tag_len = crypto_aead_authsize(tfm);\n\tu8 iv_tab[16+AESNI_ALIGN];\n\tu8* iv = (u8 *) PTR_ALIGN((u8 *)iv_tab, AESNI_ALIGN);\n\tstruct scatter_walk src_sg_walk;\n\tstruct scatter_walk assoc_sg_walk;\n\tstruct scatter_walk dst_sg_walk;\n\tunsigned int i;\n\n\t/* Assuming we are supporting rfc4106 64-bit extended */\n\t/* sequence numbers We need to have the AAD length equal */\n\t/* to 8 or 12 bytes */\n\tif (unlikely(req->assoclen != 8 && req->assoclen != 12))\n\t\treturn -EINVAL;\n\t/* IV below built */\n\tfor (i = 0; i < 4; i++)\n\t\t*(iv+i) = ctx->nonce[i];\n\tfor (i = 0; i < 8; i++)\n\t\t*(iv+4+i) = req->iv[i];\n\t*((__be32 *)(iv+12)) = counter;\n\n\tif ((sg_is_last(req->src)) && (sg_is_last(req->assoc))) {\n\t\tone_entry_in_sg = 1;\n\t\tscatterwalk_start(&src_sg_walk, req->src);\n\t\tscatterwalk_start(&assoc_sg_walk, req->assoc);\n\t\tsrc = scatterwalk_map(&src_sg_walk);\n\t\tassoc = scatterwalk_map(&assoc_sg_walk);\n\t\tdst = src;\n\t\tif (unlikely(req->src != req->dst)) {\n\t\t\tscatterwalk_start(&dst_sg_walk, req->dst);\n\t\t\tdst = scatterwalk_map(&dst_sg_walk);\n\t\t}\n\n\t} else {\n\t\t/* Allocate memory for src, dst, assoc */\n\t\tsrc = kmalloc(req->cryptlen + auth_tag_len + req->assoclen,\n\t\t\tGFP_ATOMIC);\n\t\tif (unlikely(!src))\n\t\t\treturn -ENOMEM;\n\t\tassoc = (src + req->cryptlen + auth_tag_len);\n\t\tscatterwalk_map_and_copy(src, req->src, 0, req->cryptlen, 0);\n\t\tscatterwalk_map_and_copy(assoc, req->assoc, 0,\n\t\t\t\t\treq->assoclen, 0);\n\t\tdst = src;\n\t}\n\n\taesni_gcm_enc_tfm(aes_ctx, dst, src, (unsigned long)req->cryptlen, iv,\n\t\tctx->hash_subkey, assoc, (unsigned long)req->assoclen, dst\n\t\t+ ((unsigned long)req->cryptlen), auth_tag_len);\n\n\t/* The authTag (aka the Integrity Check Value) needs to be written\n\t * back to the packet. */\n\tif (one_entry_in_sg) {\n\t\tif (unlikely(req->src != req->dst)) {\n\t\t\tscatterwalk_unmap(dst);\n\t\t\tscatterwalk_done(&dst_sg_walk, 0, 0);\n\t\t}\n\t\tscatterwalk_unmap(src);\n\t\tscatterwalk_unmap(assoc);\n\t\tscatterwalk_done(&src_sg_walk, 0, 0);\n\t\tscatterwalk_done(&assoc_sg_walk, 0, 0);\n\t} else {\n\t\tscatterwalk_map_and_copy(dst, req->dst, 0,\n\t\t\treq->cryptlen + auth_tag_len, 1);\n\t\tkfree(src);\n\t}\n\treturn 0;\n}\n\nstatic int __driver_rfc4106_decrypt(struct aead_request *req)\n{\n\tu8 one_entry_in_sg = 0;\n\tu8 *src, *dst, *assoc;\n\tunsigned long tempCipherLen = 0;\n\t__be32 counter = cpu_to_be32(1);\n\tint retval = 0;\n\tstruct crypto_aead *tfm = crypto_aead_reqtfm(req);\n\tstruct aesni_rfc4106_gcm_ctx *ctx = aesni_rfc4106_gcm_ctx_get(tfm);\n\tvoid *aes_ctx = &(ctx->aes_key_expanded);\n\tunsigned long auth_tag_len = crypto_aead_authsize(tfm);\n\tu8 iv_and_authTag[32+AESNI_ALIGN];\n\tu8 *iv = (u8 *) PTR_ALIGN((u8 *)iv_and_authTag, AESNI_ALIGN);\n\tu8 *authTag = iv + 16;\n\tstruct scatter_walk src_sg_walk;\n\tstruct scatter_walk assoc_sg_walk;\n\tstruct scatter_walk dst_sg_walk;\n\tunsigned int i;\n\n\tif (unlikely((req->cryptlen < auth_tag_len) ||\n\t\t(req->assoclen != 8 && req->assoclen != 12)))\n\t\treturn -EINVAL;\n\t/* Assuming we are supporting rfc4106 64-bit extended */\n\t/* sequence numbers We need to have the AAD length */\n\t/* equal to 8 or 12 bytes */\n\n\ttempCipherLen = (unsigned long)(req->cryptlen - auth_tag_len);\n\t/* IV below built */\n\tfor (i = 0; i < 4; i++)\n\t\t*(iv+i) = ctx->nonce[i];\n\tfor (i = 0; i < 8; i++)\n\t\t*(iv+4+i) = req->iv[i];\n\t*((__be32 *)(iv+12)) = counter;\n\n\tif ((sg_is_last(req->src)) && (sg_is_last(req->assoc))) {\n\t\tone_entry_in_sg = 1;\n\t\tscatterwalk_start(&src_sg_walk, req->src);\n\t\tscatterwalk_start(&assoc_sg_walk, req->assoc);\n\t\tsrc = scatterwalk_map(&src_sg_walk);\n\t\tassoc = scatterwalk_map(&assoc_sg_walk);\n\t\tdst = src;\n\t\tif (unlikely(req->src != req->dst)) {\n\t\t\tscatterwalk_start(&dst_sg_walk, req->dst);\n\t\t\tdst = scatterwalk_map(&dst_sg_walk);\n\t\t}\n\n\t} else {\n\t\t/* Allocate memory for src, dst, assoc */\n\t\tsrc = kmalloc(req->cryptlen + req->assoclen, GFP_ATOMIC);\n\t\tif (!src)\n\t\t\treturn -ENOMEM;\n\t\tassoc = (src + req->cryptlen + auth_tag_len);\n\t\tscatterwalk_map_and_copy(src, req->src, 0, req->cryptlen, 0);\n\t\tscatterwalk_map_and_copy(assoc, req->assoc, 0,\n\t\t\treq->assoclen, 0);\n\t\tdst = src;\n\t}\n\n\taesni_gcm_dec_tfm(aes_ctx, dst, src, tempCipherLen, iv,\n\t\tctx->hash_subkey, assoc, (unsigned long)req->assoclen,\n\t\tauthTag, auth_tag_len);\n\n\t/* Compare generated tag with passed in tag. */\n\tretval = crypto_memneq(src + tempCipherLen, authTag, auth_tag_len) ?\n\t\t-EBADMSG : 0;\n\n\tif (one_entry_in_sg) {\n\t\tif (unlikely(req->src != req->dst)) {\n\t\t\tscatterwalk_unmap(dst);\n\t\t\tscatterwalk_done(&dst_sg_walk, 0, 0);\n\t\t}\n\t\tscatterwalk_unmap(src);\n\t\tscatterwalk_unmap(assoc);\n\t\tscatterwalk_done(&src_sg_walk, 0, 0);\n\t\tscatterwalk_done(&assoc_sg_walk, 0, 0);\n\t} else {\n\t\tscatterwalk_map_and_copy(dst, req->dst, 0, req->cryptlen, 1);\n\t\tkfree(src);\n\t}\n\treturn retval;\n}\n#endif\n\nstatic struct crypto_alg aesni_algs[] = { {\n\t.cra_name\t\t= \"aes\",\n\t.cra_driver_name\t= \"aes-aesni\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_aes_ctx) +\n\t\t\t\t  AESNI_ALIGN - 1,\n\t.cra_alignmask\t\t= 0,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u\t= {\n\t\t.cipher\t= {\n\t\t\t.cia_min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t= aes_set_key,\n\t\t\t.cia_encrypt\t\t= aes_encrypt,\n\t\t\t.cia_decrypt\t\t= aes_decrypt\n\t\t}\n\t}\n}, {\n\t.cra_name\t\t= \"__aes-aesni\",\n\t.cra_driver_name\t= \"__driver-aes-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_aes_ctx) +\n\t\t\t\t  AESNI_ALIGN - 1,\n\t.cra_alignmask\t\t= 0,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u\t= {\n\t\t.cipher\t= {\n\t\t\t.cia_min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t= aes_set_key,\n\t\t\t.cia_encrypt\t\t= __aes_encrypt,\n\t\t\t.cia_decrypt\t\t= __aes_decrypt\n\t\t}\n\t}\n}, {\n\t.cra_name\t\t= \"__ecb-aes-aesni\",\n\t.cra_driver_name\t= \"__driver-ecb-aes-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_aes_ctx) +\n\t\t\t\t  AESNI_ALIGN - 1,\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= aes_set_key,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__cbc-aes-aesni\",\n\t.cra_driver_name\t= \"__driver-cbc-aes-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_aes_ctx) +\n\t\t\t\t  AESNI_ALIGN - 1,\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= aes_set_key,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ecb(aes)\",\n\t.cra_driver_name\t= \"ecb-aes-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_ecb_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(aes)\",\n\t.cra_driver_name\t= \"cbc-aes-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_cbc_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n#ifdef CONFIG_X86_64\n}, {\n\t.cra_name\t\t= \"__ctr-aes-aesni\",\n\t.cra_driver_name\t= \"__driver-ctr-aes-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct crypto_aes_ctx) +\n\t\t\t\t  AESNI_ALIGN - 1,\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t\t.setkey\t\t= aes_set_key,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(aes)\",\n\t.cra_driver_name\t= \"ctr-aes-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_ctr_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_encrypt,\n\t\t\t.geniv\t\t= \"chainiv\",\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__gcm-aes-aesni\",\n\t.cra_driver_name\t= \"__driver-gcm-aes-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_AEAD,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct aesni_rfc4106_gcm_ctx) +\n\t\t\t\t  AESNI_ALIGN,\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_aead_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.aead = {\n\t\t\t.encrypt\t= __driver_rfc4106_encrypt,\n\t\t\t.decrypt\t= __driver_rfc4106_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"rfc4106(gcm(aes))\",\n\t.cra_driver_name\t= \"rfc4106-gcm-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_AEAD | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct aesni_rfc4106_gcm_ctx) +\n\t\t\t\t  AESNI_ALIGN,\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_nivaead_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= rfc4106_init,\n\t.cra_exit\t\t= rfc4106_exit,\n\t.cra_u = {\n\t\t.aead = {\n\t\t\t.setkey\t\t= rfc4106_set_key,\n\t\t\t.setauthsize\t= rfc4106_set_authsize,\n\t\t\t.encrypt\t= rfc4106_encrypt,\n\t\t\t.decrypt\t= rfc4106_decrypt,\n\t\t\t.geniv\t\t= \"seqiv\",\n\t\t\t.ivsize\t\t= 8,\n\t\t\t.maxauthsize\t= 16,\n\t\t},\n\t},\n#endif\n#if IS_ENABLED(CONFIG_CRYPTO_PCBC)\n}, {\n\t.cra_name\t\t= \"pcbc(aes)\",\n\t.cra_driver_name\t= \"pcbc-aes-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_pcbc_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n#endif\n}, {\n\t.cra_name\t\t= \"__lrw-aes-aesni\",\n\t.cra_driver_name\t= \"__driver-lrw-aes-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct aesni_lrw_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_exit\t\t= lrw_aesni_exit_tfm,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE + AES_BLOCK_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE + AES_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t\t.setkey\t\t= lrw_aesni_setkey,\n\t\t\t.encrypt\t= lrw_encrypt,\n\t\t\t.decrypt\t= lrw_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__xts-aes-aesni\",\n\t.cra_driver_name\t= \"__driver-xts-aes-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct aesni_xts_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= 2 * AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= 2 * AES_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t\t.setkey\t\t= xts_aesni_setkey,\n\t\t\t.encrypt\t= xts_encrypt,\n\t\t\t.decrypt\t= xts_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"lrw(aes)\",\n\t.cra_driver_name\t= \"lrw-aes-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= AES_MIN_KEY_SIZE + AES_BLOCK_SIZE,\n\t\t\t.max_keysize\t= AES_MAX_KEY_SIZE + AES_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"xts(aes)\",\n\t.cra_driver_name\t= \"xts-aes-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= AES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= 2 * AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= 2 * AES_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n} };\n\n\nstatic const struct x86_cpu_id aesni_cpu_id[] = {\n\tX86_FEATURE_MATCH(X86_FEATURE_AES),\n\t{}\n};\nMODULE_DEVICE_TABLE(x86cpu, aesni_cpu_id);\n\nstatic int __init aesni_init(void)\n{\n\tint err;\n\n\tif (!x86_match_cpu(aesni_cpu_id))\n\t\treturn -ENODEV;\n#ifdef CONFIG_X86_64\n#ifdef CONFIG_AS_AVX2\n\tif (boot_cpu_has(X86_FEATURE_AVX2)) {\n\t\tpr_info(\"AVX2 version of gcm_enc/dec engaged.\\n\");\n\t\taesni_gcm_enc_tfm = aesni_gcm_enc_avx2;\n\t\taesni_gcm_dec_tfm = aesni_gcm_dec_avx2;\n\t} else\n#endif\n#ifdef CONFIG_AS_AVX\n\tif (boot_cpu_has(X86_FEATURE_AVX)) {\n\t\tpr_info(\"AVX version of gcm_enc/dec engaged.\\n\");\n\t\taesni_gcm_enc_tfm = aesni_gcm_enc_avx;\n\t\taesni_gcm_dec_tfm = aesni_gcm_dec_avx;\n\t} else\n#endif\n\t{\n\t\tpr_info(\"SSE version of gcm_enc/dec engaged.\\n\");\n\t\taesni_gcm_enc_tfm = aesni_gcm_enc;\n\t\taesni_gcm_dec_tfm = aesni_gcm_dec;\n\t}\n\taesni_ctr_enc_tfm = aesni_ctr_enc;\n#ifdef CONFIG_AS_AVX\n\tif (cpu_has_avx) {\n\t\t/* optimize performance of ctr mode encryption transform */\n\t\taesni_ctr_enc_tfm = aesni_ctr_enc_avx_tfm;\n\t\tpr_info(\"AES CTR mode by8 optimization enabled\\n\");\n\t}\n#endif\n#endif\n\n\terr = crypto_fpu_init();\n\tif (err)\n\t\treturn err;\n\n\treturn crypto_register_algs(aesni_algs, ARRAY_SIZE(aesni_algs));\n}\n\nstatic void __exit aesni_exit(void)\n{\n\tcrypto_unregister_algs(aesni_algs, ARRAY_SIZE(aesni_algs));\n\n\tcrypto_fpu_exit();\n}\n\nmodule_init(aesni_init);\nmodule_exit(aesni_exit);\n\nMODULE_DESCRIPTION(\"Rijndael (AES) Cipher Algorithm, Intel AES-NI instructions optimized\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_CRYPTO(\"aes\");\n", "/*\n * Glue Code for assembler optimized version of Blowfish\n *\n * Copyright (c) 2011 Jussi Kivilinna <jussi.kivilinna@mbnet.fi>\n *\n * CBC & ECB parts based on code (crypto/cbc.c,ecb.c) by:\n *   Copyright (c) 2006 Herbert Xu <herbert@gondor.apana.org.au>\n * CTR part based on code (crypto/ctr.c) by:\n *   (C) Copyright IBM Corp. 2007 - Joy Latten <latten@us.ibm.com>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307\n * USA\n *\n */\n\n#include <asm/processor.h>\n#include <crypto/blowfish.h>\n#include <linux/crypto.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/types.h>\n#include <crypto/algapi.h>\n\n/* regular block cipher functions */\nasmlinkage void __blowfish_enc_blk(struct bf_ctx *ctx, u8 *dst, const u8 *src,\n\t\t\t\t   bool xor);\nasmlinkage void blowfish_dec_blk(struct bf_ctx *ctx, u8 *dst, const u8 *src);\n\n/* 4-way parallel cipher functions */\nasmlinkage void __blowfish_enc_blk_4way(struct bf_ctx *ctx, u8 *dst,\n\t\t\t\t\tconst u8 *src, bool xor);\nasmlinkage void blowfish_dec_blk_4way(struct bf_ctx *ctx, u8 *dst,\n\t\t\t\t      const u8 *src);\n\nstatic inline void blowfish_enc_blk(struct bf_ctx *ctx, u8 *dst, const u8 *src)\n{\n\t__blowfish_enc_blk(ctx, dst, src, false);\n}\n\nstatic inline void blowfish_enc_blk_xor(struct bf_ctx *ctx, u8 *dst,\n\t\t\t\t\tconst u8 *src)\n{\n\t__blowfish_enc_blk(ctx, dst, src, true);\n}\n\nstatic inline void blowfish_enc_blk_4way(struct bf_ctx *ctx, u8 *dst,\n\t\t\t\t\t const u8 *src)\n{\n\t__blowfish_enc_blk_4way(ctx, dst, src, false);\n}\n\nstatic inline void blowfish_enc_blk_xor_4way(struct bf_ctx *ctx, u8 *dst,\n\t\t\t\t      const u8 *src)\n{\n\t__blowfish_enc_blk_4way(ctx, dst, src, true);\n}\n\nstatic void blowfish_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tblowfish_enc_blk(crypto_tfm_ctx(tfm), dst, src);\n}\n\nstatic void blowfish_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tblowfish_dec_blk(crypto_tfm_ctx(tfm), dst, src);\n}\n\nstatic int ecb_crypt(struct blkcipher_desc *desc, struct blkcipher_walk *walk,\n\t\t     void (*fn)(struct bf_ctx *, u8 *, const u8 *),\n\t\t     void (*fn_4way)(struct bf_ctx *, u8 *, const u8 *))\n{\n\tstruct bf_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tunsigned int bsize = BF_BLOCK_SIZE;\n\tunsigned int nbytes;\n\tint err;\n\n\terr = blkcipher_walk_virt(desc, walk);\n\n\twhile ((nbytes = walk->nbytes)) {\n\t\tu8 *wsrc = walk->src.virt.addr;\n\t\tu8 *wdst = walk->dst.virt.addr;\n\n\t\t/* Process four block batch */\n\t\tif (nbytes >= bsize * 4) {\n\t\t\tdo {\n\t\t\t\tfn_4way(ctx, wdst, wsrc);\n\n\t\t\t\twsrc += bsize * 4;\n\t\t\t\twdst += bsize * 4;\n\t\t\t\tnbytes -= bsize * 4;\n\t\t\t} while (nbytes >= bsize * 4);\n\n\t\t\tif (nbytes < bsize)\n\t\t\t\tgoto done;\n\t\t}\n\n\t\t/* Handle leftovers */\n\t\tdo {\n\t\t\tfn(ctx, wdst, wsrc);\n\n\t\t\twsrc += bsize;\n\t\t\twdst += bsize;\n\t\t\tnbytes -= bsize;\n\t\t} while (nbytes >= bsize);\n\ndone:\n\t\terr = blkcipher_walk_done(desc, walk, nbytes);\n\t}\n\n\treturn err;\n}\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_crypt(desc, &walk, blowfish_enc_blk, blowfish_enc_blk_4way);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_crypt(desc, &walk, blowfish_dec_blk, blowfish_dec_blk_4way);\n}\n\nstatic unsigned int __cbc_encrypt(struct blkcipher_desc *desc,\n\t\t\t\t  struct blkcipher_walk *walk)\n{\n\tstruct bf_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tunsigned int bsize = BF_BLOCK_SIZE;\n\tunsigned int nbytes = walk->nbytes;\n\tu64 *src = (u64 *)walk->src.virt.addr;\n\tu64 *dst = (u64 *)walk->dst.virt.addr;\n\tu64 *iv = (u64 *)walk->iv;\n\n\tdo {\n\t\t*dst = *src ^ *iv;\n\t\tblowfish_enc_blk(ctx, (u8 *)dst, (u8 *)dst);\n\t\tiv = dst;\n\n\t\tsrc += 1;\n\t\tdst += 1;\n\t\tnbytes -= bsize;\n\t} while (nbytes >= bsize);\n\n\t*(u64 *)walk->iv = *iv;\n\treturn nbytes;\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\twhile ((nbytes = walk.nbytes)) {\n\t\tnbytes = __cbc_encrypt(desc, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\n\treturn err;\n}\n\nstatic unsigned int __cbc_decrypt(struct blkcipher_desc *desc,\n\t\t\t\t  struct blkcipher_walk *walk)\n{\n\tstruct bf_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tunsigned int bsize = BF_BLOCK_SIZE;\n\tunsigned int nbytes = walk->nbytes;\n\tu64 *src = (u64 *)walk->src.virt.addr;\n\tu64 *dst = (u64 *)walk->dst.virt.addr;\n\tu64 ivs[4 - 1];\n\tu64 last_iv;\n\n\t/* Start of the last block. */\n\tsrc += nbytes / bsize - 1;\n\tdst += nbytes / bsize - 1;\n\n\tlast_iv = *src;\n\n\t/* Process four block batch */\n\tif (nbytes >= bsize * 4) {\n\t\tdo {\n\t\t\tnbytes -= bsize * 4 - bsize;\n\t\t\tsrc -= 4 - 1;\n\t\t\tdst -= 4 - 1;\n\n\t\t\tivs[0] = src[0];\n\t\t\tivs[1] = src[1];\n\t\t\tivs[2] = src[2];\n\n\t\t\tblowfish_dec_blk_4way(ctx, (u8 *)dst, (u8 *)src);\n\n\t\t\tdst[1] ^= ivs[0];\n\t\t\tdst[2] ^= ivs[1];\n\t\t\tdst[3] ^= ivs[2];\n\n\t\t\tnbytes -= bsize;\n\t\t\tif (nbytes < bsize)\n\t\t\t\tgoto done;\n\n\t\t\t*dst ^= *(src - 1);\n\t\t\tsrc -= 1;\n\t\t\tdst -= 1;\n\t\t} while (nbytes >= bsize * 4);\n\t}\n\n\t/* Handle leftovers */\n\tfor (;;) {\n\t\tblowfish_dec_blk(ctx, (u8 *)dst, (u8 *)src);\n\n\t\tnbytes -= bsize;\n\t\tif (nbytes < bsize)\n\t\t\tbreak;\n\n\t\t*dst ^= *(src - 1);\n\t\tsrc -= 1;\n\t\tdst -= 1;\n\t}\n\ndone:\n\t*dst ^= *(u64 *)walk->iv;\n\t*(u64 *)walk->iv = last_iv;\n\n\treturn nbytes;\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\twhile ((nbytes = walk.nbytes)) {\n\t\tnbytes = __cbc_decrypt(desc, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\n\treturn err;\n}\n\nstatic void ctr_crypt_final(struct bf_ctx *ctx, struct blkcipher_walk *walk)\n{\n\tu8 *ctrblk = walk->iv;\n\tu8 keystream[BF_BLOCK_SIZE];\n\tu8 *src = walk->src.virt.addr;\n\tu8 *dst = walk->dst.virt.addr;\n\tunsigned int nbytes = walk->nbytes;\n\n\tblowfish_enc_blk(ctx, keystream, ctrblk);\n\tcrypto_xor(keystream, src, nbytes);\n\tmemcpy(dst, keystream, nbytes);\n\n\tcrypto_inc(ctrblk, BF_BLOCK_SIZE);\n}\n\nstatic unsigned int __ctr_crypt(struct blkcipher_desc *desc,\n\t\t\t\tstruct blkcipher_walk *walk)\n{\n\tstruct bf_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tunsigned int bsize = BF_BLOCK_SIZE;\n\tunsigned int nbytes = walk->nbytes;\n\tu64 *src = (u64 *)walk->src.virt.addr;\n\tu64 *dst = (u64 *)walk->dst.virt.addr;\n\tu64 ctrblk = be64_to_cpu(*(__be64 *)walk->iv);\n\t__be64 ctrblocks[4];\n\n\t/* Process four block batch */\n\tif (nbytes >= bsize * 4) {\n\t\tdo {\n\t\t\tif (dst != src) {\n\t\t\t\tdst[0] = src[0];\n\t\t\t\tdst[1] = src[1];\n\t\t\t\tdst[2] = src[2];\n\t\t\t\tdst[3] = src[3];\n\t\t\t}\n\n\t\t\t/* create ctrblks for parallel encrypt */\n\t\t\tctrblocks[0] = cpu_to_be64(ctrblk++);\n\t\t\tctrblocks[1] = cpu_to_be64(ctrblk++);\n\t\t\tctrblocks[2] = cpu_to_be64(ctrblk++);\n\t\t\tctrblocks[3] = cpu_to_be64(ctrblk++);\n\n\t\t\tblowfish_enc_blk_xor_4way(ctx, (u8 *)dst,\n\t\t\t\t\t\t  (u8 *)ctrblocks);\n\n\t\t\tsrc += 4;\n\t\t\tdst += 4;\n\t\t} while ((nbytes -= bsize * 4) >= bsize * 4);\n\n\t\tif (nbytes < bsize)\n\t\t\tgoto done;\n\t}\n\n\t/* Handle leftovers */\n\tdo {\n\t\tif (dst != src)\n\t\t\t*dst = *src;\n\n\t\tctrblocks[0] = cpu_to_be64(ctrblk++);\n\n\t\tblowfish_enc_blk_xor(ctx, (u8 *)dst, (u8 *)ctrblocks);\n\n\t\tsrc += 1;\n\t\tdst += 1;\n\t} while ((nbytes -= bsize) >= bsize);\n\ndone:\n\t*(__be64 *)walk->iv = cpu_to_be64(ctrblk);\n\treturn nbytes;\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt_block(desc, &walk, BF_BLOCK_SIZE);\n\n\twhile ((nbytes = walk.nbytes) >= BF_BLOCK_SIZE) {\n\t\tnbytes = __ctr_crypt(desc, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\n\tif (walk.nbytes) {\n\t\tctr_crypt_final(crypto_blkcipher_ctx(desc->tfm), &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, 0);\n\t}\n\n\treturn err;\n}\n\nstatic struct crypto_alg bf_algs[4] = { {\n\t.cra_name\t\t= \"blowfish\",\n\t.cra_driver_name\t= \"blowfish-asm\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= BF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct bf_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.cipher = {\n\t\t\t.cia_min_keysize\t= BF_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t= BF_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t= blowfish_setkey,\n\t\t\t.cia_encrypt\t\t= blowfish_encrypt,\n\t\t\t.cia_decrypt\t\t= blowfish_decrypt,\n\t\t}\n\t}\n}, {\n\t.cra_name\t\t= \"ecb(blowfish)\",\n\t.cra_driver_name\t= \"ecb-blowfish-asm\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= BF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct bf_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= BF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= BF_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= blowfish_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(blowfish)\",\n\t.cra_driver_name\t= \"cbc-blowfish-asm\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= BF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct bf_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= BF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= BF_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= BF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= blowfish_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(blowfish)\",\n\t.cra_driver_name\t= \"ctr-blowfish-asm\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct bf_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= BF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= BF_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= BF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= blowfish_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n} };\n\nstatic bool is_blacklisted_cpu(void)\n{\n\tif (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL)\n\t\treturn false;\n\n\tif (boot_cpu_data.x86 == 0x0f) {\n\t\t/*\n\t\t * On Pentium 4, blowfish-x86_64 is slower than generic C\n\t\t * implementation because use of 64bit rotates (which are really\n\t\t * slow on P4). Therefore blacklist P4s.\n\t\t */\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic int force;\nmodule_param(force, int, 0);\nMODULE_PARM_DESC(force, \"Force module load, ignore CPU blacklist\");\n\nstatic int __init init(void)\n{\n\tif (!force && is_blacklisted_cpu()) {\n\t\tprintk(KERN_INFO\n\t\t\t\"blowfish-x86_64: performance on this CPU \"\n\t\t\t\"would be suboptimal: disabling \"\n\t\t\t\"blowfish-x86_64.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(bf_algs, ARRAY_SIZE(bf_algs));\n}\n\nstatic void __exit fini(void)\n{\n\tcrypto_unregister_algs(bf_algs, ARRAY_SIZE(bf_algs));\n}\n\nmodule_init(init);\nmodule_exit(fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Blowfish Cipher Algorithm, asm optimized\");\nMODULE_ALIAS_CRYPTO(\"blowfish\");\nMODULE_ALIAS_CRYPTO(\"blowfish-asm\");\n", "/*\n * Glue Code for x86_64/AVX2/AES-NI assembler optimized version of Camellia\n *\n * Copyright \u00a9 2013 Jussi Kivilinna <jussi.kivilinna@mbnet.fi>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n\n#include <linux/module.h>\n#include <linux/types.h>\n#include <linux/crypto.h>\n#include <linux/err.h>\n#include <crypto/ablk_helper.h>\n#include <crypto/algapi.h>\n#include <crypto/ctr.h>\n#include <crypto/lrw.h>\n#include <crypto/xts.h>\n#include <asm/xcr.h>\n#include <asm/xsave.h>\n#include <asm/crypto/camellia.h>\n#include <asm/crypto/glue_helper.h>\n\n#define CAMELLIA_AESNI_PARALLEL_BLOCKS 16\n#define CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS 32\n\n/* 32-way AVX2/AES-NI parallel cipher functions */\nasmlinkage void camellia_ecb_enc_32way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t       const u8 *src);\nasmlinkage void camellia_ecb_dec_32way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t       const u8 *src);\n\nasmlinkage void camellia_cbc_dec_32way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t       const u8 *src);\nasmlinkage void camellia_ctr_32way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t   const u8 *src, le128 *iv);\n\nasmlinkage void camellia_xts_enc_32way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t       const u8 *src, le128 *iv);\nasmlinkage void camellia_xts_dec_32way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t       const u8 *src, le128 *iv);\n\nstatic const struct common_glue_ctx camellia_enc = {\n\t.num_funcs = 4,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_ecb_enc_32way) }\n\t}, {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_ecb_enc_16way) }\n\t}, {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_enc_blk_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_enc_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_ctr = {\n\t.num_funcs = 4,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(camellia_ctr_32way) }\n\t}, {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(camellia_ctr_16way) }\n\t}, {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(camellia_crypt_ctr_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(camellia_crypt_ctr) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_enc_xts = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(camellia_xts_enc_32way) }\n\t}, {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(camellia_xts_enc_16way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(camellia_xts_enc) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_dec = {\n\t.num_funcs = 4,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_ecb_dec_32way) }\n\t}, {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_ecb_dec_16way) }\n\t}, {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_dec_blk_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_dec_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_dec_cbc = {\n\t.num_funcs = 4,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(camellia_cbc_dec_32way) }\n\t}, {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(camellia_cbc_dec_16way) }\n\t}, {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(camellia_decrypt_cbc_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(camellia_dec_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_dec_xts = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(camellia_xts_dec_32way) }\n\t}, {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(camellia_xts_dec_16way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(camellia_xts_dec) }\n\t} }\n};\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&camellia_enc, desc, dst, src, nbytes);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&camellia_dec, desc, dst, src, nbytes);\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_encrypt_128bit(GLUE_FUNC_CAST(camellia_enc_blk), desc,\n\t\t\t\t       dst, src, nbytes);\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_decrypt_128bit(&camellia_dec_cbc, desc, dst, src,\n\t\t\t\t       nbytes);\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ctr_crypt_128bit(&camellia_ctr, desc, dst, src, nbytes);\n}\n\nstatic inline bool camellia_fpu_begin(bool fpu_enabled, unsigned int nbytes)\n{\n\treturn glue_fpu_begin(CAMELLIA_BLOCK_SIZE,\n\t\t\t      CAMELLIA_AESNI_PARALLEL_BLOCKS, NULL, fpu_enabled,\n\t\t\t      nbytes);\n}\n\nstatic inline void camellia_fpu_end(bool fpu_enabled)\n{\n\tglue_fpu_end(fpu_enabled);\n}\n\nstatic int camellia_setkey(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t\t   unsigned int key_len)\n{\n\treturn __camellia_setkey(crypto_tfm_ctx(tfm), in_key, key_len,\n\t\t\t\t &tfm->crt_flags);\n}\n\nstruct crypt_priv {\n\tstruct camellia_ctx *ctx;\n\tbool fpu_enabled;\n};\n\nstatic void encrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = CAMELLIA_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = camellia_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes >= CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS * bsize) {\n\t\tcamellia_ecb_enc_32way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS;\n\t}\n\n\tif (nbytes >= CAMELLIA_AESNI_PARALLEL_BLOCKS * bsize) {\n\t\tcamellia_ecb_enc_16way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * CAMELLIA_AESNI_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * CAMELLIA_AESNI_PARALLEL_BLOCKS;\n\t}\n\n\twhile (nbytes >= CAMELLIA_PARALLEL_BLOCKS * bsize) {\n\t\tcamellia_enc_blk_2way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * CAMELLIA_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * CAMELLIA_PARALLEL_BLOCKS;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\tcamellia_enc_blk(ctx->ctx, srcdst, srcdst);\n}\n\nstatic void decrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = CAMELLIA_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = camellia_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes >= CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS * bsize) {\n\t\tcamellia_ecb_dec_32way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS;\n\t}\n\n\tif (nbytes >= CAMELLIA_AESNI_PARALLEL_BLOCKS * bsize) {\n\t\tcamellia_ecb_dec_16way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * CAMELLIA_AESNI_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * CAMELLIA_AESNI_PARALLEL_BLOCKS;\n\t}\n\n\twhile (nbytes >= CAMELLIA_PARALLEL_BLOCKS * bsize) {\n\t\tcamellia_dec_blk_2way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * CAMELLIA_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * CAMELLIA_PARALLEL_BLOCKS;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\tcamellia_dec_blk(ctx->ctx, srcdst, srcdst);\n}\n\nstatic int lrw_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->camellia_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tcamellia_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int lrw_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[CAMELLIA_AESNI_AVX2_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->camellia_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tcamellia_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&camellia_enc_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(camellia_enc_blk),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&camellia_dec_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(camellia_enc_blk),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic struct crypto_alg cmll_algs[10] = { {\n\t.cra_name\t\t= \"__ecb-camellia-aesni-avx2\",\n\t.cra_driver_name\t= \"__driver-ecb-camellia-aesni-avx2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= camellia_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__cbc-camellia-aesni-avx2\",\n\t.cra_driver_name\t= \"__driver-cbc-camellia-aesni-avx2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= camellia_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__ctr-camellia-aesni-avx2\",\n\t.cra_driver_name\t= \"__driver-ctr-camellia-aesni-avx2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= camellia_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__lrw-camellia-aesni-avx2\",\n\t.cra_driver_name\t= \"__driver-lrw-camellia-aesni-avx2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_lrw_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_exit\t\t= lrw_camellia_exit_tfm,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE +\n\t\t\t\t\t  CAMELLIA_BLOCK_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE +\n\t\t\t\t\t  CAMELLIA_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= lrw_camellia_setkey,\n\t\t\t.encrypt\t= lrw_encrypt,\n\t\t\t.decrypt\t= lrw_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__xts-camellia-aesni-avx2\",\n\t.cra_driver_name\t= \"__driver-xts-camellia-aesni-avx2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_xts_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= xts_camellia_setkey,\n\t\t\t.encrypt\t= xts_encrypt,\n\t\t\t.decrypt\t= xts_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ecb(camellia)\",\n\t.cra_driver_name\t= \"ecb-camellia-aesni-avx2\",\n\t.cra_priority\t\t= 500,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(camellia)\",\n\t.cra_driver_name\t= \"cbc-camellia-aesni-avx2\",\n\t.cra_priority\t\t= 500,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= __ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(camellia)\",\n\t.cra_driver_name\t= \"ctr-camellia-aesni-avx2\",\n\t.cra_priority\t\t= 500,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_encrypt,\n\t\t\t.geniv\t\t= \"chainiv\",\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"lrw(camellia)\",\n\t.cra_driver_name\t= \"lrw-camellia-aesni-avx2\",\n\t.cra_priority\t\t= 500,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE +\n\t\t\t\t\t  CAMELLIA_BLOCK_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE +\n\t\t\t\t\t  CAMELLIA_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"xts(camellia)\",\n\t.cra_driver_name\t= \"xts-camellia-aesni-avx2\",\n\t.cra_priority\t\t= 500,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n} };\n\nstatic int __init camellia_aesni_init(void)\n{\n\tu64 xcr0;\n\n\tif (!cpu_has_avx2 || !cpu_has_avx || !cpu_has_aes || !cpu_has_osxsave) {\n\t\tpr_info(\"AVX2 or AES-NI instructions are not detected.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\txcr0 = xgetbv(XCR_XFEATURE_ENABLED_MASK);\n\tif ((xcr0 & (XSTATE_SSE | XSTATE_YMM)) != (XSTATE_SSE | XSTATE_YMM)) {\n\t\tpr_info(\"AVX2 detected but unusable.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(cmll_algs, ARRAY_SIZE(cmll_algs));\n}\n\nstatic void __exit camellia_aesni_fini(void)\n{\n\tcrypto_unregister_algs(cmll_algs, ARRAY_SIZE(cmll_algs));\n}\n\nmodule_init(camellia_aesni_init);\nmodule_exit(camellia_aesni_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Camellia Cipher Algorithm, AES-NI/AVX2 optimized\");\nMODULE_ALIAS_CRYPTO(\"camellia\");\nMODULE_ALIAS_CRYPTO(\"camellia-asm\");\n", "/*\n * Glue Code for x86_64/AVX/AES-NI assembler optimized version of Camellia\n *\n * Copyright \u00a9 2012-2013 Jussi Kivilinna <jussi.kivilinna@iki.fi>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n\n#include <linux/module.h>\n#include <linux/types.h>\n#include <linux/crypto.h>\n#include <linux/err.h>\n#include <crypto/ablk_helper.h>\n#include <crypto/algapi.h>\n#include <crypto/ctr.h>\n#include <crypto/lrw.h>\n#include <crypto/xts.h>\n#include <asm/xcr.h>\n#include <asm/xsave.h>\n#include <asm/crypto/camellia.h>\n#include <asm/crypto/glue_helper.h>\n\n#define CAMELLIA_AESNI_PARALLEL_BLOCKS 16\n\n/* 16-way parallel cipher functions (avx/aes-ni) */\nasmlinkage void camellia_ecb_enc_16way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t       const u8 *src);\nEXPORT_SYMBOL_GPL(camellia_ecb_enc_16way);\n\nasmlinkage void camellia_ecb_dec_16way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t       const u8 *src);\nEXPORT_SYMBOL_GPL(camellia_ecb_dec_16way);\n\nasmlinkage void camellia_cbc_dec_16way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t       const u8 *src);\nEXPORT_SYMBOL_GPL(camellia_cbc_dec_16way);\n\nasmlinkage void camellia_ctr_16way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t   const u8 *src, le128 *iv);\nEXPORT_SYMBOL_GPL(camellia_ctr_16way);\n\nasmlinkage void camellia_xts_enc_16way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t       const u8 *src, le128 *iv);\nEXPORT_SYMBOL_GPL(camellia_xts_enc_16way);\n\nasmlinkage void camellia_xts_dec_16way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t       const u8 *src, le128 *iv);\nEXPORT_SYMBOL_GPL(camellia_xts_dec_16way);\n\nvoid camellia_xts_enc(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tglue_xts_crypt_128bit_one(ctx, dst, src, iv,\n\t\t\t\t  GLUE_FUNC_CAST(camellia_enc_blk));\n}\nEXPORT_SYMBOL_GPL(camellia_xts_enc);\n\nvoid camellia_xts_dec(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tglue_xts_crypt_128bit_one(ctx, dst, src, iv,\n\t\t\t\t  GLUE_FUNC_CAST(camellia_dec_blk));\n}\nEXPORT_SYMBOL_GPL(camellia_xts_dec);\n\nstatic const struct common_glue_ctx camellia_enc = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_ecb_enc_16way) }\n\t}, {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_enc_blk_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_enc_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_ctr = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(camellia_ctr_16way) }\n\t}, {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(camellia_crypt_ctr_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(camellia_crypt_ctr) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_enc_xts = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(camellia_xts_enc_16way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(camellia_xts_enc) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_dec = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_ecb_dec_16way) }\n\t}, {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_dec_blk_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_dec_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_dec_cbc = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(camellia_cbc_dec_16way) }\n\t}, {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(camellia_decrypt_cbc_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(camellia_dec_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_dec_xts = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAMELLIA_AESNI_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(camellia_xts_dec_16way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(camellia_xts_dec) }\n\t} }\n};\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&camellia_enc, desc, dst, src, nbytes);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&camellia_dec, desc, dst, src, nbytes);\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_encrypt_128bit(GLUE_FUNC_CAST(camellia_enc_blk), desc,\n\t\t\t\t       dst, src, nbytes);\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_decrypt_128bit(&camellia_dec_cbc, desc, dst, src,\n\t\t\t\t       nbytes);\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ctr_crypt_128bit(&camellia_ctr, desc, dst, src, nbytes);\n}\n\nstatic inline bool camellia_fpu_begin(bool fpu_enabled, unsigned int nbytes)\n{\n\treturn glue_fpu_begin(CAMELLIA_BLOCK_SIZE,\n\t\t\t      CAMELLIA_AESNI_PARALLEL_BLOCKS, NULL, fpu_enabled,\n\t\t\t      nbytes);\n}\n\nstatic inline void camellia_fpu_end(bool fpu_enabled)\n{\n\tglue_fpu_end(fpu_enabled);\n}\n\nstatic int camellia_setkey(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t\t   unsigned int key_len)\n{\n\treturn __camellia_setkey(crypto_tfm_ctx(tfm), in_key, key_len,\n\t\t\t\t &tfm->crt_flags);\n}\n\nstruct crypt_priv {\n\tstruct camellia_ctx *ctx;\n\tbool fpu_enabled;\n};\n\nstatic void encrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = CAMELLIA_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = camellia_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes >= CAMELLIA_AESNI_PARALLEL_BLOCKS * bsize) {\n\t\tcamellia_ecb_enc_16way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * CAMELLIA_AESNI_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * CAMELLIA_AESNI_PARALLEL_BLOCKS;\n\t}\n\n\twhile (nbytes >= CAMELLIA_PARALLEL_BLOCKS * bsize) {\n\t\tcamellia_enc_blk_2way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * CAMELLIA_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * CAMELLIA_PARALLEL_BLOCKS;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\tcamellia_enc_blk(ctx->ctx, srcdst, srcdst);\n}\n\nstatic void decrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = CAMELLIA_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = camellia_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes >= CAMELLIA_AESNI_PARALLEL_BLOCKS * bsize) {\n\t\tcamellia_ecb_dec_16way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * CAMELLIA_AESNI_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * CAMELLIA_AESNI_PARALLEL_BLOCKS;\n\t}\n\n\twhile (nbytes >= CAMELLIA_PARALLEL_BLOCKS * bsize) {\n\t\tcamellia_dec_blk_2way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * CAMELLIA_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * CAMELLIA_PARALLEL_BLOCKS;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\tcamellia_dec_blk(ctx->ctx, srcdst, srcdst);\n}\n\nstatic int lrw_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[CAMELLIA_AESNI_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->camellia_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tcamellia_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int lrw_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[CAMELLIA_AESNI_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->camellia_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tcamellia_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&camellia_enc_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(camellia_enc_blk),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&camellia_dec_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(camellia_enc_blk),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic struct crypto_alg cmll_algs[10] = { {\n\t.cra_name\t\t= \"__ecb-camellia-aesni\",\n\t.cra_driver_name\t= \"__driver-ecb-camellia-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= camellia_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__cbc-camellia-aesni\",\n\t.cra_driver_name\t= \"__driver-cbc-camellia-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= camellia_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__ctr-camellia-aesni\",\n\t.cra_driver_name\t= \"__driver-ctr-camellia-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= camellia_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__lrw-camellia-aesni\",\n\t.cra_driver_name\t= \"__driver-lrw-camellia-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_lrw_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_exit\t\t= lrw_camellia_exit_tfm,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE +\n\t\t\t\t\t  CAMELLIA_BLOCK_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE +\n\t\t\t\t\t  CAMELLIA_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= lrw_camellia_setkey,\n\t\t\t.encrypt\t= lrw_encrypt,\n\t\t\t.decrypt\t= lrw_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__xts-camellia-aesni\",\n\t.cra_driver_name\t= \"__driver-xts-camellia-aesni\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_xts_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= xts_camellia_setkey,\n\t\t\t.encrypt\t= xts_encrypt,\n\t\t\t.decrypt\t= xts_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ecb(camellia)\",\n\t.cra_driver_name\t= \"ecb-camellia-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(camellia)\",\n\t.cra_driver_name\t= \"cbc-camellia-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= __ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(camellia)\",\n\t.cra_driver_name\t= \"ctr-camellia-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_encrypt,\n\t\t\t.geniv\t\t= \"chainiv\",\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"lrw(camellia)\",\n\t.cra_driver_name\t= \"lrw-camellia-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE +\n\t\t\t\t\t  CAMELLIA_BLOCK_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE +\n\t\t\t\t\t  CAMELLIA_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"xts(camellia)\",\n\t.cra_driver_name\t= \"xts-camellia-aesni\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n} };\n\nstatic int __init camellia_aesni_init(void)\n{\n\tu64 xcr0;\n\n\tif (!cpu_has_avx || !cpu_has_aes || !cpu_has_osxsave) {\n\t\tpr_info(\"AVX or AES-NI instructions are not detected.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\txcr0 = xgetbv(XCR_XFEATURE_ENABLED_MASK);\n\tif ((xcr0 & (XSTATE_SSE | XSTATE_YMM)) != (XSTATE_SSE | XSTATE_YMM)) {\n\t\tpr_info(\"AVX detected but unusable.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(cmll_algs, ARRAY_SIZE(cmll_algs));\n}\n\nstatic void __exit camellia_aesni_fini(void)\n{\n\tcrypto_unregister_algs(cmll_algs, ARRAY_SIZE(cmll_algs));\n}\n\nmodule_init(camellia_aesni_init);\nmodule_exit(camellia_aesni_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Camellia Cipher Algorithm, AES-NI/AVX optimized\");\nMODULE_ALIAS_CRYPTO(\"camellia\");\nMODULE_ALIAS_CRYPTO(\"camellia-asm\");\n", "/*\n * Glue Code for assembler optimized version of Camellia\n *\n * Copyright (c) 2012 Jussi Kivilinna <jussi.kivilinna@mbnet.fi>\n *\n * Camellia parts based on code by:\n *  Copyright (C) 2006 NTT (Nippon Telegraph and Telephone Corporation)\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307\n * USA\n *\n */\n\n#include <asm/processor.h>\n#include <asm/unaligned.h>\n#include <linux/crypto.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/types.h>\n#include <crypto/algapi.h>\n#include <crypto/lrw.h>\n#include <crypto/xts.h>\n#include <asm/crypto/camellia.h>\n#include <asm/crypto/glue_helper.h>\n\n/* regular block cipher functions */\nasmlinkage void __camellia_enc_blk(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t   const u8 *src, bool xor);\nEXPORT_SYMBOL_GPL(__camellia_enc_blk);\nasmlinkage void camellia_dec_blk(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t const u8 *src);\nEXPORT_SYMBOL_GPL(camellia_dec_blk);\n\n/* 2-way parallel cipher functions */\nasmlinkage void __camellia_enc_blk_2way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t\tconst u8 *src, bool xor);\nEXPORT_SYMBOL_GPL(__camellia_enc_blk_2way);\nasmlinkage void camellia_dec_blk_2way(struct camellia_ctx *ctx, u8 *dst,\n\t\t\t\t      const u8 *src);\nEXPORT_SYMBOL_GPL(camellia_dec_blk_2way);\n\nstatic void camellia_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tcamellia_enc_blk(crypto_tfm_ctx(tfm), dst, src);\n}\n\nstatic void camellia_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tcamellia_dec_blk(crypto_tfm_ctx(tfm), dst, src);\n}\n\n/* camellia sboxes */\n__visible const u64 camellia_sp10011110[256] = {\n\t0x7000007070707000ULL, 0x8200008282828200ULL, 0x2c00002c2c2c2c00ULL,\n\t0xec0000ecececec00ULL, 0xb30000b3b3b3b300ULL, 0x2700002727272700ULL,\n\t0xc00000c0c0c0c000ULL, 0xe50000e5e5e5e500ULL, 0xe40000e4e4e4e400ULL,\n\t0x8500008585858500ULL, 0x5700005757575700ULL, 0x3500003535353500ULL,\n\t0xea0000eaeaeaea00ULL, 0x0c00000c0c0c0c00ULL, 0xae0000aeaeaeae00ULL,\n\t0x4100004141414100ULL, 0x2300002323232300ULL, 0xef0000efefefef00ULL,\n\t0x6b00006b6b6b6b00ULL, 0x9300009393939300ULL, 0x4500004545454500ULL,\n\t0x1900001919191900ULL, 0xa50000a5a5a5a500ULL, 0x2100002121212100ULL,\n\t0xed0000edededed00ULL, 0x0e00000e0e0e0e00ULL, 0x4f00004f4f4f4f00ULL,\n\t0x4e00004e4e4e4e00ULL, 0x1d00001d1d1d1d00ULL, 0x6500006565656500ULL,\n\t0x9200009292929200ULL, 0xbd0000bdbdbdbd00ULL, 0x8600008686868600ULL,\n\t0xb80000b8b8b8b800ULL, 0xaf0000afafafaf00ULL, 0x8f00008f8f8f8f00ULL,\n\t0x7c00007c7c7c7c00ULL, 0xeb0000ebebebeb00ULL, 0x1f00001f1f1f1f00ULL,\n\t0xce0000cececece00ULL, 0x3e00003e3e3e3e00ULL, 0x3000003030303000ULL,\n\t0xdc0000dcdcdcdc00ULL, 0x5f00005f5f5f5f00ULL, 0x5e00005e5e5e5e00ULL,\n\t0xc50000c5c5c5c500ULL, 0x0b00000b0b0b0b00ULL, 0x1a00001a1a1a1a00ULL,\n\t0xa60000a6a6a6a600ULL, 0xe10000e1e1e1e100ULL, 0x3900003939393900ULL,\n\t0xca0000cacacaca00ULL, 0xd50000d5d5d5d500ULL, 0x4700004747474700ULL,\n\t0x5d00005d5d5d5d00ULL, 0x3d00003d3d3d3d00ULL, 0xd90000d9d9d9d900ULL,\n\t0x0100000101010100ULL, 0x5a00005a5a5a5a00ULL, 0xd60000d6d6d6d600ULL,\n\t0x5100005151515100ULL, 0x5600005656565600ULL, 0x6c00006c6c6c6c00ULL,\n\t0x4d00004d4d4d4d00ULL, 0x8b00008b8b8b8b00ULL, 0x0d00000d0d0d0d00ULL,\n\t0x9a00009a9a9a9a00ULL, 0x6600006666666600ULL, 0xfb0000fbfbfbfb00ULL,\n\t0xcc0000cccccccc00ULL, 0xb00000b0b0b0b000ULL, 0x2d00002d2d2d2d00ULL,\n\t0x7400007474747400ULL, 0x1200001212121200ULL, 0x2b00002b2b2b2b00ULL,\n\t0x2000002020202000ULL, 0xf00000f0f0f0f000ULL, 0xb10000b1b1b1b100ULL,\n\t0x8400008484848400ULL, 0x9900009999999900ULL, 0xdf0000dfdfdfdf00ULL,\n\t0x4c00004c4c4c4c00ULL, 0xcb0000cbcbcbcb00ULL, 0xc20000c2c2c2c200ULL,\n\t0x3400003434343400ULL, 0x7e00007e7e7e7e00ULL, 0x7600007676767600ULL,\n\t0x0500000505050500ULL, 0x6d00006d6d6d6d00ULL, 0xb70000b7b7b7b700ULL,\n\t0xa90000a9a9a9a900ULL, 0x3100003131313100ULL, 0xd10000d1d1d1d100ULL,\n\t0x1700001717171700ULL, 0x0400000404040400ULL, 0xd70000d7d7d7d700ULL,\n\t0x1400001414141400ULL, 0x5800005858585800ULL, 0x3a00003a3a3a3a00ULL,\n\t0x6100006161616100ULL, 0xde0000dededede00ULL, 0x1b00001b1b1b1b00ULL,\n\t0x1100001111111100ULL, 0x1c00001c1c1c1c00ULL, 0x3200003232323200ULL,\n\t0x0f00000f0f0f0f00ULL, 0x9c00009c9c9c9c00ULL, 0x1600001616161600ULL,\n\t0x5300005353535300ULL, 0x1800001818181800ULL, 0xf20000f2f2f2f200ULL,\n\t0x2200002222222200ULL, 0xfe0000fefefefe00ULL, 0x4400004444444400ULL,\n\t0xcf0000cfcfcfcf00ULL, 0xb20000b2b2b2b200ULL, 0xc30000c3c3c3c300ULL,\n\t0xb50000b5b5b5b500ULL, 0x7a00007a7a7a7a00ULL, 0x9100009191919100ULL,\n\t0x2400002424242400ULL, 0x0800000808080800ULL, 0xe80000e8e8e8e800ULL,\n\t0xa80000a8a8a8a800ULL, 0x6000006060606000ULL, 0xfc0000fcfcfcfc00ULL,\n\t0x6900006969696900ULL, 0x5000005050505000ULL, 0xaa0000aaaaaaaa00ULL,\n\t0xd00000d0d0d0d000ULL, 0xa00000a0a0a0a000ULL, 0x7d00007d7d7d7d00ULL,\n\t0xa10000a1a1a1a100ULL, 0x8900008989898900ULL, 0x6200006262626200ULL,\n\t0x9700009797979700ULL, 0x5400005454545400ULL, 0x5b00005b5b5b5b00ULL,\n\t0x1e00001e1e1e1e00ULL, 0x9500009595959500ULL, 0xe00000e0e0e0e000ULL,\n\t0xff0000ffffffff00ULL, 0x6400006464646400ULL, 0xd20000d2d2d2d200ULL,\n\t0x1000001010101000ULL, 0xc40000c4c4c4c400ULL, 0x0000000000000000ULL,\n\t0x4800004848484800ULL, 0xa30000a3a3a3a300ULL, 0xf70000f7f7f7f700ULL,\n\t0x7500007575757500ULL, 0xdb0000dbdbdbdb00ULL, 0x8a00008a8a8a8a00ULL,\n\t0x0300000303030300ULL, 0xe60000e6e6e6e600ULL, 0xda0000dadadada00ULL,\n\t0x0900000909090900ULL, 0x3f00003f3f3f3f00ULL, 0xdd0000dddddddd00ULL,\n\t0x9400009494949400ULL, 0x8700008787878700ULL, 0x5c00005c5c5c5c00ULL,\n\t0x8300008383838300ULL, 0x0200000202020200ULL, 0xcd0000cdcdcdcd00ULL,\n\t0x4a00004a4a4a4a00ULL, 0x9000009090909000ULL, 0x3300003333333300ULL,\n\t0x7300007373737300ULL, 0x6700006767676700ULL, 0xf60000f6f6f6f600ULL,\n\t0xf30000f3f3f3f300ULL, 0x9d00009d9d9d9d00ULL, 0x7f00007f7f7f7f00ULL,\n\t0xbf0000bfbfbfbf00ULL, 0xe20000e2e2e2e200ULL, 0x5200005252525200ULL,\n\t0x9b00009b9b9b9b00ULL, 0xd80000d8d8d8d800ULL, 0x2600002626262600ULL,\n\t0xc80000c8c8c8c800ULL, 0x3700003737373700ULL, 0xc60000c6c6c6c600ULL,\n\t0x3b00003b3b3b3b00ULL, 0x8100008181818100ULL, 0x9600009696969600ULL,\n\t0x6f00006f6f6f6f00ULL, 0x4b00004b4b4b4b00ULL, 0x1300001313131300ULL,\n\t0xbe0000bebebebe00ULL, 0x6300006363636300ULL, 0x2e00002e2e2e2e00ULL,\n\t0xe90000e9e9e9e900ULL, 0x7900007979797900ULL, 0xa70000a7a7a7a700ULL,\n\t0x8c00008c8c8c8c00ULL, 0x9f00009f9f9f9f00ULL, 0x6e00006e6e6e6e00ULL,\n\t0xbc0000bcbcbcbc00ULL, 0x8e00008e8e8e8e00ULL, 0x2900002929292900ULL,\n\t0xf50000f5f5f5f500ULL, 0xf90000f9f9f9f900ULL, 0xb60000b6b6b6b600ULL,\n\t0x2f00002f2f2f2f00ULL, 0xfd0000fdfdfdfd00ULL, 0xb40000b4b4b4b400ULL,\n\t0x5900005959595900ULL, 0x7800007878787800ULL, 0x9800009898989800ULL,\n\t0x0600000606060600ULL, 0x6a00006a6a6a6a00ULL, 0xe70000e7e7e7e700ULL,\n\t0x4600004646464600ULL, 0x7100007171717100ULL, 0xba0000babababa00ULL,\n\t0xd40000d4d4d4d400ULL, 0x2500002525252500ULL, 0xab0000abababab00ULL,\n\t0x4200004242424200ULL, 0x8800008888888800ULL, 0xa20000a2a2a2a200ULL,\n\t0x8d00008d8d8d8d00ULL, 0xfa0000fafafafa00ULL, 0x7200007272727200ULL,\n\t0x0700000707070700ULL, 0xb90000b9b9b9b900ULL, 0x5500005555555500ULL,\n\t0xf80000f8f8f8f800ULL, 0xee0000eeeeeeee00ULL, 0xac0000acacacac00ULL,\n\t0x0a00000a0a0a0a00ULL, 0x3600003636363600ULL, 0x4900004949494900ULL,\n\t0x2a00002a2a2a2a00ULL, 0x6800006868686800ULL, 0x3c00003c3c3c3c00ULL,\n\t0x3800003838383800ULL, 0xf10000f1f1f1f100ULL, 0xa40000a4a4a4a400ULL,\n\t0x4000004040404000ULL, 0x2800002828282800ULL, 0xd30000d3d3d3d300ULL,\n\t0x7b00007b7b7b7b00ULL, 0xbb0000bbbbbbbb00ULL, 0xc90000c9c9c9c900ULL,\n\t0x4300004343434300ULL, 0xc10000c1c1c1c100ULL, 0x1500001515151500ULL,\n\t0xe30000e3e3e3e300ULL, 0xad0000adadadad00ULL, 0xf40000f4f4f4f400ULL,\n\t0x7700007777777700ULL, 0xc70000c7c7c7c700ULL, 0x8000008080808000ULL,\n\t0x9e00009e9e9e9e00ULL,\n};\n\n__visible const u64 camellia_sp22000222[256] = {\n\t0xe0e0000000e0e0e0ULL, 0x0505000000050505ULL, 0x5858000000585858ULL,\n\t0xd9d9000000d9d9d9ULL, 0x6767000000676767ULL, 0x4e4e0000004e4e4eULL,\n\t0x8181000000818181ULL, 0xcbcb000000cbcbcbULL, 0xc9c9000000c9c9c9ULL,\n\t0x0b0b0000000b0b0bULL, 0xaeae000000aeaeaeULL, 0x6a6a0000006a6a6aULL,\n\t0xd5d5000000d5d5d5ULL, 0x1818000000181818ULL, 0x5d5d0000005d5d5dULL,\n\t0x8282000000828282ULL, 0x4646000000464646ULL, 0xdfdf000000dfdfdfULL,\n\t0xd6d6000000d6d6d6ULL, 0x2727000000272727ULL, 0x8a8a0000008a8a8aULL,\n\t0x3232000000323232ULL, 0x4b4b0000004b4b4bULL, 0x4242000000424242ULL,\n\t0xdbdb000000dbdbdbULL, 0x1c1c0000001c1c1cULL, 0x9e9e0000009e9e9eULL,\n\t0x9c9c0000009c9c9cULL, 0x3a3a0000003a3a3aULL, 0xcaca000000cacacaULL,\n\t0x2525000000252525ULL, 0x7b7b0000007b7b7bULL, 0x0d0d0000000d0d0dULL,\n\t0x7171000000717171ULL, 0x5f5f0000005f5f5fULL, 0x1f1f0000001f1f1fULL,\n\t0xf8f8000000f8f8f8ULL, 0xd7d7000000d7d7d7ULL, 0x3e3e0000003e3e3eULL,\n\t0x9d9d0000009d9d9dULL, 0x7c7c0000007c7c7cULL, 0x6060000000606060ULL,\n\t0xb9b9000000b9b9b9ULL, 0xbebe000000bebebeULL, 0xbcbc000000bcbcbcULL,\n\t0x8b8b0000008b8b8bULL, 0x1616000000161616ULL, 0x3434000000343434ULL,\n\t0x4d4d0000004d4d4dULL, 0xc3c3000000c3c3c3ULL, 0x7272000000727272ULL,\n\t0x9595000000959595ULL, 0xabab000000abababULL, 0x8e8e0000008e8e8eULL,\n\t0xbaba000000bababaULL, 0x7a7a0000007a7a7aULL, 0xb3b3000000b3b3b3ULL,\n\t0x0202000000020202ULL, 0xb4b4000000b4b4b4ULL, 0xadad000000adadadULL,\n\t0xa2a2000000a2a2a2ULL, 0xacac000000acacacULL, 0xd8d8000000d8d8d8ULL,\n\t0x9a9a0000009a9a9aULL, 0x1717000000171717ULL, 0x1a1a0000001a1a1aULL,\n\t0x3535000000353535ULL, 0xcccc000000ccccccULL, 0xf7f7000000f7f7f7ULL,\n\t0x9999000000999999ULL, 0x6161000000616161ULL, 0x5a5a0000005a5a5aULL,\n\t0xe8e8000000e8e8e8ULL, 0x2424000000242424ULL, 0x5656000000565656ULL,\n\t0x4040000000404040ULL, 0xe1e1000000e1e1e1ULL, 0x6363000000636363ULL,\n\t0x0909000000090909ULL, 0x3333000000333333ULL, 0xbfbf000000bfbfbfULL,\n\t0x9898000000989898ULL, 0x9797000000979797ULL, 0x8585000000858585ULL,\n\t0x6868000000686868ULL, 0xfcfc000000fcfcfcULL, 0xecec000000ecececULL,\n\t0x0a0a0000000a0a0aULL, 0xdada000000dadadaULL, 0x6f6f0000006f6f6fULL,\n\t0x5353000000535353ULL, 0x6262000000626262ULL, 0xa3a3000000a3a3a3ULL,\n\t0x2e2e0000002e2e2eULL, 0x0808000000080808ULL, 0xafaf000000afafafULL,\n\t0x2828000000282828ULL, 0xb0b0000000b0b0b0ULL, 0x7474000000747474ULL,\n\t0xc2c2000000c2c2c2ULL, 0xbdbd000000bdbdbdULL, 0x3636000000363636ULL,\n\t0x2222000000222222ULL, 0x3838000000383838ULL, 0x6464000000646464ULL,\n\t0x1e1e0000001e1e1eULL, 0x3939000000393939ULL, 0x2c2c0000002c2c2cULL,\n\t0xa6a6000000a6a6a6ULL, 0x3030000000303030ULL, 0xe5e5000000e5e5e5ULL,\n\t0x4444000000444444ULL, 0xfdfd000000fdfdfdULL, 0x8888000000888888ULL,\n\t0x9f9f0000009f9f9fULL, 0x6565000000656565ULL, 0x8787000000878787ULL,\n\t0x6b6b0000006b6b6bULL, 0xf4f4000000f4f4f4ULL, 0x2323000000232323ULL,\n\t0x4848000000484848ULL, 0x1010000000101010ULL, 0xd1d1000000d1d1d1ULL,\n\t0x5151000000515151ULL, 0xc0c0000000c0c0c0ULL, 0xf9f9000000f9f9f9ULL,\n\t0xd2d2000000d2d2d2ULL, 0xa0a0000000a0a0a0ULL, 0x5555000000555555ULL,\n\t0xa1a1000000a1a1a1ULL, 0x4141000000414141ULL, 0xfafa000000fafafaULL,\n\t0x4343000000434343ULL, 0x1313000000131313ULL, 0xc4c4000000c4c4c4ULL,\n\t0x2f2f0000002f2f2fULL, 0xa8a8000000a8a8a8ULL, 0xb6b6000000b6b6b6ULL,\n\t0x3c3c0000003c3c3cULL, 0x2b2b0000002b2b2bULL, 0xc1c1000000c1c1c1ULL,\n\t0xffff000000ffffffULL, 0xc8c8000000c8c8c8ULL, 0xa5a5000000a5a5a5ULL,\n\t0x2020000000202020ULL, 0x8989000000898989ULL, 0x0000000000000000ULL,\n\t0x9090000000909090ULL, 0x4747000000474747ULL, 0xefef000000efefefULL,\n\t0xeaea000000eaeaeaULL, 0xb7b7000000b7b7b7ULL, 0x1515000000151515ULL,\n\t0x0606000000060606ULL, 0xcdcd000000cdcdcdULL, 0xb5b5000000b5b5b5ULL,\n\t0x1212000000121212ULL, 0x7e7e0000007e7e7eULL, 0xbbbb000000bbbbbbULL,\n\t0x2929000000292929ULL, 0x0f0f0000000f0f0fULL, 0xb8b8000000b8b8b8ULL,\n\t0x0707000000070707ULL, 0x0404000000040404ULL, 0x9b9b0000009b9b9bULL,\n\t0x9494000000949494ULL, 0x2121000000212121ULL, 0x6666000000666666ULL,\n\t0xe6e6000000e6e6e6ULL, 0xcece000000cececeULL, 0xeded000000edededULL,\n\t0xe7e7000000e7e7e7ULL, 0x3b3b0000003b3b3bULL, 0xfefe000000fefefeULL,\n\t0x7f7f0000007f7f7fULL, 0xc5c5000000c5c5c5ULL, 0xa4a4000000a4a4a4ULL,\n\t0x3737000000373737ULL, 0xb1b1000000b1b1b1ULL, 0x4c4c0000004c4c4cULL,\n\t0x9191000000919191ULL, 0x6e6e0000006e6e6eULL, 0x8d8d0000008d8d8dULL,\n\t0x7676000000767676ULL, 0x0303000000030303ULL, 0x2d2d0000002d2d2dULL,\n\t0xdede000000dededeULL, 0x9696000000969696ULL, 0x2626000000262626ULL,\n\t0x7d7d0000007d7d7dULL, 0xc6c6000000c6c6c6ULL, 0x5c5c0000005c5c5cULL,\n\t0xd3d3000000d3d3d3ULL, 0xf2f2000000f2f2f2ULL, 0x4f4f0000004f4f4fULL,\n\t0x1919000000191919ULL, 0x3f3f0000003f3f3fULL, 0xdcdc000000dcdcdcULL,\n\t0x7979000000797979ULL, 0x1d1d0000001d1d1dULL, 0x5252000000525252ULL,\n\t0xebeb000000ebebebULL, 0xf3f3000000f3f3f3ULL, 0x6d6d0000006d6d6dULL,\n\t0x5e5e0000005e5e5eULL, 0xfbfb000000fbfbfbULL, 0x6969000000696969ULL,\n\t0xb2b2000000b2b2b2ULL, 0xf0f0000000f0f0f0ULL, 0x3131000000313131ULL,\n\t0x0c0c0000000c0c0cULL, 0xd4d4000000d4d4d4ULL, 0xcfcf000000cfcfcfULL,\n\t0x8c8c0000008c8c8cULL, 0xe2e2000000e2e2e2ULL, 0x7575000000757575ULL,\n\t0xa9a9000000a9a9a9ULL, 0x4a4a0000004a4a4aULL, 0x5757000000575757ULL,\n\t0x8484000000848484ULL, 0x1111000000111111ULL, 0x4545000000454545ULL,\n\t0x1b1b0000001b1b1bULL, 0xf5f5000000f5f5f5ULL, 0xe4e4000000e4e4e4ULL,\n\t0x0e0e0000000e0e0eULL, 0x7373000000737373ULL, 0xaaaa000000aaaaaaULL,\n\t0xf1f1000000f1f1f1ULL, 0xdddd000000ddddddULL, 0x5959000000595959ULL,\n\t0x1414000000141414ULL, 0x6c6c0000006c6c6cULL, 0x9292000000929292ULL,\n\t0x5454000000545454ULL, 0xd0d0000000d0d0d0ULL, 0x7878000000787878ULL,\n\t0x7070000000707070ULL, 0xe3e3000000e3e3e3ULL, 0x4949000000494949ULL,\n\t0x8080000000808080ULL, 0x5050000000505050ULL, 0xa7a7000000a7a7a7ULL,\n\t0xf6f6000000f6f6f6ULL, 0x7777000000777777ULL, 0x9393000000939393ULL,\n\t0x8686000000868686ULL, 0x8383000000838383ULL, 0x2a2a0000002a2a2aULL,\n\t0xc7c7000000c7c7c7ULL, 0x5b5b0000005b5b5bULL, 0xe9e9000000e9e9e9ULL,\n\t0xeeee000000eeeeeeULL, 0x8f8f0000008f8f8fULL, 0x0101000000010101ULL,\n\t0x3d3d0000003d3d3dULL,\n};\n\n__visible const u64 camellia_sp03303033[256] = {\n\t0x0038380038003838ULL, 0x0041410041004141ULL, 0x0016160016001616ULL,\n\t0x0076760076007676ULL, 0x00d9d900d900d9d9ULL, 0x0093930093009393ULL,\n\t0x0060600060006060ULL, 0x00f2f200f200f2f2ULL, 0x0072720072007272ULL,\n\t0x00c2c200c200c2c2ULL, 0x00abab00ab00ababULL, 0x009a9a009a009a9aULL,\n\t0x0075750075007575ULL, 0x0006060006000606ULL, 0x0057570057005757ULL,\n\t0x00a0a000a000a0a0ULL, 0x0091910091009191ULL, 0x00f7f700f700f7f7ULL,\n\t0x00b5b500b500b5b5ULL, 0x00c9c900c900c9c9ULL, 0x00a2a200a200a2a2ULL,\n\t0x008c8c008c008c8cULL, 0x00d2d200d200d2d2ULL, 0x0090900090009090ULL,\n\t0x00f6f600f600f6f6ULL, 0x0007070007000707ULL, 0x00a7a700a700a7a7ULL,\n\t0x0027270027002727ULL, 0x008e8e008e008e8eULL, 0x00b2b200b200b2b2ULL,\n\t0x0049490049004949ULL, 0x00dede00de00dedeULL, 0x0043430043004343ULL,\n\t0x005c5c005c005c5cULL, 0x00d7d700d700d7d7ULL, 0x00c7c700c700c7c7ULL,\n\t0x003e3e003e003e3eULL, 0x00f5f500f500f5f5ULL, 0x008f8f008f008f8fULL,\n\t0x0067670067006767ULL, 0x001f1f001f001f1fULL, 0x0018180018001818ULL,\n\t0x006e6e006e006e6eULL, 0x00afaf00af00afafULL, 0x002f2f002f002f2fULL,\n\t0x00e2e200e200e2e2ULL, 0x0085850085008585ULL, 0x000d0d000d000d0dULL,\n\t0x0053530053005353ULL, 0x00f0f000f000f0f0ULL, 0x009c9c009c009c9cULL,\n\t0x0065650065006565ULL, 0x00eaea00ea00eaeaULL, 0x00a3a300a300a3a3ULL,\n\t0x00aeae00ae00aeaeULL, 0x009e9e009e009e9eULL, 0x00ecec00ec00ececULL,\n\t0x0080800080008080ULL, 0x002d2d002d002d2dULL, 0x006b6b006b006b6bULL,\n\t0x00a8a800a800a8a8ULL, 0x002b2b002b002b2bULL, 0x0036360036003636ULL,\n\t0x00a6a600a600a6a6ULL, 0x00c5c500c500c5c5ULL, 0x0086860086008686ULL,\n\t0x004d4d004d004d4dULL, 0x0033330033003333ULL, 0x00fdfd00fd00fdfdULL,\n\t0x0066660066006666ULL, 0x0058580058005858ULL, 0x0096960096009696ULL,\n\t0x003a3a003a003a3aULL, 0x0009090009000909ULL, 0x0095950095009595ULL,\n\t0x0010100010001010ULL, 0x0078780078007878ULL, 0x00d8d800d800d8d8ULL,\n\t0x0042420042004242ULL, 0x00cccc00cc00ccccULL, 0x00efef00ef00efefULL,\n\t0x0026260026002626ULL, 0x00e5e500e500e5e5ULL, 0x0061610061006161ULL,\n\t0x001a1a001a001a1aULL, 0x003f3f003f003f3fULL, 0x003b3b003b003b3bULL,\n\t0x0082820082008282ULL, 0x00b6b600b600b6b6ULL, 0x00dbdb00db00dbdbULL,\n\t0x00d4d400d400d4d4ULL, 0x0098980098009898ULL, 0x00e8e800e800e8e8ULL,\n\t0x008b8b008b008b8bULL, 0x0002020002000202ULL, 0x00ebeb00eb00ebebULL,\n\t0x000a0a000a000a0aULL, 0x002c2c002c002c2cULL, 0x001d1d001d001d1dULL,\n\t0x00b0b000b000b0b0ULL, 0x006f6f006f006f6fULL, 0x008d8d008d008d8dULL,\n\t0x0088880088008888ULL, 0x000e0e000e000e0eULL, 0x0019190019001919ULL,\n\t0x0087870087008787ULL, 0x004e4e004e004e4eULL, 0x000b0b000b000b0bULL,\n\t0x00a9a900a900a9a9ULL, 0x000c0c000c000c0cULL, 0x0079790079007979ULL,\n\t0x0011110011001111ULL, 0x007f7f007f007f7fULL, 0x0022220022002222ULL,\n\t0x00e7e700e700e7e7ULL, 0x0059590059005959ULL, 0x00e1e100e100e1e1ULL,\n\t0x00dada00da00dadaULL, 0x003d3d003d003d3dULL, 0x00c8c800c800c8c8ULL,\n\t0x0012120012001212ULL, 0x0004040004000404ULL, 0x0074740074007474ULL,\n\t0x0054540054005454ULL, 0x0030300030003030ULL, 0x007e7e007e007e7eULL,\n\t0x00b4b400b400b4b4ULL, 0x0028280028002828ULL, 0x0055550055005555ULL,\n\t0x0068680068006868ULL, 0x0050500050005050ULL, 0x00bebe00be00bebeULL,\n\t0x00d0d000d000d0d0ULL, 0x00c4c400c400c4c4ULL, 0x0031310031003131ULL,\n\t0x00cbcb00cb00cbcbULL, 0x002a2a002a002a2aULL, 0x00adad00ad00adadULL,\n\t0x000f0f000f000f0fULL, 0x00caca00ca00cacaULL, 0x0070700070007070ULL,\n\t0x00ffff00ff00ffffULL, 0x0032320032003232ULL, 0x0069690069006969ULL,\n\t0x0008080008000808ULL, 0x0062620062006262ULL, 0x0000000000000000ULL,\n\t0x0024240024002424ULL, 0x00d1d100d100d1d1ULL, 0x00fbfb00fb00fbfbULL,\n\t0x00baba00ba00babaULL, 0x00eded00ed00ededULL, 0x0045450045004545ULL,\n\t0x0081810081008181ULL, 0x0073730073007373ULL, 0x006d6d006d006d6dULL,\n\t0x0084840084008484ULL, 0x009f9f009f009f9fULL, 0x00eeee00ee00eeeeULL,\n\t0x004a4a004a004a4aULL, 0x00c3c300c300c3c3ULL, 0x002e2e002e002e2eULL,\n\t0x00c1c100c100c1c1ULL, 0x0001010001000101ULL, 0x00e6e600e600e6e6ULL,\n\t0x0025250025002525ULL, 0x0048480048004848ULL, 0x0099990099009999ULL,\n\t0x00b9b900b900b9b9ULL, 0x00b3b300b300b3b3ULL, 0x007b7b007b007b7bULL,\n\t0x00f9f900f900f9f9ULL, 0x00cece00ce00ceceULL, 0x00bfbf00bf00bfbfULL,\n\t0x00dfdf00df00dfdfULL, 0x0071710071007171ULL, 0x0029290029002929ULL,\n\t0x00cdcd00cd00cdcdULL, 0x006c6c006c006c6cULL, 0x0013130013001313ULL,\n\t0x0064640064006464ULL, 0x009b9b009b009b9bULL, 0x0063630063006363ULL,\n\t0x009d9d009d009d9dULL, 0x00c0c000c000c0c0ULL, 0x004b4b004b004b4bULL,\n\t0x00b7b700b700b7b7ULL, 0x00a5a500a500a5a5ULL, 0x0089890089008989ULL,\n\t0x005f5f005f005f5fULL, 0x00b1b100b100b1b1ULL, 0x0017170017001717ULL,\n\t0x00f4f400f400f4f4ULL, 0x00bcbc00bc00bcbcULL, 0x00d3d300d300d3d3ULL,\n\t0x0046460046004646ULL, 0x00cfcf00cf00cfcfULL, 0x0037370037003737ULL,\n\t0x005e5e005e005e5eULL, 0x0047470047004747ULL, 0x0094940094009494ULL,\n\t0x00fafa00fa00fafaULL, 0x00fcfc00fc00fcfcULL, 0x005b5b005b005b5bULL,\n\t0x0097970097009797ULL, 0x00fefe00fe00fefeULL, 0x005a5a005a005a5aULL,\n\t0x00acac00ac00acacULL, 0x003c3c003c003c3cULL, 0x004c4c004c004c4cULL,\n\t0x0003030003000303ULL, 0x0035350035003535ULL, 0x00f3f300f300f3f3ULL,\n\t0x0023230023002323ULL, 0x00b8b800b800b8b8ULL, 0x005d5d005d005d5dULL,\n\t0x006a6a006a006a6aULL, 0x0092920092009292ULL, 0x00d5d500d500d5d5ULL,\n\t0x0021210021002121ULL, 0x0044440044004444ULL, 0x0051510051005151ULL,\n\t0x00c6c600c600c6c6ULL, 0x007d7d007d007d7dULL, 0x0039390039003939ULL,\n\t0x0083830083008383ULL, 0x00dcdc00dc00dcdcULL, 0x00aaaa00aa00aaaaULL,\n\t0x007c7c007c007c7cULL, 0x0077770077007777ULL, 0x0056560056005656ULL,\n\t0x0005050005000505ULL, 0x001b1b001b001b1bULL, 0x00a4a400a400a4a4ULL,\n\t0x0015150015001515ULL, 0x0034340034003434ULL, 0x001e1e001e001e1eULL,\n\t0x001c1c001c001c1cULL, 0x00f8f800f800f8f8ULL, 0x0052520052005252ULL,\n\t0x0020200020002020ULL, 0x0014140014001414ULL, 0x00e9e900e900e9e9ULL,\n\t0x00bdbd00bd00bdbdULL, 0x00dddd00dd00ddddULL, 0x00e4e400e400e4e4ULL,\n\t0x00a1a100a100a1a1ULL, 0x00e0e000e000e0e0ULL, 0x008a8a008a008a8aULL,\n\t0x00f1f100f100f1f1ULL, 0x00d6d600d600d6d6ULL, 0x007a7a007a007a7aULL,\n\t0x00bbbb00bb00bbbbULL, 0x00e3e300e300e3e3ULL, 0x0040400040004040ULL,\n\t0x004f4f004f004f4fULL,\n};\n\n__visible const u64 camellia_sp00444404[256] = {\n\t0x0000707070700070ULL, 0x00002c2c2c2c002cULL, 0x0000b3b3b3b300b3ULL,\n\t0x0000c0c0c0c000c0ULL, 0x0000e4e4e4e400e4ULL, 0x0000575757570057ULL,\n\t0x0000eaeaeaea00eaULL, 0x0000aeaeaeae00aeULL, 0x0000232323230023ULL,\n\t0x00006b6b6b6b006bULL, 0x0000454545450045ULL, 0x0000a5a5a5a500a5ULL,\n\t0x0000edededed00edULL, 0x00004f4f4f4f004fULL, 0x00001d1d1d1d001dULL,\n\t0x0000929292920092ULL, 0x0000868686860086ULL, 0x0000afafafaf00afULL,\n\t0x00007c7c7c7c007cULL, 0x00001f1f1f1f001fULL, 0x00003e3e3e3e003eULL,\n\t0x0000dcdcdcdc00dcULL, 0x00005e5e5e5e005eULL, 0x00000b0b0b0b000bULL,\n\t0x0000a6a6a6a600a6ULL, 0x0000393939390039ULL, 0x0000d5d5d5d500d5ULL,\n\t0x00005d5d5d5d005dULL, 0x0000d9d9d9d900d9ULL, 0x00005a5a5a5a005aULL,\n\t0x0000515151510051ULL, 0x00006c6c6c6c006cULL, 0x00008b8b8b8b008bULL,\n\t0x00009a9a9a9a009aULL, 0x0000fbfbfbfb00fbULL, 0x0000b0b0b0b000b0ULL,\n\t0x0000747474740074ULL, 0x00002b2b2b2b002bULL, 0x0000f0f0f0f000f0ULL,\n\t0x0000848484840084ULL, 0x0000dfdfdfdf00dfULL, 0x0000cbcbcbcb00cbULL,\n\t0x0000343434340034ULL, 0x0000767676760076ULL, 0x00006d6d6d6d006dULL,\n\t0x0000a9a9a9a900a9ULL, 0x0000d1d1d1d100d1ULL, 0x0000040404040004ULL,\n\t0x0000141414140014ULL, 0x00003a3a3a3a003aULL, 0x0000dededede00deULL,\n\t0x0000111111110011ULL, 0x0000323232320032ULL, 0x00009c9c9c9c009cULL,\n\t0x0000535353530053ULL, 0x0000f2f2f2f200f2ULL, 0x0000fefefefe00feULL,\n\t0x0000cfcfcfcf00cfULL, 0x0000c3c3c3c300c3ULL, 0x00007a7a7a7a007aULL,\n\t0x0000242424240024ULL, 0x0000e8e8e8e800e8ULL, 0x0000606060600060ULL,\n\t0x0000696969690069ULL, 0x0000aaaaaaaa00aaULL, 0x0000a0a0a0a000a0ULL,\n\t0x0000a1a1a1a100a1ULL, 0x0000626262620062ULL, 0x0000545454540054ULL,\n\t0x00001e1e1e1e001eULL, 0x0000e0e0e0e000e0ULL, 0x0000646464640064ULL,\n\t0x0000101010100010ULL, 0x0000000000000000ULL, 0x0000a3a3a3a300a3ULL,\n\t0x0000757575750075ULL, 0x00008a8a8a8a008aULL, 0x0000e6e6e6e600e6ULL,\n\t0x0000090909090009ULL, 0x0000dddddddd00ddULL, 0x0000878787870087ULL,\n\t0x0000838383830083ULL, 0x0000cdcdcdcd00cdULL, 0x0000909090900090ULL,\n\t0x0000737373730073ULL, 0x0000f6f6f6f600f6ULL, 0x00009d9d9d9d009dULL,\n\t0x0000bfbfbfbf00bfULL, 0x0000525252520052ULL, 0x0000d8d8d8d800d8ULL,\n\t0x0000c8c8c8c800c8ULL, 0x0000c6c6c6c600c6ULL, 0x0000818181810081ULL,\n\t0x00006f6f6f6f006fULL, 0x0000131313130013ULL, 0x0000636363630063ULL,\n\t0x0000e9e9e9e900e9ULL, 0x0000a7a7a7a700a7ULL, 0x00009f9f9f9f009fULL,\n\t0x0000bcbcbcbc00bcULL, 0x0000292929290029ULL, 0x0000f9f9f9f900f9ULL,\n\t0x00002f2f2f2f002fULL, 0x0000b4b4b4b400b4ULL, 0x0000787878780078ULL,\n\t0x0000060606060006ULL, 0x0000e7e7e7e700e7ULL, 0x0000717171710071ULL,\n\t0x0000d4d4d4d400d4ULL, 0x0000abababab00abULL, 0x0000888888880088ULL,\n\t0x00008d8d8d8d008dULL, 0x0000727272720072ULL, 0x0000b9b9b9b900b9ULL,\n\t0x0000f8f8f8f800f8ULL, 0x0000acacacac00acULL, 0x0000363636360036ULL,\n\t0x00002a2a2a2a002aULL, 0x00003c3c3c3c003cULL, 0x0000f1f1f1f100f1ULL,\n\t0x0000404040400040ULL, 0x0000d3d3d3d300d3ULL, 0x0000bbbbbbbb00bbULL,\n\t0x0000434343430043ULL, 0x0000151515150015ULL, 0x0000adadadad00adULL,\n\t0x0000777777770077ULL, 0x0000808080800080ULL, 0x0000828282820082ULL,\n\t0x0000ecececec00ecULL, 0x0000272727270027ULL, 0x0000e5e5e5e500e5ULL,\n\t0x0000858585850085ULL, 0x0000353535350035ULL, 0x00000c0c0c0c000cULL,\n\t0x0000414141410041ULL, 0x0000efefefef00efULL, 0x0000939393930093ULL,\n\t0x0000191919190019ULL, 0x0000212121210021ULL, 0x00000e0e0e0e000eULL,\n\t0x00004e4e4e4e004eULL, 0x0000656565650065ULL, 0x0000bdbdbdbd00bdULL,\n\t0x0000b8b8b8b800b8ULL, 0x00008f8f8f8f008fULL, 0x0000ebebebeb00ebULL,\n\t0x0000cececece00ceULL, 0x0000303030300030ULL, 0x00005f5f5f5f005fULL,\n\t0x0000c5c5c5c500c5ULL, 0x00001a1a1a1a001aULL, 0x0000e1e1e1e100e1ULL,\n\t0x0000cacacaca00caULL, 0x0000474747470047ULL, 0x00003d3d3d3d003dULL,\n\t0x0000010101010001ULL, 0x0000d6d6d6d600d6ULL, 0x0000565656560056ULL,\n\t0x00004d4d4d4d004dULL, 0x00000d0d0d0d000dULL, 0x0000666666660066ULL,\n\t0x0000cccccccc00ccULL, 0x00002d2d2d2d002dULL, 0x0000121212120012ULL,\n\t0x0000202020200020ULL, 0x0000b1b1b1b100b1ULL, 0x0000999999990099ULL,\n\t0x00004c4c4c4c004cULL, 0x0000c2c2c2c200c2ULL, 0x00007e7e7e7e007eULL,\n\t0x0000050505050005ULL, 0x0000b7b7b7b700b7ULL, 0x0000313131310031ULL,\n\t0x0000171717170017ULL, 0x0000d7d7d7d700d7ULL, 0x0000585858580058ULL,\n\t0x0000616161610061ULL, 0x00001b1b1b1b001bULL, 0x00001c1c1c1c001cULL,\n\t0x00000f0f0f0f000fULL, 0x0000161616160016ULL, 0x0000181818180018ULL,\n\t0x0000222222220022ULL, 0x0000444444440044ULL, 0x0000b2b2b2b200b2ULL,\n\t0x0000b5b5b5b500b5ULL, 0x0000919191910091ULL, 0x0000080808080008ULL,\n\t0x0000a8a8a8a800a8ULL, 0x0000fcfcfcfc00fcULL, 0x0000505050500050ULL,\n\t0x0000d0d0d0d000d0ULL, 0x00007d7d7d7d007dULL, 0x0000898989890089ULL,\n\t0x0000979797970097ULL, 0x00005b5b5b5b005bULL, 0x0000959595950095ULL,\n\t0x0000ffffffff00ffULL, 0x0000d2d2d2d200d2ULL, 0x0000c4c4c4c400c4ULL,\n\t0x0000484848480048ULL, 0x0000f7f7f7f700f7ULL, 0x0000dbdbdbdb00dbULL,\n\t0x0000030303030003ULL, 0x0000dadadada00daULL, 0x00003f3f3f3f003fULL,\n\t0x0000949494940094ULL, 0x00005c5c5c5c005cULL, 0x0000020202020002ULL,\n\t0x00004a4a4a4a004aULL, 0x0000333333330033ULL, 0x0000676767670067ULL,\n\t0x0000f3f3f3f300f3ULL, 0x00007f7f7f7f007fULL, 0x0000e2e2e2e200e2ULL,\n\t0x00009b9b9b9b009bULL, 0x0000262626260026ULL, 0x0000373737370037ULL,\n\t0x00003b3b3b3b003bULL, 0x0000969696960096ULL, 0x00004b4b4b4b004bULL,\n\t0x0000bebebebe00beULL, 0x00002e2e2e2e002eULL, 0x0000797979790079ULL,\n\t0x00008c8c8c8c008cULL, 0x00006e6e6e6e006eULL, 0x00008e8e8e8e008eULL,\n\t0x0000f5f5f5f500f5ULL, 0x0000b6b6b6b600b6ULL, 0x0000fdfdfdfd00fdULL,\n\t0x0000595959590059ULL, 0x0000989898980098ULL, 0x00006a6a6a6a006aULL,\n\t0x0000464646460046ULL, 0x0000babababa00baULL, 0x0000252525250025ULL,\n\t0x0000424242420042ULL, 0x0000a2a2a2a200a2ULL, 0x0000fafafafa00faULL,\n\t0x0000070707070007ULL, 0x0000555555550055ULL, 0x0000eeeeeeee00eeULL,\n\t0x00000a0a0a0a000aULL, 0x0000494949490049ULL, 0x0000686868680068ULL,\n\t0x0000383838380038ULL, 0x0000a4a4a4a400a4ULL, 0x0000282828280028ULL,\n\t0x00007b7b7b7b007bULL, 0x0000c9c9c9c900c9ULL, 0x0000c1c1c1c100c1ULL,\n\t0x0000e3e3e3e300e3ULL, 0x0000f4f4f4f400f4ULL, 0x0000c7c7c7c700c7ULL,\n\t0x00009e9e9e9e009eULL,\n};\n\n__visible const u64 camellia_sp02220222[256] = {\n\t0x00e0e0e000e0e0e0ULL, 0x0005050500050505ULL, 0x0058585800585858ULL,\n\t0x00d9d9d900d9d9d9ULL, 0x0067676700676767ULL, 0x004e4e4e004e4e4eULL,\n\t0x0081818100818181ULL, 0x00cbcbcb00cbcbcbULL, 0x00c9c9c900c9c9c9ULL,\n\t0x000b0b0b000b0b0bULL, 0x00aeaeae00aeaeaeULL, 0x006a6a6a006a6a6aULL,\n\t0x00d5d5d500d5d5d5ULL, 0x0018181800181818ULL, 0x005d5d5d005d5d5dULL,\n\t0x0082828200828282ULL, 0x0046464600464646ULL, 0x00dfdfdf00dfdfdfULL,\n\t0x00d6d6d600d6d6d6ULL, 0x0027272700272727ULL, 0x008a8a8a008a8a8aULL,\n\t0x0032323200323232ULL, 0x004b4b4b004b4b4bULL, 0x0042424200424242ULL,\n\t0x00dbdbdb00dbdbdbULL, 0x001c1c1c001c1c1cULL, 0x009e9e9e009e9e9eULL,\n\t0x009c9c9c009c9c9cULL, 0x003a3a3a003a3a3aULL, 0x00cacaca00cacacaULL,\n\t0x0025252500252525ULL, 0x007b7b7b007b7b7bULL, 0x000d0d0d000d0d0dULL,\n\t0x0071717100717171ULL, 0x005f5f5f005f5f5fULL, 0x001f1f1f001f1f1fULL,\n\t0x00f8f8f800f8f8f8ULL, 0x00d7d7d700d7d7d7ULL, 0x003e3e3e003e3e3eULL,\n\t0x009d9d9d009d9d9dULL, 0x007c7c7c007c7c7cULL, 0x0060606000606060ULL,\n\t0x00b9b9b900b9b9b9ULL, 0x00bebebe00bebebeULL, 0x00bcbcbc00bcbcbcULL,\n\t0x008b8b8b008b8b8bULL, 0x0016161600161616ULL, 0x0034343400343434ULL,\n\t0x004d4d4d004d4d4dULL, 0x00c3c3c300c3c3c3ULL, 0x0072727200727272ULL,\n\t0x0095959500959595ULL, 0x00ababab00abababULL, 0x008e8e8e008e8e8eULL,\n\t0x00bababa00bababaULL, 0x007a7a7a007a7a7aULL, 0x00b3b3b300b3b3b3ULL,\n\t0x0002020200020202ULL, 0x00b4b4b400b4b4b4ULL, 0x00adadad00adadadULL,\n\t0x00a2a2a200a2a2a2ULL, 0x00acacac00acacacULL, 0x00d8d8d800d8d8d8ULL,\n\t0x009a9a9a009a9a9aULL, 0x0017171700171717ULL, 0x001a1a1a001a1a1aULL,\n\t0x0035353500353535ULL, 0x00cccccc00ccccccULL, 0x00f7f7f700f7f7f7ULL,\n\t0x0099999900999999ULL, 0x0061616100616161ULL, 0x005a5a5a005a5a5aULL,\n\t0x00e8e8e800e8e8e8ULL, 0x0024242400242424ULL, 0x0056565600565656ULL,\n\t0x0040404000404040ULL, 0x00e1e1e100e1e1e1ULL, 0x0063636300636363ULL,\n\t0x0009090900090909ULL, 0x0033333300333333ULL, 0x00bfbfbf00bfbfbfULL,\n\t0x0098989800989898ULL, 0x0097979700979797ULL, 0x0085858500858585ULL,\n\t0x0068686800686868ULL, 0x00fcfcfc00fcfcfcULL, 0x00ececec00ecececULL,\n\t0x000a0a0a000a0a0aULL, 0x00dadada00dadadaULL, 0x006f6f6f006f6f6fULL,\n\t0x0053535300535353ULL, 0x0062626200626262ULL, 0x00a3a3a300a3a3a3ULL,\n\t0x002e2e2e002e2e2eULL, 0x0008080800080808ULL, 0x00afafaf00afafafULL,\n\t0x0028282800282828ULL, 0x00b0b0b000b0b0b0ULL, 0x0074747400747474ULL,\n\t0x00c2c2c200c2c2c2ULL, 0x00bdbdbd00bdbdbdULL, 0x0036363600363636ULL,\n\t0x0022222200222222ULL, 0x0038383800383838ULL, 0x0064646400646464ULL,\n\t0x001e1e1e001e1e1eULL, 0x0039393900393939ULL, 0x002c2c2c002c2c2cULL,\n\t0x00a6a6a600a6a6a6ULL, 0x0030303000303030ULL, 0x00e5e5e500e5e5e5ULL,\n\t0x0044444400444444ULL, 0x00fdfdfd00fdfdfdULL, 0x0088888800888888ULL,\n\t0x009f9f9f009f9f9fULL, 0x0065656500656565ULL, 0x0087878700878787ULL,\n\t0x006b6b6b006b6b6bULL, 0x00f4f4f400f4f4f4ULL, 0x0023232300232323ULL,\n\t0x0048484800484848ULL, 0x0010101000101010ULL, 0x00d1d1d100d1d1d1ULL,\n\t0x0051515100515151ULL, 0x00c0c0c000c0c0c0ULL, 0x00f9f9f900f9f9f9ULL,\n\t0x00d2d2d200d2d2d2ULL, 0x00a0a0a000a0a0a0ULL, 0x0055555500555555ULL,\n\t0x00a1a1a100a1a1a1ULL, 0x0041414100414141ULL, 0x00fafafa00fafafaULL,\n\t0x0043434300434343ULL, 0x0013131300131313ULL, 0x00c4c4c400c4c4c4ULL,\n\t0x002f2f2f002f2f2fULL, 0x00a8a8a800a8a8a8ULL, 0x00b6b6b600b6b6b6ULL,\n\t0x003c3c3c003c3c3cULL, 0x002b2b2b002b2b2bULL, 0x00c1c1c100c1c1c1ULL,\n\t0x00ffffff00ffffffULL, 0x00c8c8c800c8c8c8ULL, 0x00a5a5a500a5a5a5ULL,\n\t0x0020202000202020ULL, 0x0089898900898989ULL, 0x0000000000000000ULL,\n\t0x0090909000909090ULL, 0x0047474700474747ULL, 0x00efefef00efefefULL,\n\t0x00eaeaea00eaeaeaULL, 0x00b7b7b700b7b7b7ULL, 0x0015151500151515ULL,\n\t0x0006060600060606ULL, 0x00cdcdcd00cdcdcdULL, 0x00b5b5b500b5b5b5ULL,\n\t0x0012121200121212ULL, 0x007e7e7e007e7e7eULL, 0x00bbbbbb00bbbbbbULL,\n\t0x0029292900292929ULL, 0x000f0f0f000f0f0fULL, 0x00b8b8b800b8b8b8ULL,\n\t0x0007070700070707ULL, 0x0004040400040404ULL, 0x009b9b9b009b9b9bULL,\n\t0x0094949400949494ULL, 0x0021212100212121ULL, 0x0066666600666666ULL,\n\t0x00e6e6e600e6e6e6ULL, 0x00cecece00cececeULL, 0x00ededed00edededULL,\n\t0x00e7e7e700e7e7e7ULL, 0x003b3b3b003b3b3bULL, 0x00fefefe00fefefeULL,\n\t0x007f7f7f007f7f7fULL, 0x00c5c5c500c5c5c5ULL, 0x00a4a4a400a4a4a4ULL,\n\t0x0037373700373737ULL, 0x00b1b1b100b1b1b1ULL, 0x004c4c4c004c4c4cULL,\n\t0x0091919100919191ULL, 0x006e6e6e006e6e6eULL, 0x008d8d8d008d8d8dULL,\n\t0x0076767600767676ULL, 0x0003030300030303ULL, 0x002d2d2d002d2d2dULL,\n\t0x00dedede00dededeULL, 0x0096969600969696ULL, 0x0026262600262626ULL,\n\t0x007d7d7d007d7d7dULL, 0x00c6c6c600c6c6c6ULL, 0x005c5c5c005c5c5cULL,\n\t0x00d3d3d300d3d3d3ULL, 0x00f2f2f200f2f2f2ULL, 0x004f4f4f004f4f4fULL,\n\t0x0019191900191919ULL, 0x003f3f3f003f3f3fULL, 0x00dcdcdc00dcdcdcULL,\n\t0x0079797900797979ULL, 0x001d1d1d001d1d1dULL, 0x0052525200525252ULL,\n\t0x00ebebeb00ebebebULL, 0x00f3f3f300f3f3f3ULL, 0x006d6d6d006d6d6dULL,\n\t0x005e5e5e005e5e5eULL, 0x00fbfbfb00fbfbfbULL, 0x0069696900696969ULL,\n\t0x00b2b2b200b2b2b2ULL, 0x00f0f0f000f0f0f0ULL, 0x0031313100313131ULL,\n\t0x000c0c0c000c0c0cULL, 0x00d4d4d400d4d4d4ULL, 0x00cfcfcf00cfcfcfULL,\n\t0x008c8c8c008c8c8cULL, 0x00e2e2e200e2e2e2ULL, 0x0075757500757575ULL,\n\t0x00a9a9a900a9a9a9ULL, 0x004a4a4a004a4a4aULL, 0x0057575700575757ULL,\n\t0x0084848400848484ULL, 0x0011111100111111ULL, 0x0045454500454545ULL,\n\t0x001b1b1b001b1b1bULL, 0x00f5f5f500f5f5f5ULL, 0x00e4e4e400e4e4e4ULL,\n\t0x000e0e0e000e0e0eULL, 0x0073737300737373ULL, 0x00aaaaaa00aaaaaaULL,\n\t0x00f1f1f100f1f1f1ULL, 0x00dddddd00ddddddULL, 0x0059595900595959ULL,\n\t0x0014141400141414ULL, 0x006c6c6c006c6c6cULL, 0x0092929200929292ULL,\n\t0x0054545400545454ULL, 0x00d0d0d000d0d0d0ULL, 0x0078787800787878ULL,\n\t0x0070707000707070ULL, 0x00e3e3e300e3e3e3ULL, 0x0049494900494949ULL,\n\t0x0080808000808080ULL, 0x0050505000505050ULL, 0x00a7a7a700a7a7a7ULL,\n\t0x00f6f6f600f6f6f6ULL, 0x0077777700777777ULL, 0x0093939300939393ULL,\n\t0x0086868600868686ULL, 0x0083838300838383ULL, 0x002a2a2a002a2a2aULL,\n\t0x00c7c7c700c7c7c7ULL, 0x005b5b5b005b5b5bULL, 0x00e9e9e900e9e9e9ULL,\n\t0x00eeeeee00eeeeeeULL, 0x008f8f8f008f8f8fULL, 0x0001010100010101ULL,\n\t0x003d3d3d003d3d3dULL,\n};\n\n__visible const u64 camellia_sp30333033[256] = {\n\t0x3800383838003838ULL, 0x4100414141004141ULL, 0x1600161616001616ULL,\n\t0x7600767676007676ULL, 0xd900d9d9d900d9d9ULL, 0x9300939393009393ULL,\n\t0x6000606060006060ULL, 0xf200f2f2f200f2f2ULL, 0x7200727272007272ULL,\n\t0xc200c2c2c200c2c2ULL, 0xab00ababab00ababULL, 0x9a009a9a9a009a9aULL,\n\t0x7500757575007575ULL, 0x0600060606000606ULL, 0x5700575757005757ULL,\n\t0xa000a0a0a000a0a0ULL, 0x9100919191009191ULL, 0xf700f7f7f700f7f7ULL,\n\t0xb500b5b5b500b5b5ULL, 0xc900c9c9c900c9c9ULL, 0xa200a2a2a200a2a2ULL,\n\t0x8c008c8c8c008c8cULL, 0xd200d2d2d200d2d2ULL, 0x9000909090009090ULL,\n\t0xf600f6f6f600f6f6ULL, 0x0700070707000707ULL, 0xa700a7a7a700a7a7ULL,\n\t0x2700272727002727ULL, 0x8e008e8e8e008e8eULL, 0xb200b2b2b200b2b2ULL,\n\t0x4900494949004949ULL, 0xde00dedede00dedeULL, 0x4300434343004343ULL,\n\t0x5c005c5c5c005c5cULL, 0xd700d7d7d700d7d7ULL, 0xc700c7c7c700c7c7ULL,\n\t0x3e003e3e3e003e3eULL, 0xf500f5f5f500f5f5ULL, 0x8f008f8f8f008f8fULL,\n\t0x6700676767006767ULL, 0x1f001f1f1f001f1fULL, 0x1800181818001818ULL,\n\t0x6e006e6e6e006e6eULL, 0xaf00afafaf00afafULL, 0x2f002f2f2f002f2fULL,\n\t0xe200e2e2e200e2e2ULL, 0x8500858585008585ULL, 0x0d000d0d0d000d0dULL,\n\t0x5300535353005353ULL, 0xf000f0f0f000f0f0ULL, 0x9c009c9c9c009c9cULL,\n\t0x6500656565006565ULL, 0xea00eaeaea00eaeaULL, 0xa300a3a3a300a3a3ULL,\n\t0xae00aeaeae00aeaeULL, 0x9e009e9e9e009e9eULL, 0xec00ececec00ececULL,\n\t0x8000808080008080ULL, 0x2d002d2d2d002d2dULL, 0x6b006b6b6b006b6bULL,\n\t0xa800a8a8a800a8a8ULL, 0x2b002b2b2b002b2bULL, 0x3600363636003636ULL,\n\t0xa600a6a6a600a6a6ULL, 0xc500c5c5c500c5c5ULL, 0x8600868686008686ULL,\n\t0x4d004d4d4d004d4dULL, 0x3300333333003333ULL, 0xfd00fdfdfd00fdfdULL,\n\t0x6600666666006666ULL, 0x5800585858005858ULL, 0x9600969696009696ULL,\n\t0x3a003a3a3a003a3aULL, 0x0900090909000909ULL, 0x9500959595009595ULL,\n\t0x1000101010001010ULL, 0x7800787878007878ULL, 0xd800d8d8d800d8d8ULL,\n\t0x4200424242004242ULL, 0xcc00cccccc00ccccULL, 0xef00efefef00efefULL,\n\t0x2600262626002626ULL, 0xe500e5e5e500e5e5ULL, 0x6100616161006161ULL,\n\t0x1a001a1a1a001a1aULL, 0x3f003f3f3f003f3fULL, 0x3b003b3b3b003b3bULL,\n\t0x8200828282008282ULL, 0xb600b6b6b600b6b6ULL, 0xdb00dbdbdb00dbdbULL,\n\t0xd400d4d4d400d4d4ULL, 0x9800989898009898ULL, 0xe800e8e8e800e8e8ULL,\n\t0x8b008b8b8b008b8bULL, 0x0200020202000202ULL, 0xeb00ebebeb00ebebULL,\n\t0x0a000a0a0a000a0aULL, 0x2c002c2c2c002c2cULL, 0x1d001d1d1d001d1dULL,\n\t0xb000b0b0b000b0b0ULL, 0x6f006f6f6f006f6fULL, 0x8d008d8d8d008d8dULL,\n\t0x8800888888008888ULL, 0x0e000e0e0e000e0eULL, 0x1900191919001919ULL,\n\t0x8700878787008787ULL, 0x4e004e4e4e004e4eULL, 0x0b000b0b0b000b0bULL,\n\t0xa900a9a9a900a9a9ULL, 0x0c000c0c0c000c0cULL, 0x7900797979007979ULL,\n\t0x1100111111001111ULL, 0x7f007f7f7f007f7fULL, 0x2200222222002222ULL,\n\t0xe700e7e7e700e7e7ULL, 0x5900595959005959ULL, 0xe100e1e1e100e1e1ULL,\n\t0xda00dadada00dadaULL, 0x3d003d3d3d003d3dULL, 0xc800c8c8c800c8c8ULL,\n\t0x1200121212001212ULL, 0x0400040404000404ULL, 0x7400747474007474ULL,\n\t0x5400545454005454ULL, 0x3000303030003030ULL, 0x7e007e7e7e007e7eULL,\n\t0xb400b4b4b400b4b4ULL, 0x2800282828002828ULL, 0x5500555555005555ULL,\n\t0x6800686868006868ULL, 0x5000505050005050ULL, 0xbe00bebebe00bebeULL,\n\t0xd000d0d0d000d0d0ULL, 0xc400c4c4c400c4c4ULL, 0x3100313131003131ULL,\n\t0xcb00cbcbcb00cbcbULL, 0x2a002a2a2a002a2aULL, 0xad00adadad00adadULL,\n\t0x0f000f0f0f000f0fULL, 0xca00cacaca00cacaULL, 0x7000707070007070ULL,\n\t0xff00ffffff00ffffULL, 0x3200323232003232ULL, 0x6900696969006969ULL,\n\t0x0800080808000808ULL, 0x6200626262006262ULL, 0x0000000000000000ULL,\n\t0x2400242424002424ULL, 0xd100d1d1d100d1d1ULL, 0xfb00fbfbfb00fbfbULL,\n\t0xba00bababa00babaULL, 0xed00ededed00ededULL, 0x4500454545004545ULL,\n\t0x8100818181008181ULL, 0x7300737373007373ULL, 0x6d006d6d6d006d6dULL,\n\t0x8400848484008484ULL, 0x9f009f9f9f009f9fULL, 0xee00eeeeee00eeeeULL,\n\t0x4a004a4a4a004a4aULL, 0xc300c3c3c300c3c3ULL, 0x2e002e2e2e002e2eULL,\n\t0xc100c1c1c100c1c1ULL, 0x0100010101000101ULL, 0xe600e6e6e600e6e6ULL,\n\t0x2500252525002525ULL, 0x4800484848004848ULL, 0x9900999999009999ULL,\n\t0xb900b9b9b900b9b9ULL, 0xb300b3b3b300b3b3ULL, 0x7b007b7b7b007b7bULL,\n\t0xf900f9f9f900f9f9ULL, 0xce00cecece00ceceULL, 0xbf00bfbfbf00bfbfULL,\n\t0xdf00dfdfdf00dfdfULL, 0x7100717171007171ULL, 0x2900292929002929ULL,\n\t0xcd00cdcdcd00cdcdULL, 0x6c006c6c6c006c6cULL, 0x1300131313001313ULL,\n\t0x6400646464006464ULL, 0x9b009b9b9b009b9bULL, 0x6300636363006363ULL,\n\t0x9d009d9d9d009d9dULL, 0xc000c0c0c000c0c0ULL, 0x4b004b4b4b004b4bULL,\n\t0xb700b7b7b700b7b7ULL, 0xa500a5a5a500a5a5ULL, 0x8900898989008989ULL,\n\t0x5f005f5f5f005f5fULL, 0xb100b1b1b100b1b1ULL, 0x1700171717001717ULL,\n\t0xf400f4f4f400f4f4ULL, 0xbc00bcbcbc00bcbcULL, 0xd300d3d3d300d3d3ULL,\n\t0x4600464646004646ULL, 0xcf00cfcfcf00cfcfULL, 0x3700373737003737ULL,\n\t0x5e005e5e5e005e5eULL, 0x4700474747004747ULL, 0x9400949494009494ULL,\n\t0xfa00fafafa00fafaULL, 0xfc00fcfcfc00fcfcULL, 0x5b005b5b5b005b5bULL,\n\t0x9700979797009797ULL, 0xfe00fefefe00fefeULL, 0x5a005a5a5a005a5aULL,\n\t0xac00acacac00acacULL, 0x3c003c3c3c003c3cULL, 0x4c004c4c4c004c4cULL,\n\t0x0300030303000303ULL, 0x3500353535003535ULL, 0xf300f3f3f300f3f3ULL,\n\t0x2300232323002323ULL, 0xb800b8b8b800b8b8ULL, 0x5d005d5d5d005d5dULL,\n\t0x6a006a6a6a006a6aULL, 0x9200929292009292ULL, 0xd500d5d5d500d5d5ULL,\n\t0x2100212121002121ULL, 0x4400444444004444ULL, 0x5100515151005151ULL,\n\t0xc600c6c6c600c6c6ULL, 0x7d007d7d7d007d7dULL, 0x3900393939003939ULL,\n\t0x8300838383008383ULL, 0xdc00dcdcdc00dcdcULL, 0xaa00aaaaaa00aaaaULL,\n\t0x7c007c7c7c007c7cULL, 0x7700777777007777ULL, 0x5600565656005656ULL,\n\t0x0500050505000505ULL, 0x1b001b1b1b001b1bULL, 0xa400a4a4a400a4a4ULL,\n\t0x1500151515001515ULL, 0x3400343434003434ULL, 0x1e001e1e1e001e1eULL,\n\t0x1c001c1c1c001c1cULL, 0xf800f8f8f800f8f8ULL, 0x5200525252005252ULL,\n\t0x2000202020002020ULL, 0x1400141414001414ULL, 0xe900e9e9e900e9e9ULL,\n\t0xbd00bdbdbd00bdbdULL, 0xdd00dddddd00ddddULL, 0xe400e4e4e400e4e4ULL,\n\t0xa100a1a1a100a1a1ULL, 0xe000e0e0e000e0e0ULL, 0x8a008a8a8a008a8aULL,\n\t0xf100f1f1f100f1f1ULL, 0xd600d6d6d600d6d6ULL, 0x7a007a7a7a007a7aULL,\n\t0xbb00bbbbbb00bbbbULL, 0xe300e3e3e300e3e3ULL, 0x4000404040004040ULL,\n\t0x4f004f4f4f004f4fULL,\n};\n\n__visible const u64 camellia_sp44044404[256] = {\n\t0x7070007070700070ULL, 0x2c2c002c2c2c002cULL, 0xb3b300b3b3b300b3ULL,\n\t0xc0c000c0c0c000c0ULL, 0xe4e400e4e4e400e4ULL, 0x5757005757570057ULL,\n\t0xeaea00eaeaea00eaULL, 0xaeae00aeaeae00aeULL, 0x2323002323230023ULL,\n\t0x6b6b006b6b6b006bULL, 0x4545004545450045ULL, 0xa5a500a5a5a500a5ULL,\n\t0xeded00ededed00edULL, 0x4f4f004f4f4f004fULL, 0x1d1d001d1d1d001dULL,\n\t0x9292009292920092ULL, 0x8686008686860086ULL, 0xafaf00afafaf00afULL,\n\t0x7c7c007c7c7c007cULL, 0x1f1f001f1f1f001fULL, 0x3e3e003e3e3e003eULL,\n\t0xdcdc00dcdcdc00dcULL, 0x5e5e005e5e5e005eULL, 0x0b0b000b0b0b000bULL,\n\t0xa6a600a6a6a600a6ULL, 0x3939003939390039ULL, 0xd5d500d5d5d500d5ULL,\n\t0x5d5d005d5d5d005dULL, 0xd9d900d9d9d900d9ULL, 0x5a5a005a5a5a005aULL,\n\t0x5151005151510051ULL, 0x6c6c006c6c6c006cULL, 0x8b8b008b8b8b008bULL,\n\t0x9a9a009a9a9a009aULL, 0xfbfb00fbfbfb00fbULL, 0xb0b000b0b0b000b0ULL,\n\t0x7474007474740074ULL, 0x2b2b002b2b2b002bULL, 0xf0f000f0f0f000f0ULL,\n\t0x8484008484840084ULL, 0xdfdf00dfdfdf00dfULL, 0xcbcb00cbcbcb00cbULL,\n\t0x3434003434340034ULL, 0x7676007676760076ULL, 0x6d6d006d6d6d006dULL,\n\t0xa9a900a9a9a900a9ULL, 0xd1d100d1d1d100d1ULL, 0x0404000404040004ULL,\n\t0x1414001414140014ULL, 0x3a3a003a3a3a003aULL, 0xdede00dedede00deULL,\n\t0x1111001111110011ULL, 0x3232003232320032ULL, 0x9c9c009c9c9c009cULL,\n\t0x5353005353530053ULL, 0xf2f200f2f2f200f2ULL, 0xfefe00fefefe00feULL,\n\t0xcfcf00cfcfcf00cfULL, 0xc3c300c3c3c300c3ULL, 0x7a7a007a7a7a007aULL,\n\t0x2424002424240024ULL, 0xe8e800e8e8e800e8ULL, 0x6060006060600060ULL,\n\t0x6969006969690069ULL, 0xaaaa00aaaaaa00aaULL, 0xa0a000a0a0a000a0ULL,\n\t0xa1a100a1a1a100a1ULL, 0x6262006262620062ULL, 0x5454005454540054ULL,\n\t0x1e1e001e1e1e001eULL, 0xe0e000e0e0e000e0ULL, 0x6464006464640064ULL,\n\t0x1010001010100010ULL, 0x0000000000000000ULL, 0xa3a300a3a3a300a3ULL,\n\t0x7575007575750075ULL, 0x8a8a008a8a8a008aULL, 0xe6e600e6e6e600e6ULL,\n\t0x0909000909090009ULL, 0xdddd00dddddd00ddULL, 0x8787008787870087ULL,\n\t0x8383008383830083ULL, 0xcdcd00cdcdcd00cdULL, 0x9090009090900090ULL,\n\t0x7373007373730073ULL, 0xf6f600f6f6f600f6ULL, 0x9d9d009d9d9d009dULL,\n\t0xbfbf00bfbfbf00bfULL, 0x5252005252520052ULL, 0xd8d800d8d8d800d8ULL,\n\t0xc8c800c8c8c800c8ULL, 0xc6c600c6c6c600c6ULL, 0x8181008181810081ULL,\n\t0x6f6f006f6f6f006fULL, 0x1313001313130013ULL, 0x6363006363630063ULL,\n\t0xe9e900e9e9e900e9ULL, 0xa7a700a7a7a700a7ULL, 0x9f9f009f9f9f009fULL,\n\t0xbcbc00bcbcbc00bcULL, 0x2929002929290029ULL, 0xf9f900f9f9f900f9ULL,\n\t0x2f2f002f2f2f002fULL, 0xb4b400b4b4b400b4ULL, 0x7878007878780078ULL,\n\t0x0606000606060006ULL, 0xe7e700e7e7e700e7ULL, 0x7171007171710071ULL,\n\t0xd4d400d4d4d400d4ULL, 0xabab00ababab00abULL, 0x8888008888880088ULL,\n\t0x8d8d008d8d8d008dULL, 0x7272007272720072ULL, 0xb9b900b9b9b900b9ULL,\n\t0xf8f800f8f8f800f8ULL, 0xacac00acacac00acULL, 0x3636003636360036ULL,\n\t0x2a2a002a2a2a002aULL, 0x3c3c003c3c3c003cULL, 0xf1f100f1f1f100f1ULL,\n\t0x4040004040400040ULL, 0xd3d300d3d3d300d3ULL, 0xbbbb00bbbbbb00bbULL,\n\t0x4343004343430043ULL, 0x1515001515150015ULL, 0xadad00adadad00adULL,\n\t0x7777007777770077ULL, 0x8080008080800080ULL, 0x8282008282820082ULL,\n\t0xecec00ececec00ecULL, 0x2727002727270027ULL, 0xe5e500e5e5e500e5ULL,\n\t0x8585008585850085ULL, 0x3535003535350035ULL, 0x0c0c000c0c0c000cULL,\n\t0x4141004141410041ULL, 0xefef00efefef00efULL, 0x9393009393930093ULL,\n\t0x1919001919190019ULL, 0x2121002121210021ULL, 0x0e0e000e0e0e000eULL,\n\t0x4e4e004e4e4e004eULL, 0x6565006565650065ULL, 0xbdbd00bdbdbd00bdULL,\n\t0xb8b800b8b8b800b8ULL, 0x8f8f008f8f8f008fULL, 0xebeb00ebebeb00ebULL,\n\t0xcece00cecece00ceULL, 0x3030003030300030ULL, 0x5f5f005f5f5f005fULL,\n\t0xc5c500c5c5c500c5ULL, 0x1a1a001a1a1a001aULL, 0xe1e100e1e1e100e1ULL,\n\t0xcaca00cacaca00caULL, 0x4747004747470047ULL, 0x3d3d003d3d3d003dULL,\n\t0x0101000101010001ULL, 0xd6d600d6d6d600d6ULL, 0x5656005656560056ULL,\n\t0x4d4d004d4d4d004dULL, 0x0d0d000d0d0d000dULL, 0x6666006666660066ULL,\n\t0xcccc00cccccc00ccULL, 0x2d2d002d2d2d002dULL, 0x1212001212120012ULL,\n\t0x2020002020200020ULL, 0xb1b100b1b1b100b1ULL, 0x9999009999990099ULL,\n\t0x4c4c004c4c4c004cULL, 0xc2c200c2c2c200c2ULL, 0x7e7e007e7e7e007eULL,\n\t0x0505000505050005ULL, 0xb7b700b7b7b700b7ULL, 0x3131003131310031ULL,\n\t0x1717001717170017ULL, 0xd7d700d7d7d700d7ULL, 0x5858005858580058ULL,\n\t0x6161006161610061ULL, 0x1b1b001b1b1b001bULL, 0x1c1c001c1c1c001cULL,\n\t0x0f0f000f0f0f000fULL, 0x1616001616160016ULL, 0x1818001818180018ULL,\n\t0x2222002222220022ULL, 0x4444004444440044ULL, 0xb2b200b2b2b200b2ULL,\n\t0xb5b500b5b5b500b5ULL, 0x9191009191910091ULL, 0x0808000808080008ULL,\n\t0xa8a800a8a8a800a8ULL, 0xfcfc00fcfcfc00fcULL, 0x5050005050500050ULL,\n\t0xd0d000d0d0d000d0ULL, 0x7d7d007d7d7d007dULL, 0x8989008989890089ULL,\n\t0x9797009797970097ULL, 0x5b5b005b5b5b005bULL, 0x9595009595950095ULL,\n\t0xffff00ffffff00ffULL, 0xd2d200d2d2d200d2ULL, 0xc4c400c4c4c400c4ULL,\n\t0x4848004848480048ULL, 0xf7f700f7f7f700f7ULL, 0xdbdb00dbdbdb00dbULL,\n\t0x0303000303030003ULL, 0xdada00dadada00daULL, 0x3f3f003f3f3f003fULL,\n\t0x9494009494940094ULL, 0x5c5c005c5c5c005cULL, 0x0202000202020002ULL,\n\t0x4a4a004a4a4a004aULL, 0x3333003333330033ULL, 0x6767006767670067ULL,\n\t0xf3f300f3f3f300f3ULL, 0x7f7f007f7f7f007fULL, 0xe2e200e2e2e200e2ULL,\n\t0x9b9b009b9b9b009bULL, 0x2626002626260026ULL, 0x3737003737370037ULL,\n\t0x3b3b003b3b3b003bULL, 0x9696009696960096ULL, 0x4b4b004b4b4b004bULL,\n\t0xbebe00bebebe00beULL, 0x2e2e002e2e2e002eULL, 0x7979007979790079ULL,\n\t0x8c8c008c8c8c008cULL, 0x6e6e006e6e6e006eULL, 0x8e8e008e8e8e008eULL,\n\t0xf5f500f5f5f500f5ULL, 0xb6b600b6b6b600b6ULL, 0xfdfd00fdfdfd00fdULL,\n\t0x5959005959590059ULL, 0x9898009898980098ULL, 0x6a6a006a6a6a006aULL,\n\t0x4646004646460046ULL, 0xbaba00bababa00baULL, 0x2525002525250025ULL,\n\t0x4242004242420042ULL, 0xa2a200a2a2a200a2ULL, 0xfafa00fafafa00faULL,\n\t0x0707000707070007ULL, 0x5555005555550055ULL, 0xeeee00eeeeee00eeULL,\n\t0x0a0a000a0a0a000aULL, 0x4949004949490049ULL, 0x6868006868680068ULL,\n\t0x3838003838380038ULL, 0xa4a400a4a4a400a4ULL, 0x2828002828280028ULL,\n\t0x7b7b007b7b7b007bULL, 0xc9c900c9c9c900c9ULL, 0xc1c100c1c1c100c1ULL,\n\t0xe3e300e3e3e300e3ULL, 0xf4f400f4f4f400f4ULL, 0xc7c700c7c7c700c7ULL,\n\t0x9e9e009e9e9e009eULL,\n};\n\n__visible const u64 camellia_sp11101110[256] = {\n\t0x7070700070707000ULL, 0x8282820082828200ULL, 0x2c2c2c002c2c2c00ULL,\n\t0xececec00ececec00ULL, 0xb3b3b300b3b3b300ULL, 0x2727270027272700ULL,\n\t0xc0c0c000c0c0c000ULL, 0xe5e5e500e5e5e500ULL, 0xe4e4e400e4e4e400ULL,\n\t0x8585850085858500ULL, 0x5757570057575700ULL, 0x3535350035353500ULL,\n\t0xeaeaea00eaeaea00ULL, 0x0c0c0c000c0c0c00ULL, 0xaeaeae00aeaeae00ULL,\n\t0x4141410041414100ULL, 0x2323230023232300ULL, 0xefefef00efefef00ULL,\n\t0x6b6b6b006b6b6b00ULL, 0x9393930093939300ULL, 0x4545450045454500ULL,\n\t0x1919190019191900ULL, 0xa5a5a500a5a5a500ULL, 0x2121210021212100ULL,\n\t0xededed00ededed00ULL, 0x0e0e0e000e0e0e00ULL, 0x4f4f4f004f4f4f00ULL,\n\t0x4e4e4e004e4e4e00ULL, 0x1d1d1d001d1d1d00ULL, 0x6565650065656500ULL,\n\t0x9292920092929200ULL, 0xbdbdbd00bdbdbd00ULL, 0x8686860086868600ULL,\n\t0xb8b8b800b8b8b800ULL, 0xafafaf00afafaf00ULL, 0x8f8f8f008f8f8f00ULL,\n\t0x7c7c7c007c7c7c00ULL, 0xebebeb00ebebeb00ULL, 0x1f1f1f001f1f1f00ULL,\n\t0xcecece00cecece00ULL, 0x3e3e3e003e3e3e00ULL, 0x3030300030303000ULL,\n\t0xdcdcdc00dcdcdc00ULL, 0x5f5f5f005f5f5f00ULL, 0x5e5e5e005e5e5e00ULL,\n\t0xc5c5c500c5c5c500ULL, 0x0b0b0b000b0b0b00ULL, 0x1a1a1a001a1a1a00ULL,\n\t0xa6a6a600a6a6a600ULL, 0xe1e1e100e1e1e100ULL, 0x3939390039393900ULL,\n\t0xcacaca00cacaca00ULL, 0xd5d5d500d5d5d500ULL, 0x4747470047474700ULL,\n\t0x5d5d5d005d5d5d00ULL, 0x3d3d3d003d3d3d00ULL, 0xd9d9d900d9d9d900ULL,\n\t0x0101010001010100ULL, 0x5a5a5a005a5a5a00ULL, 0xd6d6d600d6d6d600ULL,\n\t0x5151510051515100ULL, 0x5656560056565600ULL, 0x6c6c6c006c6c6c00ULL,\n\t0x4d4d4d004d4d4d00ULL, 0x8b8b8b008b8b8b00ULL, 0x0d0d0d000d0d0d00ULL,\n\t0x9a9a9a009a9a9a00ULL, 0x6666660066666600ULL, 0xfbfbfb00fbfbfb00ULL,\n\t0xcccccc00cccccc00ULL, 0xb0b0b000b0b0b000ULL, 0x2d2d2d002d2d2d00ULL,\n\t0x7474740074747400ULL, 0x1212120012121200ULL, 0x2b2b2b002b2b2b00ULL,\n\t0x2020200020202000ULL, 0xf0f0f000f0f0f000ULL, 0xb1b1b100b1b1b100ULL,\n\t0x8484840084848400ULL, 0x9999990099999900ULL, 0xdfdfdf00dfdfdf00ULL,\n\t0x4c4c4c004c4c4c00ULL, 0xcbcbcb00cbcbcb00ULL, 0xc2c2c200c2c2c200ULL,\n\t0x3434340034343400ULL, 0x7e7e7e007e7e7e00ULL, 0x7676760076767600ULL,\n\t0x0505050005050500ULL, 0x6d6d6d006d6d6d00ULL, 0xb7b7b700b7b7b700ULL,\n\t0xa9a9a900a9a9a900ULL, 0x3131310031313100ULL, 0xd1d1d100d1d1d100ULL,\n\t0x1717170017171700ULL, 0x0404040004040400ULL, 0xd7d7d700d7d7d700ULL,\n\t0x1414140014141400ULL, 0x5858580058585800ULL, 0x3a3a3a003a3a3a00ULL,\n\t0x6161610061616100ULL, 0xdedede00dedede00ULL, 0x1b1b1b001b1b1b00ULL,\n\t0x1111110011111100ULL, 0x1c1c1c001c1c1c00ULL, 0x3232320032323200ULL,\n\t0x0f0f0f000f0f0f00ULL, 0x9c9c9c009c9c9c00ULL, 0x1616160016161600ULL,\n\t0x5353530053535300ULL, 0x1818180018181800ULL, 0xf2f2f200f2f2f200ULL,\n\t0x2222220022222200ULL, 0xfefefe00fefefe00ULL, 0x4444440044444400ULL,\n\t0xcfcfcf00cfcfcf00ULL, 0xb2b2b200b2b2b200ULL, 0xc3c3c300c3c3c300ULL,\n\t0xb5b5b500b5b5b500ULL, 0x7a7a7a007a7a7a00ULL, 0x9191910091919100ULL,\n\t0x2424240024242400ULL, 0x0808080008080800ULL, 0xe8e8e800e8e8e800ULL,\n\t0xa8a8a800a8a8a800ULL, 0x6060600060606000ULL, 0xfcfcfc00fcfcfc00ULL,\n\t0x6969690069696900ULL, 0x5050500050505000ULL, 0xaaaaaa00aaaaaa00ULL,\n\t0xd0d0d000d0d0d000ULL, 0xa0a0a000a0a0a000ULL, 0x7d7d7d007d7d7d00ULL,\n\t0xa1a1a100a1a1a100ULL, 0x8989890089898900ULL, 0x6262620062626200ULL,\n\t0x9797970097979700ULL, 0x5454540054545400ULL, 0x5b5b5b005b5b5b00ULL,\n\t0x1e1e1e001e1e1e00ULL, 0x9595950095959500ULL, 0xe0e0e000e0e0e000ULL,\n\t0xffffff00ffffff00ULL, 0x6464640064646400ULL, 0xd2d2d200d2d2d200ULL,\n\t0x1010100010101000ULL, 0xc4c4c400c4c4c400ULL, 0x0000000000000000ULL,\n\t0x4848480048484800ULL, 0xa3a3a300a3a3a300ULL, 0xf7f7f700f7f7f700ULL,\n\t0x7575750075757500ULL, 0xdbdbdb00dbdbdb00ULL, 0x8a8a8a008a8a8a00ULL,\n\t0x0303030003030300ULL, 0xe6e6e600e6e6e600ULL, 0xdadada00dadada00ULL,\n\t0x0909090009090900ULL, 0x3f3f3f003f3f3f00ULL, 0xdddddd00dddddd00ULL,\n\t0x9494940094949400ULL, 0x8787870087878700ULL, 0x5c5c5c005c5c5c00ULL,\n\t0x8383830083838300ULL, 0x0202020002020200ULL, 0xcdcdcd00cdcdcd00ULL,\n\t0x4a4a4a004a4a4a00ULL, 0x9090900090909000ULL, 0x3333330033333300ULL,\n\t0x7373730073737300ULL, 0x6767670067676700ULL, 0xf6f6f600f6f6f600ULL,\n\t0xf3f3f300f3f3f300ULL, 0x9d9d9d009d9d9d00ULL, 0x7f7f7f007f7f7f00ULL,\n\t0xbfbfbf00bfbfbf00ULL, 0xe2e2e200e2e2e200ULL, 0x5252520052525200ULL,\n\t0x9b9b9b009b9b9b00ULL, 0xd8d8d800d8d8d800ULL, 0x2626260026262600ULL,\n\t0xc8c8c800c8c8c800ULL, 0x3737370037373700ULL, 0xc6c6c600c6c6c600ULL,\n\t0x3b3b3b003b3b3b00ULL, 0x8181810081818100ULL, 0x9696960096969600ULL,\n\t0x6f6f6f006f6f6f00ULL, 0x4b4b4b004b4b4b00ULL, 0x1313130013131300ULL,\n\t0xbebebe00bebebe00ULL, 0x6363630063636300ULL, 0x2e2e2e002e2e2e00ULL,\n\t0xe9e9e900e9e9e900ULL, 0x7979790079797900ULL, 0xa7a7a700a7a7a700ULL,\n\t0x8c8c8c008c8c8c00ULL, 0x9f9f9f009f9f9f00ULL, 0x6e6e6e006e6e6e00ULL,\n\t0xbcbcbc00bcbcbc00ULL, 0x8e8e8e008e8e8e00ULL, 0x2929290029292900ULL,\n\t0xf5f5f500f5f5f500ULL, 0xf9f9f900f9f9f900ULL, 0xb6b6b600b6b6b600ULL,\n\t0x2f2f2f002f2f2f00ULL, 0xfdfdfd00fdfdfd00ULL, 0xb4b4b400b4b4b400ULL,\n\t0x5959590059595900ULL, 0x7878780078787800ULL, 0x9898980098989800ULL,\n\t0x0606060006060600ULL, 0x6a6a6a006a6a6a00ULL, 0xe7e7e700e7e7e700ULL,\n\t0x4646460046464600ULL, 0x7171710071717100ULL, 0xbababa00bababa00ULL,\n\t0xd4d4d400d4d4d400ULL, 0x2525250025252500ULL, 0xababab00ababab00ULL,\n\t0x4242420042424200ULL, 0x8888880088888800ULL, 0xa2a2a200a2a2a200ULL,\n\t0x8d8d8d008d8d8d00ULL, 0xfafafa00fafafa00ULL, 0x7272720072727200ULL,\n\t0x0707070007070700ULL, 0xb9b9b900b9b9b900ULL, 0x5555550055555500ULL,\n\t0xf8f8f800f8f8f800ULL, 0xeeeeee00eeeeee00ULL, 0xacacac00acacac00ULL,\n\t0x0a0a0a000a0a0a00ULL, 0x3636360036363600ULL, 0x4949490049494900ULL,\n\t0x2a2a2a002a2a2a00ULL, 0x6868680068686800ULL, 0x3c3c3c003c3c3c00ULL,\n\t0x3838380038383800ULL, 0xf1f1f100f1f1f100ULL, 0xa4a4a400a4a4a400ULL,\n\t0x4040400040404000ULL, 0x2828280028282800ULL, 0xd3d3d300d3d3d300ULL,\n\t0x7b7b7b007b7b7b00ULL, 0xbbbbbb00bbbbbb00ULL, 0xc9c9c900c9c9c900ULL,\n\t0x4343430043434300ULL, 0xc1c1c100c1c1c100ULL, 0x1515150015151500ULL,\n\t0xe3e3e300e3e3e300ULL, 0xadadad00adadad00ULL, 0xf4f4f400f4f4f400ULL,\n\t0x7777770077777700ULL, 0xc7c7c700c7c7c700ULL, 0x8080800080808000ULL,\n\t0x9e9e9e009e9e9e00ULL,\n};\n\n/* key constants */\n#define CAMELLIA_SIGMA1L (0xA09E667FL)\n#define CAMELLIA_SIGMA1R (0x3BCC908BL)\n#define CAMELLIA_SIGMA2L (0xB67AE858L)\n#define CAMELLIA_SIGMA2R (0x4CAA73B2L)\n#define CAMELLIA_SIGMA3L (0xC6EF372FL)\n#define CAMELLIA_SIGMA3R (0xE94F82BEL)\n#define CAMELLIA_SIGMA4L (0x54FF53A5L)\n#define CAMELLIA_SIGMA4R (0xF1D36F1CL)\n#define CAMELLIA_SIGMA5L (0x10E527FAL)\n#define CAMELLIA_SIGMA5R (0xDE682D1DL)\n#define CAMELLIA_SIGMA6L (0xB05688C2L)\n#define CAMELLIA_SIGMA6R (0xB3E6C1FDL)\n\n/* macros */\n#define ROLDQ(l, r, bits) ({ \\\n\tu64 t = l;\t\t\t\t\t\\\n\tl = (l << bits) | (r >> (64 - bits));\t\t\\\n\tr = (r << bits) | (t >> (64 - bits));\t\t\\\n})\n\n#define CAMELLIA_F(x, kl, kr, y) ({ \\\n\tu64 ii = x ^ (((u64)kl << 32) | kr);\t\t\t\t\\\n\ty = camellia_sp11101110[(uint8_t)ii];\t\t\t\t\\\n\ty ^= camellia_sp44044404[(uint8_t)(ii >> 8)];\t\t\t\\\n\tii >>= 16;\t\t\t\t\t\t\t\\\n\ty ^= camellia_sp30333033[(uint8_t)ii];\t\t\t\t\\\n\ty ^= camellia_sp02220222[(uint8_t)(ii >> 8)];\t\t\t\\\n\tii >>= 16;\t\t\t\t\t\t\t\\\n\ty ^= camellia_sp00444404[(uint8_t)ii];\t\t\t\t\\\n\ty ^= camellia_sp03303033[(uint8_t)(ii >> 8)];\t\t\t\\\n\tii >>= 16;\t\t\t\t\t\t\t\\\n\ty ^= camellia_sp22000222[(uint8_t)ii];\t\t\t\t\\\n\ty ^= camellia_sp10011110[(uint8_t)(ii >> 8)];\t\t\t\\\n\ty = ror64(y, 32);\t\t\t\t\t\t\\\n})\n\n#define SET_SUBKEY_LR(INDEX, sRL) (subkey[(INDEX)] = ror64((sRL), 32))\n\nstatic void camellia_setup_tail(u64 *subkey, u64 *subRL, int max)\n{\n\tu64 kw4, tt;\n\tu32 dw, tl, tr;\n\n\t/* absorb kw2 to other subkeys */\n\t/* round 2 */\n\tsubRL[3] ^= subRL[1];\n\t/* round 4 */\n\tsubRL[5] ^= subRL[1];\n\t/* round 6 */\n\tsubRL[7] ^= subRL[1];\n\n\tsubRL[1] ^= (subRL[1] & ~subRL[9]) << 32;\n\t/* modified for FLinv(kl2) */\n\tdw = (subRL[1] & subRL[9]) >> 32;\n\tsubRL[1] ^= rol32(dw, 1);\n\n\t/* round 8 */\n\tsubRL[11] ^= subRL[1];\n\t/* round 10 */\n\tsubRL[13] ^= subRL[1];\n\t/* round 12 */\n\tsubRL[15] ^= subRL[1];\n\n\tsubRL[1] ^= (subRL[1] & ~subRL[17]) << 32;\n\t/* modified for FLinv(kl4) */\n\tdw = (subRL[1] & subRL[17]) >> 32;\n\tsubRL[1] ^= rol32(dw, 1);\n\n\t/* round 14 */\n\tsubRL[19] ^= subRL[1];\n\t/* round 16 */\n\tsubRL[21] ^= subRL[1];\n\t/* round 18 */\n\tsubRL[23] ^= subRL[1];\n\n\tif (max == 24) {\n\t\t/* kw3 */\n\t\tsubRL[24] ^= subRL[1];\n\n\t\t/* absorb kw4 to other subkeys */\n\t\tkw4 = subRL[25];\n\t} else {\n\t\tsubRL[1] ^= (subRL[1] & ~subRL[25]) << 32;\n\t\t/* modified for FLinv(kl6) */\n\t\tdw = (subRL[1] & subRL[25]) >> 32;\n\t\tsubRL[1] ^= rol32(dw, 1);\n\n\t\t/* round 20 */\n\t\tsubRL[27] ^= subRL[1];\n\t\t/* round 22 */\n\t\tsubRL[29] ^= subRL[1];\n\t\t/* round 24 */\n\t\tsubRL[31] ^= subRL[1];\n\t\t/* kw3 */\n\t\tsubRL[32] ^= subRL[1];\n\n\t\t/* absorb kw4 to other subkeys */\n\t\tkw4 = subRL[33];\n\t\t/* round 23 */\n\t\tsubRL[30] ^= kw4;\n\t\t/* round 21 */\n\t\tsubRL[28] ^= kw4;\n\t\t/* round 19 */\n\t\tsubRL[26] ^= kw4;\n\n\t\tkw4 ^= (kw4 & ~subRL[24]) << 32;\n\t\t/* modified for FL(kl5) */\n\t\tdw = (kw4 & subRL[24]) >> 32;\n\t\tkw4 ^= rol32(dw, 1);\n\t}\n\n\t/* round 17 */\n\tsubRL[22] ^= kw4;\n\t/* round 15 */\n\tsubRL[20] ^= kw4;\n\t/* round 13 */\n\tsubRL[18] ^= kw4;\n\n\tkw4 ^= (kw4 & ~subRL[16]) << 32;\n\t/* modified for FL(kl3) */\n\tdw = (kw4 & subRL[16]) >> 32;\n\tkw4 ^= rol32(dw, 1);\n\n\t/* round 11 */\n\tsubRL[14] ^= kw4;\n\t/* round 9 */\n\tsubRL[12] ^= kw4;\n\t/* round 7 */\n\tsubRL[10] ^= kw4;\n\n\tkw4 ^= (kw4 & ~subRL[8]) << 32;\n\t/* modified for FL(kl1) */\n\tdw = (kw4 & subRL[8]) >> 32;\n\tkw4 ^= rol32(dw, 1);\n\n\t/* round 5 */\n\tsubRL[6] ^= kw4;\n\t/* round 3 */\n\tsubRL[4] ^= kw4;\n\t/* round 1 */\n\tsubRL[2] ^= kw4;\n\t/* kw1 */\n\tsubRL[0] ^= kw4;\n\n\t/* key XOR is end of F-function */\n\tSET_SUBKEY_LR(0, subRL[0] ^ subRL[2]);\t\t\t/* kw1 */\n\tSET_SUBKEY_LR(2, subRL[3]);\t\t\t\t/* round 1 */\n\tSET_SUBKEY_LR(3, subRL[2] ^ subRL[4]);\t\t\t/* round 2 */\n\tSET_SUBKEY_LR(4, subRL[3] ^ subRL[5]);\t\t\t/* round 3 */\n\tSET_SUBKEY_LR(5, subRL[4] ^ subRL[6]);\t\t\t/* round 4 */\n\tSET_SUBKEY_LR(6, subRL[5] ^ subRL[7]);\t\t\t/* round 5 */\n\n\ttl = (subRL[10] >> 32) ^ (subRL[10] & ~subRL[8]);\n\tdw = tl & (subRL[8] >> 32);\t\t\t\t/* FL(kl1) */\n\ttr = subRL[10] ^ rol32(dw, 1);\n\ttt = (tr | ((u64)tl << 32));\n\n\tSET_SUBKEY_LR(7, subRL[6] ^ tt);\t\t\t/* round 6 */\n\tSET_SUBKEY_LR(8, subRL[8]);\t\t\t\t/* FL(kl1) */\n\tSET_SUBKEY_LR(9, subRL[9]);\t\t\t\t/* FLinv(kl2) */\n\n\ttl = (subRL[7] >> 32) ^ (subRL[7] & ~subRL[9]);\n\tdw = tl & (subRL[9] >> 32);\t\t\t\t/* FLinv(kl2) */\n\ttr = subRL[7] ^ rol32(dw, 1);\n\ttt = (tr | ((u64)tl << 32));\n\n\tSET_SUBKEY_LR(10, subRL[11] ^ tt);\t\t\t/* round 7 */\n\tSET_SUBKEY_LR(11, subRL[10] ^ subRL[12]);\t\t/* round 8 */\n\tSET_SUBKEY_LR(12, subRL[11] ^ subRL[13]);\t\t/* round 9 */\n\tSET_SUBKEY_LR(13, subRL[12] ^ subRL[14]);\t\t/* round 10 */\n\tSET_SUBKEY_LR(14, subRL[13] ^ subRL[15]);\t\t/* round 11 */\n\n\ttl = (subRL[18] >> 32) ^ (subRL[18] & ~subRL[16]);\n\tdw = tl & (subRL[16] >> 32);\t\t\t\t/* FL(kl3) */\n\ttr = subRL[18] ^ rol32(dw, 1);\n\ttt = (tr | ((u64)tl << 32));\n\n\tSET_SUBKEY_LR(15, subRL[14] ^ tt);\t\t\t/* round 12 */\n\tSET_SUBKEY_LR(16, subRL[16]);\t\t\t\t/* FL(kl3) */\n\tSET_SUBKEY_LR(17, subRL[17]);\t\t\t\t/* FLinv(kl4) */\n\n\ttl = (subRL[15] >> 32) ^ (subRL[15] & ~subRL[17]);\n\tdw = tl & (subRL[17] >> 32);\t\t\t\t/* FLinv(kl4) */\n\ttr = subRL[15] ^ rol32(dw, 1);\n\ttt = (tr | ((u64)tl << 32));\n\n\tSET_SUBKEY_LR(18, subRL[19] ^ tt);\t\t\t/* round 13 */\n\tSET_SUBKEY_LR(19, subRL[18] ^ subRL[20]);\t\t/* round 14 */\n\tSET_SUBKEY_LR(20, subRL[19] ^ subRL[21]);\t\t/* round 15 */\n\tSET_SUBKEY_LR(21, subRL[20] ^ subRL[22]);\t\t/* round 16 */\n\tSET_SUBKEY_LR(22, subRL[21] ^ subRL[23]);\t\t/* round 17 */\n\n\tif (max == 24) {\n\t\tSET_SUBKEY_LR(23, subRL[22]);\t\t\t/* round 18 */\n\t\tSET_SUBKEY_LR(24, subRL[24] ^ subRL[23]);\t/* kw3 */\n\t} else {\n\t\ttl = (subRL[26] >> 32) ^ (subRL[26] & ~subRL[24]);\n\t\tdw = tl & (subRL[24] >> 32);\t\t\t/* FL(kl5) */\n\t\ttr = subRL[26] ^ rol32(dw, 1);\n\t\ttt = (tr | ((u64)tl << 32));\n\n\t\tSET_SUBKEY_LR(23, subRL[22] ^ tt);\t\t/* round 18 */\n\t\tSET_SUBKEY_LR(24, subRL[24]);\t\t\t/* FL(kl5) */\n\t\tSET_SUBKEY_LR(25, subRL[25]);\t\t\t/* FLinv(kl6) */\n\n\t\ttl = (subRL[23] >> 32) ^ (subRL[23] & ~subRL[25]);\n\t\tdw = tl & (subRL[25] >> 32);\t\t\t/* FLinv(kl6) */\n\t\ttr = subRL[23] ^ rol32(dw, 1);\n\t\ttt = (tr | ((u64)tl << 32));\n\n\t\tSET_SUBKEY_LR(26, subRL[27] ^ tt);\t\t/* round 19 */\n\t\tSET_SUBKEY_LR(27, subRL[26] ^ subRL[28]);\t/* round 20 */\n\t\tSET_SUBKEY_LR(28, subRL[27] ^ subRL[29]);\t/* round 21 */\n\t\tSET_SUBKEY_LR(29, subRL[28] ^ subRL[30]);\t/* round 22 */\n\t\tSET_SUBKEY_LR(30, subRL[29] ^ subRL[31]);\t/* round 23 */\n\t\tSET_SUBKEY_LR(31, subRL[30]);\t\t\t/* round 24 */\n\t\tSET_SUBKEY_LR(32, subRL[32] ^ subRL[31]);\t/* kw3 */\n\t}\n}\n\nstatic void camellia_setup128(const unsigned char *key, u64 *subkey)\n{\n\tu64 kl, kr, ww;\n\tu64 subRL[26];\n\n\t/**\n\t *  k == kl || kr (|| is concatenation)\n\t */\n\tkl = get_unaligned_be64(key);\n\tkr = get_unaligned_be64(key + 8);\n\n\t/* generate KL dependent subkeys */\n\t/* kw1 */\n\tsubRL[0] = kl;\n\t/* kw2 */\n\tsubRL[1] = kr;\n\n\t/* rotation left shift 15bit */\n\tROLDQ(kl, kr, 15);\n\n\t/* k3 */\n\tsubRL[4] = kl;\n\t/* k4 */\n\tsubRL[5] = kr;\n\n\t/* rotation left shift 15+30bit */\n\tROLDQ(kl, kr, 30);\n\n\t/* k7 */\n\tsubRL[10] = kl;\n\t/* k8 */\n\tsubRL[11] = kr;\n\n\t/* rotation left shift 15+30+15bit */\n\tROLDQ(kl, kr, 15);\n\n\t/* k10 */\n\tsubRL[13] = kr;\n\t/* rotation left shift 15+30+15+17 bit */\n\tROLDQ(kl, kr, 17);\n\n\t/* kl3 */\n\tsubRL[16] = kl;\n\t/* kl4 */\n\tsubRL[17] = kr;\n\n\t/* rotation left shift 15+30+15+17+17 bit */\n\tROLDQ(kl, kr, 17);\n\n\t/* k13 */\n\tsubRL[18] = kl;\n\t/* k14 */\n\tsubRL[19] = kr;\n\n\t/* rotation left shift 15+30+15+17+17+17 bit */\n\tROLDQ(kl, kr, 17);\n\n\t/* k17 */\n\tsubRL[22] = kl;\n\t/* k18 */\n\tsubRL[23] = kr;\n\n\t/* generate KA */\n\tkl = subRL[0];\n\tkr = subRL[1];\n\tCAMELLIA_F(kl, CAMELLIA_SIGMA1L, CAMELLIA_SIGMA1R, ww);\n\tkr ^= ww;\n\tCAMELLIA_F(kr, CAMELLIA_SIGMA2L, CAMELLIA_SIGMA2R, kl);\n\n\t/* current status == (kll, klr, w0, w1) */\n\tCAMELLIA_F(kl, CAMELLIA_SIGMA3L, CAMELLIA_SIGMA3R, kr);\n\tkr ^= ww;\n\tCAMELLIA_F(kr, CAMELLIA_SIGMA4L, CAMELLIA_SIGMA4R, ww);\n\tkl ^= ww;\n\n\t/* generate KA dependent subkeys */\n\t/* k1, k2 */\n\tsubRL[2] = kl;\n\tsubRL[3] = kr;\n\tROLDQ(kl, kr, 15);\n\t/* k5,k6 */\n\tsubRL[6] = kl;\n\tsubRL[7] = kr;\n\tROLDQ(kl, kr, 15);\n\t/* kl1, kl2 */\n\tsubRL[8] = kl;\n\tsubRL[9] = kr;\n\tROLDQ(kl, kr, 15);\n\t/* k9 */\n\tsubRL[12] = kl;\n\tROLDQ(kl, kr, 15);\n\t/* k11, k12 */\n\tsubRL[14] = kl;\n\tsubRL[15] = kr;\n\tROLDQ(kl, kr, 34);\n\t/* k15, k16 */\n\tsubRL[20] = kl;\n\tsubRL[21] = kr;\n\tROLDQ(kl, kr, 17);\n\t/* kw3, kw4 */\n\tsubRL[24] = kl;\n\tsubRL[25] = kr;\n\n\tcamellia_setup_tail(subkey, subRL, 24);\n}\n\nstatic void camellia_setup256(const unsigned char *key, u64 *subkey)\n{\n\tu64 kl, kr;\t\t\t/* left half of key */\n\tu64 krl, krr;\t\t\t/* right half of key */\n\tu64 ww;\t\t\t\t/* temporary variables */\n\tu64 subRL[34];\n\n\t/**\n\t *  key = (kl || kr || krl || krr) (|| is concatenation)\n\t */\n\tkl = get_unaligned_be64(key);\n\tkr = get_unaligned_be64(key + 8);\n\tkrl = get_unaligned_be64(key + 16);\n\tkrr = get_unaligned_be64(key + 24);\n\n\t/* generate KL dependent subkeys */\n\t/* kw1 */\n\tsubRL[0] = kl;\n\t/* kw2 */\n\tsubRL[1] = kr;\n\tROLDQ(kl, kr, 45);\n\t/* k9 */\n\tsubRL[12] = kl;\n\t/* k10 */\n\tsubRL[13] = kr;\n\tROLDQ(kl, kr, 15);\n\t/* kl3 */\n\tsubRL[16] = kl;\n\t/* kl4 */\n\tsubRL[17] = kr;\n\tROLDQ(kl, kr, 17);\n\t/* k17 */\n\tsubRL[22] = kl;\n\t/* k18 */\n\tsubRL[23] = kr;\n\tROLDQ(kl, kr, 34);\n\t/* k23 */\n\tsubRL[30] = kl;\n\t/* k24 */\n\tsubRL[31] = kr;\n\n\t/* generate KR dependent subkeys */\n\tROLDQ(krl, krr, 15);\n\t/* k3 */\n\tsubRL[4] = krl;\n\t/* k4 */\n\tsubRL[5] = krr;\n\tROLDQ(krl, krr, 15);\n\t/* kl1 */\n\tsubRL[8] = krl;\n\t/* kl2 */\n\tsubRL[9] = krr;\n\tROLDQ(krl, krr, 30);\n\t/* k13 */\n\tsubRL[18] = krl;\n\t/* k14 */\n\tsubRL[19] = krr;\n\tROLDQ(krl, krr, 34);\n\t/* k19 */\n\tsubRL[26] = krl;\n\t/* k20 */\n\tsubRL[27] = krr;\n\tROLDQ(krl, krr, 34);\n\n\t/* generate KA */\n\tkl = subRL[0] ^ krl;\n\tkr = subRL[1] ^ krr;\n\n\tCAMELLIA_F(kl, CAMELLIA_SIGMA1L, CAMELLIA_SIGMA1R, ww);\n\tkr ^= ww;\n\tCAMELLIA_F(kr, CAMELLIA_SIGMA2L, CAMELLIA_SIGMA2R, kl);\n\tkl ^= krl;\n\tCAMELLIA_F(kl, CAMELLIA_SIGMA3L, CAMELLIA_SIGMA3R, kr);\n\tkr ^= ww ^ krr;\n\tCAMELLIA_F(kr, CAMELLIA_SIGMA4L, CAMELLIA_SIGMA4R, ww);\n\tkl ^= ww;\n\n\t/* generate KB */\n\tkrl ^= kl;\n\tkrr ^= kr;\n\tCAMELLIA_F(krl, CAMELLIA_SIGMA5L, CAMELLIA_SIGMA5R, ww);\n\tkrr ^= ww;\n\tCAMELLIA_F(krr, CAMELLIA_SIGMA6L, CAMELLIA_SIGMA6R, ww);\n\tkrl ^= ww;\n\n\t/* generate KA dependent subkeys */\n\tROLDQ(kl, kr, 15);\n\t/* k5 */\n\tsubRL[6] = kl;\n\t/* k6 */\n\tsubRL[7] = kr;\n\tROLDQ(kl, kr, 30);\n\t/* k11 */\n\tsubRL[14] = kl;\n\t/* k12 */\n\tsubRL[15] = kr;\n\t/* rotation left shift 32bit */\n\tROLDQ(kl, kr, 32);\n\t/* kl5 */\n\tsubRL[24] = kl;\n\t/* kl6 */\n\tsubRL[25] = kr;\n\t/* rotation left shift 17 from k11,k12 -> k21,k22 */\n\tROLDQ(kl, kr, 17);\n\t/* k21 */\n\tsubRL[28] = kl;\n\t/* k22 */\n\tsubRL[29] = kr;\n\n\t/* generate KB dependent subkeys */\n\t/* k1 */\n\tsubRL[2] = krl;\n\t/* k2 */\n\tsubRL[3] = krr;\n\tROLDQ(krl, krr, 30);\n\t/* k7 */\n\tsubRL[10] = krl;\n\t/* k8 */\n\tsubRL[11] = krr;\n\tROLDQ(krl, krr, 30);\n\t/* k15 */\n\tsubRL[20] = krl;\n\t/* k16 */\n\tsubRL[21] = krr;\n\tROLDQ(krl, krr, 51);\n\t/* kw3 */\n\tsubRL[32] = krl;\n\t/* kw4 */\n\tsubRL[33] = krr;\n\n\tcamellia_setup_tail(subkey, subRL, 32);\n}\n\nstatic void camellia_setup192(const unsigned char *key, u64 *subkey)\n{\n\tunsigned char kk[32];\n\tu64 krl, krr;\n\n\tmemcpy(kk, key, 24);\n\tmemcpy((unsigned char *)&krl, key+16, 8);\n\tkrr = ~krl;\n\tmemcpy(kk+24, (unsigned char *)&krr, 8);\n\tcamellia_setup256(kk, subkey);\n}\n\nint __camellia_setkey(struct camellia_ctx *cctx, const unsigned char *key,\n\t\t      unsigned int key_len, u32 *flags)\n{\n\tif (key_len != 16 && key_len != 24 && key_len != 32) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\tcctx->key_length = key_len;\n\n\tswitch (key_len) {\n\tcase 16:\n\t\tcamellia_setup128(key, cctx->key_table);\n\t\tbreak;\n\tcase 24:\n\t\tcamellia_setup192(key, cctx->key_table);\n\t\tbreak;\n\tcase 32:\n\t\tcamellia_setup256(key, cctx->key_table);\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(__camellia_setkey);\n\nstatic int camellia_setkey(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t\t   unsigned int key_len)\n{\n\treturn __camellia_setkey(crypto_tfm_ctx(tfm), in_key, key_len,\n\t\t\t\t &tfm->crt_flags);\n}\n\nvoid camellia_decrypt_cbc_2way(void *ctx, u128 *dst, const u128 *src)\n{\n\tu128 iv = *src;\n\n\tcamellia_dec_blk_2way(ctx, (u8 *)dst, (u8 *)src);\n\n\tu128_xor(&dst[1], &dst[1], &iv);\n}\nEXPORT_SYMBOL_GPL(camellia_decrypt_cbc_2way);\n\nvoid camellia_crypt_ctr(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tbe128 ctrblk;\n\n\tif (dst != src)\n\t\t*dst = *src;\n\n\tle128_to_be128(&ctrblk, iv);\n\tle128_inc(iv);\n\n\tcamellia_enc_blk_xor(ctx, (u8 *)dst, (u8 *)&ctrblk);\n}\nEXPORT_SYMBOL_GPL(camellia_crypt_ctr);\n\nvoid camellia_crypt_ctr_2way(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tbe128 ctrblks[2];\n\n\tif (dst != src) {\n\t\tdst[0] = src[0];\n\t\tdst[1] = src[1];\n\t}\n\n\tle128_to_be128(&ctrblks[0], iv);\n\tle128_inc(iv);\n\tle128_to_be128(&ctrblks[1], iv);\n\tle128_inc(iv);\n\n\tcamellia_enc_blk_xor_2way(ctx, (u8 *)dst, (u8 *)ctrblks);\n}\nEXPORT_SYMBOL_GPL(camellia_crypt_ctr_2way);\n\nstatic const struct common_glue_ctx camellia_enc = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = -1,\n\n\t.funcs = { {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_enc_blk_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_enc_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_ctr = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = -1,\n\n\t.funcs = { {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(camellia_crypt_ctr_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(camellia_crypt_ctr) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_dec = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = -1,\n\n\t.funcs = { {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_dec_blk_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(camellia_dec_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx camellia_dec_cbc = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = -1,\n\n\t.funcs = { {\n\t\t.num_blocks = 2,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(camellia_decrypt_cbc_2way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(camellia_dec_blk) }\n\t} }\n};\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&camellia_enc, desc, dst, src, nbytes);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&camellia_dec, desc, dst, src, nbytes);\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_encrypt_128bit(GLUE_FUNC_CAST(camellia_enc_blk), desc,\n\t\t\t\t       dst, src, nbytes);\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_decrypt_128bit(&camellia_dec_cbc, desc, dst, src,\n\t\t\t\t       nbytes);\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ctr_crypt_128bit(&camellia_ctr, desc, dst, src, nbytes);\n}\n\nstatic void encrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = CAMELLIA_BLOCK_SIZE;\n\tstruct camellia_ctx *ctx = priv;\n\tint i;\n\n\twhile (nbytes >= 2 * bsize) {\n\t\tcamellia_enc_blk_2way(ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * 2;\n\t\tnbytes -= bsize * 2;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\tcamellia_enc_blk(ctx, srcdst, srcdst);\n}\n\nstatic void decrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = CAMELLIA_BLOCK_SIZE;\n\tstruct camellia_ctx *ctx = priv;\n\tint i;\n\n\twhile (nbytes >= 2 * bsize) {\n\t\tcamellia_dec_blk_2way(ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * 2;\n\t\tnbytes -= bsize * 2;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\tcamellia_dec_blk(ctx, srcdst, srcdst);\n}\n\nint lrw_camellia_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\tunsigned int keylen)\n{\n\tstruct camellia_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\tint err;\n\n\terr = __camellia_setkey(&ctx->camellia_ctx, key,\n\t\t\t\tkeylen - CAMELLIA_BLOCK_SIZE,\n\t\t\t\t&tfm->crt_flags);\n\tif (err)\n\t\treturn err;\n\n\treturn lrw_init_table(&ctx->lrw_table,\n\t\t\t      key + keylen - CAMELLIA_BLOCK_SIZE);\n}\nEXPORT_SYMBOL_GPL(lrw_camellia_setkey);\n\nstatic int lrw_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[2 * 4];\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &ctx->camellia_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\n\treturn lrw_crypt(desc, dst, src, nbytes, &req);\n}\n\nstatic int lrw_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[2 * 4];\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &ctx->camellia_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\n\treturn lrw_crypt(desc, dst, src, nbytes, &req);\n}\n\nvoid lrw_camellia_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct camellia_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tlrw_free_table(&ctx->lrw_table);\n}\nEXPORT_SYMBOL_GPL(lrw_camellia_exit_tfm);\n\nint xts_camellia_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\tunsigned int keylen)\n{\n\tstruct camellia_xts_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tint err;\n\n\t/* key consists of keys of equal size concatenated, therefore\n\t * the length must be even\n\t */\n\tif (keylen % 2) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\t/* first half of xts-key is for crypt */\n\terr = __camellia_setkey(&ctx->crypt_ctx, key, keylen / 2, flags);\n\tif (err)\n\t\treturn err;\n\n\t/* second half of xts-key is for tweak */\n\treturn __camellia_setkey(&ctx->tweak_ctx, key + keylen / 2, keylen / 2,\n\t\t\t\tflags);\n}\nEXPORT_SYMBOL_GPL(xts_camellia_setkey);\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[2 * 4];\n\tstruct xts_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.tweak_ctx = &ctx->tweak_ctx,\n\t\t.tweak_fn = XTS_TWEAK_CAST(camellia_enc_blk),\n\t\t.crypt_ctx = &ctx->crypt_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\n\treturn xts_crypt(desc, dst, src, nbytes, &req);\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct camellia_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[2 * 4];\n\tstruct xts_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.tweak_ctx = &ctx->tweak_ctx,\n\t\t.tweak_fn = XTS_TWEAK_CAST(camellia_enc_blk),\n\t\t.crypt_ctx = &ctx->crypt_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\n\treturn xts_crypt(desc, dst, src, nbytes, &req);\n}\n\nstatic struct crypto_alg camellia_algs[6] = { {\n\t.cra_name\t\t= \"camellia\",\n\t.cra_driver_name\t= \"camellia-asm\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u\t\t\t= {\n\t\t.cipher = {\n\t\t\t.cia_min_keysize = CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize = CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t = camellia_setkey,\n\t\t\t.cia_encrypt\t = camellia_encrypt,\n\t\t\t.cia_decrypt\t = camellia_decrypt\n\t\t}\n\t}\n}, {\n\t.cra_name\t\t= \"ecb(camellia)\",\n\t.cra_driver_name\t= \"ecb-camellia-asm\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= camellia_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(camellia)\",\n\t.cra_driver_name\t= \"cbc-camellia-asm\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= camellia_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(camellia)\",\n\t.cra_driver_name\t= \"ctr-camellia-asm\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= camellia_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"lrw(camellia)\",\n\t.cra_driver_name\t= \"lrw-camellia-asm\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_lrw_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_exit\t\t= lrw_camellia_exit_tfm,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE +\n\t\t\t\t\t\tCAMELLIA_BLOCK_SIZE,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE +\n\t\t\t\t\t\tCAMELLIA_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= lrw_camellia_setkey,\n\t\t\t.encrypt\t= lrw_encrypt,\n\t\t\t.decrypt\t= lrw_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"xts(camellia)\",\n\t.cra_driver_name\t= \"xts-camellia-asm\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct camellia_xts_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAMELLIA_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= CAMELLIA_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= CAMELLIA_BLOCK_SIZE,\n\t\t\t.setkey\t\t= xts_camellia_setkey,\n\t\t\t.encrypt\t= xts_encrypt,\n\t\t\t.decrypt\t= xts_decrypt,\n\t\t},\n\t},\n} };\n\nstatic bool is_blacklisted_cpu(void)\n{\n\tif (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL)\n\t\treturn false;\n\n\tif (boot_cpu_data.x86 == 0x0f) {\n\t\t/*\n\t\t * On Pentium 4, camellia-asm is slower than original assembler\n\t\t * implementation because excessive uses of 64bit rotate and\n\t\t * left-shifts (which are really slow on P4) needed to store and\n\t\t * handle 128bit block in two 64bit registers.\n\t\t */\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic int force;\nmodule_param(force, int, 0);\nMODULE_PARM_DESC(force, \"Force module load, ignore CPU blacklist\");\n\nstatic int __init init(void)\n{\n\tif (!force && is_blacklisted_cpu()) {\n\t\tprintk(KERN_INFO\n\t\t\t\"camellia-x86_64: performance on this CPU \"\n\t\t\t\"would be suboptimal: disabling \"\n\t\t\t\"camellia-x86_64.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(camellia_algs, ARRAY_SIZE(camellia_algs));\n}\n\nstatic void __exit fini(void)\n{\n\tcrypto_unregister_algs(camellia_algs, ARRAY_SIZE(camellia_algs));\n}\n\nmodule_init(init);\nmodule_exit(fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Camellia Cipher Algorithm, asm optimized\");\nMODULE_ALIAS_CRYPTO(\"camellia\");\nMODULE_ALIAS_CRYPTO(\"camellia-asm\");\n", "/*\n * Glue Code for the AVX assembler implemention of the Cast5 Cipher\n *\n * Copyright (C) 2012 Johannes Goetzfried\n *     <Johannes.Goetzfried@informatik.stud.uni-erlangen.de>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307\n * USA\n *\n */\n\n#include <linux/module.h>\n#include <linux/hardirq.h>\n#include <linux/types.h>\n#include <linux/crypto.h>\n#include <linux/err.h>\n#include <crypto/ablk_helper.h>\n#include <crypto/algapi.h>\n#include <crypto/cast5.h>\n#include <crypto/cryptd.h>\n#include <crypto/ctr.h>\n#include <asm/xcr.h>\n#include <asm/xsave.h>\n#include <asm/crypto/glue_helper.h>\n\n#define CAST5_PARALLEL_BLOCKS 16\n\nasmlinkage void cast5_ecb_enc_16way(struct cast5_ctx *ctx, u8 *dst,\n\t\t\t\t    const u8 *src);\nasmlinkage void cast5_ecb_dec_16way(struct cast5_ctx *ctx, u8 *dst,\n\t\t\t\t    const u8 *src);\nasmlinkage void cast5_cbc_dec_16way(struct cast5_ctx *ctx, u8 *dst,\n\t\t\t\t    const u8 *src);\nasmlinkage void cast5_ctr_16way(struct cast5_ctx *ctx, u8 *dst, const u8 *src,\n\t\t\t\t__be64 *iv);\n\nstatic inline bool cast5_fpu_begin(bool fpu_enabled, unsigned int nbytes)\n{\n\treturn glue_fpu_begin(CAST5_BLOCK_SIZE, CAST5_PARALLEL_BLOCKS,\n\t\t\t      NULL, fpu_enabled, nbytes);\n}\n\nstatic inline void cast5_fpu_end(bool fpu_enabled)\n{\n\treturn glue_fpu_end(fpu_enabled);\n}\n\nstatic int ecb_crypt(struct blkcipher_desc *desc, struct blkcipher_walk *walk,\n\t\t     bool enc)\n{\n\tbool fpu_enabled = false;\n\tstruct cast5_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tconst unsigned int bsize = CAST5_BLOCK_SIZE;\n\tunsigned int nbytes;\n\tvoid (*fn)(struct cast5_ctx *ctx, u8 *dst, const u8 *src);\n\tint err;\n\n\tfn = (enc) ? cast5_ecb_enc_16way : cast5_ecb_dec_16way;\n\n\terr = blkcipher_walk_virt(desc, walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\twhile ((nbytes = walk->nbytes)) {\n\t\tu8 *wsrc = walk->src.virt.addr;\n\t\tu8 *wdst = walk->dst.virt.addr;\n\n\t\tfpu_enabled = cast5_fpu_begin(fpu_enabled, nbytes);\n\n\t\t/* Process multi-block batch */\n\t\tif (nbytes >= bsize * CAST5_PARALLEL_BLOCKS) {\n\t\t\tdo {\n\t\t\t\tfn(ctx, wdst, wsrc);\n\n\t\t\t\twsrc += bsize * CAST5_PARALLEL_BLOCKS;\n\t\t\t\twdst += bsize * CAST5_PARALLEL_BLOCKS;\n\t\t\t\tnbytes -= bsize * CAST5_PARALLEL_BLOCKS;\n\t\t\t} while (nbytes >= bsize * CAST5_PARALLEL_BLOCKS);\n\n\t\t\tif (nbytes < bsize)\n\t\t\t\tgoto done;\n\t\t}\n\n\t\tfn = (enc) ? __cast5_encrypt : __cast5_decrypt;\n\n\t\t/* Handle leftovers */\n\t\tdo {\n\t\t\tfn(ctx, wdst, wsrc);\n\n\t\t\twsrc += bsize;\n\t\t\twdst += bsize;\n\t\t\tnbytes -= bsize;\n\t\t} while (nbytes >= bsize);\n\ndone:\n\t\terr = blkcipher_walk_done(desc, walk, nbytes);\n\t}\n\n\tcast5_fpu_end(fpu_enabled);\n\treturn err;\n}\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_crypt(desc, &walk, true);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_crypt(desc, &walk, false);\n}\n\nstatic unsigned int __cbc_encrypt(struct blkcipher_desc *desc,\n\t\t\t\t  struct blkcipher_walk *walk)\n{\n\tstruct cast5_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tconst unsigned int bsize = CAST5_BLOCK_SIZE;\n\tunsigned int nbytes = walk->nbytes;\n\tu64 *src = (u64 *)walk->src.virt.addr;\n\tu64 *dst = (u64 *)walk->dst.virt.addr;\n\tu64 *iv = (u64 *)walk->iv;\n\n\tdo {\n\t\t*dst = *src ^ *iv;\n\t\t__cast5_encrypt(ctx, (u8 *)dst, (u8 *)dst);\n\t\tiv = dst;\n\n\t\tsrc += 1;\n\t\tdst += 1;\n\t\tnbytes -= bsize;\n\t} while (nbytes >= bsize);\n\n\t*(u64 *)walk->iv = *iv;\n\treturn nbytes;\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\twhile ((nbytes = walk.nbytes)) {\n\t\tnbytes = __cbc_encrypt(desc, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\n\treturn err;\n}\n\nstatic unsigned int __cbc_decrypt(struct blkcipher_desc *desc,\n\t\t\t\t  struct blkcipher_walk *walk)\n{\n\tstruct cast5_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tconst unsigned int bsize = CAST5_BLOCK_SIZE;\n\tunsigned int nbytes = walk->nbytes;\n\tu64 *src = (u64 *)walk->src.virt.addr;\n\tu64 *dst = (u64 *)walk->dst.virt.addr;\n\tu64 last_iv;\n\n\t/* Start of the last block. */\n\tsrc += nbytes / bsize - 1;\n\tdst += nbytes / bsize - 1;\n\n\tlast_iv = *src;\n\n\t/* Process multi-block batch */\n\tif (nbytes >= bsize * CAST5_PARALLEL_BLOCKS) {\n\t\tdo {\n\t\t\tnbytes -= bsize * (CAST5_PARALLEL_BLOCKS - 1);\n\t\t\tsrc -= CAST5_PARALLEL_BLOCKS - 1;\n\t\t\tdst -= CAST5_PARALLEL_BLOCKS - 1;\n\n\t\t\tcast5_cbc_dec_16way(ctx, (u8 *)dst, (u8 *)src);\n\n\t\t\tnbytes -= bsize;\n\t\t\tif (nbytes < bsize)\n\t\t\t\tgoto done;\n\n\t\t\t*dst ^= *(src - 1);\n\t\t\tsrc -= 1;\n\t\t\tdst -= 1;\n\t\t} while (nbytes >= bsize * CAST5_PARALLEL_BLOCKS);\n\t}\n\n\t/* Handle leftovers */\n\tfor (;;) {\n\t\t__cast5_decrypt(ctx, (u8 *)dst, (u8 *)src);\n\n\t\tnbytes -= bsize;\n\t\tif (nbytes < bsize)\n\t\t\tbreak;\n\n\t\t*dst ^= *(src - 1);\n\t\tsrc -= 1;\n\t\tdst -= 1;\n\t}\n\ndone:\n\t*dst ^= *(u64 *)walk->iv;\n\t*(u64 *)walk->iv = last_iv;\n\n\treturn nbytes;\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tbool fpu_enabled = false;\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\twhile ((nbytes = walk.nbytes)) {\n\t\tfpu_enabled = cast5_fpu_begin(fpu_enabled, nbytes);\n\t\tnbytes = __cbc_decrypt(desc, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\n\tcast5_fpu_end(fpu_enabled);\n\treturn err;\n}\n\nstatic void ctr_crypt_final(struct blkcipher_desc *desc,\n\t\t\t    struct blkcipher_walk *walk)\n{\n\tstruct cast5_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tu8 *ctrblk = walk->iv;\n\tu8 keystream[CAST5_BLOCK_SIZE];\n\tu8 *src = walk->src.virt.addr;\n\tu8 *dst = walk->dst.virt.addr;\n\tunsigned int nbytes = walk->nbytes;\n\n\t__cast5_encrypt(ctx, keystream, ctrblk);\n\tcrypto_xor(keystream, src, nbytes);\n\tmemcpy(dst, keystream, nbytes);\n\n\tcrypto_inc(ctrblk, CAST5_BLOCK_SIZE);\n}\n\nstatic unsigned int __ctr_crypt(struct blkcipher_desc *desc,\n\t\t\t\tstruct blkcipher_walk *walk)\n{\n\tstruct cast5_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tconst unsigned int bsize = CAST5_BLOCK_SIZE;\n\tunsigned int nbytes = walk->nbytes;\n\tu64 *src = (u64 *)walk->src.virt.addr;\n\tu64 *dst = (u64 *)walk->dst.virt.addr;\n\n\t/* Process multi-block batch */\n\tif (nbytes >= bsize * CAST5_PARALLEL_BLOCKS) {\n\t\tdo {\n\t\t\tcast5_ctr_16way(ctx, (u8 *)dst, (u8 *)src,\n\t\t\t\t\t(__be64 *)walk->iv);\n\n\t\t\tsrc += CAST5_PARALLEL_BLOCKS;\n\t\t\tdst += CAST5_PARALLEL_BLOCKS;\n\t\t\tnbytes -= bsize * CAST5_PARALLEL_BLOCKS;\n\t\t} while (nbytes >= bsize * CAST5_PARALLEL_BLOCKS);\n\n\t\tif (nbytes < bsize)\n\t\t\tgoto done;\n\t}\n\n\t/* Handle leftovers */\n\tdo {\n\t\tu64 ctrblk;\n\n\t\tif (dst != src)\n\t\t\t*dst = *src;\n\n\t\tctrblk = *(u64 *)walk->iv;\n\t\tbe64_add_cpu((__be64 *)walk->iv, 1);\n\n\t\t__cast5_encrypt(ctx, (u8 *)&ctrblk, (u8 *)&ctrblk);\n\t\t*dst ^= ctrblk;\n\n\t\tsrc += 1;\n\t\tdst += 1;\n\t\tnbytes -= bsize;\n\t} while (nbytes >= bsize);\n\ndone:\n\treturn nbytes;\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\tbool fpu_enabled = false;\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt_block(desc, &walk, CAST5_BLOCK_SIZE);\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\twhile ((nbytes = walk.nbytes) >= CAST5_BLOCK_SIZE) {\n\t\tfpu_enabled = cast5_fpu_begin(fpu_enabled, nbytes);\n\t\tnbytes = __ctr_crypt(desc, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\n\tcast5_fpu_end(fpu_enabled);\n\n\tif (walk.nbytes) {\n\t\tctr_crypt_final(desc, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, 0);\n\t}\n\n\treturn err;\n}\n\n\nstatic struct crypto_alg cast5_algs[6] = { {\n\t.cra_name\t\t= \"__ecb-cast5-avx\",\n\t.cra_driver_name\t= \"__driver-ecb-cast5-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAST5_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct cast5_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAST5_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST5_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= cast5_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__cbc-cast5-avx\",\n\t.cra_driver_name\t= \"__driver-cbc-cast5-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAST5_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct cast5_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAST5_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST5_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= cast5_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__ctr-cast5-avx\",\n\t.cra_driver_name\t= \"__driver-ctr-cast5-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct cast5_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAST5_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST5_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAST5_BLOCK_SIZE,\n\t\t\t.setkey\t\t= cast5_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ecb(cast5)\",\n\t.cra_driver_name\t= \"ecb-cast5-avx\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAST5_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAST5_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST5_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(cast5)\",\n\t.cra_driver_name\t= \"cbc-cast5-avx\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAST5_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAST5_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST5_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAST5_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= __ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(cast5)\",\n\t.cra_driver_name\t= \"ctr-cast5-avx\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAST5_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST5_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAST5_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_encrypt,\n\t\t\t.geniv\t\t= \"chainiv\",\n\t\t},\n\t},\n} };\n\nstatic int __init cast5_init(void)\n{\n\tu64 xcr0;\n\n\tif (!cpu_has_avx || !cpu_has_osxsave) {\n\t\tpr_info(\"AVX instructions are not detected.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\txcr0 = xgetbv(XCR_XFEATURE_ENABLED_MASK);\n\tif ((xcr0 & (XSTATE_SSE | XSTATE_YMM)) != (XSTATE_SSE | XSTATE_YMM)) {\n\t\tpr_info(\"AVX detected but unusable.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(cast5_algs, ARRAY_SIZE(cast5_algs));\n}\n\nstatic void __exit cast5_exit(void)\n{\n\tcrypto_unregister_algs(cast5_algs, ARRAY_SIZE(cast5_algs));\n}\n\nmodule_init(cast5_init);\nmodule_exit(cast5_exit);\n\nMODULE_DESCRIPTION(\"Cast5 Cipher Algorithm, AVX optimized\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_CRYPTO(\"cast5\");\n", "/*\n * Glue Code for the AVX assembler implemention of the Cast6 Cipher\n *\n * Copyright (C) 2012 Johannes Goetzfried\n *     <Johannes.Goetzfried@informatik.stud.uni-erlangen.de>\n *\n * Copyright \u00a9 2013 Jussi Kivilinna <jussi.kivilinna@iki.fi>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307\n * USA\n *\n */\n\n#include <linux/module.h>\n#include <linux/hardirq.h>\n#include <linux/types.h>\n#include <linux/crypto.h>\n#include <linux/err.h>\n#include <crypto/ablk_helper.h>\n#include <crypto/algapi.h>\n#include <crypto/cast6.h>\n#include <crypto/cryptd.h>\n#include <crypto/b128ops.h>\n#include <crypto/ctr.h>\n#include <crypto/lrw.h>\n#include <crypto/xts.h>\n#include <asm/xcr.h>\n#include <asm/xsave.h>\n#include <asm/crypto/glue_helper.h>\n\n#define CAST6_PARALLEL_BLOCKS 8\n\nasmlinkage void cast6_ecb_enc_8way(struct cast6_ctx *ctx, u8 *dst,\n\t\t\t\t   const u8 *src);\nasmlinkage void cast6_ecb_dec_8way(struct cast6_ctx *ctx, u8 *dst,\n\t\t\t\t   const u8 *src);\n\nasmlinkage void cast6_cbc_dec_8way(struct cast6_ctx *ctx, u8 *dst,\n\t\t\t\t   const u8 *src);\nasmlinkage void cast6_ctr_8way(struct cast6_ctx *ctx, u8 *dst, const u8 *src,\n\t\t\t       le128 *iv);\n\nasmlinkage void cast6_xts_enc_8way(struct cast6_ctx *ctx, u8 *dst,\n\t\t\t\t   const u8 *src, le128 *iv);\nasmlinkage void cast6_xts_dec_8way(struct cast6_ctx *ctx, u8 *dst,\n\t\t\t\t   const u8 *src, le128 *iv);\n\nstatic void cast6_xts_enc(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tglue_xts_crypt_128bit_one(ctx, dst, src, iv,\n\t\t\t\t  GLUE_FUNC_CAST(__cast6_encrypt));\n}\n\nstatic void cast6_xts_dec(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tglue_xts_crypt_128bit_one(ctx, dst, src, iv,\n\t\t\t\t  GLUE_FUNC_CAST(__cast6_decrypt));\n}\n\nstatic void cast6_crypt_ctr(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tbe128 ctrblk;\n\n\tle128_to_be128(&ctrblk, iv);\n\tle128_inc(iv);\n\n\t__cast6_encrypt(ctx, (u8 *)&ctrblk, (u8 *)&ctrblk);\n\tu128_xor(dst, src, (u128 *)&ctrblk);\n}\n\nstatic const struct common_glue_ctx cast6_enc = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = CAST6_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAST6_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(cast6_ecb_enc_8way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(__cast6_encrypt) }\n\t} }\n};\n\nstatic const struct common_glue_ctx cast6_ctr = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = CAST6_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAST6_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(cast6_ctr_8way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(cast6_crypt_ctr) }\n\t} }\n};\n\nstatic const struct common_glue_ctx cast6_enc_xts = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = CAST6_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAST6_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(cast6_xts_enc_8way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(cast6_xts_enc) }\n\t} }\n};\n\nstatic const struct common_glue_ctx cast6_dec = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = CAST6_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAST6_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(cast6_ecb_dec_8way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(__cast6_decrypt) }\n\t} }\n};\n\nstatic const struct common_glue_ctx cast6_dec_cbc = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = CAST6_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAST6_PARALLEL_BLOCKS,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(cast6_cbc_dec_8way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(__cast6_decrypt) }\n\t} }\n};\n\nstatic const struct common_glue_ctx cast6_dec_xts = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = CAST6_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = CAST6_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(cast6_xts_dec_8way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(cast6_xts_dec) }\n\t} }\n};\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&cast6_enc, desc, dst, src, nbytes);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&cast6_dec, desc, dst, src, nbytes);\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_encrypt_128bit(GLUE_FUNC_CAST(__cast6_encrypt), desc,\n\t\t\t\t       dst, src, nbytes);\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_decrypt_128bit(&cast6_dec_cbc, desc, dst, src,\n\t\t\t\t       nbytes);\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ctr_crypt_128bit(&cast6_ctr, desc, dst, src, nbytes);\n}\n\nstatic inline bool cast6_fpu_begin(bool fpu_enabled, unsigned int nbytes)\n{\n\treturn glue_fpu_begin(CAST6_BLOCK_SIZE, CAST6_PARALLEL_BLOCKS,\n\t\t\t      NULL, fpu_enabled, nbytes);\n}\n\nstatic inline void cast6_fpu_end(bool fpu_enabled)\n{\n\tglue_fpu_end(fpu_enabled);\n}\n\nstruct crypt_priv {\n\tstruct cast6_ctx *ctx;\n\tbool fpu_enabled;\n};\n\nstatic void encrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = CAST6_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = cast6_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes == bsize * CAST6_PARALLEL_BLOCKS) {\n\t\tcast6_ecb_enc_8way(ctx->ctx, srcdst, srcdst);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\t__cast6_encrypt(ctx->ctx, srcdst, srcdst);\n}\n\nstatic void decrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = CAST6_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = cast6_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes == bsize * CAST6_PARALLEL_BLOCKS) {\n\t\tcast6_ecb_dec_8way(ctx->ctx, srcdst, srcdst);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\t__cast6_decrypt(ctx->ctx, srcdst, srcdst);\n}\n\nstruct cast6_lrw_ctx {\n\tstruct lrw_table_ctx lrw_table;\n\tstruct cast6_ctx cast6_ctx;\n};\n\nstatic int lrw_cast6_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\t      unsigned int keylen)\n{\n\tstruct cast6_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\tint err;\n\n\terr = __cast6_setkey(&ctx->cast6_ctx, key, keylen - CAST6_BLOCK_SIZE,\n\t\t\t     &tfm->crt_flags);\n\tif (err)\n\t\treturn err;\n\n\treturn lrw_init_table(&ctx->lrw_table, key + keylen - CAST6_BLOCK_SIZE);\n}\n\nstatic int lrw_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct cast6_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[CAST6_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->cast6_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tcast6_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int lrw_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct cast6_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[CAST6_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->cast6_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tcast6_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic void lrw_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct cast6_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tlrw_free_table(&ctx->lrw_table);\n}\n\nstruct cast6_xts_ctx {\n\tstruct cast6_ctx tweak_ctx;\n\tstruct cast6_ctx crypt_ctx;\n};\n\nstatic int xts_cast6_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\t      unsigned int keylen)\n{\n\tstruct cast6_xts_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tint err;\n\n\t/* key consists of keys of equal size concatenated, therefore\n\t * the length must be even\n\t */\n\tif (keylen % 2) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\t/* first half of xts-key is for crypt */\n\terr = __cast6_setkey(&ctx->crypt_ctx, key, keylen / 2, flags);\n\tif (err)\n\t\treturn err;\n\n\t/* second half of xts-key is for tweak */\n\treturn __cast6_setkey(&ctx->tweak_ctx, key + keylen / 2, keylen / 2,\n\t\t\t      flags);\n}\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct cast6_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&cast6_enc_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(__cast6_encrypt),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct cast6_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&cast6_dec_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(__cast6_encrypt),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic struct crypto_alg cast6_algs[10] = { {\n\t.cra_name\t\t= \"__ecb-cast6-avx\",\n\t.cra_driver_name\t= \"__driver-ecb-cast6-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAST6_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct cast6_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAST6_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST6_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= cast6_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__cbc-cast6-avx\",\n\t.cra_driver_name\t= \"__driver-cbc-cast6-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAST6_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct cast6_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAST6_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST6_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= cast6_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__ctr-cast6-avx\",\n\t.cra_driver_name\t= \"__driver-ctr-cast6-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct cast6_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAST6_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST6_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAST6_BLOCK_SIZE,\n\t\t\t.setkey\t\t= cast6_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__lrw-cast6-avx\",\n\t.cra_driver_name\t= \"__driver-lrw-cast6-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAST6_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct cast6_lrw_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_exit\t\t= lrw_exit_tfm,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAST6_MIN_KEY_SIZE +\n\t\t\t\t\t  CAST6_BLOCK_SIZE,\n\t\t\t.max_keysize\t= CAST6_MAX_KEY_SIZE +\n\t\t\t\t\t  CAST6_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= CAST6_BLOCK_SIZE,\n\t\t\t.setkey\t\t= lrw_cast6_setkey,\n\t\t\t.encrypt\t= lrw_encrypt,\n\t\t\t.decrypt\t= lrw_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__xts-cast6-avx\",\n\t.cra_driver_name\t= \"__driver-xts-cast6-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= CAST6_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct cast6_xts_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= CAST6_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= CAST6_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= CAST6_BLOCK_SIZE,\n\t\t\t.setkey\t\t= xts_cast6_setkey,\n\t\t\t.encrypt\t= xts_encrypt,\n\t\t\t.decrypt\t= xts_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ecb(cast6)\",\n\t.cra_driver_name\t= \"ecb-cast6-avx\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAST6_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAST6_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST6_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(cast6)\",\n\t.cra_driver_name\t= \"cbc-cast6-avx\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAST6_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAST6_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST6_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAST6_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= __ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(cast6)\",\n\t.cra_driver_name\t= \"ctr-cast6-avx\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAST6_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= CAST6_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= CAST6_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_encrypt,\n\t\t\t.geniv\t\t= \"chainiv\",\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"lrw(cast6)\",\n\t.cra_driver_name\t= \"lrw-cast6-avx\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAST6_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAST6_MIN_KEY_SIZE +\n\t\t\t\t\t  CAST6_BLOCK_SIZE,\n\t\t\t.max_keysize\t= CAST6_MAX_KEY_SIZE +\n\t\t\t\t\t  CAST6_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= CAST6_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"xts(cast6)\",\n\t.cra_driver_name\t= \"xts-cast6-avx\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= CAST6_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= CAST6_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= CAST6_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= CAST6_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n} };\n\nstatic int __init cast6_init(void)\n{\n\tu64 xcr0;\n\n\tif (!cpu_has_avx || !cpu_has_osxsave) {\n\t\tpr_info(\"AVX instructions are not detected.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\txcr0 = xgetbv(XCR_XFEATURE_ENABLED_MASK);\n\tif ((xcr0 & (XSTATE_SSE | XSTATE_YMM)) != (XSTATE_SSE | XSTATE_YMM)) {\n\t\tpr_info(\"AVX detected but unusable.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(cast6_algs, ARRAY_SIZE(cast6_algs));\n}\n\nstatic void __exit cast6_exit(void)\n{\n\tcrypto_unregister_algs(cast6_algs, ARRAY_SIZE(cast6_algs));\n}\n\nmodule_init(cast6_init);\nmodule_exit(cast6_exit);\n\nMODULE_DESCRIPTION(\"Cast6 Cipher Algorithm, AVX optimized\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_CRYPTO(\"cast6\");\n", "/* GPL HEADER START\n *\n * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License version 2 only,\n * as published by the Free Software Foundation.\n *\n * This program is distributed in the hope that it will be useful, but\n * WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * General Public License version 2 for more details (a copy is included\n * in the LICENSE file that accompanied this code).\n *\n * You should have received a copy of the GNU General Public License\n * version 2 along with this program; If not, see http://www.gnu.org/licenses\n *\n * Please  visit http://www.xyratex.com/contact if you need additional\n * information or have any questions.\n *\n * GPL HEADER END\n */\n\n/*\n * Copyright 2012 Xyratex Technology Limited\n *\n * Wrappers for kernel crypto shash api to pclmulqdq crc32 imlementation.\n */\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n#include <linux/crc32.h>\n#include <crypto/internal/hash.h>\n\n#include <asm/cpufeature.h>\n#include <asm/cpu_device_id.h>\n#include <asm/i387.h>\n\n#define CHKSUM_BLOCK_SIZE\t1\n#define CHKSUM_DIGEST_SIZE\t4\n\n#define PCLMUL_MIN_LEN\t\t64L     /* minimum size of buffer\n\t\t\t\t\t * for crc32_pclmul_le_16 */\n#define SCALE_F\t\t\t16L\t/* size of xmm register */\n#define SCALE_F_MASK\t\t(SCALE_F - 1)\n\nu32 crc32_pclmul_le_16(unsigned char const *buffer, size_t len, u32 crc32);\n\nstatic u32 __attribute__((pure))\n\tcrc32_pclmul_le(u32 crc, unsigned char const *p, size_t len)\n{\n\tunsigned int iquotient;\n\tunsigned int iremainder;\n\tunsigned int prealign;\n\n\tif (len < PCLMUL_MIN_LEN + SCALE_F_MASK || !irq_fpu_usable())\n\t\treturn crc32_le(crc, p, len);\n\n\tif ((long)p & SCALE_F_MASK) {\n\t\t/* align p to 16 byte */\n\t\tprealign = SCALE_F - ((long)p & SCALE_F_MASK);\n\n\t\tcrc = crc32_le(crc, p, prealign);\n\t\tlen -= prealign;\n\t\tp = (unsigned char *)(((unsigned long)p + SCALE_F_MASK) &\n\t\t\t\t     ~SCALE_F_MASK);\n\t}\n\tiquotient = len & (~SCALE_F_MASK);\n\tiremainder = len & SCALE_F_MASK;\n\n\tkernel_fpu_begin();\n\tcrc = crc32_pclmul_le_16(p, iquotient, crc);\n\tkernel_fpu_end();\n\n\tif (iremainder)\n\t\tcrc = crc32_le(crc, p + iquotient, iremainder);\n\n\treturn crc;\n}\n\nstatic int crc32_pclmul_cra_init(struct crypto_tfm *tfm)\n{\n\tu32 *key = crypto_tfm_ctx(tfm);\n\n\t*key = 0;\n\n\treturn 0;\n}\n\nstatic int crc32_pclmul_setkey(struct crypto_shash *hash, const u8 *key,\n\t\t\tunsigned int keylen)\n{\n\tu32 *mctx = crypto_shash_ctx(hash);\n\n\tif (keylen != sizeof(u32)) {\n\t\tcrypto_shash_set_flags(hash, CRYPTO_TFM_RES_BAD_KEY_LEN);\n\t\treturn -EINVAL;\n\t}\n\t*mctx = le32_to_cpup((__le32 *)key);\n\treturn 0;\n}\n\nstatic int crc32_pclmul_init(struct shash_desc *desc)\n{\n\tu32 *mctx = crypto_shash_ctx(desc->tfm);\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t*crcp = *mctx;\n\n\treturn 0;\n}\n\nstatic int crc32_pclmul_update(struct shash_desc *desc, const u8 *data,\n\t\t\t       unsigned int len)\n{\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t*crcp = crc32_pclmul_le(*crcp, data, len);\n\treturn 0;\n}\n\n/* No final XOR 0xFFFFFFFF, like crc32_le */\nstatic int __crc32_pclmul_finup(u32 *crcp, const u8 *data, unsigned int len,\n\t\t\t\tu8 *out)\n{\n\t*(__le32 *)out = cpu_to_le32(crc32_pclmul_le(*crcp, data, len));\n\treturn 0;\n}\n\nstatic int crc32_pclmul_finup(struct shash_desc *desc, const u8 *data,\n\t\t\t      unsigned int len, u8 *out)\n{\n\treturn __crc32_pclmul_finup(shash_desc_ctx(desc), data, len, out);\n}\n\nstatic int crc32_pclmul_final(struct shash_desc *desc, u8 *out)\n{\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t*(__le32 *)out = cpu_to_le32p(crcp);\n\treturn 0;\n}\n\nstatic int crc32_pclmul_digest(struct shash_desc *desc, const u8 *data,\n\t\t\t       unsigned int len, u8 *out)\n{\n\treturn __crc32_pclmul_finup(crypto_shash_ctx(desc->tfm), data, len,\n\t\t\t\t    out);\n}\n\nstatic struct shash_alg alg = {\n\t.setkey\t\t= crc32_pclmul_setkey,\n\t.init\t\t= crc32_pclmul_init,\n\t.update\t\t= crc32_pclmul_update,\n\t.final\t\t= crc32_pclmul_final,\n\t.finup\t\t= crc32_pclmul_finup,\n\t.digest\t\t= crc32_pclmul_digest,\n\t.descsize\t= sizeof(u32),\n\t.digestsize\t= CHKSUM_DIGEST_SIZE,\n\t.base\t\t= {\n\t\t\t.cra_name\t\t= \"crc32\",\n\t\t\t.cra_driver_name\t= \"crc32-pclmul\",\n\t\t\t.cra_priority\t\t= 200,\n\t\t\t.cra_blocksize\t\t= CHKSUM_BLOCK_SIZE,\n\t\t\t.cra_ctxsize\t\t= sizeof(u32),\n\t\t\t.cra_module\t\t= THIS_MODULE,\n\t\t\t.cra_init\t\t= crc32_pclmul_cra_init,\n\t}\n};\n\nstatic const struct x86_cpu_id crc32pclmul_cpu_id[] = {\n\tX86_FEATURE_MATCH(X86_FEATURE_PCLMULQDQ),\n\t{}\n};\nMODULE_DEVICE_TABLE(x86cpu, crc32pclmul_cpu_id);\n\n\nstatic int __init crc32_pclmul_mod_init(void)\n{\n\n\tif (!x86_match_cpu(crc32pclmul_cpu_id)) {\n\t\tpr_info(\"PCLMULQDQ-NI instructions are not detected.\\n\");\n\t\treturn -ENODEV;\n\t}\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit crc32_pclmul_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(crc32_pclmul_mod_init);\nmodule_exit(crc32_pclmul_mod_fini);\n\nMODULE_AUTHOR(\"Alexander Boyko <alexander_boyko@xyratex.com>\");\nMODULE_LICENSE(\"GPL\");\n\nMODULE_ALIAS_CRYPTO(\"crc32\");\nMODULE_ALIAS_CRYPTO(\"crc32-pclmul\");\n", "/*\n * Using hardware provided CRC32 instruction to accelerate the CRC32 disposal.\n * CRC32C polynomial:0x1EDC6F41(BE)/0x82F63B78(LE)\n * CRC32 is a new instruction in Intel SSE4.2, the reference can be found at:\n * http://www.intel.com/products/processor/manuals/\n * Intel(R) 64 and IA-32 Architectures Software Developer's Manual\n * Volume 2A: Instruction Set Reference, A-M\n *\n * Copyright (C) 2008 Intel Corporation\n * Authors: Austin Zhang <austin_zhang@linux.intel.com>\n *          Kent Liu <kent.liu@intel.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms and conditions of the GNU General Public License,\n * version 2, as published by the Free Software Foundation.\n *\n * This program is distributed in the hope it will be useful, but WITHOUT\n * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for\n * more details.\n *\n * You should have received a copy of the GNU General Public License along with\n * this program; if not, write to the Free Software Foundation, Inc.,\n * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.\n *\n */\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n#include <crypto/internal/hash.h>\n\n#include <asm/cpufeature.h>\n#include <asm/cpu_device_id.h>\n#include <asm/i387.h>\n#include <asm/fpu-internal.h>\n\n#define CHKSUM_BLOCK_SIZE\t1\n#define CHKSUM_DIGEST_SIZE\t4\n\n#define SCALE_F\tsizeof(unsigned long)\n\n#ifdef CONFIG_X86_64\n#define REX_PRE \"0x48, \"\n#else\n#define REX_PRE\n#endif\n\n#ifdef CONFIG_X86_64\n/*\n * use carryless multiply version of crc32c when buffer\n * size is >= 512 (when eager fpu is enabled) or\n * >= 1024 (when eager fpu is disabled) to account\n * for fpu state save/restore overhead.\n */\n#define CRC32C_PCL_BREAKEVEN_EAGERFPU\t512\n#define CRC32C_PCL_BREAKEVEN_NOEAGERFPU\t1024\n\nasmlinkage unsigned int crc_pcl(const u8 *buffer, int len,\n\t\t\t\tunsigned int crc_init);\nstatic int crc32c_pcl_breakeven = CRC32C_PCL_BREAKEVEN_EAGERFPU;\n#if defined(X86_FEATURE_EAGER_FPU)\n#define set_pcl_breakeven_point()\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tif (!use_eager_fpu())\t\t\t\t\t\t\\\n\t\tcrc32c_pcl_breakeven = CRC32C_PCL_BREAKEVEN_NOEAGERFPU;\t\\\n} while (0)\n#else\n#define set_pcl_breakeven_point()\t\t\t\t\t\\\n\t(crc32c_pcl_breakeven = CRC32C_PCL_BREAKEVEN_NOEAGERFPU)\n#endif\n#endif /* CONFIG_X86_64 */\n\nstatic u32 crc32c_intel_le_hw_byte(u32 crc, unsigned char const *data, size_t length)\n{\n\twhile (length--) {\n\t\t__asm__ __volatile__(\n\t\t\t\".byte 0xf2, 0xf, 0x38, 0xf0, 0xf1\"\n\t\t\t:\"=S\"(crc)\n\t\t\t:\"0\"(crc), \"c\"(*data)\n\t\t);\n\t\tdata++;\n\t}\n\n\treturn crc;\n}\n\nstatic u32 __pure crc32c_intel_le_hw(u32 crc, unsigned char const *p, size_t len)\n{\n\tunsigned int iquotient = len / SCALE_F;\n\tunsigned int iremainder = len % SCALE_F;\n\tunsigned long *ptmp = (unsigned long *)p;\n\n\twhile (iquotient--) {\n\t\t__asm__ __volatile__(\n\t\t\t\".byte 0xf2, \" REX_PRE \"0xf, 0x38, 0xf1, 0xf1;\"\n\t\t\t:\"=S\"(crc)\n\t\t\t:\"0\"(crc), \"c\"(*ptmp)\n\t\t);\n\t\tptmp++;\n\t}\n\n\tif (iremainder)\n\t\tcrc = crc32c_intel_le_hw_byte(crc, (unsigned char *)ptmp,\n\t\t\t\t iremainder);\n\n\treturn crc;\n}\n\n/*\n * Setting the seed allows arbitrary accumulators and flexible XOR policy\n * If your algorithm starts with ~0, then XOR with ~0 before you set\n * the seed.\n */\nstatic int crc32c_intel_setkey(struct crypto_shash *hash, const u8 *key,\n\t\t\tunsigned int keylen)\n{\n\tu32 *mctx = crypto_shash_ctx(hash);\n\n\tif (keylen != sizeof(u32)) {\n\t\tcrypto_shash_set_flags(hash, CRYPTO_TFM_RES_BAD_KEY_LEN);\n\t\treturn -EINVAL;\n\t}\n\t*mctx = le32_to_cpup((__le32 *)key);\n\treturn 0;\n}\n\nstatic int crc32c_intel_init(struct shash_desc *desc)\n{\n\tu32 *mctx = crypto_shash_ctx(desc->tfm);\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t*crcp = *mctx;\n\n\treturn 0;\n}\n\nstatic int crc32c_intel_update(struct shash_desc *desc, const u8 *data,\n\t\t\t       unsigned int len)\n{\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t*crcp = crc32c_intel_le_hw(*crcp, data, len);\n\treturn 0;\n}\n\nstatic int __crc32c_intel_finup(u32 *crcp, const u8 *data, unsigned int len,\n\t\t\t\tu8 *out)\n{\n\t*(__le32 *)out = ~cpu_to_le32(crc32c_intel_le_hw(*crcp, data, len));\n\treturn 0;\n}\n\nstatic int crc32c_intel_finup(struct shash_desc *desc, const u8 *data,\n\t\t\t      unsigned int len, u8 *out)\n{\n\treturn __crc32c_intel_finup(shash_desc_ctx(desc), data, len, out);\n}\n\nstatic int crc32c_intel_final(struct shash_desc *desc, u8 *out)\n{\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t*(__le32 *)out = ~cpu_to_le32p(crcp);\n\treturn 0;\n}\n\nstatic int crc32c_intel_digest(struct shash_desc *desc, const u8 *data,\n\t\t\t       unsigned int len, u8 *out)\n{\n\treturn __crc32c_intel_finup(crypto_shash_ctx(desc->tfm), data, len,\n\t\t\t\t    out);\n}\n\nstatic int crc32c_intel_cra_init(struct crypto_tfm *tfm)\n{\n\tu32 *key = crypto_tfm_ctx(tfm);\n\n\t*key = ~0;\n\n\treturn 0;\n}\n\n#ifdef CONFIG_X86_64\nstatic int crc32c_pcl_intel_update(struct shash_desc *desc, const u8 *data,\n\t\t\t       unsigned int len)\n{\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t/*\n\t * use faster PCL version if datasize is large enough to\n\t * overcome kernel fpu state save/restore overhead\n\t */\n\tif (len >= crc32c_pcl_breakeven && irq_fpu_usable()) {\n\t\tkernel_fpu_begin();\n\t\t*crcp = crc_pcl(data, len, *crcp);\n\t\tkernel_fpu_end();\n\t} else\n\t\t*crcp = crc32c_intel_le_hw(*crcp, data, len);\n\treturn 0;\n}\n\nstatic int __crc32c_pcl_intel_finup(u32 *crcp, const u8 *data, unsigned int len,\n\t\t\t\tu8 *out)\n{\n\tif (len >= crc32c_pcl_breakeven && irq_fpu_usable()) {\n\t\tkernel_fpu_begin();\n\t\t*(__le32 *)out = ~cpu_to_le32(crc_pcl(data, len, *crcp));\n\t\tkernel_fpu_end();\n\t} else\n\t\t*(__le32 *)out =\n\t\t\t~cpu_to_le32(crc32c_intel_le_hw(*crcp, data, len));\n\treturn 0;\n}\n\nstatic int crc32c_pcl_intel_finup(struct shash_desc *desc, const u8 *data,\n\t\t\t      unsigned int len, u8 *out)\n{\n\treturn __crc32c_pcl_intel_finup(shash_desc_ctx(desc), data, len, out);\n}\n\nstatic int crc32c_pcl_intel_digest(struct shash_desc *desc, const u8 *data,\n\t\t\t       unsigned int len, u8 *out)\n{\n\treturn __crc32c_pcl_intel_finup(crypto_shash_ctx(desc->tfm), data, len,\n\t\t\t\t    out);\n}\n#endif /* CONFIG_X86_64 */\n\nstatic struct shash_alg alg = {\n\t.setkey\t\t\t=\tcrc32c_intel_setkey,\n\t.init\t\t\t=\tcrc32c_intel_init,\n\t.update\t\t\t=\tcrc32c_intel_update,\n\t.final\t\t\t=\tcrc32c_intel_final,\n\t.finup\t\t\t=\tcrc32c_intel_finup,\n\t.digest\t\t\t=\tcrc32c_intel_digest,\n\t.descsize\t\t=\tsizeof(u32),\n\t.digestsize\t\t=\tCHKSUM_DIGEST_SIZE,\n\t.base\t\t\t=\t{\n\t\t.cra_name\t\t=\t\"crc32c\",\n\t\t.cra_driver_name\t=\t\"crc32c-intel\",\n\t\t.cra_priority\t\t=\t200,\n\t\t.cra_blocksize\t\t=\tCHKSUM_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t=\tsizeof(u32),\n\t\t.cra_module\t\t=\tTHIS_MODULE,\n\t\t.cra_init\t\t=\tcrc32c_intel_cra_init,\n\t}\n};\n\nstatic const struct x86_cpu_id crc32c_cpu_id[] = {\n\tX86_FEATURE_MATCH(X86_FEATURE_XMM4_2),\n\t{}\n};\nMODULE_DEVICE_TABLE(x86cpu, crc32c_cpu_id);\n\nstatic int __init crc32c_intel_mod_init(void)\n{\n\tif (!x86_match_cpu(crc32c_cpu_id))\n\t\treturn -ENODEV;\n#ifdef CONFIG_X86_64\n\tif (cpu_has_pclmulqdq) {\n\t\talg.update = crc32c_pcl_intel_update;\n\t\talg.finup = crc32c_pcl_intel_finup;\n\t\talg.digest = crc32c_pcl_intel_digest;\n\t\tset_pcl_breakeven_point();\n\t}\n#endif\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit crc32c_intel_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(crc32c_intel_mod_init);\nmodule_exit(crc32c_intel_mod_fini);\n\nMODULE_AUTHOR(\"Austin Zhang <austin.zhang@intel.com>, Kent Liu <kent.liu@intel.com>\");\nMODULE_DESCRIPTION(\"CRC32c (Castagnoli) optimization using Intel Hardware.\");\nMODULE_LICENSE(\"GPL\");\n\nMODULE_ALIAS_CRYPTO(\"crc32c\");\nMODULE_ALIAS_CRYPTO(\"crc32c-intel\");\n", "/*\n * Cryptographic API.\n *\n * T10 Data Integrity Field CRC16 Crypto Transform using PCLMULQDQ Instructions\n *\n * Copyright (C) 2013 Intel Corporation\n * Author: Tim Chen <tim.c.chen@linux.intel.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS\n * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n * SOFTWARE.\n *\n */\n\n#include <linux/types.h>\n#include <linux/module.h>\n#include <linux/crc-t10dif.h>\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n#include <asm/i387.h>\n#include <asm/cpufeature.h>\n#include <asm/cpu_device_id.h>\n\nasmlinkage __u16 crc_t10dif_pcl(__u16 crc, const unsigned char *buf,\n\t\t\t\tsize_t len);\n\nstruct chksum_desc_ctx {\n\t__u16 crc;\n};\n\n/*\n * Steps through buffer one byte at at time, calculates reflected\n * crc using table.\n */\n\nstatic int chksum_init(struct shash_desc *desc)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\tctx->crc = 0;\n\n\treturn 0;\n}\n\nstatic int chksum_update(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int length)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\tif (irq_fpu_usable()) {\n\t\tkernel_fpu_begin();\n\t\tctx->crc = crc_t10dif_pcl(ctx->crc, data, length);\n\t\tkernel_fpu_end();\n\t} else\n\t\tctx->crc = crc_t10dif_generic(ctx->crc, data, length);\n\treturn 0;\n}\n\nstatic int chksum_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\t*(__u16 *)out = ctx->crc;\n\treturn 0;\n}\n\nstatic int __chksum_finup(__u16 *crcp, const u8 *data, unsigned int len,\n\t\t\tu8 *out)\n{\n\tif (irq_fpu_usable()) {\n\t\tkernel_fpu_begin();\n\t\t*(__u16 *)out = crc_t10dif_pcl(*crcp, data, len);\n\t\tkernel_fpu_end();\n\t} else\n\t\t*(__u16 *)out = crc_t10dif_generic(*crcp, data, len);\n\treturn 0;\n}\n\nstatic int chksum_finup(struct shash_desc *desc, const u8 *data,\n\t\t\tunsigned int len, u8 *out)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\treturn __chksum_finup(&ctx->crc, data, len, out);\n}\n\nstatic int chksum_digest(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int length, u8 *out)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\treturn __chksum_finup(&ctx->crc, data, length, out);\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t\t=\tCRC_T10DIF_DIGEST_SIZE,\n\t.init\t\t=\tchksum_init,\n\t.update\t\t=\tchksum_update,\n\t.final\t\t=\tchksum_final,\n\t.finup\t\t=\tchksum_finup,\n\t.digest\t\t=\tchksum_digest,\n\t.descsize\t\t=\tsizeof(struct chksum_desc_ctx),\n\t.base\t\t\t=\t{\n\t\t.cra_name\t\t=\t\"crct10dif\",\n\t\t.cra_driver_name\t=\t\"crct10dif-pclmul\",\n\t\t.cra_priority\t\t=\t200,\n\t\t.cra_blocksize\t\t=\tCRC_T10DIF_BLOCK_SIZE,\n\t\t.cra_module\t\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic const struct x86_cpu_id crct10dif_cpu_id[] = {\n\tX86_FEATURE_MATCH(X86_FEATURE_PCLMULQDQ),\n\t{}\n};\nMODULE_DEVICE_TABLE(x86cpu, crct10dif_cpu_id);\n\nstatic int __init crct10dif_intel_mod_init(void)\n{\n\tif (!x86_match_cpu(crct10dif_cpu_id))\n\t\treturn -ENODEV;\n\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit crct10dif_intel_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(crct10dif_intel_mod_init);\nmodule_exit(crct10dif_intel_mod_fini);\n\nMODULE_AUTHOR(\"Tim Chen <tim.c.chen@linux.intel.com>\");\nMODULE_DESCRIPTION(\"T10 DIF CRC calculation accelerated with PCLMULQDQ.\");\nMODULE_LICENSE(\"GPL\");\n\nMODULE_ALIAS_CRYPTO(\"crct10dif\");\nMODULE_ALIAS_CRYPTO(\"crct10dif-pclmul\");\n", "/*\n * Glue Code for assembler optimized version of 3DES\n *\n * Copyright \u00a9 2014 Jussi Kivilinna <jussi.kivilinna@mbnet.fi>\n *\n * CBC & ECB parts based on code (crypto/cbc.c,ecb.c) by:\n *   Copyright (c) 2006 Herbert Xu <herbert@gondor.apana.org.au>\n * CTR part based on code (crypto/ctr.c) by:\n *   (C) Copyright IBM Corp. 2007 - Joy Latten <latten@us.ibm.com>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n */\n\n#include <asm/processor.h>\n#include <crypto/des.h>\n#include <linux/crypto.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/types.h>\n#include <crypto/algapi.h>\n\nstruct des3_ede_x86_ctx {\n\tu32 enc_expkey[DES3_EDE_EXPKEY_WORDS];\n\tu32 dec_expkey[DES3_EDE_EXPKEY_WORDS];\n};\n\n/* regular block cipher functions */\nasmlinkage void des3_ede_x86_64_crypt_blk(const u32 *expkey, u8 *dst,\n\t\t\t\t\t  const u8 *src);\n\n/* 3-way parallel cipher functions */\nasmlinkage void des3_ede_x86_64_crypt_blk_3way(const u32 *expkey, u8 *dst,\n\t\t\t\t\t       const u8 *src);\n\nstatic inline void des3_ede_enc_blk(struct des3_ede_x86_ctx *ctx, u8 *dst,\n\t\t\t\t    const u8 *src)\n{\n\tu32 *enc_ctx = ctx->enc_expkey;\n\n\tdes3_ede_x86_64_crypt_blk(enc_ctx, dst, src);\n}\n\nstatic inline void des3_ede_dec_blk(struct des3_ede_x86_ctx *ctx, u8 *dst,\n\t\t\t\t    const u8 *src)\n{\n\tu32 *dec_ctx = ctx->dec_expkey;\n\n\tdes3_ede_x86_64_crypt_blk(dec_ctx, dst, src);\n}\n\nstatic inline void des3_ede_enc_blk_3way(struct des3_ede_x86_ctx *ctx, u8 *dst,\n\t\t\t\t\t const u8 *src)\n{\n\tu32 *enc_ctx = ctx->enc_expkey;\n\n\tdes3_ede_x86_64_crypt_blk_3way(enc_ctx, dst, src);\n}\n\nstatic inline void des3_ede_dec_blk_3way(struct des3_ede_x86_ctx *ctx, u8 *dst,\n\t\t\t\t\t const u8 *src)\n{\n\tu32 *dec_ctx = ctx->dec_expkey;\n\n\tdes3_ede_x86_64_crypt_blk_3way(dec_ctx, dst, src);\n}\n\nstatic void des3_ede_x86_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tdes3_ede_enc_blk(crypto_tfm_ctx(tfm), dst, src);\n}\n\nstatic void des3_ede_x86_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tdes3_ede_dec_blk(crypto_tfm_ctx(tfm), dst, src);\n}\n\nstatic int ecb_crypt(struct blkcipher_desc *desc, struct blkcipher_walk *walk,\n\t\t     const u32 *expkey)\n{\n\tunsigned int bsize = DES3_EDE_BLOCK_SIZE;\n\tunsigned int nbytes;\n\tint err;\n\n\terr = blkcipher_walk_virt(desc, walk);\n\n\twhile ((nbytes = walk->nbytes)) {\n\t\tu8 *wsrc = walk->src.virt.addr;\n\t\tu8 *wdst = walk->dst.virt.addr;\n\n\t\t/* Process four block batch */\n\t\tif (nbytes >= bsize * 3) {\n\t\t\tdo {\n\t\t\t\tdes3_ede_x86_64_crypt_blk_3way(expkey, wdst,\n\t\t\t\t\t\t\t       wsrc);\n\n\t\t\t\twsrc += bsize * 3;\n\t\t\t\twdst += bsize * 3;\n\t\t\t\tnbytes -= bsize * 3;\n\t\t\t} while (nbytes >= bsize * 3);\n\n\t\t\tif (nbytes < bsize)\n\t\t\t\tgoto done;\n\t\t}\n\n\t\t/* Handle leftovers */\n\t\tdo {\n\t\t\tdes3_ede_x86_64_crypt_blk(expkey, wdst, wsrc);\n\n\t\t\twsrc += bsize;\n\t\t\twdst += bsize;\n\t\t\tnbytes -= bsize;\n\t\t} while (nbytes >= bsize);\n\ndone:\n\t\terr = blkcipher_walk_done(desc, walk, nbytes);\n\t}\n\n\treturn err;\n}\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct des3_ede_x86_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_crypt(desc, &walk, ctx->enc_expkey);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct des3_ede_x86_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\treturn ecb_crypt(desc, &walk, ctx->dec_expkey);\n}\n\nstatic unsigned int __cbc_encrypt(struct blkcipher_desc *desc,\n\t\t\t\t  struct blkcipher_walk *walk)\n{\n\tstruct des3_ede_x86_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tunsigned int bsize = DES3_EDE_BLOCK_SIZE;\n\tunsigned int nbytes = walk->nbytes;\n\tu64 *src = (u64 *)walk->src.virt.addr;\n\tu64 *dst = (u64 *)walk->dst.virt.addr;\n\tu64 *iv = (u64 *)walk->iv;\n\n\tdo {\n\t\t*dst = *src ^ *iv;\n\t\tdes3_ede_enc_blk(ctx, (u8 *)dst, (u8 *)dst);\n\t\tiv = dst;\n\n\t\tsrc += 1;\n\t\tdst += 1;\n\t\tnbytes -= bsize;\n\t} while (nbytes >= bsize);\n\n\t*(u64 *)walk->iv = *iv;\n\treturn nbytes;\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\twhile ((nbytes = walk.nbytes)) {\n\t\tnbytes = __cbc_encrypt(desc, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\n\treturn err;\n}\n\nstatic unsigned int __cbc_decrypt(struct blkcipher_desc *desc,\n\t\t\t\t  struct blkcipher_walk *walk)\n{\n\tstruct des3_ede_x86_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tunsigned int bsize = DES3_EDE_BLOCK_SIZE;\n\tunsigned int nbytes = walk->nbytes;\n\tu64 *src = (u64 *)walk->src.virt.addr;\n\tu64 *dst = (u64 *)walk->dst.virt.addr;\n\tu64 ivs[3 - 1];\n\tu64 last_iv;\n\n\t/* Start of the last block. */\n\tsrc += nbytes / bsize - 1;\n\tdst += nbytes / bsize - 1;\n\n\tlast_iv = *src;\n\n\t/* Process four block batch */\n\tif (nbytes >= bsize * 3) {\n\t\tdo {\n\t\t\tnbytes -= bsize * 3 - bsize;\n\t\t\tsrc -= 3 - 1;\n\t\t\tdst -= 3 - 1;\n\n\t\t\tivs[0] = src[0];\n\t\t\tivs[1] = src[1];\n\n\t\t\tdes3_ede_dec_blk_3way(ctx, (u8 *)dst, (u8 *)src);\n\n\t\t\tdst[1] ^= ivs[0];\n\t\t\tdst[2] ^= ivs[1];\n\n\t\t\tnbytes -= bsize;\n\t\t\tif (nbytes < bsize)\n\t\t\t\tgoto done;\n\n\t\t\t*dst ^= *(src - 1);\n\t\t\tsrc -= 1;\n\t\t\tdst -= 1;\n\t\t} while (nbytes >= bsize * 3);\n\t}\n\n\t/* Handle leftovers */\n\tfor (;;) {\n\t\tdes3_ede_dec_blk(ctx, (u8 *)dst, (u8 *)src);\n\n\t\tnbytes -= bsize;\n\t\tif (nbytes < bsize)\n\t\t\tbreak;\n\n\t\t*dst ^= *(src - 1);\n\t\tsrc -= 1;\n\t\tdst -= 1;\n\t}\n\ndone:\n\t*dst ^= *(u64 *)walk->iv;\n\t*(u64 *)walk->iv = last_iv;\n\n\treturn nbytes;\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\twhile ((nbytes = walk.nbytes)) {\n\t\tnbytes = __cbc_decrypt(desc, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\n\treturn err;\n}\n\nstatic void ctr_crypt_final(struct des3_ede_x86_ctx *ctx,\n\t\t\t    struct blkcipher_walk *walk)\n{\n\tu8 *ctrblk = walk->iv;\n\tu8 keystream[DES3_EDE_BLOCK_SIZE];\n\tu8 *src = walk->src.virt.addr;\n\tu8 *dst = walk->dst.virt.addr;\n\tunsigned int nbytes = walk->nbytes;\n\n\tdes3_ede_enc_blk(ctx, keystream, ctrblk);\n\tcrypto_xor(keystream, src, nbytes);\n\tmemcpy(dst, keystream, nbytes);\n\n\tcrypto_inc(ctrblk, DES3_EDE_BLOCK_SIZE);\n}\n\nstatic unsigned int __ctr_crypt(struct blkcipher_desc *desc,\n\t\t\t\tstruct blkcipher_walk *walk)\n{\n\tstruct des3_ede_x86_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tunsigned int bsize = DES3_EDE_BLOCK_SIZE;\n\tunsigned int nbytes = walk->nbytes;\n\t__be64 *src = (__be64 *)walk->src.virt.addr;\n\t__be64 *dst = (__be64 *)walk->dst.virt.addr;\n\tu64 ctrblk = be64_to_cpu(*(__be64 *)walk->iv);\n\t__be64 ctrblocks[3];\n\n\t/* Process four block batch */\n\tif (nbytes >= bsize * 3) {\n\t\tdo {\n\t\t\t/* create ctrblks for parallel encrypt */\n\t\t\tctrblocks[0] = cpu_to_be64(ctrblk++);\n\t\t\tctrblocks[1] = cpu_to_be64(ctrblk++);\n\t\t\tctrblocks[2] = cpu_to_be64(ctrblk++);\n\n\t\t\tdes3_ede_enc_blk_3way(ctx, (u8 *)ctrblocks,\n\t\t\t\t\t      (u8 *)ctrblocks);\n\n\t\t\tdst[0] = src[0] ^ ctrblocks[0];\n\t\t\tdst[1] = src[1] ^ ctrblocks[1];\n\t\t\tdst[2] = src[2] ^ ctrblocks[2];\n\n\t\t\tsrc += 3;\n\t\t\tdst += 3;\n\t\t} while ((nbytes -= bsize * 3) >= bsize * 3);\n\n\t\tif (nbytes < bsize)\n\t\t\tgoto done;\n\t}\n\n\t/* Handle leftovers */\n\tdo {\n\t\tctrblocks[0] = cpu_to_be64(ctrblk++);\n\n\t\tdes3_ede_enc_blk(ctx, (u8 *)ctrblocks, (u8 *)ctrblocks);\n\n\t\tdst[0] = src[0] ^ ctrblocks[0];\n\n\t\tsrc += 1;\n\t\tdst += 1;\n\t} while ((nbytes -= bsize) >= bsize);\n\ndone:\n\t*(__be64 *)walk->iv = cpu_to_be64(ctrblk);\n\treturn nbytes;\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt_block(desc, &walk, DES3_EDE_BLOCK_SIZE);\n\n\twhile ((nbytes = walk.nbytes) >= DES3_EDE_BLOCK_SIZE) {\n\t\tnbytes = __ctr_crypt(desc, &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\n\tif (walk.nbytes) {\n\t\tctr_crypt_final(crypto_blkcipher_ctx(desc->tfm), &walk);\n\t\terr = blkcipher_walk_done(desc, &walk, 0);\n\t}\n\n\treturn err;\n}\n\nstatic int des3_ede_x86_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\t       unsigned int keylen)\n{\n\tstruct des3_ede_x86_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 i, j, tmp;\n\tint err;\n\n\t/* Generate encryption context using generic implementation. */\n\terr = __des3_ede_setkey(ctx->enc_expkey, &tfm->crt_flags, key, keylen);\n\tif (err < 0)\n\t\treturn err;\n\n\t/* Fix encryption context for this implementation and form decryption\n\t * context. */\n\tj = DES3_EDE_EXPKEY_WORDS - 2;\n\tfor (i = 0; i < DES3_EDE_EXPKEY_WORDS; i += 2, j -= 2) {\n\t\ttmp = ror32(ctx->enc_expkey[i + 1], 4);\n\t\tctx->enc_expkey[i + 1] = tmp;\n\n\t\tctx->dec_expkey[j + 0] = ctx->enc_expkey[i + 0];\n\t\tctx->dec_expkey[j + 1] = tmp;\n\t}\n\n\treturn 0;\n}\n\nstatic struct crypto_alg des3_ede_algs[4] = { {\n\t.cra_name\t\t= \"des3_ede\",\n\t.cra_driver_name\t= \"des3_ede-asm\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= DES3_EDE_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct des3_ede_x86_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.cipher = {\n\t\t\t.cia_min_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.cia_max_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.cia_setkey\t\t= des3_ede_x86_setkey,\n\t\t\t.cia_encrypt\t\t= des3_ede_x86_encrypt,\n\t\t\t.cia_decrypt\t\t= des3_ede_x86_decrypt,\n\t\t}\n\t}\n}, {\n\t.cra_name\t\t= \"ecb(des3_ede)\",\n\t.cra_driver_name\t= \"ecb-des3_ede-asm\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= DES3_EDE_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct des3_ede_x86_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.max_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.setkey\t\t= des3_ede_x86_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(des3_ede)\",\n\t.cra_driver_name\t= \"cbc-des3_ede-asm\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= DES3_EDE_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct des3_ede_x86_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.max_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.ivsize\t\t= DES3_EDE_BLOCK_SIZE,\n\t\t\t.setkey\t\t= des3_ede_x86_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(des3_ede)\",\n\t.cra_driver_name\t= \"ctr-des3_ede-asm\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct des3_ede_x86_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.max_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t\t.ivsize\t\t= DES3_EDE_BLOCK_SIZE,\n\t\t\t.setkey\t\t= des3_ede_x86_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n} };\n\nstatic bool is_blacklisted_cpu(void)\n{\n\tif (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL)\n\t\treturn false;\n\n\tif (boot_cpu_data.x86 == 0x0f) {\n\t\t/*\n\t\t * On Pentium 4, des3_ede-x86_64 is slower than generic C\n\t\t * implementation because use of 64bit rotates (which are really\n\t\t * slow on P4). Therefore blacklist P4s.\n\t\t */\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic int force;\nmodule_param(force, int, 0);\nMODULE_PARM_DESC(force, \"Force module load, ignore CPU blacklist\");\n\nstatic int __init des3_ede_x86_init(void)\n{\n\tif (!force && is_blacklisted_cpu()) {\n\t\tpr_info(\"des3_ede-x86_64: performance on this CPU would be suboptimal: disabling des3_ede-x86_64.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(des3_ede_algs, ARRAY_SIZE(des3_ede_algs));\n}\n\nstatic void __exit des3_ede_x86_fini(void)\n{\n\tcrypto_unregister_algs(des3_ede_algs, ARRAY_SIZE(des3_ede_algs));\n}\n\nmodule_init(des3_ede_x86_init);\nmodule_exit(des3_ede_x86_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Triple DES EDE Cipher Algorithm, asm optimized\");\nMODULE_ALIAS_CRYPTO(\"des3_ede\");\nMODULE_ALIAS_CRYPTO(\"des3_ede-asm\");\nMODULE_ALIAS_CRYPTO(\"des\");\nMODULE_ALIAS_CRYPTO(\"des-asm\");\nMODULE_AUTHOR(\"Jussi Kivilinna <jussi.kivilinna@iki.fi>\");\n", "/*\n * Accelerated GHASH implementation with Intel PCLMULQDQ-NI\n * instructions. This file contains glue code.\n *\n * Copyright (c) 2009 Intel Corp.\n *   Author: Huang Ying <ying.huang@intel.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License version 2 as published\n * by the Free Software Foundation.\n */\n\n#include <linux/err.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/crypto.h>\n#include <crypto/algapi.h>\n#include <crypto/cryptd.h>\n#include <crypto/gf128mul.h>\n#include <crypto/internal/hash.h>\n#include <asm/i387.h>\n#include <asm/cpu_device_id.h>\n\n#define GHASH_BLOCK_SIZE\t16\n#define GHASH_DIGEST_SIZE\t16\n\nvoid clmul_ghash_mul(char *dst, const u128 *shash);\n\nvoid clmul_ghash_update(char *dst, const char *src, unsigned int srclen,\n\t\t\tconst u128 *shash);\n\nstruct ghash_async_ctx {\n\tstruct cryptd_ahash *cryptd_tfm;\n};\n\nstruct ghash_ctx {\n\tu128 shash;\n};\n\nstruct ghash_desc_ctx {\n\tu8 buffer[GHASH_BLOCK_SIZE];\n\tu32 bytes;\n};\n\nstatic int ghash_init(struct shash_desc *desc)\n{\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\n\tmemset(dctx, 0, sizeof(*dctx));\n\n\treturn 0;\n}\n\nstatic int ghash_setkey(struct crypto_shash *tfm,\n\t\t\tconst u8 *key, unsigned int keylen)\n{\n\tstruct ghash_ctx *ctx = crypto_shash_ctx(tfm);\n\tbe128 *x = (be128 *)key;\n\tu64 a, b;\n\n\tif (keylen != GHASH_BLOCK_SIZE) {\n\t\tcrypto_shash_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);\n\t\treturn -EINVAL;\n\t}\n\n\t/* perform multiplication by 'x' in GF(2^128) */\n\ta = be64_to_cpu(x->a);\n\tb = be64_to_cpu(x->b);\n\n\tctx->shash.a = (b << 1) | (a >> 63);\n\tctx->shash.b = (a << 1) | (b >> 63);\n\n\tif (a >> 63)\n\t\tctx->shash.b ^= ((u64)0xc2) << 56;\n\n\treturn 0;\n}\n\nstatic int ghash_update(struct shash_desc *desc,\n\t\t\t const u8 *src, unsigned int srclen)\n{\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\tstruct ghash_ctx *ctx = crypto_shash_ctx(desc->tfm);\n\tu8 *dst = dctx->buffer;\n\n\tkernel_fpu_begin();\n\tif (dctx->bytes) {\n\t\tint n = min(srclen, dctx->bytes);\n\t\tu8 *pos = dst + (GHASH_BLOCK_SIZE - dctx->bytes);\n\n\t\tdctx->bytes -= n;\n\t\tsrclen -= n;\n\n\t\twhile (n--)\n\t\t\t*pos++ ^= *src++;\n\n\t\tif (!dctx->bytes)\n\t\t\tclmul_ghash_mul(dst, &ctx->shash);\n\t}\n\n\tclmul_ghash_update(dst, src, srclen, &ctx->shash);\n\tkernel_fpu_end();\n\n\tif (srclen & 0xf) {\n\t\tsrc += srclen - (srclen & 0xf);\n\t\tsrclen &= 0xf;\n\t\tdctx->bytes = GHASH_BLOCK_SIZE - srclen;\n\t\twhile (srclen--)\n\t\t\t*dst++ ^= *src++;\n\t}\n\n\treturn 0;\n}\n\nstatic void ghash_flush(struct ghash_ctx *ctx, struct ghash_desc_ctx *dctx)\n{\n\tu8 *dst = dctx->buffer;\n\n\tif (dctx->bytes) {\n\t\tu8 *tmp = dst + (GHASH_BLOCK_SIZE - dctx->bytes);\n\n\t\twhile (dctx->bytes--)\n\t\t\t*tmp++ ^= 0;\n\n\t\tkernel_fpu_begin();\n\t\tclmul_ghash_mul(dst, &ctx->shash);\n\t\tkernel_fpu_end();\n\t}\n\n\tdctx->bytes = 0;\n}\n\nstatic int ghash_final(struct shash_desc *desc, u8 *dst)\n{\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\tstruct ghash_ctx *ctx = crypto_shash_ctx(desc->tfm);\n\tu8 *buf = dctx->buffer;\n\n\tghash_flush(ctx, dctx);\n\tmemcpy(dst, buf, GHASH_BLOCK_SIZE);\n\n\treturn 0;\n}\n\nstatic struct shash_alg ghash_alg = {\n\t.digestsize\t= GHASH_DIGEST_SIZE,\n\t.init\t\t= ghash_init,\n\t.update\t\t= ghash_update,\n\t.final\t\t= ghash_final,\n\t.setkey\t\t= ghash_setkey,\n\t.descsize\t= sizeof(struct ghash_desc_ctx),\n\t.base\t\t= {\n\t\t.cra_name\t\t= \"__ghash\",\n\t\t.cra_driver_name\t= \"__ghash-pclmulqdqni\",\n\t\t.cra_priority\t\t= 0,\n\t\t.cra_flags\t\t= CRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t\t= GHASH_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t= sizeof(struct ghash_ctx),\n\t\t.cra_module\t\t= THIS_MODULE,\n\t},\n};\n\nstatic int ghash_async_init(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct ghash_async_ctx *ctx = crypto_ahash_ctx(tfm);\n\tstruct ahash_request *cryptd_req = ahash_request_ctx(req);\n\tstruct cryptd_ahash *cryptd_tfm = ctx->cryptd_tfm;\n\n\tif (!irq_fpu_usable()) {\n\t\tmemcpy(cryptd_req, req, sizeof(*req));\n\t\tahash_request_set_tfm(cryptd_req, &cryptd_tfm->base);\n\t\treturn crypto_ahash_init(cryptd_req);\n\t} else {\n\t\tstruct shash_desc *desc = cryptd_shash_desc(cryptd_req);\n\t\tstruct crypto_shash *child = cryptd_ahash_child(cryptd_tfm);\n\n\t\tdesc->tfm = child;\n\t\tdesc->flags = req->base.flags;\n\t\treturn crypto_shash_init(desc);\n\t}\n}\n\nstatic int ghash_async_update(struct ahash_request *req)\n{\n\tstruct ahash_request *cryptd_req = ahash_request_ctx(req);\n\n\tif (!irq_fpu_usable()) {\n\t\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\t\tstruct ghash_async_ctx *ctx = crypto_ahash_ctx(tfm);\n\t\tstruct cryptd_ahash *cryptd_tfm = ctx->cryptd_tfm;\n\n\t\tmemcpy(cryptd_req, req, sizeof(*req));\n\t\tahash_request_set_tfm(cryptd_req, &cryptd_tfm->base);\n\t\treturn crypto_ahash_update(cryptd_req);\n\t} else {\n\t\tstruct shash_desc *desc = cryptd_shash_desc(cryptd_req);\n\t\treturn shash_ahash_update(req, desc);\n\t}\n}\n\nstatic int ghash_async_final(struct ahash_request *req)\n{\n\tstruct ahash_request *cryptd_req = ahash_request_ctx(req);\n\n\tif (!irq_fpu_usable()) {\n\t\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\t\tstruct ghash_async_ctx *ctx = crypto_ahash_ctx(tfm);\n\t\tstruct cryptd_ahash *cryptd_tfm = ctx->cryptd_tfm;\n\n\t\tmemcpy(cryptd_req, req, sizeof(*req));\n\t\tahash_request_set_tfm(cryptd_req, &cryptd_tfm->base);\n\t\treturn crypto_ahash_final(cryptd_req);\n\t} else {\n\t\tstruct shash_desc *desc = cryptd_shash_desc(cryptd_req);\n\t\treturn crypto_shash_final(desc, req->result);\n\t}\n}\n\nstatic int ghash_async_digest(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct ghash_async_ctx *ctx = crypto_ahash_ctx(tfm);\n\tstruct ahash_request *cryptd_req = ahash_request_ctx(req);\n\tstruct cryptd_ahash *cryptd_tfm = ctx->cryptd_tfm;\n\n\tif (!irq_fpu_usable()) {\n\t\tmemcpy(cryptd_req, req, sizeof(*req));\n\t\tahash_request_set_tfm(cryptd_req, &cryptd_tfm->base);\n\t\treturn crypto_ahash_digest(cryptd_req);\n\t} else {\n\t\tstruct shash_desc *desc = cryptd_shash_desc(cryptd_req);\n\t\tstruct crypto_shash *child = cryptd_ahash_child(cryptd_tfm);\n\n\t\tdesc->tfm = child;\n\t\tdesc->flags = req->base.flags;\n\t\treturn shash_ahash_digest(req, desc);\n\t}\n}\n\nstatic int ghash_async_setkey(struct crypto_ahash *tfm, const u8 *key,\n\t\t\t      unsigned int keylen)\n{\n\tstruct ghash_async_ctx *ctx = crypto_ahash_ctx(tfm);\n\tstruct crypto_ahash *child = &ctx->cryptd_tfm->base;\n\tint err;\n\n\tcrypto_ahash_clear_flags(child, CRYPTO_TFM_REQ_MASK);\n\tcrypto_ahash_set_flags(child, crypto_ahash_get_flags(tfm)\n\t\t\t       & CRYPTO_TFM_REQ_MASK);\n\terr = crypto_ahash_setkey(child, key, keylen);\n\tcrypto_ahash_set_flags(tfm, crypto_ahash_get_flags(child)\n\t\t\t       & CRYPTO_TFM_RES_MASK);\n\n\treturn err;\n}\n\nstatic int ghash_async_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct cryptd_ahash *cryptd_tfm;\n\tstruct ghash_async_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcryptd_tfm = cryptd_alloc_ahash(\"__ghash-pclmulqdqni\", 0, 0);\n\tif (IS_ERR(cryptd_tfm))\n\t\treturn PTR_ERR(cryptd_tfm);\n\tctx->cryptd_tfm = cryptd_tfm;\n\tcrypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),\n\t\t\t\t sizeof(struct ahash_request) +\n\t\t\t\t crypto_ahash_reqsize(&cryptd_tfm->base));\n\n\treturn 0;\n}\n\nstatic void ghash_async_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct ghash_async_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcryptd_free_ahash(ctx->cryptd_tfm);\n}\n\nstatic struct ahash_alg ghash_async_alg = {\n\t.init\t\t= ghash_async_init,\n\t.update\t\t= ghash_async_update,\n\t.final\t\t= ghash_async_final,\n\t.setkey\t\t= ghash_async_setkey,\n\t.digest\t\t= ghash_async_digest,\n\t.halg = {\n\t\t.digestsize\t= GHASH_DIGEST_SIZE,\n\t\t.base = {\n\t\t\t.cra_name\t\t= \"ghash\",\n\t\t\t.cra_driver_name\t= \"ghash-clmulni\",\n\t\t\t.cra_priority\t\t= 400,\n\t\t\t.cra_flags\t\t= CRYPTO_ALG_TYPE_AHASH | CRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize\t\t= GHASH_BLOCK_SIZE,\n\t\t\t.cra_type\t\t= &crypto_ahash_type,\n\t\t\t.cra_module\t\t= THIS_MODULE,\n\t\t\t.cra_init\t\t= ghash_async_init_tfm,\n\t\t\t.cra_exit\t\t= ghash_async_exit_tfm,\n\t\t},\n\t},\n};\n\nstatic const struct x86_cpu_id pcmul_cpu_id[] = {\n\tX86_FEATURE_MATCH(X86_FEATURE_PCLMULQDQ), /* Pickle-Mickle-Duck */\n\t{}\n};\nMODULE_DEVICE_TABLE(x86cpu, pcmul_cpu_id);\n\nstatic int __init ghash_pclmulqdqni_mod_init(void)\n{\n\tint err;\n\n\tif (!x86_match_cpu(pcmul_cpu_id))\n\t\treturn -ENODEV;\n\n\terr = crypto_register_shash(&ghash_alg);\n\tif (err)\n\t\tgoto err_out;\n\terr = crypto_register_ahash(&ghash_async_alg);\n\tif (err)\n\t\tgoto err_shash;\n\n\treturn 0;\n\nerr_shash:\n\tcrypto_unregister_shash(&ghash_alg);\nerr_out:\n\treturn err;\n}\n\nstatic void __exit ghash_pclmulqdqni_mod_exit(void)\n{\n\tcrypto_unregister_ahash(&ghash_async_alg);\n\tcrypto_unregister_shash(&ghash_alg);\n}\n\nmodule_init(ghash_pclmulqdqni_mod_init);\nmodule_exit(ghash_pclmulqdqni_mod_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"GHASH Message Digest Algorithm, \"\n\t\t   \"acclerated by PCLMULQDQ-NI\");\nMODULE_ALIAS_CRYPTO(\"ghash\");\n", "/*\n * Glue code for optimized assembly version of  Salsa20.\n *\n * Copyright (c) 2007 Tan Swee Heng <thesweeheng@gmail.com>\n *\n * The assembly codes are public domain assembly codes written by Daniel. J.\n * Bernstein <djb@cr.yp.to>. The codes are modified to include indentation\n * and to remove extraneous comments and functions that are not needed.\n * - i586 version, renamed as salsa20-i586-asm_32.S\n *   available from <http://cr.yp.to/snuffle/salsa20/x86-pm/salsa20.s>\n * - x86-64 version, renamed as salsa20-x86_64-asm_64.S\n *   available from <http://cr.yp.to/snuffle/salsa20/amd64-3/salsa20.s>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#include <crypto/algapi.h>\n#include <linux/module.h>\n#include <linux/crypto.h>\n\n#define SALSA20_IV_SIZE        8U\n#define SALSA20_MIN_KEY_SIZE  16U\n#define SALSA20_MAX_KEY_SIZE  32U\n\nstruct salsa20_ctx\n{\n\tu32 input[16];\n};\n\nasmlinkage void salsa20_keysetup(struct salsa20_ctx *ctx, const u8 *k,\n\t\t\t\t u32 keysize, u32 ivsize);\nasmlinkage void salsa20_ivsetup(struct salsa20_ctx *ctx, const u8 *iv);\nasmlinkage void salsa20_encrypt_bytes(struct salsa20_ctx *ctx,\n\t\t\t\t      const u8 *src, u8 *dst, u32 bytes);\n\nstatic int setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t  unsigned int keysize)\n{\n\tstruct salsa20_ctx *ctx = crypto_tfm_ctx(tfm);\n\tsalsa20_keysetup(ctx, key, keysize*8, SALSA20_IV_SIZE*8);\n\treturn 0;\n}\n\nstatic int encrypt(struct blkcipher_desc *desc,\n\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t   unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\tstruct crypto_blkcipher *tfm = desc->tfm;\n\tstruct salsa20_ctx *ctx = crypto_blkcipher_ctx(tfm);\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt_block(desc, &walk, 64);\n\n\tsalsa20_ivsetup(ctx, walk.iv);\n\n\tif (likely(walk.nbytes == nbytes))\n\t{\n\t\tsalsa20_encrypt_bytes(ctx, walk.src.virt.addr,\n\t\t\t\t      walk.dst.virt.addr, nbytes);\n\t\treturn blkcipher_walk_done(desc, &walk, 0);\n\t}\n\n\twhile (walk.nbytes >= 64) {\n\t\tsalsa20_encrypt_bytes(ctx, walk.src.virt.addr,\n\t\t\t\t      walk.dst.virt.addr,\n\t\t\t\t      walk.nbytes - (walk.nbytes % 64));\n\t\terr = blkcipher_walk_done(desc, &walk, walk.nbytes % 64);\n\t}\n\n\tif (walk.nbytes) {\n\t\tsalsa20_encrypt_bytes(ctx, walk.src.virt.addr,\n\t\t\t\t      walk.dst.virt.addr, walk.nbytes);\n\t\terr = blkcipher_walk_done(desc, &walk, 0);\n\t}\n\n\treturn err;\n}\n\nstatic struct crypto_alg alg = {\n\t.cra_name           =   \"salsa20\",\n\t.cra_driver_name    =   \"salsa20-asm\",\n\t.cra_priority       =   200,\n\t.cra_flags          =   CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_type           =   &crypto_blkcipher_type,\n\t.cra_blocksize      =   1,\n\t.cra_ctxsize        =   sizeof(struct salsa20_ctx),\n\t.cra_alignmask      =\t3,\n\t.cra_module         =   THIS_MODULE,\n\t.cra_u              =   {\n\t\t.blkcipher = {\n\t\t\t.setkey         =   setkey,\n\t\t\t.encrypt        =   encrypt,\n\t\t\t.decrypt        =   encrypt,\n\t\t\t.min_keysize    =   SALSA20_MIN_KEY_SIZE,\n\t\t\t.max_keysize    =   SALSA20_MAX_KEY_SIZE,\n\t\t\t.ivsize         =   SALSA20_IV_SIZE,\n\t\t}\n\t}\n};\n\nstatic int __init init(void)\n{\n\treturn crypto_register_alg(&alg);\n}\n\nstatic void __exit fini(void)\n{\n\tcrypto_unregister_alg(&alg);\n}\n\nmodule_init(init);\nmodule_exit(fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION (\"Salsa20 stream cipher algorithm (optimized assembly version)\");\nMODULE_ALIAS_CRYPTO(\"salsa20\");\nMODULE_ALIAS_CRYPTO(\"salsa20-asm\");\n", "/*\n * Glue Code for x86_64/AVX2 assembler optimized version of Serpent\n *\n * Copyright \u00a9 2012-2013 Jussi Kivilinna <jussi.kivilinna@mbnet.fi>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n\n#include <linux/module.h>\n#include <linux/types.h>\n#include <linux/crypto.h>\n#include <linux/err.h>\n#include <crypto/ablk_helper.h>\n#include <crypto/algapi.h>\n#include <crypto/ctr.h>\n#include <crypto/lrw.h>\n#include <crypto/xts.h>\n#include <crypto/serpent.h>\n#include <asm/xcr.h>\n#include <asm/xsave.h>\n#include <asm/crypto/serpent-avx.h>\n#include <asm/crypto/glue_helper.h>\n\n#define SERPENT_AVX2_PARALLEL_BLOCKS 16\n\n/* 16-way AVX2 parallel cipher functions */\nasmlinkage void serpent_ecb_enc_16way(struct serpent_ctx *ctx, u8 *dst,\n\t\t\t\t      const u8 *src);\nasmlinkage void serpent_ecb_dec_16way(struct serpent_ctx *ctx, u8 *dst,\n\t\t\t\t      const u8 *src);\nasmlinkage void serpent_cbc_dec_16way(void *ctx, u128 *dst, const u128 *src);\n\nasmlinkage void serpent_ctr_16way(void *ctx, u128 *dst, const u128 *src,\n\t\t\t\t  le128 *iv);\nasmlinkage void serpent_xts_enc_16way(struct serpent_ctx *ctx, u8 *dst,\n\t\t\t\t      const u8 *src, le128 *iv);\nasmlinkage void serpent_xts_dec_16way(struct serpent_ctx *ctx, u8 *dst,\n\t\t\t\t      const u8 *src, le128 *iv);\n\nstatic const struct common_glue_ctx serpent_enc = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = 8,\n\n\t.funcs = { {\n\t\t.num_blocks = 16,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(serpent_ecb_enc_16way) }\n\t}, {\n\t\t.num_blocks = 8,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(serpent_ecb_enc_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(__serpent_encrypt) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_ctr = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = 8,\n\n\t.funcs = { {\n\t\t.num_blocks = 16,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(serpent_ctr_16way) }\n\t},  {\n\t\t.num_blocks = 8,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(serpent_ctr_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(__serpent_crypt_ctr) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_enc_xts = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = 8,\n\n\t.funcs = { {\n\t\t.num_blocks = 16,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(serpent_xts_enc_16way) }\n\t}, {\n\t\t.num_blocks = 8,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(serpent_xts_enc_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(serpent_xts_enc) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_dec = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = 8,\n\n\t.funcs = { {\n\t\t.num_blocks = 16,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(serpent_ecb_dec_16way) }\n\t}, {\n\t\t.num_blocks = 8,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(serpent_ecb_dec_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(__serpent_decrypt) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_dec_cbc = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = 8,\n\n\t.funcs = { {\n\t\t.num_blocks = 16,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(serpent_cbc_dec_16way) }\n\t}, {\n\t\t.num_blocks = 8,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(serpent_cbc_dec_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(__serpent_decrypt) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_dec_xts = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = 8,\n\n\t.funcs = { {\n\t\t.num_blocks = 16,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(serpent_xts_dec_16way) }\n\t}, {\n\t\t.num_blocks = 8,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(serpent_xts_dec_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(serpent_xts_dec) }\n\t} }\n};\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&serpent_enc, desc, dst, src, nbytes);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&serpent_dec, desc, dst, src, nbytes);\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_encrypt_128bit(GLUE_FUNC_CAST(__serpent_encrypt), desc,\n\t\t\t\t       dst, src, nbytes);\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_decrypt_128bit(&serpent_dec_cbc, desc, dst, src,\n\t\t\t\t       nbytes);\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ctr_crypt_128bit(&serpent_ctr, desc, dst, src, nbytes);\n}\n\nstatic inline bool serpent_fpu_begin(bool fpu_enabled, unsigned int nbytes)\n{\n\t/* since reusing AVX functions, starts using FPU at 8 parallel blocks */\n\treturn glue_fpu_begin(SERPENT_BLOCK_SIZE, 8, NULL, fpu_enabled, nbytes);\n}\n\nstatic inline void serpent_fpu_end(bool fpu_enabled)\n{\n\tglue_fpu_end(fpu_enabled);\n}\n\nstruct crypt_priv {\n\tstruct serpent_ctx *ctx;\n\tbool fpu_enabled;\n};\n\nstatic void encrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = SERPENT_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = serpent_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes >= SERPENT_AVX2_PARALLEL_BLOCKS * bsize) {\n\t\tserpent_ecb_enc_16way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * SERPENT_AVX2_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * SERPENT_AVX2_PARALLEL_BLOCKS;\n\t}\n\n\twhile (nbytes >= SERPENT_PARALLEL_BLOCKS * bsize) {\n\t\tserpent_ecb_enc_8way_avx(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * SERPENT_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * SERPENT_PARALLEL_BLOCKS;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\t__serpent_encrypt(ctx->ctx, srcdst, srcdst);\n}\n\nstatic void decrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = SERPENT_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = serpent_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes >= SERPENT_AVX2_PARALLEL_BLOCKS * bsize) {\n\t\tserpent_ecb_dec_16way(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * SERPENT_AVX2_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * SERPENT_AVX2_PARALLEL_BLOCKS;\n\t}\n\n\twhile (nbytes >= SERPENT_PARALLEL_BLOCKS * bsize) {\n\t\tserpent_ecb_dec_8way_avx(ctx->ctx, srcdst, srcdst);\n\t\tsrcdst += bsize * SERPENT_PARALLEL_BLOCKS;\n\t\tnbytes -= bsize * SERPENT_PARALLEL_BLOCKS;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\t__serpent_decrypt(ctx->ctx, srcdst, srcdst);\n}\n\nstatic int lrw_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[SERPENT_AVX2_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->serpent_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tserpent_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int lrw_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[SERPENT_AVX2_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->serpent_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tserpent_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&serpent_enc_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(__serpent_encrypt),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&serpent_dec_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(__serpent_encrypt),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic struct crypto_alg srp_algs[10] = { {\n\t.cra_name\t\t= \"__ecb-serpent-avx2\",\n\t.cra_driver_name\t= \"__driver-ecb-serpent-avx2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(srp_algs[0].cra_list),\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= serpent_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__cbc-serpent-avx2\",\n\t.cra_driver_name\t= \"__driver-cbc-serpent-avx2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(srp_algs[1].cra_list),\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= serpent_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__ctr-serpent-avx2\",\n\t.cra_driver_name\t= \"__driver-ctr-serpent-avx2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(srp_algs[2].cra_list),\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= serpent_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__lrw-serpent-avx2\",\n\t.cra_driver_name\t= \"__driver-lrw-serpent-avx2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_lrw_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(srp_algs[3].cra_list),\n\t.cra_exit\t\t= lrw_serpent_exit_tfm,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= lrw_serpent_setkey,\n\t\t\t.encrypt\t= lrw_encrypt,\n\t\t\t.decrypt\t= lrw_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__xts-serpent-avx2\",\n\t.cra_driver_name\t= \"__driver-xts-serpent-avx2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_xts_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(srp_algs[4].cra_list),\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= xts_serpent_setkey,\n\t\t\t.encrypt\t= xts_encrypt,\n\t\t\t.decrypt\t= xts_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ecb(serpent)\",\n\t.cra_driver_name\t= \"ecb-serpent-avx2\",\n\t.cra_priority\t\t= 600,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(srp_algs[5].cra_list),\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(serpent)\",\n\t.cra_driver_name\t= \"cbc-serpent-avx2\",\n\t.cra_priority\t\t= 600,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(srp_algs[6].cra_list),\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= __ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(serpent)\",\n\t.cra_driver_name\t= \"ctr-serpent-avx2\",\n\t.cra_priority\t\t= 600,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(srp_algs[7].cra_list),\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_encrypt,\n\t\t\t.geniv\t\t= \"chainiv\",\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"lrw(serpent)\",\n\t.cra_driver_name\t= \"lrw-serpent-avx2\",\n\t.cra_priority\t\t= 600,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(srp_algs[8].cra_list),\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"xts(serpent)\",\n\t.cra_driver_name\t= \"xts-serpent-avx2\",\n\t.cra_priority\t\t= 600,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(srp_algs[9].cra_list),\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n} };\n\nstatic int __init init(void)\n{\n\tu64 xcr0;\n\n\tif (!cpu_has_avx2 || !cpu_has_osxsave) {\n\t\tpr_info(\"AVX2 instructions are not detected.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\txcr0 = xgetbv(XCR_XFEATURE_ENABLED_MASK);\n\tif ((xcr0 & (XSTATE_SSE | XSTATE_YMM)) != (XSTATE_SSE | XSTATE_YMM)) {\n\t\tpr_info(\"AVX detected but unusable.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(srp_algs, ARRAY_SIZE(srp_algs));\n}\n\nstatic void __exit fini(void)\n{\n\tcrypto_unregister_algs(srp_algs, ARRAY_SIZE(srp_algs));\n}\n\nmodule_init(init);\nmodule_exit(fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Serpent Cipher Algorithm, AVX2 optimized\");\nMODULE_ALIAS_CRYPTO(\"serpent\");\nMODULE_ALIAS_CRYPTO(\"serpent-asm\");\n", "/*\n * Glue Code for AVX assembler versions of Serpent Cipher\n *\n * Copyright (C) 2012 Johannes Goetzfried\n *     <Johannes.Goetzfried@informatik.stud.uni-erlangen.de>\n *\n * Copyright \u00a9 2011-2013 Jussi Kivilinna <jussi.kivilinna@iki.fi>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307\n * USA\n *\n */\n\n#include <linux/module.h>\n#include <linux/hardirq.h>\n#include <linux/types.h>\n#include <linux/crypto.h>\n#include <linux/err.h>\n#include <crypto/ablk_helper.h>\n#include <crypto/algapi.h>\n#include <crypto/serpent.h>\n#include <crypto/cryptd.h>\n#include <crypto/b128ops.h>\n#include <crypto/ctr.h>\n#include <crypto/lrw.h>\n#include <crypto/xts.h>\n#include <asm/xcr.h>\n#include <asm/xsave.h>\n#include <asm/crypto/serpent-avx.h>\n#include <asm/crypto/glue_helper.h>\n\n/* 8-way parallel cipher functions */\nasmlinkage void serpent_ecb_enc_8way_avx(struct serpent_ctx *ctx, u8 *dst,\n\t\t\t\t\t const u8 *src);\nEXPORT_SYMBOL_GPL(serpent_ecb_enc_8way_avx);\n\nasmlinkage void serpent_ecb_dec_8way_avx(struct serpent_ctx *ctx, u8 *dst,\n\t\t\t\t\t const u8 *src);\nEXPORT_SYMBOL_GPL(serpent_ecb_dec_8way_avx);\n\nasmlinkage void serpent_cbc_dec_8way_avx(struct serpent_ctx *ctx, u8 *dst,\n\t\t\t\t\t const u8 *src);\nEXPORT_SYMBOL_GPL(serpent_cbc_dec_8way_avx);\n\nasmlinkage void serpent_ctr_8way_avx(struct serpent_ctx *ctx, u8 *dst,\n\t\t\t\t     const u8 *src, le128 *iv);\nEXPORT_SYMBOL_GPL(serpent_ctr_8way_avx);\n\nasmlinkage void serpent_xts_enc_8way_avx(struct serpent_ctx *ctx, u8 *dst,\n\t\t\t\t\t const u8 *src, le128 *iv);\nEXPORT_SYMBOL_GPL(serpent_xts_enc_8way_avx);\n\nasmlinkage void serpent_xts_dec_8way_avx(struct serpent_ctx *ctx, u8 *dst,\n\t\t\t\t\t const u8 *src, le128 *iv);\nEXPORT_SYMBOL_GPL(serpent_xts_dec_8way_avx);\n\nvoid __serpent_crypt_ctr(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tbe128 ctrblk;\n\n\tle128_to_be128(&ctrblk, iv);\n\tle128_inc(iv);\n\n\t__serpent_encrypt(ctx, (u8 *)&ctrblk, (u8 *)&ctrblk);\n\tu128_xor(dst, src, (u128 *)&ctrblk);\n}\nEXPORT_SYMBOL_GPL(__serpent_crypt_ctr);\n\nvoid serpent_xts_enc(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tglue_xts_crypt_128bit_one(ctx, dst, src, iv,\n\t\t\t\t  GLUE_FUNC_CAST(__serpent_encrypt));\n}\nEXPORT_SYMBOL_GPL(serpent_xts_enc);\n\nvoid serpent_xts_dec(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tglue_xts_crypt_128bit_one(ctx, dst, src, iv,\n\t\t\t\t  GLUE_FUNC_CAST(__serpent_decrypt));\n}\nEXPORT_SYMBOL_GPL(serpent_xts_dec);\n\n\nstatic const struct common_glue_ctx serpent_enc = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = SERPENT_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = SERPENT_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(serpent_ecb_enc_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(__serpent_encrypt) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_ctr = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = SERPENT_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = SERPENT_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(serpent_ctr_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(__serpent_crypt_ctr) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_enc_xts = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = SERPENT_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = SERPENT_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(serpent_xts_enc_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(serpent_xts_enc) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_dec = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = SERPENT_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = SERPENT_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(serpent_ecb_dec_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(__serpent_decrypt) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_dec_cbc = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = SERPENT_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = SERPENT_PARALLEL_BLOCKS,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(serpent_cbc_dec_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(__serpent_decrypt) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_dec_xts = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = SERPENT_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = SERPENT_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(serpent_xts_dec_8way_avx) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(serpent_xts_dec) }\n\t} }\n};\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&serpent_enc, desc, dst, src, nbytes);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&serpent_dec, desc, dst, src, nbytes);\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_encrypt_128bit(GLUE_FUNC_CAST(__serpent_encrypt), desc,\n\t\t\t\t     dst, src, nbytes);\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_decrypt_128bit(&serpent_dec_cbc, desc, dst, src,\n\t\t\t\t       nbytes);\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ctr_crypt_128bit(&serpent_ctr, desc, dst, src, nbytes);\n}\n\nstatic inline bool serpent_fpu_begin(bool fpu_enabled, unsigned int nbytes)\n{\n\treturn glue_fpu_begin(SERPENT_BLOCK_SIZE, SERPENT_PARALLEL_BLOCKS,\n\t\t\t      NULL, fpu_enabled, nbytes);\n}\n\nstatic inline void serpent_fpu_end(bool fpu_enabled)\n{\n\tglue_fpu_end(fpu_enabled);\n}\n\nstruct crypt_priv {\n\tstruct serpent_ctx *ctx;\n\tbool fpu_enabled;\n};\n\nstatic void encrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = SERPENT_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = serpent_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes == bsize * SERPENT_PARALLEL_BLOCKS) {\n\t\tserpent_ecb_enc_8way_avx(ctx->ctx, srcdst, srcdst);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\t__serpent_encrypt(ctx->ctx, srcdst, srcdst);\n}\n\nstatic void decrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = SERPENT_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = serpent_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes == bsize * SERPENT_PARALLEL_BLOCKS) {\n\t\tserpent_ecb_dec_8way_avx(ctx->ctx, srcdst, srcdst);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\t__serpent_decrypt(ctx->ctx, srcdst, srcdst);\n}\n\nint lrw_serpent_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t       unsigned int keylen)\n{\n\tstruct serpent_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\tint err;\n\n\terr = __serpent_setkey(&ctx->serpent_ctx, key, keylen -\n\t\t\t\t\t\t\tSERPENT_BLOCK_SIZE);\n\tif (err)\n\t\treturn err;\n\n\treturn lrw_init_table(&ctx->lrw_table, key + keylen -\n\t\t\t\t\t\tSERPENT_BLOCK_SIZE);\n}\nEXPORT_SYMBOL_GPL(lrw_serpent_setkey);\n\nstatic int lrw_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[SERPENT_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->serpent_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tserpent_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int lrw_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[SERPENT_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->serpent_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tserpent_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nvoid lrw_serpent_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct serpent_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tlrw_free_table(&ctx->lrw_table);\n}\nEXPORT_SYMBOL_GPL(lrw_serpent_exit_tfm);\n\nint xts_serpent_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t       unsigned int keylen)\n{\n\tstruct serpent_xts_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tint err;\n\n\t/* key consists of keys of equal size concatenated, therefore\n\t * the length must be even\n\t */\n\tif (keylen % 2) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\t/* first half of xts-key is for crypt */\n\terr = __serpent_setkey(&ctx->crypt_ctx, key, keylen / 2);\n\tif (err)\n\t\treturn err;\n\n\t/* second half of xts-key is for tweak */\n\treturn __serpent_setkey(&ctx->tweak_ctx, key + keylen / 2, keylen / 2);\n}\nEXPORT_SYMBOL_GPL(xts_serpent_setkey);\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&serpent_enc_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(__serpent_encrypt),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&serpent_dec_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(__serpent_encrypt),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic struct crypto_alg serpent_algs[10] = { {\n\t.cra_name\t\t= \"__ecb-serpent-avx\",\n\t.cra_driver_name\t= \"__driver-ecb-serpent-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= serpent_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__cbc-serpent-avx\",\n\t.cra_driver_name\t= \"__driver-cbc-serpent-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= serpent_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__ctr-serpent-avx\",\n\t.cra_driver_name\t= \"__driver-ctr-serpent-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= serpent_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__lrw-serpent-avx\",\n\t.cra_driver_name\t= \"__driver-lrw-serpent-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_lrw_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_exit\t\t= lrw_serpent_exit_tfm,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= lrw_serpent_setkey,\n\t\t\t.encrypt\t= lrw_encrypt,\n\t\t\t.decrypt\t= lrw_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__xts-serpent-avx\",\n\t.cra_driver_name\t= \"__driver-xts-serpent-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_xts_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= xts_serpent_setkey,\n\t\t\t.encrypt\t= xts_encrypt,\n\t\t\t.decrypt\t= xts_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ecb(serpent)\",\n\t.cra_driver_name\t= \"ecb-serpent-avx\",\n\t.cra_priority\t\t= 500,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(serpent)\",\n\t.cra_driver_name\t= \"cbc-serpent-avx\",\n\t.cra_priority\t\t= 500,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= __ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(serpent)\",\n\t.cra_driver_name\t= \"ctr-serpent-avx\",\n\t.cra_priority\t\t= 500,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_encrypt,\n\t\t\t.geniv\t\t= \"chainiv\",\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"lrw(serpent)\",\n\t.cra_driver_name\t= \"lrw-serpent-avx\",\n\t.cra_priority\t\t= 500,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"xts(serpent)\",\n\t.cra_driver_name\t= \"xts-serpent-avx\",\n\t.cra_priority\t\t= 500,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n} };\n\nstatic int __init serpent_init(void)\n{\n\tu64 xcr0;\n\n\tif (!cpu_has_avx || !cpu_has_osxsave) {\n\t\tprintk(KERN_INFO \"AVX instructions are not detected.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\txcr0 = xgetbv(XCR_XFEATURE_ENABLED_MASK);\n\tif ((xcr0 & (XSTATE_SSE | XSTATE_YMM)) != (XSTATE_SSE | XSTATE_YMM)) {\n\t\tprintk(KERN_INFO \"AVX detected but unusable.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(serpent_algs, ARRAY_SIZE(serpent_algs));\n}\n\nstatic void __exit serpent_exit(void)\n{\n\tcrypto_unregister_algs(serpent_algs, ARRAY_SIZE(serpent_algs));\n}\n\nmodule_init(serpent_init);\nmodule_exit(serpent_exit);\n\nMODULE_DESCRIPTION(\"Serpent Cipher Algorithm, AVX optimized\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_CRYPTO(\"serpent\");\n", "/*\n * Glue Code for SSE2 assembler versions of Serpent Cipher\n *\n * Copyright (c) 2011 Jussi Kivilinna <jussi.kivilinna@mbnet.fi>\n *\n * Glue code based on aesni-intel_glue.c by:\n *  Copyright (C) 2008, Intel Corp.\n *    Author: Huang Ying <ying.huang@intel.com>\n *\n * CBC & ECB parts based on code (crypto/cbc.c,ecb.c) by:\n *   Copyright (c) 2006 Herbert Xu <herbert@gondor.apana.org.au>\n * CTR part based on code (crypto/ctr.c) by:\n *   (C) Copyright IBM Corp. 2007 - Joy Latten <latten@us.ibm.com>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307\n * USA\n *\n */\n\n#include <linux/module.h>\n#include <linux/hardirq.h>\n#include <linux/types.h>\n#include <linux/crypto.h>\n#include <linux/err.h>\n#include <crypto/ablk_helper.h>\n#include <crypto/algapi.h>\n#include <crypto/serpent.h>\n#include <crypto/cryptd.h>\n#include <crypto/b128ops.h>\n#include <crypto/ctr.h>\n#include <crypto/lrw.h>\n#include <crypto/xts.h>\n#include <asm/crypto/serpent-sse2.h>\n#include <asm/crypto/glue_helper.h>\n\nstatic void serpent_decrypt_cbc_xway(void *ctx, u128 *dst, const u128 *src)\n{\n\tu128 ivs[SERPENT_PARALLEL_BLOCKS - 1];\n\tunsigned int j;\n\n\tfor (j = 0; j < SERPENT_PARALLEL_BLOCKS - 1; j++)\n\t\tivs[j] = src[j];\n\n\tserpent_dec_blk_xway(ctx, (u8 *)dst, (u8 *)src);\n\n\tfor (j = 0; j < SERPENT_PARALLEL_BLOCKS - 1; j++)\n\t\tu128_xor(dst + (j + 1), dst + (j + 1), ivs + j);\n}\n\nstatic void serpent_crypt_ctr(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tbe128 ctrblk;\n\n\tle128_to_be128(&ctrblk, iv);\n\tle128_inc(iv);\n\n\t__serpent_encrypt(ctx, (u8 *)&ctrblk, (u8 *)&ctrblk);\n\tu128_xor(dst, src, (u128 *)&ctrblk);\n}\n\nstatic void serpent_crypt_ctr_xway(void *ctx, u128 *dst, const u128 *src,\n\t\t\t\t   le128 *iv)\n{\n\tbe128 ctrblks[SERPENT_PARALLEL_BLOCKS];\n\tunsigned int i;\n\n\tfor (i = 0; i < SERPENT_PARALLEL_BLOCKS; i++) {\n\t\tif (dst != src)\n\t\t\tdst[i] = src[i];\n\n\t\tle128_to_be128(&ctrblks[i], iv);\n\t\tle128_inc(iv);\n\t}\n\n\tserpent_enc_blk_xway_xor(ctx, (u8 *)dst, (u8 *)ctrblks);\n}\n\nstatic const struct common_glue_ctx serpent_enc = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = SERPENT_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = SERPENT_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(serpent_enc_blk_xway) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(__serpent_encrypt) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_ctr = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = SERPENT_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = SERPENT_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(serpent_crypt_ctr_xway) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(serpent_crypt_ctr) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_dec = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = SERPENT_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = SERPENT_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(serpent_dec_blk_xway) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(__serpent_decrypt) }\n\t} }\n};\n\nstatic const struct common_glue_ctx serpent_dec_cbc = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = SERPENT_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = SERPENT_PARALLEL_BLOCKS,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(serpent_decrypt_cbc_xway) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(__serpent_decrypt) }\n\t} }\n};\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&serpent_enc, desc, dst, src, nbytes);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&serpent_dec, desc, dst, src, nbytes);\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_encrypt_128bit(GLUE_FUNC_CAST(__serpent_encrypt), desc,\n\t\t\t\t     dst, src, nbytes);\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_decrypt_128bit(&serpent_dec_cbc, desc, dst, src,\n\t\t\t\t       nbytes);\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ctr_crypt_128bit(&serpent_ctr, desc, dst, src, nbytes);\n}\n\nstatic inline bool serpent_fpu_begin(bool fpu_enabled, unsigned int nbytes)\n{\n\treturn glue_fpu_begin(SERPENT_BLOCK_SIZE, SERPENT_PARALLEL_BLOCKS,\n\t\t\t      NULL, fpu_enabled, nbytes);\n}\n\nstatic inline void serpent_fpu_end(bool fpu_enabled)\n{\n\tglue_fpu_end(fpu_enabled);\n}\n\nstruct crypt_priv {\n\tstruct serpent_ctx *ctx;\n\tbool fpu_enabled;\n};\n\nstatic void encrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = SERPENT_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = serpent_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes == bsize * SERPENT_PARALLEL_BLOCKS) {\n\t\tserpent_enc_blk_xway(ctx->ctx, srcdst, srcdst);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\t__serpent_encrypt(ctx->ctx, srcdst, srcdst);\n}\n\nstatic void decrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = SERPENT_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = serpent_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes == bsize * SERPENT_PARALLEL_BLOCKS) {\n\t\tserpent_dec_blk_xway(ctx->ctx, srcdst, srcdst);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\t__serpent_decrypt(ctx->ctx, srcdst, srcdst);\n}\n\nstruct serpent_lrw_ctx {\n\tstruct lrw_table_ctx lrw_table;\n\tstruct serpent_ctx serpent_ctx;\n};\n\nstatic int lrw_serpent_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\t      unsigned int keylen)\n{\n\tstruct serpent_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\tint err;\n\n\terr = __serpent_setkey(&ctx->serpent_ctx, key, keylen -\n\t\t\t\t\t\t\tSERPENT_BLOCK_SIZE);\n\tif (err)\n\t\treturn err;\n\n\treturn lrw_init_table(&ctx->lrw_table, key + keylen -\n\t\t\t\t\t\tSERPENT_BLOCK_SIZE);\n}\n\nstatic int lrw_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[SERPENT_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->serpent_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tserpent_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int lrw_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[SERPENT_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->serpent_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\tserpent_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic void lrw_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct serpent_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tlrw_free_table(&ctx->lrw_table);\n}\n\nstruct serpent_xts_ctx {\n\tstruct serpent_ctx tweak_ctx;\n\tstruct serpent_ctx crypt_ctx;\n};\n\nstatic int xts_serpent_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\t      unsigned int keylen)\n{\n\tstruct serpent_xts_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tint err;\n\n\t/* key consists of keys of equal size concatenated, therefore\n\t * the length must be even\n\t */\n\tif (keylen % 2) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\t/* first half of xts-key is for crypt */\n\terr = __serpent_setkey(&ctx->crypt_ctx, key, keylen / 2);\n\tif (err)\n\t\treturn err;\n\n\t/* second half of xts-key is for tweak */\n\treturn __serpent_setkey(&ctx->tweak_ctx, key + keylen / 2, keylen / 2);\n}\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[SERPENT_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->crypt_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct xts_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.tweak_ctx = &ctx->tweak_ctx,\n\t\t.tweak_fn = XTS_TWEAK_CAST(__serpent_encrypt),\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = xts_crypt(desc, dst, src, nbytes, &req);\n\tserpent_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct serpent_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[SERPENT_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->crypt_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct xts_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.tweak_ctx = &ctx->tweak_ctx,\n\t\t.tweak_fn = XTS_TWEAK_CAST(__serpent_encrypt),\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = xts_crypt(desc, dst, src, nbytes, &req);\n\tserpent_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic struct crypto_alg serpent_algs[10] = { {\n\t.cra_name\t\t= \"__ecb-serpent-sse2\",\n\t.cra_driver_name\t= \"__driver-ecb-serpent-sse2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= serpent_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__cbc-serpent-sse2\",\n\t.cra_driver_name\t= \"__driver-cbc-serpent-sse2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= serpent_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__ctr-serpent-sse2\",\n\t.cra_driver_name\t= \"__driver-ctr-serpent-sse2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= serpent_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__lrw-serpent-sse2\",\n\t.cra_driver_name\t= \"__driver-lrw-serpent-sse2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_lrw_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_exit\t\t= lrw_exit_tfm,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= lrw_serpent_setkey,\n\t\t\t.encrypt\t= lrw_encrypt,\n\t\t\t.decrypt\t= lrw_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__xts-serpent-sse2\",\n\t.cra_driver_name\t= \"__driver-xts-serpent-sse2\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct serpent_xts_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= xts_serpent_setkey,\n\t\t\t.encrypt\t= xts_encrypt,\n\t\t\t.decrypt\t= xts_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ecb(serpent)\",\n\t.cra_driver_name\t= \"ecb-serpent-sse2\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(serpent)\",\n\t.cra_driver_name\t= \"cbc-serpent-sse2\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= __ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(serpent)\",\n\t.cra_driver_name\t= \"ctr-serpent-sse2\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_encrypt,\n\t\t\t.geniv\t\t= \"chainiv\",\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"lrw(serpent)\",\n\t.cra_driver_name\t= \"lrw-serpent-sse2\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE +\n\t\t\t\t\t  SERPENT_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"xts(serpent)\",\n\t.cra_driver_name\t= \"xts-serpent-sse2\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= SERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= SERPENT_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= SERPENT_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= SERPENT_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n} };\n\nstatic int __init serpent_sse2_init(void)\n{\n\tif (!cpu_has_xmm2) {\n\t\tprintk(KERN_INFO \"SSE2 instructions are not detected.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(serpent_algs, ARRAY_SIZE(serpent_algs));\n}\n\nstatic void __exit serpent_sse2_exit(void)\n{\n\tcrypto_unregister_algs(serpent_algs, ARRAY_SIZE(serpent_algs));\n}\n\nmodule_init(serpent_sse2_init);\nmodule_exit(serpent_sse2_exit);\n\nMODULE_DESCRIPTION(\"Serpent Cipher Algorithm, SSE2 optimized\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_CRYPTO(\"serpent\");\n", "/*\n * Cryptographic API.\n *\n * Glue code for the SHA1 Secure Hash Algorithm assembler implementation using\n * Supplemental SSE3 instructions.\n *\n * This file is based on sha1_generic.c\n *\n * Copyright (c) Alan Smithee.\n * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n * Copyright (c) Jean-Francois Dive <jef@linuxbe.org>\n * Copyright (c) Mathias Krause <minipli@googlemail.com>\n * Copyright (c) Chandramouli Narayanan <mouli@linux.intel.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n#include <asm/byteorder.h>\n#include <asm/i387.h>\n#include <asm/xcr.h>\n#include <asm/xsave.h>\n\n\nasmlinkage void sha1_transform_ssse3(u32 *digest, const char *data,\n\t\t\t\t     unsigned int rounds);\n#ifdef CONFIG_AS_AVX\nasmlinkage void sha1_transform_avx(u32 *digest, const char *data,\n\t\t\t\t   unsigned int rounds);\n#endif\n#ifdef CONFIG_AS_AVX2\n#define SHA1_AVX2_BLOCK_OPTSIZE\t4\t/* optimal 4*64 bytes of SHA1 blocks */\n\nasmlinkage void sha1_transform_avx2(u32 *digest, const char *data,\n\t\t\t\tunsigned int rounds);\n#endif\n\nstatic asmlinkage void (*sha1_transform_asm)(u32 *, const char *, unsigned int);\n\n\nstatic int sha1_ssse3_init(struct shash_desc *desc)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\t*sctx = (struct sha1_state){\n\t\t.state = { SHA1_H0, SHA1_H1, SHA1_H2, SHA1_H3, SHA1_H4 },\n\t};\n\n\treturn 0;\n}\n\nstatic int __sha1_ssse3_update(struct shash_desc *desc, const u8 *data,\n\t\t\t       unsigned int len, unsigned int partial)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int done = 0;\n\n\tsctx->count += len;\n\n\tif (partial) {\n\t\tdone = SHA1_BLOCK_SIZE - partial;\n\t\tmemcpy(sctx->buffer + partial, data, done);\n\t\tsha1_transform_asm(sctx->state, sctx->buffer, 1);\n\t}\n\n\tif (len - done >= SHA1_BLOCK_SIZE) {\n\t\tconst unsigned int rounds = (len - done) / SHA1_BLOCK_SIZE;\n\n\t\tsha1_transform_asm(sctx->state, data + done, rounds);\n\t\tdone += rounds * SHA1_BLOCK_SIZE;\n\t}\n\n\tmemcpy(sctx->buffer, data + done, len - done);\n\n\treturn 0;\n}\n\nstatic int sha1_ssse3_update(struct shash_desc *desc, const u8 *data,\n\t\t\t     unsigned int len)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial = sctx->count % SHA1_BLOCK_SIZE;\n\tint res;\n\n\t/* Handle the fast case right here */\n\tif (partial + len < SHA1_BLOCK_SIZE) {\n\t\tsctx->count += len;\n\t\tmemcpy(sctx->buffer + partial, data, len);\n\n\t\treturn 0;\n\t}\n\n\tif (!irq_fpu_usable()) {\n\t\tres = crypto_sha1_update(desc, data, len);\n\t} else {\n\t\tkernel_fpu_begin();\n\t\tres = __sha1_ssse3_update(desc, data, len, partial);\n\t\tkernel_fpu_end();\n\t}\n\n\treturn res;\n}\n\n\n/* Add padding and return the message digest. */\nstatic int sha1_ssse3_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int i, index, padlen;\n\t__be32 *dst = (__be32 *)out;\n\t__be64 bits;\n\tstatic const u8 padding[SHA1_BLOCK_SIZE] = { 0x80, };\n\n\tbits = cpu_to_be64(sctx->count << 3);\n\n\t/* Pad out to 56 mod 64 and append length */\n\tindex = sctx->count % SHA1_BLOCK_SIZE;\n\tpadlen = (index < 56) ? (56 - index) : ((SHA1_BLOCK_SIZE+56) - index);\n\tif (!irq_fpu_usable()) {\n\t\tcrypto_sha1_update(desc, padding, padlen);\n\t\tcrypto_sha1_update(desc, (const u8 *)&bits, sizeof(bits));\n\t} else {\n\t\tkernel_fpu_begin();\n\t\t/* We need to fill a whole block for __sha1_ssse3_update() */\n\t\tif (padlen <= 56) {\n\t\t\tsctx->count += padlen;\n\t\t\tmemcpy(sctx->buffer + index, padding, padlen);\n\t\t} else {\n\t\t\t__sha1_ssse3_update(desc, padding, padlen, index);\n\t\t}\n\t\t__sha1_ssse3_update(desc, (const u8 *)&bits, sizeof(bits), 56);\n\t\tkernel_fpu_end();\n\t}\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 5; i++)\n\t\tdst[i] = cpu_to_be32(sctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha1_ssse3_export(struct shash_desc *desc, void *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha1_ssse3_import(struct shash_desc *desc, const void *in)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, sizeof(*sctx));\n\n\treturn 0;\n}\n\n#ifdef CONFIG_AS_AVX2\nstatic void sha1_apply_transform_avx2(u32 *digest, const char *data,\n\t\t\t\tunsigned int rounds)\n{\n\t/* Select the optimal transform based on data block size */\n\tif (rounds >= SHA1_AVX2_BLOCK_OPTSIZE)\n\t\tsha1_transform_avx2(digest, data, rounds);\n\telse\n\t\tsha1_transform_avx(digest, data, rounds);\n}\n#endif\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tSHA1_DIGEST_SIZE,\n\t.init\t\t=\tsha1_ssse3_init,\n\t.update\t\t=\tsha1_ssse3_update,\n\t.final\t\t=\tsha1_ssse3_final,\n\t.export\t\t=\tsha1_ssse3_export,\n\t.import\t\t=\tsha1_ssse3_import,\n\t.descsize\t=\tsizeof(struct sha1_state),\n\t.statesize\t=\tsizeof(struct sha1_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha1\",\n\t\t.cra_driver_name=\t\"sha1-ssse3\",\n\t\t.cra_priority\t=\t150,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA1_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\n#ifdef CONFIG_AS_AVX\nstatic bool __init avx_usable(void)\n{\n\tu64 xcr0;\n\n\tif (!cpu_has_avx || !cpu_has_osxsave)\n\t\treturn false;\n\n\txcr0 = xgetbv(XCR_XFEATURE_ENABLED_MASK);\n\tif ((xcr0 & (XSTATE_SSE | XSTATE_YMM)) != (XSTATE_SSE | XSTATE_YMM)) {\n\t\tpr_info(\"AVX detected but unusable.\\n\");\n\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n#ifdef CONFIG_AS_AVX2\nstatic bool __init avx2_usable(void)\n{\n\tif (avx_usable() && cpu_has_avx2 && boot_cpu_has(X86_FEATURE_BMI1) &&\n\t    boot_cpu_has(X86_FEATURE_BMI2))\n\t\treturn true;\n\n\treturn false;\n}\n#endif\n#endif\n\nstatic int __init sha1_ssse3_mod_init(void)\n{\n\tchar *algo_name;\n\n\t/* test for SSSE3 first */\n\tif (cpu_has_ssse3) {\n\t\tsha1_transform_asm = sha1_transform_ssse3;\n\t\talgo_name = \"SSSE3\";\n\t}\n\n#ifdef CONFIG_AS_AVX\n\t/* allow AVX to override SSSE3, it's a little faster */\n\tif (avx_usable()) {\n\t\tsha1_transform_asm = sha1_transform_avx;\n\t\talgo_name = \"AVX\";\n#ifdef CONFIG_AS_AVX2\n\t\t/* allow AVX2 to override AVX, it's a little faster */\n\t\tif (avx2_usable()) {\n\t\t\tsha1_transform_asm = sha1_apply_transform_avx2;\n\t\t\talgo_name = \"AVX2\";\n\t\t}\n#endif\n\t}\n#endif\n\n\tif (sha1_transform_asm) {\n\t\tpr_info(\"Using %s optimized SHA-1 implementation\\n\", algo_name);\n\t\treturn crypto_register_shash(&alg);\n\t}\n\tpr_info(\"Neither AVX nor AVX2 nor SSSE3 is available/usable.\\n\");\n\n\treturn -ENODEV;\n}\n\nstatic void __exit sha1_ssse3_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(sha1_ssse3_mod_init);\nmodule_exit(sha1_ssse3_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA1 Secure Hash Algorithm, Supplemental SSE3 accelerated\");\n\nMODULE_ALIAS_CRYPTO(\"sha1\");\n", "/*\n * Cryptographic API.\n *\n * Glue code for the SHA256 Secure Hash Algorithm assembler\n * implementation using supplemental SSE3 / AVX / AVX2 instructions.\n *\n * This file is based on sha256_generic.c\n *\n * Copyright (C) 2013 Intel Corporation.\n *\n * Author:\n *     Tim Chen <tim.c.chen@linux.intel.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS\n * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n * SOFTWARE.\n */\n\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n#include <asm/byteorder.h>\n#include <asm/i387.h>\n#include <asm/xcr.h>\n#include <asm/xsave.h>\n#include <linux/string.h>\n\nasmlinkage void sha256_transform_ssse3(const char *data, u32 *digest,\n\t\t\t\t     u64 rounds);\n#ifdef CONFIG_AS_AVX\nasmlinkage void sha256_transform_avx(const char *data, u32 *digest,\n\t\t\t\t     u64 rounds);\n#endif\n#ifdef CONFIG_AS_AVX2\nasmlinkage void sha256_transform_rorx(const char *data, u32 *digest,\n\t\t\t\t     u64 rounds);\n#endif\n\nstatic asmlinkage void (*sha256_transform_asm)(const char *, u32 *, u64);\n\n\nstatic int sha256_ssse3_init(struct shash_desc *desc)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\n\tsctx->state[0] = SHA256_H0;\n\tsctx->state[1] = SHA256_H1;\n\tsctx->state[2] = SHA256_H2;\n\tsctx->state[3] = SHA256_H3;\n\tsctx->state[4] = SHA256_H4;\n\tsctx->state[5] = SHA256_H5;\n\tsctx->state[6] = SHA256_H6;\n\tsctx->state[7] = SHA256_H7;\n\tsctx->count = 0;\n\n\treturn 0;\n}\n\nstatic int __sha256_ssse3_update(struct shash_desc *desc, const u8 *data,\n\t\t\t       unsigned int len, unsigned int partial)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\tunsigned int done = 0;\n\n\tsctx->count += len;\n\n\tif (partial) {\n\t\tdone = SHA256_BLOCK_SIZE - partial;\n\t\tmemcpy(sctx->buf + partial, data, done);\n\t\tsha256_transform_asm(sctx->buf, sctx->state, 1);\n\t}\n\n\tif (len - done >= SHA256_BLOCK_SIZE) {\n\t\tconst unsigned int rounds = (len - done) / SHA256_BLOCK_SIZE;\n\n\t\tsha256_transform_asm(data + done, sctx->state, (u64) rounds);\n\n\t\tdone += rounds * SHA256_BLOCK_SIZE;\n\t}\n\n\tmemcpy(sctx->buf, data + done, len - done);\n\n\treturn 0;\n}\n\nstatic int sha256_ssse3_update(struct shash_desc *desc, const u8 *data,\n\t\t\t     unsigned int len)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial = sctx->count % SHA256_BLOCK_SIZE;\n\tint res;\n\n\t/* Handle the fast case right here */\n\tif (partial + len < SHA256_BLOCK_SIZE) {\n\t\tsctx->count += len;\n\t\tmemcpy(sctx->buf + partial, data, len);\n\n\t\treturn 0;\n\t}\n\n\tif (!irq_fpu_usable()) {\n\t\tres = crypto_sha256_update(desc, data, len);\n\t} else {\n\t\tkernel_fpu_begin();\n\t\tres = __sha256_ssse3_update(desc, data, len, partial);\n\t\tkernel_fpu_end();\n\t}\n\n\treturn res;\n}\n\n\n/* Add padding and return the message digest. */\nstatic int sha256_ssse3_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\tunsigned int i, index, padlen;\n\t__be32 *dst = (__be32 *)out;\n\t__be64 bits;\n\tstatic const u8 padding[SHA256_BLOCK_SIZE] = { 0x80, };\n\n\tbits = cpu_to_be64(sctx->count << 3);\n\n\t/* Pad out to 56 mod 64 and append length */\n\tindex = sctx->count % SHA256_BLOCK_SIZE;\n\tpadlen = (index < 56) ? (56 - index) : ((SHA256_BLOCK_SIZE+56)-index);\n\n\tif (!irq_fpu_usable()) {\n\t\tcrypto_sha256_update(desc, padding, padlen);\n\t\tcrypto_sha256_update(desc, (const u8 *)&bits, sizeof(bits));\n\t} else {\n\t\tkernel_fpu_begin();\n\t\t/* We need to fill a whole block for __sha256_ssse3_update() */\n\t\tif (padlen <= 56) {\n\t\t\tsctx->count += padlen;\n\t\t\tmemcpy(sctx->buf + index, padding, padlen);\n\t\t} else {\n\t\t\t__sha256_ssse3_update(desc, padding, padlen, index);\n\t\t}\n\t\t__sha256_ssse3_update(desc, (const u8 *)&bits,\n\t\t\t\t\tsizeof(bits), 56);\n\t\tkernel_fpu_end();\n\t}\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 8; i++)\n\t\tdst[i] = cpu_to_be32(sctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha256_ssse3_export(struct shash_desc *desc, void *out)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha256_ssse3_import(struct shash_desc *desc, const void *in)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha224_ssse3_init(struct shash_desc *desc)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\n\tsctx->state[0] = SHA224_H0;\n\tsctx->state[1] = SHA224_H1;\n\tsctx->state[2] = SHA224_H2;\n\tsctx->state[3] = SHA224_H3;\n\tsctx->state[4] = SHA224_H4;\n\tsctx->state[5] = SHA224_H5;\n\tsctx->state[6] = SHA224_H6;\n\tsctx->state[7] = SHA224_H7;\n\tsctx->count = 0;\n\n\treturn 0;\n}\n\nstatic int sha224_ssse3_final(struct shash_desc *desc, u8 *hash)\n{\n\tu8 D[SHA256_DIGEST_SIZE];\n\n\tsha256_ssse3_final(desc, D);\n\n\tmemcpy(hash, D, SHA224_DIGEST_SIZE);\n\tmemset(D, 0, SHA256_DIGEST_SIZE);\n\n\treturn 0;\n}\n\nstatic struct shash_alg algs[] = { {\n\t.digestsize\t=\tSHA256_DIGEST_SIZE,\n\t.init\t\t=\tsha256_ssse3_init,\n\t.update\t\t=\tsha256_ssse3_update,\n\t.final\t\t=\tsha256_ssse3_final,\n\t.export\t\t=\tsha256_ssse3_export,\n\t.import\t\t=\tsha256_ssse3_import,\n\t.descsize\t=\tsizeof(struct sha256_state),\n\t.statesize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha256\",\n\t\t.cra_driver_name =\t\"sha256-ssse3\",\n\t\t.cra_priority\t=\t150,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA256_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n}, {\n\t.digestsize\t=\tSHA224_DIGEST_SIZE,\n\t.init\t\t=\tsha224_ssse3_init,\n\t.update\t\t=\tsha256_ssse3_update,\n\t.final\t\t=\tsha224_ssse3_final,\n\t.export\t\t=\tsha256_ssse3_export,\n\t.import\t\t=\tsha256_ssse3_import,\n\t.descsize\t=\tsizeof(struct sha256_state),\n\t.statesize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha224\",\n\t\t.cra_driver_name =\t\"sha224-ssse3\",\n\t\t.cra_priority\t=\t150,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA224_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n} };\n\n#ifdef CONFIG_AS_AVX\nstatic bool __init avx_usable(void)\n{\n\tu64 xcr0;\n\n\tif (!cpu_has_avx || !cpu_has_osxsave)\n\t\treturn false;\n\n\txcr0 = xgetbv(XCR_XFEATURE_ENABLED_MASK);\n\tif ((xcr0 & (XSTATE_SSE | XSTATE_YMM)) != (XSTATE_SSE | XSTATE_YMM)) {\n\t\tpr_info(\"AVX detected but unusable.\\n\");\n\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n#endif\n\nstatic int __init sha256_ssse3_mod_init(void)\n{\n\t/* test for SSSE3 first */\n\tif (cpu_has_ssse3)\n\t\tsha256_transform_asm = sha256_transform_ssse3;\n\n#ifdef CONFIG_AS_AVX\n\t/* allow AVX to override SSSE3, it's a little faster */\n\tif (avx_usable()) {\n#ifdef CONFIG_AS_AVX2\n\t\tif (boot_cpu_has(X86_FEATURE_AVX2) && boot_cpu_has(X86_FEATURE_BMI2))\n\t\t\tsha256_transform_asm = sha256_transform_rorx;\n\t\telse\n#endif\n\t\t\tsha256_transform_asm = sha256_transform_avx;\n\t}\n#endif\n\n\tif (sha256_transform_asm) {\n#ifdef CONFIG_AS_AVX\n\t\tif (sha256_transform_asm == sha256_transform_avx)\n\t\t\tpr_info(\"Using AVX optimized SHA-256 implementation\\n\");\n#ifdef CONFIG_AS_AVX2\n\t\telse if (sha256_transform_asm == sha256_transform_rorx)\n\t\t\tpr_info(\"Using AVX2 optimized SHA-256 implementation\\n\");\n#endif\n\t\telse\n#endif\n\t\t\tpr_info(\"Using SSSE3 optimized SHA-256 implementation\\n\");\n\t\treturn crypto_register_shashes(algs, ARRAY_SIZE(algs));\n\t}\n\tpr_info(\"Neither AVX nor SSSE3 is available/usable.\\n\");\n\n\treturn -ENODEV;\n}\n\nstatic void __exit sha256_ssse3_mod_fini(void)\n{\n\tcrypto_unregister_shashes(algs, ARRAY_SIZE(algs));\n}\n\nmodule_init(sha256_ssse3_mod_init);\nmodule_exit(sha256_ssse3_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA256 Secure Hash Algorithm, Supplemental SSE3 accelerated\");\n\nMODULE_ALIAS_CRYPTO(\"sha256\");\nMODULE_ALIAS_CRYPTO(\"sha224\");\n", "/*\n * Cryptographic API.\n *\n * Glue code for the SHA512 Secure Hash Algorithm assembler\n * implementation using supplemental SSE3 / AVX / AVX2 instructions.\n *\n * This file is based on sha512_generic.c\n *\n * Copyright (C) 2013 Intel Corporation\n * Author: Tim Chen <tim.c.chen@linux.intel.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS\n * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n * SOFTWARE.\n *\n */\n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n#include <asm/byteorder.h>\n#include <asm/i387.h>\n#include <asm/xcr.h>\n#include <asm/xsave.h>\n\n#include <linux/string.h>\n\nasmlinkage void sha512_transform_ssse3(const char *data, u64 *digest,\n\t\t\t\t     u64 rounds);\n#ifdef CONFIG_AS_AVX\nasmlinkage void sha512_transform_avx(const char *data, u64 *digest,\n\t\t\t\t     u64 rounds);\n#endif\n#ifdef CONFIG_AS_AVX2\nasmlinkage void sha512_transform_rorx(const char *data, u64 *digest,\n\t\t\t\t     u64 rounds);\n#endif\n\nstatic asmlinkage void (*sha512_transform_asm)(const char *, u64 *, u64);\n\n\nstatic int sha512_ssse3_init(struct shash_desc *desc)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\n\tsctx->state[0] = SHA512_H0;\n\tsctx->state[1] = SHA512_H1;\n\tsctx->state[2] = SHA512_H2;\n\tsctx->state[3] = SHA512_H3;\n\tsctx->state[4] = SHA512_H4;\n\tsctx->state[5] = SHA512_H5;\n\tsctx->state[6] = SHA512_H6;\n\tsctx->state[7] = SHA512_H7;\n\tsctx->count[0] = sctx->count[1] = 0;\n\n\treturn 0;\n}\n\nstatic int __sha512_ssse3_update(struct shash_desc *desc, const u8 *data,\n\t\t\t       unsigned int len, unsigned int partial)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tunsigned int done = 0;\n\n\tsctx->count[0] += len;\n\tif (sctx->count[0] < len)\n\t\tsctx->count[1]++;\n\n\tif (partial) {\n\t\tdone = SHA512_BLOCK_SIZE - partial;\n\t\tmemcpy(sctx->buf + partial, data, done);\n\t\tsha512_transform_asm(sctx->buf, sctx->state, 1);\n\t}\n\n\tif (len - done >= SHA512_BLOCK_SIZE) {\n\t\tconst unsigned int rounds = (len - done) / SHA512_BLOCK_SIZE;\n\n\t\tsha512_transform_asm(data + done, sctx->state, (u64) rounds);\n\n\t\tdone += rounds * SHA512_BLOCK_SIZE;\n\t}\n\n\tmemcpy(sctx->buf, data + done, len - done);\n\n\treturn 0;\n}\n\nstatic int sha512_ssse3_update(struct shash_desc *desc, const u8 *data,\n\t\t\t     unsigned int len)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial = sctx->count[0] % SHA512_BLOCK_SIZE;\n\tint res;\n\n\t/* Handle the fast case right here */\n\tif (partial + len < SHA512_BLOCK_SIZE) {\n\t\tsctx->count[0] += len;\n\t\tif (sctx->count[0] < len)\n\t\t\tsctx->count[1]++;\n\t\tmemcpy(sctx->buf + partial, data, len);\n\n\t\treturn 0;\n\t}\n\n\tif (!irq_fpu_usable()) {\n\t\tres = crypto_sha512_update(desc, data, len);\n\t} else {\n\t\tkernel_fpu_begin();\n\t\tres = __sha512_ssse3_update(desc, data, len, partial);\n\t\tkernel_fpu_end();\n\t}\n\n\treturn res;\n}\n\n\n/* Add padding and return the message digest. */\nstatic int sha512_ssse3_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tunsigned int i, index, padlen;\n\t__be64 *dst = (__be64 *)out;\n\t__be64 bits[2];\n\tstatic const u8 padding[SHA512_BLOCK_SIZE] = { 0x80, };\n\n\t/* save number of bits */\n\tbits[1] = cpu_to_be64(sctx->count[0] << 3);\n\tbits[0] = cpu_to_be64(sctx->count[1] << 3 | sctx->count[0] >> 61);\n\n\t/* Pad out to 112 mod 128 and append length */\n\tindex = sctx->count[0] & 0x7f;\n\tpadlen = (index < 112) ? (112 - index) : ((128+112) - index);\n\n\tif (!irq_fpu_usable()) {\n\t\tcrypto_sha512_update(desc, padding, padlen);\n\t\tcrypto_sha512_update(desc, (const u8 *)&bits, sizeof(bits));\n\t} else {\n\t\tkernel_fpu_begin();\n\t\t/* We need to fill a whole block for __sha512_ssse3_update() */\n\t\tif (padlen <= 112) {\n\t\t\tsctx->count[0] += padlen;\n\t\t\tif (sctx->count[0] < padlen)\n\t\t\t\tsctx->count[1]++;\n\t\t\tmemcpy(sctx->buf + index, padding, padlen);\n\t\t} else {\n\t\t\t__sha512_ssse3_update(desc, padding, padlen, index);\n\t\t}\n\t\t__sha512_ssse3_update(desc, (const u8 *)&bits,\n\t\t\t\t\tsizeof(bits), 112);\n\t\tkernel_fpu_end();\n\t}\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 8; i++)\n\t\tdst[i] = cpu_to_be64(sctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha512_ssse3_export(struct shash_desc *desc, void *out)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha512_ssse3_import(struct shash_desc *desc, const void *in)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha384_ssse3_init(struct shash_desc *desc)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\n\tsctx->state[0] = SHA384_H0;\n\tsctx->state[1] = SHA384_H1;\n\tsctx->state[2] = SHA384_H2;\n\tsctx->state[3] = SHA384_H3;\n\tsctx->state[4] = SHA384_H4;\n\tsctx->state[5] = SHA384_H5;\n\tsctx->state[6] = SHA384_H6;\n\tsctx->state[7] = SHA384_H7;\n\n\tsctx->count[0] = sctx->count[1] = 0;\n\n\treturn 0;\n}\n\nstatic int sha384_ssse3_final(struct shash_desc *desc, u8 *hash)\n{\n\tu8 D[SHA512_DIGEST_SIZE];\n\n\tsha512_ssse3_final(desc, D);\n\n\tmemcpy(hash, D, SHA384_DIGEST_SIZE);\n\tmemset(D, 0, SHA512_DIGEST_SIZE);\n\n\treturn 0;\n}\n\nstatic struct shash_alg algs[] = { {\n\t.digestsize\t=\tSHA512_DIGEST_SIZE,\n\t.init\t\t=\tsha512_ssse3_init,\n\t.update\t\t=\tsha512_ssse3_update,\n\t.final\t\t=\tsha512_ssse3_final,\n\t.export\t\t=\tsha512_ssse3_export,\n\t.import\t\t=\tsha512_ssse3_import,\n\t.descsize\t=\tsizeof(struct sha512_state),\n\t.statesize\t=\tsizeof(struct sha512_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha512\",\n\t\t.cra_driver_name =\t\"sha512-ssse3\",\n\t\t.cra_priority\t=\t150,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA512_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n},  {\n\t.digestsize\t=\tSHA384_DIGEST_SIZE,\n\t.init\t\t=\tsha384_ssse3_init,\n\t.update\t\t=\tsha512_ssse3_update,\n\t.final\t\t=\tsha384_ssse3_final,\n\t.export\t\t=\tsha512_ssse3_export,\n\t.import\t\t=\tsha512_ssse3_import,\n\t.descsize\t=\tsizeof(struct sha512_state),\n\t.statesize\t=\tsizeof(struct sha512_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha384\",\n\t\t.cra_driver_name =\t\"sha384-ssse3\",\n\t\t.cra_priority\t=\t150,\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA384_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n} };\n\n#ifdef CONFIG_AS_AVX\nstatic bool __init avx_usable(void)\n{\n\tu64 xcr0;\n\n\tif (!cpu_has_avx || !cpu_has_osxsave)\n\t\treturn false;\n\n\txcr0 = xgetbv(XCR_XFEATURE_ENABLED_MASK);\n\tif ((xcr0 & (XSTATE_SSE | XSTATE_YMM)) != (XSTATE_SSE | XSTATE_YMM)) {\n\t\tpr_info(\"AVX detected but unusable.\\n\");\n\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n#endif\n\nstatic int __init sha512_ssse3_mod_init(void)\n{\n\t/* test for SSSE3 first */\n\tif (cpu_has_ssse3)\n\t\tsha512_transform_asm = sha512_transform_ssse3;\n\n#ifdef CONFIG_AS_AVX\n\t/* allow AVX to override SSSE3, it's a little faster */\n\tif (avx_usable()) {\n#ifdef CONFIG_AS_AVX2\n\t\tif (boot_cpu_has(X86_FEATURE_AVX2))\n\t\t\tsha512_transform_asm = sha512_transform_rorx;\n\t\telse\n#endif\n\t\t\tsha512_transform_asm = sha512_transform_avx;\n\t}\n#endif\n\n\tif (sha512_transform_asm) {\n#ifdef CONFIG_AS_AVX\n\t\tif (sha512_transform_asm == sha512_transform_avx)\n\t\t\tpr_info(\"Using AVX optimized SHA-512 implementation\\n\");\n#ifdef CONFIG_AS_AVX2\n\t\telse if (sha512_transform_asm == sha512_transform_rorx)\n\t\t\tpr_info(\"Using AVX2 optimized SHA-512 implementation\\n\");\n#endif\n\t\telse\n#endif\n\t\t\tpr_info(\"Using SSSE3 optimized SHA-512 implementation\\n\");\n\t\treturn crypto_register_shashes(algs, ARRAY_SIZE(algs));\n\t}\n\tpr_info(\"Neither AVX nor SSSE3 is available/usable.\\n\");\n\n\treturn -ENODEV;\n}\n\nstatic void __exit sha512_ssse3_mod_fini(void)\n{\n\tcrypto_unregister_shashes(algs, ARRAY_SIZE(algs));\n}\n\nmodule_init(sha512_ssse3_mod_init);\nmodule_exit(sha512_ssse3_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA512 Secure Hash Algorithm, Supplemental SSE3 accelerated\");\n\nMODULE_ALIAS_CRYPTO(\"sha512\");\nMODULE_ALIAS_CRYPTO(\"sha384\");\n", "/*\n * Glue Code for AVX assembler version of Twofish Cipher\n *\n * Copyright (C) 2012 Johannes Goetzfried\n *     <Johannes.Goetzfried@informatik.stud.uni-erlangen.de>\n *\n * Copyright \u00a9 2013 Jussi Kivilinna <jussi.kivilinna@iki.fi>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307\n * USA\n *\n */\n\n#include <linux/module.h>\n#include <linux/hardirq.h>\n#include <linux/types.h>\n#include <linux/crypto.h>\n#include <linux/err.h>\n#include <crypto/ablk_helper.h>\n#include <crypto/algapi.h>\n#include <crypto/twofish.h>\n#include <crypto/cryptd.h>\n#include <crypto/b128ops.h>\n#include <crypto/ctr.h>\n#include <crypto/lrw.h>\n#include <crypto/xts.h>\n#include <asm/i387.h>\n#include <asm/xcr.h>\n#include <asm/xsave.h>\n#include <asm/crypto/twofish.h>\n#include <asm/crypto/glue_helper.h>\n#include <crypto/scatterwalk.h>\n#include <linux/workqueue.h>\n#include <linux/spinlock.h>\n\n#define TWOFISH_PARALLEL_BLOCKS 8\n\n/* 8-way parallel cipher functions */\nasmlinkage void twofish_ecb_enc_8way(struct twofish_ctx *ctx, u8 *dst,\n\t\t\t\t     const u8 *src);\nasmlinkage void twofish_ecb_dec_8way(struct twofish_ctx *ctx, u8 *dst,\n\t\t\t\t     const u8 *src);\n\nasmlinkage void twofish_cbc_dec_8way(struct twofish_ctx *ctx, u8 *dst,\n\t\t\t\t     const u8 *src);\nasmlinkage void twofish_ctr_8way(struct twofish_ctx *ctx, u8 *dst,\n\t\t\t\t const u8 *src, le128 *iv);\n\nasmlinkage void twofish_xts_enc_8way(struct twofish_ctx *ctx, u8 *dst,\n\t\t\t\t     const u8 *src, le128 *iv);\nasmlinkage void twofish_xts_dec_8way(struct twofish_ctx *ctx, u8 *dst,\n\t\t\t\t     const u8 *src, le128 *iv);\n\nstatic inline void twofish_enc_blk_3way(struct twofish_ctx *ctx, u8 *dst,\n\t\t\t\t\tconst u8 *src)\n{\n\t__twofish_enc_blk_3way(ctx, dst, src, false);\n}\n\nstatic void twofish_xts_enc(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tglue_xts_crypt_128bit_one(ctx, dst, src, iv,\n\t\t\t\t  GLUE_FUNC_CAST(twofish_enc_blk));\n}\n\nstatic void twofish_xts_dec(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tglue_xts_crypt_128bit_one(ctx, dst, src, iv,\n\t\t\t\t  GLUE_FUNC_CAST(twofish_dec_blk));\n}\n\n\nstatic const struct common_glue_ctx twofish_enc = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = TWOFISH_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = TWOFISH_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_ecb_enc_8way) }\n\t}, {\n\t\t.num_blocks = 3,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_enc_blk_3way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_enc_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx twofish_ctr = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = TWOFISH_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = TWOFISH_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(twofish_ctr_8way) }\n\t}, {\n\t\t.num_blocks = 3,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(twofish_enc_blk_ctr_3way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ctr = GLUE_CTR_FUNC_CAST(twofish_enc_blk_ctr) }\n\t} }\n};\n\nstatic const struct common_glue_ctx twofish_enc_xts = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = TWOFISH_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = TWOFISH_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(twofish_xts_enc_8way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(twofish_xts_enc) }\n\t} }\n};\n\nstatic const struct common_glue_ctx twofish_dec = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = TWOFISH_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = TWOFISH_PARALLEL_BLOCKS,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_ecb_dec_8way) }\n\t}, {\n\t\t.num_blocks = 3,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_dec_blk_3way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_dec_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx twofish_dec_cbc = {\n\t.num_funcs = 3,\n\t.fpu_blocks_limit = TWOFISH_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = TWOFISH_PARALLEL_BLOCKS,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(twofish_cbc_dec_8way) }\n\t}, {\n\t\t.num_blocks = 3,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(twofish_dec_blk_cbc_3way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(twofish_dec_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx twofish_dec_xts = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = TWOFISH_PARALLEL_BLOCKS,\n\n\t.funcs = { {\n\t\t.num_blocks = TWOFISH_PARALLEL_BLOCKS,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(twofish_xts_dec_8way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .xts = GLUE_XTS_FUNC_CAST(twofish_xts_dec) }\n\t} }\n};\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&twofish_enc, desc, dst, src, nbytes);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&twofish_dec, desc, dst, src, nbytes);\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_encrypt_128bit(GLUE_FUNC_CAST(twofish_enc_blk), desc,\n\t\t\t\t       dst, src, nbytes);\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_decrypt_128bit(&twofish_dec_cbc, desc, dst, src,\n\t\t\t\t       nbytes);\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ctr_crypt_128bit(&twofish_ctr, desc, dst, src, nbytes);\n}\n\nstatic inline bool twofish_fpu_begin(bool fpu_enabled, unsigned int nbytes)\n{\n\treturn glue_fpu_begin(TF_BLOCK_SIZE, TWOFISH_PARALLEL_BLOCKS, NULL,\n\t\t\t      fpu_enabled, nbytes);\n}\n\nstatic inline void twofish_fpu_end(bool fpu_enabled)\n{\n\tglue_fpu_end(fpu_enabled);\n}\n\nstruct crypt_priv {\n\tstruct twofish_ctx *ctx;\n\tbool fpu_enabled;\n};\n\nstatic void encrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = TF_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = twofish_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes == bsize * TWOFISH_PARALLEL_BLOCKS) {\n\t\ttwofish_ecb_enc_8way(ctx->ctx, srcdst, srcdst);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < nbytes / (bsize * 3); i++, srcdst += bsize * 3)\n\t\ttwofish_enc_blk_3way(ctx->ctx, srcdst, srcdst);\n\n\tnbytes %= bsize * 3;\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\ttwofish_enc_blk(ctx->ctx, srcdst, srcdst);\n}\n\nstatic void decrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = TF_BLOCK_SIZE;\n\tstruct crypt_priv *ctx = priv;\n\tint i;\n\n\tctx->fpu_enabled = twofish_fpu_begin(ctx->fpu_enabled, nbytes);\n\n\tif (nbytes == bsize * TWOFISH_PARALLEL_BLOCKS) {\n\t\ttwofish_ecb_dec_8way(ctx->ctx, srcdst, srcdst);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < nbytes / (bsize * 3); i++, srcdst += bsize * 3)\n\t\ttwofish_dec_blk_3way(ctx->ctx, srcdst, srcdst);\n\n\tnbytes %= bsize * 3;\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\ttwofish_dec_blk(ctx->ctx, srcdst, srcdst);\n}\n\nstatic int lrw_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct twofish_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[TWOFISH_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->twofish_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\ttwofish_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int lrw_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct twofish_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[TWOFISH_PARALLEL_BLOCKS];\n\tstruct crypt_priv crypt_ctx = {\n\t\t.ctx = &ctx->twofish_ctx,\n\t\t.fpu_enabled = false,\n\t};\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &crypt_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\tint ret;\n\n\tdesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\tret = lrw_crypt(desc, dst, src, nbytes, &req);\n\ttwofish_fpu_end(crypt_ctx.fpu_enabled);\n\n\treturn ret;\n}\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct twofish_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&twofish_enc_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(twofish_enc_blk),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct twofish_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\n\treturn glue_xts_crypt_128bit(&twofish_dec_xts, desc, dst, src, nbytes,\n\t\t\t\t     XTS_TWEAK_CAST(twofish_enc_blk),\n\t\t\t\t     &ctx->tweak_ctx, &ctx->crypt_ctx);\n}\n\nstatic struct crypto_alg twofish_algs[10] = { {\n\t.cra_name\t\t= \"__ecb-twofish-avx\",\n\t.cra_driver_name\t= \"__driver-ecb-twofish-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct twofish_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= twofish_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__cbc-twofish-avx\",\n\t.cra_driver_name\t= \"__driver-cbc-twofish-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct twofish_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= twofish_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__ctr-twofish-avx\",\n\t.cra_driver_name\t= \"__driver-ctr-twofish-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct twofish_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= TF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= twofish_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__lrw-twofish-avx\",\n\t.cra_driver_name\t= \"__driver-lrw-twofish-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct twofish_lrw_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_exit\t\t= lrw_twofish_exit_tfm,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE +\n\t\t\t\t\t  TF_BLOCK_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE +\n\t\t\t\t\t  TF_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= TF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= lrw_twofish_setkey,\n\t\t\t.encrypt\t= lrw_encrypt,\n\t\t\t.decrypt\t= lrw_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"__xts-twofish-avx\",\n\t.cra_driver_name\t= \"__driver-xts-twofish-avx\",\n\t.cra_priority\t\t= 0,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct twofish_xts_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= TF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= xts_twofish_setkey,\n\t\t\t.encrypt\t= xts_encrypt,\n\t\t\t.decrypt\t= xts_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ecb(twofish)\",\n\t.cra_driver_name\t= \"ecb-twofish-avx\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(twofish)\",\n\t.cra_driver_name\t= \"cbc-twofish-avx\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= TF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= __ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(twofish)\",\n\t.cra_driver_name\t= \"ctr-twofish-avx\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= TF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_encrypt,\n\t\t\t.geniv\t\t= \"chainiv\",\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"lrw(twofish)\",\n\t.cra_driver_name\t= \"lrw-twofish-avx\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE +\n\t\t\t\t\t  TF_BLOCK_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE +\n\t\t\t\t\t  TF_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= TF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"xts(twofish)\",\n\t.cra_driver_name\t= \"xts-twofish-avx\",\n\t.cra_priority\t\t= 400,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct async_helper_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_ablkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= ablk_init,\n\t.cra_exit\t\t= ablk_exit,\n\t.cra_u = {\n\t\t.ablkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= TF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= ablk_set_key,\n\t\t\t.encrypt\t= ablk_encrypt,\n\t\t\t.decrypt\t= ablk_decrypt,\n\t\t},\n\t},\n} };\n\nstatic int __init twofish_init(void)\n{\n\tu64 xcr0;\n\n\tif (!cpu_has_avx || !cpu_has_osxsave) {\n\t\tprintk(KERN_INFO \"AVX instructions are not detected.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\txcr0 = xgetbv(XCR_XFEATURE_ENABLED_MASK);\n\tif ((xcr0 & (XSTATE_SSE | XSTATE_YMM)) != (XSTATE_SSE | XSTATE_YMM)) {\n\t\tprintk(KERN_INFO \"AVX detected but unusable.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(twofish_algs, ARRAY_SIZE(twofish_algs));\n}\n\nstatic void __exit twofish_exit(void)\n{\n\tcrypto_unregister_algs(twofish_algs, ARRAY_SIZE(twofish_algs));\n}\n\nmodule_init(twofish_init);\nmodule_exit(twofish_exit);\n\nMODULE_DESCRIPTION(\"Twofish Cipher Algorithm, AVX optimized\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_CRYPTO(\"twofish\");\n", "/*\n * Glue Code for assembler optimized version of TWOFISH\n *\n * Originally Twofish for GPG\n * By Matthew Skala <mskala@ansuz.sooke.bc.ca>, July 26, 1998\n * 256-bit key length added March 20, 1999\n * Some modifications to reduce the text size by Werner Koch, April, 1998\n * Ported to the kerneli patch by Marc Mutz <Marc@Mutz.com>\n * Ported to CryptoAPI by Colin Slater <hoho@tacomeat.net>\n *\n * The original author has disclaimed all copyright interest in this\n * code and thus put it in the public domain. The subsequent authors\n * have put this under the GNU General Public License.\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307\n * USA\n *\n * This code is a \"clean room\" implementation, written from the paper\n * _Twofish: A 128-Bit Block Cipher_ by Bruce Schneier, John Kelsey,\n * Doug Whiting, David Wagner, Chris Hall, and Niels Ferguson, available\n * through http://www.counterpane.com/twofish.html\n *\n * For background information on multiplication in finite fields, used for\n * the matrix operations in the key schedule, see the book _Contemporary\n * Abstract Algebra_ by Joseph A. Gallian, especially chapter 22 in the\n * Third Edition.\n */\n\n#include <crypto/twofish.h>\n#include <linux/crypto.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/types.h>\n\nasmlinkage void twofish_enc_blk(struct twofish_ctx *ctx, u8 *dst,\n\t\t\t\tconst u8 *src);\nEXPORT_SYMBOL_GPL(twofish_enc_blk);\nasmlinkage void twofish_dec_blk(struct twofish_ctx *ctx, u8 *dst,\n\t\t\t\tconst u8 *src);\nEXPORT_SYMBOL_GPL(twofish_dec_blk);\n\nstatic void twofish_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\ttwofish_enc_blk(crypto_tfm_ctx(tfm), dst, src);\n}\n\nstatic void twofish_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\ttwofish_dec_blk(crypto_tfm_ctx(tfm), dst, src);\n}\n\nstatic struct crypto_alg alg = {\n\t.cra_name\t\t=\t\"twofish\",\n\t.cra_driver_name\t=\t\"twofish-asm\",\n\t.cra_priority\t\t=\t200,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tTF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct twofish_ctx),\n\t.cra_alignmask\t\t=\t0,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.cipher = {\n\t\t\t.cia_min_keysize\t=\tTF_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t=\tTF_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t=\ttwofish_setkey,\n\t\t\t.cia_encrypt\t\t=\ttwofish_encrypt,\n\t\t\t.cia_decrypt\t\t=\ttwofish_decrypt\n\t\t}\n\t}\n};\n\nstatic int __init init(void)\n{\n\treturn crypto_register_alg(&alg);\n}\n\nstatic void __exit fini(void)\n{\n\tcrypto_unregister_alg(&alg);\n}\n\nmodule_init(init);\nmodule_exit(fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION (\"Twofish Cipher Algorithm, asm optimized\");\nMODULE_ALIAS_CRYPTO(\"twofish\");\nMODULE_ALIAS_CRYPTO(\"twofish-asm\");\n", "/*\n * Glue Code for 3-way parallel assembler optimized version of Twofish\n *\n * Copyright (c) 2011 Jussi Kivilinna <jussi.kivilinna@mbnet.fi>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307\n * USA\n *\n */\n\n#include <asm/processor.h>\n#include <linux/crypto.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/types.h>\n#include <crypto/algapi.h>\n#include <crypto/twofish.h>\n#include <crypto/b128ops.h>\n#include <asm/crypto/twofish.h>\n#include <asm/crypto/glue_helper.h>\n#include <crypto/lrw.h>\n#include <crypto/xts.h>\n\nEXPORT_SYMBOL_GPL(__twofish_enc_blk_3way);\nEXPORT_SYMBOL_GPL(twofish_dec_blk_3way);\n\nstatic inline void twofish_enc_blk_3way(struct twofish_ctx *ctx, u8 *dst,\n\t\t\t\t\tconst u8 *src)\n{\n\t__twofish_enc_blk_3way(ctx, dst, src, false);\n}\n\nstatic inline void twofish_enc_blk_xor_3way(struct twofish_ctx *ctx, u8 *dst,\n\t\t\t\t\t    const u8 *src)\n{\n\t__twofish_enc_blk_3way(ctx, dst, src, true);\n}\n\nvoid twofish_dec_blk_cbc_3way(void *ctx, u128 *dst, const u128 *src)\n{\n\tu128 ivs[2];\n\n\tivs[0] = src[0];\n\tivs[1] = src[1];\n\n\ttwofish_dec_blk_3way(ctx, (u8 *)dst, (u8 *)src);\n\n\tu128_xor(&dst[1], &dst[1], &ivs[0]);\n\tu128_xor(&dst[2], &dst[2], &ivs[1]);\n}\nEXPORT_SYMBOL_GPL(twofish_dec_blk_cbc_3way);\n\nvoid twofish_enc_blk_ctr(void *ctx, u128 *dst, const u128 *src, le128 *iv)\n{\n\tbe128 ctrblk;\n\n\tif (dst != src)\n\t\t*dst = *src;\n\n\tle128_to_be128(&ctrblk, iv);\n\tle128_inc(iv);\n\n\ttwofish_enc_blk(ctx, (u8 *)&ctrblk, (u8 *)&ctrblk);\n\tu128_xor(dst, dst, (u128 *)&ctrblk);\n}\nEXPORT_SYMBOL_GPL(twofish_enc_blk_ctr);\n\nvoid twofish_enc_blk_ctr_3way(void *ctx, u128 *dst, const u128 *src,\n\t\t\t      le128 *iv)\n{\n\tbe128 ctrblks[3];\n\n\tif (dst != src) {\n\t\tdst[0] = src[0];\n\t\tdst[1] = src[1];\n\t\tdst[2] = src[2];\n\t}\n\n\tle128_to_be128(&ctrblks[0], iv);\n\tle128_inc(iv);\n\tle128_to_be128(&ctrblks[1], iv);\n\tle128_inc(iv);\n\tle128_to_be128(&ctrblks[2], iv);\n\tle128_inc(iv);\n\n\ttwofish_enc_blk_xor_3way(ctx, (u8 *)dst, (u8 *)ctrblks);\n}\nEXPORT_SYMBOL_GPL(twofish_enc_blk_ctr_3way);\n\nstatic const struct common_glue_ctx twofish_enc = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = -1,\n\n\t.funcs = { {\n\t\t.num_blocks = 3,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_enc_blk_3way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_enc_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx twofish_ctr = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = -1,\n\n\t.funcs = { {\n\t\t.num_blocks = 3,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_enc_blk_ctr_3way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_enc_blk_ctr) }\n\t} }\n};\n\nstatic const struct common_glue_ctx twofish_dec = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = -1,\n\n\t.funcs = { {\n\t\t.num_blocks = 3,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_dec_blk_3way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .ecb = GLUE_FUNC_CAST(twofish_dec_blk) }\n\t} }\n};\n\nstatic const struct common_glue_ctx twofish_dec_cbc = {\n\t.num_funcs = 2,\n\t.fpu_blocks_limit = -1,\n\n\t.funcs = { {\n\t\t.num_blocks = 3,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(twofish_dec_blk_cbc_3way) }\n\t}, {\n\t\t.num_blocks = 1,\n\t\t.fn_u = { .cbc = GLUE_CBC_FUNC_CAST(twofish_dec_blk) }\n\t} }\n};\n\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&twofish_enc, desc, dst, src, nbytes);\n}\n\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ecb_crypt_128bit(&twofish_dec, desc, dst, src, nbytes);\n}\n\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_encrypt_128bit(GLUE_FUNC_CAST(twofish_enc_blk), desc,\n\t\t\t\t       dst, src, nbytes);\n}\n\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_cbc_decrypt_128bit(&twofish_dec_cbc, desc, dst, src,\n\t\t\t\t       nbytes);\n}\n\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t     struct scatterlist *src, unsigned int nbytes)\n{\n\treturn glue_ctr_crypt_128bit(&twofish_ctr, desc, dst, src, nbytes);\n}\n\nstatic void encrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = TF_BLOCK_SIZE;\n\tstruct twofish_ctx *ctx = priv;\n\tint i;\n\n\tif (nbytes == 3 * bsize) {\n\t\ttwofish_enc_blk_3way(ctx, srcdst, srcdst);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\ttwofish_enc_blk(ctx, srcdst, srcdst);\n}\n\nstatic void decrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\n{\n\tconst unsigned int bsize = TF_BLOCK_SIZE;\n\tstruct twofish_ctx *ctx = priv;\n\tint i;\n\n\tif (nbytes == 3 * bsize) {\n\t\ttwofish_dec_blk_3way(ctx, srcdst, srcdst);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\n\t\ttwofish_dec_blk(ctx, srcdst, srcdst);\n}\n\nint lrw_twofish_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t       unsigned int keylen)\n{\n\tstruct twofish_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\tint err;\n\n\terr = __twofish_setkey(&ctx->twofish_ctx, key, keylen - TF_BLOCK_SIZE,\n\t\t\t       &tfm->crt_flags);\n\tif (err)\n\t\treturn err;\n\n\treturn lrw_init_table(&ctx->lrw_table, key + keylen - TF_BLOCK_SIZE);\n}\nEXPORT_SYMBOL_GPL(lrw_twofish_setkey);\n\nstatic int lrw_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct twofish_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[3];\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &ctx->twofish_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\n\treturn lrw_crypt(desc, dst, src, nbytes, &req);\n}\n\nstatic int lrw_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct twofish_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[3];\n\tstruct lrw_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.table_ctx = &ctx->lrw_table,\n\t\t.crypt_ctx = &ctx->twofish_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\n\treturn lrw_crypt(desc, dst, src, nbytes, &req);\n}\n\nvoid lrw_twofish_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct twofish_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tlrw_free_table(&ctx->lrw_table);\n}\nEXPORT_SYMBOL_GPL(lrw_twofish_exit_tfm);\n\nint xts_twofish_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t       unsigned int keylen)\n{\n\tstruct twofish_xts_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tint err;\n\n\t/* key consists of keys of equal size concatenated, therefore\n\t * the length must be even\n\t */\n\tif (keylen % 2) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\t/* first half of xts-key is for crypt */\n\terr = __twofish_setkey(&ctx->crypt_ctx, key, keylen / 2, flags);\n\tif (err)\n\t\treturn err;\n\n\t/* second half of xts-key is for tweak */\n\treturn __twofish_setkey(&ctx->tweak_ctx, key + keylen / 2, keylen / 2,\n\t\t\t\tflags);\n}\nEXPORT_SYMBOL_GPL(xts_twofish_setkey);\n\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct twofish_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[3];\n\tstruct xts_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.tweak_ctx = &ctx->tweak_ctx,\n\t\t.tweak_fn = XTS_TWEAK_CAST(twofish_enc_blk),\n\t\t.crypt_ctx = &ctx->crypt_ctx,\n\t\t.crypt_fn = encrypt_callback,\n\t};\n\n\treturn xts_crypt(desc, dst, src, nbytes, &req);\n}\n\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct twofish_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tbe128 buf[3];\n\tstruct xts_crypt_req req = {\n\t\t.tbuf = buf,\n\t\t.tbuflen = sizeof(buf),\n\n\t\t.tweak_ctx = &ctx->tweak_ctx,\n\t\t.tweak_fn = XTS_TWEAK_CAST(twofish_enc_blk),\n\t\t.crypt_ctx = &ctx->crypt_ctx,\n\t\t.crypt_fn = decrypt_callback,\n\t};\n\n\treturn xts_crypt(desc, dst, src, nbytes, &req);\n}\n\nstatic struct crypto_alg tf_algs[5] = { {\n\t.cra_name\t\t= \"ecb(twofish)\",\n\t.cra_driver_name\t= \"ecb-twofish-3way\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct twofish_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t= twofish_setkey,\n\t\t\t.encrypt\t= ecb_encrypt,\n\t\t\t.decrypt\t= ecb_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"cbc(twofish)\",\n\t.cra_driver_name\t= \"cbc-twofish-3way\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct twofish_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= TF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= twofish_setkey,\n\t\t\t.encrypt\t= cbc_encrypt,\n\t\t\t.decrypt\t= cbc_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"ctr(twofish)\",\n\t.cra_driver_name\t= \"ctr-twofish-3way\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= 1,\n\t.cra_ctxsize\t\t= sizeof(struct twofish_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t= TF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= twofish_setkey,\n\t\t\t.encrypt\t= ctr_crypt,\n\t\t\t.decrypt\t= ctr_crypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"lrw(twofish)\",\n\t.cra_driver_name\t= \"lrw-twofish-3way\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct twofish_lrw_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_exit\t\t= lrw_twofish_exit_tfm,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE + TF_BLOCK_SIZE,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE + TF_BLOCK_SIZE,\n\t\t\t.ivsize\t\t= TF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= lrw_twofish_setkey,\n\t\t\t.encrypt\t= lrw_encrypt,\n\t\t\t.decrypt\t= lrw_decrypt,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t= \"xts(twofish)\",\n\t.cra_driver_name\t= \"xts-twofish-3way\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t= TF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct twofish_xts_ctx),\n\t.cra_alignmask\t\t= 0,\n\t.cra_type\t\t= &crypto_blkcipher_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u = {\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t= TF_MIN_KEY_SIZE * 2,\n\t\t\t.max_keysize\t= TF_MAX_KEY_SIZE * 2,\n\t\t\t.ivsize\t\t= TF_BLOCK_SIZE,\n\t\t\t.setkey\t\t= xts_twofish_setkey,\n\t\t\t.encrypt\t= xts_encrypt,\n\t\t\t.decrypt\t= xts_decrypt,\n\t\t},\n\t},\n} };\n\nstatic bool is_blacklisted_cpu(void)\n{\n\tif (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL)\n\t\treturn false;\n\n\tif (boot_cpu_data.x86 == 0x06 &&\n\t\t(boot_cpu_data.x86_model == 0x1c ||\n\t\t boot_cpu_data.x86_model == 0x26 ||\n\t\t boot_cpu_data.x86_model == 0x36)) {\n\t\t/*\n\t\t * On Atom, twofish-3way is slower than original assembler\n\t\t * implementation. Twofish-3way trades off some performance in\n\t\t * storing blocks in 64bit registers to allow three blocks to\n\t\t * be processed parallel. Parallel operation then allows gaining\n\t\t * more performance than was trade off, on out-of-order CPUs.\n\t\t * However Atom does not benefit from this parallellism and\n\t\t * should be blacklisted.\n\t\t */\n\t\treturn true;\n\t}\n\n\tif (boot_cpu_data.x86 == 0x0f) {\n\t\t/*\n\t\t * On Pentium 4, twofish-3way is slower than original assembler\n\t\t * implementation because excessive uses of 64bit rotate and\n\t\t * left-shifts (which are really slow on P4) needed to store and\n\t\t * handle 128bit block in two 64bit registers.\n\t\t */\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic int force;\nmodule_param(force, int, 0);\nMODULE_PARM_DESC(force, \"Force module load, ignore CPU blacklist\");\n\nstatic int __init init(void)\n{\n\tif (!force && is_blacklisted_cpu()) {\n\t\tprintk(KERN_INFO\n\t\t\t\"twofish-x86_64-3way: performance on this CPU \"\n\t\t\t\"would be suboptimal: disabling \"\n\t\t\t\"twofish-x86_64-3way.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn crypto_register_algs(tf_algs, ARRAY_SIZE(tf_algs));\n}\n\nstatic void __exit fini(void)\n{\n\tcrypto_unregister_algs(tf_algs, ARRAY_SIZE(tf_algs));\n}\n\nmodule_init(init);\nmodule_exit(fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Twofish Cipher Algorithm, 3-way parallel asm optimized\");\nMODULE_ALIAS_CRYPTO(\"twofish\");\nMODULE_ALIAS_CRYPTO(\"twofish-asm\");\n", "/*\n * Cryptographic API for the 842 compression algorithm.\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.\n *\n * Copyright (C) IBM Corporation, 2011\n *\n * Authors: Robert Jennings <rcj@linux.vnet.ibm.com>\n *          Seth Jennings <sjenning@linux.vnet.ibm.com>\n */\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/crypto.h>\n#include <linux/vmalloc.h>\n#include <linux/nx842.h>\n#include <linux/lzo.h>\n#include <linux/timer.h>\n\nstatic int nx842_uselzo;\n\nstruct nx842_ctx {\n\tvoid *nx842_wmem; /* working memory for 842/lzo */\n};\n\nenum nx842_crypto_type {\n\tNX842_CRYPTO_TYPE_842,\n\tNX842_CRYPTO_TYPE_LZO\n};\n\n#define NX842_SENTINEL 0xdeadbeef\n\nstruct nx842_crypto_header {\n\tunsigned int sentinel; /* debug */\n\tenum nx842_crypto_type type;\n};\n\nstatic int nx842_init(struct crypto_tfm *tfm)\n{\n\tstruct nx842_ctx *ctx = crypto_tfm_ctx(tfm);\n\tint wmemsize;\n\n\twmemsize = max_t(int, nx842_get_workmem_size(), LZO1X_MEM_COMPRESS);\n\tctx->nx842_wmem = kmalloc(wmemsize, GFP_NOFS);\n\tif (!ctx->nx842_wmem)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic void nx842_exit(struct crypto_tfm *tfm)\n{\n\tstruct nx842_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tkfree(ctx->nx842_wmem);\n}\n\nstatic void nx842_reset_uselzo(unsigned long data)\n{\n\tnx842_uselzo = 0;\n}\n\nstatic DEFINE_TIMER(failover_timer, nx842_reset_uselzo, 0, 0);\n\nstatic int nx842_crypto_compress(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t    unsigned int slen, u8 *dst, unsigned int *dlen)\n{\n\tstruct nx842_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct nx842_crypto_header *hdr;\n\tunsigned int tmp_len = *dlen;\n\tsize_t lzodlen; /* needed for lzo */\n\tint err;\n\n\t*dlen = 0;\n\thdr = (struct nx842_crypto_header *)dst;\n\thdr->sentinel = NX842_SENTINEL; /* debug */\n\tdst += sizeof(struct nx842_crypto_header);\n\ttmp_len -= sizeof(struct nx842_crypto_header);\n\tlzodlen = tmp_len;\n\n\tif (likely(!nx842_uselzo)) {\n\t\terr = nx842_compress(src, slen, dst, &tmp_len, ctx->nx842_wmem);\n\n\t\tif (likely(!err)) {\n\t\t\thdr->type = NX842_CRYPTO_TYPE_842;\n\t\t\t*dlen = tmp_len + sizeof(struct nx842_crypto_header);\n\t\t\treturn 0;\n\t\t}\n\n\t\t/* hardware failed */\n\t\tnx842_uselzo = 1;\n\n\t\t/* set timer to check for hardware again in 1 second */\n\t\tmod_timer(&failover_timer, jiffies + msecs_to_jiffies(1000));\n\t}\n\n\t/* no hardware, use lzo */\n\terr = lzo1x_1_compress(src, slen, dst, &lzodlen, ctx->nx842_wmem);\n\tif (err != LZO_E_OK)\n\t\treturn -EINVAL;\n\n\thdr->type = NX842_CRYPTO_TYPE_LZO;\n\t*dlen = lzodlen + sizeof(struct nx842_crypto_header);\n\treturn 0;\n}\n\nstatic int nx842_crypto_decompress(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t      unsigned int slen, u8 *dst, unsigned int *dlen)\n{\n\tstruct nx842_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct nx842_crypto_header *hdr;\n\tunsigned int tmp_len = *dlen;\n\tsize_t lzodlen; /* needed for lzo */\n\tint err;\n\n\t*dlen = 0;\n\thdr = (struct nx842_crypto_header *)src;\n\n\tif (unlikely(hdr->sentinel != NX842_SENTINEL))\n\t\treturn -EINVAL;\n\n\tsrc += sizeof(struct nx842_crypto_header);\n\tslen -= sizeof(struct nx842_crypto_header);\n\n\tif (likely(hdr->type == NX842_CRYPTO_TYPE_842)) {\n\t\terr = nx842_decompress(src, slen, dst, &tmp_len,\n\t\t\tctx->nx842_wmem);\n\t\tif (err)\n\t\t\treturn -EINVAL;\n\t\t*dlen = tmp_len;\n\t} else if (hdr->type == NX842_CRYPTO_TYPE_LZO) {\n\t\tlzodlen = tmp_len;\n\t\terr = lzo1x_decompress_safe(src, slen, dst, &lzodlen);\n\t\tif (err != LZO_E_OK)\n\t\t\treturn -EINVAL;\n\t\t*dlen = lzodlen;\n\t} else\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic struct crypto_alg alg = {\n\t.cra_name\t\t= \"842\",\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_COMPRESS,\n\t.cra_ctxsize\t\t= sizeof(struct nx842_ctx),\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= nx842_init,\n\t.cra_exit\t\t= nx842_exit,\n\t.cra_u\t\t\t= { .compress = {\n\t.coa_compress\t\t= nx842_crypto_compress,\n\t.coa_decompress\t\t= nx842_crypto_decompress } }\n};\n\nstatic int __init nx842_mod_init(void)\n{\n\tdel_timer(&failover_timer);\n\treturn crypto_register_alg(&alg);\n}\n\nstatic void __exit nx842_mod_exit(void)\n{\n\tcrypto_unregister_alg(&alg);\n}\n\nmodule_init(nx842_mod_init);\nmodule_exit(nx842_mod_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"842 Compression Algorithm\");\nMODULE_ALIAS_CRYPTO(\"842\");\n", "/*\n * Cryptographic API.\n *\n * AES Cipher Algorithm.\n *\n * Based on Brian Gladman's code.\n *\n * Linux developers:\n *  Alexander Kjeldaas <astor@fast.no>\n *  Herbert Valerio Riedel <hvr@hvrlab.org>\n *  Kyle McMartin <kyle@debian.org>\n *  Adam J. Richter <adam@yggdrasil.com> (conversion to 2.5 API).\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * ---------------------------------------------------------------------------\n * Copyright (c) 2002, Dr Brian Gladman <brg@gladman.me.uk>, Worcester, UK.\n * All rights reserved.\n *\n * LICENSE TERMS\n *\n * The free distribution and use of this software in both source and binary\n * form is allowed (with or without changes) provided that:\n *\n *   1. distributions of this source code include the above copyright\n *      notice, this list of conditions and the following disclaimer;\n *\n *   2. distributions in binary form include the above copyright\n *      notice, this list of conditions and the following disclaimer\n *      in the documentation and/or other associated materials;\n *\n *   3. the copyright holder's name is not used to endorse products\n *      built using this software without specific written permission.\n *\n * ALTERNATIVELY, provided that this notice is retained in full, this product\n * may be distributed under the terms of the GNU General Public License (GPL),\n * in which case the provisions of the GPL apply INSTEAD OF those given above.\n *\n * DISCLAIMER\n *\n * This software is provided 'as is' with no explicit or implied warranties\n * in respect of its properties, including, but not limited to, correctness\n * and/or fitness for purpose.\n * ---------------------------------------------------------------------------\n */\n\n#include <crypto/aes.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/types.h>\n#include <linux/errno.h>\n#include <linux/crypto.h>\n#include <asm/byteorder.h>\n\nstatic inline u8 byte(const u32 x, const unsigned n)\n{\n\treturn x >> (n << 3);\n}\n\nstatic const u32 rco_tab[10] = { 1, 2, 4, 8, 16, 32, 64, 128, 27, 54 };\n\n__visible const u32 crypto_ft_tab[4][256] = {\n\t{\n\t\t0xa56363c6, 0x847c7cf8, 0x997777ee, 0x8d7b7bf6,\n\t\t0x0df2f2ff, 0xbd6b6bd6, 0xb16f6fde, 0x54c5c591,\n\t\t0x50303060, 0x03010102, 0xa96767ce, 0x7d2b2b56,\n\t\t0x19fefee7, 0x62d7d7b5, 0xe6abab4d, 0x9a7676ec,\n\t\t0x45caca8f, 0x9d82821f, 0x40c9c989, 0x877d7dfa,\n\t\t0x15fafaef, 0xeb5959b2, 0xc947478e, 0x0bf0f0fb,\n\t\t0xecadad41, 0x67d4d4b3, 0xfda2a25f, 0xeaafaf45,\n\t\t0xbf9c9c23, 0xf7a4a453, 0x967272e4, 0x5bc0c09b,\n\t\t0xc2b7b775, 0x1cfdfde1, 0xae93933d, 0x6a26264c,\n\t\t0x5a36366c, 0x413f3f7e, 0x02f7f7f5, 0x4fcccc83,\n\t\t0x5c343468, 0xf4a5a551, 0x34e5e5d1, 0x08f1f1f9,\n\t\t0x937171e2, 0x73d8d8ab, 0x53313162, 0x3f15152a,\n\t\t0x0c040408, 0x52c7c795, 0x65232346, 0x5ec3c39d,\n\t\t0x28181830, 0xa1969637, 0x0f05050a, 0xb59a9a2f,\n\t\t0x0907070e, 0x36121224, 0x9b80801b, 0x3de2e2df,\n\t\t0x26ebebcd, 0x6927274e, 0xcdb2b27f, 0x9f7575ea,\n\t\t0x1b090912, 0x9e83831d, 0x742c2c58, 0x2e1a1a34,\n\t\t0x2d1b1b36, 0xb26e6edc, 0xee5a5ab4, 0xfba0a05b,\n\t\t0xf65252a4, 0x4d3b3b76, 0x61d6d6b7, 0xceb3b37d,\n\t\t0x7b292952, 0x3ee3e3dd, 0x712f2f5e, 0x97848413,\n\t\t0xf55353a6, 0x68d1d1b9, 0x00000000, 0x2cededc1,\n\t\t0x60202040, 0x1ffcfce3, 0xc8b1b179, 0xed5b5bb6,\n\t\t0xbe6a6ad4, 0x46cbcb8d, 0xd9bebe67, 0x4b393972,\n\t\t0xde4a4a94, 0xd44c4c98, 0xe85858b0, 0x4acfcf85,\n\t\t0x6bd0d0bb, 0x2aefefc5, 0xe5aaaa4f, 0x16fbfbed,\n\t\t0xc5434386, 0xd74d4d9a, 0x55333366, 0x94858511,\n\t\t0xcf45458a, 0x10f9f9e9, 0x06020204, 0x817f7ffe,\n\t\t0xf05050a0, 0x443c3c78, 0xba9f9f25, 0xe3a8a84b,\n\t\t0xf35151a2, 0xfea3a35d, 0xc0404080, 0x8a8f8f05,\n\t\t0xad92923f, 0xbc9d9d21, 0x48383870, 0x04f5f5f1,\n\t\t0xdfbcbc63, 0xc1b6b677, 0x75dadaaf, 0x63212142,\n\t\t0x30101020, 0x1affffe5, 0x0ef3f3fd, 0x6dd2d2bf,\n\t\t0x4ccdcd81, 0x140c0c18, 0x35131326, 0x2fececc3,\n\t\t0xe15f5fbe, 0xa2979735, 0xcc444488, 0x3917172e,\n\t\t0x57c4c493, 0xf2a7a755, 0x827e7efc, 0x473d3d7a,\n\t\t0xac6464c8, 0xe75d5dba, 0x2b191932, 0x957373e6,\n\t\t0xa06060c0, 0x98818119, 0xd14f4f9e, 0x7fdcdca3,\n\t\t0x66222244, 0x7e2a2a54, 0xab90903b, 0x8388880b,\n\t\t0xca46468c, 0x29eeeec7, 0xd3b8b86b, 0x3c141428,\n\t\t0x79dedea7, 0xe25e5ebc, 0x1d0b0b16, 0x76dbdbad,\n\t\t0x3be0e0db, 0x56323264, 0x4e3a3a74, 0x1e0a0a14,\n\t\t0xdb494992, 0x0a06060c, 0x6c242448, 0xe45c5cb8,\n\t\t0x5dc2c29f, 0x6ed3d3bd, 0xefacac43, 0xa66262c4,\n\t\t0xa8919139, 0xa4959531, 0x37e4e4d3, 0x8b7979f2,\n\t\t0x32e7e7d5, 0x43c8c88b, 0x5937376e, 0xb76d6dda,\n\t\t0x8c8d8d01, 0x64d5d5b1, 0xd24e4e9c, 0xe0a9a949,\n\t\t0xb46c6cd8, 0xfa5656ac, 0x07f4f4f3, 0x25eaeacf,\n\t\t0xaf6565ca, 0x8e7a7af4, 0xe9aeae47, 0x18080810,\n\t\t0xd5baba6f, 0x887878f0, 0x6f25254a, 0x722e2e5c,\n\t\t0x241c1c38, 0xf1a6a657, 0xc7b4b473, 0x51c6c697,\n\t\t0x23e8e8cb, 0x7cdddda1, 0x9c7474e8, 0x211f1f3e,\n\t\t0xdd4b4b96, 0xdcbdbd61, 0x868b8b0d, 0x858a8a0f,\n\t\t0x907070e0, 0x423e3e7c, 0xc4b5b571, 0xaa6666cc,\n\t\t0xd8484890, 0x05030306, 0x01f6f6f7, 0x120e0e1c,\n\t\t0xa36161c2, 0x5f35356a, 0xf95757ae, 0xd0b9b969,\n\t\t0x91868617, 0x58c1c199, 0x271d1d3a, 0xb99e9e27,\n\t\t0x38e1e1d9, 0x13f8f8eb, 0xb398982b, 0x33111122,\n\t\t0xbb6969d2, 0x70d9d9a9, 0x898e8e07, 0xa7949433,\n\t\t0xb69b9b2d, 0x221e1e3c, 0x92878715, 0x20e9e9c9,\n\t\t0x49cece87, 0xff5555aa, 0x78282850, 0x7adfdfa5,\n\t\t0x8f8c8c03, 0xf8a1a159, 0x80898909, 0x170d0d1a,\n\t\t0xdabfbf65, 0x31e6e6d7, 0xc6424284, 0xb86868d0,\n\t\t0xc3414182, 0xb0999929, 0x772d2d5a, 0x110f0f1e,\n\t\t0xcbb0b07b, 0xfc5454a8, 0xd6bbbb6d, 0x3a16162c,\n\t}, {\n\t\t0x6363c6a5, 0x7c7cf884, 0x7777ee99, 0x7b7bf68d,\n\t\t0xf2f2ff0d, 0x6b6bd6bd, 0x6f6fdeb1, 0xc5c59154,\n\t\t0x30306050, 0x01010203, 0x6767cea9, 0x2b2b567d,\n\t\t0xfefee719, 0xd7d7b562, 0xabab4de6, 0x7676ec9a,\n\t\t0xcaca8f45, 0x82821f9d, 0xc9c98940, 0x7d7dfa87,\n\t\t0xfafaef15, 0x5959b2eb, 0x47478ec9, 0xf0f0fb0b,\n\t\t0xadad41ec, 0xd4d4b367, 0xa2a25ffd, 0xafaf45ea,\n\t\t0x9c9c23bf, 0xa4a453f7, 0x7272e496, 0xc0c09b5b,\n\t\t0xb7b775c2, 0xfdfde11c, 0x93933dae, 0x26264c6a,\n\t\t0x36366c5a, 0x3f3f7e41, 0xf7f7f502, 0xcccc834f,\n\t\t0x3434685c, 0xa5a551f4, 0xe5e5d134, 0xf1f1f908,\n\t\t0x7171e293, 0xd8d8ab73, 0x31316253, 0x15152a3f,\n\t\t0x0404080c, 0xc7c79552, 0x23234665, 0xc3c39d5e,\n\t\t0x18183028, 0x969637a1, 0x05050a0f, 0x9a9a2fb5,\n\t\t0x07070e09, 0x12122436, 0x80801b9b, 0xe2e2df3d,\n\t\t0xebebcd26, 0x27274e69, 0xb2b27fcd, 0x7575ea9f,\n\t\t0x0909121b, 0x83831d9e, 0x2c2c5874, 0x1a1a342e,\n\t\t0x1b1b362d, 0x6e6edcb2, 0x5a5ab4ee, 0xa0a05bfb,\n\t\t0x5252a4f6, 0x3b3b764d, 0xd6d6b761, 0xb3b37dce,\n\t\t0x2929527b, 0xe3e3dd3e, 0x2f2f5e71, 0x84841397,\n\t\t0x5353a6f5, 0xd1d1b968, 0x00000000, 0xededc12c,\n\t\t0x20204060, 0xfcfce31f, 0xb1b179c8, 0x5b5bb6ed,\n\t\t0x6a6ad4be, 0xcbcb8d46, 0xbebe67d9, 0x3939724b,\n\t\t0x4a4a94de, 0x4c4c98d4, 0x5858b0e8, 0xcfcf854a,\n\t\t0xd0d0bb6b, 0xefefc52a, 0xaaaa4fe5, 0xfbfbed16,\n\t\t0x434386c5, 0x4d4d9ad7, 0x33336655, 0x85851194,\n\t\t0x45458acf, 0xf9f9e910, 0x02020406, 0x7f7ffe81,\n\t\t0x5050a0f0, 0x3c3c7844, 0x9f9f25ba, 0xa8a84be3,\n\t\t0x5151a2f3, 0xa3a35dfe, 0x404080c0, 0x8f8f058a,\n\t\t0x92923fad, 0x9d9d21bc, 0x38387048, 0xf5f5f104,\n\t\t0xbcbc63df, 0xb6b677c1, 0xdadaaf75, 0x21214263,\n\t\t0x10102030, 0xffffe51a, 0xf3f3fd0e, 0xd2d2bf6d,\n\t\t0xcdcd814c, 0x0c0c1814, 0x13132635, 0xececc32f,\n\t\t0x5f5fbee1, 0x979735a2, 0x444488cc, 0x17172e39,\n\t\t0xc4c49357, 0xa7a755f2, 0x7e7efc82, 0x3d3d7a47,\n\t\t0x6464c8ac, 0x5d5dbae7, 0x1919322b, 0x7373e695,\n\t\t0x6060c0a0, 0x81811998, 0x4f4f9ed1, 0xdcdca37f,\n\t\t0x22224466, 0x2a2a547e, 0x90903bab, 0x88880b83,\n\t\t0x46468cca, 0xeeeec729, 0xb8b86bd3, 0x1414283c,\n\t\t0xdedea779, 0x5e5ebce2, 0x0b0b161d, 0xdbdbad76,\n\t\t0xe0e0db3b, 0x32326456, 0x3a3a744e, 0x0a0a141e,\n\t\t0x494992db, 0x06060c0a, 0x2424486c, 0x5c5cb8e4,\n\t\t0xc2c29f5d, 0xd3d3bd6e, 0xacac43ef, 0x6262c4a6,\n\t\t0x919139a8, 0x959531a4, 0xe4e4d337, 0x7979f28b,\n\t\t0xe7e7d532, 0xc8c88b43, 0x37376e59, 0x6d6ddab7,\n\t\t0x8d8d018c, 0xd5d5b164, 0x4e4e9cd2, 0xa9a949e0,\n\t\t0x6c6cd8b4, 0x5656acfa, 0xf4f4f307, 0xeaeacf25,\n\t\t0x6565caaf, 0x7a7af48e, 0xaeae47e9, 0x08081018,\n\t\t0xbaba6fd5, 0x7878f088, 0x25254a6f, 0x2e2e5c72,\n\t\t0x1c1c3824, 0xa6a657f1, 0xb4b473c7, 0xc6c69751,\n\t\t0xe8e8cb23, 0xdddda17c, 0x7474e89c, 0x1f1f3e21,\n\t\t0x4b4b96dd, 0xbdbd61dc, 0x8b8b0d86, 0x8a8a0f85,\n\t\t0x7070e090, 0x3e3e7c42, 0xb5b571c4, 0x6666ccaa,\n\t\t0x484890d8, 0x03030605, 0xf6f6f701, 0x0e0e1c12,\n\t\t0x6161c2a3, 0x35356a5f, 0x5757aef9, 0xb9b969d0,\n\t\t0x86861791, 0xc1c19958, 0x1d1d3a27, 0x9e9e27b9,\n\t\t0xe1e1d938, 0xf8f8eb13, 0x98982bb3, 0x11112233,\n\t\t0x6969d2bb, 0xd9d9a970, 0x8e8e0789, 0x949433a7,\n\t\t0x9b9b2db6, 0x1e1e3c22, 0x87871592, 0xe9e9c920,\n\t\t0xcece8749, 0x5555aaff, 0x28285078, 0xdfdfa57a,\n\t\t0x8c8c038f, 0xa1a159f8, 0x89890980, 0x0d0d1a17,\n\t\t0xbfbf65da, 0xe6e6d731, 0x424284c6, 0x6868d0b8,\n\t\t0x414182c3, 0x999929b0, 0x2d2d5a77, 0x0f0f1e11,\n\t\t0xb0b07bcb, 0x5454a8fc, 0xbbbb6dd6, 0x16162c3a,\n\t}, {\n\t\t0x63c6a563, 0x7cf8847c, 0x77ee9977, 0x7bf68d7b,\n\t\t0xf2ff0df2, 0x6bd6bd6b, 0x6fdeb16f, 0xc59154c5,\n\t\t0x30605030, 0x01020301, 0x67cea967, 0x2b567d2b,\n\t\t0xfee719fe, 0xd7b562d7, 0xab4de6ab, 0x76ec9a76,\n\t\t0xca8f45ca, 0x821f9d82, 0xc98940c9, 0x7dfa877d,\n\t\t0xfaef15fa, 0x59b2eb59, 0x478ec947, 0xf0fb0bf0,\n\t\t0xad41ecad, 0xd4b367d4, 0xa25ffda2, 0xaf45eaaf,\n\t\t0x9c23bf9c, 0xa453f7a4, 0x72e49672, 0xc09b5bc0,\n\t\t0xb775c2b7, 0xfde11cfd, 0x933dae93, 0x264c6a26,\n\t\t0x366c5a36, 0x3f7e413f, 0xf7f502f7, 0xcc834fcc,\n\t\t0x34685c34, 0xa551f4a5, 0xe5d134e5, 0xf1f908f1,\n\t\t0x71e29371, 0xd8ab73d8, 0x31625331, 0x152a3f15,\n\t\t0x04080c04, 0xc79552c7, 0x23466523, 0xc39d5ec3,\n\t\t0x18302818, 0x9637a196, 0x050a0f05, 0x9a2fb59a,\n\t\t0x070e0907, 0x12243612, 0x801b9b80, 0xe2df3de2,\n\t\t0xebcd26eb, 0x274e6927, 0xb27fcdb2, 0x75ea9f75,\n\t\t0x09121b09, 0x831d9e83, 0x2c58742c, 0x1a342e1a,\n\t\t0x1b362d1b, 0x6edcb26e, 0x5ab4ee5a, 0xa05bfba0,\n\t\t0x52a4f652, 0x3b764d3b, 0xd6b761d6, 0xb37dceb3,\n\t\t0x29527b29, 0xe3dd3ee3, 0x2f5e712f, 0x84139784,\n\t\t0x53a6f553, 0xd1b968d1, 0x00000000, 0xedc12ced,\n\t\t0x20406020, 0xfce31ffc, 0xb179c8b1, 0x5bb6ed5b,\n\t\t0x6ad4be6a, 0xcb8d46cb, 0xbe67d9be, 0x39724b39,\n\t\t0x4a94de4a, 0x4c98d44c, 0x58b0e858, 0xcf854acf,\n\t\t0xd0bb6bd0, 0xefc52aef, 0xaa4fe5aa, 0xfbed16fb,\n\t\t0x4386c543, 0x4d9ad74d, 0x33665533, 0x85119485,\n\t\t0x458acf45, 0xf9e910f9, 0x02040602, 0x7ffe817f,\n\t\t0x50a0f050, 0x3c78443c, 0x9f25ba9f, 0xa84be3a8,\n\t\t0x51a2f351, 0xa35dfea3, 0x4080c040, 0x8f058a8f,\n\t\t0x923fad92, 0x9d21bc9d, 0x38704838, 0xf5f104f5,\n\t\t0xbc63dfbc, 0xb677c1b6, 0xdaaf75da, 0x21426321,\n\t\t0x10203010, 0xffe51aff, 0xf3fd0ef3, 0xd2bf6dd2,\n\t\t0xcd814ccd, 0x0c18140c, 0x13263513, 0xecc32fec,\n\t\t0x5fbee15f, 0x9735a297, 0x4488cc44, 0x172e3917,\n\t\t0xc49357c4, 0xa755f2a7, 0x7efc827e, 0x3d7a473d,\n\t\t0x64c8ac64, 0x5dbae75d, 0x19322b19, 0x73e69573,\n\t\t0x60c0a060, 0x81199881, 0x4f9ed14f, 0xdca37fdc,\n\t\t0x22446622, 0x2a547e2a, 0x903bab90, 0x880b8388,\n\t\t0x468cca46, 0xeec729ee, 0xb86bd3b8, 0x14283c14,\n\t\t0xdea779de, 0x5ebce25e, 0x0b161d0b, 0xdbad76db,\n\t\t0xe0db3be0, 0x32645632, 0x3a744e3a, 0x0a141e0a,\n\t\t0x4992db49, 0x060c0a06, 0x24486c24, 0x5cb8e45c,\n\t\t0xc29f5dc2, 0xd3bd6ed3, 0xac43efac, 0x62c4a662,\n\t\t0x9139a891, 0x9531a495, 0xe4d337e4, 0x79f28b79,\n\t\t0xe7d532e7, 0xc88b43c8, 0x376e5937, 0x6ddab76d,\n\t\t0x8d018c8d, 0xd5b164d5, 0x4e9cd24e, 0xa949e0a9,\n\t\t0x6cd8b46c, 0x56acfa56, 0xf4f307f4, 0xeacf25ea,\n\t\t0x65caaf65, 0x7af48e7a, 0xae47e9ae, 0x08101808,\n\t\t0xba6fd5ba, 0x78f08878, 0x254a6f25, 0x2e5c722e,\n\t\t0x1c38241c, 0xa657f1a6, 0xb473c7b4, 0xc69751c6,\n\t\t0xe8cb23e8, 0xdda17cdd, 0x74e89c74, 0x1f3e211f,\n\t\t0x4b96dd4b, 0xbd61dcbd, 0x8b0d868b, 0x8a0f858a,\n\t\t0x70e09070, 0x3e7c423e, 0xb571c4b5, 0x66ccaa66,\n\t\t0x4890d848, 0x03060503, 0xf6f701f6, 0x0e1c120e,\n\t\t0x61c2a361, 0x356a5f35, 0x57aef957, 0xb969d0b9,\n\t\t0x86179186, 0xc19958c1, 0x1d3a271d, 0x9e27b99e,\n\t\t0xe1d938e1, 0xf8eb13f8, 0x982bb398, 0x11223311,\n\t\t0x69d2bb69, 0xd9a970d9, 0x8e07898e, 0x9433a794,\n\t\t0x9b2db69b, 0x1e3c221e, 0x87159287, 0xe9c920e9,\n\t\t0xce8749ce, 0x55aaff55, 0x28507828, 0xdfa57adf,\n\t\t0x8c038f8c, 0xa159f8a1, 0x89098089, 0x0d1a170d,\n\t\t0xbf65dabf, 0xe6d731e6, 0x4284c642, 0x68d0b868,\n\t\t0x4182c341, 0x9929b099, 0x2d5a772d, 0x0f1e110f,\n\t\t0xb07bcbb0, 0x54a8fc54, 0xbb6dd6bb, 0x162c3a16,\n\t}, {\n\t\t0xc6a56363, 0xf8847c7c, 0xee997777, 0xf68d7b7b,\n\t\t0xff0df2f2, 0xd6bd6b6b, 0xdeb16f6f, 0x9154c5c5,\n\t\t0x60503030, 0x02030101, 0xcea96767, 0x567d2b2b,\n\t\t0xe719fefe, 0xb562d7d7, 0x4de6abab, 0xec9a7676,\n\t\t0x8f45caca, 0x1f9d8282, 0x8940c9c9, 0xfa877d7d,\n\t\t0xef15fafa, 0xb2eb5959, 0x8ec94747, 0xfb0bf0f0,\n\t\t0x41ecadad, 0xb367d4d4, 0x5ffda2a2, 0x45eaafaf,\n\t\t0x23bf9c9c, 0x53f7a4a4, 0xe4967272, 0x9b5bc0c0,\n\t\t0x75c2b7b7, 0xe11cfdfd, 0x3dae9393, 0x4c6a2626,\n\t\t0x6c5a3636, 0x7e413f3f, 0xf502f7f7, 0x834fcccc,\n\t\t0x685c3434, 0x51f4a5a5, 0xd134e5e5, 0xf908f1f1,\n\t\t0xe2937171, 0xab73d8d8, 0x62533131, 0x2a3f1515,\n\t\t0x080c0404, 0x9552c7c7, 0x46652323, 0x9d5ec3c3,\n\t\t0x30281818, 0x37a19696, 0x0a0f0505, 0x2fb59a9a,\n\t\t0x0e090707, 0x24361212, 0x1b9b8080, 0xdf3de2e2,\n\t\t0xcd26ebeb, 0x4e692727, 0x7fcdb2b2, 0xea9f7575,\n\t\t0x121b0909, 0x1d9e8383, 0x58742c2c, 0x342e1a1a,\n\t\t0x362d1b1b, 0xdcb26e6e, 0xb4ee5a5a, 0x5bfba0a0,\n\t\t0xa4f65252, 0x764d3b3b, 0xb761d6d6, 0x7dceb3b3,\n\t\t0x527b2929, 0xdd3ee3e3, 0x5e712f2f, 0x13978484,\n\t\t0xa6f55353, 0xb968d1d1, 0x00000000, 0xc12ceded,\n\t\t0x40602020, 0xe31ffcfc, 0x79c8b1b1, 0xb6ed5b5b,\n\t\t0xd4be6a6a, 0x8d46cbcb, 0x67d9bebe, 0x724b3939,\n\t\t0x94de4a4a, 0x98d44c4c, 0xb0e85858, 0x854acfcf,\n\t\t0xbb6bd0d0, 0xc52aefef, 0x4fe5aaaa, 0xed16fbfb,\n\t\t0x86c54343, 0x9ad74d4d, 0x66553333, 0x11948585,\n\t\t0x8acf4545, 0xe910f9f9, 0x04060202, 0xfe817f7f,\n\t\t0xa0f05050, 0x78443c3c, 0x25ba9f9f, 0x4be3a8a8,\n\t\t0xa2f35151, 0x5dfea3a3, 0x80c04040, 0x058a8f8f,\n\t\t0x3fad9292, 0x21bc9d9d, 0x70483838, 0xf104f5f5,\n\t\t0x63dfbcbc, 0x77c1b6b6, 0xaf75dada, 0x42632121,\n\t\t0x20301010, 0xe51affff, 0xfd0ef3f3, 0xbf6dd2d2,\n\t\t0x814ccdcd, 0x18140c0c, 0x26351313, 0xc32fecec,\n\t\t0xbee15f5f, 0x35a29797, 0x88cc4444, 0x2e391717,\n\t\t0x9357c4c4, 0x55f2a7a7, 0xfc827e7e, 0x7a473d3d,\n\t\t0xc8ac6464, 0xbae75d5d, 0x322b1919, 0xe6957373,\n\t\t0xc0a06060, 0x19988181, 0x9ed14f4f, 0xa37fdcdc,\n\t\t0x44662222, 0x547e2a2a, 0x3bab9090, 0x0b838888,\n\t\t0x8cca4646, 0xc729eeee, 0x6bd3b8b8, 0x283c1414,\n\t\t0xa779dede, 0xbce25e5e, 0x161d0b0b, 0xad76dbdb,\n\t\t0xdb3be0e0, 0x64563232, 0x744e3a3a, 0x141e0a0a,\n\t\t0x92db4949, 0x0c0a0606, 0x486c2424, 0xb8e45c5c,\n\t\t0x9f5dc2c2, 0xbd6ed3d3, 0x43efacac, 0xc4a66262,\n\t\t0x39a89191, 0x31a49595, 0xd337e4e4, 0xf28b7979,\n\t\t0xd532e7e7, 0x8b43c8c8, 0x6e593737, 0xdab76d6d,\n\t\t0x018c8d8d, 0xb164d5d5, 0x9cd24e4e, 0x49e0a9a9,\n\t\t0xd8b46c6c, 0xacfa5656, 0xf307f4f4, 0xcf25eaea,\n\t\t0xcaaf6565, 0xf48e7a7a, 0x47e9aeae, 0x10180808,\n\t\t0x6fd5baba, 0xf0887878, 0x4a6f2525, 0x5c722e2e,\n\t\t0x38241c1c, 0x57f1a6a6, 0x73c7b4b4, 0x9751c6c6,\n\t\t0xcb23e8e8, 0xa17cdddd, 0xe89c7474, 0x3e211f1f,\n\t\t0x96dd4b4b, 0x61dcbdbd, 0x0d868b8b, 0x0f858a8a,\n\t\t0xe0907070, 0x7c423e3e, 0x71c4b5b5, 0xccaa6666,\n\t\t0x90d84848, 0x06050303, 0xf701f6f6, 0x1c120e0e,\n\t\t0xc2a36161, 0x6a5f3535, 0xaef95757, 0x69d0b9b9,\n\t\t0x17918686, 0x9958c1c1, 0x3a271d1d, 0x27b99e9e,\n\t\t0xd938e1e1, 0xeb13f8f8, 0x2bb39898, 0x22331111,\n\t\t0xd2bb6969, 0xa970d9d9, 0x07898e8e, 0x33a79494,\n\t\t0x2db69b9b, 0x3c221e1e, 0x15928787, 0xc920e9e9,\n\t\t0x8749cece, 0xaaff5555, 0x50782828, 0xa57adfdf,\n\t\t0x038f8c8c, 0x59f8a1a1, 0x09808989, 0x1a170d0d,\n\t\t0x65dabfbf, 0xd731e6e6, 0x84c64242, 0xd0b86868,\n\t\t0x82c34141, 0x29b09999, 0x5a772d2d, 0x1e110f0f,\n\t\t0x7bcbb0b0, 0xa8fc5454, 0x6dd6bbbb, 0x2c3a1616,\n\t}\n};\n\n__visible const u32 crypto_fl_tab[4][256] = {\n\t{\n\t\t0x00000063, 0x0000007c, 0x00000077, 0x0000007b,\n\t\t0x000000f2, 0x0000006b, 0x0000006f, 0x000000c5,\n\t\t0x00000030, 0x00000001, 0x00000067, 0x0000002b,\n\t\t0x000000fe, 0x000000d7, 0x000000ab, 0x00000076,\n\t\t0x000000ca, 0x00000082, 0x000000c9, 0x0000007d,\n\t\t0x000000fa, 0x00000059, 0x00000047, 0x000000f0,\n\t\t0x000000ad, 0x000000d4, 0x000000a2, 0x000000af,\n\t\t0x0000009c, 0x000000a4, 0x00000072, 0x000000c0,\n\t\t0x000000b7, 0x000000fd, 0x00000093, 0x00000026,\n\t\t0x00000036, 0x0000003f, 0x000000f7, 0x000000cc,\n\t\t0x00000034, 0x000000a5, 0x000000e5, 0x000000f1,\n\t\t0x00000071, 0x000000d8, 0x00000031, 0x00000015,\n\t\t0x00000004, 0x000000c7, 0x00000023, 0x000000c3,\n\t\t0x00000018, 0x00000096, 0x00000005, 0x0000009a,\n\t\t0x00000007, 0x00000012, 0x00000080, 0x000000e2,\n\t\t0x000000eb, 0x00000027, 0x000000b2, 0x00000075,\n\t\t0x00000009, 0x00000083, 0x0000002c, 0x0000001a,\n\t\t0x0000001b, 0x0000006e, 0x0000005a, 0x000000a0,\n\t\t0x00000052, 0x0000003b, 0x000000d6, 0x000000b3,\n\t\t0x00000029, 0x000000e3, 0x0000002f, 0x00000084,\n\t\t0x00000053, 0x000000d1, 0x00000000, 0x000000ed,\n\t\t0x00000020, 0x000000fc, 0x000000b1, 0x0000005b,\n\t\t0x0000006a, 0x000000cb, 0x000000be, 0x00000039,\n\t\t0x0000004a, 0x0000004c, 0x00000058, 0x000000cf,\n\t\t0x000000d0, 0x000000ef, 0x000000aa, 0x000000fb,\n\t\t0x00000043, 0x0000004d, 0x00000033, 0x00000085,\n\t\t0x00000045, 0x000000f9, 0x00000002, 0x0000007f,\n\t\t0x00000050, 0x0000003c, 0x0000009f, 0x000000a8,\n\t\t0x00000051, 0x000000a3, 0x00000040, 0x0000008f,\n\t\t0x00000092, 0x0000009d, 0x00000038, 0x000000f5,\n\t\t0x000000bc, 0x000000b6, 0x000000da, 0x00000021,\n\t\t0x00000010, 0x000000ff, 0x000000f3, 0x000000d2,\n\t\t0x000000cd, 0x0000000c, 0x00000013, 0x000000ec,\n\t\t0x0000005f, 0x00000097, 0x00000044, 0x00000017,\n\t\t0x000000c4, 0x000000a7, 0x0000007e, 0x0000003d,\n\t\t0x00000064, 0x0000005d, 0x00000019, 0x00000073,\n\t\t0x00000060, 0x00000081, 0x0000004f, 0x000000dc,\n\t\t0x00000022, 0x0000002a, 0x00000090, 0x00000088,\n\t\t0x00000046, 0x000000ee, 0x000000b8, 0x00000014,\n\t\t0x000000de, 0x0000005e, 0x0000000b, 0x000000db,\n\t\t0x000000e0, 0x00000032, 0x0000003a, 0x0000000a,\n\t\t0x00000049, 0x00000006, 0x00000024, 0x0000005c,\n\t\t0x000000c2, 0x000000d3, 0x000000ac, 0x00000062,\n\t\t0x00000091, 0x00000095, 0x000000e4, 0x00000079,\n\t\t0x000000e7, 0x000000c8, 0x00000037, 0x0000006d,\n\t\t0x0000008d, 0x000000d5, 0x0000004e, 0x000000a9,\n\t\t0x0000006c, 0x00000056, 0x000000f4, 0x000000ea,\n\t\t0x00000065, 0x0000007a, 0x000000ae, 0x00000008,\n\t\t0x000000ba, 0x00000078, 0x00000025, 0x0000002e,\n\t\t0x0000001c, 0x000000a6, 0x000000b4, 0x000000c6,\n\t\t0x000000e8, 0x000000dd, 0x00000074, 0x0000001f,\n\t\t0x0000004b, 0x000000bd, 0x0000008b, 0x0000008a,\n\t\t0x00000070, 0x0000003e, 0x000000b5, 0x00000066,\n\t\t0x00000048, 0x00000003, 0x000000f6, 0x0000000e,\n\t\t0x00000061, 0x00000035, 0x00000057, 0x000000b9,\n\t\t0x00000086, 0x000000c1, 0x0000001d, 0x0000009e,\n\t\t0x000000e1, 0x000000f8, 0x00000098, 0x00000011,\n\t\t0x00000069, 0x000000d9, 0x0000008e, 0x00000094,\n\t\t0x0000009b, 0x0000001e, 0x00000087, 0x000000e9,\n\t\t0x000000ce, 0x00000055, 0x00000028, 0x000000df,\n\t\t0x0000008c, 0x000000a1, 0x00000089, 0x0000000d,\n\t\t0x000000bf, 0x000000e6, 0x00000042, 0x00000068,\n\t\t0x00000041, 0x00000099, 0x0000002d, 0x0000000f,\n\t\t0x000000b0, 0x00000054, 0x000000bb, 0x00000016,\n\t}, {\n\t\t0x00006300, 0x00007c00, 0x00007700, 0x00007b00,\n\t\t0x0000f200, 0x00006b00, 0x00006f00, 0x0000c500,\n\t\t0x00003000, 0x00000100, 0x00006700, 0x00002b00,\n\t\t0x0000fe00, 0x0000d700, 0x0000ab00, 0x00007600,\n\t\t0x0000ca00, 0x00008200, 0x0000c900, 0x00007d00,\n\t\t0x0000fa00, 0x00005900, 0x00004700, 0x0000f000,\n\t\t0x0000ad00, 0x0000d400, 0x0000a200, 0x0000af00,\n\t\t0x00009c00, 0x0000a400, 0x00007200, 0x0000c000,\n\t\t0x0000b700, 0x0000fd00, 0x00009300, 0x00002600,\n\t\t0x00003600, 0x00003f00, 0x0000f700, 0x0000cc00,\n\t\t0x00003400, 0x0000a500, 0x0000e500, 0x0000f100,\n\t\t0x00007100, 0x0000d800, 0x00003100, 0x00001500,\n\t\t0x00000400, 0x0000c700, 0x00002300, 0x0000c300,\n\t\t0x00001800, 0x00009600, 0x00000500, 0x00009a00,\n\t\t0x00000700, 0x00001200, 0x00008000, 0x0000e200,\n\t\t0x0000eb00, 0x00002700, 0x0000b200, 0x00007500,\n\t\t0x00000900, 0x00008300, 0x00002c00, 0x00001a00,\n\t\t0x00001b00, 0x00006e00, 0x00005a00, 0x0000a000,\n\t\t0x00005200, 0x00003b00, 0x0000d600, 0x0000b300,\n\t\t0x00002900, 0x0000e300, 0x00002f00, 0x00008400,\n\t\t0x00005300, 0x0000d100, 0x00000000, 0x0000ed00,\n\t\t0x00002000, 0x0000fc00, 0x0000b100, 0x00005b00,\n\t\t0x00006a00, 0x0000cb00, 0x0000be00, 0x00003900,\n\t\t0x00004a00, 0x00004c00, 0x00005800, 0x0000cf00,\n\t\t0x0000d000, 0x0000ef00, 0x0000aa00, 0x0000fb00,\n\t\t0x00004300, 0x00004d00, 0x00003300, 0x00008500,\n\t\t0x00004500, 0x0000f900, 0x00000200, 0x00007f00,\n\t\t0x00005000, 0x00003c00, 0x00009f00, 0x0000a800,\n\t\t0x00005100, 0x0000a300, 0x00004000, 0x00008f00,\n\t\t0x00009200, 0x00009d00, 0x00003800, 0x0000f500,\n\t\t0x0000bc00, 0x0000b600, 0x0000da00, 0x00002100,\n\t\t0x00001000, 0x0000ff00, 0x0000f300, 0x0000d200,\n\t\t0x0000cd00, 0x00000c00, 0x00001300, 0x0000ec00,\n\t\t0x00005f00, 0x00009700, 0x00004400, 0x00001700,\n\t\t0x0000c400, 0x0000a700, 0x00007e00, 0x00003d00,\n\t\t0x00006400, 0x00005d00, 0x00001900, 0x00007300,\n\t\t0x00006000, 0x00008100, 0x00004f00, 0x0000dc00,\n\t\t0x00002200, 0x00002a00, 0x00009000, 0x00008800,\n\t\t0x00004600, 0x0000ee00, 0x0000b800, 0x00001400,\n\t\t0x0000de00, 0x00005e00, 0x00000b00, 0x0000db00,\n\t\t0x0000e000, 0x00003200, 0x00003a00, 0x00000a00,\n\t\t0x00004900, 0x00000600, 0x00002400, 0x00005c00,\n\t\t0x0000c200, 0x0000d300, 0x0000ac00, 0x00006200,\n\t\t0x00009100, 0x00009500, 0x0000e400, 0x00007900,\n\t\t0x0000e700, 0x0000c800, 0x00003700, 0x00006d00,\n\t\t0x00008d00, 0x0000d500, 0x00004e00, 0x0000a900,\n\t\t0x00006c00, 0x00005600, 0x0000f400, 0x0000ea00,\n\t\t0x00006500, 0x00007a00, 0x0000ae00, 0x00000800,\n\t\t0x0000ba00, 0x00007800, 0x00002500, 0x00002e00,\n\t\t0x00001c00, 0x0000a600, 0x0000b400, 0x0000c600,\n\t\t0x0000e800, 0x0000dd00, 0x00007400, 0x00001f00,\n\t\t0x00004b00, 0x0000bd00, 0x00008b00, 0x00008a00,\n\t\t0x00007000, 0x00003e00, 0x0000b500, 0x00006600,\n\t\t0x00004800, 0x00000300, 0x0000f600, 0x00000e00,\n\t\t0x00006100, 0x00003500, 0x00005700, 0x0000b900,\n\t\t0x00008600, 0x0000c100, 0x00001d00, 0x00009e00,\n\t\t0x0000e100, 0x0000f800, 0x00009800, 0x00001100,\n\t\t0x00006900, 0x0000d900, 0x00008e00, 0x00009400,\n\t\t0x00009b00, 0x00001e00, 0x00008700, 0x0000e900,\n\t\t0x0000ce00, 0x00005500, 0x00002800, 0x0000df00,\n\t\t0x00008c00, 0x0000a100, 0x00008900, 0x00000d00,\n\t\t0x0000bf00, 0x0000e600, 0x00004200, 0x00006800,\n\t\t0x00004100, 0x00009900, 0x00002d00, 0x00000f00,\n\t\t0x0000b000, 0x00005400, 0x0000bb00, 0x00001600,\n\t}, {\n\t\t0x00630000, 0x007c0000, 0x00770000, 0x007b0000,\n\t\t0x00f20000, 0x006b0000, 0x006f0000, 0x00c50000,\n\t\t0x00300000, 0x00010000, 0x00670000, 0x002b0000,\n\t\t0x00fe0000, 0x00d70000, 0x00ab0000, 0x00760000,\n\t\t0x00ca0000, 0x00820000, 0x00c90000, 0x007d0000,\n\t\t0x00fa0000, 0x00590000, 0x00470000, 0x00f00000,\n\t\t0x00ad0000, 0x00d40000, 0x00a20000, 0x00af0000,\n\t\t0x009c0000, 0x00a40000, 0x00720000, 0x00c00000,\n\t\t0x00b70000, 0x00fd0000, 0x00930000, 0x00260000,\n\t\t0x00360000, 0x003f0000, 0x00f70000, 0x00cc0000,\n\t\t0x00340000, 0x00a50000, 0x00e50000, 0x00f10000,\n\t\t0x00710000, 0x00d80000, 0x00310000, 0x00150000,\n\t\t0x00040000, 0x00c70000, 0x00230000, 0x00c30000,\n\t\t0x00180000, 0x00960000, 0x00050000, 0x009a0000,\n\t\t0x00070000, 0x00120000, 0x00800000, 0x00e20000,\n\t\t0x00eb0000, 0x00270000, 0x00b20000, 0x00750000,\n\t\t0x00090000, 0x00830000, 0x002c0000, 0x001a0000,\n\t\t0x001b0000, 0x006e0000, 0x005a0000, 0x00a00000,\n\t\t0x00520000, 0x003b0000, 0x00d60000, 0x00b30000,\n\t\t0x00290000, 0x00e30000, 0x002f0000, 0x00840000,\n\t\t0x00530000, 0x00d10000, 0x00000000, 0x00ed0000,\n\t\t0x00200000, 0x00fc0000, 0x00b10000, 0x005b0000,\n\t\t0x006a0000, 0x00cb0000, 0x00be0000, 0x00390000,\n\t\t0x004a0000, 0x004c0000, 0x00580000, 0x00cf0000,\n\t\t0x00d00000, 0x00ef0000, 0x00aa0000, 0x00fb0000,\n\t\t0x00430000, 0x004d0000, 0x00330000, 0x00850000,\n\t\t0x00450000, 0x00f90000, 0x00020000, 0x007f0000,\n\t\t0x00500000, 0x003c0000, 0x009f0000, 0x00a80000,\n\t\t0x00510000, 0x00a30000, 0x00400000, 0x008f0000,\n\t\t0x00920000, 0x009d0000, 0x00380000, 0x00f50000,\n\t\t0x00bc0000, 0x00b60000, 0x00da0000, 0x00210000,\n\t\t0x00100000, 0x00ff0000, 0x00f30000, 0x00d20000,\n\t\t0x00cd0000, 0x000c0000, 0x00130000, 0x00ec0000,\n\t\t0x005f0000, 0x00970000, 0x00440000, 0x00170000,\n\t\t0x00c40000, 0x00a70000, 0x007e0000, 0x003d0000,\n\t\t0x00640000, 0x005d0000, 0x00190000, 0x00730000,\n\t\t0x00600000, 0x00810000, 0x004f0000, 0x00dc0000,\n\t\t0x00220000, 0x002a0000, 0x00900000, 0x00880000,\n\t\t0x00460000, 0x00ee0000, 0x00b80000, 0x00140000,\n\t\t0x00de0000, 0x005e0000, 0x000b0000, 0x00db0000,\n\t\t0x00e00000, 0x00320000, 0x003a0000, 0x000a0000,\n\t\t0x00490000, 0x00060000, 0x00240000, 0x005c0000,\n\t\t0x00c20000, 0x00d30000, 0x00ac0000, 0x00620000,\n\t\t0x00910000, 0x00950000, 0x00e40000, 0x00790000,\n\t\t0x00e70000, 0x00c80000, 0x00370000, 0x006d0000,\n\t\t0x008d0000, 0x00d50000, 0x004e0000, 0x00a90000,\n\t\t0x006c0000, 0x00560000, 0x00f40000, 0x00ea0000,\n\t\t0x00650000, 0x007a0000, 0x00ae0000, 0x00080000,\n\t\t0x00ba0000, 0x00780000, 0x00250000, 0x002e0000,\n\t\t0x001c0000, 0x00a60000, 0x00b40000, 0x00c60000,\n\t\t0x00e80000, 0x00dd0000, 0x00740000, 0x001f0000,\n\t\t0x004b0000, 0x00bd0000, 0x008b0000, 0x008a0000,\n\t\t0x00700000, 0x003e0000, 0x00b50000, 0x00660000,\n\t\t0x00480000, 0x00030000, 0x00f60000, 0x000e0000,\n\t\t0x00610000, 0x00350000, 0x00570000, 0x00b90000,\n\t\t0x00860000, 0x00c10000, 0x001d0000, 0x009e0000,\n\t\t0x00e10000, 0x00f80000, 0x00980000, 0x00110000,\n\t\t0x00690000, 0x00d90000, 0x008e0000, 0x00940000,\n\t\t0x009b0000, 0x001e0000, 0x00870000, 0x00e90000,\n\t\t0x00ce0000, 0x00550000, 0x00280000, 0x00df0000,\n\t\t0x008c0000, 0x00a10000, 0x00890000, 0x000d0000,\n\t\t0x00bf0000, 0x00e60000, 0x00420000, 0x00680000,\n\t\t0x00410000, 0x00990000, 0x002d0000, 0x000f0000,\n\t\t0x00b00000, 0x00540000, 0x00bb0000, 0x00160000,\n\t}, {\n\t\t0x63000000, 0x7c000000, 0x77000000, 0x7b000000,\n\t\t0xf2000000, 0x6b000000, 0x6f000000, 0xc5000000,\n\t\t0x30000000, 0x01000000, 0x67000000, 0x2b000000,\n\t\t0xfe000000, 0xd7000000, 0xab000000, 0x76000000,\n\t\t0xca000000, 0x82000000, 0xc9000000, 0x7d000000,\n\t\t0xfa000000, 0x59000000, 0x47000000, 0xf0000000,\n\t\t0xad000000, 0xd4000000, 0xa2000000, 0xaf000000,\n\t\t0x9c000000, 0xa4000000, 0x72000000, 0xc0000000,\n\t\t0xb7000000, 0xfd000000, 0x93000000, 0x26000000,\n\t\t0x36000000, 0x3f000000, 0xf7000000, 0xcc000000,\n\t\t0x34000000, 0xa5000000, 0xe5000000, 0xf1000000,\n\t\t0x71000000, 0xd8000000, 0x31000000, 0x15000000,\n\t\t0x04000000, 0xc7000000, 0x23000000, 0xc3000000,\n\t\t0x18000000, 0x96000000, 0x05000000, 0x9a000000,\n\t\t0x07000000, 0x12000000, 0x80000000, 0xe2000000,\n\t\t0xeb000000, 0x27000000, 0xb2000000, 0x75000000,\n\t\t0x09000000, 0x83000000, 0x2c000000, 0x1a000000,\n\t\t0x1b000000, 0x6e000000, 0x5a000000, 0xa0000000,\n\t\t0x52000000, 0x3b000000, 0xd6000000, 0xb3000000,\n\t\t0x29000000, 0xe3000000, 0x2f000000, 0x84000000,\n\t\t0x53000000, 0xd1000000, 0x00000000, 0xed000000,\n\t\t0x20000000, 0xfc000000, 0xb1000000, 0x5b000000,\n\t\t0x6a000000, 0xcb000000, 0xbe000000, 0x39000000,\n\t\t0x4a000000, 0x4c000000, 0x58000000, 0xcf000000,\n\t\t0xd0000000, 0xef000000, 0xaa000000, 0xfb000000,\n\t\t0x43000000, 0x4d000000, 0x33000000, 0x85000000,\n\t\t0x45000000, 0xf9000000, 0x02000000, 0x7f000000,\n\t\t0x50000000, 0x3c000000, 0x9f000000, 0xa8000000,\n\t\t0x51000000, 0xa3000000, 0x40000000, 0x8f000000,\n\t\t0x92000000, 0x9d000000, 0x38000000, 0xf5000000,\n\t\t0xbc000000, 0xb6000000, 0xda000000, 0x21000000,\n\t\t0x10000000, 0xff000000, 0xf3000000, 0xd2000000,\n\t\t0xcd000000, 0x0c000000, 0x13000000, 0xec000000,\n\t\t0x5f000000, 0x97000000, 0x44000000, 0x17000000,\n\t\t0xc4000000, 0xa7000000, 0x7e000000, 0x3d000000,\n\t\t0x64000000, 0x5d000000, 0x19000000, 0x73000000,\n\t\t0x60000000, 0x81000000, 0x4f000000, 0xdc000000,\n\t\t0x22000000, 0x2a000000, 0x90000000, 0x88000000,\n\t\t0x46000000, 0xee000000, 0xb8000000, 0x14000000,\n\t\t0xde000000, 0x5e000000, 0x0b000000, 0xdb000000,\n\t\t0xe0000000, 0x32000000, 0x3a000000, 0x0a000000,\n\t\t0x49000000, 0x06000000, 0x24000000, 0x5c000000,\n\t\t0xc2000000, 0xd3000000, 0xac000000, 0x62000000,\n\t\t0x91000000, 0x95000000, 0xe4000000, 0x79000000,\n\t\t0xe7000000, 0xc8000000, 0x37000000, 0x6d000000,\n\t\t0x8d000000, 0xd5000000, 0x4e000000, 0xa9000000,\n\t\t0x6c000000, 0x56000000, 0xf4000000, 0xea000000,\n\t\t0x65000000, 0x7a000000, 0xae000000, 0x08000000,\n\t\t0xba000000, 0x78000000, 0x25000000, 0x2e000000,\n\t\t0x1c000000, 0xa6000000, 0xb4000000, 0xc6000000,\n\t\t0xe8000000, 0xdd000000, 0x74000000, 0x1f000000,\n\t\t0x4b000000, 0xbd000000, 0x8b000000, 0x8a000000,\n\t\t0x70000000, 0x3e000000, 0xb5000000, 0x66000000,\n\t\t0x48000000, 0x03000000, 0xf6000000, 0x0e000000,\n\t\t0x61000000, 0x35000000, 0x57000000, 0xb9000000,\n\t\t0x86000000, 0xc1000000, 0x1d000000, 0x9e000000,\n\t\t0xe1000000, 0xf8000000, 0x98000000, 0x11000000,\n\t\t0x69000000, 0xd9000000, 0x8e000000, 0x94000000,\n\t\t0x9b000000, 0x1e000000, 0x87000000, 0xe9000000,\n\t\t0xce000000, 0x55000000, 0x28000000, 0xdf000000,\n\t\t0x8c000000, 0xa1000000, 0x89000000, 0x0d000000,\n\t\t0xbf000000, 0xe6000000, 0x42000000, 0x68000000,\n\t\t0x41000000, 0x99000000, 0x2d000000, 0x0f000000,\n\t\t0xb0000000, 0x54000000, 0xbb000000, 0x16000000,\n\t}\n};\n\n__visible const u32 crypto_it_tab[4][256] = {\n\t{\n\t\t0x50a7f451, 0x5365417e, 0xc3a4171a, 0x965e273a,\n\t\t0xcb6bab3b, 0xf1459d1f, 0xab58faac, 0x9303e34b,\n\t\t0x55fa3020, 0xf66d76ad, 0x9176cc88, 0x254c02f5,\n\t\t0xfcd7e54f, 0xd7cb2ac5, 0x80443526, 0x8fa362b5,\n\t\t0x495ab1de, 0x671bba25, 0x980eea45, 0xe1c0fe5d,\n\t\t0x02752fc3, 0x12f04c81, 0xa397468d, 0xc6f9d36b,\n\t\t0xe75f8f03, 0x959c9215, 0xeb7a6dbf, 0xda595295,\n\t\t0x2d83bed4, 0xd3217458, 0x2969e049, 0x44c8c98e,\n\t\t0x6a89c275, 0x78798ef4, 0x6b3e5899, 0xdd71b927,\n\t\t0xb64fe1be, 0x17ad88f0, 0x66ac20c9, 0xb43ace7d,\n\t\t0x184adf63, 0x82311ae5, 0x60335197, 0x457f5362,\n\t\t0xe07764b1, 0x84ae6bbb, 0x1ca081fe, 0x942b08f9,\n\t\t0x58684870, 0x19fd458f, 0x876cde94, 0xb7f87b52,\n\t\t0x23d373ab, 0xe2024b72, 0x578f1fe3, 0x2aab5566,\n\t\t0x0728ebb2, 0x03c2b52f, 0x9a7bc586, 0xa50837d3,\n\t\t0xf2872830, 0xb2a5bf23, 0xba6a0302, 0x5c8216ed,\n\t\t0x2b1ccf8a, 0x92b479a7, 0xf0f207f3, 0xa1e2694e,\n\t\t0xcdf4da65, 0xd5be0506, 0x1f6234d1, 0x8afea6c4,\n\t\t0x9d532e34, 0xa055f3a2, 0x32e18a05, 0x75ebf6a4,\n\t\t0x39ec830b, 0xaaef6040, 0x069f715e, 0x51106ebd,\n\t\t0xf98a213e, 0x3d06dd96, 0xae053edd, 0x46bde64d,\n\t\t0xb58d5491, 0x055dc471, 0x6fd40604, 0xff155060,\n\t\t0x24fb9819, 0x97e9bdd6, 0xcc434089, 0x779ed967,\n\t\t0xbd42e8b0, 0x888b8907, 0x385b19e7, 0xdbeec879,\n\t\t0x470a7ca1, 0xe90f427c, 0xc91e84f8, 0x00000000,\n\t\t0x83868009, 0x48ed2b32, 0xac70111e, 0x4e725a6c,\n\t\t0xfbff0efd, 0x5638850f, 0x1ed5ae3d, 0x27392d36,\n\t\t0x64d90f0a, 0x21a65c68, 0xd1545b9b, 0x3a2e3624,\n\t\t0xb1670a0c, 0x0fe75793, 0xd296eeb4, 0x9e919b1b,\n\t\t0x4fc5c080, 0xa220dc61, 0x694b775a, 0x161a121c,\n\t\t0x0aba93e2, 0xe52aa0c0, 0x43e0223c, 0x1d171b12,\n\t\t0x0b0d090e, 0xadc78bf2, 0xb9a8b62d, 0xc8a91e14,\n\t\t0x8519f157, 0x4c0775af, 0xbbdd99ee, 0xfd607fa3,\n\t\t0x9f2601f7, 0xbcf5725c, 0xc53b6644, 0x347efb5b,\n\t\t0x7629438b, 0xdcc623cb, 0x68fcedb6, 0x63f1e4b8,\n\t\t0xcadc31d7, 0x10856342, 0x40229713, 0x2011c684,\n\t\t0x7d244a85, 0xf83dbbd2, 0x1132f9ae, 0x6da129c7,\n\t\t0x4b2f9e1d, 0xf330b2dc, 0xec52860d, 0xd0e3c177,\n\t\t0x6c16b32b, 0x99b970a9, 0xfa489411, 0x2264e947,\n\t\t0xc48cfca8, 0x1a3ff0a0, 0xd82c7d56, 0xef903322,\n\t\t0xc74e4987, 0xc1d138d9, 0xfea2ca8c, 0x360bd498,\n\t\t0xcf81f5a6, 0x28de7aa5, 0x268eb7da, 0xa4bfad3f,\n\t\t0xe49d3a2c, 0x0d927850, 0x9bcc5f6a, 0x62467e54,\n\t\t0xc2138df6, 0xe8b8d890, 0x5ef7392e, 0xf5afc382,\n\t\t0xbe805d9f, 0x7c93d069, 0xa92dd56f, 0xb31225cf,\n\t\t0x3b99acc8, 0xa77d1810, 0x6e639ce8, 0x7bbb3bdb,\n\t\t0x097826cd, 0xf418596e, 0x01b79aec, 0xa89a4f83,\n\t\t0x656e95e6, 0x7ee6ffaa, 0x08cfbc21, 0xe6e815ef,\n\t\t0xd99be7ba, 0xce366f4a, 0xd4099fea, 0xd67cb029,\n\t\t0xafb2a431, 0x31233f2a, 0x3094a5c6, 0xc066a235,\n\t\t0x37bc4e74, 0xa6ca82fc, 0xb0d090e0, 0x15d8a733,\n\t\t0x4a9804f1, 0xf7daec41, 0x0e50cd7f, 0x2ff69117,\n\t\t0x8dd64d76, 0x4db0ef43, 0x544daacc, 0xdf0496e4,\n\t\t0xe3b5d19e, 0x1b886a4c, 0xb81f2cc1, 0x7f516546,\n\t\t0x04ea5e9d, 0x5d358c01, 0x737487fa, 0x2e410bfb,\n\t\t0x5a1d67b3, 0x52d2db92, 0x335610e9, 0x1347d66d,\n\t\t0x8c61d79a, 0x7a0ca137, 0x8e14f859, 0x893c13eb,\n\t\t0xee27a9ce, 0x35c961b7, 0xede51ce1, 0x3cb1477a,\n\t\t0x59dfd29c, 0x3f73f255, 0x79ce1418, 0xbf37c773,\n\t\t0xeacdf753, 0x5baafd5f, 0x146f3ddf, 0x86db4478,\n\t\t0x81f3afca, 0x3ec468b9, 0x2c342438, 0x5f40a3c2,\n\t\t0x72c31d16, 0x0c25e2bc, 0x8b493c28, 0x41950dff,\n\t\t0x7101a839, 0xdeb30c08, 0x9ce4b4d8, 0x90c15664,\n\t\t0x6184cb7b, 0x70b632d5, 0x745c6c48, 0x4257b8d0,\n\t}, {\n\t\t0xa7f45150, 0x65417e53, 0xa4171ac3, 0x5e273a96,\n\t\t0x6bab3bcb, 0x459d1ff1, 0x58faacab, 0x03e34b93,\n\t\t0xfa302055, 0x6d76adf6, 0x76cc8891, 0x4c02f525,\n\t\t0xd7e54ffc, 0xcb2ac5d7, 0x44352680, 0xa362b58f,\n\t\t0x5ab1de49, 0x1bba2567, 0x0eea4598, 0xc0fe5de1,\n\t\t0x752fc302, 0xf04c8112, 0x97468da3, 0xf9d36bc6,\n\t\t0x5f8f03e7, 0x9c921595, 0x7a6dbfeb, 0x595295da,\n\t\t0x83bed42d, 0x217458d3, 0x69e04929, 0xc8c98e44,\n\t\t0x89c2756a, 0x798ef478, 0x3e58996b, 0x71b927dd,\n\t\t0x4fe1beb6, 0xad88f017, 0xac20c966, 0x3ace7db4,\n\t\t0x4adf6318, 0x311ae582, 0x33519760, 0x7f536245,\n\t\t0x7764b1e0, 0xae6bbb84, 0xa081fe1c, 0x2b08f994,\n\t\t0x68487058, 0xfd458f19, 0x6cde9487, 0xf87b52b7,\n\t\t0xd373ab23, 0x024b72e2, 0x8f1fe357, 0xab55662a,\n\t\t0x28ebb207, 0xc2b52f03, 0x7bc5869a, 0x0837d3a5,\n\t\t0x872830f2, 0xa5bf23b2, 0x6a0302ba, 0x8216ed5c,\n\t\t0x1ccf8a2b, 0xb479a792, 0xf207f3f0, 0xe2694ea1,\n\t\t0xf4da65cd, 0xbe0506d5, 0x6234d11f, 0xfea6c48a,\n\t\t0x532e349d, 0x55f3a2a0, 0xe18a0532, 0xebf6a475,\n\t\t0xec830b39, 0xef6040aa, 0x9f715e06, 0x106ebd51,\n\t\t0x8a213ef9, 0x06dd963d, 0x053eddae, 0xbde64d46,\n\t\t0x8d5491b5, 0x5dc47105, 0xd406046f, 0x155060ff,\n\t\t0xfb981924, 0xe9bdd697, 0x434089cc, 0x9ed96777,\n\t\t0x42e8b0bd, 0x8b890788, 0x5b19e738, 0xeec879db,\n\t\t0x0a7ca147, 0x0f427ce9, 0x1e84f8c9, 0x00000000,\n\t\t0x86800983, 0xed2b3248, 0x70111eac, 0x725a6c4e,\n\t\t0xff0efdfb, 0x38850f56, 0xd5ae3d1e, 0x392d3627,\n\t\t0xd90f0a64, 0xa65c6821, 0x545b9bd1, 0x2e36243a,\n\t\t0x670a0cb1, 0xe757930f, 0x96eeb4d2, 0x919b1b9e,\n\t\t0xc5c0804f, 0x20dc61a2, 0x4b775a69, 0x1a121c16,\n\t\t0xba93e20a, 0x2aa0c0e5, 0xe0223c43, 0x171b121d,\n\t\t0x0d090e0b, 0xc78bf2ad, 0xa8b62db9, 0xa91e14c8,\n\t\t0x19f15785, 0x0775af4c, 0xdd99eebb, 0x607fa3fd,\n\t\t0x2601f79f, 0xf5725cbc, 0x3b6644c5, 0x7efb5b34,\n\t\t0x29438b76, 0xc623cbdc, 0xfcedb668, 0xf1e4b863,\n\t\t0xdc31d7ca, 0x85634210, 0x22971340, 0x11c68420,\n\t\t0x244a857d, 0x3dbbd2f8, 0x32f9ae11, 0xa129c76d,\n\t\t0x2f9e1d4b, 0x30b2dcf3, 0x52860dec, 0xe3c177d0,\n\t\t0x16b32b6c, 0xb970a999, 0x489411fa, 0x64e94722,\n\t\t0x8cfca8c4, 0x3ff0a01a, 0x2c7d56d8, 0x903322ef,\n\t\t0x4e4987c7, 0xd138d9c1, 0xa2ca8cfe, 0x0bd49836,\n\t\t0x81f5a6cf, 0xde7aa528, 0x8eb7da26, 0xbfad3fa4,\n\t\t0x9d3a2ce4, 0x9278500d, 0xcc5f6a9b, 0x467e5462,\n\t\t0x138df6c2, 0xb8d890e8, 0xf7392e5e, 0xafc382f5,\n\t\t0x805d9fbe, 0x93d0697c, 0x2dd56fa9, 0x1225cfb3,\n\t\t0x99acc83b, 0x7d1810a7, 0x639ce86e, 0xbb3bdb7b,\n\t\t0x7826cd09, 0x18596ef4, 0xb79aec01, 0x9a4f83a8,\n\t\t0x6e95e665, 0xe6ffaa7e, 0xcfbc2108, 0xe815efe6,\n\t\t0x9be7bad9, 0x366f4ace, 0x099fead4, 0x7cb029d6,\n\t\t0xb2a431af, 0x233f2a31, 0x94a5c630, 0x66a235c0,\n\t\t0xbc4e7437, 0xca82fca6, 0xd090e0b0, 0xd8a73315,\n\t\t0x9804f14a, 0xdaec41f7, 0x50cd7f0e, 0xf691172f,\n\t\t0xd64d768d, 0xb0ef434d, 0x4daacc54, 0x0496e4df,\n\t\t0xb5d19ee3, 0x886a4c1b, 0x1f2cc1b8, 0x5165467f,\n\t\t0xea5e9d04, 0x358c015d, 0x7487fa73, 0x410bfb2e,\n\t\t0x1d67b35a, 0xd2db9252, 0x5610e933, 0x47d66d13,\n\t\t0x61d79a8c, 0x0ca1377a, 0x14f8598e, 0x3c13eb89,\n\t\t0x27a9ceee, 0xc961b735, 0xe51ce1ed, 0xb1477a3c,\n\t\t0xdfd29c59, 0x73f2553f, 0xce141879, 0x37c773bf,\n\t\t0xcdf753ea, 0xaafd5f5b, 0x6f3ddf14, 0xdb447886,\n\t\t0xf3afca81, 0xc468b93e, 0x3424382c, 0x40a3c25f,\n\t\t0xc31d1672, 0x25e2bc0c, 0x493c288b, 0x950dff41,\n\t\t0x01a83971, 0xb30c08de, 0xe4b4d89c, 0xc1566490,\n\t\t0x84cb7b61, 0xb632d570, 0x5c6c4874, 0x57b8d042,\n\t}, {\n\t\t0xf45150a7, 0x417e5365, 0x171ac3a4, 0x273a965e,\n\t\t0xab3bcb6b, 0x9d1ff145, 0xfaacab58, 0xe34b9303,\n\t\t0x302055fa, 0x76adf66d, 0xcc889176, 0x02f5254c,\n\t\t0xe54ffcd7, 0x2ac5d7cb, 0x35268044, 0x62b58fa3,\n\t\t0xb1de495a, 0xba25671b, 0xea45980e, 0xfe5de1c0,\n\t\t0x2fc30275, 0x4c8112f0, 0x468da397, 0xd36bc6f9,\n\t\t0x8f03e75f, 0x9215959c, 0x6dbfeb7a, 0x5295da59,\n\t\t0xbed42d83, 0x7458d321, 0xe0492969, 0xc98e44c8,\n\t\t0xc2756a89, 0x8ef47879, 0x58996b3e, 0xb927dd71,\n\t\t0xe1beb64f, 0x88f017ad, 0x20c966ac, 0xce7db43a,\n\t\t0xdf63184a, 0x1ae58231, 0x51976033, 0x5362457f,\n\t\t0x64b1e077, 0x6bbb84ae, 0x81fe1ca0, 0x08f9942b,\n\t\t0x48705868, 0x458f19fd, 0xde94876c, 0x7b52b7f8,\n\t\t0x73ab23d3, 0x4b72e202, 0x1fe3578f, 0x55662aab,\n\t\t0xebb20728, 0xb52f03c2, 0xc5869a7b, 0x37d3a508,\n\t\t0x2830f287, 0xbf23b2a5, 0x0302ba6a, 0x16ed5c82,\n\t\t0xcf8a2b1c, 0x79a792b4, 0x07f3f0f2, 0x694ea1e2,\n\t\t0xda65cdf4, 0x0506d5be, 0x34d11f62, 0xa6c48afe,\n\t\t0x2e349d53, 0xf3a2a055, 0x8a0532e1, 0xf6a475eb,\n\t\t0x830b39ec, 0x6040aaef, 0x715e069f, 0x6ebd5110,\n\t\t0x213ef98a, 0xdd963d06, 0x3eddae05, 0xe64d46bd,\n\t\t0x5491b58d, 0xc471055d, 0x06046fd4, 0x5060ff15,\n\t\t0x981924fb, 0xbdd697e9, 0x4089cc43, 0xd967779e,\n\t\t0xe8b0bd42, 0x8907888b, 0x19e7385b, 0xc879dbee,\n\t\t0x7ca1470a, 0x427ce90f, 0x84f8c91e, 0x00000000,\n\t\t0x80098386, 0x2b3248ed, 0x111eac70, 0x5a6c4e72,\n\t\t0x0efdfbff, 0x850f5638, 0xae3d1ed5, 0x2d362739,\n\t\t0x0f0a64d9, 0x5c6821a6, 0x5b9bd154, 0x36243a2e,\n\t\t0x0a0cb167, 0x57930fe7, 0xeeb4d296, 0x9b1b9e91,\n\t\t0xc0804fc5, 0xdc61a220, 0x775a694b, 0x121c161a,\n\t\t0x93e20aba, 0xa0c0e52a, 0x223c43e0, 0x1b121d17,\n\t\t0x090e0b0d, 0x8bf2adc7, 0xb62db9a8, 0x1e14c8a9,\n\t\t0xf1578519, 0x75af4c07, 0x99eebbdd, 0x7fa3fd60,\n\t\t0x01f79f26, 0x725cbcf5, 0x6644c53b, 0xfb5b347e,\n\t\t0x438b7629, 0x23cbdcc6, 0xedb668fc, 0xe4b863f1,\n\t\t0x31d7cadc, 0x63421085, 0x97134022, 0xc6842011,\n\t\t0x4a857d24, 0xbbd2f83d, 0xf9ae1132, 0x29c76da1,\n\t\t0x9e1d4b2f, 0xb2dcf330, 0x860dec52, 0xc177d0e3,\n\t\t0xb32b6c16, 0x70a999b9, 0x9411fa48, 0xe9472264,\n\t\t0xfca8c48c, 0xf0a01a3f, 0x7d56d82c, 0x3322ef90,\n\t\t0x4987c74e, 0x38d9c1d1, 0xca8cfea2, 0xd498360b,\n\t\t0xf5a6cf81, 0x7aa528de, 0xb7da268e, 0xad3fa4bf,\n\t\t0x3a2ce49d, 0x78500d92, 0x5f6a9bcc, 0x7e546246,\n\t\t0x8df6c213, 0xd890e8b8, 0x392e5ef7, 0xc382f5af,\n\t\t0x5d9fbe80, 0xd0697c93, 0xd56fa92d, 0x25cfb312,\n\t\t0xacc83b99, 0x1810a77d, 0x9ce86e63, 0x3bdb7bbb,\n\t\t0x26cd0978, 0x596ef418, 0x9aec01b7, 0x4f83a89a,\n\t\t0x95e6656e, 0xffaa7ee6, 0xbc2108cf, 0x15efe6e8,\n\t\t0xe7bad99b, 0x6f4ace36, 0x9fead409, 0xb029d67c,\n\t\t0xa431afb2, 0x3f2a3123, 0xa5c63094, 0xa235c066,\n\t\t0x4e7437bc, 0x82fca6ca, 0x90e0b0d0, 0xa73315d8,\n\t\t0x04f14a98, 0xec41f7da, 0xcd7f0e50, 0x91172ff6,\n\t\t0x4d768dd6, 0xef434db0, 0xaacc544d, 0x96e4df04,\n\t\t0xd19ee3b5, 0x6a4c1b88, 0x2cc1b81f, 0x65467f51,\n\t\t0x5e9d04ea, 0x8c015d35, 0x87fa7374, 0x0bfb2e41,\n\t\t0x67b35a1d, 0xdb9252d2, 0x10e93356, 0xd66d1347,\n\t\t0xd79a8c61, 0xa1377a0c, 0xf8598e14, 0x13eb893c,\n\t\t0xa9ceee27, 0x61b735c9, 0x1ce1ede5, 0x477a3cb1,\n\t\t0xd29c59df, 0xf2553f73, 0x141879ce, 0xc773bf37,\n\t\t0xf753eacd, 0xfd5f5baa, 0x3ddf146f, 0x447886db,\n\t\t0xafca81f3, 0x68b93ec4, 0x24382c34, 0xa3c25f40,\n\t\t0x1d1672c3, 0xe2bc0c25, 0x3c288b49, 0x0dff4195,\n\t\t0xa8397101, 0x0c08deb3, 0xb4d89ce4, 0x566490c1,\n\t\t0xcb7b6184, 0x32d570b6, 0x6c48745c, 0xb8d04257,\n\t}, {\n\t\t0x5150a7f4, 0x7e536541, 0x1ac3a417, 0x3a965e27,\n\t\t0x3bcb6bab, 0x1ff1459d, 0xacab58fa, 0x4b9303e3,\n\t\t0x2055fa30, 0xadf66d76, 0x889176cc, 0xf5254c02,\n\t\t0x4ffcd7e5, 0xc5d7cb2a, 0x26804435, 0xb58fa362,\n\t\t0xde495ab1, 0x25671bba, 0x45980eea, 0x5de1c0fe,\n\t\t0xc302752f, 0x8112f04c, 0x8da39746, 0x6bc6f9d3,\n\t\t0x03e75f8f, 0x15959c92, 0xbfeb7a6d, 0x95da5952,\n\t\t0xd42d83be, 0x58d32174, 0x492969e0, 0x8e44c8c9,\n\t\t0x756a89c2, 0xf478798e, 0x996b3e58, 0x27dd71b9,\n\t\t0xbeb64fe1, 0xf017ad88, 0xc966ac20, 0x7db43ace,\n\t\t0x63184adf, 0xe582311a, 0x97603351, 0x62457f53,\n\t\t0xb1e07764, 0xbb84ae6b, 0xfe1ca081, 0xf9942b08,\n\t\t0x70586848, 0x8f19fd45, 0x94876cde, 0x52b7f87b,\n\t\t0xab23d373, 0x72e2024b, 0xe3578f1f, 0x662aab55,\n\t\t0xb20728eb, 0x2f03c2b5, 0x869a7bc5, 0xd3a50837,\n\t\t0x30f28728, 0x23b2a5bf, 0x02ba6a03, 0xed5c8216,\n\t\t0x8a2b1ccf, 0xa792b479, 0xf3f0f207, 0x4ea1e269,\n\t\t0x65cdf4da, 0x06d5be05, 0xd11f6234, 0xc48afea6,\n\t\t0x349d532e, 0xa2a055f3, 0x0532e18a, 0xa475ebf6,\n\t\t0x0b39ec83, 0x40aaef60, 0x5e069f71, 0xbd51106e,\n\t\t0x3ef98a21, 0x963d06dd, 0xddae053e, 0x4d46bde6,\n\t\t0x91b58d54, 0x71055dc4, 0x046fd406, 0x60ff1550,\n\t\t0x1924fb98, 0xd697e9bd, 0x89cc4340, 0x67779ed9,\n\t\t0xb0bd42e8, 0x07888b89, 0xe7385b19, 0x79dbeec8,\n\t\t0xa1470a7c, 0x7ce90f42, 0xf8c91e84, 0x00000000,\n\t\t0x09838680, 0x3248ed2b, 0x1eac7011, 0x6c4e725a,\n\t\t0xfdfbff0e, 0x0f563885, 0x3d1ed5ae, 0x3627392d,\n\t\t0x0a64d90f, 0x6821a65c, 0x9bd1545b, 0x243a2e36,\n\t\t0x0cb1670a, 0x930fe757, 0xb4d296ee, 0x1b9e919b,\n\t\t0x804fc5c0, 0x61a220dc, 0x5a694b77, 0x1c161a12,\n\t\t0xe20aba93, 0xc0e52aa0, 0x3c43e022, 0x121d171b,\n\t\t0x0e0b0d09, 0xf2adc78b, 0x2db9a8b6, 0x14c8a91e,\n\t\t0x578519f1, 0xaf4c0775, 0xeebbdd99, 0xa3fd607f,\n\t\t0xf79f2601, 0x5cbcf572, 0x44c53b66, 0x5b347efb,\n\t\t0x8b762943, 0xcbdcc623, 0xb668fced, 0xb863f1e4,\n\t\t0xd7cadc31, 0x42108563, 0x13402297, 0x842011c6,\n\t\t0x857d244a, 0xd2f83dbb, 0xae1132f9, 0xc76da129,\n\t\t0x1d4b2f9e, 0xdcf330b2, 0x0dec5286, 0x77d0e3c1,\n\t\t0x2b6c16b3, 0xa999b970, 0x11fa4894, 0x472264e9,\n\t\t0xa8c48cfc, 0xa01a3ff0, 0x56d82c7d, 0x22ef9033,\n\t\t0x87c74e49, 0xd9c1d138, 0x8cfea2ca, 0x98360bd4,\n\t\t0xa6cf81f5, 0xa528de7a, 0xda268eb7, 0x3fa4bfad,\n\t\t0x2ce49d3a, 0x500d9278, 0x6a9bcc5f, 0x5462467e,\n\t\t0xf6c2138d, 0x90e8b8d8, 0x2e5ef739, 0x82f5afc3,\n\t\t0x9fbe805d, 0x697c93d0, 0x6fa92dd5, 0xcfb31225,\n\t\t0xc83b99ac, 0x10a77d18, 0xe86e639c, 0xdb7bbb3b,\n\t\t0xcd097826, 0x6ef41859, 0xec01b79a, 0x83a89a4f,\n\t\t0xe6656e95, 0xaa7ee6ff, 0x2108cfbc, 0xefe6e815,\n\t\t0xbad99be7, 0x4ace366f, 0xead4099f, 0x29d67cb0,\n\t\t0x31afb2a4, 0x2a31233f, 0xc63094a5, 0x35c066a2,\n\t\t0x7437bc4e, 0xfca6ca82, 0xe0b0d090, 0x3315d8a7,\n\t\t0xf14a9804, 0x41f7daec, 0x7f0e50cd, 0x172ff691,\n\t\t0x768dd64d, 0x434db0ef, 0xcc544daa, 0xe4df0496,\n\t\t0x9ee3b5d1, 0x4c1b886a, 0xc1b81f2c, 0x467f5165,\n\t\t0x9d04ea5e, 0x015d358c, 0xfa737487, 0xfb2e410b,\n\t\t0xb35a1d67, 0x9252d2db, 0xe9335610, 0x6d1347d6,\n\t\t0x9a8c61d7, 0x377a0ca1, 0x598e14f8, 0xeb893c13,\n\t\t0xceee27a9, 0xb735c961, 0xe1ede51c, 0x7a3cb147,\n\t\t0x9c59dfd2, 0x553f73f2, 0x1879ce14, 0x73bf37c7,\n\t\t0x53eacdf7, 0x5f5baafd, 0xdf146f3d, 0x7886db44,\n\t\t0xca81f3af, 0xb93ec468, 0x382c3424, 0xc25f40a3,\n\t\t0x1672c31d, 0xbc0c25e2, 0x288b493c, 0xff41950d,\n\t\t0x397101a8, 0x08deb30c, 0xd89ce4b4, 0x6490c156,\n\t\t0x7b6184cb, 0xd570b632, 0x48745c6c, 0xd04257b8,\n\t}\n};\n\n__visible const u32 crypto_il_tab[4][256] = {\n\t{\n\t\t0x00000052, 0x00000009, 0x0000006a, 0x000000d5,\n\t\t0x00000030, 0x00000036, 0x000000a5, 0x00000038,\n\t\t0x000000bf, 0x00000040, 0x000000a3, 0x0000009e,\n\t\t0x00000081, 0x000000f3, 0x000000d7, 0x000000fb,\n\t\t0x0000007c, 0x000000e3, 0x00000039, 0x00000082,\n\t\t0x0000009b, 0x0000002f, 0x000000ff, 0x00000087,\n\t\t0x00000034, 0x0000008e, 0x00000043, 0x00000044,\n\t\t0x000000c4, 0x000000de, 0x000000e9, 0x000000cb,\n\t\t0x00000054, 0x0000007b, 0x00000094, 0x00000032,\n\t\t0x000000a6, 0x000000c2, 0x00000023, 0x0000003d,\n\t\t0x000000ee, 0x0000004c, 0x00000095, 0x0000000b,\n\t\t0x00000042, 0x000000fa, 0x000000c3, 0x0000004e,\n\t\t0x00000008, 0x0000002e, 0x000000a1, 0x00000066,\n\t\t0x00000028, 0x000000d9, 0x00000024, 0x000000b2,\n\t\t0x00000076, 0x0000005b, 0x000000a2, 0x00000049,\n\t\t0x0000006d, 0x0000008b, 0x000000d1, 0x00000025,\n\t\t0x00000072, 0x000000f8, 0x000000f6, 0x00000064,\n\t\t0x00000086, 0x00000068, 0x00000098, 0x00000016,\n\t\t0x000000d4, 0x000000a4, 0x0000005c, 0x000000cc,\n\t\t0x0000005d, 0x00000065, 0x000000b6, 0x00000092,\n\t\t0x0000006c, 0x00000070, 0x00000048, 0x00000050,\n\t\t0x000000fd, 0x000000ed, 0x000000b9, 0x000000da,\n\t\t0x0000005e, 0x00000015, 0x00000046, 0x00000057,\n\t\t0x000000a7, 0x0000008d, 0x0000009d, 0x00000084,\n\t\t0x00000090, 0x000000d8, 0x000000ab, 0x00000000,\n\t\t0x0000008c, 0x000000bc, 0x000000d3, 0x0000000a,\n\t\t0x000000f7, 0x000000e4, 0x00000058, 0x00000005,\n\t\t0x000000b8, 0x000000b3, 0x00000045, 0x00000006,\n\t\t0x000000d0, 0x0000002c, 0x0000001e, 0x0000008f,\n\t\t0x000000ca, 0x0000003f, 0x0000000f, 0x00000002,\n\t\t0x000000c1, 0x000000af, 0x000000bd, 0x00000003,\n\t\t0x00000001, 0x00000013, 0x0000008a, 0x0000006b,\n\t\t0x0000003a, 0x00000091, 0x00000011, 0x00000041,\n\t\t0x0000004f, 0x00000067, 0x000000dc, 0x000000ea,\n\t\t0x00000097, 0x000000f2, 0x000000cf, 0x000000ce,\n\t\t0x000000f0, 0x000000b4, 0x000000e6, 0x00000073,\n\t\t0x00000096, 0x000000ac, 0x00000074, 0x00000022,\n\t\t0x000000e7, 0x000000ad, 0x00000035, 0x00000085,\n\t\t0x000000e2, 0x000000f9, 0x00000037, 0x000000e8,\n\t\t0x0000001c, 0x00000075, 0x000000df, 0x0000006e,\n\t\t0x00000047, 0x000000f1, 0x0000001a, 0x00000071,\n\t\t0x0000001d, 0x00000029, 0x000000c5, 0x00000089,\n\t\t0x0000006f, 0x000000b7, 0x00000062, 0x0000000e,\n\t\t0x000000aa, 0x00000018, 0x000000be, 0x0000001b,\n\t\t0x000000fc, 0x00000056, 0x0000003e, 0x0000004b,\n\t\t0x000000c6, 0x000000d2, 0x00000079, 0x00000020,\n\t\t0x0000009a, 0x000000db, 0x000000c0, 0x000000fe,\n\t\t0x00000078, 0x000000cd, 0x0000005a, 0x000000f4,\n\t\t0x0000001f, 0x000000dd, 0x000000a8, 0x00000033,\n\t\t0x00000088, 0x00000007, 0x000000c7, 0x00000031,\n\t\t0x000000b1, 0x00000012, 0x00000010, 0x00000059,\n\t\t0x00000027, 0x00000080, 0x000000ec, 0x0000005f,\n\t\t0x00000060, 0x00000051, 0x0000007f, 0x000000a9,\n\t\t0x00000019, 0x000000b5, 0x0000004a, 0x0000000d,\n\t\t0x0000002d, 0x000000e5, 0x0000007a, 0x0000009f,\n\t\t0x00000093, 0x000000c9, 0x0000009c, 0x000000ef,\n\t\t0x000000a0, 0x000000e0, 0x0000003b, 0x0000004d,\n\t\t0x000000ae, 0x0000002a, 0x000000f5, 0x000000b0,\n\t\t0x000000c8, 0x000000eb, 0x000000bb, 0x0000003c,\n\t\t0x00000083, 0x00000053, 0x00000099, 0x00000061,\n\t\t0x00000017, 0x0000002b, 0x00000004, 0x0000007e,\n\t\t0x000000ba, 0x00000077, 0x000000d6, 0x00000026,\n\t\t0x000000e1, 0x00000069, 0x00000014, 0x00000063,\n\t\t0x00000055, 0x00000021, 0x0000000c, 0x0000007d,\n\t}, {\n\t\t0x00005200, 0x00000900, 0x00006a00, 0x0000d500,\n\t\t0x00003000, 0x00003600, 0x0000a500, 0x00003800,\n\t\t0x0000bf00, 0x00004000, 0x0000a300, 0x00009e00,\n\t\t0x00008100, 0x0000f300, 0x0000d700, 0x0000fb00,\n\t\t0x00007c00, 0x0000e300, 0x00003900, 0x00008200,\n\t\t0x00009b00, 0x00002f00, 0x0000ff00, 0x00008700,\n\t\t0x00003400, 0x00008e00, 0x00004300, 0x00004400,\n\t\t0x0000c400, 0x0000de00, 0x0000e900, 0x0000cb00,\n\t\t0x00005400, 0x00007b00, 0x00009400, 0x00003200,\n\t\t0x0000a600, 0x0000c200, 0x00002300, 0x00003d00,\n\t\t0x0000ee00, 0x00004c00, 0x00009500, 0x00000b00,\n\t\t0x00004200, 0x0000fa00, 0x0000c300, 0x00004e00,\n\t\t0x00000800, 0x00002e00, 0x0000a100, 0x00006600,\n\t\t0x00002800, 0x0000d900, 0x00002400, 0x0000b200,\n\t\t0x00007600, 0x00005b00, 0x0000a200, 0x00004900,\n\t\t0x00006d00, 0x00008b00, 0x0000d100, 0x00002500,\n\t\t0x00007200, 0x0000f800, 0x0000f600, 0x00006400,\n\t\t0x00008600, 0x00006800, 0x00009800, 0x00001600,\n\t\t0x0000d400, 0x0000a400, 0x00005c00, 0x0000cc00,\n\t\t0x00005d00, 0x00006500, 0x0000b600, 0x00009200,\n\t\t0x00006c00, 0x00007000, 0x00004800, 0x00005000,\n\t\t0x0000fd00, 0x0000ed00, 0x0000b900, 0x0000da00,\n\t\t0x00005e00, 0x00001500, 0x00004600, 0x00005700,\n\t\t0x0000a700, 0x00008d00, 0x00009d00, 0x00008400,\n\t\t0x00009000, 0x0000d800, 0x0000ab00, 0x00000000,\n\t\t0x00008c00, 0x0000bc00, 0x0000d300, 0x00000a00,\n\t\t0x0000f700, 0x0000e400, 0x00005800, 0x00000500,\n\t\t0x0000b800, 0x0000b300, 0x00004500, 0x00000600,\n\t\t0x0000d000, 0x00002c00, 0x00001e00, 0x00008f00,\n\t\t0x0000ca00, 0x00003f00, 0x00000f00, 0x00000200,\n\t\t0x0000c100, 0x0000af00, 0x0000bd00, 0x00000300,\n\t\t0x00000100, 0x00001300, 0x00008a00, 0x00006b00,\n\t\t0x00003a00, 0x00009100, 0x00001100, 0x00004100,\n\t\t0x00004f00, 0x00006700, 0x0000dc00, 0x0000ea00,\n\t\t0x00009700, 0x0000f200, 0x0000cf00, 0x0000ce00,\n\t\t0x0000f000, 0x0000b400, 0x0000e600, 0x00007300,\n\t\t0x00009600, 0x0000ac00, 0x00007400, 0x00002200,\n\t\t0x0000e700, 0x0000ad00, 0x00003500, 0x00008500,\n\t\t0x0000e200, 0x0000f900, 0x00003700, 0x0000e800,\n\t\t0x00001c00, 0x00007500, 0x0000df00, 0x00006e00,\n\t\t0x00004700, 0x0000f100, 0x00001a00, 0x00007100,\n\t\t0x00001d00, 0x00002900, 0x0000c500, 0x00008900,\n\t\t0x00006f00, 0x0000b700, 0x00006200, 0x00000e00,\n\t\t0x0000aa00, 0x00001800, 0x0000be00, 0x00001b00,\n\t\t0x0000fc00, 0x00005600, 0x00003e00, 0x00004b00,\n\t\t0x0000c600, 0x0000d200, 0x00007900, 0x00002000,\n\t\t0x00009a00, 0x0000db00, 0x0000c000, 0x0000fe00,\n\t\t0x00007800, 0x0000cd00, 0x00005a00, 0x0000f400,\n\t\t0x00001f00, 0x0000dd00, 0x0000a800, 0x00003300,\n\t\t0x00008800, 0x00000700, 0x0000c700, 0x00003100,\n\t\t0x0000b100, 0x00001200, 0x00001000, 0x00005900,\n\t\t0x00002700, 0x00008000, 0x0000ec00, 0x00005f00,\n\t\t0x00006000, 0x00005100, 0x00007f00, 0x0000a900,\n\t\t0x00001900, 0x0000b500, 0x00004a00, 0x00000d00,\n\t\t0x00002d00, 0x0000e500, 0x00007a00, 0x00009f00,\n\t\t0x00009300, 0x0000c900, 0x00009c00, 0x0000ef00,\n\t\t0x0000a000, 0x0000e000, 0x00003b00, 0x00004d00,\n\t\t0x0000ae00, 0x00002a00, 0x0000f500, 0x0000b000,\n\t\t0x0000c800, 0x0000eb00, 0x0000bb00, 0x00003c00,\n\t\t0x00008300, 0x00005300, 0x00009900, 0x00006100,\n\t\t0x00001700, 0x00002b00, 0x00000400, 0x00007e00,\n\t\t0x0000ba00, 0x00007700, 0x0000d600, 0x00002600,\n\t\t0x0000e100, 0x00006900, 0x00001400, 0x00006300,\n\t\t0x00005500, 0x00002100, 0x00000c00, 0x00007d00,\n\t}, {\n\t\t0x00520000, 0x00090000, 0x006a0000, 0x00d50000,\n\t\t0x00300000, 0x00360000, 0x00a50000, 0x00380000,\n\t\t0x00bf0000, 0x00400000, 0x00a30000, 0x009e0000,\n\t\t0x00810000, 0x00f30000, 0x00d70000, 0x00fb0000,\n\t\t0x007c0000, 0x00e30000, 0x00390000, 0x00820000,\n\t\t0x009b0000, 0x002f0000, 0x00ff0000, 0x00870000,\n\t\t0x00340000, 0x008e0000, 0x00430000, 0x00440000,\n\t\t0x00c40000, 0x00de0000, 0x00e90000, 0x00cb0000,\n\t\t0x00540000, 0x007b0000, 0x00940000, 0x00320000,\n\t\t0x00a60000, 0x00c20000, 0x00230000, 0x003d0000,\n\t\t0x00ee0000, 0x004c0000, 0x00950000, 0x000b0000,\n\t\t0x00420000, 0x00fa0000, 0x00c30000, 0x004e0000,\n\t\t0x00080000, 0x002e0000, 0x00a10000, 0x00660000,\n\t\t0x00280000, 0x00d90000, 0x00240000, 0x00b20000,\n\t\t0x00760000, 0x005b0000, 0x00a20000, 0x00490000,\n\t\t0x006d0000, 0x008b0000, 0x00d10000, 0x00250000,\n\t\t0x00720000, 0x00f80000, 0x00f60000, 0x00640000,\n\t\t0x00860000, 0x00680000, 0x00980000, 0x00160000,\n\t\t0x00d40000, 0x00a40000, 0x005c0000, 0x00cc0000,\n\t\t0x005d0000, 0x00650000, 0x00b60000, 0x00920000,\n\t\t0x006c0000, 0x00700000, 0x00480000, 0x00500000,\n\t\t0x00fd0000, 0x00ed0000, 0x00b90000, 0x00da0000,\n\t\t0x005e0000, 0x00150000, 0x00460000, 0x00570000,\n\t\t0x00a70000, 0x008d0000, 0x009d0000, 0x00840000,\n\t\t0x00900000, 0x00d80000, 0x00ab0000, 0x00000000,\n\t\t0x008c0000, 0x00bc0000, 0x00d30000, 0x000a0000,\n\t\t0x00f70000, 0x00e40000, 0x00580000, 0x00050000,\n\t\t0x00b80000, 0x00b30000, 0x00450000, 0x00060000,\n\t\t0x00d00000, 0x002c0000, 0x001e0000, 0x008f0000,\n\t\t0x00ca0000, 0x003f0000, 0x000f0000, 0x00020000,\n\t\t0x00c10000, 0x00af0000, 0x00bd0000, 0x00030000,\n\t\t0x00010000, 0x00130000, 0x008a0000, 0x006b0000,\n\t\t0x003a0000, 0x00910000, 0x00110000, 0x00410000,\n\t\t0x004f0000, 0x00670000, 0x00dc0000, 0x00ea0000,\n\t\t0x00970000, 0x00f20000, 0x00cf0000, 0x00ce0000,\n\t\t0x00f00000, 0x00b40000, 0x00e60000, 0x00730000,\n\t\t0x00960000, 0x00ac0000, 0x00740000, 0x00220000,\n\t\t0x00e70000, 0x00ad0000, 0x00350000, 0x00850000,\n\t\t0x00e20000, 0x00f90000, 0x00370000, 0x00e80000,\n\t\t0x001c0000, 0x00750000, 0x00df0000, 0x006e0000,\n\t\t0x00470000, 0x00f10000, 0x001a0000, 0x00710000,\n\t\t0x001d0000, 0x00290000, 0x00c50000, 0x00890000,\n\t\t0x006f0000, 0x00b70000, 0x00620000, 0x000e0000,\n\t\t0x00aa0000, 0x00180000, 0x00be0000, 0x001b0000,\n\t\t0x00fc0000, 0x00560000, 0x003e0000, 0x004b0000,\n\t\t0x00c60000, 0x00d20000, 0x00790000, 0x00200000,\n\t\t0x009a0000, 0x00db0000, 0x00c00000, 0x00fe0000,\n\t\t0x00780000, 0x00cd0000, 0x005a0000, 0x00f40000,\n\t\t0x001f0000, 0x00dd0000, 0x00a80000, 0x00330000,\n\t\t0x00880000, 0x00070000, 0x00c70000, 0x00310000,\n\t\t0x00b10000, 0x00120000, 0x00100000, 0x00590000,\n\t\t0x00270000, 0x00800000, 0x00ec0000, 0x005f0000,\n\t\t0x00600000, 0x00510000, 0x007f0000, 0x00a90000,\n\t\t0x00190000, 0x00b50000, 0x004a0000, 0x000d0000,\n\t\t0x002d0000, 0x00e50000, 0x007a0000, 0x009f0000,\n\t\t0x00930000, 0x00c90000, 0x009c0000, 0x00ef0000,\n\t\t0x00a00000, 0x00e00000, 0x003b0000, 0x004d0000,\n\t\t0x00ae0000, 0x002a0000, 0x00f50000, 0x00b00000,\n\t\t0x00c80000, 0x00eb0000, 0x00bb0000, 0x003c0000,\n\t\t0x00830000, 0x00530000, 0x00990000, 0x00610000,\n\t\t0x00170000, 0x002b0000, 0x00040000, 0x007e0000,\n\t\t0x00ba0000, 0x00770000, 0x00d60000, 0x00260000,\n\t\t0x00e10000, 0x00690000, 0x00140000, 0x00630000,\n\t\t0x00550000, 0x00210000, 0x000c0000, 0x007d0000,\n\t}, {\n\t\t0x52000000, 0x09000000, 0x6a000000, 0xd5000000,\n\t\t0x30000000, 0x36000000, 0xa5000000, 0x38000000,\n\t\t0xbf000000, 0x40000000, 0xa3000000, 0x9e000000,\n\t\t0x81000000, 0xf3000000, 0xd7000000, 0xfb000000,\n\t\t0x7c000000, 0xe3000000, 0x39000000, 0x82000000,\n\t\t0x9b000000, 0x2f000000, 0xff000000, 0x87000000,\n\t\t0x34000000, 0x8e000000, 0x43000000, 0x44000000,\n\t\t0xc4000000, 0xde000000, 0xe9000000, 0xcb000000,\n\t\t0x54000000, 0x7b000000, 0x94000000, 0x32000000,\n\t\t0xa6000000, 0xc2000000, 0x23000000, 0x3d000000,\n\t\t0xee000000, 0x4c000000, 0x95000000, 0x0b000000,\n\t\t0x42000000, 0xfa000000, 0xc3000000, 0x4e000000,\n\t\t0x08000000, 0x2e000000, 0xa1000000, 0x66000000,\n\t\t0x28000000, 0xd9000000, 0x24000000, 0xb2000000,\n\t\t0x76000000, 0x5b000000, 0xa2000000, 0x49000000,\n\t\t0x6d000000, 0x8b000000, 0xd1000000, 0x25000000,\n\t\t0x72000000, 0xf8000000, 0xf6000000, 0x64000000,\n\t\t0x86000000, 0x68000000, 0x98000000, 0x16000000,\n\t\t0xd4000000, 0xa4000000, 0x5c000000, 0xcc000000,\n\t\t0x5d000000, 0x65000000, 0xb6000000, 0x92000000,\n\t\t0x6c000000, 0x70000000, 0x48000000, 0x50000000,\n\t\t0xfd000000, 0xed000000, 0xb9000000, 0xda000000,\n\t\t0x5e000000, 0x15000000, 0x46000000, 0x57000000,\n\t\t0xa7000000, 0x8d000000, 0x9d000000, 0x84000000,\n\t\t0x90000000, 0xd8000000, 0xab000000, 0x00000000,\n\t\t0x8c000000, 0xbc000000, 0xd3000000, 0x0a000000,\n\t\t0xf7000000, 0xe4000000, 0x58000000, 0x05000000,\n\t\t0xb8000000, 0xb3000000, 0x45000000, 0x06000000,\n\t\t0xd0000000, 0x2c000000, 0x1e000000, 0x8f000000,\n\t\t0xca000000, 0x3f000000, 0x0f000000, 0x02000000,\n\t\t0xc1000000, 0xaf000000, 0xbd000000, 0x03000000,\n\t\t0x01000000, 0x13000000, 0x8a000000, 0x6b000000,\n\t\t0x3a000000, 0x91000000, 0x11000000, 0x41000000,\n\t\t0x4f000000, 0x67000000, 0xdc000000, 0xea000000,\n\t\t0x97000000, 0xf2000000, 0xcf000000, 0xce000000,\n\t\t0xf0000000, 0xb4000000, 0xe6000000, 0x73000000,\n\t\t0x96000000, 0xac000000, 0x74000000, 0x22000000,\n\t\t0xe7000000, 0xad000000, 0x35000000, 0x85000000,\n\t\t0xe2000000, 0xf9000000, 0x37000000, 0xe8000000,\n\t\t0x1c000000, 0x75000000, 0xdf000000, 0x6e000000,\n\t\t0x47000000, 0xf1000000, 0x1a000000, 0x71000000,\n\t\t0x1d000000, 0x29000000, 0xc5000000, 0x89000000,\n\t\t0x6f000000, 0xb7000000, 0x62000000, 0x0e000000,\n\t\t0xaa000000, 0x18000000, 0xbe000000, 0x1b000000,\n\t\t0xfc000000, 0x56000000, 0x3e000000, 0x4b000000,\n\t\t0xc6000000, 0xd2000000, 0x79000000, 0x20000000,\n\t\t0x9a000000, 0xdb000000, 0xc0000000, 0xfe000000,\n\t\t0x78000000, 0xcd000000, 0x5a000000, 0xf4000000,\n\t\t0x1f000000, 0xdd000000, 0xa8000000, 0x33000000,\n\t\t0x88000000, 0x07000000, 0xc7000000, 0x31000000,\n\t\t0xb1000000, 0x12000000, 0x10000000, 0x59000000,\n\t\t0x27000000, 0x80000000, 0xec000000, 0x5f000000,\n\t\t0x60000000, 0x51000000, 0x7f000000, 0xa9000000,\n\t\t0x19000000, 0xb5000000, 0x4a000000, 0x0d000000,\n\t\t0x2d000000, 0xe5000000, 0x7a000000, 0x9f000000,\n\t\t0x93000000, 0xc9000000, 0x9c000000, 0xef000000,\n\t\t0xa0000000, 0xe0000000, 0x3b000000, 0x4d000000,\n\t\t0xae000000, 0x2a000000, 0xf5000000, 0xb0000000,\n\t\t0xc8000000, 0xeb000000, 0xbb000000, 0x3c000000,\n\t\t0x83000000, 0x53000000, 0x99000000, 0x61000000,\n\t\t0x17000000, 0x2b000000, 0x04000000, 0x7e000000,\n\t\t0xba000000, 0x77000000, 0xd6000000, 0x26000000,\n\t\t0xe1000000, 0x69000000, 0x14000000, 0x63000000,\n\t\t0x55000000, 0x21000000, 0x0c000000, 0x7d000000,\n\t}\n};\n\nEXPORT_SYMBOL_GPL(crypto_ft_tab);\nEXPORT_SYMBOL_GPL(crypto_fl_tab);\nEXPORT_SYMBOL_GPL(crypto_it_tab);\nEXPORT_SYMBOL_GPL(crypto_il_tab);\n\n/* initialise the key schedule from the user supplied key */\n\n#define star_x(x) (((x) & 0x7f7f7f7f) << 1) ^ ((((x) & 0x80808080) >> 7) * 0x1b)\n\n#define imix_col(y, x)\tdo {\t\t\\\n\tu\t= star_x(x);\t\t\\\n\tv\t= star_x(u);\t\t\\\n\tw\t= star_x(v);\t\t\\\n\tt\t= w ^ (x);\t\t\\\n\t(y)\t= u ^ v ^ w;\t\t\\\n\t(y)\t^= ror32(u ^ t, 8) ^\t\\\n\t\tror32(v ^ t, 16) ^\t\\\n\t\tror32(t, 24);\t\t\\\n} while (0)\n\n#define ls_box(x)\t\t\\\n\tcrypto_fl_tab[0][byte(x, 0)] ^\t\\\n\tcrypto_fl_tab[1][byte(x, 1)] ^\t\\\n\tcrypto_fl_tab[2][byte(x, 2)] ^\t\\\n\tcrypto_fl_tab[3][byte(x, 3)]\n\n#define loop4(i)\tdo {\t\t\\\n\tt = ror32(t, 8);\t\t\\\n\tt = ls_box(t) ^ rco_tab[i];\t\\\n\tt ^= ctx->key_enc[4 * i];\t\t\\\n\tctx->key_enc[4 * i + 4] = t;\t\t\\\n\tt ^= ctx->key_enc[4 * i + 1];\t\t\\\n\tctx->key_enc[4 * i + 5] = t;\t\t\\\n\tt ^= ctx->key_enc[4 * i + 2];\t\t\\\n\tctx->key_enc[4 * i + 6] = t;\t\t\\\n\tt ^= ctx->key_enc[4 * i + 3];\t\t\\\n\tctx->key_enc[4 * i + 7] = t;\t\t\\\n} while (0)\n\n#define loop6(i)\tdo {\t\t\\\n\tt = ror32(t, 8);\t\t\\\n\tt = ls_box(t) ^ rco_tab[i];\t\\\n\tt ^= ctx->key_enc[6 * i];\t\t\\\n\tctx->key_enc[6 * i + 6] = t;\t\t\\\n\tt ^= ctx->key_enc[6 * i + 1];\t\t\\\n\tctx->key_enc[6 * i + 7] = t;\t\t\\\n\tt ^= ctx->key_enc[6 * i + 2];\t\t\\\n\tctx->key_enc[6 * i + 8] = t;\t\t\\\n\tt ^= ctx->key_enc[6 * i + 3];\t\t\\\n\tctx->key_enc[6 * i + 9] = t;\t\t\\\n\tt ^= ctx->key_enc[6 * i + 4];\t\t\\\n\tctx->key_enc[6 * i + 10] = t;\t\t\\\n\tt ^= ctx->key_enc[6 * i + 5];\t\t\\\n\tctx->key_enc[6 * i + 11] = t;\t\t\\\n} while (0)\n\n#define loop8tophalf(i)\tdo {\t\t\t\\\n\tt = ror32(t, 8);\t\t\t\\\n\tt = ls_box(t) ^ rco_tab[i];\t\t\\\n\tt ^= ctx->key_enc[8 * i];\t\t\t\\\n\tctx->key_enc[8 * i + 8] = t;\t\t\t\\\n\tt ^= ctx->key_enc[8 * i + 1];\t\t\t\\\n\tctx->key_enc[8 * i + 9] = t;\t\t\t\\\n\tt ^= ctx->key_enc[8 * i + 2];\t\t\t\\\n\tctx->key_enc[8 * i + 10] = t;\t\t\t\\\n\tt ^= ctx->key_enc[8 * i + 3];\t\t\t\\\n\tctx->key_enc[8 * i + 11] = t;\t\t\t\\\n} while (0)\n\n#define loop8(i)\tdo {\t\t\t\t\\\n\tloop8tophalf(i);\t\t\t\t\\\n\tt  = ctx->key_enc[8 * i + 4] ^ ls_box(t);\t\\\n\tctx->key_enc[8 * i + 12] = t;\t\t\t\\\n\tt ^= ctx->key_enc[8 * i + 5];\t\t\t\\\n\tctx->key_enc[8 * i + 13] = t;\t\t\t\\\n\tt ^= ctx->key_enc[8 * i + 6];\t\t\t\\\n\tctx->key_enc[8 * i + 14] = t;\t\t\t\\\n\tt ^= ctx->key_enc[8 * i + 7];\t\t\t\\\n\tctx->key_enc[8 * i + 15] = t;\t\t\t\\\n} while (0)\n\n/**\n * crypto_aes_expand_key - Expands the AES key as described in FIPS-197\n * @ctx:\tThe location where the computed key will be stored.\n * @in_key:\tThe supplied key.\n * @key_len:\tThe length of the supplied key.\n *\n * Returns 0 on success. The function fails only if an invalid key size (or\n * pointer) is supplied.\n * The expanded key size is 240 bytes (max of 14 rounds with a unique 16 bytes\n * key schedule plus a 16 bytes key which is used before the first round).\n * The decryption key is prepared for the \"Equivalent Inverse Cipher\" as\n * described in FIPS-197. The first slot (16 bytes) of each key (enc or dec) is\n * for the initial combination, the second slot for the first round and so on.\n */\nint crypto_aes_expand_key(struct crypto_aes_ctx *ctx, const u8 *in_key,\n\t\tunsigned int key_len)\n{\n\tconst __le32 *key = (const __le32 *)in_key;\n\tu32 i, t, u, v, w, j;\n\n\tif (key_len != AES_KEYSIZE_128 && key_len != AES_KEYSIZE_192 &&\n\t\t\tkey_len != AES_KEYSIZE_256)\n\t\treturn -EINVAL;\n\n\tctx->key_length = key_len;\n\n\tctx->key_dec[key_len + 24] = ctx->key_enc[0] = le32_to_cpu(key[0]);\n\tctx->key_dec[key_len + 25] = ctx->key_enc[1] = le32_to_cpu(key[1]);\n\tctx->key_dec[key_len + 26] = ctx->key_enc[2] = le32_to_cpu(key[2]);\n\tctx->key_dec[key_len + 27] = ctx->key_enc[3] = le32_to_cpu(key[3]);\n\n\tswitch (key_len) {\n\tcase AES_KEYSIZE_128:\n\t\tt = ctx->key_enc[3];\n\t\tfor (i = 0; i < 10; ++i)\n\t\t\tloop4(i);\n\t\tbreak;\n\n\tcase AES_KEYSIZE_192:\n\t\tctx->key_enc[4] = le32_to_cpu(key[4]);\n\t\tt = ctx->key_enc[5] = le32_to_cpu(key[5]);\n\t\tfor (i = 0; i < 8; ++i)\n\t\t\tloop6(i);\n\t\tbreak;\n\n\tcase AES_KEYSIZE_256:\n\t\tctx->key_enc[4] = le32_to_cpu(key[4]);\n\t\tctx->key_enc[5] = le32_to_cpu(key[5]);\n\t\tctx->key_enc[6] = le32_to_cpu(key[6]);\n\t\tt = ctx->key_enc[7] = le32_to_cpu(key[7]);\n\t\tfor (i = 0; i < 6; ++i)\n\t\t\tloop8(i);\n\t\tloop8tophalf(i);\n\t\tbreak;\n\t}\n\n\tctx->key_dec[0] = ctx->key_enc[key_len + 24];\n\tctx->key_dec[1] = ctx->key_enc[key_len + 25];\n\tctx->key_dec[2] = ctx->key_enc[key_len + 26];\n\tctx->key_dec[3] = ctx->key_enc[key_len + 27];\n\n\tfor (i = 4; i < key_len + 24; ++i) {\n\t\tj = key_len + 24 - (i & ~3) + (i & 3);\n\t\timix_col(ctx->key_dec[j], ctx->key_enc[i]);\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(crypto_aes_expand_key);\n\n/**\n * crypto_aes_set_key - Set the AES key.\n * @tfm:\tThe %crypto_tfm that is used in the context.\n * @in_key:\tThe input key.\n * @key_len:\tThe size of the key.\n *\n * Returns 0 on success, on failure the %CRYPTO_TFM_RES_BAD_KEY_LEN flag in tfm\n * is set. The function uses crypto_aes_expand_key() to expand the key.\n * &crypto_aes_ctx _must_ be the private data embedded in @tfm which is\n * retrieved with crypto_tfm_ctx().\n */\nint crypto_aes_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\tunsigned int key_len)\n{\n\tstruct crypto_aes_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tint ret;\n\n\tret = crypto_aes_expand_key(ctx, in_key, key_len);\n\tif (!ret)\n\t\treturn 0;\n\n\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\treturn -EINVAL;\n}\nEXPORT_SYMBOL_GPL(crypto_aes_set_key);\n\n/* encrypt a block of text */\n\n#define f_rn(bo, bi, n, k)\tdo {\t\t\t\t\\\n\tbo[n] = crypto_ft_tab[0][byte(bi[n], 0)] ^\t\t\t\\\n\t\tcrypto_ft_tab[1][byte(bi[(n + 1) & 3], 1)] ^\t\t\\\n\t\tcrypto_ft_tab[2][byte(bi[(n + 2) & 3], 2)] ^\t\t\\\n\t\tcrypto_ft_tab[3][byte(bi[(n + 3) & 3], 3)] ^ *(k + n);\t\\\n} while (0)\n\n#define f_nround(bo, bi, k)\tdo {\\\n\tf_rn(bo, bi, 0, k);\t\\\n\tf_rn(bo, bi, 1, k);\t\\\n\tf_rn(bo, bi, 2, k);\t\\\n\tf_rn(bo, bi, 3, k);\t\\\n\tk += 4;\t\t\t\\\n} while (0)\n\n#define f_rl(bo, bi, n, k)\tdo {\t\t\t\t\\\n\tbo[n] = crypto_fl_tab[0][byte(bi[n], 0)] ^\t\t\t\\\n\t\tcrypto_fl_tab[1][byte(bi[(n + 1) & 3], 1)] ^\t\t\\\n\t\tcrypto_fl_tab[2][byte(bi[(n + 2) & 3], 2)] ^\t\t\\\n\t\tcrypto_fl_tab[3][byte(bi[(n + 3) & 3], 3)] ^ *(k + n);\t\\\n} while (0)\n\n#define f_lround(bo, bi, k)\tdo {\\\n\tf_rl(bo, bi, 0, k);\t\\\n\tf_rl(bo, bi, 1, k);\t\\\n\tf_rl(bo, bi, 2, k);\t\\\n\tf_rl(bo, bi, 3, k);\t\\\n} while (0)\n\nstatic void aes_encrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tconst struct crypto_aes_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *src = (const __le32 *)in;\n\t__le32 *dst = (__le32 *)out;\n\tu32 b0[4], b1[4];\n\tconst u32 *kp = ctx->key_enc + 4;\n\tconst int key_len = ctx->key_length;\n\n\tb0[0] = le32_to_cpu(src[0]) ^ ctx->key_enc[0];\n\tb0[1] = le32_to_cpu(src[1]) ^ ctx->key_enc[1];\n\tb0[2] = le32_to_cpu(src[2]) ^ ctx->key_enc[2];\n\tb0[3] = le32_to_cpu(src[3]) ^ ctx->key_enc[3];\n\n\tif (key_len > 24) {\n\t\tf_nround(b1, b0, kp);\n\t\tf_nround(b0, b1, kp);\n\t}\n\n\tif (key_len > 16) {\n\t\tf_nround(b1, b0, kp);\n\t\tf_nround(b0, b1, kp);\n\t}\n\n\tf_nround(b1, b0, kp);\n\tf_nround(b0, b1, kp);\n\tf_nround(b1, b0, kp);\n\tf_nround(b0, b1, kp);\n\tf_nround(b1, b0, kp);\n\tf_nround(b0, b1, kp);\n\tf_nround(b1, b0, kp);\n\tf_nround(b0, b1, kp);\n\tf_nround(b1, b0, kp);\n\tf_lround(b0, b1, kp);\n\n\tdst[0] = cpu_to_le32(b0[0]);\n\tdst[1] = cpu_to_le32(b0[1]);\n\tdst[2] = cpu_to_le32(b0[2]);\n\tdst[3] = cpu_to_le32(b0[3]);\n}\n\n/* decrypt a block of text */\n\n#define i_rn(bo, bi, n, k)\tdo {\t\t\t\t\\\n\tbo[n] = crypto_it_tab[0][byte(bi[n], 0)] ^\t\t\t\\\n\t\tcrypto_it_tab[1][byte(bi[(n + 3) & 3], 1)] ^\t\t\\\n\t\tcrypto_it_tab[2][byte(bi[(n + 2) & 3], 2)] ^\t\t\\\n\t\tcrypto_it_tab[3][byte(bi[(n + 1) & 3], 3)] ^ *(k + n);\t\\\n} while (0)\n\n#define i_nround(bo, bi, k)\tdo {\\\n\ti_rn(bo, bi, 0, k);\t\\\n\ti_rn(bo, bi, 1, k);\t\\\n\ti_rn(bo, bi, 2, k);\t\\\n\ti_rn(bo, bi, 3, k);\t\\\n\tk += 4;\t\t\t\\\n} while (0)\n\n#define i_rl(bo, bi, n, k)\tdo {\t\t\t\\\n\tbo[n] = crypto_il_tab[0][byte(bi[n], 0)] ^\t\t\\\n\tcrypto_il_tab[1][byte(bi[(n + 3) & 3], 1)] ^\t\t\\\n\tcrypto_il_tab[2][byte(bi[(n + 2) & 3], 2)] ^\t\t\\\n\tcrypto_il_tab[3][byte(bi[(n + 1) & 3], 3)] ^ *(k + n);\t\\\n} while (0)\n\n#define i_lround(bo, bi, k)\tdo {\\\n\ti_rl(bo, bi, 0, k);\t\\\n\ti_rl(bo, bi, 1, k);\t\\\n\ti_rl(bo, bi, 2, k);\t\\\n\ti_rl(bo, bi, 3, k);\t\\\n} while (0)\n\nstatic void aes_decrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tconst struct crypto_aes_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *src = (const __le32 *)in;\n\t__le32 *dst = (__le32 *)out;\n\tu32 b0[4], b1[4];\n\tconst int key_len = ctx->key_length;\n\tconst u32 *kp = ctx->key_dec + 4;\n\n\tb0[0] = le32_to_cpu(src[0]) ^  ctx->key_dec[0];\n\tb0[1] = le32_to_cpu(src[1]) ^  ctx->key_dec[1];\n\tb0[2] = le32_to_cpu(src[2]) ^  ctx->key_dec[2];\n\tb0[3] = le32_to_cpu(src[3]) ^  ctx->key_dec[3];\n\n\tif (key_len > 24) {\n\t\ti_nround(b1, b0, kp);\n\t\ti_nround(b0, b1, kp);\n\t}\n\n\tif (key_len > 16) {\n\t\ti_nround(b1, b0, kp);\n\t\ti_nround(b0, b1, kp);\n\t}\n\n\ti_nround(b1, b0, kp);\n\ti_nround(b0, b1, kp);\n\ti_nround(b1, b0, kp);\n\ti_nround(b0, b1, kp);\n\ti_nround(b1, b0, kp);\n\ti_nround(b0, b1, kp);\n\ti_nround(b1, b0, kp);\n\ti_nround(b0, b1, kp);\n\ti_nround(b1, b0, kp);\n\ti_lround(b0, b1, kp);\n\n\tdst[0] = cpu_to_le32(b0[0]);\n\tdst[1] = cpu_to_le32(b0[1]);\n\tdst[2] = cpu_to_le32(b0[2]);\n\tdst[3] = cpu_to_le32(b0[3]);\n}\n\nstatic struct crypto_alg aes_alg = {\n\t.cra_name\t\t=\t\"aes\",\n\t.cra_driver_name\t=\t\"aes-generic\",\n\t.cra_priority\t\t=\t100,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tAES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct crypto_aes_ctx),\n\t.cra_alignmask\t\t=\t3,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.cipher = {\n\t\t\t.cia_min_keysize\t=\tAES_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t=\tAES_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t=\tcrypto_aes_set_key,\n\t\t\t.cia_encrypt\t\t=\taes_encrypt,\n\t\t\t.cia_decrypt\t\t=\taes_decrypt\n\t\t}\n\t}\n};\n\nstatic int __init aes_init(void)\n{\n\treturn crypto_register_alg(&aes_alg);\n}\n\nstatic void __exit aes_fini(void)\n{\n\tcrypto_unregister_alg(&aes_alg);\n}\n\nmodule_init(aes_init);\nmodule_exit(aes_fini);\n\nMODULE_DESCRIPTION(\"Rijndael (AES) Cipher Algorithm\");\nMODULE_LICENSE(\"Dual BSD/GPL\");\nMODULE_ALIAS_CRYPTO(\"aes\");\n", "/*\n * PRNG: Pseudo Random Number Generator\n *       Based on NIST Recommended PRNG From ANSI X9.31 Appendix A.2.4 using\n *       AES 128 cipher\n *\n *  (C) Neil Horman <nhorman@tuxdriver.com>\n *\n *  This program is free software; you can redistribute it and/or modify it\n *  under the terms of the GNU General Public License as published by the\n *  Free Software Foundation; either version 2 of the License, or (at your\n *  any later version.\n *\n *\n */\n\n#include <crypto/internal/rng.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/moduleparam.h>\n#include <linux/string.h>\n\n#include \"internal.h\"\n\n#define DEFAULT_PRNG_KEY \"0123456789abcdef\"\n#define DEFAULT_PRNG_KSZ 16\n#define DEFAULT_BLK_SZ 16\n#define DEFAULT_V_SEED \"zaybxcwdveuftgsh\"\n\n/*\n * Flags for the prng_context flags field\n */\n\n#define PRNG_FIXED_SIZE 0x1\n#define PRNG_NEED_RESET 0x2\n\n/*\n * Note: DT is our counter value\n *\t I is our intermediate value\n *\t V is our seed vector\n * See http://csrc.nist.gov/groups/STM/cavp/documents/rng/931rngext.pdf\n * for implementation details\n */\n\n\nstruct prng_context {\n\tspinlock_t prng_lock;\n\tunsigned char rand_data[DEFAULT_BLK_SZ];\n\tunsigned char last_rand_data[DEFAULT_BLK_SZ];\n\tunsigned char DT[DEFAULT_BLK_SZ];\n\tunsigned char I[DEFAULT_BLK_SZ];\n\tunsigned char V[DEFAULT_BLK_SZ];\n\tu32 rand_data_valid;\n\tstruct crypto_cipher *tfm;\n\tu32 flags;\n};\n\nstatic int dbg;\n\nstatic void hexdump(char *note, unsigned char *buf, unsigned int len)\n{\n\tif (dbg) {\n\t\tprintk(KERN_CRIT \"%s\", note);\n\t\tprint_hex_dump(KERN_CONT, \"\", DUMP_PREFIX_OFFSET,\n\t\t\t\t16, 1,\n\t\t\t\tbuf, len, false);\n\t}\n}\n\n#define dbgprint(format, args...) do {\\\nif (dbg)\\\n\tprintk(format, ##args);\\\n} while (0)\n\nstatic void xor_vectors(unsigned char *in1, unsigned char *in2,\n\t\t\tunsigned char *out, unsigned int size)\n{\n\tint i;\n\n\tfor (i = 0; i < size; i++)\n\t\tout[i] = in1[i] ^ in2[i];\n\n}\n/*\n * Returns DEFAULT_BLK_SZ bytes of random data per call\n * returns 0 if generation succeeded, <0 if something went wrong\n */\nstatic int _get_more_prng_bytes(struct prng_context *ctx, int cont_test)\n{\n\tint i;\n\tunsigned char tmp[DEFAULT_BLK_SZ];\n\tunsigned char *output = NULL;\n\n\n\tdbgprint(KERN_CRIT \"Calling _get_more_prng_bytes for context %p\\n\",\n\t\tctx);\n\n\thexdump(\"Input DT: \", ctx->DT, DEFAULT_BLK_SZ);\n\thexdump(\"Input I: \", ctx->I, DEFAULT_BLK_SZ);\n\thexdump(\"Input V: \", ctx->V, DEFAULT_BLK_SZ);\n\n\t/*\n\t * This algorithm is a 3 stage state machine\n\t */\n\tfor (i = 0; i < 3; i++) {\n\n\t\tswitch (i) {\n\t\tcase 0:\n\t\t\t/*\n\t\t\t * Start by encrypting the counter value\n\t\t\t * This gives us an intermediate value I\n\t\t\t */\n\t\t\tmemcpy(tmp, ctx->DT, DEFAULT_BLK_SZ);\n\t\t\toutput = ctx->I;\n\t\t\thexdump(\"tmp stage 0: \", tmp, DEFAULT_BLK_SZ);\n\t\t\tbreak;\n\t\tcase 1:\n\n\t\t\t/*\n\t\t\t * Next xor I with our secret vector V\n\t\t\t * encrypt that result to obtain our\n\t\t\t * pseudo random data which we output\n\t\t\t */\n\t\t\txor_vectors(ctx->I, ctx->V, tmp, DEFAULT_BLK_SZ);\n\t\t\thexdump(\"tmp stage 1: \", tmp, DEFAULT_BLK_SZ);\n\t\t\toutput = ctx->rand_data;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\t/*\n\t\t\t * First check that we didn't produce the same\n\t\t\t * random data that we did last time around through this\n\t\t\t */\n\t\t\tif (!memcmp(ctx->rand_data, ctx->last_rand_data,\n\t\t\t\t\tDEFAULT_BLK_SZ)) {\n\t\t\t\tif (cont_test) {\n\t\t\t\t\tpanic(\"cprng %p Failed repetition check!\\n\",\n\t\t\t\t\t\tctx);\n\t\t\t\t}\n\n\t\t\t\tprintk(KERN_ERR\n\t\t\t\t\t\"ctx %p Failed repetition check!\\n\",\n\t\t\t\t\tctx);\n\n\t\t\t\tctx->flags |= PRNG_NEED_RESET;\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tmemcpy(ctx->last_rand_data, ctx->rand_data,\n\t\t\t\tDEFAULT_BLK_SZ);\n\n\t\t\t/*\n\t\t\t * Lastly xor the random data with I\n\t\t\t * and encrypt that to obtain a new secret vector V\n\t\t\t */\n\t\t\txor_vectors(ctx->rand_data, ctx->I, tmp,\n\t\t\t\tDEFAULT_BLK_SZ);\n\t\t\toutput = ctx->V;\n\t\t\thexdump(\"tmp stage 2: \", tmp, DEFAULT_BLK_SZ);\n\t\t\tbreak;\n\t\t}\n\n\n\t\t/* do the encryption */\n\t\tcrypto_cipher_encrypt_one(ctx->tfm, output, tmp);\n\n\t}\n\n\t/*\n\t * Now update our DT value\n\t */\n\tfor (i = DEFAULT_BLK_SZ - 1; i >= 0; i--) {\n\t\tctx->DT[i] += 1;\n\t\tif (ctx->DT[i] != 0)\n\t\t\tbreak;\n\t}\n\n\tdbgprint(\"Returning new block for context %p\\n\", ctx);\n\tctx->rand_data_valid = 0;\n\n\thexdump(\"Output DT: \", ctx->DT, DEFAULT_BLK_SZ);\n\thexdump(\"Output I: \", ctx->I, DEFAULT_BLK_SZ);\n\thexdump(\"Output V: \", ctx->V, DEFAULT_BLK_SZ);\n\thexdump(\"New Random Data: \", ctx->rand_data, DEFAULT_BLK_SZ);\n\n\treturn 0;\n}\n\n/* Our exported functions */\nstatic int get_prng_bytes(char *buf, size_t nbytes, struct prng_context *ctx,\n\t\t\t\tint do_cont_test)\n{\n\tunsigned char *ptr = buf;\n\tunsigned int byte_count = (unsigned int)nbytes;\n\tint err;\n\n\n\tspin_lock_bh(&ctx->prng_lock);\n\n\terr = -EINVAL;\n\tif (ctx->flags & PRNG_NEED_RESET)\n\t\tgoto done;\n\n\t/*\n\t * If the FIXED_SIZE flag is on, only return whole blocks of\n\t * pseudo random data\n\t */\n\terr = -EINVAL;\n\tif (ctx->flags & PRNG_FIXED_SIZE) {\n\t\tif (nbytes < DEFAULT_BLK_SZ)\n\t\t\tgoto done;\n\t\tbyte_count = DEFAULT_BLK_SZ;\n\t}\n\n\terr = byte_count;\n\n\tdbgprint(KERN_CRIT \"getting %d random bytes for context %p\\n\",\n\t\tbyte_count, ctx);\n\n\nremainder:\n\tif (ctx->rand_data_valid == DEFAULT_BLK_SZ) {\n\t\tif (_get_more_prng_bytes(ctx, do_cont_test) < 0) {\n\t\t\tmemset(buf, 0, nbytes);\n\t\t\terr = -EINVAL;\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\t/*\n\t * Copy any data less than an entire block\n\t */\n\tif (byte_count < DEFAULT_BLK_SZ) {\nempty_rbuf:\n\t\twhile (ctx->rand_data_valid < DEFAULT_BLK_SZ) {\n\t\t\t*ptr = ctx->rand_data[ctx->rand_data_valid];\n\t\t\tptr++;\n\t\t\tbyte_count--;\n\t\t\tctx->rand_data_valid++;\n\t\t\tif (byte_count == 0)\n\t\t\t\tgoto done;\n\t\t}\n\t}\n\n\t/*\n\t * Now copy whole blocks\n\t */\n\tfor (; byte_count >= DEFAULT_BLK_SZ; byte_count -= DEFAULT_BLK_SZ) {\n\t\tif (ctx->rand_data_valid == DEFAULT_BLK_SZ) {\n\t\t\tif (_get_more_prng_bytes(ctx, do_cont_test) < 0) {\n\t\t\t\tmemset(buf, 0, nbytes);\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t\tif (ctx->rand_data_valid > 0)\n\t\t\tgoto empty_rbuf;\n\t\tmemcpy(ptr, ctx->rand_data, DEFAULT_BLK_SZ);\n\t\tctx->rand_data_valid += DEFAULT_BLK_SZ;\n\t\tptr += DEFAULT_BLK_SZ;\n\t}\n\n\t/*\n\t * Now go back and get any remaining partial block\n\t */\n\tif (byte_count)\n\t\tgoto remainder;\n\ndone:\n\tspin_unlock_bh(&ctx->prng_lock);\n\tdbgprint(KERN_CRIT \"returning %d from get_prng_bytes in context %p\\n\",\n\t\terr, ctx);\n\treturn err;\n}\n\nstatic void free_prng_context(struct prng_context *ctx)\n{\n\tcrypto_free_cipher(ctx->tfm);\n}\n\nstatic int reset_prng_context(struct prng_context *ctx,\n\t\t\t      unsigned char *key, size_t klen,\n\t\t\t      unsigned char *V, unsigned char *DT)\n{\n\tint ret;\n\tunsigned char *prng_key;\n\n\tspin_lock_bh(&ctx->prng_lock);\n\tctx->flags |= PRNG_NEED_RESET;\n\n\tprng_key = (key != NULL) ? key : (unsigned char *)DEFAULT_PRNG_KEY;\n\n\tif (!key)\n\t\tklen = DEFAULT_PRNG_KSZ;\n\n\tif (V)\n\t\tmemcpy(ctx->V, V, DEFAULT_BLK_SZ);\n\telse\n\t\tmemcpy(ctx->V, DEFAULT_V_SEED, DEFAULT_BLK_SZ);\n\n\tif (DT)\n\t\tmemcpy(ctx->DT, DT, DEFAULT_BLK_SZ);\n\telse\n\t\tmemset(ctx->DT, 0, DEFAULT_BLK_SZ);\n\n\tmemset(ctx->rand_data, 0, DEFAULT_BLK_SZ);\n\tmemset(ctx->last_rand_data, 0, DEFAULT_BLK_SZ);\n\n\tctx->rand_data_valid = DEFAULT_BLK_SZ;\n\n\tret = crypto_cipher_setkey(ctx->tfm, prng_key, klen);\n\tif (ret) {\n\t\tdbgprint(KERN_CRIT \"PRNG: setkey() failed flags=%x\\n\",\n\t\t\tcrypto_cipher_get_flags(ctx->tfm));\n\t\tgoto out;\n\t}\n\n\tret = 0;\n\tctx->flags &= ~PRNG_NEED_RESET;\nout:\n\tspin_unlock_bh(&ctx->prng_lock);\n\treturn ret;\n}\n\nstatic int cprng_init(struct crypto_tfm *tfm)\n{\n\tstruct prng_context *ctx = crypto_tfm_ctx(tfm);\n\n\tspin_lock_init(&ctx->prng_lock);\n\tctx->tfm = crypto_alloc_cipher(\"aes\", 0, 0);\n\tif (IS_ERR(ctx->tfm)) {\n\t\tdbgprint(KERN_CRIT \"Failed to alloc tfm for context %p\\n\",\n\t\t\t\tctx);\n\t\treturn PTR_ERR(ctx->tfm);\n\t}\n\n\tif (reset_prng_context(ctx, NULL, DEFAULT_PRNG_KSZ, NULL, NULL) < 0)\n\t\treturn -EINVAL;\n\n\t/*\n\t * after allocation, we should always force the user to reset\n\t * so they don't inadvertently use the insecure default values\n\t * without specifying them intentially\n\t */\n\tctx->flags |= PRNG_NEED_RESET;\n\treturn 0;\n}\n\nstatic void cprng_exit(struct crypto_tfm *tfm)\n{\n\tfree_prng_context(crypto_tfm_ctx(tfm));\n}\n\nstatic int cprng_get_random(struct crypto_rng *tfm, u8 *rdata,\n\t\t\t    unsigned int dlen)\n{\n\tstruct prng_context *prng = crypto_rng_ctx(tfm);\n\n\treturn get_prng_bytes(rdata, dlen, prng, 0);\n}\n\n/*\n *  This is the cprng_registered reset method the seed value is\n *  interpreted as the tuple { V KEY DT}\n *  V and KEY are required during reset, and DT is optional, detected\n *  as being present by testing the length of the seed\n */\nstatic int cprng_reset(struct crypto_rng *tfm, u8 *seed, unsigned int slen)\n{\n\tstruct prng_context *prng = crypto_rng_ctx(tfm);\n\tu8 *key = seed + DEFAULT_BLK_SZ;\n\tu8 *dt = NULL;\n\n\tif (slen < DEFAULT_PRNG_KSZ + DEFAULT_BLK_SZ)\n\t\treturn -EINVAL;\n\n\tif (slen >= (2 * DEFAULT_BLK_SZ + DEFAULT_PRNG_KSZ))\n\t\tdt = key + DEFAULT_PRNG_KSZ;\n\n\treset_prng_context(prng, key, DEFAULT_PRNG_KSZ, seed, dt);\n\n\tif (prng->flags & PRNG_NEED_RESET)\n\t\treturn -EINVAL;\n\treturn 0;\n}\n\n#ifdef CONFIG_CRYPTO_FIPS\nstatic int fips_cprng_get_random(struct crypto_rng *tfm, u8 *rdata,\n\t\t\t    unsigned int dlen)\n{\n\tstruct prng_context *prng = crypto_rng_ctx(tfm);\n\n\treturn get_prng_bytes(rdata, dlen, prng, 1);\n}\n\nstatic int fips_cprng_reset(struct crypto_rng *tfm, u8 *seed, unsigned int slen)\n{\n\tu8 rdata[DEFAULT_BLK_SZ];\n\tu8 *key = seed + DEFAULT_BLK_SZ;\n\tint rc;\n\n\tstruct prng_context *prng = crypto_rng_ctx(tfm);\n\n\tif (slen < DEFAULT_PRNG_KSZ + DEFAULT_BLK_SZ)\n\t\treturn -EINVAL;\n\n\t/* fips strictly requires seed != key */\n\tif (!memcmp(seed, key, DEFAULT_PRNG_KSZ))\n\t\treturn -EINVAL;\n\n\trc = cprng_reset(tfm, seed, slen);\n\n\tif (!rc)\n\t\tgoto out;\n\n\t/* this primes our continuity test */\n\trc = get_prng_bytes(rdata, DEFAULT_BLK_SZ, prng, 0);\n\tprng->rand_data_valid = DEFAULT_BLK_SZ;\n\nout:\n\treturn rc;\n}\n#endif\n\nstatic struct crypto_alg rng_algs[] = { {\n\t.cra_name\t\t= \"stdrng\",\n\t.cra_driver_name\t= \"ansi_cprng\",\n\t.cra_priority\t\t= 100,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_RNG,\n\t.cra_ctxsize\t\t= sizeof(struct prng_context),\n\t.cra_type\t\t= &crypto_rng_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= cprng_init,\n\t.cra_exit\t\t= cprng_exit,\n\t.cra_u\t\t\t= {\n\t\t.rng = {\n\t\t\t.rng_make_random\t= cprng_get_random,\n\t\t\t.rng_reset\t\t= cprng_reset,\n\t\t\t.seedsize = DEFAULT_PRNG_KSZ + 2*DEFAULT_BLK_SZ,\n\t\t}\n\t}\n#ifdef CONFIG_CRYPTO_FIPS\n}, {\n\t.cra_name\t\t= \"fips(ansi_cprng)\",\n\t.cra_driver_name\t= \"fips_ansi_cprng\",\n\t.cra_priority\t\t= 300,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_RNG,\n\t.cra_ctxsize\t\t= sizeof(struct prng_context),\n\t.cra_type\t\t= &crypto_rng_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= cprng_init,\n\t.cra_exit\t\t= cprng_exit,\n\t.cra_u\t\t\t= {\n\t\t.rng = {\n\t\t\t.rng_make_random\t= fips_cprng_get_random,\n\t\t\t.rng_reset\t\t= fips_cprng_reset,\n\t\t\t.seedsize = DEFAULT_PRNG_KSZ + 2*DEFAULT_BLK_SZ,\n\t\t}\n\t}\n#endif\n} };\n\n/* Module initalization */\nstatic int __init prng_mod_init(void)\n{\n\treturn crypto_register_algs(rng_algs, ARRAY_SIZE(rng_algs));\n}\n\nstatic void __exit prng_mod_fini(void)\n{\n\tcrypto_unregister_algs(rng_algs, ARRAY_SIZE(rng_algs));\n}\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Software Pseudo Random Number Generator\");\nMODULE_AUTHOR(\"Neil Horman <nhorman@tuxdriver.com>\");\nmodule_param(dbg, int, 0);\nMODULE_PARM_DESC(dbg, \"Boolean to enable debugging (0/1 == off/on)\");\nmodule_init(prng_mod_init);\nmodule_exit(prng_mod_fini);\nMODULE_ALIAS_CRYPTO(\"stdrng\");\n", "/*\n * Cryptographic API.\n *\n * Anubis Algorithm\n *\n * The Anubis algorithm was developed by Paulo S. L. M. Barreto and\n * Vincent Rijmen.\n *\n * See\n *\n *\tP.S.L.M. Barreto, V. Rijmen,\n *\t``The Anubis block cipher,''\n *\tNESSIE submission, 2000.\n *\n * This software implements the \"tweaked\" version of Anubis.\n * Only the S-box and (consequently) the rounds constants have been\n * changed.\n *\n * The original authors have disclaimed all copyright interest in this\n * code and thus put it in the public domain. The subsequent authors\n * have put this under the GNU General Public License.\n *\n * By Aaron Grothe ajgrothe@yahoo.com, October 28, 2004\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <asm/byteorder.h>\n#include <linux/crypto.h>\n#include <linux/types.h>\n\n#define ANUBIS_MIN_KEY_SIZE\t16\n#define ANUBIS_MAX_KEY_SIZE\t40\n#define ANUBIS_BLOCK_SIZE\t16\n#define ANUBIS_MAX_N\t\t10\n#define ANUBIS_MAX_ROUNDS\t(8 + ANUBIS_MAX_N)\n\nstruct anubis_ctx {\n\tint key_len; // in bits\n\tint R;\n\tu32 E[ANUBIS_MAX_ROUNDS + 1][4];\n\tu32 D[ANUBIS_MAX_ROUNDS + 1][4];\n};\n\nstatic const u32 T0[256] = {\n\t0xba69d2bbU, 0x54a84de5U, 0x2f5ebce2U, 0x74e8cd25U,\n\t0x53a651f7U, 0xd3bb6bd0U, 0xd2b96fd6U, 0x4d9a29b3U,\n\t0x50a05dfdU, 0xac458acfU, 0x8d070e09U, 0xbf63c6a5U,\n\t0x70e0dd3dU, 0x52a455f1U, 0x9a29527bU, 0x4c982db5U,\n\t0xeac98f46U, 0xd5b773c4U, 0x97336655U, 0xd1bf63dcU,\n\t0x3366ccaaU, 0x51a259fbU, 0x5bb671c7U, 0xa651a2f3U,\n\t0xdea15ffeU, 0x48903dadU, 0xa84d9ad7U, 0x992f5e71U,\n\t0xdbab4be0U, 0x3264c8acU, 0xb773e695U, 0xfce5d732U,\n\t0xe3dbab70U, 0x9e214263U, 0x913f7e41U, 0x9b2b567dU,\n\t0xe2d9af76U, 0xbb6bd6bdU, 0x4182199bU, 0x6edca579U,\n\t0xa557aef9U, 0xcb8b0b80U, 0x6bd6b167U, 0x95376e59U,\n\t0xa15fbee1U, 0xf3fbeb10U, 0xb17ffe81U, 0x0204080cU,\n\t0xcc851792U, 0xc49537a2U, 0x1d3a744eU, 0x14285078U,\n\t0xc39b2bb0U, 0x63c69157U, 0xdaa94fe6U, 0x5dba69d3U,\n\t0x5fbe61dfU, 0xdca557f2U, 0x7dfae913U, 0xcd871394U,\n\t0x7ffee11fU, 0x5ab475c1U, 0x6cd8ad75U, 0x5cb86dd5U,\n\t0xf7f3fb08U, 0x264c98d4U, 0xffe3db38U, 0xedc79354U,\n\t0xe8cd874aU, 0x9d274e69U, 0x6fdea17fU, 0x8e010203U,\n\t0x19326456U, 0xa05dbae7U, 0xf0fde71aU, 0x890f1e11U,\n\t0x0f1e3c22U, 0x070e1c12U, 0xaf4386c5U, 0xfbebcb20U,\n\t0x08102030U, 0x152a547eU, 0x0d1a342eU, 0x04081018U,\n\t0x01020406U, 0x64c88d45U, 0xdfa35bf8U, 0x76ecc529U,\n\t0x79f2f90bU, 0xdda753f4U, 0x3d7af48eU, 0x162c5874U,\n\t0x3f7efc82U, 0x376edcb2U, 0x6ddaa973U, 0x3870e090U,\n\t0xb96fdeb1U, 0x73e6d137U, 0xe9cf834cU, 0x356ad4beU,\n\t0x55aa49e3U, 0x71e2d93bU, 0x7bf6f107U, 0x8c050a0fU,\n\t0x72e4d531U, 0x880d1a17U, 0xf6f1ff0eU, 0x2a54a8fcU,\n\t0x3e7cf884U, 0x5ebc65d9U, 0x274e9cd2U, 0x468c0589U,\n\t0x0c183028U, 0x65ca8943U, 0x68d0bd6dU, 0x61c2995bU,\n\t0x03060c0aU, 0xc19f23bcU, 0x57ae41efU, 0xd6b17fceU,\n\t0xd9af43ecU, 0x58b07dcdU, 0xd8ad47eaU, 0x66cc8549U,\n\t0xd7b37bc8U, 0x3a74e89cU, 0xc88d078aU, 0x3c78f088U,\n\t0xfae9cf26U, 0x96316253U, 0xa753a6f5U, 0x982d5a77U,\n\t0xecc59752U, 0xb86ddab7U, 0xc7933ba8U, 0xae4182c3U,\n\t0x69d2b96bU, 0x4b9631a7U, 0xab4b96ddU, 0xa94f9ed1U,\n\t0x67ce814fU, 0x0a14283cU, 0x478e018fU, 0xf2f9ef16U,\n\t0xb577ee99U, 0x224488ccU, 0xe5d7b364U, 0xeec19f5eU,\n\t0xbe61c2a3U, 0x2b56acfaU, 0x811f3e21U, 0x1224486cU,\n\t0x831b362dU, 0x1b366c5aU, 0x0e1c3824U, 0x23468ccaU,\n\t0xf5f7f304U, 0x458a0983U, 0x214284c6U, 0xce811f9eU,\n\t0x499239abU, 0x2c58b0e8U, 0xf9efc32cU, 0xe6d1bf6eU,\n\t0xb671e293U, 0x2850a0f0U, 0x172e5c72U, 0x8219322bU,\n\t0x1a34685cU, 0x8b0b161dU, 0xfee1df3eU, 0x8a09121bU,\n\t0x09122436U, 0xc98f038cU, 0x87132635U, 0x4e9c25b9U,\n\t0xe1dfa37cU, 0x2e5cb8e4U, 0xe4d5b762U, 0xe0dda77aU,\n\t0xebcb8b40U, 0x903d7a47U, 0xa455aaffU, 0x1e3c7844U,\n\t0x85172e39U, 0x60c09d5dU, 0x00000000U, 0x254a94deU,\n\t0xf4f5f702U, 0xf1ffe31cU, 0x94356a5fU, 0x0b162c3aU,\n\t0xe7d3bb68U, 0x75eac923U, 0xefc39b58U, 0x3468d0b8U,\n\t0x3162c4a6U, 0xd4b577c2U, 0xd0bd67daU, 0x86112233U,\n\t0x7efce519U, 0xad478ec9U, 0xfde7d334U, 0x2952a4f6U,\n\t0x3060c0a0U, 0x3b76ec9aU, 0x9f234665U, 0xf8edc72aU,\n\t0xc6913faeU, 0x13264c6aU, 0x060c1814U, 0x050a141eU,\n\t0xc59733a4U, 0x11224466U, 0x77eec12fU, 0x7cf8ed15U,\n\t0x7af4f501U, 0x78f0fd0dU, 0x366cd8b4U, 0x1c387048U,\n\t0x3972e496U, 0x59b279cbU, 0x18306050U, 0x56ac45e9U,\n\t0xb37bf68dU, 0xb07dfa87U, 0x244890d8U, 0x204080c0U,\n\t0xb279f28bU, 0x9239724bU, 0xa35bb6edU, 0xc09d27baU,\n\t0x44880d85U, 0x62c49551U, 0x10204060U, 0xb475ea9fU,\n\t0x84152a3fU, 0x43861197U, 0x933b764dU, 0xc2992fb6U,\n\t0x4a9435a1U, 0xbd67cea9U, 0x8f030605U, 0x2d5ab4eeU,\n\t0xbc65caafU, 0x9c254a6fU, 0x6ad4b561U, 0x40801d9dU,\n\t0xcf831b98U, 0xa259b2ebU, 0x801d3a27U, 0x4f9e21bfU,\n\t0x1f3e7c42U, 0xca890f86U, 0xaa4992dbU, 0x42841591U,\n};\n\nstatic const u32 T1[256] = {\n\t0x69babbd2U, 0xa854e54dU, 0x5e2fe2bcU, 0xe87425cdU,\n\t0xa653f751U, 0xbbd3d06bU, 0xb9d2d66fU, 0x9a4db329U,\n\t0xa050fd5dU, 0x45accf8aU, 0x078d090eU, 0x63bfa5c6U,\n\t0xe0703dddU, 0xa452f155U, 0x299a7b52U, 0x984cb52dU,\n\t0xc9ea468fU, 0xb7d5c473U, 0x33975566U, 0xbfd1dc63U,\n\t0x6633aaccU, 0xa251fb59U, 0xb65bc771U, 0x51a6f3a2U,\n\t0xa1defe5fU, 0x9048ad3dU, 0x4da8d79aU, 0x2f99715eU,\n\t0xabdbe04bU, 0x6432acc8U, 0x73b795e6U, 0xe5fc32d7U,\n\t0xdbe370abU, 0x219e6342U, 0x3f91417eU, 0x2b9b7d56U,\n\t0xd9e276afU, 0x6bbbbdd6U, 0x82419b19U, 0xdc6e79a5U,\n\t0x57a5f9aeU, 0x8bcb800bU, 0xd66b67b1U, 0x3795596eU,\n\t0x5fa1e1beU, 0xfbf310ebU, 0x7fb181feU, 0x04020c08U,\n\t0x85cc9217U, 0x95c4a237U, 0x3a1d4e74U, 0x28147850U,\n\t0x9bc3b02bU, 0xc6635791U, 0xa9dae64fU, 0xba5dd369U,\n\t0xbe5fdf61U, 0xa5dcf257U, 0xfa7d13e9U, 0x87cd9413U,\n\t0xfe7f1fe1U, 0xb45ac175U, 0xd86c75adU, 0xb85cd56dU,\n\t0xf3f708fbU, 0x4c26d498U, 0xe3ff38dbU, 0xc7ed5493U,\n\t0xcde84a87U, 0x279d694eU, 0xde6f7fa1U, 0x018e0302U,\n\t0x32195664U, 0x5da0e7baU, 0xfdf01ae7U, 0x0f89111eU,\n\t0x1e0f223cU, 0x0e07121cU, 0x43afc586U, 0xebfb20cbU,\n\t0x10083020U, 0x2a157e54U, 0x1a0d2e34U, 0x08041810U,\n\t0x02010604U, 0xc864458dU, 0xa3dff85bU, 0xec7629c5U,\n\t0xf2790bf9U, 0xa7ddf453U, 0x7a3d8ef4U, 0x2c167458U,\n\t0x7e3f82fcU, 0x6e37b2dcU, 0xda6d73a9U, 0x703890e0U,\n\t0x6fb9b1deU, 0xe67337d1U, 0xcfe94c83U, 0x6a35bed4U,\n\t0xaa55e349U, 0xe2713bd9U, 0xf67b07f1U, 0x058c0f0aU,\n\t0xe47231d5U, 0x0d88171aU, 0xf1f60effU, 0x542afca8U,\n\t0x7c3e84f8U, 0xbc5ed965U, 0x4e27d29cU, 0x8c468905U,\n\t0x180c2830U, 0xca654389U, 0xd0686dbdU, 0xc2615b99U,\n\t0x06030a0cU, 0x9fc1bc23U, 0xae57ef41U, 0xb1d6ce7fU,\n\t0xafd9ec43U, 0xb058cd7dU, 0xadd8ea47U, 0xcc664985U,\n\t0xb3d7c87bU, 0x743a9ce8U, 0x8dc88a07U, 0x783c88f0U,\n\t0xe9fa26cfU, 0x31965362U, 0x53a7f5a6U, 0x2d98775aU,\n\t0xc5ec5297U, 0x6db8b7daU, 0x93c7a83bU, 0x41aec382U,\n\t0xd2696bb9U, 0x964ba731U, 0x4babdd96U, 0x4fa9d19eU,\n\t0xce674f81U, 0x140a3c28U, 0x8e478f01U, 0xf9f216efU,\n\t0x77b599eeU, 0x4422cc88U, 0xd7e564b3U, 0xc1ee5e9fU,\n\t0x61bea3c2U, 0x562bfaacU, 0x1f81213eU, 0x24126c48U,\n\t0x1b832d36U, 0x361b5a6cU, 0x1c0e2438U, 0x4623ca8cU,\n\t0xf7f504f3U, 0x8a458309U, 0x4221c684U, 0x81ce9e1fU,\n\t0x9249ab39U, 0x582ce8b0U, 0xeff92cc3U, 0xd1e66ebfU,\n\t0x71b693e2U, 0x5028f0a0U, 0x2e17725cU, 0x19822b32U,\n\t0x341a5c68U, 0x0b8b1d16U, 0xe1fe3edfU, 0x098a1b12U,\n\t0x12093624U, 0x8fc98c03U, 0x13873526U, 0x9c4eb925U,\n\t0xdfe17ca3U, 0x5c2ee4b8U, 0xd5e462b7U, 0xdde07aa7U,\n\t0xcbeb408bU, 0x3d90477aU, 0x55a4ffaaU, 0x3c1e4478U,\n\t0x1785392eU, 0xc0605d9dU, 0x00000000U, 0x4a25de94U,\n\t0xf5f402f7U, 0xfff11ce3U, 0x35945f6aU, 0x160b3a2cU,\n\t0xd3e768bbU, 0xea7523c9U, 0xc3ef589bU, 0x6834b8d0U,\n\t0x6231a6c4U, 0xb5d4c277U, 0xbdd0da67U, 0x11863322U,\n\t0xfc7e19e5U, 0x47adc98eU, 0xe7fd34d3U, 0x5229f6a4U,\n\t0x6030a0c0U, 0x763b9aecU, 0x239f6546U, 0xedf82ac7U,\n\t0x91c6ae3fU, 0x26136a4cU, 0x0c061418U, 0x0a051e14U,\n\t0x97c5a433U, 0x22116644U, 0xee772fc1U, 0xf87c15edU,\n\t0xf47a01f5U, 0xf0780dfdU, 0x6c36b4d8U, 0x381c4870U,\n\t0x723996e4U, 0xb259cb79U, 0x30185060U, 0xac56e945U,\n\t0x7bb38df6U, 0x7db087faU, 0x4824d890U, 0x4020c080U,\n\t0x79b28bf2U, 0x39924b72U, 0x5ba3edb6U, 0x9dc0ba27U,\n\t0x8844850dU, 0xc4625195U, 0x20106040U, 0x75b49feaU,\n\t0x15843f2aU, 0x86439711U, 0x3b934d76U, 0x99c2b62fU,\n\t0x944aa135U, 0x67bda9ceU, 0x038f0506U, 0x5a2deeb4U,\n\t0x65bcafcaU, 0x259c6f4aU, 0xd46a61b5U, 0x80409d1dU,\n\t0x83cf981bU, 0x59a2ebb2U, 0x1d80273aU, 0x9e4fbf21U,\n\t0x3e1f427cU, 0x89ca860fU, 0x49aadb92U, 0x84429115U,\n};\n\nstatic const u32 T2[256] = {\n\t0xd2bbba69U, 0x4de554a8U, 0xbce22f5eU, 0xcd2574e8U,\n\t0x51f753a6U, 0x6bd0d3bbU, 0x6fd6d2b9U, 0x29b34d9aU,\n\t0x5dfd50a0U, 0x8acfac45U, 0x0e098d07U, 0xc6a5bf63U,\n\t0xdd3d70e0U, 0x55f152a4U, 0x527b9a29U, 0x2db54c98U,\n\t0x8f46eac9U, 0x73c4d5b7U, 0x66559733U, 0x63dcd1bfU,\n\t0xccaa3366U, 0x59fb51a2U, 0x71c75bb6U, 0xa2f3a651U,\n\t0x5ffedea1U, 0x3dad4890U, 0x9ad7a84dU, 0x5e71992fU,\n\t0x4be0dbabU, 0xc8ac3264U, 0xe695b773U, 0xd732fce5U,\n\t0xab70e3dbU, 0x42639e21U, 0x7e41913fU, 0x567d9b2bU,\n\t0xaf76e2d9U, 0xd6bdbb6bU, 0x199b4182U, 0xa5796edcU,\n\t0xaef9a557U, 0x0b80cb8bU, 0xb1676bd6U, 0x6e599537U,\n\t0xbee1a15fU, 0xeb10f3fbU, 0xfe81b17fU, 0x080c0204U,\n\t0x1792cc85U, 0x37a2c495U, 0x744e1d3aU, 0x50781428U,\n\t0x2bb0c39bU, 0x915763c6U, 0x4fe6daa9U, 0x69d35dbaU,\n\t0x61df5fbeU, 0x57f2dca5U, 0xe9137dfaU, 0x1394cd87U,\n\t0xe11f7ffeU, 0x75c15ab4U, 0xad756cd8U, 0x6dd55cb8U,\n\t0xfb08f7f3U, 0x98d4264cU, 0xdb38ffe3U, 0x9354edc7U,\n\t0x874ae8cdU, 0x4e699d27U, 0xa17f6fdeU, 0x02038e01U,\n\t0x64561932U, 0xbae7a05dU, 0xe71af0fdU, 0x1e11890fU,\n\t0x3c220f1eU, 0x1c12070eU, 0x86c5af43U, 0xcb20fbebU,\n\t0x20300810U, 0x547e152aU, 0x342e0d1aU, 0x10180408U,\n\t0x04060102U, 0x8d4564c8U, 0x5bf8dfa3U, 0xc52976ecU,\n\t0xf90b79f2U, 0x53f4dda7U, 0xf48e3d7aU, 0x5874162cU,\n\t0xfc823f7eU, 0xdcb2376eU, 0xa9736ddaU, 0xe0903870U,\n\t0xdeb1b96fU, 0xd13773e6U, 0x834ce9cfU, 0xd4be356aU,\n\t0x49e355aaU, 0xd93b71e2U, 0xf1077bf6U, 0x0a0f8c05U,\n\t0xd53172e4U, 0x1a17880dU, 0xff0ef6f1U, 0xa8fc2a54U,\n\t0xf8843e7cU, 0x65d95ebcU, 0x9cd2274eU, 0x0589468cU,\n\t0x30280c18U, 0x894365caU, 0xbd6d68d0U, 0x995b61c2U,\n\t0x0c0a0306U, 0x23bcc19fU, 0x41ef57aeU, 0x7fced6b1U,\n\t0x43ecd9afU, 0x7dcd58b0U, 0x47ead8adU, 0x854966ccU,\n\t0x7bc8d7b3U, 0xe89c3a74U, 0x078ac88dU, 0xf0883c78U,\n\t0xcf26fae9U, 0x62539631U, 0xa6f5a753U, 0x5a77982dU,\n\t0x9752ecc5U, 0xdab7b86dU, 0x3ba8c793U, 0x82c3ae41U,\n\t0xb96b69d2U, 0x31a74b96U, 0x96ddab4bU, 0x9ed1a94fU,\n\t0x814f67ceU, 0x283c0a14U, 0x018f478eU, 0xef16f2f9U,\n\t0xee99b577U, 0x88cc2244U, 0xb364e5d7U, 0x9f5eeec1U,\n\t0xc2a3be61U, 0xacfa2b56U, 0x3e21811fU, 0x486c1224U,\n\t0x362d831bU, 0x6c5a1b36U, 0x38240e1cU, 0x8cca2346U,\n\t0xf304f5f7U, 0x0983458aU, 0x84c62142U, 0x1f9ece81U,\n\t0x39ab4992U, 0xb0e82c58U, 0xc32cf9efU, 0xbf6ee6d1U,\n\t0xe293b671U, 0xa0f02850U, 0x5c72172eU, 0x322b8219U,\n\t0x685c1a34U, 0x161d8b0bU, 0xdf3efee1U, 0x121b8a09U,\n\t0x24360912U, 0x038cc98fU, 0x26358713U, 0x25b94e9cU,\n\t0xa37ce1dfU, 0xb8e42e5cU, 0xb762e4d5U, 0xa77ae0ddU,\n\t0x8b40ebcbU, 0x7a47903dU, 0xaaffa455U, 0x78441e3cU,\n\t0x2e398517U, 0x9d5d60c0U, 0x00000000U, 0x94de254aU,\n\t0xf702f4f5U, 0xe31cf1ffU, 0x6a5f9435U, 0x2c3a0b16U,\n\t0xbb68e7d3U, 0xc92375eaU, 0x9b58efc3U, 0xd0b83468U,\n\t0xc4a63162U, 0x77c2d4b5U, 0x67dad0bdU, 0x22338611U,\n\t0xe5197efcU, 0x8ec9ad47U, 0xd334fde7U, 0xa4f62952U,\n\t0xc0a03060U, 0xec9a3b76U, 0x46659f23U, 0xc72af8edU,\n\t0x3faec691U, 0x4c6a1326U, 0x1814060cU, 0x141e050aU,\n\t0x33a4c597U, 0x44661122U, 0xc12f77eeU, 0xed157cf8U,\n\t0xf5017af4U, 0xfd0d78f0U, 0xd8b4366cU, 0x70481c38U,\n\t0xe4963972U, 0x79cb59b2U, 0x60501830U, 0x45e956acU,\n\t0xf68db37bU, 0xfa87b07dU, 0x90d82448U, 0x80c02040U,\n\t0xf28bb279U, 0x724b9239U, 0xb6eda35bU, 0x27bac09dU,\n\t0x0d854488U, 0x955162c4U, 0x40601020U, 0xea9fb475U,\n\t0x2a3f8415U, 0x11974386U, 0x764d933bU, 0x2fb6c299U,\n\t0x35a14a94U, 0xcea9bd67U, 0x06058f03U, 0xb4ee2d5aU,\n\t0xcaafbc65U, 0x4a6f9c25U, 0xb5616ad4U, 0x1d9d4080U,\n\t0x1b98cf83U, 0xb2eba259U, 0x3a27801dU, 0x21bf4f9eU,\n\t0x7c421f3eU, 0x0f86ca89U, 0x92dbaa49U, 0x15914284U,\n};\n\nstatic const u32 T3[256] = {\n\t0xbbd269baU, 0xe54da854U, 0xe2bc5e2fU, 0x25cde874U,\n\t0xf751a653U, 0xd06bbbd3U, 0xd66fb9d2U, 0xb3299a4dU,\n\t0xfd5da050U, 0xcf8a45acU, 0x090e078dU, 0xa5c663bfU,\n\t0x3ddde070U, 0xf155a452U, 0x7b52299aU, 0xb52d984cU,\n\t0x468fc9eaU, 0xc473b7d5U, 0x55663397U, 0xdc63bfd1U,\n\t0xaacc6633U, 0xfb59a251U, 0xc771b65bU, 0xf3a251a6U,\n\t0xfe5fa1deU, 0xad3d9048U, 0xd79a4da8U, 0x715e2f99U,\n\t0xe04babdbU, 0xacc86432U, 0x95e673b7U, 0x32d7e5fcU,\n\t0x70abdbe3U, 0x6342219eU, 0x417e3f91U, 0x7d562b9bU,\n\t0x76afd9e2U, 0xbdd66bbbU, 0x9b198241U, 0x79a5dc6eU,\n\t0xf9ae57a5U, 0x800b8bcbU, 0x67b1d66bU, 0x596e3795U,\n\t0xe1be5fa1U, 0x10ebfbf3U, 0x81fe7fb1U, 0x0c080402U,\n\t0x921785ccU, 0xa23795c4U, 0x4e743a1dU, 0x78502814U,\n\t0xb02b9bc3U, 0x5791c663U, 0xe64fa9daU, 0xd369ba5dU,\n\t0xdf61be5fU, 0xf257a5dcU, 0x13e9fa7dU, 0x941387cdU,\n\t0x1fe1fe7fU, 0xc175b45aU, 0x75add86cU, 0xd56db85cU,\n\t0x08fbf3f7U, 0xd4984c26U, 0x38dbe3ffU, 0x5493c7edU,\n\t0x4a87cde8U, 0x694e279dU, 0x7fa1de6fU, 0x0302018eU,\n\t0x56643219U, 0xe7ba5da0U, 0x1ae7fdf0U, 0x111e0f89U,\n\t0x223c1e0fU, 0x121c0e07U, 0xc58643afU, 0x20cbebfbU,\n\t0x30201008U, 0x7e542a15U, 0x2e341a0dU, 0x18100804U,\n\t0x06040201U, 0x458dc864U, 0xf85ba3dfU, 0x29c5ec76U,\n\t0x0bf9f279U, 0xf453a7ddU, 0x8ef47a3dU, 0x74582c16U,\n\t0x82fc7e3fU, 0xb2dc6e37U, 0x73a9da6dU, 0x90e07038U,\n\t0xb1de6fb9U, 0x37d1e673U, 0x4c83cfe9U, 0xbed46a35U,\n\t0xe349aa55U, 0x3bd9e271U, 0x07f1f67bU, 0x0f0a058cU,\n\t0x31d5e472U, 0x171a0d88U, 0x0efff1f6U, 0xfca8542aU,\n\t0x84f87c3eU, 0xd965bc5eU, 0xd29c4e27U, 0x89058c46U,\n\t0x2830180cU, 0x4389ca65U, 0x6dbdd068U, 0x5b99c261U,\n\t0x0a0c0603U, 0xbc239fc1U, 0xef41ae57U, 0xce7fb1d6U,\n\t0xec43afd9U, 0xcd7db058U, 0xea47add8U, 0x4985cc66U,\n\t0xc87bb3d7U, 0x9ce8743aU, 0x8a078dc8U, 0x88f0783cU,\n\t0x26cfe9faU, 0x53623196U, 0xf5a653a7U, 0x775a2d98U,\n\t0x5297c5ecU, 0xb7da6db8U, 0xa83b93c7U, 0xc38241aeU,\n\t0x6bb9d269U, 0xa731964bU, 0xdd964babU, 0xd19e4fa9U,\n\t0x4f81ce67U, 0x3c28140aU, 0x8f018e47U, 0x16eff9f2U,\n\t0x99ee77b5U, 0xcc884422U, 0x64b3d7e5U, 0x5e9fc1eeU,\n\t0xa3c261beU, 0xfaac562bU, 0x213e1f81U, 0x6c482412U,\n\t0x2d361b83U, 0x5a6c361bU, 0x24381c0eU, 0xca8c4623U,\n\t0x04f3f7f5U, 0x83098a45U, 0xc6844221U, 0x9e1f81ceU,\n\t0xab399249U, 0xe8b0582cU, 0x2cc3eff9U, 0x6ebfd1e6U,\n\t0x93e271b6U, 0xf0a05028U, 0x725c2e17U, 0x2b321982U,\n\t0x5c68341aU, 0x1d160b8bU, 0x3edfe1feU, 0x1b12098aU,\n\t0x36241209U, 0x8c038fc9U, 0x35261387U, 0xb9259c4eU,\n\t0x7ca3dfe1U, 0xe4b85c2eU, 0x62b7d5e4U, 0x7aa7dde0U,\n\t0x408bcbebU, 0x477a3d90U, 0xffaa55a4U, 0x44783c1eU,\n\t0x392e1785U, 0x5d9dc060U, 0x00000000U, 0xde944a25U,\n\t0x02f7f5f4U, 0x1ce3fff1U, 0x5f6a3594U, 0x3a2c160bU,\n\t0x68bbd3e7U, 0x23c9ea75U, 0x589bc3efU, 0xb8d06834U,\n\t0xa6c46231U, 0xc277b5d4U, 0xda67bdd0U, 0x33221186U,\n\t0x19e5fc7eU, 0xc98e47adU, 0x34d3e7fdU, 0xf6a45229U,\n\t0xa0c06030U, 0x9aec763bU, 0x6546239fU, 0x2ac7edf8U,\n\t0xae3f91c6U, 0x6a4c2613U, 0x14180c06U, 0x1e140a05U,\n\t0xa43397c5U, 0x66442211U, 0x2fc1ee77U, 0x15edf87cU,\n\t0x01f5f47aU, 0x0dfdf078U, 0xb4d86c36U, 0x4870381cU,\n\t0x96e47239U, 0xcb79b259U, 0x50603018U, 0xe945ac56U,\n\t0x8df67bb3U, 0x87fa7db0U, 0xd8904824U, 0xc0804020U,\n\t0x8bf279b2U, 0x4b723992U, 0xedb65ba3U, 0xba279dc0U,\n\t0x850d8844U, 0x5195c462U, 0x60402010U, 0x9fea75b4U,\n\t0x3f2a1584U, 0x97118643U, 0x4d763b93U, 0xb62f99c2U,\n\t0xa135944aU, 0xa9ce67bdU, 0x0506038fU, 0xeeb45a2dU,\n\t0xafca65bcU, 0x6f4a259cU, 0x61b5d46aU, 0x9d1d8040U,\n\t0x981b83cfU, 0xebb259a2U, 0x273a1d80U, 0xbf219e4fU,\n\t0x427c3e1fU, 0x860f89caU, 0xdb9249aaU, 0x91158442U,\n};\n\nstatic const u32 T4[256] = {\n\t0xbabababaU, 0x54545454U, 0x2f2f2f2fU, 0x74747474U,\n\t0x53535353U, 0xd3d3d3d3U, 0xd2d2d2d2U, 0x4d4d4d4dU,\n\t0x50505050U, 0xacacacacU, 0x8d8d8d8dU, 0xbfbfbfbfU,\n\t0x70707070U, 0x52525252U, 0x9a9a9a9aU, 0x4c4c4c4cU,\n\t0xeaeaeaeaU, 0xd5d5d5d5U, 0x97979797U, 0xd1d1d1d1U,\n\t0x33333333U, 0x51515151U, 0x5b5b5b5bU, 0xa6a6a6a6U,\n\t0xdedededeU, 0x48484848U, 0xa8a8a8a8U, 0x99999999U,\n\t0xdbdbdbdbU, 0x32323232U, 0xb7b7b7b7U, 0xfcfcfcfcU,\n\t0xe3e3e3e3U, 0x9e9e9e9eU, 0x91919191U, 0x9b9b9b9bU,\n\t0xe2e2e2e2U, 0xbbbbbbbbU, 0x41414141U, 0x6e6e6e6eU,\n\t0xa5a5a5a5U, 0xcbcbcbcbU, 0x6b6b6b6bU, 0x95959595U,\n\t0xa1a1a1a1U, 0xf3f3f3f3U, 0xb1b1b1b1U, 0x02020202U,\n\t0xccccccccU, 0xc4c4c4c4U, 0x1d1d1d1dU, 0x14141414U,\n\t0xc3c3c3c3U, 0x63636363U, 0xdadadadaU, 0x5d5d5d5dU,\n\t0x5f5f5f5fU, 0xdcdcdcdcU, 0x7d7d7d7dU, 0xcdcdcdcdU,\n\t0x7f7f7f7fU, 0x5a5a5a5aU, 0x6c6c6c6cU, 0x5c5c5c5cU,\n\t0xf7f7f7f7U, 0x26262626U, 0xffffffffU, 0xededededU,\n\t0xe8e8e8e8U, 0x9d9d9d9dU, 0x6f6f6f6fU, 0x8e8e8e8eU,\n\t0x19191919U, 0xa0a0a0a0U, 0xf0f0f0f0U, 0x89898989U,\n\t0x0f0f0f0fU, 0x07070707U, 0xafafafafU, 0xfbfbfbfbU,\n\t0x08080808U, 0x15151515U, 0x0d0d0d0dU, 0x04040404U,\n\t0x01010101U, 0x64646464U, 0xdfdfdfdfU, 0x76767676U,\n\t0x79797979U, 0xddddddddU, 0x3d3d3d3dU, 0x16161616U,\n\t0x3f3f3f3fU, 0x37373737U, 0x6d6d6d6dU, 0x38383838U,\n\t0xb9b9b9b9U, 0x73737373U, 0xe9e9e9e9U, 0x35353535U,\n\t0x55555555U, 0x71717171U, 0x7b7b7b7bU, 0x8c8c8c8cU,\n\t0x72727272U, 0x88888888U, 0xf6f6f6f6U, 0x2a2a2a2aU,\n\t0x3e3e3e3eU, 0x5e5e5e5eU, 0x27272727U, 0x46464646U,\n\t0x0c0c0c0cU, 0x65656565U, 0x68686868U, 0x61616161U,\n\t0x03030303U, 0xc1c1c1c1U, 0x57575757U, 0xd6d6d6d6U,\n\t0xd9d9d9d9U, 0x58585858U, 0xd8d8d8d8U, 0x66666666U,\n\t0xd7d7d7d7U, 0x3a3a3a3aU, 0xc8c8c8c8U, 0x3c3c3c3cU,\n\t0xfafafafaU, 0x96969696U, 0xa7a7a7a7U, 0x98989898U,\n\t0xececececU, 0xb8b8b8b8U, 0xc7c7c7c7U, 0xaeaeaeaeU,\n\t0x69696969U, 0x4b4b4b4bU, 0xababababU, 0xa9a9a9a9U,\n\t0x67676767U, 0x0a0a0a0aU, 0x47474747U, 0xf2f2f2f2U,\n\t0xb5b5b5b5U, 0x22222222U, 0xe5e5e5e5U, 0xeeeeeeeeU,\n\t0xbebebebeU, 0x2b2b2b2bU, 0x81818181U, 0x12121212U,\n\t0x83838383U, 0x1b1b1b1bU, 0x0e0e0e0eU, 0x23232323U,\n\t0xf5f5f5f5U, 0x45454545U, 0x21212121U, 0xcecececeU,\n\t0x49494949U, 0x2c2c2c2cU, 0xf9f9f9f9U, 0xe6e6e6e6U,\n\t0xb6b6b6b6U, 0x28282828U, 0x17171717U, 0x82828282U,\n\t0x1a1a1a1aU, 0x8b8b8b8bU, 0xfefefefeU, 0x8a8a8a8aU,\n\t0x09090909U, 0xc9c9c9c9U, 0x87878787U, 0x4e4e4e4eU,\n\t0xe1e1e1e1U, 0x2e2e2e2eU, 0xe4e4e4e4U, 0xe0e0e0e0U,\n\t0xebebebebU, 0x90909090U, 0xa4a4a4a4U, 0x1e1e1e1eU,\n\t0x85858585U, 0x60606060U, 0x00000000U, 0x25252525U,\n\t0xf4f4f4f4U, 0xf1f1f1f1U, 0x94949494U, 0x0b0b0b0bU,\n\t0xe7e7e7e7U, 0x75757575U, 0xefefefefU, 0x34343434U,\n\t0x31313131U, 0xd4d4d4d4U, 0xd0d0d0d0U, 0x86868686U,\n\t0x7e7e7e7eU, 0xadadadadU, 0xfdfdfdfdU, 0x29292929U,\n\t0x30303030U, 0x3b3b3b3bU, 0x9f9f9f9fU, 0xf8f8f8f8U,\n\t0xc6c6c6c6U, 0x13131313U, 0x06060606U, 0x05050505U,\n\t0xc5c5c5c5U, 0x11111111U, 0x77777777U, 0x7c7c7c7cU,\n\t0x7a7a7a7aU, 0x78787878U, 0x36363636U, 0x1c1c1c1cU,\n\t0x39393939U, 0x59595959U, 0x18181818U, 0x56565656U,\n\t0xb3b3b3b3U, 0xb0b0b0b0U, 0x24242424U, 0x20202020U,\n\t0xb2b2b2b2U, 0x92929292U, 0xa3a3a3a3U, 0xc0c0c0c0U,\n\t0x44444444U, 0x62626262U, 0x10101010U, 0xb4b4b4b4U,\n\t0x84848484U, 0x43434343U, 0x93939393U, 0xc2c2c2c2U,\n\t0x4a4a4a4aU, 0xbdbdbdbdU, 0x8f8f8f8fU, 0x2d2d2d2dU,\n\t0xbcbcbcbcU, 0x9c9c9c9cU, 0x6a6a6a6aU, 0x40404040U,\n\t0xcfcfcfcfU, 0xa2a2a2a2U, 0x80808080U, 0x4f4f4f4fU,\n\t0x1f1f1f1fU, 0xcacacacaU, 0xaaaaaaaaU, 0x42424242U,\n};\n\nstatic const u32 T5[256] = {\n\t0x00000000U, 0x01020608U, 0x02040c10U, 0x03060a18U,\n\t0x04081820U, 0x050a1e28U, 0x060c1430U, 0x070e1238U,\n\t0x08103040U, 0x09123648U, 0x0a143c50U, 0x0b163a58U,\n\t0x0c182860U, 0x0d1a2e68U, 0x0e1c2470U, 0x0f1e2278U,\n\t0x10206080U, 0x11226688U, 0x12246c90U, 0x13266a98U,\n\t0x142878a0U, 0x152a7ea8U, 0x162c74b0U, 0x172e72b8U,\n\t0x183050c0U, 0x193256c8U, 0x1a345cd0U, 0x1b365ad8U,\n\t0x1c3848e0U, 0x1d3a4ee8U, 0x1e3c44f0U, 0x1f3e42f8U,\n\t0x2040c01dU, 0x2142c615U, 0x2244cc0dU, 0x2346ca05U,\n\t0x2448d83dU, 0x254ade35U, 0x264cd42dU, 0x274ed225U,\n\t0x2850f05dU, 0x2952f655U, 0x2a54fc4dU, 0x2b56fa45U,\n\t0x2c58e87dU, 0x2d5aee75U, 0x2e5ce46dU, 0x2f5ee265U,\n\t0x3060a09dU, 0x3162a695U, 0x3264ac8dU, 0x3366aa85U,\n\t0x3468b8bdU, 0x356abeb5U, 0x366cb4adU, 0x376eb2a5U,\n\t0x387090ddU, 0x397296d5U, 0x3a749ccdU, 0x3b769ac5U,\n\t0x3c7888fdU, 0x3d7a8ef5U, 0x3e7c84edU, 0x3f7e82e5U,\n\t0x40809d3aU, 0x41829b32U, 0x4284912aU, 0x43869722U,\n\t0x4488851aU, 0x458a8312U, 0x468c890aU, 0x478e8f02U,\n\t0x4890ad7aU, 0x4992ab72U, 0x4a94a16aU, 0x4b96a762U,\n\t0x4c98b55aU, 0x4d9ab352U, 0x4e9cb94aU, 0x4f9ebf42U,\n\t0x50a0fdbaU, 0x51a2fbb2U, 0x52a4f1aaU, 0x53a6f7a2U,\n\t0x54a8e59aU, 0x55aae392U, 0x56ace98aU, 0x57aeef82U,\n\t0x58b0cdfaU, 0x59b2cbf2U, 0x5ab4c1eaU, 0x5bb6c7e2U,\n\t0x5cb8d5daU, 0x5dbad3d2U, 0x5ebcd9caU, 0x5fbedfc2U,\n\t0x60c05d27U, 0x61c25b2fU, 0x62c45137U, 0x63c6573fU,\n\t0x64c84507U, 0x65ca430fU, 0x66cc4917U, 0x67ce4f1fU,\n\t0x68d06d67U, 0x69d26b6fU, 0x6ad46177U, 0x6bd6677fU,\n\t0x6cd87547U, 0x6dda734fU, 0x6edc7957U, 0x6fde7f5fU,\n\t0x70e03da7U, 0x71e23bafU, 0x72e431b7U, 0x73e637bfU,\n\t0x74e82587U, 0x75ea238fU, 0x76ec2997U, 0x77ee2f9fU,\n\t0x78f00de7U, 0x79f20befU, 0x7af401f7U, 0x7bf607ffU,\n\t0x7cf815c7U, 0x7dfa13cfU, 0x7efc19d7U, 0x7ffe1fdfU,\n\t0x801d2774U, 0x811f217cU, 0x82192b64U, 0x831b2d6cU,\n\t0x84153f54U, 0x8517395cU, 0x86113344U, 0x8713354cU,\n\t0x880d1734U, 0x890f113cU, 0x8a091b24U, 0x8b0b1d2cU,\n\t0x8c050f14U, 0x8d07091cU, 0x8e010304U, 0x8f03050cU,\n\t0x903d47f4U, 0x913f41fcU, 0x92394be4U, 0x933b4decU,\n\t0x94355fd4U, 0x953759dcU, 0x963153c4U, 0x973355ccU,\n\t0x982d77b4U, 0x992f71bcU, 0x9a297ba4U, 0x9b2b7dacU,\n\t0x9c256f94U, 0x9d27699cU, 0x9e216384U, 0x9f23658cU,\n\t0xa05de769U, 0xa15fe161U, 0xa259eb79U, 0xa35bed71U,\n\t0xa455ff49U, 0xa557f941U, 0xa651f359U, 0xa753f551U,\n\t0xa84dd729U, 0xa94fd121U, 0xaa49db39U, 0xab4bdd31U,\n\t0xac45cf09U, 0xad47c901U, 0xae41c319U, 0xaf43c511U,\n\t0xb07d87e9U, 0xb17f81e1U, 0xb2798bf9U, 0xb37b8df1U,\n\t0xb4759fc9U, 0xb57799c1U, 0xb67193d9U, 0xb77395d1U,\n\t0xb86db7a9U, 0xb96fb1a1U, 0xba69bbb9U, 0xbb6bbdb1U,\n\t0xbc65af89U, 0xbd67a981U, 0xbe61a399U, 0xbf63a591U,\n\t0xc09dba4eU, 0xc19fbc46U, 0xc299b65eU, 0xc39bb056U,\n\t0xc495a26eU, 0xc597a466U, 0xc691ae7eU, 0xc793a876U,\n\t0xc88d8a0eU, 0xc98f8c06U, 0xca89861eU, 0xcb8b8016U,\n\t0xcc85922eU, 0xcd879426U, 0xce819e3eU, 0xcf839836U,\n\t0xd0bddaceU, 0xd1bfdcc6U, 0xd2b9d6deU, 0xd3bbd0d6U,\n\t0xd4b5c2eeU, 0xd5b7c4e6U, 0xd6b1cefeU, 0xd7b3c8f6U,\n\t0xd8adea8eU, 0xd9afec86U, 0xdaa9e69eU, 0xdbabe096U,\n\t0xdca5f2aeU, 0xdda7f4a6U, 0xdea1febeU, 0xdfa3f8b6U,\n\t0xe0dd7a53U, 0xe1df7c5bU, 0xe2d97643U, 0xe3db704bU,\n\t0xe4d56273U, 0xe5d7647bU, 0xe6d16e63U, 0xe7d3686bU,\n\t0xe8cd4a13U, 0xe9cf4c1bU, 0xeac94603U, 0xebcb400bU,\n\t0xecc55233U, 0xedc7543bU, 0xeec15e23U, 0xefc3582bU,\n\t0xf0fd1ad3U, 0xf1ff1cdbU, 0xf2f916c3U, 0xf3fb10cbU,\n\t0xf4f502f3U, 0xf5f704fbU, 0xf6f10ee3U, 0xf7f308ebU,\n\t0xf8ed2a93U, 0xf9ef2c9bU, 0xfae92683U, 0xfbeb208bU,\n\t0xfce532b3U, 0xfde734bbU, 0xfee13ea3U, 0xffe338abU,\n};\n\nstatic const u32 rc[] = {\n\t0xba542f74U, 0x53d3d24dU, 0x50ac8dbfU, 0x70529a4cU,\n\t0xead597d1U, 0x33515ba6U, 0xde48a899U, 0xdb32b7fcU,\n\t0xe39e919bU, 0xe2bb416eU, 0xa5cb6b95U, 0xa1f3b102U,\n\t0xccc41d14U, 0xc363da5dU, 0x5fdc7dcdU, 0x7f5a6c5cU,\n\t0xf726ffedU, 0xe89d6f8eU, 0x19a0f089U,\n};\n\nstatic int anubis_setkey(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t\t unsigned int key_len)\n{\n\tstruct anubis_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __be32 *key = (const __be32 *)in_key;\n\tu32 *flags = &tfm->crt_flags;\n\tint N, R, i, r;\n\tu32 kappa[ANUBIS_MAX_N];\n\tu32 inter[ANUBIS_MAX_N];\n\n\tswitch (key_len) {\n\t\tcase 16: case 20: case 24: case 28:\n\t\tcase 32: case 36: case 40:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\t\treturn -EINVAL;\n\t}\n\n\tctx->key_len = key_len * 8;\n\tN = ctx->key_len >> 5;\n\tctx->R = R = 8 + N;\n\n\t/* * map cipher key to initial key state (mu): */\n\tfor (i = 0; i < N; i++)\n\t\tkappa[i] = be32_to_cpu(key[i]);\n\n\t/*\n\t * generate R + 1 round keys:\n\t */\n\tfor (r = 0; r <= R; r++) {\n\t\tu32 K0, K1, K2, K3;\n\t\t/*\n\t\t * generate r-th round key K^r:\n\t\t */\n\t\tK0 = T4[(kappa[N - 1] >> 24)       ];\n\t\tK1 = T4[(kappa[N - 1] >> 16) & 0xff];\n\t\tK2 = T4[(kappa[N - 1] >>  8) & 0xff];\n\t\tK3 = T4[(kappa[N - 1]      ) & 0xff];\n\t\tfor (i = N - 2; i >= 0; i--) {\n\t\t\tK0 = T4[(kappa[i] >> 24)       ] ^\n\t\t\t\t(T5[(K0 >> 24)       ] & 0xff000000U) ^\n\t\t\t\t(T5[(K0 >> 16) & 0xff] & 0x00ff0000U) ^\n\t\t\t\t(T5[(K0 >>  8) & 0xff] & 0x0000ff00U) ^\n\t\t\t\t(T5[(K0      ) & 0xff] & 0x000000ffU);\n\t\t\tK1 = T4[(kappa[i] >> 16) & 0xff] ^\n\t\t\t\t(T5[(K1 >> 24)       ] & 0xff000000U) ^\n\t\t\t\t(T5[(K1 >> 16) & 0xff] & 0x00ff0000U) ^\n\t\t\t\t(T5[(K1 >>  8) & 0xff] & 0x0000ff00U) ^\n\t\t\t\t(T5[(K1      ) & 0xff] & 0x000000ffU);\n\t\t\tK2 = T4[(kappa[i] >>  8) & 0xff] ^\n\t\t\t\t(T5[(K2 >> 24)       ] & 0xff000000U) ^\n\t\t\t\t(T5[(K2 >> 16) & 0xff] & 0x00ff0000U) ^\n\t\t\t\t(T5[(K2 >>  8) & 0xff] & 0x0000ff00U) ^\n\t\t\t\t(T5[(K2      ) & 0xff] & 0x000000ffU);\n\t\t\tK3 = T4[(kappa[i]      ) & 0xff] ^\n\t\t\t\t(T5[(K3 >> 24)       ] & 0xff000000U) ^\n\t\t\t\t(T5[(K3 >> 16) & 0xff] & 0x00ff0000U) ^\n\t\t\t\t(T5[(K3 >>  8) & 0xff] & 0x0000ff00U) ^\n\t\t\t\t(T5[(K3      ) & 0xff] & 0x000000ffU);\n\t\t}\n\n\t\tctx->E[r][0] = K0;\n\t\tctx->E[r][1] = K1;\n\t\tctx->E[r][2] = K2;\n\t\tctx->E[r][3] = K3;\n\n\t\t/*\n\t\t * compute kappa^{r+1} from kappa^r:\n\t\t */\n\t\tif (r == R)\n\t\t\tbreak;\n\t\tfor (i = 0; i < N; i++) {\n\t\t\tint j = i;\n\t\t\tinter[i]  = T0[(kappa[j--] >> 24)       ];\n\t\t\tif (j < 0)\n\t\t\t\tj = N - 1;\n\t\t\tinter[i] ^= T1[(kappa[j--] >> 16) & 0xff];\n\t\t\tif (j < 0)\n\t\t\t\tj = N - 1;\n\t\t\tinter[i] ^= T2[(kappa[j--] >>  8) & 0xff];\n\t\t\tif (j < 0)\n\t\t\t\tj = N - 1;\n\t\t\tinter[i] ^= T3[(kappa[j  ]      ) & 0xff];\n\t\t}\n\t\tkappa[0] = inter[0] ^ rc[r];\n\t\tfor (i = 1; i < N; i++)\n\t\t\tkappa[i] = inter[i];\n\t}\n\n\t/*\n\t * generate inverse key schedule: K'^0 = K^R, K'^R =\n\t * \t\t\t\t  K^0, K'^r = theta(K^{R-r}):\n\t */\n\tfor (i = 0; i < 4; i++) {\n\t\tctx->D[0][i] = ctx->E[R][i];\n\t\tctx->D[R][i] = ctx->E[0][i];\n\t}\n\tfor (r = 1; r < R; r++) {\n\t\tfor (i = 0; i < 4; i++) {\n\t\t\tu32 v = ctx->E[R - r][i];\n\t\t\tctx->D[r][i] =\n\t\t\t\tT0[T4[(v >> 24)       ] & 0xff] ^\n\t\t\t\tT1[T4[(v >> 16) & 0xff] & 0xff] ^\n\t\t\t\tT2[T4[(v >>  8) & 0xff] & 0xff] ^\n\t\t\t\tT3[T4[(v      ) & 0xff] & 0xff];\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void anubis_crypt(u32 roundKey[ANUBIS_MAX_ROUNDS + 1][4],\n\t\tu8 *ciphertext, const u8 *plaintext, const int R)\n{\n\tconst __be32 *src = (const __be32 *)plaintext;\n\t__be32 *dst = (__be32 *)ciphertext;\n\tint i, r;\n\tu32 state[4];\n\tu32 inter[4];\n\n\t/*\n\t * map plaintext block to cipher state (mu)\n\t * and add initial round key (sigma[K^0]):\n\t */\n\tfor (i = 0; i < 4; i++)\n\t\tstate[i] = be32_to_cpu(src[i]) ^ roundKey[0][i];\n\n\t/*\n\t * R - 1 full rounds:\n\t */\n\n\tfor (r = 1; r < R; r++) {\n\t\tinter[0] =\n\t\t\tT0[(state[0] >> 24)       ] ^\n\t\t\tT1[(state[1] >> 24)       ] ^\n\t\t\tT2[(state[2] >> 24)       ] ^\n\t\t\tT3[(state[3] >> 24)       ] ^\n\t\t\troundKey[r][0];\n\t\tinter[1] =\n\t\t\tT0[(state[0] >> 16) & 0xff] ^\n\t\t\tT1[(state[1] >> 16) & 0xff] ^\n\t\t\tT2[(state[2] >> 16) & 0xff] ^\n\t\t\tT3[(state[3] >> 16) & 0xff] ^\n\t\t\troundKey[r][1];\n\t\tinter[2] =\n\t\t\tT0[(state[0] >>  8) & 0xff] ^\n\t\t\tT1[(state[1] >>  8) & 0xff] ^\n\t\t\tT2[(state[2] >>  8) & 0xff] ^\n\t\t\tT3[(state[3] >>  8) & 0xff] ^\n\t\t\troundKey[r][2];\n\t\tinter[3] =\n\t\t\tT0[(state[0]      ) & 0xff] ^\n\t\t\tT1[(state[1]      ) & 0xff] ^\n\t\t\tT2[(state[2]      ) & 0xff] ^\n\t\t\tT3[(state[3]      ) & 0xff] ^\n\t\t\troundKey[r][3];\n\t\tstate[0] = inter[0];\n\t\tstate[1] = inter[1];\n\t\tstate[2] = inter[2];\n\t\tstate[3] = inter[3];\n\t}\n\n\t/*\n\t * last round:\n\t */\n\n\tinter[0] =\n\t\t(T0[(state[0] >> 24)       ] & 0xff000000U) ^\n\t\t(T1[(state[1] >> 24)       ] & 0x00ff0000U) ^\n\t\t(T2[(state[2] >> 24)       ] & 0x0000ff00U) ^\n\t\t(T3[(state[3] >> 24)       ] & 0x000000ffU) ^\n\t\troundKey[R][0];\n\tinter[1] =\n\t\t(T0[(state[0] >> 16) & 0xff] & 0xff000000U) ^\n\t\t(T1[(state[1] >> 16) & 0xff] & 0x00ff0000U) ^\n\t\t(T2[(state[2] >> 16) & 0xff] & 0x0000ff00U) ^\n\t\t(T3[(state[3] >> 16) & 0xff] & 0x000000ffU) ^\n\t\troundKey[R][1];\n\tinter[2] =\n\t\t(T0[(state[0] >>  8) & 0xff] & 0xff000000U) ^\n\t\t(T1[(state[1] >>  8) & 0xff] & 0x00ff0000U) ^\n\t\t(T2[(state[2] >>  8) & 0xff] & 0x0000ff00U) ^\n\t\t(T3[(state[3] >>  8) & 0xff] & 0x000000ffU) ^\n\t\troundKey[R][2];\n\tinter[3] =\n\t\t(T0[(state[0]      ) & 0xff] & 0xff000000U) ^\n\t\t(T1[(state[1]      ) & 0xff] & 0x00ff0000U) ^\n\t\t(T2[(state[2]      ) & 0xff] & 0x0000ff00U) ^\n\t\t(T3[(state[3]      ) & 0xff] & 0x000000ffU) ^\n\t\troundKey[R][3];\n\n\t/*\n\t * map cipher state to ciphertext block (mu^{-1}):\n\t */\n\n\tfor (i = 0; i < 4; i++)\n\t\tdst[i] = cpu_to_be32(inter[i]);\n}\n\nstatic void anubis_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct anubis_ctx *ctx = crypto_tfm_ctx(tfm);\n\tanubis_crypt(ctx->E, dst, src, ctx->R);\n}\n\nstatic void anubis_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct anubis_ctx *ctx = crypto_tfm_ctx(tfm);\n\tanubis_crypt(ctx->D, dst, src, ctx->R);\n}\n\nstatic struct crypto_alg anubis_alg = {\n\t.cra_name\t\t=\t\"anubis\",\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tANUBIS_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof (struct anubis_ctx),\n\t.cra_alignmask\t\t=\t3,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\tANUBIS_MIN_KEY_SIZE,\n\t.cia_max_keysize\t=\tANUBIS_MAX_KEY_SIZE,\n\t.cia_setkey\t\t= \tanubis_setkey,\n\t.cia_encrypt\t\t=\tanubis_encrypt,\n\t.cia_decrypt\t\t=\tanubis_decrypt } }\n};\n\nstatic int __init anubis_mod_init(void)\n{\n\tint ret = 0;\n\n\tret = crypto_register_alg(&anubis_alg);\n\treturn ret;\n}\n\nstatic void __exit anubis_mod_fini(void)\n{\n\tcrypto_unregister_alg(&anubis_alg);\n}\n\nmodule_init(anubis_mod_init);\nmodule_exit(anubis_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Anubis Cryptographic Algorithm\");\nMODULE_ALIAS_CRYPTO(\"anubis\");\n", "/*\n * Scatterlist Cryptographic API.\n *\n * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>\n * Copyright (c) 2002 David S. Miller (davem@redhat.com)\n * Copyright (c) 2005 Herbert Xu <herbert@gondor.apana.org.au>\n *\n * Portions derived from Cryptoapi, by Alexander Kjeldaas <astor@fast.no>\n * and Nettle, by Niels M\u00f6ller.\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#include <linux/err.h>\n#include <linux/errno.h>\n#include <linux/kernel.h>\n#include <linux/kmod.h>\n#include <linux/module.h>\n#include <linux/param.h>\n#include <linux/sched.h>\n#include <linux/slab.h>\n#include <linux/string.h>\n#include \"internal.h\"\n\nLIST_HEAD(crypto_alg_list);\nEXPORT_SYMBOL_GPL(crypto_alg_list);\nDECLARE_RWSEM(crypto_alg_sem);\nEXPORT_SYMBOL_GPL(crypto_alg_sem);\n\nBLOCKING_NOTIFIER_HEAD(crypto_chain);\nEXPORT_SYMBOL_GPL(crypto_chain);\n\nstatic struct crypto_alg *crypto_larval_wait(struct crypto_alg *alg);\n\nstruct crypto_alg *crypto_mod_get(struct crypto_alg *alg)\n{\n\treturn try_module_get(alg->cra_module) ? crypto_alg_get(alg) : NULL;\n}\nEXPORT_SYMBOL_GPL(crypto_mod_get);\n\nvoid crypto_mod_put(struct crypto_alg *alg)\n{\n\tstruct module *module = alg->cra_module;\n\n\tcrypto_alg_put(alg);\n\tmodule_put(module);\n}\nEXPORT_SYMBOL_GPL(crypto_mod_put);\n\nstatic inline int crypto_is_test_larval(struct crypto_larval *larval)\n{\n\treturn larval->alg.cra_driver_name[0];\n}\n\nstatic struct crypto_alg *__crypto_alg_lookup(const char *name, u32 type,\n\t\t\t\t\t      u32 mask)\n{\n\tstruct crypto_alg *q, *alg = NULL;\n\tint best = -2;\n\n\tlist_for_each_entry(q, &crypto_alg_list, cra_list) {\n\t\tint exact, fuzzy;\n\n\t\tif (crypto_is_moribund(q))\n\t\t\tcontinue;\n\n\t\tif ((q->cra_flags ^ type) & mask)\n\t\t\tcontinue;\n\n\t\tif (crypto_is_larval(q) &&\n\t\t    !crypto_is_test_larval((struct crypto_larval *)q) &&\n\t\t    ((struct crypto_larval *)q)->mask != mask)\n\t\t\tcontinue;\n\n\t\texact = !strcmp(q->cra_driver_name, name);\n\t\tfuzzy = !strcmp(q->cra_name, name);\n\t\tif (!exact && !(fuzzy && q->cra_priority > best))\n\t\t\tcontinue;\n\n\t\tif (unlikely(!crypto_mod_get(q)))\n\t\t\tcontinue;\n\n\t\tbest = q->cra_priority;\n\t\tif (alg)\n\t\t\tcrypto_mod_put(alg);\n\t\talg = q;\n\n\t\tif (exact)\n\t\t\tbreak;\n\t}\n\n\treturn alg;\n}\n\nstatic void crypto_larval_destroy(struct crypto_alg *alg)\n{\n\tstruct crypto_larval *larval = (void *)alg;\n\n\tBUG_ON(!crypto_is_larval(alg));\n\tif (larval->adult)\n\t\tcrypto_mod_put(larval->adult);\n\tkfree(larval);\n}\n\nstruct crypto_larval *crypto_larval_alloc(const char *name, u32 type, u32 mask)\n{\n\tstruct crypto_larval *larval;\n\n\tlarval = kzalloc(sizeof(*larval), GFP_KERNEL);\n\tif (!larval)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tlarval->mask = mask;\n\tlarval->alg.cra_flags = CRYPTO_ALG_LARVAL | type;\n\tlarval->alg.cra_priority = -1;\n\tlarval->alg.cra_destroy = crypto_larval_destroy;\n\n\tstrlcpy(larval->alg.cra_name, name, CRYPTO_MAX_ALG_NAME);\n\tinit_completion(&larval->completion);\n\n\treturn larval;\n}\nEXPORT_SYMBOL_GPL(crypto_larval_alloc);\n\nstatic struct crypto_alg *crypto_larval_add(const char *name, u32 type,\n\t\t\t\t\t    u32 mask)\n{\n\tstruct crypto_alg *alg;\n\tstruct crypto_larval *larval;\n\n\tlarval = crypto_larval_alloc(name, type, mask);\n\tif (IS_ERR(larval))\n\t\treturn ERR_CAST(larval);\n\n\tatomic_set(&larval->alg.cra_refcnt, 2);\n\n\tdown_write(&crypto_alg_sem);\n\talg = __crypto_alg_lookup(name, type, mask);\n\tif (!alg) {\n\t\talg = &larval->alg;\n\t\tlist_add(&alg->cra_list, &crypto_alg_list);\n\t}\n\tup_write(&crypto_alg_sem);\n\n\tif (alg != &larval->alg) {\n\t\tkfree(larval);\n\t\tif (crypto_is_larval(alg))\n\t\t\talg = crypto_larval_wait(alg);\n\t}\n\n\treturn alg;\n}\n\nvoid crypto_larval_kill(struct crypto_alg *alg)\n{\n\tstruct crypto_larval *larval = (void *)alg;\n\n\tdown_write(&crypto_alg_sem);\n\tlist_del(&alg->cra_list);\n\tup_write(&crypto_alg_sem);\n\tcomplete_all(&larval->completion);\n\tcrypto_alg_put(alg);\n}\nEXPORT_SYMBOL_GPL(crypto_larval_kill);\n\nstatic struct crypto_alg *crypto_larval_wait(struct crypto_alg *alg)\n{\n\tstruct crypto_larval *larval = (void *)alg;\n\tlong timeout;\n\n\ttimeout = wait_for_completion_interruptible_timeout(\n\t\t&larval->completion, 60 * HZ);\n\n\talg = larval->adult;\n\tif (timeout < 0)\n\t\talg = ERR_PTR(-EINTR);\n\telse if (!timeout)\n\t\talg = ERR_PTR(-ETIMEDOUT);\n\telse if (!alg)\n\t\talg = ERR_PTR(-ENOENT);\n\telse if (crypto_is_test_larval(larval) &&\n\t\t !(alg->cra_flags & CRYPTO_ALG_TESTED))\n\t\talg = ERR_PTR(-EAGAIN);\n\telse if (!crypto_mod_get(alg))\n\t\talg = ERR_PTR(-EAGAIN);\n\tcrypto_mod_put(&larval->alg);\n\n\treturn alg;\n}\n\nstruct crypto_alg *crypto_alg_lookup(const char *name, u32 type, u32 mask)\n{\n\tstruct crypto_alg *alg;\n\n\tdown_read(&crypto_alg_sem);\n\talg = __crypto_alg_lookup(name, type, mask);\n\tup_read(&crypto_alg_sem);\n\n\treturn alg;\n}\nEXPORT_SYMBOL_GPL(crypto_alg_lookup);\n\nstruct crypto_alg *crypto_larval_lookup(const char *name, u32 type, u32 mask)\n{\n\tstruct crypto_alg *alg;\n\n\tif (!name)\n\t\treturn ERR_PTR(-ENOENT);\n\n\tmask &= ~(CRYPTO_ALG_LARVAL | CRYPTO_ALG_DEAD);\n\ttype &= mask;\n\n\talg = crypto_alg_lookup(name, type, mask);\n\tif (!alg) {\n\t\trequest_module(\"crypto-%s\", name);\n\n\t\tif (!((type ^ CRYPTO_ALG_NEED_FALLBACK) & mask &\n\t\t      CRYPTO_ALG_NEED_FALLBACK))\n\t\t\trequest_module(\"crypto-%s-all\", name);\n\n\t\talg = crypto_alg_lookup(name, type, mask);\n\t}\n\n\tif (alg)\n\t\treturn crypto_is_larval(alg) ? crypto_larval_wait(alg) : alg;\n\n\treturn crypto_larval_add(name, type, mask);\n}\nEXPORT_SYMBOL_GPL(crypto_larval_lookup);\n\nint crypto_probing_notify(unsigned long val, void *v)\n{\n\tint ok;\n\n\tok = blocking_notifier_call_chain(&crypto_chain, val, v);\n\tif (ok == NOTIFY_DONE) {\n\t\trequest_module(\"cryptomgr\");\n\t\tok = blocking_notifier_call_chain(&crypto_chain, val, v);\n\t}\n\n\treturn ok;\n}\nEXPORT_SYMBOL_GPL(crypto_probing_notify);\n\nstruct crypto_alg *crypto_alg_mod_lookup(const char *name, u32 type, u32 mask)\n{\n\tstruct crypto_alg *alg;\n\tstruct crypto_alg *larval;\n\tint ok;\n\n\tif (!((type | mask) & CRYPTO_ALG_TESTED)) {\n\t\ttype |= CRYPTO_ALG_TESTED;\n\t\tmask |= CRYPTO_ALG_TESTED;\n\t}\n\n\tlarval = crypto_larval_lookup(name, type, mask);\n\tif (IS_ERR(larval) || !crypto_is_larval(larval))\n\t\treturn larval;\n\n\tok = crypto_probing_notify(CRYPTO_MSG_ALG_REQUEST, larval);\n\n\tif (ok == NOTIFY_STOP)\n\t\talg = crypto_larval_wait(larval);\n\telse {\n\t\tcrypto_mod_put(larval);\n\t\talg = ERR_PTR(-ENOENT);\n\t}\n\tcrypto_larval_kill(larval);\n\treturn alg;\n}\nEXPORT_SYMBOL_GPL(crypto_alg_mod_lookup);\n\nstatic int crypto_init_ops(struct crypto_tfm *tfm, u32 type, u32 mask)\n{\n\tconst struct crypto_type *type_obj = tfm->__crt_alg->cra_type;\n\n\tif (type_obj)\n\t\treturn type_obj->init(tfm, type, mask);\n\n\tswitch (crypto_tfm_alg_type(tfm)) {\n\tcase CRYPTO_ALG_TYPE_CIPHER:\n\t\treturn crypto_init_cipher_ops(tfm);\n\n\tcase CRYPTO_ALG_TYPE_COMPRESS:\n\t\treturn crypto_init_compress_ops(tfm);\n\n\tdefault:\n\t\tbreak;\n\t}\n\n\tBUG();\n\treturn -EINVAL;\n}\n\nstatic void crypto_exit_ops(struct crypto_tfm *tfm)\n{\n\tconst struct crypto_type *type = tfm->__crt_alg->cra_type;\n\n\tif (type) {\n\t\tif (tfm->exit)\n\t\t\ttfm->exit(tfm);\n\t\treturn;\n\t}\n\n\tswitch (crypto_tfm_alg_type(tfm)) {\n\tcase CRYPTO_ALG_TYPE_CIPHER:\n\t\tcrypto_exit_cipher_ops(tfm);\n\t\tbreak;\n\n\tcase CRYPTO_ALG_TYPE_COMPRESS:\n\t\tcrypto_exit_compress_ops(tfm);\n\t\tbreak;\n\n\tdefault:\n\t\tBUG();\n\t}\n}\n\nstatic unsigned int crypto_ctxsize(struct crypto_alg *alg, u32 type, u32 mask)\n{\n\tconst struct crypto_type *type_obj = alg->cra_type;\n\tunsigned int len;\n\n\tlen = alg->cra_alignmask & ~(crypto_tfm_ctx_alignment() - 1);\n\tif (type_obj)\n\t\treturn len + type_obj->ctxsize(alg, type, mask);\n\n\tswitch (alg->cra_flags & CRYPTO_ALG_TYPE_MASK) {\n\tdefault:\n\t\tBUG();\n\n\tcase CRYPTO_ALG_TYPE_CIPHER:\n\t\tlen += crypto_cipher_ctxsize(alg);\n\t\tbreak;\n\n\tcase CRYPTO_ALG_TYPE_COMPRESS:\n\t\tlen += crypto_compress_ctxsize(alg);\n\t\tbreak;\n\t}\n\n\treturn len;\n}\n\nvoid crypto_shoot_alg(struct crypto_alg *alg)\n{\n\tdown_write(&crypto_alg_sem);\n\talg->cra_flags |= CRYPTO_ALG_DYING;\n\tup_write(&crypto_alg_sem);\n}\nEXPORT_SYMBOL_GPL(crypto_shoot_alg);\n\nstruct crypto_tfm *__crypto_alloc_tfm(struct crypto_alg *alg, u32 type,\n\t\t\t\t      u32 mask)\n{\n\tstruct crypto_tfm *tfm = NULL;\n\tunsigned int tfm_size;\n\tint err = -ENOMEM;\n\n\ttfm_size = sizeof(*tfm) + crypto_ctxsize(alg, type, mask);\n\ttfm = kzalloc(tfm_size, GFP_KERNEL);\n\tif (tfm == NULL)\n\t\tgoto out_err;\n\n\ttfm->__crt_alg = alg;\n\n\terr = crypto_init_ops(tfm, type, mask);\n\tif (err)\n\t\tgoto out_free_tfm;\n\n\tif (!tfm->exit && alg->cra_init && (err = alg->cra_init(tfm)))\n\t\tgoto cra_init_failed;\n\n\tgoto out;\n\ncra_init_failed:\n\tcrypto_exit_ops(tfm);\nout_free_tfm:\n\tif (err == -EAGAIN)\n\t\tcrypto_shoot_alg(alg);\n\tkfree(tfm);\nout_err:\n\ttfm = ERR_PTR(err);\nout:\n\treturn tfm;\n}\nEXPORT_SYMBOL_GPL(__crypto_alloc_tfm);\n\n/*\n *\tcrypto_alloc_base - Locate algorithm and allocate transform\n *\t@alg_name: Name of algorithm\n *\t@type: Type of algorithm\n *\t@mask: Mask for type comparison\n *\n *\tThis function should not be used by new algorithm types.\n *\tPlease use crypto_alloc_tfm instead.\n *\n *\tcrypto_alloc_base() will first attempt to locate an already loaded\n *\talgorithm.  If that fails and the kernel supports dynamically loadable\n *\tmodules, it will then attempt to load a module of the same name or\n *\talias.  If that fails it will send a query to any loaded crypto manager\n *\tto construct an algorithm on the fly.  A refcount is grabbed on the\n *\talgorithm which is then associated with the new transform.\n *\n *\tThe returned transform is of a non-determinate type.  Most people\n *\tshould use one of the more specific allocation functions such as\n *\tcrypto_alloc_blkcipher.\n *\n *\tIn case of error the return value is an error pointer.\n */\nstruct crypto_tfm *crypto_alloc_base(const char *alg_name, u32 type, u32 mask)\n{\n\tstruct crypto_tfm *tfm;\n\tint err;\n\n\tfor (;;) {\n\t\tstruct crypto_alg *alg;\n\n\t\talg = crypto_alg_mod_lookup(alg_name, type, mask);\n\t\tif (IS_ERR(alg)) {\n\t\t\terr = PTR_ERR(alg);\n\t\t\tgoto err;\n\t\t}\n\n\t\ttfm = __crypto_alloc_tfm(alg, type, mask);\n\t\tif (!IS_ERR(tfm))\n\t\t\treturn tfm;\n\n\t\tcrypto_mod_put(alg);\n\t\terr = PTR_ERR(tfm);\n\nerr:\n\t\tif (err != -EAGAIN)\n\t\t\tbreak;\n\t\tif (signal_pending(current)) {\n\t\t\terr = -EINTR;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn ERR_PTR(err);\n}\nEXPORT_SYMBOL_GPL(crypto_alloc_base);\n\nvoid *crypto_create_tfm(struct crypto_alg *alg,\n\t\t\tconst struct crypto_type *frontend)\n{\n\tchar *mem;\n\tstruct crypto_tfm *tfm = NULL;\n\tunsigned int tfmsize;\n\tunsigned int total;\n\tint err = -ENOMEM;\n\n\ttfmsize = frontend->tfmsize;\n\ttotal = tfmsize + sizeof(*tfm) + frontend->extsize(alg);\n\n\tmem = kzalloc(total, GFP_KERNEL);\n\tif (mem == NULL)\n\t\tgoto out_err;\n\n\ttfm = (struct crypto_tfm *)(mem + tfmsize);\n\ttfm->__crt_alg = alg;\n\n\terr = frontend->init_tfm(tfm);\n\tif (err)\n\t\tgoto out_free_tfm;\n\n\tif (!tfm->exit && alg->cra_init && (err = alg->cra_init(tfm)))\n\t\tgoto cra_init_failed;\n\n\tgoto out;\n\ncra_init_failed:\n\tcrypto_exit_ops(tfm);\nout_free_tfm:\n\tif (err == -EAGAIN)\n\t\tcrypto_shoot_alg(alg);\n\tkfree(mem);\nout_err:\n\tmem = ERR_PTR(err);\nout:\n\treturn mem;\n}\nEXPORT_SYMBOL_GPL(crypto_create_tfm);\n\nstruct crypto_alg *crypto_find_alg(const char *alg_name,\n\t\t\t\t   const struct crypto_type *frontend,\n\t\t\t\t   u32 type, u32 mask)\n{\n\tstruct crypto_alg *(*lookup)(const char *name, u32 type, u32 mask) =\n\t\tcrypto_alg_mod_lookup;\n\n\tif (frontend) {\n\t\ttype &= frontend->maskclear;\n\t\tmask &= frontend->maskclear;\n\t\ttype |= frontend->type;\n\t\tmask |= frontend->maskset;\n\n\t\tif (frontend->lookup)\n\t\t\tlookup = frontend->lookup;\n\t}\n\n\treturn lookup(alg_name, type, mask);\n}\nEXPORT_SYMBOL_GPL(crypto_find_alg);\n\n/*\n *\tcrypto_alloc_tfm - Locate algorithm and allocate transform\n *\t@alg_name: Name of algorithm\n *\t@frontend: Frontend algorithm type\n *\t@type: Type of algorithm\n *\t@mask: Mask for type comparison\n *\n *\tcrypto_alloc_tfm() will first attempt to locate an already loaded\n *\talgorithm.  If that fails and the kernel supports dynamically loadable\n *\tmodules, it will then attempt to load a module of the same name or\n *\talias.  If that fails it will send a query to any loaded crypto manager\n *\tto construct an algorithm on the fly.  A refcount is grabbed on the\n *\talgorithm which is then associated with the new transform.\n *\n *\tThe returned transform is of a non-determinate type.  Most people\n *\tshould use one of the more specific allocation functions such as\n *\tcrypto_alloc_blkcipher.\n *\n *\tIn case of error the return value is an error pointer.\n */\nvoid *crypto_alloc_tfm(const char *alg_name,\n\t\t       const struct crypto_type *frontend, u32 type, u32 mask)\n{\n\tvoid *tfm;\n\tint err;\n\n\tfor (;;) {\n\t\tstruct crypto_alg *alg;\n\n\t\talg = crypto_find_alg(alg_name, frontend, type, mask);\n\t\tif (IS_ERR(alg)) {\n\t\t\terr = PTR_ERR(alg);\n\t\t\tgoto err;\n\t\t}\n\n\t\ttfm = crypto_create_tfm(alg, frontend);\n\t\tif (!IS_ERR(tfm))\n\t\t\treturn tfm;\n\n\t\tcrypto_mod_put(alg);\n\t\terr = PTR_ERR(tfm);\n\nerr:\n\t\tif (err != -EAGAIN)\n\t\t\tbreak;\n\t\tif (signal_pending(current)) {\n\t\t\terr = -EINTR;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn ERR_PTR(err);\n}\nEXPORT_SYMBOL_GPL(crypto_alloc_tfm);\n\n/*\n *\tcrypto_destroy_tfm - Free crypto transform\n *\t@mem: Start of tfm slab\n *\t@tfm: Transform to free\n *\n *\tThis function frees up the transform and any associated resources,\n *\tthen drops the refcount on the associated algorithm.\n */\nvoid crypto_destroy_tfm(void *mem, struct crypto_tfm *tfm)\n{\n\tstruct crypto_alg *alg;\n\n\tif (unlikely(!mem))\n\t\treturn;\n\n\talg = tfm->__crt_alg;\n\n\tif (!tfm->exit && alg->cra_exit)\n\t\talg->cra_exit(tfm);\n\tcrypto_exit_ops(tfm);\n\tcrypto_mod_put(alg);\n\tkzfree(mem);\n}\nEXPORT_SYMBOL_GPL(crypto_destroy_tfm);\n\nint crypto_has_alg(const char *name, u32 type, u32 mask)\n{\n\tint ret = 0;\n\tstruct crypto_alg *alg = crypto_alg_mod_lookup(name, type, mask);\n\n\tif (!IS_ERR(alg)) {\n\t\tcrypto_mod_put(alg);\n\t\tret = 1;\n\t}\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(crypto_has_alg);\n\nMODULE_DESCRIPTION(\"Cryptographic core API\");\nMODULE_LICENSE(\"GPL\");\n", "/*\n * Cryptographic API\n *\n * ARC4 Cipher Algorithm\n *\n * Jon Oberheide <jon@oberheide.org>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/crypto.h>\n#include <crypto/algapi.h>\n\n#define ARC4_MIN_KEY_SIZE\t1\n#define ARC4_MAX_KEY_SIZE\t256\n#define ARC4_BLOCK_SIZE\t\t1\n\nstruct arc4_ctx {\n\tu32 S[256];\n\tu32 x, y;\n};\n\nstatic int arc4_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t\tunsigned int key_len)\n{\n\tstruct arc4_ctx *ctx = crypto_tfm_ctx(tfm);\n\tint i, j = 0, k = 0;\n\n\tctx->x = 1;\n\tctx->y = 0;\n\n\tfor (i = 0; i < 256; i++)\n\t\tctx->S[i] = i;\n\n\tfor (i = 0; i < 256; i++) {\n\t\tu32 a = ctx->S[i];\n\t\tj = (j + in_key[k] + a) & 0xff;\n\t\tctx->S[i] = ctx->S[j];\n\t\tctx->S[j] = a;\n\t\tif (++k >= key_len)\n\t\t\tk = 0;\n\t}\n\n\treturn 0;\n}\n\nstatic void arc4_crypt(struct arc4_ctx *ctx, u8 *out, const u8 *in,\n\t\t       unsigned int len)\n{\n\tu32 *const S = ctx->S;\n\tu32 x, y, a, b;\n\tu32 ty, ta, tb;\n\n\tif (len == 0)\n\t\treturn;\n\n\tx = ctx->x;\n\ty = ctx->y;\n\n\ta = S[x];\n\ty = (y + a) & 0xff;\n\tb = S[y];\n\n\tdo {\n\t\tS[y] = a;\n\t\ta = (a + b) & 0xff;\n\t\tS[x] = b;\n\t\tx = (x + 1) & 0xff;\n\t\tta = S[x];\n\t\tty = (y + ta) & 0xff;\n\t\ttb = S[ty];\n\t\t*out++ = *in++ ^ S[a];\n\t\tif (--len == 0)\n\t\t\tbreak;\n\t\ty = ty;\n\t\ta = ta;\n\t\tb = tb;\n\t} while (true);\n\n\tctx->x = x;\n\tctx->y = y;\n}\n\nstatic void arc4_crypt_one(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tarc4_crypt(crypto_tfm_ctx(tfm), out, in, 1);\n}\n\nstatic int ecb_arc4_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t\t  struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct arc4_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\twhile (walk.nbytes > 0) {\n\t\tu8 *wsrc = walk.src.virt.addr;\n\t\tu8 *wdst = walk.dst.virt.addr;\n\n\t\tarc4_crypt(ctx, wdst, wsrc, walk.nbytes);\n\n\t\terr = blkcipher_walk_done(desc, &walk, 0);\n\t}\n\n\treturn err;\n}\n\nstatic struct crypto_alg arc4_algs[2] = { {\n\t.cra_name\t\t=\t\"arc4\",\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tARC4_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct arc4_ctx),\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.cipher = {\n\t\t\t.cia_min_keysize\t=\tARC4_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t=\tARC4_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t=\tarc4_set_key,\n\t\t\t.cia_encrypt\t\t=\tarc4_crypt_one,\n\t\t\t.cia_decrypt\t\t=\tarc4_crypt_one,\n\t\t},\n\t},\n}, {\n\t.cra_name\t\t=\t\"ecb(arc4)\",\n\t.cra_priority\t\t=\t100,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t=\tARC4_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct arc4_ctx),\n\t.cra_alignmask\t\t=\t0,\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t=\tARC4_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t=\tARC4_MAX_KEY_SIZE,\n\t\t\t.setkey\t\t=\tarc4_set_key,\n\t\t\t.encrypt\t=\tecb_arc4_crypt,\n\t\t\t.decrypt\t=\tecb_arc4_crypt,\n\t\t},\n\t},\n} };\n\nstatic int __init arc4_init(void)\n{\n\treturn crypto_register_algs(arc4_algs, ARRAY_SIZE(arc4_algs));\n}\n\nstatic void __exit arc4_exit(void)\n{\n\tcrypto_unregister_algs(arc4_algs, ARRAY_SIZE(arc4_algs));\n}\n\nmodule_init(arc4_init);\nmodule_exit(arc4_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"ARC4 Cipher Algorithm\");\nMODULE_AUTHOR(\"Jon Oberheide <jon@oberheide.org>\");\nMODULE_ALIAS_CRYPTO(\"arc4\");\n", "/*\n * Cryptographic API.\n *\n * Blowfish Cipher Algorithm, by Bruce Schneier.\n * http://www.counterpane.com/blowfish.html\n *\n * Adapted from Kerneli implementation.\n *\n * Copyright (c) Herbert Valerio Riedel <hvr@hvrlab.org>\n * Copyright (c) Kyle McMartin <kyle@debian.org>\n * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <asm/byteorder.h>\n#include <linux/crypto.h>\n#include <linux/types.h>\n#include <crypto/blowfish.h>\n\n/*\n * Round loop unrolling macros, S is a pointer to a S-Box array\n * organized in 4 unsigned longs at a row.\n */\n#define GET32_3(x) (((x) & 0xff))\n#define GET32_2(x) (((x) >> (8)) & (0xff))\n#define GET32_1(x) (((x) >> (16)) & (0xff))\n#define GET32_0(x) (((x) >> (24)) & (0xff))\n\n#define bf_F(x) (((S[GET32_0(x)] + S[256 + GET32_1(x)]) ^ \\\n\t\tS[512 + GET32_2(x)]) + S[768 + GET32_3(x)])\n\n#define ROUND(a, b, n) ({ b ^= P[n]; a ^= bf_F(b); })\n\nstatic void bf_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct bf_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __be32 *in_blk = (const __be32 *)src;\n\t__be32 *const out_blk = (__be32 *)dst;\n\tconst u32 *P = ctx->p;\n\tconst u32 *S = ctx->s;\n\tu32 yl = be32_to_cpu(in_blk[0]);\n\tu32 yr = be32_to_cpu(in_blk[1]);\n\n\tROUND(yr, yl, 0);\n\tROUND(yl, yr, 1);\n\tROUND(yr, yl, 2);\n\tROUND(yl, yr, 3);\n\tROUND(yr, yl, 4);\n\tROUND(yl, yr, 5);\n\tROUND(yr, yl, 6);\n\tROUND(yl, yr, 7);\n\tROUND(yr, yl, 8);\n\tROUND(yl, yr, 9);\n\tROUND(yr, yl, 10);\n\tROUND(yl, yr, 11);\n\tROUND(yr, yl, 12);\n\tROUND(yl, yr, 13);\n\tROUND(yr, yl, 14);\n\tROUND(yl, yr, 15);\n\n\tyl ^= P[16];\n\tyr ^= P[17];\n\n\tout_blk[0] = cpu_to_be32(yr);\n\tout_blk[1] = cpu_to_be32(yl);\n}\n\nstatic void bf_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct bf_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __be32 *in_blk = (const __be32 *)src;\n\t__be32 *const out_blk = (__be32 *)dst;\n\tconst u32 *P = ctx->p;\n\tconst u32 *S = ctx->s;\n\tu32 yl = be32_to_cpu(in_blk[0]);\n\tu32 yr = be32_to_cpu(in_blk[1]);\n\n\tROUND(yr, yl, 17);\n\tROUND(yl, yr, 16);\n\tROUND(yr, yl, 15);\n\tROUND(yl, yr, 14);\n\tROUND(yr, yl, 13);\n\tROUND(yl, yr, 12);\n\tROUND(yr, yl, 11);\n\tROUND(yl, yr, 10);\n\tROUND(yr, yl, 9);\n\tROUND(yl, yr, 8);\n\tROUND(yr, yl, 7);\n\tROUND(yl, yr, 6);\n\tROUND(yr, yl, 5);\n\tROUND(yl, yr, 4);\n\tROUND(yr, yl, 3);\n\tROUND(yl, yr, 2);\n\n\tyl ^= P[1];\n\tyr ^= P[0];\n\n\tout_blk[0] = cpu_to_be32(yr);\n\tout_blk[1] = cpu_to_be32(yl);\n}\n\nstatic struct crypto_alg alg = {\n\t.cra_name\t\t=\t\"blowfish\",\n\t.cra_driver_name\t=\t\"blowfish-generic\",\n\t.cra_priority\t\t=\t100,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tBF_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct bf_ctx),\n\t.cra_alignmask\t\t=\t3,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\tBF_MIN_KEY_SIZE,\n\t.cia_max_keysize\t=\tBF_MAX_KEY_SIZE,\n\t.cia_setkey\t\t=\tblowfish_setkey,\n\t.cia_encrypt\t\t=\tbf_encrypt,\n\t.cia_decrypt\t\t=\tbf_decrypt } }\n};\n\nstatic int __init blowfish_mod_init(void)\n{\n\treturn crypto_register_alg(&alg);\n}\n\nstatic void __exit blowfish_mod_fini(void)\n{\n\tcrypto_unregister_alg(&alg);\n}\n\nmodule_init(blowfish_mod_init);\nmodule_exit(blowfish_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Blowfish Cipher Algorithm\");\nMODULE_ALIAS_CRYPTO(\"blowfish\");\n", "/*\n * Copyright (C) 2006\n * NTT (Nippon Telegraph and Telephone Corporation).\n *\n * This program is free software; you can redistribute it and/or\n * modify it under the terms of the GNU General Public License\n * as published by the Free Software Foundation; either version 2\n * of the License, or (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.\n */\n\n/*\n * Algorithm Specification\n *  http://info.isl.ntt.co.jp/crypt/eng/camellia/specifications.html\n */\n\n/*\n *\n * NOTE --- NOTE --- NOTE --- NOTE\n * This implementation assumes that all memory addresses passed\n * as parameters are four-byte aligned.\n *\n */\n\n#include <linux/crypto.h>\n#include <linux/errno.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/bitops.h>\n#include <asm/unaligned.h>\n\nstatic const u32 camellia_sp1110[256] = {\n\t0x70707000, 0x82828200, 0x2c2c2c00, 0xececec00,\n\t0xb3b3b300, 0x27272700, 0xc0c0c000, 0xe5e5e500,\n\t0xe4e4e400, 0x85858500, 0x57575700, 0x35353500,\n\t0xeaeaea00, 0x0c0c0c00, 0xaeaeae00, 0x41414100,\n\t0x23232300, 0xefefef00, 0x6b6b6b00, 0x93939300,\n\t0x45454500, 0x19191900, 0xa5a5a500, 0x21212100,\n\t0xededed00, 0x0e0e0e00, 0x4f4f4f00, 0x4e4e4e00,\n\t0x1d1d1d00, 0x65656500, 0x92929200, 0xbdbdbd00,\n\t0x86868600, 0xb8b8b800, 0xafafaf00, 0x8f8f8f00,\n\t0x7c7c7c00, 0xebebeb00, 0x1f1f1f00, 0xcecece00,\n\t0x3e3e3e00, 0x30303000, 0xdcdcdc00, 0x5f5f5f00,\n\t0x5e5e5e00, 0xc5c5c500, 0x0b0b0b00, 0x1a1a1a00,\n\t0xa6a6a600, 0xe1e1e100, 0x39393900, 0xcacaca00,\n\t0xd5d5d500, 0x47474700, 0x5d5d5d00, 0x3d3d3d00,\n\t0xd9d9d900, 0x01010100, 0x5a5a5a00, 0xd6d6d600,\n\t0x51515100, 0x56565600, 0x6c6c6c00, 0x4d4d4d00,\n\t0x8b8b8b00, 0x0d0d0d00, 0x9a9a9a00, 0x66666600,\n\t0xfbfbfb00, 0xcccccc00, 0xb0b0b000, 0x2d2d2d00,\n\t0x74747400, 0x12121200, 0x2b2b2b00, 0x20202000,\n\t0xf0f0f000, 0xb1b1b100, 0x84848400, 0x99999900,\n\t0xdfdfdf00, 0x4c4c4c00, 0xcbcbcb00, 0xc2c2c200,\n\t0x34343400, 0x7e7e7e00, 0x76767600, 0x05050500,\n\t0x6d6d6d00, 0xb7b7b700, 0xa9a9a900, 0x31313100,\n\t0xd1d1d100, 0x17171700, 0x04040400, 0xd7d7d700,\n\t0x14141400, 0x58585800, 0x3a3a3a00, 0x61616100,\n\t0xdedede00, 0x1b1b1b00, 0x11111100, 0x1c1c1c00,\n\t0x32323200, 0x0f0f0f00, 0x9c9c9c00, 0x16161600,\n\t0x53535300, 0x18181800, 0xf2f2f200, 0x22222200,\n\t0xfefefe00, 0x44444400, 0xcfcfcf00, 0xb2b2b200,\n\t0xc3c3c300, 0xb5b5b500, 0x7a7a7a00, 0x91919100,\n\t0x24242400, 0x08080800, 0xe8e8e800, 0xa8a8a800,\n\t0x60606000, 0xfcfcfc00, 0x69696900, 0x50505000,\n\t0xaaaaaa00, 0xd0d0d000, 0xa0a0a000, 0x7d7d7d00,\n\t0xa1a1a100, 0x89898900, 0x62626200, 0x97979700,\n\t0x54545400, 0x5b5b5b00, 0x1e1e1e00, 0x95959500,\n\t0xe0e0e000, 0xffffff00, 0x64646400, 0xd2d2d200,\n\t0x10101000, 0xc4c4c400, 0x00000000, 0x48484800,\n\t0xa3a3a300, 0xf7f7f700, 0x75757500, 0xdbdbdb00,\n\t0x8a8a8a00, 0x03030300, 0xe6e6e600, 0xdadada00,\n\t0x09090900, 0x3f3f3f00, 0xdddddd00, 0x94949400,\n\t0x87878700, 0x5c5c5c00, 0x83838300, 0x02020200,\n\t0xcdcdcd00, 0x4a4a4a00, 0x90909000, 0x33333300,\n\t0x73737300, 0x67676700, 0xf6f6f600, 0xf3f3f300,\n\t0x9d9d9d00, 0x7f7f7f00, 0xbfbfbf00, 0xe2e2e200,\n\t0x52525200, 0x9b9b9b00, 0xd8d8d800, 0x26262600,\n\t0xc8c8c800, 0x37373700, 0xc6c6c600, 0x3b3b3b00,\n\t0x81818100, 0x96969600, 0x6f6f6f00, 0x4b4b4b00,\n\t0x13131300, 0xbebebe00, 0x63636300, 0x2e2e2e00,\n\t0xe9e9e900, 0x79797900, 0xa7a7a700, 0x8c8c8c00,\n\t0x9f9f9f00, 0x6e6e6e00, 0xbcbcbc00, 0x8e8e8e00,\n\t0x29292900, 0xf5f5f500, 0xf9f9f900, 0xb6b6b600,\n\t0x2f2f2f00, 0xfdfdfd00, 0xb4b4b400, 0x59595900,\n\t0x78787800, 0x98989800, 0x06060600, 0x6a6a6a00,\n\t0xe7e7e700, 0x46464600, 0x71717100, 0xbababa00,\n\t0xd4d4d400, 0x25252500, 0xababab00, 0x42424200,\n\t0x88888800, 0xa2a2a200, 0x8d8d8d00, 0xfafafa00,\n\t0x72727200, 0x07070700, 0xb9b9b900, 0x55555500,\n\t0xf8f8f800, 0xeeeeee00, 0xacacac00, 0x0a0a0a00,\n\t0x36363600, 0x49494900, 0x2a2a2a00, 0x68686800,\n\t0x3c3c3c00, 0x38383800, 0xf1f1f100, 0xa4a4a400,\n\t0x40404000, 0x28282800, 0xd3d3d300, 0x7b7b7b00,\n\t0xbbbbbb00, 0xc9c9c900, 0x43434300, 0xc1c1c100,\n\t0x15151500, 0xe3e3e300, 0xadadad00, 0xf4f4f400,\n\t0x77777700, 0xc7c7c700, 0x80808000, 0x9e9e9e00,\n};\n\nstatic const u32 camellia_sp0222[256] = {\n\t0x00e0e0e0, 0x00050505, 0x00585858, 0x00d9d9d9,\n\t0x00676767, 0x004e4e4e, 0x00818181, 0x00cbcbcb,\n\t0x00c9c9c9, 0x000b0b0b, 0x00aeaeae, 0x006a6a6a,\n\t0x00d5d5d5, 0x00181818, 0x005d5d5d, 0x00828282,\n\t0x00464646, 0x00dfdfdf, 0x00d6d6d6, 0x00272727,\n\t0x008a8a8a, 0x00323232, 0x004b4b4b, 0x00424242,\n\t0x00dbdbdb, 0x001c1c1c, 0x009e9e9e, 0x009c9c9c,\n\t0x003a3a3a, 0x00cacaca, 0x00252525, 0x007b7b7b,\n\t0x000d0d0d, 0x00717171, 0x005f5f5f, 0x001f1f1f,\n\t0x00f8f8f8, 0x00d7d7d7, 0x003e3e3e, 0x009d9d9d,\n\t0x007c7c7c, 0x00606060, 0x00b9b9b9, 0x00bebebe,\n\t0x00bcbcbc, 0x008b8b8b, 0x00161616, 0x00343434,\n\t0x004d4d4d, 0x00c3c3c3, 0x00727272, 0x00959595,\n\t0x00ababab, 0x008e8e8e, 0x00bababa, 0x007a7a7a,\n\t0x00b3b3b3, 0x00020202, 0x00b4b4b4, 0x00adadad,\n\t0x00a2a2a2, 0x00acacac, 0x00d8d8d8, 0x009a9a9a,\n\t0x00171717, 0x001a1a1a, 0x00353535, 0x00cccccc,\n\t0x00f7f7f7, 0x00999999, 0x00616161, 0x005a5a5a,\n\t0x00e8e8e8, 0x00242424, 0x00565656, 0x00404040,\n\t0x00e1e1e1, 0x00636363, 0x00090909, 0x00333333,\n\t0x00bfbfbf, 0x00989898, 0x00979797, 0x00858585,\n\t0x00686868, 0x00fcfcfc, 0x00ececec, 0x000a0a0a,\n\t0x00dadada, 0x006f6f6f, 0x00535353, 0x00626262,\n\t0x00a3a3a3, 0x002e2e2e, 0x00080808, 0x00afafaf,\n\t0x00282828, 0x00b0b0b0, 0x00747474, 0x00c2c2c2,\n\t0x00bdbdbd, 0x00363636, 0x00222222, 0x00383838,\n\t0x00646464, 0x001e1e1e, 0x00393939, 0x002c2c2c,\n\t0x00a6a6a6, 0x00303030, 0x00e5e5e5, 0x00444444,\n\t0x00fdfdfd, 0x00888888, 0x009f9f9f, 0x00656565,\n\t0x00878787, 0x006b6b6b, 0x00f4f4f4, 0x00232323,\n\t0x00484848, 0x00101010, 0x00d1d1d1, 0x00515151,\n\t0x00c0c0c0, 0x00f9f9f9, 0x00d2d2d2, 0x00a0a0a0,\n\t0x00555555, 0x00a1a1a1, 0x00414141, 0x00fafafa,\n\t0x00434343, 0x00131313, 0x00c4c4c4, 0x002f2f2f,\n\t0x00a8a8a8, 0x00b6b6b6, 0x003c3c3c, 0x002b2b2b,\n\t0x00c1c1c1, 0x00ffffff, 0x00c8c8c8, 0x00a5a5a5,\n\t0x00202020, 0x00898989, 0x00000000, 0x00909090,\n\t0x00474747, 0x00efefef, 0x00eaeaea, 0x00b7b7b7,\n\t0x00151515, 0x00060606, 0x00cdcdcd, 0x00b5b5b5,\n\t0x00121212, 0x007e7e7e, 0x00bbbbbb, 0x00292929,\n\t0x000f0f0f, 0x00b8b8b8, 0x00070707, 0x00040404,\n\t0x009b9b9b, 0x00949494, 0x00212121, 0x00666666,\n\t0x00e6e6e6, 0x00cecece, 0x00ededed, 0x00e7e7e7,\n\t0x003b3b3b, 0x00fefefe, 0x007f7f7f, 0x00c5c5c5,\n\t0x00a4a4a4, 0x00373737, 0x00b1b1b1, 0x004c4c4c,\n\t0x00919191, 0x006e6e6e, 0x008d8d8d, 0x00767676,\n\t0x00030303, 0x002d2d2d, 0x00dedede, 0x00969696,\n\t0x00262626, 0x007d7d7d, 0x00c6c6c6, 0x005c5c5c,\n\t0x00d3d3d3, 0x00f2f2f2, 0x004f4f4f, 0x00191919,\n\t0x003f3f3f, 0x00dcdcdc, 0x00797979, 0x001d1d1d,\n\t0x00525252, 0x00ebebeb, 0x00f3f3f3, 0x006d6d6d,\n\t0x005e5e5e, 0x00fbfbfb, 0x00696969, 0x00b2b2b2,\n\t0x00f0f0f0, 0x00313131, 0x000c0c0c, 0x00d4d4d4,\n\t0x00cfcfcf, 0x008c8c8c, 0x00e2e2e2, 0x00757575,\n\t0x00a9a9a9, 0x004a4a4a, 0x00575757, 0x00848484,\n\t0x00111111, 0x00454545, 0x001b1b1b, 0x00f5f5f5,\n\t0x00e4e4e4, 0x000e0e0e, 0x00737373, 0x00aaaaaa,\n\t0x00f1f1f1, 0x00dddddd, 0x00595959, 0x00141414,\n\t0x006c6c6c, 0x00929292, 0x00545454, 0x00d0d0d0,\n\t0x00787878, 0x00707070, 0x00e3e3e3, 0x00494949,\n\t0x00808080, 0x00505050, 0x00a7a7a7, 0x00f6f6f6,\n\t0x00777777, 0x00939393, 0x00868686, 0x00838383,\n\t0x002a2a2a, 0x00c7c7c7, 0x005b5b5b, 0x00e9e9e9,\n\t0x00eeeeee, 0x008f8f8f, 0x00010101, 0x003d3d3d,\n};\n\nstatic const u32 camellia_sp3033[256] = {\n\t0x38003838, 0x41004141, 0x16001616, 0x76007676,\n\t0xd900d9d9, 0x93009393, 0x60006060, 0xf200f2f2,\n\t0x72007272, 0xc200c2c2, 0xab00abab, 0x9a009a9a,\n\t0x75007575, 0x06000606, 0x57005757, 0xa000a0a0,\n\t0x91009191, 0xf700f7f7, 0xb500b5b5, 0xc900c9c9,\n\t0xa200a2a2, 0x8c008c8c, 0xd200d2d2, 0x90009090,\n\t0xf600f6f6, 0x07000707, 0xa700a7a7, 0x27002727,\n\t0x8e008e8e, 0xb200b2b2, 0x49004949, 0xde00dede,\n\t0x43004343, 0x5c005c5c, 0xd700d7d7, 0xc700c7c7,\n\t0x3e003e3e, 0xf500f5f5, 0x8f008f8f, 0x67006767,\n\t0x1f001f1f, 0x18001818, 0x6e006e6e, 0xaf00afaf,\n\t0x2f002f2f, 0xe200e2e2, 0x85008585, 0x0d000d0d,\n\t0x53005353, 0xf000f0f0, 0x9c009c9c, 0x65006565,\n\t0xea00eaea, 0xa300a3a3, 0xae00aeae, 0x9e009e9e,\n\t0xec00ecec, 0x80008080, 0x2d002d2d, 0x6b006b6b,\n\t0xa800a8a8, 0x2b002b2b, 0x36003636, 0xa600a6a6,\n\t0xc500c5c5, 0x86008686, 0x4d004d4d, 0x33003333,\n\t0xfd00fdfd, 0x66006666, 0x58005858, 0x96009696,\n\t0x3a003a3a, 0x09000909, 0x95009595, 0x10001010,\n\t0x78007878, 0xd800d8d8, 0x42004242, 0xcc00cccc,\n\t0xef00efef, 0x26002626, 0xe500e5e5, 0x61006161,\n\t0x1a001a1a, 0x3f003f3f, 0x3b003b3b, 0x82008282,\n\t0xb600b6b6, 0xdb00dbdb, 0xd400d4d4, 0x98009898,\n\t0xe800e8e8, 0x8b008b8b, 0x02000202, 0xeb00ebeb,\n\t0x0a000a0a, 0x2c002c2c, 0x1d001d1d, 0xb000b0b0,\n\t0x6f006f6f, 0x8d008d8d, 0x88008888, 0x0e000e0e,\n\t0x19001919, 0x87008787, 0x4e004e4e, 0x0b000b0b,\n\t0xa900a9a9, 0x0c000c0c, 0x79007979, 0x11001111,\n\t0x7f007f7f, 0x22002222, 0xe700e7e7, 0x59005959,\n\t0xe100e1e1, 0xda00dada, 0x3d003d3d, 0xc800c8c8,\n\t0x12001212, 0x04000404, 0x74007474, 0x54005454,\n\t0x30003030, 0x7e007e7e, 0xb400b4b4, 0x28002828,\n\t0x55005555, 0x68006868, 0x50005050, 0xbe00bebe,\n\t0xd000d0d0, 0xc400c4c4, 0x31003131, 0xcb00cbcb,\n\t0x2a002a2a, 0xad00adad, 0x0f000f0f, 0xca00caca,\n\t0x70007070, 0xff00ffff, 0x32003232, 0x69006969,\n\t0x08000808, 0x62006262, 0x00000000, 0x24002424,\n\t0xd100d1d1, 0xfb00fbfb, 0xba00baba, 0xed00eded,\n\t0x45004545, 0x81008181, 0x73007373, 0x6d006d6d,\n\t0x84008484, 0x9f009f9f, 0xee00eeee, 0x4a004a4a,\n\t0xc300c3c3, 0x2e002e2e, 0xc100c1c1, 0x01000101,\n\t0xe600e6e6, 0x25002525, 0x48004848, 0x99009999,\n\t0xb900b9b9, 0xb300b3b3, 0x7b007b7b, 0xf900f9f9,\n\t0xce00cece, 0xbf00bfbf, 0xdf00dfdf, 0x71007171,\n\t0x29002929, 0xcd00cdcd, 0x6c006c6c, 0x13001313,\n\t0x64006464, 0x9b009b9b, 0x63006363, 0x9d009d9d,\n\t0xc000c0c0, 0x4b004b4b, 0xb700b7b7, 0xa500a5a5,\n\t0x89008989, 0x5f005f5f, 0xb100b1b1, 0x17001717,\n\t0xf400f4f4, 0xbc00bcbc, 0xd300d3d3, 0x46004646,\n\t0xcf00cfcf, 0x37003737, 0x5e005e5e, 0x47004747,\n\t0x94009494, 0xfa00fafa, 0xfc00fcfc, 0x5b005b5b,\n\t0x97009797, 0xfe00fefe, 0x5a005a5a, 0xac00acac,\n\t0x3c003c3c, 0x4c004c4c, 0x03000303, 0x35003535,\n\t0xf300f3f3, 0x23002323, 0xb800b8b8, 0x5d005d5d,\n\t0x6a006a6a, 0x92009292, 0xd500d5d5, 0x21002121,\n\t0x44004444, 0x51005151, 0xc600c6c6, 0x7d007d7d,\n\t0x39003939, 0x83008383, 0xdc00dcdc, 0xaa00aaaa,\n\t0x7c007c7c, 0x77007777, 0x56005656, 0x05000505,\n\t0x1b001b1b, 0xa400a4a4, 0x15001515, 0x34003434,\n\t0x1e001e1e, 0x1c001c1c, 0xf800f8f8, 0x52005252,\n\t0x20002020, 0x14001414, 0xe900e9e9, 0xbd00bdbd,\n\t0xdd00dddd, 0xe400e4e4, 0xa100a1a1, 0xe000e0e0,\n\t0x8a008a8a, 0xf100f1f1, 0xd600d6d6, 0x7a007a7a,\n\t0xbb00bbbb, 0xe300e3e3, 0x40004040, 0x4f004f4f,\n};\n\nstatic const u32 camellia_sp4404[256] = {\n\t0x70700070, 0x2c2c002c, 0xb3b300b3, 0xc0c000c0,\n\t0xe4e400e4, 0x57570057, 0xeaea00ea, 0xaeae00ae,\n\t0x23230023, 0x6b6b006b, 0x45450045, 0xa5a500a5,\n\t0xeded00ed, 0x4f4f004f, 0x1d1d001d, 0x92920092,\n\t0x86860086, 0xafaf00af, 0x7c7c007c, 0x1f1f001f,\n\t0x3e3e003e, 0xdcdc00dc, 0x5e5e005e, 0x0b0b000b,\n\t0xa6a600a6, 0x39390039, 0xd5d500d5, 0x5d5d005d,\n\t0xd9d900d9, 0x5a5a005a, 0x51510051, 0x6c6c006c,\n\t0x8b8b008b, 0x9a9a009a, 0xfbfb00fb, 0xb0b000b0,\n\t0x74740074, 0x2b2b002b, 0xf0f000f0, 0x84840084,\n\t0xdfdf00df, 0xcbcb00cb, 0x34340034, 0x76760076,\n\t0x6d6d006d, 0xa9a900a9, 0xd1d100d1, 0x04040004,\n\t0x14140014, 0x3a3a003a, 0xdede00de, 0x11110011,\n\t0x32320032, 0x9c9c009c, 0x53530053, 0xf2f200f2,\n\t0xfefe00fe, 0xcfcf00cf, 0xc3c300c3, 0x7a7a007a,\n\t0x24240024, 0xe8e800e8, 0x60600060, 0x69690069,\n\t0xaaaa00aa, 0xa0a000a0, 0xa1a100a1, 0x62620062,\n\t0x54540054, 0x1e1e001e, 0xe0e000e0, 0x64640064,\n\t0x10100010, 0x00000000, 0xa3a300a3, 0x75750075,\n\t0x8a8a008a, 0xe6e600e6, 0x09090009, 0xdddd00dd,\n\t0x87870087, 0x83830083, 0xcdcd00cd, 0x90900090,\n\t0x73730073, 0xf6f600f6, 0x9d9d009d, 0xbfbf00bf,\n\t0x52520052, 0xd8d800d8, 0xc8c800c8, 0xc6c600c6,\n\t0x81810081, 0x6f6f006f, 0x13130013, 0x63630063,\n\t0xe9e900e9, 0xa7a700a7, 0x9f9f009f, 0xbcbc00bc,\n\t0x29290029, 0xf9f900f9, 0x2f2f002f, 0xb4b400b4,\n\t0x78780078, 0x06060006, 0xe7e700e7, 0x71710071,\n\t0xd4d400d4, 0xabab00ab, 0x88880088, 0x8d8d008d,\n\t0x72720072, 0xb9b900b9, 0xf8f800f8, 0xacac00ac,\n\t0x36360036, 0x2a2a002a, 0x3c3c003c, 0xf1f100f1,\n\t0x40400040, 0xd3d300d3, 0xbbbb00bb, 0x43430043,\n\t0x15150015, 0xadad00ad, 0x77770077, 0x80800080,\n\t0x82820082, 0xecec00ec, 0x27270027, 0xe5e500e5,\n\t0x85850085, 0x35350035, 0x0c0c000c, 0x41410041,\n\t0xefef00ef, 0x93930093, 0x19190019, 0x21210021,\n\t0x0e0e000e, 0x4e4e004e, 0x65650065, 0xbdbd00bd,\n\t0xb8b800b8, 0x8f8f008f, 0xebeb00eb, 0xcece00ce,\n\t0x30300030, 0x5f5f005f, 0xc5c500c5, 0x1a1a001a,\n\t0xe1e100e1, 0xcaca00ca, 0x47470047, 0x3d3d003d,\n\t0x01010001, 0xd6d600d6, 0x56560056, 0x4d4d004d,\n\t0x0d0d000d, 0x66660066, 0xcccc00cc, 0x2d2d002d,\n\t0x12120012, 0x20200020, 0xb1b100b1, 0x99990099,\n\t0x4c4c004c, 0xc2c200c2, 0x7e7e007e, 0x05050005,\n\t0xb7b700b7, 0x31310031, 0x17170017, 0xd7d700d7,\n\t0x58580058, 0x61610061, 0x1b1b001b, 0x1c1c001c,\n\t0x0f0f000f, 0x16160016, 0x18180018, 0x22220022,\n\t0x44440044, 0xb2b200b2, 0xb5b500b5, 0x91910091,\n\t0x08080008, 0xa8a800a8, 0xfcfc00fc, 0x50500050,\n\t0xd0d000d0, 0x7d7d007d, 0x89890089, 0x97970097,\n\t0x5b5b005b, 0x95950095, 0xffff00ff, 0xd2d200d2,\n\t0xc4c400c4, 0x48480048, 0xf7f700f7, 0xdbdb00db,\n\t0x03030003, 0xdada00da, 0x3f3f003f, 0x94940094,\n\t0x5c5c005c, 0x02020002, 0x4a4a004a, 0x33330033,\n\t0x67670067, 0xf3f300f3, 0x7f7f007f, 0xe2e200e2,\n\t0x9b9b009b, 0x26260026, 0x37370037, 0x3b3b003b,\n\t0x96960096, 0x4b4b004b, 0xbebe00be, 0x2e2e002e,\n\t0x79790079, 0x8c8c008c, 0x6e6e006e, 0x8e8e008e,\n\t0xf5f500f5, 0xb6b600b6, 0xfdfd00fd, 0x59590059,\n\t0x98980098, 0x6a6a006a, 0x46460046, 0xbaba00ba,\n\t0x25250025, 0x42420042, 0xa2a200a2, 0xfafa00fa,\n\t0x07070007, 0x55550055, 0xeeee00ee, 0x0a0a000a,\n\t0x49490049, 0x68680068, 0x38380038, 0xa4a400a4,\n\t0x28280028, 0x7b7b007b, 0xc9c900c9, 0xc1c100c1,\n\t0xe3e300e3, 0xf4f400f4, 0xc7c700c7, 0x9e9e009e,\n};\n\n\n#define CAMELLIA_MIN_KEY_SIZE        16\n#define CAMELLIA_MAX_KEY_SIZE        32\n#define CAMELLIA_BLOCK_SIZE          16\n#define CAMELLIA_TABLE_BYTE_LEN     272\n\n/*\n * NB: L and R below stand for 'left' and 'right' as in written numbers.\n * That is, in (xxxL,xxxR) pair xxxL holds most significant digits,\n * _not_ least significant ones!\n */\n\n\n/* key constants */\n\n#define CAMELLIA_SIGMA1L (0xA09E667FL)\n#define CAMELLIA_SIGMA1R (0x3BCC908BL)\n#define CAMELLIA_SIGMA2L (0xB67AE858L)\n#define CAMELLIA_SIGMA2R (0x4CAA73B2L)\n#define CAMELLIA_SIGMA3L (0xC6EF372FL)\n#define CAMELLIA_SIGMA3R (0xE94F82BEL)\n#define CAMELLIA_SIGMA4L (0x54FF53A5L)\n#define CAMELLIA_SIGMA4R (0xF1D36F1CL)\n#define CAMELLIA_SIGMA5L (0x10E527FAL)\n#define CAMELLIA_SIGMA5R (0xDE682D1DL)\n#define CAMELLIA_SIGMA6L (0xB05688C2L)\n#define CAMELLIA_SIGMA6R (0xB3E6C1FDL)\n\n/*\n *  macros\n */\n#define ROLDQ(ll, lr, rl, rr, w0, w1, bits) ({\t\t\\\n\tw0 = ll;\t\t\t\t\t\\\n\tll = (ll << bits) + (lr >> (32 - bits));\t\\\n\tlr = (lr << bits) + (rl >> (32 - bits));\t\\\n\trl = (rl << bits) + (rr >> (32 - bits));\t\\\n\trr = (rr << bits) + (w0 >> (32 - bits));\t\\\n})\n\n#define ROLDQo32(ll, lr, rl, rr, w0, w1, bits) ({\t\\\n\tw0 = ll;\t\t\t\t\t\\\n\tw1 = lr;\t\t\t\t\t\\\n\tll = (lr << (bits - 32)) + (rl >> (64 - bits));\t\\\n\tlr = (rl << (bits - 32)) + (rr >> (64 - bits));\t\\\n\trl = (rr << (bits - 32)) + (w0 >> (64 - bits));\t\\\n\trr = (w0 << (bits - 32)) + (w1 >> (64 - bits));\t\\\n})\n\n#define CAMELLIA_F(xl, xr, kl, kr, yl, yr, il, ir, t0, t1) ({\t\\\n\til = xl ^ kl;\t\t\t\t\t\t\\\n\tir = xr ^ kr;\t\t\t\t\t\t\\\n\tt0 = il >> 16;\t\t\t\t\t\t\\\n\tt1 = ir >> 16;\t\t\t\t\t\t\\\n\tyl = camellia_sp1110[(u8)(ir)]\t\t\t\t\\\n\t   ^ camellia_sp0222[(u8)(t1 >> 8)]\t\t\t\\\n\t   ^ camellia_sp3033[(u8)(t1)]\t\t\t\t\\\n\t   ^ camellia_sp4404[(u8)(ir >> 8)];\t\t\t\\\n\tyr = camellia_sp1110[(u8)(t0 >> 8)]\t\t\t\\\n\t   ^ camellia_sp0222[(u8)(t0)]\t\t\t\t\\\n\t   ^ camellia_sp3033[(u8)(il >> 8)]\t\t\t\\\n\t   ^ camellia_sp4404[(u8)(il)];\t\t\t\t\\\n\tyl ^= yr;\t\t\t\t\t\t\\\n\tyr = ror32(yr, 8);\t\t\t\t\t\\\n\tyr ^= yl;\t\t\t\t\t\t\\\n})\n\n#define SUBKEY_L(INDEX) (subkey[(INDEX)*2])\n#define SUBKEY_R(INDEX) (subkey[(INDEX)*2 + 1])\n\nstatic void camellia_setup_tail(u32 *subkey, u32 *subL, u32 *subR, int max)\n{\n\tu32 dw, tl, tr;\n\tu32 kw4l, kw4r;\n\n\t/* absorb kw2 to other subkeys */\n\t/* round 2 */\n\tsubL[3] ^= subL[1]; subR[3] ^= subR[1];\n\t/* round 4 */\n\tsubL[5] ^= subL[1]; subR[5] ^= subR[1];\n\t/* round 6 */\n\tsubL[7] ^= subL[1]; subR[7] ^= subR[1];\n\tsubL[1] ^= subR[1] & ~subR[9];\n\tdw = subL[1] & subL[9];\n\tsubR[1] ^= rol32(dw, 1); /* modified for FLinv(kl2) */\n\t/* round 8 */\n\tsubL[11] ^= subL[1]; subR[11] ^= subR[1];\n\t/* round 10 */\n\tsubL[13] ^= subL[1]; subR[13] ^= subR[1];\n\t/* round 12 */\n\tsubL[15] ^= subL[1]; subR[15] ^= subR[1];\n\tsubL[1] ^= subR[1] & ~subR[17];\n\tdw = subL[1] & subL[17];\n\tsubR[1] ^= rol32(dw, 1); /* modified for FLinv(kl4) */\n\t/* round 14 */\n\tsubL[19] ^= subL[1]; subR[19] ^= subR[1];\n\t/* round 16 */\n\tsubL[21] ^= subL[1]; subR[21] ^= subR[1];\n\t/* round 18 */\n\tsubL[23] ^= subL[1]; subR[23] ^= subR[1];\n\tif (max == 24) {\n\t\t/* kw3 */\n\t\tsubL[24] ^= subL[1]; subR[24] ^= subR[1];\n\n\t/* absorb kw4 to other subkeys */\n\t\tkw4l = subL[25]; kw4r = subR[25];\n\t} else {\n\t\tsubL[1] ^= subR[1] & ~subR[25];\n\t\tdw = subL[1] & subL[25];\n\t\tsubR[1] ^= rol32(dw, 1); /* modified for FLinv(kl6) */\n\t\t/* round 20 */\n\t\tsubL[27] ^= subL[1]; subR[27] ^= subR[1];\n\t\t/* round 22 */\n\t\tsubL[29] ^= subL[1]; subR[29] ^= subR[1];\n\t\t/* round 24 */\n\t\tsubL[31] ^= subL[1]; subR[31] ^= subR[1];\n\t\t/* kw3 */\n\t\tsubL[32] ^= subL[1]; subR[32] ^= subR[1];\n\n\t/* absorb kw4 to other subkeys */\n\t\tkw4l = subL[33]; kw4r = subR[33];\n\t\t/* round 23 */\n\t\tsubL[30] ^= kw4l; subR[30] ^= kw4r;\n\t\t/* round 21 */\n\t\tsubL[28] ^= kw4l; subR[28] ^= kw4r;\n\t\t/* round 19 */\n\t\tsubL[26] ^= kw4l; subR[26] ^= kw4r;\n\t\tkw4l ^= kw4r & ~subR[24];\n\t\tdw = kw4l & subL[24];\n\t\tkw4r ^= rol32(dw, 1); /* modified for FL(kl5) */\n\t}\n\t/* round 17 */\n\tsubL[22] ^= kw4l; subR[22] ^= kw4r;\n\t/* round 15 */\n\tsubL[20] ^= kw4l; subR[20] ^= kw4r;\n\t/* round 13 */\n\tsubL[18] ^= kw4l; subR[18] ^= kw4r;\n\tkw4l ^= kw4r & ~subR[16];\n\tdw = kw4l & subL[16];\n\tkw4r ^= rol32(dw, 1); /* modified for FL(kl3) */\n\t/* round 11 */\n\tsubL[14] ^= kw4l; subR[14] ^= kw4r;\n\t/* round 9 */\n\tsubL[12] ^= kw4l; subR[12] ^= kw4r;\n\t/* round 7 */\n\tsubL[10] ^= kw4l; subR[10] ^= kw4r;\n\tkw4l ^= kw4r & ~subR[8];\n\tdw = kw4l & subL[8];\n\tkw4r ^= rol32(dw, 1); /* modified for FL(kl1) */\n\t/* round 5 */\n\tsubL[6] ^= kw4l; subR[6] ^= kw4r;\n\t/* round 3 */\n\tsubL[4] ^= kw4l; subR[4] ^= kw4r;\n\t/* round 1 */\n\tsubL[2] ^= kw4l; subR[2] ^= kw4r;\n\t/* kw1 */\n\tsubL[0] ^= kw4l; subR[0] ^= kw4r;\n\n\t/* key XOR is end of F-function */\n\tSUBKEY_L(0) = subL[0] ^ subL[2];/* kw1 */\n\tSUBKEY_R(0) = subR[0] ^ subR[2];\n\tSUBKEY_L(2) = subL[3];       /* round 1 */\n\tSUBKEY_R(2) = subR[3];\n\tSUBKEY_L(3) = subL[2] ^ subL[4]; /* round 2 */\n\tSUBKEY_R(3) = subR[2] ^ subR[4];\n\tSUBKEY_L(4) = subL[3] ^ subL[5]; /* round 3 */\n\tSUBKEY_R(4) = subR[3] ^ subR[5];\n\tSUBKEY_L(5) = subL[4] ^ subL[6]; /* round 4 */\n\tSUBKEY_R(5) = subR[4] ^ subR[6];\n\tSUBKEY_L(6) = subL[5] ^ subL[7]; /* round 5 */\n\tSUBKEY_R(6) = subR[5] ^ subR[7];\n\ttl = subL[10] ^ (subR[10] & ~subR[8]);\n\tdw = tl & subL[8];  /* FL(kl1) */\n\ttr = subR[10] ^ rol32(dw, 1);\n\tSUBKEY_L(7) = subL[6] ^ tl; /* round 6 */\n\tSUBKEY_R(7) = subR[6] ^ tr;\n\tSUBKEY_L(8) = subL[8];       /* FL(kl1) */\n\tSUBKEY_R(8) = subR[8];\n\tSUBKEY_L(9) = subL[9];       /* FLinv(kl2) */\n\tSUBKEY_R(9) = subR[9];\n\ttl = subL[7] ^ (subR[7] & ~subR[9]);\n\tdw = tl & subL[9];  /* FLinv(kl2) */\n\ttr = subR[7] ^ rol32(dw, 1);\n\tSUBKEY_L(10) = tl ^ subL[11]; /* round 7 */\n\tSUBKEY_R(10) = tr ^ subR[11];\n\tSUBKEY_L(11) = subL[10] ^ subL[12]; /* round 8 */\n\tSUBKEY_R(11) = subR[10] ^ subR[12];\n\tSUBKEY_L(12) = subL[11] ^ subL[13]; /* round 9 */\n\tSUBKEY_R(12) = subR[11] ^ subR[13];\n\tSUBKEY_L(13) = subL[12] ^ subL[14]; /* round 10 */\n\tSUBKEY_R(13) = subR[12] ^ subR[14];\n\tSUBKEY_L(14) = subL[13] ^ subL[15]; /* round 11 */\n\tSUBKEY_R(14) = subR[13] ^ subR[15];\n\ttl = subL[18] ^ (subR[18] & ~subR[16]);\n\tdw = tl & subL[16]; /* FL(kl3) */\n\ttr = subR[18] ^ rol32(dw, 1);\n\tSUBKEY_L(15) = subL[14] ^ tl; /* round 12 */\n\tSUBKEY_R(15) = subR[14] ^ tr;\n\tSUBKEY_L(16) = subL[16];     /* FL(kl3) */\n\tSUBKEY_R(16) = subR[16];\n\tSUBKEY_L(17) = subL[17];     /* FLinv(kl4) */\n\tSUBKEY_R(17) = subR[17];\n\ttl = subL[15] ^ (subR[15] & ~subR[17]);\n\tdw = tl & subL[17]; /* FLinv(kl4) */\n\ttr = subR[15] ^ rol32(dw, 1);\n\tSUBKEY_L(18) = tl ^ subL[19]; /* round 13 */\n\tSUBKEY_R(18) = tr ^ subR[19];\n\tSUBKEY_L(19) = subL[18] ^ subL[20]; /* round 14 */\n\tSUBKEY_R(19) = subR[18] ^ subR[20];\n\tSUBKEY_L(20) = subL[19] ^ subL[21]; /* round 15 */\n\tSUBKEY_R(20) = subR[19] ^ subR[21];\n\tSUBKEY_L(21) = subL[20] ^ subL[22]; /* round 16 */\n\tSUBKEY_R(21) = subR[20] ^ subR[22];\n\tSUBKEY_L(22) = subL[21] ^ subL[23]; /* round 17 */\n\tSUBKEY_R(22) = subR[21] ^ subR[23];\n\tif (max == 24) {\n\t\tSUBKEY_L(23) = subL[22];     /* round 18 */\n\t\tSUBKEY_R(23) = subR[22];\n\t\tSUBKEY_L(24) = subL[24] ^ subL[23]; /* kw3 */\n\t\tSUBKEY_R(24) = subR[24] ^ subR[23];\n\t} else {\n\t\ttl = subL[26] ^ (subR[26] & ~subR[24]);\n\t\tdw = tl & subL[24]; /* FL(kl5) */\n\t\ttr = subR[26] ^ rol32(dw, 1);\n\t\tSUBKEY_L(23) = subL[22] ^ tl; /* round 18 */\n\t\tSUBKEY_R(23) = subR[22] ^ tr;\n\t\tSUBKEY_L(24) = subL[24];     /* FL(kl5) */\n\t\tSUBKEY_R(24) = subR[24];\n\t\tSUBKEY_L(25) = subL[25];     /* FLinv(kl6) */\n\t\tSUBKEY_R(25) = subR[25];\n\t\ttl = subL[23] ^ (subR[23] & ~subR[25]);\n\t\tdw = tl & subL[25]; /* FLinv(kl6) */\n\t\ttr = subR[23] ^ rol32(dw, 1);\n\t\tSUBKEY_L(26) = tl ^ subL[27]; /* round 19 */\n\t\tSUBKEY_R(26) = tr ^ subR[27];\n\t\tSUBKEY_L(27) = subL[26] ^ subL[28]; /* round 20 */\n\t\tSUBKEY_R(27) = subR[26] ^ subR[28];\n\t\tSUBKEY_L(28) = subL[27] ^ subL[29]; /* round 21 */\n\t\tSUBKEY_R(28) = subR[27] ^ subR[29];\n\t\tSUBKEY_L(29) = subL[28] ^ subL[30]; /* round 22 */\n\t\tSUBKEY_R(29) = subR[28] ^ subR[30];\n\t\tSUBKEY_L(30) = subL[29] ^ subL[31]; /* round 23 */\n\t\tSUBKEY_R(30) = subR[29] ^ subR[31];\n\t\tSUBKEY_L(31) = subL[30];     /* round 24 */\n\t\tSUBKEY_R(31) = subR[30];\n\t\tSUBKEY_L(32) = subL[32] ^ subL[31]; /* kw3 */\n\t\tSUBKEY_R(32) = subR[32] ^ subR[31];\n\t}\n}\n\nstatic void camellia_setup128(const unsigned char *key, u32 *subkey)\n{\n\tu32 kll, klr, krl, krr;\n\tu32 il, ir, t0, t1, w0, w1;\n\tu32 subL[26];\n\tu32 subR[26];\n\n\t/**\n\t *  k == kll || klr || krl || krr (|| is concatenation)\n\t */\n\tkll = get_unaligned_be32(key);\n\tklr = get_unaligned_be32(key + 4);\n\tkrl = get_unaligned_be32(key + 8);\n\tkrr = get_unaligned_be32(key + 12);\n\n\t/* generate KL dependent subkeys */\n\t/* kw1 */\n\tsubL[0] = kll; subR[0] = klr;\n\t/* kw2 */\n\tsubL[1] = krl; subR[1] = krr;\n\t/* rotation left shift 15bit */\n\tROLDQ(kll, klr, krl, krr, w0, w1, 15);\n\t/* k3 */\n\tsubL[4] = kll; subR[4] = klr;\n\t/* k4 */\n\tsubL[5] = krl; subR[5] = krr;\n\t/* rotation left shift 15+30bit */\n\tROLDQ(kll, klr, krl, krr, w0, w1, 30);\n\t/* k7 */\n\tsubL[10] = kll; subR[10] = klr;\n\t/* k8 */\n\tsubL[11] = krl; subR[11] = krr;\n\t/* rotation left shift 15+30+15bit */\n\tROLDQ(kll, klr, krl, krr, w0, w1, 15);\n\t/* k10 */\n\tsubL[13] = krl; subR[13] = krr;\n\t/* rotation left shift 15+30+15+17 bit */\n\tROLDQ(kll, klr, krl, krr, w0, w1, 17);\n\t/* kl3 */\n\tsubL[16] = kll; subR[16] = klr;\n\t/* kl4 */\n\tsubL[17] = krl; subR[17] = krr;\n\t/* rotation left shift 15+30+15+17+17 bit */\n\tROLDQ(kll, klr, krl, krr, w0, w1, 17);\n\t/* k13 */\n\tsubL[18] = kll; subR[18] = klr;\n\t/* k14 */\n\tsubL[19] = krl; subR[19] = krr;\n\t/* rotation left shift 15+30+15+17+17+17 bit */\n\tROLDQ(kll, klr, krl, krr, w0, w1, 17);\n\t/* k17 */\n\tsubL[22] = kll; subR[22] = klr;\n\t/* k18 */\n\tsubL[23] = krl; subR[23] = krr;\n\n\t/* generate KA */\n\tkll = subL[0]; klr = subR[0];\n\tkrl = subL[1]; krr = subR[1];\n\tCAMELLIA_F(kll, klr,\n\t\t   CAMELLIA_SIGMA1L, CAMELLIA_SIGMA1R,\n\t\t   w0, w1, il, ir, t0, t1);\n\tkrl ^= w0; krr ^= w1;\n\tCAMELLIA_F(krl, krr,\n\t\t   CAMELLIA_SIGMA2L, CAMELLIA_SIGMA2R,\n\t\t   kll, klr, il, ir, t0, t1);\n\t/* current status == (kll, klr, w0, w1) */\n\tCAMELLIA_F(kll, klr,\n\t\t   CAMELLIA_SIGMA3L, CAMELLIA_SIGMA3R,\n\t\t   krl, krr, il, ir, t0, t1);\n\tkrl ^= w0; krr ^= w1;\n\tCAMELLIA_F(krl, krr,\n\t\t   CAMELLIA_SIGMA4L, CAMELLIA_SIGMA4R,\n\t\t   w0, w1, il, ir, t0, t1);\n\tkll ^= w0; klr ^= w1;\n\n\t/* generate KA dependent subkeys */\n\t/* k1, k2 */\n\tsubL[2] = kll; subR[2] = klr;\n\tsubL[3] = krl; subR[3] = krr;\n\tROLDQ(kll, klr, krl, krr, w0, w1, 15);\n\t/* k5,k6 */\n\tsubL[6] = kll; subR[6] = klr;\n\tsubL[7] = krl; subR[7] = krr;\n\tROLDQ(kll, klr, krl, krr, w0, w1, 15);\n\t/* kl1, kl2 */\n\tsubL[8] = kll; subR[8] = klr;\n\tsubL[9] = krl; subR[9] = krr;\n\tROLDQ(kll, klr, krl, krr, w0, w1, 15);\n\t/* k9 */\n\tsubL[12] = kll; subR[12] = klr;\n\tROLDQ(kll, klr, krl, krr, w0, w1, 15);\n\t/* k11, k12 */\n\tsubL[14] = kll; subR[14] = klr;\n\tsubL[15] = krl; subR[15] = krr;\n\tROLDQo32(kll, klr, krl, krr, w0, w1, 34);\n\t/* k15, k16 */\n\tsubL[20] = kll; subR[20] = klr;\n\tsubL[21] = krl; subR[21] = krr;\n\tROLDQ(kll, klr, krl, krr, w0, w1, 17);\n\t/* kw3, kw4 */\n\tsubL[24] = kll; subR[24] = klr;\n\tsubL[25] = krl; subR[25] = krr;\n\n\tcamellia_setup_tail(subkey, subL, subR, 24);\n}\n\nstatic void camellia_setup256(const unsigned char *key, u32 *subkey)\n{\n\tu32 kll, klr, krl, krr;        /* left half of key */\n\tu32 krll, krlr, krrl, krrr;    /* right half of key */\n\tu32 il, ir, t0, t1, w0, w1;    /* temporary variables */\n\tu32 subL[34];\n\tu32 subR[34];\n\n\t/**\n\t *  key = (kll || klr || krl || krr || krll || krlr || krrl || krrr)\n\t *  (|| is concatenation)\n\t */\n\tkll = get_unaligned_be32(key);\n\tklr = get_unaligned_be32(key + 4);\n\tkrl = get_unaligned_be32(key + 8);\n\tkrr = get_unaligned_be32(key + 12);\n\tkrll = get_unaligned_be32(key + 16);\n\tkrlr = get_unaligned_be32(key + 20);\n\tkrrl = get_unaligned_be32(key + 24);\n\tkrrr = get_unaligned_be32(key + 28);\n\n\t/* generate KL dependent subkeys */\n\t/* kw1 */\n\tsubL[0] = kll; subR[0] = klr;\n\t/* kw2 */\n\tsubL[1] = krl; subR[1] = krr;\n\tROLDQo32(kll, klr, krl, krr, w0, w1, 45);\n\t/* k9 */\n\tsubL[12] = kll; subR[12] = klr;\n\t/* k10 */\n\tsubL[13] = krl; subR[13] = krr;\n\tROLDQ(kll, klr, krl, krr, w0, w1, 15);\n\t/* kl3 */\n\tsubL[16] = kll; subR[16] = klr;\n\t/* kl4 */\n\tsubL[17] = krl; subR[17] = krr;\n\tROLDQ(kll, klr, krl, krr, w0, w1, 17);\n\t/* k17 */\n\tsubL[22] = kll; subR[22] = klr;\n\t/* k18 */\n\tsubL[23] = krl; subR[23] = krr;\n\tROLDQo32(kll, klr, krl, krr, w0, w1, 34);\n\t/* k23 */\n\tsubL[30] = kll; subR[30] = klr;\n\t/* k24 */\n\tsubL[31] = krl; subR[31] = krr;\n\n\t/* generate KR dependent subkeys */\n\tROLDQ(krll, krlr, krrl, krrr, w0, w1, 15);\n\t/* k3 */\n\tsubL[4] = krll; subR[4] = krlr;\n\t/* k4 */\n\tsubL[5] = krrl; subR[5] = krrr;\n\tROLDQ(krll, krlr, krrl, krrr, w0, w1, 15);\n\t/* kl1 */\n\tsubL[8] = krll; subR[8] = krlr;\n\t/* kl2 */\n\tsubL[9] = krrl; subR[9] = krrr;\n\tROLDQ(krll, krlr, krrl, krrr, w0, w1, 30);\n\t/* k13 */\n\tsubL[18] = krll; subR[18] = krlr;\n\t/* k14 */\n\tsubL[19] = krrl; subR[19] = krrr;\n\tROLDQo32(krll, krlr, krrl, krrr, w0, w1, 34);\n\t/* k19 */\n\tsubL[26] = krll; subR[26] = krlr;\n\t/* k20 */\n\tsubL[27] = krrl; subR[27] = krrr;\n\tROLDQo32(krll, krlr, krrl, krrr, w0, w1, 34);\n\n\t/* generate KA */\n\tkll = subL[0] ^ krll; klr = subR[0] ^ krlr;\n\tkrl = subL[1] ^ krrl; krr = subR[1] ^ krrr;\n\tCAMELLIA_F(kll, klr,\n\t\t   CAMELLIA_SIGMA1L, CAMELLIA_SIGMA1R,\n\t\t   w0, w1, il, ir, t0, t1);\n\tkrl ^= w0; krr ^= w1;\n\tCAMELLIA_F(krl, krr,\n\t\t   CAMELLIA_SIGMA2L, CAMELLIA_SIGMA2R,\n\t\t   kll, klr, il, ir, t0, t1);\n\tkll ^= krll; klr ^= krlr;\n\tCAMELLIA_F(kll, klr,\n\t\t   CAMELLIA_SIGMA3L, CAMELLIA_SIGMA3R,\n\t\t   krl, krr, il, ir, t0, t1);\n\tkrl ^= w0 ^ krrl; krr ^= w1 ^ krrr;\n\tCAMELLIA_F(krl, krr,\n\t\t   CAMELLIA_SIGMA4L, CAMELLIA_SIGMA4R,\n\t\t   w0, w1, il, ir, t0, t1);\n\tkll ^= w0; klr ^= w1;\n\n\t/* generate KB */\n\tkrll ^= kll; krlr ^= klr;\n\tkrrl ^= krl; krrr ^= krr;\n\tCAMELLIA_F(krll, krlr,\n\t\t   CAMELLIA_SIGMA5L, CAMELLIA_SIGMA5R,\n\t\t   w0, w1, il, ir, t0, t1);\n\tkrrl ^= w0; krrr ^= w1;\n\tCAMELLIA_F(krrl, krrr,\n\t\t   CAMELLIA_SIGMA6L, CAMELLIA_SIGMA6R,\n\t\t   w0, w1, il, ir, t0, t1);\n\tkrll ^= w0; krlr ^= w1;\n\n\t/* generate KA dependent subkeys */\n\tROLDQ(kll, klr, krl, krr, w0, w1, 15);\n\t/* k5 */\n\tsubL[6] = kll; subR[6] = klr;\n\t/* k6 */\n\tsubL[7] = krl; subR[7] = krr;\n\tROLDQ(kll, klr, krl, krr, w0, w1, 30);\n\t/* k11 */\n\tsubL[14] = kll; subR[14] = klr;\n\t/* k12 */\n\tsubL[15] = krl; subR[15] = krr;\n\t/* rotation left shift 32bit */\n\t/* kl5 */\n\tsubL[24] = klr; subR[24] = krl;\n\t/* kl6 */\n\tsubL[25] = krr; subR[25] = kll;\n\t/* rotation left shift 49 from k11,k12 -> k21,k22 */\n\tROLDQo32(kll, klr, krl, krr, w0, w1, 49);\n\t/* k21 */\n\tsubL[28] = kll; subR[28] = klr;\n\t/* k22 */\n\tsubL[29] = krl; subR[29] = krr;\n\n\t/* generate KB dependent subkeys */\n\t/* k1 */\n\tsubL[2] = krll; subR[2] = krlr;\n\t/* k2 */\n\tsubL[3] = krrl; subR[3] = krrr;\n\tROLDQ(krll, krlr, krrl, krrr, w0, w1, 30);\n\t/* k7 */\n\tsubL[10] = krll; subR[10] = krlr;\n\t/* k8 */\n\tsubL[11] = krrl; subR[11] = krrr;\n\tROLDQ(krll, krlr, krrl, krrr, w0, w1, 30);\n\t/* k15 */\n\tsubL[20] = krll; subR[20] = krlr;\n\t/* k16 */\n\tsubL[21] = krrl; subR[21] = krrr;\n\tROLDQo32(krll, krlr, krrl, krrr, w0, w1, 51);\n\t/* kw3 */\n\tsubL[32] = krll; subR[32] = krlr;\n\t/* kw4 */\n\tsubL[33] = krrl; subR[33] = krrr;\n\n\tcamellia_setup_tail(subkey, subL, subR, 32);\n}\n\nstatic void camellia_setup192(const unsigned char *key, u32 *subkey)\n{\n\tunsigned char kk[32];\n\tu32 krll, krlr, krrl, krrr;\n\n\tmemcpy(kk, key, 24);\n\tmemcpy((unsigned char *)&krll, key+16, 4);\n\tmemcpy((unsigned char *)&krlr, key+20, 4);\n\tkrrl = ~krll;\n\tkrrr = ~krlr;\n\tmemcpy(kk+24, (unsigned char *)&krrl, 4);\n\tmemcpy(kk+28, (unsigned char *)&krrr, 4);\n\tcamellia_setup256(kk, subkey);\n}\n\n\n/*\n * Encrypt/decrypt\n */\n#define CAMELLIA_FLS(ll, lr, rl, rr, kll, klr, krl, krr, t0, t1, t2, t3) ({ \\\n\tt0 = kll;\t\t\t\t\t\t\t\\\n\tt2 = krr;\t\t\t\t\t\t\t\\\n\tt0 &= ll;\t\t\t\t\t\t\t\\\n\tt2 |= rr;\t\t\t\t\t\t\t\\\n\trl ^= t2;\t\t\t\t\t\t\t\\\n\tlr ^= rol32(t0, 1);\t\t\t\t\t\t\\\n\tt3 = krl;\t\t\t\t\t\t\t\\\n\tt1 = klr;\t\t\t\t\t\t\t\\\n\tt3 &= rl;\t\t\t\t\t\t\t\\\n\tt1 |= lr;\t\t\t\t\t\t\t\\\n\tll ^= t1;\t\t\t\t\t\t\t\\\n\trr ^= rol32(t3, 1);\t\t\t\t\t\t\\\n})\n\n#define CAMELLIA_ROUNDSM(xl, xr, kl, kr, yl, yr, il, ir) ({\t\t\\\n\tyl ^= kl;\t\t\t\t\t\t\t\\\n\tyr ^= kr;\t\t\t\t\t\t\t\\\n\tir =  camellia_sp1110[(u8)xr];\t\t\t\t\t\\\n\til =  camellia_sp1110[(u8)(xl >> 24)];\t\t\t\t\\\n\tir ^= camellia_sp0222[(u8)(xr >> 24)];\t\t\t\t\\\n\til ^= camellia_sp0222[(u8)(xl >> 16)];\t\t\t\t\\\n\tir ^= camellia_sp3033[(u8)(xr >> 16)];\t\t\t\t\\\n\til ^= camellia_sp3033[(u8)(xl >> 8)];\t\t\t\t\\\n\tir ^= camellia_sp4404[(u8)(xr >> 8)];\t\t\t\t\\\n\til ^= camellia_sp4404[(u8)xl];\t\t\t\t\t\\\n\tir ^= il;\t\t\t\t\t\t\t\\\n\tyl ^= ir;\t\t\t\t\t\t\t\\\n\tyr ^= ror32(il, 8) ^ ir;\t\t\t\t\t\\\n})\n\n/* max = 24: 128bit encrypt, max = 32: 256bit encrypt */\nstatic void camellia_do_encrypt(const u32 *subkey, u32 *io, unsigned max)\n{\n\tu32 il, ir, t0, t1;            /* temporary variables */\n\n\t/* pre whitening but absorb kw2 */\n\tio[0] ^= SUBKEY_L(0);\n\tio[1] ^= SUBKEY_R(0);\n\n\t/* main iteration */\n#define ROUNDS(i) ({ \\\n\tCAMELLIA_ROUNDSM(io[0], io[1], \\\n\t\t\t SUBKEY_L(i + 2), SUBKEY_R(i + 2), \\\n\t\t\t io[2], io[3], il, ir); \\\n\tCAMELLIA_ROUNDSM(io[2], io[3], \\\n\t\t\t SUBKEY_L(i + 3), SUBKEY_R(i + 3), \\\n\t\t\t io[0], io[1], il, ir); \\\n\tCAMELLIA_ROUNDSM(io[0], io[1], \\\n\t\t\t SUBKEY_L(i + 4), SUBKEY_R(i + 4), \\\n\t\t\t io[2], io[3], il, ir); \\\n\tCAMELLIA_ROUNDSM(io[2], io[3], \\\n\t\t\t SUBKEY_L(i + 5), SUBKEY_R(i + 5), \\\n\t\t\t io[0], io[1], il, ir); \\\n\tCAMELLIA_ROUNDSM(io[0], io[1], \\\n\t\t\t SUBKEY_L(i + 6), SUBKEY_R(i + 6), \\\n\t\t\t io[2], io[3], il, ir); \\\n\tCAMELLIA_ROUNDSM(io[2], io[3], \\\n\t\t\t SUBKEY_L(i + 7), SUBKEY_R(i + 7), \\\n\t\t\t io[0], io[1], il, ir); \\\n})\n#define FLS(i) ({ \\\n\tCAMELLIA_FLS(io[0], io[1], io[2], io[3], \\\n\t\t     SUBKEY_L(i + 0), SUBKEY_R(i + 0), \\\n\t\t     SUBKEY_L(i + 1), SUBKEY_R(i + 1), \\\n\t\t     t0, t1, il, ir); \\\n})\n\n\tROUNDS(0);\n\tFLS(8);\n\tROUNDS(8);\n\tFLS(16);\n\tROUNDS(16);\n\tif (max == 32) {\n\t\tFLS(24);\n\t\tROUNDS(24);\n\t}\n\n#undef ROUNDS\n#undef FLS\n\n\t/* post whitening but kw4 */\n\tio[2] ^= SUBKEY_L(max);\n\tio[3] ^= SUBKEY_R(max);\n\t/* NB: io[0],[1] should be swapped with [2],[3] by caller! */\n}\n\nstatic void camellia_do_decrypt(const u32 *subkey, u32 *io, unsigned i)\n{\n\tu32 il, ir, t0, t1;            /* temporary variables */\n\n\t/* pre whitening but absorb kw2 */\n\tio[0] ^= SUBKEY_L(i);\n\tio[1] ^= SUBKEY_R(i);\n\n\t/* main iteration */\n#define ROUNDS(i) ({ \\\n\tCAMELLIA_ROUNDSM(io[0], io[1], \\\n\t\t\t SUBKEY_L(i + 7), SUBKEY_R(i + 7), \\\n\t\t\t io[2], io[3], il, ir); \\\n\tCAMELLIA_ROUNDSM(io[2], io[3], \\\n\t\t\t SUBKEY_L(i + 6), SUBKEY_R(i + 6), \\\n\t\t\t io[0], io[1], il, ir); \\\n\tCAMELLIA_ROUNDSM(io[0], io[1], \\\n\t\t\t SUBKEY_L(i + 5), SUBKEY_R(i + 5), \\\n\t\t\t io[2], io[3], il, ir); \\\n\tCAMELLIA_ROUNDSM(io[2], io[3], \\\n\t\t\t SUBKEY_L(i + 4), SUBKEY_R(i + 4), \\\n\t\t\t io[0], io[1], il, ir); \\\n\tCAMELLIA_ROUNDSM(io[0], io[1], \\\n\t\t\t SUBKEY_L(i + 3), SUBKEY_R(i + 3), \\\n\t\t\t io[2], io[3], il, ir); \\\n\tCAMELLIA_ROUNDSM(io[2], io[3], \\\n\t\t\t SUBKEY_L(i + 2), SUBKEY_R(i + 2), \\\n\t\t\t io[0], io[1], il, ir); \\\n})\n#define FLS(i) ({ \\\n\tCAMELLIA_FLS(io[0], io[1], io[2], io[3], \\\n\t\t     SUBKEY_L(i + 1), SUBKEY_R(i + 1), \\\n\t\t     SUBKEY_L(i + 0), SUBKEY_R(i + 0), \\\n\t\t     t0, t1, il, ir); \\\n})\n\n\tif (i == 32) {\n\t\tROUNDS(24);\n\t\tFLS(24);\n\t}\n\tROUNDS(16);\n\tFLS(16);\n\tROUNDS(8);\n\tFLS(8);\n\tROUNDS(0);\n\n#undef ROUNDS\n#undef FLS\n\n\t/* post whitening but kw4 */\n\tio[2] ^= SUBKEY_L(0);\n\tio[3] ^= SUBKEY_R(0);\n\t/* NB: 0,1 should be swapped with 2,3 by caller! */\n}\n\n\nstruct camellia_ctx {\n\tint key_length;\n\tu32 key_table[CAMELLIA_TABLE_BYTE_LEN / sizeof(u32)];\n};\n\nstatic int\ncamellia_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t unsigned int key_len)\n{\n\tstruct camellia_ctx *cctx = crypto_tfm_ctx(tfm);\n\tconst unsigned char *key = (const unsigned char *)in_key;\n\tu32 *flags = &tfm->crt_flags;\n\n\tif (key_len != 16 && key_len != 24 && key_len != 32) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\tcctx->key_length = key_len;\n\n\tswitch (key_len) {\n\tcase 16:\n\t\tcamellia_setup128(key, cctx->key_table);\n\t\tbreak;\n\tcase 24:\n\t\tcamellia_setup192(key, cctx->key_table);\n\t\tbreak;\n\tcase 32:\n\t\tcamellia_setup256(key, cctx->key_table);\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nstatic void camellia_encrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tconst struct camellia_ctx *cctx = crypto_tfm_ctx(tfm);\n\tconst __be32 *src = (const __be32 *)in;\n\t__be32 *dst = (__be32 *)out;\n\tunsigned int max;\n\n\tu32 tmp[4];\n\n\ttmp[0] = be32_to_cpu(src[0]);\n\ttmp[1] = be32_to_cpu(src[1]);\n\ttmp[2] = be32_to_cpu(src[2]);\n\ttmp[3] = be32_to_cpu(src[3]);\n\n\tif (cctx->key_length == 16)\n\t\tmax = 24;\n\telse\n\t\tmax = 32; /* for key lengths of 24 and 32 */\n\n\tcamellia_do_encrypt(cctx->key_table, tmp, max);\n\n\t/* do_encrypt returns 0,1 swapped with 2,3 */\n\tdst[0] = cpu_to_be32(tmp[2]);\n\tdst[1] = cpu_to_be32(tmp[3]);\n\tdst[2] = cpu_to_be32(tmp[0]);\n\tdst[3] = cpu_to_be32(tmp[1]);\n}\n\nstatic void camellia_decrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tconst struct camellia_ctx *cctx = crypto_tfm_ctx(tfm);\n\tconst __be32 *src = (const __be32 *)in;\n\t__be32 *dst = (__be32 *)out;\n\tunsigned int max;\n\n\tu32 tmp[4];\n\n\ttmp[0] = be32_to_cpu(src[0]);\n\ttmp[1] = be32_to_cpu(src[1]);\n\ttmp[2] = be32_to_cpu(src[2]);\n\ttmp[3] = be32_to_cpu(src[3]);\n\n\tif (cctx->key_length == 16)\n\t\tmax = 24;\n\telse\n\t\tmax = 32; /* for key lengths of 24 and 32 */\n\n\tcamellia_do_decrypt(cctx->key_table, tmp, max);\n\n\t/* do_decrypt returns 0,1 swapped with 2,3 */\n\tdst[0] = cpu_to_be32(tmp[2]);\n\tdst[1] = cpu_to_be32(tmp[3]);\n\tdst[2] = cpu_to_be32(tmp[0]);\n\tdst[3] = cpu_to_be32(tmp[1]);\n}\n\nstatic struct crypto_alg camellia_alg = {\n\t.cra_name\t\t=\t\"camellia\",\n\t.cra_driver_name\t=\t\"camellia-generic\",\n\t.cra_priority\t\t=\t100,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tCAMELLIA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct camellia_ctx),\n\t.cra_alignmask\t\t=\t3,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.cipher = {\n\t\t\t.cia_min_keysize\t=\tCAMELLIA_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t=\tCAMELLIA_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t=\tcamellia_set_key,\n\t\t\t.cia_encrypt\t\t=\tcamellia_encrypt,\n\t\t\t.cia_decrypt\t\t=\tcamellia_decrypt\n\t\t}\n\t}\n};\n\nstatic int __init camellia_init(void)\n{\n\treturn crypto_register_alg(&camellia_alg);\n}\n\nstatic void __exit camellia_fini(void)\n{\n\tcrypto_unregister_alg(&camellia_alg);\n}\n\nmodule_init(camellia_init);\nmodule_exit(camellia_fini);\n\nMODULE_DESCRIPTION(\"Camellia Cipher Algorithm\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_CRYPTO(\"camellia\");\n", "/* Kernel cryptographic api.\n* cast5.c - Cast5 cipher algorithm (rfc2144).\n*\n* Derived from GnuPG implementation of cast5.\n*\n* Major Changes.\n*\tComplete conformance to rfc2144.\n*\tSupports key size from 40 to 128 bits.\n*\n* Copyright (C) 1998, 1999, 2000, 2001 Free Software Foundation, Inc.\n* Copyright (C) 2003 Kartikey Mahendra Bhatt <kartik_me@hotmail.com>.\n*\n* This program is free software; you can redistribute it and/or modify it\n* under the terms of GNU General Public License as published by the Free\n* Software Foundation; either version 2 of the License, or (at your option)\n* any later version.\n*\n* You should have received a copy of the GNU General Public License\n* along with this program; if not, write to the Free Software\n* Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA\n*/\n\n\n#include <asm/byteorder.h>\n#include <linux/init.h>\n#include <linux/crypto.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <crypto/cast5.h>\n\nstatic const u32 s5[256] = {\n\t0x7ec90c04, 0x2c6e74b9, 0x9b0e66df, 0xa6337911, 0xb86a7fff,\n\t0x1dd358f5, 0x44dd9d44, 0x1731167f,\n\t0x08fbf1fa, 0xe7f511cc, 0xd2051b00, 0x735aba00, 0x2ab722d8,\n\t0x386381cb, 0xacf6243a, 0x69befd7a,\n\t0xe6a2e77f, 0xf0c720cd, 0xc4494816, 0xccf5c180, 0x38851640,\n\t0x15b0a848, 0xe68b18cb, 0x4caadeff,\n\t0x5f480a01, 0x0412b2aa, 0x259814fc, 0x41d0efe2, 0x4e40b48d,\n\t0x248eb6fb, 0x8dba1cfe, 0x41a99b02,\n\t0x1a550a04, 0xba8f65cb, 0x7251f4e7, 0x95a51725, 0xc106ecd7,\n\t0x97a5980a, 0xc539b9aa, 0x4d79fe6a,\n\t0xf2f3f763, 0x68af8040, 0xed0c9e56, 0x11b4958b, 0xe1eb5a88,\n\t0x8709e6b0, 0xd7e07156, 0x4e29fea7,\n\t0x6366e52d, 0x02d1c000, 0xc4ac8e05, 0x9377f571, 0x0c05372a,\n\t0x578535f2, 0x2261be02, 0xd642a0c9,\n\t0xdf13a280, 0x74b55bd2, 0x682199c0, 0xd421e5ec, 0x53fb3ce8,\n\t0xc8adedb3, 0x28a87fc9, 0x3d959981,\n\t0x5c1ff900, 0xfe38d399, 0x0c4eff0b, 0x062407ea, 0xaa2f4fb1,\n\t0x4fb96976, 0x90c79505, 0xb0a8a774,\n\t0xef55a1ff, 0xe59ca2c2, 0xa6b62d27, 0xe66a4263, 0xdf65001f,\n\t0x0ec50966, 0xdfdd55bc, 0x29de0655,\n\t0x911e739a, 0x17af8975, 0x32c7911c, 0x89f89468, 0x0d01e980,\n\t0x524755f4, 0x03b63cc9, 0x0cc844b2,\n\t0xbcf3f0aa, 0x87ac36e9, 0xe53a7426, 0x01b3d82b, 0x1a9e7449,\n\t0x64ee2d7e, 0xcddbb1da, 0x01c94910,\n\t0xb868bf80, 0x0d26f3fd, 0x9342ede7, 0x04a5c284, 0x636737b6,\n\t0x50f5b616, 0xf24766e3, 0x8eca36c1,\n\t0x136e05db, 0xfef18391, 0xfb887a37, 0xd6e7f7d4, 0xc7fb7dc9,\n\t0x3063fcdf, 0xb6f589de, 0xec2941da,\n\t0x26e46695, 0xb7566419, 0xf654efc5, 0xd08d58b7, 0x48925401,\n\t0xc1bacb7f, 0xe5ff550f, 0xb6083049,\n\t0x5bb5d0e8, 0x87d72e5a, 0xab6a6ee1, 0x223a66ce, 0xc62bf3cd,\n\t0x9e0885f9, 0x68cb3e47, 0x086c010f,\n\t0xa21de820, 0xd18b69de, 0xf3f65777, 0xfa02c3f6, 0x407edac3,\n\t0xcbb3d550, 0x1793084d, 0xb0d70eba,\n\t0x0ab378d5, 0xd951fb0c, 0xded7da56, 0x4124bbe4, 0x94ca0b56,\n\t0x0f5755d1, 0xe0e1e56e, 0x6184b5be,\n\t0x580a249f, 0x94f74bc0, 0xe327888e, 0x9f7b5561, 0xc3dc0280,\n\t0x05687715, 0x646c6bd7, 0x44904db3,\n\t0x66b4f0a3, 0xc0f1648a, 0x697ed5af, 0x49e92ff6, 0x309e374f,\n\t0x2cb6356a, 0x85808573, 0x4991f840,\n\t0x76f0ae02, 0x083be84d, 0x28421c9a, 0x44489406, 0x736e4cb8,\n\t0xc1092910, 0x8bc95fc6, 0x7d869cf4,\n\t0x134f616f, 0x2e77118d, 0xb31b2be1, 0xaa90b472, 0x3ca5d717,\n\t0x7d161bba, 0x9cad9010, 0xaf462ba2,\n\t0x9fe459d2, 0x45d34559, 0xd9f2da13, 0xdbc65487, 0xf3e4f94e,\n\t0x176d486f, 0x097c13ea, 0x631da5c7,\n\t0x445f7382, 0x175683f4, 0xcdc66a97, 0x70be0288, 0xb3cdcf72,\n\t0x6e5dd2f3, 0x20936079, 0x459b80a5,\n\t0xbe60e2db, 0xa9c23101, 0xeba5315c, 0x224e42f2, 0x1c5c1572,\n\t0xf6721b2c, 0x1ad2fff3, 0x8c25404e,\n\t0x324ed72f, 0x4067b7fd, 0x0523138e, 0x5ca3bc78, 0xdc0fd66e,\n\t0x75922283, 0x784d6b17, 0x58ebb16e,\n\t0x44094f85, 0x3f481d87, 0xfcfeae7b, 0x77b5ff76, 0x8c2302bf,\n\t0xaaf47556, 0x5f46b02a, 0x2b092801,\n\t0x3d38f5f7, 0x0ca81f36, 0x52af4a8a, 0x66d5e7c0, 0xdf3b0874,\n\t0x95055110, 0x1b5ad7a8, 0xf61ed5ad,\n\t0x6cf6e479, 0x20758184, 0xd0cefa65, 0x88f7be58, 0x4a046826,\n\t0x0ff6f8f3, 0xa09c7f70, 0x5346aba0,\n\t0x5ce96c28, 0xe176eda3, 0x6bac307f, 0x376829d2, 0x85360fa9,\n\t0x17e3fe2a, 0x24b79767, 0xf5a96b20,\n\t0xd6cd2595, 0x68ff1ebf, 0x7555442c, 0xf19f06be, 0xf9e0659a,\n\t0xeeb9491d, 0x34010718, 0xbb30cab8,\n\t0xe822fe15, 0x88570983, 0x750e6249, 0xda627e55, 0x5e76ffa8,\n\t0xb1534546, 0x6d47de08, 0xefe9e7d4\n};\nstatic const u32 s6[256] = {\n\t0xf6fa8f9d, 0x2cac6ce1, 0x4ca34867, 0xe2337f7c, 0x95db08e7,\n\t0x016843b4, 0xeced5cbc, 0x325553ac,\n\t0xbf9f0960, 0xdfa1e2ed, 0x83f0579d, 0x63ed86b9, 0x1ab6a6b8,\n\t0xde5ebe39, 0xf38ff732, 0x8989b138,\n\t0x33f14961, 0xc01937bd, 0xf506c6da, 0xe4625e7e, 0xa308ea99,\n\t0x4e23e33c, 0x79cbd7cc, 0x48a14367,\n\t0xa3149619, 0xfec94bd5, 0xa114174a, 0xeaa01866, 0xa084db2d,\n\t0x09a8486f, 0xa888614a, 0x2900af98,\n\t0x01665991, 0xe1992863, 0xc8f30c60, 0x2e78ef3c, 0xd0d51932,\n\t0xcf0fec14, 0xf7ca07d2, 0xd0a82072,\n\t0xfd41197e, 0x9305a6b0, 0xe86be3da, 0x74bed3cd, 0x372da53c,\n\t0x4c7f4448, 0xdab5d440, 0x6dba0ec3,\n\t0x083919a7, 0x9fbaeed9, 0x49dbcfb0, 0x4e670c53, 0x5c3d9c01,\n\t0x64bdb941, 0x2c0e636a, 0xba7dd9cd,\n\t0xea6f7388, 0xe70bc762, 0x35f29adb, 0x5c4cdd8d, 0xf0d48d8c,\n\t0xb88153e2, 0x08a19866, 0x1ae2eac8,\n\t0x284caf89, 0xaa928223, 0x9334be53, 0x3b3a21bf, 0x16434be3,\n\t0x9aea3906, 0xefe8c36e, 0xf890cdd9,\n\t0x80226dae, 0xc340a4a3, 0xdf7e9c09, 0xa694a807, 0x5b7c5ecc,\n\t0x221db3a6, 0x9a69a02f, 0x68818a54,\n\t0xceb2296f, 0x53c0843a, 0xfe893655, 0x25bfe68a, 0xb4628abc,\n\t0xcf222ebf, 0x25ac6f48, 0xa9a99387,\n\t0x53bddb65, 0xe76ffbe7, 0xe967fd78, 0x0ba93563, 0x8e342bc1,\n\t0xe8a11be9, 0x4980740d, 0xc8087dfc,\n\t0x8de4bf99, 0xa11101a0, 0x7fd37975, 0xda5a26c0, 0xe81f994f,\n\t0x9528cd89, 0xfd339fed, 0xb87834bf,\n\t0x5f04456d, 0x22258698, 0xc9c4c83b, 0x2dc156be, 0x4f628daa,\n\t0x57f55ec5, 0xe2220abe, 0xd2916ebf,\n\t0x4ec75b95, 0x24f2c3c0, 0x42d15d99, 0xcd0d7fa0, 0x7b6e27ff,\n\t0xa8dc8af0, 0x7345c106, 0xf41e232f,\n\t0x35162386, 0xe6ea8926, 0x3333b094, 0x157ec6f2, 0x372b74af,\n\t0x692573e4, 0xe9a9d848, 0xf3160289,\n\t0x3a62ef1d, 0xa787e238, 0xf3a5f676, 0x74364853, 0x20951063,\n\t0x4576698d, 0xb6fad407, 0x592af950,\n\t0x36f73523, 0x4cfb6e87, 0x7da4cec0, 0x6c152daa, 0xcb0396a8,\n\t0xc50dfe5d, 0xfcd707ab, 0x0921c42f,\n\t0x89dff0bb, 0x5fe2be78, 0x448f4f33, 0x754613c9, 0x2b05d08d,\n\t0x48b9d585, 0xdc049441, 0xc8098f9b,\n\t0x7dede786, 0xc39a3373, 0x42410005, 0x6a091751, 0x0ef3c8a6,\n\t0x890072d6, 0x28207682, 0xa9a9f7be,\n\t0xbf32679d, 0xd45b5b75, 0xb353fd00, 0xcbb0e358, 0x830f220a,\n\t0x1f8fb214, 0xd372cf08, 0xcc3c4a13,\n\t0x8cf63166, 0x061c87be, 0x88c98f88, 0x6062e397, 0x47cf8e7a,\n\t0xb6c85283, 0x3cc2acfb, 0x3fc06976,\n\t0x4e8f0252, 0x64d8314d, 0xda3870e3, 0x1e665459, 0xc10908f0,\n\t0x513021a5, 0x6c5b68b7, 0x822f8aa0,\n\t0x3007cd3e, 0x74719eef, 0xdc872681, 0x073340d4, 0x7e432fd9,\n\t0x0c5ec241, 0x8809286c, 0xf592d891,\n\t0x08a930f6, 0x957ef305, 0xb7fbffbd, 0xc266e96f, 0x6fe4ac98,\n\t0xb173ecc0, 0xbc60b42a, 0x953498da,\n\t0xfba1ae12, 0x2d4bd736, 0x0f25faab, 0xa4f3fceb, 0xe2969123,\n\t0x257f0c3d, 0x9348af49, 0x361400bc,\n\t0xe8816f4a, 0x3814f200, 0xa3f94043, 0x9c7a54c2, 0xbc704f57,\n\t0xda41e7f9, 0xc25ad33a, 0x54f4a084,\n\t0xb17f5505, 0x59357cbe, 0xedbd15c8, 0x7f97c5ab, 0xba5ac7b5,\n\t0xb6f6deaf, 0x3a479c3a, 0x5302da25,\n\t0x653d7e6a, 0x54268d49, 0x51a477ea, 0x5017d55b, 0xd7d25d88,\n\t0x44136c76, 0x0404a8c8, 0xb8e5a121,\n\t0xb81a928a, 0x60ed5869, 0x97c55b96, 0xeaec991b, 0x29935913,\n\t0x01fdb7f1, 0x088e8dfa, 0x9ab6f6f5,\n\t0x3b4cbf9f, 0x4a5de3ab, 0xe6051d35, 0xa0e1d855, 0xd36b4cf1,\n\t0xf544edeb, 0xb0e93524, 0xbebb8fbd,\n\t0xa2d762cf, 0x49c92f54, 0x38b5f331, 0x7128a454, 0x48392905,\n\t0xa65b1db8, 0x851c97bd, 0xd675cf2f\n};\nstatic const u32 s7[256] = {\n\t0x85e04019, 0x332bf567, 0x662dbfff, 0xcfc65693, 0x2a8d7f6f,\n\t0xab9bc912, 0xde6008a1, 0x2028da1f,\n\t0x0227bce7, 0x4d642916, 0x18fac300, 0x50f18b82, 0x2cb2cb11,\n\t0xb232e75c, 0x4b3695f2, 0xb28707de,\n\t0xa05fbcf6, 0xcd4181e9, 0xe150210c, 0xe24ef1bd, 0xb168c381,\n\t0xfde4e789, 0x5c79b0d8, 0x1e8bfd43,\n\t0x4d495001, 0x38be4341, 0x913cee1d, 0x92a79c3f, 0x089766be,\n\t0xbaeeadf4, 0x1286becf, 0xb6eacb19,\n\t0x2660c200, 0x7565bde4, 0x64241f7a, 0x8248dca9, 0xc3b3ad66,\n\t0x28136086, 0x0bd8dfa8, 0x356d1cf2,\n\t0x107789be, 0xb3b2e9ce, 0x0502aa8f, 0x0bc0351e, 0x166bf52a,\n\t0xeb12ff82, 0xe3486911, 0xd34d7516,\n\t0x4e7b3aff, 0x5f43671b, 0x9cf6e037, 0x4981ac83, 0x334266ce,\n\t0x8c9341b7, 0xd0d854c0, 0xcb3a6c88,\n\t0x47bc2829, 0x4725ba37, 0xa66ad22b, 0x7ad61f1e, 0x0c5cbafa,\n\t0x4437f107, 0xb6e79962, 0x42d2d816,\n\t0x0a961288, 0xe1a5c06e, 0x13749e67, 0x72fc081a, 0xb1d139f7,\n\t0xf9583745, 0xcf19df58, 0xbec3f756,\n\t0xc06eba30, 0x07211b24, 0x45c28829, 0xc95e317f, 0xbc8ec511,\n\t0x38bc46e9, 0xc6e6fa14, 0xbae8584a,\n\t0xad4ebc46, 0x468f508b, 0x7829435f, 0xf124183b, 0x821dba9f,\n\t0xaff60ff4, 0xea2c4e6d, 0x16e39264,\n\t0x92544a8b, 0x009b4fc3, 0xaba68ced, 0x9ac96f78, 0x06a5b79a,\n\t0xb2856e6e, 0x1aec3ca9, 0xbe838688,\n\t0x0e0804e9, 0x55f1be56, 0xe7e5363b, 0xb3a1f25d, 0xf7debb85,\n\t0x61fe033c, 0x16746233, 0x3c034c28,\n\t0xda6d0c74, 0x79aac56c, 0x3ce4e1ad, 0x51f0c802, 0x98f8f35a,\n\t0x1626a49f, 0xeed82b29, 0x1d382fe3,\n\t0x0c4fb99a, 0xbb325778, 0x3ec6d97b, 0x6e77a6a9, 0xcb658b5c,\n\t0xd45230c7, 0x2bd1408b, 0x60c03eb7,\n\t0xb9068d78, 0xa33754f4, 0xf430c87d, 0xc8a71302, 0xb96d8c32,\n\t0xebd4e7be, 0xbe8b9d2d, 0x7979fb06,\n\t0xe7225308, 0x8b75cf77, 0x11ef8da4, 0xe083c858, 0x8d6b786f,\n\t0x5a6317a6, 0xfa5cf7a0, 0x5dda0033,\n\t0xf28ebfb0, 0xf5b9c310, 0xa0eac280, 0x08b9767a, 0xa3d9d2b0,\n\t0x79d34217, 0x021a718d, 0x9ac6336a,\n\t0x2711fd60, 0x438050e3, 0x069908a8, 0x3d7fedc4, 0x826d2bef,\n\t0x4eeb8476, 0x488dcf25, 0x36c9d566,\n\t0x28e74e41, 0xc2610aca, 0x3d49a9cf, 0xbae3b9df, 0xb65f8de6,\n\t0x92aeaf64, 0x3ac7d5e6, 0x9ea80509,\n\t0xf22b017d, 0xa4173f70, 0xdd1e16c3, 0x15e0d7f9, 0x50b1b887,\n\t0x2b9f4fd5, 0x625aba82, 0x6a017962,\n\t0x2ec01b9c, 0x15488aa9, 0xd716e740, 0x40055a2c, 0x93d29a22,\n\t0xe32dbf9a, 0x058745b9, 0x3453dc1e,\n\t0xd699296e, 0x496cff6f, 0x1c9f4986, 0xdfe2ed07, 0xb87242d1,\n\t0x19de7eae, 0x053e561a, 0x15ad6f8c,\n\t0x66626c1c, 0x7154c24c, 0xea082b2a, 0x93eb2939, 0x17dcb0f0,\n\t0x58d4f2ae, 0x9ea294fb, 0x52cf564c,\n\t0x9883fe66, 0x2ec40581, 0x763953c3, 0x01d6692e, 0xd3a0c108,\n\t0xa1e7160e, 0xe4f2dfa6, 0x693ed285,\n\t0x74904698, 0x4c2b0edd, 0x4f757656, 0x5d393378, 0xa132234f,\n\t0x3d321c5d, 0xc3f5e194, 0x4b269301,\n\t0xc79f022f, 0x3c997e7e, 0x5e4f9504, 0x3ffafbbd, 0x76f7ad0e,\n\t0x296693f4, 0x3d1fce6f, 0xc61e45be,\n\t0xd3b5ab34, 0xf72bf9b7, 0x1b0434c0, 0x4e72b567, 0x5592a33d,\n\t0xb5229301, 0xcfd2a87f, 0x60aeb767,\n\t0x1814386b, 0x30bcc33d, 0x38a0c07d, 0xfd1606f2, 0xc363519b,\n\t0x589dd390, 0x5479f8e6, 0x1cb8d647,\n\t0x97fd61a9, 0xea7759f4, 0x2d57539d, 0x569a58cf, 0xe84e63ad,\n\t0x462e1b78, 0x6580f87e, 0xf3817914,\n\t0x91da55f4, 0x40a230f3, 0xd1988f35, 0xb6e318d2, 0x3ffa50bc,\n\t0x3d40f021, 0xc3c0bdae, 0x4958c24c,\n\t0x518f36b2, 0x84b1d370, 0x0fedce83, 0x878ddada, 0xf2a279c7,\n\t0x94e01be8, 0x90716f4b, 0x954b8aa3\n};\nstatic const u32 sb8[256] = {\n\t0xe216300d, 0xbbddfffc, 0xa7ebdabd, 0x35648095, 0x7789f8b7,\n\t0xe6c1121b, 0x0e241600, 0x052ce8b5,\n\t0x11a9cfb0, 0xe5952f11, 0xece7990a, 0x9386d174, 0x2a42931c,\n\t0x76e38111, 0xb12def3a, 0x37ddddfc,\n\t0xde9adeb1, 0x0a0cc32c, 0xbe197029, 0x84a00940, 0xbb243a0f,\n\t0xb4d137cf, 0xb44e79f0, 0x049eedfd,\n\t0x0b15a15d, 0x480d3168, 0x8bbbde5a, 0x669ded42, 0xc7ece831,\n\t0x3f8f95e7, 0x72df191b, 0x7580330d,\n\t0x94074251, 0x5c7dcdfa, 0xabbe6d63, 0xaa402164, 0xb301d40a,\n\t0x02e7d1ca, 0x53571dae, 0x7a3182a2,\n\t0x12a8ddec, 0xfdaa335d, 0x176f43e8, 0x71fb46d4, 0x38129022,\n\t0xce949ad4, 0xb84769ad, 0x965bd862,\n\t0x82f3d055, 0x66fb9767, 0x15b80b4e, 0x1d5b47a0, 0x4cfde06f,\n\t0xc28ec4b8, 0x57e8726e, 0x647a78fc,\n\t0x99865d44, 0x608bd593, 0x6c200e03, 0x39dc5ff6, 0x5d0b00a3,\n\t0xae63aff2, 0x7e8bd632, 0x70108c0c,\n\t0xbbd35049, 0x2998df04, 0x980cf42a, 0x9b6df491, 0x9e7edd53,\n\t0x06918548, 0x58cb7e07, 0x3b74ef2e,\n\t0x522fffb1, 0xd24708cc, 0x1c7e27cd, 0xa4eb215b, 0x3cf1d2e2,\n\t0x19b47a38, 0x424f7618, 0x35856039,\n\t0x9d17dee7, 0x27eb35e6, 0xc9aff67b, 0x36baf5b8, 0x09c467cd,\n\t0xc18910b1, 0xe11dbf7b, 0x06cd1af8,\n\t0x7170c608, 0x2d5e3354, 0xd4de495a, 0x64c6d006, 0xbcc0c62c,\n\t0x3dd00db3, 0x708f8f34, 0x77d51b42,\n\t0x264f620f, 0x24b8d2bf, 0x15c1b79e, 0x46a52564, 0xf8d7e54e,\n\t0x3e378160, 0x7895cda5, 0x859c15a5,\n\t0xe6459788, 0xc37bc75f, 0xdb07ba0c, 0x0676a3ab, 0x7f229b1e,\n\t0x31842e7b, 0x24259fd7, 0xf8bef472,\n\t0x835ffcb8, 0x6df4c1f2, 0x96f5b195, 0xfd0af0fc, 0xb0fe134c,\n\t0xe2506d3d, 0x4f9b12ea, 0xf215f225,\n\t0xa223736f, 0x9fb4c428, 0x25d04979, 0x34c713f8, 0xc4618187,\n\t0xea7a6e98, 0x7cd16efc, 0x1436876c,\n\t0xf1544107, 0xbedeee14, 0x56e9af27, 0xa04aa441, 0x3cf7c899,\n\t0x92ecbae6, 0xdd67016d, 0x151682eb,\n\t0xa842eedf, 0xfdba60b4, 0xf1907b75, 0x20e3030f, 0x24d8c29e,\n\t0xe139673b, 0xefa63fb8, 0x71873054,\n\t0xb6f2cf3b, 0x9f326442, 0xcb15a4cc, 0xb01a4504, 0xf1e47d8d,\n\t0x844a1be5, 0xbae7dfdc, 0x42cbda70,\n\t0xcd7dae0a, 0x57e85b7a, 0xd53f5af6, 0x20cf4d8c, 0xcea4d428,\n\t0x79d130a4, 0x3486ebfb, 0x33d3cddc,\n\t0x77853b53, 0x37effcb5, 0xc5068778, 0xe580b3e6, 0x4e68b8f4,\n\t0xc5c8b37e, 0x0d809ea2, 0x398feb7c,\n\t0x132a4f94, 0x43b7950e, 0x2fee7d1c, 0x223613bd, 0xdd06caa2,\n\t0x37df932b, 0xc4248289, 0xacf3ebc3,\n\t0x5715f6b7, 0xef3478dd, 0xf267616f, 0xc148cbe4, 0x9052815e,\n\t0x5e410fab, 0xb48a2465, 0x2eda7fa4,\n\t0xe87b40e4, 0xe98ea084, 0x5889e9e1, 0xefd390fc, 0xdd07d35b,\n\t0xdb485694, 0x38d7e5b2, 0x57720101,\n\t0x730edebc, 0x5b643113, 0x94917e4f, 0x503c2fba, 0x646f1282,\n\t0x7523d24a, 0xe0779695, 0xf9c17a8f,\n\t0x7a5b2121, 0xd187b896, 0x29263a4d, 0xba510cdf, 0x81f47c9f,\n\t0xad1163ed, 0xea7b5965, 0x1a00726e,\n\t0x11403092, 0x00da6d77, 0x4a0cdd61, 0xad1f4603, 0x605bdfb0,\n\t0x9eedc364, 0x22ebe6a8, 0xcee7d28a,\n\t0xa0e736a0, 0x5564a6b9, 0x10853209, 0xc7eb8f37, 0x2de705ca,\n\t0x8951570f, 0xdf09822b, 0xbd691a6c,\n\t0xaa12e4f2, 0x87451c0f, 0xe0f6a27a, 0x3ada4819, 0x4cf1764f,\n\t0x0d771c2b, 0x67cdb156, 0x350d8384,\n\t0x5938fa0f, 0x42399ef3, 0x36997b07, 0x0e84093d, 0x4aa93e61,\n\t0x8360d87b, 0x1fa98b0c, 0x1149382c,\n\t0xe97625a5, 0x0614d1b7, 0x0e25244b, 0x0c768347, 0x589e8d82,\n\t0x0d2059d1, 0xa466bb1e, 0xf8da0a82,\n\t0x04f19130, 0xba6e4ec0, 0x99265164, 0x1ee7230d, 0x50b2ad80,\n\t0xeaee6801, 0x8db2a283, 0xea8bf59e\n};\n\n#define s1 cast_s1\n#define s2 cast_s2\n#define s3 cast_s3\n#define s4 cast_s4\n\n#define F1(D, m, r)  ((I = ((m) + (D))), (I = rol32(I, (r))),   \\\n\t(((s1[I >> 24] ^ s2[(I>>16)&0xff]) - s3[(I>>8)&0xff]) + s4[I&0xff]))\n#define F2(D, m, r)  ((I = ((m) ^ (D))), (I = rol32(I, (r))),   \\\n\t(((s1[I >> 24] - s2[(I>>16)&0xff]) + s3[(I>>8)&0xff]) ^ s4[I&0xff]))\n#define F3(D, m, r)  ((I = ((m) - (D))), (I = rol32(I, (r))),   \\\n\t(((s1[I >> 24] + s2[(I>>16)&0xff]) ^ s3[(I>>8)&0xff]) - s4[I&0xff]))\n\n\nvoid __cast5_encrypt(struct cast5_ctx *c, u8 *outbuf, const u8 *inbuf)\n{\n\tconst __be32 *src = (const __be32 *)inbuf;\n\t__be32 *dst = (__be32 *)outbuf;\n\tu32 l, r, t;\n\tu32 I;\t\t\t/* used by the Fx macros */\n\tu32 *Km;\n\tu8 *Kr;\n\n\tKm = c->Km;\n\tKr = c->Kr;\n\n\t/* (L0,R0) <-- (m1...m64).  (Split the plaintext into left and\n\t * right 32-bit halves L0 = m1...m32 and R0 = m33...m64.)\n\t */\n\tl = be32_to_cpu(src[0]);\n\tr = be32_to_cpu(src[1]);\n\n\t/* (16 rounds) for i from 1 to 16, compute Li and Ri as follows:\n\t *  Li = Ri-1;\n\t *  Ri = Li-1 ^ f(Ri-1,Kmi,Kri), where f is defined in Section 2.2\n\t * Rounds 1, 4, 7, 10, 13, and 16 use f function Type 1.\n\t * Rounds 2, 5, 8, 11, and 14 use f function Type 2.\n\t * Rounds 3, 6, 9, 12, and 15 use f function Type 3.\n\t */\n\n\tt = l; l = r; r = t ^ F1(r, Km[0], Kr[0]);\n\tt = l; l = r; r = t ^ F2(r, Km[1], Kr[1]);\n\tt = l; l = r; r = t ^ F3(r, Km[2], Kr[2]);\n\tt = l; l = r; r = t ^ F1(r, Km[3], Kr[3]);\n\tt = l; l = r; r = t ^ F2(r, Km[4], Kr[4]);\n\tt = l; l = r; r = t ^ F3(r, Km[5], Kr[5]);\n\tt = l; l = r; r = t ^ F1(r, Km[6], Kr[6]);\n\tt = l; l = r; r = t ^ F2(r, Km[7], Kr[7]);\n\tt = l; l = r; r = t ^ F3(r, Km[8], Kr[8]);\n\tt = l; l = r; r = t ^ F1(r, Km[9], Kr[9]);\n\tt = l; l = r; r = t ^ F2(r, Km[10], Kr[10]);\n\tt = l; l = r; r = t ^ F3(r, Km[11], Kr[11]);\n\tif (!(c->rr)) {\n\t\tt = l; l = r; r = t ^ F1(r, Km[12], Kr[12]);\n\t\tt = l; l = r; r = t ^ F2(r, Km[13], Kr[13]);\n\t\tt = l; l = r; r = t ^ F3(r, Km[14], Kr[14]);\n\t\tt = l; l = r; r = t ^ F1(r, Km[15], Kr[15]);\n\t}\n\n\t/* c1...c64 <-- (R16,L16).  (Exchange final blocks L16, R16 and\n\t *  concatenate to form the ciphertext.) */\n\tdst[0] = cpu_to_be32(r);\n\tdst[1] = cpu_to_be32(l);\n}\nEXPORT_SYMBOL_GPL(__cast5_encrypt);\n\nstatic void cast5_encrypt(struct crypto_tfm *tfm, u8 *outbuf, const u8 *inbuf)\n{\n\t__cast5_encrypt(crypto_tfm_ctx(tfm), outbuf, inbuf);\n}\n\nvoid __cast5_decrypt(struct cast5_ctx *c, u8 *outbuf, const u8 *inbuf)\n{\n\tconst __be32 *src = (const __be32 *)inbuf;\n\t__be32 *dst = (__be32 *)outbuf;\n\tu32 l, r, t;\n\tu32 I;\n\tu32 *Km;\n\tu8 *Kr;\n\n\tKm = c->Km;\n\tKr = c->Kr;\n\n\tl = be32_to_cpu(src[0]);\n\tr = be32_to_cpu(src[1]);\n\n\tif (!(c->rr)) {\n\t\tt = l; l = r; r = t ^ F1(r, Km[15], Kr[15]);\n\t\tt = l; l = r; r = t ^ F3(r, Km[14], Kr[14]);\n\t\tt = l; l = r; r = t ^ F2(r, Km[13], Kr[13]);\n\t\tt = l; l = r; r = t ^ F1(r, Km[12], Kr[12]);\n\t}\n\tt = l; l = r; r = t ^ F3(r, Km[11], Kr[11]);\n\tt = l; l = r; r = t ^ F2(r, Km[10], Kr[10]);\n\tt = l; l = r; r = t ^ F1(r, Km[9], Kr[9]);\n\tt = l; l = r; r = t ^ F3(r, Km[8], Kr[8]);\n\tt = l; l = r; r = t ^ F2(r, Km[7], Kr[7]);\n\tt = l; l = r; r = t ^ F1(r, Km[6], Kr[6]);\n\tt = l; l = r; r = t ^ F3(r, Km[5], Kr[5]);\n\tt = l; l = r; r = t ^ F2(r, Km[4], Kr[4]);\n\tt = l; l = r; r = t ^ F1(r, Km[3], Kr[3]);\n\tt = l; l = r; r = t ^ F3(r, Km[2], Kr[2]);\n\tt = l; l = r; r = t ^ F2(r, Km[1], Kr[1]);\n\tt = l; l = r; r = t ^ F1(r, Km[0], Kr[0]);\n\n\tdst[0] = cpu_to_be32(r);\n\tdst[1] = cpu_to_be32(l);\n}\nEXPORT_SYMBOL_GPL(__cast5_decrypt);\n\nstatic void cast5_decrypt(struct crypto_tfm *tfm, u8 *outbuf, const u8 *inbuf)\n{\n\t__cast5_decrypt(crypto_tfm_ctx(tfm), outbuf, inbuf);\n}\n\nstatic void key_schedule(u32 *x, u32 *z, u32 *k)\n{\n\n#define xi(i)   ((x[(i)/4] >> (8*(3-((i)%4)))) & 0xff)\n#define zi(i)   ((z[(i)/4] >> (8*(3-((i)%4)))) & 0xff)\n\n\tz[0] = x[0] ^ s5[xi(13)] ^ s6[xi(15)] ^ s7[xi(12)] ^ sb8[xi(14)] ^\n\t    s7[xi(8)];\n\tz[1] = x[2] ^ s5[zi(0)] ^ s6[zi(2)] ^ s7[zi(1)] ^ sb8[zi(3)] ^\n\t    sb8[xi(10)];\n\tz[2] = x[3] ^ s5[zi(7)] ^ s6[zi(6)] ^ s7[zi(5)] ^ sb8[zi(4)] ^\n\t    s5[xi(9)];\n\tz[3] = x[1] ^ s5[zi(10)] ^ s6[zi(9)] ^ s7[zi(11)] ^ sb8[zi(8)] ^\n\t    s6[xi(11)];\n\tk[0] = s5[zi(8)] ^ s6[zi(9)] ^ s7[zi(7)] ^ sb8[zi(6)] ^ s5[zi(2)];\n\tk[1] = s5[zi(10)] ^ s6[zi(11)] ^ s7[zi(5)] ^ sb8[zi(4)] ^\n\t    s6[zi(6)];\n\tk[2] = s5[zi(12)] ^ s6[zi(13)] ^ s7[zi(3)] ^ sb8[zi(2)] ^\n\t    s7[zi(9)];\n\tk[3] = s5[zi(14)] ^ s6[zi(15)] ^ s7[zi(1)] ^ sb8[zi(0)] ^\n\t    sb8[zi(12)];\n\n\tx[0] = z[2] ^ s5[zi(5)] ^ s6[zi(7)] ^ s7[zi(4)] ^ sb8[zi(6)] ^\n\t    s7[zi(0)];\n\tx[1] = z[0] ^ s5[xi(0)] ^ s6[xi(2)] ^ s7[xi(1)] ^ sb8[xi(3)] ^\n\t    sb8[zi(2)];\n\tx[2] = z[1] ^ s5[xi(7)] ^ s6[xi(6)] ^ s7[xi(5)] ^ sb8[xi(4)] ^\n\t    s5[zi(1)];\n\tx[3] = z[3] ^ s5[xi(10)] ^ s6[xi(9)] ^ s7[xi(11)] ^ sb8[xi(8)] ^\n\t    s6[zi(3)];\n\tk[4] = s5[xi(3)] ^ s6[xi(2)] ^ s7[xi(12)] ^ sb8[xi(13)] ^\n\t    s5[xi(8)];\n\tk[5] = s5[xi(1)] ^ s6[xi(0)] ^ s7[xi(14)] ^ sb8[xi(15)] ^\n\t    s6[xi(13)];\n\tk[6] = s5[xi(7)] ^ s6[xi(6)] ^ s7[xi(8)] ^ sb8[xi(9)] ^ s7[xi(3)];\n\tk[7] = s5[xi(5)] ^ s6[xi(4)] ^ s7[xi(10)] ^ sb8[xi(11)] ^\n\t    sb8[xi(7)];\n\n\tz[0] = x[0] ^ s5[xi(13)] ^ s6[xi(15)] ^ s7[xi(12)] ^ sb8[xi(14)] ^\n\t    s7[xi(8)];\n\tz[1] = x[2] ^ s5[zi(0)] ^ s6[zi(2)] ^ s7[zi(1)] ^ sb8[zi(3)] ^\n\t    sb8[xi(10)];\n\tz[2] = x[3] ^ s5[zi(7)] ^ s6[zi(6)] ^ s7[zi(5)] ^ sb8[zi(4)] ^\n\t    s5[xi(9)];\n\tz[3] = x[1] ^ s5[zi(10)] ^ s6[zi(9)] ^ s7[zi(11)] ^ sb8[zi(8)] ^\n\t    s6[xi(11)];\n\tk[8] = s5[zi(3)] ^ s6[zi(2)] ^ s7[zi(12)] ^ sb8[zi(13)] ^\n\t    s5[zi(9)];\n\tk[9] = s5[zi(1)] ^ s6[zi(0)] ^ s7[zi(14)] ^ sb8[zi(15)] ^\n\t    s6[zi(12)];\n\tk[10] = s5[zi(7)] ^ s6[zi(6)] ^ s7[zi(8)] ^ sb8[zi(9)] ^ s7[zi(2)];\n\tk[11] = s5[zi(5)] ^ s6[zi(4)] ^ s7[zi(10)] ^ sb8[zi(11)] ^\n\t    sb8[zi(6)];\n\n\tx[0] = z[2] ^ s5[zi(5)] ^ s6[zi(7)] ^ s7[zi(4)] ^ sb8[zi(6)] ^\n\t    s7[zi(0)];\n\tx[1] = z[0] ^ s5[xi(0)] ^ s6[xi(2)] ^ s7[xi(1)] ^ sb8[xi(3)] ^\n\t    sb8[zi(2)];\n\tx[2] = z[1] ^ s5[xi(7)] ^ s6[xi(6)] ^ s7[xi(5)] ^ sb8[xi(4)] ^\n\t    s5[zi(1)];\n\tx[3] = z[3] ^ s5[xi(10)] ^ s6[xi(9)] ^ s7[xi(11)] ^ sb8[xi(8)] ^\n\t    s6[zi(3)];\n\tk[12] = s5[xi(8)] ^ s6[xi(9)] ^ s7[xi(7)] ^ sb8[xi(6)] ^ s5[xi(3)];\n\tk[13] = s5[xi(10)] ^ s6[xi(11)] ^ s7[xi(5)] ^ sb8[xi(4)] ^\n\t    s6[xi(7)];\n\tk[14] = s5[xi(12)] ^ s6[xi(13)] ^ s7[xi(3)] ^ sb8[xi(2)] ^\n\t    s7[xi(8)];\n\tk[15] = s5[xi(14)] ^ s6[xi(15)] ^ s7[xi(1)] ^ sb8[xi(0)] ^\n\t    sb8[xi(13)];\n\n#undef xi\n#undef zi\n}\n\n\nint cast5_setkey(struct crypto_tfm *tfm, const u8 *key, unsigned int key_len)\n{\n\tstruct cast5_ctx *c = crypto_tfm_ctx(tfm);\n\tint i;\n\tu32 x[4];\n\tu32 z[4];\n\tu32 k[16];\n\t__be32 p_key[4];\n\n\tc->rr = key_len <= 10 ? 1 : 0;\n\n\tmemset(p_key, 0, 16);\n\tmemcpy(p_key, key, key_len);\n\n\n\tx[0] = be32_to_cpu(p_key[0]);\n\tx[1] = be32_to_cpu(p_key[1]);\n\tx[2] = be32_to_cpu(p_key[2]);\n\tx[3] = be32_to_cpu(p_key[3]);\n\n\tkey_schedule(x, z, k);\n\tfor (i = 0; i < 16; i++)\n\t\tc->Km[i] = k[i];\n\tkey_schedule(x, z, k);\n\tfor (i = 0; i < 16; i++)\n\t\tc->Kr[i] = k[i] & 0x1f;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(cast5_setkey);\n\nstatic struct crypto_alg alg = {\n\t.cra_name\t\t= \"cast5\",\n\t.cra_driver_name\t= \"cast5-generic\",\n\t.cra_priority\t\t= 100,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t= CAST5_BLOCK_SIZE,\n\t.cra_ctxsize\t\t= sizeof(struct cast5_ctx),\n\t.cra_alignmask\t\t= 3,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u\t\t\t= {\n\t\t.cipher = {\n\t\t\t.cia_min_keysize = CAST5_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize = CAST5_MAX_KEY_SIZE,\n\t\t\t.cia_setkey  = cast5_setkey,\n\t\t\t.cia_encrypt = cast5_encrypt,\n\t\t\t.cia_decrypt = cast5_decrypt\n\t\t}\n\t}\n};\n\nstatic int __init cast5_mod_init(void)\n{\n\treturn crypto_register_alg(&alg);\n}\n\nstatic void __exit cast5_mod_fini(void)\n{\n\tcrypto_unregister_alg(&alg);\n}\n\nmodule_init(cast5_mod_init);\nmodule_exit(cast5_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Cast5 Cipher Algorithm\");\nMODULE_ALIAS_CRYPTO(\"cast5\");\n", "/* Kernel cryptographic api.\n * cast6.c - Cast6 cipher algorithm [rfc2612].\n *\n * CAST-256 (*cast6*) is a DES like Substitution-Permutation Network (SPN)\n * cryptosystem built upon the CAST-128 (*cast5*) [rfc2144] encryption\n * algorithm.\n *\n * Copyright (C) 2003 Kartikey Mahendra Bhatt <kartik_me@hotmail.com>.\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA\n */\n\n\n#include <asm/byteorder.h>\n#include <linux/init.h>\n#include <linux/crypto.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <crypto/cast6.h>\n\n#define s1 cast_s1\n#define s2 cast_s2\n#define s3 cast_s3\n#define s4 cast_s4\n\n#define F1(D, r, m)  ((I = ((m) + (D))), (I = rol32(I, (r))),   \\\n\t(((s1[I >> 24] ^ s2[(I>>16)&0xff]) - s3[(I>>8)&0xff]) + s4[I&0xff]))\n#define F2(D, r, m)  ((I = ((m) ^ (D))), (I = rol32(I, (r))),   \\\n\t(((s1[I >> 24] - s2[(I>>16)&0xff]) + s3[(I>>8)&0xff]) ^ s4[I&0xff]))\n#define F3(D, r, m)  ((I = ((m) - (D))), (I = rol32(I, (r))),   \\\n\t(((s1[I >> 24] + s2[(I>>16)&0xff]) ^ s3[(I>>8)&0xff]) - s4[I&0xff]))\n\nstatic const u32 Tm[24][8] = {\n\t{ 0x5a827999, 0xc95c653a, 0x383650db, 0xa7103c7c, 0x15ea281d,\n\t\t0x84c413be, 0xf39dff5f, 0x6277eb00 } ,\n\t{ 0xd151d6a1, 0x402bc242, 0xaf05ade3, 0x1ddf9984, 0x8cb98525,\n\t\t0xfb9370c6, 0x6a6d5c67, 0xd9474808 } ,\n\t{ 0x482133a9, 0xb6fb1f4a, 0x25d50aeb, 0x94aef68c, 0x0388e22d,\n\t\t0x7262cdce, 0xe13cb96f, 0x5016a510 } ,\n\t{ 0xbef090b1, 0x2dca7c52, 0x9ca467f3, 0x0b7e5394, 0x7a583f35,\n\t\t0xe9322ad6, 0x580c1677, 0xc6e60218 } ,\n\t{ 0x35bfedb9, 0xa499d95a, 0x1373c4fb, 0x824db09c, 0xf1279c3d,\n\t\t0x600187de, 0xcedb737f, 0x3db55f20 } ,\n\t{ 0xac8f4ac1, 0x1b693662, 0x8a432203, 0xf91d0da4, 0x67f6f945,\n\t\t0xd6d0e4e6, 0x45aad087, 0xb484bc28 } ,\n\t{ 0x235ea7c9, 0x9238936a, 0x01127f0b, 0x6fec6aac, 0xdec6564d,\n\t\t0x4da041ee, 0xbc7a2d8f, 0x2b541930 } ,\n\t{ 0x9a2e04d1, 0x0907f072, 0x77e1dc13, 0xe6bbc7b4, 0x5595b355,\n\t\t0xc46f9ef6, 0x33498a97, 0xa2237638 } ,\n\t{ 0x10fd61d9, 0x7fd74d7a, 0xeeb1391b, 0x5d8b24bc, 0xcc65105d,\n\t\t0x3b3efbfe, 0xaa18e79f, 0x18f2d340 } ,\n\t{ 0x87ccbee1, 0xf6a6aa82, 0x65809623, 0xd45a81c4, 0x43346d65,\n\t\t0xb20e5906, 0x20e844a7, 0x8fc23048 } ,\n\t{ 0xfe9c1be9, 0x6d76078a, 0xdc4ff32b, 0x4b29decc, 0xba03ca6d,\n\t\t0x28ddb60e, 0x97b7a1af, 0x06918d50 } ,\n\t{ 0x756b78f1, 0xe4456492, 0x531f5033, 0xc1f93bd4, 0x30d32775,\n\t\t0x9fad1316, 0x0e86feb7, 0x7d60ea58 } ,\n\t{ 0xec3ad5f9, 0x5b14c19a, 0xc9eead3b, 0x38c898dc, 0xa7a2847d,\n\t\t0x167c701e, 0x85565bbf, 0xf4304760 } ,\n\t{ 0x630a3301, 0xd1e41ea2, 0x40be0a43, 0xaf97f5e4, 0x1e71e185,\n\t\t0x8d4bcd26, 0xfc25b8c7, 0x6affa468 } ,\n\t{ 0xd9d99009, 0x48b37baa, 0xb78d674b, 0x266752ec, 0x95413e8d,\n\t\t0x041b2a2e, 0x72f515cf, 0xe1cf0170 } ,\n\t{ 0x50a8ed11, 0xbf82d8b2, 0x2e5cc453, 0x9d36aff4, 0x0c109b95,\n\t\t0x7aea8736, 0xe9c472d7, 0x589e5e78 } ,\n\t{ 0xc7784a19, 0x365235ba, 0xa52c215b, 0x14060cfc, 0x82dff89d,\n\t\t0xf1b9e43e, 0x6093cfdf, 0xcf6dbb80 } ,\n\t{ 0x3e47a721, 0xad2192c2, 0x1bfb7e63, 0x8ad56a04, 0xf9af55a5,\n\t\t0x68894146, 0xd7632ce7, 0x463d1888 } ,\n\t{ 0xb5170429, 0x23f0efca, 0x92cadb6b, 0x01a4c70c, 0x707eb2ad,\n\t\t0xdf589e4e, 0x4e3289ef, 0xbd0c7590 } ,\n\t{ 0x2be66131, 0x9ac04cd2, 0x099a3873, 0x78742414, 0xe74e0fb5,\n\t\t0x5627fb56, 0xc501e6f7, 0x33dbd298 } ,\n\t{ 0xa2b5be39, 0x118fa9da, 0x8069957b, 0xef43811c, 0x5e1d6cbd,\n\t\t0xccf7585e, 0x3bd143ff, 0xaaab2fa0 } ,\n\t{ 0x19851b41, 0x885f06e2, 0xf738f283, 0x6612de24, 0xd4ecc9c5,\n\t\t0x43c6b566, 0xb2a0a107, 0x217a8ca8 } ,\n\t{ 0x90547849, 0xff2e63ea, 0x6e084f8b, 0xdce23b2c, 0x4bbc26cd,\n\t\t0xba96126e, 0x296ffe0f, 0x9849e9b0 } ,\n\t{ 0x0723d551, 0x75fdc0f2, 0xe4d7ac93, 0x53b19834, 0xc28b83d5,\n\t\t0x31656f76, 0xa03f5b17, 0x0f1946b8 }\n};\n\nstatic const u8 Tr[4][8] = {\n\t{ 0x13, 0x04, 0x15, 0x06, 0x17, 0x08, 0x19, 0x0a } ,\n\t{ 0x1b, 0x0c, 0x1d, 0x0e, 0x1f, 0x10, 0x01, 0x12 } ,\n\t{ 0x03, 0x14, 0x05, 0x16, 0x07, 0x18, 0x09, 0x1a } ,\n\t{ 0x0b, 0x1c, 0x0d, 0x1e, 0x0f, 0x00, 0x11, 0x02 }\n};\n\n/* forward octave */\nstatic inline void W(u32 *key, unsigned int i)\n{\n\tu32 I;\n\tkey[6] ^= F1(key[7], Tr[i % 4][0], Tm[i][0]);\n\tkey[5] ^= F2(key[6], Tr[i % 4][1], Tm[i][1]);\n\tkey[4] ^= F3(key[5], Tr[i % 4][2], Tm[i][2]);\n\tkey[3] ^= F1(key[4], Tr[i % 4][3], Tm[i][3]);\n\tkey[2] ^= F2(key[3], Tr[i % 4][4], Tm[i][4]);\n\tkey[1] ^= F3(key[2], Tr[i % 4][5], Tm[i][5]);\n\tkey[0] ^= F1(key[1], Tr[i % 4][6], Tm[i][6]);\n\tkey[7] ^= F2(key[0], Tr[i % 4][7], Tm[i][7]);\n}\n\nint __cast6_setkey(struct cast6_ctx *c, const u8 *in_key,\n\t\t   unsigned key_len, u32 *flags)\n{\n\tint i;\n\tu32 key[8];\n\t__be32 p_key[8]; /* padded key */\n\n\tif (key_len % 4 != 0) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\tmemset(p_key, 0, 32);\n\tmemcpy(p_key, in_key, key_len);\n\n\tkey[0] = be32_to_cpu(p_key[0]);\t\t/* A */\n\tkey[1] = be32_to_cpu(p_key[1]);\t\t/* B */\n\tkey[2] = be32_to_cpu(p_key[2]);\t\t/* C */\n\tkey[3] = be32_to_cpu(p_key[3]);\t\t/* D */\n\tkey[4] = be32_to_cpu(p_key[4]);\t\t/* E */\n\tkey[5] = be32_to_cpu(p_key[5]);\t\t/* F */\n\tkey[6] = be32_to_cpu(p_key[6]);\t\t/* G */\n\tkey[7] = be32_to_cpu(p_key[7]);\t\t/* H */\n\n\tfor (i = 0; i < 12; i++) {\n\t\tW(key, 2 * i);\n\t\tW(key, 2 * i + 1);\n\n\t\tc->Kr[i][0] = key[0] & 0x1f;\n\t\tc->Kr[i][1] = key[2] & 0x1f;\n\t\tc->Kr[i][2] = key[4] & 0x1f;\n\t\tc->Kr[i][3] = key[6] & 0x1f;\n\n\t\tc->Km[i][0] = key[7];\n\t\tc->Km[i][1] = key[5];\n\t\tc->Km[i][2] = key[3];\n\t\tc->Km[i][3] = key[1];\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(__cast6_setkey);\n\nint cast6_setkey(struct crypto_tfm *tfm, const u8 *key, unsigned int keylen)\n{\n\treturn __cast6_setkey(crypto_tfm_ctx(tfm), key, keylen,\n\t\t\t      &tfm->crt_flags);\n}\nEXPORT_SYMBOL_GPL(cast6_setkey);\n\n/*forward quad round*/\nstatic inline void Q(u32 *block, u8 *Kr, u32 *Km)\n{\n\tu32 I;\n\tblock[2] ^= F1(block[3], Kr[0], Km[0]);\n\tblock[1] ^= F2(block[2], Kr[1], Km[1]);\n\tblock[0] ^= F3(block[1], Kr[2], Km[2]);\n\tblock[3] ^= F1(block[0], Kr[3], Km[3]);\n}\n\n/*reverse quad round*/\nstatic inline void QBAR(u32 *block, u8 *Kr, u32 *Km)\n{\n\tu32 I;\n\tblock[3] ^= F1(block[0], Kr[3], Km[3]);\n\tblock[0] ^= F3(block[1], Kr[2], Km[2]);\n\tblock[1] ^= F2(block[2], Kr[1], Km[1]);\n\tblock[2] ^= F1(block[3], Kr[0], Km[0]);\n}\n\nvoid __cast6_encrypt(struct cast6_ctx *c, u8 *outbuf, const u8 *inbuf)\n{\n\tconst __be32 *src = (const __be32 *)inbuf;\n\t__be32 *dst = (__be32 *)outbuf;\n\tu32 block[4];\n\tu32 *Km;\n\tu8 *Kr;\n\n\tblock[0] = be32_to_cpu(src[0]);\n\tblock[1] = be32_to_cpu(src[1]);\n\tblock[2] = be32_to_cpu(src[2]);\n\tblock[3] = be32_to_cpu(src[3]);\n\n\tKm = c->Km[0]; Kr = c->Kr[0]; Q(block, Kr, Km);\n\tKm = c->Km[1]; Kr = c->Kr[1]; Q(block, Kr, Km);\n\tKm = c->Km[2]; Kr = c->Kr[2]; Q(block, Kr, Km);\n\tKm = c->Km[3]; Kr = c->Kr[3]; Q(block, Kr, Km);\n\tKm = c->Km[4]; Kr = c->Kr[4]; Q(block, Kr, Km);\n\tKm = c->Km[5]; Kr = c->Kr[5]; Q(block, Kr, Km);\n\tKm = c->Km[6]; Kr = c->Kr[6]; QBAR(block, Kr, Km);\n\tKm = c->Km[7]; Kr = c->Kr[7]; QBAR(block, Kr, Km);\n\tKm = c->Km[8]; Kr = c->Kr[8]; QBAR(block, Kr, Km);\n\tKm = c->Km[9]; Kr = c->Kr[9]; QBAR(block, Kr, Km);\n\tKm = c->Km[10]; Kr = c->Kr[10]; QBAR(block, Kr, Km);\n\tKm = c->Km[11]; Kr = c->Kr[11]; QBAR(block, Kr, Km);\n\n\tdst[0] = cpu_to_be32(block[0]);\n\tdst[1] = cpu_to_be32(block[1]);\n\tdst[2] = cpu_to_be32(block[2]);\n\tdst[3] = cpu_to_be32(block[3]);\n}\nEXPORT_SYMBOL_GPL(__cast6_encrypt);\n\nstatic void cast6_encrypt(struct crypto_tfm *tfm, u8 *outbuf, const u8 *inbuf)\n{\n\t__cast6_encrypt(crypto_tfm_ctx(tfm), outbuf, inbuf);\n}\n\nvoid __cast6_decrypt(struct cast6_ctx *c, u8 *outbuf, const u8 *inbuf)\n{\n\tconst __be32 *src = (const __be32 *)inbuf;\n\t__be32 *dst = (__be32 *)outbuf;\n\tu32 block[4];\n\tu32 *Km;\n\tu8 *Kr;\n\n\tblock[0] = be32_to_cpu(src[0]);\n\tblock[1] = be32_to_cpu(src[1]);\n\tblock[2] = be32_to_cpu(src[2]);\n\tblock[3] = be32_to_cpu(src[3]);\n\n\tKm = c->Km[11]; Kr = c->Kr[11]; Q(block, Kr, Km);\n\tKm = c->Km[10]; Kr = c->Kr[10]; Q(block, Kr, Km);\n\tKm = c->Km[9]; Kr = c->Kr[9]; Q(block, Kr, Km);\n\tKm = c->Km[8]; Kr = c->Kr[8]; Q(block, Kr, Km);\n\tKm = c->Km[7]; Kr = c->Kr[7]; Q(block, Kr, Km);\n\tKm = c->Km[6]; Kr = c->Kr[6]; Q(block, Kr, Km);\n\tKm = c->Km[5]; Kr = c->Kr[5]; QBAR(block, Kr, Km);\n\tKm = c->Km[4]; Kr = c->Kr[4]; QBAR(block, Kr, Km);\n\tKm = c->Km[3]; Kr = c->Kr[3]; QBAR(block, Kr, Km);\n\tKm = c->Km[2]; Kr = c->Kr[2]; QBAR(block, Kr, Km);\n\tKm = c->Km[1]; Kr = c->Kr[1]; QBAR(block, Kr, Km);\n\tKm = c->Km[0]; Kr = c->Kr[0]; QBAR(block, Kr, Km);\n\n\tdst[0] = cpu_to_be32(block[0]);\n\tdst[1] = cpu_to_be32(block[1]);\n\tdst[2] = cpu_to_be32(block[2]);\n\tdst[3] = cpu_to_be32(block[3]);\n}\nEXPORT_SYMBOL_GPL(__cast6_decrypt);\n\nstatic void cast6_decrypt(struct crypto_tfm *tfm, u8 *outbuf, const u8 *inbuf)\n{\n\t__cast6_decrypt(crypto_tfm_ctx(tfm), outbuf, inbuf);\n}\n\nstatic struct crypto_alg alg = {\n\t.cra_name = \"cast6\",\n\t.cra_driver_name = \"cast6-generic\",\n\t.cra_priority = 100,\n\t.cra_flags = CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize = CAST6_BLOCK_SIZE,\n\t.cra_ctxsize = sizeof(struct cast6_ctx),\n\t.cra_alignmask = 3,\n\t.cra_module = THIS_MODULE,\n\t.cra_u = {\n\t\t  .cipher = {\n\t\t\t     .cia_min_keysize = CAST6_MIN_KEY_SIZE,\n\t\t\t     .cia_max_keysize = CAST6_MAX_KEY_SIZE,\n\t\t\t     .cia_setkey = cast6_setkey,\n\t\t\t     .cia_encrypt = cast6_encrypt,\n\t\t\t     .cia_decrypt = cast6_decrypt}\n\t\t  }\n};\n\nstatic int __init cast6_mod_init(void)\n{\n\treturn crypto_register_alg(&alg);\n}\n\nstatic void __exit cast6_mod_fini(void)\n{\n\tcrypto_unregister_alg(&alg);\n}\n\nmodule_init(cast6_mod_init);\nmodule_exit(cast6_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Cast6 Cipher Algorithm\");\nMODULE_ALIAS_CRYPTO(\"cast6\");\n", "/*\n * CCM: Counter with CBC-MAC\n *\n * (C) Copyright IBM Corp. 2007 - Joy Latten <latten@us.ibm.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#include <crypto/internal/aead.h>\n#include <crypto/internal/skcipher.h>\n#include <crypto/scatterwalk.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/slab.h>\n\n#include \"internal.h\"\n\nstruct ccm_instance_ctx {\n\tstruct crypto_skcipher_spawn ctr;\n\tstruct crypto_spawn cipher;\n};\n\nstruct crypto_ccm_ctx {\n\tstruct crypto_cipher *cipher;\n\tstruct crypto_ablkcipher *ctr;\n};\n\nstruct crypto_rfc4309_ctx {\n\tstruct crypto_aead *child;\n\tu8 nonce[3];\n};\n\nstruct crypto_ccm_req_priv_ctx {\n\tu8 odata[16];\n\tu8 idata[16];\n\tu8 auth_tag[16];\n\tu32 ilen;\n\tu32 flags;\n\tstruct scatterlist src[2];\n\tstruct scatterlist dst[2];\n\tstruct ablkcipher_request abreq;\n};\n\nstatic inline struct crypto_ccm_req_priv_ctx *crypto_ccm_reqctx(\n\tstruct aead_request *req)\n{\n\tunsigned long align = crypto_aead_alignmask(crypto_aead_reqtfm(req));\n\n\treturn (void *)PTR_ALIGN((u8 *)aead_request_ctx(req), align + 1);\n}\n\nstatic int set_msg_len(u8 *block, unsigned int msglen, int csize)\n{\n\t__be32 data;\n\n\tmemset(block, 0, csize);\n\tblock += csize;\n\n\tif (csize >= 4)\n\t\tcsize = 4;\n\telse if (msglen > (1 << (8 * csize)))\n\t\treturn -EOVERFLOW;\n\n\tdata = cpu_to_be32(msglen);\n\tmemcpy(block - csize, (u8 *)&data + 4 - csize, csize);\n\n\treturn 0;\n}\n\nstatic int crypto_ccm_setkey(struct crypto_aead *aead, const u8 *key,\n\t\t\t     unsigned int keylen)\n{\n\tstruct crypto_ccm_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct crypto_ablkcipher *ctr = ctx->ctr;\n\tstruct crypto_cipher *tfm = ctx->cipher;\n\tint err = 0;\n\n\tcrypto_ablkcipher_clear_flags(ctr, CRYPTO_TFM_REQ_MASK);\n\tcrypto_ablkcipher_set_flags(ctr, crypto_aead_get_flags(aead) &\n\t\t\t\t    CRYPTO_TFM_REQ_MASK);\n\terr = crypto_ablkcipher_setkey(ctr, key, keylen);\n\tcrypto_aead_set_flags(aead, crypto_ablkcipher_get_flags(ctr) &\n\t\t\t      CRYPTO_TFM_RES_MASK);\n\tif (err)\n\t\tgoto out;\n\n\tcrypto_cipher_clear_flags(tfm, CRYPTO_TFM_REQ_MASK);\n\tcrypto_cipher_set_flags(tfm, crypto_aead_get_flags(aead) &\n\t\t\t\t    CRYPTO_TFM_REQ_MASK);\n\terr = crypto_cipher_setkey(tfm, key, keylen);\n\tcrypto_aead_set_flags(aead, crypto_cipher_get_flags(tfm) &\n\t\t\t      CRYPTO_TFM_RES_MASK);\n\nout:\n\treturn err;\n}\n\nstatic int crypto_ccm_setauthsize(struct crypto_aead *tfm,\n\t\t\t\t  unsigned int authsize)\n{\n\tswitch (authsize) {\n\tcase 4:\n\tcase 6:\n\tcase 8:\n\tcase 10:\n\tcase 12:\n\tcase 14:\n\tcase 16:\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int format_input(u8 *info, struct aead_request *req,\n\t\t\tunsigned int cryptlen)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tunsigned int lp = req->iv[0];\n\tunsigned int l = lp + 1;\n\tunsigned int m;\n\n\tm = crypto_aead_authsize(aead);\n\n\tmemcpy(info, req->iv, 16);\n\n\t/* format control info per RFC 3610 and\n\t * NIST Special Publication 800-38C\n\t */\n\t*info |= (8 * ((m - 2) / 2));\n\tif (req->assoclen)\n\t\t*info |= 64;\n\n\treturn set_msg_len(info + 16 - l, cryptlen, l);\n}\n\nstatic int format_adata(u8 *adata, unsigned int a)\n{\n\tint len = 0;\n\n\t/* add control info for associated data\n\t * RFC 3610 and NIST Special Publication 800-38C\n\t */\n\tif (a < 65280) {\n\t\t*(__be16 *)adata = cpu_to_be16(a);\n\t\tlen = 2;\n\t} else  {\n\t\t*(__be16 *)adata = cpu_to_be16(0xfffe);\n\t\t*(__be32 *)&adata[2] = cpu_to_be32(a);\n\t\tlen = 6;\n\t}\n\n\treturn len;\n}\n\nstatic void compute_mac(struct crypto_cipher *tfm, u8 *data, int n,\n\t\t       struct crypto_ccm_req_priv_ctx *pctx)\n{\n\tunsigned int bs = 16;\n\tu8 *odata = pctx->odata;\n\tu8 *idata = pctx->idata;\n\tint datalen, getlen;\n\n\tdatalen = n;\n\n\t/* first time in here, block may be partially filled. */\n\tgetlen = bs - pctx->ilen;\n\tif (datalen >= getlen) {\n\t\tmemcpy(idata + pctx->ilen, data, getlen);\n\t\tcrypto_xor(odata, idata, bs);\n\t\tcrypto_cipher_encrypt_one(tfm, odata, odata);\n\t\tdatalen -= getlen;\n\t\tdata += getlen;\n\t\tpctx->ilen = 0;\n\t}\n\n\t/* now encrypt rest of data */\n\twhile (datalen >= bs) {\n\t\tcrypto_xor(odata, data, bs);\n\t\tcrypto_cipher_encrypt_one(tfm, odata, odata);\n\n\t\tdatalen -= bs;\n\t\tdata += bs;\n\t}\n\n\t/* check and see if there's leftover data that wasn't\n\t * enough to fill a block.\n\t */\n\tif (datalen) {\n\t\tmemcpy(idata + pctx->ilen, data, datalen);\n\t\tpctx->ilen += datalen;\n\t}\n}\n\nstatic void get_data_to_compute(struct crypto_cipher *tfm,\n\t\t\t       struct crypto_ccm_req_priv_ctx *pctx,\n\t\t\t       struct scatterlist *sg, unsigned int len)\n{\n\tstruct scatter_walk walk;\n\tu8 *data_src;\n\tint n;\n\n\tscatterwalk_start(&walk, sg);\n\n\twhile (len) {\n\t\tn = scatterwalk_clamp(&walk, len);\n\t\tif (!n) {\n\t\t\tscatterwalk_start(&walk, sg_next(walk.sg));\n\t\t\tn = scatterwalk_clamp(&walk, len);\n\t\t}\n\t\tdata_src = scatterwalk_map(&walk);\n\n\t\tcompute_mac(tfm, data_src, n, pctx);\n\t\tlen -= n;\n\n\t\tscatterwalk_unmap(data_src);\n\t\tscatterwalk_advance(&walk, n);\n\t\tscatterwalk_done(&walk, 0, len);\n\t\tif (len)\n\t\t\tcrypto_yield(pctx->flags);\n\t}\n\n\t/* any leftover needs padding and then encrypted */\n\tif (pctx->ilen) {\n\t\tint padlen;\n\t\tu8 *odata = pctx->odata;\n\t\tu8 *idata = pctx->idata;\n\n\t\tpadlen = 16 - pctx->ilen;\n\t\tmemset(idata + pctx->ilen, 0, padlen);\n\t\tcrypto_xor(odata, idata, 16);\n\t\tcrypto_cipher_encrypt_one(tfm, odata, odata);\n\t\tpctx->ilen = 0;\n\t}\n}\n\nstatic int crypto_ccm_auth(struct aead_request *req, struct scatterlist *plain,\n\t\t\t   unsigned int cryptlen)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_ccm_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct crypto_ccm_req_priv_ctx *pctx = crypto_ccm_reqctx(req);\n\tstruct crypto_cipher *cipher = ctx->cipher;\n\tunsigned int assoclen = req->assoclen;\n\tu8 *odata = pctx->odata;\n\tu8 *idata = pctx->idata;\n\tint err;\n\n\t/* format control data for input */\n\terr = format_input(odata, req, cryptlen);\n\tif (err)\n\t\tgoto out;\n\n\t/* encrypt first block to use as start in computing mac  */\n\tcrypto_cipher_encrypt_one(cipher, odata, odata);\n\n\t/* format associated data and compute into mac */\n\tif (assoclen) {\n\t\tpctx->ilen = format_adata(idata, assoclen);\n\t\tget_data_to_compute(cipher, pctx, req->assoc, req->assoclen);\n\t} else {\n\t\tpctx->ilen = 0;\n\t}\n\n\t/* compute plaintext into mac */\n\tif (cryptlen)\n\t\tget_data_to_compute(cipher, pctx, plain, cryptlen);\n\nout:\n\treturn err;\n}\n\nstatic void crypto_ccm_encrypt_done(struct crypto_async_request *areq, int err)\n{\n\tstruct aead_request *req = areq->data;\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_ccm_req_priv_ctx *pctx = crypto_ccm_reqctx(req);\n\tu8 *odata = pctx->odata;\n\n\tif (!err)\n\t\tscatterwalk_map_and_copy(odata, req->dst, req->cryptlen,\n\t\t\t\t\t crypto_aead_authsize(aead), 1);\n\taead_request_complete(req, err);\n}\n\nstatic inline int crypto_ccm_check_iv(const u8 *iv)\n{\n\t/* 2 <= L <= 8, so 1 <= L' <= 7. */\n\tif (1 > iv[0] || iv[0] > 7)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int crypto_ccm_encrypt(struct aead_request *req)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_ccm_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct crypto_ccm_req_priv_ctx *pctx = crypto_ccm_reqctx(req);\n\tstruct ablkcipher_request *abreq = &pctx->abreq;\n\tstruct scatterlist *dst;\n\tunsigned int cryptlen = req->cryptlen;\n\tu8 *odata = pctx->odata;\n\tu8 *iv = req->iv;\n\tint err;\n\n\terr = crypto_ccm_check_iv(iv);\n\tif (err)\n\t\treturn err;\n\n\tpctx->flags = aead_request_flags(req);\n\n\terr = crypto_ccm_auth(req, req->src, cryptlen);\n\tif (err)\n\t\treturn err;\n\n\t /* Note: rfc 3610 and NIST 800-38C require counter of\n\t * zero to encrypt auth tag.\n\t */\n\tmemset(iv + 15 - iv[0], 0, iv[0] + 1);\n\n\tsg_init_table(pctx->src, 2);\n\tsg_set_buf(pctx->src, odata, 16);\n\tscatterwalk_sg_chain(pctx->src, 2, req->src);\n\n\tdst = pctx->src;\n\tif (req->src != req->dst) {\n\t\tsg_init_table(pctx->dst, 2);\n\t\tsg_set_buf(pctx->dst, odata, 16);\n\t\tscatterwalk_sg_chain(pctx->dst, 2, req->dst);\n\t\tdst = pctx->dst;\n\t}\n\n\tablkcipher_request_set_tfm(abreq, ctx->ctr);\n\tablkcipher_request_set_callback(abreq, pctx->flags,\n\t\t\t\t\tcrypto_ccm_encrypt_done, req);\n\tablkcipher_request_set_crypt(abreq, pctx->src, dst, cryptlen + 16, iv);\n\terr = crypto_ablkcipher_encrypt(abreq);\n\tif (err)\n\t\treturn err;\n\n\t/* copy authtag to end of dst */\n\tscatterwalk_map_and_copy(odata, req->dst, cryptlen,\n\t\t\t\t crypto_aead_authsize(aead), 1);\n\treturn err;\n}\n\nstatic void crypto_ccm_decrypt_done(struct crypto_async_request *areq,\n\t\t\t\t   int err)\n{\n\tstruct aead_request *req = areq->data;\n\tstruct crypto_ccm_req_priv_ctx *pctx = crypto_ccm_reqctx(req);\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tunsigned int authsize = crypto_aead_authsize(aead);\n\tunsigned int cryptlen = req->cryptlen - authsize;\n\n\tif (!err) {\n\t\terr = crypto_ccm_auth(req, req->dst, cryptlen);\n\t\tif (!err && crypto_memneq(pctx->auth_tag, pctx->odata, authsize))\n\t\t\terr = -EBADMSG;\n\t}\n\taead_request_complete(req, err);\n}\n\nstatic int crypto_ccm_decrypt(struct aead_request *req)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_ccm_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct crypto_ccm_req_priv_ctx *pctx = crypto_ccm_reqctx(req);\n\tstruct ablkcipher_request *abreq = &pctx->abreq;\n\tstruct scatterlist *dst;\n\tunsigned int authsize = crypto_aead_authsize(aead);\n\tunsigned int cryptlen = req->cryptlen;\n\tu8 *authtag = pctx->auth_tag;\n\tu8 *odata = pctx->odata;\n\tu8 *iv = req->iv;\n\tint err;\n\n\tif (cryptlen < authsize)\n\t\treturn -EINVAL;\n\tcryptlen -= authsize;\n\n\terr = crypto_ccm_check_iv(iv);\n\tif (err)\n\t\treturn err;\n\n\tpctx->flags = aead_request_flags(req);\n\n\tscatterwalk_map_and_copy(authtag, req->src, cryptlen, authsize, 0);\n\n\tmemset(iv + 15 - iv[0], 0, iv[0] + 1);\n\n\tsg_init_table(pctx->src, 2);\n\tsg_set_buf(pctx->src, authtag, 16);\n\tscatterwalk_sg_chain(pctx->src, 2, req->src);\n\n\tdst = pctx->src;\n\tif (req->src != req->dst) {\n\t\tsg_init_table(pctx->dst, 2);\n\t\tsg_set_buf(pctx->dst, authtag, 16);\n\t\tscatterwalk_sg_chain(pctx->dst, 2, req->dst);\n\t\tdst = pctx->dst;\n\t}\n\n\tablkcipher_request_set_tfm(abreq, ctx->ctr);\n\tablkcipher_request_set_callback(abreq, pctx->flags,\n\t\t\t\t\tcrypto_ccm_decrypt_done, req);\n\tablkcipher_request_set_crypt(abreq, pctx->src, dst, cryptlen + 16, iv);\n\terr = crypto_ablkcipher_decrypt(abreq);\n\tif (err)\n\t\treturn err;\n\n\terr = crypto_ccm_auth(req, req->dst, cryptlen);\n\tif (err)\n\t\treturn err;\n\n\t/* verify */\n\tif (crypto_memneq(authtag, odata, authsize))\n\t\treturn -EBADMSG;\n\n\treturn err;\n}\n\nstatic int crypto_ccm_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_instance *inst = (void *)tfm->__crt_alg;\n\tstruct ccm_instance_ctx *ictx = crypto_instance_ctx(inst);\n\tstruct crypto_ccm_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_cipher *cipher;\n\tstruct crypto_ablkcipher *ctr;\n\tunsigned long align;\n\tint err;\n\n\tcipher = crypto_spawn_cipher(&ictx->cipher);\n\tif (IS_ERR(cipher))\n\t\treturn PTR_ERR(cipher);\n\n\tctr = crypto_spawn_skcipher(&ictx->ctr);\n\terr = PTR_ERR(ctr);\n\tif (IS_ERR(ctr))\n\t\tgoto err_free_cipher;\n\n\tctx->cipher = cipher;\n\tctx->ctr = ctr;\n\n\talign = crypto_tfm_alg_alignmask(tfm);\n\talign &= ~(crypto_tfm_ctx_alignment() - 1);\n\ttfm->crt_aead.reqsize = align +\n\t\t\t\tsizeof(struct crypto_ccm_req_priv_ctx) +\n\t\t\t\tcrypto_ablkcipher_reqsize(ctr);\n\n\treturn 0;\n\nerr_free_cipher:\n\tcrypto_free_cipher(cipher);\n\treturn err;\n}\n\nstatic void crypto_ccm_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_ccm_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_cipher(ctx->cipher);\n\tcrypto_free_ablkcipher(ctx->ctr);\n}\n\nstatic struct crypto_instance *crypto_ccm_alloc_common(struct rtattr **tb,\n\t\t\t\t\t\t       const char *full_name,\n\t\t\t\t\t\t       const char *ctr_name,\n\t\t\t\t\t\t       const char *cipher_name)\n{\n\tstruct crypto_attr_type *algt;\n\tstruct crypto_instance *inst;\n\tstruct crypto_alg *ctr;\n\tstruct crypto_alg *cipher;\n\tstruct ccm_instance_ctx *ictx;\n\tint err;\n\n\talgt = crypto_get_attr_type(tb);\n\tif (IS_ERR(algt))\n\t\treturn ERR_CAST(algt);\n\n\tif ((algt->type ^ CRYPTO_ALG_TYPE_AEAD) & algt->mask)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tcipher = crypto_alg_mod_lookup(cipher_name,  CRYPTO_ALG_TYPE_CIPHER,\n\t\t\t\t       CRYPTO_ALG_TYPE_MASK);\n\tif (IS_ERR(cipher))\n\t\treturn ERR_CAST(cipher);\n\n\terr = -EINVAL;\n\tif (cipher->cra_blocksize != 16)\n\t\tgoto out_put_cipher;\n\n\tinst = kzalloc(sizeof(*inst) + sizeof(*ictx), GFP_KERNEL);\n\terr = -ENOMEM;\n\tif (!inst)\n\t\tgoto out_put_cipher;\n\n\tictx = crypto_instance_ctx(inst);\n\n\terr = crypto_init_spawn(&ictx->cipher, cipher, inst,\n\t\t\t\tCRYPTO_ALG_TYPE_MASK);\n\tif (err)\n\t\tgoto err_free_inst;\n\n\tcrypto_set_skcipher_spawn(&ictx->ctr, inst);\n\terr = crypto_grab_skcipher(&ictx->ctr, ctr_name, 0,\n\t\t\t\t   crypto_requires_sync(algt->type,\n\t\t\t\t\t\t\talgt->mask));\n\tif (err)\n\t\tgoto err_drop_cipher;\n\n\tctr = crypto_skcipher_spawn_alg(&ictx->ctr);\n\n\t/* Not a stream cipher? */\n\terr = -EINVAL;\n\tif (ctr->cra_blocksize != 1)\n\t\tgoto err_drop_ctr;\n\n\t/* We want the real thing! */\n\tif (ctr->cra_ablkcipher.ivsize != 16)\n\t\tgoto err_drop_ctr;\n\n\terr = -ENAMETOOLONG;\n\tif (snprintf(inst->alg.cra_driver_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"ccm_base(%s,%s)\", ctr->cra_driver_name,\n\t\t     cipher->cra_driver_name) >= CRYPTO_MAX_ALG_NAME)\n\t\tgoto err_drop_ctr;\n\n\tmemcpy(inst->alg.cra_name, full_name, CRYPTO_MAX_ALG_NAME);\n\n\tinst->alg.cra_flags = CRYPTO_ALG_TYPE_AEAD;\n\tinst->alg.cra_flags |= ctr->cra_flags & CRYPTO_ALG_ASYNC;\n\tinst->alg.cra_priority = cipher->cra_priority + ctr->cra_priority;\n\tinst->alg.cra_blocksize = 1;\n\tinst->alg.cra_alignmask = cipher->cra_alignmask | ctr->cra_alignmask |\n\t\t\t\t  (__alignof__(u32) - 1);\n\tinst->alg.cra_type = &crypto_aead_type;\n\tinst->alg.cra_aead.ivsize = 16;\n\tinst->alg.cra_aead.maxauthsize = 16;\n\tinst->alg.cra_ctxsize = sizeof(struct crypto_ccm_ctx);\n\tinst->alg.cra_init = crypto_ccm_init_tfm;\n\tinst->alg.cra_exit = crypto_ccm_exit_tfm;\n\tinst->alg.cra_aead.setkey = crypto_ccm_setkey;\n\tinst->alg.cra_aead.setauthsize = crypto_ccm_setauthsize;\n\tinst->alg.cra_aead.encrypt = crypto_ccm_encrypt;\n\tinst->alg.cra_aead.decrypt = crypto_ccm_decrypt;\n\nout:\n\tcrypto_mod_put(cipher);\n\treturn inst;\n\nerr_drop_ctr:\n\tcrypto_drop_skcipher(&ictx->ctr);\nerr_drop_cipher:\n\tcrypto_drop_spawn(&ictx->cipher);\nerr_free_inst:\n\tkfree(inst);\nout_put_cipher:\n\tinst = ERR_PTR(err);\n\tgoto out;\n}\n\nstatic struct crypto_instance *crypto_ccm_alloc(struct rtattr **tb)\n{\n\tconst char *cipher_name;\n\tchar ctr_name[CRYPTO_MAX_ALG_NAME];\n\tchar full_name[CRYPTO_MAX_ALG_NAME];\n\n\tcipher_name = crypto_attr_alg_name(tb[1]);\n\tif (IS_ERR(cipher_name))\n\t\treturn ERR_CAST(cipher_name);\n\n\tif (snprintf(ctr_name, CRYPTO_MAX_ALG_NAME, \"ctr(%s)\",\n\t\t     cipher_name) >= CRYPTO_MAX_ALG_NAME)\n\t\treturn ERR_PTR(-ENAMETOOLONG);\n\n\tif (snprintf(full_name, CRYPTO_MAX_ALG_NAME, \"ccm(%s)\", cipher_name) >=\n\t    CRYPTO_MAX_ALG_NAME)\n\t\treturn ERR_PTR(-ENAMETOOLONG);\n\n\treturn crypto_ccm_alloc_common(tb, full_name, ctr_name, cipher_name);\n}\n\nstatic void crypto_ccm_free(struct crypto_instance *inst)\n{\n\tstruct ccm_instance_ctx *ctx = crypto_instance_ctx(inst);\n\n\tcrypto_drop_spawn(&ctx->cipher);\n\tcrypto_drop_skcipher(&ctx->ctr);\n\tkfree(inst);\n}\n\nstatic struct crypto_template crypto_ccm_tmpl = {\n\t.name = \"ccm\",\n\t.alloc = crypto_ccm_alloc,\n\t.free = crypto_ccm_free,\n\t.module = THIS_MODULE,\n};\n\nstatic struct crypto_instance *crypto_ccm_base_alloc(struct rtattr **tb)\n{\n\tconst char *ctr_name;\n\tconst char *cipher_name;\n\tchar full_name[CRYPTO_MAX_ALG_NAME];\n\n\tctr_name = crypto_attr_alg_name(tb[1]);\n\tif (IS_ERR(ctr_name))\n\t\treturn ERR_CAST(ctr_name);\n\n\tcipher_name = crypto_attr_alg_name(tb[2]);\n\tif (IS_ERR(cipher_name))\n\t\treturn ERR_CAST(cipher_name);\n\n\tif (snprintf(full_name, CRYPTO_MAX_ALG_NAME, \"ccm_base(%s,%s)\",\n\t\t     ctr_name, cipher_name) >= CRYPTO_MAX_ALG_NAME)\n\t\treturn ERR_PTR(-ENAMETOOLONG);\n\n\treturn crypto_ccm_alloc_common(tb, full_name, ctr_name, cipher_name);\n}\n\nstatic struct crypto_template crypto_ccm_base_tmpl = {\n\t.name = \"ccm_base\",\n\t.alloc = crypto_ccm_base_alloc,\n\t.free = crypto_ccm_free,\n\t.module = THIS_MODULE,\n};\n\nstatic int crypto_rfc4309_setkey(struct crypto_aead *parent, const u8 *key,\n\t\t\t\t unsigned int keylen)\n{\n\tstruct crypto_rfc4309_ctx *ctx = crypto_aead_ctx(parent);\n\tstruct crypto_aead *child = ctx->child;\n\tint err;\n\n\tif (keylen < 3)\n\t\treturn -EINVAL;\n\n\tkeylen -= 3;\n\tmemcpy(ctx->nonce, key + keylen, 3);\n\n\tcrypto_aead_clear_flags(child, CRYPTO_TFM_REQ_MASK);\n\tcrypto_aead_set_flags(child, crypto_aead_get_flags(parent) &\n\t\t\t\t     CRYPTO_TFM_REQ_MASK);\n\terr = crypto_aead_setkey(child, key, keylen);\n\tcrypto_aead_set_flags(parent, crypto_aead_get_flags(child) &\n\t\t\t\t      CRYPTO_TFM_RES_MASK);\n\n\treturn err;\n}\n\nstatic int crypto_rfc4309_setauthsize(struct crypto_aead *parent,\n\t\t\t\t      unsigned int authsize)\n{\n\tstruct crypto_rfc4309_ctx *ctx = crypto_aead_ctx(parent);\n\n\tswitch (authsize) {\n\tcase 8:\n\tcase 12:\n\tcase 16:\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn crypto_aead_setauthsize(ctx->child, authsize);\n}\n\nstatic struct aead_request *crypto_rfc4309_crypt(struct aead_request *req)\n{\n\tstruct aead_request *subreq = aead_request_ctx(req);\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_rfc4309_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct crypto_aead *child = ctx->child;\n\tu8 *iv = PTR_ALIGN((u8 *)(subreq + 1) + crypto_aead_reqsize(child),\n\t\t\t   crypto_aead_alignmask(child) + 1);\n\n\t/* L' */\n\tiv[0] = 3;\n\n\tmemcpy(iv + 1, ctx->nonce, 3);\n\tmemcpy(iv + 4, req->iv, 8);\n\n\taead_request_set_tfm(subreq, child);\n\taead_request_set_callback(subreq, req->base.flags, req->base.complete,\n\t\t\t\t  req->base.data);\n\taead_request_set_crypt(subreq, req->src, req->dst, req->cryptlen, iv);\n\taead_request_set_assoc(subreq, req->assoc, req->assoclen);\n\n\treturn subreq;\n}\n\nstatic int crypto_rfc4309_encrypt(struct aead_request *req)\n{\n\treq = crypto_rfc4309_crypt(req);\n\n\treturn crypto_aead_encrypt(req);\n}\n\nstatic int crypto_rfc4309_decrypt(struct aead_request *req)\n{\n\treq = crypto_rfc4309_crypt(req);\n\n\treturn crypto_aead_decrypt(req);\n}\n\nstatic int crypto_rfc4309_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_instance *inst = (void *)tfm->__crt_alg;\n\tstruct crypto_aead_spawn *spawn = crypto_instance_ctx(inst);\n\tstruct crypto_rfc4309_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_aead *aead;\n\tunsigned long align;\n\n\taead = crypto_spawn_aead(spawn);\n\tif (IS_ERR(aead))\n\t\treturn PTR_ERR(aead);\n\n\tctx->child = aead;\n\n\talign = crypto_aead_alignmask(aead);\n\talign &= ~(crypto_tfm_ctx_alignment() - 1);\n\ttfm->crt_aead.reqsize = sizeof(struct aead_request) +\n\t\t\t\tALIGN(crypto_aead_reqsize(aead),\n\t\t\t\t      crypto_tfm_ctx_alignment()) +\n\t\t\t\talign + 16;\n\n\treturn 0;\n}\n\nstatic void crypto_rfc4309_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_rfc4309_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_aead(ctx->child);\n}\n\nstatic struct crypto_instance *crypto_rfc4309_alloc(struct rtattr **tb)\n{\n\tstruct crypto_attr_type *algt;\n\tstruct crypto_instance *inst;\n\tstruct crypto_aead_spawn *spawn;\n\tstruct crypto_alg *alg;\n\tconst char *ccm_name;\n\tint err;\n\n\talgt = crypto_get_attr_type(tb);\n\tif (IS_ERR(algt))\n\t\treturn ERR_CAST(algt);\n\n\tif ((algt->type ^ CRYPTO_ALG_TYPE_AEAD) & algt->mask)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tccm_name = crypto_attr_alg_name(tb[1]);\n\tif (IS_ERR(ccm_name))\n\t\treturn ERR_CAST(ccm_name);\n\n\tinst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);\n\tif (!inst)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tspawn = crypto_instance_ctx(inst);\n\tcrypto_set_aead_spawn(spawn, inst);\n\terr = crypto_grab_aead(spawn, ccm_name, 0,\n\t\t\t       crypto_requires_sync(algt->type, algt->mask));\n\tif (err)\n\t\tgoto out_free_inst;\n\n\talg = crypto_aead_spawn_alg(spawn);\n\n\terr = -EINVAL;\n\n\t/* We only support 16-byte blocks. */\n\tif (alg->cra_aead.ivsize != 16)\n\t\tgoto out_drop_alg;\n\n\t/* Not a stream cipher? */\n\tif (alg->cra_blocksize != 1)\n\t\tgoto out_drop_alg;\n\n\terr = -ENAMETOOLONG;\n\tif (snprintf(inst->alg.cra_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"rfc4309(%s)\", alg->cra_name) >= CRYPTO_MAX_ALG_NAME ||\n\t    snprintf(inst->alg.cra_driver_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"rfc4309(%s)\", alg->cra_driver_name) >=\n\t    CRYPTO_MAX_ALG_NAME)\n\t\tgoto out_drop_alg;\n\n\tinst->alg.cra_flags = CRYPTO_ALG_TYPE_AEAD;\n\tinst->alg.cra_flags |= alg->cra_flags & CRYPTO_ALG_ASYNC;\n\tinst->alg.cra_priority = alg->cra_priority;\n\tinst->alg.cra_blocksize = 1;\n\tinst->alg.cra_alignmask = alg->cra_alignmask;\n\tinst->alg.cra_type = &crypto_nivaead_type;\n\n\tinst->alg.cra_aead.ivsize = 8;\n\tinst->alg.cra_aead.maxauthsize = 16;\n\n\tinst->alg.cra_ctxsize = sizeof(struct crypto_rfc4309_ctx);\n\n\tinst->alg.cra_init = crypto_rfc4309_init_tfm;\n\tinst->alg.cra_exit = crypto_rfc4309_exit_tfm;\n\n\tinst->alg.cra_aead.setkey = crypto_rfc4309_setkey;\n\tinst->alg.cra_aead.setauthsize = crypto_rfc4309_setauthsize;\n\tinst->alg.cra_aead.encrypt = crypto_rfc4309_encrypt;\n\tinst->alg.cra_aead.decrypt = crypto_rfc4309_decrypt;\n\n\tinst->alg.cra_aead.geniv = \"seqiv\";\n\nout:\n\treturn inst;\n\nout_drop_alg:\n\tcrypto_drop_aead(spawn);\nout_free_inst:\n\tkfree(inst);\n\tinst = ERR_PTR(err);\n\tgoto out;\n}\n\nstatic void crypto_rfc4309_free(struct crypto_instance *inst)\n{\n\tcrypto_drop_spawn(crypto_instance_ctx(inst));\n\tkfree(inst);\n}\n\nstatic struct crypto_template crypto_rfc4309_tmpl = {\n\t.name = \"rfc4309\",\n\t.alloc = crypto_rfc4309_alloc,\n\t.free = crypto_rfc4309_free,\n\t.module = THIS_MODULE,\n};\n\nstatic int __init crypto_ccm_module_init(void)\n{\n\tint err;\n\n\terr = crypto_register_template(&crypto_ccm_base_tmpl);\n\tif (err)\n\t\tgoto out;\n\n\terr = crypto_register_template(&crypto_ccm_tmpl);\n\tif (err)\n\t\tgoto out_undo_base;\n\n\terr = crypto_register_template(&crypto_rfc4309_tmpl);\n\tif (err)\n\t\tgoto out_undo_ccm;\n\nout:\n\treturn err;\n\nout_undo_ccm:\n\tcrypto_unregister_template(&crypto_ccm_tmpl);\nout_undo_base:\n\tcrypto_unregister_template(&crypto_ccm_base_tmpl);\n\tgoto out;\n}\n\nstatic void __exit crypto_ccm_module_exit(void)\n{\n\tcrypto_unregister_template(&crypto_rfc4309_tmpl);\n\tcrypto_unregister_template(&crypto_ccm_tmpl);\n\tcrypto_unregister_template(&crypto_ccm_base_tmpl);\n}\n\nmodule_init(crypto_ccm_module_init);\nmodule_exit(crypto_ccm_module_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Counter with CBC MAC\");\nMODULE_ALIAS_CRYPTO(\"ccm_base\");\nMODULE_ALIAS_CRYPTO(\"rfc4309\");\n", "/* GPL HEADER START\n *\n * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License version 2 only,\n * as published by the Free Software Foundation.\n *\n * This program is distributed in the hope that it will be useful, but\n * WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * General Public License version 2 for more details (a copy is included\n * in the LICENSE file that accompanied this code).\n *\n * You should have received a copy of the GNU General Public License\n * version 2 along with this program; If not, see http://www.gnu.org/licenses\n *\n * Please  visit http://www.xyratex.com/contact if you need additional\n * information or have any questions.\n *\n * GPL HEADER END\n */\n\n/*\n * Copyright 2012 Xyratex Technology Limited\n */\n\n/*\n * This is crypto api shash wrappers to crc32_le.\n */\n\n#include <linux/crc32.h>\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\n#define CHKSUM_BLOCK_SIZE\t1\n#define CHKSUM_DIGEST_SIZE\t4\n\nstatic u32 __crc32_le(u32 crc, unsigned char const *p, size_t len)\n{\n\treturn crc32_le(crc, p, len);\n}\n\n/** No default init with ~0 */\nstatic int crc32_cra_init(struct crypto_tfm *tfm)\n{\n\tu32 *key = crypto_tfm_ctx(tfm);\n\n\t*key = 0;\n\n\treturn 0;\n}\n\n\n/*\n * Setting the seed allows arbitrary accumulators and flexible XOR policy\n * If your algorithm starts with ~0, then XOR with ~0 before you set\n * the seed.\n */\nstatic int crc32_setkey(struct crypto_shash *hash, const u8 *key,\n\t\t\tunsigned int keylen)\n{\n\tu32 *mctx = crypto_shash_ctx(hash);\n\n\tif (keylen != sizeof(u32)) {\n\t\tcrypto_shash_set_flags(hash, CRYPTO_TFM_RES_BAD_KEY_LEN);\n\t\treturn -EINVAL;\n\t}\n\t*mctx = le32_to_cpup((__le32 *)key);\n\treturn 0;\n}\n\nstatic int crc32_init(struct shash_desc *desc)\n{\n\tu32 *mctx = crypto_shash_ctx(desc->tfm);\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t*crcp = *mctx;\n\n\treturn 0;\n}\n\nstatic int crc32_update(struct shash_desc *desc, const u8 *data,\n\t\t\tunsigned int len)\n{\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t*crcp = __crc32_le(*crcp, data, len);\n\treturn 0;\n}\n\n/* No final XOR 0xFFFFFFFF, like crc32_le */\nstatic int __crc32_finup(u32 *crcp, const u8 *data, unsigned int len,\n\t\t\t u8 *out)\n{\n\t*(__le32 *)out = cpu_to_le32(__crc32_le(*crcp, data, len));\n\treturn 0;\n}\n\nstatic int crc32_finup(struct shash_desc *desc, const u8 *data,\n\t\t       unsigned int len, u8 *out)\n{\n\treturn __crc32_finup(shash_desc_ctx(desc), data, len, out);\n}\n\nstatic int crc32_final(struct shash_desc *desc, u8 *out)\n{\n\tu32 *crcp = shash_desc_ctx(desc);\n\n\t*(__le32 *)out = cpu_to_le32p(crcp);\n\treturn 0;\n}\n\nstatic int crc32_digest(struct shash_desc *desc, const u8 *data,\n\t\t\tunsigned int len, u8 *out)\n{\n\treturn __crc32_finup(crypto_shash_ctx(desc->tfm), data, len,\n\t\t\t     out);\n}\nstatic struct shash_alg alg = {\n\t.setkey\t\t= crc32_setkey,\n\t.init\t\t= crc32_init,\n\t.update\t\t= crc32_update,\n\t.final\t\t= crc32_final,\n\t.finup\t\t= crc32_finup,\n\t.digest\t\t= crc32_digest,\n\t.descsize\t= sizeof(u32),\n\t.digestsize\t= CHKSUM_DIGEST_SIZE,\n\t.base\t\t= {\n\t\t.cra_name\t\t= \"crc32\",\n\t\t.cra_driver_name\t= \"crc32-table\",\n\t\t.cra_priority\t\t= 100,\n\t\t.cra_blocksize\t\t= CHKSUM_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t= sizeof(u32),\n\t\t.cra_module\t\t= THIS_MODULE,\n\t\t.cra_init\t\t= crc32_cra_init,\n\t}\n};\n\nstatic int __init crc32_mod_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit crc32_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(crc32_mod_init);\nmodule_exit(crc32_mod_fini);\n\nMODULE_AUTHOR(\"Alexander Boyko <alexander_boyko@xyratex.com>\");\nMODULE_DESCRIPTION(\"CRC32 calculations wrapper for lib/crc32\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_CRYPTO(\"crc32\");\n", "/*\n * Cryptographic API.\n *\n * CRC32C chksum\n *\n *@Article{castagnoli-crc,\n * author =       { Guy Castagnoli and Stefan Braeuer and Martin Herrman},\n * title =        {{Optimization of Cyclic Redundancy-Check Codes with 24\n *                 and 32 Parity Bits}},\n * journal =      IEEE Transactions on Communication,\n * year =         {1993},\n * volume =       {41},\n * number =       {6},\n * pages =        {},\n * month =        {June},\n *}\n * Used by the iSCSI driver, possibly others, and derived from the\n * the iscsi-crc.c module of the linux-iscsi driver at\n * http://linux-iscsi.sourceforge.net.\n *\n * Following the example of lib/crc32, this function is intended to be\n * flexible and useful for all users.  Modules that currently have their\n * own crc32c, but hopefully may be able to use this one are:\n *  net/sctp (please add all your doco to here if you change to\n *            use this one!)\n *  <endoflist>\n *\n * Copyright (c) 2004 Cisco Systems, Inc.\n * Copyright (c) 2008 Herbert Xu <herbert@gondor.apana.org.au>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n#include <linux/crc32.h>\n\n#define CHKSUM_BLOCK_SIZE\t1\n#define CHKSUM_DIGEST_SIZE\t4\n\nstruct chksum_ctx {\n\tu32 key;\n};\n\nstruct chksum_desc_ctx {\n\tu32 crc;\n};\n\n/*\n * Steps through buffer one byte at at time, calculates reflected\n * crc using table.\n */\n\nstatic int chksum_init(struct shash_desc *desc)\n{\n\tstruct chksum_ctx *mctx = crypto_shash_ctx(desc->tfm);\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\tctx->crc = mctx->key;\n\n\treturn 0;\n}\n\n/*\n * Setting the seed allows arbitrary accumulators and flexible XOR policy\n * If your algorithm starts with ~0, then XOR with ~0 before you set\n * the seed.\n */\nstatic int chksum_setkey(struct crypto_shash *tfm, const u8 *key,\n\t\t\t unsigned int keylen)\n{\n\tstruct chksum_ctx *mctx = crypto_shash_ctx(tfm);\n\n\tif (keylen != sizeof(mctx->key)) {\n\t\tcrypto_shash_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);\n\t\treturn -EINVAL;\n\t}\n\tmctx->key = le32_to_cpu(*(__le32 *)key);\n\treturn 0;\n}\n\nstatic int chksum_update(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int length)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\tctx->crc = __crc32c_le(ctx->crc, data, length);\n\treturn 0;\n}\n\nstatic int chksum_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\t*(__le32 *)out = ~cpu_to_le32p(&ctx->crc);\n\treturn 0;\n}\n\nstatic int __chksum_finup(u32 *crcp, const u8 *data, unsigned int len, u8 *out)\n{\n\t*(__le32 *)out = ~cpu_to_le32(__crc32c_le(*crcp, data, len));\n\treturn 0;\n}\n\nstatic int chksum_finup(struct shash_desc *desc, const u8 *data,\n\t\t\tunsigned int len, u8 *out)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\treturn __chksum_finup(&ctx->crc, data, len, out);\n}\n\nstatic int chksum_digest(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int length, u8 *out)\n{\n\tstruct chksum_ctx *mctx = crypto_shash_ctx(desc->tfm);\n\n\treturn __chksum_finup(&mctx->key, data, length, out);\n}\n\nstatic int crc32c_cra_init(struct crypto_tfm *tfm)\n{\n\tstruct chksum_ctx *mctx = crypto_tfm_ctx(tfm);\n\n\tmctx->key = ~0;\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t\t=\tCHKSUM_DIGEST_SIZE,\n\t.setkey\t\t\t=\tchksum_setkey,\n\t.init\t\t=\tchksum_init,\n\t.update\t\t=\tchksum_update,\n\t.final\t\t=\tchksum_final,\n\t.finup\t\t=\tchksum_finup,\n\t.digest\t\t=\tchksum_digest,\n\t.descsize\t\t=\tsizeof(struct chksum_desc_ctx),\n\t.base\t\t\t=\t{\n\t\t.cra_name\t\t=\t\"crc32c\",\n\t\t.cra_driver_name\t=\t\"crc32c-generic\",\n\t\t.cra_priority\t\t=\t100,\n\t\t.cra_blocksize\t\t=\tCHKSUM_BLOCK_SIZE,\n\t\t.cra_alignmask\t\t=\t3,\n\t\t.cra_ctxsize\t\t=\tsizeof(struct chksum_ctx),\n\t\t.cra_module\t\t=\tTHIS_MODULE,\n\t\t.cra_init\t\t=\tcrc32c_cra_init,\n\t}\n};\n\nstatic int __init crc32c_mod_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit crc32c_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(crc32c_mod_init);\nmodule_exit(crc32c_mod_fini);\n\nMODULE_AUTHOR(\"Clay Haapala <chaapala@cisco.com>\");\nMODULE_DESCRIPTION(\"CRC32c (Castagnoli) calculations wrapper for lib/crc32c\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_CRYPTO(\"crc32c\");\nMODULE_SOFTDEP(\"pre: crc32c\");\n", "/*\n * Cryptographic API.\n *\n * T10 Data Integrity Field CRC16 Crypto Transform\n *\n * Copyright (c) 2007 Oracle Corporation.  All rights reserved.\n * Written by Martin K. Petersen <martin.petersen@oracle.com>\n * Copyright (C) 2013 Intel Corporation\n * Author: Tim Chen <tim.c.chen@linux.intel.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS\n * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n * SOFTWARE.\n *\n */\n\n#include <linux/module.h>\n#include <linux/crc-t10dif.h>\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n\nstruct chksum_desc_ctx {\n\t__u16 crc;\n};\n\n/*\n * Steps through buffer one byte at at time, calculates reflected\n * crc using table.\n */\n\nstatic int chksum_init(struct shash_desc *desc)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\tctx->crc = 0;\n\n\treturn 0;\n}\n\nstatic int chksum_update(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int length)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\tctx->crc = crc_t10dif_generic(ctx->crc, data, length);\n\treturn 0;\n}\n\nstatic int chksum_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\t*(__u16 *)out = ctx->crc;\n\treturn 0;\n}\n\nstatic int __chksum_finup(__u16 *crcp, const u8 *data, unsigned int len,\n\t\t\tu8 *out)\n{\n\t*(__u16 *)out = crc_t10dif_generic(*crcp, data, len);\n\treturn 0;\n}\n\nstatic int chksum_finup(struct shash_desc *desc, const u8 *data,\n\t\t\tunsigned int len, u8 *out)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\treturn __chksum_finup(&ctx->crc, data, len, out);\n}\n\nstatic int chksum_digest(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int length, u8 *out)\n{\n\tstruct chksum_desc_ctx *ctx = shash_desc_ctx(desc);\n\n\treturn __chksum_finup(&ctx->crc, data, length, out);\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t\t=\tCRC_T10DIF_DIGEST_SIZE,\n\t.init\t\t=\tchksum_init,\n\t.update\t\t=\tchksum_update,\n\t.final\t\t=\tchksum_final,\n\t.finup\t\t=\tchksum_finup,\n\t.digest\t\t=\tchksum_digest,\n\t.descsize\t\t=\tsizeof(struct chksum_desc_ctx),\n\t.base\t\t\t=\t{\n\t\t.cra_name\t\t=\t\"crct10dif\",\n\t\t.cra_driver_name\t=\t\"crct10dif-generic\",\n\t\t.cra_priority\t\t=\t100,\n\t\t.cra_blocksize\t\t=\tCRC_T10DIF_BLOCK_SIZE,\n\t\t.cra_module\t\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init crct10dif_mod_init(void)\n{\n\tint ret;\n\n\tret = crypto_register_shash(&alg);\n\treturn ret;\n}\n\nstatic void __exit crct10dif_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(crct10dif_mod_init);\nmodule_exit(crct10dif_mod_fini);\n\nMODULE_AUTHOR(\"Tim Chen <tim.c.chen@linux.intel.com>\");\nMODULE_DESCRIPTION(\"T10 DIF CRC calculation.\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_CRYPTO(\"crct10dif\");\n", "/*\n * Cryptographic API.\n *\n * Null algorithms, aka Much Ado About Nothing.\n *\n * These are needed for IPsec, and may be useful in general for\n * testing & debugging.\n *\n * The null cipher is compliant with RFC2410.\n *\n * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n\n#include <crypto/null.h>\n#include <crypto/internal/hash.h>\n#include <crypto/internal/skcipher.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n\nstatic int null_compress(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t unsigned int slen, u8 *dst, unsigned int *dlen)\n{\n\tif (slen > *dlen)\n\t\treturn -EINVAL;\n\tmemcpy(dst, src, slen);\n\t*dlen = slen;\n\treturn 0;\n}\n\nstatic int null_init(struct shash_desc *desc)\n{\n\treturn 0;\n}\n\nstatic int null_update(struct shash_desc *desc, const u8 *data,\n\t\t       unsigned int len)\n{\n\treturn 0;\n}\n\nstatic int null_final(struct shash_desc *desc, u8 *out)\n{\n\treturn 0;\n}\n\nstatic int null_digest(struct shash_desc *desc, const u8 *data,\n\t\t       unsigned int len, u8 *out)\n{\n\treturn 0;\n}\n\nstatic int null_hash_setkey(struct crypto_shash *tfm, const u8 *key,\n\t\t\t    unsigned int keylen)\n{ return 0; }\n\nstatic int null_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t       unsigned int keylen)\n{ return 0; }\n\nstatic void null_crypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tmemcpy(dst, src, NULL_BLOCK_SIZE);\n}\n\nstatic int skcipher_null_crypt(struct blkcipher_desc *desc,\n\t\t\t       struct scatterlist *dst,\n\t\t\t       struct scatterlist *src, unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\twhile (walk.nbytes) {\n\t\tif (walk.src.virt.addr != walk.dst.virt.addr)\n\t\t\tmemcpy(walk.dst.virt.addr, walk.src.virt.addr,\n\t\t\t       walk.nbytes);\n\t\terr = blkcipher_walk_done(desc, &walk, 0);\n\t}\n\n\treturn err;\n}\n\nstatic struct shash_alg digest_null = {\n\t.digestsize\t\t=\tNULL_DIGEST_SIZE,\n\t.setkey   \t\t=\tnull_hash_setkey,\n\t.init   \t\t=\tnull_init,\n\t.update \t\t=\tnull_update,\n\t.finup \t\t\t=\tnull_digest,\n\t.digest \t\t=\tnull_digest,\n\t.final  \t\t=\tnull_final,\n\t.base\t\t\t=\t{\n\t\t.cra_name\t\t=\t\"digest_null\",\n\t\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t\t=\tNULL_BLOCK_SIZE,\n\t\t.cra_module\t\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic struct crypto_alg null_algs[3] = { {\n\t.cra_name\t\t=\t\"cipher_null\",\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tNULL_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\t0,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\tNULL_KEY_SIZE,\n\t.cia_max_keysize\t=\tNULL_KEY_SIZE,\n\t.cia_setkey\t\t= \tnull_setkey,\n\t.cia_encrypt\t\t=\tnull_crypt,\n\t.cia_decrypt\t\t=\tnull_crypt } }\n}, {\n\t.cra_name\t\t=\t\"ecb(cipher_null)\",\n\t.cra_driver_name\t=\t\"ecb-cipher_null\",\n\t.cra_priority\t\t=\t100,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t=\tNULL_BLOCK_SIZE,\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_ctxsize\t\t=\t0,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{ .blkcipher = {\n\t.min_keysize\t\t=\tNULL_KEY_SIZE,\n\t.max_keysize\t\t=\tNULL_KEY_SIZE,\n\t.ivsize\t\t\t=\tNULL_IV_SIZE,\n\t.setkey\t\t\t= \tnull_setkey,\n\t.encrypt\t\t=\tskcipher_null_crypt,\n\t.decrypt\t\t=\tskcipher_null_crypt } }\n}, {\n\t.cra_name\t\t=\t\"compress_null\",\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_COMPRESS,\n\t.cra_blocksize\t\t=\tNULL_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\t0,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{ .compress = {\n\t.coa_compress\t\t=\tnull_compress,\n\t.coa_decompress\t\t=\tnull_compress } }\n} };\n\nMODULE_ALIAS_CRYPTO(\"compress_null\");\nMODULE_ALIAS_CRYPTO(\"digest_null\");\nMODULE_ALIAS_CRYPTO(\"cipher_null\");\n\nstatic int __init crypto_null_mod_init(void)\n{\n\tint ret = 0;\n\n\tret = crypto_register_algs(null_algs, ARRAY_SIZE(null_algs));\n\tif (ret < 0)\n\t\tgoto out;\n\n\tret = crypto_register_shash(&digest_null);\n\tif (ret < 0)\n\t\tgoto out_unregister_algs;\n\n\treturn 0;\n\nout_unregister_algs:\n\tcrypto_unregister_algs(null_algs, ARRAY_SIZE(null_algs));\nout:\n\treturn ret;\n}\n\nstatic void __exit crypto_null_mod_fini(void)\n{\n\tcrypto_unregister_shash(&digest_null);\n\tcrypto_unregister_algs(null_algs, ARRAY_SIZE(null_algs));\n}\n\nmodule_init(crypto_null_mod_init);\nmodule_exit(crypto_null_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Null Cryptographic Algorithms\");\n", "/*\n * CTR: Counter mode\n *\n * (C) Copyright IBM Corp. 2007 - Joy Latten <latten@us.ibm.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#include <crypto/algapi.h>\n#include <crypto/ctr.h>\n#include <crypto/internal/skcipher.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/random.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n\nstruct crypto_ctr_ctx {\n\tstruct crypto_cipher *child;\n};\n\nstruct crypto_rfc3686_ctx {\n\tstruct crypto_ablkcipher *child;\n\tu8 nonce[CTR_RFC3686_NONCE_SIZE];\n};\n\nstruct crypto_rfc3686_req_ctx {\n\tu8 iv[CTR_RFC3686_BLOCK_SIZE];\n\tstruct ablkcipher_request subreq CRYPTO_MINALIGN_ATTR;\n};\n\nstatic int crypto_ctr_setkey(struct crypto_tfm *parent, const u8 *key,\n\t\t\t     unsigned int keylen)\n{\n\tstruct crypto_ctr_ctx *ctx = crypto_tfm_ctx(parent);\n\tstruct crypto_cipher *child = ctx->child;\n\tint err;\n\n\tcrypto_cipher_clear_flags(child, CRYPTO_TFM_REQ_MASK);\n\tcrypto_cipher_set_flags(child, crypto_tfm_get_flags(parent) &\n\t\t\t\tCRYPTO_TFM_REQ_MASK);\n\terr = crypto_cipher_setkey(child, key, keylen);\n\tcrypto_tfm_set_flags(parent, crypto_cipher_get_flags(child) &\n\t\t\t     CRYPTO_TFM_RES_MASK);\n\n\treturn err;\n}\n\nstatic void crypto_ctr_crypt_final(struct blkcipher_walk *walk,\n\t\t\t\t   struct crypto_cipher *tfm)\n{\n\tunsigned int bsize = crypto_cipher_blocksize(tfm);\n\tunsigned long alignmask = crypto_cipher_alignmask(tfm);\n\tu8 *ctrblk = walk->iv;\n\tu8 tmp[bsize + alignmask];\n\tu8 *keystream = PTR_ALIGN(tmp + 0, alignmask + 1);\n\tu8 *src = walk->src.virt.addr;\n\tu8 *dst = walk->dst.virt.addr;\n\tunsigned int nbytes = walk->nbytes;\n\n\tcrypto_cipher_encrypt_one(tfm, keystream, ctrblk);\n\tcrypto_xor(keystream, src, nbytes);\n\tmemcpy(dst, keystream, nbytes);\n\n\tcrypto_inc(ctrblk, bsize);\n}\n\nstatic int crypto_ctr_crypt_segment(struct blkcipher_walk *walk,\n\t\t\t\t    struct crypto_cipher *tfm)\n{\n\tvoid (*fn)(struct crypto_tfm *, u8 *, const u8 *) =\n\t\t   crypto_cipher_alg(tfm)->cia_encrypt;\n\tunsigned int bsize = crypto_cipher_blocksize(tfm);\n\tu8 *ctrblk = walk->iv;\n\tu8 *src = walk->src.virt.addr;\n\tu8 *dst = walk->dst.virt.addr;\n\tunsigned int nbytes = walk->nbytes;\n\n\tdo {\n\t\t/* create keystream */\n\t\tfn(crypto_cipher_tfm(tfm), dst, ctrblk);\n\t\tcrypto_xor(dst, src, bsize);\n\n\t\t/* increment counter in counterblock */\n\t\tcrypto_inc(ctrblk, bsize);\n\n\t\tsrc += bsize;\n\t\tdst += bsize;\n\t} while ((nbytes -= bsize) >= bsize);\n\n\treturn nbytes;\n}\n\nstatic int crypto_ctr_crypt_inplace(struct blkcipher_walk *walk,\n\t\t\t\t    struct crypto_cipher *tfm)\n{\n\tvoid (*fn)(struct crypto_tfm *, u8 *, const u8 *) =\n\t\t   crypto_cipher_alg(tfm)->cia_encrypt;\n\tunsigned int bsize = crypto_cipher_blocksize(tfm);\n\tunsigned long alignmask = crypto_cipher_alignmask(tfm);\n\tunsigned int nbytes = walk->nbytes;\n\tu8 *ctrblk = walk->iv;\n\tu8 *src = walk->src.virt.addr;\n\tu8 tmp[bsize + alignmask];\n\tu8 *keystream = PTR_ALIGN(tmp + 0, alignmask + 1);\n\n\tdo {\n\t\t/* create keystream */\n\t\tfn(crypto_cipher_tfm(tfm), keystream, ctrblk);\n\t\tcrypto_xor(src, keystream, bsize);\n\n\t\t/* increment counter in counterblock */\n\t\tcrypto_inc(ctrblk, bsize);\n\n\t\tsrc += bsize;\n\t} while ((nbytes -= bsize) >= bsize);\n\n\treturn nbytes;\n}\n\nstatic int crypto_ctr_crypt(struct blkcipher_desc *desc,\n\t\t\t      struct scatterlist *dst, struct scatterlist *src,\n\t\t\t      unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\tstruct crypto_blkcipher *tfm = desc->tfm;\n\tstruct crypto_ctr_ctx *ctx = crypto_blkcipher_ctx(tfm);\n\tstruct crypto_cipher *child = ctx->child;\n\tunsigned int bsize = crypto_cipher_blocksize(child);\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt_block(desc, &walk, bsize);\n\n\twhile (walk.nbytes >= bsize) {\n\t\tif (walk.src.virt.addr == walk.dst.virt.addr)\n\t\t\tnbytes = crypto_ctr_crypt_inplace(&walk, child);\n\t\telse\n\t\t\tnbytes = crypto_ctr_crypt_segment(&walk, child);\n\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\n\tif (walk.nbytes) {\n\t\tcrypto_ctr_crypt_final(&walk, child);\n\t\terr = blkcipher_walk_done(desc, &walk, 0);\n\t}\n\n\treturn err;\n}\n\nstatic int crypto_ctr_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_instance *inst = (void *)tfm->__crt_alg;\n\tstruct crypto_spawn *spawn = crypto_instance_ctx(inst);\n\tstruct crypto_ctr_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_cipher *cipher;\n\n\tcipher = crypto_spawn_cipher(spawn);\n\tif (IS_ERR(cipher))\n\t\treturn PTR_ERR(cipher);\n\n\tctx->child = cipher;\n\n\treturn 0;\n}\n\nstatic void crypto_ctr_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_ctr_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_cipher(ctx->child);\n}\n\nstatic struct crypto_instance *crypto_ctr_alloc(struct rtattr **tb)\n{\n\tstruct crypto_instance *inst;\n\tstruct crypto_alg *alg;\n\tint err;\n\n\terr = crypto_check_attr_type(tb, CRYPTO_ALG_TYPE_BLKCIPHER);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\talg = crypto_attr_alg(tb[1], CRYPTO_ALG_TYPE_CIPHER,\n\t\t\t\t  CRYPTO_ALG_TYPE_MASK);\n\tif (IS_ERR(alg))\n\t\treturn ERR_CAST(alg);\n\n\t/* Block size must be >= 4 bytes. */\n\terr = -EINVAL;\n\tif (alg->cra_blocksize < 4)\n\t\tgoto out_put_alg;\n\n\t/* If this is false we'd fail the alignment of crypto_inc. */\n\tif (alg->cra_blocksize % 4)\n\t\tgoto out_put_alg;\n\n\tinst = crypto_alloc_instance(\"ctr\", alg);\n\tif (IS_ERR(inst))\n\t\tgoto out;\n\n\tinst->alg.cra_flags = CRYPTO_ALG_TYPE_BLKCIPHER;\n\tinst->alg.cra_priority = alg->cra_priority;\n\tinst->alg.cra_blocksize = 1;\n\tinst->alg.cra_alignmask = alg->cra_alignmask | (__alignof__(u32) - 1);\n\tinst->alg.cra_type = &crypto_blkcipher_type;\n\n\tinst->alg.cra_blkcipher.ivsize = alg->cra_blocksize;\n\tinst->alg.cra_blkcipher.min_keysize = alg->cra_cipher.cia_min_keysize;\n\tinst->alg.cra_blkcipher.max_keysize = alg->cra_cipher.cia_max_keysize;\n\n\tinst->alg.cra_ctxsize = sizeof(struct crypto_ctr_ctx);\n\n\tinst->alg.cra_init = crypto_ctr_init_tfm;\n\tinst->alg.cra_exit = crypto_ctr_exit_tfm;\n\n\tinst->alg.cra_blkcipher.setkey = crypto_ctr_setkey;\n\tinst->alg.cra_blkcipher.encrypt = crypto_ctr_crypt;\n\tinst->alg.cra_blkcipher.decrypt = crypto_ctr_crypt;\n\n\tinst->alg.cra_blkcipher.geniv = \"chainiv\";\n\nout:\n\tcrypto_mod_put(alg);\n\treturn inst;\n\nout_put_alg:\n\tinst = ERR_PTR(err);\n\tgoto out;\n}\n\nstatic void crypto_ctr_free(struct crypto_instance *inst)\n{\n\tcrypto_drop_spawn(crypto_instance_ctx(inst));\n\tkfree(inst);\n}\n\nstatic struct crypto_template crypto_ctr_tmpl = {\n\t.name = \"ctr\",\n\t.alloc = crypto_ctr_alloc,\n\t.free = crypto_ctr_free,\n\t.module = THIS_MODULE,\n};\n\nstatic int crypto_rfc3686_setkey(struct crypto_ablkcipher *parent,\n\t\t\t\t const u8 *key, unsigned int keylen)\n{\n\tstruct crypto_rfc3686_ctx *ctx = crypto_ablkcipher_ctx(parent);\n\tstruct crypto_ablkcipher *child = ctx->child;\n\tint err;\n\n\t/* the nonce is stored in bytes at end of key */\n\tif (keylen < CTR_RFC3686_NONCE_SIZE)\n\t\treturn -EINVAL;\n\n\tmemcpy(ctx->nonce, key + (keylen - CTR_RFC3686_NONCE_SIZE),\n\t       CTR_RFC3686_NONCE_SIZE);\n\n\tkeylen -= CTR_RFC3686_NONCE_SIZE;\n\n\tcrypto_ablkcipher_clear_flags(child, CRYPTO_TFM_REQ_MASK);\n\tcrypto_ablkcipher_set_flags(child, crypto_ablkcipher_get_flags(parent) &\n\t\t\t\t    CRYPTO_TFM_REQ_MASK);\n\terr = crypto_ablkcipher_setkey(child, key, keylen);\n\tcrypto_ablkcipher_set_flags(parent, crypto_ablkcipher_get_flags(child) &\n\t\t\t\t    CRYPTO_TFM_RES_MASK);\n\n\treturn err;\n}\n\nstatic int crypto_rfc3686_crypt(struct ablkcipher_request *req)\n{\n\tstruct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);\n\tstruct crypto_rfc3686_ctx *ctx = crypto_ablkcipher_ctx(tfm);\n\tstruct crypto_ablkcipher *child = ctx->child;\n\tunsigned long align = crypto_ablkcipher_alignmask(tfm);\n\tstruct crypto_rfc3686_req_ctx *rctx =\n\t\t(void *)PTR_ALIGN((u8 *)ablkcipher_request_ctx(req), align + 1);\n\tstruct ablkcipher_request *subreq = &rctx->subreq;\n\tu8 *iv = rctx->iv;\n\n\t/* set up counter block */\n\tmemcpy(iv, ctx->nonce, CTR_RFC3686_NONCE_SIZE);\n\tmemcpy(iv + CTR_RFC3686_NONCE_SIZE, req->info, CTR_RFC3686_IV_SIZE);\n\n\t/* initialize counter portion of counter block */\n\t*(__be32 *)(iv + CTR_RFC3686_NONCE_SIZE + CTR_RFC3686_IV_SIZE) =\n\t\tcpu_to_be32(1);\n\n\tablkcipher_request_set_tfm(subreq, child);\n\tablkcipher_request_set_callback(subreq, req->base.flags,\n\t\t\t\t\treq->base.complete, req->base.data);\n\tablkcipher_request_set_crypt(subreq, req->src, req->dst, req->nbytes,\n\t\t\t\t     iv);\n\n\treturn crypto_ablkcipher_encrypt(subreq);\n}\n\nstatic int crypto_rfc3686_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_instance *inst = (void *)tfm->__crt_alg;\n\tstruct crypto_skcipher_spawn *spawn = crypto_instance_ctx(inst);\n\tstruct crypto_rfc3686_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_ablkcipher *cipher;\n\tunsigned long align;\n\n\tcipher = crypto_spawn_skcipher(spawn);\n\tif (IS_ERR(cipher))\n\t\treturn PTR_ERR(cipher);\n\n\tctx->child = cipher;\n\n\talign = crypto_tfm_alg_alignmask(tfm);\n\talign &= ~(crypto_tfm_ctx_alignment() - 1);\n\ttfm->crt_ablkcipher.reqsize = align +\n\t\tsizeof(struct crypto_rfc3686_req_ctx) +\n\t\tcrypto_ablkcipher_reqsize(cipher);\n\n\treturn 0;\n}\n\nstatic void crypto_rfc3686_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_rfc3686_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_ablkcipher(ctx->child);\n}\n\nstatic struct crypto_instance *crypto_rfc3686_alloc(struct rtattr **tb)\n{\n\tstruct crypto_attr_type *algt;\n\tstruct crypto_instance *inst;\n\tstruct crypto_alg *alg;\n\tstruct crypto_skcipher_spawn *spawn;\n\tconst char *cipher_name;\n\tint err;\n\n\talgt = crypto_get_attr_type(tb);\n\tif (IS_ERR(algt))\n\t\treturn ERR_CAST(algt);\n\n\tif ((algt->type ^ CRYPTO_ALG_TYPE_BLKCIPHER) & algt->mask)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tcipher_name = crypto_attr_alg_name(tb[1]);\n\tif (IS_ERR(cipher_name))\n\t\treturn ERR_CAST(cipher_name);\n\n\tinst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);\n\tif (!inst)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tspawn = crypto_instance_ctx(inst);\n\n\tcrypto_set_skcipher_spawn(spawn, inst);\n\terr = crypto_grab_skcipher(spawn, cipher_name, 0,\n\t\t\t\t   crypto_requires_sync(algt->type,\n\t\t\t\t\t\t\talgt->mask));\n\tif (err)\n\t\tgoto err_free_inst;\n\n\talg = crypto_skcipher_spawn_alg(spawn);\n\n\t/* We only support 16-byte blocks. */\n\terr = -EINVAL;\n\tif (alg->cra_ablkcipher.ivsize != CTR_RFC3686_BLOCK_SIZE)\n\t\tgoto err_drop_spawn;\n\n\t/* Not a stream cipher? */\n\tif (alg->cra_blocksize != 1)\n\t\tgoto err_drop_spawn;\n\n\terr = -ENAMETOOLONG;\n\tif (snprintf(inst->alg.cra_name, CRYPTO_MAX_ALG_NAME, \"rfc3686(%s)\",\n\t\t     alg->cra_name) >= CRYPTO_MAX_ALG_NAME)\n\t\tgoto err_drop_spawn;\n\tif (snprintf(inst->alg.cra_driver_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"rfc3686(%s)\", alg->cra_driver_name) >=\n\t\t\tCRYPTO_MAX_ALG_NAME)\n\t\tgoto err_drop_spawn;\n\n\tinst->alg.cra_priority = alg->cra_priority;\n\tinst->alg.cra_blocksize = 1;\n\tinst->alg.cra_alignmask = alg->cra_alignmask;\n\n\tinst->alg.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\n\t\t\t      (alg->cra_flags & CRYPTO_ALG_ASYNC);\n\tinst->alg.cra_type = &crypto_ablkcipher_type;\n\n\tinst->alg.cra_ablkcipher.ivsize = CTR_RFC3686_IV_SIZE;\n\tinst->alg.cra_ablkcipher.min_keysize =\n\t\talg->cra_ablkcipher.min_keysize + CTR_RFC3686_NONCE_SIZE;\n\tinst->alg.cra_ablkcipher.max_keysize =\n\t\talg->cra_ablkcipher.max_keysize + CTR_RFC3686_NONCE_SIZE;\n\n\tinst->alg.cra_ablkcipher.geniv = \"seqiv\";\n\n\tinst->alg.cra_ablkcipher.setkey = crypto_rfc3686_setkey;\n\tinst->alg.cra_ablkcipher.encrypt = crypto_rfc3686_crypt;\n\tinst->alg.cra_ablkcipher.decrypt = crypto_rfc3686_crypt;\n\n\tinst->alg.cra_ctxsize = sizeof(struct crypto_rfc3686_ctx);\n\n\tinst->alg.cra_init = crypto_rfc3686_init_tfm;\n\tinst->alg.cra_exit = crypto_rfc3686_exit_tfm;\n\n\treturn inst;\n\nerr_drop_spawn:\n\tcrypto_drop_skcipher(spawn);\nerr_free_inst:\n\tkfree(inst);\n\treturn ERR_PTR(err);\n}\n\nstatic void crypto_rfc3686_free(struct crypto_instance *inst)\n{\n\tstruct crypto_skcipher_spawn *spawn = crypto_instance_ctx(inst);\n\n\tcrypto_drop_skcipher(spawn);\n\tkfree(inst);\n}\n\nstatic struct crypto_template crypto_rfc3686_tmpl = {\n\t.name = \"rfc3686\",\n\t.alloc = crypto_rfc3686_alloc,\n\t.free = crypto_rfc3686_free,\n\t.module = THIS_MODULE,\n};\n\nstatic int __init crypto_ctr_module_init(void)\n{\n\tint err;\n\n\terr = crypto_register_template(&crypto_ctr_tmpl);\n\tif (err)\n\t\tgoto out;\n\n\terr = crypto_register_template(&crypto_rfc3686_tmpl);\n\tif (err)\n\t\tgoto out_drop_ctr;\n\nout:\n\treturn err;\n\nout_drop_ctr:\n\tcrypto_unregister_template(&crypto_ctr_tmpl);\n\tgoto out;\n}\n\nstatic void __exit crypto_ctr_module_exit(void)\n{\n\tcrypto_unregister_template(&crypto_rfc3686_tmpl);\n\tcrypto_unregister_template(&crypto_ctr_tmpl);\n}\n\nmodule_init(crypto_ctr_module_init);\nmodule_exit(crypto_ctr_module_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"CTR Counter block mode\");\nMODULE_ALIAS_CRYPTO(\"rfc3686\");\n", "/*\n * Cryptographic API.\n *\n * Deflate algorithm (RFC 1951), implemented here primarily for use\n * by IPCOMP (RFC 3173 & RFC 2394).\n *\n * Copyright (c) 2003 James Morris <jmorris@intercode.com.au>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n * FIXME: deflate transforms will require up to a total of about 436k of kernel\n * memory on i386 (390k for compression, the rest for decompression), as the\n * current zlib kernel code uses a worst case pre-allocation system by default.\n * This needs to be fixed so that the amount of memory required is properly\n * related to the  winbits and memlevel parameters.\n *\n * The default winbits of 11 should suit most packets, and it may be something\n * to configure on a per-tfm basis in the future.\n *\n * Currently, compression history is not maintained between tfm calls, as\n * it is not needed for IPCOMP and keeps the code simpler.  It can be\n * implemented if someone wants it.\n */\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/crypto.h>\n#include <linux/zlib.h>\n#include <linux/vmalloc.h>\n#include <linux/interrupt.h>\n#include <linux/mm.h>\n#include <linux/net.h>\n\n#define DEFLATE_DEF_LEVEL\t\tZ_DEFAULT_COMPRESSION\n#define DEFLATE_DEF_WINBITS\t\t11\n#define DEFLATE_DEF_MEMLEVEL\t\tMAX_MEM_LEVEL\n\nstruct deflate_ctx {\n\tstruct z_stream_s comp_stream;\n\tstruct z_stream_s decomp_stream;\n};\n\nstatic int deflate_comp_init(struct deflate_ctx *ctx)\n{\n\tint ret = 0;\n\tstruct z_stream_s *stream = &ctx->comp_stream;\n\n\tstream->workspace = vzalloc(zlib_deflate_workspacesize(\n\t\t\t\t-DEFLATE_DEF_WINBITS, DEFLATE_DEF_MEMLEVEL));\n\tif (!stream->workspace) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tret = zlib_deflateInit2(stream, DEFLATE_DEF_LEVEL, Z_DEFLATED,\n\t                        -DEFLATE_DEF_WINBITS, DEFLATE_DEF_MEMLEVEL,\n\t                        Z_DEFAULT_STRATEGY);\n\tif (ret != Z_OK) {\n\t\tret = -EINVAL;\n\t\tgoto out_free;\n\t}\nout:\n\treturn ret;\nout_free:\n\tvfree(stream->workspace);\n\tgoto out;\n}\n\nstatic int deflate_decomp_init(struct deflate_ctx *ctx)\n{\n\tint ret = 0;\n\tstruct z_stream_s *stream = &ctx->decomp_stream;\n\n\tstream->workspace = vzalloc(zlib_inflate_workspacesize());\n\tif (!stream->workspace) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tret = zlib_inflateInit2(stream, -DEFLATE_DEF_WINBITS);\n\tif (ret != Z_OK) {\n\t\tret = -EINVAL;\n\t\tgoto out_free;\n\t}\nout:\n\treturn ret;\nout_free:\n\tvfree(stream->workspace);\n\tgoto out;\n}\n\nstatic void deflate_comp_exit(struct deflate_ctx *ctx)\n{\n\tzlib_deflateEnd(&ctx->comp_stream);\n\tvfree(ctx->comp_stream.workspace);\n}\n\nstatic void deflate_decomp_exit(struct deflate_ctx *ctx)\n{\n\tzlib_inflateEnd(&ctx->decomp_stream);\n\tvfree(ctx->decomp_stream.workspace);\n}\n\nstatic int deflate_init(struct crypto_tfm *tfm)\n{\n\tstruct deflate_ctx *ctx = crypto_tfm_ctx(tfm);\n\tint ret;\n\n\tret = deflate_comp_init(ctx);\n\tif (ret)\n\t\tgoto out;\n\tret = deflate_decomp_init(ctx);\n\tif (ret)\n\t\tdeflate_comp_exit(ctx);\nout:\n\treturn ret;\n}\n\nstatic void deflate_exit(struct crypto_tfm *tfm)\n{\n\tstruct deflate_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tdeflate_comp_exit(ctx);\n\tdeflate_decomp_exit(ctx);\n}\n\nstatic int deflate_compress(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t    unsigned int slen, u8 *dst, unsigned int *dlen)\n{\n\tint ret = 0;\n\tstruct deflate_ctx *dctx = crypto_tfm_ctx(tfm);\n\tstruct z_stream_s *stream = &dctx->comp_stream;\n\n\tret = zlib_deflateReset(stream);\n\tif (ret != Z_OK) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tstream->next_in = (u8 *)src;\n\tstream->avail_in = slen;\n\tstream->next_out = (u8 *)dst;\n\tstream->avail_out = *dlen;\n\n\tret = zlib_deflate(stream, Z_FINISH);\n\tif (ret != Z_STREAM_END) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\tret = 0;\n\t*dlen = stream->total_out;\nout:\n\treturn ret;\n}\n\nstatic int deflate_decompress(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t      unsigned int slen, u8 *dst, unsigned int *dlen)\n{\n\n\tint ret = 0;\n\tstruct deflate_ctx *dctx = crypto_tfm_ctx(tfm);\n\tstruct z_stream_s *stream = &dctx->decomp_stream;\n\n\tret = zlib_inflateReset(stream);\n\tif (ret != Z_OK) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tstream->next_in = (u8 *)src;\n\tstream->avail_in = slen;\n\tstream->next_out = (u8 *)dst;\n\tstream->avail_out = *dlen;\n\n\tret = zlib_inflate(stream, Z_SYNC_FLUSH);\n\t/*\n\t * Work around a bug in zlib, which sometimes wants to taste an extra\n\t * byte when being used in the (undocumented) raw deflate mode.\n\t * (From USAGI).\n\t */\n\tif (ret == Z_OK && !stream->avail_in && stream->avail_out) {\n\t\tu8 zerostuff = 0;\n\t\tstream->next_in = &zerostuff;\n\t\tstream->avail_in = 1;\n\t\tret = zlib_inflate(stream, Z_FINISH);\n\t}\n\tif (ret != Z_STREAM_END) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\tret = 0;\n\t*dlen = stream->total_out;\nout:\n\treturn ret;\n}\n\nstatic struct crypto_alg alg = {\n\t.cra_name\t\t= \"deflate\",\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_COMPRESS,\n\t.cra_ctxsize\t\t= sizeof(struct deflate_ctx),\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= deflate_init,\n\t.cra_exit\t\t= deflate_exit,\n\t.cra_u\t\t\t= { .compress = {\n\t.coa_compress \t\t= deflate_compress,\n\t.coa_decompress  \t= deflate_decompress } }\n};\n\nstatic int __init deflate_mod_init(void)\n{\n\treturn crypto_register_alg(&alg);\n}\n\nstatic void __exit deflate_mod_fini(void)\n{\n\tcrypto_unregister_alg(&alg);\n}\n\nmodule_init(deflate_mod_init);\nmodule_exit(deflate_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Deflate Compression Algorithm for IPCOMP\");\nMODULE_AUTHOR(\"James Morris <jmorris@intercode.com.au>\");\nMODULE_ALIAS_CRYPTO(\"deflate\");\n", "/*\n * Cryptographic API.\n *\n * DES & Triple DES EDE Cipher Algorithms.\n *\n * Copyright (c) 2005 Dag Arne Osvik <da@osvik.no>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n\n#include <asm/byteorder.h>\n#include <linux/bitops.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/crypto.h>\n#include <linux/types.h>\n\n#include <crypto/des.h>\n\n#define ROL(x, r) ((x) = rol32((x), (r)))\n#define ROR(x, r) ((x) = ror32((x), (r)))\n\nstruct des_ctx {\n\tu32 expkey[DES_EXPKEY_WORDS];\n};\n\nstruct des3_ede_ctx {\n\tu32 expkey[DES3_EDE_EXPKEY_WORDS];\n};\n\n/* Lookup tables for key expansion */\n\nstatic const u8 pc1[256] = {\n\t0x00, 0x00, 0x40, 0x04, 0x10, 0x10, 0x50, 0x14,\n\t0x04, 0x40, 0x44, 0x44, 0x14, 0x50, 0x54, 0x54,\n\t0x02, 0x02, 0x42, 0x06, 0x12, 0x12, 0x52, 0x16,\n\t0x06, 0x42, 0x46, 0x46, 0x16, 0x52, 0x56, 0x56,\n\t0x80, 0x08, 0xc0, 0x0c, 0x90, 0x18, 0xd0, 0x1c,\n\t0x84, 0x48, 0xc4, 0x4c, 0x94, 0x58, 0xd4, 0x5c,\n\t0x82, 0x0a, 0xc2, 0x0e, 0x92, 0x1a, 0xd2, 0x1e,\n\t0x86, 0x4a, 0xc6, 0x4e, 0x96, 0x5a, 0xd6, 0x5e,\n\t0x20, 0x20, 0x60, 0x24, 0x30, 0x30, 0x70, 0x34,\n\t0x24, 0x60, 0x64, 0x64, 0x34, 0x70, 0x74, 0x74,\n\t0x22, 0x22, 0x62, 0x26, 0x32, 0x32, 0x72, 0x36,\n\t0x26, 0x62, 0x66, 0x66, 0x36, 0x72, 0x76, 0x76,\n\t0xa0, 0x28, 0xe0, 0x2c, 0xb0, 0x38, 0xf0, 0x3c,\n\t0xa4, 0x68, 0xe4, 0x6c, 0xb4, 0x78, 0xf4, 0x7c,\n\t0xa2, 0x2a, 0xe2, 0x2e, 0xb2, 0x3a, 0xf2, 0x3e,\n\t0xa6, 0x6a, 0xe6, 0x6e, 0xb6, 0x7a, 0xf6, 0x7e,\n\t0x08, 0x80, 0x48, 0x84, 0x18, 0x90, 0x58, 0x94,\n\t0x0c, 0xc0, 0x4c, 0xc4, 0x1c, 0xd0, 0x5c, 0xd4,\n\t0x0a, 0x82, 0x4a, 0x86, 0x1a, 0x92, 0x5a, 0x96,\n\t0x0e, 0xc2, 0x4e, 0xc6, 0x1e, 0xd2, 0x5e, 0xd6,\n\t0x88, 0x88, 0xc8, 0x8c, 0x98, 0x98, 0xd8, 0x9c,\n\t0x8c, 0xc8, 0xcc, 0xcc, 0x9c, 0xd8, 0xdc, 0xdc,\n\t0x8a, 0x8a, 0xca, 0x8e, 0x9a, 0x9a, 0xda, 0x9e,\n\t0x8e, 0xca, 0xce, 0xce, 0x9e, 0xda, 0xde, 0xde,\n\t0x28, 0xa0, 0x68, 0xa4, 0x38, 0xb0, 0x78, 0xb4,\n\t0x2c, 0xe0, 0x6c, 0xe4, 0x3c, 0xf0, 0x7c, 0xf4,\n\t0x2a, 0xa2, 0x6a, 0xa6, 0x3a, 0xb2, 0x7a, 0xb6,\n\t0x2e, 0xe2, 0x6e, 0xe6, 0x3e, 0xf2, 0x7e, 0xf6,\n\t0xa8, 0xa8, 0xe8, 0xac, 0xb8, 0xb8, 0xf8, 0xbc,\n\t0xac, 0xe8, 0xec, 0xec, 0xbc, 0xf8, 0xfc, 0xfc,\n\t0xaa, 0xaa, 0xea, 0xae, 0xba, 0xba, 0xfa, 0xbe,\n\t0xae, 0xea, 0xee, 0xee, 0xbe, 0xfa, 0xfe, 0xfe\n};\n\nstatic const u8 rs[256] = {\n\t0x00, 0x00, 0x80, 0x80, 0x02, 0x02, 0x82, 0x82,\n\t0x04, 0x04, 0x84, 0x84, 0x06, 0x06, 0x86, 0x86,\n\t0x08, 0x08, 0x88, 0x88, 0x0a, 0x0a, 0x8a, 0x8a,\n\t0x0c, 0x0c, 0x8c, 0x8c, 0x0e, 0x0e, 0x8e, 0x8e,\n\t0x10, 0x10, 0x90, 0x90, 0x12, 0x12, 0x92, 0x92,\n\t0x14, 0x14, 0x94, 0x94, 0x16, 0x16, 0x96, 0x96,\n\t0x18, 0x18, 0x98, 0x98, 0x1a, 0x1a, 0x9a, 0x9a,\n\t0x1c, 0x1c, 0x9c, 0x9c, 0x1e, 0x1e, 0x9e, 0x9e,\n\t0x20, 0x20, 0xa0, 0xa0, 0x22, 0x22, 0xa2, 0xa2,\n\t0x24, 0x24, 0xa4, 0xa4, 0x26, 0x26, 0xa6, 0xa6,\n\t0x28, 0x28, 0xa8, 0xa8, 0x2a, 0x2a, 0xaa, 0xaa,\n\t0x2c, 0x2c, 0xac, 0xac, 0x2e, 0x2e, 0xae, 0xae,\n\t0x30, 0x30, 0xb0, 0xb0, 0x32, 0x32, 0xb2, 0xb2,\n\t0x34, 0x34, 0xb4, 0xb4, 0x36, 0x36, 0xb6, 0xb6,\n\t0x38, 0x38, 0xb8, 0xb8, 0x3a, 0x3a, 0xba, 0xba,\n\t0x3c, 0x3c, 0xbc, 0xbc, 0x3e, 0x3e, 0xbe, 0xbe,\n\t0x40, 0x40, 0xc0, 0xc0, 0x42, 0x42, 0xc2, 0xc2,\n\t0x44, 0x44, 0xc4, 0xc4, 0x46, 0x46, 0xc6, 0xc6,\n\t0x48, 0x48, 0xc8, 0xc8, 0x4a, 0x4a, 0xca, 0xca,\n\t0x4c, 0x4c, 0xcc, 0xcc, 0x4e, 0x4e, 0xce, 0xce,\n\t0x50, 0x50, 0xd0, 0xd0, 0x52, 0x52, 0xd2, 0xd2,\n\t0x54, 0x54, 0xd4, 0xd4, 0x56, 0x56, 0xd6, 0xd6,\n\t0x58, 0x58, 0xd8, 0xd8, 0x5a, 0x5a, 0xda, 0xda,\n\t0x5c, 0x5c, 0xdc, 0xdc, 0x5e, 0x5e, 0xde, 0xde,\n\t0x60, 0x60, 0xe0, 0xe0, 0x62, 0x62, 0xe2, 0xe2,\n\t0x64, 0x64, 0xe4, 0xe4, 0x66, 0x66, 0xe6, 0xe6,\n\t0x68, 0x68, 0xe8, 0xe8, 0x6a, 0x6a, 0xea, 0xea,\n\t0x6c, 0x6c, 0xec, 0xec, 0x6e, 0x6e, 0xee, 0xee,\n\t0x70, 0x70, 0xf0, 0xf0, 0x72, 0x72, 0xf2, 0xf2,\n\t0x74, 0x74, 0xf4, 0xf4, 0x76, 0x76, 0xf6, 0xf6,\n\t0x78, 0x78, 0xf8, 0xf8, 0x7a, 0x7a, 0xfa, 0xfa,\n\t0x7c, 0x7c, 0xfc, 0xfc, 0x7e, 0x7e, 0xfe, 0xfe\n};\n\nstatic const u32 pc2[1024] = {\n\t0x00000000, 0x00000000, 0x00000000, 0x00000000,\n\t0x00040000, 0x00000000, 0x04000000, 0x00100000,\n\t0x00400000, 0x00000008, 0x00000800, 0x40000000,\n\t0x00440000, 0x00000008, 0x04000800, 0x40100000,\n\t0x00000400, 0x00000020, 0x08000000, 0x00000100,\n\t0x00040400, 0x00000020, 0x0c000000, 0x00100100,\n\t0x00400400, 0x00000028, 0x08000800, 0x40000100,\n\t0x00440400, 0x00000028, 0x0c000800, 0x40100100,\n\t0x80000000, 0x00000010, 0x00000000, 0x00800000,\n\t0x80040000, 0x00000010, 0x04000000, 0x00900000,\n\t0x80400000, 0x00000018, 0x00000800, 0x40800000,\n\t0x80440000, 0x00000018, 0x04000800, 0x40900000,\n\t0x80000400, 0x00000030, 0x08000000, 0x00800100,\n\t0x80040400, 0x00000030, 0x0c000000, 0x00900100,\n\t0x80400400, 0x00000038, 0x08000800, 0x40800100,\n\t0x80440400, 0x00000038, 0x0c000800, 0x40900100,\n\t0x10000000, 0x00000000, 0x00200000, 0x00001000,\n\t0x10040000, 0x00000000, 0x04200000, 0x00101000,\n\t0x10400000, 0x00000008, 0x00200800, 0x40001000,\n\t0x10440000, 0x00000008, 0x04200800, 0x40101000,\n\t0x10000400, 0x00000020, 0x08200000, 0x00001100,\n\t0x10040400, 0x00000020, 0x0c200000, 0x00101100,\n\t0x10400400, 0x00000028, 0x08200800, 0x40001100,\n\t0x10440400, 0x00000028, 0x0c200800, 0x40101100,\n\t0x90000000, 0x00000010, 0x00200000, 0x00801000,\n\t0x90040000, 0x00000010, 0x04200000, 0x00901000,\n\t0x90400000, 0x00000018, 0x00200800, 0x40801000,\n\t0x90440000, 0x00000018, 0x04200800, 0x40901000,\n\t0x90000400, 0x00000030, 0x08200000, 0x00801100,\n\t0x90040400, 0x00000030, 0x0c200000, 0x00901100,\n\t0x90400400, 0x00000038, 0x08200800, 0x40801100,\n\t0x90440400, 0x00000038, 0x0c200800, 0x40901100,\n\t0x00000200, 0x00080000, 0x00000000, 0x00000004,\n\t0x00040200, 0x00080000, 0x04000000, 0x00100004,\n\t0x00400200, 0x00080008, 0x00000800, 0x40000004,\n\t0x00440200, 0x00080008, 0x04000800, 0x40100004,\n\t0x00000600, 0x00080020, 0x08000000, 0x00000104,\n\t0x00040600, 0x00080020, 0x0c000000, 0x00100104,\n\t0x00400600, 0x00080028, 0x08000800, 0x40000104,\n\t0x00440600, 0x00080028, 0x0c000800, 0x40100104,\n\t0x80000200, 0x00080010, 0x00000000, 0x00800004,\n\t0x80040200, 0x00080010, 0x04000000, 0x00900004,\n\t0x80400200, 0x00080018, 0x00000800, 0x40800004,\n\t0x80440200, 0x00080018, 0x04000800, 0x40900004,\n\t0x80000600, 0x00080030, 0x08000000, 0x00800104,\n\t0x80040600, 0x00080030, 0x0c000000, 0x00900104,\n\t0x80400600, 0x00080038, 0x08000800, 0x40800104,\n\t0x80440600, 0x00080038, 0x0c000800, 0x40900104,\n\t0x10000200, 0x00080000, 0x00200000, 0x00001004,\n\t0x10040200, 0x00080000, 0x04200000, 0x00101004,\n\t0x10400200, 0x00080008, 0x00200800, 0x40001004,\n\t0x10440200, 0x00080008, 0x04200800, 0x40101004,\n\t0x10000600, 0x00080020, 0x08200000, 0x00001104,\n\t0x10040600, 0x00080020, 0x0c200000, 0x00101104,\n\t0x10400600, 0x00080028, 0x08200800, 0x40001104,\n\t0x10440600, 0x00080028, 0x0c200800, 0x40101104,\n\t0x90000200, 0x00080010, 0x00200000, 0x00801004,\n\t0x90040200, 0x00080010, 0x04200000, 0x00901004,\n\t0x90400200, 0x00080018, 0x00200800, 0x40801004,\n\t0x90440200, 0x00080018, 0x04200800, 0x40901004,\n\t0x90000600, 0x00080030, 0x08200000, 0x00801104,\n\t0x90040600, 0x00080030, 0x0c200000, 0x00901104,\n\t0x90400600, 0x00080038, 0x08200800, 0x40801104,\n\t0x90440600, 0x00080038, 0x0c200800, 0x40901104,\n\t0x00000002, 0x00002000, 0x20000000, 0x00000001,\n\t0x00040002, 0x00002000, 0x24000000, 0x00100001,\n\t0x00400002, 0x00002008, 0x20000800, 0x40000001,\n\t0x00440002, 0x00002008, 0x24000800, 0x40100001,\n\t0x00000402, 0x00002020, 0x28000000, 0x00000101,\n\t0x00040402, 0x00002020, 0x2c000000, 0x00100101,\n\t0x00400402, 0x00002028, 0x28000800, 0x40000101,\n\t0x00440402, 0x00002028, 0x2c000800, 0x40100101,\n\t0x80000002, 0x00002010, 0x20000000, 0x00800001,\n\t0x80040002, 0x00002010, 0x24000000, 0x00900001,\n\t0x80400002, 0x00002018, 0x20000800, 0x40800001,\n\t0x80440002, 0x00002018, 0x24000800, 0x40900001,\n\t0x80000402, 0x00002030, 0x28000000, 0x00800101,\n\t0x80040402, 0x00002030, 0x2c000000, 0x00900101,\n\t0x80400402, 0x00002038, 0x28000800, 0x40800101,\n\t0x80440402, 0x00002038, 0x2c000800, 0x40900101,\n\t0x10000002, 0x00002000, 0x20200000, 0x00001001,\n\t0x10040002, 0x00002000, 0x24200000, 0x00101001,\n\t0x10400002, 0x00002008, 0x20200800, 0x40001001,\n\t0x10440002, 0x00002008, 0x24200800, 0x40101001,\n\t0x10000402, 0x00002020, 0x28200000, 0x00001101,\n\t0x10040402, 0x00002020, 0x2c200000, 0x00101101,\n\t0x10400402, 0x00002028, 0x28200800, 0x40001101,\n\t0x10440402, 0x00002028, 0x2c200800, 0x40101101,\n\t0x90000002, 0x00002010, 0x20200000, 0x00801001,\n\t0x90040002, 0x00002010, 0x24200000, 0x00901001,\n\t0x90400002, 0x00002018, 0x20200800, 0x40801001,\n\t0x90440002, 0x00002018, 0x24200800, 0x40901001,\n\t0x90000402, 0x00002030, 0x28200000, 0x00801101,\n\t0x90040402, 0x00002030, 0x2c200000, 0x00901101,\n\t0x90400402, 0x00002038, 0x28200800, 0x40801101,\n\t0x90440402, 0x00002038, 0x2c200800, 0x40901101,\n\t0x00000202, 0x00082000, 0x20000000, 0x00000005,\n\t0x00040202, 0x00082000, 0x24000000, 0x00100005,\n\t0x00400202, 0x00082008, 0x20000800, 0x40000005,\n\t0x00440202, 0x00082008, 0x24000800, 0x40100005,\n\t0x00000602, 0x00082020, 0x28000000, 0x00000105,\n\t0x00040602, 0x00082020, 0x2c000000, 0x00100105,\n\t0x00400602, 0x00082028, 0x28000800, 0x40000105,\n\t0x00440602, 0x00082028, 0x2c000800, 0x40100105,\n\t0x80000202, 0x00082010, 0x20000000, 0x00800005,\n\t0x80040202, 0x00082010, 0x24000000, 0x00900005,\n\t0x80400202, 0x00082018, 0x20000800, 0x40800005,\n\t0x80440202, 0x00082018, 0x24000800, 0x40900005,\n\t0x80000602, 0x00082030, 0x28000000, 0x00800105,\n\t0x80040602, 0x00082030, 0x2c000000, 0x00900105,\n\t0x80400602, 0x00082038, 0x28000800, 0x40800105,\n\t0x80440602, 0x00082038, 0x2c000800, 0x40900105,\n\t0x10000202, 0x00082000, 0x20200000, 0x00001005,\n\t0x10040202, 0x00082000, 0x24200000, 0x00101005,\n\t0x10400202, 0x00082008, 0x20200800, 0x40001005,\n\t0x10440202, 0x00082008, 0x24200800, 0x40101005,\n\t0x10000602, 0x00082020, 0x28200000, 0x00001105,\n\t0x10040602, 0x00082020, 0x2c200000, 0x00101105,\n\t0x10400602, 0x00082028, 0x28200800, 0x40001105,\n\t0x10440602, 0x00082028, 0x2c200800, 0x40101105,\n\t0x90000202, 0x00082010, 0x20200000, 0x00801005,\n\t0x90040202, 0x00082010, 0x24200000, 0x00901005,\n\t0x90400202, 0x00082018, 0x20200800, 0x40801005,\n\t0x90440202, 0x00082018, 0x24200800, 0x40901005,\n\t0x90000602, 0x00082030, 0x28200000, 0x00801105,\n\t0x90040602, 0x00082030, 0x2c200000, 0x00901105,\n\t0x90400602, 0x00082038, 0x28200800, 0x40801105,\n\t0x90440602, 0x00082038, 0x2c200800, 0x40901105,\n\n\t0x00000000, 0x00000000, 0x00000000, 0x00000000,\n\t0x00000000, 0x00000008, 0x00080000, 0x10000000,\n\t0x02000000, 0x00000000, 0x00000080, 0x00001000,\n\t0x02000000, 0x00000008, 0x00080080, 0x10001000,\n\t0x00004000, 0x00000000, 0x00000040, 0x00040000,\n\t0x00004000, 0x00000008, 0x00080040, 0x10040000,\n\t0x02004000, 0x00000000, 0x000000c0, 0x00041000,\n\t0x02004000, 0x00000008, 0x000800c0, 0x10041000,\n\t0x00020000, 0x00008000, 0x08000000, 0x00200000,\n\t0x00020000, 0x00008008, 0x08080000, 0x10200000,\n\t0x02020000, 0x00008000, 0x08000080, 0x00201000,\n\t0x02020000, 0x00008008, 0x08080080, 0x10201000,\n\t0x00024000, 0x00008000, 0x08000040, 0x00240000,\n\t0x00024000, 0x00008008, 0x08080040, 0x10240000,\n\t0x02024000, 0x00008000, 0x080000c0, 0x00241000,\n\t0x02024000, 0x00008008, 0x080800c0, 0x10241000,\n\t0x00000000, 0x01000000, 0x00002000, 0x00000020,\n\t0x00000000, 0x01000008, 0x00082000, 0x10000020,\n\t0x02000000, 0x01000000, 0x00002080, 0x00001020,\n\t0x02000000, 0x01000008, 0x00082080, 0x10001020,\n\t0x00004000, 0x01000000, 0x00002040, 0x00040020,\n\t0x00004000, 0x01000008, 0x00082040, 0x10040020,\n\t0x02004000, 0x01000000, 0x000020c0, 0x00041020,\n\t0x02004000, 0x01000008, 0x000820c0, 0x10041020,\n\t0x00020000, 0x01008000, 0x08002000, 0x00200020,\n\t0x00020000, 0x01008008, 0x08082000, 0x10200020,\n\t0x02020000, 0x01008000, 0x08002080, 0x00201020,\n\t0x02020000, 0x01008008, 0x08082080, 0x10201020,\n\t0x00024000, 0x01008000, 0x08002040, 0x00240020,\n\t0x00024000, 0x01008008, 0x08082040, 0x10240020,\n\t0x02024000, 0x01008000, 0x080020c0, 0x00241020,\n\t0x02024000, 0x01008008, 0x080820c0, 0x10241020,\n\t0x00000400, 0x04000000, 0x00100000, 0x00000004,\n\t0x00000400, 0x04000008, 0x00180000, 0x10000004,\n\t0x02000400, 0x04000000, 0x00100080, 0x00001004,\n\t0x02000400, 0x04000008, 0x00180080, 0x10001004,\n\t0x00004400, 0x04000000, 0x00100040, 0x00040004,\n\t0x00004400, 0x04000008, 0x00180040, 0x10040004,\n\t0x02004400, 0x04000000, 0x001000c0, 0x00041004,\n\t0x02004400, 0x04000008, 0x001800c0, 0x10041004,\n\t0x00020400, 0x04008000, 0x08100000, 0x00200004,\n\t0x00020400, 0x04008008, 0x08180000, 0x10200004,\n\t0x02020400, 0x04008000, 0x08100080, 0x00201004,\n\t0x02020400, 0x04008008, 0x08180080, 0x10201004,\n\t0x00024400, 0x04008000, 0x08100040, 0x00240004,\n\t0x00024400, 0x04008008, 0x08180040, 0x10240004,\n\t0x02024400, 0x04008000, 0x081000c0, 0x00241004,\n\t0x02024400, 0x04008008, 0x081800c0, 0x10241004,\n\t0x00000400, 0x05000000, 0x00102000, 0x00000024,\n\t0x00000400, 0x05000008, 0x00182000, 0x10000024,\n\t0x02000400, 0x05000000, 0x00102080, 0x00001024,\n\t0x02000400, 0x05000008, 0x00182080, 0x10001024,\n\t0x00004400, 0x05000000, 0x00102040, 0x00040024,\n\t0x00004400, 0x05000008, 0x00182040, 0x10040024,\n\t0x02004400, 0x05000000, 0x001020c0, 0x00041024,\n\t0x02004400, 0x05000008, 0x001820c0, 0x10041024,\n\t0x00020400, 0x05008000, 0x08102000, 0x00200024,\n\t0x00020400, 0x05008008, 0x08182000, 0x10200024,\n\t0x02020400, 0x05008000, 0x08102080, 0x00201024,\n\t0x02020400, 0x05008008, 0x08182080, 0x10201024,\n\t0x00024400, 0x05008000, 0x08102040, 0x00240024,\n\t0x00024400, 0x05008008, 0x08182040, 0x10240024,\n\t0x02024400, 0x05008000, 0x081020c0, 0x00241024,\n\t0x02024400, 0x05008008, 0x081820c0, 0x10241024,\n\t0x00000800, 0x00010000, 0x20000000, 0x00000010,\n\t0x00000800, 0x00010008, 0x20080000, 0x10000010,\n\t0x02000800, 0x00010000, 0x20000080, 0x00001010,\n\t0x02000800, 0x00010008, 0x20080080, 0x10001010,\n\t0x00004800, 0x00010000, 0x20000040, 0x00040010,\n\t0x00004800, 0x00010008, 0x20080040, 0x10040010,\n\t0x02004800, 0x00010000, 0x200000c0, 0x00041010,\n\t0x02004800, 0x00010008, 0x200800c0, 0x10041010,\n\t0x00020800, 0x00018000, 0x28000000, 0x00200010,\n\t0x00020800, 0x00018008, 0x28080000, 0x10200010,\n\t0x02020800, 0x00018000, 0x28000080, 0x00201010,\n\t0x02020800, 0x00018008, 0x28080080, 0x10201010,\n\t0x00024800, 0x00018000, 0x28000040, 0x00240010,\n\t0x00024800, 0x00018008, 0x28080040, 0x10240010,\n\t0x02024800, 0x00018000, 0x280000c0, 0x00241010,\n\t0x02024800, 0x00018008, 0x280800c0, 0x10241010,\n\t0x00000800, 0x01010000, 0x20002000, 0x00000030,\n\t0x00000800, 0x01010008, 0x20082000, 0x10000030,\n\t0x02000800, 0x01010000, 0x20002080, 0x00001030,\n\t0x02000800, 0x01010008, 0x20082080, 0x10001030,\n\t0x00004800, 0x01010000, 0x20002040, 0x00040030,\n\t0x00004800, 0x01010008, 0x20082040, 0x10040030,\n\t0x02004800, 0x01010000, 0x200020c0, 0x00041030,\n\t0x02004800, 0x01010008, 0x200820c0, 0x10041030,\n\t0x00020800, 0x01018000, 0x28002000, 0x00200030,\n\t0x00020800, 0x01018008, 0x28082000, 0x10200030,\n\t0x02020800, 0x01018000, 0x28002080, 0x00201030,\n\t0x02020800, 0x01018008, 0x28082080, 0x10201030,\n\t0x00024800, 0x01018000, 0x28002040, 0x00240030,\n\t0x00024800, 0x01018008, 0x28082040, 0x10240030,\n\t0x02024800, 0x01018000, 0x280020c0, 0x00241030,\n\t0x02024800, 0x01018008, 0x280820c0, 0x10241030,\n\t0x00000c00, 0x04010000, 0x20100000, 0x00000014,\n\t0x00000c00, 0x04010008, 0x20180000, 0x10000014,\n\t0x02000c00, 0x04010000, 0x20100080, 0x00001014,\n\t0x02000c00, 0x04010008, 0x20180080, 0x10001014,\n\t0x00004c00, 0x04010000, 0x20100040, 0x00040014,\n\t0x00004c00, 0x04010008, 0x20180040, 0x10040014,\n\t0x02004c00, 0x04010000, 0x201000c0, 0x00041014,\n\t0x02004c00, 0x04010008, 0x201800c0, 0x10041014,\n\t0x00020c00, 0x04018000, 0x28100000, 0x00200014,\n\t0x00020c00, 0x04018008, 0x28180000, 0x10200014,\n\t0x02020c00, 0x04018000, 0x28100080, 0x00201014,\n\t0x02020c00, 0x04018008, 0x28180080, 0x10201014,\n\t0x00024c00, 0x04018000, 0x28100040, 0x00240014,\n\t0x00024c00, 0x04018008, 0x28180040, 0x10240014,\n\t0x02024c00, 0x04018000, 0x281000c0, 0x00241014,\n\t0x02024c00, 0x04018008, 0x281800c0, 0x10241014,\n\t0x00000c00, 0x05010000, 0x20102000, 0x00000034,\n\t0x00000c00, 0x05010008, 0x20182000, 0x10000034,\n\t0x02000c00, 0x05010000, 0x20102080, 0x00001034,\n\t0x02000c00, 0x05010008, 0x20182080, 0x10001034,\n\t0x00004c00, 0x05010000, 0x20102040, 0x00040034,\n\t0x00004c00, 0x05010008, 0x20182040, 0x10040034,\n\t0x02004c00, 0x05010000, 0x201020c0, 0x00041034,\n\t0x02004c00, 0x05010008, 0x201820c0, 0x10041034,\n\t0x00020c00, 0x05018000, 0x28102000, 0x00200034,\n\t0x00020c00, 0x05018008, 0x28182000, 0x10200034,\n\t0x02020c00, 0x05018000, 0x28102080, 0x00201034,\n\t0x02020c00, 0x05018008, 0x28182080, 0x10201034,\n\t0x00024c00, 0x05018000, 0x28102040, 0x00240034,\n\t0x00024c00, 0x05018008, 0x28182040, 0x10240034,\n\t0x02024c00, 0x05018000, 0x281020c0, 0x00241034,\n\t0x02024c00, 0x05018008, 0x281820c0, 0x10241034\n};\n\n/* S-box lookup tables */\n\nstatic const u32 S1[64] = {\n\t0x01010400, 0x00000000, 0x00010000, 0x01010404,\n\t0x01010004, 0x00010404, 0x00000004, 0x00010000,\n\t0x00000400, 0x01010400, 0x01010404, 0x00000400,\n\t0x01000404, 0x01010004, 0x01000000, 0x00000004,\n\t0x00000404, 0x01000400, 0x01000400, 0x00010400,\n\t0x00010400, 0x01010000, 0x01010000, 0x01000404,\n\t0x00010004, 0x01000004, 0x01000004, 0x00010004,\n\t0x00000000, 0x00000404, 0x00010404, 0x01000000,\n\t0x00010000, 0x01010404, 0x00000004, 0x01010000,\n\t0x01010400, 0x01000000, 0x01000000, 0x00000400,\n\t0x01010004, 0x00010000, 0x00010400, 0x01000004,\n\t0x00000400, 0x00000004, 0x01000404, 0x00010404,\n\t0x01010404, 0x00010004, 0x01010000, 0x01000404,\n\t0x01000004, 0x00000404, 0x00010404, 0x01010400,\n\t0x00000404, 0x01000400, 0x01000400, 0x00000000,\n\t0x00010004, 0x00010400, 0x00000000, 0x01010004\n};\n\nstatic const u32 S2[64] = {\n\t0x80108020, 0x80008000, 0x00008000, 0x00108020,\n\t0x00100000, 0x00000020, 0x80100020, 0x80008020,\n\t0x80000020, 0x80108020, 0x80108000, 0x80000000,\n\t0x80008000, 0x00100000, 0x00000020, 0x80100020,\n\t0x00108000, 0x00100020, 0x80008020, 0x00000000,\n\t0x80000000, 0x00008000, 0x00108020, 0x80100000,\n\t0x00100020, 0x80000020, 0x00000000, 0x00108000,\n\t0x00008020, 0x80108000, 0x80100000, 0x00008020,\n\t0x00000000, 0x00108020, 0x80100020, 0x00100000,\n\t0x80008020, 0x80100000, 0x80108000, 0x00008000,\n\t0x80100000, 0x80008000, 0x00000020, 0x80108020,\n\t0x00108020, 0x00000020, 0x00008000, 0x80000000,\n\t0x00008020, 0x80108000, 0x00100000, 0x80000020,\n\t0x00100020, 0x80008020, 0x80000020, 0x00100020,\n\t0x00108000, 0x00000000, 0x80008000, 0x00008020,\n\t0x80000000, 0x80100020, 0x80108020, 0x00108000\n};\n\nstatic const u32 S3[64] = {\n\t0x00000208, 0x08020200, 0x00000000, 0x08020008,\n\t0x08000200, 0x00000000, 0x00020208, 0x08000200,\n\t0x00020008, 0x08000008, 0x08000008, 0x00020000,\n\t0x08020208, 0x00020008, 0x08020000, 0x00000208,\n\t0x08000000, 0x00000008, 0x08020200, 0x00000200,\n\t0x00020200, 0x08020000, 0x08020008, 0x00020208,\n\t0x08000208, 0x00020200, 0x00020000, 0x08000208,\n\t0x00000008, 0x08020208, 0x00000200, 0x08000000,\n\t0x08020200, 0x08000000, 0x00020008, 0x00000208,\n\t0x00020000, 0x08020200, 0x08000200, 0x00000000,\n\t0x00000200, 0x00020008, 0x08020208, 0x08000200,\n\t0x08000008, 0x00000200, 0x00000000, 0x08020008,\n\t0x08000208, 0x00020000, 0x08000000, 0x08020208,\n\t0x00000008, 0x00020208, 0x00020200, 0x08000008,\n\t0x08020000, 0x08000208, 0x00000208, 0x08020000,\n\t0x00020208, 0x00000008, 0x08020008, 0x00020200\n};\n\nstatic const u32 S4[64] = {\n\t0x00802001, 0x00002081, 0x00002081, 0x00000080,\n\t0x00802080, 0x00800081, 0x00800001, 0x00002001,\n\t0x00000000, 0x00802000, 0x00802000, 0x00802081,\n\t0x00000081, 0x00000000, 0x00800080, 0x00800001,\n\t0x00000001, 0x00002000, 0x00800000, 0x00802001,\n\t0x00000080, 0x00800000, 0x00002001, 0x00002080,\n\t0x00800081, 0x00000001, 0x00002080, 0x00800080,\n\t0x00002000, 0x00802080, 0x00802081, 0x00000081,\n\t0x00800080, 0x00800001, 0x00802000, 0x00802081,\n\t0x00000081, 0x00000000, 0x00000000, 0x00802000,\n\t0x00002080, 0x00800080, 0x00800081, 0x00000001,\n\t0x00802001, 0x00002081, 0x00002081, 0x00000080,\n\t0x00802081, 0x00000081, 0x00000001, 0x00002000,\n\t0x00800001, 0x00002001, 0x00802080, 0x00800081,\n\t0x00002001, 0x00002080, 0x00800000, 0x00802001,\n\t0x00000080, 0x00800000, 0x00002000, 0x00802080\n};\n\nstatic const u32 S5[64] = {\n\t0x00000100, 0x02080100, 0x02080000, 0x42000100,\n\t0x00080000, 0x00000100, 0x40000000, 0x02080000,\n\t0x40080100, 0x00080000, 0x02000100, 0x40080100,\n\t0x42000100, 0x42080000, 0x00080100, 0x40000000,\n\t0x02000000, 0x40080000, 0x40080000, 0x00000000,\n\t0x40000100, 0x42080100, 0x42080100, 0x02000100,\n\t0x42080000, 0x40000100, 0x00000000, 0x42000000,\n\t0x02080100, 0x02000000, 0x42000000, 0x00080100,\n\t0x00080000, 0x42000100, 0x00000100, 0x02000000,\n\t0x40000000, 0x02080000, 0x42000100, 0x40080100,\n\t0x02000100, 0x40000000, 0x42080000, 0x02080100,\n\t0x40080100, 0x00000100, 0x02000000, 0x42080000,\n\t0x42080100, 0x00080100, 0x42000000, 0x42080100,\n\t0x02080000, 0x00000000, 0x40080000, 0x42000000,\n\t0x00080100, 0x02000100, 0x40000100, 0x00080000,\n\t0x00000000, 0x40080000, 0x02080100, 0x40000100\n};\n\nstatic const u32 S6[64] = {\n\t0x20000010, 0x20400000, 0x00004000, 0x20404010,\n\t0x20400000, 0x00000010, 0x20404010, 0x00400000,\n\t0x20004000, 0x00404010, 0x00400000, 0x20000010,\n\t0x00400010, 0x20004000, 0x20000000, 0x00004010,\n\t0x00000000, 0x00400010, 0x20004010, 0x00004000,\n\t0x00404000, 0x20004010, 0x00000010, 0x20400010,\n\t0x20400010, 0x00000000, 0x00404010, 0x20404000,\n\t0x00004010, 0x00404000, 0x20404000, 0x20000000,\n\t0x20004000, 0x00000010, 0x20400010, 0x00404000,\n\t0x20404010, 0x00400000, 0x00004010, 0x20000010,\n\t0x00400000, 0x20004000, 0x20000000, 0x00004010,\n\t0x20000010, 0x20404010, 0x00404000, 0x20400000,\n\t0x00404010, 0x20404000, 0x00000000, 0x20400010,\n\t0x00000010, 0x00004000, 0x20400000, 0x00404010,\n\t0x00004000, 0x00400010, 0x20004010, 0x00000000,\n\t0x20404000, 0x20000000, 0x00400010, 0x20004010\n};\n\nstatic const u32 S7[64] = {\n\t0x00200000, 0x04200002, 0x04000802, 0x00000000,\n\t0x00000800, 0x04000802, 0x00200802, 0x04200800,\n\t0x04200802, 0x00200000, 0x00000000, 0x04000002,\n\t0x00000002, 0x04000000, 0x04200002, 0x00000802,\n\t0x04000800, 0x00200802, 0x00200002, 0x04000800,\n\t0x04000002, 0x04200000, 0x04200800, 0x00200002,\n\t0x04200000, 0x00000800, 0x00000802, 0x04200802,\n\t0x00200800, 0x00000002, 0x04000000, 0x00200800,\n\t0x04000000, 0x00200800, 0x00200000, 0x04000802,\n\t0x04000802, 0x04200002, 0x04200002, 0x00000002,\n\t0x00200002, 0x04000000, 0x04000800, 0x00200000,\n\t0x04200800, 0x00000802, 0x00200802, 0x04200800,\n\t0x00000802, 0x04000002, 0x04200802, 0x04200000,\n\t0x00200800, 0x00000000, 0x00000002, 0x04200802,\n\t0x00000000, 0x00200802, 0x04200000, 0x00000800,\n\t0x04000002, 0x04000800, 0x00000800, 0x00200002\n};\n\nstatic const u32 S8[64] = {\n\t0x10001040, 0x00001000, 0x00040000, 0x10041040,\n\t0x10000000, 0x10001040, 0x00000040, 0x10000000,\n\t0x00040040, 0x10040000, 0x10041040, 0x00041000,\n\t0x10041000, 0x00041040, 0x00001000, 0x00000040,\n\t0x10040000, 0x10000040, 0x10001000, 0x00001040,\n\t0x00041000, 0x00040040, 0x10040040, 0x10041000,\n\t0x00001040, 0x00000000, 0x00000000, 0x10040040,\n\t0x10000040, 0x10001000, 0x00041040, 0x00040000,\n\t0x00041040, 0x00040000, 0x10041000, 0x00001000,\n\t0x00000040, 0x10040040, 0x00001000, 0x00041040,\n\t0x10001000, 0x00000040, 0x10000040, 0x10040000,\n\t0x10040040, 0x10000000, 0x00040000, 0x10001040,\n\t0x00000000, 0x10041040, 0x00040040, 0x10000040,\n\t0x10040000, 0x10001000, 0x10001040, 0x00000000,\n\t0x10041040, 0x00041000, 0x00041000, 0x00001040,\n\t0x00001040, 0x00040040, 0x10000000, 0x10041000\n};\n\n/* Encryption components: IP, FP, and round function */\n\n#define IP(L, R, T)\t\t\\\n\tROL(R, 4);\t\t\\\n\tT  = L;\t\t\t\\\n\tL ^= R;\t\t\t\\\n\tL &= 0xf0f0f0f0;\t\\\n\tR ^= L;\t\t\t\\\n\tL ^= T;\t\t\t\\\n\tROL(R, 12);\t\t\\\n\tT  = L;\t\t\t\\\n\tL ^= R;\t\t\t\\\n\tL &= 0xffff0000;\t\\\n\tR ^= L;\t\t\t\\\n\tL ^= T;\t\t\t\\\n\tROR(R, 14);\t\t\\\n\tT  = L;\t\t\t\\\n\tL ^= R;\t\t\t\\\n\tL &= 0xcccccccc;\t\\\n\tR ^= L;\t\t\t\\\n\tL ^= T;\t\t\t\\\n\tROL(R, 6);\t\t\\\n\tT  = L;\t\t\t\\\n\tL ^= R;\t\t\t\\\n\tL &= 0xff00ff00;\t\\\n\tR ^= L;\t\t\t\\\n\tL ^= T;\t\t\t\\\n\tROR(R, 7);\t\t\\\n\tT  = L;\t\t\t\\\n\tL ^= R;\t\t\t\\\n\tL &= 0xaaaaaaaa;\t\\\n\tR ^= L;\t\t\t\\\n\tL ^= T;\t\t\t\\\n\tROL(L, 1);\n\n#define FP(L, R, T)\t\t\\\n\tROR(L, 1);\t\t\\\n\tT  = L;\t\t\t\\\n\tL ^= R;\t\t\t\\\n\tL &= 0xaaaaaaaa;\t\\\n\tR ^= L;\t\t\t\\\n\tL ^= T;\t\t\t\\\n\tROL(R, 7);\t\t\\\n\tT  = L;\t\t\t\\\n\tL ^= R;\t\t\t\\\n\tL &= 0xff00ff00;\t\\\n\tR ^= L;\t\t\t\\\n\tL ^= T;\t\t\t\\\n\tROR(R, 6);\t\t\\\n\tT  = L;\t\t\t\\\n\tL ^= R;\t\t\t\\\n\tL &= 0xcccccccc;\t\\\n\tR ^= L;\t\t\t\\\n\tL ^= T;\t\t\t\\\n\tROL(R, 14);\t\t\\\n\tT  = L;\t\t\t\\\n\tL ^= R;\t\t\t\\\n\tL &= 0xffff0000;\t\\\n\tR ^= L;\t\t\t\\\n\tL ^= T;\t\t\t\\\n\tROR(R, 12);\t\t\\\n\tT  = L;\t\t\t\\\n\tL ^= R;\t\t\t\\\n\tL &= 0xf0f0f0f0;\t\\\n\tR ^= L;\t\t\t\\\n\tL ^= T;\t\t\t\\\n\tROR(R, 4);\n\n#define ROUND(L, R, A, B, K, d)\t\t\t\t\t\\\n\tB = K[0];\t\t\tA = K[1];\tK += d;\t\\\n\tB ^= R;\t\t\t\tA ^= R;\t\t\t\\\n\tB &= 0x3f3f3f3f;\t\tROR(A, 4);\t\t\\\n\tL ^= S8[0xff & B];\t\tA &= 0x3f3f3f3f;\t\\\n\tL ^= S6[0xff & (B >> 8)];\tB >>= 16;\t\t\\\n\tL ^= S7[0xff & A];\t\t\t\t\t\\\n\tL ^= S5[0xff & (A >> 8)];\tA >>= 16;\t\t\\\n\tL ^= S4[0xff & B];\t\t\t\t\t\\\n\tL ^= S2[0xff & (B >> 8)];\t\t\t\t\\\n\tL ^= S3[0xff & A];\t\t\t\t\t\\\n\tL ^= S1[0xff & (A >> 8)];\n\n/*\n * PC2 lookup tables are organized as 2 consecutive sets of 4 interleaved\n * tables of 128 elements.  One set is for C_i and the other for D_i, while\n * the 4 interleaved tables correspond to four 7-bit subsets of C_i or D_i.\n *\n * After PC1 each of the variables a,b,c,d contains a 7 bit subset of C_i\n * or D_i in bits 7-1 (bit 0 being the least significant).\n */\n\n#define T1(x) pt[2 * (x) + 0]\n#define T2(x) pt[2 * (x) + 1]\n#define T3(x) pt[2 * (x) + 2]\n#define T4(x) pt[2 * (x) + 3]\n\n#define DES_PC2(a, b, c, d) (T4(d) | T3(c) | T2(b) | T1(a))\n\n/*\n * Encryption key expansion\n *\n * RFC2451: Weak key checks SHOULD be performed.\n *\n * FIPS 74:\n *\n *   Keys having duals are keys which produce all zeros, all ones, or\n *   alternating zero-one patterns in the C and D registers after Permuted\n *   Choice 1 has operated on the key.\n *\n */\nunsigned long des_ekey(u32 *pe, const u8 *k)\n{\n\t/* K&R: long is at least 32 bits */\n\tunsigned long a, b, c, d, w;\n\tconst u32 *pt = pc2;\n\n\td = k[4]; d &= 0x0e; d <<= 4; d |= k[0] & 0x1e; d = pc1[d];\n\tc = k[5]; c &= 0x0e; c <<= 4; c |= k[1] & 0x1e; c = pc1[c];\n\tb = k[6]; b &= 0x0e; b <<= 4; b |= k[2] & 0x1e; b = pc1[b];\n\ta = k[7]; a &= 0x0e; a <<= 4; a |= k[3] & 0x1e; a = pc1[a];\n\n\tpe[15 * 2 + 0] = DES_PC2(a, b, c, d); d = rs[d];\n\tpe[14 * 2 + 0] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[13 * 2 + 0] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[12 * 2 + 0] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[11 * 2 + 0] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[10 * 2 + 0] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[ 9 * 2 + 0] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[ 8 * 2 + 0] = DES_PC2(d, a, b, c); c = rs[c];\n\tpe[ 7 * 2 + 0] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[ 6 * 2 + 0] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[ 5 * 2 + 0] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[ 4 * 2 + 0] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[ 3 * 2 + 0] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[ 2 * 2 + 0] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[ 1 * 2 + 0] = DES_PC2(c, d, a, b); b = rs[b];\n\tpe[ 0 * 2 + 0] = DES_PC2(b, c, d, a);\n\n\t/* Check if first half is weak */\n\tw  = (a ^ c) | (b ^ d) | (rs[a] ^ c) | (b ^ rs[d]);\n\n\t/* Skip to next table set */\n\tpt += 512;\n\n\td = k[0]; d &= 0xe0; d >>= 4; d |= k[4] & 0xf0; d = pc1[d + 1];\n\tc = k[1]; c &= 0xe0; c >>= 4; c |= k[5] & 0xf0; c = pc1[c + 1];\n\tb = k[2]; b &= 0xe0; b >>= 4; b |= k[6] & 0xf0; b = pc1[b + 1];\n\ta = k[3]; a &= 0xe0; a >>= 4; a |= k[7] & 0xf0; a = pc1[a + 1];\n\n\t/* Check if second half is weak */\n\tw |= (a ^ c) | (b ^ d) | (rs[a] ^ c) | (b ^ rs[d]);\n\n\tpe[15 * 2 + 1] = DES_PC2(a, b, c, d); d = rs[d];\n\tpe[14 * 2 + 1] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[13 * 2 + 1] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[12 * 2 + 1] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[11 * 2 + 1] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[10 * 2 + 1] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[ 9 * 2 + 1] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[ 8 * 2 + 1] = DES_PC2(d, a, b, c); c = rs[c];\n\tpe[ 7 * 2 + 1] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[ 6 * 2 + 1] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[ 5 * 2 + 1] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[ 4 * 2 + 1] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[ 3 * 2 + 1] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[ 2 * 2 + 1] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[ 1 * 2 + 1] = DES_PC2(c, d, a, b); b = rs[b];\n\tpe[ 0 * 2 + 1] = DES_PC2(b, c, d, a);\n\n\t/* Fixup: 2413 5768 -> 1357 2468 */\n\tfor (d = 0; d < 16; ++d) {\n\t\ta = pe[2 * d];\n\t\tb = pe[2 * d + 1];\n\t\tc = a ^ b;\n\t\tc &= 0xffff0000;\n\t\ta ^= c;\n\t\tb ^= c;\n\t\tROL(b, 18);\n\t\tpe[2 * d] = a;\n\t\tpe[2 * d + 1] = b;\n\t}\n\n\t/* Zero if weak key */\n\treturn w;\n}\nEXPORT_SYMBOL_GPL(des_ekey);\n\n/*\n * Decryption key expansion\n *\n * No weak key checking is performed, as this is only used by triple DES\n *\n */\nstatic void dkey(u32 *pe, const u8 *k)\n{\n\t/* K&R: long is at least 32 bits */\n\tunsigned long a, b, c, d;\n\tconst u32 *pt = pc2;\n\n\td = k[4]; d &= 0x0e; d <<= 4; d |= k[0] & 0x1e; d = pc1[d];\n\tc = k[5]; c &= 0x0e; c <<= 4; c |= k[1] & 0x1e; c = pc1[c];\n\tb = k[6]; b &= 0x0e; b <<= 4; b |= k[2] & 0x1e; b = pc1[b];\n\ta = k[7]; a &= 0x0e; a <<= 4; a |= k[3] & 0x1e; a = pc1[a];\n\n\tpe[ 0 * 2] = DES_PC2(a, b, c, d); d = rs[d];\n\tpe[ 1 * 2] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[ 2 * 2] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[ 3 * 2] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[ 4 * 2] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[ 5 * 2] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[ 6 * 2] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[ 7 * 2] = DES_PC2(d, a, b, c); c = rs[c];\n\tpe[ 8 * 2] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[ 9 * 2] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[10 * 2] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[11 * 2] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[12 * 2] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[13 * 2] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[14 * 2] = DES_PC2(c, d, a, b); b = rs[b];\n\tpe[15 * 2] = DES_PC2(b, c, d, a);\n\n\t/* Skip to next table set */\n\tpt += 512;\n\n\td = k[0]; d &= 0xe0; d >>= 4; d |= k[4] & 0xf0; d = pc1[d + 1];\n\tc = k[1]; c &= 0xe0; c >>= 4; c |= k[5] & 0xf0; c = pc1[c + 1];\n\tb = k[2]; b &= 0xe0; b >>= 4; b |= k[6] & 0xf0; b = pc1[b + 1];\n\ta = k[3]; a &= 0xe0; a >>= 4; a |= k[7] & 0xf0; a = pc1[a + 1];\n\n\tpe[ 0 * 2 + 1] = DES_PC2(a, b, c, d); d = rs[d];\n\tpe[ 1 * 2 + 1] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[ 2 * 2 + 1] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[ 3 * 2 + 1] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[ 4 * 2 + 1] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[ 5 * 2 + 1] = DES_PC2(d, a, b, c); c = rs[c]; b = rs[b];\n\tpe[ 6 * 2 + 1] = DES_PC2(b, c, d, a); a = rs[a]; d = rs[d];\n\tpe[ 7 * 2 + 1] = DES_PC2(d, a, b, c); c = rs[c];\n\tpe[ 8 * 2 + 1] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[ 9 * 2 + 1] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[10 * 2 + 1] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[11 * 2 + 1] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[12 * 2 + 1] = DES_PC2(c, d, a, b); b = rs[b]; a = rs[a];\n\tpe[13 * 2 + 1] = DES_PC2(a, b, c, d); d = rs[d]; c = rs[c];\n\tpe[14 * 2 + 1] = DES_PC2(c, d, a, b); b = rs[b];\n\tpe[15 * 2 + 1] = DES_PC2(b, c, d, a);\n\n\t/* Fixup: 2413 5768 -> 1357 2468 */\n\tfor (d = 0; d < 16; ++d) {\n\t\ta = pe[2 * d];\n\t\tb = pe[2 * d + 1];\n\t\tc = a ^ b;\n\t\tc &= 0xffff0000;\n\t\ta ^= c;\n\t\tb ^= c;\n\t\tROL(b, 18);\n\t\tpe[2 * d] = a;\n\t\tpe[2 * d + 1] = b;\n\t}\n}\n\nstatic int des_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t      unsigned int keylen)\n{\n\tstruct des_ctx *dctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tu32 tmp[DES_EXPKEY_WORDS];\n\tint ret;\n\n\t/* Expand to tmp */\n\tret = des_ekey(tmp, key);\n\n\tif (unlikely(ret == 0) && (*flags & CRYPTO_TFM_REQ_WEAK_KEY)) {\n\t\t*flags |= CRYPTO_TFM_RES_WEAK_KEY;\n\t\treturn -EINVAL;\n\t}\n\n\t/* Copy to output */\n\tmemcpy(dctx->expkey, tmp, sizeof(dctx->expkey));\n\n\treturn 0;\n}\n\nstatic void des_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct des_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst u32 *K = ctx->expkey;\n\tconst __le32 *s = (const __le32 *)src;\n\t__le32 *d = (__le32 *)dst;\n\tu32 L, R, A, B;\n\tint i;\n\n\tL = le32_to_cpu(s[0]);\n\tR = le32_to_cpu(s[1]);\n\n\tIP(L, R, A);\n\tfor (i = 0; i < 8; i++) {\n\t\tROUND(L, R, A, B, K, 2);\n\t\tROUND(R, L, A, B, K, 2);\n\t}\n\tFP(R, L, A);\n\n\td[0] = cpu_to_le32(R);\n\td[1] = cpu_to_le32(L);\n}\n\nstatic void des_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct des_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst u32 *K = ctx->expkey + DES_EXPKEY_WORDS - 2;\n\tconst __le32 *s = (const __le32 *)src;\n\t__le32 *d = (__le32 *)dst;\n\tu32 L, R, A, B;\n\tint i;\n\n\tL = le32_to_cpu(s[0]);\n\tR = le32_to_cpu(s[1]);\n\n\tIP(L, R, A);\n\tfor (i = 0; i < 8; i++) {\n\t\tROUND(L, R, A, B, K, -2);\n\t\tROUND(R, L, A, B, K, -2);\n\t}\n\tFP(R, L, A);\n\n\td[0] = cpu_to_le32(R);\n\td[1] = cpu_to_le32(L);\n}\n\n/*\n * RFC2451:\n *\n *   For DES-EDE3, there is no known need to reject weak or\n *   complementation keys.  Any weakness is obviated by the use of\n *   multiple keys.\n *\n *   However, if the first two or last two independent 64-bit keys are\n *   equal (k1 == k2 or k2 == k3), then the DES3 operation is simply the\n *   same as DES.  Implementers MUST reject keys that exhibit this\n *   property.\n *\n */\nint __des3_ede_setkey(u32 *expkey, u32 *flags, const u8 *key,\n\t\t      unsigned int keylen)\n{\n\tconst u32 *K = (const u32 *)key;\n\n\tif (unlikely(!((K[0] ^ K[2]) | (K[1] ^ K[3])) ||\n\t\t     !((K[2] ^ K[4]) | (K[3] ^ K[5]))) &&\n\t\t     (*flags & CRYPTO_TFM_REQ_WEAK_KEY)) {\n\t\t*flags |= CRYPTO_TFM_RES_WEAK_KEY;\n\t\treturn -EINVAL;\n\t}\n\n\tdes_ekey(expkey, key); expkey += DES_EXPKEY_WORDS; key += DES_KEY_SIZE;\n\tdkey(expkey, key); expkey += DES_EXPKEY_WORDS; key += DES_KEY_SIZE;\n\tdes_ekey(expkey, key);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(__des3_ede_setkey);\n\nstatic int des3_ede_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\t   unsigned int keylen)\n{\n\tstruct des3_ede_ctx *dctx = crypto_tfm_ctx(tfm);\n\tu32 *flags = &tfm->crt_flags;\n\tu32 *expkey = dctx->expkey;\n\n\treturn __des3_ede_setkey(expkey, flags, key, keylen);\n}\n\nstatic void des3_ede_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct des3_ede_ctx *dctx = crypto_tfm_ctx(tfm);\n\tconst u32 *K = dctx->expkey;\n\tconst __le32 *s = (const __le32 *)src;\n\t__le32 *d = (__le32 *)dst;\n\tu32 L, R, A, B;\n\tint i;\n\n\tL = le32_to_cpu(s[0]);\n\tR = le32_to_cpu(s[1]);\n\n\tIP(L, R, A);\n\tfor (i = 0; i < 8; i++) {\n\t\tROUND(L, R, A, B, K, 2);\n\t\tROUND(R, L, A, B, K, 2);\n\t}\n\tfor (i = 0; i < 8; i++) {\n\t\tROUND(R, L, A, B, K, 2);\n\t\tROUND(L, R, A, B, K, 2);\n\t}\n\tfor (i = 0; i < 8; i++) {\n\t\tROUND(L, R, A, B, K, 2);\n\t\tROUND(R, L, A, B, K, 2);\n\t}\n\tFP(R, L, A);\n\n\td[0] = cpu_to_le32(R);\n\td[1] = cpu_to_le32(L);\n}\n\nstatic void des3_ede_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct des3_ede_ctx *dctx = crypto_tfm_ctx(tfm);\n\tconst u32 *K = dctx->expkey + DES3_EDE_EXPKEY_WORDS - 2;\n\tconst __le32 *s = (const __le32 *)src;\n\t__le32 *d = (__le32 *)dst;\n\tu32 L, R, A, B;\n\tint i;\n\n\tL = le32_to_cpu(s[0]);\n\tR = le32_to_cpu(s[1]);\n\n\tIP(L, R, A);\n\tfor (i = 0; i < 8; i++) {\n\t\tROUND(L, R, A, B, K, -2);\n\t\tROUND(R, L, A, B, K, -2);\n\t}\n\tfor (i = 0; i < 8; i++) {\n\t\tROUND(R, L, A, B, K, -2);\n\t\tROUND(L, R, A, B, K, -2);\n\t}\n\tfor (i = 0; i < 8; i++) {\n\t\tROUND(L, R, A, B, K, -2);\n\t\tROUND(R, L, A, B, K, -2);\n\t}\n\tFP(R, L, A);\n\n\td[0] = cpu_to_le32(R);\n\td[1] = cpu_to_le32(L);\n}\n\nstatic struct crypto_alg des_algs[2] = { {\n\t.cra_name\t\t=\t\"des\",\n\t.cra_driver_name\t=\t\"des-generic\",\n\t.cra_priority\t\t=\t100,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tDES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct des_ctx),\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_alignmask\t\t=\t3,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\tDES_KEY_SIZE,\n\t.cia_max_keysize\t=\tDES_KEY_SIZE,\n\t.cia_setkey\t\t=\tdes_setkey,\n\t.cia_encrypt\t\t=\tdes_encrypt,\n\t.cia_decrypt\t\t=\tdes_decrypt } }\n}, {\n\t.cra_name\t\t=\t\"des3_ede\",\n\t.cra_driver_name\t=\t\"des3_ede-generic\",\n\t.cra_priority\t\t=\t100,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tDES3_EDE_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct des3_ede_ctx),\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_alignmask\t\t=\t3,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\tDES3_EDE_KEY_SIZE,\n\t.cia_max_keysize\t=\tDES3_EDE_KEY_SIZE,\n\t.cia_setkey\t\t=\tdes3_ede_setkey,\n\t.cia_encrypt\t\t=\tdes3_ede_encrypt,\n\t.cia_decrypt\t\t=\tdes3_ede_decrypt } }\n} };\n\nMODULE_ALIAS_CRYPTO(\"des3_ede\");\n\nstatic int __init des_generic_mod_init(void)\n{\n\treturn crypto_register_algs(des_algs, ARRAY_SIZE(des_algs));\n}\n\nstatic void __exit des_generic_mod_fini(void)\n{\n\tcrypto_unregister_algs(des_algs, ARRAY_SIZE(des_algs));\n}\n\nmodule_init(des_generic_mod_init);\nmodule_exit(des_generic_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"DES & Triple DES EDE Cipher Algorithms\");\nMODULE_AUTHOR(\"Dag Arne Osvik <da@osvik.no>\");\nMODULE_ALIAS(\"des\");\n", "/* FCrypt encryption algorithm\n *\n * Copyright (C) 2006 Red Hat, Inc. All Rights Reserved.\n * Written by David Howells (dhowells@redhat.com)\n *\n * This program is free software; you can redistribute it and/or\n * modify it under the terms of the GNU General Public License\n * as published by the Free Software Foundation; either version\n * 2 of the License, or (at your option) any later version.\n *\n * Based on code:\n *\n * Copyright (c) 1995 - 2000 Kungliga Tekniska H\u00f6gskolan\n * (Royal Institute of Technology, Stockholm, Sweden).\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n *\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n *\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n *\n * 3. Neither the name of the Institute nor the names of its contributors\n *    may be used to endorse or promote products derived from this software\n *    without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE INSTITUTE AND CONTRIBUTORS ``AS IS'' AND\n * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED.  IN NO EVENT SHALL THE INSTITUTE OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\n * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n * SUCH DAMAGE.\n */\n\n#include <asm/byteorder.h>\n#include <linux/bitops.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/crypto.h>\n\n#define ROUNDS 16\n\nstruct fcrypt_ctx {\n\t__be32 sched[ROUNDS];\n};\n\n/* Rotate right two 32 bit numbers as a 56 bit number */\n#define ror56(hi, lo, n)\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\\\n\tu32 t = lo & ((1 << n) - 1);\t\t\t\t\\\n\tlo = (lo >> n) | ((hi & ((1 << n) - 1)) << (32 - n));\t\\\n\thi = (hi >> n) | (t << (24-n));\t\t\t\t\\\n} while (0)\n\n/* Rotate right one 64 bit number as a 56 bit number */\n#define ror56_64(k, n)\t\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\\\n\tk = (k >> n) | ((k & ((1 << n) - 1)) << (56 - n));\t\\\n} while (0)\n\n/*\n * Sboxes for Feistel network derived from\n * /afs/transarc.com/public/afsps/afs.rel31b.export-src/rxkad/sboxes.h\n */\n#undef Z\n#define Z(x) cpu_to_be32(x << 3)\nstatic const __be32 sbox0[256] = {\n\tZ(0xea), Z(0x7f), Z(0xb2), Z(0x64), Z(0x9d), Z(0xb0), Z(0xd9), Z(0x11),\n\tZ(0xcd), Z(0x86), Z(0x86), Z(0x91), Z(0x0a), Z(0xb2), Z(0x93), Z(0x06),\n\tZ(0x0e), Z(0x06), Z(0xd2), Z(0x65), Z(0x73), Z(0xc5), Z(0x28), Z(0x60),\n\tZ(0xf2), Z(0x20), Z(0xb5), Z(0x38), Z(0x7e), Z(0xda), Z(0x9f), Z(0xe3),\n\tZ(0xd2), Z(0xcf), Z(0xc4), Z(0x3c), Z(0x61), Z(0xff), Z(0x4a), Z(0x4a),\n\tZ(0x35), Z(0xac), Z(0xaa), Z(0x5f), Z(0x2b), Z(0xbb), Z(0xbc), Z(0x53),\n\tZ(0x4e), Z(0x9d), Z(0x78), Z(0xa3), Z(0xdc), Z(0x09), Z(0x32), Z(0x10),\n\tZ(0xc6), Z(0x6f), Z(0x66), Z(0xd6), Z(0xab), Z(0xa9), Z(0xaf), Z(0xfd),\n\tZ(0x3b), Z(0x95), Z(0xe8), Z(0x34), Z(0x9a), Z(0x81), Z(0x72), Z(0x80),\n\tZ(0x9c), Z(0xf3), Z(0xec), Z(0xda), Z(0x9f), Z(0x26), Z(0x76), Z(0x15),\n\tZ(0x3e), Z(0x55), Z(0x4d), Z(0xde), Z(0x84), Z(0xee), Z(0xad), Z(0xc7),\n\tZ(0xf1), Z(0x6b), Z(0x3d), Z(0xd3), Z(0x04), Z(0x49), Z(0xaa), Z(0x24),\n\tZ(0x0b), Z(0x8a), Z(0x83), Z(0xba), Z(0xfa), Z(0x85), Z(0xa0), Z(0xa8),\n\tZ(0xb1), Z(0xd4), Z(0x01), Z(0xd8), Z(0x70), Z(0x64), Z(0xf0), Z(0x51),\n\tZ(0xd2), Z(0xc3), Z(0xa7), Z(0x75), Z(0x8c), Z(0xa5), Z(0x64), Z(0xef),\n\tZ(0x10), Z(0x4e), Z(0xb7), Z(0xc6), Z(0x61), Z(0x03), Z(0xeb), Z(0x44),\n\tZ(0x3d), Z(0xe5), Z(0xb3), Z(0x5b), Z(0xae), Z(0xd5), Z(0xad), Z(0x1d),\n\tZ(0xfa), Z(0x5a), Z(0x1e), Z(0x33), Z(0xab), Z(0x93), Z(0xa2), Z(0xb7),\n\tZ(0xe7), Z(0xa8), Z(0x45), Z(0xa4), Z(0xcd), Z(0x29), Z(0x63), Z(0x44),\n\tZ(0xb6), Z(0x69), Z(0x7e), Z(0x2e), Z(0x62), Z(0x03), Z(0xc8), Z(0xe0),\n\tZ(0x17), Z(0xbb), Z(0xc7), Z(0xf3), Z(0x3f), Z(0x36), Z(0xba), Z(0x71),\n\tZ(0x8e), Z(0x97), Z(0x65), Z(0x60), Z(0x69), Z(0xb6), Z(0xf6), Z(0xe6),\n\tZ(0x6e), Z(0xe0), Z(0x81), Z(0x59), Z(0xe8), Z(0xaf), Z(0xdd), Z(0x95),\n\tZ(0x22), Z(0x99), Z(0xfd), Z(0x63), Z(0x19), Z(0x74), Z(0x61), Z(0xb1),\n\tZ(0xb6), Z(0x5b), Z(0xae), Z(0x54), Z(0xb3), Z(0x70), Z(0xff), Z(0xc6),\n\tZ(0x3b), Z(0x3e), Z(0xc1), Z(0xd7), Z(0xe1), Z(0x0e), Z(0x76), Z(0xe5),\n\tZ(0x36), Z(0x4f), Z(0x59), Z(0xc7), Z(0x08), Z(0x6e), Z(0x82), Z(0xa6),\n\tZ(0x93), Z(0xc4), Z(0xaa), Z(0x26), Z(0x49), Z(0xe0), Z(0x21), Z(0x64),\n\tZ(0x07), Z(0x9f), Z(0x64), Z(0x81), Z(0x9c), Z(0xbf), Z(0xf9), Z(0xd1),\n\tZ(0x43), Z(0xf8), Z(0xb6), Z(0xb9), Z(0xf1), Z(0x24), Z(0x75), Z(0x03),\n\tZ(0xe4), Z(0xb0), Z(0x99), Z(0x46), Z(0x3d), Z(0xf5), Z(0xd1), Z(0x39),\n\tZ(0x72), Z(0x12), Z(0xf6), Z(0xba), Z(0x0c), Z(0x0d), Z(0x42), Z(0x2e)\n};\n\n#undef Z\n#define Z(x) cpu_to_be32(((x & 0x1f) << 27) | (x >> 5))\nstatic const __be32 sbox1[256] = {\n\tZ(0x77), Z(0x14), Z(0xa6), Z(0xfe), Z(0xb2), Z(0x5e), Z(0x8c), Z(0x3e),\n\tZ(0x67), Z(0x6c), Z(0xa1), Z(0x0d), Z(0xc2), Z(0xa2), Z(0xc1), Z(0x85),\n\tZ(0x6c), Z(0x7b), Z(0x67), Z(0xc6), Z(0x23), Z(0xe3), Z(0xf2), Z(0x89),\n\tZ(0x50), Z(0x9c), Z(0x03), Z(0xb7), Z(0x73), Z(0xe6), Z(0xe1), Z(0x39),\n\tZ(0x31), Z(0x2c), Z(0x27), Z(0x9f), Z(0xa5), Z(0x69), Z(0x44), Z(0xd6),\n\tZ(0x23), Z(0x83), Z(0x98), Z(0x7d), Z(0x3c), Z(0xb4), Z(0x2d), Z(0x99),\n\tZ(0x1c), Z(0x1f), Z(0x8c), Z(0x20), Z(0x03), Z(0x7c), Z(0x5f), Z(0xad),\n\tZ(0xf4), Z(0xfa), Z(0x95), Z(0xca), Z(0x76), Z(0x44), Z(0xcd), Z(0xb6),\n\tZ(0xb8), Z(0xa1), Z(0xa1), Z(0xbe), Z(0x9e), Z(0x54), Z(0x8f), Z(0x0b),\n\tZ(0x16), Z(0x74), Z(0x31), Z(0x8a), Z(0x23), Z(0x17), Z(0x04), Z(0xfa),\n\tZ(0x79), Z(0x84), Z(0xb1), Z(0xf5), Z(0x13), Z(0xab), Z(0xb5), Z(0x2e),\n\tZ(0xaa), Z(0x0c), Z(0x60), Z(0x6b), Z(0x5b), Z(0xc4), Z(0x4b), Z(0xbc),\n\tZ(0xe2), Z(0xaf), Z(0x45), Z(0x73), Z(0xfa), Z(0xc9), Z(0x49), Z(0xcd),\n\tZ(0x00), Z(0x92), Z(0x7d), Z(0x97), Z(0x7a), Z(0x18), Z(0x60), Z(0x3d),\n\tZ(0xcf), Z(0x5b), Z(0xde), Z(0xc6), Z(0xe2), Z(0xe6), Z(0xbb), Z(0x8b),\n\tZ(0x06), Z(0xda), Z(0x08), Z(0x15), Z(0x1b), Z(0x88), Z(0x6a), Z(0x17),\n\tZ(0x89), Z(0xd0), Z(0xa9), Z(0xc1), Z(0xc9), Z(0x70), Z(0x6b), Z(0xe5),\n\tZ(0x43), Z(0xf4), Z(0x68), Z(0xc8), Z(0xd3), Z(0x84), Z(0x28), Z(0x0a),\n\tZ(0x52), Z(0x66), Z(0xa3), Z(0xca), Z(0xf2), Z(0xe3), Z(0x7f), Z(0x7a),\n\tZ(0x31), Z(0xf7), Z(0x88), Z(0x94), Z(0x5e), Z(0x9c), Z(0x63), Z(0xd5),\n\tZ(0x24), Z(0x66), Z(0xfc), Z(0xb3), Z(0x57), Z(0x25), Z(0xbe), Z(0x89),\n\tZ(0x44), Z(0xc4), Z(0xe0), Z(0x8f), Z(0x23), Z(0x3c), Z(0x12), Z(0x52),\n\tZ(0xf5), Z(0x1e), Z(0xf4), Z(0xcb), Z(0x18), Z(0x33), Z(0x1f), Z(0xf8),\n\tZ(0x69), Z(0x10), Z(0x9d), Z(0xd3), Z(0xf7), Z(0x28), Z(0xf8), Z(0x30),\n\tZ(0x05), Z(0x5e), Z(0x32), Z(0xc0), Z(0xd5), Z(0x19), Z(0xbd), Z(0x45),\n\tZ(0x8b), Z(0x5b), Z(0xfd), Z(0xbc), Z(0xe2), Z(0x5c), Z(0xa9), Z(0x96),\n\tZ(0xef), Z(0x70), Z(0xcf), Z(0xc2), Z(0x2a), Z(0xb3), Z(0x61), Z(0xad),\n\tZ(0x80), Z(0x48), Z(0x81), Z(0xb7), Z(0x1d), Z(0x43), Z(0xd9), Z(0xd7),\n\tZ(0x45), Z(0xf0), Z(0xd8), Z(0x8a), Z(0x59), Z(0x7c), Z(0x57), Z(0xc1),\n\tZ(0x79), Z(0xc7), Z(0x34), Z(0xd6), Z(0x43), Z(0xdf), Z(0xe4), Z(0x78),\n\tZ(0x16), Z(0x06), Z(0xda), Z(0x92), Z(0x76), Z(0x51), Z(0xe1), Z(0xd4),\n\tZ(0x70), Z(0x03), Z(0xe0), Z(0x2f), Z(0x96), Z(0x91), Z(0x82), Z(0x80)\n};\n\n#undef Z\n#define Z(x) cpu_to_be32(x << 11)\nstatic const __be32 sbox2[256] = {\n\tZ(0xf0), Z(0x37), Z(0x24), Z(0x53), Z(0x2a), Z(0x03), Z(0x83), Z(0x86),\n\tZ(0xd1), Z(0xec), Z(0x50), Z(0xf0), Z(0x42), Z(0x78), Z(0x2f), Z(0x6d),\n\tZ(0xbf), Z(0x80), Z(0x87), Z(0x27), Z(0x95), Z(0xe2), Z(0xc5), Z(0x5d),\n\tZ(0xf9), Z(0x6f), Z(0xdb), Z(0xb4), Z(0x65), Z(0x6e), Z(0xe7), Z(0x24),\n\tZ(0xc8), Z(0x1a), Z(0xbb), Z(0x49), Z(0xb5), Z(0x0a), Z(0x7d), Z(0xb9),\n\tZ(0xe8), Z(0xdc), Z(0xb7), Z(0xd9), Z(0x45), Z(0x20), Z(0x1b), Z(0xce),\n\tZ(0x59), Z(0x9d), Z(0x6b), Z(0xbd), Z(0x0e), Z(0x8f), Z(0xa3), Z(0xa9),\n\tZ(0xbc), Z(0x74), Z(0xa6), Z(0xf6), Z(0x7f), Z(0x5f), Z(0xb1), Z(0x68),\n\tZ(0x84), Z(0xbc), Z(0xa9), Z(0xfd), Z(0x55), Z(0x50), Z(0xe9), Z(0xb6),\n\tZ(0x13), Z(0x5e), Z(0x07), Z(0xb8), Z(0x95), Z(0x02), Z(0xc0), Z(0xd0),\n\tZ(0x6a), Z(0x1a), Z(0x85), Z(0xbd), Z(0xb6), Z(0xfd), Z(0xfe), Z(0x17),\n\tZ(0x3f), Z(0x09), Z(0xa3), Z(0x8d), Z(0xfb), Z(0xed), Z(0xda), Z(0x1d),\n\tZ(0x6d), Z(0x1c), Z(0x6c), Z(0x01), Z(0x5a), Z(0xe5), Z(0x71), Z(0x3e),\n\tZ(0x8b), Z(0x6b), Z(0xbe), Z(0x29), Z(0xeb), Z(0x12), Z(0x19), Z(0x34),\n\tZ(0xcd), Z(0xb3), Z(0xbd), Z(0x35), Z(0xea), Z(0x4b), Z(0xd5), Z(0xae),\n\tZ(0x2a), Z(0x79), Z(0x5a), Z(0xa5), Z(0x32), Z(0x12), Z(0x7b), Z(0xdc),\n\tZ(0x2c), Z(0xd0), Z(0x22), Z(0x4b), Z(0xb1), Z(0x85), Z(0x59), Z(0x80),\n\tZ(0xc0), Z(0x30), Z(0x9f), Z(0x73), Z(0xd3), Z(0x14), Z(0x48), Z(0x40),\n\tZ(0x07), Z(0x2d), Z(0x8f), Z(0x80), Z(0x0f), Z(0xce), Z(0x0b), Z(0x5e),\n\tZ(0xb7), Z(0x5e), Z(0xac), Z(0x24), Z(0x94), Z(0x4a), Z(0x18), Z(0x15),\n\tZ(0x05), Z(0xe8), Z(0x02), Z(0x77), Z(0xa9), Z(0xc7), Z(0x40), Z(0x45),\n\tZ(0x89), Z(0xd1), Z(0xea), Z(0xde), Z(0x0c), Z(0x79), Z(0x2a), Z(0x99),\n\tZ(0x6c), Z(0x3e), Z(0x95), Z(0xdd), Z(0x8c), Z(0x7d), Z(0xad), Z(0x6f),\n\tZ(0xdc), Z(0xff), Z(0xfd), Z(0x62), Z(0x47), Z(0xb3), Z(0x21), Z(0x8a),\n\tZ(0xec), Z(0x8e), Z(0x19), Z(0x18), Z(0xb4), Z(0x6e), Z(0x3d), Z(0xfd),\n\tZ(0x74), Z(0x54), Z(0x1e), Z(0x04), Z(0x85), Z(0xd8), Z(0xbc), Z(0x1f),\n\tZ(0x56), Z(0xe7), Z(0x3a), Z(0x56), Z(0x67), Z(0xd6), Z(0xc8), Z(0xa5),\n\tZ(0xf3), Z(0x8e), Z(0xde), Z(0xae), Z(0x37), Z(0x49), Z(0xb7), Z(0xfa),\n\tZ(0xc8), Z(0xf4), Z(0x1f), Z(0xe0), Z(0x2a), Z(0x9b), Z(0x15), Z(0xd1),\n\tZ(0x34), Z(0x0e), Z(0xb5), Z(0xe0), Z(0x44), Z(0x78), Z(0x84), Z(0x59),\n\tZ(0x56), Z(0x68), Z(0x77), Z(0xa5), Z(0x14), Z(0x06), Z(0xf5), Z(0x2f),\n\tZ(0x8c), Z(0x8a), Z(0x73), Z(0x80), Z(0x76), Z(0xb4), Z(0x10), Z(0x86)\n};\n\n#undef Z\n#define Z(x) cpu_to_be32(x << 19)\nstatic const __be32 sbox3[256] = {\n\tZ(0xa9), Z(0x2a), Z(0x48), Z(0x51), Z(0x84), Z(0x7e), Z(0x49), Z(0xe2),\n\tZ(0xb5), Z(0xb7), Z(0x42), Z(0x33), Z(0x7d), Z(0x5d), Z(0xa6), Z(0x12),\n\tZ(0x44), Z(0x48), Z(0x6d), Z(0x28), Z(0xaa), Z(0x20), Z(0x6d), Z(0x57),\n\tZ(0xd6), Z(0x6b), Z(0x5d), Z(0x72), Z(0xf0), Z(0x92), Z(0x5a), Z(0x1b),\n\tZ(0x53), Z(0x80), Z(0x24), Z(0x70), Z(0x9a), Z(0xcc), Z(0xa7), Z(0x66),\n\tZ(0xa1), Z(0x01), Z(0xa5), Z(0x41), Z(0x97), Z(0x41), Z(0x31), Z(0x82),\n\tZ(0xf1), Z(0x14), Z(0xcf), Z(0x53), Z(0x0d), Z(0xa0), Z(0x10), Z(0xcc),\n\tZ(0x2a), Z(0x7d), Z(0xd2), Z(0xbf), Z(0x4b), Z(0x1a), Z(0xdb), Z(0x16),\n\tZ(0x47), Z(0xf6), Z(0x51), Z(0x36), Z(0xed), Z(0xf3), Z(0xb9), Z(0x1a),\n\tZ(0xa7), Z(0xdf), Z(0x29), Z(0x43), Z(0x01), Z(0x54), Z(0x70), Z(0xa4),\n\tZ(0xbf), Z(0xd4), Z(0x0b), Z(0x53), Z(0x44), Z(0x60), Z(0x9e), Z(0x23),\n\tZ(0xa1), Z(0x18), Z(0x68), Z(0x4f), Z(0xf0), Z(0x2f), Z(0x82), Z(0xc2),\n\tZ(0x2a), Z(0x41), Z(0xb2), Z(0x42), Z(0x0c), Z(0xed), Z(0x0c), Z(0x1d),\n\tZ(0x13), Z(0x3a), Z(0x3c), Z(0x6e), Z(0x35), Z(0xdc), Z(0x60), Z(0x65),\n\tZ(0x85), Z(0xe9), Z(0x64), Z(0x02), Z(0x9a), Z(0x3f), Z(0x9f), Z(0x87),\n\tZ(0x96), Z(0xdf), Z(0xbe), Z(0xf2), Z(0xcb), Z(0xe5), Z(0x6c), Z(0xd4),\n\tZ(0x5a), Z(0x83), Z(0xbf), Z(0x92), Z(0x1b), Z(0x94), Z(0x00), Z(0x42),\n\tZ(0xcf), Z(0x4b), Z(0x00), Z(0x75), Z(0xba), Z(0x8f), Z(0x76), Z(0x5f),\n\tZ(0x5d), Z(0x3a), Z(0x4d), Z(0x09), Z(0x12), Z(0x08), Z(0x38), Z(0x95),\n\tZ(0x17), Z(0xe4), Z(0x01), Z(0x1d), Z(0x4c), Z(0xa9), Z(0xcc), Z(0x85),\n\tZ(0x82), Z(0x4c), Z(0x9d), Z(0x2f), Z(0x3b), Z(0x66), Z(0xa1), Z(0x34),\n\tZ(0x10), Z(0xcd), Z(0x59), Z(0x89), Z(0xa5), Z(0x31), Z(0xcf), Z(0x05),\n\tZ(0xc8), Z(0x84), Z(0xfa), Z(0xc7), Z(0xba), Z(0x4e), Z(0x8b), Z(0x1a),\n\tZ(0x19), Z(0xf1), Z(0xa1), Z(0x3b), Z(0x18), Z(0x12), Z(0x17), Z(0xb0),\n\tZ(0x98), Z(0x8d), Z(0x0b), Z(0x23), Z(0xc3), Z(0x3a), Z(0x2d), Z(0x20),\n\tZ(0xdf), Z(0x13), Z(0xa0), Z(0xa8), Z(0x4c), Z(0x0d), Z(0x6c), Z(0x2f),\n\tZ(0x47), Z(0x13), Z(0x13), Z(0x52), Z(0x1f), Z(0x2d), Z(0xf5), Z(0x79),\n\tZ(0x3d), Z(0xa2), Z(0x54), Z(0xbd), Z(0x69), Z(0xc8), Z(0x6b), Z(0xf3),\n\tZ(0x05), Z(0x28), Z(0xf1), Z(0x16), Z(0x46), Z(0x40), Z(0xb0), Z(0x11),\n\tZ(0xd3), Z(0xb7), Z(0x95), Z(0x49), Z(0xcf), Z(0xc3), Z(0x1d), Z(0x8f),\n\tZ(0xd8), Z(0xe1), Z(0x73), Z(0xdb), Z(0xad), Z(0xc8), Z(0xc9), Z(0xa9),\n\tZ(0xa1), Z(0xc2), Z(0xc5), Z(0xe3), Z(0xba), Z(0xfc), Z(0x0e), Z(0x25)\n};\n\n/*\n * This is a 16 round Feistel network with permutation F_ENCRYPT\n */\n#define F_ENCRYPT(R, L, sched)\t\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tunion lc4 { __be32 l; u8 c[4]; } u;\t\t\t\t\\\n\tu.l = sched ^ R;\t\t\t\t\t\t\\\n\tL ^= sbox0[u.c[0]] ^ sbox1[u.c[1]] ^ sbox2[u.c[2]] ^ sbox3[u.c[3]]; \\\n} while (0)\n\n/*\n * encryptor\n */\nstatic void fcrypt_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tconst struct fcrypt_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct {\n\t\t__be32 l, r;\n\t} X;\n\n\tmemcpy(&X, src, sizeof(X));\n\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0x0]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0x1]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0x2]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0x3]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0x4]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0x5]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0x6]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0x7]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0x8]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0x9]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0xa]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0xb]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0xc]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0xd]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0xe]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0xf]);\n\n\tmemcpy(dst, &X, sizeof(X));\n}\n\n/*\n * decryptor\n */\nstatic void fcrypt_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tconst struct fcrypt_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct {\n\t\t__be32 l, r;\n\t} X;\n\n\tmemcpy(&X, src, sizeof(X));\n\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0xf]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0xe]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0xd]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0xc]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0xb]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0xa]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0x9]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0x8]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0x7]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0x6]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0x5]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0x4]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0x3]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0x2]);\n\tF_ENCRYPT(X.l, X.r, ctx->sched[0x1]);\n\tF_ENCRYPT(X.r, X.l, ctx->sched[0x0]);\n\n\tmemcpy(dst, &X, sizeof(X));\n}\n\n/*\n * Generate a key schedule from key, the least significant bit in each key byte\n * is parity and shall be ignored. This leaves 56 significant bits in the key\n * to scatter over the 16 key schedules. For each schedule extract the low\n * order 32 bits and use as schedule, then rotate right by 11 bits.\n */\nstatic int fcrypt_setkey(struct crypto_tfm *tfm, const u8 *key, unsigned int keylen)\n{\n\tstruct fcrypt_ctx *ctx = crypto_tfm_ctx(tfm);\n\n#if BITS_PER_LONG == 64  /* the 64-bit version can also be used for 32-bit\n\t\t\t  * kernels - it seems to be faster but the code is\n\t\t\t  * larger */\n\n\tu64 k;\t/* k holds all 56 non-parity bits */\n\n\t/* discard the parity bits */\n\tk = (*key++) >> 1;\n\tk <<= 7;\n\tk |= (*key++) >> 1;\n\tk <<= 7;\n\tk |= (*key++) >> 1;\n\tk <<= 7;\n\tk |= (*key++) >> 1;\n\tk <<= 7;\n\tk |= (*key++) >> 1;\n\tk <<= 7;\n\tk |= (*key++) >> 1;\n\tk <<= 7;\n\tk |= (*key++) >> 1;\n\tk <<= 7;\n\tk |= (*key) >> 1;\n\n\t/* Use lower 32 bits for schedule, rotate by 11 each round (16 times) */\n\tctx->sched[0x0] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0x1] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0x2] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0x3] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0x4] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0x5] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0x6] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0x7] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0x8] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0x9] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0xa] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0xb] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0xc] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0xd] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0xe] = cpu_to_be32(k); ror56_64(k, 11);\n\tctx->sched[0xf] = cpu_to_be32(k);\n\n\treturn 0;\n#else\n\tu32 hi, lo;\t\t/* hi is upper 24 bits and lo lower 32, total 56 */\n\n\t/* discard the parity bits */\n\tlo = (*key++) >> 1;\n\tlo <<= 7;\n\tlo |= (*key++) >> 1;\n\tlo <<= 7;\n\tlo |= (*key++) >> 1;\n\tlo <<= 7;\n\tlo |= (*key++) >> 1;\n\thi = lo >> 4;\n\tlo &= 0xf;\n\tlo <<= 7;\n\tlo |= (*key++) >> 1;\n\tlo <<= 7;\n\tlo |= (*key++) >> 1;\n\tlo <<= 7;\n\tlo |= (*key++) >> 1;\n\tlo <<= 7;\n\tlo |= (*key) >> 1;\n\n\t/* Use lower 32 bits for schedule, rotate by 11 each round (16 times) */\n\tctx->sched[0x0] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0x1] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0x2] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0x3] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0x4] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0x5] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0x6] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0x7] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0x8] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0x9] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0xa] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0xb] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0xc] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0xd] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0xe] = cpu_to_be32(lo); ror56(hi, lo, 11);\n\tctx->sched[0xf] = cpu_to_be32(lo);\n\treturn 0;\n#endif\n}\n\nstatic struct crypto_alg fcrypt_alg = {\n\t.cra_name\t\t=\t\"fcrypt\",\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\t8,\n\t.cra_ctxsize\t\t=\tsizeof(struct fcrypt_ctx),\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_alignmask\t\t=\t3,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\t8,\n\t.cia_max_keysize\t=\t8,\n\t.cia_setkey\t\t=\tfcrypt_setkey,\n\t.cia_encrypt\t\t=\tfcrypt_encrypt,\n\t.cia_decrypt\t\t=\tfcrypt_decrypt } }\n};\n\nstatic int __init fcrypt_mod_init(void)\n{\n\treturn crypto_register_alg(&fcrypt_alg);\n}\n\nstatic void __exit fcrypt_mod_fini(void)\n{\n\tcrypto_unregister_alg(&fcrypt_alg);\n}\n\nmodule_init(fcrypt_mod_init);\nmodule_exit(fcrypt_mod_fini);\n\nMODULE_LICENSE(\"Dual BSD/GPL\");\nMODULE_DESCRIPTION(\"FCrypt Cipher Algorithm\");\nMODULE_AUTHOR(\"David Howells <dhowells@redhat.com>\");\nMODULE_ALIAS_CRYPTO(\"fcrypt\");\n", "/*\n * GCM: Galois/Counter Mode.\n *\n * Copyright (c) 2007 Nokia Siemens Networks - Mikko Herranen <mh1@iki.fi>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License version 2 as published\n * by the Free Software Foundation.\n */\n\n#include <crypto/gf128mul.h>\n#include <crypto/internal/aead.h>\n#include <crypto/internal/skcipher.h>\n#include <crypto/internal/hash.h>\n#include <crypto/scatterwalk.h>\n#include <crypto/hash.h>\n#include \"internal.h\"\n#include <linux/completion.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/slab.h>\n\nstruct gcm_instance_ctx {\n\tstruct crypto_skcipher_spawn ctr;\n\tstruct crypto_ahash_spawn ghash;\n};\n\nstruct crypto_gcm_ctx {\n\tstruct crypto_ablkcipher *ctr;\n\tstruct crypto_ahash *ghash;\n};\n\nstruct crypto_rfc4106_ctx {\n\tstruct crypto_aead *child;\n\tu8 nonce[4];\n};\n\nstruct crypto_rfc4543_instance_ctx {\n\tstruct crypto_aead_spawn aead;\n\tstruct crypto_skcipher_spawn null;\n};\n\nstruct crypto_rfc4543_ctx {\n\tstruct crypto_aead *child;\n\tstruct crypto_blkcipher *null;\n\tu8 nonce[4];\n};\n\nstruct crypto_rfc4543_req_ctx {\n\tu8 auth_tag[16];\n\tu8 assocbuf[32];\n\tstruct scatterlist cipher[1];\n\tstruct scatterlist payload[2];\n\tstruct scatterlist assoc[2];\n\tstruct aead_request subreq;\n};\n\nstruct crypto_gcm_ghash_ctx {\n\tunsigned int cryptlen;\n\tstruct scatterlist *src;\n\tvoid (*complete)(struct aead_request *req, int err);\n};\n\nstruct crypto_gcm_req_priv_ctx {\n\tu8 auth_tag[16];\n\tu8 iauth_tag[16];\n\tstruct scatterlist src[2];\n\tstruct scatterlist dst[2];\n\tstruct crypto_gcm_ghash_ctx ghash_ctx;\n\tunion {\n\t\tstruct ahash_request ahreq;\n\t\tstruct ablkcipher_request abreq;\n\t} u;\n};\n\nstruct crypto_gcm_setkey_result {\n\tint err;\n\tstruct completion completion;\n};\n\nstatic void *gcm_zeroes;\n\nstatic inline struct crypto_gcm_req_priv_ctx *crypto_gcm_reqctx(\n\tstruct aead_request *req)\n{\n\tunsigned long align = crypto_aead_alignmask(crypto_aead_reqtfm(req));\n\n\treturn (void *)PTR_ALIGN((u8 *)aead_request_ctx(req), align + 1);\n}\n\nstatic void crypto_gcm_setkey_done(struct crypto_async_request *req, int err)\n{\n\tstruct crypto_gcm_setkey_result *result = req->data;\n\n\tif (err == -EINPROGRESS)\n\t\treturn;\n\n\tresult->err = err;\n\tcomplete(&result->completion);\n}\n\nstatic int crypto_gcm_setkey(struct crypto_aead *aead, const u8 *key,\n\t\t\t     unsigned int keylen)\n{\n\tstruct crypto_gcm_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct crypto_ahash *ghash = ctx->ghash;\n\tstruct crypto_ablkcipher *ctr = ctx->ctr;\n\tstruct {\n\t\tbe128 hash;\n\t\tu8 iv[8];\n\n\t\tstruct crypto_gcm_setkey_result result;\n\n\t\tstruct scatterlist sg[1];\n\t\tstruct ablkcipher_request req;\n\t} *data;\n\tint err;\n\n\tcrypto_ablkcipher_clear_flags(ctr, CRYPTO_TFM_REQ_MASK);\n\tcrypto_ablkcipher_set_flags(ctr, crypto_aead_get_flags(aead) &\n\t\t\t\t   CRYPTO_TFM_REQ_MASK);\n\n\terr = crypto_ablkcipher_setkey(ctr, key, keylen);\n\tif (err)\n\t\treturn err;\n\n\tcrypto_aead_set_flags(aead, crypto_ablkcipher_get_flags(ctr) &\n\t\t\t\t       CRYPTO_TFM_RES_MASK);\n\n\tdata = kzalloc(sizeof(*data) + crypto_ablkcipher_reqsize(ctr),\n\t\t       GFP_KERNEL);\n\tif (!data)\n\t\treturn -ENOMEM;\n\n\tinit_completion(&data->result.completion);\n\tsg_init_one(data->sg, &data->hash, sizeof(data->hash));\n\tablkcipher_request_set_tfm(&data->req, ctr);\n\tablkcipher_request_set_callback(&data->req, CRYPTO_TFM_REQ_MAY_SLEEP |\n\t\t\t\t\t\t    CRYPTO_TFM_REQ_MAY_BACKLOG,\n\t\t\t\t\tcrypto_gcm_setkey_done,\n\t\t\t\t\t&data->result);\n\tablkcipher_request_set_crypt(&data->req, data->sg, data->sg,\n\t\t\t\t     sizeof(data->hash), data->iv);\n\n\terr = crypto_ablkcipher_encrypt(&data->req);\n\tif (err == -EINPROGRESS || err == -EBUSY) {\n\t\terr = wait_for_completion_interruptible(\n\t\t\t&data->result.completion);\n\t\tif (!err)\n\t\t\terr = data->result.err;\n\t}\n\n\tif (err)\n\t\tgoto out;\n\n\tcrypto_ahash_clear_flags(ghash, CRYPTO_TFM_REQ_MASK);\n\tcrypto_ahash_set_flags(ghash, crypto_aead_get_flags(aead) &\n\t\t\t       CRYPTO_TFM_REQ_MASK);\n\terr = crypto_ahash_setkey(ghash, (u8 *)&data->hash, sizeof(be128));\n\tcrypto_aead_set_flags(aead, crypto_ahash_get_flags(ghash) &\n\t\t\t      CRYPTO_TFM_RES_MASK);\n\nout:\n\tkfree(data);\n\treturn err;\n}\n\nstatic int crypto_gcm_setauthsize(struct crypto_aead *tfm,\n\t\t\t\t  unsigned int authsize)\n{\n\tswitch (authsize) {\n\tcase 4:\n\tcase 8:\n\tcase 12:\n\tcase 13:\n\tcase 14:\n\tcase 15:\n\tcase 16:\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic void crypto_gcm_init_crypt(struct ablkcipher_request *ablk_req,\n\t\t\t\t  struct aead_request *req,\n\t\t\t\t  unsigned int cryptlen)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_gcm_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct scatterlist *dst;\n\t__be32 counter = cpu_to_be32(1);\n\n\tmemset(pctx->auth_tag, 0, sizeof(pctx->auth_tag));\n\tmemcpy(req->iv + 12, &counter, 4);\n\n\tsg_init_table(pctx->src, 2);\n\tsg_set_buf(pctx->src, pctx->auth_tag, sizeof(pctx->auth_tag));\n\tscatterwalk_sg_chain(pctx->src, 2, req->src);\n\n\tdst = pctx->src;\n\tif (req->src != req->dst) {\n\t\tsg_init_table(pctx->dst, 2);\n\t\tsg_set_buf(pctx->dst, pctx->auth_tag, sizeof(pctx->auth_tag));\n\t\tscatterwalk_sg_chain(pctx->dst, 2, req->dst);\n\t\tdst = pctx->dst;\n\t}\n\n\tablkcipher_request_set_tfm(ablk_req, ctx->ctr);\n\tablkcipher_request_set_crypt(ablk_req, pctx->src, dst,\n\t\t\t\t     cryptlen + sizeof(pctx->auth_tag),\n\t\t\t\t     req->iv);\n}\n\nstatic inline unsigned int gcm_remain(unsigned int len)\n{\n\tlen &= 0xfU;\n\treturn len ? 16 - len : 0;\n}\n\nstatic void gcm_hash_len_done(struct crypto_async_request *areq, int err);\nstatic void gcm_hash_final_done(struct crypto_async_request *areq, int err);\n\nstatic int gcm_hash_update(struct aead_request *req,\n\t\t\t   struct crypto_gcm_req_priv_ctx *pctx,\n\t\t\t   crypto_completion_t compl,\n\t\t\t   struct scatterlist *src,\n\t\t\t   unsigned int len)\n{\n\tstruct ahash_request *ahreq = &pctx->u.ahreq;\n\n\tahash_request_set_callback(ahreq, aead_request_flags(req),\n\t\t\t\t   compl, req);\n\tahash_request_set_crypt(ahreq, src, NULL, len);\n\n\treturn crypto_ahash_update(ahreq);\n}\n\nstatic int gcm_hash_remain(struct aead_request *req,\n\t\t\t   struct crypto_gcm_req_priv_ctx *pctx,\n\t\t\t   unsigned int remain,\n\t\t\t   crypto_completion_t compl)\n{\n\tstruct ahash_request *ahreq = &pctx->u.ahreq;\n\n\tahash_request_set_callback(ahreq, aead_request_flags(req),\n\t\t\t\t   compl, req);\n\tsg_init_one(pctx->src, gcm_zeroes, remain);\n\tahash_request_set_crypt(ahreq, pctx->src, NULL, remain);\n\n\treturn crypto_ahash_update(ahreq);\n}\n\nstatic int gcm_hash_len(struct aead_request *req,\n\t\t\tstruct crypto_gcm_req_priv_ctx *pctx)\n{\n\tstruct ahash_request *ahreq = &pctx->u.ahreq;\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\tu128 lengths;\n\n\tlengths.a = cpu_to_be64(req->assoclen * 8);\n\tlengths.b = cpu_to_be64(gctx->cryptlen * 8);\n\tmemcpy(pctx->iauth_tag, &lengths, 16);\n\tsg_init_one(pctx->src, pctx->iauth_tag, 16);\n\tahash_request_set_callback(ahreq, aead_request_flags(req),\n\t\t\t\t   gcm_hash_len_done, req);\n\tahash_request_set_crypt(ahreq, pctx->src,\n\t\t\t\tNULL, sizeof(lengths));\n\n\treturn crypto_ahash_update(ahreq);\n}\n\nstatic int gcm_hash_final(struct aead_request *req,\n\t\t\t  struct crypto_gcm_req_priv_ctx *pctx)\n{\n\tstruct ahash_request *ahreq = &pctx->u.ahreq;\n\n\tahash_request_set_callback(ahreq, aead_request_flags(req),\n\t\t\t\t   gcm_hash_final_done, req);\n\tahash_request_set_crypt(ahreq, NULL, pctx->iauth_tag, 0);\n\n\treturn crypto_ahash_final(ahreq);\n}\n\nstatic void __gcm_hash_final_done(struct aead_request *req, int err)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\n\tif (!err)\n\t\tcrypto_xor(pctx->auth_tag, pctx->iauth_tag, 16);\n\n\tgctx->complete(req, err);\n}\n\nstatic void gcm_hash_final_done(struct crypto_async_request *areq, int err)\n{\n\tstruct aead_request *req = areq->data;\n\n\t__gcm_hash_final_done(req, err);\n}\n\nstatic void __gcm_hash_len_done(struct aead_request *req, int err)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\n\tif (!err) {\n\t\terr = gcm_hash_final(req, pctx);\n\t\tif (err == -EINPROGRESS || err == -EBUSY)\n\t\t\treturn;\n\t}\n\n\t__gcm_hash_final_done(req, err);\n}\n\nstatic void gcm_hash_len_done(struct crypto_async_request *areq, int err)\n{\n\tstruct aead_request *req = areq->data;\n\n\t__gcm_hash_len_done(req, err);\n}\n\nstatic void __gcm_hash_crypt_remain_done(struct aead_request *req, int err)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\n\tif (!err) {\n\t\terr = gcm_hash_len(req, pctx);\n\t\tif (err == -EINPROGRESS || err == -EBUSY)\n\t\t\treturn;\n\t}\n\n\t__gcm_hash_len_done(req, err);\n}\n\nstatic void gcm_hash_crypt_remain_done(struct crypto_async_request *areq,\n\t\t\t\t       int err)\n{\n\tstruct aead_request *req = areq->data;\n\n\t__gcm_hash_crypt_remain_done(req, err);\n}\n\nstatic void __gcm_hash_crypt_done(struct aead_request *req, int err)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\tunsigned int remain;\n\n\tif (!err) {\n\t\tremain = gcm_remain(gctx->cryptlen);\n\t\tBUG_ON(!remain);\n\t\terr = gcm_hash_remain(req, pctx, remain,\n\t\t\t\t      gcm_hash_crypt_remain_done);\n\t\tif (err == -EINPROGRESS || err == -EBUSY)\n\t\t\treturn;\n\t}\n\n\t__gcm_hash_crypt_remain_done(req, err);\n}\n\nstatic void gcm_hash_crypt_done(struct crypto_async_request *areq, int err)\n{\n\tstruct aead_request *req = areq->data;\n\n\t__gcm_hash_crypt_done(req, err);\n}\n\nstatic void __gcm_hash_assoc_remain_done(struct aead_request *req, int err)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\tcrypto_completion_t compl;\n\tunsigned int remain = 0;\n\n\tif (!err && gctx->cryptlen) {\n\t\tremain = gcm_remain(gctx->cryptlen);\n\t\tcompl = remain ? gcm_hash_crypt_done :\n\t\t\tgcm_hash_crypt_remain_done;\n\t\terr = gcm_hash_update(req, pctx, compl,\n\t\t\t\t      gctx->src, gctx->cryptlen);\n\t\tif (err == -EINPROGRESS || err == -EBUSY)\n\t\t\treturn;\n\t}\n\n\tif (remain)\n\t\t__gcm_hash_crypt_done(req, err);\n\telse\n\t\t__gcm_hash_crypt_remain_done(req, err);\n}\n\nstatic void gcm_hash_assoc_remain_done(struct crypto_async_request *areq,\n\t\t\t\t       int err)\n{\n\tstruct aead_request *req = areq->data;\n\n\t__gcm_hash_assoc_remain_done(req, err);\n}\n\nstatic void __gcm_hash_assoc_done(struct aead_request *req, int err)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tunsigned int remain;\n\n\tif (!err) {\n\t\tremain = gcm_remain(req->assoclen);\n\t\tBUG_ON(!remain);\n\t\terr = gcm_hash_remain(req, pctx, remain,\n\t\t\t\t      gcm_hash_assoc_remain_done);\n\t\tif (err == -EINPROGRESS || err == -EBUSY)\n\t\t\treturn;\n\t}\n\n\t__gcm_hash_assoc_remain_done(req, err);\n}\n\nstatic void gcm_hash_assoc_done(struct crypto_async_request *areq, int err)\n{\n\tstruct aead_request *req = areq->data;\n\n\t__gcm_hash_assoc_done(req, err);\n}\n\nstatic void __gcm_hash_init_done(struct aead_request *req, int err)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tcrypto_completion_t compl;\n\tunsigned int remain = 0;\n\n\tif (!err && req->assoclen) {\n\t\tremain = gcm_remain(req->assoclen);\n\t\tcompl = remain ? gcm_hash_assoc_done :\n\t\t\tgcm_hash_assoc_remain_done;\n\t\terr = gcm_hash_update(req, pctx, compl,\n\t\t\t\t      req->assoc, req->assoclen);\n\t\tif (err == -EINPROGRESS || err == -EBUSY)\n\t\t\treturn;\n\t}\n\n\tif (remain)\n\t\t__gcm_hash_assoc_done(req, err);\n\telse\n\t\t__gcm_hash_assoc_remain_done(req, err);\n}\n\nstatic void gcm_hash_init_done(struct crypto_async_request *areq, int err)\n{\n\tstruct aead_request *req = areq->data;\n\n\t__gcm_hash_init_done(req, err);\n}\n\nstatic int gcm_hash(struct aead_request *req,\n\t\t    struct crypto_gcm_req_priv_ctx *pctx)\n{\n\tstruct ahash_request *ahreq = &pctx->u.ahreq;\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\tstruct crypto_gcm_ctx *ctx = crypto_tfm_ctx(req->base.tfm);\n\tunsigned int remain;\n\tcrypto_completion_t compl;\n\tint err;\n\n\tahash_request_set_tfm(ahreq, ctx->ghash);\n\n\tahash_request_set_callback(ahreq, aead_request_flags(req),\n\t\t\t\t   gcm_hash_init_done, req);\n\terr = crypto_ahash_init(ahreq);\n\tif (err)\n\t\treturn err;\n\tremain = gcm_remain(req->assoclen);\n\tcompl = remain ? gcm_hash_assoc_done : gcm_hash_assoc_remain_done;\n\terr = gcm_hash_update(req, pctx, compl, req->assoc, req->assoclen);\n\tif (err)\n\t\treturn err;\n\tif (remain) {\n\t\terr = gcm_hash_remain(req, pctx, remain,\n\t\t\t\t      gcm_hash_assoc_remain_done);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\tremain = gcm_remain(gctx->cryptlen);\n\tcompl = remain ? gcm_hash_crypt_done : gcm_hash_crypt_remain_done;\n\terr = gcm_hash_update(req, pctx, compl, gctx->src, gctx->cryptlen);\n\tif (err)\n\t\treturn err;\n\tif (remain) {\n\t\terr = gcm_hash_remain(req, pctx, remain,\n\t\t\t\t      gcm_hash_crypt_remain_done);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\terr = gcm_hash_len(req, pctx);\n\tif (err)\n\t\treturn err;\n\terr = gcm_hash_final(req, pctx);\n\tif (err)\n\t\treturn err;\n\n\treturn 0;\n}\n\nstatic void gcm_enc_copy_hash(struct aead_request *req,\n\t\t\t      struct crypto_gcm_req_priv_ctx *pctx)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tu8 *auth_tag = pctx->auth_tag;\n\n\tscatterwalk_map_and_copy(auth_tag, req->dst, req->cryptlen,\n\t\t\t\t crypto_aead_authsize(aead), 1);\n}\n\nstatic void gcm_enc_hash_done(struct aead_request *req, int err)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\n\tif (!err)\n\t\tgcm_enc_copy_hash(req, pctx);\n\n\taead_request_complete(req, err);\n}\n\nstatic void gcm_encrypt_done(struct crypto_async_request *areq, int err)\n{\n\tstruct aead_request *req = areq->data;\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\n\tif (!err) {\n\t\terr = gcm_hash(req, pctx);\n\t\tif (err == -EINPROGRESS || err == -EBUSY)\n\t\t\treturn;\n\t\telse if (!err) {\n\t\t\tcrypto_xor(pctx->auth_tag, pctx->iauth_tag, 16);\n\t\t\tgcm_enc_copy_hash(req, pctx);\n\t\t}\n\t}\n\n\taead_request_complete(req, err);\n}\n\nstatic int crypto_gcm_encrypt(struct aead_request *req)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct ablkcipher_request *abreq = &pctx->u.abreq;\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\tint err;\n\n\tcrypto_gcm_init_crypt(abreq, req, req->cryptlen);\n\tablkcipher_request_set_callback(abreq, aead_request_flags(req),\n\t\t\t\t\tgcm_encrypt_done, req);\n\n\tgctx->src = req->dst;\n\tgctx->cryptlen = req->cryptlen;\n\tgctx->complete = gcm_enc_hash_done;\n\n\terr = crypto_ablkcipher_encrypt(abreq);\n\tif (err)\n\t\treturn err;\n\n\terr = gcm_hash(req, pctx);\n\tif (err)\n\t\treturn err;\n\n\tcrypto_xor(pctx->auth_tag, pctx->iauth_tag, 16);\n\tgcm_enc_copy_hash(req, pctx);\n\n\treturn 0;\n}\n\nstatic int crypto_gcm_verify(struct aead_request *req,\n\t\t\t     struct crypto_gcm_req_priv_ctx *pctx)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tu8 *auth_tag = pctx->auth_tag;\n\tu8 *iauth_tag = pctx->iauth_tag;\n\tunsigned int authsize = crypto_aead_authsize(aead);\n\tunsigned int cryptlen = req->cryptlen - authsize;\n\n\tcrypto_xor(auth_tag, iauth_tag, 16);\n\tscatterwalk_map_and_copy(iauth_tag, req->src, cryptlen, authsize, 0);\n\treturn crypto_memneq(iauth_tag, auth_tag, authsize) ? -EBADMSG : 0;\n}\n\nstatic void gcm_decrypt_done(struct crypto_async_request *areq, int err)\n{\n\tstruct aead_request *req = areq->data;\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\n\tif (!err)\n\t\terr = crypto_gcm_verify(req, pctx);\n\n\taead_request_complete(req, err);\n}\n\nstatic void gcm_dec_hash_done(struct aead_request *req, int err)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct ablkcipher_request *abreq = &pctx->u.abreq;\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\n\tif (!err) {\n\t\tablkcipher_request_set_callback(abreq, aead_request_flags(req),\n\t\t\t\t\t\tgcm_decrypt_done, req);\n\t\tcrypto_gcm_init_crypt(abreq, req, gctx->cryptlen);\n\t\terr = crypto_ablkcipher_decrypt(abreq);\n\t\tif (err == -EINPROGRESS || err == -EBUSY)\n\t\t\treturn;\n\t\telse if (!err)\n\t\t\terr = crypto_gcm_verify(req, pctx);\n\t}\n\n\taead_request_complete(req, err);\n}\n\nstatic int crypto_gcm_decrypt(struct aead_request *req)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct ablkcipher_request *abreq = &pctx->u.abreq;\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\tunsigned int authsize = crypto_aead_authsize(aead);\n\tunsigned int cryptlen = req->cryptlen;\n\tint err;\n\n\tif (cryptlen < authsize)\n\t\treturn -EINVAL;\n\tcryptlen -= authsize;\n\n\tgctx->src = req->src;\n\tgctx->cryptlen = cryptlen;\n\tgctx->complete = gcm_dec_hash_done;\n\n\terr = gcm_hash(req, pctx);\n\tif (err)\n\t\treturn err;\n\n\tablkcipher_request_set_callback(abreq, aead_request_flags(req),\n\t\t\t\t\tgcm_decrypt_done, req);\n\tcrypto_gcm_init_crypt(abreq, req, cryptlen);\n\terr = crypto_ablkcipher_decrypt(abreq);\n\tif (err)\n\t\treturn err;\n\n\treturn crypto_gcm_verify(req, pctx);\n}\n\nstatic int crypto_gcm_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_instance *inst = (void *)tfm->__crt_alg;\n\tstruct gcm_instance_ctx *ictx = crypto_instance_ctx(inst);\n\tstruct crypto_gcm_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_ablkcipher *ctr;\n\tstruct crypto_ahash *ghash;\n\tunsigned long align;\n\tint err;\n\n\tghash = crypto_spawn_ahash(&ictx->ghash);\n\tif (IS_ERR(ghash))\n\t\treturn PTR_ERR(ghash);\n\n\tctr = crypto_spawn_skcipher(&ictx->ctr);\n\terr = PTR_ERR(ctr);\n\tif (IS_ERR(ctr))\n\t\tgoto err_free_hash;\n\n\tctx->ctr = ctr;\n\tctx->ghash = ghash;\n\n\talign = crypto_tfm_alg_alignmask(tfm);\n\talign &= ~(crypto_tfm_ctx_alignment() - 1);\n\ttfm->crt_aead.reqsize = align +\n\t\toffsetof(struct crypto_gcm_req_priv_ctx, u) +\n\t\tmax(sizeof(struct ablkcipher_request) +\n\t\t    crypto_ablkcipher_reqsize(ctr),\n\t\t    sizeof(struct ahash_request) +\n\t\t    crypto_ahash_reqsize(ghash));\n\n\treturn 0;\n\nerr_free_hash:\n\tcrypto_free_ahash(ghash);\n\treturn err;\n}\n\nstatic void crypto_gcm_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_gcm_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_ahash(ctx->ghash);\n\tcrypto_free_ablkcipher(ctx->ctr);\n}\n\nstatic struct crypto_instance *crypto_gcm_alloc_common(struct rtattr **tb,\n\t\t\t\t\t\t       const char *full_name,\n\t\t\t\t\t\t       const char *ctr_name,\n\t\t\t\t\t\t       const char *ghash_name)\n{\n\tstruct crypto_attr_type *algt;\n\tstruct crypto_instance *inst;\n\tstruct crypto_alg *ctr;\n\tstruct crypto_alg *ghash_alg;\n\tstruct ahash_alg *ghash_ahash_alg;\n\tstruct gcm_instance_ctx *ctx;\n\tint err;\n\n\talgt = crypto_get_attr_type(tb);\n\tif (IS_ERR(algt))\n\t\treturn ERR_CAST(algt);\n\n\tif ((algt->type ^ CRYPTO_ALG_TYPE_AEAD) & algt->mask)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tghash_alg = crypto_find_alg(ghash_name, &crypto_ahash_type,\n\t\t\t\t    CRYPTO_ALG_TYPE_HASH,\n\t\t\t\t    CRYPTO_ALG_TYPE_AHASH_MASK);\n\tif (IS_ERR(ghash_alg))\n\t\treturn ERR_CAST(ghash_alg);\n\n\terr = -ENOMEM;\n\tinst = kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);\n\tif (!inst)\n\t\tgoto out_put_ghash;\n\n\tctx = crypto_instance_ctx(inst);\n\tghash_ahash_alg = container_of(ghash_alg, struct ahash_alg, halg.base);\n\terr = crypto_init_ahash_spawn(&ctx->ghash, &ghash_ahash_alg->halg,\n\t\t\t\t      inst);\n\tif (err)\n\t\tgoto err_free_inst;\n\n\tcrypto_set_skcipher_spawn(&ctx->ctr, inst);\n\terr = crypto_grab_skcipher(&ctx->ctr, ctr_name, 0,\n\t\t\t\t   crypto_requires_sync(algt->type,\n\t\t\t\t\t\t\talgt->mask));\n\tif (err)\n\t\tgoto err_drop_ghash;\n\n\tctr = crypto_skcipher_spawn_alg(&ctx->ctr);\n\n\t/* We only support 16-byte blocks. */\n\tif (ctr->cra_ablkcipher.ivsize != 16)\n\t\tgoto out_put_ctr;\n\n\t/* Not a stream cipher? */\n\terr = -EINVAL;\n\tif (ctr->cra_blocksize != 1)\n\t\tgoto out_put_ctr;\n\n\terr = -ENAMETOOLONG;\n\tif (snprintf(inst->alg.cra_driver_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"gcm_base(%s,%s)\", ctr->cra_driver_name,\n\t\t     ghash_alg->cra_driver_name) >=\n\t    CRYPTO_MAX_ALG_NAME)\n\t\tgoto out_put_ctr;\n\n\tmemcpy(inst->alg.cra_name, full_name, CRYPTO_MAX_ALG_NAME);\n\n\tinst->alg.cra_flags = CRYPTO_ALG_TYPE_AEAD;\n\tinst->alg.cra_flags |= ctr->cra_flags & CRYPTO_ALG_ASYNC;\n\tinst->alg.cra_priority = ctr->cra_priority;\n\tinst->alg.cra_blocksize = 1;\n\tinst->alg.cra_alignmask = ctr->cra_alignmask | (__alignof__(u64) - 1);\n\tinst->alg.cra_type = &crypto_aead_type;\n\tinst->alg.cra_aead.ivsize = 16;\n\tinst->alg.cra_aead.maxauthsize = 16;\n\tinst->alg.cra_ctxsize = sizeof(struct crypto_gcm_ctx);\n\tinst->alg.cra_init = crypto_gcm_init_tfm;\n\tinst->alg.cra_exit = crypto_gcm_exit_tfm;\n\tinst->alg.cra_aead.setkey = crypto_gcm_setkey;\n\tinst->alg.cra_aead.setauthsize = crypto_gcm_setauthsize;\n\tinst->alg.cra_aead.encrypt = crypto_gcm_encrypt;\n\tinst->alg.cra_aead.decrypt = crypto_gcm_decrypt;\n\nout:\n\tcrypto_mod_put(ghash_alg);\n\treturn inst;\n\nout_put_ctr:\n\tcrypto_drop_skcipher(&ctx->ctr);\nerr_drop_ghash:\n\tcrypto_drop_ahash(&ctx->ghash);\nerr_free_inst:\n\tkfree(inst);\nout_put_ghash:\n\tinst = ERR_PTR(err);\n\tgoto out;\n}\n\nstatic struct crypto_instance *crypto_gcm_alloc(struct rtattr **tb)\n{\n\tconst char *cipher_name;\n\tchar ctr_name[CRYPTO_MAX_ALG_NAME];\n\tchar full_name[CRYPTO_MAX_ALG_NAME];\n\n\tcipher_name = crypto_attr_alg_name(tb[1]);\n\tif (IS_ERR(cipher_name))\n\t\treturn ERR_CAST(cipher_name);\n\n\tif (snprintf(ctr_name, CRYPTO_MAX_ALG_NAME, \"ctr(%s)\", cipher_name) >=\n\t    CRYPTO_MAX_ALG_NAME)\n\t\treturn ERR_PTR(-ENAMETOOLONG);\n\n\tif (snprintf(full_name, CRYPTO_MAX_ALG_NAME, \"gcm(%s)\", cipher_name) >=\n\t    CRYPTO_MAX_ALG_NAME)\n\t\treturn ERR_PTR(-ENAMETOOLONG);\n\n\treturn crypto_gcm_alloc_common(tb, full_name, ctr_name, \"ghash\");\n}\n\nstatic void crypto_gcm_free(struct crypto_instance *inst)\n{\n\tstruct gcm_instance_ctx *ctx = crypto_instance_ctx(inst);\n\n\tcrypto_drop_skcipher(&ctx->ctr);\n\tcrypto_drop_ahash(&ctx->ghash);\n\tkfree(inst);\n}\n\nstatic struct crypto_template crypto_gcm_tmpl = {\n\t.name = \"gcm\",\n\t.alloc = crypto_gcm_alloc,\n\t.free = crypto_gcm_free,\n\t.module = THIS_MODULE,\n};\n\nstatic struct crypto_instance *crypto_gcm_base_alloc(struct rtattr **tb)\n{\n\tconst char *ctr_name;\n\tconst char *ghash_name;\n\tchar full_name[CRYPTO_MAX_ALG_NAME];\n\n\tctr_name = crypto_attr_alg_name(tb[1]);\n\tif (IS_ERR(ctr_name))\n\t\treturn ERR_CAST(ctr_name);\n\n\tghash_name = crypto_attr_alg_name(tb[2]);\n\tif (IS_ERR(ghash_name))\n\t\treturn ERR_CAST(ghash_name);\n\n\tif (snprintf(full_name, CRYPTO_MAX_ALG_NAME, \"gcm_base(%s,%s)\",\n\t\t     ctr_name, ghash_name) >= CRYPTO_MAX_ALG_NAME)\n\t\treturn ERR_PTR(-ENAMETOOLONG);\n\n\treturn crypto_gcm_alloc_common(tb, full_name, ctr_name, ghash_name);\n}\n\nstatic struct crypto_template crypto_gcm_base_tmpl = {\n\t.name = \"gcm_base\",\n\t.alloc = crypto_gcm_base_alloc,\n\t.free = crypto_gcm_free,\n\t.module = THIS_MODULE,\n};\n\nstatic int crypto_rfc4106_setkey(struct crypto_aead *parent, const u8 *key,\n\t\t\t\t unsigned int keylen)\n{\n\tstruct crypto_rfc4106_ctx *ctx = crypto_aead_ctx(parent);\n\tstruct crypto_aead *child = ctx->child;\n\tint err;\n\n\tif (keylen < 4)\n\t\treturn -EINVAL;\n\n\tkeylen -= 4;\n\tmemcpy(ctx->nonce, key + keylen, 4);\n\n\tcrypto_aead_clear_flags(child, CRYPTO_TFM_REQ_MASK);\n\tcrypto_aead_set_flags(child, crypto_aead_get_flags(parent) &\n\t\t\t\t     CRYPTO_TFM_REQ_MASK);\n\terr = crypto_aead_setkey(child, key, keylen);\n\tcrypto_aead_set_flags(parent, crypto_aead_get_flags(child) &\n\t\t\t\t      CRYPTO_TFM_RES_MASK);\n\n\treturn err;\n}\n\nstatic int crypto_rfc4106_setauthsize(struct crypto_aead *parent,\n\t\t\t\t      unsigned int authsize)\n{\n\tstruct crypto_rfc4106_ctx *ctx = crypto_aead_ctx(parent);\n\n\tswitch (authsize) {\n\tcase 8:\n\tcase 12:\n\tcase 16:\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn crypto_aead_setauthsize(ctx->child, authsize);\n}\n\nstatic struct aead_request *crypto_rfc4106_crypt(struct aead_request *req)\n{\n\tstruct aead_request *subreq = aead_request_ctx(req);\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_rfc4106_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct crypto_aead *child = ctx->child;\n\tu8 *iv = PTR_ALIGN((u8 *)(subreq + 1) + crypto_aead_reqsize(child),\n\t\t\t   crypto_aead_alignmask(child) + 1);\n\n\tmemcpy(iv, ctx->nonce, 4);\n\tmemcpy(iv + 4, req->iv, 8);\n\n\taead_request_set_tfm(subreq, child);\n\taead_request_set_callback(subreq, req->base.flags, req->base.complete,\n\t\t\t\t  req->base.data);\n\taead_request_set_crypt(subreq, req->src, req->dst, req->cryptlen, iv);\n\taead_request_set_assoc(subreq, req->assoc, req->assoclen);\n\n\treturn subreq;\n}\n\nstatic int crypto_rfc4106_encrypt(struct aead_request *req)\n{\n\treq = crypto_rfc4106_crypt(req);\n\n\treturn crypto_aead_encrypt(req);\n}\n\nstatic int crypto_rfc4106_decrypt(struct aead_request *req)\n{\n\treq = crypto_rfc4106_crypt(req);\n\n\treturn crypto_aead_decrypt(req);\n}\n\nstatic int crypto_rfc4106_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_instance *inst = (void *)tfm->__crt_alg;\n\tstruct crypto_aead_spawn *spawn = crypto_instance_ctx(inst);\n\tstruct crypto_rfc4106_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_aead *aead;\n\tunsigned long align;\n\n\taead = crypto_spawn_aead(spawn);\n\tif (IS_ERR(aead))\n\t\treturn PTR_ERR(aead);\n\n\tctx->child = aead;\n\n\talign = crypto_aead_alignmask(aead);\n\talign &= ~(crypto_tfm_ctx_alignment() - 1);\n\ttfm->crt_aead.reqsize = sizeof(struct aead_request) +\n\t\t\t\tALIGN(crypto_aead_reqsize(aead),\n\t\t\t\t      crypto_tfm_ctx_alignment()) +\n\t\t\t\talign + 16;\n\n\treturn 0;\n}\n\nstatic void crypto_rfc4106_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_rfc4106_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_aead(ctx->child);\n}\n\nstatic struct crypto_instance *crypto_rfc4106_alloc(struct rtattr **tb)\n{\n\tstruct crypto_attr_type *algt;\n\tstruct crypto_instance *inst;\n\tstruct crypto_aead_spawn *spawn;\n\tstruct crypto_alg *alg;\n\tconst char *ccm_name;\n\tint err;\n\n\talgt = crypto_get_attr_type(tb);\n\tif (IS_ERR(algt))\n\t\treturn ERR_CAST(algt);\n\n\tif ((algt->type ^ CRYPTO_ALG_TYPE_AEAD) & algt->mask)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tccm_name = crypto_attr_alg_name(tb[1]);\n\tif (IS_ERR(ccm_name))\n\t\treturn ERR_CAST(ccm_name);\n\n\tinst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);\n\tif (!inst)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tspawn = crypto_instance_ctx(inst);\n\tcrypto_set_aead_spawn(spawn, inst);\n\terr = crypto_grab_aead(spawn, ccm_name, 0,\n\t\t\t       crypto_requires_sync(algt->type, algt->mask));\n\tif (err)\n\t\tgoto out_free_inst;\n\n\talg = crypto_aead_spawn_alg(spawn);\n\n\terr = -EINVAL;\n\n\t/* We only support 16-byte blocks. */\n\tif (alg->cra_aead.ivsize != 16)\n\t\tgoto out_drop_alg;\n\n\t/* Not a stream cipher? */\n\tif (alg->cra_blocksize != 1)\n\t\tgoto out_drop_alg;\n\n\terr = -ENAMETOOLONG;\n\tif (snprintf(inst->alg.cra_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"rfc4106(%s)\", alg->cra_name) >= CRYPTO_MAX_ALG_NAME ||\n\t    snprintf(inst->alg.cra_driver_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"rfc4106(%s)\", alg->cra_driver_name) >=\n\t    CRYPTO_MAX_ALG_NAME)\n\t\tgoto out_drop_alg;\n\n\tinst->alg.cra_flags = CRYPTO_ALG_TYPE_AEAD;\n\tinst->alg.cra_flags |= alg->cra_flags & CRYPTO_ALG_ASYNC;\n\tinst->alg.cra_priority = alg->cra_priority;\n\tinst->alg.cra_blocksize = 1;\n\tinst->alg.cra_alignmask = alg->cra_alignmask;\n\tinst->alg.cra_type = &crypto_nivaead_type;\n\n\tinst->alg.cra_aead.ivsize = 8;\n\tinst->alg.cra_aead.maxauthsize = 16;\n\n\tinst->alg.cra_ctxsize = sizeof(struct crypto_rfc4106_ctx);\n\n\tinst->alg.cra_init = crypto_rfc4106_init_tfm;\n\tinst->alg.cra_exit = crypto_rfc4106_exit_tfm;\n\n\tinst->alg.cra_aead.setkey = crypto_rfc4106_setkey;\n\tinst->alg.cra_aead.setauthsize = crypto_rfc4106_setauthsize;\n\tinst->alg.cra_aead.encrypt = crypto_rfc4106_encrypt;\n\tinst->alg.cra_aead.decrypt = crypto_rfc4106_decrypt;\n\n\tinst->alg.cra_aead.geniv = \"seqiv\";\n\nout:\n\treturn inst;\n\nout_drop_alg:\n\tcrypto_drop_aead(spawn);\nout_free_inst:\n\tkfree(inst);\n\tinst = ERR_PTR(err);\n\tgoto out;\n}\n\nstatic void crypto_rfc4106_free(struct crypto_instance *inst)\n{\n\tcrypto_drop_spawn(crypto_instance_ctx(inst));\n\tkfree(inst);\n}\n\nstatic struct crypto_template crypto_rfc4106_tmpl = {\n\t.name = \"rfc4106\",\n\t.alloc = crypto_rfc4106_alloc,\n\t.free = crypto_rfc4106_free,\n\t.module = THIS_MODULE,\n};\n\nstatic inline struct crypto_rfc4543_req_ctx *crypto_rfc4543_reqctx(\n\tstruct aead_request *req)\n{\n\tunsigned long align = crypto_aead_alignmask(crypto_aead_reqtfm(req));\n\n\treturn (void *)PTR_ALIGN((u8 *)aead_request_ctx(req), align + 1);\n}\n\nstatic int crypto_rfc4543_setkey(struct crypto_aead *parent, const u8 *key,\n\t\t\t\t unsigned int keylen)\n{\n\tstruct crypto_rfc4543_ctx *ctx = crypto_aead_ctx(parent);\n\tstruct crypto_aead *child = ctx->child;\n\tint err;\n\n\tif (keylen < 4)\n\t\treturn -EINVAL;\n\n\tkeylen -= 4;\n\tmemcpy(ctx->nonce, key + keylen, 4);\n\n\tcrypto_aead_clear_flags(child, CRYPTO_TFM_REQ_MASK);\n\tcrypto_aead_set_flags(child, crypto_aead_get_flags(parent) &\n\t\t\t\t     CRYPTO_TFM_REQ_MASK);\n\terr = crypto_aead_setkey(child, key, keylen);\n\tcrypto_aead_set_flags(parent, crypto_aead_get_flags(child) &\n\t\t\t\t      CRYPTO_TFM_RES_MASK);\n\n\treturn err;\n}\n\nstatic int crypto_rfc4543_setauthsize(struct crypto_aead *parent,\n\t\t\t\t      unsigned int authsize)\n{\n\tstruct crypto_rfc4543_ctx *ctx = crypto_aead_ctx(parent);\n\n\tif (authsize != 16)\n\t\treturn -EINVAL;\n\n\treturn crypto_aead_setauthsize(ctx->child, authsize);\n}\n\nstatic void crypto_rfc4543_done(struct crypto_async_request *areq, int err)\n{\n\tstruct aead_request *req = areq->data;\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_rfc4543_req_ctx *rctx = crypto_rfc4543_reqctx(req);\n\n\tif (!err) {\n\t\tscatterwalk_map_and_copy(rctx->auth_tag, req->dst,\n\t\t\t\t\t req->cryptlen,\n\t\t\t\t\t crypto_aead_authsize(aead), 1);\n\t}\n\n\taead_request_complete(req, err);\n}\n\nstatic struct aead_request *crypto_rfc4543_crypt(struct aead_request *req,\n\t\t\t\t\t\t bool enc)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_rfc4543_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct crypto_rfc4543_req_ctx *rctx = crypto_rfc4543_reqctx(req);\n\tstruct aead_request *subreq = &rctx->subreq;\n\tstruct scatterlist *src = req->src;\n\tstruct scatterlist *cipher = rctx->cipher;\n\tstruct scatterlist *payload = rctx->payload;\n\tstruct scatterlist *assoc = rctx->assoc;\n\tunsigned int authsize = crypto_aead_authsize(aead);\n\tunsigned int assoclen = req->assoclen;\n\tstruct page *srcp;\n\tu8 *vsrc;\n\tu8 *iv = PTR_ALIGN((u8 *)(rctx + 1) + crypto_aead_reqsize(ctx->child),\n\t\t\t   crypto_aead_alignmask(ctx->child) + 1);\n\n\tmemcpy(iv, ctx->nonce, 4);\n\tmemcpy(iv + 4, req->iv, 8);\n\n\t/* construct cipher/plaintext */\n\tif (enc)\n\t\tmemset(rctx->auth_tag, 0, authsize);\n\telse\n\t\tscatterwalk_map_and_copy(rctx->auth_tag, src,\n\t\t\t\t\t req->cryptlen - authsize,\n\t\t\t\t\t authsize, 0);\n\n\tsg_init_one(cipher, rctx->auth_tag, authsize);\n\n\t/* construct the aad */\n\tsrcp = sg_page(src);\n\tvsrc = PageHighMem(srcp) ? NULL : page_address(srcp) + src->offset;\n\n\tsg_init_table(payload, 2);\n\tsg_set_buf(payload, req->iv, 8);\n\tscatterwalk_crypto_chain(payload, src, vsrc == req->iv + 8, 2);\n\tassoclen += 8 + req->cryptlen - (enc ? 0 : authsize);\n\n\tif (req->assoc->length == req->assoclen) {\n\t\tsg_init_table(assoc, 2);\n\t\tsg_set_page(assoc, sg_page(req->assoc), req->assoc->length,\n\t\t\t    req->assoc->offset);\n\t} else {\n\t\tBUG_ON(req->assoclen > sizeof(rctx->assocbuf));\n\n\t\tscatterwalk_map_and_copy(rctx->assocbuf, req->assoc, 0,\n\t\t\t\t\t req->assoclen, 0);\n\n\t\tsg_init_table(assoc, 2);\n\t\tsg_set_buf(assoc, rctx->assocbuf, req->assoclen);\n\t}\n\tscatterwalk_crypto_chain(assoc, payload, 0, 2);\n\n\taead_request_set_tfm(subreq, ctx->child);\n\taead_request_set_callback(subreq, req->base.flags, crypto_rfc4543_done,\n\t\t\t\t  req);\n\taead_request_set_crypt(subreq, cipher, cipher, enc ? 0 : authsize, iv);\n\taead_request_set_assoc(subreq, assoc, assoclen);\n\n\treturn subreq;\n}\n\nstatic int crypto_rfc4543_copy_src_to_dst(struct aead_request *req, bool enc)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_rfc4543_ctx *ctx = crypto_aead_ctx(aead);\n\tunsigned int authsize = crypto_aead_authsize(aead);\n\tunsigned int nbytes = req->cryptlen - (enc ? 0 : authsize);\n\tstruct blkcipher_desc desc = {\n\t\t.tfm = ctx->null,\n\t};\n\n\treturn crypto_blkcipher_encrypt(&desc, req->dst, req->src, nbytes);\n}\n\nstatic int crypto_rfc4543_encrypt(struct aead_request *req)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_rfc4543_req_ctx *rctx = crypto_rfc4543_reqctx(req);\n\tstruct aead_request *subreq;\n\tint err;\n\n\tif (req->src != req->dst) {\n\t\terr = crypto_rfc4543_copy_src_to_dst(req, true);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tsubreq = crypto_rfc4543_crypt(req, true);\n\terr = crypto_aead_encrypt(subreq);\n\tif (err)\n\t\treturn err;\n\n\tscatterwalk_map_and_copy(rctx->auth_tag, req->dst, req->cryptlen,\n\t\t\t\t crypto_aead_authsize(aead), 1);\n\n\treturn 0;\n}\n\nstatic int crypto_rfc4543_decrypt(struct aead_request *req)\n{\n\tint err;\n\n\tif (req->src != req->dst) {\n\t\terr = crypto_rfc4543_copy_src_to_dst(req, false);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treq = crypto_rfc4543_crypt(req, false);\n\n\treturn crypto_aead_decrypt(req);\n}\n\nstatic int crypto_rfc4543_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_instance *inst = (void *)tfm->__crt_alg;\n\tstruct crypto_rfc4543_instance_ctx *ictx = crypto_instance_ctx(inst);\n\tstruct crypto_aead_spawn *spawn = &ictx->aead;\n\tstruct crypto_rfc4543_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_aead *aead;\n\tstruct crypto_blkcipher *null;\n\tunsigned long align;\n\tint err = 0;\n\n\taead = crypto_spawn_aead(spawn);\n\tif (IS_ERR(aead))\n\t\treturn PTR_ERR(aead);\n\n\tnull = crypto_spawn_blkcipher(&ictx->null.base);\n\terr = PTR_ERR(null);\n\tif (IS_ERR(null))\n\t\tgoto err_free_aead;\n\n\tctx->child = aead;\n\tctx->null = null;\n\n\talign = crypto_aead_alignmask(aead);\n\talign &= ~(crypto_tfm_ctx_alignment() - 1);\n\ttfm->crt_aead.reqsize = sizeof(struct crypto_rfc4543_req_ctx) +\n\t\t\t\tALIGN(crypto_aead_reqsize(aead),\n\t\t\t\t      crypto_tfm_ctx_alignment()) +\n\t\t\t\talign + 16;\n\n\treturn 0;\n\nerr_free_aead:\n\tcrypto_free_aead(aead);\n\treturn err;\n}\n\nstatic void crypto_rfc4543_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_rfc4543_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_aead(ctx->child);\n\tcrypto_free_blkcipher(ctx->null);\n}\n\nstatic struct crypto_instance *crypto_rfc4543_alloc(struct rtattr **tb)\n{\n\tstruct crypto_attr_type *algt;\n\tstruct crypto_instance *inst;\n\tstruct crypto_aead_spawn *spawn;\n\tstruct crypto_alg *alg;\n\tstruct crypto_rfc4543_instance_ctx *ctx;\n\tconst char *ccm_name;\n\tint err;\n\n\talgt = crypto_get_attr_type(tb);\n\tif (IS_ERR(algt))\n\t\treturn ERR_CAST(algt);\n\n\tif ((algt->type ^ CRYPTO_ALG_TYPE_AEAD) & algt->mask)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tccm_name = crypto_attr_alg_name(tb[1]);\n\tif (IS_ERR(ccm_name))\n\t\treturn ERR_CAST(ccm_name);\n\n\tinst = kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);\n\tif (!inst)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tctx = crypto_instance_ctx(inst);\n\tspawn = &ctx->aead;\n\tcrypto_set_aead_spawn(spawn, inst);\n\terr = crypto_grab_aead(spawn, ccm_name, 0,\n\t\t\t       crypto_requires_sync(algt->type, algt->mask));\n\tif (err)\n\t\tgoto out_free_inst;\n\n\talg = crypto_aead_spawn_alg(spawn);\n\n\tcrypto_set_skcipher_spawn(&ctx->null, inst);\n\terr = crypto_grab_skcipher(&ctx->null, \"ecb(cipher_null)\", 0,\n\t\t\t\t   CRYPTO_ALG_ASYNC);\n\tif (err)\n\t\tgoto out_drop_alg;\n\n\tcrypto_skcipher_spawn_alg(&ctx->null);\n\n\terr = -EINVAL;\n\n\t/* We only support 16-byte blocks. */\n\tif (alg->cra_aead.ivsize != 16)\n\t\tgoto out_drop_ecbnull;\n\n\t/* Not a stream cipher? */\n\tif (alg->cra_blocksize != 1)\n\t\tgoto out_drop_ecbnull;\n\n\terr = -ENAMETOOLONG;\n\tif (snprintf(inst->alg.cra_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"rfc4543(%s)\", alg->cra_name) >= CRYPTO_MAX_ALG_NAME ||\n\t    snprintf(inst->alg.cra_driver_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"rfc4543(%s)\", alg->cra_driver_name) >=\n\t    CRYPTO_MAX_ALG_NAME)\n\t\tgoto out_drop_ecbnull;\n\n\tinst->alg.cra_flags = CRYPTO_ALG_TYPE_AEAD;\n\tinst->alg.cra_flags |= alg->cra_flags & CRYPTO_ALG_ASYNC;\n\tinst->alg.cra_priority = alg->cra_priority;\n\tinst->alg.cra_blocksize = 1;\n\tinst->alg.cra_alignmask = alg->cra_alignmask;\n\tinst->alg.cra_type = &crypto_nivaead_type;\n\n\tinst->alg.cra_aead.ivsize = 8;\n\tinst->alg.cra_aead.maxauthsize = 16;\n\n\tinst->alg.cra_ctxsize = sizeof(struct crypto_rfc4543_ctx);\n\n\tinst->alg.cra_init = crypto_rfc4543_init_tfm;\n\tinst->alg.cra_exit = crypto_rfc4543_exit_tfm;\n\n\tinst->alg.cra_aead.setkey = crypto_rfc4543_setkey;\n\tinst->alg.cra_aead.setauthsize = crypto_rfc4543_setauthsize;\n\tinst->alg.cra_aead.encrypt = crypto_rfc4543_encrypt;\n\tinst->alg.cra_aead.decrypt = crypto_rfc4543_decrypt;\n\n\tinst->alg.cra_aead.geniv = \"seqiv\";\n\nout:\n\treturn inst;\n\nout_drop_ecbnull:\n\tcrypto_drop_skcipher(&ctx->null);\nout_drop_alg:\n\tcrypto_drop_aead(spawn);\nout_free_inst:\n\tkfree(inst);\n\tinst = ERR_PTR(err);\n\tgoto out;\n}\n\nstatic void crypto_rfc4543_free(struct crypto_instance *inst)\n{\n\tstruct crypto_rfc4543_instance_ctx *ctx = crypto_instance_ctx(inst);\n\n\tcrypto_drop_aead(&ctx->aead);\n\tcrypto_drop_skcipher(&ctx->null);\n\n\tkfree(inst);\n}\n\nstatic struct crypto_template crypto_rfc4543_tmpl = {\n\t.name = \"rfc4543\",\n\t.alloc = crypto_rfc4543_alloc,\n\t.free = crypto_rfc4543_free,\n\t.module = THIS_MODULE,\n};\n\nstatic int __init crypto_gcm_module_init(void)\n{\n\tint err;\n\n\tgcm_zeroes = kzalloc(16, GFP_KERNEL);\n\tif (!gcm_zeroes)\n\t\treturn -ENOMEM;\n\n\terr = crypto_register_template(&crypto_gcm_base_tmpl);\n\tif (err)\n\t\tgoto out;\n\n\terr = crypto_register_template(&crypto_gcm_tmpl);\n\tif (err)\n\t\tgoto out_undo_base;\n\n\terr = crypto_register_template(&crypto_rfc4106_tmpl);\n\tif (err)\n\t\tgoto out_undo_gcm;\n\n\terr = crypto_register_template(&crypto_rfc4543_tmpl);\n\tif (err)\n\t\tgoto out_undo_rfc4106;\n\n\treturn 0;\n\nout_undo_rfc4106:\n\tcrypto_unregister_template(&crypto_rfc4106_tmpl);\nout_undo_gcm:\n\tcrypto_unregister_template(&crypto_gcm_tmpl);\nout_undo_base:\n\tcrypto_unregister_template(&crypto_gcm_base_tmpl);\nout:\n\tkfree(gcm_zeroes);\n\treturn err;\n}\n\nstatic void __exit crypto_gcm_module_exit(void)\n{\n\tkfree(gcm_zeroes);\n\tcrypto_unregister_template(&crypto_rfc4543_tmpl);\n\tcrypto_unregister_template(&crypto_rfc4106_tmpl);\n\tcrypto_unregister_template(&crypto_gcm_tmpl);\n\tcrypto_unregister_template(&crypto_gcm_base_tmpl);\n}\n\nmodule_init(crypto_gcm_module_init);\nmodule_exit(crypto_gcm_module_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Galois/Counter Mode\");\nMODULE_AUTHOR(\"Mikko Herranen <mh1@iki.fi>\");\nMODULE_ALIAS_CRYPTO(\"gcm_base\");\nMODULE_ALIAS_CRYPTO(\"rfc4106\");\nMODULE_ALIAS_CRYPTO(\"rfc4543\");\n", "/*\n * GHASH: digest algorithm for GCM (Galois/Counter Mode).\n *\n * Copyright (c) 2007 Nokia Siemens Networks - Mikko Herranen <mh1@iki.fi>\n * Copyright (c) 2009 Intel Corp.\n *   Author: Huang Ying <ying.huang@intel.com>\n *\n * The algorithm implementation is copied from gcm.c.\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License version 2 as published\n * by the Free Software Foundation.\n */\n\n#include <crypto/algapi.h>\n#include <crypto/gf128mul.h>\n#include <crypto/internal/hash.h>\n#include <linux/crypto.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n\n#define GHASH_BLOCK_SIZE\t16\n#define GHASH_DIGEST_SIZE\t16\n\nstruct ghash_ctx {\n\tstruct gf128mul_4k *gf128;\n};\n\nstruct ghash_desc_ctx {\n\tu8 buffer[GHASH_BLOCK_SIZE];\n\tu32 bytes;\n};\n\nstatic int ghash_init(struct shash_desc *desc)\n{\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\n\tmemset(dctx, 0, sizeof(*dctx));\n\n\treturn 0;\n}\n\nstatic int ghash_setkey(struct crypto_shash *tfm,\n\t\t\tconst u8 *key, unsigned int keylen)\n{\n\tstruct ghash_ctx *ctx = crypto_shash_ctx(tfm);\n\n\tif (keylen != GHASH_BLOCK_SIZE) {\n\t\tcrypto_shash_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);\n\t\treturn -EINVAL;\n\t}\n\n\tif (ctx->gf128)\n\t\tgf128mul_free_4k(ctx->gf128);\n\tctx->gf128 = gf128mul_init_4k_lle((be128 *)key);\n\tif (!ctx->gf128)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic int ghash_update(struct shash_desc *desc,\n\t\t\t const u8 *src, unsigned int srclen)\n{\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\tstruct ghash_ctx *ctx = crypto_shash_ctx(desc->tfm);\n\tu8 *dst = dctx->buffer;\n\n\tif (!ctx->gf128)\n\t\treturn -ENOKEY;\n\n\tif (dctx->bytes) {\n\t\tint n = min(srclen, dctx->bytes);\n\t\tu8 *pos = dst + (GHASH_BLOCK_SIZE - dctx->bytes);\n\n\t\tdctx->bytes -= n;\n\t\tsrclen -= n;\n\n\t\twhile (n--)\n\t\t\t*pos++ ^= *src++;\n\n\t\tif (!dctx->bytes)\n\t\t\tgf128mul_4k_lle((be128 *)dst, ctx->gf128);\n\t}\n\n\twhile (srclen >= GHASH_BLOCK_SIZE) {\n\t\tcrypto_xor(dst, src, GHASH_BLOCK_SIZE);\n\t\tgf128mul_4k_lle((be128 *)dst, ctx->gf128);\n\t\tsrc += GHASH_BLOCK_SIZE;\n\t\tsrclen -= GHASH_BLOCK_SIZE;\n\t}\n\n\tif (srclen) {\n\t\tdctx->bytes = GHASH_BLOCK_SIZE - srclen;\n\t\twhile (srclen--)\n\t\t\t*dst++ ^= *src++;\n\t}\n\n\treturn 0;\n}\n\nstatic void ghash_flush(struct ghash_ctx *ctx, struct ghash_desc_ctx *dctx)\n{\n\tu8 *dst = dctx->buffer;\n\n\tif (dctx->bytes) {\n\t\tu8 *tmp = dst + (GHASH_BLOCK_SIZE - dctx->bytes);\n\n\t\twhile (dctx->bytes--)\n\t\t\t*tmp++ ^= 0;\n\n\t\tgf128mul_4k_lle((be128 *)dst, ctx->gf128);\n\t}\n\n\tdctx->bytes = 0;\n}\n\nstatic int ghash_final(struct shash_desc *desc, u8 *dst)\n{\n\tstruct ghash_desc_ctx *dctx = shash_desc_ctx(desc);\n\tstruct ghash_ctx *ctx = crypto_shash_ctx(desc->tfm);\n\tu8 *buf = dctx->buffer;\n\n\tif (!ctx->gf128)\n\t\treturn -ENOKEY;\n\n\tghash_flush(ctx, dctx);\n\tmemcpy(dst, buf, GHASH_BLOCK_SIZE);\n\n\treturn 0;\n}\n\nstatic void ghash_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct ghash_ctx *ctx = crypto_tfm_ctx(tfm);\n\tif (ctx->gf128)\n\t\tgf128mul_free_4k(ctx->gf128);\n}\n\nstatic struct shash_alg ghash_alg = {\n\t.digestsize\t= GHASH_DIGEST_SIZE,\n\t.init\t\t= ghash_init,\n\t.update\t\t= ghash_update,\n\t.final\t\t= ghash_final,\n\t.setkey\t\t= ghash_setkey,\n\t.descsize\t= sizeof(struct ghash_desc_ctx),\n\t.base\t\t= {\n\t\t.cra_name\t\t= \"ghash\",\n\t\t.cra_driver_name\t= \"ghash-generic\",\n\t\t.cra_priority\t\t= 100,\n\t\t.cra_flags\t\t= CRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t\t= GHASH_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t= sizeof(struct ghash_ctx),\n\t\t.cra_module\t\t= THIS_MODULE,\n\t\t.cra_exit\t\t= ghash_exit_tfm,\n\t},\n};\n\nstatic int __init ghash_mod_init(void)\n{\n\treturn crypto_register_shash(&ghash_alg);\n}\n\nstatic void __exit ghash_mod_exit(void)\n{\n\tcrypto_unregister_shash(&ghash_alg);\n}\n\nmodule_init(ghash_mod_init);\nmodule_exit(ghash_mod_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"GHASH Message Digest Algorithm\");\nMODULE_ALIAS_CRYPTO(\"ghash\");\n", "/*\n * Cryptographic API.\n *\n * Khazad Algorithm\n *\n * The Khazad algorithm was developed by Paulo S. L. M. Barreto and\n * Vincent Rijmen.  It was a finalist in the NESSIE encryption contest.\n *\n * The original authors have disclaimed all copyright interest in this\n * code and thus put it in the public domain. The subsequent authors\n * have put this under the GNU General Public License.\n *\n * By Aaron Grothe ajgrothe@yahoo.com, August 1, 2004\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <asm/byteorder.h>\n#include <linux/crypto.h>\n#include <linux/types.h>\n\n#define KHAZAD_KEY_SIZE\t\t16\n#define KHAZAD_BLOCK_SIZE\t8\n#define KHAZAD_ROUNDS\t\t8\n\nstruct khazad_ctx {\n\tu64 E[KHAZAD_ROUNDS + 1];\n\tu64 D[KHAZAD_ROUNDS + 1];\n};\n\nstatic const u64 T0[256] = {\n\t0xbad3d268bbb96a01ULL, 0x54fc4d19e59a66b1ULL, 0x2f71bc93e26514cdULL,\n\t0x749ccdb925871b51ULL, 0x53f55102f7a257a4ULL, 0xd3686bb8d0d6be03ULL,\n\t0xd26b6fbdd6deb504ULL, 0x4dd72964b35285feULL, 0x50f05d0dfdba4aadULL,\n\t0xace98a26cf09e063ULL, 0x8d8a0e83091c9684ULL, 0xbfdcc679a5914d1aULL,\n\t0x7090ddad3da7374dULL, 0x52f65507f1aa5ca3ULL, 0x9ab352c87ba417e1ULL,\n\t0x4cd42d61b55a8ef9ULL, 0xea238f65460320acULL, 0xd56273a6c4e68411ULL,\n\t0x97a466f155cc68c2ULL, 0xd16e63b2dcc6a80dULL, 0x3355ccffaa85d099ULL,\n\t0x51f35908fbb241aaULL, 0x5bed712ac7e20f9cULL, 0xa6f7a204f359ae55ULL,\n\t0xde7f5f81febec120ULL, 0x48d83d75ad7aa2e5ULL, 0xa8e59a32d729cc7fULL,\n\t0x99b65ec771bc0ae8ULL, 0xdb704b90e096e63bULL, 0x3256c8faac8ddb9eULL,\n\t0xb7c4e65195d11522ULL, 0xfc19d72b32b3aaceULL, 0xe338ab48704b7393ULL,\n\t0x9ebf42dc63843bfdULL, 0x91ae7eef41fc52d0ULL, 0x9bb056cd7dac1ce6ULL,\n\t0xe23baf4d76437894ULL, 0xbbd0d66dbdb16106ULL, 0x41c319589b32f1daULL,\n\t0x6eb2a5cb7957e517ULL, 0xa5f2ae0bf941b35cULL, 0xcb400bc08016564bULL,\n\t0x6bbdb1da677fc20cULL, 0x95a26efb59dc7eccULL, 0xa1febe1fe1619f40ULL,\n\t0xf308eb1810cbc3e3ULL, 0xb1cefe4f81e12f30ULL, 0x0206080a0c10160eULL,\n\t0xcc4917db922e675eULL, 0xc45137f3a26e3f66ULL, 0x1d2774694ee8cf53ULL,\n\t0x143c504478a09c6cULL, 0xc3582be8b0560e73ULL, 0x63a591f2573f9a34ULL,\n\t0xda734f95e69eed3cULL, 0x5de76934d3d2358eULL, 0x5fe1613edfc22380ULL,\n\t0xdc79578bf2aed72eULL, 0x7d87e99413cf486eULL, 0xcd4a13de94266c59ULL,\n\t0x7f81e19e1fdf5e60ULL, 0x5aee752fc1ea049bULL, 0x6cb4adc17547f319ULL,\n\t0x5ce46d31d5da3e89ULL, 0xf704fb0c08ebefffULL, 0x266a98bed42d47f2ULL,\n\t0xff1cdb2438abb7c7ULL, 0xed2a937e543b11b9ULL, 0xe825876f4a1336a2ULL,\n\t0x9dba4ed3699c26f4ULL, 0x6fb1a1ce7f5fee10ULL, 0x8e8f028c03048b8dULL,\n\t0x192b647d56c8e34fULL, 0xa0fdba1ae7699447ULL, 0xf00de7171ad3deeaULL,\n\t0x89861e97113cba98ULL, 0x0f113c332278692dULL, 0x07091c1b12383115ULL,\n\t0xafec8629c511fd6aULL, 0xfb10cb30208b9bdbULL, 0x0818202830405838ULL,\n\t0x153f54417ea8976bULL, 0x0d1734392e687f23ULL, 0x040c101418202c1cULL,\n\t0x0103040506080b07ULL, 0x64ac8de94507ab21ULL, 0xdf7c5b84f8b6ca27ULL,\n\t0x769ac5b329970d5fULL, 0x798bf9800bef6472ULL, 0xdd7a538ef4a6dc29ULL,\n\t0x3d47f4c98ef5b2b3ULL, 0x163a584e74b08a62ULL, 0x3f41fcc382e5a4bdULL,\n\t0x3759dcebb2a5fc85ULL, 0x6db7a9c4734ff81eULL, 0x3848e0d890dd95a8ULL,\n\t0xb9d6de67b1a17708ULL, 0x7395d1a237bf2a44ULL, 0xe926836a4c1b3da5ULL,\n\t0x355fd4e1beb5ea8bULL, 0x55ff491ce3926db6ULL, 0x7193d9a83baf3c4aULL,\n\t0x7b8df18a07ff727cULL, 0x8c890a860f149d83ULL, 0x7296d5a731b72143ULL,\n\t0x88851a921734b19fULL, 0xf607ff090ee3e4f8ULL, 0x2a7ea882fc4d33d6ULL,\n\t0x3e42f8c684edafbaULL, 0x5ee2653bd9ca2887ULL, 0x27699cbbd2254cf5ULL,\n\t0x46ca0543890ac0cfULL, 0x0c14303c28607424ULL, 0x65af89ec430fa026ULL,\n\t0x68b8bdd56d67df05ULL, 0x61a399f85b2f8c3aULL, 0x03050c0f0a181d09ULL,\n\t0xc15e23e2bc46187dULL, 0x57f94116ef827bb8ULL, 0xd6677fa9cefe9918ULL,\n\t0xd976439aec86f035ULL, 0x58e87d25cdfa1295ULL, 0xd875479fea8efb32ULL,\n\t0x66aa85e34917bd2fULL, 0xd7647bacc8f6921fULL, 0x3a4ee8d29ccd83a6ULL,\n\t0xc84507cf8a0e4b42ULL, 0x3c44f0cc88fdb9b4ULL, 0xfa13cf35268390dcULL,\n\t0x96a762f453c463c5ULL, 0xa7f4a601f551a552ULL, 0x98b55ac277b401efULL,\n\t0xec29977b52331abeULL, 0xb8d5da62b7a97c0fULL, 0xc7543bfca876226fULL,\n\t0xaeef822cc319f66dULL, 0x69bbb9d06b6fd402ULL, 0x4bdd317aa762bfecULL,\n\t0xabe0963ddd31d176ULL, 0xa9e69e37d121c778ULL, 0x67a981e64f1fb628ULL,\n\t0x0a1e28223c504e36ULL, 0x47c901468f02cbc8ULL, 0xf20bef1d16c3c8e4ULL,\n\t0xb5c2ee5b99c1032cULL, 0x226688aacc0d6beeULL, 0xe532b356647b4981ULL,\n\t0xee2f9f715e230cb0ULL, 0xbedfc27ca399461dULL, 0x2b7dac87fa4538d1ULL,\n\t0x819e3ebf217ce2a0ULL, 0x1236485a6c90a67eULL, 0x839836b52d6cf4aeULL,\n\t0x1b2d6c775ad8f541ULL, 0x0e1238362470622aULL, 0x23658cafca0560e9ULL,\n\t0xf502f30604fbf9f1ULL, 0x45cf094c8312ddc6ULL, 0x216384a5c61576e7ULL,\n\t0xce4f1fd19e3e7150ULL, 0x49db3970ab72a9e2ULL, 0x2c74b09ce87d09c4ULL,\n\t0xf916c33a2c9b8dd5ULL, 0xe637bf596e635488ULL, 0xb6c7e25493d91e25ULL,\n\t0x2878a088f05d25d8ULL, 0x17395c4b72b88165ULL, 0x829b32b02b64ffa9ULL,\n\t0x1a2e68725cd0fe46ULL, 0x8b80169d1d2cac96ULL, 0xfe1fdf213ea3bcc0ULL,\n\t0x8a8312981b24a791ULL, 0x091b242d3648533fULL, 0xc94603ca8c064045ULL,\n\t0x879426a1354cd8b2ULL, 0x4ed2256bb94a98f7ULL, 0xe13ea3427c5b659dULL,\n\t0x2e72b896e46d1fcaULL, 0xe431b75362734286ULL, 0xe03da7477a536e9aULL,\n\t0xeb208b60400b2babULL, 0x90ad7aea47f459d7ULL, 0xa4f1aa0eff49b85bULL,\n\t0x1e22786644f0d25aULL, 0x85922eab395ccebcULL, 0x60a09dfd5d27873dULL,\n\t0x0000000000000000ULL, 0x256f94b1de355afbULL, 0xf401f70302f3f2f6ULL,\n\t0xf10ee3121cdbd5edULL, 0x94a16afe5fd475cbULL, 0x0b1d2c273a584531ULL,\n\t0xe734bb5c686b5f8fULL, 0x759fc9bc238f1056ULL, 0xef2c9b74582b07b7ULL,\n\t0x345cd0e4b8bde18cULL, 0x3153c4f5a695c697ULL, 0xd46177a3c2ee8f16ULL,\n\t0xd06d67b7dacea30aULL, 0x869722a43344d3b5ULL, 0x7e82e59b19d75567ULL,\n\t0xadea8e23c901eb64ULL, 0xfd1ad32e34bba1c9ULL, 0x297ba48df6552edfULL,\n\t0x3050c0f0a09dcd90ULL, 0x3b4decd79ac588a1ULL, 0x9fbc46d9658c30faULL,\n\t0xf815c73f2a9386d2ULL, 0xc6573ff9ae7e2968ULL, 0x13354c5f6a98ad79ULL,\n\t0x060a181e14303a12ULL, 0x050f14111e28271bULL, 0xc55233f6a4663461ULL,\n\t0x113344556688bb77ULL, 0x7799c1b62f9f0658ULL, 0x7c84ed9115c74369ULL,\n\t0x7a8ef58f01f7797bULL, 0x7888fd850de76f75ULL, 0x365ad8eeb4adf782ULL,\n\t0x1c24706c48e0c454ULL, 0x394be4dd96d59eafULL, 0x59eb7920cbf21992ULL,\n\t0x1828607850c0e848ULL, 0x56fa4513e98a70bfULL, 0xb3c8f6458df1393eULL,\n\t0xb0cdfa4a87e92437ULL, 0x246c90b4d83d51fcULL, 0x206080a0c01d7de0ULL,\n\t0xb2cbf2408bf93239ULL, 0x92ab72e04be44fd9ULL, 0xa3f8b615ed71894eULL,\n\t0xc05d27e7ba4e137aULL, 0x44cc0d49851ad6c1ULL, 0x62a695f751379133ULL,\n\t0x103040506080b070ULL, 0xb4c1ea5e9fc9082bULL, 0x84912aae3f54c5bbULL,\n\t0x43c511529722e7d4ULL, 0x93a876e54dec44deULL, 0xc25b2fedb65e0574ULL,\n\t0x4ade357fa16ab4ebULL, 0xbddace73a9815b14ULL, 0x8f8c0689050c808aULL,\n\t0x2d77b499ee7502c3ULL, 0xbcd9ca76af895013ULL, 0x9cb94ad66f942df3ULL,\n\t0x6abeb5df6177c90bULL, 0x40c01d5d9d3afaddULL, 0xcf4c1bd498367a57ULL,\n\t0xa2fbb210eb798249ULL, 0x809d3aba2774e9a7ULL, 0x4fd1216ebf4293f0ULL,\n\t0x1f217c6342f8d95dULL, 0xca430fc5861e5d4cULL, 0xaae39238db39da71ULL,\n\t0x42c61557912aecd3ULL\n};\n\nstatic const u64 T1[256] = {\n\t0xd3ba68d2b9bb016aULL, 0xfc54194d9ae5b166ULL, 0x712f93bc65e2cd14ULL,\n\t0x9c74b9cd8725511bULL, 0xf5530251a2f7a457ULL, 0x68d3b86bd6d003beULL,\n\t0x6bd2bd6fded604b5ULL, 0xd74d642952b3fe85ULL, 0xf0500d5dbafdad4aULL,\n\t0xe9ac268a09cf63e0ULL, 0x8a8d830e1c098496ULL, 0xdcbf79c691a51a4dULL,\n\t0x9070addda73d4d37ULL, 0xf6520755aaf1a35cULL, 0xb39ac852a47be117ULL,\n\t0xd44c612d5ab5f98eULL, 0x23ea658f0346ac20ULL, 0x62d5a673e6c41184ULL,\n\t0xa497f166cc55c268ULL, 0x6ed1b263c6dc0da8ULL, 0x5533ffcc85aa99d0ULL,\n\t0xf3510859b2fbaa41ULL, 0xed5b2a71e2c79c0fULL, 0xf7a604a259f355aeULL,\n\t0x7fde815fbefe20c1ULL, 0xd848753d7aade5a2ULL, 0xe5a8329a29d77fccULL,\n\t0xb699c75ebc71e80aULL, 0x70db904b96e03be6ULL, 0x5632fac88dac9edbULL,\n\t0xc4b751e6d1952215ULL, 0x19fc2bd7b332ceaaULL, 0x38e348ab4b709373ULL,\n\t0xbf9edc428463fd3bULL, 0xae91ef7efc41d052ULL, 0xb09bcd56ac7de61cULL,\n\t0x3be24daf43769478ULL, 0xd0bb6dd6b1bd0661ULL, 0xc3415819329bdaf1ULL,\n\t0xb26ecba5577917e5ULL, 0xf2a50bae41f95cb3ULL, 0x40cbc00b16804b56ULL,\n\t0xbd6bdab17f670cc2ULL, 0xa295fb6edc59cc7eULL, 0xfea11fbe61e1409fULL,\n\t0x08f318ebcb10e3c3ULL, 0xceb14ffee181302fULL, 0x06020a08100c0e16ULL,\n\t0x49ccdb172e925e67ULL, 0x51c4f3376ea2663fULL, 0x271d6974e84e53cfULL,\n\t0x3c144450a0786c9cULL, 0x58c3e82b56b0730eULL, 0xa563f2913f57349aULL,\n\t0x73da954f9ee63cedULL, 0xe75d3469d2d38e35ULL, 0xe15f3e61c2df8023ULL,\n\t0x79dc8b57aef22ed7ULL, 0x877d94e9cf136e48ULL, 0x4acdde132694596cULL,\n\t0x817f9ee1df1f605eULL, 0xee5a2f75eac19b04ULL, 0xb46cc1ad477519f3ULL,\n\t0xe45c316ddad5893eULL, 0x04f70cfbeb08ffefULL, 0x6a26be982dd4f247ULL,\n\t0x1cff24dbab38c7b7ULL, 0x2aed7e933b54b911ULL, 0x25e86f87134aa236ULL,\n\t0xba9dd34e9c69f426ULL, 0xb16fcea15f7f10eeULL, 0x8f8e8c0204038d8bULL,\n\t0x2b197d64c8564fe3ULL, 0xfda01aba69e74794ULL, 0x0df017e7d31aeadeULL,\n\t0x8689971e3c1198baULL, 0x110f333c78222d69ULL, 0x09071b1c38121531ULL,\n\t0xecaf298611c56afdULL, 0x10fb30cb8b20db9bULL, 0x1808282040303858ULL,\n\t0x3f154154a87e6b97ULL, 0x170d3934682e237fULL, 0x0c04141020181c2cULL,\n\t0x030105040806070bULL, 0xac64e98d074521abULL, 0x7cdf845bb6f827caULL,\n\t0x9a76b3c597295f0dULL, 0x8b7980f9ef0b7264ULL, 0x7add8e53a6f429dcULL,\n\t0x473dc9f4f58eb3b2ULL, 0x3a164e58b074628aULL, 0x413fc3fce582bda4ULL,\n\t0x5937ebdca5b285fcULL, 0xb76dc4a94f731ef8ULL, 0x4838d8e0dd90a895ULL,\n\t0xd6b967dea1b10877ULL, 0x9573a2d1bf37442aULL, 0x26e96a831b4ca53dULL,\n\t0x5f35e1d4b5be8beaULL, 0xff551c4992e3b66dULL, 0x9371a8d9af3b4a3cULL,\n\t0x8d7b8af1ff077c72ULL, 0x898c860a140f839dULL, 0x9672a7d5b7314321ULL,\n\t0x8588921a34179fb1ULL, 0x07f609ffe30ef8e4ULL, 0x7e2a82a84dfcd633ULL,\n\t0x423ec6f8ed84baafULL, 0xe25e3b65cad98728ULL, 0x6927bb9c25d2f54cULL,\n\t0xca4643050a89cfc0ULL, 0x140c3c3060282474ULL, 0xaf65ec890f4326a0ULL,\n\t0xb868d5bd676d05dfULL, 0xa361f8992f5b3a8cULL, 0x05030f0c180a091dULL,\n\t0x5ec1e22346bc7d18ULL, 0xf957164182efb87bULL, 0x67d6a97ffece1899ULL,\n\t0x76d99a4386ec35f0ULL, 0xe858257dfacd9512ULL, 0x75d89f478eea32fbULL,\n\t0xaa66e38517492fbdULL, 0x64d7ac7bf6c81f92ULL, 0x4e3ad2e8cd9ca683ULL,\n\t0x45c8cf070e8a424bULL, 0x443cccf0fd88b4b9ULL, 0x13fa35cf8326dc90ULL,\n\t0xa796f462c453c563ULL, 0xf4a701a651f552a5ULL, 0xb598c25ab477ef01ULL,\n\t0x29ec7b973352be1aULL, 0xd5b862daa9b70f7cULL, 0x54c7fc3b76a86f22ULL,\n\t0xefae2c8219c36df6ULL, 0xbb69d0b96f6b02d4ULL, 0xdd4b7a3162a7ecbfULL,\n\t0xe0ab3d9631dd76d1ULL, 0xe6a9379e21d178c7ULL, 0xa967e6811f4f28b6ULL,\n\t0x1e0a2228503c364eULL, 0xc9474601028fc8cbULL, 0x0bf21defc316e4c8ULL,\n\t0xc2b55beec1992c03ULL, 0x6622aa880dccee6bULL, 0x32e556b37b648149ULL,\n\t0x2fee719f235eb00cULL, 0xdfbe7cc299a31d46ULL, 0x7d2b87ac45fad138ULL,\n\t0x9e81bf3e7c21a0e2ULL, 0x36125a48906c7ea6ULL, 0x9883b5366c2daef4ULL,\n\t0x2d1b776cd85a41f5ULL, 0x120e363870242a62ULL, 0x6523af8c05cae960ULL,\n\t0x02f506f3fb04f1f9ULL, 0xcf454c091283c6ddULL, 0x6321a58415c6e776ULL,\n\t0x4fced11f3e9e5071ULL, 0xdb49703972abe2a9ULL, 0x742c9cb07de8c409ULL,\n\t0x16f93ac39b2cd58dULL, 0x37e659bf636e8854ULL, 0xc7b654e2d993251eULL,\n\t0x782888a05df0d825ULL, 0x39174b5cb8726581ULL, 0x9b82b032642ba9ffULL,\n\t0x2e1a7268d05c46feULL, 0x808b9d162c1d96acULL, 0x1ffe21dfa33ec0bcULL,\n\t0x838a9812241b91a7ULL, 0x1b092d2448363f53ULL, 0x46c9ca03068c4540ULL,\n\t0x9487a1264c35b2d8ULL, 0xd24e6b254ab9f798ULL, 0x3ee142a35b7c9d65ULL,\n\t0x722e96b86de4ca1fULL, 0x31e453b773628642ULL, 0x3de047a7537a9a6eULL,\n\t0x20eb608b0b40ab2bULL, 0xad90ea7af447d759ULL, 0xf1a40eaa49ff5bb8ULL,\n\t0x221e6678f0445ad2ULL, 0x9285ab2e5c39bcceULL, 0xa060fd9d275d3d87ULL,\n\t0x0000000000000000ULL, 0x6f25b19435defb5aULL, 0x01f403f7f302f6f2ULL,\n\t0x0ef112e3db1cedd5ULL, 0xa194fe6ad45fcb75ULL, 0x1d0b272c583a3145ULL,\n\t0x34e75cbb6b688f5fULL, 0x9f75bcc98f235610ULL, 0x2cef749b2b58b707ULL,\n\t0x5c34e4d0bdb88ce1ULL, 0x5331f5c495a697c6ULL, 0x61d4a377eec2168fULL,\n\t0x6dd0b767ceda0aa3ULL, 0x9786a4224433b5d3ULL, 0x827e9be5d7196755ULL,\n\t0xeaad238e01c964ebULL, 0x1afd2ed3bb34c9a1ULL, 0x7b298da455f6df2eULL,\n\t0x5030f0c09da090cdULL, 0x4d3bd7ecc59aa188ULL, 0xbc9fd9468c65fa30ULL,\n\t0x15f83fc7932ad286ULL, 0x57c6f93f7eae6829ULL, 0x35135f4c986a79adULL,\n\t0x0a061e183014123aULL, 0x0f051114281e1b27ULL, 0x52c5f63366a46134ULL,\n\t0x33115544886677bbULL, 0x9977b6c19f2f5806ULL, 0x847c91edc7156943ULL,\n\t0x8e7a8ff5f7017b79ULL, 0x887885fde70d756fULL, 0x5a36eed8adb482f7ULL,\n\t0x241c6c70e04854c4ULL, 0x4b39dde4d596af9eULL, 0xeb592079f2cb9219ULL,\n\t0x28187860c05048e8ULL, 0xfa5613458ae9bf70ULL, 0xc8b345f6f18d3e39ULL,\n\t0xcdb04afae9873724ULL, 0x6c24b4903dd8fc51ULL, 0x6020a0801dc0e07dULL,\n\t0xcbb240f2f98b3932ULL, 0xab92e072e44bd94fULL, 0xf8a315b671ed4e89ULL,\n\t0x5dc0e7274eba7a13ULL, 0xcc44490d1a85c1d6ULL, 0xa662f79537513391ULL,\n\t0x30105040806070b0ULL, 0xc1b45eeac99f2b08ULL, 0x9184ae2a543fbbc5ULL,\n\t0xc54352112297d4e7ULL, 0xa893e576ec4dde44ULL, 0x5bc2ed2f5eb67405ULL,\n\t0xde4a7f356aa1ebb4ULL, 0xdabd73ce81a9145bULL, 0x8c8f89060c058a80ULL,\n\t0x772d99b475eec302ULL, 0xd9bc76ca89af1350ULL, 0xb99cd64a946ff32dULL,\n\t0xbe6adfb577610bc9ULL, 0xc0405d1d3a9dddfaULL, 0x4ccfd41b3698577aULL,\n\t0xfba210b279eb4982ULL, 0x9d80ba3a7427a7e9ULL, 0xd14f6e2142bff093ULL,\n\t0x211f637cf8425dd9ULL, 0x43cac50f1e864c5dULL, 0xe3aa389239db71daULL,\n\t0xc64257152a91d3ecULL\n};\n\nstatic const u64 T2[256] = {\n\t0xd268bad36a01bbb9ULL, 0x4d1954fc66b1e59aULL, 0xbc932f7114cde265ULL,\n\t0xcdb9749c1b512587ULL, 0x510253f557a4f7a2ULL, 0x6bb8d368be03d0d6ULL,\n\t0x6fbdd26bb504d6deULL, 0x29644dd785feb352ULL, 0x5d0d50f04aadfdbaULL,\n\t0x8a26ace9e063cf09ULL, 0x0e838d8a9684091cULL, 0xc679bfdc4d1aa591ULL,\n\t0xddad7090374d3da7ULL, 0x550752f65ca3f1aaULL, 0x52c89ab317e17ba4ULL,\n\t0x2d614cd48ef9b55aULL, 0x8f65ea2320ac4603ULL, 0x73a6d5628411c4e6ULL,\n\t0x66f197a468c255ccULL, 0x63b2d16ea80ddcc6ULL, 0xccff3355d099aa85ULL,\n\t0x590851f341aafbb2ULL, 0x712a5bed0f9cc7e2ULL, 0xa204a6f7ae55f359ULL,\n\t0x5f81de7fc120febeULL, 0x3d7548d8a2e5ad7aULL, 0x9a32a8e5cc7fd729ULL,\n\t0x5ec799b60ae871bcULL, 0x4b90db70e63be096ULL, 0xc8fa3256db9eac8dULL,\n\t0xe651b7c4152295d1ULL, 0xd72bfc19aace32b3ULL, 0xab48e3387393704bULL,\n\t0x42dc9ebf3bfd6384ULL, 0x7eef91ae52d041fcULL, 0x56cd9bb01ce67dacULL,\n\t0xaf4de23b78947643ULL, 0xd66dbbd06106bdb1ULL, 0x195841c3f1da9b32ULL,\n\t0xa5cb6eb2e5177957ULL, 0xae0ba5f2b35cf941ULL, 0x0bc0cb40564b8016ULL,\n\t0xb1da6bbdc20c677fULL, 0x6efb95a27ecc59dcULL, 0xbe1fa1fe9f40e161ULL,\n\t0xeb18f308c3e310cbULL, 0xfe4fb1ce2f3081e1ULL, 0x080a0206160e0c10ULL,\n\t0x17dbcc49675e922eULL, 0x37f3c4513f66a26eULL, 0x74691d27cf534ee8ULL,\n\t0x5044143c9c6c78a0ULL, 0x2be8c3580e73b056ULL, 0x91f263a59a34573fULL,\n\t0x4f95da73ed3ce69eULL, 0x69345de7358ed3d2ULL, 0x613e5fe12380dfc2ULL,\n\t0x578bdc79d72ef2aeULL, 0xe9947d87486e13cfULL, 0x13decd4a6c599426ULL,\n\t0xe19e7f815e601fdfULL, 0x752f5aee049bc1eaULL, 0xadc16cb4f3197547ULL,\n\t0x6d315ce43e89d5daULL, 0xfb0cf704efff08ebULL, 0x98be266a47f2d42dULL,\n\t0xdb24ff1cb7c738abULL, 0x937eed2a11b9543bULL, 0x876fe82536a24a13ULL,\n\t0x4ed39dba26f4699cULL, 0xa1ce6fb1ee107f5fULL, 0x028c8e8f8b8d0304ULL,\n\t0x647d192be34f56c8ULL, 0xba1aa0fd9447e769ULL, 0xe717f00ddeea1ad3ULL,\n\t0x1e978986ba98113cULL, 0x3c330f11692d2278ULL, 0x1c1b070931151238ULL,\n\t0x8629afecfd6ac511ULL, 0xcb30fb109bdb208bULL, 0x2028081858383040ULL,\n\t0x5441153f976b7ea8ULL, 0x34390d177f232e68ULL, 0x1014040c2c1c1820ULL,\n\t0x040501030b070608ULL, 0x8de964acab214507ULL, 0x5b84df7cca27f8b6ULL,\n\t0xc5b3769a0d5f2997ULL, 0xf980798b64720befULL, 0x538edd7adc29f4a6ULL,\n\t0xf4c93d47b2b38ef5ULL, 0x584e163a8a6274b0ULL, 0xfcc33f41a4bd82e5ULL,\n\t0xdceb3759fc85b2a5ULL, 0xa9c46db7f81e734fULL, 0xe0d8384895a890ddULL,\n\t0xde67b9d67708b1a1ULL, 0xd1a273952a4437bfULL, 0x836ae9263da54c1bULL,\n\t0xd4e1355fea8bbeb5ULL, 0x491c55ff6db6e392ULL, 0xd9a871933c4a3bafULL,\n\t0xf18a7b8d727c07ffULL, 0x0a868c899d830f14ULL, 0xd5a77296214331b7ULL,\n\t0x1a928885b19f1734ULL, 0xff09f607e4f80ee3ULL, 0xa8822a7e33d6fc4dULL,\n\t0xf8c63e42afba84edULL, 0x653b5ee22887d9caULL, 0x9cbb27694cf5d225ULL,\n\t0x054346cac0cf890aULL, 0x303c0c1474242860ULL, 0x89ec65afa026430fULL,\n\t0xbdd568b8df056d67ULL, 0x99f861a38c3a5b2fULL, 0x0c0f03051d090a18ULL,\n\t0x23e2c15e187dbc46ULL, 0x411657f97bb8ef82ULL, 0x7fa9d6679918cefeULL,\n\t0x439ad976f035ec86ULL, 0x7d2558e81295cdfaULL, 0x479fd875fb32ea8eULL,\n\t0x85e366aabd2f4917ULL, 0x7bacd764921fc8f6ULL, 0xe8d23a4e83a69ccdULL,\n\t0x07cfc8454b428a0eULL, 0xf0cc3c44b9b488fdULL, 0xcf35fa1390dc2683ULL,\n\t0x62f496a763c553c4ULL, 0xa601a7f4a552f551ULL, 0x5ac298b501ef77b4ULL,\n\t0x977bec291abe5233ULL, 0xda62b8d57c0fb7a9ULL, 0x3bfcc754226fa876ULL,\n\t0x822caeeff66dc319ULL, 0xb9d069bbd4026b6fULL, 0x317a4bddbfeca762ULL,\n\t0x963dabe0d176dd31ULL, 0x9e37a9e6c778d121ULL, 0x81e667a9b6284f1fULL,\n\t0x28220a1e4e363c50ULL, 0x014647c9cbc88f02ULL, 0xef1df20bc8e416c3ULL,\n\t0xee5bb5c2032c99c1ULL, 0x88aa22666beecc0dULL, 0xb356e5324981647bULL,\n\t0x9f71ee2f0cb05e23ULL, 0xc27cbedf461da399ULL, 0xac872b7d38d1fa45ULL,\n\t0x3ebf819ee2a0217cULL, 0x485a1236a67e6c90ULL, 0x36b58398f4ae2d6cULL,\n\t0x6c771b2df5415ad8ULL, 0x38360e12622a2470ULL, 0x8caf236560e9ca05ULL,\n\t0xf306f502f9f104fbULL, 0x094c45cfddc68312ULL, 0x84a5216376e7c615ULL,\n\t0x1fd1ce4f71509e3eULL, 0x397049dba9e2ab72ULL, 0xb09c2c7409c4e87dULL,\n\t0xc33af9168dd52c9bULL, 0xbf59e63754886e63ULL, 0xe254b6c71e2593d9ULL,\n\t0xa088287825d8f05dULL, 0x5c4b1739816572b8ULL, 0x32b0829bffa92b64ULL,\n\t0x68721a2efe465cd0ULL, 0x169d8b80ac961d2cULL, 0xdf21fe1fbcc03ea3ULL,\n\t0x12988a83a7911b24ULL, 0x242d091b533f3648ULL, 0x03cac94640458c06ULL,\n\t0x26a18794d8b2354cULL, 0x256b4ed298f7b94aULL, 0xa342e13e659d7c5bULL,\n\t0xb8962e721fcae46dULL, 0xb753e43142866273ULL, 0xa747e03d6e9a7a53ULL,\n\t0x8b60eb202bab400bULL, 0x7aea90ad59d747f4ULL, 0xaa0ea4f1b85bff49ULL,\n\t0x78661e22d25a44f0ULL, 0x2eab8592cebc395cULL, 0x9dfd60a0873d5d27ULL,\n\t0x0000000000000000ULL, 0x94b1256f5afbde35ULL, 0xf703f401f2f602f3ULL,\n\t0xe312f10ed5ed1cdbULL, 0x6afe94a175cb5fd4ULL, 0x2c270b1d45313a58ULL,\n\t0xbb5ce7345f8f686bULL, 0xc9bc759f1056238fULL, 0x9b74ef2c07b7582bULL,\n\t0xd0e4345ce18cb8bdULL, 0xc4f53153c697a695ULL, 0x77a3d4618f16c2eeULL,\n\t0x67b7d06da30adaceULL, 0x22a48697d3b53344ULL, 0xe59b7e82556719d7ULL,\n\t0x8e23adeaeb64c901ULL, 0xd32efd1aa1c934bbULL, 0xa48d297b2edff655ULL,\n\t0xc0f03050cd90a09dULL, 0xecd73b4d88a19ac5ULL, 0x46d99fbc30fa658cULL,\n\t0xc73ff81586d22a93ULL, 0x3ff9c6572968ae7eULL, 0x4c5f1335ad796a98ULL,\n\t0x181e060a3a121430ULL, 0x1411050f271b1e28ULL, 0x33f6c5523461a466ULL,\n\t0x44551133bb776688ULL, 0xc1b6779906582f9fULL, 0xed917c84436915c7ULL,\n\t0xf58f7a8e797b01f7ULL, 0xfd8578886f750de7ULL, 0xd8ee365af782b4adULL,\n\t0x706c1c24c45448e0ULL, 0xe4dd394b9eaf96d5ULL, 0x792059eb1992cbf2ULL,\n\t0x60781828e84850c0ULL, 0x451356fa70bfe98aULL, 0xf645b3c8393e8df1ULL,\n\t0xfa4ab0cd243787e9ULL, 0x90b4246c51fcd83dULL, 0x80a020607de0c01dULL,\n\t0xf240b2cb32398bf9ULL, 0x72e092ab4fd94be4ULL, 0xb615a3f8894eed71ULL,\n\t0x27e7c05d137aba4eULL, 0x0d4944ccd6c1851aULL, 0x95f762a691335137ULL,\n\t0x40501030b0706080ULL, 0xea5eb4c1082b9fc9ULL, 0x2aae8491c5bb3f54ULL,\n\t0x115243c5e7d49722ULL, 0x76e593a844de4decULL, 0x2fedc25b0574b65eULL,\n\t0x357f4adeb4eba16aULL, 0xce73bdda5b14a981ULL, 0x06898f8c808a050cULL,\n\t0xb4992d7702c3ee75ULL, 0xca76bcd95013af89ULL, 0x4ad69cb92df36f94ULL,\n\t0xb5df6abec90b6177ULL, 0x1d5d40c0fadd9d3aULL, 0x1bd4cf4c7a579836ULL,\n\t0xb210a2fb8249eb79ULL, 0x3aba809de9a72774ULL, 0x216e4fd193f0bf42ULL,\n\t0x7c631f21d95d42f8ULL, 0x0fc5ca435d4c861eULL, 0x9238aae3da71db39ULL,\n\t0x155742c6ecd3912aULL\n};\n\nstatic const u64 T3[256] = {\n\t0x68d2d3ba016ab9bbULL, 0x194dfc54b1669ae5ULL, 0x93bc712fcd1465e2ULL,\n\t0xb9cd9c74511b8725ULL, 0x0251f553a457a2f7ULL, 0xb86b68d303bed6d0ULL,\n\t0xbd6f6bd204b5ded6ULL, 0x6429d74dfe8552b3ULL, 0x0d5df050ad4abafdULL,\n\t0x268ae9ac63e009cfULL, 0x830e8a8d84961c09ULL, 0x79c6dcbf1a4d91a5ULL,\n\t0xaddd90704d37a73dULL, 0x0755f652a35caaf1ULL, 0xc852b39ae117a47bULL,\n\t0x612dd44cf98e5ab5ULL, 0x658f23eaac200346ULL, 0xa67362d51184e6c4ULL,\n\t0xf166a497c268cc55ULL, 0xb2636ed10da8c6dcULL, 0xffcc553399d085aaULL,\n\t0x0859f351aa41b2fbULL, 0x2a71ed5b9c0fe2c7ULL, 0x04a2f7a655ae59f3ULL,\n\t0x815f7fde20c1befeULL, 0x753dd848e5a27aadULL, 0x329ae5a87fcc29d7ULL,\n\t0xc75eb699e80abc71ULL, 0x904b70db3be696e0ULL, 0xfac856329edb8dacULL,\n\t0x51e6c4b72215d195ULL, 0x2bd719fcceaab332ULL, 0x48ab38e393734b70ULL,\n\t0xdc42bf9efd3b8463ULL, 0xef7eae91d052fc41ULL, 0xcd56b09be61cac7dULL,\n\t0x4daf3be294784376ULL, 0x6dd6d0bb0661b1bdULL, 0x5819c341daf1329bULL,\n\t0xcba5b26e17e55779ULL, 0x0baef2a55cb341f9ULL, 0xc00b40cb4b561680ULL,\n\t0xdab1bd6b0cc27f67ULL, 0xfb6ea295cc7edc59ULL, 0x1fbefea1409f61e1ULL,\n\t0x18eb08f3e3c3cb10ULL, 0x4ffeceb1302fe181ULL, 0x0a0806020e16100cULL,\n\t0xdb1749cc5e672e92ULL, 0xf33751c4663f6ea2ULL, 0x6974271d53cfe84eULL,\n\t0x44503c146c9ca078ULL, 0xe82b58c3730e56b0ULL, 0xf291a563349a3f57ULL,\n\t0x954f73da3ced9ee6ULL, 0x3469e75d8e35d2d3ULL, 0x3e61e15f8023c2dfULL,\n\t0x8b5779dc2ed7aef2ULL, 0x94e9877d6e48cf13ULL, 0xde134acd596c2694ULL,\n\t0x9ee1817f605edf1fULL, 0x2f75ee5a9b04eac1ULL, 0xc1adb46c19f34775ULL,\n\t0x316de45c893edad5ULL, 0x0cfb04f7ffefeb08ULL, 0xbe986a26f2472dd4ULL,\n\t0x24db1cffc7b7ab38ULL, 0x7e932aedb9113b54ULL, 0x6f8725e8a236134aULL,\n\t0xd34eba9df4269c69ULL, 0xcea1b16f10ee5f7fULL, 0x8c028f8e8d8b0403ULL,\n\t0x7d642b194fe3c856ULL, 0x1abafda0479469e7ULL, 0x17e70df0eaded31aULL,\n\t0x971e868998ba3c11ULL, 0x333c110f2d697822ULL, 0x1b1c090715313812ULL,\n\t0x2986ecaf6afd11c5ULL, 0x30cb10fbdb9b8b20ULL, 0x2820180838584030ULL,\n\t0x41543f156b97a87eULL, 0x3934170d237f682eULL, 0x14100c041c2c2018ULL,\n\t0x05040301070b0806ULL, 0xe98dac6421ab0745ULL, 0x845b7cdf27cab6f8ULL,\n\t0xb3c59a765f0d9729ULL, 0x80f98b797264ef0bULL, 0x8e537add29dca6f4ULL,\n\t0xc9f4473db3b2f58eULL, 0x4e583a16628ab074ULL, 0xc3fc413fbda4e582ULL,\n\t0xebdc593785fca5b2ULL, 0xc4a9b76d1ef84f73ULL, 0xd8e04838a895dd90ULL,\n\t0x67ded6b90877a1b1ULL, 0xa2d19573442abf37ULL, 0x6a8326e9a53d1b4cULL,\n\t0xe1d45f358beab5beULL, 0x1c49ff55b66d92e3ULL, 0xa8d993714a3caf3bULL,\n\t0x8af18d7b7c72ff07ULL, 0x860a898c839d140fULL, 0xa7d596724321b731ULL,\n\t0x921a85889fb13417ULL, 0x09ff07f6f8e4e30eULL, 0x82a87e2ad6334dfcULL,\n\t0xc6f8423ebaafed84ULL, 0x3b65e25e8728cad9ULL, 0xbb9c6927f54c25d2ULL,\n\t0x4305ca46cfc00a89ULL, 0x3c30140c24746028ULL, 0xec89af6526a00f43ULL,\n\t0xd5bdb86805df676dULL, 0xf899a3613a8c2f5bULL, 0x0f0c0503091d180aULL,\n\t0xe2235ec17d1846bcULL, 0x1641f957b87b82efULL, 0xa97f67d61899feceULL,\n\t0x9a4376d935f086ecULL, 0x257de8589512facdULL, 0x9f4775d832fb8eeaULL,\n\t0xe385aa662fbd1749ULL, 0xac7b64d71f92f6c8ULL, 0xd2e84e3aa683cd9cULL,\n\t0xcf0745c8424b0e8aULL, 0xccf0443cb4b9fd88ULL, 0x35cf13fadc908326ULL,\n\t0xf462a796c563c453ULL, 0x01a6f4a752a551f5ULL, 0xc25ab598ef01b477ULL,\n\t0x7b9729ecbe1a3352ULL, 0x62dad5b80f7ca9b7ULL, 0xfc3b54c76f2276a8ULL,\n\t0x2c82efae6df619c3ULL, 0xd0b9bb6902d46f6bULL, 0x7a31dd4becbf62a7ULL,\n\t0x3d96e0ab76d131ddULL, 0x379ee6a978c721d1ULL, 0xe681a96728b61f4fULL,\n\t0x22281e0a364e503cULL, 0x4601c947c8cb028fULL, 0x1def0bf2e4c8c316ULL,\n\t0x5beec2b52c03c199ULL, 0xaa886622ee6b0dccULL, 0x56b332e581497b64ULL,\n\t0x719f2feeb00c235eULL, 0x7cc2dfbe1d4699a3ULL, 0x87ac7d2bd13845faULL,\n\t0xbf3e9e81a0e27c21ULL, 0x5a4836127ea6906cULL, 0xb5369883aef46c2dULL,\n\t0x776c2d1b41f5d85aULL, 0x3638120e2a627024ULL, 0xaf8c6523e96005caULL,\n\t0x06f302f5f1f9fb04ULL, 0x4c09cf45c6dd1283ULL, 0xa5846321e77615c6ULL,\n\t0xd11f4fce50713e9eULL, 0x7039db49e2a972abULL, 0x9cb0742cc4097de8ULL,\n\t0x3ac316f9d58d9b2cULL, 0x59bf37e68854636eULL, 0x54e2c7b6251ed993ULL,\n\t0x88a07828d8255df0ULL, 0x4b5c39176581b872ULL, 0xb0329b82a9ff642bULL,\n\t0x72682e1a46fed05cULL, 0x9d16808b96ac2c1dULL, 0x21df1ffec0bca33eULL,\n\t0x9812838a91a7241bULL, 0x2d241b093f534836ULL, 0xca0346c94540068cULL,\n\t0xa1269487b2d84c35ULL, 0x6b25d24ef7984ab9ULL, 0x42a33ee19d655b7cULL,\n\t0x96b8722eca1f6de4ULL, 0x53b731e486427362ULL, 0x47a73de09a6e537aULL,\n\t0x608b20ebab2b0b40ULL, 0xea7aad90d759f447ULL, 0x0eaaf1a45bb849ffULL,\n\t0x6678221e5ad2f044ULL, 0xab2e9285bcce5c39ULL, 0xfd9da0603d87275dULL,\n\t0x0000000000000000ULL, 0xb1946f25fb5a35deULL, 0x03f701f4f6f2f302ULL,\n\t0x12e30ef1edd5db1cULL, 0xfe6aa194cb75d45fULL, 0x272c1d0b3145583aULL,\n\t0x5cbb34e78f5f6b68ULL, 0xbcc99f7556108f23ULL, 0x749b2cefb7072b58ULL,\n\t0xe4d05c348ce1bdb8ULL, 0xf5c4533197c695a6ULL, 0xa37761d4168feec2ULL,\n\t0xb7676dd00aa3cedaULL, 0xa4229786b5d34433ULL, 0x9be5827e6755d719ULL,\n\t0x238eeaad64eb01c9ULL, 0x2ed31afdc9a1bb34ULL, 0x8da47b29df2e55f6ULL,\n\t0xf0c0503090cd9da0ULL, 0xd7ec4d3ba188c59aULL, 0xd946bc9ffa308c65ULL,\n\t0x3fc715f8d286932aULL, 0xf93f57c668297eaeULL, 0x5f4c351379ad986aULL,\n\t0x1e180a06123a3014ULL, 0x11140f051b27281eULL, 0xf63352c5613466a4ULL,\n\t0x5544331177bb8866ULL, 0xb6c1997758069f2fULL, 0x91ed847c6943c715ULL,\n\t0x8ff58e7a7b79f701ULL, 0x85fd8878756fe70dULL, 0xeed85a3682f7adb4ULL,\n\t0x6c70241c54c4e048ULL, 0xdde44b39af9ed596ULL, 0x2079eb599219f2cbULL,\n\t0x7860281848e8c050ULL, 0x1345fa56bf708ae9ULL, 0x45f6c8b33e39f18dULL,\n\t0x4afacdb03724e987ULL, 0xb4906c24fc513dd8ULL, 0xa0806020e07d1dc0ULL,\n\t0x40f2cbb23932f98bULL, 0xe072ab92d94fe44bULL, 0x15b6f8a34e8971edULL,\n\t0xe7275dc07a134ebaULL, 0x490dcc44c1d61a85ULL, 0xf795a66233913751ULL,\n\t0x5040301070b08060ULL, 0x5eeac1b42b08c99fULL, 0xae2a9184bbc5543fULL,\n\t0x5211c543d4e72297ULL, 0xe576a893de44ec4dULL, 0xed2f5bc274055eb6ULL,\n\t0x7f35de4aebb46aa1ULL, 0x73cedabd145b81a9ULL, 0x89068c8f8a800c05ULL,\n\t0x99b4772dc30275eeULL, 0x76cad9bc135089afULL, 0xd64ab99cf32d946fULL,\n\t0xdfb5be6a0bc97761ULL, 0x5d1dc040ddfa3a9dULL, 0xd41b4ccf577a3698ULL,\n\t0x10b2fba2498279ebULL, 0xba3a9d80a7e97427ULL, 0x6e21d14ff09342bfULL,\n\t0x637c211f5dd9f842ULL, 0xc50f43ca4c5d1e86ULL, 0x3892e3aa71da39dbULL,\n\t0x5715c642d3ec2a91ULL\n};\n\nstatic const u64 T4[256] = {\n\t0xbbb96a01bad3d268ULL, 0xe59a66b154fc4d19ULL, 0xe26514cd2f71bc93ULL,\n\t0x25871b51749ccdb9ULL, 0xf7a257a453f55102ULL, 0xd0d6be03d3686bb8ULL,\n\t0xd6deb504d26b6fbdULL, 0xb35285fe4dd72964ULL, 0xfdba4aad50f05d0dULL,\n\t0xcf09e063ace98a26ULL, 0x091c96848d8a0e83ULL, 0xa5914d1abfdcc679ULL,\n\t0x3da7374d7090ddadULL, 0xf1aa5ca352f65507ULL, 0x7ba417e19ab352c8ULL,\n\t0xb55a8ef94cd42d61ULL, 0x460320acea238f65ULL, 0xc4e68411d56273a6ULL,\n\t0x55cc68c297a466f1ULL, 0xdcc6a80dd16e63b2ULL, 0xaa85d0993355ccffULL,\n\t0xfbb241aa51f35908ULL, 0xc7e20f9c5bed712aULL, 0xf359ae55a6f7a204ULL,\n\t0xfebec120de7f5f81ULL, 0xad7aa2e548d83d75ULL, 0xd729cc7fa8e59a32ULL,\n\t0x71bc0ae899b65ec7ULL, 0xe096e63bdb704b90ULL, 0xac8ddb9e3256c8faULL,\n\t0x95d11522b7c4e651ULL, 0x32b3aacefc19d72bULL, 0x704b7393e338ab48ULL,\n\t0x63843bfd9ebf42dcULL, 0x41fc52d091ae7eefULL, 0x7dac1ce69bb056cdULL,\n\t0x76437894e23baf4dULL, 0xbdb16106bbd0d66dULL, 0x9b32f1da41c31958ULL,\n\t0x7957e5176eb2a5cbULL, 0xf941b35ca5f2ae0bULL, 0x8016564bcb400bc0ULL,\n\t0x677fc20c6bbdb1daULL, 0x59dc7ecc95a26efbULL, 0xe1619f40a1febe1fULL,\n\t0x10cbc3e3f308eb18ULL, 0x81e12f30b1cefe4fULL, 0x0c10160e0206080aULL,\n\t0x922e675ecc4917dbULL, 0xa26e3f66c45137f3ULL, 0x4ee8cf531d277469ULL,\n\t0x78a09c6c143c5044ULL, 0xb0560e73c3582be8ULL, 0x573f9a3463a591f2ULL,\n\t0xe69eed3cda734f95ULL, 0xd3d2358e5de76934ULL, 0xdfc223805fe1613eULL,\n\t0xf2aed72edc79578bULL, 0x13cf486e7d87e994ULL, 0x94266c59cd4a13deULL,\n\t0x1fdf5e607f81e19eULL, 0xc1ea049b5aee752fULL, 0x7547f3196cb4adc1ULL,\n\t0xd5da3e895ce46d31ULL, 0x08ebeffff704fb0cULL, 0xd42d47f2266a98beULL,\n\t0x38abb7c7ff1cdb24ULL, 0x543b11b9ed2a937eULL, 0x4a1336a2e825876fULL,\n\t0x699c26f49dba4ed3ULL, 0x7f5fee106fb1a1ceULL, 0x03048b8d8e8f028cULL,\n\t0x56c8e34f192b647dULL, 0xe7699447a0fdba1aULL, 0x1ad3deeaf00de717ULL,\n\t0x113cba9889861e97ULL, 0x2278692d0f113c33ULL, 0x1238311507091c1bULL,\n\t0xc511fd6aafec8629ULL, 0x208b9bdbfb10cb30ULL, 0x3040583808182028ULL,\n\t0x7ea8976b153f5441ULL, 0x2e687f230d173439ULL, 0x18202c1c040c1014ULL,\n\t0x06080b0701030405ULL, 0x4507ab2164ac8de9ULL, 0xf8b6ca27df7c5b84ULL,\n\t0x29970d5f769ac5b3ULL, 0x0bef6472798bf980ULL, 0xf4a6dc29dd7a538eULL,\n\t0x8ef5b2b33d47f4c9ULL, 0x74b08a62163a584eULL, 0x82e5a4bd3f41fcc3ULL,\n\t0xb2a5fc853759dcebULL, 0x734ff81e6db7a9c4ULL, 0x90dd95a83848e0d8ULL,\n\t0xb1a17708b9d6de67ULL, 0x37bf2a447395d1a2ULL, 0x4c1b3da5e926836aULL,\n\t0xbeb5ea8b355fd4e1ULL, 0xe3926db655ff491cULL, 0x3baf3c4a7193d9a8ULL,\n\t0x07ff727c7b8df18aULL, 0x0f149d838c890a86ULL, 0x31b721437296d5a7ULL,\n\t0x1734b19f88851a92ULL, 0x0ee3e4f8f607ff09ULL, 0xfc4d33d62a7ea882ULL,\n\t0x84edafba3e42f8c6ULL, 0xd9ca28875ee2653bULL, 0xd2254cf527699cbbULL,\n\t0x890ac0cf46ca0543ULL, 0x286074240c14303cULL, 0x430fa02665af89ecULL,\n\t0x6d67df0568b8bdd5ULL, 0x5b2f8c3a61a399f8ULL, 0x0a181d0903050c0fULL,\n\t0xbc46187dc15e23e2ULL, 0xef827bb857f94116ULL, 0xcefe9918d6677fa9ULL,\n\t0xec86f035d976439aULL, 0xcdfa129558e87d25ULL, 0xea8efb32d875479fULL,\n\t0x4917bd2f66aa85e3ULL, 0xc8f6921fd7647bacULL, 0x9ccd83a63a4ee8d2ULL,\n\t0x8a0e4b42c84507cfULL, 0x88fdb9b43c44f0ccULL, 0x268390dcfa13cf35ULL,\n\t0x53c463c596a762f4ULL, 0xf551a552a7f4a601ULL, 0x77b401ef98b55ac2ULL,\n\t0x52331abeec29977bULL, 0xb7a97c0fb8d5da62ULL, 0xa876226fc7543bfcULL,\n\t0xc319f66daeef822cULL, 0x6b6fd40269bbb9d0ULL, 0xa762bfec4bdd317aULL,\n\t0xdd31d176abe0963dULL, 0xd121c778a9e69e37ULL, 0x4f1fb62867a981e6ULL,\n\t0x3c504e360a1e2822ULL, 0x8f02cbc847c90146ULL, 0x16c3c8e4f20bef1dULL,\n\t0x99c1032cb5c2ee5bULL, 0xcc0d6bee226688aaULL, 0x647b4981e532b356ULL,\n\t0x5e230cb0ee2f9f71ULL, 0xa399461dbedfc27cULL, 0xfa4538d12b7dac87ULL,\n\t0x217ce2a0819e3ebfULL, 0x6c90a67e1236485aULL, 0x2d6cf4ae839836b5ULL,\n\t0x5ad8f5411b2d6c77ULL, 0x2470622a0e123836ULL, 0xca0560e923658cafULL,\n\t0x04fbf9f1f502f306ULL, 0x8312ddc645cf094cULL, 0xc61576e7216384a5ULL,\n\t0x9e3e7150ce4f1fd1ULL, 0xab72a9e249db3970ULL, 0xe87d09c42c74b09cULL,\n\t0x2c9b8dd5f916c33aULL, 0x6e635488e637bf59ULL, 0x93d91e25b6c7e254ULL,\n\t0xf05d25d82878a088ULL, 0x72b8816517395c4bULL, 0x2b64ffa9829b32b0ULL,\n\t0x5cd0fe461a2e6872ULL, 0x1d2cac968b80169dULL, 0x3ea3bcc0fe1fdf21ULL,\n\t0x1b24a7918a831298ULL, 0x3648533f091b242dULL, 0x8c064045c94603caULL,\n\t0x354cd8b2879426a1ULL, 0xb94a98f74ed2256bULL, 0x7c5b659de13ea342ULL,\n\t0xe46d1fca2e72b896ULL, 0x62734286e431b753ULL, 0x7a536e9ae03da747ULL,\n\t0x400b2babeb208b60ULL, 0x47f459d790ad7aeaULL, 0xff49b85ba4f1aa0eULL,\n\t0x44f0d25a1e227866ULL, 0x395ccebc85922eabULL, 0x5d27873d60a09dfdULL,\n\t0x0000000000000000ULL, 0xde355afb256f94b1ULL, 0x02f3f2f6f401f703ULL,\n\t0x1cdbd5edf10ee312ULL, 0x5fd475cb94a16afeULL, 0x3a5845310b1d2c27ULL,\n\t0x686b5f8fe734bb5cULL, 0x238f1056759fc9bcULL, 0x582b07b7ef2c9b74ULL,\n\t0xb8bde18c345cd0e4ULL, 0xa695c6973153c4f5ULL, 0xc2ee8f16d46177a3ULL,\n\t0xdacea30ad06d67b7ULL, 0x3344d3b5869722a4ULL, 0x19d755677e82e59bULL,\n\t0xc901eb64adea8e23ULL, 0x34bba1c9fd1ad32eULL, 0xf6552edf297ba48dULL,\n\t0xa09dcd903050c0f0ULL, 0x9ac588a13b4decd7ULL, 0x658c30fa9fbc46d9ULL,\n\t0x2a9386d2f815c73fULL, 0xae7e2968c6573ff9ULL, 0x6a98ad7913354c5fULL,\n\t0x14303a12060a181eULL, 0x1e28271b050f1411ULL, 0xa4663461c55233f6ULL,\n\t0x6688bb7711334455ULL, 0x2f9f06587799c1b6ULL, 0x15c743697c84ed91ULL,\n\t0x01f7797b7a8ef58fULL, 0x0de76f757888fd85ULL, 0xb4adf782365ad8eeULL,\n\t0x48e0c4541c24706cULL, 0x96d59eaf394be4ddULL, 0xcbf2199259eb7920ULL,\n\t0x50c0e84818286078ULL, 0xe98a70bf56fa4513ULL, 0x8df1393eb3c8f645ULL,\n\t0x87e92437b0cdfa4aULL, 0xd83d51fc246c90b4ULL, 0xc01d7de0206080a0ULL,\n\t0x8bf93239b2cbf240ULL, 0x4be44fd992ab72e0ULL, 0xed71894ea3f8b615ULL,\n\t0xba4e137ac05d27e7ULL, 0x851ad6c144cc0d49ULL, 0x5137913362a695f7ULL,\n\t0x6080b07010304050ULL, 0x9fc9082bb4c1ea5eULL, 0x3f54c5bb84912aaeULL,\n\t0x9722e7d443c51152ULL, 0x4dec44de93a876e5ULL, 0xb65e0574c25b2fedULL,\n\t0xa16ab4eb4ade357fULL, 0xa9815b14bddace73ULL, 0x050c808a8f8c0689ULL,\n\t0xee7502c32d77b499ULL, 0xaf895013bcd9ca76ULL, 0x6f942df39cb94ad6ULL,\n\t0x6177c90b6abeb5dfULL, 0x9d3afadd40c01d5dULL, 0x98367a57cf4c1bd4ULL,\n\t0xeb798249a2fbb210ULL, 0x2774e9a7809d3abaULL, 0xbf4293f04fd1216eULL,\n\t0x42f8d95d1f217c63ULL, 0x861e5d4cca430fc5ULL, 0xdb39da71aae39238ULL,\n\t0x912aecd342c61557ULL\n};\n\nstatic const u64 T5[256] = {\n\t0xb9bb016ad3ba68d2ULL, 0x9ae5b166fc54194dULL, 0x65e2cd14712f93bcULL,\n\t0x8725511b9c74b9cdULL, 0xa2f7a457f5530251ULL, 0xd6d003be68d3b86bULL,\n\t0xded604b56bd2bd6fULL, 0x52b3fe85d74d6429ULL, 0xbafdad4af0500d5dULL,\n\t0x09cf63e0e9ac268aULL, 0x1c0984968a8d830eULL, 0x91a51a4ddcbf79c6ULL,\n\t0xa73d4d379070adddULL, 0xaaf1a35cf6520755ULL, 0xa47be117b39ac852ULL,\n\t0x5ab5f98ed44c612dULL, 0x0346ac2023ea658fULL, 0xe6c4118462d5a673ULL,\n\t0xcc55c268a497f166ULL, 0xc6dc0da86ed1b263ULL, 0x85aa99d05533ffccULL,\n\t0xb2fbaa41f3510859ULL, 0xe2c79c0fed5b2a71ULL, 0x59f355aef7a604a2ULL,\n\t0xbefe20c17fde815fULL, 0x7aade5a2d848753dULL, 0x29d77fcce5a8329aULL,\n\t0xbc71e80ab699c75eULL, 0x96e03be670db904bULL, 0x8dac9edb5632fac8ULL,\n\t0xd1952215c4b751e6ULL, 0xb332ceaa19fc2bd7ULL, 0x4b70937338e348abULL,\n\t0x8463fd3bbf9edc42ULL, 0xfc41d052ae91ef7eULL, 0xac7de61cb09bcd56ULL,\n\t0x437694783be24dafULL, 0xb1bd0661d0bb6dd6ULL, 0x329bdaf1c3415819ULL,\n\t0x577917e5b26ecba5ULL, 0x41f95cb3f2a50baeULL, 0x16804b5640cbc00bULL,\n\t0x7f670cc2bd6bdab1ULL, 0xdc59cc7ea295fb6eULL, 0x61e1409ffea11fbeULL,\n\t0xcb10e3c308f318ebULL, 0xe181302fceb14ffeULL, 0x100c0e1606020a08ULL,\n\t0x2e925e6749ccdb17ULL, 0x6ea2663f51c4f337ULL, 0xe84e53cf271d6974ULL,\n\t0xa0786c9c3c144450ULL, 0x56b0730e58c3e82bULL, 0x3f57349aa563f291ULL,\n\t0x9ee63ced73da954fULL, 0xd2d38e35e75d3469ULL, 0xc2df8023e15f3e61ULL,\n\t0xaef22ed779dc8b57ULL, 0xcf136e48877d94e9ULL, 0x2694596c4acdde13ULL,\n\t0xdf1f605e817f9ee1ULL, 0xeac19b04ee5a2f75ULL, 0x477519f3b46cc1adULL,\n\t0xdad5893ee45c316dULL, 0xeb08ffef04f70cfbULL, 0x2dd4f2476a26be98ULL,\n\t0xab38c7b71cff24dbULL, 0x3b54b9112aed7e93ULL, 0x134aa23625e86f87ULL,\n\t0x9c69f426ba9dd34eULL, 0x5f7f10eeb16fcea1ULL, 0x04038d8b8f8e8c02ULL,\n\t0xc8564fe32b197d64ULL, 0x69e74794fda01abaULL, 0xd31aeade0df017e7ULL,\n\t0x3c1198ba8689971eULL, 0x78222d69110f333cULL, 0x3812153109071b1cULL,\n\t0x11c56afdecaf2986ULL, 0x8b20db9b10fb30cbULL, 0x4030385818082820ULL,\n\t0xa87e6b973f154154ULL, 0x682e237f170d3934ULL, 0x20181c2c0c041410ULL,\n\t0x0806070b03010504ULL, 0x074521abac64e98dULL, 0xb6f827ca7cdf845bULL,\n\t0x97295f0d9a76b3c5ULL, 0xef0b72648b7980f9ULL, 0xa6f429dc7add8e53ULL,\n\t0xf58eb3b2473dc9f4ULL, 0xb074628a3a164e58ULL, 0xe582bda4413fc3fcULL,\n\t0xa5b285fc5937ebdcULL, 0x4f731ef8b76dc4a9ULL, 0xdd90a8954838d8e0ULL,\n\t0xa1b10877d6b967deULL, 0xbf37442a9573a2d1ULL, 0x1b4ca53d26e96a83ULL,\n\t0xb5be8bea5f35e1d4ULL, 0x92e3b66dff551c49ULL, 0xaf3b4a3c9371a8d9ULL,\n\t0xff077c728d7b8af1ULL, 0x140f839d898c860aULL, 0xb73143219672a7d5ULL,\n\t0x34179fb18588921aULL, 0xe30ef8e407f609ffULL, 0x4dfcd6337e2a82a8ULL,\n\t0xed84baaf423ec6f8ULL, 0xcad98728e25e3b65ULL, 0x25d2f54c6927bb9cULL,\n\t0x0a89cfc0ca464305ULL, 0x60282474140c3c30ULL, 0x0f4326a0af65ec89ULL,\n\t0x676d05dfb868d5bdULL, 0x2f5b3a8ca361f899ULL, 0x180a091d05030f0cULL,\n\t0x46bc7d185ec1e223ULL, 0x82efb87bf9571641ULL, 0xfece189967d6a97fULL,\n\t0x86ec35f076d99a43ULL, 0xfacd9512e858257dULL, 0x8eea32fb75d89f47ULL,\n\t0x17492fbdaa66e385ULL, 0xf6c81f9264d7ac7bULL, 0xcd9ca6834e3ad2e8ULL,\n\t0x0e8a424b45c8cf07ULL, 0xfd88b4b9443cccf0ULL, 0x8326dc9013fa35cfULL,\n\t0xc453c563a796f462ULL, 0x51f552a5f4a701a6ULL, 0xb477ef01b598c25aULL,\n\t0x3352be1a29ec7b97ULL, 0xa9b70f7cd5b862daULL, 0x76a86f2254c7fc3bULL,\n\t0x19c36df6efae2c82ULL, 0x6f6b02d4bb69d0b9ULL, 0x62a7ecbfdd4b7a31ULL,\n\t0x31dd76d1e0ab3d96ULL, 0x21d178c7e6a9379eULL, 0x1f4f28b6a967e681ULL,\n\t0x503c364e1e0a2228ULL, 0x028fc8cbc9474601ULL, 0xc316e4c80bf21defULL,\n\t0xc1992c03c2b55beeULL, 0x0dccee6b6622aa88ULL, 0x7b64814932e556b3ULL,\n\t0x235eb00c2fee719fULL, 0x99a31d46dfbe7cc2ULL, 0x45fad1387d2b87acULL,\n\t0x7c21a0e29e81bf3eULL, 0x906c7ea636125a48ULL, 0x6c2daef49883b536ULL,\n\t0xd85a41f52d1b776cULL, 0x70242a62120e3638ULL, 0x05cae9606523af8cULL,\n\t0xfb04f1f902f506f3ULL, 0x1283c6ddcf454c09ULL, 0x15c6e7766321a584ULL,\n\t0x3e9e50714fced11fULL, 0x72abe2a9db497039ULL, 0x7de8c409742c9cb0ULL,\n\t0x9b2cd58d16f93ac3ULL, 0x636e885437e659bfULL, 0xd993251ec7b654e2ULL,\n\t0x5df0d825782888a0ULL, 0xb872658139174b5cULL, 0x642ba9ff9b82b032ULL,\n\t0xd05c46fe2e1a7268ULL, 0x2c1d96ac808b9d16ULL, 0xa33ec0bc1ffe21dfULL,\n\t0x241b91a7838a9812ULL, 0x48363f531b092d24ULL, 0x068c454046c9ca03ULL,\n\t0x4c35b2d89487a126ULL, 0x4ab9f798d24e6b25ULL, 0x5b7c9d653ee142a3ULL,\n\t0x6de4ca1f722e96b8ULL, 0x7362864231e453b7ULL, 0x537a9a6e3de047a7ULL,\n\t0x0b40ab2b20eb608bULL, 0xf447d759ad90ea7aULL, 0x49ff5bb8f1a40eaaULL,\n\t0xf0445ad2221e6678ULL, 0x5c39bcce9285ab2eULL, 0x275d3d87a060fd9dULL,\n\t0x0000000000000000ULL, 0x35defb5a6f25b194ULL, 0xf302f6f201f403f7ULL,\n\t0xdb1cedd50ef112e3ULL, 0xd45fcb75a194fe6aULL, 0x583a31451d0b272cULL,\n\t0x6b688f5f34e75cbbULL, 0x8f2356109f75bcc9ULL, 0x2b58b7072cef749bULL,\n\t0xbdb88ce15c34e4d0ULL, 0x95a697c65331f5c4ULL, 0xeec2168f61d4a377ULL,\n\t0xceda0aa36dd0b767ULL, 0x4433b5d39786a422ULL, 0xd7196755827e9be5ULL,\n\t0x01c964ebeaad238eULL, 0xbb34c9a11afd2ed3ULL, 0x55f6df2e7b298da4ULL,\n\t0x9da090cd5030f0c0ULL, 0xc59aa1884d3bd7ecULL, 0x8c65fa30bc9fd946ULL,\n\t0x932ad28615f83fc7ULL, 0x7eae682957c6f93fULL, 0x986a79ad35135f4cULL,\n\t0x3014123a0a061e18ULL, 0x281e1b270f051114ULL, 0x66a4613452c5f633ULL,\n\t0x886677bb33115544ULL, 0x9f2f58069977b6c1ULL, 0xc7156943847c91edULL,\n\t0xf7017b798e7a8ff5ULL, 0xe70d756f887885fdULL, 0xadb482f75a36eed8ULL,\n\t0xe04854c4241c6c70ULL, 0xd596af9e4b39dde4ULL, 0xf2cb9219eb592079ULL,\n\t0xc05048e828187860ULL, 0x8ae9bf70fa561345ULL, 0xf18d3e39c8b345f6ULL,\n\t0xe9873724cdb04afaULL, 0x3dd8fc516c24b490ULL, 0x1dc0e07d6020a080ULL,\n\t0xf98b3932cbb240f2ULL, 0xe44bd94fab92e072ULL, 0x71ed4e89f8a315b6ULL,\n\t0x4eba7a135dc0e727ULL, 0x1a85c1d6cc44490dULL, 0x37513391a662f795ULL,\n\t0x806070b030105040ULL, 0xc99f2b08c1b45eeaULL, 0x543fbbc59184ae2aULL,\n\t0x2297d4e7c5435211ULL, 0xec4dde44a893e576ULL, 0x5eb674055bc2ed2fULL,\n\t0x6aa1ebb4de4a7f35ULL, 0x81a9145bdabd73ceULL, 0x0c058a808c8f8906ULL,\n\t0x75eec302772d99b4ULL, 0x89af1350d9bc76caULL, 0x946ff32db99cd64aULL,\n\t0x77610bc9be6adfb5ULL, 0x3a9dddfac0405d1dULL, 0x3698577a4ccfd41bULL,\n\t0x79eb4982fba210b2ULL, 0x7427a7e99d80ba3aULL, 0x42bff093d14f6e21ULL,\n\t0xf8425dd9211f637cULL, 0x1e864c5d43cac50fULL, 0x39db71dae3aa3892ULL,\n\t0x2a91d3ecc6425715ULL\n};\n\nstatic const u64 T6[256] = {\n\t0x6a01bbb9d268bad3ULL, 0x66b1e59a4d1954fcULL, 0x14cde265bc932f71ULL,\n\t0x1b512587cdb9749cULL, 0x57a4f7a2510253f5ULL, 0xbe03d0d66bb8d368ULL,\n\t0xb504d6de6fbdd26bULL, 0x85feb35229644dd7ULL, 0x4aadfdba5d0d50f0ULL,\n\t0xe063cf098a26ace9ULL, 0x9684091c0e838d8aULL, 0x4d1aa591c679bfdcULL,\n\t0x374d3da7ddad7090ULL, 0x5ca3f1aa550752f6ULL, 0x17e17ba452c89ab3ULL,\n\t0x8ef9b55a2d614cd4ULL, 0x20ac46038f65ea23ULL, 0x8411c4e673a6d562ULL,\n\t0x68c255cc66f197a4ULL, 0xa80ddcc663b2d16eULL, 0xd099aa85ccff3355ULL,\n\t0x41aafbb2590851f3ULL, 0x0f9cc7e2712a5bedULL, 0xae55f359a204a6f7ULL,\n\t0xc120febe5f81de7fULL, 0xa2e5ad7a3d7548d8ULL, 0xcc7fd7299a32a8e5ULL,\n\t0x0ae871bc5ec799b6ULL, 0xe63be0964b90db70ULL, 0xdb9eac8dc8fa3256ULL,\n\t0x152295d1e651b7c4ULL, 0xaace32b3d72bfc19ULL, 0x7393704bab48e338ULL,\n\t0x3bfd638442dc9ebfULL, 0x52d041fc7eef91aeULL, 0x1ce67dac56cd9bb0ULL,\n\t0x78947643af4de23bULL, 0x6106bdb1d66dbbd0ULL, 0xf1da9b32195841c3ULL,\n\t0xe5177957a5cb6eb2ULL, 0xb35cf941ae0ba5f2ULL, 0x564b80160bc0cb40ULL,\n\t0xc20c677fb1da6bbdULL, 0x7ecc59dc6efb95a2ULL, 0x9f40e161be1fa1feULL,\n\t0xc3e310cbeb18f308ULL, 0x2f3081e1fe4fb1ceULL, 0x160e0c10080a0206ULL,\n\t0x675e922e17dbcc49ULL, 0x3f66a26e37f3c451ULL, 0xcf534ee874691d27ULL,\n\t0x9c6c78a05044143cULL, 0x0e73b0562be8c358ULL, 0x9a34573f91f263a5ULL,\n\t0xed3ce69e4f95da73ULL, 0x358ed3d269345de7ULL, 0x2380dfc2613e5fe1ULL,\n\t0xd72ef2ae578bdc79ULL, 0x486e13cfe9947d87ULL, 0x6c59942613decd4aULL,\n\t0x5e601fdfe19e7f81ULL, 0x049bc1ea752f5aeeULL, 0xf3197547adc16cb4ULL,\n\t0x3e89d5da6d315ce4ULL, 0xefff08ebfb0cf704ULL, 0x47f2d42d98be266aULL,\n\t0xb7c738abdb24ff1cULL, 0x11b9543b937eed2aULL, 0x36a24a13876fe825ULL,\n\t0x26f4699c4ed39dbaULL, 0xee107f5fa1ce6fb1ULL, 0x8b8d0304028c8e8fULL,\n\t0xe34f56c8647d192bULL, 0x9447e769ba1aa0fdULL, 0xdeea1ad3e717f00dULL,\n\t0xba98113c1e978986ULL, 0x692d22783c330f11ULL, 0x311512381c1b0709ULL,\n\t0xfd6ac5118629afecULL, 0x9bdb208bcb30fb10ULL, 0x5838304020280818ULL,\n\t0x976b7ea85441153fULL, 0x7f232e6834390d17ULL, 0x2c1c18201014040cULL,\n\t0x0b07060804050103ULL, 0xab2145078de964acULL, 0xca27f8b65b84df7cULL,\n\t0x0d5f2997c5b3769aULL, 0x64720beff980798bULL, 0xdc29f4a6538edd7aULL,\n\t0xb2b38ef5f4c93d47ULL, 0x8a6274b0584e163aULL, 0xa4bd82e5fcc33f41ULL,\n\t0xfc85b2a5dceb3759ULL, 0xf81e734fa9c46db7ULL, 0x95a890dde0d83848ULL,\n\t0x7708b1a1de67b9d6ULL, 0x2a4437bfd1a27395ULL, 0x3da54c1b836ae926ULL,\n\t0xea8bbeb5d4e1355fULL, 0x6db6e392491c55ffULL, 0x3c4a3bafd9a87193ULL,\n\t0x727c07fff18a7b8dULL, 0x9d830f140a868c89ULL, 0x214331b7d5a77296ULL,\n\t0xb19f17341a928885ULL, 0xe4f80ee3ff09f607ULL, 0x33d6fc4da8822a7eULL,\n\t0xafba84edf8c63e42ULL, 0x2887d9ca653b5ee2ULL, 0x4cf5d2259cbb2769ULL,\n\t0xc0cf890a054346caULL, 0x74242860303c0c14ULL, 0xa026430f89ec65afULL,\n\t0xdf056d67bdd568b8ULL, 0x8c3a5b2f99f861a3ULL, 0x1d090a180c0f0305ULL,\n\t0x187dbc4623e2c15eULL, 0x7bb8ef82411657f9ULL, 0x9918cefe7fa9d667ULL,\n\t0xf035ec86439ad976ULL, 0x1295cdfa7d2558e8ULL, 0xfb32ea8e479fd875ULL,\n\t0xbd2f491785e366aaULL, 0x921fc8f67bacd764ULL, 0x83a69ccde8d23a4eULL,\n\t0x4b428a0e07cfc845ULL, 0xb9b488fdf0cc3c44ULL, 0x90dc2683cf35fa13ULL,\n\t0x63c553c462f496a7ULL, 0xa552f551a601a7f4ULL, 0x01ef77b45ac298b5ULL,\n\t0x1abe5233977bec29ULL, 0x7c0fb7a9da62b8d5ULL, 0x226fa8763bfcc754ULL,\n\t0xf66dc319822caeefULL, 0xd4026b6fb9d069bbULL, 0xbfeca762317a4bddULL,\n\t0xd176dd31963dabe0ULL, 0xc778d1219e37a9e6ULL, 0xb6284f1f81e667a9ULL,\n\t0x4e363c5028220a1eULL, 0xcbc88f02014647c9ULL, 0xc8e416c3ef1df20bULL,\n\t0x032c99c1ee5bb5c2ULL, 0x6beecc0d88aa2266ULL, 0x4981647bb356e532ULL,\n\t0x0cb05e239f71ee2fULL, 0x461da399c27cbedfULL, 0x38d1fa45ac872b7dULL,\n\t0xe2a0217c3ebf819eULL, 0xa67e6c90485a1236ULL, 0xf4ae2d6c36b58398ULL,\n\t0xf5415ad86c771b2dULL, 0x622a247038360e12ULL, 0x60e9ca058caf2365ULL,\n\t0xf9f104fbf306f502ULL, 0xddc68312094c45cfULL, 0x76e7c61584a52163ULL,\n\t0x71509e3e1fd1ce4fULL, 0xa9e2ab72397049dbULL, 0x09c4e87db09c2c74ULL,\n\t0x8dd52c9bc33af916ULL, 0x54886e63bf59e637ULL, 0x1e2593d9e254b6c7ULL,\n\t0x25d8f05da0882878ULL, 0x816572b85c4b1739ULL, 0xffa92b6432b0829bULL,\n\t0xfe465cd068721a2eULL, 0xac961d2c169d8b80ULL, 0xbcc03ea3df21fe1fULL,\n\t0xa7911b2412988a83ULL, 0x533f3648242d091bULL, 0x40458c0603cac946ULL,\n\t0xd8b2354c26a18794ULL, 0x98f7b94a256b4ed2ULL, 0x659d7c5ba342e13eULL,\n\t0x1fcae46db8962e72ULL, 0x42866273b753e431ULL, 0x6e9a7a53a747e03dULL,\n\t0x2bab400b8b60eb20ULL, 0x59d747f47aea90adULL, 0xb85bff49aa0ea4f1ULL,\n\t0xd25a44f078661e22ULL, 0xcebc395c2eab8592ULL, 0x873d5d279dfd60a0ULL,\n\t0x0000000000000000ULL, 0x5afbde3594b1256fULL, 0xf2f602f3f703f401ULL,\n\t0xd5ed1cdbe312f10eULL, 0x75cb5fd46afe94a1ULL, 0x45313a582c270b1dULL,\n\t0x5f8f686bbb5ce734ULL, 0x1056238fc9bc759fULL, 0x07b7582b9b74ef2cULL,\n\t0xe18cb8bdd0e4345cULL, 0xc697a695c4f53153ULL, 0x8f16c2ee77a3d461ULL,\n\t0xa30adace67b7d06dULL, 0xd3b5334422a48697ULL, 0x556719d7e59b7e82ULL,\n\t0xeb64c9018e23adeaULL, 0xa1c934bbd32efd1aULL, 0x2edff655a48d297bULL,\n\t0xcd90a09dc0f03050ULL, 0x88a19ac5ecd73b4dULL, 0x30fa658c46d99fbcULL,\n\t0x86d22a93c73ff815ULL, 0x2968ae7e3ff9c657ULL, 0xad796a984c5f1335ULL,\n\t0x3a121430181e060aULL, 0x271b1e281411050fULL, 0x3461a46633f6c552ULL,\n\t0xbb77668844551133ULL, 0x06582f9fc1b67799ULL, 0x436915c7ed917c84ULL,\n\t0x797b01f7f58f7a8eULL, 0x6f750de7fd857888ULL, 0xf782b4add8ee365aULL,\n\t0xc45448e0706c1c24ULL, 0x9eaf96d5e4dd394bULL, 0x1992cbf2792059ebULL,\n\t0xe84850c060781828ULL, 0x70bfe98a451356faULL, 0x393e8df1f645b3c8ULL,\n\t0x243787e9fa4ab0cdULL, 0x51fcd83d90b4246cULL, 0x7de0c01d80a02060ULL,\n\t0x32398bf9f240b2cbULL, 0x4fd94be472e092abULL, 0x894eed71b615a3f8ULL,\n\t0x137aba4e27e7c05dULL, 0xd6c1851a0d4944ccULL, 0x9133513795f762a6ULL,\n\t0xb070608040501030ULL, 0x082b9fc9ea5eb4c1ULL, 0xc5bb3f542aae8491ULL,\n\t0xe7d49722115243c5ULL, 0x44de4dec76e593a8ULL, 0x0574b65e2fedc25bULL,\n\t0xb4eba16a357f4adeULL, 0x5b14a981ce73bddaULL, 0x808a050c06898f8cULL,\n\t0x02c3ee75b4992d77ULL, 0x5013af89ca76bcd9ULL, 0x2df36f944ad69cb9ULL,\n\t0xc90b6177b5df6abeULL, 0xfadd9d3a1d5d40c0ULL, 0x7a5798361bd4cf4cULL,\n\t0x8249eb79b210a2fbULL, 0xe9a727743aba809dULL, 0x93f0bf42216e4fd1ULL,\n\t0xd95d42f87c631f21ULL, 0x5d4c861e0fc5ca43ULL, 0xda71db399238aae3ULL,\n\t0xecd3912a155742c6ULL\n};\n\nstatic const u64 T7[256] = {\n\t0x016ab9bb68d2d3baULL, 0xb1669ae5194dfc54ULL, 0xcd1465e293bc712fULL,\n\t0x511b8725b9cd9c74ULL, 0xa457a2f70251f553ULL, 0x03bed6d0b86b68d3ULL,\n\t0x04b5ded6bd6f6bd2ULL, 0xfe8552b36429d74dULL, 0xad4abafd0d5df050ULL,\n\t0x63e009cf268ae9acULL, 0x84961c09830e8a8dULL, 0x1a4d91a579c6dcbfULL,\n\t0x4d37a73daddd9070ULL, 0xa35caaf10755f652ULL, 0xe117a47bc852b39aULL,\n\t0xf98e5ab5612dd44cULL, 0xac200346658f23eaULL, 0x1184e6c4a67362d5ULL,\n\t0xc268cc55f166a497ULL, 0x0da8c6dcb2636ed1ULL, 0x99d085aaffcc5533ULL,\n\t0xaa41b2fb0859f351ULL, 0x9c0fe2c72a71ed5bULL, 0x55ae59f304a2f7a6ULL,\n\t0x20c1befe815f7fdeULL, 0xe5a27aad753dd848ULL, 0x7fcc29d7329ae5a8ULL,\n\t0xe80abc71c75eb699ULL, 0x3be696e0904b70dbULL, 0x9edb8dacfac85632ULL,\n\t0x2215d19551e6c4b7ULL, 0xceaab3322bd719fcULL, 0x93734b7048ab38e3ULL,\n\t0xfd3b8463dc42bf9eULL, 0xd052fc41ef7eae91ULL, 0xe61cac7dcd56b09bULL,\n\t0x947843764daf3be2ULL, 0x0661b1bd6dd6d0bbULL, 0xdaf1329b5819c341ULL,\n\t0x17e55779cba5b26eULL, 0x5cb341f90baef2a5ULL, 0x4b561680c00b40cbULL,\n\t0x0cc27f67dab1bd6bULL, 0xcc7edc59fb6ea295ULL, 0x409f61e11fbefea1ULL,\n\t0xe3c3cb1018eb08f3ULL, 0x302fe1814ffeceb1ULL, 0x0e16100c0a080602ULL,\n\t0x5e672e92db1749ccULL, 0x663f6ea2f33751c4ULL, 0x53cfe84e6974271dULL,\n\t0x6c9ca07844503c14ULL, 0x730e56b0e82b58c3ULL, 0x349a3f57f291a563ULL,\n\t0x3ced9ee6954f73daULL, 0x8e35d2d33469e75dULL, 0x8023c2df3e61e15fULL,\n\t0x2ed7aef28b5779dcULL, 0x6e48cf1394e9877dULL, 0x596c2694de134acdULL,\n\t0x605edf1f9ee1817fULL, 0x9b04eac12f75ee5aULL, 0x19f34775c1adb46cULL,\n\t0x893edad5316de45cULL, 0xffefeb080cfb04f7ULL, 0xf2472dd4be986a26ULL,\n\t0xc7b7ab3824db1cffULL, 0xb9113b547e932aedULL, 0xa236134a6f8725e8ULL,\n\t0xf4269c69d34eba9dULL, 0x10ee5f7fcea1b16fULL, 0x8d8b04038c028f8eULL,\n\t0x4fe3c8567d642b19ULL, 0x479469e71abafda0ULL, 0xeaded31a17e70df0ULL,\n\t0x98ba3c11971e8689ULL, 0x2d697822333c110fULL, 0x153138121b1c0907ULL,\n\t0x6afd11c52986ecafULL, 0xdb9b8b2030cb10fbULL, 0x3858403028201808ULL,\n\t0x6b97a87e41543f15ULL, 0x237f682e3934170dULL, 0x1c2c201814100c04ULL,\n\t0x070b080605040301ULL, 0x21ab0745e98dac64ULL, 0x27cab6f8845b7cdfULL,\n\t0x5f0d9729b3c59a76ULL, 0x7264ef0b80f98b79ULL, 0x29dca6f48e537addULL,\n\t0xb3b2f58ec9f4473dULL, 0x628ab0744e583a16ULL, 0xbda4e582c3fc413fULL,\n\t0x85fca5b2ebdc5937ULL, 0x1ef84f73c4a9b76dULL, 0xa895dd90d8e04838ULL,\n\t0x0877a1b167ded6b9ULL, 0x442abf37a2d19573ULL, 0xa53d1b4c6a8326e9ULL,\n\t0x8beab5bee1d45f35ULL, 0xb66d92e31c49ff55ULL, 0x4a3caf3ba8d99371ULL,\n\t0x7c72ff078af18d7bULL, 0x839d140f860a898cULL, 0x4321b731a7d59672ULL,\n\t0x9fb13417921a8588ULL, 0xf8e4e30e09ff07f6ULL, 0xd6334dfc82a87e2aULL,\n\t0xbaafed84c6f8423eULL, 0x8728cad93b65e25eULL, 0xf54c25d2bb9c6927ULL,\n\t0xcfc00a894305ca46ULL, 0x247460283c30140cULL, 0x26a00f43ec89af65ULL,\n\t0x05df676dd5bdb868ULL, 0x3a8c2f5bf899a361ULL, 0x091d180a0f0c0503ULL,\n\t0x7d1846bce2235ec1ULL, 0xb87b82ef1641f957ULL, 0x1899fecea97f67d6ULL,\n\t0x35f086ec9a4376d9ULL, 0x9512facd257de858ULL, 0x32fb8eea9f4775d8ULL,\n\t0x2fbd1749e385aa66ULL, 0x1f92f6c8ac7b64d7ULL, 0xa683cd9cd2e84e3aULL,\n\t0x424b0e8acf0745c8ULL, 0xb4b9fd88ccf0443cULL, 0xdc90832635cf13faULL,\n\t0xc563c453f462a796ULL, 0x52a551f501a6f4a7ULL, 0xef01b477c25ab598ULL,\n\t0xbe1a33527b9729ecULL, 0x0f7ca9b762dad5b8ULL, 0x6f2276a8fc3b54c7ULL,\n\t0x6df619c32c82efaeULL, 0x02d46f6bd0b9bb69ULL, 0xecbf62a77a31dd4bULL,\n\t0x76d131dd3d96e0abULL, 0x78c721d1379ee6a9ULL, 0x28b61f4fe681a967ULL,\n\t0x364e503c22281e0aULL, 0xc8cb028f4601c947ULL, 0xe4c8c3161def0bf2ULL,\n\t0x2c03c1995beec2b5ULL, 0xee6b0dccaa886622ULL, 0x81497b6456b332e5ULL,\n\t0xb00c235e719f2feeULL, 0x1d4699a37cc2dfbeULL, 0xd13845fa87ac7d2bULL,\n\t0xa0e27c21bf3e9e81ULL, 0x7ea6906c5a483612ULL, 0xaef46c2db5369883ULL,\n\t0x41f5d85a776c2d1bULL, 0x2a6270243638120eULL, 0xe96005caaf8c6523ULL,\n\t0xf1f9fb0406f302f5ULL, 0xc6dd12834c09cf45ULL, 0xe77615c6a5846321ULL,\n\t0x50713e9ed11f4fceULL, 0xe2a972ab7039db49ULL, 0xc4097de89cb0742cULL,\n\t0xd58d9b2c3ac316f9ULL, 0x8854636e59bf37e6ULL, 0x251ed99354e2c7b6ULL,\n\t0xd8255df088a07828ULL, 0x6581b8724b5c3917ULL, 0xa9ff642bb0329b82ULL,\n\t0x46fed05c72682e1aULL, 0x96ac2c1d9d16808bULL, 0xc0bca33e21df1ffeULL,\n\t0x91a7241b9812838aULL, 0x3f5348362d241b09ULL, 0x4540068cca0346c9ULL,\n\t0xb2d84c35a1269487ULL, 0xf7984ab96b25d24eULL, 0x9d655b7c42a33ee1ULL,\n\t0xca1f6de496b8722eULL, 0x8642736253b731e4ULL, 0x9a6e537a47a73de0ULL,\n\t0xab2b0b40608b20ebULL, 0xd759f447ea7aad90ULL, 0x5bb849ff0eaaf1a4ULL,\n\t0x5ad2f0446678221eULL, 0xbcce5c39ab2e9285ULL, 0x3d87275dfd9da060ULL,\n\t0x0000000000000000ULL, 0xfb5a35deb1946f25ULL, 0xf6f2f30203f701f4ULL,\n\t0xedd5db1c12e30ef1ULL, 0xcb75d45ffe6aa194ULL, 0x3145583a272c1d0bULL,\n\t0x8f5f6b685cbb34e7ULL, 0x56108f23bcc99f75ULL, 0xb7072b58749b2cefULL,\n\t0x8ce1bdb8e4d05c34ULL, 0x97c695a6f5c45331ULL, 0x168feec2a37761d4ULL,\n\t0x0aa3cedab7676dd0ULL, 0xb5d34433a4229786ULL, 0x6755d7199be5827eULL,\n\t0x64eb01c9238eeaadULL, 0xc9a1bb342ed31afdULL, 0xdf2e55f68da47b29ULL,\n\t0x90cd9da0f0c05030ULL, 0xa188c59ad7ec4d3bULL, 0xfa308c65d946bc9fULL,\n\t0xd286932a3fc715f8ULL, 0x68297eaef93f57c6ULL, 0x79ad986a5f4c3513ULL,\n\t0x123a30141e180a06ULL, 0x1b27281e11140f05ULL, 0x613466a4f63352c5ULL,\n\t0x77bb886655443311ULL, 0x58069f2fb6c19977ULL, 0x6943c71591ed847cULL,\n\t0x7b79f7018ff58e7aULL, 0x756fe70d85fd8878ULL, 0x82f7adb4eed85a36ULL,\n\t0x54c4e0486c70241cULL, 0xaf9ed596dde44b39ULL, 0x9219f2cb2079eb59ULL,\n\t0x48e8c05078602818ULL, 0xbf708ae91345fa56ULL, 0x3e39f18d45f6c8b3ULL,\n\t0x3724e9874afacdb0ULL, 0xfc513dd8b4906c24ULL, 0xe07d1dc0a0806020ULL,\n\t0x3932f98b40f2cbb2ULL, 0xd94fe44be072ab92ULL, 0x4e8971ed15b6f8a3ULL,\n\t0x7a134ebae7275dc0ULL, 0xc1d61a85490dcc44ULL, 0x33913751f795a662ULL,\n\t0x70b0806050403010ULL, 0x2b08c99f5eeac1b4ULL, 0xbbc5543fae2a9184ULL,\n\t0xd4e722975211c543ULL, 0xde44ec4de576a893ULL, 0x74055eb6ed2f5bc2ULL,\n\t0xebb46aa17f35de4aULL, 0x145b81a973cedabdULL, 0x8a800c0589068c8fULL,\n\t0xc30275ee99b4772dULL, 0x135089af76cad9bcULL, 0xf32d946fd64ab99cULL,\n\t0x0bc97761dfb5be6aULL, 0xddfa3a9d5d1dc040ULL, 0x577a3698d41b4ccfULL,\n\t0x498279eb10b2fba2ULL, 0xa7e97427ba3a9d80ULL, 0xf09342bf6e21d14fULL,\n\t0x5dd9f842637c211fULL, 0x4c5d1e86c50f43caULL, 0x71da39db3892e3aaULL,\n\t0xd3ec2a915715c642ULL\n};\n\nstatic const u64 c[KHAZAD_ROUNDS + 1] = {\n\t0xba542f7453d3d24dULL, 0x50ac8dbf70529a4cULL, 0xead597d133515ba6ULL,\n\t0xde48a899db32b7fcULL, 0xe39e919be2bb416eULL, 0xa5cb6b95a1f3b102ULL,\n\t0xccc41d14c363da5dULL, 0x5fdc7dcd7f5a6c5cULL, 0xf726ffede89d6f8eULL\n};\n\nstatic int khazad_setkey(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t\t unsigned int key_len)\n{\n\tstruct khazad_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __be32 *key = (const __be32 *)in_key;\n\tint r;\n\tconst u64 *S = T7;\n\tu64 K2, K1;\n\n\t/* key is supposed to be 32-bit aligned */\n\tK2 = ((u64)be32_to_cpu(key[0]) << 32) | be32_to_cpu(key[1]);\n\tK1 = ((u64)be32_to_cpu(key[2]) << 32) | be32_to_cpu(key[3]);\n\n\t/* setup the encrypt key */\n\tfor (r = 0; r <= KHAZAD_ROUNDS; r++) {\n\t\tctx->E[r] = T0[(int)(K1 >> 56)       ] ^\n\t\t\t    T1[(int)(K1 >> 48) & 0xff] ^\n\t\t\t    T2[(int)(K1 >> 40) & 0xff] ^\n\t\t\t    T3[(int)(K1 >> 32) & 0xff] ^\n\t\t\t    T4[(int)(K1 >> 24) & 0xff] ^\n\t\t\t    T5[(int)(K1 >> 16) & 0xff] ^\n\t\t\t    T6[(int)(K1 >>  8) & 0xff] ^\n\t\t\t    T7[(int)(K1      ) & 0xff] ^\n\t\t\t    c[r] ^ K2;\n\t\tK2 = K1; \n\t\tK1 = ctx->E[r];\n\t}\n\t/* Setup the decrypt key */\n\tctx->D[0] = ctx->E[KHAZAD_ROUNDS];\n\tfor (r = 1; r < KHAZAD_ROUNDS; r++) {\n\t\tK1 = ctx->E[KHAZAD_ROUNDS - r];\n\t\tctx->D[r] = T0[(int)S[(int)(K1 >> 56)       ] & 0xff] ^\n\t\t\t    T1[(int)S[(int)(K1 >> 48) & 0xff] & 0xff] ^\n\t\t\t    T2[(int)S[(int)(K1 >> 40) & 0xff] & 0xff] ^\n\t\t\t    T3[(int)S[(int)(K1 >> 32) & 0xff] & 0xff] ^\n\t\t\t    T4[(int)S[(int)(K1 >> 24) & 0xff] & 0xff] ^\n\t\t\t    T5[(int)S[(int)(K1 >> 16) & 0xff] & 0xff] ^\n\t\t\t    T6[(int)S[(int)(K1 >>  8) & 0xff] & 0xff] ^\n\t\t\t    T7[(int)S[(int)(K1      ) & 0xff] & 0xff];\n\t}\n\tctx->D[KHAZAD_ROUNDS] = ctx->E[0];\n\n\treturn 0;\n\n}\n\nstatic void khazad_crypt(const u64 roundKey[KHAZAD_ROUNDS + 1],\n\t\tu8 *ciphertext, const u8 *plaintext)\n{\n\tconst __be64 *src = (const __be64 *)plaintext;\n\t__be64 *dst = (__be64 *)ciphertext;\n\tint r;\n\tu64 state;\n\n\tstate = be64_to_cpu(*src) ^ roundKey[0];\n\n\tfor (r = 1; r < KHAZAD_ROUNDS; r++) {\n\t\tstate = T0[(int)(state >> 56)       ] ^\n\t\t\tT1[(int)(state >> 48) & 0xff] ^\n\t\t\tT2[(int)(state >> 40) & 0xff] ^\n\t\t\tT3[(int)(state >> 32) & 0xff] ^\n\t\t\tT4[(int)(state >> 24) & 0xff] ^\n\t\t\tT5[(int)(state >> 16) & 0xff] ^\n\t\t\tT6[(int)(state >>  8) & 0xff] ^\n\t\t\tT7[(int)(state      ) & 0xff] ^\n\t\t\troundKey[r];\n    \t}\n\n\tstate = (T0[(int)(state >> 56)       ] & 0xff00000000000000ULL) ^\n\t\t(T1[(int)(state >> 48) & 0xff] & 0x00ff000000000000ULL) ^\n\t\t(T2[(int)(state >> 40) & 0xff] & 0x0000ff0000000000ULL) ^\n\t\t(T3[(int)(state >> 32) & 0xff] & 0x000000ff00000000ULL) ^\n\t\t(T4[(int)(state >> 24) & 0xff] & 0x00000000ff000000ULL) ^\n\t\t(T5[(int)(state >> 16) & 0xff] & 0x0000000000ff0000ULL) ^\n\t\t(T6[(int)(state >>  8) & 0xff] & 0x000000000000ff00ULL) ^\n\t\t(T7[(int)(state      ) & 0xff] & 0x00000000000000ffULL) ^\n\t\troundKey[KHAZAD_ROUNDS];\n\n\t*dst = cpu_to_be64(state);\n}\n\nstatic void khazad_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct khazad_ctx *ctx = crypto_tfm_ctx(tfm);\n\tkhazad_crypt(ctx->E, dst, src);\n}\n\nstatic void khazad_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct khazad_ctx *ctx = crypto_tfm_ctx(tfm);\n\tkhazad_crypt(ctx->D, dst, src);\n}\n\nstatic struct crypto_alg khazad_alg = {\n\t.cra_name\t\t=\t\"khazad\",\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tKHAZAD_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof (struct khazad_ctx),\n\t.cra_alignmask\t\t=\t7,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\tKHAZAD_KEY_SIZE,\n\t.cia_max_keysize\t=\tKHAZAD_KEY_SIZE,\n\t.cia_setkey\t\t= \tkhazad_setkey,\n\t.cia_encrypt\t\t=\tkhazad_encrypt,\n\t.cia_decrypt\t\t=\tkhazad_decrypt } }\n};\n\nstatic int __init khazad_mod_init(void)\n{\n\tint ret = 0;\n\t\n\tret = crypto_register_alg(&khazad_alg);\n\treturn ret;\n}\n\nstatic void __exit khazad_mod_fini(void)\n{\n\tcrypto_unregister_alg(&khazad_alg);\n}\n\n\nmodule_init(khazad_mod_init);\nmodule_exit(khazad_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Khazad Cryptographic Algorithm\");\nMODULE_ALIAS_CRYPTO(\"khazad\");\n", "/*\n * RNG implementation using standard kernel RNG.\n *\n * Copyright (c) 2008 Herbert Xu <herbert@gondor.apana.org.au>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the\n * Free Software Foundation; either version 2 of the License, or (at your\n * any later version.\n *\n */\n\n#include <crypto/internal/rng.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/random.h>\n\nstatic int krng_get_random(struct crypto_rng *tfm, u8 *rdata, unsigned int dlen)\n{\n\tget_random_bytes(rdata, dlen);\n\treturn 0;\n}\n\nstatic int krng_reset(struct crypto_rng *tfm, u8 *seed, unsigned int slen)\n{\n\treturn 0;\n}\n\nstatic struct crypto_alg krng_alg = {\n\t.cra_name\t\t= \"stdrng\",\n\t.cra_driver_name\t= \"krng\",\n\t.cra_priority\t\t= 200,\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_RNG,\n\t.cra_ctxsize\t\t= 0,\n\t.cra_type\t\t= &crypto_rng_type,\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_u\t\t\t= {\n\t\t.rng = {\n\t\t\t.rng_make_random\t= krng_get_random,\n\t\t\t.rng_reset\t\t= krng_reset,\n\t\t\t.seedsize\t\t= 0,\n\t\t}\n\t}\n};\n\n\n/* Module initalization */\nstatic int __init krng_mod_init(void)\n{\n\treturn crypto_register_alg(&krng_alg);\n}\n\nstatic void __exit krng_mod_fini(void)\n{\n\tcrypto_unregister_alg(&krng_alg);\n\treturn;\n}\n\nmodule_init(krng_mod_init);\nmodule_exit(krng_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Kernel Random Number Generator\");\nMODULE_ALIAS_CRYPTO(\"stdrng\");\n", "/*\n * Cryptographic API.\n *\n * Copyright (c) 2013 Chanho Min <chanho.min@lge.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License version 2 as published by\n * the Free Software Foundation.\n *\n * This program is distributed in the hope that it will be useful, but WITHOUT\n * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for\n * more details.\n *\n * You should have received a copy of the GNU General Public License along with\n * this program; if not, write to the Free Software Foundation, Inc., 51\n * Franklin St, Fifth Floor, Boston, MA 02110-1301 USA\n *\n */\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/crypto.h>\n#include <linux/vmalloc.h>\n#include <linux/lz4.h>\n\nstruct lz4_ctx {\n\tvoid *lz4_comp_mem;\n};\n\nstatic int lz4_init(struct crypto_tfm *tfm)\n{\n\tstruct lz4_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tctx->lz4_comp_mem = vmalloc(LZ4_MEM_COMPRESS);\n\tif (!ctx->lz4_comp_mem)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic void lz4_exit(struct crypto_tfm *tfm)\n{\n\tstruct lz4_ctx *ctx = crypto_tfm_ctx(tfm);\n\tvfree(ctx->lz4_comp_mem);\n}\n\nstatic int lz4_compress_crypto(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t    unsigned int slen, u8 *dst, unsigned int *dlen)\n{\n\tstruct lz4_ctx *ctx = crypto_tfm_ctx(tfm);\n\tsize_t tmp_len = *dlen;\n\tint err;\n\n\terr = lz4_compress(src, slen, dst, &tmp_len, ctx->lz4_comp_mem);\n\n\tif (err < 0)\n\t\treturn -EINVAL;\n\n\t*dlen = tmp_len;\n\treturn 0;\n}\n\nstatic int lz4_decompress_crypto(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t      unsigned int slen, u8 *dst, unsigned int *dlen)\n{\n\tint err;\n\tsize_t tmp_len = *dlen;\n\tsize_t __slen = slen;\n\n\terr = lz4_decompress_unknownoutputsize(src, __slen, dst, &tmp_len);\n\tif (err < 0)\n\t\treturn -EINVAL;\n\n\t*dlen = tmp_len;\n\treturn err;\n}\n\nstatic struct crypto_alg alg_lz4 = {\n\t.cra_name\t\t= \"lz4\",\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_COMPRESS,\n\t.cra_ctxsize\t\t= sizeof(struct lz4_ctx),\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(alg_lz4.cra_list),\n\t.cra_init\t\t= lz4_init,\n\t.cra_exit\t\t= lz4_exit,\n\t.cra_u\t\t\t= { .compress = {\n\t.coa_compress\t\t= lz4_compress_crypto,\n\t.coa_decompress\t\t= lz4_decompress_crypto } }\n};\n\nstatic int __init lz4_mod_init(void)\n{\n\treturn crypto_register_alg(&alg_lz4);\n}\n\nstatic void __exit lz4_mod_fini(void)\n{\n\tcrypto_unregister_alg(&alg_lz4);\n}\n\nmodule_init(lz4_mod_init);\nmodule_exit(lz4_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"LZ4 Compression Algorithm\");\nMODULE_ALIAS_CRYPTO(\"lz4\");\n", "/*\n * Cryptographic API.\n *\n * Copyright (c) 2013 Chanho Min <chanho.min@lge.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License version 2 as published by\n * the Free Software Foundation.\n *\n * This program is distributed in the hope that it will be useful, but WITHOUT\n * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for\n * more details.\n *\n * You should have received a copy of the GNU General Public License along with\n * this program; if not, write to the Free Software Foundation, Inc., 51\n * Franklin St, Fifth Floor, Boston, MA 02110-1301 USA\n *\n */\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/crypto.h>\n#include <linux/vmalloc.h>\n#include <linux/lz4.h>\n\nstruct lz4hc_ctx {\n\tvoid *lz4hc_comp_mem;\n};\n\nstatic int lz4hc_init(struct crypto_tfm *tfm)\n{\n\tstruct lz4hc_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tctx->lz4hc_comp_mem = vmalloc(LZ4HC_MEM_COMPRESS);\n\tif (!ctx->lz4hc_comp_mem)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic void lz4hc_exit(struct crypto_tfm *tfm)\n{\n\tstruct lz4hc_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tvfree(ctx->lz4hc_comp_mem);\n}\n\nstatic int lz4hc_compress_crypto(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t    unsigned int slen, u8 *dst, unsigned int *dlen)\n{\n\tstruct lz4hc_ctx *ctx = crypto_tfm_ctx(tfm);\n\tsize_t tmp_len = *dlen;\n\tint err;\n\n\terr = lz4hc_compress(src, slen, dst, &tmp_len, ctx->lz4hc_comp_mem);\n\n\tif (err < 0)\n\t\treturn -EINVAL;\n\n\t*dlen = tmp_len;\n\treturn 0;\n}\n\nstatic int lz4hc_decompress_crypto(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t      unsigned int slen, u8 *dst, unsigned int *dlen)\n{\n\tint err;\n\tsize_t tmp_len = *dlen;\n\tsize_t __slen = slen;\n\n\terr = lz4_decompress_unknownoutputsize(src, __slen, dst, &tmp_len);\n\tif (err < 0)\n\t\treturn -EINVAL;\n\n\t*dlen = tmp_len;\n\treturn err;\n}\n\nstatic struct crypto_alg alg_lz4hc = {\n\t.cra_name\t\t= \"lz4hc\",\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_COMPRESS,\n\t.cra_ctxsize\t\t= sizeof(struct lz4hc_ctx),\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_list\t\t= LIST_HEAD_INIT(alg_lz4hc.cra_list),\n\t.cra_init\t\t= lz4hc_init,\n\t.cra_exit\t\t= lz4hc_exit,\n\t.cra_u\t\t\t= { .compress = {\n\t.coa_compress\t\t= lz4hc_compress_crypto,\n\t.coa_decompress\t\t= lz4hc_decompress_crypto } }\n};\n\nstatic int __init lz4hc_mod_init(void)\n{\n\treturn crypto_register_alg(&alg_lz4hc);\n}\n\nstatic void __exit lz4hc_mod_fini(void)\n{\n\tcrypto_unregister_alg(&alg_lz4hc);\n}\n\nmodule_init(lz4hc_mod_init);\nmodule_exit(lz4hc_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"LZ4HC Compression Algorithm\");\nMODULE_ALIAS_CRYPTO(\"lz4hc\");\n", "/*\n * Cryptographic API.\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License version 2 as published by\n * the Free Software Foundation.\n *\n * This program is distributed in the hope that it will be useful, but WITHOUT\n * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for\n * more details.\n *\n * You should have received a copy of the GNU General Public License along with\n * this program; if not, write to the Free Software Foundation, Inc., 51\n * Franklin St, Fifth Floor, Boston, MA 02110-1301 USA\n *\n */\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/crypto.h>\n#include <linux/vmalloc.h>\n#include <linux/mm.h>\n#include <linux/lzo.h>\n\nstruct lzo_ctx {\n\tvoid *lzo_comp_mem;\n};\n\nstatic int lzo_init(struct crypto_tfm *tfm)\n{\n\tstruct lzo_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tctx->lzo_comp_mem = kmalloc(LZO1X_MEM_COMPRESS,\n\t\t\t\t    GFP_KERNEL | __GFP_NOWARN | __GFP_REPEAT);\n\tif (!ctx->lzo_comp_mem)\n\t\tctx->lzo_comp_mem = vmalloc(LZO1X_MEM_COMPRESS);\n\tif (!ctx->lzo_comp_mem)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic void lzo_exit(struct crypto_tfm *tfm)\n{\n\tstruct lzo_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tkvfree(ctx->lzo_comp_mem);\n}\n\nstatic int lzo_compress(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t    unsigned int slen, u8 *dst, unsigned int *dlen)\n{\n\tstruct lzo_ctx *ctx = crypto_tfm_ctx(tfm);\n\tsize_t tmp_len = *dlen; /* size_t(ulong) <-> uint on 64 bit */\n\tint err;\n\n\terr = lzo1x_1_compress(src, slen, dst, &tmp_len, ctx->lzo_comp_mem);\n\n\tif (err != LZO_E_OK)\n\t\treturn -EINVAL;\n\n\t*dlen = tmp_len;\n\treturn 0;\n}\n\nstatic int lzo_decompress(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t      unsigned int slen, u8 *dst, unsigned int *dlen)\n{\n\tint err;\n\tsize_t tmp_len = *dlen; /* size_t(ulong) <-> uint on 64 bit */\n\n\terr = lzo1x_decompress_safe(src, slen, dst, &tmp_len);\n\n\tif (err != LZO_E_OK)\n\t\treturn -EINVAL;\n\n\t*dlen = tmp_len;\n\treturn 0;\n\n}\n\nstatic struct crypto_alg alg = {\n\t.cra_name\t\t= \"lzo\",\n\t.cra_flags\t\t= CRYPTO_ALG_TYPE_COMPRESS,\n\t.cra_ctxsize\t\t= sizeof(struct lzo_ctx),\n\t.cra_module\t\t= THIS_MODULE,\n\t.cra_init\t\t= lzo_init,\n\t.cra_exit\t\t= lzo_exit,\n\t.cra_u\t\t\t= { .compress = {\n\t.coa_compress \t\t= lzo_compress,\n\t.coa_decompress  \t= lzo_decompress } }\n};\n\nstatic int __init lzo_mod_init(void)\n{\n\treturn crypto_register_alg(&alg);\n}\n\nstatic void __exit lzo_mod_fini(void)\n{\n\tcrypto_unregister_alg(&alg);\n}\n\nmodule_init(lzo_mod_init);\nmodule_exit(lzo_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"LZO Compression Algorithm\");\nMODULE_ALIAS_CRYPTO(\"lzo\");\n", "/* \n * Cryptographic API.\n *\n * MD4 Message Digest Algorithm (RFC1320).\n *\n * Implementation derived from Andrew Tridgell and Steve French's\n * CIFS MD4 implementation, and the cryptoapi implementation\n * originally based on the public domain implementation written\n * by Colin Plumb in 1993.\n *\n * Copyright (c) Andrew Tridgell 1997-1998.\n * Modified by Steve French (sfrench@us.ibm.com) 2002\n * Copyright (c) Cryptoapi developers.\n * Copyright (c) 2002 David S. Miller (davem@redhat.com)\n * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <asm/byteorder.h>\n\n#define MD4_DIGEST_SIZE\t\t16\n#define MD4_HMAC_BLOCK_SIZE\t64\n#define MD4_BLOCK_WORDS\t\t16\n#define MD4_HASH_WORDS\t\t4\n\nstruct md4_ctx {\n\tu32 hash[MD4_HASH_WORDS];\n\tu32 block[MD4_BLOCK_WORDS];\n\tu64 byte_count;\n};\n\nstatic inline u32 lshift(u32 x, unsigned int s)\n{\n\tx &= 0xFFFFFFFF;\n\treturn ((x << s) & 0xFFFFFFFF) | (x >> (32 - s));\n}\n\nstatic inline u32 F(u32 x, u32 y, u32 z)\n{\n\treturn (x & y) | ((~x) & z);\n}\n\nstatic inline u32 G(u32 x, u32 y, u32 z)\n{\n\treturn (x & y) | (x & z) | (y & z);\n}\n\nstatic inline u32 H(u32 x, u32 y, u32 z)\n{\n\treturn x ^ y ^ z;\n}\n\n#define ROUND1(a,b,c,d,k,s) (a = lshift(a + F(b,c,d) + k, s))\n#define ROUND2(a,b,c,d,k,s) (a = lshift(a + G(b,c,d) + k + (u32)0x5A827999,s))\n#define ROUND3(a,b,c,d,k,s) (a = lshift(a + H(b,c,d) + k + (u32)0x6ED9EBA1,s))\n\n/* XXX: this stuff can be optimized */\nstatic inline void le32_to_cpu_array(u32 *buf, unsigned int words)\n{\n\twhile (words--) {\n\t\t__le32_to_cpus(buf);\n\t\tbuf++;\n\t}\n}\n\nstatic inline void cpu_to_le32_array(u32 *buf, unsigned int words)\n{\n\twhile (words--) {\n\t\t__cpu_to_le32s(buf);\n\t\tbuf++;\n\t}\n}\n\nstatic void md4_transform(u32 *hash, u32 const *in)\n{\n\tu32 a, b, c, d;\n\n\ta = hash[0];\n\tb = hash[1];\n\tc = hash[2];\n\td = hash[3];\n\n\tROUND1(a, b, c, d, in[0], 3);\n\tROUND1(d, a, b, c, in[1], 7);\n\tROUND1(c, d, a, b, in[2], 11);\n\tROUND1(b, c, d, a, in[3], 19);\n\tROUND1(a, b, c, d, in[4], 3);\n\tROUND1(d, a, b, c, in[5], 7);\n\tROUND1(c, d, a, b, in[6], 11);\n\tROUND1(b, c, d, a, in[7], 19);\n\tROUND1(a, b, c, d, in[8], 3);\n\tROUND1(d, a, b, c, in[9], 7);\n\tROUND1(c, d, a, b, in[10], 11);\n\tROUND1(b, c, d, a, in[11], 19);\n\tROUND1(a, b, c, d, in[12], 3);\n\tROUND1(d, a, b, c, in[13], 7);\n\tROUND1(c, d, a, b, in[14], 11);\n\tROUND1(b, c, d, a, in[15], 19);\n\n\tROUND2(a, b, c, d,in[ 0], 3);\n\tROUND2(d, a, b, c, in[4], 5);\n\tROUND2(c, d, a, b, in[8], 9);\n\tROUND2(b, c, d, a, in[12], 13);\n\tROUND2(a, b, c, d, in[1], 3);\n\tROUND2(d, a, b, c, in[5], 5);\n\tROUND2(c, d, a, b, in[9], 9);\n\tROUND2(b, c, d, a, in[13], 13);\n\tROUND2(a, b, c, d, in[2], 3);\n\tROUND2(d, a, b, c, in[6], 5);\n\tROUND2(c, d, a, b, in[10], 9);\n\tROUND2(b, c, d, a, in[14], 13);\n\tROUND2(a, b, c, d, in[3], 3);\n\tROUND2(d, a, b, c, in[7], 5);\n\tROUND2(c, d, a, b, in[11], 9);\n\tROUND2(b, c, d, a, in[15], 13);\n\n\tROUND3(a, b, c, d,in[ 0], 3);\n\tROUND3(d, a, b, c, in[8], 9);\n\tROUND3(c, d, a, b, in[4], 11);\n\tROUND3(b, c, d, a, in[12], 15);\n\tROUND3(a, b, c, d, in[2], 3);\n\tROUND3(d, a, b, c, in[10], 9);\n\tROUND3(c, d, a, b, in[6], 11);\n\tROUND3(b, c, d, a, in[14], 15);\n\tROUND3(a, b, c, d, in[1], 3);\n\tROUND3(d, a, b, c, in[9], 9);\n\tROUND3(c, d, a, b, in[5], 11);\n\tROUND3(b, c, d, a, in[13], 15);\n\tROUND3(a, b, c, d, in[3], 3);\n\tROUND3(d, a, b, c, in[11], 9);\n\tROUND3(c, d, a, b, in[7], 11);\n\tROUND3(b, c, d, a, in[15], 15);\n\n\thash[0] += a;\n\thash[1] += b;\n\thash[2] += c;\n\thash[3] += d;\n}\n\nstatic inline void md4_transform_helper(struct md4_ctx *ctx)\n{\n\tle32_to_cpu_array(ctx->block, ARRAY_SIZE(ctx->block));\n\tmd4_transform(ctx->hash, ctx->block);\n}\n\nstatic int md4_init(struct shash_desc *desc)\n{\n\tstruct md4_ctx *mctx = shash_desc_ctx(desc);\n\n\tmctx->hash[0] = 0x67452301;\n\tmctx->hash[1] = 0xefcdab89;\n\tmctx->hash[2] = 0x98badcfe;\n\tmctx->hash[3] = 0x10325476;\n\tmctx->byte_count = 0;\n\n\treturn 0;\n}\n\nstatic int md4_update(struct shash_desc *desc, const u8 *data, unsigned int len)\n{\n\tstruct md4_ctx *mctx = shash_desc_ctx(desc);\n\tconst u32 avail = sizeof(mctx->block) - (mctx->byte_count & 0x3f);\n\n\tmctx->byte_count += len;\n\n\tif (avail > len) {\n\t\tmemcpy((char *)mctx->block + (sizeof(mctx->block) - avail),\n\t\t       data, len);\n\t\treturn 0;\n\t}\n\n\tmemcpy((char *)mctx->block + (sizeof(mctx->block) - avail),\n\t       data, avail);\n\n\tmd4_transform_helper(mctx);\n\tdata += avail;\n\tlen -= avail;\n\n\twhile (len >= sizeof(mctx->block)) {\n\t\tmemcpy(mctx->block, data, sizeof(mctx->block));\n\t\tmd4_transform_helper(mctx);\n\t\tdata += sizeof(mctx->block);\n\t\tlen -= sizeof(mctx->block);\n\t}\n\n\tmemcpy(mctx->block, data, len);\n\n\treturn 0;\n}\n\nstatic int md4_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct md4_ctx *mctx = shash_desc_ctx(desc);\n\tconst unsigned int offset = mctx->byte_count & 0x3f;\n\tchar *p = (char *)mctx->block + offset;\n\tint padding = 56 - (offset + 1);\n\n\t*p++ = 0x80;\n\tif (padding < 0) {\n\t\tmemset(p, 0x00, padding + sizeof (u64));\n\t\tmd4_transform_helper(mctx);\n\t\tp = (char *)mctx->block;\n\t\tpadding = 56;\n\t}\n\n\tmemset(p, 0, padding);\n\tmctx->block[14] = mctx->byte_count << 3;\n\tmctx->block[15] = mctx->byte_count >> 29;\n\tle32_to_cpu_array(mctx->block, (sizeof(mctx->block) -\n\t                  sizeof(u64)) / sizeof(u32));\n\tmd4_transform(mctx->hash, mctx->block);\n\tcpu_to_le32_array(mctx->hash, ARRAY_SIZE(mctx->hash));\n\tmemcpy(out, mctx->hash, sizeof(mctx->hash));\n\tmemset(mctx, 0, sizeof(*mctx));\n\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tMD4_DIGEST_SIZE,\n\t.init\t\t=\tmd4_init,\n\t.update\t\t=\tmd4_update,\n\t.final\t\t=\tmd4_final,\n\t.descsize\t=\tsizeof(struct md4_ctx),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"md4\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tMD4_HMAC_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init md4_mod_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit md4_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(md4_mod_init);\nmodule_exit(md4_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"MD4 Message Digest Algorithm\");\nMODULE_ALIAS_CRYPTO(\"md4\");\n", "/* \n * Cryptographic API.\n *\n * MD5 Message Digest Algorithm (RFC1321).\n *\n * Derived from cryptoapi implementation, originally based on the\n * public domain implementation written by Colin Plumb in 1993.\n *\n * Copyright (c) Cryptoapi developers.\n * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>\n * \n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option) \n * any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <crypto/md5.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/cryptohash.h>\n#include <asm/byteorder.h>\n\n/* XXX: this stuff can be optimized */\nstatic inline void le32_to_cpu_array(u32 *buf, unsigned int words)\n{\n\twhile (words--) {\n\t\t__le32_to_cpus(buf);\n\t\tbuf++;\n\t}\n}\n\nstatic inline void cpu_to_le32_array(u32 *buf, unsigned int words)\n{\n\twhile (words--) {\n\t\t__cpu_to_le32s(buf);\n\t\tbuf++;\n\t}\n}\n\nstatic inline void md5_transform_helper(struct md5_state *ctx)\n{\n\tle32_to_cpu_array(ctx->block, sizeof(ctx->block) / sizeof(u32));\n\tmd5_transform(ctx->hash, ctx->block);\n}\n\nstatic int md5_init(struct shash_desc *desc)\n{\n\tstruct md5_state *mctx = shash_desc_ctx(desc);\n\n\tmctx->hash[0] = 0x67452301;\n\tmctx->hash[1] = 0xefcdab89;\n\tmctx->hash[2] = 0x98badcfe;\n\tmctx->hash[3] = 0x10325476;\n\tmctx->byte_count = 0;\n\n\treturn 0;\n}\n\nstatic int md5_update(struct shash_desc *desc, const u8 *data, unsigned int len)\n{\n\tstruct md5_state *mctx = shash_desc_ctx(desc);\n\tconst u32 avail = sizeof(mctx->block) - (mctx->byte_count & 0x3f);\n\n\tmctx->byte_count += len;\n\n\tif (avail > len) {\n\t\tmemcpy((char *)mctx->block + (sizeof(mctx->block) - avail),\n\t\t       data, len);\n\t\treturn 0;\n\t}\n\n\tmemcpy((char *)mctx->block + (sizeof(mctx->block) - avail),\n\t       data, avail);\n\n\tmd5_transform_helper(mctx);\n\tdata += avail;\n\tlen -= avail;\n\n\twhile (len >= sizeof(mctx->block)) {\n\t\tmemcpy(mctx->block, data, sizeof(mctx->block));\n\t\tmd5_transform_helper(mctx);\n\t\tdata += sizeof(mctx->block);\n\t\tlen -= sizeof(mctx->block);\n\t}\n\n\tmemcpy(mctx->block, data, len);\n\n\treturn 0;\n}\n\nstatic int md5_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct md5_state *mctx = shash_desc_ctx(desc);\n\tconst unsigned int offset = mctx->byte_count & 0x3f;\n\tchar *p = (char *)mctx->block + offset;\n\tint padding = 56 - (offset + 1);\n\n\t*p++ = 0x80;\n\tif (padding < 0) {\n\t\tmemset(p, 0x00, padding + sizeof (u64));\n\t\tmd5_transform_helper(mctx);\n\t\tp = (char *)mctx->block;\n\t\tpadding = 56;\n\t}\n\n\tmemset(p, 0, padding);\n\tmctx->block[14] = mctx->byte_count << 3;\n\tmctx->block[15] = mctx->byte_count >> 29;\n\tle32_to_cpu_array(mctx->block, (sizeof(mctx->block) -\n\t                  sizeof(u64)) / sizeof(u32));\n\tmd5_transform(mctx->hash, mctx->block);\n\tcpu_to_le32_array(mctx->hash, sizeof(mctx->hash) / sizeof(u32));\n\tmemcpy(out, mctx->hash, sizeof(mctx->hash));\n\tmemset(mctx, 0, sizeof(*mctx));\n\n\treturn 0;\n}\n\nstatic int md5_export(struct shash_desc *desc, void *out)\n{\n\tstruct md5_state *ctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, ctx, sizeof(*ctx));\n\treturn 0;\n}\n\nstatic int md5_import(struct shash_desc *desc, const void *in)\n{\n\tstruct md5_state *ctx = shash_desc_ctx(desc);\n\n\tmemcpy(ctx, in, sizeof(*ctx));\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tMD5_DIGEST_SIZE,\n\t.init\t\t=\tmd5_init,\n\t.update\t\t=\tmd5_update,\n\t.final\t\t=\tmd5_final,\n\t.export\t\t=\tmd5_export,\n\t.import\t\t=\tmd5_import,\n\t.descsize\t=\tsizeof(struct md5_state),\n\t.statesize\t=\tsizeof(struct md5_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"md5\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tMD5_HMAC_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init md5_mod_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit md5_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(md5_mod_init);\nmodule_exit(md5_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"MD5 Message Digest Algorithm\");\nMODULE_ALIAS_CRYPTO(\"md5\");\n", "/*\n * Cryptographic API\n *\n * Michael MIC (IEEE 802.11i/TKIP) keyed digest\n *\n * Copyright (c) 2004 Jouni Malinen <j@w1.fi>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License version 2 as\n * published by the Free Software Foundation.\n */\n#include <crypto/internal/hash.h>\n#include <asm/byteorder.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/string.h>\n#include <linux/types.h>\n\n\nstruct michael_mic_ctx {\n\tu32 l, r;\n};\n\nstruct michael_mic_desc_ctx {\n\tu8 pending[4];\n\tsize_t pending_len;\n\n\tu32 l, r;\n};\n\nstatic inline u32 xswap(u32 val)\n{\n\treturn ((val & 0x00ff00ff) << 8) | ((val & 0xff00ff00) >> 8);\n}\n\n\n#define michael_block(l, r)\t\\\ndo {\t\t\t\t\\\n\tr ^= rol32(l, 17);\t\\\n\tl += r;\t\t\t\\\n\tr ^= xswap(l);\t\t\\\n\tl += r;\t\t\t\\\n\tr ^= rol32(l, 3);\t\\\n\tl += r;\t\t\t\\\n\tr ^= ror32(l, 2);\t\\\n\tl += r;\t\t\t\\\n} while (0)\n\n\nstatic int michael_init(struct shash_desc *desc)\n{\n\tstruct michael_mic_desc_ctx *mctx = shash_desc_ctx(desc);\n\tstruct michael_mic_ctx *ctx = crypto_shash_ctx(desc->tfm);\n\tmctx->pending_len = 0;\n\tmctx->l = ctx->l;\n\tmctx->r = ctx->r;\n\n\treturn 0;\n}\n\n\nstatic int michael_update(struct shash_desc *desc, const u8 *data,\n\t\t\t   unsigned int len)\n{\n\tstruct michael_mic_desc_ctx *mctx = shash_desc_ctx(desc);\n\tconst __le32 *src;\n\n\tif (mctx->pending_len) {\n\t\tint flen = 4 - mctx->pending_len;\n\t\tif (flen > len)\n\t\t\tflen = len;\n\t\tmemcpy(&mctx->pending[mctx->pending_len], data, flen);\n\t\tmctx->pending_len += flen;\n\t\tdata += flen;\n\t\tlen -= flen;\n\n\t\tif (mctx->pending_len < 4)\n\t\t\treturn 0;\n\n\t\tsrc = (const __le32 *)mctx->pending;\n\t\tmctx->l ^= le32_to_cpup(src);\n\t\tmichael_block(mctx->l, mctx->r);\n\t\tmctx->pending_len = 0;\n\t}\n\n\tsrc = (const __le32 *)data;\n\n\twhile (len >= 4) {\n\t\tmctx->l ^= le32_to_cpup(src++);\n\t\tmichael_block(mctx->l, mctx->r);\n\t\tlen -= 4;\n\t}\n\n\tif (len > 0) {\n\t\tmctx->pending_len = len;\n\t\tmemcpy(mctx->pending, src, len);\n\t}\n\n\treturn 0;\n}\n\n\nstatic int michael_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct michael_mic_desc_ctx *mctx = shash_desc_ctx(desc);\n\tu8 *data = mctx->pending;\n\t__le32 *dst = (__le32 *)out;\n\n\t/* Last block and padding (0x5a, 4..7 x 0) */\n\tswitch (mctx->pending_len) {\n\tcase 0:\n\t\tmctx->l ^= 0x5a;\n\t\tbreak;\n\tcase 1:\n\t\tmctx->l ^= data[0] | 0x5a00;\n\t\tbreak;\n\tcase 2:\n\t\tmctx->l ^= data[0] | (data[1] << 8) | 0x5a0000;\n\t\tbreak;\n\tcase 3:\n\t\tmctx->l ^= data[0] | (data[1] << 8) | (data[2] << 16) |\n\t\t\t0x5a000000;\n\t\tbreak;\n\t}\n\tmichael_block(mctx->l, mctx->r);\n\t/* l ^= 0; */\n\tmichael_block(mctx->l, mctx->r);\n\n\tdst[0] = cpu_to_le32(mctx->l);\n\tdst[1] = cpu_to_le32(mctx->r);\n\n\treturn 0;\n}\n\n\nstatic int michael_setkey(struct crypto_shash *tfm, const u8 *key,\n\t\t\t  unsigned int keylen)\n{\n\tstruct michael_mic_ctx *mctx = crypto_shash_ctx(tfm);\n\n\tconst __le32 *data = (const __le32 *)key;\n\n\tif (keylen != 8) {\n\t\tcrypto_shash_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);\n\t\treturn -EINVAL;\n\t}\n\n\tmctx->l = le32_to_cpu(data[0]);\n\tmctx->r = le32_to_cpu(data[1]);\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t\t=\t8,\n\t.setkey\t\t\t=\tmichael_setkey,\n\t.init\t\t\t=\tmichael_init,\n\t.update\t\t\t=\tmichael_update,\n\t.final\t\t\t=\tmichael_final,\n\t.descsize\t\t=\tsizeof(struct michael_mic_desc_ctx),\n\t.base\t\t\t=\t{\n\t\t.cra_name\t\t=\t\"michael_mic\",\n\t\t.cra_blocksize\t\t=\t8,\n\t\t.cra_alignmask\t\t=\t3,\n\t\t.cra_ctxsize\t\t=\tsizeof(struct michael_mic_ctx),\n\t\t.cra_module\t\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init michael_mic_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\n\nstatic void __exit michael_mic_exit(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\n\nmodule_init(michael_mic_init);\nmodule_exit(michael_mic_exit);\n\nMODULE_LICENSE(\"GPL v2\");\nMODULE_DESCRIPTION(\"Michael MIC\");\nMODULE_AUTHOR(\"Jouni Malinen <j@w1.fi>\");\nMODULE_ALIAS_CRYPTO(\"michael_mic\");\n", "/*\n * Cryptographic API.\n *\n * RIPEMD-128 - RACE Integrity Primitives Evaluation Message Digest.\n *\n * Based on the reference implementation by Antoon Bosselaers, ESAT-COSIC\n *\n * Copyright (c) 2008 Adrian-Ken Rueegsegger <ken@codelabs.ch>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/types.h>\n#include <asm/byteorder.h>\n\n#include \"ripemd.h\"\n\nstruct rmd128_ctx {\n\tu64 byte_count;\n\tu32 state[4];\n\t__le32 buffer[16];\n};\n\n#define K1  RMD_K1\n#define K2  RMD_K2\n#define K3  RMD_K3\n#define K4  RMD_K4\n#define KK1 RMD_K6\n#define KK2 RMD_K7\n#define KK3 RMD_K8\n#define KK4 RMD_K1\n\n#define F1(x, y, z) (x ^ y ^ z)\t\t/* XOR */\n#define F2(x, y, z) (z ^ (x & (y ^ z)))\t/* x ? y : z */\n#define F3(x, y, z) ((x | ~y) ^ z)\n#define F4(x, y, z) (y ^ (z & (x ^ y)))\t/* z ? x : y */\n\n#define ROUND(a, b, c, d, f, k, x, s)  { \\\n\t(a) += f((b), (c), (d)) + le32_to_cpup(&(x)) + (k);\t\\\n\t(a) = rol32((a), (s)); \\\n}\n\nstatic void rmd128_transform(u32 *state, const __le32 *in)\n{\n\tu32 aa, bb, cc, dd, aaa, bbb, ccc, ddd;\n\n\t/* Initialize left lane */\n\taa = state[0];\n\tbb = state[1];\n\tcc = state[2];\n\tdd = state[3];\n\n\t/* Initialize right lane */\n\taaa = state[0];\n\tbbb = state[1];\n\tccc = state[2];\n\tddd = state[3];\n\n\t/* round 1: left lane */\n\tROUND(aa, bb, cc, dd, F1, K1, in[0],  11);\n\tROUND(dd, aa, bb, cc, F1, K1, in[1],  14);\n\tROUND(cc, dd, aa, bb, F1, K1, in[2],  15);\n\tROUND(bb, cc, dd, aa, F1, K1, in[3],  12);\n\tROUND(aa, bb, cc, dd, F1, K1, in[4],   5);\n\tROUND(dd, aa, bb, cc, F1, K1, in[5],   8);\n\tROUND(cc, dd, aa, bb, F1, K1, in[6],   7);\n\tROUND(bb, cc, dd, aa, F1, K1, in[7],   9);\n\tROUND(aa, bb, cc, dd, F1, K1, in[8],  11);\n\tROUND(dd, aa, bb, cc, F1, K1, in[9],  13);\n\tROUND(cc, dd, aa, bb, F1, K1, in[10], 14);\n\tROUND(bb, cc, dd, aa, F1, K1, in[11], 15);\n\tROUND(aa, bb, cc, dd, F1, K1, in[12],  6);\n\tROUND(dd, aa, bb, cc, F1, K1, in[13],  7);\n\tROUND(cc, dd, aa, bb, F1, K1, in[14],  9);\n\tROUND(bb, cc, dd, aa, F1, K1, in[15],  8);\n\n\t/* round 2: left lane */\n\tROUND(aa, bb, cc, dd, F2, K2, in[7],   7);\n\tROUND(dd, aa, bb, cc, F2, K2, in[4],   6);\n\tROUND(cc, dd, aa, bb, F2, K2, in[13],  8);\n\tROUND(bb, cc, dd, aa, F2, K2, in[1],  13);\n\tROUND(aa, bb, cc, dd, F2, K2, in[10], 11);\n\tROUND(dd, aa, bb, cc, F2, K2, in[6],   9);\n\tROUND(cc, dd, aa, bb, F2, K2, in[15],  7);\n\tROUND(bb, cc, dd, aa, F2, K2, in[3],  15);\n\tROUND(aa, bb, cc, dd, F2, K2, in[12],  7);\n\tROUND(dd, aa, bb, cc, F2, K2, in[0],  12);\n\tROUND(cc, dd, aa, bb, F2, K2, in[9],  15);\n\tROUND(bb, cc, dd, aa, F2, K2, in[5],   9);\n\tROUND(aa, bb, cc, dd, F2, K2, in[2],  11);\n\tROUND(dd, aa, bb, cc, F2, K2, in[14],  7);\n\tROUND(cc, dd, aa, bb, F2, K2, in[11], 13);\n\tROUND(bb, cc, dd, aa, F2, K2, in[8],  12);\n\n\t/* round 3: left lane */\n\tROUND(aa, bb, cc, dd, F3, K3, in[3],  11);\n\tROUND(dd, aa, bb, cc, F3, K3, in[10], 13);\n\tROUND(cc, dd, aa, bb, F3, K3, in[14],  6);\n\tROUND(bb, cc, dd, aa, F3, K3, in[4],   7);\n\tROUND(aa, bb, cc, dd, F3, K3, in[9],  14);\n\tROUND(dd, aa, bb, cc, F3, K3, in[15],  9);\n\tROUND(cc, dd, aa, bb, F3, K3, in[8],  13);\n\tROUND(bb, cc, dd, aa, F3, K3, in[1],  15);\n\tROUND(aa, bb, cc, dd, F3, K3, in[2],  14);\n\tROUND(dd, aa, bb, cc, F3, K3, in[7],   8);\n\tROUND(cc, dd, aa, bb, F3, K3, in[0],  13);\n\tROUND(bb, cc, dd, aa, F3, K3, in[6],   6);\n\tROUND(aa, bb, cc, dd, F3, K3, in[13],  5);\n\tROUND(dd, aa, bb, cc, F3, K3, in[11], 12);\n\tROUND(cc, dd, aa, bb, F3, K3, in[5],   7);\n\tROUND(bb, cc, dd, aa, F3, K3, in[12],  5);\n\n\t/* round 4: left lane */\n\tROUND(aa, bb, cc, dd, F4, K4, in[1],  11);\n\tROUND(dd, aa, bb, cc, F4, K4, in[9],  12);\n\tROUND(cc, dd, aa, bb, F4, K4, in[11], 14);\n\tROUND(bb, cc, dd, aa, F4, K4, in[10], 15);\n\tROUND(aa, bb, cc, dd, F4, K4, in[0],  14);\n\tROUND(dd, aa, bb, cc, F4, K4, in[8],  15);\n\tROUND(cc, dd, aa, bb, F4, K4, in[12],  9);\n\tROUND(bb, cc, dd, aa, F4, K4, in[4],   8);\n\tROUND(aa, bb, cc, dd, F4, K4, in[13],  9);\n\tROUND(dd, aa, bb, cc, F4, K4, in[3],  14);\n\tROUND(cc, dd, aa, bb, F4, K4, in[7],   5);\n\tROUND(bb, cc, dd, aa, F4, K4, in[15],  6);\n\tROUND(aa, bb, cc, dd, F4, K4, in[14],  8);\n\tROUND(dd, aa, bb, cc, F4, K4, in[5],   6);\n\tROUND(cc, dd, aa, bb, F4, K4, in[6],   5);\n\tROUND(bb, cc, dd, aa, F4, K4, in[2],  12);\n\n\t/* round 1: right lane */\n\tROUND(aaa, bbb, ccc, ddd, F4, KK1, in[5],   8);\n\tROUND(ddd, aaa, bbb, ccc, F4, KK1, in[14],  9);\n\tROUND(ccc, ddd, aaa, bbb, F4, KK1, in[7],   9);\n\tROUND(bbb, ccc, ddd, aaa, F4, KK1, in[0],  11);\n\tROUND(aaa, bbb, ccc, ddd, F4, KK1, in[9],  13);\n\tROUND(ddd, aaa, bbb, ccc, F4, KK1, in[2],  15);\n\tROUND(ccc, ddd, aaa, bbb, F4, KK1, in[11], 15);\n\tROUND(bbb, ccc, ddd, aaa, F4, KK1, in[4],   5);\n\tROUND(aaa, bbb, ccc, ddd, F4, KK1, in[13],  7);\n\tROUND(ddd, aaa, bbb, ccc, F4, KK1, in[6],   7);\n\tROUND(ccc, ddd, aaa, bbb, F4, KK1, in[15],  8);\n\tROUND(bbb, ccc, ddd, aaa, F4, KK1, in[8],  11);\n\tROUND(aaa, bbb, ccc, ddd, F4, KK1, in[1],  14);\n\tROUND(ddd, aaa, bbb, ccc, F4, KK1, in[10], 14);\n\tROUND(ccc, ddd, aaa, bbb, F4, KK1, in[3],  12);\n\tROUND(bbb, ccc, ddd, aaa, F4, KK1, in[12],  6);\n\n\t/* round 2: right lane */\n\tROUND(aaa, bbb, ccc, ddd, F3, KK2, in[6],   9);\n\tROUND(ddd, aaa, bbb, ccc, F3, KK2, in[11], 13);\n\tROUND(ccc, ddd, aaa, bbb, F3, KK2, in[3],  15);\n\tROUND(bbb, ccc, ddd, aaa, F3, KK2, in[7],   7);\n\tROUND(aaa, bbb, ccc, ddd, F3, KK2, in[0],  12);\n\tROUND(ddd, aaa, bbb, ccc, F3, KK2, in[13],  8);\n\tROUND(ccc, ddd, aaa, bbb, F3, KK2, in[5],   9);\n\tROUND(bbb, ccc, ddd, aaa, F3, KK2, in[10], 11);\n\tROUND(aaa, bbb, ccc, ddd, F3, KK2, in[14],  7);\n\tROUND(ddd, aaa, bbb, ccc, F3, KK2, in[15],  7);\n\tROUND(ccc, ddd, aaa, bbb, F3, KK2, in[8],  12);\n\tROUND(bbb, ccc, ddd, aaa, F3, KK2, in[12],  7);\n\tROUND(aaa, bbb, ccc, ddd, F3, KK2, in[4],   6);\n\tROUND(ddd, aaa, bbb, ccc, F3, KK2, in[9],  15);\n\tROUND(ccc, ddd, aaa, bbb, F3, KK2, in[1],  13);\n\tROUND(bbb, ccc, ddd, aaa, F3, KK2, in[2],  11);\n\n\t/* round 3: right lane */\n\tROUND(aaa, bbb, ccc, ddd, F2, KK3, in[15],  9);\n\tROUND(ddd, aaa, bbb, ccc, F2, KK3, in[5],   7);\n\tROUND(ccc, ddd, aaa, bbb, F2, KK3, in[1],  15);\n\tROUND(bbb, ccc, ddd, aaa, F2, KK3, in[3],  11);\n\tROUND(aaa, bbb, ccc, ddd, F2, KK3, in[7],   8);\n\tROUND(ddd, aaa, bbb, ccc, F2, KK3, in[14],  6);\n\tROUND(ccc, ddd, aaa, bbb, F2, KK3, in[6],   6);\n\tROUND(bbb, ccc, ddd, aaa, F2, KK3, in[9],  14);\n\tROUND(aaa, bbb, ccc, ddd, F2, KK3, in[11], 12);\n\tROUND(ddd, aaa, bbb, ccc, F2, KK3, in[8],  13);\n\tROUND(ccc, ddd, aaa, bbb, F2, KK3, in[12],  5);\n\tROUND(bbb, ccc, ddd, aaa, F2, KK3, in[2],  14);\n\tROUND(aaa, bbb, ccc, ddd, F2, KK3, in[10], 13);\n\tROUND(ddd, aaa, bbb, ccc, F2, KK3, in[0],  13);\n\tROUND(ccc, ddd, aaa, bbb, F2, KK3, in[4],   7);\n\tROUND(bbb, ccc, ddd, aaa, F2, KK3, in[13],  5);\n\n\t/* round 4: right lane */\n\tROUND(aaa, bbb, ccc, ddd, F1, KK4, in[8],  15);\n\tROUND(ddd, aaa, bbb, ccc, F1, KK4, in[6],   5);\n\tROUND(ccc, ddd, aaa, bbb, F1, KK4, in[4],   8);\n\tROUND(bbb, ccc, ddd, aaa, F1, KK4, in[1],  11);\n\tROUND(aaa, bbb, ccc, ddd, F1, KK4, in[3],  14);\n\tROUND(ddd, aaa, bbb, ccc, F1, KK4, in[11], 14);\n\tROUND(ccc, ddd, aaa, bbb, F1, KK4, in[15],  6);\n\tROUND(bbb, ccc, ddd, aaa, F1, KK4, in[0],  14);\n\tROUND(aaa, bbb, ccc, ddd, F1, KK4, in[5],   6);\n\tROUND(ddd, aaa, bbb, ccc, F1, KK4, in[12],  9);\n\tROUND(ccc, ddd, aaa, bbb, F1, KK4, in[2],  12);\n\tROUND(bbb, ccc, ddd, aaa, F1, KK4, in[13],  9);\n\tROUND(aaa, bbb, ccc, ddd, F1, KK4, in[9],  12);\n\tROUND(ddd, aaa, bbb, ccc, F1, KK4, in[7],   5);\n\tROUND(ccc, ddd, aaa, bbb, F1, KK4, in[10], 15);\n\tROUND(bbb, ccc, ddd, aaa, F1, KK4, in[14],  8);\n\n\t/* combine results */\n\tddd += cc + state[1];\t\t/* final result for state[0] */\n\tstate[1] = state[2] + dd + aaa;\n\tstate[2] = state[3] + aa + bbb;\n\tstate[3] = state[0] + bb + ccc;\n\tstate[0] = ddd;\n\n\treturn;\n}\n\nstatic int rmd128_init(struct shash_desc *desc)\n{\n\tstruct rmd128_ctx *rctx = shash_desc_ctx(desc);\n\n\trctx->byte_count = 0;\n\n\trctx->state[0] = RMD_H0;\n\trctx->state[1] = RMD_H1;\n\trctx->state[2] = RMD_H2;\n\trctx->state[3] = RMD_H3;\n\n\tmemset(rctx->buffer, 0, sizeof(rctx->buffer));\n\n\treturn 0;\n}\n\nstatic int rmd128_update(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int len)\n{\n\tstruct rmd128_ctx *rctx = shash_desc_ctx(desc);\n\tconst u32 avail = sizeof(rctx->buffer) - (rctx->byte_count & 0x3f);\n\n\trctx->byte_count += len;\n\n\t/* Enough space in buffer? If so copy and we're done */\n\tif (avail > len) {\n\t\tmemcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),\n\t\t       data, len);\n\t\tgoto out;\n\t}\n\n\tmemcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),\n\t       data, avail);\n\n\trmd128_transform(rctx->state, rctx->buffer);\n\tdata += avail;\n\tlen -= avail;\n\n\twhile (len >= sizeof(rctx->buffer)) {\n\t\tmemcpy(rctx->buffer, data, sizeof(rctx->buffer));\n\t\trmd128_transform(rctx->state, rctx->buffer);\n\t\tdata += sizeof(rctx->buffer);\n\t\tlen -= sizeof(rctx->buffer);\n\t}\n\n\tmemcpy(rctx->buffer, data, len);\n\nout:\n\treturn 0;\n}\n\n/* Add padding and return the message digest. */\nstatic int rmd128_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct rmd128_ctx *rctx = shash_desc_ctx(desc);\n\tu32 i, index, padlen;\n\t__le64 bits;\n\t__le32 *dst = (__le32 *)out;\n\tstatic const u8 padding[64] = { 0x80, };\n\n\tbits = cpu_to_le64(rctx->byte_count << 3);\n\n\t/* Pad out to 56 mod 64 */\n\tindex = rctx->byte_count & 0x3f;\n\tpadlen = (index < 56) ? (56 - index) : ((64+56) - index);\n\trmd128_update(desc, padding, padlen);\n\n\t/* Append length */\n\trmd128_update(desc, (const u8 *)&bits, sizeof(bits));\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 4; i++)\n\t\tdst[i] = cpu_to_le32p(&rctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(rctx, 0, sizeof(*rctx));\n\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tRMD128_DIGEST_SIZE,\n\t.init\t\t=\trmd128_init,\n\t.update\t\t=\trmd128_update,\n\t.final\t\t=\trmd128_final,\n\t.descsize\t=\tsizeof(struct rmd128_ctx),\n\t.base\t\t=\t{\n\t\t.cra_name\t =\t\"rmd128\",\n\t\t.cra_flags\t =\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t =\tRMD128_BLOCK_SIZE,\n\t\t.cra_module\t =\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init rmd128_mod_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit rmd128_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(rmd128_mod_init);\nmodule_exit(rmd128_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Adrian-Ken Rueegsegger <ken@codelabs.ch>\");\nMODULE_DESCRIPTION(\"RIPEMD-128 Message Digest\");\nMODULE_ALIAS_CRYPTO(\"rmd128\");\n", "/*\n * Cryptographic API.\n *\n * RIPEMD-160 - RACE Integrity Primitives Evaluation Message Digest.\n *\n * Based on the reference implementation by Antoon Bosselaers, ESAT-COSIC\n *\n * Copyright (c) 2008 Adrian-Ken Rueegsegger <ken@codelabs.ch>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/types.h>\n#include <asm/byteorder.h>\n\n#include \"ripemd.h\"\n\nstruct rmd160_ctx {\n\tu64 byte_count;\n\tu32 state[5];\n\t__le32 buffer[16];\n};\n\n#define K1  RMD_K1\n#define K2  RMD_K2\n#define K3  RMD_K3\n#define K4  RMD_K4\n#define K5  RMD_K5\n#define KK1 RMD_K6\n#define KK2 RMD_K7\n#define KK3 RMD_K8\n#define KK4 RMD_K9\n#define KK5 RMD_K1\n\n#define F1(x, y, z) (x ^ y ^ z)\t\t/* XOR */\n#define F2(x, y, z) (z ^ (x & (y ^ z)))\t/* x ? y : z */\n#define F3(x, y, z) ((x | ~y) ^ z)\n#define F4(x, y, z) (y ^ (z & (x ^ y)))\t/* z ? x : y */\n#define F5(x, y, z) (x ^ (y | ~z))\n\n#define ROUND(a, b, c, d, e, f, k, x, s)  { \\\n\t(a) += f((b), (c), (d)) + le32_to_cpup(&(x)) + (k); \\\n\t(a) = rol32((a), (s)) + (e); \\\n\t(c) = rol32((c), 10); \\\n}\n\nstatic void rmd160_transform(u32 *state, const __le32 *in)\n{\n\tu32 aa, bb, cc, dd, ee, aaa, bbb, ccc, ddd, eee;\n\n\t/* Initialize left lane */\n\taa = state[0];\n\tbb = state[1];\n\tcc = state[2];\n\tdd = state[3];\n\tee = state[4];\n\n\t/* Initialize right lane */\n\taaa = state[0];\n\tbbb = state[1];\n\tccc = state[2];\n\tddd = state[3];\n\teee = state[4];\n\n\t/* round 1: left lane */\n\tROUND(aa, bb, cc, dd, ee, F1, K1, in[0],  11);\n\tROUND(ee, aa, bb, cc, dd, F1, K1, in[1],  14);\n\tROUND(dd, ee, aa, bb, cc, F1, K1, in[2],  15);\n\tROUND(cc, dd, ee, aa, bb, F1, K1, in[3],  12);\n\tROUND(bb, cc, dd, ee, aa, F1, K1, in[4],   5);\n\tROUND(aa, bb, cc, dd, ee, F1, K1, in[5],   8);\n\tROUND(ee, aa, bb, cc, dd, F1, K1, in[6],   7);\n\tROUND(dd, ee, aa, bb, cc, F1, K1, in[7],   9);\n\tROUND(cc, dd, ee, aa, bb, F1, K1, in[8],  11);\n\tROUND(bb, cc, dd, ee, aa, F1, K1, in[9],  13);\n\tROUND(aa, bb, cc, dd, ee, F1, K1, in[10], 14);\n\tROUND(ee, aa, bb, cc, dd, F1, K1, in[11], 15);\n\tROUND(dd, ee, aa, bb, cc, F1, K1, in[12],  6);\n\tROUND(cc, dd, ee, aa, bb, F1, K1, in[13],  7);\n\tROUND(bb, cc, dd, ee, aa, F1, K1, in[14],  9);\n\tROUND(aa, bb, cc, dd, ee, F1, K1, in[15],  8);\n\n\t/* round 2: left lane\" */\n\tROUND(ee, aa, bb, cc, dd, F2, K2, in[7],   7);\n\tROUND(dd, ee, aa, bb, cc, F2, K2, in[4],   6);\n\tROUND(cc, dd, ee, aa, bb, F2, K2, in[13],  8);\n\tROUND(bb, cc, dd, ee, aa, F2, K2, in[1],  13);\n\tROUND(aa, bb, cc, dd, ee, F2, K2, in[10], 11);\n\tROUND(ee, aa, bb, cc, dd, F2, K2, in[6],   9);\n\tROUND(dd, ee, aa, bb, cc, F2, K2, in[15],  7);\n\tROUND(cc, dd, ee, aa, bb, F2, K2, in[3],  15);\n\tROUND(bb, cc, dd, ee, aa, F2, K2, in[12],  7);\n\tROUND(aa, bb, cc, dd, ee, F2, K2, in[0],  12);\n\tROUND(ee, aa, bb, cc, dd, F2, K2, in[9],  15);\n\tROUND(dd, ee, aa, bb, cc, F2, K2, in[5],   9);\n\tROUND(cc, dd, ee, aa, bb, F2, K2, in[2],  11);\n\tROUND(bb, cc, dd, ee, aa, F2, K2, in[14],  7);\n\tROUND(aa, bb, cc, dd, ee, F2, K2, in[11], 13);\n\tROUND(ee, aa, bb, cc, dd, F2, K2, in[8],  12);\n\n\t/* round 3: left lane\" */\n\tROUND(dd, ee, aa, bb, cc, F3, K3, in[3],  11);\n\tROUND(cc, dd, ee, aa, bb, F3, K3, in[10], 13);\n\tROUND(bb, cc, dd, ee, aa, F3, K3, in[14],  6);\n\tROUND(aa, bb, cc, dd, ee, F3, K3, in[4],   7);\n\tROUND(ee, aa, bb, cc, dd, F3, K3, in[9],  14);\n\tROUND(dd, ee, aa, bb, cc, F3, K3, in[15],  9);\n\tROUND(cc, dd, ee, aa, bb, F3, K3, in[8],  13);\n\tROUND(bb, cc, dd, ee, aa, F3, K3, in[1],  15);\n\tROUND(aa, bb, cc, dd, ee, F3, K3, in[2],  14);\n\tROUND(ee, aa, bb, cc, dd, F3, K3, in[7],   8);\n\tROUND(dd, ee, aa, bb, cc, F3, K3, in[0],  13);\n\tROUND(cc, dd, ee, aa, bb, F3, K3, in[6],   6);\n\tROUND(bb, cc, dd, ee, aa, F3, K3, in[13],  5);\n\tROUND(aa, bb, cc, dd, ee, F3, K3, in[11], 12);\n\tROUND(ee, aa, bb, cc, dd, F3, K3, in[5],   7);\n\tROUND(dd, ee, aa, bb, cc, F3, K3, in[12],  5);\n\n\t/* round 4: left lane\" */\n\tROUND(cc, dd, ee, aa, bb, F4, K4, in[1],  11);\n\tROUND(bb, cc, dd, ee, aa, F4, K4, in[9],  12);\n\tROUND(aa, bb, cc, dd, ee, F4, K4, in[11], 14);\n\tROUND(ee, aa, bb, cc, dd, F4, K4, in[10], 15);\n\tROUND(dd, ee, aa, bb, cc, F4, K4, in[0],  14);\n\tROUND(cc, dd, ee, aa, bb, F4, K4, in[8],  15);\n\tROUND(bb, cc, dd, ee, aa, F4, K4, in[12],  9);\n\tROUND(aa, bb, cc, dd, ee, F4, K4, in[4],   8);\n\tROUND(ee, aa, bb, cc, dd, F4, K4, in[13],  9);\n\tROUND(dd, ee, aa, bb, cc, F4, K4, in[3],  14);\n\tROUND(cc, dd, ee, aa, bb, F4, K4, in[7],   5);\n\tROUND(bb, cc, dd, ee, aa, F4, K4, in[15],  6);\n\tROUND(aa, bb, cc, dd, ee, F4, K4, in[14],  8);\n\tROUND(ee, aa, bb, cc, dd, F4, K4, in[5],   6);\n\tROUND(dd, ee, aa, bb, cc, F4, K4, in[6],   5);\n\tROUND(cc, dd, ee, aa, bb, F4, K4, in[2],  12);\n\n\t/* round 5: left lane\" */\n\tROUND(bb, cc, dd, ee, aa, F5, K5, in[4],   9);\n\tROUND(aa, bb, cc, dd, ee, F5, K5, in[0],  15);\n\tROUND(ee, aa, bb, cc, dd, F5, K5, in[5],   5);\n\tROUND(dd, ee, aa, bb, cc, F5, K5, in[9],  11);\n\tROUND(cc, dd, ee, aa, bb, F5, K5, in[7],   6);\n\tROUND(bb, cc, dd, ee, aa, F5, K5, in[12],  8);\n\tROUND(aa, bb, cc, dd, ee, F5, K5, in[2],  13);\n\tROUND(ee, aa, bb, cc, dd, F5, K5, in[10], 12);\n\tROUND(dd, ee, aa, bb, cc, F5, K5, in[14],  5);\n\tROUND(cc, dd, ee, aa, bb, F5, K5, in[1],  12);\n\tROUND(bb, cc, dd, ee, aa, F5, K5, in[3],  13);\n\tROUND(aa, bb, cc, dd, ee, F5, K5, in[8],  14);\n\tROUND(ee, aa, bb, cc, dd, F5, K5, in[11], 11);\n\tROUND(dd, ee, aa, bb, cc, F5, K5, in[6],   8);\n\tROUND(cc, dd, ee, aa, bb, F5, K5, in[15],  5);\n\tROUND(bb, cc, dd, ee, aa, F5, K5, in[13],  6);\n\n\t/* round 1: right lane */\n\tROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[5],   8);\n\tROUND(eee, aaa, bbb, ccc, ddd, F5, KK1, in[14],  9);\n\tROUND(ddd, eee, aaa, bbb, ccc, F5, KK1, in[7],   9);\n\tROUND(ccc, ddd, eee, aaa, bbb, F5, KK1, in[0],  11);\n\tROUND(bbb, ccc, ddd, eee, aaa, F5, KK1, in[9],  13);\n\tROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[2],  15);\n\tROUND(eee, aaa, bbb, ccc, ddd, F5, KK1, in[11], 15);\n\tROUND(ddd, eee, aaa, bbb, ccc, F5, KK1, in[4],   5);\n\tROUND(ccc, ddd, eee, aaa, bbb, F5, KK1, in[13],  7);\n\tROUND(bbb, ccc, ddd, eee, aaa, F5, KK1, in[6],   7);\n\tROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[15],  8);\n\tROUND(eee, aaa, bbb, ccc, ddd, F5, KK1, in[8],  11);\n\tROUND(ddd, eee, aaa, bbb, ccc, F5, KK1, in[1],  14);\n\tROUND(ccc, ddd, eee, aaa, bbb, F5, KK1, in[10], 14);\n\tROUND(bbb, ccc, ddd, eee, aaa, F5, KK1, in[3],  12);\n\tROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[12],  6);\n\n\t/* round 2: right lane */\n\tROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[6],   9);\n\tROUND(ddd, eee, aaa, bbb, ccc, F4, KK2, in[11], 13);\n\tROUND(ccc, ddd, eee, aaa, bbb, F4, KK2, in[3],  15);\n\tROUND(bbb, ccc, ddd, eee, aaa, F4, KK2, in[7],   7);\n\tROUND(aaa, bbb, ccc, ddd, eee, F4, KK2, in[0],  12);\n\tROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[13],  8);\n\tROUND(ddd, eee, aaa, bbb, ccc, F4, KK2, in[5],   9);\n\tROUND(ccc, ddd, eee, aaa, bbb, F4, KK2, in[10], 11);\n\tROUND(bbb, ccc, ddd, eee, aaa, F4, KK2, in[14],  7);\n\tROUND(aaa, bbb, ccc, ddd, eee, F4, KK2, in[15],  7);\n\tROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[8],  12);\n\tROUND(ddd, eee, aaa, bbb, ccc, F4, KK2, in[12],  7);\n\tROUND(ccc, ddd, eee, aaa, bbb, F4, KK2, in[4],   6);\n\tROUND(bbb, ccc, ddd, eee, aaa, F4, KK2, in[9],  15);\n\tROUND(aaa, bbb, ccc, ddd, eee, F4, KK2, in[1],  13);\n\tROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[2],  11);\n\n\t/* round 3: right lane */\n\tROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[15],  9);\n\tROUND(ccc, ddd, eee, aaa, bbb, F3, KK3, in[5],   7);\n\tROUND(bbb, ccc, ddd, eee, aaa, F3, KK3, in[1],  15);\n\tROUND(aaa, bbb, ccc, ddd, eee, F3, KK3, in[3],  11);\n\tROUND(eee, aaa, bbb, ccc, ddd, F3, KK3, in[7],   8);\n\tROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[14],  6);\n\tROUND(ccc, ddd, eee, aaa, bbb, F3, KK3, in[6],   6);\n\tROUND(bbb, ccc, ddd, eee, aaa, F3, KK3, in[9],  14);\n\tROUND(aaa, bbb, ccc, ddd, eee, F3, KK3, in[11], 12);\n\tROUND(eee, aaa, bbb, ccc, ddd, F3, KK3, in[8],  13);\n\tROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[12],  5);\n\tROUND(ccc, ddd, eee, aaa, bbb, F3, KK3, in[2],  14);\n\tROUND(bbb, ccc, ddd, eee, aaa, F3, KK3, in[10], 13);\n\tROUND(aaa, bbb, ccc, ddd, eee, F3, KK3, in[0],  13);\n\tROUND(eee, aaa, bbb, ccc, ddd, F3, KK3, in[4],   7);\n\tROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[13],  5);\n\n\t/* round 4: right lane */\n\tROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[8],  15);\n\tROUND(bbb, ccc, ddd, eee, aaa, F2, KK4, in[6],   5);\n\tROUND(aaa, bbb, ccc, ddd, eee, F2, KK4, in[4],   8);\n\tROUND(eee, aaa, bbb, ccc, ddd, F2, KK4, in[1],  11);\n\tROUND(ddd, eee, aaa, bbb, ccc, F2, KK4, in[3],  14);\n\tROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[11], 14);\n\tROUND(bbb, ccc, ddd, eee, aaa, F2, KK4, in[15],  6);\n\tROUND(aaa, bbb, ccc, ddd, eee, F2, KK4, in[0],  14);\n\tROUND(eee, aaa, bbb, ccc, ddd, F2, KK4, in[5],   6);\n\tROUND(ddd, eee, aaa, bbb, ccc, F2, KK4, in[12],  9);\n\tROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[2],  12);\n\tROUND(bbb, ccc, ddd, eee, aaa, F2, KK4, in[13],  9);\n\tROUND(aaa, bbb, ccc, ddd, eee, F2, KK4, in[9],  12);\n\tROUND(eee, aaa, bbb, ccc, ddd, F2, KK4, in[7],   5);\n\tROUND(ddd, eee, aaa, bbb, ccc, F2, KK4, in[10], 15);\n\tROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[14],  8);\n\n\t/* round 5: right lane */\n\tROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[12],  8);\n\tROUND(aaa, bbb, ccc, ddd, eee, F1, KK5, in[15],  5);\n\tROUND(eee, aaa, bbb, ccc, ddd, F1, KK5, in[10], 12);\n\tROUND(ddd, eee, aaa, bbb, ccc, F1, KK5, in[4],   9);\n\tROUND(ccc, ddd, eee, aaa, bbb, F1, KK5, in[1],  12);\n\tROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[5],   5);\n\tROUND(aaa, bbb, ccc, ddd, eee, F1, KK5, in[8],  14);\n\tROUND(eee, aaa, bbb, ccc, ddd, F1, KK5, in[7],   6);\n\tROUND(ddd, eee, aaa, bbb, ccc, F1, KK5, in[6],   8);\n\tROUND(ccc, ddd, eee, aaa, bbb, F1, KK5, in[2],  13);\n\tROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[13],  6);\n\tROUND(aaa, bbb, ccc, ddd, eee, F1, KK5, in[14],  5);\n\tROUND(eee, aaa, bbb, ccc, ddd, F1, KK5, in[0],  15);\n\tROUND(ddd, eee, aaa, bbb, ccc, F1, KK5, in[3],  13);\n\tROUND(ccc, ddd, eee, aaa, bbb, F1, KK5, in[9],  11);\n\tROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[11], 11);\n\n\t/* combine results */\n\tddd += cc + state[1];\t\t/* final result for state[0] */\n\tstate[1] = state[2] + dd + eee;\n\tstate[2] = state[3] + ee + aaa;\n\tstate[3] = state[4] + aa + bbb;\n\tstate[4] = state[0] + bb + ccc;\n\tstate[0] = ddd;\n\n\treturn;\n}\n\nstatic int rmd160_init(struct shash_desc *desc)\n{\n\tstruct rmd160_ctx *rctx = shash_desc_ctx(desc);\n\n\trctx->byte_count = 0;\n\n\trctx->state[0] = RMD_H0;\n\trctx->state[1] = RMD_H1;\n\trctx->state[2] = RMD_H2;\n\trctx->state[3] = RMD_H3;\n\trctx->state[4] = RMD_H4;\n\n\tmemset(rctx->buffer, 0, sizeof(rctx->buffer));\n\n\treturn 0;\n}\n\nstatic int rmd160_update(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int len)\n{\n\tstruct rmd160_ctx *rctx = shash_desc_ctx(desc);\n\tconst u32 avail = sizeof(rctx->buffer) - (rctx->byte_count & 0x3f);\n\n\trctx->byte_count += len;\n\n\t/* Enough space in buffer? If so copy and we're done */\n\tif (avail > len) {\n\t\tmemcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),\n\t\t       data, len);\n\t\tgoto out;\n\t}\n\n\tmemcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),\n\t       data, avail);\n\n\trmd160_transform(rctx->state, rctx->buffer);\n\tdata += avail;\n\tlen -= avail;\n\n\twhile (len >= sizeof(rctx->buffer)) {\n\t\tmemcpy(rctx->buffer, data, sizeof(rctx->buffer));\n\t\trmd160_transform(rctx->state, rctx->buffer);\n\t\tdata += sizeof(rctx->buffer);\n\t\tlen -= sizeof(rctx->buffer);\n\t}\n\n\tmemcpy(rctx->buffer, data, len);\n\nout:\n\treturn 0;\n}\n\n/* Add padding and return the message digest. */\nstatic int rmd160_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct rmd160_ctx *rctx = shash_desc_ctx(desc);\n\tu32 i, index, padlen;\n\t__le64 bits;\n\t__le32 *dst = (__le32 *)out;\n\tstatic const u8 padding[64] = { 0x80, };\n\n\tbits = cpu_to_le64(rctx->byte_count << 3);\n\n\t/* Pad out to 56 mod 64 */\n\tindex = rctx->byte_count & 0x3f;\n\tpadlen = (index < 56) ? (56 - index) : ((64+56) - index);\n\trmd160_update(desc, padding, padlen);\n\n\t/* Append length */\n\trmd160_update(desc, (const u8 *)&bits, sizeof(bits));\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 5; i++)\n\t\tdst[i] = cpu_to_le32p(&rctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(rctx, 0, sizeof(*rctx));\n\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tRMD160_DIGEST_SIZE,\n\t.init\t\t=\trmd160_init,\n\t.update\t\t=\trmd160_update,\n\t.final\t\t=\trmd160_final,\n\t.descsize\t=\tsizeof(struct rmd160_ctx),\n\t.base\t\t=\t{\n\t\t.cra_name\t =\t\"rmd160\",\n\t\t.cra_flags\t =\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t =\tRMD160_BLOCK_SIZE,\n\t\t.cra_module\t =\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init rmd160_mod_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit rmd160_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(rmd160_mod_init);\nmodule_exit(rmd160_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Adrian-Ken Rueegsegger <ken@codelabs.ch>\");\nMODULE_DESCRIPTION(\"RIPEMD-160 Message Digest\");\nMODULE_ALIAS_CRYPTO(\"rmd160\");\n", "/*\n * Cryptographic API.\n *\n * RIPEMD-256 - RACE Integrity Primitives Evaluation Message Digest.\n *\n * Based on the reference implementation by Antoon Bosselaers, ESAT-COSIC\n *\n * Copyright (c) 2008 Adrian-Ken Rueegsegger <ken@codelabs.ch>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/types.h>\n#include <asm/byteorder.h>\n\n#include \"ripemd.h\"\n\nstruct rmd256_ctx {\n\tu64 byte_count;\n\tu32 state[8];\n\t__le32 buffer[16];\n};\n\n#define K1  RMD_K1\n#define K2  RMD_K2\n#define K3  RMD_K3\n#define K4  RMD_K4\n#define KK1 RMD_K6\n#define KK2 RMD_K7\n#define KK3 RMD_K8\n#define KK4 RMD_K1\n\n#define F1(x, y, z) (x ^ y ^ z)\t\t/* XOR */\n#define F2(x, y, z) (z ^ (x & (y ^ z)))\t/* x ? y : z */\n#define F3(x, y, z) ((x | ~y) ^ z)\n#define F4(x, y, z) (y ^ (z & (x ^ y)))\t/* z ? x : y */\n\n#define ROUND(a, b, c, d, f, k, x, s)  { \\\n\t(a) += f((b), (c), (d)) + le32_to_cpup(&(x)) + (k); \\\n\t(a) = rol32((a), (s)); \\\n}\n\nstatic void rmd256_transform(u32 *state, const __le32 *in)\n{\n\tu32 aa, bb, cc, dd, aaa, bbb, ccc, ddd, tmp;\n\n\t/* Initialize left lane */\n\taa = state[0];\n\tbb = state[1];\n\tcc = state[2];\n\tdd = state[3];\n\n\t/* Initialize right lane */\n\taaa = state[4];\n\tbbb = state[5];\n\tccc = state[6];\n\tddd = state[7];\n\n\t/* round 1: left lane */\n\tROUND(aa, bb, cc, dd, F1, K1, in[0],  11);\n\tROUND(dd, aa, bb, cc, F1, K1, in[1],  14);\n\tROUND(cc, dd, aa, bb, F1, K1, in[2],  15);\n\tROUND(bb, cc, dd, aa, F1, K1, in[3],  12);\n\tROUND(aa, bb, cc, dd, F1, K1, in[4],   5);\n\tROUND(dd, aa, bb, cc, F1, K1, in[5],   8);\n\tROUND(cc, dd, aa, bb, F1, K1, in[6],   7);\n\tROUND(bb, cc, dd, aa, F1, K1, in[7],   9);\n\tROUND(aa, bb, cc, dd, F1, K1, in[8],  11);\n\tROUND(dd, aa, bb, cc, F1, K1, in[9],  13);\n\tROUND(cc, dd, aa, bb, F1, K1, in[10], 14);\n\tROUND(bb, cc, dd, aa, F1, K1, in[11], 15);\n\tROUND(aa, bb, cc, dd, F1, K1, in[12],  6);\n\tROUND(dd, aa, bb, cc, F1, K1, in[13],  7);\n\tROUND(cc, dd, aa, bb, F1, K1, in[14],  9);\n\tROUND(bb, cc, dd, aa, F1, K1, in[15],  8);\n\n\t/* round 1: right lane */\n\tROUND(aaa, bbb, ccc, ddd, F4, KK1, in[5],   8);\n\tROUND(ddd, aaa, bbb, ccc, F4, KK1, in[14],  9);\n\tROUND(ccc, ddd, aaa, bbb, F4, KK1, in[7],   9);\n\tROUND(bbb, ccc, ddd, aaa, F4, KK1, in[0],  11);\n\tROUND(aaa, bbb, ccc, ddd, F4, KK1, in[9],  13);\n\tROUND(ddd, aaa, bbb, ccc, F4, KK1, in[2],  15);\n\tROUND(ccc, ddd, aaa, bbb, F4, KK1, in[11], 15);\n\tROUND(bbb, ccc, ddd, aaa, F4, KK1, in[4],   5);\n\tROUND(aaa, bbb, ccc, ddd, F4, KK1, in[13],  7);\n\tROUND(ddd, aaa, bbb, ccc, F4, KK1, in[6],   7);\n\tROUND(ccc, ddd, aaa, bbb, F4, KK1, in[15],  8);\n\tROUND(bbb, ccc, ddd, aaa, F4, KK1, in[8],  11);\n\tROUND(aaa, bbb, ccc, ddd, F4, KK1, in[1],  14);\n\tROUND(ddd, aaa, bbb, ccc, F4, KK1, in[10], 14);\n\tROUND(ccc, ddd, aaa, bbb, F4, KK1, in[3],  12);\n\tROUND(bbb, ccc, ddd, aaa, F4, KK1, in[12],  6);\n\n\t/* Swap contents of \"a\" registers */\n\ttmp = aa; aa = aaa; aaa = tmp;\n\n\t/* round 2: left lane */\n\tROUND(aa, bb, cc, dd, F2, K2, in[7],   7);\n\tROUND(dd, aa, bb, cc, F2, K2, in[4],   6);\n\tROUND(cc, dd, aa, bb, F2, K2, in[13],  8);\n\tROUND(bb, cc, dd, aa, F2, K2, in[1],  13);\n\tROUND(aa, bb, cc, dd, F2, K2, in[10], 11);\n\tROUND(dd, aa, bb, cc, F2, K2, in[6],   9);\n\tROUND(cc, dd, aa, bb, F2, K2, in[15],  7);\n\tROUND(bb, cc, dd, aa, F2, K2, in[3],  15);\n\tROUND(aa, bb, cc, dd, F2, K2, in[12],  7);\n\tROUND(dd, aa, bb, cc, F2, K2, in[0],  12);\n\tROUND(cc, dd, aa, bb, F2, K2, in[9],  15);\n\tROUND(bb, cc, dd, aa, F2, K2, in[5],   9);\n\tROUND(aa, bb, cc, dd, F2, K2, in[2],  11);\n\tROUND(dd, aa, bb, cc, F2, K2, in[14],  7);\n\tROUND(cc, dd, aa, bb, F2, K2, in[11], 13);\n\tROUND(bb, cc, dd, aa, F2, K2, in[8],  12);\n\n\t/* round 2: right lane */\n\tROUND(aaa, bbb, ccc, ddd, F3, KK2, in[6],   9);\n\tROUND(ddd, aaa, bbb, ccc, F3, KK2, in[11], 13);\n\tROUND(ccc, ddd, aaa, bbb, F3, KK2, in[3],  15);\n\tROUND(bbb, ccc, ddd, aaa, F3, KK2, in[7],   7);\n\tROUND(aaa, bbb, ccc, ddd, F3, KK2, in[0],  12);\n\tROUND(ddd, aaa, bbb, ccc, F3, KK2, in[13],  8);\n\tROUND(ccc, ddd, aaa, bbb, F3, KK2, in[5],   9);\n\tROUND(bbb, ccc, ddd, aaa, F3, KK2, in[10], 11);\n\tROUND(aaa, bbb, ccc, ddd, F3, KK2, in[14],  7);\n\tROUND(ddd, aaa, bbb, ccc, F3, KK2, in[15],  7);\n\tROUND(ccc, ddd, aaa, bbb, F3, KK2, in[8],  12);\n\tROUND(bbb, ccc, ddd, aaa, F3, KK2, in[12],  7);\n\tROUND(aaa, bbb, ccc, ddd, F3, KK2, in[4],   6);\n\tROUND(ddd, aaa, bbb, ccc, F3, KK2, in[9],  15);\n\tROUND(ccc, ddd, aaa, bbb, F3, KK2, in[1],  13);\n\tROUND(bbb, ccc, ddd, aaa, F3, KK2, in[2],  11);\n\n\t/* Swap contents of \"b\" registers */\n\ttmp = bb; bb = bbb; bbb = tmp;\n\n\t/* round 3: left lane */\n\tROUND(aa, bb, cc, dd, F3, K3, in[3],  11);\n\tROUND(dd, aa, bb, cc, F3, K3, in[10], 13);\n\tROUND(cc, dd, aa, bb, F3, K3, in[14],  6);\n\tROUND(bb, cc, dd, aa, F3, K3, in[4],   7);\n\tROUND(aa, bb, cc, dd, F3, K3, in[9],  14);\n\tROUND(dd, aa, bb, cc, F3, K3, in[15],  9);\n\tROUND(cc, dd, aa, bb, F3, K3, in[8],  13);\n\tROUND(bb, cc, dd, aa, F3, K3, in[1],  15);\n\tROUND(aa, bb, cc, dd, F3, K3, in[2],  14);\n\tROUND(dd, aa, bb, cc, F3, K3, in[7],   8);\n\tROUND(cc, dd, aa, bb, F3, K3, in[0],  13);\n\tROUND(bb, cc, dd, aa, F3, K3, in[6],   6);\n\tROUND(aa, bb, cc, dd, F3, K3, in[13],  5);\n\tROUND(dd, aa, bb, cc, F3, K3, in[11], 12);\n\tROUND(cc, dd, aa, bb, F3, K3, in[5],   7);\n\tROUND(bb, cc, dd, aa, F3, K3, in[12],  5);\n\n\t/* round 3: right lane */\n\tROUND(aaa, bbb, ccc, ddd, F2, KK3, in[15],  9);\n\tROUND(ddd, aaa, bbb, ccc, F2, KK3, in[5],   7);\n\tROUND(ccc, ddd, aaa, bbb, F2, KK3, in[1],  15);\n\tROUND(bbb, ccc, ddd, aaa, F2, KK3, in[3],  11);\n\tROUND(aaa, bbb, ccc, ddd, F2, KK3, in[7],   8);\n\tROUND(ddd, aaa, bbb, ccc, F2, KK3, in[14],  6);\n\tROUND(ccc, ddd, aaa, bbb, F2, KK3, in[6],   6);\n\tROUND(bbb, ccc, ddd, aaa, F2, KK3, in[9],  14);\n\tROUND(aaa, bbb, ccc, ddd, F2, KK3, in[11], 12);\n\tROUND(ddd, aaa, bbb, ccc, F2, KK3, in[8],  13);\n\tROUND(ccc, ddd, aaa, bbb, F2, KK3, in[12],  5);\n\tROUND(bbb, ccc, ddd, aaa, F2, KK3, in[2],  14);\n\tROUND(aaa, bbb, ccc, ddd, F2, KK3, in[10], 13);\n\tROUND(ddd, aaa, bbb, ccc, F2, KK3, in[0],  13);\n\tROUND(ccc, ddd, aaa, bbb, F2, KK3, in[4],   7);\n\tROUND(bbb, ccc, ddd, aaa, F2, KK3, in[13],  5);\n\n\t/* Swap contents of \"c\" registers */\n\ttmp = cc; cc = ccc; ccc = tmp;\n\n\t/* round 4: left lane */\n\tROUND(aa, bb, cc, dd, F4, K4, in[1],  11);\n\tROUND(dd, aa, bb, cc, F4, K4, in[9],  12);\n\tROUND(cc, dd, aa, bb, F4, K4, in[11], 14);\n\tROUND(bb, cc, dd, aa, F4, K4, in[10], 15);\n\tROUND(aa, bb, cc, dd, F4, K4, in[0],  14);\n\tROUND(dd, aa, bb, cc, F4, K4, in[8],  15);\n\tROUND(cc, dd, aa, bb, F4, K4, in[12],  9);\n\tROUND(bb, cc, dd, aa, F4, K4, in[4],   8);\n\tROUND(aa, bb, cc, dd, F4, K4, in[13],  9);\n\tROUND(dd, aa, bb, cc, F4, K4, in[3],  14);\n\tROUND(cc, dd, aa, bb, F4, K4, in[7],   5);\n\tROUND(bb, cc, dd, aa, F4, K4, in[15],  6);\n\tROUND(aa, bb, cc, dd, F4, K4, in[14],  8);\n\tROUND(dd, aa, bb, cc, F4, K4, in[5],   6);\n\tROUND(cc, dd, aa, bb, F4, K4, in[6],   5);\n\tROUND(bb, cc, dd, aa, F4, K4, in[2],  12);\n\n\t/* round 4: right lane */\n\tROUND(aaa, bbb, ccc, ddd, F1, KK4, in[8],  15);\n\tROUND(ddd, aaa, bbb, ccc, F1, KK4, in[6],   5);\n\tROUND(ccc, ddd, aaa, bbb, F1, KK4, in[4],   8);\n\tROUND(bbb, ccc, ddd, aaa, F1, KK4, in[1],  11);\n\tROUND(aaa, bbb, ccc, ddd, F1, KK4, in[3],  14);\n\tROUND(ddd, aaa, bbb, ccc, F1, KK4, in[11], 14);\n\tROUND(ccc, ddd, aaa, bbb, F1, KK4, in[15],  6);\n\tROUND(bbb, ccc, ddd, aaa, F1, KK4, in[0],  14);\n\tROUND(aaa, bbb, ccc, ddd, F1, KK4, in[5],   6);\n\tROUND(ddd, aaa, bbb, ccc, F1, KK4, in[12],  9);\n\tROUND(ccc, ddd, aaa, bbb, F1, KK4, in[2],  12);\n\tROUND(bbb, ccc, ddd, aaa, F1, KK4, in[13],  9);\n\tROUND(aaa, bbb, ccc, ddd, F1, KK4, in[9],  12);\n\tROUND(ddd, aaa, bbb, ccc, F1, KK4, in[7],   5);\n\tROUND(ccc, ddd, aaa, bbb, F1, KK4, in[10], 15);\n\tROUND(bbb, ccc, ddd, aaa, F1, KK4, in[14],  8);\n\n\t/* Swap contents of \"d\" registers */\n\ttmp = dd; dd = ddd; ddd = tmp;\n\n\t/* combine results */\n\tstate[0] += aa;\n\tstate[1] += bb;\n\tstate[2] += cc;\n\tstate[3] += dd;\n\tstate[4] += aaa;\n\tstate[5] += bbb;\n\tstate[6] += ccc;\n\tstate[7] += ddd;\n\n\treturn;\n}\n\nstatic int rmd256_init(struct shash_desc *desc)\n{\n\tstruct rmd256_ctx *rctx = shash_desc_ctx(desc);\n\n\trctx->byte_count = 0;\n\n\trctx->state[0] = RMD_H0;\n\trctx->state[1] = RMD_H1;\n\trctx->state[2] = RMD_H2;\n\trctx->state[3] = RMD_H3;\n\trctx->state[4] = RMD_H5;\n\trctx->state[5] = RMD_H6;\n\trctx->state[6] = RMD_H7;\n\trctx->state[7] = RMD_H8;\n\n\tmemset(rctx->buffer, 0, sizeof(rctx->buffer));\n\n\treturn 0;\n}\n\nstatic int rmd256_update(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int len)\n{\n\tstruct rmd256_ctx *rctx = shash_desc_ctx(desc);\n\tconst u32 avail = sizeof(rctx->buffer) - (rctx->byte_count & 0x3f);\n\n\trctx->byte_count += len;\n\n\t/* Enough space in buffer? If so copy and we're done */\n\tif (avail > len) {\n\t\tmemcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),\n\t\t       data, len);\n\t\tgoto out;\n\t}\n\n\tmemcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),\n\t       data, avail);\n\n\trmd256_transform(rctx->state, rctx->buffer);\n\tdata += avail;\n\tlen -= avail;\n\n\twhile (len >= sizeof(rctx->buffer)) {\n\t\tmemcpy(rctx->buffer, data, sizeof(rctx->buffer));\n\t\trmd256_transform(rctx->state, rctx->buffer);\n\t\tdata += sizeof(rctx->buffer);\n\t\tlen -= sizeof(rctx->buffer);\n\t}\n\n\tmemcpy(rctx->buffer, data, len);\n\nout:\n\treturn 0;\n}\n\n/* Add padding and return the message digest. */\nstatic int rmd256_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct rmd256_ctx *rctx = shash_desc_ctx(desc);\n\tu32 i, index, padlen;\n\t__le64 bits;\n\t__le32 *dst = (__le32 *)out;\n\tstatic const u8 padding[64] = { 0x80, };\n\n\tbits = cpu_to_le64(rctx->byte_count << 3);\n\n\t/* Pad out to 56 mod 64 */\n\tindex = rctx->byte_count & 0x3f;\n\tpadlen = (index < 56) ? (56 - index) : ((64+56) - index);\n\trmd256_update(desc, padding, padlen);\n\n\t/* Append length */\n\trmd256_update(desc, (const u8 *)&bits, sizeof(bits));\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 8; i++)\n\t\tdst[i] = cpu_to_le32p(&rctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(rctx, 0, sizeof(*rctx));\n\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tRMD256_DIGEST_SIZE,\n\t.init\t\t=\trmd256_init,\n\t.update\t\t=\trmd256_update,\n\t.final\t\t=\trmd256_final,\n\t.descsize\t=\tsizeof(struct rmd256_ctx),\n\t.base\t\t=\t{\n\t\t.cra_name\t =\t\"rmd256\",\n\t\t.cra_flags\t =\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t =\tRMD256_BLOCK_SIZE,\n\t\t.cra_module\t =\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init rmd256_mod_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit rmd256_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(rmd256_mod_init);\nmodule_exit(rmd256_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Adrian-Ken Rueegsegger <ken@codelabs.ch>\");\nMODULE_DESCRIPTION(\"RIPEMD-256 Message Digest\");\nMODULE_ALIAS_CRYPTO(\"rmd256\");\n", "/*\n * Cryptographic API.\n *\n * RIPEMD-320 - RACE Integrity Primitives Evaluation Message Digest.\n *\n * Based on the reference implementation by Antoon Bosselaers, ESAT-COSIC\n *\n * Copyright (c) 2008 Adrian-Ken Rueegsegger <ken@codelabs.ch>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/types.h>\n#include <asm/byteorder.h>\n\n#include \"ripemd.h\"\n\nstruct rmd320_ctx {\n\tu64 byte_count;\n\tu32 state[10];\n\t__le32 buffer[16];\n};\n\n#define K1  RMD_K1\n#define K2  RMD_K2\n#define K3  RMD_K3\n#define K4  RMD_K4\n#define K5  RMD_K5\n#define KK1 RMD_K6\n#define KK2 RMD_K7\n#define KK3 RMD_K8\n#define KK4 RMD_K9\n#define KK5 RMD_K1\n\n#define F1(x, y, z) (x ^ y ^ z)\t\t/* XOR */\n#define F2(x, y, z) (z ^ (x & (y ^ z)))\t/* x ? y : z */\n#define F3(x, y, z) ((x | ~y) ^ z)\n#define F4(x, y, z) (y ^ (z & (x ^ y)))\t/* z ? x : y */\n#define F5(x, y, z) (x ^ (y | ~z))\n\n#define ROUND(a, b, c, d, e, f, k, x, s)  { \\\n\t(a) += f((b), (c), (d)) + le32_to_cpup(&(x)) + (k); \\\n\t(a) = rol32((a), (s)) + (e); \\\n\t(c) = rol32((c), 10); \\\n}\n\nstatic void rmd320_transform(u32 *state, const __le32 *in)\n{\n\tu32 aa, bb, cc, dd, ee, aaa, bbb, ccc, ddd, eee, tmp;\n\n\t/* Initialize left lane */\n\taa = state[0];\n\tbb = state[1];\n\tcc = state[2];\n\tdd = state[3];\n\tee = state[4];\n\n\t/* Initialize right lane */\n\taaa = state[5];\n\tbbb = state[6];\n\tccc = state[7];\n\tddd = state[8];\n\teee = state[9];\n\n\t/* round 1: left lane */\n\tROUND(aa, bb, cc, dd, ee, F1, K1, in[0],  11);\n\tROUND(ee, aa, bb, cc, dd, F1, K1, in[1],  14);\n\tROUND(dd, ee, aa, bb, cc, F1, K1, in[2],  15);\n\tROUND(cc, dd, ee, aa, bb, F1, K1, in[3],  12);\n\tROUND(bb, cc, dd, ee, aa, F1, K1, in[4],   5);\n\tROUND(aa, bb, cc, dd, ee, F1, K1, in[5],   8);\n\tROUND(ee, aa, bb, cc, dd, F1, K1, in[6],   7);\n\tROUND(dd, ee, aa, bb, cc, F1, K1, in[7],   9);\n\tROUND(cc, dd, ee, aa, bb, F1, K1, in[8],  11);\n\tROUND(bb, cc, dd, ee, aa, F1, K1, in[9],  13);\n\tROUND(aa, bb, cc, dd, ee, F1, K1, in[10], 14);\n\tROUND(ee, aa, bb, cc, dd, F1, K1, in[11], 15);\n\tROUND(dd, ee, aa, bb, cc, F1, K1, in[12],  6);\n\tROUND(cc, dd, ee, aa, bb, F1, K1, in[13],  7);\n\tROUND(bb, cc, dd, ee, aa, F1, K1, in[14],  9);\n\tROUND(aa, bb, cc, dd, ee, F1, K1, in[15],  8);\n\n\t/* round 1: right lane */\n\tROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[5],   8);\n\tROUND(eee, aaa, bbb, ccc, ddd, F5, KK1, in[14],  9);\n\tROUND(ddd, eee, aaa, bbb, ccc, F5, KK1, in[7],   9);\n\tROUND(ccc, ddd, eee, aaa, bbb, F5, KK1, in[0],  11);\n\tROUND(bbb, ccc, ddd, eee, aaa, F5, KK1, in[9],  13);\n\tROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[2],  15);\n\tROUND(eee, aaa, bbb, ccc, ddd, F5, KK1, in[11], 15);\n\tROUND(ddd, eee, aaa, bbb, ccc, F5, KK1, in[4],   5);\n\tROUND(ccc, ddd, eee, aaa, bbb, F5, KK1, in[13],  7);\n\tROUND(bbb, ccc, ddd, eee, aaa, F5, KK1, in[6],   7);\n\tROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[15],  8);\n\tROUND(eee, aaa, bbb, ccc, ddd, F5, KK1, in[8],  11);\n\tROUND(ddd, eee, aaa, bbb, ccc, F5, KK1, in[1],  14);\n\tROUND(ccc, ddd, eee, aaa, bbb, F5, KK1, in[10], 14);\n\tROUND(bbb, ccc, ddd, eee, aaa, F5, KK1, in[3],  12);\n\tROUND(aaa, bbb, ccc, ddd, eee, F5, KK1, in[12],  6);\n\n\t/* Swap contents of \"a\" registers */\n\ttmp = aa; aa = aaa; aaa = tmp;\n\n\t/* round 2: left lane\" */\n\tROUND(ee, aa, bb, cc, dd, F2, K2, in[7],   7);\n\tROUND(dd, ee, aa, bb, cc, F2, K2, in[4],   6);\n\tROUND(cc, dd, ee, aa, bb, F2, K2, in[13],  8);\n\tROUND(bb, cc, dd, ee, aa, F2, K2, in[1],  13);\n\tROUND(aa, bb, cc, dd, ee, F2, K2, in[10], 11);\n\tROUND(ee, aa, bb, cc, dd, F2, K2, in[6],   9);\n\tROUND(dd, ee, aa, bb, cc, F2, K2, in[15],  7);\n\tROUND(cc, dd, ee, aa, bb, F2, K2, in[3],  15);\n\tROUND(bb, cc, dd, ee, aa, F2, K2, in[12],  7);\n\tROUND(aa, bb, cc, dd, ee, F2, K2, in[0],  12);\n\tROUND(ee, aa, bb, cc, dd, F2, K2, in[9],  15);\n\tROUND(dd, ee, aa, bb, cc, F2, K2, in[5],   9);\n\tROUND(cc, dd, ee, aa, bb, F2, K2, in[2],  11);\n\tROUND(bb, cc, dd, ee, aa, F2, K2, in[14],  7);\n\tROUND(aa, bb, cc, dd, ee, F2, K2, in[11], 13);\n\tROUND(ee, aa, bb, cc, dd, F2, K2, in[8],  12);\n\n\t/* round 2: right lane */\n\tROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[6],   9);\n\tROUND(ddd, eee, aaa, bbb, ccc, F4, KK2, in[11], 13);\n\tROUND(ccc, ddd, eee, aaa, bbb, F4, KK2, in[3],  15);\n\tROUND(bbb, ccc, ddd, eee, aaa, F4, KK2, in[7],   7);\n\tROUND(aaa, bbb, ccc, ddd, eee, F4, KK2, in[0],  12);\n\tROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[13],  8);\n\tROUND(ddd, eee, aaa, bbb, ccc, F4, KK2, in[5],   9);\n\tROUND(ccc, ddd, eee, aaa, bbb, F4, KK2, in[10], 11);\n\tROUND(bbb, ccc, ddd, eee, aaa, F4, KK2, in[14],  7);\n\tROUND(aaa, bbb, ccc, ddd, eee, F4, KK2, in[15],  7);\n\tROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[8],  12);\n\tROUND(ddd, eee, aaa, bbb, ccc, F4, KK2, in[12],  7);\n\tROUND(ccc, ddd, eee, aaa, bbb, F4, KK2, in[4],   6);\n\tROUND(bbb, ccc, ddd, eee, aaa, F4, KK2, in[9],  15);\n\tROUND(aaa, bbb, ccc, ddd, eee, F4, KK2, in[1],  13);\n\tROUND(eee, aaa, bbb, ccc, ddd, F4, KK2, in[2],  11);\n\n\t/* Swap contents of \"b\" registers */\n\ttmp = bb; bb = bbb; bbb = tmp;\n\n\t/* round 3: left lane\" */\n\tROUND(dd, ee, aa, bb, cc, F3, K3, in[3],  11);\n\tROUND(cc, dd, ee, aa, bb, F3, K3, in[10], 13);\n\tROUND(bb, cc, dd, ee, aa, F3, K3, in[14],  6);\n\tROUND(aa, bb, cc, dd, ee, F3, K3, in[4],   7);\n\tROUND(ee, aa, bb, cc, dd, F3, K3, in[9],  14);\n\tROUND(dd, ee, aa, bb, cc, F3, K3, in[15],  9);\n\tROUND(cc, dd, ee, aa, bb, F3, K3, in[8],  13);\n\tROUND(bb, cc, dd, ee, aa, F3, K3, in[1],  15);\n\tROUND(aa, bb, cc, dd, ee, F3, K3, in[2],  14);\n\tROUND(ee, aa, bb, cc, dd, F3, K3, in[7],   8);\n\tROUND(dd, ee, aa, bb, cc, F3, K3, in[0],  13);\n\tROUND(cc, dd, ee, aa, bb, F3, K3, in[6],   6);\n\tROUND(bb, cc, dd, ee, aa, F3, K3, in[13],  5);\n\tROUND(aa, bb, cc, dd, ee, F3, K3, in[11], 12);\n\tROUND(ee, aa, bb, cc, dd, F3, K3, in[5],   7);\n\tROUND(dd, ee, aa, bb, cc, F3, K3, in[12],  5);\n\n\t/* round 3: right lane */\n\tROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[15],  9);\n\tROUND(ccc, ddd, eee, aaa, bbb, F3, KK3, in[5],   7);\n\tROUND(bbb, ccc, ddd, eee, aaa, F3, KK3, in[1],  15);\n\tROUND(aaa, bbb, ccc, ddd, eee, F3, KK3, in[3],  11);\n\tROUND(eee, aaa, bbb, ccc, ddd, F3, KK3, in[7],   8);\n\tROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[14],  6);\n\tROUND(ccc, ddd, eee, aaa, bbb, F3, KK3, in[6],   6);\n\tROUND(bbb, ccc, ddd, eee, aaa, F3, KK3, in[9],  14);\n\tROUND(aaa, bbb, ccc, ddd, eee, F3, KK3, in[11], 12);\n\tROUND(eee, aaa, bbb, ccc, ddd, F3, KK3, in[8],  13);\n\tROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[12],  5);\n\tROUND(ccc, ddd, eee, aaa, bbb, F3, KK3, in[2],  14);\n\tROUND(bbb, ccc, ddd, eee, aaa, F3, KK3, in[10], 13);\n\tROUND(aaa, bbb, ccc, ddd, eee, F3, KK3, in[0],  13);\n\tROUND(eee, aaa, bbb, ccc, ddd, F3, KK3, in[4],   7);\n\tROUND(ddd, eee, aaa, bbb, ccc, F3, KK3, in[13],  5);\n\n\t/* Swap contents of \"c\" registers */\n\ttmp = cc; cc = ccc; ccc = tmp;\n\n\t/* round 4: left lane\" */\n\tROUND(cc, dd, ee, aa, bb, F4, K4, in[1],  11);\n\tROUND(bb, cc, dd, ee, aa, F4, K4, in[9],  12);\n\tROUND(aa, bb, cc, dd, ee, F4, K4, in[11], 14);\n\tROUND(ee, aa, bb, cc, dd, F4, K4, in[10], 15);\n\tROUND(dd, ee, aa, bb, cc, F4, K4, in[0],  14);\n\tROUND(cc, dd, ee, aa, bb, F4, K4, in[8],  15);\n\tROUND(bb, cc, dd, ee, aa, F4, K4, in[12],  9);\n\tROUND(aa, bb, cc, dd, ee, F4, K4, in[4],   8);\n\tROUND(ee, aa, bb, cc, dd, F4, K4, in[13],  9);\n\tROUND(dd, ee, aa, bb, cc, F4, K4, in[3],  14);\n\tROUND(cc, dd, ee, aa, bb, F4, K4, in[7],   5);\n\tROUND(bb, cc, dd, ee, aa, F4, K4, in[15],  6);\n\tROUND(aa, bb, cc, dd, ee, F4, K4, in[14],  8);\n\tROUND(ee, aa, bb, cc, dd, F4, K4, in[5],   6);\n\tROUND(dd, ee, aa, bb, cc, F4, K4, in[6],   5);\n\tROUND(cc, dd, ee, aa, bb, F4, K4, in[2],  12);\n\n\t/* round 4: right lane */\n\tROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[8],  15);\n\tROUND(bbb, ccc, ddd, eee, aaa, F2, KK4, in[6],   5);\n\tROUND(aaa, bbb, ccc, ddd, eee, F2, KK4, in[4],   8);\n\tROUND(eee, aaa, bbb, ccc, ddd, F2, KK4, in[1],  11);\n\tROUND(ddd, eee, aaa, bbb, ccc, F2, KK4, in[3],  14);\n\tROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[11], 14);\n\tROUND(bbb, ccc, ddd, eee, aaa, F2, KK4, in[15],  6);\n\tROUND(aaa, bbb, ccc, ddd, eee, F2, KK4, in[0],  14);\n\tROUND(eee, aaa, bbb, ccc, ddd, F2, KK4, in[5],   6);\n\tROUND(ddd, eee, aaa, bbb, ccc, F2, KK4, in[12],  9);\n\tROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[2],  12);\n\tROUND(bbb, ccc, ddd, eee, aaa, F2, KK4, in[13],  9);\n\tROUND(aaa, bbb, ccc, ddd, eee, F2, KK4, in[9],  12);\n\tROUND(eee, aaa, bbb, ccc, ddd, F2, KK4, in[7],   5);\n\tROUND(ddd, eee, aaa, bbb, ccc, F2, KK4, in[10], 15);\n\tROUND(ccc, ddd, eee, aaa, bbb, F2, KK4, in[14],  8);\n\n\t/* Swap contents of \"d\" registers */\n\ttmp = dd; dd = ddd; ddd = tmp;\n\n\t/* round 5: left lane\" */\n\tROUND(bb, cc, dd, ee, aa, F5, K5, in[4],   9);\n\tROUND(aa, bb, cc, dd, ee, F5, K5, in[0],  15);\n\tROUND(ee, aa, bb, cc, dd, F5, K5, in[5],   5);\n\tROUND(dd, ee, aa, bb, cc, F5, K5, in[9],  11);\n\tROUND(cc, dd, ee, aa, bb, F5, K5, in[7],   6);\n\tROUND(bb, cc, dd, ee, aa, F5, K5, in[12],  8);\n\tROUND(aa, bb, cc, dd, ee, F5, K5, in[2],  13);\n\tROUND(ee, aa, bb, cc, dd, F5, K5, in[10], 12);\n\tROUND(dd, ee, aa, bb, cc, F5, K5, in[14],  5);\n\tROUND(cc, dd, ee, aa, bb, F5, K5, in[1],  12);\n\tROUND(bb, cc, dd, ee, aa, F5, K5, in[3],  13);\n\tROUND(aa, bb, cc, dd, ee, F5, K5, in[8],  14);\n\tROUND(ee, aa, bb, cc, dd, F5, K5, in[11], 11);\n\tROUND(dd, ee, aa, bb, cc, F5, K5, in[6],   8);\n\tROUND(cc, dd, ee, aa, bb, F5, K5, in[15],  5);\n\tROUND(bb, cc, dd, ee, aa, F5, K5, in[13],  6);\n\n\t/* round 5: right lane */\n\tROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[12],  8);\n\tROUND(aaa, bbb, ccc, ddd, eee, F1, KK5, in[15],  5);\n\tROUND(eee, aaa, bbb, ccc, ddd, F1, KK5, in[10], 12);\n\tROUND(ddd, eee, aaa, bbb, ccc, F1, KK5, in[4],   9);\n\tROUND(ccc, ddd, eee, aaa, bbb, F1, KK5, in[1],  12);\n\tROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[5],   5);\n\tROUND(aaa, bbb, ccc, ddd, eee, F1, KK5, in[8],  14);\n\tROUND(eee, aaa, bbb, ccc, ddd, F1, KK5, in[7],   6);\n\tROUND(ddd, eee, aaa, bbb, ccc, F1, KK5, in[6],   8);\n\tROUND(ccc, ddd, eee, aaa, bbb, F1, KK5, in[2],  13);\n\tROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[13],  6);\n\tROUND(aaa, bbb, ccc, ddd, eee, F1, KK5, in[14],  5);\n\tROUND(eee, aaa, bbb, ccc, ddd, F1, KK5, in[0],  15);\n\tROUND(ddd, eee, aaa, bbb, ccc, F1, KK5, in[3],  13);\n\tROUND(ccc, ddd, eee, aaa, bbb, F1, KK5, in[9],  11);\n\tROUND(bbb, ccc, ddd, eee, aaa, F1, KK5, in[11], 11);\n\n\t/* Swap contents of \"e\" registers */\n\ttmp = ee; ee = eee; eee = tmp;\n\n\t/* combine results */\n\tstate[0] += aa;\n\tstate[1] += bb;\n\tstate[2] += cc;\n\tstate[3] += dd;\n\tstate[4] += ee;\n\tstate[5] += aaa;\n\tstate[6] += bbb;\n\tstate[7] += ccc;\n\tstate[8] += ddd;\n\tstate[9] += eee;\n\n\treturn;\n}\n\nstatic int rmd320_init(struct shash_desc *desc)\n{\n\tstruct rmd320_ctx *rctx = shash_desc_ctx(desc);\n\n\trctx->byte_count = 0;\n\n\trctx->state[0] = RMD_H0;\n\trctx->state[1] = RMD_H1;\n\trctx->state[2] = RMD_H2;\n\trctx->state[3] = RMD_H3;\n\trctx->state[4] = RMD_H4;\n\trctx->state[5] = RMD_H5;\n\trctx->state[6] = RMD_H6;\n\trctx->state[7] = RMD_H7;\n\trctx->state[8] = RMD_H8;\n\trctx->state[9] = RMD_H9;\n\n\tmemset(rctx->buffer, 0, sizeof(rctx->buffer));\n\n\treturn 0;\n}\n\nstatic int rmd320_update(struct shash_desc *desc, const u8 *data,\n\t\t\t unsigned int len)\n{\n\tstruct rmd320_ctx *rctx = shash_desc_ctx(desc);\n\tconst u32 avail = sizeof(rctx->buffer) - (rctx->byte_count & 0x3f);\n\n\trctx->byte_count += len;\n\n\t/* Enough space in buffer? If so copy and we're done */\n\tif (avail > len) {\n\t\tmemcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),\n\t\t       data, len);\n\t\tgoto out;\n\t}\n\n\tmemcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),\n\t       data, avail);\n\n\trmd320_transform(rctx->state, rctx->buffer);\n\tdata += avail;\n\tlen -= avail;\n\n\twhile (len >= sizeof(rctx->buffer)) {\n\t\tmemcpy(rctx->buffer, data, sizeof(rctx->buffer));\n\t\trmd320_transform(rctx->state, rctx->buffer);\n\t\tdata += sizeof(rctx->buffer);\n\t\tlen -= sizeof(rctx->buffer);\n\t}\n\n\tmemcpy(rctx->buffer, data, len);\n\nout:\n\treturn 0;\n}\n\n/* Add padding and return the message digest. */\nstatic int rmd320_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct rmd320_ctx *rctx = shash_desc_ctx(desc);\n\tu32 i, index, padlen;\n\t__le64 bits;\n\t__le32 *dst = (__le32 *)out;\n\tstatic const u8 padding[64] = { 0x80, };\n\n\tbits = cpu_to_le64(rctx->byte_count << 3);\n\n\t/* Pad out to 56 mod 64 */\n\tindex = rctx->byte_count & 0x3f;\n\tpadlen = (index < 56) ? (56 - index) : ((64+56) - index);\n\trmd320_update(desc, padding, padlen);\n\n\t/* Append length */\n\trmd320_update(desc, (const u8 *)&bits, sizeof(bits));\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 10; i++)\n\t\tdst[i] = cpu_to_le32p(&rctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(rctx, 0, sizeof(*rctx));\n\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tRMD320_DIGEST_SIZE,\n\t.init\t\t=\trmd320_init,\n\t.update\t\t=\trmd320_update,\n\t.final\t\t=\trmd320_final,\n\t.descsize\t=\tsizeof(struct rmd320_ctx),\n\t.base\t\t=\t{\n\t\t.cra_name\t =\t\"rmd320\",\n\t\t.cra_flags\t =\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t =\tRMD320_BLOCK_SIZE,\n\t\t.cra_module\t =\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init rmd320_mod_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit rmd320_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(rmd320_mod_init);\nmodule_exit(rmd320_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Adrian-Ken Rueegsegger <ken@codelabs.ch>\");\nMODULE_DESCRIPTION(\"RIPEMD-320 Message Digest\");\nMODULE_ALIAS_CRYPTO(\"rmd320\");\n", "/*\n * Salsa20: Salsa20 stream cipher algorithm\n *\n * Copyright (c) 2007 Tan Swee Heng <thesweeheng@gmail.com>\n *\n * Derived from:\n * - salsa20.c: Public domain C code by Daniel J. Bernstein <djb@cr.yp.to>\n *\n * Salsa20 is a stream cipher candidate in eSTREAM, the ECRYPT Stream\n * Cipher Project. It is designed by Daniel J. Bernstein <djb@cr.yp.to>.\n * More information about eSTREAM and Salsa20 can be found here:\n *   http://www.ecrypt.eu.org/stream/\n *   http://cr.yp.to/snuffle.html\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/crypto.h>\n#include <linux/types.h>\n#include <linux/bitops.h>\n#include <crypto/algapi.h>\n#include <asm/byteorder.h>\n\n#define SALSA20_IV_SIZE        8U\n#define SALSA20_MIN_KEY_SIZE  16U\n#define SALSA20_MAX_KEY_SIZE  32U\n\n/*\n * Start of code taken from D. J. Bernstein's reference implementation.\n * With some modifications and optimizations made to suit our needs.\n */\n\n/*\nsalsa20-ref.c version 20051118\nD. J. Bernstein\nPublic domain.\n*/\n\n#define U32TO8_LITTLE(p, v) \\\n\t{ (p)[0] = (v >>  0) & 0xff; (p)[1] = (v >>  8) & 0xff; \\\n\t  (p)[2] = (v >> 16) & 0xff; (p)[3] = (v >> 24) & 0xff; }\n#define U8TO32_LITTLE(p)   \\\n\t(((u32)((p)[0])      ) | ((u32)((p)[1]) <<  8) | \\\n\t ((u32)((p)[2]) << 16) | ((u32)((p)[3]) << 24)   )\n\nstruct salsa20_ctx\n{\n\tu32 input[16];\n};\n\nstatic void salsa20_wordtobyte(u8 output[64], const u32 input[16])\n{\n\tu32 x[16];\n\tint i;\n\n\tmemcpy(x, input, sizeof(x));\n\tfor (i = 20; i > 0; i -= 2) {\n\t\tx[ 4] ^= rol32((x[ 0] + x[12]),  7);\n\t\tx[ 8] ^= rol32((x[ 4] + x[ 0]),  9);\n\t\tx[12] ^= rol32((x[ 8] + x[ 4]), 13);\n\t\tx[ 0] ^= rol32((x[12] + x[ 8]), 18);\n\t\tx[ 9] ^= rol32((x[ 5] + x[ 1]),  7);\n\t\tx[13] ^= rol32((x[ 9] + x[ 5]),  9);\n\t\tx[ 1] ^= rol32((x[13] + x[ 9]), 13);\n\t\tx[ 5] ^= rol32((x[ 1] + x[13]), 18);\n\t\tx[14] ^= rol32((x[10] + x[ 6]),  7);\n\t\tx[ 2] ^= rol32((x[14] + x[10]),  9);\n\t\tx[ 6] ^= rol32((x[ 2] + x[14]), 13);\n\t\tx[10] ^= rol32((x[ 6] + x[ 2]), 18);\n\t\tx[ 3] ^= rol32((x[15] + x[11]),  7);\n\t\tx[ 7] ^= rol32((x[ 3] + x[15]),  9);\n\t\tx[11] ^= rol32((x[ 7] + x[ 3]), 13);\n\t\tx[15] ^= rol32((x[11] + x[ 7]), 18);\n\t\tx[ 1] ^= rol32((x[ 0] + x[ 3]),  7);\n\t\tx[ 2] ^= rol32((x[ 1] + x[ 0]),  9);\n\t\tx[ 3] ^= rol32((x[ 2] + x[ 1]), 13);\n\t\tx[ 0] ^= rol32((x[ 3] + x[ 2]), 18);\n\t\tx[ 6] ^= rol32((x[ 5] + x[ 4]),  7);\n\t\tx[ 7] ^= rol32((x[ 6] + x[ 5]),  9);\n\t\tx[ 4] ^= rol32((x[ 7] + x[ 6]), 13);\n\t\tx[ 5] ^= rol32((x[ 4] + x[ 7]), 18);\n\t\tx[11] ^= rol32((x[10] + x[ 9]),  7);\n\t\tx[ 8] ^= rol32((x[11] + x[10]),  9);\n\t\tx[ 9] ^= rol32((x[ 8] + x[11]), 13);\n\t\tx[10] ^= rol32((x[ 9] + x[ 8]), 18);\n\t\tx[12] ^= rol32((x[15] + x[14]),  7);\n\t\tx[13] ^= rol32((x[12] + x[15]),  9);\n\t\tx[14] ^= rol32((x[13] + x[12]), 13);\n\t\tx[15] ^= rol32((x[14] + x[13]), 18);\n\t}\n\tfor (i = 0; i < 16; ++i)\n\t\tx[i] += input[i];\n\tfor (i = 0; i < 16; ++i)\n\t\tU32TO8_LITTLE(output + 4 * i,x[i]);\n}\n\nstatic const char sigma[16] = \"expand 32-byte k\";\nstatic const char tau[16] = \"expand 16-byte k\";\n\nstatic void salsa20_keysetup(struct salsa20_ctx *ctx, const u8 *k, u32 kbytes)\n{\n\tconst char *constants;\n\n\tctx->input[1] = U8TO32_LITTLE(k + 0);\n\tctx->input[2] = U8TO32_LITTLE(k + 4);\n\tctx->input[3] = U8TO32_LITTLE(k + 8);\n\tctx->input[4] = U8TO32_LITTLE(k + 12);\n\tif (kbytes == 32) { /* recommended */\n\t\tk += 16;\n\t\tconstants = sigma;\n\t} else { /* kbytes == 16 */\n\t\tconstants = tau;\n\t}\n\tctx->input[11] = U8TO32_LITTLE(k + 0);\n\tctx->input[12] = U8TO32_LITTLE(k + 4);\n\tctx->input[13] = U8TO32_LITTLE(k + 8);\n\tctx->input[14] = U8TO32_LITTLE(k + 12);\n\tctx->input[0] = U8TO32_LITTLE(constants + 0);\n\tctx->input[5] = U8TO32_LITTLE(constants + 4);\n\tctx->input[10] = U8TO32_LITTLE(constants + 8);\n\tctx->input[15] = U8TO32_LITTLE(constants + 12);\n}\n\nstatic void salsa20_ivsetup(struct salsa20_ctx *ctx, const u8 *iv)\n{\n\tctx->input[6] = U8TO32_LITTLE(iv + 0);\n\tctx->input[7] = U8TO32_LITTLE(iv + 4);\n\tctx->input[8] = 0;\n\tctx->input[9] = 0;\n}\n\nstatic void salsa20_encrypt_bytes(struct salsa20_ctx *ctx, u8 *dst,\n\t\t\t\t  const u8 *src, unsigned int bytes)\n{\n\tu8 buf[64];\n\n\tif (dst != src)\n\t\tmemcpy(dst, src, bytes);\n\n\twhile (bytes) {\n\t\tsalsa20_wordtobyte(buf, ctx->input);\n\n\t\tctx->input[8]++;\n\t\tif (!ctx->input[8])\n\t\t\tctx->input[9]++;\n\n\t\tif (bytes <= 64) {\n\t\t\tcrypto_xor(dst, buf, bytes);\n\t\t\treturn;\n\t\t}\n\n\t\tcrypto_xor(dst, buf, 64);\n\t\tbytes -= 64;\n\t\tdst += 64;\n\t}\n}\n\n/*\n * End of code taken from D. J. Bernstein's reference implementation.\n */\n\nstatic int setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t  unsigned int keysize)\n{\n\tstruct salsa20_ctx *ctx = crypto_tfm_ctx(tfm);\n\tsalsa20_keysetup(ctx, key, keysize);\n\treturn 0;\n}\n\nstatic int encrypt(struct blkcipher_desc *desc,\n\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t   unsigned int nbytes)\n{\n\tstruct blkcipher_walk walk;\n\tstruct crypto_blkcipher *tfm = desc->tfm;\n\tstruct salsa20_ctx *ctx = crypto_blkcipher_ctx(tfm);\n\tint err;\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt_block(desc, &walk, 64);\n\n\tsalsa20_ivsetup(ctx, walk.iv);\n\n\tif (likely(walk.nbytes == nbytes))\n\t{\n\t\tsalsa20_encrypt_bytes(ctx, walk.dst.virt.addr,\n\t\t\t\t      walk.src.virt.addr, nbytes);\n\t\treturn blkcipher_walk_done(desc, &walk, 0);\n\t}\n\n\twhile (walk.nbytes >= 64) {\n\t\tsalsa20_encrypt_bytes(ctx, walk.dst.virt.addr,\n\t\t\t\t      walk.src.virt.addr,\n\t\t\t\t      walk.nbytes - (walk.nbytes % 64));\n\t\terr = blkcipher_walk_done(desc, &walk, walk.nbytes % 64);\n\t}\n\n\tif (walk.nbytes) {\n\t\tsalsa20_encrypt_bytes(ctx, walk.dst.virt.addr,\n\t\t\t\t      walk.src.virt.addr, walk.nbytes);\n\t\terr = blkcipher_walk_done(desc, &walk, 0);\n\t}\n\n\treturn err;\n}\n\nstatic struct crypto_alg alg = {\n\t.cra_name           =   \"salsa20\",\n\t.cra_driver_name    =   \"salsa20-generic\",\n\t.cra_priority       =   100,\n\t.cra_flags          =   CRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_type           =   &crypto_blkcipher_type,\n\t.cra_blocksize      =   1,\n\t.cra_ctxsize        =   sizeof(struct salsa20_ctx),\n\t.cra_alignmask      =\t3,\n\t.cra_module         =   THIS_MODULE,\n\t.cra_u              =   {\n\t\t.blkcipher = {\n\t\t\t.setkey         =   setkey,\n\t\t\t.encrypt        =   encrypt,\n\t\t\t.decrypt        =   encrypt,\n\t\t\t.min_keysize    =   SALSA20_MIN_KEY_SIZE,\n\t\t\t.max_keysize    =   SALSA20_MAX_KEY_SIZE,\n\t\t\t.ivsize         =   SALSA20_IV_SIZE,\n\t\t}\n\t}\n};\n\nstatic int __init salsa20_generic_mod_init(void)\n{\n\treturn crypto_register_alg(&alg);\n}\n\nstatic void __exit salsa20_generic_mod_fini(void)\n{\n\tcrypto_unregister_alg(&alg);\n}\n\nmodule_init(salsa20_generic_mod_init);\nmodule_exit(salsa20_generic_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION (\"Salsa20 stream cipher algorithm\");\nMODULE_ALIAS_CRYPTO(\"salsa20\");\n", "/*\n * Cryptographic API.\n *\n * SEED Cipher Algorithm.\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * Documentation of SEED can be found in RFC 4269.\n * Copyright (C) 2007 Korea Information Security Agency (KISA).\n */\n\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/types.h>\n#include <linux/errno.h>\n#include <linux/crypto.h>\n#include <asm/byteorder.h>\n\n#define SEED_NUM_KCONSTANTS\t16\n#define SEED_KEY_SIZE\t\t16\n#define SEED_BLOCK_SIZE\t\t16\n#define SEED_KEYSCHED_LEN\t32\n\n/*\n * #define byte(x, nr) ((unsigned char)((x) >> (nr*8)))\n */\nstatic inline u8\nbyte(const u32 x, const unsigned n)\n{\n\treturn x >> (n << 3);\n}\n\nstruct seed_ctx {\n\tu32 keysched[SEED_KEYSCHED_LEN];\n};\n\nstatic const u32 SS0[256] = {\n\t0x2989a1a8, 0x05858184, 0x16c6d2d4, 0x13c3d3d0,\n\t0x14445054, 0x1d0d111c, 0x2c8ca0ac, 0x25052124,\n\t0x1d4d515c, 0x03434340, 0x18081018, 0x1e0e121c,\n\t0x11415150, 0x3cccf0fc, 0x0acac2c8, 0x23436360,\n\t0x28082028, 0x04444044, 0x20002020, 0x1d8d919c,\n\t0x20c0e0e0, 0x22c2e2e0, 0x08c8c0c8, 0x17071314,\n\t0x2585a1a4, 0x0f8f838c, 0x03030300, 0x3b4b7378,\n\t0x3b8bb3b8, 0x13031310, 0x12c2d2d0, 0x2ecee2ec,\n\t0x30407070, 0x0c8c808c, 0x3f0f333c, 0x2888a0a8,\n\t0x32023230, 0x1dcdd1dc, 0x36c6f2f4, 0x34447074,\n\t0x2ccce0ec, 0x15859194, 0x0b0b0308, 0x17475354,\n\t0x1c4c505c, 0x1b4b5358, 0x3d8db1bc, 0x01010100,\n\t0x24042024, 0x1c0c101c, 0x33437370, 0x18889098,\n\t0x10001010, 0x0cccc0cc, 0x32c2f2f0, 0x19c9d1d8,\n\t0x2c0c202c, 0x27c7e3e4, 0x32427270, 0x03838380,\n\t0x1b8b9398, 0x11c1d1d0, 0x06868284, 0x09c9c1c8,\n\t0x20406060, 0x10405050, 0x2383a3a0, 0x2bcbe3e8,\n\t0x0d0d010c, 0x3686b2b4, 0x1e8e929c, 0x0f4f434c,\n\t0x3787b3b4, 0x1a4a5258, 0x06c6c2c4, 0x38487078,\n\t0x2686a2a4, 0x12021210, 0x2f8fa3ac, 0x15c5d1d4,\n\t0x21416160, 0x03c3c3c0, 0x3484b0b4, 0x01414140,\n\t0x12425250, 0x3d4d717c, 0x0d8d818c, 0x08080008,\n\t0x1f0f131c, 0x19899198, 0x00000000, 0x19091118,\n\t0x04040004, 0x13435350, 0x37c7f3f4, 0x21c1e1e0,\n\t0x3dcdf1fc, 0x36467274, 0x2f0f232c, 0x27072324,\n\t0x3080b0b0, 0x0b8b8388, 0x0e0e020c, 0x2b8ba3a8,\n\t0x2282a2a0, 0x2e4e626c, 0x13839390, 0x0d4d414c,\n\t0x29496168, 0x3c4c707c, 0x09090108, 0x0a0a0208,\n\t0x3f8fb3bc, 0x2fcfe3ec, 0x33c3f3f0, 0x05c5c1c4,\n\t0x07878384, 0x14041014, 0x3ecef2fc, 0x24446064,\n\t0x1eced2dc, 0x2e0e222c, 0x0b4b4348, 0x1a0a1218,\n\t0x06060204, 0x21012120, 0x2b4b6368, 0x26466264,\n\t0x02020200, 0x35c5f1f4, 0x12829290, 0x0a8a8288,\n\t0x0c0c000c, 0x3383b3b0, 0x3e4e727c, 0x10c0d0d0,\n\t0x3a4a7278, 0x07474344, 0x16869294, 0x25c5e1e4,\n\t0x26062224, 0x00808080, 0x2d8da1ac, 0x1fcfd3dc,\n\t0x2181a1a0, 0x30003030, 0x37073334, 0x2e8ea2ac,\n\t0x36063234, 0x15051114, 0x22022220, 0x38083038,\n\t0x34c4f0f4, 0x2787a3a4, 0x05454144, 0x0c4c404c,\n\t0x01818180, 0x29c9e1e8, 0x04848084, 0x17879394,\n\t0x35053134, 0x0bcbc3c8, 0x0ecec2cc, 0x3c0c303c,\n\t0x31417170, 0x11011110, 0x07c7c3c4, 0x09898188,\n\t0x35457174, 0x3bcbf3f8, 0x1acad2d8, 0x38c8f0f8,\n\t0x14849094, 0x19495158, 0x02828280, 0x04c4c0c4,\n\t0x3fcff3fc, 0x09494148, 0x39093138, 0x27476364,\n\t0x00c0c0c0, 0x0fcfc3cc, 0x17c7d3d4, 0x3888b0b8,\n\t0x0f0f030c, 0x0e8e828c, 0x02424240, 0x23032320,\n\t0x11819190, 0x2c4c606c, 0x1bcbd3d8, 0x2484a0a4,\n\t0x34043034, 0x31c1f1f0, 0x08484048, 0x02c2c2c0,\n\t0x2f4f636c, 0x3d0d313c, 0x2d0d212c, 0x00404040,\n\t0x3e8eb2bc, 0x3e0e323c, 0x3c8cb0bc, 0x01c1c1c0,\n\t0x2a8aa2a8, 0x3a8ab2b8, 0x0e4e424c, 0x15455154,\n\t0x3b0b3338, 0x1cccd0dc, 0x28486068, 0x3f4f737c,\n\t0x1c8c909c, 0x18c8d0d8, 0x0a4a4248, 0x16465254,\n\t0x37477374, 0x2080a0a0, 0x2dcde1ec, 0x06464244,\n\t0x3585b1b4, 0x2b0b2328, 0x25456164, 0x3acaf2f8,\n\t0x23c3e3e0, 0x3989b1b8, 0x3181b1b0, 0x1f8f939c,\n\t0x1e4e525c, 0x39c9f1f8, 0x26c6e2e4, 0x3282b2b0,\n\t0x31013130, 0x2acae2e8, 0x2d4d616c, 0x1f4f535c,\n\t0x24c4e0e4, 0x30c0f0f0, 0x0dcdc1cc, 0x08888088,\n\t0x16061214, 0x3a0a3238, 0x18485058, 0x14c4d0d4,\n\t0x22426260, 0x29092128, 0x07070304, 0x33033330,\n\t0x28c8e0e8, 0x1b0b1318, 0x05050104, 0x39497178,\n\t0x10809090, 0x2a4a6268, 0x2a0a2228, 0x1a8a9298,\n};\n\nstatic const u32 SS1[256] = {\n\t0x38380830, 0xe828c8e0, 0x2c2d0d21, 0xa42686a2,\n\t0xcc0fcfc3, 0xdc1eced2, 0xb03383b3, 0xb83888b0,\n\t0xac2f8fa3, 0x60204060, 0x54154551, 0xc407c7c3,\n\t0x44044440, 0x6c2f4f63, 0x682b4b63, 0x581b4b53,\n\t0xc003c3c3, 0x60224262, 0x30330333, 0xb43585b1,\n\t0x28290921, 0xa02080a0, 0xe022c2e2, 0xa42787a3,\n\t0xd013c3d3, 0x90118191, 0x10110111, 0x04060602,\n\t0x1c1c0c10, 0xbc3c8cb0, 0x34360632, 0x480b4b43,\n\t0xec2fcfe3, 0x88088880, 0x6c2c4c60, 0xa82888a0,\n\t0x14170713, 0xc404c4c0, 0x14160612, 0xf434c4f0,\n\t0xc002c2c2, 0x44054541, 0xe021c1e1, 0xd416c6d2,\n\t0x3c3f0f33, 0x3c3d0d31, 0x8c0e8e82, 0x98188890,\n\t0x28280820, 0x4c0e4e42, 0xf436c6f2, 0x3c3e0e32,\n\t0xa42585a1, 0xf839c9f1, 0x0c0d0d01, 0xdc1fcfd3,\n\t0xd818c8d0, 0x282b0b23, 0x64264662, 0x783a4a72,\n\t0x24270723, 0x2c2f0f23, 0xf031c1f1, 0x70324272,\n\t0x40024242, 0xd414c4d0, 0x40014141, 0xc000c0c0,\n\t0x70334373, 0x64274763, 0xac2c8ca0, 0x880b8b83,\n\t0xf437c7f3, 0xac2d8da1, 0x80008080, 0x1c1f0f13,\n\t0xc80acac2, 0x2c2c0c20, 0xa82a8aa2, 0x34340430,\n\t0xd012c2d2, 0x080b0b03, 0xec2ecee2, 0xe829c9e1,\n\t0x5c1d4d51, 0x94148490, 0x18180810, 0xf838c8f0,\n\t0x54174753, 0xac2e8ea2, 0x08080800, 0xc405c5c1,\n\t0x10130313, 0xcc0dcdc1, 0x84068682, 0xb83989b1,\n\t0xfc3fcff3, 0x7c3d4d71, 0xc001c1c1, 0x30310131,\n\t0xf435c5f1, 0x880a8a82, 0x682a4a62, 0xb03181b1,\n\t0xd011c1d1, 0x20200020, 0xd417c7d3, 0x00020202,\n\t0x20220222, 0x04040400, 0x68284860, 0x70314171,\n\t0x04070703, 0xd81bcbd3, 0x9c1d8d91, 0x98198991,\n\t0x60214161, 0xbc3e8eb2, 0xe426c6e2, 0x58194951,\n\t0xdc1dcdd1, 0x50114151, 0x90108090, 0xdc1cccd0,\n\t0x981a8a92, 0xa02383a3, 0xa82b8ba3, 0xd010c0d0,\n\t0x80018181, 0x0c0f0f03, 0x44074743, 0x181a0a12,\n\t0xe023c3e3, 0xec2ccce0, 0x8c0d8d81, 0xbc3f8fb3,\n\t0x94168692, 0x783b4b73, 0x5c1c4c50, 0xa02282a2,\n\t0xa02181a1, 0x60234363, 0x20230323, 0x4c0d4d41,\n\t0xc808c8c0, 0x9c1e8e92, 0x9c1c8c90, 0x383a0a32,\n\t0x0c0c0c00, 0x2c2e0e22, 0xb83a8ab2, 0x6c2e4e62,\n\t0x9c1f8f93, 0x581a4a52, 0xf032c2f2, 0x90128292,\n\t0xf033c3f3, 0x48094941, 0x78384870, 0xcc0cccc0,\n\t0x14150511, 0xf83bcbf3, 0x70304070, 0x74354571,\n\t0x7c3f4f73, 0x34350531, 0x10100010, 0x00030303,\n\t0x64244460, 0x6c2d4d61, 0xc406c6c2, 0x74344470,\n\t0xd415c5d1, 0xb43484b0, 0xe82acae2, 0x08090901,\n\t0x74364672, 0x18190911, 0xfc3ecef2, 0x40004040,\n\t0x10120212, 0xe020c0e0, 0xbc3d8db1, 0x04050501,\n\t0xf83acaf2, 0x00010101, 0xf030c0f0, 0x282a0a22,\n\t0x5c1e4e52, 0xa82989a1, 0x54164652, 0x40034343,\n\t0x84058581, 0x14140410, 0x88098981, 0x981b8b93,\n\t0xb03080b0, 0xe425c5e1, 0x48084840, 0x78394971,\n\t0x94178793, 0xfc3cccf0, 0x1c1e0e12, 0x80028282,\n\t0x20210121, 0x8c0c8c80, 0x181b0b13, 0x5c1f4f53,\n\t0x74374773, 0x54144450, 0xb03282b2, 0x1c1d0d11,\n\t0x24250521, 0x4c0f4f43, 0x00000000, 0x44064642,\n\t0xec2dcde1, 0x58184850, 0x50124252, 0xe82bcbe3,\n\t0x7c3e4e72, 0xd81acad2, 0xc809c9c1, 0xfc3dcdf1,\n\t0x30300030, 0x94158591, 0x64254561, 0x3c3c0c30,\n\t0xb43686b2, 0xe424c4e0, 0xb83b8bb3, 0x7c3c4c70,\n\t0x0c0e0e02, 0x50104050, 0x38390931, 0x24260622,\n\t0x30320232, 0x84048480, 0x68294961, 0x90138393,\n\t0x34370733, 0xe427c7e3, 0x24240420, 0xa42484a0,\n\t0xc80bcbc3, 0x50134353, 0x080a0a02, 0x84078783,\n\t0xd819c9d1, 0x4c0c4c40, 0x80038383, 0x8c0f8f83,\n\t0xcc0ecec2, 0x383b0b33, 0x480a4a42, 0xb43787b3,\n};\n\nstatic const u32 SS2[256] = {\n\t0xa1a82989, 0x81840585, 0xd2d416c6, 0xd3d013c3,\n\t0x50541444, 0x111c1d0d, 0xa0ac2c8c, 0x21242505,\n\t0x515c1d4d, 0x43400343, 0x10181808, 0x121c1e0e,\n\t0x51501141, 0xf0fc3ccc, 0xc2c80aca, 0x63602343,\n\t0x20282808, 0x40440444, 0x20202000, 0x919c1d8d,\n\t0xe0e020c0, 0xe2e022c2, 0xc0c808c8, 0x13141707,\n\t0xa1a42585, 0x838c0f8f, 0x03000303, 0x73783b4b,\n\t0xb3b83b8b, 0x13101303, 0xd2d012c2, 0xe2ec2ece,\n\t0x70703040, 0x808c0c8c, 0x333c3f0f, 0xa0a82888,\n\t0x32303202, 0xd1dc1dcd, 0xf2f436c6, 0x70743444,\n\t0xe0ec2ccc, 0x91941585, 0x03080b0b, 0x53541747,\n\t0x505c1c4c, 0x53581b4b, 0xb1bc3d8d, 0x01000101,\n\t0x20242404, 0x101c1c0c, 0x73703343, 0x90981888,\n\t0x10101000, 0xc0cc0ccc, 0xf2f032c2, 0xd1d819c9,\n\t0x202c2c0c, 0xe3e427c7, 0x72703242, 0x83800383,\n\t0x93981b8b, 0xd1d011c1, 0x82840686, 0xc1c809c9,\n\t0x60602040, 0x50501040, 0xa3a02383, 0xe3e82bcb,\n\t0x010c0d0d, 0xb2b43686, 0x929c1e8e, 0x434c0f4f,\n\t0xb3b43787, 0x52581a4a, 0xc2c406c6, 0x70783848,\n\t0xa2a42686, 0x12101202, 0xa3ac2f8f, 0xd1d415c5,\n\t0x61602141, 0xc3c003c3, 0xb0b43484, 0x41400141,\n\t0x52501242, 0x717c3d4d, 0x818c0d8d, 0x00080808,\n\t0x131c1f0f, 0x91981989, 0x00000000, 0x11181909,\n\t0x00040404, 0x53501343, 0xf3f437c7, 0xe1e021c1,\n\t0xf1fc3dcd, 0x72743646, 0x232c2f0f, 0x23242707,\n\t0xb0b03080, 0x83880b8b, 0x020c0e0e, 0xa3a82b8b,\n\t0xa2a02282, 0x626c2e4e, 0x93901383, 0x414c0d4d,\n\t0x61682949, 0x707c3c4c, 0x01080909, 0x02080a0a,\n\t0xb3bc3f8f, 0xe3ec2fcf, 0xf3f033c3, 0xc1c405c5,\n\t0x83840787, 0x10141404, 0xf2fc3ece, 0x60642444,\n\t0xd2dc1ece, 0x222c2e0e, 0x43480b4b, 0x12181a0a,\n\t0x02040606, 0x21202101, 0x63682b4b, 0x62642646,\n\t0x02000202, 0xf1f435c5, 0x92901282, 0x82880a8a,\n\t0x000c0c0c, 0xb3b03383, 0x727c3e4e, 0xd0d010c0,\n\t0x72783a4a, 0x43440747, 0x92941686, 0xe1e425c5,\n\t0x22242606, 0x80800080, 0xa1ac2d8d, 0xd3dc1fcf,\n\t0xa1a02181, 0x30303000, 0x33343707, 0xa2ac2e8e,\n\t0x32343606, 0x11141505, 0x22202202, 0x30383808,\n\t0xf0f434c4, 0xa3a42787, 0x41440545, 0x404c0c4c,\n\t0x81800181, 0xe1e829c9, 0x80840484, 0x93941787,\n\t0x31343505, 0xc3c80bcb, 0xc2cc0ece, 0x303c3c0c,\n\t0x71703141, 0x11101101, 0xc3c407c7, 0x81880989,\n\t0x71743545, 0xf3f83bcb, 0xd2d81aca, 0xf0f838c8,\n\t0x90941484, 0x51581949, 0x82800282, 0xc0c404c4,\n\t0xf3fc3fcf, 0x41480949, 0x31383909, 0x63642747,\n\t0xc0c000c0, 0xc3cc0fcf, 0xd3d417c7, 0xb0b83888,\n\t0x030c0f0f, 0x828c0e8e, 0x42400242, 0x23202303,\n\t0x91901181, 0x606c2c4c, 0xd3d81bcb, 0xa0a42484,\n\t0x30343404, 0xf1f031c1, 0x40480848, 0xc2c002c2,\n\t0x636c2f4f, 0x313c3d0d, 0x212c2d0d, 0x40400040,\n\t0xb2bc3e8e, 0x323c3e0e, 0xb0bc3c8c, 0xc1c001c1,\n\t0xa2a82a8a, 0xb2b83a8a, 0x424c0e4e, 0x51541545,\n\t0x33383b0b, 0xd0dc1ccc, 0x60682848, 0x737c3f4f,\n\t0x909c1c8c, 0xd0d818c8, 0x42480a4a, 0x52541646,\n\t0x73743747, 0xa0a02080, 0xe1ec2dcd, 0x42440646,\n\t0xb1b43585, 0x23282b0b, 0x61642545, 0xf2f83aca,\n\t0xe3e023c3, 0xb1b83989, 0xb1b03181, 0x939c1f8f,\n\t0x525c1e4e, 0xf1f839c9, 0xe2e426c6, 0xb2b03282,\n\t0x31303101, 0xe2e82aca, 0x616c2d4d, 0x535c1f4f,\n\t0xe0e424c4, 0xf0f030c0, 0xc1cc0dcd, 0x80880888,\n\t0x12141606, 0x32383a0a, 0x50581848, 0xd0d414c4,\n\t0x62602242, 0x21282909, 0x03040707, 0x33303303,\n\t0xe0e828c8, 0x13181b0b, 0x01040505, 0x71783949,\n\t0x90901080, 0x62682a4a, 0x22282a0a, 0x92981a8a,\n};\n\nstatic const u32 SS3[256] = {\n\t0x08303838, 0xc8e0e828, 0x0d212c2d, 0x86a2a426,\n\t0xcfc3cc0f, 0xced2dc1e, 0x83b3b033, 0x88b0b838,\n\t0x8fa3ac2f, 0x40606020, 0x45515415, 0xc7c3c407,\n\t0x44404404, 0x4f636c2f, 0x4b63682b, 0x4b53581b,\n\t0xc3c3c003, 0x42626022, 0x03333033, 0x85b1b435,\n\t0x09212829, 0x80a0a020, 0xc2e2e022, 0x87a3a427,\n\t0xc3d3d013, 0x81919011, 0x01111011, 0x06020406,\n\t0x0c101c1c, 0x8cb0bc3c, 0x06323436, 0x4b43480b,\n\t0xcfe3ec2f, 0x88808808, 0x4c606c2c, 0x88a0a828,\n\t0x07131417, 0xc4c0c404, 0x06121416, 0xc4f0f434,\n\t0xc2c2c002, 0x45414405, 0xc1e1e021, 0xc6d2d416,\n\t0x0f333c3f, 0x0d313c3d, 0x8e828c0e, 0x88909818,\n\t0x08202828, 0x4e424c0e, 0xc6f2f436, 0x0e323c3e,\n\t0x85a1a425, 0xc9f1f839, 0x0d010c0d, 0xcfd3dc1f,\n\t0xc8d0d818, 0x0b23282b, 0x46626426, 0x4a72783a,\n\t0x07232427, 0x0f232c2f, 0xc1f1f031, 0x42727032,\n\t0x42424002, 0xc4d0d414, 0x41414001, 0xc0c0c000,\n\t0x43737033, 0x47636427, 0x8ca0ac2c, 0x8b83880b,\n\t0xc7f3f437, 0x8da1ac2d, 0x80808000, 0x0f131c1f,\n\t0xcac2c80a, 0x0c202c2c, 0x8aa2a82a, 0x04303434,\n\t0xc2d2d012, 0x0b03080b, 0xcee2ec2e, 0xc9e1e829,\n\t0x4d515c1d, 0x84909414, 0x08101818, 0xc8f0f838,\n\t0x47535417, 0x8ea2ac2e, 0x08000808, 0xc5c1c405,\n\t0x03131013, 0xcdc1cc0d, 0x86828406, 0x89b1b839,\n\t0xcff3fc3f, 0x4d717c3d, 0xc1c1c001, 0x01313031,\n\t0xc5f1f435, 0x8a82880a, 0x4a62682a, 0x81b1b031,\n\t0xc1d1d011, 0x00202020, 0xc7d3d417, 0x02020002,\n\t0x02222022, 0x04000404, 0x48606828, 0x41717031,\n\t0x07030407, 0xcbd3d81b, 0x8d919c1d, 0x89919819,\n\t0x41616021, 0x8eb2bc3e, 0xc6e2e426, 0x49515819,\n\t0xcdd1dc1d, 0x41515011, 0x80909010, 0xccd0dc1c,\n\t0x8a92981a, 0x83a3a023, 0x8ba3a82b, 0xc0d0d010,\n\t0x81818001, 0x0f030c0f, 0x47434407, 0x0a12181a,\n\t0xc3e3e023, 0xcce0ec2c, 0x8d818c0d, 0x8fb3bc3f,\n\t0x86929416, 0x4b73783b, 0x4c505c1c, 0x82a2a022,\n\t0x81a1a021, 0x43636023, 0x03232023, 0x4d414c0d,\n\t0xc8c0c808, 0x8e929c1e, 0x8c909c1c, 0x0a32383a,\n\t0x0c000c0c, 0x0e222c2e, 0x8ab2b83a, 0x4e626c2e,\n\t0x8f939c1f, 0x4a52581a, 0xc2f2f032, 0x82929012,\n\t0xc3f3f033, 0x49414809, 0x48707838, 0xccc0cc0c,\n\t0x05111415, 0xcbf3f83b, 0x40707030, 0x45717435,\n\t0x4f737c3f, 0x05313435, 0x00101010, 0x03030003,\n\t0x44606424, 0x4d616c2d, 0xc6c2c406, 0x44707434,\n\t0xc5d1d415, 0x84b0b434, 0xcae2e82a, 0x09010809,\n\t0x46727436, 0x09111819, 0xcef2fc3e, 0x40404000,\n\t0x02121012, 0xc0e0e020, 0x8db1bc3d, 0x05010405,\n\t0xcaf2f83a, 0x01010001, 0xc0f0f030, 0x0a22282a,\n\t0x4e525c1e, 0x89a1a829, 0x46525416, 0x43434003,\n\t0x85818405, 0x04101414, 0x89818809, 0x8b93981b,\n\t0x80b0b030, 0xc5e1e425, 0x48404808, 0x49717839,\n\t0x87939417, 0xccf0fc3c, 0x0e121c1e, 0x82828002,\n\t0x01212021, 0x8c808c0c, 0x0b13181b, 0x4f535c1f,\n\t0x47737437, 0x44505414, 0x82b2b032, 0x0d111c1d,\n\t0x05212425, 0x4f434c0f, 0x00000000, 0x46424406,\n\t0xcde1ec2d, 0x48505818, 0x42525012, 0xcbe3e82b,\n\t0x4e727c3e, 0xcad2d81a, 0xc9c1c809, 0xcdf1fc3d,\n\t0x00303030, 0x85919415, 0x45616425, 0x0c303c3c,\n\t0x86b2b436, 0xc4e0e424, 0x8bb3b83b, 0x4c707c3c,\n\t0x0e020c0e, 0x40505010, 0x09313839, 0x06222426,\n\t0x02323032, 0x84808404, 0x49616829, 0x83939013,\n\t0x07333437, 0xc7e3e427, 0x04202424, 0x84a0a424,\n\t0xcbc3c80b, 0x43535013, 0x0a02080a, 0x87838407,\n\t0xc9d1d819, 0x4c404c0c, 0x83838003, 0x8f838c0f,\n\t0xcec2cc0e, 0x0b33383b, 0x4a42480a, 0x87b3b437,\n};\n\nstatic const u32 KC[SEED_NUM_KCONSTANTS] = {\n\t0x9e3779b9, 0x3c6ef373, 0x78dde6e6, 0xf1bbcdcc,\n\t0xe3779b99, 0xc6ef3733, 0x8dde6e67, 0x1bbcdccf,\n\t0x3779b99e, 0x6ef3733c, 0xdde6e678, 0xbbcdccf1,\n\t0x779b99e3, 0xef3733c6, 0xde6e678d, 0xbcdccf1b,\n};\n\n#define OP(X1, X2, X3, X4, rbase)\t\t\t\\\n\tt0 = X3 ^ ks[rbase];\t\t\t\t\\\n\tt1 = X4 ^ ks[rbase+1];\t\t\t\t\\\n\tt1 ^= t0;\t\t\t\t\t\\\n\tt1 = SS0[byte(t1, 0)] ^ SS1[byte(t1, 1)] ^\t\\\n\t\tSS2[byte(t1, 2)] ^ SS3[byte(t1, 3)];\t\\\n\tt0 += t1;\t\t\t\t\t\\\n\tt0 = SS0[byte(t0, 0)] ^ SS1[byte(t0, 1)] ^\t\\\n\t\tSS2[byte(t0, 2)] ^ SS3[byte(t0, 3)];\t\\\n\tt1 += t0;\t\t\t\t\t\\\n\tt1 = SS0[byte(t1, 0)] ^ SS1[byte(t1, 1)] ^\t\\\n\t\tSS2[byte(t1, 2)] ^ SS3[byte(t1, 3)];\t\\\n\tt0 += t1;\t\t\t\t\t\\\n\tX1 ^= t0;\t\t\t\t\t\\\n\tX2 ^= t1;\n\nstatic int seed_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t        unsigned int key_len)\n{\n\tstruct seed_ctx *ctx = crypto_tfm_ctx(tfm);\n\tu32 *keyout = ctx->keysched;\n\tconst __be32 *key = (const __be32 *)in_key;\n\tu32 i, t0, t1, x1, x2, x3, x4;\n\n\tx1 = be32_to_cpu(key[0]);\n\tx2 = be32_to_cpu(key[1]);\n\tx3 = be32_to_cpu(key[2]);\n\tx4 = be32_to_cpu(key[3]);\n\n\tfor (i = 0; i < SEED_NUM_KCONSTANTS; i++) {\n\t\tt0 = x1 + x3 - KC[i];\n\t\tt1 = x2 + KC[i] - x4;\n\t\t*(keyout++) = SS0[byte(t0, 0)] ^ SS1[byte(t0, 1)] ^\n\t\t\t\tSS2[byte(t0, 2)] ^ SS3[byte(t0, 3)];\n\t\t*(keyout++) = SS0[byte(t1, 0)] ^ SS1[byte(t1, 1)] ^\n\t\t\t\tSS2[byte(t1, 2)] ^ SS3[byte(t1, 3)];\n\n\t\tif (i % 2 == 0) {\n\t\t\tt0 = x1;\n\t\t\tx1 = (x1 >> 8) ^ (x2 << 24);\n\t\t\tx2 = (x2 >> 8) ^ (t0 << 24);\n\t\t} else {\n\t\t\tt0 = x3;\n\t\t\tx3 = (x3 << 8) ^ (x4 >> 24);\n\t\t\tx4 = (x4 << 8) ^ (t0 >> 24);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/* encrypt a block of text */\n\nstatic void seed_encrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tconst struct seed_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __be32 *src = (const __be32 *)in;\n\t__be32 *dst = (__be32 *)out;\n\tu32 x1, x2, x3, x4, t0, t1;\n\tconst u32 *ks = ctx->keysched;\n\n\tx1 = be32_to_cpu(src[0]);\n\tx2 = be32_to_cpu(src[1]);\n\tx3 = be32_to_cpu(src[2]);\n\tx4 = be32_to_cpu(src[3]);\n\n\tOP(x1, x2, x3, x4, 0);\n\tOP(x3, x4, x1, x2, 2);\n\tOP(x1, x2, x3, x4, 4);\n\tOP(x3, x4, x1, x2, 6);\n\tOP(x1, x2, x3, x4, 8);\n\tOP(x3, x4, x1, x2, 10);\n\tOP(x1, x2, x3, x4, 12);\n\tOP(x3, x4, x1, x2, 14);\n\tOP(x1, x2, x3, x4, 16);\n\tOP(x3, x4, x1, x2, 18);\n\tOP(x1, x2, x3, x4, 20);\n\tOP(x3, x4, x1, x2, 22);\n\tOP(x1, x2, x3, x4, 24);\n\tOP(x3, x4, x1, x2, 26);\n\tOP(x1, x2, x3, x4, 28);\n\tOP(x3, x4, x1, x2, 30);\n\n\tdst[0] = cpu_to_be32(x3);\n\tdst[1] = cpu_to_be32(x4);\n\tdst[2] = cpu_to_be32(x1);\n\tdst[3] = cpu_to_be32(x2);\n}\n\n/* decrypt a block of text */\n\nstatic void seed_decrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tconst struct seed_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __be32 *src = (const __be32 *)in;\n\t__be32 *dst = (__be32 *)out;\n\tu32 x1, x2, x3, x4, t0, t1;\n\tconst u32 *ks = ctx->keysched;\n\n\tx1 = be32_to_cpu(src[0]);\n\tx2 = be32_to_cpu(src[1]);\n\tx3 = be32_to_cpu(src[2]);\n\tx4 = be32_to_cpu(src[3]);\n\n\tOP(x1, x2, x3, x4, 30);\n\tOP(x3, x4, x1, x2, 28);\n\tOP(x1, x2, x3, x4, 26);\n\tOP(x3, x4, x1, x2, 24);\n\tOP(x1, x2, x3, x4, 22);\n\tOP(x3, x4, x1, x2, 20);\n\tOP(x1, x2, x3, x4, 18);\n\tOP(x3, x4, x1, x2, 16);\n\tOP(x1, x2, x3, x4, 14);\n\tOP(x3, x4, x1, x2, 12);\n\tOP(x1, x2, x3, x4, 10);\n\tOP(x3, x4, x1, x2, 8);\n\tOP(x1, x2, x3, x4, 6);\n\tOP(x3, x4, x1, x2, 4);\n\tOP(x1, x2, x3, x4, 2);\n\tOP(x3, x4, x1, x2, 0);\n\n\tdst[0] = cpu_to_be32(x3);\n\tdst[1] = cpu_to_be32(x4);\n\tdst[2] = cpu_to_be32(x1);\n\tdst[3] = cpu_to_be32(x2);\n}\n\n\nstatic struct crypto_alg seed_alg = {\n\t.cra_name\t\t=\t\"seed\",\n\t.cra_driver_name\t=\t\"seed-generic\",\n\t.cra_priority\t\t=\t100,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tSEED_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct seed_ctx),\n\t.cra_alignmask\t\t=\t3,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.cipher = {\n\t\t\t.cia_min_keysize\t=\tSEED_KEY_SIZE,\n\t\t\t.cia_max_keysize\t=\tSEED_KEY_SIZE,\n\t\t\t.cia_setkey\t\t=\tseed_set_key,\n\t\t\t.cia_encrypt\t\t=\tseed_encrypt,\n\t\t\t.cia_decrypt\t\t=\tseed_decrypt\n\t\t}\n\t}\n};\n\nstatic int __init seed_init(void)\n{\n\treturn crypto_register_alg(&seed_alg);\n}\n\nstatic void __exit seed_fini(void)\n{\n\tcrypto_unregister_alg(&seed_alg);\n}\n\nmodule_init(seed_init);\nmodule_exit(seed_fini);\n\nMODULE_DESCRIPTION(\"SEED Cipher Algorithm\");\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Hye-Shik Chang <perky@FreeBSD.org>, Kim Hyun <hkim@kisa.or.kr>\");\nMODULE_ALIAS_CRYPTO(\"seed\");\n", "/*\n * Cryptographic API.\n *\n * Serpent Cipher Algorithm.\n *\n * Copyright (C) 2002 Dag Arne Osvik <osvik@ii.uib.no>\n *               2003 Herbert Valerio Riedel <hvr@gnu.org>\n *\n * Added tnepres support:\n *\t\tRuben Jesus Garcia Hernandez <ruben@ugr.es>, 18.10.2004\n *              Based on code by hvr\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n */\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <asm/byteorder.h>\n#include <linux/crypto.h>\n#include <linux/types.h>\n#include <crypto/serpent.h>\n\n/* Key is padded to the maximum of 256 bits before round key generation.\n * Any key length <= 256 bits (32 bytes) is allowed by the algorithm.\n */\n\n#define PHI 0x9e3779b9UL\n\n#define keyiter(a, b, c, d, i, j) \\\n\t({ b ^= d; b ^= c; b ^= a; b ^= PHI ^ i; b = rol32(b, 11); k[j] = b; })\n\n#define loadkeys(x0, x1, x2, x3, i) \\\n\t({ x0 = k[i]; x1 = k[i+1]; x2 = k[i+2]; x3 = k[i+3]; })\n\n#define storekeys(x0, x1, x2, x3, i) \\\n\t({ k[i] = x0; k[i+1] = x1; k[i+2] = x2; k[i+3] = x3; })\n\n#define store_and_load_keys(x0, x1, x2, x3, s, l) \\\n\t({ storekeys(x0, x1, x2, x3, s); loadkeys(x0, x1, x2, x3, l); })\n\n#define K(x0, x1, x2, x3, i) ({\t\t\t\t\\\n\tx3 ^= k[4*(i)+3];        x2 ^= k[4*(i)+2];\t\\\n\tx1 ^= k[4*(i)+1];        x0 ^= k[4*(i)+0];\t\\\n\t})\n\n#define LK(x0, x1, x2, x3, x4, i) ({\t\t\t\t\t   \\\n\t\t\t\t\t\t\tx0 = rol32(x0, 13);\\\n\tx2 = rol32(x2, 3);\tx1 ^= x0;\t\tx4  = x0 << 3;\t   \\\n\tx3 ^= x2;\t\tx1 ^= x2;\t\t\t\t   \\\n\tx1 = rol32(x1, 1);\tx3 ^= x4;\t\t\t\t   \\\n\tx3 = rol32(x3, 7);\tx4  = x1;\t\t\t\t   \\\n\tx0 ^= x1;\t\tx4 <<= 7;\t\tx2 ^= x3;\t   \\\n\tx0 ^= x3;\t\tx2 ^= x4;\t\tx3 ^= k[4*i+3];\t   \\\n\tx1 ^= k[4*i+1];\t\tx0 = rol32(x0, 5);\tx2 = rol32(x2, 22);\\\n\tx0 ^= k[4*i+0];\t\tx2 ^= k[4*i+2];\t\t\t\t   \\\n\t})\n\n#define KL(x0, x1, x2, x3, x4, i) ({\t\t\t\t\t   \\\n\tx0 ^= k[4*i+0];\t\tx1 ^= k[4*i+1];\t\tx2 ^= k[4*i+2];\t   \\\n\tx3 ^= k[4*i+3];\t\tx0 = ror32(x0, 5);\tx2 = ror32(x2, 22);\\\n\tx4 =  x1;\t\tx2 ^= x3;\t\tx0 ^= x3;\t   \\\n\tx4 <<= 7;\t\tx0 ^= x1;\t\tx1 = ror32(x1, 1); \\\n\tx2 ^= x4;\t\tx3 = ror32(x3, 7);\tx4 = x0 << 3;\t   \\\n\tx1 ^= x0;\t\tx3 ^= x4;\t\tx0 = ror32(x0, 13);\\\n\tx1 ^= x2;\t\tx3 ^= x2;\t\tx2 = ror32(x2, 3); \\\n\t})\n\n#define S0(x0, x1, x2, x3, x4) ({\t\t\t\\\n\t\t\t\t\tx4  = x3;\t\\\n\tx3 |= x0;\tx0 ^= x4;\tx4 ^= x2;\t\\\n\tx4 = ~x4;\tx3 ^= x1;\tx1 &= x0;\t\\\n\tx1 ^= x4;\tx2 ^= x0;\tx0 ^= x3;\t\\\n\tx4 |= x0;\tx0 ^= x2;\tx2 &= x1;\t\\\n\tx3 ^= x2;\tx1 = ~x1;\tx2 ^= x4;\t\\\n\tx1 ^= x2;\t\t\t\t\t\\\n\t})\n\n#define S1(x0, x1, x2, x3, x4) ({\t\t\t\\\n\t\t\t\t\tx4  = x1;\t\\\n\tx1 ^= x0;\tx0 ^= x3;\tx3 = ~x3;\t\\\n\tx4 &= x1;\tx0 |= x1;\tx3 ^= x2;\t\\\n\tx0 ^= x3;\tx1 ^= x3;\tx3 ^= x4;\t\\\n\tx1 |= x4;\tx4 ^= x2;\tx2 &= x0;\t\\\n\tx2 ^= x1;\tx1 |= x0;\tx0 = ~x0;\t\\\n\tx0 ^= x2;\tx4 ^= x1;\t\t\t\\\n\t})\n\n#define S2(x0, x1, x2, x3, x4) ({\t\t\t\\\n\t\t\t\t\tx3 = ~x3;\t\\\n\tx1 ^= x0;\tx4  = x0;\tx0 &= x2;\t\\\n\tx0 ^= x3;\tx3 |= x4;\tx2 ^= x1;\t\\\n\tx3 ^= x1;\tx1 &= x0;\tx0 ^= x2;\t\\\n\tx2 &= x3;\tx3 |= x1;\tx0 = ~x0;\t\\\n\tx3 ^= x0;\tx4 ^= x0;\tx0 ^= x2;\t\\\n\tx1 |= x2;\t\t\t\t\t\\\n\t})\n\n#define S3(x0, x1, x2, x3, x4) ({\t\t\t\\\n\t\t\t\t\tx4  = x1;\t\\\n\tx1 ^= x3;\tx3 |= x0;\tx4 &= x0;\t\\\n\tx0 ^= x2;\tx2 ^= x1;\tx1 &= x3;\t\\\n\tx2 ^= x3;\tx0 |= x4;\tx4 ^= x3;\t\\\n\tx1 ^= x0;\tx0 &= x3;\tx3 &= x4;\t\\\n\tx3 ^= x2;\tx4 |= x1;\tx2 &= x1;\t\\\n\tx4 ^= x3;\tx0 ^= x3;\tx3 ^= x2;\t\\\n\t})\n\n#define S4(x0, x1, x2, x3, x4) ({\t\t\t\\\n\t\t\t\t\tx4  = x3;\t\\\n\tx3 &= x0;\tx0 ^= x4;\t\t\t\\\n\tx3 ^= x2;\tx2 |= x4;\tx0 ^= x1;\t\\\n\tx4 ^= x3;\tx2 |= x0;\t\t\t\\\n\tx2 ^= x1;\tx1 &= x0;\t\t\t\\\n\tx1 ^= x4;\tx4 &= x2;\tx2 ^= x3;\t\\\n\tx4 ^= x0;\tx3 |= x1;\tx1 = ~x1;\t\\\n\tx3 ^= x0;\t\t\t\t\t\\\n\t})\n\n#define S5(x0, x1, x2, x3, x4) ({\t\t\t\\\n\tx4  = x1;\tx1 |= x0;\t\t\t\\\n\tx2 ^= x1;\tx3 = ~x3;\tx4 ^= x0;\t\\\n\tx0 ^= x2;\tx1 &= x4;\tx4 |= x3;\t\\\n\tx4 ^= x0;\tx0 &= x3;\tx1 ^= x3;\t\\\n\tx3 ^= x2;\tx0 ^= x1;\tx2 &= x4;\t\\\n\tx1 ^= x2;\tx2 &= x0;\t\t\t\\\n\tx3 ^= x2;\t\t\t\t\t\\\n\t})\n\n#define S6(x0, x1, x2, x3, x4) ({\t\t\t\\\n\t\t\t\t\tx4  = x1;\t\\\n\tx3 ^= x0;\tx1 ^= x2;\tx2 ^= x0;\t\\\n\tx0 &= x3;\tx1 |= x3;\tx4 = ~x4;\t\\\n\tx0 ^= x1;\tx1 ^= x2;\t\t\t\\\n\tx3 ^= x4;\tx4 ^= x0;\tx2 &= x0;\t\\\n\tx4 ^= x1;\tx2 ^= x3;\tx3 &= x1;\t\\\n\tx3 ^= x0;\tx1 ^= x2;\t\t\t\\\n\t})\n\n#define S7(x0, x1, x2, x3, x4) ({\t\t\t\\\n\t\t\t\t\tx1 = ~x1;\t\\\n\tx4  = x1;\tx0 = ~x0;\tx1 &= x2;\t\\\n\tx1 ^= x3;\tx3 |= x4;\tx4 ^= x2;\t\\\n\tx2 ^= x3;\tx3 ^= x0;\tx0 |= x1;\t\\\n\tx2 &= x0;\tx0 ^= x4;\tx4 ^= x3;\t\\\n\tx3 &= x0;\tx4 ^= x1;\t\t\t\\\n\tx2 ^= x4;\tx3 ^= x1;\tx4 |= x0;\t\\\n\tx4 ^= x1;\t\t\t\t\t\\\n\t})\n\n#define SI0(x0, x1, x2, x3, x4) ({\t\t\t\\\n\t\t\tx4  = x3;\tx1 ^= x0;\t\\\n\tx3 |= x1;\tx4 ^= x1;\tx0 = ~x0;\t\\\n\tx2 ^= x3;\tx3 ^= x0;\tx0 &= x1;\t\\\n\tx0 ^= x2;\tx2 &= x3;\tx3 ^= x4;\t\\\n\tx2 ^= x3;\tx1 ^= x3;\tx3 &= x0;\t\\\n\tx1 ^= x0;\tx0 ^= x2;\tx4 ^= x3;\t\\\n\t})\n\n#define SI1(x0, x1, x2, x3, x4) ({\t\t\t\\\n\tx1 ^= x3;\tx4  = x0;\t\t\t\\\n\tx0 ^= x2;\tx2 = ~x2;\tx4 |= x1;\t\\\n\tx4 ^= x3;\tx3 &= x1;\tx1 ^= x2;\t\\\n\tx2 &= x4;\tx4 ^= x1;\tx1 |= x3;\t\\\n\tx3 ^= x0;\tx2 ^= x0;\tx0 |= x4;\t\\\n\tx2 ^= x4;\tx1 ^= x0;\t\t\t\\\n\tx4 ^= x1;\t\t\t\t\t\\\n\t})\n\n#define SI2(x0, x1, x2, x3, x4) ({\t\t\t\\\n\tx2 ^= x1;\tx4  = x3;\tx3 = ~x3;\t\\\n\tx3 |= x2;\tx2 ^= x4;\tx4 ^= x0;\t\\\n\tx3 ^= x1;\tx1 |= x2;\tx2 ^= x0;\t\\\n\tx1 ^= x4;\tx4 |= x3;\tx2 ^= x3;\t\\\n\tx4 ^= x2;\tx2 &= x1;\t\t\t\\\n\tx2 ^= x3;\tx3 ^= x4;\tx4 ^= x0;\t\\\n\t})\n\n#define SI3(x0, x1, x2, x3, x4) ({\t\t\t\\\n\t\t\t\t\tx2 ^= x1;\t\\\n\tx4  = x1;\tx1 &= x2;\t\t\t\\\n\tx1 ^= x0;\tx0 |= x4;\tx4 ^= x3;\t\\\n\tx0 ^= x3;\tx3 |= x1;\tx1 ^= x2;\t\\\n\tx1 ^= x3;\tx0 ^= x2;\tx2 ^= x3;\t\\\n\tx3 &= x1;\tx1 ^= x0;\tx0 &= x2;\t\\\n\tx4 ^= x3;\tx3 ^= x0;\tx0 ^= x1;\t\\\n\t})\n\n#define SI4(x0, x1, x2, x3, x4) ({\t\t\t\\\n\tx2 ^= x3;\tx4  = x0;\tx0 &= x1;\t\\\n\tx0 ^= x2;\tx2 |= x3;\tx4 = ~x4;\t\\\n\tx1 ^= x0;\tx0 ^= x2;\tx2 &= x4;\t\\\n\tx2 ^= x0;\tx0 |= x4;\t\t\t\\\n\tx0 ^= x3;\tx3 &= x2;\t\t\t\\\n\tx4 ^= x3;\tx3 ^= x1;\tx1 &= x0;\t\\\n\tx4 ^= x1;\tx0 ^= x3;\t\t\t\\\n\t})\n\n#define SI5(x0, x1, x2, x3, x4) ({\t\t\t\\\n\t\t\tx4  = x1;\tx1 |= x2;\t\\\n\tx2 ^= x4;\tx1 ^= x3;\tx3 &= x4;\t\\\n\tx2 ^= x3;\tx3 |= x0;\tx0 = ~x0;\t\\\n\tx3 ^= x2;\tx2 |= x0;\tx4 ^= x1;\t\\\n\tx2 ^= x4;\tx4 &= x0;\tx0 ^= x1;\t\\\n\tx1 ^= x3;\tx0 &= x2;\tx2 ^= x3;\t\\\n\tx0 ^= x2;\tx2 ^= x4;\tx4 ^= x3;\t\\\n\t})\n\n#define SI6(x0, x1, x2, x3, x4) ({\t\t\t\\\n\t\t\tx0 ^= x2;\t\t\t\\\n\tx4  = x0;\tx0 &= x3;\tx2 ^= x3;\t\\\n\tx0 ^= x2;\tx3 ^= x1;\tx2 |= x4;\t\\\n\tx2 ^= x3;\tx3 &= x0;\tx0 = ~x0;\t\\\n\tx3 ^= x1;\tx1 &= x2;\tx4 ^= x0;\t\\\n\tx3 ^= x4;\tx4 ^= x2;\tx0 ^= x1;\t\\\n\tx2 ^= x0;\t\t\t\t\t\\\n\t})\n\n#define SI7(x0, x1, x2, x3, x4) ({\t\t\t\\\n\tx4  = x3;\tx3 &= x0;\tx0 ^= x2;\t\\\n\tx2 |= x4;\tx4 ^= x1;\tx0 = ~x0;\t\\\n\tx1 |= x3;\tx4 ^= x0;\tx0 &= x2;\t\\\n\tx0 ^= x1;\tx1 &= x2;\tx3 ^= x2;\t\\\n\tx4 ^= x3;\tx2 &= x3;\tx3 |= x0;\t\\\n\tx1 ^= x4;\tx3 ^= x4;\tx4 &= x0;\t\\\n\tx4 ^= x2;\t\t\t\t\t\\\n\t})\n\nint __serpent_setkey(struct serpent_ctx *ctx, const u8 *key,\n\t\t     unsigned int keylen)\n{\n\tu32 *k = ctx->expkey;\n\tu8  *k8 = (u8 *)k;\n\tu32 r0, r1, r2, r3, r4;\n\tint i;\n\n\t/* Copy key, add padding */\n\n\tfor (i = 0; i < keylen; ++i)\n\t\tk8[i] = key[i];\n\tif (i < SERPENT_MAX_KEY_SIZE)\n\t\tk8[i++] = 1;\n\twhile (i < SERPENT_MAX_KEY_SIZE)\n\t\tk8[i++] = 0;\n\n\t/* Expand key using polynomial */\n\n\tr0 = le32_to_cpu(k[3]);\n\tr1 = le32_to_cpu(k[4]);\n\tr2 = le32_to_cpu(k[5]);\n\tr3 = le32_to_cpu(k[6]);\n\tr4 = le32_to_cpu(k[7]);\n\n\tkeyiter(le32_to_cpu(k[0]), r0, r4, r2, 0, 0);\n\tkeyiter(le32_to_cpu(k[1]), r1, r0, r3, 1, 1);\n\tkeyiter(le32_to_cpu(k[2]), r2, r1, r4, 2, 2);\n\tkeyiter(le32_to_cpu(k[3]), r3, r2, r0, 3, 3);\n\tkeyiter(le32_to_cpu(k[4]), r4, r3, r1, 4, 4);\n\tkeyiter(le32_to_cpu(k[5]), r0, r4, r2, 5, 5);\n\tkeyiter(le32_to_cpu(k[6]), r1, r0, r3, 6, 6);\n\tkeyiter(le32_to_cpu(k[7]), r2, r1, r4, 7, 7);\n\n\tkeyiter(k[0], r3, r2, r0, 8, 8);\n\tkeyiter(k[1], r4, r3, r1, 9, 9);\n\tkeyiter(k[2], r0, r4, r2, 10, 10);\n\tkeyiter(k[3], r1, r0, r3, 11, 11);\n\tkeyiter(k[4], r2, r1, r4, 12, 12);\n\tkeyiter(k[5], r3, r2, r0, 13, 13);\n\tkeyiter(k[6], r4, r3, r1, 14, 14);\n\tkeyiter(k[7], r0, r4, r2, 15, 15);\n\tkeyiter(k[8], r1, r0, r3, 16, 16);\n\tkeyiter(k[9], r2, r1, r4, 17, 17);\n\tkeyiter(k[10], r3, r2, r0, 18, 18);\n\tkeyiter(k[11], r4, r3, r1, 19, 19);\n\tkeyiter(k[12], r0, r4, r2, 20, 20);\n\tkeyiter(k[13], r1, r0, r3, 21, 21);\n\tkeyiter(k[14], r2, r1, r4, 22, 22);\n\tkeyiter(k[15], r3, r2, r0, 23, 23);\n\tkeyiter(k[16], r4, r3, r1, 24, 24);\n\tkeyiter(k[17], r0, r4, r2, 25, 25);\n\tkeyiter(k[18], r1, r0, r3, 26, 26);\n\tkeyiter(k[19], r2, r1, r4, 27, 27);\n\tkeyiter(k[20], r3, r2, r0, 28, 28);\n\tkeyiter(k[21], r4, r3, r1, 29, 29);\n\tkeyiter(k[22], r0, r4, r2, 30, 30);\n\tkeyiter(k[23], r1, r0, r3, 31, 31);\n\n\tk += 50;\n\n\tkeyiter(k[-26], r2, r1, r4, 32, -18);\n\tkeyiter(k[-25], r3, r2, r0, 33, -17);\n\tkeyiter(k[-24], r4, r3, r1, 34, -16);\n\tkeyiter(k[-23], r0, r4, r2, 35, -15);\n\tkeyiter(k[-22], r1, r0, r3, 36, -14);\n\tkeyiter(k[-21], r2, r1, r4, 37, -13);\n\tkeyiter(k[-20], r3, r2, r0, 38, -12);\n\tkeyiter(k[-19], r4, r3, r1, 39, -11);\n\tkeyiter(k[-18], r0, r4, r2, 40, -10);\n\tkeyiter(k[-17], r1, r0, r3, 41, -9);\n\tkeyiter(k[-16], r2, r1, r4, 42, -8);\n\tkeyiter(k[-15], r3, r2, r0, 43, -7);\n\tkeyiter(k[-14], r4, r3, r1, 44, -6);\n\tkeyiter(k[-13], r0, r4, r2, 45, -5);\n\tkeyiter(k[-12], r1, r0, r3, 46, -4);\n\tkeyiter(k[-11], r2, r1, r4, 47, -3);\n\tkeyiter(k[-10], r3, r2, r0, 48, -2);\n\tkeyiter(k[-9], r4, r3, r1, 49, -1);\n\tkeyiter(k[-8], r0, r4, r2, 50, 0);\n\tkeyiter(k[-7], r1, r0, r3, 51, 1);\n\tkeyiter(k[-6], r2, r1, r4, 52, 2);\n\tkeyiter(k[-5], r3, r2, r0, 53, 3);\n\tkeyiter(k[-4], r4, r3, r1, 54, 4);\n\tkeyiter(k[-3], r0, r4, r2, 55, 5);\n\tkeyiter(k[-2], r1, r0, r3, 56, 6);\n\tkeyiter(k[-1], r2, r1, r4, 57, 7);\n\tkeyiter(k[0], r3, r2, r0, 58, 8);\n\tkeyiter(k[1], r4, r3, r1, 59, 9);\n\tkeyiter(k[2], r0, r4, r2, 60, 10);\n\tkeyiter(k[3], r1, r0, r3, 61, 11);\n\tkeyiter(k[4], r2, r1, r4, 62, 12);\n\tkeyiter(k[5], r3, r2, r0, 63, 13);\n\tkeyiter(k[6], r4, r3, r1, 64, 14);\n\tkeyiter(k[7], r0, r4, r2, 65, 15);\n\tkeyiter(k[8], r1, r0, r3, 66, 16);\n\tkeyiter(k[9], r2, r1, r4, 67, 17);\n\tkeyiter(k[10], r3, r2, r0, 68, 18);\n\tkeyiter(k[11], r4, r3, r1, 69, 19);\n\tkeyiter(k[12], r0, r4, r2, 70, 20);\n\tkeyiter(k[13], r1, r0, r3, 71, 21);\n\tkeyiter(k[14], r2, r1, r4, 72, 22);\n\tkeyiter(k[15], r3, r2, r0, 73, 23);\n\tkeyiter(k[16], r4, r3, r1, 74, 24);\n\tkeyiter(k[17], r0, r4, r2, 75, 25);\n\tkeyiter(k[18], r1, r0, r3, 76, 26);\n\tkeyiter(k[19], r2, r1, r4, 77, 27);\n\tkeyiter(k[20], r3, r2, r0, 78, 28);\n\tkeyiter(k[21], r4, r3, r1, 79, 29);\n\tkeyiter(k[22], r0, r4, r2, 80, 30);\n\tkeyiter(k[23], r1, r0, r3, 81, 31);\n\n\tk += 50;\n\n\tkeyiter(k[-26], r2, r1, r4, 82, -18);\n\tkeyiter(k[-25], r3, r2, r0, 83, -17);\n\tkeyiter(k[-24], r4, r3, r1, 84, -16);\n\tkeyiter(k[-23], r0, r4, r2, 85, -15);\n\tkeyiter(k[-22], r1, r0, r3, 86, -14);\n\tkeyiter(k[-21], r2, r1, r4, 87, -13);\n\tkeyiter(k[-20], r3, r2, r0, 88, -12);\n\tkeyiter(k[-19], r4, r3, r1, 89, -11);\n\tkeyiter(k[-18], r0, r4, r2, 90, -10);\n\tkeyiter(k[-17], r1, r0, r3, 91, -9);\n\tkeyiter(k[-16], r2, r1, r4, 92, -8);\n\tkeyiter(k[-15], r3, r2, r0, 93, -7);\n\tkeyiter(k[-14], r4, r3, r1, 94, -6);\n\tkeyiter(k[-13], r0, r4, r2, 95, -5);\n\tkeyiter(k[-12], r1, r0, r3, 96, -4);\n\tkeyiter(k[-11], r2, r1, r4, 97, -3);\n\tkeyiter(k[-10], r3, r2, r0, 98, -2);\n\tkeyiter(k[-9], r4, r3, r1, 99, -1);\n\tkeyiter(k[-8], r0, r4, r2, 100, 0);\n\tkeyiter(k[-7], r1, r0, r3, 101, 1);\n\tkeyiter(k[-6], r2, r1, r4, 102, 2);\n\tkeyiter(k[-5], r3, r2, r0, 103, 3);\n\tkeyiter(k[-4], r4, r3, r1, 104, 4);\n\tkeyiter(k[-3], r0, r4, r2, 105, 5);\n\tkeyiter(k[-2], r1, r0, r3, 106, 6);\n\tkeyiter(k[-1], r2, r1, r4, 107, 7);\n\tkeyiter(k[0], r3, r2, r0, 108, 8);\n\tkeyiter(k[1], r4, r3, r1, 109, 9);\n\tkeyiter(k[2], r0, r4, r2, 110, 10);\n\tkeyiter(k[3], r1, r0, r3, 111, 11);\n\tkeyiter(k[4], r2, r1, r4, 112, 12);\n\tkeyiter(k[5], r3, r2, r0, 113, 13);\n\tkeyiter(k[6], r4, r3, r1, 114, 14);\n\tkeyiter(k[7], r0, r4, r2, 115, 15);\n\tkeyiter(k[8], r1, r0, r3, 116, 16);\n\tkeyiter(k[9], r2, r1, r4, 117, 17);\n\tkeyiter(k[10], r3, r2, r0, 118, 18);\n\tkeyiter(k[11], r4, r3, r1, 119, 19);\n\tkeyiter(k[12], r0, r4, r2, 120, 20);\n\tkeyiter(k[13], r1, r0, r3, 121, 21);\n\tkeyiter(k[14], r2, r1, r4, 122, 22);\n\tkeyiter(k[15], r3, r2, r0, 123, 23);\n\tkeyiter(k[16], r4, r3, r1, 124, 24);\n\tkeyiter(k[17], r0, r4, r2, 125, 25);\n\tkeyiter(k[18], r1, r0, r3, 126, 26);\n\tkeyiter(k[19], r2, r1, r4, 127, 27);\n\tkeyiter(k[20], r3, r2, r0, 128, 28);\n\tkeyiter(k[21], r4, r3, r1, 129, 29);\n\tkeyiter(k[22], r0, r4, r2, 130, 30);\n\tkeyiter(k[23], r1, r0, r3, 131, 31);\n\n\t/* Apply S-boxes */\n\n\tS3(r3, r4, r0, r1, r2); store_and_load_keys(r1, r2, r4, r3, 28, 24);\n\tS4(r1, r2, r4, r3, r0); store_and_load_keys(r2, r4, r3, r0, 24, 20);\n\tS5(r2, r4, r3, r0, r1); store_and_load_keys(r1, r2, r4, r0, 20, 16);\n\tS6(r1, r2, r4, r0, r3); store_and_load_keys(r4, r3, r2, r0, 16, 12);\n\tS7(r4, r3, r2, r0, r1); store_and_load_keys(r1, r2, r0, r4, 12, 8);\n\tS0(r1, r2, r0, r4, r3); store_and_load_keys(r0, r2, r4, r1, 8, 4);\n\tS1(r0, r2, r4, r1, r3); store_and_load_keys(r3, r4, r1, r0, 4, 0);\n\tS2(r3, r4, r1, r0, r2); store_and_load_keys(r2, r4, r3, r0, 0, -4);\n\tS3(r2, r4, r3, r0, r1); store_and_load_keys(r0, r1, r4, r2, -4, -8);\n\tS4(r0, r1, r4, r2, r3); store_and_load_keys(r1, r4, r2, r3, -8, -12);\n\tS5(r1, r4, r2, r3, r0); store_and_load_keys(r0, r1, r4, r3, -12, -16);\n\tS6(r0, r1, r4, r3, r2); store_and_load_keys(r4, r2, r1, r3, -16, -20);\n\tS7(r4, r2, r1, r3, r0); store_and_load_keys(r0, r1, r3, r4, -20, -24);\n\tS0(r0, r1, r3, r4, r2); store_and_load_keys(r3, r1, r4, r0, -24, -28);\n\tk -= 50;\n\tS1(r3, r1, r4, r0, r2); store_and_load_keys(r2, r4, r0, r3, 22, 18);\n\tS2(r2, r4, r0, r3, r1); store_and_load_keys(r1, r4, r2, r3, 18, 14);\n\tS3(r1, r4, r2, r3, r0); store_and_load_keys(r3, r0, r4, r1, 14, 10);\n\tS4(r3, r0, r4, r1, r2); store_and_load_keys(r0, r4, r1, r2, 10, 6);\n\tS5(r0, r4, r1, r2, r3); store_and_load_keys(r3, r0, r4, r2, 6, 2);\n\tS6(r3, r0, r4, r2, r1); store_and_load_keys(r4, r1, r0, r2, 2, -2);\n\tS7(r4, r1, r0, r2, r3); store_and_load_keys(r3, r0, r2, r4, -2, -6);\n\tS0(r3, r0, r2, r4, r1); store_and_load_keys(r2, r0, r4, r3, -6, -10);\n\tS1(r2, r0, r4, r3, r1); store_and_load_keys(r1, r4, r3, r2, -10, -14);\n\tS2(r1, r4, r3, r2, r0); store_and_load_keys(r0, r4, r1, r2, -14, -18);\n\tS3(r0, r4, r1, r2, r3); store_and_load_keys(r2, r3, r4, r0, -18, -22);\n\tk -= 50;\n\tS4(r2, r3, r4, r0, r1); store_and_load_keys(r3, r4, r0, r1, 28, 24);\n\tS5(r3, r4, r0, r1, r2); store_and_load_keys(r2, r3, r4, r1, 24, 20);\n\tS6(r2, r3, r4, r1, r0); store_and_load_keys(r4, r0, r3, r1, 20, 16);\n\tS7(r4, r0, r3, r1, r2); store_and_load_keys(r2, r3, r1, r4, 16, 12);\n\tS0(r2, r3, r1, r4, r0); store_and_load_keys(r1, r3, r4, r2, 12, 8);\n\tS1(r1, r3, r4, r2, r0); store_and_load_keys(r0, r4, r2, r1, 8, 4);\n\tS2(r0, r4, r2, r1, r3); store_and_load_keys(r3, r4, r0, r1, 4, 0);\n\tS3(r3, r4, r0, r1, r2); storekeys(r1, r2, r4, r3, 0);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(__serpent_setkey);\n\nint serpent_setkey(struct crypto_tfm *tfm, const u8 *key, unsigned int keylen)\n{\n\treturn __serpent_setkey(crypto_tfm_ctx(tfm), key, keylen);\n}\nEXPORT_SYMBOL_GPL(serpent_setkey);\n\nvoid __serpent_encrypt(struct serpent_ctx *ctx, u8 *dst, const u8 *src)\n{\n\tconst u32 *k = ctx->expkey;\n\tconst __le32 *s = (const __le32 *)src;\n\t__le32\t*d = (__le32 *)dst;\n\tu32\tr0, r1, r2, r3, r4;\n\n/*\n * Note: The conversions between u8* and u32* might cause trouble\n * on architectures with stricter alignment rules than x86\n */\n\n\tr0 = le32_to_cpu(s[0]);\n\tr1 = le32_to_cpu(s[1]);\n\tr2 = le32_to_cpu(s[2]);\n\tr3 = le32_to_cpu(s[3]);\n\n\t\t\t\t\tK(r0, r1, r2, r3, 0);\n\tS0(r0, r1, r2, r3, r4);\t\tLK(r2, r1, r3, r0, r4, 1);\n\tS1(r2, r1, r3, r0, r4);\t\tLK(r4, r3, r0, r2, r1, 2);\n\tS2(r4, r3, r0, r2, r1);\t\tLK(r1, r3, r4, r2, r0, 3);\n\tS3(r1, r3, r4, r2, r0);\t\tLK(r2, r0, r3, r1, r4, 4);\n\tS4(r2, r0, r3, r1, r4);\t\tLK(r0, r3, r1, r4, r2, 5);\n\tS5(r0, r3, r1, r4, r2);\t\tLK(r2, r0, r3, r4, r1, 6);\n\tS6(r2, r0, r3, r4, r1);\t\tLK(r3, r1, r0, r4, r2, 7);\n\tS7(r3, r1, r0, r4, r2);\t\tLK(r2, r0, r4, r3, r1, 8);\n\tS0(r2, r0, r4, r3, r1);\t\tLK(r4, r0, r3, r2, r1, 9);\n\tS1(r4, r0, r3, r2, r1);\t\tLK(r1, r3, r2, r4, r0, 10);\n\tS2(r1, r3, r2, r4, r0);\t\tLK(r0, r3, r1, r4, r2, 11);\n\tS3(r0, r3, r1, r4, r2);\t\tLK(r4, r2, r3, r0, r1, 12);\n\tS4(r4, r2, r3, r0, r1);\t\tLK(r2, r3, r0, r1, r4, 13);\n\tS5(r2, r3, r0, r1, r4);\t\tLK(r4, r2, r3, r1, r0, 14);\n\tS6(r4, r2, r3, r1, r0);\t\tLK(r3, r0, r2, r1, r4, 15);\n\tS7(r3, r0, r2, r1, r4);\t\tLK(r4, r2, r1, r3, r0, 16);\n\tS0(r4, r2, r1, r3, r0);\t\tLK(r1, r2, r3, r4, r0, 17);\n\tS1(r1, r2, r3, r4, r0);\t\tLK(r0, r3, r4, r1, r2, 18);\n\tS2(r0, r3, r4, r1, r2);\t\tLK(r2, r3, r0, r1, r4, 19);\n\tS3(r2, r3, r0, r1, r4);\t\tLK(r1, r4, r3, r2, r0, 20);\n\tS4(r1, r4, r3, r2, r0);\t\tLK(r4, r3, r2, r0, r1, 21);\n\tS5(r4, r3, r2, r0, r1);\t\tLK(r1, r4, r3, r0, r2, 22);\n\tS6(r1, r4, r3, r0, r2);\t\tLK(r3, r2, r4, r0, r1, 23);\n\tS7(r3, r2, r4, r0, r1);\t\tLK(r1, r4, r0, r3, r2, 24);\n\tS0(r1, r4, r0, r3, r2);\t\tLK(r0, r4, r3, r1, r2, 25);\n\tS1(r0, r4, r3, r1, r2);\t\tLK(r2, r3, r1, r0, r4, 26);\n\tS2(r2, r3, r1, r0, r4);\t\tLK(r4, r3, r2, r0, r1, 27);\n\tS3(r4, r3, r2, r0, r1);\t\tLK(r0, r1, r3, r4, r2, 28);\n\tS4(r0, r1, r3, r4, r2);\t\tLK(r1, r3, r4, r2, r0, 29);\n\tS5(r1, r3, r4, r2, r0);\t\tLK(r0, r1, r3, r2, r4, 30);\n\tS6(r0, r1, r3, r2, r4);\t\tLK(r3, r4, r1, r2, r0, 31);\n\tS7(r3, r4, r1, r2, r0);\t\tK(r0, r1, r2, r3, 32);\n\n\td[0] = cpu_to_le32(r0);\n\td[1] = cpu_to_le32(r1);\n\td[2] = cpu_to_le32(r2);\n\td[3] = cpu_to_le32(r3);\n}\nEXPORT_SYMBOL_GPL(__serpent_encrypt);\n\nstatic void serpent_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct serpent_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\t__serpent_encrypt(ctx, dst, src);\n}\n\nvoid __serpent_decrypt(struct serpent_ctx *ctx, u8 *dst, const u8 *src)\n{\n\tconst u32 *k = ctx->expkey;\n\tconst __le32 *s = (const __le32 *)src;\n\t__le32\t*d = (__le32 *)dst;\n\tu32\tr0, r1, r2, r3, r4;\n\n\tr0 = le32_to_cpu(s[0]);\n\tr1 = le32_to_cpu(s[1]);\n\tr2 = le32_to_cpu(s[2]);\n\tr3 = le32_to_cpu(s[3]);\n\n\t\t\t\t\tK(r0, r1, r2, r3, 32);\n\tSI7(r0, r1, r2, r3, r4);\tKL(r1, r3, r0, r4, r2, 31);\n\tSI6(r1, r3, r0, r4, r2);\tKL(r0, r2, r4, r1, r3, 30);\n\tSI5(r0, r2, r4, r1, r3);\tKL(r2, r3, r0, r4, r1, 29);\n\tSI4(r2, r3, r0, r4, r1);\tKL(r2, r0, r1, r4, r3, 28);\n\tSI3(r2, r0, r1, r4, r3);\tKL(r1, r2, r3, r4, r0, 27);\n\tSI2(r1, r2, r3, r4, r0);\tKL(r2, r0, r4, r3, r1, 26);\n\tSI1(r2, r0, r4, r3, r1);\tKL(r1, r0, r4, r3, r2, 25);\n\tSI0(r1, r0, r4, r3, r2);\tKL(r4, r2, r0, r1, r3, 24);\n\tSI7(r4, r2, r0, r1, r3);\tKL(r2, r1, r4, r3, r0, 23);\n\tSI6(r2, r1, r4, r3, r0);\tKL(r4, r0, r3, r2, r1, 22);\n\tSI5(r4, r0, r3, r2, r1);\tKL(r0, r1, r4, r3, r2, 21);\n\tSI4(r0, r1, r4, r3, r2);\tKL(r0, r4, r2, r3, r1, 20);\n\tSI3(r0, r4, r2, r3, r1);\tKL(r2, r0, r1, r3, r4, 19);\n\tSI2(r2, r0, r1, r3, r4);\tKL(r0, r4, r3, r1, r2, 18);\n\tSI1(r0, r4, r3, r1, r2);\tKL(r2, r4, r3, r1, r0, 17);\n\tSI0(r2, r4, r3, r1, r0);\tKL(r3, r0, r4, r2, r1, 16);\n\tSI7(r3, r0, r4, r2, r1);\tKL(r0, r2, r3, r1, r4, 15);\n\tSI6(r0, r2, r3, r1, r4);\tKL(r3, r4, r1, r0, r2, 14);\n\tSI5(r3, r4, r1, r0, r2);\tKL(r4, r2, r3, r1, r0, 13);\n\tSI4(r4, r2, r3, r1, r0);\tKL(r4, r3, r0, r1, r2, 12);\n\tSI3(r4, r3, r0, r1, r2);\tKL(r0, r4, r2, r1, r3, 11);\n\tSI2(r0, r4, r2, r1, r3);\tKL(r4, r3, r1, r2, r0, 10);\n\tSI1(r4, r3, r1, r2, r0);\tKL(r0, r3, r1, r2, r4, 9);\n\tSI0(r0, r3, r1, r2, r4);\tKL(r1, r4, r3, r0, r2, 8);\n\tSI7(r1, r4, r3, r0, r2);\tKL(r4, r0, r1, r2, r3, 7);\n\tSI6(r4, r0, r1, r2, r3);\tKL(r1, r3, r2, r4, r0, 6);\n\tSI5(r1, r3, r2, r4, r0);\tKL(r3, r0, r1, r2, r4, 5);\n\tSI4(r3, r0, r1, r2, r4);\tKL(r3, r1, r4, r2, r0, 4);\n\tSI3(r3, r1, r4, r2, r0);\tKL(r4, r3, r0, r2, r1, 3);\n\tSI2(r4, r3, r0, r2, r1);\tKL(r3, r1, r2, r0, r4, 2);\n\tSI1(r3, r1, r2, r0, r4);\tKL(r4, r1, r2, r0, r3, 1);\n\tSI0(r4, r1, r2, r0, r3);\tK(r2, r3, r1, r4, 0);\n\n\td[0] = cpu_to_le32(r2);\n\td[1] = cpu_to_le32(r3);\n\td[2] = cpu_to_le32(r1);\n\td[3] = cpu_to_le32(r4);\n}\nEXPORT_SYMBOL_GPL(__serpent_decrypt);\n\nstatic void serpent_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tstruct serpent_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\t__serpent_decrypt(ctx, dst, src);\n}\n\nstatic int tnepres_setkey(struct crypto_tfm *tfm, const u8 *key,\n\t\t\t  unsigned int keylen)\n{\n\tu8 rev_key[SERPENT_MAX_KEY_SIZE];\n\tint i;\n\n\tfor (i = 0; i < keylen; ++i)\n\t\trev_key[keylen - i - 1] = key[i];\n\n\treturn serpent_setkey(tfm, rev_key, keylen);\n}\n\nstatic void tnepres_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tconst u32 * const s = (const u32 * const)src;\n\tu32 * const d = (u32 * const)dst;\n\n\tu32 rs[4], rd[4];\n\n\trs[0] = swab32(s[3]);\n\trs[1] = swab32(s[2]);\n\trs[2] = swab32(s[1]);\n\trs[3] = swab32(s[0]);\n\n\tserpent_encrypt(tfm, (u8 *)rd, (u8 *)rs);\n\n\td[0] = swab32(rd[3]);\n\td[1] = swab32(rd[2]);\n\td[2] = swab32(rd[1]);\n\td[3] = swab32(rd[0]);\n}\n\nstatic void tnepres_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tconst u32 * const s = (const u32 * const)src;\n\tu32 * const d = (u32 * const)dst;\n\n\tu32 rs[4], rd[4];\n\n\trs[0] = swab32(s[3]);\n\trs[1] = swab32(s[2]);\n\trs[2] = swab32(s[1]);\n\trs[3] = swab32(s[0]);\n\n\tserpent_decrypt(tfm, (u8 *)rd, (u8 *)rs);\n\n\td[0] = swab32(rd[3]);\n\td[1] = swab32(rd[2]);\n\td[2] = swab32(rd[1]);\n\td[3] = swab32(rd[0]);\n}\n\nstatic struct crypto_alg srp_algs[2] = { {\n\t.cra_name\t\t=\t\"serpent\",\n\t.cra_driver_name\t=\t\"serpent-generic\",\n\t.cra_priority\t\t=\t100,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tSERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct serpent_ctx),\n\t.cra_alignmask\t\t=\t3,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\tSERPENT_MIN_KEY_SIZE,\n\t.cia_max_keysize\t=\tSERPENT_MAX_KEY_SIZE,\n\t.cia_setkey\t\t=\tserpent_setkey,\n\t.cia_encrypt\t\t=\tserpent_encrypt,\n\t.cia_decrypt\t\t=\tserpent_decrypt } }\n}, {\n\t.cra_name\t\t=\t\"tnepres\",\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tSERPENT_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct serpent_ctx),\n\t.cra_alignmask\t\t=\t3,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\tSERPENT_MIN_KEY_SIZE,\n\t.cia_max_keysize\t=\tSERPENT_MAX_KEY_SIZE,\n\t.cia_setkey\t\t=\ttnepres_setkey,\n\t.cia_encrypt\t\t=\ttnepres_encrypt,\n\t.cia_decrypt\t\t=\ttnepres_decrypt } }\n} };\n\nstatic int __init serpent_mod_init(void)\n{\n\treturn crypto_register_algs(srp_algs, ARRAY_SIZE(srp_algs));\n}\n\nstatic void __exit serpent_mod_fini(void)\n{\n\tcrypto_unregister_algs(srp_algs, ARRAY_SIZE(srp_algs));\n}\n\nmodule_init(serpent_mod_init);\nmodule_exit(serpent_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Serpent and tnepres (kerneli compatible serpent reversed) Cipher Algorithm\");\nMODULE_AUTHOR(\"Dag Arne Osvik <osvik@ii.uib.no>\");\nMODULE_ALIAS_CRYPTO(\"tnepres\");\nMODULE_ALIAS_CRYPTO(\"serpent\");\n", "/*\n * Cryptographic API.\n *\n * SHA1 Secure Hash Algorithm.\n *\n * Derived from cryptoapi implementation, adapted for in-place\n * scatterlist interface.\n *\n * Copyright (c) Alan Smithee.\n * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n * Copyright (c) Jean-Francois Dive <jef@linuxbe.org>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/cryptohash.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n#include <asm/byteorder.h>\n\nstatic int sha1_init(struct shash_desc *desc)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\t*sctx = (struct sha1_state){\n\t\t.state = { SHA1_H0, SHA1_H1, SHA1_H2, SHA1_H3, SHA1_H4 },\n\t};\n\n\treturn 0;\n}\n\nint crypto_sha1_update(struct shash_desc *desc, const u8 *data,\n\t\t\tunsigned int len)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial, done;\n\tconst u8 *src;\n\n\tpartial = sctx->count % SHA1_BLOCK_SIZE;\n\tsctx->count += len;\n\tdone = 0;\n\tsrc = data;\n\n\tif ((partial + len) >= SHA1_BLOCK_SIZE) {\n\t\tu32 temp[SHA_WORKSPACE_WORDS];\n\n\t\tif (partial) {\n\t\t\tdone = -partial;\n\t\t\tmemcpy(sctx->buffer + partial, data,\n\t\t\t       done + SHA1_BLOCK_SIZE);\n\t\t\tsrc = sctx->buffer;\n\t\t}\n\n\t\tdo {\n\t\t\tsha_transform(sctx->state, src, temp);\n\t\t\tdone += SHA1_BLOCK_SIZE;\n\t\t\tsrc = data + done;\n\t\t} while (done + SHA1_BLOCK_SIZE <= len);\n\n\t\tmemzero_explicit(temp, sizeof(temp));\n\t\tpartial = 0;\n\t}\n\tmemcpy(sctx->buffer + partial, src, len - done);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(crypto_sha1_update);\n\n\n/* Add padding and return the message digest. */\nstatic int sha1_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\t__be32 *dst = (__be32 *)out;\n\tu32 i, index, padlen;\n\t__be64 bits;\n\tstatic const u8 padding[64] = { 0x80, };\n\n\tbits = cpu_to_be64(sctx->count << 3);\n\n\t/* Pad out to 56 mod 64 */\n\tindex = sctx->count & 0x3f;\n\tpadlen = (index < 56) ? (56 - index) : ((64+56) - index);\n\tcrypto_sha1_update(desc, padding, padlen);\n\n\t/* Append length */\n\tcrypto_sha1_update(desc, (const u8 *)&bits, sizeof(bits));\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 5; i++)\n\t\tdst[i] = cpu_to_be32(sctx->state[i]);\n\n\t/* Wipe context */\n\tmemset(sctx, 0, sizeof *sctx);\n\n\treturn 0;\n}\n\nstatic int sha1_export(struct shash_desc *desc, void *out)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, sizeof(*sctx));\n\treturn 0;\n}\n\nstatic int sha1_import(struct shash_desc *desc, const void *in)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, sizeof(*sctx));\n\treturn 0;\n}\n\nstatic struct shash_alg alg = {\n\t.digestsize\t=\tSHA1_DIGEST_SIZE,\n\t.init\t\t=\tsha1_init,\n\t.update\t\t=\tcrypto_sha1_update,\n\t.final\t\t=\tsha1_final,\n\t.export\t\t=\tsha1_export,\n\t.import\t\t=\tsha1_import,\n\t.descsize\t=\tsizeof(struct sha1_state),\n\t.statesize\t=\tsizeof(struct sha1_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha1\",\n\t\t.cra_driver_name=\t\"sha1-generic\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA1_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic int __init sha1_generic_mod_init(void)\n{\n\treturn crypto_register_shash(&alg);\n}\n\nstatic void __exit sha1_generic_mod_fini(void)\n{\n\tcrypto_unregister_shash(&alg);\n}\n\nmodule_init(sha1_generic_mod_init);\nmodule_exit(sha1_generic_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA1 Secure Hash Algorithm\");\n\nMODULE_ALIAS_CRYPTO(\"sha1\");\n", "/*\n * Cryptographic API.\n *\n * SHA-256, as specified in\n * http://csrc.nist.gov/groups/STM/cavp/documents/shs/sha256-384-512.pdf\n *\n * SHA-256 code by Jean-Luc Cooke <jlcooke@certainkey.com>.\n *\n * Copyright (c) Jean-Luc Cooke <jlcooke@certainkey.com>\n * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>\n * SHA224 Support Copyright 2007 Intel Corporation <jonathan.lynch@intel.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option) \n * any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n#include <asm/byteorder.h>\n#include <asm/unaligned.h>\n\nstatic inline u32 Ch(u32 x, u32 y, u32 z)\n{\n\treturn z ^ (x & (y ^ z));\n}\n\nstatic inline u32 Maj(u32 x, u32 y, u32 z)\n{\n\treturn (x & y) | (z & (x | y));\n}\n\n#define e0(x)       (ror32(x, 2) ^ ror32(x,13) ^ ror32(x,22))\n#define e1(x)       (ror32(x, 6) ^ ror32(x,11) ^ ror32(x,25))\n#define s0(x)       (ror32(x, 7) ^ ror32(x,18) ^ (x >> 3))\n#define s1(x)       (ror32(x,17) ^ ror32(x,19) ^ (x >> 10))\n\nstatic inline void LOAD_OP(int I, u32 *W, const u8 *input)\n{\n\tW[I] = get_unaligned_be32((__u32 *)input + I);\n}\n\nstatic inline void BLEND_OP(int I, u32 *W)\n{\n\tW[I] = s1(W[I-2]) + W[I-7] + s0(W[I-15]) + W[I-16];\n}\n\nstatic void sha256_transform(u32 *state, const u8 *input)\n{\n\tu32 a, b, c, d, e, f, g, h, t1, t2;\n\tu32 W[64];\n\tint i;\n\n\t/* load the input */\n\tfor (i = 0; i < 16; i++)\n\t\tLOAD_OP(i, W, input);\n\n\t/* now blend */\n\tfor (i = 16; i < 64; i++)\n\t\tBLEND_OP(i, W);\n\n\t/* load the state into our registers */\n\ta=state[0];  b=state[1];  c=state[2];  d=state[3];\n\te=state[4];  f=state[5];  g=state[6];  h=state[7];\n\n\t/* now iterate */\n\tt1 = h + e1(e) + Ch(e,f,g) + 0x428a2f98 + W[ 0];\n\tt2 = e0(a) + Maj(a,b,c);    d+=t1;    h=t1+t2;\n\tt1 = g + e1(d) + Ch(d,e,f) + 0x71374491 + W[ 1];\n\tt2 = e0(h) + Maj(h,a,b);    c+=t1;    g=t1+t2;\n\tt1 = f + e1(c) + Ch(c,d,e) + 0xb5c0fbcf + W[ 2];\n\tt2 = e0(g) + Maj(g,h,a);    b+=t1;    f=t1+t2;\n\tt1 = e + e1(b) + Ch(b,c,d) + 0xe9b5dba5 + W[ 3];\n\tt2 = e0(f) + Maj(f,g,h);    a+=t1;    e=t1+t2;\n\tt1 = d + e1(a) + Ch(a,b,c) + 0x3956c25b + W[ 4];\n\tt2 = e0(e) + Maj(e,f,g);    h+=t1;    d=t1+t2;\n\tt1 = c + e1(h) + Ch(h,a,b) + 0x59f111f1 + W[ 5];\n\tt2 = e0(d) + Maj(d,e,f);    g+=t1;    c=t1+t2;\n\tt1 = b + e1(g) + Ch(g,h,a) + 0x923f82a4 + W[ 6];\n\tt2 = e0(c) + Maj(c,d,e);    f+=t1;    b=t1+t2;\n\tt1 = a + e1(f) + Ch(f,g,h) + 0xab1c5ed5 + W[ 7];\n\tt2 = e0(b) + Maj(b,c,d);    e+=t1;    a=t1+t2;\n\n\tt1 = h + e1(e) + Ch(e,f,g) + 0xd807aa98 + W[ 8];\n\tt2 = e0(a) + Maj(a,b,c);    d+=t1;    h=t1+t2;\n\tt1 = g + e1(d) + Ch(d,e,f) + 0x12835b01 + W[ 9];\n\tt2 = e0(h) + Maj(h,a,b);    c+=t1;    g=t1+t2;\n\tt1 = f + e1(c) + Ch(c,d,e) + 0x243185be + W[10];\n\tt2 = e0(g) + Maj(g,h,a);    b+=t1;    f=t1+t2;\n\tt1 = e + e1(b) + Ch(b,c,d) + 0x550c7dc3 + W[11];\n\tt2 = e0(f) + Maj(f,g,h);    a+=t1;    e=t1+t2;\n\tt1 = d + e1(a) + Ch(a,b,c) + 0x72be5d74 + W[12];\n\tt2 = e0(e) + Maj(e,f,g);    h+=t1;    d=t1+t2;\n\tt1 = c + e1(h) + Ch(h,a,b) + 0x80deb1fe + W[13];\n\tt2 = e0(d) + Maj(d,e,f);    g+=t1;    c=t1+t2;\n\tt1 = b + e1(g) + Ch(g,h,a) + 0x9bdc06a7 + W[14];\n\tt2 = e0(c) + Maj(c,d,e);    f+=t1;    b=t1+t2;\n\tt1 = a + e1(f) + Ch(f,g,h) + 0xc19bf174 + W[15];\n\tt2 = e0(b) + Maj(b,c,d);    e+=t1;    a=t1+t2;\n\n\tt1 = h + e1(e) + Ch(e,f,g) + 0xe49b69c1 + W[16];\n\tt2 = e0(a) + Maj(a,b,c);    d+=t1;    h=t1+t2;\n\tt1 = g + e1(d) + Ch(d,e,f) + 0xefbe4786 + W[17];\n\tt2 = e0(h) + Maj(h,a,b);    c+=t1;    g=t1+t2;\n\tt1 = f + e1(c) + Ch(c,d,e) + 0x0fc19dc6 + W[18];\n\tt2 = e0(g) + Maj(g,h,a);    b+=t1;    f=t1+t2;\n\tt1 = e + e1(b) + Ch(b,c,d) + 0x240ca1cc + W[19];\n\tt2 = e0(f) + Maj(f,g,h);    a+=t1;    e=t1+t2;\n\tt1 = d + e1(a) + Ch(a,b,c) + 0x2de92c6f + W[20];\n\tt2 = e0(e) + Maj(e,f,g);    h+=t1;    d=t1+t2;\n\tt1 = c + e1(h) + Ch(h,a,b) + 0x4a7484aa + W[21];\n\tt2 = e0(d) + Maj(d,e,f);    g+=t1;    c=t1+t2;\n\tt1 = b + e1(g) + Ch(g,h,a) + 0x5cb0a9dc + W[22];\n\tt2 = e0(c) + Maj(c,d,e);    f+=t1;    b=t1+t2;\n\tt1 = a + e1(f) + Ch(f,g,h) + 0x76f988da + W[23];\n\tt2 = e0(b) + Maj(b,c,d);    e+=t1;    a=t1+t2;\n\n\tt1 = h + e1(e) + Ch(e,f,g) + 0x983e5152 + W[24];\n\tt2 = e0(a) + Maj(a,b,c);    d+=t1;    h=t1+t2;\n\tt1 = g + e1(d) + Ch(d,e,f) + 0xa831c66d + W[25];\n\tt2 = e0(h) + Maj(h,a,b);    c+=t1;    g=t1+t2;\n\tt1 = f + e1(c) + Ch(c,d,e) + 0xb00327c8 + W[26];\n\tt2 = e0(g) + Maj(g,h,a);    b+=t1;    f=t1+t2;\n\tt1 = e + e1(b) + Ch(b,c,d) + 0xbf597fc7 + W[27];\n\tt2 = e0(f) + Maj(f,g,h);    a+=t1;    e=t1+t2;\n\tt1 = d + e1(a) + Ch(a,b,c) + 0xc6e00bf3 + W[28];\n\tt2 = e0(e) + Maj(e,f,g);    h+=t1;    d=t1+t2;\n\tt1 = c + e1(h) + Ch(h,a,b) + 0xd5a79147 + W[29];\n\tt2 = e0(d) + Maj(d,e,f);    g+=t1;    c=t1+t2;\n\tt1 = b + e1(g) + Ch(g,h,a) + 0x06ca6351 + W[30];\n\tt2 = e0(c) + Maj(c,d,e);    f+=t1;    b=t1+t2;\n\tt1 = a + e1(f) + Ch(f,g,h) + 0x14292967 + W[31];\n\tt2 = e0(b) + Maj(b,c,d);    e+=t1;    a=t1+t2;\n\n\tt1 = h + e1(e) + Ch(e,f,g) + 0x27b70a85 + W[32];\n\tt2 = e0(a) + Maj(a,b,c);    d+=t1;    h=t1+t2;\n\tt1 = g + e1(d) + Ch(d,e,f) + 0x2e1b2138 + W[33];\n\tt2 = e0(h) + Maj(h,a,b);    c+=t1;    g=t1+t2;\n\tt1 = f + e1(c) + Ch(c,d,e) + 0x4d2c6dfc + W[34];\n\tt2 = e0(g) + Maj(g,h,a);    b+=t1;    f=t1+t2;\n\tt1 = e + e1(b) + Ch(b,c,d) + 0x53380d13 + W[35];\n\tt2 = e0(f) + Maj(f,g,h);    a+=t1;    e=t1+t2;\n\tt1 = d + e1(a) + Ch(a,b,c) + 0x650a7354 + W[36];\n\tt2 = e0(e) + Maj(e,f,g);    h+=t1;    d=t1+t2;\n\tt1 = c + e1(h) + Ch(h,a,b) + 0x766a0abb + W[37];\n\tt2 = e0(d) + Maj(d,e,f);    g+=t1;    c=t1+t2;\n\tt1 = b + e1(g) + Ch(g,h,a) + 0x81c2c92e + W[38];\n\tt2 = e0(c) + Maj(c,d,e);    f+=t1;    b=t1+t2;\n\tt1 = a + e1(f) + Ch(f,g,h) + 0x92722c85 + W[39];\n\tt2 = e0(b) + Maj(b,c,d);    e+=t1;    a=t1+t2;\n\n\tt1 = h + e1(e) + Ch(e,f,g) + 0xa2bfe8a1 + W[40];\n\tt2 = e0(a) + Maj(a,b,c);    d+=t1;    h=t1+t2;\n\tt1 = g + e1(d) + Ch(d,e,f) + 0xa81a664b + W[41];\n\tt2 = e0(h) + Maj(h,a,b);    c+=t1;    g=t1+t2;\n\tt1 = f + e1(c) + Ch(c,d,e) + 0xc24b8b70 + W[42];\n\tt2 = e0(g) + Maj(g,h,a);    b+=t1;    f=t1+t2;\n\tt1 = e + e1(b) + Ch(b,c,d) + 0xc76c51a3 + W[43];\n\tt2 = e0(f) + Maj(f,g,h);    a+=t1;    e=t1+t2;\n\tt1 = d + e1(a) + Ch(a,b,c) + 0xd192e819 + W[44];\n\tt2 = e0(e) + Maj(e,f,g);    h+=t1;    d=t1+t2;\n\tt1 = c + e1(h) + Ch(h,a,b) + 0xd6990624 + W[45];\n\tt2 = e0(d) + Maj(d,e,f);    g+=t1;    c=t1+t2;\n\tt1 = b + e1(g) + Ch(g,h,a) + 0xf40e3585 + W[46];\n\tt2 = e0(c) + Maj(c,d,e);    f+=t1;    b=t1+t2;\n\tt1 = a + e1(f) + Ch(f,g,h) + 0x106aa070 + W[47];\n\tt2 = e0(b) + Maj(b,c,d);    e+=t1;    a=t1+t2;\n\n\tt1 = h + e1(e) + Ch(e,f,g) + 0x19a4c116 + W[48];\n\tt2 = e0(a) + Maj(a,b,c);    d+=t1;    h=t1+t2;\n\tt1 = g + e1(d) + Ch(d,e,f) + 0x1e376c08 + W[49];\n\tt2 = e0(h) + Maj(h,a,b);    c+=t1;    g=t1+t2;\n\tt1 = f + e1(c) + Ch(c,d,e) + 0x2748774c + W[50];\n\tt2 = e0(g) + Maj(g,h,a);    b+=t1;    f=t1+t2;\n\tt1 = e + e1(b) + Ch(b,c,d) + 0x34b0bcb5 + W[51];\n\tt2 = e0(f) + Maj(f,g,h);    a+=t1;    e=t1+t2;\n\tt1 = d + e1(a) + Ch(a,b,c) + 0x391c0cb3 + W[52];\n\tt2 = e0(e) + Maj(e,f,g);    h+=t1;    d=t1+t2;\n\tt1 = c + e1(h) + Ch(h,a,b) + 0x4ed8aa4a + W[53];\n\tt2 = e0(d) + Maj(d,e,f);    g+=t1;    c=t1+t2;\n\tt1 = b + e1(g) + Ch(g,h,a) + 0x5b9cca4f + W[54];\n\tt2 = e0(c) + Maj(c,d,e);    f+=t1;    b=t1+t2;\n\tt1 = a + e1(f) + Ch(f,g,h) + 0x682e6ff3 + W[55];\n\tt2 = e0(b) + Maj(b,c,d);    e+=t1;    a=t1+t2;\n\n\tt1 = h + e1(e) + Ch(e,f,g) + 0x748f82ee + W[56];\n\tt2 = e0(a) + Maj(a,b,c);    d+=t1;    h=t1+t2;\n\tt1 = g + e1(d) + Ch(d,e,f) + 0x78a5636f + W[57];\n\tt2 = e0(h) + Maj(h,a,b);    c+=t1;    g=t1+t2;\n\tt1 = f + e1(c) + Ch(c,d,e) + 0x84c87814 + W[58];\n\tt2 = e0(g) + Maj(g,h,a);    b+=t1;    f=t1+t2;\n\tt1 = e + e1(b) + Ch(b,c,d) + 0x8cc70208 + W[59];\n\tt2 = e0(f) + Maj(f,g,h);    a+=t1;    e=t1+t2;\n\tt1 = d + e1(a) + Ch(a,b,c) + 0x90befffa + W[60];\n\tt2 = e0(e) + Maj(e,f,g);    h+=t1;    d=t1+t2;\n\tt1 = c + e1(h) + Ch(h,a,b) + 0xa4506ceb + W[61];\n\tt2 = e0(d) + Maj(d,e,f);    g+=t1;    c=t1+t2;\n\tt1 = b + e1(g) + Ch(g,h,a) + 0xbef9a3f7 + W[62];\n\tt2 = e0(c) + Maj(c,d,e);    f+=t1;    b=t1+t2;\n\tt1 = a + e1(f) + Ch(f,g,h) + 0xc67178f2 + W[63];\n\tt2 = e0(b) + Maj(b,c,d);    e+=t1;    a=t1+t2;\n\n\tstate[0] += a; state[1] += b; state[2] += c; state[3] += d;\n\tstate[4] += e; state[5] += f; state[6] += g; state[7] += h;\n\n\t/* clear any sensitive info... */\n\ta = b = c = d = e = f = g = h = t1 = t2 = 0;\n\tmemzero_explicit(W, 64 * sizeof(u32));\n}\n\nstatic int sha224_init(struct shash_desc *desc)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\tsctx->state[0] = SHA224_H0;\n\tsctx->state[1] = SHA224_H1;\n\tsctx->state[2] = SHA224_H2;\n\tsctx->state[3] = SHA224_H3;\n\tsctx->state[4] = SHA224_H4;\n\tsctx->state[5] = SHA224_H5;\n\tsctx->state[6] = SHA224_H6;\n\tsctx->state[7] = SHA224_H7;\n\tsctx->count = 0;\n\n\treturn 0;\n}\n\nstatic int sha256_init(struct shash_desc *desc)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\tsctx->state[0] = SHA256_H0;\n\tsctx->state[1] = SHA256_H1;\n\tsctx->state[2] = SHA256_H2;\n\tsctx->state[3] = SHA256_H3;\n\tsctx->state[4] = SHA256_H4;\n\tsctx->state[5] = SHA256_H5;\n\tsctx->state[6] = SHA256_H6;\n\tsctx->state[7] = SHA256_H7;\n\tsctx->count = 0;\n\n\treturn 0;\n}\n\nint crypto_sha256_update(struct shash_desc *desc, const u8 *data,\n\t\t\t  unsigned int len)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial, done;\n\tconst u8 *src;\n\n\tpartial = sctx->count & 0x3f;\n\tsctx->count += len;\n\tdone = 0;\n\tsrc = data;\n\n\tif ((partial + len) > 63) {\n\t\tif (partial) {\n\t\t\tdone = -partial;\n\t\t\tmemcpy(sctx->buf + partial, data, done + 64);\n\t\t\tsrc = sctx->buf;\n\t\t}\n\n\t\tdo {\n\t\t\tsha256_transform(sctx->state, src);\n\t\t\tdone += 64;\n\t\t\tsrc = data + done;\n\t\t} while (done + 63 < len);\n\n\t\tpartial = 0;\n\t}\n\tmemcpy(sctx->buf + partial, src, len - done);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(crypto_sha256_update);\n\nstatic int sha256_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\t__be32 *dst = (__be32 *)out;\n\t__be64 bits;\n\tunsigned int index, pad_len;\n\tint i;\n\tstatic const u8 padding[64] = { 0x80, };\n\n\t/* Save number of bits */\n\tbits = cpu_to_be64(sctx->count << 3);\n\n\t/* Pad out to 56 mod 64. */\n\tindex = sctx->count & 0x3f;\n\tpad_len = (index < 56) ? (56 - index) : ((64+56) - index);\n\tcrypto_sha256_update(desc, padding, pad_len);\n\n\t/* Append length (before padding) */\n\tcrypto_sha256_update(desc, (const u8 *)&bits, sizeof(bits));\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 8; i++)\n\t\tdst[i] = cpu_to_be32(sctx->state[i]);\n\n\t/* Zeroize sensitive information. */\n\tmemset(sctx, 0, sizeof(*sctx));\n\n\treturn 0;\n}\n\nstatic int sha224_final(struct shash_desc *desc, u8 *hash)\n{\n\tu8 D[SHA256_DIGEST_SIZE];\n\n\tsha256_final(desc, D);\n\n\tmemcpy(hash, D, SHA224_DIGEST_SIZE);\n\tmemzero_explicit(D, SHA256_DIGEST_SIZE);\n\n\treturn 0;\n}\n\nstatic int sha256_export(struct shash_desc *desc, void *out)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, sizeof(*sctx));\n\treturn 0;\n}\n\nstatic int sha256_import(struct shash_desc *desc, const void *in)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, sizeof(*sctx));\n\treturn 0;\n}\n\nstatic struct shash_alg sha256_algs[2] = { {\n\t.digestsize\t=\tSHA256_DIGEST_SIZE,\n\t.init\t\t=\tsha256_init,\n\t.update\t\t=\tcrypto_sha256_update,\n\t.final\t\t=\tsha256_final,\n\t.export\t\t=\tsha256_export,\n\t.import\t\t=\tsha256_import,\n\t.descsize\t=\tsizeof(struct sha256_state),\n\t.statesize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha256\",\n\t\t.cra_driver_name=\t\"sha256-generic\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA256_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n}, {\n\t.digestsize\t=\tSHA224_DIGEST_SIZE,\n\t.init\t\t=\tsha224_init,\n\t.update\t\t=\tcrypto_sha256_update,\n\t.final\t\t=\tsha224_final,\n\t.descsize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha224\",\n\t\t.cra_driver_name=\t\"sha224-generic\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA224_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n} };\n\nstatic int __init sha256_generic_mod_init(void)\n{\n\treturn crypto_register_shashes(sha256_algs, ARRAY_SIZE(sha256_algs));\n}\n\nstatic void __exit sha256_generic_mod_fini(void)\n{\n\tcrypto_unregister_shashes(sha256_algs, ARRAY_SIZE(sha256_algs));\n}\n\nmodule_init(sha256_generic_mod_init);\nmodule_exit(sha256_generic_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA-224 and SHA-256 Secure Hash Algorithm\");\n\nMODULE_ALIAS_CRYPTO(\"sha224\");\nMODULE_ALIAS_CRYPTO(\"sha256\");\n", "/* SHA-512 code by Jean-Luc Cooke <jlcooke@certainkey.com>\n *\n * Copyright (c) Jean-Luc Cooke <jlcooke@certainkey.com>\n * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>\n * Copyright (c) 2003 Kyle McMartin <kyle@debian.org>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the\n * Free Software Foundation; either version 2, or (at your option) any\n * later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/init.h>\n#include <linux/crypto.h>\n#include <linux/types.h>\n#include <crypto/sha.h>\n#include <linux/percpu.h>\n#include <asm/byteorder.h>\n#include <asm/unaligned.h>\n\nstatic inline u64 Ch(u64 x, u64 y, u64 z)\n{\n        return z ^ (x & (y ^ z));\n}\n\nstatic inline u64 Maj(u64 x, u64 y, u64 z)\n{\n        return (x & y) | (z & (x | y));\n}\n\nstatic const u64 sha512_K[80] = {\n        0x428a2f98d728ae22ULL, 0x7137449123ef65cdULL, 0xb5c0fbcfec4d3b2fULL,\n        0xe9b5dba58189dbbcULL, 0x3956c25bf348b538ULL, 0x59f111f1b605d019ULL,\n        0x923f82a4af194f9bULL, 0xab1c5ed5da6d8118ULL, 0xd807aa98a3030242ULL,\n        0x12835b0145706fbeULL, 0x243185be4ee4b28cULL, 0x550c7dc3d5ffb4e2ULL,\n        0x72be5d74f27b896fULL, 0x80deb1fe3b1696b1ULL, 0x9bdc06a725c71235ULL,\n        0xc19bf174cf692694ULL, 0xe49b69c19ef14ad2ULL, 0xefbe4786384f25e3ULL,\n        0x0fc19dc68b8cd5b5ULL, 0x240ca1cc77ac9c65ULL, 0x2de92c6f592b0275ULL,\n        0x4a7484aa6ea6e483ULL, 0x5cb0a9dcbd41fbd4ULL, 0x76f988da831153b5ULL,\n        0x983e5152ee66dfabULL, 0xa831c66d2db43210ULL, 0xb00327c898fb213fULL,\n        0xbf597fc7beef0ee4ULL, 0xc6e00bf33da88fc2ULL, 0xd5a79147930aa725ULL,\n        0x06ca6351e003826fULL, 0x142929670a0e6e70ULL, 0x27b70a8546d22ffcULL,\n        0x2e1b21385c26c926ULL, 0x4d2c6dfc5ac42aedULL, 0x53380d139d95b3dfULL,\n        0x650a73548baf63deULL, 0x766a0abb3c77b2a8ULL, 0x81c2c92e47edaee6ULL,\n        0x92722c851482353bULL, 0xa2bfe8a14cf10364ULL, 0xa81a664bbc423001ULL,\n        0xc24b8b70d0f89791ULL, 0xc76c51a30654be30ULL, 0xd192e819d6ef5218ULL,\n        0xd69906245565a910ULL, 0xf40e35855771202aULL, 0x106aa07032bbd1b8ULL,\n        0x19a4c116b8d2d0c8ULL, 0x1e376c085141ab53ULL, 0x2748774cdf8eeb99ULL,\n        0x34b0bcb5e19b48a8ULL, 0x391c0cb3c5c95a63ULL, 0x4ed8aa4ae3418acbULL,\n        0x5b9cca4f7763e373ULL, 0x682e6ff3d6b2b8a3ULL, 0x748f82ee5defb2fcULL,\n        0x78a5636f43172f60ULL, 0x84c87814a1f0ab72ULL, 0x8cc702081a6439ecULL,\n        0x90befffa23631e28ULL, 0xa4506cebde82bde9ULL, 0xbef9a3f7b2c67915ULL,\n        0xc67178f2e372532bULL, 0xca273eceea26619cULL, 0xd186b8c721c0c207ULL,\n        0xeada7dd6cde0eb1eULL, 0xf57d4f7fee6ed178ULL, 0x06f067aa72176fbaULL,\n        0x0a637dc5a2c898a6ULL, 0x113f9804bef90daeULL, 0x1b710b35131c471bULL,\n        0x28db77f523047d84ULL, 0x32caab7b40c72493ULL, 0x3c9ebe0a15c9bebcULL,\n        0x431d67c49c100d4cULL, 0x4cc5d4becb3e42b6ULL, 0x597f299cfc657e2aULL,\n        0x5fcb6fab3ad6faecULL, 0x6c44198c4a475817ULL,\n};\n\n#define e0(x)       (ror64(x,28) ^ ror64(x,34) ^ ror64(x,39))\n#define e1(x)       (ror64(x,14) ^ ror64(x,18) ^ ror64(x,41))\n#define s0(x)       (ror64(x, 1) ^ ror64(x, 8) ^ (x >> 7))\n#define s1(x)       (ror64(x,19) ^ ror64(x,61) ^ (x >> 6))\n\nstatic inline void LOAD_OP(int I, u64 *W, const u8 *input)\n{\n\tW[I] = get_unaligned_be64((__u64 *)input + I);\n}\n\nstatic inline void BLEND_OP(int I, u64 *W)\n{\n\tW[I & 15] += s1(W[(I-2) & 15]) + W[(I-7) & 15] + s0(W[(I-15) & 15]);\n}\n\nstatic void\nsha512_transform(u64 *state, const u8 *input)\n{\n\tu64 a, b, c, d, e, f, g, h, t1, t2;\n\n\tint i;\n\tu64 W[16];\n\n\t/* load the state into our registers */\n\ta=state[0];   b=state[1];   c=state[2];   d=state[3];\n\te=state[4];   f=state[5];   g=state[6];   h=state[7];\n\n\t/* now iterate */\n\tfor (i=0; i<80; i+=8) {\n\t\tif (!(i & 8)) {\n\t\t\tint j;\n\n\t\t\tif (i < 16) {\n\t\t\t\t/* load the input */\n\t\t\t\tfor (j = 0; j < 16; j++)\n\t\t\t\t\tLOAD_OP(i + j, W, input);\n\t\t\t} else {\n\t\t\t\tfor (j = 0; j < 16; j++) {\n\t\t\t\t\tBLEND_OP(i + j, W);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tt1 = h + e1(e) + Ch(e,f,g) + sha512_K[i  ] + W[(i & 15)];\n\t\tt2 = e0(a) + Maj(a,b,c);    d+=t1;    h=t1+t2;\n\t\tt1 = g + e1(d) + Ch(d,e,f) + sha512_K[i+1] + W[(i & 15) + 1];\n\t\tt2 = e0(h) + Maj(h,a,b);    c+=t1;    g=t1+t2;\n\t\tt1 = f + e1(c) + Ch(c,d,e) + sha512_K[i+2] + W[(i & 15) + 2];\n\t\tt2 = e0(g) + Maj(g,h,a);    b+=t1;    f=t1+t2;\n\t\tt1 = e + e1(b) + Ch(b,c,d) + sha512_K[i+3] + W[(i & 15) + 3];\n\t\tt2 = e0(f) + Maj(f,g,h);    a+=t1;    e=t1+t2;\n\t\tt1 = d + e1(a) + Ch(a,b,c) + sha512_K[i+4] + W[(i & 15) + 4];\n\t\tt2 = e0(e) + Maj(e,f,g);    h+=t1;    d=t1+t2;\n\t\tt1 = c + e1(h) + Ch(h,a,b) + sha512_K[i+5] + W[(i & 15) + 5];\n\t\tt2 = e0(d) + Maj(d,e,f);    g+=t1;    c=t1+t2;\n\t\tt1 = b + e1(g) + Ch(g,h,a) + sha512_K[i+6] + W[(i & 15) + 6];\n\t\tt2 = e0(c) + Maj(c,d,e);    f+=t1;    b=t1+t2;\n\t\tt1 = a + e1(f) + Ch(f,g,h) + sha512_K[i+7] + W[(i & 15) + 7];\n\t\tt2 = e0(b) + Maj(b,c,d);    e+=t1;    a=t1+t2;\n\t}\n\n\tstate[0] += a; state[1] += b; state[2] += c; state[3] += d;\n\tstate[4] += e; state[5] += f; state[6] += g; state[7] += h;\n\n\t/* erase our data */\n\ta = b = c = d = e = f = g = h = t1 = t2 = 0;\n}\n\nstatic int\nsha512_init(struct shash_desc *desc)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tsctx->state[0] = SHA512_H0;\n\tsctx->state[1] = SHA512_H1;\n\tsctx->state[2] = SHA512_H2;\n\tsctx->state[3] = SHA512_H3;\n\tsctx->state[4] = SHA512_H4;\n\tsctx->state[5] = SHA512_H5;\n\tsctx->state[6] = SHA512_H6;\n\tsctx->state[7] = SHA512_H7;\n\tsctx->count[0] = sctx->count[1] = 0;\n\n\treturn 0;\n}\n\nstatic int\nsha384_init(struct shash_desc *desc)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\tsctx->state[0] = SHA384_H0;\n\tsctx->state[1] = SHA384_H1;\n\tsctx->state[2] = SHA384_H2;\n\tsctx->state[3] = SHA384_H3;\n\tsctx->state[4] = SHA384_H4;\n\tsctx->state[5] = SHA384_H5;\n\tsctx->state[6] = SHA384_H6;\n\tsctx->state[7] = SHA384_H7;\n\tsctx->count[0] = sctx->count[1] = 0;\n\n\treturn 0;\n}\n\nint crypto_sha512_update(struct shash_desc *desc, const u8 *data,\n\t\t\tunsigned int len)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n\n\tunsigned int i, index, part_len;\n\n\t/* Compute number of bytes mod 128 */\n\tindex = sctx->count[0] & 0x7f;\n\n\t/* Update number of bytes */\n\tif ((sctx->count[0] += len) < len)\n\t\tsctx->count[1]++;\n\n        part_len = 128 - index;\n\n\t/* Transform as many times as possible. */\n\tif (len >= part_len) {\n\t\tmemcpy(&sctx->buf[index], data, part_len);\n\t\tsha512_transform(sctx->state, sctx->buf);\n\n\t\tfor (i = part_len; i + 127 < len; i+=128)\n\t\t\tsha512_transform(sctx->state, &data[i]);\n\n\t\tindex = 0;\n\t} else {\n\t\ti = 0;\n\t}\n\n\t/* Buffer remaining input */\n\tmemcpy(&sctx->buf[index], &data[i], len - i);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(crypto_sha512_update);\n\nstatic int\nsha512_final(struct shash_desc *desc, u8 *hash)\n{\n\tstruct sha512_state *sctx = shash_desc_ctx(desc);\n        static u8 padding[128] = { 0x80, };\n\t__be64 *dst = (__be64 *)hash;\n\t__be64 bits[2];\n\tunsigned int index, pad_len;\n\tint i;\n\n\t/* Save number of bits */\n\tbits[1] = cpu_to_be64(sctx->count[0] << 3);\n\tbits[0] = cpu_to_be64(sctx->count[1] << 3 | sctx->count[0] >> 61);\n\n\t/* Pad out to 112 mod 128. */\n\tindex = sctx->count[0] & 0x7f;\n\tpad_len = (index < 112) ? (112 - index) : ((128+112) - index);\n\tcrypto_sha512_update(desc, padding, pad_len);\n\n\t/* Append length (before padding) */\n\tcrypto_sha512_update(desc, (const u8 *)bits, sizeof(bits));\n\n\t/* Store state in digest */\n\tfor (i = 0; i < 8; i++)\n\t\tdst[i] = cpu_to_be64(sctx->state[i]);\n\n\t/* Zeroize sensitive information. */\n\tmemset(sctx, 0, sizeof(struct sha512_state));\n\n\treturn 0;\n}\n\nstatic int sha384_final(struct shash_desc *desc, u8 *hash)\n{\n\tu8 D[64];\n\n\tsha512_final(desc, D);\n\n\tmemcpy(hash, D, 48);\n\tmemzero_explicit(D, 64);\n\n\treturn 0;\n}\n\nstatic struct shash_alg sha512_algs[2] = { {\n\t.digestsize\t=\tSHA512_DIGEST_SIZE,\n\t.init\t\t=\tsha512_init,\n\t.update\t\t=\tcrypto_sha512_update,\n\t.final\t\t=\tsha512_final,\n\t.descsize\t=\tsizeof(struct sha512_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha512\",\n\t\t.cra_driver_name =\t\"sha512-generic\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA512_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n}, {\n\t.digestsize\t=\tSHA384_DIGEST_SIZE,\n\t.init\t\t=\tsha384_init,\n\t.update\t\t=\tcrypto_sha512_update,\n\t.final\t\t=\tsha384_final,\n\t.descsize\t=\tsizeof(struct sha512_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"sha384\",\n\t\t.cra_driver_name =\t\"sha384-generic\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tSHA384_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n} };\n\nstatic int __init sha512_generic_mod_init(void)\n{\n\treturn crypto_register_shashes(sha512_algs, ARRAY_SIZE(sha512_algs));\n}\n\nstatic void __exit sha512_generic_mod_fini(void)\n{\n\tcrypto_unregister_shashes(sha512_algs, ARRAY_SIZE(sha512_algs));\n}\n\nmodule_init(sha512_generic_mod_init);\nmodule_exit(sha512_generic_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"SHA-512 and SHA-384 Secure Hash Algorithms\");\n\nMODULE_ALIAS_CRYPTO(\"sha384\");\nMODULE_ALIAS_CRYPTO(\"sha512\");\n", "/* \n * Cryptographic API.\n *\n * TEA, XTEA, and XETA crypto alogrithms\n *\n * The TEA and Xtended TEA algorithms were developed by David Wheeler \n * and Roger Needham at the Computer Laboratory of Cambridge University.\n *\n * Due to the order of evaluation in XTEA many people have incorrectly\n * implemented it.  XETA (XTEA in the wrong order), exists for\n * compatibility with these implementations.\n *\n * Copyright (c) 2004 Aaron Grothe ajgrothe@yahoo.com\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <asm/byteorder.h>\n#include <linux/crypto.h>\n#include <linux/types.h>\n\n#define TEA_KEY_SIZE\t\t16\n#define TEA_BLOCK_SIZE\t\t8\n#define TEA_ROUNDS\t\t32\n#define TEA_DELTA\t\t0x9e3779b9\n\n#define XTEA_KEY_SIZE\t\t16\n#define XTEA_BLOCK_SIZE\t\t8\n#define XTEA_ROUNDS\t\t32\n#define XTEA_DELTA\t\t0x9e3779b9\n\nstruct tea_ctx {\n\tu32 KEY[4];\n};\n\nstruct xtea_ctx {\n\tu32 KEY[4];\n};\n\nstatic int tea_setkey(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t      unsigned int key_len)\n{\n\tstruct tea_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *key = (const __le32 *)in_key;\n\n\tctx->KEY[0] = le32_to_cpu(key[0]);\n\tctx->KEY[1] = le32_to_cpu(key[1]);\n\tctx->KEY[2] = le32_to_cpu(key[2]);\n\tctx->KEY[3] = le32_to_cpu(key[3]);\n\n\treturn 0; \n\n}\n\nstatic void tea_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tu32 y, z, n, sum = 0;\n\tu32 k0, k1, k2, k3;\n\tstruct tea_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *in = (const __le32 *)src;\n\t__le32 *out = (__le32 *)dst;\n\n\ty = le32_to_cpu(in[0]);\n\tz = le32_to_cpu(in[1]);\n\n\tk0 = ctx->KEY[0];\n\tk1 = ctx->KEY[1];\n\tk2 = ctx->KEY[2];\n\tk3 = ctx->KEY[3];\n\n\tn = TEA_ROUNDS;\n\n\twhile (n-- > 0) {\n\t\tsum += TEA_DELTA;\n\t\ty += ((z << 4) + k0) ^ (z + sum) ^ ((z >> 5) + k1);\n\t\tz += ((y << 4) + k2) ^ (y + sum) ^ ((y >> 5) + k3);\n\t}\n\t\n\tout[0] = cpu_to_le32(y);\n\tout[1] = cpu_to_le32(z);\n}\n\nstatic void tea_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tu32 y, z, n, sum;\n\tu32 k0, k1, k2, k3;\n\tstruct tea_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *in = (const __le32 *)src;\n\t__le32 *out = (__le32 *)dst;\n\n\ty = le32_to_cpu(in[0]);\n\tz = le32_to_cpu(in[1]);\n\n\tk0 = ctx->KEY[0];\n\tk1 = ctx->KEY[1];\n\tk2 = ctx->KEY[2];\n\tk3 = ctx->KEY[3];\n\n\tsum = TEA_DELTA << 5;\n\n\tn = TEA_ROUNDS;\n\n\twhile (n-- > 0) {\n\t\tz -= ((y << 4) + k2) ^ (y + sum) ^ ((y >> 5) + k3);\n\t\ty -= ((z << 4) + k0) ^ (z + sum) ^ ((z >> 5) + k1);\n\t\tsum -= TEA_DELTA;\n\t}\n\t\n\tout[0] = cpu_to_le32(y);\n\tout[1] = cpu_to_le32(z);\n}\n\nstatic int xtea_setkey(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t       unsigned int key_len)\n{\n\tstruct xtea_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *key = (const __le32 *)in_key;\n\n\tctx->KEY[0] = le32_to_cpu(key[0]);\n\tctx->KEY[1] = le32_to_cpu(key[1]);\n\tctx->KEY[2] = le32_to_cpu(key[2]);\n\tctx->KEY[3] = le32_to_cpu(key[3]);\n\n\treturn 0; \n\n}\n\nstatic void xtea_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tu32 y, z, sum = 0;\n\tu32 limit = XTEA_DELTA * XTEA_ROUNDS;\n\tstruct xtea_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *in = (const __le32 *)src;\n\t__le32 *out = (__le32 *)dst;\n\n\ty = le32_to_cpu(in[0]);\n\tz = le32_to_cpu(in[1]);\n\n\twhile (sum != limit) {\n\t\ty += ((z << 4 ^ z >> 5) + z) ^ (sum + ctx->KEY[sum&3]); \n\t\tsum += XTEA_DELTA;\n\t\tz += ((y << 4 ^ y >> 5) + y) ^ (sum + ctx->KEY[sum>>11 &3]); \n\t}\n\t\n\tout[0] = cpu_to_le32(y);\n\tout[1] = cpu_to_le32(z);\n}\n\nstatic void xtea_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tu32 y, z, sum;\n\tstruct tea_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *in = (const __le32 *)src;\n\t__le32 *out = (__le32 *)dst;\n\n\ty = le32_to_cpu(in[0]);\n\tz = le32_to_cpu(in[1]);\n\n\tsum = XTEA_DELTA * XTEA_ROUNDS;\n\n\twhile (sum) {\n\t\tz -= ((y << 4 ^ y >> 5) + y) ^ (sum + ctx->KEY[sum>>11 & 3]);\n\t\tsum -= XTEA_DELTA;\n\t\ty -= ((z << 4 ^ z >> 5) + z) ^ (sum + ctx->KEY[sum & 3]);\n\t}\n\t\n\tout[0] = cpu_to_le32(y);\n\tout[1] = cpu_to_le32(z);\n}\n\n\nstatic void xeta_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tu32 y, z, sum = 0;\n\tu32 limit = XTEA_DELTA * XTEA_ROUNDS;\n\tstruct xtea_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *in = (const __le32 *)src;\n\t__le32 *out = (__le32 *)dst;\n\n\ty = le32_to_cpu(in[0]);\n\tz = le32_to_cpu(in[1]);\n\n\twhile (sum != limit) {\n\t\ty += (z << 4 ^ z >> 5) + (z ^ sum) + ctx->KEY[sum&3];\n\t\tsum += XTEA_DELTA;\n\t\tz += (y << 4 ^ y >> 5) + (y ^ sum) + ctx->KEY[sum>>11 &3];\n\t}\n\t\n\tout[0] = cpu_to_le32(y);\n\tout[1] = cpu_to_le32(z);\n}\n\nstatic void xeta_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\n{\n\tu32 y, z, sum;\n\tstruct tea_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *in = (const __le32 *)src;\n\t__le32 *out = (__le32 *)dst;\n\n\ty = le32_to_cpu(in[0]);\n\tz = le32_to_cpu(in[1]);\n\n\tsum = XTEA_DELTA * XTEA_ROUNDS;\n\n\twhile (sum) {\n\t\tz -= (y << 4 ^ y >> 5) + (y ^ sum) + ctx->KEY[sum>>11 & 3];\n\t\tsum -= XTEA_DELTA;\n\t\ty -= (z << 4 ^ z >> 5) + (z ^ sum) + ctx->KEY[sum & 3];\n\t}\n\t\n\tout[0] = cpu_to_le32(y);\n\tout[1] = cpu_to_le32(z);\n}\n\nstatic struct crypto_alg tea_algs[3] = { {\n\t.cra_name\t\t=\t\"tea\",\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tTEA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof (struct tea_ctx),\n\t.cra_alignmask\t\t=\t3,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\tTEA_KEY_SIZE,\n\t.cia_max_keysize\t=\tTEA_KEY_SIZE,\n\t.cia_setkey\t\t= \ttea_setkey,\n\t.cia_encrypt\t\t=\ttea_encrypt,\n\t.cia_decrypt\t\t=\ttea_decrypt } }\n}, {\n\t.cra_name\t\t=\t\"xtea\",\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tXTEA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof (struct xtea_ctx),\n\t.cra_alignmask\t\t=\t3,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\tXTEA_KEY_SIZE,\n\t.cia_max_keysize\t=\tXTEA_KEY_SIZE,\n\t.cia_setkey\t\t= \txtea_setkey,\n\t.cia_encrypt\t\t=\txtea_encrypt,\n\t.cia_decrypt\t\t=\txtea_decrypt } }\n}, {\n\t.cra_name\t\t=\t\"xeta\",\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tXTEA_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof (struct xtea_ctx),\n\t.cra_alignmask\t\t=\t3,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{ .cipher = {\n\t.cia_min_keysize\t=\tXTEA_KEY_SIZE,\n\t.cia_max_keysize\t=\tXTEA_KEY_SIZE,\n\t.cia_setkey\t\t= \txtea_setkey,\n\t.cia_encrypt\t\t=\txeta_encrypt,\n\t.cia_decrypt\t\t=\txeta_decrypt } }\n} };\n\nstatic int __init tea_mod_init(void)\n{\n\treturn crypto_register_algs(tea_algs, ARRAY_SIZE(tea_algs));\n}\n\nstatic void __exit tea_mod_fini(void)\n{\n\tcrypto_unregister_algs(tea_algs, ARRAY_SIZE(tea_algs));\n}\n\nMODULE_ALIAS_CRYPTO(\"xtea\");\nMODULE_ALIAS_CRYPTO(\"xeta\");\n\nmodule_init(tea_mod_init);\nmodule_exit(tea_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"TEA, XTEA & XETA Cryptographic Algorithms\");\n", "/*\n * Cryptographic API.\n *\n * Tiger hashing Algorithm\n *\n *      Copyright (C) 1998 Free Software Foundation, Inc.\n *\n * The Tiger algorithm was developed by Ross Anderson and Eli Biham.\n * It was optimized for 64-bit processors while still delievering\n * decent performance on 32 and 16-bit processors.\n *\n * This version is derived from the GnuPG implementation and the\n * Tiger-Perl interface written by Rafael Sevilla\n *\n * Adapted for Linux Kernel Crypto  by Aaron Grothe \n * ajgrothe@yahoo.com, February 22, 2005\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <asm/byteorder.h>\n#include <linux/types.h>\n\n#define TGR192_DIGEST_SIZE 24\n#define TGR160_DIGEST_SIZE 20\n#define TGR128_DIGEST_SIZE 16\n\n#define TGR192_BLOCK_SIZE  64\n\nstruct tgr192_ctx {\n\tu64 a, b, c;\n\tu8 hash[64];\n\tint count;\n\tu32 nblocks;\n};\n\nstatic const u64 sbox1[256] = {\n\t0x02aab17cf7e90c5eULL, 0xac424b03e243a8ecULL, 0x72cd5be30dd5fcd3ULL,\n\t0x6d019b93f6f97f3aULL, 0xcd9978ffd21f9193ULL, 0x7573a1c9708029e2ULL,\n\t0xb164326b922a83c3ULL, 0x46883eee04915870ULL, 0xeaace3057103ece6ULL,\n\t0xc54169b808a3535cULL, 0x4ce754918ddec47cULL, 0x0aa2f4dfdc0df40cULL,\n\t0x10b76f18a74dbefaULL, 0xc6ccb6235ad1ab6aULL, 0x13726121572fe2ffULL,\n\t0x1a488c6f199d921eULL, 0x4bc9f9f4da0007caULL, 0x26f5e6f6e85241c7ULL,\n\t0x859079dbea5947b6ULL, 0x4f1885c5c99e8c92ULL, 0xd78e761ea96f864bULL,\n\t0x8e36428c52b5c17dULL, 0x69cf6827373063c1ULL, 0xb607c93d9bb4c56eULL,\n\t0x7d820e760e76b5eaULL, 0x645c9cc6f07fdc42ULL, 0xbf38a078243342e0ULL,\n\t0x5f6b343c9d2e7d04ULL, 0xf2c28aeb600b0ec6ULL, 0x6c0ed85f7254bcacULL,\n\t0x71592281a4db4fe5ULL, 0x1967fa69ce0fed9fULL, 0xfd5293f8b96545dbULL,\n\t0xc879e9d7f2a7600bULL, 0x860248920193194eULL, 0xa4f9533b2d9cc0b3ULL,\n\t0x9053836c15957613ULL, 0xdb6dcf8afc357bf1ULL, 0x18beea7a7a370f57ULL,\n\t0x037117ca50b99066ULL, 0x6ab30a9774424a35ULL, 0xf4e92f02e325249bULL,\n\t0x7739db07061ccae1ULL, 0xd8f3b49ceca42a05ULL, 0xbd56be3f51382f73ULL,\n\t0x45faed5843b0bb28ULL, 0x1c813d5c11bf1f83ULL, 0x8af0e4b6d75fa169ULL,\n\t0x33ee18a487ad9999ULL, 0x3c26e8eab1c94410ULL, 0xb510102bc0a822f9ULL,\n\t0x141eef310ce6123bULL, 0xfc65b90059ddb154ULL, 0xe0158640c5e0e607ULL,\n\t0x884e079826c3a3cfULL, 0x930d0d9523c535fdULL, 0x35638d754e9a2b00ULL,\n\t0x4085fccf40469dd5ULL, 0xc4b17ad28be23a4cULL, 0xcab2f0fc6a3e6a2eULL,\n\t0x2860971a6b943fcdULL, 0x3dde6ee212e30446ULL, 0x6222f32ae01765aeULL,\n\t0x5d550bb5478308feULL, 0xa9efa98da0eda22aULL, 0xc351a71686c40da7ULL,\n\t0x1105586d9c867c84ULL, 0xdcffee85fda22853ULL, 0xccfbd0262c5eef76ULL,\n\t0xbaf294cb8990d201ULL, 0xe69464f52afad975ULL, 0x94b013afdf133e14ULL,\n\t0x06a7d1a32823c958ULL, 0x6f95fe5130f61119ULL, 0xd92ab34e462c06c0ULL,\n\t0xed7bde33887c71d2ULL, 0x79746d6e6518393eULL, 0x5ba419385d713329ULL,\n\t0x7c1ba6b948a97564ULL, 0x31987c197bfdac67ULL, 0xde6c23c44b053d02ULL,\n\t0x581c49fed002d64dULL, 0xdd474d6338261571ULL, 0xaa4546c3e473d062ULL,\n\t0x928fce349455f860ULL, 0x48161bbacaab94d9ULL, 0x63912430770e6f68ULL,\n\t0x6ec8a5e602c6641cULL, 0x87282515337ddd2bULL, 0x2cda6b42034b701bULL,\n\t0xb03d37c181cb096dULL, 0xe108438266c71c6fULL, 0x2b3180c7eb51b255ULL,\n\t0xdf92b82f96c08bbcULL, 0x5c68c8c0a632f3baULL, 0x5504cc861c3d0556ULL,\n\t0xabbfa4e55fb26b8fULL, 0x41848b0ab3baceb4ULL, 0xb334a273aa445d32ULL,\n\t0xbca696f0a85ad881ULL, 0x24f6ec65b528d56cULL, 0x0ce1512e90f4524aULL,\n\t0x4e9dd79d5506d35aULL, 0x258905fac6ce9779ULL, 0x2019295b3e109b33ULL,\n\t0xf8a9478b73a054ccULL, 0x2924f2f934417eb0ULL, 0x3993357d536d1bc4ULL,\n\t0x38a81ac21db6ff8bULL, 0x47c4fbf17d6016bfULL, 0x1e0faadd7667e3f5ULL,\n\t0x7abcff62938beb96ULL, 0xa78dad948fc179c9ULL, 0x8f1f98b72911e50dULL,\n\t0x61e48eae27121a91ULL, 0x4d62f7ad31859808ULL, 0xeceba345ef5ceaebULL,\n\t0xf5ceb25ebc9684ceULL, 0xf633e20cb7f76221ULL, 0xa32cdf06ab8293e4ULL,\n\t0x985a202ca5ee2ca4ULL, 0xcf0b8447cc8a8fb1ULL, 0x9f765244979859a3ULL,\n\t0xa8d516b1a1240017ULL, 0x0bd7ba3ebb5dc726ULL, 0xe54bca55b86adb39ULL,\n\t0x1d7a3afd6c478063ULL, 0x519ec608e7669eddULL, 0x0e5715a2d149aa23ULL,\n\t0x177d4571848ff194ULL, 0xeeb55f3241014c22ULL, 0x0f5e5ca13a6e2ec2ULL,\n\t0x8029927b75f5c361ULL, 0xad139fabc3d6e436ULL, 0x0d5df1a94ccf402fULL,\n\t0x3e8bd948bea5dfc8ULL, 0xa5a0d357bd3ff77eULL, 0xa2d12e251f74f645ULL,\n\t0x66fd9e525e81a082ULL, 0x2e0c90ce7f687a49ULL, 0xc2e8bcbeba973bc5ULL,\n\t0x000001bce509745fULL, 0x423777bbe6dab3d6ULL, 0xd1661c7eaef06eb5ULL,\n\t0xa1781f354daacfd8ULL, 0x2d11284a2b16affcULL, 0xf1fc4f67fa891d1fULL,\n\t0x73ecc25dcb920adaULL, 0xae610c22c2a12651ULL, 0x96e0a810d356b78aULL,\n\t0x5a9a381f2fe7870fULL, 0xd5ad62ede94e5530ULL, 0xd225e5e8368d1427ULL,\n\t0x65977b70c7af4631ULL, 0x99f889b2de39d74fULL, 0x233f30bf54e1d143ULL,\n\t0x9a9675d3d9a63c97ULL, 0x5470554ff334f9a8ULL, 0x166acb744a4f5688ULL,\n\t0x70c74caab2e4aeadULL, 0xf0d091646f294d12ULL, 0x57b82a89684031d1ULL,\n\t0xefd95a5a61be0b6bULL, 0x2fbd12e969f2f29aULL, 0x9bd37013feff9fe8ULL,\n\t0x3f9b0404d6085a06ULL, 0x4940c1f3166cfe15ULL, 0x09542c4dcdf3defbULL,\n\t0xb4c5218385cd5ce3ULL, 0xc935b7dc4462a641ULL, 0x3417f8a68ed3b63fULL,\n\t0xb80959295b215b40ULL, 0xf99cdaef3b8c8572ULL, 0x018c0614f8fcb95dULL,\n\t0x1b14accd1a3acdf3ULL, 0x84d471f200bb732dULL, 0xc1a3110e95e8da16ULL,\n\t0x430a7220bf1a82b8ULL, 0xb77e090d39df210eULL, 0x5ef4bd9f3cd05e9dULL,\n\t0x9d4ff6da7e57a444ULL, 0xda1d60e183d4a5f8ULL, 0xb287c38417998e47ULL,\n\t0xfe3edc121bb31886ULL, 0xc7fe3ccc980ccbefULL, 0xe46fb590189bfd03ULL,\n\t0x3732fd469a4c57dcULL, 0x7ef700a07cf1ad65ULL, 0x59c64468a31d8859ULL,\n\t0x762fb0b4d45b61f6ULL, 0x155baed099047718ULL, 0x68755e4c3d50baa6ULL,\n\t0xe9214e7f22d8b4dfULL, 0x2addbf532eac95f4ULL, 0x32ae3909b4bd0109ULL,\n\t0x834df537b08e3450ULL, 0xfa209da84220728dULL, 0x9e691d9b9efe23f7ULL,\n\t0x0446d288c4ae8d7fULL, 0x7b4cc524e169785bULL, 0x21d87f0135ca1385ULL,\n\t0xcebb400f137b8aa5ULL, 0x272e2b66580796beULL, 0x3612264125c2b0deULL,\n\t0x057702bdad1efbb2ULL, 0xd4babb8eacf84be9ULL, 0x91583139641bc67bULL,\n\t0x8bdc2de08036e024ULL, 0x603c8156f49f68edULL, 0xf7d236f7dbef5111ULL,\n\t0x9727c4598ad21e80ULL, 0xa08a0896670a5fd7ULL, 0xcb4a8f4309eba9cbULL,\n\t0x81af564b0f7036a1ULL, 0xc0b99aa778199abdULL, 0x959f1ec83fc8e952ULL,\n\t0x8c505077794a81b9ULL, 0x3acaaf8f056338f0ULL, 0x07b43f50627a6778ULL,\n\t0x4a44ab49f5eccc77ULL, 0x3bc3d6e4b679ee98ULL, 0x9cc0d4d1cf14108cULL,\n\t0x4406c00b206bc8a0ULL, 0x82a18854c8d72d89ULL, 0x67e366b35c3c432cULL,\n\t0xb923dd61102b37f2ULL, 0x56ab2779d884271dULL, 0xbe83e1b0ff1525afULL,\n\t0xfb7c65d4217e49a9ULL, 0x6bdbe0e76d48e7d4ULL, 0x08df828745d9179eULL,\n\t0x22ea6a9add53bd34ULL, 0xe36e141c5622200aULL, 0x7f805d1b8cb750eeULL,\n\t0xafe5c7a59f58e837ULL, 0xe27f996a4fb1c23cULL, 0xd3867dfb0775f0d0ULL,\n\t0xd0e673de6e88891aULL, 0x123aeb9eafb86c25ULL, 0x30f1d5d5c145b895ULL,\n\t0xbb434a2dee7269e7ULL, 0x78cb67ecf931fa38ULL, 0xf33b0372323bbf9cULL,\n\t0x52d66336fb279c74ULL, 0x505f33ac0afb4eaaULL, 0xe8a5cd99a2cce187ULL,\n\t0x534974801e2d30bbULL, 0x8d2d5711d5876d90ULL, 0x1f1a412891bc038eULL,\n\t0xd6e2e71d82e56648ULL, 0x74036c3a497732b7ULL, 0x89b67ed96361f5abULL,\n\t0xffed95d8f1ea02a2ULL, 0xe72b3bd61464d43dULL, 0xa6300f170bdc4820ULL,\n\t0xebc18760ed78a77aULL\n};\n\nstatic const u64 sbox2[256] = {\n\t0xe6a6be5a05a12138ULL, 0xb5a122a5b4f87c98ULL, 0x563c6089140b6990ULL,\n\t0x4c46cb2e391f5dd5ULL, 0xd932addbc9b79434ULL, 0x08ea70e42015aff5ULL,\n\t0xd765a6673e478cf1ULL, 0xc4fb757eab278d99ULL, 0xdf11c6862d6e0692ULL,\n\t0xddeb84f10d7f3b16ULL, 0x6f2ef604a665ea04ULL, 0x4a8e0f0ff0e0dfb3ULL,\n\t0xa5edeef83dbcba51ULL, 0xfc4f0a2a0ea4371eULL, 0xe83e1da85cb38429ULL,\n\t0xdc8ff882ba1b1ce2ULL, 0xcd45505e8353e80dULL, 0x18d19a00d4db0717ULL,\n\t0x34a0cfeda5f38101ULL, 0x0be77e518887caf2ULL, 0x1e341438b3c45136ULL,\n\t0xe05797f49089ccf9ULL, 0xffd23f9df2591d14ULL, 0x543dda228595c5cdULL,\n\t0x661f81fd99052a33ULL, 0x8736e641db0f7b76ULL, 0x15227725418e5307ULL,\n\t0xe25f7f46162eb2faULL, 0x48a8b2126c13d9feULL, 0xafdc541792e76eeaULL,\n\t0x03d912bfc6d1898fULL, 0x31b1aafa1b83f51bULL, 0xf1ac2796e42ab7d9ULL,\n\t0x40a3a7d7fcd2ebacULL, 0x1056136d0afbbcc5ULL, 0x7889e1dd9a6d0c85ULL,\n\t0xd33525782a7974aaULL, 0xa7e25d09078ac09bULL, 0xbd4138b3eac6edd0ULL,\n\t0x920abfbe71eb9e70ULL, 0xa2a5d0f54fc2625cULL, 0xc054e36b0b1290a3ULL,\n\t0xf6dd59ff62fe932bULL, 0x3537354511a8ac7dULL, 0xca845e9172fadcd4ULL,\n\t0x84f82b60329d20dcULL, 0x79c62ce1cd672f18ULL, 0x8b09a2add124642cULL,\n\t0xd0c1e96a19d9e726ULL, 0x5a786a9b4ba9500cULL, 0x0e020336634c43f3ULL,\n\t0xc17b474aeb66d822ULL, 0x6a731ae3ec9baac2ULL, 0x8226667ae0840258ULL,\n\t0x67d4567691caeca5ULL, 0x1d94155c4875adb5ULL, 0x6d00fd985b813fdfULL,\n\t0x51286efcb774cd06ULL, 0x5e8834471fa744afULL, 0xf72ca0aee761ae2eULL,\n\t0xbe40e4cdaee8e09aULL, 0xe9970bbb5118f665ULL, 0x726e4beb33df1964ULL,\n\t0x703b000729199762ULL, 0x4631d816f5ef30a7ULL, 0xb880b5b51504a6beULL,\n\t0x641793c37ed84b6cULL, 0x7b21ed77f6e97d96ULL, 0x776306312ef96b73ULL,\n\t0xae528948e86ff3f4ULL, 0x53dbd7f286a3f8f8ULL, 0x16cadce74cfc1063ULL,\n\t0x005c19bdfa52c6ddULL, 0x68868f5d64d46ad3ULL, 0x3a9d512ccf1e186aULL,\n\t0x367e62c2385660aeULL, 0xe359e7ea77dcb1d7ULL, 0x526c0773749abe6eULL,\n\t0x735ae5f9d09f734bULL, 0x493fc7cc8a558ba8ULL, 0xb0b9c1533041ab45ULL,\n\t0x321958ba470a59bdULL, 0x852db00b5f46c393ULL, 0x91209b2bd336b0e5ULL,\n\t0x6e604f7d659ef19fULL, 0xb99a8ae2782ccb24ULL, 0xccf52ab6c814c4c7ULL,\n\t0x4727d9afbe11727bULL, 0x7e950d0c0121b34dULL, 0x756f435670ad471fULL,\n\t0xf5add442615a6849ULL, 0x4e87e09980b9957aULL, 0x2acfa1df50aee355ULL,\n\t0xd898263afd2fd556ULL, 0xc8f4924dd80c8fd6ULL, 0xcf99ca3d754a173aULL,\n\t0xfe477bacaf91bf3cULL, 0xed5371f6d690c12dULL, 0x831a5c285e687094ULL,\n\t0xc5d3c90a3708a0a4ULL, 0x0f7f903717d06580ULL, 0x19f9bb13b8fdf27fULL,\n\t0xb1bd6f1b4d502843ULL, 0x1c761ba38fff4012ULL, 0x0d1530c4e2e21f3bULL,\n\t0x8943ce69a7372c8aULL, 0xe5184e11feb5ce66ULL, 0x618bdb80bd736621ULL,\n\t0x7d29bad68b574d0bULL, 0x81bb613e25e6fe5bULL, 0x071c9c10bc07913fULL,\n\t0xc7beeb7909ac2d97ULL, 0xc3e58d353bc5d757ULL, 0xeb017892f38f61e8ULL,\n\t0xd4effb9c9b1cc21aULL, 0x99727d26f494f7abULL, 0xa3e063a2956b3e03ULL,\n\t0x9d4a8b9a4aa09c30ULL, 0x3f6ab7d500090fb4ULL, 0x9cc0f2a057268ac0ULL,\n\t0x3dee9d2dedbf42d1ULL, 0x330f49c87960a972ULL, 0xc6b2720287421b41ULL,\n\t0x0ac59ec07c00369cULL, 0xef4eac49cb353425ULL, 0xf450244eef0129d8ULL,\n\t0x8acc46e5caf4deb6ULL, 0x2ffeab63989263f7ULL, 0x8f7cb9fe5d7a4578ULL,\n\t0x5bd8f7644e634635ULL, 0x427a7315bf2dc900ULL, 0x17d0c4aa2125261cULL,\n\t0x3992486c93518e50ULL, 0xb4cbfee0a2d7d4c3ULL, 0x7c75d6202c5ddd8dULL,\n\t0xdbc295d8e35b6c61ULL, 0x60b369d302032b19ULL, 0xce42685fdce44132ULL,\n\t0x06f3ddb9ddf65610ULL, 0x8ea4d21db5e148f0ULL, 0x20b0fce62fcd496fULL,\n\t0x2c1b912358b0ee31ULL, 0xb28317b818f5a308ULL, 0xa89c1e189ca6d2cfULL,\n\t0x0c6b18576aaadbc8ULL, 0xb65deaa91299fae3ULL, 0xfb2b794b7f1027e7ULL,\n\t0x04e4317f443b5bebULL, 0x4b852d325939d0a6ULL, 0xd5ae6beefb207ffcULL,\n\t0x309682b281c7d374ULL, 0xbae309a194c3b475ULL, 0x8cc3f97b13b49f05ULL,\n\t0x98a9422ff8293967ULL, 0x244b16b01076ff7cULL, 0xf8bf571c663d67eeULL,\n\t0x1f0d6758eee30da1ULL, 0xc9b611d97adeb9b7ULL, 0xb7afd5887b6c57a2ULL,\n\t0x6290ae846b984fe1ULL, 0x94df4cdeacc1a5fdULL, 0x058a5bd1c5483affULL,\n\t0x63166cc142ba3c37ULL, 0x8db8526eb2f76f40ULL, 0xe10880036f0d6d4eULL,\n\t0x9e0523c9971d311dULL, 0x45ec2824cc7cd691ULL, 0x575b8359e62382c9ULL,\n\t0xfa9e400dc4889995ULL, 0xd1823ecb45721568ULL, 0xdafd983b8206082fULL,\n\t0xaa7d29082386a8cbULL, 0x269fcd4403b87588ULL, 0x1b91f5f728bdd1e0ULL,\n\t0xe4669f39040201f6ULL, 0x7a1d7c218cf04adeULL, 0x65623c29d79ce5ceULL,\n\t0x2368449096c00bb1ULL, 0xab9bf1879da503baULL, 0xbc23ecb1a458058eULL,\n\t0x9a58df01bb401eccULL, 0xa070e868a85f143dULL, 0x4ff188307df2239eULL,\n\t0x14d565b41a641183ULL, 0xee13337452701602ULL, 0x950e3dcf3f285e09ULL,\n\t0x59930254b9c80953ULL, 0x3bf299408930da6dULL, 0xa955943f53691387ULL,\n\t0xa15edecaa9cb8784ULL, 0x29142127352be9a0ULL, 0x76f0371fff4e7afbULL,\n\t0x0239f450274f2228ULL, 0xbb073af01d5e868bULL, 0xbfc80571c10e96c1ULL,\n\t0xd267088568222e23ULL, 0x9671a3d48e80b5b0ULL, 0x55b5d38ae193bb81ULL,\n\t0x693ae2d0a18b04b8ULL, 0x5c48b4ecadd5335fULL, 0xfd743b194916a1caULL,\n\t0x2577018134be98c4ULL, 0xe77987e83c54a4adULL, 0x28e11014da33e1b9ULL,\n\t0x270cc59e226aa213ULL, 0x71495f756d1a5f60ULL, 0x9be853fb60afef77ULL,\n\t0xadc786a7f7443dbfULL, 0x0904456173b29a82ULL, 0x58bc7a66c232bd5eULL,\n\t0xf306558c673ac8b2ULL, 0x41f639c6b6c9772aULL, 0x216defe99fda35daULL,\n\t0x11640cc71c7be615ULL, 0x93c43694565c5527ULL, 0xea038e6246777839ULL,\n\t0xf9abf3ce5a3e2469ULL, 0x741e768d0fd312d2ULL, 0x0144b883ced652c6ULL,\n\t0xc20b5a5ba33f8552ULL, 0x1ae69633c3435a9dULL, 0x97a28ca4088cfdecULL,\n\t0x8824a43c1e96f420ULL, 0x37612fa66eeea746ULL, 0x6b4cb165f9cf0e5aULL,\n\t0x43aa1c06a0abfb4aULL, 0x7f4dc26ff162796bULL, 0x6cbacc8e54ed9b0fULL,\n\t0xa6b7ffefd2bb253eULL, 0x2e25bc95b0a29d4fULL, 0x86d6a58bdef1388cULL,\n\t0xded74ac576b6f054ULL, 0x8030bdbc2b45805dULL, 0x3c81af70e94d9289ULL,\n\t0x3eff6dda9e3100dbULL, 0xb38dc39fdfcc8847ULL, 0x123885528d17b87eULL,\n\t0xf2da0ed240b1b642ULL, 0x44cefadcd54bf9a9ULL, 0x1312200e433c7ee6ULL,\n\t0x9ffcc84f3a78c748ULL, 0xf0cd1f72248576bbULL, 0xec6974053638cfe4ULL,\n\t0x2ba7b67c0cec4e4cULL, 0xac2f4df3e5ce32edULL, 0xcb33d14326ea4c11ULL,\n\t0xa4e9044cc77e58bcULL, 0x5f513293d934fcefULL, 0x5dc9645506e55444ULL,\n\t0x50de418f317de40aULL, 0x388cb31a69dde259ULL, 0x2db4a83455820a86ULL,\n\t0x9010a91e84711ae9ULL, 0x4df7f0b7b1498371ULL, 0xd62a2eabc0977179ULL,\n\t0x22fac097aa8d5c0eULL\n};\n\nstatic const u64 sbox3[256] = {\n\t0xf49fcc2ff1daf39bULL, 0x487fd5c66ff29281ULL, 0xe8a30667fcdca83fULL,\n\t0x2c9b4be3d2fcce63ULL, 0xda3ff74b93fbbbc2ULL, 0x2fa165d2fe70ba66ULL,\n\t0xa103e279970e93d4ULL, 0xbecdec77b0e45e71ULL, 0xcfb41e723985e497ULL,\n\t0xb70aaa025ef75017ULL, 0xd42309f03840b8e0ULL, 0x8efc1ad035898579ULL,\n\t0x96c6920be2b2abc5ULL, 0x66af4163375a9172ULL, 0x2174abdcca7127fbULL,\n\t0xb33ccea64a72ff41ULL, 0xf04a4933083066a5ULL, 0x8d970acdd7289af5ULL,\n\t0x8f96e8e031c8c25eULL, 0xf3fec02276875d47ULL, 0xec7bf310056190ddULL,\n\t0xf5adb0aebb0f1491ULL, 0x9b50f8850fd58892ULL, 0x4975488358b74de8ULL,\n\t0xa3354ff691531c61ULL, 0x0702bbe481d2c6eeULL, 0x89fb24057deded98ULL,\n\t0xac3075138596e902ULL, 0x1d2d3580172772edULL, 0xeb738fc28e6bc30dULL,\n\t0x5854ef8f63044326ULL, 0x9e5c52325add3bbeULL, 0x90aa53cf325c4623ULL,\n\t0xc1d24d51349dd067ULL, 0x2051cfeea69ea624ULL, 0x13220f0a862e7e4fULL,\n\t0xce39399404e04864ULL, 0xd9c42ca47086fcb7ULL, 0x685ad2238a03e7ccULL,\n\t0x066484b2ab2ff1dbULL, 0xfe9d5d70efbf79ecULL, 0x5b13b9dd9c481854ULL,\n\t0x15f0d475ed1509adULL, 0x0bebcd060ec79851ULL, 0xd58c6791183ab7f8ULL,\n\t0xd1187c5052f3eee4ULL, 0xc95d1192e54e82ffULL, 0x86eea14cb9ac6ca2ULL,\n\t0x3485beb153677d5dULL, 0xdd191d781f8c492aULL, 0xf60866baa784ebf9ULL,\n\t0x518f643ba2d08c74ULL, 0x8852e956e1087c22ULL, 0xa768cb8dc410ae8dULL,\n\t0x38047726bfec8e1aULL, 0xa67738b4cd3b45aaULL, 0xad16691cec0dde19ULL,\n\t0xc6d4319380462e07ULL, 0xc5a5876d0ba61938ULL, 0x16b9fa1fa58fd840ULL,\n\t0x188ab1173ca74f18ULL, 0xabda2f98c99c021fULL, 0x3e0580ab134ae816ULL,\n\t0x5f3b05b773645abbULL, 0x2501a2be5575f2f6ULL, 0x1b2f74004e7e8ba9ULL,\n\t0x1cd7580371e8d953ULL, 0x7f6ed89562764e30ULL, 0xb15926ff596f003dULL,\n\t0x9f65293da8c5d6b9ULL, 0x6ecef04dd690f84cULL, 0x4782275fff33af88ULL,\n\t0xe41433083f820801ULL, 0xfd0dfe409a1af9b5ULL, 0x4325a3342cdb396bULL,\n\t0x8ae77e62b301b252ULL, 0xc36f9e9f6655615aULL, 0x85455a2d92d32c09ULL,\n\t0xf2c7dea949477485ULL, 0x63cfb4c133a39ebaULL, 0x83b040cc6ebc5462ULL,\n\t0x3b9454c8fdb326b0ULL, 0x56f56a9e87ffd78cULL, 0x2dc2940d99f42bc6ULL,\n\t0x98f7df096b096e2dULL, 0x19a6e01e3ad852bfULL, 0x42a99ccbdbd4b40bULL,\n\t0xa59998af45e9c559ULL, 0x366295e807d93186ULL, 0x6b48181bfaa1f773ULL,\n\t0x1fec57e2157a0a1dULL, 0x4667446af6201ad5ULL, 0xe615ebcacfb0f075ULL,\n\t0xb8f31f4f68290778ULL, 0x22713ed6ce22d11eULL, 0x3057c1a72ec3c93bULL,\n\t0xcb46acc37c3f1f2fULL, 0xdbb893fd02aaf50eULL, 0x331fd92e600b9fcfULL,\n\t0xa498f96148ea3ad6ULL, 0xa8d8426e8b6a83eaULL, 0xa089b274b7735cdcULL,\n\t0x87f6b3731e524a11ULL, 0x118808e5cbc96749ULL, 0x9906e4c7b19bd394ULL,\n\t0xafed7f7e9b24a20cULL, 0x6509eadeeb3644a7ULL, 0x6c1ef1d3e8ef0edeULL,\n\t0xb9c97d43e9798fb4ULL, 0xa2f2d784740c28a3ULL, 0x7b8496476197566fULL,\n\t0x7a5be3e6b65f069dULL, 0xf96330ed78be6f10ULL, 0xeee60de77a076a15ULL,\n\t0x2b4bee4aa08b9bd0ULL, 0x6a56a63ec7b8894eULL, 0x02121359ba34fef4ULL,\n\t0x4cbf99f8283703fcULL, 0x398071350caf30c8ULL, 0xd0a77a89f017687aULL,\n\t0xf1c1a9eb9e423569ULL, 0x8c7976282dee8199ULL, 0x5d1737a5dd1f7abdULL,\n\t0x4f53433c09a9fa80ULL, 0xfa8b0c53df7ca1d9ULL, 0x3fd9dcbc886ccb77ULL,\n\t0xc040917ca91b4720ULL, 0x7dd00142f9d1dcdfULL, 0x8476fc1d4f387b58ULL,\n\t0x23f8e7c5f3316503ULL, 0x032a2244e7e37339ULL, 0x5c87a5d750f5a74bULL,\n\t0x082b4cc43698992eULL, 0xdf917becb858f63cULL, 0x3270b8fc5bf86ddaULL,\n\t0x10ae72bb29b5dd76ULL, 0x576ac94e7700362bULL, 0x1ad112dac61efb8fULL,\n\t0x691bc30ec5faa427ULL, 0xff246311cc327143ULL, 0x3142368e30e53206ULL,\n\t0x71380e31e02ca396ULL, 0x958d5c960aad76f1ULL, 0xf8d6f430c16da536ULL,\n\t0xc8ffd13f1be7e1d2ULL, 0x7578ae66004ddbe1ULL, 0x05833f01067be646ULL,\n\t0xbb34b5ad3bfe586dULL, 0x095f34c9a12b97f0ULL, 0x247ab64525d60ca8ULL,\n\t0xdcdbc6f3017477d1ULL, 0x4a2e14d4decad24dULL, 0xbdb5e6d9be0a1eebULL,\n\t0x2a7e70f7794301abULL, 0xdef42d8a270540fdULL, 0x01078ec0a34c22c1ULL,\n\t0xe5de511af4c16387ULL, 0x7ebb3a52bd9a330aULL, 0x77697857aa7d6435ULL,\n\t0x004e831603ae4c32ULL, 0xe7a21020ad78e312ULL, 0x9d41a70c6ab420f2ULL,\n\t0x28e06c18ea1141e6ULL, 0xd2b28cbd984f6b28ULL, 0x26b75f6c446e9d83ULL,\n\t0xba47568c4d418d7fULL, 0xd80badbfe6183d8eULL, 0x0e206d7f5f166044ULL,\n\t0xe258a43911cbca3eULL, 0x723a1746b21dc0bcULL, 0xc7caa854f5d7cdd3ULL,\n\t0x7cac32883d261d9cULL, 0x7690c26423ba942cULL, 0x17e55524478042b8ULL,\n\t0xe0be477656a2389fULL, 0x4d289b5e67ab2da0ULL, 0x44862b9c8fbbfd31ULL,\n\t0xb47cc8049d141365ULL, 0x822c1b362b91c793ULL, 0x4eb14655fb13dfd8ULL,\n\t0x1ecbba0714e2a97bULL, 0x6143459d5cde5f14ULL, 0x53a8fbf1d5f0ac89ULL,\n\t0x97ea04d81c5e5b00ULL, 0x622181a8d4fdb3f3ULL, 0xe9bcd341572a1208ULL,\n\t0x1411258643cce58aULL, 0x9144c5fea4c6e0a4ULL, 0x0d33d06565cf620fULL,\n\t0x54a48d489f219ca1ULL, 0xc43e5eac6d63c821ULL, 0xa9728b3a72770dafULL,\n\t0xd7934e7b20df87efULL, 0xe35503b61a3e86e5ULL, 0xcae321fbc819d504ULL,\n\t0x129a50b3ac60bfa6ULL, 0xcd5e68ea7e9fb6c3ULL, 0xb01c90199483b1c7ULL,\n\t0x3de93cd5c295376cULL, 0xaed52edf2ab9ad13ULL, 0x2e60f512c0a07884ULL,\n\t0xbc3d86a3e36210c9ULL, 0x35269d9b163951ceULL, 0x0c7d6e2ad0cdb5faULL,\n\t0x59e86297d87f5733ULL, 0x298ef221898db0e7ULL, 0x55000029d1a5aa7eULL,\n\t0x8bc08ae1b5061b45ULL, 0xc2c31c2b6c92703aULL, 0x94cc596baf25ef42ULL,\n\t0x0a1d73db22540456ULL, 0x04b6a0f9d9c4179aULL, 0xeffdafa2ae3d3c60ULL,\n\t0xf7c8075bb49496c4ULL, 0x9cc5c7141d1cd4e3ULL, 0x78bd1638218e5534ULL,\n\t0xb2f11568f850246aULL, 0xedfabcfa9502bc29ULL, 0x796ce5f2da23051bULL,\n\t0xaae128b0dc93537cULL, 0x3a493da0ee4b29aeULL, 0xb5df6b2c416895d7ULL,\n\t0xfcabbd25122d7f37ULL, 0x70810b58105dc4b1ULL, 0xe10fdd37f7882a90ULL,\n\t0x524dcab5518a3f5cULL, 0x3c9e85878451255bULL, 0x4029828119bd34e2ULL,\n\t0x74a05b6f5d3ceccbULL, 0xb610021542e13ecaULL, 0x0ff979d12f59e2acULL,\n\t0x6037da27e4f9cc50ULL, 0x5e92975a0df1847dULL, 0xd66de190d3e623feULL,\n\t0x5032d6b87b568048ULL, 0x9a36b7ce8235216eULL, 0x80272a7a24f64b4aULL,\n\t0x93efed8b8c6916f7ULL, 0x37ddbff44cce1555ULL, 0x4b95db5d4b99bd25ULL,\n\t0x92d3fda169812fc0ULL, 0xfb1a4a9a90660bb6ULL, 0x730c196946a4b9b2ULL,\n\t0x81e289aa7f49da68ULL, 0x64669a0f83b1a05fULL, 0x27b3ff7d9644f48bULL,\n\t0xcc6b615c8db675b3ULL, 0x674f20b9bcebbe95ULL, 0x6f31238275655982ULL,\n\t0x5ae488713e45cf05ULL, 0xbf619f9954c21157ULL, 0xeabac46040a8eae9ULL,\n\t0x454c6fe9f2c0c1cdULL, 0x419cf6496412691cULL, 0xd3dc3bef265b0f70ULL,\n\t0x6d0e60f5c3578a9eULL\n};\n\nstatic const u64 sbox4[256] = {\n\t0x5b0e608526323c55ULL, 0x1a46c1a9fa1b59f5ULL, 0xa9e245a17c4c8ffaULL,\n\t0x65ca5159db2955d7ULL, 0x05db0a76ce35afc2ULL, 0x81eac77ea9113d45ULL,\n\t0x528ef88ab6ac0a0dULL, 0xa09ea253597be3ffULL, 0x430ddfb3ac48cd56ULL,\n\t0xc4b3a67af45ce46fULL, 0x4ececfd8fbe2d05eULL, 0x3ef56f10b39935f0ULL,\n\t0x0b22d6829cd619c6ULL, 0x17fd460a74df2069ULL, 0x6cf8cc8e8510ed40ULL,\n\t0xd6c824bf3a6ecaa7ULL, 0x61243d581a817049ULL, 0x048bacb6bbc163a2ULL,\n\t0xd9a38ac27d44cc32ULL, 0x7fddff5baaf410abULL, 0xad6d495aa804824bULL,\n\t0xe1a6a74f2d8c9f94ULL, 0xd4f7851235dee8e3ULL, 0xfd4b7f886540d893ULL,\n\t0x247c20042aa4bfdaULL, 0x096ea1c517d1327cULL, 0xd56966b4361a6685ULL,\n\t0x277da5c31221057dULL, 0x94d59893a43acff7ULL, 0x64f0c51ccdc02281ULL,\n\t0x3d33bcc4ff6189dbULL, 0xe005cb184ce66af1ULL, 0xff5ccd1d1db99beaULL,\n\t0xb0b854a7fe42980fULL, 0x7bd46a6a718d4b9fULL, 0xd10fa8cc22a5fd8cULL,\n\t0xd31484952be4bd31ULL, 0xc7fa975fcb243847ULL, 0x4886ed1e5846c407ULL,\n\t0x28cddb791eb70b04ULL, 0xc2b00be2f573417fULL, 0x5c9590452180f877ULL,\n\t0x7a6bddfff370eb00ULL, 0xce509e38d6d9d6a4ULL, 0xebeb0f00647fa702ULL,\n\t0x1dcc06cf76606f06ULL, 0xe4d9f28ba286ff0aULL, 0xd85a305dc918c262ULL,\n\t0x475b1d8732225f54ULL, 0x2d4fb51668ccb5feULL, 0xa679b9d9d72bba20ULL,\n\t0x53841c0d912d43a5ULL, 0x3b7eaa48bf12a4e8ULL, 0x781e0e47f22f1ddfULL,\n\t0xeff20ce60ab50973ULL, 0x20d261d19dffb742ULL, 0x16a12b03062a2e39ULL,\n\t0x1960eb2239650495ULL, 0x251c16fed50eb8b8ULL, 0x9ac0c330f826016eULL,\n\t0xed152665953e7671ULL, 0x02d63194a6369570ULL, 0x5074f08394b1c987ULL,\n\t0x70ba598c90b25ce1ULL, 0x794a15810b9742f6ULL, 0x0d5925e9fcaf8c6cULL,\n\t0x3067716cd868744eULL, 0x910ab077e8d7731bULL, 0x6a61bbdb5ac42f61ULL,\n\t0x93513efbf0851567ULL, 0xf494724b9e83e9d5ULL, 0xe887e1985c09648dULL,\n\t0x34b1d3c675370cfdULL, 0xdc35e433bc0d255dULL, 0xd0aab84234131be0ULL,\n\t0x08042a50b48b7eafULL, 0x9997c4ee44a3ab35ULL, 0x829a7b49201799d0ULL,\n\t0x263b8307b7c54441ULL, 0x752f95f4fd6a6ca6ULL, 0x927217402c08c6e5ULL,\n\t0x2a8ab754a795d9eeULL, 0xa442f7552f72943dULL, 0x2c31334e19781208ULL,\n\t0x4fa98d7ceaee6291ULL, 0x55c3862f665db309ULL, 0xbd0610175d53b1f3ULL,\n\t0x46fe6cb840413f27ULL, 0x3fe03792df0cfa59ULL, 0xcfe700372eb85e8fULL,\n\t0xa7be29e7adbce118ULL, 0xe544ee5cde8431ddULL, 0x8a781b1b41f1873eULL,\n\t0xa5c94c78a0d2f0e7ULL, 0x39412e2877b60728ULL, 0xa1265ef3afc9a62cULL,\n\t0xbcc2770c6a2506c5ULL, 0x3ab66dd5dce1ce12ULL, 0xe65499d04a675b37ULL,\n\t0x7d8f523481bfd216ULL, 0x0f6f64fcec15f389ULL, 0x74efbe618b5b13c8ULL,\n\t0xacdc82b714273e1dULL, 0xdd40bfe003199d17ULL, 0x37e99257e7e061f8ULL,\n\t0xfa52626904775aaaULL, 0x8bbbf63a463d56f9ULL, 0xf0013f1543a26e64ULL,\n\t0xa8307e9f879ec898ULL, 0xcc4c27a4150177ccULL, 0x1b432f2cca1d3348ULL,\n\t0xde1d1f8f9f6fa013ULL, 0x606602a047a7ddd6ULL, 0xd237ab64cc1cb2c7ULL,\n\t0x9b938e7225fcd1d3ULL, 0xec4e03708e0ff476ULL, 0xfeb2fbda3d03c12dULL,\n\t0xae0bced2ee43889aULL, 0x22cb8923ebfb4f43ULL, 0x69360d013cf7396dULL,\n\t0x855e3602d2d4e022ULL, 0x073805bad01f784cULL, 0x33e17a133852f546ULL,\n\t0xdf4874058ac7b638ULL, 0xba92b29c678aa14aULL, 0x0ce89fc76cfaadcdULL,\n\t0x5f9d4e0908339e34ULL, 0xf1afe9291f5923b9ULL, 0x6e3480f60f4a265fULL,\n\t0xeebf3a2ab29b841cULL, 0xe21938a88f91b4adULL, 0x57dfeff845c6d3c3ULL,\n\t0x2f006b0bf62caaf2ULL, 0x62f479ef6f75ee78ULL, 0x11a55ad41c8916a9ULL,\n\t0xf229d29084fed453ULL, 0x42f1c27b16b000e6ULL, 0x2b1f76749823c074ULL,\n\t0x4b76eca3c2745360ULL, 0x8c98f463b91691bdULL, 0x14bcc93cf1ade66aULL,\n\t0x8885213e6d458397ULL, 0x8e177df0274d4711ULL, 0xb49b73b5503f2951ULL,\n\t0x10168168c3f96b6bULL, 0x0e3d963b63cab0aeULL, 0x8dfc4b5655a1db14ULL,\n\t0xf789f1356e14de5cULL, 0x683e68af4e51dac1ULL, 0xc9a84f9d8d4b0fd9ULL,\n\t0x3691e03f52a0f9d1ULL, 0x5ed86e46e1878e80ULL, 0x3c711a0e99d07150ULL,\n\t0x5a0865b20c4e9310ULL, 0x56fbfc1fe4f0682eULL, 0xea8d5de3105edf9bULL,\n\t0x71abfdb12379187aULL, 0x2eb99de1bee77b9cULL, 0x21ecc0ea33cf4523ULL,\n\t0x59a4d7521805c7a1ULL, 0x3896f5eb56ae7c72ULL, 0xaa638f3db18f75dcULL,\n\t0x9f39358dabe9808eULL, 0xb7defa91c00b72acULL, 0x6b5541fd62492d92ULL,\n\t0x6dc6dee8f92e4d5bULL, 0x353f57abc4beea7eULL, 0x735769d6da5690ceULL,\n\t0x0a234aa642391484ULL, 0xf6f9508028f80d9dULL, 0xb8e319a27ab3f215ULL,\n\t0x31ad9c1151341a4dULL, 0x773c22a57bef5805ULL, 0x45c7561a07968633ULL,\n\t0xf913da9e249dbe36ULL, 0xda652d9b78a64c68ULL, 0x4c27a97f3bc334efULL,\n\t0x76621220e66b17f4ULL, 0x967743899acd7d0bULL, 0xf3ee5bcae0ed6782ULL,\n\t0x409f753600c879fcULL, 0x06d09a39b5926db6ULL, 0x6f83aeb0317ac588ULL,\n\t0x01e6ca4a86381f21ULL, 0x66ff3462d19f3025ULL, 0x72207c24ddfd3bfbULL,\n\t0x4af6b6d3e2ece2ebULL, 0x9c994dbec7ea08deULL, 0x49ace597b09a8bc4ULL,\n\t0xb38c4766cf0797baULL, 0x131b9373c57c2a75ULL, 0xb1822cce61931e58ULL,\n\t0x9d7555b909ba1c0cULL, 0x127fafdd937d11d2ULL, 0x29da3badc66d92e4ULL,\n\t0xa2c1d57154c2ecbcULL, 0x58c5134d82f6fe24ULL, 0x1c3ae3515b62274fULL,\n\t0xe907c82e01cb8126ULL, 0xf8ed091913e37fcbULL, 0x3249d8f9c80046c9ULL,\n\t0x80cf9bede388fb63ULL, 0x1881539a116cf19eULL, 0x5103f3f76bd52457ULL,\n\t0x15b7e6f5ae47f7a8ULL, 0xdbd7c6ded47e9ccfULL, 0x44e55c410228bb1aULL,\n\t0xb647d4255edb4e99ULL, 0x5d11882bb8aafc30ULL, 0xf5098bbb29d3212aULL,\n\t0x8fb5ea14e90296b3ULL, 0x677b942157dd025aULL, 0xfb58e7c0a390acb5ULL,\n\t0x89d3674c83bd4a01ULL, 0x9e2da4df4bf3b93bULL, 0xfcc41e328cab4829ULL,\n\t0x03f38c96ba582c52ULL, 0xcad1bdbd7fd85db2ULL, 0xbbb442c16082ae83ULL,\n\t0xb95fe86ba5da9ab0ULL, 0xb22e04673771a93fULL, 0x845358c9493152d8ULL,\n\t0xbe2a488697b4541eULL, 0x95a2dc2dd38e6966ULL, 0xc02c11ac923c852bULL,\n\t0x2388b1990df2a87bULL, 0x7c8008fa1b4f37beULL, 0x1f70d0c84d54e503ULL,\n\t0x5490adec7ece57d4ULL, 0x002b3c27d9063a3aULL, 0x7eaea3848030a2bfULL,\n\t0xc602326ded2003c0ULL, 0x83a7287d69a94086ULL, 0xc57a5fcb30f57a8aULL,\n\t0xb56844e479ebe779ULL, 0xa373b40f05dcbce9ULL, 0xd71a786e88570ee2ULL,\n\t0x879cbacdbde8f6a0ULL, 0x976ad1bcc164a32fULL, 0xab21e25e9666d78bULL,\n\t0x901063aae5e5c33cULL, 0x9818b34448698d90ULL, 0xe36487ae3e1e8abbULL,\n\t0xafbdf931893bdcb4ULL, 0x6345a0dc5fbbd519ULL, 0x8628fe269b9465caULL,\n\t0x1e5d01603f9c51ecULL, 0x4de44006a15049b7ULL, 0xbf6c70e5f776cbb1ULL,\n\t0x411218f2ef552bedULL, 0xcb0c0708705a36a3ULL, 0xe74d14754f986044ULL,\n\t0xcd56d9430ea8280eULL, 0xc12591d7535f5065ULL, 0xc83223f1720aef96ULL,\n\t0xc3a0396f7363a51fULL\n};\n\n\nstatic void tgr192_round(u64 * ra, u64 * rb, u64 * rc, u64 x, int mul)\n{\n\tu64 a = *ra;\n\tu64 b = *rb;\n\tu64 c = *rc;\n\n\tc ^= x;\n\ta -= sbox1[c         & 0xff] ^ sbox2[(c >> 16) & 0xff]\n\t   ^ sbox3[(c >> 32) & 0xff] ^ sbox4[(c >> 48) & 0xff];\n\tb += sbox4[(c >>  8) & 0xff] ^ sbox3[(c >> 24) & 0xff]\n\t   ^ sbox2[(c >> 40) & 0xff] ^ sbox1[(c >> 56) & 0xff];\n\tb *= mul;\n\n\t*ra = a;\n\t*rb = b;\n\t*rc = c;\n}\n\n\nstatic void tgr192_pass(u64 * ra, u64 * rb, u64 * rc, u64 * x, int mul)\n{\n\tu64 a = *ra;\n\tu64 b = *rb;\n\tu64 c = *rc;\n\n\ttgr192_round(&a, &b, &c, x[0], mul);\n\ttgr192_round(&b, &c, &a, x[1], mul);\n\ttgr192_round(&c, &a, &b, x[2], mul);\n\ttgr192_round(&a, &b, &c, x[3], mul);\n\ttgr192_round(&b, &c, &a, x[4], mul);\n\ttgr192_round(&c, &a, &b, x[5], mul);\n\ttgr192_round(&a, &b, &c, x[6], mul);\n\ttgr192_round(&b, &c, &a, x[7], mul);\n\n\t*ra = a;\n\t*rb = b;\n\t*rc = c;\n}\n\n\nstatic void tgr192_key_schedule(u64 * x)\n{\n\tx[0] -= x[7] ^ 0xa5a5a5a5a5a5a5a5ULL;\n\tx[1] ^= x[0];\n\tx[2] += x[1];\n\tx[3] -= x[2] ^ ((~x[1]) << 19);\n\tx[4] ^= x[3];\n\tx[5] += x[4];\n\tx[6] -= x[5] ^ ((~x[4]) >> 23);\n\tx[7] ^= x[6];\n\tx[0] += x[7];\n\tx[1] -= x[0] ^ ((~x[7]) << 19);\n\tx[2] ^= x[1];\n\tx[3] += x[2];\n\tx[4] -= x[3] ^ ((~x[2]) >> 23);\n\tx[5] ^= x[4];\n\tx[6] += x[5];\n\tx[7] -= x[6] ^ 0x0123456789abcdefULL;\n}\n\n\n/****************\n * Transform the message DATA which consists of 512 bytes (8 words)\n */\n\nstatic void tgr192_transform(struct tgr192_ctx *tctx, const u8 * data)\n{\n\tu64 a, b, c, aa, bb, cc;\n\tu64 x[8];\n\tint i;\n\tconst __le64 *ptr = (const __le64 *)data;\n\n\tfor (i = 0; i < 8; i++)\n\t\tx[i] = le64_to_cpu(ptr[i]);\n\n\t/* save */\n\ta = aa = tctx->a;\n\tb = bb = tctx->b;\n\tc = cc = tctx->c;\n\n\ttgr192_pass(&a, &b, &c, x, 5);\n\ttgr192_key_schedule(x);\n\ttgr192_pass(&c, &a, &b, x, 7);\n\ttgr192_key_schedule(x);\n\ttgr192_pass(&b, &c, &a, x, 9);\n\n\n\t/* feedforward */\n\ta ^= aa;\n\tb -= bb;\n\tc += cc;\n\t/* store */\n\ttctx->a = a;\n\ttctx->b = b;\n\ttctx->c = c;\n}\n\nstatic int tgr192_init(struct shash_desc *desc)\n{\n\tstruct tgr192_ctx *tctx = shash_desc_ctx(desc);\n\n\ttctx->a = 0x0123456789abcdefULL;\n\ttctx->b = 0xfedcba9876543210ULL;\n\ttctx->c = 0xf096a5b4c3b2e187ULL;\n\ttctx->nblocks = 0;\n\ttctx->count = 0;\n\n\treturn 0;\n}\n\n\n/* Update the message digest with the contents\n * of INBUF with length INLEN. */\nstatic int tgr192_update(struct shash_desc *desc, const u8 *inbuf,\n\t\t\t  unsigned int len)\n{\n\tstruct tgr192_ctx *tctx = shash_desc_ctx(desc);\n\n\tif (tctx->count == 64) {\t/* flush the buffer */\n\t\ttgr192_transform(tctx, tctx->hash);\n\t\ttctx->count = 0;\n\t\ttctx->nblocks++;\n\t}\n\tif (!inbuf) {\n\t\treturn 0;\n\t}\n\tif (tctx->count) {\n\t\tfor (; len && tctx->count < 64; len--) {\n\t\t\ttctx->hash[tctx->count++] = *inbuf++;\n\t\t}\n\t\ttgr192_update(desc, NULL, 0);\n\t\tif (!len) {\n\t\t\treturn 0;\n\t\t}\n\n\t}\n\n\twhile (len >= 64) {\n\t\ttgr192_transform(tctx, inbuf);\n\t\ttctx->count = 0;\n\t\ttctx->nblocks++;\n\t\tlen -= 64;\n\t\tinbuf += 64;\n\t}\n\tfor (; len && tctx->count < 64; len--) {\n\t\ttctx->hash[tctx->count++] = *inbuf++;\n\t}\n\n\treturn 0;\n}\n\n\n\n/* The routine terminates the computation */\nstatic int tgr192_final(struct shash_desc *desc, u8 * out)\n{\n\tstruct tgr192_ctx *tctx = shash_desc_ctx(desc);\n\t__be64 *dst = (__be64 *)out;\n\t__be64 *be64p;\n\t__le32 *le32p;\n\tu32 t, msb, lsb;\n\n\ttgr192_update(desc, NULL, 0); /* flush */ ;\n\n\tmsb = 0;\n\tt = tctx->nblocks;\n\tif ((lsb = t << 6) < t) { /* multiply by 64 to make a byte count */\n\t\tmsb++;\n\t}\n\tmsb += t >> 26;\n\tt = lsb;\n\tif ((lsb = t + tctx->count) < t) {\t/* add the count */\n\t\tmsb++;\n\t}\n\tt = lsb;\n\tif ((lsb = t << 3) < t)\t{ /* multiply by 8 to make a bit count */\n\t\tmsb++;\n\t}\n\tmsb += t >> 29;\n\n\tif (tctx->count < 56) {\t/* enough room */\n\t\ttctx->hash[tctx->count++] = 0x01;\t/* pad */\n\t\twhile (tctx->count < 56) {\n\t\t\ttctx->hash[tctx->count++] = 0;\t/* pad */\n\t\t}\n\t} else {\t\t/* need one extra block */\n\t\ttctx->hash[tctx->count++] = 0x01;\t/* pad character */\n\t\twhile (tctx->count < 64) {\n\t\t\ttctx->hash[tctx->count++] = 0;\n\t\t}\n\t\ttgr192_update(desc, NULL, 0); /* flush */ ;\n\t\tmemset(tctx->hash, 0, 56);    /* fill next block with zeroes */\n\t}\n\t/* append the 64 bit count */\n\tle32p = (__le32 *)&tctx->hash[56];\n\tle32p[0] = cpu_to_le32(lsb);\n\tle32p[1] = cpu_to_le32(msb);\n\n\ttgr192_transform(tctx, tctx->hash);\n\n\tbe64p = (__be64 *)tctx->hash;\n\tdst[0] = be64p[0] = cpu_to_be64(tctx->a);\n\tdst[1] = be64p[1] = cpu_to_be64(tctx->b);\n\tdst[2] = be64p[2] = cpu_to_be64(tctx->c);\n\n\treturn 0;\n}\n\nstatic int tgr160_final(struct shash_desc *desc, u8 * out)\n{\n\tu8 D[64];\n\n\ttgr192_final(desc, D);\n\tmemcpy(out, D, TGR160_DIGEST_SIZE);\n\tmemzero_explicit(D, TGR192_DIGEST_SIZE);\n\n\treturn 0;\n}\n\nstatic int tgr128_final(struct shash_desc *desc, u8 * out)\n{\n\tu8 D[64];\n\n\ttgr192_final(desc, D);\n\tmemcpy(out, D, TGR128_DIGEST_SIZE);\n\tmemzero_explicit(D, TGR192_DIGEST_SIZE);\n\n\treturn 0;\n}\n\nstatic struct shash_alg tgr_algs[3] = { {\n\t.digestsize\t=\tTGR192_DIGEST_SIZE,\n\t.init\t\t=\ttgr192_init,\n\t.update\t\t=\ttgr192_update,\n\t.final\t\t=\ttgr192_final,\n\t.descsize\t=\tsizeof(struct tgr192_ctx),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"tgr192\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tTGR192_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n}, {\n\t.digestsize\t=\tTGR160_DIGEST_SIZE,\n\t.init\t\t=\ttgr192_init,\n\t.update\t\t=\ttgr192_update,\n\t.final\t\t=\ttgr160_final,\n\t.descsize\t=\tsizeof(struct tgr192_ctx),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"tgr160\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tTGR192_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n}, {\n\t.digestsize\t=\tTGR128_DIGEST_SIZE,\n\t.init\t\t=\ttgr192_init,\n\t.update\t\t=\ttgr192_update,\n\t.final\t\t=\ttgr128_final,\n\t.descsize\t=\tsizeof(struct tgr192_ctx),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"tgr128\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tTGR192_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n} };\n\nstatic int __init tgr192_mod_init(void)\n{\n\treturn crypto_register_shashes(tgr_algs, ARRAY_SIZE(tgr_algs));\n}\n\nstatic void __exit tgr192_mod_fini(void)\n{\n\tcrypto_unregister_shashes(tgr_algs, ARRAY_SIZE(tgr_algs));\n}\n\nMODULE_ALIAS_CRYPTO(\"tgr160\");\nMODULE_ALIAS_CRYPTO(\"tgr128\");\n\nmodule_init(tgr192_mod_init);\nmodule_exit(tgr192_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Tiger Message Digest Algorithm\");\n", "/*\n * Twofish for CryptoAPI\n *\n * Originally Twofish for GPG\n * By Matthew Skala <mskala@ansuz.sooke.bc.ca>, July 26, 1998\n * 256-bit key length added March 20, 1999\n * Some modifications to reduce the text size by Werner Koch, April, 1998\n * Ported to the kerneli patch by Marc Mutz <Marc@Mutz.com>\n * Ported to CryptoAPI by Colin Slater <hoho@tacomeat.net>\n *\n * The original author has disclaimed all copyright interest in this\n * code and thus put it in the public domain. The subsequent authors \n * have put this under the GNU General Public License.\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n * \n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307\n * USA\n *\n * This code is a \"clean room\" implementation, written from the paper\n * _Twofish: A 128-Bit Block Cipher_ by Bruce Schneier, John Kelsey,\n * Doug Whiting, David Wagner, Chris Hall, and Niels Ferguson, available\n * through http://www.counterpane.com/twofish.html\n *\n * For background information on multiplication in finite fields, used for\n * the matrix operations in the key schedule, see the book _Contemporary\n * Abstract Algebra_ by Joseph A. Gallian, especially chapter 22 in the\n * Third Edition.\n */\n\n#include <asm/byteorder.h>\n#include <crypto/twofish.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/types.h>\n#include <linux/errno.h>\n#include <linux/crypto.h>\n#include <linux/bitops.h>\n\n/* Macros to compute the g() function in the encryption and decryption\n * rounds.  G1 is the straight g() function; G2 includes the 8-bit\n * rotation for the high 32-bit word. */\n\n#define G1(a) \\\n     (ctx->s[0][(a) & 0xFF]) ^ (ctx->s[1][((a) >> 8) & 0xFF]) \\\n   ^ (ctx->s[2][((a) >> 16) & 0xFF]) ^ (ctx->s[3][(a) >> 24])\n\n#define G2(b) \\\n     (ctx->s[1][(b) & 0xFF]) ^ (ctx->s[2][((b) >> 8) & 0xFF]) \\\n   ^ (ctx->s[3][((b) >> 16) & 0xFF]) ^ (ctx->s[0][(b) >> 24])\n\n/* Encryption and decryption Feistel rounds.  Each one calls the two g()\n * macros, does the PHT, and performs the XOR and the appropriate bit\n * rotations.  The parameters are the round number (used to select subkeys),\n * and the four 32-bit chunks of the text. */\n\n#define ENCROUND(n, a, b, c, d) \\\n   x = G1 (a); y = G2 (b); \\\n   x += y; y += x + ctx->k[2 * (n) + 1]; \\\n   (c) ^= x + ctx->k[2 * (n)]; \\\n   (c) = ror32((c), 1); \\\n   (d) = rol32((d), 1) ^ y\n\n#define DECROUND(n, a, b, c, d) \\\n   x = G1 (a); y = G2 (b); \\\n   x += y; y += x; \\\n   (d) ^= y + ctx->k[2 * (n) + 1]; \\\n   (d) = ror32((d), 1); \\\n   (c) = rol32((c), 1); \\\n   (c) ^= (x + ctx->k[2 * (n)])\n\n/* Encryption and decryption cycles; each one is simply two Feistel rounds\n * with the 32-bit chunks re-ordered to simulate the \"swap\" */\n\n#define ENCCYCLE(n) \\\n   ENCROUND (2 * (n), a, b, c, d); \\\n   ENCROUND (2 * (n) + 1, c, d, a, b)\n\n#define DECCYCLE(n) \\\n   DECROUND (2 * (n) + 1, c, d, a, b); \\\n   DECROUND (2 * (n), a, b, c, d)\n\n/* Macros to convert the input and output bytes into 32-bit words,\n * and simultaneously perform the whitening step.  INPACK packs word\n * number n into the variable named by x, using whitening subkey number m.\n * OUTUNPACK unpacks word number n from the variable named by x, using\n * whitening subkey number m. */\n\n#define INPACK(n, x, m) \\\n   x = le32_to_cpu(src[n]) ^ ctx->w[m]\n\n#define OUTUNPACK(n, x, m) \\\n   x ^= ctx->w[m]; \\\n   dst[n] = cpu_to_le32(x)\n\n\n\n/* Encrypt one block.  in and out may be the same. */\nstatic void twofish_encrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tstruct twofish_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *src = (const __le32 *)in;\n\t__le32 *dst = (__le32 *)out;\n\n\t/* The four 32-bit chunks of the text. */\n\tu32 a, b, c, d;\n\t\n\t/* Temporaries used by the round function. */\n\tu32 x, y;\n\n\t/* Input whitening and packing. */\n\tINPACK (0, a, 0);\n\tINPACK (1, b, 1);\n\tINPACK (2, c, 2);\n\tINPACK (3, d, 3);\n\t\n\t/* Encryption Feistel cycles. */\n\tENCCYCLE (0);\n\tENCCYCLE (1);\n\tENCCYCLE (2);\n\tENCCYCLE (3);\n\tENCCYCLE (4);\n\tENCCYCLE (5);\n\tENCCYCLE (6);\n\tENCCYCLE (7);\n\t\n\t/* Output whitening and unpacking. */\n\tOUTUNPACK (0, c, 4);\n\tOUTUNPACK (1, d, 5);\n\tOUTUNPACK (2, a, 6);\n\tOUTUNPACK (3, b, 7);\n\t\n}\n\n/* Decrypt one block.  in and out may be the same. */\nstatic void twofish_decrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tstruct twofish_ctx *ctx = crypto_tfm_ctx(tfm);\n\tconst __le32 *src = (const __le32 *)in;\n\t__le32 *dst = (__le32 *)out;\n  \n\t/* The four 32-bit chunks of the text. */\n\tu32 a, b, c, d;\n\t\n\t/* Temporaries used by the round function. */\n\tu32 x, y;\n\t\n\t/* Input whitening and packing. */\n\tINPACK (0, c, 4);\n\tINPACK (1, d, 5);\n\tINPACK (2, a, 6);\n\tINPACK (3, b, 7);\n\t\n\t/* Encryption Feistel cycles. */\n\tDECCYCLE (7);\n\tDECCYCLE (6);\n\tDECCYCLE (5);\n\tDECCYCLE (4);\n\tDECCYCLE (3);\n\tDECCYCLE (2);\n\tDECCYCLE (1);\n\tDECCYCLE (0);\n\n\t/* Output whitening and unpacking. */\n\tOUTUNPACK (0, a, 0);\n\tOUTUNPACK (1, b, 1);\n\tOUTUNPACK (2, c, 2);\n\tOUTUNPACK (3, d, 3);\n\n}\n\nstatic struct crypto_alg alg = {\n\t.cra_name           =   \"twofish\",\n\t.cra_driver_name    =   \"twofish-generic\",\n\t.cra_priority       =   100,\n\t.cra_flags          =   CRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize      =   TF_BLOCK_SIZE,\n\t.cra_ctxsize        =   sizeof(struct twofish_ctx),\n\t.cra_alignmask      =\t3,\n\t.cra_module         =   THIS_MODULE,\n\t.cra_u              =   { .cipher = {\n\t.cia_min_keysize    =   TF_MIN_KEY_SIZE,\n\t.cia_max_keysize    =   TF_MAX_KEY_SIZE,\n\t.cia_setkey         =   twofish_setkey,\n\t.cia_encrypt        =   twofish_encrypt,\n\t.cia_decrypt        =   twofish_decrypt } }\n};\n\nstatic int __init twofish_mod_init(void)\n{\n\treturn crypto_register_alg(&alg);\n}\n\nstatic void __exit twofish_mod_fini(void)\n{\n\tcrypto_unregister_alg(&alg);\n}\n\nmodule_init(twofish_mod_init);\nmodule_exit(twofish_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION (\"Twofish Cipher Algorithm\");\nMODULE_ALIAS_CRYPTO(\"twofish\");\n", "/*\n * Cryptographic API.\n *\n * Whirlpool hashing Algorithm\n *\n * The Whirlpool algorithm was developed by Paulo S. L. M. Barreto and\n * Vincent Rijmen.  It has been selected as one of cryptographic\n * primitives by the NESSIE project http://www.cryptonessie.org/\n *\n * The original authors have disclaimed all copyright interest in this\n * code and thus put it in the public domain. The subsequent authors\n * have put this under the GNU General Public License.\n *\n * By Aaron Grothe ajgrothe@yahoo.com, August 23, 2004\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n#include <crypto/internal/hash.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <asm/byteorder.h>\n#include <linux/types.h>\n\n#define WP512_DIGEST_SIZE 64\n#define WP384_DIGEST_SIZE 48\n#define WP256_DIGEST_SIZE 32\n\n#define WP512_BLOCK_SIZE  64\n#define WP512_LENGTHBYTES 32\n\n#define WHIRLPOOL_ROUNDS 10\n\nstruct wp512_ctx {\n\tu8  bitLength[WP512_LENGTHBYTES];\n\tu8  buffer[WP512_BLOCK_SIZE];\n\tint bufferBits;\n\tint bufferPos;\n\tu64 hash[WP512_DIGEST_SIZE/8];\n};\n\n/*\n * Though Whirlpool is endianness-neutral, the encryption tables are listed\n * in BIG-ENDIAN format, which is adopted throughout this implementation\n * (but little-endian notation would be equally suitable if consistently\n * employed).\n */\n\nstatic const u64 C0[256] = {\n\t0x18186018c07830d8ULL, 0x23238c2305af4626ULL, 0xc6c63fc67ef991b8ULL,\n\t0xe8e887e8136fcdfbULL, 0x878726874ca113cbULL, 0xb8b8dab8a9626d11ULL,\n\t0x0101040108050209ULL, 0x4f4f214f426e9e0dULL, 0x3636d836adee6c9bULL,\n\t0xa6a6a2a6590451ffULL, 0xd2d26fd2debdb90cULL, 0xf5f5f3f5fb06f70eULL,\n\t0x7979f979ef80f296ULL, 0x6f6fa16f5fcede30ULL, 0x91917e91fcef3f6dULL,\n\t0x52525552aa07a4f8ULL, 0x60609d6027fdc047ULL, 0xbcbccabc89766535ULL,\n\t0x9b9b569baccd2b37ULL, 0x8e8e028e048c018aULL, 0xa3a3b6a371155bd2ULL,\n\t0x0c0c300c603c186cULL, 0x7b7bf17bff8af684ULL, 0x3535d435b5e16a80ULL,\n\t0x1d1d741de8693af5ULL, 0xe0e0a7e05347ddb3ULL, 0xd7d77bd7f6acb321ULL,\n\t0xc2c22fc25eed999cULL, 0x2e2eb82e6d965c43ULL, 0x4b4b314b627a9629ULL,\n\t0xfefedffea321e15dULL, 0x575741578216aed5ULL, 0x15155415a8412abdULL,\n\t0x7777c1779fb6eee8ULL, 0x3737dc37a5eb6e92ULL, 0xe5e5b3e57b56d79eULL,\n\t0x9f9f469f8cd92313ULL, 0xf0f0e7f0d317fd23ULL, 0x4a4a354a6a7f9420ULL,\n\t0xdada4fda9e95a944ULL, 0x58587d58fa25b0a2ULL, 0xc9c903c906ca8fcfULL,\n\t0x2929a429558d527cULL, 0x0a0a280a5022145aULL, 0xb1b1feb1e14f7f50ULL,\n\t0xa0a0baa0691a5dc9ULL, 0x6b6bb16b7fdad614ULL, 0x85852e855cab17d9ULL,\n\t0xbdbdcebd8173673cULL, 0x5d5d695dd234ba8fULL, 0x1010401080502090ULL,\n\t0xf4f4f7f4f303f507ULL, 0xcbcb0bcb16c08bddULL, 0x3e3ef83eedc67cd3ULL,\n\t0x0505140528110a2dULL, 0x676781671fe6ce78ULL, 0xe4e4b7e47353d597ULL,\n\t0x27279c2725bb4e02ULL, 0x4141194132588273ULL, 0x8b8b168b2c9d0ba7ULL,\n\t0xa7a7a6a7510153f6ULL, 0x7d7de97dcf94fab2ULL, 0x95956e95dcfb3749ULL,\n\t0xd8d847d88e9fad56ULL, 0xfbfbcbfb8b30eb70ULL, 0xeeee9fee2371c1cdULL,\n\t0x7c7ced7cc791f8bbULL, 0x6666856617e3cc71ULL, 0xdddd53dda68ea77bULL,\n\t0x17175c17b84b2eafULL, 0x4747014702468e45ULL, 0x9e9e429e84dc211aULL,\n\t0xcaca0fca1ec589d4ULL, 0x2d2db42d75995a58ULL, 0xbfbfc6bf9179632eULL,\n\t0x07071c07381b0e3fULL, 0xadad8ead012347acULL, 0x5a5a755aea2fb4b0ULL,\n\t0x838336836cb51befULL, 0x3333cc3385ff66b6ULL, 0x636391633ff2c65cULL,\n\t0x02020802100a0412ULL, 0xaaaa92aa39384993ULL, 0x7171d971afa8e2deULL,\n\t0xc8c807c80ecf8dc6ULL, 0x19196419c87d32d1ULL, 0x494939497270923bULL,\n\t0xd9d943d9869aaf5fULL, 0xf2f2eff2c31df931ULL, 0xe3e3abe34b48dba8ULL,\n\t0x5b5b715be22ab6b9ULL, 0x88881a8834920dbcULL, 0x9a9a529aa4c8293eULL,\n\t0x262698262dbe4c0bULL, 0x3232c8328dfa64bfULL, 0xb0b0fab0e94a7d59ULL,\n\t0xe9e983e91b6acff2ULL, 0x0f0f3c0f78331e77ULL, 0xd5d573d5e6a6b733ULL,\n\t0x80803a8074ba1df4ULL, 0xbebec2be997c6127ULL, 0xcdcd13cd26de87ebULL,\n\t0x3434d034bde46889ULL, 0x48483d487a759032ULL, 0xffffdbffab24e354ULL,\n\t0x7a7af57af78ff48dULL, 0x90907a90f4ea3d64ULL, 0x5f5f615fc23ebe9dULL,\n\t0x202080201da0403dULL, 0x6868bd6867d5d00fULL, 0x1a1a681ad07234caULL,\n\t0xaeae82ae192c41b7ULL, 0xb4b4eab4c95e757dULL, 0x54544d549a19a8ceULL,\n\t0x93937693ece53b7fULL, 0x222288220daa442fULL, 0x64648d6407e9c863ULL,\n\t0xf1f1e3f1db12ff2aULL, 0x7373d173bfa2e6ccULL, 0x12124812905a2482ULL,\n\t0x40401d403a5d807aULL, 0x0808200840281048ULL, 0xc3c32bc356e89b95ULL,\n\t0xecec97ec337bc5dfULL, 0xdbdb4bdb9690ab4dULL, 0xa1a1bea1611f5fc0ULL,\n\t0x8d8d0e8d1c830791ULL, 0x3d3df43df5c97ac8ULL, 0x97976697ccf1335bULL,\n\t0x0000000000000000ULL, 0xcfcf1bcf36d483f9ULL, 0x2b2bac2b4587566eULL,\n\t0x7676c57697b3ece1ULL, 0x8282328264b019e6ULL, 0xd6d67fd6fea9b128ULL,\n\t0x1b1b6c1bd87736c3ULL, 0xb5b5eeb5c15b7774ULL, 0xafaf86af112943beULL,\n\t0x6a6ab56a77dfd41dULL, 0x50505d50ba0da0eaULL, 0x45450945124c8a57ULL,\n\t0xf3f3ebf3cb18fb38ULL, 0x3030c0309df060adULL, 0xefef9bef2b74c3c4ULL,\n\t0x3f3ffc3fe5c37edaULL, 0x55554955921caac7ULL, 0xa2a2b2a2791059dbULL,\n\t0xeaea8fea0365c9e9ULL, 0x656589650fecca6aULL, 0xbabad2bab9686903ULL,\n\t0x2f2fbc2f65935e4aULL, 0xc0c027c04ee79d8eULL, 0xdede5fdebe81a160ULL,\n\t0x1c1c701ce06c38fcULL, 0xfdfdd3fdbb2ee746ULL, 0x4d4d294d52649a1fULL,\n\t0x92927292e4e03976ULL, 0x7575c9758fbceafaULL, 0x06061806301e0c36ULL,\n\t0x8a8a128a249809aeULL, 0xb2b2f2b2f940794bULL, 0xe6e6bfe66359d185ULL,\n\t0x0e0e380e70361c7eULL, 0x1f1f7c1ff8633ee7ULL, 0x6262956237f7c455ULL,\n\t0xd4d477d4eea3b53aULL, 0xa8a89aa829324d81ULL, 0x96966296c4f43152ULL,\n\t0xf9f9c3f99b3aef62ULL, 0xc5c533c566f697a3ULL, 0x2525942535b14a10ULL,\n\t0x59597959f220b2abULL, 0x84842a8454ae15d0ULL, 0x7272d572b7a7e4c5ULL,\n\t0x3939e439d5dd72ecULL, 0x4c4c2d4c5a619816ULL, 0x5e5e655eca3bbc94ULL,\n\t0x7878fd78e785f09fULL, 0x3838e038ddd870e5ULL, 0x8c8c0a8c14860598ULL,\n\t0xd1d163d1c6b2bf17ULL, 0xa5a5aea5410b57e4ULL, 0xe2e2afe2434dd9a1ULL,\n\t0x616199612ff8c24eULL, 0xb3b3f6b3f1457b42ULL, 0x2121842115a54234ULL,\n\t0x9c9c4a9c94d62508ULL, 0x1e1e781ef0663ceeULL, 0x4343114322528661ULL,\n\t0xc7c73bc776fc93b1ULL, 0xfcfcd7fcb32be54fULL, 0x0404100420140824ULL,\n\t0x51515951b208a2e3ULL, 0x99995e99bcc72f25ULL, 0x6d6da96d4fc4da22ULL,\n\t0x0d0d340d68391a65ULL, 0xfafacffa8335e979ULL, 0xdfdf5bdfb684a369ULL,\n\t0x7e7ee57ed79bfca9ULL, 0x242490243db44819ULL, 0x3b3bec3bc5d776feULL,\n\t0xabab96ab313d4b9aULL, 0xcece1fce3ed181f0ULL, 0x1111441188552299ULL,\n\t0x8f8f068f0c890383ULL, 0x4e4e254e4a6b9c04ULL, 0xb7b7e6b7d1517366ULL,\n\t0xebeb8beb0b60cbe0ULL, 0x3c3cf03cfdcc78c1ULL, 0x81813e817cbf1ffdULL,\n\t0x94946a94d4fe3540ULL, 0xf7f7fbf7eb0cf31cULL, 0xb9b9deb9a1676f18ULL,\n\t0x13134c13985f268bULL, 0x2c2cb02c7d9c5851ULL, 0xd3d36bd3d6b8bb05ULL,\n\t0xe7e7bbe76b5cd38cULL, 0x6e6ea56e57cbdc39ULL, 0xc4c437c46ef395aaULL,\n\t0x03030c03180f061bULL, 0x565645568a13acdcULL, 0x44440d441a49885eULL,\n\t0x7f7fe17fdf9efea0ULL, 0xa9a99ea921374f88ULL, 0x2a2aa82a4d825467ULL,\n\t0xbbbbd6bbb16d6b0aULL, 0xc1c123c146e29f87ULL, 0x53535153a202a6f1ULL,\n\t0xdcdc57dcae8ba572ULL, 0x0b0b2c0b58271653ULL, 0x9d9d4e9d9cd32701ULL,\n\t0x6c6cad6c47c1d82bULL, 0x3131c43195f562a4ULL, 0x7474cd7487b9e8f3ULL,\n\t0xf6f6fff6e309f115ULL, 0x464605460a438c4cULL, 0xacac8aac092645a5ULL,\n\t0x89891e893c970fb5ULL, 0x14145014a04428b4ULL, 0xe1e1a3e15b42dfbaULL,\n\t0x16165816b04e2ca6ULL, 0x3a3ae83acdd274f7ULL, 0x6969b9696fd0d206ULL,\n\t0x09092409482d1241ULL, 0x7070dd70a7ade0d7ULL, 0xb6b6e2b6d954716fULL,\n\t0xd0d067d0ceb7bd1eULL, 0xeded93ed3b7ec7d6ULL, 0xcccc17cc2edb85e2ULL,\n\t0x424215422a578468ULL, 0x98985a98b4c22d2cULL, 0xa4a4aaa4490e55edULL,\n\t0x2828a0285d885075ULL, 0x5c5c6d5cda31b886ULL, 0xf8f8c7f8933fed6bULL,\n\t0x8686228644a411c2ULL,\n};\n\nstatic const u64 C1[256] = {\n\t0xd818186018c07830ULL, 0x2623238c2305af46ULL, 0xb8c6c63fc67ef991ULL,\n\t0xfbe8e887e8136fcdULL, 0xcb878726874ca113ULL, 0x11b8b8dab8a9626dULL,\n\t0x0901010401080502ULL, 0x0d4f4f214f426e9eULL, 0x9b3636d836adee6cULL,\n\t0xffa6a6a2a6590451ULL, 0x0cd2d26fd2debdb9ULL, 0x0ef5f5f3f5fb06f7ULL,\n\t0x967979f979ef80f2ULL, 0x306f6fa16f5fcedeULL, 0x6d91917e91fcef3fULL,\n\t0xf852525552aa07a4ULL, 0x4760609d6027fdc0ULL, 0x35bcbccabc897665ULL,\n\t0x379b9b569baccd2bULL, 0x8a8e8e028e048c01ULL, 0xd2a3a3b6a371155bULL,\n\t0x6c0c0c300c603c18ULL, 0x847b7bf17bff8af6ULL, 0x803535d435b5e16aULL,\n\t0xf51d1d741de8693aULL, 0xb3e0e0a7e05347ddULL, 0x21d7d77bd7f6acb3ULL,\n\t0x9cc2c22fc25eed99ULL, 0x432e2eb82e6d965cULL, 0x294b4b314b627a96ULL,\n\t0x5dfefedffea321e1ULL, 0xd5575741578216aeULL, 0xbd15155415a8412aULL,\n\t0xe87777c1779fb6eeULL, 0x923737dc37a5eb6eULL, 0x9ee5e5b3e57b56d7ULL,\n\t0x139f9f469f8cd923ULL, 0x23f0f0e7f0d317fdULL, 0x204a4a354a6a7f94ULL,\n\t0x44dada4fda9e95a9ULL, 0xa258587d58fa25b0ULL, 0xcfc9c903c906ca8fULL,\n\t0x7c2929a429558d52ULL, 0x5a0a0a280a502214ULL, 0x50b1b1feb1e14f7fULL,\n\t0xc9a0a0baa0691a5dULL, 0x146b6bb16b7fdad6ULL, 0xd985852e855cab17ULL,\n\t0x3cbdbdcebd817367ULL, 0x8f5d5d695dd234baULL, 0x9010104010805020ULL,\n\t0x07f4f4f7f4f303f5ULL, 0xddcbcb0bcb16c08bULL, 0xd33e3ef83eedc67cULL,\n\t0x2d0505140528110aULL, 0x78676781671fe6ceULL, 0x97e4e4b7e47353d5ULL,\n\t0x0227279c2725bb4eULL, 0x7341411941325882ULL, 0xa78b8b168b2c9d0bULL,\n\t0xf6a7a7a6a7510153ULL, 0xb27d7de97dcf94faULL, 0x4995956e95dcfb37ULL,\n\t0x56d8d847d88e9fadULL, 0x70fbfbcbfb8b30ebULL, 0xcdeeee9fee2371c1ULL,\n\t0xbb7c7ced7cc791f8ULL, 0x716666856617e3ccULL, 0x7bdddd53dda68ea7ULL,\n\t0xaf17175c17b84b2eULL, 0x454747014702468eULL, 0x1a9e9e429e84dc21ULL,\n\t0xd4caca0fca1ec589ULL, 0x582d2db42d75995aULL, 0x2ebfbfc6bf917963ULL,\n\t0x3f07071c07381b0eULL, 0xacadad8ead012347ULL, 0xb05a5a755aea2fb4ULL,\n\t0xef838336836cb51bULL, 0xb63333cc3385ff66ULL, 0x5c636391633ff2c6ULL,\n\t0x1202020802100a04ULL, 0x93aaaa92aa393849ULL, 0xde7171d971afa8e2ULL,\n\t0xc6c8c807c80ecf8dULL, 0xd119196419c87d32ULL, 0x3b49493949727092ULL,\n\t0x5fd9d943d9869aafULL, 0x31f2f2eff2c31df9ULL, 0xa8e3e3abe34b48dbULL,\n\t0xb95b5b715be22ab6ULL, 0xbc88881a8834920dULL, 0x3e9a9a529aa4c829ULL,\n\t0x0b262698262dbe4cULL, 0xbf3232c8328dfa64ULL, 0x59b0b0fab0e94a7dULL,\n\t0xf2e9e983e91b6acfULL, 0x770f0f3c0f78331eULL, 0x33d5d573d5e6a6b7ULL,\n\t0xf480803a8074ba1dULL, 0x27bebec2be997c61ULL, 0xebcdcd13cd26de87ULL,\n\t0x893434d034bde468ULL, 0x3248483d487a7590ULL, 0x54ffffdbffab24e3ULL,\n\t0x8d7a7af57af78ff4ULL, 0x6490907a90f4ea3dULL, 0x9d5f5f615fc23ebeULL,\n\t0x3d202080201da040ULL, 0x0f6868bd6867d5d0ULL, 0xca1a1a681ad07234ULL,\n\t0xb7aeae82ae192c41ULL, 0x7db4b4eab4c95e75ULL, 0xce54544d549a19a8ULL,\n\t0x7f93937693ece53bULL, 0x2f222288220daa44ULL, 0x6364648d6407e9c8ULL,\n\t0x2af1f1e3f1db12ffULL, 0xcc7373d173bfa2e6ULL, 0x8212124812905a24ULL,\n\t0x7a40401d403a5d80ULL, 0x4808082008402810ULL, 0x95c3c32bc356e89bULL,\n\t0xdfecec97ec337bc5ULL, 0x4ddbdb4bdb9690abULL, 0xc0a1a1bea1611f5fULL,\n\t0x918d8d0e8d1c8307ULL, 0xc83d3df43df5c97aULL, 0x5b97976697ccf133ULL,\n\t0x0000000000000000ULL, 0xf9cfcf1bcf36d483ULL, 0x6e2b2bac2b458756ULL,\n\t0xe17676c57697b3ecULL, 0xe68282328264b019ULL, 0x28d6d67fd6fea9b1ULL,\n\t0xc31b1b6c1bd87736ULL, 0x74b5b5eeb5c15b77ULL, 0xbeafaf86af112943ULL,\n\t0x1d6a6ab56a77dfd4ULL, 0xea50505d50ba0da0ULL, 0x5745450945124c8aULL,\n\t0x38f3f3ebf3cb18fbULL, 0xad3030c0309df060ULL, 0xc4efef9bef2b74c3ULL,\n\t0xda3f3ffc3fe5c37eULL, 0xc755554955921caaULL, 0xdba2a2b2a2791059ULL,\n\t0xe9eaea8fea0365c9ULL, 0x6a656589650feccaULL, 0x03babad2bab96869ULL,\n\t0x4a2f2fbc2f65935eULL, 0x8ec0c027c04ee79dULL, 0x60dede5fdebe81a1ULL,\n\t0xfc1c1c701ce06c38ULL, 0x46fdfdd3fdbb2ee7ULL, 0x1f4d4d294d52649aULL,\n\t0x7692927292e4e039ULL, 0xfa7575c9758fbceaULL, 0x3606061806301e0cULL,\n\t0xae8a8a128a249809ULL, 0x4bb2b2f2b2f94079ULL, 0x85e6e6bfe66359d1ULL,\n\t0x7e0e0e380e70361cULL, 0xe71f1f7c1ff8633eULL, 0x556262956237f7c4ULL,\n\t0x3ad4d477d4eea3b5ULL, 0x81a8a89aa829324dULL, 0x5296966296c4f431ULL,\n\t0x62f9f9c3f99b3aefULL, 0xa3c5c533c566f697ULL, 0x102525942535b14aULL,\n\t0xab59597959f220b2ULL, 0xd084842a8454ae15ULL, 0xc57272d572b7a7e4ULL,\n\t0xec3939e439d5dd72ULL, 0x164c4c2d4c5a6198ULL, 0x945e5e655eca3bbcULL,\n\t0x9f7878fd78e785f0ULL, 0xe53838e038ddd870ULL, 0x988c8c0a8c148605ULL,\n\t0x17d1d163d1c6b2bfULL, 0xe4a5a5aea5410b57ULL, 0xa1e2e2afe2434dd9ULL,\n\t0x4e616199612ff8c2ULL, 0x42b3b3f6b3f1457bULL, 0x342121842115a542ULL,\n\t0x089c9c4a9c94d625ULL, 0xee1e1e781ef0663cULL, 0x6143431143225286ULL,\n\t0xb1c7c73bc776fc93ULL, 0x4ffcfcd7fcb32be5ULL, 0x2404041004201408ULL,\n\t0xe351515951b208a2ULL, 0x2599995e99bcc72fULL, 0x226d6da96d4fc4daULL,\n\t0x650d0d340d68391aULL, 0x79fafacffa8335e9ULL, 0x69dfdf5bdfb684a3ULL,\n\t0xa97e7ee57ed79bfcULL, 0x19242490243db448ULL, 0xfe3b3bec3bc5d776ULL,\n\t0x9aabab96ab313d4bULL, 0xf0cece1fce3ed181ULL, 0x9911114411885522ULL,\n\t0x838f8f068f0c8903ULL, 0x044e4e254e4a6b9cULL, 0x66b7b7e6b7d15173ULL,\n\t0xe0ebeb8beb0b60cbULL, 0xc13c3cf03cfdcc78ULL, 0xfd81813e817cbf1fULL,\n\t0x4094946a94d4fe35ULL, 0x1cf7f7fbf7eb0cf3ULL, 0x18b9b9deb9a1676fULL,\n\t0x8b13134c13985f26ULL, 0x512c2cb02c7d9c58ULL, 0x05d3d36bd3d6b8bbULL,\n\t0x8ce7e7bbe76b5cd3ULL, 0x396e6ea56e57cbdcULL, 0xaac4c437c46ef395ULL,\n\t0x1b03030c03180f06ULL, 0xdc565645568a13acULL, 0x5e44440d441a4988ULL,\n\t0xa07f7fe17fdf9efeULL, 0x88a9a99ea921374fULL, 0x672a2aa82a4d8254ULL,\n\t0x0abbbbd6bbb16d6bULL, 0x87c1c123c146e29fULL, 0xf153535153a202a6ULL,\n\t0x72dcdc57dcae8ba5ULL, 0x530b0b2c0b582716ULL, 0x019d9d4e9d9cd327ULL,\n\t0x2b6c6cad6c47c1d8ULL, 0xa43131c43195f562ULL, 0xf37474cd7487b9e8ULL,\n\t0x15f6f6fff6e309f1ULL, 0x4c464605460a438cULL, 0xa5acac8aac092645ULL,\n\t0xb589891e893c970fULL, 0xb414145014a04428ULL, 0xbae1e1a3e15b42dfULL,\n\t0xa616165816b04e2cULL, 0xf73a3ae83acdd274ULL, 0x066969b9696fd0d2ULL,\n\t0x4109092409482d12ULL, 0xd77070dd70a7ade0ULL, 0x6fb6b6e2b6d95471ULL,\n\t0x1ed0d067d0ceb7bdULL, 0xd6eded93ed3b7ec7ULL, 0xe2cccc17cc2edb85ULL,\n\t0x68424215422a5784ULL, 0x2c98985a98b4c22dULL, 0xeda4a4aaa4490e55ULL,\n\t0x752828a0285d8850ULL, 0x865c5c6d5cda31b8ULL, 0x6bf8f8c7f8933fedULL,\n\t0xc28686228644a411ULL,\n};\n\nstatic const u64 C2[256] = {\n\t0x30d818186018c078ULL, 0x462623238c2305afULL, 0x91b8c6c63fc67ef9ULL,\n\t0xcdfbe8e887e8136fULL, 0x13cb878726874ca1ULL, 0x6d11b8b8dab8a962ULL,\n\t0x0209010104010805ULL, 0x9e0d4f4f214f426eULL, 0x6c9b3636d836adeeULL,\n\t0x51ffa6a6a2a65904ULL, 0xb90cd2d26fd2debdULL, 0xf70ef5f5f3f5fb06ULL,\n\t0xf2967979f979ef80ULL, 0xde306f6fa16f5fceULL, 0x3f6d91917e91fcefULL,\n\t0xa4f852525552aa07ULL, 0xc04760609d6027fdULL, 0x6535bcbccabc8976ULL,\n\t0x2b379b9b569baccdULL, 0x018a8e8e028e048cULL, 0x5bd2a3a3b6a37115ULL,\n\t0x186c0c0c300c603cULL, 0xf6847b7bf17bff8aULL, 0x6a803535d435b5e1ULL,\n\t0x3af51d1d741de869ULL, 0xddb3e0e0a7e05347ULL, 0xb321d7d77bd7f6acULL,\n\t0x999cc2c22fc25eedULL, 0x5c432e2eb82e6d96ULL, 0x96294b4b314b627aULL,\n\t0xe15dfefedffea321ULL, 0xaed5575741578216ULL, 0x2abd15155415a841ULL,\n\t0xeee87777c1779fb6ULL, 0x6e923737dc37a5ebULL, 0xd79ee5e5b3e57b56ULL,\n\t0x23139f9f469f8cd9ULL, 0xfd23f0f0e7f0d317ULL, 0x94204a4a354a6a7fULL,\n\t0xa944dada4fda9e95ULL, 0xb0a258587d58fa25ULL, 0x8fcfc9c903c906caULL,\n\t0x527c2929a429558dULL, 0x145a0a0a280a5022ULL, 0x7f50b1b1feb1e14fULL,\n\t0x5dc9a0a0baa0691aULL, 0xd6146b6bb16b7fdaULL, 0x17d985852e855cabULL,\n\t0x673cbdbdcebd8173ULL, 0xba8f5d5d695dd234ULL, 0x2090101040108050ULL,\n\t0xf507f4f4f7f4f303ULL, 0x8bddcbcb0bcb16c0ULL, 0x7cd33e3ef83eedc6ULL,\n\t0x0a2d050514052811ULL, 0xce78676781671fe6ULL, 0xd597e4e4b7e47353ULL,\n\t0x4e0227279c2725bbULL, 0x8273414119413258ULL, 0x0ba78b8b168b2c9dULL,\n\t0x53f6a7a7a6a75101ULL, 0xfab27d7de97dcf94ULL, 0x374995956e95dcfbULL,\n\t0xad56d8d847d88e9fULL, 0xeb70fbfbcbfb8b30ULL, 0xc1cdeeee9fee2371ULL,\n\t0xf8bb7c7ced7cc791ULL, 0xcc716666856617e3ULL, 0xa77bdddd53dda68eULL,\n\t0x2eaf17175c17b84bULL, 0x8e45474701470246ULL, 0x211a9e9e429e84dcULL,\n\t0x89d4caca0fca1ec5ULL, 0x5a582d2db42d7599ULL, 0x632ebfbfc6bf9179ULL,\n\t0x0e3f07071c07381bULL, 0x47acadad8ead0123ULL, 0xb4b05a5a755aea2fULL,\n\t0x1bef838336836cb5ULL, 0x66b63333cc3385ffULL, 0xc65c636391633ff2ULL,\n\t0x041202020802100aULL, 0x4993aaaa92aa3938ULL, 0xe2de7171d971afa8ULL,\n\t0x8dc6c8c807c80ecfULL, 0x32d119196419c87dULL, 0x923b494939497270ULL,\n\t0xaf5fd9d943d9869aULL, 0xf931f2f2eff2c31dULL, 0xdba8e3e3abe34b48ULL,\n\t0xb6b95b5b715be22aULL, 0x0dbc88881a883492ULL, 0x293e9a9a529aa4c8ULL,\n\t0x4c0b262698262dbeULL, 0x64bf3232c8328dfaULL, 0x7d59b0b0fab0e94aULL,\n\t0xcff2e9e983e91b6aULL, 0x1e770f0f3c0f7833ULL, 0xb733d5d573d5e6a6ULL,\n\t0x1df480803a8074baULL, 0x6127bebec2be997cULL, 0x87ebcdcd13cd26deULL,\n\t0x68893434d034bde4ULL, 0x903248483d487a75ULL, 0xe354ffffdbffab24ULL,\n\t0xf48d7a7af57af78fULL, 0x3d6490907a90f4eaULL, 0xbe9d5f5f615fc23eULL,\n\t0x403d202080201da0ULL, 0xd00f6868bd6867d5ULL, 0x34ca1a1a681ad072ULL,\n\t0x41b7aeae82ae192cULL, 0x757db4b4eab4c95eULL, 0xa8ce54544d549a19ULL,\n\t0x3b7f93937693ece5ULL, 0x442f222288220daaULL, 0xc86364648d6407e9ULL,\n\t0xff2af1f1e3f1db12ULL, 0xe6cc7373d173bfa2ULL, 0x248212124812905aULL,\n\t0x807a40401d403a5dULL, 0x1048080820084028ULL, 0x9b95c3c32bc356e8ULL,\n\t0xc5dfecec97ec337bULL, 0xab4ddbdb4bdb9690ULL, 0x5fc0a1a1bea1611fULL,\n\t0x07918d8d0e8d1c83ULL, 0x7ac83d3df43df5c9ULL, 0x335b97976697ccf1ULL,\n\t0x0000000000000000ULL, 0x83f9cfcf1bcf36d4ULL, 0x566e2b2bac2b4587ULL,\n\t0xece17676c57697b3ULL, 0x19e68282328264b0ULL, 0xb128d6d67fd6fea9ULL,\n\t0x36c31b1b6c1bd877ULL, 0x7774b5b5eeb5c15bULL, 0x43beafaf86af1129ULL,\n\t0xd41d6a6ab56a77dfULL, 0xa0ea50505d50ba0dULL, 0x8a5745450945124cULL,\n\t0xfb38f3f3ebf3cb18ULL, 0x60ad3030c0309df0ULL, 0xc3c4efef9bef2b74ULL,\n\t0x7eda3f3ffc3fe5c3ULL, 0xaac755554955921cULL, 0x59dba2a2b2a27910ULL,\n\t0xc9e9eaea8fea0365ULL, 0xca6a656589650fecULL, 0x6903babad2bab968ULL,\n\t0x5e4a2f2fbc2f6593ULL, 0x9d8ec0c027c04ee7ULL, 0xa160dede5fdebe81ULL,\n\t0x38fc1c1c701ce06cULL, 0xe746fdfdd3fdbb2eULL, 0x9a1f4d4d294d5264ULL,\n\t0x397692927292e4e0ULL, 0xeafa7575c9758fbcULL, 0x0c3606061806301eULL,\n\t0x09ae8a8a128a2498ULL, 0x794bb2b2f2b2f940ULL, 0xd185e6e6bfe66359ULL,\n\t0x1c7e0e0e380e7036ULL, 0x3ee71f1f7c1ff863ULL, 0xc4556262956237f7ULL,\n\t0xb53ad4d477d4eea3ULL, 0x4d81a8a89aa82932ULL, 0x315296966296c4f4ULL,\n\t0xef62f9f9c3f99b3aULL, 0x97a3c5c533c566f6ULL, 0x4a102525942535b1ULL,\n\t0xb2ab59597959f220ULL, 0x15d084842a8454aeULL, 0xe4c57272d572b7a7ULL,\n\t0x72ec3939e439d5ddULL, 0x98164c4c2d4c5a61ULL, 0xbc945e5e655eca3bULL,\n\t0xf09f7878fd78e785ULL, 0x70e53838e038ddd8ULL, 0x05988c8c0a8c1486ULL,\n\t0xbf17d1d163d1c6b2ULL, 0x57e4a5a5aea5410bULL, 0xd9a1e2e2afe2434dULL,\n\t0xc24e616199612ff8ULL, 0x7b42b3b3f6b3f145ULL, 0x42342121842115a5ULL,\n\t0x25089c9c4a9c94d6ULL, 0x3cee1e1e781ef066ULL, 0x8661434311432252ULL,\n\t0x93b1c7c73bc776fcULL, 0xe54ffcfcd7fcb32bULL, 0x0824040410042014ULL,\n\t0xa2e351515951b208ULL, 0x2f2599995e99bcc7ULL, 0xda226d6da96d4fc4ULL,\n\t0x1a650d0d340d6839ULL, 0xe979fafacffa8335ULL, 0xa369dfdf5bdfb684ULL,\n\t0xfca97e7ee57ed79bULL, 0x4819242490243db4ULL, 0x76fe3b3bec3bc5d7ULL,\n\t0x4b9aabab96ab313dULL, 0x81f0cece1fce3ed1ULL, 0x2299111144118855ULL,\n\t0x03838f8f068f0c89ULL, 0x9c044e4e254e4a6bULL, 0x7366b7b7e6b7d151ULL,\n\t0xcbe0ebeb8beb0b60ULL, 0x78c13c3cf03cfdccULL, 0x1ffd81813e817cbfULL,\n\t0x354094946a94d4feULL, 0xf31cf7f7fbf7eb0cULL, 0x6f18b9b9deb9a167ULL,\n\t0x268b13134c13985fULL, 0x58512c2cb02c7d9cULL, 0xbb05d3d36bd3d6b8ULL,\n\t0xd38ce7e7bbe76b5cULL, 0xdc396e6ea56e57cbULL, 0x95aac4c437c46ef3ULL,\n\t0x061b03030c03180fULL, 0xacdc565645568a13ULL, 0x885e44440d441a49ULL,\n\t0xfea07f7fe17fdf9eULL, 0x4f88a9a99ea92137ULL, 0x54672a2aa82a4d82ULL,\n\t0x6b0abbbbd6bbb16dULL, 0x9f87c1c123c146e2ULL, 0xa6f153535153a202ULL,\n\t0xa572dcdc57dcae8bULL, 0x16530b0b2c0b5827ULL, 0x27019d9d4e9d9cd3ULL,\n\t0xd82b6c6cad6c47c1ULL, 0x62a43131c43195f5ULL, 0xe8f37474cd7487b9ULL,\n\t0xf115f6f6fff6e309ULL, 0x8c4c464605460a43ULL, 0x45a5acac8aac0926ULL,\n\t0x0fb589891e893c97ULL, 0x28b414145014a044ULL, 0xdfbae1e1a3e15b42ULL,\n\t0x2ca616165816b04eULL, 0x74f73a3ae83acdd2ULL, 0xd2066969b9696fd0ULL,\n\t0x124109092409482dULL, 0xe0d77070dd70a7adULL, 0x716fb6b6e2b6d954ULL,\n\t0xbd1ed0d067d0ceb7ULL, 0xc7d6eded93ed3b7eULL, 0x85e2cccc17cc2edbULL,\n\t0x8468424215422a57ULL, 0x2d2c98985a98b4c2ULL, 0x55eda4a4aaa4490eULL,\n\t0x50752828a0285d88ULL, 0xb8865c5c6d5cda31ULL, 0xed6bf8f8c7f8933fULL,\n\t0x11c28686228644a4ULL,\n};\n\nstatic const u64 C3[256] = {\n\t0x7830d818186018c0ULL, 0xaf462623238c2305ULL, 0xf991b8c6c63fc67eULL,\n\t0x6fcdfbe8e887e813ULL, 0xa113cb878726874cULL, 0x626d11b8b8dab8a9ULL,\n\t0x0502090101040108ULL, 0x6e9e0d4f4f214f42ULL, 0xee6c9b3636d836adULL,\n\t0x0451ffa6a6a2a659ULL, 0xbdb90cd2d26fd2deULL, 0x06f70ef5f5f3f5fbULL,\n\t0x80f2967979f979efULL, 0xcede306f6fa16f5fULL, 0xef3f6d91917e91fcULL,\n\t0x07a4f852525552aaULL, 0xfdc04760609d6027ULL, 0x766535bcbccabc89ULL,\n\t0xcd2b379b9b569bacULL, 0x8c018a8e8e028e04ULL, 0x155bd2a3a3b6a371ULL,\n\t0x3c186c0c0c300c60ULL, 0x8af6847b7bf17bffULL, 0xe16a803535d435b5ULL,\n\t0x693af51d1d741de8ULL, 0x47ddb3e0e0a7e053ULL, 0xacb321d7d77bd7f6ULL,\n\t0xed999cc2c22fc25eULL, 0x965c432e2eb82e6dULL, 0x7a96294b4b314b62ULL,\n\t0x21e15dfefedffea3ULL, 0x16aed55757415782ULL, 0x412abd15155415a8ULL,\n\t0xb6eee87777c1779fULL, 0xeb6e923737dc37a5ULL, 0x56d79ee5e5b3e57bULL,\n\t0xd923139f9f469f8cULL, 0x17fd23f0f0e7f0d3ULL, 0x7f94204a4a354a6aULL,\n\t0x95a944dada4fda9eULL, 0x25b0a258587d58faULL, 0xca8fcfc9c903c906ULL,\n\t0x8d527c2929a42955ULL, 0x22145a0a0a280a50ULL, 0x4f7f50b1b1feb1e1ULL,\n\t0x1a5dc9a0a0baa069ULL, 0xdad6146b6bb16b7fULL, 0xab17d985852e855cULL,\n\t0x73673cbdbdcebd81ULL, 0x34ba8f5d5d695dd2ULL, 0x5020901010401080ULL,\n\t0x03f507f4f4f7f4f3ULL, 0xc08bddcbcb0bcb16ULL, 0xc67cd33e3ef83eedULL,\n\t0x110a2d0505140528ULL, 0xe6ce78676781671fULL, 0x53d597e4e4b7e473ULL,\n\t0xbb4e0227279c2725ULL, 0x5882734141194132ULL, 0x9d0ba78b8b168b2cULL,\n\t0x0153f6a7a7a6a751ULL, 0x94fab27d7de97dcfULL, 0xfb374995956e95dcULL,\n\t0x9fad56d8d847d88eULL, 0x30eb70fbfbcbfb8bULL, 0x71c1cdeeee9fee23ULL,\n\t0x91f8bb7c7ced7cc7ULL, 0xe3cc716666856617ULL, 0x8ea77bdddd53dda6ULL,\n\t0x4b2eaf17175c17b8ULL, 0x468e454747014702ULL, 0xdc211a9e9e429e84ULL,\n\t0xc589d4caca0fca1eULL, 0x995a582d2db42d75ULL, 0x79632ebfbfc6bf91ULL,\n\t0x1b0e3f07071c0738ULL, 0x2347acadad8ead01ULL, 0x2fb4b05a5a755aeaULL,\n\t0xb51bef838336836cULL, 0xff66b63333cc3385ULL, 0xf2c65c636391633fULL,\n\t0x0a04120202080210ULL, 0x384993aaaa92aa39ULL, 0xa8e2de7171d971afULL,\n\t0xcf8dc6c8c807c80eULL, 0x7d32d119196419c8ULL, 0x70923b4949394972ULL,\n\t0x9aaf5fd9d943d986ULL, 0x1df931f2f2eff2c3ULL, 0x48dba8e3e3abe34bULL,\n\t0x2ab6b95b5b715be2ULL, 0x920dbc88881a8834ULL, 0xc8293e9a9a529aa4ULL,\n\t0xbe4c0b262698262dULL, 0xfa64bf3232c8328dULL, 0x4a7d59b0b0fab0e9ULL,\n\t0x6acff2e9e983e91bULL, 0x331e770f0f3c0f78ULL, 0xa6b733d5d573d5e6ULL,\n\t0xba1df480803a8074ULL, 0x7c6127bebec2be99ULL, 0xde87ebcdcd13cd26ULL,\n\t0xe468893434d034bdULL, 0x75903248483d487aULL, 0x24e354ffffdbffabULL,\n\t0x8ff48d7a7af57af7ULL, 0xea3d6490907a90f4ULL, 0x3ebe9d5f5f615fc2ULL,\n\t0xa0403d202080201dULL, 0xd5d00f6868bd6867ULL, 0x7234ca1a1a681ad0ULL,\n\t0x2c41b7aeae82ae19ULL, 0x5e757db4b4eab4c9ULL, 0x19a8ce54544d549aULL,\n\t0xe53b7f93937693ecULL, 0xaa442f222288220dULL, 0xe9c86364648d6407ULL,\n\t0x12ff2af1f1e3f1dbULL, 0xa2e6cc7373d173bfULL, 0x5a24821212481290ULL,\n\t0x5d807a40401d403aULL, 0x2810480808200840ULL, 0xe89b95c3c32bc356ULL,\n\t0x7bc5dfecec97ec33ULL, 0x90ab4ddbdb4bdb96ULL, 0x1f5fc0a1a1bea161ULL,\n\t0x8307918d8d0e8d1cULL, 0xc97ac83d3df43df5ULL, 0xf1335b97976697ccULL,\n\t0x0000000000000000ULL, 0xd483f9cfcf1bcf36ULL, 0x87566e2b2bac2b45ULL,\n\t0xb3ece17676c57697ULL, 0xb019e68282328264ULL, 0xa9b128d6d67fd6feULL,\n\t0x7736c31b1b6c1bd8ULL, 0x5b7774b5b5eeb5c1ULL, 0x2943beafaf86af11ULL,\n\t0xdfd41d6a6ab56a77ULL, 0x0da0ea50505d50baULL, 0x4c8a574545094512ULL,\n\t0x18fb38f3f3ebf3cbULL, 0xf060ad3030c0309dULL, 0x74c3c4efef9bef2bULL,\n\t0xc37eda3f3ffc3fe5ULL, 0x1caac75555495592ULL, 0x1059dba2a2b2a279ULL,\n\t0x65c9e9eaea8fea03ULL, 0xecca6a656589650fULL, 0x686903babad2bab9ULL,\n\t0x935e4a2f2fbc2f65ULL, 0xe79d8ec0c027c04eULL, 0x81a160dede5fdebeULL,\n\t0x6c38fc1c1c701ce0ULL, 0x2ee746fdfdd3fdbbULL, 0x649a1f4d4d294d52ULL,\n\t0xe0397692927292e4ULL, 0xbceafa7575c9758fULL, 0x1e0c360606180630ULL,\n\t0x9809ae8a8a128a24ULL, 0x40794bb2b2f2b2f9ULL, 0x59d185e6e6bfe663ULL,\n\t0x361c7e0e0e380e70ULL, 0x633ee71f1f7c1ff8ULL, 0xf7c4556262956237ULL,\n\t0xa3b53ad4d477d4eeULL, 0x324d81a8a89aa829ULL, 0xf4315296966296c4ULL,\n\t0x3aef62f9f9c3f99bULL, 0xf697a3c5c533c566ULL, 0xb14a102525942535ULL,\n\t0x20b2ab59597959f2ULL, 0xae15d084842a8454ULL, 0xa7e4c57272d572b7ULL,\n\t0xdd72ec3939e439d5ULL, 0x6198164c4c2d4c5aULL, 0x3bbc945e5e655ecaULL,\n\t0x85f09f7878fd78e7ULL, 0xd870e53838e038ddULL, 0x8605988c8c0a8c14ULL,\n\t0xb2bf17d1d163d1c6ULL, 0x0b57e4a5a5aea541ULL, 0x4dd9a1e2e2afe243ULL,\n\t0xf8c24e616199612fULL, 0x457b42b3b3f6b3f1ULL, 0xa542342121842115ULL,\n\t0xd625089c9c4a9c94ULL, 0x663cee1e1e781ef0ULL, 0x5286614343114322ULL,\n\t0xfc93b1c7c73bc776ULL, 0x2be54ffcfcd7fcb3ULL, 0x1408240404100420ULL,\n\t0x08a2e351515951b2ULL, 0xc72f2599995e99bcULL, 0xc4da226d6da96d4fULL,\n\t0x391a650d0d340d68ULL, 0x35e979fafacffa83ULL, 0x84a369dfdf5bdfb6ULL,\n\t0x9bfca97e7ee57ed7ULL, 0xb44819242490243dULL, 0xd776fe3b3bec3bc5ULL,\n\t0x3d4b9aabab96ab31ULL, 0xd181f0cece1fce3eULL, 0x5522991111441188ULL,\n\t0x8903838f8f068f0cULL, 0x6b9c044e4e254e4aULL, 0x517366b7b7e6b7d1ULL,\n\t0x60cbe0ebeb8beb0bULL, 0xcc78c13c3cf03cfdULL, 0xbf1ffd81813e817cULL,\n\t0xfe354094946a94d4ULL, 0x0cf31cf7f7fbf7ebULL, 0x676f18b9b9deb9a1ULL,\n\t0x5f268b13134c1398ULL, 0x9c58512c2cb02c7dULL, 0xb8bb05d3d36bd3d6ULL,\n\t0x5cd38ce7e7bbe76bULL, 0xcbdc396e6ea56e57ULL, 0xf395aac4c437c46eULL,\n\t0x0f061b03030c0318ULL, 0x13acdc565645568aULL, 0x49885e44440d441aULL,\n\t0x9efea07f7fe17fdfULL, 0x374f88a9a99ea921ULL, 0x8254672a2aa82a4dULL,\n\t0x6d6b0abbbbd6bbb1ULL, 0xe29f87c1c123c146ULL, 0x02a6f153535153a2ULL,\n\t0x8ba572dcdc57dcaeULL, 0x2716530b0b2c0b58ULL, 0xd327019d9d4e9d9cULL,\n\t0xc1d82b6c6cad6c47ULL, 0xf562a43131c43195ULL, 0xb9e8f37474cd7487ULL,\n\t0x09f115f6f6fff6e3ULL, 0x438c4c464605460aULL, 0x2645a5acac8aac09ULL,\n\t0x970fb589891e893cULL, 0x4428b414145014a0ULL, 0x42dfbae1e1a3e15bULL,\n\t0x4e2ca616165816b0ULL, 0xd274f73a3ae83acdULL, 0xd0d2066969b9696fULL,\n\t0x2d12410909240948ULL, 0xade0d77070dd70a7ULL, 0x54716fb6b6e2b6d9ULL,\n\t0xb7bd1ed0d067d0ceULL, 0x7ec7d6eded93ed3bULL, 0xdb85e2cccc17cc2eULL,\n\t0x578468424215422aULL, 0xc22d2c98985a98b4ULL, 0x0e55eda4a4aaa449ULL,\n\t0x8850752828a0285dULL, 0x31b8865c5c6d5cdaULL, 0x3fed6bf8f8c7f893ULL,\n\t0xa411c28686228644ULL,\n};\n\nstatic const u64 C4[256] = {\n\t0xc07830d818186018ULL, 0x05af462623238c23ULL, 0x7ef991b8c6c63fc6ULL,\n\t0x136fcdfbe8e887e8ULL, 0x4ca113cb87872687ULL, 0xa9626d11b8b8dab8ULL,\n\t0x0805020901010401ULL, 0x426e9e0d4f4f214fULL, 0xadee6c9b3636d836ULL,\n\t0x590451ffa6a6a2a6ULL, 0xdebdb90cd2d26fd2ULL, 0xfb06f70ef5f5f3f5ULL,\n\t0xef80f2967979f979ULL, 0x5fcede306f6fa16fULL, 0xfcef3f6d91917e91ULL,\n\t0xaa07a4f852525552ULL, 0x27fdc04760609d60ULL, 0x89766535bcbccabcULL,\n\t0xaccd2b379b9b569bULL, 0x048c018a8e8e028eULL, 0x71155bd2a3a3b6a3ULL,\n\t0x603c186c0c0c300cULL, 0xff8af6847b7bf17bULL, 0xb5e16a803535d435ULL,\n\t0xe8693af51d1d741dULL, 0x5347ddb3e0e0a7e0ULL, 0xf6acb321d7d77bd7ULL,\n\t0x5eed999cc2c22fc2ULL, 0x6d965c432e2eb82eULL, 0x627a96294b4b314bULL,\n\t0xa321e15dfefedffeULL, 0x8216aed557574157ULL, 0xa8412abd15155415ULL,\n\t0x9fb6eee87777c177ULL, 0xa5eb6e923737dc37ULL, 0x7b56d79ee5e5b3e5ULL,\n\t0x8cd923139f9f469fULL, 0xd317fd23f0f0e7f0ULL, 0x6a7f94204a4a354aULL,\n\t0x9e95a944dada4fdaULL, 0xfa25b0a258587d58ULL, 0x06ca8fcfc9c903c9ULL,\n\t0x558d527c2929a429ULL, 0x5022145a0a0a280aULL, 0xe14f7f50b1b1feb1ULL,\n\t0x691a5dc9a0a0baa0ULL, 0x7fdad6146b6bb16bULL, 0x5cab17d985852e85ULL,\n\t0x8173673cbdbdcebdULL, 0xd234ba8f5d5d695dULL, 0x8050209010104010ULL,\n\t0xf303f507f4f4f7f4ULL, 0x16c08bddcbcb0bcbULL, 0xedc67cd33e3ef83eULL,\n\t0x28110a2d05051405ULL, 0x1fe6ce7867678167ULL, 0x7353d597e4e4b7e4ULL,\n\t0x25bb4e0227279c27ULL, 0x3258827341411941ULL, 0x2c9d0ba78b8b168bULL,\n\t0x510153f6a7a7a6a7ULL, 0xcf94fab27d7de97dULL, 0xdcfb374995956e95ULL,\n\t0x8e9fad56d8d847d8ULL, 0x8b30eb70fbfbcbfbULL, 0x2371c1cdeeee9feeULL,\n\t0xc791f8bb7c7ced7cULL, 0x17e3cc7166668566ULL, 0xa68ea77bdddd53ddULL,\n\t0xb84b2eaf17175c17ULL, 0x02468e4547470147ULL, 0x84dc211a9e9e429eULL,\n\t0x1ec589d4caca0fcaULL, 0x75995a582d2db42dULL, 0x9179632ebfbfc6bfULL,\n\t0x381b0e3f07071c07ULL, 0x012347acadad8eadULL, 0xea2fb4b05a5a755aULL,\n\t0x6cb51bef83833683ULL, 0x85ff66b63333cc33ULL, 0x3ff2c65c63639163ULL,\n\t0x100a041202020802ULL, 0x39384993aaaa92aaULL, 0xafa8e2de7171d971ULL,\n\t0x0ecf8dc6c8c807c8ULL, 0xc87d32d119196419ULL, 0x7270923b49493949ULL,\n\t0x869aaf5fd9d943d9ULL, 0xc31df931f2f2eff2ULL, 0x4b48dba8e3e3abe3ULL,\n\t0xe22ab6b95b5b715bULL, 0x34920dbc88881a88ULL, 0xa4c8293e9a9a529aULL,\n\t0x2dbe4c0b26269826ULL, 0x8dfa64bf3232c832ULL, 0xe94a7d59b0b0fab0ULL,\n\t0x1b6acff2e9e983e9ULL, 0x78331e770f0f3c0fULL, 0xe6a6b733d5d573d5ULL,\n\t0x74ba1df480803a80ULL, 0x997c6127bebec2beULL, 0x26de87ebcdcd13cdULL,\n\t0xbde468893434d034ULL, 0x7a75903248483d48ULL, 0xab24e354ffffdbffULL,\n\t0xf78ff48d7a7af57aULL, 0xf4ea3d6490907a90ULL, 0xc23ebe9d5f5f615fULL,\n\t0x1da0403d20208020ULL, 0x67d5d00f6868bd68ULL, 0xd07234ca1a1a681aULL,\n\t0x192c41b7aeae82aeULL, 0xc95e757db4b4eab4ULL, 0x9a19a8ce54544d54ULL,\n\t0xece53b7f93937693ULL, 0x0daa442f22228822ULL, 0x07e9c86364648d64ULL,\n\t0xdb12ff2af1f1e3f1ULL, 0xbfa2e6cc7373d173ULL, 0x905a248212124812ULL,\n\t0x3a5d807a40401d40ULL, 0x4028104808082008ULL, 0x56e89b95c3c32bc3ULL,\n\t0x337bc5dfecec97ecULL, 0x9690ab4ddbdb4bdbULL, 0x611f5fc0a1a1bea1ULL,\n\t0x1c8307918d8d0e8dULL, 0xf5c97ac83d3df43dULL, 0xccf1335b97976697ULL,\n\t0x0000000000000000ULL, 0x36d483f9cfcf1bcfULL, 0x4587566e2b2bac2bULL,\n\t0x97b3ece17676c576ULL, 0x64b019e682823282ULL, 0xfea9b128d6d67fd6ULL,\n\t0xd87736c31b1b6c1bULL, 0xc15b7774b5b5eeb5ULL, 0x112943beafaf86afULL,\n\t0x77dfd41d6a6ab56aULL, 0xba0da0ea50505d50ULL, 0x124c8a5745450945ULL,\n\t0xcb18fb38f3f3ebf3ULL, 0x9df060ad3030c030ULL, 0x2b74c3c4efef9befULL,\n\t0xe5c37eda3f3ffc3fULL, 0x921caac755554955ULL, 0x791059dba2a2b2a2ULL,\n\t0x0365c9e9eaea8feaULL, 0x0fecca6a65658965ULL, 0xb9686903babad2baULL,\n\t0x65935e4a2f2fbc2fULL, 0x4ee79d8ec0c027c0ULL, 0xbe81a160dede5fdeULL,\n\t0xe06c38fc1c1c701cULL, 0xbb2ee746fdfdd3fdULL, 0x52649a1f4d4d294dULL,\n\t0xe4e0397692927292ULL, 0x8fbceafa7575c975ULL, 0x301e0c3606061806ULL,\n\t0x249809ae8a8a128aULL, 0xf940794bb2b2f2b2ULL, 0x6359d185e6e6bfe6ULL,\n\t0x70361c7e0e0e380eULL, 0xf8633ee71f1f7c1fULL, 0x37f7c45562629562ULL,\n\t0xeea3b53ad4d477d4ULL, 0x29324d81a8a89aa8ULL, 0xc4f4315296966296ULL,\n\t0x9b3aef62f9f9c3f9ULL, 0x66f697a3c5c533c5ULL, 0x35b14a1025259425ULL,\n\t0xf220b2ab59597959ULL, 0x54ae15d084842a84ULL, 0xb7a7e4c57272d572ULL,\n\t0xd5dd72ec3939e439ULL, 0x5a6198164c4c2d4cULL, 0xca3bbc945e5e655eULL,\n\t0xe785f09f7878fd78ULL, 0xddd870e53838e038ULL, 0x148605988c8c0a8cULL,\n\t0xc6b2bf17d1d163d1ULL, 0x410b57e4a5a5aea5ULL, 0x434dd9a1e2e2afe2ULL,\n\t0x2ff8c24e61619961ULL, 0xf1457b42b3b3f6b3ULL, 0x15a5423421218421ULL,\n\t0x94d625089c9c4a9cULL, 0xf0663cee1e1e781eULL, 0x2252866143431143ULL,\n\t0x76fc93b1c7c73bc7ULL, 0xb32be54ffcfcd7fcULL, 0x2014082404041004ULL,\n\t0xb208a2e351515951ULL, 0xbcc72f2599995e99ULL, 0x4fc4da226d6da96dULL,\n\t0x68391a650d0d340dULL, 0x8335e979fafacffaULL, 0xb684a369dfdf5bdfULL,\n\t0xd79bfca97e7ee57eULL, 0x3db4481924249024ULL, 0xc5d776fe3b3bec3bULL,\n\t0x313d4b9aabab96abULL, 0x3ed181f0cece1fceULL, 0x8855229911114411ULL,\n\t0x0c8903838f8f068fULL, 0x4a6b9c044e4e254eULL, 0xd1517366b7b7e6b7ULL,\n\t0x0b60cbe0ebeb8bebULL, 0xfdcc78c13c3cf03cULL, 0x7cbf1ffd81813e81ULL,\n\t0xd4fe354094946a94ULL, 0xeb0cf31cf7f7fbf7ULL, 0xa1676f18b9b9deb9ULL,\n\t0x985f268b13134c13ULL, 0x7d9c58512c2cb02cULL, 0xd6b8bb05d3d36bd3ULL,\n\t0x6b5cd38ce7e7bbe7ULL, 0x57cbdc396e6ea56eULL, 0x6ef395aac4c437c4ULL,\n\t0x180f061b03030c03ULL, 0x8a13acdc56564556ULL, 0x1a49885e44440d44ULL,\n\t0xdf9efea07f7fe17fULL, 0x21374f88a9a99ea9ULL, 0x4d8254672a2aa82aULL,\n\t0xb16d6b0abbbbd6bbULL, 0x46e29f87c1c123c1ULL, 0xa202a6f153535153ULL,\n\t0xae8ba572dcdc57dcULL, 0x582716530b0b2c0bULL, 0x9cd327019d9d4e9dULL,\n\t0x47c1d82b6c6cad6cULL, 0x95f562a43131c431ULL, 0x87b9e8f37474cd74ULL,\n\t0xe309f115f6f6fff6ULL, 0x0a438c4c46460546ULL, 0x092645a5acac8aacULL,\n\t0x3c970fb589891e89ULL, 0xa04428b414145014ULL, 0x5b42dfbae1e1a3e1ULL,\n\t0xb04e2ca616165816ULL, 0xcdd274f73a3ae83aULL, 0x6fd0d2066969b969ULL,\n\t0x482d124109092409ULL, 0xa7ade0d77070dd70ULL, 0xd954716fb6b6e2b6ULL,\n\t0xceb7bd1ed0d067d0ULL, 0x3b7ec7d6eded93edULL, 0x2edb85e2cccc17ccULL,\n\t0x2a57846842421542ULL, 0xb4c22d2c98985a98ULL, 0x490e55eda4a4aaa4ULL,\n\t0x5d8850752828a028ULL, 0xda31b8865c5c6d5cULL, 0x933fed6bf8f8c7f8ULL,\n\t0x44a411c286862286ULL,\n};\n\nstatic const u64 C5[256] = {\n\t0x18c07830d8181860ULL, 0x2305af462623238cULL, 0xc67ef991b8c6c63fULL,\n\t0xe8136fcdfbe8e887ULL, 0x874ca113cb878726ULL, 0xb8a9626d11b8b8daULL,\n\t0x0108050209010104ULL, 0x4f426e9e0d4f4f21ULL, 0x36adee6c9b3636d8ULL,\n\t0xa6590451ffa6a6a2ULL, 0xd2debdb90cd2d26fULL, 0xf5fb06f70ef5f5f3ULL,\n\t0x79ef80f2967979f9ULL, 0x6f5fcede306f6fa1ULL, 0x91fcef3f6d91917eULL,\n\t0x52aa07a4f8525255ULL, 0x6027fdc04760609dULL, 0xbc89766535bcbccaULL,\n\t0x9baccd2b379b9b56ULL, 0x8e048c018a8e8e02ULL, 0xa371155bd2a3a3b6ULL,\n\t0x0c603c186c0c0c30ULL, 0x7bff8af6847b7bf1ULL, 0x35b5e16a803535d4ULL,\n\t0x1de8693af51d1d74ULL, 0xe05347ddb3e0e0a7ULL, 0xd7f6acb321d7d77bULL,\n\t0xc25eed999cc2c22fULL, 0x2e6d965c432e2eb8ULL, 0x4b627a96294b4b31ULL,\n\t0xfea321e15dfefedfULL, 0x578216aed5575741ULL, 0x15a8412abd151554ULL,\n\t0x779fb6eee87777c1ULL, 0x37a5eb6e923737dcULL, 0xe57b56d79ee5e5b3ULL,\n\t0x9f8cd923139f9f46ULL, 0xf0d317fd23f0f0e7ULL, 0x4a6a7f94204a4a35ULL,\n\t0xda9e95a944dada4fULL, 0x58fa25b0a258587dULL, 0xc906ca8fcfc9c903ULL,\n\t0x29558d527c2929a4ULL, 0x0a5022145a0a0a28ULL, 0xb1e14f7f50b1b1feULL,\n\t0xa0691a5dc9a0a0baULL, 0x6b7fdad6146b6bb1ULL, 0x855cab17d985852eULL,\n\t0xbd8173673cbdbdceULL, 0x5dd234ba8f5d5d69ULL, 0x1080502090101040ULL,\n\t0xf4f303f507f4f4f7ULL, 0xcb16c08bddcbcb0bULL, 0x3eedc67cd33e3ef8ULL,\n\t0x0528110a2d050514ULL, 0x671fe6ce78676781ULL, 0xe47353d597e4e4b7ULL,\n\t0x2725bb4e0227279cULL, 0x4132588273414119ULL, 0x8b2c9d0ba78b8b16ULL,\n\t0xa7510153f6a7a7a6ULL, 0x7dcf94fab27d7de9ULL, 0x95dcfb374995956eULL,\n\t0xd88e9fad56d8d847ULL, 0xfb8b30eb70fbfbcbULL, 0xee2371c1cdeeee9fULL,\n\t0x7cc791f8bb7c7cedULL, 0x6617e3cc71666685ULL, 0xdda68ea77bdddd53ULL,\n\t0x17b84b2eaf17175cULL, 0x4702468e45474701ULL, 0x9e84dc211a9e9e42ULL,\n\t0xca1ec589d4caca0fULL, 0x2d75995a582d2db4ULL, 0xbf9179632ebfbfc6ULL,\n\t0x07381b0e3f07071cULL, 0xad012347acadad8eULL, 0x5aea2fb4b05a5a75ULL,\n\t0x836cb51bef838336ULL, 0x3385ff66b63333ccULL, 0x633ff2c65c636391ULL,\n\t0x02100a0412020208ULL, 0xaa39384993aaaa92ULL, 0x71afa8e2de7171d9ULL,\n\t0xc80ecf8dc6c8c807ULL, 0x19c87d32d1191964ULL, 0x497270923b494939ULL,\n\t0xd9869aaf5fd9d943ULL, 0xf2c31df931f2f2efULL, 0xe34b48dba8e3e3abULL,\n\t0x5be22ab6b95b5b71ULL, 0x8834920dbc88881aULL, 0x9aa4c8293e9a9a52ULL,\n\t0x262dbe4c0b262698ULL, 0x328dfa64bf3232c8ULL, 0xb0e94a7d59b0b0faULL,\n\t0xe91b6acff2e9e983ULL, 0x0f78331e770f0f3cULL, 0xd5e6a6b733d5d573ULL,\n\t0x8074ba1df480803aULL, 0xbe997c6127bebec2ULL, 0xcd26de87ebcdcd13ULL,\n\t0x34bde468893434d0ULL, 0x487a75903248483dULL, 0xffab24e354ffffdbULL,\n\t0x7af78ff48d7a7af5ULL, 0x90f4ea3d6490907aULL, 0x5fc23ebe9d5f5f61ULL,\n\t0x201da0403d202080ULL, 0x6867d5d00f6868bdULL, 0x1ad07234ca1a1a68ULL,\n\t0xae192c41b7aeae82ULL, 0xb4c95e757db4b4eaULL, 0x549a19a8ce54544dULL,\n\t0x93ece53b7f939376ULL, 0x220daa442f222288ULL, 0x6407e9c86364648dULL,\n\t0xf1db12ff2af1f1e3ULL, 0x73bfa2e6cc7373d1ULL, 0x12905a2482121248ULL,\n\t0x403a5d807a40401dULL, 0x0840281048080820ULL, 0xc356e89b95c3c32bULL,\n\t0xec337bc5dfecec97ULL, 0xdb9690ab4ddbdb4bULL, 0xa1611f5fc0a1a1beULL,\n\t0x8d1c8307918d8d0eULL, 0x3df5c97ac83d3df4ULL, 0x97ccf1335b979766ULL,\n\t0x0000000000000000ULL, 0xcf36d483f9cfcf1bULL, 0x2b4587566e2b2bacULL,\n\t0x7697b3ece17676c5ULL, 0x8264b019e6828232ULL, 0xd6fea9b128d6d67fULL,\n\t0x1bd87736c31b1b6cULL, 0xb5c15b7774b5b5eeULL, 0xaf112943beafaf86ULL,\n\t0x6a77dfd41d6a6ab5ULL, 0x50ba0da0ea50505dULL, 0x45124c8a57454509ULL,\n\t0xf3cb18fb38f3f3ebULL, 0x309df060ad3030c0ULL, 0xef2b74c3c4efef9bULL,\n\t0x3fe5c37eda3f3ffcULL, 0x55921caac7555549ULL, 0xa2791059dba2a2b2ULL,\n\t0xea0365c9e9eaea8fULL, 0x650fecca6a656589ULL, 0xbab9686903babad2ULL,\n\t0x2f65935e4a2f2fbcULL, 0xc04ee79d8ec0c027ULL, 0xdebe81a160dede5fULL,\n\t0x1ce06c38fc1c1c70ULL, 0xfdbb2ee746fdfdd3ULL, 0x4d52649a1f4d4d29ULL,\n\t0x92e4e03976929272ULL, 0x758fbceafa7575c9ULL, 0x06301e0c36060618ULL,\n\t0x8a249809ae8a8a12ULL, 0xb2f940794bb2b2f2ULL, 0xe66359d185e6e6bfULL,\n\t0x0e70361c7e0e0e38ULL, 0x1ff8633ee71f1f7cULL, 0x6237f7c455626295ULL,\n\t0xd4eea3b53ad4d477ULL, 0xa829324d81a8a89aULL, 0x96c4f43152969662ULL,\n\t0xf99b3aef62f9f9c3ULL, 0xc566f697a3c5c533ULL, 0x2535b14a10252594ULL,\n\t0x59f220b2ab595979ULL, 0x8454ae15d084842aULL, 0x72b7a7e4c57272d5ULL,\n\t0x39d5dd72ec3939e4ULL, 0x4c5a6198164c4c2dULL, 0x5eca3bbc945e5e65ULL,\n\t0x78e785f09f7878fdULL, 0x38ddd870e53838e0ULL, 0x8c148605988c8c0aULL,\n\t0xd1c6b2bf17d1d163ULL, 0xa5410b57e4a5a5aeULL, 0xe2434dd9a1e2e2afULL,\n\t0x612ff8c24e616199ULL, 0xb3f1457b42b3b3f6ULL, 0x2115a54234212184ULL,\n\t0x9c94d625089c9c4aULL, 0x1ef0663cee1e1e78ULL, 0x4322528661434311ULL,\n\t0xc776fc93b1c7c73bULL, 0xfcb32be54ffcfcd7ULL, 0x0420140824040410ULL,\n\t0x51b208a2e3515159ULL, 0x99bcc72f2599995eULL, 0x6d4fc4da226d6da9ULL,\n\t0x0d68391a650d0d34ULL, 0xfa8335e979fafacfULL, 0xdfb684a369dfdf5bULL,\n\t0x7ed79bfca97e7ee5ULL, 0x243db44819242490ULL, 0x3bc5d776fe3b3becULL,\n\t0xab313d4b9aabab96ULL, 0xce3ed181f0cece1fULL, 0x1188552299111144ULL,\n\t0x8f0c8903838f8f06ULL, 0x4e4a6b9c044e4e25ULL, 0xb7d1517366b7b7e6ULL,\n\t0xeb0b60cbe0ebeb8bULL, 0x3cfdcc78c13c3cf0ULL, 0x817cbf1ffd81813eULL,\n\t0x94d4fe354094946aULL, 0xf7eb0cf31cf7f7fbULL, 0xb9a1676f18b9b9deULL,\n\t0x13985f268b13134cULL, 0x2c7d9c58512c2cb0ULL, 0xd3d6b8bb05d3d36bULL,\n\t0xe76b5cd38ce7e7bbULL, 0x6e57cbdc396e6ea5ULL, 0xc46ef395aac4c437ULL,\n\t0x03180f061b03030cULL, 0x568a13acdc565645ULL, 0x441a49885e44440dULL,\n\t0x7fdf9efea07f7fe1ULL, 0xa921374f88a9a99eULL, 0x2a4d8254672a2aa8ULL,\n\t0xbbb16d6b0abbbbd6ULL, 0xc146e29f87c1c123ULL, 0x53a202a6f1535351ULL,\n\t0xdcae8ba572dcdc57ULL, 0x0b582716530b0b2cULL, 0x9d9cd327019d9d4eULL,\n\t0x6c47c1d82b6c6cadULL, 0x3195f562a43131c4ULL, 0x7487b9e8f37474cdULL,\n\t0xf6e309f115f6f6ffULL, 0x460a438c4c464605ULL, 0xac092645a5acac8aULL,\n\t0x893c970fb589891eULL, 0x14a04428b4141450ULL, 0xe15b42dfbae1e1a3ULL,\n\t0x16b04e2ca6161658ULL, 0x3acdd274f73a3ae8ULL, 0x696fd0d2066969b9ULL,\n\t0x09482d1241090924ULL, 0x70a7ade0d77070ddULL, 0xb6d954716fb6b6e2ULL,\n\t0xd0ceb7bd1ed0d067ULL, 0xed3b7ec7d6eded93ULL, 0xcc2edb85e2cccc17ULL,\n\t0x422a578468424215ULL, 0x98b4c22d2c98985aULL, 0xa4490e55eda4a4aaULL,\n\t0x285d8850752828a0ULL, 0x5cda31b8865c5c6dULL, 0xf8933fed6bf8f8c7ULL,\n\t0x8644a411c2868622ULL,\n};\n\nstatic const u64 C6[256] = {\n\t0x6018c07830d81818ULL, 0x8c2305af46262323ULL, 0x3fc67ef991b8c6c6ULL,\n\t0x87e8136fcdfbe8e8ULL, 0x26874ca113cb8787ULL, 0xdab8a9626d11b8b8ULL,\n\t0x0401080502090101ULL, 0x214f426e9e0d4f4fULL, 0xd836adee6c9b3636ULL,\n\t0xa2a6590451ffa6a6ULL, 0x6fd2debdb90cd2d2ULL, 0xf3f5fb06f70ef5f5ULL,\n\t0xf979ef80f2967979ULL, 0xa16f5fcede306f6fULL, 0x7e91fcef3f6d9191ULL,\n\t0x5552aa07a4f85252ULL, 0x9d6027fdc0476060ULL, 0xcabc89766535bcbcULL,\n\t0x569baccd2b379b9bULL, 0x028e048c018a8e8eULL, 0xb6a371155bd2a3a3ULL,\n\t0x300c603c186c0c0cULL, 0xf17bff8af6847b7bULL, 0xd435b5e16a803535ULL,\n\t0x741de8693af51d1dULL, 0xa7e05347ddb3e0e0ULL, 0x7bd7f6acb321d7d7ULL,\n\t0x2fc25eed999cc2c2ULL, 0xb82e6d965c432e2eULL, 0x314b627a96294b4bULL,\n\t0xdffea321e15dfefeULL, 0x41578216aed55757ULL, 0x5415a8412abd1515ULL,\n\t0xc1779fb6eee87777ULL, 0xdc37a5eb6e923737ULL, 0xb3e57b56d79ee5e5ULL,\n\t0x469f8cd923139f9fULL, 0xe7f0d317fd23f0f0ULL, 0x354a6a7f94204a4aULL,\n\t0x4fda9e95a944dadaULL, 0x7d58fa25b0a25858ULL, 0x03c906ca8fcfc9c9ULL,\n\t0xa429558d527c2929ULL, 0x280a5022145a0a0aULL, 0xfeb1e14f7f50b1b1ULL,\n\t0xbaa0691a5dc9a0a0ULL, 0xb16b7fdad6146b6bULL, 0x2e855cab17d98585ULL,\n\t0xcebd8173673cbdbdULL, 0x695dd234ba8f5d5dULL, 0x4010805020901010ULL,\n\t0xf7f4f303f507f4f4ULL, 0x0bcb16c08bddcbcbULL, 0xf83eedc67cd33e3eULL,\n\t0x140528110a2d0505ULL, 0x81671fe6ce786767ULL, 0xb7e47353d597e4e4ULL,\n\t0x9c2725bb4e022727ULL, 0x1941325882734141ULL, 0x168b2c9d0ba78b8bULL,\n\t0xa6a7510153f6a7a7ULL, 0xe97dcf94fab27d7dULL, 0x6e95dcfb37499595ULL,\n\t0x47d88e9fad56d8d8ULL, 0xcbfb8b30eb70fbfbULL, 0x9fee2371c1cdeeeeULL,\n\t0xed7cc791f8bb7c7cULL, 0x856617e3cc716666ULL, 0x53dda68ea77bddddULL,\n\t0x5c17b84b2eaf1717ULL, 0x014702468e454747ULL, 0x429e84dc211a9e9eULL,\n\t0x0fca1ec589d4cacaULL, 0xb42d75995a582d2dULL, 0xc6bf9179632ebfbfULL,\n\t0x1c07381b0e3f0707ULL, 0x8ead012347acadadULL, 0x755aea2fb4b05a5aULL,\n\t0x36836cb51bef8383ULL, 0xcc3385ff66b63333ULL, 0x91633ff2c65c6363ULL,\n\t0x0802100a04120202ULL, 0x92aa39384993aaaaULL, 0xd971afa8e2de7171ULL,\n\t0x07c80ecf8dc6c8c8ULL, 0x6419c87d32d11919ULL, 0x39497270923b4949ULL,\n\t0x43d9869aaf5fd9d9ULL, 0xeff2c31df931f2f2ULL, 0xabe34b48dba8e3e3ULL,\n\t0x715be22ab6b95b5bULL, 0x1a8834920dbc8888ULL, 0x529aa4c8293e9a9aULL,\n\t0x98262dbe4c0b2626ULL, 0xc8328dfa64bf3232ULL, 0xfab0e94a7d59b0b0ULL,\n\t0x83e91b6acff2e9e9ULL, 0x3c0f78331e770f0fULL, 0x73d5e6a6b733d5d5ULL,\n\t0x3a8074ba1df48080ULL, 0xc2be997c6127bebeULL, 0x13cd26de87ebcdcdULL,\n\t0xd034bde468893434ULL, 0x3d487a7590324848ULL, 0xdbffab24e354ffffULL,\n\t0xf57af78ff48d7a7aULL, 0x7a90f4ea3d649090ULL, 0x615fc23ebe9d5f5fULL,\n\t0x80201da0403d2020ULL, 0xbd6867d5d00f6868ULL, 0x681ad07234ca1a1aULL,\n\t0x82ae192c41b7aeaeULL, 0xeab4c95e757db4b4ULL, 0x4d549a19a8ce5454ULL,\n\t0x7693ece53b7f9393ULL, 0x88220daa442f2222ULL, 0x8d6407e9c8636464ULL,\n\t0xe3f1db12ff2af1f1ULL, 0xd173bfa2e6cc7373ULL, 0x4812905a24821212ULL,\n\t0x1d403a5d807a4040ULL, 0x2008402810480808ULL, 0x2bc356e89b95c3c3ULL,\n\t0x97ec337bc5dfececULL, 0x4bdb9690ab4ddbdbULL, 0xbea1611f5fc0a1a1ULL,\n\t0x0e8d1c8307918d8dULL, 0xf43df5c97ac83d3dULL, 0x6697ccf1335b9797ULL,\n\t0x0000000000000000ULL, 0x1bcf36d483f9cfcfULL, 0xac2b4587566e2b2bULL,\n\t0xc57697b3ece17676ULL, 0x328264b019e68282ULL, 0x7fd6fea9b128d6d6ULL,\n\t0x6c1bd87736c31b1bULL, 0xeeb5c15b7774b5b5ULL, 0x86af112943beafafULL,\n\t0xb56a77dfd41d6a6aULL, 0x5d50ba0da0ea5050ULL, 0x0945124c8a574545ULL,\n\t0xebf3cb18fb38f3f3ULL, 0xc0309df060ad3030ULL, 0x9bef2b74c3c4efefULL,\n\t0xfc3fe5c37eda3f3fULL, 0x4955921caac75555ULL, 0xb2a2791059dba2a2ULL,\n\t0x8fea0365c9e9eaeaULL, 0x89650fecca6a6565ULL, 0xd2bab9686903babaULL,\n\t0xbc2f65935e4a2f2fULL, 0x27c04ee79d8ec0c0ULL, 0x5fdebe81a160dedeULL,\n\t0x701ce06c38fc1c1cULL, 0xd3fdbb2ee746fdfdULL, 0x294d52649a1f4d4dULL,\n\t0x7292e4e039769292ULL, 0xc9758fbceafa7575ULL, 0x1806301e0c360606ULL,\n\t0x128a249809ae8a8aULL, 0xf2b2f940794bb2b2ULL, 0xbfe66359d185e6e6ULL,\n\t0x380e70361c7e0e0eULL, 0x7c1ff8633ee71f1fULL, 0x956237f7c4556262ULL,\n\t0x77d4eea3b53ad4d4ULL, 0x9aa829324d81a8a8ULL, 0x6296c4f431529696ULL,\n\t0xc3f99b3aef62f9f9ULL, 0x33c566f697a3c5c5ULL, 0x942535b14a102525ULL,\n\t0x7959f220b2ab5959ULL, 0x2a8454ae15d08484ULL, 0xd572b7a7e4c57272ULL,\n\t0xe439d5dd72ec3939ULL, 0x2d4c5a6198164c4cULL, 0x655eca3bbc945e5eULL,\n\t0xfd78e785f09f7878ULL, 0xe038ddd870e53838ULL, 0x0a8c148605988c8cULL,\n\t0x63d1c6b2bf17d1d1ULL, 0xaea5410b57e4a5a5ULL, 0xafe2434dd9a1e2e2ULL,\n\t0x99612ff8c24e6161ULL, 0xf6b3f1457b42b3b3ULL, 0x842115a542342121ULL,\n\t0x4a9c94d625089c9cULL, 0x781ef0663cee1e1eULL, 0x1143225286614343ULL,\n\t0x3bc776fc93b1c7c7ULL, 0xd7fcb32be54ffcfcULL, 0x1004201408240404ULL,\n\t0x5951b208a2e35151ULL, 0x5e99bcc72f259999ULL, 0xa96d4fc4da226d6dULL,\n\t0x340d68391a650d0dULL, 0xcffa8335e979fafaULL, 0x5bdfb684a369dfdfULL,\n\t0xe57ed79bfca97e7eULL, 0x90243db448192424ULL, 0xec3bc5d776fe3b3bULL,\n\t0x96ab313d4b9aababULL, 0x1fce3ed181f0ceceULL, 0x4411885522991111ULL,\n\t0x068f0c8903838f8fULL, 0x254e4a6b9c044e4eULL, 0xe6b7d1517366b7b7ULL,\n\t0x8beb0b60cbe0ebebULL, 0xf03cfdcc78c13c3cULL, 0x3e817cbf1ffd8181ULL,\n\t0x6a94d4fe35409494ULL, 0xfbf7eb0cf31cf7f7ULL, 0xdeb9a1676f18b9b9ULL,\n\t0x4c13985f268b1313ULL, 0xb02c7d9c58512c2cULL, 0x6bd3d6b8bb05d3d3ULL,\n\t0xbbe76b5cd38ce7e7ULL, 0xa56e57cbdc396e6eULL, 0x37c46ef395aac4c4ULL,\n\t0x0c03180f061b0303ULL, 0x45568a13acdc5656ULL, 0x0d441a49885e4444ULL,\n\t0xe17fdf9efea07f7fULL, 0x9ea921374f88a9a9ULL, 0xa82a4d8254672a2aULL,\n\t0xd6bbb16d6b0abbbbULL, 0x23c146e29f87c1c1ULL, 0x5153a202a6f15353ULL,\n\t0x57dcae8ba572dcdcULL, 0x2c0b582716530b0bULL, 0x4e9d9cd327019d9dULL,\n\t0xad6c47c1d82b6c6cULL, 0xc43195f562a43131ULL, 0xcd7487b9e8f37474ULL,\n\t0xfff6e309f115f6f6ULL, 0x05460a438c4c4646ULL, 0x8aac092645a5acacULL,\n\t0x1e893c970fb58989ULL, 0x5014a04428b41414ULL, 0xa3e15b42dfbae1e1ULL,\n\t0x5816b04e2ca61616ULL, 0xe83acdd274f73a3aULL, 0xb9696fd0d2066969ULL,\n\t0x2409482d12410909ULL, 0xdd70a7ade0d77070ULL, 0xe2b6d954716fb6b6ULL,\n\t0x67d0ceb7bd1ed0d0ULL, 0x93ed3b7ec7d6ededULL, 0x17cc2edb85e2ccccULL,\n\t0x15422a5784684242ULL, 0x5a98b4c22d2c9898ULL, 0xaaa4490e55eda4a4ULL,\n\t0xa0285d8850752828ULL, 0x6d5cda31b8865c5cULL, 0xc7f8933fed6bf8f8ULL,\n\t0x228644a411c28686ULL,\n};\n\nstatic const u64 C7[256] = {\n\t0x186018c07830d818ULL, 0x238c2305af462623ULL, 0xc63fc67ef991b8c6ULL,\n\t0xe887e8136fcdfbe8ULL, 0x8726874ca113cb87ULL, 0xb8dab8a9626d11b8ULL,\n\t0x0104010805020901ULL, 0x4f214f426e9e0d4fULL, 0x36d836adee6c9b36ULL,\n\t0xa6a2a6590451ffa6ULL, 0xd26fd2debdb90cd2ULL, 0xf5f3f5fb06f70ef5ULL,\n\t0x79f979ef80f29679ULL, 0x6fa16f5fcede306fULL, 0x917e91fcef3f6d91ULL,\n\t0x525552aa07a4f852ULL, 0x609d6027fdc04760ULL, 0xbccabc89766535bcULL,\n\t0x9b569baccd2b379bULL, 0x8e028e048c018a8eULL, 0xa3b6a371155bd2a3ULL,\n\t0x0c300c603c186c0cULL, 0x7bf17bff8af6847bULL, 0x35d435b5e16a8035ULL,\n\t0x1d741de8693af51dULL, 0xe0a7e05347ddb3e0ULL, 0xd77bd7f6acb321d7ULL,\n\t0xc22fc25eed999cc2ULL, 0x2eb82e6d965c432eULL, 0x4b314b627a96294bULL,\n\t0xfedffea321e15dfeULL, 0x5741578216aed557ULL, 0x155415a8412abd15ULL,\n\t0x77c1779fb6eee877ULL, 0x37dc37a5eb6e9237ULL, 0xe5b3e57b56d79ee5ULL,\n\t0x9f469f8cd923139fULL, 0xf0e7f0d317fd23f0ULL, 0x4a354a6a7f94204aULL,\n\t0xda4fda9e95a944daULL, 0x587d58fa25b0a258ULL, 0xc903c906ca8fcfc9ULL,\n\t0x29a429558d527c29ULL, 0x0a280a5022145a0aULL, 0xb1feb1e14f7f50b1ULL,\n\t0xa0baa0691a5dc9a0ULL, 0x6bb16b7fdad6146bULL, 0x852e855cab17d985ULL,\n\t0xbdcebd8173673cbdULL, 0x5d695dd234ba8f5dULL, 0x1040108050209010ULL,\n\t0xf4f7f4f303f507f4ULL, 0xcb0bcb16c08bddcbULL, 0x3ef83eedc67cd33eULL,\n\t0x05140528110a2d05ULL, 0x6781671fe6ce7867ULL, 0xe4b7e47353d597e4ULL,\n\t0x279c2725bb4e0227ULL, 0x4119413258827341ULL, 0x8b168b2c9d0ba78bULL,\n\t0xa7a6a7510153f6a7ULL, 0x7de97dcf94fab27dULL, 0x956e95dcfb374995ULL,\n\t0xd847d88e9fad56d8ULL, 0xfbcbfb8b30eb70fbULL, 0xee9fee2371c1cdeeULL,\n\t0x7ced7cc791f8bb7cULL, 0x66856617e3cc7166ULL, 0xdd53dda68ea77bddULL,\n\t0x175c17b84b2eaf17ULL, 0x47014702468e4547ULL, 0x9e429e84dc211a9eULL,\n\t0xca0fca1ec589d4caULL, 0x2db42d75995a582dULL, 0xbfc6bf9179632ebfULL,\n\t0x071c07381b0e3f07ULL, 0xad8ead012347acadULL, 0x5a755aea2fb4b05aULL,\n\t0x8336836cb51bef83ULL, 0x33cc3385ff66b633ULL, 0x6391633ff2c65c63ULL,\n\t0x020802100a041202ULL, 0xaa92aa39384993aaULL, 0x71d971afa8e2de71ULL,\n\t0xc807c80ecf8dc6c8ULL, 0x196419c87d32d119ULL, 0x4939497270923b49ULL,\n\t0xd943d9869aaf5fd9ULL, 0xf2eff2c31df931f2ULL, 0xe3abe34b48dba8e3ULL,\n\t0x5b715be22ab6b95bULL, 0x881a8834920dbc88ULL, 0x9a529aa4c8293e9aULL,\n\t0x2698262dbe4c0b26ULL, 0x32c8328dfa64bf32ULL, 0xb0fab0e94a7d59b0ULL,\n\t0xe983e91b6acff2e9ULL, 0x0f3c0f78331e770fULL, 0xd573d5e6a6b733d5ULL,\n\t0x803a8074ba1df480ULL, 0xbec2be997c6127beULL, 0xcd13cd26de87ebcdULL,\n\t0x34d034bde4688934ULL, 0x483d487a75903248ULL, 0xffdbffab24e354ffULL,\n\t0x7af57af78ff48d7aULL, 0x907a90f4ea3d6490ULL, 0x5f615fc23ebe9d5fULL,\n\t0x2080201da0403d20ULL, 0x68bd6867d5d00f68ULL, 0x1a681ad07234ca1aULL,\n\t0xae82ae192c41b7aeULL, 0xb4eab4c95e757db4ULL, 0x544d549a19a8ce54ULL,\n\t0x937693ece53b7f93ULL, 0x2288220daa442f22ULL, 0x648d6407e9c86364ULL,\n\t0xf1e3f1db12ff2af1ULL, 0x73d173bfa2e6cc73ULL, 0x124812905a248212ULL,\n\t0x401d403a5d807a40ULL, 0x0820084028104808ULL, 0xc32bc356e89b95c3ULL,\n\t0xec97ec337bc5dfecULL, 0xdb4bdb9690ab4ddbULL, 0xa1bea1611f5fc0a1ULL,\n\t0x8d0e8d1c8307918dULL, 0x3df43df5c97ac83dULL, 0x976697ccf1335b97ULL,\n\t0x0000000000000000ULL, 0xcf1bcf36d483f9cfULL, 0x2bac2b4587566e2bULL,\n\t0x76c57697b3ece176ULL, 0x82328264b019e682ULL, 0xd67fd6fea9b128d6ULL,\n\t0x1b6c1bd87736c31bULL, 0xb5eeb5c15b7774b5ULL, 0xaf86af112943beafULL,\n\t0x6ab56a77dfd41d6aULL, 0x505d50ba0da0ea50ULL, 0x450945124c8a5745ULL,\n\t0xf3ebf3cb18fb38f3ULL, 0x30c0309df060ad30ULL, 0xef9bef2b74c3c4efULL,\n\t0x3ffc3fe5c37eda3fULL, 0x554955921caac755ULL, 0xa2b2a2791059dba2ULL,\n\t0xea8fea0365c9e9eaULL, 0x6589650fecca6a65ULL, 0xbad2bab9686903baULL,\n\t0x2fbc2f65935e4a2fULL, 0xc027c04ee79d8ec0ULL, 0xde5fdebe81a160deULL,\n\t0x1c701ce06c38fc1cULL, 0xfdd3fdbb2ee746fdULL, 0x4d294d52649a1f4dULL,\n\t0x927292e4e0397692ULL, 0x75c9758fbceafa75ULL, 0x061806301e0c3606ULL,\n\t0x8a128a249809ae8aULL, 0xb2f2b2f940794bb2ULL, 0xe6bfe66359d185e6ULL,\n\t0x0e380e70361c7e0eULL, 0x1f7c1ff8633ee71fULL, 0x62956237f7c45562ULL,\n\t0xd477d4eea3b53ad4ULL, 0xa89aa829324d81a8ULL, 0x966296c4f4315296ULL,\n\t0xf9c3f99b3aef62f9ULL, 0xc533c566f697a3c5ULL, 0x25942535b14a1025ULL,\n\t0x597959f220b2ab59ULL, 0x842a8454ae15d084ULL, 0x72d572b7a7e4c572ULL,\n\t0x39e439d5dd72ec39ULL, 0x4c2d4c5a6198164cULL, 0x5e655eca3bbc945eULL,\n\t0x78fd78e785f09f78ULL, 0x38e038ddd870e538ULL, 0x8c0a8c148605988cULL,\n\t0xd163d1c6b2bf17d1ULL, 0xa5aea5410b57e4a5ULL, 0xe2afe2434dd9a1e2ULL,\n\t0x6199612ff8c24e61ULL, 0xb3f6b3f1457b42b3ULL, 0x21842115a5423421ULL,\n\t0x9c4a9c94d625089cULL, 0x1e781ef0663cee1eULL, 0x4311432252866143ULL,\n\t0xc73bc776fc93b1c7ULL, 0xfcd7fcb32be54ffcULL, 0x0410042014082404ULL,\n\t0x515951b208a2e351ULL, 0x995e99bcc72f2599ULL, 0x6da96d4fc4da226dULL,\n\t0x0d340d68391a650dULL, 0xfacffa8335e979faULL, 0xdf5bdfb684a369dfULL,\n\t0x7ee57ed79bfca97eULL, 0x2490243db4481924ULL, 0x3bec3bc5d776fe3bULL,\n\t0xab96ab313d4b9aabULL, 0xce1fce3ed181f0ceULL, 0x1144118855229911ULL,\n\t0x8f068f0c8903838fULL, 0x4e254e4a6b9c044eULL, 0xb7e6b7d1517366b7ULL,\n\t0xeb8beb0b60cbe0ebULL, 0x3cf03cfdcc78c13cULL, 0x813e817cbf1ffd81ULL,\n\t0x946a94d4fe354094ULL, 0xf7fbf7eb0cf31cf7ULL, 0xb9deb9a1676f18b9ULL,\n\t0x134c13985f268b13ULL, 0x2cb02c7d9c58512cULL, 0xd36bd3d6b8bb05d3ULL,\n\t0xe7bbe76b5cd38ce7ULL, 0x6ea56e57cbdc396eULL, 0xc437c46ef395aac4ULL,\n\t0x030c03180f061b03ULL, 0x5645568a13acdc56ULL, 0x440d441a49885e44ULL,\n\t0x7fe17fdf9efea07fULL, 0xa99ea921374f88a9ULL, 0x2aa82a4d8254672aULL,\n\t0xbbd6bbb16d6b0abbULL, 0xc123c146e29f87c1ULL, 0x535153a202a6f153ULL,\n\t0xdc57dcae8ba572dcULL, 0x0b2c0b582716530bULL, 0x9d4e9d9cd327019dULL,\n\t0x6cad6c47c1d82b6cULL, 0x31c43195f562a431ULL, 0x74cd7487b9e8f374ULL,\n\t0xf6fff6e309f115f6ULL, 0x4605460a438c4c46ULL, 0xac8aac092645a5acULL,\n\t0x891e893c970fb589ULL, 0x145014a04428b414ULL, 0xe1a3e15b42dfbae1ULL,\n\t0x165816b04e2ca616ULL, 0x3ae83acdd274f73aULL, 0x69b9696fd0d20669ULL,\n\t0x092409482d124109ULL, 0x70dd70a7ade0d770ULL, 0xb6e2b6d954716fb6ULL,\n\t0xd067d0ceb7bd1ed0ULL, 0xed93ed3b7ec7d6edULL, 0xcc17cc2edb85e2ccULL,\n\t0x4215422a57846842ULL, 0x985a98b4c22d2c98ULL, 0xa4aaa4490e55eda4ULL,\n\t0x28a0285d88507528ULL, 0x5c6d5cda31b8865cULL, 0xf8c7f8933fed6bf8ULL,\n\t0x86228644a411c286ULL,\n};\n\nstatic const u64 rc[WHIRLPOOL_ROUNDS] = {\n\t0x1823c6e887b8014fULL,\n\t0x36a6d2f5796f9152ULL,\n\t0x60bc9b8ea30c7b35ULL,\n\t0x1de0d7c22e4bfe57ULL,\n\t0x157737e59ff04adaULL,\n\t0x58c9290ab1a06b85ULL,\n\t0xbd5d10f4cb3e0567ULL,\n\t0xe427418ba77d95d8ULL,\n\t0xfbee7c66dd17479eULL,\n\t0xca2dbf07ad5a8333ULL,\n};\n\n/**\n * The core Whirlpool transform.\n */\n\nstatic void wp512_process_buffer(struct wp512_ctx *wctx) {\n\tint i, r;\n\tu64 K[8];        /* the round key */\n\tu64 block[8];    /* mu(buffer) */\n\tu64 state[8];    /* the cipher state */\n\tu64 L[8];\n\tconst __be64 *buffer = (const __be64 *)wctx->buffer;\n\n\tfor (i = 0; i < 8; i++)\n\t\tblock[i] = be64_to_cpu(buffer[i]);\n\n\tstate[0] = block[0] ^ (K[0] = wctx->hash[0]);\n\tstate[1] = block[1] ^ (K[1] = wctx->hash[1]);\n\tstate[2] = block[2] ^ (K[2] = wctx->hash[2]);\n\tstate[3] = block[3] ^ (K[3] = wctx->hash[3]);\n\tstate[4] = block[4] ^ (K[4] = wctx->hash[4]);\n\tstate[5] = block[5] ^ (K[5] = wctx->hash[5]);\n\tstate[6] = block[6] ^ (K[6] = wctx->hash[6]);\n\tstate[7] = block[7] ^ (K[7] = wctx->hash[7]);\n\n\tfor (r = 0; r < WHIRLPOOL_ROUNDS; r++) {\n\n\t\tL[0] = C0[(int)(K[0] >> 56)       ] ^\n\t\t\t   C1[(int)(K[7] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(K[6] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(K[5] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(K[4] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(K[3] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(K[2] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(K[1]      ) & 0xff] ^\n\t\t\t   rc[r];\n\n\t\tL[1] = C0[(int)(K[1] >> 56)       ] ^\n\t\t\t   C1[(int)(K[0] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(K[7] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(K[6] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(K[5] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(K[4] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(K[3] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(K[2]      ) & 0xff];\n\n\t\tL[2] = C0[(int)(K[2] >> 56)       ] ^\n\t\t\t   C1[(int)(K[1] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(K[0] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(K[7] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(K[6] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(K[5] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(K[4] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(K[3]      ) & 0xff];\n\n\t\tL[3] = C0[(int)(K[3] >> 56)       ] ^\n\t\t\t   C1[(int)(K[2] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(K[1] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(K[0] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(K[7] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(K[6] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(K[5] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(K[4]      ) & 0xff];\n\n\t\tL[4] = C0[(int)(K[4] >> 56)       ] ^\n\t\t\t   C1[(int)(K[3] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(K[2] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(K[1] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(K[0] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(K[7] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(K[6] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(K[5]      ) & 0xff];\n\n\t\tL[5] = C0[(int)(K[5] >> 56)       ] ^\n\t\t\t   C1[(int)(K[4] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(K[3] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(K[2] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(K[1] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(K[0] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(K[7] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(K[6]      ) & 0xff];\n\n\t\tL[6] = C0[(int)(K[6] >> 56)       ] ^\n\t\t\t   C1[(int)(K[5] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(K[4] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(K[3] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(K[2] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(K[1] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(K[0] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(K[7]      ) & 0xff];\n\n\t\tL[7] = C0[(int)(K[7] >> 56)       ] ^\n\t\t\t   C1[(int)(K[6] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(K[5] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(K[4] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(K[3] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(K[2] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(K[1] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(K[0]      ) & 0xff];\n\n\t\tK[0] = L[0];\n\t\tK[1] = L[1];\n\t\tK[2] = L[2];\n\t\tK[3] = L[3];\n\t\tK[4] = L[4];\n\t\tK[5] = L[5];\n\t\tK[6] = L[6];\n\t\tK[7] = L[7];\n\n\t\tL[0] = C0[(int)(state[0] >> 56)       ] ^\n\t\t\t   C1[(int)(state[7] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(state[6] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(state[5] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(state[4] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(state[3] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(state[2] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(state[1]      ) & 0xff] ^\n\t\t\t   K[0];\n\n\t\tL[1] = C0[(int)(state[1] >> 56)       ] ^\n\t\t\t   C1[(int)(state[0] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(state[7] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(state[6] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(state[5] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(state[4] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(state[3] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(state[2]      ) & 0xff] ^\n\t\t\t   K[1];\n\n\t\tL[2] = C0[(int)(state[2] >> 56)       ] ^\n\t\t\t   C1[(int)(state[1] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(state[0] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(state[7] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(state[6] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(state[5] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(state[4] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(state[3]      ) & 0xff] ^\n\t\t\t   K[2];\n\n\t\tL[3] = C0[(int)(state[3] >> 56)       ] ^\n\t\t\t   C1[(int)(state[2] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(state[1] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(state[0] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(state[7] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(state[6] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(state[5] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(state[4]      ) & 0xff] ^\n\t\t\t   K[3];\n\n\t\tL[4] = C0[(int)(state[4] >> 56)       ] ^\n\t\t\t   C1[(int)(state[3] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(state[2] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(state[1] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(state[0] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(state[7] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(state[6] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(state[5]      ) & 0xff] ^\n\t\t\t   K[4];\n\n\t\tL[5] = C0[(int)(state[5] >> 56)       ] ^\n\t\t\t   C1[(int)(state[4] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(state[3] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(state[2] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(state[1] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(state[0] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(state[7] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(state[6]      ) & 0xff] ^\n\t\t\t   K[5];\n\n\t\tL[6] = C0[(int)(state[6] >> 56)       ] ^\n\t\t\t   C1[(int)(state[5] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(state[4] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(state[3] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(state[2] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(state[1] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(state[0] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(state[7]      ) & 0xff] ^\n\t\t\t   K[6];\n\n\t\tL[7] = C0[(int)(state[7] >> 56)       ] ^\n\t\t\t   C1[(int)(state[6] >> 48) & 0xff] ^\n\t\t\t   C2[(int)(state[5] >> 40) & 0xff] ^\n\t\t\t   C3[(int)(state[4] >> 32) & 0xff] ^\n\t\t\t   C4[(int)(state[3] >> 24) & 0xff] ^\n\t\t\t   C5[(int)(state[2] >> 16) & 0xff] ^\n\t\t\t   C6[(int)(state[1] >>  8) & 0xff] ^\n\t\t\t   C7[(int)(state[0]      ) & 0xff] ^\n\t\t\t   K[7];\n\n\t\tstate[0] = L[0];\n\t\tstate[1] = L[1];\n\t\tstate[2] = L[2];\n\t\tstate[3] = L[3];\n\t\tstate[4] = L[4];\n\t\tstate[5] = L[5];\n\t\tstate[6] = L[6];\n\t\tstate[7] = L[7];\n\t}\n\t/*\n\t* apply the Miyaguchi-Preneel compression function:\n\t*/\n\twctx->hash[0] ^= state[0] ^ block[0];\n\twctx->hash[1] ^= state[1] ^ block[1];\n\twctx->hash[2] ^= state[2] ^ block[2];\n\twctx->hash[3] ^= state[3] ^ block[3];\n\twctx->hash[4] ^= state[4] ^ block[4];\n\twctx->hash[5] ^= state[5] ^ block[5];\n\twctx->hash[6] ^= state[6] ^ block[6];\n\twctx->hash[7] ^= state[7] ^ block[7];\n\n}\n\nstatic int wp512_init(struct shash_desc *desc) {\n\tstruct wp512_ctx *wctx = shash_desc_ctx(desc);\n\tint i;\n\n\tmemset(wctx->bitLength, 0, 32);\n\twctx->bufferBits = wctx->bufferPos = 0;\n\twctx->buffer[0] = 0;\n\tfor (i = 0; i < 8; i++) {\n\t\twctx->hash[i] = 0L;\n\t}\n\n\treturn 0;\n}\n\nstatic int wp512_update(struct shash_desc *desc, const u8 *source,\n\t\t\t unsigned int len)\n{\n\tstruct wp512_ctx *wctx = shash_desc_ctx(desc);\n\tint sourcePos    = 0;\n\tunsigned int bits_len = len * 8; // convert to number of bits\n\tint sourceGap    = (8 - ((int)bits_len & 7)) & 7;\n\tint bufferRem    = wctx->bufferBits & 7;\n\tint i;\n\tu32 b, carry;\n\tu8 *buffer       = wctx->buffer;\n\tu8 *bitLength    = wctx->bitLength;\n\tint bufferBits   = wctx->bufferBits;\n\tint bufferPos    = wctx->bufferPos;\n\n\tu64 value = bits_len;\n\tfor (i = 31, carry = 0; i >= 0 && (carry != 0 || value != 0ULL); i--) {\n\t\tcarry += bitLength[i] + ((u32)value & 0xff);\n\t\tbitLength[i] = (u8)carry;\n\t\tcarry >>= 8;\n\t\tvalue >>= 8;\n\t}\n\twhile (bits_len > 8) {\n\t\tb = ((source[sourcePos] << sourceGap) & 0xff) |\n\t\t((source[sourcePos + 1] & 0xff) >> (8 - sourceGap));\n\t\tbuffer[bufferPos++] |= (u8)(b >> bufferRem);\n\t\tbufferBits += 8 - bufferRem;\n\t\tif (bufferBits == WP512_BLOCK_SIZE * 8) {\n\t\t\twp512_process_buffer(wctx);\n\t\t\tbufferBits = bufferPos = 0;\n\t\t}\n\t\tbuffer[bufferPos] = b << (8 - bufferRem);\n\t\tbufferBits += bufferRem;\n\t\tbits_len -= 8;\n\t\tsourcePos++;\n\t}\n\tif (bits_len > 0) {\n\t\tb = (source[sourcePos] << sourceGap) & 0xff;\n\t\tbuffer[bufferPos] |= b >> bufferRem;\n\t} else {\n\t\tb = 0;\n\t}\n\tif (bufferRem + bits_len < 8) {\n\t\tbufferBits += bits_len;\n\t} else {\n\t\tbufferPos++;\n\t\tbufferBits += 8 - bufferRem;\n\t\tbits_len -= 8 - bufferRem;\n\t\tif (bufferBits == WP512_BLOCK_SIZE * 8) {\n\t\t\twp512_process_buffer(wctx);\n\t\t\tbufferBits = bufferPos = 0;\n\t\t}\n\t\tbuffer[bufferPos] = b << (8 - bufferRem);\n\t\tbufferBits += (int)bits_len;\n\t}\n\n\twctx->bufferBits   = bufferBits;\n\twctx->bufferPos    = bufferPos;\n\n\treturn 0;\n}\n\nstatic int wp512_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct wp512_ctx *wctx = shash_desc_ctx(desc);\n\tint i;\n   \tu8 *buffer      = wctx->buffer;\n   \tu8 *bitLength   = wctx->bitLength;\n   \tint bufferBits  = wctx->bufferBits;\n   \tint bufferPos   = wctx->bufferPos;\n\t__be64 *digest  = (__be64 *)out;\n\n   \tbuffer[bufferPos] |= 0x80U >> (bufferBits & 7);\n   \tbufferPos++;\n   \tif (bufferPos > WP512_BLOCK_SIZE - WP512_LENGTHBYTES) {\n   \t\tif (bufferPos < WP512_BLOCK_SIZE) {\n\t   \tmemset(&buffer[bufferPos], 0, WP512_BLOCK_SIZE - bufferPos);\n   \t\t}\n   \t\twp512_process_buffer(wctx);\n   \t\tbufferPos = 0;\n   \t}\n   \tif (bufferPos < WP512_BLOCK_SIZE - WP512_LENGTHBYTES) {\n   \t\tmemset(&buffer[bufferPos], 0,\n\t\t\t  (WP512_BLOCK_SIZE - WP512_LENGTHBYTES) - bufferPos);\n   \t}\n   \tbufferPos = WP512_BLOCK_SIZE - WP512_LENGTHBYTES;\n   \tmemcpy(&buffer[WP512_BLOCK_SIZE - WP512_LENGTHBYTES],\n\t\t   bitLength, WP512_LENGTHBYTES);\n   \twp512_process_buffer(wctx);\n\tfor (i = 0; i < WP512_DIGEST_SIZE/8; i++)\n\t\tdigest[i] = cpu_to_be64(wctx->hash[i]);\n   \twctx->bufferBits   = bufferBits;\n   \twctx->bufferPos    = bufferPos;\n\n\treturn 0;\n}\n\nstatic int wp384_final(struct shash_desc *desc, u8 *out)\n{\n\tu8 D[64];\n\n\twp512_final(desc, D);\n\tmemcpy(out, D, WP384_DIGEST_SIZE);\n\tmemzero_explicit(D, WP512_DIGEST_SIZE);\n\n\treturn 0;\n}\n\nstatic int wp256_final(struct shash_desc *desc, u8 *out)\n{\n\tu8 D[64];\n\n\twp512_final(desc, D);\n\tmemcpy(out, D, WP256_DIGEST_SIZE);\n\tmemzero_explicit(D, WP512_DIGEST_SIZE);\n\n\treturn 0;\n}\n\nstatic struct shash_alg wp_algs[3] = { {\n\t.digestsize\t=\tWP512_DIGEST_SIZE,\n\t.init\t\t=\twp512_init,\n\t.update\t\t=\twp512_update,\n\t.final\t\t=\twp512_final,\n\t.descsize\t=\tsizeof(struct wp512_ctx),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"wp512\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tWP512_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n}, {\n\t.digestsize\t=\tWP384_DIGEST_SIZE,\n\t.init\t\t=\twp512_init,\n\t.update\t\t=\twp512_update,\n\t.final\t\t=\twp384_final,\n\t.descsize\t=\tsizeof(struct wp512_ctx),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"wp384\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tWP512_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n}, {\n\t.digestsize\t=\tWP256_DIGEST_SIZE,\n\t.init\t\t=\twp512_init,\n\t.update\t\t=\twp512_update,\n\t.final\t\t=\twp256_final,\n\t.descsize\t=\tsizeof(struct wp512_ctx),\n\t.base\t\t=\t{\n\t\t.cra_name\t=\t\"wp256\",\n\t\t.cra_flags\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t=\tWP512_BLOCK_SIZE,\n\t\t.cra_module\t=\tTHIS_MODULE,\n\t}\n} };\n\nstatic int __init wp512_mod_init(void)\n{\n\treturn crypto_register_shashes(wp_algs, ARRAY_SIZE(wp_algs));\n}\n\nstatic void __exit wp512_mod_fini(void)\n{\n\tcrypto_unregister_shashes(wp_algs, ARRAY_SIZE(wp_algs));\n}\n\nMODULE_ALIAS_CRYPTO(\"wp384\");\nMODULE_ALIAS_CRYPTO(\"wp256\");\n\nmodule_init(wp512_mod_init);\nmodule_exit(wp512_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Whirlpool Message Digest Algorithm\");\n", "/*\n * Cryptographic API.\n *\n * Zlib algorithm\n *\n * Copyright 2008 Sony Corporation\n *\n * Based on deflate.c, which is\n * Copyright (c) 2003 James Morris <jmorris@intercode.com.au>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n * FIXME: deflate transforms will require up to a total of about 436k of kernel\n * memory on i386 (390k for compression, the rest for decompression), as the\n * current zlib kernel code uses a worst case pre-allocation system by default.\n * This needs to be fixed so that the amount of memory required is properly\n * related to the winbits and memlevel parameters.\n */\n\n#define pr_fmt(fmt)\t\"%s: \" fmt, __func__\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/zlib.h>\n#include <linux/vmalloc.h>\n#include <linux/interrupt.h>\n#include <linux/mm.h>\n#include <linux/net.h>\n\n#include <crypto/internal/compress.h>\n\n#include <net/netlink.h>\n\n\nstruct zlib_ctx {\n\tstruct z_stream_s comp_stream;\n\tstruct z_stream_s decomp_stream;\n\tint decomp_windowBits;\n};\n\n\nstatic void zlib_comp_exit(struct zlib_ctx *ctx)\n{\n\tstruct z_stream_s *stream = &ctx->comp_stream;\n\n\tif (stream->workspace) {\n\t\tzlib_deflateEnd(stream);\n\t\tvfree(stream->workspace);\n\t\tstream->workspace = NULL;\n\t}\n}\n\nstatic void zlib_decomp_exit(struct zlib_ctx *ctx)\n{\n\tstruct z_stream_s *stream = &ctx->decomp_stream;\n\n\tif (stream->workspace) {\n\t\tzlib_inflateEnd(stream);\n\t\tvfree(stream->workspace);\n\t\tstream->workspace = NULL;\n\t}\n}\n\nstatic int zlib_init(struct crypto_tfm *tfm)\n{\n\treturn 0;\n}\n\nstatic void zlib_exit(struct crypto_tfm *tfm)\n{\n\tstruct zlib_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tzlib_comp_exit(ctx);\n\tzlib_decomp_exit(ctx);\n}\n\n\nstatic int zlib_compress_setup(struct crypto_pcomp *tfm, void *params,\n\t\t\t       unsigned int len)\n{\n\tstruct zlib_ctx *ctx = crypto_tfm_ctx(crypto_pcomp_tfm(tfm));\n\tstruct z_stream_s *stream = &ctx->comp_stream;\n\tstruct nlattr *tb[ZLIB_COMP_MAX + 1];\n\tint window_bits, mem_level;\n\tsize_t workspacesize;\n\tint ret;\n\n\tret = nla_parse(tb, ZLIB_COMP_MAX, params, len, NULL);\n\tif (ret)\n\t\treturn ret;\n\n\tzlib_comp_exit(ctx);\n\n\twindow_bits = tb[ZLIB_COMP_WINDOWBITS]\n\t\t\t\t\t? nla_get_u32(tb[ZLIB_COMP_WINDOWBITS])\n\t\t\t\t\t: MAX_WBITS;\n\tmem_level = tb[ZLIB_COMP_MEMLEVEL]\n\t\t\t\t\t? nla_get_u32(tb[ZLIB_COMP_MEMLEVEL])\n\t\t\t\t\t: DEF_MEM_LEVEL;\n\n\tworkspacesize = zlib_deflate_workspacesize(window_bits, mem_level);\n\tstream->workspace = vzalloc(workspacesize);\n\tif (!stream->workspace)\n\t\treturn -ENOMEM;\n\n\tret = zlib_deflateInit2(stream,\n\t\t\t\ttb[ZLIB_COMP_LEVEL]\n\t\t\t\t\t? nla_get_u32(tb[ZLIB_COMP_LEVEL])\n\t\t\t\t\t: Z_DEFAULT_COMPRESSION,\n\t\t\t\ttb[ZLIB_COMP_METHOD]\n\t\t\t\t\t? nla_get_u32(tb[ZLIB_COMP_METHOD])\n\t\t\t\t\t: Z_DEFLATED,\n\t\t\t\twindow_bits,\n\t\t\t\tmem_level,\n\t\t\t\ttb[ZLIB_COMP_STRATEGY]\n\t\t\t\t\t? nla_get_u32(tb[ZLIB_COMP_STRATEGY])\n\t\t\t\t\t: Z_DEFAULT_STRATEGY);\n\tif (ret != Z_OK) {\n\t\tvfree(stream->workspace);\n\t\tstream->workspace = NULL;\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int zlib_compress_init(struct crypto_pcomp *tfm)\n{\n\tint ret;\n\tstruct zlib_ctx *dctx = crypto_tfm_ctx(crypto_pcomp_tfm(tfm));\n\tstruct z_stream_s *stream = &dctx->comp_stream;\n\n\tret = zlib_deflateReset(stream);\n\tif (ret != Z_OK)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int zlib_compress_update(struct crypto_pcomp *tfm,\n\t\t\t\tstruct comp_request *req)\n{\n\tint ret;\n\tstruct zlib_ctx *dctx = crypto_tfm_ctx(crypto_pcomp_tfm(tfm));\n\tstruct z_stream_s *stream = &dctx->comp_stream;\n\n\tpr_debug(\"avail_in %u, avail_out %u\\n\", req->avail_in, req->avail_out);\n\tstream->next_in = req->next_in;\n\tstream->avail_in = req->avail_in;\n\tstream->next_out = req->next_out;\n\tstream->avail_out = req->avail_out;\n\n\tret = zlib_deflate(stream, Z_NO_FLUSH);\n\tswitch (ret) {\n\tcase Z_OK:\n\t\tbreak;\n\n\tcase Z_BUF_ERROR:\n\t\tpr_debug(\"zlib_deflate could not make progress\\n\");\n\t\treturn -EAGAIN;\n\n\tdefault:\n\t\tpr_debug(\"zlib_deflate failed %d\\n\", ret);\n\t\treturn -EINVAL;\n\t}\n\n\tret = req->avail_out - stream->avail_out;\n\tpr_debug(\"avail_in %lu, avail_out %lu (consumed %lu, produced %u)\\n\",\n\t\t stream->avail_in, stream->avail_out,\n\t\t req->avail_in - stream->avail_in, ret);\n\treq->next_in = stream->next_in;\n\treq->avail_in = stream->avail_in;\n\treq->next_out = stream->next_out;\n\treq->avail_out = stream->avail_out;\n\treturn ret;\n}\n\nstatic int zlib_compress_final(struct crypto_pcomp *tfm,\n\t\t\t       struct comp_request *req)\n{\n\tint ret;\n\tstruct zlib_ctx *dctx = crypto_tfm_ctx(crypto_pcomp_tfm(tfm));\n\tstruct z_stream_s *stream = &dctx->comp_stream;\n\n\tpr_debug(\"avail_in %u, avail_out %u\\n\", req->avail_in, req->avail_out);\n\tstream->next_in = req->next_in;\n\tstream->avail_in = req->avail_in;\n\tstream->next_out = req->next_out;\n\tstream->avail_out = req->avail_out;\n\n\tret = zlib_deflate(stream, Z_FINISH);\n\tif (ret != Z_STREAM_END) {\n\t\tpr_debug(\"zlib_deflate failed %d\\n\", ret);\n\t\treturn -EINVAL;\n\t}\n\n\tret = req->avail_out - stream->avail_out;\n\tpr_debug(\"avail_in %lu, avail_out %lu (consumed %lu, produced %u)\\n\",\n\t\t stream->avail_in, stream->avail_out,\n\t\t req->avail_in - stream->avail_in, ret);\n\treq->next_in = stream->next_in;\n\treq->avail_in = stream->avail_in;\n\treq->next_out = stream->next_out;\n\treq->avail_out = stream->avail_out;\n\treturn ret;\n}\n\n\nstatic int zlib_decompress_setup(struct crypto_pcomp *tfm, void *params,\n\t\t\t\t unsigned int len)\n{\n\tstruct zlib_ctx *ctx = crypto_tfm_ctx(crypto_pcomp_tfm(tfm));\n\tstruct z_stream_s *stream = &ctx->decomp_stream;\n\tstruct nlattr *tb[ZLIB_DECOMP_MAX + 1];\n\tint ret = 0;\n\n\tret = nla_parse(tb, ZLIB_DECOMP_MAX, params, len, NULL);\n\tif (ret)\n\t\treturn ret;\n\n\tzlib_decomp_exit(ctx);\n\n\tctx->decomp_windowBits = tb[ZLIB_DECOMP_WINDOWBITS]\n\t\t\t\t ? nla_get_u32(tb[ZLIB_DECOMP_WINDOWBITS])\n\t\t\t\t : DEF_WBITS;\n\n\tstream->workspace = vzalloc(zlib_inflate_workspacesize());\n\tif (!stream->workspace)\n\t\treturn -ENOMEM;\n\n\tret = zlib_inflateInit2(stream, ctx->decomp_windowBits);\n\tif (ret != Z_OK) {\n\t\tvfree(stream->workspace);\n\t\tstream->workspace = NULL;\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int zlib_decompress_init(struct crypto_pcomp *tfm)\n{\n\tint ret;\n\tstruct zlib_ctx *dctx = crypto_tfm_ctx(crypto_pcomp_tfm(tfm));\n\tstruct z_stream_s *stream = &dctx->decomp_stream;\n\n\tret = zlib_inflateReset(stream);\n\tif (ret != Z_OK)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int zlib_decompress_update(struct crypto_pcomp *tfm,\n\t\t\t\t  struct comp_request *req)\n{\n\tint ret;\n\tstruct zlib_ctx *dctx = crypto_tfm_ctx(crypto_pcomp_tfm(tfm));\n\tstruct z_stream_s *stream = &dctx->decomp_stream;\n\n\tpr_debug(\"avail_in %u, avail_out %u\\n\", req->avail_in, req->avail_out);\n\tstream->next_in = req->next_in;\n\tstream->avail_in = req->avail_in;\n\tstream->next_out = req->next_out;\n\tstream->avail_out = req->avail_out;\n\n\tret = zlib_inflate(stream, Z_SYNC_FLUSH);\n\tswitch (ret) {\n\tcase Z_OK:\n\tcase Z_STREAM_END:\n\t\tbreak;\n\n\tcase Z_BUF_ERROR:\n\t\tpr_debug(\"zlib_inflate could not make progress\\n\");\n\t\treturn -EAGAIN;\n\n\tdefault:\n\t\tpr_debug(\"zlib_inflate failed %d\\n\", ret);\n\t\treturn -EINVAL;\n\t}\n\n\tret = req->avail_out - stream->avail_out;\n\tpr_debug(\"avail_in %lu, avail_out %lu (consumed %lu, produced %u)\\n\",\n\t\t stream->avail_in, stream->avail_out,\n\t\t req->avail_in - stream->avail_in, ret);\n\treq->next_in = stream->next_in;\n\treq->avail_in = stream->avail_in;\n\treq->next_out = stream->next_out;\n\treq->avail_out = stream->avail_out;\n\treturn ret;\n}\n\nstatic int zlib_decompress_final(struct crypto_pcomp *tfm,\n\t\t\t\t struct comp_request *req)\n{\n\tint ret;\n\tstruct zlib_ctx *dctx = crypto_tfm_ctx(crypto_pcomp_tfm(tfm));\n\tstruct z_stream_s *stream = &dctx->decomp_stream;\n\n\tpr_debug(\"avail_in %u, avail_out %u\\n\", req->avail_in, req->avail_out);\n\tstream->next_in = req->next_in;\n\tstream->avail_in = req->avail_in;\n\tstream->next_out = req->next_out;\n\tstream->avail_out = req->avail_out;\n\n\tif (dctx->decomp_windowBits < 0) {\n\t\tret = zlib_inflate(stream, Z_SYNC_FLUSH);\n\t\t/*\n\t\t * Work around a bug in zlib, which sometimes wants to taste an\n\t\t * extra byte when being used in the (undocumented) raw deflate\n\t\t * mode. (From USAGI).\n\t\t */\n\t\tif (ret == Z_OK && !stream->avail_in && stream->avail_out) {\n\t\t\tconst void *saved_next_in = stream->next_in;\n\t\t\tu8 zerostuff = 0;\n\n\t\t\tstream->next_in = &zerostuff;\n\t\t\tstream->avail_in = 1;\n\t\t\tret = zlib_inflate(stream, Z_FINISH);\n\t\t\tstream->next_in = saved_next_in;\n\t\t\tstream->avail_in = 0;\n\t\t}\n\t} else\n\t\tret = zlib_inflate(stream, Z_FINISH);\n\tif (ret != Z_STREAM_END) {\n\t\tpr_debug(\"zlib_inflate failed %d\\n\", ret);\n\t\treturn -EINVAL;\n\t}\n\n\tret = req->avail_out - stream->avail_out;\n\tpr_debug(\"avail_in %lu, avail_out %lu (consumed %lu, produced %u)\\n\",\n\t\t stream->avail_in, stream->avail_out,\n\t\t req->avail_in - stream->avail_in, ret);\n\treq->next_in = stream->next_in;\n\treq->avail_in = stream->avail_in;\n\treq->next_out = stream->next_out;\n\treq->avail_out = stream->avail_out;\n\treturn ret;\n}\n\n\nstatic struct pcomp_alg zlib_alg = {\n\t.compress_setup\t\t= zlib_compress_setup,\n\t.compress_init\t\t= zlib_compress_init,\n\t.compress_update\t= zlib_compress_update,\n\t.compress_final\t\t= zlib_compress_final,\n\t.decompress_setup\t= zlib_decompress_setup,\n\t.decompress_init\t= zlib_decompress_init,\n\t.decompress_update\t= zlib_decompress_update,\n\t.decompress_final\t= zlib_decompress_final,\n\n\t.base\t\t\t= {\n\t\t.cra_name\t= \"zlib\",\n\t\t.cra_flags\t= CRYPTO_ALG_TYPE_PCOMPRESS,\n\t\t.cra_ctxsize\t= sizeof(struct zlib_ctx),\n\t\t.cra_module\t= THIS_MODULE,\n\t\t.cra_init\t= zlib_init,\n\t\t.cra_exit\t= zlib_exit,\n\t}\n};\n\nstatic int __init zlib_mod_init(void)\n{\n\treturn crypto_register_pcomp(&zlib_alg);\n}\n\nstatic void __exit zlib_mod_fini(void)\n{\n\tcrypto_unregister_pcomp(&zlib_alg);\n}\n\nmodule_init(zlib_mod_init);\nmodule_exit(zlib_mod_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Zlib Compression Algorithm\");\nMODULE_AUTHOR(\"Sony Corporation\");\nMODULE_ALIAS_CRYPTO(\"zlib\");\n", "/* \n * Cryptographic API.\n *\n * Support for VIA PadLock hardware crypto engine.\n *\n * Copyright (c) 2004  Michal Ludvig <michal@logix.cz>\n *\n */\n\n#include <crypto/algapi.h>\n#include <crypto/aes.h>\n#include <crypto/padlock.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/types.h>\n#include <linux/errno.h>\n#include <linux/interrupt.h>\n#include <linux/kernel.h>\n#include <linux/percpu.h>\n#include <linux/smp.h>\n#include <linux/slab.h>\n#include <asm/cpu_device_id.h>\n#include <asm/byteorder.h>\n#include <asm/processor.h>\n#include <asm/i387.h>\n\n/*\n * Number of data blocks actually fetched for each xcrypt insn.\n * Processors with prefetch errata will fetch extra blocks.\n */\nstatic unsigned int ecb_fetch_blocks = 2;\n#define MAX_ECB_FETCH_BLOCKS (8)\n#define ecb_fetch_bytes (ecb_fetch_blocks * AES_BLOCK_SIZE)\n\nstatic unsigned int cbc_fetch_blocks = 1;\n#define MAX_CBC_FETCH_BLOCKS (4)\n#define cbc_fetch_bytes (cbc_fetch_blocks * AES_BLOCK_SIZE)\n\n/* Control word. */\nstruct cword {\n\tunsigned int __attribute__ ((__packed__))\n\t\trounds:4,\n\t\talgo:3,\n\t\tkeygen:1,\n\t\tinterm:1,\n\t\tencdec:1,\n\t\tksize:2;\n} __attribute__ ((__aligned__(PADLOCK_ALIGNMENT)));\n\n/* Whenever making any changes to the following\n * structure *make sure* you keep E, d_data\n * and cword aligned on 16 Bytes boundaries and\n * the Hardware can access 16 * 16 bytes of E and d_data\n * (only the first 15 * 16 bytes matter but the HW reads\n * more).\n */\nstruct aes_ctx {\n\tu32 E[AES_MAX_KEYLENGTH_U32]\n\t\t__attribute__ ((__aligned__(PADLOCK_ALIGNMENT)));\n\tu32 d_data[AES_MAX_KEYLENGTH_U32]\n\t\t__attribute__ ((__aligned__(PADLOCK_ALIGNMENT)));\n\tstruct {\n\t\tstruct cword encrypt;\n\t\tstruct cword decrypt;\n\t} cword;\n\tu32 *D;\n};\n\nstatic DEFINE_PER_CPU(struct cword *, paes_last_cword);\n\n/* Tells whether the ACE is capable to generate\n   the extended key for a given key_len. */\nstatic inline int\naes_hw_extkey_available(uint8_t key_len)\n{\n\t/* TODO: We should check the actual CPU model/stepping\n\t         as it's possible that the capability will be\n\t         added in the next CPU revisions. */\n\tif (key_len == 16)\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic inline struct aes_ctx *aes_ctx_common(void *ctx)\n{\n\tunsigned long addr = (unsigned long)ctx;\n\tunsigned long align = PADLOCK_ALIGNMENT;\n\n\tif (align <= crypto_tfm_ctx_alignment())\n\t\talign = 1;\n\treturn (struct aes_ctx *)ALIGN(addr, align);\n}\n\nstatic inline struct aes_ctx *aes_ctx(struct crypto_tfm *tfm)\n{\n\treturn aes_ctx_common(crypto_tfm_ctx(tfm));\n}\n\nstatic inline struct aes_ctx *blk_aes_ctx(struct crypto_blkcipher *tfm)\n{\n\treturn aes_ctx_common(crypto_blkcipher_ctx(tfm));\n}\n\nstatic int aes_set_key(struct crypto_tfm *tfm, const u8 *in_key,\n\t\t       unsigned int key_len)\n{\n\tstruct aes_ctx *ctx = aes_ctx(tfm);\n\tconst __le32 *key = (const __le32 *)in_key;\n\tu32 *flags = &tfm->crt_flags;\n\tstruct crypto_aes_ctx gen_aes;\n\tint cpu;\n\n\tif (key_len % 8) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\t/*\n\t * If the hardware is capable of generating the extended key\n\t * itself we must supply the plain key for both encryption\n\t * and decryption.\n\t */\n\tctx->D = ctx->E;\n\n\tctx->E[0] = le32_to_cpu(key[0]);\n\tctx->E[1] = le32_to_cpu(key[1]);\n\tctx->E[2] = le32_to_cpu(key[2]);\n\tctx->E[3] = le32_to_cpu(key[3]);\n\n\t/* Prepare control words. */\n\tmemset(&ctx->cword, 0, sizeof(ctx->cword));\n\n\tctx->cword.decrypt.encdec = 1;\n\tctx->cword.encrypt.rounds = 10 + (key_len - 16) / 4;\n\tctx->cword.decrypt.rounds = ctx->cword.encrypt.rounds;\n\tctx->cword.encrypt.ksize = (key_len - 16) / 8;\n\tctx->cword.decrypt.ksize = ctx->cword.encrypt.ksize;\n\n\t/* Don't generate extended keys if the hardware can do it. */\n\tif (aes_hw_extkey_available(key_len))\n\t\tgoto ok;\n\n\tctx->D = ctx->d_data;\n\tctx->cword.encrypt.keygen = 1;\n\tctx->cword.decrypt.keygen = 1;\n\n\tif (crypto_aes_expand_key(&gen_aes, in_key, key_len)) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(ctx->E, gen_aes.key_enc, AES_MAX_KEYLENGTH);\n\tmemcpy(ctx->D, gen_aes.key_dec, AES_MAX_KEYLENGTH);\n\nok:\n\tfor_each_online_cpu(cpu)\n\t\tif (&ctx->cword.encrypt == per_cpu(paes_last_cword, cpu) ||\n\t\t    &ctx->cword.decrypt == per_cpu(paes_last_cword, cpu))\n\t\t\tper_cpu(paes_last_cword, cpu) = NULL;\n\n\treturn 0;\n}\n\n/* ====== Encryption/decryption routines ====== */\n\n/* These are the real call to PadLock. */\nstatic inline void padlock_reset_key(struct cword *cword)\n{\n\tint cpu = raw_smp_processor_id();\n\n\tif (cword != per_cpu(paes_last_cword, cpu))\n#ifndef CONFIG_X86_64\n\t\tasm volatile (\"pushfl; popfl\");\n#else\n\t\tasm volatile (\"pushfq; popfq\");\n#endif\n}\n\nstatic inline void padlock_store_cword(struct cword *cword)\n{\n\tper_cpu(paes_last_cword, raw_smp_processor_id()) = cword;\n}\n\n/*\n * While the padlock instructions don't use FP/SSE registers, they\n * generate a spurious DNA fault when cr0.ts is '1'. These instructions\n * should be used only inside the irq_ts_save/restore() context\n */\n\nstatic inline void rep_xcrypt_ecb(const u8 *input, u8 *output, void *key,\n\t\t\t\t  struct cword *control_word, int count)\n{\n\tasm volatile (\".byte 0xf3,0x0f,0xa7,0xc8\"\t/* rep xcryptecb */\n\t\t      : \"+S\"(input), \"+D\"(output)\n\t\t      : \"d\"(control_word), \"b\"(key), \"c\"(count));\n}\n\nstatic inline u8 *rep_xcrypt_cbc(const u8 *input, u8 *output, void *key,\n\t\t\t\t u8 *iv, struct cword *control_word, int count)\n{\n\tasm volatile (\".byte 0xf3,0x0f,0xa7,0xd0\"\t/* rep xcryptcbc */\n\t\t      : \"+S\" (input), \"+D\" (output), \"+a\" (iv)\n\t\t      : \"d\" (control_word), \"b\" (key), \"c\" (count));\n\treturn iv;\n}\n\nstatic void ecb_crypt_copy(const u8 *in, u8 *out, u32 *key,\n\t\t\t   struct cword *cword, int count)\n{\n\t/*\n\t * Padlock prefetches extra data so we must provide mapped input buffers.\n\t * Assume there are at least 16 bytes of stack already in use.\n\t */\n\tu8 buf[AES_BLOCK_SIZE * (MAX_ECB_FETCH_BLOCKS - 1) + PADLOCK_ALIGNMENT - 1];\n\tu8 *tmp = PTR_ALIGN(&buf[0], PADLOCK_ALIGNMENT);\n\n\tmemcpy(tmp, in, count * AES_BLOCK_SIZE);\n\trep_xcrypt_ecb(tmp, out, key, cword, count);\n}\n\nstatic u8 *cbc_crypt_copy(const u8 *in, u8 *out, u32 *key,\n\t\t\t   u8 *iv, struct cword *cword, int count)\n{\n\t/*\n\t * Padlock prefetches extra data so we must provide mapped input buffers.\n\t * Assume there are at least 16 bytes of stack already in use.\n\t */\n\tu8 buf[AES_BLOCK_SIZE * (MAX_CBC_FETCH_BLOCKS - 1) + PADLOCK_ALIGNMENT - 1];\n\tu8 *tmp = PTR_ALIGN(&buf[0], PADLOCK_ALIGNMENT);\n\n\tmemcpy(tmp, in, count * AES_BLOCK_SIZE);\n\treturn rep_xcrypt_cbc(tmp, out, key, iv, cword, count);\n}\n\nstatic inline void ecb_crypt(const u8 *in, u8 *out, u32 *key,\n\t\t\t     struct cword *cword, int count)\n{\n\t/* Padlock in ECB mode fetches at least ecb_fetch_bytes of data.\n\t * We could avoid some copying here but it's probably not worth it.\n\t */\n\tif (unlikely(((unsigned long)in & ~PAGE_MASK) + ecb_fetch_bytes > PAGE_SIZE)) {\n\t\tecb_crypt_copy(in, out, key, cword, count);\n\t\treturn;\n\t}\n\n\trep_xcrypt_ecb(in, out, key, cword, count);\n}\n\nstatic inline u8 *cbc_crypt(const u8 *in, u8 *out, u32 *key,\n\t\t\t    u8 *iv, struct cword *cword, int count)\n{\n\t/* Padlock in CBC mode fetches at least cbc_fetch_bytes of data. */\n\tif (unlikely(((unsigned long)in & ~PAGE_MASK) + cbc_fetch_bytes > PAGE_SIZE))\n\t\treturn cbc_crypt_copy(in, out, key, iv, cword, count);\n\n\treturn rep_xcrypt_cbc(in, out, key, iv, cword, count);\n}\n\nstatic inline void padlock_xcrypt_ecb(const u8 *input, u8 *output, void *key,\n\t\t\t\t      void *control_word, u32 count)\n{\n\tu32 initial = count & (ecb_fetch_blocks - 1);\n\n\tif (count < ecb_fetch_blocks) {\n\t\tecb_crypt(input, output, key, control_word, count);\n\t\treturn;\n\t}\n\n\tif (initial)\n\t\tasm volatile (\".byte 0xf3,0x0f,0xa7,0xc8\"\t/* rep xcryptecb */\n\t\t\t      : \"+S\"(input), \"+D\"(output)\n\t\t\t      : \"d\"(control_word), \"b\"(key), \"c\"(initial));\n\n\tasm volatile (\".byte 0xf3,0x0f,0xa7,0xc8\"\t/* rep xcryptecb */\n\t\t      : \"+S\"(input), \"+D\"(output)\n\t\t      : \"d\"(control_word), \"b\"(key), \"c\"(count - initial));\n}\n\nstatic inline u8 *padlock_xcrypt_cbc(const u8 *input, u8 *output, void *key,\n\t\t\t\t     u8 *iv, void *control_word, u32 count)\n{\n\tu32 initial = count & (cbc_fetch_blocks - 1);\n\n\tif (count < cbc_fetch_blocks)\n\t\treturn cbc_crypt(input, output, key, iv, control_word, count);\n\n\tif (initial)\n\t\tasm volatile (\".byte 0xf3,0x0f,0xa7,0xd0\"\t/* rep xcryptcbc */\n\t\t\t      : \"+S\" (input), \"+D\" (output), \"+a\" (iv)\n\t\t\t      : \"d\" (control_word), \"b\" (key), \"c\" (initial));\n\n\tasm volatile (\".byte 0xf3,0x0f,0xa7,0xd0\"\t/* rep xcryptcbc */\n\t\t      : \"+S\" (input), \"+D\" (output), \"+a\" (iv)\n\t\t      : \"d\" (control_word), \"b\" (key), \"c\" (count-initial));\n\treturn iv;\n}\n\nstatic void aes_encrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tstruct aes_ctx *ctx = aes_ctx(tfm);\n\tint ts_state;\n\n\tpadlock_reset_key(&ctx->cword.encrypt);\n\tts_state = irq_ts_save();\n\tecb_crypt(in, out, ctx->E, &ctx->cword.encrypt, 1);\n\tirq_ts_restore(ts_state);\n\tpadlock_store_cword(&ctx->cword.encrypt);\n}\n\nstatic void aes_decrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tstruct aes_ctx *ctx = aes_ctx(tfm);\n\tint ts_state;\n\n\tpadlock_reset_key(&ctx->cword.encrypt);\n\tts_state = irq_ts_save();\n\tecb_crypt(in, out, ctx->D, &ctx->cword.decrypt, 1);\n\tirq_ts_restore(ts_state);\n\tpadlock_store_cword(&ctx->cword.encrypt);\n}\n\nstatic struct crypto_alg aes_alg = {\n\t.cra_name\t\t=\t\"aes\",\n\t.cra_driver_name\t=\t\"aes-padlock\",\n\t.cra_priority\t\t=\tPADLOCK_CRA_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_CIPHER,\n\t.cra_blocksize\t\t=\tAES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct aes_ctx),\n\t.cra_alignmask\t\t=\tPADLOCK_ALIGNMENT - 1,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.cipher = {\n\t\t\t.cia_min_keysize\t=\tAES_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t=\tAES_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t   \t= \taes_set_key,\n\t\t\t.cia_encrypt\t \t=\taes_encrypt,\n\t\t\t.cia_decrypt\t  \t=\taes_decrypt,\n\t\t}\n\t}\n};\n\nstatic int ecb_aes_encrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct aes_ctx *ctx = blk_aes_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tint err;\n\tint ts_state;\n\n\tpadlock_reset_key(&ctx->cword.encrypt);\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\tts_state = irq_ts_save();\n\twhile ((nbytes = walk.nbytes)) {\n\t\tpadlock_xcrypt_ecb(walk.src.virt.addr, walk.dst.virt.addr,\n\t\t\t\t   ctx->E, &ctx->cword.encrypt,\n\t\t\t\t   nbytes / AES_BLOCK_SIZE);\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tirq_ts_restore(ts_state);\n\n\tpadlock_store_cword(&ctx->cword.encrypt);\n\n\treturn err;\n}\n\nstatic int ecb_aes_decrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct aes_ctx *ctx = blk_aes_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tint err;\n\tint ts_state;\n\n\tpadlock_reset_key(&ctx->cword.decrypt);\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\tts_state = irq_ts_save();\n\twhile ((nbytes = walk.nbytes)) {\n\t\tpadlock_xcrypt_ecb(walk.src.virt.addr, walk.dst.virt.addr,\n\t\t\t\t   ctx->D, &ctx->cword.decrypt,\n\t\t\t\t   nbytes / AES_BLOCK_SIZE);\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tirq_ts_restore(ts_state);\n\n\tpadlock_store_cword(&ctx->cword.encrypt);\n\n\treturn err;\n}\n\nstatic struct crypto_alg ecb_aes_alg = {\n\t.cra_name\t\t=\t\"ecb(aes)\",\n\t.cra_driver_name\t=\t\"ecb-aes-padlock\",\n\t.cra_priority\t\t=\tPADLOCK_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t=\tAES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct aes_ctx),\n\t.cra_alignmask\t\t=\tPADLOCK_ALIGNMENT - 1,\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\tAES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\tAES_MAX_KEY_SIZE,\n\t\t\t.setkey\t   \t\t= \taes_set_key,\n\t\t\t.encrypt\t\t=\tecb_aes_encrypt,\n\t\t\t.decrypt\t\t=\tecb_aes_decrypt,\n\t\t}\n\t}\n};\n\nstatic int cbc_aes_encrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct aes_ctx *ctx = blk_aes_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tint err;\n\tint ts_state;\n\n\tpadlock_reset_key(&ctx->cword.encrypt);\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\tts_state = irq_ts_save();\n\twhile ((nbytes = walk.nbytes)) {\n\t\tu8 *iv = padlock_xcrypt_cbc(walk.src.virt.addr,\n\t\t\t\t\t    walk.dst.virt.addr, ctx->E,\n\t\t\t\t\t    walk.iv, &ctx->cword.encrypt,\n\t\t\t\t\t    nbytes / AES_BLOCK_SIZE);\n\t\tmemcpy(walk.iv, iv, AES_BLOCK_SIZE);\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\tirq_ts_restore(ts_state);\n\n\tpadlock_store_cword(&ctx->cword.decrypt);\n\n\treturn err;\n}\n\nstatic int cbc_aes_decrypt(struct blkcipher_desc *desc,\n\t\t\t   struct scatterlist *dst, struct scatterlist *src,\n\t\t\t   unsigned int nbytes)\n{\n\tstruct aes_ctx *ctx = blk_aes_ctx(desc->tfm);\n\tstruct blkcipher_walk walk;\n\tint err;\n\tint ts_state;\n\n\tpadlock_reset_key(&ctx->cword.encrypt);\n\n\tblkcipher_walk_init(&walk, dst, src, nbytes);\n\terr = blkcipher_walk_virt(desc, &walk);\n\n\tts_state = irq_ts_save();\n\twhile ((nbytes = walk.nbytes)) {\n\t\tpadlock_xcrypt_cbc(walk.src.virt.addr, walk.dst.virt.addr,\n\t\t\t\t   ctx->D, walk.iv, &ctx->cword.decrypt,\n\t\t\t\t   nbytes / AES_BLOCK_SIZE);\n\t\tnbytes &= AES_BLOCK_SIZE - 1;\n\t\terr = blkcipher_walk_done(desc, &walk, nbytes);\n\t}\n\n\tirq_ts_restore(ts_state);\n\n\tpadlock_store_cword(&ctx->cword.encrypt);\n\n\treturn err;\n}\n\nstatic struct crypto_alg cbc_aes_alg = {\n\t.cra_name\t\t=\t\"cbc(aes)\",\n\t.cra_driver_name\t=\t\"cbc-aes-padlock\",\n\t.cra_priority\t\t=\tPADLOCK_COMPOSITE_PRIORITY,\n\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_BLKCIPHER,\n\t.cra_blocksize\t\t=\tAES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct aes_ctx),\n\t.cra_alignmask\t\t=\tPADLOCK_ALIGNMENT - 1,\n\t.cra_type\t\t=\t&crypto_blkcipher_type,\n\t.cra_module\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t=\t{\n\t\t.blkcipher = {\n\t\t\t.min_keysize\t\t=\tAES_MIN_KEY_SIZE,\n\t\t\t.max_keysize\t\t=\tAES_MAX_KEY_SIZE,\n\t\t\t.ivsize\t\t\t=\tAES_BLOCK_SIZE,\n\t\t\t.setkey\t   \t\t= \taes_set_key,\n\t\t\t.encrypt\t\t=\tcbc_aes_encrypt,\n\t\t\t.decrypt\t\t=\tcbc_aes_decrypt,\n\t\t}\n\t}\n};\n\nstatic struct x86_cpu_id padlock_cpu_id[] = {\n\tX86_FEATURE_MATCH(X86_FEATURE_XCRYPT),\n\t{}\n};\nMODULE_DEVICE_TABLE(x86cpu, padlock_cpu_id);\n\nstatic int __init padlock_init(void)\n{\n\tint ret;\n\tstruct cpuinfo_x86 *c = &cpu_data(0);\n\n\tif (!x86_match_cpu(padlock_cpu_id))\n\t\treturn -ENODEV;\n\n\tif (!cpu_has_xcrypt_enabled) {\n\t\tprintk(KERN_NOTICE PFX \"VIA PadLock detected, but not enabled. Hmm, strange...\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif ((ret = crypto_register_alg(&aes_alg)))\n\t\tgoto aes_err;\n\n\tif ((ret = crypto_register_alg(&ecb_aes_alg)))\n\t\tgoto ecb_aes_err;\n\n\tif ((ret = crypto_register_alg(&cbc_aes_alg)))\n\t\tgoto cbc_aes_err;\n\n\tprintk(KERN_NOTICE PFX \"Using VIA PadLock ACE for AES algorithm.\\n\");\n\n\tif (c->x86 == 6 && c->x86_model == 15 && c->x86_mask == 2) {\n\t\tecb_fetch_blocks = MAX_ECB_FETCH_BLOCKS;\n\t\tcbc_fetch_blocks = MAX_CBC_FETCH_BLOCKS;\n\t\tprintk(KERN_NOTICE PFX \"VIA Nano stepping 2 detected: enabling workaround.\\n\");\n\t}\n\nout:\n\treturn ret;\n\ncbc_aes_err:\n\tcrypto_unregister_alg(&ecb_aes_alg);\necb_aes_err:\n\tcrypto_unregister_alg(&aes_alg);\naes_err:\n\tprintk(KERN_ERR PFX \"VIA PadLock AES initialization failed.\\n\");\n\tgoto out;\n}\n\nstatic void __exit padlock_fini(void)\n{\n\tcrypto_unregister_alg(&cbc_aes_alg);\n\tcrypto_unregister_alg(&ecb_aes_alg);\n\tcrypto_unregister_alg(&aes_alg);\n}\n\nmodule_init(padlock_init);\nmodule_exit(padlock_fini);\n\nMODULE_DESCRIPTION(\"VIA PadLock AES algorithm support\");\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Michal Ludvig\");\n\nMODULE_ALIAS_CRYPTO(\"aes\");\n", "/*\n * Cryptographic API.\n *\n * Support for VIA PadLock hardware crypto engine.\n *\n * Copyright (c) 2006  Michal Ludvig <michal@logix.cz>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n */\n\n#include <crypto/internal/hash.h>\n#include <crypto/padlock.h>\n#include <crypto/sha.h>\n#include <linux/err.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/errno.h>\n#include <linux/interrupt.h>\n#include <linux/kernel.h>\n#include <linux/scatterlist.h>\n#include <asm/cpu_device_id.h>\n#include <asm/i387.h>\n\nstruct padlock_sha_desc {\n\tstruct shash_desc fallback;\n};\n\nstruct padlock_sha_ctx {\n\tstruct crypto_shash *fallback;\n};\n\nstatic int padlock_sha_init(struct shash_desc *desc)\n{\n\tstruct padlock_sha_desc *dctx = shash_desc_ctx(desc);\n\tstruct padlock_sha_ctx *ctx = crypto_shash_ctx(desc->tfm);\n\n\tdctx->fallback.tfm = ctx->fallback;\n\tdctx->fallback.flags = desc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\treturn crypto_shash_init(&dctx->fallback);\n}\n\nstatic int padlock_sha_update(struct shash_desc *desc,\n\t\t\t      const u8 *data, unsigned int length)\n{\n\tstruct padlock_sha_desc *dctx = shash_desc_ctx(desc);\n\n\tdctx->fallback.flags = desc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\treturn crypto_shash_update(&dctx->fallback, data, length);\n}\n\nstatic int padlock_sha_export(struct shash_desc *desc, void *out)\n{\n\tstruct padlock_sha_desc *dctx = shash_desc_ctx(desc);\n\n\treturn crypto_shash_export(&dctx->fallback, out);\n}\n\nstatic int padlock_sha_import(struct shash_desc *desc, const void *in)\n{\n\tstruct padlock_sha_desc *dctx = shash_desc_ctx(desc);\n\tstruct padlock_sha_ctx *ctx = crypto_shash_ctx(desc->tfm);\n\n\tdctx->fallback.tfm = ctx->fallback;\n\tdctx->fallback.flags = desc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\treturn crypto_shash_import(&dctx->fallback, in);\n}\n\nstatic inline void padlock_output_block(uint32_t *src,\n\t\t \tuint32_t *dst, size_t count)\n{\n\twhile (count--)\n\t\t*dst++ = swab32(*src++);\n}\n\nstatic int padlock_sha1_finup(struct shash_desc *desc, const u8 *in,\n\t\t\t      unsigned int count, u8 *out)\n{\n\t/* We can't store directly to *out as it may be unaligned. */\n\t/* BTW Don't reduce the buffer size below 128 Bytes!\n\t *     PadLock microcode needs it that big. */\n\tchar buf[128 + PADLOCK_ALIGNMENT - STACK_ALIGN] __attribute__\n\t\t((aligned(STACK_ALIGN)));\n\tchar *result = PTR_ALIGN(&buf[0], PADLOCK_ALIGNMENT);\n\tstruct padlock_sha_desc *dctx = shash_desc_ctx(desc);\n\tstruct sha1_state state;\n\tunsigned int space;\n\tunsigned int leftover;\n\tint ts_state;\n\tint err;\n\n\tdctx->fallback.flags = desc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\terr = crypto_shash_export(&dctx->fallback, &state);\n\tif (err)\n\t\tgoto out;\n\n\tif (state.count + count > ULONG_MAX)\n\t\treturn crypto_shash_finup(&dctx->fallback, in, count, out);\n\n\tleftover = ((state.count - 1) & (SHA1_BLOCK_SIZE - 1)) + 1;\n\tspace =  SHA1_BLOCK_SIZE - leftover;\n\tif (space) {\n\t\tif (count > space) {\n\t\t\terr = crypto_shash_update(&dctx->fallback, in, space) ?:\n\t\t\t      crypto_shash_export(&dctx->fallback, &state);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\t\t\tcount -= space;\n\t\t\tin += space;\n\t\t} else {\n\t\t\tmemcpy(state.buffer + leftover, in, count);\n\t\t\tin = state.buffer;\n\t\t\tcount += leftover;\n\t\t\tstate.count &= ~(SHA1_BLOCK_SIZE - 1);\n\t\t}\n\t}\n\n\tmemcpy(result, &state.state, SHA1_DIGEST_SIZE);\n\n\t/* prevent taking the spurious DNA fault with padlock. */\n\tts_state = irq_ts_save();\n\tasm volatile (\".byte 0xf3,0x0f,0xa6,0xc8\" /* rep xsha1 */\n\t\t      : \\\n\t\t      : \"c\"((unsigned long)state.count + count), \\\n\t\t\t\"a\"((unsigned long)state.count), \\\n\t\t\t\"S\"(in), \"D\"(result));\n\tirq_ts_restore(ts_state);\n\n\tpadlock_output_block((uint32_t *)result, (uint32_t *)out, 5);\n\nout:\n\treturn err;\n}\n\nstatic int padlock_sha1_final(struct shash_desc *desc, u8 *out)\n{\n\tu8 buf[4];\n\n\treturn padlock_sha1_finup(desc, buf, 0, out);\n}\n\nstatic int padlock_sha256_finup(struct shash_desc *desc, const u8 *in,\n\t\t\t\tunsigned int count, u8 *out)\n{\n\t/* We can't store directly to *out as it may be unaligned. */\n\t/* BTW Don't reduce the buffer size below 128 Bytes!\n\t *     PadLock microcode needs it that big. */\n\tchar buf[128 + PADLOCK_ALIGNMENT - STACK_ALIGN] __attribute__\n\t\t((aligned(STACK_ALIGN)));\n\tchar *result = PTR_ALIGN(&buf[0], PADLOCK_ALIGNMENT);\n\tstruct padlock_sha_desc *dctx = shash_desc_ctx(desc);\n\tstruct sha256_state state;\n\tunsigned int space;\n\tunsigned int leftover;\n\tint ts_state;\n\tint err;\n\n\tdctx->fallback.flags = desc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\terr = crypto_shash_export(&dctx->fallback, &state);\n\tif (err)\n\t\tgoto out;\n\n\tif (state.count + count > ULONG_MAX)\n\t\treturn crypto_shash_finup(&dctx->fallback, in, count, out);\n\n\tleftover = ((state.count - 1) & (SHA256_BLOCK_SIZE - 1)) + 1;\n\tspace =  SHA256_BLOCK_SIZE - leftover;\n\tif (space) {\n\t\tif (count > space) {\n\t\t\terr = crypto_shash_update(&dctx->fallback, in, space) ?:\n\t\t\t      crypto_shash_export(&dctx->fallback, &state);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\t\t\tcount -= space;\n\t\t\tin += space;\n\t\t} else {\n\t\t\tmemcpy(state.buf + leftover, in, count);\n\t\t\tin = state.buf;\n\t\t\tcount += leftover;\n\t\t\tstate.count &= ~(SHA1_BLOCK_SIZE - 1);\n\t\t}\n\t}\n\n\tmemcpy(result, &state.state, SHA256_DIGEST_SIZE);\n\n\t/* prevent taking the spurious DNA fault with padlock. */\n\tts_state = irq_ts_save();\n\tasm volatile (\".byte 0xf3,0x0f,0xa6,0xd0\" /* rep xsha256 */\n\t\t      : \\\n\t\t      : \"c\"((unsigned long)state.count + count), \\\n\t\t\t\"a\"((unsigned long)state.count), \\\n\t\t\t\"S\"(in), \"D\"(result));\n\tirq_ts_restore(ts_state);\n\n\tpadlock_output_block((uint32_t *)result, (uint32_t *)out, 8);\n\nout:\n\treturn err;\n}\n\nstatic int padlock_sha256_final(struct shash_desc *desc, u8 *out)\n{\n\tu8 buf[4];\n\n\treturn padlock_sha256_finup(desc, buf, 0, out);\n}\n\nstatic int padlock_cra_init(struct crypto_tfm *tfm)\n{\n\tstruct crypto_shash *hash = __crypto_shash_cast(tfm);\n\tconst char *fallback_driver_name = crypto_tfm_alg_name(tfm);\n\tstruct padlock_sha_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_shash *fallback_tfm;\n\tint err = -ENOMEM;\n\n\t/* Allocate a fallback and abort if it failed. */\n\tfallback_tfm = crypto_alloc_shash(fallback_driver_name, 0,\n\t\t\t\t\t  CRYPTO_ALG_NEED_FALLBACK);\n\tif (IS_ERR(fallback_tfm)) {\n\t\tprintk(KERN_WARNING PFX \"Fallback driver '%s' could not be loaded!\\n\",\n\t\t       fallback_driver_name);\n\t\terr = PTR_ERR(fallback_tfm);\n\t\tgoto out;\n\t}\n\n\tctx->fallback = fallback_tfm;\n\thash->descsize += crypto_shash_descsize(fallback_tfm);\n\treturn 0;\n\nout:\n\treturn err;\n}\n\nstatic void padlock_cra_exit(struct crypto_tfm *tfm)\n{\n\tstruct padlock_sha_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_shash(ctx->fallback);\n}\n\nstatic struct shash_alg sha1_alg = {\n\t.digestsize\t=\tSHA1_DIGEST_SIZE,\n\t.init   \t= \tpadlock_sha_init,\n\t.update \t=\tpadlock_sha_update,\n\t.finup  \t=\tpadlock_sha1_finup,\n\t.final  \t=\tpadlock_sha1_final,\n\t.export\t\t=\tpadlock_sha_export,\n\t.import\t\t=\tpadlock_sha_import,\n\t.descsize\t=\tsizeof(struct padlock_sha_desc),\n\t.statesize\t=\tsizeof(struct sha1_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t\t=\t\"sha1\",\n\t\t.cra_driver_name\t=\t\"sha1-padlock\",\n\t\t.cra_priority\t\t=\tPADLOCK_CRA_PRIORITY,\n\t\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_SHASH |\n\t\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t\t.cra_blocksize\t\t=\tSHA1_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t=\tsizeof(struct padlock_sha_ctx),\n\t\t.cra_module\t\t=\tTHIS_MODULE,\n\t\t.cra_init\t\t=\tpadlock_cra_init,\n\t\t.cra_exit\t\t=\tpadlock_cra_exit,\n\t}\n};\n\nstatic struct shash_alg sha256_alg = {\n\t.digestsize\t=\tSHA256_DIGEST_SIZE,\n\t.init   \t= \tpadlock_sha_init,\n\t.update \t=\tpadlock_sha_update,\n\t.finup  \t=\tpadlock_sha256_finup,\n\t.final  \t=\tpadlock_sha256_final,\n\t.export\t\t=\tpadlock_sha_export,\n\t.import\t\t=\tpadlock_sha_import,\n\t.descsize\t=\tsizeof(struct padlock_sha_desc),\n\t.statesize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t\t=\t\"sha256\",\n\t\t.cra_driver_name\t=\t\"sha256-padlock\",\n\t\t.cra_priority\t\t=\tPADLOCK_CRA_PRIORITY,\n\t\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_SHASH |\n\t\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t\t.cra_blocksize\t\t=\tSHA256_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t=\tsizeof(struct padlock_sha_ctx),\n\t\t.cra_module\t\t=\tTHIS_MODULE,\n\t\t.cra_init\t\t=\tpadlock_cra_init,\n\t\t.cra_exit\t\t=\tpadlock_cra_exit,\n\t}\n};\n\n/* Add two shash_alg instance for hardware-implemented *\n* multiple-parts hash supported by VIA Nano Processor.*/\nstatic int padlock_sha1_init_nano(struct shash_desc *desc)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\n\t*sctx = (struct sha1_state){\n\t\t.state = { SHA1_H0, SHA1_H1, SHA1_H2, SHA1_H3, SHA1_H4 },\n\t};\n\n\treturn 0;\n}\n\nstatic int padlock_sha1_update_nano(struct shash_desc *desc,\n\t\t\tconst u8 *data,\tunsigned int len)\n{\n\tstruct sha1_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial, done;\n\tconst u8 *src;\n\t/*The PHE require the out buffer must 128 bytes and 16-bytes aligned*/\n\tu8 buf[128 + PADLOCK_ALIGNMENT - STACK_ALIGN] __attribute__\n\t\t((aligned(STACK_ALIGN)));\n\tu8 *dst = PTR_ALIGN(&buf[0], PADLOCK_ALIGNMENT);\n\tint ts_state;\n\n\tpartial = sctx->count & 0x3f;\n\tsctx->count += len;\n\tdone = 0;\n\tsrc = data;\n\tmemcpy(dst, (u8 *)(sctx->state), SHA1_DIGEST_SIZE);\n\n\tif ((partial + len) >= SHA1_BLOCK_SIZE) {\n\n\t\t/* Append the bytes in state's buffer to a block to handle */\n\t\tif (partial) {\n\t\t\tdone = -partial;\n\t\t\tmemcpy(sctx->buffer + partial, data,\n\t\t\t\tdone + SHA1_BLOCK_SIZE);\n\t\t\tsrc = sctx->buffer;\n\t\t\tts_state = irq_ts_save();\n\t\t\tasm volatile (\".byte 0xf3,0x0f,0xa6,0xc8\"\n\t\t\t: \"+S\"(src), \"+D\"(dst) \\\n\t\t\t: \"a\"((long)-1), \"c\"((unsigned long)1));\n\t\t\tirq_ts_restore(ts_state);\n\t\t\tdone += SHA1_BLOCK_SIZE;\n\t\t\tsrc = data + done;\n\t\t}\n\n\t\t/* Process the left bytes from the input data */\n\t\tif (len - done >= SHA1_BLOCK_SIZE) {\n\t\t\tts_state = irq_ts_save();\n\t\t\tasm volatile (\".byte 0xf3,0x0f,0xa6,0xc8\"\n\t\t\t: \"+S\"(src), \"+D\"(dst)\n\t\t\t: \"a\"((long)-1),\n\t\t\t\"c\"((unsigned long)((len - done) / SHA1_BLOCK_SIZE)));\n\t\t\tirq_ts_restore(ts_state);\n\t\t\tdone += ((len - done) - (len - done) % SHA1_BLOCK_SIZE);\n\t\t\tsrc = data + done;\n\t\t}\n\t\tpartial = 0;\n\t}\n\tmemcpy((u8 *)(sctx->state), dst, SHA1_DIGEST_SIZE);\n\tmemcpy(sctx->buffer + partial, src, len - done);\n\n\treturn 0;\n}\n\nstatic int padlock_sha1_final_nano(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha1_state *state = (struct sha1_state *)shash_desc_ctx(desc);\n\tunsigned int partial, padlen;\n\t__be64 bits;\n\tstatic const u8 padding[64] = { 0x80, };\n\n\tbits = cpu_to_be64(state->count << 3);\n\n\t/* Pad out to 56 mod 64 */\n\tpartial = state->count & 0x3f;\n\tpadlen = (partial < 56) ? (56 - partial) : ((64+56) - partial);\n\tpadlock_sha1_update_nano(desc, padding, padlen);\n\n\t/* Append length field bytes */\n\tpadlock_sha1_update_nano(desc, (const u8 *)&bits, sizeof(bits));\n\n\t/* Swap to output */\n\tpadlock_output_block((uint32_t *)(state->state), (uint32_t *)out, 5);\n\n\treturn 0;\n}\n\nstatic int padlock_sha256_init_nano(struct shash_desc *desc)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\n\t*sctx = (struct sha256_state){\n\t\t.state = { SHA256_H0, SHA256_H1, SHA256_H2, SHA256_H3, \\\n\t\t\t\tSHA256_H4, SHA256_H5, SHA256_H6, SHA256_H7},\n\t};\n\n\treturn 0;\n}\n\nstatic int padlock_sha256_update_nano(struct shash_desc *desc, const u8 *data,\n\t\t\t  unsigned int len)\n{\n\tstruct sha256_state *sctx = shash_desc_ctx(desc);\n\tunsigned int partial, done;\n\tconst u8 *src;\n\t/*The PHE require the out buffer must 128 bytes and 16-bytes aligned*/\n\tu8 buf[128 + PADLOCK_ALIGNMENT - STACK_ALIGN] __attribute__\n\t\t((aligned(STACK_ALIGN)));\n\tu8 *dst = PTR_ALIGN(&buf[0], PADLOCK_ALIGNMENT);\n\tint ts_state;\n\n\tpartial = sctx->count & 0x3f;\n\tsctx->count += len;\n\tdone = 0;\n\tsrc = data;\n\tmemcpy(dst, (u8 *)(sctx->state), SHA256_DIGEST_SIZE);\n\n\tif ((partial + len) >= SHA256_BLOCK_SIZE) {\n\n\t\t/* Append the bytes in state's buffer to a block to handle */\n\t\tif (partial) {\n\t\t\tdone = -partial;\n\t\t\tmemcpy(sctx->buf + partial, data,\n\t\t\t\tdone + SHA256_BLOCK_SIZE);\n\t\t\tsrc = sctx->buf;\n\t\t\tts_state = irq_ts_save();\n\t\t\tasm volatile (\".byte 0xf3,0x0f,0xa6,0xd0\"\n\t\t\t: \"+S\"(src), \"+D\"(dst)\n\t\t\t: \"a\"((long)-1), \"c\"((unsigned long)1));\n\t\t\tirq_ts_restore(ts_state);\n\t\t\tdone += SHA256_BLOCK_SIZE;\n\t\t\tsrc = data + done;\n\t\t}\n\n\t\t/* Process the left bytes from input data*/\n\t\tif (len - done >= SHA256_BLOCK_SIZE) {\n\t\t\tts_state = irq_ts_save();\n\t\t\tasm volatile (\".byte 0xf3,0x0f,0xa6,0xd0\"\n\t\t\t: \"+S\"(src), \"+D\"(dst)\n\t\t\t: \"a\"((long)-1),\n\t\t\t\"c\"((unsigned long)((len - done) / 64)));\n\t\t\tirq_ts_restore(ts_state);\n\t\t\tdone += ((len - done) - (len - done) % 64);\n\t\t\tsrc = data + done;\n\t\t}\n\t\tpartial = 0;\n\t}\n\tmemcpy((u8 *)(sctx->state), dst, SHA256_DIGEST_SIZE);\n\tmemcpy(sctx->buf + partial, src, len - done);\n\n\treturn 0;\n}\n\nstatic int padlock_sha256_final_nano(struct shash_desc *desc, u8 *out)\n{\n\tstruct sha256_state *state =\n\t\t(struct sha256_state *)shash_desc_ctx(desc);\n\tunsigned int partial, padlen;\n\t__be64 bits;\n\tstatic const u8 padding[64] = { 0x80, };\n\n\tbits = cpu_to_be64(state->count << 3);\n\n\t/* Pad out to 56 mod 64 */\n\tpartial = state->count & 0x3f;\n\tpadlen = (partial < 56) ? (56 - partial) : ((64+56) - partial);\n\tpadlock_sha256_update_nano(desc, padding, padlen);\n\n\t/* Append length field bytes */\n\tpadlock_sha256_update_nano(desc, (const u8 *)&bits, sizeof(bits));\n\n\t/* Swap to output */\n\tpadlock_output_block((uint32_t *)(state->state), (uint32_t *)out, 8);\n\n\treturn 0;\n}\n\nstatic int padlock_sha_export_nano(struct shash_desc *desc,\n\t\t\t\tvoid *out)\n{\n\tint statesize = crypto_shash_statesize(desc->tfm);\n\tvoid *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(out, sctx, statesize);\n\treturn 0;\n}\n\nstatic int padlock_sha_import_nano(struct shash_desc *desc,\n\t\t\t\tconst void *in)\n{\n\tint statesize = crypto_shash_statesize(desc->tfm);\n\tvoid *sctx = shash_desc_ctx(desc);\n\n\tmemcpy(sctx, in, statesize);\n\treturn 0;\n}\n\nstatic struct shash_alg sha1_alg_nano = {\n\t.digestsize\t=\tSHA1_DIGEST_SIZE,\n\t.init\t\t=\tpadlock_sha1_init_nano,\n\t.update\t\t=\tpadlock_sha1_update_nano,\n\t.final\t\t=\tpadlock_sha1_final_nano,\n\t.export\t\t=\tpadlock_sha_export_nano,\n\t.import\t\t=\tpadlock_sha_import_nano,\n\t.descsize\t=\tsizeof(struct sha1_state),\n\t.statesize\t=\tsizeof(struct sha1_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t\t=\t\"sha1\",\n\t\t.cra_driver_name\t=\t\"sha1-padlock-nano\",\n\t\t.cra_priority\t\t=\tPADLOCK_CRA_PRIORITY,\n\t\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t\t=\tSHA1_BLOCK_SIZE,\n\t\t.cra_module\t\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic struct shash_alg sha256_alg_nano = {\n\t.digestsize\t=\tSHA256_DIGEST_SIZE,\n\t.init\t\t=\tpadlock_sha256_init_nano,\n\t.update\t\t=\tpadlock_sha256_update_nano,\n\t.final\t\t=\tpadlock_sha256_final_nano,\n\t.export\t\t=\tpadlock_sha_export_nano,\n\t.import\t\t=\tpadlock_sha_import_nano,\n\t.descsize\t=\tsizeof(struct sha256_state),\n\t.statesize\t=\tsizeof(struct sha256_state),\n\t.base\t\t=\t{\n\t\t.cra_name\t\t=\t\"sha256\",\n\t\t.cra_driver_name\t=\t\"sha256-padlock-nano\",\n\t\t.cra_priority\t\t=\tPADLOCK_CRA_PRIORITY,\n\t\t.cra_flags\t\t=\tCRYPTO_ALG_TYPE_SHASH,\n\t\t.cra_blocksize\t\t=\tSHA256_BLOCK_SIZE,\n\t\t.cra_module\t\t=\tTHIS_MODULE,\n\t}\n};\n\nstatic struct x86_cpu_id padlock_sha_ids[] = {\n\tX86_FEATURE_MATCH(X86_FEATURE_PHE),\n\t{}\n};\nMODULE_DEVICE_TABLE(x86cpu, padlock_sha_ids);\n\nstatic int __init padlock_init(void)\n{\n\tint rc = -ENODEV;\n\tstruct cpuinfo_x86 *c = &cpu_data(0);\n\tstruct shash_alg *sha1;\n\tstruct shash_alg *sha256;\n\n\tif (!x86_match_cpu(padlock_sha_ids) || !cpu_has_phe_enabled)\n\t\treturn -ENODEV;\n\n\t/* Register the newly added algorithm module if on *\n\t* VIA Nano processor, or else just do as before */\n\tif (c->x86_model < 0x0f) {\n\t\tsha1 = &sha1_alg;\n\t\tsha256 = &sha256_alg;\n\t} else {\n\t\tsha1 = &sha1_alg_nano;\n\t\tsha256 = &sha256_alg_nano;\n\t}\n\n\trc = crypto_register_shash(sha1);\n\tif (rc)\n\t\tgoto out;\n\n\trc = crypto_register_shash(sha256);\n\tif (rc)\n\t\tgoto out_unreg1;\n\n\tprintk(KERN_NOTICE PFX \"Using VIA PadLock ACE for SHA1/SHA256 algorithms.\\n\");\n\n\treturn 0;\n\nout_unreg1:\n\tcrypto_unregister_shash(sha1);\n\nout:\n\tprintk(KERN_ERR PFX \"VIA PadLock SHA1/SHA256 initialization failed.\\n\");\n\treturn rc;\n}\n\nstatic void __exit padlock_fini(void)\n{\n\tstruct cpuinfo_x86 *c = &cpu_data(0);\n\n\tif (c->x86_model >= 0x0f) {\n\t\tcrypto_unregister_shash(&sha1_alg_nano);\n\t\tcrypto_unregister_shash(&sha256_alg_nano);\n\t} else {\n\t\tcrypto_unregister_shash(&sha1_alg);\n\t\tcrypto_unregister_shash(&sha256_alg);\n\t}\n}\n\nmodule_init(padlock_init);\nmodule_exit(padlock_fini);\n\nMODULE_DESCRIPTION(\"VIA PadLock SHA1/SHA256 algorithms support.\");\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Michal Ludvig\");\n\nMODULE_ALIAS_CRYPTO(\"sha1-all\");\nMODULE_ALIAS_CRYPTO(\"sha256-all\");\nMODULE_ALIAS_CRYPTO(\"sha1-padlock\");\nMODULE_ALIAS_CRYPTO(\"sha256-padlock\");\n", "/*\n  This file is provided under a dual BSD/GPLv2 license.  When using or\n  redistributing this file, you may do so under either license.\n\n  GPL LICENSE SUMMARY\n  Copyright(c) 2014 Intel Corporation.\n  This program is free software; you can redistribute it and/or modify\n  it under the terms of version 2 of the GNU General Public License as\n  published by the Free Software Foundation.\n\n  This program is distributed in the hope that it will be useful, but\n  WITHOUT ANY WARRANTY; without even the implied warranty of\n  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n  General Public License for more details.\n\n  Contact Information:\n  qat-linux@intel.com\n\n  BSD LICENSE\n  Copyright(c) 2014 Intel Corporation.\n  Redistribution and use in source and binary forms, with or without\n  modification, are permitted provided that the following conditions\n  are met:\n\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n    * Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in\n      the documentation and/or other materials provided with the\n      distribution.\n    * Neither the name of Intel Corporation nor the names of its\n      contributors may be used to endorse or promote products derived\n      from this software without specific prior written permission.\n\n  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n  \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n*/\n#include <linux/module.h>\n#include <linux/mutex.h>\n#include <linux/slab.h>\n#include <linux/fs.h>\n#include <linux/bitops.h>\n#include <linux/pci.h>\n#include <linux/cdev.h>\n#include <linux/uaccess.h>\n#include <linux/crypto.h>\n\n#include \"adf_accel_devices.h\"\n#include \"adf_common_drv.h\"\n#include \"adf_cfg.h\"\n#include \"adf_cfg_common.h\"\n#include \"adf_cfg_user.h\"\n\n#define DEVICE_NAME \"qat_adf_ctl\"\n\nstatic DEFINE_MUTEX(adf_ctl_lock);\nstatic long adf_ctl_ioctl(struct file *fp, unsigned int cmd, unsigned long arg);\n\nstatic const struct file_operations adf_ctl_ops = {\n\t.owner = THIS_MODULE,\n\t.unlocked_ioctl = adf_ctl_ioctl,\n\t.compat_ioctl = adf_ctl_ioctl,\n};\n\nstruct adf_ctl_drv_info {\n\tunsigned int major;\n\tstruct cdev drv_cdev;\n\tstruct class *drv_class;\n};\n\nstatic struct adf_ctl_drv_info adt_ctl_drv;\n\nstatic void adf_chr_drv_destroy(void)\n{\n\tdevice_destroy(adt_ctl_drv.drv_class, MKDEV(adt_ctl_drv.major, 0));\n\tcdev_del(&adt_ctl_drv.drv_cdev);\n\tclass_destroy(adt_ctl_drv.drv_class);\n\tunregister_chrdev_region(MKDEV(adt_ctl_drv.major, 0), 1);\n}\n\nstatic int adf_chr_drv_create(void)\n{\n\tdev_t dev_id;\n\tstruct device *drv_device;\n\n\tif (alloc_chrdev_region(&dev_id, 0, 1, DEVICE_NAME)) {\n\t\tpr_err(\"QAT: unable to allocate chrdev region\\n\");\n\t\treturn -EFAULT;\n\t}\n\n\tadt_ctl_drv.drv_class = class_create(THIS_MODULE, DEVICE_NAME);\n\tif (IS_ERR(adt_ctl_drv.drv_class)) {\n\t\tpr_err(\"QAT: class_create failed for adf_ctl\\n\");\n\t\tgoto err_chrdev_unreg;\n\t}\n\tadt_ctl_drv.major = MAJOR(dev_id);\n\tcdev_init(&adt_ctl_drv.drv_cdev, &adf_ctl_ops);\n\tif (cdev_add(&adt_ctl_drv.drv_cdev, dev_id, 1)) {\n\t\tpr_err(\"QAT: cdev add failed\\n\");\n\t\tgoto err_class_destr;\n\t}\n\n\tdrv_device = device_create(adt_ctl_drv.drv_class, NULL,\n\t\t\t\t   MKDEV(adt_ctl_drv.major, 0),\n\t\t\t\t   NULL, DEVICE_NAME);\n\tif (IS_ERR(drv_device)) {\n\t\tpr_err(\"QAT: failed to create device\\n\");\n\t\tgoto err_cdev_del;\n\t}\n\treturn 0;\nerr_cdev_del:\n\tcdev_del(&adt_ctl_drv.drv_cdev);\nerr_class_destr:\n\tclass_destroy(adt_ctl_drv.drv_class);\nerr_chrdev_unreg:\n\tunregister_chrdev_region(dev_id, 1);\n\treturn -EFAULT;\n}\n\nstatic int adf_ctl_alloc_resources(struct adf_user_cfg_ctl_data **ctl_data,\n\t\t\t\t   unsigned long arg)\n{\n\tstruct adf_user_cfg_ctl_data *cfg_data;\n\n\tcfg_data = kzalloc(sizeof(*cfg_data), GFP_KERNEL);\n\tif (!cfg_data)\n\t\treturn -ENOMEM;\n\n\t/* Initialize device id to NO DEVICE as 0 is a valid device id */\n\tcfg_data->device_id = ADF_CFG_NO_DEVICE;\n\n\tif (copy_from_user(cfg_data, (void __user *)arg, sizeof(*cfg_data))) {\n\t\tpr_err(\"QAT: failed to copy from user cfg_data.\\n\");\n\t\tkfree(cfg_data);\n\t\treturn -EIO;\n\t}\n\n\t*ctl_data = cfg_data;\n\treturn 0;\n}\n\nstatic int adf_add_key_value_data(struct adf_accel_dev *accel_dev,\n\t\t\t\t  const char *section,\n\t\t\t\t  const struct adf_user_cfg_key_val *key_val)\n{\n\tif (key_val->type == ADF_HEX) {\n\t\tlong *ptr = (long *)key_val->val;\n\t\tlong val = *ptr;\n\n\t\tif (adf_cfg_add_key_value_param(accel_dev, section,\n\t\t\t\t\t\tkey_val->key, (void *)val,\n\t\t\t\t\t\tkey_val->type)) {\n\t\t\tpr_err(\"QAT: failed to add keyvalue.\\n\");\n\t\t\treturn -EFAULT;\n\t\t}\n\t} else {\n\t\tif (adf_cfg_add_key_value_param(accel_dev, section,\n\t\t\t\t\t\tkey_val->key, key_val->val,\n\t\t\t\t\t\tkey_val->type)) {\n\t\t\tpr_err(\"QAT: failed to add keyvalue.\\n\");\n\t\t\treturn -EFAULT;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int adf_copy_key_value_data(struct adf_accel_dev *accel_dev,\n\t\t\t\t   struct adf_user_cfg_ctl_data *ctl_data)\n{\n\tstruct adf_user_cfg_key_val key_val;\n\tstruct adf_user_cfg_key_val *params_head;\n\tstruct adf_user_cfg_section section, *section_head;\n\n\tsection_head = ctl_data->config_section;\n\n\twhile (section_head) {\n\t\tif (copy_from_user(&section, (void __user *)section_head,\n\t\t\t\t   sizeof(*section_head))) {\n\t\t\tpr_err(\"QAT: failed to copy section info\\n\");\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tif (adf_cfg_section_add(accel_dev, section.name)) {\n\t\t\tpr_err(\"QAT: failed to add section.\\n\");\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tparams_head = section_head->params;\n\n\t\twhile (params_head) {\n\t\t\tif (copy_from_user(&key_val, (void __user *)params_head,\n\t\t\t\t\t   sizeof(key_val))) {\n\t\t\t\tpr_err(\"QAT: Failed to copy keyvalue.\\n\");\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t\tif (adf_add_key_value_data(accel_dev, section.name,\n\t\t\t\t\t\t   &key_val)) {\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t\tparams_head = key_val.next;\n\t\t}\n\t\tsection_head = section.next;\n\t}\n\treturn 0;\nout_err:\n\tadf_cfg_del_all(accel_dev);\n\treturn -EFAULT;\n}\n\nstatic int adf_ctl_ioctl_dev_config(struct file *fp, unsigned int cmd,\n\t\t\t\t    unsigned long arg)\n{\n\tint ret;\n\tstruct adf_user_cfg_ctl_data *ctl_data;\n\tstruct adf_accel_dev *accel_dev;\n\n\tret = adf_ctl_alloc_resources(&ctl_data, arg);\n\tif (ret)\n\t\treturn ret;\n\n\taccel_dev = adf_devmgr_get_dev_by_id(ctl_data->device_id);\n\tif (!accel_dev) {\n\t\tret = -EFAULT;\n\t\tgoto out;\n\t}\n\n\tif (adf_dev_started(accel_dev)) {\n\t\tret = -EFAULT;\n\t\tgoto out;\n\t}\n\n\tif (adf_copy_key_value_data(accel_dev, ctl_data)) {\n\t\tret = -EFAULT;\n\t\tgoto out;\n\t}\n\tset_bit(ADF_STATUS_CONFIGURED, &accel_dev->status);\nout:\n\tkfree(ctl_data);\n\treturn ret;\n}\n\nstatic int adf_ctl_is_device_in_use(int id)\n{\n\tstruct list_head *itr, *head = adf_devmgr_get_head();\n\n\tlist_for_each(itr, head) {\n\t\tstruct adf_accel_dev *dev =\n\t\t\t\tlist_entry(itr, struct adf_accel_dev, list);\n\n\t\tif (id == dev->accel_id || id == ADF_CFG_ALL_DEVICES) {\n\t\t\tif (adf_devmgr_in_reset(dev) || adf_dev_in_use(dev)) {\n\t\t\t\tpr_info(\"QAT: device qat_dev%d is busy\\n\",\n\t\t\t\t\tdev->accel_id);\n\t\t\t\treturn -EBUSY;\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int adf_ctl_stop_devices(uint32_t id)\n{\n\tstruct list_head *itr, *head = adf_devmgr_get_head();\n\tint ret = 0;\n\n\tlist_for_each(itr, head) {\n\t\tstruct adf_accel_dev *accel_dev =\n\t\t\t\tlist_entry(itr, struct adf_accel_dev, list);\n\t\tif (id == accel_dev->accel_id || id == ADF_CFG_ALL_DEVICES) {\n\t\t\tif (!adf_dev_started(accel_dev))\n\t\t\t\tcontinue;\n\n\t\t\tif (adf_dev_stop(accel_dev)) {\n\t\t\t\tpr_err(\"QAT: Failed to stop qat_dev%d\\n\", id);\n\t\t\t\tret = -EFAULT;\n\t\t\t}\n\t\t}\n\t}\n\treturn ret;\n}\n\nstatic int adf_ctl_ioctl_dev_stop(struct file *fp, unsigned int cmd,\n\t\t\t\t  unsigned long arg)\n{\n\tint ret;\n\tstruct adf_user_cfg_ctl_data *ctl_data;\n\n\tret = adf_ctl_alloc_resources(&ctl_data, arg);\n\tif (ret)\n\t\treturn ret;\n\n\tif (adf_devmgr_verify_id(ctl_data->device_id)) {\n\t\tpr_err(\"QAT: Device %d not found\\n\", ctl_data->device_id);\n\t\tret = -ENODEV;\n\t\tgoto out;\n\t}\n\n\tret = adf_ctl_is_device_in_use(ctl_data->device_id);\n\tif (ret)\n\t\tgoto out;\n\n\tif (ctl_data->device_id == ADF_CFG_ALL_DEVICES)\n\t\tpr_info(\"QAT: Stopping all acceleration devices.\\n\");\n\telse\n\t\tpr_info(\"QAT: Stopping acceleration device qat_dev%d.\\n\",\n\t\t\tctl_data->device_id);\n\n\tret = adf_ctl_stop_devices(ctl_data->device_id);\n\tif (ret)\n\t\tpr_err(\"QAT: failed to stop device.\\n\");\nout:\n\tkfree(ctl_data);\n\treturn ret;\n}\n\nstatic int adf_ctl_ioctl_dev_start(struct file *fp, unsigned int cmd,\n\t\t\t\t   unsigned long arg)\n{\n\tint ret;\n\tstruct adf_user_cfg_ctl_data *ctl_data;\n\tstruct adf_accel_dev *accel_dev;\n\n\tret = adf_ctl_alloc_resources(&ctl_data, arg);\n\tif (ret)\n\t\treturn ret;\n\n\taccel_dev = adf_devmgr_get_dev_by_id(ctl_data->device_id);\n\tif (!accel_dev) {\n\t\tpr_err(\"QAT: Device %d not found\\n\", ctl_data->device_id);\n\t\tret = -ENODEV;\n\t\tgoto out;\n\t}\n\n\tif (!adf_dev_started(accel_dev)) {\n\t\tpr_info(\"QAT: Starting acceleration device qat_dev%d.\\n\",\n\t\t\tctl_data->device_id);\n\t\tret = adf_dev_start(accel_dev);\n\t} else {\n\t\tpr_info(\"QAT: Acceleration device qat_dev%d already started.\\n\",\n\t\t\tctl_data->device_id);\n\t}\n\tif (ret) {\n\t\tpr_err(\"QAT: Failed to start qat_dev%d\\n\", ctl_data->device_id);\n\t\tadf_dev_stop(accel_dev);\n\t}\nout:\n\tkfree(ctl_data);\n\treturn ret;\n}\n\nstatic int adf_ctl_ioctl_get_num_devices(struct file *fp, unsigned int cmd,\n\t\t\t\t\t unsigned long arg)\n{\n\tuint32_t num_devices = 0;\n\n\tadf_devmgr_get_num_dev(&num_devices);\n\tif (copy_to_user((void __user *)arg, &num_devices, sizeof(num_devices)))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n\nstatic int adf_ctl_ioctl_get_status(struct file *fp, unsigned int cmd,\n\t\t\t\t    unsigned long arg)\n{\n\tstruct adf_hw_device_data *hw_data;\n\tstruct adf_dev_status_info dev_info;\n\tstruct adf_accel_dev *accel_dev;\n\n\tif (copy_from_user(&dev_info, (void __user *)arg,\n\t\t\t   sizeof(struct adf_dev_status_info))) {\n\t\tpr_err(\"QAT: failed to copy from user.\\n\");\n\t\treturn -EFAULT;\n\t}\n\n\taccel_dev = adf_devmgr_get_dev_by_id(dev_info.accel_id);\n\tif (!accel_dev) {\n\t\tpr_err(\"QAT: Device %d not found\\n\", dev_info.accel_id);\n\t\treturn -ENODEV;\n\t}\n\thw_data = accel_dev->hw_device;\n\tdev_info.state = adf_dev_started(accel_dev) ? DEV_UP : DEV_DOWN;\n\tdev_info.num_ae = hw_data->get_num_aes(hw_data);\n\tdev_info.num_accel = hw_data->get_num_accels(hw_data);\n\tdev_info.num_logical_accel = hw_data->num_logical_accel;\n\tdev_info.banks_per_accel = hw_data->num_banks\n\t\t\t\t\t/ hw_data->num_logical_accel;\n\tstrlcpy(dev_info.name, hw_data->dev_class->name, sizeof(dev_info.name));\n\tdev_info.instance_id = hw_data->instance_id;\n\tdev_info.type = hw_data->dev_class->type;\n\tdev_info.bus = accel_to_pci_dev(accel_dev)->bus->number;\n\tdev_info.dev = PCI_SLOT(accel_to_pci_dev(accel_dev)->devfn);\n\tdev_info.fun = PCI_FUNC(accel_to_pci_dev(accel_dev)->devfn);\n\n\tif (copy_to_user((void __user *)arg, &dev_info,\n\t\t\t sizeof(struct adf_dev_status_info))) {\n\t\tpr_err(\"QAT: failed to copy status.\\n\");\n\t\treturn -EFAULT;\n\t}\n\treturn 0;\n}\n\nstatic long adf_ctl_ioctl(struct file *fp, unsigned int cmd, unsigned long arg)\n{\n\tint ret;\n\n\tif (mutex_lock_interruptible(&adf_ctl_lock))\n\t\treturn -EFAULT;\n\n\tswitch (cmd) {\n\tcase IOCTL_CONFIG_SYS_RESOURCE_PARAMETERS:\n\t\tret = adf_ctl_ioctl_dev_config(fp, cmd, arg);\n\t\tbreak;\n\n\tcase IOCTL_STOP_ACCEL_DEV:\n\t\tret = adf_ctl_ioctl_dev_stop(fp, cmd, arg);\n\t\tbreak;\n\n\tcase IOCTL_START_ACCEL_DEV:\n\t\tret = adf_ctl_ioctl_dev_start(fp, cmd, arg);\n\t\tbreak;\n\n\tcase IOCTL_GET_NUM_DEVICES:\n\t\tret = adf_ctl_ioctl_get_num_devices(fp, cmd, arg);\n\t\tbreak;\n\n\tcase IOCTL_STATUS_ACCEL_DEV:\n\t\tret = adf_ctl_ioctl_get_status(fp, cmd, arg);\n\t\tbreak;\n\tdefault:\n\t\tpr_err(\"QAT: Invalid ioctl\\n\");\n\t\tret = -EFAULT;\n\t\tbreak;\n\t}\n\tmutex_unlock(&adf_ctl_lock);\n\treturn ret;\n}\n\nstatic int __init adf_register_ctl_device_driver(void)\n{\n\tmutex_init(&adf_ctl_lock);\n\n\tif (qat_algs_init())\n\t\tgoto err_algs_init;\n\n\tif (adf_chr_drv_create())\n\t\tgoto err_chr_dev;\n\n\tif (adf_init_aer())\n\t\tgoto err_aer;\n\n\tif (qat_crypto_register())\n\t\tgoto err_crypto_register;\n\n\treturn 0;\n\nerr_crypto_register:\n\tadf_exit_aer();\nerr_aer:\n\tadf_chr_drv_destroy();\nerr_chr_dev:\n\tqat_algs_exit();\nerr_algs_init:\n\tmutex_destroy(&adf_ctl_lock);\n\treturn -EFAULT;\n}\n\nstatic void __exit adf_unregister_ctl_device_driver(void)\n{\n\tadf_chr_drv_destroy();\n\tadf_exit_aer();\n\tqat_crypto_unregister();\n\tqat_algs_exit();\n\tmutex_destroy(&adf_ctl_lock);\n}\n\nmodule_init(adf_register_ctl_device_driver);\nmodule_exit(adf_unregister_ctl_device_driver);\nMODULE_LICENSE(\"Dual BSD/GPL\");\nMODULE_AUTHOR(\"Intel\");\nMODULE_DESCRIPTION(\"Intel(R) QuickAssist Technology\");\nMODULE_ALIAS_CRYPTO(\"intel_qat\");\n", "/**\n * Copyright (C) ST-Ericsson SA 2010\n * Author: Shujuan Chen <shujuan.chen@stericsson.com> for ST-Ericsson.\n * Author: Joakim Bech <joakim.xx.bech@stericsson.com> for ST-Ericsson.\n * Author: Berne Hebark <berne.herbark@stericsson.com> for ST-Ericsson.\n * Author: Niklas Hernaeus <niklas.hernaeus@stericsson.com> for ST-Ericsson.\n * Author: Jonas Linde <jonas.linde@stericsson.com> for ST-Ericsson.\n * Author: Andreas Westin <andreas.westin@stericsson.com> for ST-Ericsson.\n * License terms: GNU General Public License (GPL) version 2\n */\n\n#include <linux/clk.h>\n#include <linux/completion.h>\n#include <linux/crypto.h>\n#include <linux/dmaengine.h>\n#include <linux/err.h>\n#include <linux/errno.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/irqreturn.h>\n#include <linux/klist.h>\n#include <linux/module.h>\n#include <linux/platform_device.h>\n#include <linux/regulator/consumer.h>\n#include <linux/semaphore.h>\n#include <linux/platform_data/dma-ste-dma40.h>\n\n#include <crypto/aes.h>\n#include <crypto/algapi.h>\n#include <crypto/ctr.h>\n#include <crypto/des.h>\n#include <crypto/scatterwalk.h>\n\n#include <linux/platform_data/crypto-ux500.h>\n\n#include \"cryp_p.h\"\n#include \"cryp.h\"\n\n#define CRYP_MAX_KEY_SIZE\t32\n#define BYTES_PER_WORD\t\t4\n\nstatic int cryp_mode;\nstatic atomic_t session_id;\n\nstatic struct stedma40_chan_cfg *mem_to_engine;\nstatic struct stedma40_chan_cfg *engine_to_mem;\n\n/**\n * struct cryp_driver_data - data specific to the driver.\n *\n * @device_list: A list of registered devices to choose from.\n * @device_allocation: A semaphore initialized with number of devices.\n */\nstruct cryp_driver_data {\n\tstruct klist device_list;\n\tstruct semaphore device_allocation;\n};\n\n/**\n * struct cryp_ctx - Crypto context\n * @config: Crypto mode.\n * @key[CRYP_MAX_KEY_SIZE]: Key.\n * @keylen: Length of key.\n * @iv: Pointer to initialization vector.\n * @indata: Pointer to indata.\n * @outdata: Pointer to outdata.\n * @datalen: Length of indata.\n * @outlen: Length of outdata.\n * @blocksize: Size of blocks.\n * @updated: Updated flag.\n * @dev_ctx: Device dependent context.\n * @device: Pointer to the device.\n */\nstruct cryp_ctx {\n\tstruct cryp_config config;\n\tu8 key[CRYP_MAX_KEY_SIZE];\n\tu32 keylen;\n\tu8 *iv;\n\tconst u8 *indata;\n\tu8 *outdata;\n\tu32 datalen;\n\tu32 outlen;\n\tu32 blocksize;\n\tu8 updated;\n\tstruct cryp_device_context dev_ctx;\n\tstruct cryp_device_data *device;\n\tu32 session_id;\n};\n\nstatic struct cryp_driver_data driver_data;\n\n/**\n * uint8p_to_uint32_be - 4*uint8 to uint32 big endian\n * @in: Data to convert.\n */\nstatic inline u32 uint8p_to_uint32_be(u8 *in)\n{\n\tu32 *data = (u32 *)in;\n\n\treturn cpu_to_be32p(data);\n}\n\n/**\n * swap_bits_in_byte - mirror the bits in a byte\n * @b: the byte to be mirrored\n *\n * The bits are swapped the following way:\n *  Byte b include bits 0-7, nibble 1 (n1) include bits 0-3 and\n *  nibble 2 (n2) bits 4-7.\n *\n *  Nibble 1 (n1):\n *  (The \"old\" (moved) bit is replaced with a zero)\n *  1. Move bit 6 and 7, 4 positions to the left.\n *  2. Move bit 3 and 5, 2 positions to the left.\n *  3. Move bit 1-4, 1 position to the left.\n *\n *  Nibble 2 (n2):\n *  1. Move bit 0 and 1, 4 positions to the right.\n *  2. Move bit 2 and 4, 2 positions to the right.\n *  3. Move bit 3-6, 1 position to the right.\n *\n *  Combine the two nibbles to a complete and swapped byte.\n */\n\nstatic inline u8 swap_bits_in_byte(u8 b)\n{\n#define R_SHIFT_4_MASK  0xc0 /* Bits 6 and 7, right shift 4 */\n#define R_SHIFT_2_MASK  0x28 /* (After right shift 4) Bits 3 and 5,\n\t\t\t\t  right shift 2 */\n#define R_SHIFT_1_MASK  0x1e /* (After right shift 2) Bits 1-4,\n\t\t\t\t  right shift 1 */\n#define L_SHIFT_4_MASK  0x03 /* Bits 0 and 1, left shift 4 */\n#define L_SHIFT_2_MASK  0x14 /* (After left shift 4) Bits 2 and 4,\n\t\t\t\t  left shift 2 */\n#define L_SHIFT_1_MASK  0x78 /* (After left shift 1) Bits 3-6,\n\t\t\t\t  left shift 1 */\n\n\tu8 n1;\n\tu8 n2;\n\n\t/* Swap most significant nibble */\n\t/* Right shift 4, bits 6 and 7 */\n\tn1 = ((b  & R_SHIFT_4_MASK) >> 4) | (b  & ~(R_SHIFT_4_MASK >> 4));\n\t/* Right shift 2, bits 3 and 5 */\n\tn1 = ((n1 & R_SHIFT_2_MASK) >> 2) | (n1 & ~(R_SHIFT_2_MASK >> 2));\n\t/* Right shift 1, bits 1-4 */\n\tn1 = (n1  & R_SHIFT_1_MASK) >> 1;\n\n\t/* Swap least significant nibble */\n\t/* Left shift 4, bits 0 and 1 */\n\tn2 = ((b  & L_SHIFT_4_MASK) << 4) | (b  & ~(L_SHIFT_4_MASK << 4));\n\t/* Left shift 2, bits 2 and 4 */\n\tn2 = ((n2 & L_SHIFT_2_MASK) << 2) | (n2 & ~(L_SHIFT_2_MASK << 2));\n\t/* Left shift 1, bits 3-6 */\n\tn2 = (n2  & L_SHIFT_1_MASK) << 1;\n\n\treturn n1 | n2;\n}\n\nstatic inline void swap_words_in_key_and_bits_in_byte(const u8 *in,\n\t\t\t\t\t\t      u8 *out, u32 len)\n{\n\tunsigned int i = 0;\n\tint j;\n\tint index = 0;\n\n\tj = len - BYTES_PER_WORD;\n\twhile (j >= 0) {\n\t\tfor (i = 0; i < BYTES_PER_WORD; i++) {\n\t\t\tindex = len - j - BYTES_PER_WORD + i;\n\t\t\tout[j + i] =\n\t\t\t\tswap_bits_in_byte(in[index]);\n\t\t}\n\t\tj -= BYTES_PER_WORD;\n\t}\n}\n\nstatic void add_session_id(struct cryp_ctx *ctx)\n{\n\t/*\n\t * We never want 0 to be a valid value, since this is the default value\n\t * for the software context.\n\t */\n\tif (unlikely(atomic_inc_and_test(&session_id)))\n\t\tatomic_inc(&session_id);\n\n\tctx->session_id = atomic_read(&session_id);\n}\n\nstatic irqreturn_t cryp_interrupt_handler(int irq, void *param)\n{\n\tstruct cryp_ctx *ctx;\n\tint count;\n\tstruct cryp_device_data *device_data;\n\n\tif (param == NULL) {\n\t\tBUG_ON(!param);\n\t\treturn IRQ_HANDLED;\n\t}\n\n\t/* The device is coming from the one found in hw_crypt_noxts. */\n\tdevice_data = (struct cryp_device_data *)param;\n\n\tctx = device_data->current_ctx;\n\n\tif (ctx == NULL) {\n\t\tBUG_ON(!ctx);\n\t\treturn IRQ_HANDLED;\n\t}\n\n\tdev_dbg(ctx->device->dev, \"[%s] (len: %d) %s, \", __func__, ctx->outlen,\n\t\tcryp_pending_irq_src(device_data, CRYP_IRQ_SRC_OUTPUT_FIFO) ?\n\t\t\"out\" : \"in\");\n\n\tif (cryp_pending_irq_src(device_data,\n\t\t\t\t CRYP_IRQ_SRC_OUTPUT_FIFO)) {\n\t\tif (ctx->outlen / ctx->blocksize > 0) {\n\t\t\tcount = ctx->blocksize / 4;\n\n\t\t\treadsl(&device_data->base->dout, ctx->outdata, count);\n\t\t\tctx->outdata += count;\n\t\t\tctx->outlen -= count;\n\n\t\t\tif (ctx->outlen == 0) {\n\t\t\t\tcryp_disable_irq_src(device_data,\n\t\t\t\t\t\t     CRYP_IRQ_SRC_OUTPUT_FIFO);\n\t\t\t}\n\t\t}\n\t} else if (cryp_pending_irq_src(device_data,\n\t\t\t\t\tCRYP_IRQ_SRC_INPUT_FIFO)) {\n\t\tif (ctx->datalen / ctx->blocksize > 0) {\n\t\t\tcount = ctx->blocksize / 4;\n\n\t\t\twritesl(&device_data->base->din, ctx->indata, count);\n\n\t\t\tctx->indata += count;\n\t\t\tctx->datalen -= count;\n\n\t\t\tif (ctx->datalen == 0)\n\t\t\t\tcryp_disable_irq_src(device_data,\n\t\t\t\t\t\t   CRYP_IRQ_SRC_INPUT_FIFO);\n\n\t\t\tif (ctx->config.algomode == CRYP_ALGO_AES_XTS) {\n\t\t\t\tCRYP_PUT_BITS(&device_data->base->cr,\n\t\t\t\t\t      CRYP_START_ENABLE,\n\t\t\t\t\t      CRYP_CR_START_POS,\n\t\t\t\t\t      CRYP_CR_START_MASK);\n\n\t\t\t\tcryp_wait_until_done(device_data);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int mode_is_aes(enum cryp_algo_mode mode)\n{\n\treturn\tCRYP_ALGO_AES_ECB == mode ||\n\t\tCRYP_ALGO_AES_CBC == mode ||\n\t\tCRYP_ALGO_AES_CTR == mode ||\n\t\tCRYP_ALGO_AES_XTS == mode;\n}\n\nstatic int cfg_iv(struct cryp_device_data *device_data, u32 left, u32 right,\n\t\t  enum cryp_init_vector_index index)\n{\n\tstruct cryp_init_vector_value vector_value;\n\n\tdev_dbg(device_data->dev, \"[%s]\", __func__);\n\n\tvector_value.init_value_left = left;\n\tvector_value.init_value_right = right;\n\n\treturn cryp_configure_init_vector(device_data,\n\t\t\t\t\t  index,\n\t\t\t\t\t  vector_value);\n}\n\nstatic int cfg_ivs(struct cryp_device_data *device_data, struct cryp_ctx *ctx)\n{\n\tint i;\n\tint status = 0;\n\tint num_of_regs = ctx->blocksize / 8;\n\tu32 iv[AES_BLOCK_SIZE / 4];\n\n\tdev_dbg(device_data->dev, \"[%s]\", __func__);\n\n\t/*\n\t * Since we loop on num_of_regs we need to have a check in case\n\t * someone provides an incorrect blocksize which would force calling\n\t * cfg_iv with i greater than 2 which is an error.\n\t */\n\tif (num_of_regs > 2) {\n\t\tdev_err(device_data->dev, \"[%s] Incorrect blocksize %d\",\n\t\t\t__func__, ctx->blocksize);\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < ctx->blocksize / 4; i++)\n\t\tiv[i] = uint8p_to_uint32_be(ctx->iv + i*4);\n\n\tfor (i = 0; i < num_of_regs; i++) {\n\t\tstatus = cfg_iv(device_data, iv[i*2], iv[i*2+1],\n\t\t\t\t(enum cryp_init_vector_index) i);\n\t\tif (status != 0)\n\t\t\treturn status;\n\t}\n\treturn status;\n}\n\nstatic int set_key(struct cryp_device_data *device_data,\n\t\t   u32 left_key,\n\t\t   u32 right_key,\n\t\t   enum cryp_key_reg_index index)\n{\n\tstruct cryp_key_value key_value;\n\tint cryp_error;\n\n\tdev_dbg(device_data->dev, \"[%s]\", __func__);\n\n\tkey_value.key_value_left = left_key;\n\tkey_value.key_value_right = right_key;\n\n\tcryp_error = cryp_configure_key_values(device_data,\n\t\t\t\t\t       index,\n\t\t\t\t\t       key_value);\n\tif (cryp_error != 0)\n\t\tdev_err(device_data->dev, \"[%s]: \"\n\t\t\t\"cryp_configure_key_values() failed!\", __func__);\n\n\treturn cryp_error;\n}\n\nstatic int cfg_keys(struct cryp_ctx *ctx)\n{\n\tint i;\n\tint num_of_regs = ctx->keylen / 8;\n\tu32 swapped_key[CRYP_MAX_KEY_SIZE / 4];\n\tint cryp_error = 0;\n\n\tdev_dbg(ctx->device->dev, \"[%s]\", __func__);\n\n\tif (mode_is_aes(ctx->config.algomode)) {\n\t\tswap_words_in_key_and_bits_in_byte((u8 *)ctx->key,\n\t\t\t\t\t\t   (u8 *)swapped_key,\n\t\t\t\t\t\t   ctx->keylen);\n\t} else {\n\t\tfor (i = 0; i < ctx->keylen / 4; i++)\n\t\t\tswapped_key[i] = uint8p_to_uint32_be(ctx->key + i*4);\n\t}\n\n\tfor (i = 0; i < num_of_regs; i++) {\n\t\tcryp_error = set_key(ctx->device,\n\t\t\t\t     *(((u32 *)swapped_key)+i*2),\n\t\t\t\t     *(((u32 *)swapped_key)+i*2+1),\n\t\t\t\t     (enum cryp_key_reg_index) i);\n\n\t\tif (cryp_error != 0) {\n\t\t\tdev_err(ctx->device->dev, \"[%s]: set_key() failed!\",\n\t\t\t\t\t__func__);\n\t\t\treturn cryp_error;\n\t\t}\n\t}\n\treturn cryp_error;\n}\n\nstatic int cryp_setup_context(struct cryp_ctx *ctx,\n\t\t\t      struct cryp_device_data *device_data)\n{\n\tu32 control_register = CRYP_CR_DEFAULT;\n\n\tswitch (cryp_mode) {\n\tcase CRYP_MODE_INTERRUPT:\n\t\twritel_relaxed(CRYP_IMSC_DEFAULT, &device_data->base->imsc);\n\t\tbreak;\n\n\tcase CRYP_MODE_DMA:\n\t\twritel_relaxed(CRYP_DMACR_DEFAULT, &device_data->base->dmacr);\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (ctx->updated == 0) {\n\t\tcryp_flush_inoutfifo(device_data);\n\t\tif (cfg_keys(ctx) != 0) {\n\t\t\tdev_err(ctx->device->dev, \"[%s]: cfg_keys failed!\",\n\t\t\t\t__func__);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (ctx->iv &&\n\t\t    CRYP_ALGO_AES_ECB != ctx->config.algomode &&\n\t\t    CRYP_ALGO_DES_ECB != ctx->config.algomode &&\n\t\t    CRYP_ALGO_TDES_ECB != ctx->config.algomode) {\n\t\t\tif (cfg_ivs(device_data, ctx) != 0)\n\t\t\t\treturn -EPERM;\n\t\t}\n\n\t\tcryp_set_configuration(device_data, &ctx->config,\n\t\t\t\t       &control_register);\n\t\tadd_session_id(ctx);\n\t} else if (ctx->updated == 1 &&\n\t\t   ctx->session_id != atomic_read(&session_id)) {\n\t\tcryp_flush_inoutfifo(device_data);\n\t\tcryp_restore_device_context(device_data, &ctx->dev_ctx);\n\n\t\tadd_session_id(ctx);\n\t\tcontrol_register = ctx->dev_ctx.cr;\n\t} else\n\t\tcontrol_register = ctx->dev_ctx.cr;\n\n\twritel(control_register |\n\t       (CRYP_CRYPEN_ENABLE << CRYP_CR_CRYPEN_POS),\n\t       &device_data->base->cr);\n\n\treturn 0;\n}\n\nstatic int cryp_get_device_data(struct cryp_ctx *ctx,\n\t\t\t\tstruct cryp_device_data **device_data)\n{\n\tint ret;\n\tstruct klist_iter device_iterator;\n\tstruct klist_node *device_node;\n\tstruct cryp_device_data *local_device_data = NULL;\n\tpr_debug(DEV_DBG_NAME \" [%s]\", __func__);\n\n\t/* Wait until a device is available */\n\tret = down_interruptible(&driver_data.device_allocation);\n\tif (ret)\n\t\treturn ret;  /* Interrupted */\n\n\t/* Select a device */\n\tklist_iter_init(&driver_data.device_list, &device_iterator);\n\n\tdevice_node = klist_next(&device_iterator);\n\twhile (device_node) {\n\t\tlocal_device_data = container_of(device_node,\n\t\t\t\t\t   struct cryp_device_data, list_node);\n\t\tspin_lock(&local_device_data->ctx_lock);\n\t\t/* current_ctx allocates a device, NULL = unallocated */\n\t\tif (local_device_data->current_ctx) {\n\t\t\tdevice_node = klist_next(&device_iterator);\n\t\t} else {\n\t\t\tlocal_device_data->current_ctx = ctx;\n\t\t\tctx->device = local_device_data;\n\t\t\tspin_unlock(&local_device_data->ctx_lock);\n\t\t\tbreak;\n\t\t}\n\t\tspin_unlock(&local_device_data->ctx_lock);\n\t}\n\tklist_iter_exit(&device_iterator);\n\n\tif (!device_node) {\n\t\t/**\n\t\t * No free device found.\n\t\t * Since we allocated a device with down_interruptible, this\n\t\t * should not be able to happen.\n\t\t * Number of available devices, which are contained in\n\t\t * device_allocation, is therefore decremented by not doing\n\t\t * an up(device_allocation).\n\t\t */\n\t\treturn -EBUSY;\n\t}\n\n\t*device_data = local_device_data;\n\n\treturn 0;\n}\n\nstatic void cryp_dma_setup_channel(struct cryp_device_data *device_data,\n\t\t\t\t   struct device *dev)\n{\n\tstruct dma_slave_config mem2cryp = {\n\t\t.direction = DMA_MEM_TO_DEV,\n\t\t.dst_addr = device_data->phybase + CRYP_DMA_TX_FIFO,\n\t\t.dst_addr_width = DMA_SLAVE_BUSWIDTH_2_BYTES,\n\t\t.dst_maxburst = 4,\n        };\n\tstruct dma_slave_config cryp2mem = {\n\t\t.direction = DMA_DEV_TO_MEM,\n\t\t.src_addr = device_data->phybase + CRYP_DMA_RX_FIFO,\n\t\t.src_addr_width = DMA_SLAVE_BUSWIDTH_2_BYTES,\n\t\t.src_maxburst = 4,\n        };\n\n\tdma_cap_zero(device_data->dma.mask);\n\tdma_cap_set(DMA_SLAVE, device_data->dma.mask);\n\n\tdevice_data->dma.cfg_mem2cryp = mem_to_engine;\n\tdevice_data->dma.chan_mem2cryp =\n\t\tdma_request_channel(device_data->dma.mask,\n\t\t\t\t    stedma40_filter,\n\t\t\t\t    device_data->dma.cfg_mem2cryp);\n\n\tdevice_data->dma.cfg_cryp2mem = engine_to_mem;\n\tdevice_data->dma.chan_cryp2mem =\n\t\tdma_request_channel(device_data->dma.mask,\n\t\t\t\t    stedma40_filter,\n\t\t\t\t    device_data->dma.cfg_cryp2mem);\n\n\tdmaengine_slave_config(device_data->dma.chan_mem2cryp, &mem2cryp);\n\tdmaengine_slave_config(device_data->dma.chan_cryp2mem, &cryp2mem);\n\n\tinit_completion(&device_data->dma.cryp_dma_complete);\n}\n\nstatic void cryp_dma_out_callback(void *data)\n{\n\tstruct cryp_ctx *ctx = (struct cryp_ctx *) data;\n\tdev_dbg(ctx->device->dev, \"[%s]: \", __func__);\n\n\tcomplete(&ctx->device->dma.cryp_dma_complete);\n}\n\nstatic int cryp_set_dma_transfer(struct cryp_ctx *ctx,\n\t\t\t\t struct scatterlist *sg,\n\t\t\t\t int len,\n\t\t\t\t enum dma_data_direction direction)\n{\n\tstruct dma_async_tx_descriptor *desc;\n\tstruct dma_chan *channel = NULL;\n\tdma_cookie_t cookie;\n\n\tdev_dbg(ctx->device->dev, \"[%s]: \", __func__);\n\n\tif (unlikely(!IS_ALIGNED((u32)sg, 4))) {\n\t\tdev_err(ctx->device->dev, \"[%s]: Data in sg list isn't \"\n\t\t\t\"aligned! Addr: 0x%08x\", __func__, (u32)sg);\n\t\treturn -EFAULT;\n\t}\n\n\tswitch (direction) {\n\tcase DMA_TO_DEVICE:\n\t\tchannel = ctx->device->dma.chan_mem2cryp;\n\t\tctx->device->dma.sg_src = sg;\n\t\tctx->device->dma.sg_src_len = dma_map_sg(channel->device->dev,\n\t\t\t\t\t\t ctx->device->dma.sg_src,\n\t\t\t\t\t\t ctx->device->dma.nents_src,\n\t\t\t\t\t\t direction);\n\n\t\tif (!ctx->device->dma.sg_src_len) {\n\t\t\tdev_dbg(ctx->device->dev,\n\t\t\t\t\"[%s]: Could not map the sg list (TO_DEVICE)\",\n\t\t\t\t__func__);\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\tdev_dbg(ctx->device->dev, \"[%s]: Setting up DMA for buffer \"\n\t\t\t\"(TO_DEVICE)\", __func__);\n\n\t\tdesc = dmaengine_prep_slave_sg(channel,\n\t\t\t\tctx->device->dma.sg_src,\n\t\t\t\tctx->device->dma.sg_src_len,\n\t\t\t\tdirection, DMA_CTRL_ACK);\n\t\tbreak;\n\n\tcase DMA_FROM_DEVICE:\n\t\tchannel = ctx->device->dma.chan_cryp2mem;\n\t\tctx->device->dma.sg_dst = sg;\n\t\tctx->device->dma.sg_dst_len = dma_map_sg(channel->device->dev,\n\t\t\t\t\t\t ctx->device->dma.sg_dst,\n\t\t\t\t\t\t ctx->device->dma.nents_dst,\n\t\t\t\t\t\t direction);\n\n\t\tif (!ctx->device->dma.sg_dst_len) {\n\t\t\tdev_dbg(ctx->device->dev,\n\t\t\t\t\"[%s]: Could not map the sg list (FROM_DEVICE)\",\n\t\t\t\t__func__);\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\tdev_dbg(ctx->device->dev, \"[%s]: Setting up DMA for buffer \"\n\t\t\t\"(FROM_DEVICE)\", __func__);\n\n\t\tdesc = dmaengine_prep_slave_sg(channel,\n\t\t\t\tctx->device->dma.sg_dst,\n\t\t\t\tctx->device->dma.sg_dst_len,\n\t\t\t\tdirection,\n\t\t\t\tDMA_CTRL_ACK |\n\t\t\t\tDMA_PREP_INTERRUPT);\n\n\t\tdesc->callback = cryp_dma_out_callback;\n\t\tdesc->callback_param = ctx;\n\t\tbreak;\n\n\tdefault:\n\t\tdev_dbg(ctx->device->dev, \"[%s]: Invalid DMA direction\",\n\t\t\t__func__);\n\t\treturn -EFAULT;\n\t}\n\n\tcookie = dmaengine_submit(desc);\n\tdma_async_issue_pending(channel);\n\n\treturn 0;\n}\n\nstatic void cryp_dma_done(struct cryp_ctx *ctx)\n{\n\tstruct dma_chan *chan;\n\n\tdev_dbg(ctx->device->dev, \"[%s]: \", __func__);\n\n\tchan = ctx->device->dma.chan_mem2cryp;\n\tdmaengine_device_control(chan, DMA_TERMINATE_ALL, 0);\n\tdma_unmap_sg(chan->device->dev, ctx->device->dma.sg_src,\n\t\t     ctx->device->dma.sg_src_len, DMA_TO_DEVICE);\n\n\tchan = ctx->device->dma.chan_cryp2mem;\n\tdmaengine_device_control(chan, DMA_TERMINATE_ALL, 0);\n\tdma_unmap_sg(chan->device->dev, ctx->device->dma.sg_dst,\n\t\t     ctx->device->dma.sg_dst_len, DMA_FROM_DEVICE);\n}\n\nstatic int cryp_dma_write(struct cryp_ctx *ctx, struct scatterlist *sg,\n\t\t\t  int len)\n{\n\tint error = cryp_set_dma_transfer(ctx, sg, len, DMA_TO_DEVICE);\n\tdev_dbg(ctx->device->dev, \"[%s]: \", __func__);\n\n\tif (error) {\n\t\tdev_dbg(ctx->device->dev, \"[%s]: cryp_set_dma_transfer() \"\n\t\t\t\"failed\", __func__);\n\t\treturn error;\n\t}\n\n\treturn len;\n}\n\nstatic int cryp_dma_read(struct cryp_ctx *ctx, struct scatterlist *sg, int len)\n{\n\tint error = cryp_set_dma_transfer(ctx, sg, len, DMA_FROM_DEVICE);\n\tif (error) {\n\t\tdev_dbg(ctx->device->dev, \"[%s]: cryp_set_dma_transfer() \"\n\t\t\t\"failed\", __func__);\n\t\treturn error;\n\t}\n\n\treturn len;\n}\n\nstatic void cryp_polling_mode(struct cryp_ctx *ctx,\n\t\t\t      struct cryp_device_data *device_data)\n{\n\tint len = ctx->blocksize / BYTES_PER_WORD;\n\tint remaining_length = ctx->datalen;\n\tu32 *indata = (u32 *)ctx->indata;\n\tu32 *outdata = (u32 *)ctx->outdata;\n\n\twhile (remaining_length > 0) {\n\t\twritesl(&device_data->base->din, indata, len);\n\t\tindata += len;\n\t\tremaining_length -= (len * BYTES_PER_WORD);\n\t\tcryp_wait_until_done(device_data);\n\n\t\treadsl(&device_data->base->dout, outdata, len);\n\t\toutdata += len;\n\t\tcryp_wait_until_done(device_data);\n\t}\n}\n\nstatic int cryp_disable_power(struct device *dev,\n\t\t\t      struct cryp_device_data *device_data,\n\t\t\t      bool save_device_context)\n{\n\tint ret = 0;\n\n\tdev_dbg(dev, \"[%s]\", __func__);\n\n\tspin_lock(&device_data->power_state_spinlock);\n\tif (!device_data->power_state)\n\t\tgoto out;\n\n\tspin_lock(&device_data->ctx_lock);\n\tif (save_device_context && device_data->current_ctx) {\n\t\tcryp_save_device_context(device_data,\n\t\t\t\t&device_data->current_ctx->dev_ctx,\n\t\t\t\tcryp_mode);\n\t\tdevice_data->restore_dev_ctx = true;\n\t}\n\tspin_unlock(&device_data->ctx_lock);\n\n\tclk_disable(device_data->clk);\n\tret = regulator_disable(device_data->pwr_regulator);\n\tif (ret)\n\t\tdev_err(dev, \"[%s]: \"\n\t\t\t\t\"regulator_disable() failed!\",\n\t\t\t\t__func__);\n\n\tdevice_data->power_state = false;\n\nout:\n\tspin_unlock(&device_data->power_state_spinlock);\n\n\treturn ret;\n}\n\nstatic int cryp_enable_power(\n\t\tstruct device *dev,\n\t\tstruct cryp_device_data *device_data,\n\t\tbool restore_device_context)\n{\n\tint ret = 0;\n\n\tdev_dbg(dev, \"[%s]\", __func__);\n\n\tspin_lock(&device_data->power_state_spinlock);\n\tif (!device_data->power_state) {\n\t\tret = regulator_enable(device_data->pwr_regulator);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"[%s]: regulator_enable() failed!\",\n\t\t\t\t\t__func__);\n\t\t\tgoto out;\n\t\t}\n\n\t\tret = clk_enable(device_data->clk);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"[%s]: clk_enable() failed!\",\n\t\t\t\t\t__func__);\n\t\t\tregulator_disable(device_data->pwr_regulator);\n\t\t\tgoto out;\n\t\t}\n\t\tdevice_data->power_state = true;\n\t}\n\n\tif (device_data->restore_dev_ctx) {\n\t\tspin_lock(&device_data->ctx_lock);\n\t\tif (restore_device_context && device_data->current_ctx) {\n\t\t\tdevice_data->restore_dev_ctx = false;\n\t\t\tcryp_restore_device_context(device_data,\n\t\t\t\t\t&device_data->current_ctx->dev_ctx);\n\t\t}\n\t\tspin_unlock(&device_data->ctx_lock);\n\t}\nout:\n\tspin_unlock(&device_data->power_state_spinlock);\n\n\treturn ret;\n}\n\nstatic int hw_crypt_noxts(struct cryp_ctx *ctx,\n\t\t\t  struct cryp_device_data *device_data)\n{\n\tint ret = 0;\n\n\tconst u8 *indata = ctx->indata;\n\tu8 *outdata = ctx->outdata;\n\tu32 datalen = ctx->datalen;\n\tu32 outlen = datalen;\n\n\tpr_debug(DEV_DBG_NAME \" [%s]\", __func__);\n\n\tctx->outlen = ctx->datalen;\n\n\tif (unlikely(!IS_ALIGNED((u32)indata, 4))) {\n\t\tpr_debug(DEV_DBG_NAME \" [%s]: Data isn't aligned! Addr: \"\n\t\t\t \"0x%08x\", __func__, (u32)indata);\n\t\treturn -EINVAL;\n\t}\n\n\tret = cryp_setup_context(ctx, device_data);\n\n\tif (ret)\n\t\tgoto out;\n\n\tif (cryp_mode == CRYP_MODE_INTERRUPT) {\n\t\tcryp_enable_irq_src(device_data, CRYP_IRQ_SRC_INPUT_FIFO |\n\t\t\t\t    CRYP_IRQ_SRC_OUTPUT_FIFO);\n\n\t\t/*\n\t\t * ctx->outlen is decremented in the cryp_interrupt_handler\n\t\t * function. We had to add cpu_relax() (barrier) to make sure\n\t\t * that gcc didn't optimze away this variable.\n\t\t */\n\t\twhile (ctx->outlen > 0)\n\t\t\tcpu_relax();\n\t} else if (cryp_mode == CRYP_MODE_POLLING ||\n\t\t   cryp_mode == CRYP_MODE_DMA) {\n\t\t/*\n\t\t * The reason for having DMA in this if case is that if we are\n\t\t * running cryp_mode = 2, then we separate DMA routines for\n\t\t * handling cipher/plaintext > blocksize, except when\n\t\t * running the normal CRYPTO_ALG_TYPE_CIPHER, then we still use\n\t\t * the polling mode. Overhead of doing DMA setup eats up the\n\t\t * benefits using it.\n\t\t */\n\t\tcryp_polling_mode(ctx, device_data);\n\t} else {\n\t\tdev_err(ctx->device->dev, \"[%s]: Invalid operation mode!\",\n\t\t\t__func__);\n\t\tret = -EPERM;\n\t\tgoto out;\n\t}\n\n\tcryp_save_device_context(device_data, &ctx->dev_ctx, cryp_mode);\n\tctx->updated = 1;\n\nout:\n\tctx->indata = indata;\n\tctx->outdata = outdata;\n\tctx->datalen = datalen;\n\tctx->outlen = outlen;\n\n\treturn ret;\n}\n\nstatic int get_nents(struct scatterlist *sg, int nbytes)\n{\n\tint nents = 0;\n\n\twhile (nbytes > 0) {\n\t\tnbytes -= sg->length;\n\t\tsg = scatterwalk_sg_next(sg);\n\t\tnents++;\n\t}\n\n\treturn nents;\n}\n\nstatic int ablk_dma_crypt(struct ablkcipher_request *areq)\n{\n\tstruct crypto_ablkcipher *cipher = crypto_ablkcipher_reqtfm(areq);\n\tstruct cryp_ctx *ctx = crypto_ablkcipher_ctx(cipher);\n\tstruct cryp_device_data *device_data;\n\n\tint bytes_written = 0;\n\tint bytes_read = 0;\n\tint ret;\n\n\tpr_debug(DEV_DBG_NAME \" [%s]\", __func__);\n\n\tctx->datalen = areq->nbytes;\n\tctx->outlen = areq->nbytes;\n\n\tret = cryp_get_device_data(ctx, &device_data);\n\tif (ret)\n\t\treturn ret;\n\n\tret = cryp_setup_context(ctx, device_data);\n\tif (ret)\n\t\tgoto out;\n\n\t/* We have the device now, so store the nents in the dma struct. */\n\tctx->device->dma.nents_src = get_nents(areq->src, ctx->datalen);\n\tctx->device->dma.nents_dst = get_nents(areq->dst, ctx->outlen);\n\n\t/* Enable DMA in- and output. */\n\tcryp_configure_for_dma(device_data, CRYP_DMA_ENABLE_BOTH_DIRECTIONS);\n\n\tbytes_written = cryp_dma_write(ctx, areq->src, ctx->datalen);\n\tbytes_read = cryp_dma_read(ctx, areq->dst, bytes_written);\n\n\twait_for_completion(&ctx->device->dma.cryp_dma_complete);\n\tcryp_dma_done(ctx);\n\n\tcryp_save_device_context(device_data, &ctx->dev_ctx, cryp_mode);\n\tctx->updated = 1;\n\nout:\n\tspin_lock(&device_data->ctx_lock);\n\tdevice_data->current_ctx = NULL;\n\tctx->device = NULL;\n\tspin_unlock(&device_data->ctx_lock);\n\n\t/*\n\t * The down_interruptible part for this semaphore is called in\n\t * cryp_get_device_data.\n\t */\n\tup(&driver_data.device_allocation);\n\n\tif (unlikely(bytes_written != bytes_read))\n\t\treturn -EPERM;\n\n\treturn 0;\n}\n\nstatic int ablk_crypt(struct ablkcipher_request *areq)\n{\n\tstruct ablkcipher_walk walk;\n\tstruct crypto_ablkcipher *cipher = crypto_ablkcipher_reqtfm(areq);\n\tstruct cryp_ctx *ctx = crypto_ablkcipher_ctx(cipher);\n\tstruct cryp_device_data *device_data;\n\tunsigned long src_paddr;\n\tunsigned long dst_paddr;\n\tint ret;\n\tint nbytes;\n\n\tpr_debug(DEV_DBG_NAME \" [%s]\", __func__);\n\n\tret = cryp_get_device_data(ctx, &device_data);\n\tif (ret)\n\t\tgoto out;\n\n\tablkcipher_walk_init(&walk, areq->dst, areq->src, areq->nbytes);\n\tret = ablkcipher_walk_phys(areq, &walk);\n\n\tif (ret) {\n\t\tpr_err(DEV_DBG_NAME \"[%s]: ablkcipher_walk_phys() failed!\",\n\t\t\t__func__);\n\t\tgoto out;\n\t}\n\n\twhile ((nbytes = walk.nbytes) > 0) {\n\t\tctx->iv = walk.iv;\n\t\tsrc_paddr = (page_to_phys(walk.src.page) + walk.src.offset);\n\t\tctx->indata = phys_to_virt(src_paddr);\n\n\t\tdst_paddr = (page_to_phys(walk.dst.page) + walk.dst.offset);\n\t\tctx->outdata = phys_to_virt(dst_paddr);\n\n\t\tctx->datalen = nbytes - (nbytes % ctx->blocksize);\n\n\t\tret = hw_crypt_noxts(ctx, device_data);\n\t\tif (ret)\n\t\t\tgoto out;\n\n\t\tnbytes -= ctx->datalen;\n\t\tret = ablkcipher_walk_done(areq, &walk, nbytes);\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\tablkcipher_walk_complete(&walk);\n\nout:\n\t/* Release the device */\n\tspin_lock(&device_data->ctx_lock);\n\tdevice_data->current_ctx = NULL;\n\tctx->device = NULL;\n\tspin_unlock(&device_data->ctx_lock);\n\n\t/*\n\t * The down_interruptible part for this semaphore is called in\n\t * cryp_get_device_data.\n\t */\n\tup(&driver_data.device_allocation);\n\n\treturn ret;\n}\n\nstatic int aes_ablkcipher_setkey(struct crypto_ablkcipher *cipher,\n\t\t\t\t const u8 *key, unsigned int keylen)\n{\n\tstruct cryp_ctx *ctx = crypto_ablkcipher_ctx(cipher);\n\tu32 *flags = &cipher->base.crt_flags;\n\n\tpr_debug(DEV_DBG_NAME \" [%s]\", __func__);\n\n\tswitch (keylen) {\n\tcase AES_KEYSIZE_128:\n\t\tctx->config.keysize = CRYP_KEY_SIZE_128;\n\t\tbreak;\n\n\tcase AES_KEYSIZE_192:\n\t\tctx->config.keysize = CRYP_KEY_SIZE_192;\n\t\tbreak;\n\n\tcase AES_KEYSIZE_256:\n\t\tctx->config.keysize = CRYP_KEY_SIZE_256;\n\t\tbreak;\n\n\tdefault:\n\t\tpr_err(DEV_DBG_NAME \"[%s]: Unknown keylen!\", __func__);\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(ctx->key, key, keylen);\n\tctx->keylen = keylen;\n\n\tctx->updated = 0;\n\n\treturn 0;\n}\n\nstatic int des_ablkcipher_setkey(struct crypto_ablkcipher *cipher,\n\t\t\t\t const u8 *key, unsigned int keylen)\n{\n\tstruct cryp_ctx *ctx = crypto_ablkcipher_ctx(cipher);\n\tu32 *flags = &cipher->base.crt_flags;\n\tu32 tmp[DES_EXPKEY_WORDS];\n\tint ret;\n\n\tpr_debug(DEV_DBG_NAME \" [%s]\", __func__);\n\tif (keylen != DES_KEY_SIZE) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\tpr_debug(DEV_DBG_NAME \" [%s]: CRYPTO_TFM_RES_BAD_KEY_LEN\",\n\t\t\t\t__func__);\n\t\treturn -EINVAL;\n\t}\n\n\tret = des_ekey(tmp, key);\n\tif (unlikely(ret == 0) && (*flags & CRYPTO_TFM_REQ_WEAK_KEY)) {\n\t\t*flags |= CRYPTO_TFM_RES_WEAK_KEY;\n\t\tpr_debug(DEV_DBG_NAME \" [%s]: CRYPTO_TFM_REQ_WEAK_KEY\",\n\t\t\t\t__func__);\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(ctx->key, key, keylen);\n\tctx->keylen = keylen;\n\n\tctx->updated = 0;\n\treturn 0;\n}\n\nstatic int des3_ablkcipher_setkey(struct crypto_ablkcipher *cipher,\n\t\t\t\t  const u8 *key, unsigned int keylen)\n{\n\tstruct cryp_ctx *ctx = crypto_ablkcipher_ctx(cipher);\n\tu32 *flags = &cipher->base.crt_flags;\n\tconst u32 *K = (const u32 *)key;\n\tu32 tmp[DES3_EDE_EXPKEY_WORDS];\n\tint i, ret;\n\n\tpr_debug(DEV_DBG_NAME \" [%s]\", __func__);\n\tif (keylen != DES3_EDE_KEY_SIZE) {\n\t\t*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\n\t\tpr_debug(DEV_DBG_NAME \" [%s]: CRYPTO_TFM_RES_BAD_KEY_LEN\",\n\t\t\t\t__func__);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Checking key interdependency for weak key detection. */\n\tif (unlikely(!((K[0] ^ K[2]) | (K[1] ^ K[3])) ||\n\t\t\t\t!((K[2] ^ K[4]) | (K[3] ^ K[5]))) &&\n\t\t\t(*flags & CRYPTO_TFM_REQ_WEAK_KEY)) {\n\t\t*flags |= CRYPTO_TFM_RES_WEAK_KEY;\n\t\tpr_debug(DEV_DBG_NAME \" [%s]: CRYPTO_TFM_REQ_WEAK_KEY\",\n\t\t\t\t__func__);\n\t\treturn -EINVAL;\n\t}\n\tfor (i = 0; i < 3; i++) {\n\t\tret = des_ekey(tmp, key + i*DES_KEY_SIZE);\n\t\tif (unlikely(ret == 0) && (*flags & CRYPTO_TFM_REQ_WEAK_KEY)) {\n\t\t\t*flags |= CRYPTO_TFM_RES_WEAK_KEY;\n\t\t\tpr_debug(DEV_DBG_NAME \" [%s]: \"\n\t\t\t\t\t\"CRYPTO_TFM_REQ_WEAK_KEY\", __func__);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tmemcpy(ctx->key, key, keylen);\n\tctx->keylen = keylen;\n\n\tctx->updated = 0;\n\treturn 0;\n}\n\nstatic int cryp_blk_encrypt(struct ablkcipher_request *areq)\n{\n\tstruct crypto_ablkcipher *cipher = crypto_ablkcipher_reqtfm(areq);\n\tstruct cryp_ctx *ctx = crypto_ablkcipher_ctx(cipher);\n\n\tpr_debug(DEV_DBG_NAME \" [%s]\", __func__);\n\n\tctx->config.algodir = CRYP_ALGORITHM_ENCRYPT;\n\n\t/*\n\t * DMA does not work for DES due to a hw bug */\n\tif (cryp_mode == CRYP_MODE_DMA && mode_is_aes(ctx->config.algomode))\n\t\treturn ablk_dma_crypt(areq);\n\n\t/* For everything except DMA, we run the non DMA version. */\n\treturn ablk_crypt(areq);\n}\n\nstatic int cryp_blk_decrypt(struct ablkcipher_request *areq)\n{\n\tstruct crypto_ablkcipher *cipher = crypto_ablkcipher_reqtfm(areq);\n\tstruct cryp_ctx *ctx = crypto_ablkcipher_ctx(cipher);\n\n\tpr_debug(DEV_DBG_NAME \" [%s]\", __func__);\n\n\tctx->config.algodir = CRYP_ALGORITHM_DECRYPT;\n\n\t/* DMA does not work for DES due to a hw bug */\n\tif (cryp_mode == CRYP_MODE_DMA && mode_is_aes(ctx->config.algomode))\n\t\treturn ablk_dma_crypt(areq);\n\n\t/* For everything except DMA, we run the non DMA version. */\n\treturn ablk_crypt(areq);\n}\n\nstruct cryp_algo_template {\n\tenum cryp_algo_mode algomode;\n\tstruct crypto_alg crypto;\n};\n\nstatic int cryp_cra_init(struct crypto_tfm *tfm)\n{\n\tstruct cryp_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_alg *alg = tfm->__crt_alg;\n\tstruct cryp_algo_template *cryp_alg = container_of(alg,\n\t\t\tstruct cryp_algo_template,\n\t\t\tcrypto);\n\n\tctx->config.algomode = cryp_alg->algomode;\n\tctx->blocksize = crypto_tfm_alg_blocksize(tfm);\n\n\treturn 0;\n}\n\nstatic struct cryp_algo_template cryp_algs[] = {\n\t{\n\t\t.algomode = CRYP_ALGO_AES_ECB,\n\t\t.crypto = {\n\t\t\t.cra_name = \"aes\",\n\t\t\t.cra_driver_name = \"aes-ux500\",\n\t\t\t.cra_priority =\t300,\n\t\t\t.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\n\t\t\t\t\tCRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct cryp_ctx),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_type = &crypto_ablkcipher_type,\n\t\t\t.cra_init = cryp_cra_init,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_u = {\n\t\t\t\t.ablkcipher = {\n\t\t\t\t\t.min_keysize = AES_MIN_KEY_SIZE,\n\t\t\t\t\t.max_keysize = AES_MAX_KEY_SIZE,\n\t\t\t\t\t.setkey = aes_ablkcipher_setkey,\n\t\t\t\t\t.encrypt = cryp_blk_encrypt,\n\t\t\t\t\t.decrypt = cryp_blk_decrypt\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\t.algomode = CRYP_ALGO_AES_ECB,\n\t\t.crypto = {\n\t\t\t.cra_name = \"ecb(aes)\",\n\t\t\t.cra_driver_name = \"ecb-aes-ux500\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\n\t\t\t\t\tCRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct cryp_ctx),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_type = &crypto_ablkcipher_type,\n\t\t\t.cra_init = cryp_cra_init,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_u = {\n\t\t\t\t.ablkcipher = {\n\t\t\t\t\t.min_keysize = AES_MIN_KEY_SIZE,\n\t\t\t\t\t.max_keysize = AES_MAX_KEY_SIZE,\n\t\t\t\t\t.setkey = aes_ablkcipher_setkey,\n\t\t\t\t\t.encrypt = cryp_blk_encrypt,\n\t\t\t\t\t.decrypt = cryp_blk_decrypt,\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\t.algomode = CRYP_ALGO_AES_CBC,\n\t\t.crypto = {\n\t\t\t.cra_name = \"cbc(aes)\",\n\t\t\t.cra_driver_name = \"cbc-aes-ux500\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\n\t\t\t\t\tCRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct cryp_ctx),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_type = &crypto_ablkcipher_type,\n\t\t\t.cra_init = cryp_cra_init,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_u = {\n\t\t\t\t.ablkcipher = {\n\t\t\t\t\t.min_keysize = AES_MIN_KEY_SIZE,\n\t\t\t\t\t.max_keysize = AES_MAX_KEY_SIZE,\n\t\t\t\t\t.setkey = aes_ablkcipher_setkey,\n\t\t\t\t\t.encrypt = cryp_blk_encrypt,\n\t\t\t\t\t.decrypt = cryp_blk_decrypt,\n\t\t\t\t\t.ivsize = AES_BLOCK_SIZE,\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\t.algomode = CRYP_ALGO_AES_CTR,\n\t\t.crypto = {\n\t\t\t.cra_name = \"ctr(aes)\",\n\t\t\t.cra_driver_name = \"ctr-aes-ux500\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\n\t\t\t\t\t\tCRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct cryp_ctx),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_type = &crypto_ablkcipher_type,\n\t\t\t.cra_init = cryp_cra_init,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_u = {\n\t\t\t\t.ablkcipher = {\n\t\t\t\t\t.min_keysize = AES_MIN_KEY_SIZE,\n\t\t\t\t\t.max_keysize = AES_MAX_KEY_SIZE,\n\t\t\t\t\t.setkey = aes_ablkcipher_setkey,\n\t\t\t\t\t.encrypt = cryp_blk_encrypt,\n\t\t\t\t\t.decrypt = cryp_blk_decrypt,\n\t\t\t\t\t.ivsize = AES_BLOCK_SIZE,\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\t.algomode = CRYP_ALGO_DES_ECB,\n\t\t.crypto = {\n\t\t\t.cra_name = \"des\",\n\t\t\t.cra_driver_name = \"des-ux500\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\n\t\t\t\t\t\tCRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize = DES_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct cryp_ctx),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_type = &crypto_ablkcipher_type,\n\t\t\t.cra_init = cryp_cra_init,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_u = {\n\t\t\t\t.ablkcipher = {\n\t\t\t\t\t.min_keysize = DES_KEY_SIZE,\n\t\t\t\t\t.max_keysize = DES_KEY_SIZE,\n\t\t\t\t\t.setkey = des_ablkcipher_setkey,\n\t\t\t\t\t.encrypt = cryp_blk_encrypt,\n\t\t\t\t\t.decrypt = cryp_blk_decrypt\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t},\n\t{\n\t\t.algomode = CRYP_ALGO_TDES_ECB,\n\t\t.crypto = {\n\t\t\t.cra_name = \"des3_ede\",\n\t\t\t.cra_driver_name = \"des3_ede-ux500\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\n\t\t\t\t\t\tCRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize = DES3_EDE_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct cryp_ctx),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_type = &crypto_ablkcipher_type,\n\t\t\t.cra_init = cryp_cra_init,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_u = {\n\t\t\t\t.ablkcipher = {\n\t\t\t\t\t.min_keysize = DES3_EDE_KEY_SIZE,\n\t\t\t\t\t.max_keysize = DES3_EDE_KEY_SIZE,\n\t\t\t\t\t.setkey = des_ablkcipher_setkey,\n\t\t\t\t\t.encrypt = cryp_blk_encrypt,\n\t\t\t\t\t.decrypt = cryp_blk_decrypt\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\t.algomode = CRYP_ALGO_DES_ECB,\n\t\t.crypto = {\n\t\t\t.cra_name = \"ecb(des)\",\n\t\t\t.cra_driver_name = \"ecb-des-ux500\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\n\t\t\t\t\tCRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize = DES_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct cryp_ctx),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_type = &crypto_ablkcipher_type,\n\t\t\t.cra_init = cryp_cra_init,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_u = {\n\t\t\t\t.ablkcipher = {\n\t\t\t\t\t.min_keysize = DES_KEY_SIZE,\n\t\t\t\t\t.max_keysize = DES_KEY_SIZE,\n\t\t\t\t\t.setkey = des_ablkcipher_setkey,\n\t\t\t\t\t.encrypt = cryp_blk_encrypt,\n\t\t\t\t\t.decrypt = cryp_blk_decrypt,\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\t.algomode = CRYP_ALGO_TDES_ECB,\n\t\t.crypto = {\n\t\t\t.cra_name = \"ecb(des3_ede)\",\n\t\t\t.cra_driver_name = \"ecb-des3_ede-ux500\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\n\t\t\t\t\tCRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize = DES3_EDE_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct cryp_ctx),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_type = &crypto_ablkcipher_type,\n\t\t\t.cra_init = cryp_cra_init,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_u = {\n\t\t\t\t.ablkcipher = {\n\t\t\t\t\t.min_keysize = DES3_EDE_KEY_SIZE,\n\t\t\t\t\t.max_keysize = DES3_EDE_KEY_SIZE,\n\t\t\t\t\t.setkey = des3_ablkcipher_setkey,\n\t\t\t\t\t.encrypt = cryp_blk_encrypt,\n\t\t\t\t\t.decrypt = cryp_blk_decrypt,\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\t.algomode = CRYP_ALGO_DES_CBC,\n\t\t.crypto = {\n\t\t\t.cra_name = \"cbc(des)\",\n\t\t\t.cra_driver_name = \"cbc-des-ux500\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\n\t\t\t\t\tCRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize = DES_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct cryp_ctx),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_type = &crypto_ablkcipher_type,\n\t\t\t.cra_init = cryp_cra_init,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_u = {\n\t\t\t\t.ablkcipher = {\n\t\t\t\t\t.min_keysize = DES_KEY_SIZE,\n\t\t\t\t\t.max_keysize = DES_KEY_SIZE,\n\t\t\t\t\t.setkey = des_ablkcipher_setkey,\n\t\t\t\t\t.encrypt = cryp_blk_encrypt,\n\t\t\t\t\t.decrypt = cryp_blk_decrypt,\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\t.algomode = CRYP_ALGO_TDES_CBC,\n\t\t.crypto = {\n\t\t\t.cra_name = \"cbc(des3_ede)\",\n\t\t\t.cra_driver_name = \"cbc-des3_ede-ux500\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\n\t\t\t\t\tCRYPTO_ALG_ASYNC,\n\t\t\t.cra_blocksize = DES3_EDE_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct cryp_ctx),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_type = &crypto_ablkcipher_type,\n\t\t\t.cra_init = cryp_cra_init,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_u = {\n\t\t\t\t.ablkcipher = {\n\t\t\t\t\t.min_keysize = DES3_EDE_KEY_SIZE,\n\t\t\t\t\t.max_keysize = DES3_EDE_KEY_SIZE,\n\t\t\t\t\t.setkey = des3_ablkcipher_setkey,\n\t\t\t\t\t.encrypt = cryp_blk_encrypt,\n\t\t\t\t\t.decrypt = cryp_blk_decrypt,\n\t\t\t\t\t.ivsize = DES3_EDE_BLOCK_SIZE,\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n};\n\n/**\n * cryp_algs_register_all -\n */\nstatic int cryp_algs_register_all(void)\n{\n\tint ret;\n\tint i;\n\tint count;\n\n\tpr_debug(\"[%s]\", __func__);\n\n\tfor (i = 0; i < ARRAY_SIZE(cryp_algs); i++) {\n\t\tret = crypto_register_alg(&cryp_algs[i].crypto);\n\t\tif (ret) {\n\t\t\tcount = i;\n\t\t\tpr_err(\"[%s] alg registration failed\",\n\t\t\t\t\tcryp_algs[i].crypto.cra_driver_name);\n\t\t\tgoto unreg;\n\t\t}\n\t}\n\treturn 0;\nunreg:\n\tfor (i = 0; i < count; i++)\n\t\tcrypto_unregister_alg(&cryp_algs[i].crypto);\n\treturn ret;\n}\n\n/**\n * cryp_algs_unregister_all -\n */\nstatic void cryp_algs_unregister_all(void)\n{\n\tint i;\n\n\tpr_debug(DEV_DBG_NAME \" [%s]\", __func__);\n\n\tfor (i = 0; i < ARRAY_SIZE(cryp_algs); i++)\n\t\tcrypto_unregister_alg(&cryp_algs[i].crypto);\n}\n\nstatic int ux500_cryp_probe(struct platform_device *pdev)\n{\n\tint ret;\n\tint cryp_error = 0;\n\tstruct resource *res = NULL;\n\tstruct resource *res_irq = NULL;\n\tstruct cryp_device_data *device_data;\n\tstruct cryp_protection_config prot = {\n\t\t.privilege_access = CRYP_STATE_ENABLE\n\t};\n\tstruct device *dev = &pdev->dev;\n\n\tdev_dbg(dev, \"[%s]\", __func__);\n\tdevice_data = kzalloc(sizeof(struct cryp_device_data), GFP_ATOMIC);\n\tif (!device_data) {\n\t\tdev_err(dev, \"[%s]: kzalloc() failed!\", __func__);\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tdevice_data->dev = dev;\n\tdevice_data->current_ctx = NULL;\n\n\t/* Grab the DMA configuration from platform data. */\n\tmem_to_engine = &((struct cryp_platform_data *)\n\t\t\t dev->platform_data)->mem_to_engine;\n\tengine_to_mem = &((struct cryp_platform_data *)\n\t\t\t dev->platform_data)->engine_to_mem;\n\n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tif (!res) {\n\t\tdev_err(dev, \"[%s]: platform_get_resource() failed\",\n\t\t\t\t__func__);\n\t\tret = -ENODEV;\n\t\tgoto out_kfree;\n\t}\n\n\tres = request_mem_region(res->start, resource_size(res), pdev->name);\n\tif (res == NULL) {\n\t\tdev_err(dev, \"[%s]: request_mem_region() failed\",\n\t\t\t\t__func__);\n\t\tret = -EBUSY;\n\t\tgoto out_kfree;\n\t}\n\n\tdevice_data->phybase = res->start;\n\tdevice_data->base = ioremap(res->start, resource_size(res));\n\tif (!device_data->base) {\n\t\tdev_err(dev, \"[%s]: ioremap failed!\", __func__);\n\t\tret = -ENOMEM;\n\t\tgoto out_free_mem;\n\t}\n\n\tspin_lock_init(&device_data->ctx_lock);\n\tspin_lock_init(&device_data->power_state_spinlock);\n\n\t/* Enable power for CRYP hardware block */\n\tdevice_data->pwr_regulator = regulator_get(&pdev->dev, \"v-ape\");\n\tif (IS_ERR(device_data->pwr_regulator)) {\n\t\tdev_err(dev, \"[%s]: could not get cryp regulator\", __func__);\n\t\tret = PTR_ERR(device_data->pwr_regulator);\n\t\tdevice_data->pwr_regulator = NULL;\n\t\tgoto out_unmap;\n\t}\n\n\t/* Enable the clk for CRYP hardware block */\n\tdevice_data->clk = clk_get(&pdev->dev, NULL);\n\tif (IS_ERR(device_data->clk)) {\n\t\tdev_err(dev, \"[%s]: clk_get() failed!\", __func__);\n\t\tret = PTR_ERR(device_data->clk);\n\t\tgoto out_regulator;\n\t}\n\n\tret = clk_prepare(device_data->clk);\n\tif (ret) {\n\t\tdev_err(dev, \"[%s]: clk_prepare() failed!\", __func__);\n\t\tgoto out_clk;\n\t}\n\n\t/* Enable device power (and clock) */\n\tret = cryp_enable_power(device_data->dev, device_data, false);\n\tif (ret) {\n\t\tdev_err(dev, \"[%s]: cryp_enable_power() failed!\", __func__);\n\t\tgoto out_clk_unprepare;\n\t}\n\n\tcryp_error = cryp_check(device_data);\n\tif (cryp_error != 0) {\n\t\tdev_err(dev, \"[%s]: cryp_init() failed!\", __func__);\n\t\tret = -EINVAL;\n\t\tgoto out_power;\n\t}\n\n\tcryp_error = cryp_configure_protection(device_data, &prot);\n\tif (cryp_error != 0) {\n\t\tdev_err(dev, \"[%s]: cryp_configure_protection() failed!\",\n\t\t\t__func__);\n\t\tret = -EINVAL;\n\t\tgoto out_power;\n\t}\n\n\tres_irq = platform_get_resource(pdev, IORESOURCE_IRQ, 0);\n\tif (!res_irq) {\n\t\tdev_err(dev, \"[%s]: IORESOURCE_IRQ unavailable\",\n\t\t\t__func__);\n\t\tret = -ENODEV;\n\t\tgoto out_power;\n\t}\n\n\tret = request_irq(res_irq->start,\n\t\t\t  cryp_interrupt_handler,\n\t\t\t  0,\n\t\t\t  \"cryp1\",\n\t\t\t  device_data);\n\tif (ret) {\n\t\tdev_err(dev, \"[%s]: Unable to request IRQ\", __func__);\n\t\tgoto out_power;\n\t}\n\n\tif (cryp_mode == CRYP_MODE_DMA)\n\t\tcryp_dma_setup_channel(device_data, dev);\n\n\tplatform_set_drvdata(pdev, device_data);\n\n\t/* Put the new device into the device list... */\n\tklist_add_tail(&device_data->list_node, &driver_data.device_list);\n\n\t/* ... and signal that a new device is available. */\n\tup(&driver_data.device_allocation);\n\n\tatomic_set(&session_id, 1);\n\n\tret = cryp_algs_register_all();\n\tif (ret) {\n\t\tdev_err(dev, \"[%s]: cryp_algs_register_all() failed!\",\n\t\t\t__func__);\n\t\tgoto out_power;\n\t}\n\n\tdev_info(dev, \"successfully registered\\n\");\n\n\treturn 0;\n\nout_power:\n\tcryp_disable_power(device_data->dev, device_data, false);\n\nout_clk_unprepare:\n\tclk_unprepare(device_data->clk);\n\nout_clk:\n\tclk_put(device_data->clk);\n\nout_regulator:\n\tregulator_put(device_data->pwr_regulator);\n\nout_unmap:\n\tiounmap(device_data->base);\n\nout_free_mem:\n\trelease_mem_region(res->start, resource_size(res));\n\nout_kfree:\n\tkfree(device_data);\nout:\n\treturn ret;\n}\n\nstatic int ux500_cryp_remove(struct platform_device *pdev)\n{\n\tstruct resource *res = NULL;\n\tstruct resource *res_irq = NULL;\n\tstruct cryp_device_data *device_data;\n\n\tdev_dbg(&pdev->dev, \"[%s]\", __func__);\n\tdevice_data = platform_get_drvdata(pdev);\n\tif (!device_data) {\n\t\tdev_err(&pdev->dev, \"[%s]: platform_get_drvdata() failed!\",\n\t\t\t__func__);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* Try to decrease the number of available devices. */\n\tif (down_trylock(&driver_data.device_allocation))\n\t\treturn -EBUSY;\n\n\t/* Check that the device is free */\n\tspin_lock(&device_data->ctx_lock);\n\t/* current_ctx allocates a device, NULL = unallocated */\n\tif (device_data->current_ctx) {\n\t\t/* The device is busy */\n\t\tspin_unlock(&device_data->ctx_lock);\n\t\t/* Return the device to the pool. */\n\t\tup(&driver_data.device_allocation);\n\t\treturn -EBUSY;\n\t}\n\n\tspin_unlock(&device_data->ctx_lock);\n\n\t/* Remove the device from the list */\n\tif (klist_node_attached(&device_data->list_node))\n\t\tklist_remove(&device_data->list_node);\n\n\t/* If this was the last device, remove the services */\n\tif (list_empty(&driver_data.device_list.k_list))\n\t\tcryp_algs_unregister_all();\n\n\tres_irq = platform_get_resource(pdev, IORESOURCE_IRQ, 0);\n\tif (!res_irq)\n\t\tdev_err(&pdev->dev, \"[%s]: IORESOURCE_IRQ, unavailable\",\n\t\t\t__func__);\n\telse {\n\t\tdisable_irq(res_irq->start);\n\t\tfree_irq(res_irq->start, device_data);\n\t}\n\n\tif (cryp_disable_power(&pdev->dev, device_data, false))\n\t\tdev_err(&pdev->dev, \"[%s]: cryp_disable_power() failed\",\n\t\t\t__func__);\n\n\tclk_unprepare(device_data->clk);\n\tclk_put(device_data->clk);\n\tregulator_put(device_data->pwr_regulator);\n\n\tiounmap(device_data->base);\n\n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tif (res)\n\t\trelease_mem_region(res->start, resource_size(res));\n\n\tkfree(device_data);\n\n\treturn 0;\n}\n\nstatic void ux500_cryp_shutdown(struct platform_device *pdev)\n{\n\tstruct resource *res_irq = NULL;\n\tstruct cryp_device_data *device_data;\n\n\tdev_dbg(&pdev->dev, \"[%s]\", __func__);\n\n\tdevice_data = platform_get_drvdata(pdev);\n\tif (!device_data) {\n\t\tdev_err(&pdev->dev, \"[%s]: platform_get_drvdata() failed!\",\n\t\t\t__func__);\n\t\treturn;\n\t}\n\n\t/* Check that the device is free */\n\tspin_lock(&device_data->ctx_lock);\n\t/* current_ctx allocates a device, NULL = unallocated */\n\tif (!device_data->current_ctx) {\n\t\tif (down_trylock(&driver_data.device_allocation))\n\t\t\tdev_dbg(&pdev->dev, \"[%s]: Cryp still in use!\"\n\t\t\t\t\"Shutting down anyway...\", __func__);\n\t\t/**\n\t\t * (Allocate the device)\n\t\t * Need to set this to non-null (dummy) value,\n\t\t * to avoid usage if context switching.\n\t\t */\n\t\tdevice_data->current_ctx++;\n\t}\n\tspin_unlock(&device_data->ctx_lock);\n\n\t/* Remove the device from the list */\n\tif (klist_node_attached(&device_data->list_node))\n\t\tklist_remove(&device_data->list_node);\n\n\t/* If this was the last device, remove the services */\n\tif (list_empty(&driver_data.device_list.k_list))\n\t\tcryp_algs_unregister_all();\n\n\tres_irq = platform_get_resource(pdev, IORESOURCE_IRQ, 0);\n\tif (!res_irq)\n\t\tdev_err(&pdev->dev, \"[%s]: IORESOURCE_IRQ, unavailable\",\n\t\t\t__func__);\n\telse {\n\t\tdisable_irq(res_irq->start);\n\t\tfree_irq(res_irq->start, device_data);\n\t}\n\n\tif (cryp_disable_power(&pdev->dev, device_data, false))\n\t\tdev_err(&pdev->dev, \"[%s]: cryp_disable_power() failed\",\n\t\t\t__func__);\n\n}\n\n#ifdef CONFIG_PM_SLEEP\nstatic int ux500_cryp_suspend(struct device *dev)\n{\n\tint ret;\n\tstruct platform_device *pdev = to_platform_device(dev);\n\tstruct cryp_device_data *device_data;\n\tstruct resource *res_irq;\n\tstruct cryp_ctx *temp_ctx = NULL;\n\n\tdev_dbg(dev, \"[%s]\", __func__);\n\n\t/* Handle state? */\n\tdevice_data = platform_get_drvdata(pdev);\n\tif (!device_data) {\n\t\tdev_err(dev, \"[%s]: platform_get_drvdata() failed!\", __func__);\n\t\treturn -ENOMEM;\n\t}\n\n\tres_irq = platform_get_resource(pdev, IORESOURCE_IRQ, 0);\n\tif (!res_irq)\n\t\tdev_err(dev, \"[%s]: IORESOURCE_IRQ, unavailable\", __func__);\n\telse\n\t\tdisable_irq(res_irq->start);\n\n\tspin_lock(&device_data->ctx_lock);\n\tif (!device_data->current_ctx)\n\t\tdevice_data->current_ctx++;\n\tspin_unlock(&device_data->ctx_lock);\n\n\tif (device_data->current_ctx == ++temp_ctx) {\n\t\tif (down_interruptible(&driver_data.device_allocation))\n\t\t\tdev_dbg(dev, \"[%s]: down_interruptible() failed\",\n\t\t\t\t__func__);\n\t\tret = cryp_disable_power(dev, device_data, false);\n\n\t} else\n\t\tret = cryp_disable_power(dev, device_data, true);\n\n\tif (ret)\n\t\tdev_err(dev, \"[%s]: cryp_disable_power()\", __func__);\n\n\treturn ret;\n}\n\nstatic int ux500_cryp_resume(struct device *dev)\n{\n\tint ret = 0;\n\tstruct platform_device *pdev = to_platform_device(dev);\n\tstruct cryp_device_data *device_data;\n\tstruct resource *res_irq;\n\tstruct cryp_ctx *temp_ctx = NULL;\n\n\tdev_dbg(dev, \"[%s]\", __func__);\n\n\tdevice_data = platform_get_drvdata(pdev);\n\tif (!device_data) {\n\t\tdev_err(dev, \"[%s]: platform_get_drvdata() failed!\", __func__);\n\t\treturn -ENOMEM;\n\t}\n\n\tspin_lock(&device_data->ctx_lock);\n\tif (device_data->current_ctx == ++temp_ctx)\n\t\tdevice_data->current_ctx = NULL;\n\tspin_unlock(&device_data->ctx_lock);\n\n\n\tif (!device_data->current_ctx)\n\t\tup(&driver_data.device_allocation);\n\telse\n\t\tret = cryp_enable_power(dev, device_data, true);\n\n\tif (ret)\n\t\tdev_err(dev, \"[%s]: cryp_enable_power() failed!\", __func__);\n\telse {\n\t\tres_irq = platform_get_resource(pdev, IORESOURCE_IRQ, 0);\n\t\tif (res_irq)\n\t\t\tenable_irq(res_irq->start);\n\t}\n\n\treturn ret;\n}\n#endif\n\nstatic SIMPLE_DEV_PM_OPS(ux500_cryp_pm, ux500_cryp_suspend, ux500_cryp_resume);\n\nstatic const struct of_device_id ux500_cryp_match[] = {\n        { .compatible = \"stericsson,ux500-cryp\" },\n        { },\n};\n\nstatic struct platform_driver cryp_driver = {\n\t.probe  = ux500_cryp_probe,\n\t.remove = ux500_cryp_remove,\n\t.shutdown = ux500_cryp_shutdown,\n\t.driver = {\n\t\t.owner = THIS_MODULE,\n\t\t.name  = \"cryp1\",\n\t\t.of_match_table = ux500_cryp_match,\n\t\t.pm    = &ux500_cryp_pm,\n\t}\n};\n\nstatic int __init ux500_cryp_mod_init(void)\n{\n\tpr_debug(\"[%s] is called!\", __func__);\n\tklist_init(&driver_data.device_list, NULL, NULL);\n\t/* Initialize the semaphore to 0 devices (locked state) */\n\tsema_init(&driver_data.device_allocation, 0);\n\treturn platform_driver_register(&cryp_driver);\n}\n\nstatic void __exit ux500_cryp_mod_fini(void)\n{\n\tpr_debug(\"[%s] is called!\", __func__);\n\tplatform_driver_unregister(&cryp_driver);\n\treturn;\n}\n\nmodule_init(ux500_cryp_mod_init);\nmodule_exit(ux500_cryp_mod_fini);\n\nmodule_param(cryp_mode, int, 0);\n\nMODULE_DESCRIPTION(\"Driver for ST-Ericsson UX500 CRYP crypto engine.\");\nMODULE_ALIAS_CRYPTO(\"aes-all\");\nMODULE_ALIAS_CRYPTO(\"des-all\");\n\nMODULE_LICENSE(\"GPL\");\n", "/*\n * Cryptographic API.\n * Support for Nomadik hardware crypto engine.\n\n * Copyright (C) ST-Ericsson SA 2010\n * Author: Shujuan Chen <shujuan.chen@stericsson.com> for ST-Ericsson\n * Author: Joakim Bech <joakim.xx.bech@stericsson.com> for ST-Ericsson\n * Author: Berne Hebark <berne.herbark@stericsson.com> for ST-Ericsson.\n * Author: Niklas Hernaeus <niklas.hernaeus@stericsson.com> for ST-Ericsson.\n * Author: Andreas Westin <andreas.westin@stericsson.com> for ST-Ericsson.\n * License terms: GNU General Public License (GPL) version 2\n */\n\n#define pr_fmt(fmt) \"hashX hashX: \" fmt\n\n#include <linux/clk.h>\n#include <linux/device.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/io.h>\n#include <linux/klist.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/platform_device.h>\n#include <linux/crypto.h>\n\n#include <linux/regulator/consumer.h>\n#include <linux/dmaengine.h>\n#include <linux/bitops.h>\n\n#include <crypto/internal/hash.h>\n#include <crypto/sha.h>\n#include <crypto/scatterwalk.h>\n#include <crypto/algapi.h>\n\n#include <linux/platform_data/crypto-ux500.h>\n\n#include \"hash_alg.h\"\n\nstatic int hash_mode;\nmodule_param(hash_mode, int, 0);\nMODULE_PARM_DESC(hash_mode, \"CPU or DMA mode. CPU = 0 (default), DMA = 1\");\n\n/**\n * Pre-calculated empty message digests.\n */\nstatic const u8 zero_message_hash_sha1[SHA1_DIGEST_SIZE] = {\n\t0xda, 0x39, 0xa3, 0xee, 0x5e, 0x6b, 0x4b, 0x0d,\n\t0x32, 0x55, 0xbf, 0xef, 0x95, 0x60, 0x18, 0x90,\n\t0xaf, 0xd8, 0x07, 0x09\n};\n\nstatic const u8 zero_message_hash_sha256[SHA256_DIGEST_SIZE] = {\n\t0xe3, 0xb0, 0xc4, 0x42, 0x98, 0xfc, 0x1c, 0x14,\n\t0x9a, 0xfb, 0xf4, 0xc8, 0x99, 0x6f, 0xb9, 0x24,\n\t0x27, 0xae, 0x41, 0xe4, 0x64, 0x9b, 0x93, 0x4c,\n\t0xa4, 0x95, 0x99, 0x1b, 0x78, 0x52, 0xb8, 0x55\n};\n\n/* HMAC-SHA1, no key */\nstatic const u8 zero_message_hmac_sha1[SHA1_DIGEST_SIZE] = {\n\t0xfb, 0xdb, 0x1d, 0x1b, 0x18, 0xaa, 0x6c, 0x08,\n\t0x32, 0x4b, 0x7d, 0x64, 0xb7, 0x1f, 0xb7, 0x63,\n\t0x70, 0x69, 0x0e, 0x1d\n};\n\n/* HMAC-SHA256, no key */\nstatic const u8 zero_message_hmac_sha256[SHA256_DIGEST_SIZE] = {\n\t0xb6, 0x13, 0x67, 0x9a, 0x08, 0x14, 0xd9, 0xec,\n\t0x77, 0x2f, 0x95, 0xd7, 0x78, 0xc3, 0x5f, 0xc5,\n\t0xff, 0x16, 0x97, 0xc4, 0x93, 0x71, 0x56, 0x53,\n\t0xc6, 0xc7, 0x12, 0x14, 0x42, 0x92, 0xc5, 0xad\n};\n\n/**\n * struct hash_driver_data - data specific to the driver.\n *\n * @device_list:\tA list of registered devices to choose from.\n * @device_allocation:\tA semaphore initialized with number of devices.\n */\nstruct hash_driver_data {\n\tstruct klist\t\tdevice_list;\n\tstruct semaphore\tdevice_allocation;\n};\n\nstatic struct hash_driver_data\tdriver_data;\n\n/* Declaration of functions */\n/**\n * hash_messagepad - Pads a message and write the nblw bits.\n * @device_data:\tStructure for the hash device.\n * @message:\t\tLast word of a message\n * @index_bytes:\tThe number of bytes in the last message\n *\n * This function manages the final part of the digest calculation, when less\n * than 512 bits (64 bytes) remain in message. This means index_bytes < 64.\n *\n */\nstatic void hash_messagepad(struct hash_device_data *device_data,\n\t\t\t    const u32 *message, u8 index_bytes);\n\n/**\n * release_hash_device - Releases a previously allocated hash device.\n * @device_data:\tStructure for the hash device.\n *\n */\nstatic void release_hash_device(struct hash_device_data *device_data)\n{\n\tspin_lock(&device_data->ctx_lock);\n\tdevice_data->current_ctx->device = NULL;\n\tdevice_data->current_ctx = NULL;\n\tspin_unlock(&device_data->ctx_lock);\n\n\t/*\n\t * The down_interruptible part for this semaphore is called in\n\t * cryp_get_device_data.\n\t */\n\tup(&driver_data.device_allocation);\n}\n\nstatic void hash_dma_setup_channel(struct hash_device_data *device_data,\n\t\t\t\t   struct device *dev)\n{\n\tstruct hash_platform_data *platform_data = dev->platform_data;\n\tstruct dma_slave_config conf = {\n\t\t.direction = DMA_MEM_TO_DEV,\n\t\t.dst_addr = device_data->phybase + HASH_DMA_FIFO,\n\t\t.dst_addr_width = DMA_SLAVE_BUSWIDTH_2_BYTES,\n\t\t.dst_maxburst = 16,\n\t};\n\n\tdma_cap_zero(device_data->dma.mask);\n\tdma_cap_set(DMA_SLAVE, device_data->dma.mask);\n\n\tdevice_data->dma.cfg_mem2hash = platform_data->mem_to_engine;\n\tdevice_data->dma.chan_mem2hash =\n\t\tdma_request_channel(device_data->dma.mask,\n\t\t\t\t    platform_data->dma_filter,\n\t\t\t\t    device_data->dma.cfg_mem2hash);\n\n\tdmaengine_slave_config(device_data->dma.chan_mem2hash, &conf);\n\n\tinit_completion(&device_data->dma.complete);\n}\n\nstatic void hash_dma_callback(void *data)\n{\n\tstruct hash_ctx *ctx = data;\n\n\tcomplete(&ctx->device->dma.complete);\n}\n\nstatic int hash_set_dma_transfer(struct hash_ctx *ctx, struct scatterlist *sg,\n\t\t\t\t int len, enum dma_data_direction direction)\n{\n\tstruct dma_async_tx_descriptor *desc = NULL;\n\tstruct dma_chan *channel = NULL;\n\tdma_cookie_t cookie;\n\n\tif (direction != DMA_TO_DEVICE) {\n\t\tdev_err(ctx->device->dev, \"%s: Invalid DMA direction\\n\",\n\t\t\t__func__);\n\t\treturn -EFAULT;\n\t}\n\n\tsg->length = ALIGN(sg->length, HASH_DMA_ALIGN_SIZE);\n\n\tchannel = ctx->device->dma.chan_mem2hash;\n\tctx->device->dma.sg = sg;\n\tctx->device->dma.sg_len = dma_map_sg(channel->device->dev,\n\t\t\tctx->device->dma.sg, ctx->device->dma.nents,\n\t\t\tdirection);\n\n\tif (!ctx->device->dma.sg_len) {\n\t\tdev_err(ctx->device->dev, \"%s: Could not map the sg list (TO_DEVICE)\\n\",\n\t\t\t__func__);\n\t\treturn -EFAULT;\n\t}\n\n\tdev_dbg(ctx->device->dev, \"%s: Setting up DMA for buffer (TO_DEVICE)\\n\",\n\t\t__func__);\n\tdesc = dmaengine_prep_slave_sg(channel,\n\t\t\tctx->device->dma.sg, ctx->device->dma.sg_len,\n\t\t\tdirection, DMA_CTRL_ACK | DMA_PREP_INTERRUPT);\n\tif (!desc) {\n\t\tdev_err(ctx->device->dev,\n\t\t\t\"%s: device_prep_slave_sg() failed!\\n\", __func__);\n\t\treturn -EFAULT;\n\t}\n\n\tdesc->callback = hash_dma_callback;\n\tdesc->callback_param = ctx;\n\n\tcookie = dmaengine_submit(desc);\n\tdma_async_issue_pending(channel);\n\n\treturn 0;\n}\n\nstatic void hash_dma_done(struct hash_ctx *ctx)\n{\n\tstruct dma_chan *chan;\n\n\tchan = ctx->device->dma.chan_mem2hash;\n\tdmaengine_device_control(chan, DMA_TERMINATE_ALL, 0);\n\tdma_unmap_sg(chan->device->dev, ctx->device->dma.sg,\n\t\t     ctx->device->dma.sg_len, DMA_TO_DEVICE);\n}\n\nstatic int hash_dma_write(struct hash_ctx *ctx,\n\t\t\t  struct scatterlist *sg, int len)\n{\n\tint error = hash_set_dma_transfer(ctx, sg, len, DMA_TO_DEVICE);\n\tif (error) {\n\t\tdev_dbg(ctx->device->dev,\n\t\t\t\"%s: hash_set_dma_transfer() failed\\n\", __func__);\n\t\treturn error;\n\t}\n\n\treturn len;\n}\n\n/**\n * get_empty_message_digest - Returns a pre-calculated digest for\n * the empty message.\n * @device_data:\tStructure for the hash device.\n * @zero_hash:\t\tBuffer to return the empty message digest.\n * @zero_hash_size:\tHash size of the empty message digest.\n * @zero_digest:\tTrue if zero_digest returned.\n */\nstatic int get_empty_message_digest(\n\t\tstruct hash_device_data *device_data,\n\t\tu8 *zero_hash, u32 *zero_hash_size, bool *zero_digest)\n{\n\tint ret = 0;\n\tstruct hash_ctx *ctx = device_data->current_ctx;\n\t*zero_digest = false;\n\n\t/**\n\t * Caller responsible for ctx != NULL.\n\t */\n\n\tif (HASH_OPER_MODE_HASH == ctx->config.oper_mode) {\n\t\tif (HASH_ALGO_SHA1 == ctx->config.algorithm) {\n\t\t\tmemcpy(zero_hash, &zero_message_hash_sha1[0],\n\t\t\t       SHA1_DIGEST_SIZE);\n\t\t\t*zero_hash_size = SHA1_DIGEST_SIZE;\n\t\t\t*zero_digest = true;\n\t\t} else if (HASH_ALGO_SHA256 ==\n\t\t\t\tctx->config.algorithm) {\n\t\t\tmemcpy(zero_hash, &zero_message_hash_sha256[0],\n\t\t\t       SHA256_DIGEST_SIZE);\n\t\t\t*zero_hash_size = SHA256_DIGEST_SIZE;\n\t\t\t*zero_digest = true;\n\t\t} else {\n\t\t\tdev_err(device_data->dev, \"%s: Incorrect algorithm!\\n\",\n\t\t\t\t__func__);\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t} else if (HASH_OPER_MODE_HMAC == ctx->config.oper_mode) {\n\t\tif (!ctx->keylen) {\n\t\t\tif (HASH_ALGO_SHA1 == ctx->config.algorithm) {\n\t\t\t\tmemcpy(zero_hash, &zero_message_hmac_sha1[0],\n\t\t\t\t       SHA1_DIGEST_SIZE);\n\t\t\t\t*zero_hash_size = SHA1_DIGEST_SIZE;\n\t\t\t\t*zero_digest = true;\n\t\t\t} else if (HASH_ALGO_SHA256 == ctx->config.algorithm) {\n\t\t\t\tmemcpy(zero_hash, &zero_message_hmac_sha256[0],\n\t\t\t\t       SHA256_DIGEST_SIZE);\n\t\t\t\t*zero_hash_size = SHA256_DIGEST_SIZE;\n\t\t\t\t*zero_digest = true;\n\t\t\t} else {\n\t\t\t\tdev_err(device_data->dev, \"%s: Incorrect algorithm!\\n\",\n\t\t\t\t\t__func__);\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t} else {\n\t\t\tdev_dbg(device_data->dev,\n\t\t\t\t\"%s: Continue hash calculation, since hmac key available\\n\",\n\t\t\t\t__func__);\n\t\t}\n\t}\nout:\n\n\treturn ret;\n}\n\n/**\n * hash_disable_power - Request to disable power and clock.\n * @device_data:\tStructure for the hash device.\n * @save_device_state:\tIf true, saves the current hw state.\n *\n * This function request for disabling power (regulator) and clock,\n * and could also save current hw state.\n */\nstatic int hash_disable_power(struct hash_device_data *device_data,\n\t\t\t      bool save_device_state)\n{\n\tint ret = 0;\n\tstruct device *dev = device_data->dev;\n\n\tspin_lock(&device_data->power_state_lock);\n\tif (!device_data->power_state)\n\t\tgoto out;\n\n\tif (save_device_state) {\n\t\thash_save_state(device_data,\n\t\t\t\t&device_data->state);\n\t\tdevice_data->restore_dev_state = true;\n\t}\n\n\tclk_disable(device_data->clk);\n\tret = regulator_disable(device_data->regulator);\n\tif (ret)\n\t\tdev_err(dev, \"%s: regulator_disable() failed!\\n\", __func__);\n\n\tdevice_data->power_state = false;\n\nout:\n\tspin_unlock(&device_data->power_state_lock);\n\n\treturn ret;\n}\n\n/**\n * hash_enable_power - Request to enable power and clock.\n * @device_data:\t\tStructure for the hash device.\n * @restore_device_state:\tIf true, restores a previous saved hw state.\n *\n * This function request for enabling power (regulator) and clock,\n * and could also restore a previously saved hw state.\n */\nstatic int hash_enable_power(struct hash_device_data *device_data,\n\t\t\t     bool restore_device_state)\n{\n\tint ret = 0;\n\tstruct device *dev = device_data->dev;\n\n\tspin_lock(&device_data->power_state_lock);\n\tif (!device_data->power_state) {\n\t\tret = regulator_enable(device_data->regulator);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"%s: regulator_enable() failed!\\n\",\n\t\t\t\t__func__);\n\t\t\tgoto out;\n\t\t}\n\t\tret = clk_enable(device_data->clk);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"%s: clk_enable() failed!\\n\", __func__);\n\t\t\tret = regulator_disable(\n\t\t\t\t\tdevice_data->regulator);\n\t\t\tgoto out;\n\t\t}\n\t\tdevice_data->power_state = true;\n\t}\n\n\tif (device_data->restore_dev_state) {\n\t\tif (restore_device_state) {\n\t\t\tdevice_data->restore_dev_state = false;\n\t\t\thash_resume_state(device_data, &device_data->state);\n\t\t}\n\t}\nout:\n\tspin_unlock(&device_data->power_state_lock);\n\n\treturn ret;\n}\n\n/**\n * hash_get_device_data - Checks for an available hash device and return it.\n * @hash_ctx:\t\tStructure for the hash context.\n * @device_data:\tStructure for the hash device.\n *\n * This function check for an available hash device and return it to\n * the caller.\n * Note! Caller need to release the device, calling up().\n */\nstatic int hash_get_device_data(struct hash_ctx *ctx,\n\t\t\t\tstruct hash_device_data **device_data)\n{\n\tint\t\t\tret;\n\tstruct klist_iter\tdevice_iterator;\n\tstruct klist_node\t*device_node;\n\tstruct hash_device_data *local_device_data = NULL;\n\n\t/* Wait until a device is available */\n\tret = down_interruptible(&driver_data.device_allocation);\n\tif (ret)\n\t\treturn ret;  /* Interrupted */\n\n\t/* Select a device */\n\tklist_iter_init(&driver_data.device_list, &device_iterator);\n\tdevice_node = klist_next(&device_iterator);\n\twhile (device_node) {\n\t\tlocal_device_data = container_of(device_node,\n\t\t\t\t\t   struct hash_device_data, list_node);\n\t\tspin_lock(&local_device_data->ctx_lock);\n\t\t/* current_ctx allocates a device, NULL = unallocated */\n\t\tif (local_device_data->current_ctx) {\n\t\t\tdevice_node = klist_next(&device_iterator);\n\t\t} else {\n\t\t\tlocal_device_data->current_ctx = ctx;\n\t\t\tctx->device = local_device_data;\n\t\t\tspin_unlock(&local_device_data->ctx_lock);\n\t\t\tbreak;\n\t\t}\n\t\tspin_unlock(&local_device_data->ctx_lock);\n\t}\n\tklist_iter_exit(&device_iterator);\n\n\tif (!device_node) {\n\t\t/**\n\t\t * No free device found.\n\t\t * Since we allocated a device with down_interruptible, this\n\t\t * should not be able to happen.\n\t\t * Number of available devices, which are contained in\n\t\t * device_allocation, is therefore decremented by not doing\n\t\t * an up(device_allocation).\n\t\t */\n\t\treturn -EBUSY;\n\t}\n\n\t*device_data = local_device_data;\n\n\treturn 0;\n}\n\n/**\n * hash_hw_write_key - Writes the key to the hardware registries.\n *\n * @device_data:\tStructure for the hash device.\n * @key:\t\tKey to be written.\n * @keylen:\t\tThe lengt of the key.\n *\n * Note! This function DOES NOT write to the NBLW registry, even though\n * specified in the the hw design spec. Either due to incorrect info in the\n * spec or due to a bug in the hw.\n */\nstatic void hash_hw_write_key(struct hash_device_data *device_data,\n\t\t\t      const u8 *key, unsigned int keylen)\n{\n\tu32 word = 0;\n\tint nwords = 1;\n\n\tHASH_CLEAR_BITS(&device_data->base->str, HASH_STR_NBLW_MASK);\n\n\twhile (keylen >= 4) {\n\t\tu32 *key_word = (u32 *)key;\n\n\t\tHASH_SET_DIN(key_word, nwords);\n\t\tkeylen -= 4;\n\t\tkey += 4;\n\t}\n\n\t/* Take care of the remaining bytes in the last word */\n\tif (keylen) {\n\t\tword = 0;\n\t\twhile (keylen) {\n\t\t\tword |= (key[keylen - 1] << (8 * (keylen - 1)));\n\t\t\tkeylen--;\n\t\t}\n\n\t\tHASH_SET_DIN(&word, nwords);\n\t}\n\n\twhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\n\t\tcpu_relax();\n\n\tHASH_SET_DCAL;\n\n\twhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\n\t\tcpu_relax();\n}\n\n/**\n * init_hash_hw - Initialise the hash hardware for a new calculation.\n * @device_data:\tStructure for the hash device.\n * @ctx:\t\tThe hash context.\n *\n * This function will enable the bits needed to clear and start a new\n * calculation.\n */\nstatic int init_hash_hw(struct hash_device_data *device_data,\n\t\t\tstruct hash_ctx *ctx)\n{\n\tint ret = 0;\n\n\tret = hash_setconfiguration(device_data, &ctx->config);\n\tif (ret) {\n\t\tdev_err(device_data->dev, \"%s: hash_setconfiguration() failed!\\n\",\n\t\t\t__func__);\n\t\treturn ret;\n\t}\n\n\thash_begin(device_data, ctx);\n\n\tif (ctx->config.oper_mode == HASH_OPER_MODE_HMAC)\n\t\thash_hw_write_key(device_data, ctx->key, ctx->keylen);\n\n\treturn ret;\n}\n\n/**\n * hash_get_nents - Return number of entries (nents) in scatterlist (sg).\n *\n * @sg:\t\tScatterlist.\n * @size:\tSize in bytes.\n * @aligned:\tTrue if sg data aligned to work in DMA mode.\n *\n */\nstatic int hash_get_nents(struct scatterlist *sg, int size, bool *aligned)\n{\n\tint nents = 0;\n\tbool aligned_data = true;\n\n\twhile (size > 0 && sg) {\n\t\tnents++;\n\t\tsize -= sg->length;\n\n\t\t/* hash_set_dma_transfer will align last nent */\n\t\tif ((aligned && !IS_ALIGNED(sg->offset, HASH_DMA_ALIGN_SIZE)) ||\n\t\t    (!IS_ALIGNED(sg->length, HASH_DMA_ALIGN_SIZE) && size > 0))\n\t\t\taligned_data = false;\n\n\t\tsg = sg_next(sg);\n\t}\n\n\tif (aligned)\n\t\t*aligned = aligned_data;\n\n\tif (size != 0)\n\t\treturn -EFAULT;\n\n\treturn nents;\n}\n\n/**\n * hash_dma_valid_data - checks for dma valid sg data.\n * @sg:\t\tScatterlist.\n * @datasize:\tDatasize in bytes.\n *\n * NOTE! This function checks for dma valid sg data, since dma\n * only accept datasizes of even wordsize.\n */\nstatic bool hash_dma_valid_data(struct scatterlist *sg, int datasize)\n{\n\tbool aligned;\n\n\t/* Need to include at least one nent, else error */\n\tif (hash_get_nents(sg, datasize, &aligned) < 1)\n\t\treturn false;\n\n\treturn aligned;\n}\n\n/**\n * hash_init - Common hash init function for SHA1/SHA2 (SHA256).\n * @req: The hash request for the job.\n *\n * Initialize structures.\n */\nstatic int hash_init(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\n\tstruct hash_req_ctx *req_ctx = ahash_request_ctx(req);\n\n\tif (!ctx->key)\n\t\tctx->keylen = 0;\n\n\tmemset(&req_ctx->state, 0, sizeof(struct hash_state));\n\treq_ctx->updated = 0;\n\tif (hash_mode == HASH_MODE_DMA) {\n\t\tif (req->nbytes < HASH_DMA_ALIGN_SIZE) {\n\t\t\treq_ctx->dma_mode = false; /* Don't use DMA */\n\n\t\t\tpr_debug(\"%s: DMA mode, but direct to CPU mode for data size < %d\\n\",\n\t\t\t\t __func__, HASH_DMA_ALIGN_SIZE);\n\t\t} else {\n\t\t\tif (req->nbytes >= HASH_DMA_PERFORMANCE_MIN_SIZE &&\n\t\t\t    hash_dma_valid_data(req->src, req->nbytes)) {\n\t\t\t\treq_ctx->dma_mode = true;\n\t\t\t} else {\n\t\t\t\treq_ctx->dma_mode = false;\n\t\t\t\tpr_debug(\"%s: DMA mode, but use CPU mode for datalength < %d or non-aligned data, except in last nent\\n\",\n\t\t\t\t\t __func__,\n\t\t\t\t\t HASH_DMA_PERFORMANCE_MIN_SIZE);\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n\n/**\n * hash_processblock - This function processes a single block of 512 bits (64\n *                     bytes), word aligned, starting at message.\n * @device_data:\tStructure for the hash device.\n * @message:\t\tBlock (512 bits) of message to be written to\n *\t\t\tthe HASH hardware.\n *\n */\nstatic void hash_processblock(struct hash_device_data *device_data,\n\t\t\t      const u32 *message, int length)\n{\n\tint len = length / HASH_BYTES_PER_WORD;\n\t/*\n\t * NBLW bits. Reset the number of bits in last word (NBLW).\n\t */\n\tHASH_CLEAR_BITS(&device_data->base->str, HASH_STR_NBLW_MASK);\n\n\t/*\n\t * Write message data to the HASH_DIN register.\n\t */\n\tHASH_SET_DIN(message, len);\n}\n\n/**\n * hash_messagepad - Pads a message and write the nblw bits.\n * @device_data:\tStructure for the hash device.\n * @message:\t\tLast word of a message.\n * @index_bytes:\tThe number of bytes in the last message.\n *\n * This function manages the final part of the digest calculation, when less\n * than 512 bits (64 bytes) remain in message. This means index_bytes < 64.\n *\n */\nstatic void hash_messagepad(struct hash_device_data *device_data,\n\t\t\t    const u32 *message, u8 index_bytes)\n{\n\tint nwords = 1;\n\n\t/*\n\t * Clear hash str register, only clear NBLW\n\t * since DCAL will be reset by hardware.\n\t */\n\tHASH_CLEAR_BITS(&device_data->base->str, HASH_STR_NBLW_MASK);\n\n\t/* Main loop */\n\twhile (index_bytes >= 4) {\n\t\tHASH_SET_DIN(message, nwords);\n\t\tindex_bytes -= 4;\n\t\tmessage++;\n\t}\n\n\tif (index_bytes)\n\t\tHASH_SET_DIN(message, nwords);\n\n\twhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\n\t\tcpu_relax();\n\n\t/* num_of_bytes == 0 => NBLW <- 0 (32 bits valid in DATAIN) */\n\tHASH_SET_NBLW(index_bytes * 8);\n\tdev_dbg(device_data->dev, \"%s: DIN=0x%08x NBLW=%lu\\n\",\n\t\t__func__, readl_relaxed(&device_data->base->din),\n\t\treadl_relaxed(&device_data->base->str) & HASH_STR_NBLW_MASK);\n\tHASH_SET_DCAL;\n\tdev_dbg(device_data->dev, \"%s: after dcal -> DIN=0x%08x NBLW=%lu\\n\",\n\t\t__func__, readl_relaxed(&device_data->base->din),\n\t\treadl_relaxed(&device_data->base->str) & HASH_STR_NBLW_MASK);\n\n\twhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\n\t\tcpu_relax();\n}\n\n/**\n * hash_incrementlength - Increments the length of the current message.\n * @ctx: Hash context\n * @incr: Length of message processed already\n *\n * Overflow cannot occur, because conditions for overflow are checked in\n * hash_hw_update.\n */\nstatic void hash_incrementlength(struct hash_req_ctx *ctx, u32 incr)\n{\n\tctx->state.length.low_word += incr;\n\n\t/* Check for wrap-around */\n\tif (ctx->state.length.low_word < incr)\n\t\tctx->state.length.high_word++;\n}\n\n/**\n * hash_setconfiguration - Sets the required configuration for the hash\n *                         hardware.\n * @device_data:\tStructure for the hash device.\n * @config:\t\tPointer to a configuration structure.\n */\nint hash_setconfiguration(struct hash_device_data *device_data,\n\t\t\t  struct hash_config *config)\n{\n\tint ret = 0;\n\n\tif (config->algorithm != HASH_ALGO_SHA1 &&\n\t    config->algorithm != HASH_ALGO_SHA256)\n\t\treturn -EPERM;\n\n\t/*\n\t * DATAFORM bits. Set the DATAFORM bits to 0b11, which means the data\n\t * to be written to HASH_DIN is considered as 32 bits.\n\t */\n\tHASH_SET_DATA_FORMAT(config->data_format);\n\n\t/*\n\t * ALGO bit. Set to 0b1 for SHA-1 and 0b0 for SHA-256\n\t */\n\tswitch (config->algorithm) {\n\tcase HASH_ALGO_SHA1:\n\t\tHASH_SET_BITS(&device_data->base->cr, HASH_CR_ALGO_MASK);\n\t\tbreak;\n\n\tcase HASH_ALGO_SHA256:\n\t\tHASH_CLEAR_BITS(&device_data->base->cr, HASH_CR_ALGO_MASK);\n\t\tbreak;\n\n\tdefault:\n\t\tdev_err(device_data->dev, \"%s: Incorrect algorithm\\n\",\n\t\t\t__func__);\n\t\treturn -EPERM;\n\t}\n\n\t/*\n\t * MODE bit. This bit selects between HASH or HMAC mode for the\n\t * selected algorithm. 0b0 = HASH and 0b1 = HMAC.\n\t */\n\tif (HASH_OPER_MODE_HASH == config->oper_mode)\n\t\tHASH_CLEAR_BITS(&device_data->base->cr,\n\t\t\t\tHASH_CR_MODE_MASK);\n\telse if (HASH_OPER_MODE_HMAC == config->oper_mode) {\n\t\tHASH_SET_BITS(&device_data->base->cr, HASH_CR_MODE_MASK);\n\t\tif (device_data->current_ctx->keylen > HASH_BLOCK_SIZE) {\n\t\t\t/* Truncate key to blocksize */\n\t\t\tdev_dbg(device_data->dev, \"%s: LKEY set\\n\", __func__);\n\t\t\tHASH_SET_BITS(&device_data->base->cr,\n\t\t\t\t      HASH_CR_LKEY_MASK);\n\t\t} else {\n\t\t\tdev_dbg(device_data->dev, \"%s: LKEY cleared\\n\",\n\t\t\t\t__func__);\n\t\t\tHASH_CLEAR_BITS(&device_data->base->cr,\n\t\t\t\t\tHASH_CR_LKEY_MASK);\n\t\t}\n\t} else {\t/* Wrong hash mode */\n\t\tret = -EPERM;\n\t\tdev_err(device_data->dev, \"%s: HASH_INVALID_PARAMETER!\\n\",\n\t\t\t__func__);\n\t}\n\treturn ret;\n}\n\n/**\n * hash_begin - This routine resets some globals and initializes the hash\n *              hardware.\n * @device_data:\tStructure for the hash device.\n * @ctx:\t\tHash context.\n */\nvoid hash_begin(struct hash_device_data *device_data, struct hash_ctx *ctx)\n{\n\t/* HW and SW initializations */\n\t/* Note: there is no need to initialize buffer and digest members */\n\n\twhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\n\t\tcpu_relax();\n\n\t/*\n\t * INIT bit. Set this bit to 0b1 to reset the HASH processor core and\n\t * prepare the initialize the HASH accelerator to compute the message\n\t * digest of a new message.\n\t */\n\tHASH_INITIALIZE;\n\n\t/*\n\t * NBLW bits. Reset the number of bits in last word (NBLW).\n\t */\n\tHASH_CLEAR_BITS(&device_data->base->str, HASH_STR_NBLW_MASK);\n}\n\nstatic int hash_process_data(struct hash_device_data *device_data,\n\t\t\t     struct hash_ctx *ctx, struct hash_req_ctx *req_ctx,\n\t\t\t     int msg_length, u8 *data_buffer, u8 *buffer,\n\t\t\t     u8 *index)\n{\n\tint ret = 0;\n\tu32 count;\n\n\tdo {\n\t\tif ((*index + msg_length) < HASH_BLOCK_SIZE) {\n\t\t\tfor (count = 0; count < msg_length; count++) {\n\t\t\t\tbuffer[*index + count] =\n\t\t\t\t\t*(data_buffer + count);\n\t\t\t}\n\t\t\t*index += msg_length;\n\t\t\tmsg_length = 0;\n\t\t} else {\n\t\t\tif (req_ctx->updated) {\n\t\t\t\tret = hash_resume_state(device_data,\n\t\t\t\t\t\t&device_data->state);\n\t\t\t\tmemmove(req_ctx->state.buffer,\n\t\t\t\t\tdevice_data->state.buffer,\n\t\t\t\t\tHASH_BLOCK_SIZE / sizeof(u32));\n\t\t\t\tif (ret) {\n\t\t\t\t\tdev_err(device_data->dev,\n\t\t\t\t\t\t\"%s: hash_resume_state() failed!\\n\",\n\t\t\t\t\t\t__func__);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tret = init_hash_hw(device_data, ctx);\n\t\t\t\tif (ret) {\n\t\t\t\t\tdev_err(device_data->dev,\n\t\t\t\t\t\t\"%s: init_hash_hw() failed!\\n\",\n\t\t\t\t\t\t__func__);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t\treq_ctx->updated = 1;\n\t\t\t}\n\t\t\t/*\n\t\t\t * If 'data_buffer' is four byte aligned and\n\t\t\t * local buffer does not have any data, we can\n\t\t\t * write data directly from 'data_buffer' to\n\t\t\t * HW peripheral, otherwise we first copy data\n\t\t\t * to a local buffer\n\t\t\t */\n\t\t\tif ((0 == (((u32)data_buffer) % 4)) &&\n\t\t\t    (0 == *index))\n\t\t\t\thash_processblock(device_data,\n\t\t\t\t\t\t  (const u32 *)data_buffer,\n\t\t\t\t\t\t  HASH_BLOCK_SIZE);\n\t\t\telse {\n\t\t\t\tfor (count = 0;\n\t\t\t\t     count < (u32)(HASH_BLOCK_SIZE - *index);\n\t\t\t\t     count++) {\n\t\t\t\t\tbuffer[*index + count] =\n\t\t\t\t\t\t*(data_buffer + count);\n\t\t\t\t}\n\t\t\t\thash_processblock(device_data,\n\t\t\t\t\t\t  (const u32 *)buffer,\n\t\t\t\t\t\t  HASH_BLOCK_SIZE);\n\t\t\t}\n\t\t\thash_incrementlength(req_ctx, HASH_BLOCK_SIZE);\n\t\t\tdata_buffer += (HASH_BLOCK_SIZE - *index);\n\n\t\t\tmsg_length -= (HASH_BLOCK_SIZE - *index);\n\t\t\t*index = 0;\n\n\t\t\tret = hash_save_state(device_data,\n\t\t\t\t\t&device_data->state);\n\n\t\t\tmemmove(device_data->state.buffer,\n\t\t\t\treq_ctx->state.buffer,\n\t\t\t\tHASH_BLOCK_SIZE / sizeof(u32));\n\t\t\tif (ret) {\n\t\t\t\tdev_err(device_data->dev, \"%s: hash_save_state() failed!\\n\",\n\t\t\t\t\t__func__);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t} while (msg_length != 0);\nout:\n\n\treturn ret;\n}\n\n/**\n * hash_dma_final - The hash dma final function for SHA1/SHA256.\n * @req:\tThe hash request for the job.\n */\nstatic int hash_dma_final(struct ahash_request *req)\n{\n\tint ret = 0;\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\n\tstruct hash_req_ctx *req_ctx = ahash_request_ctx(req);\n\tstruct hash_device_data *device_data;\n\tu8 digest[SHA256_DIGEST_SIZE];\n\tint bytes_written = 0;\n\n\tret = hash_get_device_data(ctx, &device_data);\n\tif (ret)\n\t\treturn ret;\n\n\tdev_dbg(device_data->dev, \"%s: (ctx=0x%x)!\\n\", __func__, (u32) ctx);\n\n\tif (req_ctx->updated) {\n\t\tret = hash_resume_state(device_data, &device_data->state);\n\n\t\tif (ret) {\n\t\t\tdev_err(device_data->dev, \"%s: hash_resume_state() failed!\\n\",\n\t\t\t\t__func__);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (!req_ctx->updated) {\n\t\tret = hash_setconfiguration(device_data, &ctx->config);\n\t\tif (ret) {\n\t\t\tdev_err(device_data->dev,\n\t\t\t\t\"%s: hash_setconfiguration() failed!\\n\",\n\t\t\t\t__func__);\n\t\t\tgoto out;\n\t\t}\n\n\t\t/* Enable DMA input */\n\t\tif (hash_mode != HASH_MODE_DMA || !req_ctx->dma_mode) {\n\t\t\tHASH_CLEAR_BITS(&device_data->base->cr,\n\t\t\t\t\tHASH_CR_DMAE_MASK);\n\t\t} else {\n\t\t\tHASH_SET_BITS(&device_data->base->cr,\n\t\t\t\t      HASH_CR_DMAE_MASK);\n\t\t\tHASH_SET_BITS(&device_data->base->cr,\n\t\t\t\t      HASH_CR_PRIVN_MASK);\n\t\t}\n\n\t\tHASH_INITIALIZE;\n\n\t\tif (ctx->config.oper_mode == HASH_OPER_MODE_HMAC)\n\t\t\thash_hw_write_key(device_data, ctx->key, ctx->keylen);\n\n\t\t/* Number of bits in last word = (nbytes * 8) % 32 */\n\t\tHASH_SET_NBLW((req->nbytes * 8) % 32);\n\t\treq_ctx->updated = 1;\n\t}\n\n\t/* Store the nents in the dma struct. */\n\tctx->device->dma.nents = hash_get_nents(req->src, req->nbytes, NULL);\n\tif (!ctx->device->dma.nents) {\n\t\tdev_err(device_data->dev, \"%s: ctx->device->dma.nents = 0\\n\",\n\t\t\t__func__);\n\t\tret = ctx->device->dma.nents;\n\t\tgoto out;\n\t}\n\n\tbytes_written = hash_dma_write(ctx, req->src, req->nbytes);\n\tif (bytes_written != req->nbytes) {\n\t\tdev_err(device_data->dev, \"%s: hash_dma_write() failed!\\n\",\n\t\t\t__func__);\n\t\tret = bytes_written;\n\t\tgoto out;\n\t}\n\n\twait_for_completion(&ctx->device->dma.complete);\n\thash_dma_done(ctx);\n\n\twhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\n\t\tcpu_relax();\n\n\tif (ctx->config.oper_mode == HASH_OPER_MODE_HMAC && ctx->key) {\n\t\tunsigned int keylen = ctx->keylen;\n\t\tu8 *key = ctx->key;\n\n\t\tdev_dbg(device_data->dev, \"%s: keylen: %d\\n\",\n\t\t\t__func__, ctx->keylen);\n\t\thash_hw_write_key(device_data, key, keylen);\n\t}\n\n\thash_get_digest(device_data, digest, ctx->config.algorithm);\n\tmemcpy(req->result, digest, ctx->digestsize);\n\nout:\n\trelease_hash_device(device_data);\n\n\t/**\n\t * Allocated in setkey, and only used in HMAC.\n\t */\n\tkfree(ctx->key);\n\n\treturn ret;\n}\n\n/**\n * hash_hw_final - The final hash calculation function\n * @req:\tThe hash request for the job.\n */\nstatic int hash_hw_final(struct ahash_request *req)\n{\n\tint ret = 0;\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\n\tstruct hash_req_ctx *req_ctx = ahash_request_ctx(req);\n\tstruct hash_device_data *device_data;\n\tu8 digest[SHA256_DIGEST_SIZE];\n\n\tret = hash_get_device_data(ctx, &device_data);\n\tif (ret)\n\t\treturn ret;\n\n\tdev_dbg(device_data->dev, \"%s: (ctx=0x%x)!\\n\", __func__, (u32) ctx);\n\n\tif (req_ctx->updated) {\n\t\tret = hash_resume_state(device_data, &device_data->state);\n\n\t\tif (ret) {\n\t\t\tdev_err(device_data->dev,\n\t\t\t\t\"%s: hash_resume_state() failed!\\n\", __func__);\n\t\t\tgoto out;\n\t\t}\n\t} else if (req->nbytes == 0 && ctx->keylen == 0) {\n\t\tu8 zero_hash[SHA256_DIGEST_SIZE];\n\t\tu32 zero_hash_size = 0;\n\t\tbool zero_digest = false;\n\t\t/**\n\t\t * Use a pre-calculated empty message digest\n\t\t * (workaround since hw return zeroes, hw bug!?)\n\t\t */\n\t\tret = get_empty_message_digest(device_data, &zero_hash[0],\n\t\t\t\t&zero_hash_size, &zero_digest);\n\t\tif (!ret && likely(zero_hash_size == ctx->digestsize) &&\n\t\t    zero_digest) {\n\t\t\tmemcpy(req->result, &zero_hash[0], ctx->digestsize);\n\t\t\tgoto out;\n\t\t} else if (!ret && !zero_digest) {\n\t\t\tdev_dbg(device_data->dev,\n\t\t\t\t\"%s: HMAC zero msg with key, continue...\\n\",\n\t\t\t\t__func__);\n\t\t} else {\n\t\t\tdev_err(device_data->dev,\n\t\t\t\t\"%s: ret=%d, or wrong digest size? %s\\n\",\n\t\t\t\t__func__, ret,\n\t\t\t\tzero_hash_size == ctx->digestsize ?\n\t\t\t\t\"true\" : \"false\");\n\t\t\t/* Return error */\n\t\t\tgoto out;\n\t\t}\n\t} else if (req->nbytes == 0 && ctx->keylen > 0) {\n\t\tdev_err(device_data->dev, \"%s: Empty message with keylength > 0, NOT supported\\n\",\n\t\t\t__func__);\n\t\tgoto out;\n\t}\n\n\tif (!req_ctx->updated) {\n\t\tret = init_hash_hw(device_data, ctx);\n\t\tif (ret) {\n\t\t\tdev_err(device_data->dev,\n\t\t\t\t\"%s: init_hash_hw() failed!\\n\", __func__);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (req_ctx->state.index) {\n\t\thash_messagepad(device_data, req_ctx->state.buffer,\n\t\t\t\treq_ctx->state.index);\n\t} else {\n\t\tHASH_SET_DCAL;\n\t\twhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\n\t\t\tcpu_relax();\n\t}\n\n\tif (ctx->config.oper_mode == HASH_OPER_MODE_HMAC && ctx->key) {\n\t\tunsigned int keylen = ctx->keylen;\n\t\tu8 *key = ctx->key;\n\n\t\tdev_dbg(device_data->dev, \"%s: keylen: %d\\n\",\n\t\t\t__func__, ctx->keylen);\n\t\thash_hw_write_key(device_data, key, keylen);\n\t}\n\n\thash_get_digest(device_data, digest, ctx->config.algorithm);\n\tmemcpy(req->result, digest, ctx->digestsize);\n\nout:\n\trelease_hash_device(device_data);\n\n\t/**\n\t * Allocated in setkey, and only used in HMAC.\n\t */\n\tkfree(ctx->key);\n\n\treturn ret;\n}\n\n/**\n * hash_hw_update - Updates current HASH computation hashing another part of\n *                  the message.\n * @req:\tByte array containing the message to be hashed (caller\n *\t\tallocated).\n */\nint hash_hw_update(struct ahash_request *req)\n{\n\tint ret = 0;\n\tu8 index = 0;\n\tu8 *buffer;\n\tstruct hash_device_data *device_data;\n\tu8 *data_buffer;\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\n\tstruct hash_req_ctx *req_ctx = ahash_request_ctx(req);\n\tstruct crypto_hash_walk walk;\n\tint msg_length = crypto_hash_walk_first(req, &walk);\n\n\t/* Empty message (\"\") is correct indata */\n\tif (msg_length == 0)\n\t\treturn ret;\n\n\tindex = req_ctx->state.index;\n\tbuffer = (u8 *)req_ctx->state.buffer;\n\n\t/* Check if ctx->state.length + msg_length\n\t   overflows */\n\tif (msg_length > (req_ctx->state.length.low_word + msg_length) &&\n\t    HASH_HIGH_WORD_MAX_VAL == req_ctx->state.length.high_word) {\n\t\tpr_err(\"%s: HASH_MSG_LENGTH_OVERFLOW!\\n\", __func__);\n\t\treturn -EPERM;\n\t}\n\n\tret = hash_get_device_data(ctx, &device_data);\n\tif (ret)\n\t\treturn ret;\n\n\t/* Main loop */\n\twhile (0 != msg_length) {\n\t\tdata_buffer = walk.data;\n\t\tret = hash_process_data(device_data, ctx, req_ctx, msg_length,\n\t\t\t\tdata_buffer, buffer, &index);\n\n\t\tif (ret) {\n\t\t\tdev_err(device_data->dev, \"%s: hash_internal_hw_update() failed!\\n\",\n\t\t\t\t__func__);\n\t\t\tgoto out;\n\t\t}\n\n\t\tmsg_length = crypto_hash_walk_done(&walk, 0);\n\t}\n\n\treq_ctx->state.index = index;\n\tdev_dbg(device_data->dev, \"%s: indata length=%d, bin=%d\\n\",\n\t\t__func__, req_ctx->state.index, req_ctx->state.bit_index);\n\nout:\n\trelease_hash_device(device_data);\n\n\treturn ret;\n}\n\n/**\n * hash_resume_state - Function that resumes the state of an calculation.\n * @device_data:\tPointer to the device structure.\n * @device_state:\tThe state to be restored in the hash hardware\n */\nint hash_resume_state(struct hash_device_data *device_data,\n\t\t      const struct hash_state *device_state)\n{\n\tu32 temp_cr;\n\ts32 count;\n\tint hash_mode = HASH_OPER_MODE_HASH;\n\n\tif (NULL == device_state) {\n\t\tdev_err(device_data->dev, \"%s: HASH_INVALID_PARAMETER!\\n\",\n\t\t\t__func__);\n\t\treturn -EPERM;\n\t}\n\n\t/* Check correctness of index and length members */\n\tif (device_state->index > HASH_BLOCK_SIZE ||\n\t    (device_state->length.low_word % HASH_BLOCK_SIZE) != 0) {\n\t\tdev_err(device_data->dev, \"%s: HASH_INVALID_PARAMETER!\\n\",\n\t\t\t__func__);\n\t\treturn -EPERM;\n\t}\n\n\t/*\n\t * INIT bit. Set this bit to 0b1 to reset the HASH processor core and\n\t * prepare the initialize the HASH accelerator to compute the message\n\t * digest of a new message.\n\t */\n\tHASH_INITIALIZE;\n\n\ttemp_cr = device_state->temp_cr;\n\twritel_relaxed(temp_cr & HASH_CR_RESUME_MASK, &device_data->base->cr);\n\n\tif (readl(&device_data->base->cr) & HASH_CR_MODE_MASK)\n\t\thash_mode = HASH_OPER_MODE_HMAC;\n\telse\n\t\thash_mode = HASH_OPER_MODE_HASH;\n\n\tfor (count = 0; count < HASH_CSR_COUNT; count++) {\n\t\tif ((count >= 36) && (hash_mode == HASH_OPER_MODE_HASH))\n\t\t\tbreak;\n\n\t\twritel_relaxed(device_state->csr[count],\n\t\t\t       &device_data->base->csrx[count]);\n\t}\n\n\twritel_relaxed(device_state->csfull, &device_data->base->csfull);\n\twritel_relaxed(device_state->csdatain, &device_data->base->csdatain);\n\n\twritel_relaxed(device_state->str_reg, &device_data->base->str);\n\twritel_relaxed(temp_cr, &device_data->base->cr);\n\n\treturn 0;\n}\n\n/**\n * hash_save_state - Function that saves the state of hardware.\n * @device_data:\tPointer to the device structure.\n * @device_state:\tThe strucure where the hardware state should be saved.\n */\nint hash_save_state(struct hash_device_data *device_data,\n\t\t    struct hash_state *device_state)\n{\n\tu32 temp_cr;\n\tu32 count;\n\tint hash_mode = HASH_OPER_MODE_HASH;\n\n\tif (NULL == device_state) {\n\t\tdev_err(device_data->dev, \"%s: HASH_INVALID_PARAMETER!\\n\",\n\t\t\t__func__);\n\t\treturn -ENOTSUPP;\n\t}\n\n\t/* Write dummy value to force digest intermediate calculation. This\n\t * actually makes sure that there isn't any ongoing calculation in the\n\t * hardware.\n\t */\n\twhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\n\t\tcpu_relax();\n\n\ttemp_cr = readl_relaxed(&device_data->base->cr);\n\n\tdevice_state->str_reg = readl_relaxed(&device_data->base->str);\n\n\tdevice_state->din_reg = readl_relaxed(&device_data->base->din);\n\n\tif (readl(&device_data->base->cr) & HASH_CR_MODE_MASK)\n\t\thash_mode = HASH_OPER_MODE_HMAC;\n\telse\n\t\thash_mode = HASH_OPER_MODE_HASH;\n\n\tfor (count = 0; count < HASH_CSR_COUNT; count++) {\n\t\tif ((count >= 36) && (hash_mode == HASH_OPER_MODE_HASH))\n\t\t\tbreak;\n\n\t\tdevice_state->csr[count] =\n\t\t\treadl_relaxed(&device_data->base->csrx[count]);\n\t}\n\n\tdevice_state->csfull = readl_relaxed(&device_data->base->csfull);\n\tdevice_state->csdatain = readl_relaxed(&device_data->base->csdatain);\n\n\tdevice_state->temp_cr = temp_cr;\n\n\treturn 0;\n}\n\n/**\n * hash_check_hw - This routine checks for peripheral Ids and PCell Ids.\n * @device_data:\n *\n */\nint hash_check_hw(struct hash_device_data *device_data)\n{\n\t/* Checking Peripheral Ids  */\n\tif (HASH_P_ID0 == readl_relaxed(&device_data->base->periphid0) &&\n\t    HASH_P_ID1 == readl_relaxed(&device_data->base->periphid1) &&\n\t    HASH_P_ID2 == readl_relaxed(&device_data->base->periphid2) &&\n\t    HASH_P_ID3 == readl_relaxed(&device_data->base->periphid3) &&\n\t    HASH_CELL_ID0 == readl_relaxed(&device_data->base->cellid0) &&\n\t    HASH_CELL_ID1 == readl_relaxed(&device_data->base->cellid1) &&\n\t    HASH_CELL_ID2 == readl_relaxed(&device_data->base->cellid2) &&\n\t    HASH_CELL_ID3 == readl_relaxed(&device_data->base->cellid3)) {\n\t\treturn 0;\n\t}\n\n\tdev_err(device_data->dev, \"%s: HASH_UNSUPPORTED_HW!\\n\", __func__);\n\treturn -ENOTSUPP;\n}\n\n/**\n * hash_get_digest - Gets the digest.\n * @device_data:\tPointer to the device structure.\n * @digest:\t\tUser allocated byte array for the calculated digest.\n * @algorithm:\t\tThe algorithm in use.\n */\nvoid hash_get_digest(struct hash_device_data *device_data,\n\t\t     u8 *digest, int algorithm)\n{\n\tu32 temp_hx_val, count;\n\tint loop_ctr;\n\n\tif (algorithm != HASH_ALGO_SHA1 && algorithm != HASH_ALGO_SHA256) {\n\t\tdev_err(device_data->dev, \"%s: Incorrect algorithm %d\\n\",\n\t\t\t__func__, algorithm);\n\t\treturn;\n\t}\n\n\tif (algorithm == HASH_ALGO_SHA1)\n\t\tloop_ctr = SHA1_DIGEST_SIZE / sizeof(u32);\n\telse\n\t\tloop_ctr = SHA256_DIGEST_SIZE / sizeof(u32);\n\n\tdev_dbg(device_data->dev, \"%s: digest array:(0x%x)\\n\",\n\t\t__func__, (u32) digest);\n\n\t/* Copy result into digest array */\n\tfor (count = 0; count < loop_ctr; count++) {\n\t\ttemp_hx_val = readl_relaxed(&device_data->base->hx[count]);\n\t\tdigest[count * 4] = (u8) ((temp_hx_val >> 24) & 0xFF);\n\t\tdigest[count * 4 + 1] = (u8) ((temp_hx_val >> 16) & 0xFF);\n\t\tdigest[count * 4 + 2] = (u8) ((temp_hx_val >> 8) & 0xFF);\n\t\tdigest[count * 4 + 3] = (u8) ((temp_hx_val >> 0) & 0xFF);\n\t}\n}\n\n/**\n * hash_update - The hash update function for SHA1/SHA2 (SHA256).\n * @req: The hash request for the job.\n */\nstatic int ahash_update(struct ahash_request *req)\n{\n\tint ret = 0;\n\tstruct hash_req_ctx *req_ctx = ahash_request_ctx(req);\n\n\tif (hash_mode != HASH_MODE_DMA || !req_ctx->dma_mode)\n\t\tret = hash_hw_update(req);\n\t/* Skip update for DMA, all data will be passed to DMA in final */\n\n\tif (ret) {\n\t\tpr_err(\"%s: hash_hw_update() failed!\\n\", __func__);\n\t}\n\n\treturn ret;\n}\n\n/**\n * hash_final - The hash final function for SHA1/SHA2 (SHA256).\n * @req:\tThe hash request for the job.\n */\nstatic int ahash_final(struct ahash_request *req)\n{\n\tint ret = 0;\n\tstruct hash_req_ctx *req_ctx = ahash_request_ctx(req);\n\n\tpr_debug(\"%s: data size: %d\\n\", __func__, req->nbytes);\n\n\tif ((hash_mode == HASH_MODE_DMA) && req_ctx->dma_mode)\n\t\tret = hash_dma_final(req);\n\telse\n\t\tret = hash_hw_final(req);\n\n\tif (ret) {\n\t\tpr_err(\"%s: hash_hw/dma_final() failed\\n\", __func__);\n\t}\n\n\treturn ret;\n}\n\nstatic int hash_setkey(struct crypto_ahash *tfm,\n\t\t       const u8 *key, unsigned int keylen, int alg)\n{\n\tint ret = 0;\n\tstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\n\n\t/**\n\t * Freed in final.\n\t */\n\tctx->key = kmemdup(key, keylen, GFP_KERNEL);\n\tif (!ctx->key) {\n\t\tpr_err(\"%s: Failed to allocate ctx->key for %d\\n\",\n\t\t       __func__, alg);\n\t\treturn -ENOMEM;\n\t}\n\tctx->keylen = keylen;\n\n\treturn ret;\n}\n\nstatic int ahash_sha1_init(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\n\n\tctx->config.data_format = HASH_DATA_8_BITS;\n\tctx->config.algorithm = HASH_ALGO_SHA1;\n\tctx->config.oper_mode = HASH_OPER_MODE_HASH;\n\tctx->digestsize = SHA1_DIGEST_SIZE;\n\n\treturn hash_init(req);\n}\n\nstatic int ahash_sha256_init(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\n\n\tctx->config.data_format = HASH_DATA_8_BITS;\n\tctx->config.algorithm = HASH_ALGO_SHA256;\n\tctx->config.oper_mode = HASH_OPER_MODE_HASH;\n\tctx->digestsize = SHA256_DIGEST_SIZE;\n\n\treturn hash_init(req);\n}\n\nstatic int ahash_sha1_digest(struct ahash_request *req)\n{\n\tint ret2, ret1;\n\n\tret1 = ahash_sha1_init(req);\n\tif (ret1)\n\t\tgoto out;\n\n\tret1 = ahash_update(req);\n\tret2 = ahash_final(req);\n\nout:\n\treturn ret1 ? ret1 : ret2;\n}\n\nstatic int ahash_sha256_digest(struct ahash_request *req)\n{\n\tint ret2, ret1;\n\n\tret1 = ahash_sha256_init(req);\n\tif (ret1)\n\t\tgoto out;\n\n\tret1 = ahash_update(req);\n\tret2 = ahash_final(req);\n\nout:\n\treturn ret1 ? ret1 : ret2;\n}\n\nstatic int hmac_sha1_init(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\n\n\tctx->config.data_format\t= HASH_DATA_8_BITS;\n\tctx->config.algorithm\t= HASH_ALGO_SHA1;\n\tctx->config.oper_mode\t= HASH_OPER_MODE_HMAC;\n\tctx->digestsize\t\t= SHA1_DIGEST_SIZE;\n\n\treturn hash_init(req);\n}\n\nstatic int hmac_sha256_init(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\n\n\tctx->config.data_format\t= HASH_DATA_8_BITS;\n\tctx->config.algorithm\t= HASH_ALGO_SHA256;\n\tctx->config.oper_mode\t= HASH_OPER_MODE_HMAC;\n\tctx->digestsize\t\t= SHA256_DIGEST_SIZE;\n\n\treturn hash_init(req);\n}\n\nstatic int hmac_sha1_digest(struct ahash_request *req)\n{\n\tint ret2, ret1;\n\n\tret1 = hmac_sha1_init(req);\n\tif (ret1)\n\t\tgoto out;\n\n\tret1 = ahash_update(req);\n\tret2 = ahash_final(req);\n\nout:\n\treturn ret1 ? ret1 : ret2;\n}\n\nstatic int hmac_sha256_digest(struct ahash_request *req)\n{\n\tint ret2, ret1;\n\n\tret1 = hmac_sha256_init(req);\n\tif (ret1)\n\t\tgoto out;\n\n\tret1 = ahash_update(req);\n\tret2 = ahash_final(req);\n\nout:\n\treturn ret1 ? ret1 : ret2;\n}\n\nstatic int hmac_sha1_setkey(struct crypto_ahash *tfm,\n\t\t\t    const u8 *key, unsigned int keylen)\n{\n\treturn hash_setkey(tfm, key, keylen, HASH_ALGO_SHA1);\n}\n\nstatic int hmac_sha256_setkey(struct crypto_ahash *tfm,\n\t\t\t      const u8 *key, unsigned int keylen)\n{\n\treturn hash_setkey(tfm, key, keylen, HASH_ALGO_SHA256);\n}\n\nstruct hash_algo_template {\n\tstruct hash_config conf;\n\tstruct ahash_alg hash;\n};\n\nstatic int hash_cra_init(struct crypto_tfm *tfm)\n{\n\tstruct hash_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_alg *alg = tfm->__crt_alg;\n\tstruct hash_algo_template *hash_alg;\n\n\thash_alg = container_of(__crypto_ahash_alg(alg),\n\t\t\tstruct hash_algo_template,\n\t\t\thash);\n\n\tcrypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),\n\t\t\t\t sizeof(struct hash_req_ctx));\n\n\tctx->config.data_format = HASH_DATA_8_BITS;\n\tctx->config.algorithm = hash_alg->conf.algorithm;\n\tctx->config.oper_mode = hash_alg->conf.oper_mode;\n\n\tctx->digestsize = hash_alg->hash.halg.digestsize;\n\n\treturn 0;\n}\n\nstatic struct hash_algo_template hash_algs[] = {\n\t{\n\t\t.conf.algorithm = HASH_ALGO_SHA1,\n\t\t.conf.oper_mode = HASH_OPER_MODE_HASH,\n\t\t.hash = {\n\t\t\t.init = hash_init,\n\t\t\t.update = ahash_update,\n\t\t\t.final = ahash_final,\n\t\t\t.digest = ahash_sha1_digest,\n\t\t\t.halg.digestsize = SHA1_DIGEST_SIZE,\n\t\t\t.halg.statesize = sizeof(struct hash_ctx),\n\t\t\t.halg.base = {\n\t\t\t\t.cra_name = \"sha1\",\n\t\t\t\t.cra_driver_name = \"sha1-ux500\",\n\t\t\t\t.cra_flags = (CRYPTO_ALG_TYPE_AHASH |\n\t\t\t\t\t      CRYPTO_ALG_ASYNC),\n\t\t\t\t.cra_blocksize = SHA1_BLOCK_SIZE,\n\t\t\t\t.cra_ctxsize = sizeof(struct hash_ctx),\n\t\t\t\t.cra_init = hash_cra_init,\n\t\t\t\t.cra_module = THIS_MODULE,\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\t.conf.algorithm\t= HASH_ALGO_SHA256,\n\t\t.conf.oper_mode\t= HASH_OPER_MODE_HASH,\n\t\t.hash = {\n\t\t\t.init = hash_init,\n\t\t\t.update\t= ahash_update,\n\t\t\t.final = ahash_final,\n\t\t\t.digest = ahash_sha256_digest,\n\t\t\t.halg.digestsize = SHA256_DIGEST_SIZE,\n\t\t\t.halg.statesize = sizeof(struct hash_ctx),\n\t\t\t.halg.base = {\n\t\t\t\t.cra_name = \"sha256\",\n\t\t\t\t.cra_driver_name = \"sha256-ux500\",\n\t\t\t\t.cra_flags = (CRYPTO_ALG_TYPE_AHASH |\n\t\t\t\t\t      CRYPTO_ALG_ASYNC),\n\t\t\t\t.cra_blocksize = SHA256_BLOCK_SIZE,\n\t\t\t\t.cra_ctxsize = sizeof(struct hash_ctx),\n\t\t\t\t.cra_type = &crypto_ahash_type,\n\t\t\t\t.cra_init = hash_cra_init,\n\t\t\t\t.cra_module = THIS_MODULE,\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\t.conf.algorithm = HASH_ALGO_SHA1,\n\t\t.conf.oper_mode = HASH_OPER_MODE_HMAC,\n\t\t\t.hash = {\n\t\t\t.init = hash_init,\n\t\t\t.update = ahash_update,\n\t\t\t.final = ahash_final,\n\t\t\t.digest = hmac_sha1_digest,\n\t\t\t.setkey = hmac_sha1_setkey,\n\t\t\t.halg.digestsize = SHA1_DIGEST_SIZE,\n\t\t\t.halg.statesize = sizeof(struct hash_ctx),\n\t\t\t.halg.base = {\n\t\t\t\t.cra_name = \"hmac(sha1)\",\n\t\t\t\t.cra_driver_name = \"hmac-sha1-ux500\",\n\t\t\t\t.cra_flags = (CRYPTO_ALG_TYPE_AHASH |\n\t\t\t\t\t      CRYPTO_ALG_ASYNC),\n\t\t\t\t.cra_blocksize = SHA1_BLOCK_SIZE,\n\t\t\t\t.cra_ctxsize = sizeof(struct hash_ctx),\n\t\t\t\t.cra_type = &crypto_ahash_type,\n\t\t\t\t.cra_init = hash_cra_init,\n\t\t\t\t.cra_module = THIS_MODULE,\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\t.conf.algorithm = HASH_ALGO_SHA256,\n\t\t.conf.oper_mode = HASH_OPER_MODE_HMAC,\n\t\t.hash = {\n\t\t\t.init = hash_init,\n\t\t\t.update = ahash_update,\n\t\t\t.final = ahash_final,\n\t\t\t.digest = hmac_sha256_digest,\n\t\t\t.setkey = hmac_sha256_setkey,\n\t\t\t.halg.digestsize = SHA256_DIGEST_SIZE,\n\t\t\t.halg.statesize = sizeof(struct hash_ctx),\n\t\t\t.halg.base = {\n\t\t\t\t.cra_name = \"hmac(sha256)\",\n\t\t\t\t.cra_driver_name = \"hmac-sha256-ux500\",\n\t\t\t\t.cra_flags = (CRYPTO_ALG_TYPE_AHASH |\n\t\t\t\t\t      CRYPTO_ALG_ASYNC),\n\t\t\t\t.cra_blocksize = SHA256_BLOCK_SIZE,\n\t\t\t\t.cra_ctxsize = sizeof(struct hash_ctx),\n\t\t\t\t.cra_type = &crypto_ahash_type,\n\t\t\t\t.cra_init = hash_cra_init,\n\t\t\t\t.cra_module = THIS_MODULE,\n\t\t\t}\n\t\t}\n\t}\n};\n\n/**\n * hash_algs_register_all -\n */\nstatic int ahash_algs_register_all(struct hash_device_data *device_data)\n{\n\tint ret;\n\tint i;\n\tint count;\n\n\tfor (i = 0; i < ARRAY_SIZE(hash_algs); i++) {\n\t\tret = crypto_register_ahash(&hash_algs[i].hash);\n\t\tif (ret) {\n\t\t\tcount = i;\n\t\t\tdev_err(device_data->dev, \"%s: alg registration failed\\n\",\n\t\t\t\thash_algs[i].hash.halg.base.cra_driver_name);\n\t\t\tgoto unreg;\n\t\t}\n\t}\n\treturn 0;\nunreg:\n\tfor (i = 0; i < count; i++)\n\t\tcrypto_unregister_ahash(&hash_algs[i].hash);\n\treturn ret;\n}\n\n/**\n * hash_algs_unregister_all -\n */\nstatic void ahash_algs_unregister_all(struct hash_device_data *device_data)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(hash_algs); i++)\n\t\tcrypto_unregister_ahash(&hash_algs[i].hash);\n}\n\n/**\n * ux500_hash_probe - Function that probes the hash hardware.\n * @pdev: The platform device.\n */\nstatic int ux500_hash_probe(struct platform_device *pdev)\n{\n\tint\t\t\tret = 0;\n\tstruct resource\t\t*res = NULL;\n\tstruct hash_device_data *device_data;\n\tstruct device\t\t*dev = &pdev->dev;\n\n\tdevice_data = kzalloc(sizeof(*device_data), GFP_ATOMIC);\n\tif (!device_data) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tdevice_data->dev = dev;\n\tdevice_data->current_ctx = NULL;\n\n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tif (!res) {\n\t\tdev_dbg(dev, \"%s: platform_get_resource() failed!\\n\", __func__);\n\t\tret = -ENODEV;\n\t\tgoto out_kfree;\n\t}\n\n\tres = request_mem_region(res->start, resource_size(res), pdev->name);\n\tif (res == NULL) {\n\t\tdev_dbg(dev, \"%s: request_mem_region() failed!\\n\", __func__);\n\t\tret = -EBUSY;\n\t\tgoto out_kfree;\n\t}\n\n\tdevice_data->phybase = res->start;\n\tdevice_data->base = ioremap(res->start, resource_size(res));\n\tif (!device_data->base) {\n\t\tdev_err(dev, \"%s: ioremap() failed!\\n\", __func__);\n\t\tret = -ENOMEM;\n\t\tgoto out_free_mem;\n\t}\n\tspin_lock_init(&device_data->ctx_lock);\n\tspin_lock_init(&device_data->power_state_lock);\n\n\t/* Enable power for HASH1 hardware block */\n\tdevice_data->regulator = regulator_get(dev, \"v-ape\");\n\tif (IS_ERR(device_data->regulator)) {\n\t\tdev_err(dev, \"%s: regulator_get() failed!\\n\", __func__);\n\t\tret = PTR_ERR(device_data->regulator);\n\t\tdevice_data->regulator = NULL;\n\t\tgoto out_unmap;\n\t}\n\n\t/* Enable the clock for HASH1 hardware block */\n\tdevice_data->clk = clk_get(dev, NULL);\n\tif (IS_ERR(device_data->clk)) {\n\t\tdev_err(dev, \"%s: clk_get() failed!\\n\", __func__);\n\t\tret = PTR_ERR(device_data->clk);\n\t\tgoto out_regulator;\n\t}\n\n\tret = clk_prepare(device_data->clk);\n\tif (ret) {\n\t\tdev_err(dev, \"%s: clk_prepare() failed!\\n\", __func__);\n\t\tgoto out_clk;\n\t}\n\n\t/* Enable device power (and clock) */\n\tret = hash_enable_power(device_data, false);\n\tif (ret) {\n\t\tdev_err(dev, \"%s: hash_enable_power() failed!\\n\", __func__);\n\t\tgoto out_clk_unprepare;\n\t}\n\n\tret = hash_check_hw(device_data);\n\tif (ret) {\n\t\tdev_err(dev, \"%s: hash_check_hw() failed!\\n\", __func__);\n\t\tgoto out_power;\n\t}\n\n\tif (hash_mode == HASH_MODE_DMA)\n\t\thash_dma_setup_channel(device_data, dev);\n\n\tplatform_set_drvdata(pdev, device_data);\n\n\t/* Put the new device into the device list... */\n\tklist_add_tail(&device_data->list_node, &driver_data.device_list);\n\t/* ... and signal that a new device is available. */\n\tup(&driver_data.device_allocation);\n\n\tret = ahash_algs_register_all(device_data);\n\tif (ret) {\n\t\tdev_err(dev, \"%s: ahash_algs_register_all() failed!\\n\",\n\t\t\t__func__);\n\t\tgoto out_power;\n\t}\n\n\tdev_info(dev, \"successfully registered\\n\");\n\treturn 0;\n\nout_power:\n\thash_disable_power(device_data, false);\n\nout_clk_unprepare:\n\tclk_unprepare(device_data->clk);\n\nout_clk:\n\tclk_put(device_data->clk);\n\nout_regulator:\n\tregulator_put(device_data->regulator);\n\nout_unmap:\n\tiounmap(device_data->base);\n\nout_free_mem:\n\trelease_mem_region(res->start, resource_size(res));\n\nout_kfree:\n\tkfree(device_data);\nout:\n\treturn ret;\n}\n\n/**\n * ux500_hash_remove - Function that removes the hash device from the platform.\n * @pdev: The platform device.\n */\nstatic int ux500_hash_remove(struct platform_device *pdev)\n{\n\tstruct resource\t\t*res;\n\tstruct hash_device_data *device_data;\n\tstruct device\t\t*dev = &pdev->dev;\n\n\tdevice_data = platform_get_drvdata(pdev);\n\tif (!device_data) {\n\t\tdev_err(dev, \"%s: platform_get_drvdata() failed!\\n\", __func__);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* Try to decrease the number of available devices. */\n\tif (down_trylock(&driver_data.device_allocation))\n\t\treturn -EBUSY;\n\n\t/* Check that the device is free */\n\tspin_lock(&device_data->ctx_lock);\n\t/* current_ctx allocates a device, NULL = unallocated */\n\tif (device_data->current_ctx) {\n\t\t/* The device is busy */\n\t\tspin_unlock(&device_data->ctx_lock);\n\t\t/* Return the device to the pool. */\n\t\tup(&driver_data.device_allocation);\n\t\treturn -EBUSY;\n\t}\n\n\tspin_unlock(&device_data->ctx_lock);\n\n\t/* Remove the device from the list */\n\tif (klist_node_attached(&device_data->list_node))\n\t\tklist_remove(&device_data->list_node);\n\n\t/* If this was the last device, remove the services */\n\tif (list_empty(&driver_data.device_list.k_list))\n\t\tahash_algs_unregister_all(device_data);\n\n\tif (hash_disable_power(device_data, false))\n\t\tdev_err(dev, \"%s: hash_disable_power() failed\\n\",\n\t\t\t__func__);\n\n\tclk_unprepare(device_data->clk);\n\tclk_put(device_data->clk);\n\tregulator_put(device_data->regulator);\n\n\tiounmap(device_data->base);\n\n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tif (res)\n\t\trelease_mem_region(res->start, resource_size(res));\n\n\tkfree(device_data);\n\n\treturn 0;\n}\n\n/**\n * ux500_hash_shutdown - Function that shutdown the hash device.\n * @pdev: The platform device\n */\nstatic void ux500_hash_shutdown(struct platform_device *pdev)\n{\n\tstruct resource *res = NULL;\n\tstruct hash_device_data *device_data;\n\n\tdevice_data = platform_get_drvdata(pdev);\n\tif (!device_data) {\n\t\tdev_err(&pdev->dev, \"%s: platform_get_drvdata() failed!\\n\",\n\t\t\t__func__);\n\t\treturn;\n\t}\n\n\t/* Check that the device is free */\n\tspin_lock(&device_data->ctx_lock);\n\t/* current_ctx allocates a device, NULL = unallocated */\n\tif (!device_data->current_ctx) {\n\t\tif (down_trylock(&driver_data.device_allocation))\n\t\t\tdev_dbg(&pdev->dev, \"%s: Cryp still in use! Shutting down anyway...\\n\",\n\t\t\t\t__func__);\n\t\t/**\n\t\t * (Allocate the device)\n\t\t * Need to set this to non-null (dummy) value,\n\t\t * to avoid usage if context switching.\n\t\t */\n\t\tdevice_data->current_ctx++;\n\t}\n\tspin_unlock(&device_data->ctx_lock);\n\n\t/* Remove the device from the list */\n\tif (klist_node_attached(&device_data->list_node))\n\t\tklist_remove(&device_data->list_node);\n\n\t/* If this was the last device, remove the services */\n\tif (list_empty(&driver_data.device_list.k_list))\n\t\tahash_algs_unregister_all(device_data);\n\n\tiounmap(device_data->base);\n\n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tif (res)\n\t\trelease_mem_region(res->start, resource_size(res));\n\n\tif (hash_disable_power(device_data, false))\n\t\tdev_err(&pdev->dev, \"%s: hash_disable_power() failed\\n\",\n\t\t\t__func__);\n}\n\n#ifdef CONFIG_PM_SLEEP\n/**\n * ux500_hash_suspend - Function that suspends the hash device.\n * @dev:\tDevice to suspend.\n */\nstatic int ux500_hash_suspend(struct device *dev)\n{\n\tint ret;\n\tstruct hash_device_data *device_data;\n\tstruct hash_ctx *temp_ctx = NULL;\n\n\tdevice_data = dev_get_drvdata(dev);\n\tif (!device_data) {\n\t\tdev_err(dev, \"%s: platform_get_drvdata() failed!\\n\", __func__);\n\t\treturn -ENOMEM;\n\t}\n\n\tspin_lock(&device_data->ctx_lock);\n\tif (!device_data->current_ctx)\n\t\tdevice_data->current_ctx++;\n\tspin_unlock(&device_data->ctx_lock);\n\n\tif (device_data->current_ctx == ++temp_ctx) {\n\t\tif (down_interruptible(&driver_data.device_allocation))\n\t\t\tdev_dbg(dev, \"%s: down_interruptible() failed\\n\",\n\t\t\t\t__func__);\n\t\tret = hash_disable_power(device_data, false);\n\n\t} else {\n\t\tret = hash_disable_power(device_data, true);\n\t}\n\n\tif (ret)\n\t\tdev_err(dev, \"%s: hash_disable_power()\\n\", __func__);\n\n\treturn ret;\n}\n\n/**\n * ux500_hash_resume - Function that resume the hash device.\n * @dev:\tDevice to resume.\n */\nstatic int ux500_hash_resume(struct device *dev)\n{\n\tint ret = 0;\n\tstruct hash_device_data *device_data;\n\tstruct hash_ctx *temp_ctx = NULL;\n\n\tdevice_data = dev_get_drvdata(dev);\n\tif (!device_data) {\n\t\tdev_err(dev, \"%s: platform_get_drvdata() failed!\\n\", __func__);\n\t\treturn -ENOMEM;\n\t}\n\n\tspin_lock(&device_data->ctx_lock);\n\tif (device_data->current_ctx == ++temp_ctx)\n\t\tdevice_data->current_ctx = NULL;\n\tspin_unlock(&device_data->ctx_lock);\n\n\tif (!device_data->current_ctx)\n\t\tup(&driver_data.device_allocation);\n\telse\n\t\tret = hash_enable_power(device_data, true);\n\n\tif (ret)\n\t\tdev_err(dev, \"%s: hash_enable_power() failed!\\n\", __func__);\n\n\treturn ret;\n}\n#endif\n\nstatic SIMPLE_DEV_PM_OPS(ux500_hash_pm, ux500_hash_suspend, ux500_hash_resume);\n\nstatic const struct of_device_id ux500_hash_match[] = {\n\t{ .compatible = \"stericsson,ux500-hash\" },\n\t{ },\n};\n\nstatic struct platform_driver hash_driver = {\n\t.probe  = ux500_hash_probe,\n\t.remove = ux500_hash_remove,\n\t.shutdown = ux500_hash_shutdown,\n\t.driver = {\n\t\t.owner = THIS_MODULE,\n\t\t.name  = \"hash1\",\n\t\t.of_match_table = ux500_hash_match,\n\t\t.pm    = &ux500_hash_pm,\n\t}\n};\n\n/**\n * ux500_hash_mod_init - The kernel module init function.\n */\nstatic int __init ux500_hash_mod_init(void)\n{\n\tklist_init(&driver_data.device_list, NULL, NULL);\n\t/* Initialize the semaphore to 0 devices (locked state) */\n\tsema_init(&driver_data.device_allocation, 0);\n\n\treturn platform_driver_register(&hash_driver);\n}\n\n/**\n * ux500_hash_mod_fini - The kernel module exit function.\n */\nstatic void __exit ux500_hash_mod_fini(void)\n{\n\tplatform_driver_unregister(&hash_driver);\n}\n\nmodule_init(ux500_hash_mod_init);\nmodule_exit(ux500_hash_mod_fini);\n\nMODULE_DESCRIPTION(\"Driver for ST-Ericsson UX500 HASH engine.\");\nMODULE_LICENSE(\"GPL\");\n\nMODULE_ALIAS_CRYPTO(\"sha1-all\");\nMODULE_ALIAS_CRYPTO(\"sha256-all\");\nMODULE_ALIAS_CRYPTO(\"hmac-sha1-all\");\nMODULE_ALIAS_CRYPTO(\"hmac-sha256-all\");\n", "/*\n * Copyright IBM Corp. 2006, 2012\n * Author(s): Cornelia Huck <cornelia.huck@de.ibm.com>\n *\t      Martin Schwidefsky <schwidefsky@de.ibm.com>\n *\t      Ralph Wuerthner <rwuerthn@de.ibm.com>\n *\t      Felix Beck <felix.beck@de.ibm.com>\n *\t      Holger Dengler <hd@linux.vnet.ibm.com>\n *\n * Adjunct processor bus.\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2, or (at your option)\n * any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.\n */\n\n#define KMSG_COMPONENT \"ap\"\n#define pr_fmt(fmt) KMSG_COMPONENT \": \" fmt\n\n#include <linux/kernel_stat.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/delay.h>\n#include <linux/err.h>\n#include <linux/interrupt.h>\n#include <linux/workqueue.h>\n#include <linux/slab.h>\n#include <linux/notifier.h>\n#include <linux/kthread.h>\n#include <linux/mutex.h>\n#include <asm/reset.h>\n#include <asm/airq.h>\n#include <linux/atomic.h>\n#include <asm/isc.h>\n#include <linux/hrtimer.h>\n#include <linux/ktime.h>\n#include <asm/facility.h>\n#include <linux/crypto.h>\n\n#include \"ap_bus.h\"\n\n/* Some prototypes. */\nstatic void ap_scan_bus(struct work_struct *);\nstatic void ap_poll_all(unsigned long);\nstatic enum hrtimer_restart ap_poll_timeout(struct hrtimer *);\nstatic int ap_poll_thread_start(void);\nstatic void ap_poll_thread_stop(void);\nstatic void ap_request_timeout(unsigned long);\nstatic inline void ap_schedule_poll_timer(void);\nstatic int __ap_poll_device(struct ap_device *ap_dev, unsigned long *flags);\nstatic int ap_device_remove(struct device *dev);\nstatic int ap_device_probe(struct device *dev);\nstatic void ap_interrupt_handler(struct airq_struct *airq);\nstatic void ap_reset(struct ap_device *ap_dev);\nstatic void ap_config_timeout(unsigned long ptr);\nstatic int ap_select_domain(void);\nstatic void ap_query_configuration(void);\n\n/*\n * Module description.\n */\nMODULE_AUTHOR(\"IBM Corporation\");\nMODULE_DESCRIPTION(\"Adjunct Processor Bus driver, \" \\\n\t\t   \"Copyright IBM Corp. 2006, 2012\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_CRYPTO(\"z90crypt\");\n\n/*\n * Module parameter\n */\nint ap_domain_index = -1;\t/* Adjunct Processor Domain Index */\nmodule_param_named(domain, ap_domain_index, int, S_IRUSR|S_IRGRP);\nMODULE_PARM_DESC(domain, \"domain index for ap devices\");\nEXPORT_SYMBOL(ap_domain_index);\n\nstatic int ap_thread_flag = 0;\nmodule_param_named(poll_thread, ap_thread_flag, int, S_IRUSR|S_IRGRP);\nMODULE_PARM_DESC(poll_thread, \"Turn on/off poll thread, default is 0 (off).\");\n\nstatic struct device *ap_root_device = NULL;\nstatic struct ap_config_info *ap_configuration;\nstatic DEFINE_SPINLOCK(ap_device_list_lock);\nstatic LIST_HEAD(ap_device_list);\n\n/*\n * Workqueue & timer for bus rescan.\n */\nstatic struct workqueue_struct *ap_work_queue;\nstatic struct timer_list ap_config_timer;\nstatic int ap_config_time = AP_CONFIG_TIME;\nstatic DECLARE_WORK(ap_config_work, ap_scan_bus);\n\n/*\n * Tasklet & timer for AP request polling and interrupts\n */\nstatic DECLARE_TASKLET(ap_tasklet, ap_poll_all, 0);\nstatic atomic_t ap_poll_requests = ATOMIC_INIT(0);\nstatic DECLARE_WAIT_QUEUE_HEAD(ap_poll_wait);\nstatic struct task_struct *ap_poll_kthread = NULL;\nstatic DEFINE_MUTEX(ap_poll_thread_mutex);\nstatic DEFINE_SPINLOCK(ap_poll_timer_lock);\nstatic struct hrtimer ap_poll_timer;\n/* In LPAR poll with 4kHz frequency. Poll every 250000 nanoseconds.\n * If z/VM change to 1500000 nanoseconds to adjust to z/VM polling.*/\nstatic unsigned long long poll_timeout = 250000;\n\n/* Suspend flag */\nstatic int ap_suspend_flag;\n/* Flag to check if domain was set through module parameter domain=. This is\n * important when supsend and resume is done in a z/VM environment where the\n * domain might change. */\nstatic int user_set_domain = 0;\nstatic struct bus_type ap_bus_type;\n\n/* Adapter interrupt definitions */\nstatic int ap_airq_flag;\n\nstatic struct airq_struct ap_airq = {\n\t.handler = ap_interrupt_handler,\n\t.isc = AP_ISC,\n};\n\n/**\n * ap_using_interrupts() - Returns non-zero if interrupt support is\n * available.\n */\nstatic inline int ap_using_interrupts(void)\n{\n\treturn ap_airq_flag;\n}\n\n/**\n * ap_intructions_available() - Test if AP instructions are available.\n *\n * Returns 0 if the AP instructions are installed.\n */\nstatic inline int ap_instructions_available(void)\n{\n\tregister unsigned long reg0 asm (\"0\") = AP_MKQID(0,0);\n\tregister unsigned long reg1 asm (\"1\") = -ENODEV;\n\tregister unsigned long reg2 asm (\"2\") = 0UL;\n\n\tasm volatile(\n\t\t\"   .long 0xb2af0000\\n\"\t\t/* PQAP(TAPQ) */\n\t\t\"0: la    %1,0\\n\"\n\t\t\"1:\\n\"\n\t\tEX_TABLE(0b, 1b)\n\t\t: \"+d\" (reg0), \"+d\" (reg1), \"+d\" (reg2) : : \"cc\" );\n\treturn reg1;\n}\n\n/**\n * ap_interrupts_available(): Test if AP interrupts are available.\n *\n * Returns 1 if AP interrupts are available.\n */\nstatic int ap_interrupts_available(void)\n{\n\treturn test_facility(2) && test_facility(65);\n}\n\n/**\n * ap_configuration_available(): Test if AP configuration\n * information is available.\n *\n * Returns 1 if AP configuration information is available.\n */\n#ifdef CONFIG_64BIT\nstatic int ap_configuration_available(void)\n{\n\treturn test_facility(2) && test_facility(12);\n}\n#endif\n\n/**\n * ap_test_queue(): Test adjunct processor queue.\n * @qid: The AP queue number\n * @queue_depth: Pointer to queue depth value\n * @device_type: Pointer to device type value\n *\n * Returns AP queue status structure.\n */\nstatic inline struct ap_queue_status\nap_test_queue(ap_qid_t qid, int *queue_depth, int *device_type)\n{\n\tregister unsigned long reg0 asm (\"0\") = qid;\n\tregister struct ap_queue_status reg1 asm (\"1\");\n\tregister unsigned long reg2 asm (\"2\") = 0UL;\n\n\tasm volatile(\".long 0xb2af0000\"\t\t/* PQAP(TAPQ) */\n\t\t     : \"+d\" (reg0), \"=d\" (reg1), \"+d\" (reg2) : : \"cc\");\n\t*device_type = (int) (reg2 >> 24);\n\t*queue_depth = (int) (reg2 & 0xff);\n\treturn reg1;\n}\n\n/**\n * ap_reset_queue(): Reset adjunct processor queue.\n * @qid: The AP queue number\n *\n * Returns AP queue status structure.\n */\nstatic inline struct ap_queue_status ap_reset_queue(ap_qid_t qid)\n{\n\tregister unsigned long reg0 asm (\"0\") = qid | 0x01000000UL;\n\tregister struct ap_queue_status reg1 asm (\"1\");\n\tregister unsigned long reg2 asm (\"2\") = 0UL;\n\n\tasm volatile(\n\t\t\".long 0xb2af0000\"\t\t/* PQAP(RAPQ) */\n\t\t: \"+d\" (reg0), \"=d\" (reg1), \"+d\" (reg2) : : \"cc\");\n\treturn reg1;\n}\n\n#ifdef CONFIG_64BIT\n/**\n * ap_queue_interruption_control(): Enable interruption for a specific AP.\n * @qid: The AP queue number\n * @ind: The notification indicator byte\n *\n * Returns AP queue status.\n */\nstatic inline struct ap_queue_status\nap_queue_interruption_control(ap_qid_t qid, void *ind)\n{\n\tregister unsigned long reg0 asm (\"0\") = qid | 0x03000000UL;\n\tregister unsigned long reg1_in asm (\"1\") = 0x0000800000000000UL | AP_ISC;\n\tregister struct ap_queue_status reg1_out asm (\"1\");\n\tregister void *reg2 asm (\"2\") = ind;\n\tasm volatile(\n\t\t\".long 0xb2af0000\"\t\t/* PQAP(AQIC) */\n\t\t: \"+d\" (reg0), \"+d\" (reg1_in), \"=d\" (reg1_out), \"+d\" (reg2)\n\t\t:\n\t\t: \"cc\" );\n\treturn reg1_out;\n}\n#endif\n\n#ifdef CONFIG_64BIT\nstatic inline struct ap_queue_status\n__ap_query_functions(ap_qid_t qid, unsigned int *functions)\n{\n\tregister unsigned long reg0 asm (\"0\") = 0UL | qid | (1UL << 23);\n\tregister struct ap_queue_status reg1 asm (\"1\") = AP_QUEUE_STATUS_INVALID;\n\tregister unsigned long reg2 asm (\"2\");\n\n\tasm volatile(\n\t\t\".long 0xb2af0000\\n\"\t\t/* PQAP(TAPQ) */\n\t\t\"0:\\n\"\n\t\tEX_TABLE(0b, 0b)\n\t\t: \"+d\" (reg0), \"+d\" (reg1), \"=d\" (reg2)\n\t\t:\n\t\t: \"cc\");\n\n\t*functions = (unsigned int)(reg2 >> 32);\n\treturn reg1;\n}\n#endif\n\n#ifdef CONFIG_64BIT\nstatic inline int __ap_query_configuration(struct ap_config_info *config)\n{\n\tregister unsigned long reg0 asm (\"0\") = 0x04000000UL;\n\tregister unsigned long reg1 asm (\"1\") = -EINVAL;\n\tregister unsigned char *reg2 asm (\"2\") = (unsigned char *)config;\n\n\tasm volatile(\n\t\t\".long 0xb2af0000\\n\"\t\t/* PQAP(QCI) */\n\t\t\"0: la    %1,0\\n\"\n\t\t\"1:\\n\"\n\t\tEX_TABLE(0b, 1b)\n\t\t: \"+d\" (reg0), \"+d\" (reg1), \"+d\" (reg2)\n\t\t:\n\t\t: \"cc\");\n\n\treturn reg1;\n}\n#endif\n\n/**\n * ap_query_functions(): Query supported functions.\n * @qid: The AP queue number\n * @functions: Pointer to functions field.\n *\n * Returns\n *   0\t     on success.\n *   -ENODEV  if queue not valid.\n *   -EBUSY   if device busy.\n *   -EINVAL  if query function is not supported\n */\nstatic int ap_query_functions(ap_qid_t qid, unsigned int *functions)\n{\n#ifdef CONFIG_64BIT\n\tstruct ap_queue_status status;\n\tint i;\n\tstatus = __ap_query_functions(qid, functions);\n\n\tfor (i = 0; i < AP_MAX_RESET; i++) {\n\t\tif (ap_queue_status_invalid_test(&status))\n\t\t\treturn -ENODEV;\n\n\t\tswitch (status.response_code) {\n\t\tcase AP_RESPONSE_NORMAL:\n\t\t\treturn 0;\n\t\tcase AP_RESPONSE_RESET_IN_PROGRESS:\n\t\tcase AP_RESPONSE_BUSY:\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_Q_NOT_AVAIL:\n\t\tcase AP_RESPONSE_DECONFIGURED:\n\t\tcase AP_RESPONSE_CHECKSTOPPED:\n\t\tcase AP_RESPONSE_INVALID_ADDRESS:\n\t\t\treturn -ENODEV;\n\t\tcase AP_RESPONSE_OTHERWISE_CHANGED:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\tif (i < AP_MAX_RESET - 1) {\n\t\t\tudelay(5);\n\t\t\tstatus = __ap_query_functions(qid, functions);\n\t\t}\n\t}\n\treturn -EBUSY;\n#else\n\treturn -EINVAL;\n#endif\n}\n\n/**\n * ap_queue_enable_interruption(): Enable interruption on an AP.\n * @qid: The AP queue number\n * @ind: the notification indicator byte\n *\n * Enables interruption on AP queue via ap_queue_interruption_control(). Based\n * on the return value it waits a while and tests the AP queue if interrupts\n * have been switched on using ap_test_queue().\n */\nstatic int ap_queue_enable_interruption(ap_qid_t qid, void *ind)\n{\n#ifdef CONFIG_64BIT\n\tstruct ap_queue_status status;\n\tint t_depth, t_device_type, rc, i;\n\n\trc = -EBUSY;\n\tstatus = ap_queue_interruption_control(qid, ind);\n\n\tfor (i = 0; i < AP_MAX_RESET; i++) {\n\t\tswitch (status.response_code) {\n\t\tcase AP_RESPONSE_NORMAL:\n\t\t\tif (status.int_enabled)\n\t\t\t\treturn 0;\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_RESET_IN_PROGRESS:\n\t\tcase AP_RESPONSE_BUSY:\n\t\t\tif (i < AP_MAX_RESET - 1) {\n\t\t\t\tudelay(5);\n\t\t\t\tstatus = ap_queue_interruption_control(qid,\n\t\t\t\t\t\t\t\t       ind);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_Q_NOT_AVAIL:\n\t\tcase AP_RESPONSE_DECONFIGURED:\n\t\tcase AP_RESPONSE_CHECKSTOPPED:\n\t\tcase AP_RESPONSE_INVALID_ADDRESS:\n\t\t\treturn -ENODEV;\n\t\tcase AP_RESPONSE_OTHERWISE_CHANGED:\n\t\t\tif (status.int_enabled)\n\t\t\t\treturn 0;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\tif (i < AP_MAX_RESET - 1) {\n\t\t\tudelay(5);\n\t\t\tstatus = ap_test_queue(qid, &t_depth, &t_device_type);\n\t\t}\n\t}\n\treturn rc;\n#else\n\treturn -EINVAL;\n#endif\n}\n\n/**\n * __ap_send(): Send message to adjunct processor queue.\n * @qid: The AP queue number\n * @psmid: The program supplied message identifier\n * @msg: The message text\n * @length: The message length\n * @special: Special Bit\n *\n * Returns AP queue status structure.\n * Condition code 1 on NQAP can't happen because the L bit is 1.\n * Condition code 2 on NQAP also means the send is incomplete,\n * because a segment boundary was reached. The NQAP is repeated.\n */\nstatic inline struct ap_queue_status\n__ap_send(ap_qid_t qid, unsigned long long psmid, void *msg, size_t length,\n\t  unsigned int special)\n{\n\ttypedef struct { char _[length]; } msgblock;\n\tregister unsigned long reg0 asm (\"0\") = qid | 0x40000000UL;\n\tregister struct ap_queue_status reg1 asm (\"1\");\n\tregister unsigned long reg2 asm (\"2\") = (unsigned long) msg;\n\tregister unsigned long reg3 asm (\"3\") = (unsigned long) length;\n\tregister unsigned long reg4 asm (\"4\") = (unsigned int) (psmid >> 32);\n\tregister unsigned long reg5 asm (\"5\") = psmid & 0xffffffff;\n\n\tif (special == 1)\n\t\treg0 |= 0x400000UL;\n\n\tasm volatile (\n\t\t\"0: .long 0xb2ad0042\\n\"\t\t/* NQAP */\n\t\t\"   brc   2,0b\"\n\t\t: \"+d\" (reg0), \"=d\" (reg1), \"+d\" (reg2), \"+d\" (reg3)\n\t\t: \"d\" (reg4), \"d\" (reg5), \"m\" (*(msgblock *) msg)\n\t\t: \"cc\" );\n\treturn reg1;\n}\n\nint ap_send(ap_qid_t qid, unsigned long long psmid, void *msg, size_t length)\n{\n\tstruct ap_queue_status status;\n\n\tstatus = __ap_send(qid, psmid, msg, length, 0);\n\tswitch (status.response_code) {\n\tcase AP_RESPONSE_NORMAL:\n\t\treturn 0;\n\tcase AP_RESPONSE_Q_FULL:\n\tcase AP_RESPONSE_RESET_IN_PROGRESS:\n\t\treturn -EBUSY;\n\tcase AP_RESPONSE_REQ_FAC_NOT_INST:\n\t\treturn -EINVAL;\n\tdefault:\t/* Device is gone. */\n\t\treturn -ENODEV;\n\t}\n}\nEXPORT_SYMBOL(ap_send);\n\n/**\n * __ap_recv(): Receive message from adjunct processor queue.\n * @qid: The AP queue number\n * @psmid: Pointer to program supplied message identifier\n * @msg: The message text\n * @length: The message length\n *\n * Returns AP queue status structure.\n * Condition code 1 on DQAP means the receive has taken place\n * but only partially.\tThe response is incomplete, hence the\n * DQAP is repeated.\n * Condition code 2 on DQAP also means the receive is incomplete,\n * this time because a segment boundary was reached. Again, the\n * DQAP is repeated.\n * Note that gpr2 is used by the DQAP instruction to keep track of\n * any 'residual' length, in case the instruction gets interrupted.\n * Hence it gets zeroed before the instruction.\n */\nstatic inline struct ap_queue_status\n__ap_recv(ap_qid_t qid, unsigned long long *psmid, void *msg, size_t length)\n{\n\ttypedef struct { char _[length]; } msgblock;\n\tregister unsigned long reg0 asm(\"0\") = qid | 0x80000000UL;\n\tregister struct ap_queue_status reg1 asm (\"1\");\n\tregister unsigned long reg2 asm(\"2\") = 0UL;\n\tregister unsigned long reg4 asm(\"4\") = (unsigned long) msg;\n\tregister unsigned long reg5 asm(\"5\") = (unsigned long) length;\n\tregister unsigned long reg6 asm(\"6\") = 0UL;\n\tregister unsigned long reg7 asm(\"7\") = 0UL;\n\n\n\tasm volatile(\n\t\t\"0: .long 0xb2ae0064\\n\"\t\t/* DQAP */\n\t\t\"   brc   6,0b\\n\"\n\t\t: \"+d\" (reg0), \"=d\" (reg1), \"+d\" (reg2),\n\t\t\"+d\" (reg4), \"+d\" (reg5), \"+d\" (reg6), \"+d\" (reg7),\n\t\t\"=m\" (*(msgblock *) msg) : : \"cc\" );\n\t*psmid = (((unsigned long long) reg6) << 32) + reg7;\n\treturn reg1;\n}\n\nint ap_recv(ap_qid_t qid, unsigned long long *psmid, void *msg, size_t length)\n{\n\tstruct ap_queue_status status;\n\n\tstatus = __ap_recv(qid, psmid, msg, length);\n\tswitch (status.response_code) {\n\tcase AP_RESPONSE_NORMAL:\n\t\treturn 0;\n\tcase AP_RESPONSE_NO_PENDING_REPLY:\n\t\tif (status.queue_empty)\n\t\t\treturn -ENOENT;\n\t\treturn -EBUSY;\n\tcase AP_RESPONSE_RESET_IN_PROGRESS:\n\t\treturn -EBUSY;\n\tdefault:\n\t\treturn -ENODEV;\n\t}\n}\nEXPORT_SYMBOL(ap_recv);\n\n/**\n * ap_query_queue(): Check if an AP queue is available.\n * @qid: The AP queue number\n * @queue_depth: Pointer to queue depth value\n * @device_type: Pointer to device type value\n *\n * The test is repeated for AP_MAX_RESET times.\n */\nstatic int ap_query_queue(ap_qid_t qid, int *queue_depth, int *device_type)\n{\n\tstruct ap_queue_status status;\n\tint t_depth, t_device_type, rc, i;\n\n\trc = -EBUSY;\n\tfor (i = 0; i < AP_MAX_RESET; i++) {\n\t\tstatus = ap_test_queue(qid, &t_depth, &t_device_type);\n\t\tswitch (status.response_code) {\n\t\tcase AP_RESPONSE_NORMAL:\n\t\t\t*queue_depth = t_depth + 1;\n\t\t\t*device_type = t_device_type;\n\t\t\trc = 0;\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_Q_NOT_AVAIL:\n\t\t\trc = -ENODEV;\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_RESET_IN_PROGRESS:\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_DECONFIGURED:\n\t\t\trc = -ENODEV;\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_CHECKSTOPPED:\n\t\t\trc = -ENODEV;\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_INVALID_ADDRESS:\n\t\t\trc = -ENODEV;\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_OTHERWISE_CHANGED:\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_BUSY:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tBUG();\n\t\t}\n\t\tif (rc != -EBUSY)\n\t\t\tbreak;\n\t\tif (i < AP_MAX_RESET - 1)\n\t\t\tudelay(5);\n\t}\n\treturn rc;\n}\n\n/**\n * ap_init_queue(): Reset an AP queue.\n * @qid: The AP queue number\n *\n * Reset an AP queue and wait for it to become available again.\n */\nstatic int ap_init_queue(ap_qid_t qid)\n{\n\tstruct ap_queue_status status;\n\tint rc, dummy, i;\n\n\trc = -ENODEV;\n\tstatus = ap_reset_queue(qid);\n\tfor (i = 0; i < AP_MAX_RESET; i++) {\n\t\tswitch (status.response_code) {\n\t\tcase AP_RESPONSE_NORMAL:\n\t\t\tif (status.queue_empty)\n\t\t\t\trc = 0;\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_Q_NOT_AVAIL:\n\t\tcase AP_RESPONSE_DECONFIGURED:\n\t\tcase AP_RESPONSE_CHECKSTOPPED:\n\t\t\ti = AP_MAX_RESET;\t/* return with -ENODEV */\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_RESET_IN_PROGRESS:\n\t\t\trc = -EBUSY;\n\t\tcase AP_RESPONSE_BUSY:\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\tif (rc != -ENODEV && rc != -EBUSY)\n\t\t\tbreak;\n\t\tif (i < AP_MAX_RESET - 1) {\n\t\t\t/* Time we are waiting until we give up (0.7sec * 90).\n\t\t\t * Since the actual request (in progress) will not\n\t\t\t * interrupted immediately for the reset command,\n\t\t\t * we have to be patient. In worst case we have to\n\t\t\t * wait 60sec + reset time (some msec).\n\t\t\t */\n\t\t\tschedule_timeout(AP_RESET_TIMEOUT);\n\t\t\tstatus = ap_test_queue(qid, &dummy, &dummy);\n\t\t}\n\t}\n\tif (rc == 0 && ap_using_interrupts()) {\n\t\trc = ap_queue_enable_interruption(qid, ap_airq.lsi_ptr);\n\t\t/* If interruption mode is supported by the machine,\n\t\t* but an AP can not be enabled for interruption then\n\t\t* the AP will be discarded.    */\n\t\tif (rc)\n\t\t\tpr_err(\"Registering adapter interrupts for \"\n\t\t\t       \"AP %d failed\\n\", AP_QID_DEVICE(qid));\n\t}\n\treturn rc;\n}\n\n/**\n * ap_increase_queue_count(): Arm request timeout.\n * @ap_dev: Pointer to an AP device.\n *\n * Arm request timeout if an AP device was idle and a new request is submitted.\n */\nstatic void ap_increase_queue_count(struct ap_device *ap_dev)\n{\n\tint timeout = ap_dev->drv->request_timeout;\n\n\tap_dev->queue_count++;\n\tif (ap_dev->queue_count == 1) {\n\t\tmod_timer(&ap_dev->timeout, jiffies + timeout);\n\t\tap_dev->reset = AP_RESET_ARMED;\n\t}\n}\n\n/**\n * ap_decrease_queue_count(): Decrease queue count.\n * @ap_dev: Pointer to an AP device.\n *\n * If AP device is still alive, re-schedule request timeout if there are still\n * pending requests.\n */\nstatic void ap_decrease_queue_count(struct ap_device *ap_dev)\n{\n\tint timeout = ap_dev->drv->request_timeout;\n\n\tap_dev->queue_count--;\n\tif (ap_dev->queue_count > 0)\n\t\tmod_timer(&ap_dev->timeout, jiffies + timeout);\n\telse\n\t\t/*\n\t\t * The timeout timer should to be disabled now - since\n\t\t * del_timer_sync() is very expensive, we just tell via the\n\t\t * reset flag to ignore the pending timeout timer.\n\t\t */\n\t\tap_dev->reset = AP_RESET_IGNORE;\n}\n\n/*\n * AP device related attributes.\n */\nstatic ssize_t ap_hwtype_show(struct device *dev,\n\t\t\t      struct device_attribute *attr, char *buf)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", ap_dev->device_type);\n}\n\nstatic DEVICE_ATTR(hwtype, 0444, ap_hwtype_show, NULL);\n\nstatic ssize_t ap_raw_hwtype_show(struct device *dev,\n\t\t\t      struct device_attribute *attr, char *buf)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", ap_dev->raw_hwtype);\n}\n\nstatic DEVICE_ATTR(raw_hwtype, 0444, ap_raw_hwtype_show, NULL);\n\nstatic ssize_t ap_depth_show(struct device *dev, struct device_attribute *attr,\n\t\t\t     char *buf)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", ap_dev->queue_depth);\n}\n\nstatic DEVICE_ATTR(depth, 0444, ap_depth_show, NULL);\nstatic ssize_t ap_request_count_show(struct device *dev,\n\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t     char *buf)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\tint rc;\n\n\tspin_lock_bh(&ap_dev->lock);\n\trc = snprintf(buf, PAGE_SIZE, \"%d\\n\", ap_dev->total_request_count);\n\tspin_unlock_bh(&ap_dev->lock);\n\treturn rc;\n}\n\nstatic DEVICE_ATTR(request_count, 0444, ap_request_count_show, NULL);\n\nstatic ssize_t ap_requestq_count_show(struct device *dev,\n\t\t\t\t      struct device_attribute *attr, char *buf)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\tint rc;\n\n\tspin_lock_bh(&ap_dev->lock);\n\trc = snprintf(buf, PAGE_SIZE, \"%d\\n\", ap_dev->requestq_count);\n\tspin_unlock_bh(&ap_dev->lock);\n\treturn rc;\n}\n\nstatic DEVICE_ATTR(requestq_count, 0444, ap_requestq_count_show, NULL);\n\nstatic ssize_t ap_pendingq_count_show(struct device *dev,\n\t\t\t\t      struct device_attribute *attr, char *buf)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\tint rc;\n\n\tspin_lock_bh(&ap_dev->lock);\n\trc = snprintf(buf, PAGE_SIZE, \"%d\\n\", ap_dev->pendingq_count);\n\tspin_unlock_bh(&ap_dev->lock);\n\treturn rc;\n}\n\nstatic DEVICE_ATTR(pendingq_count, 0444, ap_pendingq_count_show, NULL);\n\nstatic ssize_t ap_modalias_show(struct device *dev,\n\t\t\t\tstruct device_attribute *attr, char *buf)\n{\n\treturn sprintf(buf, \"ap:t%02X\", to_ap_dev(dev)->device_type);\n}\n\nstatic DEVICE_ATTR(modalias, 0444, ap_modalias_show, NULL);\n\nstatic ssize_t ap_functions_show(struct device *dev,\n\t\t\t\t struct device_attribute *attr, char *buf)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\treturn snprintf(buf, PAGE_SIZE, \"0x%08X\\n\", ap_dev->functions);\n}\n\nstatic DEVICE_ATTR(ap_functions, 0444, ap_functions_show, NULL);\n\nstatic struct attribute *ap_dev_attrs[] = {\n\t&dev_attr_hwtype.attr,\n\t&dev_attr_raw_hwtype.attr,\n\t&dev_attr_depth.attr,\n\t&dev_attr_request_count.attr,\n\t&dev_attr_requestq_count.attr,\n\t&dev_attr_pendingq_count.attr,\n\t&dev_attr_modalias.attr,\n\t&dev_attr_ap_functions.attr,\n\tNULL\n};\nstatic struct attribute_group ap_dev_attr_group = {\n\t.attrs = ap_dev_attrs\n};\n\n/**\n * ap_bus_match()\n * @dev: Pointer to device\n * @drv: Pointer to device_driver\n *\n * AP bus driver registration/unregistration.\n */\nstatic int ap_bus_match(struct device *dev, struct device_driver *drv)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\tstruct ap_driver *ap_drv = to_ap_drv(drv);\n\tstruct ap_device_id *id;\n\n\t/*\n\t * Compare device type of the device with the list of\n\t * supported types of the device_driver.\n\t */\n\tfor (id = ap_drv->ids; id->match_flags; id++) {\n\t\tif ((id->match_flags & AP_DEVICE_ID_MATCH_DEVICE_TYPE) &&\n\t\t    (id->dev_type != ap_dev->device_type))\n\t\t\tcontinue;\n\t\treturn 1;\n\t}\n\treturn 0;\n}\n\n/**\n * ap_uevent(): Uevent function for AP devices.\n * @dev: Pointer to device\n * @env: Pointer to kobj_uevent_env\n *\n * It sets up a single environment variable DEV_TYPE which contains the\n * hardware device type.\n */\nstatic int ap_uevent (struct device *dev, struct kobj_uevent_env *env)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\tint retval = 0;\n\n\tif (!ap_dev)\n\t\treturn -ENODEV;\n\n\t/* Set up DEV_TYPE environment variable. */\n\tretval = add_uevent_var(env, \"DEV_TYPE=%04X\", ap_dev->device_type);\n\tif (retval)\n\t\treturn retval;\n\n\t/* Add MODALIAS= */\n\tretval = add_uevent_var(env, \"MODALIAS=ap:t%02X\", ap_dev->device_type);\n\n\treturn retval;\n}\n\nstatic int ap_bus_suspend(struct device *dev, pm_message_t state)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\tunsigned long flags;\n\n\tif (!ap_suspend_flag) {\n\t\tap_suspend_flag = 1;\n\n\t\t/* Disable scanning for devices, thus we do not want to scan\n\t\t * for them after removing.\n\t\t */\n\t\tdel_timer_sync(&ap_config_timer);\n\t\tif (ap_work_queue != NULL) {\n\t\t\tdestroy_workqueue(ap_work_queue);\n\t\t\tap_work_queue = NULL;\n\t\t}\n\n\t\ttasklet_disable(&ap_tasklet);\n\t}\n\t/* Poll on the device until all requests are finished. */\n\tdo {\n\t\tflags = 0;\n\t\tspin_lock_bh(&ap_dev->lock);\n\t\t__ap_poll_device(ap_dev, &flags);\n\t\tspin_unlock_bh(&ap_dev->lock);\n\t} while ((flags & 1) || (flags & 2));\n\n\tspin_lock_bh(&ap_dev->lock);\n\tap_dev->unregistered = 1;\n\tspin_unlock_bh(&ap_dev->lock);\n\n\treturn 0;\n}\n\nstatic int ap_bus_resume(struct device *dev)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\tint rc;\n\n\tif (ap_suspend_flag) {\n\t\tap_suspend_flag = 0;\n\t\tif (ap_interrupts_available()) {\n\t\t\tif (!ap_using_interrupts()) {\n\t\t\t\trc = register_adapter_interrupt(&ap_airq);\n\t\t\t\tap_airq_flag = (rc == 0);\n\t\t\t}\n\t\t} else {\n\t\t\tif (ap_using_interrupts()) {\n\t\t\t\tunregister_adapter_interrupt(&ap_airq);\n\t\t\t\tap_airq_flag = 0;\n\t\t\t}\n\t\t}\n\t\tap_query_configuration();\n\t\tif (!user_set_domain) {\n\t\t\tap_domain_index = -1;\n\t\t\tap_select_domain();\n\t\t}\n\t\tinit_timer(&ap_config_timer);\n\t\tap_config_timer.function = ap_config_timeout;\n\t\tap_config_timer.data = 0;\n\t\tap_config_timer.expires = jiffies + ap_config_time * HZ;\n\t\tadd_timer(&ap_config_timer);\n\t\tap_work_queue = create_singlethread_workqueue(\"kapwork\");\n\t\tif (!ap_work_queue)\n\t\t\treturn -ENOMEM;\n\t\ttasklet_enable(&ap_tasklet);\n\t\tif (!ap_using_interrupts())\n\t\t\tap_schedule_poll_timer();\n\t\telse\n\t\t\ttasklet_schedule(&ap_tasklet);\n\t\tif (ap_thread_flag)\n\t\t\trc = ap_poll_thread_start();\n\t\telse\n\t\t\trc = 0;\n\t} else\n\t\trc = 0;\n\tif (AP_QID_QUEUE(ap_dev->qid) != ap_domain_index) {\n\t\tspin_lock_bh(&ap_dev->lock);\n\t\tap_dev->qid = AP_MKQID(AP_QID_DEVICE(ap_dev->qid),\n\t\t\t\t       ap_domain_index);\n\t\tspin_unlock_bh(&ap_dev->lock);\n\t}\n\tqueue_work(ap_work_queue, &ap_config_work);\n\n\treturn rc;\n}\n\nstatic struct bus_type ap_bus_type = {\n\t.name = \"ap\",\n\t.match = &ap_bus_match,\n\t.uevent = &ap_uevent,\n\t.suspend = ap_bus_suspend,\n\t.resume = ap_bus_resume\n};\n\nstatic int ap_device_probe(struct device *dev)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\tstruct ap_driver *ap_drv = to_ap_drv(dev->driver);\n\tint rc;\n\n\tap_dev->drv = ap_drv;\n\n\tspin_lock_bh(&ap_device_list_lock);\n\tlist_add(&ap_dev->list, &ap_device_list);\n\tspin_unlock_bh(&ap_device_list_lock);\n\n\trc = ap_drv->probe ? ap_drv->probe(ap_dev) : -ENODEV;\n\tif (rc) {\n\t\tspin_lock_bh(&ap_device_list_lock);\n\t\tlist_del_init(&ap_dev->list);\n\t\tspin_unlock_bh(&ap_device_list_lock);\n\t}\n\treturn rc;\n}\n\n/**\n * __ap_flush_queue(): Flush requests.\n * @ap_dev: Pointer to the AP device\n *\n * Flush all requests from the request/pending queue of an AP device.\n */\nstatic void __ap_flush_queue(struct ap_device *ap_dev)\n{\n\tstruct ap_message *ap_msg, *next;\n\n\tlist_for_each_entry_safe(ap_msg, next, &ap_dev->pendingq, list) {\n\t\tlist_del_init(&ap_msg->list);\n\t\tap_dev->pendingq_count--;\n\t\tap_msg->receive(ap_dev, ap_msg, ERR_PTR(-ENODEV));\n\t}\n\tlist_for_each_entry_safe(ap_msg, next, &ap_dev->requestq, list) {\n\t\tlist_del_init(&ap_msg->list);\n\t\tap_dev->requestq_count--;\n\t\tap_msg->receive(ap_dev, ap_msg, ERR_PTR(-ENODEV));\n\t}\n}\n\nvoid ap_flush_queue(struct ap_device *ap_dev)\n{\n\tspin_lock_bh(&ap_dev->lock);\n\t__ap_flush_queue(ap_dev);\n\tspin_unlock_bh(&ap_dev->lock);\n}\nEXPORT_SYMBOL(ap_flush_queue);\n\nstatic int ap_device_remove(struct device *dev)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\tstruct ap_driver *ap_drv = ap_dev->drv;\n\n\tap_flush_queue(ap_dev);\n\tdel_timer_sync(&ap_dev->timeout);\n\tspin_lock_bh(&ap_device_list_lock);\n\tlist_del_init(&ap_dev->list);\n\tspin_unlock_bh(&ap_device_list_lock);\n\tif (ap_drv->remove)\n\t\tap_drv->remove(ap_dev);\n\tspin_lock_bh(&ap_dev->lock);\n\tatomic_sub(ap_dev->queue_count, &ap_poll_requests);\n\tspin_unlock_bh(&ap_dev->lock);\n\treturn 0;\n}\n\nint ap_driver_register(struct ap_driver *ap_drv, struct module *owner,\n\t\t       char *name)\n{\n\tstruct device_driver *drv = &ap_drv->driver;\n\n\tdrv->bus = &ap_bus_type;\n\tdrv->probe = ap_device_probe;\n\tdrv->remove = ap_device_remove;\n\tdrv->owner = owner;\n\tdrv->name = name;\n\treturn driver_register(drv);\n}\nEXPORT_SYMBOL(ap_driver_register);\n\nvoid ap_driver_unregister(struct ap_driver *ap_drv)\n{\n\tdriver_unregister(&ap_drv->driver);\n}\nEXPORT_SYMBOL(ap_driver_unregister);\n\nvoid ap_bus_force_rescan(void)\n{\n\t/* reconfigure the AP bus rescan timer. */\n\tmod_timer(&ap_config_timer, jiffies + ap_config_time * HZ);\n\t/* processing a asynchronous bus rescan */\n\tqueue_work(ap_work_queue, &ap_config_work);\n\tflush_work(&ap_config_work);\n}\nEXPORT_SYMBOL(ap_bus_force_rescan);\n\n/*\n * AP bus attributes.\n */\nstatic ssize_t ap_domain_show(struct bus_type *bus, char *buf)\n{\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", ap_domain_index);\n}\n\nstatic BUS_ATTR(ap_domain, 0444, ap_domain_show, NULL);\n\nstatic ssize_t ap_control_domain_mask_show(struct bus_type *bus, char *buf)\n{\n\tif (ap_configuration != NULL) { /* QCI not supported */\n\t\tif (test_facility(76)) { /* format 1 - 256 bit domain field */\n\t\t\treturn snprintf(buf, PAGE_SIZE,\n\t\t\t\t\"0x%08x%08x%08x%08x%08x%08x%08x%08x\\n\",\n\t\t\tap_configuration->adm[0], ap_configuration->adm[1],\n\t\t\tap_configuration->adm[2], ap_configuration->adm[3],\n\t\t\tap_configuration->adm[4], ap_configuration->adm[5],\n\t\t\tap_configuration->adm[6], ap_configuration->adm[7]);\n\t\t} else { /* format 0 - 16 bit domain field */\n\t\t\treturn snprintf(buf, PAGE_SIZE, \"%08x%08x\\n\",\n\t\t\tap_configuration->adm[0], ap_configuration->adm[1]);\n\t\t  }\n\t} else {\n\t\treturn snprintf(buf, PAGE_SIZE, \"not supported\\n\");\n\t  }\n}\n\nstatic BUS_ATTR(ap_control_domain_mask, 0444,\n\t\tap_control_domain_mask_show, NULL);\n\nstatic ssize_t ap_config_time_show(struct bus_type *bus, char *buf)\n{\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", ap_config_time);\n}\n\nstatic ssize_t ap_interrupts_show(struct bus_type *bus, char *buf)\n{\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\",\n\t\t\tap_using_interrupts() ? 1 : 0);\n}\n\nstatic BUS_ATTR(ap_interrupts, 0444, ap_interrupts_show, NULL);\n\nstatic ssize_t ap_config_time_store(struct bus_type *bus,\n\t\t\t\t    const char *buf, size_t count)\n{\n\tint time;\n\n\tif (sscanf(buf, \"%d\\n\", &time) != 1 || time < 5 || time > 120)\n\t\treturn -EINVAL;\n\tap_config_time = time;\n\tif (!timer_pending(&ap_config_timer) ||\n\t    !mod_timer(&ap_config_timer, jiffies + ap_config_time * HZ)) {\n\t\tap_config_timer.expires = jiffies + ap_config_time * HZ;\n\t\tadd_timer(&ap_config_timer);\n\t}\n\treturn count;\n}\n\nstatic BUS_ATTR(config_time, 0644, ap_config_time_show, ap_config_time_store);\n\nstatic ssize_t ap_poll_thread_show(struct bus_type *bus, char *buf)\n{\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", ap_poll_kthread ? 1 : 0);\n}\n\nstatic ssize_t ap_poll_thread_store(struct bus_type *bus,\n\t\t\t\t    const char *buf, size_t count)\n{\n\tint flag, rc;\n\n\tif (sscanf(buf, \"%d\\n\", &flag) != 1)\n\t\treturn -EINVAL;\n\tif (flag) {\n\t\trc = ap_poll_thread_start();\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\telse\n\t\tap_poll_thread_stop();\n\treturn count;\n}\n\nstatic BUS_ATTR(poll_thread, 0644, ap_poll_thread_show, ap_poll_thread_store);\n\nstatic ssize_t poll_timeout_show(struct bus_type *bus, char *buf)\n{\n\treturn snprintf(buf, PAGE_SIZE, \"%llu\\n\", poll_timeout);\n}\n\nstatic ssize_t poll_timeout_store(struct bus_type *bus, const char *buf,\n\t\t\t\t  size_t count)\n{\n\tunsigned long long time;\n\tktime_t hr_time;\n\n\t/* 120 seconds = maximum poll interval */\n\tif (sscanf(buf, \"%llu\\n\", &time) != 1 || time < 1 ||\n\t    time > 120000000000ULL)\n\t\treturn -EINVAL;\n\tpoll_timeout = time;\n\thr_time = ktime_set(0, poll_timeout);\n\n\tif (!hrtimer_is_queued(&ap_poll_timer) ||\n\t    !hrtimer_forward(&ap_poll_timer, hrtimer_get_expires(&ap_poll_timer), hr_time)) {\n\t\thrtimer_set_expires(&ap_poll_timer, hr_time);\n\t\thrtimer_start_expires(&ap_poll_timer, HRTIMER_MODE_ABS);\n\t}\n\treturn count;\n}\n\nstatic BUS_ATTR(poll_timeout, 0644, poll_timeout_show, poll_timeout_store);\n\nstatic struct bus_attribute *const ap_bus_attrs[] = {\n\t&bus_attr_ap_domain,\n\t&bus_attr_ap_control_domain_mask,\n\t&bus_attr_config_time,\n\t&bus_attr_poll_thread,\n\t&bus_attr_ap_interrupts,\n\t&bus_attr_poll_timeout,\n\tNULL,\n};\n\nstatic inline int ap_test_config(unsigned int *field, unsigned int nr)\n{\n\tif (nr > 0xFFu)\n\t\treturn 0;\n\treturn ap_test_bit((field + (nr >> 5)), (nr & 0x1f));\n}\n\n/*\n * ap_test_config_card_id(): Test, whether an AP card ID is configured.\n * @id AP card ID\n *\n * Returns 0 if the card is not configured\n *\t   1 if the card is configured or\n *\t     if the configuration information is not available\n */\nstatic inline int ap_test_config_card_id(unsigned int id)\n{\n\tif (!ap_configuration)\n\t\treturn 1;\n\treturn ap_test_config(ap_configuration->apm, id);\n}\n\n/*\n * ap_test_config_domain(): Test, whether an AP usage domain is configured.\n * @domain AP usage domain ID\n *\n * Returns 0 if the usage domain is not configured\n *\t   1 if the usage domain is configured or\n *\t     if the configuration information is not available\n */\nstatic inline int ap_test_config_domain(unsigned int domain)\n{\n\tif (!ap_configuration)\n\t\treturn 1;\n\treturn ap_test_config(ap_configuration->aqm, domain);\n}\n\n/**\n * ap_query_configuration(): Query AP configuration information.\n *\n * Query information of installed cards and configured domains from AP.\n */\nstatic void ap_query_configuration(void)\n{\n#ifdef CONFIG_64BIT\n\tif (ap_configuration_available()) {\n\t\tif (!ap_configuration)\n\t\t\tap_configuration =\n\t\t\t\tkzalloc(sizeof(struct ap_config_info),\n\t\t\t\t\tGFP_KERNEL);\n\t\tif (ap_configuration)\n\t\t\t__ap_query_configuration(ap_configuration);\n\t} else\n\t\tap_configuration = NULL;\n#else\n\tap_configuration = NULL;\n#endif\n}\n\n/**\n * ap_select_domain(): Select an AP domain.\n *\n * Pick one of the 16 AP domains.\n */\nstatic int ap_select_domain(void)\n{\n\tint queue_depth, device_type, count, max_count, best_domain;\n\tap_qid_t qid;\n\tint rc, i, j;\n\n\t/* IF APXA isn't installed, only 16 domains could be defined */\n\tif (!ap_configuration->ap_extended && (ap_domain_index > 15))\n\t\treturn -EINVAL;\n\n\t/*\n\t * We want to use a single domain. Either the one specified with\n\t * the \"domain=\" parameter or the domain with the maximum number\n\t * of devices.\n\t */\n\tif (ap_domain_index >= 0 && ap_domain_index < AP_DOMAINS)\n\t\t/* Domain has already been selected. */\n\t\treturn 0;\n\tbest_domain = -1;\n\tmax_count = 0;\n\tfor (i = 0; i < AP_DOMAINS; i++) {\n\t\tif (!ap_test_config_domain(i))\n\t\t\tcontinue;\n\t\tcount = 0;\n\t\tfor (j = 0; j < AP_DEVICES; j++) {\n\t\t\tif (!ap_test_config_card_id(j))\n\t\t\t\tcontinue;\n\t\t\tqid = AP_MKQID(j, i);\n\t\t\trc = ap_query_queue(qid, &queue_depth, &device_type);\n\t\t\tif (rc)\n\t\t\t\tcontinue;\n\t\t\tcount++;\n\t\t}\n\t\tif (count > max_count) {\n\t\t\tmax_count = count;\n\t\t\tbest_domain = i;\n\t\t}\n\t}\n\tif (best_domain >= 0){\n\t\tap_domain_index = best_domain;\n\t\treturn 0;\n\t}\n\treturn -ENODEV;\n}\n\n/**\n * ap_probe_device_type(): Find the device type of an AP.\n * @ap_dev: pointer to the AP device.\n *\n * Find the device type if query queue returned a device type of 0.\n */\nstatic int ap_probe_device_type(struct ap_device *ap_dev)\n{\n\tstatic unsigned char msg[] = {\n\t\t0x00,0x06,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x58,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x01,0x00,0x43,0x43,0x41,0x2d,0x41,0x50,\n\t\t0x50,0x4c,0x20,0x20,0x20,0x01,0x01,0x01,\n\t\t0x00,0x00,0x00,0x00,0x50,0x4b,0x00,0x00,\n\t\t0x00,0x00,0x01,0x1c,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x05,0xb8,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x70,0x00,0x41,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x54,0x32,0x01,0x00,0xa0,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0xb8,0x05,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x0a,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,\n\t\t0x00,0x00,0x00,0x00,0x00,0x00,0x08,0x00,\n\t\t0x49,0x43,0x53,0x46,0x20,0x20,0x20,0x20,\n\t\t0x50,0x4b,0x0a,0x00,0x50,0x4b,0x43,0x53,\n\t\t0x2d,0x31,0x2e,0x32,0x37,0x00,0x11,0x22,\n\t\t0x33,0x44,0x55,0x66,0x77,0x88,0x99,0x00,\n\t\t0x11,0x22,0x33,0x44,0x55,0x66,0x77,0x88,\n\t\t0x99,0x00,0x11,0x22,0x33,0x44,0x55,0x66,\n\t\t0x77,0x88,0x99,0x00,0x11,0x22,0x33,0x44,\n\t\t0x55,0x66,0x77,0x88,0x99,0x00,0x11,0x22,\n\t\t0x33,0x44,0x55,0x66,0x77,0x88,0x99,0x00,\n\t\t0x11,0x22,0x33,0x5d,0x00,0x5b,0x00,0x77,\n\t\t0x88,0x1e,0x00,0x00,0x57,0x00,0x00,0x00,\n\t\t0x00,0x04,0x00,0x00,0x4f,0x00,0x00,0x00,\n\t\t0x03,0x02,0x00,0x00,0x40,0x01,0x00,0x01,\n\t\t0xce,0x02,0x68,0x2d,0x5f,0xa9,0xde,0x0c,\n\t\t0xf6,0xd2,0x7b,0x58,0x4b,0xf9,0x28,0x68,\n\t\t0x3d,0xb4,0xf4,0xef,0x78,0xd5,0xbe,0x66,\n\t\t0x63,0x42,0xef,0xf8,0xfd,0xa4,0xf8,0xb0,\n\t\t0x8e,0x29,0xc2,0xc9,0x2e,0xd8,0x45,0xb8,\n\t\t0x53,0x8c,0x6f,0x4e,0x72,0x8f,0x6c,0x04,\n\t\t0x9c,0x88,0xfc,0x1e,0xc5,0x83,0x55,0x57,\n\t\t0xf7,0xdd,0xfd,0x4f,0x11,0x36,0x95,0x5d,\n\t};\n\tstruct ap_queue_status status;\n\tunsigned long long psmid;\n\tchar *reply;\n\tint rc, i;\n\n\treply = (void *) get_zeroed_page(GFP_KERNEL);\n\tif (!reply) {\n\t\trc = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tstatus = __ap_send(ap_dev->qid, 0x0102030405060708ULL,\n\t\t\t   msg, sizeof(msg), 0);\n\tif (status.response_code != AP_RESPONSE_NORMAL) {\n\t\trc = -ENODEV;\n\t\tgoto out_free;\n\t}\n\n\t/* Wait for the test message to complete. */\n\tfor (i = 0; i < 6; i++) {\n\t\tmdelay(300);\n\t\tstatus = __ap_recv(ap_dev->qid, &psmid, reply, 4096);\n\t\tif (status.response_code == AP_RESPONSE_NORMAL &&\n\t\t    psmid == 0x0102030405060708ULL)\n\t\t\tbreak;\n\t}\n\tif (i < 6) {\n\t\t/* Got an answer. */\n\t\tif (reply[0] == 0x00 && reply[1] == 0x86)\n\t\t\tap_dev->device_type = AP_DEVICE_TYPE_PCICC;\n\t\telse\n\t\t\tap_dev->device_type = AP_DEVICE_TYPE_PCICA;\n\t\trc = 0;\n\t} else\n\t\trc = -ENODEV;\n\nout_free:\n\tfree_page((unsigned long) reply);\nout:\n\treturn rc;\n}\n\nstatic void ap_interrupt_handler(struct airq_struct *airq)\n{\n\tinc_irq_stat(IRQIO_APB);\n\ttasklet_schedule(&ap_tasklet);\n}\n\n/**\n * __ap_scan_bus(): Scan the AP bus.\n * @dev: Pointer to device\n * @data: Pointer to data\n *\n * Scan the AP bus for new devices.\n */\nstatic int __ap_scan_bus(struct device *dev, void *data)\n{\n\treturn to_ap_dev(dev)->qid == (ap_qid_t)(unsigned long) data;\n}\n\nstatic void ap_device_release(struct device *dev)\n{\n\tstruct ap_device *ap_dev = to_ap_dev(dev);\n\n\tkfree(ap_dev);\n}\n\nstatic void ap_scan_bus(struct work_struct *unused)\n{\n\tstruct ap_device *ap_dev;\n\tstruct device *dev;\n\tap_qid_t qid;\n\tint queue_depth, device_type;\n\tunsigned int device_functions;\n\tint rc, i;\n\n\tap_query_configuration();\n\tif (ap_select_domain() != 0) {\n\t\treturn;\n\t}\n\tfor (i = 0; i < AP_DEVICES; i++) {\n\t\tqid = AP_MKQID(i, ap_domain_index);\n\t\tdev = bus_find_device(&ap_bus_type, NULL,\n\t\t\t\t      (void *)(unsigned long)qid,\n\t\t\t\t      __ap_scan_bus);\n\t\tif (ap_test_config_card_id(i))\n\t\t\trc = ap_query_queue(qid, &queue_depth, &device_type);\n\t\telse\n\t\t\trc = -ENODEV;\n\t\tif (dev) {\n\t\t\tif (rc == -EBUSY) {\n\t\t\t\tset_current_state(TASK_UNINTERRUPTIBLE);\n\t\t\t\tschedule_timeout(AP_RESET_TIMEOUT);\n\t\t\t\trc = ap_query_queue(qid, &queue_depth,\n\t\t\t\t\t\t    &device_type);\n\t\t\t}\n\t\t\tap_dev = to_ap_dev(dev);\n\t\t\tspin_lock_bh(&ap_dev->lock);\n\t\t\tif (rc || ap_dev->unregistered) {\n\t\t\t\tspin_unlock_bh(&ap_dev->lock);\n\t\t\t\tif (ap_dev->unregistered)\n\t\t\t\t\ti--;\n\t\t\t\tdevice_unregister(dev);\n\t\t\t\tput_device(dev);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tspin_unlock_bh(&ap_dev->lock);\n\t\t\tput_device(dev);\n\t\t\tcontinue;\n\t\t}\n\t\tif (rc)\n\t\t\tcontinue;\n\t\trc = ap_init_queue(qid);\n\t\tif (rc)\n\t\t\tcontinue;\n\t\tap_dev = kzalloc(sizeof(*ap_dev), GFP_KERNEL);\n\t\tif (!ap_dev)\n\t\t\tbreak;\n\t\tap_dev->qid = qid;\n\t\tap_dev->queue_depth = queue_depth;\n\t\tap_dev->unregistered = 1;\n\t\tspin_lock_init(&ap_dev->lock);\n\t\tINIT_LIST_HEAD(&ap_dev->pendingq);\n\t\tINIT_LIST_HEAD(&ap_dev->requestq);\n\t\tINIT_LIST_HEAD(&ap_dev->list);\n\t\tsetup_timer(&ap_dev->timeout, ap_request_timeout,\n\t\t\t    (unsigned long) ap_dev);\n\t\tswitch (device_type) {\n\t\tcase 0:\n\t\t\t/* device type probing for old cards */\n\t\t\tif (ap_probe_device_type(ap_dev)) {\n\t\t\t\tkfree(ap_dev);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 11:\n\t\t\tap_dev->device_type = 10;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tap_dev->device_type = device_type;\n\t\t}\n\t\tap_dev->raw_hwtype = device_type;\n\n\t\trc = ap_query_functions(qid, &device_functions);\n\t\tif (!rc)\n\t\t\tap_dev->functions = device_functions;\n\t\telse\n\t\t\tap_dev->functions = 0u;\n\n\t\tap_dev->device.bus = &ap_bus_type;\n\t\tap_dev->device.parent = ap_root_device;\n\t\tif (dev_set_name(&ap_dev->device, \"card%02x\",\n\t\t\t\t AP_QID_DEVICE(ap_dev->qid))) {\n\t\t\tkfree(ap_dev);\n\t\t\tcontinue;\n\t\t}\n\t\tap_dev->device.release = ap_device_release;\n\t\trc = device_register(&ap_dev->device);\n\t\tif (rc) {\n\t\t\tput_device(&ap_dev->device);\n\t\t\tcontinue;\n\t\t}\n\t\t/* Add device attributes. */\n\t\trc = sysfs_create_group(&ap_dev->device.kobj,\n\t\t\t\t\t&ap_dev_attr_group);\n\t\tif (!rc) {\n\t\t\tspin_lock_bh(&ap_dev->lock);\n\t\t\tap_dev->unregistered = 0;\n\t\t\tspin_unlock_bh(&ap_dev->lock);\n\t\t}\n\t\telse\n\t\t\tdevice_unregister(&ap_dev->device);\n\t}\n}\n\nstatic void\nap_config_timeout(unsigned long ptr)\n{\n\tqueue_work(ap_work_queue, &ap_config_work);\n\tap_config_timer.expires = jiffies + ap_config_time * HZ;\n\tadd_timer(&ap_config_timer);\n}\n\n/**\n * __ap_schedule_poll_timer(): Schedule poll timer.\n *\n * Set up the timer to run the poll tasklet\n */\nstatic inline void __ap_schedule_poll_timer(void)\n{\n\tktime_t hr_time;\n\n\tspin_lock_bh(&ap_poll_timer_lock);\n\tif (hrtimer_is_queued(&ap_poll_timer) || ap_suspend_flag)\n\t\tgoto out;\n\tif (ktime_to_ns(hrtimer_expires_remaining(&ap_poll_timer)) <= 0) {\n\t\thr_time = ktime_set(0, poll_timeout);\n\t\thrtimer_forward_now(&ap_poll_timer, hr_time);\n\t\thrtimer_restart(&ap_poll_timer);\n\t}\nout:\n\tspin_unlock_bh(&ap_poll_timer_lock);\n}\n\n/**\n * ap_schedule_poll_timer(): Schedule poll timer.\n *\n * Set up the timer to run the poll tasklet\n */\nstatic inline void ap_schedule_poll_timer(void)\n{\n\tif (ap_using_interrupts())\n\t\treturn;\n\t__ap_schedule_poll_timer();\n}\n\n/**\n * ap_poll_read(): Receive pending reply messages from an AP device.\n * @ap_dev: pointer to the AP device\n * @flags: pointer to control flags, bit 2^0 is set if another poll is\n *\t   required, bit 2^1 is set if the poll timer needs to get armed\n *\n * Returns 0 if the device is still present, -ENODEV if not.\n */\nstatic int ap_poll_read(struct ap_device *ap_dev, unsigned long *flags)\n{\n\tstruct ap_queue_status status;\n\tstruct ap_message *ap_msg;\n\n\tif (ap_dev->queue_count <= 0)\n\t\treturn 0;\n\tstatus = __ap_recv(ap_dev->qid, &ap_dev->reply->psmid,\n\t\t\t   ap_dev->reply->message, ap_dev->reply->length);\n\tswitch (status.response_code) {\n\tcase AP_RESPONSE_NORMAL:\n\t\tatomic_dec(&ap_poll_requests);\n\t\tap_decrease_queue_count(ap_dev);\n\t\tlist_for_each_entry(ap_msg, &ap_dev->pendingq, list) {\n\t\t\tif (ap_msg->psmid != ap_dev->reply->psmid)\n\t\t\t\tcontinue;\n\t\t\tlist_del_init(&ap_msg->list);\n\t\t\tap_dev->pendingq_count--;\n\t\t\tap_msg->receive(ap_dev, ap_msg, ap_dev->reply);\n\t\t\tbreak;\n\t\t}\n\t\tif (ap_dev->queue_count > 0)\n\t\t\t*flags |= 1;\n\t\tbreak;\n\tcase AP_RESPONSE_NO_PENDING_REPLY:\n\t\tif (status.queue_empty) {\n\t\t\t/* The card shouldn't forget requests but who knows. */\n\t\t\tatomic_sub(ap_dev->queue_count, &ap_poll_requests);\n\t\t\tap_dev->queue_count = 0;\n\t\t\tlist_splice_init(&ap_dev->pendingq, &ap_dev->requestq);\n\t\t\tap_dev->requestq_count += ap_dev->pendingq_count;\n\t\t\tap_dev->pendingq_count = 0;\n\t\t} else\n\t\t\t*flags |= 2;\n\t\tbreak;\n\tdefault:\n\t\treturn -ENODEV;\n\t}\n\treturn 0;\n}\n\n/**\n * ap_poll_write(): Send messages from the request queue to an AP device.\n * @ap_dev: pointer to the AP device\n * @flags: pointer to control flags, bit 2^0 is set if another poll is\n *\t   required, bit 2^1 is set if the poll timer needs to get armed\n *\n * Returns 0 if the device is still present, -ENODEV if not.\n */\nstatic int ap_poll_write(struct ap_device *ap_dev, unsigned long *flags)\n{\n\tstruct ap_queue_status status;\n\tstruct ap_message *ap_msg;\n\n\tif (ap_dev->requestq_count <= 0 ||\n\t    ap_dev->queue_count >= ap_dev->queue_depth)\n\t\treturn 0;\n\t/* Start the next request on the queue. */\n\tap_msg = list_entry(ap_dev->requestq.next, struct ap_message, list);\n\tstatus = __ap_send(ap_dev->qid, ap_msg->psmid,\n\t\t\t   ap_msg->message, ap_msg->length, ap_msg->special);\n\tswitch (status.response_code) {\n\tcase AP_RESPONSE_NORMAL:\n\t\tatomic_inc(&ap_poll_requests);\n\t\tap_increase_queue_count(ap_dev);\n\t\tlist_move_tail(&ap_msg->list, &ap_dev->pendingq);\n\t\tap_dev->requestq_count--;\n\t\tap_dev->pendingq_count++;\n\t\tif (ap_dev->queue_count < ap_dev->queue_depth &&\n\t\t    ap_dev->requestq_count > 0)\n\t\t\t*flags |= 1;\n\t\t*flags |= 2;\n\t\tbreak;\n\tcase AP_RESPONSE_RESET_IN_PROGRESS:\n\t\t__ap_schedule_poll_timer();\n\tcase AP_RESPONSE_Q_FULL:\n\t\t*flags |= 2;\n\t\tbreak;\n\tcase AP_RESPONSE_MESSAGE_TOO_BIG:\n\tcase AP_RESPONSE_REQ_FAC_NOT_INST:\n\t\treturn -EINVAL;\n\tdefault:\n\t\treturn -ENODEV;\n\t}\n\treturn 0;\n}\n\n/**\n * ap_poll_queue(): Poll AP device for pending replies and send new messages.\n * @ap_dev: pointer to the bus device\n * @flags: pointer to control flags, bit 2^0 is set if another poll is\n *\t   required, bit 2^1 is set if the poll timer needs to get armed\n *\n * Poll AP device for pending replies and send new messages. If either\n * ap_poll_read or ap_poll_write returns -ENODEV unregister the device.\n * Returns 0.\n */\nstatic inline int ap_poll_queue(struct ap_device *ap_dev, unsigned long *flags)\n{\n\tint rc;\n\n\trc = ap_poll_read(ap_dev, flags);\n\tif (rc)\n\t\treturn rc;\n\treturn ap_poll_write(ap_dev, flags);\n}\n\n/**\n * __ap_queue_message(): Queue a message to a device.\n * @ap_dev: pointer to the AP device\n * @ap_msg: the message to be queued\n *\n * Queue a message to a device. Returns 0 if successful.\n */\nstatic int __ap_queue_message(struct ap_device *ap_dev, struct ap_message *ap_msg)\n{\n\tstruct ap_queue_status status;\n\n\tif (list_empty(&ap_dev->requestq) &&\n\t    ap_dev->queue_count < ap_dev->queue_depth) {\n\t\tstatus = __ap_send(ap_dev->qid, ap_msg->psmid,\n\t\t\t\t   ap_msg->message, ap_msg->length,\n\t\t\t\t   ap_msg->special);\n\t\tswitch (status.response_code) {\n\t\tcase AP_RESPONSE_NORMAL:\n\t\t\tlist_add_tail(&ap_msg->list, &ap_dev->pendingq);\n\t\t\tatomic_inc(&ap_poll_requests);\n\t\t\tap_dev->pendingq_count++;\n\t\t\tap_increase_queue_count(ap_dev);\n\t\t\tap_dev->total_request_count++;\n\t\t\tbreak;\n\t\tcase AP_RESPONSE_Q_FULL:\n\t\tcase AP_RESPONSE_RESET_IN_PROGRESS:\n\t\t\tlist_add_tail(&ap_msg->list, &ap_dev->requestq);\n\t\t\tap_dev->requestq_count++;\n\t\t\tap_dev->total_request_count++;\n\t\t\treturn -EBUSY;\n\t\tcase AP_RESPONSE_REQ_FAC_NOT_INST:\n\t\tcase AP_RESPONSE_MESSAGE_TOO_BIG:\n\t\t\tap_msg->receive(ap_dev, ap_msg, ERR_PTR(-EINVAL));\n\t\t\treturn -EINVAL;\n\t\tdefault:\t/* Device is gone. */\n\t\t\tap_msg->receive(ap_dev, ap_msg, ERR_PTR(-ENODEV));\n\t\t\treturn -ENODEV;\n\t\t}\n\t} else {\n\t\tlist_add_tail(&ap_msg->list, &ap_dev->requestq);\n\t\tap_dev->requestq_count++;\n\t\tap_dev->total_request_count++;\n\t\treturn -EBUSY;\n\t}\n\tap_schedule_poll_timer();\n\treturn 0;\n}\n\nvoid ap_queue_message(struct ap_device *ap_dev, struct ap_message *ap_msg)\n{\n\tunsigned long flags;\n\tint rc;\n\n\t/* For asynchronous message handling a valid receive-callback\n\t * is required. */\n\tBUG_ON(!ap_msg->receive);\n\n\tspin_lock_bh(&ap_dev->lock);\n\tif (!ap_dev->unregistered) {\n\t\t/* Make room on the queue by polling for finished requests. */\n\t\trc = ap_poll_queue(ap_dev, &flags);\n\t\tif (!rc)\n\t\t\trc = __ap_queue_message(ap_dev, ap_msg);\n\t\tif (!rc)\n\t\t\twake_up(&ap_poll_wait);\n\t\tif (rc == -ENODEV)\n\t\t\tap_dev->unregistered = 1;\n\t} else {\n\t\tap_msg->receive(ap_dev, ap_msg, ERR_PTR(-ENODEV));\n\t\trc = -ENODEV;\n\t}\n\tspin_unlock_bh(&ap_dev->lock);\n\tif (rc == -ENODEV)\n\t\tdevice_unregister(&ap_dev->device);\n}\nEXPORT_SYMBOL(ap_queue_message);\n\n/**\n * ap_cancel_message(): Cancel a crypto request.\n * @ap_dev: The AP device that has the message queued\n * @ap_msg: The message that is to be removed\n *\n * Cancel a crypto request. This is done by removing the request\n * from the device pending or request queue. Note that the\n * request stays on the AP queue. When it finishes the message\n * reply will be discarded because the psmid can't be found.\n */\nvoid ap_cancel_message(struct ap_device *ap_dev, struct ap_message *ap_msg)\n{\n\tstruct ap_message *tmp;\n\n\tspin_lock_bh(&ap_dev->lock);\n\tif (!list_empty(&ap_msg->list)) {\n\t\tlist_for_each_entry(tmp, &ap_dev->pendingq, list)\n\t\t\tif (tmp->psmid == ap_msg->psmid) {\n\t\t\t\tap_dev->pendingq_count--;\n\t\t\t\tgoto found;\n\t\t\t}\n\t\tap_dev->requestq_count--;\n\tfound:\n\t\tlist_del_init(&ap_msg->list);\n\t}\n\tspin_unlock_bh(&ap_dev->lock);\n}\nEXPORT_SYMBOL(ap_cancel_message);\n\n/**\n * ap_poll_timeout(): AP receive polling for finished AP requests.\n * @unused: Unused pointer.\n *\n * Schedules the AP tasklet using a high resolution timer.\n */\nstatic enum hrtimer_restart ap_poll_timeout(struct hrtimer *unused)\n{\n\ttasklet_schedule(&ap_tasklet);\n\treturn HRTIMER_NORESTART;\n}\n\n/**\n * ap_reset(): Reset a not responding AP device.\n * @ap_dev: Pointer to the AP device\n *\n * Reset a not responding AP device and move all requests from the\n * pending queue to the request queue.\n */\nstatic void ap_reset(struct ap_device *ap_dev)\n{\n\tint rc;\n\n\tap_dev->reset = AP_RESET_IGNORE;\n\tatomic_sub(ap_dev->queue_count, &ap_poll_requests);\n\tap_dev->queue_count = 0;\n\tlist_splice_init(&ap_dev->pendingq, &ap_dev->requestq);\n\tap_dev->requestq_count += ap_dev->pendingq_count;\n\tap_dev->pendingq_count = 0;\n\trc = ap_init_queue(ap_dev->qid);\n\tif (rc == -ENODEV)\n\t\tap_dev->unregistered = 1;\n\telse\n\t\t__ap_schedule_poll_timer();\n}\n\nstatic int __ap_poll_device(struct ap_device *ap_dev, unsigned long *flags)\n{\n\tif (!ap_dev->unregistered) {\n\t\tif (ap_poll_queue(ap_dev, flags))\n\t\t\tap_dev->unregistered = 1;\n\t\tif (ap_dev->reset == AP_RESET_DO)\n\t\t\tap_reset(ap_dev);\n\t}\n\treturn 0;\n}\n\n/**\n * ap_poll_all(): Poll all AP devices.\n * @dummy: Unused variable\n *\n * Poll all AP devices on the bus in a round robin fashion. Continue\n * polling until bit 2^0 of the control flags is not set. If bit 2^1\n * of the control flags has been set arm the poll timer.\n */\nstatic void ap_poll_all(unsigned long dummy)\n{\n\tunsigned long flags;\n\tstruct ap_device *ap_dev;\n\n\t/* Reset the indicator if interrupts are used. Thus new interrupts can\n\t * be received. Doing it in the beginning of the tasklet is therefor\n\t * important that no requests on any AP get lost.\n\t */\n\tif (ap_using_interrupts())\n\t\txchg(ap_airq.lsi_ptr, 0);\n\tdo {\n\t\tflags = 0;\n\t\tspin_lock(&ap_device_list_lock);\n\t\tlist_for_each_entry(ap_dev, &ap_device_list, list) {\n\t\t\tspin_lock(&ap_dev->lock);\n\t\t\t__ap_poll_device(ap_dev, &flags);\n\t\t\tspin_unlock(&ap_dev->lock);\n\t\t}\n\t\tspin_unlock(&ap_device_list_lock);\n\t} while (flags & 1);\n\tif (flags & 2)\n\t\tap_schedule_poll_timer();\n}\n\n/**\n * ap_poll_thread(): Thread that polls for finished requests.\n * @data: Unused pointer\n *\n * AP bus poll thread. The purpose of this thread is to poll for\n * finished requests in a loop if there is a \"free\" cpu - that is\n * a cpu that doesn't have anything better to do. The polling stops\n * as soon as there is another task or if all messages have been\n * delivered.\n */\nstatic int ap_poll_thread(void *data)\n{\n\tDECLARE_WAITQUEUE(wait, current);\n\tunsigned long flags;\n\tint requests;\n\tstruct ap_device *ap_dev;\n\n\tset_user_nice(current, MAX_NICE);\n\twhile (1) {\n\t\tif (ap_suspend_flag)\n\t\t\treturn 0;\n\t\tif (need_resched()) {\n\t\t\tschedule();\n\t\t\tcontinue;\n\t\t}\n\t\tadd_wait_queue(&ap_poll_wait, &wait);\n\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\tif (kthread_should_stop())\n\t\t\tbreak;\n\t\trequests = atomic_read(&ap_poll_requests);\n\t\tif (requests <= 0)\n\t\t\tschedule();\n\t\tset_current_state(TASK_RUNNING);\n\t\tremove_wait_queue(&ap_poll_wait, &wait);\n\n\t\tflags = 0;\n\t\tspin_lock_bh(&ap_device_list_lock);\n\t\tlist_for_each_entry(ap_dev, &ap_device_list, list) {\n\t\t\tspin_lock(&ap_dev->lock);\n\t\t\t__ap_poll_device(ap_dev, &flags);\n\t\t\tspin_unlock(&ap_dev->lock);\n\t\t}\n\t\tspin_unlock_bh(&ap_device_list_lock);\n\t}\n\tset_current_state(TASK_RUNNING);\n\tremove_wait_queue(&ap_poll_wait, &wait);\n\treturn 0;\n}\n\nstatic int ap_poll_thread_start(void)\n{\n\tint rc;\n\n\tif (ap_using_interrupts() || ap_suspend_flag)\n\t\treturn 0;\n\tmutex_lock(&ap_poll_thread_mutex);\n\tif (!ap_poll_kthread) {\n\t\tap_poll_kthread = kthread_run(ap_poll_thread, NULL, \"appoll\");\n\t\trc = PTR_RET(ap_poll_kthread);\n\t\tif (rc)\n\t\t\tap_poll_kthread = NULL;\n\t}\n\telse\n\t\trc = 0;\n\tmutex_unlock(&ap_poll_thread_mutex);\n\treturn rc;\n}\n\nstatic void ap_poll_thread_stop(void)\n{\n\tmutex_lock(&ap_poll_thread_mutex);\n\tif (ap_poll_kthread) {\n\t\tkthread_stop(ap_poll_kthread);\n\t\tap_poll_kthread = NULL;\n\t}\n\tmutex_unlock(&ap_poll_thread_mutex);\n}\n\n/**\n * ap_request_timeout(): Handling of request timeouts\n * @data: Holds the AP device.\n *\n * Handles request timeouts.\n */\nstatic void ap_request_timeout(unsigned long data)\n{\n\tstruct ap_device *ap_dev = (struct ap_device *) data;\n\n\tif (ap_dev->reset == AP_RESET_ARMED) {\n\t\tap_dev->reset = AP_RESET_DO;\n\n\t\tif (ap_using_interrupts())\n\t\t\ttasklet_schedule(&ap_tasklet);\n\t}\n}\n\nstatic void ap_reset_domain(void)\n{\n\tint i;\n\n\tif (ap_domain_index != -1)\n\t\tfor (i = 0; i < AP_DEVICES; i++)\n\t\t\tap_reset_queue(AP_MKQID(i, ap_domain_index));\n}\n\nstatic void ap_reset_all(void)\n{\n\tint i, j;\n\n\tfor (i = 0; i < AP_DOMAINS; i++) {\n\t\tif (!ap_test_config_domain(i))\n\t\t\tcontinue;\n\t\tfor (j = 0; j < AP_DEVICES; j++) {\n\t\t\tif (!ap_test_config_card_id(j))\n\t\t\t\tcontinue;\n\t\t\tap_reset_queue(AP_MKQID(j, i));\n\t\t}\n\t}\n}\n\nstatic struct reset_call ap_reset_call = {\n\t.fn = ap_reset_all,\n};\n\n/**\n * ap_module_init(): The module initialization code.\n *\n * Initializes the module.\n */\nint __init ap_module_init(void)\n{\n\tint rc, i;\n\n\tif (ap_domain_index < -1 || ap_domain_index >= AP_DOMAINS) {\n\t\tpr_warning(\"%d is not a valid cryptographic domain\\n\",\n\t\t\t   ap_domain_index);\n\t\treturn -EINVAL;\n\t}\n\t/* In resume callback we need to know if the user had set the domain.\n\t * If so, we can not just reset it.\n\t */\n\tif (ap_domain_index >= 0)\n\t\tuser_set_domain = 1;\n\n\tif (ap_instructions_available() != 0) {\n\t\tpr_warning(\"The hardware system does not support \"\n\t\t\t   \"AP instructions\\n\");\n\t\treturn -ENODEV;\n\t}\n\tif (ap_interrupts_available()) {\n\t\trc = register_adapter_interrupt(&ap_airq);\n\t\tap_airq_flag = (rc == 0);\n\t}\n\n\tregister_reset_call(&ap_reset_call);\n\n\t/* Create /sys/bus/ap. */\n\trc = bus_register(&ap_bus_type);\n\tif (rc)\n\t\tgoto out;\n\tfor (i = 0; ap_bus_attrs[i]; i++) {\n\t\trc = bus_create_file(&ap_bus_type, ap_bus_attrs[i]);\n\t\tif (rc)\n\t\t\tgoto out_bus;\n\t}\n\n\t/* Create /sys/devices/ap. */\n\tap_root_device = root_device_register(\"ap\");\n\trc = PTR_RET(ap_root_device);\n\tif (rc)\n\t\tgoto out_bus;\n\n\tap_work_queue = create_singlethread_workqueue(\"kapwork\");\n\tif (!ap_work_queue) {\n\t\trc = -ENOMEM;\n\t\tgoto out_root;\n\t}\n\n\tap_query_configuration();\n\tif (ap_select_domain() == 0)\n\t\tap_scan_bus(NULL);\n\n\t/* Setup the AP bus rescan timer. */\n\tinit_timer(&ap_config_timer);\n\tap_config_timer.function = ap_config_timeout;\n\tap_config_timer.data = 0;\n\tap_config_timer.expires = jiffies + ap_config_time * HZ;\n\tadd_timer(&ap_config_timer);\n\n\t/* Setup the high resultion poll timer.\n\t * If we are running under z/VM adjust polling to z/VM polling rate.\n\t */\n\tif (MACHINE_IS_VM)\n\t\tpoll_timeout = 1500000;\n\tspin_lock_init(&ap_poll_timer_lock);\n\thrtimer_init(&ap_poll_timer, CLOCK_MONOTONIC, HRTIMER_MODE_ABS);\n\tap_poll_timer.function = ap_poll_timeout;\n\n\t/* Start the low priority AP bus poll thread. */\n\tif (ap_thread_flag) {\n\t\trc = ap_poll_thread_start();\n\t\tif (rc)\n\t\t\tgoto out_work;\n\t}\n\n\treturn 0;\n\nout_work:\n\tdel_timer_sync(&ap_config_timer);\n\thrtimer_cancel(&ap_poll_timer);\n\tdestroy_workqueue(ap_work_queue);\nout_root:\n\troot_device_unregister(ap_root_device);\nout_bus:\n\twhile (i--)\n\t\tbus_remove_file(&ap_bus_type, ap_bus_attrs[i]);\n\tbus_unregister(&ap_bus_type);\nout:\n\tunregister_reset_call(&ap_reset_call);\n\tif (ap_using_interrupts())\n\t\tunregister_adapter_interrupt(&ap_airq);\n\treturn rc;\n}\n\nstatic int __ap_match_all(struct device *dev, void *data)\n{\n\treturn 1;\n}\n\n/**\n * ap_modules_exit(): The module termination code\n *\n * Terminates the module.\n */\nvoid ap_module_exit(void)\n{\n\tint i;\n\tstruct device *dev;\n\n\tap_reset_domain();\n\tap_poll_thread_stop();\n\tdel_timer_sync(&ap_config_timer);\n\thrtimer_cancel(&ap_poll_timer);\n\tdestroy_workqueue(ap_work_queue);\n\ttasklet_kill(&ap_tasklet);\n\troot_device_unregister(ap_root_device);\n\twhile ((dev = bus_find_device(&ap_bus_type, NULL, NULL,\n\t\t    __ap_match_all)))\n\t{\n\t\tdevice_unregister(dev);\n\t\tput_device(dev);\n\t}\n\tfor (i = 0; ap_bus_attrs[i]; i++)\n\t\tbus_remove_file(&ap_bus_type, ap_bus_attrs[i]);\n\tbus_unregister(&ap_bus_type);\n\tunregister_reset_call(&ap_reset_call);\n\tif (ap_using_interrupts())\n\t\tunregister_adapter_interrupt(&ap_airq);\n}\n\nmodule_init(ap_module_init);\nmodule_exit(ap_module_exit);\n", "/*\n * Scatterlist Cryptographic API.\n *\n * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>\n * Copyright (c) 2002 David S. Miller (davem@redhat.com)\n * Copyright (c) 2005 Herbert Xu <herbert@gondor.apana.org.au>\n *\n * Portions derived from Cryptoapi, by Alexander Kjeldaas <astor@fast.no>\n * and Nettle, by Niels M\u00f6ller.\n * \n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option) \n * any later version.\n *\n */\n#ifndef _LINUX_CRYPTO_H\n#define _LINUX_CRYPTO_H\n\n#include <linux/atomic.h>\n#include <linux/kernel.h>\n#include <linux/list.h>\n#include <linux/bug.h>\n#include <linux/slab.h>\n#include <linux/string.h>\n#include <linux/uaccess.h>\n\n/*\n * Autoloaded crypto modules should only use a prefixed name to avoid allowing\n * arbitrary modules to be loaded. Loading from userspace may still need the\n * unprefixed names, so retains those aliases as well.\n * This uses __MODULE_INFO directly instead of MODULE_ALIAS because pre-4.3\n * gcc (e.g. avr32 toolchain) uses __LINE__ for uniqueness, and this macro\n * expands twice on the same line. Instead, use a separate base name for the\n * alias.\n */\n#define MODULE_ALIAS_CRYPTO(name)\t\\\n\t\t__MODULE_INFO(alias, alias_userspace, name);\t\\\n\t\t__MODULE_INFO(alias, alias_crypto, \"crypto-\" name)\n\n/*\n * Algorithm masks and types.\n */\n#define CRYPTO_ALG_TYPE_MASK\t\t0x0000000f\n#define CRYPTO_ALG_TYPE_CIPHER\t\t0x00000001\n#define CRYPTO_ALG_TYPE_COMPRESS\t0x00000002\n#define CRYPTO_ALG_TYPE_AEAD\t\t0x00000003\n#define CRYPTO_ALG_TYPE_BLKCIPHER\t0x00000004\n#define CRYPTO_ALG_TYPE_ABLKCIPHER\t0x00000005\n#define CRYPTO_ALG_TYPE_GIVCIPHER\t0x00000006\n#define CRYPTO_ALG_TYPE_DIGEST\t\t0x00000008\n#define CRYPTO_ALG_TYPE_HASH\t\t0x00000008\n#define CRYPTO_ALG_TYPE_SHASH\t\t0x00000009\n#define CRYPTO_ALG_TYPE_AHASH\t\t0x0000000a\n#define CRYPTO_ALG_TYPE_RNG\t\t0x0000000c\n#define CRYPTO_ALG_TYPE_PCOMPRESS\t0x0000000f\n\n#define CRYPTO_ALG_TYPE_HASH_MASK\t0x0000000e\n#define CRYPTO_ALG_TYPE_AHASH_MASK\t0x0000000c\n#define CRYPTO_ALG_TYPE_BLKCIPHER_MASK\t0x0000000c\n\n#define CRYPTO_ALG_LARVAL\t\t0x00000010\n#define CRYPTO_ALG_DEAD\t\t\t0x00000020\n#define CRYPTO_ALG_DYING\t\t0x00000040\n#define CRYPTO_ALG_ASYNC\t\t0x00000080\n\n/*\n * Set this bit if and only if the algorithm requires another algorithm of\n * the same type to handle corner cases.\n */\n#define CRYPTO_ALG_NEED_FALLBACK\t0x00000100\n\n/*\n * This bit is set for symmetric key ciphers that have already been wrapped\n * with a generic IV generator to prevent them from being wrapped again.\n */\n#define CRYPTO_ALG_GENIV\t\t0x00000200\n\n/*\n * Set if the algorithm has passed automated run-time testing.  Note that\n * if there is no run-time testing for a given algorithm it is considered\n * to have passed.\n */\n\n#define CRYPTO_ALG_TESTED\t\t0x00000400\n\n/*\n * Set if the algorithm is an instance that is build from templates.\n */\n#define CRYPTO_ALG_INSTANCE\t\t0x00000800\n\n/* Set this bit if the algorithm provided is hardware accelerated but\n * not available to userspace via instruction set or so.\n */\n#define CRYPTO_ALG_KERN_DRIVER_ONLY\t0x00001000\n\n/*\n * Transform masks and values (for crt_flags).\n */\n#define CRYPTO_TFM_REQ_MASK\t\t0x000fff00\n#define CRYPTO_TFM_RES_MASK\t\t0xfff00000\n\n#define CRYPTO_TFM_REQ_WEAK_KEY\t\t0x00000100\n#define CRYPTO_TFM_REQ_MAY_SLEEP\t0x00000200\n#define CRYPTO_TFM_REQ_MAY_BACKLOG\t0x00000400\n#define CRYPTO_TFM_RES_WEAK_KEY\t\t0x00100000\n#define CRYPTO_TFM_RES_BAD_KEY_LEN   \t0x00200000\n#define CRYPTO_TFM_RES_BAD_KEY_SCHED \t0x00400000\n#define CRYPTO_TFM_RES_BAD_BLOCK_LEN \t0x00800000\n#define CRYPTO_TFM_RES_BAD_FLAGS \t0x01000000\n\n/*\n * Miscellaneous stuff.\n */\n#define CRYPTO_MAX_ALG_NAME\t\t64\n\n/*\n * The macro CRYPTO_MINALIGN_ATTR (along with the void * type in the actual\n * declaration) is used to ensure that the crypto_tfm context structure is\n * aligned correctly for the given architecture so that there are no alignment\n * faults for C data types.  In particular, this is required on platforms such\n * as arm where pointers are 32-bit aligned but there are data types such as\n * u64 which require 64-bit alignment.\n */\n#define CRYPTO_MINALIGN ARCH_KMALLOC_MINALIGN\n\n#define CRYPTO_MINALIGN_ATTR __attribute__ ((__aligned__(CRYPTO_MINALIGN)))\n\nstruct scatterlist;\nstruct crypto_ablkcipher;\nstruct crypto_async_request;\nstruct crypto_aead;\nstruct crypto_blkcipher;\nstruct crypto_hash;\nstruct crypto_rng;\nstruct crypto_tfm;\nstruct crypto_type;\nstruct aead_givcrypt_request;\nstruct skcipher_givcrypt_request;\n\ntypedef void (*crypto_completion_t)(struct crypto_async_request *req, int err);\n\n/**\n * DOC: Block Cipher Context Data Structures\n *\n * These data structures define the operating context for each block cipher\n * type.\n */\n\nstruct crypto_async_request {\n\tstruct list_head list;\n\tcrypto_completion_t complete;\n\tvoid *data;\n\tstruct crypto_tfm *tfm;\n\n\tu32 flags;\n};\n\nstruct ablkcipher_request {\n\tstruct crypto_async_request base;\n\n\tunsigned int nbytes;\n\n\tvoid *info;\n\n\tstruct scatterlist *src;\n\tstruct scatterlist *dst;\n\n\tvoid *__ctx[] CRYPTO_MINALIGN_ATTR;\n};\n\n/**\n *\tstruct aead_request - AEAD request\n *\t@base: Common attributes for async crypto requests\n *\t@assoclen: Length in bytes of associated data for authentication\n *\t@cryptlen: Length of data to be encrypted or decrypted\n *\t@iv: Initialisation vector\n *\t@assoc: Associated data\n *\t@src: Source data\n *\t@dst: Destination data\n *\t@__ctx: Start of private context data\n */\nstruct aead_request {\n\tstruct crypto_async_request base;\n\n\tunsigned int assoclen;\n\tunsigned int cryptlen;\n\n\tu8 *iv;\n\n\tstruct scatterlist *assoc;\n\tstruct scatterlist *src;\n\tstruct scatterlist *dst;\n\n\tvoid *__ctx[] CRYPTO_MINALIGN_ATTR;\n};\n\nstruct blkcipher_desc {\n\tstruct crypto_blkcipher *tfm;\n\tvoid *info;\n\tu32 flags;\n};\n\nstruct cipher_desc {\n\tstruct crypto_tfm *tfm;\n\tvoid (*crfn)(struct crypto_tfm *tfm, u8 *dst, const u8 *src);\n\tunsigned int (*prfn)(const struct cipher_desc *desc, u8 *dst,\n\t\t\t     const u8 *src, unsigned int nbytes);\n\tvoid *info;\n};\n\nstruct hash_desc {\n\tstruct crypto_hash *tfm;\n\tu32 flags;\n};\n\n/**\n * DOC: Block Cipher Algorithm Definitions\n *\n * These data structures define modular crypto algorithm implementations,\n * managed via crypto_register_alg() and crypto_unregister_alg().\n */\n\n/**\n * struct ablkcipher_alg - asynchronous block cipher definition\n * @min_keysize: Minimum key size supported by the transformation. This is the\n *\t\t smallest key length supported by this transformation algorithm.\n *\t\t This must be set to one of the pre-defined values as this is\n *\t\t not hardware specific. Possible values for this field can be\n *\t\t found via git grep \"_MIN_KEY_SIZE\" include/crypto/\n * @max_keysize: Maximum key size supported by the transformation. This is the\n *\t\t largest key length supported by this transformation algorithm.\n *\t\t This must be set to one of the pre-defined values as this is\n *\t\t not hardware specific. Possible values for this field can be\n *\t\t found via git grep \"_MAX_KEY_SIZE\" include/crypto/\n * @setkey: Set key for the transformation. This function is used to either\n *\t    program a supplied key into the hardware or store the key in the\n *\t    transformation context for programming it later. Note that this\n *\t    function does modify the transformation context. This function can\n *\t    be called multiple times during the existence of the transformation\n *\t    object, so one must make sure the key is properly reprogrammed into\n *\t    the hardware. This function is also responsible for checking the key\n *\t    length for validity. In case a software fallback was put in place in\n *\t    the @cra_init call, this function might need to use the fallback if\n *\t    the algorithm doesn't support all of the key sizes.\n * @encrypt: Encrypt a scatterlist of blocks. This function is used to encrypt\n *\t     the supplied scatterlist containing the blocks of data. The crypto\n *\t     API consumer is responsible for aligning the entries of the\n *\t     scatterlist properly and making sure the chunks are correctly\n *\t     sized. In case a software fallback was put in place in the\n *\t     @cra_init call, this function might need to use the fallback if\n *\t     the algorithm doesn't support all of the key sizes. In case the\n *\t     key was stored in transformation context, the key might need to be\n *\t     re-programmed into the hardware in this function. This function\n *\t     shall not modify the transformation context, as this function may\n *\t     be called in parallel with the same transformation object.\n * @decrypt: Decrypt a single block. This is a reverse counterpart to @encrypt\n *\t     and the conditions are exactly the same.\n * @givencrypt: Update the IV for encryption. With this function, a cipher\n *\t        implementation may provide the function on how to update the IV\n *\t        for encryption.\n * @givdecrypt: Update the IV for decryption. This is the reverse of\n *\t        @givencrypt .\n * @geniv: The transformation implementation may use an \"IV generator\" provided\n *\t   by the kernel crypto API. Several use cases have a predefined\n *\t   approach how IVs are to be updated. For such use cases, the kernel\n *\t   crypto API provides ready-to-use implementations that can be\n *\t   referenced with this variable.\n * @ivsize: IV size applicable for transformation. The consumer must provide an\n *\t    IV of exactly that size to perform the encrypt or decrypt operation.\n *\n * All fields except @givencrypt , @givdecrypt , @geniv and @ivsize are\n * mandatory and must be filled.\n */\nstruct ablkcipher_alg {\n\tint (*setkey)(struct crypto_ablkcipher *tfm, const u8 *key,\n\t              unsigned int keylen);\n\tint (*encrypt)(struct ablkcipher_request *req);\n\tint (*decrypt)(struct ablkcipher_request *req);\n\tint (*givencrypt)(struct skcipher_givcrypt_request *req);\n\tint (*givdecrypt)(struct skcipher_givcrypt_request *req);\n\n\tconst char *geniv;\n\n\tunsigned int min_keysize;\n\tunsigned int max_keysize;\n\tunsigned int ivsize;\n};\n\n/**\n * struct aead_alg - AEAD cipher definition\n * @maxauthsize: Set the maximum authentication tag size supported by the\n *\t\t transformation. A transformation may support smaller tag sizes.\n *\t\t As the authentication tag is a message digest to ensure the\n *\t\t integrity of the encrypted data, a consumer typically wants the\n *\t\t largest authentication tag possible as defined by this\n *\t\t variable.\n * @setauthsize: Set authentication size for the AEAD transformation. This\n *\t\t function is used to specify the consumer requested size of the\n * \t\t authentication tag to be either generated by the transformation\n *\t\t during encryption or the size of the authentication tag to be\n *\t\t supplied during the decryption operation. This function is also\n *\t\t responsible for checking the authentication tag size for\n *\t\t validity.\n * @setkey: see struct ablkcipher_alg\n * @encrypt: see struct ablkcipher_alg\n * @decrypt: see struct ablkcipher_alg\n * @givencrypt: see struct ablkcipher_alg\n * @givdecrypt: see struct ablkcipher_alg\n * @geniv: see struct ablkcipher_alg\n * @ivsize: see struct ablkcipher_alg\n *\n * All fields except @givencrypt , @givdecrypt , @geniv and @ivsize are\n * mandatory and must be filled.\n */\nstruct aead_alg {\n\tint (*setkey)(struct crypto_aead *tfm, const u8 *key,\n\t              unsigned int keylen);\n\tint (*setauthsize)(struct crypto_aead *tfm, unsigned int authsize);\n\tint (*encrypt)(struct aead_request *req);\n\tint (*decrypt)(struct aead_request *req);\n\tint (*givencrypt)(struct aead_givcrypt_request *req);\n\tint (*givdecrypt)(struct aead_givcrypt_request *req);\n\n\tconst char *geniv;\n\n\tunsigned int ivsize;\n\tunsigned int maxauthsize;\n};\n\n/**\n * struct blkcipher_alg - synchronous block cipher definition\n * @min_keysize: see struct ablkcipher_alg\n * @max_keysize: see struct ablkcipher_alg\n * @setkey: see struct ablkcipher_alg\n * @encrypt: see struct ablkcipher_alg\n * @decrypt: see struct ablkcipher_alg\n * @geniv: see struct ablkcipher_alg\n * @ivsize: see struct ablkcipher_alg\n *\n * All fields except @geniv and @ivsize are mandatory and must be filled.\n */\nstruct blkcipher_alg {\n\tint (*setkey)(struct crypto_tfm *tfm, const u8 *key,\n\t              unsigned int keylen);\n\tint (*encrypt)(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes);\n\tint (*decrypt)(struct blkcipher_desc *desc,\n\t\t       struct scatterlist *dst, struct scatterlist *src,\n\t\t       unsigned int nbytes);\n\n\tconst char *geniv;\n\n\tunsigned int min_keysize;\n\tunsigned int max_keysize;\n\tunsigned int ivsize;\n};\n\n/**\n * struct cipher_alg - single-block symmetric ciphers definition\n * @cia_min_keysize: Minimum key size supported by the transformation. This is\n *\t\t     the smallest key length supported by this transformation\n *\t\t     algorithm. This must be set to one of the pre-defined\n *\t\t     values as this is not hardware specific. Possible values\n *\t\t     for this field can be found via git grep \"_MIN_KEY_SIZE\"\n *\t\t     include/crypto/\n * @cia_max_keysize: Maximum key size supported by the transformation. This is\n *\t\t    the largest key length supported by this transformation\n *\t\t    algorithm. This must be set to one of the pre-defined values\n *\t\t    as this is not hardware specific. Possible values for this\n *\t\t    field can be found via git grep \"_MAX_KEY_SIZE\"\n *\t\t    include/crypto/\n * @cia_setkey: Set key for the transformation. This function is used to either\n *\t        program a supplied key into the hardware or store the key in the\n *\t        transformation context for programming it later. Note that this\n *\t        function does modify the transformation context. This function\n *\t        can be called multiple times during the existence of the\n *\t        transformation object, so one must make sure the key is properly\n *\t        reprogrammed into the hardware. This function is also\n *\t        responsible for checking the key length for validity.\n * @cia_encrypt: Encrypt a single block. This function is used to encrypt a\n *\t\t single block of data, which must be @cra_blocksize big. This\n *\t\t always operates on a full @cra_blocksize and it is not possible\n *\t\t to encrypt a block of smaller size. The supplied buffers must\n *\t\t therefore also be at least of @cra_blocksize size. Both the\n *\t\t input and output buffers are always aligned to @cra_alignmask.\n *\t\t In case either of the input or output buffer supplied by user\n *\t\t of the crypto API is not aligned to @cra_alignmask, the crypto\n *\t\t API will re-align the buffers. The re-alignment means that a\n *\t\t new buffer will be allocated, the data will be copied into the\n *\t\t new buffer, then the processing will happen on the new buffer,\n *\t\t then the data will be copied back into the original buffer and\n *\t\t finally the new buffer will be freed. In case a software\n *\t\t fallback was put in place in the @cra_init call, this function\n *\t\t might need to use the fallback if the algorithm doesn't support\n *\t\t all of the key sizes. In case the key was stored in\n *\t\t transformation context, the key might need to be re-programmed\n *\t\t into the hardware in this function. This function shall not\n *\t\t modify the transformation context, as this function may be\n *\t\t called in parallel with the same transformation object.\n * @cia_decrypt: Decrypt a single block. This is a reverse counterpart to\n *\t\t @cia_encrypt, and the conditions are exactly the same.\n *\n * All fields are mandatory and must be filled.\n */\nstruct cipher_alg {\n\tunsigned int cia_min_keysize;\n\tunsigned int cia_max_keysize;\n\tint (*cia_setkey)(struct crypto_tfm *tfm, const u8 *key,\n\t                  unsigned int keylen);\n\tvoid (*cia_encrypt)(struct crypto_tfm *tfm, u8 *dst, const u8 *src);\n\tvoid (*cia_decrypt)(struct crypto_tfm *tfm, u8 *dst, const u8 *src);\n};\n\nstruct compress_alg {\n\tint (*coa_compress)(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t    unsigned int slen, u8 *dst, unsigned int *dlen);\n\tint (*coa_decompress)(struct crypto_tfm *tfm, const u8 *src,\n\t\t\t      unsigned int slen, u8 *dst, unsigned int *dlen);\n};\n\n/**\n * struct rng_alg - random number generator definition\n * @rng_make_random: The function defined by this variable obtains a random\n *\t\t     number. The random number generator transform must generate\n *\t\t     the random number out of the context provided with this\n *\t\t     call.\n * @rng_reset: Reset of the random number generator by clearing the entire state.\n *\t       With the invocation of this function call, the random number\n *             generator shall completely reinitialize its state. If the random\n *\t       number generator requires a seed for setting up a new state,\n *\t       the seed must be provided by the consumer while invoking this\n *\t       function. The required size of the seed is defined with\n *\t       @seedsize .\n * @seedsize: The seed size required for a random number generator\n *\t      initialization defined with this variable. Some random number\n *\t      generators like the SP800-90A DRBG does not require a seed as the\n *\t      seeding is implemented internally without the need of support by\n *\t      the consumer. In this case, the seed size is set to zero.\n */\nstruct rng_alg {\n\tint (*rng_make_random)(struct crypto_rng *tfm, u8 *rdata,\n\t\t\t       unsigned int dlen);\n\tint (*rng_reset)(struct crypto_rng *tfm, u8 *seed, unsigned int slen);\n\n\tunsigned int seedsize;\n};\n\n\n#define cra_ablkcipher\tcra_u.ablkcipher\n#define cra_aead\tcra_u.aead\n#define cra_blkcipher\tcra_u.blkcipher\n#define cra_cipher\tcra_u.cipher\n#define cra_compress\tcra_u.compress\n#define cra_rng\t\tcra_u.rng\n\n/**\n * struct crypto_alg - definition of a cryptograpic cipher algorithm\n * @cra_flags: Flags describing this transformation. See include/linux/crypto.h\n *\t       CRYPTO_ALG_* flags for the flags which go in here. Those are\n *\t       used for fine-tuning the description of the transformation\n *\t       algorithm.\n * @cra_blocksize: Minimum block size of this transformation. The size in bytes\n *\t\t   of the smallest possible unit which can be transformed with\n *\t\t   this algorithm. The users must respect this value.\n *\t\t   In case of HASH transformation, it is possible for a smaller\n *\t\t   block than @cra_blocksize to be passed to the crypto API for\n *\t\t   transformation, in case of any other transformation type, an\n * \t\t   error will be returned upon any attempt to transform smaller\n *\t\t   than @cra_blocksize chunks.\n * @cra_ctxsize: Size of the operational context of the transformation. This\n *\t\t value informs the kernel crypto API about the memory size\n *\t\t needed to be allocated for the transformation context.\n * @cra_alignmask: Alignment mask for the input and output data buffer. The data\n *\t\t   buffer containing the input data for the algorithm must be\n *\t\t   aligned to this alignment mask. The data buffer for the\n *\t\t   output data must be aligned to this alignment mask. Note that\n *\t\t   the Crypto API will do the re-alignment in software, but\n *\t\t   only under special conditions and there is a performance hit.\n *\t\t   The re-alignment happens at these occasions for different\n *\t\t   @cra_u types: cipher -- For both input data and output data\n *\t\t   buffer; ahash -- For output hash destination buf; shash --\n *\t\t   For output hash destination buf.\n *\t\t   This is needed on hardware which is flawed by design and\n *\t\t   cannot pick data from arbitrary addresses.\n * @cra_priority: Priority of this transformation implementation. In case\n *\t\t  multiple transformations with same @cra_name are available to\n *\t\t  the Crypto API, the kernel will use the one with highest\n *\t\t  @cra_priority.\n * @cra_name: Generic name (usable by multiple implementations) of the\n *\t      transformation algorithm. This is the name of the transformation\n *\t      itself. This field is used by the kernel when looking up the\n *\t      providers of particular transformation.\n * @cra_driver_name: Unique name of the transformation provider. This is the\n *\t\t     name of the provider of the transformation. This can be any\n *\t\t     arbitrary value, but in the usual case, this contains the\n *\t\t     name of the chip or provider and the name of the\n *\t\t     transformation algorithm.\n * @cra_type: Type of the cryptographic transformation. This is a pointer to\n *\t      struct crypto_type, which implements callbacks common for all\n *\t      trasnformation types. There are multiple options:\n *\t      &crypto_blkcipher_type, &crypto_ablkcipher_type,\n *\t      &crypto_ahash_type, &crypto_aead_type, &crypto_rng_type.\n *\t      This field might be empty. In that case, there are no common\n *\t      callbacks. This is the case for: cipher, compress, shash.\n * @cra_u: Callbacks implementing the transformation. This is a union of\n *\t   multiple structures. Depending on the type of transformation selected\n *\t   by @cra_type and @cra_flags above, the associated structure must be\n *\t   filled with callbacks. This field might be empty. This is the case\n *\t   for ahash, shash.\n * @cra_init: Initialize the cryptographic transformation object. This function\n *\t      is used to initialize the cryptographic transformation object.\n *\t      This function is called only once at the instantiation time, right\n *\t      after the transformation context was allocated. In case the\n *\t      cryptographic hardware has some special requirements which need to\n *\t      be handled by software, this function shall check for the precise\n *\t      requirement of the transformation and put any software fallbacks\n *\t      in place.\n * @cra_exit: Deinitialize the cryptographic transformation object. This is a\n *\t      counterpart to @cra_init, used to remove various changes set in\n *\t      @cra_init.\n * @cra_module: Owner of this transformation implementation. Set to THIS_MODULE\n * @cra_list: internally used\n * @cra_users: internally used\n * @cra_refcnt: internally used\n * @cra_destroy: internally used\n *\n * The struct crypto_alg describes a generic Crypto API algorithm and is common\n * for all of the transformations. Any variable not documented here shall not\n * be used by a cipher implementation as it is internal to the Crypto API.\n */\nstruct crypto_alg {\n\tstruct list_head cra_list;\n\tstruct list_head cra_users;\n\n\tu32 cra_flags;\n\tunsigned int cra_blocksize;\n\tunsigned int cra_ctxsize;\n\tunsigned int cra_alignmask;\n\n\tint cra_priority;\n\tatomic_t cra_refcnt;\n\n\tchar cra_name[CRYPTO_MAX_ALG_NAME];\n\tchar cra_driver_name[CRYPTO_MAX_ALG_NAME];\n\n\tconst struct crypto_type *cra_type;\n\n\tunion {\n\t\tstruct ablkcipher_alg ablkcipher;\n\t\tstruct aead_alg aead;\n\t\tstruct blkcipher_alg blkcipher;\n\t\tstruct cipher_alg cipher;\n\t\tstruct compress_alg compress;\n\t\tstruct rng_alg rng;\n\t} cra_u;\n\n\tint (*cra_init)(struct crypto_tfm *tfm);\n\tvoid (*cra_exit)(struct crypto_tfm *tfm);\n\tvoid (*cra_destroy)(struct crypto_alg *alg);\n\t\n\tstruct module *cra_module;\n};\n\n/*\n * Algorithm registration interface.\n */\nint crypto_register_alg(struct crypto_alg *alg);\nint crypto_unregister_alg(struct crypto_alg *alg);\nint crypto_register_algs(struct crypto_alg *algs, int count);\nint crypto_unregister_algs(struct crypto_alg *algs, int count);\n\n/*\n * Algorithm query interface.\n */\nint crypto_has_alg(const char *name, u32 type, u32 mask);\n\n/*\n * Transforms: user-instantiated objects which encapsulate algorithms\n * and core processing logic.  Managed via crypto_alloc_*() and\n * crypto_free_*(), as well as the various helpers below.\n */\n\nstruct ablkcipher_tfm {\n\tint (*setkey)(struct crypto_ablkcipher *tfm, const u8 *key,\n\t              unsigned int keylen);\n\tint (*encrypt)(struct ablkcipher_request *req);\n\tint (*decrypt)(struct ablkcipher_request *req);\n\tint (*givencrypt)(struct skcipher_givcrypt_request *req);\n\tint (*givdecrypt)(struct skcipher_givcrypt_request *req);\n\n\tstruct crypto_ablkcipher *base;\n\n\tunsigned int ivsize;\n\tunsigned int reqsize;\n};\n\nstruct aead_tfm {\n\tint (*setkey)(struct crypto_aead *tfm, const u8 *key,\n\t              unsigned int keylen);\n\tint (*encrypt)(struct aead_request *req);\n\tint (*decrypt)(struct aead_request *req);\n\tint (*givencrypt)(struct aead_givcrypt_request *req);\n\tint (*givdecrypt)(struct aead_givcrypt_request *req);\n\n\tstruct crypto_aead *base;\n\n\tunsigned int ivsize;\n\tunsigned int authsize;\n\tunsigned int reqsize;\n};\n\nstruct blkcipher_tfm {\n\tvoid *iv;\n\tint (*setkey)(struct crypto_tfm *tfm, const u8 *key,\n\t\t      unsigned int keylen);\n\tint (*encrypt)(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes);\n\tint (*decrypt)(struct blkcipher_desc *desc, struct scatterlist *dst,\n\t\t       struct scatterlist *src, unsigned int nbytes);\n};\n\nstruct cipher_tfm {\n\tint (*cit_setkey)(struct crypto_tfm *tfm,\n\t                  const u8 *key, unsigned int keylen);\n\tvoid (*cit_encrypt_one)(struct crypto_tfm *tfm, u8 *dst, const u8 *src);\n\tvoid (*cit_decrypt_one)(struct crypto_tfm *tfm, u8 *dst, const u8 *src);\n};\n\nstruct hash_tfm {\n\tint (*init)(struct hash_desc *desc);\n\tint (*update)(struct hash_desc *desc,\n\t\t      struct scatterlist *sg, unsigned int nsg);\n\tint (*final)(struct hash_desc *desc, u8 *out);\n\tint (*digest)(struct hash_desc *desc, struct scatterlist *sg,\n\t\t      unsigned int nsg, u8 *out);\n\tint (*setkey)(struct crypto_hash *tfm, const u8 *key,\n\t\t      unsigned int keylen);\n\tunsigned int digestsize;\n};\n\nstruct compress_tfm {\n\tint (*cot_compress)(struct crypto_tfm *tfm,\n\t                    const u8 *src, unsigned int slen,\n\t                    u8 *dst, unsigned int *dlen);\n\tint (*cot_decompress)(struct crypto_tfm *tfm,\n\t                      const u8 *src, unsigned int slen,\n\t                      u8 *dst, unsigned int *dlen);\n};\n\nstruct rng_tfm {\n\tint (*rng_gen_random)(struct crypto_rng *tfm, u8 *rdata,\n\t\t\t      unsigned int dlen);\n\tint (*rng_reset)(struct crypto_rng *tfm, u8 *seed, unsigned int slen);\n};\n\n#define crt_ablkcipher\tcrt_u.ablkcipher\n#define crt_aead\tcrt_u.aead\n#define crt_blkcipher\tcrt_u.blkcipher\n#define crt_cipher\tcrt_u.cipher\n#define crt_hash\tcrt_u.hash\n#define crt_compress\tcrt_u.compress\n#define crt_rng\t\tcrt_u.rng\n\nstruct crypto_tfm {\n\n\tu32 crt_flags;\n\t\n\tunion {\n\t\tstruct ablkcipher_tfm ablkcipher;\n\t\tstruct aead_tfm aead;\n\t\tstruct blkcipher_tfm blkcipher;\n\t\tstruct cipher_tfm cipher;\n\t\tstruct hash_tfm hash;\n\t\tstruct compress_tfm compress;\n\t\tstruct rng_tfm rng;\n\t} crt_u;\n\n\tvoid (*exit)(struct crypto_tfm *tfm);\n\t\n\tstruct crypto_alg *__crt_alg;\n\n\tvoid *__crt_ctx[] CRYPTO_MINALIGN_ATTR;\n};\n\nstruct crypto_ablkcipher {\n\tstruct crypto_tfm base;\n};\n\nstruct crypto_aead {\n\tstruct crypto_tfm base;\n};\n\nstruct crypto_blkcipher {\n\tstruct crypto_tfm base;\n};\n\nstruct crypto_cipher {\n\tstruct crypto_tfm base;\n};\n\nstruct crypto_comp {\n\tstruct crypto_tfm base;\n};\n\nstruct crypto_hash {\n\tstruct crypto_tfm base;\n};\n\nstruct crypto_rng {\n\tstruct crypto_tfm base;\n};\n\nenum {\n\tCRYPTOA_UNSPEC,\n\tCRYPTOA_ALG,\n\tCRYPTOA_TYPE,\n\tCRYPTOA_U32,\n\t__CRYPTOA_MAX,\n};\n\n#define CRYPTOA_MAX (__CRYPTOA_MAX - 1)\n\n/* Maximum number of (rtattr) parameters for each template. */\n#define CRYPTO_MAX_ATTRS 32\n\nstruct crypto_attr_alg {\n\tchar name[CRYPTO_MAX_ALG_NAME];\n};\n\nstruct crypto_attr_type {\n\tu32 type;\n\tu32 mask;\n};\n\nstruct crypto_attr_u32 {\n\tu32 num;\n};\n\n/* \n * Transform user interface.\n */\n \nstruct crypto_tfm *crypto_alloc_base(const char *alg_name, u32 type, u32 mask);\nvoid crypto_destroy_tfm(void *mem, struct crypto_tfm *tfm);\n\nstatic inline void crypto_free_tfm(struct crypto_tfm *tfm)\n{\n\treturn crypto_destroy_tfm(tfm, tfm);\n}\n\nint alg_test(const char *driver, const char *alg, u32 type, u32 mask);\n\n/*\n * Transform helpers which query the underlying algorithm.\n */\nstatic inline const char *crypto_tfm_alg_name(struct crypto_tfm *tfm)\n{\n\treturn tfm->__crt_alg->cra_name;\n}\n\nstatic inline const char *crypto_tfm_alg_driver_name(struct crypto_tfm *tfm)\n{\n\treturn tfm->__crt_alg->cra_driver_name;\n}\n\nstatic inline int crypto_tfm_alg_priority(struct crypto_tfm *tfm)\n{\n\treturn tfm->__crt_alg->cra_priority;\n}\n\nstatic inline u32 crypto_tfm_alg_type(struct crypto_tfm *tfm)\n{\n\treturn tfm->__crt_alg->cra_flags & CRYPTO_ALG_TYPE_MASK;\n}\n\nstatic inline unsigned int crypto_tfm_alg_blocksize(struct crypto_tfm *tfm)\n{\n\treturn tfm->__crt_alg->cra_blocksize;\n}\n\nstatic inline unsigned int crypto_tfm_alg_alignmask(struct crypto_tfm *tfm)\n{\n\treturn tfm->__crt_alg->cra_alignmask;\n}\n\nstatic inline u32 crypto_tfm_get_flags(struct crypto_tfm *tfm)\n{\n\treturn tfm->crt_flags;\n}\n\nstatic inline void crypto_tfm_set_flags(struct crypto_tfm *tfm, u32 flags)\n{\n\ttfm->crt_flags |= flags;\n}\n\nstatic inline void crypto_tfm_clear_flags(struct crypto_tfm *tfm, u32 flags)\n{\n\ttfm->crt_flags &= ~flags;\n}\n\nstatic inline void *crypto_tfm_ctx(struct crypto_tfm *tfm)\n{\n\treturn tfm->__crt_ctx;\n}\n\nstatic inline unsigned int crypto_tfm_ctx_alignment(void)\n{\n\tstruct crypto_tfm *tfm;\n\treturn __alignof__(tfm->__crt_ctx);\n}\n\n/*\n * API wrappers.\n */\nstatic inline struct crypto_ablkcipher *__crypto_ablkcipher_cast(\n\tstruct crypto_tfm *tfm)\n{\n\treturn (struct crypto_ablkcipher *)tfm;\n}\n\nstatic inline u32 crypto_skcipher_type(u32 type)\n{\n\ttype &= ~(CRYPTO_ALG_TYPE_MASK | CRYPTO_ALG_GENIV);\n\ttype |= CRYPTO_ALG_TYPE_BLKCIPHER;\n\treturn type;\n}\n\nstatic inline u32 crypto_skcipher_mask(u32 mask)\n{\n\tmask &= ~(CRYPTO_ALG_TYPE_MASK | CRYPTO_ALG_GENIV);\n\tmask |= CRYPTO_ALG_TYPE_BLKCIPHER_MASK;\n\treturn mask;\n}\n\n/**\n * DOC: Asynchronous Block Cipher API\n *\n * Asynchronous block cipher API is used with the ciphers of type\n * CRYPTO_ALG_TYPE_ABLKCIPHER (listed as type \"ablkcipher\" in /proc/crypto).\n *\n * Asynchronous cipher operations imply that the function invocation for a\n * cipher request returns immediately before the completion of the operation.\n * The cipher request is scheduled as a separate kernel thread and therefore\n * load-balanced on the different CPUs via the process scheduler. To allow\n * the kernel crypto API to inform the caller about the completion of a cipher\n * request, the caller must provide a callback function. That function is\n * invoked with the cipher handle when the request completes.\n *\n * To support the asynchronous operation, additional information than just the\n * cipher handle must be supplied to the kernel crypto API. That additional\n * information is given by filling in the ablkcipher_request data structure.\n *\n * For the asynchronous block cipher API, the state is maintained with the tfm\n * cipher handle. A single tfm can be used across multiple calls and in\n * parallel. For asynchronous block cipher calls, context data supplied and\n * only used by the caller can be referenced the request data structure in\n * addition to the IV used for the cipher request. The maintenance of such\n * state information would be important for a crypto driver implementer to\n * have, because when calling the callback function upon completion of the\n * cipher operation, that callback function may need some information about\n * which operation just finished if it invoked multiple in parallel. This\n * state information is unused by the kernel crypto API.\n */\n\n/**\n * crypto_alloc_ablkcipher() - allocate asynchronous block cipher handle\n * @alg_name: is the cra_name / name or cra_driver_name / driver name of the\n *\t      ablkcipher cipher\n * @type: specifies the type of the cipher\n * @mask: specifies the mask for the cipher\n *\n * Allocate a cipher handle for an ablkcipher. The returned struct\n * crypto_ablkcipher is the cipher handle that is required for any subsequent\n * API invocation for that ablkcipher.\n *\n * Return: allocated cipher handle in case of success; IS_ERR() is true in case\n *\t   of an error, PTR_ERR() returns the error code.\n */\nstruct crypto_ablkcipher *crypto_alloc_ablkcipher(const char *alg_name,\n\t\t\t\t\t\t  u32 type, u32 mask);\n\nstatic inline struct crypto_tfm *crypto_ablkcipher_tfm(\n\tstruct crypto_ablkcipher *tfm)\n{\n\treturn &tfm->base;\n}\n\n/**\n * crypto_free_ablkcipher() - zeroize and free cipher handle\n * @tfm: cipher handle to be freed\n */\nstatic inline void crypto_free_ablkcipher(struct crypto_ablkcipher *tfm)\n{\n\tcrypto_free_tfm(crypto_ablkcipher_tfm(tfm));\n}\n\n/**\n * crypto_has_ablkcipher() - Search for the availability of an ablkcipher.\n * @alg_name: is the cra_name / name or cra_driver_name / driver name of the\n *\t      ablkcipher\n * @type: specifies the type of the cipher\n * @mask: specifies the mask for the cipher\n *\n * Return: true when the ablkcipher is known to the kernel crypto API; false\n *\t   otherwise\n */\nstatic inline int crypto_has_ablkcipher(const char *alg_name, u32 type,\n\t\t\t\t\tu32 mask)\n{\n\treturn crypto_has_alg(alg_name, crypto_skcipher_type(type),\n\t\t\t      crypto_skcipher_mask(mask));\n}\n\nstatic inline struct ablkcipher_tfm *crypto_ablkcipher_crt(\n\tstruct crypto_ablkcipher *tfm)\n{\n\treturn &crypto_ablkcipher_tfm(tfm)->crt_ablkcipher;\n}\n\n/**\n * crypto_ablkcipher_ivsize() - obtain IV size\n * @tfm: cipher handle\n *\n * The size of the IV for the ablkcipher referenced by the cipher handle is\n * returned. This IV size may be zero if the cipher does not need an IV.\n *\n * Return: IV size in bytes\n */\nstatic inline unsigned int crypto_ablkcipher_ivsize(\n\tstruct crypto_ablkcipher *tfm)\n{\n\treturn crypto_ablkcipher_crt(tfm)->ivsize;\n}\n\n/**\n * crypto_ablkcipher_blocksize() - obtain block size of cipher\n * @tfm: cipher handle\n *\n * The block size for the ablkcipher referenced with the cipher handle is\n * returned. The caller may use that information to allocate appropriate\n * memory for the data returned by the encryption or decryption operation\n *\n * Return: block size of cipher\n */\nstatic inline unsigned int crypto_ablkcipher_blocksize(\n\tstruct crypto_ablkcipher *tfm)\n{\n\treturn crypto_tfm_alg_blocksize(crypto_ablkcipher_tfm(tfm));\n}\n\nstatic inline unsigned int crypto_ablkcipher_alignmask(\n\tstruct crypto_ablkcipher *tfm)\n{\n\treturn crypto_tfm_alg_alignmask(crypto_ablkcipher_tfm(tfm));\n}\n\nstatic inline u32 crypto_ablkcipher_get_flags(struct crypto_ablkcipher *tfm)\n{\n\treturn crypto_tfm_get_flags(crypto_ablkcipher_tfm(tfm));\n}\n\nstatic inline void crypto_ablkcipher_set_flags(struct crypto_ablkcipher *tfm,\n\t\t\t\t\t       u32 flags)\n{\n\tcrypto_tfm_set_flags(crypto_ablkcipher_tfm(tfm), flags);\n}\n\nstatic inline void crypto_ablkcipher_clear_flags(struct crypto_ablkcipher *tfm,\n\t\t\t\t\t\t u32 flags)\n{\n\tcrypto_tfm_clear_flags(crypto_ablkcipher_tfm(tfm), flags);\n}\n\n/**\n * crypto_ablkcipher_setkey() - set key for cipher\n * @tfm: cipher handle\n * @key: buffer holding the key\n * @keylen: length of the key in bytes\n *\n * The caller provided key is set for the ablkcipher referenced by the cipher\n * handle.\n *\n * Note, the key length determines the cipher type. Many block ciphers implement\n * different cipher modes depending on the key size, such as AES-128 vs AES-192\n * vs. AES-256. When providing a 16 byte key for an AES cipher handle, AES-128\n * is performed.\n *\n * Return: 0 if the setting of the key was successful; < 0 if an error occurred\n */\nstatic inline int crypto_ablkcipher_setkey(struct crypto_ablkcipher *tfm,\n\t\t\t\t\t   const u8 *key, unsigned int keylen)\n{\n\tstruct ablkcipher_tfm *crt = crypto_ablkcipher_crt(tfm);\n\n\treturn crt->setkey(crt->base, key, keylen);\n}\n\n/**\n * crypto_ablkcipher_reqtfm() - obtain cipher handle from request\n * @req: ablkcipher_request out of which the cipher handle is to be obtained\n *\n * Return the crypto_ablkcipher handle when furnishing an ablkcipher_request\n * data structure.\n *\n * Return: crypto_ablkcipher handle\n */\nstatic inline struct crypto_ablkcipher *crypto_ablkcipher_reqtfm(\n\tstruct ablkcipher_request *req)\n{\n\treturn __crypto_ablkcipher_cast(req->base.tfm);\n}\n\n/**\n * crypto_ablkcipher_encrypt() - encrypt plaintext\n * @req: reference to the ablkcipher_request handle that holds all information\n *\t needed to perform the cipher operation\n *\n * Encrypt plaintext data using the ablkcipher_request handle. That data\n * structure and how it is filled with data is discussed with the\n * ablkcipher_request_* functions.\n *\n * Return: 0 if the cipher operation was successful; < 0 if an error occurred\n */\nstatic inline int crypto_ablkcipher_encrypt(struct ablkcipher_request *req)\n{\n\tstruct ablkcipher_tfm *crt =\n\t\tcrypto_ablkcipher_crt(crypto_ablkcipher_reqtfm(req));\n\treturn crt->encrypt(req);\n}\n\n/**\n * crypto_ablkcipher_decrypt() - decrypt ciphertext\n * @req: reference to the ablkcipher_request handle that holds all information\n *\t needed to perform the cipher operation\n *\n * Decrypt ciphertext data using the ablkcipher_request handle. That data\n * structure and how it is filled with data is discussed with the\n * ablkcipher_request_* functions.\n *\n * Return: 0 if the cipher operation was successful; < 0 if an error occurred\n */\nstatic inline int crypto_ablkcipher_decrypt(struct ablkcipher_request *req)\n{\n\tstruct ablkcipher_tfm *crt =\n\t\tcrypto_ablkcipher_crt(crypto_ablkcipher_reqtfm(req));\n\treturn crt->decrypt(req);\n}\n\n/**\n * DOC: Asynchronous Cipher Request Handle\n *\n * The ablkcipher_request data structure contains all pointers to data\n * required for the asynchronous cipher operation. This includes the cipher\n * handle (which can be used by multiple ablkcipher_request instances), pointer\n * to plaintext and ciphertext, asynchronous callback function, etc. It acts\n * as a handle to the ablkcipher_request_* API calls in a similar way as\n * ablkcipher handle to the crypto_ablkcipher_* API calls.\n */\n\n/**\n * crypto_ablkcipher_reqsize() - obtain size of the request data structure\n * @tfm: cipher handle\n *\n * Return: number of bytes\n */\nstatic inline unsigned int crypto_ablkcipher_reqsize(\n\tstruct crypto_ablkcipher *tfm)\n{\n\treturn crypto_ablkcipher_crt(tfm)->reqsize;\n}\n\n/**\n * ablkcipher_request_set_tfm() - update cipher handle reference in request\n * @req: request handle to be modified\n * @tfm: cipher handle that shall be added to the request handle\n *\n * Allow the caller to replace the existing ablkcipher handle in the request\n * data structure with a different one.\n */\nstatic inline void ablkcipher_request_set_tfm(\n\tstruct ablkcipher_request *req, struct crypto_ablkcipher *tfm)\n{\n\treq->base.tfm = crypto_ablkcipher_tfm(crypto_ablkcipher_crt(tfm)->base);\n}\n\nstatic inline struct ablkcipher_request *ablkcipher_request_cast(\n\tstruct crypto_async_request *req)\n{\n\treturn container_of(req, struct ablkcipher_request, base);\n}\n\n/**\n * ablkcipher_request_alloc() - allocate request data structure\n * @tfm: cipher handle to be registered with the request\n * @gfp: memory allocation flag that is handed to kmalloc by the API call.\n *\n * Allocate the request data structure that must be used with the ablkcipher\n * encrypt and decrypt API calls. During the allocation, the provided ablkcipher\n * handle is registered in the request data structure.\n *\n * Return: allocated request handle in case of success; IS_ERR() is true in case\n *\t   of an error, PTR_ERR() returns the error code.\n */\nstatic inline struct ablkcipher_request *ablkcipher_request_alloc(\n\tstruct crypto_ablkcipher *tfm, gfp_t gfp)\n{\n\tstruct ablkcipher_request *req;\n\n\treq = kmalloc(sizeof(struct ablkcipher_request) +\n\t\t      crypto_ablkcipher_reqsize(tfm), gfp);\n\n\tif (likely(req))\n\t\tablkcipher_request_set_tfm(req, tfm);\n\n\treturn req;\n}\n\n/**\n * ablkcipher_request_free() - zeroize and free request data structure\n * @req: request data structure cipher handle to be freed\n */\nstatic inline void ablkcipher_request_free(struct ablkcipher_request *req)\n{\n\tkzfree(req);\n}\n\n/**\n * ablkcipher_request_set_callback() - set asynchronous callback function\n * @req: request handle\n * @flags: specify zero or an ORing of the flags\n *         CRYPTO_TFM_REQ_MAY_BACKLOG the request queue may back log and\n *\t   increase the wait queue beyond the initial maximum size;\n *\t   CRYPTO_TFM_REQ_MAY_SLEEP the request processing may sleep\n * @compl: callback function pointer to be registered with the request handle\n * @data: The data pointer refers to memory that is not used by the kernel\n *\t  crypto API, but provided to the callback function for it to use. Here,\n *\t  the caller can provide a reference to memory the callback function can\n *\t  operate on. As the callback function is invoked asynchronously to the\n *\t  related functionality, it may need to access data structures of the\n *\t  related functionality which can be referenced using this pointer. The\n *\t  callback function can access the memory via the \"data\" field in the\n *\t  crypto_async_request data structure provided to the callback function.\n *\n * This function allows setting the callback function that is triggered once the\n * cipher operation completes.\n *\n * The callback function is registered with the ablkcipher_request handle and\n * must comply with the following template:\n *\n *\tvoid callback_function(struct crypto_async_request *req, int error)\n */\nstatic inline void ablkcipher_request_set_callback(\n\tstruct ablkcipher_request *req,\n\tu32 flags, crypto_completion_t compl, void *data)\n{\n\treq->base.complete = compl;\n\treq->base.data = data;\n\treq->base.flags = flags;\n}\n\n/**\n * ablkcipher_request_set_crypt() - set data buffers\n * @req: request handle\n * @src: source scatter / gather list\n * @dst: destination scatter / gather list\n * @nbytes: number of bytes to process from @src\n * @iv: IV for the cipher operation which must comply with the IV size defined\n *      by crypto_ablkcipher_ivsize\n *\n * This function allows setting of the source data and destination data\n * scatter / gather lists.\n *\n * For encryption, the source is treated as the plaintext and the\n * destination is the ciphertext. For a decryption operation, the use is\n * reversed: the source is the ciphertext and the destination is the plaintext.\n */\nstatic inline void ablkcipher_request_set_crypt(\n\tstruct ablkcipher_request *req,\n\tstruct scatterlist *src, struct scatterlist *dst,\n\tunsigned int nbytes, void *iv)\n{\n\treq->src = src;\n\treq->dst = dst;\n\treq->nbytes = nbytes;\n\treq->info = iv;\n}\n\n/**\n * DOC: Authenticated Encryption With Associated Data (AEAD) Cipher API\n *\n * The AEAD cipher API is used with the ciphers of type CRYPTO_ALG_TYPE_AEAD\n * (listed as type \"aead\" in /proc/crypto)\n *\n * The most prominent examples for this type of encryption is GCM and CCM.\n * However, the kernel supports other types of AEAD ciphers which are defined\n * with the following cipher string:\n *\n *\tauthenc(keyed message digest, block cipher)\n *\n * For example: authenc(hmac(sha256), cbc(aes))\n *\n * The example code provided for the asynchronous block cipher operation\n * applies here as well. Naturally all *ablkcipher* symbols must be exchanged\n * the *aead* pendants discussed in the following. In addtion, for the AEAD\n * operation, the aead_request_set_assoc function must be used to set the\n * pointer to the associated data memory location before performing the\n * encryption or decryption operation. In case of an encryption, the associated\n * data memory is filled during the encryption operation. For decryption, the\n * associated data memory must contain data that is used to verify the integrity\n * of the decrypted data. Another deviation from the asynchronous block cipher\n * operation is that the caller should explicitly check for -EBADMSG of the\n * crypto_aead_decrypt. That error indicates an authentication error, i.e.\n * a breach in the integrity of the message. In essence, that -EBADMSG error\n * code is the key bonus an AEAD cipher has over \"standard\" block chaining\n * modes.\n */\n\nstatic inline struct crypto_aead *__crypto_aead_cast(struct crypto_tfm *tfm)\n{\n\treturn (struct crypto_aead *)tfm;\n}\n\n/**\n * crypto_alloc_aead() - allocate AEAD cipher handle\n * @alg_name: is the cra_name / name or cra_driver_name / driver name of the\n *\t     AEAD cipher\n * @type: specifies the type of the cipher\n * @mask: specifies the mask for the cipher\n *\n * Allocate a cipher handle for an AEAD. The returned struct\n * crypto_aead is the cipher handle that is required for any subsequent\n * API invocation for that AEAD.\n *\n * Return: allocated cipher handle in case of success; IS_ERR() is true in case\n *\t   of an error, PTR_ERR() returns the error code.\n */\nstruct crypto_aead *crypto_alloc_aead(const char *alg_name, u32 type, u32 mask);\n\nstatic inline struct crypto_tfm *crypto_aead_tfm(struct crypto_aead *tfm)\n{\n\treturn &tfm->base;\n}\n\n/**\n * crypto_free_aead() - zeroize and free aead handle\n * @tfm: cipher handle to be freed\n */\nstatic inline void crypto_free_aead(struct crypto_aead *tfm)\n{\n\tcrypto_free_tfm(crypto_aead_tfm(tfm));\n}\n\nstatic inline struct aead_tfm *crypto_aead_crt(struct crypto_aead *tfm)\n{\n\treturn &crypto_aead_tfm(tfm)->crt_aead;\n}\n\n/**\n * crypto_aead_ivsize() - obtain IV size\n * @tfm: cipher handle\n *\n * The size of the IV for the aead referenced by the cipher handle is\n * returned. This IV size may be zero if the cipher does not need an IV.\n *\n * Return: IV size in bytes\n */\nstatic inline unsigned int crypto_aead_ivsize(struct crypto_aead *tfm)\n{\n\treturn crypto_aead_crt(tfm)->ivsize;\n}\n\n/**\n * crypto_aead_authsize() - obtain maximum authentication data size\n * @tfm: cipher handle\n *\n * The maximum size of the authentication data for the AEAD cipher referenced\n * by the AEAD cipher handle is returned. The authentication data size may be\n * zero if the cipher implements a hard-coded maximum.\n *\n * The authentication data may also be known as \"tag value\".\n *\n * Return: authentication data size / tag size in bytes\n */\nstatic inline unsigned int crypto_aead_authsize(struct crypto_aead *tfm)\n{\n\treturn crypto_aead_crt(tfm)->authsize;\n}\n\n/**\n * crypto_aead_blocksize() - obtain block size of cipher\n * @tfm: cipher handle\n *\n * The block size for the AEAD referenced with the cipher handle is returned.\n * The caller may use that information to allocate appropriate memory for the\n * data returned by the encryption or decryption operation\n *\n * Return: block size of cipher\n */\nstatic inline unsigned int crypto_aead_blocksize(struct crypto_aead *tfm)\n{\n\treturn crypto_tfm_alg_blocksize(crypto_aead_tfm(tfm));\n}\n\nstatic inline unsigned int crypto_aead_alignmask(struct crypto_aead *tfm)\n{\n\treturn crypto_tfm_alg_alignmask(crypto_aead_tfm(tfm));\n}\n\nstatic inline u32 crypto_aead_get_flags(struct crypto_aead *tfm)\n{\n\treturn crypto_tfm_get_flags(crypto_aead_tfm(tfm));\n}\n\nstatic inline void crypto_aead_set_flags(struct crypto_aead *tfm, u32 flags)\n{\n\tcrypto_tfm_set_flags(crypto_aead_tfm(tfm), flags);\n}\n\nstatic inline void crypto_aead_clear_flags(struct crypto_aead *tfm, u32 flags)\n{\n\tcrypto_tfm_clear_flags(crypto_aead_tfm(tfm), flags);\n}\n\n/**\n * crypto_aead_setkey() - set key for cipher\n * @tfm: cipher handle\n * @key: buffer holding the key\n * @keylen: length of the key in bytes\n *\n * The caller provided key is set for the AEAD referenced by the cipher\n * handle.\n *\n * Note, the key length determines the cipher type. Many block ciphers implement\n * different cipher modes depending on the key size, such as AES-128 vs AES-192\n * vs. AES-256. When providing a 16 byte key for an AES cipher handle, AES-128\n * is performed.\n *\n * Return: 0 if the setting of the key was successful; < 0 if an error occurred\n */\nstatic inline int crypto_aead_setkey(struct crypto_aead *tfm, const u8 *key,\n\t\t\t\t     unsigned int keylen)\n{\n\tstruct aead_tfm *crt = crypto_aead_crt(tfm);\n\n\treturn crt->setkey(crt->base, key, keylen);\n}\n\n/**\n * crypto_aead_setauthsize() - set authentication data size\n * @tfm: cipher handle\n * @authsize: size of the authentication data / tag in bytes\n *\n * Set the authentication data size / tag size. AEAD requires an authentication\n * tag (or MAC) in addition to the associated data.\n *\n * Return: 0 if the setting of the key was successful; < 0 if an error occurred\n */\nint crypto_aead_setauthsize(struct crypto_aead *tfm, unsigned int authsize);\n\nstatic inline struct crypto_aead *crypto_aead_reqtfm(struct aead_request *req)\n{\n\treturn __crypto_aead_cast(req->base.tfm);\n}\n\n/**\n * crypto_aead_encrypt() - encrypt plaintext\n * @req: reference to the aead_request handle that holds all information\n *\t needed to perform the cipher operation\n *\n * Encrypt plaintext data using the aead_request handle. That data structure\n * and how it is filled with data is discussed with the aead_request_*\n * functions.\n *\n * IMPORTANT NOTE The encryption operation creates the authentication data /\n *\t\t  tag. That data is concatenated with the created ciphertext.\n *\t\t  The ciphertext memory size is therefore the given number of\n *\t\t  block cipher blocks + the size defined by the\n *\t\t  crypto_aead_setauthsize invocation. The caller must ensure\n *\t\t  that sufficient memory is available for the ciphertext and\n *\t\t  the authentication tag.\n *\n * Return: 0 if the cipher operation was successful; < 0 if an error occurred\n */\nstatic inline int crypto_aead_encrypt(struct aead_request *req)\n{\n\treturn crypto_aead_crt(crypto_aead_reqtfm(req))->encrypt(req);\n}\n\n/**\n * crypto_aead_decrypt() - decrypt ciphertext\n * @req: reference to the ablkcipher_request handle that holds all information\n *\t needed to perform the cipher operation\n *\n * Decrypt ciphertext data using the aead_request handle. That data structure\n * and how it is filled with data is discussed with the aead_request_*\n * functions.\n *\n * IMPORTANT NOTE The caller must concatenate the ciphertext followed by the\n *\t\t  authentication data / tag. That authentication data / tag\n *\t\t  must have the size defined by the crypto_aead_setauthsize\n *\t\t  invocation.\n *\n *\n * Return: 0 if the cipher operation was successful; -EBADMSG: The AEAD\n *\t   cipher operation performs the authentication of the data during the\n *\t   decryption operation. Therefore, the function returns this error if\n *\t   the authentication of the ciphertext was unsuccessful (i.e. the\n *\t   integrity of the ciphertext or the associated data was violated);\n *\t   < 0 if an error occurred.\n */\nstatic inline int crypto_aead_decrypt(struct aead_request *req)\n{\n\treturn crypto_aead_crt(crypto_aead_reqtfm(req))->decrypt(req);\n}\n\n/**\n * DOC: Asynchronous AEAD Request Handle\n *\n * The aead_request data structure contains all pointers to data required for\n * the AEAD cipher operation. This includes the cipher handle (which can be\n * used by multiple aead_request instances), pointer to plaintext and\n * ciphertext, asynchronous callback function, etc. It acts as a handle to the\n * aead_request_* API calls in a similar way as AEAD handle to the\n * crypto_aead_* API calls.\n */\n\n/**\n * crypto_aead_reqsize() - obtain size of the request data structure\n * @tfm: cipher handle\n *\n * Return: number of bytes\n */\nstatic inline unsigned int crypto_aead_reqsize(struct crypto_aead *tfm)\n{\n\treturn crypto_aead_crt(tfm)->reqsize;\n}\n\n/**\n * aead_request_set_tfm() - update cipher handle reference in request\n * @req: request handle to be modified\n * @tfm: cipher handle that shall be added to the request handle\n *\n * Allow the caller to replace the existing aead handle in the request\n * data structure with a different one.\n */\nstatic inline void aead_request_set_tfm(struct aead_request *req,\n\t\t\t\t\tstruct crypto_aead *tfm)\n{\n\treq->base.tfm = crypto_aead_tfm(crypto_aead_crt(tfm)->base);\n}\n\n/**\n * aead_request_alloc() - allocate request data structure\n * @tfm: cipher handle to be registered with the request\n * @gfp: memory allocation flag that is handed to kmalloc by the API call.\n *\n * Allocate the request data structure that must be used with the AEAD\n * encrypt and decrypt API calls. During the allocation, the provided aead\n * handle is registered in the request data structure.\n *\n * Return: allocated request handle in case of success; IS_ERR() is true in case\n *\t   of an error, PTR_ERR() returns the error code.\n */\nstatic inline struct aead_request *aead_request_alloc(struct crypto_aead *tfm,\n\t\t\t\t\t\t      gfp_t gfp)\n{\n\tstruct aead_request *req;\n\n\treq = kmalloc(sizeof(*req) + crypto_aead_reqsize(tfm), gfp);\n\n\tif (likely(req))\n\t\taead_request_set_tfm(req, tfm);\n\n\treturn req;\n}\n\n/**\n * aead_request_free() - zeroize and free request data structure\n * @req: request data structure cipher handle to be freed\n */\nstatic inline void aead_request_free(struct aead_request *req)\n{\n\tkzfree(req);\n}\n\n/**\n * aead_request_set_callback() - set asynchronous callback function\n * @req: request handle\n * @flags: specify zero or an ORing of the flags\n *\t   CRYPTO_TFM_REQ_MAY_BACKLOG the request queue may back log and\n *\t   increase the wait queue beyond the initial maximum size;\n *\t   CRYPTO_TFM_REQ_MAY_SLEEP the request processing may sleep\n * @compl: callback function pointer to be registered with the request handle\n * @data: The data pointer refers to memory that is not used by the kernel\n *\t  crypto API, but provided to the callback function for it to use. Here,\n *\t  the caller can provide a reference to memory the callback function can\n *\t  operate on. As the callback function is invoked asynchronously to the\n *\t  related functionality, it may need to access data structures of the\n *\t  related functionality which can be referenced using this pointer. The\n *\t  callback function can access the memory via the \"data\" field in the\n *\t  crypto_async_request data structure provided to the callback function.\n *\n * Setting the callback function that is triggered once the cipher operation\n * completes\n *\n * The callback function is registered with the aead_request handle and\n * must comply with the following template:\n *\n *\tvoid callback_function(struct crypto_async_request *req, int error)\n */\nstatic inline void aead_request_set_callback(struct aead_request *req,\n\t\t\t\t\t     u32 flags,\n\t\t\t\t\t     crypto_completion_t compl,\n\t\t\t\t\t     void *data)\n{\n\treq->base.complete = compl;\n\treq->base.data = data;\n\treq->base.flags = flags;\n}\n\n/**\n * aead_request_set_crypt - set data buffers\n * @req: request handle\n * @src: source scatter / gather list\n * @dst: destination scatter / gather list\n * @cryptlen: number of bytes to process from @src\n * @iv: IV for the cipher operation which must comply with the IV size defined\n *      by crypto_aead_ivsize()\n *\n * Setting the source data and destination data scatter / gather lists.\n *\n * For encryption, the source is treated as the plaintext and the\n * destination is the ciphertext. For a decryption operation, the use is\n * reversed: the source is the ciphertext and the destination is the plaintext.\n *\n * IMPORTANT NOTE AEAD requires an authentication tag (MAC). For decryption,\n *\t\t  the caller must concatenate the ciphertext followed by the\n *\t\t  authentication tag and provide the entire data stream to the\n *\t\t  decryption operation (i.e. the data length used for the\n *\t\t  initialization of the scatterlist and the data length for the\n *\t\t  decryption operation is identical). For encryption, however,\n *\t\t  the authentication tag is created while encrypting the data.\n *\t\t  The destination buffer must hold sufficient space for the\n *\t\t  ciphertext and the authentication tag while the encryption\n *\t\t  invocation must only point to the plaintext data size. The\n *\t\t  following code snippet illustrates the memory usage\n *\t\t  buffer = kmalloc(ptbuflen + (enc ? authsize : 0));\n *\t\t  sg_init_one(&sg, buffer, ptbuflen + (enc ? authsize : 0));\n *\t\t  aead_request_set_crypt(req, &sg, &sg, ptbuflen, iv);\n */\nstatic inline void aead_request_set_crypt(struct aead_request *req,\n\t\t\t\t\t  struct scatterlist *src,\n\t\t\t\t\t  struct scatterlist *dst,\n\t\t\t\t\t  unsigned int cryptlen, u8 *iv)\n{\n\treq->src = src;\n\treq->dst = dst;\n\treq->cryptlen = cryptlen;\n\treq->iv = iv;\n}\n\n/**\n * aead_request_set_assoc() - set the associated data scatter / gather list\n * @req: request handle\n * @assoc: associated data scatter / gather list\n * @assoclen: number of bytes to process from @assoc\n *\n * For encryption, the memory is filled with the associated data. For\n * decryption, the memory must point to the associated data.\n */\nstatic inline void aead_request_set_assoc(struct aead_request *req,\n\t\t\t\t\t  struct scatterlist *assoc,\n\t\t\t\t\t  unsigned int assoclen)\n{\n\treq->assoc = assoc;\n\treq->assoclen = assoclen;\n}\n\n/**\n * DOC: Synchronous Block Cipher API\n *\n * The synchronous block cipher API is used with the ciphers of type\n * CRYPTO_ALG_TYPE_BLKCIPHER (listed as type \"blkcipher\" in /proc/crypto)\n *\n * Synchronous calls, have a context in the tfm. But since a single tfm can be\n * used in multiple calls and in parallel, this info should not be changeable\n * (unless a lock is used). This applies, for example, to the symmetric key.\n * However, the IV is changeable, so there is an iv field in blkcipher_tfm\n * structure for synchronous blkcipher api. So, its the only state info that can\n * be kept for synchronous calls without using a big lock across a tfm.\n *\n * The block cipher API allows the use of a complete cipher, i.e. a cipher\n * consisting of a template (a block chaining mode) and a single block cipher\n * primitive (e.g. AES).\n *\n * The plaintext data buffer and the ciphertext data buffer are pointed to\n * by using scatter/gather lists. The cipher operation is performed\n * on all segments of the provided scatter/gather lists.\n *\n * The kernel crypto API supports a cipher operation \"in-place\" which means that\n * the caller may provide the same scatter/gather list for the plaintext and\n * cipher text. After the completion of the cipher operation, the plaintext\n * data is replaced with the ciphertext data in case of an encryption and vice\n * versa for a decryption. The caller must ensure that the scatter/gather lists\n * for the output data point to sufficiently large buffers, i.e. multiples of\n * the block size of the cipher.\n */\n\nstatic inline struct crypto_blkcipher *__crypto_blkcipher_cast(\n\tstruct crypto_tfm *tfm)\n{\n\treturn (struct crypto_blkcipher *)tfm;\n}\n\nstatic inline struct crypto_blkcipher *crypto_blkcipher_cast(\n\tstruct crypto_tfm *tfm)\n{\n\tBUG_ON(crypto_tfm_alg_type(tfm) != CRYPTO_ALG_TYPE_BLKCIPHER);\n\treturn __crypto_blkcipher_cast(tfm);\n}\n\n/**\n * crypto_alloc_blkcipher() - allocate synchronous block cipher handle\n * @alg_name: is the cra_name / name or cra_driver_name / driver name of the\n *\t      blkcipher cipher\n * @type: specifies the type of the cipher\n * @mask: specifies the mask for the cipher\n *\n * Allocate a cipher handle for a block cipher. The returned struct\n * crypto_blkcipher is the cipher handle that is required for any subsequent\n * API invocation for that block cipher.\n *\n * Return: allocated cipher handle in case of success; IS_ERR() is true in case\n *\t   of an error, PTR_ERR() returns the error code.\n */\nstatic inline struct crypto_blkcipher *crypto_alloc_blkcipher(\n\tconst char *alg_name, u32 type, u32 mask)\n{\n\ttype &= ~CRYPTO_ALG_TYPE_MASK;\n\ttype |= CRYPTO_ALG_TYPE_BLKCIPHER;\n\tmask |= CRYPTO_ALG_TYPE_MASK;\n\n\treturn __crypto_blkcipher_cast(crypto_alloc_base(alg_name, type, mask));\n}\n\nstatic inline struct crypto_tfm *crypto_blkcipher_tfm(\n\tstruct crypto_blkcipher *tfm)\n{\n\treturn &tfm->base;\n}\n\n/**\n * crypto_free_blkcipher() - zeroize and free the block cipher handle\n * @tfm: cipher handle to be freed\n */\nstatic inline void crypto_free_blkcipher(struct crypto_blkcipher *tfm)\n{\n\tcrypto_free_tfm(crypto_blkcipher_tfm(tfm));\n}\n\n/**\n * crypto_has_blkcipher() - Search for the availability of a block cipher\n * @alg_name: is the cra_name / name or cra_driver_name / driver name of the\n *\t      block cipher\n * @type: specifies the type of the cipher\n * @mask: specifies the mask for the cipher\n *\n * Return: true when the block cipher is known to the kernel crypto API; false\n *\t   otherwise\n */\nstatic inline int crypto_has_blkcipher(const char *alg_name, u32 type, u32 mask)\n{\n\ttype &= ~CRYPTO_ALG_TYPE_MASK;\n\ttype |= CRYPTO_ALG_TYPE_BLKCIPHER;\n\tmask |= CRYPTO_ALG_TYPE_MASK;\n\n\treturn crypto_has_alg(alg_name, type, mask);\n}\n\n/**\n * crypto_blkcipher_name() - return the name / cra_name from the cipher handle\n * @tfm: cipher handle\n *\n * Return: The character string holding the name of the cipher\n */\nstatic inline const char *crypto_blkcipher_name(struct crypto_blkcipher *tfm)\n{\n\treturn crypto_tfm_alg_name(crypto_blkcipher_tfm(tfm));\n}\n\nstatic inline struct blkcipher_tfm *crypto_blkcipher_crt(\n\tstruct crypto_blkcipher *tfm)\n{\n\treturn &crypto_blkcipher_tfm(tfm)->crt_blkcipher;\n}\n\nstatic inline struct blkcipher_alg *crypto_blkcipher_alg(\n\tstruct crypto_blkcipher *tfm)\n{\n\treturn &crypto_blkcipher_tfm(tfm)->__crt_alg->cra_blkcipher;\n}\n\n/**\n * crypto_blkcipher_ivsize() - obtain IV size\n * @tfm: cipher handle\n *\n * The size of the IV for the block cipher referenced by the cipher handle is\n * returned. This IV size may be zero if the cipher does not need an IV.\n *\n * Return: IV size in bytes\n */\nstatic inline unsigned int crypto_blkcipher_ivsize(struct crypto_blkcipher *tfm)\n{\n\treturn crypto_blkcipher_alg(tfm)->ivsize;\n}\n\n/**\n * crypto_blkcipher_blocksize() - obtain block size of cipher\n * @tfm: cipher handle\n *\n * The block size for the block cipher referenced with the cipher handle is\n * returned. The caller may use that information to allocate appropriate\n * memory for the data returned by the encryption or decryption operation.\n *\n * Return: block size of cipher\n */\nstatic inline unsigned int crypto_blkcipher_blocksize(\n\tstruct crypto_blkcipher *tfm)\n{\n\treturn crypto_tfm_alg_blocksize(crypto_blkcipher_tfm(tfm));\n}\n\nstatic inline unsigned int crypto_blkcipher_alignmask(\n\tstruct crypto_blkcipher *tfm)\n{\n\treturn crypto_tfm_alg_alignmask(crypto_blkcipher_tfm(tfm));\n}\n\nstatic inline u32 crypto_blkcipher_get_flags(struct crypto_blkcipher *tfm)\n{\n\treturn crypto_tfm_get_flags(crypto_blkcipher_tfm(tfm));\n}\n\nstatic inline void crypto_blkcipher_set_flags(struct crypto_blkcipher *tfm,\n\t\t\t\t\t      u32 flags)\n{\n\tcrypto_tfm_set_flags(crypto_blkcipher_tfm(tfm), flags);\n}\n\nstatic inline void crypto_blkcipher_clear_flags(struct crypto_blkcipher *tfm,\n\t\t\t\t\t\tu32 flags)\n{\n\tcrypto_tfm_clear_flags(crypto_blkcipher_tfm(tfm), flags);\n}\n\n/**\n * crypto_blkcipher_setkey() - set key for cipher\n * @tfm: cipher handle\n * @key: buffer holding the key\n * @keylen: length of the key in bytes\n *\n * The caller provided key is set for the block cipher referenced by the cipher\n * handle.\n *\n * Note, the key length determines the cipher type. Many block ciphers implement\n * different cipher modes depending on the key size, such as AES-128 vs AES-192\n * vs. AES-256. When providing a 16 byte key for an AES cipher handle, AES-128\n * is performed.\n *\n * Return: 0 if the setting of the key was successful; < 0 if an error occurred\n */\nstatic inline int crypto_blkcipher_setkey(struct crypto_blkcipher *tfm,\n\t\t\t\t\t  const u8 *key, unsigned int keylen)\n{\n\treturn crypto_blkcipher_crt(tfm)->setkey(crypto_blkcipher_tfm(tfm),\n\t\t\t\t\t\t key, keylen);\n}\n\n/**\n * crypto_blkcipher_encrypt() - encrypt plaintext\n * @desc: reference to the block cipher handle with meta data\n * @dst: scatter/gather list that is filled by the cipher operation with the\n *\tciphertext\n * @src: scatter/gather list that holds the plaintext\n * @nbytes: number of bytes of the plaintext to encrypt.\n *\n * Encrypt plaintext data using the IV set by the caller with a preceding\n * call of crypto_blkcipher_set_iv.\n *\n * The blkcipher_desc data structure must be filled by the caller and can\n * reside on the stack. The caller must fill desc as follows: desc.tfm is filled\n * with the block cipher handle; desc.flags is filled with either\n * CRYPTO_TFM_REQ_MAY_SLEEP or 0.\n *\n * Return: 0 if the cipher operation was successful; < 0 if an error occurred\n */\nstatic inline int crypto_blkcipher_encrypt(struct blkcipher_desc *desc,\n\t\t\t\t\t   struct scatterlist *dst,\n\t\t\t\t\t   struct scatterlist *src,\n\t\t\t\t\t   unsigned int nbytes)\n{\n\tdesc->info = crypto_blkcipher_crt(desc->tfm)->iv;\n\treturn crypto_blkcipher_crt(desc->tfm)->encrypt(desc, dst, src, nbytes);\n}\n\n/**\n * crypto_blkcipher_encrypt_iv() - encrypt plaintext with dedicated IV\n * @desc: reference to the block cipher handle with meta data\n * @dst: scatter/gather list that is filled by the cipher operation with the\n *\tciphertext\n * @src: scatter/gather list that holds the plaintext\n * @nbytes: number of bytes of the plaintext to encrypt.\n *\n * Encrypt plaintext data with the use of an IV that is solely used for this\n * cipher operation. Any previously set IV is not used.\n *\n * The blkcipher_desc data structure must be filled by the caller and can\n * reside on the stack. The caller must fill desc as follows: desc.tfm is filled\n * with the block cipher handle; desc.info is filled with the IV to be used for\n * the current operation; desc.flags is filled with either\n * CRYPTO_TFM_REQ_MAY_SLEEP or 0.\n *\n * Return: 0 if the cipher operation was successful; < 0 if an error occurred\n */\nstatic inline int crypto_blkcipher_encrypt_iv(struct blkcipher_desc *desc,\n\t\t\t\t\t      struct scatterlist *dst,\n\t\t\t\t\t      struct scatterlist *src,\n\t\t\t\t\t      unsigned int nbytes)\n{\n\treturn crypto_blkcipher_crt(desc->tfm)->encrypt(desc, dst, src, nbytes);\n}\n\n/**\n * crypto_blkcipher_decrypt() - decrypt ciphertext\n * @desc: reference to the block cipher handle with meta data\n * @dst: scatter/gather list that is filled by the cipher operation with the\n *\tplaintext\n * @src: scatter/gather list that holds the ciphertext\n * @nbytes: number of bytes of the ciphertext to decrypt.\n *\n * Decrypt ciphertext data using the IV set by the caller with a preceding\n * call of crypto_blkcipher_set_iv.\n *\n * The blkcipher_desc data structure must be filled by the caller as documented\n * for the crypto_blkcipher_encrypt call above.\n *\n * Return: 0 if the cipher operation was successful; < 0 if an error occurred\n *\n */\nstatic inline int crypto_blkcipher_decrypt(struct blkcipher_desc *desc,\n\t\t\t\t\t   struct scatterlist *dst,\n\t\t\t\t\t   struct scatterlist *src,\n\t\t\t\t\t   unsigned int nbytes)\n{\n\tdesc->info = crypto_blkcipher_crt(desc->tfm)->iv;\n\treturn crypto_blkcipher_crt(desc->tfm)->decrypt(desc, dst, src, nbytes);\n}\n\n/**\n * crypto_blkcipher_decrypt_iv() - decrypt ciphertext with dedicated IV\n * @desc: reference to the block cipher handle with meta data\n * @dst: scatter/gather list that is filled by the cipher operation with the\n *\tplaintext\n * @src: scatter/gather list that holds the ciphertext\n * @nbytes: number of bytes of the ciphertext to decrypt.\n *\n * Decrypt ciphertext data with the use of an IV that is solely used for this\n * cipher operation. Any previously set IV is not used.\n *\n * The blkcipher_desc data structure must be filled by the caller as documented\n * for the crypto_blkcipher_encrypt_iv call above.\n *\n * Return: 0 if the cipher operation was successful; < 0 if an error occurred\n */\nstatic inline int crypto_blkcipher_decrypt_iv(struct blkcipher_desc *desc,\n\t\t\t\t\t      struct scatterlist *dst,\n\t\t\t\t\t      struct scatterlist *src,\n\t\t\t\t\t      unsigned int nbytes)\n{\n\treturn crypto_blkcipher_crt(desc->tfm)->decrypt(desc, dst, src, nbytes);\n}\n\n/**\n * crypto_blkcipher_set_iv() - set IV for cipher\n * @tfm: cipher handle\n * @src: buffer holding the IV\n * @len: length of the IV in bytes\n *\n * The caller provided IV is set for the block cipher referenced by the cipher\n * handle.\n */\nstatic inline void crypto_blkcipher_set_iv(struct crypto_blkcipher *tfm,\n\t\t\t\t\t   const u8 *src, unsigned int len)\n{\n\tmemcpy(crypto_blkcipher_crt(tfm)->iv, src, len);\n}\n\n/**\n * crypto_blkcipher_get_iv() - obtain IV from cipher\n * @tfm: cipher handle\n * @dst: buffer filled with the IV\n * @len: length of the buffer dst\n *\n * The caller can obtain the IV set for the block cipher referenced by the\n * cipher handle and store it into the user-provided buffer. If the buffer\n * has an insufficient space, the IV is truncated to fit the buffer.\n */\nstatic inline void crypto_blkcipher_get_iv(struct crypto_blkcipher *tfm,\n\t\t\t\t\t   u8 *dst, unsigned int len)\n{\n\tmemcpy(dst, crypto_blkcipher_crt(tfm)->iv, len);\n}\n\n/**\n * DOC: Single Block Cipher API\n *\n * The single block cipher API is used with the ciphers of type\n * CRYPTO_ALG_TYPE_CIPHER (listed as type \"cipher\" in /proc/crypto).\n *\n * Using the single block cipher API calls, operations with the basic cipher\n * primitive can be implemented. These cipher primitives exclude any block\n * chaining operations including IV handling.\n *\n * The purpose of this single block cipher API is to support the implementation\n * of templates or other concepts that only need to perform the cipher operation\n * on one block at a time. Templates invoke the underlying cipher primitive\n * block-wise and process either the input or the output data of these cipher\n * operations.\n */\n\nstatic inline struct crypto_cipher *__crypto_cipher_cast(struct crypto_tfm *tfm)\n{\n\treturn (struct crypto_cipher *)tfm;\n}\n\nstatic inline struct crypto_cipher *crypto_cipher_cast(struct crypto_tfm *tfm)\n{\n\tBUG_ON(crypto_tfm_alg_type(tfm) != CRYPTO_ALG_TYPE_CIPHER);\n\treturn __crypto_cipher_cast(tfm);\n}\n\n/**\n * crypto_alloc_cipher() - allocate single block cipher handle\n * @alg_name: is the cra_name / name or cra_driver_name / driver name of the\n *\t     single block cipher\n * @type: specifies the type of the cipher\n * @mask: specifies the mask for the cipher\n *\n * Allocate a cipher handle for a single block cipher. The returned struct\n * crypto_cipher is the cipher handle that is required for any subsequent API\n * invocation for that single block cipher.\n *\n * Return: allocated cipher handle in case of success; IS_ERR() is true in case\n *\t   of an error, PTR_ERR() returns the error code.\n */\nstatic inline struct crypto_cipher *crypto_alloc_cipher(const char *alg_name,\n\t\t\t\t\t\t\tu32 type, u32 mask)\n{\n\ttype &= ~CRYPTO_ALG_TYPE_MASK;\n\ttype |= CRYPTO_ALG_TYPE_CIPHER;\n\tmask |= CRYPTO_ALG_TYPE_MASK;\n\n\treturn __crypto_cipher_cast(crypto_alloc_base(alg_name, type, mask));\n}\n\nstatic inline struct crypto_tfm *crypto_cipher_tfm(struct crypto_cipher *tfm)\n{\n\treturn &tfm->base;\n}\n\n/**\n * crypto_free_cipher() - zeroize and free the single block cipher handle\n * @tfm: cipher handle to be freed\n */\nstatic inline void crypto_free_cipher(struct crypto_cipher *tfm)\n{\n\tcrypto_free_tfm(crypto_cipher_tfm(tfm));\n}\n\n/**\n * crypto_has_cipher() - Search for the availability of a single block cipher\n * @alg_name: is the cra_name / name or cra_driver_name / driver name of the\n *\t     single block cipher\n * @type: specifies the type of the cipher\n * @mask: specifies the mask for the cipher\n *\n * Return: true when the single block cipher is known to the kernel crypto API;\n *\t   false otherwise\n */\nstatic inline int crypto_has_cipher(const char *alg_name, u32 type, u32 mask)\n{\n\ttype &= ~CRYPTO_ALG_TYPE_MASK;\n\ttype |= CRYPTO_ALG_TYPE_CIPHER;\n\tmask |= CRYPTO_ALG_TYPE_MASK;\n\n\treturn crypto_has_alg(alg_name, type, mask);\n}\n\nstatic inline struct cipher_tfm *crypto_cipher_crt(struct crypto_cipher *tfm)\n{\n\treturn &crypto_cipher_tfm(tfm)->crt_cipher;\n}\n\n/**\n * crypto_cipher_blocksize() - obtain block size for cipher\n * @tfm: cipher handle\n *\n * The block size for the single block cipher referenced with the cipher handle\n * tfm is returned. The caller may use that information to allocate appropriate\n * memory for the data returned by the encryption or decryption operation\n *\n * Return: block size of cipher\n */\nstatic inline unsigned int crypto_cipher_blocksize(struct crypto_cipher *tfm)\n{\n\treturn crypto_tfm_alg_blocksize(crypto_cipher_tfm(tfm));\n}\n\nstatic inline unsigned int crypto_cipher_alignmask(struct crypto_cipher *tfm)\n{\n\treturn crypto_tfm_alg_alignmask(crypto_cipher_tfm(tfm));\n}\n\nstatic inline u32 crypto_cipher_get_flags(struct crypto_cipher *tfm)\n{\n\treturn crypto_tfm_get_flags(crypto_cipher_tfm(tfm));\n}\n\nstatic inline void crypto_cipher_set_flags(struct crypto_cipher *tfm,\n\t\t\t\t\t   u32 flags)\n{\n\tcrypto_tfm_set_flags(crypto_cipher_tfm(tfm), flags);\n}\n\nstatic inline void crypto_cipher_clear_flags(struct crypto_cipher *tfm,\n\t\t\t\t\t     u32 flags)\n{\n\tcrypto_tfm_clear_flags(crypto_cipher_tfm(tfm), flags);\n}\n\n/**\n * crypto_cipher_setkey() - set key for cipher\n * @tfm: cipher handle\n * @key: buffer holding the key\n * @keylen: length of the key in bytes\n *\n * The caller provided key is set for the single block cipher referenced by the\n * cipher handle.\n *\n * Note, the key length determines the cipher type. Many block ciphers implement\n * different cipher modes depending on the key size, such as AES-128 vs AES-192\n * vs. AES-256. When providing a 16 byte key for an AES cipher handle, AES-128\n * is performed.\n *\n * Return: 0 if the setting of the key was successful; < 0 if an error occurred\n */\nstatic inline int crypto_cipher_setkey(struct crypto_cipher *tfm,\n                                       const u8 *key, unsigned int keylen)\n{\n\treturn crypto_cipher_crt(tfm)->cit_setkey(crypto_cipher_tfm(tfm),\n\t\t\t\t\t\t  key, keylen);\n}\n\n/**\n * crypto_cipher_encrypt_one() - encrypt one block of plaintext\n * @tfm: cipher handle\n * @dst: points to the buffer that will be filled with the ciphertext\n * @src: buffer holding the plaintext to be encrypted\n *\n * Invoke the encryption operation of one block. The caller must ensure that\n * the plaintext and ciphertext buffers are at least one block in size.\n */\nstatic inline void crypto_cipher_encrypt_one(struct crypto_cipher *tfm,\n\t\t\t\t\t     u8 *dst, const u8 *src)\n{\n\tcrypto_cipher_crt(tfm)->cit_encrypt_one(crypto_cipher_tfm(tfm),\n\t\t\t\t\t\tdst, src);\n}\n\n/**\n * crypto_cipher_decrypt_one() - decrypt one block of ciphertext\n * @tfm: cipher handle\n * @dst: points to the buffer that will be filled with the plaintext\n * @src: buffer holding the ciphertext to be decrypted\n *\n * Invoke the decryption operation of one block. The caller must ensure that\n * the plaintext and ciphertext buffers are at least one block in size.\n */\nstatic inline void crypto_cipher_decrypt_one(struct crypto_cipher *tfm,\n\t\t\t\t\t     u8 *dst, const u8 *src)\n{\n\tcrypto_cipher_crt(tfm)->cit_decrypt_one(crypto_cipher_tfm(tfm),\n\t\t\t\t\t\tdst, src);\n}\n\n/**\n * DOC: Synchronous Message Digest API\n *\n * The synchronous message digest API is used with the ciphers of type\n * CRYPTO_ALG_TYPE_HASH (listed as type \"hash\" in /proc/crypto)\n */\n\nstatic inline struct crypto_hash *__crypto_hash_cast(struct crypto_tfm *tfm)\n{\n\treturn (struct crypto_hash *)tfm;\n}\n\nstatic inline struct crypto_hash *crypto_hash_cast(struct crypto_tfm *tfm)\n{\n\tBUG_ON((crypto_tfm_alg_type(tfm) ^ CRYPTO_ALG_TYPE_HASH) &\n\t       CRYPTO_ALG_TYPE_HASH_MASK);\n\treturn __crypto_hash_cast(tfm);\n}\n\n/**\n * crypto_alloc_hash() - allocate synchronous message digest handle\n * @alg_name: is the cra_name / name or cra_driver_name / driver name of the\n *\t      message digest cipher\n * @type: specifies the type of the cipher\n * @mask: specifies the mask for the cipher\n *\n * Allocate a cipher handle for a message digest. The returned struct\n * crypto_hash is the cipher handle that is required for any subsequent\n * API invocation for that message digest.\n *\n * Return: allocated cipher handle in case of success; IS_ERR() is true in case\n * of an error, PTR_ERR() returns the error code.\n */\nstatic inline struct crypto_hash *crypto_alloc_hash(const char *alg_name,\n\t\t\t\t\t\t    u32 type, u32 mask)\n{\n\ttype &= ~CRYPTO_ALG_TYPE_MASK;\n\tmask &= ~CRYPTO_ALG_TYPE_MASK;\n\ttype |= CRYPTO_ALG_TYPE_HASH;\n\tmask |= CRYPTO_ALG_TYPE_HASH_MASK;\n\n\treturn __crypto_hash_cast(crypto_alloc_base(alg_name, type, mask));\n}\n\nstatic inline struct crypto_tfm *crypto_hash_tfm(struct crypto_hash *tfm)\n{\n\treturn &tfm->base;\n}\n\n/**\n * crypto_free_hash() - zeroize and free message digest handle\n * @tfm: cipher handle to be freed\n */\nstatic inline void crypto_free_hash(struct crypto_hash *tfm)\n{\n\tcrypto_free_tfm(crypto_hash_tfm(tfm));\n}\n\n/**\n * crypto_has_hash() - Search for the availability of a message digest\n * @alg_name: is the cra_name / name or cra_driver_name / driver name of the\n *\t      message digest cipher\n * @type: specifies the type of the cipher\n * @mask: specifies the mask for the cipher\n *\n * Return: true when the message digest cipher is known to the kernel crypto\n *\t   API; false otherwise\n */\nstatic inline int crypto_has_hash(const char *alg_name, u32 type, u32 mask)\n{\n\ttype &= ~CRYPTO_ALG_TYPE_MASK;\n\tmask &= ~CRYPTO_ALG_TYPE_MASK;\n\ttype |= CRYPTO_ALG_TYPE_HASH;\n\tmask |= CRYPTO_ALG_TYPE_HASH_MASK;\n\n\treturn crypto_has_alg(alg_name, type, mask);\n}\n\nstatic inline struct hash_tfm *crypto_hash_crt(struct crypto_hash *tfm)\n{\n\treturn &crypto_hash_tfm(tfm)->crt_hash;\n}\n\n/**\n * crypto_hash_blocksize() - obtain block size for message digest\n * @tfm: cipher handle\n *\n * The block size for the message digest cipher referenced with the cipher\n * handle is returned.\n *\n * Return: block size of cipher\n */\nstatic inline unsigned int crypto_hash_blocksize(struct crypto_hash *tfm)\n{\n\treturn crypto_tfm_alg_blocksize(crypto_hash_tfm(tfm));\n}\n\nstatic inline unsigned int crypto_hash_alignmask(struct crypto_hash *tfm)\n{\n\treturn crypto_tfm_alg_alignmask(crypto_hash_tfm(tfm));\n}\n\n/**\n * crypto_hash_digestsize() - obtain message digest size\n * @tfm: cipher handle\n *\n * The size for the message digest created by the message digest cipher\n * referenced with the cipher handle is returned.\n *\n * Return: message digest size\n */\nstatic inline unsigned int crypto_hash_digestsize(struct crypto_hash *tfm)\n{\n\treturn crypto_hash_crt(tfm)->digestsize;\n}\n\nstatic inline u32 crypto_hash_get_flags(struct crypto_hash *tfm)\n{\n\treturn crypto_tfm_get_flags(crypto_hash_tfm(tfm));\n}\n\nstatic inline void crypto_hash_set_flags(struct crypto_hash *tfm, u32 flags)\n{\n\tcrypto_tfm_set_flags(crypto_hash_tfm(tfm), flags);\n}\n\nstatic inline void crypto_hash_clear_flags(struct crypto_hash *tfm, u32 flags)\n{\n\tcrypto_tfm_clear_flags(crypto_hash_tfm(tfm), flags);\n}\n\n/**\n * crypto_hash_init() - (re)initialize message digest handle\n * @desc: cipher request handle that to be filled by caller --\n *\t  desc.tfm is filled with the hash cipher handle;\n *\t  desc.flags is filled with either CRYPTO_TFM_REQ_MAY_SLEEP or 0.\n *\n * The call (re-)initializes the message digest referenced by the hash cipher\n * request handle. Any potentially existing state created by previous\n * operations is discarded.\n *\n * Return: 0 if the message digest initialization was successful; < 0 if an\n *\t   error occurred\n */\nstatic inline int crypto_hash_init(struct hash_desc *desc)\n{\n\treturn crypto_hash_crt(desc->tfm)->init(desc);\n}\n\n/**\n * crypto_hash_update() - add data to message digest for processing\n * @desc: cipher request handle\n * @sg: scatter / gather list pointing to the data to be added to the message\n *      digest\n * @nbytes: number of bytes to be processed from @sg\n *\n * Updates the message digest state of the cipher handle pointed to by the\n * hash cipher request handle with the input data pointed to by the\n * scatter/gather list.\n *\n * Return: 0 if the message digest update was successful; < 0 if an error\n *\t   occurred\n */\nstatic inline int crypto_hash_update(struct hash_desc *desc,\n\t\t\t\t     struct scatterlist *sg,\n\t\t\t\t     unsigned int nbytes)\n{\n\treturn crypto_hash_crt(desc->tfm)->update(desc, sg, nbytes);\n}\n\n/**\n * crypto_hash_final() - calculate message digest\n * @desc: cipher request handle\n * @out: message digest output buffer -- The caller must ensure that the out\n *\t buffer has a sufficient size (e.g. by using the crypto_hash_digestsize\n *\t function).\n *\n * Finalize the message digest operation and create the message digest\n * based on all data added to the cipher handle. The message digest is placed\n * into the output buffer.\n *\n * Return: 0 if the message digest creation was successful; < 0 if an error\n *\t   occurred\n */\nstatic inline int crypto_hash_final(struct hash_desc *desc, u8 *out)\n{\n\treturn crypto_hash_crt(desc->tfm)->final(desc, out);\n}\n\n/**\n * crypto_hash_digest() - calculate message digest for a buffer\n * @desc: see crypto_hash_final()\n * @sg: see crypto_hash_update()\n * @nbytes:  see crypto_hash_update()\n * @out: see crypto_hash_final()\n *\n * This function is a \"short-hand\" for the function calls of crypto_hash_init,\n * crypto_hash_update and crypto_hash_final. The parameters have the same\n * meaning as discussed for those separate three functions.\n *\n * Return: 0 if the message digest creation was successful; < 0 if an error\n *\t   occurred\n */\nstatic inline int crypto_hash_digest(struct hash_desc *desc,\n\t\t\t\t     struct scatterlist *sg,\n\t\t\t\t     unsigned int nbytes, u8 *out)\n{\n\treturn crypto_hash_crt(desc->tfm)->digest(desc, sg, nbytes, out);\n}\n\n/**\n * crypto_hash_setkey() - set key for message digest\n * @hash: cipher handle\n * @key: buffer holding the key\n * @keylen: length of the key in bytes\n *\n * The caller provided key is set for the message digest cipher. The cipher\n * handle must point to a keyed hash in order for this function to succeed.\n *\n * Return: 0 if the setting of the key was successful; < 0 if an error occurred\n */\nstatic inline int crypto_hash_setkey(struct crypto_hash *hash,\n\t\t\t\t     const u8 *key, unsigned int keylen)\n{\n\treturn crypto_hash_crt(hash)->setkey(hash, key, keylen);\n}\n\nstatic inline struct crypto_comp *__crypto_comp_cast(struct crypto_tfm *tfm)\n{\n\treturn (struct crypto_comp *)tfm;\n}\n\nstatic inline struct crypto_comp *crypto_comp_cast(struct crypto_tfm *tfm)\n{\n\tBUG_ON((crypto_tfm_alg_type(tfm) ^ CRYPTO_ALG_TYPE_COMPRESS) &\n\t       CRYPTO_ALG_TYPE_MASK);\n\treturn __crypto_comp_cast(tfm);\n}\n\nstatic inline struct crypto_comp *crypto_alloc_comp(const char *alg_name,\n\t\t\t\t\t\t    u32 type, u32 mask)\n{\n\ttype &= ~CRYPTO_ALG_TYPE_MASK;\n\ttype |= CRYPTO_ALG_TYPE_COMPRESS;\n\tmask |= CRYPTO_ALG_TYPE_MASK;\n\n\treturn __crypto_comp_cast(crypto_alloc_base(alg_name, type, mask));\n}\n\nstatic inline struct crypto_tfm *crypto_comp_tfm(struct crypto_comp *tfm)\n{\n\treturn &tfm->base;\n}\n\nstatic inline void crypto_free_comp(struct crypto_comp *tfm)\n{\n\tcrypto_free_tfm(crypto_comp_tfm(tfm));\n}\n\nstatic inline int crypto_has_comp(const char *alg_name, u32 type, u32 mask)\n{\n\ttype &= ~CRYPTO_ALG_TYPE_MASK;\n\ttype |= CRYPTO_ALG_TYPE_COMPRESS;\n\tmask |= CRYPTO_ALG_TYPE_MASK;\n\n\treturn crypto_has_alg(alg_name, type, mask);\n}\n\nstatic inline const char *crypto_comp_name(struct crypto_comp *tfm)\n{\n\treturn crypto_tfm_alg_name(crypto_comp_tfm(tfm));\n}\n\nstatic inline struct compress_tfm *crypto_comp_crt(struct crypto_comp *tfm)\n{\n\treturn &crypto_comp_tfm(tfm)->crt_compress;\n}\n\nstatic inline int crypto_comp_compress(struct crypto_comp *tfm,\n                                       const u8 *src, unsigned int slen,\n                                       u8 *dst, unsigned int *dlen)\n{\n\treturn crypto_comp_crt(tfm)->cot_compress(crypto_comp_tfm(tfm),\n\t\t\t\t\t\t  src, slen, dst, dlen);\n}\n\nstatic inline int crypto_comp_decompress(struct crypto_comp *tfm,\n                                         const u8 *src, unsigned int slen,\n                                         u8 *dst, unsigned int *dlen)\n{\n\treturn crypto_comp_crt(tfm)->cot_decompress(crypto_comp_tfm(tfm),\n\t\t\t\t\t\t    src, slen, dst, dlen);\n}\n\n#endif\t/* _LINUX_CRYPTO_H */\n\n"], "filenames": ["arch/arm/crypto/aes_glue.c", "arch/arm/crypto/sha1_glue.c", "arch/arm/crypto/sha1_neon_glue.c", "arch/arm/crypto/sha512_neon_glue.c", "arch/arm64/crypto/aes-ce-ccm-glue.c", "arch/arm64/crypto/aes-glue.c", "arch/powerpc/crypto/sha1.c", "arch/s390/crypto/aes_s390.c", "arch/s390/crypto/des_s390.c", "arch/s390/crypto/ghash_s390.c", "arch/s390/crypto/sha1_s390.c", "arch/s390/crypto/sha256_s390.c", "arch/s390/crypto/sha512_s390.c", "arch/sparc/crypto/aes_glue.c", "arch/sparc/crypto/camellia_glue.c", "arch/sparc/crypto/crc32c_glue.c", "arch/sparc/crypto/des_glue.c", "arch/sparc/crypto/md5_glue.c", "arch/sparc/crypto/sha1_glue.c", "arch/sparc/crypto/sha256_glue.c", "arch/sparc/crypto/sha512_glue.c", "arch/x86/crypto/aes_glue.c", "arch/x86/crypto/aesni-intel_glue.c", "arch/x86/crypto/blowfish_glue.c", "arch/x86/crypto/camellia_aesni_avx2_glue.c", "arch/x86/crypto/camellia_aesni_avx_glue.c", "arch/x86/crypto/camellia_glue.c", "arch/x86/crypto/cast5_avx_glue.c", "arch/x86/crypto/cast6_avx_glue.c", "arch/x86/crypto/crc32-pclmul_glue.c", "arch/x86/crypto/crc32c-intel_glue.c", "arch/x86/crypto/crct10dif-pclmul_glue.c", "arch/x86/crypto/des3_ede_glue.c", "arch/x86/crypto/ghash-clmulni-intel_glue.c", "arch/x86/crypto/salsa20_glue.c", "arch/x86/crypto/serpent_avx2_glue.c", "arch/x86/crypto/serpent_avx_glue.c", "arch/x86/crypto/serpent_sse2_glue.c", "arch/x86/crypto/sha1_ssse3_glue.c", "arch/x86/crypto/sha256_ssse3_glue.c", "arch/x86/crypto/sha512_ssse3_glue.c", "arch/x86/crypto/twofish_avx_glue.c", "arch/x86/crypto/twofish_glue.c", "arch/x86/crypto/twofish_glue_3way.c", "crypto/842.c", "crypto/aes_generic.c", "crypto/ansi_cprng.c", "crypto/anubis.c", "crypto/api.c", "crypto/arc4.c", "crypto/blowfish_generic.c", "crypto/camellia_generic.c", "crypto/cast5_generic.c", "crypto/cast6_generic.c", "crypto/ccm.c", "crypto/crc32.c", "crypto/crc32c_generic.c", "crypto/crct10dif_generic.c", "crypto/crypto_null.c", "crypto/ctr.c", "crypto/deflate.c", "crypto/des_generic.c", "crypto/fcrypt.c", "crypto/gcm.c", "crypto/ghash-generic.c", "crypto/khazad.c", "crypto/krng.c", "crypto/lz4.c", "crypto/lz4hc.c", "crypto/lzo.c", "crypto/md4.c", "crypto/md5.c", "crypto/michael_mic.c", "crypto/rmd128.c", "crypto/rmd160.c", "crypto/rmd256.c", "crypto/rmd320.c", "crypto/salsa20_generic.c", "crypto/seed.c", "crypto/serpent_generic.c", "crypto/sha1_generic.c", "crypto/sha256_generic.c", "crypto/sha512_generic.c", "crypto/tea.c", "crypto/tgr192.c", "crypto/twofish_generic.c", "crypto/wp512.c", "crypto/zlib.c", "drivers/crypto/padlock-aes.c", "drivers/crypto/padlock-sha.c", "drivers/crypto/qat/qat_common/adf_ctl_drv.c", "drivers/crypto/ux500/cryp/cryp_core.c", "drivers/crypto/ux500/hash/hash_core.c", "drivers/s390/crypto/ap_bus.c", "include/linux/crypto.h"], "buggy_code_start_loc": [96, 174, 197, 304, 297, 41, 157, 982, 622, 163, 106, 146, 89, 502, 325, 179, 535, 188, 183, 240, 225, 69, 1549, 481, 585, 577, 1728, 494, 614, 200, 283, 150, 505, 344, 122, 561, 620, 621, 281, 321, 329, 582, 99, 498, 182, 1477, 479, 706, 219, 168, 141, 1101, 552, 294, 882, 158, 173, 127, 148, 469, 225, 986, 422, 1444, 175, 882, 65, 106, 106, 109, 258, 170, 186, 329, 373, 348, 397, 251, 478, 668, 156, 387, 291, 273, 679, 214, 1170, 380, 566, 596, 54, 1815, 2000, 46, 26], "buggy_code_end_loc": [98, 175, 198, 306, 298, 45, 158, 983, 624, 164, 107, 148, 130, 503, 326, 180, 536, 189, 184, 242, 227, 71, 1550, 483, 587, 579, 1730, 495, 615, 202, 285, 152, 509, 345, 124, 563, 621, 622, 282, 323, 331, 583, 101, 500, 182, 1478, 480, 706, 224, 168, 142, 1102, 553, 295, 884, 158, 174, 128, 151, 470, 226, 987, 422, 1447, 176, 882, 66, 106, 106, 109, 259, 170, 186, 329, 373, 348, 397, 252, 478, 670, 157, 389, 293, 275, 681, 215, 1172, 380, 567, 600, 491, 1817, 2004, 75, 26], "fixing_code_start_loc": [96, 174, 197, 304, 297, 41, 157, 982, 622, 163, 106, 146, 89, 502, 325, 179, 535, 188, 183, 240, 225, 69, 1549, 481, 585, 577, 1728, 494, 614, 200, 283, 150, 505, 344, 122, 561, 620, 621, 281, 321, 329, 582, 99, 498, 183, 1477, 479, 707, 219, 169, 141, 1101, 552, 294, 882, 159, 173, 127, 148, 469, 225, 986, 423, 1444, 175, 883, 65, 107, 107, 110, 258, 171, 187, 330, 374, 349, 398, 251, 479, 668, 156, 387, 291, 273, 679, 214, 1170, 381, 566, 596, 55, 1815, 2000, 47, 27], "fixing_code_end_loc": [98, 175, 198, 306, 298, 45, 158, 983, 624, 164, 107, 148, 130, 503, 326, 180, 536, 189, 184, 242, 227, 71, 1550, 483, 587, 579, 1730, 495, 615, 202, 285, 152, 509, 345, 124, 563, 621, 622, 282, 323, 331, 583, 101, 500, 184, 1478, 480, 708, 224, 170, 142, 1102, 553, 295, 884, 160, 174, 128, 151, 470, 226, 987, 424, 1447, 176, 884, 66, 108, 108, 111, 259, 172, 188, 331, 375, 350, 399, 252, 480, 670, 157, 389, 293, 275, 681, 215, 1172, 382, 567, 600, 492, 1817, 2004, 76, 40], "type": "CWE-269", "message": "The Crypto API in the Linux kernel before 3.18.5 allows local users to load arbitrary kernel modules via a bind system call for an AF_ALG socket with a module name in the salg_name field, a different vulnerability than CVE-2014-9644.", "other": {"cve": {"id": "CVE-2013-7421", "sourceIdentifier": "cve@mitre.org", "published": "2015-03-02T11:59:00.053", "lastModified": "2020-05-19T14:32:00.977", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "The Crypto API in the Linux kernel before 3.18.5 allows local users to load arbitrary kernel modules via a bind system call for an AF_ALG socket with a module name in the salg_name field, a different vulnerability than CVE-2014-9644."}, {"lang": "es", "value": "La API Crypto en el kernel de Linux anterior a 3.18.5 permite a usuarios locales cargar m\u00f3dulos del kernel arbitrarios a trav\u00e9s de una llamada al sistema de enlaces para un socket AF_ALG con un nombre de m\u00f3dulo en el campo salg_name, una vulnerabilidad diferente a CVE-2014-9644."}], "metrics": {"cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:N/I:P/A:N", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "PARTIAL", "availabilityImpact": "NONE", "baseScore": 2.1}, "baseSeverity": "LOW", "exploitabilityScore": 3.9, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-269"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:12.04:*:*:*:lts:*:*:*", "matchCriteriaId": "B6B7CAD7-9D4E-4FDB-88E3-1E583210A01F"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:14.04:*:*:*:lts:*:*:*", "matchCriteriaId": "B5A6F2F3-4894-4392-8296-3B8DD2679084"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:14.10:*:*:*:*:*:*:*", "matchCriteriaId": "49A63F39-30BE-443F-AF10-6245587D3359"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:7.0:*:*:*:*:*:*:*", "matchCriteriaId": "16F59A04-14CF-49E2-9973-645477EA09DA"}, {"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "C11E6FB0-C8C0-4527-9AA0-CB9B316F8F43"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndExcluding": "3.18.5", "matchCriteriaId": "C8C3FC9D-A833-4B7B-865B-54510F1C7EBF"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:oracle:linux:5:-:*:*:*:*:*:*", "matchCriteriaId": "62A2AC02-A933-4E51-810E-5D040B476B7B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:oracle:linux:6:-:*:*:*:*:*:*", "matchCriteriaId": "D7B037A8-72A6-4DFF-94B2-D688A5F6F876"}, {"vulnerable": true, "criteria": "cpe:2.3:o:oracle:linux:7:-:*:*:*:*:*:*", "matchCriteriaId": "44B8FEDF-6CB0-46E9-9AD7-4445B001C158"}]}]}], "references": [{"url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commit;h=5d26a105b5a73e5635eae0629b42fa0a90e07b7b", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "http://rhn.redhat.com/errata/RHSA-2016-0068.html", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "http://www.debian.org/security/2015/dsa-3170", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "http://www.kernel.org/pub/linux/kernel/v3.x/ChangeLog-3.18.5", "source": "cve@mitre.org", "tags": ["Release Notes", "Third Party Advisory"]}, {"url": "http://www.mandriva.com/security/advisories?name=MDVSA-2015:057", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "http://www.mandriva.com/security/advisories?name=MDVSA-2015:058", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "http://www.openwall.com/lists/oss-security/2015/01/24/4", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://www.oracle.com/technetwork/topics/security/linuxbulletinjan2016-2867209.html", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "http://www.oracle.com/technetwork/topics/security/linuxbulletinoct2015-2719645.html", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "http://www.securityfocus.com/bid/72322", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "http://www.ubuntu.com/usn/USN-2513-1", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "http://www.ubuntu.com/usn/USN-2514-1", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "http://www.ubuntu.com/usn/USN-2543-1", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "http://www.ubuntu.com/usn/USN-2544-1", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "http://www.ubuntu.com/usn/USN-2545-1", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "http://www.ubuntu.com/usn/USN-2546-1", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://bugzilla.redhat.com/show_bug.cgi?id=1185469", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Third Party Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/5d26a105b5a73e5635eae0629b42fa0a90e07b7b", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://lkml.org/lkml/2013/3/4/70", "source": "cve@mitre.org", "tags": ["Exploit", "Third Party Advisory"]}, {"url": "https://plus.google.com/+MathiasKrause/posts/PqFCo4bfrWu", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/5d26a105b5a73e5635eae0629b42fa0a90e07b7b"}}
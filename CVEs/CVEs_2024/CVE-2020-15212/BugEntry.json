{"buggy_code": ["/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include <stdint.h>\n\n#include \"tensorflow/lite/c/common.h\"\n#include \"tensorflow/lite/kernels/internal/reference/reference_ops.h\"\n#include \"tensorflow/lite/kernels/internal/tensor.h\"\n#include \"tensorflow/lite/kernels/internal/tensor_ctypes.h\"\n#include \"tensorflow/lite/kernels/kernel_util.h\"\n\nnamespace tflite {\nnamespace ops {\nnamespace builtin {\nnamespace segment_sum {\n\nstatic const int kInputDataTensor = 0;\nstatic const int kInputSegmentIdsTensor = 1;\nstatic const int kOutputTensor = 0;\n\nTfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n                                const TfLiteTensor* data,\n                                const TfLiteTensor* segment_ids,\n                                TfLiteTensor* output) {\n  int max_index = -1;\n  const int segment_id_size = segment_ids->dims->data[0];\n  if (segment_id_size > 0) {\n    max_index = segment_ids->data.i32[segment_id_size - 1];\n  }\n  const int data_rank = NumDimensions(data);\n  TfLiteIntArray* output_shape = TfLiteIntArrayCreate(NumDimensions(data));\n  output_shape->data[0] = max_index + 1;\n  for (int i = 1; i < data_rank; ++i) {\n    output_shape->data[i] = data->dims->data[i];\n  }\n  return context->ResizeTensor(context, output, output_shape);\n}\n\nTfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n  const TfLiteTensor* data = GetInput(context, node, kInputDataTensor);\n  const TfLiteTensor* segment_ids =\n      GetInput(context, node, kInputSegmentIdsTensor);\n  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n\n  TF_LITE_ENSURE(context,\n                 data->type == kTfLiteInt32 || data->type == kTfLiteFloat32);\n  TF_LITE_ENSURE_EQ(context, segment_ids->type, kTfLiteInt32);\n\n  if (!IsConstantTensor(data) || !IsConstantTensor(segment_ids)) {\n    SetTensorToDynamic(output);\n    return kTfLiteOk;\n  }\n\n  return ResizeOutputTensor(context, data, segment_ids, output);\n}\n\nTfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteTensor* data = GetInput(context, node, kInputDataTensor);\n  const TfLiteTensor* segment_ids =\n      GetInput(context, node, kInputSegmentIdsTensor);\n  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n\n  if (IsDynamicTensor(output)) {\n    TF_LITE_ENSURE_OK(context,\n                      ResizeOutputTensor(context, data, segment_ids, output));\n  }\n\n#define TF_LITE_SEGMENT_SUM(dtype)                                      \\\n  reference_ops::SegmentSum<dtype>(                                     \\\n      GetTensorShape(data), GetTensorData<dtype>(data),                 \\\n      GetTensorShape(segment_ids), GetTensorData<int32_t>(segment_ids), \\\n      GetTensorShape(output), GetTensorData<dtype>(output));\n  switch (data->type) {\n    case kTfLiteInt32:\n      TF_LITE_SEGMENT_SUM(int32_t);\n      break;\n    case kTfLiteFloat32:\n      TF_LITE_SEGMENT_SUM(float);\n      break;\n    default:\n      context->ReportError(context,\n                           \"Currently SegmentSum doesn't support type: %s\",\n                           TfLiteTypeGetName(data->type));\n      return kTfLiteError;\n  }\n#undef TF_LITE_SEGMENT_SUM\n  return kTfLiteOk;\n}\n\n}  // namespace segment_sum\n\nTfLiteRegistration* Register_SEGMENT_SUM() {\n  static TfLiteRegistration r = {nullptr, nullptr, segment_sum::Prepare,\n                                 segment_sum::Eval};\n  return &r;\n}\n\n}  // namespace builtin\n}  // namespace ops\n}  // namespace tflite\n", "/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include <stdint.h>\n\n#include <vector>\n\n#include <gtest/gtest.h>\n#include \"tensorflow/lite/kernels/test_util.h\"\n#include \"tensorflow/lite/schema/schema_generated.h\"\n\nnamespace tflite {\nnamespace {\n\nusing ::testing::ElementsAreArray;\n\ntemplate <typename T>\nclass SegmentSumOpModel : public SingleOpModel {\n public:\n  SegmentSumOpModel(const TensorData& data, const TensorData& segment_ids) {\n    data_id_ = AddInput(data);\n    segment_ids_id_ = AddInput(segment_ids);\n    output_id_ = AddOutput(data.type);\n    SetBuiltinOp(BuiltinOperator_SEGMENT_SUM, BuiltinOptions_NONE, 0);\n    BuildInterpreter({GetShape(data_id_), GetShape(segment_ids_id_)});\n  }\n\n  int data() const { return data_id_; }\n  int segment_ids() const { return segment_ids_id_; }\n  std::vector<T> GetOutput() { return ExtractVector<T>(output_id_); }\n  std::vector<int32_t> GetOutputShape() { return GetTensorShape(output_id_); }\n\n protected:\n  int data_id_;\n  int segment_ids_id_;\n  int output_id_;\n};\n\nTEST(SegmentSumOpModelTest, Int32Test_Simple) {\n  SegmentSumOpModel<int32_t> model({TensorType_INT32, {3, 4}},\n                                   {TensorType_INT32, {3}});\n  model.PopulateTensor<int32_t>(model.data(),\n                                {1, 2, 3, 4, 4, 3, 2, 1, 5, 6, 7, 8});\n  model.PopulateTensor<int32_t>(model.segment_ids(), {0, 0, 1});\n  model.Invoke();\n  EXPECT_THAT(model.GetOutput(), ElementsAreArray({5, 5, 5, 5, 5, 6, 7, 8}));\n  EXPECT_THAT(model.GetOutputShape(), ElementsAreArray({2, 4}));\n}\n\nTEST(SegmentSumOpModelTest, Int32Test_OneDimension) {\n  SegmentSumOpModel<int32_t> model({TensorType_INT32, {3}},\n                                   {TensorType_INT32, {3}});\n  model.PopulateTensor<int32_t>(model.data(), {1, 2, 3});\n  model.PopulateTensor<int32_t>(model.segment_ids(), {0, 0, 1});\n  model.Invoke();\n  EXPECT_THAT(model.GetOutput(), ElementsAreArray({3, 3}));\n  EXPECT_THAT(model.GetOutputShape(), ElementsAreArray({2}));\n}\n\nTEST(SegmentSumOpModelTest, Int32Test_ThreeDimensions) {\n  SegmentSumOpModel<int32_t> model({TensorType_INT32, {3, 2, 1}},\n                                   {TensorType_INT32, {3}});\n  model.PopulateTensor<int32_t>(model.data(), {1, 2, 3, 4, 5, 6});\n  model.PopulateTensor<int32_t>(model.segment_ids(), {0, 0, 1});\n  model.Invoke();\n  EXPECT_THAT(model.GetOutput(), ElementsAreArray({4, 6, 5, 6}));\n  EXPECT_THAT(model.GetOutputShape(), ElementsAreArray({2, 2, 1}));\n}\n\nTEST(SegmentSumOpModelTest, Float32Test_Simple) {\n  SegmentSumOpModel<float> model({TensorType_FLOAT32, {3, 4}},\n                                 {TensorType_INT32, {3}});\n  model.PopulateTensor<float>(model.data(),\n                              {1, 2, 3, 4, 4, 3, 2, 1, 5, 6, 7, 8});\n  model.PopulateTensor<int>(model.segment_ids(), {0, 0, 1});\n  model.Invoke();\n  EXPECT_THAT(model.GetOutput(), ElementsAreArray({5.0f, 5.0f, 5.0f, 5.0f, 5.0f,\n                                                   6.0f, 7.0f, 8.0f}));\n  EXPECT_THAT(model.GetOutputShape(), ElementsAreArray({2, 4}));\n}\n\nTEST(SegmentSumOpModelTest, Float32Test_OneDimension) {\n  SegmentSumOpModel<float> model({TensorType_FLOAT32, {3}},\n                                 {TensorType_INT32, {3}});\n  model.PopulateTensor<float>(model.data(), {1, 2, 3});\n  model.PopulateTensor<int32_t>(model.segment_ids(), {0, 0, 1});\n  model.Invoke();\n  EXPECT_THAT(model.GetOutput(), ElementsAreArray({3.0f, 3.0f}));\n  EXPECT_THAT(model.GetOutputShape(), ElementsAreArray({2}));\n}\n\nTEST(SegmentSumOpModelTest, Float32Test_ThreeDimensions) {\n  SegmentSumOpModel<float> model({TensorType_FLOAT32, {3, 2, 1}},\n                                 {TensorType_INT32, {3}});\n  model.PopulateTensor<float>(model.data(), {1, 2, 3, 4, 5, 6});\n  model.PopulateTensor<int32_t>(model.segment_ids(), {0, 0, 1});\n  model.Invoke();\n  EXPECT_THAT(model.GetOutput(), ElementsAreArray({4.0f, 6.0f, 5.0f, 6.0f}));\n  EXPECT_THAT(model.GetOutputShape(), ElementsAreArray({2, 2, 1}));\n}\n\n}  // namespace\n}  // namespace tflite\n"], "fixing_code": ["/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include <stdint.h>\n\n#include \"tensorflow/lite/c/common.h\"\n#include \"tensorflow/lite/kernels/internal/reference/reference_ops.h\"\n#include \"tensorflow/lite/kernels/internal/tensor.h\"\n#include \"tensorflow/lite/kernels/internal/tensor_ctypes.h\"\n#include \"tensorflow/lite/kernels/kernel_util.h\"\n\nnamespace tflite {\nnamespace ops {\nnamespace builtin {\nnamespace segment_sum {\n\nstatic const int kInputDataTensor = 0;\nstatic const int kInputSegmentIdsTensor = 1;\nstatic const int kOutputTensor = 0;\n\nTfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n                                const TfLiteTensor* data,\n                                const TfLiteTensor* segment_ids,\n                                TfLiteTensor* output) {\n  // Segment ids should be of same cardinality as first input dimension and they\n  // should be increasing by at most 1, from 0 (e.g., [0, 0, 1, 2, 3] is valid)\n  const int segment_id_size = segment_ids->dims->data[0];\n  TF_LITE_ENSURE_EQ(context, segment_id_size, data->dims->data[0]);\n  int previous_segment_id = -1;\n  for (int i = 0; i < segment_id_size; i++) {\n    const int current_segment_id = GetTensorData<int32_t>(segment_ids)[i];\n    if (i == 0) {\n      TF_LITE_ENSURE_EQ(context, current_segment_id, 0);\n    } else {\n      int delta = current_segment_id - previous_segment_id;\n      TF_LITE_ENSURE(context, delta == 0 || delta == 1);\n    }\n    previous_segment_id = current_segment_id;\n  }\n\n  const int max_index = previous_segment_id;\n\n  const int data_rank = NumDimensions(data);\n  TfLiteIntArray* output_shape = TfLiteIntArrayCreate(NumDimensions(data));\n  output_shape->data[0] = max_index + 1;\n  for (int i = 1; i < data_rank; ++i) {\n    output_shape->data[i] = data->dims->data[i];\n  }\n  return context->ResizeTensor(context, output, output_shape);\n}\n\nTfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n  const TfLiteTensor* data = GetInput(context, node, kInputDataTensor);\n  const TfLiteTensor* segment_ids =\n      GetInput(context, node, kInputSegmentIdsTensor);\n  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n\n  TF_LITE_ENSURE(context,\n                 data->type == kTfLiteInt32 || data->type == kTfLiteFloat32);\n  TF_LITE_ENSURE_EQ(context, segment_ids->type, kTfLiteInt32);\n\n  if (!IsConstantTensor(data) || !IsConstantTensor(segment_ids)) {\n    SetTensorToDynamic(output);\n    return kTfLiteOk;\n  }\n\n  return ResizeOutputTensor(context, data, segment_ids, output);\n}\n\nTfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteTensor* data = GetInput(context, node, kInputDataTensor);\n  const TfLiteTensor* segment_ids =\n      GetInput(context, node, kInputSegmentIdsTensor);\n  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n\n  if (IsDynamicTensor(output)) {\n    TF_LITE_ENSURE_OK(context,\n                      ResizeOutputTensor(context, data, segment_ids, output));\n  }\n\n#define TF_LITE_SEGMENT_SUM(dtype)                                      \\\n  reference_ops::SegmentSum<dtype>(                                     \\\n      GetTensorShape(data), GetTensorData<dtype>(data),                 \\\n      GetTensorShape(segment_ids), GetTensorData<int32_t>(segment_ids), \\\n      GetTensorShape(output), GetTensorData<dtype>(output));\n  switch (data->type) {\n    case kTfLiteInt32:\n      TF_LITE_SEGMENT_SUM(int32_t);\n      break;\n    case kTfLiteFloat32:\n      TF_LITE_SEGMENT_SUM(float);\n      break;\n    default:\n      context->ReportError(context,\n                           \"Currently SegmentSum doesn't support type: %s\",\n                           TfLiteTypeGetName(data->type));\n      return kTfLiteError;\n  }\n#undef TF_LITE_SEGMENT_SUM\n  return kTfLiteOk;\n}\n\n}  // namespace segment_sum\n\nTfLiteRegistration* Register_SEGMENT_SUM() {\n  static TfLiteRegistration r = {nullptr, nullptr, segment_sum::Prepare,\n                                 segment_sum::Eval};\n  return &r;\n}\n\n}  // namespace builtin\n}  // namespace ops\n}  // namespace tflite\n", "/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include <stdint.h>\n\n#include <vector>\n\n#include <gtest/gtest.h>\n#include \"tensorflow/lite/kernels/test_util.h\"\n#include \"tensorflow/lite/schema/schema_generated.h\"\n\nnamespace tflite {\nnamespace {\n\nusing ::testing::ElementsAreArray;\n\ntemplate <typename T>\nclass SegmentSumOpModel : public SingleOpModel {\n public:\n  SegmentSumOpModel(const TensorData& data, const TensorData& segment_ids) {\n    data_id_ = AddInput(data);\n    segment_ids_id_ = AddInput(segment_ids);\n    output_id_ = AddOutput(data.type);\n    SetBuiltinOp(BuiltinOperator_SEGMENT_SUM, BuiltinOptions_NONE, 0);\n    BuildInterpreter({GetShape(data_id_), GetShape(segment_ids_id_)});\n  }\n\n  int data() const { return data_id_; }\n  int segment_ids() const { return segment_ids_id_; }\n  std::vector<T> GetOutput() { return ExtractVector<T>(output_id_); }\n  std::vector<int32_t> GetOutputShape() { return GetTensorShape(output_id_); }\n\n protected:\n  int data_id_;\n  int segment_ids_id_;\n  int output_id_;\n};\n\nTEST(SegmentSumOpModelTest, Int32Test_Simple) {\n  SegmentSumOpModel<int32_t> model({TensorType_INT32, {3, 4}},\n                                   {TensorType_INT32, {3}});\n  model.PopulateTensor<int32_t>(model.data(),\n                                {1, 2, 3, 4, 4, 3, 2, 1, 5, 6, 7, 8});\n  model.PopulateTensor<int32_t>(model.segment_ids(), {0, 0, 1});\n  model.Invoke();\n  EXPECT_THAT(model.GetOutput(), ElementsAreArray({5, 5, 5, 5, 5, 6, 7, 8}));\n  EXPECT_THAT(model.GetOutputShape(), ElementsAreArray({2, 4}));\n}\n\nTEST(SegmentSumOpModelTest, Int32Test_OneDimension) {\n  SegmentSumOpModel<int32_t> model({TensorType_INT32, {3}},\n                                   {TensorType_INT32, {3}});\n  model.PopulateTensor<int32_t>(model.data(), {1, 2, 3});\n  model.PopulateTensor<int32_t>(model.segment_ids(), {0, 0, 1});\n  model.Invoke();\n  EXPECT_THAT(model.GetOutput(), ElementsAreArray({3, 3}));\n  EXPECT_THAT(model.GetOutputShape(), ElementsAreArray({2}));\n}\n\nTEST(SegmentSumOpModelTest, Int32Test_ThreeDimensions) {\n  SegmentSumOpModel<int32_t> model({TensorType_INT32, {3, 2, 1}},\n                                   {TensorType_INT32, {3}});\n  model.PopulateTensor<int32_t>(model.data(), {1, 2, 3, 4, 5, 6});\n  model.PopulateTensor<int32_t>(model.segment_ids(), {0, 0, 1});\n  model.Invoke();\n  EXPECT_THAT(model.GetOutput(), ElementsAreArray({4, 6, 5, 6}));\n  EXPECT_THAT(model.GetOutputShape(), ElementsAreArray({2, 2, 1}));\n}\n\nTEST(SegmentSumOpModelTest, Float32Test_Simple) {\n  SegmentSumOpModel<float> model({TensorType_FLOAT32, {3, 4}},\n                                 {TensorType_INT32, {3}});\n  model.PopulateTensor<float>(model.data(),\n                              {1, 2, 3, 4, 4, 3, 2, 1, 5, 6, 7, 8});\n  model.PopulateTensor<int>(model.segment_ids(), {0, 0, 1});\n  model.Invoke();\n  EXPECT_THAT(model.GetOutput(), ElementsAreArray({5.0f, 5.0f, 5.0f, 5.0f, 5.0f,\n                                                   6.0f, 7.0f, 8.0f}));\n  EXPECT_THAT(model.GetOutputShape(), ElementsAreArray({2, 4}));\n}\n\nTEST(SegmentSumOpModelTest, Float32Test_OneDimension) {\n  SegmentSumOpModel<float> model({TensorType_FLOAT32, {3}},\n                                 {TensorType_INT32, {3}});\n  model.PopulateTensor<float>(model.data(), {1, 2, 3});\n  model.PopulateTensor<int32_t>(model.segment_ids(), {0, 0, 1});\n  model.Invoke();\n  EXPECT_THAT(model.GetOutput(), ElementsAreArray({3.0f, 3.0f}));\n  EXPECT_THAT(model.GetOutputShape(), ElementsAreArray({2}));\n}\n\nTEST(SegmentSumOpModelTest, Float32Test_ThreeDimensions) {\n  SegmentSumOpModel<float> model({TensorType_FLOAT32, {3, 2, 1}},\n                                 {TensorType_INT32, {3}});\n  model.PopulateTensor<float>(model.data(), {1, 2, 3, 4, 5, 6});\n  model.PopulateTensor<int32_t>(model.segment_ids(), {0, 0, 1});\n  model.Invoke();\n  EXPECT_THAT(model.GetOutput(), ElementsAreArray({4.0f, 6.0f, 5.0f, 6.0f}));\n  EXPECT_THAT(model.GetOutputShape(), ElementsAreArray({2, 2, 1}));\n}\n\nTEST(SegmentSumOpModelTest, TestFailIfSegmentsAreNotSorted) {\n  SegmentSumOpModel<int32_t> model({TensorType_INT32, {3, 2}},\n                                   {TensorType_INT32, {3}});\n  model.PopulateTensor<int32_t>(model.data(), {1, 2, 3, 4, 5, 6});\n  model.PopulateTensor<int32_t>(model.segment_ids(), {0, 3, 1});\n  ASSERT_EQ(model.InvokeUnchecked(), kTfLiteError);\n}\n\nTEST(SegmentSumOpModelTest, TestFailIfSegmentsAreNotConsecutive) {\n  SegmentSumOpModel<int32_t> model({TensorType_INT32, {3, 2}},\n                                   {TensorType_INT32, {3}});\n  model.PopulateTensor<int32_t>(model.data(), {1, 2, 3, 4, 5, 6});\n  model.PopulateTensor<int32_t>(model.segment_ids(), {0, 3, 5});\n  ASSERT_EQ(model.InvokeUnchecked(), kTfLiteError);\n}\n\nTEST(SegmentSumOpModelTest, TestFailIfSegmentsAreNegative) {\n  SegmentSumOpModel<int32_t> model({TensorType_INT32, {3, 2}},\n                                   {TensorType_INT32, {3}});\n  model.PopulateTensor<int32_t>(model.data(), {1, 2, 3, 4, 5, 6});\n  model.PopulateTensor<int32_t>(model.segment_ids(), {-1, 0, 1});\n  ASSERT_EQ(model.InvokeUnchecked(), kTfLiteError);\n}\n\nTEST(SegmentSumOpModelTest, TestFailIfSegmentsAreNotTheRightCardinality) {\n  SegmentSumOpModel<int32_t> model({TensorType_INT32, {3, 2}},\n                                   {TensorType_INT32, {2}});\n  model.PopulateTensor<int32_t>(model.data(), {1, 2, 3, 4, 5, 6});\n  model.PopulateTensor<int32_t>(model.segment_ids(), {0, 1});\n  ASSERT_EQ(model.InvokeUnchecked(), kTfLiteError);\n}\n\n}  // namespace\n}  // namespace tflite\n"], "filenames": ["tensorflow/lite/kernels/segment_sum.cc", "tensorflow/lite/kernels/segment_sum_test.cc"], "buggy_code_start_loc": [37, 112], "buggy_code_end_loc": [41, 112], "fixing_code_start_loc": [37, 113], "fixing_code_end_loc": [55, 145], "type": "CWE-787", "message": "In TensorFlow Lite before versions 2.2.1 and 2.3.1, models using segment sum can trigger writes outside of bounds of heap allocated buffers by inserting negative elements in the segment ids tensor. Users having access to `segment_ids_data` can alter `output_index` and then write to outside of `output_data` buffer. This might result in a segmentation fault but it can also be used to further corrupt the memory and can be chained with other vulnerabilities to create more advanced exploits. The issue is patched in commit 204945b19e44b57906c9344c0d00120eeeae178a and is released in TensorFlow versions 2.2.1, or 2.3.1. A potential workaround would be to add a custom `Verifier` to the model loading code to ensure that the segment ids are all positive, although this only handles the case when the segment ids are stored statically in the model. A similar validation could be done if the segment ids are generated at runtime between inference steps. If the segment ids are generated as outputs of a tensor during inference steps, then there are no possible workaround and users are advised to upgrade to patched code.", "other": {"cve": {"id": "CVE-2020-15212", "sourceIdentifier": "security-advisories@github.com", "published": "2020-09-25T19:15:16.510", "lastModified": "2021-08-17T13:21:32.277", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "In TensorFlow Lite before versions 2.2.1 and 2.3.1, models using segment sum can trigger writes outside of bounds of heap allocated buffers by inserting negative elements in the segment ids tensor. Users having access to `segment_ids_data` can alter `output_index` and then write to outside of `output_data` buffer. This might result in a segmentation fault but it can also be used to further corrupt the memory and can be chained with other vulnerabilities to create more advanced exploits. The issue is patched in commit 204945b19e44b57906c9344c0d00120eeeae178a and is released in TensorFlow versions 2.2.1, or 2.3.1. A potential workaround would be to add a custom `Verifier` to the model loading code to ensure that the segment ids are all positive, although this only handles the case when the segment ids are stored statically in the model. A similar validation could be done if the segment ids are generated at runtime between inference steps. If the segment ids are generated as outputs of a tensor during inference steps, then there are no possible workaround and users are advised to upgrade to patched code."}, {"lang": "es", "value": "En TensorFlow Lite versiones anteriores a 2.2.1 y 2.3.1, los modelos que utilizan la suma de segmentos pueden activar escrituras fuera de l\u00edmites de los b\u00faferes asignados de la pila insertando elementos negativos en el tensor de los ids de segmento. Los usuarios que tienen acceso a \"segment_ids_data\" pueden alterar \"output_index\" y luego escribir fuera del b\u00fafer de \"output_data\". Esto podr\u00eda resultar en un fallo de segmentaci\u00f3n, pero tambi\u00e9n se puede usar para corromper a\u00fan m\u00e1s la memoria y se puede encadenar con otras vulnerabilidades para crear explotaciones m\u00e1s avanzadas. El problema es parcheado en el commit 204945b19e44b57906c9344c0d00120eeeae178a y es publicado en TensorFlow versiones 2.2.1 o 2.3.1. Una soluci\u00f3n alternativa potencial ser\u00eda agregar un \"Verifier\" personalizado al c\u00f3digo de carga del modelo para asegurar que los ids de segmento sean todos positivos, aunque esto solo maneja el caso cuando los ids de segmento son almacenados est\u00e1ticamente en el modelo. Una comprobaci\u00f3n similar podr\u00eda ser realizada si los ids de segmento se generan en el tiempo de ejecuci\u00f3n entre los pasos de inferencia. Si los ids de segmento son generados como salidas de un tensor durante los pasos de inferencia, entonces no existe una posible soluci\u00f3n alternativa y se recomienda a los usuarios actualizar al c\u00f3digo parcheado"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:L/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "HIGH", "baseScore": 8.6, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 4.7}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:C/C:L/I:L/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "CHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "HIGH", "baseScore": 8.1, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.2, "impactScore": 5.3}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:P/I:P/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 7.5}, "baseSeverity": "HIGH", "exploitabilityScore": 10.0, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-787"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-787"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:lite:*:*:*", "versionStartIncluding": "2.2.0", "versionEndExcluding": "2.2.1", "matchCriteriaId": "323B716A-E8F7-4CDA-B8FD-A56977D59C02"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:lite:*:*:*", "versionStartIncluding": "2.3.0", "versionEndExcluding": "2.3.1", "matchCriteriaId": "C09502A8-B667-4867-BEBD-40333E98A601"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/204945b19e44b57906c9344c0d00120eeeae178a", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/releases/tag/v2.3.1", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-hx2x-85gr-wrpq", "source": "security-advisories@github.com", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/204945b19e44b57906c9344c0d00120eeeae178a"}}
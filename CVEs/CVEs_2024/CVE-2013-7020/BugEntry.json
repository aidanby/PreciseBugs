{"buggy_code": ["/*\n * FFV1 decoder\n *\n * Copyright (c) 2003-2013 Michael Niedermayer <michaelni@gmx.at>\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n/**\n * @file\n * FF Video Codec 1 (a lossless codec) decoder\n */\n\n#include \"libavutil/avassert.h\"\n#include \"libavutil/crc.h\"\n#include \"libavutil/opt.h\"\n#include \"libavutil/imgutils.h\"\n#include \"libavutil/pixdesc.h\"\n#include \"libavutil/timer.h\"\n#include \"avcodec.h\"\n#include \"internal.h\"\n#include \"get_bits.h\"\n#include \"rangecoder.h\"\n#include \"golomb.h\"\n#include \"mathops.h\"\n#include \"ffv1.h\"\n\nstatic inline av_flatten int get_symbol_inline(RangeCoder *c, uint8_t *state,\n                                               int is_signed)\n{\n    if (get_rac(c, state + 0))\n        return 0;\n    else {\n        int i, e, a;\n        e = 0;\n        while (get_rac(c, state + 1 + FFMIN(e, 9))) // 1..10\n            e++;\n\n        a = 1;\n        for (i = e - 1; i >= 0; i--)\n            a += a + get_rac(c, state + 22 + FFMIN(i, 9));  // 22..31\n\n        e = -(is_signed && get_rac(c, state + 11 + FFMIN(e, 10))); // 11..21\n        return (a ^ e) - e;\n    }\n}\n\nstatic av_noinline int get_symbol(RangeCoder *c, uint8_t *state, int is_signed)\n{\n    return get_symbol_inline(c, state, is_signed);\n}\n\nstatic inline int get_vlc_symbol(GetBitContext *gb, VlcState *const state,\n                                 int bits)\n{\n    int k, i, v, ret;\n\n    i = state->count;\n    k = 0;\n    while (i < state->error_sum) { // FIXME: optimize\n        k++;\n        i += i;\n    }\n\n    v = get_sr_golomb(gb, k, 12, bits);\n    av_dlog(NULL, \"v:%d bias:%d error:%d drift:%d count:%d k:%d\",\n            v, state->bias, state->error_sum, state->drift, state->count, k);\n\n#if 0 // JPEG LS\n    if (k == 0 && 2 * state->drift <= -state->count)\n        v ^= (-1);\n#else\n    v ^= ((2 * state->drift + state->count) >> 31);\n#endif\n\n    ret = fold(v + state->bias, bits);\n\n    update_vlc_state(state, v);\n\n    return ret;\n}\n\nstatic av_always_inline void decode_line(FFV1Context *s, int w,\n                                         int16_t *sample[2],\n                                         int plane_index, int bits)\n{\n    PlaneContext *const p = &s->plane[plane_index];\n    RangeCoder *const c   = &s->c;\n    int x;\n    int run_count = 0;\n    int run_mode  = 0;\n    int run_index = s->run_index;\n\n    for (x = 0; x < w; x++) {\n        int diff, context, sign;\n\n        context = get_context(p, sample[1] + x, sample[0] + x, sample[1] + x);\n        if (context < 0) {\n            context = -context;\n            sign    = 1;\n        } else\n            sign = 0;\n\n        av_assert2(context < p->context_count);\n\n        if (s->ac) {\n            diff = get_symbol_inline(c, p->state[context], 1);\n        } else {\n            if (context == 0 && run_mode == 0)\n                run_mode = 1;\n\n            if (run_mode) {\n                if (run_count == 0 && run_mode == 1) {\n                    if (get_bits1(&s->gb)) {\n                        run_count = 1 << ff_log2_run[run_index];\n                        if (x + run_count <= w)\n                            run_index++;\n                    } else {\n                        if (ff_log2_run[run_index])\n                            run_count = get_bits(&s->gb, ff_log2_run[run_index]);\n                        else\n                            run_count = 0;\n                        if (run_index)\n                            run_index--;\n                        run_mode = 2;\n                    }\n                }\n                run_count--;\n                if (run_count < 0) {\n                    run_mode  = 0;\n                    run_count = 0;\n                    diff      = get_vlc_symbol(&s->gb, &p->vlc_state[context],\n                                               bits);\n                    if (diff >= 0)\n                        diff++;\n                } else\n                    diff = 0;\n            } else\n                diff = get_vlc_symbol(&s->gb, &p->vlc_state[context], bits);\n\n            av_dlog(s->avctx, \"count:%d index:%d, mode:%d, x:%d pos:%d\\n\",\n                    run_count, run_index, run_mode, x, get_bits_count(&s->gb));\n        }\n\n        if (sign)\n            diff = -diff;\n\n        sample[1][x] = (predict(sample[1] + x, sample[0] + x) + diff) &\n                       ((1 << bits) - 1);\n    }\n    s->run_index = run_index;\n}\n\nstatic void decode_plane(FFV1Context *s, uint8_t *src,\n                         int w, int h, int stride, int plane_index)\n{\n    int x, y;\n    int16_t *sample[2];\n    sample[0] = s->sample_buffer + 3;\n    sample[1] = s->sample_buffer + w + 6 + 3;\n\n    s->run_index = 0;\n\n    memset(s->sample_buffer, 0, 2 * (w + 6) * sizeof(*s->sample_buffer));\n\n    for (y = 0; y < h; y++) {\n        int16_t *temp = sample[0]; // FIXME: try a normal buffer\n\n        sample[0] = sample[1];\n        sample[1] = temp;\n\n        sample[1][-1] = sample[0][0];\n        sample[0][w]  = sample[0][w - 1];\n\n// { START_TIMER\n        if (s->avctx->bits_per_raw_sample <= 8) {\n            decode_line(s, w, sample, plane_index, 8);\n            for (x = 0; x < w; x++)\n                src[x + stride * y] = sample[1][x];\n        } else {\n            decode_line(s, w, sample, plane_index, s->avctx->bits_per_raw_sample);\n            if (s->packed_at_lsb) {\n                for (x = 0; x < w; x++) {\n                    ((uint16_t*)(src + stride*y))[x] = sample[1][x];\n                }\n            } else {\n                for (x = 0; x < w; x++) {\n                    ((uint16_t*)(src + stride*y))[x] = sample[1][x] << (16 - s->avctx->bits_per_raw_sample);\n                }\n            }\n        }\n// STOP_TIMER(\"decode-line\") }\n    }\n}\n\nstatic void decode_rgb_frame(FFV1Context *s, uint8_t *src[3], int w, int h, int stride[3])\n{\n    int x, y, p;\n    int16_t *sample[4][2];\n    int lbd    = s->avctx->bits_per_raw_sample <= 8;\n    int bits   = s->avctx->bits_per_raw_sample > 0 ? s->avctx->bits_per_raw_sample : 8;\n    int offset = 1 << bits;\n\n    for (x = 0; x < 4; x++) {\n        sample[x][0] = s->sample_buffer +  x * 2      * (w + 6) + 3;\n        sample[x][1] = s->sample_buffer + (x * 2 + 1) * (w + 6) + 3;\n    }\n\n    s->run_index = 0;\n\n    memset(s->sample_buffer, 0, 8 * (w + 6) * sizeof(*s->sample_buffer));\n\n    for (y = 0; y < h; y++) {\n        for (p = 0; p < 3 + s->transparency; p++) {\n            int16_t *temp = sample[p][0]; // FIXME: try a normal buffer\n\n            sample[p][0] = sample[p][1];\n            sample[p][1] = temp;\n\n            sample[p][1][-1]= sample[p][0][0  ];\n            sample[p][0][ w]= sample[p][0][w-1];\n            if (lbd)\n                decode_line(s, w, sample[p], (p + 1)/2, 9);\n            else\n                decode_line(s, w, sample[p], (p + 1)/2, bits + 1);\n        }\n        for (x = 0; x < w; x++) {\n            int g = sample[0][1][x];\n            int b = sample[1][1][x];\n            int r = sample[2][1][x];\n            int a = sample[3][1][x];\n\n            b -= offset;\n            r -= offset;\n            g -= (b + r) >> 2;\n            b += g;\n            r += g;\n\n            if (lbd)\n                *((uint32_t*)(src[0] + x*4 + stride[0]*y)) = b + (g<<8) + (r<<16) + (a<<24);\n            else {\n                *((uint16_t*)(src[0] + x*2 + stride[0]*y)) = b;\n                *((uint16_t*)(src[1] + x*2 + stride[1]*y)) = g;\n                *((uint16_t*)(src[2] + x*2 + stride[2]*y)) = r;\n            }\n        }\n    }\n}\n\nstatic int decode_slice_header(FFV1Context *f, FFV1Context *fs)\n{\n    RangeCoder *c = &fs->c;\n    uint8_t state[CONTEXT_SIZE];\n    unsigned ps, i, context_count;\n    memset(state, 128, sizeof(state));\n\n    av_assert0(f->version > 2);\n\n    fs->slice_x      =  get_symbol(c, state, 0)      * f->width ;\n    fs->slice_y      =  get_symbol(c, state, 0)      * f->height;\n    fs->slice_width  = (get_symbol(c, state, 0) + 1) * f->width  + fs->slice_x;\n    fs->slice_height = (get_symbol(c, state, 0) + 1) * f->height + fs->slice_y;\n\n    fs->slice_x /= f->num_h_slices;\n    fs->slice_y /= f->num_v_slices;\n    fs->slice_width  = fs->slice_width /f->num_h_slices - fs->slice_x;\n    fs->slice_height = fs->slice_height/f->num_v_slices - fs->slice_y;\n    if ((unsigned)fs->slice_width > f->width || (unsigned)fs->slice_height > f->height)\n        return -1;\n    if (    (unsigned)fs->slice_x + (uint64_t)fs->slice_width  > f->width\n         || (unsigned)fs->slice_y + (uint64_t)fs->slice_height > f->height)\n        return -1;\n\n    for (i = 0; i < f->plane_count; i++) {\n        PlaneContext * const p = &fs->plane[i];\n        int idx = get_symbol(c, state, 0);\n        if (idx > (unsigned)f->quant_table_count) {\n            av_log(f->avctx, AV_LOG_ERROR, \"quant_table_index out of range\\n\");\n            return -1;\n        }\n        p->quant_table_index = idx;\n        memcpy(p->quant_table, f->quant_tables[idx], sizeof(p->quant_table));\n        context_count = f->context_count[idx];\n\n        if (p->context_count < context_count) {\n            av_freep(&p->state);\n            av_freep(&p->vlc_state);\n        }\n        p->context_count = context_count;\n    }\n\n    ps = get_symbol(c, state, 0);\n    if (ps == 1) {\n        f->cur->interlaced_frame = 1;\n        f->cur->top_field_first  = 1;\n    } else if (ps == 2) {\n        f->cur->interlaced_frame = 1;\n        f->cur->top_field_first  = 0;\n    } else if (ps == 3) {\n        f->cur->interlaced_frame = 0;\n    }\n    f->cur->sample_aspect_ratio.num = get_symbol(c, state, 0);\n    f->cur->sample_aspect_ratio.den = get_symbol(c, state, 0);\n\n    return 0;\n}\n\nstatic int decode_slice(AVCodecContext *c, void *arg)\n{\n    FFV1Context *fs   = *(void **)arg;\n    FFV1Context *f    = fs->avctx->priv_data;\n    int width, height, x, y, ret;\n    const int ps      = av_pix_fmt_desc_get(c->pix_fmt)->comp[0].step_minus1 + 1;\n    AVFrame * const p = f->cur;\n    int i, si;\n\n    for( si=0; fs != f->slice_context[si]; si ++)\n        ;\n\n    if(f->fsrc && !p->key_frame)\n        ff_thread_await_progress(&f->last_picture, si, 0);\n\n    if(f->fsrc && !p->key_frame) {\n        FFV1Context *fssrc = f->fsrc->slice_context[si];\n        FFV1Context *fsdst = f->slice_context[si];\n        av_assert1(fsdst->plane_count == fssrc->plane_count);\n        av_assert1(fsdst == fs);\n\n        if (!p->key_frame)\n            fsdst->slice_damaged |= fssrc->slice_damaged;\n\n        for (i = 0; i < f->plane_count; i++) {\n            PlaneContext *psrc = &fssrc->plane[i];\n            PlaneContext *pdst = &fsdst->plane[i];\n\n            av_free(pdst->state);\n            av_free(pdst->vlc_state);\n            memcpy(pdst, psrc, sizeof(*pdst));\n            pdst->state = NULL;\n            pdst->vlc_state = NULL;\n\n            if (fssrc->ac) {\n                pdst->state = av_malloc(CONTEXT_SIZE * psrc->context_count);\n                memcpy(pdst->state, psrc->state, CONTEXT_SIZE * psrc->context_count);\n            } else {\n                pdst->vlc_state = av_malloc(sizeof(*pdst->vlc_state) * psrc->context_count);\n                memcpy(pdst->vlc_state, psrc->vlc_state, sizeof(*pdst->vlc_state) * psrc->context_count);\n            }\n        }\n    }\n\n    if (f->version > 2) {\n        if (ffv1_init_slice_state(f, fs) < 0)\n            return AVERROR(ENOMEM);\n        if (decode_slice_header(f, fs) < 0) {\n            fs->slice_damaged = 1;\n            return AVERROR_INVALIDDATA;\n        }\n    }\n    if ((ret = ffv1_init_slice_state(f, fs)) < 0)\n        return ret;\n    if (f->cur->key_frame)\n        ffv1_clear_slice_state(f, fs);\n\n    width  = fs->slice_width;\n    height = fs->slice_height;\n    x      = fs->slice_x;\n    y      = fs->slice_y;\n\n    if (!fs->ac) {\n        if (f->version == 3 && f->micro_version > 1 || f->version > 3)\n            get_rac(&fs->c, (uint8_t[]) { 129 });\n        fs->ac_byte_count = f->version > 2 || (!x && !y) ? fs->c.bytestream - fs->c.bytestream_start - 1 : 0;\n        init_get_bits(&fs->gb,\n                      fs->c.bytestream_start + fs->ac_byte_count,\n                      (fs->c.bytestream_end - fs->c.bytestream_start - fs->ac_byte_count) * 8);\n    }\n\n    av_assert1(width && height);\n    if (f->colorspace == 0) {\n        const int chroma_width  = FF_CEIL_RSHIFT(width,  f->chroma_h_shift);\n        const int chroma_height = FF_CEIL_RSHIFT(height, f->chroma_v_shift);\n        const int cx            = x >> f->chroma_h_shift;\n        const int cy            = y >> f->chroma_v_shift;\n        decode_plane(fs, p->data[0] + ps*x + y*p->linesize[0], width, height, p->linesize[0], 0);\n\n        if (f->chroma_planes) {\n            decode_plane(fs, p->data[1] + ps*cx+cy*p->linesize[1], chroma_width, chroma_height, p->linesize[1], 1);\n            decode_plane(fs, p->data[2] + ps*cx+cy*p->linesize[2], chroma_width, chroma_height, p->linesize[2], 1);\n        }\n        if (fs->transparency)\n            decode_plane(fs, p->data[3] + ps*x + y*p->linesize[3], width, height, p->linesize[3], 2);\n    } else {\n        uint8_t *planes[3] = { p->data[0] + ps * x + y * p->linesize[0],\n                               p->data[1] + ps * x + y * p->linesize[1],\n                               p->data[2] + ps * x + y * p->linesize[2] };\n        decode_rgb_frame(fs, planes, width, height, p->linesize);\n    }\n    if (fs->ac && f->version > 2) {\n        int v;\n        get_rac(&fs->c, (uint8_t[]) { 129 });\n        v = fs->c.bytestream_end - fs->c.bytestream - 2 - 5*f->ec;\n        if (v) {\n            av_log(f->avctx, AV_LOG_ERROR, \"bytestream end mismatching by %d\\n\", v);\n            fs->slice_damaged = 1;\n        }\n    }\n\n    emms_c();\n\n    ff_thread_report_progress(&f->picture, si, 0);\n\n    return 0;\n}\n\nstatic int read_quant_table(RangeCoder *c, int16_t *quant_table, int scale)\n{\n    int v;\n    int i = 0;\n    uint8_t state[CONTEXT_SIZE];\n\n    memset(state, 128, sizeof(state));\n\n    for (v = 0; i < 128; v++) {\n        unsigned len = get_symbol(c, state, 0) + 1;\n\n        if (len > 128 - i)\n            return AVERROR_INVALIDDATA;\n\n        while (len--) {\n            quant_table[i] = scale * v;\n            i++;\n        }\n    }\n\n    for (i = 1; i < 128; i++)\n        quant_table[256 - i] = -quant_table[i];\n    quant_table[128] = -quant_table[127];\n\n    return 2 * v - 1;\n}\n\nstatic int read_quant_tables(RangeCoder *c,\n                             int16_t quant_table[MAX_CONTEXT_INPUTS][256])\n{\n    int i;\n    int context_count = 1;\n\n    for (i = 0; i < 5; i++) {\n        context_count *= read_quant_table(c, quant_table[i], context_count);\n        if (context_count > 32768U) {\n            return AVERROR_INVALIDDATA;\n        }\n    }\n    return (context_count + 1) / 2;\n}\n\nstatic int read_extra_header(FFV1Context *f)\n{\n    RangeCoder *const c = &f->c;\n    uint8_t state[CONTEXT_SIZE];\n    int i, j, k, ret;\n    uint8_t state2[32][CONTEXT_SIZE];\n\n    memset(state2, 128, sizeof(state2));\n    memset(state, 128, sizeof(state));\n\n    ff_init_range_decoder(c, f->avctx->extradata, f->avctx->extradata_size);\n    ff_build_rac_states(c, 0.05 * (1LL << 32), 256 - 8);\n\n    f->version = get_symbol(c, state, 0);\n    if (f->version < 2) {\n        av_log(f->avctx, AV_LOG_ERROR, \"Invalid version in global header\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n    if (f->version > 2) {\n        c->bytestream_end -= 4;\n        f->micro_version = get_symbol(c, state, 0);\n    }\n    f->ac = f->avctx->coder_type = get_symbol(c, state, 0);\n    if (f->ac > 1) {\n        for (i = 1; i < 256; i++)\n            f->state_transition[i] = get_symbol(c, state, 1) + c->one_state[i];\n    }\n\n    f->colorspace                 = get_symbol(c, state, 0); //YUV cs type\n    f->avctx->bits_per_raw_sample = get_symbol(c, state, 0);\n    f->chroma_planes              = get_rac(c, state);\n    f->chroma_h_shift             = get_symbol(c, state, 0);\n    f->chroma_v_shift             = get_symbol(c, state, 0);\n    f->transparency               = get_rac(c, state);\n    f->plane_count                = 1 + (f->chroma_planes || f->version<4) + f->transparency;\n    f->num_h_slices               = 1 + get_symbol(c, state, 0);\n    f->num_v_slices               = 1 + get_symbol(c, state, 0);\n\n    if (f->num_h_slices > (unsigned)f->width  || !f->num_h_slices ||\n        f->num_v_slices > (unsigned)f->height || !f->num_v_slices\n       ) {\n        av_log(f->avctx, AV_LOG_ERROR, \"slice count invalid\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    f->quant_table_count = get_symbol(c, state, 0);\n    if (f->quant_table_count > (unsigned)MAX_QUANT_TABLES)\n        return AVERROR_INVALIDDATA;\n\n    for (i = 0; i < f->quant_table_count; i++) {\n        f->context_count[i] = read_quant_tables(c, f->quant_tables[i]);\n        if (f->context_count[i] < 0) {\n            av_log(f->avctx, AV_LOG_ERROR, \"read_quant_table error\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n    }\n    if ((ret = ffv1_allocate_initial_states(f)) < 0)\n        return ret;\n\n    for (i = 0; i < f->quant_table_count; i++)\n        if (get_rac(c, state)) {\n            for (j = 0; j < f->context_count[i]; j++)\n                for (k = 0; k < CONTEXT_SIZE; k++) {\n                    int pred = j ? f->initial_states[i][j - 1][k] : 128;\n                    f->initial_states[i][j][k] =\n                        (pred + get_symbol(c, state2[k], 1)) & 0xFF;\n                }\n        }\n\n    if (f->version > 2) {\n        f->ec = get_symbol(c, state, 0);\n        if (f->micro_version > 2)\n            f->intra = get_symbol(c, state, 0);\n    }\n\n    if (f->version > 2) {\n        unsigned v;\n        v = av_crc(av_crc_get_table(AV_CRC_32_IEEE), 0,\n                   f->avctx->extradata, f->avctx->extradata_size);\n        if (v) {\n            av_log(f->avctx, AV_LOG_ERROR, \"CRC mismatch %X!\\n\", v);\n            return AVERROR_INVALIDDATA;\n        }\n    }\n\n    if (f->avctx->debug & FF_DEBUG_PICT_INFO)\n        av_log(f->avctx, AV_LOG_DEBUG,\n               \"global: ver:%d.%d, coder:%d, colorspace: %d bpr:%d chroma:%d(%d:%d), alpha:%d slices:%dx%d qtabs:%d ec:%d intra:%d\\n\",\n               f->version, f->micro_version,\n               f->ac,\n               f->colorspace,\n               f->avctx->bits_per_raw_sample,\n               f->chroma_planes, f->chroma_h_shift, f->chroma_v_shift,\n               f->transparency,\n               f->num_h_slices, f->num_v_slices,\n               f->quant_table_count,\n               f->ec,\n               f->intra\n              );\n    return 0;\n}\n\nstatic int read_header(FFV1Context *f)\n{\n    uint8_t state[CONTEXT_SIZE];\n    int i, j, context_count = -1; //-1 to avoid warning\n    RangeCoder *const c = &f->slice_context[0]->c;\n\n    memset(state, 128, sizeof(state));\n\n    if (f->version < 2) {\n        int chroma_planes, chroma_h_shift, chroma_v_shift, transparency;\n        unsigned v= get_symbol(c, state, 0);\n        if (v >= 2) {\n            av_log(f->avctx, AV_LOG_ERROR, \"invalid version %d in ver01 header\\n\", v);\n            return AVERROR_INVALIDDATA;\n        }\n        f->version = v;\n        f->ac      = f->avctx->coder_type = get_symbol(c, state, 0);\n        if (f->ac > 1) {\n            for (i = 1; i < 256; i++)\n                f->state_transition[i] = get_symbol(c, state, 1) + c->one_state[i];\n        }\n\n        f->colorspace = get_symbol(c, state, 0); //YUV cs type\n\n        if (f->version > 0)\n            f->avctx->bits_per_raw_sample = get_symbol(c, state, 0);\n\n        chroma_planes  = get_rac(c, state);\n        chroma_h_shift = get_symbol(c, state, 0);\n        chroma_v_shift = get_symbol(c, state, 0);\n        transparency   = get_rac(c, state);\n\n        if (f->plane_count) {\n            if (   chroma_planes != f->chroma_planes\n                || chroma_h_shift!= f->chroma_h_shift\n                || chroma_v_shift!= f->chroma_v_shift\n                || transparency  != f->transparency) {\n                av_log(f->avctx, AV_LOG_ERROR, \"Invalid change of global parameters\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n        }\n\n        f->chroma_planes  = chroma_planes;\n        f->chroma_h_shift = chroma_h_shift;\n        f->chroma_v_shift = chroma_v_shift;\n        f->transparency   = transparency;\n\n        f->plane_count    = 2 + f->transparency;\n    }\n\n    if (f->colorspace == 0) {\n        if (!f->transparency && !f->chroma_planes) {\n            if (f->avctx->bits_per_raw_sample <= 8)\n                f->avctx->pix_fmt = AV_PIX_FMT_GRAY8;\n            else\n                f->avctx->pix_fmt = AV_PIX_FMT_GRAY16;\n        } else if (f->avctx->bits_per_raw_sample<=8 && !f->transparency) {\n            switch(16 * f->chroma_h_shift + f->chroma_v_shift) {\n            case 0x00: f->avctx->pix_fmt = AV_PIX_FMT_YUV444P; break;\n            case 0x01: f->avctx->pix_fmt = AV_PIX_FMT_YUV440P; break;\n            case 0x10: f->avctx->pix_fmt = AV_PIX_FMT_YUV422P; break;\n            case 0x11: f->avctx->pix_fmt = AV_PIX_FMT_YUV420P; break;\n            case 0x20: f->avctx->pix_fmt = AV_PIX_FMT_YUV411P; break;\n            case 0x22: f->avctx->pix_fmt = AV_PIX_FMT_YUV410P; break;\n            default:\n                av_log(f->avctx, AV_LOG_ERROR, \"format not supported\\n\");\n                return AVERROR(ENOSYS);\n            }\n        } else if (f->avctx->bits_per_raw_sample <= 8 && f->transparency) {\n            switch(16*f->chroma_h_shift + f->chroma_v_shift) {\n            case 0x00: f->avctx->pix_fmt = AV_PIX_FMT_YUVA444P; break;\n            case 0x10: f->avctx->pix_fmt = AV_PIX_FMT_YUVA422P; break;\n            case 0x11: f->avctx->pix_fmt = AV_PIX_FMT_YUVA420P; break;\n            default:\n                av_log(f->avctx, AV_LOG_ERROR, \"format not supported\\n\");\n                return AVERROR(ENOSYS);\n            }\n        } else if (f->avctx->bits_per_raw_sample == 9) {\n            f->packed_at_lsb = 1;\n            switch(16 * f->chroma_h_shift + f->chroma_v_shift) {\n            case 0x00: f->avctx->pix_fmt = AV_PIX_FMT_YUV444P9; break;\n            case 0x10: f->avctx->pix_fmt = AV_PIX_FMT_YUV422P9; break;\n            case 0x11: f->avctx->pix_fmt = AV_PIX_FMT_YUV420P9; break;\n            default:\n                av_log(f->avctx, AV_LOG_ERROR, \"format not supported\\n\");\n                return AVERROR(ENOSYS);\n            }\n        } else if (f->avctx->bits_per_raw_sample == 10) {\n            f->packed_at_lsb = 1;\n            switch(16 * f->chroma_h_shift + f->chroma_v_shift) {\n            case 0x00: f->avctx->pix_fmt = AV_PIX_FMT_YUV444P10; break;\n            case 0x10: f->avctx->pix_fmt = AV_PIX_FMT_YUV422P10; break;\n            case 0x11: f->avctx->pix_fmt = AV_PIX_FMT_YUV420P10; break;\n            default:\n                av_log(f->avctx, AV_LOG_ERROR, \"format not supported\\n\");\n                return AVERROR(ENOSYS);\n            }\n        } else {\n            switch(16 * f->chroma_h_shift + f->chroma_v_shift) {\n            case 0x00: f->avctx->pix_fmt = AV_PIX_FMT_YUV444P16; break;\n            case 0x10: f->avctx->pix_fmt = AV_PIX_FMT_YUV422P16; break;\n            case 0x11: f->avctx->pix_fmt = AV_PIX_FMT_YUV420P16; break;\n            default:\n                av_log(f->avctx, AV_LOG_ERROR, \"format not supported\\n\");\n                return AVERROR(ENOSYS);\n            }\n        }\n    } else if (f->colorspace == 1) {\n        if (f->chroma_h_shift || f->chroma_v_shift) {\n            av_log(f->avctx, AV_LOG_ERROR,\n                   \"chroma subsampling not supported in this colorspace\\n\");\n            return AVERROR(ENOSYS);\n        }\n        if (     f->avctx->bits_per_raw_sample ==  9)\n            f->avctx->pix_fmt = AV_PIX_FMT_GBRP9;\n        else if (f->avctx->bits_per_raw_sample == 10)\n            f->avctx->pix_fmt = AV_PIX_FMT_GBRP10;\n        else if (f->avctx->bits_per_raw_sample == 12)\n            f->avctx->pix_fmt = AV_PIX_FMT_GBRP12;\n        else if (f->avctx->bits_per_raw_sample == 14)\n            f->avctx->pix_fmt = AV_PIX_FMT_GBRP14;\n        else\n        if (f->transparency) f->avctx->pix_fmt = AV_PIX_FMT_RGB32;\n        else                 f->avctx->pix_fmt = AV_PIX_FMT_0RGB32;\n    } else {\n        av_log(f->avctx, AV_LOG_ERROR, \"colorspace not supported\\n\");\n        return AVERROR(ENOSYS);\n    }\n\n    av_dlog(f->avctx, \"%d %d %d\\n\",\n            f->chroma_h_shift, f->chroma_v_shift, f->avctx->pix_fmt);\n    if (f->version < 2) {\n        context_count = read_quant_tables(c, f->quant_table);\n        if (context_count < 0) {\n            av_log(f->avctx, AV_LOG_ERROR, \"read_quant_table error\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n    } else if (f->version < 3) {\n        f->slice_count = get_symbol(c, state, 0);\n    } else {\n        const uint8_t *p = c->bytestream_end;\n        for (f->slice_count = 0;\n             f->slice_count < MAX_SLICES && 3 < p - c->bytestream_start;\n             f->slice_count++) {\n            int trailer = 3 + 5*!!f->ec;\n            int size = AV_RB24(p-trailer);\n            if (size + trailer > p - c->bytestream_start)\n                break;\n            p -= size + trailer;\n        }\n    }\n    if (f->slice_count > (unsigned)MAX_SLICES || f->slice_count <= 0) {\n        av_log(f->avctx, AV_LOG_ERROR, \"slice count %d is invalid\\n\", f->slice_count);\n        return AVERROR_INVALIDDATA;\n    }\n\n    for (j = 0; j < f->slice_count; j++) {\n        FFV1Context *fs = f->slice_context[j];\n        fs->ac            = f->ac;\n        fs->packed_at_lsb = f->packed_at_lsb;\n\n        fs->slice_damaged = 0;\n\n        if (f->version == 2) {\n            fs->slice_x      =  get_symbol(c, state, 0)      * f->width ;\n            fs->slice_y      =  get_symbol(c, state, 0)      * f->height;\n            fs->slice_width  = (get_symbol(c, state, 0) + 1) * f->width  + fs->slice_x;\n            fs->slice_height = (get_symbol(c, state, 0) + 1) * f->height + fs->slice_y;\n\n            fs->slice_x     /= f->num_h_slices;\n            fs->slice_y     /= f->num_v_slices;\n            fs->slice_width  = fs->slice_width  / f->num_h_slices - fs->slice_x;\n            fs->slice_height = fs->slice_height / f->num_v_slices - fs->slice_y;\n            if ((unsigned)fs->slice_width  > f->width ||\n                (unsigned)fs->slice_height > f->height)\n                return AVERROR_INVALIDDATA;\n            if (   (unsigned)fs->slice_x + (uint64_t)fs->slice_width  > f->width\n                || (unsigned)fs->slice_y + (uint64_t)fs->slice_height > f->height)\n                return AVERROR_INVALIDDATA;\n        }\n\n        for (i = 0; i < f->plane_count; i++) {\n            PlaneContext *const p = &fs->plane[i];\n\n            if (f->version == 2) {\n                int idx = get_symbol(c, state, 0);\n                if (idx > (unsigned)f->quant_table_count) {\n                    av_log(f->avctx, AV_LOG_ERROR,\n                           \"quant_table_index out of range\\n\");\n                    return AVERROR_INVALIDDATA;\n                }\n                p->quant_table_index = idx;\n                memcpy(p->quant_table, f->quant_tables[idx],\n                       sizeof(p->quant_table));\n                context_count = f->context_count[idx];\n            } else {\n                memcpy(p->quant_table, f->quant_table, sizeof(p->quant_table));\n            }\n\n            if (f->version <= 2) {\n                av_assert0(context_count >= 0);\n                if (p->context_count < context_count) {\n                    av_freep(&p->state);\n                    av_freep(&p->vlc_state);\n                }\n                p->context_count = context_count;\n            }\n        }\n    }\n    return 0;\n}\n\nstatic av_cold int decode_init(AVCodecContext *avctx)\n{\n    FFV1Context *f = avctx->priv_data;\n    int ret;\n\n    if ((ret = ffv1_common_init(avctx)) < 0)\n        return ret;\n\n    if (avctx->extradata && (ret = read_extra_header(f)) < 0)\n        return ret;\n\n    if ((ret = ffv1_init_slice_contexts(f)) < 0)\n        return ret;\n\n    avctx->internal->allocate_progress = 1;\n\n    return 0;\n}\n\nstatic int decode_frame(AVCodecContext *avctx, void *data, int *got_frame, AVPacket *avpkt)\n{\n    const uint8_t *buf  = avpkt->data;\n    int buf_size        = avpkt->size;\n    FFV1Context *f      = avctx->priv_data;\n    RangeCoder *const c = &f->slice_context[0]->c;\n    int i, ret;\n    uint8_t keystate = 128;\n    const uint8_t *buf_p;\n    AVFrame *p;\n\n    if (f->last_picture.f)\n        ff_thread_release_buffer(avctx, &f->last_picture);\n    FFSWAP(ThreadFrame, f->picture, f->last_picture);\n\n    f->cur = p = f->picture.f;\n\n    if (f->version < 3 && avctx->field_order > AV_FIELD_PROGRESSIVE) {\n        /* we have interlaced material flagged in container */\n        p->interlaced_frame = 1;\n        if (avctx->field_order == AV_FIELD_TT || avctx->field_order == AV_FIELD_TB)\n            p->top_field_first = 1;\n    }\n\n    f->avctx = avctx;\n    ff_init_range_decoder(c, buf, buf_size);\n    ff_build_rac_states(c, 0.05 * (1LL << 32), 256 - 8);\n\n    p->pict_type = AV_PICTURE_TYPE_I; //FIXME I vs. P\n    if (get_rac(c, &keystate)) {\n        p->key_frame    = 1;\n        f->key_frame_ok = 0;\n        if ((ret = read_header(f)) < 0)\n            return ret;\n        f->key_frame_ok = 1;\n    } else {\n        if (!f->key_frame_ok) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"Cannot decode non-keyframe without valid keyframe\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        p->key_frame = 0;\n    }\n\n    if ((ret = ff_thread_get_buffer(avctx, &f->picture, AV_GET_BUFFER_FLAG_REF)) < 0)\n        return ret;\n\n    if (avctx->debug & FF_DEBUG_PICT_INFO)\n        av_log(avctx, AV_LOG_DEBUG, \"ver:%d keyframe:%d coder:%d ec:%d slices:%d bps:%d\\n\",\n               f->version, p->key_frame, f->ac, f->ec, f->slice_count, f->avctx->bits_per_raw_sample);\n\n    ff_thread_finish_setup(avctx);\n\n    buf_p = buf + buf_size;\n    for (i = f->slice_count - 1; i >= 0; i--) {\n        FFV1Context *fs = f->slice_context[i];\n        int trailer = 3 + 5*!!f->ec;\n        int v;\n\n        if (i || f->version > 2) v = AV_RB24(buf_p-trailer) + trailer;\n        else                     v = buf_p - c->bytestream_start;\n        if (buf_p - c->bytestream_start < v) {\n            av_log(avctx, AV_LOG_ERROR, \"Slice pointer chain broken\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        buf_p -= v;\n\n        if (f->ec) {\n            unsigned crc = av_crc(av_crc_get_table(AV_CRC_32_IEEE), 0, buf_p, v);\n            if (crc) {\n                int64_t ts = avpkt->pts != AV_NOPTS_VALUE ? avpkt->pts : avpkt->dts;\n                av_log(f->avctx, AV_LOG_ERROR, \"CRC mismatch %X!\", crc);\n                if (ts != AV_NOPTS_VALUE && avctx->pkt_timebase.num) {\n                    av_log(f->avctx, AV_LOG_ERROR, \"at %f seconds\\n\", ts*av_q2d(avctx->pkt_timebase));\n                } else if (ts != AV_NOPTS_VALUE) {\n                    av_log(f->avctx, AV_LOG_ERROR, \"at %\"PRId64\"\\n\", ts);\n                } else {\n                    av_log(f->avctx, AV_LOG_ERROR, \"\\n\");\n                }\n                fs->slice_damaged = 1;\n            }\n        }\n\n        if (i) {\n            ff_init_range_decoder(&fs->c, buf_p, v);\n        } else\n            fs->c.bytestream_end = (uint8_t *)(buf_p + v);\n\n        fs->avctx = avctx;\n        fs->cur = p;\n    }\n\n    avctx->execute(avctx,\n                   decode_slice,\n                   &f->slice_context[0],\n                   NULL,\n                   f->slice_count,\n                   sizeof(void*));\n\n    for (i = f->slice_count - 1; i >= 0; i--) {\n        FFV1Context *fs = f->slice_context[i];\n        int j;\n        if (fs->slice_damaged && f->last_picture.f->data[0]) {\n            const uint8_t *src[4];\n            uint8_t *dst[4];\n            ff_thread_await_progress(&f->last_picture, INT_MAX, 0);\n            for (j = 0; j < 4; j++) {\n                int sh = (j==1 || j==2) ? f->chroma_h_shift : 0;\n                int sv = (j==1 || j==2) ? f->chroma_v_shift : 0;\n                dst[j] = p->data[j] + p->linesize[j]*\n                         (fs->slice_y>>sv) + (fs->slice_x>>sh);\n                src[j] = f->last_picture.f->data[j] + f->last_picture.f->linesize[j]*\n                         (fs->slice_y>>sv) + (fs->slice_x>>sh);\n            }\n            av_image_copy(dst, p->linesize, (const uint8_t **)src,\n                          f->last_picture.f->linesize,\n                          avctx->pix_fmt,\n                          fs->slice_width,\n                          fs->slice_height);\n        }\n    }\n    ff_thread_report_progress(&f->picture, INT_MAX, 0);\n\n    f->picture_number++;\n\n    if (f->last_picture.f)\n        ff_thread_release_buffer(avctx, &f->last_picture);\n    f->cur = NULL;\n    if ((ret = av_frame_ref(data, f->picture.f)) < 0)\n        return ret;\n\n    *got_frame = 1;\n\n    return buf_size;\n}\n\nstatic int init_thread_copy(AVCodecContext *avctx)\n{\n    FFV1Context *f = avctx->priv_data;\n\n    f->picture.f      = NULL;\n    f->last_picture.f = NULL;\n    f->sample_buffer  = NULL;\n    f->quant_table_count = 0;\n    f->slice_count = 0;\n\n    return 0;\n}\n\nstatic int update_thread_context(AVCodecContext *dst, const AVCodecContext *src)\n{\n    FFV1Context *fsrc = src->priv_data;\n    FFV1Context *fdst = dst->priv_data;\n    int i, ret;\n\n    if (dst == src)\n        return 0;\n\n    if (!fdst->picture.f) {\n        memcpy(fdst, fsrc, sizeof(*fdst));\n\n        for (i = 0; i < fdst->quant_table_count; i++) {\n            fdst->initial_states[i] = av_malloc(fdst->context_count[i] * sizeof(*fdst->initial_states[i]));\n            memcpy(fdst->initial_states[i], fsrc->initial_states[i], fdst->context_count[i] * sizeof(*fdst->initial_states[i]));\n        }\n\n        fdst->picture.f      = av_frame_alloc();\n        fdst->last_picture.f = av_frame_alloc();\n\n        if ((ret = ffv1_init_slice_contexts(fdst)) < 0)\n            return ret;\n    }\n\n    av_assert1(fdst->slice_count == fsrc->slice_count);\n\n    fdst->key_frame_ok = fsrc->key_frame_ok;\n\n    ff_thread_release_buffer(dst, &fdst->picture);\n    if (fsrc->picture.f->data[0]) {\n        if ((ret = ff_thread_ref_frame(&fdst->picture, &fsrc->picture)) < 0)\n            return ret;\n    }\n    for (i = 0; i < fdst->slice_count; i++) {\n        FFV1Context *fsdst = fdst->slice_context[i];\n        FFV1Context *fssrc = fsrc->slice_context[i];\n\n        fsdst->slice_damaged = fssrc->slice_damaged;\n    }\n\n    fdst->fsrc = fsrc;\n\n    return 0;\n}\n\nAVCodec ff_ffv1_decoder = {\n    .name           = \"ffv1\",\n    .type           = AVMEDIA_TYPE_VIDEO,\n    .id             = AV_CODEC_ID_FFV1,\n    .priv_data_size = sizeof(FFV1Context),\n    .init           = decode_init,\n    .close          = ffv1_close,\n    .decode         = decode_frame,\n    .init_thread_copy = ONLY_IF_THREADS_ENABLED(init_thread_copy),\n    .update_thread_context = ONLY_IF_THREADS_ENABLED(update_thread_context),\n    .capabilities   = CODEC_CAP_DR1 /*| CODEC_CAP_DRAW_HORIZ_BAND*/ |\n                      CODEC_CAP_FRAME_THREADS | CODEC_CAP_SLICE_THREADS,\n    .long_name      = NULL_IF_CONFIG_SMALL(\"FFmpeg video codec #1\"),\n};\n"], "fixing_code": ["/*\n * FFV1 decoder\n *\n * Copyright (c) 2003-2013 Michael Niedermayer <michaelni@gmx.at>\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n/**\n * @file\n * FF Video Codec 1 (a lossless codec) decoder\n */\n\n#include \"libavutil/avassert.h\"\n#include \"libavutil/crc.h\"\n#include \"libavutil/opt.h\"\n#include \"libavutil/imgutils.h\"\n#include \"libavutil/pixdesc.h\"\n#include \"libavutil/timer.h\"\n#include \"avcodec.h\"\n#include \"internal.h\"\n#include \"get_bits.h\"\n#include \"rangecoder.h\"\n#include \"golomb.h\"\n#include \"mathops.h\"\n#include \"ffv1.h\"\n\nstatic inline av_flatten int get_symbol_inline(RangeCoder *c, uint8_t *state,\n                                               int is_signed)\n{\n    if (get_rac(c, state + 0))\n        return 0;\n    else {\n        int i, e, a;\n        e = 0;\n        while (get_rac(c, state + 1 + FFMIN(e, 9))) // 1..10\n            e++;\n\n        a = 1;\n        for (i = e - 1; i >= 0; i--)\n            a += a + get_rac(c, state + 22 + FFMIN(i, 9));  // 22..31\n\n        e = -(is_signed && get_rac(c, state + 11 + FFMIN(e, 10))); // 11..21\n        return (a ^ e) - e;\n    }\n}\n\nstatic av_noinline int get_symbol(RangeCoder *c, uint8_t *state, int is_signed)\n{\n    return get_symbol_inline(c, state, is_signed);\n}\n\nstatic inline int get_vlc_symbol(GetBitContext *gb, VlcState *const state,\n                                 int bits)\n{\n    int k, i, v, ret;\n\n    i = state->count;\n    k = 0;\n    while (i < state->error_sum) { // FIXME: optimize\n        k++;\n        i += i;\n    }\n\n    v = get_sr_golomb(gb, k, 12, bits);\n    av_dlog(NULL, \"v:%d bias:%d error:%d drift:%d count:%d k:%d\",\n            v, state->bias, state->error_sum, state->drift, state->count, k);\n\n#if 0 // JPEG LS\n    if (k == 0 && 2 * state->drift <= -state->count)\n        v ^= (-1);\n#else\n    v ^= ((2 * state->drift + state->count) >> 31);\n#endif\n\n    ret = fold(v + state->bias, bits);\n\n    update_vlc_state(state, v);\n\n    return ret;\n}\n\nstatic av_always_inline void decode_line(FFV1Context *s, int w,\n                                         int16_t *sample[2],\n                                         int plane_index, int bits)\n{\n    PlaneContext *const p = &s->plane[plane_index];\n    RangeCoder *const c   = &s->c;\n    int x;\n    int run_count = 0;\n    int run_mode  = 0;\n    int run_index = s->run_index;\n\n    for (x = 0; x < w; x++) {\n        int diff, context, sign;\n\n        context = get_context(p, sample[1] + x, sample[0] + x, sample[1] + x);\n        if (context < 0) {\n            context = -context;\n            sign    = 1;\n        } else\n            sign = 0;\n\n        av_assert2(context < p->context_count);\n\n        if (s->ac) {\n            diff = get_symbol_inline(c, p->state[context], 1);\n        } else {\n            if (context == 0 && run_mode == 0)\n                run_mode = 1;\n\n            if (run_mode) {\n                if (run_count == 0 && run_mode == 1) {\n                    if (get_bits1(&s->gb)) {\n                        run_count = 1 << ff_log2_run[run_index];\n                        if (x + run_count <= w)\n                            run_index++;\n                    } else {\n                        if (ff_log2_run[run_index])\n                            run_count = get_bits(&s->gb, ff_log2_run[run_index]);\n                        else\n                            run_count = 0;\n                        if (run_index)\n                            run_index--;\n                        run_mode = 2;\n                    }\n                }\n                run_count--;\n                if (run_count < 0) {\n                    run_mode  = 0;\n                    run_count = 0;\n                    diff      = get_vlc_symbol(&s->gb, &p->vlc_state[context],\n                                               bits);\n                    if (diff >= 0)\n                        diff++;\n                } else\n                    diff = 0;\n            } else\n                diff = get_vlc_symbol(&s->gb, &p->vlc_state[context], bits);\n\n            av_dlog(s->avctx, \"count:%d index:%d, mode:%d, x:%d pos:%d\\n\",\n                    run_count, run_index, run_mode, x, get_bits_count(&s->gb));\n        }\n\n        if (sign)\n            diff = -diff;\n\n        sample[1][x] = (predict(sample[1] + x, sample[0] + x) + diff) &\n                       ((1 << bits) - 1);\n    }\n    s->run_index = run_index;\n}\n\nstatic void decode_plane(FFV1Context *s, uint8_t *src,\n                         int w, int h, int stride, int plane_index)\n{\n    int x, y;\n    int16_t *sample[2];\n    sample[0] = s->sample_buffer + 3;\n    sample[1] = s->sample_buffer + w + 6 + 3;\n\n    s->run_index = 0;\n\n    memset(s->sample_buffer, 0, 2 * (w + 6) * sizeof(*s->sample_buffer));\n\n    for (y = 0; y < h; y++) {\n        int16_t *temp = sample[0]; // FIXME: try a normal buffer\n\n        sample[0] = sample[1];\n        sample[1] = temp;\n\n        sample[1][-1] = sample[0][0];\n        sample[0][w]  = sample[0][w - 1];\n\n// { START_TIMER\n        if (s->avctx->bits_per_raw_sample <= 8) {\n            decode_line(s, w, sample, plane_index, 8);\n            for (x = 0; x < w; x++)\n                src[x + stride * y] = sample[1][x];\n        } else {\n            decode_line(s, w, sample, plane_index, s->avctx->bits_per_raw_sample);\n            if (s->packed_at_lsb) {\n                for (x = 0; x < w; x++) {\n                    ((uint16_t*)(src + stride*y))[x] = sample[1][x];\n                }\n            } else {\n                for (x = 0; x < w; x++) {\n                    ((uint16_t*)(src + stride*y))[x] = sample[1][x] << (16 - s->avctx->bits_per_raw_sample);\n                }\n            }\n        }\n// STOP_TIMER(\"decode-line\") }\n    }\n}\n\nstatic void decode_rgb_frame(FFV1Context *s, uint8_t *src[3], int w, int h, int stride[3])\n{\n    int x, y, p;\n    int16_t *sample[4][2];\n    int lbd    = s->avctx->bits_per_raw_sample <= 8;\n    int bits   = s->avctx->bits_per_raw_sample > 0 ? s->avctx->bits_per_raw_sample : 8;\n    int offset = 1 << bits;\n\n    for (x = 0; x < 4; x++) {\n        sample[x][0] = s->sample_buffer +  x * 2      * (w + 6) + 3;\n        sample[x][1] = s->sample_buffer + (x * 2 + 1) * (w + 6) + 3;\n    }\n\n    s->run_index = 0;\n\n    memset(s->sample_buffer, 0, 8 * (w + 6) * sizeof(*s->sample_buffer));\n\n    for (y = 0; y < h; y++) {\n        for (p = 0; p < 3 + s->transparency; p++) {\n            int16_t *temp = sample[p][0]; // FIXME: try a normal buffer\n\n            sample[p][0] = sample[p][1];\n            sample[p][1] = temp;\n\n            sample[p][1][-1]= sample[p][0][0  ];\n            sample[p][0][ w]= sample[p][0][w-1];\n            if (lbd)\n                decode_line(s, w, sample[p], (p + 1)/2, 9);\n            else\n                decode_line(s, w, sample[p], (p + 1)/2, bits + 1);\n        }\n        for (x = 0; x < w; x++) {\n            int g = sample[0][1][x];\n            int b = sample[1][1][x];\n            int r = sample[2][1][x];\n            int a = sample[3][1][x];\n\n            b -= offset;\n            r -= offset;\n            g -= (b + r) >> 2;\n            b += g;\n            r += g;\n\n            if (lbd)\n                *((uint32_t*)(src[0] + x*4 + stride[0]*y)) = b + (g<<8) + (r<<16) + (a<<24);\n            else {\n                *((uint16_t*)(src[0] + x*2 + stride[0]*y)) = b;\n                *((uint16_t*)(src[1] + x*2 + stride[1]*y)) = g;\n                *((uint16_t*)(src[2] + x*2 + stride[2]*y)) = r;\n            }\n        }\n    }\n}\n\nstatic int decode_slice_header(FFV1Context *f, FFV1Context *fs)\n{\n    RangeCoder *c = &fs->c;\n    uint8_t state[CONTEXT_SIZE];\n    unsigned ps, i, context_count;\n    memset(state, 128, sizeof(state));\n\n    av_assert0(f->version > 2);\n\n    fs->slice_x      =  get_symbol(c, state, 0)      * f->width ;\n    fs->slice_y      =  get_symbol(c, state, 0)      * f->height;\n    fs->slice_width  = (get_symbol(c, state, 0) + 1) * f->width  + fs->slice_x;\n    fs->slice_height = (get_symbol(c, state, 0) + 1) * f->height + fs->slice_y;\n\n    fs->slice_x /= f->num_h_slices;\n    fs->slice_y /= f->num_v_slices;\n    fs->slice_width  = fs->slice_width /f->num_h_slices - fs->slice_x;\n    fs->slice_height = fs->slice_height/f->num_v_slices - fs->slice_y;\n    if ((unsigned)fs->slice_width > f->width || (unsigned)fs->slice_height > f->height)\n        return -1;\n    if (    (unsigned)fs->slice_x + (uint64_t)fs->slice_width  > f->width\n         || (unsigned)fs->slice_y + (uint64_t)fs->slice_height > f->height)\n        return -1;\n\n    for (i = 0; i < f->plane_count; i++) {\n        PlaneContext * const p = &fs->plane[i];\n        int idx = get_symbol(c, state, 0);\n        if (idx > (unsigned)f->quant_table_count) {\n            av_log(f->avctx, AV_LOG_ERROR, \"quant_table_index out of range\\n\");\n            return -1;\n        }\n        p->quant_table_index = idx;\n        memcpy(p->quant_table, f->quant_tables[idx], sizeof(p->quant_table));\n        context_count = f->context_count[idx];\n\n        if (p->context_count < context_count) {\n            av_freep(&p->state);\n            av_freep(&p->vlc_state);\n        }\n        p->context_count = context_count;\n    }\n\n    ps = get_symbol(c, state, 0);\n    if (ps == 1) {\n        f->cur->interlaced_frame = 1;\n        f->cur->top_field_first  = 1;\n    } else if (ps == 2) {\n        f->cur->interlaced_frame = 1;\n        f->cur->top_field_first  = 0;\n    } else if (ps == 3) {\n        f->cur->interlaced_frame = 0;\n    }\n    f->cur->sample_aspect_ratio.num = get_symbol(c, state, 0);\n    f->cur->sample_aspect_ratio.den = get_symbol(c, state, 0);\n\n    return 0;\n}\n\nstatic int decode_slice(AVCodecContext *c, void *arg)\n{\n    FFV1Context *fs   = *(void **)arg;\n    FFV1Context *f    = fs->avctx->priv_data;\n    int width, height, x, y, ret;\n    const int ps      = av_pix_fmt_desc_get(c->pix_fmt)->comp[0].step_minus1 + 1;\n    AVFrame * const p = f->cur;\n    int i, si;\n\n    for( si=0; fs != f->slice_context[si]; si ++)\n        ;\n\n    if(f->fsrc && !p->key_frame)\n        ff_thread_await_progress(&f->last_picture, si, 0);\n\n    if(f->fsrc && !p->key_frame) {\n        FFV1Context *fssrc = f->fsrc->slice_context[si];\n        FFV1Context *fsdst = f->slice_context[si];\n        av_assert1(fsdst->plane_count == fssrc->plane_count);\n        av_assert1(fsdst == fs);\n\n        if (!p->key_frame)\n            fsdst->slice_damaged |= fssrc->slice_damaged;\n\n        for (i = 0; i < f->plane_count; i++) {\n            PlaneContext *psrc = &fssrc->plane[i];\n            PlaneContext *pdst = &fsdst->plane[i];\n\n            av_free(pdst->state);\n            av_free(pdst->vlc_state);\n            memcpy(pdst, psrc, sizeof(*pdst));\n            pdst->state = NULL;\n            pdst->vlc_state = NULL;\n\n            if (fssrc->ac) {\n                pdst->state = av_malloc(CONTEXT_SIZE * psrc->context_count);\n                memcpy(pdst->state, psrc->state, CONTEXT_SIZE * psrc->context_count);\n            } else {\n                pdst->vlc_state = av_malloc(sizeof(*pdst->vlc_state) * psrc->context_count);\n                memcpy(pdst->vlc_state, psrc->vlc_state, sizeof(*pdst->vlc_state) * psrc->context_count);\n            }\n        }\n    }\n\n    if (f->version > 2) {\n        if (ffv1_init_slice_state(f, fs) < 0)\n            return AVERROR(ENOMEM);\n        if (decode_slice_header(f, fs) < 0) {\n            fs->slice_damaged = 1;\n            return AVERROR_INVALIDDATA;\n        }\n    }\n    if ((ret = ffv1_init_slice_state(f, fs)) < 0)\n        return ret;\n    if (f->cur->key_frame)\n        ffv1_clear_slice_state(f, fs);\n\n    width  = fs->slice_width;\n    height = fs->slice_height;\n    x      = fs->slice_x;\n    y      = fs->slice_y;\n\n    if (!fs->ac) {\n        if (f->version == 3 && f->micro_version > 1 || f->version > 3)\n            get_rac(&fs->c, (uint8_t[]) { 129 });\n        fs->ac_byte_count = f->version > 2 || (!x && !y) ? fs->c.bytestream - fs->c.bytestream_start - 1 : 0;\n        init_get_bits(&fs->gb,\n                      fs->c.bytestream_start + fs->ac_byte_count,\n                      (fs->c.bytestream_end - fs->c.bytestream_start - fs->ac_byte_count) * 8);\n    }\n\n    av_assert1(width && height);\n    if (f->colorspace == 0) {\n        const int chroma_width  = FF_CEIL_RSHIFT(width,  f->chroma_h_shift);\n        const int chroma_height = FF_CEIL_RSHIFT(height, f->chroma_v_shift);\n        const int cx            = x >> f->chroma_h_shift;\n        const int cy            = y >> f->chroma_v_shift;\n        decode_plane(fs, p->data[0] + ps*x + y*p->linesize[0], width, height, p->linesize[0], 0);\n\n        if (f->chroma_planes) {\n            decode_plane(fs, p->data[1] + ps*cx+cy*p->linesize[1], chroma_width, chroma_height, p->linesize[1], 1);\n            decode_plane(fs, p->data[2] + ps*cx+cy*p->linesize[2], chroma_width, chroma_height, p->linesize[2], 1);\n        }\n        if (fs->transparency)\n            decode_plane(fs, p->data[3] + ps*x + y*p->linesize[3], width, height, p->linesize[3], 2);\n    } else {\n        uint8_t *planes[3] = { p->data[0] + ps * x + y * p->linesize[0],\n                               p->data[1] + ps * x + y * p->linesize[1],\n                               p->data[2] + ps * x + y * p->linesize[2] };\n        decode_rgb_frame(fs, planes, width, height, p->linesize);\n    }\n    if (fs->ac && f->version > 2) {\n        int v;\n        get_rac(&fs->c, (uint8_t[]) { 129 });\n        v = fs->c.bytestream_end - fs->c.bytestream - 2 - 5*f->ec;\n        if (v) {\n            av_log(f->avctx, AV_LOG_ERROR, \"bytestream end mismatching by %d\\n\", v);\n            fs->slice_damaged = 1;\n        }\n    }\n\n    emms_c();\n\n    ff_thread_report_progress(&f->picture, si, 0);\n\n    return 0;\n}\n\nstatic int read_quant_table(RangeCoder *c, int16_t *quant_table, int scale)\n{\n    int v;\n    int i = 0;\n    uint8_t state[CONTEXT_SIZE];\n\n    memset(state, 128, sizeof(state));\n\n    for (v = 0; i < 128; v++) {\n        unsigned len = get_symbol(c, state, 0) + 1;\n\n        if (len > 128 - i)\n            return AVERROR_INVALIDDATA;\n\n        while (len--) {\n            quant_table[i] = scale * v;\n            i++;\n        }\n    }\n\n    for (i = 1; i < 128; i++)\n        quant_table[256 - i] = -quant_table[i];\n    quant_table[128] = -quant_table[127];\n\n    return 2 * v - 1;\n}\n\nstatic int read_quant_tables(RangeCoder *c,\n                             int16_t quant_table[MAX_CONTEXT_INPUTS][256])\n{\n    int i;\n    int context_count = 1;\n\n    for (i = 0; i < 5; i++) {\n        context_count *= read_quant_table(c, quant_table[i], context_count);\n        if (context_count > 32768U) {\n            return AVERROR_INVALIDDATA;\n        }\n    }\n    return (context_count + 1) / 2;\n}\n\nstatic int read_extra_header(FFV1Context *f)\n{\n    RangeCoder *const c = &f->c;\n    uint8_t state[CONTEXT_SIZE];\n    int i, j, k, ret;\n    uint8_t state2[32][CONTEXT_SIZE];\n\n    memset(state2, 128, sizeof(state2));\n    memset(state, 128, sizeof(state));\n\n    ff_init_range_decoder(c, f->avctx->extradata, f->avctx->extradata_size);\n    ff_build_rac_states(c, 0.05 * (1LL << 32), 256 - 8);\n\n    f->version = get_symbol(c, state, 0);\n    if (f->version < 2) {\n        av_log(f->avctx, AV_LOG_ERROR, \"Invalid version in global header\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n    if (f->version > 2) {\n        c->bytestream_end -= 4;\n        f->micro_version = get_symbol(c, state, 0);\n    }\n    f->ac = f->avctx->coder_type = get_symbol(c, state, 0);\n    if (f->ac > 1) {\n        for (i = 1; i < 256; i++)\n            f->state_transition[i] = get_symbol(c, state, 1) + c->one_state[i];\n    }\n\n    f->colorspace                 = get_symbol(c, state, 0); //YUV cs type\n    f->avctx->bits_per_raw_sample = get_symbol(c, state, 0);\n    f->chroma_planes              = get_rac(c, state);\n    f->chroma_h_shift             = get_symbol(c, state, 0);\n    f->chroma_v_shift             = get_symbol(c, state, 0);\n    f->transparency               = get_rac(c, state);\n    f->plane_count                = 1 + (f->chroma_planes || f->version<4) + f->transparency;\n    f->num_h_slices               = 1 + get_symbol(c, state, 0);\n    f->num_v_slices               = 1 + get_symbol(c, state, 0);\n\n    if (f->num_h_slices > (unsigned)f->width  || !f->num_h_slices ||\n        f->num_v_slices > (unsigned)f->height || !f->num_v_slices\n       ) {\n        av_log(f->avctx, AV_LOG_ERROR, \"slice count invalid\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    f->quant_table_count = get_symbol(c, state, 0);\n    if (f->quant_table_count > (unsigned)MAX_QUANT_TABLES)\n        return AVERROR_INVALIDDATA;\n\n    for (i = 0; i < f->quant_table_count; i++) {\n        f->context_count[i] = read_quant_tables(c, f->quant_tables[i]);\n        if (f->context_count[i] < 0) {\n            av_log(f->avctx, AV_LOG_ERROR, \"read_quant_table error\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n    }\n    if ((ret = ffv1_allocate_initial_states(f)) < 0)\n        return ret;\n\n    for (i = 0; i < f->quant_table_count; i++)\n        if (get_rac(c, state)) {\n            for (j = 0; j < f->context_count[i]; j++)\n                for (k = 0; k < CONTEXT_SIZE; k++) {\n                    int pred = j ? f->initial_states[i][j - 1][k] : 128;\n                    f->initial_states[i][j][k] =\n                        (pred + get_symbol(c, state2[k], 1)) & 0xFF;\n                }\n        }\n\n    if (f->version > 2) {\n        f->ec = get_symbol(c, state, 0);\n        if (f->micro_version > 2)\n            f->intra = get_symbol(c, state, 0);\n    }\n\n    if (f->version > 2) {\n        unsigned v;\n        v = av_crc(av_crc_get_table(AV_CRC_32_IEEE), 0,\n                   f->avctx->extradata, f->avctx->extradata_size);\n        if (v) {\n            av_log(f->avctx, AV_LOG_ERROR, \"CRC mismatch %X!\\n\", v);\n            return AVERROR_INVALIDDATA;\n        }\n    }\n\n    if (f->avctx->debug & FF_DEBUG_PICT_INFO)\n        av_log(f->avctx, AV_LOG_DEBUG,\n               \"global: ver:%d.%d, coder:%d, colorspace: %d bpr:%d chroma:%d(%d:%d), alpha:%d slices:%dx%d qtabs:%d ec:%d intra:%d\\n\",\n               f->version, f->micro_version,\n               f->ac,\n               f->colorspace,\n               f->avctx->bits_per_raw_sample,\n               f->chroma_planes, f->chroma_h_shift, f->chroma_v_shift,\n               f->transparency,\n               f->num_h_slices, f->num_v_slices,\n               f->quant_table_count,\n               f->ec,\n               f->intra\n              );\n    return 0;\n}\n\nstatic int read_header(FFV1Context *f)\n{\n    uint8_t state[CONTEXT_SIZE];\n    int i, j, context_count = -1; //-1 to avoid warning\n    RangeCoder *const c = &f->slice_context[0]->c;\n\n    memset(state, 128, sizeof(state));\n\n    if (f->version < 2) {\n        int chroma_planes, chroma_h_shift, chroma_v_shift, transparency, colorspace, bits_per_raw_sample;\n        unsigned v= get_symbol(c, state, 0);\n        if (v >= 2) {\n            av_log(f->avctx, AV_LOG_ERROR, \"invalid version %d in ver01 header\\n\", v);\n            return AVERROR_INVALIDDATA;\n        }\n        f->version = v;\n        f->ac      = f->avctx->coder_type = get_symbol(c, state, 0);\n        if (f->ac > 1) {\n            for (i = 1; i < 256; i++)\n                f->state_transition[i] = get_symbol(c, state, 1) + c->one_state[i];\n        }\n\n        colorspace     = get_symbol(c, state, 0); //YUV cs type\n        bits_per_raw_sample = f->version > 0 ? get_symbol(c, state, 0) : f->avctx->bits_per_raw_sample;\n        chroma_planes  = get_rac(c, state);\n        chroma_h_shift = get_symbol(c, state, 0);\n        chroma_v_shift = get_symbol(c, state, 0);\n        transparency   = get_rac(c, state);\n\n        if (f->plane_count) {\n            if (   colorspace    != f->colorspace\n                || bits_per_raw_sample != f->avctx->bits_per_raw_sample\n                || chroma_planes != f->chroma_planes\n                || chroma_h_shift!= f->chroma_h_shift\n                || chroma_v_shift!= f->chroma_v_shift\n                || transparency  != f->transparency) {\n                av_log(f->avctx, AV_LOG_ERROR, \"Invalid change of global parameters\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n        }\n\n        f->colorspace     = colorspace;\n        f->avctx->bits_per_raw_sample = bits_per_raw_sample;\n        f->chroma_planes  = chroma_planes;\n        f->chroma_h_shift = chroma_h_shift;\n        f->chroma_v_shift = chroma_v_shift;\n        f->transparency   = transparency;\n\n        f->plane_count    = 2 + f->transparency;\n    }\n\n    if (f->colorspace == 0) {\n        if (!f->transparency && !f->chroma_planes) {\n            if (f->avctx->bits_per_raw_sample <= 8)\n                f->avctx->pix_fmt = AV_PIX_FMT_GRAY8;\n            else\n                f->avctx->pix_fmt = AV_PIX_FMT_GRAY16;\n        } else if (f->avctx->bits_per_raw_sample<=8 && !f->transparency) {\n            switch(16 * f->chroma_h_shift + f->chroma_v_shift) {\n            case 0x00: f->avctx->pix_fmt = AV_PIX_FMT_YUV444P; break;\n            case 0x01: f->avctx->pix_fmt = AV_PIX_FMT_YUV440P; break;\n            case 0x10: f->avctx->pix_fmt = AV_PIX_FMT_YUV422P; break;\n            case 0x11: f->avctx->pix_fmt = AV_PIX_FMT_YUV420P; break;\n            case 0x20: f->avctx->pix_fmt = AV_PIX_FMT_YUV411P; break;\n            case 0x22: f->avctx->pix_fmt = AV_PIX_FMT_YUV410P; break;\n            default:\n                av_log(f->avctx, AV_LOG_ERROR, \"format not supported\\n\");\n                return AVERROR(ENOSYS);\n            }\n        } else if (f->avctx->bits_per_raw_sample <= 8 && f->transparency) {\n            switch(16*f->chroma_h_shift + f->chroma_v_shift) {\n            case 0x00: f->avctx->pix_fmt = AV_PIX_FMT_YUVA444P; break;\n            case 0x10: f->avctx->pix_fmt = AV_PIX_FMT_YUVA422P; break;\n            case 0x11: f->avctx->pix_fmt = AV_PIX_FMT_YUVA420P; break;\n            default:\n                av_log(f->avctx, AV_LOG_ERROR, \"format not supported\\n\");\n                return AVERROR(ENOSYS);\n            }\n        } else if (f->avctx->bits_per_raw_sample == 9) {\n            f->packed_at_lsb = 1;\n            switch(16 * f->chroma_h_shift + f->chroma_v_shift) {\n            case 0x00: f->avctx->pix_fmt = AV_PIX_FMT_YUV444P9; break;\n            case 0x10: f->avctx->pix_fmt = AV_PIX_FMT_YUV422P9; break;\n            case 0x11: f->avctx->pix_fmt = AV_PIX_FMT_YUV420P9; break;\n            default:\n                av_log(f->avctx, AV_LOG_ERROR, \"format not supported\\n\");\n                return AVERROR(ENOSYS);\n            }\n        } else if (f->avctx->bits_per_raw_sample == 10) {\n            f->packed_at_lsb = 1;\n            switch(16 * f->chroma_h_shift + f->chroma_v_shift) {\n            case 0x00: f->avctx->pix_fmt = AV_PIX_FMT_YUV444P10; break;\n            case 0x10: f->avctx->pix_fmt = AV_PIX_FMT_YUV422P10; break;\n            case 0x11: f->avctx->pix_fmt = AV_PIX_FMT_YUV420P10; break;\n            default:\n                av_log(f->avctx, AV_LOG_ERROR, \"format not supported\\n\");\n                return AVERROR(ENOSYS);\n            }\n        } else {\n            switch(16 * f->chroma_h_shift + f->chroma_v_shift) {\n            case 0x00: f->avctx->pix_fmt = AV_PIX_FMT_YUV444P16; break;\n            case 0x10: f->avctx->pix_fmt = AV_PIX_FMT_YUV422P16; break;\n            case 0x11: f->avctx->pix_fmt = AV_PIX_FMT_YUV420P16; break;\n            default:\n                av_log(f->avctx, AV_LOG_ERROR, \"format not supported\\n\");\n                return AVERROR(ENOSYS);\n            }\n        }\n    } else if (f->colorspace == 1) {\n        if (f->chroma_h_shift || f->chroma_v_shift) {\n            av_log(f->avctx, AV_LOG_ERROR,\n                   \"chroma subsampling not supported in this colorspace\\n\");\n            return AVERROR(ENOSYS);\n        }\n        if (     f->avctx->bits_per_raw_sample ==  9)\n            f->avctx->pix_fmt = AV_PIX_FMT_GBRP9;\n        else if (f->avctx->bits_per_raw_sample == 10)\n            f->avctx->pix_fmt = AV_PIX_FMT_GBRP10;\n        else if (f->avctx->bits_per_raw_sample == 12)\n            f->avctx->pix_fmt = AV_PIX_FMT_GBRP12;\n        else if (f->avctx->bits_per_raw_sample == 14)\n            f->avctx->pix_fmt = AV_PIX_FMT_GBRP14;\n        else\n        if (f->transparency) f->avctx->pix_fmt = AV_PIX_FMT_RGB32;\n        else                 f->avctx->pix_fmt = AV_PIX_FMT_0RGB32;\n    } else {\n        av_log(f->avctx, AV_LOG_ERROR, \"colorspace not supported\\n\");\n        return AVERROR(ENOSYS);\n    }\n\n    av_dlog(f->avctx, \"%d %d %d\\n\",\n            f->chroma_h_shift, f->chroma_v_shift, f->avctx->pix_fmt);\n    if (f->version < 2) {\n        context_count = read_quant_tables(c, f->quant_table);\n        if (context_count < 0) {\n            av_log(f->avctx, AV_LOG_ERROR, \"read_quant_table error\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n    } else if (f->version < 3) {\n        f->slice_count = get_symbol(c, state, 0);\n    } else {\n        const uint8_t *p = c->bytestream_end;\n        for (f->slice_count = 0;\n             f->slice_count < MAX_SLICES && 3 < p - c->bytestream_start;\n             f->slice_count++) {\n            int trailer = 3 + 5*!!f->ec;\n            int size = AV_RB24(p-trailer);\n            if (size + trailer > p - c->bytestream_start)\n                break;\n            p -= size + trailer;\n        }\n    }\n    if (f->slice_count > (unsigned)MAX_SLICES || f->slice_count <= 0) {\n        av_log(f->avctx, AV_LOG_ERROR, \"slice count %d is invalid\\n\", f->slice_count);\n        return AVERROR_INVALIDDATA;\n    }\n\n    for (j = 0; j < f->slice_count; j++) {\n        FFV1Context *fs = f->slice_context[j];\n        fs->ac            = f->ac;\n        fs->packed_at_lsb = f->packed_at_lsb;\n\n        fs->slice_damaged = 0;\n\n        if (f->version == 2) {\n            fs->slice_x      =  get_symbol(c, state, 0)      * f->width ;\n            fs->slice_y      =  get_symbol(c, state, 0)      * f->height;\n            fs->slice_width  = (get_symbol(c, state, 0) + 1) * f->width  + fs->slice_x;\n            fs->slice_height = (get_symbol(c, state, 0) + 1) * f->height + fs->slice_y;\n\n            fs->slice_x     /= f->num_h_slices;\n            fs->slice_y     /= f->num_v_slices;\n            fs->slice_width  = fs->slice_width  / f->num_h_slices - fs->slice_x;\n            fs->slice_height = fs->slice_height / f->num_v_slices - fs->slice_y;\n            if ((unsigned)fs->slice_width  > f->width ||\n                (unsigned)fs->slice_height > f->height)\n                return AVERROR_INVALIDDATA;\n            if (   (unsigned)fs->slice_x + (uint64_t)fs->slice_width  > f->width\n                || (unsigned)fs->slice_y + (uint64_t)fs->slice_height > f->height)\n                return AVERROR_INVALIDDATA;\n        }\n\n        for (i = 0; i < f->plane_count; i++) {\n            PlaneContext *const p = &fs->plane[i];\n\n            if (f->version == 2) {\n                int idx = get_symbol(c, state, 0);\n                if (idx > (unsigned)f->quant_table_count) {\n                    av_log(f->avctx, AV_LOG_ERROR,\n                           \"quant_table_index out of range\\n\");\n                    return AVERROR_INVALIDDATA;\n                }\n                p->quant_table_index = idx;\n                memcpy(p->quant_table, f->quant_tables[idx],\n                       sizeof(p->quant_table));\n                context_count = f->context_count[idx];\n            } else {\n                memcpy(p->quant_table, f->quant_table, sizeof(p->quant_table));\n            }\n\n            if (f->version <= 2) {\n                av_assert0(context_count >= 0);\n                if (p->context_count < context_count) {\n                    av_freep(&p->state);\n                    av_freep(&p->vlc_state);\n                }\n                p->context_count = context_count;\n            }\n        }\n    }\n    return 0;\n}\n\nstatic av_cold int decode_init(AVCodecContext *avctx)\n{\n    FFV1Context *f = avctx->priv_data;\n    int ret;\n\n    if ((ret = ffv1_common_init(avctx)) < 0)\n        return ret;\n\n    if (avctx->extradata && (ret = read_extra_header(f)) < 0)\n        return ret;\n\n    if ((ret = ffv1_init_slice_contexts(f)) < 0)\n        return ret;\n\n    avctx->internal->allocate_progress = 1;\n\n    return 0;\n}\n\nstatic int decode_frame(AVCodecContext *avctx, void *data, int *got_frame, AVPacket *avpkt)\n{\n    const uint8_t *buf  = avpkt->data;\n    int buf_size        = avpkt->size;\n    FFV1Context *f      = avctx->priv_data;\n    RangeCoder *const c = &f->slice_context[0]->c;\n    int i, ret;\n    uint8_t keystate = 128;\n    const uint8_t *buf_p;\n    AVFrame *p;\n\n    if (f->last_picture.f)\n        ff_thread_release_buffer(avctx, &f->last_picture);\n    FFSWAP(ThreadFrame, f->picture, f->last_picture);\n\n    f->cur = p = f->picture.f;\n\n    if (f->version < 3 && avctx->field_order > AV_FIELD_PROGRESSIVE) {\n        /* we have interlaced material flagged in container */\n        p->interlaced_frame = 1;\n        if (avctx->field_order == AV_FIELD_TT || avctx->field_order == AV_FIELD_TB)\n            p->top_field_first = 1;\n    }\n\n    f->avctx = avctx;\n    ff_init_range_decoder(c, buf, buf_size);\n    ff_build_rac_states(c, 0.05 * (1LL << 32), 256 - 8);\n\n    p->pict_type = AV_PICTURE_TYPE_I; //FIXME I vs. P\n    if (get_rac(c, &keystate)) {\n        p->key_frame    = 1;\n        f->key_frame_ok = 0;\n        if ((ret = read_header(f)) < 0)\n            return ret;\n        f->key_frame_ok = 1;\n    } else {\n        if (!f->key_frame_ok) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"Cannot decode non-keyframe without valid keyframe\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        p->key_frame = 0;\n    }\n\n    if ((ret = ff_thread_get_buffer(avctx, &f->picture, AV_GET_BUFFER_FLAG_REF)) < 0)\n        return ret;\n\n    if (avctx->debug & FF_DEBUG_PICT_INFO)\n        av_log(avctx, AV_LOG_DEBUG, \"ver:%d keyframe:%d coder:%d ec:%d slices:%d bps:%d\\n\",\n               f->version, p->key_frame, f->ac, f->ec, f->slice_count, f->avctx->bits_per_raw_sample);\n\n    ff_thread_finish_setup(avctx);\n\n    buf_p = buf + buf_size;\n    for (i = f->slice_count - 1; i >= 0; i--) {\n        FFV1Context *fs = f->slice_context[i];\n        int trailer = 3 + 5*!!f->ec;\n        int v;\n\n        if (i || f->version > 2) v = AV_RB24(buf_p-trailer) + trailer;\n        else                     v = buf_p - c->bytestream_start;\n        if (buf_p - c->bytestream_start < v) {\n            av_log(avctx, AV_LOG_ERROR, \"Slice pointer chain broken\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        buf_p -= v;\n\n        if (f->ec) {\n            unsigned crc = av_crc(av_crc_get_table(AV_CRC_32_IEEE), 0, buf_p, v);\n            if (crc) {\n                int64_t ts = avpkt->pts != AV_NOPTS_VALUE ? avpkt->pts : avpkt->dts;\n                av_log(f->avctx, AV_LOG_ERROR, \"CRC mismatch %X!\", crc);\n                if (ts != AV_NOPTS_VALUE && avctx->pkt_timebase.num) {\n                    av_log(f->avctx, AV_LOG_ERROR, \"at %f seconds\\n\", ts*av_q2d(avctx->pkt_timebase));\n                } else if (ts != AV_NOPTS_VALUE) {\n                    av_log(f->avctx, AV_LOG_ERROR, \"at %\"PRId64\"\\n\", ts);\n                } else {\n                    av_log(f->avctx, AV_LOG_ERROR, \"\\n\");\n                }\n                fs->slice_damaged = 1;\n            }\n        }\n\n        if (i) {\n            ff_init_range_decoder(&fs->c, buf_p, v);\n        } else\n            fs->c.bytestream_end = (uint8_t *)(buf_p + v);\n\n        fs->avctx = avctx;\n        fs->cur = p;\n    }\n\n    avctx->execute(avctx,\n                   decode_slice,\n                   &f->slice_context[0],\n                   NULL,\n                   f->slice_count,\n                   sizeof(void*));\n\n    for (i = f->slice_count - 1; i >= 0; i--) {\n        FFV1Context *fs = f->slice_context[i];\n        int j;\n        if (fs->slice_damaged && f->last_picture.f->data[0]) {\n            const uint8_t *src[4];\n            uint8_t *dst[4];\n            ff_thread_await_progress(&f->last_picture, INT_MAX, 0);\n            for (j = 0; j < 4; j++) {\n                int sh = (j==1 || j==2) ? f->chroma_h_shift : 0;\n                int sv = (j==1 || j==2) ? f->chroma_v_shift : 0;\n                dst[j] = p->data[j] + p->linesize[j]*\n                         (fs->slice_y>>sv) + (fs->slice_x>>sh);\n                src[j] = f->last_picture.f->data[j] + f->last_picture.f->linesize[j]*\n                         (fs->slice_y>>sv) + (fs->slice_x>>sh);\n            }\n            av_image_copy(dst, p->linesize, (const uint8_t **)src,\n                          f->last_picture.f->linesize,\n                          avctx->pix_fmt,\n                          fs->slice_width,\n                          fs->slice_height);\n        }\n    }\n    ff_thread_report_progress(&f->picture, INT_MAX, 0);\n\n    f->picture_number++;\n\n    if (f->last_picture.f)\n        ff_thread_release_buffer(avctx, &f->last_picture);\n    f->cur = NULL;\n    if ((ret = av_frame_ref(data, f->picture.f)) < 0)\n        return ret;\n\n    *got_frame = 1;\n\n    return buf_size;\n}\n\nstatic int init_thread_copy(AVCodecContext *avctx)\n{\n    FFV1Context *f = avctx->priv_data;\n\n    f->picture.f      = NULL;\n    f->last_picture.f = NULL;\n    f->sample_buffer  = NULL;\n    f->quant_table_count = 0;\n    f->slice_count = 0;\n\n    return 0;\n}\n\nstatic int update_thread_context(AVCodecContext *dst, const AVCodecContext *src)\n{\n    FFV1Context *fsrc = src->priv_data;\n    FFV1Context *fdst = dst->priv_data;\n    int i, ret;\n\n    if (dst == src)\n        return 0;\n\n    if (!fdst->picture.f) {\n        memcpy(fdst, fsrc, sizeof(*fdst));\n\n        for (i = 0; i < fdst->quant_table_count; i++) {\n            fdst->initial_states[i] = av_malloc(fdst->context_count[i] * sizeof(*fdst->initial_states[i]));\n            memcpy(fdst->initial_states[i], fsrc->initial_states[i], fdst->context_count[i] * sizeof(*fdst->initial_states[i]));\n        }\n\n        fdst->picture.f      = av_frame_alloc();\n        fdst->last_picture.f = av_frame_alloc();\n\n        if ((ret = ffv1_init_slice_contexts(fdst)) < 0)\n            return ret;\n    }\n\n    av_assert1(fdst->slice_count == fsrc->slice_count);\n\n    fdst->key_frame_ok = fsrc->key_frame_ok;\n\n    ff_thread_release_buffer(dst, &fdst->picture);\n    if (fsrc->picture.f->data[0]) {\n        if ((ret = ff_thread_ref_frame(&fdst->picture, &fsrc->picture)) < 0)\n            return ret;\n    }\n    for (i = 0; i < fdst->slice_count; i++) {\n        FFV1Context *fsdst = fdst->slice_context[i];\n        FFV1Context *fssrc = fsrc->slice_context[i];\n\n        fsdst->slice_damaged = fssrc->slice_damaged;\n    }\n\n    fdst->fsrc = fsrc;\n\n    return 0;\n}\n\nAVCodec ff_ffv1_decoder = {\n    .name           = \"ffv1\",\n    .type           = AVMEDIA_TYPE_VIDEO,\n    .id             = AV_CODEC_ID_FFV1,\n    .priv_data_size = sizeof(FFV1Context),\n    .init           = decode_init,\n    .close          = ffv1_close,\n    .decode         = decode_frame,\n    .init_thread_copy = ONLY_IF_THREADS_ENABLED(init_thread_copy),\n    .update_thread_context = ONLY_IF_THREADS_ENABLED(update_thread_context),\n    .capabilities   = CODEC_CAP_DR1 /*| CODEC_CAP_DRAW_HORIZ_BAND*/ |\n                      CODEC_CAP_FRAME_THREADS | CODEC_CAP_SLICE_THREADS,\n    .long_name      = NULL_IF_CONFIG_SMALL(\"FFmpeg video codec #1\"),\n};\n"], "filenames": ["libavcodec/ffv1dec.c"], "buggy_code_start_loc": [583], "buggy_code_end_loc": [615], "fixing_code_start_loc": [583], "fixing_code_end_loc": [617], "type": "CWE-119", "message": "The read_header function in libavcodec/ffv1dec.c in FFmpeg before 2.1 does not properly enforce certain bit-count and colorspace constraints, which allows remote attackers to cause a denial of service (out-of-bounds array access) or possibly have unspecified other impact via crafted FFV1 data.", "other": {"cve": {"id": "CVE-2013-7020", "sourceIdentifier": "cve@mitre.org", "published": "2013-12-09T16:36:49.987", "lastModified": "2017-01-07T02:59:14.577", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "The read_header function in libavcodec/ffv1dec.c in FFmpeg before 2.1 does not properly enforce certain bit-count and colorspace constraints, which allows remote attackers to cause a denial of service (out-of-bounds array access) or possibly have unspecified other impact via crafted FFV1 data."}, {"lang": "es", "value": "La funci\u00f3n read_header function en libavcodec/ffv1dec.c en FFmpeg anterior a v2.1 no aplica correctamente ciertas restricciones en el n\u00famero de bits y en el espacio de colores, lo que permite a atacantes remotos provocar una denegaci\u00f3n de servicio (acceso a array fuera de rango) o posiblemente tener otro impacto no especificado a trav\u00e9s de informaci\u00f3n FFV1 manipulada."}], "metrics": {"cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:P/I:P/A:P", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 6.8}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.6, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-119"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:*:*:*:*:*:*:*:*", "versionEndIncluding": "2.0.1", "matchCriteriaId": "C41A1983-BA74-4806-A227-EBBF7989112C"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.3:*:*:*:*:*:*:*", "matchCriteriaId": "B2649A80-4739-4BBB-AB0B-99AD435BE7CF"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.3.1:*:*:*:*:*:*:*", "matchCriteriaId": "D4A2E77D-B826-4B49-ADC8-7F704E149A5A"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.3.2:*:*:*:*:*:*:*", "matchCriteriaId": "18157837-4550-45E3-A12E-AE06E047E253"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.3.3:*:*:*:*:*:*:*", "matchCriteriaId": "E9F42611-C3E2-416B-9AE7-A5AE83E4DEF7"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.3.4:*:*:*:*:*:*:*", "matchCriteriaId": "3A20789F-26E3-4871-B24E-25E922BADDF0"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.4.0:*:*:*:*:*:*:*", "matchCriteriaId": "67C6C243-3ACC-49C3-80CA-D7CA8FEFF0D8"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.4.2:*:*:*:*:*:*:*", "matchCriteriaId": "6AE6D368-0BA6-4499-B7E1-EE16C03012E9"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.4.3:*:*:*:*:*:*:*", "matchCriteriaId": "26C0F6EF-0452-4AFE-AF3E-B88F963A0938"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.4.4:*:*:*:*:*:*:*", "matchCriteriaId": "5B4DD372-4D3B-445C-8C38-E083A3C0D4A7"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.4.5:*:*:*:*:*:*:*", "matchCriteriaId": "733C03D7-2780-4D69-A98D-BCFB91D1119A"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.4.6:*:*:*:*:*:*:*", "matchCriteriaId": "0AEE1977-E9E0-4BFF-B33B-B083E49E51F1"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.4.7:*:*:*:*:*:*:*", "matchCriteriaId": "E6979C17-0BC6-47D1-9B73-254D84306A96"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.4.8:*:*:*:*:*:*:*", "matchCriteriaId": "204C7C05-3441-4DB0-8702-D99C8FCB381E"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.4.9:pre1:*:*:*:*:*:*", "matchCriteriaId": "2E1A7011-B992-4E35-B306-45772DACB23C"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.5:*:*:*:*:*:*:*", "matchCriteriaId": "8D486C17-FC4A-4AEE-A430-1B1FBCC2C27C"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.5.1:*:*:*:*:*:*:*", "matchCriteriaId": "632BC7C2-FE59-47B0-885C-0EB8C74DF041"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.5.2:*:*:*:*:*:*:*", "matchCriteriaId": "5D1AE0BF-A6FD-4EBA-BF61-07AC81EA560D"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.5.3:*:*:*:*:*:*:*", "matchCriteriaId": "5B8FA106-FE65-4BB0-92A7-E8A5AF978A9B"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.5.4:*:*:*:*:*:*:*", "matchCriteriaId": "514669DA-8D02-44CE-BE18-8783F69AE394"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.5.4.5:*:*:*:*:*:*:*", "matchCriteriaId": "8041E6ED-472A-40DF-AA90-F3509D90D47A"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.5.4.6:*:*:*:*:*:*:*", "matchCriteriaId": "D2C64382-9259-4D61-B352-7F123527289C"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.5.5:*:*:*:*:*:*:*", "matchCriteriaId": "32A152D9-947E-4198-9C2D-2A582F09AB75"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.6:*:*:*:*:*:*:*", "matchCriteriaId": "37FBB817-A186-4517-9DA7-B3638576AAE7"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.6.1:*:*:*:*:*:*:*", "matchCriteriaId": "157ABA40-6101-4E9C-A24C-84F8E23D374D"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.6.2:*:*:*:*:*:*:*", "matchCriteriaId": "C7EA46DD-2CC4-426F-8709-821B7572C94A"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.6.3:*:*:*:*:*:*:*", "matchCriteriaId": "3DE12C59-4409-4F7A-9759-7B26FA9DAC34"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.7:*:*:*:*:*:*:*", "matchCriteriaId": "30FE6578-F031-4F5B-B955-8F912CFCA1B0"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.7.1:*:*:*:*:*:*:*", "matchCriteriaId": "07669E0E-8C4B-430E-802F-F64EEA2B5A0B"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.7.2:*:*:*:*:*:*:*", "matchCriteriaId": "F3EB7F17-F25D-4E48-8A43-F799619CE71F"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.7.3:*:*:*:*:*:*:*", "matchCriteriaId": "60705A3B-7136-45D1-8068-E2DC9E01EB04"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.7.4:*:*:*:*:*:*:*", "matchCriteriaId": "C722B143-2648-4EB2-A090-7B788F41F300"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.7.5:*:*:*:*:*:*:*", "matchCriteriaId": "B31AFDBC-A782-4C18-8EAA-6D927397BEA3"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.7.6:*:*:*:*:*:*:*", "matchCriteriaId": "73E9E8F4-A942-4F34-BCE2-82A180F1DD1F"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.7.7:*:*:*:*:*:*:*", "matchCriteriaId": "AAA31D75-C3FB-4D89-8B2D-21372AAEB78B"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.7.8:*:*:*:*:*:*:*", "matchCriteriaId": "B20E5358-826C-47A2-B39F-ED4E9213BA95"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.7.9:*:*:*:*:*:*:*", "matchCriteriaId": "26321888-E140-4F09-AAA0-7392AA7F6307"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.7.11:*:*:*:*:*:*:*", "matchCriteriaId": "7E46B9F3-A9C0-4B8A-A119-40CA4CBBD0EE"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.7.12:*:*:*:*:*:*:*", "matchCriteriaId": "44800572-71C5-4AA1-9CB6-30AA902B0353"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.8.0:*:*:*:*:*:*:*", "matchCriteriaId": "87090477-1D36-48B3-88AE-5CD5EE8F89D7"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.8.1:*:*:*:*:*:*:*", "matchCriteriaId": "2096FF8B-9B57-4C59-84DB-9CC0DEAB47AC"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.8.2:*:*:*:*:*:*:*", "matchCriteriaId": "34C99254-776C-4AAD-BDA2-3F544256AA67"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.8.5:*:*:*:*:*:*:*", "matchCriteriaId": "CE9D7B73-9CDA-4BAE-8DD9-8E1E34C20648"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.8.5.3:*:*:*:*:*:*:*", "matchCriteriaId": "4FDBF2C0-8E33-4575-8A19-4F1CABA3023F"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.8.5.4:*:*:*:*:*:*:*", "matchCriteriaId": "72040664-077A-48FB-9E6B-B69EA8D26CB4"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.8.6:*:*:*:*:*:*:*", "matchCriteriaId": "F428A2E4-A54F-4296-A00F-1A4E160253D7"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.8.7:*:*:*:*:*:*:*", "matchCriteriaId": "5239E4FA-0359-49F1-93D4-24AB013FAC20"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.8.8:*:*:*:*:*:*:*", "matchCriteriaId": "F0C8230D-4E89-45F9-B0F7-E317119E0FA0"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.8.10:*:*:*:*:*:*:*", "matchCriteriaId": "585CE7D2-1CE8-44AB-AE67-07D7D3721F68"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.8.11:*:*:*:*:*:*:*", "matchCriteriaId": "EE81C339-A794-4303-B829-BE743DF0B132"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.9:*:*:*:*:*:*:*", "matchCriteriaId": "5CE0A27B-66D7-4D1B-8E6A-F4722C070BD3"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.9.1:*:*:*:*:*:*:*", "matchCriteriaId": "864DC4A2-A378-4389-B62E-9E785879A744"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.10:*:*:*:*:*:*:*", "matchCriteriaId": "16304267-C808-4B6B-9903-2DEAB40AD899"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.10.3:*:*:*:*:*:*:*", "matchCriteriaId": "CEEBBA83-1BFC-45A8-B34A-AB3A9B8A9414"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.10.4:*:*:*:*:*:*:*", "matchCriteriaId": "F559B34E-23EE-4E09-A044-E7F54C55B05E"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:0.11:*:*:*:*:*:*:*", "matchCriteriaId": "62BA2708-BE77-42B7-B51A-C1B58632462C"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:1.0:*:*:*:*:*:*:*", "matchCriteriaId": "23E57BB1-DF1E-4173-BE52-72E2B3E6BA23"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:1.1.1:*:*:*:*:*:*:*", "matchCriteriaId": "A3E30DB1-0CFC-4EAA-BF07-CE7551ABDCB5"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:1.1.2:*:*:*:*:*:*:*", "matchCriteriaId": "DBA7D745-DC16-43B9-8A2D-4D6944A6BFD0"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:1.1.3:*:*:*:*:*:*:*", "matchCriteriaId": "87A511A5-2040-433A-9B32-B89332214FA6"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:1.1.4:*:*:*:*:*:*:*", "matchCriteriaId": "0C01DD9C-98C9-4896-8D66-A8336582298B"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:1.2:*:*:*:*:*:*:*", "matchCriteriaId": "BBE7723A-3D6B-4390-B82E-6A5A6992141A"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:1.2.1:*:*:*:*:*:*:*", "matchCriteriaId": "1ED8FF93-5AA7-443C-BBDB-845736BB337B"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:2.0:*:*:*:*:*:*:*", "matchCriteriaId": "A1337F5B-E9D9-4335-9E05-50018E59E530"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:6.0:*:*:*:*:*:*:*", "matchCriteriaId": "036E8A89-7A16-411F-9D31-676313BB7244"}]}]}], "references": [{"url": "http://ffmpeg.org/security.html", "source": "cve@mitre.org", "tags": ["Vendor Advisory"]}, {"url": "http://openwall.com/lists/oss-security/2013/11/26/7", "source": "cve@mitre.org", "tags": ["Mailing List", "Patch", "Third Party Advisory"]}, {"url": "http://openwall.com/lists/oss-security/2013/12/08/3", "source": "cve@mitre.org", "tags": ["Mailing List", "Patch", "Third Party Advisory"]}, {"url": "http://secunia.com/advisories/61389", "source": "cve@mitre.org"}, {"url": "http://www.debian.org/security/2014/dsa-3027", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "http://www.mandriva.com/security/advisories?name=MDVSA-2014:227", "source": "cve@mitre.org", "tags": ["Broken Link"]}, {"url": "https://github.com/FFmpeg/FFmpeg/commit/b05cd1ea7e45a836f7f6071a716c38bb30326e0f", "source": "cve@mitre.org", "tags": ["Patch", "Issue Tracking"]}, {"url": "https://security.gentoo.org/glsa/201603-06", "source": "cve@mitre.org"}]}, "github_commit_url": "https://github.com/FFmpeg/FFmpeg/commit/b05cd1ea7e45a836f7f6071a716c38bb30326e0f"}}
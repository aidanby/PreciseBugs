{"buggy_code": ["// Copyright (c) Open Enclave SDK contributors.\n// Licensed under the MIT License.\n\n#ifndef _ASM_COMMON_INC\n#define _ASM_COMMON_INC\n\n//==============================================================================\n//\n// This macro is used to reset all XSAVE supported state components to a\n// clean initial state. This includes:\n//\n//  - The legacy SSE state:\n//    - Initializes the FPU control word to ABI-specified value 0x037F\n//    - Initializes MXCSR to ABI-specified value 0x1F80 and MXCSR_MASK to 0xFFFF\n//    - Clears FPU Status, Tag, OpCode, and FIP words\n//    - Clears all FDP bits\n//    - Clears all MMX/FPU registers\n//    - Clears all XMM registers\n//\n//  - The extended XSAVE state components:\n//    - Clears all XSTATE_BV bits\n//    - Sets XCOMP_BV bit-63 to support compaction mode\n//    - Clears all other XCOMP_BV bits\n//\n//==============================================================================\n.macro oe_cleanup_xstates\n    // Preserve registers being used\n    mov %rax, %r8\n    mov %rdx, %r9\n\n    // Check if extended states are supported by the OS.\n    // If not, fallback to FXRSTOR to clear legacy SSE states only.\n    // Otherwise, clear both legacy SSE states and extended states with XRSTOR.\n    movl    oe_is_xsave_supported(%rip), %eax\n    cmpl    $0, %eax\n    jz      1f\n\n    // Set the XSAVE_MASK\n    mov $0xFFFFFFFF, %eax\n    mov $0xFFFFFFFF, %edx\n\n    // Restore initial enclave XSAVE state\n    xrstor64 OE_XSAVE_INITIAL_STATE(%rip)\n    jmp     2f\n1:\n    // Restore initial enclave legacy SSE state\n    fxrstor64 OE_XSAVE_INITIAL_STATE(%rip)\n2:\n    // Restore the registers\n    mov %r8, %rax\n    mov %r9, %rdx\n.endm\n\n//==============================================================================\n//\n// This macro is used to clean up the enclave registers in addition to the\n// extended states (see oe_cleanup_xstates).\n//\n// It scrubs all general purpose registers excluding:\n//  - RAX and RBX, which are used as input registers of EEXIT.\n//  - RCX, which is used as the output register of EEXIT.\n//  - RDI and RSI, which are used as output parameters defined by SDK.\n//  - RBP and RSP, which will be set to host values of RBP & RSP right before\n//      EEXIT is executed.\n//\n//==============================================================================\n.macro oe_cleanup_registers\n    // Scrub both Legacy SSE and extended XSTATEs.\n    oe_cleanup_xstates\n\n    // Zero out GPRs.\n    // Retain r11 since it is used as a reference to the td structure.\n    // The exit and enter routines are responsible for clearing r11\n    // prior to returning.\n    xor %rdx, %rdx\n    xor %r9,  %r9\n    xor %r10, %r10\n    xor %r12, %r12\n    xor %r13, %r13\n    xor %r14, %r14\n    xor %r15, %r15\n\n    // Zero out the RFLAGS except for system flags and\n    // reserved bits that are not writable by the enclave\n    mov %rax, %r8\n    xor %rax, %rax\n    test %al, %al // Clear OF\n    cld // Clear DF\n    sahf // Clear SF, ZF AF, PF, and CF\n    mov %r8, %rax\n\n    // No need to clear r8, which equals to rax (return value to the host)\n\n.endm\n\n#endif\n", "// Copyright (c) Open Enclave SDK contributors.\n// Licensed under the MIT License.\n\n#include <openenclave/bits/types.h>\n#include <openenclave/internal/constants_x64.h>\n\n/*\n * Initialization state for XSAVE area in the enclave.\n */\n/* clang-format off */\nOE_ALIGNED(OE_XSAVE_ALIGNMENT) const uint32_t\nOE_XSAVE_INITIAL_STATE[OE_MINIMAL_XSTATE_AREA_SIZE/sizeof(uint32_t)] = {\n\n    /* FXSAVE (a.k.a. legacy XSAVE) area */\n    /* Set FPU Control Word to ABI init value of 0x037F,\n     * clear Status, Tag, OpCode, FIP words */\n    0x037F, 0, 0, 0,\n\n    /* Clear FDP bits, set MXCSR to ABI init value of 0x1F80\n     * and MXCSR_MASK to all bits (0XFFFF) */\n    0, 0, 0x1F80, 0xFFFF,\n\n    /* Clear ST/MM0-7 */\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n\n    /* Clear XMM0-15 */\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n\n    /* Reserved bits up to end of FXSAVE area */\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0,\n\n    /* XSAVE Header */\n    /* Clear XSTATE_BV. Note that this means we don't support\n     * compaction mode (XCOMP_BV[63]) to accommodate running\n     * the same code in simulation mode on older CPUs. */\n    0, 0, 0, 0,\n\n    /* Reserved XSAVE header bits */\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n};\n/* clang-format on */\n", "// Copyright (c) Open Enclave SDK contributors.\n// Licensed under the MIT License.\n\n#include \"../calls.h\"\n#include <openenclave/advanced/allocator.h>\n#include <openenclave/attestation/attester.h>\n#include <openenclave/attestation/verifier.h>\n#include <openenclave/bits/sgx/sgxtypes.h>\n#include <openenclave/corelibc/stdlib.h>\n#include <openenclave/corelibc/string.h>\n#include <openenclave/edger8r/enclave.h>\n#include <openenclave/enclave.h>\n#include <openenclave/internal/atomic.h>\n#include <openenclave/internal/calls.h>\n#include <openenclave/internal/crypto/init.h>\n#include <openenclave/internal/fault.h>\n#include <openenclave/internal/globals.h>\n#include <openenclave/internal/jump.h>\n#include <openenclave/internal/malloc.h>\n#include <openenclave/internal/print.h>\n#include <openenclave/internal/raise.h>\n#include <openenclave/internal/safecrt.h>\n#include <openenclave/internal/safemath.h>\n#include <openenclave/internal/sgx/ecall_context.h>\n#include <openenclave/internal/sgx/td.h>\n#include <openenclave/internal/thread.h>\n#include <openenclave/internal/trace.h>\n#include <openenclave/internal/types.h>\n#include <openenclave/internal/utils.h>\n#include \"../../../common/sgx/sgxmeasure.h\"\n#include \"../../sgx/report.h\"\n#include \"../atexit.h\"\n#include \"../tracee.h\"\n#include \"arena.h\"\n#include \"asmdefs.h\"\n#include \"core_t.h\"\n#include \"cpuid.h\"\n#include \"handle_ecall.h\"\n#include \"init.h\"\n#include \"openenclave/bits/result.h\"\n#include \"openenclave/internal/backtrace.h\"\n#include \"platform_t.h\"\n#include \"report.h\"\n#include \"switchlesscalls.h\"\n#include \"td.h\"\n#include \"xstate.h\"\n\nvoid oe_abort_with_td(oe_sgx_td_t* td) OE_NO_RETURN;\n\noe_result_t __oe_enclave_status = OE_OK;\nuint8_t __oe_initialized = 0;\n\n/*\n**==============================================================================\n**\n** Glossary:\n**\n**     TCS      - Thread control structure. The TCS is an address passed to\n**                EENTER and passed onto the entry point (_start). The TCS\n**                is the address of a TCS page in the enclave memory. This page\n**                is not accessible to the enclave itself. The enclave stores\n**                state about the execution of a thread in this structure,\n**                such as the entry point (TCS.oentry), which refers to the\n**                _start function. It also maintains the index of the\n**                current SSA (TCS.cssa) and the number of SSA's (TCS.nssa).\n**\n**     oe_sgx_td_t       - Thread data. Per thread data as defined by the\n**                oe_thread_data_t structure and extended by the oe_sgx_td_t\n*structure.\n**                This structure records the stack pointer of the last EENTER.\n**\n**     SP       - Stack pointer. Refers to the enclave's stack pointer.\n**\n**     BP       - Base pointer. Refers to the enclave's base pointer.\n**\n**     HOSTSP   - Host stack pointer. Refers to the host's stack pointer as\n**                received in the EENTER call.\n**\n**     HOSTBP   - Host base pointer. Refers to the host's base pointer as\n**                received in the EENTER call.\n**\n**     AEP      - Asynchronous Exception Procedure. This procedure is passed\n**                by the host to EENTER. If a fault occurs while in the enclave,\n**                the hardware calls this procedure. The procedure may\n**                terminate or call ERESUME to continue executing in the\n**                enclave.\n**\n**     AEX      - Asynchronous Exception (occurs when enclave faults). The\n**                hardware transfers control to a host AEP (passed as a\n**                parameter to EENTER).\n**\n**     SSA      - State Save Area. When a fault occurs in the enclave, the\n**                hardware saves the state here (general purpose registers)\n**                and then transfers control to the host AEP. If the AEP\n**                executes the ERESUME instruction, the hardware restores the\n**                state from the SSA.\n**\n**     EENTER   - An untrusted instruction that is executed by the host to\n**                enter the enclave. The caller passes the address of a TCS page\n**                within the enclave, an AEP, and any parameters in the RDI and\n**                RSI registers. This implementation passes the operation\n**                number (FUNC) in RDI and a pointer to the arguments structure\n**                (ARGS) in RSI.\n**\n**     EEXIT    - An instruction that is executed by the host to exit the\n**                enclave and return control to the host. The caller passes\n**                the address of some instruction to jump to (RETADDR) in the\n**                RBX register and an AEP in the RCX register (null at this\n**                time).\n**\n**     RETADDR  - Refers to the address of the return instruction that the\n**                hardware jumps to from EEXIT. This is an instruction in\n**                host immediately following the instruction that executed\n**                EENTER.\n**\n**     CSSA     - The current SSA slot index (as given by TCS.cssa). EENTER\n**                passes a CSSA parameter (RAX) to _start(). A CSSA of zero\n**                indicates a normal entry. A non-zero CSSA indicates an\n**                exception entry (an AEX has occurred).\n**\n**     NSSA     - The number of SSA slots in the thread section (of this\n**                enclave. If CSSA == NSSA, then the SSA's have been exhausted\n**                and the EENTER instruction will fault.\n**\n**     ECALL    - A function call initiated by the host and carried out by\n**                the enclave. The host executes the EENTER instruction to\n**                enter the enclave.\n**\n**     ERET     - A return from an ECALL initiated by the enclave. The\n**                enclave executes the EEXIT instruction to exit the enclave.\n**\n**     OCALL    - A function call initiated by the enclave and carried out\n**                by the host. The enclave executes the EEXIT instruction to\n**                exit the enclave.\n**\n**     ORET     - A return from an OCALL initiated by the host. The host\n**                executes the EENTER instruction to enter the enclave.\n**\n**==============================================================================\n*/\n\n/*\n**==============================================================================\n** oe_libc_initialize()\n**\n**   Weak implementation of libc initialization function.\n**\n**==============================================================================\n*/\nOE_WEAK void oe_libc_initialize(void)\n{\n}\n\n/*\n**==============================================================================\n**\n** _handle_init_enclave()\n**\n**     Handle the OE_ECALL_INIT_ENCLAVE from host and ensures that each state\n**     initialization function in the enclave only runs once.\n**\n**==============================================================================\n*/\nstatic oe_result_t _handle_init_enclave(uint64_t arg_in)\n{\n    static bool _once = false;\n    oe_result_t result = OE_OK;\n    /* Double checked locking (DCLP). */\n    bool o = _once;\n\n    /* DCLP Acquire barrier. */\n    OE_ATOMIC_MEMORY_BARRIER_ACQUIRE();\n    if (o == false)\n    {\n        static oe_spinlock_t _lock = OE_SPINLOCK_INITIALIZER;\n        oe_spin_lock(&_lock);\n\n        if (_once == false)\n        {\n            oe_enclave_t* enclave = (oe_enclave_t*)arg_in;\n\n            if (!oe_is_outside_enclave(enclave, 1))\n                OE_RAISE(OE_INVALID_PARAMETER);\n\n            oe_enclave = enclave;\n\n            /* Initialize the CPUID table before calling global constructors. */\n            OE_CHECK(oe_initialize_cpuid());\n\n            /* Initialize the xstate settings\n             * Depends on TD and sgx_create_report, so can't happen earlier */\n            OE_CHECK(oe_set_is_xsave_supported());\n\n            /* Initialize libc */\n            oe_libc_initialize();\n\n            /* Initialize the OE crypto library. */\n            oe_crypto_initialize();\n\n            /* Call global constructors. Now they can safely use simulated\n             * instructions like CPUID. */\n            oe_call_init_functions();\n\n            /* DCLP Release barrier. */\n            OE_ATOMIC_MEMORY_BARRIER_RELEASE();\n            _once = true;\n            __oe_initialized = 1;\n        }\n\n        oe_spin_unlock(&_lock);\n    }\ndone:\n    return result;\n}\n\n/**\n * This is the preferred way to call enclave functions.\n */\noe_result_t oe_handle_call_enclave_function(uint64_t arg_in)\n{\n    oe_call_enclave_function_args_t args = {0}, *args_host_ptr = NULL;\n    oe_call_function_return_args_t* return_args_ptr = NULL;\n    oe_result_t result = OE_OK;\n    oe_ecall_func_t func = NULL;\n    uint8_t* buffer = NULL;\n    uint8_t* input_buffer = NULL;\n    uint8_t* output_buffer = NULL;\n    size_t buffer_size = 0;\n    size_t output_bytes_written = 0;\n    ecall_table_t ecall_table;\n\n    // Ensure that args lies outside the enclave and is 8-byte aligned\n    // (against the xAPIC vulnerability).\n    // The size of oe_call_enclave_function_args_t is guaranteed to be\n    // 8-byte aligned via compile-time checks.\n    if (!oe_is_outside_enclave(\n            (void*)arg_in, sizeof(oe_call_enclave_function_args_t)) ||\n        (arg_in % 8) != 0)\n        OE_RAISE(OE_INVALID_PARAMETER);\n\n    // Copy args to enclave memory to avoid TOCTOU issues.\n    args_host_ptr = (oe_call_enclave_function_args_t*)arg_in;\n    oe_memcpy_aligned(\n        &args, args_host_ptr, sizeof(oe_call_enclave_function_args_t));\n\n    // Ensure that input buffer is valid (oe_is_outside_enclave ensures\n    // the buffer is not NULL).\n    // The buffer size must at least equal to oe_call_function_args_t\n    if (!oe_is_outside_enclave(args.input_buffer, args.input_buffer_size) ||\n        args.input_buffer_size < sizeof(oe_call_function_return_args_t))\n        OE_RAISE(OE_INVALID_PARAMETER);\n\n    // Ensure that output buffer is valid (oe_is_outside_enclave ensures\n    // the buffer is not NULL).\n    // The buffer size must at least equal to oe_call_function_return_args_t\n    if (!oe_is_outside_enclave(args.output_buffer, args.output_buffer_size) ||\n        args.output_buffer_size < sizeof(oe_call_function_return_args_t))\n        OE_RAISE(OE_INVALID_PARAMETER);\n\n    // Validate output and input buffer addresses and sizes.\n    // Both of them must be correctly aligned (against the xAPIC vulnerability).\n    if ((args.input_buffer_size % OE_EDGER8R_BUFFER_ALIGNMENT) != 0 ||\n        ((uint64_t)args.input_buffer % 8) != 0)\n        OE_RAISE(OE_INVALID_PARAMETER);\n\n    if ((args.output_buffer_size % OE_EDGER8R_BUFFER_ALIGNMENT) != 0 ||\n        ((uint64_t)args.output_buffer % 8) != 0)\n        OE_RAISE(OE_INVALID_PARAMETER);\n\n    OE_CHECK(oe_safe_add_u64(\n        args.input_buffer_size, args.output_buffer_size, &buffer_size));\n\n    // The __oe_ecall_table is defined in the oeedger8r-generated\n    // code.\n    ecall_table.ecalls = oe_ecalls_table;\n    ecall_table.num_ecalls = oe_ecalls_table_size;\n\n    // Fetch matching function.\n    if (args.function_id >= ecall_table.num_ecalls)\n        OE_RAISE(OE_NOT_FOUND);\n\n    func = ecall_table.ecalls[args.function_id];\n\n    if (func == NULL)\n        OE_RAISE(OE_NOT_FOUND);\n\n    // Allocate buffers in enclave memory\n    buffer = input_buffer = oe_malloc(buffer_size);\n    if (buffer == NULL)\n        OE_RAISE(OE_OUT_OF_MEMORY);\n\n    // Copy input buffer from the host to enclave buffer.\n    oe_memcpy_aligned(input_buffer, args.input_buffer, args.input_buffer_size);\n\n    // Clear out output buffer.\n    // This ensures reproducible behavior if say the function is reading from\n    // output buffer.\n    output_buffer = buffer + args.input_buffer_size;\n    memset(output_buffer, 0, args.output_buffer_size);\n\n    // Call the function.\n    func(\n        input_buffer,\n        args.input_buffer_size,\n        output_buffer,\n        args.output_buffer_size,\n        &output_bytes_written);\n\n    /*\n     * The output_buffer is expected to point to a marshaling struct.\n     * The function is expected to fill the struct.\n     */\n    return_args_ptr = (oe_call_function_return_args_t*)output_buffer;\n\n    result = return_args_ptr->result;\n    if (result == OE_OK)\n    {\n        /*\n         * Error out the case if the deepcopy_out_buffer is NULL but the\n         * deepcopy_out_buffer_size is not zero or if the deepcopy_out_buffer is\n         * not NULL but the deepcopy_out_buffer_size is zero. Note that this\n         * should only occur if the oeedger8r was not used or if\n         * oeedger8r-generated routine is modified.\n         */\n        if ((!return_args_ptr->deepcopy_out_buffer &&\n             return_args_ptr->deepcopy_out_buffer_size) ||\n            (return_args_ptr->deepcopy_out_buffer &&\n             !return_args_ptr->deepcopy_out_buffer_size))\n            OE_RAISE(OE_UNEXPECTED);\n\n        /*\n         * Nonzero deepcopy_out_buffer and deepcopy_out_buffer_size fields\n         * indicate that there is deep-copied content that needs to be\n         * transmitted to the host.\n         */\n        if (return_args_ptr->deepcopy_out_buffer &&\n            return_args_ptr->deepcopy_out_buffer_size)\n        {\n            /*\n             * Ensure that the content lies in enclave memory.\n             * Note that this should only fail if oeedger8r was not used or if\n             * the oeedger8r-generated routine is modified.\n             */\n            if (!oe_is_within_enclave(\n                    return_args_ptr->deepcopy_out_buffer,\n                    return_args_ptr->deepcopy_out_buffer_size))\n                OE_RAISE(OE_UNEXPECTED);\n\n            void* host_buffer =\n                oe_host_malloc(return_args_ptr->deepcopy_out_buffer_size);\n\n            /* Copy the deep-copied content to host memory. */\n            OE_CHECK(oe_memcpy_s_with_barrier(\n                host_buffer,\n                return_args_ptr->deepcopy_out_buffer_size,\n                return_args_ptr->deepcopy_out_buffer,\n                return_args_ptr->deepcopy_out_buffer_size));\n\n            /* Release the memory on the enclave heap. */\n            oe_free(return_args_ptr->deepcopy_out_buffer);\n\n            return_args_ptr->deepcopy_out_buffer = host_buffer;\n        }\n\n        // Copy outputs to host memory.\n        OE_CHECK(oe_memcpy_s_with_barrier(\n            args.output_buffer,\n            args.output_buffer_size,\n            output_buffer,\n            args.output_buffer_size));\n\n        // The ecall succeeded.\n        OE_WRITE_VALUE_WITH_BARRIER(\n            &args_host_ptr->output_bytes_written, output_bytes_written);\n        OE_WRITE_VALUE_WITH_BARRIER(&args_host_ptr->result, OE_OK);\n    }\n\ndone:\n    if (result != OE_OK && return_args_ptr && args.output_buffer)\n    {\n        return_args_ptr->result = result;\n        return_args_ptr->deepcopy_out_buffer = NULL;\n        return_args_ptr->deepcopy_out_buffer_size = 0;\n\n        oe_memcpy_s_with_barrier(\n            args.output_buffer,\n            args.output_buffer_size,\n            return_args_ptr,\n            sizeof(oe_call_function_return_args_t));\n    }\n\n    if (buffer)\n        oe_free(buffer);\n\n    return result;\n}\n\n/*\n**==============================================================================\n**\n** _handle_exit()\n**\n**     Initiate call to EEXIT.\n**\n**==============================================================================\n*/\nstatic void _handle_exit(oe_code_t code, uint16_t func, uint64_t arg)\n    OE_NO_RETURN;\n\nstatic void _handle_exit(oe_code_t code, uint16_t func, uint64_t arg)\n{\n    oe_exit_enclave(oe_make_call_arg1(code, func, 0, OE_OK), arg);\n}\n\nvoid oe_virtual_exception_dispatcher(\n    oe_sgx_td_t* td,\n    uint64_t arg_in,\n    uint64_t* arg_out);\n\n/*\n**==============================================================================\n**\n** _call_at_exit_functions()\n**\n**     Invoke atexit functions (e.g., registered by atexit() or the destructor\n**     attribute)\n**\n**==============================================================================\n*/\nstatic void _call_at_exit_functions(void)\n{\n    static bool _at_exit_functions_done = false;\n    static oe_spinlock_t _lock = OE_SPINLOCK_INITIALIZER;\n\n    oe_spin_lock(&_lock);\n    if (!_at_exit_functions_done)\n    {\n        /* Call functions installed by oe_cxa_atexit() and oe_atexit()\n         */\n        oe_call_atexit_functions();\n\n        /* Call all finalization functions */\n        oe_call_fini_functions();\n\n        _at_exit_functions_done = true;\n    }\n    oe_spin_unlock(&_lock);\n}\n\n/*\n**==============================================================================\n**\n** _enclave_destructor()\n**\n**==============================================================================\n*/\nstatic oe_result_t _enclave_destructor(void)\n{\n    oe_result_t result = OE_FAILURE;\n    static bool _destructor_done = false;\n    static oe_spinlock_t _lock = OE_SPINLOCK_INITIALIZER;\n\n    oe_spin_lock(&_lock);\n    if (!_destructor_done)\n    {\n        /* Cleanup attesters */\n        oe_attester_shutdown();\n\n        /* Cleanup verifiers */\n        oe_verifier_shutdown();\n\n        /* If memory still allocated, print a trace and return an error */\n        OE_CHECK(oe_check_memory_leaks());\n\n        /* Cleanup the allocator */\n        oe_allocator_cleanup();\n\n        _destructor_done = true;\n    }\n\n    result = OE_OK;\n\ndone:\n    oe_spin_unlock(&_lock);\n    return result;\n}\n\n/*\n**==============================================================================\n**\n** _handle_ecall()\n**\n**     Handle an ECALL.\n**\n**==============================================================================\n*/\n\nstatic void _handle_ecall(\n    oe_sgx_td_t* td,\n    uint16_t func,\n    uint64_t arg_in,\n    uint64_t* output_arg1,\n    uint64_t* output_arg2)\n{\n    /* To keep status of td consistent before and after _handle_ecall, td_init\n     is moved into _handle_ecall. In this way _handle_ecall will not trigger\n     stack check fail by accident. Of course not all function have the\n     opportunity to keep such consistency. Such basic functions are moved to a\n     separate source file and the stack protector is disabled by force\n     through fno-stack-protector option. */\n\n    /* Initialize thread data structure (if not already initialized) */\n    if (!td_initialized(td))\n    {\n        td_init(td);\n    }\n\n    oe_result_t result = OE_OK;\n\n    /* Insert ECALL context onto front of oe_sgx_td_t.ecalls list */\n    oe_callsite_t callsite = {{0}};\n    uint64_t arg_out = 0;\n\n    td_push_callsite(td, &callsite);\n\n    // Acquire release semantics for __oe_initialized are present in\n    // _handle_init_enclave.\n    if (!__oe_initialized)\n    {\n        // The first call to the enclave must be to initialize it.\n        // Global constructors can throw exceptions/signals and result in signal\n        // handlers being invoked. Eg. Using CPUID instruction within a global\n        // constructor. We should also allow handling these exceptions.\n        if (func != OE_ECALL_INIT_ENCLAVE &&\n            func != OE_ECALL_VIRTUAL_EXCEPTION_HANDLER)\n        {\n            goto done;\n        }\n    }\n    else\n    {\n        // Disallow re-initialization.\n        if (func == OE_ECALL_INIT_ENCLAVE)\n        {\n            goto done;\n        }\n    }\n\n    // td_push_callsite increments the depth. depth > 1 indicates a reentrant\n    // call. Reentrancy is allowed to handle exceptions and to terminate the\n    // enclave.\n    if (td->depth > 1 && (func != OE_ECALL_VIRTUAL_EXCEPTION_HANDLER &&\n                          func != OE_ECALL_DESTRUCTOR))\n    {\n        /* reentrancy not permitted. */\n        result = OE_REENTRANT_ECALL;\n        goto done;\n    }\n\n    /* Dispatch the ECALL */\n    switch (func)\n    {\n        case OE_ECALL_CALL_ENCLAVE_FUNCTION:\n        {\n            arg_out = oe_handle_call_enclave_function(arg_in);\n            break;\n        }\n        case OE_ECALL_CALL_AT_EXIT_FUNCTIONS:\n        {\n            _call_at_exit_functions();\n            break;\n        }\n        case OE_ECALL_DESTRUCTOR:\n        {\n            /* Invoke atexit functions in case the host does not invoke\n             * the CALL_AT_EXIT_FUNCTIONS ecall before the DESTRUCTOR ecall\n             * (retaining the previous behavior) */\n            _call_at_exit_functions();\n\n            OE_CHECK(_enclave_destructor());\n\n            break;\n        }\n        case OE_ECALL_VIRTUAL_EXCEPTION_HANDLER:\n        {\n            oe_virtual_exception_dispatcher(td, arg_in, &arg_out);\n            break;\n        }\n        case OE_ECALL_INIT_ENCLAVE:\n        {\n            arg_out = _handle_init_enclave(arg_in);\n            break;\n        }\n        default:\n        {\n            /* No function found with the number */\n            result = OE_NOT_FOUND;\n            goto done;\n        }\n    }\n\ndone:\n\n    /* Free shared memory arena before we clear TLS */\n    if (td->depth == 1)\n    {\n        oe_teardown_arena();\n    }\n\n    /* Remove ECALL context from front of oe_sgx_td_t.ecalls list */\n    td_pop_callsite(td);\n\n    /* Perform ERET, giving control back to host */\n    *output_arg1 = oe_make_call_arg1(OE_CODE_ERET, func, 0, result);\n    *output_arg2 = arg_out;\n}\n\n/*\n**==============================================================================\n**\n** _handle_oret()\n**\n**     Handle an OCALL return.\n**\n**==============================================================================\n*/\n\nOE_INLINE void _handle_oret(\n    oe_sgx_td_t* td,\n    uint16_t func,\n    uint16_t result,\n    uint64_t arg)\n{\n    oe_callsite_t* callsite = td->callsites;\n\n    if (!callsite)\n        return;\n\n    td->oret_func = func;\n    td->oret_result = result;\n    td->oret_arg = arg;\n\n    /* Restore the FXSTATE and flags */\n    asm volatile(\"pushq %[rflags] \\n\\t\" // Restore flags.\n                 \"popfq \\n\\t\"\n                 \"fldcw %[fcw] \\n\\t\"     // Restore x87 control word\n                 \"ldmxcsr %[mxcsr] \\n\\t\" // Restore MXCSR\n                 : [mxcsr] \"=m\"(callsite->mxcsr),\n                   [fcw] \"=m\"(callsite->fcw),\n                   [rflags] \"=m\"(callsite->rflags)\n                 :\n                 : \"cc\");\n\n    oe_longjmp(&callsite->jmpbuf, 1);\n}\n\n/*\n**==============================================================================\n**\n** oe_get_enclave_status()\n**\n**     Return the value of __oe_enclave_status to external code.\n**\n**==============================================================================\n*/\noe_result_t oe_get_enclave_status()\n{\n    return __oe_enclave_status;\n}\n\n/*\n**==============================================================================\n**\n** _exit_enclave()\n**\n** Exit the enclave.\n** Additionally, if a debug enclave, write the exit frame information to host's\n** ecall_context so that the host can stitch the ocall stack.\n**\n** This function is intended to be called by oe_asm_exit (see below).\n** When called, the call stack would look like this:\n**\n**     enclave-function\n**       -> oe_ocall\n**         -> oe_exit_enclave (aliased as __morestack)\n**           -> _exit_enclave\n**\n** For debug enclaves, _exit_enclave reads its caller (oe_exit_enclave/\n** __morestack) information (return address, rbp) and passes it along to the\n** host in the ecall_context.\n**\n** Then it proceeds to exit the enclave by invoking oe_asm_exit.\n** oe_asm_exit invokes eexit instruction which resumes execution in host at the\n** oe_enter function. The host dispatches the ocall via the following sequence:\n**\n**     oe_enter\n**       -> __oe_host_stack_bridge   (Stitches the ocall stack)\n**         -> __oe_dispatch_ocall\n**           -> invoke ocall function\n**\n** Now that the enclave exit frame is available to the host,\n** __oe_host_stack_bridge temporarily modifies its caller info with the\n** enclave's exit information so that the stitched stack looks like this:\n**\n**     enclave-function                                    |\n**       -> oe_ocall                                       |\n**         -> oe_exit_enclave (aliased as __morestack)     | in enclave\n**   --------------------------------------------------------------------------\n**           -> __oe_host_stack_bridge                     | in host\n**             -> __oe_dispatch_ocall                      |\n**               -> invoke ocall function                  |\n**\n** This stitching of the stack is temporary, and __oe_host_stack_bridge reverts\n** it prior to returning to its caller.\n**\n** Since the stitched (split) stack is preceded by the __morestack function, gdb\n** natively walks the stack correctly.\n**\n**==============================================================================\n*/\nOE_NEVER_INLINE\nOE_NO_RETURN\nstatic void _exit_enclave(uint64_t arg1, uint64_t arg2)\n{\n    oe_sgx_td_t* td = oe_sgx_get_td();\n\n    if (oe_is_enclave_debug_allowed())\n    {\n        oe_ecall_context_t* host_ecall_context = td->host_ecall_context;\n\n        // Make sure the context is valid.\n        if (host_ecall_context &&\n            oe_is_outside_enclave(\n                host_ecall_context, sizeof(*host_ecall_context)))\n        {\n            uint64_t* frame = (uint64_t*)__builtin_frame_address(0);\n\n            /* NOTE: host memory writes that is only for debugging purposes,\n             * no need for using write with barrier */\n            host_ecall_context->debug_eexit_rbp = frame[0];\n            // The caller's RSP is always given by this equation\n            //   RBP + 8 (caller frame pointer) + 8 (caller return address)\n            host_ecall_context->debug_eexit_rsp = frame[0] + 8;\n            host_ecall_context->debug_eexit_rip = frame[1];\n        }\n    }\n    oe_asm_exit(arg1, arg2, td, 0 /* direct_return */);\n}\n\n/*\n**==============================================================================\n**\n** This function is wrapper of oe_asm_exit. It is needed to stitch the host\n** stack and enclave stack together. It calls oe_asm_exit via an intermediary\n** (_exit_enclave) that records the exit frame for ocall stack stitching.\n**\n** N.B: Don't change the function name, otherwise debugger can't work. GDB\n** depends on this hardcoded function name when does stack walking for split\n** stack. oe_exit_enclave has been #defined as __morestack.\n**==============================================================================\n*/\n\nOE_NEVER_INLINE\nvoid oe_exit_enclave(uint64_t arg1, uint64_t arg2)\n{\n    _exit_enclave(arg1, arg2);\n\n    // This code is never reached. It exists to prevent tail call optimization\n    // of the call to _exit_enclave. Tail-call optimization would effectively\n    // inline _exit_enclave, and its caller would be come the caller of\n    // oe_exit_enclave instead of oe_exit_enclave.\n    oe_abort();\n}\n\n/*\n**==============================================================================\n**\n** oe_ocall()\n**\n**     Initiate a call into the host (exiting the enclave).\n**\n** Remark: Given that the logging implementation relies on making an ocall to\n** host, any failures when handling oe_ocall should not invoke any oe_log\n** functions so as to avoid infinite recursion. OE_RAISE and OE_CHECK macros\n** call oe_log functions, and therefore the following code locations use\n** OE_RAISE_NO_TRACE and OE_CHECK_NO_TRACE macros.\n**==============================================================================\n*/\n\noe_result_t oe_ocall(uint16_t func, uint64_t arg_in, uint64_t* arg_out)\n{\n    oe_result_t result = OE_UNEXPECTED;\n    oe_sgx_td_t* td = oe_sgx_get_td();\n    oe_callsite_t* callsite = td->callsites;\n\n    /* If the enclave is in crashing/crashed status, new OCALL should fail\n    immediately. */\n    if (__oe_enclave_status != OE_OK)\n        OE_RAISE_NO_TRACE((oe_result_t)__oe_enclave_status);\n\n    /* Check for unexpected failures */\n    if (!callsite)\n        OE_RAISE_NO_TRACE(OE_UNEXPECTED);\n\n    /* Check for unexpected failures */\n    if (!td_initialized(td))\n        OE_RAISE_NO_TRACE(OE_FAILURE);\n\n    /* Preserve the FXSTATE and flags */\n    asm volatile(\"stmxcsr %[mxcsr] \\n\\t\" // Save MXCSR\n                 \"fstcw %[fcw] \\n\\t\"     // Save x87 control word\n                 \"pushfq \\n\\t\"           // Save flags.\n                 \"popq %[rflags] \\n\\t\"\n                 :\n                 : [mxcsr] \"m\"(callsite->mxcsr),\n                   [fcw] \"m\"(callsite->fcw),\n                   [rflags] \"m\"(callsite->rflags)\n                 :);\n\n    /* Save call site where execution will resume after OCALL */\n    if (oe_setjmp(&callsite->jmpbuf) == 0)\n    {\n        /* Exit, giving control back to the host so it can handle OCALL */\n        _handle_exit(OE_CODE_OCALL, func, arg_in);\n\n        /* Unreachable! Host will transfer control back to oe_enter() */\n        oe_abort();\n    }\n    else\n    {\n        /* ORET here */\n\n        OE_CHECK_NO_TRACE(result = (oe_result_t)td->oret_result);\n\n        if (arg_out)\n            *arg_out = td->oret_arg;\n\n        if (td->state != OE_TD_STATE_SECOND_LEVEL_EXCEPTION_HANDLING)\n        {\n            /* State machine check */\n            if (td->state != OE_TD_STATE_ENTERED)\n                oe_abort();\n\n            td->state = OE_TD_STATE_RUNNING;\n        }\n    }\n\n    result = OE_OK;\n\ndone:\n    return result;\n}\n\n/*\n**==============================================================================\n**\n** oe_call_host_function_by_table_id()\n**\n**==============================================================================\n*/\n\noe_result_t oe_call_host_function_internal(\n    uint64_t function_id,\n    const void* input_buffer,\n    size_t input_buffer_size,\n    void* output_buffer,\n    size_t output_buffer_size,\n    size_t* output_bytes_written,\n    bool switchless)\n{\n    oe_result_t result = OE_UNEXPECTED;\n    oe_call_host_function_args_t args, *args_host_ptr = NULL;\n    oe_call_function_return_args_t return_args, *return_args_host_ptr = NULL;\n    uint64_t host_result = 0;\n\n    /* Ensure input buffer is outside the enclave memory and its size is valid\n     */\n    if (!oe_is_outside_enclave(input_buffer, input_buffer_size) ||\n        input_buffer_size < sizeof(oe_call_function_return_args_t))\n        OE_RAISE(OE_INVALID_PARAMETER);\n\n    /* Ensure output buffer is outside the enclave memory and its size is\n     * valid. Also, check its address is 8-byte aligned (against the xAPIC\n     * vulnerability) */\n    if (!oe_is_outside_enclave(output_buffer, output_buffer_size) ||\n        output_buffer_size < sizeof(oe_call_function_return_args_t) ||\n        ((uint64_t)output_buffer % 8) != 0)\n        OE_RAISE(OE_INVALID_PARAMETER);\n\n    /*\n     * oe_post_switchless_ocall (below) can make a regular ocall to wake up the\n     * host worker thread, and will end up using the ecall context's args.\n     * Therefore, for switchless calls, allocate args in the arena so that it is\n     * is not overwritten by oe_post_switchless_ocall.\n     */\n    args_host_ptr =\n        (oe_call_host_function_args_t*)(switchless ? oe_arena_malloc(sizeof(*args_host_ptr)) : oe_ecall_context_get_ocall_args());\n\n    /* Ensure the args_host_ptr is valid and 8-byte aligned (for xAPIC\n     * vulnerability mitigation) */\n    if (!oe_is_outside_enclave(\n            (const void*)args_host_ptr, sizeof(oe_call_host_function_args_t)) ||\n        ((uint64_t)args_host_ptr % 8) != 0)\n    {\n        /* Fail if the enclave is crashing. */\n        OE_CHECK(__oe_enclave_status);\n        OE_RAISE(OE_UNEXPECTED);\n    }\n\n    /* Prepare a local copy of args */\n    args.function_id = function_id;\n    args.input_buffer = input_buffer;\n    args.input_buffer_size = input_buffer_size;\n    args.output_buffer = output_buffer;\n    args.output_buffer_size = output_buffer_size;\n    args.result = OE_UNEXPECTED;\n\n    /* Copy the local copy of args to host memory */\n    OE_CHECK(oe_memcpy_s_with_barrier(\n        args_host_ptr, sizeof(*args_host_ptr), &args, sizeof(args)));\n\n    /* Call the host function with this address */\n    if (switchless && oe_is_switchless_initialized())\n    {\n        oe_result_t post_result = oe_post_switchless_ocall(args_host_ptr);\n\n        // Fall back to regular OCALL if host worker threads are unavailable\n        if (post_result == OE_CONTEXT_SWITCHLESS_OCALL_MISSED)\n            OE_CHECK(oe_ocall(\n                OE_OCALL_CALL_HOST_FUNCTION, (uint64_t)args_host_ptr, NULL));\n        else\n        {\n            OE_CHECK(post_result);\n            // Wait until args.result is set by the host worker.\n            while (true)\n            {\n                OE_ATOMIC_MEMORY_BARRIER_ACQUIRE();\n\n                /* The member result is alignend given that args_host_ptr is\n                 * aligned and its size is 8-byte (for xAPIC vulnerability\n                 * mitigation). */\n                if (__atomic_load_n(&args_host_ptr->result, __ATOMIC_SEQ_CST) !=\n                    OE_UINT64_MAX)\n                    break;\n\n                /* Yield to CPU */\n                asm volatile(\"pause\");\n            }\n        }\n    }\n    else\n    {\n        OE_CHECK(oe_ocall(\n            OE_OCALL_CALL_HOST_FUNCTION, (uint64_t)args_host_ptr, NULL));\n    }\n\n    /* Copy the result from the host memory\n     * The member result is aligned given that args_host_ptr is aligned\n     * and its size is 8 byte (for xAPIC vulnerability mitigation). */\n    host_result = args_host_ptr->result;\n\n    /* Check the result */\n    OE_CHECK((oe_result_t)host_result);\n\n    return_args_host_ptr = (oe_call_function_return_args_t*)output_buffer;\n\n    /* Copy the marshaling struct from the host memory to avoid TOCTOU issues.\n     * To mitigate the xAPIC vulnerability, the output_buffer and the size of\n     * oe_call_function_return_args_t must be aligned at this point via runtime\n     * and compile-time checks, repsectively. */\n    oe_memcpy_aligned(\n        &return_args,\n        return_args_host_ptr,\n        sizeof(oe_call_function_return_args_t));\n\n    if (return_args.result == OE_OK)\n    {\n        /*\n         * Error out the case if the deepcopy_out_buffer is NULL but the\n         * deepcopy_out_buffer_size is not zero or if the deepcopy_out_buffer is\n         * not NULL but the deepcopy_out_buffer_size is zero. Note that this\n         * should only occur if the oeedger8r was not used or if\n         * oeedger8r-generated routine is modified.\n         */\n        if ((!return_args.deepcopy_out_buffer &&\n             return_args.deepcopy_out_buffer_size) ||\n            (return_args.deepcopy_out_buffer &&\n             !return_args.deepcopy_out_buffer_size))\n            OE_RAISE(OE_UNEXPECTED);\n\n        /*\n         * Nonzero deepcopy_out_buffer and deepcopy_out_buffer_size fields\n         * indicate that there is deep-copied content that needs to be\n         * transmitted from the host.\n         */\n        if (return_args.deepcopy_out_buffer &&\n            return_args.deepcopy_out_buffer_size)\n        {\n            /*\n             * Ensure that the deepcopy_out_buffer and deepcopy_out_buffer_size\n             * are both 8-byte aligned against the xAPIC vulnerability.\n             */\n            if ((((uint64_t)return_args.deepcopy_out_buffer % 8) != 0) ||\n                (return_args.deepcopy_out_buffer_size % 8) != 0)\n                OE_RAISE(OE_UNEXPECTED);\n\n            /*\n             * Ensure that the content lies in host memory.\n             * Note that this should only fail if oeedger8r was not used or if\n             * the oeedger8r-generated routine is modified.\n             */\n            if (!oe_is_outside_enclave(\n                    return_args.deepcopy_out_buffer,\n                    return_args.deepcopy_out_buffer_size))\n                OE_RAISE(OE_UNEXPECTED);\n\n            void* enclave_buffer =\n                oe_malloc(return_args.deepcopy_out_buffer_size);\n\n            if (!enclave_buffer)\n                OE_RAISE(OE_OUT_OF_MEMORY);\n\n            /* Copy the deep-copied content to enclave memory. */\n            oe_memcpy_aligned(\n                enclave_buffer,\n                return_args.deepcopy_out_buffer,\n                return_args.deepcopy_out_buffer_size);\n\n            /* Release the memory on host heap. */\n            oe_host_free(return_args.deepcopy_out_buffer);\n\n            /*\n             * Update the deepcopy_out_buffer field.\n             * Note that the field is still in host memory. Currently, the\n             * oeedger8r-generated code will perform an additional check that\n             * ensures the buffer stays within the enclave memory.\n             */\n            OE_WRITE_VALUE_WITH_BARRIER(\n                &(return_args_host_ptr->deepcopy_out_buffer), enclave_buffer);\n        }\n    }\n\n    /* The member output_bytes_written is aligned given that args_host_ptr is\n     * aligned (for xAPIC vulnerability mitigation) */\n    *output_bytes_written = args_host_ptr->output_bytes_written;\n    result = OE_OK;\n\ndone:\n    if (result != OE_OK && return_args_host_ptr)\n    {\n        /* Set up the local return_args for the failing case */\n        return_args.result = result;\n        return_args.deepcopy_out_buffer = NULL;\n        return_args.deepcopy_out_buffer_size = 0;\n\n        /* Copy the return_args to host memory */\n        oe_memcpy_s_with_barrier(\n            return_args_host_ptr,\n            sizeof(*return_args_host_ptr),\n            &return_args,\n            sizeof(return_args));\n    }\n\n    return result;\n}\n\n/*\n**==============================================================================\n**\n** oe_call_host_function()\n** This is the preferred way to call host functions.\n**\n**==============================================================================\n*/\n\noe_result_t oe_call_host_function(\n    size_t function_id,\n    const void* input_buffer,\n    size_t input_buffer_size,\n    void* output_buffer,\n    size_t output_buffer_size,\n    size_t* output_bytes_written)\n{\n    return oe_call_host_function_internal(\n        function_id,\n        input_buffer,\n        input_buffer_size,\n        output_buffer,\n        output_buffer_size,\n        output_bytes_written,\n        false /* non-switchless */);\n}\n\n/*\n**==============================================================================\n**\n** _stitch_ecall_stack()\n**\n**     This function fixes up the first enclave frame (passed in) when the\n**     enclave is in debug mode and the ecall_context includes valid\n**     debug_eenter_rbp and debug_eenter_rip (i.e., both of which should\n**     be set and point to host memory). Otherwise, the function is a no-op.\n**     Currently, the stack stitching is required when vDSO is used on Linux.\n**\n**     Backtrace before stitching:\n**\n**     oe_ecall                                    | in host\n**       -> _do_eenter                             |\n**         -> oe_enter (aliased as __morestack)    |\n**           -> oe_vdso_enter                      |\n**             -> __vdso_sgx_enter_enclave         |\n**   --------------------------------------------------------------------------\n**             -> oe_enter                         | in enclave\n**              -> __oe_handle_main                |\n**\n**     Given that __vdso_sgx_enter_enclave is the vDSO function, we cannot rely\n**     on the Linux kernel to preserve its stack frame. Instead, we fix up the\n**     call stack that bypasses oe_vdso_enter and __vdso_sgx_enter_enclave in\n**     the trace, making it align with the trace when vDSO is not used.\n**\n**     Backtrace after stitching:\n**\n**     oe_ecall                                    | in host\n**       -> _do_eenter                             |\n**         -> oe_enter (aliased as __morestack)    |\n**   --------------------------------------------------------------------------\n**         -> oe_enter                             | in enclave\n**           -> __oe_handle_main                   |\n**\n**==============================================================================\n*/\n\nstatic void _stitch_ecall_stack(oe_sgx_td_t* td, uint64_t* first_enclave_frame)\n{\n    oe_ecall_context_t* ecall_context = td->host_ecall_context;\n\n    if (oe_is_enclave_debug_allowed())\n    {\n        if (oe_is_outside_enclave(ecall_context, sizeof(*ecall_context)))\n        {\n            uint64_t host_rbp = ecall_context->debug_eenter_rbp;\n            uint64_t host_rip = ecall_context->debug_eenter_rip;\n\n            /* Check that the supplied host frame (hpst_rbp, host_rip) are set\n             * and really lies outside before stitching the stack */\n            if (oe_is_outside_enclave((void*)host_rbp, sizeof(uint64_t)) &&\n                oe_is_outside_enclave((void*)host_rip, sizeof(uint64_t)))\n            {\n                first_enclave_frame[0] = host_rbp;\n                first_enclave_frame[1] = host_rip;\n            }\n        }\n    }\n}\n\n/*\n**==============================================================================\n**\n** __oe_handle_main()\n**\n**     This function is called by oe_enter(), which is called by the EENTER\n**     instruction (executed by the host). The host passes the following\n**     parameters to EENTER:\n**\n**         RBX - TCS - address of a TCS page in the enclave\n**         RCX - AEP - pointer to host's asynchronous exception procedure\n**         RDI - ARGS1 (holds the CODE and FUNC parameters)\n**         RSI - ARGS2 (holds the pointer to the args structure)\n**\n**     EENTER then calls oe_enter() with the following registers:\n**\n**         RAX - CSSA - index of current SSA\n**         RBX - TCS - address of TCS\n**         RCX - RETADDR - address to jump back to on EEXIT\n**         RDI - ARGS1 (holds the code and func parameters)\n**         RSI - ARGS2 (holds the pointer to the args structure)\n**\n**     Finally oe_enter() calls this function with the following parameters:\n**\n**         ARGS1 (holds the code and func parameters)\n**         ARGS2 (holds the pointer to the args structure)\n**         CSSA - index of current SSA\n**         TCS - address of TCS (thread control structure)\n**\n**     Each enclave contains one or more thread sections (a collection of pages\n**     used by a thread entering the enclave). Each thread section has the\n**     following layout:\n**\n**         +----------------------------+\n**         | Guard Page                 |\n**         +----------------------------+\n**         | Stack pages                |\n**         +----------------------------+\n**         | Guard Page                 |\n**         +----------------------------+\n**         | TCS Page                   |\n**         +----------------------------+\n**         | SSA (State Save Area) 0    |\n**         +----------------------------+\n**         | SSA (State Save Area) 1    |\n**         +----------------------------+\n**         | Guard Page                 |\n**         +----------------------------+\n**         | Thread local storage       |\n**         +----------------------------+\n**         | FS/GS Page (oe_sgx_td_t + tsp)    |\n**         +----------------------------+\n**\n**     EENTER sets the FS segment register to refer to the FS page before\n**     calling this function.\n**\n**     If the enclave should fault, SGX saves the registers in the SSA slot\n**     (given by CSSA) and invokes the host's asynchronous exception handler\n**     (AEP). The handler may terminate or call ERESUME which increments CSSA\n**     and enters this function again. So:\n**\n**         CSSA == 0: indicates a normal entry\n**         CSSA >= 1: indicates an exception entry\n**\n**     Since the enclave builder only allocates two SSA pages, the enclave can\n**     nest no more than two faults. EENTER fails when the number of SSA slots\n**     are exhausted (i.e., TCS.CSSA == TCS.NSSA)\n**\n**     This function ultimately calls EEXIT to exit the enclave. An enclave may\n**     exit to the host for two reasons (aside from an asynchronous exception\n**     already mentioned):\n**\n**         (1) To return normally from an ECALL\n**         (2) To initiate an OCALL\n**\n**     When exiting to perform an OCALL, the host may perform another ECALL,\n**     and so ECALLS and OCALLS may be nested arbitrarily until stack space is\n**     exhausted (hitting a guard page). The state for performing nested calls\n**     is maintained on the stack associated with the TCS (see diagram above).\n**\n**     The enclave's stack pointer is determined as follows:\n**\n**         (*) For non-nested calls, the stack pointer is calculated relative\n**             to the TCS (one page before minus the STATIC stack size).\n**\n**         (*) For nested calls the stack pointer is obtained from the\n**             oe_sgx_td_t.last_sp field (saved by the previous call).\n**\n**==============================================================================\n*/\nvoid __oe_handle_main(\n    uint64_t arg1,\n    uint64_t arg2,\n    uint64_t cssa,\n    void* tcs,\n    uint64_t* output_arg1,\n    uint64_t* output_arg2)\n{\n    oe_code_t code = oe_get_code_from_call_arg1(arg1);\n    uint16_t func = oe_get_func_from_call_arg1(arg1);\n    uint16_t arg1_result = oe_get_result_from_call_arg1(arg1);\n    uint64_t arg_in = arg2;\n    *output_arg1 = 0;\n    *output_arg2 = 0;\n\n    /* Get pointer to the thread data structure */\n    oe_sgx_td_t* td = td_from_tcs(tcs);\n\n    /* Initialize the enclave the first time it is ever entered. Note that\n     * this function DOES NOT call global constructors. Global construction\n     * is performed while handling OE_ECALL_INIT_ENCLAVE. */\n    oe_initialize_enclave(td);\n\n    /* td's host_ecall_context is set in enter.S and this is the first chance we\n       get to validate it. */\n    oe_ecall_context_t* ecall_context = td->host_ecall_context;\n    if (!oe_is_outside_enclave(ecall_context, sizeof(*ecall_context)))\n        td->host_ecall_context = NULL;\n\n    /* Ensure that ecall_context is 8-byte aligned against the xAPIC\n     * vunlerability */\n    if (((uint64_t)ecall_context % 8) != 0)\n        td->host_ecall_context = NULL;\n\n    /* Stitch the stack. Pass the caller's frame for fix up.\n     * Note that before stitching, the caller's frame points\n     * to the host stack right before switiching to the enclave\n     * stack (see .construct_stack_frame in enter.S).\n     * The function is called after oe_initialize_enclave\n     * (relocations have been applied) so that we can safely\n     * access globals that are referenced via GOT. */\n    _stitch_ecall_stack(td, __builtin_frame_address(1));\n\n    // Block enclave enter based on current enclave status.\n    switch (__oe_enclave_status)\n    {\n        case OE_OK:\n        {\n            break;\n        }\n        case OE_ENCLAVE_ABORTING:\n        {\n            // Block any ECALL except first time OE_ECALL_DESTRUCTOR call.\n            // Don't block ORET here.\n            if (code == OE_CODE_ECALL)\n            {\n                if (func == OE_ECALL_DESTRUCTOR)\n                {\n                    // Termination function should be only called once.\n                    __oe_enclave_status = OE_ENCLAVE_ABORTED;\n                }\n                else\n                {\n                    // Return crashing status.\n                    *output_arg1 =\n                        oe_make_call_arg1(OE_CODE_ERET, func, 0, OE_OK);\n                    *output_arg2 = __oe_enclave_status;\n                    return;\n                }\n            }\n\n            break;\n        }\n        default:\n        {\n            // Return crashed status.\n            *output_arg1 = oe_make_call_arg1(OE_CODE_ERET, func, 0, OE_OK);\n            *output_arg2 = OE_ENCLAVE_ABORTED;\n            return;\n        }\n    }\n\n    /* If this is a normal (non-exception) entry */\n    if (cssa == 0)\n    {\n        switch (code)\n        {\n            case OE_CODE_ECALL:\n            {\n                /* The invocation of the virtual exception handler is not\n                 * allowed when cssa=0. */\n                if (func == OE_ECALL_VIRTUAL_EXCEPTION_HANDLER)\n                    oe_abort_with_td(td);\n\n                /* State machine check */\n                if (td->state != OE_TD_STATE_ENTERED)\n                    oe_abort_with_td(td);\n\n                /* At this point, we are ready to execute the ecall.\n                 * Update the state to RUNNING */\n                td->state = OE_TD_STATE_RUNNING;\n\n                _handle_ecall(td, func, arg_in, output_arg1, output_arg2);\n                break;\n            }\n            case OE_CODE_ORET:\n                /* Eventually calls oe_exit_enclave() and never returns here if\n                 * successful */\n                _handle_oret(td, func, arg1_result, arg_in);\n                // fallthrough\n\n            default:\n                /* Unexpected case */\n                oe_abort_with_td(td);\n        }\n    }\n    else if (cssa == 1)\n    {\n        /* cssa == 1 indicates the entry after an AEX. We only allow the\n         * invocation of the virtual exception handler in this case. */\n        if ((code == OE_CODE_ECALL) &&\n            (func == OE_ECALL_VIRTUAL_EXCEPTION_HANDLER))\n        {\n            _handle_ecall(td, func, arg_in, output_arg1, output_arg2);\n            return;\n        }\n\n        /* Unexpected case */\n        oe_abort_with_td(td);\n    }\n    else /* cssa > 1 */\n    {\n        /* Currently OE only supports an enclave with nssa = 2, which means\n         * that cssa can never exceed 1 (indicating nested AEX). */\n        oe_abort_with_td(td);\n    }\n}\n\n/* Abort the enclave execution with valid td. This function is only directly\n * invoked by __oe_handle_main and init.c where the td may not be initialized\n * yet (i.e., before the td_init() is called in the very first\n * oe_handle_ecall()). For the other scenarios, this function is wrapped by\n * oe_abort where we can safely get td with oe_sgx_get_td_no_check(). */\nvoid oe_abort_with_td(oe_sgx_td_t* td)\n{\n    uint64_t arg1 = oe_make_call_arg1(OE_CODE_ERET, 0, 0, OE_OK);\n\n    /* Abort can be called with user-modified FS (e.g., FS check fails in\n     * oe_sgx_get_td()). */\n    if (oe_is_enclave_debug_allowed())\n    {\n        oe_ecall_context_t* host_ecall_context = td->host_ecall_context;\n\n        // Make sure the context is valid.\n        if (host_ecall_context &&\n            oe_is_outside_enclave(\n                host_ecall_context, sizeof(*host_ecall_context)))\n        {\n            uint64_t* frame = (uint64_t*)__builtin_frame_address(0);\n\n            /* NOTE: host memory writes that is only for debugging purposes,\n             * no need for using write with barrier */\n            host_ecall_context->debug_eexit_rbp = frame[0];\n            // The caller's RSP is always given by this equation\n            //   RBP + 8 (caller frame pointer) + 8 (caller return address)\n            host_ecall_context->debug_eexit_rsp = frame[0] + 8;\n            host_ecall_context->debug_eexit_rip = frame[1];\n        }\n\n        // For debug enclaves, log the backtrace before marking the enclave as\n        // aborted.\n        {\n            // Fetch current values of FS and GS. Typically, FS[0] == FS and\n            // GS[0] == GS.\n            uint64_t fs;\n            uint64_t gs;\n            asm volatile(\"mov %%fs:0, %0\" : \"=r\"(fs));\n            asm volatile(\"mov %%gs:0, %0\" : \"=r\"(gs));\n\n            // We can make ocalls only if td has been initialized which is true\n            // only when the self-pointer has been setup.\n            if (gs == (uint64_t)td)\n            {\n                // Restore FS if FS has been modified.\n                if (fs != gs)\n                {\n                    // wrfsbase could trigger an exception. The enclave may not\n                    // be in a state to emulate the instruction. Therefore, just\n                    // restore FS[0].\n                    asm volatile(\"mov %0, %%fs:0\" : : \"r\"(gs) : \"memory\");\n                }\n\n                void* buffer[OE_BACKTRACE_MAX];\n                int size;\n                oe_result_t r = OE_UNEXPECTED;\n                if ((size = oe_backtrace(buffer, OE_BACKTRACE_MAX)) > 0)\n                {\n                    oe_sgx_log_backtrace_ocall(\n                        &r,\n                        oe_get_enclave(),\n                        OE_LOG_LEVEL_ERROR,\n                        (uint64_t*)buffer,\n                        (size_t)size);\n                }\n                else\n                {\n                    // It is not possible to convey much information at this\n                    // point.\n                }\n\n                // Rever FS if it was restored above.\n                if (fs != gs)\n                    asm volatile(\"mov %0, %%fs:0\" : : \"r\"(fs) : \"memory\");\n            }\n        }\n    }\n\n    td->state = OE_TD_STATE_ABORTED;\n\n    // Once it starts to crash, the state can only transit forward, not\n    // backward.\n    if (__oe_enclave_status < OE_ENCLAVE_ABORTING)\n    {\n        __oe_enclave_status = OE_ENCLAVE_ABORTING;\n    }\n\n    // Return to the latest ECALL.\n    oe_asm_exit(arg1, __oe_enclave_status, td, 1 /* direct_return */);\n}\n\nvoid oe_abort(void)\n{\n    /* Bypass the FS check given that the oe_abort can be invoked anywhere */\n    oe_sgx_td_t* td = oe_sgx_get_td_no_fs_check();\n\n    /* It is unlikely that td is invalid. If this is the case, we cannot\n     * call _abort to exit the enclave. Instead, we intentionally trigger\n     * the page fault by writing to the code page to exit the enclave.\n     * Note that the subsequent execution may hang in case that state machine\n     * check fails in oe_enter, which will block the call to the\n     * __oe_handle_main(). If the execution reaches __oe_handle_main(), we can\n     * safely abort with valid td via the check against __oe_enclave_status. */\n    if (!td)\n    {\n        uint64_t oe_abort_address = (uint64_t)oe_abort;\n\n        __oe_enclave_status = OE_ENCLAVE_ABORTING;\n\n        asm volatile(\"mov $1, %0\" : \"=r\"(*(uint64_t*)oe_abort_address));\n    }\n\n    oe_abort_with_td(td);\n}\n", "// Copyright (c) Open Enclave SDK contributors.\n// Licensed under the MIT License.\n\n#include <openenclave/internal/constants_x64.h>\n\n//==============================================================================\n//\n// void oe_snap_current_context(OE_CONTEXT * oe_context)\n//\n// Routine Description:\n//\n// This function captures the context of the caller. All register values except\n// the rip are exactly same as the values before this function call instruction\n// is executed. The rip in the output context is set to the return address of\n// this function.\n//\n// Arguments:\n//     oe_context(rdi): The output context.\n//\n// Return value:\n//     None.\n//==============================================================================\n\n.globl oe_snap_current_context\n.type oe_snap_current_context, @function\noe_snap_current_context:\n.cfi_startproc\n    // Save the flags.\n    pushfq\n    popq OE_CONTEXT_FLAGS(%rdi)\n\n    // Get general registers.\n    // Save rax, rbx, rcx, rdx.\n    movq    %rax, OE_CONTEXT_RAX(%rdi)\n    movq    %rbx, OE_CONTEXT_RBX(%rdi)\n    movq    %rcx, OE_CONTEXT_RCX(%rdi)\n    movq    %rdx, OE_CONTEXT_RDX(%rdi)\n\n    // Save rbp and rsp.\n    movq    %rbp, OE_CONTEXT_RBP(%rdi)\n    movq    %rsp, %rax\n    addq    $0x10, %rax\n    movq    %rax, OE_CONTEXT_RSP(%rdi)\n\n    // Save rsi and rdi.\n    movq    %rdi, OE_CONTEXT_RDI(%rdi)\n    movq    %rsi, OE_CONTEXT_RSI(%rdi)\n\n    // Save r8, r9 ... r15.\n    movq    %r8, OE_CONTEXT_R8(%rdi)\n    movq    %r9, OE_CONTEXT_R9(%rdi)\n    movq    %r10, OE_CONTEXT_R10(%rdi)\n    movq    %r11, OE_CONTEXT_R11(%rdi)\n    movq    %r12, OE_CONTEXT_R12(%rdi)\n    movq    %r13, OE_CONTEXT_R13(%rdi)\n    movq    %r14, OE_CONTEXT_R14(%rdi)\n    movq    %r15, OE_CONTEXT_R15(%rdi)\n\n    // Save rip.\n    movq    %rsp, %rax\n    addq    $0x8, %rax\n    movq    (%rax), %rbx\n    movq    %rbx, OE_CONTEXT_RIP(%rdi)\n\n    // Save SSE control flags.\n    // This is redundant given fxsave, but is done to expose the mxcsr\n    // value in the oe_context_t as part of the oe_exception_record_t.\n    stmxcsr OE_CONTEXT_MXCSR(%rdi)\n\n    // Save x87 and SSE values.\n    fxsave  OE_CONTEXT_FLOAT(%rdi)\n\n\n    // Return\n    retq\n.cfi_endproc\n\n//==============================================================================\n//\n// void oe_continue_execution(OE_CONTEXT * oe_context)\n//\n// Routine Description:\n//\n//   This function restores the full oe_context, and continue run on the rip of\n//   input context.\n//\n// Arguments:\n//\n//    oe_context (rdi) - Supplies a pointer to a context record.\n//\n// Return Value:\n//\n//    None. This function will not return to caller.\n//\n//==============================================================================\n\n.globl oe_continue_execution\n.type oe_continue_execution, @function\noe_continue_execution:\n.cfi_startproc\n    // Restore the x87 and SSE values.\n    fxrstor OE_CONTEXT_FLOAT(%rdi)\n\n    // Restore SSE control flags.\n    // This is redundant given fxrstor, but included here for parity with\n    // oe_snap_current_context.\n    ldmxcsr OE_CONTEXT_MXCSR(%rdi)\n\n    // Restore general registers.\n    // Restore rax, rbx, rcx, rdx.\n    movq    OE_CONTEXT_RAX(%rdi), %rax\n    movq    OE_CONTEXT_RBX(%rdi), %rbx\n    movq    OE_CONTEXT_RCX(%rdi), %rcx\n    movq    OE_CONTEXT_RDX(%rdi), %rdx\n\n    // Restore rsi.\n    movq    OE_CONTEXT_RSI(%rdi), %rsi\n\n    // Restore r8, r9 ... r15.\n    movq    OE_CONTEXT_R8(%rdi), %r8\n    movq    OE_CONTEXT_R9(%rdi), %r9\n    movq    OE_CONTEXT_R10(%rdi), %r10\n    movq    OE_CONTEXT_R11(%rdi), %r11\n    movq    OE_CONTEXT_R12(%rdi), %r12\n    movq    OE_CONTEXT_R13(%rdi), %r13\n    movq    OE_CONTEXT_R14(%rdi), %r14\n    movq    OE_CONTEXT_R15(%rdi), %r15\n\n    // Restore rbp, rsp\n    movq    OE_CONTEXT_RBP(%rdi), %rbp\n    movq    OE_CONTEXT_RSP(%rdi), %rsp\n\n    // Put local variables under the red zone.\n    sub     $ABI_REDZONE_BYTE_SIZE, %rsp\n\n    // Push the target address to stack.\n    pushq   OE_CONTEXT_RIP(%rdi)\n\n    // Restore the saved flags.\n    pushq   OE_CONTEXT_FLAGS(%rdi)\n    popfq\n\n    // Restore rdi.\n    movq    OE_CONTEXT_RDI(%rdi), %rdi\n\n    // LVI mitigation strategy:\n    // Since no register is free, we cannot load the target into a register and\n    // then issue an lfence. Instead, we use retq (return) instruction to carry\n    // out a jump. The return address is at 0(RSP). RSP is ABI_REDZONE_BYTE_SIZE\n    // + 8 bytes below the correct RSP which was fetched from the context.\n    // We issue a\n    //     retq $ABI_REDZONE_BYTE_SIZE\n    // This has the following effect:\n    //     - The return address is popped and control is transferred to\n    //       the target address.\n    //     - Additionally, ABI_REDZONE_BYTE_SIZE is subtracted from RSP,\n    //       thereby restoring RSP correctly.\n    //     - Ideally assembler's LVI mitigation would insert lfence as appropriate.\n    //       Since it does not seem to handle retq with an immediate value, the\n    //       LVI mitigation is manually inserted.\n\n    // Manual LVI mitigation since the assember does not handle the retq below.\n    notq (%rsp)\n    notq (%rsp)\n    lfence\n\n    // Jump to the target and restore RSP.\n    retq $ABI_REDZONE_BYTE_SIZE\n.cfi_endproc\n", "// Copyright (c) Open Enclave SDK contributors.\n// Licensed under the MIT License.\n\n#include \"asmdefs.h\"\n#include \"asmcommon.inc\"\n#include \"context.inc\"\n\n//==============================================================================\n//\n// oe_enter(RAX=CSSA, RBX=TCS, RCX=RETADDR, RDI=ARG1, RSI=ARG2)\n//\n//     The EENTER instruction (executed by the host) calls this function to\n//     enter the enclave.\n//\n//     Registers from EENTER:\n//         RAX - index of current SSA (CSSA)\n//         RBX - address of TCS (TCS)\n//         RCX - address of instruction following EENTER (RETADDR)\n//\n//     Registers from host caller of EENTER:\n//         RDI - ARG1\n//         RSI - ARG2\n//         RDX - HOST ECALL CONTEXT\n//\n//     This function performs the following tasks:\n//\n//         (1) Saves the host registers\n//         (2) Calculates the enclave stack base\n//         (3) Sets up the enclave stack frame\n//         (4) Calls __oe_handle_main()\n//\n//     Note: __oe_handle_main does not return. Instead it eventually\n//     calls oe_asm_exit (see exit.S)\n//\n//==============================================================================\n\n.globl oe_enter\n.type oe_enter, @function\noe_enter:\n.cfi_startproc\n\n.get_td:\n\n    // Get the location of the td_t structure for this thread. This value is\n    // expected to be present in %r11 for the remainder of oe_enter.\n    //\n    // Upon first entry to the enclave, td->base.self in the td_t structure\n    // is not yet initialized. However, the loader in host/sgx/create.c places\n    // the td_t structure as a specific offset from TCS.\n    mov _td_from_tcs_offset(%rip), %r11\n    add %rbx, %r11\n\n.check_aborted:\n    cmpq $TD_STATE_ABORTED, td_state(%r11)\n    je .abort\n\n    // Get the first ssa address from tcs\n    lea OE_SSA_FROM_TCS_BYTE_OFFSET(%rbx), %r10\n\n.save_host_registers:\n    // Backup the current ecall context to previous\n    mov td_host_ecall_context(%r11), %r8\n    mov %r8, td_host_previous_ecall_context(%r11)\n\n    // Save host registers (restored on EEXIT)\n    mov %rax, td_eenter_rax(%r11) // cssa set by EENTER\n    mov %rcx, td_host_rcx(%r11) // host return address here\n    mov %rdx, td_host_ecall_context(%r11)\n\n.determine_entry_type:\n    // Check if this is exception dispatching request\n    // Return on the eenter if cssa greater than one, which\n    // should not occur because OE assumes the enclave with nssa=2\n    cmp $1, %rax\n    je .exception_entry\n    ja .return\n\n    // Stop speculative execution at fallthrough of conditional\n    // exception-dispatching-request-check.\n    lfence\n\n.update_td_state_on_normal_entry:\n    // Do not update the state if the enclave enters in the middle\n    // the exception handling (e.g., making an ocall)\n    cmpq $TD_STATE_SECOND_LEVEL_EXCEPTION_HANDLING, td_state(%r11)\n    je .check_entry_nesting_level\n\n    // Update state and clear previous state on normal entries\n    movq $TD_STATE_NULL, td_previous_state(%r11)\n    movq $TD_STATE_ENTERED, td_state(%r11)\n\n.check_entry_nesting_level:\n    lfence\n    // Check whether this is a clean entry or a nested entry\n    // clean-entry-check.\n    mov td_depth(%r11), %r8\n    cmp $0, %r8\n    je .clean_entry\n    jmp .nested_entry\n\n.exception_entry:\n    // Stop speculative execution at target of conditional jump\n    // after exception-dispatching-request-check.\n    lfence\n\n    // Abort if SSA[0].GPRSGX.RSP equals to SSA[0].GPRSGX.URSP\n    mov SGX_SSA_RSP_OFFSET(%r10), %r8\n    mov SGX_SSA_URSP_OFFSET(%r10), %r9\n    cmp %r8, %r9\n    je .return\n\n    // Calculate the base address of the enclave\n    lea _enclave_rva(%rip), %r12\n    mov (%r12), %r13\n    sub %r13, %r12\n\n    // Calculate the end of the enclave address (base + enclave_size)\n    lea oe_enclave_properties_sgx(%rip), %r13\n    mov OE_SGX_ENCLAVE_SIZE_OFFSET(%r13), %r13\n    add %r12, %r13\n\n    // Abort if SSA[0].GPRSGX.URSP is within the enclave memory range\n    cmp %r12, %r9\n    jb .exception_handler_stack_check\n    cmp %r13, %r9\n    jae .exception_handler_stack_check\n    jmp .return\n\n    // Reaching this point implies SSA[0].GPRSGX.RSP is within the enclave\n    // memory range so we do not need additional checks.\n\n.exception_handler_stack_check:\n    // Stop speculative execution at target of conditional jump\n    lfence\n\n    // Get the exception_handler_stack_check range\n    mov td_exception_handler_stack(%r11), %r14\n    mov td_exception_handler_stack_size(%r11), %r15\n    test %r15, %r15\n    jz .exception_stack_setup // check if size is zero\n    add %r14, %r15\n    jc .exception_stack_setup // check for overflow\n\n    // Check if the stack range is within the enclave memory range\n    // If the check fails, fallback to the default behavior (i.e.,\n    // re-using the stack pointer saved in the SSA)\n    cmp %r12, %r14\n    jb .exception_stack_setup\n    cmp %r13, %r15\n    ja .exception_stack_setup\n\n    // Check passes, use the exception handler stack\n    mov %r15, %r8\n\n    // Align the stack\n    and $-16, %r8\n\n    // Proceed without the red zone\n    jmp .state_machine_check\n\n.exception_stack_setup:\n    // Stop speculative execution at target of conditional jump\n    lfence\n\n    // Align the stack\n    and $-16, %r8\n\n    // Start the new stack under the red zone\n    sub $ABI_REDZONE_BYTE_SIZE, %r8\n\n.state_machine_check:\n    cmpq $0, td_exception_nesting_level(%r11)\n    jne .state_machine_check_nested_exception\n\n.state_machine_check_non_nested_exception:\n    // Expect the state to be RUNNING on a non-nested exception\n    // entry\n    cmpq $TD_STATE_RUNNING, td_state(%r11)\n    jne .return\n    jmp .check_host_signal_request\n\n.state_machine_check_nested_exception:\n    lfence\n    // Expect the state to be SECOND_LEVEL_EXCEPTION_HANDLING\n    // on a nested exception entry\n    cmpq $TD_STATE_SECOND_LEVEL_EXCEPTION_HANDLING, td_state(%r11)\n    jne .return\n\n.check_host_signal_request:\n    movq td_state(%r11), %r12\n\n    // Input value falls in the range of [1, 64] indicates\n    // a host signal request\n    cmp $0, %rsi\n    je .update_td_state\n    cmp $MAX_SIGNAL_NUMBER, %rsi\n    ja .update_td_state\n\n    // Proceed if the host_signal_unmasked flag is set\n    cmpq $1, td_host_signal_unmasked(%r11)\n    jne .return\n\n    // Proceed if the corresponding bit of the signal\n    // (i.e., signal number - 1) is set in the bitmask\n    mov td_host_signal_bitmask(%r11), %r13\n    mov %rsi, %r14\n    dec %r14\n    bt %r14, %r13\n    jnc .return\n\n    // Proceed only if the state is RUNNING\n    cmp $TD_STATE_RUNNING, %r12\n    jne .return\n\n    // Proceed if the thread is currently not handling a host signal\n    cmpq $1, td_is_handling_host_signal(%r11)\n    je .return\n\n    // Proceed if the exception entry is not nested\n    cmpq $0, td_exception_nesting_level(%r11)\n    jne .return\n\n    lfence\n\n    // Set the flag if the request is accepted\n    movq $1, td_is_handling_host_signal(%r11)\n\n    // Store the host-passed signal number\n    mov %rsi, td_host_signal(%r11)\n\n.update_td_state:\n    lfence\n\n    // Keep the state before the exception so that we can restore the\n    // state in the illegal instruction emulation flow\n    mov %r12, td_previous_state(%r11)\n    movq $TD_STATE_FIRST_LEVEL_EXCEPTION_HANDLING, td_state(%r11)\n\n    // Increase the nesting level, which will be decreased before resuming\n    // the execution (see exception.c)\n    incq td_exception_nesting_level(%r11)\n    jmp .call_function\n\n.nested_entry:\n    // Stop speculative execution at fallthrough of conditional\n    // clean-entry-check.\n    lfence\n\n    // Restore stack pointer and enclave registers:\n    mov td_last_sp(%r11), %r8\n\n    // align the stack\n    and $-16, %r8\n\n    // Start the new stack under the red zone.\n    sub $ABI_REDZONE_BYTE_SIZE, %r8\n    jmp .call_function\n\n.clean_entry:\n    // Stop speculative execution at target of conditional jump\n    // after clean-entry-check.\n    lfence\n\n    // Calculate stack base relative to TCS (subtract guard page size)\n    mov %rbx, %r8\n    sub $PAGE_SIZE, %r8\n\n.call_function:\n    // Stop speculative execution for the fallthrough cases\n    lfence\n\n    // Set the rsp to the in-enclave stack\n    mov %r8, %rsp\n\n    cmp $1, %rax\n    je .locate_next_ssa\n    jmp .construct_stack_frame\n\n.locate_next_ssa:\n    // Stop speculative execution at fallthrough of conditional\n    // rax (cssa) check.\n    lfence\n\n    add $PAGE_SIZE, %r10\n\n.construct_stack_frame:\n    // Get the host stack pointer from SSA\n    mov SGX_SSA_URSP_OFFSET(%r10), %r8\n    mov SGX_SSA_URBP_OFFSET(%r10), %r9\n\n    // Construct the frame and align the stack\n    pushq $0\n    pushq %r8\n    pushq %rcx\n    pushq %r9\n.cfi_def_cfa_offset     16\n.cfi_offset             rbp, -16\n    mov %rsp, %rbp\n.cfi_def_cfa_register   rbp\n\n// 16-byte alignment\n#define OM_STACK_LENGTH             0X20\n#define OM_HOST_OUTPUT_ARG1         (-1*8)(%rbp)\n#define OM_HOST_OUTPUT_ARG2         (-2*8)(%rbp)\n#define OM_ENC_TD                   (-3*8)(%rbp)\n\n    // Allocate stack.\n    sub $OM_STACK_LENGTH, %rsp\n\n    // Save reference to the td structure to enclave stack.\n    mov %r11, OM_ENC_TD\n\n    // Clear the XSTATE so that enclave has clean legacy SSE and extended states\n    xor %r11, %r11\n    oe_cleanup_registers\n\n    // Call __oe_handle_main(ARG1=RDI, ARG2=RSI, CSSA=RDX, TCS=RCX, OUTPUTARG1=R8, OUTPUTARG2=R9)\n    mov %rax, %rdx\n    mov %rbx, %rcx\n    lea OM_HOST_OUTPUT_ARG1, %r8\n    lea OM_HOST_OUTPUT_ARG2, %r9\n    call __oe_handle_main\n\n    // Get the output parameters.\n    mov OM_HOST_OUTPUT_ARG1, %rdi\n    mov OM_HOST_OUTPUT_ARG2, %rsi\n\n    // Restore td pointer\n    mov OM_ENC_TD, %rdx\n    // Set the argument aborting=0 for oe_asm_exit\n    xor %rcx, %rcx\n    jmp .eexit\n\n.abort:\n    lfence\n\n    // Set argument 2 for oe_asm_exit\n    mov $CODE_ENCLAVE_ABORTING, %rsi\n\n    // Update the global enclave status\n    mov %rsi, __oe_enclave_status(%rip)\n\n    jmp .prepare_eexit\n\n.return:\n    lfence\n\n    // Set argument 2 for oe_asm_exit\n    mov $CODE_EXCEPTION_CONTINUE_EXECUTION, %rsi\n\n.prepare_eexit:\n#define ARG1_CODE_ERET        0x2 // OE_CODE_ERET in oe_code_t\n#define ARG1_CODE_BIT_OFFSET  0x30 // Refer to oe_make_call_arg1 in calls.h\n\n    // Set argument 1 for oe_asm_exit\n    mov $ARG1_CODE_ERET, %rdi\n    shl $ARG1_CODE_BIT_OFFSET, %rdi\n    mov %r11, %rdx\n    mov $1, %rcx // direct_return=1\n\n.eexit:\n    // Invoke oe_asm_exit with (ARG1=RDI, ARG2=RSI, TD=RDX, ABORTING=RCX)\n    jmp oe_asm_exit\n\n    // Should never reach here because oe_asm_exit does not return\n\n.forever:\n    jmp .forever\n\n.cfi_endproc\n\n.size oe_enter, .-oe_enter\n\n//==============================================================================\n//\n// void oe_exception_dispatcher(void)\n//\n// Routine Description:\n//\n//   This function is used to dispatch an enclave exception.\n//\n//  Arguments:\n//      None.\n//\n//  Return value:\n//      None.\n//==============================================================================\n\n#define SIZEOF_OE_CONTEXT 0X2A0\n#define ED_STACK_LENGTH SIZEOF_OE_CONTEXT + 0x20\n#define ED_OE_CONTEXT        (%rsp)\n#define ED_SAVED_RDI         (0*8)(%rbp)\n#define ED_SAVED_RBP         (1*8)(%rbp)\n#define ED_SAVED_RSP         (2*8)(%rbp)\n\n.globl oe_exception_dispatcher\n.type oe_exception_dispatcher, @function\noe_exception_dispatcher:\n.cfi_startproc\n\n    // Dummy operations to ensure the red zone does not bypass the guard page.\n    // This could happen when setting the exception handler stack but not\n    // registering the stack for #PF. In this case, when the stack overflow\n    // occurs, the first-stage handler will use the exception handler stack and\n    // then continue the execution to this point with the corrupted stack,\n    // pointing to near the end of the guard page.\n    push %rbp\n    pop %rbp\n\n    // Start the new stack under the red zone.\n    sub $ABI_REDZONE_BYTE_SIZE, %rsp\n\n    // Save the registers that will be clobbered before snap context is called.\n    push %rsp\n    push %rbp\n    push %rdi\n    mov %rsp, %rbp\n\n    // align the stack.\n    and $-16, %rsp\n\n    // Allocate stack.\n    sub $ED_STACK_LENGTH, %rsp\n\n    // Recapture the context of exception. The output context is all correct except:\n    // rbp, rsp, rdi, and rip.\n    lea ED_OE_CONTEXT, %rdi\n    call oe_snap_current_context\n\n    // Restore the previous rbp to rbp of OE_CONTEXT.\n    lea ED_OE_CONTEXT, %rdi\n    movq ED_SAVED_RBP, %rax\n    movq %rax, OE_CONTEXT_RBP(%rdi)\n\n    // Restore the previous rsp to rsp of OE_CONTEXT.\n    movq ED_SAVED_RSP, %rax\n    add $ABI_REDZONE_BYTE_SIZE, %rax\n    movq %rax, OE_CONTEXT_RSP(%rdi)\n\n    // Restore the previous rdi to rdi of OE_CONTEXT.\n    movq ED_SAVED_RDI, %rax\n    movq %rax, OE_CONTEXT_RDI(%rdi)\n\n    call oe_real_exception_dispatcher\n\n    // Should never reach here since oe_real_exception_dispatcher will not return.\n\n.forever_loop:\n    jmp .forever_loop\n.cfi_endproc\n\n.size oe_exception_dispatcher, .-oe_exception_dispatcher\n", "// Copyright (c) Open Enclave SDK contributors.\n// Licensed under the MIT License.\n\n#ifndef _OE_ABI_UTILS_H\n#define _OE_ABI_UTILS_H\n\n#include <openenclave/bits/defs.h>\n\nOE_EXTERNC_BEGIN\n// oe_is_avx_enabled is an internal variable setup and used by OE SDK host\n// runtime. It is OK for the abi test to depend on it do selectively perform\n// checks.\nextern bool oe_is_avx_enabled;\nOE_EXTERNC_END\n\n// User-mode settable RFLAGS that are not commonly modified and usually\n// survive function calls: IF:9, NT:14\n#define TEST_RFLAGS 0x4200\n\n// RFLAGS value to clear TEST_RFLAGS: IF:9\n// IF is kernel-managed and usually set, so restore it if changed\n#define INIT_RFLAGS 0x200\n\n// Set FTZ, Truncation RC and DAZ, clear all exception masks\n#define TEST_MXCSR 0xE040\n\n// Initial MXCSR value as defined by Linux/Window ABIs\n#define INIT_MXCSR 0x1F80\n\n// Set RC to RNE, PC to SP, clear all exception masks (11 00 01 000000)\n#define TEST_FCW 0xC40\n\n// Initial MXCSR value as defined by Linux/Window ABIs\n#define INIT_FCW 0x37F\n\n// Constant for expected result of enclave_check_abi function\n#define EXPECTED_CHECK_ABI_RETURN_VALUE 42.0\n\ntypedef struct _windows_abi_state\n{\n    uint64_t rsi;\n    uint64_t rdi;\n    uint8_t xmm6[16];\n    uint8_t xmm7[16];\n    uint8_t xmm8[16];\n    uint8_t xmm9[16];\n    uint8_t xmm10[16];\n    uint8_t xmm11[16];\n    uint8_t xmm12[16];\n    uint8_t xmm13[16];\n    uint8_t xmm14[16];\n    uint8_t xmm15[16];\n} windows_abi_state_t;\n\ntypedef struct _abi_state\n{\n    uint64_t rbx;\n    uint64_t rbp;\n    uint64_t rsp;\n    uint64_t r12;\n    uint64_t r13;\n    uint64_t r14;\n    uint64_t r15;\n\n    uint64_t flags;\n    uint32_t mxcsr;\n    uint16_t fcw;\n    uint16_t padding;\n\n    windows_abi_state_t win_abi;\n} abi_state_t;\n\nOE_ALWAYS_INLINE void set_test_xmm_state(void)\n{\n    static const uint8_t test_xmm[16] = {\n        0xBE,\n        0xEF,\n        0xCA,\n        0xFE,\n        0xBE,\n        0xEF,\n        0xCA,\n        0xFE,\n        0xBE,\n        0xEF,\n        0xCA,\n        0xFE,\n        0xBE,\n        0xEF,\n        0xCA,\n        0xFE};\n\n    if (oe_is_avx_enabled)\n        asm(\"vmovdqu %0, %%xmm6;\"\n            \"vmovdqu %0, %%xmm7;\"\n            \"vmovdqu %0, %%xmm8;\"\n            \"vmovdqu %0, %%xmm9;\"\n            \"vmovdqu %0, %%xmm10;\"\n            \"vmovdqu %0, %%xmm11;\"\n            \"vmovdqu %0, %%xmm12;\"\n            \"vmovdqu %0, %%xmm13;\"\n            \"vmovdqu %0, %%xmm14;\"\n            \"vmovdqu %0, %%xmm15;\"\n            :\n            : \"m\"(test_xmm)\n            : \"xmm6\",\n              \"xmm7\",\n              \"xmm8\",\n              \"xmm9\",\n              \"xmm10\",\n              \"xmm11\",\n              \"xmm12\",\n              \"xmm13\",\n              \"xmm14\",\n              \"xmm15\");\n}\n\nOE_ALWAYS_INLINE void set_test_abi_state(void)\n{\n    uint64_t test_flags = TEST_RFLAGS;\n    uint32_t test_mxcsr = TEST_MXCSR;\n    uint16_t test_fcw = TEST_FCW;\n\n    asm(\"pushq %0;\"\n        \"popfq;\"\n        \"ldmxcsr %1;\"\n        \"fldcw %2;\" ::\"m\"(test_flags),\n        \"m\"(test_mxcsr),\n        \"m\"(test_fcw));\n}\n\nOE_ALWAYS_INLINE void reset_test_abi_state(void)\n{\n    uint64_t test_flags = INIT_RFLAGS;\n    uint32_t test_mxcsr = INIT_MXCSR;\n    uint16_t test_fcw = INIT_FCW;\n\n    asm(\"pushq %0;\"\n        \"popfq;\"\n        \"ldmxcsr %1;\"\n        \"fldcw %2;\" ::\"m\"(test_flags),\n        \"m\"(test_mxcsr),\n        \"m\"(test_fcw));\n}\n\nOE_ALWAYS_INLINE void read_abi_state(abi_state_t* state)\n{\n    if (oe_is_avx_enabled)\n        asm(\"movq %%rbx, (%0);\"\n            \"movq %%rbp, 8(%0);\"\n            \"movq %%rsp, 16(%0);\"\n            \"movq %%r12, 24(%0);\"\n            \"movq %%r13, 32(%0);\"\n            \"movq %%r14, 40(%0);\"\n            \"movq %%r15, 48(%0);\"\n            \"pushfq;\"\n            \"popq 56(%0);\"\n            \"stmxcsr 64(%0);\"\n            \"fstcw 68(%0);\"\n            \"movq    %%rsi, (%1);\"\n            \"movq    %%rdi, 8(%1);\"\n            \"vmovdqu %%xmm6, 16(%1);\"\n            \"vmovdqu %%xmm7, 32(%1);\"\n            \"vmovdqu %%xmm8, 48(%1);\"\n            \"vmovdqu %%xmm9, 64(%1);\"\n            \"vmovdqu %%xmm10, 80(%1);\"\n            \"vmovdqu %%xmm11, 96(%1);\"\n            \"vmovdqu %%xmm12, 112(%1);\"\n            \"vmovdqu %%xmm13, 128(%1);\"\n            \"vmovdqu %%xmm14, 144(%1);\"\n            \"vmovdqu %%xmm15, 160(%1);\"\n            :\n            : \"r\"(state), \"r\"(&state->win_abi));\n}\n\nOE_ALWAYS_INLINE bool is_same_abi_state(abi_state_t* a, abi_state_t* b)\n{\n    return (\n        (a->rbx == b->rbx) && (a->rbp == b->rbp) &&\n#ifndef GCC_RELEASE\n        /* On GCC Release builds (Clang or Debug builds work),\n         * the compiler optimization doesn't treat the always inlined\n         * read_abi_state as a boundary and only restores RSP prior to\n         * next function call, so RSP right before and after oe_enter\n         * can have different values. oe_enter itself before and after ENCLU\n         * does preserve the RSP, by manual debugging inspection, so this\n         * is a test limitation. */\n        (a->rsp == b->rsp) &&\n#endif\n        (a->r12 == b->r12) && (a->r13 == b->r13) && (a->r14 == b->r14) &&\n        (a->r15 == b->r15) &&\n\n        /* RFLAGS are generally volatile, only check stable test bits */\n        ((a->flags & TEST_RFLAGS) == (b->flags & TEST_RFLAGS)) &&\n\n        (a->mxcsr == b->mxcsr) && (a->fcw == b->fcw)\n#if defined(_WIN32)\n        && (memcmp(\n                (char*)&a->win_abi,\n                (char*)&b->win_abi,\n                sizeof(windows_abi_state_t)) == 0)\n#endif\n    );\n}\n\n#endif //_OE_ABI_UTILS_H\n", "// Copyright (c) Open Enclave SDK contributors.\n// Licensed under the MIT License.\n\n#include <math.h>\n#include <openenclave/edger8r/enclave.h>\n#include <openenclave/internal/calls.h>\n#include <stdlib.h>\n#include <string.h>\n#include \"../abi_utils.h\"\n#include \"abi_t.h\"\n\nOE_EXTERNC_BEGIN\n// By default, assume avx is available. This is the case with most processors\n// with SGX support.\nbool oe_is_avx_enabled = true;\nOE_EXTERNC_END\n\nvoid enclave_set_oe_is_avx_enabled(bool enabled)\n{\n    oe_is_avx_enabled = enabled;\n}\n\ndouble enclave_add_float()\n{\n    double my_res = 0;\n    volatile double my_num = 0.12345678899;\n\n    asm(\"fldl %1\\n\\t\"\n        \"fadd %%st, %%st\\n\\t\"\n        \"fstl %0\\n\\t\"\n        : \"=m\"(my_res)\n        : \"m\"(my_num)\n        :);\n\n    return my_res;\n}\n\ndouble enclave_check_abi()\n{\n    double retval = NAN;\n    oe_result_t result = OE_UNEXPECTED;\n    abi_state_t before_ocall_state = {};\n    abi_state_t after_ocall_state = {};\n\n    /* Marshalling struct cloned from abi_t.c, needs to be at least 16-bytes */\n    typedef struct _host_check_abi_args_t\n    {\n        oe_result_t _result;\n        void* deepcopy_out_buffer;\n        size_t deepcopy_out_buffer_size;\n        double _retval;\n    } host_check_abi_args_t;\n\n    /* Helper struct definition to manually flatten out ocall buffer with\n     * standard ocall parameters and args for host_check_abi. This test\n     * unrolls the EDL generated call stubs so that it can directly invoke\n     * the oe_ocall directly to check its ABI handling */\n    typedef struct _flat_ocall_args\n    {\n        oe_call_host_function_args_t host_function_args;\n        host_check_abi_args_t check_abi_args;\n    } flat_ocall_args_t;\n\n    /* abi_fcn_id_host_check_abi is defined in abi_t.c, must be kept in sync */\n    static const size_t abi_fcn_id_host_check_abi = 0;\n    const flat_ocall_args_t args_template = {\n        {.function_id = abi_fcn_id_host_check_abi,\n         .input_buffer = NULL,\n         .input_buffer_size = sizeof(args_template.check_abi_args),\n         .output_buffer = NULL,\n         .output_buffer_size = sizeof(args_template.check_abi_args),\n         .output_bytes_written = 0,\n         .result = OE_UNEXPECTED},\n        {._result = OE_UNEXPECTED,\n         .deepcopy_out_buffer = NULL,\n         .deepcopy_out_buffer_size = 0,\n         ._retval = 0}};\n\n    /* Alloc and initialize host_check_abi OCALL args buffer */\n    flat_ocall_args_t* args =\n        (flat_ocall_args_t*)oe_allocate_ocall_buffer(sizeof(args_template));\n    if (!args)\n        goto done;\n\n    /* Note that the OCALL code enforces that input_buffer must be provided\n     * and at least 16-bytes, even though it is not used by host_check_abi,\n     * so the test assigns it the same buffer as the output_buffer */\n    memcpy(args, &args_template, sizeof(args_template));\n    args->host_function_args.input_buffer = &args->check_abi_args;\n    args->host_function_args.output_buffer = &args->check_abi_args;\n\n    /* Set up and cache ABI test state */\n    set_test_abi_state();\n    read_abi_state(&before_ocall_state);\n\n    /* Invoke oe_ocall directly to test the ocall transition ABI handling */\n    result = oe_ocall(OE_OCALL_CALL_HOST_FUNCTION, (uint64_t)args, NULL);\n\n    /* Snap the ABI state immediately on return and clear test manipulations */\n    read_abi_state(&after_ocall_state);\n    reset_test_abi_state();\n\n    /* Check that oe_ocall succeeded */\n    if (result != OE_OK)\n        goto done;\n\n    /* Check the host_check_abi function succeeded and produced output */\n    if (args->host_function_args.result != OE_OK)\n        goto done;\n\n    if (args->host_function_args.output_bytes_written !=\n        sizeof(args_template.check_abi_args))\n        goto done;\n\n    /* Check the enclave_check_abi function returned expected value */\n    if (args->check_abi_args._retval != EXPECTED_CHECK_ABI_RETURN_VALUE)\n        goto done;\n\n    /* Verify expected ABI state around oe_ocall is preserved */\n    if (!is_same_abi_state(&before_ocall_state, &after_ocall_state))\n        goto done;\n\n    retval = args->check_abi_args._retval;\n\ndone:\n    return retval;\n}\n\nOE_SET_ENCLAVE_SGX(\n    1,    /* ProductID */\n    1,    /* SecurityVersion */\n    true, /* Debug */\n    1024, /* NumHeapPages */\n    1024, /* NumStackPages */\n    1);   /* NumTCS */\n", "// Copyright (c) Open Enclave SDK contributors.\n// Licensed under the MIT License.\n\n#include <host/ecall_ids.h>\n#include <host/hostthread.h>\n#include <math.h>\n#include <openenclave/host.h>\n#include <openenclave/internal/calls.h>\n#include <openenclave/internal/error.h>\n#include <openenclave/internal/raise.h>\n#include <openenclave/internal/tests.h>\n#include \"../abi_utils.h\"\n#include \"abi_u.h\"\n\nextern \"C\"\n{\n#include <host/sgx/enclave.h>\n}\n\n#include <openenclave/internal/constants_x64.h>\n\n#ifdef _WIN32\nextern \"C\"\n{\n    void oe_dummy_mmx_add();\n    void oe_dummy_fpu_loads();\n}\n#endif\n\noe_result_t test_abi_roundtrip(oe_enclave_t* enclave)\n{\n    printf(\"=== test_abi_roundtrip()\\n\");\n\n    oe_result_t result = OE_UNEXPECTED;\n    abi_state_t before_ecall_state = {};\n    abi_state_t after_ecall_state = {};\n\n    uint64_t global_id = OE_GLOBAL_ECALL_ID_NULL;\n    oe_thread_key thread_binding_key;\n\n    /* Test invariant: abi_enc is defined with only a single thread */\n    oe_thread_binding_t* binding = &enclave->bindings[0];\n    void* tcs = (void*)binding->tcs;\n\n    /* Marshalling struct cloned from abi_u.c, needs to be at least 16-bytes */\n    typedef struct _enclave_check_abi_args_t\n    {\n        oe_result_t _result;\n        void* deepcopy_out_buffer;\n        size_t deepcopy_out_buffer_size;\n        double _retval;\n    } enclave_check_abi_args_t;\n\n    /* Helper struct definition to manually flatten out ecall buffer with\n     * standard ecall parameters and args for enclave_check_abi. This test\n     * unrolls the EDL generated call stubs so that it can directly invoke\n     * the oe_enter directly to check its ABI handling */\n    typedef struct _flat_ecall_args\n    {\n        oe_call_enclave_function_args_t enc_function_args;\n        enclave_check_abi_args_t check_abi_args;\n    } flat_ecall_args_t;\n\n    flat_ecall_args_t* args = NULL;\n\n    const flat_ecall_args_t args_template = {\n        {.function_id = 0,\n         .input_buffer = NULL,\n         .input_buffer_size = sizeof(args_template.check_abi_args),\n         .output_buffer = NULL,\n         .output_buffer_size = sizeof(args_template.check_abi_args),\n         .output_bytes_written = 0,\n         .result = OE_UNEXPECTED},\n        {._result = OE_UNEXPECTED,\n         .deepcopy_out_buffer = NULL,\n         .deepcopy_out_buffer_size = 0,\n         ._retval = 0}};\n\n    /* Skip the ABI state test in simulation mode since OE SDK doesn't\n     * provide special ABI handling on simulated enclave transition */\n    if (enclave->simulate)\n        OE_RAISE_MSG(\n            OE_UNSUPPORTED,\n            \"SKIPPING in test_abi_roundtrip() in Simulation Mode\\n\",\n            NULL);\n\n    /* Alloc and initialize the enclave_check_abi ECALL args buffer */\n    args = (flat_ecall_args_t*)malloc(sizeof(args_template));\n    if (!args)\n        OE_RAISE(OE_OUT_OF_MEMORY);\n\n    memcpy(args, &args_template, sizeof(args_template));\n    args->enc_function_args.input_buffer = &args->check_abi_args;\n    args->enc_function_args.output_buffer = &args->check_abi_args;\n    OE_CHECK(oe_get_ecall_ids(\n        enclave,\n        \"enclave_check_abi\",\n        &global_id,\n        &args->enc_function_args.function_id));\n\n    /* This method needs to perform its own thread binding since it doesn't\n     * call through oe_ecall to get at oe_enter directly, and oe_ecall is\n     * responsible for the thread binding in the normal code path. */\n    if (binding->flags & _OE_THREAD_BUSY)\n        OE_RAISE_MSG(\n            OE_UNEXPECTED,\n            \"ASSERT: test_abi_roundtrip() expects to be single threaded with \"\n            \"access to the only enclave thread context, but the thread binding \"\n            \"at index 0 is marked BUSY\\n\",\n            NULL);\n\n    /* This test asserts the invariant as a single threaded app that\n     * test_abi_roundtrip runs right after enclave initialization, which set\n     * the thread_binding_key for ecalls already. This oe_thread_key_create\n     * value called here should then return the next thread local storage index,\n     * so to infer the one used for ecalls we use the obtained value - 1 */\n    if (!oe_thread_key_create(&thread_binding_key))\n    {\n        /* The key index (the reservation of the slot) can be freed immediately\n         * since the thread storage itself is not used by this test */\n        oe_thread_key_delete(thread_binding_key);\n    }\n    else\n        OE_RAISE_MSG(OE_UNEXPECTED, \"oe_thread_key_create failed\\n\", NULL);\n\n    oe_thread_setspecific(thread_binding_key - 1, binding);\n    binding->flags |= _OE_THREAD_BUSY;\n    binding->thread = oe_thread_self();\n    binding->count = 1;\n\n    /* Notify the debugger runtime */\n    if (enclave->debug && enclave->debug_enclave != NULL)\n        oe_debug_push_thread_binding(enclave->debug_enclave, (sgx_tcs_t*)tcs);\n\n    /* Emulate the oe_ecall flow */\n    {\n        uint64_t arg1 = oe_make_call_arg1(\n            OE_CODE_ECALL, OE_ECALL_CALL_ENCLAVE_FUNCTION, 0, OE_OK);\n        uint64_t arg2 = (uint64_t)args;\n        uint64_t arg3 = 0;\n        uint64_t arg4 = 0;\n\n        /* Set up and cache ABI test state */\n        set_test_xmm_state();\n        set_test_abi_state();\n        read_abi_state(&before_ecall_state);\n\n        /* Invoke oe_enter directly to test the ocall transition ABI handling */\n        oe_enter(tcs, OE_AEP_ADDRESS, arg1, arg2, &arg3, &arg4, enclave);\n\n        /* Snap the ABI state immediately on return and clear test changes */\n        read_abi_state(&after_ecall_state);\n        reset_test_abi_state();\n\n        oe_code_t code_out = oe_get_code_from_call_arg1(arg3);\n        uint16_t result_out = oe_get_result_from_call_arg1(arg3);\n\n        /* Check that the exit is not from unexpected OCALL, which should\n         * have been handled within oe_enter already */\n        if (code_out != OE_CODE_ERET)\n            OE_RAISE_MSG(\n                OE_UNEXPECTED,\n                \"test_abi_roundtrip only expects ERET but received an \"\n                \"unexpected EEXIT code: %#x\\n\",\n                code_out);\n\n        /* Check that the ECALL succeeded */\n        OE_CHECK((oe_result_t)result_out);\n    }\n\n    /* Check the enclave_check_abi function succeeded and produced output */\n    OE_CHECK(args->enc_function_args.result);\n    if (args->enc_function_args.output_bytes_written !=\n        sizeof(args_template.check_abi_args))\n        OE_RAISE_MSG(\n            OE_UNEXPECTED,\n            \"enclave_check_abi only wrote %#x output bytes\\n\",\n            args->enc_function_args.output_bytes_written);\n\n    /* Check the enclave_check_abi function returned expected value */\n    if (args->check_abi_args._retval != EXPECTED_CHECK_ABI_RETURN_VALUE)\n        OE_RAISE_MSG(\n            OE_FAILURE,\n            \"enclave_check_abi returned %f instead of expected value set by \"\n            \"host_check_abi\\n\",\n            args->check_abi_args._retval);\n\n    /* Verify that the expected ABI is preserved */\n    if (!is_same_abi_state(&before_ecall_state, &after_ecall_state))\n        OE_RAISE_MSG(\n            OE_FAILURE,\n            \"ABI state before and after oe_enter were not equal\\n\",\n            NULL);\n\n    result = OE_OK;\n\ndone:\n    /* Clean up the thread binding and debugger registration */\n    if (binding->flags & _OE_THREAD_BUSY)\n    {\n        binding->count--;\n\n        /* Notify the debugger runtime */\n        if (enclave->debug && enclave->debug_enclave != NULL)\n            oe_debug_pop_thread_binding();\n\n        if (binding->count == 0)\n        {\n            binding->flags &= (~_OE_THREAD_BUSY);\n            binding->thread = 0;\n            memset(&binding->event, 0, sizeof(binding->event));\n            oe_thread_setspecific(thread_binding_key - 1, NULL);\n        }\n    }\n\n    return result;\n}\n\ndouble host_check_abi()\n{\n    return EXPECTED_CHECK_ABI_RETURN_VALUE;\n}\n\nvoid test_mmx_abi_poison(oe_enclave_t* enclave)\n{\n    double float_result = 0;\n    uint64_t dummy = 0;\n\n    printf(\"=== test_mmx_abi_poison()\\n\");\n\n#ifdef _WIN32\n    oe_dummy_mmx_add();\n#else\n    asm(\"movq %0, %%mm0\\n\\t\"\n        \"paddd %%mm0, %%mm0\\n\\t\" ::\"m\"(dummy)\n        :);\n#endif\n\n    OE_TEST(enclave_add_float(enclave, &float_result) == OE_OK);\n\n    printf(\"x87 FPU result = %f\\n\", float_result);\n    OE_TEST(!isnan(float_result));\n}\n\nvoid test_fpu_stack_overflow(oe_enclave_t* enclave)\n{\n    double float_result = 0;\n    uint64_t dummy = 0;\n\n    printf(\"=== test_fpu_stack_overflow()\\n\");\n\n#ifdef _WIN32\n    oe_dummy_fpu_loads();\n#else\n    asm(\"fldl %0\\n\\t\"\n        \"fldl %0\\n\\t\"\n        \"fldl %0\\n\\t\"\n        \"fldl %0\\n\\t\"\n        \"fldl %0\\n\\t\"\n        \"fldl %0\\n\\t\"\n        \"fldl %0\\n\\t\"\n        \"fldl %0\\n\\t\" ::\"m\"(dummy)\n        :);\n#endif\n\n    OE_TEST(enclave_add_float(enclave, &float_result) == OE_OK);\n\n    printf(\"x87 FPU result = %f\\n\", float_result);\n    OE_TEST(!isnan(float_result));\n}\n\nint main(int argc, const char* argv[])\n{\n    oe_result_t result;\n    oe_enclave_t* enclave = NULL;\n\n    if (argc != 2)\n    {\n        fprintf(stderr, \"Usage: %s ENCLAVE\\n\", argv[0]);\n        exit(1);\n    }\n\n    const uint32_t flags = oe_get_create_flags();\n\n    result = oe_create_abi_enclave(\n        argv[1], OE_ENCLAVE_TYPE_SGX, flags, NULL, 0, &enclave);\n    if (result != OE_OK)\n    {\n        oe_put_err(\"oe_create_abi_enclave(): result=%u\", result);\n    }\n\n    // oe_is_avx_enabled has already been setup by the host runtime.\n    // Pass it along to the enclave.\n    OE_TEST(enclave_set_oe_is_avx_enabled(enclave, oe_is_avx_enabled) == OE_OK);\n\n    result = test_abi_roundtrip(enclave);\n    OE_TEST(result == OE_OK || result == OE_UNSUPPORTED);\n\n    test_mmx_abi_poison(enclave);\n    test_fpu_stack_overflow(enclave);\n\n    if ((result = oe_terminate_enclave(enclave)) != OE_OK)\n    {\n        oe_put_err(\"oe_terminate_enclave(): result=%u\", result);\n    }\n\n    printf(\"=== passed all tests (%s)\\n\", argv[0]);\n\n    return 0;\n}\n", "// Copyright (c) Open Enclave SDK contributors.\n// Licensed under the MIT License.\n\n#include <dirent.h>\n#include <errno.h>\n#include <libgen.h>\n#include <openenclave/enclave.h>\n#include <openenclave/internal/constants_x64.h>\n#include <openenclave/internal/libc/init.h>\n#include <openenclave/internal/tests.h>\n#include <search.h>\n#include <stdarg.h>\n#include <stdbool.h>\n#include <stdint.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/mount.h>\n#include <time.h>\n#include \"libc_t.h\"\n#include \"mtest.h\"\n\n#include \"libc_tests.h\"\n\n#pragma STDC FENV_ACCESS ON\n\n#if defined(__x86_64__) || defined(_M_X64)\n#define XMM_OK\n#endif\n\n#if defined(XMM_OK)\nvoid _reset_fxsave_state()\n{\n    /* Initialize the FXSAVE state values to Linux x86-64 ABI defined values:\n     * FCW = 0x037F, MXCSR = 0x1F80, MXCSR mask = 0xFFFF */\n    static OE_ALIGNED(OE_FXSAVE_ALIGNMENT) const uint64_t\n        _initial_fxstate[OE_FXSAVE_AREA_SIZE / sizeof(uint64_t)] = {\n            0x037F, 0, 0, 0xFFFF00001F80,\n            0,      0, 0, 0,\n            0,      0, 0, 0,\n            0,      0, 0, 0,\n            0,      0, 0, 0,\n            0,      0, 0, 0,\n            0,      0, 0, 0,\n            0,      0, 0, 0,\n            0,      0, 0, 0,\n            0,      0, 0, 0,\n            0,      0, 0, 0,\n            0,      0, 0, 0,\n            0,      0, 0, 0,\n            0,      0, 0, 0,\n            0,      0, 0, 0,\n            0,      0, 0, 0,\n        };\n\n    asm volatile(\"fxrstor %[fx_state] \\n\\t\"\n                 :\n                 : [fx_state] \"m\"(_initial_fxstate)\n                 :);\n}\n#endif\n\nint t_status = 0;\n\nint device_init()\n{\n    OE_TEST(oe_load_module_host_file_system() == OE_OK);\n    OE_TEST(oe_load_module_host_socket_interface() == OE_OK);\n    // OE_TEST(oe_load_module_host_epoll() == OE_OK);\n\n#ifndef CODE_COVERAGE\n    OE_TEST(mount(\"/\", \"/\", OE_HOST_FILE_SYSTEM, 0, NULL) == 0);\n#endif\n    return 0;\n}\n\nint t_printf(const char* s, ...)\n{\n    va_list ap;\n    char buf[512];\n\n    t_status = 1;\n    va_start(ap, s);\n    int n = vsnprintf(buf, sizeof buf, s, ap);\n    va_end(ap);\n\n    printf(\"%s\\n\", buf);\n    return n;\n}\n\nint t_setrlim(int r, int64_t lim)\n{\n    return 0;\n}\n\nint run_test_helper(const char* test_name, libc_test_function_t test_function)\n{\n    extern char** __environ;\n    char** environ = NULL;\n    int ret = 1;\n\n    /* Print running message. */\n    printf(\"=== running: %s\\n\", test_name);\n\n#if defined(XMM_OK)\n    /* Reset the FXSAVE state between tests.\n     * The original libc tests for floating point math were compiled as\n     * individual executables and assume ABI-initialized floating point and\n     * MXCSR state. Since the enclave runs multiple tests in the same enclave\n     * consecutively, we reset the FXSAVE state on each run. */\n    _reset_fxsave_state();\n#endif\n\n    /* Disable Open Enclave debug malloc checks. */\n    extern bool oe_disable_debug_malloc_check;\n    oe_disable_debug_malloc_check = true;\n\n    /* Allocate an environment for invoking the test. */\n    if (!(environ = (char**)calloc(1, sizeof(char*))))\n        goto done;\n\n    memset(environ, 0, sizeof(char**));\n    __environ = environ;\n\n    /* Run the test */\n    const char* argv[] = {\"test\", NULL};\n\n    if (test_function(1, argv) != 0)\n    {\n        /* Prevent cascading of false negatives. */\n        t_status = 0;\n\n        fprintf(stderr, \"*** failed: %s\\n\", test_name);\n        goto done;\n    }\n\n    ret = 0;\n\ndone:\n\n    free(environ);\n    __environ = NULL;\n\n    return ret;\n}\n\nint run_test(const char* test_name)\n{\n    device_init();\n    libc_test_function_t test = get_test_case(test_name);\n\n    OE_TEST(oe_test_libc_is_initialized());\n\n    if (test)\n    {\n        return run_test_helper(test_name, test);\n    }\n\n    printf(\"*** failed: test %s is not a valid test\", test_name);\n    return 1;\n}\n\nint run_all_tests()\n{\n    int ret;\n\n    device_init();\n\n    OE_TEST(oe_test_libc_is_initialized());\n\n    ret = 0;\n    for (int i = 0; i < sizeof(libc_tests) / sizeof(libc_test_entry_t); i++)\n    {\n        libc_test_entry_t test = libc_tests[i];\n        ret += run_test_helper(test.test_name, test.test_function);\n    }\n\n    return ret;\n}\n\nOE_SET_ENCLAVE_SGX(\n    1,    /* ProductID */\n    1,    /* SecurityVersion */\n    true, /* Debug */\n    512,  /* NumHeapPages */\n    256,  /* NumStackPages */\n    4);   /* NumTCS */\n\n#define TA_UUID                                            \\\n    { /* d7fe296a-24e9-46d1-aa78-9c7395082a41 */           \\\n        0xd7fe296a, 0x24e9, 0x46d1,                        \\\n        {                                                  \\\n            0xaa, 0x78, 0x9c, 0x73, 0x95, 0x08, 0x2a, 0x41 \\\n        }                                                  \\\n    }\n\nOE_SET_ENCLAVE_OPTEE(\n    TA_UUID,\n    1 * 1024 * 1024,\n    12 * 1024,\n    0,\n    \"1.0.0\",\n    \"libc test\")\n"], "fixing_code": ["// Copyright (c) Open Enclave SDK contributors.\n// Licensed under the MIT License.\n\n#ifndef _ASM_COMMON_INC\n#define _ASM_COMMON_INC\n\n//==============================================================================\n//\n// This macro is used to reset all XSAVE supported state components to a\n// clean initial state. This includes:\n//\n//  - The legacy SSE state:\n//    - Initializes the FPU control word to ABI-specified value 0x037F\n//    - Initializes MXCSR to ABI-specified value 0x1FBF and MXCSR_MASK to 0xFFFF\n//    - Clears FPU Status, Tag, OpCode, and FIP words\n//    - Clears all FDP bits\n//    - Clears all MMX/FPU registers\n//    - Clears all XMM registers\n//\n//  - The extended XSAVE state components:\n//    - Clears all XSTATE_BV bits\n//    - Sets XCOMP_BV bit-63 to support compaction mode\n//    - Clears all other XCOMP_BV bits\n//\n//==============================================================================\n.macro oe_cleanup_xstates\n    // Preserve registers being used\n    mov %rax, %r8\n    mov %rdx, %r9\n\n    // Check if extended states are supported by the OS.\n    // If not, fallback to FXRSTOR to clear legacy SSE states only.\n    // Otherwise, clear both legacy SSE states and extended states with XRSTOR.\n    movl    oe_is_xsave_supported(%rip), %eax\n    cmpl    $0, %eax\n    jz      1f\n\n    // Set the XSAVE_MASK\n    mov $0xFFFFFFFF, %eax\n    mov $0xFFFFFFFF, %edx\n\n    // Restore initial enclave XSAVE state\n    xrstor64 OE_XSAVE_INITIAL_STATE(%rip)\n    jmp     2f\n1:\n    // Restore initial enclave legacy SSE state\n    fxrstor64 OE_XSAVE_INITIAL_STATE(%rip)\n2:\n    // Put a lfence after changing MXCSR for MXCSR Configuration Dependent\n    // Timing (MCDT) mitigation\n    lfence\n    // Restore the registers\n    mov %r8, %rax\n    mov %r9, %rdx\n.endm\n\n//==============================================================================\n//\n// This macro is used to clean up the enclave registers in addition to the\n// extended states (see oe_cleanup_xstates).\n//\n// It scrubs all general purpose registers excluding:\n//  - RAX and RBX, which are used as input registers of EEXIT.\n//  - RCX, which is used as the output register of EEXIT.\n//  - RDI and RSI, which are used as output parameters defined by SDK.\n//  - RBP and RSP, which will be set to host values of RBP & RSP right before\n//      EEXIT is executed.\n//\n//==============================================================================\n.macro oe_cleanup_registers\n    // Scrub both Legacy SSE and extended XSTATEs.\n    oe_cleanup_xstates\n\n    // Zero out GPRs.\n    // Retain r11 since it is used as a reference to the td structure.\n    // The exit and enter routines are responsible for clearing r11\n    // prior to returning.\n    xor %rdx, %rdx\n    xor %r9,  %r9\n    xor %r10, %r10\n    xor %r12, %r12\n    xor %r13, %r13\n    xor %r14, %r14\n    xor %r15, %r15\n\n    // Zero out the status flags (CF, PF, AF, SF, OF) that could leak\n    // information about instructions executed by the enclave without using stack.\n    // Doing so avoiding using untrusted host stack when cleaning up registers\n    // during enclave enter and exit routines.\n    // To clear system and control flags, see oe_cleanup_flags_on_enclave_stack\n    // for more detail.\n    mov %rax, %r8\n    xor %rax, %rax\n    test %al, %al // Clear OF\n    sahf // Clear SF, ZF AF, PF, and CF\n    mov %r8, %rax\n\n    // No need to clear r8, which equals to rax (return value to the host)\n\n.endm\n\n//==============================================================================\n//\n// This macro is used to clean up the enclave FLAGS register, including not only\n// status but also system and control flags.\n//\n// The macro does not reserve r15 and require consuming stack. Please make sure\n// using the macro within the enclave stack. Currently, the macro is only used\n// during oe_enter.\n//\n//==============================================================================\n.macro oe_cleanup_flags_on_enclave_stack\n    xor %r15, %r15\n    pushq %r15\n    popfq\n.endm\n\n#endif\n", "// Copyright (c) Open Enclave SDK contributors.\n// Licensed under the MIT License.\n\n#include <openenclave/bits/types.h>\n#include <openenclave/internal/constants_x64.h>\n\n/*\n * Initialization state for XSAVE area in the enclave.\n */\n/* clang-format off */\nOE_ALIGNED(OE_XSAVE_ALIGNMENT) const uint32_t\nOE_XSAVE_INITIAL_STATE[OE_MINIMAL_XSTATE_AREA_SIZE/sizeof(uint32_t)] = {\n\n    /* FXSAVE (a.k.a. legacy XSAVE) area */\n    /* Set FPU Control Word to ABI init value of 0x037F,\n     * clear Status, Tag, OpCode, FIP words */\n    0x037F, 0, 0, 0,\n\n    /* Clear FDP bits, set MXCSR to ABI init value of 0x1FBF\n     * and MXCSR_MASK to all bits (0XFFFF) */\n    0, 0, 0x1FBF, 0xFFFF,\n\n    /* Clear ST/MM0-7 */\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n\n    /* Clear XMM0-15 */\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n\n    /* Reserved bits up to end of FXSAVE area */\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0,\n\n    /* XSAVE Header */\n    /* Set XSTATE_BV[1] to 1 (SSE state) */\n    2, 0,\n    /* Set XCOMP_BV[1] to 1 (SSE state), allowing non-default\n     * MXCSR value to be restored.\n     * Also, set XCOMP_BV[63] to 1 for compaction mode */\n    2, 0x80000000,\n\n    /* Reserved XSAVE header bits */\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n};\n/* clang-format on */\n", "// Copyright (c) Open Enclave SDK contributors.\n// Licensed under the MIT License.\n\n#include \"../calls.h\"\n#include <openenclave/advanced/allocator.h>\n#include <openenclave/attestation/attester.h>\n#include <openenclave/attestation/verifier.h>\n#include <openenclave/bits/sgx/sgxtypes.h>\n#include <openenclave/corelibc/stdlib.h>\n#include <openenclave/corelibc/string.h>\n#include <openenclave/edger8r/enclave.h>\n#include <openenclave/enclave.h>\n#include <openenclave/internal/atomic.h>\n#include <openenclave/internal/calls.h>\n#include <openenclave/internal/crypto/init.h>\n#include <openenclave/internal/fault.h>\n#include <openenclave/internal/globals.h>\n#include <openenclave/internal/jump.h>\n#include <openenclave/internal/malloc.h>\n#include <openenclave/internal/print.h>\n#include <openenclave/internal/raise.h>\n#include <openenclave/internal/safecrt.h>\n#include <openenclave/internal/safemath.h>\n#include <openenclave/internal/sgx/ecall_context.h>\n#include <openenclave/internal/sgx/td.h>\n#include <openenclave/internal/thread.h>\n#include <openenclave/internal/trace.h>\n#include <openenclave/internal/types.h>\n#include <openenclave/internal/utils.h>\n#include \"../../../common/sgx/sgxmeasure.h\"\n#include \"../../sgx/report.h\"\n#include \"../atexit.h\"\n#include \"../tracee.h\"\n#include \"arena.h\"\n#include \"asmdefs.h\"\n#include \"core_t.h\"\n#include \"cpuid.h\"\n#include \"handle_ecall.h\"\n#include \"init.h\"\n#include \"openenclave/bits/result.h\"\n#include \"openenclave/internal/backtrace.h\"\n#include \"platform_t.h\"\n#include \"report.h\"\n#include \"switchlesscalls.h\"\n#include \"td.h\"\n#include \"xstate.h\"\n\nvoid oe_abort_with_td(oe_sgx_td_t* td) OE_NO_RETURN;\n\noe_result_t __oe_enclave_status = OE_OK;\nuint8_t __oe_initialized = 0;\n\n/*\n**==============================================================================\n**\n** Glossary:\n**\n**     TCS      - Thread control structure. The TCS is an address passed to\n**                EENTER and passed onto the entry point (_start). The TCS\n**                is the address of a TCS page in the enclave memory. This page\n**                is not accessible to the enclave itself. The enclave stores\n**                state about the execution of a thread in this structure,\n**                such as the entry point (TCS.oentry), which refers to the\n**                _start function. It also maintains the index of the\n**                current SSA (TCS.cssa) and the number of SSA's (TCS.nssa).\n**\n**     oe_sgx_td_t       - Thread data. Per thread data as defined by the\n**                oe_thread_data_t structure and extended by the oe_sgx_td_t\n*structure.\n**                This structure records the stack pointer of the last EENTER.\n**\n**     SP       - Stack pointer. Refers to the enclave's stack pointer.\n**\n**     BP       - Base pointer. Refers to the enclave's base pointer.\n**\n**     HOSTSP   - Host stack pointer. Refers to the host's stack pointer as\n**                received in the EENTER call.\n**\n**     HOSTBP   - Host base pointer. Refers to the host's base pointer as\n**                received in the EENTER call.\n**\n**     AEP      - Asynchronous Exception Procedure. This procedure is passed\n**                by the host to EENTER. If a fault occurs while in the enclave,\n**                the hardware calls this procedure. The procedure may\n**                terminate or call ERESUME to continue executing in the\n**                enclave.\n**\n**     AEX      - Asynchronous Exception (occurs when enclave faults). The\n**                hardware transfers control to a host AEP (passed as a\n**                parameter to EENTER).\n**\n**     SSA      - State Save Area. When a fault occurs in the enclave, the\n**                hardware saves the state here (general purpose registers)\n**                and then transfers control to the host AEP. If the AEP\n**                executes the ERESUME instruction, the hardware restores the\n**                state from the SSA.\n**\n**     EENTER   - An untrusted instruction that is executed by the host to\n**                enter the enclave. The caller passes the address of a TCS page\n**                within the enclave, an AEP, and any parameters in the RDI and\n**                RSI registers. This implementation passes the operation\n**                number (FUNC) in RDI and a pointer to the arguments structure\n**                (ARGS) in RSI.\n**\n**     EEXIT    - An instruction that is executed by the host to exit the\n**                enclave and return control to the host. The caller passes\n**                the address of some instruction to jump to (RETADDR) in the\n**                RBX register and an AEP in the RCX register (null at this\n**                time).\n**\n**     RETADDR  - Refers to the address of the return instruction that the\n**                hardware jumps to from EEXIT. This is an instruction in\n**                host immediately following the instruction that executed\n**                EENTER.\n**\n**     CSSA     - The current SSA slot index (as given by TCS.cssa). EENTER\n**                passes a CSSA parameter (RAX) to _start(). A CSSA of zero\n**                indicates a normal entry. A non-zero CSSA indicates an\n**                exception entry (an AEX has occurred).\n**\n**     NSSA     - The number of SSA slots in the thread section (of this\n**                enclave. If CSSA == NSSA, then the SSA's have been exhausted\n**                and the EENTER instruction will fault.\n**\n**     ECALL    - A function call initiated by the host and carried out by\n**                the enclave. The host executes the EENTER instruction to\n**                enter the enclave.\n**\n**     ERET     - A return from an ECALL initiated by the enclave. The\n**                enclave executes the EEXIT instruction to exit the enclave.\n**\n**     OCALL    - A function call initiated by the enclave and carried out\n**                by the host. The enclave executes the EEXIT instruction to\n**                exit the enclave.\n**\n**     ORET     - A return from an OCALL initiated by the host. The host\n**                executes the EENTER instruction to enter the enclave.\n**\n**==============================================================================\n*/\n\n/*\n**==============================================================================\n** oe_libc_initialize()\n**\n**   Weak implementation of libc initialization function.\n**\n**==============================================================================\n*/\nOE_WEAK void oe_libc_initialize(void)\n{\n}\n\n/*\n**==============================================================================\n**\n** _handle_init_enclave()\n**\n**     Handle the OE_ECALL_INIT_ENCLAVE from host and ensures that each state\n**     initialization function in the enclave only runs once.\n**\n**==============================================================================\n*/\nstatic oe_result_t _handle_init_enclave(uint64_t arg_in)\n{\n    static bool _once = false;\n    oe_result_t result = OE_OK;\n    /* Double checked locking (DCLP). */\n    bool o = _once;\n\n    /* DCLP Acquire barrier. */\n    OE_ATOMIC_MEMORY_BARRIER_ACQUIRE();\n    if (o == false)\n    {\n        static oe_spinlock_t _lock = OE_SPINLOCK_INITIALIZER;\n        oe_spin_lock(&_lock);\n\n        if (_once == false)\n        {\n            oe_enclave_t* enclave = (oe_enclave_t*)arg_in;\n\n            if (!oe_is_outside_enclave(enclave, 1))\n                OE_RAISE(OE_INVALID_PARAMETER);\n\n            oe_enclave = enclave;\n\n            /* Initialize the CPUID table before calling global constructors. */\n            OE_CHECK(oe_initialize_cpuid());\n\n            /* Initialize the xstate settings\n             * Depends on TD and sgx_create_report, so can't happen earlier */\n            OE_CHECK(oe_set_is_xsave_supported());\n\n            /* Initialize libc */\n            oe_libc_initialize();\n\n            /* Initialize the OE crypto library. */\n            oe_crypto_initialize();\n\n            /* Call global constructors. Now they can safely use simulated\n             * instructions like CPUID. */\n            oe_call_init_functions();\n\n            /* DCLP Release barrier. */\n            OE_ATOMIC_MEMORY_BARRIER_RELEASE();\n            _once = true;\n            __oe_initialized = 1;\n        }\n\n        oe_spin_unlock(&_lock);\n    }\ndone:\n    return result;\n}\n\n/**\n * This is the preferred way to call enclave functions.\n */\noe_result_t oe_handle_call_enclave_function(uint64_t arg_in)\n{\n    oe_call_enclave_function_args_t args = {0}, *args_host_ptr = NULL;\n    oe_call_function_return_args_t* return_args_ptr = NULL;\n    oe_result_t result = OE_OK;\n    oe_ecall_func_t func = NULL;\n    uint8_t* buffer = NULL;\n    uint8_t* input_buffer = NULL;\n    uint8_t* output_buffer = NULL;\n    size_t buffer_size = 0;\n    size_t output_bytes_written = 0;\n    ecall_table_t ecall_table;\n\n    // Ensure that args lies outside the enclave and is 8-byte aligned\n    // (against the xAPIC vulnerability).\n    // The size of oe_call_enclave_function_args_t is guaranteed to be\n    // 8-byte aligned via compile-time checks.\n    if (!oe_is_outside_enclave(\n            (void*)arg_in, sizeof(oe_call_enclave_function_args_t)) ||\n        (arg_in % 8) != 0)\n        OE_RAISE(OE_INVALID_PARAMETER);\n\n    // Copy args to enclave memory to avoid TOCTOU issues.\n    args_host_ptr = (oe_call_enclave_function_args_t*)arg_in;\n    oe_memcpy_aligned(\n        &args, args_host_ptr, sizeof(oe_call_enclave_function_args_t));\n\n    // Ensure that input buffer is valid (oe_is_outside_enclave ensures\n    // the buffer is not NULL).\n    // The buffer size must at least equal to oe_call_function_args_t\n    if (!oe_is_outside_enclave(args.input_buffer, args.input_buffer_size) ||\n        args.input_buffer_size < sizeof(oe_call_function_return_args_t))\n        OE_RAISE(OE_INVALID_PARAMETER);\n\n    // Ensure that output buffer is valid (oe_is_outside_enclave ensures\n    // the buffer is not NULL).\n    // The buffer size must at least equal to oe_call_function_return_args_t\n    if (!oe_is_outside_enclave(args.output_buffer, args.output_buffer_size) ||\n        args.output_buffer_size < sizeof(oe_call_function_return_args_t))\n        OE_RAISE(OE_INVALID_PARAMETER);\n\n    // Validate output and input buffer addresses and sizes.\n    // Both of them must be correctly aligned (against the xAPIC vulnerability).\n    if ((args.input_buffer_size % OE_EDGER8R_BUFFER_ALIGNMENT) != 0 ||\n        ((uint64_t)args.input_buffer % 8) != 0)\n        OE_RAISE(OE_INVALID_PARAMETER);\n\n    if ((args.output_buffer_size % OE_EDGER8R_BUFFER_ALIGNMENT) != 0 ||\n        ((uint64_t)args.output_buffer % 8) != 0)\n        OE_RAISE(OE_INVALID_PARAMETER);\n\n    OE_CHECK(oe_safe_add_u64(\n        args.input_buffer_size, args.output_buffer_size, &buffer_size));\n\n    // The __oe_ecall_table is defined in the oeedger8r-generated\n    // code.\n    ecall_table.ecalls = oe_ecalls_table;\n    ecall_table.num_ecalls = oe_ecalls_table_size;\n\n    // Fetch matching function.\n    if (args.function_id >= ecall_table.num_ecalls)\n        OE_RAISE(OE_NOT_FOUND);\n\n    func = ecall_table.ecalls[args.function_id];\n\n    if (func == NULL)\n        OE_RAISE(OE_NOT_FOUND);\n\n    // Allocate buffers in enclave memory\n    buffer = input_buffer = oe_malloc(buffer_size);\n    if (buffer == NULL)\n        OE_RAISE(OE_OUT_OF_MEMORY);\n\n    // Copy input buffer from the host to enclave buffer.\n    oe_memcpy_aligned(input_buffer, args.input_buffer, args.input_buffer_size);\n\n    // Clear out output buffer.\n    // This ensures reproducible behavior if say the function is reading from\n    // output buffer.\n    output_buffer = buffer + args.input_buffer_size;\n    memset(output_buffer, 0, args.output_buffer_size);\n\n    // Call the function.\n    func(\n        input_buffer,\n        args.input_buffer_size,\n        output_buffer,\n        args.output_buffer_size,\n        &output_bytes_written);\n\n    /*\n     * The output_buffer is expected to point to a marshaling struct.\n     * The function is expected to fill the struct.\n     */\n    return_args_ptr = (oe_call_function_return_args_t*)output_buffer;\n\n    result = return_args_ptr->result;\n    if (result == OE_OK)\n    {\n        /*\n         * Error out the case if the deepcopy_out_buffer is NULL but the\n         * deepcopy_out_buffer_size is not zero or if the deepcopy_out_buffer is\n         * not NULL but the deepcopy_out_buffer_size is zero. Note that this\n         * should only occur if the oeedger8r was not used or if\n         * oeedger8r-generated routine is modified.\n         */\n        if ((!return_args_ptr->deepcopy_out_buffer &&\n             return_args_ptr->deepcopy_out_buffer_size) ||\n            (return_args_ptr->deepcopy_out_buffer &&\n             !return_args_ptr->deepcopy_out_buffer_size))\n            OE_RAISE(OE_UNEXPECTED);\n\n        /*\n         * Nonzero deepcopy_out_buffer and deepcopy_out_buffer_size fields\n         * indicate that there is deep-copied content that needs to be\n         * transmitted to the host.\n         */\n        if (return_args_ptr->deepcopy_out_buffer &&\n            return_args_ptr->deepcopy_out_buffer_size)\n        {\n            /*\n             * Ensure that the content lies in enclave memory.\n             * Note that this should only fail if oeedger8r was not used or if\n             * the oeedger8r-generated routine is modified.\n             */\n            if (!oe_is_within_enclave(\n                    return_args_ptr->deepcopy_out_buffer,\n                    return_args_ptr->deepcopy_out_buffer_size))\n                OE_RAISE(OE_UNEXPECTED);\n\n            void* host_buffer =\n                oe_host_malloc(return_args_ptr->deepcopy_out_buffer_size);\n\n            /* Copy the deep-copied content to host memory. */\n            OE_CHECK(oe_memcpy_s_with_barrier(\n                host_buffer,\n                return_args_ptr->deepcopy_out_buffer_size,\n                return_args_ptr->deepcopy_out_buffer,\n                return_args_ptr->deepcopy_out_buffer_size));\n\n            /* Release the memory on the enclave heap. */\n            oe_free(return_args_ptr->deepcopy_out_buffer);\n\n            return_args_ptr->deepcopy_out_buffer = host_buffer;\n        }\n\n        // Copy outputs to host memory.\n        OE_CHECK(oe_memcpy_s_with_barrier(\n            args.output_buffer,\n            args.output_buffer_size,\n            output_buffer,\n            args.output_buffer_size));\n\n        // The ecall succeeded.\n        OE_WRITE_VALUE_WITH_BARRIER(\n            &args_host_ptr->output_bytes_written, output_bytes_written);\n        OE_WRITE_VALUE_WITH_BARRIER(&args_host_ptr->result, OE_OK);\n    }\n\ndone:\n    if (result != OE_OK && return_args_ptr && args.output_buffer)\n    {\n        return_args_ptr->result = result;\n        return_args_ptr->deepcopy_out_buffer = NULL;\n        return_args_ptr->deepcopy_out_buffer_size = 0;\n\n        oe_memcpy_s_with_barrier(\n            args.output_buffer,\n            args.output_buffer_size,\n            return_args_ptr,\n            sizeof(oe_call_function_return_args_t));\n    }\n\n    if (buffer)\n        oe_free(buffer);\n\n    return result;\n}\n\n/*\n**==============================================================================\n**\n** _handle_exit()\n**\n**     Initiate call to EEXIT.\n**\n**==============================================================================\n*/\nstatic void _handle_exit(oe_code_t code, uint16_t func, uint64_t arg)\n    OE_NO_RETURN;\n\nstatic void _handle_exit(oe_code_t code, uint16_t func, uint64_t arg)\n{\n    oe_exit_enclave(oe_make_call_arg1(code, func, 0, OE_OK), arg);\n}\n\nvoid oe_virtual_exception_dispatcher(\n    oe_sgx_td_t* td,\n    uint64_t arg_in,\n    uint64_t* arg_out);\n\n/*\n**==============================================================================\n**\n** _call_at_exit_functions()\n**\n**     Invoke atexit functions (e.g., registered by atexit() or the destructor\n**     attribute)\n**\n**==============================================================================\n*/\nstatic void _call_at_exit_functions(void)\n{\n    static bool _at_exit_functions_done = false;\n    static oe_spinlock_t _lock = OE_SPINLOCK_INITIALIZER;\n\n    oe_spin_lock(&_lock);\n    if (!_at_exit_functions_done)\n    {\n        /* Call functions installed by oe_cxa_atexit() and oe_atexit()\n         */\n        oe_call_atexit_functions();\n\n        /* Call all finalization functions */\n        oe_call_fini_functions();\n\n        _at_exit_functions_done = true;\n    }\n    oe_spin_unlock(&_lock);\n}\n\n/*\n**==============================================================================\n**\n** _enclave_destructor()\n**\n**==============================================================================\n*/\nstatic oe_result_t _enclave_destructor(void)\n{\n    oe_result_t result = OE_FAILURE;\n    static bool _destructor_done = false;\n    static oe_spinlock_t _lock = OE_SPINLOCK_INITIALIZER;\n\n    oe_spin_lock(&_lock);\n    if (!_destructor_done)\n    {\n        /* Cleanup attesters */\n        oe_attester_shutdown();\n\n        /* Cleanup verifiers */\n        oe_verifier_shutdown();\n\n        /* If memory still allocated, print a trace and return an error */\n        OE_CHECK(oe_check_memory_leaks());\n\n        /* Cleanup the allocator */\n        oe_allocator_cleanup();\n\n        _destructor_done = true;\n    }\n\n    result = OE_OK;\n\ndone:\n    oe_spin_unlock(&_lock);\n    return result;\n}\n\n/*\n**==============================================================================\n**\n** _handle_ecall()\n**\n**     Handle an ECALL.\n**\n**==============================================================================\n*/\n\nstatic void _handle_ecall(\n    oe_sgx_td_t* td,\n    uint16_t func,\n    uint64_t arg_in,\n    uint64_t* output_arg1,\n    uint64_t* output_arg2)\n{\n    /* To keep status of td consistent before and after _handle_ecall, td_init\n     is moved into _handle_ecall. In this way _handle_ecall will not trigger\n     stack check fail by accident. Of course not all function have the\n     opportunity to keep such consistency. Such basic functions are moved to a\n     separate source file and the stack protector is disabled by force\n     through fno-stack-protector option. */\n\n    /* Initialize thread data structure (if not already initialized) */\n    if (!td_initialized(td))\n    {\n        td_init(td);\n    }\n\n    oe_result_t result = OE_OK;\n\n    /* Insert ECALL context onto front of oe_sgx_td_t.ecalls list */\n    oe_callsite_t callsite = {{0}};\n    uint64_t arg_out = 0;\n\n    td_push_callsite(td, &callsite);\n\n    // Acquire release semantics for __oe_initialized are present in\n    // _handle_init_enclave.\n    if (!__oe_initialized)\n    {\n        // The first call to the enclave must be to initialize it.\n        // Global constructors can throw exceptions/signals and result in signal\n        // handlers being invoked. Eg. Using CPUID instruction within a global\n        // constructor. We should also allow handling these exceptions.\n        if (func != OE_ECALL_INIT_ENCLAVE &&\n            func != OE_ECALL_VIRTUAL_EXCEPTION_HANDLER)\n        {\n            goto done;\n        }\n    }\n    else\n    {\n        // Disallow re-initialization.\n        if (func == OE_ECALL_INIT_ENCLAVE)\n        {\n            goto done;\n        }\n    }\n\n    // td_push_callsite increments the depth. depth > 1 indicates a reentrant\n    // call. Reentrancy is allowed to handle exceptions and to terminate the\n    // enclave.\n    if (td->depth > 1 && (func != OE_ECALL_VIRTUAL_EXCEPTION_HANDLER &&\n                          func != OE_ECALL_DESTRUCTOR))\n    {\n        /* reentrancy not permitted. */\n        result = OE_REENTRANT_ECALL;\n        goto done;\n    }\n\n    /* Dispatch the ECALL */\n    switch (func)\n    {\n        case OE_ECALL_CALL_ENCLAVE_FUNCTION:\n        {\n            arg_out = oe_handle_call_enclave_function(arg_in);\n            break;\n        }\n        case OE_ECALL_CALL_AT_EXIT_FUNCTIONS:\n        {\n            _call_at_exit_functions();\n            break;\n        }\n        case OE_ECALL_DESTRUCTOR:\n        {\n            /* Invoke atexit functions in case the host does not invoke\n             * the CALL_AT_EXIT_FUNCTIONS ecall before the DESTRUCTOR ecall\n             * (retaining the previous behavior) */\n            _call_at_exit_functions();\n\n            OE_CHECK(_enclave_destructor());\n\n            break;\n        }\n        case OE_ECALL_VIRTUAL_EXCEPTION_HANDLER:\n        {\n            oe_virtual_exception_dispatcher(td, arg_in, &arg_out);\n            break;\n        }\n        case OE_ECALL_INIT_ENCLAVE:\n        {\n            arg_out = _handle_init_enclave(arg_in);\n            break;\n        }\n        default:\n        {\n            /* No function found with the number */\n            result = OE_NOT_FOUND;\n            goto done;\n        }\n    }\n\ndone:\n\n    /* Free shared memory arena before we clear TLS */\n    if (td->depth == 1)\n    {\n        oe_teardown_arena();\n    }\n\n    /* Remove ECALL context from front of oe_sgx_td_t.ecalls list */\n    td_pop_callsite(td);\n\n    /* Perform ERET, giving control back to host */\n    *output_arg1 = oe_make_call_arg1(OE_CODE_ERET, func, 0, result);\n    *output_arg2 = arg_out;\n}\n\n/*\n**==============================================================================\n**\n** _handle_oret()\n**\n**     Handle an OCALL return.\n**\n**==============================================================================\n*/\n\nOE_INLINE void _handle_oret(\n    oe_sgx_td_t* td,\n    uint16_t func,\n    uint16_t result,\n    uint64_t arg)\n{\n    oe_callsite_t* callsite = td->callsites;\n\n    if (!callsite)\n        return;\n\n    td->oret_func = func;\n    td->oret_result = result;\n    td->oret_arg = arg;\n\n    /* Restore the FXSTATE and flags */\n    asm volatile(\n        \"pushq %[rflags] \\n\\t\" // Restore flags.\n        \"popfq \\n\\t\"\n        \"fldcw %[fcw] \\n\\t\"     // Restore x87 control word\n        \"ldmxcsr %[mxcsr] \\n\\t\" // Restore MXCSR\n        \"lfence \\n\\t\" // MXCSR Configuration Dependent Timing (MCDT) mitigation\n        : [mxcsr] \"=m\"(callsite->mxcsr),\n          [fcw] \"=m\"(callsite->fcw),\n          [rflags] \"=m\"(callsite->rflags)\n        :\n        : \"cc\");\n\n    oe_longjmp(&callsite->jmpbuf, 1);\n}\n\n/*\n**==============================================================================\n**\n** oe_get_enclave_status()\n**\n**     Return the value of __oe_enclave_status to external code.\n**\n**==============================================================================\n*/\noe_result_t oe_get_enclave_status()\n{\n    return __oe_enclave_status;\n}\n\n/*\n**==============================================================================\n**\n** _exit_enclave()\n**\n** Exit the enclave.\n** Additionally, if a debug enclave, write the exit frame information to host's\n** ecall_context so that the host can stitch the ocall stack.\n**\n** This function is intended to be called by oe_asm_exit (see below).\n** When called, the call stack would look like this:\n**\n**     enclave-function\n**       -> oe_ocall\n**         -> oe_exit_enclave (aliased as __morestack)\n**           -> _exit_enclave\n**\n** For debug enclaves, _exit_enclave reads its caller (oe_exit_enclave/\n** __morestack) information (return address, rbp) and passes it along to the\n** host in the ecall_context.\n**\n** Then it proceeds to exit the enclave by invoking oe_asm_exit.\n** oe_asm_exit invokes eexit instruction which resumes execution in host at the\n** oe_enter function. The host dispatches the ocall via the following sequence:\n**\n**     oe_enter\n**       -> __oe_host_stack_bridge   (Stitches the ocall stack)\n**         -> __oe_dispatch_ocall\n**           -> invoke ocall function\n**\n** Now that the enclave exit frame is available to the host,\n** __oe_host_stack_bridge temporarily modifies its caller info with the\n** enclave's exit information so that the stitched stack looks like this:\n**\n**     enclave-function                                    |\n**       -> oe_ocall                                       |\n**         -> oe_exit_enclave (aliased as __morestack)     | in enclave\n**   --------------------------------------------------------------------------\n**           -> __oe_host_stack_bridge                     | in host\n**             -> __oe_dispatch_ocall                      |\n**               -> invoke ocall function                  |\n**\n** This stitching of the stack is temporary, and __oe_host_stack_bridge reverts\n** it prior to returning to its caller.\n**\n** Since the stitched (split) stack is preceded by the __morestack function, gdb\n** natively walks the stack correctly.\n**\n**==============================================================================\n*/\nOE_NEVER_INLINE\nOE_NO_RETURN\nstatic void _exit_enclave(uint64_t arg1, uint64_t arg2)\n{\n    oe_sgx_td_t* td = oe_sgx_get_td();\n\n    if (oe_is_enclave_debug_allowed())\n    {\n        oe_ecall_context_t* host_ecall_context = td->host_ecall_context;\n\n        // Make sure the context is valid.\n        if (host_ecall_context &&\n            oe_is_outside_enclave(\n                host_ecall_context, sizeof(*host_ecall_context)))\n        {\n            uint64_t* frame = (uint64_t*)__builtin_frame_address(0);\n\n            /* NOTE: host memory writes that is only for debugging purposes,\n             * no need for using write with barrier */\n            host_ecall_context->debug_eexit_rbp = frame[0];\n            // The caller's RSP is always given by this equation\n            //   RBP + 8 (caller frame pointer) + 8 (caller return address)\n            host_ecall_context->debug_eexit_rsp = frame[0] + 8;\n            host_ecall_context->debug_eexit_rip = frame[1];\n        }\n    }\n    oe_asm_exit(arg1, arg2, td, 0 /* direct_return */);\n}\n\n/*\n**==============================================================================\n**\n** This function is wrapper of oe_asm_exit. It is needed to stitch the host\n** stack and enclave stack together. It calls oe_asm_exit via an intermediary\n** (_exit_enclave) that records the exit frame for ocall stack stitching.\n**\n** N.B: Don't change the function name, otherwise debugger can't work. GDB\n** depends on this hardcoded function name when does stack walking for split\n** stack. oe_exit_enclave has been #defined as __morestack.\n**==============================================================================\n*/\n\nOE_NEVER_INLINE\nvoid oe_exit_enclave(uint64_t arg1, uint64_t arg2)\n{\n    _exit_enclave(arg1, arg2);\n\n    // This code is never reached. It exists to prevent tail call optimization\n    // of the call to _exit_enclave. Tail-call optimization would effectively\n    // inline _exit_enclave, and its caller would be come the caller of\n    // oe_exit_enclave instead of oe_exit_enclave.\n    oe_abort();\n}\n\n/*\n**==============================================================================\n**\n** oe_ocall()\n**\n**     Initiate a call into the host (exiting the enclave).\n**\n** Remark: Given that the logging implementation relies on making an ocall to\n** host, any failures when handling oe_ocall should not invoke any oe_log\n** functions so as to avoid infinite recursion. OE_RAISE and OE_CHECK macros\n** call oe_log functions, and therefore the following code locations use\n** OE_RAISE_NO_TRACE and OE_CHECK_NO_TRACE macros.\n**==============================================================================\n*/\n\noe_result_t oe_ocall(uint16_t func, uint64_t arg_in, uint64_t* arg_out)\n{\n    oe_result_t result = OE_UNEXPECTED;\n    oe_sgx_td_t* td = oe_sgx_get_td();\n    oe_callsite_t* callsite = td->callsites;\n\n    /* If the enclave is in crashing/crashed status, new OCALL should fail\n    immediately. */\n    if (__oe_enclave_status != OE_OK)\n        OE_RAISE_NO_TRACE((oe_result_t)__oe_enclave_status);\n\n    /* Check for unexpected failures */\n    if (!callsite)\n        OE_RAISE_NO_TRACE(OE_UNEXPECTED);\n\n    /* Check for unexpected failures */\n    if (!td_initialized(td))\n        OE_RAISE_NO_TRACE(OE_FAILURE);\n\n    /* Preserve the FXSTATE and flags */\n    asm volatile(\"stmxcsr %[mxcsr] \\n\\t\" // Save MXCSR\n                 \"fstcw %[fcw] \\n\\t\"     // Save x87 control word\n                 \"pushfq \\n\\t\"           // Save flags.\n                 \"popq %[rflags] \\n\\t\"\n                 :\n                 : [mxcsr] \"m\"(callsite->mxcsr),\n                   [fcw] \"m\"(callsite->fcw),\n                   [rflags] \"m\"(callsite->rflags)\n                 :);\n\n    /* Save call site where execution will resume after OCALL */\n    if (oe_setjmp(&callsite->jmpbuf) == 0)\n    {\n        /* Exit, giving control back to the host so it can handle OCALL */\n        _handle_exit(OE_CODE_OCALL, func, arg_in);\n\n        /* Unreachable! Host will transfer control back to oe_enter() */\n        oe_abort();\n    }\n    else\n    {\n        /* ORET here */\n\n        OE_CHECK_NO_TRACE(result = (oe_result_t)td->oret_result);\n\n        if (arg_out)\n            *arg_out = td->oret_arg;\n\n        if (td->state != OE_TD_STATE_SECOND_LEVEL_EXCEPTION_HANDLING)\n        {\n            /* State machine check */\n            if (td->state != OE_TD_STATE_ENTERED)\n                oe_abort();\n\n            td->state = OE_TD_STATE_RUNNING;\n        }\n    }\n\n    result = OE_OK;\n\ndone:\n    return result;\n}\n\n/*\n**==============================================================================\n**\n** oe_call_host_function_by_table_id()\n**\n**==============================================================================\n*/\n\noe_result_t oe_call_host_function_internal(\n    uint64_t function_id,\n    const void* input_buffer,\n    size_t input_buffer_size,\n    void* output_buffer,\n    size_t output_buffer_size,\n    size_t* output_bytes_written,\n    bool switchless)\n{\n    oe_result_t result = OE_UNEXPECTED;\n    oe_call_host_function_args_t args, *args_host_ptr = NULL;\n    oe_call_function_return_args_t return_args, *return_args_host_ptr = NULL;\n    uint64_t host_result = 0;\n\n    /* Ensure input buffer is outside the enclave memory and its size is valid\n     */\n    if (!oe_is_outside_enclave(input_buffer, input_buffer_size) ||\n        input_buffer_size < sizeof(oe_call_function_return_args_t))\n        OE_RAISE(OE_INVALID_PARAMETER);\n\n    /* Ensure output buffer is outside the enclave memory and its size is\n     * valid. Also, check its address is 8-byte aligned (against the xAPIC\n     * vulnerability) */\n    if (!oe_is_outside_enclave(output_buffer, output_buffer_size) ||\n        output_buffer_size < sizeof(oe_call_function_return_args_t) ||\n        ((uint64_t)output_buffer % 8) != 0)\n        OE_RAISE(OE_INVALID_PARAMETER);\n\n    /*\n     * oe_post_switchless_ocall (below) can make a regular ocall to wake up the\n     * host worker thread, and will end up using the ecall context's args.\n     * Therefore, for switchless calls, allocate args in the arena so that it is\n     * is not overwritten by oe_post_switchless_ocall.\n     */\n    args_host_ptr =\n        (oe_call_host_function_args_t*)(switchless ? oe_arena_malloc(sizeof(*args_host_ptr)) : oe_ecall_context_get_ocall_args());\n\n    /* Ensure the args_host_ptr is valid and 8-byte aligned (for xAPIC\n     * vulnerability mitigation) */\n    if (!oe_is_outside_enclave(\n            (const void*)args_host_ptr, sizeof(oe_call_host_function_args_t)) ||\n        ((uint64_t)args_host_ptr % 8) != 0)\n    {\n        /* Fail if the enclave is crashing. */\n        OE_CHECK(__oe_enclave_status);\n        OE_RAISE(OE_UNEXPECTED);\n    }\n\n    /* Prepare a local copy of args */\n    args.function_id = function_id;\n    args.input_buffer = input_buffer;\n    args.input_buffer_size = input_buffer_size;\n    args.output_buffer = output_buffer;\n    args.output_buffer_size = output_buffer_size;\n    args.result = OE_UNEXPECTED;\n\n    /* Copy the local copy of args to host memory */\n    OE_CHECK(oe_memcpy_s_with_barrier(\n        args_host_ptr, sizeof(*args_host_ptr), &args, sizeof(args)));\n\n    /* Call the host function with this address */\n    if (switchless && oe_is_switchless_initialized())\n    {\n        oe_result_t post_result = oe_post_switchless_ocall(args_host_ptr);\n\n        // Fall back to regular OCALL if host worker threads are unavailable\n        if (post_result == OE_CONTEXT_SWITCHLESS_OCALL_MISSED)\n            OE_CHECK(oe_ocall(\n                OE_OCALL_CALL_HOST_FUNCTION, (uint64_t)args_host_ptr, NULL));\n        else\n        {\n            OE_CHECK(post_result);\n            // Wait until args.result is set by the host worker.\n            while (true)\n            {\n                OE_ATOMIC_MEMORY_BARRIER_ACQUIRE();\n\n                /* The member result is alignend given that args_host_ptr is\n                 * aligned and its size is 8-byte (for xAPIC vulnerability\n                 * mitigation). */\n                if (__atomic_load_n(&args_host_ptr->result, __ATOMIC_SEQ_CST) !=\n                    OE_UINT64_MAX)\n                    break;\n\n                /* Yield to CPU */\n                asm volatile(\"pause\");\n            }\n        }\n    }\n    else\n    {\n        OE_CHECK(oe_ocall(\n            OE_OCALL_CALL_HOST_FUNCTION, (uint64_t)args_host_ptr, NULL));\n    }\n\n    /* Copy the result from the host memory\n     * The member result is aligned given that args_host_ptr is aligned\n     * and its size is 8 byte (for xAPIC vulnerability mitigation). */\n    host_result = args_host_ptr->result;\n\n    /* Check the result */\n    OE_CHECK((oe_result_t)host_result);\n\n    return_args_host_ptr = (oe_call_function_return_args_t*)output_buffer;\n\n    /* Copy the marshaling struct from the host memory to avoid TOCTOU issues.\n     * To mitigate the xAPIC vulnerability, the output_buffer and the size of\n     * oe_call_function_return_args_t must be aligned at this point via runtime\n     * and compile-time checks, repsectively. */\n    oe_memcpy_aligned(\n        &return_args,\n        return_args_host_ptr,\n        sizeof(oe_call_function_return_args_t));\n\n    if (return_args.result == OE_OK)\n    {\n        /*\n         * Error out the case if the deepcopy_out_buffer is NULL but the\n         * deepcopy_out_buffer_size is not zero or if the deepcopy_out_buffer is\n         * not NULL but the deepcopy_out_buffer_size is zero. Note that this\n         * should only occur if the oeedger8r was not used or if\n         * oeedger8r-generated routine is modified.\n         */\n        if ((!return_args.deepcopy_out_buffer &&\n             return_args.deepcopy_out_buffer_size) ||\n            (return_args.deepcopy_out_buffer &&\n             !return_args.deepcopy_out_buffer_size))\n            OE_RAISE(OE_UNEXPECTED);\n\n        /*\n         * Nonzero deepcopy_out_buffer and deepcopy_out_buffer_size fields\n         * indicate that there is deep-copied content that needs to be\n         * transmitted from the host.\n         */\n        if (return_args.deepcopy_out_buffer &&\n            return_args.deepcopy_out_buffer_size)\n        {\n            /*\n             * Ensure that the deepcopy_out_buffer and deepcopy_out_buffer_size\n             * are both 8-byte aligned against the xAPIC vulnerability.\n             */\n            if ((((uint64_t)return_args.deepcopy_out_buffer % 8) != 0) ||\n                (return_args.deepcopy_out_buffer_size % 8) != 0)\n                OE_RAISE(OE_UNEXPECTED);\n\n            /*\n             * Ensure that the content lies in host memory.\n             * Note that this should only fail if oeedger8r was not used or if\n             * the oeedger8r-generated routine is modified.\n             */\n            if (!oe_is_outside_enclave(\n                    return_args.deepcopy_out_buffer,\n                    return_args.deepcopy_out_buffer_size))\n                OE_RAISE(OE_UNEXPECTED);\n\n            void* enclave_buffer =\n                oe_malloc(return_args.deepcopy_out_buffer_size);\n\n            if (!enclave_buffer)\n                OE_RAISE(OE_OUT_OF_MEMORY);\n\n            /* Copy the deep-copied content to enclave memory. */\n            oe_memcpy_aligned(\n                enclave_buffer,\n                return_args.deepcopy_out_buffer,\n                return_args.deepcopy_out_buffer_size);\n\n            /* Release the memory on host heap. */\n            oe_host_free(return_args.deepcopy_out_buffer);\n\n            /*\n             * Update the deepcopy_out_buffer field.\n             * Note that the field is still in host memory. Currently, the\n             * oeedger8r-generated code will perform an additional check that\n             * ensures the buffer stays within the enclave memory.\n             */\n            OE_WRITE_VALUE_WITH_BARRIER(\n                &(return_args_host_ptr->deepcopy_out_buffer), enclave_buffer);\n        }\n    }\n\n    /* The member output_bytes_written is aligned given that args_host_ptr is\n     * aligned (for xAPIC vulnerability mitigation) */\n    *output_bytes_written = args_host_ptr->output_bytes_written;\n    result = OE_OK;\n\ndone:\n    if (result != OE_OK && return_args_host_ptr)\n    {\n        /* Set up the local return_args for the failing case */\n        return_args.result = result;\n        return_args.deepcopy_out_buffer = NULL;\n        return_args.deepcopy_out_buffer_size = 0;\n\n        /* Copy the return_args to host memory */\n        oe_memcpy_s_with_barrier(\n            return_args_host_ptr,\n            sizeof(*return_args_host_ptr),\n            &return_args,\n            sizeof(return_args));\n    }\n\n    return result;\n}\n\n/*\n**==============================================================================\n**\n** oe_call_host_function()\n** This is the preferred way to call host functions.\n**\n**==============================================================================\n*/\n\noe_result_t oe_call_host_function(\n    size_t function_id,\n    const void* input_buffer,\n    size_t input_buffer_size,\n    void* output_buffer,\n    size_t output_buffer_size,\n    size_t* output_bytes_written)\n{\n    return oe_call_host_function_internal(\n        function_id,\n        input_buffer,\n        input_buffer_size,\n        output_buffer,\n        output_buffer_size,\n        output_bytes_written,\n        false /* non-switchless */);\n}\n\n/*\n**==============================================================================\n**\n** _stitch_ecall_stack()\n**\n**     This function fixes up the first enclave frame (passed in) when the\n**     enclave is in debug mode and the ecall_context includes valid\n**     debug_eenter_rbp and debug_eenter_rip (i.e., both of which should\n**     be set and point to host memory). Otherwise, the function is a no-op.\n**     Currently, the stack stitching is required when vDSO is used on Linux.\n**\n**     Backtrace before stitching:\n**\n**     oe_ecall                                    | in host\n**       -> _do_eenter                             |\n**         -> oe_enter (aliased as __morestack)    |\n**           -> oe_vdso_enter                      |\n**             -> __vdso_sgx_enter_enclave         |\n**   --------------------------------------------------------------------------\n**             -> oe_enter                         | in enclave\n**              -> __oe_handle_main                |\n**\n**     Given that __vdso_sgx_enter_enclave is the vDSO function, we cannot rely\n**     on the Linux kernel to preserve its stack frame. Instead, we fix up the\n**     call stack that bypasses oe_vdso_enter and __vdso_sgx_enter_enclave in\n**     the trace, making it align with the trace when vDSO is not used.\n**\n**     Backtrace after stitching:\n**\n**     oe_ecall                                    | in host\n**       -> _do_eenter                             |\n**         -> oe_enter (aliased as __morestack)    |\n**   --------------------------------------------------------------------------\n**         -> oe_enter                             | in enclave\n**           -> __oe_handle_main                   |\n**\n**==============================================================================\n*/\n\nstatic void _stitch_ecall_stack(oe_sgx_td_t* td, uint64_t* first_enclave_frame)\n{\n    oe_ecall_context_t* ecall_context = td->host_ecall_context;\n\n    if (oe_is_enclave_debug_allowed())\n    {\n        if (oe_is_outside_enclave(ecall_context, sizeof(*ecall_context)))\n        {\n            uint64_t host_rbp = ecall_context->debug_eenter_rbp;\n            uint64_t host_rip = ecall_context->debug_eenter_rip;\n\n            /* Check that the supplied host frame (hpst_rbp, host_rip) are set\n             * and really lies outside before stitching the stack */\n            if (oe_is_outside_enclave((void*)host_rbp, sizeof(uint64_t)) &&\n                oe_is_outside_enclave((void*)host_rip, sizeof(uint64_t)))\n            {\n                first_enclave_frame[0] = host_rbp;\n                first_enclave_frame[1] = host_rip;\n            }\n        }\n    }\n}\n\n/*\n**==============================================================================\n**\n** __oe_handle_main()\n**\n**     This function is called by oe_enter(), which is called by the EENTER\n**     instruction (executed by the host). The host passes the following\n**     parameters to EENTER:\n**\n**         RBX - TCS - address of a TCS page in the enclave\n**         RCX - AEP - pointer to host's asynchronous exception procedure\n**         RDI - ARGS1 (holds the CODE and FUNC parameters)\n**         RSI - ARGS2 (holds the pointer to the args structure)\n**\n**     EENTER then calls oe_enter() with the following registers:\n**\n**         RAX - CSSA - index of current SSA\n**         RBX - TCS - address of TCS\n**         RCX - RETADDR - address to jump back to on EEXIT\n**         RDI - ARGS1 (holds the code and func parameters)\n**         RSI - ARGS2 (holds the pointer to the args structure)\n**\n**     Finally oe_enter() calls this function with the following parameters:\n**\n**         ARGS1 (holds the code and func parameters)\n**         ARGS2 (holds the pointer to the args structure)\n**         CSSA - index of current SSA\n**         TCS - address of TCS (thread control structure)\n**\n**     Each enclave contains one or more thread sections (a collection of pages\n**     used by a thread entering the enclave). Each thread section has the\n**     following layout:\n**\n**         +----------------------------+\n**         | Guard Page                 |\n**         +----------------------------+\n**         | Stack pages                |\n**         +----------------------------+\n**         | Guard Page                 |\n**         +----------------------------+\n**         | TCS Page                   |\n**         +----------------------------+\n**         | SSA (State Save Area) 0    |\n**         +----------------------------+\n**         | SSA (State Save Area) 1    |\n**         +----------------------------+\n**         | Guard Page                 |\n**         +----------------------------+\n**         | Thread local storage       |\n**         +----------------------------+\n**         | FS/GS Page (oe_sgx_td_t + tsp)    |\n**         +----------------------------+\n**\n**     EENTER sets the FS segment register to refer to the FS page before\n**     calling this function.\n**\n**     If the enclave should fault, SGX saves the registers in the SSA slot\n**     (given by CSSA) and invokes the host's asynchronous exception handler\n**     (AEP). The handler may terminate or call ERESUME which increments CSSA\n**     and enters this function again. So:\n**\n**         CSSA == 0: indicates a normal entry\n**         CSSA >= 1: indicates an exception entry\n**\n**     Since the enclave builder only allocates two SSA pages, the enclave can\n**     nest no more than two faults. EENTER fails when the number of SSA slots\n**     are exhausted (i.e., TCS.CSSA == TCS.NSSA)\n**\n**     This function ultimately calls EEXIT to exit the enclave. An enclave may\n**     exit to the host for two reasons (aside from an asynchronous exception\n**     already mentioned):\n**\n**         (1) To return normally from an ECALL\n**         (2) To initiate an OCALL\n**\n**     When exiting to perform an OCALL, the host may perform another ECALL,\n**     and so ECALLS and OCALLS may be nested arbitrarily until stack space is\n**     exhausted (hitting a guard page). The state for performing nested calls\n**     is maintained on the stack associated with the TCS (see diagram above).\n**\n**     The enclave's stack pointer is determined as follows:\n**\n**         (*) For non-nested calls, the stack pointer is calculated relative\n**             to the TCS (one page before minus the STATIC stack size).\n**\n**         (*) For nested calls the stack pointer is obtained from the\n**             oe_sgx_td_t.last_sp field (saved by the previous call).\n**\n**==============================================================================\n*/\nvoid __oe_handle_main(\n    uint64_t arg1,\n    uint64_t arg2,\n    uint64_t cssa,\n    void* tcs,\n    uint64_t* output_arg1,\n    uint64_t* output_arg2)\n{\n    oe_code_t code = oe_get_code_from_call_arg1(arg1);\n    uint16_t func = oe_get_func_from_call_arg1(arg1);\n    uint16_t arg1_result = oe_get_result_from_call_arg1(arg1);\n    uint64_t arg_in = arg2;\n    *output_arg1 = 0;\n    *output_arg2 = 0;\n\n    /* Get pointer to the thread data structure */\n    oe_sgx_td_t* td = td_from_tcs(tcs);\n\n    /* Initialize the enclave the first time it is ever entered. Note that\n     * this function DOES NOT call global constructors. Global construction\n     * is performed while handling OE_ECALL_INIT_ENCLAVE. */\n    oe_initialize_enclave(td);\n\n    /* td's host_ecall_context is set in enter.S and this is the first chance we\n       get to validate it. */\n    oe_ecall_context_t* ecall_context = td->host_ecall_context;\n    if (!oe_is_outside_enclave(ecall_context, sizeof(*ecall_context)))\n        td->host_ecall_context = NULL;\n\n    /* Ensure that ecall_context is 8-byte aligned against the xAPIC\n     * vunlerability */\n    if (((uint64_t)ecall_context % 8) != 0)\n        td->host_ecall_context = NULL;\n\n    /* Stitch the stack. Pass the caller's frame for fix up.\n     * Note that before stitching, the caller's frame points\n     * to the host stack right before switiching to the enclave\n     * stack (see .construct_stack_frame in enter.S).\n     * The function is called after oe_initialize_enclave\n     * (relocations have been applied) so that we can safely\n     * access globals that are referenced via GOT. */\n    _stitch_ecall_stack(td, __builtin_frame_address(1));\n\n    // Block enclave enter based on current enclave status.\n    switch (__oe_enclave_status)\n    {\n        case OE_OK:\n        {\n            break;\n        }\n        case OE_ENCLAVE_ABORTING:\n        {\n            // Block any ECALL except first time OE_ECALL_DESTRUCTOR call.\n            // Don't block ORET here.\n            if (code == OE_CODE_ECALL)\n            {\n                if (func == OE_ECALL_DESTRUCTOR)\n                {\n                    // Termination function should be only called once.\n                    __oe_enclave_status = OE_ENCLAVE_ABORTED;\n                }\n                else\n                {\n                    // Return crashing status.\n                    *output_arg1 =\n                        oe_make_call_arg1(OE_CODE_ERET, func, 0, OE_OK);\n                    *output_arg2 = __oe_enclave_status;\n                    return;\n                }\n            }\n\n            break;\n        }\n        default:\n        {\n            // Return crashed status.\n            *output_arg1 = oe_make_call_arg1(OE_CODE_ERET, func, 0, OE_OK);\n            *output_arg2 = OE_ENCLAVE_ABORTED;\n            return;\n        }\n    }\n\n    /* If this is a normal (non-exception) entry */\n    if (cssa == 0)\n    {\n        switch (code)\n        {\n            case OE_CODE_ECALL:\n            {\n                /* The invocation of the virtual exception handler is not\n                 * allowed when cssa=0. */\n                if (func == OE_ECALL_VIRTUAL_EXCEPTION_HANDLER)\n                    oe_abort_with_td(td);\n\n                /* State machine check */\n                if (td->state != OE_TD_STATE_ENTERED)\n                    oe_abort_with_td(td);\n\n                /* At this point, we are ready to execute the ecall.\n                 * Update the state to RUNNING */\n                td->state = OE_TD_STATE_RUNNING;\n\n                _handle_ecall(td, func, arg_in, output_arg1, output_arg2);\n                break;\n            }\n            case OE_CODE_ORET:\n                /* Eventually calls oe_exit_enclave() and never returns here if\n                 * successful */\n                _handle_oret(td, func, arg1_result, arg_in);\n                // fallthrough\n\n            default:\n                /* Unexpected case */\n                oe_abort_with_td(td);\n        }\n    }\n    else if (cssa == 1)\n    {\n        /* cssa == 1 indicates the entry after an AEX. We only allow the\n         * invocation of the virtual exception handler in this case. */\n        if ((code == OE_CODE_ECALL) &&\n            (func == OE_ECALL_VIRTUAL_EXCEPTION_HANDLER))\n        {\n            _handle_ecall(td, func, arg_in, output_arg1, output_arg2);\n            return;\n        }\n\n        /* Unexpected case */\n        oe_abort_with_td(td);\n    }\n    else /* cssa > 1 */\n    {\n        /* Currently OE only supports an enclave with nssa = 2, which means\n         * that cssa can never exceed 1 (indicating nested AEX). */\n        oe_abort_with_td(td);\n    }\n}\n\n/* Abort the enclave execution with valid td. This function is only directly\n * invoked by __oe_handle_main and init.c where the td may not be initialized\n * yet (i.e., before the td_init() is called in the very first\n * oe_handle_ecall()). For the other scenarios, this function is wrapped by\n * oe_abort where we can safely get td with oe_sgx_get_td_no_check(). */\nvoid oe_abort_with_td(oe_sgx_td_t* td)\n{\n    uint64_t arg1 = oe_make_call_arg1(OE_CODE_ERET, 0, 0, OE_OK);\n\n    /* Abort can be called with user-modified FS (e.g., FS check fails in\n     * oe_sgx_get_td()). */\n    if (oe_is_enclave_debug_allowed())\n    {\n        oe_ecall_context_t* host_ecall_context = td->host_ecall_context;\n\n        // Make sure the context is valid.\n        if (host_ecall_context &&\n            oe_is_outside_enclave(\n                host_ecall_context, sizeof(*host_ecall_context)))\n        {\n            uint64_t* frame = (uint64_t*)__builtin_frame_address(0);\n\n            /* NOTE: host memory writes that is only for debugging purposes,\n             * no need for using write with barrier */\n            host_ecall_context->debug_eexit_rbp = frame[0];\n            // The caller's RSP is always given by this equation\n            //   RBP + 8 (caller frame pointer) + 8 (caller return address)\n            host_ecall_context->debug_eexit_rsp = frame[0] + 8;\n            host_ecall_context->debug_eexit_rip = frame[1];\n        }\n\n        // For debug enclaves, log the backtrace before marking the enclave as\n        // aborted.\n        {\n            // Fetch current values of FS and GS. Typically, FS[0] == FS and\n            // GS[0] == GS.\n            uint64_t fs;\n            uint64_t gs;\n            asm volatile(\"mov %%fs:0, %0\" : \"=r\"(fs));\n            asm volatile(\"mov %%gs:0, %0\" : \"=r\"(gs));\n\n            // We can make ocalls only if td has been initialized which is true\n            // only when the self-pointer has been setup.\n            if (gs == (uint64_t)td)\n            {\n                // Restore FS if FS has been modified.\n                if (fs != gs)\n                {\n                    // wrfsbase could trigger an exception. The enclave may not\n                    // be in a state to emulate the instruction. Therefore, just\n                    // restore FS[0].\n                    asm volatile(\"mov %0, %%fs:0\" : : \"r\"(gs) : \"memory\");\n                }\n\n                void* buffer[OE_BACKTRACE_MAX];\n                int size;\n                oe_result_t r = OE_UNEXPECTED;\n                if ((size = oe_backtrace(buffer, OE_BACKTRACE_MAX)) > 0)\n                {\n                    oe_sgx_log_backtrace_ocall(\n                        &r,\n                        oe_get_enclave(),\n                        OE_LOG_LEVEL_ERROR,\n                        (uint64_t*)buffer,\n                        (size_t)size);\n                }\n                else\n                {\n                    // It is not possible to convey much information at this\n                    // point.\n                }\n\n                // Rever FS if it was restored above.\n                if (fs != gs)\n                    asm volatile(\"mov %0, %%fs:0\" : : \"r\"(fs) : \"memory\");\n            }\n        }\n    }\n\n    td->state = OE_TD_STATE_ABORTED;\n\n    // Once it starts to crash, the state can only transit forward, not\n    // backward.\n    if (__oe_enclave_status < OE_ENCLAVE_ABORTING)\n    {\n        __oe_enclave_status = OE_ENCLAVE_ABORTING;\n    }\n\n    // Return to the latest ECALL.\n    oe_asm_exit(arg1, __oe_enclave_status, td, 1 /* direct_return */);\n}\n\nvoid oe_abort(void)\n{\n    /* Bypass the FS check given that the oe_abort can be invoked anywhere */\n    oe_sgx_td_t* td = oe_sgx_get_td_no_fs_check();\n\n    /* It is unlikely that td is invalid. If this is the case, we cannot\n     * call _abort to exit the enclave. Instead, we intentionally trigger\n     * the page fault by writing to the code page to exit the enclave.\n     * Note that the subsequent execution may hang in case that state machine\n     * check fails in oe_enter, which will block the call to the\n     * __oe_handle_main(). If the execution reaches __oe_handle_main(), we can\n     * safely abort with valid td via the check against __oe_enclave_status. */\n    if (!td)\n    {\n        uint64_t oe_abort_address = (uint64_t)oe_abort;\n\n        __oe_enclave_status = OE_ENCLAVE_ABORTING;\n\n        asm volatile(\"mov $1, %0\" : \"=r\"(*(uint64_t*)oe_abort_address));\n    }\n\n    oe_abort_with_td(td);\n}\n", "// Copyright (c) Open Enclave SDK contributors.\n// Licensed under the MIT License.\n\n#include <openenclave/internal/constants_x64.h>\n\n//==============================================================================\n//\n// void oe_snap_current_context(OE_CONTEXT * oe_context)\n//\n// Routine Description:\n//\n// This function captures the context of the caller. All register values except\n// the rip are exactly same as the values before this function call instruction\n// is executed. The rip in the output context is set to the return address of\n// this function.\n//\n// Arguments:\n//     oe_context(rdi): The output context.\n//\n// Return value:\n//     None.\n//==============================================================================\n\n.globl oe_snap_current_context\n.type oe_snap_current_context, @function\noe_snap_current_context:\n.cfi_startproc\n    // Save the flags.\n    pushfq\n    popq OE_CONTEXT_FLAGS(%rdi)\n\n    // Get general registers.\n    // Save rax, rbx, rcx, rdx.\n    movq    %rax, OE_CONTEXT_RAX(%rdi)\n    movq    %rbx, OE_CONTEXT_RBX(%rdi)\n    movq    %rcx, OE_CONTEXT_RCX(%rdi)\n    movq    %rdx, OE_CONTEXT_RDX(%rdi)\n\n    // Save rbp and rsp.\n    movq    %rbp, OE_CONTEXT_RBP(%rdi)\n    movq    %rsp, %rax\n    addq    $0x10, %rax\n    movq    %rax, OE_CONTEXT_RSP(%rdi)\n\n    // Save rsi and rdi.\n    movq    %rdi, OE_CONTEXT_RDI(%rdi)\n    movq    %rsi, OE_CONTEXT_RSI(%rdi)\n\n    // Save r8, r9 ... r15.\n    movq    %r8, OE_CONTEXT_R8(%rdi)\n    movq    %r9, OE_CONTEXT_R9(%rdi)\n    movq    %r10, OE_CONTEXT_R10(%rdi)\n    movq    %r11, OE_CONTEXT_R11(%rdi)\n    movq    %r12, OE_CONTEXT_R12(%rdi)\n    movq    %r13, OE_CONTEXT_R13(%rdi)\n    movq    %r14, OE_CONTEXT_R14(%rdi)\n    movq    %r15, OE_CONTEXT_R15(%rdi)\n\n    // Save rip.\n    movq    %rsp, %rax\n    addq    $0x8, %rax\n    movq    (%rax), %rbx\n    movq    %rbx, OE_CONTEXT_RIP(%rdi)\n\n    // Save SSE control flags.\n    // This is redundant given fxsave, but is done to expose the mxcsr\n    // value in the oe_context_t as part of the oe_exception_record_t.\n    stmxcsr OE_CONTEXT_MXCSR(%rdi)\n\n    // Save x87 and SSE values.\n    fxsave  OE_CONTEXT_FLOAT(%rdi)\n\n\n    // Return\n    retq\n.cfi_endproc\n\n//==============================================================================\n//\n// void oe_continue_execution(OE_CONTEXT * oe_context)\n//\n// Routine Description:\n//\n//   This function restores the full oe_context, and continue run on the rip of\n//   input context.\n//\n// Arguments:\n//\n//    oe_context (rdi) - Supplies a pointer to a context record.\n//\n// Return Value:\n//\n//    None. This function will not return to caller.\n//\n//==============================================================================\n\n.globl oe_continue_execution\n.type oe_continue_execution, @function\noe_continue_execution:\n.cfi_startproc\n    // Restore the x87 and SSE values.\n    fxrstor OE_CONTEXT_FLOAT(%rdi)\n\n    // Restore SSE control flags.\n    // This is redundant given fxrstor, but included here for parity with\n    // oe_snap_current_context.\n    ldmxcsr OE_CONTEXT_MXCSR(%rdi)\n\n    // For MXCSR Configuration Dependent Timing (MCDT) mitigation\n    lfence\n\n    // Restore general registers.\n    // Restore rax, rbx, rcx, rdx.\n    movq    OE_CONTEXT_RAX(%rdi), %rax\n    movq    OE_CONTEXT_RBX(%rdi), %rbx\n    movq    OE_CONTEXT_RCX(%rdi), %rcx\n    movq    OE_CONTEXT_RDX(%rdi), %rdx\n\n    // Restore rsi.\n    movq    OE_CONTEXT_RSI(%rdi), %rsi\n\n    // Restore r8, r9 ... r15.\n    movq    OE_CONTEXT_R8(%rdi), %r8\n    movq    OE_CONTEXT_R9(%rdi), %r9\n    movq    OE_CONTEXT_R10(%rdi), %r10\n    movq    OE_CONTEXT_R11(%rdi), %r11\n    movq    OE_CONTEXT_R12(%rdi), %r12\n    movq    OE_CONTEXT_R13(%rdi), %r13\n    movq    OE_CONTEXT_R14(%rdi), %r14\n    movq    OE_CONTEXT_R15(%rdi), %r15\n\n    // Restore rbp, rsp\n    movq    OE_CONTEXT_RBP(%rdi), %rbp\n    movq    OE_CONTEXT_RSP(%rdi), %rsp\n\n    // Put local variables under the red zone.\n    sub     $ABI_REDZONE_BYTE_SIZE, %rsp\n\n    // Push the target address to stack.\n    pushq   OE_CONTEXT_RIP(%rdi)\n\n    // Restore the saved flags.\n    pushq   OE_CONTEXT_FLAGS(%rdi)\n    popfq\n\n    // Restore rdi.\n    movq    OE_CONTEXT_RDI(%rdi), %rdi\n\n    // LVI mitigation strategy:\n    // Since no register is free, we cannot load the target into a register and\n    // then issue an lfence. Instead, we use retq (return) instruction to carry\n    // out a jump. The return address is at 0(RSP). RSP is ABI_REDZONE_BYTE_SIZE\n    // + 8 bytes below the correct RSP which was fetched from the context.\n    // We issue a\n    //     retq $ABI_REDZONE_BYTE_SIZE\n    // This has the following effect:\n    //     - The return address is popped and control is transferred to\n    //       the target address.\n    //     - Additionally, ABI_REDZONE_BYTE_SIZE is subtracted from RSP,\n    //       thereby restoring RSP correctly.\n    //     - Ideally assembler's LVI mitigation would insert lfence as appropriate.\n    //       Since it does not seem to handle retq with an immediate value, the\n    //       LVI mitigation is manually inserted.\n\n    // Manual LVI mitigation since the assember does not handle the retq below.\n    notq (%rsp)\n    notq (%rsp)\n    lfence\n\n    // Jump to the target and restore RSP.\n    retq $ABI_REDZONE_BYTE_SIZE\n.cfi_endproc\n", "// Copyright (c) Open Enclave SDK contributors.\n// Licensed under the MIT License.\n\n#include \"asmdefs.h\"\n#include \"asmcommon.inc\"\n#include \"context.inc\"\n\n//==============================================================================\n//\n// oe_enter(RAX=CSSA, RBX=TCS, RCX=RETADDR, RDI=ARG1, RSI=ARG2)\n//\n//     The EENTER instruction (executed by the host) calls this function to\n//     enter the enclave.\n//\n//     Registers from EENTER:\n//         RAX - index of current SSA (CSSA)\n//         RBX - address of TCS (TCS)\n//         RCX - address of instruction following EENTER (RETADDR)\n//\n//     Registers from host caller of EENTER:\n//         RDI - ARG1\n//         RSI - ARG2\n//         RDX - HOST ECALL CONTEXT\n//\n//     This function performs the following tasks:\n//\n//         (1) Saves the host registers\n//         (2) Calculates the enclave stack base\n//         (3) Sets up the enclave stack frame\n//         (4) Calls __oe_handle_main()\n//\n//     Note: __oe_handle_main does not return. Instead it eventually\n//     calls oe_asm_exit (see exit.S)\n//\n//==============================================================================\n\n.globl oe_enter\n.type oe_enter, @function\noe_enter:\n.cfi_startproc\n\n.get_td:\n\n    // Get the location of the td_t structure for this thread. This value is\n    // expected to be present in %r11 for the remainder of oe_enter.\n    //\n    // Upon first entry to the enclave, td->base.self in the td_t structure\n    // is not yet initialized. However, the loader in host/sgx/create.c places\n    // the td_t structure as a specific offset from TCS.\n    mov _td_from_tcs_offset(%rip), %r11\n    add %rbx, %r11\n\n.check_aborted:\n    cmpq $TD_STATE_ABORTED, td_state(%r11)\n    je .abort\n\n    // Get the first ssa address from tcs\n    lea OE_SSA_FROM_TCS_BYTE_OFFSET(%rbx), %r10\n\n.save_host_registers:\n    // Backup the current ecall context to previous\n    mov td_host_ecall_context(%r11), %r8\n    mov %r8, td_host_previous_ecall_context(%r11)\n\n    // Save host registers (restored on EEXIT)\n    mov %rax, td_eenter_rax(%r11) // cssa set by EENTER\n    mov %rcx, td_host_rcx(%r11) // host return address here\n    mov %rdx, td_host_ecall_context(%r11)\n\n.determine_entry_type:\n    // Check if this is exception dispatching request\n    // Return on the eenter if cssa greater than one, which\n    // should not occur because OE assumes the enclave with nssa=2\n    cmp $1, %rax\n    je .exception_entry\n    ja .return\n\n    // Stop speculative execution at fallthrough of conditional\n    // exception-dispatching-request-check.\n    lfence\n\n.update_td_state_on_normal_entry:\n    // Do not update the state if the enclave enters in the middle\n    // the exception handling (e.g., making an ocall)\n    cmpq $TD_STATE_SECOND_LEVEL_EXCEPTION_HANDLING, td_state(%r11)\n    je .check_entry_nesting_level\n\n    // Update state and clear previous state on normal entries\n    movq $TD_STATE_NULL, td_previous_state(%r11)\n    movq $TD_STATE_ENTERED, td_state(%r11)\n\n.check_entry_nesting_level:\n    lfence\n    // Check whether this is a clean entry or a nested entry\n    // clean-entry-check.\n    mov td_depth(%r11), %r8\n    cmp $0, %r8\n    je .clean_entry\n    jmp .nested_entry\n\n.exception_entry:\n    // Stop speculative execution at target of conditional jump\n    // after exception-dispatching-request-check.\n    lfence\n\n    // Abort if SSA[0].GPRSGX.RSP equals to SSA[0].GPRSGX.URSP\n    mov SGX_SSA_RSP_OFFSET(%r10), %r8\n    mov SGX_SSA_URSP_OFFSET(%r10), %r9\n    cmp %r8, %r9\n    je .return\n\n    // Calculate the base address of the enclave\n    lea _enclave_rva(%rip), %r12\n    mov (%r12), %r13\n    sub %r13, %r12\n\n    // Calculate the end of the enclave address (base + enclave_size)\n    lea oe_enclave_properties_sgx(%rip), %r13\n    mov OE_SGX_ENCLAVE_SIZE_OFFSET(%r13), %r13\n    add %r12, %r13\n\n    // Abort if SSA[0].GPRSGX.URSP is within the enclave memory range\n    cmp %r12, %r9\n    jb .exception_handler_stack_check\n    cmp %r13, %r9\n    jae .exception_handler_stack_check\n    jmp .return\n\n    // Reaching this point implies SSA[0].GPRSGX.RSP is within the enclave\n    // memory range so we do not need additional checks.\n\n.exception_handler_stack_check:\n    // Stop speculative execution at target of conditional jump\n    lfence\n\n    // Get the exception_handler_stack_check range\n    mov td_exception_handler_stack(%r11), %r14\n    mov td_exception_handler_stack_size(%r11), %r15\n    test %r15, %r15\n    jz .exception_stack_setup // check if size is zero\n    add %r14, %r15\n    jc .exception_stack_setup // check for overflow\n\n    // Check if the stack range is within the enclave memory range\n    // If the check fails, fallback to the default behavior (i.e.,\n    // re-using the stack pointer saved in the SSA)\n    cmp %r12, %r14\n    jb .exception_stack_setup\n    cmp %r13, %r15\n    ja .exception_stack_setup\n\n    // Check passes, use the exception handler stack\n    mov %r15, %r8\n\n    // Align the stack\n    and $-16, %r8\n\n    // Proceed without the red zone\n    jmp .state_machine_check\n\n.exception_stack_setup:\n    // Stop speculative execution at target of conditional jump\n    lfence\n\n    // Align the stack\n    and $-16, %r8\n\n    // Start the new stack under the red zone\n    sub $ABI_REDZONE_BYTE_SIZE, %r8\n\n.state_machine_check:\n    cmpq $0, td_exception_nesting_level(%r11)\n    jne .state_machine_check_nested_exception\n\n.state_machine_check_non_nested_exception:\n    // Expect the state to be RUNNING on a non-nested exception\n    // entry\n    cmpq $TD_STATE_RUNNING, td_state(%r11)\n    jne .return\n    jmp .check_host_signal_request\n\n.state_machine_check_nested_exception:\n    lfence\n    // Expect the state to be SECOND_LEVEL_EXCEPTION_HANDLING\n    // on a nested exception entry\n    cmpq $TD_STATE_SECOND_LEVEL_EXCEPTION_HANDLING, td_state(%r11)\n    jne .return\n\n.check_host_signal_request:\n    movq td_state(%r11), %r12\n\n    // Input value falls in the range of [1, 64] indicates\n    // a host signal request\n    cmp $0, %rsi\n    je .update_td_state\n    cmp $MAX_SIGNAL_NUMBER, %rsi\n    ja .update_td_state\n\n    // Proceed if the host_signal_unmasked flag is set\n    cmpq $1, td_host_signal_unmasked(%r11)\n    jne .return\n\n    // Proceed if the corresponding bit of the signal\n    // (i.e., signal number - 1) is set in the bitmask\n    mov td_host_signal_bitmask(%r11), %r13\n    mov %rsi, %r14\n    dec %r14\n    bt %r14, %r13\n    jnc .return\n\n    // Proceed only if the state is RUNNING\n    cmp $TD_STATE_RUNNING, %r12\n    jne .return\n\n    // Proceed if the thread is currently not handling a host signal\n    cmpq $1, td_is_handling_host_signal(%r11)\n    je .return\n\n    // Proceed if the exception entry is not nested\n    cmpq $0, td_exception_nesting_level(%r11)\n    jne .return\n\n    lfence\n\n    // Set the flag if the request is accepted\n    movq $1, td_is_handling_host_signal(%r11)\n\n    // Store the host-passed signal number\n    mov %rsi, td_host_signal(%r11)\n\n.update_td_state:\n    lfence\n\n    // Keep the state before the exception so that we can restore the\n    // state in the illegal instruction emulation flow\n    mov %r12, td_previous_state(%r11)\n    movq $TD_STATE_FIRST_LEVEL_EXCEPTION_HANDLING, td_state(%r11)\n\n    // Increase the nesting level, which will be decreased before resuming\n    // the execution (see exception.c)\n    incq td_exception_nesting_level(%r11)\n    jmp .call_function\n\n.nested_entry:\n    // Stop speculative execution at fallthrough of conditional\n    // clean-entry-check.\n    lfence\n\n    // Restore stack pointer and enclave registers:\n    mov td_last_sp(%r11), %r8\n\n    // align the stack\n    and $-16, %r8\n\n    // Start the new stack under the red zone.\n    sub $ABI_REDZONE_BYTE_SIZE, %r8\n    jmp .call_function\n\n.clean_entry:\n    // Stop speculative execution at target of conditional jump\n    // after clean-entry-check.\n    lfence\n\n    // Calculate stack base relative to TCS (subtract guard page size)\n    mov %rbx, %r8\n    sub $PAGE_SIZE, %r8\n\n.call_function:\n    // Stop speculative execution for the fallthrough cases\n    lfence\n\n    // Set the rsp to the in-enclave stack\n    mov %r8, %rsp\n\n    cmp $1, %rax\n    je .locate_next_ssa\n    jmp .construct_stack_frame\n\n.locate_next_ssa:\n    // Stop speculative execution at fallthrough of conditional\n    // rax (cssa) check.\n    lfence\n\n    add $PAGE_SIZE, %r10\n\n.construct_stack_frame:\n    // Get the host stack pointer from SSA\n    mov SGX_SSA_URSP_OFFSET(%r10), %r8\n    mov SGX_SSA_URBP_OFFSET(%r10), %r9\n\n    // Construct the frame and align the stack\n    pushq $0\n    pushq %r8\n    pushq %rcx\n    pushq %r9\n.cfi_def_cfa_offset     16\n.cfi_offset             rbp, -16\n    mov %rsp, %rbp\n.cfi_def_cfa_register   rbp\n\n// 16-byte alignment\n#define OM_STACK_LENGTH             0X20\n#define OM_HOST_OUTPUT_ARG1         (-1*8)(%rbp)\n#define OM_HOST_OUTPUT_ARG2         (-2*8)(%rbp)\n#define OM_ENC_TD                   (-3*8)(%rbp)\n\n    // Allocate stack.\n    sub $OM_STACK_LENGTH, %rsp\n\n    // Save reference to the td structure to enclave stack.\n    mov %r11, OM_ENC_TD\n\n    // Clear the XSTATE so that enclave has clean legacy SSE and extended states\n    xor %r11, %r11\n    oe_cleanup_registers\n\n    // Clear the flags not covered by oe_cleanup_registers (i.e., control and system\n    // flags) that requires using (enclave) stack. Given that these flags are not\n    // affected instructions and persistent throughout the enclave lifetime, we only\n    // clear them once during the enter routine, which prevents poisoning attack from\n    // the host.\n    oe_cleanup_flags_on_enclave_stack\n\n    // Call __oe_handle_main(ARG1=RDI, ARG2=RSI, CSSA=RDX, TCS=RCX, OUTPUTARG1=R8, OUTPUTARG2=R9)\n    mov %rax, %rdx\n    mov %rbx, %rcx\n    lea OM_HOST_OUTPUT_ARG1, %r8\n    lea OM_HOST_OUTPUT_ARG2, %r9\n    call __oe_handle_main\n\n    // Get the output parameters.\n    mov OM_HOST_OUTPUT_ARG1, %rdi\n    mov OM_HOST_OUTPUT_ARG2, %rsi\n\n    // Restore td pointer\n    mov OM_ENC_TD, %rdx\n    // Set the argument aborting=0 for oe_asm_exit\n    xor %rcx, %rcx\n    jmp .eexit\n\n.abort:\n    lfence\n\n    // Set argument 2 for oe_asm_exit\n    mov $CODE_ENCLAVE_ABORTING, %rsi\n\n    // Update the global enclave status\n    mov %rsi, __oe_enclave_status(%rip)\n\n    jmp .prepare_eexit\n\n.return:\n    lfence\n\n    // Set argument 2 for oe_asm_exit\n    mov $CODE_EXCEPTION_CONTINUE_EXECUTION, %rsi\n\n.prepare_eexit:\n#define ARG1_CODE_ERET        0x2 // OE_CODE_ERET in oe_code_t\n#define ARG1_CODE_BIT_OFFSET  0x30 // Refer to oe_make_call_arg1 in calls.h\n\n    // Set argument 1 for oe_asm_exit\n    mov $ARG1_CODE_ERET, %rdi\n    shl $ARG1_CODE_BIT_OFFSET, %rdi\n    mov %r11, %rdx\n    mov $1, %rcx // direct_return=1\n\n.eexit:\n    // Invoke oe_asm_exit with (ARG1=RDI, ARG2=RSI, TD=RDX, ABORTING=RCX)\n    jmp oe_asm_exit\n\n    // Should never reach here because oe_asm_exit does not return\n\n.forever:\n    jmp .forever\n\n.cfi_endproc\n\n.size oe_enter, .-oe_enter\n\n//==============================================================================\n//\n// void oe_exception_dispatcher(void)\n//\n// Routine Description:\n//\n//   This function is used to dispatch an enclave exception.\n//\n//  Arguments:\n//      None.\n//\n//  Return value:\n//      None.\n//==============================================================================\n\n#define SIZEOF_OE_CONTEXT 0X2A0\n#define ED_STACK_LENGTH SIZEOF_OE_CONTEXT + 0x20\n#define ED_OE_CONTEXT        (%rsp)\n#define ED_SAVED_RDI         (0*8)(%rbp)\n#define ED_SAVED_RBP         (1*8)(%rbp)\n#define ED_SAVED_RSP         (2*8)(%rbp)\n\n.globl oe_exception_dispatcher\n.type oe_exception_dispatcher, @function\noe_exception_dispatcher:\n.cfi_startproc\n\n    // Dummy operations to ensure the red zone does not bypass the guard page.\n    // This could happen when setting the exception handler stack but not\n    // registering the stack for #PF. In this case, when the stack overflow\n    // occurs, the first-stage handler will use the exception handler stack and\n    // then continue the execution to this point with the corrupted stack,\n    // pointing to near the end of the guard page.\n    push %rbp\n    pop %rbp\n\n    // Start the new stack under the red zone.\n    sub $ABI_REDZONE_BYTE_SIZE, %rsp\n\n    // Save the registers that will be clobbered before snap context is called.\n    push %rsp\n    push %rbp\n    push %rdi\n    mov %rsp, %rbp\n\n    // align the stack.\n    and $-16, %rsp\n\n    // Allocate stack.\n    sub $ED_STACK_LENGTH, %rsp\n\n    // Recapture the context of exception. The output context is all correct except:\n    // rbp, rsp, rdi, and rip.\n    lea ED_OE_CONTEXT, %rdi\n    call oe_snap_current_context\n\n    // Restore the previous rbp to rbp of OE_CONTEXT.\n    lea ED_OE_CONTEXT, %rdi\n    movq ED_SAVED_RBP, %rax\n    movq %rax, OE_CONTEXT_RBP(%rdi)\n\n    // Restore the previous rsp to rsp of OE_CONTEXT.\n    movq ED_SAVED_RSP, %rax\n    add $ABI_REDZONE_BYTE_SIZE, %rax\n    movq %rax, OE_CONTEXT_RSP(%rdi)\n\n    // Restore the previous rdi to rdi of OE_CONTEXT.\n    movq ED_SAVED_RDI, %rax\n    movq %rax, OE_CONTEXT_RDI(%rdi)\n\n    call oe_real_exception_dispatcher\n\n    // Should never reach here since oe_real_exception_dispatcher will not return.\n\n.forever_loop:\n    jmp .forever_loop\n.cfi_endproc\n\n.size oe_exception_dispatcher, .-oe_exception_dispatcher\n", "// Copyright (c) Open Enclave SDK contributors.\n// Licensed under the MIT License.\n\n#ifndef _OE_ABI_UTILS_H\n#define _OE_ABI_UTILS_H\n\n#include <openenclave/bits/defs.h>\n\nOE_EXTERNC_BEGIN\n// oe_is_avx_enabled is an internal variable setup and used by OE SDK host\n// runtime. It is OK for the abi test to depend on it do selectively perform\n// checks.\nextern bool oe_is_avx_enabled;\nOE_EXTERNC_END\n\n// User-mode settable RFLAGS that are not commonly modified and usually\n// survive function calls: IF:9, NT:14\n#define TEST_RFLAGS 0x4200\n\n// RFLAGS value to clear TEST_RFLAGS: IF:9\n// IF is kernel-managed and usually set, so restore it if changed\n#define INIT_RFLAGS 0x200\n\n// Set FTZ, Truncation RC and DAZ, clear all exception masks\n#define TEST_MXCSR 0xE040\n\n// Default MXCSR value used by OE for MCDT mitigation\n#define INIT_MXCSR 0x1FBF\n\n// Set RC to RNE, PC to SP, clear all exception masks (11 00 01 000000)\n#define TEST_FCW 0xC40\n\n// Initial MXCSR value as defined by Linux/Window ABIs\n#define INIT_FCW 0x37F\n\n// Constant for expected result of enclave_check_abi function\n#define EXPECTED_CHECK_ABI_RETURN_VALUE 42.0\n\ntypedef struct _windows_abi_state\n{\n    uint64_t rsi;\n    uint64_t rdi;\n    uint8_t xmm6[16];\n    uint8_t xmm7[16];\n    uint8_t xmm8[16];\n    uint8_t xmm9[16];\n    uint8_t xmm10[16];\n    uint8_t xmm11[16];\n    uint8_t xmm12[16];\n    uint8_t xmm13[16];\n    uint8_t xmm14[16];\n    uint8_t xmm15[16];\n} windows_abi_state_t;\n\ntypedef struct _abi_state\n{\n    uint64_t rbx;\n    uint64_t rbp;\n    uint64_t rsp;\n    uint64_t r12;\n    uint64_t r13;\n    uint64_t r14;\n    uint64_t r15;\n\n    uint64_t flags;\n    uint32_t mxcsr;\n    uint16_t fcw;\n    uint16_t padding;\n\n    windows_abi_state_t win_abi;\n} abi_state_t;\n\nOE_ALWAYS_INLINE void set_test_xmm_state(void)\n{\n    static const uint8_t test_xmm[16] = {\n        0xBE,\n        0xEF,\n        0xCA,\n        0xFE,\n        0xBE,\n        0xEF,\n        0xCA,\n        0xFE,\n        0xBE,\n        0xEF,\n        0xCA,\n        0xFE,\n        0xBE,\n        0xEF,\n        0xCA,\n        0xFE};\n\n    if (oe_is_avx_enabled)\n        asm(\"vmovdqu %0, %%xmm6;\"\n            \"vmovdqu %0, %%xmm7;\"\n            \"vmovdqu %0, %%xmm8;\"\n            \"vmovdqu %0, %%xmm9;\"\n            \"vmovdqu %0, %%xmm10;\"\n            \"vmovdqu %0, %%xmm11;\"\n            \"vmovdqu %0, %%xmm12;\"\n            \"vmovdqu %0, %%xmm13;\"\n            \"vmovdqu %0, %%xmm14;\"\n            \"vmovdqu %0, %%xmm15;\"\n            :\n            : \"m\"(test_xmm)\n            : \"xmm6\",\n              \"xmm7\",\n              \"xmm8\",\n              \"xmm9\",\n              \"xmm10\",\n              \"xmm11\",\n              \"xmm12\",\n              \"xmm13\",\n              \"xmm14\",\n              \"xmm15\");\n}\n\nOE_ALWAYS_INLINE void set_test_abi_state(void)\n{\n    uint64_t test_flags = TEST_RFLAGS;\n    uint32_t test_mxcsr = TEST_MXCSR;\n    uint16_t test_fcw = TEST_FCW;\n\n    asm(\"pushq %0;\"\n        \"popfq;\"\n        \"ldmxcsr %1;\"\n        \"fldcw %2;\" ::\"m\"(test_flags),\n        \"m\"(test_mxcsr),\n        \"m\"(test_fcw));\n}\n\nOE_ALWAYS_INLINE void reset_test_abi_state(void)\n{\n    uint64_t test_flags = INIT_RFLAGS;\n    uint32_t test_mxcsr = INIT_MXCSR;\n    uint16_t test_fcw = INIT_FCW;\n\n    asm(\"pushq %0;\"\n        \"popfq;\"\n        \"ldmxcsr %1;\"\n        \"fldcw %2;\" ::\"m\"(test_flags),\n        \"m\"(test_mxcsr),\n        \"m\"(test_fcw));\n}\n\nOE_ALWAYS_INLINE void read_abi_state(abi_state_t* state)\n{\n    if (oe_is_avx_enabled)\n        asm(\"movq %%rbx, (%0);\"\n            \"movq %%rbp, 8(%0);\"\n            \"movq %%rsp, 16(%0);\"\n            \"movq %%r12, 24(%0);\"\n            \"movq %%r13, 32(%0);\"\n            \"movq %%r14, 40(%0);\"\n            \"movq %%r15, 48(%0);\"\n            \"pushfq;\"\n            \"popq 56(%0);\"\n            \"stmxcsr 64(%0);\"\n            \"fstcw 68(%0);\"\n            \"movq    %%rsi, (%1);\"\n            \"movq    %%rdi, 8(%1);\"\n            \"vmovdqu %%xmm6, 16(%1);\"\n            \"vmovdqu %%xmm7, 32(%1);\"\n            \"vmovdqu %%xmm8, 48(%1);\"\n            \"vmovdqu %%xmm9, 64(%1);\"\n            \"vmovdqu %%xmm10, 80(%1);\"\n            \"vmovdqu %%xmm11, 96(%1);\"\n            \"vmovdqu %%xmm12, 112(%1);\"\n            \"vmovdqu %%xmm13, 128(%1);\"\n            \"vmovdqu %%xmm14, 144(%1);\"\n            \"vmovdqu %%xmm15, 160(%1);\"\n            :\n            : \"r\"(state), \"r\"(&state->win_abi));\n}\n\nOE_ALWAYS_INLINE bool is_same_abi_state(abi_state_t* a, abi_state_t* b)\n{\n    return (\n        (a->rbx == b->rbx) && (a->rbp == b->rbp) &&\n#ifndef GCC_RELEASE\n        /* On GCC Release builds (Clang or Debug builds work),\n         * the compiler optimization doesn't treat the always inlined\n         * read_abi_state as a boundary and only restores RSP prior to\n         * next function call, so RSP right before and after oe_enter\n         * can have different values. oe_enter itself before and after ENCLU\n         * does preserve the RSP, by manual debugging inspection, so this\n         * is a test limitation. */\n        (a->rsp == b->rsp) &&\n#endif\n        (a->r12 == b->r12) && (a->r13 == b->r13) && (a->r14 == b->r14) &&\n        (a->r15 == b->r15) &&\n\n        /* RFLAGS are generally volatile, only check stable test bits */\n        ((a->flags & TEST_RFLAGS) == (b->flags & TEST_RFLAGS)) &&\n\n        (a->mxcsr == b->mxcsr) && (a->fcw == b->fcw)\n#if defined(_WIN32)\n        && (memcmp(\n                (char*)&a->win_abi,\n                (char*)&b->win_abi,\n                sizeof(windows_abi_state_t)) == 0)\n#endif\n    );\n}\n\n#endif //_OE_ABI_UTILS_H\n", "// Copyright (c) Open Enclave SDK contributors.\n// Licensed under the MIT License.\n\n#include <math.h>\n#include <openenclave/edger8r/enclave.h>\n#include <openenclave/internal/calls.h>\n#include <stdlib.h>\n#include <string.h>\n#include \"../abi_utils.h\"\n#include \"abi_t.h\"\n\nOE_EXTERNC_BEGIN\n// By default, assume avx is available. This is the case with most processors\n// with SGX support.\nbool oe_is_avx_enabled = true;\nOE_EXTERNC_END\n\nvoid enclave_set_oe_is_avx_enabled(bool enabled)\n{\n    oe_is_avx_enabled = enabled;\n}\n\ndouble enclave_add_float()\n{\n    double my_res = 0;\n    volatile double my_num = 0.12345678899;\n\n    asm(\"fldl %1\\n\\t\"\n        \"fadd %%st, %%st\\n\\t\"\n        \"fstl %0\\n\\t\"\n        : \"=m\"(my_res)\n        : \"m\"(my_num)\n        :);\n\n    return my_res;\n}\n\ndouble enclave_check_abi()\n{\n    double retval = NAN;\n    oe_result_t result = OE_UNEXPECTED;\n    abi_state_t before_ocall_state = {};\n    abi_state_t after_ocall_state = {};\n\n    /* Marshalling struct cloned from abi_t.c, needs to be at least 16-bytes */\n    typedef struct _host_check_abi_args_t\n    {\n        oe_result_t _result;\n        void* deepcopy_out_buffer;\n        size_t deepcopy_out_buffer_size;\n        double _retval;\n    } host_check_abi_args_t;\n\n    /* Helper struct definition to manually flatten out ocall buffer with\n     * standard ocall parameters and args for host_check_abi. This test\n     * unrolls the EDL generated call stubs so that it can directly invoke\n     * the oe_ocall directly to check its ABI handling */\n    typedef struct _flat_ocall_args\n    {\n        oe_call_host_function_args_t host_function_args;\n        host_check_abi_args_t check_abi_args;\n    } flat_ocall_args_t;\n\n    /* abi_fcn_id_host_check_abi is defined in abi_t.c, must be kept in sync */\n    static const size_t abi_fcn_id_host_check_abi = 0;\n    const flat_ocall_args_t args_template = {\n        {.function_id = abi_fcn_id_host_check_abi,\n         .input_buffer = NULL,\n         .input_buffer_size = sizeof(args_template.check_abi_args),\n         .output_buffer = NULL,\n         .output_buffer_size = sizeof(args_template.check_abi_args),\n         .output_bytes_written = 0,\n         .result = OE_UNEXPECTED},\n        {._result = OE_UNEXPECTED,\n         .deepcopy_out_buffer = NULL,\n         .deepcopy_out_buffer_size = 0,\n         ._retval = 0}};\n\n    flat_ocall_args_t* args = NULL;\n\n    /* Get the FLAGS */\n    uint64_t flags = 0xffffffff;\n    asm volatile(\"pushfq\\n\\t\"\n                 \"popq %0\"\n                 : \"=r\"(flags)\n                 :\n                 : \"r8\");\n\n    /* Validate bit 10 (DF) and 16 - 31 bits are cleared by the\n     * oe_enter routine.\n     * Skip checks against other bits given that they could be impacted\n     * by branch or memory access executed until this point */\n    if (flags & 0xffff0400)\n        goto done;\n\n    /* Alloc and initialize host_check_abi OCALL args buffer */\n    args = (flat_ocall_args_t*)oe_allocate_ocall_buffer(sizeof(args_template));\n    if (!args)\n        goto done;\n\n    /* Note that the OCALL code enforces that input_buffer must be provided\n     * and at least 16-bytes, even though it is not used by host_check_abi,\n     * so the test assigns it the same buffer as the output_buffer */\n    memcpy(args, &args_template, sizeof(args_template));\n    args->host_function_args.input_buffer = &args->check_abi_args;\n    args->host_function_args.output_buffer = &args->check_abi_args;\n\n    /* Set up and cache ABI test state */\n    set_test_abi_state();\n    read_abi_state(&before_ocall_state);\n\n    /* Invoke oe_ocall directly to test the ocall transition ABI handling */\n    result = oe_ocall(OE_OCALL_CALL_HOST_FUNCTION, (uint64_t)args, NULL);\n\n    /* Snap the ABI state immediately on return and clear test manipulations */\n    read_abi_state(&after_ocall_state);\n    reset_test_abi_state();\n\n    /* Check that oe_ocall succeeded */\n    if (result != OE_OK)\n        goto done;\n\n    /* Check the host_check_abi function succeeded and produced output */\n    if (args->host_function_args.result != OE_OK)\n        goto done;\n\n    if (args->host_function_args.output_bytes_written !=\n        sizeof(args_template.check_abi_args))\n        goto done;\n\n    /* Check the enclave_check_abi function returned expected value */\n    if (args->check_abi_args._retval != EXPECTED_CHECK_ABI_RETURN_VALUE)\n        goto done;\n\n    /* Verify expected ABI state around oe_ocall is preserved */\n    if (!is_same_abi_state(&before_ocall_state, &after_ocall_state))\n        goto done;\n\n    retval = args->check_abi_args._retval;\n\ndone:\n    return retval;\n}\n\nOE_SET_ENCLAVE_SGX(\n    1,    /* ProductID */\n    1,    /* SecurityVersion */\n    true, /* Debug */\n    1024, /* NumHeapPages */\n    1024, /* NumStackPages */\n    1);   /* NumTCS */\n", "// Copyright (c) Open Enclave SDK contributors.\n// Licensed under the MIT License.\n\n#include <host/ecall_ids.h>\n#include <host/hostthread.h>\n#include <math.h>\n#include <openenclave/host.h>\n#include <openenclave/internal/calls.h>\n#include <openenclave/internal/error.h>\n#include <openenclave/internal/raise.h>\n#include <openenclave/internal/tests.h>\n#include \"../abi_utils.h\"\n#include \"abi_u.h\"\n\nextern \"C\"\n{\n#include <host/sgx/enclave.h>\n}\n\n#include <openenclave/internal/constants_x64.h>\n\n#ifdef _WIN32\nextern \"C\"\n{\n    void oe_dummy_mmx_add();\n    void oe_dummy_fpu_loads();\n}\n#endif\n\noe_result_t test_abi_roundtrip(oe_enclave_t* enclave)\n{\n    printf(\"=== test_abi_roundtrip()\\n\");\n\n    oe_result_t result = OE_UNEXPECTED;\n    abi_state_t before_ecall_state = {};\n    abi_state_t after_ecall_state = {};\n\n    uint64_t global_id = OE_GLOBAL_ECALL_ID_NULL;\n    oe_thread_key thread_binding_key;\n\n    /* Test invariant: abi_enc is defined with only a single thread */\n    oe_thread_binding_t* binding = &enclave->bindings[0];\n    void* tcs = (void*)binding->tcs;\n\n    /* Marshalling struct cloned from abi_u.c, needs to be at least 16-bytes */\n    typedef struct _enclave_check_abi_args_t\n    {\n        oe_result_t _result;\n        void* deepcopy_out_buffer;\n        size_t deepcopy_out_buffer_size;\n        double _retval;\n    } enclave_check_abi_args_t;\n\n    /* Helper struct definition to manually flatten out ecall buffer with\n     * standard ecall parameters and args for enclave_check_abi. This test\n     * unrolls the EDL generated call stubs so that it can directly invoke\n     * the oe_enter directly to check its ABI handling */\n    typedef struct _flat_ecall_args\n    {\n        oe_call_enclave_function_args_t enc_function_args;\n        enclave_check_abi_args_t check_abi_args;\n    } flat_ecall_args_t;\n\n    flat_ecall_args_t* args = NULL;\n\n    const flat_ecall_args_t args_template = {\n        {.function_id = 0,\n         .input_buffer = NULL,\n         .input_buffer_size = sizeof(args_template.check_abi_args),\n         .output_buffer = NULL,\n         .output_buffer_size = sizeof(args_template.check_abi_args),\n         .output_bytes_written = 0,\n         .result = OE_UNEXPECTED},\n        {._result = OE_UNEXPECTED,\n         .deepcopy_out_buffer = NULL,\n         .deepcopy_out_buffer_size = 0,\n         ._retval = 0}};\n\n    /* Skip the ABI state test in simulation mode since OE SDK doesn't\n     * provide special ABI handling on simulated enclave transition */\n    if (enclave->simulate)\n        OE_RAISE_MSG(\n            OE_UNSUPPORTED,\n            \"SKIPPING in test_abi_roundtrip() in Simulation Mode\\n\",\n            NULL);\n\n    /* Alloc and initialize the enclave_check_abi ECALL args buffer */\n    args = (flat_ecall_args_t*)malloc(sizeof(args_template));\n    if (!args)\n        OE_RAISE(OE_OUT_OF_MEMORY);\n\n    memcpy(args, &args_template, sizeof(args_template));\n    args->enc_function_args.input_buffer = &args->check_abi_args;\n    args->enc_function_args.output_buffer = &args->check_abi_args;\n    OE_CHECK(oe_get_ecall_ids(\n        enclave,\n        \"enclave_check_abi\",\n        &global_id,\n        &args->enc_function_args.function_id));\n\n    /* This method needs to perform its own thread binding since it doesn't\n     * call through oe_ecall to get at oe_enter directly, and oe_ecall is\n     * responsible for the thread binding in the normal code path. */\n    if (binding->flags & _OE_THREAD_BUSY)\n        OE_RAISE_MSG(\n            OE_UNEXPECTED,\n            \"ASSERT: test_abi_roundtrip() expects to be single threaded with \"\n            \"access to the only enclave thread context, but the thread binding \"\n            \"at index 0 is marked BUSY\\n\",\n            NULL);\n\n    /* This test asserts the invariant as a single threaded app that\n     * test_abi_roundtrip runs right after enclave initialization, which set\n     * the thread_binding_key for ecalls already. This oe_thread_key_create\n     * value called here should then return the next thread local storage index,\n     * so to infer the one used for ecalls we use the obtained value - 1 */\n    if (!oe_thread_key_create(&thread_binding_key))\n    {\n        /* The key index (the reservation of the slot) can be freed immediately\n         * since the thread storage itself is not used by this test */\n        oe_thread_key_delete(thread_binding_key);\n    }\n    else\n        OE_RAISE_MSG(OE_UNEXPECTED, \"oe_thread_key_create failed\\n\", NULL);\n\n    oe_thread_setspecific(thread_binding_key - 1, binding);\n    binding->flags |= _OE_THREAD_BUSY;\n    binding->thread = oe_thread_self();\n    binding->count = 1;\n\n    /* Notify the debugger runtime */\n    if (enclave->debug && enclave->debug_enclave != NULL)\n        oe_debug_push_thread_binding(enclave->debug_enclave, (sgx_tcs_t*)tcs);\n\n    /* Emulate the oe_ecall flow */\n    {\n        uint64_t arg1 = oe_make_call_arg1(\n            OE_CODE_ECALL, OE_ECALL_CALL_ENCLAVE_FUNCTION, 0, OE_OK);\n        uint64_t arg2 = (uint64_t)args;\n        uint64_t arg3 = 0;\n        uint64_t arg4 = 0;\n\n        /* Set up and cache ABI test state */\n        set_test_xmm_state();\n        set_test_abi_state();\n        read_abi_state(&before_ecall_state);\n\n#ifndef _WIN32\n        /* Explicitly poison FLAGS bits 10 (DF) and 15-31 while reserving the\n         * others\n         */\n        uint64_t flags = 0xffff0400;\n#else\n        /* Do not set DF on Windows, which will affect the behavior of\n         * memset_repmovs that is invoked in the critical path on the host */\n        uint64_t flags = 0xffff0000;\n#endif\n        asm volatile(\"pushfq\\n\\t\"\n                     \"or %0, (%%rsp)\\n\\t\"\n                     \"popfq\\n\\t\"\n                     :\n                     : \"r\"(flags)\n                     : \"r8\");\n\n        /* Invoke oe_enter directly to test the ocall transition ABI handling */\n        oe_enter(tcs, OE_AEP_ADDRESS, arg1, arg2, &arg3, &arg4, enclave);\n\n        /* Snap the ABI state immediately on return and clear test changes */\n        read_abi_state(&after_ecall_state);\n        reset_test_abi_state();\n\n        oe_code_t code_out = oe_get_code_from_call_arg1(arg3);\n        uint16_t result_out = oe_get_result_from_call_arg1(arg3);\n\n        /* Check that the exit is not from unexpected OCALL, which should\n         * have been handled within oe_enter already */\n        if (code_out != OE_CODE_ERET)\n            OE_RAISE_MSG(\n                OE_UNEXPECTED,\n                \"test_abi_roundtrip only expects ERET but received an \"\n                \"unexpected EEXIT code: %#x\\n\",\n                code_out);\n\n        /* Check that the ECALL succeeded */\n        OE_CHECK((oe_result_t)result_out);\n    }\n\n    /* Check the enclave_check_abi function succeeded and produced output */\n    OE_CHECK(args->enc_function_args.result);\n    if (args->enc_function_args.output_bytes_written !=\n        sizeof(args_template.check_abi_args))\n        OE_RAISE_MSG(\n            OE_UNEXPECTED,\n            \"enclave_check_abi only wrote %#x output bytes\\n\",\n            args->enc_function_args.output_bytes_written);\n\n    /* Check the enclave_check_abi function returned expected value */\n    if (args->check_abi_args._retval != EXPECTED_CHECK_ABI_RETURN_VALUE)\n        OE_RAISE_MSG(\n            OE_FAILURE,\n            \"enclave_check_abi returned %f instead of expected value set by \"\n            \"host_check_abi\\n\",\n            args->check_abi_args._retval);\n\n    /* Verify that the expected ABI is preserved */\n    if (!is_same_abi_state(&before_ecall_state, &after_ecall_state))\n        OE_RAISE_MSG(\n            OE_FAILURE,\n            \"ABI state before and after oe_enter were not equal\\n\",\n            NULL);\n\n    result = OE_OK;\n\ndone:\n    /* Clean up the thread binding and debugger registration */\n    if (binding->flags & _OE_THREAD_BUSY)\n    {\n        binding->count--;\n\n        /* Notify the debugger runtime */\n        if (enclave->debug && enclave->debug_enclave != NULL)\n            oe_debug_pop_thread_binding();\n\n        if (binding->count == 0)\n        {\n            binding->flags &= (~_OE_THREAD_BUSY);\n            binding->thread = 0;\n            memset(&binding->event, 0, sizeof(binding->event));\n            oe_thread_setspecific(thread_binding_key - 1, NULL);\n        }\n    }\n\n    return result;\n}\n\ndouble host_check_abi()\n{\n    return EXPECTED_CHECK_ABI_RETURN_VALUE;\n}\n\nvoid test_mmx_abi_poison(oe_enclave_t* enclave)\n{\n    double float_result = 0;\n    uint64_t dummy = 0;\n\n    printf(\"=== test_mmx_abi_poison()\\n\");\n\n#ifdef _WIN32\n    oe_dummy_mmx_add();\n#else\n    asm(\"movq %0, %%mm0\\n\\t\"\n        \"paddd %%mm0, %%mm0\\n\\t\" ::\"m\"(dummy)\n        :);\n#endif\n\n    OE_TEST(enclave_add_float(enclave, &float_result) == OE_OK);\n\n    printf(\"x87 FPU result = %f\\n\", float_result);\n    OE_TEST(!isnan(float_result));\n}\n\nvoid test_fpu_stack_overflow(oe_enclave_t* enclave)\n{\n    double float_result = 0;\n    uint64_t dummy = 0;\n\n    printf(\"=== test_fpu_stack_overflow()\\n\");\n\n#ifdef _WIN32\n    oe_dummy_fpu_loads();\n#else\n    asm(\"fldl %0\\n\\t\"\n        \"fldl %0\\n\\t\"\n        \"fldl %0\\n\\t\"\n        \"fldl %0\\n\\t\"\n        \"fldl %0\\n\\t\"\n        \"fldl %0\\n\\t\"\n        \"fldl %0\\n\\t\"\n        \"fldl %0\\n\\t\" ::\"m\"(dummy)\n        :);\n#endif\n\n    OE_TEST(enclave_add_float(enclave, &float_result) == OE_OK);\n\n    printf(\"x87 FPU result = %f\\n\", float_result);\n    OE_TEST(!isnan(float_result));\n}\n\nint main(int argc, const char* argv[])\n{\n    oe_result_t result;\n    oe_enclave_t* enclave = NULL;\n\n    if (argc != 2)\n    {\n        fprintf(stderr, \"Usage: %s ENCLAVE\\n\", argv[0]);\n        exit(1);\n    }\n\n    const uint32_t flags = oe_get_create_flags();\n\n    result = oe_create_abi_enclave(\n        argv[1], OE_ENCLAVE_TYPE_SGX, flags, NULL, 0, &enclave);\n    if (result != OE_OK)\n    {\n        oe_put_err(\"oe_create_abi_enclave(): result=%u\", result);\n    }\n\n    // oe_is_avx_enabled has already been setup by the host runtime.\n    // Pass it along to the enclave.\n    OE_TEST(enclave_set_oe_is_avx_enabled(enclave, oe_is_avx_enabled) == OE_OK);\n\n    result = test_abi_roundtrip(enclave);\n    OE_TEST(result == OE_OK || result == OE_UNSUPPORTED);\n\n    test_mmx_abi_poison(enclave);\n    test_fpu_stack_overflow(enclave);\n\n    if ((result = oe_terminate_enclave(enclave)) != OE_OK)\n    {\n        oe_put_err(\"oe_terminate_enclave(): result=%u\", result);\n    }\n\n    printf(\"=== passed all tests (%s)\\n\", argv[0]);\n\n    return 0;\n}\n", "// Copyright (c) Open Enclave SDK contributors.\n// Licensed under the MIT License.\n\n#include <dirent.h>\n#include <errno.h>\n#include <libgen.h>\n#include <openenclave/enclave.h>\n#include <openenclave/internal/constants_x64.h>\n#include <openenclave/internal/libc/init.h>\n#include <openenclave/internal/tests.h>\n#include <search.h>\n#include <stdarg.h>\n#include <stdbool.h>\n#include <stdint.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/mount.h>\n#include <time.h>\n#include \"libc_t.h\"\n#include \"mtest.h\"\n\n#include \"libc_tests.h\"\n\n#pragma STDC FENV_ACCESS ON\n\n#if defined(__x86_64__) || defined(_M_X64)\n#define XMM_OK\n#endif\n\n#if defined(XMM_OK)\nvoid _reset_fxsave_state()\n{\n    /* Initialize the FXSAVE state values to Linux x86-64 ABI defined values:\n     * FCW = 0x037F, MXCSR = 0x1FBF, MXCSR mask = 0xFFFF */\n    static OE_ALIGNED(OE_FXSAVE_ALIGNMENT) const uint64_t\n        _initial_fxstate[OE_FXSAVE_AREA_SIZE / sizeof(uint64_t)] = {\n            0x037F, 0,          0, 0xFFFF00001FBF,\n            0,      0,          0, 0,\n            0,      0,          0, 0,\n            0,      0,          0, 0,\n            0,      0,          0, 0,\n            0,      0,          0, 0,\n            0,      0,          0, 0,\n            0,      0,          0, 0,\n            0,      0,          0, 0,\n            0,      0,          0, 0,\n            0,      0,          0, 0,\n            0,      0,          0, 0,\n            0,      0,          0, 0,\n            0,      0,          0, 0,\n            2,      0x80000002, 0, 0,\n            0,      0,          0, 0,\n        };\n\n    asm volatile(\"fxrstor %[fx_state] \\n\\t\"\n                 :\n                 : [fx_state] \"m\"(_initial_fxstate)\n                 :);\n}\n#endif\n\nint t_status = 0;\n\nint device_init()\n{\n    OE_TEST(oe_load_module_host_file_system() == OE_OK);\n    OE_TEST(oe_load_module_host_socket_interface() == OE_OK);\n    // OE_TEST(oe_load_module_host_epoll() == OE_OK);\n\n#ifndef CODE_COVERAGE\n    OE_TEST(mount(\"/\", \"/\", OE_HOST_FILE_SYSTEM, 0, NULL) == 0);\n#endif\n    return 0;\n}\n\nint t_printf(const char* s, ...)\n{\n    va_list ap;\n    char buf[512];\n\n    t_status = 1;\n    va_start(ap, s);\n    int n = vsnprintf(buf, sizeof buf, s, ap);\n    va_end(ap);\n\n    printf(\"%s\\n\", buf);\n    return n;\n}\n\nint t_setrlim(int r, int64_t lim)\n{\n    return 0;\n}\n\nint run_test_helper(const char* test_name, libc_test_function_t test_function)\n{\n    extern char** __environ;\n    char** environ = NULL;\n    int ret = 1;\n\n    /* Print running message. */\n    printf(\"=== running: %s\\n\", test_name);\n\n#if defined(XMM_OK)\n    /* Reset the FXSAVE state between tests.\n     * The original libc tests for floating point math were compiled as\n     * individual executables and assume ABI-initialized floating point and\n     * MXCSR state. Since the enclave runs multiple tests in the same enclave\n     * consecutively, we reset the FXSAVE state on each run. */\n    _reset_fxsave_state();\n#endif\n\n    /* Disable Open Enclave debug malloc checks. */\n    extern bool oe_disable_debug_malloc_check;\n    oe_disable_debug_malloc_check = true;\n\n    /* Allocate an environment for invoking the test. */\n    if (!(environ = (char**)calloc(1, sizeof(char*))))\n        goto done;\n\n    memset(environ, 0, sizeof(char**));\n    __environ = environ;\n\n    /* Run the test */\n    const char* argv[] = {\"test\", NULL};\n\n    if (test_function(1, argv) != 0)\n    {\n        /* Prevent cascading of false negatives. */\n        t_status = 0;\n\n        fprintf(stderr, \"*** failed: %s\\n\", test_name);\n        goto done;\n    }\n\n    ret = 0;\n\ndone:\n\n    free(environ);\n    __environ = NULL;\n\n    return ret;\n}\n\nint run_test(const char* test_name)\n{\n    device_init();\n    libc_test_function_t test = get_test_case(test_name);\n\n    OE_TEST(oe_test_libc_is_initialized());\n\n    if (test)\n    {\n        return run_test_helper(test_name, test);\n    }\n\n    printf(\"*** failed: test %s is not a valid test\", test_name);\n    return 1;\n}\n\nint run_all_tests()\n{\n    int ret;\n\n    device_init();\n\n    OE_TEST(oe_test_libc_is_initialized());\n\n    ret = 0;\n    for (int i = 0; i < sizeof(libc_tests) / sizeof(libc_test_entry_t); i++)\n    {\n        libc_test_entry_t test = libc_tests[i];\n        ret += run_test_helper(test.test_name, test.test_function);\n    }\n\n    return ret;\n}\n\nOE_SET_ENCLAVE_SGX(\n    1,    /* ProductID */\n    1,    /* SecurityVersion */\n    true, /* Debug */\n    512,  /* NumHeapPages */\n    256,  /* NumStackPages */\n    4);   /* NumTCS */\n\n#define TA_UUID                                            \\\n    { /* d7fe296a-24e9-46d1-aa78-9c7395082a41 */           \\\n        0xd7fe296a, 0x24e9, 0x46d1,                        \\\n        {                                                  \\\n            0xaa, 0x78, 0x9c, 0x73, 0x95, 0x08, 0x2a, 0x41 \\\n        }                                                  \\\n    }\n\nOE_SET_ENCLAVE_OPTEE(\n    TA_UUID,\n    1 * 1024 * 1024,\n    12 * 1024,\n    0,\n    \"1.0.0\",\n    \"libc test\")\n"], "filenames": ["enclave/core/sgx/asmcommon.inc", "enclave/core/sgx/asmdefs.c", "enclave/core/sgx/calls.c", "enclave/core/sgx/context.inc", "enclave/core/sgx/enter.S", "tests/abi/abi_utils.h", "tests/abi/enc/enc.cpp", "tests/abi/host/host.cpp", "tests/libc/enc/enc.c"], "buggy_code_start_loc": [14, 19, 644, 108, 316, 27, 78, 147, 35], "buggy_code_end_loc": [95, 42, 653, 108, 316, 29, 82, 147, 54], "fixing_code_start_loc": [14, 19, 644, 109, 317, 27, 79, 148, 35], "fixing_code_end_loc": [118, 44, 655, 112, 324, 29, 98, 165, 54], "type": "CWE-665", "message": "Open Enclave is a hardware-agnostic open source library for developing applications that utilize Hardware-based Trusted Execution Environments, also known as Enclaves. There are two issues that are mitigated in version 0.19.3. First, Open Enclave SDK does not properly sanitize the `MXCSR` register on enclave entry. This makes applications vulnerable to MXCSR Configuration Dependent Timing (MCDT) attacks, where incorrect `MXCSR` values can impact instruction retirement by at most one cycle, depending on the (secret) data operand value. Please find more details in the guidance from Intel in the references. Second, Open Enclave SDK does not sanitize x86's alignment check flag `RFLAGS.AC` on enclave entry. This opens up the possibility for a side-channel attacker to be notified for every unaligned memory access performed by the enclave. The issue has been addressed in version 0.19.3 and the current master branch. Users will need to recompile their applications against the patched libraries to be protected from this vulnerability. There are no known workarounds for this vulnerability.", "other": {"cve": {"id": "CVE-2023-37479", "sourceIdentifier": "security-advisories@github.com", "published": "2023-07-17T23:15:08.973", "lastModified": "2023-07-28T13:53:27.773", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Open Enclave is a hardware-agnostic open source library for developing applications that utilize Hardware-based Trusted Execution Environments, also known as Enclaves. There are two issues that are mitigated in version 0.19.3. First, Open Enclave SDK does not properly sanitize the `MXCSR` register on enclave entry. This makes applications vulnerable to MXCSR Configuration Dependent Timing (MCDT) attacks, where incorrect `MXCSR` values can impact instruction retirement by at most one cycle, depending on the (secret) data operand value. Please find more details in the guidance from Intel in the references. Second, Open Enclave SDK does not sanitize x86's alignment check flag `RFLAGS.AC` on enclave entry. This opens up the possibility for a side-channel attacker to be notified for every unaligned memory access performed by the enclave. The issue has been addressed in version 0.19.3 and the current master branch. Users will need to recompile their applications against the patched libraries to be protected from this vulnerability. There are no known workarounds for this vulnerability."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:H/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "HIGH", "availabilityImpact": "NONE", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:R/S:U/C:N/I:H/A:N", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "HIGH", "availabilityImpact": "NONE", "baseScore": 5.3, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.6, "impactScore": 3.6}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-665"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:openenclave:openenclave:*:*:*:*:*:*:*:*", "versionEndExcluding": "0.19.3", "matchCriteriaId": "5D059C21-E43F-4C02-B5F7-21F468CCAFE3"}]}]}], "references": [{"url": "https://github.com/openenclave/openenclave/commit/ca54623333875b9beaad92c999a92b015c44b079", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/openenclave/openenclave/security/advisories/GHSA-5gfr-m6mx-p5w4", "source": "security-advisories@github.com", "tags": ["Vendor Advisory"]}, {"url": "https://www.intel.com/content/www/us/en/developer/articles/technical/software-security-guidance/best-practices/mxcsr-configuration-dependent-timing.html", "source": "security-advisories@github.com", "tags": ["Technical Description"]}]}, "github_commit_url": "https://github.com/openenclave/openenclave/commit/ca54623333875b9beaad92c999a92b015c44b079"}}
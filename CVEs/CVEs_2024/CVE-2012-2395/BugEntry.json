{"buggy_code": ["\"\"\"\nPower management library.  For cobbler objects with power management configured\nencapsulate the logic to run power management commands so that the admin does not\nhave to use seperate tools and remember how each of the power management tools are\nset up.  This makes power cycling a system for reinstallation much easier.\n\nSee https://github.com/cobbler/cobbler/wiki/Power-management\n\nCopyright 2008-2009, Red Hat, Inc and Others\nMichael DeHaan <michael.dehaan AT gmail>\n\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA\n02110-1301  USA\n\"\"\"\n\n\nimport os\nimport os.path\nimport traceback\nimport time\nimport re\n\nimport utils\nimport func_utils\nfrom cexceptions import *\nimport templar\nimport clogger\n\nclass PowerTool:\n    \"\"\"\n    Handles conversion of internal state to the tftpboot tree layout\n    \"\"\"\n\n    def __init__(self,config,system,api,force_user=None,force_pass=None,logger=None):\n        \"\"\"\n        Power library constructor requires a cobbler system object.\n        \"\"\"\n        self.system      = system\n        self.config      = config\n        self.settings    = config.settings()\n        self.api         = api\n        self.logger      = self.api.logger\n        self.force_user  = force_user\n        self.force_pass  = force_pass\n        if logger is None:\n            logger = clogger.Logger()\n        self.logger      = logger\n\n    def power(self, desired_state):\n        \"\"\"\n        state is either \"on\" or \"off\".  Rebooting is implemented at the api.py\n        level.\n\n        The user and password need not be supplied.  If not supplied they\n        will be taken from the environment, COBBLER_POWER_USER and COBBLER_POWER_PASS.\n        If provided, these will override any other data and be used instead.  Users\n        interested in maximum security should take that route.\n        \"\"\"\n\n        template = self.get_command_template()\n        template_file = open(template, \"r\")\n\n        meta = utils.blender(self.api, False, self.system)\n        meta[\"power_mode\"] = desired_state\n\n        # allow command line overrides of the username/password \n        if self.force_user is not None:\n           meta[\"power_user\"] = self.force_user\n        if self.force_pass is not None:\n           meta[\"power_pass\"] = self.force_pass\n\n        tmp = templar.Templar(self.api._config)\n        cmd = tmp.render(template_file, meta, None, self.system)\n        template_file.close()\n\n        cmd = cmd.strip()\n\n        self.logger.info(\"cobbler power configuration is:\")\n\n        self.logger.info(\"      type   : %s\" % self.system.power_type)\n        self.logger.info(\"      address: %s\" % self.system.power_address)\n        self.logger.info(\"      user   : %s\" % self.system.power_user)\n        self.logger.info(\"      id     : %s\" % self.system.power_id)\n\n        # if no username/password data, check the environment\n\n        if meta.get(\"power_user\",\"\") == \"\":\n            meta[\"power_user\"] = os.environ.get(\"COBBLER_POWER_USER\",\"\")\n        if meta.get(\"power_pass\",\"\") == \"\":\n            meta[\"power_pass\"] = os.environ.get(\"COBBLER_POWER_PASS\",\"\")\n\n        self.logger.info(\"- %s\" % cmd)\n\n        # use shell so we can have mutliple power commands chained together\n        cmd = ['/bin/sh','-c', cmd]\n\n        # Try the power command 5 times before giving up.\n        # Some power switches are flakey\n        for x in range(0,5):\n            output, rc = utils.subprocess_sp(self.logger, cmd, shell=False)\n            if rc == 0:\n                # If the desired state is actually a query for the status\n                # return different information than command return code\n                if desired_state == 'status':\n                    match = re.match('(^Status:\\s)(ON|OFF)', output)\n                    if match:\n                        power_status = match.groups()[1]\n                        if power_status == 'ON':\n                            return True\n                        else:\n                            return False\n                    utils.die(self.logger,\"command succeeded (rc=%s), but output ('%s') was not understood\" % (rc, output))\n                    return None\n                break\n            else:\n                time.sleep(2)\n\n        if not rc == 0:\n           utils.die(self.logger,\"command failed (rc=%s), please validate the physical setup and cobbler config\" % rc)\n\n        return rc\n\n    def get_command_template(self):\n\n        \"\"\"\n        In case the user wants to customize the power management commands, \n        we source the code for each command from /etc/cobbler and run\n        them through Cheetah.\n        \"\"\"\n\n        if self.system.power_type in [ \"\", \"none\" ]:\n            utils.die(self.logger,\"Power management is not enabled for this system\")\n\n        result = utils.get_power(self.system.power_type)\n        if not result:\n            utils.die(self.logger, \"Invalid power management type for this system (%s, %s)\" % (self.system.power_type, self.system.name))\n        return result\n\n", "\"\"\"\nA Cobbler System.\n\nCopyright 2006-2009, Red Hat, Inc and Others\nMichael DeHaan <michael.dehaan AT gmail>\n\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA\n02110-1301  USA\n\"\"\"\n\nimport utils\nimport item\nimport time\nfrom cexceptions import *\nfrom utils import _\n\n# this datastructure is described in great detail in item_distro.py -- read the comments there.\n\nFIELDS = [\n  [\"name\",\"\",0,\"Name\",True,\"Ex: vanhalen.example.org\",0,\"str\"],\n  [\"uid\",\"\",0,\"\",False,\"\",0,\"str\"],\n  [\"owners\",\"SETTINGS:default_ownership\",0,\"Owners\",True,\"Owners list for authz_ownership (space delimited)\",0,\"list\"],\n  [\"profile\",None,0,\"Profile\",True,\"Parent profile\",[],\"str\"],\n  [\"image\",None,0,\"Image\",True,\"Parent image (if not a profile)\",0,\"str\"],\n  [\"status\",\"production\",0,\"Status\",True,\"System status\",[\"development\",\"testing\",\"acceptance\",\"production\"],\"str\"],\n  [\"kernel_options\",{},0,\"Kernel Options\",True,\"Ex: selinux=permissive\",0,\"dict\"],\n  [\"kernel_options_post\",{},0,\"Kernel Options (Post Install)\",True,\"Ex: clocksource=pit noapic\",0,\"dict\"],\n  [\"ks_meta\",{},0,\"Kickstart Metadata\",True,\"Ex: dog=fang agent=86\",0,\"dict\"],\n  [\"enable_gpxe\",\"SETTINGS:enable_gpxe\",0,\"Enable gPXE?\",True,\"Use gPXE instead of PXELINUX for advanced booting options\",0,\"bool\"],\n  [\"proxy\",\"<<inherit>>\",0,\"Proxy\",True,\"Proxy URL\",0,\"str\"],\n  [\"netboot_enabled\",True,0,\"Netboot Enabled\",True,\"PXE (re)install this machine at next boot?\",0,\"bool\"],\n  [\"kickstart\",\"<<inherit>>\",0,\"Kickstart\",True,\"Path to kickstart template\",0,\"str\"],\n  [\"comment\",\"\",0,\"Comment\",True,\"Free form text description\",0,\"str\"],\n  [\"depth\",2,0,\"\",False,\"\",0,\"int\"],\n  [\"server\",\"<<inherit>>\",0,\"Server Override\",True,\"See manpage or leave blank\",0,\"str\"],\n  [\"virt_path\",\"<<inherit>>\",0,\"Virt Path\",True,\"Ex: /directory or VolGroup00\",0,\"str\"],\n  [\"virt_type\",\"<<inherit>>\",0,\"Virt Type\",True,\"Virtualization technology to use\",[\"xenpv\",\"xenfv\",\"qemu\",\"kvm\",\"vmware\"],\"str\"],\n  [\"virt_cpus\",\"<<inherit>>\",0,\"Virt CPUs\",True,\"\",0,\"int\"],\n  [\"virt_file_size\",\"<<inherit>>\",0,\"Virt File Size(GB)\",True,\"\",0,\"float\"],\n  [\"virt_disk_driver\",\"<<inherit>>\",0,\"Virt Disk Driver Type\",True,\"The on-disk format for the virtualization disk\",\"raw\",\"str\"],\n  [\"virt_ram\",\"<<inherit>>\",0,\"Virt RAM (MB)\",True,\"\",0,\"int\"],\n  [\"virt_auto_boot\",\"<<inherit>>\",0,\"Virt Auto Boot\",True,\"Auto boot this VM?\",0,\"bool\"],\n  [\"ctime\",0,0,\"\",False,\"\",0,\"float\"],\n  [\"mtime\",0,0,\"\",False,\"\",0,\"float\"],\n  [\"power_type\",\"SETTINGS:power_management_default_type\",0,\"Type\",True,\"Power management script to use\",utils.get_power_types(),\"str\"],\n  [\"power_address\",\"\",0,\"Address\",True,\"Ex: power-device.example.org\",0,\"str\"],\n  [\"power_user\",\"\",0,\"Username \",True,\"\",0,\"str\"],\n  [\"power_pass\",\"\",0,\"Password\",True,\"\",0,\"str\"],\n  [\"power_id\",\"\",0,\"ID\",True,\"Usually a plug number or blade name, if power type requires it\",0,\"str\"],\n  [\"hostname\",\"\",0,\"Hostname\",True,\"\",0,\"str\"],\n  [\"gateway\",\"\",0,\"Gateway\",True,\"\",0,\"str\"],\n  [\"name_servers\",[],0,\"Name Servers\",True,\"space delimited\",0,\"list\"],\n  [\"name_servers_search\",[],0,\"Name Servers Search Path\",True,\"space delimited\",0,\"list\"],\n  [\"ipv6_default_device\",\"\",0,\"IPv6 Default Device\",True,\"\",0,\"str\"],\n  [\"ipv6_autoconfiguration\",False,0,\"IPv6 Autoconfiguration\",True,\"\",0,\"bool\"],\n  [\"network_widget_a\",\"\",0,\"Add Interface\",True,\"\",0,\"str\"], # not a real field, a marker for the web app\n  [\"network_widget_b\",\"\",0,\"Edit Interface\",True,\"\",0,\"str\"], # not a real field, a marker for the web app\n  [\"*mac_address\",\"\",0,\"MAC Address\",True,\"(Place \\\"random\\\" in this field for a random MAC Address.)\",0,\"str\"],\n  [\"network_widget_c\",\"\",0,\"\",True,\"\",0,\"str\"], # not a real field, a marker for the web app\n  [\"*mtu\",\"\",0,\"MTU\",True,\"\",0,\"str\"],\n  [\"*ip_address\",\"\",0,\"IP Address\",True,\"\",0,\"str\"],\n  [\"*interface_type\",\"na\",0,\"Interface Type\",True,\"\",[\"na\",\"master\",\"slave\",\"bond\",\"bond_slave\",\"bridge\",\"bridge_slave\"],\"str\"],\n  [\"*interface_master\",\"\",0,\"Master Interface\",True,\"\",0,\"str\"],\n  [\"*bonding_opts\",\"\",0,\"Bonding Opts\",True,\"\",0,\"str\"],\n  [\"*bridge_opts\",\"\",0,\"Bridge Opts\",True,\"\",0,\"str\"],\n  [\"*management\",False,0,\"Management Interface\",True,\"Is this the management interface?\",0,\"bool\"],\n  [\"*static\",False,0,\"Static\",True,\"Is this interface static?\",0,\"bool\"],\n  [\"*netmask\",\"\",0,\"Subnet Mask\",True,\"\",0,\"str\"],\n  [\"*dhcp_tag\",\"\",0,\"DHCP Tag\",True,\"\",0,\"str\"],\n  [\"*dns_name\",\"\",0,\"DNS Name\",True,\"\",0,\"str\"],\n  [\"*static_routes\",[],0,\"Static Routes\",True,\"\",0,\"list\"],\n  [\"*virt_bridge\",\"\",0,\"Virt Bridge\",True,\"\",0,\"str\"],\n  [\"*ipv6_address\",\"\",0,\"IPv6 Address\",True,\"\",0,\"str\"],\n  [\"*ipv6_secondaries\",[],0,\"IPv6 Secondaries\",True,\"space delimited\",0,\"list\"],\n  [\"*ipv6_mtu\",\"\",0,\"IPv6 MTU\",True,\"\",0,\"str\"],\n  [\"*ipv6_static_routes\",[],0,\"IPv6 Static Routes\",True,\"\",0,\"list\"],\n  [\"*ipv6_default_gateway\",\"\",0,\"IPv6 Default Gateway\",True,\"\",0,\"str\"],\n  [\"mgmt_classes\",[],0,\"Management Classes\",True,\"For external config management\",0,\"list\"],\n  [\"mgmt_parameters\",\"<<inherit>>\",0,\"Management Parameters\",True,\"Parameters which will be handed to your management application (Must be valid YAML dictionary)\", 0,\"str\"],\n  [ \"boot_files\",{},'<<inherit>>',\"TFTP Boot Files\",True,\"Files copied into tftpboot beyond the kernel/initrd\",0,\"list\"],\n  [\"fetchable_files\",{},'<<inherit>>',\"Fetchable Files\",True,\"Templates for tftp or wget\",0,\"dict\"],\n  [\"template_files\",{},0,\"Template Files\",True,\"File mappings for built-in configuration management\",0,\"dict\"],\n  [\"redhat_management_key\",\"<<inherit>>\",0,\"Red Hat Management Key\",True,\"Registration key for RHN, Satellite, or Spacewalk\",0,\"str\"],\n  [\"redhat_management_server\",\"<<inherit>>\",0,\"Red Hat Management Server\",True,\"Address of Satellite or Spacewalk Server\",0,\"str\"],\n  [\"template_remote_kickstarts\", \"SETTINGS:template_remote_kickstarts\", \"SETTINGS:template_remote_kickstarts\", \"\", False, \"\", 0, \"bool\"],\n  [\"repos_enabled\",False,0,\"Repos Enabled\",True,\"(re)configure local repos on this machine at next config update?\",0,\"bool\"],\n  [\"ldap_enabled\",False,0,\"LDAP Enabled\",True,\"(re)configure LDAP on this machine at next config update?\",0,\"bool\"],\n  [\"ldap_type\",\"SETTINGS:ldap_management_default_type\",0,\"LDAP Management Type\",True,\"Ex: authconfig\",0,\"str\"],\n  [\"monit_enabled\",False,0,\"Monit Enabled\",True,\"(re)configure monit on this machine at next config update?\",0,\"bool\"],\n]\n\nclass System(item.Item):\n\n    TYPE_NAME = _(\"system\")\n    COLLECTION_TYPE = \"system\"\n\n    def get_fields(self):\n        return FIELDS\n\n    def make_clone(self):\n        ds = self.to_datastruct()\n        cloned = System(self.config)\n        cloned.from_datastruct(ds)\n        return cloned\n\n    def delete_interface(self,name):\n        \"\"\"\n        Used to remove an interface.\n        \"\"\"\n        if self.interfaces.has_key(name) and len(self.interfaces) > 1:\n            del self.interfaces[name]\n        else:\n            if not self.interfaces.has_key(name):\n                # no interface here to delete\n                pass\n            else:\n                raise CX(_(\"At least one interface needs to be defined.\"))\n\n        return True\n        \n\n    def __get_interface(self,name):\n\n        if not self.interfaces.has_key(name):\n            self.interfaces[name] = {\n                \"mac_address\"          : \"\",\n                \"mtu\"                  : \"\",\n                \"ip_address\"           : \"\",\n                \"dhcp_tag\"             : \"\",\n                \"subnet\"               : \"\", # deprecated\n                \"netmask\"              : \"\",\n                \"virt_bridge\"          : \"\",\n                \"static\"               : False,\n                \"interface_type\"       : \"\",\n                \"interface_master\"     : \"\",\n                \"bonding\"              : \"\", # deprecated\n                \"bonding_master\"       : \"\", # deprecated\n                \"bonding_opts\"         : \"\",\n                \"bridge_opts\"          : \"\",\n                \"management\"           : False,\n                \"dns_name\"             : \"\",\n                \"static_routes\"        : [],\n                \"ipv6_address\"         : \"\",\n                \"ipv6_secondaries\"     : [],\n                \"ipv6_mtu\"             : \"\",\n                \"ipv6_static_routes\"   : [],\n                \"ipv6_default_gateway\" : \"\",\n            }\n\n        return self.interfaces[name]\n\n\n    def from_datastruct(self,seed_data):\n        # FIXME: most definitely doesn't grok interfaces yet.\n        return utils.from_datastruct_from_fields(self,seed_data,FIELDS)\n\n    def get_parent(self):\n        \"\"\"\n        Return object next highest up the tree.\n        \"\"\"\n        if (self.parent is None or self.parent == '') and self.profile:\n            return self.config.profiles().find(name=self.profile)\n        elif (self.parent is None or self.parent == '') and self.image:\n            return self.config.images().find(name=self.image)\n        else:\n            return self.config.systems().find(name=self.parent)\n\n    def set_name(self,name):\n        \"\"\"\n        Set the name.  If the name is a MAC or IP, and the first MAC and/or IP is not defined, go ahead\n        and fill that value in.  \n        \"\"\"\n\n        if self.name not in [\"\",None] and self.parent not in [\"\",None] and self.name == self.parent:\n            raise CX(_(\"self parentage is weird\"))\n        if not isinstance(name, basestring):\n            raise CX(_(\"name must be a string\"))\n        for x in name:\n            if not x.isalnum() and not x in [ \"_\", \"-\", \".\", \":\", \"+\" ] :\n                raise CX(_(\"invalid characters in name: %s\") % x)\n\n        # Stuff here defaults to eth0. Yes, it's ugly and hardcoded, but so was\n        # the default interface behaviour that's now removed. ;)\n        # --Jasper Capel\n        if utils.is_mac(name):\n           intf = self.__get_interface(\"eth0\")\n           if intf[\"mac_address\"] == \"\":\n               intf[\"mac_address\"] = name\n        elif utils.is_ip(name):\n           intf = self.__get_interface(\"eth0\")\n           if intf[\"ip_address\"] == \"\":\n               intf[\"ip_address\"] = name\n        self.name = name \n\n        return True\n\n    def set_redhat_management_key(self,key):\n        return utils.set_redhat_management_key(self,key)\n\n    def set_redhat_management_server(self,server):\n        return utils.set_redhat_management_server(self,server)\n\n    def set_server(self,server):\n        \"\"\"\n        If a system can't reach the boot server at the value configured in settings\n        because it doesn't have the same name on it's subnet this is there for an override.\n        \"\"\"\n        if server is None or server == \"\":\n            server = \"<<inherit>>\"\n        self.server = server\n        return True\n\n    def set_proxy(self,proxy):\n        if proxy is None or proxy == \"\":\n            proxy = \"<<inherit>>\"\n        self.proxy = proxy\n        return True\n\n    def get_mac_address(self,interface):\n        \"\"\"\n        Get the mac address, which may be implicit in the object name or explicit with --mac-address.\n        Use the explicit location first.\n        \"\"\"\n\n        intf = self.__get_interface(interface)\n\n        if intf[\"mac_address\"] != \"\":\n            return intf[\"mac_address\"].strip()\n        else:\n            return None\n\n    def get_ip_address(self,interface):\n        \"\"\"\n        Get the IP address, which may be implicit in the object name or explict with --ip-address.\n        Use the explicit location first.\n        \"\"\"\n\n        intf = self.__get_interface(interface)\n\n        if intf[\"ip_address\"] != \"\": \n            return intf[\"ip_address\"].strip()\n        else:\n            return \"\"\n\n    def is_management_supported(self,cidr_ok=True):\n        \"\"\"\n        Can only add system PXE records if a MAC or IP address is available, else it's a koan\n        only record.  Actually Itanium goes beyond all this and needs the IP all of the time\n        though this is enforced elsewhere (action_sync.py).\n        \"\"\"\n        if self.name == \"default\":\n           return True\n        for (name,x) in self.interfaces.iteritems():\n            mac = x.get(\"mac_address\",None)\n            ip  = x.get(\"ip_address\",None)\n            if ip is not None and not cidr_ok and ip.find(\"/\") != -1:\n                # ip is in CIDR notation\n                return False\n            if mac is not None or ip is not None:\n                # has ip and/or mac\n                return True\n        return False\n\n    def set_dhcp_tag(self,dhcp_tag,interface):\n        intf = self.__get_interface(interface)\n        intf[\"dhcp_tag\"] = dhcp_tag\n        return True\n\n    def set_dns_name(self,dns_name,interface):\n        intf = self.__get_interface(interface)\n        # FIXME: move duplicate supression code to the object validation\n        # functions to take a harder line on supression?\n        if dns_name != \"\" and not str(self.config._settings.allow_duplicate_hostnames).lower() in [ \"1\", \"y\", \"yes\"]:\n           matched = self.config.api.find_items(\"system\", {\"dns_name\" : dns_name})\n           for x in matched:\n               if x.name != self.name:\n                   raise CX(\"dns-name duplicated: %s\" % dns_name)\n\n\n        intf[\"dns_name\"] = dns_name\n        return True\n \n    def set_static_routes(self,routes,interface):\n        intf = self.__get_interface(interface)\n        data = utils.input_string_or_list(routes)\n        intf[\"static_routes\"] = data\n        return True\n\n    def set_hostname(self,hostname):\n        if hostname is None:\n           hostname = \"\"\n        self.hostname = hostname\n        return True\n\n    def set_status(self,status):\n        self.status = status\n        return True\n\n    def set_static(self,truthiness,interface):\n        intf = self.__get_interface(interface)\n        intf[\"static\"] = utils.input_boolean(truthiness)\n        return True\n\n    def set_management(self,truthiness,interface):\n        intf = self.__get_interface(interface)\n        intf[\"management\"] = utils.input_boolean(truthiness)\n        return True\n\n    def set_ip_address(self,address,interface):\n        \"\"\"\n        Assign a IP or hostname in DHCP when this MAC boots.\n        Only works if manage_dhcp is set in /etc/cobbler/settings\n        \"\"\"\n        intf = self.__get_interface(interface)\n\n        # FIXME: move duplicate supression code to the object validation\n        # functions to take a harder line on supression?\n        if address != \"\" and not str(self.config._settings.allow_duplicate_ips).lower() in [ \"1\", \"y\", \"yes\"]:\n           matched = self.config.api.find_items(\"system\", {\"ip_address\" : address})\n           for x in matched:\n               if x.name != self.name:\n                   raise CX(\"IP address duplicated: %s\" % address)\n\n\n        if address == \"\" or utils.is_ip(address):\n           intf[\"ip_address\"] = address.strip()\n           return True\n        raise CX(_(\"invalid format for IP address (%s)\") % address)\n\n    def set_mac_address(self,address,interface):\n        if address == \"random\":\n           address = utils.get_random_mac(self.config.api)\n\n        # FIXME: move duplicate supression code to the object validation\n        # functions to take a harder line on supression?\n        if address != \"\" and not str(self.config._settings.allow_duplicate_macs).lower() in [ \"1\", \"y\", \"yes\"]:\n           matched = self.config.api.find_items(\"system\", {\"mac_address\" : address})\n           for x in matched:\n               if x.name != self.name:\n                   raise CX(\"MAC address duplicated: %s\" % address)\n\n        intf = self.__get_interface(interface)\n        if address == \"\" or utils.is_mac(address):\n           intf[\"mac_address\"] = address.strip()\n           return True\n        raise CX(_(\"invalid format for MAC address (%s)\" % address))\n\n\n    def set_gateway(self,gateway):\n        if gateway is None:\n           gateway = \"\"\n        if utils.is_ip(gateway) or gateway == \"\":\n           self.gateway = gateway\n        else:\n           raise CX(_(\"invalid format for gateway IP address (%s)\") % gateway)\n        return True\n \n    def set_name_servers(self,data):\n        if data == \"<<inherit>>\":\n           data = []\n        data = utils.input_string_or_list(data)\n        self.name_servers = data\n        return True\n\n    def set_name_servers_search(self,data):\n        if data == \"<<inherit>>\":\n           data = []\n        data = utils.input_string_or_list(data)\n        self.name_servers_search = data\n        return True\n\n    def set_netmask(self,netmask,interface):\n        intf = self.__get_interface(interface)\n        intf[\"netmask\"] = netmask\n        return True\n    \n    def set_virt_bridge(self,bridge,interface):\n        if bridge == \"\":\n            bridge = self.settings.default_virt_bridge\n        intf = self.__get_interface(interface)\n        intf[\"virt_bridge\"] = bridge\n        return True\n\n    def set_interface_type(self,type,interface):\n        # master and slave are deprecated, and will\n        # be assumed to mean bonding slave/master\n        interface_types = [\"bridge\",\"bridge_slave\",\"bond\",\"bond_slave\",\"master\",\"slave\",\"na\",\"\"]\n        if type not in interface_types:\n            raise CX(_(\"interface type value must be one of: %s or blank\" % interface_types.join(\",\")))\n        if type == \"na\":\n            type = \"\"\n        elif type == \"master\":\n            type = \"bond\"\n        elif type == \"slave\":\n            type = \"bond_slave\"\n        intf = self.__get_interface(interface)\n        intf[\"interface_type\"] = type\n        return True\n\n    def set_interface_master(self,interface_master,interface):\n        intf = self.__get_interface(interface)\n        intf[\"interface_master\"] = interface_master\n        return True\n\n    def set_bonding_opts(self,bonding_opts,interface):\n        intf = self.__get_interface(interface)\n        intf[\"bonding_opts\"] = bonding_opts\n        return True\n\n    def set_bridge_opts(self,bridge_opts,interface):\n        intf = self.__get_interface(interface)\n        intf[\"bridge_opts\"] = bridge_opts\n        return True\n\n    def set_ipv6_autoconfiguration(self,truthiness):\n        self.ipv6_autoconfiguration = utils.input_boolean(truthiness)\n        return True\n\n    def set_ipv6_default_device(self,interface_name):\n        if interface_name is None:\n           interface_name = \"\"\n        self.ipv6_default_device = interface_name\n        return True\n\n    def set_ipv6_address(self,address,interface):\n        \"\"\"\n        Assign a IP or hostname in DHCP when this MAC boots.\n        Only works if manage_dhcp is set in /etc/cobbler/settings\n        \"\"\"\n        intf = self.__get_interface(interface)\n        if address == \"\" or utils.is_ip(address):\n           intf[\"ipv6_address\"] = address.strip()\n           return True\n        raise CX(_(\"invalid format for IPv6 IP address (%s)\") % address)\n\n    def set_ipv6_secondaries(self,addresses,interface):\n        intf = self.__get_interface(interface)\n        data = utils.input_string_or_list(addresses)\n        secondaries = []\n        for address in data:\n           if address == \"\" or utils.is_ip(address):\n               secondaries.append(address)\n           else:\n               raise CX(_(\"invalid format for IPv6 IP address (%s)\") % address)\n\n        intf[\"ipv6_secondaries\"] = secondaries\n        return True\n\n    def set_ipv6_default_gateway(self,address,interface):\n        intf = self.__get_interface(interface)\n        if address == \"\" or utils.is_ip(address):\n           intf[\"ipv6_default_gateway\"] = address.strip()\n           return True\n        raise CX(_(\"invalid format for IPv6 IP address (%s)\") % address)\n\n    def set_ipv6_static_routes(self,routes,interface):\n        intf = self.__get_interface(interface)\n        data = utils.input_string_or_list(routes)\n        intf[\"ipv6_static_routes\"] = data\n        return True\n\n    def set_ipv6_mtu(self,mtu,interface):\n        intf = self.__get_interface(interface)\n        intf[\"ipv6_mtu\"] = mtu\n        return True\n\n    def set_mtu(self,mtu,interface):\n        intf = self.__get_interface(interface)\n        intf[\"mtu\"] = mtu\n        return True\n\n    def set_enable_gpxe(self,enable_gpxe):\n        \"\"\"\n        Sets whether or not the system will use gPXE for booting.\n        \"\"\"\n        self.enable_gpxe = utils.input_boolean(enable_gpxe)\n        return True\n\n    def set_profile(self,profile_name):\n        \"\"\"\n        Set the system to use a certain named profile.  The profile\n        must have already been loaded into the Profiles collection.\n        \"\"\"\n        old_parent = self.get_parent()\n        if profile_name in [ \"delete\", \"None\", \"~\", \"\"] or profile_name is None:\n            self.profile = \"\"\n            if isinstance(old_parent, item.Item):\n                old_parent.children.pop(self.name, 'pass')\n            return True\n\n        self.image = \"\" # mutual exclusion rule\n\n        p = self.config.profiles().find(name=profile_name)\n        if p is not None:\n            self.profile = profile_name\n            self.depth = p.depth + 1 # subprofiles have varying depths.\n            if isinstance(old_parent, item.Item):\n                old_parent.children.pop(self.name, 'pass')\n            new_parent = self.get_parent()\n            if isinstance(new_parent, item.Item):\n                new_parent.children[self.name] = self\n            return True\n        raise CX(_(\"invalid profile name: %s\") % profile_name)\n\n    def set_image(self,image_name):\n        \"\"\"\n        Set the system to use a certain named image.  Works like set_profile\n        but cannot be used at the same time.  It's one or the other.\n        \"\"\"\n        old_parent = self.get_parent()\n        if image_name in [ \"delete\", \"None\", \"~\", \"\"] or image_name is None:\n            self.image = \"\"\n            if isinstance(old_parent, item.Item):\n                old_parent.children.pop(self.name, 'pass')\n            return True\n\n        self.profile = \"\" # mutual exclusion rule\n\n        img = self.config.images().find(name=image_name)\n\n        if img is not None:\n            self.image = image_name\n            self.depth = img.depth + 1\n            if isinstance(old_parent, item.Item):\n                old_parent.children.pop(self.name, 'pass')\n            new_parent = self.get_parent()\n            if isinstance(new_parent, item.Item):\n                new_parent.children[self.name] = self\n            return True\n        raise CX(_(\"invalid image name (%s)\") % image_name)\n\n    def set_virt_cpus(self,num):\n        return utils.set_virt_cpus(self,num)\n\n    def set_virt_file_size(self,num):\n        return utils.set_virt_file_size(self,num)\n\n    def set_virt_disk_driver(self,driver):\n        return utils.set_virt_disk_driver(self,driver)\n \n    def set_virt_auto_boot(self,num):\n        return utils.set_virt_auto_boot(self,num)\n\n    def set_virt_ram(self,num):\n        return utils.set_virt_ram(self,num)\n\n    def set_virt_type(self,vtype):\n        return utils.set_virt_type(self,vtype)\n\n    def set_virt_path(self,path):\n        return utils.set_virt_path(self,path,for_system=True)\n\n    def set_netboot_enabled(self,netboot_enabled):\n        \"\"\"\n        If true, allows per-system PXE files to be generated on sync (or add).  If false,\n        these files are not generated, thus eliminating the potential for an infinite install\n        loop when systems are set to PXE boot first in the boot order.  In general, users\n        who are PXE booting first in the boot order won't create system definitions, so this\n        feature primarily comes into play for programmatic users of the API, who want to\n        initially create a system with netboot enabled and then disable it after the system installs, \n        as triggered by some action in kickstart %post.   For this reason, this option is not\n        surfaced in the CLI, output, or documentation (yet).\n\n        Use of this option does not affect the ability to use PXE menus.  If an admin has machines \n        set up to PXE only after local boot fails, this option isn't even relevant.\n        \"\"\"\n        self.netboot_enabled = utils.input_boolean(netboot_enabled)\n        return True\n\n    def set_kickstart(self,kickstart):\n        \"\"\"\n        Sets the kickstart.  This must be a NFS, HTTP, or FTP URL.\n        Or filesystem path. Minor checking of the URL is performed here.\n\n        NOTE -- usage of the --kickstart parameter in the profile\n        is STRONGLY encouraged.  This is only for exception cases\n        where a user already has kickstarts made for each system\n        and can't leverage templating.  Profiles provide an important\n        abstraction layer -- assigning systems to defined and repeatable \n        roles.\n        \"\"\"\n        if kickstart is None or kickstart in [ \"\", \"delete\", \"<<inherit>>\" ]:\n            self.kickstart = \"<<inherit>>\"\n            return True\n        kickstart = utils.find_kickstart(kickstart)\n        if kickstart:\n            self.kickstart = kickstart\n            return True\n        raise CX(_(\"kickstart not found: %s\" % kickstart))\n\n\n    def set_power_type(self, power_type):\n        # FIXME: modularize this better\n        if power_type is None:\n            power_type = \"\"\n        choices = utils.get_power_types()\n        choices.sort()\n        if power_type not in choices:\n            raise CX(\"power management type must be one of: %s\" % \",\".join(choices))\n        self.power_type = power_type\n        return True\n\n    def set_power_user(self, power_user):\n        if power_user is None:\n           power_user = \"\"\n        utils.safe_filter(power_user)\n        self.power_user = power_user\n        return True \n\n    def set_power_pass(self, power_pass):\n        if power_pass is None:\n           power_pass = \"\"\n        utils.safe_filter(power_pass)\n        self.power_pass = power_pass\n        return True    \n\n    def set_power_address(self, power_address):\n        if power_address is None:\n           power_address = \"\"\n        utils.safe_filter(power_address)\n        self.power_address = power_address\n        return True\n\n    def set_power_id(self, power_id):\n        if power_id is None:\n           power_id = \"\"\n        utils.safe_filter(power_id)\n        self.power_id = power_id\n        return True\n\n    def modify_interface(self, hash):\n        \"\"\"\n        Used by the WUI to modify an interface more-efficiently\n        \"\"\"\n        for (key,value) in hash.iteritems():\n            (field,interface) = key.split(\"-\")\n            field = field.replace(\"_\",\"\").replace(\"-\",\"\")\n            if field == \"macaddress\"          : self.set_mac_address(value, interface)\n            if field == \"mtu\"                 : self.set_mtu(value, interface)\n            if field == \"ipaddress\"           : self.set_ip_address(value, interface)\n            if field == \"dnsname\"             : self.set_dns_name(value, interface)\n            if field == \"static\"              : self.set_static(value, interface)\n            if field == \"dhcptag\"             : self.set_dhcp_tag(value, interface)\n            if field == \"netmask\"             : self.set_netmask(value, interface)\n            if field == \"subnet\"              : self.set_netmask(value, interface)\n            if field == \"virtbridge\"          : self.set_virt_bridge(value, interface)\n            if field == \"interfacetype\"       : self.set_interface_type(value, interface)\n            if field == \"interfacemaster\"     : self.set_interface_master(value, interface)\n            if field == \"bonding\"             : self.set_interface_type(value, interface)   # deprecated\n            if field == \"bondingmaster\"       : self.set_interface_master(value, interface) # deprecated\n            if field == \"bondingopts\"         : self.set_bonding_opts(value, interface)\n            if field == \"bridgeopts\"          : self.set_bridge_opts(value, interface)\n            if field == \"management\"          : self.set_management(value, interface)\n            if field == \"staticroutes\"        : self.set_static_routes(value, interface)\n            if field == \"ipv6address\"         : self.set_ipv6_address(value, interface)\n            if field == \"ipv6secondaries\"     : self.set_ipv6_secondaries(value, interface)\n            if field == \"ipv6mtu\"             : self.set_ipv6_mtu(value, interface)\n            if field == \"ipv6staticroutes\"    : self.set_ipv6_static_routes(value, interface)\n            if field == \"ipv6defaultgateway\"  : self.set_ipv6_default_gateway(value, interface)\n\n        return True\n\n    def check_if_valid(self):\n        if self.name is None or self.name == \"\":\n            raise CX(\"name is required\")\n        if self.profile is None or self.profile == \"\":\n            if self.image is None or self.image == \"\":\n                raise CX(\"Error with system %s - profile or image is required\" % (self.name))\n            \n    def set_template_remote_kickstarts(self, template):\n        \"\"\"\n        Sets whether or not the server is configured to template remote \n        kickstarts.\n        \"\"\"\n        self.template_remote_kickstarts = utils.input_boolean(template)\n        return True\n    \n    def set_monit_enabled(self,monit_enabled):\n        \"\"\"\n        If true, allows per-system to start Monit to monitor system services such as apache.\n        If monit is not running it will start the service.\n        \n        If false, no management of monit will take place. If monit is not running it will not\n        be started. If monit is running it will not be stopped or restarted.\n        \"\"\"\n        self.monit_enabled = utils.input_boolean(monit_enabled)\n        return True\n    \n    def set_ldap_enabled(self,ldap_enabled):\n        \"\"\"\n        If true, allows per-system to start Monit to monitor system services such as apache.\n        If monit is not running it will start the service.\n        \n        If false, no management of monit will take place. If monit is not running it will not\n        be started. If monit is running it will not be stopped or restarted.\n        \"\"\"\n        self.ldap_enabled = utils.input_boolean(ldap_enabled)\n        return True\n    \n    def set_repos_enabled(self,repos_enabled):\n        \"\"\"\n        If true, allows per-system to start Monit to monitor system services such as apache.\n        If monit is not running it will start the service.\n        \n        If false, no management of monit will take place. If monit is not running it will not\n        be started. If monit is running it will not be stopped or restarted.\n        \"\"\"\n        self.repos_enabled = utils.input_boolean(repos_enabled)\n        return True\n    \n    def set_ldap_type(self, ldap_type):\n        if ldap_type is None:\n            ldap_type = \"\"\n        ldap_type = ldap_type.lower()\n        self.ldap_type = ldap_type\n        return True\n\n\n", "\"\"\"\nMisc heavy lifting functions for cobbler\n\nCopyright 2006-2009, Red Hat, Inc and Others\nMichael DeHaan <michael.dehaan AT gmail>\n\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA\n02110-1301  USA\n\"\"\"\n\nimport sys\nimport os\nimport re\nimport copy\nimport socket\nimport glob\nimport random\ntry:\n    import subprocess as sub_process\nexcept:\n    import sub_process\nimport shutil\nimport string\nimport traceback\nimport errno\nimport logging\nimport shutil\nimport tempfile\nimport signal\nfrom cexceptions import *\nimport codes\nimport time\nimport netaddr\nimport shlex\nimport field_info\nimport clogger\nimport yaml\nimport urllib2\nimport simplejson\n\ntry:\n    import hashlib as fiver\n    def md5(key):\n        return fiver.md5(key)\nexcept ImportError: \n    # for Python < 2.5\n    import md5 as fiver\n    def md5(key):\n        return fiver.md5(key)\n\n# python-netaddr 0.7 broke backward compatability, try to use the old IP\n# classes, and fallback on the newer if there's an import error.\nNETADDR_PRE_0_7 = True\ntry:\n    # Try importing the old (pre-0.7) netaddr IP class:\n    from netaddr import IP\nexcept ImportError:\n    NETADDR_PRE_0_7 = False\n\nCHEETAH_ERROR_DISCLAIMER=\"\"\"\n# *** ERROR ***\n#\n# There is a templating error preventing this file from rendering correctly. \n#\n# This is most likely not due to a bug in Cobbler and is something you can fix.\n#\n# Look at the message below to see what things are causing problems.  \n#\n# (1) Does the template file reference a $variable that is not defined?\n# (2) is there a formatting error in a Cheetah directive?\n# (3) Should dollar signs ($) be escaped that are not being escaped?\n#\n# Try fixing the problem and then investigate to see if this message goes\n# away or changes.\n#\n\"\"\"\n\n# From http://code.activestate.com/recipes/303342/\nclass Translator:\n    allchars = string.maketrans('','')\n    def __init__(self, frm='', to='', delete='', keep=None):\n        if len(to) == 1:\n            to = to * len(frm)\n        self.trans = string.maketrans(frm, to)\n        if keep is None:\n            self.delete = delete\n        else:\n            self.delete = self.allchars.translate(self.allchars, keep.translate(self.allchars, delete))\n    def __call__(self, s):\n        return s.translate(self.trans, self.delete)\n\n\n#placeholder for translation\ndef _(foo):\n   return foo\n\nMODULE_CACHE = {}\n\n_re_kernel = re.compile(r'(vmlinu[xz]|kernel.img)')\n_re_initrd = re.compile(r'(initrd(.*).img|ramdisk.image.gz)')\n\n# all logging from utils.die goes to the main log even if there\n# is another log.\nmain_logger = None #  the logger will be lazy loaded later\n\ndef die(logger, msg):\n    global main_logger\n    if main_logger is None:\n        main_logger = clogger.Logger()\n\n    # log the exception once in the per-task log or the main\n    # log if this is not a background op.\n    try:\n       raise CX(msg)\n    except:\n       if logger is not None:\n           log_exc(logger)\n       else:\n           log_exc(main_logger)\n\n    # now re-raise it so the error can fail the operation\n    raise CX(msg)\n\ndef log_exc(logger):\n    \"\"\"\n    Log an exception.\n    \"\"\"\n    (t, v, tb) = sys.exc_info()\n    logger.info(\"Exception occured: %s\" % t )\n    logger.info(\"Exception value: %s\" % v)\n    logger.info(\"Exception Info:\\n%s\" % string.join(traceback.format_list(traceback.extract_tb(tb))))\n   \n\ndef get_exc(exc,full=True):\n   (t, v, tb) = sys.exc_info()\n   buf = \"\"\n   try:\n      getattr(exc, \"from_cobbler\")\n      buf = str(exc)[1:-1] + \"\\n\"\n   except:\n      if not full:\n          buf = buf + str(t)\n      buf = \"%s\\n%s\" % (buf,v)\n      if full:\n          buf = buf + \"\\n\" + \"\\n\".join(traceback.format_list(traceback.extract_tb(tb)))\n   return buf\n\ndef cheetah_exc(exc,full=False):\n   lines = get_exc(exc).split(\"\\n\")\n   buf = \"\"\n   for l in lines:\n      buf = buf + \"# %s\\n\" % l\n   return CHEETAH_ERROR_DISCLAIMER + buf\n\ndef trace_me():\n   x = traceback.extract_stack()\n   bar = string.join(traceback.format_list(x))\n   return bar\n\ndef pretty_hex(ip, length=8):\n    \"\"\"\n    Pads an IP object with leading zeroes so that the result is\n    _length_ hex digits.  Also do an upper().\n    \"\"\"\n    hexval = \"%x\" % ip.value\n    if len(hexval) < length:\n        hexval = '0' * (length - len(hexval)) + hexval\n    return hexval.upper()\n\ndef get_host_ip(ip, shorten=True):\n    \"\"\"\n    Return the IP encoding needed for the TFTP boot tree.\n    \"\"\"\n    cidr = None\n\n    if NETADDR_PRE_0_7:\n        ip = netaddr.IP(ip)\n        cidr = ip.cidr()\n    else:\n        ip = netaddr.ip.IPAddress(ip)\n        cidr = netaddr.ip.IPNetwork(ip)\n\n    if len(cidr) == 1: # Just an IP, e.g. a /32\n        return pretty_hex(ip)\n    else:\n        pretty = pretty_hex(cidr[0])\n        if not shorten or len(cidr) <= 8:\n            # not enough to make the last nibble insignificant\n            return pretty\n        else:\n            cutoff = (32 - cidr.prefixlen) / 4\n            return pretty[0:-cutoff]\n\ndef _IP(ip):\n   \"\"\"\n   Returns a netaddr.IP object representing ip.\n   If ip is already an netaddr.IP instance just return it.\n   Else return a new instance\n   \"\"\"\n   ip_class = None\n   if NETADDR_PRE_0_7:\n       ip_class = netaddr.IP\n   else:\n        ip_class = netaddr.ip.IPAddress\n   if isinstance(ip, ip_class) or ip == \"\":\n      return ip\n   else:\n      return ip_class(ip)\n\ndef get_config_filename(sys,interface):\n    \"\"\"\n    The configuration file for each system pxe uses is either\n    a form of the MAC address of the hex version of the IP.  If none\n    of that is available, just use the given name, though the name\n    given will be unsuitable for PXE configuration (For this, check\n    system.is_management_supported()).  This same file is used to store\n    system config information in the Apache tree, so it's still relevant.\n    \"\"\"\n\n    interface = str(interface)\n    if not sys.interfaces.has_key(interface):\n        return None\n\n    if sys.name == \"default\":\n        return \"default\"\n    mac = sys.get_mac_address(interface)\n    ip  = sys.get_ip_address(interface)\n    if mac is not None and mac != \"\":\n        return \"01-\" + \"-\".join(mac.split(\":\")).lower()\n    elif ip is not None and ip != \"\":\n        return get_host_ip(ip)\n    else:\n        return sys.name\n\n\ndef is_ip(strdata):\n    \"\"\"\n    Return whether the argument is an IP address.\n    \"\"\"\n    try:\n        _IP(strdata)\n    except:\n        return False\n    return True\n\n\ndef is_mac(strdata):\n    \"\"\"\n    Return whether the argument is a mac address.\n    \"\"\"\n    # needs testcase\n    if strdata is None:\n        return False\n    if re.search(r'[A-F0-9]{2}:[A-F0-9]{2}:[A-F0-9]{2}:[A-F0-9]{2}:[A-F:0-9]{2}:[A-F:0-9]{2}',strdata, re.IGNORECASE):\n        return True\n    return False\n\ndef get_random_mac(api_handle,virt_type=\"xenpv\"):\n    \"\"\"\n    Generate a random MAC address.\n    from xend/server/netif.py\n    return: MAC address string\n    \"\"\"\n    if virt_type.startswith(\"vmware\"):\n        mac = [ 0x00, 0x50, 0x56,\n            random.randint(0x00, 0x3f),\n            random.randint(0x00, 0xff),\n            random.randint(0x00, 0xff)\n        ]\n    elif virt_type.startswith(\"xen\") or virt_type.startswith(\"qemu\") or virt_type.startswith(\"kvm\"):\n        mac = [ 0x00, 0x16, 0x3e,\n            random.randint(0x00, 0x7f),\n            random.randint(0x00, 0xff),\n            random.randint(0x00, 0xff) \n        ]\n    else:\n        raise CX(\"virt mac assignment not yet supported\")\n\n        \n    mac = ':'.join(map(lambda x: \"%02x\" % x, mac))\n    systems = api_handle.systems()\n    while ( systems.find(mac_address=mac) ):\n        mac = get_random_mac(api_handle)\n\n    return mac\n\n\ndef resolve_ip(strdata):\n    \"\"\"\n    Resolve the IP address and handle errors...\n    \"\"\"\n    try:\n        return socket.gethostbyname(strdata)\n    except:\n        return None\n\n\ndef find_matching_files(directory,regex):\n    \"\"\"\n    Find all files in a given directory that match a given regex.\n    Can't use glob directly as glob doesn't take regexen.\n    \"\"\"\n    files = glob.glob(os.path.join(directory,\"*\"))\n    results = []\n    for f in files:\n       if regex.match(os.path.basename(f)):\n           results.append(f)\n    return results\n\n\ndef find_highest_files(directory,unversioned,regex):\n    \"\"\"\n    Find the highest numbered file (kernel or initrd numbering scheme)\n    in a given directory that matches a given pattern.  Used for\n    auto-booting the latest kernel in a directory.\n    \"\"\"\n    files = find_matching_files(directory, regex)\n    get_numbers = re.compile(r'(\\d+).(\\d+).(\\d+)')\n    def max2(a, b):\n        \"\"\"Returns the larger of the two values\"\"\"\n        av  = get_numbers.search(os.path.basename(a)).groups()\n        bv  = get_numbers.search(os.path.basename(b)).groups()\n\n        ret = cmp(av[0], bv[0]) or cmp(av[1], bv[1]) or cmp(av[2], bv[2])\n        if ret < 0:\n            return b\n        return a\n\n    if len(files) > 0:\n        return reduce(max2, files)\n\n    # couldn't find a highest numbered file, but maybe there\n    # is just a 'vmlinuz' or an 'initrd.img' in this directory?\n    last_chance = os.path.join(directory,unversioned)\n    if os.path.exists(last_chance):\n        return last_chance\n    return None\n\n\ndef find_kernel(path):\n    \"\"\"\n    Given a directory or a filename, find if the path can be made\n    to resolve into a kernel, and return that full path if possible.\n    \"\"\"\n    if path is None:\n        return None\n\n    if os.path.isfile(path):\n        #filename = os.path.basename(path)\n        #if _re_kernel.match(filename):\n        #   return path\n        #elif filename == \"vmlinuz\":\n        #   return path\n        return path\n\n    elif os.path.isdir(path):\n        return find_highest_files(path,\"vmlinuz\",_re_kernel)\n\n    # For remote URLs we expect an absolute path, and will not\n    # do any searching for the latest:\n    elif file_is_remote(path) and remote_file_exists(path):\n        return path\n\n    return None\n\ndef remove_yum_olddata(path,logger=None):\n    \"\"\"\n    Delete .olddata files that might be present from a failed run\n    of createrepo.  \n    # FIXME: verify this is still being used\n    \"\"\"\n    trythese = [\n        \".olddata\",\n        \".repodata/.olddata\",\n        \"repodata/.oldata\",\n        \"repodata/repodata\"\n    ]\n    for pathseg in trythese:\n        olddata = os.path.join(path, pathseg)\n        if os.path.exists(olddata):\n            if logger is not None:\n                logger.info(\"removing: %s\" % olddata)\n            shutil.rmtree(olddata, ignore_errors=False, onerror=None)  \n\ndef find_initrd(path):\n    \"\"\"\n    Given a directory or a filename, see if the path can be made\n    to resolve into an intird, return that full path if possible.\n    \"\"\"\n    # FUTURE: try to match kernel/initrd pairs?\n    if path is None:\n        return None\n\n    if os.path.isfile(path):\n        #filename = os.path.basename(path)\n        #if _re_initrd.match(filename):\n        #   return path\n        #if filename == \"initrd.img\" or filename == \"initrd\":\n        #   return path\n        return path\n\n    elif os.path.isdir(path):\n        return find_highest_files(path,\"initrd.img\",_re_initrd)\n\n    # For remote URLs we expect an absolute path, and will not\n    # do any searching for the latest:\n    elif file_is_remote(path) and remote_file_exists(path):\n        return path\n\n    return None\n\n\ndef find_kickstart(url):\n    \"\"\"\n    Check if a kickstart url looks like an http, ftp, nfs or local path.\n    If a local path is used, cobbler will copy the kickstart and serve\n    it over http.\n\n    Return None if the url format does not look valid.\n    \"\"\"\n    if url is None:\n        return None\n    x = url.lstrip()\n    for y in [\"http://\", \"nfs://\", \"ftp://\", \"/\"]:\n       # make sure we get a lower-case protocol without \n       # affecting the rest of the string\n       x = re.sub(r\"(?i)%s\" % y, y, x, count=1)\n       if x.startswith(y):\n           if x.startswith(\"/\") and not os.path.isfile(x):\n               return None\n           return x\n    return None\n\n\ndef read_file_contents(file_location, logger=None, fetch_if_remote=False):\n    \"\"\"\n    Reads the contents of a file, which could be referenced locally\n    or as a URI.\n\n    Returns None if file is remote and templating of remote files is \n    disabled.\n\n    Throws a FileNotFoundException if the file does not exist at the\n    specified location.\n    \"\"\"\n\n    # Local files:\n    if file_location.startswith(\"/\"):\n\n        if not os.path.exists(file_location):\n            if logger:\n                logger.warning(\"File does not exist: %s\" % file_location)\n            raise FileNotFoundException(\"%s: %s\" % (_(\"File not found\"), \n                file_location))\n\n        try:\n            f = open(file_location)\n            data = f.read()\n            f.close()\n            return data\n        except:\n            if logger:\n                log_exc(logger)\n            raise\n\n    # Remote files:\n    if not fetch_if_remote:\n        return None\n\n    if file_is_remote(file_location):\n        try:\n            handler = urllib2.urlopen(file_location)\n            data = handler.read()\n            handler.close()\n            return data\n        except urllib2.HTTPError:\n            # File likely doesn't exist\n            if logger:\n                logger.warning(\"File does not exist: %s\" % file_location)\n            raise FileNotFoundException(\"%s: %s\" % (_(\"File not found\"), \n                file_location))\n\n\ndef remote_file_exists(file_url):\n    \"\"\" Return True if the remote file exists. \"\"\"\n    try:\n        handler = urllib2.urlopen(file_url)\n        handler.close()\n        return True\n    except urllib2.HTTPError:\n        # File likely doesn't exist\n        return False\n\n\ndef file_is_remote(file_location):\n    \"\"\" \n    Returns true if the file is remote and referenced via a protocol\n    we support.\n    \"\"\"\n    # TODO: nfs and ftp ok too?\n    file_loc_lc = file_location.lower()\n    for prefix in [\"http://\"]:\n        if file_loc_lc.startswith(prefix):\n            return True\n    return False\n\n\ndef input_string_or_list(options):\n    \"\"\"\n    Accepts a delimited list of stuff or a list, but always returns a list.\n    \"\"\"\n    delim = None\n    if options == \"<<inherit>>\":\n       return \"<<inherit>>\"\n    if options is None or options == \"\" or options == \"delete\":\n       return []\n    elif isinstance(options,list):\n       return options\n    elif isinstance(options,basestring):\n       tokens = options.split(delim)\n       return tokens\n    else:\n       raise CX(_(\"invalid input type\"))\n\ndef input_string_or_hash(options,allow_multiples=True):\n    \"\"\"\n    Older cobbler files stored configurations in a flat way, such that all values for strings.\n    Newer versions of cobbler allow dictionaries.  This function is used to allow loading\n    of older value formats so new users of cobbler aren't broken in an upgrade.\n    \"\"\"\n\n    if options == \"<<inherit>>\":\n        options = {}\n\n    if options is None or options == \"delete\":\n        return (True, {})\n    elif isinstance(options, list):\n        raise CX(_(\"No idea what to do with list: %s\") % options)\n    elif isinstance(options, str):\n        new_dict = {}\n        tokens = shlex.split(options)\n        for t in tokens:\n            tokens2 = t.split(\"=\",1)\n            if len(tokens2) == 1:\n                # this is a singleton option, no value\n                key = tokens2[0]\n                value = None\n            else:\n                key = tokens2[0]\n                value = tokens2[1] \n\n            # if we're allowing multiple values for the same key,\n            # check to see if this token has already been\n            # inserted into the dictionary of values already\n\n            if key in new_dict.keys() and allow_multiples:\n                # if so, check to see if there is already a list of values\n                # otherwise convert the dictionary value to an array, and add\n                # the new value to the end of the list\n                if isinstance(new_dict[key], list):\n                    new_dict[key].append(value)\n                else:\n                    new_dict[key] = [new_dict[key], value]\n            else:\n                new_dict[key] = value\n        # make sure we have no empty entries\n        new_dict.pop('', None)\n        return (True, new_dict)\n    elif isinstance(options, dict):\n        options.pop('',None)\n        return (True, options)\n    else:\n        raise CX(_(\"invalid input type\"))\n\ndef input_boolean(value):\n    value = str(value)\n    if value.lower() in [ \"true\", \"1\", \"on\", \"yes\", \"y\" ]:\n       return True\n    else:\n       return False\n\ndef grab_tree(api_handle, obj):\n    \"\"\"\n    Climb the tree and get every node.\n    \"\"\"\n    settings = api_handle.settings()\n    results = [ obj ]\n    parent = obj.get_parent()\n    while parent is not None:\n       results.append(parent)\n       parent = parent.get_parent()\n    results.append(settings)  \n    return results\n\ndef blender(api_handle,remove_hashes, root_obj):\n    \"\"\"\n    Combine all of the data in an object tree from the perspective\n    of that point on the tree, and produce a merged hash containing\n    consolidated data.\n    \"\"\"\n \n    settings = api_handle.settings()\n    tree = grab_tree(api_handle, root_obj)\n    tree.reverse()  # start with top of tree, override going down\n    results = {}\n    for node in tree:\n        __consolidate(node,results)\n\n    # hack -- s390 nodes get additional default kernel options\n    arch = results.get(\"arch\",\"?\")\n    if arch.startswith(\"s390\"):\n        keyz = settings.kernel_options_s390x.keys()\n        for k in keyz:\n           if not results.has_key(k):\n               results[\"kernel_options\"][k] = settings.kernel_options_s390x[k]\n\n    # Get topmost object to determine which breed we're dealing with\n    parent = root_obj.get_parent()\n    if parent is None:\n        parent = root_obj\n\n    while parent.COLLECTION_TYPE is \"profile\" or parent.COLLECTION_TYPE is \"system\":\n        parent = parent.get_parent()\n\n    breed = parent.breed\n\n    if breed == \"redhat\":\n        # determine if we have room to add kssendmac to the kernel options line\n        kernel_txt = hash_to_string(results[\"kernel_options\"])\n        if len(kernel_txt) < 244:\n            results[\"kernel_options\"][\"kssendmac\"] = None\n\n    # convert post kernel options to string\n    if results.has_key(\"kernel_options_post\"):\n        results[\"kernel_options_post\"] = hash_to_string(results[\"kernel_options_post\"])\n\n\n    # make interfaces accessible without Cheetah-voodoo in the templates\n    # EXAMPLE:  $ip == $ip0, $ip1, $ip2 and so on.\n \n    if root_obj.COLLECTION_TYPE == \"system\":\n        for (name,interface) in root_obj.interfaces.iteritems():\n            for key in interface.keys():\n                results[\"%s_%s\" % (key,name)] = interface[key]\n                # just to keep templates backwards compatibile\n                if name == \"intf0\":\n                    # prevent stomping on profile variables, which really only happens\n                    # with the way we check for virt_bridge, which is a profile setting\n                    # and an interface setting\n                    if not results.has_key(key):\n                        results[key] = interface[key]\n\n    http_port = results.get(\"http_port\",80)\n    if http_port not in (80, \"80\"):\n       results[\"http_server\"] = \"%s:%s\" % (results[\"server\"] , http_port)\n    else:\n       results[\"http_server\"] = results[\"server\"]\n\n    mgmt_parameters = results.get(\"mgmt_parameters\",{})\n    mgmt_parameters.update(results.get(\"ks_meta\", {}))\n    results[\"mgmt_parameters\"] = mgmt_parameters\n \n    # sanitize output for koan and kernel option lines, etc\n    if remove_hashes:\n        results = flatten(results)\n\n    # the password field is inputed as escaped strings but Cheetah\n    # does weird things when expanding it due to multiple dollar signs\n    # so this is the workaround\n    if results.has_key(\"default_password_crypted\"):\n        results[\"default_password_crypted\"] = results[\"default_password_crypted\"].replace(\"\\$\",\"$\")\n\n    # add in some variables for easier templating\n    # as these variables change based on object type\n    if results.has_key(\"interfaces\"):\n        # is a system object\n        results[\"system_name\"]  = results[\"name\"]\n        results[\"profile_name\"] = results[\"profile\"]\n        if results.has_key(\"distro\"):\n            results[\"distro_name\"]  = results[\"distro\"]\n        elif results.has_key(\"image\"):\n            results[\"distro_name\"]  = \"N/A\"\n            results[\"image_name\"]   = results[\"image\"]\n    elif results.has_key(\"distro\"):\n        # is a profile or subprofile object\n        results[\"profile_name\"] = results[\"name\"]\n        results[\"distro_name\"]  = results[\"distro\"]\n    elif results.has_key(\"kernel\"):\n        # is a distro object\n        results[\"distro_name\"]  = results[\"name\"]\n    elif results.has_key(\"file\"):\n        # is an image object\n        results[\"distro_name\"]  = \"N/A\"\n        results[\"image_name\"]   = results[\"name\"]\n\n    return results\n\ndef flatten(data):\n    # convert certain nested hashes to strings.\n    # this is only really done for the ones koan needs as strings\n    # this should not be done for everything\n    if data is None:\n        return None\n    if data.has_key(\"environment\"):\n        data[\"environment\"] = hash_to_string(data[\"environment\"])\n    if data.has_key(\"kernel_options\"):\n        data[\"kernel_options\"] = hash_to_string(data[\"kernel_options\"])\n    if data.has_key(\"kernel_options_post\"):\n        data[\"kernel_options_post\"] = hash_to_string(data[\"kernel_options_post\"])\n    if data.has_key(\"yumopts\"):\n        data[\"yumopts\"]        = hash_to_string(data[\"yumopts\"])\n    if data.has_key(\"ks_meta\"):\n        data[\"ks_meta\"] = hash_to_string(data[\"ks_meta\"])\n    if data.has_key(\"template_files\"):\n        data[\"template_files\"] = hash_to_string(data[\"template_files\"])\n    if data.has_key(\"boot_files\"):\n        data[\"boot_files\"] = hash_to_string(data[\"boot_files\"])\n    if data.has_key(\"fetchable_files\"):\n        data[\"fetchable_files\"] = hash_to_string(data[\"fetchable_files\"])\n    if data.has_key(\"repos\") and isinstance(data[\"repos\"], list):\n        data[\"repos\"]   = \" \".join(data[\"repos\"])\n    if data.has_key(\"rpm_list\") and isinstance(data[\"rpm_list\"], list):\n        data[\"rpm_list\"] = \" \".join(data[\"rpm_list\"])\n\n    # note -- we do not need to flatten \"interfaces\" as koan does not expect\n    # it to be a string, nor do we use it on a kernel options line, etc...\n \n    return data\n\ndef uniquify(seq, idfun=None): \n    # credit: http://www.peterbe.com/plog/uniqifiers-benchmark\n    # FIXME: if this is actually slower than some other way, overhaul it\n    if idfun is None:\n        def idfun(x): \n           return x\n    seen = {}\n    result = []\n    for item in seq:\n        marker = idfun(item)\n        if marker in seen:\n            continue\n        seen[marker] = 1\n        result.append(item)\n    return result\n\ndef __consolidate(node,results):\n    \"\"\"\n    Merge data from a given node with the aggregate of all\n    data from past scanned nodes.  Hashes and arrays are treated\n    specially.\n    \"\"\"\n    node_data =  node.to_datastruct()\n\n    # if the node has any data items labelled <<inherit>> we need to expunge them.\n    # so that they do not override the supernodes.\n    node_data_copy = {}\n    for key in node_data:\n       value = node_data[key]\n       if value != \"<<inherit>>\":\n          if isinstance(value, dict):\n              node_data_copy[key] = value.copy()\n          elif isinstance(value, list):\n              node_data_copy[key] = value[:]\n          else:\n              node_data_copy[key] = value\n\n    for field in node_data_copy:\n\n       data_item = node_data_copy[field] \n       if results.has_key(field):\n \n          # now merge data types seperately depending on whether they are hash, list,\n          # or scalar.\n\n          fielddata = results[field]\n\n          if isinstance(fielddata, dict):\n             # interweave hash results\n             results[field].update(data_item.copy())\n          elif isinstance(fielddata, list) or isinstance(fielddata, tuple):\n             # add to lists (cobbler doesn't have many lists)\n             # FIXME: should probably uniqueify list after doing this\n             results[field].extend(data_item)\n             results[field] = uniquify(results[field])\n          else:\n             # just override scalars\n             results[field] = data_item\n       else:\n          results[field] = data_item\n\n    # now if we have any \"!foo\" results in the list, delete corresponding\n    # key entry \"foo\", and also the entry \"!foo\", allowing for removal\n    # of kernel options set in a distro later in a profile, etc.\n\n    hash_removals(results,\"kernel_options\")\n    hash_removals(results,\"kernel_options_post\")\n    hash_removals(results,\"ks_meta\")\n    hash_removals(results,\"template_files\")\n    hash_removals(results,\"boot_files\")\n    hash_removals(results,\"fetchable_files\")\n\ndef hash_removals(results,subkey):\n    if not results.has_key(subkey):\n        return\n    scan = results[subkey].keys()\n    for k in scan:\n        if str(k).startswith(\"!\") and k != \"!\":\n           remove_me = k[1:]\n           if results[subkey].has_key(remove_me):\n               del results[subkey][remove_me]\n           del results[subkey][k]\n\ndef hash_to_string(hash):\n    \"\"\"\n    Convert a hash to a printable string.\n    used primarily in the kernel options string\n    and for some legacy stuff where koan expects strings\n    (though this last part should be changed to hashes)\n    \"\"\"\n    buffer = \"\"\n    if not isinstance(hash, dict):\n       return hash\n    for key in hash:\n       value = hash[key]\n       if not value:\n           buffer = buffer + str(key) + \" \"\n       elif isinstance(value, list):\n           # this value is an array, so we print out every\n           # key=value\n           for item in value:\n              buffer = buffer + str(key) + \"=\" + str(item) + \" \"\n       else:\n          buffer = buffer + str(key) + \"=\" + str(value) + \" \"\n    return buffer\n\ndef rsync_files(src, dst, args, logger=None, quiet=True):\n    \"\"\"\n    Sync files from src to dst. The extra arguments specified\n    by args are appended to the command\n    \"\"\"\n\n    if args == None:\n        args = ''\n\n    RSYNC_CMD = \"rsync -a %%s '%%s' %%s %s --exclude-from=/etc/cobbler/rsync.exclude\" % args\n    if quiet:\n        RSYNC_CMD += \" --quiet\"\n    else:\n        RSYNC_CMD += \" --progress\"\n\n    # Make sure we put a \"/\" on the end of the source\n    # and destination to make sure we don't cause any\n    # rsync weirdness\n    if not dst.endswith(\"/\"):\n        dst = \"%s/\" % dst\n    if not src.endswith(\"/\"):\n        src = \"%s/\" % src\n\n    spacer = \"\"\n    if not src.startswith(\"rsync://\") and not src.startswith(\"/\"):\n        spacer = ' -e \"ssh\" '\n\n    rsync_cmd = RSYNC_CMD % (spacer,src,dst)\n    try:\n        res = subprocess_call(logger, rsync_cmd)\n        if res != 0:\n            die(logger, \"Failed to run the rsync command: '%s'\" % rsync_cmd)\n    except:\n        return False\n\n    return True\n\ndef run_this(cmd, args, logger):\n    \"\"\"\n    A simple wrapper around subprocess calls.\n    \"\"\"\n\n    my_cmd = cmd % args\n    rc = subprocess_call(logger,my_cmd,shell=True)\n    if rc != 0:\n        die(logger,\"Command failed\")\n\ndef run_triggers(api,ref,globber,additional=[],logger=None):\n    \"\"\"\n    Runs all the trigger scripts in a given directory.\n    ref can be a cobbler object, if not None, the name will be passed\n    to the script.  If ref is None, the script will be called with\n    no argumenets.  Globber is a wildcard expression indicating which\n    triggers to run.  Example:  \"/var/lib/cobbler/triggers/blah/*\"\n\n    As of Cobbler 1.5.X, this also runs cobbler modules that match the globbing paths.\n    \"\"\"\n\n    # Python triggers first, before shell\n\n    if logger is not None:\n        logger.debug(\"running python triggers from %s\" % globber)\n    modules = api.get_modules_in_category(globber)\n    for m in modules:\n        arglist = []\n        if ref:\n            arglist.append(ref.name)\n        for x in additional:\n       \n            arglist.append(x)\n        if logger is not None:\n            logger.debug(\"running python trigger %s\" % m.__name__)\n        rc = m.run(api, arglist, logger)\n        if rc != 0:\n            raise CX(\"cobbler trigger failed: %s\" % m.__name__)\n\n    # now do the old shell triggers, which are usually going to be slower, but are easier to write  \n    # and support any language\n\n    if logger is not None:\n        logger.debug(\"running shell triggers from %s\" % globber)\n    triggers = glob.glob(globber)\n    triggers.sort()\n    for file in triggers:\n        try:\n            if file.startswith(\".\") or file.find(\".rpm\") != -1:\n                # skip dotfiles or .rpmnew files that may have been installed\n                # in the triggers directory\n                continue\n            arglist = [ file ]\n            if ref:\n                arglist.append(ref.name)\n            for x in additional:\n                if x:\n                    arglist.append(x)\n            if logger is not None:\n                logger.debug(\"running shell trigger %s\" % file)\n            rc = subprocess_call(logger, arglist, shell=False) # close_fds=True)\n        except:\n            if logger is not None:\n                logger.warning(\"failed to execute trigger: %s\" % file)\n            continue\n\n        if rc != 0:\n            raise CX(_(\"cobbler trigger failed: %(file)s returns %(code)d\") % { \"file\" : file, \"code\" : rc })\n\ndef fix_mod_python_select_submission(repos):\n    \"\"\" \n    WARNING: this is a heinous hack to convert mod_python submitted form data\n    to something usable.  Ultimately we need to fix the root cause of this\n    which doesn't seem to happen on all versions of python/mp.\n    \"\"\"\n\n    # should be nice regex, but this is readable :)\n    repos = str(repos)\n    repos = repos.replace(\"'repos'\",\"\")\n    repos = repos.replace(\"'\",\"\")\n    repos = repos.replace(\"[\",\"\")\n    repos = repos.replace(\"]\",\"\")\n    repos = repos.replace(\"Field(\",\"\")\n    repos = repos.replace(\")\",\"\")\n    repos = repos.replace(\",\",\"\")\n    repos = repos.replace('\"',\"\")\n    repos = repos.lstrip().rstrip()\n    return repos\n\ndef check_dist():\n    \"\"\"\n    Determines what distro we're running under.  \n    \"\"\"\n    if os.path.exists(\"/etc/debian_version\"):\n       import lsb_release\n       return lsb_release.get_distro_information()['ID'].lower()\n    elif os.path.exists(\"/etc/SuSE-release\"):\n       return \"suse\"\n    elif os.path.exists(\"/etc/redhat-release\"):\n       # valid for Fedora and all Red Hat / Fedora derivatives\n       return \"redhat\"\n    else:\n       return \"unknown\"\n\ndef os_release():\n\n   if check_dist() == \"redhat\":\n      fh = open(\"/etc/redhat-release\")\n      data = fh.read().lower()\n      if data.find(\"fedora\") != -1:\n         make = \"fedora\"\n      elif data.find(\"centos\") != -1:\n         make = \"centos\"\n      else:\n         make = \"redhat\"\n      release_index = data.find(\"release\") \n      rest = data[release_index+7:-1]\n      tokens = rest.split(\" \")\n      for t in tokens:\n         try:\n             return (make,float(t))\n         except ValueError, ve:\n             pass\n      raise CX(\"failed to detect local OS version from /etc/redhat-release\")\n\n   elif check_dist() == \"debian\":\n      import lsb_release\n      release = lsb_release.get_distro_information()['RELEASE']\n      return (\"debian\", release)\n   elif check_dist() == \"ubuntu\":\n      version = sub_process.check_output((\"lsb_release\",\"--release\",\"--short\")).rstrip()\n      make = \"ubuntu\"\n      return (make, float(version))\n   elif check_dist() == \"suse\":\n      fd = open(\"/etc/SuSE-release\")\n      for line in fd.read().split(\"\\n\"):\n         if line.find(\"VERSION\") != -1:\n            version = line.replace(\"VERSION = \",\"\")\n         if line.find(\"PATCHLEVEL\") != -1:\n            rest = line.replace(\"PATCHLEVEL = \",\"\")\n      make = \"suse\"\n      return (make, float(version))\n   else:\n      return (\"unknown\",0)\n\ndef tftpboot_location():\n\n    # if possible, read from TFTP config file to get the location\n    if os.path.exists(\"/etc/xinetd.d/tftp\"):\n        fd = open(\"/etc/xinetd.d/tftp\")\n        lines = fd.read().split(\"\\n\")\n        for line in lines:\n           if line.find(\"server_args\") != -1:\n              tokens = line.split(None)\n              mark = False\n              for t in tokens:\n                 if t == \"-s\":    \n                    mark = True\n                 elif mark:\n                    return t\n\n    # otherwise, guess based on the distro\n    (make,version) = os_release()\n    if make == \"fedora\" and version >= 9:\n        return \"/var/lib/tftpboot\"\n    elif make ==\"redhat\" and version >= 6:\n        return \"/var/lib/tftpboot\"\n    elif make == \"debian\" or make == \"ubuntu\":\n        return \"/var/lib/tftpboot\"\n    if make == \"suse\":\n        return \"/srv/tftpboot\"\n    return \"/tftpboot\"\n\ndef can_do_public_content(api):\n    \"\"\"\n    Returns whether we can use public_content_t which greatly\n    simplifies SELinux usage.\n    \"\"\"\n    (dist, ver) = api.get_os_details()\n    if dist == \"redhat\" and ver <= 4:\n       return False\n    return True\n\ndef is_safe_to_hardlink(src,dst,api):\n    (dev1, path1) = get_file_device_path(src)\n    (dev2, path2) = get_file_device_path(dst)\n    if dev1 != dev2:\n       return False\n    if dev1.find(\":\") != -1:\n       # is remoted\n       return False\n    # note: this is very cobbler implementation specific!\n    if not api.is_selinux_enabled():\n       return True\n    if _re_initrd.match(os.path.basename(path1)):\n       return True\n    if _re_kernel.match(os.path.basename(path1)):\n       return True\n    # we're dealing with SELinux and files that are not safe to chcon\n    return False\n\ndef hashfile(fn, lcache=None, logger=None):\n    \"\"\"\n    Returns the sha1sum of the file\n    \"\"\"\n\n    db = {}\n    try:\n        dbfile = os.path.join(lcache,'link_cache.json')\n        if os.path.exists(dbfile):\n            db = simplejson.load(open(dbfile, 'r'))\n    except:\n        pass\n\n    mtime = os.stat(fn).st_mtime\n    if db.has_key(fn):\n        if db[fn][0] >= mtime:\n            return db[fn][1]\n\n    if os.path.exists(fn):\n        cmd = '/usr/bin/sha1sum %s'%fn\n        key = subprocess_get(logger,cmd).split(' ')[0]\n        if lcache is not None:\n            db[fn] = (mtime,key)\n            simplejson.dump(db, open(dbfile,'w'))\n        return key\n    else:\n        return None\n\ndef cachefile(src, dst, api=None, logger=None):\n    \"\"\"\n    Copy a file into a cache and link it into place.\n    Use this with caution, otherwise you could end up\n    copying data twice if the cache is not on the same device\n    as the destination\n    \"\"\"\n    lcache = os.path.join(os.path.dirname(os.path.dirname(dst)),'.link_cache')\n    if not os.path.isdir(lcache):\n        os.mkdir(lcache)\n    key = hashfile(src, lcache=lcache, logger=logger)\n    cachefile = os.path.join(lcache, key)\n    if not os.path.exists(cachefile):\n        logger.info(\"trying to create cache file %s\"%cachefile)\n        copyfile(src,cachefile,api=api,logger=logger)\n\n    logger.debug(\"trying cachelink %s -> %s -> %s\"%(src,cachefile,dst))\n    rc = os.link(cachefile,dst)\n    return rc\n\ndef linkfile(src, dst, symlink_ok=False, cache=True, api=None, logger=None):\n    \"\"\"\n    Attempt to create a link dst that points to src.  Because file\n    systems suck we attempt several different methods or bail to\n    copyfile()\n    \"\"\"\n\n    if api is None:\n        # FIXME: this really should not be a keyword\n        # arg\n        raise \"Internal error: API handle is required\"\n\n    is_remote = is_remote_file(src)\n\n    if os.path.exists(dst):\n        # if the destination exists, is it right in terms of accuracy\n        # and context?\n        if os.path.samefile(src, dst):\n            if not is_safe_to_hardlink(src,dst,api):\n                # may have to remove old hardlinks for SELinux reasons\n                # as previous implementations were not complete\n                if logger is not None:\n                   logger.info(\"removing: %s\" % dst)\n                os.remove(dst)\n            else:\n                return True\n        elif os.path.islink(dst):\n            # existing path exists and is a symlink, update the symlink\n            if logger is not None:\n               logger.info(\"removing: %s\" % dst)\n            os.remove(dst)\n\n    if is_safe_to_hardlink(src,dst,api):\n        # we can try a hardlink if the destination isn't to NFS or Samba\n        # this will help save space and sync time.\n        try:\n            if logger is not None:\n                logger.info(\"trying hardlink %s -> %s\" % (src,dst))\n            rc = os.link(src, dst)\n            return rc\n        except (IOError, OSError):\n            # hardlink across devices, or link already exists\n            # we'll just symlink it if we can\n            # or otherwise copy it\n            pass\n\n    if symlink_ok:\n        # we can symlink anywhere except for /tftpboot because\n        # that is run chroot, so if we can symlink now, try it.\n        try:\n            if logger is not None:\n                logger.info(\"trying symlink %s -> %s\" % (src,dst))\n            rc = os.symlink(src, dst)\n            return rc\n        except (IOError, OSError):\n            pass\n\n    if cache:\n        try:\n            return cachefile(src,dst,api=api,logger=logger)\n        except (IOError, OSError):\n            pass\n\n    # we couldn't hardlink and we couldn't symlink so we must copy\n\n    return copyfile(src, dst, api=api, logger=logger)\n\ndef copyfile(src,dst,api=None,logger=None):\n    try:\n        if logger is not None:\n           logger.info(\"copying: %s -> %s\" % (src,dst))\n        rc = shutil.copyfile(src,dst)\n        return rc\n    except:\n        if not os.access(src,os.R_OK):\n            raise CX(_(\"Cannot read: %s\") % src)\n        if not os.path.samefile(src,dst):\n            # accomodate for the possibility that we already copied\n            # the file as a symlink/hardlink\n            raise\n            # traceback.print_exc()\n            # raise CX(_(\"Error copying %(src)s to %(dst)s\") % { \"src\" : src, \"dst\" : dst})\n\ndef check_openfiles(src):\n    \"\"\"\n    Used to check for open files on a mounted partition.\n    \"\"\"\n    try:\n        if not os.path.isdir(src):\n            raise CX(_(\"Error in check_openfiles: the source (%s) must be a directory\") % src)\n        cmd = [ \"/usr/sbin/lsof\", \"+D\", src, \"-Fn\", \"|\", \"wc\", \"-l\" ]\n        handle = sub_process.Popen(cmd, shell=True, stdout=sub_process.PIPE, close_fds=True)\n        out = handle.stdout\n        results = out.read()\n        return int(results)\n    except:\n        if not os.access(src,os.R_OK):\n            raise CX(_(\"Cannot read: %s\") % src)\n        if not os.path.samefile(src,dst):\n            # accomodate for the possibility that we already copied\n            # the file as a symlink/hardlink\n            raise\n\n\ndef copyfile_pattern(pattern,dst,require_match=True,symlink_ok=False,cache=True,api=None,logger=None):\n    files = glob.glob(pattern)\n    if require_match and not len(files) > 0:\n        raise CX(_(\"Could not find files matching %s\") % pattern)\n    for file in files:\n        base = os.path.basename(file)\n        dst1 = os.path.join(dst,os.path.basename(file))\n        linkfile(file,dst1,symlink_ok=symlink_ok,cache=cache,api=api,logger=logger)\n\ndef rmfile(path,logger=None):\n    try:\n        if logger is not None:\n           logger.info(\"removing: %s\" % path)\n        os.unlink(path)\n        return True\n    except OSError, ioe:\n        if not ioe.errno == errno.ENOENT: # doesn't exist\n            if logger is not None:\n                log_exc(logger)\n            raise CX(_(\"Error deleting %s\") % path)\n        return True\n\ndef rmtree_contents(path,logger=None):\n   what_to_delete = glob.glob(\"%s/*\" % path)\n   for x in what_to_delete:\n       rmtree(x,logger=logger)\n\ndef rmtree(path,logger=None):\n   try:\n       if os.path.isfile(path):\n           return rmfile(path,logger=logger)\n       else:\n           if logger is not None:\n               logger.info(\"removing: %s\" % path)\n           return shutil.rmtree(path,ignore_errors=True)\n   except OSError, ioe:\n       if logger is not None:\n           log_exc(logger)\n       if not ioe.errno == errno.ENOENT: # doesn't exist\n           raise CX(_(\"Error deleting %s\") % path)\n       return True\n\ndef mkdir(path,mode=0755,logger=None):\n   try:\n       if logger is not None:\n          logger.info(\"mkdir: %s\" % path)\n       return os.makedirs(path,mode)\n   except OSError, oe:\n       if not oe.errno == 17: # already exists (no constant for 17?)\n           if logger is not None:\n               log_exc(logger)\n           raise CX(_(\"Error creating %s\") % path)\n\ndef path_tail(apath, bpath):\n    \"\"\"\n    Given two paths (B is longer than A), find the part in B not in A\n    \"\"\"\n    position = bpath.find(apath)\n    if position != 0:\n        return \"\"\n    rposition = position + len(apath)\n    result = bpath[rposition:]\n    if not result.startswith(\"/\"):\n        result = \"/\" + result\n    return result\n\ndef set_redhat_management_key(self,key):\n   self.redhat_management_key = key\n   return True\n\ndef set_redhat_management_server(self,server):\n   self.redhat_management_server = server\n   return True\n\ndef set_arch(self,arch,repo=False):\n   if arch is None or arch == \"\" or arch == \"standard\" or arch == \"x86\":\n       arch = \"i386\"\n\n   if repo:\n       valids = [ \"i386\", \"x86_64\", \"ia64\", \"ppc\", \"ppc64\", \"s390\", \"s390x\", \"noarch\", \"src\", \"arm\" ]\n   else:\n       valids = [ \"i386\", \"x86_64\", \"ia64\", \"ppc\", \"ppc64\", \"s390\", \"s390x\", \"arm\" ]\n\n   if arch in valids:\n       self.arch = arch\n       return True\n\n   raise CX(\"arch choices include: %s\" % \", \".join(valids))\n\ndef set_os_version(self,os_version):\n   if os_version == \"\" or os_version is None:\n      self.os_version = \"\"\n      return True\n   self.os_version = os_version.lower()\n   if self.breed is None or self.breed == \"\":\n      raise CX(_(\"cannot set --os-version without setting --breed first\"))\n   if not self.breed in codes.VALID_OS_BREEDS:\n      raise CX(_(\"fix --breed first before applying this setting\"))\n   matched = codes.VALID_OS_VERSIONS[self.breed]\n   if not os_version in matched:\n      nicer = \", \".join(matched)\n      raise CX(_(\"--os-version for breed %s must be one of %s, given was %s\") % (self.breed, nicer, os_version))\n   self.os_version = os_version\n   return True\n\ndef set_breed(self,breed):\n   valid_breeds = codes.VALID_OS_BREEDS\n   if breed is not None and breed.lower() in valid_breeds:\n       self.breed = breed.lower()\n       return True\n   nicer = \", \".join(valid_breeds)\n   raise CX(_(\"invalid value for --breed (%s), must be one of %s, different breeds have different levels of support\") % (breed, nicer))\n\ndef set_repo_os_version(self,os_version):\n   if os_version == \"\" or os_version is None:\n      self.os_version = \"\"\n      return True\n   self.os_version = os_version.lower()\n   if self.breed is None or self.breed == \"\":\n      raise CX(_(\"cannot set --os-version without setting --breed first\"))\n   if not self.breed in codes.VALID_REPO_BREEDS:\n      raise CX(_(\"fix --breed first before applying this setting\"))\n   self.os_version = os_version\n   return True\n\ndef set_repo_breed(self,breed):\n   valid_breeds = codes.VALID_REPO_BREEDS\n   if breed is not None and breed.lower() in valid_breeds:\n       self.breed = breed.lower()\n       return True\n   nicer = \", \".join(valid_breeds)\n   raise CX(_(\"invalid value for --breed (%s), must be one of %s, different breeds have different levels of support\") % (breed, nicer))\n\ndef set_repos(self,repos,bypass_check=False):\n   # WARNING: hack\n   # repos = fix_mod_python_select_submission(repos)\n\n   # allow the magic inherit string to persist\n   if repos == \"<<inherit>>\":\n        self.repos = \"<<inherit>>\"\n        return True\n\n   # store as an array regardless of input type\n   if repos is None:\n        self.repos = []\n   else:\n        self.repos = input_string_or_list(repos)\n   if bypass_check:\n       return True\n\n   for r in self.repos:\n       if self.config.repos().find(name=r) is None:\n          raise CX(_(\"repo %s is not defined\") % r)\n\n   return True\n\ndef set_virt_file_size(self,num):\n    \"\"\"\n    For Virt only.\n    Specifies the size of the virt image in gigabytes.  \n    Older versions of koan (x<0.6.3) interpret 0 as \"don't care\"\n    Newer versions (x>=0.6.4) interpret 0 as \"no disks\"\n    \"\"\"\n    # num is a non-negative integer (0 means default)\n    # can also be a comma seperated list -- for usage with multiple disks\n\n    if num is None or num == \"\":\n        self.virt_file_size = 0\n        return True\n\n    if num == \"<<inherit>>\":\n        self.virt_file_size = \"<<inherit>>\"\n        return True\n\n    if isinstance(num, str) and num.find(\",\") != -1:\n        tokens = num.split(\",\")\n        for t in tokens:\n            # hack to run validation on each\n            self.set_virt_file_size(t)\n        # if no exceptions raised, good enough\n        self.virt_file_size = num\n        return True\n\n    try:\n        inum = int(num)\n        if inum != float(num):\n            return CX(_(\"invalid virt file size (%s)\" % num))\n        if inum >= 0:\n            self.virt_file_size = inum\n            return True\n        raise CX(_(\"invalid virt file size (%s)\" % num))\n    except:\n        raise CX(_(\"invalid virt file size (%s)\" % num))\n    return True\n\ndef set_virt_disk_driver(self,driver):\n    \"\"\"\n    For Virt only.\n    Specifies the on-disk format for the virtualized disk\n    \"\"\"\n    # FIXME: we should probably check the driver type\n    #        here against the libvirt/virtinst list of\n    #        drivers, but this makes things more flexible\n    #        meaning we don't have to manage this list\n    #        and it's up to the user not to enter an\n    #        unsupported disk format\n    self.virt_disk_driver = driver\n    return True\n\ndef set_virt_auto_boot(self,num):\n    \"\"\"\n    For Virt only.\n    Specifies whether the VM should automatically boot upon host reboot\n    0 tells Koan not to auto_boot virtuals\n    \"\"\"\n\n    if num == \"<<inherit>>\":\n        self.virt_auto_boot = \"<<inherit>>\"\n        return True\n\n    # num is a non-negative integer (0 means default)\n    try:\n        inum = int(num)\n        if (inum == 0) or (inum == 1):\n            self.virt_auto_boot = inum\n            return True\n        return CX(_(\"invalid virt_auto_boot value (%s): value must be either '0' (disabled) or '1' (enabled)\" % inum))\n    except:\n        return CX(_(\"invalid virt_auto_boot value (%s): value must be either '0' (disabled) or '1' (enabled)\" % inum))\n    return True\n\ndef set_virt_ram(self,num):\n    \"\"\"\n    For Virt only.\n    Specifies the size of the Virt RAM in MB.\n    0 tells Koan to just choose a reasonable default.\n    \"\"\"\n\n    if num == \"<<inherit>>\":\n        self.virt_ram = \"<<inherit>>\"\n        return True\n\n    # num is a non-negative integer (0 means default)\n    try:\n        inum = int(num)\n        if inum != float(num):\n            return CX(_(\"invalid virt ram size (%s)\" % num))\n        if inum >= 0:\n            self.virt_ram = inum\n            return True\n        return CX(_(\"invalid virt ram size (%s)\" % num))\n    except:\n        return CX(_(\"invalid virt ram size (%s)\" % num))\n    return True\n\ndef set_virt_type(self,vtype):\n    \"\"\"\n    Virtualization preference, can be overridden by koan.\n    \"\"\"\n\n    if vtype == \"<<inherit>>\":\n        self.virt_type == \"<<inherit>>\"\n        return True\n\n    if vtype.lower() not in [ \"qemu\", \"kvm\", \"xenpv\", \"xenfv\", \"vmware\", \"vmwarew\", \"auto\" ]:\n        raise CX(_(\"invalid virt type (%s)\" % vtype))\n    self.virt_type = vtype\n    return True\n\ndef set_virt_bridge(self,vbridge):\n    \"\"\"\n    The default bridge for all virtual interfaces under this profile.\n    \"\"\"\n    if vbridge is None or vbridge == \"\":\n       vbridge = self.settings.default_virt_bridge\n    self.virt_bridge = vbridge\n    return True\n\ndef set_virt_path(self,path,for_system=False):\n    \"\"\"\n    Virtual storage location suggestion, can be overriden by koan.\n    \"\"\"\n    if path is None:\n       path = \"\"\n    if for_system:\n       if path == \"\":\n          path = \"<<inherit>>\"\n    self.virt_path = path\n    return True\n\ndef set_virt_cpus(self,num):\n    \"\"\"\n    For Virt only.  Set the number of virtual CPUs to give to the\n    virtual machine.  This is fed to virtinst RAW, so cobbler\n    will not yelp if you try to feed it 9999 CPUs.  No formatting\n    like 9,999 please :)\n    \"\"\"\n    if num == \"\" or num is None:\n        self.virt_cpus = 1\n        return True\n\n    if num == \"<<inherit>>\":\n        self.virt_cpus = \"<<inherit>>\"\n        return True\n\n    try:\n        num = int(str(num))\n    except:\n        raise CX(_(\"invalid number of virtual CPUs (%s)\" % num))\n\n    self.virt_cpus = num\n    return True\n\ndef get_kickstart_templates(api):\n    files = {}\n    for x in api.profiles():\n        if x.kickstart is not None and x.kickstart != \"\" and x.kickstart != \"<<inherit>>\":\n            if os.path.exists(x.kickstart):\n                files[x.kickstart] = 1\n    for x in api.systems():\n        if x.kickstart is not None and x.kickstart != \"\" and x.kickstart != \"<<inherit>>\":\n            if os.path.exists(x.kickstart):\n                files[x.kickstart] = 1\n    for x in glob.glob(\"/var/lib/cobbler/kickstarts/*\"):\n        if os.path.isfile(x):\n            files[x] = 1\n    for x in glob.glob(\"/etc/cobbler/*.ks\"):\n        if os.path.isfile(x):\n            files[x] = 1\n\n    results = files.keys()\n    results.sort()\n    return results\n\ndef safe_filter(var):\n    if var is None:\n       return\n    if var.find(\"..\") != -1 or var.find(\";\") != -1:\n       raise CX(\"Invalid characters found in input\")\n\ndef is_selinux_enabled():\n    if not os.path.exists(\"/usr/sbin/selinuxenabled\"):\n       return False\n    args = \"/usr/sbin/selinuxenabled\"\n    selinuxenabled = sub_process.call(args,close_fds=True)\n    if selinuxenabled == 0:\n        return True\n    else:\n        return False\n\nimport os\nimport sys\nimport random\n\n# We cache the contents of /etc/mtab ... the following variables are used \n# to keep our cache in sync\nmtab_mtime = None\nmtab_map = []\n\nclass MntEntObj(object):\n    mnt_fsname = None #* name of mounted file system */\n    mnt_dir = None    #* file system path prefix */\n    mnt_type = None   #* mount type (see mntent.h) */\n    mnt_opts = None   #* mount options (see mntent.h) */\n    mnt_freq = 0      #* dump frequency in days */\n    mnt_passno = 0    #* pass number on parallel fsck */\n\n    def __init__(self,input=None):\n        if input and isinstance(input, str):\n            (self.mnt_fsname, self.mnt_dir, self.mnt_type, self.mnt_opts, \\\n             self.mnt_freq, self.mnt_passno) = input.split()\n    def __dict__(self):\n        return {\"mnt_fsname\": self.mnt_fsname, \"mnt_dir\": self.mnt_dir, \\\n                \"mnt_type\": self.mnt_type, \"mnt_opts\": self.mnt_opts, \\\n                \"mnt_freq\": self.mnt_freq, \"mnt_passno\": self.mnt_passno}\n    def __str__(self):\n        return \"%s %s %s %s %s %s\" % (self.mnt_fsname, self.mnt_dir, self.mnt_type, \\\n                                      self.mnt_opts, self.mnt_freq, self.mnt_passno)\n\ndef get_mtab(mtab=\"/etc/mtab\", vfstype=None):\n    global mtab_mtime, mtab_map\n\n    mtab_stat = os.stat(mtab)\n    if mtab_stat.st_mtime != mtab_mtime:\n        '''cache is stale ... refresh'''\n        mtab_mtime = mtab_stat.st_mtime\n        mtab_map = __cache_mtab__(mtab)\n\n    # was a specific fstype requested?\n    if vfstype:\n        mtab_type_map = []\n        for ent in mtab_map:\n            if ent.mnt_type == \"nfs\":\n                mtab_type_map.append(ent)\n        return mtab_type_map\n\n    return mtab_map\n\ndef __cache_mtab__(mtab=\"/etc/mtab\"):\n    global mtab_mtime\n\n    f = open(mtab)\n    mtab = [MntEntObj(line) for line in f.read().split('\\n') if len(line) > 0]\n    f.close()\n\n    return mtab\n\ndef get_file_device_path(fname):\n    '''What this function attempts to do is take a file and return:\n         - the device the file is on\n         - the path of the file relative to the device.\n       For example:\n         /boot/vmlinuz -> (/dev/sda3, /vmlinuz)\n         /boot/efi/efi/redhat/elilo.conf -> (/dev/cciss0, /elilo.conf)\n         /etc/fstab -> (/dev/sda4, /etc/fstab)\n    '''\n\n    # resolve any symlinks\n    fname = os.path.realpath(fname)\n\n    # convert mtab to a dict\n    mtab_dict = {}\n    for ent in get_mtab():\n        mtab_dict[ent.mnt_dir] = ent.mnt_fsname\n\n    # find a best match\n    fdir = os.path.dirname(fname)\n    match = mtab_dict.has_key(fdir)\n    while not match:\n        fdir = os.path.realpath(os.path.join(fdir, os.path.pardir))\n        match = mtab_dict.has_key(fdir)\n\n    # construct file path relative to device\n    if fdir != os.path.sep:\n        fname = fname[len(fdir):]\n\n    return (mtab_dict[fdir], fname)\n\ndef is_remote_file(file):\n    (dev, path) = get_file_device_path(file)\n    if dev.find(\":\") != -1:\n       return True\n    else:\n       return False\n\ndef subprocess_sp(logger, cmd, shell=True):\n    if logger is not None:\n        logger.info(\"running: %s\" % cmd)\n    try:\n        sp = sub_process.Popen(cmd, shell=shell, stdout=sub_process.PIPE, stderr=sub_process.PIPE, close_fds=True)\n    except OSError:\n        if logger is not None:\n            log_exc(logger)\n        die(logger, \"OS Error, command not found?  While running: %s\" % cmd)\n\n    (out,err) = sp.communicate()\n    rc = sp.returncode\n    if logger is not None:\n        logger.info(\"received on stdout: %s\" % out)\n        logger.debug(\"received on stderr: %s\" % err)\n    return out, rc\n\ndef subprocess_call(logger, cmd, shell=True):\n    data, rc = subprocess_sp(logger, cmd, shell=shell)\n    return rc\n\ndef subprocess_get(logger, cmd, shell=True):\n    data, rc = subprocess_sp(logger, cmd, shell=shell)\n    return data\n\ndef popen2(args, **kwargs):\n    \"\"\" \n    Leftovers from borrowing some bits from Snake, replace this \n    function with just the subprocess call.\n    \"\"\"\n    p = sub_process.Popen(args, stdout=sub_process.PIPE, stdin=sub_process.PIPE, **kwargs)\n    return (p.stdout, p.stdin)\n\ndef ram_consumption_of_guests(host, api):\n    guest_names = host.virt_guests\n    ttl_ram = 0\n    if len(guest_names) == 0:\n       # a system with no virt hosts already is our best\n       # candidate\n       return 0\n\n    for g in guest_names:\n       host_obj = api.find_system(g)\n       if host_obj is None:\n          # guest object was deleted but host was not updated\n          continue\n       host_data = blender(api,False,host_obj)\n       ram = host_data.get(\"virt_ram\", 512)\n       ttl_ram = ttl_ram + host_data[\"virt_ram\"]\n    return ttl_ram\n\n\n\ndef choose_virt_host(systems, api):\n    \"\"\"\n    From a list of systems, choose a system that can best host a virtual\n    machine.  This initial engine is not as optimal as it could be, but\n    works by determining the system with the least amount of VM RAM deployed\n    as defined by the amount of virtual ram on each guest for each guest\n    that the hosts hosts.  Hop on pop.  \n\n    This does assume hosts are reasonably homogenous.  In the future\n    this heuristic should be pluggable and be able to tap into other\n    external data sources and maybe basic usage stats.\n    \"\"\"\n     \n    if len(systems) == 0:\n       raise CX(\"empty candidate systems list\")\n    by_name = {}\n    least_host = systems[0] \n    least_host_ct = -1\n    for s in systems:\n       ct = ram_consumption_of_guests(s, api)\n       if (ct < least_host_ct) or (least_host_ct == -1):\n          least_host = s\n          least_host_ct = ct\n    return least_host.name\n\ndef os_system(cmd):\n    \"\"\"\n    os.system doesn't close file descriptors, so this is a wrapper\n    to ensure we never use it.\n    \"\"\"\n    rc = sub_process.call(cmd, shell=True, close_fds=True)\n    return rc\n\ndef clear_from_fields(obj, fields, is_subobject=False):\n    \"\"\"\n    Used by various item_*.py classes for automating datastructure boilerplate.\n    \"\"\"\n    for elems in fields:\n        # if elems startswith * it's an interface field and we do not operate on it.\n        if elems[0].startswith(\"*\") or elems[0].find(\"widget\") != -1:\n           continue\n        if is_subobject:\n           val = elems[2]\n        else:\n           val = elems[1]\n        if isinstance(val,basestring):\n           if val.startswith(\"SETTINGS:\"):\n               setkey = val.split(\":\")[-1]\n               val = getattr(obj.settings, setkey)\n        setattr(obj, elems[0], val)\n\n    if obj.COLLECTION_TYPE == \"system\":\n        obj.interfaces = {}\n\ndef from_datastruct_from_fields(obj, seed_data, fields):\n\n    for elems in fields:\n        # we don't have to load interface fields here\n        if elems[0].startswith(\"*\") or elems[0].find(\"widget\") != -1:\n            continue\n        src_k = dst_k = elems[0]\n        # deprecated field switcheroo\n        if field_info.DEPRECATED_FIELDS.has_key(src_k):\n            dst_k = field_info.DEPRECATED_FIELDS[src_k]\n        if seed_data.has_key(src_k):\n            setattr(obj, dst_k, seed_data[src_k])\n\n    if obj.uid == '':\n        obj.uid = obj.config.generate_uid()\n\n    # special handling for interfaces\n    if obj.COLLECTION_TYPE == \"system\":\n        obj.interfaces = copy.deepcopy(seed_data[\"interfaces\"])\n        # deprecated field switcheroo for interfaces\n        for interface in obj.interfaces.keys():\n            for k in obj.interfaces[interface].keys():\n                if field_info.DEPRECATED_FIELDS.has_key(k):\n                    if not obj.interfaces[interface].has_key(field_info.DEPRECATED_FIELDS[k]) or \\\n                           obj.interfaces[interface][field_info.DEPRECATED_FIELDS[k]] == \"\":\n                        obj.interfaces[interface][field_info.DEPRECATED_FIELDS[k]] = obj.interfaces[interface][k]\n\n    return obj\n\ndef get_methods_from_fields(obj, fields):\n    ds = {}\n    for elem in fields:\n        k = elem[0]\n        # modify interfaces is handled differently, and need not work this way\n        if k.startswith(\"*\") or k.find(\"widget\") != -1:\n            continue\n        setfn = getattr(obj, \"set_%s\" % k)\n        ds[k] = setfn\n    return ds\n\ndef to_datastruct_from_fields(obj, fields):\n    ds = {}\n    for elem in fields:\n        k = elem[0]\n        if k.startswith(\"*\") or k.find(\"widget\") != -1:\n            continue\n        data = getattr(obj, k)\n        ds[k] = data\n    # interfaces on systems require somewhat special handling\n    # they are the only exception in Cobbler.\n    if obj.COLLECTION_TYPE == \"system\":\n        ds[\"interfaces\"] = copy.deepcopy(obj.interfaces)\n        #for interface in ds[\"interfaces\"].keys():\n        #    for k in ds[\"interfaces\"][interface].keys():\n        #        if field_info.DEPRECATED_FIELDS.has_key(k):\n        #            ds[\"interfaces\"][interface][field_info.DEPRECATED_FIELDS[k]] = ds[\"interfaces\"][interface][k]\n\n    return ds\n\ndef printable_from_fields(obj, fields):\n    \"\"\"\n    Obj is a hash datastructure, fields is something like item_distro.FIELDS\n    \"\"\"\n    buf  = \"\"\n    keys = []\n    for elem in fields:\n       keys.append((elem[0], elem[3], elem[4]))\n    keys.sort()\n    buf = buf + \"%-30s : %s\\n\" % (\"Name\", obj[\"name\"])\n    for (k, nicename, editable) in keys:\n       # FIXME: supress fields users don't need to see?\n       # FIXME: interfaces should be sorted\n       # FIXME: print ctime, mtime nicely\n       if k.startswith(\"*\") or not editable or k.find(\"widget\") != -1:\n           continue\n\n       if k != \"name\":\n           # FIXME: move examples one field over, use description here.\n           buf = buf + \"%-30s : %s\\n\" % (nicename, obj[k])\n\n    # somewhat brain-melting special handling to print the hashes\n    # inside of the interfaces more neatly.\n    if obj.has_key(\"interfaces\"):\n       for iname in obj[\"interfaces\"].keys():\n          # FIXME: inames possibly not sorted\n          buf = buf + \"%-30s : %s\\n\" % (\"Interface ===== \",iname)\n          for (k, nicename, editable) in keys:\n             nkey = k.replace(\"*\",\"\")\n             if k.startswith(\"*\") and editable:\n                 buf = buf + \"%-30s : %s\\n\" % (nicename, obj[\"interfaces\"][iname].get(nkey,\"\"))\n\n    return buf\n\ndef matches_args(args, list_of):\n    \"\"\"\n    Used to simplify some code around which arguments to add when.\n    \"\"\"\n    for x in args:\n        if x in list_of:\n            return True\n    return False\n\ndef add_options_from_fields(object_type, parser, fields, object_action):\n    for elem in fields:\n        k = elem[0] \n        if k.find(\"widget\") != -1:\n            continue\n        # scrub interface tags so all fields get added correctly.\n        k = k.replace(\"*\",\"\")\n        default = elem[1]\n        nicename = elem[3]\n        tooltip = elem[5]\n        choices = elem[6]\n        if field_info.ALTERNATE_OPTIONS.has_key(k):\n            niceopt = field_info.ALTERNATE_OPTIONS[k]\n        else:\n            niceopt = \"--%s\" % k.replace(\"_\",\"-\")\n        desc = nicename\n        if tooltip != \"\":\n            desc = nicename + \" (%s)\" % tooltip\n\n        aliasopt = []\n        for deprecated_field in field_info.DEPRECATED_FIELDS.keys():\n            if field_info.DEPRECATED_FIELDS[deprecated_field] == k:\n                aliasopt.append(\"--%s\" % deprecated_field)\n\n        if isinstance(choices, list) and len(choices) != 0:\n            desc = desc + \" (valid options: %s)\" % \",\".join(choices)    \n            parser.add_option(niceopt, dest=k, help=desc, choices=choices)\n            for alias in aliasopt:\n                parser.add_option(alias, dest=k, help=desc, choices=choices)\n        else:\n            parser.add_option(niceopt, dest=k, help=desc)\n            for alias in aliasopt:\n                parser.add_option(alias, dest=k, help=desc)\n\n\n    # FIXME: not supported in 2.0?\n    if not object_action in [\"dumpvars\",\"find\",\"remove\",\"report\",\"list\"]: \n        # FIXME: implement\n        parser.add_option(\"--clobber\", dest=\"clobber\", help=\"allow add to overwrite existing objects\", action=\"store_true\")\n        parser.add_option(\"--in-place\", action=\"store_true\", default=False, dest=\"in_place\", help=\"edit items in kopts or ksmeta without clearing the other items\")\n    if object_action in [\"copy\",\"rename\"]:\n        parser.add_option(\"--newname\", help=\"new object name\")\n    # FIXME: not supported in 2.0 ?\n    #if not object_action in [\"dumpvars\",\"find\",\"remove\",\"report\",\"list\"]: \n    #    parser.add_option(\"--no-sync\",     action=\"store_true\", dest=\"nosync\", help=\"suppress sync for speed\")\n    # FIXME: not supported in 2.0 ?\n    # if not matches_args(args,[\"dumpvars\",\"report\",\"list\"]):\n    #    parser.add_option(\"--no-triggers\", action=\"store_true\", dest=\"notriggers\", help=\"suppress trigger execution\")\n    if object_action in [\"remove\"]:\n        parser.add_option(\"--recursive\", action=\"store_true\", dest=\"recursive\", help=\"also delete child objects\")\n    if object_type == \"system\":\n        # system object\n        parser.add_option(\"--interface\", dest=\"interface\", help=\"which interface to edit\")\n        parser.add_option(\"--delete-interface\", dest=\"delete_interface\", action=\"store_true\")\n\n\ndef get_remote_methods_from_fields(obj,fields):\n    \"\"\"\n    Return the name of set functions for all fields, keyed by the field name.\n    \"\"\"\n    ds = {}\n    for elem in fields:\n       name = elem[0].replace(\"*\",\"\")\n       if name.find(\"widget\") == -1:\n          ds[name] = getattr(obj,\"set_%s\" % name)\n    if obj.COLLECTION_TYPE == \"system\":\n       ds[\"modify_interface\"] = getattr(obj,\"modify_interface\")\n       ds[\"delete_interface\"] = getattr(obj,\"delete_interface\")\n    return ds\n\ndef get_power_types():\n    \"\"\"\n    Return all possible power types\n    \"\"\"\n    power_types = []\n    power_template = re.compile(r'power_(.*).template')\n    for x in glob.glob(\"/etc/cobbler/power/power_*.template\"):\n        power_types.append(power_template.search(x).group(1))\n    power_types.sort()\n    return power_types\n\ndef get_power(powertype=None):\n    \"\"\"\n    Return power command for type\n    \"\"\"\n    if powertype:\n        powerpath = \"/etc/cobbler/power/power_%s.template\" % powertype\n        if os.path.isfile(powerpath):\n            return powerpath\n    return None\n\ndef get_shared_secret():\n    \"\"\"\n    The 'web.ss' file is regenerated each time cobblerd restarts and is\n    used to agree on shared secret interchange between mod_python and\n    cobblerd, and also the CLI and cobblerd, when username/password\n    access is not required.  For the CLI, this enables root users\n    to avoid entering username/pass if on the cobbler server.\n    \"\"\"\n\n    try:\n       fd = open(\"/var/lib/cobbler/web.ss\")\n       data = fd.read()\n    except:\n       return -1\n    return str(data).strip()\n\ndef local_get_cobbler_api_url():\n    # Load server and http port\n    try:\n        fh = open(\"/etc/cobbler/settings\")\n        data = yaml.safe_load(fh.read())\n        fh.close()\n    except:\n       traceback.print_exc()\n       raise CX(\"/etc/cobbler/settings is not a valid YAML file\")\n\n    if data.get(\"client_use_localhost\", False):\n      return \"http://%s:%s/cobbler_api\" % (\"127.0.0.1\",data.get(\"http_port\",\"80\"))\n    else:\n      return \"http://%s:%s/cobbler_api\" % (data.get(\"server\",\"127.0.0.1\"),data.get(\"http_port\",\"80\"))\n\ndef get_ldap_template(ldaptype=None):\n    \"\"\"\n    Return ldap command for type\n    \"\"\"\n    if ldaptype:\n        ldappath = \"/etc/cobbler/ldap/ldap_%s.template\" % ldaptype\n        if os.path.isfile(ldappath):\n            return ldappath\n    return None\n\ndef local_get_cobbler_xmlrpc_url():\n    # Load xmlrpc port\n    try:\n        fh = open(\"/etc/cobbler/settings\")\n        data = yaml.safe_load(fh.read())\n        fh.close()\n    except:\n       traceback.print_exc()\n       raise CX(\"/etc/cobbler/settings is not a valid YAML file\")\n    return \"http://%s:%s\" % (\"127.0.0.1\",data.get(\"xmlrpc_port\",\"25151\"))\n\ndef strip_none(data, omit_none=False):\n    \"\"\"\n    Remove \"none\" entries from datastructures.\n    Used prior to communicating with XMLRPC.\n    \"\"\"\n    if data is None:\n        data = '~'\n\n    elif isinstance(data, list):\n        data2 = []\n        for x in data:\n            if omit_none and x is None:\n                pass\n            else:\n                data2.append(strip_none(x))\n        return data2\n\n    elif isinstance(data, dict):\n        data2 = {}\n        for key in data.keys():\n            keydata = data[key]\n            if omit_none and data[key] is None:\n                pass\n            else:\n                data2[str(key)] = strip_none(data[key])\n        return data2\n\n    return data\n\ndef cli_find_via_xmlrpc(remote, otype, options):\n    \"\"\"\n    Given an options object and a remote handle, find options matching\n    the criteria given.\n    \"\"\"\n    criteria = strip_none2(options.__dict__)\n    return remote.find_items(otype,criteria,\"name\",False)\n\n# -------------------------------------------------------\n    \ndef loh_to_hoh(datastruct, indexkey):\n    \"\"\"\n    things like get_distros() returns a list of a hashes\n    convert this to a hash of hashes keyed off of an arbitrary field\n\n    EX:  [  { \"a\" : 2 }, { \"a : 3 } ]  ->  { \"2\" : { \"a\" : 2 }, \"3\" : { \"a\" : \"3\" }\n\n    \"\"\"\n    results = {}\n    for item in datastruct:\n        results[item[indexkey]] = item\n    return results\n\n# -------------------------------------------------------\n\ndef loh_sort_by_key(datastruct, indexkey):\n    \"\"\"\n    Sorts a list of hashes by a given key in the hashes\n    note: this is a destructive operation\n    \"\"\"\n    datastruct.sort(lambda a, b: a[indexkey] < b[indexkey])\n    return datastruct\n\ndef dhcpconf_location(api):\n    version = api.os_version\n    (dist, ver) = api.get_os_details()\n    if version[0] in [ \"redhat\", \"centos\" ] and version[1] < 6:\n        return \"/etc/dhcpd.conf\"\n    elif version[0] in [ \"fedora\" ] and version[1] < 11: \n        return \"/etc/dhcpd.conf\"\n    elif dist == \"suse\":\n        return \"/etc/dhcpd.conf\"\n    else:\n        return \"/etc/dhcp/dhcpd.conf\"\n\ndef link_distro(settings, distro):\n    # find the tree location\n    base = find_distro_path(settings, distro)\n    if not base:\n        return\n\n    dest_link = os.path.join(settings.webdir, \"links\", distro.name)\n\n    # create the links directory only if we are mirroring because with\n    # SELinux Apache can't symlink to NFS (without some doing)\n\n    if not os.path.lexists(dest_link):\n        try:\n            os.symlink(base, dest_link)\n        except:\n            # this shouldn't happen but I've seen it ... debug ...\n            print _(\"- symlink creation failed: %(base)s, %(dest)s\") % { \"base\" : base, \"dest\" : dest_link }\n\ndef find_distro_path(settings, distro):\n    possible_dirs = glob.glob(settings.webdir+\"/ks_mirror/*\")\n    for dir in possible_dirs:\n        if os.path.dirname(distro.kernel).find(dir) != -1:\n            return os.path.join(settings.webdir, \"ks_mirror\", dir)\n    # non-standard directory, assume it's the same as the\n    # directory in which the given distro's kernel is\n    return os.path.dirname(distro.kernel)\n\nif __name__ == \"__main__\":\n    print os_release() # returns 2, not 3\n\n\n"], "fixing_code": ["\"\"\"\nPower management library.  For cobbler objects with power management configured\nencapsulate the logic to run power management commands so that the admin does not\nhave to use seperate tools and remember how each of the power management tools are\nset up.  This makes power cycling a system for reinstallation much easier.\n\nSee https://github.com/cobbler/cobbler/wiki/Power-management\n\nCopyright 2008-2009, Red Hat, Inc and Others\nMichael DeHaan <michael.dehaan AT gmail>\n\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA\n02110-1301  USA\n\"\"\"\n\n\nimport os\nimport os.path\nimport traceback\nimport time\nimport re\n\nimport utils\nimport func_utils\nfrom cexceptions import *\nimport templar\nimport clogger\n\nclass PowerTool:\n    \"\"\"\n    Handles conversion of internal state to the tftpboot tree layout\n    \"\"\"\n\n    def __init__(self,config,system,api,force_user=None,force_pass=None,logger=None):\n        \"\"\"\n        Power library constructor requires a cobbler system object.\n        \"\"\"\n        self.system      = system\n        self.config      = config\n        self.settings    = config.settings()\n        self.api         = api\n        self.logger      = self.api.logger\n        self.force_user  = force_user\n        self.force_pass  = force_pass\n        if logger is None:\n            logger = clogger.Logger()\n        self.logger      = logger\n\n    def power(self, desired_state):\n        \"\"\"\n        state is either \"on\" or \"off\".  Rebooting is implemented at the api.py\n        level.\n\n        The user and password need not be supplied.  If not supplied they\n        will be taken from the environment, COBBLER_POWER_USER and COBBLER_POWER_PASS.\n        If provided, these will override any other data and be used instead.  Users\n        interested in maximum security should take that route.\n        \"\"\"\n\n        power_command = utils.get_power(self.system.power_type)\n        if not power_command:\n            utils.die(self.logger,\"no power type set for system\")\n\n        meta = utils.blender(self.api, False, self.system)\n        meta[\"power_mode\"] = desired_state\n\n        # allow command line overrides of the username/password \n        if self.force_user is not None:\n           meta[\"power_user\"] = self.force_user\n        if self.force_pass is not None:\n           meta[\"power_pass\"] = self.force_pass\n\n        self.logger.info(\"cobbler power configuration is:\")\n        self.logger.info(\"      type   : %s\" % self.system.power_type)\n        self.logger.info(\"      address: %s\" % self.system.power_address)\n        self.logger.info(\"      user   : %s\" % self.system.power_user)\n        self.logger.info(\"      id     : %s\" % self.system.power_id)\n\n        # if no username/password data, check the environment\n        if meta.get(\"power_user\",\"\") == \"\":\n            meta[\"power_user\"] = os.environ.get(\"COBBLER_POWER_USER\",\"\")\n        if meta.get(\"power_pass\",\"\") == \"\":\n            meta[\"power_pass\"] = os.environ.get(\"COBBLER_POWER_PASS\",\"\")\n\n        template = utils.get_power_template(self.system.power_type)\n        tmp = templar.Templar(self.api._config)\n        template_data = tmp.render(template, meta, None, self.system)\n\n        # Try the power command 5 times before giving up.\n        # Some power switches are flakey\n        for x in range(0,5):\n            output, rc = utils.subprocess_sp(self.logger, power_command, shell=False, input=template_data)\n            if rc == 0:\n                # If the desired state is actually a query for the status\n                # return different information than command return code\n                if desired_state == 'status':\n                    match = re.match('(^Status:\\s)(on|off)', output, re.IGNORECASE)\n                    if match:\n                        power_status = match.groups()[1]\n                        if power_status.lower() == 'on':\n                            return True\n                        else:\n                            return False\n                    utils.die(self.logger,\"command succeeded (rc=%s), but output ('%s') was not understood\" % (rc, output))\n                    return None\n                break\n            else:\n                time.sleep(2)\n\n        if not rc == 0:\n           utils.die(self.logger,\"command failed (rc=%s), please validate the physical setup and cobbler config\" % rc)\n\n        return rc\n\n", "\"\"\"\nA Cobbler System.\n\nCopyright 2006-2009, Red Hat, Inc and Others\nMichael DeHaan <michael.dehaan AT gmail>\n\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA\n02110-1301  USA\n\"\"\"\n\nimport utils\nimport item\nimport time\nfrom cexceptions import *\nfrom utils import _\n\n# this datastructure is described in great detail in item_distro.py -- read the comments there.\n\nFIELDS = [\n  [\"name\",\"\",0,\"Name\",True,\"Ex: vanhalen.example.org\",0,\"str\"],\n  [\"uid\",\"\",0,\"\",False,\"\",0,\"str\"],\n  [\"owners\",\"SETTINGS:default_ownership\",0,\"Owners\",True,\"Owners list for authz_ownership (space delimited)\",0,\"list\"],\n  [\"profile\",None,0,\"Profile\",True,\"Parent profile\",[],\"str\"],\n  [\"image\",None,0,\"Image\",True,\"Parent image (if not a profile)\",0,\"str\"],\n  [\"status\",\"production\",0,\"Status\",True,\"System status\",[\"development\",\"testing\",\"acceptance\",\"production\"],\"str\"],\n  [\"kernel_options\",{},0,\"Kernel Options\",True,\"Ex: selinux=permissive\",0,\"dict\"],\n  [\"kernel_options_post\",{},0,\"Kernel Options (Post Install)\",True,\"Ex: clocksource=pit noapic\",0,\"dict\"],\n  [\"ks_meta\",{},0,\"Kickstart Metadata\",True,\"Ex: dog=fang agent=86\",0,\"dict\"],\n  [\"enable_gpxe\",\"SETTINGS:enable_gpxe\",0,\"Enable gPXE?\",True,\"Use gPXE instead of PXELINUX for advanced booting options\",0,\"bool\"],\n  [\"proxy\",\"<<inherit>>\",0,\"Proxy\",True,\"Proxy URL\",0,\"str\"],\n  [\"netboot_enabled\",True,0,\"Netboot Enabled\",True,\"PXE (re)install this machine at next boot?\",0,\"bool\"],\n  [\"kickstart\",\"<<inherit>>\",0,\"Kickstart\",True,\"Path to kickstart template\",0,\"str\"],\n  [\"comment\",\"\",0,\"Comment\",True,\"Free form text description\",0,\"str\"],\n  [\"depth\",2,0,\"\",False,\"\",0,\"int\"],\n  [\"server\",\"<<inherit>>\",0,\"Server Override\",True,\"See manpage or leave blank\",0,\"str\"],\n  [\"virt_path\",\"<<inherit>>\",0,\"Virt Path\",True,\"Ex: /directory or VolGroup00\",0,\"str\"],\n  [\"virt_type\",\"<<inherit>>\",0,\"Virt Type\",True,\"Virtualization technology to use\",[\"xenpv\",\"xenfv\",\"qemu\",\"kvm\",\"vmware\"],\"str\"],\n  [\"virt_cpus\",\"<<inherit>>\",0,\"Virt CPUs\",True,\"\",0,\"int\"],\n  [\"virt_file_size\",\"<<inherit>>\",0,\"Virt File Size(GB)\",True,\"\",0,\"float\"],\n  [\"virt_disk_driver\",\"<<inherit>>\",0,\"Virt Disk Driver Type\",True,\"The on-disk format for the virtualization disk\",\"raw\",\"str\"],\n  [\"virt_ram\",\"<<inherit>>\",0,\"Virt RAM (MB)\",True,\"\",0,\"int\"],\n  [\"virt_auto_boot\",\"<<inherit>>\",0,\"Virt Auto Boot\",True,\"Auto boot this VM?\",0,\"bool\"],\n  [\"ctime\",0,0,\"\",False,\"\",0,\"float\"],\n  [\"mtime\",0,0,\"\",False,\"\",0,\"float\"],\n  [\"power_type\",\"SETTINGS:power_management_default_type\",0,\"Power Management Type\",True,\"Power management script to use\",utils.get_power_types(),\"str\"],\n  [\"power_address\",\"\",0,\"Power Management Address\",True,\"Ex: power-device.example.org\",0,\"str\"],\n  [\"power_user\",\"\",0,\"Power Management Username \",True,\"\",0,\"str\"],\n  [\"power_pass\",\"\",0,\"Power Management Password\",True,\"\",0,\"str\"],\n  [\"power_id\",\"\",0,\"Power Management ID\",True,\"Usually a plug number or blade name, if power type requires it\",0,\"str\"],\n  [\"hostname\",\"\",0,\"Hostname\",True,\"\",0,\"str\"],\n  [\"gateway\",\"\",0,\"Gateway\",True,\"\",0,\"str\"],\n  [\"name_servers\",[],0,\"Name Servers\",True,\"space delimited\",0,\"list\"],\n  [\"name_servers_search\",[],0,\"Name Servers Search Path\",True,\"space delimited\",0,\"list\"],\n  [\"ipv6_default_device\",\"\",0,\"IPv6 Default Device\",True,\"\",0,\"str\"],\n  [\"ipv6_autoconfiguration\",False,0,\"IPv6 Autoconfiguration\",True,\"\",0,\"bool\"],\n  [\"network_widget_a\",\"\",0,\"Add Interface\",True,\"\",0,\"str\"], # not a real field, a marker for the web app\n  [\"network_widget_b\",\"\",0,\"Edit Interface\",True,\"\",0,\"str\"], # not a real field, a marker for the web app\n  [\"*mac_address\",\"\",0,\"MAC Address\",True,\"(Place \\\"random\\\" in this field for a random MAC Address.)\",0,\"str\"],\n  [\"network_widget_c\",\"\",0,\"\",True,\"\",0,\"str\"], # not a real field, a marker for the web app\n  [\"*mtu\",\"\",0,\"MTU\",True,\"\",0,\"str\"],\n  [\"*ip_address\",\"\",0,\"IP Address\",True,\"\",0,\"str\"],\n  [\"*interface_type\",\"na\",0,\"Interface Type\",True,\"\",[\"na\",\"master\",\"slave\",\"bond\",\"bond_slave\",\"bridge\",\"bridge_slave\"],\"str\"],\n  [\"*interface_master\",\"\",0,\"Master Interface\",True,\"\",0,\"str\"],\n  [\"*bonding_opts\",\"\",0,\"Bonding Opts\",True,\"\",0,\"str\"],\n  [\"*bridge_opts\",\"\",0,\"Bridge Opts\",True,\"\",0,\"str\"],\n  [\"*management\",False,0,\"Management Interface\",True,\"Is this the management interface?\",0,\"bool\"],\n  [\"*static\",False,0,\"Static\",True,\"Is this interface static?\",0,\"bool\"],\n  [\"*netmask\",\"\",0,\"Subnet Mask\",True,\"\",0,\"str\"],\n  [\"*dhcp_tag\",\"\",0,\"DHCP Tag\",True,\"\",0,\"str\"],\n  [\"*dns_name\",\"\",0,\"DNS Name\",True,\"\",0,\"str\"],\n  [\"*static_routes\",[],0,\"Static Routes\",True,\"\",0,\"list\"],\n  [\"*virt_bridge\",\"\",0,\"Virt Bridge\",True,\"\",0,\"str\"],\n  [\"*ipv6_address\",\"\",0,\"IPv6 Address\",True,\"\",0,\"str\"],\n  [\"*ipv6_secondaries\",[],0,\"IPv6 Secondaries\",True,\"space delimited\",0,\"list\"],\n  [\"*ipv6_mtu\",\"\",0,\"IPv6 MTU\",True,\"\",0,\"str\"],\n  [\"*ipv6_static_routes\",[],0,\"IPv6 Static Routes\",True,\"\",0,\"list\"],\n  [\"*ipv6_default_gateway\",\"\",0,\"IPv6 Default Gateway\",True,\"\",0,\"str\"],\n  [\"mgmt_classes\",[],0,\"Management Classes\",True,\"For external config management\",0,\"list\"],\n  [\"mgmt_parameters\",\"<<inherit>>\",0,\"Management Parameters\",True,\"Parameters which will be handed to your management application (Must be valid YAML dictionary)\", 0,\"str\"],\n  [ \"boot_files\",{},'<<inherit>>',\"TFTP Boot Files\",True,\"Files copied into tftpboot beyond the kernel/initrd\",0,\"list\"],\n  [\"fetchable_files\",{},'<<inherit>>',\"Fetchable Files\",True,\"Templates for tftp or wget\",0,\"dict\"],\n  [\"template_files\",{},0,\"Template Files\",True,\"File mappings for built-in configuration management\",0,\"dict\"],\n  [\"redhat_management_key\",\"<<inherit>>\",0,\"Red Hat Management Key\",True,\"Registration key for RHN, Satellite, or Spacewalk\",0,\"str\"],\n  [\"redhat_management_server\",\"<<inherit>>\",0,\"Red Hat Management Server\",True,\"Address of Satellite or Spacewalk Server\",0,\"str\"],\n  [\"template_remote_kickstarts\", \"SETTINGS:template_remote_kickstarts\", \"SETTINGS:template_remote_kickstarts\", \"\", False, \"\", 0, \"bool\"],\n  [\"repos_enabled\",False,0,\"Repos Enabled\",True,\"(re)configure local repos on this machine at next config update?\",0,\"bool\"],\n  [\"ldap_enabled\",False,0,\"LDAP Enabled\",True,\"(re)configure LDAP on this machine at next config update?\",0,\"bool\"],\n  [\"ldap_type\",\"SETTINGS:ldap_management_default_type\",0,\"LDAP Management Type\",True,\"Ex: authconfig\",0,\"str\"],\n  [\"monit_enabled\",False,0,\"Monit Enabled\",True,\"(re)configure monit on this machine at next config update?\",0,\"bool\"],\n]\n\nclass System(item.Item):\n\n    TYPE_NAME = _(\"system\")\n    COLLECTION_TYPE = \"system\"\n\n    def get_fields(self):\n        return FIELDS\n\n    def make_clone(self):\n        ds = self.to_datastruct()\n        cloned = System(self.config)\n        cloned.from_datastruct(ds)\n        return cloned\n\n    def delete_interface(self,name):\n        \"\"\"\n        Used to remove an interface.\n        \"\"\"\n        if self.interfaces.has_key(name) and len(self.interfaces) > 1:\n            del self.interfaces[name]\n        else:\n            if not self.interfaces.has_key(name):\n                # no interface here to delete\n                pass\n            else:\n                raise CX(_(\"At least one interface needs to be defined.\"))\n\n        return True\n        \n\n    def __get_interface(self,name):\n\n        if not self.interfaces.has_key(name):\n            self.interfaces[name] = {\n                \"mac_address\"          : \"\",\n                \"mtu\"                  : \"\",\n                \"ip_address\"           : \"\",\n                \"dhcp_tag\"             : \"\",\n                \"subnet\"               : \"\", # deprecated\n                \"netmask\"              : \"\",\n                \"virt_bridge\"          : \"\",\n                \"static\"               : False,\n                \"interface_type\"       : \"\",\n                \"interface_master\"     : \"\",\n                \"bonding\"              : \"\", # deprecated\n                \"bonding_master\"       : \"\", # deprecated\n                \"bonding_opts\"         : \"\",\n                \"bridge_opts\"          : \"\",\n                \"management\"           : False,\n                \"dns_name\"             : \"\",\n                \"static_routes\"        : [],\n                \"ipv6_address\"         : \"\",\n                \"ipv6_secondaries\"     : [],\n                \"ipv6_mtu\"             : \"\",\n                \"ipv6_static_routes\"   : [],\n                \"ipv6_default_gateway\" : \"\",\n            }\n\n        return self.interfaces[name]\n\n\n    def from_datastruct(self,seed_data):\n        # FIXME: most definitely doesn't grok interfaces yet.\n        return utils.from_datastruct_from_fields(self,seed_data,FIELDS)\n\n    def get_parent(self):\n        \"\"\"\n        Return object next highest up the tree.\n        \"\"\"\n        if (self.parent is None or self.parent == '') and self.profile:\n            return self.config.profiles().find(name=self.profile)\n        elif (self.parent is None or self.parent == '') and self.image:\n            return self.config.images().find(name=self.image)\n        else:\n            return self.config.systems().find(name=self.parent)\n\n    def set_name(self,name):\n        \"\"\"\n        Set the name.  If the name is a MAC or IP, and the first MAC and/or IP is not defined, go ahead\n        and fill that value in.  \n        \"\"\"\n\n        if self.name not in [\"\",None] and self.parent not in [\"\",None] and self.name == self.parent:\n            raise CX(_(\"self parentage is weird\"))\n        if not isinstance(name, basestring):\n            raise CX(_(\"name must be a string\"))\n        for x in name:\n            if not x.isalnum() and not x in [ \"_\", \"-\", \".\", \":\", \"+\" ] :\n                raise CX(_(\"invalid characters in name: %s\") % x)\n\n        # Stuff here defaults to eth0. Yes, it's ugly and hardcoded, but so was\n        # the default interface behaviour that's now removed. ;)\n        # --Jasper Capel\n        if utils.is_mac(name):\n           intf = self.__get_interface(\"eth0\")\n           if intf[\"mac_address\"] == \"\":\n               intf[\"mac_address\"] = name\n        elif utils.is_ip(name):\n           intf = self.__get_interface(\"eth0\")\n           if intf[\"ip_address\"] == \"\":\n               intf[\"ip_address\"] = name\n        self.name = name \n\n        return True\n\n    def set_redhat_management_key(self,key):\n        return utils.set_redhat_management_key(self,key)\n\n    def set_redhat_management_server(self,server):\n        return utils.set_redhat_management_server(self,server)\n\n    def set_server(self,server):\n        \"\"\"\n        If a system can't reach the boot server at the value configured in settings\n        because it doesn't have the same name on it's subnet this is there for an override.\n        \"\"\"\n        if server is None or server == \"\":\n            server = \"<<inherit>>\"\n        self.server = server\n        return True\n\n    def set_proxy(self,proxy):\n        if proxy is None or proxy == \"\":\n            proxy = \"<<inherit>>\"\n        self.proxy = proxy\n        return True\n\n    def get_mac_address(self,interface):\n        \"\"\"\n        Get the mac address, which may be implicit in the object name or explicit with --mac-address.\n        Use the explicit location first.\n        \"\"\"\n\n        intf = self.__get_interface(interface)\n\n        if intf[\"mac_address\"] != \"\":\n            return intf[\"mac_address\"].strip()\n        else:\n            return None\n\n    def get_ip_address(self,interface):\n        \"\"\"\n        Get the IP address, which may be implicit in the object name or explict with --ip-address.\n        Use the explicit location first.\n        \"\"\"\n\n        intf = self.__get_interface(interface)\n\n        if intf[\"ip_address\"] != \"\": \n            return intf[\"ip_address\"].strip()\n        else:\n            return \"\"\n\n    def is_management_supported(self,cidr_ok=True):\n        \"\"\"\n        Can only add system PXE records if a MAC or IP address is available, else it's a koan\n        only record.  Actually Itanium goes beyond all this and needs the IP all of the time\n        though this is enforced elsewhere (action_sync.py).\n        \"\"\"\n        if self.name == \"default\":\n           return True\n        for (name,x) in self.interfaces.iteritems():\n            mac = x.get(\"mac_address\",None)\n            ip  = x.get(\"ip_address\",None)\n            if ip is not None and not cidr_ok and ip.find(\"/\") != -1:\n                # ip is in CIDR notation\n                return False\n            if mac is not None or ip is not None:\n                # has ip and/or mac\n                return True\n        return False\n\n    def set_dhcp_tag(self,dhcp_tag,interface):\n        intf = self.__get_interface(interface)\n        intf[\"dhcp_tag\"] = dhcp_tag\n        return True\n\n    def set_dns_name(self,dns_name,interface):\n        intf = self.__get_interface(interface)\n        # FIXME: move duplicate supression code to the object validation\n        # functions to take a harder line on supression?\n        if dns_name != \"\" and not str(self.config._settings.allow_duplicate_hostnames).lower() in [ \"1\", \"y\", \"yes\"]:\n           matched = self.config.api.find_items(\"system\", {\"dns_name\" : dns_name})\n           for x in matched:\n               if x.name != self.name:\n                   raise CX(\"dns-name duplicated: %s\" % dns_name)\n\n\n        intf[\"dns_name\"] = dns_name\n        return True\n \n    def set_static_routes(self,routes,interface):\n        intf = self.__get_interface(interface)\n        data = utils.input_string_or_list(routes)\n        intf[\"static_routes\"] = data\n        return True\n\n    def set_hostname(self,hostname):\n        if hostname is None:\n           hostname = \"\"\n        self.hostname = hostname\n        return True\n\n    def set_status(self,status):\n        self.status = status\n        return True\n\n    def set_static(self,truthiness,interface):\n        intf = self.__get_interface(interface)\n        intf[\"static\"] = utils.input_boolean(truthiness)\n        return True\n\n    def set_management(self,truthiness,interface):\n        intf = self.__get_interface(interface)\n        intf[\"management\"] = utils.input_boolean(truthiness)\n        return True\n\n    def set_ip_address(self,address,interface):\n        \"\"\"\n        Assign a IP or hostname in DHCP when this MAC boots.\n        Only works if manage_dhcp is set in /etc/cobbler/settings\n        \"\"\"\n        intf = self.__get_interface(interface)\n\n        # FIXME: move duplicate supression code to the object validation\n        # functions to take a harder line on supression?\n        if address != \"\" and not str(self.config._settings.allow_duplicate_ips).lower() in [ \"1\", \"y\", \"yes\"]:\n           matched = self.config.api.find_items(\"system\", {\"ip_address\" : address})\n           for x in matched:\n               if x.name != self.name:\n                   raise CX(\"IP address duplicated: %s\" % address)\n\n\n        if address == \"\" or utils.is_ip(address):\n           intf[\"ip_address\"] = address.strip()\n           return True\n        raise CX(_(\"invalid format for IP address (%s)\") % address)\n\n    def set_mac_address(self,address,interface):\n        if address == \"random\":\n           address = utils.get_random_mac(self.config.api)\n\n        # FIXME: move duplicate supression code to the object validation\n        # functions to take a harder line on supression?\n        if address != \"\" and not str(self.config._settings.allow_duplicate_macs).lower() in [ \"1\", \"y\", \"yes\"]:\n           matched = self.config.api.find_items(\"system\", {\"mac_address\" : address})\n           for x in matched:\n               if x.name != self.name:\n                   raise CX(\"MAC address duplicated: %s\" % address)\n\n        intf = self.__get_interface(interface)\n        if address == \"\" or utils.is_mac(address):\n           intf[\"mac_address\"] = address.strip()\n           return True\n        raise CX(_(\"invalid format for MAC address (%s)\" % address))\n\n\n    def set_gateway(self,gateway):\n        if gateway is None:\n           gateway = \"\"\n        if utils.is_ip(gateway) or gateway == \"\":\n           self.gateway = gateway\n        else:\n           raise CX(_(\"invalid format for gateway IP address (%s)\") % gateway)\n        return True\n \n    def set_name_servers(self,data):\n        if data == \"<<inherit>>\":\n           data = []\n        data = utils.input_string_or_list(data)\n        self.name_servers = data\n        return True\n\n    def set_name_servers_search(self,data):\n        if data == \"<<inherit>>\":\n           data = []\n        data = utils.input_string_or_list(data)\n        self.name_servers_search = data\n        return True\n\n    def set_netmask(self,netmask,interface):\n        intf = self.__get_interface(interface)\n        intf[\"netmask\"] = netmask\n        return True\n    \n    def set_virt_bridge(self,bridge,interface):\n        if bridge == \"\":\n            bridge = self.settings.default_virt_bridge\n        intf = self.__get_interface(interface)\n        intf[\"virt_bridge\"] = bridge\n        return True\n\n    def set_interface_type(self,type,interface):\n        # master and slave are deprecated, and will\n        # be assumed to mean bonding slave/master\n        interface_types = [\"bridge\",\"bridge_slave\",\"bond\",\"bond_slave\",\"master\",\"slave\",\"na\",\"\"]\n        if type not in interface_types:\n            raise CX(_(\"interface type value must be one of: %s or blank\" % interface_types.join(\",\")))\n        if type == \"na\":\n            type = \"\"\n        elif type == \"master\":\n            type = \"bond\"\n        elif type == \"slave\":\n            type = \"bond_slave\"\n        intf = self.__get_interface(interface)\n        intf[\"interface_type\"] = type\n        return True\n\n    def set_interface_master(self,interface_master,interface):\n        intf = self.__get_interface(interface)\n        intf[\"interface_master\"] = interface_master\n        return True\n\n    def set_bonding_opts(self,bonding_opts,interface):\n        intf = self.__get_interface(interface)\n        intf[\"bonding_opts\"] = bonding_opts\n        return True\n\n    def set_bridge_opts(self,bridge_opts,interface):\n        intf = self.__get_interface(interface)\n        intf[\"bridge_opts\"] = bridge_opts\n        return True\n\n    def set_ipv6_autoconfiguration(self,truthiness):\n        self.ipv6_autoconfiguration = utils.input_boolean(truthiness)\n        return True\n\n    def set_ipv6_default_device(self,interface_name):\n        if interface_name is None:\n           interface_name = \"\"\n        self.ipv6_default_device = interface_name\n        return True\n\n    def set_ipv6_address(self,address,interface):\n        \"\"\"\n        Assign a IP or hostname in DHCP when this MAC boots.\n        Only works if manage_dhcp is set in /etc/cobbler/settings\n        \"\"\"\n        intf = self.__get_interface(interface)\n        if address == \"\" or utils.is_ip(address):\n           intf[\"ipv6_address\"] = address.strip()\n           return True\n        raise CX(_(\"invalid format for IPv6 IP address (%s)\") % address)\n\n    def set_ipv6_secondaries(self,addresses,interface):\n        intf = self.__get_interface(interface)\n        data = utils.input_string_or_list(addresses)\n        secondaries = []\n        for address in data:\n           if address == \"\" or utils.is_ip(address):\n               secondaries.append(address)\n           else:\n               raise CX(_(\"invalid format for IPv6 IP address (%s)\") % address)\n\n        intf[\"ipv6_secondaries\"] = secondaries\n        return True\n\n    def set_ipv6_default_gateway(self,address,interface):\n        intf = self.__get_interface(interface)\n        if address == \"\" or utils.is_ip(address):\n           intf[\"ipv6_default_gateway\"] = address.strip()\n           return True\n        raise CX(_(\"invalid format for IPv6 IP address (%s)\") % address)\n\n    def set_ipv6_static_routes(self,routes,interface):\n        intf = self.__get_interface(interface)\n        data = utils.input_string_or_list(routes)\n        intf[\"ipv6_static_routes\"] = data\n        return True\n\n    def set_ipv6_mtu(self,mtu,interface):\n        intf = self.__get_interface(interface)\n        intf[\"ipv6_mtu\"] = mtu\n        return True\n\n    def set_mtu(self,mtu,interface):\n        intf = self.__get_interface(interface)\n        intf[\"mtu\"] = mtu\n        return True\n\n    def set_enable_gpxe(self,enable_gpxe):\n        \"\"\"\n        Sets whether or not the system will use gPXE for booting.\n        \"\"\"\n        self.enable_gpxe = utils.input_boolean(enable_gpxe)\n        return True\n\n    def set_profile(self,profile_name):\n        \"\"\"\n        Set the system to use a certain named profile.  The profile\n        must have already been loaded into the Profiles collection.\n        \"\"\"\n        old_parent = self.get_parent()\n        if profile_name in [ \"delete\", \"None\", \"~\", \"\"] or profile_name is None:\n            self.profile = \"\"\n            if isinstance(old_parent, item.Item):\n                old_parent.children.pop(self.name, 'pass')\n            return True\n\n        self.image = \"\" # mutual exclusion rule\n\n        p = self.config.profiles().find(name=profile_name)\n        if p is not None:\n            self.profile = profile_name\n            self.depth = p.depth + 1 # subprofiles have varying depths.\n            if isinstance(old_parent, item.Item):\n                old_parent.children.pop(self.name, 'pass')\n            new_parent = self.get_parent()\n            if isinstance(new_parent, item.Item):\n                new_parent.children[self.name] = self\n            return True\n        raise CX(_(\"invalid profile name: %s\") % profile_name)\n\n    def set_image(self,image_name):\n        \"\"\"\n        Set the system to use a certain named image.  Works like set_profile\n        but cannot be used at the same time.  It's one or the other.\n        \"\"\"\n        old_parent = self.get_parent()\n        if image_name in [ \"delete\", \"None\", \"~\", \"\"] or image_name is None:\n            self.image = \"\"\n            if isinstance(old_parent, item.Item):\n                old_parent.children.pop(self.name, 'pass')\n            return True\n\n        self.profile = \"\" # mutual exclusion rule\n\n        img = self.config.images().find(name=image_name)\n\n        if img is not None:\n            self.image = image_name\n            self.depth = img.depth + 1\n            if isinstance(old_parent, item.Item):\n                old_parent.children.pop(self.name, 'pass')\n            new_parent = self.get_parent()\n            if isinstance(new_parent, item.Item):\n                new_parent.children[self.name] = self\n            return True\n        raise CX(_(\"invalid image name (%s)\") % image_name)\n\n    def set_virt_cpus(self,num):\n        return utils.set_virt_cpus(self,num)\n\n    def set_virt_file_size(self,num):\n        return utils.set_virt_file_size(self,num)\n\n    def set_virt_disk_driver(self,driver):\n        return utils.set_virt_disk_driver(self,driver)\n \n    def set_virt_auto_boot(self,num):\n        return utils.set_virt_auto_boot(self,num)\n\n    def set_virt_ram(self,num):\n        return utils.set_virt_ram(self,num)\n\n    def set_virt_type(self,vtype):\n        return utils.set_virt_type(self,vtype)\n\n    def set_virt_path(self,path):\n        return utils.set_virt_path(self,path,for_system=True)\n\n    def set_netboot_enabled(self,netboot_enabled):\n        \"\"\"\n        If true, allows per-system PXE files to be generated on sync (or add).  If false,\n        these files are not generated, thus eliminating the potential for an infinite install\n        loop when systems are set to PXE boot first in the boot order.  In general, users\n        who are PXE booting first in the boot order won't create system definitions, so this\n        feature primarily comes into play for programmatic users of the API, who want to\n        initially create a system with netboot enabled and then disable it after the system installs, \n        as triggered by some action in kickstart %post.   For this reason, this option is not\n        surfaced in the CLI, output, or documentation (yet).\n\n        Use of this option does not affect the ability to use PXE menus.  If an admin has machines \n        set up to PXE only after local boot fails, this option isn't even relevant.\n        \"\"\"\n        self.netboot_enabled = utils.input_boolean(netboot_enabled)\n        return True\n\n    def set_kickstart(self,kickstart):\n        \"\"\"\n        Sets the kickstart.  This must be a NFS, HTTP, or FTP URL.\n        Or filesystem path. Minor checking of the URL is performed here.\n\n        NOTE -- usage of the --kickstart parameter in the profile\n        is STRONGLY encouraged.  This is only for exception cases\n        where a user already has kickstarts made for each system\n        and can't leverage templating.  Profiles provide an important\n        abstraction layer -- assigning systems to defined and repeatable \n        roles.\n        \"\"\"\n        if kickstart is None or kickstart in [ \"\", \"delete\", \"<<inherit>>\" ]:\n            self.kickstart = \"<<inherit>>\"\n            return True\n        kickstart = utils.find_kickstart(kickstart)\n        if kickstart:\n            self.kickstart = kickstart\n            return True\n        raise CX(_(\"kickstart not found: %s\" % kickstart))\n\n\n    def set_power_type(self, power_type):\n        # FIXME: modularize this better\n        if power_type is None:\n            power_type = \"\"\n        choices = utils.get_power_types()\n        choices.sort()\n        if power_type not in choices:\n            raise CX(\"power management type must be one of: %s\" % \",\".join(choices))\n        self.power_type = power_type\n        return True\n\n    def set_power_user(self, power_user):\n        if power_user is None:\n           power_user = \"\"\n        utils.safe_filter(power_user)\n        self.power_user = power_user\n        return True \n\n    def set_power_pass(self, power_pass):\n        if power_pass is None:\n           power_pass = \"\"\n        utils.safe_filter(power_pass)\n        self.power_pass = power_pass\n        return True    \n\n    def set_power_address(self, power_address):\n        if power_address is None:\n           power_address = \"\"\n        utils.safe_filter(power_address)\n        self.power_address = power_address\n        return True\n\n    def set_power_id(self, power_id):\n        if power_id is None:\n           power_id = \"\"\n        utils.safe_filter(power_id)\n        self.power_id = power_id\n        return True\n\n    def modify_interface(self, hash):\n        \"\"\"\n        Used by the WUI to modify an interface more-efficiently\n        \"\"\"\n        for (key,value) in hash.iteritems():\n            (field,interface) = key.split(\"-\")\n            field = field.replace(\"_\",\"\").replace(\"-\",\"\")\n            if field == \"macaddress\"          : self.set_mac_address(value, interface)\n            if field == \"mtu\"                 : self.set_mtu(value, interface)\n            if field == \"ipaddress\"           : self.set_ip_address(value, interface)\n            if field == \"dnsname\"             : self.set_dns_name(value, interface)\n            if field == \"static\"              : self.set_static(value, interface)\n            if field == \"dhcptag\"             : self.set_dhcp_tag(value, interface)\n            if field == \"netmask\"             : self.set_netmask(value, interface)\n            if field == \"subnet\"              : self.set_netmask(value, interface)\n            if field == \"virtbridge\"          : self.set_virt_bridge(value, interface)\n            if field == \"interfacetype\"       : self.set_interface_type(value, interface)\n            if field == \"interfacemaster\"     : self.set_interface_master(value, interface)\n            if field == \"bonding\"             : self.set_interface_type(value, interface)   # deprecated\n            if field == \"bondingmaster\"       : self.set_interface_master(value, interface) # deprecated\n            if field == \"bondingopts\"         : self.set_bonding_opts(value, interface)\n            if field == \"bridgeopts\"          : self.set_bridge_opts(value, interface)\n            if field == \"management\"          : self.set_management(value, interface)\n            if field == \"staticroutes\"        : self.set_static_routes(value, interface)\n            if field == \"ipv6address\"         : self.set_ipv6_address(value, interface)\n            if field == \"ipv6secondaries\"     : self.set_ipv6_secondaries(value, interface)\n            if field == \"ipv6mtu\"             : self.set_ipv6_mtu(value, interface)\n            if field == \"ipv6staticroutes\"    : self.set_ipv6_static_routes(value, interface)\n            if field == \"ipv6defaultgateway\"  : self.set_ipv6_default_gateway(value, interface)\n\n        return True\n\n    def check_if_valid(self):\n        if self.name is None or self.name == \"\":\n            raise CX(\"name is required\")\n        if self.profile is None or self.profile == \"\":\n            if self.image is None or self.image == \"\":\n                raise CX(\"Error with system %s - profile or image is required\" % (self.name))\n            \n    def set_template_remote_kickstarts(self, template):\n        \"\"\"\n        Sets whether or not the server is configured to template remote \n        kickstarts.\n        \"\"\"\n        self.template_remote_kickstarts = utils.input_boolean(template)\n        return True\n    \n    def set_monit_enabled(self,monit_enabled):\n        \"\"\"\n        If true, allows per-system to start Monit to monitor system services such as apache.\n        If monit is not running it will start the service.\n        \n        If false, no management of monit will take place. If monit is not running it will not\n        be started. If monit is running it will not be stopped or restarted.\n        \"\"\"\n        self.monit_enabled = utils.input_boolean(monit_enabled)\n        return True\n    \n    def set_ldap_enabled(self,ldap_enabled):\n        \"\"\"\n        If true, allows per-system to start Monit to monitor system services such as apache.\n        If monit is not running it will start the service.\n        \n        If false, no management of monit will take place. If monit is not running it will not\n        be started. If monit is running it will not be stopped or restarted.\n        \"\"\"\n        self.ldap_enabled = utils.input_boolean(ldap_enabled)\n        return True\n    \n    def set_repos_enabled(self,repos_enabled):\n        \"\"\"\n        If true, allows per-system to start Monit to monitor system services such as apache.\n        If monit is not running it will start the service.\n        \n        If false, no management of monit will take place. If monit is not running it will not\n        be started. If monit is running it will not be stopped or restarted.\n        \"\"\"\n        self.repos_enabled = utils.input_boolean(repos_enabled)\n        return True\n    \n    def set_ldap_type(self, ldap_type):\n        if ldap_type is None:\n            ldap_type = \"\"\n        ldap_type = ldap_type.lower()\n        self.ldap_type = ldap_type\n        return True\n\n\n", "\"\"\"\nMisc heavy lifting functions for cobbler\n\nCopyright 2006-2009, Red Hat, Inc and Others\nMichael DeHaan <michael.dehaan AT gmail>\n\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA\n02110-1301  USA\n\"\"\"\n\nimport sys\nimport os\nimport re\nimport copy\nimport socket\nimport glob\nimport random\ntry:\n    import subprocess as sub_process\nexcept:\n    import sub_process\nimport shutil\nimport string\nimport traceback\nimport errno\nimport logging\nimport shutil\nimport tempfile\nimport signal\nfrom cexceptions import *\nimport codes\nimport time\nimport netaddr\nimport shlex\nimport field_info\nimport clogger\nimport yaml\nimport urllib2\nimport simplejson\n\ntry:\n    import hashlib as fiver\n    def md5(key):\n        return fiver.md5(key)\nexcept ImportError: \n    # for Python < 2.5\n    import md5 as fiver\n    def md5(key):\n        return fiver.md5(key)\n\n# python-netaddr 0.7 broke backward compatability, try to use the old IP\n# classes, and fallback on the newer if there's an import error.\nNETADDR_PRE_0_7 = True\ntry:\n    # Try importing the old (pre-0.7) netaddr IP class:\n    from netaddr import IP\nexcept ImportError:\n    NETADDR_PRE_0_7 = False\n\nCHEETAH_ERROR_DISCLAIMER=\"\"\"\n# *** ERROR ***\n#\n# There is a templating error preventing this file from rendering correctly. \n#\n# This is most likely not due to a bug in Cobbler and is something you can fix.\n#\n# Look at the message below to see what things are causing problems.  \n#\n# (1) Does the template file reference a $variable that is not defined?\n# (2) is there a formatting error in a Cheetah directive?\n# (3) Should dollar signs ($) be escaped that are not being escaped?\n#\n# Try fixing the problem and then investigate to see if this message goes\n# away or changes.\n#\n\"\"\"\n\n# From http://code.activestate.com/recipes/303342/\nclass Translator:\n    allchars = string.maketrans('','')\n    def __init__(self, frm='', to='', delete='', keep=None):\n        if len(to) == 1:\n            to = to * len(frm)\n        self.trans = string.maketrans(frm, to)\n        if keep is None:\n            self.delete = delete\n        else:\n            self.delete = self.allchars.translate(self.allchars, keep.translate(self.allchars, delete))\n    def __call__(self, s):\n        return s.translate(self.trans, self.delete)\n\n\n#placeholder for translation\ndef _(foo):\n   return foo\n\nMODULE_CACHE = {}\n\n_re_kernel = re.compile(r'(vmlinu[xz]|kernel.img)')\n_re_initrd = re.compile(r'(initrd(.*).img|ramdisk.image.gz)')\n\n# all logging from utils.die goes to the main log even if there\n# is another log.\nmain_logger = None #  the logger will be lazy loaded later\n\ndef die(logger, msg):\n    global main_logger\n    if main_logger is None:\n        main_logger = clogger.Logger()\n\n    # log the exception once in the per-task log or the main\n    # log if this is not a background op.\n    try:\n       raise CX(msg)\n    except:\n       if logger is not None:\n           log_exc(logger)\n       else:\n           log_exc(main_logger)\n\n    # now re-raise it so the error can fail the operation\n    raise CX(msg)\n\ndef log_exc(logger):\n    \"\"\"\n    Log an exception.\n    \"\"\"\n    (t, v, tb) = sys.exc_info()\n    logger.info(\"Exception occured: %s\" % t )\n    logger.info(\"Exception value: %s\" % v)\n    logger.info(\"Exception Info:\\n%s\" % string.join(traceback.format_list(traceback.extract_tb(tb))))\n   \n\ndef get_exc(exc,full=True):\n   (t, v, tb) = sys.exc_info()\n   buf = \"\"\n   try:\n      getattr(exc, \"from_cobbler\")\n      buf = str(exc)[1:-1] + \"\\n\"\n   except:\n      if not full:\n          buf = buf + str(t)\n      buf = \"%s\\n%s\" % (buf,v)\n      if full:\n          buf = buf + \"\\n\" + \"\\n\".join(traceback.format_list(traceback.extract_tb(tb)))\n   return buf\n\ndef cheetah_exc(exc,full=False):\n   lines = get_exc(exc).split(\"\\n\")\n   buf = \"\"\n   for l in lines:\n      buf = buf + \"# %s\\n\" % l\n   return CHEETAH_ERROR_DISCLAIMER + buf\n\ndef trace_me():\n   x = traceback.extract_stack()\n   bar = string.join(traceback.format_list(x))\n   return bar\n\ndef pretty_hex(ip, length=8):\n    \"\"\"\n    Pads an IP object with leading zeroes so that the result is\n    _length_ hex digits.  Also do an upper().\n    \"\"\"\n    hexval = \"%x\" % ip.value\n    if len(hexval) < length:\n        hexval = '0' * (length - len(hexval)) + hexval\n    return hexval.upper()\n\ndef get_host_ip(ip, shorten=True):\n    \"\"\"\n    Return the IP encoding needed for the TFTP boot tree.\n    \"\"\"\n    cidr = None\n\n    if NETADDR_PRE_0_7:\n        ip = netaddr.IP(ip)\n        cidr = ip.cidr()\n    else:\n        ip = netaddr.ip.IPAddress(ip)\n        cidr = netaddr.ip.IPNetwork(ip)\n\n    if len(cidr) == 1: # Just an IP, e.g. a /32\n        return pretty_hex(ip)\n    else:\n        pretty = pretty_hex(cidr[0])\n        if not shorten or len(cidr) <= 8:\n            # not enough to make the last nibble insignificant\n            return pretty\n        else:\n            cutoff = (32 - cidr.prefixlen) / 4\n            return pretty[0:-cutoff]\n\ndef _IP(ip):\n   \"\"\"\n   Returns a netaddr.IP object representing ip.\n   If ip is already an netaddr.IP instance just return it.\n   Else return a new instance\n   \"\"\"\n   ip_class = None\n   if NETADDR_PRE_0_7:\n       ip_class = netaddr.IP\n   else:\n        ip_class = netaddr.ip.IPAddress\n   if isinstance(ip, ip_class) or ip == \"\":\n      return ip\n   else:\n      return ip_class(ip)\n\ndef get_config_filename(sys,interface):\n    \"\"\"\n    The configuration file for each system pxe uses is either\n    a form of the MAC address of the hex version of the IP.  If none\n    of that is available, just use the given name, though the name\n    given will be unsuitable for PXE configuration (For this, check\n    system.is_management_supported()).  This same file is used to store\n    system config information in the Apache tree, so it's still relevant.\n    \"\"\"\n\n    interface = str(interface)\n    if not sys.interfaces.has_key(interface):\n        return None\n\n    if sys.name == \"default\":\n        return \"default\"\n    mac = sys.get_mac_address(interface)\n    ip  = sys.get_ip_address(interface)\n    if mac is not None and mac != \"\":\n        return \"01-\" + \"-\".join(mac.split(\":\")).lower()\n    elif ip is not None and ip != \"\":\n        return get_host_ip(ip)\n    else:\n        return sys.name\n\n\ndef is_ip(strdata):\n    \"\"\"\n    Return whether the argument is an IP address.\n    \"\"\"\n    try:\n        _IP(strdata)\n    except:\n        return False\n    return True\n\n\ndef is_mac(strdata):\n    \"\"\"\n    Return whether the argument is a mac address.\n    \"\"\"\n    # needs testcase\n    if strdata is None:\n        return False\n    if re.search(r'[A-F0-9]{2}:[A-F0-9]{2}:[A-F0-9]{2}:[A-F0-9]{2}:[A-F:0-9]{2}:[A-F:0-9]{2}',strdata, re.IGNORECASE):\n        return True\n    return False\n\ndef get_random_mac(api_handle,virt_type=\"xenpv\"):\n    \"\"\"\n    Generate a random MAC address.\n    from xend/server/netif.py\n    return: MAC address string\n    \"\"\"\n    if virt_type.startswith(\"vmware\"):\n        mac = [ 0x00, 0x50, 0x56,\n            random.randint(0x00, 0x3f),\n            random.randint(0x00, 0xff),\n            random.randint(0x00, 0xff)\n        ]\n    elif virt_type.startswith(\"xen\") or virt_type.startswith(\"qemu\") or virt_type.startswith(\"kvm\"):\n        mac = [ 0x00, 0x16, 0x3e,\n            random.randint(0x00, 0x7f),\n            random.randint(0x00, 0xff),\n            random.randint(0x00, 0xff) \n        ]\n    else:\n        raise CX(\"virt mac assignment not yet supported\")\n\n        \n    mac = ':'.join(map(lambda x: \"%02x\" % x, mac))\n    systems = api_handle.systems()\n    while ( systems.find(mac_address=mac) ):\n        mac = get_random_mac(api_handle)\n\n    return mac\n\n\ndef resolve_ip(strdata):\n    \"\"\"\n    Resolve the IP address and handle errors...\n    \"\"\"\n    try:\n        return socket.gethostbyname(strdata)\n    except:\n        return None\n\n\ndef find_matching_files(directory,regex):\n    \"\"\"\n    Find all files in a given directory that match a given regex.\n    Can't use glob directly as glob doesn't take regexen.\n    \"\"\"\n    files = glob.glob(os.path.join(directory,\"*\"))\n    results = []\n    for f in files:\n       if regex.match(os.path.basename(f)):\n           results.append(f)\n    return results\n\n\ndef find_highest_files(directory,unversioned,regex):\n    \"\"\"\n    Find the highest numbered file (kernel or initrd numbering scheme)\n    in a given directory that matches a given pattern.  Used for\n    auto-booting the latest kernel in a directory.\n    \"\"\"\n    files = find_matching_files(directory, regex)\n    get_numbers = re.compile(r'(\\d+).(\\d+).(\\d+)')\n    def max2(a, b):\n        \"\"\"Returns the larger of the two values\"\"\"\n        av  = get_numbers.search(os.path.basename(a)).groups()\n        bv  = get_numbers.search(os.path.basename(b)).groups()\n\n        ret = cmp(av[0], bv[0]) or cmp(av[1], bv[1]) or cmp(av[2], bv[2])\n        if ret < 0:\n            return b\n        return a\n\n    if len(files) > 0:\n        return reduce(max2, files)\n\n    # couldn't find a highest numbered file, but maybe there\n    # is just a 'vmlinuz' or an 'initrd.img' in this directory?\n    last_chance = os.path.join(directory,unversioned)\n    if os.path.exists(last_chance):\n        return last_chance\n    return None\n\n\ndef find_kernel(path):\n    \"\"\"\n    Given a directory or a filename, find if the path can be made\n    to resolve into a kernel, and return that full path if possible.\n    \"\"\"\n    if path is None:\n        return None\n\n    if os.path.isfile(path):\n        #filename = os.path.basename(path)\n        #if _re_kernel.match(filename):\n        #   return path\n        #elif filename == \"vmlinuz\":\n        #   return path\n        return path\n\n    elif os.path.isdir(path):\n        return find_highest_files(path,\"vmlinuz\",_re_kernel)\n\n    # For remote URLs we expect an absolute path, and will not\n    # do any searching for the latest:\n    elif file_is_remote(path) and remote_file_exists(path):\n        return path\n\n    return None\n\ndef remove_yum_olddata(path,logger=None):\n    \"\"\"\n    Delete .olddata files that might be present from a failed run\n    of createrepo.  \n    # FIXME: verify this is still being used\n    \"\"\"\n    trythese = [\n        \".olddata\",\n        \".repodata/.olddata\",\n        \"repodata/.oldata\",\n        \"repodata/repodata\"\n    ]\n    for pathseg in trythese:\n        olddata = os.path.join(path, pathseg)\n        if os.path.exists(olddata):\n            if logger is not None:\n                logger.info(\"removing: %s\" % olddata)\n            shutil.rmtree(olddata, ignore_errors=False, onerror=None)  \n\ndef find_initrd(path):\n    \"\"\"\n    Given a directory or a filename, see if the path can be made\n    to resolve into an intird, return that full path if possible.\n    \"\"\"\n    # FUTURE: try to match kernel/initrd pairs?\n    if path is None:\n        return None\n\n    if os.path.isfile(path):\n        #filename = os.path.basename(path)\n        #if _re_initrd.match(filename):\n        #   return path\n        #if filename == \"initrd.img\" or filename == \"initrd\":\n        #   return path\n        return path\n\n    elif os.path.isdir(path):\n        return find_highest_files(path,\"initrd.img\",_re_initrd)\n\n    # For remote URLs we expect an absolute path, and will not\n    # do any searching for the latest:\n    elif file_is_remote(path) and remote_file_exists(path):\n        return path\n\n    return None\n\n\ndef find_kickstart(url):\n    \"\"\"\n    Check if a kickstart url looks like an http, ftp, nfs or local path.\n    If a local path is used, cobbler will copy the kickstart and serve\n    it over http.\n\n    Return None if the url format does not look valid.\n    \"\"\"\n    if url is None:\n        return None\n    x = url.lstrip()\n    for y in [\"http://\", \"nfs://\", \"ftp://\", \"/\"]:\n       # make sure we get a lower-case protocol without \n       # affecting the rest of the string\n       x = re.sub(r\"(?i)%s\" % y, y, x, count=1)\n       if x.startswith(y):\n           if x.startswith(\"/\") and not os.path.isfile(x):\n               return None\n           return x\n    return None\n\n\ndef read_file_contents(file_location, logger=None, fetch_if_remote=False):\n    \"\"\"\n    Reads the contents of a file, which could be referenced locally\n    or as a URI.\n\n    Returns None if file is remote and templating of remote files is \n    disabled.\n\n    Throws a FileNotFoundException if the file does not exist at the\n    specified location.\n    \"\"\"\n\n    # Local files:\n    if file_location.startswith(\"/\"):\n\n        if not os.path.exists(file_location):\n            if logger:\n                logger.warning(\"File does not exist: %s\" % file_location)\n            raise FileNotFoundException(\"%s: %s\" % (_(\"File not found\"), \n                file_location))\n\n        try:\n            f = open(file_location)\n            data = f.read()\n            f.close()\n            return data\n        except:\n            if logger:\n                log_exc(logger)\n            raise\n\n    # Remote files:\n    if not fetch_if_remote:\n        return None\n\n    if file_is_remote(file_location):\n        try:\n            handler = urllib2.urlopen(file_location)\n            data = handler.read()\n            handler.close()\n            return data\n        except urllib2.HTTPError:\n            # File likely doesn't exist\n            if logger:\n                logger.warning(\"File does not exist: %s\" % file_location)\n            raise FileNotFoundException(\"%s: %s\" % (_(\"File not found\"), \n                file_location))\n\n\ndef remote_file_exists(file_url):\n    \"\"\" Return True if the remote file exists. \"\"\"\n    try:\n        handler = urllib2.urlopen(file_url)\n        handler.close()\n        return True\n    except urllib2.HTTPError:\n        # File likely doesn't exist\n        return False\n\n\ndef file_is_remote(file_location):\n    \"\"\" \n    Returns true if the file is remote and referenced via a protocol\n    we support.\n    \"\"\"\n    # TODO: nfs and ftp ok too?\n    file_loc_lc = file_location.lower()\n    for prefix in [\"http://\"]:\n        if file_loc_lc.startswith(prefix):\n            return True\n    return False\n\n\ndef input_string_or_list(options):\n    \"\"\"\n    Accepts a delimited list of stuff or a list, but always returns a list.\n    \"\"\"\n    delim = None\n    if options == \"<<inherit>>\":\n       return \"<<inherit>>\"\n    if options is None or options == \"\" or options == \"delete\":\n       return []\n    elif isinstance(options,list):\n       return options\n    elif isinstance(options,basestring):\n       tokens = options.split(delim)\n       return tokens\n    else:\n       raise CX(_(\"invalid input type\"))\n\ndef input_string_or_hash(options,allow_multiples=True):\n    \"\"\"\n    Older cobbler files stored configurations in a flat way, such that all values for strings.\n    Newer versions of cobbler allow dictionaries.  This function is used to allow loading\n    of older value formats so new users of cobbler aren't broken in an upgrade.\n    \"\"\"\n\n    if options == \"<<inherit>>\":\n        options = {}\n\n    if options is None or options == \"delete\":\n        return (True, {})\n    elif isinstance(options, list):\n        raise CX(_(\"No idea what to do with list: %s\") % options)\n    elif isinstance(options, str):\n        new_dict = {}\n        tokens = shlex.split(options)\n        for t in tokens:\n            tokens2 = t.split(\"=\",1)\n            if len(tokens2) == 1:\n                # this is a singleton option, no value\n                key = tokens2[0]\n                value = None\n            else:\n                key = tokens2[0]\n                value = tokens2[1] \n\n            # if we're allowing multiple values for the same key,\n            # check to see if this token has already been\n            # inserted into the dictionary of values already\n\n            if key in new_dict.keys() and allow_multiples:\n                # if so, check to see if there is already a list of values\n                # otherwise convert the dictionary value to an array, and add\n                # the new value to the end of the list\n                if isinstance(new_dict[key], list):\n                    new_dict[key].append(value)\n                else:\n                    new_dict[key] = [new_dict[key], value]\n            else:\n                new_dict[key] = value\n        # make sure we have no empty entries\n        new_dict.pop('', None)\n        return (True, new_dict)\n    elif isinstance(options, dict):\n        options.pop('',None)\n        return (True, options)\n    else:\n        raise CX(_(\"invalid input type\"))\n\ndef input_boolean(value):\n    value = str(value)\n    if value.lower() in [ \"true\", \"1\", \"on\", \"yes\", \"y\" ]:\n       return True\n    else:\n       return False\n\ndef grab_tree(api_handle, obj):\n    \"\"\"\n    Climb the tree and get every node.\n    \"\"\"\n    settings = api_handle.settings()\n    results = [ obj ]\n    parent = obj.get_parent()\n    while parent is not None:\n       results.append(parent)\n       parent = parent.get_parent()\n    results.append(settings)  \n    return results\n\ndef blender(api_handle,remove_hashes, root_obj):\n    \"\"\"\n    Combine all of the data in an object tree from the perspective\n    of that point on the tree, and produce a merged hash containing\n    consolidated data.\n    \"\"\"\n \n    settings = api_handle.settings()\n    tree = grab_tree(api_handle, root_obj)\n    tree.reverse()  # start with top of tree, override going down\n    results = {}\n    for node in tree:\n        __consolidate(node,results)\n\n    # hack -- s390 nodes get additional default kernel options\n    arch = results.get(\"arch\",\"?\")\n    if arch.startswith(\"s390\"):\n        keyz = settings.kernel_options_s390x.keys()\n        for k in keyz:\n           if not results.has_key(k):\n               results[\"kernel_options\"][k] = settings.kernel_options_s390x[k]\n\n    # Get topmost object to determine which breed we're dealing with\n    parent = root_obj.get_parent()\n    if parent is None:\n        parent = root_obj\n\n    while parent.COLLECTION_TYPE is \"profile\" or parent.COLLECTION_TYPE is \"system\":\n        parent = parent.get_parent()\n\n    breed = parent.breed\n\n    if breed == \"redhat\":\n        # determine if we have room to add kssendmac to the kernel options line\n        kernel_txt = hash_to_string(results[\"kernel_options\"])\n        if len(kernel_txt) < 244:\n            results[\"kernel_options\"][\"kssendmac\"] = None\n\n    # convert post kernel options to string\n    if results.has_key(\"kernel_options_post\"):\n        results[\"kernel_options_post\"] = hash_to_string(results[\"kernel_options_post\"])\n\n\n    # make interfaces accessible without Cheetah-voodoo in the templates\n    # EXAMPLE:  $ip == $ip0, $ip1, $ip2 and so on.\n \n    if root_obj.COLLECTION_TYPE == \"system\":\n        for (name,interface) in root_obj.interfaces.iteritems():\n            for key in interface.keys():\n                results[\"%s_%s\" % (key,name)] = interface[key]\n                # just to keep templates backwards compatibile\n                if name == \"intf0\":\n                    # prevent stomping on profile variables, which really only happens\n                    # with the way we check for virt_bridge, which is a profile setting\n                    # and an interface setting\n                    if not results.has_key(key):\n                        results[key] = interface[key]\n\n    http_port = results.get(\"http_port\",80)\n    if http_port not in (80, \"80\"):\n       results[\"http_server\"] = \"%s:%s\" % (results[\"server\"] , http_port)\n    else:\n       results[\"http_server\"] = results[\"server\"]\n\n    mgmt_parameters = results.get(\"mgmt_parameters\",{})\n    mgmt_parameters.update(results.get(\"ks_meta\", {}))\n    results[\"mgmt_parameters\"] = mgmt_parameters\n \n    # sanitize output for koan and kernel option lines, etc\n    if remove_hashes:\n        results = flatten(results)\n\n    # the password field is inputed as escaped strings but Cheetah\n    # does weird things when expanding it due to multiple dollar signs\n    # so this is the workaround\n    if results.has_key(\"default_password_crypted\"):\n        results[\"default_password_crypted\"] = results[\"default_password_crypted\"].replace(\"\\$\",\"$\")\n\n    # add in some variables for easier templating\n    # as these variables change based on object type\n    if results.has_key(\"interfaces\"):\n        # is a system object\n        results[\"system_name\"]  = results[\"name\"]\n        results[\"profile_name\"] = results[\"profile\"]\n        if results.has_key(\"distro\"):\n            results[\"distro_name\"]  = results[\"distro\"]\n        elif results.has_key(\"image\"):\n            results[\"distro_name\"]  = \"N/A\"\n            results[\"image_name\"]   = results[\"image\"]\n    elif results.has_key(\"distro\"):\n        # is a profile or subprofile object\n        results[\"profile_name\"] = results[\"name\"]\n        results[\"distro_name\"]  = results[\"distro\"]\n    elif results.has_key(\"kernel\"):\n        # is a distro object\n        results[\"distro_name\"]  = results[\"name\"]\n    elif results.has_key(\"file\"):\n        # is an image object\n        results[\"distro_name\"]  = \"N/A\"\n        results[\"image_name\"]   = results[\"name\"]\n\n    return results\n\ndef flatten(data):\n    # convert certain nested hashes to strings.\n    # this is only really done for the ones koan needs as strings\n    # this should not be done for everything\n    if data is None:\n        return None\n    if data.has_key(\"environment\"):\n        data[\"environment\"] = hash_to_string(data[\"environment\"])\n    if data.has_key(\"kernel_options\"):\n        data[\"kernel_options\"] = hash_to_string(data[\"kernel_options\"])\n    if data.has_key(\"kernel_options_post\"):\n        data[\"kernel_options_post\"] = hash_to_string(data[\"kernel_options_post\"])\n    if data.has_key(\"yumopts\"):\n        data[\"yumopts\"]        = hash_to_string(data[\"yumopts\"])\n    if data.has_key(\"ks_meta\"):\n        data[\"ks_meta\"] = hash_to_string(data[\"ks_meta\"])\n    if data.has_key(\"template_files\"):\n        data[\"template_files\"] = hash_to_string(data[\"template_files\"])\n    if data.has_key(\"boot_files\"):\n        data[\"boot_files\"] = hash_to_string(data[\"boot_files\"])\n    if data.has_key(\"fetchable_files\"):\n        data[\"fetchable_files\"] = hash_to_string(data[\"fetchable_files\"])\n    if data.has_key(\"repos\") and isinstance(data[\"repos\"], list):\n        data[\"repos\"]   = \" \".join(data[\"repos\"])\n    if data.has_key(\"rpm_list\") and isinstance(data[\"rpm_list\"], list):\n        data[\"rpm_list\"] = \" \".join(data[\"rpm_list\"])\n\n    # note -- we do not need to flatten \"interfaces\" as koan does not expect\n    # it to be a string, nor do we use it on a kernel options line, etc...\n \n    return data\n\ndef uniquify(seq, idfun=None): \n    # credit: http://www.peterbe.com/plog/uniqifiers-benchmark\n    # FIXME: if this is actually slower than some other way, overhaul it\n    if idfun is None:\n        def idfun(x): \n           return x\n    seen = {}\n    result = []\n    for item in seq:\n        marker = idfun(item)\n        if marker in seen:\n            continue\n        seen[marker] = 1\n        result.append(item)\n    return result\n\ndef __consolidate(node,results):\n    \"\"\"\n    Merge data from a given node with the aggregate of all\n    data from past scanned nodes.  Hashes and arrays are treated\n    specially.\n    \"\"\"\n    node_data =  node.to_datastruct()\n\n    # if the node has any data items labelled <<inherit>> we need to expunge them.\n    # so that they do not override the supernodes.\n    node_data_copy = {}\n    for key in node_data:\n       value = node_data[key]\n       if value != \"<<inherit>>\":\n          if isinstance(value, dict):\n              node_data_copy[key] = value.copy()\n          elif isinstance(value, list):\n              node_data_copy[key] = value[:]\n          else:\n              node_data_copy[key] = value\n\n    for field in node_data_copy:\n\n       data_item = node_data_copy[field] \n       if results.has_key(field):\n \n          # now merge data types seperately depending on whether they are hash, list,\n          # or scalar.\n\n          fielddata = results[field]\n\n          if isinstance(fielddata, dict):\n             # interweave hash results\n             results[field].update(data_item.copy())\n          elif isinstance(fielddata, list) or isinstance(fielddata, tuple):\n             # add to lists (cobbler doesn't have many lists)\n             # FIXME: should probably uniqueify list after doing this\n             results[field].extend(data_item)\n             results[field] = uniquify(results[field])\n          else:\n             # just override scalars\n             results[field] = data_item\n       else:\n          results[field] = data_item\n\n    # now if we have any \"!foo\" results in the list, delete corresponding\n    # key entry \"foo\", and also the entry \"!foo\", allowing for removal\n    # of kernel options set in a distro later in a profile, etc.\n\n    hash_removals(results,\"kernel_options\")\n    hash_removals(results,\"kernel_options_post\")\n    hash_removals(results,\"ks_meta\")\n    hash_removals(results,\"template_files\")\n    hash_removals(results,\"boot_files\")\n    hash_removals(results,\"fetchable_files\")\n\ndef hash_removals(results,subkey):\n    if not results.has_key(subkey):\n        return\n    scan = results[subkey].keys()\n    for k in scan:\n        if str(k).startswith(\"!\") and k != \"!\":\n           remove_me = k[1:]\n           if results[subkey].has_key(remove_me):\n               del results[subkey][remove_me]\n           del results[subkey][k]\n\ndef hash_to_string(hash):\n    \"\"\"\n    Convert a hash to a printable string.\n    used primarily in the kernel options string\n    and for some legacy stuff where koan expects strings\n    (though this last part should be changed to hashes)\n    \"\"\"\n    buffer = \"\"\n    if not isinstance(hash, dict):\n       return hash\n    for key in hash:\n       value = hash[key]\n       if not value:\n           buffer = buffer + str(key) + \" \"\n       elif isinstance(value, list):\n           # this value is an array, so we print out every\n           # key=value\n           for item in value:\n              buffer = buffer + str(key) + \"=\" + str(item) + \" \"\n       else:\n          buffer = buffer + str(key) + \"=\" + str(value) + \" \"\n    return buffer\n\ndef rsync_files(src, dst, args, logger=None, quiet=True):\n    \"\"\"\n    Sync files from src to dst. The extra arguments specified\n    by args are appended to the command\n    \"\"\"\n\n    if args == None:\n        args = ''\n\n    RSYNC_CMD = \"rsync -a %%s '%%s' %%s %s --exclude-from=/etc/cobbler/rsync.exclude\" % args\n    if quiet:\n        RSYNC_CMD += \" --quiet\"\n    else:\n        RSYNC_CMD += \" --progress\"\n\n    # Make sure we put a \"/\" on the end of the source\n    # and destination to make sure we don't cause any\n    # rsync weirdness\n    if not dst.endswith(\"/\"):\n        dst = \"%s/\" % dst\n    if not src.endswith(\"/\"):\n        src = \"%s/\" % src\n\n    spacer = \"\"\n    if not src.startswith(\"rsync://\") and not src.startswith(\"/\"):\n        spacer = ' -e \"ssh\" '\n\n    rsync_cmd = RSYNC_CMD % (spacer,src,dst)\n    try:\n        res = subprocess_call(logger, rsync_cmd)\n        if res != 0:\n            die(logger, \"Failed to run the rsync command: '%s'\" % rsync_cmd)\n    except:\n        return False\n\n    return True\n\ndef run_this(cmd, args, logger):\n    \"\"\"\n    A simple wrapper around subprocess calls.\n    \"\"\"\n\n    my_cmd = cmd % args\n    rc = subprocess_call(logger,my_cmd,shell=True)\n    if rc != 0:\n        die(logger,\"Command failed\")\n\ndef run_triggers(api,ref,globber,additional=[],logger=None):\n    \"\"\"\n    Runs all the trigger scripts in a given directory.\n    ref can be a cobbler object, if not None, the name will be passed\n    to the script.  If ref is None, the script will be called with\n    no argumenets.  Globber is a wildcard expression indicating which\n    triggers to run.  Example:  \"/var/lib/cobbler/triggers/blah/*\"\n\n    As of Cobbler 1.5.X, this also runs cobbler modules that match the globbing paths.\n    \"\"\"\n\n    # Python triggers first, before shell\n\n    if logger is not None:\n        logger.debug(\"running python triggers from %s\" % globber)\n    modules = api.get_modules_in_category(globber)\n    for m in modules:\n        arglist = []\n        if ref:\n            arglist.append(ref.name)\n        for x in additional:\n       \n            arglist.append(x)\n        if logger is not None:\n            logger.debug(\"running python trigger %s\" % m.__name__)\n        rc = m.run(api, arglist, logger)\n        if rc != 0:\n            raise CX(\"cobbler trigger failed: %s\" % m.__name__)\n\n    # now do the old shell triggers, which are usually going to be slower, but are easier to write  \n    # and support any language\n\n    if logger is not None:\n        logger.debug(\"running shell triggers from %s\" % globber)\n    triggers = glob.glob(globber)\n    triggers.sort()\n    for file in triggers:\n        try:\n            if file.startswith(\".\") or file.find(\".rpm\") != -1:\n                # skip dotfiles or .rpmnew files that may have been installed\n                # in the triggers directory\n                continue\n            arglist = [ file ]\n            if ref:\n                arglist.append(ref.name)\n            for x in additional:\n                if x:\n                    arglist.append(x)\n            if logger is not None:\n                logger.debug(\"running shell trigger %s\" % file)\n            rc = subprocess_call(logger, arglist, shell=False) # close_fds=True)\n        except:\n            if logger is not None:\n                logger.warning(\"failed to execute trigger: %s\" % file)\n            continue\n\n        if rc != 0:\n            raise CX(_(\"cobbler trigger failed: %(file)s returns %(code)d\") % { \"file\" : file, \"code\" : rc })\n\ndef fix_mod_python_select_submission(repos):\n    \"\"\" \n    WARNING: this is a heinous hack to convert mod_python submitted form data\n    to something usable.  Ultimately we need to fix the root cause of this\n    which doesn't seem to happen on all versions of python/mp.\n    \"\"\"\n\n    # should be nice regex, but this is readable :)\n    repos = str(repos)\n    repos = repos.replace(\"'repos'\",\"\")\n    repos = repos.replace(\"'\",\"\")\n    repos = repos.replace(\"[\",\"\")\n    repos = repos.replace(\"]\",\"\")\n    repos = repos.replace(\"Field(\",\"\")\n    repos = repos.replace(\")\",\"\")\n    repos = repos.replace(\",\",\"\")\n    repos = repos.replace('\"',\"\")\n    repos = repos.lstrip().rstrip()\n    return repos\n\ndef check_dist():\n    \"\"\"\n    Determines what distro we're running under.  \n    \"\"\"\n    if os.path.exists(\"/etc/debian_version\"):\n       import lsb_release\n       return lsb_release.get_distro_information()['ID'].lower()\n    elif os.path.exists(\"/etc/SuSE-release\"):\n       return \"suse\"\n    elif os.path.exists(\"/etc/redhat-release\"):\n       # valid for Fedora and all Red Hat / Fedora derivatives\n       return \"redhat\"\n    else:\n       return \"unknown\"\n\ndef os_release():\n\n   if check_dist() == \"redhat\":\n      fh = open(\"/etc/redhat-release\")\n      data = fh.read().lower()\n      if data.find(\"fedora\") != -1:\n         make = \"fedora\"\n      elif data.find(\"centos\") != -1:\n         make = \"centos\"\n      else:\n         make = \"redhat\"\n      release_index = data.find(\"release\") \n      rest = data[release_index+7:-1]\n      tokens = rest.split(\" \")\n      for t in tokens:\n         try:\n             return (make,float(t))\n         except ValueError, ve:\n             pass\n      raise CX(\"failed to detect local OS version from /etc/redhat-release\")\n\n   elif check_dist() == \"debian\":\n      import lsb_release\n      release = lsb_release.get_distro_information()['RELEASE']\n      return (\"debian\", release)\n   elif check_dist() == \"ubuntu\":\n      version = sub_process.check_output((\"lsb_release\",\"--release\",\"--short\")).rstrip()\n      make = \"ubuntu\"\n      return (make, float(version))\n   elif check_dist() == \"suse\":\n      fd = open(\"/etc/SuSE-release\")\n      for line in fd.read().split(\"\\n\"):\n         if line.find(\"VERSION\") != -1:\n            version = line.replace(\"VERSION = \",\"\")\n         if line.find(\"PATCHLEVEL\") != -1:\n            rest = line.replace(\"PATCHLEVEL = \",\"\")\n      make = \"suse\"\n      return (make, float(version))\n   else:\n      return (\"unknown\",0)\n\ndef tftpboot_location():\n\n    # if possible, read from TFTP config file to get the location\n    if os.path.exists(\"/etc/xinetd.d/tftp\"):\n        fd = open(\"/etc/xinetd.d/tftp\")\n        lines = fd.read().split(\"\\n\")\n        for line in lines:\n           if line.find(\"server_args\") != -1:\n              tokens = line.split(None)\n              mark = False\n              for t in tokens:\n                 if t == \"-s\":    \n                    mark = True\n                 elif mark:\n                    return t\n\n    # otherwise, guess based on the distro\n    (make,version) = os_release()\n    if make == \"fedora\" and version >= 9:\n        return \"/var/lib/tftpboot\"\n    elif make ==\"redhat\" and version >= 6:\n        return \"/var/lib/tftpboot\"\n    elif make == \"debian\" or make == \"ubuntu\":\n        return \"/var/lib/tftpboot\"\n    if make == \"suse\":\n        return \"/srv/tftpboot\"\n    return \"/tftpboot\"\n\ndef can_do_public_content(api):\n    \"\"\"\n    Returns whether we can use public_content_t which greatly\n    simplifies SELinux usage.\n    \"\"\"\n    (dist, ver) = api.get_os_details()\n    if dist == \"redhat\" and ver <= 4:\n       return False\n    return True\n\ndef is_safe_to_hardlink(src,dst,api):\n    (dev1, path1) = get_file_device_path(src)\n    (dev2, path2) = get_file_device_path(dst)\n    if dev1 != dev2:\n       return False\n    if dev1.find(\":\") != -1:\n       # is remoted\n       return False\n    # note: this is very cobbler implementation specific!\n    if not api.is_selinux_enabled():\n       return True\n    if _re_initrd.match(os.path.basename(path1)):\n       return True\n    if _re_kernel.match(os.path.basename(path1)):\n       return True\n    # we're dealing with SELinux and files that are not safe to chcon\n    return False\n\ndef hashfile(fn, lcache=None, logger=None):\n    \"\"\"\n    Returns the sha1sum of the file\n    \"\"\"\n\n    db = {}\n    try:\n        dbfile = os.path.join(lcache,'link_cache.json')\n        if os.path.exists(dbfile):\n            db = simplejson.load(open(dbfile, 'r'))\n    except:\n        pass\n\n    mtime = os.stat(fn).st_mtime\n    if db.has_key(fn):\n        if db[fn][0] >= mtime:\n            return db[fn][1]\n\n    if os.path.exists(fn):\n        cmd = '/usr/bin/sha1sum %s'%fn\n        key = subprocess_get(logger,cmd).split(' ')[0]\n        if lcache is not None:\n            db[fn] = (mtime,key)\n            simplejson.dump(db, open(dbfile,'w'))\n        return key\n    else:\n        return None\n\ndef cachefile(src, dst, api=None, logger=None):\n    \"\"\"\n    Copy a file into a cache and link it into place.\n    Use this with caution, otherwise you could end up\n    copying data twice if the cache is not on the same device\n    as the destination\n    \"\"\"\n    lcache = os.path.join(os.path.dirname(os.path.dirname(dst)),'.link_cache')\n    if not os.path.isdir(lcache):\n        os.mkdir(lcache)\n    key = hashfile(src, lcache=lcache, logger=logger)\n    cachefile = os.path.join(lcache, key)\n    if not os.path.exists(cachefile):\n        logger.info(\"trying to create cache file %s\"%cachefile)\n        copyfile(src,cachefile,api=api,logger=logger)\n\n    logger.debug(\"trying cachelink %s -> %s -> %s\"%(src,cachefile,dst))\n    rc = os.link(cachefile,dst)\n    return rc\n\ndef linkfile(src, dst, symlink_ok=False, cache=True, api=None, logger=None):\n    \"\"\"\n    Attempt to create a link dst that points to src.  Because file\n    systems suck we attempt several different methods or bail to\n    copyfile()\n    \"\"\"\n\n    if api is None:\n        # FIXME: this really should not be a keyword\n        # arg\n        raise \"Internal error: API handle is required\"\n\n    is_remote = is_remote_file(src)\n\n    if os.path.exists(dst):\n        # if the destination exists, is it right in terms of accuracy\n        # and context?\n        if os.path.samefile(src, dst):\n            if not is_safe_to_hardlink(src,dst,api):\n                # may have to remove old hardlinks for SELinux reasons\n                # as previous implementations were not complete\n                if logger is not None:\n                   logger.info(\"removing: %s\" % dst)\n                os.remove(dst)\n            else:\n                return True\n        elif os.path.islink(dst):\n            # existing path exists and is a symlink, update the symlink\n            if logger is not None:\n               logger.info(\"removing: %s\" % dst)\n            os.remove(dst)\n\n    if is_safe_to_hardlink(src,dst,api):\n        # we can try a hardlink if the destination isn't to NFS or Samba\n        # this will help save space and sync time.\n        try:\n            if logger is not None:\n                logger.info(\"trying hardlink %s -> %s\" % (src,dst))\n            rc = os.link(src, dst)\n            return rc\n        except (IOError, OSError):\n            # hardlink across devices, or link already exists\n            # we'll just symlink it if we can\n            # or otherwise copy it\n            pass\n\n    if symlink_ok:\n        # we can symlink anywhere except for /tftpboot because\n        # that is run chroot, so if we can symlink now, try it.\n        try:\n            if logger is not None:\n                logger.info(\"trying symlink %s -> %s\" % (src,dst))\n            rc = os.symlink(src, dst)\n            return rc\n        except (IOError, OSError):\n            pass\n\n    if cache:\n        try:\n            return cachefile(src,dst,api=api,logger=logger)\n        except (IOError, OSError):\n            pass\n\n    # we couldn't hardlink and we couldn't symlink so we must copy\n\n    return copyfile(src, dst, api=api, logger=logger)\n\ndef copyfile(src,dst,api=None,logger=None):\n    try:\n        if logger is not None:\n           logger.info(\"copying: %s -> %s\" % (src,dst))\n        rc = shutil.copyfile(src,dst)\n        return rc\n    except:\n        if not os.access(src,os.R_OK):\n            raise CX(_(\"Cannot read: %s\") % src)\n        if not os.path.samefile(src,dst):\n            # accomodate for the possibility that we already copied\n            # the file as a symlink/hardlink\n            raise\n            # traceback.print_exc()\n            # raise CX(_(\"Error copying %(src)s to %(dst)s\") % { \"src\" : src, \"dst\" : dst})\n\ndef check_openfiles(src):\n    \"\"\"\n    Used to check for open files on a mounted partition.\n    \"\"\"\n    try:\n        if not os.path.isdir(src):\n            raise CX(_(\"Error in check_openfiles: the source (%s) must be a directory\") % src)\n        cmd = [ \"/usr/sbin/lsof\", \"+D\", src, \"-Fn\", \"|\", \"wc\", \"-l\" ]\n        handle = sub_process.Popen(cmd, shell=True, stdout=sub_process.PIPE, close_fds=True)\n        out = handle.stdout\n        results = out.read()\n        return int(results)\n    except:\n        if not os.access(src,os.R_OK):\n            raise CX(_(\"Cannot read: %s\") % src)\n        if not os.path.samefile(src,dst):\n            # accomodate for the possibility that we already copied\n            # the file as a symlink/hardlink\n            raise\n\n\ndef copyfile_pattern(pattern,dst,require_match=True,symlink_ok=False,cache=True,api=None,logger=None):\n    files = glob.glob(pattern)\n    if require_match and not len(files) > 0:\n        raise CX(_(\"Could not find files matching %s\") % pattern)\n    for file in files:\n        base = os.path.basename(file)\n        dst1 = os.path.join(dst,os.path.basename(file))\n        linkfile(file,dst1,symlink_ok=symlink_ok,cache=cache,api=api,logger=logger)\n\ndef rmfile(path,logger=None):\n    try:\n        if logger is not None:\n           logger.info(\"removing: %s\" % path)\n        os.unlink(path)\n        return True\n    except OSError, ioe:\n        if not ioe.errno == errno.ENOENT: # doesn't exist\n            if logger is not None:\n                log_exc(logger)\n            raise CX(_(\"Error deleting %s\") % path)\n        return True\n\ndef rmtree_contents(path,logger=None):\n   what_to_delete = glob.glob(\"%s/*\" % path)\n   for x in what_to_delete:\n       rmtree(x,logger=logger)\n\ndef rmtree(path,logger=None):\n   try:\n       if os.path.isfile(path):\n           return rmfile(path,logger=logger)\n       else:\n           if logger is not None:\n               logger.info(\"removing: %s\" % path)\n           return shutil.rmtree(path,ignore_errors=True)\n   except OSError, ioe:\n       if logger is not None:\n           log_exc(logger)\n       if not ioe.errno == errno.ENOENT: # doesn't exist\n           raise CX(_(\"Error deleting %s\") % path)\n       return True\n\ndef mkdir(path,mode=0755,logger=None):\n   try:\n       if logger is not None:\n          logger.info(\"mkdir: %s\" % path)\n       return os.makedirs(path,mode)\n   except OSError, oe:\n       if not oe.errno == 17: # already exists (no constant for 17?)\n           if logger is not None:\n               log_exc(logger)\n           raise CX(_(\"Error creating %s\") % path)\n\ndef path_tail(apath, bpath):\n    \"\"\"\n    Given two paths (B is longer than A), find the part in B not in A\n    \"\"\"\n    position = bpath.find(apath)\n    if position != 0:\n        return \"\"\n    rposition = position + len(apath)\n    result = bpath[rposition:]\n    if not result.startswith(\"/\"):\n        result = \"/\" + result\n    return result\n\ndef set_redhat_management_key(self,key):\n   self.redhat_management_key = key\n   return True\n\ndef set_redhat_management_server(self,server):\n   self.redhat_management_server = server\n   return True\n\ndef set_arch(self,arch,repo=False):\n   if arch is None or arch == \"\" or arch == \"standard\" or arch == \"x86\":\n       arch = \"i386\"\n\n   if repo:\n       valids = [ \"i386\", \"x86_64\", \"ia64\", \"ppc\", \"ppc64\", \"s390\", \"s390x\", \"noarch\", \"src\", \"arm\" ]\n   else:\n       valids = [ \"i386\", \"x86_64\", \"ia64\", \"ppc\", \"ppc64\", \"s390\", \"s390x\", \"arm\" ]\n\n   if arch in valids:\n       self.arch = arch\n       return True\n\n   raise CX(\"arch choices include: %s\" % \", \".join(valids))\n\ndef set_os_version(self,os_version):\n   if os_version == \"\" or os_version is None:\n      self.os_version = \"\"\n      return True\n   self.os_version = os_version.lower()\n   if self.breed is None or self.breed == \"\":\n      raise CX(_(\"cannot set --os-version without setting --breed first\"))\n   if not self.breed in codes.VALID_OS_BREEDS:\n      raise CX(_(\"fix --breed first before applying this setting\"))\n   matched = codes.VALID_OS_VERSIONS[self.breed]\n   if not os_version in matched:\n      nicer = \", \".join(matched)\n      raise CX(_(\"--os-version for breed %s must be one of %s, given was %s\") % (self.breed, nicer, os_version))\n   self.os_version = os_version\n   return True\n\ndef set_breed(self,breed):\n   valid_breeds = codes.VALID_OS_BREEDS\n   if breed is not None and breed.lower() in valid_breeds:\n       self.breed = breed.lower()\n       return True\n   nicer = \", \".join(valid_breeds)\n   raise CX(_(\"invalid value for --breed (%s), must be one of %s, different breeds have different levels of support\") % (breed, nicer))\n\ndef set_repo_os_version(self,os_version):\n   if os_version == \"\" or os_version is None:\n      self.os_version = \"\"\n      return True\n   self.os_version = os_version.lower()\n   if self.breed is None or self.breed == \"\":\n      raise CX(_(\"cannot set --os-version without setting --breed first\"))\n   if not self.breed in codes.VALID_REPO_BREEDS:\n      raise CX(_(\"fix --breed first before applying this setting\"))\n   self.os_version = os_version\n   return True\n\ndef set_repo_breed(self,breed):\n   valid_breeds = codes.VALID_REPO_BREEDS\n   if breed is not None and breed.lower() in valid_breeds:\n       self.breed = breed.lower()\n       return True\n   nicer = \", \".join(valid_breeds)\n   raise CX(_(\"invalid value for --breed (%s), must be one of %s, different breeds have different levels of support\") % (breed, nicer))\n\ndef set_repos(self,repos,bypass_check=False):\n   # WARNING: hack\n   # repos = fix_mod_python_select_submission(repos)\n\n   # allow the magic inherit string to persist\n   if repos == \"<<inherit>>\":\n        self.repos = \"<<inherit>>\"\n        return True\n\n   # store as an array regardless of input type\n   if repos is None:\n        self.repos = []\n   else:\n        self.repos = input_string_or_list(repos)\n   if bypass_check:\n       return True\n\n   for r in self.repos:\n       if self.config.repos().find(name=r) is None:\n          raise CX(_(\"repo %s is not defined\") % r)\n\n   return True\n\ndef set_virt_file_size(self,num):\n    \"\"\"\n    For Virt only.\n    Specifies the size of the virt image in gigabytes.  \n    Older versions of koan (x<0.6.3) interpret 0 as \"don't care\"\n    Newer versions (x>=0.6.4) interpret 0 as \"no disks\"\n    \"\"\"\n    # num is a non-negative integer (0 means default)\n    # can also be a comma seperated list -- for usage with multiple disks\n\n    if num is None or num == \"\":\n        self.virt_file_size = 0\n        return True\n\n    if num == \"<<inherit>>\":\n        self.virt_file_size = \"<<inherit>>\"\n        return True\n\n    if isinstance(num, str) and num.find(\",\") != -1:\n        tokens = num.split(\",\")\n        for t in tokens:\n            # hack to run validation on each\n            self.set_virt_file_size(t)\n        # if no exceptions raised, good enough\n        self.virt_file_size = num\n        return True\n\n    try:\n        inum = int(num)\n        if inum != float(num):\n            return CX(_(\"invalid virt file size (%s)\" % num))\n        if inum >= 0:\n            self.virt_file_size = inum\n            return True\n        raise CX(_(\"invalid virt file size (%s)\" % num))\n    except:\n        raise CX(_(\"invalid virt file size (%s)\" % num))\n    return True\n\ndef set_virt_disk_driver(self,driver):\n    \"\"\"\n    For Virt only.\n    Specifies the on-disk format for the virtualized disk\n    \"\"\"\n    # FIXME: we should probably check the driver type\n    #        here against the libvirt/virtinst list of\n    #        drivers, but this makes things more flexible\n    #        meaning we don't have to manage this list\n    #        and it's up to the user not to enter an\n    #        unsupported disk format\n    self.virt_disk_driver = driver\n    return True\n\ndef set_virt_auto_boot(self,num):\n    \"\"\"\n    For Virt only.\n    Specifies whether the VM should automatically boot upon host reboot\n    0 tells Koan not to auto_boot virtuals\n    \"\"\"\n\n    if num == \"<<inherit>>\":\n        self.virt_auto_boot = \"<<inherit>>\"\n        return True\n\n    # num is a non-negative integer (0 means default)\n    try:\n        inum = int(num)\n        if (inum == 0) or (inum == 1):\n            self.virt_auto_boot = inum\n            return True\n        return CX(_(\"invalid virt_auto_boot value (%s): value must be either '0' (disabled) or '1' (enabled)\" % inum))\n    except:\n        return CX(_(\"invalid virt_auto_boot value (%s): value must be either '0' (disabled) or '1' (enabled)\" % inum))\n    return True\n\ndef set_virt_ram(self,num):\n    \"\"\"\n    For Virt only.\n    Specifies the size of the Virt RAM in MB.\n    0 tells Koan to just choose a reasonable default.\n    \"\"\"\n\n    if num == \"<<inherit>>\":\n        self.virt_ram = \"<<inherit>>\"\n        return True\n\n    # num is a non-negative integer (0 means default)\n    try:\n        inum = int(num)\n        if inum != float(num):\n            return CX(_(\"invalid virt ram size (%s)\" % num))\n        if inum >= 0:\n            self.virt_ram = inum\n            return True\n        return CX(_(\"invalid virt ram size (%s)\" % num))\n    except:\n        return CX(_(\"invalid virt ram size (%s)\" % num))\n    return True\n\ndef set_virt_type(self,vtype):\n    \"\"\"\n    Virtualization preference, can be overridden by koan.\n    \"\"\"\n\n    if vtype == \"<<inherit>>\":\n        self.virt_type == \"<<inherit>>\"\n        return True\n\n    if vtype.lower() not in [ \"qemu\", \"kvm\", \"xenpv\", \"xenfv\", \"vmware\", \"vmwarew\", \"auto\" ]:\n        raise CX(_(\"invalid virt type (%s)\" % vtype))\n    self.virt_type = vtype\n    return True\n\ndef set_virt_bridge(self,vbridge):\n    \"\"\"\n    The default bridge for all virtual interfaces under this profile.\n    \"\"\"\n    if vbridge is None or vbridge == \"\":\n       vbridge = self.settings.default_virt_bridge\n    self.virt_bridge = vbridge\n    return True\n\ndef set_virt_path(self,path,for_system=False):\n    \"\"\"\n    Virtual storage location suggestion, can be overriden by koan.\n    \"\"\"\n    if path is None:\n       path = \"\"\n    if for_system:\n       if path == \"\":\n          path = \"<<inherit>>\"\n    self.virt_path = path\n    return True\n\ndef set_virt_cpus(self,num):\n    \"\"\"\n    For Virt only.  Set the number of virtual CPUs to give to the\n    virtual machine.  This is fed to virtinst RAW, so cobbler\n    will not yelp if you try to feed it 9999 CPUs.  No formatting\n    like 9,999 please :)\n    \"\"\"\n    if num == \"\" or num is None:\n        self.virt_cpus = 1\n        return True\n\n    if num == \"<<inherit>>\":\n        self.virt_cpus = \"<<inherit>>\"\n        return True\n\n    try:\n        num = int(str(num))\n    except:\n        raise CX(_(\"invalid number of virtual CPUs (%s)\" % num))\n\n    self.virt_cpus = num\n    return True\n\ndef get_kickstart_templates(api):\n    files = {}\n    for x in api.profiles():\n        if x.kickstart is not None and x.kickstart != \"\" and x.kickstart != \"<<inherit>>\":\n            if os.path.exists(x.kickstart):\n                files[x.kickstart] = 1\n    for x in api.systems():\n        if x.kickstart is not None and x.kickstart != \"\" and x.kickstart != \"<<inherit>>\":\n            if os.path.exists(x.kickstart):\n                files[x.kickstart] = 1\n    for x in glob.glob(\"/var/lib/cobbler/kickstarts/*\"):\n        if os.path.isfile(x):\n            files[x] = 1\n    for x in glob.glob(\"/etc/cobbler/*.ks\"):\n        if os.path.isfile(x):\n            files[x] = 1\n\n    results = files.keys()\n    results.sort()\n    return results\n\ndef safe_filter(var):\n    if var is None:\n       return\n    if var.find(\"..\") != -1 or var.find(\";\") != -1:\n       raise CX(\"Invalid characters found in input\")\n\ndef is_selinux_enabled():\n    if not os.path.exists(\"/usr/sbin/selinuxenabled\"):\n       return False\n    args = \"/usr/sbin/selinuxenabled\"\n    selinuxenabled = sub_process.call(args,close_fds=True)\n    if selinuxenabled == 0:\n        return True\n    else:\n        return False\n\nimport os\nimport sys\nimport random\n\n# We cache the contents of /etc/mtab ... the following variables are used \n# to keep our cache in sync\nmtab_mtime = None\nmtab_map = []\n\nclass MntEntObj(object):\n    mnt_fsname = None #* name of mounted file system */\n    mnt_dir = None    #* file system path prefix */\n    mnt_type = None   #* mount type (see mntent.h) */\n    mnt_opts = None   #* mount options (see mntent.h) */\n    mnt_freq = 0      #* dump frequency in days */\n    mnt_passno = 0    #* pass number on parallel fsck */\n\n    def __init__(self,input=None):\n        if input and isinstance(input, str):\n            (self.mnt_fsname, self.mnt_dir, self.mnt_type, self.mnt_opts, \\\n             self.mnt_freq, self.mnt_passno) = input.split()\n    def __dict__(self):\n        return {\"mnt_fsname\": self.mnt_fsname, \"mnt_dir\": self.mnt_dir, \\\n                \"mnt_type\": self.mnt_type, \"mnt_opts\": self.mnt_opts, \\\n                \"mnt_freq\": self.mnt_freq, \"mnt_passno\": self.mnt_passno}\n    def __str__(self):\n        return \"%s %s %s %s %s %s\" % (self.mnt_fsname, self.mnt_dir, self.mnt_type, \\\n                                      self.mnt_opts, self.mnt_freq, self.mnt_passno)\n\ndef get_mtab(mtab=\"/etc/mtab\", vfstype=None):\n    global mtab_mtime, mtab_map\n\n    mtab_stat = os.stat(mtab)\n    if mtab_stat.st_mtime != mtab_mtime:\n        '''cache is stale ... refresh'''\n        mtab_mtime = mtab_stat.st_mtime\n        mtab_map = __cache_mtab__(mtab)\n\n    # was a specific fstype requested?\n    if vfstype:\n        mtab_type_map = []\n        for ent in mtab_map:\n            if ent.mnt_type == \"nfs\":\n                mtab_type_map.append(ent)\n        return mtab_type_map\n\n    return mtab_map\n\ndef __cache_mtab__(mtab=\"/etc/mtab\"):\n    global mtab_mtime\n\n    f = open(mtab)\n    mtab = [MntEntObj(line) for line in f.read().split('\\n') if len(line) > 0]\n    f.close()\n\n    return mtab\n\ndef get_file_device_path(fname):\n    '''What this function attempts to do is take a file and return:\n         - the device the file is on\n         - the path of the file relative to the device.\n       For example:\n         /boot/vmlinuz -> (/dev/sda3, /vmlinuz)\n         /boot/efi/efi/redhat/elilo.conf -> (/dev/cciss0, /elilo.conf)\n         /etc/fstab -> (/dev/sda4, /etc/fstab)\n    '''\n\n    # resolve any symlinks\n    fname = os.path.realpath(fname)\n\n    # convert mtab to a dict\n    mtab_dict = {}\n    for ent in get_mtab():\n        mtab_dict[ent.mnt_dir] = ent.mnt_fsname\n\n    # find a best match\n    fdir = os.path.dirname(fname)\n    match = mtab_dict.has_key(fdir)\n    while not match:\n        fdir = os.path.realpath(os.path.join(fdir, os.path.pardir))\n        match = mtab_dict.has_key(fdir)\n\n    # construct file path relative to device\n    if fdir != os.path.sep:\n        fname = fname[len(fdir):]\n\n    return (mtab_dict[fdir], fname)\n\ndef is_remote_file(file):\n    (dev, path) = get_file_device_path(file)\n    if dev.find(\":\") != -1:\n       return True\n    else:\n       return False\n\ndef subprocess_sp(logger, cmd, shell=True, input=None):\n    if logger is not None:\n        logger.info(\"running: %s\" % cmd)\n\n    stdin = None\n    if input:\n        stdin = sub_process.PIPE\n\n    try:\n        sp = sub_process.Popen(cmd, shell=shell, stdin=stdin, stdout=sub_process.PIPE, stderr=sub_process.PIPE, close_fds=True)\n    except OSError:\n        if logger is not None:\n            log_exc(logger)\n        die(logger, \"OS Error, command not found?  While running: %s\" % cmd)\n\n    (out,err) = sp.communicate(input)\n    rc = sp.returncode\n    if logger is not None:\n        logger.info(\"received on stdout: %s\" % out)\n        logger.debug(\"received on stderr: %s\" % err)\n    return out, rc\n\ndef subprocess_call(logger, cmd, shell=True, input=None):\n    data, rc = subprocess_sp(logger, cmd, shell=shell, input=input)\n    return rc\n\ndef subprocess_get(logger, cmd, shell=True, input=None):\n    data, rc = subprocess_sp(logger, cmd, shell=shell, input=input)\n    return data\n\ndef popen2(args, **kwargs):\n    \"\"\" \n    Leftovers from borrowing some bits from Snake, replace this \n    function with just the subprocess call.\n    \"\"\"\n    p = sub_process.Popen(args, stdout=sub_process.PIPE, stdin=sub_process.PIPE, **kwargs)\n    return (p.stdout, p.stdin)\n\ndef ram_consumption_of_guests(host, api):\n    guest_names = host.virt_guests\n    ttl_ram = 0\n    if len(guest_names) == 0:\n       # a system with no virt hosts already is our best\n       # candidate\n       return 0\n\n    for g in guest_names:\n       host_obj = api.find_system(g)\n       if host_obj is None:\n          # guest object was deleted but host was not updated\n          continue\n       host_data = blender(api,False,host_obj)\n       ram = host_data.get(\"virt_ram\", 512)\n       ttl_ram = ttl_ram + host_data[\"virt_ram\"]\n    return ttl_ram\n\n\n\ndef choose_virt_host(systems, api):\n    \"\"\"\n    From a list of systems, choose a system that can best host a virtual\n    machine.  This initial engine is not as optimal as it could be, but\n    works by determining the system with the least amount of VM RAM deployed\n    as defined by the amount of virtual ram on each guest for each guest\n    that the hosts hosts.  Hop on pop.  \n\n    This does assume hosts are reasonably homogenous.  In the future\n    this heuristic should be pluggable and be able to tap into other\n    external data sources and maybe basic usage stats.\n    \"\"\"\n     \n    if len(systems) == 0:\n       raise CX(\"empty candidate systems list\")\n    by_name = {}\n    least_host = systems[0] \n    least_host_ct = -1\n    for s in systems:\n       ct = ram_consumption_of_guests(s, api)\n       if (ct < least_host_ct) or (least_host_ct == -1):\n          least_host = s\n          least_host_ct = ct\n    return least_host.name\n\ndef os_system(cmd):\n    \"\"\"\n    os.system doesn't close file descriptors, so this is a wrapper\n    to ensure we never use it.\n    \"\"\"\n    rc = sub_process.call(cmd, shell=True, close_fds=True)\n    return rc\n\ndef clear_from_fields(obj, fields, is_subobject=False):\n    \"\"\"\n    Used by various item_*.py classes for automating datastructure boilerplate.\n    \"\"\"\n    for elems in fields:\n        # if elems startswith * it's an interface field and we do not operate on it.\n        if elems[0].startswith(\"*\") or elems[0].find(\"widget\") != -1:\n           continue\n        if is_subobject:\n           val = elems[2]\n        else:\n           val = elems[1]\n        if isinstance(val,basestring):\n           if val.startswith(\"SETTINGS:\"):\n               setkey = val.split(\":\")[-1]\n               val = getattr(obj.settings, setkey)\n        setattr(obj, elems[0], val)\n\n    if obj.COLLECTION_TYPE == \"system\":\n        obj.interfaces = {}\n\ndef from_datastruct_from_fields(obj, seed_data, fields):\n\n    for elems in fields:\n        # we don't have to load interface fields here\n        if elems[0].startswith(\"*\") or elems[0].find(\"widget\") != -1:\n            continue\n        src_k = dst_k = elems[0]\n        # deprecated field switcheroo\n        if field_info.DEPRECATED_FIELDS.has_key(src_k):\n            dst_k = field_info.DEPRECATED_FIELDS[src_k]\n        if seed_data.has_key(src_k):\n            setattr(obj, dst_k, seed_data[src_k])\n\n    if obj.uid == '':\n        obj.uid = obj.config.generate_uid()\n\n    # special handling for interfaces\n    if obj.COLLECTION_TYPE == \"system\":\n        obj.interfaces = copy.deepcopy(seed_data[\"interfaces\"])\n        # deprecated field switcheroo for interfaces\n        for interface in obj.interfaces.keys():\n            for k in obj.interfaces[interface].keys():\n                if field_info.DEPRECATED_FIELDS.has_key(k):\n                    if not obj.interfaces[interface].has_key(field_info.DEPRECATED_FIELDS[k]) or \\\n                           obj.interfaces[interface][field_info.DEPRECATED_FIELDS[k]] == \"\":\n                        obj.interfaces[interface][field_info.DEPRECATED_FIELDS[k]] = obj.interfaces[interface][k]\n\n    return obj\n\ndef get_methods_from_fields(obj, fields):\n    ds = {}\n    for elem in fields:\n        k = elem[0]\n        # modify interfaces is handled differently, and need not work this way\n        if k.startswith(\"*\") or k.find(\"widget\") != -1:\n            continue\n        setfn = getattr(obj, \"set_%s\" % k)\n        ds[k] = setfn\n    return ds\n\ndef to_datastruct_from_fields(obj, fields):\n    ds = {}\n    for elem in fields:\n        k = elem[0]\n        if k.startswith(\"*\") or k.find(\"widget\") != -1:\n            continue\n        data = getattr(obj, k)\n        ds[k] = data\n    # interfaces on systems require somewhat special handling\n    # they are the only exception in Cobbler.\n    if obj.COLLECTION_TYPE == \"system\":\n        ds[\"interfaces\"] = copy.deepcopy(obj.interfaces)\n        #for interface in ds[\"interfaces\"].keys():\n        #    for k in ds[\"interfaces\"][interface].keys():\n        #        if field_info.DEPRECATED_FIELDS.has_key(k):\n        #            ds[\"interfaces\"][interface][field_info.DEPRECATED_FIELDS[k]] = ds[\"interfaces\"][interface][k]\n\n    return ds\n\ndef printable_from_fields(obj, fields):\n    \"\"\"\n    Obj is a hash datastructure, fields is something like item_distro.FIELDS\n    \"\"\"\n    buf  = \"\"\n    keys = []\n    for elem in fields:\n       keys.append((elem[0], elem[3], elem[4]))\n    keys.sort()\n    buf = buf + \"%-30s : %s\\n\" % (\"Name\", obj[\"name\"])\n    for (k, nicename, editable) in keys:\n       # FIXME: supress fields users don't need to see?\n       # FIXME: interfaces should be sorted\n       # FIXME: print ctime, mtime nicely\n       if k.startswith(\"*\") or not editable or k.find(\"widget\") != -1:\n           continue\n\n       if k != \"name\":\n           # FIXME: move examples one field over, use description here.\n           buf = buf + \"%-30s : %s\\n\" % (nicename, obj[k])\n\n    # somewhat brain-melting special handling to print the hashes\n    # inside of the interfaces more neatly.\n    if obj.has_key(\"interfaces\"):\n       for iname in obj[\"interfaces\"].keys():\n          # FIXME: inames possibly not sorted\n          buf = buf + \"%-30s : %s\\n\" % (\"Interface ===== \",iname)\n          for (k, nicename, editable) in keys:\n             nkey = k.replace(\"*\",\"\")\n             if k.startswith(\"*\") and editable:\n                 buf = buf + \"%-30s : %s\\n\" % (nicename, obj[\"interfaces\"][iname].get(nkey,\"\"))\n\n    return buf\n\ndef matches_args(args, list_of):\n    \"\"\"\n    Used to simplify some code around which arguments to add when.\n    \"\"\"\n    for x in args:\n        if x in list_of:\n            return True\n    return False\n\ndef add_options_from_fields(object_type, parser, fields, object_action):\n    for elem in fields:\n        k = elem[0] \n        if k.find(\"widget\") != -1:\n            continue\n        # scrub interface tags so all fields get added correctly.\n        k = k.replace(\"*\",\"\")\n        default = elem[1]\n        nicename = elem[3]\n        tooltip = elem[5]\n        choices = elem[6]\n        if field_info.ALTERNATE_OPTIONS.has_key(k):\n            niceopt = field_info.ALTERNATE_OPTIONS[k]\n        else:\n            niceopt = \"--%s\" % k.replace(\"_\",\"-\")\n        desc = nicename\n        if tooltip != \"\":\n            desc = nicename + \" (%s)\" % tooltip\n\n        aliasopt = []\n        for deprecated_field in field_info.DEPRECATED_FIELDS.keys():\n            if field_info.DEPRECATED_FIELDS[deprecated_field] == k:\n                aliasopt.append(\"--%s\" % deprecated_field)\n\n        if isinstance(choices, list) and len(choices) != 0:\n            desc = desc + \" (valid options: %s)\" % \",\".join(choices)    \n            parser.add_option(niceopt, dest=k, help=desc, choices=choices)\n            for alias in aliasopt:\n                parser.add_option(alias, dest=k, help=desc, choices=choices)\n        else:\n            parser.add_option(niceopt, dest=k, help=desc)\n            for alias in aliasopt:\n                parser.add_option(alias, dest=k, help=desc)\n\n\n    # FIXME: not supported in 2.0?\n    if not object_action in [\"dumpvars\",\"find\",\"remove\",\"report\",\"list\"]: \n        # FIXME: implement\n        parser.add_option(\"--clobber\", dest=\"clobber\", help=\"allow add to overwrite existing objects\", action=\"store_true\")\n        parser.add_option(\"--in-place\", action=\"store_true\", default=False, dest=\"in_place\", help=\"edit items in kopts or ksmeta without clearing the other items\")\n    if object_action in [\"copy\",\"rename\"]:\n        parser.add_option(\"--newname\", help=\"new object name\")\n    # FIXME: not supported in 2.0 ?\n    #if not object_action in [\"dumpvars\",\"find\",\"remove\",\"report\",\"list\"]: \n    #    parser.add_option(\"--no-sync\",     action=\"store_true\", dest=\"nosync\", help=\"suppress sync for speed\")\n    # FIXME: not supported in 2.0 ?\n    # if not matches_args(args,[\"dumpvars\",\"report\",\"list\"]):\n    #    parser.add_option(\"--no-triggers\", action=\"store_true\", dest=\"notriggers\", help=\"suppress trigger execution\")\n    if object_action in [\"remove\"]:\n        parser.add_option(\"--recursive\", action=\"store_true\", dest=\"recursive\", help=\"also delete child objects\")\n    if object_type == \"system\":\n        # system object\n        parser.add_option(\"--interface\", dest=\"interface\", help=\"which interface to edit\")\n        parser.add_option(\"--delete-interface\", dest=\"delete_interface\", action=\"store_true\")\n\n\ndef get_remote_methods_from_fields(obj,fields):\n    \"\"\"\n    Return the name of set functions for all fields, keyed by the field name.\n    \"\"\"\n    ds = {}\n    for elem in fields:\n       name = elem[0].replace(\"*\",\"\")\n       if name.find(\"widget\") == -1:\n          ds[name] = getattr(obj,\"set_%s\" % name)\n    if obj.COLLECTION_TYPE == \"system\":\n       ds[\"modify_interface\"] = getattr(obj,\"modify_interface\")\n       ds[\"delete_interface\"] = getattr(obj,\"delete_interface\")\n    return ds\n\ndef get_power_types():\n    \"\"\"\n    Return all possible power types\n    \"\"\"\n    power_types = []\n    power_template = re.compile(r'fence_(.*)')\n    for x in glob.glob(\"/usr/sbin/fence_*\"):\n        power_types.append(power_template.search(x).group(1))\n    power_types.sort()\n    return power_types\n\ndef get_power(powertype=None):\n    \"\"\"\n    Return power command for type\n    \"\"\"\n    if powertype:\n        powerpath = \"/usr/sbin/fence_%s\" % powertype\n        if os.path.isfile(powerpath) and os.access(powerpath, os.X_OK):\n            return powerpath\n    return None\n\ndef get_power_template(powertype=None):\n    \"\"\"\n    Return power template for type\n    \"\"\"\n    if powertype:\n        powertemplate = \"/etc/cobbler/power/fence_%s.template\" % powertype\n        if os.path.isfile(powertemplate):\n            f = open(powertemplate)\n            template = f.read()\n            f.close()\n            return template\n    # return a generic template if a specific one wasn't found\n    return \"action=$power_mode\\nlogin=$power_user\\npasswd=$power_pass\\nipaddr=$power_address\\nport=$power_id\"\n\ndef get_shared_secret():\n    \"\"\"\n    The 'web.ss' file is regenerated each time cobblerd restarts and is\n    used to agree on shared secret interchange between mod_python and\n    cobblerd, and also the CLI and cobblerd, when username/password\n    access is not required.  For the CLI, this enables root users\n    to avoid entering username/pass if on the cobbler server.\n    \"\"\"\n\n    try:\n       fd = open(\"/var/lib/cobbler/web.ss\")\n       data = fd.read()\n    except:\n       return -1\n    return str(data).strip()\n\ndef local_get_cobbler_api_url():\n    # Load server and http port\n    try:\n        fh = open(\"/etc/cobbler/settings\")\n        data = yaml.safe_load(fh.read())\n        fh.close()\n    except:\n       traceback.print_exc()\n       raise CX(\"/etc/cobbler/settings is not a valid YAML file\")\n\n    if data.get(\"client_use_localhost\", False):\n      return \"http://%s:%s/cobbler_api\" % (\"127.0.0.1\",data.get(\"http_port\",\"80\"))\n    else:\n      return \"http://%s:%s/cobbler_api\" % (data.get(\"server\",\"127.0.0.1\"),data.get(\"http_port\",\"80\"))\n\ndef get_ldap_template(ldaptype=None):\n    \"\"\"\n    Return ldap command for type\n    \"\"\"\n    if ldaptype:\n        ldappath = \"/etc/cobbler/ldap/ldap_%s.template\" % ldaptype\n        if os.path.isfile(ldappath):\n            return ldappath\n    return None\n\ndef local_get_cobbler_xmlrpc_url():\n    # Load xmlrpc port\n    try:\n        fh = open(\"/etc/cobbler/settings\")\n        data = yaml.safe_load(fh.read())\n        fh.close()\n    except:\n       traceback.print_exc()\n       raise CX(\"/etc/cobbler/settings is not a valid YAML file\")\n    return \"http://%s:%s\" % (\"127.0.0.1\",data.get(\"xmlrpc_port\",\"25151\"))\n\ndef strip_none(data, omit_none=False):\n    \"\"\"\n    Remove \"none\" entries from datastructures.\n    Used prior to communicating with XMLRPC.\n    \"\"\"\n    if data is None:\n        data = '~'\n\n    elif isinstance(data, list):\n        data2 = []\n        for x in data:\n            if omit_none and x is None:\n                pass\n            else:\n                data2.append(strip_none(x))\n        return data2\n\n    elif isinstance(data, dict):\n        data2 = {}\n        for key in data.keys():\n            keydata = data[key]\n            if omit_none and data[key] is None:\n                pass\n            else:\n                data2[str(key)] = strip_none(data[key])\n        return data2\n\n    return data\n\ndef cli_find_via_xmlrpc(remote, otype, options):\n    \"\"\"\n    Given an options object and a remote handle, find options matching\n    the criteria given.\n    \"\"\"\n    criteria = strip_none2(options.__dict__)\n    return remote.find_items(otype,criteria,\"name\",False)\n\n# -------------------------------------------------------\n    \ndef loh_to_hoh(datastruct, indexkey):\n    \"\"\"\n    things like get_distros() returns a list of a hashes\n    convert this to a hash of hashes keyed off of an arbitrary field\n\n    EX:  [  { \"a\" : 2 }, { \"a : 3 } ]  ->  { \"2\" : { \"a\" : 2 }, \"3\" : { \"a\" : \"3\" }\n\n    \"\"\"\n    results = {}\n    for item in datastruct:\n        results[item[indexkey]] = item\n    return results\n\n# -------------------------------------------------------\n\ndef loh_sort_by_key(datastruct, indexkey):\n    \"\"\"\n    Sorts a list of hashes by a given key in the hashes\n    note: this is a destructive operation\n    \"\"\"\n    datastruct.sort(lambda a, b: a[indexkey] < b[indexkey])\n    return datastruct\n\ndef dhcpconf_location(api):\n    version = api.os_version\n    (dist, ver) = api.get_os_details()\n    if version[0] in [ \"redhat\", \"centos\" ] and version[1] < 6:\n        return \"/etc/dhcpd.conf\"\n    elif version[0] in [ \"fedora\" ] and version[1] < 11: \n        return \"/etc/dhcpd.conf\"\n    elif dist == \"suse\":\n        return \"/etc/dhcpd.conf\"\n    else:\n        return \"/etc/dhcp/dhcpd.conf\"\n\ndef link_distro(settings, distro):\n    # find the tree location\n    base = find_distro_path(settings, distro)\n    if not base:\n        return\n\n    dest_link = os.path.join(settings.webdir, \"links\", distro.name)\n\n    # create the links directory only if we are mirroring because with\n    # SELinux Apache can't symlink to NFS (without some doing)\n\n    if not os.path.lexists(dest_link):\n        try:\n            os.symlink(base, dest_link)\n        except:\n            # this shouldn't happen but I've seen it ... debug ...\n            print _(\"- symlink creation failed: %(base)s, %(dest)s\") % { \"base\" : base, \"dest\" : dest_link }\n\ndef find_distro_path(settings, distro):\n    possible_dirs = glob.glob(settings.webdir+\"/ks_mirror/*\")\n    for dir in possible_dirs:\n        if os.path.dirname(distro.kernel).find(dir) != -1:\n            return os.path.join(settings.webdir, \"ks_mirror\", dir)\n    # non-standard directory, assume it's the same as the\n    # directory in which the given distro's kernel is\n    return os.path.dirname(distro.kernel)\n\nif __name__ == \"__main__\":\n    print os_release() # returns 2, not 3\n\n\n"], "filenames": ["cobbler/action_power.py", "cobbler/item_system.py", "cobbler/utils.py"], "buggy_code_start_loc": [72, 57, 1683], "buggy_code_end_loc": [151, 62, 1981], "fixing_code_start_loc": [72, 57, 1683], "fixing_code_end_loc": [126, 62, 2001], "type": "NVD-CWE-Other", "message": "Incomplete blacklist vulnerability in action_power.py in Cobbler 2.2.0 allows remote attackers to execute arbitrary commands via shell metacharacters in the (1) username or (2) password fields to the power_system method in the xmlrpc API.", "other": {"cve": {"id": "CVE-2012-2395", "sourceIdentifier": "secalert@redhat.com", "published": "2012-06-16T00:55:07.310", "lastModified": "2023-02-13T04:33:34.770", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "Incomplete blacklist vulnerability in action_power.py in Cobbler 2.2.0 allows remote attackers to execute arbitrary commands via shell metacharacters in the (1) username or (2) password fields to the power_system method in the xmlrpc API."}, {"lang": "es", "value": "Vulnerabilidad de lista negra incompleta en action_power.py de Cobbler 2.2.0. Permite a atacantes remotos ejecutar comandos arbitrarios a trav\u00e9s de meta-caracteres de shell en los campos (1) username o (2) password del m\u00e9todo power_system method del API xmlrpc."}], "metrics": {"cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:P/I:P/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 7.5}, "baseSeverity": "HIGH", "exploitabilityScore": 10.0, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "NVD-CWE-Other"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:michael_dehaan:cobbler:2.2.0:*:*:*:*:*:*:*", "matchCriteriaId": "3937A0E5-7F9D-4FC5-9D0A-EE11C43A51FC"}]}]}], "references": [{"url": "http://lists.opensuse.org/opensuse-security-announce/2012-05/msg00016.html", "source": "secalert@redhat.com"}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2012-07/msg00000.html", "source": "secalert@redhat.com"}, {"url": "http://www.openwall.com/lists/oss-security/2012/05/23/18", "source": "secalert@redhat.com"}, {"url": "http://www.openwall.com/lists/oss-security/2012/05/23/4", "source": "secalert@redhat.com"}, {"url": "http://www.securityfocus.com/bid/53666", "source": "secalert@redhat.com"}, {"url": "https://bugs.launchpad.net/ubuntu/+source/cobbler/+bug/978999", "source": "secalert@redhat.com"}, {"url": "https://github.com/cobbler/cobbler/commit/6d9167e5da44eca56bdf42b5776097a6779aaadf", "source": "secalert@redhat.com", "tags": ["Exploit", "Patch"]}, {"url": "https://github.com/cobbler/cobbler/issues/141", "source": "secalert@redhat.com"}]}, "github_commit_url": "https://github.com/cobbler/cobbler/commit/6d9167e5da44eca56bdf42b5776097a6779aaadf"}}
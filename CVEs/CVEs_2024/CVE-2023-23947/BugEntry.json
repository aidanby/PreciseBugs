{"buggy_code": ["package common\n\nimport (\n\t\"errors\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strconv\"\n\t\"time\"\n\n\t\"github.com/sirupsen/logrus\"\n)\n\n// Default service addresses and URLS of Argo CD internal services\nconst (\n\t// DefaultRepoServerAddr is the gRPC address of the Argo CD repo server\n\tDefaultRepoServerAddr = \"argocd-repo-server:8081\"\n\t// DefaultDexServerAddr is the HTTP address of the Dex OIDC server, which we run a reverse proxy against\n\tDefaultDexServerAddr = \"argocd-dex-server:5556\"\n\t// DefaultRedisAddr is the default redis address\n\tDefaultRedisAddr = \"argocd-redis:6379\"\n)\n\n// Kubernetes ConfigMap and Secret resource names which hold Argo CD settings\nconst (\n\tArgoCDConfigMapName              = \"argocd-cm\"\n\tArgoCDSecretName                 = \"argocd-secret\"\n\tArgoCDNotificationsConfigMapName = \"argocd-notifications-cm\"\n\tArgoCDNotificationsSecretName    = \"argocd-notifications-secret\"\n\tArgoCDRBACConfigMapName          = \"argocd-rbac-cm\"\n\t// Contains SSH known hosts data for connecting repositories. Will get mounted as volume to pods\n\tArgoCDKnownHostsConfigMapName = \"argocd-ssh-known-hosts-cm\"\n\t// Contains TLS certificate data for connecting repositories. Will get mounted as volume to pods\n\tArgoCDTLSCertsConfigMapName = \"argocd-tls-certs-cm\"\n\tArgoCDGPGKeysConfigMapName  = \"argocd-gpg-keys-cm\"\n)\n\n// Some default configurables\nconst (\n\tDefaultSystemNamespace = \"kube-system\"\n\tDefaultRepoType        = \"git\"\n)\n\n// Default listener ports for ArgoCD components\nconst (\n\tDefaultPortAPIServer              = 8080\n\tDefaultPortRepoServer             = 8081\n\tDefaultPortArgoCDMetrics          = 8082\n\tDefaultPortArgoCDAPIServerMetrics = 8083\n\tDefaultPortRepoServerMetrics      = 8084\n)\n\n// Default listener address for ArgoCD components\nconst (\n\tDefaultAddressAPIServer = \"localhost\"\n)\n\n// Default paths on the pod's file system\nconst (\n\t// The default path where TLS certificates for repositories are located\n\tDefaultPathTLSConfig = \"/app/config/tls\"\n\t// The default path where SSH known hosts are stored\n\tDefaultPathSSHConfig = \"/app/config/ssh\"\n\t// Default name for the SSH known hosts file\n\tDefaultSSHKnownHostsName = \"ssh_known_hosts\"\n\t// Default path to GnuPG home directory\n\tDefaultGnuPgHomePath = \"/app/config/gpg/keys\"\n\t// Default path to repo server TLS endpoint config\n\tDefaultAppConfigPath = \"/app/config\"\n\t// Default path to cmp server plugin socket file\n\tDefaultPluginSockFilePath = \"/home/argocd/cmp-server/plugins\"\n\t// Default path to cmp server plugin configuration file\n\tDefaultPluginConfigFilePath = \"/home/argocd/cmp-server/config\"\n\t// Plugin Config File is a ConfigManagementPlugin manifest located inside the plugin container\n\tPluginConfigFileName = \"plugin.yaml\"\n)\n\n// Argo CD application related constants\nconst (\n\n\t// ArgoCDAdminUsername is the username of the 'admin' user\n\tArgoCDAdminUsername = \"admin\"\n\t// ArgoCDUserAgentName is the default user-agent name used by the gRPC API client library and grpc-gateway\n\tArgoCDUserAgentName = \"argocd-client\"\n\t// ArgoCDSSAManager is the default argocd manager name used by server-side apply syncs\n\tArgoCDSSAManager = \"argocd-controller\"\n\t// AuthCookieName is the HTTP cookie name where we store our auth token\n\tAuthCookieName = \"argocd.token\"\n\t// StateCookieName is the HTTP cookie name that holds temporary nonce tokens for CSRF protection\n\tStateCookieName = \"argocd.oauthstate\"\n\t// StateCookieMaxAge is the maximum age of the oauth state cookie\n\tStateCookieMaxAge = time.Minute * 5\n\n\t// ChangePasswordSSOTokenMaxAge is the max token age for password change operation\n\tChangePasswordSSOTokenMaxAge = time.Minute * 5\n\t// GithubAppCredsExpirationDuration is the default time used to cache the GitHub app credentials\n\tGithubAppCredsExpirationDuration = time.Minute * 60\n\n\t// PasswordPatten is the default password patten\n\tPasswordPatten = `^.{8,32}$`\n)\n\n// Dex related constants\nconst (\n\t// DexAPIEndpoint is the endpoint where we serve the Dex API server\n\tDexAPIEndpoint = \"/api/dex\"\n\t// LoginEndpoint is Argo CD's shorthand login endpoint which redirects to dex's OAuth 2.0 provider's consent page\n\tLoginEndpoint = \"/auth/login\"\n\t// LogoutEndpoint is Argo CD's shorthand logout endpoint which invalidates OIDC session after logout\n\tLogoutEndpoint = \"/auth/logout\"\n\t// CallbackEndpoint is Argo CD's final callback endpoint we reach after OAuth 2.0 login flow has been completed\n\tCallbackEndpoint = \"/auth/callback\"\n\t// DexCallbackEndpoint is Argo CD's final callback endpoint when Dex is configured\n\tDexCallbackEndpoint = \"/api/dex/callback\"\n\t// ArgoCDClientAppName is name of the Oauth client app used when registering our web app to dex\n\tArgoCDClientAppName = \"Argo CD\"\n\t// ArgoCDClientAppID is the Oauth client ID we will use when registering our app to dex\n\tArgoCDClientAppID = \"argo-cd\"\n\t// ArgoCDCLIClientAppName is name of the Oauth client app used when registering our CLI to dex\n\tArgoCDCLIClientAppName = \"Argo CD CLI\"\n\t// ArgoCDCLIClientAppID is the Oauth client ID we will use when registering our CLI to dex\n\tArgoCDCLIClientAppID = \"argo-cd-cli\"\n)\n\n// Resource metadata labels and annotations (keys and values) used by Argo CD components\nconst (\n\t// LabelKeyAppInstance is the label key to use to uniquely identify the instance of an application\n\t// The Argo CD application name is used as the instance name\n\tLabelKeyAppInstance = \"app.kubernetes.io/instance\"\n\t// LabelKeyLegacyApplicationName is the legacy label (v0.10 and below) and is superseded by 'app.kubernetes.io/instance'\n\tLabelKeyLegacyApplicationName = \"applications.argoproj.io/app-name\"\n\t// LabelKeySecretType contains the type of argocd secret (currently: 'cluster', 'repository', 'repo-config' or 'repo-creds')\n\tLabelKeySecretType = \"argocd.argoproj.io/secret-type\"\n\t// LabelValueSecretTypeCluster indicates a secret type of cluster\n\tLabelValueSecretTypeCluster = \"cluster\"\n\t// LabelValueSecretTypeRepository indicates a secret type of repository\n\tLabelValueSecretTypeRepository = \"repository\"\n\t// LabelValueSecretTypeRepoCreds indicates a secret type of repository credentials\n\tLabelValueSecretTypeRepoCreds = \"repo-creds\"\n\n\t// The Argo CD application name is used as the instance name\n\tAnnotationKeyAppInstance = \"argocd.argoproj.io/tracking-id\"\n\n\t// AnnotationCompareOptions is a comma-separated list of options for comparison\n\tAnnotationCompareOptions = \"argocd.argoproj.io/compare-options\"\n\n\t// AnnotationKeyManagedBy is annotation name which indicates that k8s resource is managed by an application.\n\tAnnotationKeyManagedBy = \"managed-by\"\n\t// AnnotationValueManagedByArgoCD is a 'managed-by' annotation value for resources managed by Argo CD\n\tAnnotationValueManagedByArgoCD = \"argocd.argoproj.io\"\n\n\t// AnnotationKeyLinkPrefix tells the UI to add an external link icon to the application node\n\t// that links to the value given in the annotation.\n\t// The annotation key must be followed by a unique identifier. Ex: link.argocd.argoproj.io/dashboard\n\t// It's valid to have multiple annotations that match the prefix.\n\t// Values can simply be a url or they can have\n\t// an optional link title separated by a \"|\"\n\t// Ex: \"http://grafana.example.com/d/yu5UH4MMz/deployments\"\n\t// Ex: \"Go to Dashboard|http://grafana.example.com/d/yu5UH4MMz/deployments\"\n\tAnnotationKeyLinkPrefix = \"link.argocd.argoproj.io/\"\n)\n\n// Environment variables for tuning and debugging Argo CD\nconst (\n\t// EnvVarSSODebug is an environment variable to enable additional OAuth debugging in the API server\n\tEnvVarSSODebug = \"ARGOCD_SSO_DEBUG\"\n\t// EnvVarRBACDebug is an environment variable to enable additional RBAC debugging in the API server\n\tEnvVarRBACDebug = \"ARGOCD_RBAC_DEBUG\"\n\t// Overrides the location where SSH known hosts for repo access data is stored\n\tEnvVarSSHDataPath = \"ARGOCD_SSH_DATA_PATH\"\n\t// Overrides the location where TLS certificate for repo access data is stored\n\tEnvVarTLSDataPath = \"ARGOCD_TLS_DATA_PATH\"\n\t// Specifies number of git remote operations attempts count\n\tEnvGitAttemptsCount = \"ARGOCD_GIT_ATTEMPTS_COUNT\"\n\t// Specifices max duration of git remote operation retry\n\tEnvGitRetryMaxDuration = \"ARGOCD_GIT_RETRY_MAX_DURATION\"\n\t// Specifies duration of git remote operation retry\n\tEnvGitRetryDuration = \"ARGOCD_GIT_RETRY_DURATION\"\n\t// Specifies fator of git remote operation retry\n\tEnvGitRetryFactor = \"ARGOCD_GIT_RETRY_FACTOR\"\n\t// Overrides git submodule support, true by default\n\tEnvGitSubmoduleEnabled = \"ARGOCD_GIT_MODULES_ENABLED\"\n\t// EnvGnuPGHome is the path to ArgoCD's GnuPG keyring for signature verification\n\tEnvGnuPGHome = \"ARGOCD_GNUPGHOME\"\n\t// EnvWatchAPIBufferSize is the buffer size used to transfer K8S watch events to watch API consumer\n\tEnvWatchAPIBufferSize = \"ARGOCD_WATCH_API_BUFFER_SIZE\"\n\t// EnvPauseGenerationAfterFailedAttempts will pause manifest generation after the specified number of failed generation attempts\n\tEnvPauseGenerationAfterFailedAttempts = \"ARGOCD_PAUSE_GEN_AFTER_FAILED_ATTEMPTS\"\n\t// EnvPauseGenerationMinutes pauses manifest generation for the specified number of minutes, after sufficient manifest generation failures\n\tEnvPauseGenerationMinutes = \"ARGOCD_PAUSE_GEN_MINUTES\"\n\t// EnvPauseGenerationRequests pauses manifest generation for the specified number of requests, after sufficient manifest generation failures\n\tEnvPauseGenerationRequests = \"ARGOCD_PAUSE_GEN_REQUESTS\"\n\t// EnvControllerReplicas is the number of controller replicas\n\tEnvControllerReplicas = \"ARGOCD_CONTROLLER_REPLICAS\"\n\t// EnvControllerShard is the shard number that should be handled by controller\n\tEnvControllerShard = \"ARGOCD_CONTROLLER_SHARD\"\n\t// EnvEnableGRPCTimeHistogramEnv enables gRPC metrics collection\n\tEnvEnableGRPCTimeHistogramEnv = \"ARGOCD_ENABLE_GRPC_TIME_HISTOGRAM\"\n\t// EnvGithubAppCredsExpirationDuration controls the caching of Github app credentials. This value is in minutes (default: 60)\n\tEnvGithubAppCredsExpirationDuration = \"ARGOCD_GITHUB_APP_CREDS_EXPIRATION_DURATION\"\n\t// EnvHelmIndexCacheDuration controls how the helm repository index file is cached for (default: 0)\n\tEnvHelmIndexCacheDuration = \"ARGOCD_HELM_INDEX_CACHE_DURATION\"\n\t// EnvRepoServerConfigPath allows to override the configuration path for repo server\n\tEnvAppConfigPath = \"ARGOCD_APP_CONF_PATH\"\n\t// EnvLogFormat log format that is defined by `--logformat` option\n\tEnvLogFormat = \"ARGOCD_LOG_FORMAT\"\n\t// EnvLogLevel log level that is defined by `--loglevel` option\n\tEnvLogLevel = \"ARGOCD_LOG_LEVEL\"\n\t// EnvMaxCookieNumber max number of chunks a cookie can be broken into\n\tEnvMaxCookieNumber = \"ARGOCD_MAX_COOKIE_NUMBER\"\n\t// EnvPluginSockFilePath allows to override the pluginSockFilePath for repo server and cmp server\n\tEnvPluginSockFilePath = \"ARGOCD_PLUGINSOCKFILEPATH\"\n\t// EnvCMPChunkSize defines the chunk size in bytes used when sending files to the cmp server\n\tEnvCMPChunkSize = \"ARGOCD_CMP_CHUNK_SIZE\"\n\t// EnvCMPWorkDir defines the full path of the work directory used by the CMP server\n\tEnvCMPWorkDir = \"ARGOCD_CMP_WORKDIR\"\n)\n\n// Config Management Plugin related constants\nconst (\n\t// DefaultCMPChunkSize defines chunk size in bytes used when sending files to the cmp server\n\tDefaultCMPChunkSize = 1024\n\n\t// DefaultCMPWorkDirName defines the work directory name used by the cmp-server\n\tDefaultCMPWorkDirName = \"_cmp_server\"\n\n\tConfigMapPluginDeprecationWarning = \"argocd-cm plugins are deprecated, and support will be removed in v2.7. Upgrade your plugin to be installed via sidecar. https://argo-cd.readthedocs.io/en/stable/user-guide/config-management-plugins/\"\n)\n\nconst (\n\t// MinClientVersion is the minimum client version that can interface with this API server.\n\t// When introducing breaking changes to the API or datastructures, this number should be bumped.\n\t// The value here may be lower than the current value in VERSION\n\tMinClientVersion = \"1.4.0\"\n\t// CacheVersion is a objects version cached using util/cache/cache.go.\n\t// Number should be bumped in case of backward incompatible change to make sure cache is invalidated after upgrade.\n\tCacheVersion = \"1.8.3\"\n)\n\n// Constants used by util/clusterauth package\nconst (\n\tClusterAuthRequestTimeout = 10 * time.Second\n\tBearerTokenTimeout        = 30 * time.Second\n)\n\nconst (\n\tDefaultGitRetryMaxDuration time.Duration = time.Second * 5        // 5s\n\tDefaultGitRetryDuration    time.Duration = time.Millisecond * 250 // 0.25s\n\tDefaultGitRetryFactor                    = int64(2)\n)\n\n// GetGnuPGHomePath retrieves the path to use for GnuPG home directory, which is either taken from GNUPGHOME environment or a default value\nfunc GetGnuPGHomePath() string {\n\tif gnuPgHome := os.Getenv(EnvGnuPGHome); gnuPgHome == \"\" {\n\t\treturn DefaultGnuPgHomePath\n\t} else {\n\t\treturn gnuPgHome\n\t}\n}\n\n// GetPluginSockFilePath retrieves the path of plugin sock file, which is either taken from PluginSockFilePath environment or a default value\nfunc GetPluginSockFilePath() string {\n\tif pluginSockFilePath := os.Getenv(EnvPluginSockFilePath); pluginSockFilePath == \"\" {\n\t\treturn DefaultPluginSockFilePath\n\t} else {\n\t\treturn pluginSockFilePath\n\t}\n}\n\n// GetCMPChunkSize will return the env var EnvCMPChunkSize value if defined or DefaultCMPChunkSize otherwise.\n// If EnvCMPChunkSize is defined but not a valid int, DefaultCMPChunkSize will be returned\nfunc GetCMPChunkSize() int {\n\tif chunkSizeStr := os.Getenv(EnvCMPChunkSize); chunkSizeStr != \"\" {\n\t\tchunkSize, err := strconv.Atoi(chunkSizeStr)\n\t\tif err != nil {\n\t\t\tlogrus.Warnf(\"invalid env var value for %s: not a valid int: %s. Default value will be used.\", EnvCMPChunkSize, err)\n\t\t\treturn DefaultCMPChunkSize\n\t\t}\n\t\treturn chunkSize\n\t}\n\treturn DefaultCMPChunkSize\n}\n\n// GetCMPWorkDir will return the full path of the work directory used by the CMP server.\n// This directory and all it's contents will be deleted durring CMP bootstrap.\nfunc GetCMPWorkDir() string {\n\tif workDir := os.Getenv(EnvCMPWorkDir); workDir != \"\" {\n\t\treturn filepath.Join(workDir, DefaultCMPWorkDirName)\n\t}\n\treturn filepath.Join(os.TempDir(), DefaultCMPWorkDirName)\n}\n\nconst (\n\t// AnnotationApplicationRefresh is an annotation that is added when an ApplicationSet is requested to be refreshed by a webhook. The ApplicationSet controller will remove this annotation at the end of reconciliation.\n\tAnnotationApplicationSetRefresh = \"argocd.argoproj.io/application-set-refresh\"\n)\n\n// gRPC settings\nconst (\n\tGRPCKeepAliveEnforcementMinimum = 10 * time.Second\n\t// Keep alive is 2x enforcement minimum to ensure network jitter does not introduce ENHANCE_YOUR_CALM errors\n\tGRPCKeepAliveTime = 2 * GRPCKeepAliveEnforcementMinimum\n)\n\n// Security severity logging\nconst (\n\tSecurityField     = \"security\"\n\tSecurityCWEField  = \"CWE\"\n\tSecurityEmergency = 5 // Indicates unmistakably malicious events that should NEVER occur accidentally and indicates an active attack (i.e. brute forcing, DoS)\n\tSecurityCritical  = 4 // Indicates any malicious or exploitable event that had a side effect (i.e. secrets being left behind on the filesystem)\n\tSecurityHigh      = 3 // Indicates likely malicious events but one that had no side effects or was blocked (i.e. out of bounds symlinks in repos)\n\tSecurityMedium    = 2 // Could indicate malicious events, but has a high likelihood of being user/system error (i.e. access denied)\n\tSecurityLow       = 1 // Unexceptional entries (i.e. successful access logs)\n)\n\n// Common error messages\nconst TokenVerificationError = \"failed to verify the token\"\n\nvar TokenVerificationErr = errors.New(TokenVerificationError)\n", "package cluster\n\nimport (\n\t\"net/url\"\n\t\"time\"\n\n\t\"context\"\n\n\t\"github.com/argoproj/gitops-engine/pkg/utils/kube\"\n\tlog \"github.com/sirupsen/logrus\"\n\t\"google.golang.org/grpc/codes\"\n\t\"google.golang.org/grpc/status\"\n\tv1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/util/sets\"\n\t\"k8s.io/client-go/kubernetes\"\n\n\t\"github.com/argoproj/argo-cd/v2/pkg/apiclient/cluster\"\n\tappv1 \"github.com/argoproj/argo-cd/v2/pkg/apis/application/v1alpha1\"\n\tservercache \"github.com/argoproj/argo-cd/v2/server/cache\"\n\t\"github.com/argoproj/argo-cd/v2/server/rbacpolicy\"\n\t\"github.com/argoproj/argo-cd/v2/util/argo\"\n\t\"github.com/argoproj/argo-cd/v2/util/clusterauth\"\n\t\"github.com/argoproj/argo-cd/v2/util/db\"\n\t\"github.com/argoproj/argo-cd/v2/util/rbac\"\n)\n\n// Server provides a Cluster service\ntype Server struct {\n\tdb      db.ArgoDB\n\tenf     *rbac.Enforcer\n\tcache   *servercache.Cache\n\tkubectl kube.Kubectl\n}\n\n// NewServer returns a new instance of the Cluster service\nfunc NewServer(db db.ArgoDB, enf *rbac.Enforcer, cache *servercache.Cache, kubectl kube.Kubectl) *Server {\n\treturn &Server{\n\t\tdb:      db,\n\t\tenf:     enf,\n\t\tcache:   cache,\n\t\tkubectl: kubectl,\n\t}\n}\n\nfunc createRBACObject(project string, server string) string {\n\tif project != \"\" {\n\t\treturn project + \"/\" + server\n\t}\n\treturn server\n}\n\n// List returns list of clusters\nfunc (s *Server) List(ctx context.Context, q *cluster.ClusterQuery) (*appv1.ClusterList, error) {\n\tclusterList, err := s.db.ListClusters(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\titems := make([]appv1.Cluster, 0)\n\tfor _, clust := range clusterList.Items {\n\t\tif s.enf.Enforce(ctx.Value(\"claims\"), rbacpolicy.ResourceClusters, rbacpolicy.ActionGet, createRBACObject(clust.Project, clust.Server)) {\n\t\t\titems = append(items, clust)\n\t\t}\n\t}\n\terr = kube.RunAllAsync(len(items), func(i int) error {\n\t\titems[i] = *s.toAPIResponse(&items[i])\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tclusterList.Items = items\n\treturn clusterList, nil\n}\n\n// Create creates a cluster\nfunc (s *Server) Create(ctx context.Context, q *cluster.ClusterCreateRequest) (*appv1.Cluster, error) {\n\tif err := s.enf.EnforceErr(ctx.Value(\"claims\"), rbacpolicy.ResourceClusters, rbacpolicy.ActionCreate, createRBACObject(q.Cluster.Project, q.Cluster.Server)); err != nil {\n\t\treturn nil, err\n\t}\n\tc := q.Cluster\n\tserverVersion, err := s.kubectl.GetServerVersion(c.RESTConfig())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tclust, err := s.db.CreateCluster(ctx, c)\n\tif err != nil {\n\t\tif status.Convert(err).Code() == codes.AlreadyExists {\n\t\t\t// act idempotent if existing spec matches new spec\n\t\t\texisting, getErr := s.db.GetCluster(ctx, c.Server)\n\t\t\tif getErr != nil {\n\t\t\t\treturn nil, status.Errorf(codes.Internal, \"unable to check existing cluster details: %v\", getErr)\n\t\t\t}\n\n\t\t\tif existing.Equals(c) {\n\t\t\t\tclust = existing\n\t\t\t} else if q.Upsert {\n\t\t\t\treturn s.Update(ctx, &cluster.ClusterUpdateRequest{Cluster: c})\n\t\t\t} else {\n\t\t\t\treturn nil, status.Errorf(codes.InvalidArgument, argo.GenerateSpecIsDifferentErrorMessage(\"cluster\", existing, c))\n\t\t\t}\n\t\t} else {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\terr = s.cache.SetClusterInfo(c.Server, &appv1.ClusterInfo{\n\t\tServerVersion: serverVersion,\n\t\tConnectionState: appv1.ConnectionState{\n\t\t\tStatus:     appv1.ConnectionStatusSuccessful,\n\t\t\tModifiedAt: &v1.Time{Time: time.Now()},\n\t\t},\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn s.toAPIResponse(clust), err\n}\n\n// Get returns a cluster from a query\nfunc (s *Server) Get(ctx context.Context, q *cluster.ClusterQuery) (*appv1.Cluster, error) {\n\tc, err := s.getClusterWith403IfNotExist(ctx, q)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := s.enf.EnforceErr(ctx.Value(\"claims\"), rbacpolicy.ResourceClusters, rbacpolicy.ActionGet, createRBACObject(c.Project, q.Server)); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn s.toAPIResponse(c), nil\n}\n\nfunc (s *Server) getClusterWith403IfNotExist(ctx context.Context, q *cluster.ClusterQuery) (*appv1.Cluster, error) {\n\trepo, err := s.getCluster(ctx, q)\n\tif err != nil || repo == nil {\n\t\treturn nil, status.Error(codes.PermissionDenied, \"permission denied\")\n\t}\n\treturn repo, nil\n}\n\nfunc (s *Server) getCluster(ctx context.Context, q *cluster.ClusterQuery) (*appv1.Cluster, error) {\n\tif q.Id != nil {\n\t\tq.Server = \"\"\n\t\tq.Name = \"\"\n\t\tif q.Id.Type == \"name\" {\n\t\t\tq.Name = q.Id.Value\n\t\t} else if q.Id.Type == \"name_escaped\" {\n\t\t\tnameUnescaped, err := url.QueryUnescape(q.Id.Value)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tq.Name = nameUnescaped\n\t\t} else {\n\t\t\tq.Server = q.Id.Value\n\t\t}\n\t}\n\n\tif q.Server != \"\" {\n\t\tc, err := s.db.GetCluster(ctx, q.Server)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn c, nil\n\t}\n\n\t//we only get the name when we specify Name in ApplicationDestination and next\n\t//we want to find the server in order to populate ApplicationDestination.Server\n\tif q.Name != \"\" {\n\t\tclusterList, err := s.db.ListClusters(ctx)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tfor _, c := range clusterList.Items {\n\t\t\tif c.Name == q.Name {\n\t\t\t\treturn &c, nil\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil, nil\n}\n\nvar clusterFieldsByPath = map[string]func(updated *appv1.Cluster, existing *appv1.Cluster){\n\t\"name\": func(updated *appv1.Cluster, existing *appv1.Cluster) {\n\t\tupdated.Name = existing.Name\n\t},\n\t\"namespaces\": func(updated *appv1.Cluster, existing *appv1.Cluster) {\n\t\tupdated.Namespaces = existing.Namespaces\n\t},\n\t\"config\": func(updated *appv1.Cluster, existing *appv1.Cluster) {\n\t\tupdated.Config = existing.Config\n\t},\n\t\"shard\": func(updated *appv1.Cluster, existing *appv1.Cluster) {\n\t\tupdated.Shard = existing.Shard\n\t},\n\t\"clusterResources\": func(updated *appv1.Cluster, existing *appv1.Cluster) {\n\t\tupdated.ClusterResources = existing.ClusterResources\n\t},\n\t\"labels\": func(updated *appv1.Cluster, existing *appv1.Cluster) {\n\t\tupdated.Labels = existing.Labels\n\t},\n\t\"annotations\": func(updated *appv1.Cluster, existing *appv1.Cluster) {\n\t\tupdated.Annotations = existing.Annotations\n\t},\n\t\"project\": func(updated *appv1.Cluster, existing *appv1.Cluster) {\n\t\tupdated.Project = existing.Project\n\t},\n}\n\n// Update updates a cluster\nfunc (s *Server) Update(ctx context.Context, q *cluster.ClusterUpdateRequest) (*appv1.Cluster, error) {\n\tc, err := s.getClusterWith403IfNotExist(ctx, &cluster.ClusterQuery{\n\t\tServer: q.Cluster.Server,\n\t\tName:   q.Cluster.Name,\n\t\tId:     q.Id,\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// verify that user can do update inside project where cluster is located\n\tif err := s.enf.EnforceErr(ctx.Value(\"claims\"), rbacpolicy.ResourceClusters, rbacpolicy.ActionUpdate, createRBACObject(c.Project, q.Cluster.Server)); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif len(q.UpdatedFields) == 0 || sets.NewString(q.UpdatedFields...).Has(\"project\") {\n\t\t// verify that user can do update inside project where cluster will be located\n\t\tif err := s.enf.EnforceErr(ctx.Value(\"claims\"), rbacpolicy.ResourceClusters, rbacpolicy.ActionUpdate, createRBACObject(q.Cluster.Project, q.Cluster.Server)); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif len(q.UpdatedFields) != 0 {\n\t\tfor _, path := range q.UpdatedFields {\n\t\t\tif updater, ok := clusterFieldsByPath[path]; ok {\n\t\t\t\tupdater(c, q.Cluster)\n\t\t\t}\n\t\t}\n\t\tq.Cluster = c\n\t}\n\n\t// Test the token we just created before persisting it\n\tserverVersion, err := s.kubectl.GetServerVersion(q.Cluster.RESTConfig())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tclust, err := s.db.UpdateCluster(ctx, q.Cluster)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = s.cache.SetClusterInfo(clust.Server, &appv1.ClusterInfo{\n\t\tServerVersion: serverVersion,\n\t\tConnectionState: appv1.ConnectionState{\n\t\t\tStatus:     appv1.ConnectionStatusSuccessful,\n\t\t\tModifiedAt: &v1.Time{Time: time.Now()},\n\t\t},\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn s.toAPIResponse(clust), nil\n}\n\n// Delete deletes a cluster by server/name\nfunc (s *Server) Delete(ctx context.Context, q *cluster.ClusterQuery) (*cluster.ClusterResponse, error) {\n\tc, err := s.getClusterWith403IfNotExist(ctx, q)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif q.Name != \"\" {\n\t\tservers, err := s.db.GetClusterServersByName(ctx, q.Name)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tfor _, server := range servers {\n\t\t\tif err := enforceAndDelete(s, ctx, server, c.Project); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t} else {\n\t\tif err := enforceAndDelete(s, ctx, q.Server, c.Project); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn &cluster.ClusterResponse{}, nil\n}\n\nfunc enforceAndDelete(s *Server, ctx context.Context, server, project string) error {\n\tif err := s.enf.EnforceErr(ctx.Value(\"claims\"), rbacpolicy.ResourceClusters, rbacpolicy.ActionDelete, createRBACObject(project, server)); err != nil {\n\t\treturn err\n\t}\n\tif err := s.db.DeleteCluster(ctx, server); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n\n// RotateAuth rotates the bearer token used for a cluster\nfunc (s *Server) RotateAuth(ctx context.Context, q *cluster.ClusterQuery) (*cluster.ClusterResponse, error) {\n\tclust, err := s.getClusterWith403IfNotExist(ctx, q)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar servers []string\n\tif q.Name != \"\" {\n\t\tservers, err = s.db.GetClusterServersByName(ctx, q.Name)\n\t\tif err != nil {\n\t\t\treturn nil, status.Errorf(codes.NotFound, \"failed to get cluster servers by name: %v\", err)\n\t\t}\n\t\tfor _, server := range servers {\n\t\t\tif err := s.enf.EnforceErr(ctx.Value(\"claims\"), rbacpolicy.ResourceClusters, rbacpolicy.ActionUpdate, createRBACObject(clust.Project, server)); err != nil {\n\t\t\t\treturn nil, status.Errorf(codes.PermissionDenied, \"encountered permissions issue while processing request: %v\", err)\n\t\t\t}\n\t\t}\n\t} else {\n\t\tif err := s.enf.EnforceErr(ctx.Value(\"claims\"), rbacpolicy.ResourceClusters, rbacpolicy.ActionUpdate, createRBACObject(clust.Project, q.Server)); err != nil {\n\t\t\treturn nil, status.Errorf(codes.PermissionDenied, \"encountered permissions issue while processing request: %v\", err)\n\t\t}\n\t\tservers = append(servers, q.Server)\n\t}\n\n\tfor _, server := range servers {\n\t\tlogCtx := log.WithField(\"cluster\", server)\n\t\tlogCtx.Info(\"Rotating auth\")\n\t\trestCfg := clust.RESTConfig()\n\t\tif restCfg.BearerToken == \"\" {\n\t\t\treturn nil, status.Errorf(codes.InvalidArgument, \"Cluster '%s' does not use bearer token authentication\", server)\n\t\t}\n\n\t\tclaims, err := clusterauth.ParseServiceAccountToken(restCfg.BearerToken)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tkubeclientset, err := kubernetes.NewForConfig(restCfg)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tnewSecret, err := clusterauth.GenerateNewClusterManagerSecret(kubeclientset, claims)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\t// we are using token auth, make sure we don't store client-cert information\n\t\tclust.Config.KeyData = nil\n\t\tclust.Config.CertData = nil\n\t\tclust.Config.BearerToken = string(newSecret.Data[\"token\"])\n\n\t\t// Test the token we just created before persisting it\n\t\tserverVersion, err := s.kubectl.GetServerVersion(clust.RESTConfig())\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\t_, err = s.db.UpdateCluster(ctx, clust)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\terr = s.cache.SetClusterInfo(clust.Server, &appv1.ClusterInfo{\n\t\t\tServerVersion: serverVersion,\n\t\t\tConnectionState: appv1.ConnectionState{\n\t\t\t\tStatus:     appv1.ConnectionStatusSuccessful,\n\t\t\t\tModifiedAt: &v1.Time{Time: time.Now()},\n\t\t\t},\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\terr = clusterauth.RotateServiceAccountSecrets(kubeclientset, claims, newSecret)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tlogCtx.Infof(\"Rotated auth (old: %s, new: %s)\", claims.SecretName, newSecret.Name)\n\t}\n\treturn &cluster.ClusterResponse{}, nil\n}\n\nfunc (s *Server) toAPIResponse(clust *appv1.Cluster) *appv1.Cluster {\n\t_ = s.cache.GetClusterInfo(clust.Server, &clust.Info)\n\n\tclust.Config.Password = \"\"\n\tclust.Config.BearerToken = \"\"\n\tclust.Config.TLSClientConfig.KeyData = nil\n\tif clust.Config.ExecProviderConfig != nil {\n\t\t// We can't know what the user has put into args or\n\t\t// env vars on the exec provider that might be sensitive\n\t\t// (e.g. --private-key=XXX, PASSWORD=XXX)\n\t\t// Implicitly assumes the command executable name is non-sensitive\n\t\tclust.Config.ExecProviderConfig.Env = make(map[string]string)\n\t\tclust.Config.ExecProviderConfig.Args = nil\n\t}\n\t// populate deprecated fields for backward compatibility\n\tclust.ServerVersion = clust.Info.ServerVersion\n\tclust.ConnectionState = clust.Info.ConnectionState\n\treturn clust\n}\n\n// InvalidateCache invalidates cluster cache\nfunc (s *Server) InvalidateCache(ctx context.Context, q *cluster.ClusterQuery) (*appv1.Cluster, error) {\n\tcls, err := s.getClusterWith403IfNotExist(ctx, q)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif err := s.enf.EnforceErr(ctx.Value(\"claims\"), rbacpolicy.ResourceClusters, rbacpolicy.ActionUpdate, createRBACObject(cls.Project, q.Server)); err != nil {\n\t\treturn nil, err\n\t}\n\tnow := v1.Now()\n\tcls.RefreshRequestedAt = &now\n\tcls, err = s.db.UpdateCluster(ctx, cls)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn s.toAPIResponse(cls), nil\n}\n", "package cluster\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"testing\"\n\t\"time\"\n\n\tcorev1 \"k8s.io/api/core/v1\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\tv1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/runtime\"\n\n\t\"github.com/argoproj/gitops-engine/pkg/utils/kube/kubetest\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/mock\"\n\t\"github.com/stretchr/testify/require\"\n\t\"k8s.io/client-go/kubernetes/fake\"\n\t\"k8s.io/utils/pointer\"\n\n\t\"github.com/argoproj/argo-cd/v2/common\"\n\tclusterapi \"github.com/argoproj/argo-cd/v2/pkg/apiclient/cluster\"\n\t\"github.com/argoproj/argo-cd/v2/pkg/apis/application/v1alpha1\"\n\tservercache \"github.com/argoproj/argo-cd/v2/server/cache\"\n\t\"github.com/argoproj/argo-cd/v2/test\"\n\tcacheutil \"github.com/argoproj/argo-cd/v2/util/cache\"\n\tappstatecache \"github.com/argoproj/argo-cd/v2/util/cache/appstate\"\n\t\"github.com/argoproj/argo-cd/v2/util/db\"\n\tdbmocks \"github.com/argoproj/argo-cd/v2/util/db/mocks\"\n\t\"github.com/argoproj/argo-cd/v2/util/rbac\"\n\t\"github.com/argoproj/argo-cd/v2/util/settings\"\n)\n\nfunc newServerInMemoryCache() *servercache.Cache {\n\treturn servercache.NewCache(\n\t\tappstatecache.NewCache(\n\t\t\tcacheutil.NewCache(cacheutil.NewInMemoryCache(1*time.Hour)),\n\t\t\t1*time.Minute,\n\t\t),\n\t\t1*time.Minute,\n\t\t1*time.Minute,\n\t\t1*time.Minute,\n\t)\n}\n\nfunc newNoopEnforcer() *rbac.Enforcer {\n\tenf := rbac.NewEnforcer(fake.NewSimpleClientset(test.NewFakeConfigMap()), test.FakeArgoCDNamespace, common.ArgoCDConfigMapName, nil)\n\tenf.EnableEnforce(false)\n\treturn enf\n}\n\nfunc TestGetCluster_UrlEncodedName(t *testing.T) {\n\tdb := &dbmocks.ArgoDB{}\n\n\tmockCluster := v1alpha1.Cluster{\n\t\tName:       \"test/ing\",\n\t\tServer:     \"https://127.0.0.1\",\n\t\tNamespaces: []string{\"default\", \"kube-system\"},\n\t}\n\tmockClusterList := v1alpha1.ClusterList{\n\t\tListMeta: v1.ListMeta{},\n\t\tItems: []v1alpha1.Cluster{\n\t\t\tmockCluster,\n\t\t},\n\t}\n\n\tdb.On(\"ListClusters\", mock.Anything).Return(&mockClusterList, nil)\n\n\tserver := NewServer(db, newNoopEnforcer(), newServerInMemoryCache(), &kubetest.MockKubectlCmd{})\n\n\tcluster, err := server.Get(context.Background(), &clusterapi.ClusterQuery{\n\t\tId: &clusterapi.ClusterID{\n\t\t\tType:  \"name_escaped\",\n\t\t\tValue: \"test%2fing\",\n\t\t},\n\t})\n\trequire.NoError(t, err)\n\n\tassert.Equal(t, cluster.Name, \"test/ing\")\n}\n\nfunc TestGetCluster_NameWithUrlEncodingButShouldNotBeUnescaped(t *testing.T) {\n\tdb := &dbmocks.ArgoDB{}\n\n\tmockCluster := v1alpha1.Cluster{\n\t\tName:       \"test%2fing\",\n\t\tServer:     \"https://127.0.0.1\",\n\t\tNamespaces: []string{\"default\", \"kube-system\"},\n\t}\n\tmockClusterList := v1alpha1.ClusterList{\n\t\tListMeta: v1.ListMeta{},\n\t\tItems: []v1alpha1.Cluster{\n\t\t\tmockCluster,\n\t\t},\n\t}\n\n\tdb.On(\"ListClusters\", mock.Anything).Return(&mockClusterList, nil)\n\n\tserver := NewServer(db, newNoopEnforcer(), newServerInMemoryCache(), &kubetest.MockKubectlCmd{})\n\n\tcluster, err := server.Get(context.Background(), &clusterapi.ClusterQuery{\n\t\tId: &clusterapi.ClusterID{\n\t\t\tType:  \"name\",\n\t\t\tValue: \"test%2fing\",\n\t\t},\n\t})\n\trequire.NoError(t, err)\n\n\tassert.Equal(t, cluster.Name, \"test%2fing\")\n}\n\nfunc TestUpdateCluster_NoFieldsPaths(t *testing.T) {\n\tdb := &dbmocks.ArgoDB{}\n\tvar updated *v1alpha1.Cluster\n\n\tclusters := []v1alpha1.Cluster{\n\t\t{\n\t\t\tName:       \"minikube\",\n\t\t\tServer:     \"https://127.0.0.1\",\n\t\t\tNamespaces: []string{\"default\", \"kube-system\"},\n\t\t},\n\t}\n\n\tclusterList := v1alpha1.ClusterList{\n\t\tListMeta: v1.ListMeta{},\n\t\tItems:    clusters,\n\t}\n\n\tdb.On(\"ListClusters\", mock.Anything).Return(&clusterList, nil)\n\tdb.On(\"UpdateCluster\", mock.Anything, mock.MatchedBy(func(c *v1alpha1.Cluster) bool {\n\t\tupdated = c\n\t\treturn true\n\t})).Return(&v1alpha1.Cluster{}, nil)\n\n\tserver := NewServer(db, newNoopEnforcer(), newServerInMemoryCache(), &kubetest.MockKubectlCmd{})\n\n\t_, err := server.Update(context.Background(), &clusterapi.ClusterUpdateRequest{\n\t\tCluster: &v1alpha1.Cluster{\n\t\t\tName:       \"minikube\",\n\t\t\tNamespaces: []string{\"default\", \"kube-system\"},\n\t\t},\n\t})\n\n\trequire.NoError(t, err)\n\n\tassert.Equal(t, updated.Name, \"minikube\")\n\tassert.Equal(t, updated.Namespaces, []string{\"default\", \"kube-system\"})\n}\n\nfunc TestUpdateCluster_FieldsPathSet(t *testing.T) {\n\tdb := &dbmocks.ArgoDB{}\n\tvar updated *v1alpha1.Cluster\n\tdb.On(\"GetCluster\", mock.Anything, \"https://127.0.0.1\").Return(&v1alpha1.Cluster{\n\t\tName:       \"minikube\",\n\t\tServer:     \"https://127.0.0.1\",\n\t\tNamespaces: []string{\"default\", \"kube-system\"},\n\t}, nil)\n\tdb.On(\"UpdateCluster\", mock.Anything, mock.MatchedBy(func(c *v1alpha1.Cluster) bool {\n\t\tupdated = c\n\t\treturn true\n\t})).Return(&v1alpha1.Cluster{}, nil)\n\n\tserver := NewServer(db, newNoopEnforcer(), newServerInMemoryCache(), &kubetest.MockKubectlCmd{})\n\n\t_, err := server.Update(context.Background(), &clusterapi.ClusterUpdateRequest{\n\t\tCluster: &v1alpha1.Cluster{\n\t\t\tServer: \"https://127.0.0.1\",\n\t\t\tShard:  pointer.Int64Ptr(1),\n\t\t},\n\t\tUpdatedFields: []string{\"shard\"},\n\t})\n\n\trequire.NoError(t, err)\n\n\tassert.Equal(t, updated.Name, \"minikube\")\n\tassert.Equal(t, updated.Namespaces, []string{\"default\", \"kube-system\"})\n\tassert.Equal(t, *updated.Shard, int64(1))\n\n\tlabelEnv := map[string]string{\n\t\t\"env\": \"qa\",\n\t}\n\t_, err = server.Update(context.Background(), &clusterapi.ClusterUpdateRequest{\n\t\tCluster: &v1alpha1.Cluster{\n\t\t\tServer: \"https://127.0.0.1\",\n\t\t\tLabels: labelEnv,\n\t\t},\n\t\tUpdatedFields: []string{\"labels\"},\n\t})\n\n\trequire.NoError(t, err)\n\n\tassert.Equal(t, updated.Name, \"minikube\")\n\tassert.Equal(t, updated.Namespaces, []string{\"default\", \"kube-system\"})\n\tassert.Equal(t, updated.Labels, labelEnv)\n\n\tannotationEnv := map[string]string{\n\t\t\"env\": \"qa\",\n\t}\n\t_, err = server.Update(context.Background(), &clusterapi.ClusterUpdateRequest{\n\t\tCluster: &v1alpha1.Cluster{\n\t\t\tServer:      \"https://127.0.0.1\",\n\t\t\tAnnotations: annotationEnv,\n\t\t},\n\t\tUpdatedFields: []string{\"annotations\"},\n\t})\n\n\trequire.NoError(t, err)\n\n\tassert.Equal(t, updated.Name, \"minikube\")\n\tassert.Equal(t, updated.Namespaces, []string{\"default\", \"kube-system\"})\n\tassert.Equal(t, updated.Annotations, annotationEnv)\n\n\t_, err = server.Update(context.Background(), &clusterapi.ClusterUpdateRequest{\n\t\tCluster: &v1alpha1.Cluster{\n\t\t\tServer:  \"https://127.0.0.1\",\n\t\t\tProject: \"new-project\",\n\t\t},\n\t\tUpdatedFields: []string{\"project\"},\n\t})\n\n\trequire.NoError(t, err)\n\n\tassert.Equal(t, updated.Name, \"minikube\")\n\tassert.Equal(t, updated.Namespaces, []string{\"default\", \"kube-system\"})\n\tassert.Equal(t, updated.Project, \"new-project\")\n}\n\nfunc TestDeleteClusterByName(t *testing.T) {\n\ttestNamespace := \"default\"\n\tclientset := getClientset(nil, testNamespace, &corev1.Secret{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"my-cluster-secret\",\n\t\t\tNamespace: testNamespace,\n\t\t\tLabels: map[string]string{\n\t\t\t\tcommon.LabelKeySecretType: common.LabelValueSecretTypeCluster,\n\t\t\t},\n\t\t\tAnnotations: map[string]string{\n\t\t\t\tcommon.AnnotationKeyManagedBy: common.AnnotationValueManagedByArgoCD,\n\t\t\t},\n\t\t},\n\t\tData: map[string][]byte{\n\t\t\t\"name\":   []byte(\"my-cluster-name\"),\n\t\t\t\"server\": []byte(\"https://my-cluster-server\"),\n\t\t\t\"config\": []byte(\"{}\"),\n\t\t},\n\t})\n\tdb := db.NewDB(testNamespace, settings.NewSettingsManager(context.Background(), clientset, testNamespace), clientset)\n\tserver := NewServer(db, newNoopEnforcer(), newServerInMemoryCache(), &kubetest.MockKubectlCmd{})\n\n\tt.Run(\"Delete Fails When Deleting by Unknown Name\", func(t *testing.T) {\n\t\t_, err := server.Delete(context.Background(), &clusterapi.ClusterQuery{\n\t\t\tName: \"foo\",\n\t\t})\n\n\t\tassert.EqualError(t, err, `rpc error: code = PermissionDenied desc = permission denied`)\n\t})\n\n\tt.Run(\"Delete Succeeds When Deleting by Name\", func(t *testing.T) {\n\t\t_, err := server.Delete(context.Background(), &clusterapi.ClusterQuery{\n\t\t\tName: \"my-cluster-name\",\n\t\t})\n\t\tassert.Nil(t, err)\n\n\t\t_, err = db.GetCluster(context.Background(), \"https://my-cluster-server\")\n\t\tassert.EqualError(t, err, `rpc error: code = NotFound desc = cluster \"https://my-cluster-server\" not found`)\n\t})\n}\n\nfunc TestRotateAuth(t *testing.T) {\n\ttestNamespace := \"kube-system\"\n\ttoken := \"eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhcmdvY2QtbWFuYWdlci10b2tlbi10ajc5ciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJhcmdvY2QtbWFuYWdlciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjkxZGQzN2NmLThkOTItMTFlOS1hMDkxLWQ2NWYyYWU3ZmE4ZCIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTphcmdvY2QtbWFuYWdlciJ9.ytZjt2pDV8-A7DBMR06zQ3wt9cuVEfq262TQw7sdra-KRpDpMPnziMhc8bkwvgW-LGhTWUh5iu1y-1QhEx6mtbCt7vQArlBRxfvM5ys6ClFkplzq5c2TtZ7EzGSD0Up7tdxuG9dvR6TGXYdfFcG779yCdZo2H48sz5OSJfdEriduMEY1iL5suZd3ebOoVi1fGflmqFEkZX6SvxkoArl5mtNP6TvZ1eTcn64xh4ws152hxio42E-eSnl_CET4tpB5vgP5BVlSKW2xB7w2GJxqdETA5LJRI_OilY77dTOp8cMr_Ck3EOeda3zHfh4Okflg8rZFEeAuJYahQNeAILLkcA\"\n\tconfig := v1alpha1.ClusterConfig{\n\t\tBearerToken: token,\n\t}\n\n\tconfigMarshal, err := json.Marshal(config)\n\tif err != nil {\n\t\tt.Errorf(\"failed to marshal config for test: %v\", err)\n\t}\n\n\tclientset := getClientset(nil, testNamespace,\n\t\t&corev1.Secret{\n\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\tName:      \"my-cluster-secret\",\n\t\t\t\tNamespace: testNamespace,\n\t\t\t\tLabels: map[string]string{\n\t\t\t\t\tcommon.LabelKeySecretType: common.LabelValueSecretTypeCluster,\n\t\t\t\t},\n\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\tcommon.AnnotationKeyManagedBy: common.AnnotationValueManagedByArgoCD,\n\t\t\t\t},\n\t\t\t},\n\t\t\tData: map[string][]byte{\n\t\t\t\t\"name\":   []byte(\"my-cluster-name\"),\n\t\t\t\t\"server\": []byte(\"https://my-cluster-name\"),\n\t\t\t\t\"config\": configMarshal,\n\t\t\t},\n\t\t},\n\t\t&corev1.Namespace{\n\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\tName: \"kube-system\",\n\t\t\t},\n\t\t},\n\t\t&corev1.Secret{\n\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\tName:      \"argocd-manager-token-tj79r\",\n\t\t\t\tNamespace: \"kube-system\",\n\t\t\t},\n\t\t\tData: map[string][]byte{\n\t\t\t\t\"token\": []byte(token),\n\t\t\t},\n\t\t},\n\t\t&corev1.ServiceAccount{\n\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\tName:      \"argocd-manager\",\n\t\t\t\tNamespace: \"kube-system\",\n\t\t\t},\n\t\t\tSecrets: []corev1.ObjectReference{\n\t\t\t\t{\n\t\t\t\t\tKind: \"Secret\",\n\t\t\t\t\tName: \"argocd-manager-token-tj79r\",\n\t\t\t\t},\n\t\t\t},\n\t\t})\n\n\tdb := db.NewDB(testNamespace, settings.NewSettingsManager(context.Background(), clientset, testNamespace), clientset)\n\tserver := NewServer(db, newNoopEnforcer(), newServerInMemoryCache(), &kubetest.MockKubectlCmd{})\n\n\tt.Run(\"RotateAuth by Unknown Name\", func(t *testing.T) {\n\t\t_, err := server.RotateAuth(context.Background(), &clusterapi.ClusterQuery{\n\t\t\tName: \"foo\",\n\t\t})\n\n\t\tassert.EqualError(t, err, `rpc error: code = PermissionDenied desc = permission denied`)\n\t})\n\n\t// While the tests results for the next two tests result in an error, they do\n\t// demonstrate the proper mapping of cluster names/server to server info (i.e. my-cluster-name\n\t// results in https://my-cluster-name info being used and https://my-cluster-name results in https://my-cluster-name).\n\tt.Run(\"RotateAuth by Name - Error from no such host\", func(t *testing.T) {\n\t\t_, err := server.RotateAuth(context.Background(), &clusterapi.ClusterQuery{\n\t\t\tName: \"my-cluster-name\",\n\t\t})\n\n\t\trequire.NotNil(t, err)\n\t\tassert.Contains(t, err.Error(), \"Get \\\"https://my-cluster-name/\")\n\t})\n\n\tt.Run(\"RotateAuth by Server - Error from no such host\", func(t *testing.T) {\n\t\t_, err := server.RotateAuth(context.Background(), &clusterapi.ClusterQuery{\n\t\t\tServer: \"https://my-cluster-name\",\n\t\t})\n\n\t\trequire.NotNil(t, err)\n\t\tassert.Contains(t, err.Error(), \"Get \\\"https://my-cluster-name/\")\n\t})\n}\n\nfunc getClientset(config map[string]string, ns string, objects ...runtime.Object) *fake.Clientset {\n\tsecret := corev1.Secret{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"argocd-secret\",\n\t\t\tNamespace: ns,\n\t\t},\n\t\tData: map[string][]byte{\n\t\t\t\"admin.password\":   []byte(\"test\"),\n\t\t\t\"server.secretkey\": []byte(\"test\"),\n\t\t},\n\t}\n\tcm := corev1.ConfigMap{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"argocd-cm\",\n\t\t\tNamespace: ns,\n\t\t\tLabels: map[string]string{\n\t\t\t\t\"app.kubernetes.io/part-of\": \"argocd\",\n\t\t\t},\n\t\t},\n\t\tData: config,\n\t}\n\treturn fake.NewSimpleClientset(append(objects, &cm, &secret)...)\n}\n"], "fixing_code": ["package common\n\nimport (\n\t\"errors\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strconv\"\n\t\"time\"\n\n\t\"github.com/sirupsen/logrus\"\n\t\"google.golang.org/grpc/codes\"\n\t\"google.golang.org/grpc/status\"\n)\n\n// Default service addresses and URLS of Argo CD internal services\nconst (\n\t// DefaultRepoServerAddr is the gRPC address of the Argo CD repo server\n\tDefaultRepoServerAddr = \"argocd-repo-server:8081\"\n\t// DefaultDexServerAddr is the HTTP address of the Dex OIDC server, which we run a reverse proxy against\n\tDefaultDexServerAddr = \"argocd-dex-server:5556\"\n\t// DefaultRedisAddr is the default redis address\n\tDefaultRedisAddr = \"argocd-redis:6379\"\n)\n\n// Kubernetes ConfigMap and Secret resource names which hold Argo CD settings\nconst (\n\tArgoCDConfigMapName              = \"argocd-cm\"\n\tArgoCDSecretName                 = \"argocd-secret\"\n\tArgoCDNotificationsConfigMapName = \"argocd-notifications-cm\"\n\tArgoCDNotificationsSecretName    = \"argocd-notifications-secret\"\n\tArgoCDRBACConfigMapName          = \"argocd-rbac-cm\"\n\t// Contains SSH known hosts data for connecting repositories. Will get mounted as volume to pods\n\tArgoCDKnownHostsConfigMapName = \"argocd-ssh-known-hosts-cm\"\n\t// Contains TLS certificate data for connecting repositories. Will get mounted as volume to pods\n\tArgoCDTLSCertsConfigMapName = \"argocd-tls-certs-cm\"\n\tArgoCDGPGKeysConfigMapName  = \"argocd-gpg-keys-cm\"\n)\n\n// Some default configurables\nconst (\n\tDefaultSystemNamespace = \"kube-system\"\n\tDefaultRepoType        = \"git\"\n)\n\n// Default listener ports for ArgoCD components\nconst (\n\tDefaultPortAPIServer              = 8080\n\tDefaultPortRepoServer             = 8081\n\tDefaultPortArgoCDMetrics          = 8082\n\tDefaultPortArgoCDAPIServerMetrics = 8083\n\tDefaultPortRepoServerMetrics      = 8084\n)\n\n// Default listener address for ArgoCD components\nconst (\n\tDefaultAddressAPIServer = \"localhost\"\n)\n\n// Default paths on the pod's file system\nconst (\n\t// The default path where TLS certificates for repositories are located\n\tDefaultPathTLSConfig = \"/app/config/tls\"\n\t// The default path where SSH known hosts are stored\n\tDefaultPathSSHConfig = \"/app/config/ssh\"\n\t// Default name for the SSH known hosts file\n\tDefaultSSHKnownHostsName = \"ssh_known_hosts\"\n\t// Default path to GnuPG home directory\n\tDefaultGnuPgHomePath = \"/app/config/gpg/keys\"\n\t// Default path to repo server TLS endpoint config\n\tDefaultAppConfigPath = \"/app/config\"\n\t// Default path to cmp server plugin socket file\n\tDefaultPluginSockFilePath = \"/home/argocd/cmp-server/plugins\"\n\t// Default path to cmp server plugin configuration file\n\tDefaultPluginConfigFilePath = \"/home/argocd/cmp-server/config\"\n\t// Plugin Config File is a ConfigManagementPlugin manifest located inside the plugin container\n\tPluginConfigFileName = \"plugin.yaml\"\n)\n\n// Argo CD application related constants\nconst (\n\n\t// ArgoCDAdminUsername is the username of the 'admin' user\n\tArgoCDAdminUsername = \"admin\"\n\t// ArgoCDUserAgentName is the default user-agent name used by the gRPC API client library and grpc-gateway\n\tArgoCDUserAgentName = \"argocd-client\"\n\t// ArgoCDSSAManager is the default argocd manager name used by server-side apply syncs\n\tArgoCDSSAManager = \"argocd-controller\"\n\t// AuthCookieName is the HTTP cookie name where we store our auth token\n\tAuthCookieName = \"argocd.token\"\n\t// StateCookieName is the HTTP cookie name that holds temporary nonce tokens for CSRF protection\n\tStateCookieName = \"argocd.oauthstate\"\n\t// StateCookieMaxAge is the maximum age of the oauth state cookie\n\tStateCookieMaxAge = time.Minute * 5\n\n\t// ChangePasswordSSOTokenMaxAge is the max token age for password change operation\n\tChangePasswordSSOTokenMaxAge = time.Minute * 5\n\t// GithubAppCredsExpirationDuration is the default time used to cache the GitHub app credentials\n\tGithubAppCredsExpirationDuration = time.Minute * 60\n\n\t// PasswordPatten is the default password patten\n\tPasswordPatten = `^.{8,32}$`\n)\n\n// Dex related constants\nconst (\n\t// DexAPIEndpoint is the endpoint where we serve the Dex API server\n\tDexAPIEndpoint = \"/api/dex\"\n\t// LoginEndpoint is Argo CD's shorthand login endpoint which redirects to dex's OAuth 2.0 provider's consent page\n\tLoginEndpoint = \"/auth/login\"\n\t// LogoutEndpoint is Argo CD's shorthand logout endpoint which invalidates OIDC session after logout\n\tLogoutEndpoint = \"/auth/logout\"\n\t// CallbackEndpoint is Argo CD's final callback endpoint we reach after OAuth 2.0 login flow has been completed\n\tCallbackEndpoint = \"/auth/callback\"\n\t// DexCallbackEndpoint is Argo CD's final callback endpoint when Dex is configured\n\tDexCallbackEndpoint = \"/api/dex/callback\"\n\t// ArgoCDClientAppName is name of the Oauth client app used when registering our web app to dex\n\tArgoCDClientAppName = \"Argo CD\"\n\t// ArgoCDClientAppID is the Oauth client ID we will use when registering our app to dex\n\tArgoCDClientAppID = \"argo-cd\"\n\t// ArgoCDCLIClientAppName is name of the Oauth client app used when registering our CLI to dex\n\tArgoCDCLIClientAppName = \"Argo CD CLI\"\n\t// ArgoCDCLIClientAppID is the Oauth client ID we will use when registering our CLI to dex\n\tArgoCDCLIClientAppID = \"argo-cd-cli\"\n)\n\n// Resource metadata labels and annotations (keys and values) used by Argo CD components\nconst (\n\t// LabelKeyAppInstance is the label key to use to uniquely identify the instance of an application\n\t// The Argo CD application name is used as the instance name\n\tLabelKeyAppInstance = \"app.kubernetes.io/instance\"\n\t// LabelKeyLegacyApplicationName is the legacy label (v0.10 and below) and is superseded by 'app.kubernetes.io/instance'\n\tLabelKeyLegacyApplicationName = \"applications.argoproj.io/app-name\"\n\t// LabelKeySecretType contains the type of argocd secret (currently: 'cluster', 'repository', 'repo-config' or 'repo-creds')\n\tLabelKeySecretType = \"argocd.argoproj.io/secret-type\"\n\t// LabelValueSecretTypeCluster indicates a secret type of cluster\n\tLabelValueSecretTypeCluster = \"cluster\"\n\t// LabelValueSecretTypeRepository indicates a secret type of repository\n\tLabelValueSecretTypeRepository = \"repository\"\n\t// LabelValueSecretTypeRepoCreds indicates a secret type of repository credentials\n\tLabelValueSecretTypeRepoCreds = \"repo-creds\"\n\n\t// The Argo CD application name is used as the instance name\n\tAnnotationKeyAppInstance = \"argocd.argoproj.io/tracking-id\"\n\n\t// AnnotationCompareOptions is a comma-separated list of options for comparison\n\tAnnotationCompareOptions = \"argocd.argoproj.io/compare-options\"\n\n\t// AnnotationKeyManagedBy is annotation name which indicates that k8s resource is managed by an application.\n\tAnnotationKeyManagedBy = \"managed-by\"\n\t// AnnotationValueManagedByArgoCD is a 'managed-by' annotation value for resources managed by Argo CD\n\tAnnotationValueManagedByArgoCD = \"argocd.argoproj.io\"\n\n\t// AnnotationKeyLinkPrefix tells the UI to add an external link icon to the application node\n\t// that links to the value given in the annotation.\n\t// The annotation key must be followed by a unique identifier. Ex: link.argocd.argoproj.io/dashboard\n\t// It's valid to have multiple annotations that match the prefix.\n\t// Values can simply be a url or they can have\n\t// an optional link title separated by a \"|\"\n\t// Ex: \"http://grafana.example.com/d/yu5UH4MMz/deployments\"\n\t// Ex: \"Go to Dashboard|http://grafana.example.com/d/yu5UH4MMz/deployments\"\n\tAnnotationKeyLinkPrefix = \"link.argocd.argoproj.io/\"\n)\n\n// Environment variables for tuning and debugging Argo CD\nconst (\n\t// EnvVarSSODebug is an environment variable to enable additional OAuth debugging in the API server\n\tEnvVarSSODebug = \"ARGOCD_SSO_DEBUG\"\n\t// EnvVarRBACDebug is an environment variable to enable additional RBAC debugging in the API server\n\tEnvVarRBACDebug = \"ARGOCD_RBAC_DEBUG\"\n\t// Overrides the location where SSH known hosts for repo access data is stored\n\tEnvVarSSHDataPath = \"ARGOCD_SSH_DATA_PATH\"\n\t// Overrides the location where TLS certificate for repo access data is stored\n\tEnvVarTLSDataPath = \"ARGOCD_TLS_DATA_PATH\"\n\t// Specifies number of git remote operations attempts count\n\tEnvGitAttemptsCount = \"ARGOCD_GIT_ATTEMPTS_COUNT\"\n\t// Specifices max duration of git remote operation retry\n\tEnvGitRetryMaxDuration = \"ARGOCD_GIT_RETRY_MAX_DURATION\"\n\t// Specifies duration of git remote operation retry\n\tEnvGitRetryDuration = \"ARGOCD_GIT_RETRY_DURATION\"\n\t// Specifies fator of git remote operation retry\n\tEnvGitRetryFactor = \"ARGOCD_GIT_RETRY_FACTOR\"\n\t// Overrides git submodule support, true by default\n\tEnvGitSubmoduleEnabled = \"ARGOCD_GIT_MODULES_ENABLED\"\n\t// EnvGnuPGHome is the path to ArgoCD's GnuPG keyring for signature verification\n\tEnvGnuPGHome = \"ARGOCD_GNUPGHOME\"\n\t// EnvWatchAPIBufferSize is the buffer size used to transfer K8S watch events to watch API consumer\n\tEnvWatchAPIBufferSize = \"ARGOCD_WATCH_API_BUFFER_SIZE\"\n\t// EnvPauseGenerationAfterFailedAttempts will pause manifest generation after the specified number of failed generation attempts\n\tEnvPauseGenerationAfterFailedAttempts = \"ARGOCD_PAUSE_GEN_AFTER_FAILED_ATTEMPTS\"\n\t// EnvPauseGenerationMinutes pauses manifest generation for the specified number of minutes, after sufficient manifest generation failures\n\tEnvPauseGenerationMinutes = \"ARGOCD_PAUSE_GEN_MINUTES\"\n\t// EnvPauseGenerationRequests pauses manifest generation for the specified number of requests, after sufficient manifest generation failures\n\tEnvPauseGenerationRequests = \"ARGOCD_PAUSE_GEN_REQUESTS\"\n\t// EnvControllerReplicas is the number of controller replicas\n\tEnvControllerReplicas = \"ARGOCD_CONTROLLER_REPLICAS\"\n\t// EnvControllerShard is the shard number that should be handled by controller\n\tEnvControllerShard = \"ARGOCD_CONTROLLER_SHARD\"\n\t// EnvEnableGRPCTimeHistogramEnv enables gRPC metrics collection\n\tEnvEnableGRPCTimeHistogramEnv = \"ARGOCD_ENABLE_GRPC_TIME_HISTOGRAM\"\n\t// EnvGithubAppCredsExpirationDuration controls the caching of Github app credentials. This value is in minutes (default: 60)\n\tEnvGithubAppCredsExpirationDuration = \"ARGOCD_GITHUB_APP_CREDS_EXPIRATION_DURATION\"\n\t// EnvHelmIndexCacheDuration controls how the helm repository index file is cached for (default: 0)\n\tEnvHelmIndexCacheDuration = \"ARGOCD_HELM_INDEX_CACHE_DURATION\"\n\t// EnvRepoServerConfigPath allows to override the configuration path for repo server\n\tEnvAppConfigPath = \"ARGOCD_APP_CONF_PATH\"\n\t// EnvLogFormat log format that is defined by `--logformat` option\n\tEnvLogFormat = \"ARGOCD_LOG_FORMAT\"\n\t// EnvLogLevel log level that is defined by `--loglevel` option\n\tEnvLogLevel = \"ARGOCD_LOG_LEVEL\"\n\t// EnvMaxCookieNumber max number of chunks a cookie can be broken into\n\tEnvMaxCookieNumber = \"ARGOCD_MAX_COOKIE_NUMBER\"\n\t// EnvPluginSockFilePath allows to override the pluginSockFilePath for repo server and cmp server\n\tEnvPluginSockFilePath = \"ARGOCD_PLUGINSOCKFILEPATH\"\n\t// EnvCMPChunkSize defines the chunk size in bytes used when sending files to the cmp server\n\tEnvCMPChunkSize = \"ARGOCD_CMP_CHUNK_SIZE\"\n\t// EnvCMPWorkDir defines the full path of the work directory used by the CMP server\n\tEnvCMPWorkDir = \"ARGOCD_CMP_WORKDIR\"\n)\n\n// Config Management Plugin related constants\nconst (\n\t// DefaultCMPChunkSize defines chunk size in bytes used when sending files to the cmp server\n\tDefaultCMPChunkSize = 1024\n\n\t// DefaultCMPWorkDirName defines the work directory name used by the cmp-server\n\tDefaultCMPWorkDirName = \"_cmp_server\"\n\n\tConfigMapPluginDeprecationWarning = \"argocd-cm plugins are deprecated, and support will be removed in v2.7. Upgrade your plugin to be installed via sidecar. https://argo-cd.readthedocs.io/en/stable/user-guide/config-management-plugins/\"\n)\n\nconst (\n\t// MinClientVersion is the minimum client version that can interface with this API server.\n\t// When introducing breaking changes to the API or datastructures, this number should be bumped.\n\t// The value here may be lower than the current value in VERSION\n\tMinClientVersion = \"1.4.0\"\n\t// CacheVersion is a objects version cached using util/cache/cache.go.\n\t// Number should be bumped in case of backward incompatible change to make sure cache is invalidated after upgrade.\n\tCacheVersion = \"1.8.3\"\n)\n\n// Constants used by util/clusterauth package\nconst (\n\tClusterAuthRequestTimeout = 10 * time.Second\n\tBearerTokenTimeout        = 30 * time.Second\n)\n\nconst (\n\tDefaultGitRetryMaxDuration time.Duration = time.Second * 5        // 5s\n\tDefaultGitRetryDuration    time.Duration = time.Millisecond * 250 // 0.25s\n\tDefaultGitRetryFactor                    = int64(2)\n)\n\n// GetGnuPGHomePath retrieves the path to use for GnuPG home directory, which is either taken from GNUPGHOME environment or a default value\nfunc GetGnuPGHomePath() string {\n\tif gnuPgHome := os.Getenv(EnvGnuPGHome); gnuPgHome == \"\" {\n\t\treturn DefaultGnuPgHomePath\n\t} else {\n\t\treturn gnuPgHome\n\t}\n}\n\n// GetPluginSockFilePath retrieves the path of plugin sock file, which is either taken from PluginSockFilePath environment or a default value\nfunc GetPluginSockFilePath() string {\n\tif pluginSockFilePath := os.Getenv(EnvPluginSockFilePath); pluginSockFilePath == \"\" {\n\t\treturn DefaultPluginSockFilePath\n\t} else {\n\t\treturn pluginSockFilePath\n\t}\n}\n\n// GetCMPChunkSize will return the env var EnvCMPChunkSize value if defined or DefaultCMPChunkSize otherwise.\n// If EnvCMPChunkSize is defined but not a valid int, DefaultCMPChunkSize will be returned\nfunc GetCMPChunkSize() int {\n\tif chunkSizeStr := os.Getenv(EnvCMPChunkSize); chunkSizeStr != \"\" {\n\t\tchunkSize, err := strconv.Atoi(chunkSizeStr)\n\t\tif err != nil {\n\t\t\tlogrus.Warnf(\"invalid env var value for %s: not a valid int: %s. Default value will be used.\", EnvCMPChunkSize, err)\n\t\t\treturn DefaultCMPChunkSize\n\t\t}\n\t\treturn chunkSize\n\t}\n\treturn DefaultCMPChunkSize\n}\n\n// GetCMPWorkDir will return the full path of the work directory used by the CMP server.\n// This directory and all it's contents will be deleted durring CMP bootstrap.\nfunc GetCMPWorkDir() string {\n\tif workDir := os.Getenv(EnvCMPWorkDir); workDir != \"\" {\n\t\treturn filepath.Join(workDir, DefaultCMPWorkDirName)\n\t}\n\treturn filepath.Join(os.TempDir(), DefaultCMPWorkDirName)\n}\n\nconst (\n\t// AnnotationApplicationRefresh is an annotation that is added when an ApplicationSet is requested to be refreshed by a webhook. The ApplicationSet controller will remove this annotation at the end of reconciliation.\n\tAnnotationApplicationSetRefresh = \"argocd.argoproj.io/application-set-refresh\"\n)\n\n// gRPC settings\nconst (\n\tGRPCKeepAliveEnforcementMinimum = 10 * time.Second\n\t// Keep alive is 2x enforcement minimum to ensure network jitter does not introduce ENHANCE_YOUR_CALM errors\n\tGRPCKeepAliveTime = 2 * GRPCKeepAliveEnforcementMinimum\n)\n\n// Security severity logging\nconst (\n\tSecurityField     = \"security\"\n\tSecurityCWEField  = \"CWE\"\n\tSecurityEmergency = 5 // Indicates unmistakably malicious events that should NEVER occur accidentally and indicates an active attack (i.e. brute forcing, DoS)\n\tSecurityCritical  = 4 // Indicates any malicious or exploitable event that had a side effect (i.e. secrets being left behind on the filesystem)\n\tSecurityHigh      = 3 // Indicates likely malicious events but one that had no side effects or was blocked (i.e. out of bounds symlinks in repos)\n\tSecurityMedium    = 2 // Could indicate malicious events, but has a high likelihood of being user/system error (i.e. access denied)\n\tSecurityLow       = 1 // Unexceptional entries (i.e. successful access logs)\n)\n\n// Common error messages\nconst TokenVerificationError = \"failed to verify the token\"\n\nvar TokenVerificationErr = errors.New(TokenVerificationError)\n\nvar PermissionDeniedAPIError = status.Error(codes.PermissionDenied, \"permission denied\")\n", "package cluster\n\nimport (\n\t\"context\"\n\t\"net/url\"\n\t\"time\"\n\n\t\"github.com/argoproj/gitops-engine/pkg/utils/kube\"\n\tlog \"github.com/sirupsen/logrus\"\n\t\"google.golang.org/grpc/codes\"\n\t\"google.golang.org/grpc/status\"\n\tv1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/util/sets\"\n\t\"k8s.io/client-go/kubernetes\"\n\n\t\"github.com/argoproj/argo-cd/v2/common\"\n\t\"github.com/argoproj/argo-cd/v2/pkg/apiclient/cluster\"\n\tappv1 \"github.com/argoproj/argo-cd/v2/pkg/apis/application/v1alpha1\"\n\tservercache \"github.com/argoproj/argo-cd/v2/server/cache\"\n\t\"github.com/argoproj/argo-cd/v2/server/rbacpolicy\"\n\t\"github.com/argoproj/argo-cd/v2/util/argo\"\n\t\"github.com/argoproj/argo-cd/v2/util/clusterauth\"\n\t\"github.com/argoproj/argo-cd/v2/util/db\"\n\t\"github.com/argoproj/argo-cd/v2/util/rbac\"\n)\n\n// Server provides a Cluster service\ntype Server struct {\n\tdb      db.ArgoDB\n\tenf     *rbac.Enforcer\n\tcache   *servercache.Cache\n\tkubectl kube.Kubectl\n}\n\n// NewServer returns a new instance of the Cluster service\nfunc NewServer(db db.ArgoDB, enf *rbac.Enforcer, cache *servercache.Cache, kubectl kube.Kubectl) *Server {\n\treturn &Server{\n\t\tdb:      db,\n\t\tenf:     enf,\n\t\tcache:   cache,\n\t\tkubectl: kubectl,\n\t}\n}\n\nfunc createRBACObject(project string, server string) string {\n\tif project != \"\" {\n\t\treturn project + \"/\" + server\n\t}\n\treturn server\n}\n\n// List returns list of clusters\nfunc (s *Server) List(ctx context.Context, q *cluster.ClusterQuery) (*appv1.ClusterList, error) {\n\tclusterList, err := s.db.ListClusters(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\titems := make([]appv1.Cluster, 0)\n\tfor _, clust := range clusterList.Items {\n\t\tif s.enf.Enforce(ctx.Value(\"claims\"), rbacpolicy.ResourceClusters, rbacpolicy.ActionGet, createRBACObject(clust.Project, clust.Server)) {\n\t\t\titems = append(items, clust)\n\t\t}\n\t}\n\terr = kube.RunAllAsync(len(items), func(i int) error {\n\t\titems[i] = *s.toAPIResponse(&items[i])\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tclusterList.Items = items\n\treturn clusterList, nil\n}\n\n// Create creates a cluster\nfunc (s *Server) Create(ctx context.Context, q *cluster.ClusterCreateRequest) (*appv1.Cluster, error) {\n\tif err := s.enf.EnforceErr(ctx.Value(\"claims\"), rbacpolicy.ResourceClusters, rbacpolicy.ActionCreate, createRBACObject(q.Cluster.Project, q.Cluster.Server)); err != nil {\n\t\treturn nil, err\n\t}\n\tc := q.Cluster\n\tserverVersion, err := s.kubectl.GetServerVersion(c.RESTConfig())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tclust, err := s.db.CreateCluster(ctx, c)\n\tif err != nil {\n\t\tif status.Convert(err).Code() == codes.AlreadyExists {\n\t\t\t// act idempotent if existing spec matches new spec\n\t\t\texisting, getErr := s.db.GetCluster(ctx, c.Server)\n\t\t\tif getErr != nil {\n\t\t\t\treturn nil, status.Errorf(codes.Internal, \"unable to check existing cluster details: %v\", getErr)\n\t\t\t}\n\n\t\t\tif existing.Equals(c) {\n\t\t\t\tclust = existing\n\t\t\t} else if q.Upsert {\n\t\t\t\treturn s.Update(ctx, &cluster.ClusterUpdateRequest{Cluster: c})\n\t\t\t} else {\n\t\t\t\treturn nil, status.Errorf(codes.InvalidArgument, argo.GenerateSpecIsDifferentErrorMessage(\"cluster\", existing, c))\n\t\t\t}\n\t\t} else {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\terr = s.cache.SetClusterInfo(c.Server, &appv1.ClusterInfo{\n\t\tServerVersion: serverVersion,\n\t\tConnectionState: appv1.ConnectionState{\n\t\t\tStatus:     appv1.ConnectionStatusSuccessful,\n\t\t\tModifiedAt: &v1.Time{Time: time.Now()},\n\t\t},\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn s.toAPIResponse(clust), err\n}\n\n// Get returns a cluster from a query\nfunc (s *Server) Get(ctx context.Context, q *cluster.ClusterQuery) (*appv1.Cluster, error) {\n\tc, err := s.getClusterWith403IfNotExist(ctx, q)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := s.enf.EnforceErr(ctx.Value(\"claims\"), rbacpolicy.ResourceClusters, rbacpolicy.ActionGet, createRBACObject(c.Project, q.Server)); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn s.toAPIResponse(c), nil\n}\n\nfunc (s *Server) getClusterWith403IfNotExist(ctx context.Context, q *cluster.ClusterQuery) (*appv1.Cluster, error) {\n\trepo, err := s.getCluster(ctx, q)\n\tif err != nil || repo == nil {\n\t\treturn nil, common.PermissionDeniedAPIError\n\t}\n\treturn repo, nil\n}\n\nfunc (s *Server) getCluster(ctx context.Context, q *cluster.ClusterQuery) (*appv1.Cluster, error) {\n\tif q.Id != nil {\n\t\tq.Server = \"\"\n\t\tq.Name = \"\"\n\t\tif q.Id.Type == \"name\" {\n\t\t\tq.Name = q.Id.Value\n\t\t} else if q.Id.Type == \"name_escaped\" {\n\t\t\tnameUnescaped, err := url.QueryUnescape(q.Id.Value)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tq.Name = nameUnescaped\n\t\t} else {\n\t\t\tq.Server = q.Id.Value\n\t\t}\n\t}\n\n\tif q.Server != \"\" {\n\t\tc, err := s.db.GetCluster(ctx, q.Server)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn c, nil\n\t}\n\n\t//we only get the name when we specify Name in ApplicationDestination and next\n\t//we want to find the server in order to populate ApplicationDestination.Server\n\tif q.Name != \"\" {\n\t\tclusterList, err := s.db.ListClusters(ctx)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tfor _, c := range clusterList.Items {\n\t\t\tif c.Name == q.Name {\n\t\t\t\treturn &c, nil\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil, nil\n}\n\nvar clusterFieldsByPath = map[string]func(updated *appv1.Cluster, existing *appv1.Cluster){\n\t\"name\": func(updated *appv1.Cluster, existing *appv1.Cluster) {\n\t\tupdated.Name = existing.Name\n\t},\n\t\"namespaces\": func(updated *appv1.Cluster, existing *appv1.Cluster) {\n\t\tupdated.Namespaces = existing.Namespaces\n\t},\n\t\"config\": func(updated *appv1.Cluster, existing *appv1.Cluster) {\n\t\tupdated.Config = existing.Config\n\t},\n\t\"shard\": func(updated *appv1.Cluster, existing *appv1.Cluster) {\n\t\tupdated.Shard = existing.Shard\n\t},\n\t\"clusterResources\": func(updated *appv1.Cluster, existing *appv1.Cluster) {\n\t\tupdated.ClusterResources = existing.ClusterResources\n\t},\n\t\"labels\": func(updated *appv1.Cluster, existing *appv1.Cluster) {\n\t\tupdated.Labels = existing.Labels\n\t},\n\t\"annotations\": func(updated *appv1.Cluster, existing *appv1.Cluster) {\n\t\tupdated.Annotations = existing.Annotations\n\t},\n\t\"project\": func(updated *appv1.Cluster, existing *appv1.Cluster) {\n\t\tupdated.Project = existing.Project\n\t},\n}\n\n// Update updates a cluster\nfunc (s *Server) Update(ctx context.Context, q *cluster.ClusterUpdateRequest) (*appv1.Cluster, error) {\n\tc, err := s.getClusterWith403IfNotExist(ctx, &cluster.ClusterQuery{\n\t\tServer: q.Cluster.Server,\n\t\tName:   q.Cluster.Name,\n\t\tId:     q.Id,\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// verify that user can do update inside project where cluster is located\n\tif !s.enf.Enforce(ctx.Value(\"claims\"), rbacpolicy.ResourceClusters, rbacpolicy.ActionUpdate, createRBACObject(c.Project, c.Server)) {\n\t\treturn nil, common.PermissionDeniedAPIError\n\t}\n\n\tif len(q.UpdatedFields) == 0 || sets.NewString(q.UpdatedFields...).Has(\"project\") {\n\t\t// verify that user can do update inside project where cluster will be located\n\t\tif !s.enf.Enforce(ctx.Value(\"claims\"), rbacpolicy.ResourceClusters, rbacpolicy.ActionUpdate, createRBACObject(q.Cluster.Project, c.Server)) {\n\t\t\treturn nil, common.PermissionDeniedAPIError\n\t\t}\n\t}\n\n\tif len(q.UpdatedFields) != 0 {\n\t\tfor _, path := range q.UpdatedFields {\n\t\t\tif updater, ok := clusterFieldsByPath[path]; ok {\n\t\t\t\tupdater(c, q.Cluster)\n\t\t\t}\n\t\t}\n\t\tq.Cluster = c\n\t}\n\n\t// Test the token we just created before persisting it\n\tserverVersion, err := s.kubectl.GetServerVersion(q.Cluster.RESTConfig())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tclust, err := s.db.UpdateCluster(ctx, q.Cluster)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = s.cache.SetClusterInfo(clust.Server, &appv1.ClusterInfo{\n\t\tServerVersion: serverVersion,\n\t\tConnectionState: appv1.ConnectionState{\n\t\t\tStatus:     appv1.ConnectionStatusSuccessful,\n\t\t\tModifiedAt: &v1.Time{Time: time.Now()},\n\t\t},\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn s.toAPIResponse(clust), nil\n}\n\n// Delete deletes a cluster by server/name\nfunc (s *Server) Delete(ctx context.Context, q *cluster.ClusterQuery) (*cluster.ClusterResponse, error) {\n\tc, err := s.getClusterWith403IfNotExist(ctx, q)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif q.Name != \"\" {\n\t\tservers, err := s.db.GetClusterServersByName(ctx, q.Name)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tfor _, server := range servers {\n\t\t\tif err := enforceAndDelete(s, ctx, server, c.Project); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t} else {\n\t\tif err := enforceAndDelete(s, ctx, q.Server, c.Project); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn &cluster.ClusterResponse{}, nil\n}\n\nfunc enforceAndDelete(s *Server, ctx context.Context, server, project string) error {\n\tif err := s.enf.EnforceErr(ctx.Value(\"claims\"), rbacpolicy.ResourceClusters, rbacpolicy.ActionDelete, createRBACObject(project, server)); err != nil {\n\t\treturn err\n\t}\n\tif err := s.db.DeleteCluster(ctx, server); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n\n// RotateAuth rotates the bearer token used for a cluster\nfunc (s *Server) RotateAuth(ctx context.Context, q *cluster.ClusterQuery) (*cluster.ClusterResponse, error) {\n\tclust, err := s.getClusterWith403IfNotExist(ctx, q)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar servers []string\n\tif q.Name != \"\" {\n\t\tservers, err = s.db.GetClusterServersByName(ctx, q.Name)\n\t\tif err != nil {\n\t\t\treturn nil, status.Errorf(codes.NotFound, \"failed to get cluster servers by name: %v\", err)\n\t\t}\n\t\tfor _, server := range servers {\n\t\t\tif err := s.enf.EnforceErr(ctx.Value(\"claims\"), rbacpolicy.ResourceClusters, rbacpolicy.ActionUpdate, createRBACObject(clust.Project, server)); err != nil {\n\t\t\t\treturn nil, status.Errorf(codes.PermissionDenied, \"encountered permissions issue while processing request: %v\", err)\n\t\t\t}\n\t\t}\n\t} else {\n\t\tif err := s.enf.EnforceErr(ctx.Value(\"claims\"), rbacpolicy.ResourceClusters, rbacpolicy.ActionUpdate, createRBACObject(clust.Project, q.Server)); err != nil {\n\t\t\treturn nil, status.Errorf(codes.PermissionDenied, \"encountered permissions issue while processing request: %v\", err)\n\t\t}\n\t\tservers = append(servers, q.Server)\n\t}\n\n\tfor _, server := range servers {\n\t\tlogCtx := log.WithField(\"cluster\", server)\n\t\tlogCtx.Info(\"Rotating auth\")\n\t\trestCfg := clust.RESTConfig()\n\t\tif restCfg.BearerToken == \"\" {\n\t\t\treturn nil, status.Errorf(codes.InvalidArgument, \"Cluster '%s' does not use bearer token authentication\", server)\n\t\t}\n\n\t\tclaims, err := clusterauth.ParseServiceAccountToken(restCfg.BearerToken)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tkubeclientset, err := kubernetes.NewForConfig(restCfg)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tnewSecret, err := clusterauth.GenerateNewClusterManagerSecret(kubeclientset, claims)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\t// we are using token auth, make sure we don't store client-cert information\n\t\tclust.Config.KeyData = nil\n\t\tclust.Config.CertData = nil\n\t\tclust.Config.BearerToken = string(newSecret.Data[\"token\"])\n\n\t\t// Test the token we just created before persisting it\n\t\tserverVersion, err := s.kubectl.GetServerVersion(clust.RESTConfig())\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\t_, err = s.db.UpdateCluster(ctx, clust)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\terr = s.cache.SetClusterInfo(clust.Server, &appv1.ClusterInfo{\n\t\t\tServerVersion: serverVersion,\n\t\t\tConnectionState: appv1.ConnectionState{\n\t\t\t\tStatus:     appv1.ConnectionStatusSuccessful,\n\t\t\t\tModifiedAt: &v1.Time{Time: time.Now()},\n\t\t\t},\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\terr = clusterauth.RotateServiceAccountSecrets(kubeclientset, claims, newSecret)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tlogCtx.Infof(\"Rotated auth (old: %s, new: %s)\", claims.SecretName, newSecret.Name)\n\t}\n\treturn &cluster.ClusterResponse{}, nil\n}\n\nfunc (s *Server) toAPIResponse(clust *appv1.Cluster) *appv1.Cluster {\n\t_ = s.cache.GetClusterInfo(clust.Server, &clust.Info)\n\n\tclust.Config.Password = \"\"\n\tclust.Config.BearerToken = \"\"\n\tclust.Config.TLSClientConfig.KeyData = nil\n\tif clust.Config.ExecProviderConfig != nil {\n\t\t// We can't know what the user has put into args or\n\t\t// env vars on the exec provider that might be sensitive\n\t\t// (e.g. --private-key=XXX, PASSWORD=XXX)\n\t\t// Implicitly assumes the command executable name is non-sensitive\n\t\tclust.Config.ExecProviderConfig.Env = make(map[string]string)\n\t\tclust.Config.ExecProviderConfig.Args = nil\n\t}\n\t// populate deprecated fields for backward compatibility\n\tclust.ServerVersion = clust.Info.ServerVersion\n\tclust.ConnectionState = clust.Info.ConnectionState\n\treturn clust\n}\n\n// InvalidateCache invalidates cluster cache\nfunc (s *Server) InvalidateCache(ctx context.Context, q *cluster.ClusterQuery) (*appv1.Cluster, error) {\n\tcls, err := s.getClusterWith403IfNotExist(ctx, q)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif err := s.enf.EnforceErr(ctx.Value(\"claims\"), rbacpolicy.ResourceClusters, rbacpolicy.ActionUpdate, createRBACObject(cls.Project, q.Server)); err != nil {\n\t\treturn nil, err\n\t}\n\tnow := v1.Now()\n\tcls.RefreshRequestedAt = &now\n\tcls, err = s.db.UpdateCluster(ctx, cls)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn s.toAPIResponse(cls), nil\n}\n", "package cluster\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"testing\"\n\t\"time\"\n\n\tcorev1 \"k8s.io/api/core/v1\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\tv1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/runtime\"\n\n\t\"github.com/argoproj/gitops-engine/pkg/utils/kube/kubetest\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/mock\"\n\t\"github.com/stretchr/testify/require\"\n\t\"k8s.io/client-go/kubernetes/fake\"\n\t\"k8s.io/utils/pointer\"\n\n\t\"github.com/argoproj/argo-cd/v2/common\"\n\tclusterapi \"github.com/argoproj/argo-cd/v2/pkg/apiclient/cluster\"\n\t\"github.com/argoproj/argo-cd/v2/pkg/apis/application/v1alpha1\"\n\tservercache \"github.com/argoproj/argo-cd/v2/server/cache\"\n\t\"github.com/argoproj/argo-cd/v2/test\"\n\tcacheutil \"github.com/argoproj/argo-cd/v2/util/cache\"\n\tappstatecache \"github.com/argoproj/argo-cd/v2/util/cache/appstate\"\n\t\"github.com/argoproj/argo-cd/v2/util/db\"\n\tdbmocks \"github.com/argoproj/argo-cd/v2/util/db/mocks\"\n\t\"github.com/argoproj/argo-cd/v2/util/rbac\"\n\t\"github.com/argoproj/argo-cd/v2/util/settings\"\n)\n\nfunc newServerInMemoryCache() *servercache.Cache {\n\treturn servercache.NewCache(\n\t\tappstatecache.NewCache(\n\t\t\tcacheutil.NewCache(cacheutil.NewInMemoryCache(1*time.Hour)),\n\t\t\t1*time.Minute,\n\t\t),\n\t\t1*time.Minute,\n\t\t1*time.Minute,\n\t\t1*time.Minute,\n\t)\n}\n\nfunc newNoopEnforcer() *rbac.Enforcer {\n\tenf := rbac.NewEnforcer(fake.NewSimpleClientset(test.NewFakeConfigMap()), test.FakeArgoCDNamespace, common.ArgoCDConfigMapName, nil)\n\tenf.EnableEnforce(false)\n\treturn enf\n}\n\nfunc TestUpdateCluster_RejectInvalidParams(t *testing.T) {\n\ttestCases := []struct {\n\t\tname    string\n\t\trequest clusterapi.ClusterUpdateRequest\n\t}{\n\t\t{\n\t\t\tname:    \"allowed cluster URL in body, disallowed cluster URL in query\",\n\t\t\trequest: clusterapi.ClusterUpdateRequest{Cluster: &v1alpha1.Cluster{Name: \"\", Server: \"https://127.0.0.1\", Project: \"\", ClusterResources: true}, Id: &clusterapi.ClusterID{Type: \"\", Value: \"https://127.0.0.2\"}, UpdatedFields: []string{\"clusterResources\", \"project\"}},\n\t\t},\n\t\t{\n\t\t\tname:    \"allowed cluster URL in body, disallowed cluster name in query\",\n\t\t\trequest: clusterapi.ClusterUpdateRequest{Cluster: &v1alpha1.Cluster{Name: \"\", Server: \"https://127.0.0.1\", Project: \"\", ClusterResources: true}, Id: &clusterapi.ClusterID{Type: \"name\", Value: \"disallowed-unscoped\"}, UpdatedFields: []string{\"clusterResources\", \"project\"}},\n\t\t},\n\t\t{\n\t\t\tname:    \"allowed cluster URL in body, disallowed cluster name in query, changing unscoped to scoped\",\n\t\t\trequest: clusterapi.ClusterUpdateRequest{Cluster: &v1alpha1.Cluster{Name: \"\", Server: \"https://127.0.0.1\", Project: \"allowed-project\", ClusterResources: true}, Id: &clusterapi.ClusterID{Type: \"\", Value: \"https://127.0.0.2\"}, UpdatedFields: []string{\"clusterResources\", \"project\"}},\n\t\t},\n\t\t{\n\t\t\tname:    \"allowed cluster URL in body, disallowed cluster URL in query, changing unscoped to scoped\",\n\t\t\trequest: clusterapi.ClusterUpdateRequest{Cluster: &v1alpha1.Cluster{Name: \"\", Server: \"https://127.0.0.1\", Project: \"allowed-project\", ClusterResources: true}, Id: &clusterapi.ClusterID{Type: \"name\", Value: \"disallowed-unscoped\"}, UpdatedFields: []string{\"clusterResources\", \"project\"}},\n\t\t},\n\t}\n\n\tdb := &dbmocks.ArgoDB{}\n\n\tclusters := []v1alpha1.Cluster{\n\t\t{\n\t\t\tName:   \"allowed-unscoped\",\n\t\t\tServer: \"https://127.0.0.1\",\n\t\t},\n\t\t{\n\t\t\tName:   \"disallowed-unscoped\",\n\t\t\tServer: \"https://127.0.0.2\",\n\t\t},\n\t\t{\n\t\t\tName:    \"allowed-scoped\",\n\t\t\tServer:  \"https://127.0.0.3\",\n\t\t\tProject: \"allowed-project\",\n\t\t},\n\t\t{\n\t\t\tName:    \"disallowed-scoped\",\n\t\t\tServer:  \"https://127.0.0.4\",\n\t\t\tProject: \"disallowed-project\",\n\t\t},\n\t}\n\n\tdb.On(\"ListClusters\", mock.Anything).Return(\n\t\tfunc(ctx context.Context) *v1alpha1.ClusterList {\n\t\t\treturn &v1alpha1.ClusterList{\n\t\t\t\tListMeta: v1.ListMeta{},\n\t\t\t\tItems:    clusters,\n\t\t\t}\n\t\t},\n\t\tfunc(ctx context.Context) error {\n\t\t\treturn nil\n\t\t},\n\t)\n\tdb.On(\"UpdateCluster\", mock.Anything, mock.Anything).Return(\n\t\tfunc(ctx context.Context, c *v1alpha1.Cluster) *v1alpha1.Cluster {\n\t\t\tfor _, cluster := range clusters {\n\t\t\t\tif c.Server == cluster.Server {\n\t\t\t\t\treturn c\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn nil\n\t\t},\n\t\tfunc(ctx context.Context, c *v1alpha1.Cluster) error {\n\t\t\tfor _, cluster := range clusters {\n\t\t\t\tif c.Server == cluster.Server {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn fmt.Errorf(\"cluster '%s' not found\", c.Server)\n\t\t},\n\t)\n\tdb.On(\"GetCluster\", mock.Anything, mock.Anything).Return(\n\t\tfunc(ctx context.Context, server string) *v1alpha1.Cluster {\n\t\t\tfor _, cluster := range clusters {\n\t\t\t\tif server == cluster.Server {\n\t\t\t\t\treturn &cluster\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn nil\n\t\t},\n\t\tfunc(ctx context.Context, server string) error {\n\t\t\tfor _, cluster := range clusters {\n\t\t\t\tif server == cluster.Server {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn fmt.Errorf(\"cluster '%s' not found\", server)\n\t\t},\n\t)\n\n\tenf := rbac.NewEnforcer(fake.NewSimpleClientset(test.NewFakeConfigMap()), test.FakeArgoCDNamespace, common.ArgoCDConfigMapName, nil)\n\t_ = enf.SetBuiltinPolicy(`p, role:test, clusters, *, https://127.0.0.1, allow\np, role:test, clusters, *, allowed-project/*, allow`)\n\tenf.SetDefaultRole(\"role:test\")\n\tserver := NewServer(db, enf, newServerInMemoryCache(), &kubetest.MockKubectlCmd{})\n\n\tfor _, c := range testCases {\n\t\tcc := c\n\t\tt.Run(cc.name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\t\t\tout, err := server.Update(context.Background(), &cc.request)\n\t\t\trequire.Nil(t, out)\n\t\t\tassert.ErrorIs(t, err, common.PermissionDeniedAPIError)\n\t\t})\n\t}\n}\n\nfunc TestGetCluster_UrlEncodedName(t *testing.T) {\n\tdb := &dbmocks.ArgoDB{}\n\n\tmockCluster := v1alpha1.Cluster{\n\t\tName:       \"test/ing\",\n\t\tServer:     \"https://127.0.0.1\",\n\t\tNamespaces: []string{\"default\", \"kube-system\"},\n\t}\n\tmockClusterList := v1alpha1.ClusterList{\n\t\tListMeta: v1.ListMeta{},\n\t\tItems: []v1alpha1.Cluster{\n\t\t\tmockCluster,\n\t\t},\n\t}\n\n\tdb.On(\"ListClusters\", mock.Anything).Return(&mockClusterList, nil)\n\n\tserver := NewServer(db, newNoopEnforcer(), newServerInMemoryCache(), &kubetest.MockKubectlCmd{})\n\n\tcluster, err := server.Get(context.Background(), &clusterapi.ClusterQuery{\n\t\tId: &clusterapi.ClusterID{\n\t\t\tType:  \"name_escaped\",\n\t\t\tValue: \"test%2fing\",\n\t\t},\n\t})\n\trequire.NoError(t, err)\n\n\tassert.Equal(t, cluster.Name, \"test/ing\")\n}\n\nfunc TestGetCluster_NameWithUrlEncodingButShouldNotBeUnescaped(t *testing.T) {\n\tdb := &dbmocks.ArgoDB{}\n\n\tmockCluster := v1alpha1.Cluster{\n\t\tName:       \"test%2fing\",\n\t\tServer:     \"https://127.0.0.1\",\n\t\tNamespaces: []string{\"default\", \"kube-system\"},\n\t}\n\tmockClusterList := v1alpha1.ClusterList{\n\t\tListMeta: v1.ListMeta{},\n\t\tItems: []v1alpha1.Cluster{\n\t\t\tmockCluster,\n\t\t},\n\t}\n\n\tdb.On(\"ListClusters\", mock.Anything).Return(&mockClusterList, nil)\n\n\tserver := NewServer(db, newNoopEnforcer(), newServerInMemoryCache(), &kubetest.MockKubectlCmd{})\n\n\tcluster, err := server.Get(context.Background(), &clusterapi.ClusterQuery{\n\t\tId: &clusterapi.ClusterID{\n\t\t\tType:  \"name\",\n\t\t\tValue: \"test%2fing\",\n\t\t},\n\t})\n\trequire.NoError(t, err)\n\n\tassert.Equal(t, cluster.Name, \"test%2fing\")\n}\n\nfunc TestUpdateCluster_NoFieldsPaths(t *testing.T) {\n\tdb := &dbmocks.ArgoDB{}\n\tvar updated *v1alpha1.Cluster\n\n\tclusters := []v1alpha1.Cluster{\n\t\t{\n\t\t\tName:       \"minikube\",\n\t\t\tServer:     \"https://127.0.0.1\",\n\t\t\tNamespaces: []string{\"default\", \"kube-system\"},\n\t\t},\n\t}\n\n\tclusterList := v1alpha1.ClusterList{\n\t\tListMeta: v1.ListMeta{},\n\t\tItems:    clusters,\n\t}\n\n\tdb.On(\"ListClusters\", mock.Anything).Return(&clusterList, nil)\n\tdb.On(\"UpdateCluster\", mock.Anything, mock.MatchedBy(func(c *v1alpha1.Cluster) bool {\n\t\tupdated = c\n\t\treturn true\n\t})).Return(&v1alpha1.Cluster{}, nil)\n\n\tserver := NewServer(db, newNoopEnforcer(), newServerInMemoryCache(), &kubetest.MockKubectlCmd{})\n\n\t_, err := server.Update(context.Background(), &clusterapi.ClusterUpdateRequest{\n\t\tCluster: &v1alpha1.Cluster{\n\t\t\tName:       \"minikube\",\n\t\t\tNamespaces: []string{\"default\", \"kube-system\"},\n\t\t},\n\t})\n\n\trequire.NoError(t, err)\n\n\tassert.Equal(t, updated.Name, \"minikube\")\n\tassert.Equal(t, updated.Namespaces, []string{\"default\", \"kube-system\"})\n}\n\nfunc TestUpdateCluster_FieldsPathSet(t *testing.T) {\n\tdb := &dbmocks.ArgoDB{}\n\tvar updated *v1alpha1.Cluster\n\tdb.On(\"GetCluster\", mock.Anything, \"https://127.0.0.1\").Return(&v1alpha1.Cluster{\n\t\tName:       \"minikube\",\n\t\tServer:     \"https://127.0.0.1\",\n\t\tNamespaces: []string{\"default\", \"kube-system\"},\n\t}, nil)\n\tdb.On(\"UpdateCluster\", mock.Anything, mock.MatchedBy(func(c *v1alpha1.Cluster) bool {\n\t\tupdated = c\n\t\treturn true\n\t})).Return(&v1alpha1.Cluster{}, nil)\n\n\tserver := NewServer(db, newNoopEnforcer(), newServerInMemoryCache(), &kubetest.MockKubectlCmd{})\n\n\t_, err := server.Update(context.Background(), &clusterapi.ClusterUpdateRequest{\n\t\tCluster: &v1alpha1.Cluster{\n\t\t\tServer: \"https://127.0.0.1\",\n\t\t\tShard:  pointer.Int64Ptr(1),\n\t\t},\n\t\tUpdatedFields: []string{\"shard\"},\n\t})\n\n\trequire.NoError(t, err)\n\n\tassert.Equal(t, updated.Name, \"minikube\")\n\tassert.Equal(t, updated.Namespaces, []string{\"default\", \"kube-system\"})\n\tassert.Equal(t, *updated.Shard, int64(1))\n\n\tlabelEnv := map[string]string{\n\t\t\"env\": \"qa\",\n\t}\n\t_, err = server.Update(context.Background(), &clusterapi.ClusterUpdateRequest{\n\t\tCluster: &v1alpha1.Cluster{\n\t\t\tServer: \"https://127.0.0.1\",\n\t\t\tLabels: labelEnv,\n\t\t},\n\t\tUpdatedFields: []string{\"labels\"},\n\t})\n\n\trequire.NoError(t, err)\n\n\tassert.Equal(t, updated.Name, \"minikube\")\n\tassert.Equal(t, updated.Namespaces, []string{\"default\", \"kube-system\"})\n\tassert.Equal(t, updated.Labels, labelEnv)\n\n\tannotationEnv := map[string]string{\n\t\t\"env\": \"qa\",\n\t}\n\t_, err = server.Update(context.Background(), &clusterapi.ClusterUpdateRequest{\n\t\tCluster: &v1alpha1.Cluster{\n\t\t\tServer:      \"https://127.0.0.1\",\n\t\t\tAnnotations: annotationEnv,\n\t\t},\n\t\tUpdatedFields: []string{\"annotations\"},\n\t})\n\n\trequire.NoError(t, err)\n\n\tassert.Equal(t, updated.Name, \"minikube\")\n\tassert.Equal(t, updated.Namespaces, []string{\"default\", \"kube-system\"})\n\tassert.Equal(t, updated.Annotations, annotationEnv)\n\n\t_, err = server.Update(context.Background(), &clusterapi.ClusterUpdateRequest{\n\t\tCluster: &v1alpha1.Cluster{\n\t\t\tServer:  \"https://127.0.0.1\",\n\t\t\tProject: \"new-project\",\n\t\t},\n\t\tUpdatedFields: []string{\"project\"},\n\t})\n\n\trequire.NoError(t, err)\n\n\tassert.Equal(t, updated.Name, \"minikube\")\n\tassert.Equal(t, updated.Namespaces, []string{\"default\", \"kube-system\"})\n\tassert.Equal(t, updated.Project, \"new-project\")\n}\n\nfunc TestDeleteClusterByName(t *testing.T) {\n\ttestNamespace := \"default\"\n\tclientset := getClientset(nil, testNamespace, &corev1.Secret{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"my-cluster-secret\",\n\t\t\tNamespace: testNamespace,\n\t\t\tLabels: map[string]string{\n\t\t\t\tcommon.LabelKeySecretType: common.LabelValueSecretTypeCluster,\n\t\t\t},\n\t\t\tAnnotations: map[string]string{\n\t\t\t\tcommon.AnnotationKeyManagedBy: common.AnnotationValueManagedByArgoCD,\n\t\t\t},\n\t\t},\n\t\tData: map[string][]byte{\n\t\t\t\"name\":   []byte(\"my-cluster-name\"),\n\t\t\t\"server\": []byte(\"https://my-cluster-server\"),\n\t\t\t\"config\": []byte(\"{}\"),\n\t\t},\n\t})\n\tdb := db.NewDB(testNamespace, settings.NewSettingsManager(context.Background(), clientset, testNamespace), clientset)\n\tserver := NewServer(db, newNoopEnforcer(), newServerInMemoryCache(), &kubetest.MockKubectlCmd{})\n\n\tt.Run(\"Delete Fails When Deleting by Unknown Name\", func(t *testing.T) {\n\t\t_, err := server.Delete(context.Background(), &clusterapi.ClusterQuery{\n\t\t\tName: \"foo\",\n\t\t})\n\n\t\tassert.EqualError(t, err, `rpc error: code = PermissionDenied desc = permission denied`)\n\t})\n\n\tt.Run(\"Delete Succeeds When Deleting by Name\", func(t *testing.T) {\n\t\t_, err := server.Delete(context.Background(), &clusterapi.ClusterQuery{\n\t\t\tName: \"my-cluster-name\",\n\t\t})\n\t\tassert.Nil(t, err)\n\n\t\t_, err = db.GetCluster(context.Background(), \"https://my-cluster-server\")\n\t\tassert.EqualError(t, err, `rpc error: code = NotFound desc = cluster \"https://my-cluster-server\" not found`)\n\t})\n}\n\nfunc TestRotateAuth(t *testing.T) {\n\ttestNamespace := \"kube-system\"\n\ttoken := \"eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhcmdvY2QtbWFuYWdlci10b2tlbi10ajc5ciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJhcmdvY2QtbWFuYWdlciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjkxZGQzN2NmLThkOTItMTFlOS1hMDkxLWQ2NWYyYWU3ZmE4ZCIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTphcmdvY2QtbWFuYWdlciJ9.ytZjt2pDV8-A7DBMR06zQ3wt9cuVEfq262TQw7sdra-KRpDpMPnziMhc8bkwvgW-LGhTWUh5iu1y-1QhEx6mtbCt7vQArlBRxfvM5ys6ClFkplzq5c2TtZ7EzGSD0Up7tdxuG9dvR6TGXYdfFcG779yCdZo2H48sz5OSJfdEriduMEY1iL5suZd3ebOoVi1fGflmqFEkZX6SvxkoArl5mtNP6TvZ1eTcn64xh4ws152hxio42E-eSnl_CET4tpB5vgP5BVlSKW2xB7w2GJxqdETA5LJRI_OilY77dTOp8cMr_Ck3EOeda3zHfh4Okflg8rZFEeAuJYahQNeAILLkcA\"\n\tconfig := v1alpha1.ClusterConfig{\n\t\tBearerToken: token,\n\t}\n\n\tconfigMarshal, err := json.Marshal(config)\n\tif err != nil {\n\t\tt.Errorf(\"failed to marshal config for test: %v\", err)\n\t}\n\n\tclientset := getClientset(nil, testNamespace,\n\t\t&corev1.Secret{\n\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\tName:      \"my-cluster-secret\",\n\t\t\t\tNamespace: testNamespace,\n\t\t\t\tLabels: map[string]string{\n\t\t\t\t\tcommon.LabelKeySecretType: common.LabelValueSecretTypeCluster,\n\t\t\t\t},\n\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\tcommon.AnnotationKeyManagedBy: common.AnnotationValueManagedByArgoCD,\n\t\t\t\t},\n\t\t\t},\n\t\t\tData: map[string][]byte{\n\t\t\t\t\"name\":   []byte(\"my-cluster-name\"),\n\t\t\t\t\"server\": []byte(\"https://my-cluster-name\"),\n\t\t\t\t\"config\": configMarshal,\n\t\t\t},\n\t\t},\n\t\t&corev1.Namespace{\n\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\tName: \"kube-system\",\n\t\t\t},\n\t\t},\n\t\t&corev1.Secret{\n\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\tName:      \"argocd-manager-token-tj79r\",\n\t\t\t\tNamespace: \"kube-system\",\n\t\t\t},\n\t\t\tData: map[string][]byte{\n\t\t\t\t\"token\": []byte(token),\n\t\t\t},\n\t\t},\n\t\t&corev1.ServiceAccount{\n\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\tName:      \"argocd-manager\",\n\t\t\t\tNamespace: \"kube-system\",\n\t\t\t},\n\t\t\tSecrets: []corev1.ObjectReference{\n\t\t\t\t{\n\t\t\t\t\tKind: \"Secret\",\n\t\t\t\t\tName: \"argocd-manager-token-tj79r\",\n\t\t\t\t},\n\t\t\t},\n\t\t})\n\n\tdb := db.NewDB(testNamespace, settings.NewSettingsManager(context.Background(), clientset, testNamespace), clientset)\n\tserver := NewServer(db, newNoopEnforcer(), newServerInMemoryCache(), &kubetest.MockKubectlCmd{})\n\n\tt.Run(\"RotateAuth by Unknown Name\", func(t *testing.T) {\n\t\t_, err := server.RotateAuth(context.Background(), &clusterapi.ClusterQuery{\n\t\t\tName: \"foo\",\n\t\t})\n\n\t\tassert.EqualError(t, err, `rpc error: code = PermissionDenied desc = permission denied`)\n\t})\n\n\t// While the tests results for the next two tests result in an error, they do\n\t// demonstrate the proper mapping of cluster names/server to server info (i.e. my-cluster-name\n\t// results in https://my-cluster-name info being used and https://my-cluster-name results in https://my-cluster-name).\n\tt.Run(\"RotateAuth by Name - Error from no such host\", func(t *testing.T) {\n\t\t_, err := server.RotateAuth(context.Background(), &clusterapi.ClusterQuery{\n\t\t\tName: \"my-cluster-name\",\n\t\t})\n\n\t\trequire.NotNil(t, err)\n\t\tassert.Contains(t, err.Error(), \"Get \\\"https://my-cluster-name/\")\n\t})\n\n\tt.Run(\"RotateAuth by Server - Error from no such host\", func(t *testing.T) {\n\t\t_, err := server.RotateAuth(context.Background(), &clusterapi.ClusterQuery{\n\t\t\tServer: \"https://my-cluster-name\",\n\t\t})\n\n\t\trequire.NotNil(t, err)\n\t\tassert.Contains(t, err.Error(), \"Get \\\"https://my-cluster-name/\")\n\t})\n}\n\nfunc getClientset(config map[string]string, ns string, objects ...runtime.Object) *fake.Clientset {\n\tsecret := corev1.Secret{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"argocd-secret\",\n\t\t\tNamespace: ns,\n\t\t},\n\t\tData: map[string][]byte{\n\t\t\t\"admin.password\":   []byte(\"test\"),\n\t\t\t\"server.secretkey\": []byte(\"test\"),\n\t\t},\n\t}\n\tcm := corev1.ConfigMap{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"argocd-cm\",\n\t\t\tNamespace: ns,\n\t\t\tLabels: map[string]string{\n\t\t\t\t\"app.kubernetes.io/part-of\": \"argocd\",\n\t\t\t},\n\t\t},\n\t\tData: config,\n\t}\n\treturn fake.NewSimpleClientset(append(objects, &cm, &secret)...)\n}\n"], "filenames": ["common/common.go", "server/cluster/cluster.go", "server/cluster/cluster_test.go"], "buggy_code_start_loc": [10, 3, 5], "buggy_code_end_loc": [318, 232, 51], "fixing_code_start_loc": [11, 4, 6], "fixing_code_end_loc": [323, 232, 164], "type": "CWE-863", "message": "Argo CD is a declarative, GitOps continuous delivery tool for Kubernetes. All Argo CD versions starting with 2.3.0-rc1 and prior to 2.3.17, 2.4.23 2.5.11, and 2.6.2 are vulnerable to an improper authorization bug which allows users who have the ability to update at least one cluster secret to update any cluster secret. The attacker could use this access to escalate privileges (potentially controlling Kubernetes resources) or to break Argo CD functionality (by preventing connections to external clusters). A patch for this vulnerability has been released in Argo CD versions 2.6.2, 2.5.11, 2.4.23, and 2.3.17. Two workarounds are available. Either modify the RBAC configuration to completely revoke all `clusters, update` access, or use the `destinations` and `clusterResourceWhitelist` fields to apply similar restrictions as the `namespaces` and `clusterResources` fields.", "other": {"cve": {"id": "CVE-2023-23947", "sourceIdentifier": "security-advisories@github.com", "published": "2023-02-16T18:15:11.310", "lastModified": "2023-02-27T18:00:46.797", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Argo CD is a declarative, GitOps continuous delivery tool for Kubernetes. All Argo CD versions starting with 2.3.0-rc1 and prior to 2.3.17, 2.4.23 2.5.11, and 2.6.2 are vulnerable to an improper authorization bug which allows users who have the ability to update at least one cluster secret to update any cluster secret. The attacker could use this access to escalate privileges (potentially controlling Kubernetes resources) or to break Argo CD functionality (by preventing connections to external clusters). A patch for this vulnerability has been released in Argo CD versions 2.6.2, 2.5.11, 2.4.23, and 2.3.17. Two workarounds are available. Either modify the RBAC configuration to completely revoke all `clusters, update` access, or use the `destinations` and `clusterResourceWhitelist` fields to apply similar restrictions as the `namespaces` and `clusterResources` fields."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:L/UI:N/S:C/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "CHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 6.0}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:C/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "HIGH", "userInteraction": "NONE", "scope": "CHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.1, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 2.3, "impactScore": 6.0}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-863"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-863"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:linuxfoundation:argo-cd:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.3.0", "versionEndExcluding": "2.3.17", "matchCriteriaId": "89F9767D-3CAA-4341-BB96-AC353DAEA83D"}, {"vulnerable": true, "criteria": "cpe:2.3:a:linuxfoundation:argo-cd:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.4.0", "versionEndExcluding": "2.4.23", "matchCriteriaId": "14F9E3CF-680E-4EE6-8B1E-525C41F7A77D"}, {"vulnerable": true, "criteria": "cpe:2.3:a:linuxfoundation:argo-cd:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.5.0", "versionEndExcluding": "2.5.11", "matchCriteriaId": "FCBEAE6A-8D10-42CC-917D-1C9881620AFA"}, {"vulnerable": true, "criteria": "cpe:2.3:a:linuxfoundation:argo-cd:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.6.0", "versionEndExcluding": "2.6.2", "matchCriteriaId": "860243DF-3E99-45E7-B2EE-EA3664CFC223"}]}]}], "references": [{"url": "https://github.com/argoproj/argo-cd/commit/fbb0b99b1ac3361b253052bd30259fa43a520945", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/argoproj/argo-cd/security/advisories/GHSA-3jfq-742w-xg8j", "source": "security-advisories@github.com", "tags": ["Vendor Advisory"]}]}, "github_commit_url": "https://github.com/argoproj/argo-cd/commit/fbb0b99b1ac3361b253052bd30259fa43a520945"}}
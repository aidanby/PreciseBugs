{"buggy_code": ["\"\"\"Fork of urllib2.\n\nWhen reading this, don't assume that all code in here is reachable.  Code in\nthe rest of mechanize may be used instead.\n\nCopyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009 Python\nSoftware Foundation; All Rights Reserved\n\nCopyright 2002-2009 John J Lee <jjl@pobox.com>\n\nThis code is free software; you can redistribute it and/or modify it\nunder the terms of the BSD or ZPL 2.1 licenses (see the file\nLICENSE included with the distribution).\n\n\"\"\"\n\n# XXX issues:\n# If an authentication error handler that tries to perform\n# authentication for some reason but fails, how should the error be\n# signalled?  The client needs to know the HTTP error code.  But if\n# the handler knows that the problem was, e.g., that it didn't know\n# that hash algo that requested in the challenge, it would be good to\n# pass that information along to the client, too.\n# ftp errors aren't handled cleanly\n# check digest against correct (i.e. non-apache) implementation\n\n# Possible extensions:\n# complex proxies  XXX not sure what exactly was meant by this\n# abstract factory for opener\n\nfrom __future__ import absolute_import\n\nimport base64\nimport bisect\nimport copy\nimport hashlib\nimport logging\nimport os\nimport platform\nimport posixpath\nimport re\nimport socket\nimport sys\nimport time\nfrom collections import OrderedDict\nfrom functools import partial\nfrom io import BufferedReader, BytesIO\n\nfrom . import _rfc3986\nfrom ._clientcookie import CookieJar\nfrom ._headersutil import normalize_header_name\nfrom ._response import closeable_response\nfrom .polyglot import (HTTPConnection, HTTPError, HTTPSConnection, URLError,\n                       as_unicode, create_response_info, ftpwrapper,\n                       getproxies, is_class, is_mapping, is_py2, is_string,\n                       iteritems, map, raise_with_traceback, splitattr,\n                       splitpasswd, splitport, splittype, splituser,\n                       splitvalue, unquote, unwrap, url2pathname,\n                       urllib_proxy_bypass, urllib_splithost, urlparse,\n                       urlsplit, urlunparse)\n\n\ndef sha1_digest(data):\n    if not isinstance(data, bytes):\n        data = data.encode('utf-8')\n    return hashlib.sha1(data).hexdigest()\n\n\ndef md5_digest(data):\n    if not isinstance(data, bytes):\n        data = data.encode('utf-8')\n    return hashlib.md5(data).hexdigest()\n\n\nif platform.python_implementation() == 'PyPy':\n    def create_readline_wrapper(fh):\n        fh.recv = fh.read\n        if not hasattr(fh, '_drop'):\n            fh._drop = lambda: None\n            fh._reuse = lambda: None\n        return socket._fileobject(fh, close=True)\nelse:\n    def create_readline_wrapper(fh):\n        fh.recv = fh.read\n        if is_py2:\n            ans = socket._fileobject(fh, close=True)\n        else:\n            fh.recv_into = fh.readinto\n            fh._decref_socketios = lambda: None\n            ans = BufferedReader(socket.SocketIO(fh, 'r'))\n        return ans\n\n\nsplithost = urllib_splithost\n\n\n# used in User-Agent header sent\n__version__ = sys.version[:3]\n\n_opener = None\n\n\ndef urlopen(url, data=None):\n    global _opener\n    if _opener is None:\n        _opener = build_opener()\n    return _opener._open(url, data)\n\n\ndef install_opener(opener):\n    global _opener\n    _opener = opener\n\n\n# copied from cookielib.py\n_cut_port_re = re.compile(r\":\\d+$\")\n\n\ndef request_host(request):\n    \"\"\"Return request-host, as defined by RFC 2965.\n\n    Variation from RFC: returned value is lowercased, for convenient\n    comparison.\n\n    \"\"\"\n    url = request.get_full_url()\n    host = urlparse(url)[1]\n    if host == \"\":\n        host = request.get_header(\"Host\", \"\")\n\n    # remove port, if present\n    host = _cut_port_re.sub(\"\", host, 1)\n    return host.lower()\n\n\nPERCENT_RE = re.compile(b\"%[a-fA-F0-9]{2}\")\nZONE_ID_CHARS = set(bytearray(\n    b\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\" b\"abcdefghijklmnopqrstuvwxyz\" b\"0123456789._!-\"\n))\nUSERINFO_CHARS = ZONE_ID_CHARS | set(bytearray(b\"$&'()*+,;=:\"))\nPATH_CHARS = USERINFO_CHARS | set(bytearray(b'@/'))\nQUERY_CHARS = FRAGMENT_CHARS = PATH_CHARS | {ord(b\"?\")}\n\n\ndef fix_invalid_bytes_in_url_component(component, allowed_chars=PATH_CHARS):\n    if not component:\n        return component\n    is_bytes = isinstance(component, bytes)\n    if not is_bytes:\n        component = component.encode('utf-8', 'surrogatepass')\n    percent_encodings = PERCENT_RE.findall(component)\n    for enc in percent_encodings:\n        if not enc.isupper():\n            component = component.replace(enc, enc.upper())\n    is_percent_encoded = len(percent_encodings) == component.count(b\"%\")\n    encoded_component = bytearray()\n    percent = ord('%')\n    for byte_ord in bytearray(component):\n        if (is_percent_encoded and byte_ord == percent) or (byte_ord < 128 and byte_ord in allowed_chars):\n            encoded_component.append(byte_ord)\n            continue\n        encoded_component.extend(b\"%\" + (hex(byte_ord)[2:].encode().zfill(2).upper()))\n    encoded_component = bytes(encoded_component)\n    if not is_bytes:\n        encoded_component = encoded_component.decode('utf-8')\n    return encoded_component\n\n\ndef normalize_url(url):\n    parsed = urlparse(url)\n    netloc = parsed.netloc\n    if not isinstance(netloc, bytes) and netloc:\n        def safe_encode(label):\n            try:\n                return label.encode('idna').decode('ascii')\n            except ValueError:\n                return label.encode('ascii', 'replace').decode('ascii')\n        netloc = u'.'.join(map(safe_encode, netloc.split(u'.')))\n\n    return urlunparse(parsed._replace(\n        path=fix_invalid_bytes_in_url_component(parsed.path), netloc=netloc,\n        query=fix_invalid_bytes_in_url_component(parsed.query, QUERY_CHARS),\n        fragment=fix_invalid_bytes_in_url_component(parsed.fragment, FRAGMENT_CHARS),\n    ))\n\n\nclass Request:\n\n    def __init__(self, url, data=None, headers={},\n                 origin_req_host=None, unverifiable=False, method=None):\n        # unwrap('<URL:type://host/path>') --> 'type://host/path'\n        self.__original = normalize_url(unwrap(url))\n        self.type = None\n        self._method = method and str(method)\n        # self.__r_type is what's left after doing the splittype\n        self.host = None\n        self.port = None\n        self._tunnel_host = None\n        self.data = data\n        self.headers = OrderedDict()\n        for key, value in iteritems(headers):\n            self.add_header(key, value)\n        self.unredirected_hdrs = OrderedDict()\n        if origin_req_host is None:\n            origin_req_host = request_host(self)\n        self.origin_req_host = origin_req_host\n        self.unverifiable = unverifiable\n        try:\n            self.get_host()  # in py3 cookiejar expect self.host to be not None\n        except Exception:\n            self.host = None\n\n    def __getattr__(self, attr):\n        # XXX this is a fallback mechanism to guard against these\n        # methods getting called in a non-standard order.  this may be\n        # too complicated and/or unnecessary.\n        # XXX should the __r_XXX attributes be public?\n        if attr[:12] == '_Request__r_':\n            name = attr[12:]\n            if hasattr(Request, 'get_' + name):\n                getattr(self, 'get_' + name)()\n                return getattr(self, attr)\n        raise AttributeError(attr)\n\n    def get_method(self):\n        ' The method used for HTTP requests '\n        if self._method is None:\n            return \"POST\" if self.has_data() else 'GET'\n        return self._method\n\n    # XXX these helper methods are lame\n\n    def set_data(self, data):\n        ' Set the data (a bytestring) to be sent with this request '\n        self.data = data\n    add_data = set_data\n\n    def has_data(self):\n        ' True iff there is some data to be sent with this request '\n        return self.data is not None\n\n    def get_data(self):\n        ' The data to be sent with this request '\n        return self.data\n\n    def get_full_url(self):\n        return self.__original\n\n    @property\n    def full_url(self):\n        # In python 3 this is a deleteable and settable property, which when\n        # deleted gets set to None. But this interface does not seem to be used\n        # by any stdlib code, so this should be sufficient.\n        return self.__original\n\n    def get_type(self):\n        if self.type is None:\n            self.type, self.__r_type = splittype(self.__original)\n            if self.type is None:\n                raise ValueError(\"unknown url type: %s\" % self.__original)\n        return self.type\n\n    def get_host(self):\n        if self.host is None:\n            self.host, self.__r_host = splithost(self.__r_type)\n            if self.host:\n                self.host = unquote(self.host)\n        return self.host\n\n    def get_selector(self):\n        scheme, authority, path, query, fragment = _rfc3986.urlsplit(\n            self.__r_host)\n        if path == \"\":\n            path = \"/\"  # RFC 2616, section 3.2.2\n        fragment = None  # RFC 3986, section 3.5\n        return _rfc3986.urlunsplit([scheme, authority, path, query, fragment])\n\n    def set_proxy(self, host, type):\n        orig_host = self.get_host()\n        if self.get_type() == 'https' and not self._tunnel_host:\n            self._tunnel_host = orig_host\n        else:\n            self.type = type\n            self.__r_host = self.__original\n\n        self.host = host\n\n    def has_proxy(self):\n        \"\"\"Private method.\"\"\"\n        # has non-HTTPS proxy\n        return self.__r_host == self.__original\n\n    def get_origin_req_host(self):\n        return self.origin_req_host\n\n    def is_unverifiable(self):\n        return self.unverifiable\n\n    def add_header(self, key, val=None):\n        ''' Add the specified header, replacing existing one, if needed. If val\n        is None, remove the header. '''\n        # useful for something like authentication\n        key = normalize_header_name(key)\n        if val is None:\n            self.headers.pop(key, None)\n        else:\n            self.headers[key] = val\n\n    def add_unredirected_header(self, key, val):\n        ''' Same as :meth:`add_header()` except that this header will not\n        be sent for redirected requests. '''\n        key = normalize_header_name(key)\n        if val is None:\n            self.unredirected_hdrs.pop(key, None)\n        else:\n            self.unredirected_hdrs[key] = val\n\n    def has_header(self, header_name):\n        ''' Check if the specified header is present '''\n        header_name = normalize_header_name(header_name)\n        return (header_name in self.headers or\n                header_name in self.unredirected_hdrs)\n\n    def get_header(self, header_name, default=None):\n        ''' Get the value of the specified header. If absent, return `default`\n        '''\n        header_name = normalize_header_name(header_name)\n        return self.headers.get(\n            header_name,\n            self.unredirected_hdrs.get(header_name, default))\n\n    def header_items(self):\n        ''' Get a copy of all headers for this request as a list of 2-tuples\n        '''\n        hdrs = self.unredirected_hdrs.copy()\n        hdrs.update(self.headers)\n        return list(iteritems(hdrs))\n\n\nclass OpenerDirector(object):\n\n    def __init__(self):\n        client_version = \"Python-urllib/%s\" % __version__\n        self.addheaders = [('User-agent', client_version)]\n        self.finalize_request_headers = None\n        # manage the individual handlers\n        self.handlers = []\n        self.handle_open = {}\n        self.handle_error = {}\n        self.process_response = {}\n        self.process_request = {}\n\n    def add_handler(self, handler):\n        if not hasattr(handler, \"add_parent\"):\n            raise TypeError(\"expected BaseHandler instance, got %r\" %\n                            type(handler))\n\n        added = False\n        for meth in dir(handler):\n            if meth in [\"redirect_request\", \"do_open\", \"proxy_open\"]:\n                # oops, coincidental match\n                continue\n\n            i = meth.find(\"_\")\n            protocol = meth[:i]\n            condition = meth[i + 1:]\n\n            if condition.startswith(\"error\"):\n                j = condition.find(\"_\") + i + 1\n                kind = meth[j + 1:]\n                try:\n                    kind = int(kind)\n                except ValueError:\n                    pass\n                lookup = self.handle_error.get(protocol, {})\n                self.handle_error[protocol] = lookup\n            elif condition == \"open\":\n                kind = protocol\n                lookup = self.handle_open\n            elif condition == \"response\":\n                kind = protocol\n                lookup = self.process_response\n            elif condition == \"request\":\n                kind = protocol\n                lookup = self.process_request\n            else:\n                continue\n\n            handlers = lookup.setdefault(kind, [])\n            if handlers:\n                bisect.insort(handlers, handler)\n            else:\n                handlers.append(handler)\n            added = True\n\n        if added:\n            # the handlers must work in an specific order, the order\n            # is specified in a Handler attribute\n            bisect.insort(self.handlers, handler)\n            handler.add_parent(self)\n\n    def close(self):\n        # Only exists for backwards compatibility.\n        pass\n\n    def _call_chain(self, chain, kind, meth_name, *args):\n        # Handlers raise an exception if no one else should try to handle\n        # the request, or return None if they can't but another handler\n        # could.  Otherwise, they return the response.\n        handlers = chain.get(kind, ())\n        for handler in handlers:\n            func = getattr(handler, meth_name)\n\n            result = func(*args)\n            if result is not None:\n                return result\n\n    def _open(self, req, data=None):\n        result = self._call_chain(self.handle_open, 'default',\n                                  'default_open', req)\n        if result:\n            return result\n\n        protocol = req.get_type()\n        result = self._call_chain(self.handle_open, protocol, protocol +\n                                  '_open', req)\n        if result:\n            return result\n\n        return self._call_chain(self.handle_open, 'unknown',\n                                'unknown_open', req)\n\n    def error(self, proto, *args):\n        if proto in ('http', 'https'):\n            # XXX http[s] protocols are special-cased\n            # https is not different than http\n            dict = self.handle_error['http']\n            proto = args[2]  # YUCK!\n            meth_name = 'http_error_%s' % proto\n            http_err = 1\n            orig_args = args\n        else:\n            dict = self.handle_error\n            meth_name = proto + '_error'\n            http_err = 0\n        args = (dict, proto, meth_name) + args\n        result = self._call_chain(*args)\n        if result:\n            return result\n\n        if http_err:\n            args = (dict, 'default', 'http_error_default') + orig_args\n            return self._call_chain(*args)\n\n# XXX probably also want an abstract factory that knows when it makes\n# sense to skip a superclass in favor of a subclass and when it might\n# make sense to include both\n\n\ndef build_opener(*handlers):\n    \"\"\"Create an opener object from a list of handlers.\n\n    The opener will use several default handlers, including support\n    for HTTP, FTP and when applicable, HTTPS.\n\n    If any of the handlers passed as arguments are subclasses of the\n    default handlers, the default handlers will not be used.\n    \"\"\"\n    opener = OpenerDirector()\n    default_classes = [ProxyHandler, UnknownHandler, HTTPHandler,\n                       HTTPDefaultErrorHandler, HTTPRedirectHandler,\n                       FTPHandler, FileHandler, HTTPErrorProcessor]\n    default_classes.append(HTTPSHandler)\n    skip = set()\n    for klass in default_classes:\n        for check in handlers:\n            if is_class(check):\n                if issubclass(check, klass):\n                    skip.add(klass)\n            elif isinstance(check, klass):\n                skip.add(klass)\n    for klass in skip:\n        default_classes.remove(klass)\n\n    for klass in default_classes:\n        opener.add_handler(klass())\n\n    for h in handlers:\n        if is_class(h):\n            h = h()\n        opener.add_handler(h)\n    return opener\n\n\nclass BaseHandler:\n    handler_order = 500\n\n    def add_parent(self, parent):\n        self.parent = parent\n\n    def close(self):\n        # Only exists for backwards compatibility\n        pass\n\n    def __lt__(self, other):\n        return self.handler_order < getattr(\n                other, 'handler_order', sys.maxsize)\n\n    def __copy__(self):\n        return self.__class__()\n\n\nclass HTTPErrorProcessor(BaseHandler):\n    \"\"\"Process HTTP error responses.\n\n    The purpose of this handler is to to allow other response processors a\n    look-in by removing the call to parent.error() from\n    AbstractHTTPHandler.\n\n    For non-2xx error codes, this just passes the job on to the\n    Handler.<proto>_error_<code> methods, via the OpenerDirector.error method.\n    Eventually, HTTPDefaultErrorHandler will raise an HTTPError if no other\n    handler handles the error.\n\n    \"\"\"\n    handler_order = 1000  # after all other processors\n\n    def http_response(self, request, response):\n        code, msg, hdrs = response.code, response.msg, response.info()\n\n        # According to RFC 2616, \"2xx\" code indicates that the client's\n        # request was successfully received, understood, and accepted.\n        if not (200 <= code < 300):\n            # hardcoded http is NOT a bug\n            response = self.parent.error(\n                'http', request, response, code, msg, hdrs)\n\n        return response\n\n    https_response = http_response\n\n\nclass HTTPDefaultErrorHandler(BaseHandler):\n\n    def http_error_default(self, req, fp, code, msg, hdrs):\n        # why these error methods took the code, msg, headers args in the first\n        # place rather than a response object, I don't know, but to avoid\n        # multiple wrapping, we're discarding them\n\n        if isinstance(fp, HTTPError):\n            response = fp\n        else:\n            response = HTTPError(\n                req.get_full_url(), code, msg, hdrs, fp)\n        assert code == response.code\n        assert msg == response.msg\n        assert hdrs == response.hdrs\n        raise response\n\n\nclass HTTPRedirectHandler(BaseHandler):\n    # maximum number of redirections to any single URL\n    # this is needed because of the state that cookies introduce\n    max_repeats = 4\n    # maximum total number of redirections (regardless of URL) before\n    # assuming we're in a loop\n    max_redirections = 10\n\n    # Implementation notes:\n\n    # To avoid the server sending us into an infinite loop, the request\n    # object needs to track what URLs we have already seen.  Do this by\n    # adding a handler-specific attribute to the Request object.  The value\n    # of the dict is used to count the number of times the same URL has\n    # been visited.  This is needed because visiting the same URL twice\n    # does not necessarily imply a loop, thanks to state introduced by\n    # cookies.\n\n    # Always unhandled redirection codes:\n    # 300 Multiple Choices: should not handle this here.\n    # 304 Not Modified: no need to handle here: only of interest to caches\n    #     that do conditional GETs\n    # 305 Use Proxy: probably not worth dealing with here\n    # 306 Unused: what was this for in the previous versions of protocol??\n\n    def redirect_request(self, req, fp, code, msg, headers, newurl):\n        \"\"\"Return a Request or None in response to a redirect.\n\n        This is called by the http_error_30x methods when a\n        redirection response is received.  If a redirection should\n        take place, return a new Request to allow http_error_30x to\n        perform the redirect.  Otherwise, raise HTTPError if no-one\n        else should try to handle this url.  Return None if you can't\n        but another Handler might.\n        \"\"\"\n        from ._request import Request\n        m = req.get_method()\n        if (code in (301, 302, 303, 307, \"refresh\") and m in (\"GET\", \"HEAD\")\n                or code in (301, 302, 303, \"refresh\") and m == \"POST\"):\n            # Strictly (according to RFC 2616), 301 or 302 in response\n            # to a POST MUST NOT cause a redirection without confirmation\n            # from the user (of urllib2, in this case).  In practice,\n            # essentially all clients do redirect in this case, so we do\n            # the same.\n            # TODO: really refresh redirections should be visiting; tricky to\n            # fix\n            new = Request(\n                newurl,\n                headers=req.headers,\n                origin_req_host=req.get_origin_req_host(),\n                unverifiable=True,\n                visit=False,\n                timeout=req.timeout)\n            new._origin_req = getattr(req, \"_origin_req\", req)\n            return new\n        else:\n            raise HTTPError(req.get_full_url(), code, msg, headers, fp)\n\n    def http_error_302(self, req, fp, code, msg, headers):\n        # Some servers (incorrectly) return multiple Location headers\n        # (so probably same goes for URI).  Use first header.\n        if 'location' in headers:\n            newurl = headers.getheaders('location')[0]\n        elif 'uri' in headers:\n            newurl = headers.getheaders('uri')[0]\n        else:\n            return\n        newurl = _rfc3986.clean_url(newurl)\n        newurl = _rfc3986.urljoin(req.get_full_url(), newurl)\n\n        # XXX Probably want to forget about the state of the current\n        # request, although that might interact poorly with other\n        # handlers that also use handler-specific request attributes\n        new = self.redirect_request(req, fp, code, msg, headers, newurl)\n        if new is None:\n            return\n\n        # loop detection\n        # .redirect_dict has a key url if url was previously visited.\n        if hasattr(req, 'redirect_dict'):\n            visited = new.redirect_dict = req.redirect_dict\n            if (visited.get(newurl, 0) >= self.max_repeats or\n                    len(visited) >= self.max_redirections):\n                raise HTTPError(req.get_full_url(), code,\n                                self.inf_msg + msg, headers, fp)\n        else:\n            visited = new.redirect_dict = req.redirect_dict = {}\n        visited[newurl] = visited.get(newurl, 0) + 1\n\n        # Don't close the fp until we are sure that we won't use it\n        # with HTTPError.\n        fp.read()\n        fp.close()\n\n        return self.parent.open(new)\n\n    http_error_301 = http_error_303 = http_error_307 = http_error_302\n    http_error_refresh = http_error_302\n\n    inf_msg = \"The HTTP server returned a redirect error that would \" \\\n              \"lead to an infinite loop.\\n\" \\\n              \"The last 30x error message was:\\n\"\n\n\ndef _parse_proxy(proxy):\n    \"\"\"Return (scheme, user, password, host/port) given a URL or an authority.\n\n    If a URL is supplied, it must have an authority (host:port) component.\n    According to RFC 3986, having an authority component means the URL must\n    have two slashes after the scheme:\n\n    >>> _parse_proxy('file:/ftp.example.com/')\n    Traceback (most recent call last):\n    ValueError: proxy URL with no authority: 'file:/ftp.example.com/'\n\n    The first three items of the returned tuple may be None.\n\n    Examples of authority parsing:\n\n    >>> _parse_proxy('proxy.example.com')\n    (None, None, None, 'proxy.example.com')\n    >>> _parse_proxy('proxy.example.com:3128')\n    (None, None, None, 'proxy.example.com:3128')\n\n    The authority component may optionally include userinfo (assumed to be\n    username:password):\n\n    >>> _parse_proxy('joe:password@proxy.example.com')\n    (None, 'joe', 'password', 'proxy.example.com')\n    >>> _parse_proxy('joe:password@proxy.example.com:3128')\n    (None, 'joe', 'password', 'proxy.example.com:3128')\n\n    Same examples, but with URLs instead:\n\n    >>> _parse_proxy('http://proxy.example.com/')\n    ('http', None, None, 'proxy.example.com')\n    >>> _parse_proxy('http://proxy.example.com:3128/')\n    ('http', None, None, 'proxy.example.com:3128')\n    >>> _parse_proxy('http://joe:password@proxy.example.com/')\n    ('http', 'joe', 'password', 'proxy.example.com')\n    >>> _parse_proxy('http://joe:password@proxy.example.com:3128')\n    ('http', 'joe', 'password', 'proxy.example.com:3128')\n\n    Everything after the authority is ignored:\n\n    >>> _parse_proxy('ftp://joe:password@proxy.example.com/rubbish:3128')\n    ('ftp', 'joe', 'password', 'proxy.example.com')\n\n    Test for no trailing '/' case:\n\n    >>> _parse_proxy('http://joe:password@proxy.example.com')\n    ('http', 'joe', 'password', 'proxy.example.com')\n\n    \"\"\"\n    scheme, r_scheme = splittype(proxy)\n    if not r_scheme.startswith(\"/\"):\n        # authority\n        scheme = None\n        authority = proxy\n    else:\n        # URL\n        if not r_scheme.startswith(\"//\"):\n            raise ValueError(\"proxy URL with no authority: %r\" % proxy)\n        # We have an authority, so for RFC 3986-compliant URLs (by ss 3.\n        # and 3.3.), path is empty or starts with '/'\n        end = r_scheme.find(\"/\", 2)\n        if end == -1:\n            end = None\n        authority = r_scheme[2:end]\n    userinfo, hostport = splituser(authority)\n    if userinfo is not None:\n        user, password = splitpasswd(userinfo)\n    else:\n        user = password = None\n    return scheme, user, password, hostport\n\n\nclass ProxyHandler(BaseHandler):\n    # Proxies must be in front\n    handler_order = 100\n\n    def __init__(self, proxies=None, proxy_bypass=None):\n        if proxies is None:\n            proxies = getproxies()\n\n        assert is_mapping(proxies), \"proxies must be a mapping\"\n        self.proxies = proxies\n        for type, url in iteritems(proxies):\n            setattr(self, '%s_open' % type,\n                    lambda r, proxy=url, type=type, meth=self.proxy_open:\n                    meth(r, proxy, type))\n        if proxy_bypass is None:\n            proxy_bypass = urllib_proxy_bypass\n        self._proxy_bypass = proxy_bypass\n\n    def proxy_open(self, req, proxy, type):\n        orig_type = req.get_type()\n        proxy_type, user, password, hostport = _parse_proxy(proxy)\n\n        if proxy_type is None:\n            proxy_type = orig_type\n\n        if req.get_host() and self._proxy_bypass(req.get_host()):\n            return None\n\n        if user and password:\n            user_pass = '%s:%s' % (unquote(user), unquote(password))\n            if not isinstance(user_pass, bytes):\n                user_pass = user_pass.encode('utf-8')\n            creds = base64.b64encode(user_pass).strip()\n            if isinstance(creds, bytes):\n                creds = creds.decode('ascii')\n            req.add_header('Proxy-authorization', 'Basic ' + creds)\n        hostport = unquote(hostport)\n        req.set_proxy(hostport, proxy_type)\n        if orig_type == proxy_type or orig_type == 'https':\n            # let other handlers take care of it\n            return None\n        else:\n            # need to start over, because the other handlers don't\n            # grok the proxy's URL type\n            # e.g. if we have a constructor arg proxies like so:\n            # {'http': 'ftp://proxy.example.com'}, we may end up turning\n            # a request for http://acme.example.com/a into one for\n            # ftp://proxy.example.com/a\n            return self.parent.open(req)\n\n    def __copy__(self):\n        return ProxyHandler(self.proxies.copy(), self._proxy_bypass)\n\n\nclass HTTPPasswordMgr:\n\n    def __init__(self):\n        self.passwd = {}\n\n    def add_password(self, realm, uri, user, passwd):\n        # uri could be a single URI or a sequence\n        if is_string(uri):\n            uri = [uri]\n        if realm not in self.passwd:\n            self.passwd[realm] = {}\n        for default_port in True, False:\n            reduced_uri = tuple(\n                [self.reduce_uri(u, default_port) for u in uri])\n            self.passwd[realm][reduced_uri] = (user, passwd)\n\n    def find_user_password(self, realm, authuri):\n        domains = self.passwd.get(realm, {})\n        for default_port in True, False:\n            reduced_authuri = self.reduce_uri(authuri, default_port)\n            for uris, authinfo in iteritems(domains):\n                for uri in uris:\n                    if self.is_suburi(uri, reduced_authuri):\n                        return authinfo\n        return None, None\n\n    def reduce_uri(self, uri, default_port=True):\n        \"\"\"Accept authority or URI and extract only the authority and path.\"\"\"\n        # note HTTP URLs do not have a userinfo component\n        parts = urlsplit(uri)\n        if parts[1]:\n            # URI\n            scheme = parts[0]\n            authority = parts[1]\n            path = parts[2] or '/'\n        else:\n            # host or host:port\n            scheme = None\n            authority = uri\n            path = '/'\n        host, port = splitport(authority)\n        if default_port and port is None and scheme is not None:\n            dport = {\"http\": 80,\n                     \"https\": 443,\n                     }.get(scheme)\n            if dport is not None:\n                authority = \"%s:%d\" % (host, dport)\n        return authority, path\n\n    def is_suburi(self, base, test):\n        \"\"\"Check if test is below base in a URI tree\n\n        Both args must be URIs in reduced form.\n        \"\"\"\n        if base == test:\n            return True\n        if base[0] != test[0]:\n            return False\n        common = posixpath.commonprefix((base[1], test[1]))\n        if len(common) == len(base[1]):\n            return True\n        return False\n\n    def __copy__(self):\n        ans = self.__class__()\n        ans.passwd = copy.deepcopy(self.passwd)\n        return ans\n\n\nclass HTTPPasswordMgrWithDefaultRealm(HTTPPasswordMgr):\n\n    def find_user_password(self, realm, authuri):\n        user, password = HTTPPasswordMgr.find_user_password(self, realm,\n                                                            authuri)\n        if user is not None:\n            return user, password\n        return HTTPPasswordMgr.find_user_password(self, None, authuri)\n\n\nclass AbstractBasicAuthHandler:\n\n    # XXX this allows for multiple auth-schemes, but will stupidly pick\n    # the last one with a realm specified.\n\n    # allow for double- and single-quoted realm values\n    # (single quotes are a violation of the RFC, but appear in the wild)\n    rx = re.compile('(?:.*,)*[ \\t]*([^ \\t]+)[ \\t]+'\n                    'realm=([\"\\'])(.*?)\\\\2', re.I)\n\n    # XXX could pre-emptively send auth info already accepted (RFC 2617,\n    # end of section 2, and section 1.2 immediately after \"credentials\"\n    # production).\n\n    def __init__(self, password_mgr=None):\n        if password_mgr is None:\n            password_mgr = HTTPPasswordMgr()\n        self.passwd = password_mgr\n        self.add_password = self.passwd.add_password\n\n    def http_error_auth_reqed(self, authreq, host, req, headers):\n        # host may be an authority (without userinfo) or a URL with an\n        # authority\n        # XXX could be multiple headers\n        authreq = headers.get(authreq, None)\n        if authreq:\n            mo = AbstractBasicAuthHandler.rx.search(authreq)\n            if mo:\n                scheme, quote, realm = mo.groups()\n                if scheme.lower() == 'basic':\n                    return self.retry_http_basic_auth(host, req, realm)\n\n    def retry_http_basic_auth(self, host, req, realm):\n        user, pw = self.passwd.find_user_password(realm, host)\n        if pw is not None:\n            raw = \"%s:%s\" % (user, pw)\n            auth = str('Basic %s' % base64.b64encode(\n                    raw.encode('utf-8')).strip().decode('ascii'))\n            if req.get_header(self.auth_header, None) == auth:\n                return None\n            newreq = copy.copy(req)\n            newreq.add_header(self.auth_header, auth)\n            newreq.visit = False\n            return self.parent.open(newreq)\n        else:\n            return None\n\n    def __copy__(self):\n        return self.__class__(self.passwd.__copy__())\n\n\nclass HTTPBasicAuthHandler(AbstractBasicAuthHandler, BaseHandler):\n\n    auth_header = 'Authorization'\n\n    def http_error_401(self, req, fp, code, msg, headers):\n        url = req.get_full_url()\n        return self.http_error_auth_reqed('www-authenticate',\n                                          url, req, headers)\n\n    def __copy__(self):\n        return AbstractBasicAuthHandler.__copy__(self)\n\n\nclass ProxyBasicAuthHandler(AbstractBasicAuthHandler, BaseHandler):\n\n    auth_header = 'Proxy-authorization'\n\n    def http_error_407(self, req, fp, code, msg, headers):\n        # http_error_auth_reqed requires that there is no userinfo component in\n        # authority.  Assume there isn't one, since urllib2 does not (and\n        # should not, RFC 3986 s. 3.2.1) support requests for URLs containing\n        # userinfo.\n        authority = req.get_host()\n        return self.http_error_auth_reqed('proxy-authenticate',\n                                          authority, req, headers)\n\n    def __copy__(self):\n        return AbstractBasicAuthHandler.__copy__(self)\n\n\nrandombytes = os.urandom\n\n\nclass AbstractDigestAuthHandler:\n    # Digest authentication is specified in RFC 2617.\n\n    # XXX The client does not inspect the Authentication-Info header\n    # in a successful response.\n\n    # XXX It should be possible to test this implementation against\n    # a mock server that just generates a static set of challenges.\n\n    # XXX qop=\"auth-int\" supports is shaky\n\n    def __init__(self, passwd=None):\n        if passwd is None:\n            passwd = HTTPPasswordMgr()\n        self.passwd = passwd\n        self.add_password = self.passwd.add_password\n        self.retried = 0\n        self.nonce_count = 0\n        self.last_nonce = None\n\n    def reset_retry_count(self):\n        self.retried = 0\n\n    def http_error_auth_reqed(self, auth_header, host, req, headers):\n        authreq = headers.get(auth_header, None)\n        if self.retried > 5:\n            # Don't fail endlessly - if we failed once, we'll probably\n            # fail a second time. Hm. Unless the Password Manager is\n            # prompting for the information. Crap. This isn't great\n            # but it's better than the current 'repeat until recursion\n            # depth exceeded' approach <wink>\n            raise HTTPError(req.get_full_url(), 401, \"digest auth failed\",\n                            headers, None)\n        else:\n            self.retried += 1\n        if authreq:\n            scheme = authreq.split()[0]\n            if scheme.lower() == 'digest':\n                return self.retry_http_digest_auth(req, authreq)\n\n    def retry_http_digest_auth(self, req, auth):\n        token, challenge = auth.split(' ', 1)\n        chal = parse_keqv_list(parse_http_list(challenge))\n        auth = self.get_authorization(req, chal)\n        if auth:\n            auth_val = 'Digest %s' % auth\n            if req.get_header(self.auth_header, None) == auth_val:\n                return None\n            newreq = copy.copy(req)\n            newreq.add_unredirected_header(self.auth_header, auth_val)\n            newreq.visit = False\n            return self.parent.open(newreq)\n\n    def get_cnonce(self, nonce):\n        # The cnonce-value is an opaque\n        # quoted string value provided by the client and used by both client\n        # and server to avoid chosen plaintext attacks, to provide mutual\n        # authentication, and to provide some message integrity protection.\n        # This isn't a fabulous effort, but it's probably Good Enough.\n        dig = sha1_digest(\"%s:%s:%s:%s\" % (self.nonce_count, nonce,\n                                           time.ctime(), randombytes(8)))\n        return dig[:16]\n\n    def get_authorization(self, req, chal):\n        try:\n            realm = chal['realm']\n            nonce = chal['nonce']\n            qop = chal.get('qop')\n            algorithm = chal.get('algorithm', 'MD5')\n            # mod_digest doesn't send an opaque, even though it isn't\n            # supposed to be optional\n            opaque = chal.get('opaque', None)\n        except KeyError:\n            return None\n\n        H, KD = self.get_algorithm_impls(algorithm)\n        if H is None:\n            return None\n\n        user, pw = self.passwd.find_user_password(realm, req.get_full_url())\n        if user is None:\n            return None\n\n        # XXX not implemented yet\n        if req.has_data():\n            entdig = self.get_entity_digest(req.get_data(), chal)\n        else:\n            entdig = None\n\n        A1 = \"%s:%s:%s\" % (user, realm, pw)\n        A2 = \"%s:%s\" % (req.get_method(),\n                        # XXX selector: what about proxies and full urls\n                        req.get_selector())\n        if qop == 'auth':\n            if nonce == self.last_nonce:\n                self.nonce_count += 1\n            else:\n                self.nonce_count = 1\n                self.last_nonce = nonce\n\n            ncvalue = '%08x' % self.nonce_count\n            cnonce = self.get_cnonce(nonce)\n            noncebit = \"%s:%s:%s:%s:%s\" % (nonce, ncvalue, cnonce, qop, H(A2))\n            respdig = KD(H(A1), noncebit)\n        elif qop is None:\n            respdig = KD(H(A1), \"%s:%s\" % (nonce, H(A2)))\n        else:\n            # XXX handle auth-int.\n            logger = logging.getLogger(\"mechanize.auth\")\n            logger.info(\"digest auth auth-int qop is not supported, not \"\n                        \"handling digest authentication\")\n            return None\n\n        # XXX should the partial digests be encoded too?\n\n        base = 'username=\"%s\", realm=\"%s\", nonce=\"%s\", uri=\"%s\", ' \\\n               'response=\"%s\"' % (user, realm, nonce, req.get_selector(),\n                                  respdig)\n        if opaque:\n            base += ', opaque=\"%s\"' % opaque\n        if entdig:\n            base += ', digest=\"%s\"' % entdig\n        base += ', algorithm=\"%s\"' % algorithm\n        if qop:\n            base += ', qop=auth, nc=%s, cnonce=\"%s\"' % (ncvalue, cnonce)\n        return base\n\n    def get_algorithm_impls(self, algorithm):\n        # algorithm should be case-insensitive according to RFC2617\n        algorithm = algorithm.upper()\n        if algorithm == 'MD5':\n            H = md5_digest\n        elif algorithm == 'SHA':\n            H = sha1_digest\n        # XXX MD5-sess\n        KD = lambda s, d: H(\"%s:%s\" % (s, d))  # noqa\n        return H, KD\n\n    def get_entity_digest(self, data, chal):\n        # XXX not implemented yet\n        return None\n\n    def __copy__(self):\n        return self.__class__(self.passwd.__copy__())\n\n\nclass HTTPDigestAuthHandler(BaseHandler, AbstractDigestAuthHandler):\n    \"\"\"An authentication protocol defined by RFC 2069\n\n    Digest authentication improves on basic authentication because it\n    does not transmit passwords in the clear.\n    \"\"\"\n\n    auth_header = 'Authorization'\n    handler_order = 490  # before Basic auth\n\n    def http_error_401(self, req, fp, code, msg, headers):\n        host = urlparse(req.get_full_url())[1]\n        retry = self.http_error_auth_reqed('www-authenticate',\n                                           host, req, headers)\n        self.reset_retry_count()\n        return retry\n\n    def __copy__(self):\n        return AbstractDigestAuthHandler.__copy__(self)\n\n\nclass ProxyDigestAuthHandler(BaseHandler, AbstractDigestAuthHandler):\n\n    auth_header = 'Proxy-Authorization'\n    handler_order = 490  # before Basic auth\n\n    def http_error_407(self, req, fp, code, msg, headers):\n        host = req.get_host()\n        retry = self.http_error_auth_reqed('proxy-authenticate',\n                                           host, req, headers)\n        self.reset_retry_count()\n        return retry\n\n    def __copy__(self):\n        return AbstractDigestAuthHandler.__copy__(self)\n\n\nclass AbstractHTTPHandler(BaseHandler):\n\n    def __init__(self, debuglevel=0):\n        self._debuglevel = debuglevel\n\n    def set_http_debuglevel(self, level):\n        self._debuglevel = level\n\n    def do_request_(self, request):\n        host = request.get_host()\n        if not host:\n            raise URLError('no host given')\n\n        if request.has_data():  # POST\n            data = request.get_data()\n            if not request.has_header('Content-type'):\n                request.add_unredirected_header(\n                    'Content-type',\n                    'application/x-www-form-urlencoded')\n            if not request.has_header('Content-length'):\n                request.add_unredirected_header(\n                    'Content-length', '%d' % len(data))\n\n        sel_host = host\n        if request.has_proxy():\n            scheme, sel = splittype(request.get_selector())\n            sel_host, sel_path = splithost(sel)\n\n        for name, value in self.parent.addheaders:\n            name = name.capitalize()\n            if not request.has_header(name):\n                request.add_unredirected_header(name, value)\n        if not request.has_header('Host'):\n            request.add_unredirected_header('Host', sel_host)\n\n        return request\n\n    def do_open(self, http_class, req):\n        \"\"\"Return an addinfourl object for the request, using http_class.\n\n        http_class must implement the HTTPConnection API from httplib.\n        The addinfourl return value is a file-like object.  It also\n        has methods and attributes including:\n            - info(): return a HTTPMessage object for the headers\n            - geturl(): return the original request URL\n            - code: HTTP status code\n        \"\"\"\n        host_port = req.get_host()\n        if not host_port:\n            raise URLError('no host given')\n\n        h = http_class(host_port, timeout=req.timeout)\n        h.set_debuglevel(self._debuglevel)\n\n        headers = OrderedDict(req.headers)\n        for key, val in iteritems(req.unredirected_hdrs):\n            headers[key] = val\n        # We want to make an HTTP/1.1 request, but the addinfourl\n        # class isn't prepared to deal with a persistent connection.\n        # It will try to read all remaining data from the socket,\n        # which will block while the server waits for the next request.\n        # So make sure the connection gets closed after the (only)\n        # request.\n        headers[\"Connection\"] = \"close\"\n        # httplib in python 2 needs str() not unicode() for all request\n        # parameters\n        if is_py2:\n            headers = OrderedDict(\n                    (str(name.title()), str(val))\n                    for name, val in iteritems(headers))\n        else:\n            headers = OrderedDict(\n                    (as_unicode(name, 'iso-8859-1').title(),\n                     as_unicode(val, 'iso-8859-1'))\n                    for name, val in iteritems(headers))\n\n        if req._tunnel_host:\n            set_tunnel = h.set_tunnel if hasattr(\n                h, \"set_tunnel\") else h._set_tunnel\n            tunnel_headers = {}\n            proxy_auth_hdr = \"Proxy-Authorization\"\n            if proxy_auth_hdr in headers:\n                tunnel_headers[proxy_auth_hdr] = headers[proxy_auth_hdr]\n                # Proxy-Authorization should not be sent to origin server.\n                del headers[proxy_auth_hdr]\n            set_tunnel(req._tunnel_host, headers=tunnel_headers)\n\n        if self.parent.finalize_request_headers is not None:\n            self.parent.finalize_request_headers(req, headers)\n\n        try:\n            h.request(str(req.get_method()), str(req.get_selector()), req.data,\n                      headers)\n            r = h.getresponse()\n        except socket.error as err:  # XXX what error?\n            raise URLError(err)\n\n        # Pick apart the HTTPResponse object to get the addinfourl\n        # object initialized properly.\n        fp = create_readline_wrapper(r)\n\n        resp = closeable_response(\n            fp, r.msg, req.get_full_url(), r.status, r.reason,\n            getattr(r, 'version', None))\n        return resp\n\n    def __copy__(self):\n        return self.__class__(self._debuglevel)\n\n\nclass HTTPHandler(AbstractHTTPHandler):\n\n    def http_open(self, req):\n        return self.do_open(HTTPConnection, req)\n\n    http_request = AbstractHTTPHandler.do_request_\n\n\nclass HTTPSHandler(AbstractHTTPHandler):\n\n    def __init__(self, client_cert_manager=None):\n        AbstractHTTPHandler.__init__(self)\n        self.client_cert_manager = client_cert_manager\n        self.ssl_context = None\n\n    def https_open(self, req):\n        key_file = cert_file = None\n        if self.client_cert_manager is not None:\n            key_file, cert_file = self.client_cert_manager.find_key_cert(\n                req.get_full_url())\n        if self.ssl_context is None:\n            conn_factory = partial(\n                HTTPSConnection, key_file=key_file,\n                cert_file=cert_file)\n        else:\n            conn_factory = partial(\n                HTTPSConnection, key_file=key_file,\n                cert_file=cert_file, context=self.ssl_context)\n        return self.do_open(conn_factory, req)\n\n    https_request = AbstractHTTPHandler.do_request_\n\n    def __copy__(self):\n        ans = self.__class__(self.client_cert_manager)\n        ans._debuglevel = self._debuglevel\n        ans.ssl_context = self.ssl_context\n        return ans\n\n\nclass HTTPCookieProcessor(BaseHandler):\n    \"\"\"Handle HTTP cookies.\n\n    Public attributes:\n\n    cookiejar: CookieJar instance\n\n    \"\"\"\n\n    def __init__(self, cookiejar=None):\n        if cookiejar is None:\n            cookiejar = CookieJar()\n        self.cookiejar = cookiejar\n\n    def http_request(self, request):\n        self.cookiejar.add_cookie_header(request)\n        return request\n\n    def http_response(self, request, response):\n        self.cookiejar.extract_cookies(response, request)\n        return response\n\n    def __copy__(self):\n        return self.__class__(self.cookiejar)\n\n    https_request = http_request\n    https_response = http_response\n\n\nclass UnknownHandler(BaseHandler):\n\n    def unknown_open(self, req):\n        type = req.get_type()\n        raise URLError('unknown url type: %s' % type)\n\n\ndef parse_keqv_list(ln):\n    \"\"\"Parse list of key=value strings where keys are not duplicated.\"\"\"\n    parsed = {}\n    for elt in ln:\n        k, v = elt.split('=', 1)\n        if v[0:1] == '\"' and v[-1:] == '\"':\n            v = v[1:-1]\n        parsed[k] = v\n    return parsed\n\n\ndef parse_http_list(s):\n    \"\"\"Parse lists as described by RFC 2068 Section 2.\n\n    In particular, parse comma-separated lists where the elements of\n    the list may include quoted-strings.  A quoted-string could\n    contain a comma.  A non-quoted string could have quotes in the\n    middle.  Neither commas nor quotes count if they are escaped.\n    Only double-quotes count, not single-quotes.\n    \"\"\"\n    res = []\n    part = ''\n\n    escape = quote = False\n    for cur in s:\n        if escape:\n            part += cur\n            escape = False\n            continue\n        if quote:\n            if cur == '\\\\':\n                escape = True\n                continue\n            elif cur == '\"':\n                quote = False\n            part += cur\n            continue\n\n        if cur == ',':\n            res.append(part)\n            part = ''\n            continue\n\n        if cur == '\"':\n            quote = True\n\n        part += cur\n\n    # append last part\n    if part:\n        res.append(part)\n\n    return list(filter(None, (part_.strip() for part_ in res)))\n\n\nclass FileHandler(BaseHandler):\n    # Use local file or FTP depending on form of URL\n\n    def file_open(self, req):\n        url = req.get_selector()\n        if url[:2] == '//' and url[2:3] != '/':\n            req.type = 'ftp'\n            return self.parent.open(req)\n        else:\n            return self.open_local_file(req)\n\n    # names for the localhost\n    names = None\n\n    def get_names(self):\n        if FileHandler.names is None:\n            try:\n                FileHandler.names = (socket.gethostbyname('localhost'),\n                                     socket.gethostbyname(socket.gethostname())\n                                     )\n            except socket.gaierror:\n                FileHandler.names = (socket.gethostbyname('localhost'),)\n        return FileHandler.names\n\n    # not entirely sure what the rules are here\n    def open_local_file(self, req):\n        import email.utils as emailutils\n        import mimetypes\n        host = req.get_host()\n        file = req.get_selector()\n        try:\n            localfile = url2pathname(file)\n        except IOError as err:\n            # url2pathname raises this on windows for bad urls\n            raise URLError(err)\n        try:\n            stats = os.stat(localfile)\n            size = stats.st_size\n            modified = emailutils.formatdate(stats.st_mtime, usegmt=True)\n            mtype = mimetypes.guess_type(file)[0]\n            headers = create_response_info(BytesIO(\n                ('Content-type: %s\\nContent-length: %d\\nLast-modified: %s\\n' %\n                    (mtype or 'text/plain', size, modified)).encode(\n                        'iso-8859-1')))\n            if host:\n                host, port = splitport(host)\n            if not host or (\n                    not port and socket.gethostbyname(host) in self.get_names()\n            ):\n                fp = open(localfile, 'rb')\n                return closeable_response(fp, headers, 'file:' + file)\n        except OSError as msg:\n            # urllib2 users shouldn't expect OSErrors coming from urlopen()\n            raise URLError(msg)\n        raise URLError('file not on local host')\n\n\nclass FTPHandler(BaseHandler):\n\n    def ftp_open(self, req):\n        import ftplib\n        import mimetypes\n        host = req.get_host()\n        if not host:\n            raise URLError('ftp error: no host given')\n        host, port = splitport(host)\n        if port is None:\n            port = ftplib.FTP_PORT\n        else:\n            port = int(port)\n\n        # username/password handling\n        user, host = splituser(host)\n        if user:\n            user, passwd = splitpasswd(user)\n        else:\n            passwd = None\n        host = unquote(host)\n        user = unquote(user or '')\n        passwd = unquote(passwd or '')\n\n        try:\n            host = socket.gethostbyname(host)\n        except socket.error as msg:\n            raise URLError(msg)\n        path, attrs = splitattr(req.get_selector())\n        dirs = path.split('/')\n        dirs = list(map(unquote, dirs))\n        dirs, file = dirs[:-1], dirs[-1]\n        if dirs and not dirs[0]:\n            dirs = dirs[1:]\n        try:\n            fw = self.connect_ftp(user, passwd, host, port, dirs, req.timeout)\n            type = file and 'I' or 'D'\n            for attr in attrs:\n                attr, value = splitvalue(attr)\n                if attr.lower() == 'type' and \\\n                   value in ('a', 'A', 'i', 'I', 'd', 'D'):\n                    type = value.upper()\n            fp, retrlen = fw.retrfile(file, type)\n            headers = \"\"\n            mtype = mimetypes.guess_type(req.get_full_url())[0]\n            if mtype:\n                headers += \"Content-type: %s\\n\" % mtype\n            if retrlen is not None and retrlen >= 0:\n                headers += \"Content-length: %d\\n\" % retrlen\n            sf = BytesIO(headers.encode('iso-8859-1'))\n            headers = create_response_info(sf)\n            return closeable_response(fp, headers, req.get_full_url())\n        except ftplib.all_errors as msg:\n            raise_with_traceback(URLError('ftp error: %s' % msg))\n\n    def connect_ftp(self, user, passwd, host, port, dirs, timeout):\n        try:\n            fw = ftpwrapper(user, passwd, host, port, dirs, timeout)\n        except TypeError:\n            # Python < 2.6, no per-connection timeout support\n            fw = ftpwrapper(user, passwd, host, port, dirs)\n# fw.ftp.set_debuglevel(1)\n        return fw\n\n\nclass CacheFTPHandler(FTPHandler):\n    # XXX would be nice to have pluggable cache strategies\n    # XXX this stuff is definitely not thread safe\n\n    def __init__(self):\n        self.cache = {}\n        self.timeout = {}\n        self.soonest = 0\n        self.delay = 60\n        self.max_conns = 16\n\n    def setTimeout(self, t):\n        self.delay = t\n\n    def setMaxConns(self, m):\n        self.max_conns = m\n\n    def connect_ftp(self, user, passwd, host, port, dirs, timeout):\n        key = user, host, port, '/'.join(dirs), timeout\n        if key in self.cache:\n            self.timeout[key] = time.time() + self.delay\n        else:\n            self.cache[key] = ftpwrapper(\n                user, passwd, host, port, dirs, timeout)\n            self.timeout[key] = time.time() + self.delay\n        self.check_cache()\n        return self.cache[key]\n\n    def check_cache(self):\n        # first check for old ones\n        t = time.time()\n        if self.soonest <= t:\n            for k, v in iteritems(self.timeout):\n                if v < t:\n                    self.cache[k].close()\n                    del self.cache[k]\n                    del self.timeout[k]\n        self.soonest = min(self.timeout.values())\n\n        # then check the size\n        if len(self.cache) == self.max_conns:\n            for k, v in iteritems(self.timeout):\n                if v == self.soonest:\n                    del self.cache[k]\n                    del self.timeout[k]\n                    break\n            self.soonest = min(self.timeout.values())\n", "# vim:fileencoding=utf-8\n\"\"\"Tests for urllib2-level functionality.\n\nThis is urllib2's tests (most of which came from mechanize originally), plus\nsome extra tests added, and modifications from bug fixes and feature additions\nto mechanize.\n\"\"\"\n\n# TODO:\n# Request\n# CacheFTPHandler (hard to write)\n# parse_keqv_list, parse_http_list\n\nimport os\nimport sys\nimport unittest\nfrom io import BytesIO\n\nimport mechanize\n\nfrom mechanize._response import test_response\nfrom mechanize import HTTPRedirectHandler, \\\n    HTTPEquivProcessor, HTTPRefreshProcessor, \\\n    HTTPCookieProcessor, HTTPRefererProcessor, \\\n    HTTPErrorProcessor, HTTPHandler\nfrom mechanize import OpenerDirector, build_opener, Request\nfrom mechanize._urllib2_fork import AbstractHTTPHandler, normalize_url\nfrom mechanize._util import write_file\n\nimport mechanize._response\nimport mechanize._sockettimeout as _sockettimeout\nimport mechanize._testcase\nimport mechanize._urllib2_fork\nfrom mechanize._mechanize import sanepathname2url\nfrom mechanize.polyglot import create_response_info, iteritems\n\n# from logging import getLogger, DEBUG\n# l = getLogger(\"mechanize\")\n# l.setLevel(DEBUG)\n\n\nclass TrivialTests(mechanize._testcase.TestCase):\n    def test_trivial(self):\n        # A couple trivial tests\n\n        self.assertRaises(ValueError, mechanize.urlopen, 'bogus url')\n\n        fname = os.path.join(self.make_temp_dir(), \"test.txt\")\n        data = b'data'\n        write_file(fname, data)\n        if os.sep == '\\\\':\n            fname = '/' + fname\n        file_url = \"file://\" + fname\n        try:\n            f = mechanize.urlopen(file_url)\n        except Exception as e:\n            raise ValueError('Failed to open URL: {} for fname: {} with error: {}'.format(file_url, fname, e))\n        self.assertEqual(f.read(), data)\n        f.close()\n\n    def test_parse_http_list(self):\n        tests = [('a,b,c', ['a', 'b', 'c']), (\n            'path\"o,l\"og\"i\"cal, example', ['path\"o,l\"og\"i\"cal', 'example']),\n                 ('a, b, \"c\", \"d\", \"e,f\", g, h',\n                  ['a', 'b', '\"c\"', '\"d\"', '\"e,f\"', 'g',\n                   'h']), ('a=\"b\\\\\"c\", d=\"e\\\\,f\", g=\"h\\\\\\\\i\"',\n                           ['a=\"b\"c\"', 'd=\"e,f\"', 'g=\"h\\\\i\"'])]\n        for string, list in tests:\n            self.assertEqual(\n                mechanize._urllib2_fork.parse_http_list(string), list)\n\n\ndef test_request_headers_dict():\n    \"\"\"\n    The Request.headers dictionary is not a documented interface.  It should\n    stay that way, because the complete set of headers are only accessible\n    through the .get_header(), .has_header(), .header_items() interface.\n    However, .headers pre-dates those methods, and so real code will be using\n    the dictionary.\n\n    The introduction in 2.4 of those methods was a mistake for the same reason:\n    code that previously saw all (urllib2 user)-provided headers in .headers\n    now sees only a subset (and the function interface is ugly and incomplete).\n    A better change would have been to replace .headers dict with a dict\n    subclass (or UserDict.DictMixin instance?)  that preserved the .headers\n    interface and also provided access to the \"unredirected\" headers.  It's\n    probably too late to fix that, though.\n\n\n    Check .capitalize() case normalization:\n\n    >>> url = \"http://example.com\"\n    >>> Request(url, headers={\"Spam-eggs\": \"blah\"}).headers[\"Spam-eggs\"]\n    'blah'\n    >>> Request(url, headers={\"spam-EggS\": \"blah\"}).headers[\"Spam-eggs\"]\n    'blah'\n\n    Currently, Request(url, \"Spam-eggs\").headers[\"Spam-Eggs\"] raises KeyError,\n    but that could be changed in future.\n\n    \"\"\"\n\n\ndef test_request_headers_methods():\n    \"\"\"\n    Note the case normalization of header names here, to .capitalize()-case.\n    This should be preserved for backwards-compatibility.  (In the HTTP case,\n    normalization to .title()-case is done by urllib2 before sending headers to\n    httplib).\n\n    >>> url = \"http://example.com\"\n    >>> r = Request(url, headers={\"Spam-eggs\": \"blah\"})\n    >>> r.has_header(\"Spam-eggs\")\n    True\n    >>> r.header_items()\n    [('Spam-eggs', 'blah')]\n    >>> r.add_header(\"Foo-Bar\", \"baz\")\n    >>> items = r.header_items()\n    >>> items.sort()\n    >>> items\n    [('Foo-bar', 'baz'), ('Spam-eggs', 'blah')]\n\n    Note that e.g. r.has_header(\"spam-EggS\") is currently False, and\n    r.get_header(\"spam-EggS\") returns None, but that could be changed in\n    future.\n\n    >>> r.has_header(\"Not-there\")\n    False\n    >>> print r.get_header(\"Not-there\")\n    None\n    >>> r.get_header(\"Not-there\", \"default\")\n    'default'\n\n    \"\"\"\n\n\ndef test_password_manager(self):\n    \"\"\"\n    >>> mgr = mechanize.HTTPPasswordMgr()\n    >>> add = mgr.add_password\n    >>> add(\"Some Realm\", \"http://example.com/\", \"joe\", \"password\")\n    >>> add(\"Some Realm\", \"http://example.com/ni\", \"ni\", \"ni\")\n    >>> add(\"c\", \"http://example.com/foo\", \"foo\", \"ni\")\n    >>> add(\"c\", \"http://example.com/bar\", \"bar\", \"nini\")\n    >>> add(\"b\", \"http://example.com/\", \"first\", \"blah\")\n    >>> add(\"b\", \"http://example.com/\", \"second\", \"spam\")\n    >>> add(\"a\", \"http://example.com\", \"1\", \"a\")\n    >>> add(\"Some Realm\", \"http://c.example.com:3128\", \"3\", \"c\")\n    >>> add(\"Some Realm\", \"d.example.com\", \"4\", \"d\")\n    >>> add(\"Some Realm\", \"e.example.com:3128\", \"5\", \"e\")\n\n    >>> mgr.find_user_password(\"Some Realm\", \"example.com\")\n    ('joe', 'password')\n    >>> mgr.find_user_password(\"Some Realm\", \"http://example.com\")\n    ('joe', 'password')\n    >>> mgr.find_user_password(\"Some Realm\", \"http://example.com/\")\n    ('joe', 'password')\n    >>> mgr.find_user_password(\"Some Realm\", \"http://example.com/spam\")\n    ('joe', 'password')\n    >>> mgr.find_user_password(\"Some Realm\", \"http://example.com/spam/spam\")\n    ('joe', 'password')\n    >>> mgr.find_user_password(\"c\", \"http://example.com/foo\")\n    ('foo', 'ni')\n    >>> mgr.find_user_password(\"c\", \"http://example.com/bar\")\n    ('bar', 'nini')\n\n    Actually, this is really undefined ATM\n##     Currently, we use the highest-level path where more than one match:\n\n##     >>> mgr.find_user_password(\"Some Realm\", \"http://example.com/ni\")\n##     ('joe', 'password')\n\n    Use latest add_password() in case of conflict:\n\n    >>> mgr.find_user_password(\"b\", \"http://example.com/\")\n    ('second', 'spam')\n\n    No special relationship between a.example.com and example.com:\n\n    >>> mgr.find_user_password(\"a\", \"http://example.com/\")\n    ('1', 'a')\n    >>> mgr.find_user_password(\"a\", \"http://a.example.com/\")\n    (None, None)\n\n    Ports:\n\n    >>> mgr.find_user_password(\"Some Realm\", \"c.example.com\")\n    (None, None)\n    >>> mgr.find_user_password(\"Some Realm\", \"c.example.com:3128\")\n    ('3', 'c')\n    >>> mgr.find_user_password(\"Some Realm\", \"http://c.example.com:3128\")\n    ('3', 'c')\n    >>> mgr.find_user_password(\"Some Realm\", \"d.example.com\")\n    ('4', 'd')\n    >>> mgr.find_user_password(\"Some Realm\", \"e.example.com:3128\")\n    ('5', 'e')\n\n    \"\"\"\n    pass\n\n\ndef test_password_manager_default_port(self):\n    \"\"\"\n    >>> mgr = mechanize.HTTPPasswordMgr()\n    >>> add = mgr.add_password\n\n    The point to note here is that we can't guess the default port if there's\n    no scheme.  This applies to both add_password and find_user_password.\n\n    >>> add(\"f\", \"http://g.example.com:80\", \"10\", \"j\")\n    >>> add(\"g\", \"http://h.example.com\", \"11\", \"k\")\n    >>> add(\"h\", \"i.example.com:80\", \"12\", \"l\")\n    >>> add(\"i\", \"j.example.com\", \"13\", \"m\")\n    >>> mgr.find_user_password(\"f\", \"g.example.com:100\")\n    (None, None)\n    >>> mgr.find_user_password(\"f\", \"g.example.com:80\")\n    ('10', 'j')\n    >>> mgr.find_user_password(\"f\", \"g.example.com\")\n    (None, None)\n    >>> mgr.find_user_password(\"f\", \"http://g.example.com:100\")\n    (None, None)\n    >>> mgr.find_user_password(\"f\", \"http://g.example.com:80\")\n    ('10', 'j')\n    >>> mgr.find_user_password(\"f\", \"http://g.example.com\")\n    ('10', 'j')\n    >>> mgr.find_user_password(\"g\", \"h.example.com\")\n    ('11', 'k')\n    >>> mgr.find_user_password(\"g\", \"h.example.com:80\")\n    ('11', 'k')\n    >>> mgr.find_user_password(\"g\", \"http://h.example.com:80\")\n    ('11', 'k')\n    >>> mgr.find_user_password(\"h\", \"i.example.com\")\n    (None, None)\n    >>> mgr.find_user_password(\"h\", \"i.example.com:80\")\n    ('12', 'l')\n    >>> mgr.find_user_password(\"h\", \"http://i.example.com:80\")\n    ('12', 'l')\n    >>> mgr.find_user_password(\"i\", \"j.example.com\")\n    ('13', 'm')\n    >>> mgr.find_user_password(\"i\", \"j.example.com:80\")\n    (None, None)\n    >>> mgr.find_user_password(\"i\", \"http://j.example.com\")\n    ('13', 'm')\n    >>> mgr.find_user_password(\"i\", \"http://j.example.com:80\")\n    (None, None)\n\n    \"\"\"\n\n\nclass MockOpener:\n    addheaders = []\n    finalize_request_headers = None\n\n    def open(self,\n             req,\n             data=None,\n             timeout=_sockettimeout._GLOBAL_DEFAULT_TIMEOUT):\n        self.req, self.data, self.timeout = req, data, timeout\n\n    def error(self, proto, *args):\n        self.proto, self.args = proto, args\n\n\nclass MockFile:\n    def read(self, count=None):\n        pass\n\n    def readline(self, count=None):\n        pass\n\n    def close(self):\n        pass\n\n    def __iter__(self):\n        for i in ():\n            yield i\n\n\ndef http_message(mapping):\n    \"\"\"\n    >>> http_message({\"Content-Type\": \"text/html\"}).items()\n    [('content-type', 'text/html')]\n\n    \"\"\"\n    f = []\n    for kv in iteritems(mapping):\n        f.append(\"%s: %s\" % kv)\n    f.append(\"\")\n    msg = \"\\r\\n\".join(f)\n    if not isinstance(msg, bytes):\n        msg = msg.encode('iso-8859-1')\n    msg = create_response_info(BytesIO(msg))\n    return msg\n\n\nclass MockResponse(BytesIO):\n    def __init__(self, code, msg, headers, data, url=None):\n        if not isinstance(data, bytes):\n            data = data.encode('utf-8')\n        BytesIO.__init__(self, data)\n        self.code, self.msg, self.headers, self.url = code, msg, headers, url\n\n    def info(self):\n        return self.headers\n\n    def geturl(self):\n        return self.url\n\n\nclass MockCookieJar:\n    def add_cookie_header(self, request, unverifiable=False):\n        self.ach_req, self.ach_u = request, unverifiable\n\n    def extract_cookies(self, response, request, unverifiable=False):\n        self.ec_req, self.ec_r, self.ec_u = request, response, unverifiable\n\n\nclass FakeMethod:\n    def __init__(self, meth_name, action, handle):\n        self.meth_name = meth_name\n        self.handle = handle\n        self.action = action\n\n    def __call__(self, *args):\n        return self.handle(self.meth_name, self.action, *args)\n\n\nclass MockHandler:\n    # useful for testing handler machinery\n    # see add_ordered_mock_handlers() docstring\n    handler_order = 500\n\n    def __init__(self, methods):\n        self._define_methods(methods)\n\n    def _define_methods(self, methods):\n        for spec in methods:\n            if len(spec) == 2:\n                name, action = spec\n            else:\n                name, action = spec, None\n            meth = FakeMethod(name, action, self.handle)\n            setattr(self.__class__, name, meth)\n\n    def handle(self, fn_name, action, *args, **kwds):\n        self.parent.calls.append((self, fn_name, args, kwds))\n        if action is None:\n            return None\n        elif action == \"return self\":\n            return self\n        elif action == \"return response\":\n            res = MockResponse(200, \"OK\", {}, \"\")\n            return res\n        elif action == \"return request\":\n            return Request(\"http://blah/\")\n        elif action.startswith(\"error\"):\n            code = action[action.rfind(\" \") + 1:]\n            try:\n                code = int(code)\n            except ValueError:\n                pass\n            res = MockResponse(200, \"OK\", {}, \"\")\n            return self.parent.error(\"http\", args[0], res, code, \"\", {})\n        elif action == \"raise\":\n            raise mechanize.URLError(\"blah\")\n        assert False\n\n    def close(self):\n        pass\n\n    def add_parent(self, parent):\n        self.parent = parent\n        self.parent.calls = []\n\n    def __lt__(self, other):\n        if not hasattr(other, \"handler_order\"):\n            # Try to preserve the old behavior of having custom classes\n            # inserted after default ones (works only for custom user\n            # classes which are not aware of handler_order).\n            return True\n        return self.handler_order < other.handler_order\n\n\ndef add_ordered_mock_handlers(opener, meth_spec):\n    \"\"\"Create MockHandlers and add them to an OpenerDirector.\n\n    meth_spec: list of lists of tuples and strings defining methods to define\n    on handlers.  eg:\n\n    [[\"http_error\", \"ftp_open\"], [\"http_open\"]]\n\n    defines methods .http_error() and .ftp_open() on one handler, and\n    .http_open() on another.  These methods just record their arguments and\n    return None.  Using a tuple instead of a string causes the method to\n    perform some action (see MockHandler.handle()), eg:\n\n    [[\"http_error\"], [(\"http_open\", \"return request\")]]\n\n    defines .http_error() on one handler (which simply returns None), and\n    .http_open() on another handler, which returns a Request object.\n\n    \"\"\"\n    handlers = []\n    count = 0\n    for meths in meth_spec:\n\n        class MockHandlerSubclass(MockHandler):\n            pass\n\n        h = MockHandlerSubclass(meths)\n        h.handler_order += count\n        h.add_parent(opener)\n        count = count + 1\n        handlers.append(h)\n        opener.add_handler(h)\n    return handlers\n\n\ndef build_test_opener(*handler_instances):\n    opener = OpenerDirector()\n    for h in handler_instances:\n        opener.add_handler(h)\n    return opener\n\n\nclass MockHTTPHandler(mechanize.BaseHandler):\n    # useful for testing redirections and auth\n    # sends supplied headers and code as first response\n    # sends 200 OK as second response\n\n    def __init__(self, code, headers):\n        self.code = code\n        self.headers = headers\n        self.reset()\n\n    def reset(self):\n        self._count = 0\n        self.requests = []\n\n    def http_open(self, req):\n        import copy\n        self.requests.append(copy.deepcopy(req))\n        if self._count == 0:\n            self._count = self._count + 1\n            name = \"Not important\"\n            msg = create_response_info(BytesIO(\n                self.headers.encode('iso-8859-1')))\n            return self.parent.error(\"http\", req,\n                                     test_response(), self.code, name, msg)\n        else:\n            self.req = req\n            return test_response(\"\", [], req.get_full_url())\n\n\nclass MockHTTPResponse:\n    def __init__(self, fp, msg, status, reason):\n        self.fp = fp\n        self.msg = msg\n        self.status = status\n        self.reason = reason\n\n    def read(self):\n        return b''\n\n    def readinto(self, b):\n        pass\n\n    def close(self):\n        self.fp = None\n\n\nclass MockHTTPClass:\n    def __init__(self):\n        self.req_headers = []\n        self.data = None\n        self.raise_on_endheaders = False\n        self._tunnel_headers = {}\n\n    def __call__(self, host, timeout=_sockettimeout._GLOBAL_DEFAULT_TIMEOUT):\n        self.host = host\n        self.timeout = timeout\n        return self\n\n    def set_debuglevel(self, level):\n        self.level = level\n\n    def set_tunnel(self, host, port=None, headers=None):\n        self._tunnel_host = host\n        self._tunnel_port = port\n        if headers:\n            self._tunnel_headers = headers\n        else:\n            self._tunnel_headers.clear()\n\n    def request(self, method, url, body=None, headers={}):\n        self.method = method\n        self.selector = url\n        self.req_headers += list(iteritems(headers))\n        self.req_headers.sort()\n        if body:\n            self.data = body\n        if self.raise_on_endheaders:\n            import socket\n\n            raise socket.error()\n\n    def getresponse(self):\n        return MockHTTPResponse(MockFile(), {}, 200, \"OK\")\n\n\nclass MockHTTPSHandler(AbstractHTTPHandler):\n    # Useful for testing the Proxy-Authorization request by verifying the\n    # properties of httpcon\n    httpconn = MockHTTPClass()\n\n    def https_open(self, req):\n        return self.do_open(self.httpconn, req)\n\n\nclass OpenerDirectorTests(unittest.TestCase):\n    def test_add_non_handler(self):\n        class NonHandler(object):\n            pass\n\n        self.assertRaises(TypeError, OpenerDirector().add_handler,\n                          NonHandler())\n\n    def test_badly_named_methods(self):\n        # test work-around for three methods that accidentally follow the\n        # naming conventions for handler methods\n        # (*_open() / *_request() / *_response())\n\n        # These used to call the accidentally-named methods, causing a\n        # TypeError in real code; here, returning self from these mock\n        # methods would either cause no exception, or AttributeError.\n\n        from mechanize import URLError\n\n        o = OpenerDirector()\n        meth_spec = [\n            [(\"do_open\", \"return self\"), (\"proxy_open\", \"return self\")],\n            [(\"redirect_request\", \"return self\")],\n        ]\n        add_ordered_mock_handlers(o, meth_spec)\n        o.add_handler(mechanize.UnknownHandler())\n        for scheme in \"do\", \"proxy\", \"redirect\":\n            self.assertRaises(URLError, o.open, scheme + \"://example.com/\")\n\n    def test_handled(self):\n        # handler returning non-None means no more handlers will be called\n        o = OpenerDirector()\n        meth_spec = [\n            [\"http_open\", \"ftp_open\", \"http_error_302\"],\n            [\"ftp_open\"],\n            [(\"http_open\", \"return self\")],\n            [(\"http_open\", \"return self\")],\n        ]\n        handlers = add_ordered_mock_handlers(o, meth_spec)\n\n        req = Request(\"http://example.com/\")\n        r = o.open(req)\n        # Second .http_open() gets called, third doesn't, since second returned\n        # non-None.  Handlers without .http_open() never get any methods called\n        # on them.\n        # In fact, second mock handler defining .http_open() returns self\n        # (instead of response), which becomes the OpenerDirector's return\n        # value.\n        self.assertEqual(r, handlers[2])\n        calls = [(handlers[0], \"http_open\"), (handlers[2], \"http_open\")]\n        for expected, got in zip(calls, o.calls):\n            handler, name, args, kwds = got\n            self.assertEqual((handler, name), expected)\n            self.assertEqual(args, (req, ))\n\n    def test_reindex_handlers(self):\n        o = OpenerDirector()\n\n        class MockHandler:\n            def add_parent(self, parent):\n                pass\n\n            def close(self):\n                pass\n\n            def __lt__(self, other):\n                return self.handler_order < other.handler_order\n\n        # this first class is here as an obscure regression test for bug\n        # encountered during development: if something manages to get through\n        # to _maybe_reindex_handlers, make sure it's properly removed and\n        # doesn't affect adding of subsequent handlers\n        class NonHandler(MockHandler):\n            handler_order = 1\n\n        class Handler(MockHandler):\n            handler_order = 2\n\n            def http_open(self):\n                pass\n\n        class Processor(MockHandler):\n            handler_order = 3\n\n            def any_response(self):\n                pass\n\n            def http_response(self):\n                pass\n\n        o.add_handler(NonHandler())\n        h = Handler()\n        o.add_handler(h)\n        p = Processor()\n        o.add_handler(p)\n        o._maybe_reindex_handlers()\n        self.assertEqual(o.handle_open, {\"http\": [h]})\n        self.assertEqual(len(list(o.process_response.keys())), 1)\n        self.assertEqual(list(o.process_response[\"http\"]), [p])\n        self.assertEqual(list(o._any_response), [p])\n        self.assertEqual(o.handlers, [h, p])\n\n    def test_handler_order(self):\n        o = OpenerDirector()\n        handlers = []\n        for meths, handler_order in [\n            ([(\"http_open\", \"return self\")], 500),\n            ([\"http_open\"], 0),\n        ]:\n\n            class MockHandlerSubclass(MockHandler):\n                pass\n\n            h = MockHandlerSubclass(meths)\n            h.handler_order = handler_order\n            handlers.append(h)\n            o.add_handler(h)\n\n        o.open(\"http://example.com/\")\n        # handlers called in reverse order, thanks to their sort order\n        self.assertEqual(o.calls[0][0], handlers[1])\n        self.assertEqual(o.calls[1][0], handlers[0])\n\n    def test_raise(self):\n        # raising URLError stops processing of request\n        o = OpenerDirector()\n        meth_spec = [\n            [(\"http_open\", \"raise\")],\n            [(\"http_open\", \"return self\")],\n        ]\n        handlers = add_ordered_mock_handlers(o, meth_spec)\n\n        req = Request(\"http://example.com/\")\n        self.assertRaises(mechanize.URLError, o.open, req)\n        self.assertEqual(o.calls, [(handlers[0], \"http_open\", (req, ), {})])\n\n# def test_error(self):\n# XXX this doesn't actually seem to be used in standard library,\n# but should really be tested anyway...\n\n    def test_http_error(self):\n        # XXX http_error_default\n        # http errors are a special case\n        o = OpenerDirector()\n        meth_spec = [\n            [(\"http_open\", \"error 302\")],\n            [(\"http_error_400\", \"raise\"), \"http_open\"],\n            [(\"http_error_302\", \"return response\"), \"http_error_303\",\n             \"http_error\"],\n            [(\"http_error_302\")],\n        ]\n        handlers = add_ordered_mock_handlers(o, meth_spec)\n\n        req = Request(\"http://example.com/\")\n        o.open(req)\n        assert len(o.calls) == 2\n        ignore = object()\n        calls = [(handlers[0], \"http_open\", (req, )), (\n            handlers[2], \"http_error_302\", (req, ignore, 302, \"\", {}))]\n        for expected, got in zip(calls, o.calls):\n            handler, method_name, args = expected\n            self.assertEqual((handler, method_name), got[:2])\n            self.assertEqual(len(args), len(got[2]))\n            for a, b in zip(args, got[2]):\n                if a is not ignore:\n                    self.assertEqual(a, b)\n\n    def test_http_error_raised(self):\n        # should get an HTTPError if an HTTP handler raises a non-200 response\n        # XXX it worries me that this is the only test that excercises the else\n        # branch in HTTPDefaultErrorHandler\n        from mechanize import _response\n        o = mechanize.OpenerDirector()\n        o.add_handler(mechanize.HTTPErrorProcessor())\n        o.add_handler(mechanize.HTTPDefaultErrorHandler())\n\n        class HTTPHandler(AbstractHTTPHandler):\n            def http_open(self, req):\n                return _response.test_response(code=302)\n\n        o.add_handler(HTTPHandler())\n        self.assertRaises(mechanize.HTTPError, o.open, \"http://example.com/\")\n\n    def test_processors(self):\n        # *_request / *_response methods get called appropriately\n        o = OpenerDirector()\n        meth_spec = [\n            [(\"http_request\", \"return request\"),\n             (\"http_response\", \"return response\")],\n            [(\"http_request\", \"return request\"),\n             (\"http_response\", \"return response\")],\n        ]\n        handlers = add_ordered_mock_handlers(o, meth_spec)\n\n        req = Request(\"http://example.com/\")\n        o.open(req)\n        # processor methods are called on *all* handlers that define them,\n        # not just the first handler that handles the request\n        calls = [(handlers[0], \"http_request\"), (handlers[1], \"http_request\"),\n                 (handlers[0], \"http_response\"),\n                 (handlers[1], \"http_response\")]\n\n        self.assertEqual(len(o.calls), len(calls))\n        for i, (handler, name, args, kwds) in enumerate(o.calls):\n            if i < 2:\n                # *_request\n                self.assertEqual((handler, name), calls[i])\n                self.assertEqual(len(args), 1)\n                self.assertTrue(isinstance(args[0], Request))\n            else:\n                # *_response\n                self.assertEqual((handler, name), calls[i])\n                self.assertEqual(len(args), 2)\n                self.assertTrue(isinstance(args[0], Request))\n                # response from opener.open is None, because there's no\n                # handler that defines http_open to handle it\n                self.assertTrue(args[1] is None or\n                                isinstance(args[1], MockResponse))\n\n    def test_any(self):\n        # XXXXX two handlers case: ordering\n        o = OpenerDirector()\n        meth_spec = [[\n            (\"http_request\", \"return request\"),\n            (\"http_response\", \"return response\"),\n            (\"ftp_request\", \"return request\"),\n            (\"ftp_response\", \"return response\"),\n            (\"any_request\", \"return request\"),\n            (\"any_response\", \"return response\"),\n        ]]\n        handlers = add_ordered_mock_handlers(o, meth_spec)\n        handler = handlers[0]\n\n        for scheme in [\"http\", \"ftp\"]:\n            o.calls = []\n            req = Request(\"%s://example.com/\" % scheme)\n            o.open(req)\n\n            calls = [\n                (handler, \"any_request\"),\n                (handler, (\"%s_request\" % scheme)),\n                (handler, \"any_response\"),\n                (handler, (\"%s_response\" % scheme)),\n            ]\n            self.assertEqual(len(o.calls), len(calls))\n            for i, ((handler, name, args, kwds), calls) in (\n                    enumerate(zip(o.calls, calls))):\n                if i < 2:\n                    # *_request\n                    self.assertTrue((handler, name) == calls)\n                    self.assertTrue(len(args) == 1)\n                    self.assertTrue(isinstance(args[0], Request))\n                else:\n                    # *_response\n                    self.assertTrue((handler, name) == calls)\n                    self.assertTrue(len(args) == 2)\n                    self.assertTrue(isinstance(args[0], Request))\n                    # response from opener.open is None, because there's no\n                    # handler that defines http_open to handle it\n                    self.assertTrue(args[1] is None or isinstance(\n                        args[1], MockResponse))\n\n\nclass MockRobotFileParserClass:\n    def __init__(self):\n        self.calls = []\n        self._can_fetch = True\n\n    def clear(self):\n        self.calls = []\n\n    def __call__(self):\n        self.calls.append(\"__call__\")\n        return self\n\n    def set_url(self, url):\n        self.calls.append((\"set_url\", url))\n\n    def set_timeout(self, timeout):\n        self.calls.append((\"set_timeout\", timeout))\n\n    def set_opener(self, opener):\n        self.calls.append((\"set_opener\", opener))\n\n    def read(self):\n        self.calls.append(\"read\")\n\n    def can_fetch(self, ua, url):\n        self.calls.append((\"can_fetch\", ua, url))\n        return self._can_fetch\n\n\nclass MockPasswordManager:\n    def add_password(self, realm, uri, user, password):\n        self.realm = realm\n        self.url = uri\n        self.user = user\n        self.password = password\n\n    def find_user_password(self, realm, authuri):\n        self.target_realm = realm\n        self.target_url = authuri\n        return self.user, self.password\n\n\nclass HandlerTests(mechanize._testcase.TestCase):\n    def test_ftp(self):\n        class MockFTPWrapper:\n            def __init__(self, data):\n                self.data = data\n\n            def retrfile(self, filename, filetype):\n                self.filename, self.filetype = filename, filetype\n                data = self.data if isinstance(\n                        self.data, bytes) else self.data.encode('utf-8')\n                return BytesIO(data), len(self.data)\n\n        class NullFTPHandler(mechanize.FTPHandler):\n            def __init__(self, data):\n                self.data = data\n\n            def connect_ftp(self, user, passwd, host, port, dirs, timeout):\n                self.user, self.passwd = user, passwd\n                self.host, self.port = host, port\n                self.dirs = dirs\n                self.timeout = timeout\n                self.ftpwrapper = MockFTPWrapper(self.data)\n                return self.ftpwrapper\n\n        import ftplib\n        import socket\n        data = \"rheum rhaponicum\"\n        h = NullFTPHandler(data)\n        h.parent = MockOpener()\n\n        for url, host, port, type_, dirs, timeout, filename, mimetype in [\n            (\"ftp://localhost/foo/bar/baz.html\", \"localhost\", ftplib.FTP_PORT,\n             \"I\", [\"foo\", \"bar\"], _sockettimeout._GLOBAL_DEFAULT_TIMEOUT,\n             \"baz.html\", \"text/html\"),\n            (\"ftp://localhost:80/foo/bar/\", \"localhost\", 80, \"D\",\n             [\"foo\", \"bar\"], _sockettimeout._GLOBAL_DEFAULT_TIMEOUT, \"\", None),\n            (\"ftp://localhost/baz.gif;type=a\", \"localhost\", ftplib.FTP_PORT,\n             \"A\", [], _sockettimeout._GLOBAL_DEFAULT_TIMEOUT, \"baz.gif\",\n             None),  # TODO: really this should guess image/gif\n        ]:\n            req = Request(url, timeout=timeout)\n            r = h.ftp_open(req)\n            # ftp authentication not yet implemented by FTPHandler\n            self.assertTrue(h.user == h.passwd == \"\")\n            self.assertEqual(h.host, socket.gethostbyname(host))\n            self.assertEqual(h.port, port)\n            self.assertEqual(h.dirs, dirs)\n            if sys.version_info >= (2, 6):\n                self.assertEqual(h.timeout, timeout)\n            self.assertEqual(h.ftpwrapper.filename, filename)\n            self.assertEqual(h.ftpwrapper.filetype, type_)\n            headers = r.info()\n            self.assertEqual(headers.get(\"Content-type\"), mimetype)\n            self.assertEqual(int(headers[\"Content-length\"]), len(data))\n\n    def test_file(self):\n        from email.utils import formatdate\n        import socket\n        h = mechanize.FileHandler()\n        o = h.parent = MockOpener()\n\n        temp_file = os.path.join(self.make_temp_dir(), \"test.txt\")\n        urlpath = sanepathname2url(os.path.abspath(temp_file))\n        towrite = b\"hello, world\\n\"\n        try:\n            fqdn = socket.gethostbyname(socket.gethostname())\n        except socket.gaierror:\n            fqdn = \"localhost\"\n        for url in [\n                \"file://localhost%s\" % urlpath, \"file://%s\" % urlpath,\n                \"file://%s%s\" % (socket.gethostbyname('localhost'), urlpath),\n                \"file://%s%s\" % (fqdn, urlpath)\n        ]:\n            write_file(temp_file, towrite)\n            r = h.file_open(Request(url))\n            try:\n                data = r.read()\n                headers = r.info()\n                r.geturl()\n            finally:\n                r.close()\n            stats = os.stat(temp_file)\n            modified = formatdate(stats.st_mtime, usegmt=True)\n            self.assertEqual(data, towrite)\n            self.assertEqual(headers[\"Content-type\"], \"text/plain\")\n            self.assertEqual(headers[\"Content-length\"], \"13\")\n            self.assertEqual(headers[\"Last-modified\"], modified)\n\n        for url in [\n                \"file://localhost:80%s\" % urlpath,\n                \"file:///file_does_not_exist.txt\",\n                \"file://%s:80%s/%s\" % (socket.gethostbyname('localhost'),\n                                       sanepathname2url(os.getcwd()),\n                                       temp_file),\n                \"file://somerandomhost.ontheinternet.com%s/%s\" % (\n                    sanepathname2url(os.getcwd()), temp_file),\n        ]:\n            write_file(temp_file, towrite)\n            self.assertRaises(mechanize.URLError, h.file_open, Request(url))\n\n        h = mechanize.FileHandler()\n        o = h.parent = MockOpener()\n        # XXXX why does // mean ftp (and /// mean not ftp!), and where\n        #  is file: scheme specified?  I think this is really a bug, and\n        #  what was intended was to distinguish between URLs like:\n        # file:/blah.txt (a file)\n        # file://localhost/blah.txt (a file)\n        # file:///blah.txt (a file)\n        # file://ftp.example.com/blah.txt (an ftp URL)\n        for url, ftp in [\n            (\"file://ftp.example.com//foo.txt\", True),\n            (\"file://ftp.example.com///foo.txt\", False),\n                # XXXX bug: fails with OSError, should be URLError\n            (\"file://ftp.example.com/foo.txt\", False),\n        ]:\n            req = Request(url)\n            try:\n                h.file_open(req)\n            # XXXX remove OSError when bug fixed\n            except (mechanize.URLError, OSError):\n                self.assertFalse(ftp)\n            else:\n                self.assertTrue(o.req is req)\n                self.assertEqual(req.type, \"ftp\")\n\n    def test_http(self):\n        class MockHTTPResponse:\n            def __init__(self, fp, msg, status, reason):\n                self.fp = fp\n                self.msg = msg\n                self.status = status\n                self.reason = reason\n\n            def read(self):\n                return b''\n\n            def readinto(self, b):\n                pass\n\n            def close(self):\n                self.fp = None\n\n        class MockHTTPClass:\n            def __init__(self):\n                self.req_headers = []\n                self.data = None\n                self.raise_on_endheaders = False\n\n            def __call__(self,\n                         host,\n                         timeout=_sockettimeout._GLOBAL_DEFAULT_TIMEOUT):\n                self.host = host\n                self.timeout = timeout\n                return self\n\n            def set_debuglevel(self, level):\n                self.level = level\n\n            def request(self, method, url, body=None, headers={}):\n                self.method = method\n                self.selector = url\n                self.req_headers += list(iteritems(headers))\n                if body:\n                    self.data = body\n                if self.raise_on_endheaders:\n                    import socket\n                    raise socket.error()\n\n            def getresponse(self):\n                return MockHTTPResponse(MockFile(), {}, 200, \"OK\")\n\n        h = AbstractHTTPHandler()\n        o = h.parent = MockOpener()\n\n        url = \"http://example.com/\"\n        for method, data in [(\"GET\", None), (\"POST\", \"blah\")]:\n            req = Request(url, data, {\"Foo\": \"bar\"})\n            req.add_header('Order', '1')\n            req.add_unredirected_header(\"Spam\", \"eggs\")\n            http = MockHTTPClass()\n            r = h.do_open(http, req)\n\n            # result attributes\n            r.read\n            r.readline  # wrapped MockFile methods\n            r.info\n            r.geturl  # addinfourl methods\n            r.code, r.msg == 200, \"OK\"  # added from MockHTTPClass.getreply()\n            hdrs = r.info()\n            hdrs.get\n            hdrs.__contains__  # r.info() gives dict from .getreply()\n            self.assertEqual(r.geturl(), url)\n\n            self.assertEqual(http.host, \"example.com\")\n            self.assertEqual(http.level, 0)\n            self.assertEqual(http.method, method)\n            self.assertEqual(http.selector, \"/\")\n            self.assertEqual(\n                http.req_headers,\n                [('Foo', 'bar'), ('Order', '1'),\n                    ('Spam', 'eggs'), ('Connection', 'close')]\n            )\n            self.assertEqual(http.data, data)\n\n        # check socket.error converted to URLError\n        http.raise_on_endheaders = True\n        self.assertRaises(mechanize.URLError, h.do_open, http, req)\n\n        # check adding of standard headers\n        o.addheaders = [(\"Spam\", \"eggs\")]\n        for data in \"\", None:  # POST, GET\n            req = Request(\"http://example.com/\", data)\n            r = MockResponse(200, \"OK\", {}, \"\")\n            h.do_request_(req)\n            if data is None:  # GET\n                self.assertTrue(\"Content-length\" not in req.unredirected_hdrs)\n                self.assertTrue(\"Content-type\" not in req.unredirected_hdrs)\n            else:  # POST\n                self.assertEqual(req.unredirected_hdrs[\"Content-Length\"], \"0\")\n                self.assertEqual(req.unredirected_hdrs[\"Content-Type\"],\n                                 \"application/x-www-form-urlencoded\")\n            # XXX the details of Host could be better tested\n            self.assertEqual(req.unredirected_hdrs[\"Host\"], \"example.com\")\n            self.assertEqual(req.unredirected_hdrs[\"Spam\"], \"eggs\")\n\n            # don't clobber existing headers\n            req.add_unredirected_header(\"Content-Length\", \"foo\")\n            req.add_unredirected_header(\"Content-Type\", \"bar\")\n            req.add_unredirected_header(\"Host\", \"baz\")\n            req.add_unredirected_header(\"Spam\", \"foo\")\n            h.do_request_(req)\n            self.assertEqual(req.unredirected_hdrs[\"Content-Length\"], \"foo\")\n            self.assertEqual(req.unredirected_hdrs[\"Content-Type\"], \"bar\")\n            self.assertEqual(req.unredirected_hdrs[\"Host\"], \"baz\")\n            self.assertEqual(req.unredirected_hdrs[\"Spam\"], \"foo\")\n\n    def test_http_double_slash(self):\n        # Checks that the presence of an unnecessary double slash in a url\n        # doesn't break anything Previously, a double slash directly after the\n        # host could cause incorrect parsing of the url\n        h = AbstractHTTPHandler()\n        h.parent = MockOpener()\n\n        data = \"\"\n        ds_urls = [\n            \"http://example.com/foo/bar/baz.html\",\n            \"http://example.com//foo/bar/baz.html\",\n            \"http://example.com/foo//bar/baz.html\",\n            \"http://example.com/foo/bar//baz.html\",\n        ]\n\n        for ds_url in ds_urls:\n            ds_req = Request(ds_url, data)\n\n            # Check whether host is determined correctly if there is no proxy\n            np_ds_req = h.do_request_(ds_req)\n            self.assertEqual(np_ds_req.unredirected_hdrs[\"Host\"],\n                             \"example.com\")\n\n            # Check whether host is determined correctly if there is a proxy\n            ds_req.set_proxy(\"someproxy:3128\", None)\n            p_ds_req = h.do_request_(ds_req)\n            self.assertEqual(p_ds_req.unredirected_hdrs[\"Host\"], \"example.com\")\n\n    def test_errors(self):\n        h = HTTPErrorProcessor()\n        o = h.parent = MockOpener()\n\n        req = Request(\"http://example.com\")\n        # all 2xx are passed through\n        r = mechanize._response.test_response()\n        newr = h.http_response(req, r)\n        self.assertTrue(r is newr)\n        self.assertTrue(not hasattr(o, \"proto\"))  # o.error not called\n        r = mechanize._response.test_response(code=202, msg=\"Accepted\")\n        newr = h.http_response(req, r)\n        self.assertTrue(r is newr)\n        self.assertTrue(not hasattr(o, \"proto\"))  # o.error not called\n        r = mechanize._response.test_response(code=206, msg=\"Partial content\")\n        newr = h.http_response(req, r)\n        self.assertTrue(r is newr)\n        self.assertTrue(not hasattr(o, \"proto\"))  # o.error not called\n        # anything else calls o.error (and MockOpener returns None, here)\n        r = mechanize._response.test_response(code=502, msg=\"Bad gateway\")\n        self.assertTrue(h.http_response(req, r) is None)\n        self.assertEqual(o.proto, \"http\")  # o.error called\n        self.assertEqual(o.args[:4], (req, r, 502, \"Bad gateway\"))\n\n    def test_referer(self):\n        h = HTTPRefererProcessor()\n        h.parent = MockOpener()\n\n        # normal case\n        url = \"http://example.com/\"\n        req = Request(url)\n        r = MockResponse(200, \"OK\", {}, \"\", url)\n        newr = h.http_response(req, r)\n        self.assertTrue(r is newr)\n        self.assertTrue(h.referer == url)\n        newreq = h.http_request(req)\n        self.assertTrue(req is newreq)\n        self.assertTrue(req.unredirected_hdrs[\"Referer\"] == url)\n        # don't clobber existing Referer\n        ref = \"http://set.by.user.com/\"\n        req.add_unredirected_header(\"Referer\", ref)\n        newreq = h.http_request(req)\n        self.assertTrue(req is newreq)\n        self.assertTrue(req.unredirected_hdrs[\"Referer\"] == ref)\n\n    def test_raise_http_errors(self):\n        # HTTPDefaultErrorHandler should raise HTTPError if no error handler\n        # handled the error response\n        from mechanize import _response\n        h = mechanize.HTTPDefaultErrorHandler()\n\n        url = \"http://example.com\"\n        code = 500\n        msg = \"Error\"\n        request = mechanize.Request(url)\n        response = _response.test_response(url=url, code=code, msg=msg)\n\n        # case 1. it's not an HTTPError\n        try:\n            h.http_error_default(request, response, code, msg, response.info())\n        except mechanize.HTTPError as exc:\n            self.assertTrue(exc is not response)\n            self.assertTrue(exc.fp is response)\n        else:\n            self.assertTrue(False)\n\n        # case 2. response object is already an HTTPError, so just re-raise it\n        error = mechanize.HTTPError(url, code, msg, \"fake headers\", response)\n        try:\n            h.http_error_default(request, error, code, msg, error.info())\n        except mechanize.HTTPError as exc:\n            self.assertTrue(exc is error)\n        else:\n            self.assertTrue(False)\n\n    def test_robots(self):\n        # XXX useragent\n        from mechanize import HTTPRobotRulesProcessor\n        opener = OpenerDirector()\n        rfpc = MockRobotFileParserClass()\n        h = HTTPRobotRulesProcessor(rfpc)\n        opener.add_handler(h)\n\n        url = \"http://example.com:80/foo/bar.html\"\n        req = Request(url)\n        # first time: initialise and set up robots.txt parser before checking\n        #  whether OK to fetch URL\n        h.http_request(req)\n        self.assertEqual(rfpc.calls, [\n            \"__call__\",\n            (\"set_opener\", opener),\n            (\"set_url\", \"http://example.com:80/robots.txt\"),\n            (\"set_timeout\", _sockettimeout._GLOBAL_DEFAULT_TIMEOUT),\n            \"read\",\n            (\"can_fetch\", \"\", url),\n        ])\n        # second time: just use existing parser\n        rfpc.clear()\n        req = Request(url)\n        h.http_request(req)\n        self.assertTrue(rfpc.calls == [\n            (\"can_fetch\", \"\", url),\n        ])\n        # different URL on same server: same again\n        rfpc.clear()\n        url = \"http://example.com:80/blah.html\"\n        req = Request(url)\n        h.http_request(req)\n        self.assertTrue(rfpc.calls == [\n            (\"can_fetch\", \"\", url),\n        ])\n        # disallowed URL\n        rfpc.clear()\n        rfpc._can_fetch = False\n        url = \"http://example.com:80/rhubarb.html\"\n        req = Request(url)\n        try:\n            h.http_request(req)\n        except mechanize.HTTPError as e:\n            self.assertTrue(e.request == req)\n            self.assertTrue(e.code == 403)\n        # new host: reload robots.txt (even though the host and port are\n        #  unchanged, we treat this as a new host because\n        #  \"example.com\" != \"example.com:80\")\n        rfpc.clear()\n        rfpc._can_fetch = True\n        url = \"http://example.com/rhubarb.html\"\n        req = Request(url)\n        h.http_request(req)\n        self.assertEqual(rfpc.calls, [\n            \"__call__\",\n            (\"set_opener\", opener),\n            (\"set_url\", \"http://example.com/robots.txt\"),\n            (\"set_timeout\", _sockettimeout._GLOBAL_DEFAULT_TIMEOUT),\n            \"read\",\n            (\"can_fetch\", \"\", url),\n        ])\n        # https url -> should fetch robots.txt from https url too\n        rfpc.clear()\n        url = \"https://example.org/rhubarb.html\"\n        req = Request(url)\n        h.http_request(req)\n        self.assertEqual(rfpc.calls, [\n            \"__call__\",\n            (\"set_opener\", opener),\n            (\"set_url\", \"https://example.org/robots.txt\"),\n            (\"set_timeout\", _sockettimeout._GLOBAL_DEFAULT_TIMEOUT),\n            \"read\",\n            (\"can_fetch\", \"\", url),\n        ])\n        # non-HTTP URL -> ignore robots.txt\n        rfpc.clear()\n        url = \"ftp://example.com/\"\n        req = Request(url)\n        h.http_request(req)\n        self.assertTrue(rfpc.calls == [])\n\n    def test_redirected_robots_txt(self):\n        # redirected robots.txt fetch shouldn't result in another attempted\n        # robots.txt fetch to check the redirection is allowed!\n        import mechanize\n        from mechanize import (\n                HTTPDefaultErrorHandler, HTTPRedirectHandler,\n                HTTPRobotRulesProcessor)\n\n        class MockHTTPHandler(mechanize.BaseHandler):\n            def __init__(self):\n                self.requests = []\n\n            def http_open(self, req):\n                import copy\n                self.requests.append(copy.deepcopy(req))\n                if req.get_full_url() == \"http://example.com/robots.txt\":\n                    hdr = b\"Location: http://example.com/en/robots.txt\\r\\n\\r\\n\"\n                    msg = create_response_info(BytesIO(hdr))\n                    return self.parent.error(\"http\", req,\n                                             test_response(), 302, \"Blah\", msg)\n                else:\n                    return test_response(\"Allow: *\", [], req.get_full_url())\n\n        hh = MockHTTPHandler()\n        hdeh = HTTPDefaultErrorHandler()\n        hrh = HTTPRedirectHandler()\n        rh = HTTPRobotRulesProcessor()\n        o = build_test_opener(hh, hdeh, hrh, rh)\n        o.open(\"http://example.com/\")\n        self.assertEqual([req.get_full_url() for req in hh.requests], [\n            \"http://example.com/robots.txt\",\n            \"http://example.com/en/robots.txt\",\n            \"http://example.com/\",\n        ])\n\n    def test_cookies(self):\n        cj = MockCookieJar()\n        h = HTTPCookieProcessor(cj)\n        h.parent = MockOpener()\n\n        req = Request(\"http://example.com/\")\n        r = MockResponse(200, \"OK\", {}, \"\")\n        newreq = h.http_request(req)\n        self.assertTrue(cj.ach_req is req is newreq)\n        self.assertEqual(req.get_origin_req_host(), \"example.com\")\n        self.assertFalse(cj.ach_u)\n        newr = h.http_response(req, r)\n        self.assertTrue(cj.ec_req is req)\n        self.assertTrue(cj.ec_r is r is newr)\n        self.assertFalse(cj.ec_u)\n\n    def test_http_equiv(self):\n        h = HTTPEquivProcessor()\n        h.parent = MockOpener()\n\n        data = ('<html><HEad>'\n                '<Meta httP-equiv=\"RefResh\" coNtent=\"spam&amp;Eggs\">'\n                '</Head></html>')\n        headers = [\n            (\"Foo\", \"Bar\"),\n            (\"Content-type\", \"text/html\"),\n            (\"Refresh\", \"blah\"),\n        ]\n        url = \"http://example.com/\"\n        req = Request(url)\n        r = mechanize._response.make_response(data, headers, url, 200, \"OK\")\n        newr = h.http_response(req, r)\n\n        new_headers = newr.info()\n        self.assertEqual(new_headers[\"Foo\"], \"Bar\")\n        self.assertEqual(new_headers[\"Refresh\"], \"spam&Eggs\")\n        self.assertEqual(\n            new_headers.getheaders(\"Refresh\"), [\"blah\", \"spam&Eggs\"])\n\n    def test_refresh(self):\n        # XXX test processor constructor optional args\n        h = HTTPRefreshProcessor(max_time=None, honor_time=False)\n\n        for val, valid in [\n            ('0; url=\"http://example.com/foo/\"', True),\n            (\"2\", True),\n                # in the past, this failed with UnboundLocalError\n            ('0; \"http://example.com/foo/\"', False),\n        ]:\n            o = h.parent = MockOpener()\n            req = Request(\"http://example.com/\")\n            headers = http_message({\"refresh\": val})\n            r = MockResponse(200, \"OK\", headers, \"\", \"http://example.com/\")\n            h.http_response(req, r)\n            if valid:\n                self.assertEqual(o.proto, \"http\")\n                self.assertEqual(o.args, (req, r, \"refresh\", \"OK\", headers))\n\n    def test_refresh_honor_time(self):\n        class SleepTester:\n            def __init__(self, test, seconds):\n                self._test = test\n                if seconds == 0:\n                    seconds = None  # don't expect a sleep for 0 seconds\n                self._expected = seconds\n                self._got = None\n\n            def sleep(self, seconds):\n                self._got = seconds\n\n            def verify(self):\n                self._test.assertEqual(self._expected, self._got)\n\n        class Opener:\n            called = False\n\n            def error(self, *args, **kwds):\n                self.called = True\n\n        def test(rp, header, refresh_after):\n            expect_refresh = refresh_after is not None\n            opener = Opener()\n            rp.parent = opener\n            st = SleepTester(self, refresh_after)\n            rp._sleep = st.sleep\n            rp.http_response(\n                Request(\"http://example.com\"),\n                test_response(headers=[(\"Refresh\", header)], url=\"http://example.com/\"), )\n            self.assertEqual(expect_refresh, opener.called)\n            st.verify()\n\n        # by default, only zero-time refreshes are honoured\n        test(HTTPRefreshProcessor(), \"0\", 0)\n        test(HTTPRefreshProcessor(), \"2\", None)\n\n        # if requested, more than zero seconds are allowed\n        test(HTTPRefreshProcessor(max_time=None), \"2\", 2)\n        test(HTTPRefreshProcessor(max_time=30), \"2\", 2)\n\n        # no sleep if we don't \"honor_time\"\n        test(HTTPRefreshProcessor(max_time=30, honor_time=False), \"2\", 0)\n\n        # request for too-long wait before refreshing --> no refresh occurs\n        test(HTTPRefreshProcessor(max_time=30), \"60\", None)\n\n    def test_redirect(self):\n        from_url = \"http://example.com/a.html\"\n        to_url = \"http://example.com/b.html\"\n        h = HTTPRedirectHandler()\n        o = h.parent = MockOpener()\n\n        # ordinary redirect behaviour\n        for code in 301, 302, 303, 307, \"refresh\":\n            for data in None, \"blah\\nblah\\n\":\n                method = getattr(h, \"http_error_%s\" % code)\n                req = Request(from_url, data)\n                req.add_header(\"Nonsense\", \"viking=withhold\")\n                req.add_unredirected_header(\"Spam\", \"spam\")\n                req.origin_req_host = \"example.com\"  # XXX\n                try:\n                    method(req,\n                           MockFile(), code, \"Blah\",\n                           http_message({\n                               \"location\": to_url\n                           }))\n                except mechanize.HTTPError:\n                    # 307 in response to POST requires user OK\n                    self.assertEqual(code, 307)\n                    self.assertTrue(data is not None)\n                self.assertEqual(o.req.get_full_url(), to_url)\n                try:\n                    self.assertEqual(o.req.get_method(), \"GET\")\n                except AttributeError:\n                    self.assertFalse(o.req.has_data())\n\n                # now it's a GET, there should not be headers regarding content\n                # (possibly dragged from before being a POST)\n                headers = [x.lower() for x in o.req.headers]\n                self.assertTrue(\"content-length\" not in headers)\n                self.assertTrue(\"content-type\" not in headers)\n\n                self.assertEqual(o.req.headers[\"Nonsense\"], \"viking=withhold\")\n                self.assertTrue(\"Spam\" not in o.req.headers)\n                self.assertTrue(\"Spam\" not in o.req.unredirected_hdrs)\n\n        # loop detection\n        req = Request(from_url)\n\n        def redirect(h, req, url=to_url):\n            h.http_error_302(req,\n                             MockFile(), 302, \"Blah\",\n                             http_message({\n                                 \"location\": url\n                             }))\n\n        # Note that the *original* request shares the same record of\n        # redirections with the sub-requests caused by the redirections.\n\n        # detect infinite loop redirect of a URL to itself\n        req = Request(from_url, origin_req_host=\"example.com\")\n        count = 0\n        try:\n            while 1:\n                redirect(h, req, \"http://example.com/\")\n                count = count + 1\n        except mechanize.HTTPError:\n            # don't stop until max_repeats, because cookies may introduce state\n            self.assertEqual(count, HTTPRedirectHandler.max_repeats)\n\n        # detect endless non-repeating chain of redirects\n        req = Request(from_url, origin_req_host=\"example.com\")\n        count = 0\n        try:\n            while 1:\n                redirect(h, req, \"http://example.com/%d\" % count)\n                count = count + 1\n        except mechanize.HTTPError:\n            self.assertEqual(count, HTTPRedirectHandler.max_redirections)\n\n    def test_redirect_bad_uri(self):\n        # bad URIs should be cleaned up before redirection\n        from mechanize._response import test_html_response\n        from_url = \"http://example.com/a.html\"\n        bad_to_url = \"http://example.com/b. |html\"\n        good_to_url = \"http://example.com/b.%20%7Chtml\"\n\n        h = HTTPRedirectHandler()\n        o = h.parent = MockOpener()\n\n        req = Request(from_url)\n        h.http_error_302(\n            req,\n            test_html_response(),\n            302,\n            \"Blah\",\n            http_message({\n                \"location\": bad_to_url\n            }), )\n        self.assertEqual(o.req.get_full_url(), good_to_url)\n\n    def test_refresh_bad_uri(self):\n        # bad URIs should be cleaned up before redirection\n        from mechanize._response import test_html_response\n        bad_to_url = \"http://example.com/b. |html\"\n        good_to_url = \"http://example.com/b.%20%7Chtml\"\n\n        h = HTTPRefreshProcessor(max_time=None, honor_time=False)\n        o = h.parent = MockOpener()\n\n        req = Request(\"http://example.com/\")\n        r = test_html_response(\n            headers=[(\"refresh\", '0; url=\"%s\"' % bad_to_url)])\n        h.http_response(req, r)\n        headers = o.args[-1]\n        self.assertEqual(headers[\"Location\"], good_to_url)\n\n    def test_cookie_redirect(self):\n        # cookies shouldn't leak into redirected requests\n        from mechanize import (\n                CookieJar, HTTPCookieProcessor, HTTPDefaultErrorHandler,\n                HTTPRedirectHandler)\n\n        from test.test_cookies import interact_netscape\n\n        cj = CookieJar()\n        interact_netscape(cj, \"http://www.example.com/\", \"spam=eggs\")\n        hh = MockHTTPHandler(302, \"Location: http://www.cracker.com/\\r\\n\\r\\n\")\n        hdeh = HTTPDefaultErrorHandler()\n        hrh = HTTPRedirectHandler()\n        cp = HTTPCookieProcessor(cj)\n        o = build_test_opener(hh, hdeh, hrh, cp)\n        o.open(\"http://www.example.com/\")\n        self.assertFalse(hh.req.has_header(\"Cookie\"))\n\n    def test_proxy(self):\n        o = OpenerDirector()\n        ph = mechanize.ProxyHandler(dict(http=\"proxy.example.com:3128\"))\n        o.add_handler(ph)\n        meth_spec = [[(\"http_open\", \"return response\")]]\n        handlers = add_ordered_mock_handlers(o, meth_spec)\n\n        o._maybe_reindex_handlers()\n\n        req = Request(\"http://acme.example.com/\")\n        self.assertEqual(req.get_host(), \"acme.example.com\")\n        o.open(req)\n        self.assertEqual(req.get_host(), \"proxy.example.com:3128\")\n\n        self.assertEqual([(handlers[0], \"http_open\")],\n                         [tup[0:2] for tup in o.calls])\n\n    def test_proxy_no_proxy(self):\n        self.monkey_patch_environ(\"no_proxy\", \"python.org\")\n        o = OpenerDirector()\n        ph = mechanize.ProxyHandler(dict(http=\"proxy.example.com\"))\n        o.add_handler(ph)\n        req = Request(\"http://www.perl.org/\")\n        self.assertEqual(req.get_host(), \"www.perl.org\")\n        o.open(req)\n        self.assertEqual(req.get_host(), \"proxy.example.com\")\n        req = Request(\"http://www.python.org\")\n        self.assertEqual(req.get_host(), \"www.python.org\")\n        o.open(req)\n        if sys.version_info >= (2, 6):\n            # no_proxy environment variable not supported in python 2.5\n            self.assertEqual(req.get_host(), \"www.python.org\")\n\n    def test_proxy_custom_proxy_bypass(self):\n        self.monkey_patch_environ(\"no_proxy\",\n                                  mechanize._testcase.MonkeyPatcher.Unset)\n\n        def proxy_bypass(hostname):\n            return hostname == \"noproxy.com\"\n\n        o = OpenerDirector()\n        ph = mechanize.ProxyHandler(\n            dict(http=\"proxy.example.com\"), proxy_bypass=proxy_bypass)\n\n        def is_proxied(url):\n            o.add_handler(ph)\n            req = Request(url)\n            o.open(req)\n            return req.has_proxy()\n\n        self.assertTrue(is_proxied(\"http://example.com\"))\n        self.assertFalse(is_proxied(\"http://noproxy.com\"))\n\n    def test_proxy_https(self):\n        o = OpenerDirector()\n        ph = mechanize.ProxyHandler(dict(https='proxy.example.com:3128'))\n        o.add_handler(ph)\n        meth_spec = [[(\"https_open\", \"return response\")]]\n        handlers = add_ordered_mock_handlers(o, meth_spec)\n        req = Request(\"https://www.example.com/\")\n        self.assertEqual(req.get_host(), \"www.example.com\")\n        o.open(req)\n        self.assertEqual(req.get_host(), \"proxy.example.com:3128\")\n        self.assertEqual([(handlers[0], \"https_open\")],\n                         [tup[0:2] for tup in o.calls])\n\n    def test_basic_auth(self, quote_char='\"'):\n        opener = OpenerDirector()\n        password_manager = MockPasswordManager()\n        auth_handler = mechanize.HTTPBasicAuthHandler(password_manager)\n        realm = \"ACME Widget Store\"\n        http_handler = MockHTTPHandler(\n            401, 'WWW-Authenticate: Basic realm=%s%s%s\\r\\n\\r\\n' %\n            (quote_char, realm, quote_char))\n        opener.add_handler(auth_handler)\n        opener.add_handler(http_handler)\n        self._test_basic_auth(\n            opener,\n            auth_handler,\n            \"Authorization\",\n            realm,\n            http_handler,\n            password_manager,\n            \"http://acme.example.com/protected\",\n            \"http://acme.example.com/protected\", )\n\n    def test_basic_auth_with_single_quoted_realm(self):\n        self.test_basic_auth(quote_char=\"'\")\n\n    def test_proxy_basic_auth(self):\n        opener = OpenerDirector()\n        ph = mechanize.ProxyHandler(dict(http=\"proxy.example.com:3128\"))\n        opener.add_handler(ph)\n        password_manager = MockPasswordManager()\n        auth_handler = mechanize.ProxyBasicAuthHandler(password_manager)\n        realm = \"ACME Networks\"\n        http_handler = MockHTTPHandler(\n            407, 'Proxy-Authenticate: Basic realm=\"%s\"\\r\\n\\r\\n' % realm)\n        opener.add_handler(auth_handler)\n        opener.add_handler(http_handler)\n        self._test_basic_auth(\n            opener,\n            auth_handler,\n            \"Proxy-authorization\",\n            realm,\n            http_handler,\n            password_manager,\n            \"http://acme.example.com:3128/protected\",\n            \"proxy.example.com:3128\", )\n\n    def test_proxy_https_proxy_authorization(self):\n        o = OpenerDirector()\n        ph = mechanize.ProxyHandler(dict(https='proxy.example.com:3128'))\n        o.add_handler(ph)\n        https_handler = MockHTTPSHandler()\n        o.add_handler(https_handler)\n        req = Request(\"https://www.example.com/\")\n        req.add_header(\"Proxy-Authorization\", \"FooBar\")\n        req.add_header(\"User-Agent\", \"Grail\")\n        self.assertEqual(req.get_host(), \"www.example.com\")\n        self.assertIsNone(req._tunnel_host)\n        o.open(req)\n        # Verify Proxy-Authorization gets tunneled to request.\n        # httpsconn req_headers do not have the Proxy-Authorization header but\n        # the req will have.\n        self.assertNotIn(\n            (\"Proxy-Authorization\", \"FooBar\"),\n            https_handler.httpconn.req_headers)\n        self.assertIn(\n            (\"User-Agent\", \"Grail\"), https_handler.httpconn.req_headers)\n        self.assertIsNotNone(req._tunnel_host)\n        self.assertEqual(req.get_host(), \"proxy.example.com:3128\")\n        self.assertEqual(req.get_header(\"Proxy-authorization\"), \"FooBar\")\n\n    def test_basic_and_digest_auth_handlers(self):\n        # HTTPDigestAuthHandler threw an exception if it couldn't handle a 40*\n        # response (http://python.org/sf/1479302), where it should instead\n        # return None to allow another handler (especially\n        # HTTPBasicAuthHandler) to handle the response.\n\n        # Also (http://python.org/sf/1479302, RFC 2617 section 1.2), we must\n        # try digest first (since it's the strongest auth scheme), so we record\n        # order of calls here to check digest comes first:\n        class RecordingOpenerDirector(OpenerDirector):\n            def __init__(self):\n                OpenerDirector.__init__(self)\n                self.recorded = []\n\n            def record(self, info):\n                self.recorded.append(info)\n\n        class TestDigestAuthHandler(mechanize.HTTPDigestAuthHandler):\n            def http_error_401(self, *args, **kwds):\n                self.parent.record(\"digest\")\n                mechanize.HTTPDigestAuthHandler.http_error_401(self, *args,\n                                                               **kwds)\n\n        class TestBasicAuthHandler(mechanize.HTTPBasicAuthHandler):\n            def http_error_401(self, *args, **kwds):\n                self.parent.record(\"basic\")\n                mechanize.HTTPBasicAuthHandler.http_error_401(self, *args,\n                                                              **kwds)\n\n        opener = RecordingOpenerDirector()\n        password_manager = MockPasswordManager()\n        digest_handler = TestDigestAuthHandler(password_manager)\n        basic_handler = TestBasicAuthHandler(password_manager)\n        realm = \"ACME Networks\"\n        http_handler = MockHTTPHandler(\n            401, 'WWW-Authenticate: Basic realm=\"%s\"\\r\\n\\r\\n' % realm)\n        opener.add_handler(digest_handler)\n        opener.add_handler(basic_handler)\n        opener.add_handler(http_handler)\n        opener._maybe_reindex_handlers()\n\n        # check basic auth isn't blocked by digest handler failing\n        self._test_basic_auth(\n            opener,\n            basic_handler,\n            \"Authorization\",\n            realm,\n            http_handler,\n            password_manager,\n            \"http://acme.example.com/protected\",\n            \"http://acme.example.com/protected\", )\n        # check digest was tried before basic (twice, because\n        # _test_basic_auth called .open() twice)\n        self.assertEqual(opener.recorded, [\"digest\", \"basic\"] * 2)\n\n    def _test_basic_auth(self, opener, auth_handler, auth_header, realm,\n                         http_handler, password_manager, request_url,\n                         protected_url):\n        import base64\n        user, password = \"wile\", \"coyote\"\n\n        # .add_password() fed through to password manager\n        auth_handler.add_password(realm, request_url, user, password)\n        self.assertEqual(realm, password_manager.realm)\n        self.assertEqual(request_url, password_manager.url)\n        self.assertEqual(user, password_manager.user)\n        self.assertEqual(password, password_manager.password)\n\n        opener.open(request_url)\n\n        # should have asked the password manager for the username/password\n        self.assertEqual(password_manager.target_realm, realm)\n        self.assertEqual(password_manager.target_url, protected_url)\n\n        # expect one request without authorization, then one with\n        self.assertEqual(len(http_handler.requests), 2)\n        self.assertFalse(http_handler.requests[0].has_header(auth_header))\n        userpass = ('%s:%s' % (user, password)).encode('utf-8')\n        auth_hdr_value = b'Basic ' + base64.b64encode(userpass).strip()\n        self.assertEqual(http_handler.requests[1].get_header(auth_header),\n                         auth_hdr_value.decode('ascii'))\n\n        # if the password manager can't find a password, the handler won't\n        # handle the HTTP auth error\n        password_manager.user = password_manager.password = None\n        http_handler.reset()\n        opener.open(request_url)\n        self.assertEqual(len(http_handler.requests), 1)\n        self.assertFalse(http_handler.requests[0].has_header(auth_header))\n\n\nclass HeadParserTests(unittest.TestCase):\n    def test(self):\n        from mechanize import HTTPEquivParser\n        htmls = [\n            (\n                b\"\"\"<meta http-equiv=refresh content=\"1; http://example.com/\">\n                \"\"\", [(b\"refresh\", b\"1; http://example.com/\")]),\n\n            (\n                b\"\"\"\n                <html><head><title>\\xea</title>\n                <meta http-equiv=\"refresh\" content=\"1; http://example.com/\">\n                <meta name=\"spam\" content=\"eggs\">\n                <meta content=\"b&bsol;ar\" http-equiv=\"f&Newline;oo\">\n                <p> <!-- p is not allowed in head, so parsing should stop -->\n                <meta http-equiv=\"moo\" content=\"cow\">\n                </html>\n                \"\"\",\n                [\n                    (b\"refresh\", b\"1; http://example.com/\"),\n                    (b\"f\\noo\", b\"b\\\\ar\")\n                ]),\n\n            (\n                b\"\"\"<meta http-equiv=\"refresh\">\n                \"\"\", []),\n\n        ]\n        for html, result in htmls:\n            headers = HTTPEquivParser(html)()\n            self.assertEqual(result, headers)\n\n\nclass A:\n    def a(self):\n        pass\n\n\nclass B(A):\n    def a(self):\n        pass\n\n    def b(self):\n        pass\n\n\nclass C(A):\n    def c(self):\n        pass\n\n\nclass D(C, B):\n    def a(self):\n        pass\n\n    def d(self):\n        pass\n\n\nclass FunctionTests(unittest.TestCase):\n    def test_build_opener(self):\n        class MyHTTPHandler(HTTPHandler):\n            pass\n\n        class FooHandler(mechanize.BaseHandler):\n            def foo_open(self):\n                pass\n\n        class BarHandler(mechanize.BaseHandler):\n            def bar_open(self):\n                pass\n\n        o = build_opener(FooHandler, BarHandler)\n        self.opener_has_handler(o, FooHandler)\n        self.opener_has_handler(o, BarHandler)\n\n        # can take a mix of classes and instances\n        o = build_opener(FooHandler, BarHandler())\n        self.opener_has_handler(o, FooHandler)\n        self.opener_has_handler(o, BarHandler)\n\n        # subclasses of default handlers override default handlers\n        o = build_opener(MyHTTPHandler)\n        self.opener_has_handler(o, MyHTTPHandler)\n\n        # a particular case of overriding: default handlers can be passed\n        # in explicitly\n        o = build_opener()\n        self.opener_has_handler(o, HTTPHandler)\n        o = build_opener(HTTPHandler)\n        self.opener_has_handler(o, HTTPHandler)\n        o = build_opener(HTTPHandler())\n        self.opener_has_handler(o, HTTPHandler)\n\n        # Issue2670: multiple handlers sharing the same base class\n        class MyOtherHTTPHandler(HTTPHandler):\n            pass\n\n        o = build_opener(MyHTTPHandler, MyOtherHTTPHandler)\n        self.opener_has_handler(o, MyHTTPHandler)\n        self.opener_has_handler(o, MyOtherHTTPHandler)\n\n    def opener_has_handler(self, opener, handler_class):\n        for h in opener.handlers:\n            if h.__class__ == handler_class:\n                break\n        else:\n            self.assertTrue(False)\n\n\nclass RequestTests(unittest.TestCase):\n    def setUp(self):\n        self.get = Request(\"http://www.python.org/~jeremy/\")\n        self.post = Request(\n            \"http://www.python.org/~jeremy/\",\n            \"data\",\n            headers={\"X-Test\": \"test\"})\n\n    def test_method(self):\n        self.assertEqual(\"POST\", self.post.get_method())\n        self.assertEqual(\"GET\", self.get.get_method())\n\n    def test_add_data(self):\n        self.assertTrue(not self.get.has_data())\n        self.assertEqual(\"GET\", self.get.get_method())\n        self.get.add_data(\"spam\")\n        self.assertTrue(self.get.has_data())\n        self.assertEqual(\"POST\", self.get.get_method())\n\n    def test_get_full_url(self):\n        self.assertEqual(\"http://www.python.org/%7Ejeremy/\",\n                         self.get.get_full_url())\n\n    def test_selector(self):\n        self.assertEqual(\"/%7Ejeremy/\", self.get.get_selector())\n        req = Request(\"http://www.python.org/\")\n        self.assertEqual(\"/\", req.get_selector())\n\n    def test_normalize_url(self):\n        def t(x, expected=None):\n            self.assertEqual(normalize_url(x), expected or x)\n\n        t('https://simple.com/moo%7Ese')\n        t('https://ex.com/Sp\u00f6rt', 'https://ex.com/Sp%C3%B6rt')\n        t('https://ex.com/Sp%C3%B6rt')\n\n    def test_get_type(self):\n        self.assertEqual(\"http\", self.get.get_type())\n\n    def test_get_host(self):\n        self.assertEqual(\"www.python.org\", self.get.get_host())\n\n    def test_get_host_unquote(self):\n        req = Request(\"http://www.%70ython.org/\")\n        self.assertEqual(\"www.python.org\", req.get_host())\n\n    def test_proxy(self):\n        self.assertTrue(not self.get.has_proxy())\n        self.get.set_proxy(\"www.perl.org\", \"http\")\n        self.assertTrue(self.get.has_proxy())\n        self.assertEqual(\"www.python.org\", self.get.get_origin_req_host())\n        self.assertEqual(\"www.perl.org\", self.get.get_host())\n\n    def test_data(self):\n        r = Request('https://example.com', data={'a': 1})\n        self.assertEqual(r.get_method(), 'POST')\n        self.assertEqual(r.get_data(), 'a=1')\n        r = Request('https://example.com', data={'a': 1}, method='GET')\n        self.assertEqual(r.get_method(), 'GET')\n        self.assertEqual(r.get_data(), None)\n        self.assertEqual(r.get_full_url(), 'https://example.com?a=1')\n\n\nif __name__ == \"__main__\":\n    import doctest\n    doctest.testmod()\n    unittest.main()\n"], "fixing_code": ["\"\"\"Fork of urllib2.\n\nWhen reading this, don't assume that all code in here is reachable.  Code in\nthe rest of mechanize may be used instead.\n\nCopyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009 Python\nSoftware Foundation; All Rights Reserved\n\nCopyright 2002-2009 John J Lee <jjl@pobox.com>\n\nThis code is free software; you can redistribute it and/or modify it\nunder the terms of the BSD or ZPL 2.1 licenses (see the file\nLICENSE included with the distribution).\n\n\"\"\"\n\n# XXX issues:\n# If an authentication error handler that tries to perform\n# authentication for some reason but fails, how should the error be\n# signalled?  The client needs to know the HTTP error code.  But if\n# the handler knows that the problem was, e.g., that it didn't know\n# that hash algo that requested in the challenge, it would be good to\n# pass that information along to the client, too.\n# ftp errors aren't handled cleanly\n# check digest against correct (i.e. non-apache) implementation\n\n# Possible extensions:\n# complex proxies  XXX not sure what exactly was meant by this\n# abstract factory for opener\n\nfrom __future__ import absolute_import\n\nimport base64\nimport bisect\nimport copy\nimport hashlib\nimport logging\nimport os\nimport platform\nimport posixpath\nimport re\nimport socket\nimport sys\nimport time\nfrom collections import OrderedDict\nfrom functools import partial\nfrom io import BufferedReader, BytesIO\n\nfrom . import _rfc3986\nfrom ._clientcookie import CookieJar\nfrom ._headersutil import normalize_header_name\nfrom ._response import closeable_response\nfrom .polyglot import (HTTPConnection, HTTPError, HTTPSConnection, URLError,\n                       as_unicode, create_response_info, ftpwrapper,\n                       getproxies, is_class, is_mapping, is_py2, is_string,\n                       iteritems, map, raise_with_traceback, splitattr,\n                       splitpasswd, splitport, splittype, splituser,\n                       splitvalue, unquote, unwrap, url2pathname,\n                       urllib_proxy_bypass, urllib_splithost, urlparse,\n                       urlsplit, urlunparse)\n\n\ndef sha1_digest(data):\n    if not isinstance(data, bytes):\n        data = data.encode('utf-8')\n    return hashlib.sha1(data).hexdigest()\n\n\ndef md5_digest(data):\n    if not isinstance(data, bytes):\n        data = data.encode('utf-8')\n    return hashlib.md5(data).hexdigest()\n\n\nif platform.python_implementation() == 'PyPy':\n    def create_readline_wrapper(fh):\n        fh.recv = fh.read\n        if not hasattr(fh, '_drop'):\n            fh._drop = lambda: None\n            fh._reuse = lambda: None\n        return socket._fileobject(fh, close=True)\nelse:\n    def create_readline_wrapper(fh):\n        fh.recv = fh.read\n        if is_py2:\n            ans = socket._fileobject(fh, close=True)\n        else:\n            fh.recv_into = fh.readinto\n            fh._decref_socketios = lambda: None\n            ans = BufferedReader(socket.SocketIO(fh, 'r'))\n        return ans\n\n\nsplithost = urllib_splithost\n\n\n# used in User-Agent header sent\n__version__ = sys.version[:3]\n\n_opener = None\n\n\ndef urlopen(url, data=None):\n    global _opener\n    if _opener is None:\n        _opener = build_opener()\n    return _opener._open(url, data)\n\n\ndef install_opener(opener):\n    global _opener\n    _opener = opener\n\n\n# copied from cookielib.py\n_cut_port_re = re.compile(r\":\\d+$\")\n\n\ndef request_host(request):\n    \"\"\"Return request-host, as defined by RFC 2965.\n\n    Variation from RFC: returned value is lowercased, for convenient\n    comparison.\n\n    \"\"\"\n    url = request.get_full_url()\n    host = urlparse(url)[1]\n    if host == \"\":\n        host = request.get_header(\"Host\", \"\")\n\n    # remove port, if present\n    host = _cut_port_re.sub(\"\", host, 1)\n    return host.lower()\n\n\nPERCENT_RE = re.compile(b\"%[a-fA-F0-9]{2}\")\nZONE_ID_CHARS = set(bytearray(\n    b\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\" b\"abcdefghijklmnopqrstuvwxyz\" b\"0123456789._!-\"\n))\nUSERINFO_CHARS = ZONE_ID_CHARS | set(bytearray(b\"$&'()*+,;=:\"))\nPATH_CHARS = USERINFO_CHARS | set(bytearray(b'@/'))\nQUERY_CHARS = FRAGMENT_CHARS = PATH_CHARS | {ord(b\"?\")}\n\n\ndef fix_invalid_bytes_in_url_component(component, allowed_chars=PATH_CHARS):\n    if not component:\n        return component\n    is_bytes = isinstance(component, bytes)\n    if not is_bytes:\n        component = component.encode('utf-8', 'surrogatepass')\n    percent_encodings = PERCENT_RE.findall(component)\n    for enc in percent_encodings:\n        if not enc.isupper():\n            component = component.replace(enc, enc.upper())\n    is_percent_encoded = len(percent_encodings) == component.count(b\"%\")\n    encoded_component = bytearray()\n    percent = ord('%')\n    for byte_ord in bytearray(component):\n        if (is_percent_encoded and byte_ord == percent) or (byte_ord < 128 and byte_ord in allowed_chars):\n            encoded_component.append(byte_ord)\n            continue\n        encoded_component.extend(b\"%\" + (hex(byte_ord)[2:].encode().zfill(2).upper()))\n    encoded_component = bytes(encoded_component)\n    if not is_bytes:\n        encoded_component = encoded_component.decode('utf-8')\n    return encoded_component\n\n\ndef normalize_url(url):\n    parsed = urlparse(url)\n    netloc = parsed.netloc\n    if not isinstance(netloc, bytes) and netloc:\n        def safe_encode(label):\n            try:\n                return label.encode('idna').decode('ascii')\n            except ValueError:\n                return label.encode('ascii', 'replace').decode('ascii')\n        netloc = u'.'.join(map(safe_encode, netloc.split(u'.')))\n\n    return urlunparse(parsed._replace(\n        path=fix_invalid_bytes_in_url_component(parsed.path), netloc=netloc,\n        query=fix_invalid_bytes_in_url_component(parsed.query, QUERY_CHARS),\n        fragment=fix_invalid_bytes_in_url_component(parsed.fragment, FRAGMENT_CHARS),\n    ))\n\n\nclass Request:\n\n    def __init__(self, url, data=None, headers={},\n                 origin_req_host=None, unverifiable=False, method=None):\n        # unwrap('<URL:type://host/path>') --> 'type://host/path'\n        self.__original = normalize_url(unwrap(url))\n        self.type = None\n        self._method = method and str(method)\n        # self.__r_type is what's left after doing the splittype\n        self.host = None\n        self.port = None\n        self._tunnel_host = None\n        self.data = data\n        self.headers = OrderedDict()\n        for key, value in iteritems(headers):\n            self.add_header(key, value)\n        self.unredirected_hdrs = OrderedDict()\n        if origin_req_host is None:\n            origin_req_host = request_host(self)\n        self.origin_req_host = origin_req_host\n        self.unverifiable = unverifiable\n        try:\n            self.get_host()  # in py3 cookiejar expect self.host to be not None\n        except Exception:\n            self.host = None\n\n    def __getattr__(self, attr):\n        # XXX this is a fallback mechanism to guard against these\n        # methods getting called in a non-standard order.  this may be\n        # too complicated and/or unnecessary.\n        # XXX should the __r_XXX attributes be public?\n        if attr[:12] == '_Request__r_':\n            name = attr[12:]\n            if hasattr(Request, 'get_' + name):\n                getattr(self, 'get_' + name)()\n                return getattr(self, attr)\n        raise AttributeError(attr)\n\n    def get_method(self):\n        ' The method used for HTTP requests '\n        if self._method is None:\n            return \"POST\" if self.has_data() else 'GET'\n        return self._method\n\n    # XXX these helper methods are lame\n\n    def set_data(self, data):\n        ' Set the data (a bytestring) to be sent with this request '\n        self.data = data\n    add_data = set_data\n\n    def has_data(self):\n        ' True iff there is some data to be sent with this request '\n        return self.data is not None\n\n    def get_data(self):\n        ' The data to be sent with this request '\n        return self.data\n\n    def get_full_url(self):\n        return self.__original\n\n    @property\n    def full_url(self):\n        # In python 3 this is a deleteable and settable property, which when\n        # deleted gets set to None. But this interface does not seem to be used\n        # by any stdlib code, so this should be sufficient.\n        return self.__original\n\n    def get_type(self):\n        if self.type is None:\n            self.type, self.__r_type = splittype(self.__original)\n            if self.type is None:\n                raise ValueError(\"unknown url type: %s\" % self.__original)\n        return self.type\n\n    def get_host(self):\n        if self.host is None:\n            self.host, self.__r_host = splithost(self.__r_type)\n            if self.host:\n                self.host = unquote(self.host)\n        return self.host\n\n    def get_selector(self):\n        scheme, authority, path, query, fragment = _rfc3986.urlsplit(\n            self.__r_host)\n        if path == \"\":\n            path = \"/\"  # RFC 2616, section 3.2.2\n        fragment = None  # RFC 3986, section 3.5\n        return _rfc3986.urlunsplit([scheme, authority, path, query, fragment])\n\n    def set_proxy(self, host, type):\n        orig_host = self.get_host()\n        if self.get_type() == 'https' and not self._tunnel_host:\n            self._tunnel_host = orig_host\n        else:\n            self.type = type\n            self.__r_host = self.__original\n\n        self.host = host\n\n    def has_proxy(self):\n        \"\"\"Private method.\"\"\"\n        # has non-HTTPS proxy\n        return self.__r_host == self.__original\n\n    def get_origin_req_host(self):\n        return self.origin_req_host\n\n    def is_unverifiable(self):\n        return self.unverifiable\n\n    def add_header(self, key, val=None):\n        ''' Add the specified header, replacing existing one, if needed. If val\n        is None, remove the header. '''\n        # useful for something like authentication\n        key = normalize_header_name(key)\n        if val is None:\n            self.headers.pop(key, None)\n        else:\n            self.headers[key] = val\n\n    def add_unredirected_header(self, key, val):\n        ''' Same as :meth:`add_header()` except that this header will not\n        be sent for redirected requests. '''\n        key = normalize_header_name(key)\n        if val is None:\n            self.unredirected_hdrs.pop(key, None)\n        else:\n            self.unredirected_hdrs[key] = val\n\n    def has_header(self, header_name):\n        ''' Check if the specified header is present '''\n        header_name = normalize_header_name(header_name)\n        return (header_name in self.headers or\n                header_name in self.unredirected_hdrs)\n\n    def get_header(self, header_name, default=None):\n        ''' Get the value of the specified header. If absent, return `default`\n        '''\n        header_name = normalize_header_name(header_name)\n        return self.headers.get(\n            header_name,\n            self.unredirected_hdrs.get(header_name, default))\n\n    def header_items(self):\n        ''' Get a copy of all headers for this request as a list of 2-tuples\n        '''\n        hdrs = self.unredirected_hdrs.copy()\n        hdrs.update(self.headers)\n        return list(iteritems(hdrs))\n\n\nclass OpenerDirector(object):\n\n    def __init__(self):\n        client_version = \"Python-urllib/%s\" % __version__\n        self.addheaders = [('User-agent', client_version)]\n        self.finalize_request_headers = None\n        # manage the individual handlers\n        self.handlers = []\n        self.handle_open = {}\n        self.handle_error = {}\n        self.process_response = {}\n        self.process_request = {}\n\n    def add_handler(self, handler):\n        if not hasattr(handler, \"add_parent\"):\n            raise TypeError(\"expected BaseHandler instance, got %r\" %\n                            type(handler))\n\n        added = False\n        for meth in dir(handler):\n            if meth in [\"redirect_request\", \"do_open\", \"proxy_open\"]:\n                # oops, coincidental match\n                continue\n\n            i = meth.find(\"_\")\n            protocol = meth[:i]\n            condition = meth[i + 1:]\n\n            if condition.startswith(\"error\"):\n                j = condition.find(\"_\") + i + 1\n                kind = meth[j + 1:]\n                try:\n                    kind = int(kind)\n                except ValueError:\n                    pass\n                lookup = self.handle_error.get(protocol, {})\n                self.handle_error[protocol] = lookup\n            elif condition == \"open\":\n                kind = protocol\n                lookup = self.handle_open\n            elif condition == \"response\":\n                kind = protocol\n                lookup = self.process_response\n            elif condition == \"request\":\n                kind = protocol\n                lookup = self.process_request\n            else:\n                continue\n\n            handlers = lookup.setdefault(kind, [])\n            if handlers:\n                bisect.insort(handlers, handler)\n            else:\n                handlers.append(handler)\n            added = True\n\n        if added:\n            # the handlers must work in an specific order, the order\n            # is specified in a Handler attribute\n            bisect.insort(self.handlers, handler)\n            handler.add_parent(self)\n\n    def close(self):\n        # Only exists for backwards compatibility.\n        pass\n\n    def _call_chain(self, chain, kind, meth_name, *args):\n        # Handlers raise an exception if no one else should try to handle\n        # the request, or return None if they can't but another handler\n        # could.  Otherwise, they return the response.\n        handlers = chain.get(kind, ())\n        for handler in handlers:\n            func = getattr(handler, meth_name)\n\n            result = func(*args)\n            if result is not None:\n                return result\n\n    def _open(self, req, data=None):\n        result = self._call_chain(self.handle_open, 'default',\n                                  'default_open', req)\n        if result:\n            return result\n\n        protocol = req.get_type()\n        result = self._call_chain(self.handle_open, protocol, protocol +\n                                  '_open', req)\n        if result:\n            return result\n\n        return self._call_chain(self.handle_open, 'unknown',\n                                'unknown_open', req)\n\n    def error(self, proto, *args):\n        if proto in ('http', 'https'):\n            # XXX http[s] protocols are special-cased\n            # https is not different than http\n            dict = self.handle_error['http']\n            proto = args[2]  # YUCK!\n            meth_name = 'http_error_%s' % proto\n            http_err = 1\n            orig_args = args\n        else:\n            dict = self.handle_error\n            meth_name = proto + '_error'\n            http_err = 0\n        args = (dict, proto, meth_name) + args\n        result = self._call_chain(*args)\n        if result:\n            return result\n\n        if http_err:\n            args = (dict, 'default', 'http_error_default') + orig_args\n            return self._call_chain(*args)\n\n# XXX probably also want an abstract factory that knows when it makes\n# sense to skip a superclass in favor of a subclass and when it might\n# make sense to include both\n\n\ndef build_opener(*handlers):\n    \"\"\"Create an opener object from a list of handlers.\n\n    The opener will use several default handlers, including support\n    for HTTP, FTP and when applicable, HTTPS.\n\n    If any of the handlers passed as arguments are subclasses of the\n    default handlers, the default handlers will not be used.\n    \"\"\"\n    opener = OpenerDirector()\n    default_classes = [ProxyHandler, UnknownHandler, HTTPHandler,\n                       HTTPDefaultErrorHandler, HTTPRedirectHandler,\n                       FTPHandler, FileHandler, HTTPErrorProcessor]\n    default_classes.append(HTTPSHandler)\n    skip = set()\n    for klass in default_classes:\n        for check in handlers:\n            if is_class(check):\n                if issubclass(check, klass):\n                    skip.add(klass)\n            elif isinstance(check, klass):\n                skip.add(klass)\n    for klass in skip:\n        default_classes.remove(klass)\n\n    for klass in default_classes:\n        opener.add_handler(klass())\n\n    for h in handlers:\n        if is_class(h):\n            h = h()\n        opener.add_handler(h)\n    return opener\n\n\nclass BaseHandler:\n    handler_order = 500\n\n    def add_parent(self, parent):\n        self.parent = parent\n\n    def close(self):\n        # Only exists for backwards compatibility\n        pass\n\n    def __lt__(self, other):\n        return self.handler_order < getattr(\n                other, 'handler_order', sys.maxsize)\n\n    def __copy__(self):\n        return self.__class__()\n\n\nclass HTTPErrorProcessor(BaseHandler):\n    \"\"\"Process HTTP error responses.\n\n    The purpose of this handler is to to allow other response processors a\n    look-in by removing the call to parent.error() from\n    AbstractHTTPHandler.\n\n    For non-2xx error codes, this just passes the job on to the\n    Handler.<proto>_error_<code> methods, via the OpenerDirector.error method.\n    Eventually, HTTPDefaultErrorHandler will raise an HTTPError if no other\n    handler handles the error.\n\n    \"\"\"\n    handler_order = 1000  # after all other processors\n\n    def http_response(self, request, response):\n        code, msg, hdrs = response.code, response.msg, response.info()\n\n        # According to RFC 2616, \"2xx\" code indicates that the client's\n        # request was successfully received, understood, and accepted.\n        if not (200 <= code < 300):\n            # hardcoded http is NOT a bug\n            response = self.parent.error(\n                'http', request, response, code, msg, hdrs)\n\n        return response\n\n    https_response = http_response\n\n\nclass HTTPDefaultErrorHandler(BaseHandler):\n\n    def http_error_default(self, req, fp, code, msg, hdrs):\n        # why these error methods took the code, msg, headers args in the first\n        # place rather than a response object, I don't know, but to avoid\n        # multiple wrapping, we're discarding them\n\n        if isinstance(fp, HTTPError):\n            response = fp\n        else:\n            response = HTTPError(\n                req.get_full_url(), code, msg, hdrs, fp)\n        assert code == response.code\n        assert msg == response.msg\n        assert hdrs == response.hdrs\n        raise response\n\n\nclass HTTPRedirectHandler(BaseHandler):\n    # maximum number of redirections to any single URL\n    # this is needed because of the state that cookies introduce\n    max_repeats = 4\n    # maximum total number of redirections (regardless of URL) before\n    # assuming we're in a loop\n    max_redirections = 10\n\n    # Implementation notes:\n\n    # To avoid the server sending us into an infinite loop, the request\n    # object needs to track what URLs we have already seen.  Do this by\n    # adding a handler-specific attribute to the Request object.  The value\n    # of the dict is used to count the number of times the same URL has\n    # been visited.  This is needed because visiting the same URL twice\n    # does not necessarily imply a loop, thanks to state introduced by\n    # cookies.\n\n    # Always unhandled redirection codes:\n    # 300 Multiple Choices: should not handle this here.\n    # 304 Not Modified: no need to handle here: only of interest to caches\n    #     that do conditional GETs\n    # 305 Use Proxy: probably not worth dealing with here\n    # 306 Unused: what was this for in the previous versions of protocol??\n\n    def redirect_request(self, req, fp, code, msg, headers, newurl):\n        \"\"\"Return a Request or None in response to a redirect.\n\n        This is called by the http_error_30x methods when a\n        redirection response is received.  If a redirection should\n        take place, return a new Request to allow http_error_30x to\n        perform the redirect.  Otherwise, raise HTTPError if no-one\n        else should try to handle this url.  Return None if you can't\n        but another Handler might.\n        \"\"\"\n        from ._request import Request\n        m = req.get_method()\n        if (code in (301, 302, 303, 307, \"refresh\") and m in (\"GET\", \"HEAD\")\n                or code in (301, 302, 303, \"refresh\") and m == \"POST\"):\n            # Strictly (according to RFC 2616), 301 or 302 in response\n            # to a POST MUST NOT cause a redirection without confirmation\n            # from the user (of urllib2, in this case).  In practice,\n            # essentially all clients do redirect in this case, so we do\n            # the same.\n            # TODO: really refresh redirections should be visiting; tricky to\n            # fix\n            new = Request(\n                newurl,\n                headers=req.headers,\n                origin_req_host=req.get_origin_req_host(),\n                unverifiable=True,\n                visit=False,\n                timeout=req.timeout)\n            new._origin_req = getattr(req, \"_origin_req\", req)\n            return new\n        else:\n            raise HTTPError(req.get_full_url(), code, msg, headers, fp)\n\n    def http_error_302(self, req, fp, code, msg, headers):\n        # Some servers (incorrectly) return multiple Location headers\n        # (so probably same goes for URI).  Use first header.\n        if 'location' in headers:\n            newurl = headers.getheaders('location')[0]\n        elif 'uri' in headers:\n            newurl = headers.getheaders('uri')[0]\n        else:\n            return\n        newurl = _rfc3986.clean_url(newurl)\n        newurl = _rfc3986.urljoin(req.get_full_url(), newurl)\n\n        # XXX Probably want to forget about the state of the current\n        # request, although that might interact poorly with other\n        # handlers that also use handler-specific request attributes\n        new = self.redirect_request(req, fp, code, msg, headers, newurl)\n        if new is None:\n            return\n\n        # loop detection\n        # .redirect_dict has a key url if url was previously visited.\n        if hasattr(req, 'redirect_dict'):\n            visited = new.redirect_dict = req.redirect_dict\n            if (visited.get(newurl, 0) >= self.max_repeats or\n                    len(visited) >= self.max_redirections):\n                raise HTTPError(req.get_full_url(), code,\n                                self.inf_msg + msg, headers, fp)\n        else:\n            visited = new.redirect_dict = req.redirect_dict = {}\n        visited[newurl] = visited.get(newurl, 0) + 1\n\n        # Don't close the fp until we are sure that we won't use it\n        # with HTTPError.\n        fp.read()\n        fp.close()\n\n        return self.parent.open(new)\n\n    http_error_301 = http_error_303 = http_error_307 = http_error_302\n    http_error_refresh = http_error_302\n\n    inf_msg = \"The HTTP server returned a redirect error that would \" \\\n              \"lead to an infinite loop.\\n\" \\\n              \"The last 30x error message was:\\n\"\n\n\ndef _parse_proxy(proxy):\n    \"\"\"Return (scheme, user, password, host/port) given a URL or an authority.\n\n    If a URL is supplied, it must have an authority (host:port) component.\n    According to RFC 3986, having an authority component means the URL must\n    have two slashes after the scheme:\n\n    >>> _parse_proxy('file:/ftp.example.com/')\n    Traceback (most recent call last):\n    ValueError: proxy URL with no authority: 'file:/ftp.example.com/'\n\n    The first three items of the returned tuple may be None.\n\n    Examples of authority parsing:\n\n    >>> _parse_proxy('proxy.example.com')\n    (None, None, None, 'proxy.example.com')\n    >>> _parse_proxy('proxy.example.com:3128')\n    (None, None, None, 'proxy.example.com:3128')\n\n    The authority component may optionally include userinfo (assumed to be\n    username:password):\n\n    >>> _parse_proxy('joe:password@proxy.example.com')\n    (None, 'joe', 'password', 'proxy.example.com')\n    >>> _parse_proxy('joe:password@proxy.example.com:3128')\n    (None, 'joe', 'password', 'proxy.example.com:3128')\n\n    Same examples, but with URLs instead:\n\n    >>> _parse_proxy('http://proxy.example.com/')\n    ('http', None, None, 'proxy.example.com')\n    >>> _parse_proxy('http://proxy.example.com:3128/')\n    ('http', None, None, 'proxy.example.com:3128')\n    >>> _parse_proxy('http://joe:password@proxy.example.com/')\n    ('http', 'joe', 'password', 'proxy.example.com')\n    >>> _parse_proxy('http://joe:password@proxy.example.com:3128')\n    ('http', 'joe', 'password', 'proxy.example.com:3128')\n\n    Everything after the authority is ignored:\n\n    >>> _parse_proxy('ftp://joe:password@proxy.example.com/rubbish:3128')\n    ('ftp', 'joe', 'password', 'proxy.example.com')\n\n    Test for no trailing '/' case:\n\n    >>> _parse_proxy('http://joe:password@proxy.example.com')\n    ('http', 'joe', 'password', 'proxy.example.com')\n\n    \"\"\"\n    scheme, r_scheme = splittype(proxy)\n    if not r_scheme.startswith(\"/\"):\n        # authority\n        scheme = None\n        authority = proxy\n    else:\n        # URL\n        if not r_scheme.startswith(\"//\"):\n            raise ValueError(\"proxy URL with no authority: %r\" % proxy)\n        # We have an authority, so for RFC 3986-compliant URLs (by ss 3.\n        # and 3.3.), path is empty or starts with '/'\n        end = r_scheme.find(\"/\", 2)\n        if end == -1:\n            end = None\n        authority = r_scheme[2:end]\n    userinfo, hostport = splituser(authority)\n    if userinfo is not None:\n        user, password = splitpasswd(userinfo)\n    else:\n        user = password = None\n    return scheme, user, password, hostport\n\n\nclass ProxyHandler(BaseHandler):\n    # Proxies must be in front\n    handler_order = 100\n\n    def __init__(self, proxies=None, proxy_bypass=None):\n        if proxies is None:\n            proxies = getproxies()\n\n        assert is_mapping(proxies), \"proxies must be a mapping\"\n        self.proxies = proxies\n        for type, url in iteritems(proxies):\n            setattr(self, '%s_open' % type,\n                    lambda r, proxy=url, type=type, meth=self.proxy_open:\n                    meth(r, proxy, type))\n        if proxy_bypass is None:\n            proxy_bypass = urllib_proxy_bypass\n        self._proxy_bypass = proxy_bypass\n\n    def proxy_open(self, req, proxy, type):\n        orig_type = req.get_type()\n        proxy_type, user, password, hostport = _parse_proxy(proxy)\n\n        if proxy_type is None:\n            proxy_type = orig_type\n\n        if req.get_host() and self._proxy_bypass(req.get_host()):\n            return None\n\n        if user and password:\n            user_pass = '%s:%s' % (unquote(user), unquote(password))\n            if not isinstance(user_pass, bytes):\n                user_pass = user_pass.encode('utf-8')\n            creds = base64.b64encode(user_pass).strip()\n            if isinstance(creds, bytes):\n                creds = creds.decode('ascii')\n            req.add_header('Proxy-authorization', 'Basic ' + creds)\n        hostport = unquote(hostport)\n        req.set_proxy(hostport, proxy_type)\n        if orig_type == proxy_type or orig_type == 'https':\n            # let other handlers take care of it\n            return None\n        else:\n            # need to start over, because the other handlers don't\n            # grok the proxy's URL type\n            # e.g. if we have a constructor arg proxies like so:\n            # {'http': 'ftp://proxy.example.com'}, we may end up turning\n            # a request for http://acme.example.com/a into one for\n            # ftp://proxy.example.com/a\n            return self.parent.open(req)\n\n    def __copy__(self):\n        return ProxyHandler(self.proxies.copy(), self._proxy_bypass)\n\n\nclass HTTPPasswordMgr:\n\n    def __init__(self):\n        self.passwd = {}\n\n    def add_password(self, realm, uri, user, passwd):\n        # uri could be a single URI or a sequence\n        if is_string(uri):\n            uri = [uri]\n        if realm not in self.passwd:\n            self.passwd[realm] = {}\n        for default_port in True, False:\n            reduced_uri = tuple(\n                [self.reduce_uri(u, default_port) for u in uri])\n            self.passwd[realm][reduced_uri] = (user, passwd)\n\n    def find_user_password(self, realm, authuri):\n        domains = self.passwd.get(realm, {})\n        for default_port in True, False:\n            reduced_authuri = self.reduce_uri(authuri, default_port)\n            for uris, authinfo in iteritems(domains):\n                for uri in uris:\n                    if self.is_suburi(uri, reduced_authuri):\n                        return authinfo\n        return None, None\n\n    def reduce_uri(self, uri, default_port=True):\n        \"\"\"Accept authority or URI and extract only the authority and path.\"\"\"\n        # note HTTP URLs do not have a userinfo component\n        parts = urlsplit(uri)\n        if parts[1]:\n            # URI\n            scheme = parts[0]\n            authority = parts[1]\n            path = parts[2] or '/'\n        else:\n            # host or host:port\n            scheme = None\n            authority = uri\n            path = '/'\n        host, port = splitport(authority)\n        if default_port and port is None and scheme is not None:\n            dport = {\"http\": 80,\n                     \"https\": 443,\n                     }.get(scheme)\n            if dport is not None:\n                authority = \"%s:%d\" % (host, dport)\n        return authority, path\n\n    def is_suburi(self, base, test):\n        \"\"\"Check if test is below base in a URI tree\n\n        Both args must be URIs in reduced form.\n        \"\"\"\n        if base == test:\n            return True\n        if base[0] != test[0]:\n            return False\n        common = posixpath.commonprefix((base[1], test[1]))\n        if len(common) == len(base[1]):\n            return True\n        return False\n\n    def __copy__(self):\n        ans = self.__class__()\n        ans.passwd = copy.deepcopy(self.passwd)\n        return ans\n\n\nclass HTTPPasswordMgrWithDefaultRealm(HTTPPasswordMgr):\n\n    def find_user_password(self, realm, authuri):\n        user, password = HTTPPasswordMgr.find_user_password(self, realm,\n                                                            authuri)\n        if user is not None:\n            return user, password\n        return HTTPPasswordMgr.find_user_password(self, None, authuri)\n\n\nclass AbstractBasicAuthHandler:\n\n    # XXX this allows for multiple auth-schemes, but will stupidly pick\n    # the last one with a realm specified.\n\n    # allow for double- and single-quoted realm values\n    # (single quotes are a violation of the RFC, but appear in the wild)\n    rx = re.compile('(?:^|,)'     # start of the string or ','\n                    '[ \\t]*'      # optional whitespaces\n                    '([^ \\t,]+)'  # scheme like \"Basic\"\n                    '[ \\t]+'      # mandatory whitespaces\n                    # realm=xxx\n                    # realm='xxx'\n                    # realm=\"xxx\"\n                    'realm=([\"\\']?)([^\"\\']*)\\\\2',\n                    re.I)\n\n    # XXX could pre-emptively send auth info already accepted (RFC 2617,\n    # end of section 2, and section 1.2 immediately after \"credentials\"\n    # production).\n\n    def __init__(self, password_mgr=None):\n        if password_mgr is None:\n            password_mgr = HTTPPasswordMgr()\n        self.passwd = password_mgr\n        self.add_password = self.passwd.add_password\n\n    def http_error_auth_reqed(self, authreq, host, req, headers):\n        # host may be an authority (without userinfo) or a URL with an\n        # authority\n        # XXX could be multiple headers\n        authreq = headers.get(authreq, None)\n        if authreq:\n            mo = AbstractBasicAuthHandler.rx.search(authreq)\n            if mo:\n                scheme, quote, realm = mo.groups()\n                if scheme.lower() == 'basic':\n                    return self.retry_http_basic_auth(host, req, realm)\n\n    def retry_http_basic_auth(self, host, req, realm):\n        user, pw = self.passwd.find_user_password(realm, host)\n        if pw is not None:\n            raw = \"%s:%s\" % (user, pw)\n            auth = str('Basic %s' % base64.b64encode(\n                    raw.encode('utf-8')).strip().decode('ascii'))\n            if req.get_header(self.auth_header, None) == auth:\n                return None\n            newreq = copy.copy(req)\n            newreq.add_header(self.auth_header, auth)\n            newreq.visit = False\n            return self.parent.open(newreq)\n        else:\n            return None\n\n    def __copy__(self):\n        return self.__class__(self.passwd.__copy__())\n\n\nclass HTTPBasicAuthHandler(AbstractBasicAuthHandler, BaseHandler):\n\n    auth_header = 'Authorization'\n\n    def http_error_401(self, req, fp, code, msg, headers):\n        url = req.get_full_url()\n        return self.http_error_auth_reqed('www-authenticate',\n                                          url, req, headers)\n\n    def __copy__(self):\n        return AbstractBasicAuthHandler.__copy__(self)\n\n\nclass ProxyBasicAuthHandler(AbstractBasicAuthHandler, BaseHandler):\n\n    auth_header = 'Proxy-authorization'\n\n    def http_error_407(self, req, fp, code, msg, headers):\n        # http_error_auth_reqed requires that there is no userinfo component in\n        # authority.  Assume there isn't one, since urllib2 does not (and\n        # should not, RFC 3986 s. 3.2.1) support requests for URLs containing\n        # userinfo.\n        authority = req.get_host()\n        return self.http_error_auth_reqed('proxy-authenticate',\n                                          authority, req, headers)\n\n    def __copy__(self):\n        return AbstractBasicAuthHandler.__copy__(self)\n\n\nrandombytes = os.urandom\n\n\nclass AbstractDigestAuthHandler:\n    # Digest authentication is specified in RFC 2617.\n\n    # XXX The client does not inspect the Authentication-Info header\n    # in a successful response.\n\n    # XXX It should be possible to test this implementation against\n    # a mock server that just generates a static set of challenges.\n\n    # XXX qop=\"auth-int\" supports is shaky\n\n    def __init__(self, passwd=None):\n        if passwd is None:\n            passwd = HTTPPasswordMgr()\n        self.passwd = passwd\n        self.add_password = self.passwd.add_password\n        self.retried = 0\n        self.nonce_count = 0\n        self.last_nonce = None\n\n    def reset_retry_count(self):\n        self.retried = 0\n\n    def http_error_auth_reqed(self, auth_header, host, req, headers):\n        authreq = headers.get(auth_header, None)\n        if self.retried > 5:\n            # Don't fail endlessly - if we failed once, we'll probably\n            # fail a second time. Hm. Unless the Password Manager is\n            # prompting for the information. Crap. This isn't great\n            # but it's better than the current 'repeat until recursion\n            # depth exceeded' approach <wink>\n            raise HTTPError(req.get_full_url(), 401, \"digest auth failed\",\n                            headers, None)\n        else:\n            self.retried += 1\n        if authreq:\n            scheme = authreq.split()[0]\n            if scheme.lower() == 'digest':\n                return self.retry_http_digest_auth(req, authreq)\n\n    def retry_http_digest_auth(self, req, auth):\n        token, challenge = auth.split(' ', 1)\n        chal = parse_keqv_list(parse_http_list(challenge))\n        auth = self.get_authorization(req, chal)\n        if auth:\n            auth_val = 'Digest %s' % auth\n            if req.get_header(self.auth_header, None) == auth_val:\n                return None\n            newreq = copy.copy(req)\n            newreq.add_unredirected_header(self.auth_header, auth_val)\n            newreq.visit = False\n            return self.parent.open(newreq)\n\n    def get_cnonce(self, nonce):\n        # The cnonce-value is an opaque\n        # quoted string value provided by the client and used by both client\n        # and server to avoid chosen plaintext attacks, to provide mutual\n        # authentication, and to provide some message integrity protection.\n        # This isn't a fabulous effort, but it's probably Good Enough.\n        dig = sha1_digest(\"%s:%s:%s:%s\" % (self.nonce_count, nonce,\n                                           time.ctime(), randombytes(8)))\n        return dig[:16]\n\n    def get_authorization(self, req, chal):\n        try:\n            realm = chal['realm']\n            nonce = chal['nonce']\n            qop = chal.get('qop')\n            algorithm = chal.get('algorithm', 'MD5')\n            # mod_digest doesn't send an opaque, even though it isn't\n            # supposed to be optional\n            opaque = chal.get('opaque', None)\n        except KeyError:\n            return None\n\n        H, KD = self.get_algorithm_impls(algorithm)\n        if H is None:\n            return None\n\n        user, pw = self.passwd.find_user_password(realm, req.get_full_url())\n        if user is None:\n            return None\n\n        # XXX not implemented yet\n        if req.has_data():\n            entdig = self.get_entity_digest(req.get_data(), chal)\n        else:\n            entdig = None\n\n        A1 = \"%s:%s:%s\" % (user, realm, pw)\n        A2 = \"%s:%s\" % (req.get_method(),\n                        # XXX selector: what about proxies and full urls\n                        req.get_selector())\n        if qop == 'auth':\n            if nonce == self.last_nonce:\n                self.nonce_count += 1\n            else:\n                self.nonce_count = 1\n                self.last_nonce = nonce\n\n            ncvalue = '%08x' % self.nonce_count\n            cnonce = self.get_cnonce(nonce)\n            noncebit = \"%s:%s:%s:%s:%s\" % (nonce, ncvalue, cnonce, qop, H(A2))\n            respdig = KD(H(A1), noncebit)\n        elif qop is None:\n            respdig = KD(H(A1), \"%s:%s\" % (nonce, H(A2)))\n        else:\n            # XXX handle auth-int.\n            logger = logging.getLogger(\"mechanize.auth\")\n            logger.info(\"digest auth auth-int qop is not supported, not \"\n                        \"handling digest authentication\")\n            return None\n\n        # XXX should the partial digests be encoded too?\n\n        base = 'username=\"%s\", realm=\"%s\", nonce=\"%s\", uri=\"%s\", ' \\\n               'response=\"%s\"' % (user, realm, nonce, req.get_selector(),\n                                  respdig)\n        if opaque:\n            base += ', opaque=\"%s\"' % opaque\n        if entdig:\n            base += ', digest=\"%s\"' % entdig\n        base += ', algorithm=\"%s\"' % algorithm\n        if qop:\n            base += ', qop=auth, nc=%s, cnonce=\"%s\"' % (ncvalue, cnonce)\n        return base\n\n    def get_algorithm_impls(self, algorithm):\n        # algorithm should be case-insensitive according to RFC2617\n        algorithm = algorithm.upper()\n        if algorithm == 'MD5':\n            H = md5_digest\n        elif algorithm == 'SHA':\n            H = sha1_digest\n        # XXX MD5-sess\n        KD = lambda s, d: H(\"%s:%s\" % (s, d))  # noqa\n        return H, KD\n\n    def get_entity_digest(self, data, chal):\n        # XXX not implemented yet\n        return None\n\n    def __copy__(self):\n        return self.__class__(self.passwd.__copy__())\n\n\nclass HTTPDigestAuthHandler(BaseHandler, AbstractDigestAuthHandler):\n    \"\"\"An authentication protocol defined by RFC 2069\n\n    Digest authentication improves on basic authentication because it\n    does not transmit passwords in the clear.\n    \"\"\"\n\n    auth_header = 'Authorization'\n    handler_order = 490  # before Basic auth\n\n    def http_error_401(self, req, fp, code, msg, headers):\n        host = urlparse(req.get_full_url())[1]\n        retry = self.http_error_auth_reqed('www-authenticate',\n                                           host, req, headers)\n        self.reset_retry_count()\n        return retry\n\n    def __copy__(self):\n        return AbstractDigestAuthHandler.__copy__(self)\n\n\nclass ProxyDigestAuthHandler(BaseHandler, AbstractDigestAuthHandler):\n\n    auth_header = 'Proxy-Authorization'\n    handler_order = 490  # before Basic auth\n\n    def http_error_407(self, req, fp, code, msg, headers):\n        host = req.get_host()\n        retry = self.http_error_auth_reqed('proxy-authenticate',\n                                           host, req, headers)\n        self.reset_retry_count()\n        return retry\n\n    def __copy__(self):\n        return AbstractDigestAuthHandler.__copy__(self)\n\n\nclass AbstractHTTPHandler(BaseHandler):\n\n    def __init__(self, debuglevel=0):\n        self._debuglevel = debuglevel\n\n    def set_http_debuglevel(self, level):\n        self._debuglevel = level\n\n    def do_request_(self, request):\n        host = request.get_host()\n        if not host:\n            raise URLError('no host given')\n\n        if request.has_data():  # POST\n            data = request.get_data()\n            if not request.has_header('Content-type'):\n                request.add_unredirected_header(\n                    'Content-type',\n                    'application/x-www-form-urlencoded')\n            if not request.has_header('Content-length'):\n                request.add_unredirected_header(\n                    'Content-length', '%d' % len(data))\n\n        sel_host = host\n        if request.has_proxy():\n            scheme, sel = splittype(request.get_selector())\n            sel_host, sel_path = splithost(sel)\n\n        for name, value in self.parent.addheaders:\n            name = name.capitalize()\n            if not request.has_header(name):\n                request.add_unredirected_header(name, value)\n        if not request.has_header('Host'):\n            request.add_unredirected_header('Host', sel_host)\n\n        return request\n\n    def do_open(self, http_class, req):\n        \"\"\"Return an addinfourl object for the request, using http_class.\n\n        http_class must implement the HTTPConnection API from httplib.\n        The addinfourl return value is a file-like object.  It also\n        has methods and attributes including:\n            - info(): return a HTTPMessage object for the headers\n            - geturl(): return the original request URL\n            - code: HTTP status code\n        \"\"\"\n        host_port = req.get_host()\n        if not host_port:\n            raise URLError('no host given')\n\n        h = http_class(host_port, timeout=req.timeout)\n        h.set_debuglevel(self._debuglevel)\n\n        headers = OrderedDict(req.headers)\n        for key, val in iteritems(req.unredirected_hdrs):\n            headers[key] = val\n        # We want to make an HTTP/1.1 request, but the addinfourl\n        # class isn't prepared to deal with a persistent connection.\n        # It will try to read all remaining data from the socket,\n        # which will block while the server waits for the next request.\n        # So make sure the connection gets closed after the (only)\n        # request.\n        headers[\"Connection\"] = \"close\"\n        # httplib in python 2 needs str() not unicode() for all request\n        # parameters\n        if is_py2:\n            headers = OrderedDict(\n                    (str(name.title()), str(val))\n                    for name, val in iteritems(headers))\n        else:\n            headers = OrderedDict(\n                    (as_unicode(name, 'iso-8859-1').title(),\n                     as_unicode(val, 'iso-8859-1'))\n                    for name, val in iteritems(headers))\n\n        if req._tunnel_host:\n            set_tunnel = h.set_tunnel if hasattr(\n                h, \"set_tunnel\") else h._set_tunnel\n            tunnel_headers = {}\n            proxy_auth_hdr = \"Proxy-Authorization\"\n            if proxy_auth_hdr in headers:\n                tunnel_headers[proxy_auth_hdr] = headers[proxy_auth_hdr]\n                # Proxy-Authorization should not be sent to origin server.\n                del headers[proxy_auth_hdr]\n            set_tunnel(req._tunnel_host, headers=tunnel_headers)\n\n        if self.parent.finalize_request_headers is not None:\n            self.parent.finalize_request_headers(req, headers)\n\n        try:\n            h.request(str(req.get_method()), str(req.get_selector()), req.data,\n                      headers)\n            r = h.getresponse()\n        except socket.error as err:  # XXX what error?\n            raise URLError(err)\n\n        # Pick apart the HTTPResponse object to get the addinfourl\n        # object initialized properly.\n        fp = create_readline_wrapper(r)\n\n        resp = closeable_response(\n            fp, r.msg, req.get_full_url(), r.status, r.reason,\n            getattr(r, 'version', None))\n        return resp\n\n    def __copy__(self):\n        return self.__class__(self._debuglevel)\n\n\nclass HTTPHandler(AbstractHTTPHandler):\n\n    def http_open(self, req):\n        return self.do_open(HTTPConnection, req)\n\n    http_request = AbstractHTTPHandler.do_request_\n\n\nclass HTTPSHandler(AbstractHTTPHandler):\n\n    def __init__(self, client_cert_manager=None):\n        AbstractHTTPHandler.__init__(self)\n        self.client_cert_manager = client_cert_manager\n        self.ssl_context = None\n\n    def https_open(self, req):\n        key_file = cert_file = None\n        if self.client_cert_manager is not None:\n            key_file, cert_file = self.client_cert_manager.find_key_cert(\n                req.get_full_url())\n        if self.ssl_context is None:\n            conn_factory = partial(\n                HTTPSConnection, key_file=key_file,\n                cert_file=cert_file)\n        else:\n            conn_factory = partial(\n                HTTPSConnection, key_file=key_file,\n                cert_file=cert_file, context=self.ssl_context)\n        return self.do_open(conn_factory, req)\n\n    https_request = AbstractHTTPHandler.do_request_\n\n    def __copy__(self):\n        ans = self.__class__(self.client_cert_manager)\n        ans._debuglevel = self._debuglevel\n        ans.ssl_context = self.ssl_context\n        return ans\n\n\nclass HTTPCookieProcessor(BaseHandler):\n    \"\"\"Handle HTTP cookies.\n\n    Public attributes:\n\n    cookiejar: CookieJar instance\n\n    \"\"\"\n\n    def __init__(self, cookiejar=None):\n        if cookiejar is None:\n            cookiejar = CookieJar()\n        self.cookiejar = cookiejar\n\n    def http_request(self, request):\n        self.cookiejar.add_cookie_header(request)\n        return request\n\n    def http_response(self, request, response):\n        self.cookiejar.extract_cookies(response, request)\n        return response\n\n    def __copy__(self):\n        return self.__class__(self.cookiejar)\n\n    https_request = http_request\n    https_response = http_response\n\n\nclass UnknownHandler(BaseHandler):\n\n    def unknown_open(self, req):\n        type = req.get_type()\n        raise URLError('unknown url type: %s' % type)\n\n\ndef parse_keqv_list(ln):\n    \"\"\"Parse list of key=value strings where keys are not duplicated.\"\"\"\n    parsed = {}\n    for elt in ln:\n        k, v = elt.split('=', 1)\n        if v[0:1] == '\"' and v[-1:] == '\"':\n            v = v[1:-1]\n        parsed[k] = v\n    return parsed\n\n\ndef parse_http_list(s):\n    \"\"\"Parse lists as described by RFC 2068 Section 2.\n\n    In particular, parse comma-separated lists where the elements of\n    the list may include quoted-strings.  A quoted-string could\n    contain a comma.  A non-quoted string could have quotes in the\n    middle.  Neither commas nor quotes count if they are escaped.\n    Only double-quotes count, not single-quotes.\n    \"\"\"\n    res = []\n    part = ''\n\n    escape = quote = False\n    for cur in s:\n        if escape:\n            part += cur\n            escape = False\n            continue\n        if quote:\n            if cur == '\\\\':\n                escape = True\n                continue\n            elif cur == '\"':\n                quote = False\n            part += cur\n            continue\n\n        if cur == ',':\n            res.append(part)\n            part = ''\n            continue\n\n        if cur == '\"':\n            quote = True\n\n        part += cur\n\n    # append last part\n    if part:\n        res.append(part)\n\n    return list(filter(None, (part_.strip() for part_ in res)))\n\n\nclass FileHandler(BaseHandler):\n    # Use local file or FTP depending on form of URL\n\n    def file_open(self, req):\n        url = req.get_selector()\n        if url[:2] == '//' and url[2:3] != '/':\n            req.type = 'ftp'\n            return self.parent.open(req)\n        else:\n            return self.open_local_file(req)\n\n    # names for the localhost\n    names = None\n\n    def get_names(self):\n        if FileHandler.names is None:\n            try:\n                FileHandler.names = (socket.gethostbyname('localhost'),\n                                     socket.gethostbyname(socket.gethostname())\n                                     )\n            except socket.gaierror:\n                FileHandler.names = (socket.gethostbyname('localhost'),)\n        return FileHandler.names\n\n    # not entirely sure what the rules are here\n    def open_local_file(self, req):\n        import email.utils as emailutils\n        import mimetypes\n        host = req.get_host()\n        file = req.get_selector()\n        try:\n            localfile = url2pathname(file)\n        except IOError as err:\n            # url2pathname raises this on windows for bad urls\n            raise URLError(err)\n        try:\n            stats = os.stat(localfile)\n            size = stats.st_size\n            modified = emailutils.formatdate(stats.st_mtime, usegmt=True)\n            mtype = mimetypes.guess_type(file)[0]\n            headers = create_response_info(BytesIO(\n                ('Content-type: %s\\nContent-length: %d\\nLast-modified: %s\\n' %\n                    (mtype or 'text/plain', size, modified)).encode(\n                        'iso-8859-1')))\n            if host:\n                host, port = splitport(host)\n            if not host or (\n                    not port and socket.gethostbyname(host) in self.get_names()\n            ):\n                fp = open(localfile, 'rb')\n                return closeable_response(fp, headers, 'file:' + file)\n        except OSError as msg:\n            # urllib2 users shouldn't expect OSErrors coming from urlopen()\n            raise URLError(msg)\n        raise URLError('file not on local host')\n\n\nclass FTPHandler(BaseHandler):\n\n    def ftp_open(self, req):\n        import ftplib\n        import mimetypes\n        host = req.get_host()\n        if not host:\n            raise URLError('ftp error: no host given')\n        host, port = splitport(host)\n        if port is None:\n            port = ftplib.FTP_PORT\n        else:\n            port = int(port)\n\n        # username/password handling\n        user, host = splituser(host)\n        if user:\n            user, passwd = splitpasswd(user)\n        else:\n            passwd = None\n        host = unquote(host)\n        user = unquote(user or '')\n        passwd = unquote(passwd or '')\n\n        try:\n            host = socket.gethostbyname(host)\n        except socket.error as msg:\n            raise URLError(msg)\n        path, attrs = splitattr(req.get_selector())\n        dirs = path.split('/')\n        dirs = list(map(unquote, dirs))\n        dirs, file = dirs[:-1], dirs[-1]\n        if dirs and not dirs[0]:\n            dirs = dirs[1:]\n        try:\n            fw = self.connect_ftp(user, passwd, host, port, dirs, req.timeout)\n            type = file and 'I' or 'D'\n            for attr in attrs:\n                attr, value = splitvalue(attr)\n                if attr.lower() == 'type' and \\\n                   value in ('a', 'A', 'i', 'I', 'd', 'D'):\n                    type = value.upper()\n            fp, retrlen = fw.retrfile(file, type)\n            headers = \"\"\n            mtype = mimetypes.guess_type(req.get_full_url())[0]\n            if mtype:\n                headers += \"Content-type: %s\\n\" % mtype\n            if retrlen is not None and retrlen >= 0:\n                headers += \"Content-length: %d\\n\" % retrlen\n            sf = BytesIO(headers.encode('iso-8859-1'))\n            headers = create_response_info(sf)\n            return closeable_response(fp, headers, req.get_full_url())\n        except ftplib.all_errors as msg:\n            raise_with_traceback(URLError('ftp error: %s' % msg))\n\n    def connect_ftp(self, user, passwd, host, port, dirs, timeout):\n        try:\n            fw = ftpwrapper(user, passwd, host, port, dirs, timeout)\n        except TypeError:\n            # Python < 2.6, no per-connection timeout support\n            fw = ftpwrapper(user, passwd, host, port, dirs)\n# fw.ftp.set_debuglevel(1)\n        return fw\n\n\nclass CacheFTPHandler(FTPHandler):\n    # XXX would be nice to have pluggable cache strategies\n    # XXX this stuff is definitely not thread safe\n\n    def __init__(self):\n        self.cache = {}\n        self.timeout = {}\n        self.soonest = 0\n        self.delay = 60\n        self.max_conns = 16\n\n    def setTimeout(self, t):\n        self.delay = t\n\n    def setMaxConns(self, m):\n        self.max_conns = m\n\n    def connect_ftp(self, user, passwd, host, port, dirs, timeout):\n        key = user, host, port, '/'.join(dirs), timeout\n        if key in self.cache:\n            self.timeout[key] = time.time() + self.delay\n        else:\n            self.cache[key] = ftpwrapper(\n                user, passwd, host, port, dirs, timeout)\n            self.timeout[key] = time.time() + self.delay\n        self.check_cache()\n        return self.cache[key]\n\n    def check_cache(self):\n        # first check for old ones\n        t = time.time()\n        if self.soonest <= t:\n            for k, v in iteritems(self.timeout):\n                if v < t:\n                    self.cache[k].close()\n                    del self.cache[k]\n                    del self.timeout[k]\n        self.soonest = min(self.timeout.values())\n\n        # then check the size\n        if len(self.cache) == self.max_conns:\n            for k, v in iteritems(self.timeout):\n                if v == self.soonest:\n                    del self.cache[k]\n                    del self.timeout[k]\n                    break\n            self.soonest = min(self.timeout.values())\n", "# vim:fileencoding=utf-8\n\"\"\"Tests for urllib2-level functionality.\n\nThis is urllib2's tests (most of which came from mechanize originally), plus\nsome extra tests added, and modifications from bug fixes and feature additions\nto mechanize.\n\"\"\"\n\n# TODO:\n# Request\n# CacheFTPHandler (hard to write)\n# parse_keqv_list, parse_http_list\n\nimport os\nimport sys\nimport unittest\nfrom io import BytesIO\n\nimport mechanize\n\nfrom mechanize._response import test_response\nfrom mechanize import HTTPRedirectHandler, \\\n    HTTPEquivProcessor, HTTPRefreshProcessor, \\\n    HTTPCookieProcessor, HTTPRefererProcessor, \\\n    HTTPErrorProcessor, HTTPHandler\nfrom mechanize import OpenerDirector, build_opener, Request\nfrom mechanize._urllib2_fork import AbstractHTTPHandler, normalize_url, AbstractBasicAuthHandler\nfrom mechanize._util import write_file\n\nimport mechanize._response\nimport mechanize._sockettimeout as _sockettimeout\nimport mechanize._testcase\nimport mechanize._urllib2_fork\nfrom mechanize._mechanize import sanepathname2url\nfrom mechanize.polyglot import create_response_info, iteritems\n\n# from logging import getLogger, DEBUG\n# l = getLogger(\"mechanize\")\n# l.setLevel(DEBUG)\n\n\nclass TrivialTests(mechanize._testcase.TestCase):\n    def test_trivial(self):\n        # A couple trivial tests\n\n        self.assertRaises(ValueError, mechanize.urlopen, 'bogus url')\n\n        fname = os.path.join(self.make_temp_dir(), \"test.txt\")\n        data = b'data'\n        write_file(fname, data)\n        if os.sep == '\\\\':\n            fname = '/' + fname\n        file_url = \"file://\" + fname\n        try:\n            f = mechanize.urlopen(file_url)\n        except Exception as e:\n            raise ValueError('Failed to open URL: {} for fname: {} with error: {}'.format(file_url, fname, e))\n        self.assertEqual(f.read(), data)\n        f.close()\n\n    def test_parse_http_list(self):\n        tests = [('a,b,c', ['a', 'b', 'c']), (\n            'path\"o,l\"og\"i\"cal, example', ['path\"o,l\"og\"i\"cal', 'example']),\n                 ('a, b, \"c\", \"d\", \"e,f\", g, h',\n                  ['a', 'b', '\"c\"', '\"d\"', '\"e,f\"', 'g',\n                   'h']), ('a=\"b\\\\\"c\", d=\"e\\\\,f\", g=\"h\\\\\\\\i\"',\n                           ['a=\"b\"c\"', 'd=\"e,f\"', 'g=\"h\\\\i\"'])]\n        for string, list in tests:\n            self.assertEqual(\n                mechanize._urllib2_fork.parse_http_list(string), list)\n\n    def test_parse_authreq(self):\n        for bad in (\",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\",):\n            self.assertIsNone(AbstractBasicAuthHandler.rx.search(bad))\n\n\ndef test_request_headers_dict():\n    \"\"\"\n    The Request.headers dictionary is not a documented interface.  It should\n    stay that way, because the complete set of headers are only accessible\n    through the .get_header(), .has_header(), .header_items() interface.\n    However, .headers pre-dates those methods, and so real code will be using\n    the dictionary.\n\n    The introduction in 2.4 of those methods was a mistake for the same reason:\n    code that previously saw all (urllib2 user)-provided headers in .headers\n    now sees only a subset (and the function interface is ugly and incomplete).\n    A better change would have been to replace .headers dict with a dict\n    subclass (or UserDict.DictMixin instance?)  that preserved the .headers\n    interface and also provided access to the \"unredirected\" headers.  It's\n    probably too late to fix that, though.\n\n\n    Check .capitalize() case normalization:\n\n    >>> url = \"http://example.com\"\n    >>> Request(url, headers={\"Spam-eggs\": \"blah\"}).headers[\"Spam-eggs\"]\n    'blah'\n    >>> Request(url, headers={\"spam-EggS\": \"blah\"}).headers[\"Spam-eggs\"]\n    'blah'\n\n    Currently, Request(url, \"Spam-eggs\").headers[\"Spam-Eggs\"] raises KeyError,\n    but that could be changed in future.\n\n    \"\"\"\n\n\ndef test_request_headers_methods():\n    \"\"\"\n    Note the case normalization of header names here, to .capitalize()-case.\n    This should be preserved for backwards-compatibility.  (In the HTTP case,\n    normalization to .title()-case is done by urllib2 before sending headers to\n    httplib).\n\n    >>> url = \"http://example.com\"\n    >>> r = Request(url, headers={\"Spam-eggs\": \"blah\"})\n    >>> r.has_header(\"Spam-eggs\")\n    True\n    >>> r.header_items()\n    [('Spam-eggs', 'blah')]\n    >>> r.add_header(\"Foo-Bar\", \"baz\")\n    >>> items = r.header_items()\n    >>> items.sort()\n    >>> items\n    [('Foo-bar', 'baz'), ('Spam-eggs', 'blah')]\n\n    Note that e.g. r.has_header(\"spam-EggS\") is currently False, and\n    r.get_header(\"spam-EggS\") returns None, but that could be changed in\n    future.\n\n    >>> r.has_header(\"Not-there\")\n    False\n    >>> print r.get_header(\"Not-there\")\n    None\n    >>> r.get_header(\"Not-there\", \"default\")\n    'default'\n\n    \"\"\"\n\n\ndef test_password_manager(self):\n    \"\"\"\n    >>> mgr = mechanize.HTTPPasswordMgr()\n    >>> add = mgr.add_password\n    >>> add(\"Some Realm\", \"http://example.com/\", \"joe\", \"password\")\n    >>> add(\"Some Realm\", \"http://example.com/ni\", \"ni\", \"ni\")\n    >>> add(\"c\", \"http://example.com/foo\", \"foo\", \"ni\")\n    >>> add(\"c\", \"http://example.com/bar\", \"bar\", \"nini\")\n    >>> add(\"b\", \"http://example.com/\", \"first\", \"blah\")\n    >>> add(\"b\", \"http://example.com/\", \"second\", \"spam\")\n    >>> add(\"a\", \"http://example.com\", \"1\", \"a\")\n    >>> add(\"Some Realm\", \"http://c.example.com:3128\", \"3\", \"c\")\n    >>> add(\"Some Realm\", \"d.example.com\", \"4\", \"d\")\n    >>> add(\"Some Realm\", \"e.example.com:3128\", \"5\", \"e\")\n\n    >>> mgr.find_user_password(\"Some Realm\", \"example.com\")\n    ('joe', 'password')\n    >>> mgr.find_user_password(\"Some Realm\", \"http://example.com\")\n    ('joe', 'password')\n    >>> mgr.find_user_password(\"Some Realm\", \"http://example.com/\")\n    ('joe', 'password')\n    >>> mgr.find_user_password(\"Some Realm\", \"http://example.com/spam\")\n    ('joe', 'password')\n    >>> mgr.find_user_password(\"Some Realm\", \"http://example.com/spam/spam\")\n    ('joe', 'password')\n    >>> mgr.find_user_password(\"c\", \"http://example.com/foo\")\n    ('foo', 'ni')\n    >>> mgr.find_user_password(\"c\", \"http://example.com/bar\")\n    ('bar', 'nini')\n\n    Actually, this is really undefined ATM\n##     Currently, we use the highest-level path where more than one match:\n\n##     >>> mgr.find_user_password(\"Some Realm\", \"http://example.com/ni\")\n##     ('joe', 'password')\n\n    Use latest add_password() in case of conflict:\n\n    >>> mgr.find_user_password(\"b\", \"http://example.com/\")\n    ('second', 'spam')\n\n    No special relationship between a.example.com and example.com:\n\n    >>> mgr.find_user_password(\"a\", \"http://example.com/\")\n    ('1', 'a')\n    >>> mgr.find_user_password(\"a\", \"http://a.example.com/\")\n    (None, None)\n\n    Ports:\n\n    >>> mgr.find_user_password(\"Some Realm\", \"c.example.com\")\n    (None, None)\n    >>> mgr.find_user_password(\"Some Realm\", \"c.example.com:3128\")\n    ('3', 'c')\n    >>> mgr.find_user_password(\"Some Realm\", \"http://c.example.com:3128\")\n    ('3', 'c')\n    >>> mgr.find_user_password(\"Some Realm\", \"d.example.com\")\n    ('4', 'd')\n    >>> mgr.find_user_password(\"Some Realm\", \"e.example.com:3128\")\n    ('5', 'e')\n\n    \"\"\"\n    pass\n\n\ndef test_password_manager_default_port(self):\n    \"\"\"\n    >>> mgr = mechanize.HTTPPasswordMgr()\n    >>> add = mgr.add_password\n\n    The point to note here is that we can't guess the default port if there's\n    no scheme.  This applies to both add_password and find_user_password.\n\n    >>> add(\"f\", \"http://g.example.com:80\", \"10\", \"j\")\n    >>> add(\"g\", \"http://h.example.com\", \"11\", \"k\")\n    >>> add(\"h\", \"i.example.com:80\", \"12\", \"l\")\n    >>> add(\"i\", \"j.example.com\", \"13\", \"m\")\n    >>> mgr.find_user_password(\"f\", \"g.example.com:100\")\n    (None, None)\n    >>> mgr.find_user_password(\"f\", \"g.example.com:80\")\n    ('10', 'j')\n    >>> mgr.find_user_password(\"f\", \"g.example.com\")\n    (None, None)\n    >>> mgr.find_user_password(\"f\", \"http://g.example.com:100\")\n    (None, None)\n    >>> mgr.find_user_password(\"f\", \"http://g.example.com:80\")\n    ('10', 'j')\n    >>> mgr.find_user_password(\"f\", \"http://g.example.com\")\n    ('10', 'j')\n    >>> mgr.find_user_password(\"g\", \"h.example.com\")\n    ('11', 'k')\n    >>> mgr.find_user_password(\"g\", \"h.example.com:80\")\n    ('11', 'k')\n    >>> mgr.find_user_password(\"g\", \"http://h.example.com:80\")\n    ('11', 'k')\n    >>> mgr.find_user_password(\"h\", \"i.example.com\")\n    (None, None)\n    >>> mgr.find_user_password(\"h\", \"i.example.com:80\")\n    ('12', 'l')\n    >>> mgr.find_user_password(\"h\", \"http://i.example.com:80\")\n    ('12', 'l')\n    >>> mgr.find_user_password(\"i\", \"j.example.com\")\n    ('13', 'm')\n    >>> mgr.find_user_password(\"i\", \"j.example.com:80\")\n    (None, None)\n    >>> mgr.find_user_password(\"i\", \"http://j.example.com\")\n    ('13', 'm')\n    >>> mgr.find_user_password(\"i\", \"http://j.example.com:80\")\n    (None, None)\n\n    \"\"\"\n\n\nclass MockOpener:\n    addheaders = []\n    finalize_request_headers = None\n\n    def open(self,\n             req,\n             data=None,\n             timeout=_sockettimeout._GLOBAL_DEFAULT_TIMEOUT):\n        self.req, self.data, self.timeout = req, data, timeout\n\n    def error(self, proto, *args):\n        self.proto, self.args = proto, args\n\n\nclass MockFile:\n    def read(self, count=None):\n        pass\n\n    def readline(self, count=None):\n        pass\n\n    def close(self):\n        pass\n\n    def __iter__(self):\n        for i in ():\n            yield i\n\n\ndef http_message(mapping):\n    \"\"\"\n    >>> http_message({\"Content-Type\": \"text/html\"}).items()\n    [('content-type', 'text/html')]\n\n    \"\"\"\n    f = []\n    for kv in iteritems(mapping):\n        f.append(\"%s: %s\" % kv)\n    f.append(\"\")\n    msg = \"\\r\\n\".join(f)\n    if not isinstance(msg, bytes):\n        msg = msg.encode('iso-8859-1')\n    msg = create_response_info(BytesIO(msg))\n    return msg\n\n\nclass MockResponse(BytesIO):\n    def __init__(self, code, msg, headers, data, url=None):\n        if not isinstance(data, bytes):\n            data = data.encode('utf-8')\n        BytesIO.__init__(self, data)\n        self.code, self.msg, self.headers, self.url = code, msg, headers, url\n\n    def info(self):\n        return self.headers\n\n    def geturl(self):\n        return self.url\n\n\nclass MockCookieJar:\n    def add_cookie_header(self, request, unverifiable=False):\n        self.ach_req, self.ach_u = request, unverifiable\n\n    def extract_cookies(self, response, request, unverifiable=False):\n        self.ec_req, self.ec_r, self.ec_u = request, response, unverifiable\n\n\nclass FakeMethod:\n    def __init__(self, meth_name, action, handle):\n        self.meth_name = meth_name\n        self.handle = handle\n        self.action = action\n\n    def __call__(self, *args):\n        return self.handle(self.meth_name, self.action, *args)\n\n\nclass MockHandler:\n    # useful for testing handler machinery\n    # see add_ordered_mock_handlers() docstring\n    handler_order = 500\n\n    def __init__(self, methods):\n        self._define_methods(methods)\n\n    def _define_methods(self, methods):\n        for spec in methods:\n            if len(spec) == 2:\n                name, action = spec\n            else:\n                name, action = spec, None\n            meth = FakeMethod(name, action, self.handle)\n            setattr(self.__class__, name, meth)\n\n    def handle(self, fn_name, action, *args, **kwds):\n        self.parent.calls.append((self, fn_name, args, kwds))\n        if action is None:\n            return None\n        elif action == \"return self\":\n            return self\n        elif action == \"return response\":\n            res = MockResponse(200, \"OK\", {}, \"\")\n            return res\n        elif action == \"return request\":\n            return Request(\"http://blah/\")\n        elif action.startswith(\"error\"):\n            code = action[action.rfind(\" \") + 1:]\n            try:\n                code = int(code)\n            except ValueError:\n                pass\n            res = MockResponse(200, \"OK\", {}, \"\")\n            return self.parent.error(\"http\", args[0], res, code, \"\", {})\n        elif action == \"raise\":\n            raise mechanize.URLError(\"blah\")\n        assert False\n\n    def close(self):\n        pass\n\n    def add_parent(self, parent):\n        self.parent = parent\n        self.parent.calls = []\n\n    def __lt__(self, other):\n        if not hasattr(other, \"handler_order\"):\n            # Try to preserve the old behavior of having custom classes\n            # inserted after default ones (works only for custom user\n            # classes which are not aware of handler_order).\n            return True\n        return self.handler_order < other.handler_order\n\n\ndef add_ordered_mock_handlers(opener, meth_spec):\n    \"\"\"Create MockHandlers and add them to an OpenerDirector.\n\n    meth_spec: list of lists of tuples and strings defining methods to define\n    on handlers.  eg:\n\n    [[\"http_error\", \"ftp_open\"], [\"http_open\"]]\n\n    defines methods .http_error() and .ftp_open() on one handler, and\n    .http_open() on another.  These methods just record their arguments and\n    return None.  Using a tuple instead of a string causes the method to\n    perform some action (see MockHandler.handle()), eg:\n\n    [[\"http_error\"], [(\"http_open\", \"return request\")]]\n\n    defines .http_error() on one handler (which simply returns None), and\n    .http_open() on another handler, which returns a Request object.\n\n    \"\"\"\n    handlers = []\n    count = 0\n    for meths in meth_spec:\n\n        class MockHandlerSubclass(MockHandler):\n            pass\n\n        h = MockHandlerSubclass(meths)\n        h.handler_order += count\n        h.add_parent(opener)\n        count = count + 1\n        handlers.append(h)\n        opener.add_handler(h)\n    return handlers\n\n\ndef build_test_opener(*handler_instances):\n    opener = OpenerDirector()\n    for h in handler_instances:\n        opener.add_handler(h)\n    return opener\n\n\nclass MockHTTPHandler(mechanize.BaseHandler):\n    # useful for testing redirections and auth\n    # sends supplied headers and code as first response\n    # sends 200 OK as second response\n\n    def __init__(self, code, headers):\n        self.code = code\n        self.headers = headers\n        self.reset()\n\n    def reset(self):\n        self._count = 0\n        self.requests = []\n\n    def http_open(self, req):\n        import copy\n        self.requests.append(copy.deepcopy(req))\n        if self._count == 0:\n            self._count = self._count + 1\n            name = \"Not important\"\n            msg = create_response_info(BytesIO(\n                self.headers.encode('iso-8859-1')))\n            return self.parent.error(\"http\", req,\n                                     test_response(), self.code, name, msg)\n        else:\n            self.req = req\n            return test_response(\"\", [], req.get_full_url())\n\n\nclass MockHTTPResponse:\n    def __init__(self, fp, msg, status, reason):\n        self.fp = fp\n        self.msg = msg\n        self.status = status\n        self.reason = reason\n\n    def read(self):\n        return b''\n\n    def readinto(self, b):\n        pass\n\n    def close(self):\n        self.fp = None\n\n\nclass MockHTTPClass:\n    def __init__(self):\n        self.req_headers = []\n        self.data = None\n        self.raise_on_endheaders = False\n        self._tunnel_headers = {}\n\n    def __call__(self, host, timeout=_sockettimeout._GLOBAL_DEFAULT_TIMEOUT):\n        self.host = host\n        self.timeout = timeout\n        return self\n\n    def set_debuglevel(self, level):\n        self.level = level\n\n    def set_tunnel(self, host, port=None, headers=None):\n        self._tunnel_host = host\n        self._tunnel_port = port\n        if headers:\n            self._tunnel_headers = headers\n        else:\n            self._tunnel_headers.clear()\n\n    def request(self, method, url, body=None, headers={}):\n        self.method = method\n        self.selector = url\n        self.req_headers += list(iteritems(headers))\n        self.req_headers.sort()\n        if body:\n            self.data = body\n        if self.raise_on_endheaders:\n            import socket\n\n            raise socket.error()\n\n    def getresponse(self):\n        return MockHTTPResponse(MockFile(), {}, 200, \"OK\")\n\n\nclass MockHTTPSHandler(AbstractHTTPHandler):\n    # Useful for testing the Proxy-Authorization request by verifying the\n    # properties of httpcon\n    httpconn = MockHTTPClass()\n\n    def https_open(self, req):\n        return self.do_open(self.httpconn, req)\n\n\nclass OpenerDirectorTests(unittest.TestCase):\n    def test_add_non_handler(self):\n        class NonHandler(object):\n            pass\n\n        self.assertRaises(TypeError, OpenerDirector().add_handler,\n                          NonHandler())\n\n    def test_badly_named_methods(self):\n        # test work-around for three methods that accidentally follow the\n        # naming conventions for handler methods\n        # (*_open() / *_request() / *_response())\n\n        # These used to call the accidentally-named methods, causing a\n        # TypeError in real code; here, returning self from these mock\n        # methods would either cause no exception, or AttributeError.\n\n        from mechanize import URLError\n\n        o = OpenerDirector()\n        meth_spec = [\n            [(\"do_open\", \"return self\"), (\"proxy_open\", \"return self\")],\n            [(\"redirect_request\", \"return self\")],\n        ]\n        add_ordered_mock_handlers(o, meth_spec)\n        o.add_handler(mechanize.UnknownHandler())\n        for scheme in \"do\", \"proxy\", \"redirect\":\n            self.assertRaises(URLError, o.open, scheme + \"://example.com/\")\n\n    def test_handled(self):\n        # handler returning non-None means no more handlers will be called\n        o = OpenerDirector()\n        meth_spec = [\n            [\"http_open\", \"ftp_open\", \"http_error_302\"],\n            [\"ftp_open\"],\n            [(\"http_open\", \"return self\")],\n            [(\"http_open\", \"return self\")],\n        ]\n        handlers = add_ordered_mock_handlers(o, meth_spec)\n\n        req = Request(\"http://example.com/\")\n        r = o.open(req)\n        # Second .http_open() gets called, third doesn't, since second returned\n        # non-None.  Handlers without .http_open() never get any methods called\n        # on them.\n        # In fact, second mock handler defining .http_open() returns self\n        # (instead of response), which becomes the OpenerDirector's return\n        # value.\n        self.assertEqual(r, handlers[2])\n        calls = [(handlers[0], \"http_open\"), (handlers[2], \"http_open\")]\n        for expected, got in zip(calls, o.calls):\n            handler, name, args, kwds = got\n            self.assertEqual((handler, name), expected)\n            self.assertEqual(args, (req, ))\n\n    def test_reindex_handlers(self):\n        o = OpenerDirector()\n\n        class MockHandler:\n            def add_parent(self, parent):\n                pass\n\n            def close(self):\n                pass\n\n            def __lt__(self, other):\n                return self.handler_order < other.handler_order\n\n        # this first class is here as an obscure regression test for bug\n        # encountered during development: if something manages to get through\n        # to _maybe_reindex_handlers, make sure it's properly removed and\n        # doesn't affect adding of subsequent handlers\n        class NonHandler(MockHandler):\n            handler_order = 1\n\n        class Handler(MockHandler):\n            handler_order = 2\n\n            def http_open(self):\n                pass\n\n        class Processor(MockHandler):\n            handler_order = 3\n\n            def any_response(self):\n                pass\n\n            def http_response(self):\n                pass\n\n        o.add_handler(NonHandler())\n        h = Handler()\n        o.add_handler(h)\n        p = Processor()\n        o.add_handler(p)\n        o._maybe_reindex_handlers()\n        self.assertEqual(o.handle_open, {\"http\": [h]})\n        self.assertEqual(len(list(o.process_response.keys())), 1)\n        self.assertEqual(list(o.process_response[\"http\"]), [p])\n        self.assertEqual(list(o._any_response), [p])\n        self.assertEqual(o.handlers, [h, p])\n\n    def test_handler_order(self):\n        o = OpenerDirector()\n        handlers = []\n        for meths, handler_order in [\n            ([(\"http_open\", \"return self\")], 500),\n            ([\"http_open\"], 0),\n        ]:\n\n            class MockHandlerSubclass(MockHandler):\n                pass\n\n            h = MockHandlerSubclass(meths)\n            h.handler_order = handler_order\n            handlers.append(h)\n            o.add_handler(h)\n\n        o.open(\"http://example.com/\")\n        # handlers called in reverse order, thanks to their sort order\n        self.assertEqual(o.calls[0][0], handlers[1])\n        self.assertEqual(o.calls[1][0], handlers[0])\n\n    def test_raise(self):\n        # raising URLError stops processing of request\n        o = OpenerDirector()\n        meth_spec = [\n            [(\"http_open\", \"raise\")],\n            [(\"http_open\", \"return self\")],\n        ]\n        handlers = add_ordered_mock_handlers(o, meth_spec)\n\n        req = Request(\"http://example.com/\")\n        self.assertRaises(mechanize.URLError, o.open, req)\n        self.assertEqual(o.calls, [(handlers[0], \"http_open\", (req, ), {})])\n\n# def test_error(self):\n# XXX this doesn't actually seem to be used in standard library,\n# but should really be tested anyway...\n\n    def test_http_error(self):\n        # XXX http_error_default\n        # http errors are a special case\n        o = OpenerDirector()\n        meth_spec = [\n            [(\"http_open\", \"error 302\")],\n            [(\"http_error_400\", \"raise\"), \"http_open\"],\n            [(\"http_error_302\", \"return response\"), \"http_error_303\",\n             \"http_error\"],\n            [(\"http_error_302\")],\n        ]\n        handlers = add_ordered_mock_handlers(o, meth_spec)\n\n        req = Request(\"http://example.com/\")\n        o.open(req)\n        assert len(o.calls) == 2\n        ignore = object()\n        calls = [(handlers[0], \"http_open\", (req, )), (\n            handlers[2], \"http_error_302\", (req, ignore, 302, \"\", {}))]\n        for expected, got in zip(calls, o.calls):\n            handler, method_name, args = expected\n            self.assertEqual((handler, method_name), got[:2])\n            self.assertEqual(len(args), len(got[2]))\n            for a, b in zip(args, got[2]):\n                if a is not ignore:\n                    self.assertEqual(a, b)\n\n    def test_http_error_raised(self):\n        # should get an HTTPError if an HTTP handler raises a non-200 response\n        # XXX it worries me that this is the only test that excercises the else\n        # branch in HTTPDefaultErrorHandler\n        from mechanize import _response\n        o = mechanize.OpenerDirector()\n        o.add_handler(mechanize.HTTPErrorProcessor())\n        o.add_handler(mechanize.HTTPDefaultErrorHandler())\n\n        class HTTPHandler(AbstractHTTPHandler):\n            def http_open(self, req):\n                return _response.test_response(code=302)\n\n        o.add_handler(HTTPHandler())\n        self.assertRaises(mechanize.HTTPError, o.open, \"http://example.com/\")\n\n    def test_processors(self):\n        # *_request / *_response methods get called appropriately\n        o = OpenerDirector()\n        meth_spec = [\n            [(\"http_request\", \"return request\"),\n             (\"http_response\", \"return response\")],\n            [(\"http_request\", \"return request\"),\n             (\"http_response\", \"return response\")],\n        ]\n        handlers = add_ordered_mock_handlers(o, meth_spec)\n\n        req = Request(\"http://example.com/\")\n        o.open(req)\n        # processor methods are called on *all* handlers that define them,\n        # not just the first handler that handles the request\n        calls = [(handlers[0], \"http_request\"), (handlers[1], \"http_request\"),\n                 (handlers[0], \"http_response\"),\n                 (handlers[1], \"http_response\")]\n\n        self.assertEqual(len(o.calls), len(calls))\n        for i, (handler, name, args, kwds) in enumerate(o.calls):\n            if i < 2:\n                # *_request\n                self.assertEqual((handler, name), calls[i])\n                self.assertEqual(len(args), 1)\n                self.assertTrue(isinstance(args[0], Request))\n            else:\n                # *_response\n                self.assertEqual((handler, name), calls[i])\n                self.assertEqual(len(args), 2)\n                self.assertTrue(isinstance(args[0], Request))\n                # response from opener.open is None, because there's no\n                # handler that defines http_open to handle it\n                self.assertTrue(args[1] is None or\n                                isinstance(args[1], MockResponse))\n\n    def test_any(self):\n        # XXXXX two handlers case: ordering\n        o = OpenerDirector()\n        meth_spec = [[\n            (\"http_request\", \"return request\"),\n            (\"http_response\", \"return response\"),\n            (\"ftp_request\", \"return request\"),\n            (\"ftp_response\", \"return response\"),\n            (\"any_request\", \"return request\"),\n            (\"any_response\", \"return response\"),\n        ]]\n        handlers = add_ordered_mock_handlers(o, meth_spec)\n        handler = handlers[0]\n\n        for scheme in [\"http\", \"ftp\"]:\n            o.calls = []\n            req = Request(\"%s://example.com/\" % scheme)\n            o.open(req)\n\n            calls = [\n                (handler, \"any_request\"),\n                (handler, (\"%s_request\" % scheme)),\n                (handler, \"any_response\"),\n                (handler, (\"%s_response\" % scheme)),\n            ]\n            self.assertEqual(len(o.calls), len(calls))\n            for i, ((handler, name, args, kwds), calls) in (\n                    enumerate(zip(o.calls, calls))):\n                if i < 2:\n                    # *_request\n                    self.assertTrue((handler, name) == calls)\n                    self.assertTrue(len(args) == 1)\n                    self.assertTrue(isinstance(args[0], Request))\n                else:\n                    # *_response\n                    self.assertTrue((handler, name) == calls)\n                    self.assertTrue(len(args) == 2)\n                    self.assertTrue(isinstance(args[0], Request))\n                    # response from opener.open is None, because there's no\n                    # handler that defines http_open to handle it\n                    self.assertTrue(args[1] is None or isinstance(\n                        args[1], MockResponse))\n\n\nclass MockRobotFileParserClass:\n    def __init__(self):\n        self.calls = []\n        self._can_fetch = True\n\n    def clear(self):\n        self.calls = []\n\n    def __call__(self):\n        self.calls.append(\"__call__\")\n        return self\n\n    def set_url(self, url):\n        self.calls.append((\"set_url\", url))\n\n    def set_timeout(self, timeout):\n        self.calls.append((\"set_timeout\", timeout))\n\n    def set_opener(self, opener):\n        self.calls.append((\"set_opener\", opener))\n\n    def read(self):\n        self.calls.append(\"read\")\n\n    def can_fetch(self, ua, url):\n        self.calls.append((\"can_fetch\", ua, url))\n        return self._can_fetch\n\n\nclass MockPasswordManager:\n    def add_password(self, realm, uri, user, password):\n        self.realm = realm\n        self.url = uri\n        self.user = user\n        self.password = password\n\n    def find_user_password(self, realm, authuri):\n        self.target_realm = realm\n        self.target_url = authuri\n        return self.user, self.password\n\n\nclass HandlerTests(mechanize._testcase.TestCase):\n    def test_ftp(self):\n        class MockFTPWrapper:\n            def __init__(self, data):\n                self.data = data\n\n            def retrfile(self, filename, filetype):\n                self.filename, self.filetype = filename, filetype\n                data = self.data if isinstance(\n                        self.data, bytes) else self.data.encode('utf-8')\n                return BytesIO(data), len(self.data)\n\n        class NullFTPHandler(mechanize.FTPHandler):\n            def __init__(self, data):\n                self.data = data\n\n            def connect_ftp(self, user, passwd, host, port, dirs, timeout):\n                self.user, self.passwd = user, passwd\n                self.host, self.port = host, port\n                self.dirs = dirs\n                self.timeout = timeout\n                self.ftpwrapper = MockFTPWrapper(self.data)\n                return self.ftpwrapper\n\n        import ftplib\n        import socket\n        data = \"rheum rhaponicum\"\n        h = NullFTPHandler(data)\n        h.parent = MockOpener()\n\n        for url, host, port, type_, dirs, timeout, filename, mimetype in [\n            (\"ftp://localhost/foo/bar/baz.html\", \"localhost\", ftplib.FTP_PORT,\n             \"I\", [\"foo\", \"bar\"], _sockettimeout._GLOBAL_DEFAULT_TIMEOUT,\n             \"baz.html\", \"text/html\"),\n            (\"ftp://localhost:80/foo/bar/\", \"localhost\", 80, \"D\",\n             [\"foo\", \"bar\"], _sockettimeout._GLOBAL_DEFAULT_TIMEOUT, \"\", None),\n            (\"ftp://localhost/baz.gif;type=a\", \"localhost\", ftplib.FTP_PORT,\n             \"A\", [], _sockettimeout._GLOBAL_DEFAULT_TIMEOUT, \"baz.gif\",\n             None),  # TODO: really this should guess image/gif\n        ]:\n            req = Request(url, timeout=timeout)\n            r = h.ftp_open(req)\n            # ftp authentication not yet implemented by FTPHandler\n            self.assertTrue(h.user == h.passwd == \"\")\n            self.assertEqual(h.host, socket.gethostbyname(host))\n            self.assertEqual(h.port, port)\n            self.assertEqual(h.dirs, dirs)\n            if sys.version_info >= (2, 6):\n                self.assertEqual(h.timeout, timeout)\n            self.assertEqual(h.ftpwrapper.filename, filename)\n            self.assertEqual(h.ftpwrapper.filetype, type_)\n            headers = r.info()\n            self.assertEqual(headers.get(\"Content-type\"), mimetype)\n            self.assertEqual(int(headers[\"Content-length\"]), len(data))\n\n    def test_file(self):\n        from email.utils import formatdate\n        import socket\n        h = mechanize.FileHandler()\n        o = h.parent = MockOpener()\n\n        temp_file = os.path.join(self.make_temp_dir(), \"test.txt\")\n        urlpath = sanepathname2url(os.path.abspath(temp_file))\n        towrite = b\"hello, world\\n\"\n        try:\n            fqdn = socket.gethostbyname(socket.gethostname())\n        except socket.gaierror:\n            fqdn = \"localhost\"\n        for url in [\n                \"file://localhost%s\" % urlpath, \"file://%s\" % urlpath,\n                \"file://%s%s\" % (socket.gethostbyname('localhost'), urlpath),\n                \"file://%s%s\" % (fqdn, urlpath)\n        ]:\n            write_file(temp_file, towrite)\n            r = h.file_open(Request(url))\n            try:\n                data = r.read()\n                headers = r.info()\n                r.geturl()\n            finally:\n                r.close()\n            stats = os.stat(temp_file)\n            modified = formatdate(stats.st_mtime, usegmt=True)\n            self.assertEqual(data, towrite)\n            self.assertEqual(headers[\"Content-type\"], \"text/plain\")\n            self.assertEqual(headers[\"Content-length\"], \"13\")\n            self.assertEqual(headers[\"Last-modified\"], modified)\n\n        for url in [\n                \"file://localhost:80%s\" % urlpath,\n                \"file:///file_does_not_exist.txt\",\n                \"file://%s:80%s/%s\" % (socket.gethostbyname('localhost'),\n                                       sanepathname2url(os.getcwd()),\n                                       temp_file),\n                \"file://somerandomhost.ontheinternet.com%s/%s\" % (\n                    sanepathname2url(os.getcwd()), temp_file),\n        ]:\n            write_file(temp_file, towrite)\n            self.assertRaises(mechanize.URLError, h.file_open, Request(url))\n\n        h = mechanize.FileHandler()\n        o = h.parent = MockOpener()\n        # XXXX why does // mean ftp (and /// mean not ftp!), and where\n        #  is file: scheme specified?  I think this is really a bug, and\n        #  what was intended was to distinguish between URLs like:\n        # file:/blah.txt (a file)\n        # file://localhost/blah.txt (a file)\n        # file:///blah.txt (a file)\n        # file://ftp.example.com/blah.txt (an ftp URL)\n        for url, ftp in [\n            (\"file://ftp.example.com//foo.txt\", True),\n            (\"file://ftp.example.com///foo.txt\", False),\n                # XXXX bug: fails with OSError, should be URLError\n            (\"file://ftp.example.com/foo.txt\", False),\n        ]:\n            req = Request(url)\n            try:\n                h.file_open(req)\n            # XXXX remove OSError when bug fixed\n            except (mechanize.URLError, OSError):\n                self.assertFalse(ftp)\n            else:\n                self.assertTrue(o.req is req)\n                self.assertEqual(req.type, \"ftp\")\n\n    def test_http(self):\n        class MockHTTPResponse:\n            def __init__(self, fp, msg, status, reason):\n                self.fp = fp\n                self.msg = msg\n                self.status = status\n                self.reason = reason\n\n            def read(self):\n                return b''\n\n            def readinto(self, b):\n                pass\n\n            def close(self):\n                self.fp = None\n\n        class MockHTTPClass:\n            def __init__(self):\n                self.req_headers = []\n                self.data = None\n                self.raise_on_endheaders = False\n\n            def __call__(self,\n                         host,\n                         timeout=_sockettimeout._GLOBAL_DEFAULT_TIMEOUT):\n                self.host = host\n                self.timeout = timeout\n                return self\n\n            def set_debuglevel(self, level):\n                self.level = level\n\n            def request(self, method, url, body=None, headers={}):\n                self.method = method\n                self.selector = url\n                self.req_headers += list(iteritems(headers))\n                if body:\n                    self.data = body\n                if self.raise_on_endheaders:\n                    import socket\n                    raise socket.error()\n\n            def getresponse(self):\n                return MockHTTPResponse(MockFile(), {}, 200, \"OK\")\n\n        h = AbstractHTTPHandler()\n        o = h.parent = MockOpener()\n\n        url = \"http://example.com/\"\n        for method, data in [(\"GET\", None), (\"POST\", \"blah\")]:\n            req = Request(url, data, {\"Foo\": \"bar\"})\n            req.add_header('Order', '1')\n            req.add_unredirected_header(\"Spam\", \"eggs\")\n            http = MockHTTPClass()\n            r = h.do_open(http, req)\n\n            # result attributes\n            r.read\n            r.readline  # wrapped MockFile methods\n            r.info\n            r.geturl  # addinfourl methods\n            r.code, r.msg == 200, \"OK\"  # added from MockHTTPClass.getreply()\n            hdrs = r.info()\n            hdrs.get\n            hdrs.__contains__  # r.info() gives dict from .getreply()\n            self.assertEqual(r.geturl(), url)\n\n            self.assertEqual(http.host, \"example.com\")\n            self.assertEqual(http.level, 0)\n            self.assertEqual(http.method, method)\n            self.assertEqual(http.selector, \"/\")\n            self.assertEqual(\n                http.req_headers,\n                [('Foo', 'bar'), ('Order', '1'),\n                    ('Spam', 'eggs'), ('Connection', 'close')]\n            )\n            self.assertEqual(http.data, data)\n\n        # check socket.error converted to URLError\n        http.raise_on_endheaders = True\n        self.assertRaises(mechanize.URLError, h.do_open, http, req)\n\n        # check adding of standard headers\n        o.addheaders = [(\"Spam\", \"eggs\")]\n        for data in \"\", None:  # POST, GET\n            req = Request(\"http://example.com/\", data)\n            r = MockResponse(200, \"OK\", {}, \"\")\n            h.do_request_(req)\n            if data is None:  # GET\n                self.assertTrue(\"Content-length\" not in req.unredirected_hdrs)\n                self.assertTrue(\"Content-type\" not in req.unredirected_hdrs)\n            else:  # POST\n                self.assertEqual(req.unredirected_hdrs[\"Content-Length\"], \"0\")\n                self.assertEqual(req.unredirected_hdrs[\"Content-Type\"],\n                                 \"application/x-www-form-urlencoded\")\n            # XXX the details of Host could be better tested\n            self.assertEqual(req.unredirected_hdrs[\"Host\"], \"example.com\")\n            self.assertEqual(req.unredirected_hdrs[\"Spam\"], \"eggs\")\n\n            # don't clobber existing headers\n            req.add_unredirected_header(\"Content-Length\", \"foo\")\n            req.add_unredirected_header(\"Content-Type\", \"bar\")\n            req.add_unredirected_header(\"Host\", \"baz\")\n            req.add_unredirected_header(\"Spam\", \"foo\")\n            h.do_request_(req)\n            self.assertEqual(req.unredirected_hdrs[\"Content-Length\"], \"foo\")\n            self.assertEqual(req.unredirected_hdrs[\"Content-Type\"], \"bar\")\n            self.assertEqual(req.unredirected_hdrs[\"Host\"], \"baz\")\n            self.assertEqual(req.unredirected_hdrs[\"Spam\"], \"foo\")\n\n    def test_http_double_slash(self):\n        # Checks that the presence of an unnecessary double slash in a url\n        # doesn't break anything Previously, a double slash directly after the\n        # host could cause incorrect parsing of the url\n        h = AbstractHTTPHandler()\n        h.parent = MockOpener()\n\n        data = \"\"\n        ds_urls = [\n            \"http://example.com/foo/bar/baz.html\",\n            \"http://example.com//foo/bar/baz.html\",\n            \"http://example.com/foo//bar/baz.html\",\n            \"http://example.com/foo/bar//baz.html\",\n        ]\n\n        for ds_url in ds_urls:\n            ds_req = Request(ds_url, data)\n\n            # Check whether host is determined correctly if there is no proxy\n            np_ds_req = h.do_request_(ds_req)\n            self.assertEqual(np_ds_req.unredirected_hdrs[\"Host\"],\n                             \"example.com\")\n\n            # Check whether host is determined correctly if there is a proxy\n            ds_req.set_proxy(\"someproxy:3128\", None)\n            p_ds_req = h.do_request_(ds_req)\n            self.assertEqual(p_ds_req.unredirected_hdrs[\"Host\"], \"example.com\")\n\n    def test_errors(self):\n        h = HTTPErrorProcessor()\n        o = h.parent = MockOpener()\n\n        req = Request(\"http://example.com\")\n        # all 2xx are passed through\n        r = mechanize._response.test_response()\n        newr = h.http_response(req, r)\n        self.assertTrue(r is newr)\n        self.assertTrue(not hasattr(o, \"proto\"))  # o.error not called\n        r = mechanize._response.test_response(code=202, msg=\"Accepted\")\n        newr = h.http_response(req, r)\n        self.assertTrue(r is newr)\n        self.assertTrue(not hasattr(o, \"proto\"))  # o.error not called\n        r = mechanize._response.test_response(code=206, msg=\"Partial content\")\n        newr = h.http_response(req, r)\n        self.assertTrue(r is newr)\n        self.assertTrue(not hasattr(o, \"proto\"))  # o.error not called\n        # anything else calls o.error (and MockOpener returns None, here)\n        r = mechanize._response.test_response(code=502, msg=\"Bad gateway\")\n        self.assertTrue(h.http_response(req, r) is None)\n        self.assertEqual(o.proto, \"http\")  # o.error called\n        self.assertEqual(o.args[:4], (req, r, 502, \"Bad gateway\"))\n\n    def test_referer(self):\n        h = HTTPRefererProcessor()\n        h.parent = MockOpener()\n\n        # normal case\n        url = \"http://example.com/\"\n        req = Request(url)\n        r = MockResponse(200, \"OK\", {}, \"\", url)\n        newr = h.http_response(req, r)\n        self.assertTrue(r is newr)\n        self.assertTrue(h.referer == url)\n        newreq = h.http_request(req)\n        self.assertTrue(req is newreq)\n        self.assertTrue(req.unredirected_hdrs[\"Referer\"] == url)\n        # don't clobber existing Referer\n        ref = \"http://set.by.user.com/\"\n        req.add_unredirected_header(\"Referer\", ref)\n        newreq = h.http_request(req)\n        self.assertTrue(req is newreq)\n        self.assertTrue(req.unredirected_hdrs[\"Referer\"] == ref)\n\n    def test_raise_http_errors(self):\n        # HTTPDefaultErrorHandler should raise HTTPError if no error handler\n        # handled the error response\n        from mechanize import _response\n        h = mechanize.HTTPDefaultErrorHandler()\n\n        url = \"http://example.com\"\n        code = 500\n        msg = \"Error\"\n        request = mechanize.Request(url)\n        response = _response.test_response(url=url, code=code, msg=msg)\n\n        # case 1. it's not an HTTPError\n        try:\n            h.http_error_default(request, response, code, msg, response.info())\n        except mechanize.HTTPError as exc:\n            self.assertTrue(exc is not response)\n            self.assertTrue(exc.fp is response)\n        else:\n            self.assertTrue(False)\n\n        # case 2. response object is already an HTTPError, so just re-raise it\n        error = mechanize.HTTPError(url, code, msg, \"fake headers\", response)\n        try:\n            h.http_error_default(request, error, code, msg, error.info())\n        except mechanize.HTTPError as exc:\n            self.assertTrue(exc is error)\n        else:\n            self.assertTrue(False)\n\n    def test_robots(self):\n        # XXX useragent\n        from mechanize import HTTPRobotRulesProcessor\n        opener = OpenerDirector()\n        rfpc = MockRobotFileParserClass()\n        h = HTTPRobotRulesProcessor(rfpc)\n        opener.add_handler(h)\n\n        url = \"http://example.com:80/foo/bar.html\"\n        req = Request(url)\n        # first time: initialise and set up robots.txt parser before checking\n        #  whether OK to fetch URL\n        h.http_request(req)\n        self.assertEqual(rfpc.calls, [\n            \"__call__\",\n            (\"set_opener\", opener),\n            (\"set_url\", \"http://example.com:80/robots.txt\"),\n            (\"set_timeout\", _sockettimeout._GLOBAL_DEFAULT_TIMEOUT),\n            \"read\",\n            (\"can_fetch\", \"\", url),\n        ])\n        # second time: just use existing parser\n        rfpc.clear()\n        req = Request(url)\n        h.http_request(req)\n        self.assertTrue(rfpc.calls == [\n            (\"can_fetch\", \"\", url),\n        ])\n        # different URL on same server: same again\n        rfpc.clear()\n        url = \"http://example.com:80/blah.html\"\n        req = Request(url)\n        h.http_request(req)\n        self.assertTrue(rfpc.calls == [\n            (\"can_fetch\", \"\", url),\n        ])\n        # disallowed URL\n        rfpc.clear()\n        rfpc._can_fetch = False\n        url = \"http://example.com:80/rhubarb.html\"\n        req = Request(url)\n        try:\n            h.http_request(req)\n        except mechanize.HTTPError as e:\n            self.assertTrue(e.request == req)\n            self.assertTrue(e.code == 403)\n        # new host: reload robots.txt (even though the host and port are\n        #  unchanged, we treat this as a new host because\n        #  \"example.com\" != \"example.com:80\")\n        rfpc.clear()\n        rfpc._can_fetch = True\n        url = \"http://example.com/rhubarb.html\"\n        req = Request(url)\n        h.http_request(req)\n        self.assertEqual(rfpc.calls, [\n            \"__call__\",\n            (\"set_opener\", opener),\n            (\"set_url\", \"http://example.com/robots.txt\"),\n            (\"set_timeout\", _sockettimeout._GLOBAL_DEFAULT_TIMEOUT),\n            \"read\",\n            (\"can_fetch\", \"\", url),\n        ])\n        # https url -> should fetch robots.txt from https url too\n        rfpc.clear()\n        url = \"https://example.org/rhubarb.html\"\n        req = Request(url)\n        h.http_request(req)\n        self.assertEqual(rfpc.calls, [\n            \"__call__\",\n            (\"set_opener\", opener),\n            (\"set_url\", \"https://example.org/robots.txt\"),\n            (\"set_timeout\", _sockettimeout._GLOBAL_DEFAULT_TIMEOUT),\n            \"read\",\n            (\"can_fetch\", \"\", url),\n        ])\n        # non-HTTP URL -> ignore robots.txt\n        rfpc.clear()\n        url = \"ftp://example.com/\"\n        req = Request(url)\n        h.http_request(req)\n        self.assertTrue(rfpc.calls == [])\n\n    def test_redirected_robots_txt(self):\n        # redirected robots.txt fetch shouldn't result in another attempted\n        # robots.txt fetch to check the redirection is allowed!\n        import mechanize\n        from mechanize import (\n                HTTPDefaultErrorHandler, HTTPRedirectHandler,\n                HTTPRobotRulesProcessor)\n\n        class MockHTTPHandler(mechanize.BaseHandler):\n            def __init__(self):\n                self.requests = []\n\n            def http_open(self, req):\n                import copy\n                self.requests.append(copy.deepcopy(req))\n                if req.get_full_url() == \"http://example.com/robots.txt\":\n                    hdr = b\"Location: http://example.com/en/robots.txt\\r\\n\\r\\n\"\n                    msg = create_response_info(BytesIO(hdr))\n                    return self.parent.error(\"http\", req,\n                                             test_response(), 302, \"Blah\", msg)\n                else:\n                    return test_response(\"Allow: *\", [], req.get_full_url())\n\n        hh = MockHTTPHandler()\n        hdeh = HTTPDefaultErrorHandler()\n        hrh = HTTPRedirectHandler()\n        rh = HTTPRobotRulesProcessor()\n        o = build_test_opener(hh, hdeh, hrh, rh)\n        o.open(\"http://example.com/\")\n        self.assertEqual([req.get_full_url() for req in hh.requests], [\n            \"http://example.com/robots.txt\",\n            \"http://example.com/en/robots.txt\",\n            \"http://example.com/\",\n        ])\n\n    def test_cookies(self):\n        cj = MockCookieJar()\n        h = HTTPCookieProcessor(cj)\n        h.parent = MockOpener()\n\n        req = Request(\"http://example.com/\")\n        r = MockResponse(200, \"OK\", {}, \"\")\n        newreq = h.http_request(req)\n        self.assertTrue(cj.ach_req is req is newreq)\n        self.assertEqual(req.get_origin_req_host(), \"example.com\")\n        self.assertFalse(cj.ach_u)\n        newr = h.http_response(req, r)\n        self.assertTrue(cj.ec_req is req)\n        self.assertTrue(cj.ec_r is r is newr)\n        self.assertFalse(cj.ec_u)\n\n    def test_http_equiv(self):\n        h = HTTPEquivProcessor()\n        h.parent = MockOpener()\n\n        data = ('<html><HEad>'\n                '<Meta httP-equiv=\"RefResh\" coNtent=\"spam&amp;Eggs\">'\n                '</Head></html>')\n        headers = [\n            (\"Foo\", \"Bar\"),\n            (\"Content-type\", \"text/html\"),\n            (\"Refresh\", \"blah\"),\n        ]\n        url = \"http://example.com/\"\n        req = Request(url)\n        r = mechanize._response.make_response(data, headers, url, 200, \"OK\")\n        newr = h.http_response(req, r)\n\n        new_headers = newr.info()\n        self.assertEqual(new_headers[\"Foo\"], \"Bar\")\n        self.assertEqual(new_headers[\"Refresh\"], \"spam&Eggs\")\n        self.assertEqual(\n            new_headers.getheaders(\"Refresh\"), [\"blah\", \"spam&Eggs\"])\n\n    def test_refresh(self):\n        # XXX test processor constructor optional args\n        h = HTTPRefreshProcessor(max_time=None, honor_time=False)\n\n        for val, valid in [\n            ('0; url=\"http://example.com/foo/\"', True),\n            (\"2\", True),\n                # in the past, this failed with UnboundLocalError\n            ('0; \"http://example.com/foo/\"', False),\n        ]:\n            o = h.parent = MockOpener()\n            req = Request(\"http://example.com/\")\n            headers = http_message({\"refresh\": val})\n            r = MockResponse(200, \"OK\", headers, \"\", \"http://example.com/\")\n            h.http_response(req, r)\n            if valid:\n                self.assertEqual(o.proto, \"http\")\n                self.assertEqual(o.args, (req, r, \"refresh\", \"OK\", headers))\n\n    def test_refresh_honor_time(self):\n        class SleepTester:\n            def __init__(self, test, seconds):\n                self._test = test\n                if seconds == 0:\n                    seconds = None  # don't expect a sleep for 0 seconds\n                self._expected = seconds\n                self._got = None\n\n            def sleep(self, seconds):\n                self._got = seconds\n\n            def verify(self):\n                self._test.assertEqual(self._expected, self._got)\n\n        class Opener:\n            called = False\n\n            def error(self, *args, **kwds):\n                self.called = True\n\n        def test(rp, header, refresh_after):\n            expect_refresh = refresh_after is not None\n            opener = Opener()\n            rp.parent = opener\n            st = SleepTester(self, refresh_after)\n            rp._sleep = st.sleep\n            rp.http_response(\n                Request(\"http://example.com\"),\n                test_response(headers=[(\"Refresh\", header)], url=\"http://example.com/\"), )\n            self.assertEqual(expect_refresh, opener.called)\n            st.verify()\n\n        # by default, only zero-time refreshes are honoured\n        test(HTTPRefreshProcessor(), \"0\", 0)\n        test(HTTPRefreshProcessor(), \"2\", None)\n\n        # if requested, more than zero seconds are allowed\n        test(HTTPRefreshProcessor(max_time=None), \"2\", 2)\n        test(HTTPRefreshProcessor(max_time=30), \"2\", 2)\n\n        # no sleep if we don't \"honor_time\"\n        test(HTTPRefreshProcessor(max_time=30, honor_time=False), \"2\", 0)\n\n        # request for too-long wait before refreshing --> no refresh occurs\n        test(HTTPRefreshProcessor(max_time=30), \"60\", None)\n\n    def test_redirect(self):\n        from_url = \"http://example.com/a.html\"\n        to_url = \"http://example.com/b.html\"\n        h = HTTPRedirectHandler()\n        o = h.parent = MockOpener()\n\n        # ordinary redirect behaviour\n        for code in 301, 302, 303, 307, \"refresh\":\n            for data in None, \"blah\\nblah\\n\":\n                method = getattr(h, \"http_error_%s\" % code)\n                req = Request(from_url, data)\n                req.add_header(\"Nonsense\", \"viking=withhold\")\n                req.add_unredirected_header(\"Spam\", \"spam\")\n                req.origin_req_host = \"example.com\"  # XXX\n                try:\n                    method(req,\n                           MockFile(), code, \"Blah\",\n                           http_message({\n                               \"location\": to_url\n                           }))\n                except mechanize.HTTPError:\n                    # 307 in response to POST requires user OK\n                    self.assertEqual(code, 307)\n                    self.assertTrue(data is not None)\n                self.assertEqual(o.req.get_full_url(), to_url)\n                try:\n                    self.assertEqual(o.req.get_method(), \"GET\")\n                except AttributeError:\n                    self.assertFalse(o.req.has_data())\n\n                # now it's a GET, there should not be headers regarding content\n                # (possibly dragged from before being a POST)\n                headers = [x.lower() for x in o.req.headers]\n                self.assertTrue(\"content-length\" not in headers)\n                self.assertTrue(\"content-type\" not in headers)\n\n                self.assertEqual(o.req.headers[\"Nonsense\"], \"viking=withhold\")\n                self.assertTrue(\"Spam\" not in o.req.headers)\n                self.assertTrue(\"Spam\" not in o.req.unredirected_hdrs)\n\n        # loop detection\n        req = Request(from_url)\n\n        def redirect(h, req, url=to_url):\n            h.http_error_302(req,\n                             MockFile(), 302, \"Blah\",\n                             http_message({\n                                 \"location\": url\n                             }))\n\n        # Note that the *original* request shares the same record of\n        # redirections with the sub-requests caused by the redirections.\n\n        # detect infinite loop redirect of a URL to itself\n        req = Request(from_url, origin_req_host=\"example.com\")\n        count = 0\n        try:\n            while 1:\n                redirect(h, req, \"http://example.com/\")\n                count = count + 1\n        except mechanize.HTTPError:\n            # don't stop until max_repeats, because cookies may introduce state\n            self.assertEqual(count, HTTPRedirectHandler.max_repeats)\n\n        # detect endless non-repeating chain of redirects\n        req = Request(from_url, origin_req_host=\"example.com\")\n        count = 0\n        try:\n            while 1:\n                redirect(h, req, \"http://example.com/%d\" % count)\n                count = count + 1\n        except mechanize.HTTPError:\n            self.assertEqual(count, HTTPRedirectHandler.max_redirections)\n\n    def test_redirect_bad_uri(self):\n        # bad URIs should be cleaned up before redirection\n        from mechanize._response import test_html_response\n        from_url = \"http://example.com/a.html\"\n        bad_to_url = \"http://example.com/b. |html\"\n        good_to_url = \"http://example.com/b.%20%7Chtml\"\n\n        h = HTTPRedirectHandler()\n        o = h.parent = MockOpener()\n\n        req = Request(from_url)\n        h.http_error_302(\n            req,\n            test_html_response(),\n            302,\n            \"Blah\",\n            http_message({\n                \"location\": bad_to_url\n            }), )\n        self.assertEqual(o.req.get_full_url(), good_to_url)\n\n    def test_refresh_bad_uri(self):\n        # bad URIs should be cleaned up before redirection\n        from mechanize._response import test_html_response\n        bad_to_url = \"http://example.com/b. |html\"\n        good_to_url = \"http://example.com/b.%20%7Chtml\"\n\n        h = HTTPRefreshProcessor(max_time=None, honor_time=False)\n        o = h.parent = MockOpener()\n\n        req = Request(\"http://example.com/\")\n        r = test_html_response(\n            headers=[(\"refresh\", '0; url=\"%s\"' % bad_to_url)])\n        h.http_response(req, r)\n        headers = o.args[-1]\n        self.assertEqual(headers[\"Location\"], good_to_url)\n\n    def test_cookie_redirect(self):\n        # cookies shouldn't leak into redirected requests\n        from mechanize import (\n                CookieJar, HTTPCookieProcessor, HTTPDefaultErrorHandler,\n                HTTPRedirectHandler)\n\n        from test.test_cookies import interact_netscape\n\n        cj = CookieJar()\n        interact_netscape(cj, \"http://www.example.com/\", \"spam=eggs\")\n        hh = MockHTTPHandler(302, \"Location: http://www.cracker.com/\\r\\n\\r\\n\")\n        hdeh = HTTPDefaultErrorHandler()\n        hrh = HTTPRedirectHandler()\n        cp = HTTPCookieProcessor(cj)\n        o = build_test_opener(hh, hdeh, hrh, cp)\n        o.open(\"http://www.example.com/\")\n        self.assertFalse(hh.req.has_header(\"Cookie\"))\n\n    def test_proxy(self):\n        o = OpenerDirector()\n        ph = mechanize.ProxyHandler(dict(http=\"proxy.example.com:3128\"))\n        o.add_handler(ph)\n        meth_spec = [[(\"http_open\", \"return response\")]]\n        handlers = add_ordered_mock_handlers(o, meth_spec)\n\n        o._maybe_reindex_handlers()\n\n        req = Request(\"http://acme.example.com/\")\n        self.assertEqual(req.get_host(), \"acme.example.com\")\n        o.open(req)\n        self.assertEqual(req.get_host(), \"proxy.example.com:3128\")\n\n        self.assertEqual([(handlers[0], \"http_open\")],\n                         [tup[0:2] for tup in o.calls])\n\n    def test_proxy_no_proxy(self):\n        self.monkey_patch_environ(\"no_proxy\", \"python.org\")\n        o = OpenerDirector()\n        ph = mechanize.ProxyHandler(dict(http=\"proxy.example.com\"))\n        o.add_handler(ph)\n        req = Request(\"http://www.perl.org/\")\n        self.assertEqual(req.get_host(), \"www.perl.org\")\n        o.open(req)\n        self.assertEqual(req.get_host(), \"proxy.example.com\")\n        req = Request(\"http://www.python.org\")\n        self.assertEqual(req.get_host(), \"www.python.org\")\n        o.open(req)\n        if sys.version_info >= (2, 6):\n            # no_proxy environment variable not supported in python 2.5\n            self.assertEqual(req.get_host(), \"www.python.org\")\n\n    def test_proxy_custom_proxy_bypass(self):\n        self.monkey_patch_environ(\"no_proxy\",\n                                  mechanize._testcase.MonkeyPatcher.Unset)\n\n        def proxy_bypass(hostname):\n            return hostname == \"noproxy.com\"\n\n        o = OpenerDirector()\n        ph = mechanize.ProxyHandler(\n            dict(http=\"proxy.example.com\"), proxy_bypass=proxy_bypass)\n\n        def is_proxied(url):\n            o.add_handler(ph)\n            req = Request(url)\n            o.open(req)\n            return req.has_proxy()\n\n        self.assertTrue(is_proxied(\"http://example.com\"))\n        self.assertFalse(is_proxied(\"http://noproxy.com\"))\n\n    def test_proxy_https(self):\n        o = OpenerDirector()\n        ph = mechanize.ProxyHandler(dict(https='proxy.example.com:3128'))\n        o.add_handler(ph)\n        meth_spec = [[(\"https_open\", \"return response\")]]\n        handlers = add_ordered_mock_handlers(o, meth_spec)\n        req = Request(\"https://www.example.com/\")\n        self.assertEqual(req.get_host(), \"www.example.com\")\n        o.open(req)\n        self.assertEqual(req.get_host(), \"proxy.example.com:3128\")\n        self.assertEqual([(handlers[0], \"https_open\")],\n                         [tup[0:2] for tup in o.calls])\n\n    def test_basic_auth(self, quote_char='\"'):\n        opener = OpenerDirector()\n        password_manager = MockPasswordManager()\n        auth_handler = mechanize.HTTPBasicAuthHandler(password_manager)\n        realm = \"ACME Widget Store\"\n        http_handler = MockHTTPHandler(\n            401, 'WWW-Authenticate: Basic realm=%s%s%s\\r\\n\\r\\n' %\n            (quote_char, realm, quote_char))\n        opener.add_handler(auth_handler)\n        opener.add_handler(http_handler)\n        self._test_basic_auth(\n            opener,\n            auth_handler,\n            \"Authorization\",\n            realm,\n            http_handler,\n            password_manager,\n            \"http://acme.example.com/protected\",\n            \"http://acme.example.com/protected\", )\n\n    def test_basic_auth_with_single_quoted_realm(self):\n        self.test_basic_auth(quote_char=\"'\")\n\n    def test_proxy_basic_auth(self):\n        opener = OpenerDirector()\n        ph = mechanize.ProxyHandler(dict(http=\"proxy.example.com:3128\"))\n        opener.add_handler(ph)\n        password_manager = MockPasswordManager()\n        auth_handler = mechanize.ProxyBasicAuthHandler(password_manager)\n        realm = \"ACME Networks\"\n        http_handler = MockHTTPHandler(\n            407, 'Proxy-Authenticate: Basic realm=\"%s\"\\r\\n\\r\\n' % realm)\n        opener.add_handler(auth_handler)\n        opener.add_handler(http_handler)\n        self._test_basic_auth(\n            opener,\n            auth_handler,\n            \"Proxy-authorization\",\n            realm,\n            http_handler,\n            password_manager,\n            \"http://acme.example.com:3128/protected\",\n            \"proxy.example.com:3128\", )\n\n    def test_proxy_https_proxy_authorization(self):\n        o = OpenerDirector()\n        ph = mechanize.ProxyHandler(dict(https='proxy.example.com:3128'))\n        o.add_handler(ph)\n        https_handler = MockHTTPSHandler()\n        o.add_handler(https_handler)\n        req = Request(\"https://www.example.com/\")\n        req.add_header(\"Proxy-Authorization\", \"FooBar\")\n        req.add_header(\"User-Agent\", \"Grail\")\n        self.assertEqual(req.get_host(), \"www.example.com\")\n        self.assertIsNone(req._tunnel_host)\n        o.open(req)\n        # Verify Proxy-Authorization gets tunneled to request.\n        # httpsconn req_headers do not have the Proxy-Authorization header but\n        # the req will have.\n        self.assertNotIn(\n            (\"Proxy-Authorization\", \"FooBar\"),\n            https_handler.httpconn.req_headers)\n        self.assertIn(\n            (\"User-Agent\", \"Grail\"), https_handler.httpconn.req_headers)\n        self.assertIsNotNone(req._tunnel_host)\n        self.assertEqual(req.get_host(), \"proxy.example.com:3128\")\n        self.assertEqual(req.get_header(\"Proxy-authorization\"), \"FooBar\")\n\n    def test_basic_and_digest_auth_handlers(self):\n        # HTTPDigestAuthHandler threw an exception if it couldn't handle a 40*\n        # response (http://python.org/sf/1479302), where it should instead\n        # return None to allow another handler (especially\n        # HTTPBasicAuthHandler) to handle the response.\n\n        # Also (http://python.org/sf/1479302, RFC 2617 section 1.2), we must\n        # try digest first (since it's the strongest auth scheme), so we record\n        # order of calls here to check digest comes first:\n        class RecordingOpenerDirector(OpenerDirector):\n            def __init__(self):\n                OpenerDirector.__init__(self)\n                self.recorded = []\n\n            def record(self, info):\n                self.recorded.append(info)\n\n        class TestDigestAuthHandler(mechanize.HTTPDigestAuthHandler):\n            def http_error_401(self, *args, **kwds):\n                self.parent.record(\"digest\")\n                mechanize.HTTPDigestAuthHandler.http_error_401(self, *args,\n                                                               **kwds)\n\n        class TestBasicAuthHandler(mechanize.HTTPBasicAuthHandler):\n            def http_error_401(self, *args, **kwds):\n                self.parent.record(\"basic\")\n                mechanize.HTTPBasicAuthHandler.http_error_401(self, *args,\n                                                              **kwds)\n\n        opener = RecordingOpenerDirector()\n        password_manager = MockPasswordManager()\n        digest_handler = TestDigestAuthHandler(password_manager)\n        basic_handler = TestBasicAuthHandler(password_manager)\n        realm = \"ACME Networks\"\n        http_handler = MockHTTPHandler(\n            401, 'WWW-Authenticate: Basic realm=\"%s\"\\r\\n\\r\\n' % realm)\n        opener.add_handler(digest_handler)\n        opener.add_handler(basic_handler)\n        opener.add_handler(http_handler)\n        opener._maybe_reindex_handlers()\n\n        # check basic auth isn't blocked by digest handler failing\n        self._test_basic_auth(\n            opener,\n            basic_handler,\n            \"Authorization\",\n            realm,\n            http_handler,\n            password_manager,\n            \"http://acme.example.com/protected\",\n            \"http://acme.example.com/protected\", )\n        # check digest was tried before basic (twice, because\n        # _test_basic_auth called .open() twice)\n        self.assertEqual(opener.recorded, [\"digest\", \"basic\"] * 2)\n\n    def _test_basic_auth(self, opener, auth_handler, auth_header, realm,\n                         http_handler, password_manager, request_url,\n                         protected_url):\n        import base64\n        user, password = \"wile\", \"coyote\"\n\n        # .add_password() fed through to password manager\n        auth_handler.add_password(realm, request_url, user, password)\n        self.assertEqual(realm, password_manager.realm)\n        self.assertEqual(request_url, password_manager.url)\n        self.assertEqual(user, password_manager.user)\n        self.assertEqual(password, password_manager.password)\n\n        opener.open(request_url)\n\n        # should have asked the password manager for the username/password\n        self.assertEqual(password_manager.target_realm, realm)\n        self.assertEqual(password_manager.target_url, protected_url)\n\n        # expect one request without authorization, then one with\n        self.assertEqual(len(http_handler.requests), 2)\n        self.assertFalse(http_handler.requests[0].has_header(auth_header))\n        userpass = ('%s:%s' % (user, password)).encode('utf-8')\n        auth_hdr_value = b'Basic ' + base64.b64encode(userpass).strip()\n        self.assertEqual(http_handler.requests[1].get_header(auth_header),\n                         auth_hdr_value.decode('ascii'))\n\n        # if the password manager can't find a password, the handler won't\n        # handle the HTTP auth error\n        password_manager.user = password_manager.password = None\n        http_handler.reset()\n        opener.open(request_url)\n        self.assertEqual(len(http_handler.requests), 1)\n        self.assertFalse(http_handler.requests[0].has_header(auth_header))\n\n\nclass HeadParserTests(unittest.TestCase):\n    def test(self):\n        from mechanize import HTTPEquivParser\n        htmls = [\n            (\n                b\"\"\"<meta http-equiv=refresh content=\"1; http://example.com/\">\n                \"\"\", [(b\"refresh\", b\"1; http://example.com/\")]),\n\n            (\n                b\"\"\"\n                <html><head><title>\\xea</title>\n                <meta http-equiv=\"refresh\" content=\"1; http://example.com/\">\n                <meta name=\"spam\" content=\"eggs\">\n                <meta content=\"b&bsol;ar\" http-equiv=\"f&Newline;oo\">\n                <p> <!-- p is not allowed in head, so parsing should stop -->\n                <meta http-equiv=\"moo\" content=\"cow\">\n                </html>\n                \"\"\",\n                [\n                    (b\"refresh\", b\"1; http://example.com/\"),\n                    (b\"f\\noo\", b\"b\\\\ar\")\n                ]),\n\n            (\n                b\"\"\"<meta http-equiv=\"refresh\">\n                \"\"\", []),\n\n        ]\n        for html, result in htmls:\n            headers = HTTPEquivParser(html)()\n            self.assertEqual(result, headers)\n\n\nclass A:\n    def a(self):\n        pass\n\n\nclass B(A):\n    def a(self):\n        pass\n\n    def b(self):\n        pass\n\n\nclass C(A):\n    def c(self):\n        pass\n\n\nclass D(C, B):\n    def a(self):\n        pass\n\n    def d(self):\n        pass\n\n\nclass FunctionTests(unittest.TestCase):\n    def test_build_opener(self):\n        class MyHTTPHandler(HTTPHandler):\n            pass\n\n        class FooHandler(mechanize.BaseHandler):\n            def foo_open(self):\n                pass\n\n        class BarHandler(mechanize.BaseHandler):\n            def bar_open(self):\n                pass\n\n        o = build_opener(FooHandler, BarHandler)\n        self.opener_has_handler(o, FooHandler)\n        self.opener_has_handler(o, BarHandler)\n\n        # can take a mix of classes and instances\n        o = build_opener(FooHandler, BarHandler())\n        self.opener_has_handler(o, FooHandler)\n        self.opener_has_handler(o, BarHandler)\n\n        # subclasses of default handlers override default handlers\n        o = build_opener(MyHTTPHandler)\n        self.opener_has_handler(o, MyHTTPHandler)\n\n        # a particular case of overriding: default handlers can be passed\n        # in explicitly\n        o = build_opener()\n        self.opener_has_handler(o, HTTPHandler)\n        o = build_opener(HTTPHandler)\n        self.opener_has_handler(o, HTTPHandler)\n        o = build_opener(HTTPHandler())\n        self.opener_has_handler(o, HTTPHandler)\n\n        # Issue2670: multiple handlers sharing the same base class\n        class MyOtherHTTPHandler(HTTPHandler):\n            pass\n\n        o = build_opener(MyHTTPHandler, MyOtherHTTPHandler)\n        self.opener_has_handler(o, MyHTTPHandler)\n        self.opener_has_handler(o, MyOtherHTTPHandler)\n\n    def opener_has_handler(self, opener, handler_class):\n        for h in opener.handlers:\n            if h.__class__ == handler_class:\n                break\n        else:\n            self.assertTrue(False)\n\n\nclass RequestTests(unittest.TestCase):\n    def setUp(self):\n        self.get = Request(\"http://www.python.org/~jeremy/\")\n        self.post = Request(\n            \"http://www.python.org/~jeremy/\",\n            \"data\",\n            headers={\"X-Test\": \"test\"})\n\n    def test_method(self):\n        self.assertEqual(\"POST\", self.post.get_method())\n        self.assertEqual(\"GET\", self.get.get_method())\n\n    def test_add_data(self):\n        self.assertTrue(not self.get.has_data())\n        self.assertEqual(\"GET\", self.get.get_method())\n        self.get.add_data(\"spam\")\n        self.assertTrue(self.get.has_data())\n        self.assertEqual(\"POST\", self.get.get_method())\n\n    def test_get_full_url(self):\n        self.assertEqual(\"http://www.python.org/%7Ejeremy/\",\n                         self.get.get_full_url())\n\n    def test_selector(self):\n        self.assertEqual(\"/%7Ejeremy/\", self.get.get_selector())\n        req = Request(\"http://www.python.org/\")\n        self.assertEqual(\"/\", req.get_selector())\n\n    def test_normalize_url(self):\n        def t(x, expected=None):\n            self.assertEqual(normalize_url(x), expected or x)\n\n        t('https://simple.com/moo%7Ese')\n        t('https://ex.com/Sp\u00f6rt', 'https://ex.com/Sp%C3%B6rt')\n        t('https://ex.com/Sp%C3%B6rt')\n\n    def test_get_type(self):\n        self.assertEqual(\"http\", self.get.get_type())\n\n    def test_get_host(self):\n        self.assertEqual(\"www.python.org\", self.get.get_host())\n\n    def test_get_host_unquote(self):\n        req = Request(\"http://www.%70ython.org/\")\n        self.assertEqual(\"www.python.org\", req.get_host())\n\n    def test_proxy(self):\n        self.assertTrue(not self.get.has_proxy())\n        self.get.set_proxy(\"www.perl.org\", \"http\")\n        self.assertTrue(self.get.has_proxy())\n        self.assertEqual(\"www.python.org\", self.get.get_origin_req_host())\n        self.assertEqual(\"www.perl.org\", self.get.get_host())\n\n    def test_data(self):\n        r = Request('https://example.com', data={'a': 1})\n        self.assertEqual(r.get_method(), 'POST')\n        self.assertEqual(r.get_data(), 'a=1')\n        r = Request('https://example.com', data={'a': 1}, method='GET')\n        self.assertEqual(r.get_method(), 'GET')\n        self.assertEqual(r.get_data(), None)\n        self.assertEqual(r.get_full_url(), 'https://example.com?a=1')\n\n\nif __name__ == \"__main__\":\n    import doctest\n    doctest.testmod()\n    unittest.main()\n"], "filenames": ["mechanize/_urllib2_fork.py", "test/test_urllib2.py"], "buggy_code_start_loc": [878, 27], "buggy_code_end_loc": [880, 70], "fixing_code_start_loc": [878, 27], "fixing_code_end_loc": [887, 75], "type": "CWE-1333", "message": "mechanize, a library for automatically interacting with HTTP web servers, contains a regular expression that is vulnerable to regular expression denial of service (ReDoS) prior to version 0.4.6. If a web server responds in a malicious way, then mechanize could crash. Version 0.4.6 has a patch for the issue.", "other": {"cve": {"id": "CVE-2021-32837", "sourceIdentifier": "security-advisories@github.com", "published": "2023-01-17T22:15:10.533", "lastModified": "2023-01-25T02:14:30.137", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "mechanize, a library for automatically interacting with HTTP web servers, contains a regular expression that is vulnerable to regular expression denial of service (ReDoS) prior to version 0.4.6. If a web server responds in a malicious way, then mechanize could crash. Version 0.4.6 has a patch for the issue."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-1333"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:mechanize_project:mechanize:*:*:*:*:*:python:*:*", "versionEndExcluding": "0.4.6", "matchCriteriaId": "29D79742-1F31-48EC-B67A-A49B3B73EADE"}]}]}], "references": [{"url": "https://github.com/python-mechanize/mechanize/blob/3acb1836f3fd8edc5a758a417dd46b53832ae3b5/mechanize/_urllib2_fork.py#L878-L879", "source": "security-advisories@github.com", "tags": ["Exploit", "Third Party Advisory"]}, {"url": "https://github.com/python-mechanize/mechanize/commit/dd05334448e9f39814bab044d2eaa5ef69b410d6", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/python-mechanize/mechanize/releases/tag/v0.4.6", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}, {"url": "https://securitylab.github.com/advisories/GHSL-2021-108-python-mechanize-mechanize/", "source": "security-advisories@github.com", "tags": ["Exploit", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/python-mechanize/mechanize/commit/dd05334448e9f39814bab044d2eaa5ef69b410d6"}}
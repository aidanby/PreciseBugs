{"buggy_code": ["/*\n * Central processing for nfsd.\n *\n * Authors:\tOlaf Kirch (okir@monad.swb.de)\n *\n * Copyright (C) 1995, 1996, 1997 Olaf Kirch <okir@monad.swb.de>\n */\n\n#include <linux/sched/signal.h>\n#include <linux/freezer.h>\n#include <linux/module.h>\n#include <linux/fs_struct.h>\n#include <linux/swap.h>\n\n#include <linux/sunrpc/stats.h>\n#include <linux/sunrpc/svcsock.h>\n#include <linux/sunrpc/svc_xprt.h>\n#include <linux/lockd/bind.h>\n#include <linux/nfsacl.h>\n#include <linux/seq_file.h>\n#include <linux/inetdevice.h>\n#include <net/addrconf.h>\n#include <net/ipv6.h>\n#include <net/net_namespace.h>\n#include \"nfsd.h\"\n#include \"cache.h\"\n#include \"vfs.h\"\n#include \"netns.h\"\n\n#define NFSDDBG_FACILITY\tNFSDDBG_SVC\n\nextern struct svc_program\tnfsd_program;\nstatic int\t\t\tnfsd(void *vrqstp);\n\n/*\n * nfsd_mutex protects nn->nfsd_serv -- both the pointer itself and the members\n * of the svc_serv struct. In particular, ->sv_nrthreads but also to some\n * extent ->sv_temp_socks and ->sv_permsocks. It also protects nfsdstats.th_cnt\n *\n * If (out side the lock) nn->nfsd_serv is non-NULL, then it must point to a\n * properly initialised 'struct svc_serv' with ->sv_nrthreads > 0. That number\n * of nfsd threads must exist and each must listed in ->sp_all_threads in each\n * entry of ->sv_pools[].\n *\n * Transitions of the thread count between zero and non-zero are of particular\n * interest since the svc_serv needs to be created and initialized at that\n * point, or freed.\n *\n * Finally, the nfsd_mutex also protects some of the global variables that are\n * accessed when nfsd starts and that are settable via the write_* routines in\n * nfsctl.c. In particular:\n *\n *\tuser_recovery_dirname\n *\tuser_lease_time\n *\tnfsd_versions\n */\nDEFINE_MUTEX(nfsd_mutex);\n\n/*\n * nfsd_drc_lock protects nfsd_drc_max_pages and nfsd_drc_pages_used.\n * nfsd_drc_max_pages limits the total amount of memory available for\n * version 4.1 DRC caches.\n * nfsd_drc_pages_used tracks the current version 4.1 DRC memory usage.\n */\nspinlock_t\tnfsd_drc_lock;\nunsigned long\tnfsd_drc_max_mem;\nunsigned long\tnfsd_drc_mem_used;\n\n#if defined(CONFIG_NFSD_V2_ACL) || defined(CONFIG_NFSD_V3_ACL)\nstatic struct svc_stat\tnfsd_acl_svcstats;\nstatic struct svc_version *\tnfsd_acl_version[] = {\n\t[2] = &nfsd_acl_version2,\n\t[3] = &nfsd_acl_version3,\n};\n\n#define NFSD_ACL_MINVERS            2\n#define NFSD_ACL_NRVERS\t\tARRAY_SIZE(nfsd_acl_version)\nstatic struct svc_version *nfsd_acl_versions[NFSD_ACL_NRVERS];\n\nstatic struct svc_program\tnfsd_acl_program = {\n\t.pg_prog\t\t= NFS_ACL_PROGRAM,\n\t.pg_nvers\t\t= NFSD_ACL_NRVERS,\n\t.pg_vers\t\t= nfsd_acl_versions,\n\t.pg_name\t\t= \"nfsacl\",\n\t.pg_class\t\t= \"nfsd\",\n\t.pg_stats\t\t= &nfsd_acl_svcstats,\n\t.pg_authenticate\t= &svc_set_client,\n};\n\nstatic struct svc_stat\tnfsd_acl_svcstats = {\n\t.program\t= &nfsd_acl_program,\n};\n#endif /* defined(CONFIG_NFSD_V2_ACL) || defined(CONFIG_NFSD_V3_ACL) */\n\nstatic struct svc_version *\tnfsd_version[] = {\n\t[2] = &nfsd_version2,\n#if defined(CONFIG_NFSD_V3)\n\t[3] = &nfsd_version3,\n#endif\n#if defined(CONFIG_NFSD_V4)\n\t[4] = &nfsd_version4,\n#endif\n};\n\n#define NFSD_MINVERS    \t2\n#define NFSD_NRVERS\t\tARRAY_SIZE(nfsd_version)\nstatic struct svc_version *nfsd_versions[NFSD_NRVERS];\n\nstruct svc_program\t\tnfsd_program = {\n#if defined(CONFIG_NFSD_V2_ACL) || defined(CONFIG_NFSD_V3_ACL)\n\t.pg_next\t\t= &nfsd_acl_program,\n#endif\n\t.pg_prog\t\t= NFS_PROGRAM,\t\t/* program number */\n\t.pg_nvers\t\t= NFSD_NRVERS,\t\t/* nr of entries in nfsd_version */\n\t.pg_vers\t\t= nfsd_versions,\t/* version table */\n\t.pg_name\t\t= \"nfsd\",\t\t/* program name */\n\t.pg_class\t\t= \"nfsd\",\t\t/* authentication class */\n\t.pg_stats\t\t= &nfsd_svcstats,\t/* version table */\n\t.pg_authenticate\t= &svc_set_client,\t/* export authentication */\n\n};\n\nstatic bool nfsd_supported_minorversions[NFSD_SUPPORTED_MINOR_VERSION + 1] = {\n\t[0] = 1,\n\t[1] = 1,\n\t[2] = 1,\n};\n\nint nfsd_vers(int vers, enum vers_op change)\n{\n\tif (vers < NFSD_MINVERS || vers >= NFSD_NRVERS)\n\t\treturn 0;\n\tswitch(change) {\n\tcase NFSD_SET:\n\t\tnfsd_versions[vers] = nfsd_version[vers];\n#if defined(CONFIG_NFSD_V2_ACL) || defined(CONFIG_NFSD_V3_ACL)\n\t\tif (vers < NFSD_ACL_NRVERS)\n\t\t\tnfsd_acl_versions[vers] = nfsd_acl_version[vers];\n#endif\n\t\tbreak;\n\tcase NFSD_CLEAR:\n\t\tnfsd_versions[vers] = NULL;\n#if defined(CONFIG_NFSD_V2_ACL) || defined(CONFIG_NFSD_V3_ACL)\n\t\tif (vers < NFSD_ACL_NRVERS)\n\t\t\tnfsd_acl_versions[vers] = NULL;\n#endif\n\t\tbreak;\n\tcase NFSD_TEST:\n\t\treturn nfsd_versions[vers] != NULL;\n\tcase NFSD_AVAIL:\n\t\treturn nfsd_version[vers] != NULL;\n\t}\n\treturn 0;\n}\n\nstatic void\nnfsd_adjust_nfsd_versions4(void)\n{\n\tunsigned i;\n\n\tfor (i = 0; i <= NFSD_SUPPORTED_MINOR_VERSION; i++) {\n\t\tif (nfsd_supported_minorversions[i])\n\t\t\treturn;\n\t}\n\tnfsd_vers(4, NFSD_CLEAR);\n}\n\nint nfsd_minorversion(u32 minorversion, enum vers_op change)\n{\n\tif (minorversion > NFSD_SUPPORTED_MINOR_VERSION &&\n\t    change != NFSD_AVAIL)\n\t\treturn -1;\n\tswitch(change) {\n\tcase NFSD_SET:\n\t\tnfsd_supported_minorversions[minorversion] = true;\n\t\tnfsd_vers(4, NFSD_SET);\n\t\tbreak;\n\tcase NFSD_CLEAR:\n\t\tnfsd_supported_minorversions[minorversion] = false;\n\t\tnfsd_adjust_nfsd_versions4();\n\t\tbreak;\n\tcase NFSD_TEST:\n\t\treturn nfsd_supported_minorversions[minorversion];\n\tcase NFSD_AVAIL:\n\t\treturn minorversion <= NFSD_SUPPORTED_MINOR_VERSION;\n\t}\n\treturn 0;\n}\n\n/*\n * Maximum number of nfsd processes\n */\n#define\tNFSD_MAXSERVS\t\t8192\n\nint nfsd_nrthreads(struct net *net)\n{\n\tint rv = 0;\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\n\tmutex_lock(&nfsd_mutex);\n\tif (nn->nfsd_serv)\n\t\trv = nn->nfsd_serv->sv_nrthreads;\n\tmutex_unlock(&nfsd_mutex);\n\treturn rv;\n}\n\nstatic int nfsd_init_socks(struct net *net)\n{\n\tint error;\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\n\tif (!list_empty(&nn->nfsd_serv->sv_permsocks))\n\t\treturn 0;\n\n\terror = svc_create_xprt(nn->nfsd_serv, \"udp\", net, PF_INET, NFS_PORT,\n\t\t\t\t\tSVC_SOCK_DEFAULTS);\n\tif (error < 0)\n\t\treturn error;\n\n\terror = svc_create_xprt(nn->nfsd_serv, \"tcp\", net, PF_INET, NFS_PORT,\n\t\t\t\t\tSVC_SOCK_DEFAULTS);\n\tif (error < 0)\n\t\treturn error;\n\n\treturn 0;\n}\n\nstatic int nfsd_users = 0;\n\nstatic int nfsd_startup_generic(int nrservs)\n{\n\tint ret;\n\n\tif (nfsd_users++)\n\t\treturn 0;\n\n\t/*\n\t * Readahead param cache - will no-op if it already exists.\n\t * (Note therefore results will be suboptimal if number of\n\t * threads is modified after nfsd start.)\n\t */\n\tret = nfsd_racache_init(2*nrservs);\n\tif (ret)\n\t\tgoto dec_users;\n\n\tret = nfs4_state_start();\n\tif (ret)\n\t\tgoto out_racache;\n\treturn 0;\n\nout_racache:\n\tnfsd_racache_shutdown();\ndec_users:\n\tnfsd_users--;\n\treturn ret;\n}\n\nstatic void nfsd_shutdown_generic(void)\n{\n\tif (--nfsd_users)\n\t\treturn;\n\n\tnfs4_state_shutdown();\n\tnfsd_racache_shutdown();\n}\n\nstatic bool nfsd_needs_lockd(void)\n{\n#if defined(CONFIG_NFSD_V3)\n\treturn (nfsd_versions[2] != NULL) || (nfsd_versions[3] != NULL);\n#else\n\treturn (nfsd_versions[2] != NULL);\n#endif\n}\n\nstatic int nfsd_startup_net(int nrservs, struct net *net)\n{\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\tint ret;\n\n\tif (nn->nfsd_net_up)\n\t\treturn 0;\n\n\tret = nfsd_startup_generic(nrservs);\n\tif (ret)\n\t\treturn ret;\n\tret = nfsd_init_socks(net);\n\tif (ret)\n\t\tgoto out_socks;\n\n\tif (nfsd_needs_lockd() && !nn->lockd_up) {\n\t\tret = lockd_up(net);\n\t\tif (ret)\n\t\t\tgoto out_socks;\n\t\tnn->lockd_up = 1;\n\t}\n\n\tret = nfs4_state_start_net(net);\n\tif (ret)\n\t\tgoto out_lockd;\n\n\tnn->nfsd_net_up = true;\n\treturn 0;\n\nout_lockd:\n\tif (nn->lockd_up) {\n\t\tlockd_down(net);\n\t\tnn->lockd_up = 0;\n\t}\nout_socks:\n\tnfsd_shutdown_generic();\n\treturn ret;\n}\n\nstatic void nfsd_shutdown_net(struct net *net)\n{\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\n\tnfs4_state_shutdown_net(net);\n\tif (nn->lockd_up) {\n\t\tlockd_down(net);\n\t\tnn->lockd_up = 0;\n\t}\n\tnn->nfsd_net_up = false;\n\tnfsd_shutdown_generic();\n}\n\nstatic int nfsd_inetaddr_event(struct notifier_block *this, unsigned long event,\n\tvoid *ptr)\n{\n\tstruct in_ifaddr *ifa = (struct in_ifaddr *)ptr;\n\tstruct net_device *dev = ifa->ifa_dev->dev;\n\tstruct net *net = dev_net(dev);\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\tstruct sockaddr_in sin;\n\n\tif (event != NETDEV_DOWN)\n\t\tgoto out;\n\n\tif (nn->nfsd_serv) {\n\t\tdprintk(\"nfsd_inetaddr_event: removed %pI4\\n\", &ifa->ifa_local);\n\t\tsin.sin_family = AF_INET;\n\t\tsin.sin_addr.s_addr = ifa->ifa_local;\n\t\tsvc_age_temp_xprts_now(nn->nfsd_serv, (struct sockaddr *)&sin);\n\t}\n\nout:\n\treturn NOTIFY_DONE;\n}\n\nstatic struct notifier_block nfsd_inetaddr_notifier = {\n\t.notifier_call = nfsd_inetaddr_event,\n};\n\n#if IS_ENABLED(CONFIG_IPV6)\nstatic int nfsd_inet6addr_event(struct notifier_block *this,\n\tunsigned long event, void *ptr)\n{\n\tstruct inet6_ifaddr *ifa = (struct inet6_ifaddr *)ptr;\n\tstruct net_device *dev = ifa->idev->dev;\n\tstruct net *net = dev_net(dev);\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\tstruct sockaddr_in6 sin6;\n\n\tif (event != NETDEV_DOWN)\n\t\tgoto out;\n\n\tif (nn->nfsd_serv) {\n\t\tdprintk(\"nfsd_inet6addr_event: removed %pI6\\n\", &ifa->addr);\n\t\tsin6.sin6_family = AF_INET6;\n\t\tsin6.sin6_addr = ifa->addr;\n\t\tif (ipv6_addr_type(&sin6.sin6_addr) & IPV6_ADDR_LINKLOCAL)\n\t\t\tsin6.sin6_scope_id = ifa->idev->dev->ifindex;\n\t\tsvc_age_temp_xprts_now(nn->nfsd_serv, (struct sockaddr *)&sin6);\n\t}\n\nout:\n\treturn NOTIFY_DONE;\n}\n\nstatic struct notifier_block nfsd_inet6addr_notifier = {\n\t.notifier_call = nfsd_inet6addr_event,\n};\n#endif\n\n/* Only used under nfsd_mutex, so this atomic may be overkill: */\nstatic atomic_t nfsd_notifier_refcount = ATOMIC_INIT(0);\n\nstatic void nfsd_last_thread(struct svc_serv *serv, struct net *net)\n{\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\n\t/* check if the notifier still has clients */\n\tif (atomic_dec_return(&nfsd_notifier_refcount) == 0) {\n\t\tunregister_inetaddr_notifier(&nfsd_inetaddr_notifier);\n#if IS_ENABLED(CONFIG_IPV6)\n\t\tunregister_inet6addr_notifier(&nfsd_inet6addr_notifier);\n#endif\n\t}\n\n\t/*\n\t * write_ports can create the server without actually starting\n\t * any threads--if we get shut down before any threads are\n\t * started, then nfsd_last_thread will be run before any of this\n\t * other initialization has been done except the rpcb information.\n\t */\n\tsvc_rpcb_cleanup(serv, net);\n\tif (!nn->nfsd_net_up)\n\t\treturn;\n\n\tnfsd_shutdown_net(net);\n\tprintk(KERN_WARNING \"nfsd: last server has exited, flushing export \"\n\t\t\t    \"cache\\n\");\n\tnfsd_export_flush(net);\n}\n\nvoid nfsd_reset_versions(void)\n{\n\tint i;\n\n\tfor (i = 0; i < NFSD_NRVERS; i++)\n\t\tif (nfsd_vers(i, NFSD_TEST))\n\t\t\treturn;\n\n\tfor (i = 0; i < NFSD_NRVERS; i++)\n\t\tif (i != 4)\n\t\t\tnfsd_vers(i, NFSD_SET);\n\t\telse {\n\t\t\tint minor = 0;\n\t\t\twhile (nfsd_minorversion(minor, NFSD_SET) >= 0)\n\t\t\t\tminor++;\n\t\t}\n}\n\n/*\n * Each session guarantees a negotiated per slot memory cache for replies\n * which in turn consumes memory beyond the v2/v3/v4.0 server. A dedicated\n * NFSv4.1 server might want to use more memory for a DRC than a machine\n * with mutiple services.\n *\n * Impose a hard limit on the number of pages for the DRC which varies\n * according to the machines free pages. This is of course only a default.\n *\n * For now this is a #defined shift which could be under admin control\n * in the future.\n */\nstatic void set_max_drc(void)\n{\n\t#define NFSD_DRC_SIZE_SHIFT\t10\n\tnfsd_drc_max_mem = (nr_free_buffer_pages()\n\t\t\t\t\t>> NFSD_DRC_SIZE_SHIFT) * PAGE_SIZE;\n\tnfsd_drc_mem_used = 0;\n\tspin_lock_init(&nfsd_drc_lock);\n\tdprintk(\"%s nfsd_drc_max_mem %lu \\n\", __func__, nfsd_drc_max_mem);\n}\n\nstatic int nfsd_get_default_max_blksize(void)\n{\n\tstruct sysinfo i;\n\tunsigned long long target;\n\tunsigned long ret;\n\n\tsi_meminfo(&i);\n\ttarget = (i.totalram - i.totalhigh) << PAGE_SHIFT;\n\t/*\n\t * Aim for 1/4096 of memory per thread This gives 1MB on 4Gig\n\t * machines, but only uses 32K on 128M machines.  Bottom out at\n\t * 8K on 32M and smaller.  Of course, this is only a default.\n\t */\n\ttarget >>= 12;\n\n\tret = NFSSVC_MAXBLKSIZE;\n\twhile (ret > target && ret >= 8*1024*2)\n\t\tret /= 2;\n\treturn ret;\n}\n\nstatic struct svc_serv_ops nfsd_thread_sv_ops = {\n\t.svo_shutdown\t\t= nfsd_last_thread,\n\t.svo_function\t\t= nfsd,\n\t.svo_enqueue_xprt\t= svc_xprt_do_enqueue,\n\t.svo_setup\t\t= svc_set_num_threads,\n\t.svo_module\t\t= THIS_MODULE,\n};\n\nint nfsd_create_serv(struct net *net)\n{\n\tint error;\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\n\tWARN_ON(!mutex_is_locked(&nfsd_mutex));\n\tif (nn->nfsd_serv) {\n\t\tsvc_get(nn->nfsd_serv);\n\t\treturn 0;\n\t}\n\tif (nfsd_max_blksize == 0)\n\t\tnfsd_max_blksize = nfsd_get_default_max_blksize();\n\tnfsd_reset_versions();\n\tnn->nfsd_serv = svc_create_pooled(&nfsd_program, nfsd_max_blksize,\n\t\t\t\t\t\t&nfsd_thread_sv_ops);\n\tif (nn->nfsd_serv == NULL)\n\t\treturn -ENOMEM;\n\n\tnn->nfsd_serv->sv_maxconn = nn->max_connections;\n\terror = svc_bind(nn->nfsd_serv, net);\n\tif (error < 0) {\n\t\tsvc_destroy(nn->nfsd_serv);\n\t\treturn error;\n\t}\n\n\tset_max_drc();\n\t/* check if the notifier is already set */\n\tif (atomic_inc_return(&nfsd_notifier_refcount) == 1) {\n\t\tregister_inetaddr_notifier(&nfsd_inetaddr_notifier);\n#if IS_ENABLED(CONFIG_IPV6)\n\t\tregister_inet6addr_notifier(&nfsd_inet6addr_notifier);\n#endif\n\t}\n\tdo_gettimeofday(&nn->nfssvc_boot);\t\t/* record boot time */\n\treturn 0;\n}\n\nint nfsd_nrpools(struct net *net)\n{\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\n\tif (nn->nfsd_serv == NULL)\n\t\treturn 0;\n\telse\n\t\treturn nn->nfsd_serv->sv_nrpools;\n}\n\nint nfsd_get_nrthreads(int n, int *nthreads, struct net *net)\n{\n\tint i = 0;\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\n\tif (nn->nfsd_serv != NULL) {\n\t\tfor (i = 0; i < nn->nfsd_serv->sv_nrpools && i < n; i++)\n\t\t\tnthreads[i] = nn->nfsd_serv->sv_pools[i].sp_nrthreads;\n\t}\n\n\treturn 0;\n}\n\nvoid nfsd_destroy(struct net *net)\n{\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\tint destroy = (nn->nfsd_serv->sv_nrthreads == 1);\n\n\tif (destroy)\n\t\tsvc_shutdown_net(nn->nfsd_serv, net);\n\tsvc_destroy(nn->nfsd_serv);\n\tif (destroy)\n\t\tnn->nfsd_serv = NULL;\n}\n\nint nfsd_set_nrthreads(int n, int *nthreads, struct net *net)\n{\n\tint i = 0;\n\tint tot = 0;\n\tint err = 0;\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\n\tWARN_ON(!mutex_is_locked(&nfsd_mutex));\n\n\tif (nn->nfsd_serv == NULL || n <= 0)\n\t\treturn 0;\n\n\tif (n > nn->nfsd_serv->sv_nrpools)\n\t\tn = nn->nfsd_serv->sv_nrpools;\n\n\t/* enforce a global maximum number of threads */\n\ttot = 0;\n\tfor (i = 0; i < n; i++) {\n\t\tnthreads[i] = min(nthreads[i], NFSD_MAXSERVS);\n\t\ttot += nthreads[i];\n\t}\n\tif (tot > NFSD_MAXSERVS) {\n\t\t/* total too large: scale down requested numbers */\n\t\tfor (i = 0; i < n && tot > 0; i++) {\n\t\t    \tint new = nthreads[i] * NFSD_MAXSERVS / tot;\n\t\t\ttot -= (nthreads[i] - new);\n\t\t\tnthreads[i] = new;\n\t\t}\n\t\tfor (i = 0; i < n && tot > 0; i++) {\n\t\t\tnthreads[i]--;\n\t\t\ttot--;\n\t\t}\n\t}\n\n\t/*\n\t * There must always be a thread in pool 0; the admin\n\t * can't shut down NFS completely using pool_threads.\n\t */\n\tif (nthreads[0] == 0)\n\t\tnthreads[0] = 1;\n\n\t/* apply the new numbers */\n\tsvc_get(nn->nfsd_serv);\n\tfor (i = 0; i < n; i++) {\n\t\terr = nn->nfsd_serv->sv_ops->svo_setup(nn->nfsd_serv,\n\t\t\t\t&nn->nfsd_serv->sv_pools[i], nthreads[i]);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\tnfsd_destroy(net);\n\treturn err;\n}\n\n/*\n * Adjust the number of threads and return the new number of threads.\n * This is also the function that starts the server if necessary, if\n * this is the first time nrservs is nonzero.\n */\nint\nnfsd_svc(int nrservs, struct net *net)\n{\n\tint\terror;\n\tbool\tnfsd_up_before;\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\n\tmutex_lock(&nfsd_mutex);\n\tdprintk(\"nfsd: creating service\\n\");\n\n\tnrservs = max(nrservs, 0);\n\tnrservs = min(nrservs, NFSD_MAXSERVS);\n\terror = 0;\n\n\tif (nrservs == 0 && nn->nfsd_serv == NULL)\n\t\tgoto out;\n\n\terror = nfsd_create_serv(net);\n\tif (error)\n\t\tgoto out;\n\n\tnfsd_up_before = nn->nfsd_net_up;\n\n\terror = nfsd_startup_net(nrservs, net);\n\tif (error)\n\t\tgoto out_destroy;\n\terror = nn->nfsd_serv->sv_ops->svo_setup(nn->nfsd_serv,\n\t\t\tNULL, nrservs);\n\tif (error)\n\t\tgoto out_shutdown;\n\t/* We are holding a reference to nn->nfsd_serv which\n\t * we don't want to count in the return value,\n\t * so subtract 1\n\t */\n\terror = nn->nfsd_serv->sv_nrthreads - 1;\nout_shutdown:\n\tif (error < 0 && !nfsd_up_before)\n\t\tnfsd_shutdown_net(net);\nout_destroy:\n\tnfsd_destroy(net);\t\t/* Release server */\nout:\n\tmutex_unlock(&nfsd_mutex);\n\treturn error;\n}\n\n\n/*\n * This is the NFS server kernel thread\n */\nstatic int\nnfsd(void *vrqstp)\n{\n\tstruct svc_rqst *rqstp = (struct svc_rqst *) vrqstp;\n\tstruct svc_xprt *perm_sock = list_entry(rqstp->rq_server->sv_permsocks.next, typeof(struct svc_xprt), xpt_list);\n\tstruct net *net = perm_sock->xpt_net;\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\tint err;\n\n\t/* Lock module and set up kernel thread */\n\tmutex_lock(&nfsd_mutex);\n\n\t/* At this point, the thread shares current->fs\n\t * with the init process. We need to create files with the\n\t * umask as defined by the client instead of init's umask. */\n\tif (unshare_fs_struct() < 0) {\n\t\tprintk(\"Unable to start nfsd thread: out of memory\\n\");\n\t\tgoto out;\n\t}\n\n\tcurrent->fs->umask = 0;\n\n\t/*\n\t * thread is spawned with all signals set to SIG_IGN, re-enable\n\t * the ones that will bring down the thread\n\t */\n\tallow_signal(SIGKILL);\n\tallow_signal(SIGHUP);\n\tallow_signal(SIGINT);\n\tallow_signal(SIGQUIT);\n\n\tnfsdstats.th_cnt++;\n\tmutex_unlock(&nfsd_mutex);\n\n\tset_freezable();\n\n\t/*\n\t * The main request loop\n\t */\n\tfor (;;) {\n\t\t/* Update sv_maxconn if it has changed */\n\t\trqstp->rq_server->sv_maxconn = nn->max_connections;\n\n\t\t/*\n\t\t * Find a socket with data available and call its\n\t\t * recvfrom routine.\n\t\t */\n\t\twhile ((err = svc_recv(rqstp, 60*60*HZ)) == -EAGAIN)\n\t\t\t;\n\t\tif (err == -EINTR)\n\t\t\tbreak;\n\t\tvalidate_process_creds();\n\t\tsvc_process(rqstp);\n\t\tvalidate_process_creds();\n\t}\n\n\t/* Clear signals before calling svc_exit_thread() */\n\tflush_signals(current);\n\n\tmutex_lock(&nfsd_mutex);\n\tnfsdstats.th_cnt --;\n\nout:\n\trqstp->rq_server = NULL;\n\n\t/* Release the thread */\n\tsvc_exit_thread(rqstp);\n\n\tnfsd_destroy(net);\n\n\t/* Release module */\n\tmutex_unlock(&nfsd_mutex);\n\tmodule_put_and_exit(0);\n\treturn 0;\n}\n\nstatic __be32 map_new_errors(u32 vers, __be32 nfserr)\n{\n\tif (nfserr == nfserr_jukebox && vers == 2)\n\t\treturn nfserr_dropit;\n\tif (nfserr == nfserr_wrongsec && vers < 4)\n\t\treturn nfserr_acces;\n\treturn nfserr;\n}\n\nint\nnfsd_dispatch(struct svc_rqst *rqstp, __be32 *statp)\n{\n\tstruct svc_procedure\t*proc;\n\tkxdrproc_t\t\txdr;\n\t__be32\t\t\tnfserr;\n\t__be32\t\t\t*nfserrp;\n\n\tdprintk(\"nfsd_dispatch: vers %d proc %d\\n\",\n\t\t\t\trqstp->rq_vers, rqstp->rq_proc);\n\tproc = rqstp->rq_procinfo;\n\n\t/*\n\t * Give the xdr decoder a chance to change this if it wants\n\t * (necessary in the NFSv4.0 compound case)\n\t */\n\trqstp->rq_cachetype = proc->pc_cachetype;\n\t/* Decode arguments */\n\txdr = proc->pc_decode;\n\tif (xdr && !xdr(rqstp, (__be32*)rqstp->rq_arg.head[0].iov_base,\n\t\t\trqstp->rq_argp)) {\n\t\tdprintk(\"nfsd: failed to decode arguments!\\n\");\n\t\t*statp = rpc_garbage_args;\n\t\treturn 1;\n\t}\n\n\t/* Check whether we have this call in the cache. */\n\tswitch (nfsd_cache_lookup(rqstp)) {\n\tcase RC_DROPIT:\n\t\treturn 0;\n\tcase RC_REPLY:\n\t\treturn 1;\n\tcase RC_DOIT:;\n\t\t/* do it */\n\t}\n\n\t/* need to grab the location to store the status, as\n\t * nfsv4 does some encoding while processing \n\t */\n\tnfserrp = rqstp->rq_res.head[0].iov_base\n\t\t+ rqstp->rq_res.head[0].iov_len;\n\trqstp->rq_res.head[0].iov_len += sizeof(__be32);\n\n\t/* Now call the procedure handler, and encode NFS status. */\n\tnfserr = proc->pc_func(rqstp, rqstp->rq_argp, rqstp->rq_resp);\n\tnfserr = map_new_errors(rqstp->rq_vers, nfserr);\n\tif (nfserr == nfserr_dropit || test_bit(RQ_DROPME, &rqstp->rq_flags)) {\n\t\tdprintk(\"nfsd: Dropping request; may be revisited later\\n\");\n\t\tnfsd_cache_update(rqstp, RC_NOCACHE, NULL);\n\t\treturn 0;\n\t}\n\n\tif (rqstp->rq_proc != 0)\n\t\t*nfserrp++ = nfserr;\n\n\t/* Encode result.\n\t * For NFSv2, additional info is never returned in case of an error.\n\t */\n\tif (!(nfserr && rqstp->rq_vers == 2)) {\n\t\txdr = proc->pc_encode;\n\t\tif (xdr && !xdr(rqstp, nfserrp,\n\t\t\t\trqstp->rq_resp)) {\n\t\t\t/* Failed to encode result. Release cache entry */\n\t\t\tdprintk(\"nfsd: failed to encode result!\\n\");\n\t\t\tnfsd_cache_update(rqstp, RC_NOCACHE, NULL);\n\t\t\t*statp = rpc_system_err;\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* Store reply in cache. */\n\tnfsd_cache_update(rqstp, rqstp->rq_cachetype, statp + 1);\n\treturn 1;\n}\n\nint nfsd_pool_stats_open(struct inode *inode, struct file *file)\n{\n\tint ret;\n\tstruct nfsd_net *nn = net_generic(inode->i_sb->s_fs_info, nfsd_net_id);\n\n\tmutex_lock(&nfsd_mutex);\n\tif (nn->nfsd_serv == NULL) {\n\t\tmutex_unlock(&nfsd_mutex);\n\t\treturn -ENODEV;\n\t}\n\t/* bump up the psudo refcount while traversing */\n\tsvc_get(nn->nfsd_serv);\n\tret = svc_pool_stats_open(nn->nfsd_serv, file);\n\tmutex_unlock(&nfsd_mutex);\n\treturn ret;\n}\n\nint nfsd_pool_stats_release(struct inode *inode, struct file *file)\n{\n\tint ret = seq_release(inode, file);\n\tstruct net *net = inode->i_sb->s_fs_info;\n\n\tmutex_lock(&nfsd_mutex);\n\t/* this function really, really should have been called svc_put() */\n\tnfsd_destroy(net);\n\tmutex_unlock(&nfsd_mutex);\n\treturn ret;\n}\n"], "fixing_code": ["/*\n * Central processing for nfsd.\n *\n * Authors:\tOlaf Kirch (okir@monad.swb.de)\n *\n * Copyright (C) 1995, 1996, 1997 Olaf Kirch <okir@monad.swb.de>\n */\n\n#include <linux/sched/signal.h>\n#include <linux/freezer.h>\n#include <linux/module.h>\n#include <linux/fs_struct.h>\n#include <linux/swap.h>\n\n#include <linux/sunrpc/stats.h>\n#include <linux/sunrpc/svcsock.h>\n#include <linux/sunrpc/svc_xprt.h>\n#include <linux/lockd/bind.h>\n#include <linux/nfsacl.h>\n#include <linux/seq_file.h>\n#include <linux/inetdevice.h>\n#include <net/addrconf.h>\n#include <net/ipv6.h>\n#include <net/net_namespace.h>\n#include \"nfsd.h\"\n#include \"cache.h\"\n#include \"vfs.h\"\n#include \"netns.h\"\n\n#define NFSDDBG_FACILITY\tNFSDDBG_SVC\n\nextern struct svc_program\tnfsd_program;\nstatic int\t\t\tnfsd(void *vrqstp);\n\n/*\n * nfsd_mutex protects nn->nfsd_serv -- both the pointer itself and the members\n * of the svc_serv struct. In particular, ->sv_nrthreads but also to some\n * extent ->sv_temp_socks and ->sv_permsocks. It also protects nfsdstats.th_cnt\n *\n * If (out side the lock) nn->nfsd_serv is non-NULL, then it must point to a\n * properly initialised 'struct svc_serv' with ->sv_nrthreads > 0. That number\n * of nfsd threads must exist and each must listed in ->sp_all_threads in each\n * entry of ->sv_pools[].\n *\n * Transitions of the thread count between zero and non-zero are of particular\n * interest since the svc_serv needs to be created and initialized at that\n * point, or freed.\n *\n * Finally, the nfsd_mutex also protects some of the global variables that are\n * accessed when nfsd starts and that are settable via the write_* routines in\n * nfsctl.c. In particular:\n *\n *\tuser_recovery_dirname\n *\tuser_lease_time\n *\tnfsd_versions\n */\nDEFINE_MUTEX(nfsd_mutex);\n\n/*\n * nfsd_drc_lock protects nfsd_drc_max_pages and nfsd_drc_pages_used.\n * nfsd_drc_max_pages limits the total amount of memory available for\n * version 4.1 DRC caches.\n * nfsd_drc_pages_used tracks the current version 4.1 DRC memory usage.\n */\nspinlock_t\tnfsd_drc_lock;\nunsigned long\tnfsd_drc_max_mem;\nunsigned long\tnfsd_drc_mem_used;\n\n#if defined(CONFIG_NFSD_V2_ACL) || defined(CONFIG_NFSD_V3_ACL)\nstatic struct svc_stat\tnfsd_acl_svcstats;\nstatic struct svc_version *\tnfsd_acl_version[] = {\n\t[2] = &nfsd_acl_version2,\n\t[3] = &nfsd_acl_version3,\n};\n\n#define NFSD_ACL_MINVERS            2\n#define NFSD_ACL_NRVERS\t\tARRAY_SIZE(nfsd_acl_version)\nstatic struct svc_version *nfsd_acl_versions[NFSD_ACL_NRVERS];\n\nstatic struct svc_program\tnfsd_acl_program = {\n\t.pg_prog\t\t= NFS_ACL_PROGRAM,\n\t.pg_nvers\t\t= NFSD_ACL_NRVERS,\n\t.pg_vers\t\t= nfsd_acl_versions,\n\t.pg_name\t\t= \"nfsacl\",\n\t.pg_class\t\t= \"nfsd\",\n\t.pg_stats\t\t= &nfsd_acl_svcstats,\n\t.pg_authenticate\t= &svc_set_client,\n};\n\nstatic struct svc_stat\tnfsd_acl_svcstats = {\n\t.program\t= &nfsd_acl_program,\n};\n#endif /* defined(CONFIG_NFSD_V2_ACL) || defined(CONFIG_NFSD_V3_ACL) */\n\nstatic struct svc_version *\tnfsd_version[] = {\n\t[2] = &nfsd_version2,\n#if defined(CONFIG_NFSD_V3)\n\t[3] = &nfsd_version3,\n#endif\n#if defined(CONFIG_NFSD_V4)\n\t[4] = &nfsd_version4,\n#endif\n};\n\n#define NFSD_MINVERS    \t2\n#define NFSD_NRVERS\t\tARRAY_SIZE(nfsd_version)\nstatic struct svc_version *nfsd_versions[NFSD_NRVERS];\n\nstruct svc_program\t\tnfsd_program = {\n#if defined(CONFIG_NFSD_V2_ACL) || defined(CONFIG_NFSD_V3_ACL)\n\t.pg_next\t\t= &nfsd_acl_program,\n#endif\n\t.pg_prog\t\t= NFS_PROGRAM,\t\t/* program number */\n\t.pg_nvers\t\t= NFSD_NRVERS,\t\t/* nr of entries in nfsd_version */\n\t.pg_vers\t\t= nfsd_versions,\t/* version table */\n\t.pg_name\t\t= \"nfsd\",\t\t/* program name */\n\t.pg_class\t\t= \"nfsd\",\t\t/* authentication class */\n\t.pg_stats\t\t= &nfsd_svcstats,\t/* version table */\n\t.pg_authenticate\t= &svc_set_client,\t/* export authentication */\n\n};\n\nstatic bool nfsd_supported_minorversions[NFSD_SUPPORTED_MINOR_VERSION + 1] = {\n\t[0] = 1,\n\t[1] = 1,\n\t[2] = 1,\n};\n\nint nfsd_vers(int vers, enum vers_op change)\n{\n\tif (vers < NFSD_MINVERS || vers >= NFSD_NRVERS)\n\t\treturn 0;\n\tswitch(change) {\n\tcase NFSD_SET:\n\t\tnfsd_versions[vers] = nfsd_version[vers];\n#if defined(CONFIG_NFSD_V2_ACL) || defined(CONFIG_NFSD_V3_ACL)\n\t\tif (vers < NFSD_ACL_NRVERS)\n\t\t\tnfsd_acl_versions[vers] = nfsd_acl_version[vers];\n#endif\n\t\tbreak;\n\tcase NFSD_CLEAR:\n\t\tnfsd_versions[vers] = NULL;\n#if defined(CONFIG_NFSD_V2_ACL) || defined(CONFIG_NFSD_V3_ACL)\n\t\tif (vers < NFSD_ACL_NRVERS)\n\t\t\tnfsd_acl_versions[vers] = NULL;\n#endif\n\t\tbreak;\n\tcase NFSD_TEST:\n\t\treturn nfsd_versions[vers] != NULL;\n\tcase NFSD_AVAIL:\n\t\treturn nfsd_version[vers] != NULL;\n\t}\n\treturn 0;\n}\n\nstatic void\nnfsd_adjust_nfsd_versions4(void)\n{\n\tunsigned i;\n\n\tfor (i = 0; i <= NFSD_SUPPORTED_MINOR_VERSION; i++) {\n\t\tif (nfsd_supported_minorversions[i])\n\t\t\treturn;\n\t}\n\tnfsd_vers(4, NFSD_CLEAR);\n}\n\nint nfsd_minorversion(u32 minorversion, enum vers_op change)\n{\n\tif (minorversion > NFSD_SUPPORTED_MINOR_VERSION &&\n\t    change != NFSD_AVAIL)\n\t\treturn -1;\n\tswitch(change) {\n\tcase NFSD_SET:\n\t\tnfsd_supported_minorversions[minorversion] = true;\n\t\tnfsd_vers(4, NFSD_SET);\n\t\tbreak;\n\tcase NFSD_CLEAR:\n\t\tnfsd_supported_minorversions[minorversion] = false;\n\t\tnfsd_adjust_nfsd_versions4();\n\t\tbreak;\n\tcase NFSD_TEST:\n\t\treturn nfsd_supported_minorversions[minorversion];\n\tcase NFSD_AVAIL:\n\t\treturn minorversion <= NFSD_SUPPORTED_MINOR_VERSION;\n\t}\n\treturn 0;\n}\n\n/*\n * Maximum number of nfsd processes\n */\n#define\tNFSD_MAXSERVS\t\t8192\n\nint nfsd_nrthreads(struct net *net)\n{\n\tint rv = 0;\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\n\tmutex_lock(&nfsd_mutex);\n\tif (nn->nfsd_serv)\n\t\trv = nn->nfsd_serv->sv_nrthreads;\n\tmutex_unlock(&nfsd_mutex);\n\treturn rv;\n}\n\nstatic int nfsd_init_socks(struct net *net)\n{\n\tint error;\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\n\tif (!list_empty(&nn->nfsd_serv->sv_permsocks))\n\t\treturn 0;\n\n\terror = svc_create_xprt(nn->nfsd_serv, \"udp\", net, PF_INET, NFS_PORT,\n\t\t\t\t\tSVC_SOCK_DEFAULTS);\n\tif (error < 0)\n\t\treturn error;\n\n\terror = svc_create_xprt(nn->nfsd_serv, \"tcp\", net, PF_INET, NFS_PORT,\n\t\t\t\t\tSVC_SOCK_DEFAULTS);\n\tif (error < 0)\n\t\treturn error;\n\n\treturn 0;\n}\n\nstatic int nfsd_users = 0;\n\nstatic int nfsd_startup_generic(int nrservs)\n{\n\tint ret;\n\n\tif (nfsd_users++)\n\t\treturn 0;\n\n\t/*\n\t * Readahead param cache - will no-op if it already exists.\n\t * (Note therefore results will be suboptimal if number of\n\t * threads is modified after nfsd start.)\n\t */\n\tret = nfsd_racache_init(2*nrservs);\n\tif (ret)\n\t\tgoto dec_users;\n\n\tret = nfs4_state_start();\n\tif (ret)\n\t\tgoto out_racache;\n\treturn 0;\n\nout_racache:\n\tnfsd_racache_shutdown();\ndec_users:\n\tnfsd_users--;\n\treturn ret;\n}\n\nstatic void nfsd_shutdown_generic(void)\n{\n\tif (--nfsd_users)\n\t\treturn;\n\n\tnfs4_state_shutdown();\n\tnfsd_racache_shutdown();\n}\n\nstatic bool nfsd_needs_lockd(void)\n{\n#if defined(CONFIG_NFSD_V3)\n\treturn (nfsd_versions[2] != NULL) || (nfsd_versions[3] != NULL);\n#else\n\treturn (nfsd_versions[2] != NULL);\n#endif\n}\n\nstatic int nfsd_startup_net(int nrservs, struct net *net)\n{\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\tint ret;\n\n\tif (nn->nfsd_net_up)\n\t\treturn 0;\n\n\tret = nfsd_startup_generic(nrservs);\n\tif (ret)\n\t\treturn ret;\n\tret = nfsd_init_socks(net);\n\tif (ret)\n\t\tgoto out_socks;\n\n\tif (nfsd_needs_lockd() && !nn->lockd_up) {\n\t\tret = lockd_up(net);\n\t\tif (ret)\n\t\t\tgoto out_socks;\n\t\tnn->lockd_up = 1;\n\t}\n\n\tret = nfs4_state_start_net(net);\n\tif (ret)\n\t\tgoto out_lockd;\n\n\tnn->nfsd_net_up = true;\n\treturn 0;\n\nout_lockd:\n\tif (nn->lockd_up) {\n\t\tlockd_down(net);\n\t\tnn->lockd_up = 0;\n\t}\nout_socks:\n\tnfsd_shutdown_generic();\n\treturn ret;\n}\n\nstatic void nfsd_shutdown_net(struct net *net)\n{\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\n\tnfs4_state_shutdown_net(net);\n\tif (nn->lockd_up) {\n\t\tlockd_down(net);\n\t\tnn->lockd_up = 0;\n\t}\n\tnn->nfsd_net_up = false;\n\tnfsd_shutdown_generic();\n}\n\nstatic int nfsd_inetaddr_event(struct notifier_block *this, unsigned long event,\n\tvoid *ptr)\n{\n\tstruct in_ifaddr *ifa = (struct in_ifaddr *)ptr;\n\tstruct net_device *dev = ifa->ifa_dev->dev;\n\tstruct net *net = dev_net(dev);\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\tstruct sockaddr_in sin;\n\n\tif (event != NETDEV_DOWN)\n\t\tgoto out;\n\n\tif (nn->nfsd_serv) {\n\t\tdprintk(\"nfsd_inetaddr_event: removed %pI4\\n\", &ifa->ifa_local);\n\t\tsin.sin_family = AF_INET;\n\t\tsin.sin_addr.s_addr = ifa->ifa_local;\n\t\tsvc_age_temp_xprts_now(nn->nfsd_serv, (struct sockaddr *)&sin);\n\t}\n\nout:\n\treturn NOTIFY_DONE;\n}\n\nstatic struct notifier_block nfsd_inetaddr_notifier = {\n\t.notifier_call = nfsd_inetaddr_event,\n};\n\n#if IS_ENABLED(CONFIG_IPV6)\nstatic int nfsd_inet6addr_event(struct notifier_block *this,\n\tunsigned long event, void *ptr)\n{\n\tstruct inet6_ifaddr *ifa = (struct inet6_ifaddr *)ptr;\n\tstruct net_device *dev = ifa->idev->dev;\n\tstruct net *net = dev_net(dev);\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\tstruct sockaddr_in6 sin6;\n\n\tif (event != NETDEV_DOWN)\n\t\tgoto out;\n\n\tif (nn->nfsd_serv) {\n\t\tdprintk(\"nfsd_inet6addr_event: removed %pI6\\n\", &ifa->addr);\n\t\tsin6.sin6_family = AF_INET6;\n\t\tsin6.sin6_addr = ifa->addr;\n\t\tif (ipv6_addr_type(&sin6.sin6_addr) & IPV6_ADDR_LINKLOCAL)\n\t\t\tsin6.sin6_scope_id = ifa->idev->dev->ifindex;\n\t\tsvc_age_temp_xprts_now(nn->nfsd_serv, (struct sockaddr *)&sin6);\n\t}\n\nout:\n\treturn NOTIFY_DONE;\n}\n\nstatic struct notifier_block nfsd_inet6addr_notifier = {\n\t.notifier_call = nfsd_inet6addr_event,\n};\n#endif\n\n/* Only used under nfsd_mutex, so this atomic may be overkill: */\nstatic atomic_t nfsd_notifier_refcount = ATOMIC_INIT(0);\n\nstatic void nfsd_last_thread(struct svc_serv *serv, struct net *net)\n{\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\n\t/* check if the notifier still has clients */\n\tif (atomic_dec_return(&nfsd_notifier_refcount) == 0) {\n\t\tunregister_inetaddr_notifier(&nfsd_inetaddr_notifier);\n#if IS_ENABLED(CONFIG_IPV6)\n\t\tunregister_inet6addr_notifier(&nfsd_inet6addr_notifier);\n#endif\n\t}\n\n\t/*\n\t * write_ports can create the server without actually starting\n\t * any threads--if we get shut down before any threads are\n\t * started, then nfsd_last_thread will be run before any of this\n\t * other initialization has been done except the rpcb information.\n\t */\n\tsvc_rpcb_cleanup(serv, net);\n\tif (!nn->nfsd_net_up)\n\t\treturn;\n\n\tnfsd_shutdown_net(net);\n\tprintk(KERN_WARNING \"nfsd: last server has exited, flushing export \"\n\t\t\t    \"cache\\n\");\n\tnfsd_export_flush(net);\n}\n\nvoid nfsd_reset_versions(void)\n{\n\tint i;\n\n\tfor (i = 0; i < NFSD_NRVERS; i++)\n\t\tif (nfsd_vers(i, NFSD_TEST))\n\t\t\treturn;\n\n\tfor (i = 0; i < NFSD_NRVERS; i++)\n\t\tif (i != 4)\n\t\t\tnfsd_vers(i, NFSD_SET);\n\t\telse {\n\t\t\tint minor = 0;\n\t\t\twhile (nfsd_minorversion(minor, NFSD_SET) >= 0)\n\t\t\t\tminor++;\n\t\t}\n}\n\n/*\n * Each session guarantees a negotiated per slot memory cache for replies\n * which in turn consumes memory beyond the v2/v3/v4.0 server. A dedicated\n * NFSv4.1 server might want to use more memory for a DRC than a machine\n * with mutiple services.\n *\n * Impose a hard limit on the number of pages for the DRC which varies\n * according to the machines free pages. This is of course only a default.\n *\n * For now this is a #defined shift which could be under admin control\n * in the future.\n */\nstatic void set_max_drc(void)\n{\n\t#define NFSD_DRC_SIZE_SHIFT\t10\n\tnfsd_drc_max_mem = (nr_free_buffer_pages()\n\t\t\t\t\t>> NFSD_DRC_SIZE_SHIFT) * PAGE_SIZE;\n\tnfsd_drc_mem_used = 0;\n\tspin_lock_init(&nfsd_drc_lock);\n\tdprintk(\"%s nfsd_drc_max_mem %lu \\n\", __func__, nfsd_drc_max_mem);\n}\n\nstatic int nfsd_get_default_max_blksize(void)\n{\n\tstruct sysinfo i;\n\tunsigned long long target;\n\tunsigned long ret;\n\n\tsi_meminfo(&i);\n\ttarget = (i.totalram - i.totalhigh) << PAGE_SHIFT;\n\t/*\n\t * Aim for 1/4096 of memory per thread This gives 1MB on 4Gig\n\t * machines, but only uses 32K on 128M machines.  Bottom out at\n\t * 8K on 32M and smaller.  Of course, this is only a default.\n\t */\n\ttarget >>= 12;\n\n\tret = NFSSVC_MAXBLKSIZE;\n\twhile (ret > target && ret >= 8*1024*2)\n\t\tret /= 2;\n\treturn ret;\n}\n\nstatic struct svc_serv_ops nfsd_thread_sv_ops = {\n\t.svo_shutdown\t\t= nfsd_last_thread,\n\t.svo_function\t\t= nfsd,\n\t.svo_enqueue_xprt\t= svc_xprt_do_enqueue,\n\t.svo_setup\t\t= svc_set_num_threads,\n\t.svo_module\t\t= THIS_MODULE,\n};\n\nint nfsd_create_serv(struct net *net)\n{\n\tint error;\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\n\tWARN_ON(!mutex_is_locked(&nfsd_mutex));\n\tif (nn->nfsd_serv) {\n\t\tsvc_get(nn->nfsd_serv);\n\t\treturn 0;\n\t}\n\tif (nfsd_max_blksize == 0)\n\t\tnfsd_max_blksize = nfsd_get_default_max_blksize();\n\tnfsd_reset_versions();\n\tnn->nfsd_serv = svc_create_pooled(&nfsd_program, nfsd_max_blksize,\n\t\t\t\t\t\t&nfsd_thread_sv_ops);\n\tif (nn->nfsd_serv == NULL)\n\t\treturn -ENOMEM;\n\n\tnn->nfsd_serv->sv_maxconn = nn->max_connections;\n\terror = svc_bind(nn->nfsd_serv, net);\n\tif (error < 0) {\n\t\tsvc_destroy(nn->nfsd_serv);\n\t\treturn error;\n\t}\n\n\tset_max_drc();\n\t/* check if the notifier is already set */\n\tif (atomic_inc_return(&nfsd_notifier_refcount) == 1) {\n\t\tregister_inetaddr_notifier(&nfsd_inetaddr_notifier);\n#if IS_ENABLED(CONFIG_IPV6)\n\t\tregister_inet6addr_notifier(&nfsd_inet6addr_notifier);\n#endif\n\t}\n\tdo_gettimeofday(&nn->nfssvc_boot);\t\t/* record boot time */\n\treturn 0;\n}\n\nint nfsd_nrpools(struct net *net)\n{\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\n\tif (nn->nfsd_serv == NULL)\n\t\treturn 0;\n\telse\n\t\treturn nn->nfsd_serv->sv_nrpools;\n}\n\nint nfsd_get_nrthreads(int n, int *nthreads, struct net *net)\n{\n\tint i = 0;\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\n\tif (nn->nfsd_serv != NULL) {\n\t\tfor (i = 0; i < nn->nfsd_serv->sv_nrpools && i < n; i++)\n\t\t\tnthreads[i] = nn->nfsd_serv->sv_pools[i].sp_nrthreads;\n\t}\n\n\treturn 0;\n}\n\nvoid nfsd_destroy(struct net *net)\n{\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\tint destroy = (nn->nfsd_serv->sv_nrthreads == 1);\n\n\tif (destroy)\n\t\tsvc_shutdown_net(nn->nfsd_serv, net);\n\tsvc_destroy(nn->nfsd_serv);\n\tif (destroy)\n\t\tnn->nfsd_serv = NULL;\n}\n\nint nfsd_set_nrthreads(int n, int *nthreads, struct net *net)\n{\n\tint i = 0;\n\tint tot = 0;\n\tint err = 0;\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\n\tWARN_ON(!mutex_is_locked(&nfsd_mutex));\n\n\tif (nn->nfsd_serv == NULL || n <= 0)\n\t\treturn 0;\n\n\tif (n > nn->nfsd_serv->sv_nrpools)\n\t\tn = nn->nfsd_serv->sv_nrpools;\n\n\t/* enforce a global maximum number of threads */\n\ttot = 0;\n\tfor (i = 0; i < n; i++) {\n\t\tnthreads[i] = min(nthreads[i], NFSD_MAXSERVS);\n\t\ttot += nthreads[i];\n\t}\n\tif (tot > NFSD_MAXSERVS) {\n\t\t/* total too large: scale down requested numbers */\n\t\tfor (i = 0; i < n && tot > 0; i++) {\n\t\t    \tint new = nthreads[i] * NFSD_MAXSERVS / tot;\n\t\t\ttot -= (nthreads[i] - new);\n\t\t\tnthreads[i] = new;\n\t\t}\n\t\tfor (i = 0; i < n && tot > 0; i++) {\n\t\t\tnthreads[i]--;\n\t\t\ttot--;\n\t\t}\n\t}\n\n\t/*\n\t * There must always be a thread in pool 0; the admin\n\t * can't shut down NFS completely using pool_threads.\n\t */\n\tif (nthreads[0] == 0)\n\t\tnthreads[0] = 1;\n\n\t/* apply the new numbers */\n\tsvc_get(nn->nfsd_serv);\n\tfor (i = 0; i < n; i++) {\n\t\terr = nn->nfsd_serv->sv_ops->svo_setup(nn->nfsd_serv,\n\t\t\t\t&nn->nfsd_serv->sv_pools[i], nthreads[i]);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\tnfsd_destroy(net);\n\treturn err;\n}\n\n/*\n * Adjust the number of threads and return the new number of threads.\n * This is also the function that starts the server if necessary, if\n * this is the first time nrservs is nonzero.\n */\nint\nnfsd_svc(int nrservs, struct net *net)\n{\n\tint\terror;\n\tbool\tnfsd_up_before;\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\n\tmutex_lock(&nfsd_mutex);\n\tdprintk(\"nfsd: creating service\\n\");\n\n\tnrservs = max(nrservs, 0);\n\tnrservs = min(nrservs, NFSD_MAXSERVS);\n\terror = 0;\n\n\tif (nrservs == 0 && nn->nfsd_serv == NULL)\n\t\tgoto out;\n\n\terror = nfsd_create_serv(net);\n\tif (error)\n\t\tgoto out;\n\n\tnfsd_up_before = nn->nfsd_net_up;\n\n\terror = nfsd_startup_net(nrservs, net);\n\tif (error)\n\t\tgoto out_destroy;\n\terror = nn->nfsd_serv->sv_ops->svo_setup(nn->nfsd_serv,\n\t\t\tNULL, nrservs);\n\tif (error)\n\t\tgoto out_shutdown;\n\t/* We are holding a reference to nn->nfsd_serv which\n\t * we don't want to count in the return value,\n\t * so subtract 1\n\t */\n\terror = nn->nfsd_serv->sv_nrthreads - 1;\nout_shutdown:\n\tif (error < 0 && !nfsd_up_before)\n\t\tnfsd_shutdown_net(net);\nout_destroy:\n\tnfsd_destroy(net);\t\t/* Release server */\nout:\n\tmutex_unlock(&nfsd_mutex);\n\treturn error;\n}\n\n\n/*\n * This is the NFS server kernel thread\n */\nstatic int\nnfsd(void *vrqstp)\n{\n\tstruct svc_rqst *rqstp = (struct svc_rqst *) vrqstp;\n\tstruct svc_xprt *perm_sock = list_entry(rqstp->rq_server->sv_permsocks.next, typeof(struct svc_xprt), xpt_list);\n\tstruct net *net = perm_sock->xpt_net;\n\tstruct nfsd_net *nn = net_generic(net, nfsd_net_id);\n\tint err;\n\n\t/* Lock module and set up kernel thread */\n\tmutex_lock(&nfsd_mutex);\n\n\t/* At this point, the thread shares current->fs\n\t * with the init process. We need to create files with the\n\t * umask as defined by the client instead of init's umask. */\n\tif (unshare_fs_struct() < 0) {\n\t\tprintk(\"Unable to start nfsd thread: out of memory\\n\");\n\t\tgoto out;\n\t}\n\n\tcurrent->fs->umask = 0;\n\n\t/*\n\t * thread is spawned with all signals set to SIG_IGN, re-enable\n\t * the ones that will bring down the thread\n\t */\n\tallow_signal(SIGKILL);\n\tallow_signal(SIGHUP);\n\tallow_signal(SIGINT);\n\tallow_signal(SIGQUIT);\n\n\tnfsdstats.th_cnt++;\n\tmutex_unlock(&nfsd_mutex);\n\n\tset_freezable();\n\n\t/*\n\t * The main request loop\n\t */\n\tfor (;;) {\n\t\t/* Update sv_maxconn if it has changed */\n\t\trqstp->rq_server->sv_maxconn = nn->max_connections;\n\n\t\t/*\n\t\t * Find a socket with data available and call its\n\t\t * recvfrom routine.\n\t\t */\n\t\twhile ((err = svc_recv(rqstp, 60*60*HZ)) == -EAGAIN)\n\t\t\t;\n\t\tif (err == -EINTR)\n\t\t\tbreak;\n\t\tvalidate_process_creds();\n\t\tsvc_process(rqstp);\n\t\tvalidate_process_creds();\n\t}\n\n\t/* Clear signals before calling svc_exit_thread() */\n\tflush_signals(current);\n\n\tmutex_lock(&nfsd_mutex);\n\tnfsdstats.th_cnt --;\n\nout:\n\trqstp->rq_server = NULL;\n\n\t/* Release the thread */\n\tsvc_exit_thread(rqstp);\n\n\tnfsd_destroy(net);\n\n\t/* Release module */\n\tmutex_unlock(&nfsd_mutex);\n\tmodule_put_and_exit(0);\n\treturn 0;\n}\n\nstatic __be32 map_new_errors(u32 vers, __be32 nfserr)\n{\n\tif (nfserr == nfserr_jukebox && vers == 2)\n\t\treturn nfserr_dropit;\n\tif (nfserr == nfserr_wrongsec && vers < 4)\n\t\treturn nfserr_acces;\n\treturn nfserr;\n}\n\n/*\n * A write procedure can have a large argument, and a read procedure can\n * have a large reply, but no NFSv2 or NFSv3 procedure has argument and\n * reply that can both be larger than a page.  The xdr code has taken\n * advantage of this assumption to be a sloppy about bounds checking in\n * some cases.  Pending a rewrite of the NFSv2/v3 xdr code to fix that\n * problem, we enforce these assumptions here:\n */\nstatic bool nfs_request_too_big(struct svc_rqst *rqstp,\n\t\t\t\tstruct svc_procedure *proc)\n{\n\t/*\n\t * The ACL code has more careful bounds-checking and is not\n\t * susceptible to this problem:\n\t */\n\tif (rqstp->rq_prog != NFS_PROGRAM)\n\t\treturn false;\n\t/*\n\t * Ditto NFSv4 (which can in theory have argument and reply both\n\t * more than a page):\n\t */\n\tif (rqstp->rq_vers >= 4)\n\t\treturn false;\n\t/* The reply will be small, we're OK: */\n\tif (proc->pc_xdrressize > 0 &&\n\t    proc->pc_xdrressize < XDR_QUADLEN(PAGE_SIZE))\n\t\treturn false;\n\n\treturn rqstp->rq_arg.len > PAGE_SIZE;\n}\n\nint\nnfsd_dispatch(struct svc_rqst *rqstp, __be32 *statp)\n{\n\tstruct svc_procedure\t*proc;\n\tkxdrproc_t\t\txdr;\n\t__be32\t\t\tnfserr;\n\t__be32\t\t\t*nfserrp;\n\n\tdprintk(\"nfsd_dispatch: vers %d proc %d\\n\",\n\t\t\t\trqstp->rq_vers, rqstp->rq_proc);\n\tproc = rqstp->rq_procinfo;\n\n\tif (nfs_request_too_big(rqstp, proc)) {\n\t\tdprintk(\"nfsd: NFSv%d argument too large\\n\", rqstp->rq_vers);\n\t\t*statp = rpc_garbage_args;\n\t\treturn 1;\n\t}\n\t/*\n\t * Give the xdr decoder a chance to change this if it wants\n\t * (necessary in the NFSv4.0 compound case)\n\t */\n\trqstp->rq_cachetype = proc->pc_cachetype;\n\t/* Decode arguments */\n\txdr = proc->pc_decode;\n\tif (xdr && !xdr(rqstp, (__be32*)rqstp->rq_arg.head[0].iov_base,\n\t\t\trqstp->rq_argp)) {\n\t\tdprintk(\"nfsd: failed to decode arguments!\\n\");\n\t\t*statp = rpc_garbage_args;\n\t\treturn 1;\n\t}\n\n\t/* Check whether we have this call in the cache. */\n\tswitch (nfsd_cache_lookup(rqstp)) {\n\tcase RC_DROPIT:\n\t\treturn 0;\n\tcase RC_REPLY:\n\t\treturn 1;\n\tcase RC_DOIT:;\n\t\t/* do it */\n\t}\n\n\t/* need to grab the location to store the status, as\n\t * nfsv4 does some encoding while processing \n\t */\n\tnfserrp = rqstp->rq_res.head[0].iov_base\n\t\t+ rqstp->rq_res.head[0].iov_len;\n\trqstp->rq_res.head[0].iov_len += sizeof(__be32);\n\n\t/* Now call the procedure handler, and encode NFS status. */\n\tnfserr = proc->pc_func(rqstp, rqstp->rq_argp, rqstp->rq_resp);\n\tnfserr = map_new_errors(rqstp->rq_vers, nfserr);\n\tif (nfserr == nfserr_dropit || test_bit(RQ_DROPME, &rqstp->rq_flags)) {\n\t\tdprintk(\"nfsd: Dropping request; may be revisited later\\n\");\n\t\tnfsd_cache_update(rqstp, RC_NOCACHE, NULL);\n\t\treturn 0;\n\t}\n\n\tif (rqstp->rq_proc != 0)\n\t\t*nfserrp++ = nfserr;\n\n\t/* Encode result.\n\t * For NFSv2, additional info is never returned in case of an error.\n\t */\n\tif (!(nfserr && rqstp->rq_vers == 2)) {\n\t\txdr = proc->pc_encode;\n\t\tif (xdr && !xdr(rqstp, nfserrp,\n\t\t\t\trqstp->rq_resp)) {\n\t\t\t/* Failed to encode result. Release cache entry */\n\t\t\tdprintk(\"nfsd: failed to encode result!\\n\");\n\t\t\tnfsd_cache_update(rqstp, RC_NOCACHE, NULL);\n\t\t\t*statp = rpc_system_err;\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* Store reply in cache. */\n\tnfsd_cache_update(rqstp, rqstp->rq_cachetype, statp + 1);\n\treturn 1;\n}\n\nint nfsd_pool_stats_open(struct inode *inode, struct file *file)\n{\n\tint ret;\n\tstruct nfsd_net *nn = net_generic(inode->i_sb->s_fs_info, nfsd_net_id);\n\n\tmutex_lock(&nfsd_mutex);\n\tif (nn->nfsd_serv == NULL) {\n\t\tmutex_unlock(&nfsd_mutex);\n\t\treturn -ENODEV;\n\t}\n\t/* bump up the psudo refcount while traversing */\n\tsvc_get(nn->nfsd_serv);\n\tret = svc_pool_stats_open(nn->nfsd_serv, file);\n\tmutex_unlock(&nfsd_mutex);\n\treturn ret;\n}\n\nint nfsd_pool_stats_release(struct inode *inode, struct file *file)\n{\n\tint ret = seq_release(inode, file);\n\tstruct net *net = inode->i_sb->s_fs_info;\n\n\tmutex_lock(&nfsd_mutex);\n\t/* this function really, really should have been called svc_put() */\n\tnfsd_destroy(net);\n\tmutex_unlock(&nfsd_mutex);\n\treturn ret;\n}\n"], "filenames": ["fs/nfsd/nfssvc.c"], "buggy_code_start_loc": [749], "buggy_code_end_loc": [761], "fixing_code_start_loc": [750], "fixing_code_end_loc": [798], "type": "CWE-20", "message": "The NFSv2/NFSv3 server in the nfsd subsystem in the Linux kernel through 4.10.11 allows remote attackers to cause a denial of service (system crash) via a long RPC reply, related to net/sunrpc/svc.c, fs/nfsd/nfs3xdr.c, and fs/nfsd/nfsxdr.c.", "other": {"cve": {"id": "CVE-2017-7645", "sourceIdentifier": "cve@mitre.org", "published": "2017-04-18T14:59:00.213", "lastModified": "2023-01-17T21:34:43.127", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "The NFSv2/NFSv3 server in the nfsd subsystem in the Linux kernel through 4.10.11 allows remote attackers to cause a denial of service (system crash) via a long RPC reply, related to net/sunrpc/svc.c, fs/nfsd/nfs3xdr.c, and fs/nfsd/nfsxdr.c."}, {"lang": "es", "value": "El servidor NFSv2/NFSv3 en el subsistema nfsd en el Kernel de Linux hasta la versi\u00f3n 4.10.11 permite a atacantes remotos provocar una denegaci\u00f3n de servicio (ca\u00edda de sistema) a trav\u00e9s de una respuesta RPC larga, relacionada con net/sunrpc/svc.c, fs/nfsd/nfs3xdr.c y fs/nfsd/nfsxdr.c."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:N/A:C", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "COMPLETE", "baseScore": 7.8}, "baseSeverity": "HIGH", "exploitabilityScore": 10.0, "impactScore": 6.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-20"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndExcluding": "3.2.89", "matchCriteriaId": "9A5C1F01-214B-4477-A3A1-F6DF10181D3C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.3", "versionEndExcluding": "3.10.107", "matchCriteriaId": "314F9C88-C8E1-46EF-8119-538C824ED137"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.11", "versionEndExcluding": "3.12.74", "matchCriteriaId": "75647580-464B-4AEF-8DE2-F17D1748F182"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.13", "versionEndExcluding": "3.16.44", "matchCriteriaId": "50A4478F-EC43-46DF-AE23-9298AE3F8892"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.17", "versionEndExcluding": "3.18.52", "matchCriteriaId": "8104AAC1-9700-4372-8E11-37B09309A76F"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.19", "versionEndExcluding": "4.1.40", "matchCriteriaId": "70E79011-B658-40F2-B406-D3619DEBFACD"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.2", "versionEndExcluding": "4.4.66", "matchCriteriaId": "BF5669AA-0250-493C-9D38-F0B563103943"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.5", "versionEndExcluding": "4.9.26", "matchCriteriaId": "92A58CFB-13B7-4E99-8A14-A0308E4F126A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.10", "versionEndExcluding": "4.10.14", "matchCriteriaId": "90895EF1-9DC7-4E47-A937-405661F7A44B"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "C11E6FB0-C8C0-4527-9AA0-CB9B316F8F43"}, {"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:9.0:*:*:*:*:*:*:*", "matchCriteriaId": "DEECE5FC-CACF-4496-A3E7-164736409252"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:14.04:*:*:*:esm:*:*:*", "matchCriteriaId": "815D70A8-47D3-459C-A32C-9FEACA0659D1"}]}]}], "references": [{"url": "http://www.debian.org/security/2017/dsa-3886", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "http://www.securityfocus.com/bid/97950", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://access.redhat.com/errata/RHSA-2017:1615", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://access.redhat.com/errata/RHSA-2017:1616", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://access.redhat.com/errata/RHSA-2017:1647", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://access.redhat.com/errata/RHSA-2018:1319", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=e6838a29ecb484c97e4efef9429643b9851fba6e", "source": "cve@mitre.org", "tags": ["Vendor Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/e6838a29ecb484c97e4efef9429643b9851fba6e", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://help.ecostruxureit.com/display/public/UADCE725/Security+fixes+in+StruxureWare+Data+Center+Expert+v7.6.0", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://marc.info/?l=linux-nfs&m=149218228327497&w=2", "source": "cve@mitre.org", "tags": ["Mailing List", "Patch", "Third Party Advisory"]}, {"url": "https://marc.info/?l=linux-nfs&m=149247516212924&w=2", "source": "cve@mitre.org", "tags": ["Mailing List", "Patch", "Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/3754-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/e6838a29ecb484c97e4efef9429643b9851fba6e"}}
{"buggy_code": ["############################\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\nimport logging\n\nfrom ansible_runner.config._base import BaseConfig, BaseExecutionMode\nfrom ansible_runner.exceptions import ConfigurationError\nfrom ansible_runner.utils import get_executable_path\n\nlogger = logging.getLogger('ansible-runner')\n\n\nclass DocConfig(BaseConfig):\n    \"\"\"\n    A ``Runner`` configuration object that's meant to encapsulate the configuration used by the\n    :py:mod:`ansible_runner.runner.DocConfig` object to launch and manage the invocation of\n    command execution.\n\n    Typically this object is initialized for you when using the standard ``get_plugin_docs`` or ``get_plugin_list`` interfaces\n    in :py:mod:`ansible_runner.interface` but can be used to construct the ``DocConfig`` configuration to be invoked elsewhere.\n    It can also be overridden to provide different functionality to the DocConfig object.\n\n    :Example:\n\n    >>> dc = DocConfig(...)\n    >>> r = Runner(config=dc)\n    >>> r.run()\n\n    \"\"\"\n\n    def __init__(self, runner_mode=None, **kwargs):\n        # runner params\n        self.runner_mode = runner_mode if runner_mode else 'subprocess'\n        if self.runner_mode not in ['pexpect', 'subprocess']:\n            raise ConfigurationError(\"Invalid runner mode {0}, valid value is either 'pexpect' or 'subprocess'\".format(self.runner_mode))\n\n        if kwargs.get(\"process_isolation\"):\n            self._ansible_doc_exec_path = \"ansible-doc\"\n        else:\n            self._ansible_doc_exec_path = get_executable_path(\"ansible-doc\")\n\n        self.execution_mode = BaseExecutionMode.ANSIBLE_COMMANDS\n        super(DocConfig, self).__init__(**kwargs)\n\n    _supported_response_formats = ('json', 'human')\n\n    def prepare_plugin_docs_command(self, plugin_names, plugin_type=None, response_format=None,\n                                    snippet=False, playbook_dir=None, module_path=None):\n\n        if response_format and response_format not in DocConfig._supported_response_formats:\n            raise ConfigurationError(\"Invalid response_format {0}, valid value is one of either {1}\".format(response_format,\n                                                                                                            \", \".join(DocConfig._supported_response_formats)))\n\n        if not isinstance(plugin_names, list):\n            raise ConfigurationError(\"plugin_names should be of type list, instead received {0} of type {1}\".format(plugin_names, type(plugin_names)))\n\n        self._prepare_env(runner_mode=self.runner_mode)\n        self.cmdline_args = []\n\n        if response_format == 'json':\n            self.cmdline_args.append('-j')\n\n        if snippet:\n            self.cmdline_args.append('-s')\n\n        if plugin_type:\n            self.cmdline_args.extend(['-t', plugin_type])\n\n        if playbook_dir:\n            self.cmdline_args.extend(['--playbook-dir', playbook_dir])\n\n        if module_path:\n            self.cmdline_args.extend(['-M', module_path])\n\n        self.cmdline_args.append(\" \".join(plugin_names))\n\n        self.command = [self._ansible_doc_exec_path] + self.cmdline_args\n        self._handle_command_wrap(self.execution_mode, self.cmdline_args)\n\n    def prepare_plugin_list_command(self, list_files=None, response_format=None, plugin_type=None,\n                                    playbook_dir=None, module_path=None):\n\n        if response_format and response_format not in DocConfig._supported_response_formats:\n            raise ConfigurationError(\"Invalid response_format {0}, valid value is one of either {1}\".format(response_format,\n                                                                                                            \", \".join(DocConfig._supported_response_formats)))\n\n        self._prepare_env(runner_mode=self.runner_mode)\n        self.cmdline_args = []\n\n        if list_files:\n            self.cmdline_args.append('-F')\n        else:\n            self.cmdline_args.append('-l')\n\n        if response_format == 'json':\n            self.cmdline_args.append('-j')\n\n        if plugin_type:\n            self.cmdline_args.extend(['-t', plugin_type])\n\n        if playbook_dir:\n            self.cmdline_args.extend(['--playbook-dir', playbook_dir])\n\n        if module_path:\n            self.cmdline_args.extend(['-M', module_path])\n\n        self.command = [self._ansible_doc_exec_path] + self.cmdline_args\n        self._handle_command_wrap(self.execution_mode, self.cmdline_args)\n", "import os\nimport stat\nimport time\nimport json\nimport errno\nimport signal\nfrom subprocess import Popen, PIPE, CalledProcessError, TimeoutExpired, run as run_subprocess\nimport shutil\nimport codecs\nimport collections\nimport datetime\nimport logging\n\nimport six\nimport pexpect\n\nimport ansible_runner.plugins\n\nfrom .utils import OutputEventFilter, cleanup_artifact_dir, ensure_str, collect_new_events\nfrom .exceptions import CallbackError, AnsibleRunnerException\nfrom ansible_runner.output import debug\n\nlogger = logging.getLogger('ansible-runner')\n\n\nclass Runner(object):\n\n    def __init__(self, config, cancel_callback=None, remove_partials=True, event_handler=None,\n                 artifacts_handler=None, finished_callback=None, status_handler=None):\n        self.config = config\n        self.cancel_callback = cancel_callback\n        self.event_handler = event_handler\n        self.artifacts_handler = artifacts_handler\n        self.finished_callback = finished_callback\n        self.status_handler = status_handler\n        self.canceled = False\n        self.timed_out = False\n        self.errored = False\n        self.status = \"unstarted\"\n        self.rc = None\n        self.remove_partials = remove_partials\n\n        # default runner mode to pexpect\n        self.runner_mode = self.config.runner_mode if hasattr(self.config, 'runner_mode') else 'pexpect'\n\n        self.resource_profiling = self.config.resource_profiling if hasattr(self.config, 'resource_profiling') else False\n        self.directory_isolation_path = self.config.directory_isolation_path if hasattr(self.config, 'directory_isolation_path') else None\n        self.directory_isolation_cleanup = self.config.directory_isolation_cleanup if hasattr(self.config, 'directory_isolation_cleanup') else None\n        self.process_isolation = self.config.process_isolation if hasattr(self.config, 'process_isolation') else None\n        self.process_isolation_path_actual = self.config.process_isolation_path_actual if hasattr(self.config, 'process_isolation_path_actual') else None\n\n    def event_callback(self, event_data):\n        '''\n        Invoked for every Ansible event to collect stdout with the event data and store it for\n        later use\n        '''\n        self.last_stdout_update = time.time()\n        if 'uuid' in event_data:\n            filename = '{}-partial.json'.format(event_data['uuid'])\n            partial_filename = os.path.join(self.config.artifact_dir,\n                                            'job_events',\n                                            filename)\n            full_filename = os.path.join(self.config.artifact_dir,\n                                         'job_events',\n                                         '{}-{}.json'.format(event_data['counter'],\n                                                             event_data['uuid']))\n            try:\n                event_data.update(dict(runner_ident=str(self.config.ident)))\n                try:\n                    with codecs.open(partial_filename, 'r', encoding='utf-8') as read_file:\n                        partial_event_data = json.load(read_file)\n                    event_data.update(partial_event_data)\n                    if self.remove_partials:\n                        os.remove(partial_filename)\n                except IOError as e:\n                    msg = \"Failed to open ansible stdout callback plugin partial data\" \\\n                          \" file {} with error {}\".format(partial_filename, str(e))\n                    debug(msg)\n                    if self.config.check_job_event_data:\n                        raise AnsibleRunnerException(msg)\n\n                # prefer 'created' from partial data, but verbose events set time here\n                if 'created' not in event_data:\n                    event_data['created'] = datetime.datetime.utcnow().isoformat()\n\n                if self.event_handler is not None:\n                    should_write = self.event_handler(event_data)\n                else:\n                    should_write = True\n                for plugin in ansible_runner.plugins:\n                    ansible_runner.plugins[plugin].event_handler(self.config, event_data)\n                if should_write:\n                    temporary_filename = full_filename + '.tmp'\n                    with codecs.open(temporary_filename, 'w', encoding='utf-8') as write_file:\n                        os.chmod(temporary_filename, stat.S_IRUSR | stat.S_IWUSR)\n                        json.dump(event_data, write_file)\n                    os.rename(temporary_filename, full_filename)\n            except IOError as e:\n                debug(\"Failed writing event data: {}\".format(e))\n\n    def status_callback(self, status):\n        self.status = status\n        status_data = {'status': status, 'runner_ident': str(self.config.ident)}\n        if status == 'starting':\n            status_data.update({'command': self.config.command, 'env': self.config.env, 'cwd': self.config.cwd})\n        for plugin in ansible_runner.plugins:\n            ansible_runner.plugins[plugin].status_handler(self.config, status_data)\n        if self.status_handler is not None:\n            self.status_handler(status_data, runner_config=self.config)\n\n    def run(self):\n        '''\n        Launch the Ansible task configured in self.config (A RunnerConfig object), returns once the\n        invocation is complete\n        '''\n        password_patterns = []\n        password_values = []\n\n        self.status_callback('starting')\n        stdout_filename = os.path.join(self.config.artifact_dir, 'stdout')\n        command_filename = os.path.join(self.config.artifact_dir, 'command')\n        stderr_filename = os.path.join(self.config.artifact_dir, 'stderr')\n\n        try:\n            os.makedirs(self.config.artifact_dir, mode=0o700)\n        except OSError as exc:\n            if exc.errno == errno.EEXIST and os.path.isdir(self.config.artifact_dir):\n                pass\n            else:\n                raise\n        os.close(os.open(stdout_filename, os.O_CREAT, stat.S_IRUSR | stat.S_IWUSR))\n\n        job_events_path = os.path.join(self.config.artifact_dir, 'job_events')\n        if not os.path.exists(job_events_path):\n            os.mkdir(job_events_path, 0o700)\n\n        command = self.config.command\n        with codecs.open(command_filename, 'w', encoding='utf-8') as f:\n            os.chmod(command_filename, stat.S_IRUSR | stat.S_IWUSR)\n            json.dump(\n                {'command': command,\n                 'cwd': self.config.cwd,\n                 'env': self.config.env}, f, ensure_ascii=False\n            )\n\n        if self.config.ident is not None:\n            cleanup_artifact_dir(os.path.join(self.config.artifact_dir, \"..\"), self.config.rotate_artifacts)\n\n        if hasattr(self.config, 'suppress_ansible_output'):\n            suppress_ansible_output = self.config.suppress_ansible_output\n        else:\n            suppress_ansible_output = False\n\n        stdout_handle = codecs.open(stdout_filename, 'w', encoding='utf-8')\n        stdout_handle = OutputEventFilter(stdout_handle, self.event_callback, suppress_ansible_output, output_json=self.config.json_mode)\n        stderr_handle = codecs.open(stderr_filename, 'w', encoding='utf-8')\n        stderr_handle = OutputEventFilter(stderr_handle, self.event_callback, suppress_ansible_output, output_json=self.config.json_mode)\n\n        if self.runner_mode == 'pexpect' and not isinstance(self.config.expect_passwords, collections.OrderedDict):\n            # We iterate over `expect_passwords.keys()` and\n            # `expect_passwords.values()` separately to map matched inputs to\n            # patterns and choose the proper string to send to the subprocess;\n            # enforce usage of an OrderedDict so that the ordering of elements in\n            # `keys()` matches `values()`.\n            expect_passwords = collections.OrderedDict(self.config.expect_passwords)\n            password_patterns = list(expect_passwords.keys())\n            password_values = list(expect_passwords.values())\n\n        # pexpect needs all env vars to be utf-8 encoded bytes\n        # https://github.com/pexpect/pexpect/issues/512\n\n        # Use a copy so as not to cause problems when serializing the job_env.\n        if self.config.containerized:\n            # We call the actual docker or podman executable right where we are\n            cwd = os.getcwd()\n            # If this is containerized, the shell environment calling podman has little\n            # to do with the actual job environment, but still needs PATH, auth, etc.\n            pexpect_env = os.environ.copy()\n            # But we still rely on env vars to pass secrets\n            pexpect_env.update(self.config.env)\n            # Write the keys to pass into container to expected file in artifacts dir\n            # option expecting should have already been written in ansible_runner.runner_config\n            env_file_host = os.path.join(self.config.artifact_dir, 'env.list')\n            with open(env_file_host, 'w') as f:\n                f.write(\n                    '\\n'.join(\n                        [\"{}={}\".format(key, value) for key, value in self.config.env.items()]\n                    )\n                )\n        else:\n            cwd = self.config.cwd\n            pexpect_env = self.config.env\n        env = {\n            ensure_str(k): ensure_str(v) if k != 'PATH' and isinstance(v, six.text_type) else v\n            for k, v in pexpect_env.items()\n        }\n\n        # Prepare to collect performance data\n        if self.resource_profiling:\n            cgroup_path = '{0}/{1}'.format(self.config.resource_profiling_base_cgroup, self.config.ident)\n\n            import getpass\n            import grp\n            user = getpass.getuser()\n            group = grp.getgrgid(os.getgid()).gr_name\n\n            cmd = 'cgcreate -a {user}:{group} -t {user}:{group} -g cpuacct,memory,pids:{}'.format(cgroup_path, user=user, group=group)\n            proc = Popen(cmd, stdout=PIPE, stderr=PIPE, shell=True)\n            _, stderr = proc.communicate()\n            if proc.returncode:\n                # Unable to create cgroup\n                logger.error('Unable to create cgroup: {}'.format(stderr))\n                raise RuntimeError('Unable to create cgroup: {}'.format(stderr))\n            else:\n                logger.info(\"Created cgroup '{}'\".format(cgroup_path))\n\n        self.status_callback('running')\n        self.last_stdout_update = time.time()\n\n        # The subprocess runner interface provides stdin/stdout/stderr with streaming capability\n        # to the caller if input_fd/output_fd/error_fd is passed to config class.\n        # Alsp, provides an workaround for known issue in pexpect for long running non-interactive process\n        # https://pexpect.readthedocs.io/en/stable/commonissues.html#truncated-output-just-before-child-exits\n        if self.runner_mode == 'subprocess':\n            if hasattr(self.config, 'input_fd') and self.config.input_fd:\n                input_fd = self.config.input_fd\n            else:\n                input_fd = None\n\n            if hasattr(self.config, 'output_fd') and self.config.output_fd:\n                output_fd = self.config.output_fd\n            else:\n                output_fd = PIPE\n\n            if hasattr(self.config, 'error_fd') and self.config.error_fd:\n                error_fd = self.config.error_fd\n            else:\n                error_fd = PIPE\n\n            subprocess_timeout = self.config.subprocess_timeout if hasattr(self.config, 'subprocess_timeout') else None\n            try:\n                stdout_response = ''\n                stderr_response = ''\n                kwargs = {\n                    'cwd': cwd,\n                    'env': env,\n                    'stdin': input_fd,\n                    'stdout': output_fd,\n                    'stderr': error_fd,\n                    'check': True,\n                    'universal_newlines': True,\n                    'shell': True\n                }\n                if subprocess_timeout is not None:\n                    kwargs.update({'timeout': subprocess_timeout})\n\n                proc_out = run_subprocess(\" \".join(command), **kwargs)\n\n                stdout_response = proc_out.stdout\n                stderr_response = proc_out.stderr\n                self.rc = proc_out.returncode\n            except CalledProcessError as exc:\n                logger.debug(\"{cmd} execution failed, returncode: {rc}, output: {output}, stdout: {stdout}, stderr: {stderr}\".format(\n                    cmd=exc.cmd, rc=exc.returncode, output=exc.output, stdout=exc.stdout, stderr=exc.stderr))\n                self.rc = exc.returncode\n                self.errored = True\n                stdout_response = exc.stdout\n                stderr_response = exc.stderr\n            except TimeoutExpired as exc:\n                logger.debug(\"{cmd} execution timedout, timeout: {timeout}, output: {output}, stdout: {stdout}, stderr: {stderr}\".format(\n                    cmd=exc.cmd, timeout=exc.timeout, output=exc.output, stdout=exc.stdout, stderr=exc.stderr))\n                self.rc = 254\n                stdout_response = exc.stdout\n                stderr_response = exc.stderr\n                self.timed_out = True\n            except Exception as exc:\n                import traceback\n                stderr_response = traceback.format_exc()\n                self.rc = 254\n                self.errored = True\n                logger.debug(\"received execption: {exc}\".format(exc=str(exc)))\n\n            if self.timed_out or self.errored:\n                self.kill_container()\n\n            if stdout_response is not None:\n                if isinstance(stdout_response, bytes):\n                    stdout_response = stdout_response.decode()\n                stdout_handle.write(stdout_response)\n            if stderr_response is not None:\n                if isinstance(stderr_response, bytes):\n                    stderr_response = stderr_response.decode()\n                stderr_handle.write(stderr_response)\n        else:\n            try:\n                child = pexpect.spawn(\n                    command[0],\n                    command[1:],\n                    cwd=cwd,\n                    env=env,\n                    ignore_sighup=True,\n                    encoding='utf-8',\n                    codec_errors='replace',\n                    echo=False,\n                    use_poll=self.config.pexpect_use_poll,\n                )\n                child.logfile_read = stdout_handle\n            except pexpect.exceptions.ExceptionPexpect as e:\n                child = collections.namedtuple(\n                    'MissingProcess', 'exitstatus isalive close'\n                )(\n                    exitstatus=127,\n                    isalive=lambda: False,\n                    close=lambda: None,\n                )\n\n                def _decode(x):\n                    return x.decode('utf-8') if six.PY2 else x\n\n                # create the events directory (the callback plugin won't run, so it\n                # won't get created)\n                events_directory = os.path.join(self.config.artifact_dir, 'job_events')\n                if not os.path.exists(events_directory):\n                    os.mkdir(events_directory, 0o700)\n                stdout_handle.write(_decode(str(e)))\n                stdout_handle.write(_decode('\\n'))\n\n            job_start = time.time()\n            while child.isalive():\n                result_id = child.expect(password_patterns, timeout=self.config.pexpect_timeout, searchwindowsize=100)\n                password = password_values[result_id]\n                if password is not None:\n                    child.sendline(password)\n                    self.last_stdout_update = time.time()\n                if self.cancel_callback:\n                    try:\n                        self.canceled = self.cancel_callback()\n                    except Exception as e:\n                        # TODO: logger.exception('Could not check cancel callback - cancelling immediately')\n                        # if isinstance(extra_update_fields, dict):\n                        #     extra_update_fields['job_explanation'] = \"System error during job execution, check system logs\"\n                        raise CallbackError(\"Exception in Cancel Callback: {}\".format(e))\n                if self.config.job_timeout and not self.canceled and (time.time() - job_start) > self.config.job_timeout:\n                    self.timed_out = True\n                    # if isinstance(extra_update_fields, dict):\n                    #     extra_update_fields['job_explanation'] = \"Job terminated due to timeout\"\n                if self.canceled or self.timed_out or self.errored:\n                    self.kill_container()\n                    Runner.handle_termination(child.pid, is_cancel=self.canceled)\n                if self.config.idle_timeout and (time.time() - self.last_stdout_update) > self.config.idle_timeout:\n                    self.kill_container()\n                    Runner.handle_termination(child.pid, is_cancel=False)\n                    self.timed_out = True\n\n            stdout_handle.flush()\n            stdout_handle.close()\n            child.close()\n            self.rc = child.exitstatus if not (self.timed_out or self.canceled) else 254\n\n        if self.canceled:\n            self.status_callback('canceled')\n        elif self.rc == 0 and not self.timed_out:\n            self.status_callback('successful')\n        elif self.timed_out:\n            self.status_callback('timeout')\n        else:\n            self.status_callback('failed')\n\n        for filename, data in [\n            ('status', self.status),\n            ('rc', self.rc),\n        ]:\n            artifact_path = os.path.join(self.config.artifact_dir, filename)\n            if not os.path.exists(artifact_path):\n                os.close(os.open(artifact_path, os.O_CREAT, stat.S_IRUSR | stat.S_IWUSR))\n            with open(artifact_path, 'w') as f:\n                f.write(str(data))\n        if self.directory_isolation_path and self.directory_isolation_cleanup:\n            shutil.rmtree(self.directory_isolation_path)\n        if self.process_isolation and self.process_isolation_path_actual:\n            def _delete(retries=15):\n                try:\n                    shutil.rmtree(self.process_isolation_path_actual)\n                except OSError as e:\n                    res = False\n                    if e.errno == 16 and retries > 0:\n                        time.sleep(1)\n                        res = _delete(retries=retries - 1)\n                    if not res:\n                        raise\n                return True\n            _delete()\n        if self.resource_profiling:\n            cmd = 'cgdelete -g cpuacct,memory,pids:{}'.format(cgroup_path)\n            proc = Popen(cmd, stdout=PIPE, stderr=PIPE, shell=True)\n            _, stderr = proc.communicate()\n            if proc.returncode:\n                logger.error('Failed to delete cgroup: {}'.format(stderr))\n                raise RuntimeError('Failed to delete cgroup: {}'.format(stderr))\n\n        if self.artifacts_handler is not None:\n            try:\n                self.artifacts_handler(self.config.artifact_dir)\n            except Exception as e:\n                raise CallbackError(\"Exception in Artifact Callback: {}\".format(e))\n\n        if self.finished_callback is not None:\n            try:\n                self.finished_callback(self)\n            except Exception as e:\n                raise CallbackError(\"Exception in Finished Callback: {}\".format(e))\n        return self.status, self.rc\n\n    @property\n    def stdout(self):\n        '''\n        Returns an open file handle to the stdout representing the Ansible run\n        '''\n        stdout_path = os.path.join(self.config.artifact_dir, 'stdout')\n        if not os.path.exists(stdout_path):\n            raise AnsibleRunnerException(\"stdout missing\")\n        return open(os.path.join(self.config.artifact_dir, 'stdout'), 'r')\n\n    @property\n    def stderr(self):\n        '''\n        Returns an open file handle to the stderr representing the Ansible run\n        '''\n        stderr_path = os.path.join(self.config.artifact_dir, 'stderr')\n        if not os.path.exists(stderr_path):\n            raise AnsibleRunnerException(\"stderr missing\")\n        return open(os.path.join(self.config.artifact_dir, 'stderr'), 'r')\n\n    @property\n    def events(self):\n        '''\n        A generator that will return all ansible job events in the order that they were emitted from Ansible\n\n        :Example:\n\n        .. code-block::\n\n            {\n               \"event\": \"runner_on_ok\",\n               \"uuid\": \"00a50d9c-161a-4b74-b978-9f60becaf209\",\n               \"stdout\": \"ok: [localhost] => {\\\\r\\\\n    \\\\\"   msg\\\\\":\\\\\"Test!\\\\\"\\\\r\\\\n}\",\n               \"counter\": 6,\n               \"pid\": 740,\n               \"created\": \"2018-04-05T18:24:36.096725\",\n               \"end_line\": 10,\n               \"start_line\": 7,\n               \"event_data\": {\n                  \"play_pattern\": \"all\",\n                  \"play\": \"all\",\n                  \"task\": \"debug\",\n                  \"task_args\": \"msg=Test!\",\n                  \"remote_addr\": \"localhost\",\n                  \"res\": {\n                     \"msg\": \"Test!\",\n                     \"changed\": false,\n                     \"_ansible_verbose_always\": true,\n                     \"_ansible_no_log\": false\n                  },\n                  \"pid\": 740,\n                  \"play_uuid\": \"0242ac11-0002-443b-cdb1-000000000006\",\n                  \"task_uuid\": \"0242ac11-0002-443b-cdb1-000000000008\",\n                  \"event_loop\": null,\n                  \"playbook_uuid\": \"634edeee-3228-4c17-a1b4-f010fdd42eb2\",\n                  \"playbook\": \"test.yml\",\n                  \"task_action\": \"debug\",\n                  \"host\": \"localhost\",\n                  \"task_path\": \"/tmp/demo/project/test.yml:3\"\n               }\n           }\n        '''\n        # collection of all the events that were yielded\n        old_events = {}\n        event_path = os.path.join(self.config.artifact_dir, 'job_events')\n\n        # Wait for events dir to be created\n        now = datetime.datetime.now()\n        while not os.path.exists(event_path):\n            time.sleep(0.05)\n            wait_time = datetime.datetime.now() - now\n            if wait_time.total_seconds() > 60:\n                raise AnsibleRunnerException(\"events directory is missing: %s\" % event_path)\n\n        while self.status == \"running\":\n            for event, old_evnts in collect_new_events(event_path, old_events):\n                old_events = old_evnts\n                yield event\n\n        # collect new events that were written after the playbook has finished\n        for event, old_evnts in collect_new_events(event_path, old_events):\n            old_events = old_evnts\n            yield event\n\n    @property\n    def stats(self):\n        '''\n        Returns the final high level stats from the Ansible run\n\n        Example:\n            {'dark': {}, 'failures': {}, 'skipped': {}, 'ok': {u'localhost': 2}, 'processed': {u'localhost': 1}}\n        '''\n        last_event = list(filter(lambda x: 'event' in x and x['event'] == 'playbook_on_stats',\n                                 self.events))\n        if not last_event:\n            return None\n        last_event = last_event[0]['event_data']\n        return dict(skipped=last_event.get('skipped', {}),\n                    ok=last_event.get('ok', {}),\n                    dark=last_event.get('dark', {}),\n                    failures=last_event.get('failures', {}),\n                    ignored=last_event.get('ignored', {}),\n                    rescued=last_event.get('rescued', {}),\n                    processed=last_event.get('processed', {}),\n                    changed=last_event.get('changed', {}))\n\n    def host_events(self, host):\n        '''\n        Given a host name, this will return all task events executed on that host\n        '''\n        all_host_events = filter(lambda x: 'event_data' in x and 'host' in x['event_data'] and x['event_data']['host'] == host,\n                                 self.events)\n        return all_host_events\n\n    def kill_container(self):\n        '''\n        Internal method to terminate a container being used for job isolation\n        '''\n        container_name = self.config.container_name\n        if container_name:\n            container_cli = self.config.process_isolation_executable\n            cmd = '{} kill {}'.format(container_cli, container_name)\n            proc = Popen(cmd, stdout=PIPE, stderr=PIPE, shell=True)\n            _, stderr = proc.communicate()\n            if proc.returncode:\n                logger.info('Error from {} kill {} command:\\n{}'.format(container_cli, container_name, stderr))\n            else:\n                logger.info(\"Killed container {}\".format(container_name))\n\n    @classmethod\n    def handle_termination(cls, pid, pidfile=None, is_cancel=True):\n        '''\n        Internal method to terminate a subprocess spawned by `pexpect` representing an invocation of runner.\n\n        :param pid:       the process id of the running the job.\n        :param pidfile:   the daemon's PID file\n        :param is_cancel: flag showing whether this termination is caused by\n                          instance's cancel_flag.\n        '''\n\n        try:\n            pgroup = os.getpgid(pid)\n            os.killpg(pgroup, signal.SIGKILL)\n        except (OSError, ProcessLookupError):\n            pass\n        try:\n            os.remove(pidfile)\n        except (TypeError, OSError):\n            pass\n\n    def get_fact_cache(self, host):\n        '''\n        Get the entire fact cache only if the fact_cache_type is 'jsonfile'\n        '''\n        if self.config.fact_cache_type != 'jsonfile':\n            raise Exception('Unsupported fact cache type.  Only \"jsonfile\" is supported for reading and writing facts from ansible-runner')\n        fact_cache = os.path.join(self.config.fact_cache, host)\n        if os.path.exists(fact_cache):\n            with open(fact_cache) as f:\n                return json.loads(f.read())\n        return {}\n\n    def set_fact_cache(self, host, data):\n        '''\n        Set the entire fact cache data only if the fact_cache_type is 'jsonfile'\n        '''\n        if self.config.fact_cache_type != 'jsonfile':\n            raise Exception('Unsupported fact cache type.  Only \"jsonfile\" is supported for reading and writing facts from ansible-runner')\n        fact_cache = os.path.join(self.config.fact_cache, host)\n        if not os.path.exists(os.path.dirname(fact_cache)):\n            os.makedirs(os.path.dirname(fact_cache), mode=0o700)\n        with open(fact_cache, 'w') as f:\n            return f.write(json.dumps(data))\n", "import os\nimport pytest\n\nfrom ansible_runner import defaults\nfrom ansible_runner.interface import run, run_async, run_command, run_command_async, get_plugin_docs, \\\n    get_plugin_docs_async, get_plugin_list, get_ansible_config, get_inventory\n\n\ndef test_run():\n    r = run(module='debug', host_pattern='localhost')\n    assert r.status == 'successful'\n\n\n@pytest.mark.parametrize(\n    'playbook', (\n        [{'hosts': 'localhost', 'tasks': [{'ping': ''}]}],\n        {'hosts': 'localhost', 'tasks': [{'ping': ''}]},\n    )\n)\ndef test_run_playbook_data(playbook, tmp_path):\n    r = run(private_data_dir=str(tmp_path), playbook=playbook)\n    assert r.status == 'successful'\n\n\ndef test_run_async(tmp_path):\n    thread, r = run_async(private_data_dir=str(tmp_path), module='debug', host_pattern='localhost')\n    thread.join()\n    assert r.status == 'successful'\n\n\ndef get_env_data(res):\n    for event in res.events:\n        found = bool(\n            event['event'] == 'runner_on_ok' and event.get(\n                'event_data', {}\n            ).get('task_action', None) == 'look_at_environment'\n        )\n        if found:\n            return event['event_data']['res']\n    else:\n        print('output:')\n        print(res.stdout.read())\n        raise RuntimeError('Count not find look_at_environment task from playbook')\n\n\ndef test_env_accuracy(request, project_fixtures):\n    printenv_example = project_fixtures / 'printenv'\n    os.environ['SET_BEFORE_TEST'] = 'MADE_UP_VALUE'\n\n    def remove_test_env_var():\n        if 'SET_BEFORE_TEST' in os.environ:\n            del os.environ['SET_BEFORE_TEST']\n\n    request.addfinalizer(remove_test_env_var)\n\n    res = run(\n        private_data_dir=printenv_example,\n        playbook='get_environment.yml',\n        inventory=None,\n        envvars={'FROM_TEST': 'FOOBAR'},\n    )\n    assert res.rc == 0, res.stdout.read()\n\n    actual_env = get_env_data(res)['environment']\n\n    assert actual_env == res.config.env\n\n\n@pytest.mark.test_all_runtimes\ndef test_env_accuracy_inside_container(request, project_fixtures, runtime):\n    printenv_example = project_fixtures / 'printenv'\n    os.environ['SET_BEFORE_TEST'] = 'MADE_UP_VALUE'\n\n    def remove_test_env_var():\n        if 'SET_BEFORE_TEST' in os.environ:\n            del os.environ['SET_BEFORE_TEST']\n\n    request.addfinalizer(remove_test_env_var)\n\n    res = run(\n        private_data_dir=printenv_example,\n        project_dir='/tmp',\n        playbook='get_environment.yml',\n        inventory=None,\n        envvars={'FROM_TEST': 'FOOBAR'},\n        settings={\n            'process_isolation_executable': runtime,\n            'process_isolation': True\n        }\n    )\n    assert res.rc == 0, res.stdout.read()\n\n    env_data = get_env_data(res)\n    actual_env = env_data['environment']\n\n    expected_env = res.config.env.copy()\n\n    # NOTE: the reported environment for containerized jobs will not account for\n    # all environment variables, particularly those set by the entrypoint script\n    for key, value in expected_env.items():\n        assert key in actual_env\n        assert actual_env[key] == value, 'Reported value wrong for {0} env var'.format(key)\n\n    assert env_data['cwd'] == res.config.cwd\n\n\ndef test_multiple_inventories(project_fixtures):\n    private_data_dir = project_fixtures / 'debug'\n\n    res = run(\n        private_data_dir=private_data_dir,\n        playbook='debug.yml',\n    )\n    stdout = res.stdout.read()\n    assert res.rc == 0, stdout\n\n    # providing no inventory should cause <private_data_dir>/inventory\n    # to be used, reading both inventories in the directory\n    assert 'host_1' in stdout\n    assert 'host_2' in stdout\n\n\ndef test_inventory_absolute_path(project_fixtures):\n    private_data_dir = project_fixtures / 'debug'\n\n    res = run(\n        private_data_dir=private_data_dir,\n        playbook='debug.yml',\n        inventory=[\n            str(private_data_dir / 'inventory' / 'inv_1'),\n        ],\n    )\n    stdout = res.stdout.read()\n    assert res.rc == 0, stdout\n\n    # hosts can be down-selected to one inventory out of those available\n    assert 'host_1' in stdout\n    assert 'host_2' not in stdout\n\n\ndef test_run_command(project_fixtures):\n    private_data_dir = project_fixtures / 'debug'\n    inventory = private_data_dir / 'inventory' / 'inv_1'\n    playbook = private_data_dir / 'project' / 'debug.yml'\n    out, err, rc = run_command(\n        private_data_dir=private_data_dir,\n        executable_cmd='ansible-playbook',\n        cmdline_args=[str(playbook), '-i', str(inventory)]\n    )\n    assert \"Hello world!\" in out\n    assert rc == 0\n    assert err == ''\n\n\n@pytest.mark.test_all_runtimes\ndef test_run_ansible_command_within_container(project_fixtures, runtime):\n    private_data_dir = project_fixtures / 'debug'\n    inventory = private_data_dir / 'inventory' / 'inv_1'\n    playbook = private_data_dir / 'project' / 'debug.yml'\n    container_kwargs = {\n        'process_isolation_executable': runtime,\n        'process_isolation': True,\n        'container_image': defaults.default_container_image\n    }\n    out, err, rc = run_command(\n        private_data_dir=private_data_dir,\n        executable_cmd='ansible-playbook',\n        cmdline_args=[str(playbook), '-i', str(inventory)],\n        **container_kwargs\n    )\n    assert \"Hello world!\" in out\n    assert rc == 0\n    assert err == ''\n\n\n@pytest.mark.test_all_runtimes\ndef test_run_script_within_container(project_fixtures, runtime):\n    private_data_dir = project_fixtures / 'debug'\n    script_path = project_fixtures / 'files'\n    container_volume_mounts = [\"{}:{}:Z\".format(script_path, script_path)]\n    container_kwargs = {\n        'process_isolation_executable': runtime,\n        'process_isolation': True,\n        'container_image': defaults.default_container_image,\n        'container_volume_mounts': container_volume_mounts\n    }\n    out, _, rc = run_command(\n        private_data_dir=private_data_dir,\n        executable_cmd='python3',\n        cmdline_args=[str(script_path / 'test_ee.py')],\n        **container_kwargs\n    )\n\n    assert \"os-release\" in out\n    assert rc == 0\n\n\ndef test_run_command_async(project_fixtures):\n    private_data_dir = project_fixtures / 'debug'\n    inventory = private_data_dir / 'inventory' / 'inv_1'\n    playbook = private_data_dir / 'project' / 'debug.yml'\n    thread, r = run_command_async(\n        private_data_dir=private_data_dir,\n        executable_cmd='ansible-playbook',\n        cmdline_args=[str(playbook), '-i', str(inventory)]\n    )\n    thread.join()\n    out = r.stdout.read()\n    assert \"Hello world!\" in out\n    assert r.status == 'successful'\n\n\ndef test_get_plugin_docs():\n    out, _ = get_plugin_docs(\n        plugin_names=['file', 'copy'],\n        plugin_type='module',\n        quiet=True\n    )\n    assert 'copy' in out\n    assert 'file' in out\n\n\ndef test_get_plugin_docs_async():\n    thread, r = get_plugin_docs_async(\n        plugin_names=['file', 'copy'],\n        plugin_type='module',\n        quiet=True\n    )\n    thread.join()\n    out = r.stdout.read()\n    assert 'copy' in out\n    assert 'file' in out\n    assert r.status == 'successful'\n\n\n@pytest.mark.test_all_runtimes\ndef test_get_plugin_docs_within_container(runtime):\n    container_kwargs = {\n        'process_isolation_executable': runtime,\n        'process_isolation': True,\n        'container_image': defaults.default_container_image\n    }\n    out, _ = get_plugin_docs(\n        plugin_names=['file', 'copy'],\n        plugin_type='module',\n        quiet=True,\n        **container_kwargs\n    )\n    assert 'copy' in out\n    assert 'file' in out\n\n\ndef test_get_plugin_docs_list():\n    out, _ = get_plugin_list(\n        list_files=True,\n        quiet=True\n    )\n    assert 'copy' in out\n    assert 'file' in out\n\n\n@pytest.mark.test_all_runtimes\ndef test_get_plugin_docs_list_within_container(runtime):\n    container_kwargs = {\n        'process_isolation_executable': runtime,\n        'process_isolation': True,\n        'container_image': defaults.default_container_image\n    }\n    out, _ = get_plugin_list(\n        list_files=True,\n        quiet=True,\n        **container_kwargs\n    )\n    assert 'copy' in out\n    assert 'file' in out\n\n\ndef test_ansible_config():\n    out, _ = get_ansible_config(\n        action='list',\n        quiet=True\n    )\n    assert 'DEFAULT_VERBOSITY' in out\n\n\ndef test_get_inventory(project_fixtures):\n    private_data_dir = project_fixtures / 'debug'\n    inventory1 = private_data_dir / 'inventory' / 'inv_1'\n    inventory2 = private_data_dir / 'inventory' / 'inv_2'\n\n    out, _ = get_inventory(\n        action='list',\n        inventories=[str(inventory1), str(inventory2)],\n        response_format='json',\n        quiet=True\n    )\n    assert 'host_1' in out['ungrouped']['hosts']\n    assert 'host_2' in out['ungrouped']['hosts']\n\n\n@pytest.mark.test_all_runtimes\ndef test_get_inventory_within_container(project_fixtures, runtime):\n    container_kwargs = {\n        'process_isolation_executable': runtime,\n        'process_isolation': True,\n        'container_image': defaults.default_container_image\n    }\n    private_data_dir = project_fixtures / 'debug'\n    inventory1 = private_data_dir / 'inventory' / 'inv_1'\n    inventory2 = private_data_dir / 'inventory' / 'inv_2'\n\n    out, _ = get_inventory(\n        action='list',\n        inventories=[str(inventory1), str(inventory2)],\n        response_format='json',\n        quiet=True,\n        **container_kwargs\n    )\n    assert 'host_1' in out['ungrouped']['hosts']\n    assert 'host_2' in out['ungrouped']['hosts']\n", "# -*- coding: utf-8 -*-\n\nimport os\nimport pytest\n\nfrom ansible_runner.config.doc import DocConfig\nfrom ansible_runner.config._base import BaseExecutionMode\nfrom ansible_runner.exceptions import ConfigurationError\nfrom ansible_runner.utils import get_executable_path\n\n\ndef test_ansible_doc_defaults(tmp_path, patch_private_data_dir):\n    rc = DocConfig()\n\n    # Check that the private data dir is placed in our default location with our default prefix\n    # and has some extra uniqueness on the end.\n    base_private_data_dir = tmp_path.joinpath('.ansible-runner-').as_posix()\n    assert rc.private_data_dir.startswith(base_private_data_dir)\n    assert len(rc.private_data_dir) > len(base_private_data_dir)\n\n    assert rc.execution_mode == BaseExecutionMode.ANSIBLE_COMMANDS\n    assert rc.runner_mode == 'subprocess'\n\n\ndef test_invalid_runner_mode_value():\n    with pytest.raises(ConfigurationError) as exc:\n        DocConfig(runner_mode='test')\n\n    assert \"Invalid runner mode\" in exc.value.args[0]\n\n\ndef test_invalid_response_format_value():\n    with pytest.raises(ConfigurationError) as exc:\n        rc = DocConfig()\n        plugin_names = ['copy', 'file']\n        rc.prepare_plugin_docs_command(plugin_names, response_format='test')\n\n    assert \"Invalid response_format test, valid value is one of either json, human\" == exc.value.args[0]\n\n\ndef test_invalid_plugin_name_value():\n    with pytest.raises(ConfigurationError) as exc:\n        rc = DocConfig()\n        plugin_names = 'copy', 'file'\n        rc.prepare_plugin_docs_command(plugin_names)\n\n    assert \"plugin_names should be of type list\" in exc.value.args[0]\n\n\ndef test_prepare_plugin_docs_command():\n    rc = DocConfig()\n    plugin_names = ['copy', 'file']\n    plugin_type = 'module'\n    rc.prepare_plugin_docs_command(plugin_names, plugin_type=plugin_type, snippet=True, playbook_dir='/tmp/test')\n    expected_command = [get_executable_path('ansible-doc'), '-s', '-t', 'module', '--playbook-dir', '/tmp/test', 'copy file']\n    assert rc.command == expected_command\n    assert rc.runner_mode == 'subprocess'\n    assert rc.execution_mode == BaseExecutionMode.ANSIBLE_COMMANDS\n\n\n@pytest.mark.test_all_runtimes\ndef test_prepare_plugin_docs_command_with_containerization(tmp_path, runtime, mocker):\n    mocker.patch.dict('os.environ', {'HOME': str(tmp_path)}, clear=True)\n    tmp_path.joinpath('.ssh').mkdir()\n\n    kwargs = {\n        'private_data_dir': tmp_path,\n        'process_isolation': True,\n        'container_image': 'my_container',\n        'process_isolation_executable': runtime\n    }\n    rc = DocConfig(**kwargs)\n    rc.ident = 'foo'\n\n    plugin_names = ['copy', 'file']\n    plugin_type = 'module'\n    rc.prepare_plugin_docs_command(plugin_names, plugin_type=plugin_type, snippet=True, playbook_dir='/tmp/test')\n\n    assert rc.runner_mode == 'subprocess'\n    extra_container_args = []\n\n    if runtime == 'podman':\n        extra_container_args = ['--quiet']\n    else:\n        extra_container_args = [f'--user={os.getuid()}']\n\n    expected_command_start = [\n        runtime,\n        'run',\n        '--rm',\n        '--interactive',\n        '--workdir',\n        '/runner/project',\n        '-v', '{}/.ssh/:/home/runner/.ssh/'.format(rc.private_data_dir),\n        '-v', '{}/.ssh/:/root/.ssh/'.format(rc.private_data_dir),\n    ]\n\n    if runtime == 'podman':\n        expected_command_start.extend(['--group-add=root', '--ipc=host'])\n\n    expected_command_start.extend([\n        '-v', '{}/artifacts/:/runner/artifacts/:Z'.format(rc.private_data_dir),\n        '-v', '{}/:/runner/:Z'.format(rc.private_data_dir),\n        '--env-file', '{}/env.list'.format(rc.artifact_dir),\n    ])\n\n    expected_command_start.extend(extra_container_args)\n\n    expected_command_start.extend([\n        '--name', 'ansible_runner_foo',\n        'my_container',\n        'ansible-doc',\n        '-s',\n        '-t', 'module',\n        '--playbook-dir', '/tmp/test',\n        'copy '\n        'file',\n    ])\n\n    assert expected_command_start == rc.command\n\n\ndef test_prepare_plugin_list_command():\n    rc = DocConfig()\n    rc.prepare_plugin_list_command(list_files=True, plugin_type='module', playbook_dir='/tmp/test', module_path='/test/module')\n    expected_command = [get_executable_path('ansible-doc'), '-F', '-t', 'module', '--playbook-dir', '/tmp/test', '-M', '/test/module']\n    assert rc.command == expected_command\n    assert rc.runner_mode == 'subprocess'\n    assert rc.execution_mode == BaseExecutionMode.ANSIBLE_COMMANDS\n\n\n@pytest.mark.test_all_runtimes\ndef test_prepare_plugin_list_command_with_containerization(tmp_path, runtime, mocker):\n    mocker.patch.dict('os.environ', {'HOME': str(tmp_path)}, clear=True)\n    tmp_path.joinpath('.ssh').mkdir()\n\n    kwargs = {\n        'private_data_dir': tmp_path,\n        'process_isolation': True,\n        'container_image': 'my_container',\n        'process_isolation_executable': runtime\n    }\n    rc = DocConfig(**kwargs)\n    rc.ident = 'foo'\n    rc.prepare_plugin_list_command(list_files=True, plugin_type='module', playbook_dir='/tmp/test', module_path='/test/module')\n\n    assert rc.runner_mode == 'subprocess'\n    extra_container_args = []\n\n    if runtime == 'podman':\n        extra_container_args = ['--quiet']\n    else:\n        extra_container_args = [f'--user={os.getuid()}']\n\n    expected_command_start = [\n        runtime,\n        'run',\n        '--rm',\n        '--interactive',\n        '--workdir',\n        '/runner/project',\n        '-v', '{}/.ssh/:/home/runner/.ssh/'.format(rc.private_data_dir),\n        '-v', '{}/.ssh/:/root/.ssh/'.format(rc.private_data_dir),\n    ]\n\n    if runtime == 'podman':\n        expected_command_start.extend(['--group-add=root', '--ipc=host'])\n\n    expected_command_start.extend([\n        '-v', '{}/artifacts/:/runner/artifacts/:Z'.format(rc.private_data_dir),\n        '-v', '{}/:/runner/:Z'.format(rc.private_data_dir),\n        '--env-file', '{}/env.list'.format(rc.artifact_dir),\n    ])\n\n    expected_command_start.extend(extra_container_args)\n\n    expected_command_start.extend([\n        '--name', 'ansible_runner_foo',\n        'my_container',\n        'ansible-doc',\n        '-F',\n        '-t', 'module',\n        '--playbook-dir', '/tmp/test',\n        '-M', '/test/module'\n    ])\n\n    assert expected_command_start == rc.command\n"], "fixing_code": ["############################\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\nimport logging\n\nfrom ansible_runner.config._base import BaseConfig, BaseExecutionMode\nfrom ansible_runner.exceptions import ConfigurationError\nfrom ansible_runner.utils import get_executable_path\n\nlogger = logging.getLogger('ansible-runner')\n\n\nclass DocConfig(BaseConfig):\n    \"\"\"\n    A ``Runner`` configuration object that's meant to encapsulate the configuration used by the\n    :py:mod:`ansible_runner.runner.DocConfig` object to launch and manage the invocation of\n    command execution.\n\n    Typically this object is initialized for you when using the standard ``get_plugin_docs`` or ``get_plugin_list`` interfaces\n    in :py:mod:`ansible_runner.interface` but can be used to construct the ``DocConfig`` configuration to be invoked elsewhere.\n    It can also be overridden to provide different functionality to the DocConfig object.\n\n    :Example:\n\n    >>> dc = DocConfig(...)\n    >>> r = Runner(config=dc)\n    >>> r.run()\n\n    \"\"\"\n\n    def __init__(self, runner_mode=None, **kwargs):\n        # runner params\n        self.runner_mode = runner_mode if runner_mode else 'subprocess'\n        if self.runner_mode not in ['pexpect', 'subprocess']:\n            raise ConfigurationError(\"Invalid runner mode {0}, valid value is either 'pexpect' or 'subprocess'\".format(self.runner_mode))\n\n        if kwargs.get(\"process_isolation\"):\n            self._ansible_doc_exec_path = \"ansible-doc\"\n        else:\n            self._ansible_doc_exec_path = get_executable_path(\"ansible-doc\")\n\n        self.execution_mode = BaseExecutionMode.ANSIBLE_COMMANDS\n        super(DocConfig, self).__init__(**kwargs)\n\n    _supported_response_formats = ('json', 'human')\n\n    def prepare_plugin_docs_command(self, plugin_names, plugin_type=None, response_format=None,\n                                    snippet=False, playbook_dir=None, module_path=None):\n\n        if response_format and response_format not in DocConfig._supported_response_formats:\n            raise ConfigurationError(\"Invalid response_format {0}, valid value is one of either {1}\".format(response_format,\n                                                                                                            \", \".join(DocConfig._supported_response_formats)))\n\n        if not isinstance(plugin_names, list):\n            raise ConfigurationError(\"plugin_names should be of type list, instead received {0} of type {1}\".format(plugin_names, type(plugin_names)))\n\n        self._prepare_env(runner_mode=self.runner_mode)\n        self.cmdline_args = []\n\n        if response_format == 'json':\n            self.cmdline_args.append('-j')\n\n        if snippet:\n            self.cmdline_args.append('-s')\n\n        if plugin_type:\n            self.cmdline_args.extend(['-t', plugin_type])\n\n        if playbook_dir:\n            self.cmdline_args.extend(['--playbook-dir', playbook_dir])\n\n        if module_path:\n            self.cmdline_args.extend(['-M', module_path])\n\n        self.cmdline_args.extend(plugin_names)\n\n        self.command = [self._ansible_doc_exec_path] + self.cmdline_args\n        self._handle_command_wrap(self.execution_mode, self.cmdline_args)\n\n    def prepare_plugin_list_command(self, list_files=None, response_format=None, plugin_type=None,\n                                    playbook_dir=None, module_path=None):\n\n        if response_format and response_format not in DocConfig._supported_response_formats:\n            raise ConfigurationError(\"Invalid response_format {0}, valid value is one of either {1}\".format(response_format,\n                                                                                                            \", \".join(DocConfig._supported_response_formats)))\n\n        self._prepare_env(runner_mode=self.runner_mode)\n        self.cmdline_args = []\n\n        if list_files:\n            self.cmdline_args.append('-F')\n        else:\n            self.cmdline_args.append('-l')\n\n        if response_format == 'json':\n            self.cmdline_args.append('-j')\n\n        if plugin_type:\n            self.cmdline_args.extend(['-t', plugin_type])\n\n        if playbook_dir:\n            self.cmdline_args.extend(['--playbook-dir', playbook_dir])\n\n        if module_path:\n            self.cmdline_args.extend(['-M', module_path])\n\n        self.command = [self._ansible_doc_exec_path] + self.cmdline_args\n        self._handle_command_wrap(self.execution_mode, self.cmdline_args)\n", "import os\nimport stat\nimport time\nimport json\nimport errno\nimport signal\nfrom subprocess import Popen, PIPE, CalledProcessError, TimeoutExpired, run as run_subprocess\nimport shutil\nimport codecs\nimport collections\nimport datetime\nimport logging\n\nimport six\nimport pexpect\n\nimport ansible_runner.plugins\n\nfrom .utils import OutputEventFilter, cleanup_artifact_dir, ensure_str, collect_new_events\nfrom .exceptions import CallbackError, AnsibleRunnerException\nfrom ansible_runner.output import debug\n\nlogger = logging.getLogger('ansible-runner')\n\n\nclass Runner(object):\n\n    def __init__(self, config, cancel_callback=None, remove_partials=True, event_handler=None,\n                 artifacts_handler=None, finished_callback=None, status_handler=None):\n        self.config = config\n        self.cancel_callback = cancel_callback\n        self.event_handler = event_handler\n        self.artifacts_handler = artifacts_handler\n        self.finished_callback = finished_callback\n        self.status_handler = status_handler\n        self.canceled = False\n        self.timed_out = False\n        self.errored = False\n        self.status = \"unstarted\"\n        self.rc = None\n        self.remove_partials = remove_partials\n\n        # default runner mode to pexpect\n        self.runner_mode = self.config.runner_mode if hasattr(self.config, 'runner_mode') else 'pexpect'\n\n        self.resource_profiling = self.config.resource_profiling if hasattr(self.config, 'resource_profiling') else False\n        self.directory_isolation_path = self.config.directory_isolation_path if hasattr(self.config, 'directory_isolation_path') else None\n        self.directory_isolation_cleanup = self.config.directory_isolation_cleanup if hasattr(self.config, 'directory_isolation_cleanup') else None\n        self.process_isolation = self.config.process_isolation if hasattr(self.config, 'process_isolation') else None\n        self.process_isolation_path_actual = self.config.process_isolation_path_actual if hasattr(self.config, 'process_isolation_path_actual') else None\n\n    def event_callback(self, event_data):\n        '''\n        Invoked for every Ansible event to collect stdout with the event data and store it for\n        later use\n        '''\n        self.last_stdout_update = time.time()\n        if 'uuid' in event_data:\n            filename = '{}-partial.json'.format(event_data['uuid'])\n            partial_filename = os.path.join(self.config.artifact_dir,\n                                            'job_events',\n                                            filename)\n            full_filename = os.path.join(self.config.artifact_dir,\n                                         'job_events',\n                                         '{}-{}.json'.format(event_data['counter'],\n                                                             event_data['uuid']))\n            try:\n                event_data.update(dict(runner_ident=str(self.config.ident)))\n                try:\n                    with codecs.open(partial_filename, 'r', encoding='utf-8') as read_file:\n                        partial_event_data = json.load(read_file)\n                    event_data.update(partial_event_data)\n                    if self.remove_partials:\n                        os.remove(partial_filename)\n                except IOError as e:\n                    msg = \"Failed to open ansible stdout callback plugin partial data\" \\\n                          \" file {} with error {}\".format(partial_filename, str(e))\n                    debug(msg)\n                    if self.config.check_job_event_data:\n                        raise AnsibleRunnerException(msg)\n\n                # prefer 'created' from partial data, but verbose events set time here\n                if 'created' not in event_data:\n                    event_data['created'] = datetime.datetime.utcnow().isoformat()\n\n                if self.event_handler is not None:\n                    should_write = self.event_handler(event_data)\n                else:\n                    should_write = True\n                for plugin in ansible_runner.plugins:\n                    ansible_runner.plugins[plugin].event_handler(self.config, event_data)\n                if should_write:\n                    temporary_filename = full_filename + '.tmp'\n                    with codecs.open(temporary_filename, 'w', encoding='utf-8') as write_file:\n                        os.chmod(temporary_filename, stat.S_IRUSR | stat.S_IWUSR)\n                        json.dump(event_data, write_file)\n                    os.rename(temporary_filename, full_filename)\n            except IOError as e:\n                debug(\"Failed writing event data: {}\".format(e))\n\n    def status_callback(self, status):\n        self.status = status\n        status_data = {'status': status, 'runner_ident': str(self.config.ident)}\n        if status == 'starting':\n            status_data.update({'command': self.config.command, 'env': self.config.env, 'cwd': self.config.cwd})\n        for plugin in ansible_runner.plugins:\n            ansible_runner.plugins[plugin].status_handler(self.config, status_data)\n        if self.status_handler is not None:\n            self.status_handler(status_data, runner_config=self.config)\n\n    def run(self):\n        '''\n        Launch the Ansible task configured in self.config (A RunnerConfig object), returns once the\n        invocation is complete\n        '''\n        password_patterns = []\n        password_values = []\n\n        self.status_callback('starting')\n        stdout_filename = os.path.join(self.config.artifact_dir, 'stdout')\n        command_filename = os.path.join(self.config.artifact_dir, 'command')\n        stderr_filename = os.path.join(self.config.artifact_dir, 'stderr')\n\n        try:\n            os.makedirs(self.config.artifact_dir, mode=0o700)\n        except OSError as exc:\n            if exc.errno == errno.EEXIST and os.path.isdir(self.config.artifact_dir):\n                pass\n            else:\n                raise\n        os.close(os.open(stdout_filename, os.O_CREAT, stat.S_IRUSR | stat.S_IWUSR))\n\n        job_events_path = os.path.join(self.config.artifact_dir, 'job_events')\n        if not os.path.exists(job_events_path):\n            os.mkdir(job_events_path, 0o700)\n\n        command = self.config.command\n        with codecs.open(command_filename, 'w', encoding='utf-8') as f:\n            os.chmod(command_filename, stat.S_IRUSR | stat.S_IWUSR)\n            json.dump(\n                {'command': command,\n                 'cwd': self.config.cwd,\n                 'env': self.config.env}, f, ensure_ascii=False\n            )\n\n        if self.config.ident is not None:\n            cleanup_artifact_dir(os.path.join(self.config.artifact_dir, \"..\"), self.config.rotate_artifacts)\n\n        if hasattr(self.config, 'suppress_ansible_output'):\n            suppress_ansible_output = self.config.suppress_ansible_output\n        else:\n            suppress_ansible_output = False\n\n        stdout_handle = codecs.open(stdout_filename, 'w', encoding='utf-8')\n        stdout_handle = OutputEventFilter(stdout_handle, self.event_callback, suppress_ansible_output, output_json=self.config.json_mode)\n        stderr_handle = codecs.open(stderr_filename, 'w', encoding='utf-8')\n        stderr_handle = OutputEventFilter(stderr_handle, self.event_callback, suppress_ansible_output, output_json=self.config.json_mode)\n\n        if self.runner_mode == 'pexpect' and not isinstance(self.config.expect_passwords, collections.OrderedDict):\n            # We iterate over `expect_passwords.keys()` and\n            # `expect_passwords.values()` separately to map matched inputs to\n            # patterns and choose the proper string to send to the subprocess;\n            # enforce usage of an OrderedDict so that the ordering of elements in\n            # `keys()` matches `values()`.\n            expect_passwords = collections.OrderedDict(self.config.expect_passwords)\n            password_patterns = list(expect_passwords.keys())\n            password_values = list(expect_passwords.values())\n\n        # pexpect needs all env vars to be utf-8 encoded bytes\n        # https://github.com/pexpect/pexpect/issues/512\n\n        # Use a copy so as not to cause problems when serializing the job_env.\n        if self.config.containerized:\n            # We call the actual docker or podman executable right where we are\n            cwd = os.getcwd()\n            # If this is containerized, the shell environment calling podman has little\n            # to do with the actual job environment, but still needs PATH, auth, etc.\n            pexpect_env = os.environ.copy()\n            # But we still rely on env vars to pass secrets\n            pexpect_env.update(self.config.env)\n            # Write the keys to pass into container to expected file in artifacts dir\n            # option expecting should have already been written in ansible_runner.runner_config\n            env_file_host = os.path.join(self.config.artifact_dir, 'env.list')\n            with open(env_file_host, 'w') as f:\n                f.write(\n                    '\\n'.join(\n                        [\"{}={}\".format(key, value) for key, value in self.config.env.items()]\n                    )\n                )\n        else:\n            cwd = self.config.cwd\n            pexpect_env = self.config.env\n        env = {\n            ensure_str(k): ensure_str(v) if k != 'PATH' and isinstance(v, six.text_type) else v\n            for k, v in pexpect_env.items()\n        }\n\n        # Prepare to collect performance data\n        if self.resource_profiling:\n            cgroup_path = '{0}/{1}'.format(self.config.resource_profiling_base_cgroup, self.config.ident)\n\n            import getpass\n            import grp\n            user = getpass.getuser()\n            group = grp.getgrgid(os.getgid()).gr_name\n\n            cmd = ['cgcreate',\n                   '-a', f'{user}:{group}',\n                   '-t', f'{user}:{group}',\n                   '-g', f'cpuacct,memory,pids:{cgroup_path}',\n                   ]\n            proc = Popen(cmd, stdout=PIPE, stderr=PIPE)\n            _, stderr = proc.communicate()\n            if proc.returncode:\n                # Unable to create cgroup\n                logger.error('Unable to create cgroup: {}'.format(stderr))\n                raise RuntimeError('Unable to create cgroup: {}'.format(stderr))\n            else:\n                logger.info(\"Created cgroup '{}'\".format(cgroup_path))\n\n        self.status_callback('running')\n        self.last_stdout_update = time.time()\n\n        # The subprocess runner interface provides stdin/stdout/stderr with streaming capability\n        # to the caller if input_fd/output_fd/error_fd is passed to config class.\n        # Alsp, provides an workaround for known issue in pexpect for long running non-interactive process\n        # https://pexpect.readthedocs.io/en/stable/commonissues.html#truncated-output-just-before-child-exits\n        if self.runner_mode == 'subprocess':\n            if hasattr(self.config, 'input_fd') and self.config.input_fd:\n                input_fd = self.config.input_fd\n            else:\n                input_fd = None\n\n            if hasattr(self.config, 'output_fd') and self.config.output_fd:\n                output_fd = self.config.output_fd\n            else:\n                output_fd = PIPE\n\n            if hasattr(self.config, 'error_fd') and self.config.error_fd:\n                error_fd = self.config.error_fd\n            else:\n                error_fd = PIPE\n\n            subprocess_timeout = self.config.subprocess_timeout if hasattr(self.config, 'subprocess_timeout') else None\n            try:\n                stdout_response = ''\n                stderr_response = ''\n                kwargs = {\n                    'cwd': cwd,\n                    'env': env,\n                    'stdin': input_fd,\n                    'stdout': output_fd,\n                    'stderr': error_fd,\n                    'check': True,\n                    'universal_newlines': True,\n                }\n                if subprocess_timeout is not None:\n                    kwargs.update({'timeout': subprocess_timeout})\n\n                proc_out = run_subprocess(command, **kwargs)\n\n                stdout_response = proc_out.stdout\n                stderr_response = proc_out.stderr\n                self.rc = proc_out.returncode\n            except CalledProcessError as exc:\n                logger.debug(\"{cmd} execution failed, returncode: {rc}, output: {output}, stdout: {stdout}, stderr: {stderr}\".format(\n                    cmd=exc.cmd, rc=exc.returncode, output=exc.output, stdout=exc.stdout, stderr=exc.stderr))\n                self.rc = exc.returncode\n                self.errored = True\n                stdout_response = exc.stdout\n                stderr_response = exc.stderr\n            except TimeoutExpired as exc:\n                logger.debug(\"{cmd} execution timedout, timeout: {timeout}, output: {output}, stdout: {stdout}, stderr: {stderr}\".format(\n                    cmd=exc.cmd, timeout=exc.timeout, output=exc.output, stdout=exc.stdout, stderr=exc.stderr))\n                self.rc = 254\n                stdout_response = exc.stdout\n                stderr_response = exc.stderr\n                self.timed_out = True\n            except Exception as exc:\n                import traceback\n                stderr_response = traceback.format_exc()\n                self.rc = 254\n                self.errored = True\n                logger.debug(\"received execption: {exc}\".format(exc=str(exc)))\n\n            if self.timed_out or self.errored:\n                self.kill_container()\n\n            if stdout_response is not None:\n                if isinstance(stdout_response, bytes):\n                    stdout_response = stdout_response.decode()\n                stdout_handle.write(stdout_response)\n            if stderr_response is not None:\n                if isinstance(stderr_response, bytes):\n                    stderr_response = stderr_response.decode()\n                stderr_handle.write(stderr_response)\n        else:\n            try:\n                child = pexpect.spawn(\n                    command[0],\n                    command[1:],\n                    cwd=cwd,\n                    env=env,\n                    ignore_sighup=True,\n                    encoding='utf-8',\n                    codec_errors='replace',\n                    echo=False,\n                    use_poll=self.config.pexpect_use_poll,\n                )\n                child.logfile_read = stdout_handle\n            except pexpect.exceptions.ExceptionPexpect as e:\n                child = collections.namedtuple(\n                    'MissingProcess', 'exitstatus isalive close'\n                )(\n                    exitstatus=127,\n                    isalive=lambda: False,\n                    close=lambda: None,\n                )\n\n                def _decode(x):\n                    return x.decode('utf-8') if six.PY2 else x\n\n                # create the events directory (the callback plugin won't run, so it\n                # won't get created)\n                events_directory = os.path.join(self.config.artifact_dir, 'job_events')\n                if not os.path.exists(events_directory):\n                    os.mkdir(events_directory, 0o700)\n                stdout_handle.write(_decode(str(e)))\n                stdout_handle.write(_decode('\\n'))\n\n            job_start = time.time()\n            while child.isalive():\n                result_id = child.expect(password_patterns, timeout=self.config.pexpect_timeout, searchwindowsize=100)\n                password = password_values[result_id]\n                if password is not None:\n                    child.sendline(password)\n                    self.last_stdout_update = time.time()\n                if self.cancel_callback:\n                    try:\n                        self.canceled = self.cancel_callback()\n                    except Exception as e:\n                        # TODO: logger.exception('Could not check cancel callback - cancelling immediately')\n                        # if isinstance(extra_update_fields, dict):\n                        #     extra_update_fields['job_explanation'] = \"System error during job execution, check system logs\"\n                        raise CallbackError(\"Exception in Cancel Callback: {}\".format(e))\n                if self.config.job_timeout and not self.canceled and (time.time() - job_start) > self.config.job_timeout:\n                    self.timed_out = True\n                    # if isinstance(extra_update_fields, dict):\n                    #     extra_update_fields['job_explanation'] = \"Job terminated due to timeout\"\n                if self.canceled or self.timed_out or self.errored:\n                    self.kill_container()\n                    Runner.handle_termination(child.pid, is_cancel=self.canceled)\n                if self.config.idle_timeout and (time.time() - self.last_stdout_update) > self.config.idle_timeout:\n                    self.kill_container()\n                    Runner.handle_termination(child.pid, is_cancel=False)\n                    self.timed_out = True\n\n            stdout_handle.flush()\n            stdout_handle.close()\n            child.close()\n            self.rc = child.exitstatus if not (self.timed_out or self.canceled) else 254\n\n        if self.canceled:\n            self.status_callback('canceled')\n        elif self.rc == 0 and not self.timed_out:\n            self.status_callback('successful')\n        elif self.timed_out:\n            self.status_callback('timeout')\n        else:\n            self.status_callback('failed')\n\n        for filename, data in [\n            ('status', self.status),\n            ('rc', self.rc),\n        ]:\n            artifact_path = os.path.join(self.config.artifact_dir, filename)\n            if not os.path.exists(artifact_path):\n                os.close(os.open(artifact_path, os.O_CREAT, stat.S_IRUSR | stat.S_IWUSR))\n            with open(artifact_path, 'w') as f:\n                f.write(str(data))\n        if self.directory_isolation_path and self.directory_isolation_cleanup:\n            shutil.rmtree(self.directory_isolation_path)\n        if self.process_isolation and self.process_isolation_path_actual:\n            def _delete(retries=15):\n                try:\n                    shutil.rmtree(self.process_isolation_path_actual)\n                except OSError as e:\n                    res = False\n                    if e.errno == 16 and retries > 0:\n                        time.sleep(1)\n                        res = _delete(retries=retries - 1)\n                    if not res:\n                        raise\n                return True\n            _delete()\n        if self.resource_profiling:\n            cmd = ['cgdelete', '-g', f'cpuacct,memory,pids:{cgroup_path}']\n            proc = Popen(cmd, stdout=PIPE, stderr=PIPE)\n            _, stderr = proc.communicate()\n            if proc.returncode:\n                logger.error('Failed to delete cgroup: {}'.format(stderr))\n                raise RuntimeError('Failed to delete cgroup: {}'.format(stderr))\n\n        if self.artifacts_handler is not None:\n            try:\n                self.artifacts_handler(self.config.artifact_dir)\n            except Exception as e:\n                raise CallbackError(\"Exception in Artifact Callback: {}\".format(e))\n\n        if self.finished_callback is not None:\n            try:\n                self.finished_callback(self)\n            except Exception as e:\n                raise CallbackError(\"Exception in Finished Callback: {}\".format(e))\n        return self.status, self.rc\n\n    @property\n    def stdout(self):\n        '''\n        Returns an open file handle to the stdout representing the Ansible run\n        '''\n        stdout_path = os.path.join(self.config.artifact_dir, 'stdout')\n        if not os.path.exists(stdout_path):\n            raise AnsibleRunnerException(\"stdout missing\")\n        return open(os.path.join(self.config.artifact_dir, 'stdout'), 'r')\n\n    @property\n    def stderr(self):\n        '''\n        Returns an open file handle to the stderr representing the Ansible run\n        '''\n        stderr_path = os.path.join(self.config.artifact_dir, 'stderr')\n        if not os.path.exists(stderr_path):\n            raise AnsibleRunnerException(\"stderr missing\")\n        return open(os.path.join(self.config.artifact_dir, 'stderr'), 'r')\n\n    @property\n    def events(self):\n        '''\n        A generator that will return all ansible job events in the order that they were emitted from Ansible\n\n        :Example:\n\n        .. code-block::\n\n            {\n               \"event\": \"runner_on_ok\",\n               \"uuid\": \"00a50d9c-161a-4b74-b978-9f60becaf209\",\n               \"stdout\": \"ok: [localhost] => {\\\\r\\\\n    \\\\\"   msg\\\\\":\\\\\"Test!\\\\\"\\\\r\\\\n}\",\n               \"counter\": 6,\n               \"pid\": 740,\n               \"created\": \"2018-04-05T18:24:36.096725\",\n               \"end_line\": 10,\n               \"start_line\": 7,\n               \"event_data\": {\n                  \"play_pattern\": \"all\",\n                  \"play\": \"all\",\n                  \"task\": \"debug\",\n                  \"task_args\": \"msg=Test!\",\n                  \"remote_addr\": \"localhost\",\n                  \"res\": {\n                     \"msg\": \"Test!\",\n                     \"changed\": false,\n                     \"_ansible_verbose_always\": true,\n                     \"_ansible_no_log\": false\n                  },\n                  \"pid\": 740,\n                  \"play_uuid\": \"0242ac11-0002-443b-cdb1-000000000006\",\n                  \"task_uuid\": \"0242ac11-0002-443b-cdb1-000000000008\",\n                  \"event_loop\": null,\n                  \"playbook_uuid\": \"634edeee-3228-4c17-a1b4-f010fdd42eb2\",\n                  \"playbook\": \"test.yml\",\n                  \"task_action\": \"debug\",\n                  \"host\": \"localhost\",\n                  \"task_path\": \"/tmp/demo/project/test.yml:3\"\n               }\n           }\n        '''\n        # collection of all the events that were yielded\n        old_events = {}\n        event_path = os.path.join(self.config.artifact_dir, 'job_events')\n\n        # Wait for events dir to be created\n        now = datetime.datetime.now()\n        while not os.path.exists(event_path):\n            time.sleep(0.05)\n            wait_time = datetime.datetime.now() - now\n            if wait_time.total_seconds() > 60:\n                raise AnsibleRunnerException(\"events directory is missing: %s\" % event_path)\n\n        while self.status == \"running\":\n            for event, old_evnts in collect_new_events(event_path, old_events):\n                old_events = old_evnts\n                yield event\n\n        # collect new events that were written after the playbook has finished\n        for event, old_evnts in collect_new_events(event_path, old_events):\n            old_events = old_evnts\n            yield event\n\n    @property\n    def stats(self):\n        '''\n        Returns the final high level stats from the Ansible run\n\n        Example:\n            {'dark': {}, 'failures': {}, 'skipped': {}, 'ok': {u'localhost': 2}, 'processed': {u'localhost': 1}}\n        '''\n        last_event = list(filter(lambda x: 'event' in x and x['event'] == 'playbook_on_stats',\n                                 self.events))\n        if not last_event:\n            return None\n        last_event = last_event[0]['event_data']\n        return dict(skipped=last_event.get('skipped', {}),\n                    ok=last_event.get('ok', {}),\n                    dark=last_event.get('dark', {}),\n                    failures=last_event.get('failures', {}),\n                    ignored=last_event.get('ignored', {}),\n                    rescued=last_event.get('rescued', {}),\n                    processed=last_event.get('processed', {}),\n                    changed=last_event.get('changed', {}))\n\n    def host_events(self, host):\n        '''\n        Given a host name, this will return all task events executed on that host\n        '''\n        all_host_events = filter(lambda x: 'event_data' in x and 'host' in x['event_data'] and x['event_data']['host'] == host,\n                                 self.events)\n        return all_host_events\n\n    def kill_container(self):\n        '''\n        Internal method to terminate a container being used for job isolation\n        '''\n        container_name = self.config.container_name\n        if container_name:\n            container_cli = self.config.process_isolation_executable\n            cmd = [container_cli, 'kill', container_name]\n            proc = Popen(cmd, stdout=PIPE, stderr=PIPE)\n            _, stderr = proc.communicate()\n            if proc.returncode:\n                logger.info('Error from {} kill {} command:\\n{}'.format(container_cli, container_name, stderr))\n            else:\n                logger.info(\"Killed container {}\".format(container_name))\n\n    @classmethod\n    def handle_termination(cls, pid, pidfile=None, is_cancel=True):\n        '''\n        Internal method to terminate a subprocess spawned by `pexpect` representing an invocation of runner.\n\n        :param pid:       the process id of the running the job.\n        :param pidfile:   the daemon's PID file\n        :param is_cancel: flag showing whether this termination is caused by\n                          instance's cancel_flag.\n        '''\n\n        try:\n            pgroup = os.getpgid(pid)\n            os.killpg(pgroup, signal.SIGKILL)\n        except (OSError, ProcessLookupError):\n            pass\n        try:\n            os.remove(pidfile)\n        except (TypeError, OSError):\n            pass\n\n    def get_fact_cache(self, host):\n        '''\n        Get the entire fact cache only if the fact_cache_type is 'jsonfile'\n        '''\n        if self.config.fact_cache_type != 'jsonfile':\n            raise Exception('Unsupported fact cache type.  Only \"jsonfile\" is supported for reading and writing facts from ansible-runner')\n        fact_cache = os.path.join(self.config.fact_cache, host)\n        if os.path.exists(fact_cache):\n            with open(fact_cache) as f:\n                return json.loads(f.read())\n        return {}\n\n    def set_fact_cache(self, host, data):\n        '''\n        Set the entire fact cache data only if the fact_cache_type is 'jsonfile'\n        '''\n        if self.config.fact_cache_type != 'jsonfile':\n            raise Exception('Unsupported fact cache type.  Only \"jsonfile\" is supported for reading and writing facts from ansible-runner')\n        fact_cache = os.path.join(self.config.fact_cache, host)\n        if not os.path.exists(os.path.dirname(fact_cache)):\n            os.makedirs(os.path.dirname(fact_cache), mode=0o700)\n        with open(fact_cache, 'w') as f:\n            return f.write(json.dumps(data))\n", "import os\nimport pytest\n\nfrom ansible_runner import defaults\nfrom ansible_runner.interface import run, run_async, run_command, run_command_async, get_plugin_docs, \\\n    get_plugin_docs_async, get_plugin_list, get_ansible_config, get_inventory\n\n\ndef test_run():\n    r = run(module='debug', host_pattern='localhost')\n    assert r.status == 'successful'\n\n\n@pytest.mark.parametrize(\n    'playbook', (\n        [{'hosts': 'localhost', 'tasks': [{'ping': ''}]}],\n        {'hosts': 'localhost', 'tasks': [{'ping': ''}]},\n    )\n)\ndef test_run_playbook_data(playbook, tmp_path):\n    r = run(private_data_dir=str(tmp_path), playbook=playbook)\n    assert r.status == 'successful'\n\n\ndef test_run_async(tmp_path):\n    thread, r = run_async(private_data_dir=str(tmp_path), module='debug', host_pattern='localhost')\n    thread.join()\n    assert r.status == 'successful'\n\n\ndef get_env_data(res):\n    for event in res.events:\n        found = bool(\n            event['event'] == 'runner_on_ok' and event.get(\n                'event_data', {}\n            ).get('task_action', None) == 'look_at_environment'\n        )\n        if found:\n            return event['event_data']['res']\n    else:\n        print('output:')\n        print(res.stdout.read())\n        raise RuntimeError('Count not find look_at_environment task from playbook')\n\n\ndef test_env_accuracy(request, project_fixtures):\n    printenv_example = project_fixtures / 'printenv'\n    os.environ['SET_BEFORE_TEST'] = 'MADE_UP_VALUE'\n\n    def remove_test_env_var():\n        if 'SET_BEFORE_TEST' in os.environ:\n            del os.environ['SET_BEFORE_TEST']\n\n    request.addfinalizer(remove_test_env_var)\n\n    res = run(\n        private_data_dir=printenv_example,\n        playbook='get_environment.yml',\n        inventory=None,\n        envvars={'FROM_TEST': 'FOOBAR'},\n    )\n    assert res.rc == 0, res.stdout.read()\n\n    actual_env = get_env_data(res)['environment']\n\n    assert actual_env == res.config.env\n\n\n@pytest.mark.test_all_runtimes\ndef test_env_accuracy_inside_container(request, project_fixtures, runtime):\n    printenv_example = project_fixtures / 'printenv'\n    os.environ['SET_BEFORE_TEST'] = 'MADE_UP_VALUE'\n\n    def remove_test_env_var():\n        if 'SET_BEFORE_TEST' in os.environ:\n            del os.environ['SET_BEFORE_TEST']\n\n    request.addfinalizer(remove_test_env_var)\n\n    res = run(\n        private_data_dir=printenv_example,\n        project_dir='/tmp',\n        playbook='get_environment.yml',\n        inventory=None,\n        envvars={'FROM_TEST': 'FOOBAR'},\n        settings={\n            'process_isolation_executable': runtime,\n            'process_isolation': True\n        }\n    )\n    assert res.rc == 0, res.stdout.read()\n\n    env_data = get_env_data(res)\n    actual_env = env_data['environment']\n\n    expected_env = res.config.env.copy()\n\n    # NOTE: the reported environment for containerized jobs will not account for\n    # all environment variables, particularly those set by the entrypoint script\n    for key, value in expected_env.items():\n        assert key in actual_env\n        assert actual_env[key] == value, 'Reported value wrong for {0} env var'.format(key)\n\n    assert env_data['cwd'] == res.config.cwd\n\n\ndef test_multiple_inventories(project_fixtures):\n    private_data_dir = project_fixtures / 'debug'\n\n    res = run(\n        private_data_dir=private_data_dir,\n        playbook='debug.yml',\n    )\n    stdout = res.stdout.read()\n    assert res.rc == 0, stdout\n\n    # providing no inventory should cause <private_data_dir>/inventory\n    # to be used, reading both inventories in the directory\n    assert 'host_1' in stdout\n    assert 'host_2' in stdout\n\n\ndef test_inventory_absolute_path(project_fixtures):\n    private_data_dir = project_fixtures / 'debug'\n\n    res = run(\n        private_data_dir=private_data_dir,\n        playbook='debug.yml',\n        inventory=[\n            str(private_data_dir / 'inventory' / 'inv_1'),\n        ],\n    )\n    stdout = res.stdout.read()\n    assert res.rc == 0, stdout\n\n    # hosts can be down-selected to one inventory out of those available\n    assert 'host_1' in stdout\n    assert 'host_2' not in stdout\n\n\ndef test_run_command(project_fixtures):\n    private_data_dir = project_fixtures / 'debug'\n    inventory = private_data_dir / 'inventory' / 'inv_1'\n    playbook = private_data_dir / 'project' / 'debug.yml'\n    out, err, rc = run_command(\n        private_data_dir=private_data_dir,\n        executable_cmd='ansible-playbook',\n        cmdline_args=[str(playbook), '-i', str(inventory)]\n    )\n    assert \"Hello world!\" in out\n    assert rc == 0\n    assert err == ''\n\n\ndef test_run_command_injection_error():\n    out, err, rc = run_command(\n        executable_cmd='whoami',\n        cmdline_args=[';hostname'],\n        runner_mode='subprocess',\n    )\n    assert rc == 1\n    assert \"usage: whoami\" in err or \"whoami: extra operand \u2018;hostname\u2019\" in err\n\n\n@pytest.mark.test_all_runtimes\ndef test_run_command_injection_error_within_container(runtime):\n    out, err, rc = run_command(\n        executable_cmd='whoami',\n        cmdline_args=[';hostname'],\n        runner_mode='subprocess',\n        process_isolation_executable=runtime,\n        process_isolation=True,\n        container_image=defaults.default_container_image,\n    )\n    assert rc == 1\n    assert \"whoami: extra operand ';hostname'\" in err\n\n\n@pytest.mark.test_all_runtimes\ndef test_run_ansible_command_within_container(project_fixtures, runtime):\n    private_data_dir = project_fixtures / 'debug'\n    inventory = private_data_dir / 'inventory' / 'inv_1'\n    playbook = private_data_dir / 'project' / 'debug.yml'\n    container_kwargs = {\n        'process_isolation_executable': runtime,\n        'process_isolation': True,\n        'container_image': defaults.default_container_image\n    }\n    out, err, rc = run_command(\n        private_data_dir=private_data_dir,\n        executable_cmd='ansible-playbook',\n        cmdline_args=[str(playbook), '-i', str(inventory)],\n        **container_kwargs\n    )\n    assert \"Hello world!\" in out\n    assert rc == 0\n    assert err == ''\n\n\n@pytest.mark.test_all_runtimes\ndef test_run_script_within_container(project_fixtures, runtime):\n    private_data_dir = project_fixtures / 'debug'\n    script_path = project_fixtures / 'files'\n    container_volume_mounts = [\"{}:{}:Z\".format(script_path, script_path)]\n    container_kwargs = {\n        'process_isolation_executable': runtime,\n        'process_isolation': True,\n        'container_image': defaults.default_container_image,\n        'container_volume_mounts': container_volume_mounts\n    }\n    out, _, rc = run_command(\n        private_data_dir=private_data_dir,\n        executable_cmd='python3',\n        cmdline_args=[str(script_path / 'test_ee.py')],\n        **container_kwargs\n    )\n\n    assert \"os-release\" in out\n    assert rc == 0\n\n\ndef test_run_command_async(project_fixtures):\n    private_data_dir = project_fixtures / 'debug'\n    inventory = private_data_dir / 'inventory' / 'inv_1'\n    playbook = private_data_dir / 'project' / 'debug.yml'\n    thread, r = run_command_async(\n        private_data_dir=private_data_dir,\n        executable_cmd='ansible-playbook',\n        cmdline_args=[str(playbook), '-i', str(inventory)]\n    )\n    thread.join()\n    out = r.stdout.read()\n    assert \"Hello world!\" in out\n    assert r.status == 'successful'\n\n\ndef test_get_plugin_docs():\n    out, _ = get_plugin_docs(\n        plugin_names=['file', 'copy'],\n        plugin_type='module',\n        quiet=True\n    )\n    assert 'copy' in out\n    assert 'file' in out\n\n\ndef test_get_plugin_docs_async():\n    thread, r = get_plugin_docs_async(\n        plugin_names=['file', 'copy'],\n        plugin_type='module',\n        quiet=True\n    )\n    thread.join()\n    out = r.stdout.read()\n    assert 'copy' in out\n    assert 'file' in out\n    assert r.status == 'successful'\n\n\n@pytest.mark.test_all_runtimes\ndef test_get_plugin_docs_within_container(runtime):\n    container_kwargs = {\n        'process_isolation_executable': runtime,\n        'process_isolation': True,\n        'container_image': defaults.default_container_image\n    }\n    out, _ = get_plugin_docs(\n        plugin_names=['file', 'copy'],\n        plugin_type='module',\n        quiet=True,\n        **container_kwargs\n    )\n    assert 'copy' in out\n    assert 'file' in out\n\n\ndef test_get_plugin_docs_list():\n    out, _ = get_plugin_list(\n        list_files=True,\n        quiet=True\n    )\n    assert 'copy' in out\n    assert 'file' in out\n\n\n@pytest.mark.test_all_runtimes\ndef test_get_plugin_docs_list_within_container(runtime):\n    container_kwargs = {\n        'process_isolation_executable': runtime,\n        'process_isolation': True,\n        'container_image': defaults.default_container_image\n    }\n    out, _ = get_plugin_list(\n        list_files=True,\n        quiet=True,\n        **container_kwargs\n    )\n    assert 'copy' in out\n    assert 'file' in out\n\n\ndef test_ansible_config():\n    out, _ = get_ansible_config(\n        action='list',\n        quiet=True\n    )\n    assert 'DEFAULT_VERBOSITY' in out\n\n\ndef test_get_inventory(project_fixtures):\n    private_data_dir = project_fixtures / 'debug'\n    inventory1 = private_data_dir / 'inventory' / 'inv_1'\n    inventory2 = private_data_dir / 'inventory' / 'inv_2'\n\n    out, _ = get_inventory(\n        action='list',\n        inventories=[str(inventory1), str(inventory2)],\n        response_format='json',\n        quiet=True\n    )\n    assert 'host_1' in out['ungrouped']['hosts']\n    assert 'host_2' in out['ungrouped']['hosts']\n\n\n@pytest.mark.test_all_runtimes\ndef test_get_inventory_within_container(project_fixtures, runtime):\n    container_kwargs = {\n        'process_isolation_executable': runtime,\n        'process_isolation': True,\n        'container_image': defaults.default_container_image\n    }\n    private_data_dir = project_fixtures / 'debug'\n    inventory1 = private_data_dir / 'inventory' / 'inv_1'\n    inventory2 = private_data_dir / 'inventory' / 'inv_2'\n\n    out, _ = get_inventory(\n        action='list',\n        inventories=[str(inventory1), str(inventory2)],\n        response_format='json',\n        quiet=True,\n        **container_kwargs\n    )\n    assert 'host_1' in out['ungrouped']['hosts']\n    assert 'host_2' in out['ungrouped']['hosts']\n", "# -*- coding: utf-8 -*-\n\nimport os\nimport pytest\n\nfrom ansible_runner.config.doc import DocConfig\nfrom ansible_runner.config._base import BaseExecutionMode\nfrom ansible_runner.exceptions import ConfigurationError\nfrom ansible_runner.utils import get_executable_path\n\n\ndef test_ansible_doc_defaults(tmp_path, patch_private_data_dir):\n    rc = DocConfig()\n\n    # Check that the private data dir is placed in our default location with our default prefix\n    # and has some extra uniqueness on the end.\n    base_private_data_dir = tmp_path.joinpath('.ansible-runner-').as_posix()\n    assert rc.private_data_dir.startswith(base_private_data_dir)\n    assert len(rc.private_data_dir) > len(base_private_data_dir)\n\n    assert rc.execution_mode == BaseExecutionMode.ANSIBLE_COMMANDS\n    assert rc.runner_mode == 'subprocess'\n\n\ndef test_invalid_runner_mode_value():\n    with pytest.raises(ConfigurationError) as exc:\n        DocConfig(runner_mode='test')\n\n    assert \"Invalid runner mode\" in exc.value.args[0]\n\n\ndef test_invalid_response_format_value():\n    with pytest.raises(ConfigurationError) as exc:\n        rc = DocConfig()\n        plugin_names = ['copy', 'file']\n        rc.prepare_plugin_docs_command(plugin_names, response_format='test')\n\n    assert \"Invalid response_format test, valid value is one of either json, human\" == exc.value.args[0]\n\n\ndef test_invalid_plugin_name_value():\n    with pytest.raises(ConfigurationError) as exc:\n        rc = DocConfig()\n        plugin_names = 'copy', 'file'\n        rc.prepare_plugin_docs_command(plugin_names)\n\n    assert \"plugin_names should be of type list\" in exc.value.args[0]\n\n\ndef test_prepare_plugin_docs_command():\n    rc = DocConfig()\n    plugin_names = ['copy', 'file']\n    plugin_type = 'module'\n    rc.prepare_plugin_docs_command(plugin_names, plugin_type=plugin_type, snippet=True, playbook_dir='/tmp/test')\n    expected_command = [get_executable_path('ansible-doc'), '-s', '-t', 'module', '--playbook-dir', '/tmp/test', 'copy', 'file']\n    assert rc.command == expected_command\n    assert rc.runner_mode == 'subprocess'\n    assert rc.execution_mode == BaseExecutionMode.ANSIBLE_COMMANDS\n\n\n@pytest.mark.test_all_runtimes\ndef test_prepare_plugin_docs_command_with_containerization(tmp_path, runtime, mocker):\n    mocker.patch.dict('os.environ', {'HOME': str(tmp_path)}, clear=True)\n    tmp_path.joinpath('.ssh').mkdir()\n\n    kwargs = {\n        'private_data_dir': tmp_path,\n        'process_isolation': True,\n        'container_image': 'my_container',\n        'process_isolation_executable': runtime\n    }\n    rc = DocConfig(**kwargs)\n    rc.ident = 'foo'\n\n    plugin_names = ['copy', 'file']\n    plugin_type = 'module'\n    rc.prepare_plugin_docs_command(plugin_names, plugin_type=plugin_type, snippet=True, playbook_dir='/tmp/test')\n\n    assert rc.runner_mode == 'subprocess'\n    extra_container_args = []\n\n    if runtime == 'podman':\n        extra_container_args = ['--quiet']\n    else:\n        extra_container_args = [f'--user={os.getuid()}']\n\n    expected_command_start = [\n        runtime,\n        'run',\n        '--rm',\n        '--interactive',\n        '--workdir',\n        '/runner/project',\n        '-v', '{}/.ssh/:/home/runner/.ssh/'.format(rc.private_data_dir),\n        '-v', '{}/.ssh/:/root/.ssh/'.format(rc.private_data_dir),\n    ]\n\n    if runtime == 'podman':\n        expected_command_start.extend(['--group-add=root', '--ipc=host'])\n\n    expected_command_start.extend([\n        '-v', '{}/artifacts/:/runner/artifacts/:Z'.format(rc.private_data_dir),\n        '-v', '{}/:/runner/:Z'.format(rc.private_data_dir),\n        '--env-file', '{}/env.list'.format(rc.artifact_dir),\n    ])\n\n    expected_command_start.extend(extra_container_args)\n\n    expected_command_start.extend([\n        '--name', 'ansible_runner_foo',\n        'my_container',\n        'ansible-doc',\n        '-s',\n        '-t', 'module',\n        '--playbook-dir', '/tmp/test',\n        'copy',\n        'file',\n    ])\n\n    assert expected_command_start == rc.command\n\n\ndef test_prepare_plugin_list_command():\n    rc = DocConfig()\n    rc.prepare_plugin_list_command(list_files=True, plugin_type='module', playbook_dir='/tmp/test', module_path='/test/module')\n    expected_command = [get_executable_path('ansible-doc'), '-F', '-t', 'module', '--playbook-dir', '/tmp/test', '-M', '/test/module']\n    assert rc.command == expected_command\n    assert rc.runner_mode == 'subprocess'\n    assert rc.execution_mode == BaseExecutionMode.ANSIBLE_COMMANDS\n\n\n@pytest.mark.test_all_runtimes\ndef test_prepare_plugin_list_command_with_containerization(tmp_path, runtime, mocker):\n    mocker.patch.dict('os.environ', {'HOME': str(tmp_path)}, clear=True)\n    tmp_path.joinpath('.ssh').mkdir()\n\n    kwargs = {\n        'private_data_dir': tmp_path,\n        'process_isolation': True,\n        'container_image': 'my_container',\n        'process_isolation_executable': runtime\n    }\n    rc = DocConfig(**kwargs)\n    rc.ident = 'foo'\n    rc.prepare_plugin_list_command(list_files=True, plugin_type='module', playbook_dir='/tmp/test', module_path='/test/module')\n\n    assert rc.runner_mode == 'subprocess'\n    extra_container_args = []\n\n    if runtime == 'podman':\n        extra_container_args = ['--quiet']\n    else:\n        extra_container_args = [f'--user={os.getuid()}']\n\n    expected_command_start = [\n        runtime,\n        'run',\n        '--rm',\n        '--interactive',\n        '--workdir',\n        '/runner/project',\n        '-v', '{}/.ssh/:/home/runner/.ssh/'.format(rc.private_data_dir),\n        '-v', '{}/.ssh/:/root/.ssh/'.format(rc.private_data_dir),\n    ]\n\n    if runtime == 'podman':\n        expected_command_start.extend(['--group-add=root', '--ipc=host'])\n\n    expected_command_start.extend([\n        '-v', '{}/artifacts/:/runner/artifacts/:Z'.format(rc.private_data_dir),\n        '-v', '{}/:/runner/:Z'.format(rc.private_data_dir),\n        '--env-file', '{}/env.list'.format(rc.artifact_dir),\n    ])\n\n    expected_command_start.extend(extra_container_args)\n\n    expected_command_start.extend([\n        '--name', 'ansible_runner_foo',\n        'my_container',\n        'ansible-doc',\n        '-F',\n        '-t', 'module',\n        '--playbook-dir', '/tmp/test',\n        '-M', '/test/module'\n    ])\n\n    assert expected_command_start == rc.command\n"], "filenames": ["ansible_runner/config/doc.py", "ansible_runner/runner.py", "test/integration/test_interface.py", "test/unit/config/test_doc.py"], "buggy_code_start_loc": [90, 207, 154, 55], "buggy_code_end_loc": [91, 537, 154, 117], "fixing_code_start_loc": [90, 207, 155, 55], "fixing_code_end_loc": [91, 540, 179, 117], "type": "CWE-116", "message": "A flaw was found in ansible-runner. An improper escaping of the shell command, while calling the ansible_runner.interface.run_command, can lead to parameters getting executed as host's shell command. A developer could unintentionally write code that gets executed in the host rather than the virtual environment.", "other": {"cve": {"id": "CVE-2021-4041", "sourceIdentifier": "secalert@redhat.com", "published": "2022-08-24T16:15:09.370", "lastModified": "2022-08-29T14:30:13.960", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "A flaw was found in ansible-runner. An improper escaping of the shell command, while calling the ansible_runner.interface.run_command, can lead to parameters getting executed as host's shell command. A developer could unintentionally write code that gets executed in the host rather than the virtual environment."}, {"lang": "es", "value": "Se ha encontrado un fallo en ansible-runner. Un escape inapropiado del comando shell, mientras es llamado a ansible_runner.interface.run_command, puede conllevar a que los par\u00e1metros sean ejecutados como el comando shell del host. Un desarrollador podr\u00eda escribir involuntariamente c\u00f3digo que es ejecutado en el host en lugar de en el entorno virtual."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.9}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-116"}]}, {"source": "secalert@redhat.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-20"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:redhat:ansible_runner:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.1.0", "matchCriteriaId": "A0CD1454-F8D9-4398-A693-7EDD8E78CF3D"}, {"vulnerable": true, "criteria": "cpe:2.3:a:redhat:ansible_runner:2.1.0:alpha1:*:*:*:*:*:*", "matchCriteriaId": "AF2F5E46-5EE6-4480-989D-4FAE1339F755"}, {"vulnerable": true, "criteria": "cpe:2.3:a:redhat:ansible_runner:2.1.0:alpha2:*:*:*:*:*:*", "matchCriteriaId": "33D69031-082E-4C58-A4C6-DF4572F2960C"}, {"vulnerable": true, "criteria": "cpe:2.3:a:redhat:ansible_runner:2.1.0:beta1:*:*:*:*:*:*", "matchCriteriaId": "8F62416A-386A-4093-91D0-A91C1BB067B1"}]}]}], "references": [{"url": "https://access.redhat.com/security/cve/CVE-2021-4041", "source": "secalert@redhat.com", "tags": ["Vendor Advisory"]}, {"url": "https://bugzilla.redhat.com/show_bug.cgi?id=2028074", "source": "secalert@redhat.com", "tags": ["Issue Tracking", "Patch", "Vendor Advisory"]}, {"url": "https://github.com/ansible/ansible-runner/commit/3533f265f4349a3f2a0283158cd01b59a6bbc7bd", "source": "secalert@redhat.com", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/ansible/ansible-runner/commit/3533f265f4349a3f2a0283158cd01b59a6bbc7bd"}}
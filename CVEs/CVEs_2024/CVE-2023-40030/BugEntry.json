{"buggy_code": ["#![allow(clippy::all)]\n\nuse std::cell::RefCell;\nuse std::cmp::PartialEq;\nuse std::cmp::{max, min};\nuse std::collections::{BTreeMap, BTreeSet, HashMap, HashSet};\nuse std::fmt;\nuse std::fmt::Write;\nuse std::rc::Rc;\nuse std::task::Poll;\nuse std::time::Instant;\n\nuse cargo::core::dependency::DepKind;\nuse cargo::core::resolver::{self, ResolveOpts, VersionPreferences};\nuse cargo::core::source::{GitReference, QueryKind, SourceId};\nuse cargo::core::Resolve;\nuse cargo::core::{Dependency, PackageId, Registry, Summary};\nuse cargo::util::{CargoResult, Config, Graph, IntoUrl};\n\nuse proptest::collection::{btree_map, vec};\nuse proptest::prelude::*;\nuse proptest::sample::Index;\nuse proptest::string::string_regex;\nuse varisat::{self, ExtendFormula};\n\npub fn resolve(deps: Vec<Dependency>, registry: &[Summary]) -> CargoResult<Vec<PackageId>> {\n    resolve_with_config(deps, registry, &Config::default().unwrap())\n}\n\npub fn resolve_and_validated(\n    deps: Vec<Dependency>,\n    registry: &[Summary],\n    sat_resolve: Option<SatResolve>,\n) -> CargoResult<Vec<PackageId>> {\n    let resolve = resolve_with_config_raw(deps.clone(), registry, &Config::default().unwrap());\n\n    match resolve {\n        Err(e) => {\n            let sat_resolve = sat_resolve.unwrap_or_else(|| SatResolve::new(registry));\n            if sat_resolve.sat_resolve(&deps) {\n                panic!(\n                    \"the resolve err but the sat_resolve thinks this will work:\\n{}\",\n                    sat_resolve.use_packages().unwrap()\n                );\n            }\n            Err(e)\n        }\n        Ok(resolve) => {\n            let mut stack = vec![pkg_id(\"root\")];\n            let mut used = HashSet::new();\n            let mut links = HashSet::new();\n            while let Some(p) = stack.pop() {\n                assert!(resolve.contains(&p));\n                if used.insert(p) {\n                    // in the tests all `links` crates end in `-sys`\n                    if p.name().ends_with(\"-sys\") {\n                        assert!(links.insert(p.name()));\n                    }\n                    stack.extend(resolve.deps(p).map(|(dp, deps)| {\n                        for d in deps {\n                            assert!(d.matches_id(dp));\n                        }\n                        dp\n                    }));\n                }\n            }\n            let out = resolve.sort();\n            assert_eq!(out.len(), used.len());\n\n            let mut pub_deps: HashMap<PackageId, HashSet<_>> = HashMap::new();\n            for &p in out.iter() {\n                // make the list of `p` public dependencies\n                let mut self_pub_dep = HashSet::new();\n                self_pub_dep.insert(p);\n                for (dp, deps) in resolve.deps(p) {\n                    if deps.iter().any(|d| d.is_public()) {\n                        self_pub_dep.extend(pub_deps[&dp].iter().cloned())\n                    }\n                }\n                pub_deps.insert(p, self_pub_dep);\n\n                // check if `p` has a public dependencies conflicts\n                let seen_dep: BTreeSet<_> = resolve\n                    .deps(p)\n                    .flat_map(|(dp, _)| pub_deps[&dp].iter().cloned())\n                    .collect();\n                let seen_dep: Vec<_> = seen_dep.iter().collect();\n                for a in seen_dep.windows(2) {\n                    if a[0].name() == a[1].name() {\n                        panic!(\n                            \"the package {:?} can publicly see {:?} and {:?}\",\n                            p, a[0], a[1]\n                        )\n                    }\n                }\n            }\n            let sat_resolve = sat_resolve.unwrap_or_else(|| SatResolve::new(registry));\n            if !sat_resolve.sat_is_valid_solution(&out) {\n                panic!(\n                    \"the sat_resolve err but the resolve thinks this will work:\\n{:?}\",\n                    resolve\n                );\n            }\n            Ok(out)\n        }\n    }\n}\n\npub fn resolve_with_config(\n    deps: Vec<Dependency>,\n    registry: &[Summary],\n    config: &Config,\n) -> CargoResult<Vec<PackageId>> {\n    let resolve = resolve_with_config_raw(deps, registry, config)?;\n    Ok(resolve.sort())\n}\n\npub fn resolve_with_config_raw(\n    deps: Vec<Dependency>,\n    registry: &[Summary],\n    config: &Config,\n) -> CargoResult<Resolve> {\n    struct MyRegistry<'a> {\n        list: &'a [Summary],\n        used: HashSet<PackageId>,\n    }\n    impl<'a> Registry for MyRegistry<'a> {\n        fn query(\n            &mut self,\n            dep: &Dependency,\n            kind: QueryKind,\n            f: &mut dyn FnMut(Summary),\n        ) -> Poll<CargoResult<()>> {\n            for summary in self.list.iter() {\n                let matched = match kind {\n                    QueryKind::Exact => dep.matches(summary),\n                    QueryKind::Fuzzy => true,\n                };\n                if matched {\n                    self.used.insert(summary.package_id());\n                    f(summary.clone());\n                }\n            }\n            Poll::Ready(Ok(()))\n        }\n\n        fn describe_source(&self, _src: SourceId) -> String {\n            String::new()\n        }\n\n        fn is_replaced(&self, _src: SourceId) -> bool {\n            false\n        }\n\n        fn block_until_ready(&mut self) -> CargoResult<()> {\n            Ok(())\n        }\n    }\n    impl<'a> Drop for MyRegistry<'a> {\n        fn drop(&mut self) {\n            if std::thread::panicking() && self.list.len() != self.used.len() {\n                // we found a case that causes a panic and did not use all of the input.\n                // lets print the part of the input that was used for minimization.\n                println!(\n                    \"{:?}\",\n                    PrettyPrintRegistry(\n                        self.list\n                            .iter()\n                            .filter(|s| { self.used.contains(&s.package_id()) })\n                            .cloned()\n                            .collect()\n                    )\n                );\n            }\n        }\n    }\n    let mut registry = MyRegistry {\n        list: registry,\n        used: HashSet::new(),\n    };\n    let summary = Summary::new(\n        config,\n        pkg_id(\"root\"),\n        deps,\n        &BTreeMap::new(),\n        None::<&String>,\n        None::<&String>,\n    )\n    .unwrap();\n    let opts = ResolveOpts::everything();\n    let start = Instant::now();\n    let resolve = resolver::resolve(\n        &[(summary, opts)],\n        &[],\n        &mut registry,\n        &VersionPreferences::default(),\n        Some(config),\n        true,\n    );\n\n    // The largest test in our suite takes less then 30 sec.\n    // So lets fail the test if we have ben running for two long.\n    assert!(start.elapsed().as_secs() < 60);\n    resolve\n}\n\nconst fn num_bits<T>() -> usize {\n    std::mem::size_of::<T>() * 8\n}\n\nfn log_bits(x: usize) -> usize {\n    if x == 0 {\n        return 0;\n    }\n    assert!(x > 0);\n    (num_bits::<usize>() as u32 - x.leading_zeros()) as usize\n}\n\nfn sat_at_most_one(solver: &mut impl varisat::ExtendFormula, vars: &[varisat::Var]) {\n    if vars.len() <= 1 {\n        return;\n    } else if vars.len() == 2 {\n        solver.add_clause(&[vars[0].negative(), vars[1].negative()]);\n        return;\n    } else if vars.len() == 3 {\n        solver.add_clause(&[vars[0].negative(), vars[1].negative()]);\n        solver.add_clause(&[vars[0].negative(), vars[2].negative()]);\n        solver.add_clause(&[vars[1].negative(), vars[2].negative()]);\n        return;\n    }\n    // use the \"Binary Encoding\" from\n    // https://www.it.uu.se/research/group/astra/ModRef10/papers/Alan%20M.%20Frisch%20and%20Paul%20A.%20Giannoros.%20SAT%20Encodings%20of%20the%20At-Most-k%20Constraint%20-%20ModRef%202010.pdf\n    let bits: Vec<varisat::Var> = solver.new_var_iter(log_bits(vars.len())).collect();\n    for (i, p) in vars.iter().enumerate() {\n        for b in 0..bits.len() {\n            solver.add_clause(&[p.negative(), bits[b].lit(((1 << b) & i) > 0)]);\n        }\n    }\n}\n\nfn sat_at_most_one_by_key<K: std::hash::Hash + Eq>(\n    cnf: &mut impl varisat::ExtendFormula,\n    data: impl Iterator<Item = (K, varisat::Var)>,\n) -> HashMap<K, Vec<varisat::Var>> {\n    // no two packages with the same links set\n    let mut by_keys: HashMap<K, Vec<varisat::Var>> = HashMap::new();\n    for (p, v) in data {\n        by_keys.entry(p).or_default().push(v)\n    }\n    for key in by_keys.values() {\n        sat_at_most_one(cnf, key);\n    }\n    by_keys\n}\n\n/// Resolution can be reduced to the SAT problem. So this is an alternative implementation\n/// of the resolver that uses a SAT library for the hard work. This is intended to be easy to read,\n/// as compared to the real resolver.\n///\n/// For the subset of functionality that are currently made by `registry_strategy` this will,\n/// find a valid resolution if one exists. The big thing that the real resolver does,\n/// that this one does not do is work with features and optional dependencies.\n///\n/// The SAT library dose not optimize for the newer version,\n/// so the selected packages may not match the real resolver.\n#[derive(Clone)]\npub struct SatResolve(Rc<RefCell<SatResolveInner>>);\nstruct SatResolveInner {\n    solver: varisat::Solver<'static>,\n    var_for_is_packages_used: HashMap<PackageId, varisat::Var>,\n    by_name: HashMap<&'static str, Vec<PackageId>>,\n}\n\nimpl SatResolve {\n    pub fn new(registry: &[Summary]) -> Self {\n        let mut cnf = varisat::CnfFormula::new();\n        let var_for_is_packages_used: HashMap<PackageId, varisat::Var> = registry\n            .iter()\n            .map(|s| (s.package_id(), cnf.new_var()))\n            .collect();\n\n        // no two packages with the same links set\n        sat_at_most_one_by_key(\n            &mut cnf,\n            registry\n                .iter()\n                .map(|s| (s.links(), var_for_is_packages_used[&s.package_id()]))\n                .filter(|(l, _)| l.is_some()),\n        );\n\n        // no two semver compatible versions of the same package\n        let by_activations_keys = sat_at_most_one_by_key(\n            &mut cnf,\n            var_for_is_packages_used\n                .iter()\n                .map(|(p, &v)| (p.as_activations_key(), v)),\n        );\n\n        let mut by_name: HashMap<&'static str, Vec<PackageId>> = HashMap::new();\n\n        for p in registry.iter() {\n            by_name\n                .entry(p.name().as_str())\n                .or_default()\n                .push(p.package_id())\n        }\n\n        let empty_vec = vec![];\n\n        let mut graph: Graph<PackageId, ()> = Graph::new();\n\n        let mut version_selected_for: HashMap<\n            PackageId,\n            HashMap<Dependency, HashMap<_, varisat::Var>>,\n        > = HashMap::new();\n        // active packages need each of there `deps` to be satisfied\n        for p in registry.iter() {\n            graph.add(p.package_id());\n            for dep in p.dependencies() {\n                // This can more easily be written as:\n                // !is_active(p) or one of the things that match dep is_active\n                // All the complexity, from here to the end, is to support public and private dependencies!\n                let mut by_key: HashMap<_, Vec<varisat::Lit>> = HashMap::new();\n                for &m in by_name\n                    .get(dep.package_name().as_str())\n                    .unwrap_or(&empty_vec)\n                    .iter()\n                    .filter(|&p| dep.matches_id(*p))\n                {\n                    graph.link(p.package_id(), m);\n                    by_key\n                        .entry(m.as_activations_key())\n                        .or_default()\n                        .push(var_for_is_packages_used[&m].positive());\n                }\n                let keys: HashMap<_, _> = by_key.keys().map(|&k| (k, cnf.new_var())).collect();\n\n                // if `p` is active then we need to select one of the keys\n                let matches: Vec<_> = keys\n                    .values()\n                    .map(|v| v.positive())\n                    .chain(Some(var_for_is_packages_used[&p.package_id()].negative()))\n                    .collect();\n                cnf.add_clause(&matches);\n\n                // if a key is active then we need to select one of the versions\n                for (key, vars) in by_key.iter() {\n                    let mut matches = vars.clone();\n                    matches.push(keys[key].negative());\n                    cnf.add_clause(&matches);\n                }\n\n                version_selected_for\n                    .entry(p.package_id())\n                    .or_default()\n                    .insert(dep.clone(), keys);\n            }\n        }\n\n        let topological_order = graph.sort();\n\n        // we already ensure there is only one version for each `activations_key` so we can think of\n        // `publicly_exports` as being in terms of a set of `activations_key`s\n        let mut publicly_exports: HashMap<_, HashMap<_, varisat::Var>> = HashMap::new();\n\n        for &key in by_activations_keys.keys() {\n            // everything publicly depends on itself\n            let var = publicly_exports\n                .entry(key)\n                .or_default()\n                .entry(key)\n                .or_insert_with(|| cnf.new_var());\n            cnf.add_clause(&[var.positive()]);\n        }\n\n        // if a `dep` is public then `p` `publicly_exports` all the things that the selected version `publicly_exports`\n        for &p in topological_order.iter() {\n            if let Some(deps) = version_selected_for.get(&p) {\n                let mut p_exports = publicly_exports.remove(&p.as_activations_key()).unwrap();\n                for (_, versions) in deps.iter().filter(|(d, _)| d.is_public()) {\n                    for (ver, sel) in versions {\n                        for (&export_pid, &export_var) in publicly_exports[ver].iter() {\n                            let our_var =\n                                p_exports.entry(export_pid).or_insert_with(|| cnf.new_var());\n                            cnf.add_clause(&[\n                                sel.negative(),\n                                export_var.negative(),\n                                our_var.positive(),\n                            ]);\n                        }\n                    }\n                }\n                publicly_exports.insert(p.as_activations_key(), p_exports);\n            }\n        }\n\n        // we already ensure there is only one version for each `activations_key` so we can think of\n        // `can_see` as being in terms of a set of `activations_key`s\n        // and if `p` `publicly_exports` `export` then it `can_see` `export`\n        let mut can_see: HashMap<_, HashMap<_, varisat::Var>> = HashMap::new();\n\n        // if `p` has a `dep` that selected `ver` then it `can_see` all the things that the selected version `publicly_exports`\n        for (&p, deps) in version_selected_for.iter() {\n            let p_can_see = can_see.entry(p).or_default();\n            for (_, versions) in deps.iter() {\n                for (&ver, sel) in versions {\n                    for (&export_pid, &export_var) in publicly_exports[&ver].iter() {\n                        let our_var = p_can_see.entry(export_pid).or_insert_with(|| cnf.new_var());\n                        cnf.add_clause(&[\n                            sel.negative(),\n                            export_var.negative(),\n                            our_var.positive(),\n                        ]);\n                    }\n                }\n            }\n        }\n\n        // a package `can_see` only one version by each name\n        for (_, see) in can_see.iter() {\n            sat_at_most_one_by_key(&mut cnf, see.iter().map(|((name, _, _), &v)| (name, v)));\n        }\n        let mut solver = varisat::Solver::new();\n        solver.add_formula(&cnf);\n\n        // We dont need to `solve` now. We know that \"use nothing\" will satisfy all the clauses so far.\n        // But things run faster if we let it spend some time figuring out how the constraints interact before we add assumptions.\n        solver\n            .solve()\n            .expect(\"docs say it can't error in default config\");\n        SatResolve(Rc::new(RefCell::new(SatResolveInner {\n            solver,\n            var_for_is_packages_used,\n            by_name,\n        })))\n    }\n    pub fn sat_resolve(&self, deps: &[Dependency]) -> bool {\n        let mut s = self.0.borrow_mut();\n        let mut assumption = vec![];\n        let mut this_call = None;\n\n        // the starting `deps` need to be satisfied\n        for dep in deps.iter() {\n            let empty_vec = vec![];\n            let matches: Vec<varisat::Lit> = s\n                .by_name\n                .get(dep.package_name().as_str())\n                .unwrap_or(&empty_vec)\n                .iter()\n                .filter(|&p| dep.matches_id(*p))\n                .map(|p| s.var_for_is_packages_used[p].positive())\n                .collect();\n            if matches.is_empty() {\n                return false;\n            } else if matches.len() == 1 {\n                assumption.extend_from_slice(&matches)\n            } else {\n                if this_call.is_none() {\n                    let new_var = s.solver.new_var();\n                    this_call = Some(new_var);\n                    assumption.push(new_var.positive());\n                }\n                let mut matches = matches;\n                matches.push(this_call.unwrap().negative());\n                s.solver.add_clause(&matches);\n            }\n        }\n\n        s.solver.assume(&assumption);\n\n        s.solver\n            .solve()\n            .expect(\"docs say it can't error in default config\")\n    }\n    pub fn sat_is_valid_solution(&self, pids: &[PackageId]) -> bool {\n        let mut s = self.0.borrow_mut();\n        for p in pids {\n            if p.name().as_str() != \"root\" && !s.var_for_is_packages_used.contains_key(p) {\n                return false;\n            }\n        }\n        let assumption: Vec<_> = s\n            .var_for_is_packages_used\n            .iter()\n            .map(|(p, v)| v.lit(pids.contains(p)))\n            .collect();\n\n        s.solver.assume(&assumption);\n\n        s.solver\n            .solve()\n            .expect(\"docs say it can't error in default config\")\n    }\n    fn use_packages(&self) -> Option<String> {\n        self.0.borrow().solver.model().map(|lits| {\n            let lits: HashSet<_> = lits\n                .iter()\n                .filter(|l| l.is_positive())\n                .map(|l| l.var())\n                .collect();\n            let mut out = String::new();\n            out.push_str(\"used:\\n\");\n            for (p, v) in self.0.borrow().var_for_is_packages_used.iter() {\n                if lits.contains(v) {\n                    writeln!(&mut out, \"    {}\", p).unwrap();\n                }\n            }\n            out\n        })\n    }\n}\n\npub trait ToDep {\n    fn to_dep(self) -> Dependency;\n}\n\nimpl ToDep for &'static str {\n    fn to_dep(self) -> Dependency {\n        Dependency::parse(self, Some(\"1.0.0\"), registry_loc()).unwrap()\n    }\n}\n\nimpl ToDep for Dependency {\n    fn to_dep(self) -> Dependency {\n        self\n    }\n}\n\npub trait ToPkgId {\n    fn to_pkgid(&self) -> PackageId;\n}\n\nimpl ToPkgId for PackageId {\n    fn to_pkgid(&self) -> PackageId {\n        *self\n    }\n}\n\nimpl<'a> ToPkgId for &'a str {\n    fn to_pkgid(&self) -> PackageId {\n        PackageId::new(*self, \"1.0.0\", registry_loc()).unwrap()\n    }\n}\n\nimpl<T: AsRef<str>, U: AsRef<str>> ToPkgId for (T, U) {\n    fn to_pkgid(&self) -> PackageId {\n        let (name, vers) = self;\n        PackageId::new(name.as_ref(), vers.as_ref(), registry_loc()).unwrap()\n    }\n}\n\n#[macro_export]\nmacro_rules! pkg {\n    ($pkgid:expr => [$($deps:expr),+ $(,)* ]) => ({\n        let d: Vec<Dependency> = vec![$($deps.to_dep()),+];\n        $crate::pkg_dep($pkgid, d)\n    });\n\n    ($pkgid:expr) => ({\n        $crate::pkg($pkgid)\n    })\n}\n\nfn registry_loc() -> SourceId {\n    lazy_static::lazy_static! {\n        static ref EXAMPLE_DOT_COM: SourceId =\n            SourceId::for_registry(&\"https://example.com\".into_url().unwrap()).unwrap();\n    }\n    *EXAMPLE_DOT_COM\n}\n\npub fn pkg<T: ToPkgId>(name: T) -> Summary {\n    pkg_dep(name, Vec::new())\n}\n\npub fn pkg_dep<T: ToPkgId>(name: T, dep: Vec<Dependency>) -> Summary {\n    let pkgid = name.to_pkgid();\n    let link = if pkgid.name().ends_with(\"-sys\") {\n        Some(pkgid.name().as_str())\n    } else {\n        None\n    };\n    Summary::new(\n        &Config::default().unwrap(),\n        name.to_pkgid(),\n        dep,\n        &BTreeMap::new(),\n        link,\n        None::<&String>,\n    )\n    .unwrap()\n}\n\npub fn pkg_id(name: &str) -> PackageId {\n    PackageId::new(name, \"1.0.0\", registry_loc()).unwrap()\n}\n\nfn pkg_id_loc(name: &str, loc: &str) -> PackageId {\n    let remote = loc.into_url();\n    let master = GitReference::Branch(\"master\".to_string());\n    let source_id = SourceId::for_git(&remote.unwrap(), master).unwrap();\n\n    PackageId::new(name, \"1.0.0\", source_id).unwrap()\n}\n\npub fn pkg_loc(name: &str, loc: &str) -> Summary {\n    let link = if name.ends_with(\"-sys\") {\n        Some(name)\n    } else {\n        None\n    };\n    Summary::new(\n        &Config::default().unwrap(),\n        pkg_id_loc(name, loc),\n        Vec::new(),\n        &BTreeMap::new(),\n        link,\n        None::<&String>,\n    )\n    .unwrap()\n}\n\npub fn remove_dep(sum: &Summary, ind: usize) -> Summary {\n    let mut deps = sum.dependencies().to_vec();\n    deps.remove(ind);\n    // note: more things will need to be copied over in the future, but it works for now.\n    Summary::new(\n        &Config::default().unwrap(),\n        sum.package_id(),\n        deps,\n        &BTreeMap::new(),\n        sum.links().map(|a| a.as_str()),\n        None::<&String>,\n    )\n    .unwrap()\n}\n\npub fn dep(name: &str) -> Dependency {\n    dep_req(name, \"*\")\n}\npub fn dep_req(name: &str, req: &str) -> Dependency {\n    Dependency::parse(name, Some(req), registry_loc()).unwrap()\n}\npub fn dep_req_kind(name: &str, req: &str, kind: DepKind, public: bool) -> Dependency {\n    let mut dep = dep_req(name, req);\n    dep.set_kind(kind);\n    dep.set_public(public);\n    dep\n}\n\npub fn dep_loc(name: &str, location: &str) -> Dependency {\n    let url = location.into_url().unwrap();\n    let master = GitReference::Branch(\"master\".to_string());\n    let source_id = SourceId::for_git(&url, master).unwrap();\n    Dependency::parse(name, Some(\"1.0.0\"), source_id).unwrap()\n}\npub fn dep_kind(name: &str, kind: DepKind) -> Dependency {\n    dep(name).set_kind(kind).clone()\n}\n\npub fn registry(pkgs: Vec<Summary>) -> Vec<Summary> {\n    pkgs\n}\n\npub fn names<P: ToPkgId>(names: &[P]) -> Vec<PackageId> {\n    names.iter().map(|name| name.to_pkgid()).collect()\n}\n\npub fn loc_names(names: &[(&'static str, &'static str)]) -> Vec<PackageId> {\n    names\n        .iter()\n        .map(|&(name, loc)| pkg_id_loc(name, loc))\n        .collect()\n}\n\n/// By default `Summary` and `Dependency` have a very verbose `Debug` representation.\n/// This replaces with a representation that uses constructors from this file.\n///\n/// If `registry_strategy` is improved to modify more fields\n/// then this needs to update to display the corresponding constructor.\npub struct PrettyPrintRegistry(pub Vec<Summary>);\n\nimpl fmt::Debug for PrettyPrintRegistry {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"vec![\")?;\n        for s in &self.0 {\n            if s.dependencies().is_empty() {\n                write!(f, \"pkg!((\\\"{}\\\", \\\"{}\\\")),\", s.name(), s.version())?;\n            } else {\n                write!(f, \"pkg!((\\\"{}\\\", \\\"{}\\\") => [\", s.name(), s.version())?;\n                for d in s.dependencies() {\n                    if d.kind() == DepKind::Normal\n                        && &d.version_req().to_string() == \"*\"\n                        && !d.is_public()\n                    {\n                        write!(f, \"dep(\\\"{}\\\"),\", d.name_in_toml())?;\n                    } else if d.kind() == DepKind::Normal && !d.is_public() {\n                        write!(\n                            f,\n                            \"dep_req(\\\"{}\\\", \\\"{}\\\"),\",\n                            d.name_in_toml(),\n                            d.version_req()\n                        )?;\n                    } else {\n                        write!(\n                            f,\n                            \"dep_req_kind(\\\"{}\\\", \\\"{}\\\", {}, {}),\",\n                            d.name_in_toml(),\n                            d.version_req(),\n                            match d.kind() {\n                                DepKind::Development => \"DepKind::Development\",\n                                DepKind::Build => \"DepKind::Build\",\n                                DepKind::Normal => \"DepKind::Normal\",\n                            },\n                            d.is_public()\n                        )?;\n                    }\n                }\n                write!(f, \"]),\")?;\n            }\n        }\n        write!(f, \"]\")\n    }\n}\n\n#[test]\nfn meta_test_deep_pretty_print_registry() {\n    assert_eq!(\n        &format!(\n            \"{:?}\",\n            PrettyPrintRegistry(vec![\n                pkg!((\"foo\", \"1.0.1\") => [dep_req(\"bar\", \"1\")]),\n                pkg!((\"foo\", \"1.0.0\") => [dep_req(\"bar\", \"2\")]),\n                pkg!((\"foo\", \"2.0.0\") => [dep_req(\"bar\", \"*\")]),\n                pkg!((\"bar\", \"1.0.0\") => [dep_req(\"baz\", \"=1.0.2\"),\n                                  dep_req(\"other\", \"1\")]),\n                pkg!((\"bar\", \"2.0.0\") => [dep_req(\"baz\", \"=1.0.1\")]),\n                pkg!((\"baz\", \"1.0.2\") => [dep_req(\"other\", \"2\")]),\n                pkg!((\"baz\", \"1.0.1\")),\n                pkg!((\"cat\", \"1.0.2\") => [dep_req_kind(\"other\", \"2\", DepKind::Build, false)]),\n                pkg!((\"cat\", \"1.0.3\") => [dep_req_kind(\"other\", \"2\", DepKind::Development, false)]),\n                pkg!((\"dep_req\", \"1.0.0\")),\n                pkg!((\"dep_req\", \"2.0.0\")),\n            ])\n        ),\n        \"vec![pkg!((\\\"foo\\\", \\\"1.0.1\\\") => [dep_req(\\\"bar\\\", \\\"^1\\\"),]),\\\n         pkg!((\\\"foo\\\", \\\"1.0.0\\\") => [dep_req(\\\"bar\\\", \\\"^2\\\"),]),\\\n         pkg!((\\\"foo\\\", \\\"2.0.0\\\") => [dep(\\\"bar\\\"),]),\\\n         pkg!((\\\"bar\\\", \\\"1.0.0\\\") => [dep_req(\\\"baz\\\", \\\"=1.0.2\\\"),dep_req(\\\"other\\\", \\\"^1\\\"),]),\\\n         pkg!((\\\"bar\\\", \\\"2.0.0\\\") => [dep_req(\\\"baz\\\", \\\"=1.0.1\\\"),]),\\\n         pkg!((\\\"baz\\\", \\\"1.0.2\\\") => [dep_req(\\\"other\\\", \\\"^2\\\"),]),\\\n         pkg!((\\\"baz\\\", \\\"1.0.1\\\")),\\\n         pkg!((\\\"cat\\\", \\\"1.0.2\\\") => [dep_req_kind(\\\"other\\\", \\\"^2\\\", DepKind::Build, false),]),\\\n         pkg!((\\\"cat\\\", \\\"1.0.3\\\") => [dep_req_kind(\\\"other\\\", \\\"^2\\\", DepKind::Development, false),]),\\\n         pkg!((\\\"dep_req\\\", \\\"1.0.0\\\")),\\\n         pkg!((\\\"dep_req\\\", \\\"2.0.0\\\")),]\"\n    )\n}\n\n/// This generates a random registry index.\n/// Unlike vec((Name, Ver, vec((Name, VerRq), ..), ..)\n/// This strategy has a high probability of having valid dependencies\npub fn registry_strategy(\n    max_crates: usize,\n    max_versions: usize,\n    shrinkage: usize,\n) -> impl Strategy<Value = PrettyPrintRegistry> {\n    let name = string_regex(\"[A-Za-z][A-Za-z0-9_-]*(-sys)?\").unwrap();\n\n    let raw_version = ..max_versions.pow(3);\n    let version_from_raw = move |r: usize| {\n        let major = ((r / max_versions) / max_versions) % max_versions;\n        let minor = (r / max_versions) % max_versions;\n        let patch = r % max_versions;\n        format!(\"{}.{}.{}\", major, minor, patch)\n    };\n\n    // If this is false then the crate will depend on the nonexistent \"bad\"\n    // instead of the complex set we generated for it.\n    let allow_deps = prop::bool::weighted(0.99);\n\n    let list_of_versions =\n        btree_map(raw_version, allow_deps, 1..=max_versions).prop_map(move |ver| {\n            ver.into_iter()\n                .map(|a| (version_from_raw(a.0), a.1))\n                .collect::<Vec<_>>()\n        });\n\n    let list_of_crates_with_versions =\n        btree_map(name, list_of_versions, 1..=max_crates).prop_map(|mut vers| {\n            // root is the name of the thing being compiled\n            // so it would be confusing to have it in the index\n            vers.remove(\"root\");\n            // bad is a name reserved for a dep that won't work\n            vers.remove(\"bad\");\n            vers\n        });\n\n    // each version of each crate can depend on each crate smaller then it.\n    // In theory shrinkage should be 2, but in practice we get better trees with a larger value.\n    let max_deps = max_versions * (max_crates * (max_crates - 1)) / shrinkage;\n\n    let raw_version_range = (any::<Index>(), any::<Index>());\n    let raw_dependency = (\n        any::<Index>(),\n        any::<Index>(),\n        raw_version_range,\n        0..=1,\n        Just(false),\n        // TODO: ^ this needs to be set back to `any::<bool>()` and work before public & private dependencies can stabilize\n    );\n\n    fn order_index(a: Index, b: Index, size: usize) -> (usize, usize) {\n        let (a, b) = (a.index(size), b.index(size));\n        (min(a, b), max(a, b))\n    }\n\n    let list_of_raw_dependency = vec(raw_dependency, ..=max_deps);\n\n    // By default a package depends only on other packages that have a smaller name,\n    // this helps make sure that all things in the resulting index are DAGs.\n    // If this is true then the DAG is maintained with grater instead.\n    let reverse_alphabetical = any::<bool>().no_shrink();\n\n    (\n        list_of_crates_with_versions,\n        list_of_raw_dependency,\n        reverse_alphabetical,\n    )\n        .prop_map(\n            |(crate_vers_by_name, raw_dependencies, reverse_alphabetical)| {\n                let list_of_pkgid: Vec<_> = crate_vers_by_name\n                    .iter()\n                    .flat_map(|(name, vers)| vers.iter().map(move |x| ((name.as_str(), &x.0), x.1)))\n                    .collect();\n                let len_all_pkgid = list_of_pkgid.len();\n                let mut dependency_by_pkgid = vec![vec![]; len_all_pkgid];\n                for (a, b, (c, d), k, p) in raw_dependencies {\n                    let (a, b) = order_index(a, b, len_all_pkgid);\n                    let (a, b) = if reverse_alphabetical { (b, a) } else { (a, b) };\n                    let ((dep_name, _), _) = list_of_pkgid[a];\n                    if (list_of_pkgid[b].0).0 == dep_name {\n                        continue;\n                    }\n                    let s = &crate_vers_by_name[dep_name];\n                    let s_last_index = s.len() - 1;\n                    let (c, d) = order_index(c, d, s.len());\n\n                    dependency_by_pkgid[b].push(dep_req_kind(\n                        dep_name,\n                        &if c == 0 && d == s_last_index {\n                            \"*\".to_string()\n                        } else if c == 0 {\n                            format!(\"<={}\", s[d].0)\n                        } else if d == s_last_index {\n                            format!(\">={}\", s[c].0)\n                        } else if c == d {\n                            format!(\"={}\", s[c].0)\n                        } else {\n                            format!(\">={}, <={}\", s[c].0, s[d].0)\n                        },\n                        match k {\n                            0 => DepKind::Normal,\n                            1 => DepKind::Build,\n                            // => DepKind::Development, // Development has no impact so don't gen\n                            _ => panic!(\"bad index for DepKind\"),\n                        },\n                        p && k == 0,\n                    ))\n                }\n\n                let mut out: Vec<Summary> = list_of_pkgid\n                    .into_iter()\n                    .zip(dependency_by_pkgid.into_iter())\n                    .map(|(((name, ver), allow_deps), deps)| {\n                        pkg_dep(\n                            (name, ver).to_pkgid(),\n                            if !allow_deps {\n                                vec![dep_req(\"bad\", \"*\")]\n                            } else {\n                                let mut deps = deps;\n                                deps.sort_by_key(|d| d.name_in_toml());\n                                deps.dedup_by_key(|d| d.name_in_toml());\n                                deps\n                            },\n                        )\n                    })\n                    .collect();\n\n                if reverse_alphabetical {\n                    // make sure the complicated cases are at the end\n                    out.reverse();\n                }\n\n                PrettyPrintRegistry(out)\n            },\n        )\n}\n\n/// This test is to test the generator to ensure\n/// that it makes registries with large dependency trees\n#[test]\nfn meta_test_deep_trees_from_strategy() {\n    use proptest::strategy::ValueTree;\n    use proptest::test_runner::TestRunner;\n\n    let mut dis = [0; 21];\n\n    let strategy = registry_strategy(50, 20, 60);\n    let mut test_runner = TestRunner::deterministic();\n    for _ in 0..128 {\n        let PrettyPrintRegistry(input) = strategy\n            .new_tree(&mut TestRunner::new_with_rng(\n                Default::default(),\n                test_runner.new_rng(),\n            ))\n            .unwrap()\n            .current();\n        let reg = registry(input.clone());\n        for this in input.iter().rev().take(10) {\n            let res = resolve(\n                vec![dep_req(&this.name(), &format!(\"={}\", this.version()))],\n                &reg,\n            );\n            dis[res\n                .as_ref()\n                .map(|x| min(x.len(), dis.len()) - 1)\n                .unwrap_or(0)] += 1;\n            if dis.iter().all(|&x| x > 0) {\n                return;\n            }\n        }\n    }\n\n    panic!(\n        \"In 1280 tries we did not see a wide enough distribution of dependency trees! dis: {:?}\",\n        dis\n    );\n}\n\n/// This test is to test the generator to ensure\n/// that it makes registries that include multiple versions of the same library\n#[test]\nfn meta_test_multiple_versions_strategy() {\n    use proptest::strategy::ValueTree;\n    use proptest::test_runner::TestRunner;\n\n    let mut dis = [0; 10];\n\n    let strategy = registry_strategy(50, 20, 60);\n    let mut test_runner = TestRunner::deterministic();\n    for _ in 0..128 {\n        let PrettyPrintRegistry(input) = strategy\n            .new_tree(&mut TestRunner::new_with_rng(\n                Default::default(),\n                test_runner.new_rng(),\n            ))\n            .unwrap()\n            .current();\n        let reg = registry(input.clone());\n        for this in input.iter().rev().take(10) {\n            let res = resolve(\n                vec![dep_req(&this.name(), &format!(\"={}\", this.version()))],\n                &reg,\n            );\n            if let Ok(mut res) = res {\n                let res_len = res.len();\n                res.sort_by_key(|s| s.name());\n                res.dedup_by_key(|s| s.name());\n                dis[min(res_len - res.len(), dis.len() - 1)] += 1;\n            }\n            if dis.iter().all(|&x| x > 0) {\n                return;\n            }\n        }\n    }\n    panic!(\n        \"In 1280 tries we did not see a wide enough distribution of multiple versions of the same library! dis: {:?}\",\n        dis\n    );\n}\n\n/// Assert `xs` contains `elems`\n#[track_caller]\npub fn assert_contains<A: PartialEq>(xs: &[A], elems: &[A]) {\n    for elem in elems {\n        assert!(xs.contains(elem));\n    }\n}\n\n#[track_caller]\npub fn assert_same<A: PartialEq>(a: &[A], b: &[A]) {\n    assert_eq!(a.len(), b.len());\n    assert_contains(b, a);\n}\n", "//! This module implements support for preferring some versions of a package\n//! over other versions.\n\nuse std::cmp::Ordering;\nuse std::collections::{HashMap, HashSet};\n\nuse crate::core::{Dependency, PackageId, Summary};\nuse crate::util::interning::InternedString;\n\n/// A collection of preferences for particular package versions.\n///\n/// This is built up with [`Self::prefer_package_id`] and [`Self::prefer_dependency`], then used to sort the set of\n/// summaries for a package during resolution via [`Self::sort_summaries`].\n///\n/// As written, a version is either \"preferred\" or \"not preferred\".  Later extensions may\n/// introduce more granular preferences.\n#[derive(Default)]\npub struct VersionPreferences {\n    try_to_use: HashSet<PackageId>,\n    prefer_patch_deps: HashMap<InternedString, HashSet<Dependency>>,\n}\n\npub enum VersionOrdering {\n    MaximumVersionsFirst,\n    MinimumVersionsFirst,\n}\n\nimpl VersionPreferences {\n    /// Indicate that the given package (specified as a [`PackageId`]) should be preferred.\n    pub fn prefer_package_id(&mut self, pkg_id: PackageId) {\n        self.try_to_use.insert(pkg_id);\n    }\n\n    /// Indicate that the given package (specified as a [`Dependency`])  should be preferred.\n    pub fn prefer_dependency(&mut self, dep: Dependency) {\n        self.prefer_patch_deps\n            .entry(dep.package_name())\n            .or_insert_with(HashSet::new)\n            .insert(dep);\n    }\n\n    /// Sort the given vector of summaries in-place, with all summaries presumed to be for\n    /// the same package.  Preferred versions appear first in the result, sorted by\n    /// `version_ordering`, followed by non-preferred versions sorted the same way.\n    pub fn sort_summaries(\n        &self,\n        summaries: &mut Vec<Summary>,\n        version_ordering: VersionOrdering,\n        first_version: bool,\n    ) {\n        let should_prefer = |pkg_id: &PackageId| {\n            self.try_to_use.contains(pkg_id)\n                || self\n                    .prefer_patch_deps\n                    .get(&pkg_id.name())\n                    .map(|deps| deps.iter().any(|d| d.matches_id(*pkg_id)))\n                    .unwrap_or(false)\n        };\n        summaries.sort_unstable_by(|a, b| {\n            let prefer_a = should_prefer(&a.package_id());\n            let prefer_b = should_prefer(&b.package_id());\n            let previous_cmp = prefer_a.cmp(&prefer_b).reverse();\n            match previous_cmp {\n                Ordering::Equal => {\n                    let cmp = a.version().cmp(b.version());\n                    match version_ordering {\n                        VersionOrdering::MaximumVersionsFirst => cmp.reverse(),\n                        VersionOrdering::MinimumVersionsFirst => cmp,\n                    }\n                }\n                _ => previous_cmp,\n            }\n        });\n        if first_version {\n            let _ = summaries.split_off(1);\n        }\n    }\n}\n\n#[cfg(test)]\nmod test {\n    use super::*;\n    use crate::core::SourceId;\n    use crate::util::Config;\n    use std::collections::BTreeMap;\n\n    fn pkgid(name: &str, version: &str) -> PackageId {\n        let src_id =\n            SourceId::from_url(\"registry+https://github.com/rust-lang/crates.io-index\").unwrap();\n        PackageId::new(name, version, src_id).unwrap()\n    }\n\n    fn dep(name: &str, version: &str) -> Dependency {\n        let src_id =\n            SourceId::from_url(\"registry+https://github.com/rust-lang/crates.io-index\").unwrap();\n        Dependency::parse(name, Some(version), src_id).unwrap()\n    }\n\n    fn summ(name: &str, version: &str) -> Summary {\n        let pkg_id = pkgid(name, version);\n        let config = Config::default().unwrap();\n        let features = BTreeMap::new();\n        Summary::new(\n            &config,\n            pkg_id,\n            Vec::new(),\n            &features,\n            None::<&String>,\n            None::<&String>,\n        )\n        .unwrap()\n    }\n\n    fn describe(summaries: &Vec<Summary>) -> String {\n        let strs: Vec<String> = summaries\n            .iter()\n            .map(|summary| format!(\"{}/{}\", summary.name(), summary.version()))\n            .collect();\n        strs.join(\", \")\n    }\n\n    #[test]\n    fn test_prefer_package_id() {\n        let mut vp = VersionPreferences::default();\n        vp.prefer_package_id(pkgid(\"foo\", \"1.2.3\"));\n\n        let mut summaries = vec![\n            summ(\"foo\", \"1.2.4\"),\n            summ(\"foo\", \"1.2.3\"),\n            summ(\"foo\", \"1.1.0\"),\n            summ(\"foo\", \"1.0.9\"),\n        ];\n\n        vp.sort_summaries(&mut summaries, VersionOrdering::MaximumVersionsFirst, false);\n        assert_eq!(\n            describe(&summaries),\n            \"foo/1.2.3, foo/1.2.4, foo/1.1.0, foo/1.0.9\".to_string()\n        );\n\n        vp.sort_summaries(&mut summaries, VersionOrdering::MinimumVersionsFirst, false);\n        assert_eq!(\n            describe(&summaries),\n            \"foo/1.2.3, foo/1.0.9, foo/1.1.0, foo/1.2.4\".to_string()\n        );\n    }\n\n    #[test]\n    fn test_prefer_dependency() {\n        let mut vp = VersionPreferences::default();\n        vp.prefer_dependency(dep(\"foo\", \"=1.2.3\"));\n\n        let mut summaries = vec![\n            summ(\"foo\", \"1.2.4\"),\n            summ(\"foo\", \"1.2.3\"),\n            summ(\"foo\", \"1.1.0\"),\n            summ(\"foo\", \"1.0.9\"),\n        ];\n\n        vp.sort_summaries(&mut summaries, VersionOrdering::MaximumVersionsFirst, false);\n        assert_eq!(\n            describe(&summaries),\n            \"foo/1.2.3, foo/1.2.4, foo/1.1.0, foo/1.0.9\".to_string()\n        );\n\n        vp.sort_summaries(&mut summaries, VersionOrdering::MinimumVersionsFirst, false);\n        assert_eq!(\n            describe(&summaries),\n            \"foo/1.2.3, foo/1.0.9, foo/1.1.0, foo/1.2.4\".to_string()\n        );\n    }\n\n    #[test]\n    fn test_prefer_both() {\n        let mut vp = VersionPreferences::default();\n        vp.prefer_package_id(pkgid(\"foo\", \"1.2.3\"));\n        vp.prefer_dependency(dep(\"foo\", \"=1.1.0\"));\n\n        let mut summaries = vec![\n            summ(\"foo\", \"1.2.4\"),\n            summ(\"foo\", \"1.2.3\"),\n            summ(\"foo\", \"1.1.0\"),\n            summ(\"foo\", \"1.0.9\"),\n        ];\n\n        vp.sort_summaries(&mut summaries, VersionOrdering::MaximumVersionsFirst, false);\n        assert_eq!(\n            describe(&summaries),\n            \"foo/1.2.3, foo/1.1.0, foo/1.2.4, foo/1.0.9\".to_string()\n        );\n\n        vp.sort_summaries(&mut summaries, VersionOrdering::MinimumVersionsFirst, false);\n        assert_eq!(\n            describe(&summaries),\n            \"foo/1.1.0, foo/1.2.3, foo/1.0.9, foo/1.2.4\".to_string()\n        );\n    }\n}\n", "use crate::core::{Dependency, PackageId, SourceId};\nuse crate::util::interning::InternedString;\nuse crate::util::{CargoResult, Config};\nuse anyhow::bail;\nuse semver::Version;\nuse std::collections::{BTreeMap, HashMap, HashSet};\nuse std::fmt;\nuse std::hash::{Hash, Hasher};\nuse std::mem;\nuse std::rc::Rc;\n\n/// Subset of a `Manifest`. Contains only the most important information about\n/// a package.\n///\n/// Summaries are cloned, and should not be mutated after creation\n#[derive(Debug, Clone)]\npub struct Summary {\n    inner: Rc<Inner>,\n}\n\n#[derive(Debug, Clone)]\nstruct Inner {\n    package_id: PackageId,\n    dependencies: Vec<Dependency>,\n    features: Rc<FeatureMap>,\n    checksum: Option<String>,\n    links: Option<InternedString>,\n    rust_version: Option<InternedString>,\n}\n\nimpl Summary {\n    pub fn new(\n        config: &Config,\n        pkg_id: PackageId,\n        dependencies: Vec<Dependency>,\n        features: &BTreeMap<InternedString, Vec<InternedString>>,\n        links: Option<impl Into<InternedString>>,\n        rust_version: Option<impl Into<InternedString>>,\n    ) -> CargoResult<Summary> {\n        // ****CAUTION**** If you change anything here that may raise a new\n        // error, be sure to coordinate that change with either the index\n        // schema field or the SummariesCache version.\n        for dep in dependencies.iter() {\n            let dep_name = dep.name_in_toml();\n            if dep.is_optional() && !dep.is_transitive() {\n                bail!(\n                    \"dev-dependencies are not allowed to be optional: `{}`\",\n                    dep_name\n                )\n            }\n        }\n        let feature_map = build_feature_map(config, pkg_id, features, &dependencies)?;\n        Ok(Summary {\n            inner: Rc::new(Inner {\n                package_id: pkg_id,\n                dependencies,\n                features: Rc::new(feature_map),\n                checksum: None,\n                links: links.map(|l| l.into()),\n                rust_version: rust_version.map(|l| l.into()),\n            }),\n        })\n    }\n\n    pub fn package_id(&self) -> PackageId {\n        self.inner.package_id\n    }\n    pub fn name(&self) -> InternedString {\n        self.package_id().name()\n    }\n    pub fn version(&self) -> &Version {\n        self.package_id().version()\n    }\n    pub fn source_id(&self) -> SourceId {\n        self.package_id().source_id()\n    }\n    pub fn dependencies(&self) -> &[Dependency] {\n        &self.inner.dependencies\n    }\n    pub fn features(&self) -> &FeatureMap {\n        &self.inner.features\n    }\n\n    pub fn checksum(&self) -> Option<&str> {\n        self.inner.checksum.as_deref()\n    }\n    pub fn links(&self) -> Option<InternedString> {\n        self.inner.links\n    }\n\n    pub fn rust_version(&self) -> Option<InternedString> {\n        self.inner.rust_version\n    }\n\n    pub fn override_id(mut self, id: PackageId) -> Summary {\n        Rc::make_mut(&mut self.inner).package_id = id;\n        self\n    }\n\n    pub fn set_checksum(&mut self, cksum: String) {\n        Rc::make_mut(&mut self.inner).checksum = Some(cksum);\n    }\n\n    pub fn map_dependencies<F>(mut self, f: F) -> Summary\n    where\n        F: FnMut(Dependency) -> Dependency,\n    {\n        {\n            let slot = &mut Rc::make_mut(&mut self.inner).dependencies;\n            *slot = mem::take(slot).into_iter().map(f).collect();\n        }\n        self\n    }\n\n    pub fn map_source(self, to_replace: SourceId, replace_with: SourceId) -> Summary {\n        let me = if self.package_id().source_id() == to_replace {\n            let new_id = self.package_id().with_source_id(replace_with);\n            self.override_id(new_id)\n        } else {\n            self\n        };\n        me.map_dependencies(|dep| dep.map_source(to_replace, replace_with))\n    }\n}\n\nimpl PartialEq for Summary {\n    fn eq(&self, other: &Summary) -> bool {\n        self.inner.package_id == other.inner.package_id\n    }\n}\n\nimpl Eq for Summary {}\n\nimpl Hash for Summary {\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        self.inner.package_id.hash(state);\n    }\n}\n\n/// Checks features for errors, bailing out a CargoResult:Err if invalid,\n/// and creates FeatureValues for each feature.\nfn build_feature_map(\n    config: &Config,\n    pkg_id: PackageId,\n    features: &BTreeMap<InternedString, Vec<InternedString>>,\n    dependencies: &[Dependency],\n) -> CargoResult<FeatureMap> {\n    use self::FeatureValue::*;\n    let mut dep_map = HashMap::new();\n    for dep in dependencies.iter() {\n        dep_map\n            .entry(dep.name_in_toml())\n            .or_insert_with(Vec::new)\n            .push(dep);\n    }\n\n    let mut map: FeatureMap = features\n        .iter()\n        .map(|(feature, list)| {\n            let fvs: Vec<_> = list\n                .iter()\n                .map(|feat_value| FeatureValue::new(*feat_value))\n                .collect();\n            (*feature, fvs)\n        })\n        .collect();\n\n    // Add implicit features for optional dependencies if they weren't\n    // explicitly listed anywhere.\n    let explicitly_listed: HashSet<_> = map\n        .values()\n        .flatten()\n        .filter_map(|fv| match fv {\n            Dep { dep_name } => Some(*dep_name),\n            _ => None,\n        })\n        .collect();\n    for dep in dependencies {\n        if !dep.is_optional() {\n            continue;\n        }\n        let dep_name_in_toml = dep.name_in_toml();\n        if features.contains_key(&dep_name_in_toml) || explicitly_listed.contains(&dep_name_in_toml)\n        {\n            continue;\n        }\n        let fv = Dep {\n            dep_name: dep_name_in_toml,\n        };\n        map.insert(dep_name_in_toml, vec![fv]);\n    }\n\n    // Validate features are listed properly.\n    for (feature, fvs) in &map {\n        if feature.starts_with(\"dep:\") {\n            bail!(\n                \"feature named `{}` is not allowed to start with `dep:`\",\n                feature\n            );\n        }\n        if feature.contains('/') {\n            bail!(\n                \"feature named `{}` is not allowed to contain slashes\",\n                feature\n            );\n        }\n        validate_feature_name(config, pkg_id, feature)?;\n        for fv in fvs {\n            // Find data for the referenced dependency...\n            let dep_data = {\n                match fv {\n                    Feature(dep_name) | Dep { dep_name, .. } | DepFeature { dep_name, .. } => {\n                        dep_map.get(dep_name)\n                    }\n                }\n            };\n            let is_optional_dep = dep_data\n                .iter()\n                .flat_map(|d| d.iter())\n                .any(|d| d.is_optional());\n            let is_any_dep = dep_data.is_some();\n            match fv {\n                Feature(f) => {\n                    if !features.contains_key(f) {\n                        if !is_any_dep {\n                            bail!(\n                                \"feature `{}` includes `{}` which is neither a dependency \\\n                                 nor another feature\",\n                                feature,\n                                fv\n                            );\n                        }\n                        if is_optional_dep {\n                            if !map.contains_key(f) {\n                                bail!(\n                                    \"feature `{}` includes `{}`, but `{}` is an \\\n                                     optional dependency without an implicit feature\\n\\\n                                     Use `dep:{}` to enable the dependency.\",\n                                    feature,\n                                    fv,\n                                    f,\n                                    f\n                                );\n                            }\n                        } else {\n                            bail!(\"feature `{}` includes `{}`, but `{}` is not an optional dependency\\n\\\n                                A non-optional dependency of the same name is defined; \\\n                                consider adding `optional = true` to its definition.\",\n                                feature, fv, f);\n                        }\n                    }\n                }\n                Dep { dep_name } => {\n                    if !is_any_dep {\n                        bail!(\n                            \"feature `{}` includes `{}`, but `{}` is not listed as a dependency\",\n                            feature,\n                            fv,\n                            dep_name\n                        );\n                    }\n                    if !is_optional_dep {\n                        bail!(\n                            \"feature `{}` includes `{}`, but `{}` is not an optional dependency\\n\\\n                             A non-optional dependency of the same name is defined; \\\n                             consider adding `optional = true` to its definition.\",\n                            feature,\n                            fv,\n                            dep_name\n                        );\n                    }\n                }\n                DepFeature {\n                    dep_name,\n                    dep_feature,\n                    weak,\n                    ..\n                } => {\n                    // Early check for some unlikely syntax.\n                    if dep_feature.contains('/') {\n                        bail!(\n                            \"multiple slashes in feature `{}` (included by feature `{}`) are not allowed\",\n                            fv,\n                            feature\n                        );\n                    }\n\n                    // dep: cannot be combined with /\n                    if let Some(stripped_dep) = dep_name.strip_prefix(\"dep:\") {\n                        let has_other_dep = explicitly_listed.contains(stripped_dep);\n                        let is_optional = dep_map\n                            .get(stripped_dep)\n                            .iter()\n                            .flat_map(|d| d.iter())\n                            .any(|d| d.is_optional());\n                        let extra_help = if *weak || has_other_dep || !is_optional {\n                            // In this case, the user should just remove dep:.\n                            // Note that \"hiding\" an optional dependency\n                            // wouldn't work with just a single `dep:foo?/bar`\n                            // because there would not be any way to enable\n                            // `foo`.\n                            String::new()\n                        } else {\n                            format!(\n                                \"\\nIf the intent is to avoid creating an implicit feature \\\n                                 `{stripped_dep}` for an optional dependency, \\\n                                 then consider replacing this with two values:\\n    \\\n                                 \\\"dep:{stripped_dep}\\\", \\\"{stripped_dep}/{dep_feature}\\\"\"\n                            )\n                        };\n                        bail!(\n                            \"feature `{feature}` includes `{fv}` with both `dep:` and `/`\\n\\\n                            To fix this, remove the `dep:` prefix.{extra_help}\"\n                        )\n                    }\n\n                    // Validation of the feature name will be performed in the resolver.\n                    if !is_any_dep {\n                        bail!(\n                            \"feature `{}` includes `{}`, but `{}` is not a dependency\",\n                            feature,\n                            fv,\n                            dep_name\n                        );\n                    }\n                    if *weak && !is_optional_dep {\n                        bail!(\"feature `{}` includes `{}` with a `?`, but `{}` is not an optional dependency\\n\\\n                            A non-optional dependency of the same name is defined; \\\n                            consider removing the `?` or changing the dependency to be optional\",\n                            feature, fv, dep_name);\n                    }\n                }\n            }\n        }\n    }\n\n    // Make sure every optional dep is mentioned at least once.\n    let used: HashSet<_> = map\n        .values()\n        .flatten()\n        .filter_map(|fv| match fv {\n            Dep { dep_name } | DepFeature { dep_name, .. } => Some(dep_name),\n            _ => None,\n        })\n        .collect();\n    if let Some(dep) = dependencies\n        .iter()\n        .find(|dep| dep.is_optional() && !used.contains(&dep.name_in_toml()))\n    {\n        bail!(\n            \"optional dependency `{}` is not included in any feature\\n\\\n            Make sure that `dep:{}` is included in one of features in the [features] table.\",\n            dep.name_in_toml(),\n            dep.name_in_toml(),\n        );\n    }\n\n    Ok(map)\n}\n\n/// FeatureValue represents the types of dependencies a feature can have.\n#[derive(Clone, Debug, Ord, PartialOrd, Eq, PartialEq, Hash)]\npub enum FeatureValue {\n    /// A feature enabling another feature.\n    Feature(InternedString),\n    /// A feature enabling a dependency with `dep:dep_name` syntax.\n    Dep { dep_name: InternedString },\n    /// A feature enabling a feature on a dependency with `crate_name/feat_name` syntax.\n    DepFeature {\n        dep_name: InternedString,\n        dep_feature: InternedString,\n        /// If `true`, indicates the `?` syntax is used, which means this will\n        /// not automatically enable the dependency unless the dependency is\n        /// activated through some other means.\n        weak: bool,\n    },\n}\n\nimpl FeatureValue {\n    pub fn new(feature: InternedString) -> FeatureValue {\n        match feature.find('/') {\n            Some(pos) => {\n                let (dep, dep_feat) = feature.split_at(pos);\n                let dep_feat = &dep_feat[1..];\n                let (dep, weak) = if let Some(dep) = dep.strip_suffix('?') {\n                    (dep, true)\n                } else {\n                    (dep, false)\n                };\n                FeatureValue::DepFeature {\n                    dep_name: InternedString::new(dep),\n                    dep_feature: InternedString::new(dep_feat),\n                    weak,\n                }\n            }\n            None => {\n                if let Some(dep_name) = feature.strip_prefix(\"dep:\") {\n                    FeatureValue::Dep {\n                        dep_name: InternedString::new(dep_name),\n                    }\n                } else {\n                    FeatureValue::Feature(feature)\n                }\n            }\n        }\n    }\n\n    /// Returns `true` if this feature explicitly used `dep:` syntax.\n    pub fn has_dep_prefix(&self) -> bool {\n        matches!(self, FeatureValue::Dep { .. })\n    }\n}\n\nimpl fmt::Display for FeatureValue {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        use self::FeatureValue::*;\n        match self {\n            Feature(feat) => write!(f, \"{}\", feat),\n            Dep { dep_name } => write!(f, \"dep:{}\", dep_name),\n            DepFeature {\n                dep_name,\n                dep_feature,\n                weak,\n            } => {\n                let weak = if *weak { \"?\" } else { \"\" };\n                write!(f, \"{}{}/{}\", dep_name, weak, dep_feature)\n            }\n        }\n    }\n}\n\npub type FeatureMap = BTreeMap<InternedString, Vec<FeatureValue>>;\n\nfn validate_feature_name(config: &Config, pkg_id: PackageId, name: &str) -> CargoResult<()> {\n    let mut chars = name.chars();\n    const FUTURE: &str = \"This was previously accepted but is being phased out; \\\n        it will become a hard error in a future release.\\n\\\n        For more information, see issue #8813 <https://github.com/rust-lang/cargo/issues/8813>, \\\n        and please leave a comment if this will be a problem for your project.\";\n    if let Some(ch) = chars.next() {\n        if !(unicode_xid::UnicodeXID::is_xid_start(ch) || ch == '_' || ch.is_digit(10)) {\n            config.shell().warn(&format!(\n                \"invalid character `{}` in feature `{}` in package {}, \\\n                the first character must be a Unicode XID start character or digit \\\n                (most letters or `_` or `0` to `9`)\\n\\\n                {}\",\n                ch, name, pkg_id, FUTURE\n            ))?;\n        }\n    }\n    for ch in chars {\n        if !(unicode_xid::UnicodeXID::is_xid_continue(ch) || ch == '-' || ch == '+' || ch == '.') {\n            config.shell().warn(&format!(\n                \"invalid character `{}` in feature `{}` in package {}, \\\n                characters must be Unicode XID characters, `+`, or `.` \\\n                (numbers, `+`, `-`, `_`, `.`, or most letters)\\n\\\n                {}\",\n                ch, name, pkg_id, FUTURE\n            ))?;\n        }\n    }\n    Ok(())\n}\n", "//! Management of the index of a registry source.\n//!\n//! This module contains management of the index and various operations, such as\n//! actually parsing the index, looking for crates, etc. This is intended to be\n//! abstract over remote indices (downloaded via Git or HTTP) and local registry\n//! indices (which are all just present on the filesystem).\n//!\n//! ## How the index works\n//!\n//! Here is a simple flow when loading a [`Summary`] (metadata) from the index:\n//!\n//! 1. A query is fired via [`RegistryIndex::query_inner`].\n//! 2. Tries loading all summaries via [`RegistryIndex::load_summaries`], and\n//!    under the hood calling [`Summaries::parse`] to parse an index file.\n//!     1. If an on-disk index cache is present, loads it via\n//!        [`Summaries::parse_cache`].\n//!     2. Otherwise goes to the slower path [`RegistryData::load`] to get the\n//!        specific index file.\n//! 3. A [`Summary`] is now ready in callback `f` in [`RegistryIndex::query_inner`].\n//!\n//! This is just an overview. To know the rationale behind, continue reading.\n//!\n//! ## A layer of on-disk index cache for performance\n//!\n//! One important aspect of the index is that we want to optimize the \"happy\n//! path\" as much as possible. Whenever you type `cargo build` Cargo will\n//! *always* reparse the registry and learn about dependency information. This\n//! is done because Cargo needs to learn about the upstream crates.io crates\n//! that you're using and ensure that the preexisting `Cargo.lock` still matches\n//! the current state of the world.\n//!\n//! Consequently, Cargo \"null builds\" (the index that Cargo adds to each build\n//! itself) need to be fast when accessing the index. The primary performance\n//! optimization here is to avoid parsing JSON blobs from the registry if we\n//! don't need them. Most secondary optimizations are centered around removing\n//! allocations and such, but avoiding parsing JSON is the #1 optimization.\n//!\n//! When we get queries from the resolver we're given a [`Dependency`]. This\n//! dependency in turn has a version requirement, and with lock files that\n//! already exist these version requirements are exact version requirements\n//! `=a.b.c`. This means that we in theory only need to parse one line of JSON\n//! per query in the registry, the one that matches version `a.b.c`.\n//!\n//! The crates.io index, however, is not amenable to this form of query. Instead\n//! the crates.io index simply is a file where each line is a JSON blob, aka\n//! [`IndexPackage`]. To learn about the versions in each JSON blob we would\n//! need to parse the JSON via [`IndexSummary::parse`], defeating the purpose\n//! of trying to parse as little as possible.\n//!\n//! > Note that as a small aside even *loading* the JSON from the registry is\n//! > actually pretty slow. For crates.io and [`RemoteRegistry`] we don't\n//! > actually check out the git index on disk because that takes quite some\n//! > time and is quite large. Instead we use `libgit2` to read the JSON from\n//! > the raw git objects. This in turn can be slow (aka show up high in\n//! > profiles) because libgit2 has to do deflate decompression and such.\n//!\n//! To solve all these issues a strategy is employed here where Cargo basically\n//! creates an index into the index. The first time a package is queried about\n//! (first time being for an entire computer) Cargo will load the contents\n//! (slowly via libgit2) from the registry. It will then (slowly) parse every\n//! single line to learn about its versions. Afterwards, however, Cargo will\n//! emit a new file (a cache, representing as [`SummariesCache`]) which is\n//! amenable for speedily parsing in future invocations.\n//!\n//! This cache file is currently organized by basically having the semver\n//! version extracted from each JSON blob. That way Cargo can quickly and\n//! easily parse all versions contained and which JSON blob they're associated\n//! with. The JSON blob then doesn't actually need to get parsed unless the\n//! version is parsed.\n//!\n//! Altogether the initial measurements of this shows a massive improvement for\n//! Cargo null build performance. It's expected that the improvements earned\n//! here will continue to grow over time in the sense that the previous\n//! implementation (parse all lines each time) actually continues to slow down\n//! over time as new versions of a crate are published. In any case when first\n//! implemented a null build of Cargo itself would parse 3700 JSON blobs from\n//! the registry and load 150 blobs from git. Afterwards it parses 150 JSON\n//! blobs and loads 0 files git. Removing 200ms or more from Cargo's startup\n//! time is certainly nothing to sneeze at!\n//!\n//! Note that this is just a high-level overview, there's of course lots of\n//! details like invalidating caches and whatnot which are handled below, but\n//! hopefully those are more obvious inline in the code itself.\n//!\n//! [`RemoteRegistry`]: super::remote::RemoteRegistry\n//! [`Dependency`]: crate::core::Dependency\n\nuse crate::core::dependency::DepKind;\nuse crate::core::Dependency;\nuse crate::core::{PackageId, SourceId, Summary};\nuse crate::sources::registry::{LoadResponse, RegistryData};\nuse crate::util::interning::InternedString;\nuse crate::util::IntoUrl;\nuse crate::util::{internal, CargoResult, Config, Filesystem, OptVersionReq, ToSemver};\nuse anyhow::bail;\nuse cargo_util::{paths, registry::make_dep_path};\nuse log::{debug, info};\nuse semver::Version;\nuse serde::Deserialize;\nuse std::borrow::Cow;\nuse std::collections::BTreeMap;\nuse std::collections::{HashMap, HashSet};\nuse std::fs;\nuse std::io::ErrorKind;\nuse std::path::Path;\nuse std::str;\nuse std::task::{ready, Poll};\n\n/// The current version of [`SummariesCache`].\nconst CURRENT_CACHE_VERSION: u8 = 3;\n\n/// The maximum schema version of the `v` field in the index this version of\n/// cargo understands. See [`IndexPackage::v`] for the detail.\nconst INDEX_V_MAX: u32 = 2;\n\n/// Manager for handling the on-disk index.\n///\n/// Different kinds of registries store the index differently:\n///\n/// * [`LocalRegistry`]` is a simple on-disk tree of files of the raw index.\n/// * [`RemoteRegistry`] is stored as a raw git repository.\n/// * [`HttpRegistry`] fills the on-disk index cache directly without keeping\n///   any raw index.\n///\n/// These means of access are handled via the [`RegistryData`] trait abstraction.\n/// This transparently handles caching of the index in a more efficient format.\n///\n/// [`LocalRegistry`]: super::local::LocalRegistry\n/// [`RemoteRegistry`]: super::remote::RemoteRegistry\n/// [`HttpRegistry`]: super::http_remote::HttpRegistry\npub struct RegistryIndex<'cfg> {\n    source_id: SourceId,\n    /// Root directory of the index for the registry.\n    path: Filesystem,\n    /// In-memory cache of summary data.\n    ///\n    /// This is keyed off the package name. The [`Summaries`] value handles\n    /// loading the summary data. It keeps an optimized on-disk representation\n    /// of the JSON files, which is created in an as-needed fashion. If it\n    /// hasn't been cached already, it uses [`RegistryData::load`] to access\n    /// to JSON files from the index, and the creates the optimized on-disk\n    /// summary cache.\n    summaries_cache: HashMap<InternedString, Summaries>,\n    /// [`Config`] reference for convenience.\n    config: &'cfg Config,\n}\n\n/// An internal cache of summaries for a particular package.\n///\n/// A list of summaries are loaded from disk via one of two methods:\n///\n/// 1. From raw registry index --- Primarily Cargo will parse the corresponding\n///    file for a crate in the upstream crates.io registry. That's just a JSON\n///    blob per line which we can parse, extract the version, and then store here.\n///    See [`IndexPackage`] and [`IndexSummary::parse`].\n///\n/// 2. From on-disk index cache --- If Cargo has previously run, we'll have a\n///    cached index of dependencies for the upstream index. This is a file that\n///    Cargo maintains lazily on the local filesystem and is much faster to\n///    parse since it doesn't involve parsing all of the JSON.\n///    See [`SummariesCache`].\n///\n/// The outward-facing interface of this doesn't matter too much where it's\n/// loaded from, but it's important when reading the implementation to note that\n/// we try to parse as little as possible!\n#[derive(Default)]\nstruct Summaries {\n    /// A raw vector of uninterpreted bytes. This is what `Unparsed` start/end\n    /// fields are indexes into. If a `Summaries` is loaded from the crates.io\n    /// index then this field will be empty since nothing is `Unparsed`.\n    raw_data: Vec<u8>,\n\n    /// All known versions of a crate, keyed from their `Version` to the\n    /// possibly parsed or unparsed version of the full summary.\n    versions: HashMap<Version, MaybeIndexSummary>,\n}\n\n/// A lazily parsed [`IndexSummary`].\nenum MaybeIndexSummary {\n    /// A summary which has not been parsed, The `start` and `end` are pointers\n    /// into [`Summaries::raw_data`] which this is an entry of.\n    Unparsed { start: usize, end: usize },\n\n    /// An actually parsed summary.\n    Parsed(IndexSummary),\n}\n\n/// A parsed representation of a summary from the index. This is usually parsed\n/// from a line from a raw index file, or a JSON blob from on-disk index cache.\n///\n/// In addition to a full [`Summary`], we have information on whether it is `yanked`.\npub struct IndexSummary {\n    pub summary: Summary,\n    pub yanked: bool,\n    /// Schema version, see [`IndexPackage::v`].\n    v: u32,\n}\n\n/// A representation of the cache on disk that Cargo maintains of summaries.\n///\n/// Cargo will initially parse all summaries in the registry and will then\n/// serialize that into this form and place it in a new location on disk,\n/// ensuring that access in the future is much speedier.\n///\n/// For serialization and deserialization of this on-disk index cache of\n/// summaries, see [`SummariesCache::serialize`]  and [`SummariesCache::parse`].\n///\n/// # The format of the index cache\n///\n/// The idea of this format is that it's a very easy file for Cargo to parse in\n/// future invocations. The read from disk should be fast and then afterwards\n/// all we need to know is what versions correspond to which JSON blob.\n///\n/// Currently the format looks like:\n///\n/// ```text\n/// +---------------+----------------------+--------------------+---+\n/// | cache version | index schema version | index file version | 0 |\n/// +---------------+----------------------+--------------------+---+\n/// ```\n///\n/// followed by one or more (version + JSON blob) pairs...\n///\n/// ```text\n/// +----------------+---+-----------+---+\n/// | semver version | 0 | JSON blob | 0 | ...\n/// +----------------+---+-----------+---+\n/// ```\n///\n/// Each field represents:\n///\n/// * _cache version_ --- Intended to ensure that there's some level of\n///   future compatibility against changes to this cache format so if different\n///   versions of Cargo share the same cache they don't get too confused.\n/// * _index schema version_ --- The schema version of the raw index file.\n///   See [`IndexPackage::v`] for the detail.\n/// * _index file version_ --- Tracks when a cache needs to be regenerated.\n///   A cache regeneration is required whenever the index file itself updates.\n/// * _semver version_ --- The version for each JSON blob. Extracted from the\n///   blob for fast queries without parsing the entire blob.\n/// * _JSON blob_ --- The actual metadata for each version of the package. It\n///   has the same representation as [`IndexPackage`].\n///\n/// # Changes between each cache version\n///\n/// * `1`: The original version.\n/// * `2`: Added the \"index schema version\" field so that if the index schema\n///   changes, different versions of cargo won't get confused reading each\n///   other's caches.\n/// * `3`: Bumped the version to work around an issue where multiple versions of\n///   a package were published that differ only by semver metadata. For\n///   example, openssl-src 110.0.0 and 110.0.0+1.1.0f. Previously, the cache\n///   would be incorrectly populated with two entries, both 110.0.0. After\n///   this, the metadata will be correctly included. This isn't really a format\n///   change, just a version bump to clear the incorrect cache entries. Note:\n///   the index shouldn't allow these, but unfortunately crates.io doesn't\n///   check it.\n///\n/// See [`CURRENT_CACHE_VERSION`] for the current cache version.\n#[derive(Default)]\nstruct SummariesCache<'a> {\n    /// JSON blobs of the summaries. Each JSON blob has a [`Version`] beside,\n    /// so that Cargo can query a version without full JSON parsing.\n    versions: Vec<(Version, &'a [u8])>,\n    /// For cache invalidation, we tracks the index file version to determine\n    /// when to regenerate the cache itself.\n    index_version: &'a str,\n}\n\n/// A single line in the index representing a single version of a package.\n#[derive(Deserialize)]\npub struct IndexPackage<'a> {\n    /// Name of the pacakge.\n    name: InternedString,\n    /// The version of this dependency.\n    vers: Version,\n    /// All kinds of direct dependencies of the package, including dev and\n    /// build dependencies.\n    #[serde(borrow)]\n    deps: Vec<RegistryDependency<'a>>,\n    /// Set of features defined for the package, i.e., `[features]` table.\n    features: BTreeMap<InternedString, Vec<InternedString>>,\n    /// This field contains features with new, extended syntax. Specifically,\n    /// namespaced features (`dep:`) and weak dependencies (`pkg?/feat`).\n    ///\n    /// This is separated from `features` because versions older than 1.19\n    /// will fail to load due to not being able to parse the new syntax, even\n    /// with a `Cargo.lock` file.\n    features2: Option<BTreeMap<InternedString, Vec<InternedString>>>,\n    /// Checksum for verifying the integrity of the corresponding downloaded package.\n    cksum: String,\n    /// If `true`, Cargo will skip this version when resolving.\n    ///\n    /// This was added in 2014. Everything in the crates.io index has this set\n    /// now, so this probably doesn't need to be an option anymore.\n    yanked: Option<bool>,\n    /// Native library name this package links to.\n    ///\n    /// Added early 2018 (see <https://github.com/rust-lang/cargo/pull/4978>),\n    /// can be `None` if published before then.\n    links: Option<InternedString>,\n    /// Required version of rust\n    ///\n    /// Corresponds to `package.rust-version`.\n    ///\n    /// Added in 2023 (see <https://github.com/rust-lang/crates.io/pull/6267>),\n    /// can be `None` if published before then or if not set in the manifest.\n    rust_version: Option<InternedString>,\n    /// The schema version for this entry.\n    ///\n    /// If this is None, it defaults to version `1`. Entries with unknown\n    /// versions are ignored.\n    ///\n    /// Version `2` schema adds the `features2` field.\n    ///\n    /// This provides a method to safely introduce changes to index entries\n    /// and allow older versions of cargo to ignore newer entries it doesn't\n    /// understand. This is honored as of 1.51, so unfortunately older\n    /// versions will ignore it, and potentially misinterpret version 2 and\n    /// newer entries.\n    ///\n    /// The intent is that versions older than 1.51 will work with a\n    /// pre-existing `Cargo.lock`, but they may not correctly process `cargo\n    /// update` or build a lock from scratch. In that case, cargo may\n    /// incorrectly select a new package that uses a new index schema. A\n    /// workaround is to downgrade any packages that are incompatible with the\n    /// `--precise` flag of `cargo update`.\n    v: Option<u32>,\n}\n\n/// A dependency as encoded in the [`IndexPackage`] index JSON.\n#[derive(Deserialize)]\nstruct RegistryDependency<'a> {\n    /// Name of the dependency. If the dependency is renamed, the original\n    /// would be stored in [`RegistryDependency::package`].\n    name: InternedString,\n    /// The SemVer requirement for this dependency.\n    #[serde(borrow)]\n    req: Cow<'a, str>,\n    /// Set of features enabled for this dependency.\n    features: Vec<InternedString>,\n    /// Whether or not this is an optional dependency.\n    optional: bool,\n    /// Whether or not default features are enabled.\n    default_features: bool,\n    /// The target platform for this dependency.\n    target: Option<Cow<'a, str>>,\n    /// The dependency kind. \"dev\", \"build\", and \"normal\".\n    kind: Option<Cow<'a, str>>,\n    // The URL of the index of the registry where this dependency is from.\n    // `None` if it is from the same index.\n    registry: Option<Cow<'a, str>>,\n    /// The original name if the dependency is renamed.\n    package: Option<InternedString>,\n    /// Whether or not this is a public dependency. Unstable. See [RFC 1977].\n    ///\n    /// [RFC 1977]: https://rust-lang.github.io/rfcs/1977-public-private-dependencies.html\n    public: Option<bool>,\n}\n\nimpl<'cfg> RegistryIndex<'cfg> {\n    /// Creates an empty registry index at `path`.\n    pub fn new(\n        source_id: SourceId,\n        path: &Filesystem,\n        config: &'cfg Config,\n    ) -> RegistryIndex<'cfg> {\n        RegistryIndex {\n            source_id,\n            path: path.clone(),\n            summaries_cache: HashMap::new(),\n            config,\n        }\n    }\n\n    /// Returns the hash listed for a specified `PackageId`. Primarily for\n    /// checking the integrity of a downloaded package matching the checksum in\n    /// the index file, aka [`IndexSummary`].\n    pub fn hash(&mut self, pkg: PackageId, load: &mut dyn RegistryData) -> Poll<CargoResult<&str>> {\n        let req = OptVersionReq::exact(pkg.version());\n        let summary = self.summaries(&pkg.name(), &req, load)?;\n        let summary = ready!(summary).next();\n        Poll::Ready(Ok(summary\n            .ok_or_else(|| internal(format!(\"no hash listed for {}\", pkg)))?\n            .summary\n            .checksum()\n            .ok_or_else(|| internal(format!(\"no hash listed for {}\", pkg)))?))\n    }\n\n    /// Load a list of summaries for `name` package in this registry which\n    /// match `req`.\n    ///\n    /// This function will semantically\n    ///\n    /// 1. parse the index file (either raw or cache),\n    /// 2. match all versions,\n    /// 3. and then return an iterator over all summaries which matched.\n    ///\n    /// Internally there's quite a few layer of caching to amortize this cost\n    /// though since this method is called quite a lot on null builds in Cargo.\n    pub fn summaries<'a, 'b>(\n        &'a mut self,\n        name: &str,\n        req: &'b OptVersionReq,\n        load: &mut dyn RegistryData,\n    ) -> Poll<CargoResult<impl Iterator<Item = &'a IndexSummary> + 'b>>\n    where\n        'a: 'b,\n    {\n        let source_id = self.source_id;\n        let config = self.config;\n\n        // First up parse what summaries we have available.\n        let name = InternedString::new(name);\n        let summaries = ready!(self.load_summaries(name, load)?);\n\n        // Iterate over our summaries, extract all relevant ones which match our\n        // version requirement, and then parse all corresponding rows in the\n        // registry. As a reminder this `summaries` method is called for each\n        // entry in a lock file on every build, so we want to absolutely\n        // minimize the amount of work being done here and parse as little as\n        // necessary.\n        let raw_data = &summaries.raw_data;\n        Poll::Ready(Ok(summaries\n            .versions\n            .iter_mut()\n            .filter_map(move |(k, v)| if req.matches(k) { Some(v) } else { None })\n            .filter_map(\n                move |maybe| match maybe.parse(config, raw_data, source_id) {\n                    Ok(summary) => Some(summary),\n                    Err(e) => {\n                        info!(\"failed to parse `{}` registry package: {}\", name, e);\n                        None\n                    }\n                },\n            )\n            .filter(move |is| {\n                if is.v > INDEX_V_MAX {\n                    debug!(\n                        \"unsupported schema version {} ({} {})\",\n                        is.v,\n                        is.summary.name(),\n                        is.summary.version()\n                    );\n                    false\n                } else {\n                    true\n                }\n            })))\n    }\n\n    /// Actually parses what summaries we have available.\n    ///\n    /// If Cargo has run previously, this tries in this order:\n    ///\n    /// 1. Returns from in-memory cache, aka [`RegistryIndex::summaries_cache`].\n    /// 2. If missing, hands over to [`Summaries::parse`] to parse an index file.\n    ///\n    ///    The actual kind index file being parsed depends on which kind of\n    ///    [`RegistryData`] the `load` argument is given. For example, a\n    ///    Git-based [`RemoteRegistry`] will first try a on-disk index cache\n    ///    file, and then try parsing registry raw index fomr Git repository.\n    ///\n    /// In effect, this is intended to be a quite cheap operation.\n    ///\n    /// [`RemoteRegistry`]: super::remote::RemoteRegistry\n    fn load_summaries(\n        &mut self,\n        name: InternedString,\n        load: &mut dyn RegistryData,\n    ) -> Poll<CargoResult<&mut Summaries>> {\n        // If we've previously loaded what versions are present for `name`, just\n        // return that since our in-memory cache should still be valid.\n        if self.summaries_cache.contains_key(&name) {\n            return Poll::Ready(Ok(self.summaries_cache.get_mut(&name).unwrap()));\n        }\n\n        // Prepare the `RegistryData` which will lazily initialize internal data\n        // structures.\n        load.prepare()?;\n\n        let root = load.assert_index_locked(&self.path);\n        let cache_root = root.join(\".cache\");\n\n        // See module comment in `registry/mod.rs` for why this is structured\n        // the way it is.\n        let path = make_dep_path(&name.to_lowercase(), false);\n        let summaries = ready!(Summaries::parse(\n            root,\n            &cache_root,\n            path.as_ref(),\n            self.source_id,\n            load,\n            self.config,\n        ))?\n        .unwrap_or_default();\n        self.summaries_cache.insert(name, summaries);\n        Poll::Ready(Ok(self.summaries_cache.get_mut(&name).unwrap()))\n    }\n\n    /// Clears the in-memory summaries cache.\n    pub fn clear_summaries_cache(&mut self) {\n        self.summaries_cache.clear();\n    }\n\n    /// Attempts to find the packages that match a `name` and a version `req`.\n    ///\n    /// This is primarily used by [`Source::query`](super::Source).\n    pub fn query_inner(\n        &mut self,\n        name: &str,\n        req: &OptVersionReq,\n        load: &mut dyn RegistryData,\n        yanked_whitelist: &HashSet<PackageId>,\n        f: &mut dyn FnMut(Summary),\n    ) -> Poll<CargoResult<()>> {\n        if self.config.offline() {\n            // This should only return `Poll::Ready(Ok(()))` if there is at least 1 match.\n            //\n            // If there are 0 matches it should fall through and try again with online.\n            // This is necessary for dependencies that are not used (such as\n            // target-cfg or optional), but are not downloaded. Normally the\n            // build should succeed if they are not downloaded and not used,\n            // but they still need to resolve. If they are actually needed\n            // then cargo will fail to download and an error message\n            // indicating that the required dependency is unavailable while\n            // offline will be displayed.\n            if ready!(self.query_inner_with_online(name, req, load, yanked_whitelist, f, false)?)\n                > 0\n            {\n                return Poll::Ready(Ok(()));\n            }\n        }\n        self.query_inner_with_online(name, req, load, yanked_whitelist, f, true)\n            .map_ok(|_| ())\n    }\n\n    /// Inner implementation of [`Self::query_inner`]. Returns the number of\n    /// summaries we've got.\n    ///\n    /// The `online` controls whether Cargo can access the network when needed.\n    fn query_inner_with_online(\n        &mut self,\n        name: &str,\n        req: &OptVersionReq,\n        load: &mut dyn RegistryData,\n        yanked_whitelist: &HashSet<PackageId>,\n        f: &mut dyn FnMut(Summary),\n        online: bool,\n    ) -> Poll<CargoResult<usize>> {\n        let source_id = self.source_id;\n\n        let summaries = ready!(self.summaries(name, req, load))?;\n\n        let summaries = summaries\n            // First filter summaries for `--offline`. If we're online then\n            // everything is a candidate, otherwise if we're offline we're only\n            // going to consider candidates which are actually present on disk.\n            //\n            // Note: This particular logic can cause problems with\n            // optional dependencies when offline. If at least 1 version\n            // of an optional dependency is downloaded, but that version\n            // does not satisfy the requirements, then resolution will\n            // fail. Unfortunately, whether or not something is optional\n            // is not known here.\n            .filter(|s| (online || load.is_crate_downloaded(s.summary.package_id())))\n            // Next filter out all yanked packages. Some yanked packages may\n            // leak through if they're in a whitelist (aka if they were\n            // previously in `Cargo.lock`\n            .filter(|s| !s.yanked || yanked_whitelist.contains(&s.summary.package_id()))\n            .map(|s| s.summary.clone());\n\n        // Handle `cargo update --precise` here. If specified, our own source\n        // will have a precise version listed of the form\n        // `<pkg>=<p_req>o-><f_req>` where `<pkg>` is the name of a crate on\n        // this source, `<p_req>` is the version installed and `<f_req> is the\n        // version requested (argument to `--precise`).\n        let precise = match source_id.precise() {\n            Some(p) if p.starts_with(name) && p[name.len()..].starts_with('=') => {\n                let mut vers = p[name.len() + 1..].splitn(2, \"->\");\n                let current_vers = vers.next().unwrap().to_semver().unwrap();\n                let requested_vers = vers.next().unwrap().to_semver().unwrap();\n                Some((current_vers, requested_vers))\n            }\n            _ => None,\n        };\n        let summaries = summaries.filter(|s| match &precise {\n            Some((current, requested)) => {\n                if req.matches(current) {\n                    // Unfortunately crates.io allows versions to differ only\n                    // by build metadata. This shouldn't be allowed, but since\n                    // it is, this will honor it if requested. However, if not\n                    // specified, then ignore it.\n                    let s_vers = s.version();\n                    match (s_vers.build.is_empty(), requested.build.is_empty()) {\n                        (true, true) => s_vers == requested,\n                        (true, false) => false,\n                        (false, true) => {\n                            // Strip out the metadata.\n                            s_vers.major == requested.major\n                                && s_vers.minor == requested.minor\n                                && s_vers.patch == requested.patch\n                                && s_vers.pre == requested.pre\n                        }\n                        (false, false) => s_vers == requested,\n                    }\n                } else {\n                    true\n                }\n            }\n            None => true,\n        });\n\n        let mut count = 0;\n        for summary in summaries {\n            f(summary);\n            count += 1;\n        }\n        Poll::Ready(Ok(count))\n    }\n\n    /// Looks into the summaries to check if a package has been yanked.\n    pub fn is_yanked(\n        &mut self,\n        pkg: PackageId,\n        load: &mut dyn RegistryData,\n    ) -> Poll<CargoResult<bool>> {\n        let req = OptVersionReq::exact(pkg.version());\n        let found = self\n            .summaries(&pkg.name(), &req, load)\n            .map_ok(|mut p| p.any(|summary| summary.yanked));\n        found\n    }\n}\n\nimpl Summaries {\n    /// Parse out a [`Summaries`] instances from on-disk state.\n    ///\n    /// This will do the followings in order:\n    ///\n    /// 1. Attempt to prefer parsing a previous index cache file that already\n    ///    exists from a previous invocation of Cargo (aka you're typing `cargo\n    ///    build` again after typing it previously).\n    /// 2. If parsing fails, or the cache isn't found or is invalid, we then\n    ///    take a slower path which loads the full descriptor for `relative`\n    ///    from the underlying index (aka libgit2 with crates.io, or from a\n    ///    remote HTTP index) and then parse everything in there.\n    ///\n    /// * `root` --- this is the root argument passed to `load`\n    /// * `cache_root` --- this is the root on the filesystem itself of where\n    ///   to store cache files.\n    /// * `relative` --- this is the file we're loading from cache or the index\n    ///   data\n    /// * `source_id` --- the registry's SourceId used when parsing JSON blobs\n    ///   to create summaries.\n    /// * `load` --- the actual index implementation which may be very slow to\n    ///   call. We avoid this if we can.\n    pub fn parse(\n        root: &Path,\n        cache_root: &Path,\n        relative: &Path,\n        source_id: SourceId,\n        load: &mut dyn RegistryData,\n        config: &Config,\n    ) -> Poll<CargoResult<Option<Summaries>>> {\n        // First up, attempt to load the cache. This could fail for all manner\n        // of reasons, but consider all of them non-fatal and just log their\n        // occurrence in case anyone is debugging anything.\n        let cache_path = cache_root.join(relative);\n        let mut cached_summaries = None;\n        let mut index_version = None;\n        match fs::read(&cache_path) {\n            Ok(contents) => match Summaries::parse_cache(contents) {\n                Ok((s, v)) => {\n                    cached_summaries = Some(s);\n                    index_version = Some(v);\n                }\n                Err(e) => {\n                    log::debug!(\"failed to parse {:?} cache: {}\", relative, e);\n                }\n            },\n            Err(e) => log::debug!(\"cache missing for {:?} error: {}\", relative, e),\n        }\n\n        let response = ready!(load.load(root, relative, index_version.as_deref())?);\n\n        match response {\n            LoadResponse::CacheValid => {\n                log::debug!(\"fast path for registry cache of {:?}\", relative);\n                return Poll::Ready(Ok(cached_summaries));\n            }\n            LoadResponse::NotFound => {\n                if let Err(e) = fs::remove_file(cache_path) {\n                    if e.kind() != ErrorKind::NotFound {\n                        log::debug!(\"failed to remove from cache: {}\", e);\n                    }\n                }\n                return Poll::Ready(Ok(None));\n            }\n            LoadResponse::Data {\n                raw_data,\n                index_version,\n            } => {\n                // This is the fallback path where we actually talk to the registry backend to load\n                // information. Here we parse every single line in the index (as we need\n                // to find the versions)\n                log::debug!(\"slow path for {:?}\", relative);\n                let mut cache = SummariesCache::default();\n                let mut ret = Summaries::default();\n                ret.raw_data = raw_data;\n                for line in split(&ret.raw_data, b'\\n') {\n                    // Attempt forwards-compatibility on the index by ignoring\n                    // everything that we ourselves don't understand, that should\n                    // allow future cargo implementations to break the\n                    // interpretation of each line here and older cargo will simply\n                    // ignore the new lines.\n                    let summary = match IndexSummary::parse(config, line, source_id) {\n                        Ok(summary) => summary,\n                        Err(e) => {\n                            // This should only happen when there is an index\n                            // entry from a future version of cargo that this\n                            // version doesn't understand. Hopefully, those future\n                            // versions of cargo correctly set INDEX_V_MAX and\n                            // CURRENT_CACHE_VERSION, otherwise this will skip\n                            // entries in the cache preventing those newer\n                            // versions from reading them (that is, until the\n                            // cache is rebuilt).\n                            log::info!(\"failed to parse {:?} registry package: {}\", relative, e);\n                            continue;\n                        }\n                    };\n                    let version = summary.summary.package_id().version().clone();\n                    cache.versions.push((version.clone(), line));\n                    ret.versions.insert(version, summary.into());\n                }\n                if let Some(index_version) = index_version {\n                    log::trace!(\"caching index_version {}\", index_version);\n                    let cache_bytes = cache.serialize(index_version.as_str());\n                    // Once we have our `cache_bytes` which represents the `Summaries` we're\n                    // about to return, write that back out to disk so future Cargo\n                    // invocations can use it.\n                    //\n                    // This is opportunistic so we ignore failure here but are sure to log\n                    // something in case of error.\n                    if paths::create_dir_all(cache_path.parent().unwrap()).is_ok() {\n                        let path = Filesystem::new(cache_path.clone());\n                        config.assert_package_cache_locked(&path);\n                        if let Err(e) = fs::write(cache_path, &cache_bytes) {\n                            log::info!(\"failed to write cache: {}\", e);\n                        }\n                    }\n\n                    // If we've got debug assertions enabled read back in the cached values\n                    // and assert they match the expected result.\n                    #[cfg(debug_assertions)]\n                    {\n                        let readback = SummariesCache::parse(&cache_bytes)\n                            .expect(\"failed to parse cache we just wrote\");\n                        assert_eq!(\n                            readback.index_version, index_version,\n                            \"index_version mismatch\"\n                        );\n                        assert_eq!(readback.versions, cache.versions, \"versions mismatch\");\n                    }\n                }\n                Poll::Ready(Ok(Some(ret)))\n            }\n        }\n    }\n\n    /// Parses the contents of an on-disk cache, aka [`SummariesCache`], which\n    /// represents information previously cached by Cargo.\n    pub fn parse_cache(contents: Vec<u8>) -> CargoResult<(Summaries, InternedString)> {\n        let cache = SummariesCache::parse(&contents)?;\n        let index_version = InternedString::new(cache.index_version);\n        let mut ret = Summaries::default();\n        for (version, summary) in cache.versions {\n            let (start, end) = subslice_bounds(&contents, summary);\n            ret.versions\n                .insert(version, MaybeIndexSummary::Unparsed { start, end });\n        }\n        ret.raw_data = contents;\n        return Ok((ret, index_version));\n\n        // Returns the start/end offsets of `inner` with `outer`. Asserts that\n        // `inner` is a subslice of `outer`.\n        fn subslice_bounds(outer: &[u8], inner: &[u8]) -> (usize, usize) {\n            let outer_start = outer.as_ptr() as usize;\n            let outer_end = outer_start + outer.len();\n            let inner_start = inner.as_ptr() as usize;\n            let inner_end = inner_start + inner.len();\n            assert!(inner_start >= outer_start);\n            assert!(inner_end <= outer_end);\n            (inner_start - outer_start, inner_end - outer_start)\n        }\n    }\n}\n\nimpl<'a> SummariesCache<'a> {\n    /// Deserializes an on-disk cache.\n    fn parse(data: &'a [u8]) -> CargoResult<SummariesCache<'a>> {\n        // NB: keep this method in sync with `serialize` below\n        let (first_byte, rest) = data\n            .split_first()\n            .ok_or_else(|| anyhow::format_err!(\"malformed cache\"))?;\n        if *first_byte != CURRENT_CACHE_VERSION {\n            bail!(\"looks like a different Cargo's cache, bailing out\");\n        }\n        let index_v_bytes = rest\n            .get(..4)\n            .ok_or_else(|| anyhow::anyhow!(\"cache expected 4 bytes for index schema version\"))?;\n        let index_v = u32::from_le_bytes(index_v_bytes.try_into().unwrap());\n        if index_v != INDEX_V_MAX {\n            bail!(\n                \"index schema version {index_v} doesn't match the version I know ({INDEX_V_MAX})\",\n            );\n        }\n        let rest = &rest[4..];\n\n        let mut iter = split(rest, 0);\n        let last_index_update = if let Some(update) = iter.next() {\n            str::from_utf8(update)?\n        } else {\n            bail!(\"malformed file\");\n        };\n        let mut ret = SummariesCache::default();\n        ret.index_version = last_index_update;\n        while let Some(version) = iter.next() {\n            let version = str::from_utf8(version)?;\n            let version = Version::parse(version)?;\n            let summary = iter.next().unwrap();\n            ret.versions.push((version, summary));\n        }\n        Ok(ret)\n    }\n\n    /// Serializes itself with a given `index_version`.\n    fn serialize(&self, index_version: &str) -> Vec<u8> {\n        // NB: keep this method in sync with `parse` above\n        let size = self\n            .versions\n            .iter()\n            .map(|(_version, data)| (10 + data.len()))\n            .sum();\n        let mut contents = Vec::with_capacity(size);\n        contents.push(CURRENT_CACHE_VERSION);\n        contents.extend(&u32::to_le_bytes(INDEX_V_MAX));\n        contents.extend_from_slice(index_version.as_bytes());\n        contents.push(0);\n        for (version, data) in self.versions.iter() {\n            contents.extend_from_slice(version.to_string().as_bytes());\n            contents.push(0);\n            contents.extend_from_slice(data);\n            contents.push(0);\n        }\n        contents\n    }\n}\n\nimpl MaybeIndexSummary {\n    /// Parses this \"maybe a summary\" into a `Parsed` for sure variant.\n    ///\n    /// Does nothing if this is already `Parsed`, and otherwise the `raw_data`\n    /// passed in is sliced with the bounds in `Unparsed` and then actually\n    /// parsed.\n    fn parse(\n        &mut self,\n        config: &Config,\n        raw_data: &[u8],\n        source_id: SourceId,\n    ) -> CargoResult<&IndexSummary> {\n        let (start, end) = match self {\n            MaybeIndexSummary::Unparsed { start, end } => (*start, *end),\n            MaybeIndexSummary::Parsed(summary) => return Ok(summary),\n        };\n        let summary = IndexSummary::parse(config, &raw_data[start..end], source_id)?;\n        *self = MaybeIndexSummary::Parsed(summary);\n        match self {\n            MaybeIndexSummary::Unparsed { .. } => unreachable!(),\n            MaybeIndexSummary::Parsed(summary) => Ok(summary),\n        }\n    }\n}\n\nimpl From<IndexSummary> for MaybeIndexSummary {\n    fn from(summary: IndexSummary) -> MaybeIndexSummary {\n        MaybeIndexSummary::Parsed(summary)\n    }\n}\n\nimpl IndexSummary {\n    /// Parses a line from the registry's index file into an [`IndexSummary`]\n    /// for a package.\n    ///\n    /// The `line` provided is expected to be valid JSON. It is supposed to be\n    /// a [`IndexPackage`].\n    fn parse(config: &Config, line: &[u8], source_id: SourceId) -> CargoResult<IndexSummary> {\n        // ****CAUTION**** Please be extremely careful with returning errors\n        // from this function. Entries that error are not included in the\n        // index cache, and can cause cargo to get confused when switching\n        // between different versions that understand the index differently.\n        // Make sure to consider the INDEX_V_MAX and CURRENT_CACHE_VERSION\n        // values carefully when making changes here.\n        let IndexPackage {\n            name,\n            vers,\n            cksum,\n            deps,\n            mut features,\n            features2,\n            yanked,\n            links,\n            rust_version,\n            v,\n        } = serde_json::from_slice(line)?;\n        let v = v.unwrap_or(1);\n        log::trace!(\"json parsed registry {}/{}\", name, vers);\n        let pkgid = PackageId::new(name, &vers, source_id)?;\n        let deps = deps\n            .into_iter()\n            .map(|dep| dep.into_dep(source_id))\n            .collect::<CargoResult<Vec<_>>>()?;\n        if let Some(features2) = features2 {\n            for (name, values) in features2 {\n                features.entry(name).or_default().extend(values);\n            }\n        }\n        let mut summary = Summary::new(config, pkgid, deps, &features, links, rust_version)?;\n        summary.set_checksum(cksum);\n        Ok(IndexSummary {\n            summary,\n            yanked: yanked.unwrap_or(false),\n            v,\n        })\n    }\n}\n\nimpl<'a> RegistryDependency<'a> {\n    /// Converts an encoded dependency in the registry to a cargo dependency\n    pub fn into_dep(self, default: SourceId) -> CargoResult<Dependency> {\n        let RegistryDependency {\n            name,\n            req,\n            mut features,\n            optional,\n            default_features,\n            target,\n            kind,\n            registry,\n            package,\n            public,\n        } = self;\n\n        let id = if let Some(registry) = &registry {\n            SourceId::for_registry(&registry.into_url()?)?\n        } else {\n            default\n        };\n\n        let mut dep = Dependency::parse(package.unwrap_or(name), Some(&req), id)?;\n        if package.is_some() {\n            dep.set_explicit_name_in_toml(name);\n        }\n        let kind = match kind.as_deref().unwrap_or(\"\") {\n            \"dev\" => DepKind::Development,\n            \"build\" => DepKind::Build,\n            _ => DepKind::Normal,\n        };\n\n        let platform = match target {\n            Some(target) => Some(target.parse()?),\n            None => None,\n        };\n\n        // All dependencies are private by default\n        let public = public.unwrap_or(false);\n\n        // Unfortunately older versions of cargo and/or the registry ended up\n        // publishing lots of entries where the features array contained the\n        // empty feature, \"\", inside. This confuses the resolution process much\n        // later on and these features aren't actually valid, so filter them all\n        // out here.\n        features.retain(|s| !s.is_empty());\n\n        // In index, \"registry\" is null if it is from the same index.\n        // In Cargo.toml, \"registry\" is None if it is from the default\n        if !id.is_crates_io() {\n            dep.set_registry_id(id);\n        }\n\n        dep.set_optional(optional)\n            .set_default_features(default_features)\n            .set_features(features)\n            .set_platform(platform)\n            .set_kind(kind)\n            .set_public(public);\n\n        Ok(dep)\n    }\n}\n\n/// Like [`slice::split`] but is optimized by [`memchr`].\nfn split(haystack: &[u8], needle: u8) -> impl Iterator<Item = &[u8]> {\n    struct Split<'a> {\n        haystack: &'a [u8],\n        needle: u8,\n    }\n\n    impl<'a> Iterator for Split<'a> {\n        type Item = &'a [u8];\n\n        fn next(&mut self) -> Option<&'a [u8]> {\n            if self.haystack.is_empty() {\n                return None;\n            }\n            let (ret, remaining) = match memchr::memchr(self.needle, self.haystack) {\n                Some(pos) => (&self.haystack[..pos], &self.haystack[pos + 1..]),\n                None => (self.haystack, &[][..]),\n            };\n            self.haystack = remaining;\n            Some(ret)\n        }\n    }\n\n    Split { haystack, needle }\n}\n\n#[test]\nfn escaped_char_in_index_json_blob() {\n    let _: IndexPackage<'_> = serde_json::from_str(\n        r#\"{\"name\":\"a\",\"vers\":\"0.0.1\",\"deps\":[],\"cksum\":\"bae3\",\"features\":{}}\"#,\n    )\n    .unwrap();\n    let _: IndexPackage<'_> = serde_json::from_str(\n        r#\"{\"name\":\"a\",\"vers\":\"0.0.1\",\"deps\":[],\"cksum\":\"bae3\",\"features\":{\"test\":[\"k\",\"q\"]},\"links\":\"a-sys\"}\"#\n    ).unwrap();\n\n    // Now we add escaped cher all the places they can go\n    // these are not valid, but it should error later than json parsing\n    let _: IndexPackage<'_> = serde_json::from_str(\n        r#\"{\n        \"name\":\"This name has a escaped cher in it \\n\\t\\\" \",\n        \"vers\":\"0.0.1\",\n        \"deps\":[{\n            \"name\": \" \\n\\t\\\" \",\n            \"req\": \" \\n\\t\\\" \",\n            \"features\": [\" \\n\\t\\\" \"],\n            \"optional\": true,\n            \"default_features\": true,\n            \"target\": \" \\n\\t\\\" \",\n            \"kind\": \" \\n\\t\\\" \",\n            \"registry\": \" \\n\\t\\\" \"\n        }],\n        \"cksum\":\"bae3\",\n        \"features\":{\"test \\n\\t\\\" \":[\"k \\n\\t\\\" \",\"q \\n\\t\\\" \"]},\n        \"links\":\" \\n\\t\\\" \"}\"#,\n    )\n    .unwrap();\n}\n", "use std::collections::{BTreeMap, BTreeSet, HashMap};\nuse std::ffi::OsStr;\nuse std::fmt::{self, Display, Write};\nuse std::marker::PhantomData;\nuse std::path::{Path, PathBuf};\nuse std::rc::Rc;\nuse std::str::{self, FromStr};\n\nuse anyhow::{anyhow, bail, Context as _};\nuse cargo_platform::Platform;\nuse cargo_util::paths;\nuse itertools::Itertools;\nuse lazycell::LazyCell;\nuse log::{debug, trace};\nuse semver::{self, VersionReq};\nuse serde::de::IntoDeserializer as _;\nuse serde::de::{self, Unexpected};\nuse serde::ser;\nuse serde::{Deserialize, Serialize};\nuse url::Url;\n\nuse crate::core::compiler::{CompileKind, CompileTarget};\nuse crate::core::dependency::{Artifact, ArtifactTarget, DepKind};\nuse crate::core::manifest::{ManifestMetadata, TargetSourcePath, Warnings};\nuse crate::core::resolver::ResolveBehavior;\nuse crate::core::{find_workspace_root, resolve_relative_path, CliUnstable};\nuse crate::core::{Dependency, Manifest, PackageId, Summary, Target};\nuse crate::core::{Edition, EitherManifest, Feature, Features, VirtualManifest, Workspace};\nuse crate::core::{GitReference, PackageIdSpec, SourceId, WorkspaceConfig, WorkspaceRootConfig};\nuse crate::sources::{CRATES_IO_INDEX, CRATES_IO_REGISTRY};\nuse crate::util::errors::{CargoResult, ManifestError};\nuse crate::util::interning::InternedString;\nuse crate::util::{\n    self, config::ConfigRelativePath, validate_package_name, Config, IntoUrl, VersionReqExt,\n};\n\npub mod embedded;\nmod targets;\nuse self::targets::targets;\n\n/// Loads a `Cargo.toml` from a file on disk.\n///\n/// This could result in a real or virtual manifest being returned.\n///\n/// A list of nested paths is also returned, one for each path dependency\n/// within the manifest. For virtual manifests, these paths can only\n/// come from patched or replaced dependencies. These paths are not\n/// canonicalized.\npub fn read_manifest(\n    path: &Path,\n    source_id: SourceId,\n    config: &Config,\n) -> Result<(EitherManifest, Vec<PathBuf>), ManifestError> {\n    trace!(\n        \"read_manifest; path={}; source-id={}\",\n        path.display(),\n        source_id\n    );\n    let mut contents = paths::read(path).map_err(|err| ManifestError::new(err, path.into()))?;\n    let embedded = is_embedded(path);\n    if embedded {\n        if !config.cli_unstable().script {\n            return Err(ManifestError::new(\n                anyhow::anyhow!(\"parsing `{}` requires `-Zscript`\", path.display()),\n                path.into(),\n            ));\n        }\n        contents = embedded::expand_manifest(&contents, path, config)\n            .map_err(|err| ManifestError::new(err, path.into()))?;\n    }\n\n    read_manifest_from_str(&contents, path, embedded, source_id, config)\n        .with_context(|| format!(\"failed to parse manifest at `{}`\", path.display()))\n        .map_err(|err| ManifestError::new(err, path.into()))\n}\n\nfn is_embedded(path: &Path) -> bool {\n    let ext = path.extension();\n    ext.is_none() || ext == Some(OsStr::new(\"rs\"))\n}\n\n/// Parse an already-loaded `Cargo.toml` as a Cargo manifest.\n///\n/// This could result in a real or virtual manifest being returned.\n///\n/// A list of nested paths is also returned, one for each path dependency\n/// within the manifest. For virtual manifests, these paths can only\n/// come from patched or replaced dependencies. These paths are not\n/// canonicalized.\nfn read_manifest_from_str(\n    contents: &str,\n    manifest_file: &Path,\n    embedded: bool,\n    source_id: SourceId,\n    config: &Config,\n) -> CargoResult<(EitherManifest, Vec<PathBuf>)> {\n    let package_root = manifest_file.parent().unwrap();\n\n    let toml = {\n        let pretty_filename = manifest_file\n            .strip_prefix(config.cwd())\n            .unwrap_or(manifest_file);\n        parse_document(contents, pretty_filename, config)?\n    };\n\n    // Provide a helpful error message for a common user error.\n    if let Some(package) = toml.get(\"package\").or_else(|| toml.get(\"project\")) {\n        if let Some(feats) = package.get(\"cargo-features\") {\n            bail!(\n                \"cargo-features = {} was found in the wrong location: it \\\n                 should be set at the top of Cargo.toml before any tables\",\n                feats\n            );\n        }\n    }\n\n    let mut unused = BTreeSet::new();\n    let manifest: TomlManifest = serde_ignored::deserialize(toml.into_deserializer(), |path| {\n        let mut key = String::new();\n        stringify(&mut key, &path);\n        unused.insert(key);\n    })?;\n    let add_unused = |warnings: &mut Warnings| {\n        for key in unused {\n            warnings.add_warning(format!(\"unused manifest key: {}\", key));\n            if key == \"profiles.debug\" {\n                warnings.add_warning(\"use `[profile.dev]` to configure debug builds\".to_string());\n            }\n        }\n    };\n\n    let manifest = Rc::new(manifest);\n    if let Some(deps) = manifest\n        .workspace\n        .as_ref()\n        .and_then(|ws| ws.dependencies.as_ref())\n    {\n        for (name, dep) in deps {\n            if dep.is_optional() {\n                bail!(\n                    \"{} is optional, but workspace dependencies cannot be optional\",\n                    name\n                );\n            }\n        }\n    }\n    return if manifest.project.is_some() || manifest.package.is_some() {\n        let (mut manifest, paths) =\n            TomlManifest::to_real_manifest(&manifest, embedded, source_id, package_root, config)?;\n        add_unused(manifest.warnings_mut());\n        if manifest.targets().iter().all(|t| t.is_custom_build()) {\n            bail!(\n                \"no targets specified in the manifest\\n\\\n                 either src/lib.rs, src/main.rs, a [lib] section, or \\\n                 [[bin]] section must be present\"\n            )\n        }\n        Ok((EitherManifest::Real(manifest), paths))\n    } else {\n        let (mut m, paths) =\n            TomlManifest::to_virtual_manifest(&manifest, source_id, package_root, config)?;\n        add_unused(m.warnings_mut());\n        Ok((EitherManifest::Virtual(m), paths))\n    };\n\n    fn stringify(dst: &mut String, path: &serde_ignored::Path<'_>) {\n        use serde_ignored::Path;\n\n        match *path {\n            Path::Root => {}\n            Path::Seq { parent, index } => {\n                stringify(dst, parent);\n                if !dst.is_empty() {\n                    dst.push('.');\n                }\n                dst.push_str(&index.to_string());\n            }\n            Path::Map { parent, ref key } => {\n                stringify(dst, parent);\n                if !dst.is_empty() {\n                    dst.push('.');\n                }\n                dst.push_str(key);\n            }\n            Path::Some { parent }\n            | Path::NewtypeVariant { parent }\n            | Path::NewtypeStruct { parent } => stringify(dst, parent),\n        }\n    }\n}\n\npub fn parse_document(toml: &str, _file: &Path, _config: &Config) -> CargoResult<toml::Table> {\n    // At the moment, no compatibility checks are needed.\n    toml.parse()\n        .map_err(|e| anyhow::Error::from(e).context(\"could not parse input as TOML\"))\n}\n\n/// Warn about paths that have been deprecated and may conflict.\nfn warn_on_deprecated(new_path: &str, name: &str, kind: &str, warnings: &mut Vec<String>) {\n    let old_path = new_path.replace(\"-\", \"_\");\n    warnings.push(format!(\n        \"conflicting between `{new_path}` and `{old_path}` in the `{name}` {kind}.\\n\n        `{old_path}` is ignored and not recommended for use in the future\"\n    ))\n}\n\ntype TomlLibTarget = TomlTarget;\ntype TomlBinTarget = TomlTarget;\ntype TomlExampleTarget = TomlTarget;\ntype TomlTestTarget = TomlTarget;\ntype TomlBenchTarget = TomlTarget;\n\n#[derive(Clone, Debug, Serialize)]\n#[serde(untagged)]\npub enum TomlDependency<P: Clone = String> {\n    /// In the simple format, only a version is specified, eg.\n    /// `package = \"<version>\"`\n    Simple(String),\n    /// The simple format is equivalent to a detailed dependency\n    /// specifying only a version, eg.\n    /// `package = { version = \"<version>\" }`\n    Detailed(DetailedTomlDependency<P>),\n}\n\nimpl<'de, P: Deserialize<'de> + Clone> de::Deserialize<'de> for TomlDependency<P> {\n    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        struct TomlDependencyVisitor<P>(PhantomData<P>);\n\n        impl<'de, P: Deserialize<'de> + Clone> de::Visitor<'de> for TomlDependencyVisitor<P> {\n            type Value = TomlDependency<P>;\n\n            fn expecting(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n                formatter.write_str(\n                    \"a version string like \\\"0.9.8\\\" or a \\\n                     detailed dependency like { version = \\\"0.9.8\\\" }\",\n                )\n            }\n\n            fn visit_str<E>(self, s: &str) -> Result<Self::Value, E>\n            where\n                E: de::Error,\n            {\n                Ok(TomlDependency::Simple(s.to_owned()))\n            }\n\n            fn visit_map<V>(self, map: V) -> Result<Self::Value, V::Error>\n            where\n                V: de::MapAccess<'de>,\n            {\n                let mvd = de::value::MapAccessDeserializer::new(map);\n                DetailedTomlDependency::deserialize(mvd).map(TomlDependency::Detailed)\n            }\n        }\n        deserializer.deserialize_any(TomlDependencyVisitor(PhantomData))\n    }\n}\n\nimpl TomlDependency {\n    fn unused_keys(&self) -> Vec<String> {\n        match self {\n            TomlDependency::Simple(_) => vec![],\n            TomlDependency::Detailed(detailed) => detailed.other.keys().cloned().collect(),\n        }\n    }\n}\n\npub trait ResolveToPath {\n    fn resolve(&self, config: &Config) -> PathBuf;\n}\n\nimpl ResolveToPath for String {\n    fn resolve(&self, _: &Config) -> PathBuf {\n        self.into()\n    }\n}\n\nimpl ResolveToPath for ConfigRelativePath {\n    fn resolve(&self, c: &Config) -> PathBuf {\n        self.resolve_path(c)\n    }\n}\n\n#[derive(Deserialize, Serialize, Clone, Debug)]\n#[serde(rename_all = \"kebab-case\")]\npub struct DetailedTomlDependency<P: Clone = String> {\n    version: Option<String>,\n    registry: Option<String>,\n    /// The URL of the `registry` field.\n    /// This is an internal implementation detail. When Cargo creates a\n    /// package, it replaces `registry` with `registry-index` so that the\n    /// manifest contains the correct URL. All users won't have the same\n    /// registry names configured, so Cargo can't rely on just the name for\n    /// crates published by other users.\n    registry_index: Option<String>,\n    // `path` is relative to the file it appears in. If that's a `Cargo.toml`, it'll be relative to\n    // that TOML file, and if it's a `.cargo/config` file, it'll be relative to that file.\n    path: Option<P>,\n    git: Option<String>,\n    branch: Option<String>,\n    tag: Option<String>,\n    rev: Option<String>,\n    features: Option<Vec<String>>,\n    optional: Option<bool>,\n    default_features: Option<bool>,\n    #[serde(rename = \"default_features\")]\n    default_features2: Option<bool>,\n    package: Option<String>,\n    public: Option<bool>,\n\n    /// One or more of `bin`, `cdylib`, `staticlib`, `bin:<name>`.\n    artifact: Option<StringOrVec>,\n    /// If set, the artifact should also be a dependency\n    lib: Option<bool>,\n    /// A platform name, like `x86_64-apple-darwin`\n    target: Option<String>,\n    /// This is here to provide a way to see the \"unused manifest keys\" when deserializing\n    #[serde(skip_serializing)]\n    #[serde(flatten)]\n    other: BTreeMap<String, toml::Value>,\n}\n\n// Explicit implementation so we avoid pulling in P: Default\nimpl<P: Clone> Default for DetailedTomlDependency<P> {\n    fn default() -> Self {\n        Self {\n            version: Default::default(),\n            registry: Default::default(),\n            registry_index: Default::default(),\n            path: Default::default(),\n            git: Default::default(),\n            branch: Default::default(),\n            tag: Default::default(),\n            rev: Default::default(),\n            features: Default::default(),\n            optional: Default::default(),\n            default_features: Default::default(),\n            default_features2: Default::default(),\n            package: Default::default(),\n            public: Default::default(),\n            artifact: Default::default(),\n            lib: Default::default(),\n            target: Default::default(),\n            other: Default::default(),\n        }\n    }\n}\n\n/// This type is used to deserialize `Cargo.toml` files.\n#[derive(Debug, Deserialize, Serialize)]\n#[serde(rename_all = \"kebab-case\")]\npub struct TomlManifest {\n    cargo_features: Option<Vec<String>>,\n    package: Option<Box<TomlPackage>>,\n    project: Option<Box<TomlPackage>>,\n    profile: Option<TomlProfiles>,\n    lib: Option<TomlLibTarget>,\n    bin: Option<Vec<TomlBinTarget>>,\n    example: Option<Vec<TomlExampleTarget>>,\n    test: Option<Vec<TomlTestTarget>>,\n    bench: Option<Vec<TomlTestTarget>>,\n    dependencies: Option<BTreeMap<String, MaybeWorkspaceDependency>>,\n    dev_dependencies: Option<BTreeMap<String, MaybeWorkspaceDependency>>,\n    #[serde(rename = \"dev_dependencies\")]\n    dev_dependencies2: Option<BTreeMap<String, MaybeWorkspaceDependency>>,\n    build_dependencies: Option<BTreeMap<String, MaybeWorkspaceDependency>>,\n    #[serde(rename = \"build_dependencies\")]\n    build_dependencies2: Option<BTreeMap<String, MaybeWorkspaceDependency>>,\n    features: Option<BTreeMap<InternedString, Vec<InternedString>>>,\n    target: Option<BTreeMap<String, TomlPlatform>>,\n    replace: Option<BTreeMap<String, TomlDependency>>,\n    patch: Option<BTreeMap<String, BTreeMap<String, TomlDependency>>>,\n    workspace: Option<TomlWorkspace>,\n    badges: Option<MaybeWorkspaceBtreeMap>,\n    lints: Option<toml::Value>,\n}\n\n#[derive(Deserialize, Serialize, Clone, Debug, Default)]\npub struct TomlProfiles(BTreeMap<InternedString, TomlProfile>);\n\nimpl TomlProfiles {\n    pub fn get_all(&self) -> &BTreeMap<InternedString, TomlProfile> {\n        &self.0\n    }\n\n    pub fn get(&self, name: &str) -> Option<&TomlProfile> {\n        self.0.get(name)\n    }\n\n    /// Checks syntax validity and unstable feature gate for each profile.\n    ///\n    /// It's a bit unfortunate both `-Z` flags and `cargo-features` are required,\n    /// because profiles can now be set in either `Cargo.toml` or `config.toml`.\n    pub fn validate(\n        &self,\n        cli_unstable: &CliUnstable,\n        features: &Features,\n        warnings: &mut Vec<String>,\n    ) -> CargoResult<()> {\n        for (name, profile) in &self.0 {\n            profile.validate(name, cli_unstable, features, warnings)?;\n        }\n        Ok(())\n    }\n}\n\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct TomlOptLevel(pub String);\n\nimpl<'de> de::Deserialize<'de> for TomlOptLevel {\n    fn deserialize<D>(d: D) -> Result<TomlOptLevel, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        struct Visitor;\n\n        impl<'de> de::Visitor<'de> for Visitor {\n            type Value = TomlOptLevel;\n\n            fn expecting(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n                formatter.write_str(\"an optimization level\")\n            }\n\n            fn visit_i64<E>(self, value: i64) -> Result<TomlOptLevel, E>\n            where\n                E: de::Error,\n            {\n                Ok(TomlOptLevel(value.to_string()))\n            }\n\n            fn visit_str<E>(self, value: &str) -> Result<TomlOptLevel, E>\n            where\n                E: de::Error,\n            {\n                if value == \"s\" || value == \"z\" {\n                    Ok(TomlOptLevel(value.to_string()))\n                } else {\n                    Err(E::custom(format!(\n                        \"must be `0`, `1`, `2`, `3`, `s` or `z`, \\\n                         but found the string: \\\"{}\\\"\",\n                        value\n                    )))\n                }\n            }\n        }\n\n        d.deserialize_any(Visitor)\n    }\n}\n\nimpl ser::Serialize for TomlOptLevel {\n    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>\n    where\n        S: ser::Serializer,\n    {\n        match self.0.parse::<u32>() {\n            Ok(n) => n.serialize(serializer),\n            Err(_) => self.0.serialize(serializer),\n        }\n    }\n}\n\n#[derive(Copy, Clone, Debug, Eq, PartialEq, Hash, PartialOrd, Ord)]\npub enum TomlDebugInfo {\n    None,\n    LineDirectivesOnly,\n    LineTablesOnly,\n    Limited,\n    Full,\n}\n\nimpl ser::Serialize for TomlDebugInfo {\n    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>\n    where\n        S: ser::Serializer,\n    {\n        match self {\n            Self::None => 0.serialize(serializer),\n            Self::LineDirectivesOnly => \"line-directives-only\".serialize(serializer),\n            Self::LineTablesOnly => \"line-tables-only\".serialize(serializer),\n            Self::Limited => 1.serialize(serializer),\n            Self::Full => 2.serialize(serializer),\n        }\n    }\n}\n\nimpl<'de> de::Deserialize<'de> for TomlDebugInfo {\n    fn deserialize<D>(d: D) -> Result<TomlDebugInfo, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        struct Visitor;\n\n        impl<'de> de::Visitor<'de> for Visitor {\n            type Value = TomlDebugInfo;\n\n            fn expecting(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n                formatter.write_str(\n                    \"a boolean, 0, 1, 2, \\\"line-tables-only\\\", or \\\"line-directives-only\\\"\",\n                )\n            }\n\n            fn visit_i64<E>(self, value: i64) -> Result<TomlDebugInfo, E>\n            where\n                E: de::Error,\n            {\n                let debuginfo = match value {\n                    0 => TomlDebugInfo::None,\n                    1 => TomlDebugInfo::Limited,\n                    2 => TomlDebugInfo::Full,\n                    _ => return Err(de::Error::invalid_value(Unexpected::Signed(value), &self)),\n                };\n                Ok(debuginfo)\n            }\n\n            fn visit_bool<E>(self, v: bool) -> Result<Self::Value, E>\n            where\n                E: de::Error,\n            {\n                Ok(if v {\n                    TomlDebugInfo::Full\n                } else {\n                    TomlDebugInfo::None\n                })\n            }\n\n            fn visit_str<E>(self, value: &str) -> Result<TomlDebugInfo, E>\n            where\n                E: de::Error,\n            {\n                let debuginfo = match value {\n                    \"none\" => TomlDebugInfo::None,\n                    \"limited\" => TomlDebugInfo::Limited,\n                    \"full\" => TomlDebugInfo::Full,\n                    \"line-directives-only\" => TomlDebugInfo::LineDirectivesOnly,\n                    \"line-tables-only\" => TomlDebugInfo::LineTablesOnly,\n                    _ => return Err(de::Error::invalid_value(Unexpected::Str(value), &self)),\n                };\n                Ok(debuginfo)\n            }\n        }\n\n        d.deserialize_any(Visitor)\n    }\n}\n\nimpl Display for TomlDebugInfo {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            TomlDebugInfo::None => f.write_char('0'),\n            TomlDebugInfo::Limited => f.write_char('1'),\n            TomlDebugInfo::Full => f.write_char('2'),\n            TomlDebugInfo::LineDirectivesOnly => f.write_str(\"line-directives-only\"),\n            TomlDebugInfo::LineTablesOnly => f.write_str(\"line-tables-only\"),\n        }\n    }\n}\n\n#[derive(Deserialize, Serialize, Clone, Debug, Default, Eq, PartialEq)]\n#[serde(default, rename_all = \"kebab-case\")]\npub struct TomlProfile {\n    pub opt_level: Option<TomlOptLevel>,\n    pub lto: Option<StringOrBool>,\n    pub codegen_backend: Option<InternedString>,\n    pub codegen_units: Option<u32>,\n    pub debug: Option<TomlDebugInfo>,\n    pub split_debuginfo: Option<String>,\n    pub debug_assertions: Option<bool>,\n    pub rpath: Option<bool>,\n    pub panic: Option<String>,\n    pub overflow_checks: Option<bool>,\n    pub incremental: Option<bool>,\n    pub dir_name: Option<InternedString>,\n    pub inherits: Option<InternedString>,\n    pub strip: Option<StringOrBool>,\n    // Note that `rustflags` is used for the cargo-feature `profile_rustflags`\n    pub rustflags: Option<Vec<InternedString>>,\n    // These two fields must be last because they are sub-tables, and TOML\n    // requires all non-tables to be listed first.\n    pub package: Option<BTreeMap<ProfilePackageSpec, TomlProfile>>,\n    pub build_override: Option<Box<TomlProfile>>,\n}\n\n#[derive(Clone, Debug, PartialEq, Eq, Ord, PartialOrd, Hash)]\npub enum ProfilePackageSpec {\n    Spec(PackageIdSpec),\n    All,\n}\n\nimpl ser::Serialize for ProfilePackageSpec {\n    fn serialize<S>(&self, s: S) -> Result<S::Ok, S::Error>\n    where\n        S: ser::Serializer,\n    {\n        self.to_string().serialize(s)\n    }\n}\n\nimpl<'de> de::Deserialize<'de> for ProfilePackageSpec {\n    fn deserialize<D>(d: D) -> Result<ProfilePackageSpec, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        let string = String::deserialize(d)?;\n        if string == \"*\" {\n            Ok(ProfilePackageSpec::All)\n        } else {\n            PackageIdSpec::parse(&string)\n                .map_err(de::Error::custom)\n                .map(ProfilePackageSpec::Spec)\n        }\n    }\n}\n\nimpl fmt::Display for ProfilePackageSpec {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            ProfilePackageSpec::Spec(spec) => spec.fmt(f),\n            ProfilePackageSpec::All => f.write_str(\"*\"),\n        }\n    }\n}\n\nimpl TomlProfile {\n    /// Checks stytax validity and unstable feature gate for a given profile.\n    pub fn validate(\n        &self,\n        name: &str,\n        cli_unstable: &CliUnstable,\n        features: &Features,\n        warnings: &mut Vec<String>,\n    ) -> CargoResult<()> {\n        self.validate_profile(name, cli_unstable, features)?;\n        if let Some(ref profile) = self.build_override {\n            profile.validate_override(\"build-override\")?;\n            profile.validate_profile(&format!(\"{name}.build-override\"), cli_unstable, features)?;\n        }\n        if let Some(ref packages) = self.package {\n            for (override_name, profile) in packages {\n                profile.validate_override(\"package\")?;\n                profile.validate_profile(\n                    &format!(\"{name}.package.{override_name}\"),\n                    cli_unstable,\n                    features,\n                )?;\n            }\n        }\n\n        // Profile name validation\n        Self::validate_name(name)?;\n\n        if let Some(dir_name) = self.dir_name {\n            // This is disabled for now, as we would like to stabilize named\n            // profiles without this, and then decide in the future if it is\n            // needed. This helps simplify the UI a little.\n            bail!(\n                \"dir-name=\\\"{}\\\" in profile `{}` is not currently allowed, \\\n                 directory names are tied to the profile name for custom profiles\",\n                dir_name,\n                name\n            );\n        }\n\n        // `inherits` validation\n        if matches!(self.inherits.map(|s| s.as_str()), Some(\"debug\")) {\n            bail!(\n                \"profile.{}.inherits=\\\"debug\\\" should be profile.{}.inherits=\\\"dev\\\"\",\n                name,\n                name\n            );\n        }\n\n        match name {\n            \"doc\" => {\n                warnings.push(\"profile `doc` is deprecated and has no effect\".to_string());\n            }\n            \"test\" | \"bench\" => {\n                if self.panic.is_some() {\n                    warnings.push(format!(\"`panic` setting is ignored for `{}` profile\", name))\n                }\n            }\n            _ => {}\n        }\n\n        if let Some(panic) = &self.panic {\n            if panic != \"unwind\" && panic != \"abort\" {\n                bail!(\n                    \"`panic` setting of `{}` is not a valid setting, \\\n                     must be `unwind` or `abort`\",\n                    panic\n                );\n            }\n        }\n\n        if let Some(StringOrBool::String(arg)) = &self.lto {\n            if arg == \"true\" || arg == \"false\" {\n                bail!(\n                    \"`lto` setting of string `\\\"{arg}\\\"` for `{name}` profile is not \\\n                     a valid setting, must be a boolean (`true`/`false`) or a string \\\n                    (`\\\"thin\\\"`/`\\\"fat\\\"`/`\\\"off\\\"`) or omitted.\",\n                );\n            }\n        }\n\n        Ok(())\n    }\n\n    /// Validate dir-names and profile names according to RFC 2678.\n    pub fn validate_name(name: &str) -> CargoResult<()> {\n        if let Some(ch) = name\n            .chars()\n            .find(|ch| !ch.is_alphanumeric() && *ch != '_' && *ch != '-')\n        {\n            bail!(\n                \"invalid character `{}` in profile name `{}`\\n\\\n                Allowed characters are letters, numbers, underscore, and hyphen.\",\n                ch,\n                name\n            );\n        }\n\n        const SEE_DOCS: &str = \"See https://doc.rust-lang.org/cargo/reference/profiles.html \\\n            for more on configuring profiles.\";\n\n        let lower_name = name.to_lowercase();\n        if lower_name == \"debug\" {\n            bail!(\n                \"profile name `{}` is reserved\\n\\\n                 To configure the default development profile, use the name `dev` \\\n                 as in [profile.dev]\\n\\\n                {}\",\n                name,\n                SEE_DOCS\n            );\n        }\n        if lower_name == \"build-override\" {\n            bail!(\n                \"profile name `{}` is reserved\\n\\\n                 To configure build dependency settings, use [profile.dev.build-override] \\\n                 and [profile.release.build-override]\\n\\\n                 {}\",\n                name,\n                SEE_DOCS\n            );\n        }\n\n        // These are some arbitrary reservations. We have no plans to use\n        // these, but it seems safer to reserve a few just in case we want to\n        // add more built-in profiles in the future. We can also uses special\n        // syntax like cargo:foo if needed. But it is unlikely these will ever\n        // be used.\n        if matches!(\n            lower_name.as_str(),\n            \"build\"\n                | \"check\"\n                | \"clean\"\n                | \"config\"\n                | \"fetch\"\n                | \"fix\"\n                | \"install\"\n                | \"metadata\"\n                | \"package\"\n                | \"publish\"\n                | \"report\"\n                | \"root\"\n                | \"run\"\n                | \"rust\"\n                | \"rustc\"\n                | \"rustdoc\"\n                | \"target\"\n                | \"tmp\"\n                | \"uninstall\"\n        ) || lower_name.starts_with(\"cargo\")\n        {\n            bail!(\n                \"profile name `{}` is reserved\\n\\\n                 Please choose a different name.\\n\\\n                 {}\",\n                name,\n                SEE_DOCS\n            );\n        }\n\n        Ok(())\n    }\n\n    /// Validates a profile.\n    ///\n    /// This is a shallow check, which is reused for the profile itself and any overrides.\n    fn validate_profile(\n        &self,\n        name: &str,\n        cli_unstable: &CliUnstable,\n        features: &Features,\n    ) -> CargoResult<()> {\n        if let Some(codegen_backend) = &self.codegen_backend {\n            match (\n                features.require(Feature::codegen_backend()),\n                cli_unstable.codegen_backend,\n            ) {\n                (Err(e), false) => return Err(e),\n                _ => {}\n            }\n\n            if codegen_backend.contains(|c: char| !c.is_ascii_alphanumeric() && c != '_') {\n                bail!(\n                    \"`profile.{}.codegen-backend` setting of `{}` is not a valid backend name.\",\n                    name,\n                    codegen_backend,\n                );\n            }\n        }\n        if self.rustflags.is_some() {\n            match (\n                features.require(Feature::profile_rustflags()),\n                cli_unstable.profile_rustflags,\n            ) {\n                (Err(e), false) => return Err(e),\n                _ => {}\n            }\n        }\n        Ok(())\n    }\n\n    /// Validation that is specific to an override.\n    fn validate_override(&self, which: &str) -> CargoResult<()> {\n        if self.package.is_some() {\n            bail!(\"package-specific profiles cannot be nested\");\n        }\n        if self.build_override.is_some() {\n            bail!(\"build-override profiles cannot be nested\");\n        }\n        if self.panic.is_some() {\n            bail!(\"`panic` may not be specified in a `{}` profile\", which)\n        }\n        if self.lto.is_some() {\n            bail!(\"`lto` may not be specified in a `{}` profile\", which)\n        }\n        if self.rpath.is_some() {\n            bail!(\"`rpath` may not be specified in a `{}` profile\", which)\n        }\n        Ok(())\n    }\n\n    /// Overwrite self's values with the given profile.\n    pub fn merge(&mut self, profile: &TomlProfile) {\n        if let Some(v) = &profile.opt_level {\n            self.opt_level = Some(v.clone());\n        }\n\n        if let Some(v) = &profile.lto {\n            self.lto = Some(v.clone());\n        }\n\n        if let Some(v) = profile.codegen_backend {\n            self.codegen_backend = Some(v);\n        }\n\n        if let Some(v) = profile.codegen_units {\n            self.codegen_units = Some(v);\n        }\n\n        if let Some(v) = &profile.debug {\n            self.debug = Some(v.clone());\n        }\n\n        if let Some(v) = profile.debug_assertions {\n            self.debug_assertions = Some(v);\n        }\n\n        if let Some(v) = &profile.split_debuginfo {\n            self.split_debuginfo = Some(v.clone());\n        }\n\n        if let Some(v) = profile.rpath {\n            self.rpath = Some(v);\n        }\n\n        if let Some(v) = &profile.panic {\n            self.panic = Some(v.clone());\n        }\n\n        if let Some(v) = profile.overflow_checks {\n            self.overflow_checks = Some(v);\n        }\n\n        if let Some(v) = profile.incremental {\n            self.incremental = Some(v);\n        }\n\n        if let Some(v) = &profile.rustflags {\n            self.rustflags = Some(v.clone());\n        }\n\n        if let Some(other_package) = &profile.package {\n            match &mut self.package {\n                Some(self_package) => {\n                    for (spec, other_pkg_profile) in other_package {\n                        match self_package.get_mut(spec) {\n                            Some(p) => p.merge(other_pkg_profile),\n                            None => {\n                                self_package.insert(spec.clone(), other_pkg_profile.clone());\n                            }\n                        }\n                    }\n                }\n                None => self.package = Some(other_package.clone()),\n            }\n        }\n\n        if let Some(other_bo) = &profile.build_override {\n            match &mut self.build_override {\n                Some(self_bo) => self_bo.merge(other_bo),\n                None => self.build_override = Some(other_bo.clone()),\n            }\n        }\n\n        if let Some(v) = &profile.inherits {\n            self.inherits = Some(*v);\n        }\n\n        if let Some(v) = &profile.dir_name {\n            self.dir_name = Some(*v);\n        }\n\n        if let Some(v) = &profile.strip {\n            self.strip = Some(v.clone());\n        }\n    }\n}\n\n/// A StringOrVec can be parsed from either a TOML string or array,\n/// but is always stored as a vector.\n#[derive(Clone, Debug, Serialize, Eq, PartialEq, PartialOrd, Ord)]\npub struct StringOrVec(Vec<String>);\n\nimpl<'de> de::Deserialize<'de> for StringOrVec {\n    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        struct Visitor;\n\n        impl<'de> de::Visitor<'de> for Visitor {\n            type Value = StringOrVec;\n\n            fn expecting(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n                formatter.write_str(\"string or list of strings\")\n            }\n\n            fn visit_str<E>(self, s: &str) -> Result<Self::Value, E>\n            where\n                E: de::Error,\n            {\n                Ok(StringOrVec(vec![s.to_string()]))\n            }\n\n            fn visit_seq<V>(self, v: V) -> Result<Self::Value, V::Error>\n            where\n                V: de::SeqAccess<'de>,\n            {\n                let seq = de::value::SeqAccessDeserializer::new(v);\n                Vec::deserialize(seq).map(StringOrVec)\n            }\n        }\n\n        deserializer.deserialize_any(Visitor)\n    }\n}\n\nimpl StringOrVec {\n    pub fn iter<'a>(&'a self) -> std::slice::Iter<'a, String> {\n        self.0.iter()\n    }\n}\n\n#[derive(Clone, Debug, Deserialize, Serialize, Eq, PartialEq)]\n#[serde(untagged, expecting = \"expected a boolean or a string\")]\npub enum StringOrBool {\n    String(String),\n    Bool(bool),\n}\n\n#[derive(PartialEq, Clone, Debug, Serialize)]\n#[serde(untagged)]\npub enum VecStringOrBool {\n    VecString(Vec<String>),\n    Bool(bool),\n}\n\nimpl<'de> de::Deserialize<'de> for VecStringOrBool {\n    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        struct Visitor;\n\n        impl<'de> de::Visitor<'de> for Visitor {\n            type Value = VecStringOrBool;\n\n            fn expecting(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n                formatter.write_str(\"a boolean or vector of strings\")\n            }\n\n            fn visit_seq<V>(self, v: V) -> Result<Self::Value, V::Error>\n            where\n                V: de::SeqAccess<'de>,\n            {\n                let seq = de::value::SeqAccessDeserializer::new(v);\n                Vec::deserialize(seq).map(VecStringOrBool::VecString)\n            }\n\n            fn visit_bool<E>(self, b: bool) -> Result<Self::Value, E>\n            where\n                E: de::Error,\n            {\n                Ok(VecStringOrBool::Bool(b))\n            }\n        }\n\n        deserializer.deserialize_any(Visitor)\n    }\n}\n\nfn version_trim_whitespace<'de, D>(deserializer: D) -> Result<MaybeWorkspaceSemverVersion, D::Error>\nwhere\n    D: de::Deserializer<'de>,\n{\n    struct Visitor;\n\n    impl<'de> de::Visitor<'de> for Visitor {\n        type Value = MaybeWorkspaceSemverVersion;\n\n        fn expecting(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n            formatter.write_str(\"SemVer version\")\n        }\n\n        fn visit_str<E>(self, string: &str) -> Result<Self::Value, E>\n        where\n            E: de::Error,\n        {\n            match string.trim().parse().map_err(de::Error::custom) {\n                Ok(parsed) => Ok(MaybeWorkspace::Defined(parsed)),\n                Err(e) => Err(e),\n            }\n        }\n\n        fn visit_map<V>(self, map: V) -> Result<Self::Value, V::Error>\n        where\n            V: de::MapAccess<'de>,\n        {\n            let mvd = de::value::MapAccessDeserializer::new(map);\n            TomlWorkspaceField::deserialize(mvd).map(MaybeWorkspace::Workspace)\n        }\n    }\n\n    deserializer.deserialize_any(Visitor)\n}\n\n/// This Trait exists to make [`MaybeWorkspace::Workspace`] generic. It makes deserialization of\n/// [`MaybeWorkspace`] much easier, as well as making error messages for\n/// [`MaybeWorkspace::resolve`] much nicer\n///\n/// Implementors should have a field `workspace` with the type of `bool`. It is used to ensure\n/// `workspace` is not `false` in a `Cargo.toml`\npub trait WorkspaceInherit {\n    /// This is the workspace table that is being inherited from.\n    /// For example `[workspace.dependencies]` would be the table \"dependencies\"\n    fn inherit_toml_table(&self) -> &str;\n\n    /// This is used to output the value of the implementors `workspace` field\n    fn workspace(&self) -> bool;\n}\n\n/// An enum that allows for inheriting keys from a workspace in a Cargo.toml.\n#[derive(Serialize, Clone, Debug)]\n#[serde(untagged)]\npub enum MaybeWorkspace<T, W: WorkspaceInherit> {\n    /// The \"defined\" type, or the type that that is used when not inheriting from a workspace.\n    Defined(T),\n    /// The type when inheriting from a workspace.\n    Workspace(W),\n}\n\nimpl<T, W: WorkspaceInherit> MaybeWorkspace<T, W> {\n    fn resolve<'a>(\n        self,\n        label: &str,\n        get_ws_inheritable: impl FnOnce() -> CargoResult<T>,\n    ) -> CargoResult<T> {\n        match self {\n            MaybeWorkspace::Defined(value) => Ok(value),\n            MaybeWorkspace::Workspace(w) => get_ws_inheritable().with_context(|| {\n                format!(\n                \"error inheriting `{label}` from workspace root manifest's `workspace.{}.{label}`\",\n                w.inherit_toml_table(),\n            )\n            }),\n        }\n    }\n\n    fn resolve_with_self<'a>(\n        self,\n        label: &str,\n        get_ws_inheritable: impl FnOnce(&W) -> CargoResult<T>,\n    ) -> CargoResult<T> {\n        match self {\n            MaybeWorkspace::Defined(value) => Ok(value),\n            MaybeWorkspace::Workspace(w) => get_ws_inheritable(&w).with_context(|| {\n                format!(\n                \"error inheriting `{label}` from workspace root manifest's `workspace.{}.{label}`\",\n                w.inherit_toml_table(),\n            )\n            }),\n        }\n    }\n\n    fn as_defined(&self) -> Option<&T> {\n        match self {\n            MaybeWorkspace::Workspace(_) => None,\n            MaybeWorkspace::Defined(defined) => Some(defined),\n        }\n    }\n}\n\ntype MaybeWorkspaceDependency = MaybeWorkspace<TomlDependency, TomlWorkspaceDependency>;\n\nimpl<'de> de::Deserialize<'de> for MaybeWorkspaceDependency {\n    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        let value = serde_value::Value::deserialize(deserializer)?;\n\n        if let Ok(w) = TomlWorkspaceDependency::deserialize(serde_value::ValueDeserializer::<\n            D::Error,\n        >::new(value.clone()))\n        {\n            return if w.workspace() {\n                Ok(MaybeWorkspace::Workspace(w))\n            } else {\n                Err(de::Error::custom(\"`workspace` cannot be false\"))\n            };\n        }\n        TomlDependency::deserialize(serde_value::ValueDeserializer::<D::Error>::new(value))\n            .map(MaybeWorkspace::Defined)\n    }\n}\n\nimpl MaybeWorkspaceDependency {\n    fn unused_keys(&self) -> Vec<String> {\n        match self {\n            MaybeWorkspaceDependency::Defined(d) => d.unused_keys(),\n            MaybeWorkspaceDependency::Workspace(w) => w.other.keys().cloned().collect(),\n        }\n    }\n}\n\n#[derive(Deserialize, Serialize, Clone, Debug)]\n#[serde(rename_all = \"kebab-case\")]\npub struct TomlWorkspaceDependency {\n    workspace: bool,\n    features: Option<Vec<String>>,\n    default_features: Option<bool>,\n    #[serde(rename = \"default_features\")]\n    default_features2: Option<bool>,\n    optional: Option<bool>,\n    /// This is here to provide a way to see the \"unused manifest keys\" when deserializing\n    #[serde(skip_serializing)]\n    #[serde(flatten)]\n    other: BTreeMap<String, toml::Value>,\n}\n\nimpl WorkspaceInherit for TomlWorkspaceDependency {\n    fn inherit_toml_table(&self) -> &str {\n        \"dependencies\"\n    }\n\n    fn workspace(&self) -> bool {\n        self.workspace\n    }\n}\n\nimpl TomlWorkspaceDependency {\n    fn resolve<'a>(\n        &self,\n        name: &str,\n        inheritable: impl FnOnce() -> CargoResult<&'a InheritableFields>,\n        cx: &mut Context<'_, '_>,\n    ) -> CargoResult<TomlDependency> {\n        fn default_features_msg(label: &str, ws_def_feat: Option<bool>, cx: &mut Context<'_, '_>) {\n            let ws_def_feat = match ws_def_feat {\n                Some(true) => \"true\",\n                Some(false) => \"false\",\n                None => \"not specified\",\n            };\n            cx.warnings.push(format!(\n                \"`default-features` is ignored for {label}, since `default-features` was \\\n                {ws_def_feat} for `workspace.dependencies.{label}`, \\\n                this could become a hard error in the future\"\n            ))\n        }\n        if self.default_features.is_some() && self.default_features2.is_some() {\n            warn_on_deprecated(\"default-features\", name, \"dependency\", cx.warnings);\n        }\n        inheritable()?.get_dependency(name, cx.root).map(|d| {\n            match d {\n                TomlDependency::Simple(s) => {\n                    if let Some(false) = self.default_features.or(self.default_features2) {\n                        default_features_msg(name, None, cx);\n                    }\n                    if self.optional.is_some() || self.features.is_some() {\n                        TomlDependency::Detailed(DetailedTomlDependency {\n                            version: Some(s),\n                            optional: self.optional,\n                            features: self.features.clone(),\n                            ..Default::default()\n                        })\n                    } else {\n                        TomlDependency::Simple(s)\n                    }\n                }\n                TomlDependency::Detailed(d) => {\n                    let mut d = d.clone();\n                    match (\n                        self.default_features.or(self.default_features2),\n                        d.default_features.or(d.default_features2),\n                    ) {\n                        // member: default-features = true and\n                        // workspace: default-features = false should turn on\n                        // default-features\n                        (Some(true), Some(false)) => {\n                            d.default_features = Some(true);\n                        }\n                        // member: default-features = false and\n                        // workspace: default-features = true should ignore member\n                        // default-features\n                        (Some(false), Some(true)) => {\n                            default_features_msg(name, Some(true), cx);\n                        }\n                        // member: default-features = false and\n                        // workspace: dep = \"1.0\" should ignore member default-features\n                        (Some(false), None) => {\n                            default_features_msg(name, None, cx);\n                        }\n                        _ => {}\n                    }\n                    d.add_features(self.features.clone());\n                    d.update_optional(self.optional);\n                    TomlDependency::Detailed(d)\n                }\n            }\n        })\n    }\n}\n\n//. This already has a `Deserialize` impl from version_trim_whitespace\ntype MaybeWorkspaceSemverVersion = MaybeWorkspace<semver::Version, TomlWorkspaceField>;\n\ntype MaybeWorkspaceString = MaybeWorkspace<String, TomlWorkspaceField>;\nimpl<'de> de::Deserialize<'de> for MaybeWorkspaceString {\n    fn deserialize<D>(d: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        struct Visitor;\n\n        impl<'de> de::Visitor<'de> for Visitor {\n            type Value = MaybeWorkspaceString;\n\n            fn expecting(&self, f: &mut fmt::Formatter<'_>) -> Result<(), std::fmt::Error> {\n                f.write_str(\"a string or workspace\")\n            }\n\n            fn visit_string<E>(self, value: String) -> Result<Self::Value, E>\n            where\n                E: de::Error,\n            {\n                Ok(MaybeWorkspaceString::Defined(value))\n            }\n\n            fn visit_map<V>(self, map: V) -> Result<Self::Value, V::Error>\n            where\n                V: de::MapAccess<'de>,\n            {\n                let mvd = de::value::MapAccessDeserializer::new(map);\n                TomlWorkspaceField::deserialize(mvd).map(MaybeWorkspace::Workspace)\n            }\n        }\n\n        d.deserialize_any(Visitor)\n    }\n}\n\ntype MaybeWorkspaceVecString = MaybeWorkspace<Vec<String>, TomlWorkspaceField>;\nimpl<'de> de::Deserialize<'de> for MaybeWorkspaceVecString {\n    fn deserialize<D>(d: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        struct Visitor;\n\n        impl<'de> de::Visitor<'de> for Visitor {\n            type Value = MaybeWorkspaceVecString;\n\n            fn expecting(&self, f: &mut fmt::Formatter<'_>) -> Result<(), fmt::Error> {\n                f.write_str(\"a vector of strings or workspace\")\n            }\n            fn visit_seq<A>(self, v: A) -> Result<Self::Value, A::Error>\n            where\n                A: de::SeqAccess<'de>,\n            {\n                let seq = de::value::SeqAccessDeserializer::new(v);\n                Vec::deserialize(seq).map(MaybeWorkspace::Defined)\n            }\n\n            fn visit_map<V>(self, map: V) -> Result<Self::Value, V::Error>\n            where\n                V: de::MapAccess<'de>,\n            {\n                let mvd = de::value::MapAccessDeserializer::new(map);\n                TomlWorkspaceField::deserialize(mvd).map(MaybeWorkspace::Workspace)\n            }\n        }\n\n        d.deserialize_any(Visitor)\n    }\n}\n\ntype MaybeWorkspaceStringOrBool = MaybeWorkspace<StringOrBool, TomlWorkspaceField>;\nimpl<'de> de::Deserialize<'de> for MaybeWorkspaceStringOrBool {\n    fn deserialize<D>(d: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        struct Visitor;\n\n        impl<'de> de::Visitor<'de> for Visitor {\n            type Value = MaybeWorkspaceStringOrBool;\n\n            fn expecting(&self, f: &mut fmt::Formatter<'_>) -> Result<(), fmt::Error> {\n                f.write_str(\"a string, a bool, or workspace\")\n            }\n\n            fn visit_bool<E>(self, v: bool) -> Result<Self::Value, E>\n            where\n                E: de::Error,\n            {\n                let b = de::value::BoolDeserializer::new(v);\n                StringOrBool::deserialize(b).map(MaybeWorkspace::Defined)\n            }\n\n            fn visit_string<E>(self, v: String) -> Result<Self::Value, E>\n            where\n                E: de::Error,\n            {\n                let string = de::value::StringDeserializer::new(v);\n                StringOrBool::deserialize(string).map(MaybeWorkspace::Defined)\n            }\n\n            fn visit_map<V>(self, map: V) -> Result<Self::Value, V::Error>\n            where\n                V: de::MapAccess<'de>,\n            {\n                let mvd = de::value::MapAccessDeserializer::new(map);\n                TomlWorkspaceField::deserialize(mvd).map(MaybeWorkspace::Workspace)\n            }\n        }\n\n        d.deserialize_any(Visitor)\n    }\n}\n\ntype MaybeWorkspaceVecStringOrBool = MaybeWorkspace<VecStringOrBool, TomlWorkspaceField>;\nimpl<'de> de::Deserialize<'de> for MaybeWorkspaceVecStringOrBool {\n    fn deserialize<D>(d: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        struct Visitor;\n\n        impl<'de> de::Visitor<'de> for Visitor {\n            type Value = MaybeWorkspaceVecStringOrBool;\n\n            fn expecting(&self, f: &mut fmt::Formatter<'_>) -> Result<(), fmt::Error> {\n                f.write_str(\"a boolean, a vector of strings, or workspace\")\n            }\n\n            fn visit_bool<E>(self, v: bool) -> Result<Self::Value, E>\n            where\n                E: de::Error,\n            {\n                let b = de::value::BoolDeserializer::new(v);\n                VecStringOrBool::deserialize(b).map(MaybeWorkspace::Defined)\n            }\n\n            fn visit_seq<A>(self, v: A) -> Result<Self::Value, A::Error>\n            where\n                A: de::SeqAccess<'de>,\n            {\n                let seq = de::value::SeqAccessDeserializer::new(v);\n                VecStringOrBool::deserialize(seq).map(MaybeWorkspace::Defined)\n            }\n\n            fn visit_map<V>(self, map: V) -> Result<Self::Value, V::Error>\n            where\n                V: de::MapAccess<'de>,\n            {\n                let mvd = de::value::MapAccessDeserializer::new(map);\n                TomlWorkspaceField::deserialize(mvd).map(MaybeWorkspace::Workspace)\n            }\n        }\n\n        d.deserialize_any(Visitor)\n    }\n}\n\ntype MaybeWorkspaceBtreeMap =\n    MaybeWorkspace<BTreeMap<String, BTreeMap<String, String>>, TomlWorkspaceField>;\n\nimpl<'de> de::Deserialize<'de> for MaybeWorkspaceBtreeMap {\n    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        let value = serde_value::Value::deserialize(deserializer)?;\n\n        if let Ok(w) = TomlWorkspaceField::deserialize(\n            serde_value::ValueDeserializer::<D::Error>::new(value.clone()),\n        ) {\n            return if w.workspace() {\n                Ok(MaybeWorkspace::Workspace(w))\n            } else {\n                Err(de::Error::custom(\"`workspace` cannot be false\"))\n            };\n        }\n        BTreeMap::deserialize(serde_value::ValueDeserializer::<D::Error>::new(value))\n            .map(MaybeWorkspace::Defined)\n    }\n}\n\ntype MaybeWorkspaceLints = MaybeWorkspace<TomlLints, TomlWorkspaceField>;\n\nimpl<'de> de::Deserialize<'de> for MaybeWorkspaceLints {\n    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        let value = serde_value::Value::deserialize(deserializer)?;\n\n        if let Ok(w) = TomlWorkspaceField::deserialize(\n            serde_value::ValueDeserializer::<D::Error>::new(value.clone()),\n        ) {\n            return if w.workspace() {\n                Ok(MaybeWorkspace::Workspace(w))\n            } else {\n                Err(de::Error::custom(\"`workspace` cannot be false\"))\n            };\n        }\n        TomlLints::deserialize(serde_value::ValueDeserializer::<D::Error>::new(value))\n            .map(MaybeWorkspace::Defined)\n    }\n}\n\n#[derive(Deserialize, Serialize, Clone, Debug)]\npub struct TomlWorkspaceField {\n    #[serde(deserialize_with = \"bool_no_false\")]\n    workspace: bool,\n}\n\nfn bool_no_false<'de, D: de::Deserializer<'de>>(deserializer: D) -> Result<bool, D::Error> {\n    let b: bool = Deserialize::deserialize(deserializer)?;\n    if b {\n        Ok(b)\n    } else {\n        Err(de::Error::custom(\"`workspace` cannot be false\"))\n    }\n}\n\nimpl WorkspaceInherit for TomlWorkspaceField {\n    fn inherit_toml_table(&self) -> &str {\n        \"package\"\n    }\n\n    fn workspace(&self) -> bool {\n        self.workspace\n    }\n}\n\n/// Represents the `package`/`project` sections of a `Cargo.toml`.\n///\n/// Note that the order of the fields matters, since this is the order they\n/// are serialized to a TOML file. For example, you cannot have values after\n/// the field `metadata`, since it is a table and values cannot appear after\n/// tables.\n#[derive(Deserialize, Serialize, Clone, Debug)]\n#[serde(rename_all = \"kebab-case\")]\npub struct TomlPackage {\n    edition: Option<MaybeWorkspaceString>,\n    rust_version: Option<MaybeWorkspaceString>,\n    name: InternedString,\n    #[serde(deserialize_with = \"version_trim_whitespace\")]\n    version: MaybeWorkspaceSemverVersion,\n    authors: Option<MaybeWorkspaceVecString>,\n    build: Option<StringOrBool>,\n    metabuild: Option<StringOrVec>,\n    #[serde(rename = \"default-target\")]\n    default_target: Option<String>,\n    #[serde(rename = \"forced-target\")]\n    forced_target: Option<String>,\n    links: Option<String>,\n    exclude: Option<MaybeWorkspaceVecString>,\n    include: Option<MaybeWorkspaceVecString>,\n    publish: Option<MaybeWorkspaceVecStringOrBool>,\n    workspace: Option<String>,\n    im_a_teapot: Option<bool>,\n    autobins: Option<bool>,\n    autoexamples: Option<bool>,\n    autotests: Option<bool>,\n    autobenches: Option<bool>,\n    default_run: Option<String>,\n\n    // Package metadata.\n    description: Option<MaybeWorkspaceString>,\n    homepage: Option<MaybeWorkspaceString>,\n    documentation: Option<MaybeWorkspaceString>,\n    readme: Option<MaybeWorkspaceStringOrBool>,\n    keywords: Option<MaybeWorkspaceVecString>,\n    categories: Option<MaybeWorkspaceVecString>,\n    license: Option<MaybeWorkspaceString>,\n    license_file: Option<MaybeWorkspaceString>,\n    repository: Option<MaybeWorkspaceString>,\n    resolver: Option<String>,\n\n    // Note that this field must come last due to the way toml serialization\n    // works which requires tables to be emitted after all values.\n    metadata: Option<toml::Value>,\n}\n\n#[derive(Debug, Deserialize, Serialize, Clone)]\npub struct TomlWorkspace {\n    members: Option<Vec<String>>,\n    #[serde(rename = \"default-members\")]\n    default_members: Option<Vec<String>>,\n    exclude: Option<Vec<String>>,\n    resolver: Option<String>,\n\n    // Properties that can be inherited by members.\n    package: Option<InheritableFields>,\n    dependencies: Option<BTreeMap<String, TomlDependency>>,\n    lints: Option<toml::Value>,\n\n    // Note that this field must come last due to the way toml serialization\n    // works which requires tables to be emitted after all values.\n    metadata: Option<toml::Value>,\n}\n\n/// A group of fields that are inheritable by members of the workspace\n#[derive(Clone, Debug, Default, Deserialize, Serialize)]\npub struct InheritableFields {\n    // We use skip here since it will never be present when deserializing\n    // and we don't want it present when serializing\n    #[serde(skip)]\n    dependencies: Option<BTreeMap<String, TomlDependency>>,\n    #[serde(skip)]\n    lints: Option<TomlLints>,\n\n    version: Option<semver::Version>,\n    authors: Option<Vec<String>>,\n    description: Option<String>,\n    homepage: Option<String>,\n    documentation: Option<String>,\n    readme: Option<StringOrBool>,\n    keywords: Option<Vec<String>>,\n    categories: Option<Vec<String>>,\n    license: Option<String>,\n    #[serde(rename = \"license-file\")]\n    license_file: Option<String>,\n    repository: Option<String>,\n    publish: Option<VecStringOrBool>,\n    edition: Option<String>,\n    badges: Option<BTreeMap<String, BTreeMap<String, String>>>,\n    exclude: Option<Vec<String>>,\n    include: Option<Vec<String>>,\n    #[serde(rename = \"rust-version\")]\n    rust_version: Option<String>,\n    // We use skip here since it will never be present when deserializing\n    // and we don't want it present when serializing\n    #[serde(skip)]\n    ws_root: PathBuf,\n}\n\nimpl InheritableFields {\n    pub fn update_deps(&mut self, deps: Option<BTreeMap<String, TomlDependency>>) {\n        self.dependencies = deps;\n    }\n\n    pub fn update_lints(&mut self, lints: Option<TomlLints>) {\n        self.lints = lints;\n    }\n\n    pub fn update_ws_path(&mut self, ws_root: PathBuf) {\n        self.ws_root = ws_root;\n    }\n\n    pub fn dependencies(&self) -> CargoResult<BTreeMap<String, TomlDependency>> {\n        self.dependencies.clone().map_or(\n            Err(anyhow!(\"`workspace.dependencies` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn lints(&self) -> CargoResult<TomlLints> {\n        self.lints\n            .clone()\n            .map_or(Err(anyhow!(\"`workspace.lints` was not defined\")), |d| Ok(d))\n    }\n\n    pub fn get_dependency(&self, name: &str, package_root: &Path) -> CargoResult<TomlDependency> {\n        self.dependencies.clone().map_or(\n            Err(anyhow!(\"`workspace.dependencies` was not defined\")),\n            |deps| {\n                deps.get(name).map_or(\n                    Err(anyhow!(\n                        \"`dependency.{}` was not found in `workspace.dependencies`\",\n                        name\n                    )),\n                    |dep| {\n                        let mut dep = dep.clone();\n                        if let TomlDependency::Detailed(detailed) = &mut dep {\n                            detailed.resolve_path(name, self.ws_root(), package_root)?\n                        }\n                        Ok(dep)\n                    },\n                )\n            },\n        )\n    }\n\n    pub fn version(&self) -> CargoResult<semver::Version> {\n        self.version.clone().map_or(\n            Err(anyhow!(\"`workspace.package.version` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn authors(&self) -> CargoResult<Vec<String>> {\n        self.authors.clone().map_or(\n            Err(anyhow!(\"`workspace.package.authors` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn description(&self) -> CargoResult<String> {\n        self.description.clone().map_or(\n            Err(anyhow!(\"`workspace.package.description` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn homepage(&self) -> CargoResult<String> {\n        self.homepage.clone().map_or(\n            Err(anyhow!(\"`workspace.package.homepage` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn documentation(&self) -> CargoResult<String> {\n        self.documentation.clone().map_or(\n            Err(anyhow!(\"`workspace.package.documentation` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn readme(&self, package_root: &Path) -> CargoResult<StringOrBool> {\n        readme_for_package(self.ws_root.as_path(), self.readme.clone()).map_or(\n            Err(anyhow!(\"`workspace.package.readme` was not defined\")),\n            |readme| {\n                let rel_path =\n                    resolve_relative_path(\"readme\", &self.ws_root, package_root, &readme)?;\n                Ok(StringOrBool::String(rel_path))\n            },\n        )\n    }\n\n    pub fn keywords(&self) -> CargoResult<Vec<String>> {\n        self.keywords.clone().map_or(\n            Err(anyhow!(\"`workspace.package.keywords` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn categories(&self) -> CargoResult<Vec<String>> {\n        self.categories.clone().map_or(\n            Err(anyhow!(\"`workspace.package.categories` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn license(&self) -> CargoResult<String> {\n        self.license.clone().map_or(\n            Err(anyhow!(\"`workspace.package.license` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn license_file(&self, package_root: &Path) -> CargoResult<String> {\n        self.license_file.clone().map_or(\n            Err(anyhow!(\"`workspace.package.license_file` was not defined\")),\n            |d| resolve_relative_path(\"license-file\", &self.ws_root, package_root, &d),\n        )\n    }\n\n    pub fn repository(&self) -> CargoResult<String> {\n        self.repository.clone().map_or(\n            Err(anyhow!(\"`workspace.package.repository` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn publish(&self) -> CargoResult<VecStringOrBool> {\n        self.publish.clone().map_or(\n            Err(anyhow!(\"`workspace.package.publish` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn edition(&self) -> CargoResult<String> {\n        self.edition.clone().map_or(\n            Err(anyhow!(\"`workspace.package.edition` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn rust_version(&self) -> CargoResult<String> {\n        self.rust_version.clone().map_or(\n            Err(anyhow!(\"`workspace.package.rust-version` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn badges(&self) -> CargoResult<BTreeMap<String, BTreeMap<String, String>>> {\n        self.badges.clone().map_or(\n            Err(anyhow!(\"`workspace.package.badges` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn exclude(&self) -> CargoResult<Vec<String>> {\n        self.exclude.clone().map_or(\n            Err(anyhow!(\"`workspace.package.exclude` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn include(&self) -> CargoResult<Vec<String>> {\n        self.include.clone().map_or(\n            Err(anyhow!(\"`workspace.package.include` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn ws_root(&self) -> &PathBuf {\n        &self.ws_root\n    }\n}\n\nimpl TomlPackage {\n    pub fn to_package_id(\n        &self,\n        source_id: SourceId,\n        version: semver::Version,\n    ) -> CargoResult<PackageId> {\n        PackageId::new(self.name, version, source_id)\n    }\n}\n\nstruct Context<'a, 'b> {\n    deps: &'a mut Vec<Dependency>,\n    source_id: SourceId,\n    nested_paths: &'a mut Vec<PathBuf>,\n    config: &'b Config,\n    warnings: &'a mut Vec<String>,\n    platform: Option<Platform>,\n    root: &'a Path,\n    features: &'a Features,\n}\n\nimpl TomlManifest {\n    /// Prepares the manifest for publishing.\n    // - Path and git components of dependency specifications are removed.\n    // - License path is updated to point within the package.\n    pub fn prepare_for_publish(\n        &self,\n        ws: &Workspace<'_>,\n        package_root: &Path,\n    ) -> CargoResult<TomlManifest> {\n        let config = ws.config();\n        let mut package = self\n            .package\n            .as_ref()\n            .or_else(|| self.project.as_ref())\n            .unwrap()\n            .clone();\n        package.workspace = None;\n        let current_resolver = package\n            .resolver\n            .as_ref()\n            .map(|r| ResolveBehavior::from_manifest(r))\n            .unwrap_or_else(|| {\n                package\n                    .edition\n                    .as_ref()\n                    .and_then(|e| e.as_defined())\n                    .map(|e| Edition::from_str(e))\n                    .unwrap_or(Ok(Edition::Edition2015))\n                    .map(|e| e.default_resolve_behavior())\n            })?;\n        if ws.resolve_behavior() != current_resolver {\n            // This ensures the published crate if built as a root (e.g. `cargo install`) will\n            // use the same resolver behavior it was tested with in the workspace.\n            // To avoid forcing a higher MSRV we don't explicitly set this if it would implicitly\n            // result in the same thing.\n            package.resolver = Some(ws.resolve_behavior().to_manifest());\n        }\n        if let Some(license_file) = &package.license_file {\n            let license_file = license_file\n                .as_defined()\n                .context(\"license file should have been resolved before `prepare_for_publish()`\")?;\n            let license_path = Path::new(&license_file);\n            let abs_license_path = paths::normalize_path(&package_root.join(license_path));\n            if abs_license_path.strip_prefix(package_root).is_err() {\n                // This path points outside of the package root. `cargo package`\n                // will copy it into the root, so adjust the path to this location.\n                package.license_file = Some(MaybeWorkspace::Defined(\n                    license_path\n                        .file_name()\n                        .unwrap()\n                        .to_str()\n                        .unwrap()\n                        .to_string(),\n                ));\n            }\n        }\n\n        if let Some(readme) = &package.readme {\n            let readme = readme\n                .as_defined()\n                .context(\"readme should have been resolved before `prepare_for_publish()`\")?;\n            match readme {\n                StringOrBool::String(readme) => {\n                    let readme_path = Path::new(&readme);\n                    let abs_readme_path = paths::normalize_path(&package_root.join(readme_path));\n                    if abs_readme_path.strip_prefix(package_root).is_err() {\n                        // This path points outside of the package root. `cargo package`\n                        // will copy it into the root, so adjust the path to this location.\n                        package.readme = Some(MaybeWorkspace::Defined(StringOrBool::String(\n                            readme_path\n                                .file_name()\n                                .unwrap()\n                                .to_str()\n                                .unwrap()\n                                .to_string(),\n                        )));\n                    }\n                }\n                StringOrBool::Bool(_) => {}\n            }\n        }\n        let all = |_d: &TomlDependency| true;\n        return Ok(TomlManifest {\n            package: Some(package),\n            project: None,\n            profile: self.profile.clone(),\n            lib: self.lib.clone(),\n            bin: self.bin.clone(),\n            example: self.example.clone(),\n            test: self.test.clone(),\n            bench: self.bench.clone(),\n            dependencies: map_deps(config, self.dependencies.as_ref(), all)?,\n            dev_dependencies: map_deps(\n                config,\n                self.dev_dependencies\n                    .as_ref()\n                    .or_else(|| self.dev_dependencies2.as_ref()),\n                TomlDependency::is_version_specified,\n            )?,\n            dev_dependencies2: None,\n            build_dependencies: map_deps(\n                config,\n                self.build_dependencies\n                    .as_ref()\n                    .or_else(|| self.build_dependencies2.as_ref()),\n                all,\n            )?,\n            build_dependencies2: None,\n            features: self.features.clone(),\n            target: match self.target.as_ref().map(|target_map| {\n                target_map\n                    .iter()\n                    .map(|(k, v)| {\n                        Ok((\n                            k.clone(),\n                            TomlPlatform {\n                                dependencies: map_deps(config, v.dependencies.as_ref(), all)?,\n                                dev_dependencies: map_deps(\n                                    config,\n                                    v.dev_dependencies\n                                        .as_ref()\n                                        .or_else(|| v.dev_dependencies2.as_ref()),\n                                    TomlDependency::is_version_specified,\n                                )?,\n                                dev_dependencies2: None,\n                                build_dependencies: map_deps(\n                                    config,\n                                    v.build_dependencies\n                                        .as_ref()\n                                        .or_else(|| v.build_dependencies2.as_ref()),\n                                    all,\n                                )?,\n                                build_dependencies2: None,\n                            },\n                        ))\n                    })\n                    .collect()\n            }) {\n                Some(Ok(v)) => Some(v),\n                Some(Err(e)) => return Err(e),\n                None => None,\n            },\n            replace: None,\n            patch: None,\n            workspace: None,\n            badges: self.badges.clone(),\n            cargo_features: self.cargo_features.clone(),\n            lints: self.lints.clone(),\n        });\n\n        fn map_deps(\n            config: &Config,\n            deps: Option<&BTreeMap<String, MaybeWorkspaceDependency>>,\n            filter: impl Fn(&TomlDependency) -> bool,\n        ) -> CargoResult<Option<BTreeMap<String, MaybeWorkspaceDependency>>> {\n            let deps = match deps {\n                Some(deps) => deps,\n                None => return Ok(None),\n            };\n            let deps = deps\n                .iter()\n                .filter(|(_k, v)| {\n                    if let MaybeWorkspace::Defined(def) = v {\n                        filter(def)\n                    } else {\n                        false\n                    }\n                })\n                .map(|(k, v)| Ok((k.clone(), map_dependency(config, v)?)))\n                .collect::<CargoResult<BTreeMap<_, _>>>()?;\n            Ok(Some(deps))\n        }\n\n        fn map_dependency(\n            config: &Config,\n            dep: &MaybeWorkspaceDependency,\n        ) -> CargoResult<MaybeWorkspaceDependency> {\n            let dep = match dep {\n                MaybeWorkspace::Defined(TomlDependency::Detailed(d)) => {\n                    let mut d = d.clone();\n                    // Path dependencies become crates.io deps.\n                    d.path.take();\n                    // Same with git dependencies.\n                    d.git.take();\n                    d.branch.take();\n                    d.tag.take();\n                    d.rev.take();\n                    // registry specifications are elaborated to the index URL\n                    if let Some(registry) = d.registry.take() {\n                        d.registry_index = Some(config.get_registry_index(&registry)?.to_string());\n                    }\n                    Ok(d)\n                }\n                MaybeWorkspace::Defined(TomlDependency::Simple(s)) => Ok(DetailedTomlDependency {\n                    version: Some(s.clone()),\n                    ..Default::default()\n                }),\n                _ => unreachable!(),\n            };\n            dep.map(TomlDependency::Detailed)\n                .map(MaybeWorkspace::Defined)\n        }\n    }\n\n    pub fn to_real_manifest(\n        me: &Rc<TomlManifest>,\n        embedded: bool,\n        source_id: SourceId,\n        package_root: &Path,\n        config: &Config,\n    ) -> CargoResult<(Manifest, Vec<PathBuf>)> {\n        fn get_ws(\n            config: &Config,\n            resolved_path: &Path,\n            workspace_config: &WorkspaceConfig,\n        ) -> CargoResult<InheritableFields> {\n            match workspace_config {\n                WorkspaceConfig::Root(root) => Ok(root.inheritable().clone()),\n                WorkspaceConfig::Member {\n                    root: Some(ref path_to_root),\n                } => {\n                    let path = resolved_path\n                        .parent()\n                        .unwrap()\n                        .join(path_to_root)\n                        .join(\"Cargo.toml\");\n                    let root_path = paths::normalize_path(&path);\n                    inheritable_from_path(config, root_path)\n                }\n                WorkspaceConfig::Member { root: None } => {\n                    match find_workspace_root(&resolved_path, config)? {\n                        Some(path_to_root) => inheritable_from_path(config, path_to_root),\n                        None => Err(anyhow!(\"failed to find a workspace root\")),\n                    }\n                }\n            }\n        }\n\n        let mut nested_paths = vec![];\n        let mut warnings = vec![];\n        let mut errors = vec![];\n\n        // Parse features first so they will be available when parsing other parts of the TOML.\n        let empty = Vec::new();\n        let cargo_features = me.cargo_features.as_ref().unwrap_or(&empty);\n        let features = Features::new(cargo_features, config, &mut warnings, source_id.is_path())?;\n\n        let mut package = match (&me.package, &me.project) {\n            (Some(_), Some(project)) => {\n                if source_id.is_path() {\n                    config.shell().warn(format!(\n                        \"manifest at `{}` contains both `project` and `package`, \\\n                    this could become a hard error in the future\",\n                        package_root.display()\n                    ))?;\n                }\n                project.clone()\n            }\n            (Some(package), None) => package.clone(),\n            (None, Some(project)) => {\n                if source_id.is_path() {\n                    config.shell().warn(format!(\n                        \"manifest at `{}` contains `[project]` instead of `[package]`, \\\n                                this could become a hard error in the future\",\n                        package_root.display()\n                    ))?;\n                }\n                project.clone()\n            }\n            (None, None) => bail!(\"no `package` section found\"),\n        };\n\n        let workspace_config = match (me.workspace.as_ref(), package.workspace.as_ref()) {\n            (Some(toml_config), None) => {\n                let mut inheritable = toml_config.package.clone().unwrap_or_default();\n                inheritable.update_ws_path(package_root.to_path_buf());\n                inheritable.update_deps(toml_config.dependencies.clone());\n                let lints = parse_unstable_lints(toml_config.lints.clone(), config, &mut warnings)?;\n                let lints = verify_lints(lints)?;\n                inheritable.update_lints(lints);\n                if let Some(ws_deps) = &inheritable.dependencies {\n                    for (name, dep) in ws_deps {\n                        unused_dep_keys(\n                            name,\n                            \"workspace.dependencies\",\n                            dep.unused_keys(),\n                            &mut warnings,\n                        );\n                    }\n                }\n                let ws_root_config = WorkspaceRootConfig::new(\n                    package_root,\n                    &toml_config.members,\n                    &toml_config.default_members,\n                    &toml_config.exclude,\n                    &Some(inheritable),\n                    &toml_config.metadata,\n                );\n                config\n                    .ws_roots\n                    .borrow_mut()\n                    .insert(package_root.to_path_buf(), ws_root_config.clone());\n                WorkspaceConfig::Root(ws_root_config)\n            }\n            (None, root) => WorkspaceConfig::Member {\n                root: root.cloned(),\n            },\n            (Some(..), Some(..)) => bail!(\n                \"cannot configure both `package.workspace` and \\\n                 `[workspace]`, only one can be specified\"\n            ),\n        };\n\n        let package_name = package.name.trim();\n        if package_name.is_empty() {\n            bail!(\"package name cannot be an empty string\")\n        }\n\n        validate_package_name(package_name, \"package name\", \"\")?;\n\n        let resolved_path = package_root.join(\"Cargo.toml\");\n\n        let inherit_cell: LazyCell<InheritableFields> = LazyCell::new();\n        let inherit =\n            || inherit_cell.try_borrow_with(|| get_ws(config, &resolved_path, &workspace_config));\n\n        let version = package\n            .version\n            .clone()\n            .resolve(\"version\", || inherit()?.version())?;\n\n        package.version = MaybeWorkspace::Defined(version.clone());\n\n        let pkgid = package.to_package_id(source_id, version)?;\n\n        let edition = if let Some(edition) = package.edition.clone() {\n            let edition: Edition = edition\n                .resolve(\"edition\", || inherit()?.edition())?\n                .parse()\n                .with_context(|| \"failed to parse the `edition` key\")?;\n            package.edition = Some(MaybeWorkspace::Defined(edition.to_string()));\n            edition\n        } else {\n            Edition::Edition2015\n        };\n        // Add these lines if start a new unstable edition.\n        // ```\n        // if edition == Edition::Edition20xx {\n        //     features.require(Feature::edition20xx))?;\n        // }\n        // ```\n        if !edition.is_stable() {\n            // Guard in case someone forgets to add .require()\n            return Err(util::errors::internal(format!(\n                \"edition {} should be gated\",\n                edition\n            )));\n        }\n\n        let rust_version = if let Some(rust_version) = &package.rust_version {\n            let rust_version = rust_version\n                .clone()\n                .resolve(\"rust_version\", || inherit()?.rust_version())?;\n            let req = match semver::VersionReq::parse(&rust_version) {\n                // Exclude semver operators like `^` and pre-release identifiers\n                Ok(req) if rust_version.chars().all(|c| c.is_ascii_digit() || c == '.') => req,\n                _ => bail!(\"`rust-version` must be a value like \\\"1.32\\\"\"),\n            };\n            if let Some(first_version) = edition.first_version() {\n                let unsupported =\n                    semver::Version::new(first_version.major, first_version.minor - 1, 9999);\n                if req.matches(&unsupported) {\n                    bail!(\n                        \"rust-version {} is older than first version ({}) required by \\\n                            the specified edition ({})\",\n                        rust_version,\n                        first_version,\n                        edition,\n                    )\n                }\n            }\n            Some(rust_version.clone())\n        } else {\n            None\n        };\n\n        if package.metabuild.is_some() {\n            features.require(Feature::metabuild())?;\n        }\n\n        let resolve_behavior = match (\n            package.resolver.as_ref(),\n            me.workspace.as_ref().and_then(|ws| ws.resolver.as_ref()),\n        ) {\n            (None, None) => None,\n            (Some(s), None) | (None, Some(s)) => Some(ResolveBehavior::from_manifest(s)?),\n            (Some(_), Some(_)) => {\n                bail!(\"cannot specify `resolver` field in both `[workspace]` and `[package]`\")\n            }\n        };\n\n        // If we have no lib at all, use the inferred lib, if available.\n        // If we have a lib with a path, we're done.\n        // If we have a lib with no path, use the inferred lib or else the package name.\n        let targets = targets(\n            &features,\n            me,\n            package_name,\n            package_root,\n            edition,\n            &package.build,\n            &package.metabuild,\n            &mut warnings,\n            &mut errors,\n        )?;\n\n        if targets.is_empty() {\n            debug!(\"manifest has no build targets\");\n        }\n\n        if let Err(conflict_targets) = unique_build_targets(&targets, package_root) {\n            conflict_targets\n                .iter()\n                .for_each(|(target_path, conflicts)| {\n                    warnings.push(format!(\n                        \"file `{}` found to be present in multiple \\\n                 build targets:\\n{}\",\n                        target_path.display().to_string(),\n                        conflicts\n                            .iter()\n                            .map(|t| format!(\n                                \"  * `{}` target `{}`\",\n                                t.kind().description(),\n                                t.name(),\n                            ))\n                            .join(\"\\n\")\n                    ));\n                })\n        }\n\n        if let Some(links) = &package.links {\n            if !targets.iter().any(|t| t.is_custom_build()) {\n                bail!(\n                    \"package `{}` specifies that it links to `{}` but does not \\\n                     have a custom build script\",\n                    pkgid,\n                    links\n                )\n            }\n        }\n\n        let mut deps = Vec::new();\n\n        let mut cx = Context {\n            deps: &mut deps,\n            source_id,\n            nested_paths: &mut nested_paths,\n            config,\n            warnings: &mut warnings,\n            features: &features,\n            platform: None,\n            root: package_root,\n        };\n\n        fn process_dependencies(\n            cx: &mut Context<'_, '_>,\n            new_deps: Option<&BTreeMap<String, MaybeWorkspaceDependency>>,\n            kind: Option<DepKind>,\n            workspace_config: &WorkspaceConfig,\n            inherit_cell: &LazyCell<InheritableFields>,\n        ) -> CargoResult<Option<BTreeMap<String, MaybeWorkspaceDependency>>> {\n            let dependencies = match new_deps {\n                Some(dependencies) => dependencies,\n                None => return Ok(None),\n            };\n\n            let inheritable = || {\n                inherit_cell.try_borrow_with(|| {\n                    get_ws(cx.config, &cx.root.join(\"Cargo.toml\"), &workspace_config)\n                })\n            };\n\n            let mut deps: BTreeMap<String, MaybeWorkspaceDependency> = BTreeMap::new();\n            for (n, v) in dependencies.iter() {\n                let resolved = v\n                    .clone()\n                    .resolve_with_self(n, |dep| dep.resolve(n, inheritable, cx))?;\n                let dep = resolved.to_dependency(n, cx, kind)?;\n                let name_in_toml = dep.name_in_toml().as_str();\n                validate_package_name(name_in_toml, \"dependency name\", \"\")?;\n                let kind_name = match kind {\n                    Some(k) => k.kind_table(),\n                    None => \"dependencies\",\n                };\n                let table_in_toml = if let Some(platform) = &cx.platform {\n                    format!(\"target.{}.{kind_name}\", platform.to_string())\n                } else {\n                    kind_name.to_string()\n                };\n                unused_dep_keys(name_in_toml, &table_in_toml, v.unused_keys(), cx.warnings);\n                cx.deps.push(dep);\n                deps.insert(n.to_string(), MaybeWorkspace::Defined(resolved.clone()));\n            }\n            Ok(Some(deps))\n        }\n\n        // Collect the dependencies.\n        let dependencies = process_dependencies(\n            &mut cx,\n            me.dependencies.as_ref(),\n            None,\n            &workspace_config,\n            &inherit_cell,\n        )?;\n        if me.dev_dependencies.is_some() && me.dev_dependencies2.is_some() {\n            warn_on_deprecated(\"dev-dependencies\", package_name, \"package\", cx.warnings);\n        }\n        let dev_deps = me\n            .dev_dependencies\n            .as_ref()\n            .or_else(|| me.dev_dependencies2.as_ref());\n        let dev_deps = process_dependencies(\n            &mut cx,\n            dev_deps,\n            Some(DepKind::Development),\n            &workspace_config,\n            &inherit_cell,\n        )?;\n        if me.build_dependencies.is_some() && me.build_dependencies2.is_some() {\n            warn_on_deprecated(\"build-dependencies\", package_name, \"package\", cx.warnings);\n        }\n        let build_deps = me\n            .build_dependencies\n            .as_ref()\n            .or_else(|| me.build_dependencies2.as_ref());\n        let build_deps = process_dependencies(\n            &mut cx,\n            build_deps,\n            Some(DepKind::Build),\n            &workspace_config,\n            &inherit_cell,\n        )?;\n\n        let lints =\n            parse_unstable_lints::<MaybeWorkspaceLints>(me.lints.clone(), config, cx.warnings)?\n                .map(|mw| mw.resolve(\"lints\", || inherit()?.lints()))\n                .transpose()?;\n        let lints = verify_lints(lints)?;\n        let default = TomlLints::default();\n        let rustflags = lints_to_rustflags(lints.as_ref().unwrap_or(&default));\n\n        let mut target: BTreeMap<String, TomlPlatform> = BTreeMap::new();\n        for (name, platform) in me.target.iter().flatten() {\n            cx.platform = {\n                let platform: Platform = name.parse()?;\n                platform.check_cfg_attributes(cx.warnings);\n                Some(platform)\n            };\n            let deps = process_dependencies(\n                &mut cx,\n                platform.dependencies.as_ref(),\n                None,\n                &workspace_config,\n                &inherit_cell,\n            )?;\n            if platform.build_dependencies.is_some() && platform.build_dependencies2.is_some() {\n                warn_on_deprecated(\"build-dependencies\", name, \"platform target\", cx.warnings);\n            }\n            let build_deps = platform\n                .build_dependencies\n                .as_ref()\n                .or_else(|| platform.build_dependencies2.as_ref());\n            let build_deps = process_dependencies(\n                &mut cx,\n                build_deps,\n                Some(DepKind::Build),\n                &workspace_config,\n                &inherit_cell,\n            )?;\n            if platform.dev_dependencies.is_some() && platform.dev_dependencies2.is_some() {\n                warn_on_deprecated(\"dev-dependencies\", name, \"platform target\", cx.warnings);\n            }\n            let dev_deps = platform\n                .dev_dependencies\n                .as_ref()\n                .or_else(|| platform.dev_dependencies2.as_ref());\n            let dev_deps = process_dependencies(\n                &mut cx,\n                dev_deps,\n                Some(DepKind::Development),\n                &workspace_config,\n                &inherit_cell,\n            )?;\n            target.insert(\n                name.clone(),\n                TomlPlatform {\n                    dependencies: deps,\n                    build_dependencies: build_deps,\n                    build_dependencies2: None,\n                    dev_dependencies: dev_deps,\n                    dev_dependencies2: None,\n                },\n            );\n        }\n\n        let target = if target.is_empty() {\n            None\n        } else {\n            Some(target)\n        };\n        let replace = me.replace(&mut cx)?;\n        let patch = me.patch(&mut cx)?;\n\n        {\n            let mut names_sources = BTreeMap::new();\n            for dep in &deps {\n                let name = dep.name_in_toml();\n                let prev = names_sources.insert(name.to_string(), dep.source_id());\n                if prev.is_some() && prev != Some(dep.source_id()) {\n                    bail!(\n                        \"Dependency '{}' has different source paths depending on the build \\\n                         target. Each dependency must have a single canonical source path \\\n                         irrespective of build target.\",\n                        name\n                    );\n                }\n            }\n        }\n\n        let exclude = package\n            .exclude\n            .clone()\n            .map(|mw| mw.resolve(\"exclude\", || inherit()?.exclude()))\n            .transpose()?\n            .unwrap_or_default();\n        let include = package\n            .include\n            .clone()\n            .map(|mw| mw.resolve(\"include\", || inherit()?.include()))\n            .transpose()?\n            .unwrap_or_default();\n        let empty_features = BTreeMap::new();\n\n        let summary = Summary::new(\n            config,\n            pkgid,\n            deps,\n            me.features.as_ref().unwrap_or(&empty_features),\n            package.links.as_deref(),\n            rust_version.as_deref().map(InternedString::new),\n        )?;\n\n        let metadata = ManifestMetadata {\n            description: package\n                .description\n                .clone()\n                .map(|mw| mw.resolve(\"description\", || inherit()?.description()))\n                .transpose()?,\n            homepage: package\n                .homepage\n                .clone()\n                .map(|mw| mw.resolve(\"homepage\", || inherit()?.homepage()))\n                .transpose()?,\n            documentation: package\n                .documentation\n                .clone()\n                .map(|mw| mw.resolve(\"documentation\", || inherit()?.documentation()))\n                .transpose()?,\n            readme: readme_for_package(\n                package_root,\n                package\n                    .readme\n                    .clone()\n                    .map(|mw| mw.resolve(\"readme\", || inherit()?.readme(package_root)))\n                    .transpose()?,\n            ),\n            authors: package\n                .authors\n                .clone()\n                .map(|mw| mw.resolve(\"authors\", || inherit()?.authors()))\n                .transpose()?\n                .unwrap_or_default(),\n            license: package\n                .license\n                .clone()\n                .map(|mw| mw.resolve(\"license\", || inherit()?.license()))\n                .transpose()?,\n            license_file: package\n                .license_file\n                .clone()\n                .map(|mw| mw.resolve(\"license\", || inherit()?.license_file(package_root)))\n                .transpose()?,\n            repository: package\n                .repository\n                .clone()\n                .map(|mw| mw.resolve(\"repository\", || inherit()?.repository()))\n                .transpose()?,\n            keywords: package\n                .keywords\n                .clone()\n                .map(|mw| mw.resolve(\"keywords\", || inherit()?.keywords()))\n                .transpose()?\n                .unwrap_or_default(),\n            categories: package\n                .categories\n                .clone()\n                .map(|mw| mw.resolve(\"categories\", || inherit()?.categories()))\n                .transpose()?\n                .unwrap_or_default(),\n            badges: me\n                .badges\n                .clone()\n                .map(|mw| mw.resolve(\"badges\", || inherit()?.badges()))\n                .transpose()?\n                .unwrap_or_default(),\n            links: package.links.clone(),\n            rust_version: package\n                .rust_version\n                .clone()\n                .map(|mw| mw.resolve(\"rust-version\", || inherit()?.rust_version()))\n                .transpose()?,\n        };\n        package.description = metadata\n            .description\n            .clone()\n            .map(|description| MaybeWorkspace::Defined(description));\n        package.homepage = metadata\n            .homepage\n            .clone()\n            .map(|homepage| MaybeWorkspace::Defined(homepage));\n        package.documentation = metadata\n            .documentation\n            .clone()\n            .map(|documentation| MaybeWorkspace::Defined(documentation));\n        package.readme = metadata\n            .readme\n            .clone()\n            .map(|readme| MaybeWorkspace::Defined(StringOrBool::String(readme)));\n        package.authors = package\n            .authors\n            .as_ref()\n            .map(|_| MaybeWorkspace::Defined(metadata.authors.clone()));\n        package.license = metadata\n            .license\n            .clone()\n            .map(|license| MaybeWorkspace::Defined(license));\n        package.license_file = metadata\n            .license_file\n            .clone()\n            .map(|license_file| MaybeWorkspace::Defined(license_file));\n        package.repository = metadata\n            .repository\n            .clone()\n            .map(|repository| MaybeWorkspace::Defined(repository));\n        package.keywords = package\n            .keywords\n            .as_ref()\n            .map(|_| MaybeWorkspace::Defined(metadata.keywords.clone()));\n        package.categories = package\n            .categories\n            .as_ref()\n            .map(|_| MaybeWorkspace::Defined(metadata.categories.clone()));\n        package.rust_version = rust_version.clone().map(|rv| MaybeWorkspace::Defined(rv));\n        package.exclude = package\n            .exclude\n            .as_ref()\n            .map(|_| MaybeWorkspace::Defined(exclude.clone()));\n        package.include = package\n            .include\n            .as_ref()\n            .map(|_| MaybeWorkspace::Defined(include.clone()));\n\n        let profiles = me.profile.clone();\n        if let Some(profiles) = &profiles {\n            let cli_unstable = config.cli_unstable();\n            profiles.validate(cli_unstable, &features, &mut warnings)?;\n        }\n\n        let publish = package\n            .publish\n            .clone()\n            .map(|publish| publish.resolve(\"publish\", || inherit()?.publish()).unwrap());\n\n        package.publish = publish.clone().map(|p| MaybeWorkspace::Defined(p));\n\n        let publish = match publish {\n            Some(VecStringOrBool::VecString(ref vecstring)) => Some(vecstring.clone()),\n            Some(VecStringOrBool::Bool(false)) => Some(vec![]),\n            None | Some(VecStringOrBool::Bool(true)) => None,\n        };\n\n        if summary.features().contains_key(\"default-features\") {\n            warnings.push(\n                \"`default-features = [\\\"..\\\"]` was found in [features]. \\\n                 Did you mean to use `default = [\\\"..\\\"]`?\"\n                    .to_string(),\n            )\n        }\n\n        if let Some(run) = &package.default_run {\n            if !targets\n                .iter()\n                .filter(|t| t.is_bin())\n                .any(|t| t.name() == run)\n            {\n                let suggestion =\n                    util::closest_msg(run, targets.iter().filter(|t| t.is_bin()), |t| t.name());\n                bail!(\"default-run target `{}` not found{}\", run, suggestion);\n            }\n        }\n\n        let default_kind = package\n            .default_target\n            .as_ref()\n            .map(|t| CompileTarget::new(&*t))\n            .transpose()?\n            .map(CompileKind::Target);\n        let forced_kind = package\n            .forced_target\n            .as_ref()\n            .map(|t| CompileTarget::new(&*t))\n            .transpose()?\n            .map(CompileKind::Target);\n        let custom_metadata = package.metadata.clone();\n        let resolved_toml = TomlManifest {\n            cargo_features: me.cargo_features.clone(),\n            package: Some(package.clone()),\n            project: None,\n            profile: me.profile.clone(),\n            lib: me.lib.clone(),\n            bin: me.bin.clone(),\n            example: me.example.clone(),\n            test: me.test.clone(),\n            bench: me.bench.clone(),\n            dependencies,\n            dev_dependencies: dev_deps,\n            dev_dependencies2: None,\n            build_dependencies: build_deps,\n            build_dependencies2: None,\n            features: me.features.clone(),\n            target,\n            replace: me.replace.clone(),\n            patch: me.patch.clone(),\n            workspace: me.workspace.clone(),\n            badges: me\n                .badges\n                .as_ref()\n                .map(|_| MaybeWorkspace::Defined(metadata.badges.clone())),\n            lints: lints\n                .map(|lints| toml::Value::try_from(MaybeWorkspaceLints::Defined(lints)).unwrap()),\n        };\n        let mut manifest = Manifest::new(\n            summary,\n            default_kind,\n            forced_kind,\n            targets,\n            exclude,\n            include,\n            package.links.clone(),\n            metadata,\n            custom_metadata,\n            profiles,\n            publish,\n            replace,\n            patch,\n            workspace_config,\n            features,\n            edition,\n            rust_version,\n            package.im_a_teapot,\n            package.default_run.clone(),\n            Rc::new(resolved_toml),\n            package.metabuild.clone().map(|sov| sov.0),\n            resolve_behavior,\n            rustflags,\n            embedded,\n        );\n        if package.license_file.is_some() && package.license.is_some() {\n            manifest.warnings_mut().add_warning(\n                \"only one of `license` or `license-file` is necessary\\n\\\n                 `license` should be used if the package license can be expressed \\\n                 with a standard SPDX expression.\\n\\\n                 `license-file` should be used if the package uses a non-standard license.\\n\\\n                 See https://doc.rust-lang.org/cargo/reference/manifest.html#the-license-and-license-file-fields \\\n                 for more information.\"\n                    .to_string(),\n            );\n        }\n        for warning in warnings {\n            manifest.warnings_mut().add_warning(warning);\n        }\n        for error in errors {\n            manifest.warnings_mut().add_critical_warning(error);\n        }\n\n        manifest.feature_gate()?;\n\n        Ok((manifest, nested_paths))\n    }\n\n    fn to_virtual_manifest(\n        me: &Rc<TomlManifest>,\n        source_id: SourceId,\n        root: &Path,\n        config: &Config,\n    ) -> CargoResult<(VirtualManifest, Vec<PathBuf>)> {\n        if me.project.is_some() {\n            bail!(\"this virtual manifest specifies a [project] section, which is not allowed\");\n        }\n        if me.package.is_some() {\n            bail!(\"this virtual manifest specifies a [package] section, which is not allowed\");\n        }\n        if me.lib.is_some() {\n            bail!(\"this virtual manifest specifies a [lib] section, which is not allowed\");\n        }\n        if me.bin.is_some() {\n            bail!(\"this virtual manifest specifies a [[bin]] section, which is not allowed\");\n        }\n        if me.example.is_some() {\n            bail!(\"this virtual manifest specifies a [[example]] section, which is not allowed\");\n        }\n        if me.test.is_some() {\n            bail!(\"this virtual manifest specifies a [[test]] section, which is not allowed\");\n        }\n        if me.bench.is_some() {\n            bail!(\"this virtual manifest specifies a [[bench]] section, which is not allowed\");\n        }\n        if me.dependencies.is_some() {\n            bail!(\"this virtual manifest specifies a [dependencies] section, which is not allowed\");\n        }\n        if me.dev_dependencies.is_some() || me.dev_dependencies2.is_some() {\n            bail!(\"this virtual manifest specifies a [dev-dependencies] section, which is not allowed\");\n        }\n        if me.build_dependencies.is_some() || me.build_dependencies2.is_some() {\n            bail!(\"this virtual manifest specifies a [build-dependencies] section, which is not allowed\");\n        }\n        if me.features.is_some() {\n            bail!(\"this virtual manifest specifies a [features] section, which is not allowed\");\n        }\n        if me.target.is_some() {\n            bail!(\"this virtual manifest specifies a [target] section, which is not allowed\");\n        }\n        if me.badges.is_some() {\n            bail!(\"this virtual manifest specifies a [badges] section, which is not allowed\");\n        }\n\n        let mut nested_paths = Vec::new();\n        let mut warnings = Vec::new();\n        let mut deps = Vec::new();\n        let empty = Vec::new();\n        let cargo_features = me.cargo_features.as_ref().unwrap_or(&empty);\n        let features = Features::new(cargo_features, config, &mut warnings, source_id.is_path())?;\n\n        let (replace, patch) = {\n            let mut cx = Context {\n                deps: &mut deps,\n                source_id,\n                nested_paths: &mut nested_paths,\n                config,\n                warnings: &mut warnings,\n                platform: None,\n                features: &features,\n                root,\n            };\n            (me.replace(&mut cx)?, me.patch(&mut cx)?)\n        };\n        let profiles = me.profile.clone();\n        if let Some(profiles) = &profiles {\n            profiles.validate(config.cli_unstable(), &features, &mut warnings)?;\n        }\n        let resolve_behavior = me\n            .workspace\n            .as_ref()\n            .and_then(|ws| ws.resolver.as_deref())\n            .map(|r| ResolveBehavior::from_manifest(r))\n            .transpose()?;\n        let workspace_config = match me.workspace {\n            Some(ref toml_config) => {\n                let mut inheritable = toml_config.package.clone().unwrap_or_default();\n                inheritable.update_ws_path(root.to_path_buf());\n                inheritable.update_deps(toml_config.dependencies.clone());\n                let lints = parse_unstable_lints(toml_config.lints.clone(), config, &mut warnings)?;\n                let lints = verify_lints(lints)?;\n                inheritable.update_lints(lints);\n                let ws_root_config = WorkspaceRootConfig::new(\n                    root,\n                    &toml_config.members,\n                    &toml_config.default_members,\n                    &toml_config.exclude,\n                    &Some(inheritable),\n                    &toml_config.metadata,\n                );\n                config\n                    .ws_roots\n                    .borrow_mut()\n                    .insert(root.to_path_buf(), ws_root_config.clone());\n                WorkspaceConfig::Root(ws_root_config)\n            }\n            None => {\n                bail!(\"virtual manifests must be configured with [workspace]\");\n            }\n        };\n        Ok((\n            VirtualManifest::new(\n                replace,\n                patch,\n                workspace_config,\n                profiles,\n                features,\n                resolve_behavior,\n            ),\n            nested_paths,\n        ))\n    }\n\n    fn replace(&self, cx: &mut Context<'_, '_>) -> CargoResult<Vec<(PackageIdSpec, Dependency)>> {\n        if self.patch.is_some() && self.replace.is_some() {\n            bail!(\"cannot specify both [replace] and [patch]\");\n        }\n        let mut replace = Vec::new();\n        for (spec, replacement) in self.replace.iter().flatten() {\n            let mut spec = PackageIdSpec::parse(spec).with_context(|| {\n                format!(\n                    \"replacements must specify a valid semver \\\n                     version to replace, but `{}` does not\",\n                    spec\n                )\n            })?;\n            if spec.url().is_none() {\n                spec.set_url(CRATES_IO_INDEX.parse().unwrap());\n            }\n\n            if replacement.is_version_specified() {\n                bail!(\n                    \"replacements cannot specify a version \\\n                     requirement, but found one for `{}`\",\n                    spec\n                );\n            }\n\n            let mut dep = replacement.to_dependency(spec.name().as_str(), cx, None)?;\n            let version = spec.version().ok_or_else(|| {\n                anyhow!(\n                    \"replacements must specify a version \\\n                     to replace, but `{}` does not\",\n                    spec\n                )\n            })?;\n            unused_dep_keys(\n                dep.name_in_toml().as_str(),\n                \"replace\",\n                replacement.unused_keys(),\n                &mut cx.warnings,\n            );\n            dep.set_version_req(VersionReq::exact(version))\n                .lock_version(version);\n            replace.push((spec, dep));\n        }\n        Ok(replace)\n    }\n\n    fn patch(&self, cx: &mut Context<'_, '_>) -> CargoResult<HashMap<Url, Vec<Dependency>>> {\n        let mut patch = HashMap::new();\n        for (toml_url, deps) in self.patch.iter().flatten() {\n            let url = match &toml_url[..] {\n                CRATES_IO_REGISTRY => CRATES_IO_INDEX.parse().unwrap(),\n                _ => cx\n                    .config\n                    .get_registry_index(toml_url)\n                    .or_else(|_| toml_url.into_url())\n                    .with_context(|| {\n                        format!(\n                            \"[patch] entry `{}` should be a URL or registry name\",\n                            toml_url\n                        )\n                    })?,\n            };\n            patch.insert(\n                url,\n                deps.iter()\n                    .map(|(name, dep)| {\n                        unused_dep_keys(\n                            name,\n                            &format!(\"patch.{toml_url}\",),\n                            dep.unused_keys(),\n                            &mut cx.warnings,\n                        );\n                        dep.to_dependency(name, cx, None)\n                    })\n                    .collect::<CargoResult<Vec<_>>>()?,\n            );\n        }\n        Ok(patch)\n    }\n\n    /// Returns the path to the build script if one exists for this crate.\n    fn maybe_custom_build(\n        &self,\n        build: &Option<StringOrBool>,\n        package_root: &Path,\n    ) -> Option<PathBuf> {\n        let build_rs = package_root.join(\"build.rs\");\n        match *build {\n            // Explicitly no build script.\n            Some(StringOrBool::Bool(false)) => None,\n            Some(StringOrBool::Bool(true)) => Some(build_rs),\n            Some(StringOrBool::String(ref s)) => Some(PathBuf::from(s)),\n            None => {\n                // If there is a `build.rs` file next to the `Cargo.toml`, assume it is\n                // a build script.\n                if build_rs.is_file() {\n                    Some(build_rs)\n                } else {\n                    None\n                }\n            }\n        }\n    }\n\n    pub fn has_profiles(&self) -> bool {\n        self.profile.is_some()\n    }\n\n    pub fn features(&self) -> Option<&BTreeMap<InternedString, Vec<InternedString>>> {\n        self.features.as_ref()\n    }\n}\n\nfn parse_unstable_lints<T: Deserialize<'static>>(\n    lints: Option<toml::Value>,\n    config: &Config,\n    warnings: &mut Vec<String>,\n) -> CargoResult<Option<T>> {\n    let Some(lints) = lints else { return Ok(None); };\n\n    if !config.cli_unstable().lints {\n        warn_for_lint_feature(config, warnings);\n        return Ok(None);\n    }\n\n    lints.try_into().map(Some).map_err(|err| err.into())\n}\n\nfn warn_for_lint_feature(config: &Config, warnings: &mut Vec<String>) {\n    use std::fmt::Write as _;\n\n    let key_name = \"lints\";\n    let feature_name = \"lints\";\n\n    let mut message = String::new();\n\n    let _ = write!(\n        message,\n        \"unused manifest key `{key_name}` (may be supported in a future version)\"\n    );\n    if config.nightly_features_allowed {\n        let _ = write!(\n            message,\n            \"\n\nconsider passing `-Z{feature_name}` to enable this feature.\"\n        );\n    } else {\n        let _ = write!(\n            message,\n            \"\n\nthis Cargo does not support nightly features, but if you\nswitch to nightly channel you can pass\n`-Z{feature_name}` to enable this feature.\",\n        );\n    }\n    warnings.push(message);\n}\n\nfn verify_lints(lints: Option<TomlLints>) -> CargoResult<Option<TomlLints>> {\n    let Some(lints) = lints else { return Ok(None); };\n\n    for (tool, lints) in &lints {\n        let supported = [\"rust\", \"clippy\", \"rustdoc\"];\n        if !supported.contains(&tool.as_str()) {\n            let supported = supported.join(\", \");\n            anyhow::bail!(\"unsupported `{tool}` in `[lints]`, must be one of {supported}\")\n        }\n        for name in lints.keys() {\n            if let Some((prefix, suffix)) = name.split_once(\"::\") {\n                if tool == prefix {\n                    anyhow::bail!(\n                        \"`lints.{tool}.{name}` is not valid lint name; try `lints.{prefix}.{suffix}`\"\n                    )\n                } else if tool == \"rust\" && supported.contains(&prefix) {\n                    anyhow::bail!(\n                        \"`lints.{tool}.{name}` is not valid lint name; try `lints.{prefix}.{suffix}`\"\n                    )\n                } else {\n                    anyhow::bail!(\"`lints.{tool}.{name}` is not a valid lint name\")\n                }\n            }\n        }\n    }\n\n    Ok(Some(lints))\n}\n\nfn lints_to_rustflags(lints: &TomlLints) -> Vec<String> {\n    let mut rustflags = lints\n        .iter()\n        .flat_map(|(tool, lints)| {\n            lints.iter().map(move |(name, config)| {\n                let flag = config.level().flag();\n                let option = if tool == \"rust\" {\n                    format!(\"{flag}={name}\")\n                } else {\n                    format!(\"{flag}={tool}::{name}\")\n                };\n                (\n                    config.priority(),\n                    // Since the most common group will be `all`, put it last so people are more\n                    // likely to notice that they need to use `priority`.\n                    std::cmp::Reverse(name),\n                    option,\n                )\n            })\n        })\n        .collect::<Vec<_>>();\n    rustflags.sort();\n    rustflags.into_iter().map(|(_, _, option)| option).collect()\n}\n\nfn unused_dep_keys(\n    dep_name: &str,\n    kind: &str,\n    unused_keys: Vec<String>,\n    warnings: &mut Vec<String>,\n) {\n    for unused in unused_keys {\n        let key = format!(\"unused manifest key: {kind}.{dep_name}.{unused}\");\n        warnings.push(key);\n    }\n}\n\nfn inheritable_from_path(\n    config: &Config,\n    workspace_path: PathBuf,\n) -> CargoResult<InheritableFields> {\n    // Workspace path should have Cargo.toml at the end\n    let workspace_path_root = workspace_path.parent().unwrap();\n\n    // Let the borrow exit scope so that it can be picked up if there is a need to\n    // read a manifest\n    if let Some(ws_root) = config.ws_roots.borrow().get(workspace_path_root) {\n        return Ok(ws_root.inheritable().clone());\n    };\n\n    let source_id = SourceId::for_path(workspace_path_root)?;\n    let (man, _) = read_manifest(&workspace_path, source_id, config)?;\n    match man.workspace_config() {\n        WorkspaceConfig::Root(root) => {\n            config\n                .ws_roots\n                .borrow_mut()\n                .insert(workspace_path, root.clone());\n            Ok(root.inheritable().clone())\n        }\n        _ => bail!(\n            \"root of a workspace inferred but wasn't a root: {}\",\n            workspace_path.display()\n        ),\n    }\n}\n\n/// Returns the name of the README file for a [`TomlPackage`].\npub fn readme_for_package(package_root: &Path, readme: Option<StringOrBool>) -> Option<String> {\n    match &readme {\n        None => default_readme_from_package_root(package_root),\n        Some(value) => match value {\n            StringOrBool::Bool(false) => None,\n            StringOrBool::Bool(true) => Some(\"README.md\".to_string()),\n            StringOrBool::String(v) => Some(v.clone()),\n        },\n    }\n}\n\nconst DEFAULT_README_FILES: [&str; 3] = [\"README.md\", \"README.txt\", \"README\"];\n\n/// Checks if a file with any of the default README file names exists in the package root.\n/// If so, returns a `String` representing that name.\nfn default_readme_from_package_root(package_root: &Path) -> Option<String> {\n    for &readme_filename in DEFAULT_README_FILES.iter() {\n        if package_root.join(readme_filename).is_file() {\n            return Some(readme_filename.to_string());\n        }\n    }\n\n    None\n}\n\n/// Checks a list of build targets, and ensures the target names are unique within a vector.\n/// If not, the name of the offending build target is returned.\nfn unique_build_targets(\n    targets: &[Target],\n    package_root: &Path,\n) -> Result<(), HashMap<PathBuf, Vec<Target>>> {\n    let mut source_targets = HashMap::<_, Vec<_>>::new();\n    for target in targets {\n        if let TargetSourcePath::Path(path) = target.src_path() {\n            let full = package_root.join(path);\n            source_targets.entry(full).or_default().push(target.clone());\n        }\n    }\n\n    let conflict_targets = source_targets\n        .into_iter()\n        .filter(|(_, targets)| targets.len() > 1)\n        .collect::<HashMap<_, _>>();\n\n    if !conflict_targets.is_empty() {\n        return Err(conflict_targets);\n    }\n\n    Ok(())\n}\n\nimpl<P: ResolveToPath + Clone> TomlDependency<P> {\n    pub(crate) fn to_dependency_split(\n        &self,\n        name: &str,\n        source_id: SourceId,\n        nested_paths: &mut Vec<PathBuf>,\n        config: &Config,\n        warnings: &mut Vec<String>,\n        platform: Option<Platform>,\n        root: &Path,\n        features: &Features,\n        kind: Option<DepKind>,\n    ) -> CargoResult<Dependency> {\n        self.to_dependency(\n            name,\n            &mut Context {\n                deps: &mut Vec::new(),\n                source_id,\n                nested_paths,\n                config,\n                warnings,\n                platform,\n                root,\n                features,\n            },\n            kind,\n        )\n    }\n\n    fn to_dependency(\n        &self,\n        name: &str,\n        cx: &mut Context<'_, '_>,\n        kind: Option<DepKind>,\n    ) -> CargoResult<Dependency> {\n        match *self {\n            TomlDependency::Simple(ref version) => DetailedTomlDependency::<P> {\n                version: Some(version.clone()),\n                ..Default::default()\n            }\n            .to_dependency(name, cx, kind),\n            TomlDependency::Detailed(ref details) => details.to_dependency(name, cx, kind),\n        }\n    }\n\n    fn is_version_specified(&self) -> bool {\n        match self {\n            TomlDependency::Detailed(d) => d.version.is_some(),\n            TomlDependency::Simple(..) => true,\n        }\n    }\n\n    fn is_optional(&self) -> bool {\n        match self {\n            TomlDependency::Detailed(d) => d.optional.unwrap_or(false),\n            TomlDependency::Simple(..) => false,\n        }\n    }\n}\n\nimpl<P: ResolveToPath + Clone> DetailedTomlDependency<P> {\n    fn to_dependency(\n        &self,\n        name_in_toml: &str,\n        cx: &mut Context<'_, '_>,\n        kind: Option<DepKind>,\n    ) -> CargoResult<Dependency> {\n        if self.version.is_none() && self.path.is_none() && self.git.is_none() {\n            let msg = format!(\n                \"dependency ({}) specified without \\\n                 providing a local path, Git repository, version, or \\\n                 workspace dependency to use. This will be considered an \\\n                 error in future versions\",\n                name_in_toml\n            );\n            cx.warnings.push(msg);\n        }\n\n        if let Some(version) = &self.version {\n            if version.contains('+') {\n                cx.warnings.push(format!(\n                    \"version requirement `{}` for dependency `{}` \\\n                     includes semver metadata which will be ignored, removing the \\\n                     metadata is recommended to avoid confusion\",\n                    version, name_in_toml\n                ));\n            }\n        }\n\n        if self.git.is_none() {\n            let git_only_keys = [\n                (&self.branch, \"branch\"),\n                (&self.tag, \"tag\"),\n                (&self.rev, \"rev\"),\n            ];\n\n            for &(key, key_name) in &git_only_keys {\n                if key.is_some() {\n                    bail!(\n                        \"key `{}` is ignored for dependency ({}).\",\n                        key_name,\n                        name_in_toml\n                    );\n                }\n            }\n        }\n\n        // Early detection of potentially misused feature syntax\n        // instead of generating a \"feature not found\" error.\n        if let Some(features) = &self.features {\n            for feature in features {\n                if feature.contains('/') {\n                    bail!(\n                        \"feature `{}` in dependency `{}` is not allowed to contain slashes\\n\\\n                         If you want to enable features of a transitive dependency, \\\n                         the direct dependency needs to re-export those features from \\\n                         the `[features]` table.\",\n                        feature,\n                        name_in_toml\n                    );\n                }\n                if feature.starts_with(\"dep:\") {\n                    bail!(\n                        \"feature `{}` in dependency `{}` is not allowed to use explicit \\\n                        `dep:` syntax\\n\\\n                         If you want to enable an optional dependency, specify the name \\\n                         of the optional dependency without the `dep:` prefix, or specify \\\n                         a feature from the dependency's `[features]` table that enables \\\n                         the optional dependency.\",\n                        feature,\n                        name_in_toml\n                    );\n                }\n            }\n        }\n\n        let new_source_id = match (\n            self.git.as_ref(),\n            self.path.as_ref(),\n            self.registry.as_ref(),\n            self.registry_index.as_ref(),\n        ) {\n            (Some(_), _, Some(_), _) | (Some(_), _, _, Some(_)) => bail!(\n                \"dependency ({}) specification is ambiguous. \\\n                 Only one of `git` or `registry` is allowed.\",\n                name_in_toml\n            ),\n            (_, _, Some(_), Some(_)) => bail!(\n                \"dependency ({}) specification is ambiguous. \\\n                 Only one of `registry` or `registry-index` is allowed.\",\n                name_in_toml\n            ),\n            (Some(git), maybe_path, _, _) => {\n                if maybe_path.is_some() {\n                    bail!(\n                        \"dependency ({}) specification is ambiguous. \\\n                         Only one of `git` or `path` is allowed.\",\n                        name_in_toml\n                    );\n                }\n\n                let n_details = [&self.branch, &self.tag, &self.rev]\n                    .iter()\n                    .filter(|d| d.is_some())\n                    .count();\n\n                if n_details > 1 {\n                    bail!(\n                        \"dependency ({}) specification is ambiguous. \\\n                         Only one of `branch`, `tag` or `rev` is allowed.\",\n                        name_in_toml\n                    );\n                }\n\n                let reference = self\n                    .branch\n                    .clone()\n                    .map(GitReference::Branch)\n                    .or_else(|| self.tag.clone().map(GitReference::Tag))\n                    .or_else(|| self.rev.clone().map(GitReference::Rev))\n                    .unwrap_or(GitReference::DefaultBranch);\n                let loc = git.into_url()?;\n\n                if let Some(fragment) = loc.fragment() {\n                    let msg = format!(\n                        \"URL fragment `#{}` in git URL is ignored for dependency ({}). \\\n                        If you were trying to specify a specific git revision, \\\n                        use `rev = \\\"{}\\\"` in the dependency declaration.\",\n                        fragment, name_in_toml, fragment\n                    );\n                    cx.warnings.push(msg)\n                }\n\n                SourceId::for_git(&loc, reference)?\n            }\n            (None, Some(path), _, _) => {\n                let path = path.resolve(cx.config);\n                cx.nested_paths.push(path.clone());\n                // If the source ID for the package we're parsing is a path\n                // source, then we normalize the path here to get rid of\n                // components like `..`.\n                //\n                // The purpose of this is to get a canonical ID for the package\n                // that we're depending on to ensure that builds of this package\n                // always end up hashing to the same value no matter where it's\n                // built from.\n                if cx.source_id.is_path() {\n                    let path = cx.root.join(path);\n                    let path = paths::normalize_path(&path);\n                    SourceId::for_path(&path)?\n                } else {\n                    cx.source_id\n                }\n            }\n            (None, None, Some(registry), None) => SourceId::alt_registry(cx.config, registry)?,\n            (None, None, None, Some(registry_index)) => {\n                let url = registry_index.into_url()?;\n                SourceId::for_registry(&url)?\n            }\n            (None, None, None, None) => SourceId::crates_io(cx.config)?,\n        };\n\n        let (pkg_name, explicit_name_in_toml) = match self.package {\n            Some(ref s) => (&s[..], Some(name_in_toml)),\n            None => (name_in_toml, None),\n        };\n\n        let version = self.version.as_deref();\n        let mut dep = Dependency::parse(pkg_name, version, new_source_id)?;\n        if self.default_features.is_some() && self.default_features2.is_some() {\n            warn_on_deprecated(\"default-features\", name_in_toml, \"dependency\", cx.warnings);\n        }\n        dep.set_features(self.features.iter().flatten())\n            .set_default_features(\n                self.default_features\n                    .or(self.default_features2)\n                    .unwrap_or(true),\n            )\n            .set_optional(self.optional.unwrap_or(false))\n            .set_platform(cx.platform.clone());\n        if let Some(registry) = &self.registry {\n            let registry_id = SourceId::alt_registry(cx.config, registry)?;\n            dep.set_registry_id(registry_id);\n        }\n        if let Some(registry_index) = &self.registry_index {\n            let url = registry_index.into_url()?;\n            let registry_id = SourceId::for_registry(&url)?;\n            dep.set_registry_id(registry_id);\n        }\n\n        if let Some(kind) = kind {\n            dep.set_kind(kind);\n        }\n        if let Some(name_in_toml) = explicit_name_in_toml {\n            dep.set_explicit_name_in_toml(name_in_toml);\n        }\n\n        if let Some(p) = self.public {\n            cx.features.require(Feature::public_dependency())?;\n\n            if dep.kind() != DepKind::Normal {\n                bail!(\"'public' specifier can only be used on regular dependencies, not {:?} dependencies\", dep.kind());\n            }\n\n            dep.set_public(p);\n        }\n\n        if let (Some(artifact), is_lib, target) = (\n            self.artifact.as_ref(),\n            self.lib.unwrap_or(false),\n            self.target.as_deref(),\n        ) {\n            if cx.config.cli_unstable().bindeps {\n                let artifact = Artifact::parse(artifact, is_lib, target)?;\n                if dep.kind() != DepKind::Build\n                    && artifact.target() == Some(ArtifactTarget::BuildDependencyAssumeTarget)\n                {\n                    bail!(\n                        r#\"`target = \"target\"` in normal- or dev-dependencies has no effect ({})\"#,\n                        name_in_toml\n                    );\n                }\n                dep.set_artifact(artifact)\n            } else {\n                bail!(\"`artifact = \u2026` requires `-Z bindeps` ({})\", name_in_toml);\n            }\n        } else if self.lib.is_some() || self.target.is_some() {\n            for (is_set, specifier) in [\n                (self.lib.is_some(), \"lib\"),\n                (self.target.is_some(), \"target\"),\n            ] {\n                if !is_set {\n                    continue;\n                }\n                bail!(\n                    \"'{}' specifier cannot be used without an 'artifact = \u2026' value ({})\",\n                    specifier,\n                    name_in_toml\n                )\n            }\n        }\n        Ok(dep)\n    }\n}\n\nimpl DetailedTomlDependency {\n    fn add_features(&mut self, features: Option<Vec<String>>) {\n        self.features = match (self.features.clone(), features.clone()) {\n            (Some(dep_feat), Some(inherit_feat)) => Some(\n                dep_feat\n                    .into_iter()\n                    .chain(inherit_feat)\n                    .collect::<Vec<String>>(),\n            ),\n            (Some(dep_fet), None) => Some(dep_fet),\n            (None, Some(inherit_feat)) => Some(inherit_feat),\n            (None, None) => None,\n        };\n    }\n\n    fn update_optional(&mut self, optional: Option<bool>) {\n        self.optional = optional;\n    }\n\n    fn resolve_path(\n        &mut self,\n        name: &str,\n        root_path: &Path,\n        package_root: &Path,\n    ) -> CargoResult<()> {\n        if let Some(rel_path) = &self.path {\n            self.path = Some(resolve_relative_path(\n                name,\n                root_path,\n                package_root,\n                rel_path,\n            )?)\n        }\n        Ok(())\n    }\n}\n\n#[derive(Default, Serialize, Deserialize, Debug, Clone)]\n#[serde(rename_all = \"kebab-case\")]\nstruct TomlTarget {\n    name: Option<String>,\n\n    // The intention was to only accept `crate-type` here but historical\n    // versions of Cargo also accepted `crate_type`, so look for both.\n    crate_type: Option<Vec<String>>,\n    #[serde(rename = \"crate_type\")]\n    crate_type2: Option<Vec<String>>,\n\n    path: Option<PathValue>,\n    // Note that `filename` is used for the cargo-feature `different_binary_name`\n    filename: Option<String>,\n    test: Option<bool>,\n    doctest: Option<bool>,\n    bench: Option<bool>,\n    doc: Option<bool>,\n    plugin: Option<bool>,\n    doc_scrape_examples: Option<bool>,\n    #[serde(rename = \"proc-macro\")]\n    proc_macro_raw: Option<bool>,\n    #[serde(rename = \"proc_macro\")]\n    proc_macro_raw2: Option<bool>,\n    harness: Option<bool>,\n    required_features: Option<Vec<String>>,\n    edition: Option<String>,\n}\n\n#[derive(Clone)]\nstruct PathValue(PathBuf);\n\nimpl<'de> de::Deserialize<'de> for PathValue {\n    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        Ok(PathValue(String::deserialize(deserializer)?.into()))\n    }\n}\n\nimpl ser::Serialize for PathValue {\n    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>\n    where\n        S: ser::Serializer,\n    {\n        self.0.serialize(serializer)\n    }\n}\n\n/// Corresponds to a `target` entry, but `TomlTarget` is already used.\n#[derive(Serialize, Deserialize, Debug, Clone)]\nstruct TomlPlatform {\n    dependencies: Option<BTreeMap<String, MaybeWorkspaceDependency>>,\n    #[serde(rename = \"build-dependencies\")]\n    build_dependencies: Option<BTreeMap<String, MaybeWorkspaceDependency>>,\n    #[serde(rename = \"build_dependencies\")]\n    build_dependencies2: Option<BTreeMap<String, MaybeWorkspaceDependency>>,\n    #[serde(rename = \"dev-dependencies\")]\n    dev_dependencies: Option<BTreeMap<String, MaybeWorkspaceDependency>>,\n    #[serde(rename = \"dev_dependencies\")]\n    dev_dependencies2: Option<BTreeMap<String, MaybeWorkspaceDependency>>,\n}\n\nimpl TomlTarget {\n    fn new() -> TomlTarget {\n        TomlTarget::default()\n    }\n\n    fn name(&self) -> String {\n        match self.name {\n            Some(ref name) => name.clone(),\n            None => panic!(\"target name is required\"),\n        }\n    }\n\n    fn validate_proc_macro(&self, warnings: &mut Vec<String>) {\n        if self.proc_macro_raw.is_some() && self.proc_macro_raw2.is_some() {\n            warn_on_deprecated(\n                \"proc-macro\",\n                self.name().as_str(),\n                \"library target\",\n                warnings,\n            );\n        }\n    }\n\n    fn proc_macro(&self) -> Option<bool> {\n        self.proc_macro_raw.or(self.proc_macro_raw2).or_else(|| {\n            if let Some(types) = self.crate_types() {\n                if types.contains(&\"proc-macro\".to_string()) {\n                    return Some(true);\n                }\n            }\n            None\n        })\n    }\n\n    fn validate_crate_types(&self, target_kind_human: &str, warnings: &mut Vec<String>) {\n        if self.crate_type.is_some() && self.crate_type2.is_some() {\n            warn_on_deprecated(\n                \"crate-type\",\n                self.name().as_str(),\n                format!(\"{target_kind_human} target\").as_str(),\n                warnings,\n            );\n        }\n    }\n\n    fn crate_types(&self) -> Option<&Vec<String>> {\n        self.crate_type\n            .as_ref()\n            .or_else(|| self.crate_type2.as_ref())\n    }\n}\n\nimpl fmt::Debug for PathValue {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.0.fmt(f)\n    }\n}\n\npub type TomlLints = BTreeMap<String, TomlToolLints>;\n\npub type TomlToolLints = BTreeMap<String, TomlLint>;\n\n#[derive(Serialize, Deserialize, Debug, Clone)]\n#[serde(untagged)]\npub enum TomlLint {\n    Level(TomlLintLevel),\n    Config(TomlLintConfig),\n}\n\nimpl TomlLint {\n    fn level(&self) -> TomlLintLevel {\n        match self {\n            Self::Level(level) => *level,\n            Self::Config(config) => config.level,\n        }\n    }\n\n    fn priority(&self) -> i8 {\n        match self {\n            Self::Level(_) => 0,\n            Self::Config(config) => config.priority,\n        }\n    }\n}\n\n#[derive(Serialize, Deserialize, Debug, Clone)]\n#[serde(rename_all = \"kebab-case\")]\npub struct TomlLintConfig {\n    level: TomlLintLevel,\n    #[serde(default)]\n    priority: i8,\n}\n\n#[derive(Serialize, Deserialize, Debug, Copy, Clone)]\n#[serde(rename_all = \"kebab-case\")]\npub enum TomlLintLevel {\n    Forbid,\n    Deny,\n    Warn,\n    Allow,\n}\n\nimpl TomlLintLevel {\n    fn flag(&self) -> &'static str {\n        match self {\n            Self::Forbid => \"--forbid\",\n            Self::Deny => \"--deny\",\n            Self::Warn => \"--warn\",\n            Self::Allow => \"--allow\",\n        }\n    }\n}\n", "//! Tests for `[features]` table.\n\nuse cargo_test_support::paths::CargoPathExt;\nuse cargo_test_support::registry::{Dependency, Package};\nuse cargo_test_support::{basic_manifest, project};\n\n#[cargo_test]\nfn invalid1() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                bar = [\"baz\"]\n            \"#,\n        )\n        .file(\"src/main.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_status(101)\n        .with_stderr(\n            \"\\\n[ERROR] failed to parse manifest at `[..]`\n\nCaused by:\n  feature `bar` includes `baz` which is neither a dependency nor another feature\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn same_name() {\n    // Feature with the same name as a dependency.\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                bar = [\"baz\"]\n                baz = []\n\n                [dependencies.bar]\n                path = \"bar\"\n            \"#,\n        )\n        .file(\"src/main.rs\", \"\")\n        .file(\"bar/Cargo.toml\", &basic_manifest(\"bar\", \"1.0.0\"))\n        .file(\"bar/src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"tree -f\")\n        .arg(\"{p} [{f}]\")\n        .with_stderr(\"\")\n        .with_stdout(\n            \"\\\nfoo v0.0.1 ([..]) []\n\u2514\u2500\u2500 bar v1.0.0 ([..]) []\n\",\n        )\n        .run();\n\n    p.cargo(\"tree --features bar -f\")\n        .arg(\"{p} [{f}]\")\n        .with_stderr(\"\")\n        .with_stdout(\n            \"\\\nfoo v0.0.1 ([..]) [bar,baz]\n\u2514\u2500\u2500 bar v1.0.0 ([..]) []\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn invalid3() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                bar = [\"baz\"]\n\n                [dependencies.baz]\n                path = \"foo\"\n            \"#,\n        )\n        .file(\"src/main.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_status(101)\n        .with_stderr(\n            \"\\\n[ERROR] failed to parse manifest at `[..]`\n\nCaused by:\n  feature `bar` includes `baz`, but `baz` is not an optional dependency\n  A non-optional dependency of the same name is defined; consider adding `optional = true` to its definition.\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn invalid4() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.bar]\n                path = \"bar\"\n                features = [\"bar\"]\n            \"#,\n        )\n        .file(\"src/main.rs\", \"\")\n        .file(\"bar/Cargo.toml\", &basic_manifest(\"bar\", \"0.0.1\"))\n        .file(\"bar/src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_status(101)\n        .with_stderr(\n            \"\\\nerror: failed to select a version for `bar`.\n    ... required by package `foo v0.0.1 ([..])`\nversions that meet the requirements `*` are: 0.0.1\n\nthe package `foo` depends on `bar`, with features: `bar` but `bar` does not have these features.\n\n\nfailed to select a version for `bar` which could resolve this conflict\",\n        )\n        .run();\n\n    p.change_file(\"Cargo.toml\", &basic_manifest(\"foo\", \"0.0.1\"));\n\n    p.cargo(\"check --features test\")\n        .with_status(101)\n        .with_stderr(\"error: Package `foo v0.0.1 ([..])` does not have the feature `test`\")\n        .run();\n}\n\n#[cargo_test]\nfn invalid5() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dev-dependencies.bar]\n                path = \"bar\"\n                optional = true\n            \"#,\n        )\n        .file(\"src/main.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_status(101)\n        .with_stderr(\n            \"\\\n[ERROR] failed to parse manifest at `[..]`\n\nCaused by:\n  dev-dependencies are not allowed to be optional: `bar`\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn invalid6() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                foo = [\"bar/baz\"]\n            \"#,\n        )\n        .file(\"src/main.rs\", \"\")\n        .build();\n\n    p.cargo(\"check --features foo\")\n        .with_status(101)\n        .with_stderr(\n            \"\\\n[ERROR] failed to parse manifest at `[..]`\n\nCaused by:\n  feature `foo` includes `bar/baz`, but `bar` is not a dependency\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn invalid7() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                foo = [\"bar/baz\"]\n                bar = []\n            \"#,\n        )\n        .file(\"src/main.rs\", \"\")\n        .build();\n\n    p.cargo(\"check --features foo\")\n        .with_status(101)\n        .with_stderr(\n            \"\\\n[ERROR] failed to parse manifest at `[..]`\n\nCaused by:\n  feature `foo` includes `bar/baz`, but `bar` is not a dependency\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn invalid8() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.bar]\n                path = \"bar\"\n                features = [\"foo/bar\"]\n            \"#,\n        )\n        .file(\"src/main.rs\", \"\")\n        .file(\"bar/Cargo.toml\", &basic_manifest(\"bar\", \"0.0.1\"))\n        .file(\"bar/src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"check --features foo\")\n        .with_status(101)\n        .with_stderr(\n            \"\\\nerror: failed to parse manifest at `[CWD]/Cargo.toml`\n\nCaused by:\n  feature `foo/bar` in dependency `bar` is not allowed to contain slashes\n  If you want to enable features [..]\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn invalid9() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.bar]\n                path = \"bar\"\n            \"#,\n        )\n        .file(\"src/main.rs\", \"fn main() {}\")\n        .file(\"bar/Cargo.toml\", &basic_manifest(\"bar\", \"0.0.1\"))\n        .file(\"bar/src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"check --features bar\")\n        .with_stderr(\n            \"\\\nerror: Package `foo v0.0.1 ([..])` does not have feature `bar`. It has a required dependency with that name, but only optional dependencies can be used as features.\n\",\n        ).with_status(101).run();\n}\n\n#[cargo_test]\nfn invalid10() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.bar]\n                path = \"bar\"\n                features = [\"baz\"]\n            \"#,\n        )\n        .file(\"src/main.rs\", \"fn main() {}\")\n        .file(\n            \"bar/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"bar\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.baz]\n                path = \"baz\"\n            \"#,\n        )\n        .file(\"bar/src/lib.rs\", \"\")\n        .file(\"bar/baz/Cargo.toml\", &basic_manifest(\"baz\", \"0.0.1\"))\n        .file(\"bar/baz/src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\").with_stderr(\"\\\nerror: failed to select a version for `bar`.\n    ... required by package `foo v0.0.1 ([..])`\nversions that meet the requirements `*` are: 0.0.1\n\nthe package `foo` depends on `bar`, with features: `baz` but `bar` does not have these features.\n It has a required dependency with that name, but only optional dependencies can be used as features.\n\n\nfailed to select a version for `bar` which could resolve this conflict\n\").with_status(101)\n        .run();\n}\n\n#[cargo_test]\nfn no_transitive_dep_feature_requirement() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.derived]\n                path = \"derived\"\n\n                [features]\n                default = [\"derived/bar/qux\"]\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                extern crate derived;\n                fn main() { derived::test(); }\n            \"#,\n        )\n        .file(\n            \"derived/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"derived\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.bar]\n                path = \"../bar\"\n            \"#,\n        )\n        .file(\"derived/src/lib.rs\", \"extern crate bar; pub use bar::test;\")\n        .file(\n            \"bar/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"bar\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                qux = []\n            \"#,\n        )\n        .file(\n            \"bar/src/lib.rs\",\n            r#\"\n                #[cfg(feature = \"qux\")]\n                pub fn test() { print!(\"test\"); }\n            \"#,\n        )\n        .build();\n    p.cargo(\"check\")\n        .with_status(101)\n        .with_stderr(\n            \"\\\nerror: failed to parse manifest at `[CWD]/Cargo.toml`\n\nCaused by:\n  multiple slashes in feature `derived/bar/qux` (included by feature `default`) are not allowed\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn no_feature_doesnt_build() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.bar]\n                path = \"bar\"\n                optional = true\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                #[cfg(feature = \"bar\")]\n                extern crate bar;\n                #[cfg(feature = \"bar\")]\n                fn main() { bar::bar(); println!(\"bar\") }\n                #[cfg(not(feature = \"bar\"))]\n                fn main() {}\n            \"#,\n        )\n        .file(\"bar/Cargo.toml\", &basic_manifest(\"bar\", \"0.0.1\"))\n        .file(\"bar/src/lib.rs\", \"pub fn bar() {}\")\n        .build();\n\n    p.cargo(\"build\")\n        .with_stderr(\n            \"\\\n[COMPILING] foo v0.0.1 ([CWD])\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n    p.process(&p.bin(\"foo\")).with_stdout(\"\").run();\n\n    p.cargo(\"build --features bar -v\")\n        .with_stderr(\n            \"\\\n[COMPILING] bar v0.0.1 ([CWD]/bar)\n[RUNNING] `rustc --crate-name bar [..]\n[DIRTY-MSVC] foo v0.0.1 ([CWD]): the list of features changed\n[COMPILING] foo v0.0.1 ([CWD])\n[RUNNING] `rustc --crate-name foo [..]\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n    p.process(&p.bin(\"foo\")).with_stdout(\"bar\\n\").run();\n}\n\n#[cargo_test]\nfn default_feature_pulled_in() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                default = [\"bar\"]\n\n                [dependencies.bar]\n                path = \"bar\"\n                optional = true\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                #[cfg(feature = \"bar\")]\n                extern crate bar;\n                #[cfg(feature = \"bar\")]\n                fn main() { bar::bar(); println!(\"bar\") }\n                #[cfg(not(feature = \"bar\"))]\n                fn main() {}\n            \"#,\n        )\n        .file(\"bar/Cargo.toml\", &basic_manifest(\"bar\", \"0.0.1\"))\n        .file(\"bar/src/lib.rs\", \"pub fn bar() {}\")\n        .build();\n\n    p.cargo(\"build\")\n        .with_stderr(\n            \"\\\n[COMPILING] bar v0.0.1 ([CWD]/bar)\n[COMPILING] foo v0.0.1 ([CWD])\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n    p.process(&p.bin(\"foo\")).with_stdout(\"bar\\n\").run();\n\n    p.cargo(\"build --no-default-features -v\")\n        .with_stderr(\n            \"\\\n[DIRTY-MSVC] foo v0.0.1 ([CWD]): the list of features changed\n[COMPILING] foo v0.0.1 ([CWD])\n[RUNNING] `rustc --crate-name foo [..]\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n    p.process(&p.bin(\"foo\")).with_stdout(\"\").run();\n}\n\n#[cargo_test]\nfn cyclic_feature() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                default = [\"default\"]\n            \"#,\n        )\n        .file(\"src/main.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_status(101)\n        .with_stderr(\"[ERROR] cyclic feature dependency: feature `default` depends on itself\")\n        .run();\n}\n\n#[cargo_test]\nfn cyclic_feature2() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                foo = [\"bar\"]\n                bar = [\"foo\"]\n            \"#,\n        )\n        .file(\"src/main.rs\", \"fn main() {}\")\n        .build();\n\n    p.cargo(\"check\").with_stdout(\"\").run();\n}\n\n#[cargo_test]\nfn groups_on_groups_on_groups() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                default = [\"f1\"]\n                f1 = [\"f2\", \"bar\"]\n                f2 = [\"f3\", \"f4\"]\n                f3 = [\"f5\", \"f6\", \"baz\"]\n                f4 = [\"f5\", \"f7\"]\n                f5 = [\"f6\"]\n                f6 = [\"f7\"]\n                f7 = [\"bar\"]\n\n                [dependencies.bar]\n                path = \"bar\"\n                optional = true\n\n                [dependencies.baz]\n                path = \"baz\"\n                optional = true\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                #[allow(unused_extern_crates)]\n                extern crate bar;\n                #[allow(unused_extern_crates)]\n                extern crate baz;\n                fn main() {}\n            \"#,\n        )\n        .file(\"bar/Cargo.toml\", &basic_manifest(\"bar\", \"0.0.1\"))\n        .file(\"bar/src/lib.rs\", \"pub fn bar() {}\")\n        .file(\"baz/Cargo.toml\", &basic_manifest(\"baz\", \"0.0.1\"))\n        .file(\"baz/src/lib.rs\", \"pub fn baz() {}\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_stderr(\n            \"\\\n[CHECKING] ba[..] v0.0.1 ([CWD]/ba[..])\n[CHECKING] ba[..] v0.0.1 ([CWD]/ba[..])\n[CHECKING] foo v0.0.1 ([CWD])\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn many_cli_features() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.bar]\n                path = \"bar\"\n                optional = true\n\n                [dependencies.baz]\n                path = \"baz\"\n                optional = true\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                #[allow(unused_extern_crates)]\n                extern crate bar;\n                #[allow(unused_extern_crates)]\n                extern crate baz;\n                fn main() {}\n            \"#,\n        )\n        .file(\"bar/Cargo.toml\", &basic_manifest(\"bar\", \"0.0.1\"))\n        .file(\"bar/src/lib.rs\", \"pub fn bar() {}\")\n        .file(\"baz/Cargo.toml\", &basic_manifest(\"baz\", \"0.0.1\"))\n        .file(\"baz/src/lib.rs\", \"pub fn baz() {}\")\n        .build();\n\n    p.cargo(\"check --features\")\n        .arg(\"bar baz\")\n        .with_stderr(\n            \"\\\n[CHECKING] ba[..] v0.0.1 ([CWD]/ba[..])\n[CHECKING] ba[..] v0.0.1 ([CWD]/ba[..])\n[CHECKING] foo v0.0.1 ([CWD])\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn union_features() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.d1]\n                path = \"d1\"\n                features = [\"f1\"]\n                [dependencies.d2]\n                path = \"d2\"\n                features = [\"f2\"]\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                #[allow(unused_extern_crates)]\n                extern crate d1;\n                extern crate d2;\n                fn main() {\n                    d2::f1();\n                    d2::f2();\n                }\n            \"#,\n        )\n        .file(\n            \"d1/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"d1\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                f1 = [\"d2\"]\n\n                [dependencies.d2]\n                path = \"../d2\"\n                features = [\"f1\"]\n                optional = true\n            \"#,\n        )\n        .file(\"d1/src/lib.rs\", \"\")\n        .file(\n            \"d2/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"d2\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                f1 = []\n                f2 = []\n            \"#,\n        )\n        .file(\n            \"d2/src/lib.rs\",\n            r#\"\n                #[cfg(feature = \"f1\")] pub fn f1() {}\n                #[cfg(feature = \"f2\")] pub fn f2() {}\n            \"#,\n        )\n        .build();\n\n    p.cargo(\"check\")\n        .with_stderr(\n            \"\\\n[CHECKING] d2 v0.0.1 ([CWD]/d2)\n[CHECKING] d1 v0.0.1 ([CWD]/d1)\n[CHECKING] foo v0.0.1 ([CWD])\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn many_features_no_rebuilds() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name    = \"b\"\n                version = \"0.1.0\"\n                authors = []\n\n                [dependencies.a]\n                path = \"a\"\n                features = [\"fall\"]\n            \"#,\n        )\n        .file(\"src/main.rs\", \"fn main() {}\")\n        .file(\n            \"a/Cargo.toml\",\n            r#\"\n                [package]\n                name    = \"a\"\n                version = \"0.1.0\"\n                authors = []\n\n                [features]\n                ftest  = []\n                ftest2 = []\n                fall   = [\"ftest\", \"ftest2\"]\n            \"#,\n        )\n        .file(\"a/src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_stderr(\n            \"\\\n[CHECKING] a v0.1.0 ([CWD]/a)\n[CHECKING] b v0.1.0 ([CWD])\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n    p.root().move_into_the_past();\n\n    p.cargo(\"check -v\")\n        .with_stderr(\n            \"\\\n[FRESH] a v0.1.0 ([..]/a)\n[FRESH] b v0.1.0 ([..])\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n}\n\n// Tests that all cmd lines work with `--features \"\"`\n#[cargo_test]\nfn empty_features() {\n    let p = project().file(\"src/main.rs\", \"fn main() {}\").build();\n\n    p.cargo(\"check --features\").arg(\"\").run();\n}\n\n// Tests that all cmd lines work with `--features \"\"`\n#[cargo_test]\nfn transitive_features() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                foo = [\"bar/baz\"]\n\n                [dependencies.bar]\n                path = \"bar\"\n            \"#,\n        )\n        .file(\"src/main.rs\", \"extern crate bar; fn main() { bar::baz(); }\")\n        .file(\n            \"bar/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"bar\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                baz = []\n            \"#,\n        )\n        .file(\n            \"bar/src/lib.rs\",\n            r#\"#[cfg(feature = \"baz\")] pub fn baz() {}\"#,\n        )\n        .build();\n\n    p.cargo(\"check --features foo\").run();\n}\n\n#[cargo_test]\nfn everything_in_the_lockfile() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                f1 = [\"d1/f1\"]\n                f2 = [\"d2\"]\n\n                [dependencies.d1]\n                path = \"d1\"\n                [dependencies.d2]\n                path = \"d2\"\n                optional = true\n                [dependencies.d3]\n                path = \"d3\"\n                optional = true\n            \"#,\n        )\n        .file(\"src/main.rs\", \"fn main() {}\")\n        .file(\n            \"d1/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"d1\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                f1 = []\n            \"#,\n        )\n        .file(\"d1/src/lib.rs\", \"\")\n        .file(\"d2/Cargo.toml\", &basic_manifest(\"d2\", \"0.0.2\"))\n        .file(\"d2/src/lib.rs\", \"\")\n        .file(\n            \"d3/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"d3\"\n                version = \"0.0.3\"\n                authors = []\n\n                [features]\n                f3 = []\n            \"#,\n        )\n        .file(\"d3/src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"fetch\").run();\n    let lockfile = p.read_lockfile();\n    assert!(\n        lockfile.contains(r#\"name = \"d1\"\"#),\n        \"d1 not found\\n{}\",\n        lockfile\n    );\n    assert!(\n        lockfile.contains(r#\"name = \"d2\"\"#),\n        \"d2 not found\\n{}\",\n        lockfile\n    );\n    assert!(\n        lockfile.contains(r#\"name = \"d3\"\"#),\n        \"d3 not found\\n{}\",\n        lockfile\n    );\n}\n\n#[cargo_test]\nfn no_rebuild_when_frobbing_default_feature() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.1.0\"\n                authors = []\n\n                [dependencies]\n                a = { path = \"a\" }\n                b = { path = \"b\" }\n            \"#,\n        )\n        .file(\"src/lib.rs\", \"\")\n        .file(\n            \"b/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"b\"\n                version = \"0.1.0\"\n                authors = []\n\n                [dependencies]\n                a = { path = \"../a\", features = [\"f1\"], default-features = false }\n            \"#,\n        )\n        .file(\"b/src/lib.rs\", \"\")\n        .file(\n            \"a/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"a\"\n                version = \"0.1.0\"\n                authors = []\n\n                [features]\n                default = [\"f1\"]\n                f1 = []\n            \"#,\n        )\n        .file(\"a/src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\").run();\n    p.cargo(\"check\").with_stdout(\"\").run();\n    p.cargo(\"check\").with_stdout(\"\").run();\n}\n\n#[cargo_test]\nfn unions_work_with_no_default_features() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.1.0\"\n                authors = []\n\n                [dependencies]\n                a = { path = \"a\" }\n                b = { path = \"b\" }\n            \"#,\n        )\n        .file(\"src/lib.rs\", \"extern crate a; pub fn foo() { a::a(); }\")\n        .file(\n            \"b/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"b\"\n                version = \"0.1.0\"\n                authors = []\n\n                [dependencies]\n                a = { path = \"../a\", features = [], default-features = false }\n            \"#,\n        )\n        .file(\"b/src/lib.rs\", \"\")\n        .file(\n            \"a/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"a\"\n                version = \"0.1.0\"\n                authors = []\n\n                [features]\n                default = [\"f1\"]\n                f1 = []\n            \"#,\n        )\n        .file(\"a/src/lib.rs\", r#\"#[cfg(feature = \"f1\")] pub fn a() {}\"#)\n        .build();\n\n    p.cargo(\"check\").run();\n    p.cargo(\"check\").with_stdout(\"\").run();\n    p.cargo(\"check\").with_stdout(\"\").run();\n}\n\n#[cargo_test]\nfn optional_and_dev_dep() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name    = \"test\"\n                version = \"0.1.0\"\n                authors = []\n\n                [dependencies]\n                foo = { path = \"foo\", optional = true }\n                [dev-dependencies]\n                foo = { path = \"foo\" }\n            \"#,\n        )\n        .file(\"src/lib.rs\", \"\")\n        .file(\"foo/Cargo.toml\", &basic_manifest(\"foo\", \"0.1.0\"))\n        .file(\"foo/src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_stderr(\n            \"\\\n[CHECKING] test v0.1.0 ([..])\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn activating_feature_activates_dep() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name    = \"test\"\n                version = \"0.1.0\"\n                authors = []\n\n                [dependencies]\n                foo = { path = \"foo\", optional = true }\n\n                [features]\n                a = [\"foo/a\"]\n            \"#,\n        )\n        .file(\n            \"src/lib.rs\",\n            \"extern crate foo; pub fn bar() { foo::bar(); }\",\n        )\n        .file(\n            \"foo/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.1.0\"\n                authors = []\n\n                [features]\n                a = []\n            \"#,\n        )\n        .file(\"foo/src/lib.rs\", r#\"#[cfg(feature = \"a\")] pub fn bar() {}\"#)\n        .build();\n\n    p.cargo(\"check --features a -v\").run();\n}\n\n#[cargo_test]\nfn dep_feature_in_cmd_line() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.derived]\n                path = \"derived\"\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                extern crate derived;\n                fn main() { derived::test(); }\n            \"#,\n        )\n        .file(\n            \"derived/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"derived\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.bar]\n                path = \"../bar\"\n\n                [features]\n                default = []\n                derived-feat = [\"bar/some-feat\"]\n            \"#,\n        )\n        .file(\"derived/src/lib.rs\", \"extern crate bar; pub use bar::test;\")\n        .file(\n            \"bar/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"bar\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                some-feat = []\n            \"#,\n        )\n        .file(\n            \"bar/src/lib.rs\",\n            r#\"\n                #[cfg(feature = \"some-feat\")]\n                pub fn test() { print!(\"test\"); }\n            \"#,\n        )\n        .build();\n\n    // The foo project requires that feature \"some-feat\" in \"bar\" is enabled.\n    // Building without any features enabled should fail:\n    p.cargo(\"check\")\n        .with_status(101)\n        .with_stderr_contains(\"[..]unresolved import `bar::test`\")\n        .run();\n\n    // We should be able to enable the feature \"derived-feat\", which enables \"some-feat\",\n    // on the command line. The feature is enabled, thus building should be successful:\n    p.cargo(\"check --features derived/derived-feat\").run();\n\n    // Trying to enable features of transitive dependencies is an error\n    p.cargo(\"check --features bar/some-feat\")\n        .with_status(101)\n        .with_stderr(\"error: package `foo v0.0.1 ([..])` does not have a dependency named `bar`\")\n        .run();\n\n    // Hierarchical feature specification should still be disallowed\n    p.cargo(\"check --features derived/bar/some-feat\")\n        .with_status(101)\n        .with_stderr(\"[ERROR] multiple slashes in feature `derived/bar/some-feat` is not allowed\")\n        .run();\n}\n\n#[cargo_test]\nfn all_features_flag_enables_all_features() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                foo = []\n                bar = []\n\n                [dependencies.baz]\n                path = \"baz\"\n                optional = true\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                #[cfg(feature = \"foo\")]\n                pub fn foo() {}\n\n                #[cfg(feature = \"bar\")]\n                pub fn bar() {\n                    extern crate baz;\n                    baz::baz();\n                }\n\n                fn main() {\n                    foo();\n                    bar();\n                }\n            \"#,\n        )\n        .file(\"baz/Cargo.toml\", &basic_manifest(\"baz\", \"0.0.1\"))\n        .file(\"baz/src/lib.rs\", \"pub fn baz() {}\")\n        .build();\n\n    p.cargo(\"check --all-features\").run();\n}\n\n#[cargo_test]\nfn many_cli_features_comma_delimited() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.bar]\n                path = \"bar\"\n                optional = true\n\n                [dependencies.baz]\n                path = \"baz\"\n                optional = true\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                #[allow(unused_extern_crates)]\n                extern crate bar;\n                #[allow(unused_extern_crates)]\n                extern crate baz;\n                fn main() {}\n            \"#,\n        )\n        .file(\"bar/Cargo.toml\", &basic_manifest(\"bar\", \"0.0.1\"))\n        .file(\"bar/src/lib.rs\", \"pub fn bar() {}\")\n        .file(\"baz/Cargo.toml\", &basic_manifest(\"baz\", \"0.0.1\"))\n        .file(\"baz/src/lib.rs\", \"pub fn baz() {}\")\n        .build();\n\n    p.cargo(\"check --features bar,baz\")\n        .with_stderr(\n            \"\\\n[CHECKING] ba[..] v0.0.1 ([CWD]/ba[..])\n[CHECKING] ba[..] v0.0.1 ([CWD]/ba[..])\n[CHECKING] foo v0.0.1 ([CWD])\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn many_cli_features_comma_and_space_delimited() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.bar]\n                path = \"bar\"\n                optional = true\n\n                [dependencies.baz]\n                path = \"baz\"\n                optional = true\n\n                [dependencies.bam]\n                path = \"bam\"\n                optional = true\n\n                [dependencies.bap]\n                path = \"bap\"\n                optional = true\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                #[allow(unused_extern_crates)]\n                extern crate bar;\n                #[allow(unused_extern_crates)]\n                extern crate baz;\n                #[allow(unused_extern_crates)]\n                extern crate bam;\n                #[allow(unused_extern_crates)]\n                extern crate bap;\n                fn main() {}\n            \"#,\n        )\n        .file(\"bar/Cargo.toml\", &basic_manifest(\"bar\", \"0.0.1\"))\n        .file(\"bar/src/lib.rs\", \"pub fn bar() {}\")\n        .file(\"baz/Cargo.toml\", &basic_manifest(\"baz\", \"0.0.1\"))\n        .file(\"baz/src/lib.rs\", \"pub fn baz() {}\")\n        .file(\"bam/Cargo.toml\", &basic_manifest(\"bam\", \"0.0.1\"))\n        .file(\"bam/src/lib.rs\", \"pub fn bam() {}\")\n        .file(\"bap/Cargo.toml\", &basic_manifest(\"bap\", \"0.0.1\"))\n        .file(\"bap/src/lib.rs\", \"pub fn bap() {}\")\n        .build();\n\n    p.cargo(\"check --features\")\n        .arg(\"bar,baz bam bap\")\n        .with_stderr(\n            \"\\\n[CHECKING] ba[..] v0.0.1 ([CWD]/ba[..])\n[CHECKING] ba[..] v0.0.1 ([CWD]/ba[..])\n[CHECKING] ba[..] v0.0.1 ([CWD]/ba[..])\n[CHECKING] ba[..] v0.0.1 ([CWD]/ba[..])\n[CHECKING] foo v0.0.1 ([CWD])\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn only_dep_is_optional() {\n    Package::new(\"bar\", \"0.1.0\").publish();\n\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                foo = ['bar']\n\n                [dependencies]\n                bar = { version = \"0.1\", optional = true }\n\n                [dev-dependencies]\n                bar = \"0.1\"\n            \"#,\n        )\n        .file(\"src/main.rs\", \"fn main() {}\")\n        .build();\n\n    p.cargo(\"check\").run();\n}\n\n#[cargo_test]\nfn all_features_all_crates() {\n    Package::new(\"bar\", \"0.1.0\").publish();\n\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [workspace]\n                members = ['bar']\n            \"#,\n        )\n        .file(\"src/main.rs\", \"fn main() {}\")\n        .file(\n            \"bar/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"bar\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                foo = []\n            \"#,\n        )\n        .file(\"bar/src/main.rs\", \"#[cfg(feature = \\\"foo\\\")] fn main() {}\")\n        .build();\n\n    p.cargo(\"check --all-features --workspace\").run();\n}\n\n#[cargo_test]\nfn feature_off_dylib() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [workspace]\n                members = [\"bar\"]\n\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n\n                [lib]\n                crate-type = [\"dylib\"]\n\n                [features]\n                f1 = []\n            \"#,\n        )\n        .file(\n            \"src/lib.rs\",\n            r#\"\n                pub fn hello() -> &'static str {\n                    if cfg!(feature = \"f1\") {\n                        \"f1\"\n                    } else {\n                        \"no f1\"\n                    }\n                }\n            \"#,\n        )\n        .file(\n            \"bar/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"bar\"\n                version = \"0.0.1\"\n\n                [dependencies]\n                foo = { path = \"..\" }\n            \"#,\n        )\n        .file(\n            \"bar/src/main.rs\",\n            r#\"\n                extern crate foo;\n\n                fn main() {\n                    assert_eq!(foo::hello(), \"no f1\");\n                }\n            \"#,\n        )\n        .build();\n\n    // Build the dylib with `f1` feature.\n    p.cargo(\"check --features f1\").run();\n    // Check that building without `f1` uses a dylib without `f1`.\n    p.cargo(\"run -p bar\").run();\n}\n\n#[cargo_test]\nfn warn_if_default_features() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n               [package]\n               name = \"foo\"\n               version = \"0.0.1\"\n               authors = []\n\n               [dependencies.bar]\n               path = \"bar\"\n               optional = true\n\n               [features]\n               default-features = [\"bar\"]\n            \"#,\n        )\n        .file(\"src/main.rs\", \"fn main() {}\")\n        .file(\"bar/Cargo.toml\", &basic_manifest(\"bar\", \"0.0.1\"))\n        .file(\"bar/src/lib.rs\", \"pub fn bar() {}\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_stderr(\n            r#\"\n[WARNING] `default-features = [\"..\"]` was found in [features]. Did you mean to use `default = [\"..\"]`?\n[CHECKING] foo v0.0.1 ([CWD])\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n            \"#.trim(),\n        ).run();\n}\n\n#[cargo_test]\nfn no_feature_for_non_optional_dep() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies]\n                bar = { path = \"bar\" }\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                #[cfg(not(feature = \"bar\"))]\n                fn main() {\n                }\n            \"#,\n        )\n        .file(\n            \"bar/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"bar\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                a = []\n            \"#,\n        )\n        .file(\"bar/src/lib.rs\", \"pub fn bar() {}\")\n        .build();\n\n    p.cargo(\"check --features bar/a\").run();\n}\n\n#[cargo_test]\nfn features_option_given_twice() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                a = []\n                b = []\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                #[cfg(all(feature = \"a\", feature = \"b\"))]\n                fn main() {}\n            \"#,\n        )\n        .build();\n\n    p.cargo(\"check --features a --features b\").run();\n}\n\n#[cargo_test]\nfn multi_multi_features() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                a = []\n                b = []\n                c = []\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n               #[cfg(all(feature = \"a\", feature = \"b\", feature = \"c\"))]\n               fn main() {}\n            \"#,\n        )\n        .build();\n\n    p.cargo(\"check --features a --features\").arg(\"b c\").run();\n}\n\n#[cargo_test]\nfn cli_parse_ok() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                a = []\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n               #[cfg(feature = \"a\")]\n               fn main() {\n                    assert_eq!(std::env::args().nth(1).unwrap(), \"b\");\n               }\n            \"#,\n        )\n        .build();\n\n    p.cargo(\"run --features a b\").run();\n}\n\n#[cargo_test]\nfn all_features_virtual_ws() {\n    // What happens with `--all-features` in the root of a virtual workspace.\n    // Some of this behavior is a little strange (member dependencies also\n    // have all features enabled, one might expect `f4` to be disabled).\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [workspace]\n                members = [\"a\", \"b\"]\n            \"#,\n        )\n        .file(\n            \"a/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"a\"\n                version = \"0.1.0\"\n                edition = \"2018\"\n\n                [dependencies]\n                b = {path=\"../b\", optional=true}\n\n                [features]\n                default = [\"f1\"]\n                f1 = []\n                f2 = []\n            \"#,\n        )\n        .file(\n            \"a/src/main.rs\",\n            r#\"\n                fn main() {\n                    if cfg!(feature=\"f1\") {\n                        println!(\"f1\");\n                    }\n                    if cfg!(feature=\"f2\") {\n                        println!(\"f2\");\n                    }\n                    #[cfg(feature=\"b\")]\n                    b::f();\n                }\n            \"#,\n        )\n        .file(\n            \"b/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"b\"\n                version = \"0.1.0\"\n\n                [features]\n                default = [\"f3\"]\n                f3 = []\n                f4 = []\n            \"#,\n        )\n        .file(\n            \"b/src/lib.rs\",\n            r#\"\n                pub fn f() {\n                    if cfg!(feature=\"f3\") {\n                        println!(\"f3\");\n                    }\n                    if cfg!(feature=\"f4\") {\n                        println!(\"f4\");\n                    }\n                }\n            \"#,\n        )\n        .build();\n\n    p.cargo(\"run\").with_stdout(\"f1\\n\").run();\n    p.cargo(\"run --all-features\")\n        .with_stdout(\"f1\\nf2\\nf3\\nf4\\n\")\n        .run();\n    // In `a`, it behaves differently. :(\n    p.cargo(\"run --all-features\")\n        .cwd(\"a\")\n        .with_stdout(\"f1\\nf2\\nf3\\n\")\n        .run();\n}\n\n#[cargo_test]\nfn slash_optional_enables() {\n    // --features dep/feat will enable `dep` and set its feature.\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n            [package]\n            name = \"foo\"\n            version = \"0.1.0\"\n\n            [dependencies]\n            dep = {path=\"dep\", optional=true}\n            \"#,\n        )\n        .file(\n            \"src/lib.rs\",\n            r#\"\n            #[cfg(not(feature=\"dep\"))]\n            compile_error!(\"dep not set\");\n            \"#,\n        )\n        .file(\n            \"dep/Cargo.toml\",\n            r#\"\n            [package]\n            name = \"dep\"\n            version = \"0.1.0\"\n\n            [features]\n            feat = []\n            \"#,\n        )\n        .file(\n            \"dep/src/lib.rs\",\n            r#\"\n            #[cfg(not(feature=\"feat\"))]\n            compile_error!(\"feat not set\");\n            \"#,\n        )\n        .build();\n\n    p.cargo(\"check\")\n        .with_status(101)\n        .with_stderr_contains(\"[..]dep not set[..]\")\n        .run();\n\n    p.cargo(\"check --features dep/feat\").run();\n}\n\n#[cargo_test]\nfn registry_summary_order_doesnt_matter() {\n    // Checks for an issue where the resolver depended on the order of entries\n    // in the registry summary. If there was a non-optional dev-dependency\n    // that appeared before an optional normal dependency, then the resolver\n    // would not activate the optional dependency with a pkg/featname feature\n    // syntax.\n    Package::new(\"dep\", \"0.1.0\")\n        .feature(\"feat1\", &[])\n        .file(\n            \"src/lib.rs\",\n            r#\"\n                #[cfg(feature=\"feat1\")]\n                pub fn work() {\n                    println!(\"it works\");\n                }\n            \"#,\n        )\n        .publish();\n    Package::new(\"bar\", \"0.1.0\")\n        .feature(\"bar_feat\", &[\"dep/feat1\"])\n        .add_dep(Dependency::new(\"dep\", \"0.1.0\").dev())\n        .add_dep(Dependency::new(\"dep\", \"0.1.0\").optional(true))\n        .file(\n            \"src/lib.rs\",\n            r#\"\n                // This will fail to compile without `dep` optional dep activated.\n                extern crate dep;\n\n                pub fn doit() {\n                    dep::work();\n                }\n            \"#,\n        )\n        .publish();\n\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.1.0\"\n                edition = \"2018\"\n\n                [dependencies]\n                bar = { version=\"0.1\", features = [\"bar_feat\"] }\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                fn main() {\n                    bar::doit();\n                }\n            \"#,\n        )\n        .build();\n\n    p.cargo(\"run\")\n        .with_stderr(\n            \"\\\n[UPDATING] [..]\n[DOWNLOADING] crates ...\n[DOWNLOADED] [..]\n[DOWNLOADED] [..]\n[COMPILING] dep v0.1.0\n[COMPILING] bar v0.1.0\n[COMPILING] foo v0.1.0 [..]\n[FINISHED] [..]\n[RUNNING] `target/debug/foo[EXE]`\n\",\n        )\n        .with_stdout(\"it works\")\n        .run();\n}\n\n#[cargo_test]\nfn nonexistent_required_features() {\n    Package::new(\"required_dependency\", \"0.1.0\")\n        .feature(\"simple\", &[])\n        .publish();\n    Package::new(\"optional_dependency\", \"0.2.0\")\n        .feature(\"optional\", &[])\n        .publish();\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n            [package]\n            name = \"foo\"\n            version = \"0.1.0\"\n            [features]\n            existing = []\n            fancy = [\"optional_dependency\"]\n            [dependencies]\n            required_dependency = { version = \"0.1\", optional = false}\n            optional_dependency = { version = \"0.2\", optional = true}\n            [[example]]\n            name = \"ololo\"\n            required-features = [\"not_present\",\n                                 \"existing\",\n                                 \"fancy\",\n                                 \"required_dependency/not_existing\",\n                                 \"required_dependency/simple\",\n                                 \"optional_dependency/optional\",\n                                 \"not_specified_dependency/some_feature\"]\n            \"#,\n        )\n        .file(\"src/main.rs\", \"fn main() {}\")\n        .file(\"examples/ololo.rs\", \"fn main() {}\")\n        .build();\n\n    p.cargo(\"check --examples\")\n        .with_stderr_contains(\n            \"\\\n[WARNING] invalid feature `not_present` in required-features of target `ololo`: \\\n    `not_present` is not present in [features] section\n[WARNING] invalid feature `required_dependency/not_existing` in required-features \\\n    of target `ololo`: feature `not_existing` does not exist in package \\\n    `required_dependency v0.1.0`\n[WARNING] invalid feature `not_specified_dependency/some_feature` in required-features \\\n    of target `ololo`: dependency `not_specified_dependency` does not exist\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn invalid_feature_names_warning() {\n    // Warnings for more restricted feature syntax.\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.1.0\"\n\n                [features]\n                # Some valid, but unusual names, shouldn't warn.\n                \"c++17\" = []\n                \"128bit\" = []\n                \"_foo\" = []\n                \"feat-name\" = []\n                \"feat_name\" = []\n                \"foo.bar\" = []\n\n                # Invalid names.\n                \"+foo\" = []\n                \"-foo\" = []\n                \".foo\" = []\n                \"foo:bar\" = []\n                \"foo?\" = []\n                \"?foo\" = []\n                \"\u24b6\u24b7\u24b8\" = []\n                \"a\u00bc\" = []\n            \"#,\n        )\n        .file(\"src/lib.rs\", \"\")\n        .build();\n\n    // Unfortunately the warnings are duplicated due to the Summary being\n    // loaded twice (once in the Workspace, and once in PackageRegistry) and\n    // Cargo does not have a de-duplication system. This should probably be\n    // OK, since I'm not expecting this to affect anyone.\n    p.cargo(\"check\")\n        .with_stderr(\"\\\n[WARNING] invalid character `+` in feature `+foo` in package foo v0.1.0 ([ROOT]/foo), the first character must be a Unicode XID start character or digit (most letters or `_` or `0` to `9`)\nThis was previously accepted but is being phased out; it will become a hard error in a future release.\nFor more information, see issue #8813 <https://github.com/rust-lang/cargo/issues/8813>, and please leave a comment if this will be a problem for your project.\n[WARNING] invalid character `-` in feature `-foo` in package foo v0.1.0 ([ROOT]/foo), the first character must be a Unicode XID start character or digit (most letters or `_` or `0` to `9`)\nThis was previously accepted but is being phased out; it will become a hard error in a future release.\nFor more information, see issue #8813 <https://github.com/rust-lang/cargo/issues/8813>, and please leave a comment if this will be a problem for your project.\n[WARNING] invalid character `.` in feature `.foo` in package foo v0.1.0 ([ROOT]/foo), the first character must be a Unicode XID start character or digit (most letters or `_` or `0` to `9`)\nThis was previously accepted but is being phased out; it will become a hard error in a future release.\nFor more information, see issue #8813 <https://github.com/rust-lang/cargo/issues/8813>, and please leave a comment if this will be a problem for your project.\n[WARNING] invalid character `?` in feature `?foo` in package foo v0.1.0 ([ROOT]/foo), the first character must be a Unicode XID start character or digit (most letters or `_` or `0` to `9`)\nThis was previously accepted but is being phased out; it will become a hard error in a future release.\nFor more information, see issue #8813 <https://github.com/rust-lang/cargo/issues/8813>, and please leave a comment if this will be a problem for your project.\n[WARNING] invalid character `\u00bc` in feature `a\u00bc` in package foo v0.1.0 ([ROOT]/foo), characters must be Unicode XID characters, `+`, or `.` (numbers, `+`, `-`, `_`, `.`, or most letters)\nThis was previously accepted but is being phased out; it will become a hard error in a future release.\nFor more information, see issue #8813 <https://github.com/rust-lang/cargo/issues/8813>, and please leave a comment if this will be a problem for your project.\n[WARNING] invalid character `:` in feature `foo:bar` in package foo v0.1.0 ([ROOT]/foo), characters must be Unicode XID characters, `+`, or `.` (numbers, `+`, `-`, `_`, `.`, or most letters)\nThis was previously accepted but is being phased out; it will become a hard error in a future release.\nFor more information, see issue #8813 <https://github.com/rust-lang/cargo/issues/8813>, and please leave a comment if this will be a problem for your project.\n[WARNING] invalid character `?` in feature `foo?` in package foo v0.1.0 ([ROOT]/foo), characters must be Unicode XID characters, `+`, or `.` (numbers, `+`, `-`, `_`, `.`, or most letters)\nThis was previously accepted but is being phased out; it will become a hard error in a future release.\nFor more information, see issue #8813 <https://github.com/rust-lang/cargo/issues/8813>, and please leave a comment if this will be a problem for your project.\n[WARNING] invalid character `\u24b6` in feature `\u24b6\u24b7\u24b8` in package foo v0.1.0 ([ROOT]/foo), the first character must be a Unicode XID start character or digit (most letters or `_` or `0` to `9`)\nThis was previously accepted but is being phased out; it will become a hard error in a future release.\nFor more information, see issue #8813 <https://github.com/rust-lang/cargo/issues/8813>, and please leave a comment if this will be a problem for your project.\n[WARNING] invalid character `\u24b7` in feature `\u24b6\u24b7\u24b8` in package foo v0.1.0 ([ROOT]/foo), characters must be Unicode XID characters, `+`, or `.` (numbers, `+`, `-`, `_`, `.`, or most letters)\nThis was previously accepted but is being phased out; it will become a hard error in a future release.\nFor more information, see issue #8813 <https://github.com/rust-lang/cargo/issues/8813>, and please leave a comment if this will be a problem for your project.\n[WARNING] invalid character `\u24b8` in feature `\u24b6\u24b7\u24b8` in package foo v0.1.0 ([ROOT]/foo), characters must be Unicode XID characters, `+`, or `.` (numbers, `+`, `-`, `_`, `.`, or most letters)\nThis was previously accepted but is being phased out; it will become a hard error in a future release.\nFor more information, see issue #8813 <https://github.com/rust-lang/cargo/issues/8813>, and please leave a comment if this will be a problem for your project.\n[CHECKING] foo v0.1.0 [..]\n[FINISHED] [..]\n\")\n        .run();\n}\n\n#[cargo_test]\nfn invalid_feature_names_error() {\n    // Errors for more restricted feature syntax.\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.1.0\"\n\n                [features]\n                \"foo/bar\" = []\n            \"#,\n        )\n        .file(\"src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_status(101)\n        .with_stderr(\n            \"\\\nerror: failed to parse manifest at `[CWD]/Cargo.toml`\n\nCaused by:\n  feature named `foo/bar` is not allowed to contain slashes\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn default_features_conflicting_warning() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.1.0\"\n                authors = []\n\n                [dependencies]\n                a = { path = \"a\", features = [\"f1\"], default-features = false, default_features = false }\n            \"#,\n        )\n        .file(\"src/lib.rs\", \"\")\n        .file(\n            \"a/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"a\"\n                version = \"0.1.0\"\n                authors = []\n\n                [features]\n                default = [\"f1\"]\n                f1 = []\n            \"#,\n        )\n        .file(\"a/src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_stderr_contains(\n\"[WARNING] conflicting between `default-features` and `default_features` in the `a` dependency.\\n\n        `default_features` is ignored and not recommended for use in the future\"\n        )\n        .run();\n}\n"], "fixing_code": ["#![allow(clippy::all)]\n\nuse std::cell::RefCell;\nuse std::cmp::PartialEq;\nuse std::cmp::{max, min};\nuse std::collections::{BTreeMap, BTreeSet, HashMap, HashSet};\nuse std::fmt;\nuse std::fmt::Write;\nuse std::rc::Rc;\nuse std::task::Poll;\nuse std::time::Instant;\n\nuse cargo::core::dependency::DepKind;\nuse cargo::core::resolver::{self, ResolveOpts, VersionPreferences};\nuse cargo::core::source::{GitReference, QueryKind, SourceId};\nuse cargo::core::Resolve;\nuse cargo::core::{Dependency, PackageId, Registry, Summary};\nuse cargo::util::{CargoResult, Config, Graph, IntoUrl};\n\nuse proptest::collection::{btree_map, vec};\nuse proptest::prelude::*;\nuse proptest::sample::Index;\nuse proptest::string::string_regex;\nuse varisat::{self, ExtendFormula};\n\npub fn resolve(deps: Vec<Dependency>, registry: &[Summary]) -> CargoResult<Vec<PackageId>> {\n    resolve_with_config(deps, registry, &Config::default().unwrap())\n}\n\npub fn resolve_and_validated(\n    deps: Vec<Dependency>,\n    registry: &[Summary],\n    sat_resolve: Option<SatResolve>,\n) -> CargoResult<Vec<PackageId>> {\n    let resolve = resolve_with_config_raw(deps.clone(), registry, &Config::default().unwrap());\n\n    match resolve {\n        Err(e) => {\n            let sat_resolve = sat_resolve.unwrap_or_else(|| SatResolve::new(registry));\n            if sat_resolve.sat_resolve(&deps) {\n                panic!(\n                    \"the resolve err but the sat_resolve thinks this will work:\\n{}\",\n                    sat_resolve.use_packages().unwrap()\n                );\n            }\n            Err(e)\n        }\n        Ok(resolve) => {\n            let mut stack = vec![pkg_id(\"root\")];\n            let mut used = HashSet::new();\n            let mut links = HashSet::new();\n            while let Some(p) = stack.pop() {\n                assert!(resolve.contains(&p));\n                if used.insert(p) {\n                    // in the tests all `links` crates end in `-sys`\n                    if p.name().ends_with(\"-sys\") {\n                        assert!(links.insert(p.name()));\n                    }\n                    stack.extend(resolve.deps(p).map(|(dp, deps)| {\n                        for d in deps {\n                            assert!(d.matches_id(dp));\n                        }\n                        dp\n                    }));\n                }\n            }\n            let out = resolve.sort();\n            assert_eq!(out.len(), used.len());\n\n            let mut pub_deps: HashMap<PackageId, HashSet<_>> = HashMap::new();\n            for &p in out.iter() {\n                // make the list of `p` public dependencies\n                let mut self_pub_dep = HashSet::new();\n                self_pub_dep.insert(p);\n                for (dp, deps) in resolve.deps(p) {\n                    if deps.iter().any(|d| d.is_public()) {\n                        self_pub_dep.extend(pub_deps[&dp].iter().cloned())\n                    }\n                }\n                pub_deps.insert(p, self_pub_dep);\n\n                // check if `p` has a public dependencies conflicts\n                let seen_dep: BTreeSet<_> = resolve\n                    .deps(p)\n                    .flat_map(|(dp, _)| pub_deps[&dp].iter().cloned())\n                    .collect();\n                let seen_dep: Vec<_> = seen_dep.iter().collect();\n                for a in seen_dep.windows(2) {\n                    if a[0].name() == a[1].name() {\n                        panic!(\n                            \"the package {:?} can publicly see {:?} and {:?}\",\n                            p, a[0], a[1]\n                        )\n                    }\n                }\n            }\n            let sat_resolve = sat_resolve.unwrap_or_else(|| SatResolve::new(registry));\n            if !sat_resolve.sat_is_valid_solution(&out) {\n                panic!(\n                    \"the sat_resolve err but the resolve thinks this will work:\\n{:?}\",\n                    resolve\n                );\n            }\n            Ok(out)\n        }\n    }\n}\n\npub fn resolve_with_config(\n    deps: Vec<Dependency>,\n    registry: &[Summary],\n    config: &Config,\n) -> CargoResult<Vec<PackageId>> {\n    let resolve = resolve_with_config_raw(deps, registry, config)?;\n    Ok(resolve.sort())\n}\n\npub fn resolve_with_config_raw(\n    deps: Vec<Dependency>,\n    registry: &[Summary],\n    config: &Config,\n) -> CargoResult<Resolve> {\n    struct MyRegistry<'a> {\n        list: &'a [Summary],\n        used: HashSet<PackageId>,\n    }\n    impl<'a> Registry for MyRegistry<'a> {\n        fn query(\n            &mut self,\n            dep: &Dependency,\n            kind: QueryKind,\n            f: &mut dyn FnMut(Summary),\n        ) -> Poll<CargoResult<()>> {\n            for summary in self.list.iter() {\n                let matched = match kind {\n                    QueryKind::Exact => dep.matches(summary),\n                    QueryKind::Fuzzy => true,\n                };\n                if matched {\n                    self.used.insert(summary.package_id());\n                    f(summary.clone());\n                }\n            }\n            Poll::Ready(Ok(()))\n        }\n\n        fn describe_source(&self, _src: SourceId) -> String {\n            String::new()\n        }\n\n        fn is_replaced(&self, _src: SourceId) -> bool {\n            false\n        }\n\n        fn block_until_ready(&mut self) -> CargoResult<()> {\n            Ok(())\n        }\n    }\n    impl<'a> Drop for MyRegistry<'a> {\n        fn drop(&mut self) {\n            if std::thread::panicking() && self.list.len() != self.used.len() {\n                // we found a case that causes a panic and did not use all of the input.\n                // lets print the part of the input that was used for minimization.\n                println!(\n                    \"{:?}\",\n                    PrettyPrintRegistry(\n                        self.list\n                            .iter()\n                            .filter(|s| { self.used.contains(&s.package_id()) })\n                            .cloned()\n                            .collect()\n                    )\n                );\n            }\n        }\n    }\n    let mut registry = MyRegistry {\n        list: registry,\n        used: HashSet::new(),\n    };\n    let summary = Summary::new(\n        pkg_id(\"root\"),\n        deps,\n        &BTreeMap::new(),\n        None::<&String>,\n        None::<&String>,\n    )\n    .unwrap();\n    let opts = ResolveOpts::everything();\n    let start = Instant::now();\n    let resolve = resolver::resolve(\n        &[(summary, opts)],\n        &[],\n        &mut registry,\n        &VersionPreferences::default(),\n        Some(config),\n        true,\n    );\n\n    // The largest test in our suite takes less then 30 sec.\n    // So lets fail the test if we have ben running for two long.\n    assert!(start.elapsed().as_secs() < 60);\n    resolve\n}\n\nconst fn num_bits<T>() -> usize {\n    std::mem::size_of::<T>() * 8\n}\n\nfn log_bits(x: usize) -> usize {\n    if x == 0 {\n        return 0;\n    }\n    assert!(x > 0);\n    (num_bits::<usize>() as u32 - x.leading_zeros()) as usize\n}\n\nfn sat_at_most_one(solver: &mut impl varisat::ExtendFormula, vars: &[varisat::Var]) {\n    if vars.len() <= 1 {\n        return;\n    } else if vars.len() == 2 {\n        solver.add_clause(&[vars[0].negative(), vars[1].negative()]);\n        return;\n    } else if vars.len() == 3 {\n        solver.add_clause(&[vars[0].negative(), vars[1].negative()]);\n        solver.add_clause(&[vars[0].negative(), vars[2].negative()]);\n        solver.add_clause(&[vars[1].negative(), vars[2].negative()]);\n        return;\n    }\n    // use the \"Binary Encoding\" from\n    // https://www.it.uu.se/research/group/astra/ModRef10/papers/Alan%20M.%20Frisch%20and%20Paul%20A.%20Giannoros.%20SAT%20Encodings%20of%20the%20At-Most-k%20Constraint%20-%20ModRef%202010.pdf\n    let bits: Vec<varisat::Var> = solver.new_var_iter(log_bits(vars.len())).collect();\n    for (i, p) in vars.iter().enumerate() {\n        for b in 0..bits.len() {\n            solver.add_clause(&[p.negative(), bits[b].lit(((1 << b) & i) > 0)]);\n        }\n    }\n}\n\nfn sat_at_most_one_by_key<K: std::hash::Hash + Eq>(\n    cnf: &mut impl varisat::ExtendFormula,\n    data: impl Iterator<Item = (K, varisat::Var)>,\n) -> HashMap<K, Vec<varisat::Var>> {\n    // no two packages with the same links set\n    let mut by_keys: HashMap<K, Vec<varisat::Var>> = HashMap::new();\n    for (p, v) in data {\n        by_keys.entry(p).or_default().push(v)\n    }\n    for key in by_keys.values() {\n        sat_at_most_one(cnf, key);\n    }\n    by_keys\n}\n\n/// Resolution can be reduced to the SAT problem. So this is an alternative implementation\n/// of the resolver that uses a SAT library for the hard work. This is intended to be easy to read,\n/// as compared to the real resolver.\n///\n/// For the subset of functionality that are currently made by `registry_strategy` this will,\n/// find a valid resolution if one exists. The big thing that the real resolver does,\n/// that this one does not do is work with features and optional dependencies.\n///\n/// The SAT library dose not optimize for the newer version,\n/// so the selected packages may not match the real resolver.\n#[derive(Clone)]\npub struct SatResolve(Rc<RefCell<SatResolveInner>>);\nstruct SatResolveInner {\n    solver: varisat::Solver<'static>,\n    var_for_is_packages_used: HashMap<PackageId, varisat::Var>,\n    by_name: HashMap<&'static str, Vec<PackageId>>,\n}\n\nimpl SatResolve {\n    pub fn new(registry: &[Summary]) -> Self {\n        let mut cnf = varisat::CnfFormula::new();\n        let var_for_is_packages_used: HashMap<PackageId, varisat::Var> = registry\n            .iter()\n            .map(|s| (s.package_id(), cnf.new_var()))\n            .collect();\n\n        // no two packages with the same links set\n        sat_at_most_one_by_key(\n            &mut cnf,\n            registry\n                .iter()\n                .map(|s| (s.links(), var_for_is_packages_used[&s.package_id()]))\n                .filter(|(l, _)| l.is_some()),\n        );\n\n        // no two semver compatible versions of the same package\n        let by_activations_keys = sat_at_most_one_by_key(\n            &mut cnf,\n            var_for_is_packages_used\n                .iter()\n                .map(|(p, &v)| (p.as_activations_key(), v)),\n        );\n\n        let mut by_name: HashMap<&'static str, Vec<PackageId>> = HashMap::new();\n\n        for p in registry.iter() {\n            by_name\n                .entry(p.name().as_str())\n                .or_default()\n                .push(p.package_id())\n        }\n\n        let empty_vec = vec![];\n\n        let mut graph: Graph<PackageId, ()> = Graph::new();\n\n        let mut version_selected_for: HashMap<\n            PackageId,\n            HashMap<Dependency, HashMap<_, varisat::Var>>,\n        > = HashMap::new();\n        // active packages need each of there `deps` to be satisfied\n        for p in registry.iter() {\n            graph.add(p.package_id());\n            for dep in p.dependencies() {\n                // This can more easily be written as:\n                // !is_active(p) or one of the things that match dep is_active\n                // All the complexity, from here to the end, is to support public and private dependencies!\n                let mut by_key: HashMap<_, Vec<varisat::Lit>> = HashMap::new();\n                for &m in by_name\n                    .get(dep.package_name().as_str())\n                    .unwrap_or(&empty_vec)\n                    .iter()\n                    .filter(|&p| dep.matches_id(*p))\n                {\n                    graph.link(p.package_id(), m);\n                    by_key\n                        .entry(m.as_activations_key())\n                        .or_default()\n                        .push(var_for_is_packages_used[&m].positive());\n                }\n                let keys: HashMap<_, _> = by_key.keys().map(|&k| (k, cnf.new_var())).collect();\n\n                // if `p` is active then we need to select one of the keys\n                let matches: Vec<_> = keys\n                    .values()\n                    .map(|v| v.positive())\n                    .chain(Some(var_for_is_packages_used[&p.package_id()].negative()))\n                    .collect();\n                cnf.add_clause(&matches);\n\n                // if a key is active then we need to select one of the versions\n                for (key, vars) in by_key.iter() {\n                    let mut matches = vars.clone();\n                    matches.push(keys[key].negative());\n                    cnf.add_clause(&matches);\n                }\n\n                version_selected_for\n                    .entry(p.package_id())\n                    .or_default()\n                    .insert(dep.clone(), keys);\n            }\n        }\n\n        let topological_order = graph.sort();\n\n        // we already ensure there is only one version for each `activations_key` so we can think of\n        // `publicly_exports` as being in terms of a set of `activations_key`s\n        let mut publicly_exports: HashMap<_, HashMap<_, varisat::Var>> = HashMap::new();\n\n        for &key in by_activations_keys.keys() {\n            // everything publicly depends on itself\n            let var = publicly_exports\n                .entry(key)\n                .or_default()\n                .entry(key)\n                .or_insert_with(|| cnf.new_var());\n            cnf.add_clause(&[var.positive()]);\n        }\n\n        // if a `dep` is public then `p` `publicly_exports` all the things that the selected version `publicly_exports`\n        for &p in topological_order.iter() {\n            if let Some(deps) = version_selected_for.get(&p) {\n                let mut p_exports = publicly_exports.remove(&p.as_activations_key()).unwrap();\n                for (_, versions) in deps.iter().filter(|(d, _)| d.is_public()) {\n                    for (ver, sel) in versions {\n                        for (&export_pid, &export_var) in publicly_exports[ver].iter() {\n                            let our_var =\n                                p_exports.entry(export_pid).or_insert_with(|| cnf.new_var());\n                            cnf.add_clause(&[\n                                sel.negative(),\n                                export_var.negative(),\n                                our_var.positive(),\n                            ]);\n                        }\n                    }\n                }\n                publicly_exports.insert(p.as_activations_key(), p_exports);\n            }\n        }\n\n        // we already ensure there is only one version for each `activations_key` so we can think of\n        // `can_see` as being in terms of a set of `activations_key`s\n        // and if `p` `publicly_exports` `export` then it `can_see` `export`\n        let mut can_see: HashMap<_, HashMap<_, varisat::Var>> = HashMap::new();\n\n        // if `p` has a `dep` that selected `ver` then it `can_see` all the things that the selected version `publicly_exports`\n        for (&p, deps) in version_selected_for.iter() {\n            let p_can_see = can_see.entry(p).or_default();\n            for (_, versions) in deps.iter() {\n                for (&ver, sel) in versions {\n                    for (&export_pid, &export_var) in publicly_exports[&ver].iter() {\n                        let our_var = p_can_see.entry(export_pid).or_insert_with(|| cnf.new_var());\n                        cnf.add_clause(&[\n                            sel.negative(),\n                            export_var.negative(),\n                            our_var.positive(),\n                        ]);\n                    }\n                }\n            }\n        }\n\n        // a package `can_see` only one version by each name\n        for (_, see) in can_see.iter() {\n            sat_at_most_one_by_key(&mut cnf, see.iter().map(|((name, _, _), &v)| (name, v)));\n        }\n        let mut solver = varisat::Solver::new();\n        solver.add_formula(&cnf);\n\n        // We dont need to `solve` now. We know that \"use nothing\" will satisfy all the clauses so far.\n        // But things run faster if we let it spend some time figuring out how the constraints interact before we add assumptions.\n        solver\n            .solve()\n            .expect(\"docs say it can't error in default config\");\n        SatResolve(Rc::new(RefCell::new(SatResolveInner {\n            solver,\n            var_for_is_packages_used,\n            by_name,\n        })))\n    }\n    pub fn sat_resolve(&self, deps: &[Dependency]) -> bool {\n        let mut s = self.0.borrow_mut();\n        let mut assumption = vec![];\n        let mut this_call = None;\n\n        // the starting `deps` need to be satisfied\n        for dep in deps.iter() {\n            let empty_vec = vec![];\n            let matches: Vec<varisat::Lit> = s\n                .by_name\n                .get(dep.package_name().as_str())\n                .unwrap_or(&empty_vec)\n                .iter()\n                .filter(|&p| dep.matches_id(*p))\n                .map(|p| s.var_for_is_packages_used[p].positive())\n                .collect();\n            if matches.is_empty() {\n                return false;\n            } else if matches.len() == 1 {\n                assumption.extend_from_slice(&matches)\n            } else {\n                if this_call.is_none() {\n                    let new_var = s.solver.new_var();\n                    this_call = Some(new_var);\n                    assumption.push(new_var.positive());\n                }\n                let mut matches = matches;\n                matches.push(this_call.unwrap().negative());\n                s.solver.add_clause(&matches);\n            }\n        }\n\n        s.solver.assume(&assumption);\n\n        s.solver\n            .solve()\n            .expect(\"docs say it can't error in default config\")\n    }\n    pub fn sat_is_valid_solution(&self, pids: &[PackageId]) -> bool {\n        let mut s = self.0.borrow_mut();\n        for p in pids {\n            if p.name().as_str() != \"root\" && !s.var_for_is_packages_used.contains_key(p) {\n                return false;\n            }\n        }\n        let assumption: Vec<_> = s\n            .var_for_is_packages_used\n            .iter()\n            .map(|(p, v)| v.lit(pids.contains(p)))\n            .collect();\n\n        s.solver.assume(&assumption);\n\n        s.solver\n            .solve()\n            .expect(\"docs say it can't error in default config\")\n    }\n    fn use_packages(&self) -> Option<String> {\n        self.0.borrow().solver.model().map(|lits| {\n            let lits: HashSet<_> = lits\n                .iter()\n                .filter(|l| l.is_positive())\n                .map(|l| l.var())\n                .collect();\n            let mut out = String::new();\n            out.push_str(\"used:\\n\");\n            for (p, v) in self.0.borrow().var_for_is_packages_used.iter() {\n                if lits.contains(v) {\n                    writeln!(&mut out, \"    {}\", p).unwrap();\n                }\n            }\n            out\n        })\n    }\n}\n\npub trait ToDep {\n    fn to_dep(self) -> Dependency;\n}\n\nimpl ToDep for &'static str {\n    fn to_dep(self) -> Dependency {\n        Dependency::parse(self, Some(\"1.0.0\"), registry_loc()).unwrap()\n    }\n}\n\nimpl ToDep for Dependency {\n    fn to_dep(self) -> Dependency {\n        self\n    }\n}\n\npub trait ToPkgId {\n    fn to_pkgid(&self) -> PackageId;\n}\n\nimpl ToPkgId for PackageId {\n    fn to_pkgid(&self) -> PackageId {\n        *self\n    }\n}\n\nimpl<'a> ToPkgId for &'a str {\n    fn to_pkgid(&self) -> PackageId {\n        PackageId::new(*self, \"1.0.0\", registry_loc()).unwrap()\n    }\n}\n\nimpl<T: AsRef<str>, U: AsRef<str>> ToPkgId for (T, U) {\n    fn to_pkgid(&self) -> PackageId {\n        let (name, vers) = self;\n        PackageId::new(name.as_ref(), vers.as_ref(), registry_loc()).unwrap()\n    }\n}\n\n#[macro_export]\nmacro_rules! pkg {\n    ($pkgid:expr => [$($deps:expr),+ $(,)* ]) => ({\n        let d: Vec<Dependency> = vec![$($deps.to_dep()),+];\n        $crate::pkg_dep($pkgid, d)\n    });\n\n    ($pkgid:expr) => ({\n        $crate::pkg($pkgid)\n    })\n}\n\nfn registry_loc() -> SourceId {\n    lazy_static::lazy_static! {\n        static ref EXAMPLE_DOT_COM: SourceId =\n            SourceId::for_registry(&\"https://example.com\".into_url().unwrap()).unwrap();\n    }\n    *EXAMPLE_DOT_COM\n}\n\npub fn pkg<T: ToPkgId>(name: T) -> Summary {\n    pkg_dep(name, Vec::new())\n}\n\npub fn pkg_dep<T: ToPkgId>(name: T, dep: Vec<Dependency>) -> Summary {\n    let pkgid = name.to_pkgid();\n    let link = if pkgid.name().ends_with(\"-sys\") {\n        Some(pkgid.name().as_str())\n    } else {\n        None\n    };\n    Summary::new(\n        name.to_pkgid(),\n        dep,\n        &BTreeMap::new(),\n        link,\n        None::<&String>,\n    )\n    .unwrap()\n}\n\npub fn pkg_id(name: &str) -> PackageId {\n    PackageId::new(name, \"1.0.0\", registry_loc()).unwrap()\n}\n\nfn pkg_id_loc(name: &str, loc: &str) -> PackageId {\n    let remote = loc.into_url();\n    let master = GitReference::Branch(\"master\".to_string());\n    let source_id = SourceId::for_git(&remote.unwrap(), master).unwrap();\n\n    PackageId::new(name, \"1.0.0\", source_id).unwrap()\n}\n\npub fn pkg_loc(name: &str, loc: &str) -> Summary {\n    let link = if name.ends_with(\"-sys\") {\n        Some(name)\n    } else {\n        None\n    };\n    Summary::new(\n        pkg_id_loc(name, loc),\n        Vec::new(),\n        &BTreeMap::new(),\n        link,\n        None::<&String>,\n    )\n    .unwrap()\n}\n\npub fn remove_dep(sum: &Summary, ind: usize) -> Summary {\n    let mut deps = sum.dependencies().to_vec();\n    deps.remove(ind);\n    // note: more things will need to be copied over in the future, but it works for now.\n    Summary::new(\n        sum.package_id(),\n        deps,\n        &BTreeMap::new(),\n        sum.links().map(|a| a.as_str()),\n        None::<&String>,\n    )\n    .unwrap()\n}\n\npub fn dep(name: &str) -> Dependency {\n    dep_req(name, \"*\")\n}\npub fn dep_req(name: &str, req: &str) -> Dependency {\n    Dependency::parse(name, Some(req), registry_loc()).unwrap()\n}\npub fn dep_req_kind(name: &str, req: &str, kind: DepKind, public: bool) -> Dependency {\n    let mut dep = dep_req(name, req);\n    dep.set_kind(kind);\n    dep.set_public(public);\n    dep\n}\n\npub fn dep_loc(name: &str, location: &str) -> Dependency {\n    let url = location.into_url().unwrap();\n    let master = GitReference::Branch(\"master\".to_string());\n    let source_id = SourceId::for_git(&url, master).unwrap();\n    Dependency::parse(name, Some(\"1.0.0\"), source_id).unwrap()\n}\npub fn dep_kind(name: &str, kind: DepKind) -> Dependency {\n    dep(name).set_kind(kind).clone()\n}\n\npub fn registry(pkgs: Vec<Summary>) -> Vec<Summary> {\n    pkgs\n}\n\npub fn names<P: ToPkgId>(names: &[P]) -> Vec<PackageId> {\n    names.iter().map(|name| name.to_pkgid()).collect()\n}\n\npub fn loc_names(names: &[(&'static str, &'static str)]) -> Vec<PackageId> {\n    names\n        .iter()\n        .map(|&(name, loc)| pkg_id_loc(name, loc))\n        .collect()\n}\n\n/// By default `Summary` and `Dependency` have a very verbose `Debug` representation.\n/// This replaces with a representation that uses constructors from this file.\n///\n/// If `registry_strategy` is improved to modify more fields\n/// then this needs to update to display the corresponding constructor.\npub struct PrettyPrintRegistry(pub Vec<Summary>);\n\nimpl fmt::Debug for PrettyPrintRegistry {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"vec![\")?;\n        for s in &self.0 {\n            if s.dependencies().is_empty() {\n                write!(f, \"pkg!((\\\"{}\\\", \\\"{}\\\")),\", s.name(), s.version())?;\n            } else {\n                write!(f, \"pkg!((\\\"{}\\\", \\\"{}\\\") => [\", s.name(), s.version())?;\n                for d in s.dependencies() {\n                    if d.kind() == DepKind::Normal\n                        && &d.version_req().to_string() == \"*\"\n                        && !d.is_public()\n                    {\n                        write!(f, \"dep(\\\"{}\\\"),\", d.name_in_toml())?;\n                    } else if d.kind() == DepKind::Normal && !d.is_public() {\n                        write!(\n                            f,\n                            \"dep_req(\\\"{}\\\", \\\"{}\\\"),\",\n                            d.name_in_toml(),\n                            d.version_req()\n                        )?;\n                    } else {\n                        write!(\n                            f,\n                            \"dep_req_kind(\\\"{}\\\", \\\"{}\\\", {}, {}),\",\n                            d.name_in_toml(),\n                            d.version_req(),\n                            match d.kind() {\n                                DepKind::Development => \"DepKind::Development\",\n                                DepKind::Build => \"DepKind::Build\",\n                                DepKind::Normal => \"DepKind::Normal\",\n                            },\n                            d.is_public()\n                        )?;\n                    }\n                }\n                write!(f, \"]),\")?;\n            }\n        }\n        write!(f, \"]\")\n    }\n}\n\n#[test]\nfn meta_test_deep_pretty_print_registry() {\n    assert_eq!(\n        &format!(\n            \"{:?}\",\n            PrettyPrintRegistry(vec![\n                pkg!((\"foo\", \"1.0.1\") => [dep_req(\"bar\", \"1\")]),\n                pkg!((\"foo\", \"1.0.0\") => [dep_req(\"bar\", \"2\")]),\n                pkg!((\"foo\", \"2.0.0\") => [dep_req(\"bar\", \"*\")]),\n                pkg!((\"bar\", \"1.0.0\") => [dep_req(\"baz\", \"=1.0.2\"),\n                                  dep_req(\"other\", \"1\")]),\n                pkg!((\"bar\", \"2.0.0\") => [dep_req(\"baz\", \"=1.0.1\")]),\n                pkg!((\"baz\", \"1.0.2\") => [dep_req(\"other\", \"2\")]),\n                pkg!((\"baz\", \"1.0.1\")),\n                pkg!((\"cat\", \"1.0.2\") => [dep_req_kind(\"other\", \"2\", DepKind::Build, false)]),\n                pkg!((\"cat\", \"1.0.3\") => [dep_req_kind(\"other\", \"2\", DepKind::Development, false)]),\n                pkg!((\"dep_req\", \"1.0.0\")),\n                pkg!((\"dep_req\", \"2.0.0\")),\n            ])\n        ),\n        \"vec![pkg!((\\\"foo\\\", \\\"1.0.1\\\") => [dep_req(\\\"bar\\\", \\\"^1\\\"),]),\\\n         pkg!((\\\"foo\\\", \\\"1.0.0\\\") => [dep_req(\\\"bar\\\", \\\"^2\\\"),]),\\\n         pkg!((\\\"foo\\\", \\\"2.0.0\\\") => [dep(\\\"bar\\\"),]),\\\n         pkg!((\\\"bar\\\", \\\"1.0.0\\\") => [dep_req(\\\"baz\\\", \\\"=1.0.2\\\"),dep_req(\\\"other\\\", \\\"^1\\\"),]),\\\n         pkg!((\\\"bar\\\", \\\"2.0.0\\\") => [dep_req(\\\"baz\\\", \\\"=1.0.1\\\"),]),\\\n         pkg!((\\\"baz\\\", \\\"1.0.2\\\") => [dep_req(\\\"other\\\", \\\"^2\\\"),]),\\\n         pkg!((\\\"baz\\\", \\\"1.0.1\\\")),\\\n         pkg!((\\\"cat\\\", \\\"1.0.2\\\") => [dep_req_kind(\\\"other\\\", \\\"^2\\\", DepKind::Build, false),]),\\\n         pkg!((\\\"cat\\\", \\\"1.0.3\\\") => [dep_req_kind(\\\"other\\\", \\\"^2\\\", DepKind::Development, false),]),\\\n         pkg!((\\\"dep_req\\\", \\\"1.0.0\\\")),\\\n         pkg!((\\\"dep_req\\\", \\\"2.0.0\\\")),]\"\n    )\n}\n\n/// This generates a random registry index.\n/// Unlike vec((Name, Ver, vec((Name, VerRq), ..), ..)\n/// This strategy has a high probability of having valid dependencies\npub fn registry_strategy(\n    max_crates: usize,\n    max_versions: usize,\n    shrinkage: usize,\n) -> impl Strategy<Value = PrettyPrintRegistry> {\n    let name = string_regex(\"[A-Za-z][A-Za-z0-9_-]*(-sys)?\").unwrap();\n\n    let raw_version = ..max_versions.pow(3);\n    let version_from_raw = move |r: usize| {\n        let major = ((r / max_versions) / max_versions) % max_versions;\n        let minor = (r / max_versions) % max_versions;\n        let patch = r % max_versions;\n        format!(\"{}.{}.{}\", major, minor, patch)\n    };\n\n    // If this is false then the crate will depend on the nonexistent \"bad\"\n    // instead of the complex set we generated for it.\n    let allow_deps = prop::bool::weighted(0.99);\n\n    let list_of_versions =\n        btree_map(raw_version, allow_deps, 1..=max_versions).prop_map(move |ver| {\n            ver.into_iter()\n                .map(|a| (version_from_raw(a.0), a.1))\n                .collect::<Vec<_>>()\n        });\n\n    let list_of_crates_with_versions =\n        btree_map(name, list_of_versions, 1..=max_crates).prop_map(|mut vers| {\n            // root is the name of the thing being compiled\n            // so it would be confusing to have it in the index\n            vers.remove(\"root\");\n            // bad is a name reserved for a dep that won't work\n            vers.remove(\"bad\");\n            vers\n        });\n\n    // each version of each crate can depend on each crate smaller then it.\n    // In theory shrinkage should be 2, but in practice we get better trees with a larger value.\n    let max_deps = max_versions * (max_crates * (max_crates - 1)) / shrinkage;\n\n    let raw_version_range = (any::<Index>(), any::<Index>());\n    let raw_dependency = (\n        any::<Index>(),\n        any::<Index>(),\n        raw_version_range,\n        0..=1,\n        Just(false),\n        // TODO: ^ this needs to be set back to `any::<bool>()` and work before public & private dependencies can stabilize\n    );\n\n    fn order_index(a: Index, b: Index, size: usize) -> (usize, usize) {\n        let (a, b) = (a.index(size), b.index(size));\n        (min(a, b), max(a, b))\n    }\n\n    let list_of_raw_dependency = vec(raw_dependency, ..=max_deps);\n\n    // By default a package depends only on other packages that have a smaller name,\n    // this helps make sure that all things in the resulting index are DAGs.\n    // If this is true then the DAG is maintained with grater instead.\n    let reverse_alphabetical = any::<bool>().no_shrink();\n\n    (\n        list_of_crates_with_versions,\n        list_of_raw_dependency,\n        reverse_alphabetical,\n    )\n        .prop_map(\n            |(crate_vers_by_name, raw_dependencies, reverse_alphabetical)| {\n                let list_of_pkgid: Vec<_> = crate_vers_by_name\n                    .iter()\n                    .flat_map(|(name, vers)| vers.iter().map(move |x| ((name.as_str(), &x.0), x.1)))\n                    .collect();\n                let len_all_pkgid = list_of_pkgid.len();\n                let mut dependency_by_pkgid = vec![vec![]; len_all_pkgid];\n                for (a, b, (c, d), k, p) in raw_dependencies {\n                    let (a, b) = order_index(a, b, len_all_pkgid);\n                    let (a, b) = if reverse_alphabetical { (b, a) } else { (a, b) };\n                    let ((dep_name, _), _) = list_of_pkgid[a];\n                    if (list_of_pkgid[b].0).0 == dep_name {\n                        continue;\n                    }\n                    let s = &crate_vers_by_name[dep_name];\n                    let s_last_index = s.len() - 1;\n                    let (c, d) = order_index(c, d, s.len());\n\n                    dependency_by_pkgid[b].push(dep_req_kind(\n                        dep_name,\n                        &if c == 0 && d == s_last_index {\n                            \"*\".to_string()\n                        } else if c == 0 {\n                            format!(\"<={}\", s[d].0)\n                        } else if d == s_last_index {\n                            format!(\">={}\", s[c].0)\n                        } else if c == d {\n                            format!(\"={}\", s[c].0)\n                        } else {\n                            format!(\">={}, <={}\", s[c].0, s[d].0)\n                        },\n                        match k {\n                            0 => DepKind::Normal,\n                            1 => DepKind::Build,\n                            // => DepKind::Development, // Development has no impact so don't gen\n                            _ => panic!(\"bad index for DepKind\"),\n                        },\n                        p && k == 0,\n                    ))\n                }\n\n                let mut out: Vec<Summary> = list_of_pkgid\n                    .into_iter()\n                    .zip(dependency_by_pkgid.into_iter())\n                    .map(|(((name, ver), allow_deps), deps)| {\n                        pkg_dep(\n                            (name, ver).to_pkgid(),\n                            if !allow_deps {\n                                vec![dep_req(\"bad\", \"*\")]\n                            } else {\n                                let mut deps = deps;\n                                deps.sort_by_key(|d| d.name_in_toml());\n                                deps.dedup_by_key(|d| d.name_in_toml());\n                                deps\n                            },\n                        )\n                    })\n                    .collect();\n\n                if reverse_alphabetical {\n                    // make sure the complicated cases are at the end\n                    out.reverse();\n                }\n\n                PrettyPrintRegistry(out)\n            },\n        )\n}\n\n/// This test is to test the generator to ensure\n/// that it makes registries with large dependency trees\n#[test]\nfn meta_test_deep_trees_from_strategy() {\n    use proptest::strategy::ValueTree;\n    use proptest::test_runner::TestRunner;\n\n    let mut dis = [0; 21];\n\n    let strategy = registry_strategy(50, 20, 60);\n    let mut test_runner = TestRunner::deterministic();\n    for _ in 0..128 {\n        let PrettyPrintRegistry(input) = strategy\n            .new_tree(&mut TestRunner::new_with_rng(\n                Default::default(),\n                test_runner.new_rng(),\n            ))\n            .unwrap()\n            .current();\n        let reg = registry(input.clone());\n        for this in input.iter().rev().take(10) {\n            let res = resolve(\n                vec![dep_req(&this.name(), &format!(\"={}\", this.version()))],\n                &reg,\n            );\n            dis[res\n                .as_ref()\n                .map(|x| min(x.len(), dis.len()) - 1)\n                .unwrap_or(0)] += 1;\n            if dis.iter().all(|&x| x > 0) {\n                return;\n            }\n        }\n    }\n\n    panic!(\n        \"In 1280 tries we did not see a wide enough distribution of dependency trees! dis: {:?}\",\n        dis\n    );\n}\n\n/// This test is to test the generator to ensure\n/// that it makes registries that include multiple versions of the same library\n#[test]\nfn meta_test_multiple_versions_strategy() {\n    use proptest::strategy::ValueTree;\n    use proptest::test_runner::TestRunner;\n\n    let mut dis = [0; 10];\n\n    let strategy = registry_strategy(50, 20, 60);\n    let mut test_runner = TestRunner::deterministic();\n    for _ in 0..128 {\n        let PrettyPrintRegistry(input) = strategy\n            .new_tree(&mut TestRunner::new_with_rng(\n                Default::default(),\n                test_runner.new_rng(),\n            ))\n            .unwrap()\n            .current();\n        let reg = registry(input.clone());\n        for this in input.iter().rev().take(10) {\n            let res = resolve(\n                vec![dep_req(&this.name(), &format!(\"={}\", this.version()))],\n                &reg,\n            );\n            if let Ok(mut res) = res {\n                let res_len = res.len();\n                res.sort_by_key(|s| s.name());\n                res.dedup_by_key(|s| s.name());\n                dis[min(res_len - res.len(), dis.len() - 1)] += 1;\n            }\n            if dis.iter().all(|&x| x > 0) {\n                return;\n            }\n        }\n    }\n    panic!(\n        \"In 1280 tries we did not see a wide enough distribution of multiple versions of the same library! dis: {:?}\",\n        dis\n    );\n}\n\n/// Assert `xs` contains `elems`\n#[track_caller]\npub fn assert_contains<A: PartialEq>(xs: &[A], elems: &[A]) {\n    for elem in elems {\n        assert!(xs.contains(elem));\n    }\n}\n\n#[track_caller]\npub fn assert_same<A: PartialEq>(a: &[A], b: &[A]) {\n    assert_eq!(a.len(), b.len());\n    assert_contains(b, a);\n}\n", "//! This module implements support for preferring some versions of a package\n//! over other versions.\n\nuse std::cmp::Ordering;\nuse std::collections::{HashMap, HashSet};\n\nuse crate::core::{Dependency, PackageId, Summary};\nuse crate::util::interning::InternedString;\n\n/// A collection of preferences for particular package versions.\n///\n/// This is built up with [`Self::prefer_package_id`] and [`Self::prefer_dependency`], then used to sort the set of\n/// summaries for a package during resolution via [`Self::sort_summaries`].\n///\n/// As written, a version is either \"preferred\" or \"not preferred\".  Later extensions may\n/// introduce more granular preferences.\n#[derive(Default)]\npub struct VersionPreferences {\n    try_to_use: HashSet<PackageId>,\n    prefer_patch_deps: HashMap<InternedString, HashSet<Dependency>>,\n}\n\npub enum VersionOrdering {\n    MaximumVersionsFirst,\n    MinimumVersionsFirst,\n}\n\nimpl VersionPreferences {\n    /// Indicate that the given package (specified as a [`PackageId`]) should be preferred.\n    pub fn prefer_package_id(&mut self, pkg_id: PackageId) {\n        self.try_to_use.insert(pkg_id);\n    }\n\n    /// Indicate that the given package (specified as a [`Dependency`])  should be preferred.\n    pub fn prefer_dependency(&mut self, dep: Dependency) {\n        self.prefer_patch_deps\n            .entry(dep.package_name())\n            .or_insert_with(HashSet::new)\n            .insert(dep);\n    }\n\n    /// Sort the given vector of summaries in-place, with all summaries presumed to be for\n    /// the same package.  Preferred versions appear first in the result, sorted by\n    /// `version_ordering`, followed by non-preferred versions sorted the same way.\n    pub fn sort_summaries(\n        &self,\n        summaries: &mut Vec<Summary>,\n        version_ordering: VersionOrdering,\n        first_version: bool,\n    ) {\n        let should_prefer = |pkg_id: &PackageId| {\n            self.try_to_use.contains(pkg_id)\n                || self\n                    .prefer_patch_deps\n                    .get(&pkg_id.name())\n                    .map(|deps| deps.iter().any(|d| d.matches_id(*pkg_id)))\n                    .unwrap_or(false)\n        };\n        summaries.sort_unstable_by(|a, b| {\n            let prefer_a = should_prefer(&a.package_id());\n            let prefer_b = should_prefer(&b.package_id());\n            let previous_cmp = prefer_a.cmp(&prefer_b).reverse();\n            match previous_cmp {\n                Ordering::Equal => {\n                    let cmp = a.version().cmp(b.version());\n                    match version_ordering {\n                        VersionOrdering::MaximumVersionsFirst => cmp.reverse(),\n                        VersionOrdering::MinimumVersionsFirst => cmp,\n                    }\n                }\n                _ => previous_cmp,\n            }\n        });\n        if first_version {\n            let _ = summaries.split_off(1);\n        }\n    }\n}\n\n#[cfg(test)]\nmod test {\n    use super::*;\n    use crate::core::SourceId;\n    use std::collections::BTreeMap;\n\n    fn pkgid(name: &str, version: &str) -> PackageId {\n        let src_id =\n            SourceId::from_url(\"registry+https://github.com/rust-lang/crates.io-index\").unwrap();\n        PackageId::new(name, version, src_id).unwrap()\n    }\n\n    fn dep(name: &str, version: &str) -> Dependency {\n        let src_id =\n            SourceId::from_url(\"registry+https://github.com/rust-lang/crates.io-index\").unwrap();\n        Dependency::parse(name, Some(version), src_id).unwrap()\n    }\n\n    fn summ(name: &str, version: &str) -> Summary {\n        let pkg_id = pkgid(name, version);\n        let features = BTreeMap::new();\n        Summary::new(\n            pkg_id,\n            Vec::new(),\n            &features,\n            None::<&String>,\n            None::<&String>,\n        )\n        .unwrap()\n    }\n\n    fn describe(summaries: &Vec<Summary>) -> String {\n        let strs: Vec<String> = summaries\n            .iter()\n            .map(|summary| format!(\"{}/{}\", summary.name(), summary.version()))\n            .collect();\n        strs.join(\", \")\n    }\n\n    #[test]\n    fn test_prefer_package_id() {\n        let mut vp = VersionPreferences::default();\n        vp.prefer_package_id(pkgid(\"foo\", \"1.2.3\"));\n\n        let mut summaries = vec![\n            summ(\"foo\", \"1.2.4\"),\n            summ(\"foo\", \"1.2.3\"),\n            summ(\"foo\", \"1.1.0\"),\n            summ(\"foo\", \"1.0.9\"),\n        ];\n\n        vp.sort_summaries(&mut summaries, VersionOrdering::MaximumVersionsFirst, false);\n        assert_eq!(\n            describe(&summaries),\n            \"foo/1.2.3, foo/1.2.4, foo/1.1.0, foo/1.0.9\".to_string()\n        );\n\n        vp.sort_summaries(&mut summaries, VersionOrdering::MinimumVersionsFirst, false);\n        assert_eq!(\n            describe(&summaries),\n            \"foo/1.2.3, foo/1.0.9, foo/1.1.0, foo/1.2.4\".to_string()\n        );\n    }\n\n    #[test]\n    fn test_prefer_dependency() {\n        let mut vp = VersionPreferences::default();\n        vp.prefer_dependency(dep(\"foo\", \"=1.2.3\"));\n\n        let mut summaries = vec![\n            summ(\"foo\", \"1.2.4\"),\n            summ(\"foo\", \"1.2.3\"),\n            summ(\"foo\", \"1.1.0\"),\n            summ(\"foo\", \"1.0.9\"),\n        ];\n\n        vp.sort_summaries(&mut summaries, VersionOrdering::MaximumVersionsFirst, false);\n        assert_eq!(\n            describe(&summaries),\n            \"foo/1.2.3, foo/1.2.4, foo/1.1.0, foo/1.0.9\".to_string()\n        );\n\n        vp.sort_summaries(&mut summaries, VersionOrdering::MinimumVersionsFirst, false);\n        assert_eq!(\n            describe(&summaries),\n            \"foo/1.2.3, foo/1.0.9, foo/1.1.0, foo/1.2.4\".to_string()\n        );\n    }\n\n    #[test]\n    fn test_prefer_both() {\n        let mut vp = VersionPreferences::default();\n        vp.prefer_package_id(pkgid(\"foo\", \"1.2.3\"));\n        vp.prefer_dependency(dep(\"foo\", \"=1.1.0\"));\n\n        let mut summaries = vec![\n            summ(\"foo\", \"1.2.4\"),\n            summ(\"foo\", \"1.2.3\"),\n            summ(\"foo\", \"1.1.0\"),\n            summ(\"foo\", \"1.0.9\"),\n        ];\n\n        vp.sort_summaries(&mut summaries, VersionOrdering::MaximumVersionsFirst, false);\n        assert_eq!(\n            describe(&summaries),\n            \"foo/1.2.3, foo/1.1.0, foo/1.2.4, foo/1.0.9\".to_string()\n        );\n\n        vp.sort_summaries(&mut summaries, VersionOrdering::MinimumVersionsFirst, false);\n        assert_eq!(\n            describe(&summaries),\n            \"foo/1.1.0, foo/1.2.3, foo/1.0.9, foo/1.2.4\".to_string()\n        );\n    }\n}\n", "use crate::core::{Dependency, PackageId, SourceId};\nuse crate::util::interning::InternedString;\nuse crate::util::CargoResult;\nuse anyhow::bail;\nuse semver::Version;\nuse std::collections::{BTreeMap, HashMap, HashSet};\nuse std::fmt;\nuse std::hash::{Hash, Hasher};\nuse std::mem;\nuse std::rc::Rc;\n\n/// Subset of a `Manifest`. Contains only the most important information about\n/// a package.\n///\n/// Summaries are cloned, and should not be mutated after creation\n#[derive(Debug, Clone)]\npub struct Summary {\n    inner: Rc<Inner>,\n}\n\n#[derive(Debug, Clone)]\nstruct Inner {\n    package_id: PackageId,\n    dependencies: Vec<Dependency>,\n    features: Rc<FeatureMap>,\n    checksum: Option<String>,\n    links: Option<InternedString>,\n    rust_version: Option<InternedString>,\n}\n\nimpl Summary {\n    pub fn new(\n        pkg_id: PackageId,\n        dependencies: Vec<Dependency>,\n        features: &BTreeMap<InternedString, Vec<InternedString>>,\n        links: Option<impl Into<InternedString>>,\n        rust_version: Option<impl Into<InternedString>>,\n    ) -> CargoResult<Summary> {\n        // ****CAUTION**** If you change anything here that may raise a new\n        // error, be sure to coordinate that change with either the index\n        // schema field or the SummariesCache version.\n        for dep in dependencies.iter() {\n            let dep_name = dep.name_in_toml();\n            if dep.is_optional() && !dep.is_transitive() {\n                bail!(\n                    \"dev-dependencies are not allowed to be optional: `{}`\",\n                    dep_name\n                )\n            }\n        }\n        let feature_map = build_feature_map(pkg_id, features, &dependencies)?;\n        Ok(Summary {\n            inner: Rc::new(Inner {\n                package_id: pkg_id,\n                dependencies,\n                features: Rc::new(feature_map),\n                checksum: None,\n                links: links.map(|l| l.into()),\n                rust_version: rust_version.map(|l| l.into()),\n            }),\n        })\n    }\n\n    pub fn package_id(&self) -> PackageId {\n        self.inner.package_id\n    }\n    pub fn name(&self) -> InternedString {\n        self.package_id().name()\n    }\n    pub fn version(&self) -> &Version {\n        self.package_id().version()\n    }\n    pub fn source_id(&self) -> SourceId {\n        self.package_id().source_id()\n    }\n    pub fn dependencies(&self) -> &[Dependency] {\n        &self.inner.dependencies\n    }\n    pub fn features(&self) -> &FeatureMap {\n        &self.inner.features\n    }\n\n    pub fn checksum(&self) -> Option<&str> {\n        self.inner.checksum.as_deref()\n    }\n    pub fn links(&self) -> Option<InternedString> {\n        self.inner.links\n    }\n\n    pub fn rust_version(&self) -> Option<InternedString> {\n        self.inner.rust_version\n    }\n\n    pub fn override_id(mut self, id: PackageId) -> Summary {\n        Rc::make_mut(&mut self.inner).package_id = id;\n        self\n    }\n\n    pub fn set_checksum(&mut self, cksum: String) {\n        Rc::make_mut(&mut self.inner).checksum = Some(cksum);\n    }\n\n    pub fn map_dependencies<F>(mut self, f: F) -> Summary\n    where\n        F: FnMut(Dependency) -> Dependency,\n    {\n        {\n            let slot = &mut Rc::make_mut(&mut self.inner).dependencies;\n            *slot = mem::take(slot).into_iter().map(f).collect();\n        }\n        self\n    }\n\n    pub fn map_source(self, to_replace: SourceId, replace_with: SourceId) -> Summary {\n        let me = if self.package_id().source_id() == to_replace {\n            let new_id = self.package_id().with_source_id(replace_with);\n            self.override_id(new_id)\n        } else {\n            self\n        };\n        me.map_dependencies(|dep| dep.map_source(to_replace, replace_with))\n    }\n}\n\nimpl PartialEq for Summary {\n    fn eq(&self, other: &Summary) -> bool {\n        self.inner.package_id == other.inner.package_id\n    }\n}\n\nimpl Eq for Summary {}\n\nimpl Hash for Summary {\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        self.inner.package_id.hash(state);\n    }\n}\n\n/// Checks features for errors, bailing out a CargoResult:Err if invalid,\n/// and creates FeatureValues for each feature.\nfn build_feature_map(\n    pkg_id: PackageId,\n    features: &BTreeMap<InternedString, Vec<InternedString>>,\n    dependencies: &[Dependency],\n) -> CargoResult<FeatureMap> {\n    use self::FeatureValue::*;\n    let mut dep_map = HashMap::new();\n    for dep in dependencies.iter() {\n        dep_map\n            .entry(dep.name_in_toml())\n            .or_insert_with(Vec::new)\n            .push(dep);\n    }\n\n    let mut map: FeatureMap = features\n        .iter()\n        .map(|(feature, list)| {\n            let fvs: Vec<_> = list\n                .iter()\n                .map(|feat_value| FeatureValue::new(*feat_value))\n                .collect();\n            (*feature, fvs)\n        })\n        .collect();\n\n    // Add implicit features for optional dependencies if they weren't\n    // explicitly listed anywhere.\n    let explicitly_listed: HashSet<_> = map\n        .values()\n        .flatten()\n        .filter_map(|fv| match fv {\n            Dep { dep_name } => Some(*dep_name),\n            _ => None,\n        })\n        .collect();\n    for dep in dependencies {\n        if !dep.is_optional() {\n            continue;\n        }\n        let dep_name_in_toml = dep.name_in_toml();\n        if features.contains_key(&dep_name_in_toml) || explicitly_listed.contains(&dep_name_in_toml)\n        {\n            continue;\n        }\n        let fv = Dep {\n            dep_name: dep_name_in_toml,\n        };\n        map.insert(dep_name_in_toml, vec![fv]);\n    }\n\n    // Validate features are listed properly.\n    for (feature, fvs) in &map {\n        if feature.starts_with(\"dep:\") {\n            bail!(\n                \"feature named `{}` is not allowed to start with `dep:`\",\n                feature\n            );\n        }\n        if feature.contains('/') {\n            bail!(\n                \"feature named `{}` is not allowed to contain slashes\",\n                feature\n            );\n        }\n        validate_feature_name(pkg_id, feature)?;\n        for fv in fvs {\n            // Find data for the referenced dependency...\n            let dep_data = {\n                match fv {\n                    Feature(dep_name) | Dep { dep_name, .. } | DepFeature { dep_name, .. } => {\n                        dep_map.get(dep_name)\n                    }\n                }\n            };\n            let is_optional_dep = dep_data\n                .iter()\n                .flat_map(|d| d.iter())\n                .any(|d| d.is_optional());\n            let is_any_dep = dep_data.is_some();\n            match fv {\n                Feature(f) => {\n                    if !features.contains_key(f) {\n                        if !is_any_dep {\n                            bail!(\n                                \"feature `{}` includes `{}` which is neither a dependency \\\n                                 nor another feature\",\n                                feature,\n                                fv\n                            );\n                        }\n                        if is_optional_dep {\n                            if !map.contains_key(f) {\n                                bail!(\n                                    \"feature `{}` includes `{}`, but `{}` is an \\\n                                     optional dependency without an implicit feature\\n\\\n                                     Use `dep:{}` to enable the dependency.\",\n                                    feature,\n                                    fv,\n                                    f,\n                                    f\n                                );\n                            }\n                        } else {\n                            bail!(\"feature `{}` includes `{}`, but `{}` is not an optional dependency\\n\\\n                                A non-optional dependency of the same name is defined; \\\n                                consider adding `optional = true` to its definition.\",\n                                feature, fv, f);\n                        }\n                    }\n                }\n                Dep { dep_name } => {\n                    if !is_any_dep {\n                        bail!(\n                            \"feature `{}` includes `{}`, but `{}` is not listed as a dependency\",\n                            feature,\n                            fv,\n                            dep_name\n                        );\n                    }\n                    if !is_optional_dep {\n                        bail!(\n                            \"feature `{}` includes `{}`, but `{}` is not an optional dependency\\n\\\n                             A non-optional dependency of the same name is defined; \\\n                             consider adding `optional = true` to its definition.\",\n                            feature,\n                            fv,\n                            dep_name\n                        );\n                    }\n                }\n                DepFeature {\n                    dep_name,\n                    dep_feature,\n                    weak,\n                    ..\n                } => {\n                    // Early check for some unlikely syntax.\n                    if dep_feature.contains('/') {\n                        bail!(\n                            \"multiple slashes in feature `{}` (included by feature `{}`) are not allowed\",\n                            fv,\n                            feature\n                        );\n                    }\n\n                    // dep: cannot be combined with /\n                    if let Some(stripped_dep) = dep_name.strip_prefix(\"dep:\") {\n                        let has_other_dep = explicitly_listed.contains(stripped_dep);\n                        let is_optional = dep_map\n                            .get(stripped_dep)\n                            .iter()\n                            .flat_map(|d| d.iter())\n                            .any(|d| d.is_optional());\n                        let extra_help = if *weak || has_other_dep || !is_optional {\n                            // In this case, the user should just remove dep:.\n                            // Note that \"hiding\" an optional dependency\n                            // wouldn't work with just a single `dep:foo?/bar`\n                            // because there would not be any way to enable\n                            // `foo`.\n                            String::new()\n                        } else {\n                            format!(\n                                \"\\nIf the intent is to avoid creating an implicit feature \\\n                                 `{stripped_dep}` for an optional dependency, \\\n                                 then consider replacing this with two values:\\n    \\\n                                 \\\"dep:{stripped_dep}\\\", \\\"{stripped_dep}/{dep_feature}\\\"\"\n                            )\n                        };\n                        bail!(\n                            \"feature `{feature}` includes `{fv}` with both `dep:` and `/`\\n\\\n                            To fix this, remove the `dep:` prefix.{extra_help}\"\n                        )\n                    }\n\n                    // Validation of the feature name will be performed in the resolver.\n                    if !is_any_dep {\n                        bail!(\n                            \"feature `{}` includes `{}`, but `{}` is not a dependency\",\n                            feature,\n                            fv,\n                            dep_name\n                        );\n                    }\n                    if *weak && !is_optional_dep {\n                        bail!(\"feature `{}` includes `{}` with a `?`, but `{}` is not an optional dependency\\n\\\n                            A non-optional dependency of the same name is defined; \\\n                            consider removing the `?` or changing the dependency to be optional\",\n                            feature, fv, dep_name);\n                    }\n                }\n            }\n        }\n    }\n\n    // Make sure every optional dep is mentioned at least once.\n    let used: HashSet<_> = map\n        .values()\n        .flatten()\n        .filter_map(|fv| match fv {\n            Dep { dep_name } | DepFeature { dep_name, .. } => Some(dep_name),\n            _ => None,\n        })\n        .collect();\n    if let Some(dep) = dependencies\n        .iter()\n        .find(|dep| dep.is_optional() && !used.contains(&dep.name_in_toml()))\n    {\n        bail!(\n            \"optional dependency `{}` is not included in any feature\\n\\\n            Make sure that `dep:{}` is included in one of features in the [features] table.\",\n            dep.name_in_toml(),\n            dep.name_in_toml(),\n        );\n    }\n\n    Ok(map)\n}\n\n/// FeatureValue represents the types of dependencies a feature can have.\n#[derive(Clone, Debug, Ord, PartialOrd, Eq, PartialEq, Hash)]\npub enum FeatureValue {\n    /// A feature enabling another feature.\n    Feature(InternedString),\n    /// A feature enabling a dependency with `dep:dep_name` syntax.\n    Dep { dep_name: InternedString },\n    /// A feature enabling a feature on a dependency with `crate_name/feat_name` syntax.\n    DepFeature {\n        dep_name: InternedString,\n        dep_feature: InternedString,\n        /// If `true`, indicates the `?` syntax is used, which means this will\n        /// not automatically enable the dependency unless the dependency is\n        /// activated through some other means.\n        weak: bool,\n    },\n}\n\nimpl FeatureValue {\n    pub fn new(feature: InternedString) -> FeatureValue {\n        match feature.find('/') {\n            Some(pos) => {\n                let (dep, dep_feat) = feature.split_at(pos);\n                let dep_feat = &dep_feat[1..];\n                let (dep, weak) = if let Some(dep) = dep.strip_suffix('?') {\n                    (dep, true)\n                } else {\n                    (dep, false)\n                };\n                FeatureValue::DepFeature {\n                    dep_name: InternedString::new(dep),\n                    dep_feature: InternedString::new(dep_feat),\n                    weak,\n                }\n            }\n            None => {\n                if let Some(dep_name) = feature.strip_prefix(\"dep:\") {\n                    FeatureValue::Dep {\n                        dep_name: InternedString::new(dep_name),\n                    }\n                } else {\n                    FeatureValue::Feature(feature)\n                }\n            }\n        }\n    }\n\n    /// Returns `true` if this feature explicitly used `dep:` syntax.\n    pub fn has_dep_prefix(&self) -> bool {\n        matches!(self, FeatureValue::Dep { .. })\n    }\n}\n\nimpl fmt::Display for FeatureValue {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        use self::FeatureValue::*;\n        match self {\n            Feature(feat) => write!(f, \"{}\", feat),\n            Dep { dep_name } => write!(f, \"dep:{}\", dep_name),\n            DepFeature {\n                dep_name,\n                dep_feature,\n                weak,\n            } => {\n                let weak = if *weak { \"?\" } else { \"\" };\n                write!(f, \"{}{}/{}\", dep_name, weak, dep_feature)\n            }\n        }\n    }\n}\n\npub type FeatureMap = BTreeMap<InternedString, Vec<FeatureValue>>;\n\nfn validate_feature_name(pkg_id: PackageId, name: &str) -> CargoResult<()> {\n    let mut chars = name.chars();\n    if let Some(ch) = chars.next() {\n        if !(unicode_xid::UnicodeXID::is_xid_start(ch) || ch == '_' || ch.is_digit(10)) {\n            bail!(\n                \"invalid character `{}` in feature `{}` in package {}, \\\n                the first character must be a Unicode XID start character or digit \\\n                (most letters or `_` or `0` to `9`)\",\n                ch,\n                name,\n                pkg_id\n            );\n        }\n    }\n    for ch in chars {\n        if !(unicode_xid::UnicodeXID::is_xid_continue(ch) || ch == '-' || ch == '+' || ch == '.') {\n            bail!(\n                \"invalid character `{}` in feature `{}` in package {}, \\\n                characters must be Unicode XID characters, `+`, or `.` \\\n                (numbers, `+`, `-`, `_`, `.`, or most letters)\",\n                ch,\n                name,\n                pkg_id\n            );\n        }\n    }\n    Ok(())\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::sources::CRATES_IO_INDEX;\n    use crate::util::into_url::IntoUrl;\n\n    use crate::core::SourceId;\n\n    #[test]\n    fn valid_feature_names() {\n        let loc = CRATES_IO_INDEX.into_url().unwrap();\n        let source_id = SourceId::for_registry(&loc).unwrap();\n        let pkg_id = PackageId::new(\"foo\", \"1.0.0\", source_id).unwrap();\n\n        assert!(validate_feature_name(pkg_id, \"c++17\").is_ok());\n        assert!(validate_feature_name(pkg_id, \"128bit\").is_ok());\n        assert!(validate_feature_name(pkg_id, \"_foo\").is_ok());\n        assert!(validate_feature_name(pkg_id, \"feat-name\").is_ok());\n        assert!(validate_feature_name(pkg_id, \"feat_name\").is_ok());\n        assert!(validate_feature_name(pkg_id, \"foo.bar\").is_ok());\n\n        assert!(validate_feature_name(pkg_id, \"+foo\").is_err());\n        assert!(validate_feature_name(pkg_id, \"-foo\").is_err());\n        assert!(validate_feature_name(pkg_id, \".foo\").is_err());\n        assert!(validate_feature_name(pkg_id, \"foo:bar\").is_err());\n        assert!(validate_feature_name(pkg_id, \"foo?\").is_err());\n        assert!(validate_feature_name(pkg_id, \"?foo\").is_err());\n        assert!(validate_feature_name(pkg_id, \"\u24b6\u24b7\u24b8\").is_err());\n        assert!(validate_feature_name(pkg_id, \"a\u00bc\").is_err());\n    }\n}\n", "//! Management of the index of a registry source.\n//!\n//! This module contains management of the index and various operations, such as\n//! actually parsing the index, looking for crates, etc. This is intended to be\n//! abstract over remote indices (downloaded via Git or HTTP) and local registry\n//! indices (which are all just present on the filesystem).\n//!\n//! ## How the index works\n//!\n//! Here is a simple flow when loading a [`Summary`] (metadata) from the index:\n//!\n//! 1. A query is fired via [`RegistryIndex::query_inner`].\n//! 2. Tries loading all summaries via [`RegistryIndex::load_summaries`], and\n//!    under the hood calling [`Summaries::parse`] to parse an index file.\n//!     1. If an on-disk index cache is present, loads it via\n//!        [`Summaries::parse_cache`].\n//!     2. Otherwise goes to the slower path [`RegistryData::load`] to get the\n//!        specific index file.\n//! 3. A [`Summary`] is now ready in callback `f` in [`RegistryIndex::query_inner`].\n//!\n//! This is just an overview. To know the rationale behind, continue reading.\n//!\n//! ## A layer of on-disk index cache for performance\n//!\n//! One important aspect of the index is that we want to optimize the \"happy\n//! path\" as much as possible. Whenever you type `cargo build` Cargo will\n//! *always* reparse the registry and learn about dependency information. This\n//! is done because Cargo needs to learn about the upstream crates.io crates\n//! that you're using and ensure that the preexisting `Cargo.lock` still matches\n//! the current state of the world.\n//!\n//! Consequently, Cargo \"null builds\" (the index that Cargo adds to each build\n//! itself) need to be fast when accessing the index. The primary performance\n//! optimization here is to avoid parsing JSON blobs from the registry if we\n//! don't need them. Most secondary optimizations are centered around removing\n//! allocations and such, but avoiding parsing JSON is the #1 optimization.\n//!\n//! When we get queries from the resolver we're given a [`Dependency`]. This\n//! dependency in turn has a version requirement, and with lock files that\n//! already exist these version requirements are exact version requirements\n//! `=a.b.c`. This means that we in theory only need to parse one line of JSON\n//! per query in the registry, the one that matches version `a.b.c`.\n//!\n//! The crates.io index, however, is not amenable to this form of query. Instead\n//! the crates.io index simply is a file where each line is a JSON blob, aka\n//! [`IndexPackage`]. To learn about the versions in each JSON blob we would\n//! need to parse the JSON via [`IndexSummary::parse`], defeating the purpose\n//! of trying to parse as little as possible.\n//!\n//! > Note that as a small aside even *loading* the JSON from the registry is\n//! > actually pretty slow. For crates.io and [`RemoteRegistry`] we don't\n//! > actually check out the git index on disk because that takes quite some\n//! > time and is quite large. Instead we use `libgit2` to read the JSON from\n//! > the raw git objects. This in turn can be slow (aka show up high in\n//! > profiles) because libgit2 has to do deflate decompression and such.\n//!\n//! To solve all these issues a strategy is employed here where Cargo basically\n//! creates an index into the index. The first time a package is queried about\n//! (first time being for an entire computer) Cargo will load the contents\n//! (slowly via libgit2) from the registry. It will then (slowly) parse every\n//! single line to learn about its versions. Afterwards, however, Cargo will\n//! emit a new file (a cache, representing as [`SummariesCache`]) which is\n//! amenable for speedily parsing in future invocations.\n//!\n//! This cache file is currently organized by basically having the semver\n//! version extracted from each JSON blob. That way Cargo can quickly and\n//! easily parse all versions contained and which JSON blob they're associated\n//! with. The JSON blob then doesn't actually need to get parsed unless the\n//! version is parsed.\n//!\n//! Altogether the initial measurements of this shows a massive improvement for\n//! Cargo null build performance. It's expected that the improvements earned\n//! here will continue to grow over time in the sense that the previous\n//! implementation (parse all lines each time) actually continues to slow down\n//! over time as new versions of a crate are published. In any case when first\n//! implemented a null build of Cargo itself would parse 3700 JSON blobs from\n//! the registry and load 150 blobs from git. Afterwards it parses 150 JSON\n//! blobs and loads 0 files git. Removing 200ms or more from Cargo's startup\n//! time is certainly nothing to sneeze at!\n//!\n//! Note that this is just a high-level overview, there's of course lots of\n//! details like invalidating caches and whatnot which are handled below, but\n//! hopefully those are more obvious inline in the code itself.\n//!\n//! [`RemoteRegistry`]: super::remote::RemoteRegistry\n//! [`Dependency`]: crate::core::Dependency\n\nuse crate::core::dependency::DepKind;\nuse crate::core::Dependency;\nuse crate::core::{PackageId, SourceId, Summary};\nuse crate::sources::registry::{LoadResponse, RegistryData};\nuse crate::util::interning::InternedString;\nuse crate::util::IntoUrl;\nuse crate::util::{internal, CargoResult, Config, Filesystem, OptVersionReq, ToSemver};\nuse anyhow::bail;\nuse cargo_util::{paths, registry::make_dep_path};\nuse log::{debug, info};\nuse semver::Version;\nuse serde::Deserialize;\nuse std::borrow::Cow;\nuse std::collections::BTreeMap;\nuse std::collections::{HashMap, HashSet};\nuse std::fs;\nuse std::io::ErrorKind;\nuse std::path::Path;\nuse std::str;\nuse std::task::{ready, Poll};\n\n/// The current version of [`SummariesCache`].\nconst CURRENT_CACHE_VERSION: u8 = 3;\n\n/// The maximum schema version of the `v` field in the index this version of\n/// cargo understands. See [`IndexPackage::v`] for the detail.\nconst INDEX_V_MAX: u32 = 2;\n\n/// Manager for handling the on-disk index.\n///\n/// Different kinds of registries store the index differently:\n///\n/// * [`LocalRegistry`]` is a simple on-disk tree of files of the raw index.\n/// * [`RemoteRegistry`] is stored as a raw git repository.\n/// * [`HttpRegistry`] fills the on-disk index cache directly without keeping\n///   any raw index.\n///\n/// These means of access are handled via the [`RegistryData`] trait abstraction.\n/// This transparently handles caching of the index in a more efficient format.\n///\n/// [`LocalRegistry`]: super::local::LocalRegistry\n/// [`RemoteRegistry`]: super::remote::RemoteRegistry\n/// [`HttpRegistry`]: super::http_remote::HttpRegistry\npub struct RegistryIndex<'cfg> {\n    source_id: SourceId,\n    /// Root directory of the index for the registry.\n    path: Filesystem,\n    /// In-memory cache of summary data.\n    ///\n    /// This is keyed off the package name. The [`Summaries`] value handles\n    /// loading the summary data. It keeps an optimized on-disk representation\n    /// of the JSON files, which is created in an as-needed fashion. If it\n    /// hasn't been cached already, it uses [`RegistryData::load`] to access\n    /// to JSON files from the index, and the creates the optimized on-disk\n    /// summary cache.\n    summaries_cache: HashMap<InternedString, Summaries>,\n    /// [`Config`] reference for convenience.\n    config: &'cfg Config,\n}\n\n/// An internal cache of summaries for a particular package.\n///\n/// A list of summaries are loaded from disk via one of two methods:\n///\n/// 1. From raw registry index --- Primarily Cargo will parse the corresponding\n///    file for a crate in the upstream crates.io registry. That's just a JSON\n///    blob per line which we can parse, extract the version, and then store here.\n///    See [`IndexPackage`] and [`IndexSummary::parse`].\n///\n/// 2. From on-disk index cache --- If Cargo has previously run, we'll have a\n///    cached index of dependencies for the upstream index. This is a file that\n///    Cargo maintains lazily on the local filesystem and is much faster to\n///    parse since it doesn't involve parsing all of the JSON.\n///    See [`SummariesCache`].\n///\n/// The outward-facing interface of this doesn't matter too much where it's\n/// loaded from, but it's important when reading the implementation to note that\n/// we try to parse as little as possible!\n#[derive(Default)]\nstruct Summaries {\n    /// A raw vector of uninterpreted bytes. This is what `Unparsed` start/end\n    /// fields are indexes into. If a `Summaries` is loaded from the crates.io\n    /// index then this field will be empty since nothing is `Unparsed`.\n    raw_data: Vec<u8>,\n\n    /// All known versions of a crate, keyed from their `Version` to the\n    /// possibly parsed or unparsed version of the full summary.\n    versions: HashMap<Version, MaybeIndexSummary>,\n}\n\n/// A lazily parsed [`IndexSummary`].\nenum MaybeIndexSummary {\n    /// A summary which has not been parsed, The `start` and `end` are pointers\n    /// into [`Summaries::raw_data`] which this is an entry of.\n    Unparsed { start: usize, end: usize },\n\n    /// An actually parsed summary.\n    Parsed(IndexSummary),\n}\n\n/// A parsed representation of a summary from the index. This is usually parsed\n/// from a line from a raw index file, or a JSON blob from on-disk index cache.\n///\n/// In addition to a full [`Summary`], we have information on whether it is `yanked`.\npub struct IndexSummary {\n    pub summary: Summary,\n    pub yanked: bool,\n    /// Schema version, see [`IndexPackage::v`].\n    v: u32,\n}\n\n/// A representation of the cache on disk that Cargo maintains of summaries.\n///\n/// Cargo will initially parse all summaries in the registry and will then\n/// serialize that into this form and place it in a new location on disk,\n/// ensuring that access in the future is much speedier.\n///\n/// For serialization and deserialization of this on-disk index cache of\n/// summaries, see [`SummariesCache::serialize`]  and [`SummariesCache::parse`].\n///\n/// # The format of the index cache\n///\n/// The idea of this format is that it's a very easy file for Cargo to parse in\n/// future invocations. The read from disk should be fast and then afterwards\n/// all we need to know is what versions correspond to which JSON blob.\n///\n/// Currently the format looks like:\n///\n/// ```text\n/// +---------------+----------------------+--------------------+---+\n/// | cache version | index schema version | index file version | 0 |\n/// +---------------+----------------------+--------------------+---+\n/// ```\n///\n/// followed by one or more (version + JSON blob) pairs...\n///\n/// ```text\n/// +----------------+---+-----------+---+\n/// | semver version | 0 | JSON blob | 0 | ...\n/// +----------------+---+-----------+---+\n/// ```\n///\n/// Each field represents:\n///\n/// * _cache version_ --- Intended to ensure that there's some level of\n///   future compatibility against changes to this cache format so if different\n///   versions of Cargo share the same cache they don't get too confused.\n/// * _index schema version_ --- The schema version of the raw index file.\n///   See [`IndexPackage::v`] for the detail.\n/// * _index file version_ --- Tracks when a cache needs to be regenerated.\n///   A cache regeneration is required whenever the index file itself updates.\n/// * _semver version_ --- The version for each JSON blob. Extracted from the\n///   blob for fast queries without parsing the entire blob.\n/// * _JSON blob_ --- The actual metadata for each version of the package. It\n///   has the same representation as [`IndexPackage`].\n///\n/// # Changes between each cache version\n///\n/// * `1`: The original version.\n/// * `2`: Added the \"index schema version\" field so that if the index schema\n///   changes, different versions of cargo won't get confused reading each\n///   other's caches.\n/// * `3`: Bumped the version to work around an issue where multiple versions of\n///   a package were published that differ only by semver metadata. For\n///   example, openssl-src 110.0.0 and 110.0.0+1.1.0f. Previously, the cache\n///   would be incorrectly populated with two entries, both 110.0.0. After\n///   this, the metadata will be correctly included. This isn't really a format\n///   change, just a version bump to clear the incorrect cache entries. Note:\n///   the index shouldn't allow these, but unfortunately crates.io doesn't\n///   check it.\n///\n/// See [`CURRENT_CACHE_VERSION`] for the current cache version.\n#[derive(Default)]\nstruct SummariesCache<'a> {\n    /// JSON blobs of the summaries. Each JSON blob has a [`Version`] beside,\n    /// so that Cargo can query a version without full JSON parsing.\n    versions: Vec<(Version, &'a [u8])>,\n    /// For cache invalidation, we tracks the index file version to determine\n    /// when to regenerate the cache itself.\n    index_version: &'a str,\n}\n\n/// A single line in the index representing a single version of a package.\n#[derive(Deserialize)]\npub struct IndexPackage<'a> {\n    /// Name of the pacakge.\n    name: InternedString,\n    /// The version of this dependency.\n    vers: Version,\n    /// All kinds of direct dependencies of the package, including dev and\n    /// build dependencies.\n    #[serde(borrow)]\n    deps: Vec<RegistryDependency<'a>>,\n    /// Set of features defined for the package, i.e., `[features]` table.\n    features: BTreeMap<InternedString, Vec<InternedString>>,\n    /// This field contains features with new, extended syntax. Specifically,\n    /// namespaced features (`dep:`) and weak dependencies (`pkg?/feat`).\n    ///\n    /// This is separated from `features` because versions older than 1.19\n    /// will fail to load due to not being able to parse the new syntax, even\n    /// with a `Cargo.lock` file.\n    features2: Option<BTreeMap<InternedString, Vec<InternedString>>>,\n    /// Checksum for verifying the integrity of the corresponding downloaded package.\n    cksum: String,\n    /// If `true`, Cargo will skip this version when resolving.\n    ///\n    /// This was added in 2014. Everything in the crates.io index has this set\n    /// now, so this probably doesn't need to be an option anymore.\n    yanked: Option<bool>,\n    /// Native library name this package links to.\n    ///\n    /// Added early 2018 (see <https://github.com/rust-lang/cargo/pull/4978>),\n    /// can be `None` if published before then.\n    links: Option<InternedString>,\n    /// Required version of rust\n    ///\n    /// Corresponds to `package.rust-version`.\n    ///\n    /// Added in 2023 (see <https://github.com/rust-lang/crates.io/pull/6267>),\n    /// can be `None` if published before then or if not set in the manifest.\n    rust_version: Option<InternedString>,\n    /// The schema version for this entry.\n    ///\n    /// If this is None, it defaults to version `1`. Entries with unknown\n    /// versions are ignored.\n    ///\n    /// Version `2` schema adds the `features2` field.\n    ///\n    /// This provides a method to safely introduce changes to index entries\n    /// and allow older versions of cargo to ignore newer entries it doesn't\n    /// understand. This is honored as of 1.51, so unfortunately older\n    /// versions will ignore it, and potentially misinterpret version 2 and\n    /// newer entries.\n    ///\n    /// The intent is that versions older than 1.51 will work with a\n    /// pre-existing `Cargo.lock`, but they may not correctly process `cargo\n    /// update` or build a lock from scratch. In that case, cargo may\n    /// incorrectly select a new package that uses a new index schema. A\n    /// workaround is to downgrade any packages that are incompatible with the\n    /// `--precise` flag of `cargo update`.\n    v: Option<u32>,\n}\n\n/// A dependency as encoded in the [`IndexPackage`] index JSON.\n#[derive(Deserialize)]\nstruct RegistryDependency<'a> {\n    /// Name of the dependency. If the dependency is renamed, the original\n    /// would be stored in [`RegistryDependency::package`].\n    name: InternedString,\n    /// The SemVer requirement for this dependency.\n    #[serde(borrow)]\n    req: Cow<'a, str>,\n    /// Set of features enabled for this dependency.\n    features: Vec<InternedString>,\n    /// Whether or not this is an optional dependency.\n    optional: bool,\n    /// Whether or not default features are enabled.\n    default_features: bool,\n    /// The target platform for this dependency.\n    target: Option<Cow<'a, str>>,\n    /// The dependency kind. \"dev\", \"build\", and \"normal\".\n    kind: Option<Cow<'a, str>>,\n    // The URL of the index of the registry where this dependency is from.\n    // `None` if it is from the same index.\n    registry: Option<Cow<'a, str>>,\n    /// The original name if the dependency is renamed.\n    package: Option<InternedString>,\n    /// Whether or not this is a public dependency. Unstable. See [RFC 1977].\n    ///\n    /// [RFC 1977]: https://rust-lang.github.io/rfcs/1977-public-private-dependencies.html\n    public: Option<bool>,\n}\n\nimpl<'cfg> RegistryIndex<'cfg> {\n    /// Creates an empty registry index at `path`.\n    pub fn new(\n        source_id: SourceId,\n        path: &Filesystem,\n        config: &'cfg Config,\n    ) -> RegistryIndex<'cfg> {\n        RegistryIndex {\n            source_id,\n            path: path.clone(),\n            summaries_cache: HashMap::new(),\n            config,\n        }\n    }\n\n    /// Returns the hash listed for a specified `PackageId`. Primarily for\n    /// checking the integrity of a downloaded package matching the checksum in\n    /// the index file, aka [`IndexSummary`].\n    pub fn hash(&mut self, pkg: PackageId, load: &mut dyn RegistryData) -> Poll<CargoResult<&str>> {\n        let req = OptVersionReq::exact(pkg.version());\n        let summary = self.summaries(&pkg.name(), &req, load)?;\n        let summary = ready!(summary).next();\n        Poll::Ready(Ok(summary\n            .ok_or_else(|| internal(format!(\"no hash listed for {}\", pkg)))?\n            .summary\n            .checksum()\n            .ok_or_else(|| internal(format!(\"no hash listed for {}\", pkg)))?))\n    }\n\n    /// Load a list of summaries for `name` package in this registry which\n    /// match `req`.\n    ///\n    /// This function will semantically\n    ///\n    /// 1. parse the index file (either raw or cache),\n    /// 2. match all versions,\n    /// 3. and then return an iterator over all summaries which matched.\n    ///\n    /// Internally there's quite a few layer of caching to amortize this cost\n    /// though since this method is called quite a lot on null builds in Cargo.\n    pub fn summaries<'a, 'b>(\n        &'a mut self,\n        name: &str,\n        req: &'b OptVersionReq,\n        load: &mut dyn RegistryData,\n    ) -> Poll<CargoResult<impl Iterator<Item = &'a IndexSummary> + 'b>>\n    where\n        'a: 'b,\n    {\n        let source_id = self.source_id;\n\n        // First up parse what summaries we have available.\n        let name = InternedString::new(name);\n        let summaries = ready!(self.load_summaries(name, load)?);\n\n        // Iterate over our summaries, extract all relevant ones which match our\n        // version requirement, and then parse all corresponding rows in the\n        // registry. As a reminder this `summaries` method is called for each\n        // entry in a lock file on every build, so we want to absolutely\n        // minimize the amount of work being done here and parse as little as\n        // necessary.\n        let raw_data = &summaries.raw_data;\n        Poll::Ready(Ok(summaries\n            .versions\n            .iter_mut()\n            .filter_map(move |(k, v)| if req.matches(k) { Some(v) } else { None })\n            .filter_map(move |maybe| match maybe.parse(raw_data, source_id) {\n                Ok(summary) => Some(summary),\n                Err(e) => {\n                    info!(\"failed to parse `{}` registry package: {}\", name, e);\n                    None\n                }\n            })\n            .filter(move |is| {\n                if is.v > INDEX_V_MAX {\n                    debug!(\n                        \"unsupported schema version {} ({} {})\",\n                        is.v,\n                        is.summary.name(),\n                        is.summary.version()\n                    );\n                    false\n                } else {\n                    true\n                }\n            })))\n    }\n\n    /// Actually parses what summaries we have available.\n    ///\n    /// If Cargo has run previously, this tries in this order:\n    ///\n    /// 1. Returns from in-memory cache, aka [`RegistryIndex::summaries_cache`].\n    /// 2. If missing, hands over to [`Summaries::parse`] to parse an index file.\n    ///\n    ///    The actual kind index file being parsed depends on which kind of\n    ///    [`RegistryData`] the `load` argument is given. For example, a\n    ///    Git-based [`RemoteRegistry`] will first try a on-disk index cache\n    ///    file, and then try parsing registry raw index fomr Git repository.\n    ///\n    /// In effect, this is intended to be a quite cheap operation.\n    ///\n    /// [`RemoteRegistry`]: super::remote::RemoteRegistry\n    fn load_summaries(\n        &mut self,\n        name: InternedString,\n        load: &mut dyn RegistryData,\n    ) -> Poll<CargoResult<&mut Summaries>> {\n        // If we've previously loaded what versions are present for `name`, just\n        // return that since our in-memory cache should still be valid.\n        if self.summaries_cache.contains_key(&name) {\n            return Poll::Ready(Ok(self.summaries_cache.get_mut(&name).unwrap()));\n        }\n\n        // Prepare the `RegistryData` which will lazily initialize internal data\n        // structures.\n        load.prepare()?;\n\n        let root = load.assert_index_locked(&self.path);\n        let cache_root = root.join(\".cache\");\n\n        // See module comment in `registry/mod.rs` for why this is structured\n        // the way it is.\n        let path = make_dep_path(&name.to_lowercase(), false);\n        let summaries = ready!(Summaries::parse(\n            root,\n            &cache_root,\n            path.as_ref(),\n            self.source_id,\n            load,\n            self.config,\n        ))?\n        .unwrap_or_default();\n        self.summaries_cache.insert(name, summaries);\n        Poll::Ready(Ok(self.summaries_cache.get_mut(&name).unwrap()))\n    }\n\n    /// Clears the in-memory summaries cache.\n    pub fn clear_summaries_cache(&mut self) {\n        self.summaries_cache.clear();\n    }\n\n    /// Attempts to find the packages that match a `name` and a version `req`.\n    ///\n    /// This is primarily used by [`Source::query`](super::Source).\n    pub fn query_inner(\n        &mut self,\n        name: &str,\n        req: &OptVersionReq,\n        load: &mut dyn RegistryData,\n        yanked_whitelist: &HashSet<PackageId>,\n        f: &mut dyn FnMut(Summary),\n    ) -> Poll<CargoResult<()>> {\n        if self.config.offline() {\n            // This should only return `Poll::Ready(Ok(()))` if there is at least 1 match.\n            //\n            // If there are 0 matches it should fall through and try again with online.\n            // This is necessary for dependencies that are not used (such as\n            // target-cfg or optional), but are not downloaded. Normally the\n            // build should succeed if they are not downloaded and not used,\n            // but they still need to resolve. If they are actually needed\n            // then cargo will fail to download and an error message\n            // indicating that the required dependency is unavailable while\n            // offline will be displayed.\n            if ready!(self.query_inner_with_online(name, req, load, yanked_whitelist, f, false)?)\n                > 0\n            {\n                return Poll::Ready(Ok(()));\n            }\n        }\n        self.query_inner_with_online(name, req, load, yanked_whitelist, f, true)\n            .map_ok(|_| ())\n    }\n\n    /// Inner implementation of [`Self::query_inner`]. Returns the number of\n    /// summaries we've got.\n    ///\n    /// The `online` controls whether Cargo can access the network when needed.\n    fn query_inner_with_online(\n        &mut self,\n        name: &str,\n        req: &OptVersionReq,\n        load: &mut dyn RegistryData,\n        yanked_whitelist: &HashSet<PackageId>,\n        f: &mut dyn FnMut(Summary),\n        online: bool,\n    ) -> Poll<CargoResult<usize>> {\n        let source_id = self.source_id;\n\n        let summaries = ready!(self.summaries(name, req, load))?;\n\n        let summaries = summaries\n            // First filter summaries for `--offline`. If we're online then\n            // everything is a candidate, otherwise if we're offline we're only\n            // going to consider candidates which are actually present on disk.\n            //\n            // Note: This particular logic can cause problems with\n            // optional dependencies when offline. If at least 1 version\n            // of an optional dependency is downloaded, but that version\n            // does not satisfy the requirements, then resolution will\n            // fail. Unfortunately, whether or not something is optional\n            // is not known here.\n            .filter(|s| (online || load.is_crate_downloaded(s.summary.package_id())))\n            // Next filter out all yanked packages. Some yanked packages may\n            // leak through if they're in a whitelist (aka if they were\n            // previously in `Cargo.lock`\n            .filter(|s| !s.yanked || yanked_whitelist.contains(&s.summary.package_id()))\n            .map(|s| s.summary.clone());\n\n        // Handle `cargo update --precise` here. If specified, our own source\n        // will have a precise version listed of the form\n        // `<pkg>=<p_req>o-><f_req>` where `<pkg>` is the name of a crate on\n        // this source, `<p_req>` is the version installed and `<f_req> is the\n        // version requested (argument to `--precise`).\n        let precise = match source_id.precise() {\n            Some(p) if p.starts_with(name) && p[name.len()..].starts_with('=') => {\n                let mut vers = p[name.len() + 1..].splitn(2, \"->\");\n                let current_vers = vers.next().unwrap().to_semver().unwrap();\n                let requested_vers = vers.next().unwrap().to_semver().unwrap();\n                Some((current_vers, requested_vers))\n            }\n            _ => None,\n        };\n        let summaries = summaries.filter(|s| match &precise {\n            Some((current, requested)) => {\n                if req.matches(current) {\n                    // Unfortunately crates.io allows versions to differ only\n                    // by build metadata. This shouldn't be allowed, but since\n                    // it is, this will honor it if requested. However, if not\n                    // specified, then ignore it.\n                    let s_vers = s.version();\n                    match (s_vers.build.is_empty(), requested.build.is_empty()) {\n                        (true, true) => s_vers == requested,\n                        (true, false) => false,\n                        (false, true) => {\n                            // Strip out the metadata.\n                            s_vers.major == requested.major\n                                && s_vers.minor == requested.minor\n                                && s_vers.patch == requested.patch\n                                && s_vers.pre == requested.pre\n                        }\n                        (false, false) => s_vers == requested,\n                    }\n                } else {\n                    true\n                }\n            }\n            None => true,\n        });\n\n        let mut count = 0;\n        for summary in summaries {\n            f(summary);\n            count += 1;\n        }\n        Poll::Ready(Ok(count))\n    }\n\n    /// Looks into the summaries to check if a package has been yanked.\n    pub fn is_yanked(\n        &mut self,\n        pkg: PackageId,\n        load: &mut dyn RegistryData,\n    ) -> Poll<CargoResult<bool>> {\n        let req = OptVersionReq::exact(pkg.version());\n        let found = self\n            .summaries(&pkg.name(), &req, load)\n            .map_ok(|mut p| p.any(|summary| summary.yanked));\n        found\n    }\n}\n\nimpl Summaries {\n    /// Parse out a [`Summaries`] instances from on-disk state.\n    ///\n    /// This will do the followings in order:\n    ///\n    /// 1. Attempt to prefer parsing a previous index cache file that already\n    ///    exists from a previous invocation of Cargo (aka you're typing `cargo\n    ///    build` again after typing it previously).\n    /// 2. If parsing fails, or the cache isn't found or is invalid, we then\n    ///    take a slower path which loads the full descriptor for `relative`\n    ///    from the underlying index (aka libgit2 with crates.io, or from a\n    ///    remote HTTP index) and then parse everything in there.\n    ///\n    /// * `root` --- this is the root argument passed to `load`\n    /// * `cache_root` --- this is the root on the filesystem itself of where\n    ///   to store cache files.\n    /// * `relative` --- this is the file we're loading from cache or the index\n    ///   data\n    /// * `source_id` --- the registry's SourceId used when parsing JSON blobs\n    ///   to create summaries.\n    /// * `load` --- the actual index implementation which may be very slow to\n    ///   call. We avoid this if we can.\n    pub fn parse(\n        root: &Path,\n        cache_root: &Path,\n        relative: &Path,\n        source_id: SourceId,\n        load: &mut dyn RegistryData,\n        config: &Config,\n    ) -> Poll<CargoResult<Option<Summaries>>> {\n        // First up, attempt to load the cache. This could fail for all manner\n        // of reasons, but consider all of them non-fatal and just log their\n        // occurrence in case anyone is debugging anything.\n        let cache_path = cache_root.join(relative);\n        let mut cached_summaries = None;\n        let mut index_version = None;\n        match fs::read(&cache_path) {\n            Ok(contents) => match Summaries::parse_cache(contents) {\n                Ok((s, v)) => {\n                    cached_summaries = Some(s);\n                    index_version = Some(v);\n                }\n                Err(e) => {\n                    log::debug!(\"failed to parse {:?} cache: {}\", relative, e);\n                }\n            },\n            Err(e) => log::debug!(\"cache missing for {:?} error: {}\", relative, e),\n        }\n\n        let response = ready!(load.load(root, relative, index_version.as_deref())?);\n\n        match response {\n            LoadResponse::CacheValid => {\n                log::debug!(\"fast path for registry cache of {:?}\", relative);\n                return Poll::Ready(Ok(cached_summaries));\n            }\n            LoadResponse::NotFound => {\n                if let Err(e) = fs::remove_file(cache_path) {\n                    if e.kind() != ErrorKind::NotFound {\n                        log::debug!(\"failed to remove from cache: {}\", e);\n                    }\n                }\n                return Poll::Ready(Ok(None));\n            }\n            LoadResponse::Data {\n                raw_data,\n                index_version,\n            } => {\n                // This is the fallback path where we actually talk to the registry backend to load\n                // information. Here we parse every single line in the index (as we need\n                // to find the versions)\n                log::debug!(\"slow path for {:?}\", relative);\n                let mut cache = SummariesCache::default();\n                let mut ret = Summaries::default();\n                ret.raw_data = raw_data;\n                for line in split(&ret.raw_data, b'\\n') {\n                    // Attempt forwards-compatibility on the index by ignoring\n                    // everything that we ourselves don't understand, that should\n                    // allow future cargo implementations to break the\n                    // interpretation of each line here and older cargo will simply\n                    // ignore the new lines.\n                    let summary = match IndexSummary::parse(line, source_id) {\n                        Ok(summary) => summary,\n                        Err(e) => {\n                            // This should only happen when there is an index\n                            // entry from a future version of cargo that this\n                            // version doesn't understand. Hopefully, those future\n                            // versions of cargo correctly set INDEX_V_MAX and\n                            // CURRENT_CACHE_VERSION, otherwise this will skip\n                            // entries in the cache preventing those newer\n                            // versions from reading them (that is, until the\n                            // cache is rebuilt).\n                            log::info!(\"failed to parse {:?} registry package: {}\", relative, e);\n                            continue;\n                        }\n                    };\n                    let version = summary.summary.package_id().version().clone();\n                    cache.versions.push((version.clone(), line));\n                    ret.versions.insert(version, summary.into());\n                }\n                if let Some(index_version) = index_version {\n                    log::trace!(\"caching index_version {}\", index_version);\n                    let cache_bytes = cache.serialize(index_version.as_str());\n                    // Once we have our `cache_bytes` which represents the `Summaries` we're\n                    // about to return, write that back out to disk so future Cargo\n                    // invocations can use it.\n                    //\n                    // This is opportunistic so we ignore failure here but are sure to log\n                    // something in case of error.\n                    if paths::create_dir_all(cache_path.parent().unwrap()).is_ok() {\n                        let path = Filesystem::new(cache_path.clone());\n                        config.assert_package_cache_locked(&path);\n                        if let Err(e) = fs::write(cache_path, &cache_bytes) {\n                            log::info!(\"failed to write cache: {}\", e);\n                        }\n                    }\n\n                    // If we've got debug assertions enabled read back in the cached values\n                    // and assert they match the expected result.\n                    #[cfg(debug_assertions)]\n                    {\n                        let readback = SummariesCache::parse(&cache_bytes)\n                            .expect(\"failed to parse cache we just wrote\");\n                        assert_eq!(\n                            readback.index_version, index_version,\n                            \"index_version mismatch\"\n                        );\n                        assert_eq!(readback.versions, cache.versions, \"versions mismatch\");\n                    }\n                }\n                Poll::Ready(Ok(Some(ret)))\n            }\n        }\n    }\n\n    /// Parses the contents of an on-disk cache, aka [`SummariesCache`], which\n    /// represents information previously cached by Cargo.\n    pub fn parse_cache(contents: Vec<u8>) -> CargoResult<(Summaries, InternedString)> {\n        let cache = SummariesCache::parse(&contents)?;\n        let index_version = InternedString::new(cache.index_version);\n        let mut ret = Summaries::default();\n        for (version, summary) in cache.versions {\n            let (start, end) = subslice_bounds(&contents, summary);\n            ret.versions\n                .insert(version, MaybeIndexSummary::Unparsed { start, end });\n        }\n        ret.raw_data = contents;\n        return Ok((ret, index_version));\n\n        // Returns the start/end offsets of `inner` with `outer`. Asserts that\n        // `inner` is a subslice of `outer`.\n        fn subslice_bounds(outer: &[u8], inner: &[u8]) -> (usize, usize) {\n            let outer_start = outer.as_ptr() as usize;\n            let outer_end = outer_start + outer.len();\n            let inner_start = inner.as_ptr() as usize;\n            let inner_end = inner_start + inner.len();\n            assert!(inner_start >= outer_start);\n            assert!(inner_end <= outer_end);\n            (inner_start - outer_start, inner_end - outer_start)\n        }\n    }\n}\n\nimpl<'a> SummariesCache<'a> {\n    /// Deserializes an on-disk cache.\n    fn parse(data: &'a [u8]) -> CargoResult<SummariesCache<'a>> {\n        // NB: keep this method in sync with `serialize` below\n        let (first_byte, rest) = data\n            .split_first()\n            .ok_or_else(|| anyhow::format_err!(\"malformed cache\"))?;\n        if *first_byte != CURRENT_CACHE_VERSION {\n            bail!(\"looks like a different Cargo's cache, bailing out\");\n        }\n        let index_v_bytes = rest\n            .get(..4)\n            .ok_or_else(|| anyhow::anyhow!(\"cache expected 4 bytes for index schema version\"))?;\n        let index_v = u32::from_le_bytes(index_v_bytes.try_into().unwrap());\n        if index_v != INDEX_V_MAX {\n            bail!(\n                \"index schema version {index_v} doesn't match the version I know ({INDEX_V_MAX})\",\n            );\n        }\n        let rest = &rest[4..];\n\n        let mut iter = split(rest, 0);\n        let last_index_update = if let Some(update) = iter.next() {\n            str::from_utf8(update)?\n        } else {\n            bail!(\"malformed file\");\n        };\n        let mut ret = SummariesCache::default();\n        ret.index_version = last_index_update;\n        while let Some(version) = iter.next() {\n            let version = str::from_utf8(version)?;\n            let version = Version::parse(version)?;\n            let summary = iter.next().unwrap();\n            ret.versions.push((version, summary));\n        }\n        Ok(ret)\n    }\n\n    /// Serializes itself with a given `index_version`.\n    fn serialize(&self, index_version: &str) -> Vec<u8> {\n        // NB: keep this method in sync with `parse` above\n        let size = self\n            .versions\n            .iter()\n            .map(|(_version, data)| (10 + data.len()))\n            .sum();\n        let mut contents = Vec::with_capacity(size);\n        contents.push(CURRENT_CACHE_VERSION);\n        contents.extend(&u32::to_le_bytes(INDEX_V_MAX));\n        contents.extend_from_slice(index_version.as_bytes());\n        contents.push(0);\n        for (version, data) in self.versions.iter() {\n            contents.extend_from_slice(version.to_string().as_bytes());\n            contents.push(0);\n            contents.extend_from_slice(data);\n            contents.push(0);\n        }\n        contents\n    }\n}\n\nimpl MaybeIndexSummary {\n    /// Parses this \"maybe a summary\" into a `Parsed` for sure variant.\n    ///\n    /// Does nothing if this is already `Parsed`, and otherwise the `raw_data`\n    /// passed in is sliced with the bounds in `Unparsed` and then actually\n    /// parsed.\n    fn parse(&mut self, raw_data: &[u8], source_id: SourceId) -> CargoResult<&IndexSummary> {\n        let (start, end) = match self {\n            MaybeIndexSummary::Unparsed { start, end } => (*start, *end),\n            MaybeIndexSummary::Parsed(summary) => return Ok(summary),\n        };\n        let summary = IndexSummary::parse(&raw_data[start..end], source_id)?;\n        *self = MaybeIndexSummary::Parsed(summary);\n        match self {\n            MaybeIndexSummary::Unparsed { .. } => unreachable!(),\n            MaybeIndexSummary::Parsed(summary) => Ok(summary),\n        }\n    }\n}\n\nimpl From<IndexSummary> for MaybeIndexSummary {\n    fn from(summary: IndexSummary) -> MaybeIndexSummary {\n        MaybeIndexSummary::Parsed(summary)\n    }\n}\n\nimpl IndexSummary {\n    /// Parses a line from the registry's index file into an [`IndexSummary`]\n    /// for a package.\n    ///\n    /// The `line` provided is expected to be valid JSON. It is supposed to be\n    /// a [`IndexPackage`].\n    fn parse(line: &[u8], source_id: SourceId) -> CargoResult<IndexSummary> {\n        // ****CAUTION**** Please be extremely careful with returning errors\n        // from this function. Entries that error are not included in the\n        // index cache, and can cause cargo to get confused when switching\n        // between different versions that understand the index differently.\n        // Make sure to consider the INDEX_V_MAX and CURRENT_CACHE_VERSION\n        // values carefully when making changes here.\n        let IndexPackage {\n            name,\n            vers,\n            cksum,\n            deps,\n            mut features,\n            features2,\n            yanked,\n            links,\n            rust_version,\n            v,\n        } = serde_json::from_slice(line)?;\n        let v = v.unwrap_or(1);\n        log::trace!(\"json parsed registry {}/{}\", name, vers);\n        let pkgid = PackageId::new(name, &vers, source_id)?;\n        let deps = deps\n            .into_iter()\n            .map(|dep| dep.into_dep(source_id))\n            .collect::<CargoResult<Vec<_>>>()?;\n        if let Some(features2) = features2 {\n            for (name, values) in features2 {\n                features.entry(name).or_default().extend(values);\n            }\n        }\n        let mut summary = Summary::new(pkgid, deps, &features, links, rust_version)?;\n        summary.set_checksum(cksum);\n        Ok(IndexSummary {\n            summary,\n            yanked: yanked.unwrap_or(false),\n            v,\n        })\n    }\n}\n\nimpl<'a> RegistryDependency<'a> {\n    /// Converts an encoded dependency in the registry to a cargo dependency\n    pub fn into_dep(self, default: SourceId) -> CargoResult<Dependency> {\n        let RegistryDependency {\n            name,\n            req,\n            mut features,\n            optional,\n            default_features,\n            target,\n            kind,\n            registry,\n            package,\n            public,\n        } = self;\n\n        let id = if let Some(registry) = &registry {\n            SourceId::for_registry(&registry.into_url()?)?\n        } else {\n            default\n        };\n\n        let mut dep = Dependency::parse(package.unwrap_or(name), Some(&req), id)?;\n        if package.is_some() {\n            dep.set_explicit_name_in_toml(name);\n        }\n        let kind = match kind.as_deref().unwrap_or(\"\") {\n            \"dev\" => DepKind::Development,\n            \"build\" => DepKind::Build,\n            _ => DepKind::Normal,\n        };\n\n        let platform = match target {\n            Some(target) => Some(target.parse()?),\n            None => None,\n        };\n\n        // All dependencies are private by default\n        let public = public.unwrap_or(false);\n\n        // Unfortunately older versions of cargo and/or the registry ended up\n        // publishing lots of entries where the features array contained the\n        // empty feature, \"\", inside. This confuses the resolution process much\n        // later on and these features aren't actually valid, so filter them all\n        // out here.\n        features.retain(|s| !s.is_empty());\n\n        // In index, \"registry\" is null if it is from the same index.\n        // In Cargo.toml, \"registry\" is None if it is from the default\n        if !id.is_crates_io() {\n            dep.set_registry_id(id);\n        }\n\n        dep.set_optional(optional)\n            .set_default_features(default_features)\n            .set_features(features)\n            .set_platform(platform)\n            .set_kind(kind)\n            .set_public(public);\n\n        Ok(dep)\n    }\n}\n\n/// Like [`slice::split`] but is optimized by [`memchr`].\nfn split(haystack: &[u8], needle: u8) -> impl Iterator<Item = &[u8]> {\n    struct Split<'a> {\n        haystack: &'a [u8],\n        needle: u8,\n    }\n\n    impl<'a> Iterator for Split<'a> {\n        type Item = &'a [u8];\n\n        fn next(&mut self) -> Option<&'a [u8]> {\n            if self.haystack.is_empty() {\n                return None;\n            }\n            let (ret, remaining) = match memchr::memchr(self.needle, self.haystack) {\n                Some(pos) => (&self.haystack[..pos], &self.haystack[pos + 1..]),\n                None => (self.haystack, &[][..]),\n            };\n            self.haystack = remaining;\n            Some(ret)\n        }\n    }\n\n    Split { haystack, needle }\n}\n\n#[test]\nfn escaped_char_in_index_json_blob() {\n    let _: IndexPackage<'_> = serde_json::from_str(\n        r#\"{\"name\":\"a\",\"vers\":\"0.0.1\",\"deps\":[],\"cksum\":\"bae3\",\"features\":{}}\"#,\n    )\n    .unwrap();\n    let _: IndexPackage<'_> = serde_json::from_str(\n        r#\"{\"name\":\"a\",\"vers\":\"0.0.1\",\"deps\":[],\"cksum\":\"bae3\",\"features\":{\"test\":[\"k\",\"q\"]},\"links\":\"a-sys\"}\"#\n    ).unwrap();\n\n    // Now we add escaped cher all the places they can go\n    // these are not valid, but it should error later than json parsing\n    let _: IndexPackage<'_> = serde_json::from_str(\n        r#\"{\n        \"name\":\"This name has a escaped cher in it \\n\\t\\\" \",\n        \"vers\":\"0.0.1\",\n        \"deps\":[{\n            \"name\": \" \\n\\t\\\" \",\n            \"req\": \" \\n\\t\\\" \",\n            \"features\": [\" \\n\\t\\\" \"],\n            \"optional\": true,\n            \"default_features\": true,\n            \"target\": \" \\n\\t\\\" \",\n            \"kind\": \" \\n\\t\\\" \",\n            \"registry\": \" \\n\\t\\\" \"\n        }],\n        \"cksum\":\"bae3\",\n        \"features\":{\"test \\n\\t\\\" \":[\"k \\n\\t\\\" \",\"q \\n\\t\\\" \"]},\n        \"links\":\" \\n\\t\\\" \"}\"#,\n    )\n    .unwrap();\n}\n", "use std::collections::{BTreeMap, BTreeSet, HashMap};\nuse std::ffi::OsStr;\nuse std::fmt::{self, Display, Write};\nuse std::marker::PhantomData;\nuse std::path::{Path, PathBuf};\nuse std::rc::Rc;\nuse std::str::{self, FromStr};\n\nuse anyhow::{anyhow, bail, Context as _};\nuse cargo_platform::Platform;\nuse cargo_util::paths;\nuse itertools::Itertools;\nuse lazycell::LazyCell;\nuse log::{debug, trace};\nuse semver::{self, VersionReq};\nuse serde::de::IntoDeserializer as _;\nuse serde::de::{self, Unexpected};\nuse serde::ser;\nuse serde::{Deserialize, Serialize};\nuse url::Url;\n\nuse crate::core::compiler::{CompileKind, CompileTarget};\nuse crate::core::dependency::{Artifact, ArtifactTarget, DepKind};\nuse crate::core::manifest::{ManifestMetadata, TargetSourcePath, Warnings};\nuse crate::core::resolver::ResolveBehavior;\nuse crate::core::{find_workspace_root, resolve_relative_path, CliUnstable};\nuse crate::core::{Dependency, Manifest, PackageId, Summary, Target};\nuse crate::core::{Edition, EitherManifest, Feature, Features, VirtualManifest, Workspace};\nuse crate::core::{GitReference, PackageIdSpec, SourceId, WorkspaceConfig, WorkspaceRootConfig};\nuse crate::sources::{CRATES_IO_INDEX, CRATES_IO_REGISTRY};\nuse crate::util::errors::{CargoResult, ManifestError};\nuse crate::util::interning::InternedString;\nuse crate::util::{\n    self, config::ConfigRelativePath, validate_package_name, Config, IntoUrl, VersionReqExt,\n};\n\npub mod embedded;\nmod targets;\nuse self::targets::targets;\n\n/// Loads a `Cargo.toml` from a file on disk.\n///\n/// This could result in a real or virtual manifest being returned.\n///\n/// A list of nested paths is also returned, one for each path dependency\n/// within the manifest. For virtual manifests, these paths can only\n/// come from patched or replaced dependencies. These paths are not\n/// canonicalized.\npub fn read_manifest(\n    path: &Path,\n    source_id: SourceId,\n    config: &Config,\n) -> Result<(EitherManifest, Vec<PathBuf>), ManifestError> {\n    trace!(\n        \"read_manifest; path={}; source-id={}\",\n        path.display(),\n        source_id\n    );\n    let mut contents = paths::read(path).map_err(|err| ManifestError::new(err, path.into()))?;\n    let embedded = is_embedded(path);\n    if embedded {\n        if !config.cli_unstable().script {\n            return Err(ManifestError::new(\n                anyhow::anyhow!(\"parsing `{}` requires `-Zscript`\", path.display()),\n                path.into(),\n            ));\n        }\n        contents = embedded::expand_manifest(&contents, path, config)\n            .map_err(|err| ManifestError::new(err, path.into()))?;\n    }\n\n    read_manifest_from_str(&contents, path, embedded, source_id, config)\n        .with_context(|| format!(\"failed to parse manifest at `{}`\", path.display()))\n        .map_err(|err| ManifestError::new(err, path.into()))\n}\n\nfn is_embedded(path: &Path) -> bool {\n    let ext = path.extension();\n    ext.is_none() || ext == Some(OsStr::new(\"rs\"))\n}\n\n/// Parse an already-loaded `Cargo.toml` as a Cargo manifest.\n///\n/// This could result in a real or virtual manifest being returned.\n///\n/// A list of nested paths is also returned, one for each path dependency\n/// within the manifest. For virtual manifests, these paths can only\n/// come from patched or replaced dependencies. These paths are not\n/// canonicalized.\nfn read_manifest_from_str(\n    contents: &str,\n    manifest_file: &Path,\n    embedded: bool,\n    source_id: SourceId,\n    config: &Config,\n) -> CargoResult<(EitherManifest, Vec<PathBuf>)> {\n    let package_root = manifest_file.parent().unwrap();\n\n    let toml = {\n        let pretty_filename = manifest_file\n            .strip_prefix(config.cwd())\n            .unwrap_or(manifest_file);\n        parse_document(contents, pretty_filename, config)?\n    };\n\n    // Provide a helpful error message for a common user error.\n    if let Some(package) = toml.get(\"package\").or_else(|| toml.get(\"project\")) {\n        if let Some(feats) = package.get(\"cargo-features\") {\n            bail!(\n                \"cargo-features = {} was found in the wrong location: it \\\n                 should be set at the top of Cargo.toml before any tables\",\n                feats\n            );\n        }\n    }\n\n    let mut unused = BTreeSet::new();\n    let manifest: TomlManifest = serde_ignored::deserialize(toml.into_deserializer(), |path| {\n        let mut key = String::new();\n        stringify(&mut key, &path);\n        unused.insert(key);\n    })?;\n    let add_unused = |warnings: &mut Warnings| {\n        for key in unused {\n            warnings.add_warning(format!(\"unused manifest key: {}\", key));\n            if key == \"profiles.debug\" {\n                warnings.add_warning(\"use `[profile.dev]` to configure debug builds\".to_string());\n            }\n        }\n    };\n\n    let manifest = Rc::new(manifest);\n    if let Some(deps) = manifest\n        .workspace\n        .as_ref()\n        .and_then(|ws| ws.dependencies.as_ref())\n    {\n        for (name, dep) in deps {\n            if dep.is_optional() {\n                bail!(\n                    \"{} is optional, but workspace dependencies cannot be optional\",\n                    name\n                );\n            }\n        }\n    }\n    return if manifest.project.is_some() || manifest.package.is_some() {\n        let (mut manifest, paths) =\n            TomlManifest::to_real_manifest(&manifest, embedded, source_id, package_root, config)?;\n        add_unused(manifest.warnings_mut());\n        if manifest.targets().iter().all(|t| t.is_custom_build()) {\n            bail!(\n                \"no targets specified in the manifest\\n\\\n                 either src/lib.rs, src/main.rs, a [lib] section, or \\\n                 [[bin]] section must be present\"\n            )\n        }\n        Ok((EitherManifest::Real(manifest), paths))\n    } else {\n        let (mut m, paths) =\n            TomlManifest::to_virtual_manifest(&manifest, source_id, package_root, config)?;\n        add_unused(m.warnings_mut());\n        Ok((EitherManifest::Virtual(m), paths))\n    };\n\n    fn stringify(dst: &mut String, path: &serde_ignored::Path<'_>) {\n        use serde_ignored::Path;\n\n        match *path {\n            Path::Root => {}\n            Path::Seq { parent, index } => {\n                stringify(dst, parent);\n                if !dst.is_empty() {\n                    dst.push('.');\n                }\n                dst.push_str(&index.to_string());\n            }\n            Path::Map { parent, ref key } => {\n                stringify(dst, parent);\n                if !dst.is_empty() {\n                    dst.push('.');\n                }\n                dst.push_str(key);\n            }\n            Path::Some { parent }\n            | Path::NewtypeVariant { parent }\n            | Path::NewtypeStruct { parent } => stringify(dst, parent),\n        }\n    }\n}\n\npub fn parse_document(toml: &str, _file: &Path, _config: &Config) -> CargoResult<toml::Table> {\n    // At the moment, no compatibility checks are needed.\n    toml.parse()\n        .map_err(|e| anyhow::Error::from(e).context(\"could not parse input as TOML\"))\n}\n\n/// Warn about paths that have been deprecated and may conflict.\nfn warn_on_deprecated(new_path: &str, name: &str, kind: &str, warnings: &mut Vec<String>) {\n    let old_path = new_path.replace(\"-\", \"_\");\n    warnings.push(format!(\n        \"conflicting between `{new_path}` and `{old_path}` in the `{name}` {kind}.\\n\n        `{old_path}` is ignored and not recommended for use in the future\"\n    ))\n}\n\ntype TomlLibTarget = TomlTarget;\ntype TomlBinTarget = TomlTarget;\ntype TomlExampleTarget = TomlTarget;\ntype TomlTestTarget = TomlTarget;\ntype TomlBenchTarget = TomlTarget;\n\n#[derive(Clone, Debug, Serialize)]\n#[serde(untagged)]\npub enum TomlDependency<P: Clone = String> {\n    /// In the simple format, only a version is specified, eg.\n    /// `package = \"<version>\"`\n    Simple(String),\n    /// The simple format is equivalent to a detailed dependency\n    /// specifying only a version, eg.\n    /// `package = { version = \"<version>\" }`\n    Detailed(DetailedTomlDependency<P>),\n}\n\nimpl<'de, P: Deserialize<'de> + Clone> de::Deserialize<'de> for TomlDependency<P> {\n    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        struct TomlDependencyVisitor<P>(PhantomData<P>);\n\n        impl<'de, P: Deserialize<'de> + Clone> de::Visitor<'de> for TomlDependencyVisitor<P> {\n            type Value = TomlDependency<P>;\n\n            fn expecting(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n                formatter.write_str(\n                    \"a version string like \\\"0.9.8\\\" or a \\\n                     detailed dependency like { version = \\\"0.9.8\\\" }\",\n                )\n            }\n\n            fn visit_str<E>(self, s: &str) -> Result<Self::Value, E>\n            where\n                E: de::Error,\n            {\n                Ok(TomlDependency::Simple(s.to_owned()))\n            }\n\n            fn visit_map<V>(self, map: V) -> Result<Self::Value, V::Error>\n            where\n                V: de::MapAccess<'de>,\n            {\n                let mvd = de::value::MapAccessDeserializer::new(map);\n                DetailedTomlDependency::deserialize(mvd).map(TomlDependency::Detailed)\n            }\n        }\n        deserializer.deserialize_any(TomlDependencyVisitor(PhantomData))\n    }\n}\n\nimpl TomlDependency {\n    fn unused_keys(&self) -> Vec<String> {\n        match self {\n            TomlDependency::Simple(_) => vec![],\n            TomlDependency::Detailed(detailed) => detailed.other.keys().cloned().collect(),\n        }\n    }\n}\n\npub trait ResolveToPath {\n    fn resolve(&self, config: &Config) -> PathBuf;\n}\n\nimpl ResolveToPath for String {\n    fn resolve(&self, _: &Config) -> PathBuf {\n        self.into()\n    }\n}\n\nimpl ResolveToPath for ConfigRelativePath {\n    fn resolve(&self, c: &Config) -> PathBuf {\n        self.resolve_path(c)\n    }\n}\n\n#[derive(Deserialize, Serialize, Clone, Debug)]\n#[serde(rename_all = \"kebab-case\")]\npub struct DetailedTomlDependency<P: Clone = String> {\n    version: Option<String>,\n    registry: Option<String>,\n    /// The URL of the `registry` field.\n    /// This is an internal implementation detail. When Cargo creates a\n    /// package, it replaces `registry` with `registry-index` so that the\n    /// manifest contains the correct URL. All users won't have the same\n    /// registry names configured, so Cargo can't rely on just the name for\n    /// crates published by other users.\n    registry_index: Option<String>,\n    // `path` is relative to the file it appears in. If that's a `Cargo.toml`, it'll be relative to\n    // that TOML file, and if it's a `.cargo/config` file, it'll be relative to that file.\n    path: Option<P>,\n    git: Option<String>,\n    branch: Option<String>,\n    tag: Option<String>,\n    rev: Option<String>,\n    features: Option<Vec<String>>,\n    optional: Option<bool>,\n    default_features: Option<bool>,\n    #[serde(rename = \"default_features\")]\n    default_features2: Option<bool>,\n    package: Option<String>,\n    public: Option<bool>,\n\n    /// One or more of `bin`, `cdylib`, `staticlib`, `bin:<name>`.\n    artifact: Option<StringOrVec>,\n    /// If set, the artifact should also be a dependency\n    lib: Option<bool>,\n    /// A platform name, like `x86_64-apple-darwin`\n    target: Option<String>,\n    /// This is here to provide a way to see the \"unused manifest keys\" when deserializing\n    #[serde(skip_serializing)]\n    #[serde(flatten)]\n    other: BTreeMap<String, toml::Value>,\n}\n\n// Explicit implementation so we avoid pulling in P: Default\nimpl<P: Clone> Default for DetailedTomlDependency<P> {\n    fn default() -> Self {\n        Self {\n            version: Default::default(),\n            registry: Default::default(),\n            registry_index: Default::default(),\n            path: Default::default(),\n            git: Default::default(),\n            branch: Default::default(),\n            tag: Default::default(),\n            rev: Default::default(),\n            features: Default::default(),\n            optional: Default::default(),\n            default_features: Default::default(),\n            default_features2: Default::default(),\n            package: Default::default(),\n            public: Default::default(),\n            artifact: Default::default(),\n            lib: Default::default(),\n            target: Default::default(),\n            other: Default::default(),\n        }\n    }\n}\n\n/// This type is used to deserialize `Cargo.toml` files.\n#[derive(Debug, Deserialize, Serialize)]\n#[serde(rename_all = \"kebab-case\")]\npub struct TomlManifest {\n    cargo_features: Option<Vec<String>>,\n    package: Option<Box<TomlPackage>>,\n    project: Option<Box<TomlPackage>>,\n    profile: Option<TomlProfiles>,\n    lib: Option<TomlLibTarget>,\n    bin: Option<Vec<TomlBinTarget>>,\n    example: Option<Vec<TomlExampleTarget>>,\n    test: Option<Vec<TomlTestTarget>>,\n    bench: Option<Vec<TomlTestTarget>>,\n    dependencies: Option<BTreeMap<String, MaybeWorkspaceDependency>>,\n    dev_dependencies: Option<BTreeMap<String, MaybeWorkspaceDependency>>,\n    #[serde(rename = \"dev_dependencies\")]\n    dev_dependencies2: Option<BTreeMap<String, MaybeWorkspaceDependency>>,\n    build_dependencies: Option<BTreeMap<String, MaybeWorkspaceDependency>>,\n    #[serde(rename = \"build_dependencies\")]\n    build_dependencies2: Option<BTreeMap<String, MaybeWorkspaceDependency>>,\n    features: Option<BTreeMap<InternedString, Vec<InternedString>>>,\n    target: Option<BTreeMap<String, TomlPlatform>>,\n    replace: Option<BTreeMap<String, TomlDependency>>,\n    patch: Option<BTreeMap<String, BTreeMap<String, TomlDependency>>>,\n    workspace: Option<TomlWorkspace>,\n    badges: Option<MaybeWorkspaceBtreeMap>,\n    lints: Option<toml::Value>,\n}\n\n#[derive(Deserialize, Serialize, Clone, Debug, Default)]\npub struct TomlProfiles(BTreeMap<InternedString, TomlProfile>);\n\nimpl TomlProfiles {\n    pub fn get_all(&self) -> &BTreeMap<InternedString, TomlProfile> {\n        &self.0\n    }\n\n    pub fn get(&self, name: &str) -> Option<&TomlProfile> {\n        self.0.get(name)\n    }\n\n    /// Checks syntax validity and unstable feature gate for each profile.\n    ///\n    /// It's a bit unfortunate both `-Z` flags and `cargo-features` are required,\n    /// because profiles can now be set in either `Cargo.toml` or `config.toml`.\n    pub fn validate(\n        &self,\n        cli_unstable: &CliUnstable,\n        features: &Features,\n        warnings: &mut Vec<String>,\n    ) -> CargoResult<()> {\n        for (name, profile) in &self.0 {\n            profile.validate(name, cli_unstable, features, warnings)?;\n        }\n        Ok(())\n    }\n}\n\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct TomlOptLevel(pub String);\n\nimpl<'de> de::Deserialize<'de> for TomlOptLevel {\n    fn deserialize<D>(d: D) -> Result<TomlOptLevel, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        struct Visitor;\n\n        impl<'de> de::Visitor<'de> for Visitor {\n            type Value = TomlOptLevel;\n\n            fn expecting(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n                formatter.write_str(\"an optimization level\")\n            }\n\n            fn visit_i64<E>(self, value: i64) -> Result<TomlOptLevel, E>\n            where\n                E: de::Error,\n            {\n                Ok(TomlOptLevel(value.to_string()))\n            }\n\n            fn visit_str<E>(self, value: &str) -> Result<TomlOptLevel, E>\n            where\n                E: de::Error,\n            {\n                if value == \"s\" || value == \"z\" {\n                    Ok(TomlOptLevel(value.to_string()))\n                } else {\n                    Err(E::custom(format!(\n                        \"must be `0`, `1`, `2`, `3`, `s` or `z`, \\\n                         but found the string: \\\"{}\\\"\",\n                        value\n                    )))\n                }\n            }\n        }\n\n        d.deserialize_any(Visitor)\n    }\n}\n\nimpl ser::Serialize for TomlOptLevel {\n    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>\n    where\n        S: ser::Serializer,\n    {\n        match self.0.parse::<u32>() {\n            Ok(n) => n.serialize(serializer),\n            Err(_) => self.0.serialize(serializer),\n        }\n    }\n}\n\n#[derive(Copy, Clone, Debug, Eq, PartialEq, Hash, PartialOrd, Ord)]\npub enum TomlDebugInfo {\n    None,\n    LineDirectivesOnly,\n    LineTablesOnly,\n    Limited,\n    Full,\n}\n\nimpl ser::Serialize for TomlDebugInfo {\n    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>\n    where\n        S: ser::Serializer,\n    {\n        match self {\n            Self::None => 0.serialize(serializer),\n            Self::LineDirectivesOnly => \"line-directives-only\".serialize(serializer),\n            Self::LineTablesOnly => \"line-tables-only\".serialize(serializer),\n            Self::Limited => 1.serialize(serializer),\n            Self::Full => 2.serialize(serializer),\n        }\n    }\n}\n\nimpl<'de> de::Deserialize<'de> for TomlDebugInfo {\n    fn deserialize<D>(d: D) -> Result<TomlDebugInfo, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        struct Visitor;\n\n        impl<'de> de::Visitor<'de> for Visitor {\n            type Value = TomlDebugInfo;\n\n            fn expecting(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n                formatter.write_str(\n                    \"a boolean, 0, 1, 2, \\\"line-tables-only\\\", or \\\"line-directives-only\\\"\",\n                )\n            }\n\n            fn visit_i64<E>(self, value: i64) -> Result<TomlDebugInfo, E>\n            where\n                E: de::Error,\n            {\n                let debuginfo = match value {\n                    0 => TomlDebugInfo::None,\n                    1 => TomlDebugInfo::Limited,\n                    2 => TomlDebugInfo::Full,\n                    _ => return Err(de::Error::invalid_value(Unexpected::Signed(value), &self)),\n                };\n                Ok(debuginfo)\n            }\n\n            fn visit_bool<E>(self, v: bool) -> Result<Self::Value, E>\n            where\n                E: de::Error,\n            {\n                Ok(if v {\n                    TomlDebugInfo::Full\n                } else {\n                    TomlDebugInfo::None\n                })\n            }\n\n            fn visit_str<E>(self, value: &str) -> Result<TomlDebugInfo, E>\n            where\n                E: de::Error,\n            {\n                let debuginfo = match value {\n                    \"none\" => TomlDebugInfo::None,\n                    \"limited\" => TomlDebugInfo::Limited,\n                    \"full\" => TomlDebugInfo::Full,\n                    \"line-directives-only\" => TomlDebugInfo::LineDirectivesOnly,\n                    \"line-tables-only\" => TomlDebugInfo::LineTablesOnly,\n                    _ => return Err(de::Error::invalid_value(Unexpected::Str(value), &self)),\n                };\n                Ok(debuginfo)\n            }\n        }\n\n        d.deserialize_any(Visitor)\n    }\n}\n\nimpl Display for TomlDebugInfo {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            TomlDebugInfo::None => f.write_char('0'),\n            TomlDebugInfo::Limited => f.write_char('1'),\n            TomlDebugInfo::Full => f.write_char('2'),\n            TomlDebugInfo::LineDirectivesOnly => f.write_str(\"line-directives-only\"),\n            TomlDebugInfo::LineTablesOnly => f.write_str(\"line-tables-only\"),\n        }\n    }\n}\n\n#[derive(Deserialize, Serialize, Clone, Debug, Default, Eq, PartialEq)]\n#[serde(default, rename_all = \"kebab-case\")]\npub struct TomlProfile {\n    pub opt_level: Option<TomlOptLevel>,\n    pub lto: Option<StringOrBool>,\n    pub codegen_backend: Option<InternedString>,\n    pub codegen_units: Option<u32>,\n    pub debug: Option<TomlDebugInfo>,\n    pub split_debuginfo: Option<String>,\n    pub debug_assertions: Option<bool>,\n    pub rpath: Option<bool>,\n    pub panic: Option<String>,\n    pub overflow_checks: Option<bool>,\n    pub incremental: Option<bool>,\n    pub dir_name: Option<InternedString>,\n    pub inherits: Option<InternedString>,\n    pub strip: Option<StringOrBool>,\n    // Note that `rustflags` is used for the cargo-feature `profile_rustflags`\n    pub rustflags: Option<Vec<InternedString>>,\n    // These two fields must be last because they are sub-tables, and TOML\n    // requires all non-tables to be listed first.\n    pub package: Option<BTreeMap<ProfilePackageSpec, TomlProfile>>,\n    pub build_override: Option<Box<TomlProfile>>,\n}\n\n#[derive(Clone, Debug, PartialEq, Eq, Ord, PartialOrd, Hash)]\npub enum ProfilePackageSpec {\n    Spec(PackageIdSpec),\n    All,\n}\n\nimpl ser::Serialize for ProfilePackageSpec {\n    fn serialize<S>(&self, s: S) -> Result<S::Ok, S::Error>\n    where\n        S: ser::Serializer,\n    {\n        self.to_string().serialize(s)\n    }\n}\n\nimpl<'de> de::Deserialize<'de> for ProfilePackageSpec {\n    fn deserialize<D>(d: D) -> Result<ProfilePackageSpec, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        let string = String::deserialize(d)?;\n        if string == \"*\" {\n            Ok(ProfilePackageSpec::All)\n        } else {\n            PackageIdSpec::parse(&string)\n                .map_err(de::Error::custom)\n                .map(ProfilePackageSpec::Spec)\n        }\n    }\n}\n\nimpl fmt::Display for ProfilePackageSpec {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            ProfilePackageSpec::Spec(spec) => spec.fmt(f),\n            ProfilePackageSpec::All => f.write_str(\"*\"),\n        }\n    }\n}\n\nimpl TomlProfile {\n    /// Checks stytax validity and unstable feature gate for a given profile.\n    pub fn validate(\n        &self,\n        name: &str,\n        cli_unstable: &CliUnstable,\n        features: &Features,\n        warnings: &mut Vec<String>,\n    ) -> CargoResult<()> {\n        self.validate_profile(name, cli_unstable, features)?;\n        if let Some(ref profile) = self.build_override {\n            profile.validate_override(\"build-override\")?;\n            profile.validate_profile(&format!(\"{name}.build-override\"), cli_unstable, features)?;\n        }\n        if let Some(ref packages) = self.package {\n            for (override_name, profile) in packages {\n                profile.validate_override(\"package\")?;\n                profile.validate_profile(\n                    &format!(\"{name}.package.{override_name}\"),\n                    cli_unstable,\n                    features,\n                )?;\n            }\n        }\n\n        // Profile name validation\n        Self::validate_name(name)?;\n\n        if let Some(dir_name) = self.dir_name {\n            // This is disabled for now, as we would like to stabilize named\n            // profiles without this, and then decide in the future if it is\n            // needed. This helps simplify the UI a little.\n            bail!(\n                \"dir-name=\\\"{}\\\" in profile `{}` is not currently allowed, \\\n                 directory names are tied to the profile name for custom profiles\",\n                dir_name,\n                name\n            );\n        }\n\n        // `inherits` validation\n        if matches!(self.inherits.map(|s| s.as_str()), Some(\"debug\")) {\n            bail!(\n                \"profile.{}.inherits=\\\"debug\\\" should be profile.{}.inherits=\\\"dev\\\"\",\n                name,\n                name\n            );\n        }\n\n        match name {\n            \"doc\" => {\n                warnings.push(\"profile `doc` is deprecated and has no effect\".to_string());\n            }\n            \"test\" | \"bench\" => {\n                if self.panic.is_some() {\n                    warnings.push(format!(\"`panic` setting is ignored for `{}` profile\", name))\n                }\n            }\n            _ => {}\n        }\n\n        if let Some(panic) = &self.panic {\n            if panic != \"unwind\" && panic != \"abort\" {\n                bail!(\n                    \"`panic` setting of `{}` is not a valid setting, \\\n                     must be `unwind` or `abort`\",\n                    panic\n                );\n            }\n        }\n\n        if let Some(StringOrBool::String(arg)) = &self.lto {\n            if arg == \"true\" || arg == \"false\" {\n                bail!(\n                    \"`lto` setting of string `\\\"{arg}\\\"` for `{name}` profile is not \\\n                     a valid setting, must be a boolean (`true`/`false`) or a string \\\n                    (`\\\"thin\\\"`/`\\\"fat\\\"`/`\\\"off\\\"`) or omitted.\",\n                );\n            }\n        }\n\n        Ok(())\n    }\n\n    /// Validate dir-names and profile names according to RFC 2678.\n    pub fn validate_name(name: &str) -> CargoResult<()> {\n        if let Some(ch) = name\n            .chars()\n            .find(|ch| !ch.is_alphanumeric() && *ch != '_' && *ch != '-')\n        {\n            bail!(\n                \"invalid character `{}` in profile name `{}`\\n\\\n                Allowed characters are letters, numbers, underscore, and hyphen.\",\n                ch,\n                name\n            );\n        }\n\n        const SEE_DOCS: &str = \"See https://doc.rust-lang.org/cargo/reference/profiles.html \\\n            for more on configuring profiles.\";\n\n        let lower_name = name.to_lowercase();\n        if lower_name == \"debug\" {\n            bail!(\n                \"profile name `{}` is reserved\\n\\\n                 To configure the default development profile, use the name `dev` \\\n                 as in [profile.dev]\\n\\\n                {}\",\n                name,\n                SEE_DOCS\n            );\n        }\n        if lower_name == \"build-override\" {\n            bail!(\n                \"profile name `{}` is reserved\\n\\\n                 To configure build dependency settings, use [profile.dev.build-override] \\\n                 and [profile.release.build-override]\\n\\\n                 {}\",\n                name,\n                SEE_DOCS\n            );\n        }\n\n        // These are some arbitrary reservations. We have no plans to use\n        // these, but it seems safer to reserve a few just in case we want to\n        // add more built-in profiles in the future. We can also uses special\n        // syntax like cargo:foo if needed. But it is unlikely these will ever\n        // be used.\n        if matches!(\n            lower_name.as_str(),\n            \"build\"\n                | \"check\"\n                | \"clean\"\n                | \"config\"\n                | \"fetch\"\n                | \"fix\"\n                | \"install\"\n                | \"metadata\"\n                | \"package\"\n                | \"publish\"\n                | \"report\"\n                | \"root\"\n                | \"run\"\n                | \"rust\"\n                | \"rustc\"\n                | \"rustdoc\"\n                | \"target\"\n                | \"tmp\"\n                | \"uninstall\"\n        ) || lower_name.starts_with(\"cargo\")\n        {\n            bail!(\n                \"profile name `{}` is reserved\\n\\\n                 Please choose a different name.\\n\\\n                 {}\",\n                name,\n                SEE_DOCS\n            );\n        }\n\n        Ok(())\n    }\n\n    /// Validates a profile.\n    ///\n    /// This is a shallow check, which is reused for the profile itself and any overrides.\n    fn validate_profile(\n        &self,\n        name: &str,\n        cli_unstable: &CliUnstable,\n        features: &Features,\n    ) -> CargoResult<()> {\n        if let Some(codegen_backend) = &self.codegen_backend {\n            match (\n                features.require(Feature::codegen_backend()),\n                cli_unstable.codegen_backend,\n            ) {\n                (Err(e), false) => return Err(e),\n                _ => {}\n            }\n\n            if codegen_backend.contains(|c: char| !c.is_ascii_alphanumeric() && c != '_') {\n                bail!(\n                    \"`profile.{}.codegen-backend` setting of `{}` is not a valid backend name.\",\n                    name,\n                    codegen_backend,\n                );\n            }\n        }\n        if self.rustflags.is_some() {\n            match (\n                features.require(Feature::profile_rustflags()),\n                cli_unstable.profile_rustflags,\n            ) {\n                (Err(e), false) => return Err(e),\n                _ => {}\n            }\n        }\n        Ok(())\n    }\n\n    /// Validation that is specific to an override.\n    fn validate_override(&self, which: &str) -> CargoResult<()> {\n        if self.package.is_some() {\n            bail!(\"package-specific profiles cannot be nested\");\n        }\n        if self.build_override.is_some() {\n            bail!(\"build-override profiles cannot be nested\");\n        }\n        if self.panic.is_some() {\n            bail!(\"`panic` may not be specified in a `{}` profile\", which)\n        }\n        if self.lto.is_some() {\n            bail!(\"`lto` may not be specified in a `{}` profile\", which)\n        }\n        if self.rpath.is_some() {\n            bail!(\"`rpath` may not be specified in a `{}` profile\", which)\n        }\n        Ok(())\n    }\n\n    /// Overwrite self's values with the given profile.\n    pub fn merge(&mut self, profile: &TomlProfile) {\n        if let Some(v) = &profile.opt_level {\n            self.opt_level = Some(v.clone());\n        }\n\n        if let Some(v) = &profile.lto {\n            self.lto = Some(v.clone());\n        }\n\n        if let Some(v) = profile.codegen_backend {\n            self.codegen_backend = Some(v);\n        }\n\n        if let Some(v) = profile.codegen_units {\n            self.codegen_units = Some(v);\n        }\n\n        if let Some(v) = &profile.debug {\n            self.debug = Some(v.clone());\n        }\n\n        if let Some(v) = profile.debug_assertions {\n            self.debug_assertions = Some(v);\n        }\n\n        if let Some(v) = &profile.split_debuginfo {\n            self.split_debuginfo = Some(v.clone());\n        }\n\n        if let Some(v) = profile.rpath {\n            self.rpath = Some(v);\n        }\n\n        if let Some(v) = &profile.panic {\n            self.panic = Some(v.clone());\n        }\n\n        if let Some(v) = profile.overflow_checks {\n            self.overflow_checks = Some(v);\n        }\n\n        if let Some(v) = profile.incremental {\n            self.incremental = Some(v);\n        }\n\n        if let Some(v) = &profile.rustflags {\n            self.rustflags = Some(v.clone());\n        }\n\n        if let Some(other_package) = &profile.package {\n            match &mut self.package {\n                Some(self_package) => {\n                    for (spec, other_pkg_profile) in other_package {\n                        match self_package.get_mut(spec) {\n                            Some(p) => p.merge(other_pkg_profile),\n                            None => {\n                                self_package.insert(spec.clone(), other_pkg_profile.clone());\n                            }\n                        }\n                    }\n                }\n                None => self.package = Some(other_package.clone()),\n            }\n        }\n\n        if let Some(other_bo) = &profile.build_override {\n            match &mut self.build_override {\n                Some(self_bo) => self_bo.merge(other_bo),\n                None => self.build_override = Some(other_bo.clone()),\n            }\n        }\n\n        if let Some(v) = &profile.inherits {\n            self.inherits = Some(*v);\n        }\n\n        if let Some(v) = &profile.dir_name {\n            self.dir_name = Some(*v);\n        }\n\n        if let Some(v) = &profile.strip {\n            self.strip = Some(v.clone());\n        }\n    }\n}\n\n/// A StringOrVec can be parsed from either a TOML string or array,\n/// but is always stored as a vector.\n#[derive(Clone, Debug, Serialize, Eq, PartialEq, PartialOrd, Ord)]\npub struct StringOrVec(Vec<String>);\n\nimpl<'de> de::Deserialize<'de> for StringOrVec {\n    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        struct Visitor;\n\n        impl<'de> de::Visitor<'de> for Visitor {\n            type Value = StringOrVec;\n\n            fn expecting(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n                formatter.write_str(\"string or list of strings\")\n            }\n\n            fn visit_str<E>(self, s: &str) -> Result<Self::Value, E>\n            where\n                E: de::Error,\n            {\n                Ok(StringOrVec(vec![s.to_string()]))\n            }\n\n            fn visit_seq<V>(self, v: V) -> Result<Self::Value, V::Error>\n            where\n                V: de::SeqAccess<'de>,\n            {\n                let seq = de::value::SeqAccessDeserializer::new(v);\n                Vec::deserialize(seq).map(StringOrVec)\n            }\n        }\n\n        deserializer.deserialize_any(Visitor)\n    }\n}\n\nimpl StringOrVec {\n    pub fn iter<'a>(&'a self) -> std::slice::Iter<'a, String> {\n        self.0.iter()\n    }\n}\n\n#[derive(Clone, Debug, Deserialize, Serialize, Eq, PartialEq)]\n#[serde(untagged, expecting = \"expected a boolean or a string\")]\npub enum StringOrBool {\n    String(String),\n    Bool(bool),\n}\n\n#[derive(PartialEq, Clone, Debug, Serialize)]\n#[serde(untagged)]\npub enum VecStringOrBool {\n    VecString(Vec<String>),\n    Bool(bool),\n}\n\nimpl<'de> de::Deserialize<'de> for VecStringOrBool {\n    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        struct Visitor;\n\n        impl<'de> de::Visitor<'de> for Visitor {\n            type Value = VecStringOrBool;\n\n            fn expecting(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n                formatter.write_str(\"a boolean or vector of strings\")\n            }\n\n            fn visit_seq<V>(self, v: V) -> Result<Self::Value, V::Error>\n            where\n                V: de::SeqAccess<'de>,\n            {\n                let seq = de::value::SeqAccessDeserializer::new(v);\n                Vec::deserialize(seq).map(VecStringOrBool::VecString)\n            }\n\n            fn visit_bool<E>(self, b: bool) -> Result<Self::Value, E>\n            where\n                E: de::Error,\n            {\n                Ok(VecStringOrBool::Bool(b))\n            }\n        }\n\n        deserializer.deserialize_any(Visitor)\n    }\n}\n\nfn version_trim_whitespace<'de, D>(deserializer: D) -> Result<MaybeWorkspaceSemverVersion, D::Error>\nwhere\n    D: de::Deserializer<'de>,\n{\n    struct Visitor;\n\n    impl<'de> de::Visitor<'de> for Visitor {\n        type Value = MaybeWorkspaceSemverVersion;\n\n        fn expecting(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n            formatter.write_str(\"SemVer version\")\n        }\n\n        fn visit_str<E>(self, string: &str) -> Result<Self::Value, E>\n        where\n            E: de::Error,\n        {\n            match string.trim().parse().map_err(de::Error::custom) {\n                Ok(parsed) => Ok(MaybeWorkspace::Defined(parsed)),\n                Err(e) => Err(e),\n            }\n        }\n\n        fn visit_map<V>(self, map: V) -> Result<Self::Value, V::Error>\n        where\n            V: de::MapAccess<'de>,\n        {\n            let mvd = de::value::MapAccessDeserializer::new(map);\n            TomlWorkspaceField::deserialize(mvd).map(MaybeWorkspace::Workspace)\n        }\n    }\n\n    deserializer.deserialize_any(Visitor)\n}\n\n/// This Trait exists to make [`MaybeWorkspace::Workspace`] generic. It makes deserialization of\n/// [`MaybeWorkspace`] much easier, as well as making error messages for\n/// [`MaybeWorkspace::resolve`] much nicer\n///\n/// Implementors should have a field `workspace` with the type of `bool`. It is used to ensure\n/// `workspace` is not `false` in a `Cargo.toml`\npub trait WorkspaceInherit {\n    /// This is the workspace table that is being inherited from.\n    /// For example `[workspace.dependencies]` would be the table \"dependencies\"\n    fn inherit_toml_table(&self) -> &str;\n\n    /// This is used to output the value of the implementors `workspace` field\n    fn workspace(&self) -> bool;\n}\n\n/// An enum that allows for inheriting keys from a workspace in a Cargo.toml.\n#[derive(Serialize, Clone, Debug)]\n#[serde(untagged)]\npub enum MaybeWorkspace<T, W: WorkspaceInherit> {\n    /// The \"defined\" type, or the type that that is used when not inheriting from a workspace.\n    Defined(T),\n    /// The type when inheriting from a workspace.\n    Workspace(W),\n}\n\nimpl<T, W: WorkspaceInherit> MaybeWorkspace<T, W> {\n    fn resolve<'a>(\n        self,\n        label: &str,\n        get_ws_inheritable: impl FnOnce() -> CargoResult<T>,\n    ) -> CargoResult<T> {\n        match self {\n            MaybeWorkspace::Defined(value) => Ok(value),\n            MaybeWorkspace::Workspace(w) => get_ws_inheritable().with_context(|| {\n                format!(\n                \"error inheriting `{label}` from workspace root manifest's `workspace.{}.{label}`\",\n                w.inherit_toml_table(),\n            )\n            }),\n        }\n    }\n\n    fn resolve_with_self<'a>(\n        self,\n        label: &str,\n        get_ws_inheritable: impl FnOnce(&W) -> CargoResult<T>,\n    ) -> CargoResult<T> {\n        match self {\n            MaybeWorkspace::Defined(value) => Ok(value),\n            MaybeWorkspace::Workspace(w) => get_ws_inheritable(&w).with_context(|| {\n                format!(\n                \"error inheriting `{label}` from workspace root manifest's `workspace.{}.{label}`\",\n                w.inherit_toml_table(),\n            )\n            }),\n        }\n    }\n\n    fn as_defined(&self) -> Option<&T> {\n        match self {\n            MaybeWorkspace::Workspace(_) => None,\n            MaybeWorkspace::Defined(defined) => Some(defined),\n        }\n    }\n}\n\ntype MaybeWorkspaceDependency = MaybeWorkspace<TomlDependency, TomlWorkspaceDependency>;\n\nimpl<'de> de::Deserialize<'de> for MaybeWorkspaceDependency {\n    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        let value = serde_value::Value::deserialize(deserializer)?;\n\n        if let Ok(w) = TomlWorkspaceDependency::deserialize(serde_value::ValueDeserializer::<\n            D::Error,\n        >::new(value.clone()))\n        {\n            return if w.workspace() {\n                Ok(MaybeWorkspace::Workspace(w))\n            } else {\n                Err(de::Error::custom(\"`workspace` cannot be false\"))\n            };\n        }\n        TomlDependency::deserialize(serde_value::ValueDeserializer::<D::Error>::new(value))\n            .map(MaybeWorkspace::Defined)\n    }\n}\n\nimpl MaybeWorkspaceDependency {\n    fn unused_keys(&self) -> Vec<String> {\n        match self {\n            MaybeWorkspaceDependency::Defined(d) => d.unused_keys(),\n            MaybeWorkspaceDependency::Workspace(w) => w.other.keys().cloned().collect(),\n        }\n    }\n}\n\n#[derive(Deserialize, Serialize, Clone, Debug)]\n#[serde(rename_all = \"kebab-case\")]\npub struct TomlWorkspaceDependency {\n    workspace: bool,\n    features: Option<Vec<String>>,\n    default_features: Option<bool>,\n    #[serde(rename = \"default_features\")]\n    default_features2: Option<bool>,\n    optional: Option<bool>,\n    /// This is here to provide a way to see the \"unused manifest keys\" when deserializing\n    #[serde(skip_serializing)]\n    #[serde(flatten)]\n    other: BTreeMap<String, toml::Value>,\n}\n\nimpl WorkspaceInherit for TomlWorkspaceDependency {\n    fn inherit_toml_table(&self) -> &str {\n        \"dependencies\"\n    }\n\n    fn workspace(&self) -> bool {\n        self.workspace\n    }\n}\n\nimpl TomlWorkspaceDependency {\n    fn resolve<'a>(\n        &self,\n        name: &str,\n        inheritable: impl FnOnce() -> CargoResult<&'a InheritableFields>,\n        cx: &mut Context<'_, '_>,\n    ) -> CargoResult<TomlDependency> {\n        fn default_features_msg(label: &str, ws_def_feat: Option<bool>, cx: &mut Context<'_, '_>) {\n            let ws_def_feat = match ws_def_feat {\n                Some(true) => \"true\",\n                Some(false) => \"false\",\n                None => \"not specified\",\n            };\n            cx.warnings.push(format!(\n                \"`default-features` is ignored for {label}, since `default-features` was \\\n                {ws_def_feat} for `workspace.dependencies.{label}`, \\\n                this could become a hard error in the future\"\n            ))\n        }\n        if self.default_features.is_some() && self.default_features2.is_some() {\n            warn_on_deprecated(\"default-features\", name, \"dependency\", cx.warnings);\n        }\n        inheritable()?.get_dependency(name, cx.root).map(|d| {\n            match d {\n                TomlDependency::Simple(s) => {\n                    if let Some(false) = self.default_features.or(self.default_features2) {\n                        default_features_msg(name, None, cx);\n                    }\n                    if self.optional.is_some() || self.features.is_some() {\n                        TomlDependency::Detailed(DetailedTomlDependency {\n                            version: Some(s),\n                            optional: self.optional,\n                            features: self.features.clone(),\n                            ..Default::default()\n                        })\n                    } else {\n                        TomlDependency::Simple(s)\n                    }\n                }\n                TomlDependency::Detailed(d) => {\n                    let mut d = d.clone();\n                    match (\n                        self.default_features.or(self.default_features2),\n                        d.default_features.or(d.default_features2),\n                    ) {\n                        // member: default-features = true and\n                        // workspace: default-features = false should turn on\n                        // default-features\n                        (Some(true), Some(false)) => {\n                            d.default_features = Some(true);\n                        }\n                        // member: default-features = false and\n                        // workspace: default-features = true should ignore member\n                        // default-features\n                        (Some(false), Some(true)) => {\n                            default_features_msg(name, Some(true), cx);\n                        }\n                        // member: default-features = false and\n                        // workspace: dep = \"1.0\" should ignore member default-features\n                        (Some(false), None) => {\n                            default_features_msg(name, None, cx);\n                        }\n                        _ => {}\n                    }\n                    d.add_features(self.features.clone());\n                    d.update_optional(self.optional);\n                    TomlDependency::Detailed(d)\n                }\n            }\n        })\n    }\n}\n\n//. This already has a `Deserialize` impl from version_trim_whitespace\ntype MaybeWorkspaceSemverVersion = MaybeWorkspace<semver::Version, TomlWorkspaceField>;\n\ntype MaybeWorkspaceString = MaybeWorkspace<String, TomlWorkspaceField>;\nimpl<'de> de::Deserialize<'de> for MaybeWorkspaceString {\n    fn deserialize<D>(d: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        struct Visitor;\n\n        impl<'de> de::Visitor<'de> for Visitor {\n            type Value = MaybeWorkspaceString;\n\n            fn expecting(&self, f: &mut fmt::Formatter<'_>) -> Result<(), std::fmt::Error> {\n                f.write_str(\"a string or workspace\")\n            }\n\n            fn visit_string<E>(self, value: String) -> Result<Self::Value, E>\n            where\n                E: de::Error,\n            {\n                Ok(MaybeWorkspaceString::Defined(value))\n            }\n\n            fn visit_map<V>(self, map: V) -> Result<Self::Value, V::Error>\n            where\n                V: de::MapAccess<'de>,\n            {\n                let mvd = de::value::MapAccessDeserializer::new(map);\n                TomlWorkspaceField::deserialize(mvd).map(MaybeWorkspace::Workspace)\n            }\n        }\n\n        d.deserialize_any(Visitor)\n    }\n}\n\ntype MaybeWorkspaceVecString = MaybeWorkspace<Vec<String>, TomlWorkspaceField>;\nimpl<'de> de::Deserialize<'de> for MaybeWorkspaceVecString {\n    fn deserialize<D>(d: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        struct Visitor;\n\n        impl<'de> de::Visitor<'de> for Visitor {\n            type Value = MaybeWorkspaceVecString;\n\n            fn expecting(&self, f: &mut fmt::Formatter<'_>) -> Result<(), fmt::Error> {\n                f.write_str(\"a vector of strings or workspace\")\n            }\n            fn visit_seq<A>(self, v: A) -> Result<Self::Value, A::Error>\n            where\n                A: de::SeqAccess<'de>,\n            {\n                let seq = de::value::SeqAccessDeserializer::new(v);\n                Vec::deserialize(seq).map(MaybeWorkspace::Defined)\n            }\n\n            fn visit_map<V>(self, map: V) -> Result<Self::Value, V::Error>\n            where\n                V: de::MapAccess<'de>,\n            {\n                let mvd = de::value::MapAccessDeserializer::new(map);\n                TomlWorkspaceField::deserialize(mvd).map(MaybeWorkspace::Workspace)\n            }\n        }\n\n        d.deserialize_any(Visitor)\n    }\n}\n\ntype MaybeWorkspaceStringOrBool = MaybeWorkspace<StringOrBool, TomlWorkspaceField>;\nimpl<'de> de::Deserialize<'de> for MaybeWorkspaceStringOrBool {\n    fn deserialize<D>(d: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        struct Visitor;\n\n        impl<'de> de::Visitor<'de> for Visitor {\n            type Value = MaybeWorkspaceStringOrBool;\n\n            fn expecting(&self, f: &mut fmt::Formatter<'_>) -> Result<(), fmt::Error> {\n                f.write_str(\"a string, a bool, or workspace\")\n            }\n\n            fn visit_bool<E>(self, v: bool) -> Result<Self::Value, E>\n            where\n                E: de::Error,\n            {\n                let b = de::value::BoolDeserializer::new(v);\n                StringOrBool::deserialize(b).map(MaybeWorkspace::Defined)\n            }\n\n            fn visit_string<E>(self, v: String) -> Result<Self::Value, E>\n            where\n                E: de::Error,\n            {\n                let string = de::value::StringDeserializer::new(v);\n                StringOrBool::deserialize(string).map(MaybeWorkspace::Defined)\n            }\n\n            fn visit_map<V>(self, map: V) -> Result<Self::Value, V::Error>\n            where\n                V: de::MapAccess<'de>,\n            {\n                let mvd = de::value::MapAccessDeserializer::new(map);\n                TomlWorkspaceField::deserialize(mvd).map(MaybeWorkspace::Workspace)\n            }\n        }\n\n        d.deserialize_any(Visitor)\n    }\n}\n\ntype MaybeWorkspaceVecStringOrBool = MaybeWorkspace<VecStringOrBool, TomlWorkspaceField>;\nimpl<'de> de::Deserialize<'de> for MaybeWorkspaceVecStringOrBool {\n    fn deserialize<D>(d: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        struct Visitor;\n\n        impl<'de> de::Visitor<'de> for Visitor {\n            type Value = MaybeWorkspaceVecStringOrBool;\n\n            fn expecting(&self, f: &mut fmt::Formatter<'_>) -> Result<(), fmt::Error> {\n                f.write_str(\"a boolean, a vector of strings, or workspace\")\n            }\n\n            fn visit_bool<E>(self, v: bool) -> Result<Self::Value, E>\n            where\n                E: de::Error,\n            {\n                let b = de::value::BoolDeserializer::new(v);\n                VecStringOrBool::deserialize(b).map(MaybeWorkspace::Defined)\n            }\n\n            fn visit_seq<A>(self, v: A) -> Result<Self::Value, A::Error>\n            where\n                A: de::SeqAccess<'de>,\n            {\n                let seq = de::value::SeqAccessDeserializer::new(v);\n                VecStringOrBool::deserialize(seq).map(MaybeWorkspace::Defined)\n            }\n\n            fn visit_map<V>(self, map: V) -> Result<Self::Value, V::Error>\n            where\n                V: de::MapAccess<'de>,\n            {\n                let mvd = de::value::MapAccessDeserializer::new(map);\n                TomlWorkspaceField::deserialize(mvd).map(MaybeWorkspace::Workspace)\n            }\n        }\n\n        d.deserialize_any(Visitor)\n    }\n}\n\ntype MaybeWorkspaceBtreeMap =\n    MaybeWorkspace<BTreeMap<String, BTreeMap<String, String>>, TomlWorkspaceField>;\n\nimpl<'de> de::Deserialize<'de> for MaybeWorkspaceBtreeMap {\n    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        let value = serde_value::Value::deserialize(deserializer)?;\n\n        if let Ok(w) = TomlWorkspaceField::deserialize(\n            serde_value::ValueDeserializer::<D::Error>::new(value.clone()),\n        ) {\n            return if w.workspace() {\n                Ok(MaybeWorkspace::Workspace(w))\n            } else {\n                Err(de::Error::custom(\"`workspace` cannot be false\"))\n            };\n        }\n        BTreeMap::deserialize(serde_value::ValueDeserializer::<D::Error>::new(value))\n            .map(MaybeWorkspace::Defined)\n    }\n}\n\ntype MaybeWorkspaceLints = MaybeWorkspace<TomlLints, TomlWorkspaceField>;\n\nimpl<'de> de::Deserialize<'de> for MaybeWorkspaceLints {\n    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        let value = serde_value::Value::deserialize(deserializer)?;\n\n        if let Ok(w) = TomlWorkspaceField::deserialize(\n            serde_value::ValueDeserializer::<D::Error>::new(value.clone()),\n        ) {\n            return if w.workspace() {\n                Ok(MaybeWorkspace::Workspace(w))\n            } else {\n                Err(de::Error::custom(\"`workspace` cannot be false\"))\n            };\n        }\n        TomlLints::deserialize(serde_value::ValueDeserializer::<D::Error>::new(value))\n            .map(MaybeWorkspace::Defined)\n    }\n}\n\n#[derive(Deserialize, Serialize, Clone, Debug)]\npub struct TomlWorkspaceField {\n    #[serde(deserialize_with = \"bool_no_false\")]\n    workspace: bool,\n}\n\nfn bool_no_false<'de, D: de::Deserializer<'de>>(deserializer: D) -> Result<bool, D::Error> {\n    let b: bool = Deserialize::deserialize(deserializer)?;\n    if b {\n        Ok(b)\n    } else {\n        Err(de::Error::custom(\"`workspace` cannot be false\"))\n    }\n}\n\nimpl WorkspaceInherit for TomlWorkspaceField {\n    fn inherit_toml_table(&self) -> &str {\n        \"package\"\n    }\n\n    fn workspace(&self) -> bool {\n        self.workspace\n    }\n}\n\n/// Represents the `package`/`project` sections of a `Cargo.toml`.\n///\n/// Note that the order of the fields matters, since this is the order they\n/// are serialized to a TOML file. For example, you cannot have values after\n/// the field `metadata`, since it is a table and values cannot appear after\n/// tables.\n#[derive(Deserialize, Serialize, Clone, Debug)]\n#[serde(rename_all = \"kebab-case\")]\npub struct TomlPackage {\n    edition: Option<MaybeWorkspaceString>,\n    rust_version: Option<MaybeWorkspaceString>,\n    name: InternedString,\n    #[serde(deserialize_with = \"version_trim_whitespace\")]\n    version: MaybeWorkspaceSemverVersion,\n    authors: Option<MaybeWorkspaceVecString>,\n    build: Option<StringOrBool>,\n    metabuild: Option<StringOrVec>,\n    #[serde(rename = \"default-target\")]\n    default_target: Option<String>,\n    #[serde(rename = \"forced-target\")]\n    forced_target: Option<String>,\n    links: Option<String>,\n    exclude: Option<MaybeWorkspaceVecString>,\n    include: Option<MaybeWorkspaceVecString>,\n    publish: Option<MaybeWorkspaceVecStringOrBool>,\n    workspace: Option<String>,\n    im_a_teapot: Option<bool>,\n    autobins: Option<bool>,\n    autoexamples: Option<bool>,\n    autotests: Option<bool>,\n    autobenches: Option<bool>,\n    default_run: Option<String>,\n\n    // Package metadata.\n    description: Option<MaybeWorkspaceString>,\n    homepage: Option<MaybeWorkspaceString>,\n    documentation: Option<MaybeWorkspaceString>,\n    readme: Option<MaybeWorkspaceStringOrBool>,\n    keywords: Option<MaybeWorkspaceVecString>,\n    categories: Option<MaybeWorkspaceVecString>,\n    license: Option<MaybeWorkspaceString>,\n    license_file: Option<MaybeWorkspaceString>,\n    repository: Option<MaybeWorkspaceString>,\n    resolver: Option<String>,\n\n    // Note that this field must come last due to the way toml serialization\n    // works which requires tables to be emitted after all values.\n    metadata: Option<toml::Value>,\n}\n\n#[derive(Debug, Deserialize, Serialize, Clone)]\npub struct TomlWorkspace {\n    members: Option<Vec<String>>,\n    #[serde(rename = \"default-members\")]\n    default_members: Option<Vec<String>>,\n    exclude: Option<Vec<String>>,\n    resolver: Option<String>,\n\n    // Properties that can be inherited by members.\n    package: Option<InheritableFields>,\n    dependencies: Option<BTreeMap<String, TomlDependency>>,\n    lints: Option<toml::Value>,\n\n    // Note that this field must come last due to the way toml serialization\n    // works which requires tables to be emitted after all values.\n    metadata: Option<toml::Value>,\n}\n\n/// A group of fields that are inheritable by members of the workspace\n#[derive(Clone, Debug, Default, Deserialize, Serialize)]\npub struct InheritableFields {\n    // We use skip here since it will never be present when deserializing\n    // and we don't want it present when serializing\n    #[serde(skip)]\n    dependencies: Option<BTreeMap<String, TomlDependency>>,\n    #[serde(skip)]\n    lints: Option<TomlLints>,\n\n    version: Option<semver::Version>,\n    authors: Option<Vec<String>>,\n    description: Option<String>,\n    homepage: Option<String>,\n    documentation: Option<String>,\n    readme: Option<StringOrBool>,\n    keywords: Option<Vec<String>>,\n    categories: Option<Vec<String>>,\n    license: Option<String>,\n    #[serde(rename = \"license-file\")]\n    license_file: Option<String>,\n    repository: Option<String>,\n    publish: Option<VecStringOrBool>,\n    edition: Option<String>,\n    badges: Option<BTreeMap<String, BTreeMap<String, String>>>,\n    exclude: Option<Vec<String>>,\n    include: Option<Vec<String>>,\n    #[serde(rename = \"rust-version\")]\n    rust_version: Option<String>,\n    // We use skip here since it will never be present when deserializing\n    // and we don't want it present when serializing\n    #[serde(skip)]\n    ws_root: PathBuf,\n}\n\nimpl InheritableFields {\n    pub fn update_deps(&mut self, deps: Option<BTreeMap<String, TomlDependency>>) {\n        self.dependencies = deps;\n    }\n\n    pub fn update_lints(&mut self, lints: Option<TomlLints>) {\n        self.lints = lints;\n    }\n\n    pub fn update_ws_path(&mut self, ws_root: PathBuf) {\n        self.ws_root = ws_root;\n    }\n\n    pub fn dependencies(&self) -> CargoResult<BTreeMap<String, TomlDependency>> {\n        self.dependencies.clone().map_or(\n            Err(anyhow!(\"`workspace.dependencies` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn lints(&self) -> CargoResult<TomlLints> {\n        self.lints\n            .clone()\n            .map_or(Err(anyhow!(\"`workspace.lints` was not defined\")), |d| Ok(d))\n    }\n\n    pub fn get_dependency(&self, name: &str, package_root: &Path) -> CargoResult<TomlDependency> {\n        self.dependencies.clone().map_or(\n            Err(anyhow!(\"`workspace.dependencies` was not defined\")),\n            |deps| {\n                deps.get(name).map_or(\n                    Err(anyhow!(\n                        \"`dependency.{}` was not found in `workspace.dependencies`\",\n                        name\n                    )),\n                    |dep| {\n                        let mut dep = dep.clone();\n                        if let TomlDependency::Detailed(detailed) = &mut dep {\n                            detailed.resolve_path(name, self.ws_root(), package_root)?\n                        }\n                        Ok(dep)\n                    },\n                )\n            },\n        )\n    }\n\n    pub fn version(&self) -> CargoResult<semver::Version> {\n        self.version.clone().map_or(\n            Err(anyhow!(\"`workspace.package.version` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn authors(&self) -> CargoResult<Vec<String>> {\n        self.authors.clone().map_or(\n            Err(anyhow!(\"`workspace.package.authors` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn description(&self) -> CargoResult<String> {\n        self.description.clone().map_or(\n            Err(anyhow!(\"`workspace.package.description` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn homepage(&self) -> CargoResult<String> {\n        self.homepage.clone().map_or(\n            Err(anyhow!(\"`workspace.package.homepage` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn documentation(&self) -> CargoResult<String> {\n        self.documentation.clone().map_or(\n            Err(anyhow!(\"`workspace.package.documentation` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn readme(&self, package_root: &Path) -> CargoResult<StringOrBool> {\n        readme_for_package(self.ws_root.as_path(), self.readme.clone()).map_or(\n            Err(anyhow!(\"`workspace.package.readme` was not defined\")),\n            |readme| {\n                let rel_path =\n                    resolve_relative_path(\"readme\", &self.ws_root, package_root, &readme)?;\n                Ok(StringOrBool::String(rel_path))\n            },\n        )\n    }\n\n    pub fn keywords(&self) -> CargoResult<Vec<String>> {\n        self.keywords.clone().map_or(\n            Err(anyhow!(\"`workspace.package.keywords` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn categories(&self) -> CargoResult<Vec<String>> {\n        self.categories.clone().map_or(\n            Err(anyhow!(\"`workspace.package.categories` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn license(&self) -> CargoResult<String> {\n        self.license.clone().map_or(\n            Err(anyhow!(\"`workspace.package.license` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn license_file(&self, package_root: &Path) -> CargoResult<String> {\n        self.license_file.clone().map_or(\n            Err(anyhow!(\"`workspace.package.license_file` was not defined\")),\n            |d| resolve_relative_path(\"license-file\", &self.ws_root, package_root, &d),\n        )\n    }\n\n    pub fn repository(&self) -> CargoResult<String> {\n        self.repository.clone().map_or(\n            Err(anyhow!(\"`workspace.package.repository` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn publish(&self) -> CargoResult<VecStringOrBool> {\n        self.publish.clone().map_or(\n            Err(anyhow!(\"`workspace.package.publish` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn edition(&self) -> CargoResult<String> {\n        self.edition.clone().map_or(\n            Err(anyhow!(\"`workspace.package.edition` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn rust_version(&self) -> CargoResult<String> {\n        self.rust_version.clone().map_or(\n            Err(anyhow!(\"`workspace.package.rust-version` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn badges(&self) -> CargoResult<BTreeMap<String, BTreeMap<String, String>>> {\n        self.badges.clone().map_or(\n            Err(anyhow!(\"`workspace.package.badges` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn exclude(&self) -> CargoResult<Vec<String>> {\n        self.exclude.clone().map_or(\n            Err(anyhow!(\"`workspace.package.exclude` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn include(&self) -> CargoResult<Vec<String>> {\n        self.include.clone().map_or(\n            Err(anyhow!(\"`workspace.package.include` was not defined\")),\n            |d| Ok(d),\n        )\n    }\n\n    pub fn ws_root(&self) -> &PathBuf {\n        &self.ws_root\n    }\n}\n\nimpl TomlPackage {\n    pub fn to_package_id(\n        &self,\n        source_id: SourceId,\n        version: semver::Version,\n    ) -> CargoResult<PackageId> {\n        PackageId::new(self.name, version, source_id)\n    }\n}\n\nstruct Context<'a, 'b> {\n    deps: &'a mut Vec<Dependency>,\n    source_id: SourceId,\n    nested_paths: &'a mut Vec<PathBuf>,\n    config: &'b Config,\n    warnings: &'a mut Vec<String>,\n    platform: Option<Platform>,\n    root: &'a Path,\n    features: &'a Features,\n}\n\nimpl TomlManifest {\n    /// Prepares the manifest for publishing.\n    // - Path and git components of dependency specifications are removed.\n    // - License path is updated to point within the package.\n    pub fn prepare_for_publish(\n        &self,\n        ws: &Workspace<'_>,\n        package_root: &Path,\n    ) -> CargoResult<TomlManifest> {\n        let config = ws.config();\n        let mut package = self\n            .package\n            .as_ref()\n            .or_else(|| self.project.as_ref())\n            .unwrap()\n            .clone();\n        package.workspace = None;\n        let current_resolver = package\n            .resolver\n            .as_ref()\n            .map(|r| ResolveBehavior::from_manifest(r))\n            .unwrap_or_else(|| {\n                package\n                    .edition\n                    .as_ref()\n                    .and_then(|e| e.as_defined())\n                    .map(|e| Edition::from_str(e))\n                    .unwrap_or(Ok(Edition::Edition2015))\n                    .map(|e| e.default_resolve_behavior())\n            })?;\n        if ws.resolve_behavior() != current_resolver {\n            // This ensures the published crate if built as a root (e.g. `cargo install`) will\n            // use the same resolver behavior it was tested with in the workspace.\n            // To avoid forcing a higher MSRV we don't explicitly set this if it would implicitly\n            // result in the same thing.\n            package.resolver = Some(ws.resolve_behavior().to_manifest());\n        }\n        if let Some(license_file) = &package.license_file {\n            let license_file = license_file\n                .as_defined()\n                .context(\"license file should have been resolved before `prepare_for_publish()`\")?;\n            let license_path = Path::new(&license_file);\n            let abs_license_path = paths::normalize_path(&package_root.join(license_path));\n            if abs_license_path.strip_prefix(package_root).is_err() {\n                // This path points outside of the package root. `cargo package`\n                // will copy it into the root, so adjust the path to this location.\n                package.license_file = Some(MaybeWorkspace::Defined(\n                    license_path\n                        .file_name()\n                        .unwrap()\n                        .to_str()\n                        .unwrap()\n                        .to_string(),\n                ));\n            }\n        }\n\n        if let Some(readme) = &package.readme {\n            let readme = readme\n                .as_defined()\n                .context(\"readme should have been resolved before `prepare_for_publish()`\")?;\n            match readme {\n                StringOrBool::String(readme) => {\n                    let readme_path = Path::new(&readme);\n                    let abs_readme_path = paths::normalize_path(&package_root.join(readme_path));\n                    if abs_readme_path.strip_prefix(package_root).is_err() {\n                        // This path points outside of the package root. `cargo package`\n                        // will copy it into the root, so adjust the path to this location.\n                        package.readme = Some(MaybeWorkspace::Defined(StringOrBool::String(\n                            readme_path\n                                .file_name()\n                                .unwrap()\n                                .to_str()\n                                .unwrap()\n                                .to_string(),\n                        )));\n                    }\n                }\n                StringOrBool::Bool(_) => {}\n            }\n        }\n        let all = |_d: &TomlDependency| true;\n        return Ok(TomlManifest {\n            package: Some(package),\n            project: None,\n            profile: self.profile.clone(),\n            lib: self.lib.clone(),\n            bin: self.bin.clone(),\n            example: self.example.clone(),\n            test: self.test.clone(),\n            bench: self.bench.clone(),\n            dependencies: map_deps(config, self.dependencies.as_ref(), all)?,\n            dev_dependencies: map_deps(\n                config,\n                self.dev_dependencies\n                    .as_ref()\n                    .or_else(|| self.dev_dependencies2.as_ref()),\n                TomlDependency::is_version_specified,\n            )?,\n            dev_dependencies2: None,\n            build_dependencies: map_deps(\n                config,\n                self.build_dependencies\n                    .as_ref()\n                    .or_else(|| self.build_dependencies2.as_ref()),\n                all,\n            )?,\n            build_dependencies2: None,\n            features: self.features.clone(),\n            target: match self.target.as_ref().map(|target_map| {\n                target_map\n                    .iter()\n                    .map(|(k, v)| {\n                        Ok((\n                            k.clone(),\n                            TomlPlatform {\n                                dependencies: map_deps(config, v.dependencies.as_ref(), all)?,\n                                dev_dependencies: map_deps(\n                                    config,\n                                    v.dev_dependencies\n                                        .as_ref()\n                                        .or_else(|| v.dev_dependencies2.as_ref()),\n                                    TomlDependency::is_version_specified,\n                                )?,\n                                dev_dependencies2: None,\n                                build_dependencies: map_deps(\n                                    config,\n                                    v.build_dependencies\n                                        .as_ref()\n                                        .or_else(|| v.build_dependencies2.as_ref()),\n                                    all,\n                                )?,\n                                build_dependencies2: None,\n                            },\n                        ))\n                    })\n                    .collect()\n            }) {\n                Some(Ok(v)) => Some(v),\n                Some(Err(e)) => return Err(e),\n                None => None,\n            },\n            replace: None,\n            patch: None,\n            workspace: None,\n            badges: self.badges.clone(),\n            cargo_features: self.cargo_features.clone(),\n            lints: self.lints.clone(),\n        });\n\n        fn map_deps(\n            config: &Config,\n            deps: Option<&BTreeMap<String, MaybeWorkspaceDependency>>,\n            filter: impl Fn(&TomlDependency) -> bool,\n        ) -> CargoResult<Option<BTreeMap<String, MaybeWorkspaceDependency>>> {\n            let deps = match deps {\n                Some(deps) => deps,\n                None => return Ok(None),\n            };\n            let deps = deps\n                .iter()\n                .filter(|(_k, v)| {\n                    if let MaybeWorkspace::Defined(def) = v {\n                        filter(def)\n                    } else {\n                        false\n                    }\n                })\n                .map(|(k, v)| Ok((k.clone(), map_dependency(config, v)?)))\n                .collect::<CargoResult<BTreeMap<_, _>>>()?;\n            Ok(Some(deps))\n        }\n\n        fn map_dependency(\n            config: &Config,\n            dep: &MaybeWorkspaceDependency,\n        ) -> CargoResult<MaybeWorkspaceDependency> {\n            let dep = match dep {\n                MaybeWorkspace::Defined(TomlDependency::Detailed(d)) => {\n                    let mut d = d.clone();\n                    // Path dependencies become crates.io deps.\n                    d.path.take();\n                    // Same with git dependencies.\n                    d.git.take();\n                    d.branch.take();\n                    d.tag.take();\n                    d.rev.take();\n                    // registry specifications are elaborated to the index URL\n                    if let Some(registry) = d.registry.take() {\n                        d.registry_index = Some(config.get_registry_index(&registry)?.to_string());\n                    }\n                    Ok(d)\n                }\n                MaybeWorkspace::Defined(TomlDependency::Simple(s)) => Ok(DetailedTomlDependency {\n                    version: Some(s.clone()),\n                    ..Default::default()\n                }),\n                _ => unreachable!(),\n            };\n            dep.map(TomlDependency::Detailed)\n                .map(MaybeWorkspace::Defined)\n        }\n    }\n\n    pub fn to_real_manifest(\n        me: &Rc<TomlManifest>,\n        embedded: bool,\n        source_id: SourceId,\n        package_root: &Path,\n        config: &Config,\n    ) -> CargoResult<(Manifest, Vec<PathBuf>)> {\n        fn get_ws(\n            config: &Config,\n            resolved_path: &Path,\n            workspace_config: &WorkspaceConfig,\n        ) -> CargoResult<InheritableFields> {\n            match workspace_config {\n                WorkspaceConfig::Root(root) => Ok(root.inheritable().clone()),\n                WorkspaceConfig::Member {\n                    root: Some(ref path_to_root),\n                } => {\n                    let path = resolved_path\n                        .parent()\n                        .unwrap()\n                        .join(path_to_root)\n                        .join(\"Cargo.toml\");\n                    let root_path = paths::normalize_path(&path);\n                    inheritable_from_path(config, root_path)\n                }\n                WorkspaceConfig::Member { root: None } => {\n                    match find_workspace_root(&resolved_path, config)? {\n                        Some(path_to_root) => inheritable_from_path(config, path_to_root),\n                        None => Err(anyhow!(\"failed to find a workspace root\")),\n                    }\n                }\n            }\n        }\n\n        let mut nested_paths = vec![];\n        let mut warnings = vec![];\n        let mut errors = vec![];\n\n        // Parse features first so they will be available when parsing other parts of the TOML.\n        let empty = Vec::new();\n        let cargo_features = me.cargo_features.as_ref().unwrap_or(&empty);\n        let features = Features::new(cargo_features, config, &mut warnings, source_id.is_path())?;\n\n        let mut package = match (&me.package, &me.project) {\n            (Some(_), Some(project)) => {\n                if source_id.is_path() {\n                    config.shell().warn(format!(\n                        \"manifest at `{}` contains both `project` and `package`, \\\n                    this could become a hard error in the future\",\n                        package_root.display()\n                    ))?;\n                }\n                project.clone()\n            }\n            (Some(package), None) => package.clone(),\n            (None, Some(project)) => {\n                if source_id.is_path() {\n                    config.shell().warn(format!(\n                        \"manifest at `{}` contains `[project]` instead of `[package]`, \\\n                                this could become a hard error in the future\",\n                        package_root.display()\n                    ))?;\n                }\n                project.clone()\n            }\n            (None, None) => bail!(\"no `package` section found\"),\n        };\n\n        let workspace_config = match (me.workspace.as_ref(), package.workspace.as_ref()) {\n            (Some(toml_config), None) => {\n                let mut inheritable = toml_config.package.clone().unwrap_or_default();\n                inheritable.update_ws_path(package_root.to_path_buf());\n                inheritable.update_deps(toml_config.dependencies.clone());\n                let lints = parse_unstable_lints(toml_config.lints.clone(), config, &mut warnings)?;\n                let lints = verify_lints(lints)?;\n                inheritable.update_lints(lints);\n                if let Some(ws_deps) = &inheritable.dependencies {\n                    for (name, dep) in ws_deps {\n                        unused_dep_keys(\n                            name,\n                            \"workspace.dependencies\",\n                            dep.unused_keys(),\n                            &mut warnings,\n                        );\n                    }\n                }\n                let ws_root_config = WorkspaceRootConfig::new(\n                    package_root,\n                    &toml_config.members,\n                    &toml_config.default_members,\n                    &toml_config.exclude,\n                    &Some(inheritable),\n                    &toml_config.metadata,\n                );\n                config\n                    .ws_roots\n                    .borrow_mut()\n                    .insert(package_root.to_path_buf(), ws_root_config.clone());\n                WorkspaceConfig::Root(ws_root_config)\n            }\n            (None, root) => WorkspaceConfig::Member {\n                root: root.cloned(),\n            },\n            (Some(..), Some(..)) => bail!(\n                \"cannot configure both `package.workspace` and \\\n                 `[workspace]`, only one can be specified\"\n            ),\n        };\n\n        let package_name = package.name.trim();\n        if package_name.is_empty() {\n            bail!(\"package name cannot be an empty string\")\n        }\n\n        validate_package_name(package_name, \"package name\", \"\")?;\n\n        let resolved_path = package_root.join(\"Cargo.toml\");\n\n        let inherit_cell: LazyCell<InheritableFields> = LazyCell::new();\n        let inherit =\n            || inherit_cell.try_borrow_with(|| get_ws(config, &resolved_path, &workspace_config));\n\n        let version = package\n            .version\n            .clone()\n            .resolve(\"version\", || inherit()?.version())?;\n\n        package.version = MaybeWorkspace::Defined(version.clone());\n\n        let pkgid = package.to_package_id(source_id, version)?;\n\n        let edition = if let Some(edition) = package.edition.clone() {\n            let edition: Edition = edition\n                .resolve(\"edition\", || inherit()?.edition())?\n                .parse()\n                .with_context(|| \"failed to parse the `edition` key\")?;\n            package.edition = Some(MaybeWorkspace::Defined(edition.to_string()));\n            edition\n        } else {\n            Edition::Edition2015\n        };\n        // Add these lines if start a new unstable edition.\n        // ```\n        // if edition == Edition::Edition20xx {\n        //     features.require(Feature::edition20xx))?;\n        // }\n        // ```\n        if !edition.is_stable() {\n            // Guard in case someone forgets to add .require()\n            return Err(util::errors::internal(format!(\n                \"edition {} should be gated\",\n                edition\n            )));\n        }\n\n        let rust_version = if let Some(rust_version) = &package.rust_version {\n            let rust_version = rust_version\n                .clone()\n                .resolve(\"rust_version\", || inherit()?.rust_version())?;\n            let req = match semver::VersionReq::parse(&rust_version) {\n                // Exclude semver operators like `^` and pre-release identifiers\n                Ok(req) if rust_version.chars().all(|c| c.is_ascii_digit() || c == '.') => req,\n                _ => bail!(\"`rust-version` must be a value like \\\"1.32\\\"\"),\n            };\n            if let Some(first_version) = edition.first_version() {\n                let unsupported =\n                    semver::Version::new(first_version.major, first_version.minor - 1, 9999);\n                if req.matches(&unsupported) {\n                    bail!(\n                        \"rust-version {} is older than first version ({}) required by \\\n                            the specified edition ({})\",\n                        rust_version,\n                        first_version,\n                        edition,\n                    )\n                }\n            }\n            Some(rust_version.clone())\n        } else {\n            None\n        };\n\n        if package.metabuild.is_some() {\n            features.require(Feature::metabuild())?;\n        }\n\n        let resolve_behavior = match (\n            package.resolver.as_ref(),\n            me.workspace.as_ref().and_then(|ws| ws.resolver.as_ref()),\n        ) {\n            (None, None) => None,\n            (Some(s), None) | (None, Some(s)) => Some(ResolveBehavior::from_manifest(s)?),\n            (Some(_), Some(_)) => {\n                bail!(\"cannot specify `resolver` field in both `[workspace]` and `[package]`\")\n            }\n        };\n\n        // If we have no lib at all, use the inferred lib, if available.\n        // If we have a lib with a path, we're done.\n        // If we have a lib with no path, use the inferred lib or else the package name.\n        let targets = targets(\n            &features,\n            me,\n            package_name,\n            package_root,\n            edition,\n            &package.build,\n            &package.metabuild,\n            &mut warnings,\n            &mut errors,\n        )?;\n\n        if targets.is_empty() {\n            debug!(\"manifest has no build targets\");\n        }\n\n        if let Err(conflict_targets) = unique_build_targets(&targets, package_root) {\n            conflict_targets\n                .iter()\n                .for_each(|(target_path, conflicts)| {\n                    warnings.push(format!(\n                        \"file `{}` found to be present in multiple \\\n                 build targets:\\n{}\",\n                        target_path.display().to_string(),\n                        conflicts\n                            .iter()\n                            .map(|t| format!(\n                                \"  * `{}` target `{}`\",\n                                t.kind().description(),\n                                t.name(),\n                            ))\n                            .join(\"\\n\")\n                    ));\n                })\n        }\n\n        if let Some(links) = &package.links {\n            if !targets.iter().any(|t| t.is_custom_build()) {\n                bail!(\n                    \"package `{}` specifies that it links to `{}` but does not \\\n                     have a custom build script\",\n                    pkgid,\n                    links\n                )\n            }\n        }\n\n        let mut deps = Vec::new();\n\n        let mut cx = Context {\n            deps: &mut deps,\n            source_id,\n            nested_paths: &mut nested_paths,\n            config,\n            warnings: &mut warnings,\n            features: &features,\n            platform: None,\n            root: package_root,\n        };\n\n        fn process_dependencies(\n            cx: &mut Context<'_, '_>,\n            new_deps: Option<&BTreeMap<String, MaybeWorkspaceDependency>>,\n            kind: Option<DepKind>,\n            workspace_config: &WorkspaceConfig,\n            inherit_cell: &LazyCell<InheritableFields>,\n        ) -> CargoResult<Option<BTreeMap<String, MaybeWorkspaceDependency>>> {\n            let dependencies = match new_deps {\n                Some(dependencies) => dependencies,\n                None => return Ok(None),\n            };\n\n            let inheritable = || {\n                inherit_cell.try_borrow_with(|| {\n                    get_ws(cx.config, &cx.root.join(\"Cargo.toml\"), &workspace_config)\n                })\n            };\n\n            let mut deps: BTreeMap<String, MaybeWorkspaceDependency> = BTreeMap::new();\n            for (n, v) in dependencies.iter() {\n                let resolved = v\n                    .clone()\n                    .resolve_with_self(n, |dep| dep.resolve(n, inheritable, cx))?;\n                let dep = resolved.to_dependency(n, cx, kind)?;\n                let name_in_toml = dep.name_in_toml().as_str();\n                validate_package_name(name_in_toml, \"dependency name\", \"\")?;\n                let kind_name = match kind {\n                    Some(k) => k.kind_table(),\n                    None => \"dependencies\",\n                };\n                let table_in_toml = if let Some(platform) = &cx.platform {\n                    format!(\"target.{}.{kind_name}\", platform.to_string())\n                } else {\n                    kind_name.to_string()\n                };\n                unused_dep_keys(name_in_toml, &table_in_toml, v.unused_keys(), cx.warnings);\n                cx.deps.push(dep);\n                deps.insert(n.to_string(), MaybeWorkspace::Defined(resolved.clone()));\n            }\n            Ok(Some(deps))\n        }\n\n        // Collect the dependencies.\n        let dependencies = process_dependencies(\n            &mut cx,\n            me.dependencies.as_ref(),\n            None,\n            &workspace_config,\n            &inherit_cell,\n        )?;\n        if me.dev_dependencies.is_some() && me.dev_dependencies2.is_some() {\n            warn_on_deprecated(\"dev-dependencies\", package_name, \"package\", cx.warnings);\n        }\n        let dev_deps = me\n            .dev_dependencies\n            .as_ref()\n            .or_else(|| me.dev_dependencies2.as_ref());\n        let dev_deps = process_dependencies(\n            &mut cx,\n            dev_deps,\n            Some(DepKind::Development),\n            &workspace_config,\n            &inherit_cell,\n        )?;\n        if me.build_dependencies.is_some() && me.build_dependencies2.is_some() {\n            warn_on_deprecated(\"build-dependencies\", package_name, \"package\", cx.warnings);\n        }\n        let build_deps = me\n            .build_dependencies\n            .as_ref()\n            .or_else(|| me.build_dependencies2.as_ref());\n        let build_deps = process_dependencies(\n            &mut cx,\n            build_deps,\n            Some(DepKind::Build),\n            &workspace_config,\n            &inherit_cell,\n        )?;\n\n        let lints =\n            parse_unstable_lints::<MaybeWorkspaceLints>(me.lints.clone(), config, cx.warnings)?\n                .map(|mw| mw.resolve(\"lints\", || inherit()?.lints()))\n                .transpose()?;\n        let lints = verify_lints(lints)?;\n        let default = TomlLints::default();\n        let rustflags = lints_to_rustflags(lints.as_ref().unwrap_or(&default));\n\n        let mut target: BTreeMap<String, TomlPlatform> = BTreeMap::new();\n        for (name, platform) in me.target.iter().flatten() {\n            cx.platform = {\n                let platform: Platform = name.parse()?;\n                platform.check_cfg_attributes(cx.warnings);\n                Some(platform)\n            };\n            let deps = process_dependencies(\n                &mut cx,\n                platform.dependencies.as_ref(),\n                None,\n                &workspace_config,\n                &inherit_cell,\n            )?;\n            if platform.build_dependencies.is_some() && platform.build_dependencies2.is_some() {\n                warn_on_deprecated(\"build-dependencies\", name, \"platform target\", cx.warnings);\n            }\n            let build_deps = platform\n                .build_dependencies\n                .as_ref()\n                .or_else(|| platform.build_dependencies2.as_ref());\n            let build_deps = process_dependencies(\n                &mut cx,\n                build_deps,\n                Some(DepKind::Build),\n                &workspace_config,\n                &inherit_cell,\n            )?;\n            if platform.dev_dependencies.is_some() && platform.dev_dependencies2.is_some() {\n                warn_on_deprecated(\"dev-dependencies\", name, \"platform target\", cx.warnings);\n            }\n            let dev_deps = platform\n                .dev_dependencies\n                .as_ref()\n                .or_else(|| platform.dev_dependencies2.as_ref());\n            let dev_deps = process_dependencies(\n                &mut cx,\n                dev_deps,\n                Some(DepKind::Development),\n                &workspace_config,\n                &inherit_cell,\n            )?;\n            target.insert(\n                name.clone(),\n                TomlPlatform {\n                    dependencies: deps,\n                    build_dependencies: build_deps,\n                    build_dependencies2: None,\n                    dev_dependencies: dev_deps,\n                    dev_dependencies2: None,\n                },\n            );\n        }\n\n        let target = if target.is_empty() {\n            None\n        } else {\n            Some(target)\n        };\n        let replace = me.replace(&mut cx)?;\n        let patch = me.patch(&mut cx)?;\n\n        {\n            let mut names_sources = BTreeMap::new();\n            for dep in &deps {\n                let name = dep.name_in_toml();\n                let prev = names_sources.insert(name.to_string(), dep.source_id());\n                if prev.is_some() && prev != Some(dep.source_id()) {\n                    bail!(\n                        \"Dependency '{}' has different source paths depending on the build \\\n                         target. Each dependency must have a single canonical source path \\\n                         irrespective of build target.\",\n                        name\n                    );\n                }\n            }\n        }\n\n        let exclude = package\n            .exclude\n            .clone()\n            .map(|mw| mw.resolve(\"exclude\", || inherit()?.exclude()))\n            .transpose()?\n            .unwrap_or_default();\n        let include = package\n            .include\n            .clone()\n            .map(|mw| mw.resolve(\"include\", || inherit()?.include()))\n            .transpose()?\n            .unwrap_or_default();\n        let empty_features = BTreeMap::new();\n\n        let summary = Summary::new(\n            pkgid,\n            deps,\n            me.features.as_ref().unwrap_or(&empty_features),\n            package.links.as_deref(),\n            rust_version.as_deref().map(InternedString::new),\n        )?;\n\n        let metadata = ManifestMetadata {\n            description: package\n                .description\n                .clone()\n                .map(|mw| mw.resolve(\"description\", || inherit()?.description()))\n                .transpose()?,\n            homepage: package\n                .homepage\n                .clone()\n                .map(|mw| mw.resolve(\"homepage\", || inherit()?.homepage()))\n                .transpose()?,\n            documentation: package\n                .documentation\n                .clone()\n                .map(|mw| mw.resolve(\"documentation\", || inherit()?.documentation()))\n                .transpose()?,\n            readme: readme_for_package(\n                package_root,\n                package\n                    .readme\n                    .clone()\n                    .map(|mw| mw.resolve(\"readme\", || inherit()?.readme(package_root)))\n                    .transpose()?,\n            ),\n            authors: package\n                .authors\n                .clone()\n                .map(|mw| mw.resolve(\"authors\", || inherit()?.authors()))\n                .transpose()?\n                .unwrap_or_default(),\n            license: package\n                .license\n                .clone()\n                .map(|mw| mw.resolve(\"license\", || inherit()?.license()))\n                .transpose()?,\n            license_file: package\n                .license_file\n                .clone()\n                .map(|mw| mw.resolve(\"license\", || inherit()?.license_file(package_root)))\n                .transpose()?,\n            repository: package\n                .repository\n                .clone()\n                .map(|mw| mw.resolve(\"repository\", || inherit()?.repository()))\n                .transpose()?,\n            keywords: package\n                .keywords\n                .clone()\n                .map(|mw| mw.resolve(\"keywords\", || inherit()?.keywords()))\n                .transpose()?\n                .unwrap_or_default(),\n            categories: package\n                .categories\n                .clone()\n                .map(|mw| mw.resolve(\"categories\", || inherit()?.categories()))\n                .transpose()?\n                .unwrap_or_default(),\n            badges: me\n                .badges\n                .clone()\n                .map(|mw| mw.resolve(\"badges\", || inherit()?.badges()))\n                .transpose()?\n                .unwrap_or_default(),\n            links: package.links.clone(),\n            rust_version: package\n                .rust_version\n                .clone()\n                .map(|mw| mw.resolve(\"rust-version\", || inherit()?.rust_version()))\n                .transpose()?,\n        };\n        package.description = metadata\n            .description\n            .clone()\n            .map(|description| MaybeWorkspace::Defined(description));\n        package.homepage = metadata\n            .homepage\n            .clone()\n            .map(|homepage| MaybeWorkspace::Defined(homepage));\n        package.documentation = metadata\n            .documentation\n            .clone()\n            .map(|documentation| MaybeWorkspace::Defined(documentation));\n        package.readme = metadata\n            .readme\n            .clone()\n            .map(|readme| MaybeWorkspace::Defined(StringOrBool::String(readme)));\n        package.authors = package\n            .authors\n            .as_ref()\n            .map(|_| MaybeWorkspace::Defined(metadata.authors.clone()));\n        package.license = metadata\n            .license\n            .clone()\n            .map(|license| MaybeWorkspace::Defined(license));\n        package.license_file = metadata\n            .license_file\n            .clone()\n            .map(|license_file| MaybeWorkspace::Defined(license_file));\n        package.repository = metadata\n            .repository\n            .clone()\n            .map(|repository| MaybeWorkspace::Defined(repository));\n        package.keywords = package\n            .keywords\n            .as_ref()\n            .map(|_| MaybeWorkspace::Defined(metadata.keywords.clone()));\n        package.categories = package\n            .categories\n            .as_ref()\n            .map(|_| MaybeWorkspace::Defined(metadata.categories.clone()));\n        package.rust_version = rust_version.clone().map(|rv| MaybeWorkspace::Defined(rv));\n        package.exclude = package\n            .exclude\n            .as_ref()\n            .map(|_| MaybeWorkspace::Defined(exclude.clone()));\n        package.include = package\n            .include\n            .as_ref()\n            .map(|_| MaybeWorkspace::Defined(include.clone()));\n\n        let profiles = me.profile.clone();\n        if let Some(profiles) = &profiles {\n            let cli_unstable = config.cli_unstable();\n            profiles.validate(cli_unstable, &features, &mut warnings)?;\n        }\n\n        let publish = package\n            .publish\n            .clone()\n            .map(|publish| publish.resolve(\"publish\", || inherit()?.publish()).unwrap());\n\n        package.publish = publish.clone().map(|p| MaybeWorkspace::Defined(p));\n\n        let publish = match publish {\n            Some(VecStringOrBool::VecString(ref vecstring)) => Some(vecstring.clone()),\n            Some(VecStringOrBool::Bool(false)) => Some(vec![]),\n            None | Some(VecStringOrBool::Bool(true)) => None,\n        };\n\n        if summary.features().contains_key(\"default-features\") {\n            warnings.push(\n                \"`default-features = [\\\"..\\\"]` was found in [features]. \\\n                 Did you mean to use `default = [\\\"..\\\"]`?\"\n                    .to_string(),\n            )\n        }\n\n        if let Some(run) = &package.default_run {\n            if !targets\n                .iter()\n                .filter(|t| t.is_bin())\n                .any(|t| t.name() == run)\n            {\n                let suggestion =\n                    util::closest_msg(run, targets.iter().filter(|t| t.is_bin()), |t| t.name());\n                bail!(\"default-run target `{}` not found{}\", run, suggestion);\n            }\n        }\n\n        let default_kind = package\n            .default_target\n            .as_ref()\n            .map(|t| CompileTarget::new(&*t))\n            .transpose()?\n            .map(CompileKind::Target);\n        let forced_kind = package\n            .forced_target\n            .as_ref()\n            .map(|t| CompileTarget::new(&*t))\n            .transpose()?\n            .map(CompileKind::Target);\n        let custom_metadata = package.metadata.clone();\n        let resolved_toml = TomlManifest {\n            cargo_features: me.cargo_features.clone(),\n            package: Some(package.clone()),\n            project: None,\n            profile: me.profile.clone(),\n            lib: me.lib.clone(),\n            bin: me.bin.clone(),\n            example: me.example.clone(),\n            test: me.test.clone(),\n            bench: me.bench.clone(),\n            dependencies,\n            dev_dependencies: dev_deps,\n            dev_dependencies2: None,\n            build_dependencies: build_deps,\n            build_dependencies2: None,\n            features: me.features.clone(),\n            target,\n            replace: me.replace.clone(),\n            patch: me.patch.clone(),\n            workspace: me.workspace.clone(),\n            badges: me\n                .badges\n                .as_ref()\n                .map(|_| MaybeWorkspace::Defined(metadata.badges.clone())),\n            lints: lints\n                .map(|lints| toml::Value::try_from(MaybeWorkspaceLints::Defined(lints)).unwrap()),\n        };\n        let mut manifest = Manifest::new(\n            summary,\n            default_kind,\n            forced_kind,\n            targets,\n            exclude,\n            include,\n            package.links.clone(),\n            metadata,\n            custom_metadata,\n            profiles,\n            publish,\n            replace,\n            patch,\n            workspace_config,\n            features,\n            edition,\n            rust_version,\n            package.im_a_teapot,\n            package.default_run.clone(),\n            Rc::new(resolved_toml),\n            package.metabuild.clone().map(|sov| sov.0),\n            resolve_behavior,\n            rustflags,\n            embedded,\n        );\n        if package.license_file.is_some() && package.license.is_some() {\n            manifest.warnings_mut().add_warning(\n                \"only one of `license` or `license-file` is necessary\\n\\\n                 `license` should be used if the package license can be expressed \\\n                 with a standard SPDX expression.\\n\\\n                 `license-file` should be used if the package uses a non-standard license.\\n\\\n                 See https://doc.rust-lang.org/cargo/reference/manifest.html#the-license-and-license-file-fields \\\n                 for more information.\"\n                    .to_string(),\n            );\n        }\n        for warning in warnings {\n            manifest.warnings_mut().add_warning(warning);\n        }\n        for error in errors {\n            manifest.warnings_mut().add_critical_warning(error);\n        }\n\n        manifest.feature_gate()?;\n\n        Ok((manifest, nested_paths))\n    }\n\n    fn to_virtual_manifest(\n        me: &Rc<TomlManifest>,\n        source_id: SourceId,\n        root: &Path,\n        config: &Config,\n    ) -> CargoResult<(VirtualManifest, Vec<PathBuf>)> {\n        if me.project.is_some() {\n            bail!(\"this virtual manifest specifies a [project] section, which is not allowed\");\n        }\n        if me.package.is_some() {\n            bail!(\"this virtual manifest specifies a [package] section, which is not allowed\");\n        }\n        if me.lib.is_some() {\n            bail!(\"this virtual manifest specifies a [lib] section, which is not allowed\");\n        }\n        if me.bin.is_some() {\n            bail!(\"this virtual manifest specifies a [[bin]] section, which is not allowed\");\n        }\n        if me.example.is_some() {\n            bail!(\"this virtual manifest specifies a [[example]] section, which is not allowed\");\n        }\n        if me.test.is_some() {\n            bail!(\"this virtual manifest specifies a [[test]] section, which is not allowed\");\n        }\n        if me.bench.is_some() {\n            bail!(\"this virtual manifest specifies a [[bench]] section, which is not allowed\");\n        }\n        if me.dependencies.is_some() {\n            bail!(\"this virtual manifest specifies a [dependencies] section, which is not allowed\");\n        }\n        if me.dev_dependencies.is_some() || me.dev_dependencies2.is_some() {\n            bail!(\"this virtual manifest specifies a [dev-dependencies] section, which is not allowed\");\n        }\n        if me.build_dependencies.is_some() || me.build_dependencies2.is_some() {\n            bail!(\"this virtual manifest specifies a [build-dependencies] section, which is not allowed\");\n        }\n        if me.features.is_some() {\n            bail!(\"this virtual manifest specifies a [features] section, which is not allowed\");\n        }\n        if me.target.is_some() {\n            bail!(\"this virtual manifest specifies a [target] section, which is not allowed\");\n        }\n        if me.badges.is_some() {\n            bail!(\"this virtual manifest specifies a [badges] section, which is not allowed\");\n        }\n\n        let mut nested_paths = Vec::new();\n        let mut warnings = Vec::new();\n        let mut deps = Vec::new();\n        let empty = Vec::new();\n        let cargo_features = me.cargo_features.as_ref().unwrap_or(&empty);\n        let features = Features::new(cargo_features, config, &mut warnings, source_id.is_path())?;\n\n        let (replace, patch) = {\n            let mut cx = Context {\n                deps: &mut deps,\n                source_id,\n                nested_paths: &mut nested_paths,\n                config,\n                warnings: &mut warnings,\n                platform: None,\n                features: &features,\n                root,\n            };\n            (me.replace(&mut cx)?, me.patch(&mut cx)?)\n        };\n        let profiles = me.profile.clone();\n        if let Some(profiles) = &profiles {\n            profiles.validate(config.cli_unstable(), &features, &mut warnings)?;\n        }\n        let resolve_behavior = me\n            .workspace\n            .as_ref()\n            .and_then(|ws| ws.resolver.as_deref())\n            .map(|r| ResolveBehavior::from_manifest(r))\n            .transpose()?;\n        let workspace_config = match me.workspace {\n            Some(ref toml_config) => {\n                let mut inheritable = toml_config.package.clone().unwrap_or_default();\n                inheritable.update_ws_path(root.to_path_buf());\n                inheritable.update_deps(toml_config.dependencies.clone());\n                let lints = parse_unstable_lints(toml_config.lints.clone(), config, &mut warnings)?;\n                let lints = verify_lints(lints)?;\n                inheritable.update_lints(lints);\n                let ws_root_config = WorkspaceRootConfig::new(\n                    root,\n                    &toml_config.members,\n                    &toml_config.default_members,\n                    &toml_config.exclude,\n                    &Some(inheritable),\n                    &toml_config.metadata,\n                );\n                config\n                    .ws_roots\n                    .borrow_mut()\n                    .insert(root.to_path_buf(), ws_root_config.clone());\n                WorkspaceConfig::Root(ws_root_config)\n            }\n            None => {\n                bail!(\"virtual manifests must be configured with [workspace]\");\n            }\n        };\n        Ok((\n            VirtualManifest::new(\n                replace,\n                patch,\n                workspace_config,\n                profiles,\n                features,\n                resolve_behavior,\n            ),\n            nested_paths,\n        ))\n    }\n\n    fn replace(&self, cx: &mut Context<'_, '_>) -> CargoResult<Vec<(PackageIdSpec, Dependency)>> {\n        if self.patch.is_some() && self.replace.is_some() {\n            bail!(\"cannot specify both [replace] and [patch]\");\n        }\n        let mut replace = Vec::new();\n        for (spec, replacement) in self.replace.iter().flatten() {\n            let mut spec = PackageIdSpec::parse(spec).with_context(|| {\n                format!(\n                    \"replacements must specify a valid semver \\\n                     version to replace, but `{}` does not\",\n                    spec\n                )\n            })?;\n            if spec.url().is_none() {\n                spec.set_url(CRATES_IO_INDEX.parse().unwrap());\n            }\n\n            if replacement.is_version_specified() {\n                bail!(\n                    \"replacements cannot specify a version \\\n                     requirement, but found one for `{}`\",\n                    spec\n                );\n            }\n\n            let mut dep = replacement.to_dependency(spec.name().as_str(), cx, None)?;\n            let version = spec.version().ok_or_else(|| {\n                anyhow!(\n                    \"replacements must specify a version \\\n                     to replace, but `{}` does not\",\n                    spec\n                )\n            })?;\n            unused_dep_keys(\n                dep.name_in_toml().as_str(),\n                \"replace\",\n                replacement.unused_keys(),\n                &mut cx.warnings,\n            );\n            dep.set_version_req(VersionReq::exact(version))\n                .lock_version(version);\n            replace.push((spec, dep));\n        }\n        Ok(replace)\n    }\n\n    fn patch(&self, cx: &mut Context<'_, '_>) -> CargoResult<HashMap<Url, Vec<Dependency>>> {\n        let mut patch = HashMap::new();\n        for (toml_url, deps) in self.patch.iter().flatten() {\n            let url = match &toml_url[..] {\n                CRATES_IO_REGISTRY => CRATES_IO_INDEX.parse().unwrap(),\n                _ => cx\n                    .config\n                    .get_registry_index(toml_url)\n                    .or_else(|_| toml_url.into_url())\n                    .with_context(|| {\n                        format!(\n                            \"[patch] entry `{}` should be a URL or registry name\",\n                            toml_url\n                        )\n                    })?,\n            };\n            patch.insert(\n                url,\n                deps.iter()\n                    .map(|(name, dep)| {\n                        unused_dep_keys(\n                            name,\n                            &format!(\"patch.{toml_url}\",),\n                            dep.unused_keys(),\n                            &mut cx.warnings,\n                        );\n                        dep.to_dependency(name, cx, None)\n                    })\n                    .collect::<CargoResult<Vec<_>>>()?,\n            );\n        }\n        Ok(patch)\n    }\n\n    /// Returns the path to the build script if one exists for this crate.\n    fn maybe_custom_build(\n        &self,\n        build: &Option<StringOrBool>,\n        package_root: &Path,\n    ) -> Option<PathBuf> {\n        let build_rs = package_root.join(\"build.rs\");\n        match *build {\n            // Explicitly no build script.\n            Some(StringOrBool::Bool(false)) => None,\n            Some(StringOrBool::Bool(true)) => Some(build_rs),\n            Some(StringOrBool::String(ref s)) => Some(PathBuf::from(s)),\n            None => {\n                // If there is a `build.rs` file next to the `Cargo.toml`, assume it is\n                // a build script.\n                if build_rs.is_file() {\n                    Some(build_rs)\n                } else {\n                    None\n                }\n            }\n        }\n    }\n\n    pub fn has_profiles(&self) -> bool {\n        self.profile.is_some()\n    }\n\n    pub fn features(&self) -> Option<&BTreeMap<InternedString, Vec<InternedString>>> {\n        self.features.as_ref()\n    }\n}\n\nfn parse_unstable_lints<T: Deserialize<'static>>(\n    lints: Option<toml::Value>,\n    config: &Config,\n    warnings: &mut Vec<String>,\n) -> CargoResult<Option<T>> {\n    let Some(lints) = lints else { return Ok(None); };\n\n    if !config.cli_unstable().lints {\n        warn_for_lint_feature(config, warnings);\n        return Ok(None);\n    }\n\n    lints.try_into().map(Some).map_err(|err| err.into())\n}\n\nfn warn_for_lint_feature(config: &Config, warnings: &mut Vec<String>) {\n    use std::fmt::Write as _;\n\n    let key_name = \"lints\";\n    let feature_name = \"lints\";\n\n    let mut message = String::new();\n\n    let _ = write!(\n        message,\n        \"unused manifest key `{key_name}` (may be supported in a future version)\"\n    );\n    if config.nightly_features_allowed {\n        let _ = write!(\n            message,\n            \"\n\nconsider passing `-Z{feature_name}` to enable this feature.\"\n        );\n    } else {\n        let _ = write!(\n            message,\n            \"\n\nthis Cargo does not support nightly features, but if you\nswitch to nightly channel you can pass\n`-Z{feature_name}` to enable this feature.\",\n        );\n    }\n    warnings.push(message);\n}\n\nfn verify_lints(lints: Option<TomlLints>) -> CargoResult<Option<TomlLints>> {\n    let Some(lints) = lints else { return Ok(None); };\n\n    for (tool, lints) in &lints {\n        let supported = [\"rust\", \"clippy\", \"rustdoc\"];\n        if !supported.contains(&tool.as_str()) {\n            let supported = supported.join(\", \");\n            anyhow::bail!(\"unsupported `{tool}` in `[lints]`, must be one of {supported}\")\n        }\n        for name in lints.keys() {\n            if let Some((prefix, suffix)) = name.split_once(\"::\") {\n                if tool == prefix {\n                    anyhow::bail!(\n                        \"`lints.{tool}.{name}` is not valid lint name; try `lints.{prefix}.{suffix}`\"\n                    )\n                } else if tool == \"rust\" && supported.contains(&prefix) {\n                    anyhow::bail!(\n                        \"`lints.{tool}.{name}` is not valid lint name; try `lints.{prefix}.{suffix}`\"\n                    )\n                } else {\n                    anyhow::bail!(\"`lints.{tool}.{name}` is not a valid lint name\")\n                }\n            }\n        }\n    }\n\n    Ok(Some(lints))\n}\n\nfn lints_to_rustflags(lints: &TomlLints) -> Vec<String> {\n    let mut rustflags = lints\n        .iter()\n        .flat_map(|(tool, lints)| {\n            lints.iter().map(move |(name, config)| {\n                let flag = config.level().flag();\n                let option = if tool == \"rust\" {\n                    format!(\"{flag}={name}\")\n                } else {\n                    format!(\"{flag}={tool}::{name}\")\n                };\n                (\n                    config.priority(),\n                    // Since the most common group will be `all`, put it last so people are more\n                    // likely to notice that they need to use `priority`.\n                    std::cmp::Reverse(name),\n                    option,\n                )\n            })\n        })\n        .collect::<Vec<_>>();\n    rustflags.sort();\n    rustflags.into_iter().map(|(_, _, option)| option).collect()\n}\n\nfn unused_dep_keys(\n    dep_name: &str,\n    kind: &str,\n    unused_keys: Vec<String>,\n    warnings: &mut Vec<String>,\n) {\n    for unused in unused_keys {\n        let key = format!(\"unused manifest key: {kind}.{dep_name}.{unused}\");\n        warnings.push(key);\n    }\n}\n\nfn inheritable_from_path(\n    config: &Config,\n    workspace_path: PathBuf,\n) -> CargoResult<InheritableFields> {\n    // Workspace path should have Cargo.toml at the end\n    let workspace_path_root = workspace_path.parent().unwrap();\n\n    // Let the borrow exit scope so that it can be picked up if there is a need to\n    // read a manifest\n    if let Some(ws_root) = config.ws_roots.borrow().get(workspace_path_root) {\n        return Ok(ws_root.inheritable().clone());\n    };\n\n    let source_id = SourceId::for_path(workspace_path_root)?;\n    let (man, _) = read_manifest(&workspace_path, source_id, config)?;\n    match man.workspace_config() {\n        WorkspaceConfig::Root(root) => {\n            config\n                .ws_roots\n                .borrow_mut()\n                .insert(workspace_path, root.clone());\n            Ok(root.inheritable().clone())\n        }\n        _ => bail!(\n            \"root of a workspace inferred but wasn't a root: {}\",\n            workspace_path.display()\n        ),\n    }\n}\n\n/// Returns the name of the README file for a [`TomlPackage`].\npub fn readme_for_package(package_root: &Path, readme: Option<StringOrBool>) -> Option<String> {\n    match &readme {\n        None => default_readme_from_package_root(package_root),\n        Some(value) => match value {\n            StringOrBool::Bool(false) => None,\n            StringOrBool::Bool(true) => Some(\"README.md\".to_string()),\n            StringOrBool::String(v) => Some(v.clone()),\n        },\n    }\n}\n\nconst DEFAULT_README_FILES: [&str; 3] = [\"README.md\", \"README.txt\", \"README\"];\n\n/// Checks if a file with any of the default README file names exists in the package root.\n/// If so, returns a `String` representing that name.\nfn default_readme_from_package_root(package_root: &Path) -> Option<String> {\n    for &readme_filename in DEFAULT_README_FILES.iter() {\n        if package_root.join(readme_filename).is_file() {\n            return Some(readme_filename.to_string());\n        }\n    }\n\n    None\n}\n\n/// Checks a list of build targets, and ensures the target names are unique within a vector.\n/// If not, the name of the offending build target is returned.\nfn unique_build_targets(\n    targets: &[Target],\n    package_root: &Path,\n) -> Result<(), HashMap<PathBuf, Vec<Target>>> {\n    let mut source_targets = HashMap::<_, Vec<_>>::new();\n    for target in targets {\n        if let TargetSourcePath::Path(path) = target.src_path() {\n            let full = package_root.join(path);\n            source_targets.entry(full).or_default().push(target.clone());\n        }\n    }\n\n    let conflict_targets = source_targets\n        .into_iter()\n        .filter(|(_, targets)| targets.len() > 1)\n        .collect::<HashMap<_, _>>();\n\n    if !conflict_targets.is_empty() {\n        return Err(conflict_targets);\n    }\n\n    Ok(())\n}\n\nimpl<P: ResolveToPath + Clone> TomlDependency<P> {\n    pub(crate) fn to_dependency_split(\n        &self,\n        name: &str,\n        source_id: SourceId,\n        nested_paths: &mut Vec<PathBuf>,\n        config: &Config,\n        warnings: &mut Vec<String>,\n        platform: Option<Platform>,\n        root: &Path,\n        features: &Features,\n        kind: Option<DepKind>,\n    ) -> CargoResult<Dependency> {\n        self.to_dependency(\n            name,\n            &mut Context {\n                deps: &mut Vec::new(),\n                source_id,\n                nested_paths,\n                config,\n                warnings,\n                platform,\n                root,\n                features,\n            },\n            kind,\n        )\n    }\n\n    fn to_dependency(\n        &self,\n        name: &str,\n        cx: &mut Context<'_, '_>,\n        kind: Option<DepKind>,\n    ) -> CargoResult<Dependency> {\n        match *self {\n            TomlDependency::Simple(ref version) => DetailedTomlDependency::<P> {\n                version: Some(version.clone()),\n                ..Default::default()\n            }\n            .to_dependency(name, cx, kind),\n            TomlDependency::Detailed(ref details) => details.to_dependency(name, cx, kind),\n        }\n    }\n\n    fn is_version_specified(&self) -> bool {\n        match self {\n            TomlDependency::Detailed(d) => d.version.is_some(),\n            TomlDependency::Simple(..) => true,\n        }\n    }\n\n    fn is_optional(&self) -> bool {\n        match self {\n            TomlDependency::Detailed(d) => d.optional.unwrap_or(false),\n            TomlDependency::Simple(..) => false,\n        }\n    }\n}\n\nimpl<P: ResolveToPath + Clone> DetailedTomlDependency<P> {\n    fn to_dependency(\n        &self,\n        name_in_toml: &str,\n        cx: &mut Context<'_, '_>,\n        kind: Option<DepKind>,\n    ) -> CargoResult<Dependency> {\n        if self.version.is_none() && self.path.is_none() && self.git.is_none() {\n            let msg = format!(\n                \"dependency ({}) specified without \\\n                 providing a local path, Git repository, version, or \\\n                 workspace dependency to use. This will be considered an \\\n                 error in future versions\",\n                name_in_toml\n            );\n            cx.warnings.push(msg);\n        }\n\n        if let Some(version) = &self.version {\n            if version.contains('+') {\n                cx.warnings.push(format!(\n                    \"version requirement `{}` for dependency `{}` \\\n                     includes semver metadata which will be ignored, removing the \\\n                     metadata is recommended to avoid confusion\",\n                    version, name_in_toml\n                ));\n            }\n        }\n\n        if self.git.is_none() {\n            let git_only_keys = [\n                (&self.branch, \"branch\"),\n                (&self.tag, \"tag\"),\n                (&self.rev, \"rev\"),\n            ];\n\n            for &(key, key_name) in &git_only_keys {\n                if key.is_some() {\n                    bail!(\n                        \"key `{}` is ignored for dependency ({}).\",\n                        key_name,\n                        name_in_toml\n                    );\n                }\n            }\n        }\n\n        // Early detection of potentially misused feature syntax\n        // instead of generating a \"feature not found\" error.\n        if let Some(features) = &self.features {\n            for feature in features {\n                if feature.contains('/') {\n                    bail!(\n                        \"feature `{}` in dependency `{}` is not allowed to contain slashes\\n\\\n                         If you want to enable features of a transitive dependency, \\\n                         the direct dependency needs to re-export those features from \\\n                         the `[features]` table.\",\n                        feature,\n                        name_in_toml\n                    );\n                }\n                if feature.starts_with(\"dep:\") {\n                    bail!(\n                        \"feature `{}` in dependency `{}` is not allowed to use explicit \\\n                        `dep:` syntax\\n\\\n                         If you want to enable an optional dependency, specify the name \\\n                         of the optional dependency without the `dep:` prefix, or specify \\\n                         a feature from the dependency's `[features]` table that enables \\\n                         the optional dependency.\",\n                        feature,\n                        name_in_toml\n                    );\n                }\n            }\n        }\n\n        let new_source_id = match (\n            self.git.as_ref(),\n            self.path.as_ref(),\n            self.registry.as_ref(),\n            self.registry_index.as_ref(),\n        ) {\n            (Some(_), _, Some(_), _) | (Some(_), _, _, Some(_)) => bail!(\n                \"dependency ({}) specification is ambiguous. \\\n                 Only one of `git` or `registry` is allowed.\",\n                name_in_toml\n            ),\n            (_, _, Some(_), Some(_)) => bail!(\n                \"dependency ({}) specification is ambiguous. \\\n                 Only one of `registry` or `registry-index` is allowed.\",\n                name_in_toml\n            ),\n            (Some(git), maybe_path, _, _) => {\n                if maybe_path.is_some() {\n                    bail!(\n                        \"dependency ({}) specification is ambiguous. \\\n                         Only one of `git` or `path` is allowed.\",\n                        name_in_toml\n                    );\n                }\n\n                let n_details = [&self.branch, &self.tag, &self.rev]\n                    .iter()\n                    .filter(|d| d.is_some())\n                    .count();\n\n                if n_details > 1 {\n                    bail!(\n                        \"dependency ({}) specification is ambiguous. \\\n                         Only one of `branch`, `tag` or `rev` is allowed.\",\n                        name_in_toml\n                    );\n                }\n\n                let reference = self\n                    .branch\n                    .clone()\n                    .map(GitReference::Branch)\n                    .or_else(|| self.tag.clone().map(GitReference::Tag))\n                    .or_else(|| self.rev.clone().map(GitReference::Rev))\n                    .unwrap_or(GitReference::DefaultBranch);\n                let loc = git.into_url()?;\n\n                if let Some(fragment) = loc.fragment() {\n                    let msg = format!(\n                        \"URL fragment `#{}` in git URL is ignored for dependency ({}). \\\n                        If you were trying to specify a specific git revision, \\\n                        use `rev = \\\"{}\\\"` in the dependency declaration.\",\n                        fragment, name_in_toml, fragment\n                    );\n                    cx.warnings.push(msg)\n                }\n\n                SourceId::for_git(&loc, reference)?\n            }\n            (None, Some(path), _, _) => {\n                let path = path.resolve(cx.config);\n                cx.nested_paths.push(path.clone());\n                // If the source ID for the package we're parsing is a path\n                // source, then we normalize the path here to get rid of\n                // components like `..`.\n                //\n                // The purpose of this is to get a canonical ID for the package\n                // that we're depending on to ensure that builds of this package\n                // always end up hashing to the same value no matter where it's\n                // built from.\n                if cx.source_id.is_path() {\n                    let path = cx.root.join(path);\n                    let path = paths::normalize_path(&path);\n                    SourceId::for_path(&path)?\n                } else {\n                    cx.source_id\n                }\n            }\n            (None, None, Some(registry), None) => SourceId::alt_registry(cx.config, registry)?,\n            (None, None, None, Some(registry_index)) => {\n                let url = registry_index.into_url()?;\n                SourceId::for_registry(&url)?\n            }\n            (None, None, None, None) => SourceId::crates_io(cx.config)?,\n        };\n\n        let (pkg_name, explicit_name_in_toml) = match self.package {\n            Some(ref s) => (&s[..], Some(name_in_toml)),\n            None => (name_in_toml, None),\n        };\n\n        let version = self.version.as_deref();\n        let mut dep = Dependency::parse(pkg_name, version, new_source_id)?;\n        if self.default_features.is_some() && self.default_features2.is_some() {\n            warn_on_deprecated(\"default-features\", name_in_toml, \"dependency\", cx.warnings);\n        }\n        dep.set_features(self.features.iter().flatten())\n            .set_default_features(\n                self.default_features\n                    .or(self.default_features2)\n                    .unwrap_or(true),\n            )\n            .set_optional(self.optional.unwrap_or(false))\n            .set_platform(cx.platform.clone());\n        if let Some(registry) = &self.registry {\n            let registry_id = SourceId::alt_registry(cx.config, registry)?;\n            dep.set_registry_id(registry_id);\n        }\n        if let Some(registry_index) = &self.registry_index {\n            let url = registry_index.into_url()?;\n            let registry_id = SourceId::for_registry(&url)?;\n            dep.set_registry_id(registry_id);\n        }\n\n        if let Some(kind) = kind {\n            dep.set_kind(kind);\n        }\n        if let Some(name_in_toml) = explicit_name_in_toml {\n            dep.set_explicit_name_in_toml(name_in_toml);\n        }\n\n        if let Some(p) = self.public {\n            cx.features.require(Feature::public_dependency())?;\n\n            if dep.kind() != DepKind::Normal {\n                bail!(\"'public' specifier can only be used on regular dependencies, not {:?} dependencies\", dep.kind());\n            }\n\n            dep.set_public(p);\n        }\n\n        if let (Some(artifact), is_lib, target) = (\n            self.artifact.as_ref(),\n            self.lib.unwrap_or(false),\n            self.target.as_deref(),\n        ) {\n            if cx.config.cli_unstable().bindeps {\n                let artifact = Artifact::parse(artifact, is_lib, target)?;\n                if dep.kind() != DepKind::Build\n                    && artifact.target() == Some(ArtifactTarget::BuildDependencyAssumeTarget)\n                {\n                    bail!(\n                        r#\"`target = \"target\"` in normal- or dev-dependencies has no effect ({})\"#,\n                        name_in_toml\n                    );\n                }\n                dep.set_artifact(artifact)\n            } else {\n                bail!(\"`artifact = \u2026` requires `-Z bindeps` ({})\", name_in_toml);\n            }\n        } else if self.lib.is_some() || self.target.is_some() {\n            for (is_set, specifier) in [\n                (self.lib.is_some(), \"lib\"),\n                (self.target.is_some(), \"target\"),\n            ] {\n                if !is_set {\n                    continue;\n                }\n                bail!(\n                    \"'{}' specifier cannot be used without an 'artifact = \u2026' value ({})\",\n                    specifier,\n                    name_in_toml\n                )\n            }\n        }\n        Ok(dep)\n    }\n}\n\nimpl DetailedTomlDependency {\n    fn add_features(&mut self, features: Option<Vec<String>>) {\n        self.features = match (self.features.clone(), features.clone()) {\n            (Some(dep_feat), Some(inherit_feat)) => Some(\n                dep_feat\n                    .into_iter()\n                    .chain(inherit_feat)\n                    .collect::<Vec<String>>(),\n            ),\n            (Some(dep_fet), None) => Some(dep_fet),\n            (None, Some(inherit_feat)) => Some(inherit_feat),\n            (None, None) => None,\n        };\n    }\n\n    fn update_optional(&mut self, optional: Option<bool>) {\n        self.optional = optional;\n    }\n\n    fn resolve_path(\n        &mut self,\n        name: &str,\n        root_path: &Path,\n        package_root: &Path,\n    ) -> CargoResult<()> {\n        if let Some(rel_path) = &self.path {\n            self.path = Some(resolve_relative_path(\n                name,\n                root_path,\n                package_root,\n                rel_path,\n            )?)\n        }\n        Ok(())\n    }\n}\n\n#[derive(Default, Serialize, Deserialize, Debug, Clone)]\n#[serde(rename_all = \"kebab-case\")]\nstruct TomlTarget {\n    name: Option<String>,\n\n    // The intention was to only accept `crate-type` here but historical\n    // versions of Cargo also accepted `crate_type`, so look for both.\n    crate_type: Option<Vec<String>>,\n    #[serde(rename = \"crate_type\")]\n    crate_type2: Option<Vec<String>>,\n\n    path: Option<PathValue>,\n    // Note that `filename` is used for the cargo-feature `different_binary_name`\n    filename: Option<String>,\n    test: Option<bool>,\n    doctest: Option<bool>,\n    bench: Option<bool>,\n    doc: Option<bool>,\n    plugin: Option<bool>,\n    doc_scrape_examples: Option<bool>,\n    #[serde(rename = \"proc-macro\")]\n    proc_macro_raw: Option<bool>,\n    #[serde(rename = \"proc_macro\")]\n    proc_macro_raw2: Option<bool>,\n    harness: Option<bool>,\n    required_features: Option<Vec<String>>,\n    edition: Option<String>,\n}\n\n#[derive(Clone)]\nstruct PathValue(PathBuf);\n\nimpl<'de> de::Deserialize<'de> for PathValue {\n    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        Ok(PathValue(String::deserialize(deserializer)?.into()))\n    }\n}\n\nimpl ser::Serialize for PathValue {\n    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>\n    where\n        S: ser::Serializer,\n    {\n        self.0.serialize(serializer)\n    }\n}\n\n/// Corresponds to a `target` entry, but `TomlTarget` is already used.\n#[derive(Serialize, Deserialize, Debug, Clone)]\nstruct TomlPlatform {\n    dependencies: Option<BTreeMap<String, MaybeWorkspaceDependency>>,\n    #[serde(rename = \"build-dependencies\")]\n    build_dependencies: Option<BTreeMap<String, MaybeWorkspaceDependency>>,\n    #[serde(rename = \"build_dependencies\")]\n    build_dependencies2: Option<BTreeMap<String, MaybeWorkspaceDependency>>,\n    #[serde(rename = \"dev-dependencies\")]\n    dev_dependencies: Option<BTreeMap<String, MaybeWorkspaceDependency>>,\n    #[serde(rename = \"dev_dependencies\")]\n    dev_dependencies2: Option<BTreeMap<String, MaybeWorkspaceDependency>>,\n}\n\nimpl TomlTarget {\n    fn new() -> TomlTarget {\n        TomlTarget::default()\n    }\n\n    fn name(&self) -> String {\n        match self.name {\n            Some(ref name) => name.clone(),\n            None => panic!(\"target name is required\"),\n        }\n    }\n\n    fn validate_proc_macro(&self, warnings: &mut Vec<String>) {\n        if self.proc_macro_raw.is_some() && self.proc_macro_raw2.is_some() {\n            warn_on_deprecated(\n                \"proc-macro\",\n                self.name().as_str(),\n                \"library target\",\n                warnings,\n            );\n        }\n    }\n\n    fn proc_macro(&self) -> Option<bool> {\n        self.proc_macro_raw.or(self.proc_macro_raw2).or_else(|| {\n            if let Some(types) = self.crate_types() {\n                if types.contains(&\"proc-macro\".to_string()) {\n                    return Some(true);\n                }\n            }\n            None\n        })\n    }\n\n    fn validate_crate_types(&self, target_kind_human: &str, warnings: &mut Vec<String>) {\n        if self.crate_type.is_some() && self.crate_type2.is_some() {\n            warn_on_deprecated(\n                \"crate-type\",\n                self.name().as_str(),\n                format!(\"{target_kind_human} target\").as_str(),\n                warnings,\n            );\n        }\n    }\n\n    fn crate_types(&self) -> Option<&Vec<String>> {\n        self.crate_type\n            .as_ref()\n            .or_else(|| self.crate_type2.as_ref())\n    }\n}\n\nimpl fmt::Debug for PathValue {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.0.fmt(f)\n    }\n}\n\npub type TomlLints = BTreeMap<String, TomlToolLints>;\n\npub type TomlToolLints = BTreeMap<String, TomlLint>;\n\n#[derive(Serialize, Deserialize, Debug, Clone)]\n#[serde(untagged)]\npub enum TomlLint {\n    Level(TomlLintLevel),\n    Config(TomlLintConfig),\n}\n\nimpl TomlLint {\n    fn level(&self) -> TomlLintLevel {\n        match self {\n            Self::Level(level) => *level,\n            Self::Config(config) => config.level,\n        }\n    }\n\n    fn priority(&self) -> i8 {\n        match self {\n            Self::Level(_) => 0,\n            Self::Config(config) => config.priority,\n        }\n    }\n}\n\n#[derive(Serialize, Deserialize, Debug, Clone)]\n#[serde(rename_all = \"kebab-case\")]\npub struct TomlLintConfig {\n    level: TomlLintLevel,\n    #[serde(default)]\n    priority: i8,\n}\n\n#[derive(Serialize, Deserialize, Debug, Copy, Clone)]\n#[serde(rename_all = \"kebab-case\")]\npub enum TomlLintLevel {\n    Forbid,\n    Deny,\n    Warn,\n    Allow,\n}\n\nimpl TomlLintLevel {\n    fn flag(&self) -> &'static str {\n        match self {\n            Self::Forbid => \"--forbid\",\n            Self::Deny => \"--deny\",\n            Self::Warn => \"--warn\",\n            Self::Allow => \"--allow\",\n        }\n    }\n}\n", "//! Tests for `[features]` table.\n\nuse cargo_test_support::paths::CargoPathExt;\nuse cargo_test_support::registry::{Dependency, Package};\nuse cargo_test_support::{basic_manifest, project};\n\n#[cargo_test]\nfn invalid1() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                bar = [\"baz\"]\n            \"#,\n        )\n        .file(\"src/main.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_status(101)\n        .with_stderr(\n            \"\\\n[ERROR] failed to parse manifest at `[..]`\n\nCaused by:\n  feature `bar` includes `baz` which is neither a dependency nor another feature\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn same_name() {\n    // Feature with the same name as a dependency.\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                bar = [\"baz\"]\n                baz = []\n\n                [dependencies.bar]\n                path = \"bar\"\n            \"#,\n        )\n        .file(\"src/main.rs\", \"\")\n        .file(\"bar/Cargo.toml\", &basic_manifest(\"bar\", \"1.0.0\"))\n        .file(\"bar/src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"tree -f\")\n        .arg(\"{p} [{f}]\")\n        .with_stderr(\"\")\n        .with_stdout(\n            \"\\\nfoo v0.0.1 ([..]) []\n\u2514\u2500\u2500 bar v1.0.0 ([..]) []\n\",\n        )\n        .run();\n\n    p.cargo(\"tree --features bar -f\")\n        .arg(\"{p} [{f}]\")\n        .with_stderr(\"\")\n        .with_stdout(\n            \"\\\nfoo v0.0.1 ([..]) [bar,baz]\n\u2514\u2500\u2500 bar v1.0.0 ([..]) []\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn invalid3() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                bar = [\"baz\"]\n\n                [dependencies.baz]\n                path = \"foo\"\n            \"#,\n        )\n        .file(\"src/main.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_status(101)\n        .with_stderr(\n            \"\\\n[ERROR] failed to parse manifest at `[..]`\n\nCaused by:\n  feature `bar` includes `baz`, but `baz` is not an optional dependency\n  A non-optional dependency of the same name is defined; consider adding `optional = true` to its definition.\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn invalid4() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.bar]\n                path = \"bar\"\n                features = [\"bar\"]\n            \"#,\n        )\n        .file(\"src/main.rs\", \"\")\n        .file(\"bar/Cargo.toml\", &basic_manifest(\"bar\", \"0.0.1\"))\n        .file(\"bar/src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_status(101)\n        .with_stderr(\n            \"\\\nerror: failed to select a version for `bar`.\n    ... required by package `foo v0.0.1 ([..])`\nversions that meet the requirements `*` are: 0.0.1\n\nthe package `foo` depends on `bar`, with features: `bar` but `bar` does not have these features.\n\n\nfailed to select a version for `bar` which could resolve this conflict\",\n        )\n        .run();\n\n    p.change_file(\"Cargo.toml\", &basic_manifest(\"foo\", \"0.0.1\"));\n\n    p.cargo(\"check --features test\")\n        .with_status(101)\n        .with_stderr(\"error: Package `foo v0.0.1 ([..])` does not have the feature `test`\")\n        .run();\n}\n\n#[cargo_test]\nfn invalid5() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dev-dependencies.bar]\n                path = \"bar\"\n                optional = true\n            \"#,\n        )\n        .file(\"src/main.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_status(101)\n        .with_stderr(\n            \"\\\n[ERROR] failed to parse manifest at `[..]`\n\nCaused by:\n  dev-dependencies are not allowed to be optional: `bar`\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn invalid6() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                foo = [\"bar/baz\"]\n            \"#,\n        )\n        .file(\"src/main.rs\", \"\")\n        .build();\n\n    p.cargo(\"check --features foo\")\n        .with_status(101)\n        .with_stderr(\n            \"\\\n[ERROR] failed to parse manifest at `[..]`\n\nCaused by:\n  feature `foo` includes `bar/baz`, but `bar` is not a dependency\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn invalid7() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                foo = [\"bar/baz\"]\n                bar = []\n            \"#,\n        )\n        .file(\"src/main.rs\", \"\")\n        .build();\n\n    p.cargo(\"check --features foo\")\n        .with_status(101)\n        .with_stderr(\n            \"\\\n[ERROR] failed to parse manifest at `[..]`\n\nCaused by:\n  feature `foo` includes `bar/baz`, but `bar` is not a dependency\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn invalid8() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.bar]\n                path = \"bar\"\n                features = [\"foo/bar\"]\n            \"#,\n        )\n        .file(\"src/main.rs\", \"\")\n        .file(\"bar/Cargo.toml\", &basic_manifest(\"bar\", \"0.0.1\"))\n        .file(\"bar/src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"check --features foo\")\n        .with_status(101)\n        .with_stderr(\n            \"\\\nerror: failed to parse manifest at `[CWD]/Cargo.toml`\n\nCaused by:\n  feature `foo/bar` in dependency `bar` is not allowed to contain slashes\n  If you want to enable features [..]\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn invalid9() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.bar]\n                path = \"bar\"\n            \"#,\n        )\n        .file(\"src/main.rs\", \"fn main() {}\")\n        .file(\"bar/Cargo.toml\", &basic_manifest(\"bar\", \"0.0.1\"))\n        .file(\"bar/src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"check --features bar\")\n        .with_stderr(\n            \"\\\nerror: Package `foo v0.0.1 ([..])` does not have feature `bar`. It has a required dependency with that name, but only optional dependencies can be used as features.\n\",\n        ).with_status(101).run();\n}\n\n#[cargo_test]\nfn invalid10() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.bar]\n                path = \"bar\"\n                features = [\"baz\"]\n            \"#,\n        )\n        .file(\"src/main.rs\", \"fn main() {}\")\n        .file(\n            \"bar/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"bar\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.baz]\n                path = \"baz\"\n            \"#,\n        )\n        .file(\"bar/src/lib.rs\", \"\")\n        .file(\"bar/baz/Cargo.toml\", &basic_manifest(\"baz\", \"0.0.1\"))\n        .file(\"bar/baz/src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\").with_stderr(\"\\\nerror: failed to select a version for `bar`.\n    ... required by package `foo v0.0.1 ([..])`\nversions that meet the requirements `*` are: 0.0.1\n\nthe package `foo` depends on `bar`, with features: `baz` but `bar` does not have these features.\n It has a required dependency with that name, but only optional dependencies can be used as features.\n\n\nfailed to select a version for `bar` which could resolve this conflict\n\").with_status(101)\n        .run();\n}\n\n#[cargo_test]\nfn no_transitive_dep_feature_requirement() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.derived]\n                path = \"derived\"\n\n                [features]\n                default = [\"derived/bar/qux\"]\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                extern crate derived;\n                fn main() { derived::test(); }\n            \"#,\n        )\n        .file(\n            \"derived/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"derived\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.bar]\n                path = \"../bar\"\n            \"#,\n        )\n        .file(\"derived/src/lib.rs\", \"extern crate bar; pub use bar::test;\")\n        .file(\n            \"bar/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"bar\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                qux = []\n            \"#,\n        )\n        .file(\n            \"bar/src/lib.rs\",\n            r#\"\n                #[cfg(feature = \"qux\")]\n                pub fn test() { print!(\"test\"); }\n            \"#,\n        )\n        .build();\n    p.cargo(\"check\")\n        .with_status(101)\n        .with_stderr(\n            \"\\\nerror: failed to parse manifest at `[CWD]/Cargo.toml`\n\nCaused by:\n  multiple slashes in feature `derived/bar/qux` (included by feature `default`) are not allowed\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn no_feature_doesnt_build() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.bar]\n                path = \"bar\"\n                optional = true\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                #[cfg(feature = \"bar\")]\n                extern crate bar;\n                #[cfg(feature = \"bar\")]\n                fn main() { bar::bar(); println!(\"bar\") }\n                #[cfg(not(feature = \"bar\"))]\n                fn main() {}\n            \"#,\n        )\n        .file(\"bar/Cargo.toml\", &basic_manifest(\"bar\", \"0.0.1\"))\n        .file(\"bar/src/lib.rs\", \"pub fn bar() {}\")\n        .build();\n\n    p.cargo(\"build\")\n        .with_stderr(\n            \"\\\n[COMPILING] foo v0.0.1 ([CWD])\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n    p.process(&p.bin(\"foo\")).with_stdout(\"\").run();\n\n    p.cargo(\"build --features bar -v\")\n        .with_stderr(\n            \"\\\n[COMPILING] bar v0.0.1 ([CWD]/bar)\n[RUNNING] `rustc --crate-name bar [..]\n[DIRTY-MSVC] foo v0.0.1 ([CWD]): the list of features changed\n[COMPILING] foo v0.0.1 ([CWD])\n[RUNNING] `rustc --crate-name foo [..]\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n    p.process(&p.bin(\"foo\")).with_stdout(\"bar\\n\").run();\n}\n\n#[cargo_test]\nfn default_feature_pulled_in() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                default = [\"bar\"]\n\n                [dependencies.bar]\n                path = \"bar\"\n                optional = true\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                #[cfg(feature = \"bar\")]\n                extern crate bar;\n                #[cfg(feature = \"bar\")]\n                fn main() { bar::bar(); println!(\"bar\") }\n                #[cfg(not(feature = \"bar\"))]\n                fn main() {}\n            \"#,\n        )\n        .file(\"bar/Cargo.toml\", &basic_manifest(\"bar\", \"0.0.1\"))\n        .file(\"bar/src/lib.rs\", \"pub fn bar() {}\")\n        .build();\n\n    p.cargo(\"build\")\n        .with_stderr(\n            \"\\\n[COMPILING] bar v0.0.1 ([CWD]/bar)\n[COMPILING] foo v0.0.1 ([CWD])\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n    p.process(&p.bin(\"foo\")).with_stdout(\"bar\\n\").run();\n\n    p.cargo(\"build --no-default-features -v\")\n        .with_stderr(\n            \"\\\n[DIRTY-MSVC] foo v0.0.1 ([CWD]): the list of features changed\n[COMPILING] foo v0.0.1 ([CWD])\n[RUNNING] `rustc --crate-name foo [..]\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n    p.process(&p.bin(\"foo\")).with_stdout(\"\").run();\n}\n\n#[cargo_test]\nfn cyclic_feature() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                default = [\"default\"]\n            \"#,\n        )\n        .file(\"src/main.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_status(101)\n        .with_stderr(\"[ERROR] cyclic feature dependency: feature `default` depends on itself\")\n        .run();\n}\n\n#[cargo_test]\nfn cyclic_feature2() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                foo = [\"bar\"]\n                bar = [\"foo\"]\n            \"#,\n        )\n        .file(\"src/main.rs\", \"fn main() {}\")\n        .build();\n\n    p.cargo(\"check\").with_stdout(\"\").run();\n}\n\n#[cargo_test]\nfn groups_on_groups_on_groups() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                default = [\"f1\"]\n                f1 = [\"f2\", \"bar\"]\n                f2 = [\"f3\", \"f4\"]\n                f3 = [\"f5\", \"f6\", \"baz\"]\n                f4 = [\"f5\", \"f7\"]\n                f5 = [\"f6\"]\n                f6 = [\"f7\"]\n                f7 = [\"bar\"]\n\n                [dependencies.bar]\n                path = \"bar\"\n                optional = true\n\n                [dependencies.baz]\n                path = \"baz\"\n                optional = true\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                #[allow(unused_extern_crates)]\n                extern crate bar;\n                #[allow(unused_extern_crates)]\n                extern crate baz;\n                fn main() {}\n            \"#,\n        )\n        .file(\"bar/Cargo.toml\", &basic_manifest(\"bar\", \"0.0.1\"))\n        .file(\"bar/src/lib.rs\", \"pub fn bar() {}\")\n        .file(\"baz/Cargo.toml\", &basic_manifest(\"baz\", \"0.0.1\"))\n        .file(\"baz/src/lib.rs\", \"pub fn baz() {}\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_stderr(\n            \"\\\n[CHECKING] ba[..] v0.0.1 ([CWD]/ba[..])\n[CHECKING] ba[..] v0.0.1 ([CWD]/ba[..])\n[CHECKING] foo v0.0.1 ([CWD])\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn many_cli_features() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.bar]\n                path = \"bar\"\n                optional = true\n\n                [dependencies.baz]\n                path = \"baz\"\n                optional = true\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                #[allow(unused_extern_crates)]\n                extern crate bar;\n                #[allow(unused_extern_crates)]\n                extern crate baz;\n                fn main() {}\n            \"#,\n        )\n        .file(\"bar/Cargo.toml\", &basic_manifest(\"bar\", \"0.0.1\"))\n        .file(\"bar/src/lib.rs\", \"pub fn bar() {}\")\n        .file(\"baz/Cargo.toml\", &basic_manifest(\"baz\", \"0.0.1\"))\n        .file(\"baz/src/lib.rs\", \"pub fn baz() {}\")\n        .build();\n\n    p.cargo(\"check --features\")\n        .arg(\"bar baz\")\n        .with_stderr(\n            \"\\\n[CHECKING] ba[..] v0.0.1 ([CWD]/ba[..])\n[CHECKING] ba[..] v0.0.1 ([CWD]/ba[..])\n[CHECKING] foo v0.0.1 ([CWD])\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn union_features() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.d1]\n                path = \"d1\"\n                features = [\"f1\"]\n                [dependencies.d2]\n                path = \"d2\"\n                features = [\"f2\"]\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                #[allow(unused_extern_crates)]\n                extern crate d1;\n                extern crate d2;\n                fn main() {\n                    d2::f1();\n                    d2::f2();\n                }\n            \"#,\n        )\n        .file(\n            \"d1/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"d1\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                f1 = [\"d2\"]\n\n                [dependencies.d2]\n                path = \"../d2\"\n                features = [\"f1\"]\n                optional = true\n            \"#,\n        )\n        .file(\"d1/src/lib.rs\", \"\")\n        .file(\n            \"d2/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"d2\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                f1 = []\n                f2 = []\n            \"#,\n        )\n        .file(\n            \"d2/src/lib.rs\",\n            r#\"\n                #[cfg(feature = \"f1\")] pub fn f1() {}\n                #[cfg(feature = \"f2\")] pub fn f2() {}\n            \"#,\n        )\n        .build();\n\n    p.cargo(\"check\")\n        .with_stderr(\n            \"\\\n[CHECKING] d2 v0.0.1 ([CWD]/d2)\n[CHECKING] d1 v0.0.1 ([CWD]/d1)\n[CHECKING] foo v0.0.1 ([CWD])\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn many_features_no_rebuilds() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name    = \"b\"\n                version = \"0.1.0\"\n                authors = []\n\n                [dependencies.a]\n                path = \"a\"\n                features = [\"fall\"]\n            \"#,\n        )\n        .file(\"src/main.rs\", \"fn main() {}\")\n        .file(\n            \"a/Cargo.toml\",\n            r#\"\n                [package]\n                name    = \"a\"\n                version = \"0.1.0\"\n                authors = []\n\n                [features]\n                ftest  = []\n                ftest2 = []\n                fall   = [\"ftest\", \"ftest2\"]\n            \"#,\n        )\n        .file(\"a/src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_stderr(\n            \"\\\n[CHECKING] a v0.1.0 ([CWD]/a)\n[CHECKING] b v0.1.0 ([CWD])\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n    p.root().move_into_the_past();\n\n    p.cargo(\"check -v\")\n        .with_stderr(\n            \"\\\n[FRESH] a v0.1.0 ([..]/a)\n[FRESH] b v0.1.0 ([..])\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n}\n\n// Tests that all cmd lines work with `--features \"\"`\n#[cargo_test]\nfn empty_features() {\n    let p = project().file(\"src/main.rs\", \"fn main() {}\").build();\n\n    p.cargo(\"check --features\").arg(\"\").run();\n}\n\n// Tests that all cmd lines work with `--features \"\"`\n#[cargo_test]\nfn transitive_features() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                foo = [\"bar/baz\"]\n\n                [dependencies.bar]\n                path = \"bar\"\n            \"#,\n        )\n        .file(\"src/main.rs\", \"extern crate bar; fn main() { bar::baz(); }\")\n        .file(\n            \"bar/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"bar\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                baz = []\n            \"#,\n        )\n        .file(\n            \"bar/src/lib.rs\",\n            r#\"#[cfg(feature = \"baz\")] pub fn baz() {}\"#,\n        )\n        .build();\n\n    p.cargo(\"check --features foo\").run();\n}\n\n#[cargo_test]\nfn everything_in_the_lockfile() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                f1 = [\"d1/f1\"]\n                f2 = [\"d2\"]\n\n                [dependencies.d1]\n                path = \"d1\"\n                [dependencies.d2]\n                path = \"d2\"\n                optional = true\n                [dependencies.d3]\n                path = \"d3\"\n                optional = true\n            \"#,\n        )\n        .file(\"src/main.rs\", \"fn main() {}\")\n        .file(\n            \"d1/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"d1\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                f1 = []\n            \"#,\n        )\n        .file(\"d1/src/lib.rs\", \"\")\n        .file(\"d2/Cargo.toml\", &basic_manifest(\"d2\", \"0.0.2\"))\n        .file(\"d2/src/lib.rs\", \"\")\n        .file(\n            \"d3/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"d3\"\n                version = \"0.0.3\"\n                authors = []\n\n                [features]\n                f3 = []\n            \"#,\n        )\n        .file(\"d3/src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"fetch\").run();\n    let lockfile = p.read_lockfile();\n    assert!(\n        lockfile.contains(r#\"name = \"d1\"\"#),\n        \"d1 not found\\n{}\",\n        lockfile\n    );\n    assert!(\n        lockfile.contains(r#\"name = \"d2\"\"#),\n        \"d2 not found\\n{}\",\n        lockfile\n    );\n    assert!(\n        lockfile.contains(r#\"name = \"d3\"\"#),\n        \"d3 not found\\n{}\",\n        lockfile\n    );\n}\n\n#[cargo_test]\nfn no_rebuild_when_frobbing_default_feature() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.1.0\"\n                authors = []\n\n                [dependencies]\n                a = { path = \"a\" }\n                b = { path = \"b\" }\n            \"#,\n        )\n        .file(\"src/lib.rs\", \"\")\n        .file(\n            \"b/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"b\"\n                version = \"0.1.0\"\n                authors = []\n\n                [dependencies]\n                a = { path = \"../a\", features = [\"f1\"], default-features = false }\n            \"#,\n        )\n        .file(\"b/src/lib.rs\", \"\")\n        .file(\n            \"a/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"a\"\n                version = \"0.1.0\"\n                authors = []\n\n                [features]\n                default = [\"f1\"]\n                f1 = []\n            \"#,\n        )\n        .file(\"a/src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\").run();\n    p.cargo(\"check\").with_stdout(\"\").run();\n    p.cargo(\"check\").with_stdout(\"\").run();\n}\n\n#[cargo_test]\nfn unions_work_with_no_default_features() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.1.0\"\n                authors = []\n\n                [dependencies]\n                a = { path = \"a\" }\n                b = { path = \"b\" }\n            \"#,\n        )\n        .file(\"src/lib.rs\", \"extern crate a; pub fn foo() { a::a(); }\")\n        .file(\n            \"b/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"b\"\n                version = \"0.1.0\"\n                authors = []\n\n                [dependencies]\n                a = { path = \"../a\", features = [], default-features = false }\n            \"#,\n        )\n        .file(\"b/src/lib.rs\", \"\")\n        .file(\n            \"a/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"a\"\n                version = \"0.1.0\"\n                authors = []\n\n                [features]\n                default = [\"f1\"]\n                f1 = []\n            \"#,\n        )\n        .file(\"a/src/lib.rs\", r#\"#[cfg(feature = \"f1\")] pub fn a() {}\"#)\n        .build();\n\n    p.cargo(\"check\").run();\n    p.cargo(\"check\").with_stdout(\"\").run();\n    p.cargo(\"check\").with_stdout(\"\").run();\n}\n\n#[cargo_test]\nfn optional_and_dev_dep() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name    = \"test\"\n                version = \"0.1.0\"\n                authors = []\n\n                [dependencies]\n                foo = { path = \"foo\", optional = true }\n                [dev-dependencies]\n                foo = { path = \"foo\" }\n            \"#,\n        )\n        .file(\"src/lib.rs\", \"\")\n        .file(\"foo/Cargo.toml\", &basic_manifest(\"foo\", \"0.1.0\"))\n        .file(\"foo/src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_stderr(\n            \"\\\n[CHECKING] test v0.1.0 ([..])\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn activating_feature_activates_dep() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name    = \"test\"\n                version = \"0.1.0\"\n                authors = []\n\n                [dependencies]\n                foo = { path = \"foo\", optional = true }\n\n                [features]\n                a = [\"foo/a\"]\n            \"#,\n        )\n        .file(\n            \"src/lib.rs\",\n            \"extern crate foo; pub fn bar() { foo::bar(); }\",\n        )\n        .file(\n            \"foo/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.1.0\"\n                authors = []\n\n                [features]\n                a = []\n            \"#,\n        )\n        .file(\"foo/src/lib.rs\", r#\"#[cfg(feature = \"a\")] pub fn bar() {}\"#)\n        .build();\n\n    p.cargo(\"check --features a -v\").run();\n}\n\n#[cargo_test]\nfn dep_feature_in_cmd_line() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.derived]\n                path = \"derived\"\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                extern crate derived;\n                fn main() { derived::test(); }\n            \"#,\n        )\n        .file(\n            \"derived/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"derived\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.bar]\n                path = \"../bar\"\n\n                [features]\n                default = []\n                derived-feat = [\"bar/some-feat\"]\n            \"#,\n        )\n        .file(\"derived/src/lib.rs\", \"extern crate bar; pub use bar::test;\")\n        .file(\n            \"bar/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"bar\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                some-feat = []\n            \"#,\n        )\n        .file(\n            \"bar/src/lib.rs\",\n            r#\"\n                #[cfg(feature = \"some-feat\")]\n                pub fn test() { print!(\"test\"); }\n            \"#,\n        )\n        .build();\n\n    // The foo project requires that feature \"some-feat\" in \"bar\" is enabled.\n    // Building without any features enabled should fail:\n    p.cargo(\"check\")\n        .with_status(101)\n        .with_stderr_contains(\"[..]unresolved import `bar::test`\")\n        .run();\n\n    // We should be able to enable the feature \"derived-feat\", which enables \"some-feat\",\n    // on the command line. The feature is enabled, thus building should be successful:\n    p.cargo(\"check --features derived/derived-feat\").run();\n\n    // Trying to enable features of transitive dependencies is an error\n    p.cargo(\"check --features bar/some-feat\")\n        .with_status(101)\n        .with_stderr(\"error: package `foo v0.0.1 ([..])` does not have a dependency named `bar`\")\n        .run();\n\n    // Hierarchical feature specification should still be disallowed\n    p.cargo(\"check --features derived/bar/some-feat\")\n        .with_status(101)\n        .with_stderr(\"[ERROR] multiple slashes in feature `derived/bar/some-feat` is not allowed\")\n        .run();\n}\n\n#[cargo_test]\nfn all_features_flag_enables_all_features() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                foo = []\n                bar = []\n\n                [dependencies.baz]\n                path = \"baz\"\n                optional = true\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                #[cfg(feature = \"foo\")]\n                pub fn foo() {}\n\n                #[cfg(feature = \"bar\")]\n                pub fn bar() {\n                    extern crate baz;\n                    baz::baz();\n                }\n\n                fn main() {\n                    foo();\n                    bar();\n                }\n            \"#,\n        )\n        .file(\"baz/Cargo.toml\", &basic_manifest(\"baz\", \"0.0.1\"))\n        .file(\"baz/src/lib.rs\", \"pub fn baz() {}\")\n        .build();\n\n    p.cargo(\"check --all-features\").run();\n}\n\n#[cargo_test]\nfn many_cli_features_comma_delimited() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.bar]\n                path = \"bar\"\n                optional = true\n\n                [dependencies.baz]\n                path = \"baz\"\n                optional = true\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                #[allow(unused_extern_crates)]\n                extern crate bar;\n                #[allow(unused_extern_crates)]\n                extern crate baz;\n                fn main() {}\n            \"#,\n        )\n        .file(\"bar/Cargo.toml\", &basic_manifest(\"bar\", \"0.0.1\"))\n        .file(\"bar/src/lib.rs\", \"pub fn bar() {}\")\n        .file(\"baz/Cargo.toml\", &basic_manifest(\"baz\", \"0.0.1\"))\n        .file(\"baz/src/lib.rs\", \"pub fn baz() {}\")\n        .build();\n\n    p.cargo(\"check --features bar,baz\")\n        .with_stderr(\n            \"\\\n[CHECKING] ba[..] v0.0.1 ([CWD]/ba[..])\n[CHECKING] ba[..] v0.0.1 ([CWD]/ba[..])\n[CHECKING] foo v0.0.1 ([CWD])\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn many_cli_features_comma_and_space_delimited() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies.bar]\n                path = \"bar\"\n                optional = true\n\n                [dependencies.baz]\n                path = \"baz\"\n                optional = true\n\n                [dependencies.bam]\n                path = \"bam\"\n                optional = true\n\n                [dependencies.bap]\n                path = \"bap\"\n                optional = true\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                #[allow(unused_extern_crates)]\n                extern crate bar;\n                #[allow(unused_extern_crates)]\n                extern crate baz;\n                #[allow(unused_extern_crates)]\n                extern crate bam;\n                #[allow(unused_extern_crates)]\n                extern crate bap;\n                fn main() {}\n            \"#,\n        )\n        .file(\"bar/Cargo.toml\", &basic_manifest(\"bar\", \"0.0.1\"))\n        .file(\"bar/src/lib.rs\", \"pub fn bar() {}\")\n        .file(\"baz/Cargo.toml\", &basic_manifest(\"baz\", \"0.0.1\"))\n        .file(\"baz/src/lib.rs\", \"pub fn baz() {}\")\n        .file(\"bam/Cargo.toml\", &basic_manifest(\"bam\", \"0.0.1\"))\n        .file(\"bam/src/lib.rs\", \"pub fn bam() {}\")\n        .file(\"bap/Cargo.toml\", &basic_manifest(\"bap\", \"0.0.1\"))\n        .file(\"bap/src/lib.rs\", \"pub fn bap() {}\")\n        .build();\n\n    p.cargo(\"check --features\")\n        .arg(\"bar,baz bam bap\")\n        .with_stderr(\n            \"\\\n[CHECKING] ba[..] v0.0.1 ([CWD]/ba[..])\n[CHECKING] ba[..] v0.0.1 ([CWD]/ba[..])\n[CHECKING] ba[..] v0.0.1 ([CWD]/ba[..])\n[CHECKING] ba[..] v0.0.1 ([CWD]/ba[..])\n[CHECKING] foo v0.0.1 ([CWD])\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn only_dep_is_optional() {\n    Package::new(\"bar\", \"0.1.0\").publish();\n\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                foo = ['bar']\n\n                [dependencies]\n                bar = { version = \"0.1\", optional = true }\n\n                [dev-dependencies]\n                bar = \"0.1\"\n            \"#,\n        )\n        .file(\"src/main.rs\", \"fn main() {}\")\n        .build();\n\n    p.cargo(\"check\").run();\n}\n\n#[cargo_test]\nfn all_features_all_crates() {\n    Package::new(\"bar\", \"0.1.0\").publish();\n\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [workspace]\n                members = ['bar']\n            \"#,\n        )\n        .file(\"src/main.rs\", \"fn main() {}\")\n        .file(\n            \"bar/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"bar\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                foo = []\n            \"#,\n        )\n        .file(\"bar/src/main.rs\", \"#[cfg(feature = \\\"foo\\\")] fn main() {}\")\n        .build();\n\n    p.cargo(\"check --all-features --workspace\").run();\n}\n\n#[cargo_test]\nfn feature_off_dylib() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [workspace]\n                members = [\"bar\"]\n\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n\n                [lib]\n                crate-type = [\"dylib\"]\n\n                [features]\n                f1 = []\n            \"#,\n        )\n        .file(\n            \"src/lib.rs\",\n            r#\"\n                pub fn hello() -> &'static str {\n                    if cfg!(feature = \"f1\") {\n                        \"f1\"\n                    } else {\n                        \"no f1\"\n                    }\n                }\n            \"#,\n        )\n        .file(\n            \"bar/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"bar\"\n                version = \"0.0.1\"\n\n                [dependencies]\n                foo = { path = \"..\" }\n            \"#,\n        )\n        .file(\n            \"bar/src/main.rs\",\n            r#\"\n                extern crate foo;\n\n                fn main() {\n                    assert_eq!(foo::hello(), \"no f1\");\n                }\n            \"#,\n        )\n        .build();\n\n    // Build the dylib with `f1` feature.\n    p.cargo(\"check --features f1\").run();\n    // Check that building without `f1` uses a dylib without `f1`.\n    p.cargo(\"run -p bar\").run();\n}\n\n#[cargo_test]\nfn warn_if_default_features() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n               [package]\n               name = \"foo\"\n               version = \"0.0.1\"\n               authors = []\n\n               [dependencies.bar]\n               path = \"bar\"\n               optional = true\n\n               [features]\n               default-features = [\"bar\"]\n            \"#,\n        )\n        .file(\"src/main.rs\", \"fn main() {}\")\n        .file(\"bar/Cargo.toml\", &basic_manifest(\"bar\", \"0.0.1\"))\n        .file(\"bar/src/lib.rs\", \"pub fn bar() {}\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_stderr(\n            r#\"\n[WARNING] `default-features = [\"..\"]` was found in [features]. Did you mean to use `default = [\"..\"]`?\n[CHECKING] foo v0.0.1 ([CWD])\n[FINISHED] dev [unoptimized + debuginfo] target(s) in [..]\n            \"#.trim(),\n        ).run();\n}\n\n#[cargo_test]\nfn no_feature_for_non_optional_dep() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [dependencies]\n                bar = { path = \"bar\" }\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                #[cfg(not(feature = \"bar\"))]\n                fn main() {\n                }\n            \"#,\n        )\n        .file(\n            \"bar/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"bar\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                a = []\n            \"#,\n        )\n        .file(\"bar/src/lib.rs\", \"pub fn bar() {}\")\n        .build();\n\n    p.cargo(\"check --features bar/a\").run();\n}\n\n#[cargo_test]\nfn features_option_given_twice() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                a = []\n                b = []\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                #[cfg(all(feature = \"a\", feature = \"b\"))]\n                fn main() {}\n            \"#,\n        )\n        .build();\n\n    p.cargo(\"check --features a --features b\").run();\n}\n\n#[cargo_test]\nfn multi_multi_features() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                a = []\n                b = []\n                c = []\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n               #[cfg(all(feature = \"a\", feature = \"b\", feature = \"c\"))]\n               fn main() {}\n            \"#,\n        )\n        .build();\n\n    p.cargo(\"check --features a --features\").arg(\"b c\").run();\n}\n\n#[cargo_test]\nfn cli_parse_ok() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.0.1\"\n                authors = []\n\n                [features]\n                a = []\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n               #[cfg(feature = \"a\")]\n               fn main() {\n                    assert_eq!(std::env::args().nth(1).unwrap(), \"b\");\n               }\n            \"#,\n        )\n        .build();\n\n    p.cargo(\"run --features a b\").run();\n}\n\n#[cargo_test]\nfn all_features_virtual_ws() {\n    // What happens with `--all-features` in the root of a virtual workspace.\n    // Some of this behavior is a little strange (member dependencies also\n    // have all features enabled, one might expect `f4` to be disabled).\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [workspace]\n                members = [\"a\", \"b\"]\n            \"#,\n        )\n        .file(\n            \"a/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"a\"\n                version = \"0.1.0\"\n                edition = \"2018\"\n\n                [dependencies]\n                b = {path=\"../b\", optional=true}\n\n                [features]\n                default = [\"f1\"]\n                f1 = []\n                f2 = []\n            \"#,\n        )\n        .file(\n            \"a/src/main.rs\",\n            r#\"\n                fn main() {\n                    if cfg!(feature=\"f1\") {\n                        println!(\"f1\");\n                    }\n                    if cfg!(feature=\"f2\") {\n                        println!(\"f2\");\n                    }\n                    #[cfg(feature=\"b\")]\n                    b::f();\n                }\n            \"#,\n        )\n        .file(\n            \"b/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"b\"\n                version = \"0.1.0\"\n\n                [features]\n                default = [\"f3\"]\n                f3 = []\n                f4 = []\n            \"#,\n        )\n        .file(\n            \"b/src/lib.rs\",\n            r#\"\n                pub fn f() {\n                    if cfg!(feature=\"f3\") {\n                        println!(\"f3\");\n                    }\n                    if cfg!(feature=\"f4\") {\n                        println!(\"f4\");\n                    }\n                }\n            \"#,\n        )\n        .build();\n\n    p.cargo(\"run\").with_stdout(\"f1\\n\").run();\n    p.cargo(\"run --all-features\")\n        .with_stdout(\"f1\\nf2\\nf3\\nf4\\n\")\n        .run();\n    // In `a`, it behaves differently. :(\n    p.cargo(\"run --all-features\")\n        .cwd(\"a\")\n        .with_stdout(\"f1\\nf2\\nf3\\n\")\n        .run();\n}\n\n#[cargo_test]\nfn slash_optional_enables() {\n    // --features dep/feat will enable `dep` and set its feature.\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n            [package]\n            name = \"foo\"\n            version = \"0.1.0\"\n\n            [dependencies]\n            dep = {path=\"dep\", optional=true}\n            \"#,\n        )\n        .file(\n            \"src/lib.rs\",\n            r#\"\n            #[cfg(not(feature=\"dep\"))]\n            compile_error!(\"dep not set\");\n            \"#,\n        )\n        .file(\n            \"dep/Cargo.toml\",\n            r#\"\n            [package]\n            name = \"dep\"\n            version = \"0.1.0\"\n\n            [features]\n            feat = []\n            \"#,\n        )\n        .file(\n            \"dep/src/lib.rs\",\n            r#\"\n            #[cfg(not(feature=\"feat\"))]\n            compile_error!(\"feat not set\");\n            \"#,\n        )\n        .build();\n\n    p.cargo(\"check\")\n        .with_status(101)\n        .with_stderr_contains(\"[..]dep not set[..]\")\n        .run();\n\n    p.cargo(\"check --features dep/feat\").run();\n}\n\n#[cargo_test]\nfn registry_summary_order_doesnt_matter() {\n    // Checks for an issue where the resolver depended on the order of entries\n    // in the registry summary. If there was a non-optional dev-dependency\n    // that appeared before an optional normal dependency, then the resolver\n    // would not activate the optional dependency with a pkg/featname feature\n    // syntax.\n    Package::new(\"dep\", \"0.1.0\")\n        .feature(\"feat1\", &[])\n        .file(\n            \"src/lib.rs\",\n            r#\"\n                #[cfg(feature=\"feat1\")]\n                pub fn work() {\n                    println!(\"it works\");\n                }\n            \"#,\n        )\n        .publish();\n    Package::new(\"bar\", \"0.1.0\")\n        .feature(\"bar_feat\", &[\"dep/feat1\"])\n        .add_dep(Dependency::new(\"dep\", \"0.1.0\").dev())\n        .add_dep(Dependency::new(\"dep\", \"0.1.0\").optional(true))\n        .file(\n            \"src/lib.rs\",\n            r#\"\n                // This will fail to compile without `dep` optional dep activated.\n                extern crate dep;\n\n                pub fn doit() {\n                    dep::work();\n                }\n            \"#,\n        )\n        .publish();\n\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.1.0\"\n                edition = \"2018\"\n\n                [dependencies]\n                bar = { version=\"0.1\", features = [\"bar_feat\"] }\n            \"#,\n        )\n        .file(\n            \"src/main.rs\",\n            r#\"\n                fn main() {\n                    bar::doit();\n                }\n            \"#,\n        )\n        .build();\n\n    p.cargo(\"run\")\n        .with_stderr(\n            \"\\\n[UPDATING] [..]\n[DOWNLOADING] crates ...\n[DOWNLOADED] [..]\n[DOWNLOADED] [..]\n[COMPILING] dep v0.1.0\n[COMPILING] bar v0.1.0\n[COMPILING] foo v0.1.0 [..]\n[FINISHED] [..]\n[RUNNING] `target/debug/foo[EXE]`\n\",\n        )\n        .with_stdout(\"it works\")\n        .run();\n}\n\n#[cargo_test]\nfn nonexistent_required_features() {\n    Package::new(\"required_dependency\", \"0.1.0\")\n        .feature(\"simple\", &[])\n        .publish();\n    Package::new(\"optional_dependency\", \"0.2.0\")\n        .feature(\"optional\", &[])\n        .publish();\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n            [package]\n            name = \"foo\"\n            version = \"0.1.0\"\n            [features]\n            existing = []\n            fancy = [\"optional_dependency\"]\n            [dependencies]\n            required_dependency = { version = \"0.1\", optional = false}\n            optional_dependency = { version = \"0.2\", optional = true}\n            [[example]]\n            name = \"ololo\"\n            required-features = [\"not_present\",\n                                 \"existing\",\n                                 \"fancy\",\n                                 \"required_dependency/not_existing\",\n                                 \"required_dependency/simple\",\n                                 \"optional_dependency/optional\",\n                                 \"not_specified_dependency/some_feature\"]\n            \"#,\n        )\n        .file(\"src/main.rs\", \"fn main() {}\")\n        .file(\"examples/ololo.rs\", \"fn main() {}\")\n        .build();\n\n    p.cargo(\"check --examples\")\n        .with_stderr_contains(\n            \"\\\n[WARNING] invalid feature `not_present` in required-features of target `ololo`: \\\n    `not_present` is not present in [features] section\n[WARNING] invalid feature `required_dependency/not_existing` in required-features \\\n    of target `ololo`: feature `not_existing` does not exist in package \\\n    `required_dependency v0.1.0`\n[WARNING] invalid feature `not_specified_dependency/some_feature` in required-features \\\n    of target `ololo`: dependency `not_specified_dependency` does not exist\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn invalid_feature_names_error() {\n    // Errors for more restricted feature syntax.\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.1.0\"\n\n                [features]\n                # Invalid start character.\n                \"+foo\" = []\n            \"#,\n        )\n        .file(\"src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_status(101)\n        .with_stderr(\n            \"\\\nerror: failed to parse manifest at `[ROOT]/foo/Cargo.toml`\n\nCaused by:\n  invalid character `+` in feature `+foo` in package foo v0.1.0 ([ROOT]/foo), \\\n  the first character must be a Unicode XID start character or digit \\\n  (most letters or `_` or `0` to `9`)\n\",\n        )\n        .run();\n\n    p.change_file(\n        \"Cargo.toml\",\n        r#\"\n            [package]\n            name = \"foo\"\n            version = \"0.1.0\"\n\n            [features]\n            # Invalid continue character.\n            \"a&b\" = []\n        \"#,\n    );\n\n    p.cargo(\"check\")\n        .with_status(101)\n        .with_stderr(\n            \"\\\nerror: failed to parse manifest at `[ROOT]/foo/Cargo.toml`\n\nCaused by:\n  invalid character `&` in feature `a&b` in package foo v0.1.0 ([ROOT]/foo), \\\n  characters must be Unicode XID characters, `+`, or `.` \\\n  (numbers, `+`, `-`, `_`, `.`, or most letters)\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn invalid_feature_name_slash_error() {\n    // Errors for more restricted feature syntax.\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.1.0\"\n\n                [features]\n                \"foo/bar\" = []\n            \"#,\n        )\n        .file(\"src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_status(101)\n        .with_stderr(\n            \"\\\nerror: failed to parse manifest at `[CWD]/Cargo.toml`\n\nCaused by:\n  feature named `foo/bar` is not allowed to contain slashes\n\",\n        )\n        .run();\n}\n\n#[cargo_test]\nfn default_features_conflicting_warning() {\n    let p = project()\n        .file(\n            \"Cargo.toml\",\n            r#\"\n                [package]\n                name = \"foo\"\n                version = \"0.1.0\"\n                authors = []\n\n                [dependencies]\n                a = { path = \"a\", features = [\"f1\"], default-features = false, default_features = false }\n            \"#,\n        )\n        .file(\"src/lib.rs\", \"\")\n        .file(\n            \"a/Cargo.toml\",\n            r#\"\n                [package]\n                name = \"a\"\n                version = \"0.1.0\"\n                authors = []\n\n                [features]\n                default = [\"f1\"]\n                f1 = []\n            \"#,\n        )\n        .file(\"a/src/lib.rs\", \"\")\n        .build();\n\n    p.cargo(\"check\")\n        .with_stderr_contains(\n\"[WARNING] conflicting between `default-features` and `default_features` in the `a` dependency.\\n\n        `default_features` is ignored and not recommended for use in the future\"\n        )\n        .run();\n}\n"], "filenames": ["crates/resolver-tests/src/lib.rs", "src/cargo/core/resolver/version_prefs.rs", "src/cargo/core/summary.rs", "src/cargo/sources/registry/index.rs", "src/cargo/util/toml/mod.rs", "tests/testsuite/features.rs"], "buggy_code_start_loc": [182, 84, 3, 411, 2435, 1940], "buggy_code_end_loc": [629, 105, 463, 929, 2436, 2017], "fixing_code_start_loc": [181, 83, 3, 410, 2434, 1940], "fixing_code_end_loc": [624, 101, 492, 921, 2434, 2002], "type": "CWE-79", "message": "Cargo downloads a Rust project\u2019s dependencies and compiles the project. Starting in Rust 1.60.0 and prior to 1.72, Cargo did not escape Cargo feature names when including them in the report generated by `cargo build --timings`. A malicious package included as a dependency may inject nearly arbitrary HTML here, potentially leading to cross-site scripting if the report is subsequently uploaded somewhere. The vulnerability affects users relying on dependencies from git, local paths, or alternative registries. Users who solely depend on crates.io are unaffected.\n\nRust 1.60.0 introduced `cargo build --timings`, which produces a report of how long the different steps of the build process took. It includes lists of Cargo features for each crate. Prior to Rust 1.72, Cargo feature names were allowed to contain almost any characters (with some exceptions as used by the feature syntax), but it would produce a future incompatibility warning about them since Rust 1.49. crates.io is far more stringent about what it considers a valid feature name and has not allowed such feature names. As the feature names were included unescaped in the timings report, they could be used to inject Javascript into the page, for example with a feature name like `features = [\"<img src='' onerror=alert(0)\"]`. If this report were subsequently uploaded to a domain that uses credentials, the injected Javascript could access resources from the website visitor.\n\nThis issue was fixed in Rust 1.72 by turning the future incompatibility warning into an error. Users should still exercise care in which package they download, by only including trusted dependencies in their projects. Please note that even with these vulnerabilities fixed, by design Cargo allows arbitrary code execution at build time thanks to build scripts and procedural macros: a malicious dependency will be able to cause damage regardless of these vulnerabilities. crates.io has server-side checks preventing this attack, and there are no packages on crates.io exploiting these vulnerabilities. crates.io users still need to excercise care in choosing their dependencies though, as remote code execution is allowed by design there as well.", "other": {"cve": {"id": "CVE-2023-40030", "sourceIdentifier": "security-advisories@github.com", "published": "2023-08-24T23:15:09.287", "lastModified": "2023-08-31T14:35:56.270", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Cargo downloads a Rust project\u2019s dependencies and compiles the project. Starting in Rust 1.60.0 and prior to 1.72, Cargo did not escape Cargo feature names when including them in the report generated by `cargo build --timings`. A malicious package included as a dependency may inject nearly arbitrary HTML here, potentially leading to cross-site scripting if the report is subsequently uploaded somewhere. The vulnerability affects users relying on dependencies from git, local paths, or alternative registries. Users who solely depend on crates.io are unaffected.\n\nRust 1.60.0 introduced `cargo build --timings`, which produces a report of how long the different steps of the build process took. It includes lists of Cargo features for each crate. Prior to Rust 1.72, Cargo feature names were allowed to contain almost any characters (with some exceptions as used by the feature syntax), but it would produce a future incompatibility warning about them since Rust 1.49. crates.io is far more stringent about what it considers a valid feature name and has not allowed such feature names. As the feature names were included unescaped in the timings report, they could be used to inject Javascript into the page, for example with a feature name like `features = [\"<img src='' onerror=alert(0)\"]`. If this report were subsequently uploaded to a domain that uses credentials, the injected Javascript could access resources from the website visitor.\n\nThis issue was fixed in Rust 1.72 by turning the future incompatibility warning into an error. Users should still exercise care in which package they download, by only including trusted dependencies in their projects. Please note that even with these vulnerabilities fixed, by design Cargo allows arbitrary code execution at build time thanks to build scripts and procedural macros: a malicious dependency will be able to cause damage regardless of these vulnerabilities. crates.io has server-side checks preventing this attack, and there are no packages on crates.io exploiting these vulnerabilities. crates.io users still need to excercise care in choosing their dependencies though, as remote code execution is allowed by design there as well."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:L/I:L/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "CHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "NONE", "baseScore": 6.1, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 2.7}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:L/I:L/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "CHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "NONE", "baseScore": 6.1, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 2.7}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-79"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:rust-lang:rust:*:*:*:*:*:*:*:*", "versionStartIncluding": "1.60.0", "versionEndExcluding": "1.72.0", "matchCriteriaId": "A4332257-40DF-4F0A-8011-AB20D162C058"}]}]}], "references": [{"url": "https://github.com/rust-lang/cargo/commit/9835622853f08be9a4b58ebe29dcec8f43b64b33", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/rust-lang/cargo/commit/f975722a0eac934c0722f111f107c4ea2f5c4365", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/rust-lang/cargo/pull/12291", "source": "security-advisories@github.com", "tags": ["Issue Tracking", "Patch"]}, {"url": "https://github.com/rust-lang/cargo/security/advisories/GHSA-wrrj-h57r-vx9p", "source": "security-advisories@github.com", "tags": ["Vendor Advisory"]}]}, "github_commit_url": "https://github.com/rust-lang/cargo/commit/9835622853f08be9a4b58ebe29dcec8f43b64b33"}}
{"buggy_code": ["// +build linux\n\npackage chroot\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"os/exec\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"syscall\"\n\t\"time\"\n\t\"unsafe\"\n\n\t\"github.com/containers/buildah/bind\"\n\t\"github.com/containers/buildah/copier\"\n\t\"github.com/containers/buildah/util\"\n\t\"github.com/containers/storage/pkg/ioutils\"\n\t\"github.com/containers/storage/pkg/mount\"\n\t\"github.com/containers/storage/pkg/reexec\"\n\t\"github.com/containers/storage/pkg/unshare\"\n\t\"github.com/opencontainers/runc/libcontainer/apparmor\"\n\t\"github.com/opencontainers/runtime-spec/specs-go\"\n\t\"github.com/pkg/errors\"\n\t\"github.com/sirupsen/logrus\"\n\t\"github.com/syndtr/gocapability/capability\"\n\t\"golang.org/x/crypto/ssh/terminal\"\n\t\"golang.org/x/sys/unix\"\n)\n\nconst (\n\t// runUsingChrootCommand is a command we use as a key for reexec\n\trunUsingChrootCommand = \"buildah-chroot-runtime\"\n\t// runUsingChrootExec is a command we use as a key for reexec\n\trunUsingChrootExecCommand = \"buildah-chroot-exec\"\n)\n\nvar (\n\trlimitsMap = map[string]int{\n\t\t\"RLIMIT_AS\":         unix.RLIMIT_AS,\n\t\t\"RLIMIT_CORE\":       unix.RLIMIT_CORE,\n\t\t\"RLIMIT_CPU\":        unix.RLIMIT_CPU,\n\t\t\"RLIMIT_DATA\":       unix.RLIMIT_DATA,\n\t\t\"RLIMIT_FSIZE\":      unix.RLIMIT_FSIZE,\n\t\t\"RLIMIT_LOCKS\":      unix.RLIMIT_LOCKS,\n\t\t\"RLIMIT_MEMLOCK\":    unix.RLIMIT_MEMLOCK,\n\t\t\"RLIMIT_MSGQUEUE\":   unix.RLIMIT_MSGQUEUE,\n\t\t\"RLIMIT_NICE\":       unix.RLIMIT_NICE,\n\t\t\"RLIMIT_NOFILE\":     unix.RLIMIT_NOFILE,\n\t\t\"RLIMIT_NPROC\":      unix.RLIMIT_NPROC,\n\t\t\"RLIMIT_RSS\":        unix.RLIMIT_RSS,\n\t\t\"RLIMIT_RTPRIO\":     unix.RLIMIT_RTPRIO,\n\t\t\"RLIMIT_RTTIME\":     unix.RLIMIT_RTTIME,\n\t\t\"RLIMIT_SIGPENDING\": unix.RLIMIT_SIGPENDING,\n\t\t\"RLIMIT_STACK\":      unix.RLIMIT_STACK,\n\t}\n\trlimitsReverseMap = map[int]string{}\n)\n\nfunc init() {\n\treexec.Register(runUsingChrootCommand, runUsingChrootMain)\n\treexec.Register(runUsingChrootExecCommand, runUsingChrootExecMain)\n\tfor limitName, limitNumber := range rlimitsMap {\n\t\trlimitsReverseMap[limitNumber] = limitName\n\t}\n}\n\ntype runUsingChrootSubprocOptions struct {\n\tSpec        *specs.Spec\n\tBundlePath  string\n\tUIDMappings []syscall.SysProcIDMap\n\tGIDMappings []syscall.SysProcIDMap\n}\n\ntype runUsingChrootExecSubprocOptions struct {\n\tSpec       *specs.Spec\n\tBundlePath string\n}\n\n// RunUsingChroot runs a chrooted process, using some of the settings from the\n// passed-in spec, and using the specified bundlePath to hold temporary files,\n// directories, and mountpoints.\nfunc RunUsingChroot(spec *specs.Spec, bundlePath, homeDir string, stdin io.Reader, stdout, stderr io.Writer) (err error) {\n\tvar confwg sync.WaitGroup\n\tvar homeFound bool\n\tfor _, env := range spec.Process.Env {\n\t\tif strings.HasPrefix(env, \"HOME=\") {\n\t\t\thomeFound = true\n\t\t\tbreak\n\t\t}\n\t}\n\tif !homeFound {\n\t\tspec.Process.Env = append(spec.Process.Env, fmt.Sprintf(\"HOME=%s\", homeDir))\n\t}\n\truntime.LockOSThread()\n\tdefer runtime.UnlockOSThread()\n\n\t// Write the runtime configuration, mainly for debugging.\n\tspecbytes, err := json.Marshal(spec)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif err = ioutils.AtomicWriteFile(filepath.Join(bundlePath, \"config.json\"), specbytes, 0600); err != nil {\n\t\treturn errors.Wrapf(err, \"error storing runtime configuration\")\n\t}\n\tlogrus.Debugf(\"config = %v\", string(specbytes))\n\n\t// Default to using stdin/stdout/stderr if we weren't passed objects to use.\n\tif stdin == nil {\n\t\tstdin = os.Stdin\n\t}\n\tif stdout == nil {\n\t\tstdout = os.Stdout\n\t}\n\tif stderr == nil {\n\t\tstderr = os.Stderr\n\t}\n\n\t// Create a pipe for passing configuration down to the next process.\n\tpreader, pwriter, err := os.Pipe()\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"error creating configuration pipe\")\n\t}\n\tconfig, conferr := json.Marshal(runUsingChrootSubprocOptions{\n\t\tSpec:       spec,\n\t\tBundlePath: bundlePath,\n\t})\n\tif conferr != nil {\n\t\treturn errors.Wrapf(conferr, \"error encoding configuration for %q\", runUsingChrootCommand)\n\t}\n\n\t// Set our terminal's mode to raw, to pass handling of special\n\t// terminal input to the terminal in the container.\n\tif spec.Process.Terminal && terminal.IsTerminal(unix.Stdin) {\n\t\tstate, err := terminal.MakeRaw(unix.Stdin)\n\t\tif err != nil {\n\t\t\tlogrus.Warnf(\"error setting terminal state: %v\", err)\n\t\t} else {\n\t\t\tdefer func() {\n\t\t\t\tif err = terminal.Restore(unix.Stdin, state); err != nil {\n\t\t\t\t\tlogrus.Errorf(\"unable to restore terminal state: %v\", err)\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t}\n\n\t// Raise any resource limits that are higher than they are now, before\n\t// we drop any more privileges.\n\tif err = setRlimits(spec, false, true); err != nil {\n\t\treturn err\n\t}\n\n\t// Start the grandparent subprocess.\n\tcmd := unshare.Command(runUsingChrootCommand)\n\tcmd.Stdin, cmd.Stdout, cmd.Stderr = stdin, stdout, stderr\n\tcmd.Dir = \"/\"\n\tcmd.Env = append([]string{fmt.Sprintf(\"LOGLEVEL=%d\", logrus.GetLevel())}, os.Environ()...)\n\n\tlogrus.Debugf(\"Running %#v in %#v\", cmd.Cmd, cmd)\n\tconfwg.Add(1)\n\tgo func() {\n\t\t_, conferr = io.Copy(pwriter, bytes.NewReader(config))\n\t\tpwriter.Close()\n\t\tconfwg.Done()\n\t}()\n\tcmd.ExtraFiles = append([]*os.File{preader}, cmd.ExtraFiles...)\n\terr = cmd.Run()\n\tconfwg.Wait()\n\tif err == nil {\n\t\treturn conferr\n\t}\n\treturn err\n}\n\n// main() for grandparent subprocess.  Its main job is to shuttle stdio back\n// and forth, managing a pseudo-terminal if we want one, for our child, the\n// parent subprocess.\nfunc runUsingChrootMain() {\n\tvar options runUsingChrootSubprocOptions\n\n\truntime.LockOSThread()\n\n\t// Set logging.\n\tif level := os.Getenv(\"LOGLEVEL\"); level != \"\" {\n\t\tif ll, err := strconv.Atoi(level); err == nil {\n\t\t\tlogrus.SetLevel(logrus.Level(ll))\n\t\t}\n\t\tos.Unsetenv(\"LOGLEVEL\")\n\t}\n\n\t// Unpack our configuration.\n\tconfPipe := os.NewFile(3, \"confpipe\")\n\tif confPipe == nil {\n\t\tfmt.Fprintf(os.Stderr, \"error reading options pipe\\n\")\n\t\tos.Exit(1)\n\t}\n\tdefer confPipe.Close()\n\tif err := json.NewDecoder(confPipe).Decode(&options); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error decoding options: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\tif options.Spec == nil {\n\t\tfmt.Fprintf(os.Stderr, \"invalid options spec in runUsingChrootMain\\n\")\n\t\tos.Exit(1)\n\t}\n\n\t// Prepare to shuttle stdio back and forth.\n\trootUID32, rootGID32, err := util.GetHostRootIDs(options.Spec)\n\tif err != nil {\n\t\tlogrus.Errorf(\"error determining ownership for container stdio\")\n\t\tos.Exit(1)\n\t}\n\trootUID := int(rootUID32)\n\trootGID := int(rootGID32)\n\trelays := make(map[int]int)\n\tcloseOnceRunning := []*os.File{}\n\tvar ctty *os.File\n\tvar stdin io.Reader\n\tvar stdinCopy io.WriteCloser\n\tvar stdout io.Writer\n\tvar stderr io.Writer\n\tfdDesc := make(map[int]string)\n\tif options.Spec.Process.Terminal {\n\t\t// Create a pseudo-terminal -- open a copy of the master side.\n\t\tptyMasterFd, err := unix.Open(\"/dev/ptmx\", os.O_RDWR, 0600)\n\t\tif err != nil {\n\t\t\tlogrus.Errorf(\"error opening PTY master using /dev/ptmx: %v\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\t// Set the kernel's lock to \"unlocked\".\n\t\tlocked := 0\n\t\tif result, _, err := unix.Syscall(unix.SYS_IOCTL, uintptr(ptyMasterFd), unix.TIOCSPTLCK, uintptr(unsafe.Pointer(&locked))); int(result) == -1 {\n\t\t\tlogrus.Errorf(\"error locking PTY descriptor: %v\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\t// Get a handle for the other end.\n\t\tptyFd, _, err := unix.Syscall(unix.SYS_IOCTL, uintptr(ptyMasterFd), unix.TIOCGPTPEER, unix.O_RDWR|unix.O_NOCTTY)\n\t\tif int(ptyFd) == -1 {\n\t\t\tif errno, isErrno := err.(syscall.Errno); !isErrno || (errno != syscall.EINVAL && errno != syscall.ENOTTY) {\n\t\t\t\tlogrus.Errorf(\"error getting PTY descriptor: %v\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\t// EINVAL means the kernel's too old to understand TIOCGPTPEER.  Try TIOCGPTN.\n\t\t\tptyN, err := unix.IoctlGetInt(ptyMasterFd, unix.TIOCGPTN)\n\t\t\tif err != nil {\n\t\t\t\tlogrus.Errorf(\"error getting PTY number: %v\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tptyName := fmt.Sprintf(\"/dev/pts/%d\", ptyN)\n\t\t\tfd, err := unix.Open(ptyName, unix.O_RDWR|unix.O_NOCTTY, 0620)\n\t\t\tif err != nil {\n\t\t\t\tlogrus.Errorf(\"error opening PTY %q: %v\", ptyName, err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tptyFd = uintptr(fd)\n\t\t}\n\t\t// Make notes about what's going where.\n\t\trelays[ptyMasterFd] = unix.Stdout\n\t\trelays[unix.Stdin] = ptyMasterFd\n\t\tfdDesc[ptyMasterFd] = \"container terminal\"\n\t\tfdDesc[unix.Stdin] = \"stdin\"\n\t\tfdDesc[unix.Stdout] = \"stdout\"\n\t\twinsize := &unix.Winsize{}\n\t\t// Set the pseudoterminal's size to the configured size, or our own.\n\t\tif options.Spec.Process.ConsoleSize != nil {\n\t\t\t// Use configured sizes.\n\t\t\twinsize.Row = uint16(options.Spec.Process.ConsoleSize.Height)\n\t\t\twinsize.Col = uint16(options.Spec.Process.ConsoleSize.Width)\n\t\t} else {\n\t\t\tif terminal.IsTerminal(unix.Stdin) {\n\t\t\t\t// Use the size of our terminal.\n\t\t\t\twinsize, err = unix.IoctlGetWinsize(unix.Stdin, unix.TIOCGWINSZ)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlogrus.Debugf(\"error reading current terminal's size\")\n\t\t\t\t\twinsize.Row = 0\n\t\t\t\t\twinsize.Col = 0\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif winsize.Row != 0 && winsize.Col != 0 {\n\t\t\tif err = unix.IoctlSetWinsize(int(ptyFd), unix.TIOCSWINSZ, winsize); err != nil {\n\t\t\t\tlogrus.Warnf(\"error setting terminal size for pty\")\n\t\t\t}\n\t\t\t// FIXME - if we're connected to a terminal, we should\n\t\t\t// be passing the updated terminal size down when we\n\t\t\t// receive a SIGWINCH.\n\t\t}\n\t\t// Open an *os.File object that we can pass to our child.\n\t\tctty = os.NewFile(ptyFd, \"/dev/tty\")\n\t\t// Set ownership for the PTY.\n\t\tif err = ctty.Chown(rootUID, rootGID); err != nil {\n\t\t\tvar cttyInfo unix.Stat_t\n\t\t\terr2 := unix.Fstat(int(ptyFd), &cttyInfo)\n\t\t\tfrom := \"\"\n\t\t\top := \"setting\"\n\t\t\tif err2 == nil {\n\t\t\t\top = \"changing\"\n\t\t\t\tfrom = fmt.Sprintf(\"from %d/%d \", cttyInfo.Uid, cttyInfo.Gid)\n\t\t\t}\n\t\t\tlogrus.Warnf(\"error %s ownership of container PTY %sto %d/%d: %v\", op, from, rootUID, rootGID, err)\n\t\t}\n\t\t// Set permissions on the PTY.\n\t\tif err = ctty.Chmod(0620); err != nil {\n\t\t\tlogrus.Errorf(\"error setting permissions of container PTY: %v\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\t// Make a note that our child (the parent subprocess) should\n\t\t// have the PTY connected to its stdio, and that we should\n\t\t// close it once it's running.\n\t\tstdin = ctty\n\t\tstdout = ctty\n\t\tstderr = ctty\n\t\tcloseOnceRunning = append(closeOnceRunning, ctty)\n\t} else {\n\t\t// Create pipes for stdio.\n\t\tstdinRead, stdinWrite, err := os.Pipe()\n\t\tif err != nil {\n\t\t\tlogrus.Errorf(\"error opening pipe for stdin: %v\", err)\n\t\t}\n\t\tstdoutRead, stdoutWrite, err := os.Pipe()\n\t\tif err != nil {\n\t\t\tlogrus.Errorf(\"error opening pipe for stdout: %v\", err)\n\t\t}\n\t\tstderrRead, stderrWrite, err := os.Pipe()\n\t\tif err != nil {\n\t\t\tlogrus.Errorf(\"error opening pipe for stderr: %v\", err)\n\t\t}\n\t\t// Make notes about what's going where.\n\t\trelays[unix.Stdin] = int(stdinWrite.Fd())\n\t\trelays[int(stdoutRead.Fd())] = unix.Stdout\n\t\trelays[int(stderrRead.Fd())] = unix.Stderr\n\t\tfdDesc[int(stdinWrite.Fd())] = \"container stdin pipe\"\n\t\tfdDesc[int(stdoutRead.Fd())] = \"container stdout pipe\"\n\t\tfdDesc[int(stderrRead.Fd())] = \"container stderr pipe\"\n\t\tfdDesc[unix.Stdin] = \"stdin\"\n\t\tfdDesc[unix.Stdout] = \"stdout\"\n\t\tfdDesc[unix.Stderr] = \"stderr\"\n\t\t// Set ownership for the pipes.\n\t\tif err = stdinRead.Chown(rootUID, rootGID); err != nil {\n\t\t\tlogrus.Errorf(\"error setting ownership of container stdin pipe: %v\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\tif err = stdoutWrite.Chown(rootUID, rootGID); err != nil {\n\t\t\tlogrus.Errorf(\"error setting ownership of container stdout pipe: %v\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\tif err = stderrWrite.Chown(rootUID, rootGID); err != nil {\n\t\t\tlogrus.Errorf(\"error setting ownership of container stderr pipe: %v\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\t// Make a note that our child (the parent subprocess) should\n\t\t// have the pipes connected to its stdio, and that we should\n\t\t// close its ends of them once it's running.\n\t\tstdin = stdinRead\n\t\tstdout = stdoutWrite\n\t\tstderr = stderrWrite\n\t\tcloseOnceRunning = append(closeOnceRunning, stdinRead, stdoutWrite, stderrWrite)\n\t\tstdinCopy = stdinWrite\n\t\tdefer stdoutRead.Close()\n\t\tdefer stderrRead.Close()\n\t}\n\tfor readFd, writeFd := range relays {\n\t\tif err := unix.SetNonblock(readFd, true); err != nil {\n\t\t\tlogrus.Errorf(\"error setting descriptor %d (%s) non-blocking: %v\", readFd, fdDesc[readFd], err)\n\t\t\treturn\n\t\t}\n\t\tif err := unix.SetNonblock(writeFd, false); err != nil {\n\t\t\tlogrus.Errorf(\"error setting descriptor %d (%s) blocking: %v\", relays[writeFd], fdDesc[writeFd], err)\n\t\t\treturn\n\t\t}\n\t}\n\tif err := unix.SetNonblock(relays[unix.Stdin], true); err != nil {\n\t\tlogrus.Errorf(\"error setting %d to nonblocking: %v\", relays[unix.Stdin], err)\n\t}\n\tgo func() {\n\t\tbuffers := make(map[int]*bytes.Buffer)\n\t\tfor _, writeFd := range relays {\n\t\t\tbuffers[writeFd] = new(bytes.Buffer)\n\t\t}\n\t\tpollTimeout := -1\n\t\tstdinClose := false\n\t\tfor len(relays) > 0 {\n\t\t\tfds := make([]unix.PollFd, 0, len(relays))\n\t\t\tfor fd := range relays {\n\t\t\t\tfds = append(fds, unix.PollFd{Fd: int32(fd), Events: unix.POLLIN | unix.POLLHUP})\n\t\t\t}\n\t\t\t_, err := unix.Poll(fds, pollTimeout)\n\t\t\tif !util.LogIfNotRetryable(err, fmt.Sprintf(\"poll: %v\", err)) {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tremoveFds := make(map[int]struct{})\n\t\t\tfor _, rfd := range fds {\n\t\t\t\tif rfd.Revents&unix.POLLHUP == unix.POLLHUP {\n\t\t\t\t\tremoveFds[int(rfd.Fd)] = struct{}{}\n\t\t\t\t}\n\t\t\t\tif rfd.Revents&unix.POLLNVAL == unix.POLLNVAL {\n\t\t\t\t\tlogrus.Debugf(\"error polling descriptor %s: closed?\", fdDesc[int(rfd.Fd)])\n\t\t\t\t\tremoveFds[int(rfd.Fd)] = struct{}{}\n\t\t\t\t}\n\t\t\t\tif rfd.Revents&unix.POLLIN == 0 {\n\t\t\t\t\tif stdinClose && stdinCopy == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tb := make([]byte, 8192)\n\t\t\t\tnread, err := unix.Read(int(rfd.Fd), b)\n\t\t\t\tutil.LogIfNotRetryable(err, fmt.Sprintf(\"read %s: %v\", fdDesc[int(rfd.Fd)], err))\n\t\t\t\tif nread > 0 {\n\t\t\t\t\tif wfd, ok := relays[int(rfd.Fd)]; ok {\n\t\t\t\t\t\tnwritten, err := buffers[wfd].Write(b[:nread])\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\tlogrus.Debugf(\"buffer: %v\", err)\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif nwritten != nread {\n\t\t\t\t\t\t\tlogrus.Debugf(\"buffer: expected to buffer %d bytes, wrote %d\", nread, nwritten)\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t// If this is the last of the data we'll be able to read\n\t\t\t\t\t// from this descriptor, read as much as there is to read.\n\t\t\t\t\tfor rfd.Revents&unix.POLLHUP == unix.POLLHUP {\n\t\t\t\t\t\tnr, err := unix.Read(int(rfd.Fd), b)\n\t\t\t\t\t\tutil.LogIfUnexpectedWhileDraining(err, fmt.Sprintf(\"read %s: %v\", fdDesc[int(rfd.Fd)], err))\n\t\t\t\t\t\tif nr <= 0 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif wfd, ok := relays[int(rfd.Fd)]; ok {\n\t\t\t\t\t\t\tnwritten, err := buffers[wfd].Write(b[:nr])\n\t\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t\tlogrus.Debugf(\"buffer: %v\", err)\n\t\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif nwritten != nr {\n\t\t\t\t\t\t\t\tlogrus.Debugf(\"buffer: expected to buffer %d bytes, wrote %d\", nr, nwritten)\n\t\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif nread == 0 {\n\t\t\t\t\tremoveFds[int(rfd.Fd)] = struct{}{}\n\t\t\t\t}\n\t\t\t}\n\t\t\tpollTimeout = -1\n\t\t\tfor wfd, buffer := range buffers {\n\t\t\t\tif buffer.Len() > 0 {\n\t\t\t\t\tnwritten, err := unix.Write(wfd, buffer.Bytes())\n\t\t\t\t\tutil.LogIfNotRetryable(err, fmt.Sprintf(\"write %s: %v\", fdDesc[wfd], err))\n\t\t\t\t\tif nwritten >= 0 {\n\t\t\t\t\t\t_ = buffer.Next(nwritten)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif buffer.Len() > 0 {\n\t\t\t\t\tpollTimeout = 100\n\t\t\t\t}\n\t\t\t\tif wfd == relays[unix.Stdin] && stdinClose && buffer.Len() == 0 {\n\t\t\t\t\tstdinCopy.Close()\n\t\t\t\t\tdelete(relays, unix.Stdin)\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor rfd := range removeFds {\n\t\t\t\tif rfd == unix.Stdin {\n\t\t\t\t\tbuffer, found := buffers[relays[unix.Stdin]]\n\t\t\t\t\tif found && buffer.Len() > 0 {\n\t\t\t\t\t\tstdinClose = true\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif !options.Spec.Process.Terminal && rfd == unix.Stdin {\n\t\t\t\t\tstdinCopy.Close()\n\t\t\t\t}\n\t\t\t\tdelete(relays, rfd)\n\t\t\t}\n\t\t}\n\t}()\n\n\t// Set up mounts and namespaces, and run the parent subprocess.\n\tstatus, err := runUsingChroot(options.Spec, options.BundlePath, ctty, stdin, stdout, stderr, closeOnceRunning)\n\tif err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error running subprocess: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Pass the process's exit status back to the caller by exiting with the same status.\n\tif status.Exited() {\n\t\tif status.ExitStatus() != 0 {\n\t\t\tfmt.Fprintf(os.Stderr, \"subprocess exited with status %d\\n\", status.ExitStatus())\n\t\t}\n\t\tos.Exit(status.ExitStatus())\n\t} else if status.Signaled() {\n\t\tfmt.Fprintf(os.Stderr, \"subprocess exited on %s\\n\", status.Signal())\n\t\tos.Exit(1)\n\t}\n}\n\n// runUsingChroot, still in the grandparent process, sets up various bind\n// mounts and then runs the parent process in its own user namespace with the\n// necessary ID mappings.\nfunc runUsingChroot(spec *specs.Spec, bundlePath string, ctty *os.File, stdin io.Reader, stdout, stderr io.Writer, closeOnceRunning []*os.File) (wstatus unix.WaitStatus, err error) {\n\tvar confwg sync.WaitGroup\n\n\t// Create a new mount namespace for ourselves and bind mount everything to a new location.\n\tundoIntermediates, err := bind.SetupIntermediateMountNamespace(spec, bundlePath)\n\tif err != nil {\n\t\treturn 1, err\n\t}\n\tdefer func() {\n\t\tif undoErr := undoIntermediates(); undoErr != nil {\n\t\t\tlogrus.Debugf(\"error cleaning up intermediate mount NS: %v\", err)\n\t\t}\n\t}()\n\n\t// Bind mount in our filesystems.\n\tundoChroots, err := setupChrootBindMounts(spec, bundlePath)\n\tif err != nil {\n\t\treturn 1, err\n\t}\n\tdefer func() {\n\t\tif undoErr := undoChroots(); undoErr != nil {\n\t\t\tlogrus.Debugf(\"error cleaning up intermediate chroot bind mounts: %v\", err)\n\t\t}\n\t}()\n\n\t// Create a pipe for passing configuration down to the next process.\n\tpreader, pwriter, err := os.Pipe()\n\tif err != nil {\n\t\treturn 1, errors.Wrapf(err, \"error creating configuration pipe\")\n\t}\n\tconfig, conferr := json.Marshal(runUsingChrootExecSubprocOptions{\n\t\tSpec:       spec,\n\t\tBundlePath: bundlePath,\n\t})\n\tif conferr != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error re-encoding configuration for %q\", runUsingChrootExecCommand)\n\t\tos.Exit(1)\n\t}\n\n\t// Apologize for the namespace configuration that we're about to ignore.\n\tlogNamespaceDiagnostics(spec)\n\n\t// If we have configured ID mappings, set them here so that they can apply to the child.\n\thostUidmap, hostGidmap, err := unshare.GetHostIDMappings(\"\")\n\tif err != nil {\n\t\treturn 1, err\n\t}\n\tuidmap, gidmap := spec.Linux.UIDMappings, spec.Linux.GIDMappings\n\tif len(uidmap) == 0 {\n\t\t// No UID mappings are configured for the container.  Borrow our parent's mappings.\n\t\tuidmap = append([]specs.LinuxIDMapping{}, hostUidmap...)\n\t\tfor i := range uidmap {\n\t\t\tuidmap[i].HostID = uidmap[i].ContainerID\n\t\t}\n\t}\n\tif len(gidmap) == 0 {\n\t\t// No GID mappings are configured for the container.  Borrow our parent's mappings.\n\t\tgidmap = append([]specs.LinuxIDMapping{}, hostGidmap...)\n\t\tfor i := range gidmap {\n\t\t\tgidmap[i].HostID = gidmap[i].ContainerID\n\t\t}\n\t}\n\n\t// Start the parent subprocess.\n\tcmd := unshare.Command(append([]string{runUsingChrootExecCommand}, spec.Process.Args...)...)\n\tcmd.Stdin, cmd.Stdout, cmd.Stderr = stdin, stdout, stderr\n\tcmd.Dir = \"/\"\n\tcmd.Env = append([]string{fmt.Sprintf(\"LOGLEVEL=%d\", logrus.GetLevel())}, os.Environ()...)\n\tcmd.UnshareFlags = syscall.CLONE_NEWUTS | syscall.CLONE_NEWNS\n\trequestedUserNS := false\n\tfor _, ns := range spec.Linux.Namespaces {\n\t\tif ns.Type == specs.UserNamespace {\n\t\t\trequestedUserNS = true\n\t\t}\n\t}\n\tif len(spec.Linux.UIDMappings) > 0 || len(spec.Linux.GIDMappings) > 0 || requestedUserNS {\n\t\tcmd.UnshareFlags = cmd.UnshareFlags | syscall.CLONE_NEWUSER\n\t\tcmd.UidMappings = uidmap\n\t\tcmd.GidMappings = gidmap\n\t\tcmd.GidMappingsEnableSetgroups = true\n\t}\n\tif ctty != nil {\n\t\tcmd.Setsid = true\n\t\tcmd.Ctty = ctty\n\t}\n\tcmd.OOMScoreAdj = spec.Process.OOMScoreAdj\n\tcmd.ExtraFiles = append([]*os.File{preader}, cmd.ExtraFiles...)\n\tcmd.Hook = func(int) error {\n\t\tfor _, f := range closeOnceRunning {\n\t\t\tf.Close()\n\t\t}\n\t\treturn nil\n\t}\n\n\tlogrus.Debugf(\"Running %#v in %#v\", cmd.Cmd, cmd)\n\tconfwg.Add(1)\n\tgo func() {\n\t\t_, conferr = io.Copy(pwriter, bytes.NewReader(config))\n\t\tpwriter.Close()\n\t\tconfwg.Done()\n\t}()\n\terr = cmd.Run()\n\tconfwg.Wait()\n\tif err != nil {\n\t\tif exitError, ok := err.(*exec.ExitError); ok {\n\t\t\tif waitStatus, ok := exitError.ProcessState.Sys().(syscall.WaitStatus); ok {\n\t\t\t\tif waitStatus.Exited() {\n\t\t\t\t\tif waitStatus.ExitStatus() != 0 {\n\t\t\t\t\t\tfmt.Fprintf(os.Stderr, \"subprocess exited with status %d\\n\", waitStatus.ExitStatus())\n\t\t\t\t\t}\n\t\t\t\t\tos.Exit(waitStatus.ExitStatus())\n\t\t\t\t} else if waitStatus.Signaled() {\n\t\t\t\t\tfmt.Fprintf(os.Stderr, \"subprocess exited on %s\\n\", waitStatus.Signal())\n\t\t\t\t\tos.Exit(1)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfmt.Fprintf(os.Stderr, \"process exited with error: %v\", err)\n\t\tos.Exit(1)\n\t}\n\n\treturn 0, nil\n}\n\n// main() for parent subprocess.  Its main job is to try to make our\n// environment look like the one described by the runtime configuration blob,\n// and then launch the intended command as a child.\nfunc runUsingChrootExecMain() {\n\targs := os.Args[1:]\n\tvar options runUsingChrootExecSubprocOptions\n\tvar err error\n\n\truntime.LockOSThread()\n\n\t// Set logging.\n\tif level := os.Getenv(\"LOGLEVEL\"); level != \"\" {\n\t\tif ll, err := strconv.Atoi(level); err == nil {\n\t\t\tlogrus.SetLevel(logrus.Level(ll))\n\t\t}\n\t\tos.Unsetenv(\"LOGLEVEL\")\n\t}\n\n\t// Unpack our configuration.\n\tconfPipe := os.NewFile(3, \"confpipe\")\n\tif confPipe == nil {\n\t\tfmt.Fprintf(os.Stderr, \"error reading options pipe\\n\")\n\t\tos.Exit(1)\n\t}\n\tdefer confPipe.Close()\n\tif err := json.NewDecoder(confPipe).Decode(&options); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error decoding options: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Set the hostname.  We're already in a distinct UTS namespace and are admins in the user\n\t// namespace which created it, so we shouldn't get a permissions error, but seccomp policy\n\t// might deny our attempt to call sethostname() anyway, so log a debug message for that.\n\tif options.Spec == nil {\n\t\tfmt.Fprintf(os.Stderr, \"invalid options spec passed in\\n\")\n\t\tos.Exit(1)\n\t}\n\n\tif options.Spec.Hostname != \"\" {\n\t\tif err := unix.Sethostname([]byte(options.Spec.Hostname)); err != nil {\n\t\t\tlogrus.Debugf(\"failed to set hostname %q for process: %v\", options.Spec.Hostname, err)\n\t\t}\n\t}\n\n\t// Try to chroot into the root.  Do this before we potentially block the syscall via the\n\t// seccomp profile.\n\tvar oldst, newst unix.Stat_t\n\tif err := unix.Stat(options.Spec.Root.Path, &oldst); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error stat()ing intended root directory %q: %v\\n\", options.Spec.Root.Path, err)\n\t\tos.Exit(1)\n\t}\n\tif err := unix.Chdir(options.Spec.Root.Path); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error chdir()ing to intended root directory %q: %v\\n\", options.Spec.Root.Path, err)\n\t\tos.Exit(1)\n\t}\n\tif err := unix.Chroot(options.Spec.Root.Path); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error chroot()ing into directory %q: %v\\n\", options.Spec.Root.Path, err)\n\t\tos.Exit(1)\n\t}\n\tif err := unix.Stat(\"/\", &newst); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error stat()ing current root directory: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tif oldst.Dev != newst.Dev || oldst.Ino != newst.Ino {\n\t\tfmt.Fprintf(os.Stderr, \"unknown error chroot()ing into directory %q: %v\\n\", options.Spec.Root.Path, err)\n\t\tos.Exit(1)\n\t}\n\tlogrus.Debugf(\"chrooted into %q\", options.Spec.Root.Path)\n\n\t// not doing because it's still shared: creating devices\n\t// not doing because it's not applicable: setting annotations\n\t// not doing because it's still shared: setting sysctl settings\n\t// not doing because cgroupfs is read only: configuring control groups\n\t// -> this means we can use the freezer to make sure there aren't any lingering processes\n\t// -> this means we ignore cgroups-based controls\n\t// not doing because we don't set any in the config: running hooks\n\t// not doing because we don't set it in the config: setting rootfs read-only\n\t// not doing because we don't set it in the config: setting rootfs propagation\n\tlogrus.Debugf(\"setting apparmor profile\")\n\tif err = setApparmorProfile(options.Spec); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error setting apparmor profile for process: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tif err = setSelinuxLabel(options.Spec); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error setting SELinux label for process: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\tlogrus.Debugf(\"setting resource limits\")\n\tif err = setRlimits(options.Spec, false, false); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error setting process resource limits for process: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Try to change to the directory.\n\tcwd := options.Spec.Process.Cwd\n\tif !filepath.IsAbs(cwd) {\n\t\tcwd = \"/\" + cwd\n\t}\n\tcwd = filepath.Clean(cwd)\n\tif err := unix.Chdir(\"/\"); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error chdir()ing into new root directory %q: %v\\n\", options.Spec.Root.Path, err)\n\t\tos.Exit(1)\n\t}\n\tif err := unix.Chdir(cwd); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error chdir()ing into directory %q under root %q: %v\\n\", cwd, options.Spec.Root.Path, err)\n\t\tos.Exit(1)\n\t}\n\tlogrus.Debugf(\"changed working directory to %q\", cwd)\n\n\t// Drop privileges.\n\tuser := options.Spec.Process.User\n\tif len(user.AdditionalGids) > 0 {\n\t\tgids := make([]int, len(user.AdditionalGids))\n\t\tfor i := range user.AdditionalGids {\n\t\t\tgids[i] = int(user.AdditionalGids[i])\n\t\t}\n\t\tlogrus.Debugf(\"setting supplemental groups\")\n\t\tif err = syscall.Setgroups(gids); err != nil {\n\t\t\tfmt.Fprintf(os.Stderr, \"error setting supplemental groups list: %v\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t} else {\n\t\tsetgroups, _ := ioutil.ReadFile(\"/proc/self/setgroups\")\n\t\tif strings.Trim(string(setgroups), \"\\n\") != \"deny\" {\n\t\t\tlogrus.Debugf(\"clearing supplemental groups\")\n\t\t\tif err = syscall.Setgroups([]int{}); err != nil {\n\t\t\t\tfmt.Fprintf(os.Stderr, \"error clearing supplemental groups list: %v\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t}\n\t}\n\n\tlogrus.Debugf(\"setting gid\")\n\tif err = syscall.Setresgid(int(user.GID), int(user.GID), int(user.GID)); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error setting GID: %v\", err)\n\t\tos.Exit(1)\n\t}\n\n\tif err = setSeccomp(options.Spec); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error setting seccomp filter for process: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\tlogrus.Debugf(\"setting capabilities\")\n\tvar keepCaps []string\n\tif user.UID != 0 {\n\t\tkeepCaps = []string{\"CAP_SETUID\"}\n\t}\n\tif err := setCapabilities(options.Spec, keepCaps...); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error setting capabilities for process: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\tlogrus.Debugf(\"setting uid\")\n\tif err = syscall.Setresuid(int(user.UID), int(user.UID), int(user.UID)); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error setting UID: %v\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Actually run the specified command.\n\tcmd := exec.Command(args[0], args[1:]...)\n\tcmd.Env = options.Spec.Process.Env\n\tcmd.Stdin, cmd.Stdout, cmd.Stderr = os.Stdin, os.Stdout, os.Stderr\n\tcmd.Dir = cwd\n\tlogrus.Debugf(\"Running %#v (PATH = %q)\", cmd, os.Getenv(\"PATH\"))\n\tif err = cmd.Run(); err != nil {\n\t\tif exitError, ok := err.(*exec.ExitError); ok {\n\t\t\tif waitStatus, ok := exitError.ProcessState.Sys().(syscall.WaitStatus); ok {\n\t\t\t\tif waitStatus.Exited() {\n\t\t\t\t\tif waitStatus.ExitStatus() != 0 {\n\t\t\t\t\t\tfmt.Fprintf(os.Stderr, \"subprocess exited with status %d\\n\", waitStatus.ExitStatus())\n\t\t\t\t\t}\n\t\t\t\t\tos.Exit(waitStatus.ExitStatus())\n\t\t\t\t} else if waitStatus.Signaled() {\n\t\t\t\t\tfmt.Fprintf(os.Stderr, \"subprocess exited on %s\\n\", waitStatus.Signal())\n\t\t\t\t\tos.Exit(1)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfmt.Fprintf(os.Stderr, \"process exited with error: %v\", err)\n\t\tos.Exit(1)\n\t}\n}\n\n// logNamespaceDiagnostics knows which namespaces we want to create.\n// Output debug messages when that differs from what we're being asked to do.\nfunc logNamespaceDiagnostics(spec *specs.Spec) {\n\tsawMountNS := false\n\tsawUserNS := false\n\tsawUTSNS := false\n\tfor _, ns := range spec.Linux.Namespaces {\n\t\tswitch ns.Type {\n\t\tcase specs.CgroupNamespace:\n\t\t\tif ns.Path != \"\" {\n\t\t\t\tlogrus.Debugf(\"unable to join cgroup namespace, sorry about that\")\n\t\t\t} else {\n\t\t\t\tlogrus.Debugf(\"unable to create cgroup namespace, sorry about that\")\n\t\t\t}\n\t\tcase specs.IPCNamespace:\n\t\t\tif ns.Path != \"\" {\n\t\t\t\tlogrus.Debugf(\"unable to join IPC namespace, sorry about that\")\n\t\t\t} else {\n\t\t\t\tlogrus.Debugf(\"unable to create IPC namespace, sorry about that\")\n\t\t\t}\n\t\tcase specs.MountNamespace:\n\t\t\tif ns.Path != \"\" {\n\t\t\t\tlogrus.Debugf(\"unable to join mount namespace %q, creating a new one\", ns.Path)\n\t\t\t}\n\t\t\tsawMountNS = true\n\t\tcase specs.NetworkNamespace:\n\t\t\tif ns.Path != \"\" {\n\t\t\t\tlogrus.Debugf(\"unable to join network namespace, sorry about that\")\n\t\t\t} else {\n\t\t\t\tlogrus.Debugf(\"unable to create network namespace, sorry about that\")\n\t\t\t}\n\t\tcase specs.PIDNamespace:\n\t\t\tif ns.Path != \"\" {\n\t\t\t\tlogrus.Debugf(\"unable to join PID namespace, sorry about that\")\n\t\t\t} else {\n\t\t\t\tlogrus.Debugf(\"unable to create PID namespace, sorry about that\")\n\t\t\t}\n\t\tcase specs.UserNamespace:\n\t\t\tif ns.Path != \"\" {\n\t\t\t\tlogrus.Debugf(\"unable to join user namespace %q, creating a new one\", ns.Path)\n\t\t\t}\n\t\t\tsawUserNS = true\n\t\tcase specs.UTSNamespace:\n\t\t\tif ns.Path != \"\" {\n\t\t\t\tlogrus.Debugf(\"unable to join UTS namespace %q, creating a new one\", ns.Path)\n\t\t\t}\n\t\t\tsawUTSNS = true\n\t\t}\n\t}\n\tif !sawMountNS {\n\t\tlogrus.Debugf(\"mount namespace not requested, but creating a new one anyway\")\n\t}\n\tif !sawUserNS {\n\t\tlogrus.Debugf(\"user namespace not requested, but creating a new one anyway\")\n\t}\n\tif !sawUTSNS {\n\t\tlogrus.Debugf(\"UTS namespace not requested, but creating a new one anyway\")\n\t}\n}\n\n// setApparmorProfile sets the apparmor profile for ourselves, and hopefully any child processes that we'll start.\nfunc setApparmorProfile(spec *specs.Spec) error {\n\tif !apparmor.IsEnabled() || spec.Process.ApparmorProfile == \"\" {\n\t\treturn nil\n\t}\n\tif err := apparmor.ApplyProfile(spec.Process.ApparmorProfile); err != nil {\n\t\treturn errors.Wrapf(err, \"error setting apparmor profile to %q\", spec.Process.ApparmorProfile)\n\t}\n\treturn nil\n}\n\n// setCapabilities sets capabilities for ourselves, to be more or less inherited by any processes that we'll start.\nfunc setCapabilities(spec *specs.Spec, keepCaps ...string) error {\n\tcurrentCaps, err := capability.NewPid(0)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"error reading capabilities of current process\")\n\t}\n\tcaps, err := capability.NewPid(0)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"error reading capabilities of current process\")\n\t}\n\tcapMap := map[capability.CapType][]string{\n\t\tcapability.BOUNDING:    spec.Process.Capabilities.Bounding,\n\t\tcapability.EFFECTIVE:   spec.Process.Capabilities.Effective,\n\t\tcapability.INHERITABLE: spec.Process.Capabilities.Inheritable,\n\t\tcapability.PERMITTED:   spec.Process.Capabilities.Permitted,\n\t\tcapability.AMBIENT:     spec.Process.Capabilities.Ambient,\n\t}\n\tknownCaps := capability.List()\n\tcaps.Clear(capability.CAPS | capability.BOUNDS | capability.AMBS)\n\tfor capType, capList := range capMap {\n\t\tfor _, capToSet := range capList {\n\t\t\tcap := capability.CAP_LAST_CAP\n\t\t\tfor _, c := range knownCaps {\n\t\t\t\tif strings.EqualFold(\"CAP_\"+c.String(), capToSet) {\n\t\t\t\t\tcap = c\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif cap == capability.CAP_LAST_CAP {\n\t\t\t\treturn errors.Errorf(\"error mapping capability %q to a number\", capToSet)\n\t\t\t}\n\t\t\tcaps.Set(capType, cap)\n\t\t}\n\t\tfor _, capToSet := range keepCaps {\n\t\t\tcap := capability.CAP_LAST_CAP\n\t\t\tfor _, c := range knownCaps {\n\t\t\t\tif strings.EqualFold(\"CAP_\"+c.String(), capToSet) {\n\t\t\t\t\tcap = c\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif cap == capability.CAP_LAST_CAP {\n\t\t\t\treturn errors.Errorf(\"error mapping capability %q to a number\", capToSet)\n\t\t\t}\n\t\t\tif currentCaps.Get(capType, cap) {\n\t\t\t\tcaps.Set(capType, cap)\n\t\t\t}\n\t\t}\n\t}\n\tif err = caps.Apply(capability.CAPS | capability.BOUNDS | capability.AMBS); err != nil {\n\t\treturn errors.Wrapf(err, \"error setting capabilities\")\n\t}\n\treturn nil\n}\n\n// parses the resource limits for ourselves and any processes that\n// we'll start into a format that's more in line with the kernel APIs\nfunc parseRlimits(spec *specs.Spec) (map[int]unix.Rlimit, error) {\n\tif spec.Process == nil {\n\t\treturn nil, nil\n\t}\n\tparsed := make(map[int]unix.Rlimit)\n\tfor _, limit := range spec.Process.Rlimits {\n\t\tresource, recognized := rlimitsMap[strings.ToUpper(limit.Type)]\n\t\tif !recognized {\n\t\t\treturn nil, errors.Errorf(\"error parsing limit type %q\", limit.Type)\n\t\t}\n\t\tparsed[resource] = unix.Rlimit{Cur: limit.Soft, Max: limit.Hard}\n\t}\n\treturn parsed, nil\n}\n\n// setRlimits sets any resource limits that we want to apply to processes that\n// we'll start.\nfunc setRlimits(spec *specs.Spec, onlyLower, onlyRaise bool) error {\n\tlimits, err := parseRlimits(spec)\n\tif err != nil {\n\t\treturn err\n\t}\n\tfor resource, desired := range limits {\n\t\tvar current unix.Rlimit\n\t\tif err := unix.Getrlimit(resource, &current); err != nil {\n\t\t\treturn errors.Wrapf(err, \"error reading %q limit\", rlimitsReverseMap[resource])\n\t\t}\n\t\tif desired.Max > current.Max && onlyLower {\n\t\t\t// this would raise a hard limit, and we're only here to lower them\n\t\t\tcontinue\n\t\t}\n\t\tif desired.Max < current.Max && onlyRaise {\n\t\t\t// this would lower a hard limit, and we're only here to raise them\n\t\t\tcontinue\n\t\t}\n\t\tif err := unix.Setrlimit(resource, &desired); err != nil {\n\t\t\treturn errors.Wrapf(err, \"error setting %q limit to soft=%d,hard=%d (was soft=%d,hard=%d)\", rlimitsReverseMap[resource], desired.Cur, desired.Max, current.Cur, current.Max)\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc makeReadOnly(mntpoint string, flags uintptr) error {\n\tvar fs unix.Statfs_t\n\t// Make sure it's read-only.\n\tif err := unix.Statfs(mntpoint, &fs); err != nil {\n\t\treturn errors.Wrapf(err, \"error checking if directory %q was bound read-only\", mntpoint)\n\t}\n\tif fs.Flags&unix.ST_RDONLY == 0 {\n\t\tif err := unix.Mount(mntpoint, mntpoint, \"bind\", flags|unix.MS_REMOUNT, \"\"); err != nil {\n\t\t\treturn errors.Wrapf(err, \"error remounting %s in mount namespace read-only\", mntpoint)\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc isDevNull(dev os.FileInfo) bool {\n\tif dev.Mode()&os.ModeCharDevice != 0 {\n\t\tstat, _ := dev.Sys().(*syscall.Stat_t)\n\t\tnullStat := syscall.Stat_t{}\n\t\tif err := syscall.Stat(os.DevNull, &nullStat); err != nil {\n\t\t\tlogrus.Warnf(\"unable to stat /dev/null: %v\", err)\n\t\t\treturn false\n\t\t}\n\t\tif stat.Rdev == nullStat.Rdev {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// setupChrootBindMounts actually bind mounts things under the rootfs, and returns a\n// callback that will clean up its work.\nfunc setupChrootBindMounts(spec *specs.Spec, bundlePath string) (undoBinds func() error, err error) {\n\tvar fs unix.Statfs_t\n\tundoBinds = func() error {\n\t\tif err2 := unix.Unmount(spec.Root.Path, unix.MNT_DETACH); err2 != nil {\n\t\t\tretries := 0\n\t\t\tfor (err2 == unix.EBUSY || err2 == unix.EAGAIN) && retries < 50 {\n\t\t\t\ttime.Sleep(50 * time.Millisecond)\n\t\t\t\terr2 = unix.Unmount(spec.Root.Path, unix.MNT_DETACH)\n\t\t\t\tretries++\n\t\t\t}\n\t\t\tif err2 != nil {\n\t\t\t\tlogrus.Warnf(\"pkg/chroot: error unmounting %q (retried %d times): %v\", spec.Root.Path, retries, err2)\n\t\t\t\tif err == nil {\n\t\t\t\t\terr = err2\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn err\n\t}\n\n\t// Now bind mount all of those things to be under the rootfs's location in this\n\t// mount namespace.\n\tcommonFlags := uintptr(unix.MS_BIND | unix.MS_REC | unix.MS_PRIVATE)\n\tbindFlags := commonFlags | unix.MS_NODEV\n\tdevFlags := commonFlags | unix.MS_NOEXEC | unix.MS_NOSUID | unix.MS_RDONLY\n\tprocFlags := devFlags | unix.MS_NODEV\n\tsysFlags := devFlags | unix.MS_NODEV\n\n\t// Bind /dev read-only.\n\tsubDev := filepath.Join(spec.Root.Path, \"/dev\")\n\tif err := unix.Mount(\"/dev\", subDev, \"bind\", devFlags, \"\"); err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\terr = os.Mkdir(subDev, 0755)\n\t\t\tif err == nil {\n\t\t\t\terr = unix.Mount(\"/dev\", subDev, \"bind\", devFlags, \"\")\n\t\t\t}\n\t\t}\n\t\tif err != nil {\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error bind mounting /dev from host into mount namespace\")\n\t\t}\n\t}\n\t// Make sure it's read-only.\n\tif err = unix.Statfs(subDev, &fs); err != nil {\n\t\treturn undoBinds, errors.Wrapf(err, \"error checking if directory %q was bound read-only\", subDev)\n\t}\n\tif fs.Flags&unix.ST_RDONLY == 0 {\n\t\tif err := unix.Mount(subDev, subDev, \"bind\", devFlags|unix.MS_REMOUNT, \"\"); err != nil {\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error remounting /dev in mount namespace read-only\")\n\t\t}\n\t}\n\tlogrus.Debugf(\"bind mounted %q to %q\", \"/dev\", filepath.Join(spec.Root.Path, \"/dev\"))\n\n\t// Bind /proc read-only.\n\tsubProc := filepath.Join(spec.Root.Path, \"/proc\")\n\tif err := unix.Mount(\"/proc\", subProc, \"bind\", procFlags, \"\"); err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\terr = os.Mkdir(subProc, 0755)\n\t\t\tif err == nil {\n\t\t\t\terr = unix.Mount(\"/proc\", subProc, \"bind\", procFlags, \"\")\n\t\t\t}\n\t\t}\n\t\tif err != nil {\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error bind mounting /proc from host into mount namespace\")\n\t\t}\n\t}\n\tlogrus.Debugf(\"bind mounted %q to %q\", \"/proc\", filepath.Join(spec.Root.Path, \"/proc\"))\n\n\t// Bind /sys read-only.\n\tsubSys := filepath.Join(spec.Root.Path, \"/sys\")\n\tif err := unix.Mount(\"/sys\", subSys, \"bind\", sysFlags, \"\"); err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\terr = os.Mkdir(subSys, 0755)\n\t\t\tif err == nil {\n\t\t\t\terr = unix.Mount(\"/sys\", subSys, \"bind\", sysFlags, \"\")\n\t\t\t}\n\t\t}\n\t\tif err != nil {\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error bind mounting /sys from host into mount namespace\")\n\t\t}\n\t}\n\tif err := makeReadOnly(subSys, sysFlags); err != nil {\n\t\treturn undoBinds, err\n\t}\n\n\tmnts, _ := mount.GetMounts()\n\tfor _, m := range mnts {\n\t\tif !strings.HasPrefix(m.Mountpoint, \"/sys/\") &&\n\t\t\tm.Mountpoint != \"/sys\" {\n\t\t\tcontinue\n\t\t}\n\t\tsubSys := filepath.Join(spec.Root.Path, m.Mountpoint)\n\t\tif err := unix.Mount(m.Mountpoint, subSys, \"bind\", sysFlags, \"\"); err != nil {\n\t\t\tmsg := fmt.Sprintf(\"could not bind mount %q, skipping: %v\", m.Mountpoint, err)\n\t\t\tif strings.HasPrefix(m.Mountpoint, \"/sys\") {\n\t\t\t\tlogrus.Infof(msg)\n\t\t\t} else {\n\t\t\t\tlogrus.Warningf(msg)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\tif err := makeReadOnly(subSys, sysFlags); err != nil {\n\t\t\treturn undoBinds, err\n\t\t}\n\t}\n\tlogrus.Debugf(\"bind mounted %q to %q\", \"/sys\", filepath.Join(spec.Root.Path, \"/sys\"))\n\n\t// Bind mount in everything we've been asked to mount.\n\tfor _, m := range spec.Mounts {\n\t\t// Skip anything that we just mounted.\n\t\tswitch m.Destination {\n\t\tcase \"/dev\", \"/proc\", \"/sys\":\n\t\t\tlogrus.Debugf(\"already bind mounted %q on %q\", m.Destination, filepath.Join(spec.Root.Path, m.Destination))\n\t\t\tcontinue\n\t\tdefault:\n\t\t\tif strings.HasPrefix(m.Destination, \"/dev/\") {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif strings.HasPrefix(m.Destination, \"/proc/\") {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif strings.HasPrefix(m.Destination, \"/sys/\") {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\t// Skip anything that isn't a bind or tmpfs mount.\n\t\tif m.Type != \"bind\" && m.Type != \"tmpfs\" && m.Type != \"overlay\" {\n\t\t\tlogrus.Debugf(\"skipping mount of type %q on %q\", m.Type, m.Destination)\n\t\t\tcontinue\n\t\t}\n\t\t// If the target is there, we can just mount it.\n\t\tvar srcinfo os.FileInfo\n\t\tswitch m.Type {\n\t\tcase \"bind\":\n\t\t\tsrcinfo, err = os.Stat(m.Source)\n\t\t\tif err != nil {\n\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error examining %q for mounting in mount namespace\", m.Source)\n\t\t\t}\n\t\tcase \"overlay\":\n\t\t\tfallthrough\n\t\tcase \"tmpfs\":\n\t\t\tsrcinfo, err = os.Stat(\"/\")\n\t\t\tif err != nil {\n\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error examining / to use as a template for a %s\", m.Type)\n\t\t\t}\n\t\t}\n\t\ttarget := filepath.Join(spec.Root.Path, m.Destination)\n\t\t// Check if target is a symlink\n\t\tstat, err := os.Lstat(target)\n\t\t// If target is a symlink, follow the link and ensure the destination exists\n\t\tif err == nil && stat != nil && (stat.Mode()&os.ModeSymlink != 0) {\n\t\t\ttarget, err = copier.Eval(spec.Root.Path, m.Destination, copier.EvalOptions{})\n\t\t\tif err != nil {\n\t\t\t\treturn nil, errors.Wrapf(err, \"evaluating symlink %q\", target)\n\t\t\t}\n\t\t\t// Stat the destination of the evaluated symlink\n\t\t\t_, err = os.Stat(target)\n\t\t}\n\t\tif err != nil {\n\t\t\t// If the target can't be stat()ted, check the error.\n\t\t\tif !os.IsNotExist(err) {\n\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error examining %q for mounting in mount namespace\", target)\n\t\t\t}\n\t\t\t// The target isn't there yet, so create it.\n\t\t\tif srcinfo.IsDir() {\n\t\t\t\tif err = os.MkdirAll(target, 0755); err != nil {\n\t\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error creating mountpoint %q in mount namespace\", target)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif err = os.MkdirAll(filepath.Dir(target), 0755); err != nil {\n\t\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error ensuring parent of mountpoint %q (%q) is present in mount namespace\", target, filepath.Dir(target))\n\t\t\t\t}\n\t\t\t\tvar file *os.File\n\t\t\t\tif file, err = os.OpenFile(target, os.O_WRONLY|os.O_CREATE, 0755); err != nil {\n\t\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error creating mountpoint %q in mount namespace\", target)\n\t\t\t\t}\n\t\t\t\tfile.Close()\n\t\t\t}\n\t\t}\n\t\trequestFlags := bindFlags\n\t\texpectedFlags := uintptr(0)\n\t\tif util.StringInSlice(\"nodev\", m.Options) {\n\t\t\trequestFlags |= unix.MS_NODEV\n\t\t\texpectedFlags |= unix.ST_NODEV\n\t\t}\n\t\tif util.StringInSlice(\"noexec\", m.Options) {\n\t\t\trequestFlags |= unix.MS_NOEXEC\n\t\t\texpectedFlags |= unix.ST_NOEXEC\n\t\t}\n\t\tif util.StringInSlice(\"nosuid\", m.Options) {\n\t\t\trequestFlags |= unix.MS_NOSUID\n\t\t\texpectedFlags |= unix.ST_NOSUID\n\t\t}\n\t\tif util.StringInSlice(\"ro\", m.Options) {\n\t\t\trequestFlags |= unix.MS_RDONLY\n\t\t\texpectedFlags |= unix.ST_RDONLY\n\t\t}\n\t\tswitch m.Type {\n\t\tcase \"bind\":\n\t\t\t// Do the bind mount.\n\t\t\tlogrus.Debugf(\"bind mounting %q on %q\", m.Destination, filepath.Join(spec.Root.Path, m.Destination))\n\t\t\tif err := unix.Mount(m.Source, target, \"\", requestFlags, \"\"); err != nil {\n\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error bind mounting %q from host to %q in mount namespace (%q)\", m.Source, m.Destination, target)\n\t\t\t}\n\t\t\tlogrus.Debugf(\"bind mounted %q to %q\", m.Source, target)\n\t\tcase \"tmpfs\":\n\t\t\t// Mount a tmpfs.\n\t\t\tif err := mount.Mount(m.Source, target, m.Type, strings.Join(append(m.Options, \"private\"), \",\")); err != nil {\n\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error mounting tmpfs to %q in mount namespace (%q, %q)\", m.Destination, target, strings.Join(m.Options, \",\"))\n\t\t\t}\n\t\t\tlogrus.Debugf(\"mounted a tmpfs to %q\", target)\n\t\tcase \"overlay\":\n\t\t\t// Mount a overlay.\n\t\t\tif err := mount.Mount(m.Source, target, m.Type, strings.Join(append(m.Options, \"private\"), \",\")); err != nil {\n\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error mounting overlay to %q in mount namespace (%q, %q)\", m.Destination, target, strings.Join(m.Options, \",\"))\n\t\t\t}\n\t\t\tlogrus.Debugf(\"mounted a overlay to %q\", target)\n\t\t}\n\t\tif err = unix.Statfs(target, &fs); err != nil {\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error checking if directory %q was bound read-only\", target)\n\t\t}\n\t\tif uintptr(fs.Flags)&expectedFlags != expectedFlags {\n\t\t\tif err := unix.Mount(target, target, \"bind\", requestFlags|unix.MS_REMOUNT, \"\"); err != nil {\n\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error remounting %q in mount namespace with expected flags\", target)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Set up any read-only paths that we need to.  If we're running inside\n\t// of a container, some of these locations will already be read-only.\n\tfor _, roPath := range spec.Linux.ReadonlyPaths {\n\t\tr := filepath.Join(spec.Root.Path, roPath)\n\t\ttarget, err := filepath.EvalSymlinks(r)\n\t\tif err != nil {\n\t\t\tif os.IsNotExist(err) {\n\t\t\t\t// No target, no problem.\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error checking %q for symlinks before marking it read-only\", r)\n\t\t}\n\t\t// Check if the location is already read-only.\n\t\tvar fs unix.Statfs_t\n\t\tif err = unix.Statfs(target, &fs); err != nil {\n\t\t\tif os.IsNotExist(err) {\n\t\t\t\t// No target, no problem.\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error checking if directory %q is already read-only\", target)\n\t\t}\n\t\tif fs.Flags&unix.ST_RDONLY != 0 {\n\t\t\tcontinue\n\t\t}\n\t\t// Mount the location over itself, so that we can remount it as read-only.\n\t\troFlags := uintptr(unix.MS_NODEV | unix.MS_NOEXEC | unix.MS_NOSUID | unix.MS_RDONLY)\n\t\tif err := unix.Mount(target, target, \"\", roFlags|unix.MS_BIND|unix.MS_REC, \"\"); err != nil {\n\t\t\tif os.IsNotExist(err) {\n\t\t\t\t// No target, no problem.\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error bind mounting %q onto itself in preparation for making it read-only\", target)\n\t\t}\n\t\t// Remount the location read-only.\n\t\tif err = unix.Statfs(target, &fs); err != nil {\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error checking if directory %q was bound read-only\", target)\n\t\t}\n\t\tif fs.Flags&unix.ST_RDONLY == 0 {\n\t\t\tif err := unix.Mount(target, target, \"\", roFlags|unix.MS_BIND|unix.MS_REMOUNT, \"\"); err != nil {\n\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error remounting %q in mount namespace read-only\", target)\n\t\t\t}\n\t\t}\n\t\t// Check again.\n\t\tif err = unix.Statfs(target, &fs); err != nil {\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error checking if directory %q was remounted read-only\", target)\n\t\t}\n\t\tif fs.Flags&unix.ST_RDONLY == 0 {\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error verifying that %q in mount namespace was remounted read-only\", target)\n\t\t}\n\t}\n\n\t// Create an empty directory for to use for masking directories.\n\troEmptyDir := filepath.Join(bundlePath, \"empty\")\n\tif len(spec.Linux.MaskedPaths) > 0 {\n\t\tif err := os.Mkdir(roEmptyDir, 0700); err != nil {\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error creating empty directory %q\", roEmptyDir)\n\t\t}\n\t}\n\n\t// Set up any masked paths that we need to.  If we're running inside of\n\t// a container, some of these locations will already be read-only tmpfs\n\t// filesystems or bind mounted to os.DevNull.  If we're not running\n\t// inside of a container, and nobody else has done that, we'll do it.\n\tfor _, masked := range spec.Linux.MaskedPaths {\n\t\tt := filepath.Join(spec.Root.Path, masked)\n\t\ttarget, err := filepath.EvalSymlinks(t)\n\t\tif err != nil {\n\t\t\ttarget = t\n\t\t}\n\t\t// Get some info about the target.\n\t\ttargetinfo, err := os.Stat(target)\n\t\tif err != nil {\n\t\t\tif os.IsNotExist(err) {\n\t\t\t\t// No target, no problem.\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error examining %q for masking in mount namespace\", target)\n\t\t}\n\t\tif targetinfo.IsDir() {\n\t\t\t// The target's a directory.  Check if it's a read-only filesystem.\n\t\t\tvar statfs unix.Statfs_t\n\t\t\tif err = unix.Statfs(target, &statfs); err != nil {\n\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error checking if directory %q is a mountpoint\", target)\n\t\t\t}\n\t\t\tisReadOnly := statfs.Flags&unix.MS_RDONLY != 0\n\t\t\t// Check if any of the IDs we're mapping could read it.\n\t\t\tvar stat unix.Stat_t\n\t\t\tif err = unix.Stat(target, &stat); err != nil {\n\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error checking permissions on directory %q\", target)\n\t\t\t}\n\t\t\tisAccessible := false\n\t\t\tif stat.Mode&unix.S_IROTH|unix.S_IXOTH != 0 {\n\t\t\t\tisAccessible = true\n\t\t\t}\n\t\t\tif !isAccessible && stat.Mode&unix.S_IROTH|unix.S_IXOTH != 0 {\n\t\t\t\tif len(spec.Linux.GIDMappings) > 0 {\n\t\t\t\t\tfor _, mapping := range spec.Linux.GIDMappings {\n\t\t\t\t\t\tif stat.Gid >= mapping.ContainerID && stat.Gid < mapping.ContainerID+mapping.Size {\n\t\t\t\t\t\t\tisAccessible = true\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !isAccessible && stat.Mode&unix.S_IRUSR|unix.S_IXUSR != 0 {\n\t\t\t\tif len(spec.Linux.UIDMappings) > 0 {\n\t\t\t\t\tfor _, mapping := range spec.Linux.UIDMappings {\n\t\t\t\t\t\tif stat.Uid >= mapping.ContainerID && stat.Uid < mapping.ContainerID+mapping.Size {\n\t\t\t\t\t\t\tisAccessible = true\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Check if it's empty.\n\t\t\thasContent := false\n\t\t\tdirectory, err := os.Open(target)\n\t\t\tif err != nil {\n\t\t\t\tif !os.IsPermission(err) {\n\t\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error opening directory %q\", target)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tnames, err := directory.Readdirnames(0)\n\t\t\t\tdirectory.Close()\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error reading contents of directory %q\", target)\n\t\t\t\t}\n\t\t\t\thasContent = false\n\t\t\t\tfor _, name := range names {\n\t\t\t\t\tswitch name {\n\t\t\t\t\tcase \".\", \"..\":\n\t\t\t\t\t\tcontinue\n\t\t\t\t\tdefault:\n\t\t\t\t\t\thasContent = true\n\t\t\t\t\t}\n\t\t\t\t\tif hasContent {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t// The target's a directory, so read-only bind mount an empty directory on it.\n\t\t\troFlags := uintptr(syscall.MS_BIND | syscall.MS_NOSUID | syscall.MS_NODEV | syscall.MS_NOEXEC | syscall.MS_RDONLY)\n\t\t\tif !isReadOnly || (hasContent && isAccessible) {\n\t\t\t\tif err = unix.Mount(roEmptyDir, target, \"bind\", roFlags, \"\"); err != nil {\n\t\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error masking directory %q in mount namespace\", target)\n\t\t\t\t}\n\t\t\t\tif err = unix.Statfs(target, &fs); err != nil {\n\t\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error checking if directory %q was mounted read-only in mount namespace\", target)\n\t\t\t\t}\n\t\t\t\tif fs.Flags&unix.ST_RDONLY == 0 {\n\t\t\t\t\tif err = unix.Mount(target, target, \"\", roFlags|syscall.MS_REMOUNT, \"\"); err != nil {\n\t\t\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error making sure directory %q in mount namespace is read only\", target)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\t// If the target's is not a directory or os.DevNull, bind mount os.DevNull over it.\n\t\t\tif !isDevNull(targetinfo) {\n\t\t\t\tif err = unix.Mount(os.DevNull, target, \"\", uintptr(syscall.MS_BIND|syscall.MS_RDONLY|syscall.MS_PRIVATE), \"\"); err != nil {\n\t\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error masking non-directory %q in mount namespace\", target)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn undoBinds, nil\n}\n", "# buildah-bud \"1\" \"April 2017\" \"buildah\"\n\n## NAME\nbuildah\\-bud - Build an image using instructions from Containerfiles\n\n## SYNOPSIS\n\n**buildah build-using-dockerfile** [*options*] [*context*]\n\n**buildah bud** [*options*] [*context*]\n\n**bud** is an alias for **build-using-dockerfile**.\n\n## DESCRIPTION\nBuilds an image using instructions from one or more Containerfiles or Dockerfiles and a specified\nbuild context directory.  A Containerfile uses the same syntax as a Dockerfile internally.  For this\ndocument, a file referred to as a Containerfile can be a file named either 'Containerfile' or 'Dockerfile'.\n\nThe build context directory can be specified as the http(s) URL of an archive, git repository or Containerfile.\n\nIf no context directory is specified, then Buildah will assume the current working directory as build context, which should contain a Containerfile.\n\nContainerfiles ending with a \".in\" suffix will be preprocessed via cpp(1).  This can be useful to decompose Containerfiles into several reusable parts that can be used via CPP's **#include** directive.  Notice, a Containerfile.in file can still be used by other tools when manually preprocessing them via `cpp -E`. Any comments ( Lines beginning with `#` ) in included Containerfile(s) that are not preprocess commands, will be printed as warnings during builds.\n\nWhen the URL is an archive, the contents of the URL is downloaded to a temporary location and extracted before execution.\n\nWhen the URL is a Containerfile, the file is downloaded to a temporary location.\n\nWhen a Git repository is set as the URL, the repository is cloned locally and then set as the context.\n\n## OPTIONS\n\n**--add-host**=[]\n\nAdd a custom host-to-IP mapping (host:ip)\n\nAdd a line to /etc/hosts. The format is hostname:ip. The **--add-host** option can be set multiple times.\n\n**--annotation** *annotation*\n\nAdd an image *annotation* (e.g. annotation=*value*) to the image metadata. Can be used multiple times.\n\nNote: this information is not present in Docker image formats, so it is discarded when writing images in Docker formats.\n\n**--arch**=\"ARCH\"\n\nSet the ARCH of the image to be pulled to the provided value instead of using the architecture of the host. (Examples: aarch64, arm, i686, ppc64le, s390x, x86_64)\n\n**--authfile** *path*\n\nPath of the authentication file. Default is ${XDG_\\RUNTIME\\_DIR}/containers/auth.json. If XDG_RUNTIME_DIR is not set, the default is /run/containers/$UID/auth.json. This file is created using using `buildah login`.\n\nIf the authorization state is not found there, $HOME/.docker/config.json is checked, which is set using `docker login`.\n\nNote: You can also override the default path of the authentication file by setting the REGISTRY\\_AUTH\\_FILE\nenvironment variable. `export REGISTRY_AUTH_FILE=path`\n\n**--build-arg** *arg=value*\n\nSpecifies a build argument and its value, which will be interpolated in\ninstructions read from the Containerfiles in the same way that environment\nvariables are, but which will not be added to environment variable list in the\nresulting image's configuration.\n\nPlease refer to the [BUILD TIME VARIABLES](#build-time-variables) section for the\nlist of variables that can be overridden within the Containerfile at run time.\n\n**--cache-from**\n\nImages to utilise as potential cache sources. Buildah does not currently support --cache-from so this is a NOOP.\n\n**--cap-add**=*CAP\\_xxx*\n\nWhen executing RUN instructions, run the command specified in the instruction\nwith the specified capability added to its capability set.\nCertain capabilities are granted by default; this option can be used to add\nmore.\n\n**--cap-drop**=*CAP\\_xxx*\n\nWhen executing RUN instructions, run the command specified in the instruction\nwith the specified capability removed from its capability set.\nThe CAP\\_AUDIT\\_WRITE, CAP\\_CHOWN, CAP\\_DAC\\_OVERRIDE, CAP\\_FOWNER,\nCAP\\_FSETID, CAP\\_KILL, CAP\\_MKNOD, CAP\\_NET\\_BIND\\_SERVICE, CAP\\_SETFCAP,\nCAP\\_SETGID, CAP\\_SETPCAP, CAP\\_SETUID, and CAP\\_SYS\\_CHROOT capabilities are\ngranted by default; this option can be used to remove them.\n\nIf a capability is specified to both the **--cap-add** and **--cap-drop**\noptions, it will be dropped, regardless of the order in which the options were\ngiven.\n\n**--cert-dir** *path*\n\nUse certificates at *path* (\\*.crt, \\*.cert, \\*.key) to connect to the registry.\nThe default certificates directory is _/etc/containers/certs.d_.\n\n**--cgroup-parent**=\"\"\n\nPath to cgroups under which the cgroup for the container will be created. If the path is not absolute, the path is considered to be relative to the cgroups path of the init process. Cgroups will be created if they do not already exist.\n\n**--compress**\n\nThis option is added to be aligned with other containers CLIs.\nBuildah doesn't send a copy of the context directory to a daemon or a remote server.\nThus, compressing the data before sending it is irrelevant to Buildah.\n\n**--cni-config-dir**=*directory*\n\nLocation of CNI configuration files which will dictate which plugins will be\nused to configure network interfaces and routing for containers created for\nhandling `RUN` instructions, if those containers will be run in their own\nnetwork namespaces, and networking is not disabled.\n\n**--cni-plugin-path**=*directory[:directory[:directory[...]]]*\n\nList of directories in which the CNI plugins which will be used for configuring\nnetwork namespaces can be found.\n\n**--cpu-period**=*0*\n\nSet the CPU period for the Completely Fair Scheduler (CFS), which is a\nduration in microseconds. Once the container's CPU quota is used up, it will\nnot be scheduled to run until the current period ends. Defaults to 100000\nmicroseconds.\n\nOn some systems, changing the CPU limits may not be allowed for non-root\nusers. For more details, see\nhttps://github.com/containers/podman/blob/main/troubleshooting.md#26-running-containers-with-cpu-limits-fails-with-a-permissions-error\n\n**--cpu-quota**=*0*\n\nLimit the CPU CFS (Completely Fair Scheduler) quota\n\nLimit the container's CPU usage. By default, containers run with the full\nCPU resource. This flag tell the kernel to restrict the container's CPU usage\nto the quota you specify.\n\nOn some systems, changing the CPU limits may not be allowed for non-root\nusers. For more details, see\nhttps://github.com/containers/podman/blob/main/troubleshooting.md#26-running-containers-with-cpu-limits-fails-with-a-permissions-error\n\n**--cpu-shares**, **-c**=*0*\n\nCPU shares (relative weight)\n\nBy default, all containers get the same proportion of CPU cycles. This proportion\ncan be modified by changing the container's CPU share weighting relative\nto the weighting of all other running containers.\n\nTo modify the proportion from the default of 1024, use the **--cpu-shares**\nflag to set the weighting to 2 or higher.\n\nThe proportion will only apply when CPU-intensive processes are running.\nWhen tasks in one container are idle, other containers can use the\nleft-over CPU time. The actual amount of CPU time will vary depending on\nthe number of containers running on the system.\n\nFor example, consider three containers, one has a cpu-share of 1024 and\ntwo others have a cpu-share setting of 512. When processes in all three\ncontainers attempt to use 100% of CPU, the first container would receive\n50% of the total CPU time. If you add a fourth container with a cpu-share\nof 1024, the first container only gets 33% of the CPU. The remaining containers\nreceive 16.5%, 16.5% and 33% of the CPU.\n\nOn a multi-core system, the shares of CPU time are distributed over all CPU\ncores. Even if a container is limited to less than 100% of CPU time, it can\nuse 100% of each individual CPU core.\n\nFor example, consider a system with more than three cores. If you start one\ncontainer **{C0}** with **-c=512** running one process, and another container\n**{C1}** with **-c=1024** running two processes, this can result in the following\ndivision of CPU shares:\n\n    PID    container\tCPU\tCPU share\n    100    {C0}\t\t0\t100% of CPU0\n    101    {C1}\t\t1\t100% of CPU1\n    102    {C1}\t\t2\t100% of CPU2\n\n**--cpuset-cpus**=\"\"\n\n  CPUs in which to allow execution (0-3, 0,1)\n\n**--cpuset-mems**=\"\"\n\nMemory nodes (MEMs) in which to allow execution (0-3, 0,1). Only effective on NUMA systems.\n\nIf you have four memory nodes on your system (0-3), use `--cpuset-mems=0,1`\nthen processes in your container will only use memory from the first\ntwo memory nodes.\n\n**--creds** *creds*\n\nThe [username[:password]] to use to authenticate with the registry if required.\nIf one or both values are not supplied, a command line prompt will appear and the\nvalue can be entered.  The password is entered without echo.\n\n**--decryption-key** *key[:passphrase]*\n\nThe [key[:passphrase]] to be used for decryption of images. Key can point to keys and/or certificates. Decryption will be tried with all keys. If the key is protected by a passphrase, it is required to be passed in the argument and omitted otherwise.\n\n**--device**=*device*\n\nAdd a host device to the container. Optional *permissions* parameter\ncan be used to specify device permissions, it is combination of\n**r** for read, **w** for write, and **m** for **mknod**(2).\n\nExample: **--device=/dev/sdc:/dev/xvdc:rwm**.\n\nNote: if _host_device_ is a symbolic link then it will be resolved first.\nThe container will only store the major and minor numbers of the host device.\n\nNote: if the user only has access rights via a group, accessing the device\nfrom inside a rootless container will fail. The **crun**(1) runtime offers a\nworkaround for this by adding the option **--annotation run.oci.keep_original_groups=1**.\n\n**--disable-compression**, **-D**\nDon't compress filesystem layers when building the image unless it is required\nby the location where the image is being written.  This is the default setting,\nbecause image layers are compressed automatically when they are pushed to\nregistries, and images being written to local storage would only need to be\ndecompressed again to be stored.  Compression can be forced in all cases by\nspecifying **--disable-compression=false**.\n\n**--disable-content-trust**\n\nThis is a Docker specific option to disable image verification to a Docker\nregistry and is not supported by Buildah.  This flag is a NOOP and provided\nsolely for scripting compatibility.\n\n**--dns**=[]\n\nSet custom DNS servers\n\nThis option can be used to override the DNS configuration passed to the container. Typically this is necessary when the host DNS configuration is invalid for the container (e.g., 127.0.0.1). When this is the case the `--dns` flag is necessary for every run.\n\nThe special value **none** can be specified to disable creation of /etc/resolv.conf in the container by Buildah. The /etc/resolv.conf file in the image will be used without changes.\n\n**--dns-option**=[]\n\nSet custom DNS options\n\n**--dns-search**=[]\n\nSet custom DNS search domains\n\n**--file**, **-f** *Containerfile*\n\nSpecifies a Containerfile which contains instructions for building the image,\neither a local file or an **http** or **https** URL.  If more than one\nContainerfile is specified, *FROM* instructions will only be accepted from the\nfirst specified file.\n\nIf a local file is specified as the Containerfile and it does not exist, the\ncontext directory will be prepended to the local file value.\n\nIf you specify `-f -`, the Containerfile contents will be read from stdin.\n\n**--force-rm** *bool-value*\n\nAlways remove intermediate containers after a build, even if the build fails (default false).\n\n**--format**\n\nControl the format for the built image's manifest and configuration data.\nRecognized formats include *oci* (OCI image-spec v1.0, the default) and\n*docker* (version 2, using schema format 2 for the manifest).\n\nNote: You can also override the default format by setting the BUILDAH\\_FORMAT\nenvironment variable.  `export BUILDAH_FORMAT=docker`\n\n**--from**\n\nOverrides the first `FROM` instruction within the Containerfile.  If there are multiple\nFROM instructions in a Containerfile, only the first is changed.\n\n**-h**, **--help**\n\nPrint usage statement\n\n**--http-proxy**=true\n\nBy default proxy environment variables are passed into the container if set\nfor the buildah process.  This can be disabled by setting the `--http-proxy`\noption to `false`.  The environment variables passed in include `http_proxy`,\n`https_proxy`, `ftp_proxy`, `no_proxy`, and also the upper case versions of\nthose.\n\n**--iidfile** *ImageIDfile*\n\nWrite the image ID to the file.\n\n**--ignorefile** *file*\n\nPath to an alternative .containerignore (.dockerignore) file.\n\n**--ipc** *how*\n\nSets the configuration for IPC namespaces when handling `RUN` instructions.\nThe configured value can be \"\" (the empty string) or \"container\" to indicate\nthat a new IPC namespace should be created, or it can be \"host\" to indicate\nthat the IPC namespace in which `buildah` itself is being run should be reused,\nor it can be the path to an IPC namespace which is already in use by\nanother process.\n\n**--isolation** *type*\n\nControls what type of isolation is used for running processes as part of `RUN`\ninstructions.  Recognized types include *oci* (OCI-compatible runtime, the\ndefault), *rootless* (OCI-compatible runtime invoked using a modified\nconfiguration, with *--no-new-keyring* added to its *create*\ninvocation, with network and UTS namespaces disabled, and IPC, PID,\nand user namespaces enabled; the default for unprivileged users), and\n*chroot* (an internal wrapper that leans more toward chroot(1) than\ncontainer technology).\n\nNote: You can also override the default isolation type by setting the\nBUILDAH\\_ISOLATION environment variable.  `export BUILDAH_ISOLATION=oci`\n\n**--jobs** *N*\n\nRun up to N concurrent stages in parallel.  If the number of jobs is greater than 1,\nstdin will be read from /dev/null.  If 0 is specified, then there is\nno limit in the number of jobs that run in parallel.\n\n**--label** *label*\n\nAdd an image *label* (e.g. label=*value*) to the image metadata. Can be used multiple times.\n\nUsers can set a special LABEL **io.containers.capabilities=CAP1,CAP2,CAP3** in\na Containerfile that specified the list of Linux capabilities required for the\ncontainer to run properly. This label specified in a container image tells\ncontainer engines, like Podman, to run the container with just these\ncapabilities. The container engine launches the container with just the specified\ncapabilities, as long as this list of capabilities is a subset of the default\nlist.\n\nIf the specified capabilities are not in the default set, container engines\nshould print an error message and will run the container with the default\ncapabilities.\n\n**--layers** *bool-value*\n\nCache intermediate images during the build process (Default is `false`).\n\nNote: You can also override the default value of layers by setting the BUILDAH\\_LAYERS\nenvironment variable. `export BUILDAH_LAYERS=true`\n\n**--logfile** *filename*\n\nLog output which would be sent to standard output and standard error to the\nspecified file instead of to standard output and standard error.\n\n**--manifest** \"manifest\"\n\nName of the manifest list to which the image will be added. Creates the manifest list\nif it does not exist. This option is useful for building multi architecture images.\n\n**--memory**, **-m**=\"\"\n\nMemory limit (format: <number>[<unit>], where unit = b, k, m or g)\n\nAllows you to constrain the memory available to a container. If the host\nsupports swap memory, then the **-m** memory setting can be larger than physical\nRAM. If a limit of 0 is specified (not using **-m**), the container's memory is\nnot limited. The actual limit may be rounded up to a multiple of the operating\nsystem's page size (the value would be very large, that's millions of trillions).\n\n**--memory-swap**=\"LIMIT\"\n\nA limit value equal to memory plus swap. Must be used with the  **-m**\n(**--memory**) flag. The swap `LIMIT` should always be larger than **-m**\n(**--memory**) value.  By default, the swap `LIMIT` will be set to double\nthe value of --memory.\n\nThe format of `LIMIT` is `<number>[<unit>]`. Unit can be `b` (bytes),\n`k` (kilobytes), `m` (megabytes), or `g` (gigabytes). If you don't specify a\nunit, `b` is used. Set LIMIT to `-1` to enable unlimited swap.\n\n**--network**, **--net**=*mode*\n\nSets the configuration for network namespaces when handling `RUN` instructions.\n\nValid _mode_ values are:\n\n- **none**: no networking;\n- **host**: use the host network stack. Note: the host mode gives the container full access to local system services such as D-bus and is therefore considered insecure;\n- **ns:**_path_: path to a network namespace to join;\n- `private`: create a new namespace for the container (default)\n\n**--no-cache**\n\nDo not use existing cached images for the container build. Build from the start with a new set of cached layers.\n\n**--os**=\"OS\"\n\nSet the OS of the image to be pulled instead of using the current operating system of the host.\n\n**--pid** *how*\n\nSets the configuration for PID namespaces when handling `RUN` instructions.\nThe configured value can be \"\" (the empty string) or \"private\" to indicate\nthat a new PID namespace should be created, or it can be \"host\" to indicate\nthat the PID namespace in which `buildah` itself is being run should be reused,\nor it can be the path to a PID namespace which is already in use by another\nprocess.\n\n**--platform**=\"OS/ARCH\"\n\nSet the OS/ARCH of the image to the provided value instead of using the current\noperating system and architecture of the host (for example `linux/arm`). If\n`--platform` is set, then the values of the `--arch` and `--os` options will be\noverridden.\n\n**--pull**\n\nWhen the flag is enabled, attempt to pull the latest image from the registries\nlisted in registries.conf if a local image does not exist or the image is newer\nthan the one in storage. Raise an error if the image is not in any listed\nregistry and is not present locally.\n\nIf the flag is disabled (with *--pull=false*), do not pull the image from the\nregistry, unless there is no local image. Raise an error if the image is not\nin any registry and is not present locally.\n\nDefaults to *true*.\n\n**--pull-always**\n\nPull the image from the first registry it is found in as listed in registries.conf.\nRaise an error if not found in the registries, even if the image is present locally.\n\n**--pull-never**\n\nDo not pull the image from the registry, use only the local version. Raise an error\nif the image is not present locally.\n\n**--quiet**, **-q**\n\nSuppress output messages which indicate which instruction is being processed,\nand of progress when pulling images from a registry, and when writing the\noutput image.\n\n**--rm** *bool-value*\n\nRemove intermediate containers after a successful build (default true).\n\n**--runtime** *path*\n\nThe *path* to an alternate OCI-compatible runtime, which will be used to run\ncommands specified by the **RUN** instruction. Default is `runc`, or `crun` when machine is configured to use cgroups V2.\n\nNote: You can also override the default runtime by setting the BUILDAH\\_RUNTIME\nenvironment variable.  `export BUILDAH_RUNTIME=/usr/bin/crun`\n\n**--runtime-flag** *flag*\n\nAdds global flags for the container rutime. To list the supported flags, please\nconsult the manpages of the selected container runtime.\n\nNote: Do not pass the leading `--` to the flag. To pass the runc flag `--log-format json`\nto buildah bud, the option given would be `--runtime-flag log-format=json`.\n\n**--secret**=**id=id,src=path**\nPass secret information to be used in the Containerfile for building images\nin a safe way that will not end up stored in the final image, or be seen in other stages.\nThe secret will be mounted in the container at the default location of `/run/secrets/id`.\n\nTo later use the secret, use the --mount flag in a `RUN` instruction within a `Containerfile`:\n\n`RUN --mount=type=secret,id=mysecret cat /run/secrets/mysecret`\n\n**--security-opt**=[]\n\nSecurity Options\n\n  \"apparmor=unconfined\" : Turn off apparmor confinement for the container\n  \"apparmor=your-profile\" : Set the apparmor confinement profile for the container\n\n  \"label=user:USER\"   : Set the label user for the container\n  \"label=role:ROLE\"   : Set the label role for the container\n  \"label=type:TYPE\"   : Set the label type for the container\n  \"label=level:LEVEL\" : Set the label level for the container\n  \"label=disable\"     : Turn off label confinement for the container\n  \"no-new-privileges\" : Not supported\n\n  \"seccomp=unconfined\" : Turn off seccomp confinement for the container\n  \"seccomp=profile.json :  White listed syscalls seccomp Json file to be used as a seccomp filter\n\n**--shm-size**=\"\"\n\nSize of `/dev/shm`. The format is `<number><unit>`. `number` must be greater than `0`.\nUnit is optional and can be `b` (bytes), `k` (kilobytes), `m`(megabytes), or `g` (gigabytes).\nIf you omit the unit, the system uses bytes. If you omit the size entirely, the system uses `64m`.\n\n**--sign-by** *fingerprint*\n\nSign the built image using the GPG key that matches the specified fingerprint.\n\n**--squash**\n\nSquash all of the image's new layers into a single new layer; any preexisting layers\nare not squashed.\n\n**--stdin**\n\nPass stdin into the RUN containers. Sometime commands being RUN within a Containerfile\nwant to request information from the user. For example apt asking for a confirmation for install.\nUse --stdin to be able to interact from the terminal during the build.\n\n**--tag**, **-t** *imageName*\n\nSpecifies the name which will be assigned to the resulting image if the build\nprocess completes successfully.\nIf _imageName_ does not include a registry name, the registry name *localhost* will be prepended to the image name.\n\n**--target** *stageName*\n\nSet the target build stage to build.  When building a Containerfile with multiple build stages, --target\ncan be used to specify an intermediate build stage by name as the final stage for the resulting image.\nCommands after the target stage will be skipped.\n\n**--timestamp** *seconds*\n\nSet the create timestamp to seconds since epoch to allow for deterministic builds (defaults to current time).\nBy default, the created timestamp is changed and written into the image manifest with every commit,\ncausing the image's sha256 hash to be different even if the sources are exactly the same otherwise.\nWhen --timestamp is set, the created timestamp is always set to the time specified and therefore not changed, allowing the image's sha256 to remain the same. All files committed to the layers of the image will be created with the timestamp.\n\n**--tls-verify** *bool-value*\n\nRequire HTTPS and verification of certificates when talking to container registries (defaults to true).  TLS verification cannot be used when talking to an insecure registry.\n\n**--ulimit** *type*=*soft-limit*[:*hard-limit*]\n\nSpecifies resource limits to apply to processes launched when processing `RUN` instructions.\nThis option can be specified multiple times.  Recognized resource types\ninclude:\n  \"core\": maximum core dump size (ulimit -c)\n  \"cpu\": maximum CPU time (ulimit -t)\n  \"data\": maximum size of a process's data segment (ulimit -d)\n  \"fsize\": maximum size of new files (ulimit -f)\n  \"locks\": maximum number of file locks (ulimit -x)\n  \"memlock\": maximum amount of locked memory (ulimit -l)\n  \"msgqueue\": maximum amount of data in message queues (ulimit -q)\n  \"nice\": niceness adjustment (nice -n, ulimit -e)\n  \"nofile\": maximum number of open files (ulimit -n)\n  \"nofile\": maximum number of open files (1048576); when run by root\n  \"nproc\": maximum number of processes (ulimit -u)\n  \"nproc\": maximum number of processes (1048576); when run by root\n  \"rss\": maximum size of a process's (ulimit -m)\n  \"rtprio\": maximum real-time scheduling priority (ulimit -r)\n  \"rttime\": maximum amount of real-time execution between blocking syscalls\n  \"sigpending\": maximum number of pending signals (ulimit -i)\n  \"stack\": maximum stack size (ulimit -s)\n\n**--userns** *how*\n\nSets the configuration for user namespaces when handling `RUN` instructions.\nThe configured value can be \"\" (the empty string) or \"private\" to indicate\nthat a new user namespace should be created, it can be \"host\" to indicate that\nthe user namespace in which `buildah` itself is being run should be reused, or\nit can be the path to an user namespace which is already in use by another\nprocess.\n\n**--userns-uid-map-user** *user*\n\nSpecifies that a UID mapping which should be used to set ownership, at the\nfilesystem level, on the working container's contents, can be found in entries\nin the `/etc/subuid` file which correspond to the specified user.\nCommands run when handling `RUN` instructions will default to being run in\ntheir own user namespaces, configured using the UID and GID maps.\nIf --userns-gid-map-group is specified, but --userns-uid-map-user is not\nspecified, `buildah` will assume that the specified group name is also a\nsuitable user name to use as the default setting for this option.\n\nUsers can specify the maps directly using `--userns-uid-map` described in the buildah(1) man page.\n\n**NOTE:** When this option is specified by a rootless user, the specified mappings are relative to the rootless usernamespace in the container, rather than being relative to the host as it would be when run rootful.\n\n**--userns-gid-map-group** *group*\n\nSpecifies that a GID mapping which should be used to set ownership, at the\nfilesystem level, on the working container's contents, can be found in entries\nin the `/etc/subgid` file which correspond to the specified group.\nCommands run when handling `RUN` instructions will default to being run in\ntheir own user namespaces, configured using the UID and GID maps.\nIf --userns-uid-map-user is specified, but --userns-gid-map-group is not\nspecified, `buildah` will assume that the specified user name is also a\nsuitable group name to use as the default setting for this option.\n\nUsers can specify the maps directly using `--userns-gid-map` described in the buildah(1) man page.\n\n**NOTE:** When this option is specified by a rootless user, the specified mappings are relative to the rootless usernamespace in the container, rather than being relative to the host as it would be when run rootful.\n\n**--uts** *how*\n\nSets the configuration for UTS namespaces when the handling `RUN` instructions.\nThe configured value can be \"\" (the empty string) or \"container\" to indicate\nthat a new UTS namespace should be created, or it can be \"host\" to indicate\nthat the UTS namespace in which `buildah` itself is being run should be reused,\nor it can be the path to a UTS namespace which is already in use by another\nprocess.\n\n**--variant**=\"\"\n\nSet the architecture variant of the image to be pulled.\n\n**--volume**, **-v**[=*[HOST-DIR:CONTAINER-DIR[:OPTIONS]]*]\n\n   Create a bind mount. If you specify, ` -v /HOST-DIR:/CONTAINER-DIR`, Buildah\n   bind mounts `/HOST-DIR` in the host to `/CONTAINER-DIR` in the Buildah\n   container. The `OPTIONS` are a comma delimited list and can be: <sup>[[1]](#Footnote1)</sup>\n\n   * [rw|ro]\n   * [U]\n   * [z|Z|O]\n   * [`[r]shared`|`[r]slave`|`[r]private`]\n\nThe `CONTAINER-DIR` must be an absolute path such as `/src/docs`. The `HOST-DIR`\nmust be an absolute path as well. Buildah bind-mounts the `HOST-DIR` to the\npath you specify. For example, if you supply `/foo` as the host path,\nBuildah copies the contents of `/foo` to the container filesystem on the host\nand bind mounts that into the container.\n\nYou can specify multiple  **-v** options to mount one or more mounts to a\ncontainer.\n\n  `Write Protected Volume Mounts`\n\nYou can add the `:ro` or `:rw` suffix to a volume to mount it read-only or\nread-write mode, respectively. By default, the volumes are mounted read-write.\nSee examples.\n\n  `Chowning Volume Mounts`\n\nBy default, Buildah does not change the owner and group of source volume directories mounted into containers. If a container is created in a new user namespace, the UID and GID in the container may correspond to another UID and GID on the host.\n\nThe `:U` suffix tells Buildah to use the correct host UID and GID based on the UID and GID within the container, to change the owner and group of the source volume.\n\n  `Labeling Volume Mounts`\n\nLabeling systems like SELinux require that proper labels are placed on volume\ncontent mounted into a container. Without a label, the security system might\nprevent the processes running inside the container from using the content. By\ndefault, Buildah does not change the labels set by the OS.\n\nTo change a label in the container context, you can add either of two suffixes\n`:z` or `:Z` to the volume mount. These suffixes tell Buildah to relabel file\nobjects on the shared volumes. The `z` option tells Buildah that two containers\nshare the volume content. As a result, Buildah labels the content with a shared\ncontent label. Shared volume labels allow all containers to read/write content.\nThe `Z` option tells Buildah to label the content with a private unshared label.\nOnly the current container can use a private volume.\n\n  `Overlay Volume Mounts`\n\n   The `:O` flag tells Buildah to mount the directory from the host as a temporary storage using the Overlay file system. The `RUN` command containers are allowed to modify contents within the mountpoint and are stored in the container storage in a separate directory.  In Overlay FS terms the source directory will be the lower, and the container storage directory will be the upper. Modifications to the mount point are destroyed when the `RUN` command finishes executing, similar to a tmpfs mount point.\n\n  Any subsequent execution of `RUN` commands sees the original source directory content, any changes from previous RUN commands no longer exists.\n\n  One use case of the `overlay` mount is sharing the package cache from the host into the container to allow speeding up builds.\n\n  Note:\n\n     - The `O` flag is not allowed to be specified with the `Z` or `z` flags. Content mounted into the container is labeled with the private label.\n       On SELinux systems, labels in the source directory needs to be readable by the container label. If not, SELinux container separation must be disabled for the container to work.\n     - Modification of the directory volume mounted into the container with an overlay mount can cause unexpected failures.  It is recommended that you do not modify the directory until the container finishes running.\n\nBy default bind mounted volumes are `private`. That means any mounts done\ninside container will not be visible on the host and vice versa. This behavior can\nbe changed by specifying a volume mount propagation property.\n\nWhen the mount propagation policy is set to `shared`, any mounts completed inside\nthe container on that volume will be visible to both the host and container. When\nthe mount propagation policy is set to `slave`, one way mount propagation is enabled\nand any mounts completed on the host for that volume will be visible only inside of the container.\nTo control the mount propagation property of the volume use the `:[r]shared`,\n`:[r]slave` or `:[r]private` propagation flag. The propagation property can\nbe specified only for bind mounted volumes and not for internal volumes or\nnamed volumes. For mount propagation to work on the source mount point (the mount point\nwhere source dir is mounted on) it has to have the right propagation properties. For\nshared volumes, the source mount point has to be shared. And for slave volumes,\nthe source mount has to be either shared or slave. <sup>[[1]](#Footnote1)</sup>\n\nUse `df <source-dir>` to determine the source mount and then use\n`findmnt -o TARGET,PROPAGATION <source-mount-dir>` to determine propagation\nproperties of source mount, if `findmnt` utility is not available, the source mount point\ncan be determined by looking at the mount entry in `/proc/self/mountinfo`. Look\nat `optional fields` and see if any propagation properties are specified.\n`shared:X` means the mount is `shared`, `master:X` means the mount is `slave` and if\nnothing is there that means the mount is `private`. <sup>[[1]](#Footnote1)</sup>\n\nTo change propagation properties of a mount point use the `mount` command. For\nexample, to bind mount the source directory `/foo` do\n`mount --bind /foo /foo` and `mount --make-private --make-shared /foo`. This\nwill convert /foo into a `shared` mount point.  The propagation properties of the source\nmount can be changed directly. For instance if `/` is the source mount for\n`/foo`, then use `mount --make-shared /` to convert `/` into a `shared` mount.\n\n## BUILD TIME VARIABLES\n\nThe ENV instruction in a Containerfile can be used to define variable values.  When the image\nis built, the values will persist in the container image.  At times it is more convenient to\nchange the values in the Containerfile via a command-line option rather than changing the\nvalues within the Containerfile itself.\n\nThe following variables can be used in conjunction with the `--build-arg` option to override the\ncorresponding values set in the Containerfile using the `ENV` instruction.\n\n  * HTTP_PROXY\n  * HTTPS_PROXY\n  * FTP_PROXY\n  * NO_PROXY\n\nPlease refer to the [Using Build Time Variables](#using-build-time-variables) section of the Examples.\n\n## EXAMPLE\n\n### Build an image using local Containerfiles\n\nbuildah bud .\n\nbuildah bud -f Containerfile .\n\ncat ~/Dockerfile | buildah bud -f - .\n\nbuildah bud -f Dockerfile.simple -f Dockerfile.notsosimple .\n\nbuildah bud --timestamp=$(date '+%s') -t imageName .\n\nbuildah bud -t imageName .\n\nbuildah bud --tls-verify=true -t imageName -f Dockerfile.simple .\n\nbuildah bud --tls-verify=false -t imageName .\n\nbuildah bud --runtime-flag log-format=json .\n\nbuildah bud -f Containerfile --runtime-flag debug .\n\nbuildah bud --authfile /tmp/auths/myauths.json --cert-dir ~/auth --tls-verify=true --creds=username:password -t imageName -f Dockerfile.simple .\n\nbuildah bud --memory 40m --cpu-period 10000 --cpu-quota 50000 --ulimit nofile=1024:1028 -t imageName .\n\nbuildah bud --security-opt label=level:s0:c100,c200 --cgroup-parent /path/to/cgroup/parent -t imageName .\n\nbuildah bud --arch=arm --variant v7 -t imageName .\n\nbuildah bud --volume /home/test:/myvol:ro,Z -t imageName .\n\nbuildah bud -v /home/test:/myvol:z,U -t imageName .\n\nbuildah bud -v /var/lib/dnf:/var/lib/dnf:O -t imageName .\n\nbuildah bud --layers -t imageName .\n\nbuildah bud --no-cache -t imageName .\n\nbuildah bud -f Containerfile --layers --force-rm -t imageName .\n\nbuildah bud --no-cache --rm=false -t imageName .\n\nbuildah bud --dns-search=example.com --dns=223.5.5.5 --dns-option=use-vc .\n\nbuildah bud -f Containerfile.in -t imageName .\n\n### Building an multi-architecture image using a --manifest option (Requires emulation software)\n\nbuildah bud --arch arm --manifest myimage /tmp/mysrc\n\nbuildah bud --arch amd64 --manifest myimage /tmp/mysrc\n\nbuildah bud --arch s390x --manifest myimage /tmp/mysrc\n\n### Building an image using a URL\n\n  This will clone the specified GitHub repository from the URL and use it as context. The Containerfile or Dockerfile at the root of the repository is used as the context of the build. This only works if the GitHub repository is a dedicated repository.\n\n  buildah bud github.com/scollier/purpletest\n\n  Note: You can set an arbitrary Git repository via the git:// scheme.\n\n### Building an image using a URL to a tarball'ed context\n  Buildah will fetch the tarball archive, decompress it and use its contents as the build context.  The Containerfile or Dockerfile at the root of the archive and the rest of the archive will get used as the context of the build. If you pass an -f PATH/Containerfile option as well, the system will look for that file inside the contents of the tarball.\n\n  buildah bud -f dev/Containerfile https://10.10.10.1/docker/context.tar.gz\n\n  Note: supported compression formats are 'xz', 'bzip2', 'gzip' and 'identity' (no compression).\n\n### Using Build Time Variables\n#### Replace the value set for the HTTP_PROXY environment variable within the Containerfile.\n\nbuildah bud --build-arg=HTTP_PROXY=\"http://127.0.0.1:8321\"\n\n## ENVIRONMENT\n\n**BUILD\\_REGISTRY\\_SOURCES**\n\nBUILD\\_REGISTRY\\_SOURCES, if set, is treated as a JSON object which contains\nlists of registry names under the keys `insecureRegistries`,\n`blockedRegistries`, and `allowedRegistries`.\n\nWhen pulling an image from a registry, if the name of the registry matches any\nof the items in the `blockedRegistries` list, the image pull attempt is denied.\nIf there are registries in the `allowedRegistries` list, and the registry's\nname is not in the list, the pull attempt is denied.\n\n**TMPDIR**\nThe TMPDIR environment variable allows the user to specify where temporary files\nare stored while pulling and pushing images.  Defaults to '/var/tmp'.\n\n## Files\n\n### `.containerignore`/`.dockerignore`\n\nIf the .containerignore/.dockerignore file exists in the context directory,\n`buildah bud` reads its contents. If both exist, then .containerignore is used.\nUse the `--ignorefile` flag to override the ignore file path location. Buildah uses the content to exclude files and directories from the context directory, when executing COPY and ADD directives in the Containerfile/Dockerfile\n\nUsers can specify a series of Unix shell globals in a\n.containerignore/.dockerignore file to identify files/directories to exclude.\n\nBuildah supports a special wildcard string `**` which matches any number of\ndirectories (including zero). For example, **/*.go will exclude all files that\nend with .go that are found in all directories.\n\nExample .containerignore file:\n\n```\n# exclude this content for image\n*/*.c\n**/output*\nsrc\n```\n\n`*/*.c`\nExcludes files and directories whose names ends with .c in any top level subdirectory. For example, the source file include/rootless.c.\n\n`**/output*`\nExcludes files and directories starting with `output` from any directory.\n\n`src`\nExcludes files named src and the directory src as well as any content in it.\n\nLines starting with ! (exclamation mark) can be used to make exceptions to\nexclusions. The following is an example .containerignore/.dockerignore file that uses this\nmechanism:\n```\n*.doc\n!Help.doc\n```\n\nExclude all doc files except Help.doc from the image.\n\nThis functionality is compatible with the handling of .dockerignore files described here:\n\nhttps://docs.docker.com/engine/reference/builder/#dockerignore-file\n\n**registries.conf** (`/etc/containers/registries.conf`)\n\nregistries.conf is the configuration file which specifies which container registries should be consulted when completing image names which do not include a registry or domain portion.\n\n**policy.json** (`/etc/containers/policy.json`)\n\nSignature policy file.  This defines the trust policy for container images.  Controls which container registries can be used for image, and whether or not the tool should trust the images.\n\n## SEE ALSO\nbuildah(1), cpp(1), buildah-login(1), docker-login(1), namespaces(7), pid\\_namespaces(7), containers-policy.json(5), containers-registries.conf(5), user\\_namespaces(7), crun(1), runc(8)\n\n## FOOTNOTES\n<a name=\"Footnote1\">1</a>: The Buildah project is committed to inclusivity, a core value of open source. The `master` and `slave` mount propagation terminology used here is problematic and divisive, and should be changed. However, these terms are currently used within the Linux kernel and must be used as-is at this time. When the kernel maintainers rectify this usage, Buildah will follow suit immediately.\n", "# buildah-from \"1\" \"March 2017\" \"buildah\"\n\n## NAME\nbuildah\\-from - Creates a new working container, either from scratch or using a specified image as a starting point.\n\n## SYNOPSIS\n**buildah from** [*options*] *image*\n\n## DESCRIPTION\nCreates a working container based upon the specified image name.  If the\nsupplied image name is \"scratch\" a new empty container is created.  Image names\nuse a \"transport\":\"details\" format.\n\nMultiple transports are supported:\n\n  **dir:**_path_\n  An existing local directory _path_ containing the manifest, layer tarballs, and signatures in individual files. This is a non-standardized format, primarily useful for debugging or noninvasive image inspection.\n\n  **docker://**_docker-reference_ (Default)\n  An image in a registry implementing the \"Docker Registry HTTP API V2\". By default, uses the authorization state in `$XDG\\_RUNTIME\\_DIR/containers/auth.json`, which is set using `(buildah login)`.  If XDG_RUNTIME_DIR is not set, the default is /run/containers/$UID/auth.json. If the authorization state is not found there, `$HOME/.docker/config.json` is checked, which is set using `(docker login)`.\n  If _docker-reference_ does not include a registry name, *localhost* will be consulted first, followed by any registries named in the registries configuration.\n\n  **docker-archive:**_path_\n  An image is retrieved as a `docker load` formatted file.\n\n  **docker-daemon:**_docker-reference_\n  An image _docker-reference_ stored in the docker daemon's internal storage.  _docker-reference_ must include either a tag or a digest.  Alternatively, when reading images, the format can also be docker-daemon:algo:digest (an image ID).\n\n  **oci:**_path_**:**_tag_**\n  An image tag in a directory compliant with \"Open Container Image Layout Specification\" at _path_.\n\n  **oci-archive:**_path_**:**_tag_\n  An image _tag_ in a directory compliant with \"Open Container Image Layout Specification\" at _path_.\n\n### DEPENDENCIES\n\nBuildah resolves the path to the registry to pull from by using the /etc/containers/registries.conf\nfile, containers-registries.conf(5).  If the `buildah from` command fails with an \"image not known\" error,\nfirst verify that the registries.conf file is installed and configured appropriately.\n\n## RETURN VALUE\nThe container ID of the container that was created.  On error 1 is returned.\n\n## OPTIONS\n\n**--add-host**=[]\n\nAdd a custom host-to-IP mapping (host:ip)\n\nAdd a line to /etc/hosts. The format is hostname:ip. The **--add-host** option can be set multiple times.\n\n**--arch**=\"ARCH\"\n\nSet the ARCH of the image to be pulled to the provided value instead of using the architecture of the host. (Examples: aarch64, arm, i686, ppc64le, s390x, x86_64)\n\n**--authfile** *path*\n\nPath of the authentication file. Default is ${XDG_\\RUNTIME\\_DIR}/containers/auth.json. If XDG_RUNTIME_DIR is not set, the default is /run/containers/$UID/auth.json. This file is created using using `buildah login`.\n\nIf the authorization state is not found there, $HOME/.docker/config.json is checked, which is set using `docker login`.\n\nNote: You can also override the default path of the authentication file by setting the REGISTRY\\_AUTH\\_FILE\nenvironment variable. `export REGISTRY_AUTH_FILE=path`\n\n**--cap-add**=*CAP\\_xxx*\n\nAdd the specified capability to the default set of capabilities which will be\nsupplied for subsequent *buildah run* invocations which use this container.\nCertain capabilities are granted by default; this option can be used to add\nmore.\n\n**--cap-drop**=*CAP\\_xxx*\n\nRemove the specified capability from the default set of capabilities which will\nbe supplied for subsequent *buildah run* invocations which use this container.\nThe CAP\\_AUDIT\\_WRITE, CAP\\_CHOWN, CAP\\_DAC\\_OVERRIDE, CAP\\_FOWNER,\nCAP\\_FSETID, CAP\\_KILL, CAP\\_MKNOD, CAP\\_NET\\_BIND\\_SERVICE, CAP\\_SETFCAP,\nCAP\\_SETGID, CAP\\_SETPCAP, CAP\\_SETUID, and CAP\\_SYS\\_CHROOT capabilities are\ngranted by default; this option can be used to remove them.\n\nIf a capability is specified to both the **--cap-add** and **--cap-drop**\noptions, it will be dropped, regardless of the order in which the options were\ngiven.\n\n**--cert-dir** *path*\n\nUse certificates at *path* (\\*.crt, \\*.cert, \\*.key) to connect to the registry.\nThe default certificates directory is _/etc/containers/certs.d_.\n\n**--cgroup-parent**=\"\"\n\nPath to cgroups under which the cgroup for the container will be created. If the path is not absolute, the path is considered to be relative to the cgroups path of the init process. Cgroups will be created if they do not already exist.\n\n**--cidfile** *ContainerIDFile*\n\nWrite the container ID to the file.\n\n**--cni-config-dir**=*directory*\n\nLocation of CNI configuration files which will dictate which plugins will be\nused to configure network interfaces and routing when the container is\nsubsequently used for `buildah run`, if processes to be started will be run in\ntheir own network namespaces, and networking is not disabled.\n\n**--cni-plugin-path**=*directory[:directory[:directory[...]]]*\n\nList of directories in which the CNI plugins which will be used for configuring\nnetwork namespaces can be found.\n\n**--cpu-period**=*0*\n\nLimit the CPU CFS (Completely Fair Scheduler) period\n\nLimit the container's CPU usage. This flag tell the kernel to restrict the container's CPU usage to the period you specify.\n\n**--cpu-quota**=*0*\n\nLimit the CPU CFS (Completely Fair Scheduler) quota\n\nLimit the container's CPU usage. By default, containers run with the full\nCPU resource. This flag tell the kernel to restrict the container's CPU usage\nto the quota you specify.\n\n**--cpu-shares**, **-c**=*0*\n\nCPU shares (relative weight)\n\nBy default, all containers get the same proportion of CPU cycles. This proportion\ncan be modified by changing the container's CPU share weighting relative\nto the weighting of all other running containers.\n\nTo modify the proportion from the default of 1024, use the **--cpu-shares**\nflag to set the weighting to 2 or higher.\n\nThe proportion will only apply when CPU-intensive processes are running.\nWhen tasks in one container are idle, other containers can use the\nleft-over CPU time. The actual amount of CPU time will vary depending on\nthe number of containers running on the system.\n\nFor example, consider three containers, one has a cpu-share of 1024 and\ntwo others have a cpu-share setting of 512. When processes in all three\ncontainers attempt to use 100% of CPU, the first container would receive\n50% of the total CPU time. If you add a fourth container with a cpu-share\nof 1024, the first container only gets 33% of the CPU. The remaining containers\nreceive 16.5%, 16.5% and 33% of the CPU.\n\nOn a multi-core system, the shares of CPU time are distributed over all CPU\ncores. Even if a container is limited to less than 100% of CPU time, it can\nuse 100% of each individual CPU core.\n\nFor example, consider a system with more than three cores. If you start one\ncontainer **{C0}** with **-c=512** running one process, and another container\n**{C1}** with **-c=1024** running two processes, this can result in the following\ndivision of CPU shares:\n\n    PID    container\tCPU\tCPU share\n    100    {C0}\t\t0\t100% of CPU0\n    101    {C1}\t\t1\t100% of CPU1\n    102    {C1}\t\t2\t100% of CPU2\n\n**--cpuset-cpus**=\"\"\n\n  CPUs in which to allow execution (0-3, 0,1)\n\n**--cpuset-mems**=\"\"\n\nMemory nodes (MEMs) in which to allow execution (0-3, 0,1). Only effective on NUMA systems.\n\nIf you have four memory nodes on your system (0-3), use `--cpuset-mems=0,1`\nthen processes in your container will only use memory from the first\ntwo memory nodes.\n\n**--creds** *creds*\n\nThe [username[:password]] to use to authenticate with the registry if required.\nIf one or both values are not supplied, a command line prompt will appear and the\nvalue can be entered.  The password is entered without echo.\n\n**--decryption-key** *key[:passphrase]*\n\nThe [key[:passphrase]] to be used for decryption of images. Key can point to keys and/or certificates. Decryption will be tried with all keys. If the key is protected by a passphrase, it is required to be passed in the argument and omitted otherwise.\n\n**--device**=*device*\n\nAdd a host device or devices under a directory to the container. The format is `<device-on-host>[:<device-on-container>][:<permissions>]` (e.g. --device=/dev/sdc:/dev/xvdc:rwm)\n\n**--dns**=[]\n\nSet custom DNS servers\n\nThis option can be used to override the DNS configuration passed to the container. Typically this is necessary when the host DNS configuration is invalid for the container (e.g., 127.0.0.1). When this is the case the `--dns` flag is necessary for every run.\n\nThe special value **none** can be specified to disable creation of /etc/resolv.conf in the container by Buildah. The /etc/resolv.conf file in the image will be used without changes.\n\n**--dns-option**=[]\n\nSet custom DNS options\n\n**--dns-search**=[]\n\nSet custom DNS search domains\n\n**--format**, **-f** *oci* | *docker*\n\nControl the format for the built image's manifest and configuration data.\nRecognized formats include *oci* (OCI image-spec v1.0, the default) and\n*docker* (version 2, using schema format 2 for the manifest).\n\nNote: You can also override the default format by setting the BUILDAH\\_FORMAT\nenvironment variable.  `export BUILDAH_FORMAT=docker`\n\n**--http-proxy**\n\nBy default proxy environment variables are passed into the container if set\nfor the Buildah process.  This can be disabled by setting the `--http-proxy`\noption to `false`.  The environment variables passed in include `http_proxy`,\n`https_proxy`, `ftp_proxy`, `no_proxy`, and also the upper case versions of\nthose.\n\nDefaults to `true`\n\n**--ipc** *how*\n\nSets the configuration for IPC namespaces when the container is subsequently\nused for `buildah run`.\nThe configured value can be \"\" (the empty string) or \"container\" to indicate\nthat a new IPC namespace should be created, or it can be \"host\" to indicate\nthat the IPC namespace in which `Buildah` itself is being run should be reused,\nor it can be the path to an IPC namespace which is already in use by\nanother process.\n\n**--isolation** *type*\n\nControls what type of isolation is used for running processes under `buildah\nrun`.  Recognized types include *oci* (OCI-compatible runtime, the default),\n*rootless* (OCI-compatible runtime invoked using a modified\nconfiguration, with *--no-new-keyring* added to its *create*\ninvocation, with network and UTS namespaces disabled, and IPC, PID,\nand user namespaces enabled; the default for unprivileged users), and\n*chroot* (an internal wrapper that leans more toward chroot(1) than\ncontainer technology).\n\nNote: You can also override the default isolation type by setting the\nBUILDAH\\_ISOLATION environment variable.  `export BUILDAH_ISOLATION=oci`\n\n**--memory**, **-m**=\"\"\n\nMemory limit (format: <number>[<unit>], where unit = b, k, m or g)\n\nAllows you to constrain the memory available to a container. If the host\nsupports swap memory, then the **-m** memory setting can be larger than physical\nRAM. If a limit of 0 is specified (not using **-m**), the container's memory is\nnot limited. The actual limit may be rounded up to a multiple of the operating\nsystem's page size (the value would be very large, that's millions of trillions).\n\n**--memory-swap**=\"LIMIT\"\n\nA limit value equal to memory plus swap. Must be used with the  **-m**\n(**--memory**) flag. The swap `LIMIT` should always be larger than **-m**\n(**--memory**) value.  By default, the swap `LIMIT` will be set to double\nthe value of --memory.\n\nThe format of `LIMIT` is `<number>[<unit>]`. Unit can be `b` (bytes),\n`k` (kilobytes), `m` (megabytes), or `g` (gigabytes). If you don't specify a\nunit, `b` is used. Set LIMIT to `-1` to enable unlimited swap.\n\n**--name** *name*\n\nA *name* for the working container\n\n**--net** *how*\n**--network** *how*\n\nSets the configuration for network namespaces when the container is subsequently\nused for `buildah run`.\nThe configured value can be \"\" (the empty string) or \"container\" to indicate\nthat a new network namespace should be created, or it can be \"host\" to indicate\nthat the network namespace in which `Buildah` itself is being run should be\nreused, or it can be the path to a network namespace which is already in use by\nanother process.\n\n**--os**=\"OS\"\n\nSet the OS of the image to be pulled to the provided value instead of using the current operating system of the host.\n\n**--pid** *how*\n\nSets the configuration for PID namespaces when the container is subsequently\nused for `buildah run`.\nThe configured value can be \"\" (the empty string) or \"container\" to indicate\nthat a new PID namespace should be created, or it can be \"host\" to indicate\nthat the PID namespace in which `Buildah` itself is being run should be reused,\nor it can be the path to a PID namespace which is already in use by another\nprocess.\n\n**--pull**\n\nWhen the flag is enabled, attempt to pull the latest image from the registries\nlisted in registries.conf if a local image does not exist or the image is newer\nthan the one in storage. Raise an error if the image is not in any listed\nregistry and is not present locally.\n\nIf the flag is disabled (with *--pull=false*), do not pull the image from the\nregistry, use only the local version. Raise an error if the image is not\npresent locally.\n\nDefaults to *true*.\n\n**--pull-always**\n\nPull the image from the first registry it is found in as listed in registries.conf.\nRaise an error if not found in the registries, even if the image is present locally.\n\n**--pull-never**\n\nDo not pull the image from the registry, use only the local version. Raise an error\nif the image is not present locally.\n\n**--quiet**, **-q**\n\nIf an image needs to be pulled from the registry, suppress progress output.\n\n**--security-opt**=[]\n\nSecurity Options\n\n  \"label=user:USER\"   : Set the label user for the container\n  \"label=role:ROLE\"   : Set the label role for the container\n  \"label=type:TYPE\"   : Set the label type for the container\n  \"label=level:LEVEL\" : Set the label level for the container\n  \"label=disable\"     : Turn off label confinement for the container\n  \"no-new-privileges\" : Not supported\n\n  \"seccomp=unconfined\" : Turn off seccomp confinement for the container\n  \"seccomp=profile.json :  White listed syscalls seccomp Json file to be used as a seccomp filter\n\n  \"apparmor=unconfined\" : Turn off apparmor confinement for the container\n  \"apparmor=your-profile\" : Set the apparmor confinement profile for the container\n\n**--shm-size**=\"\"\n\nSize of `/dev/shm`. The format is `<number><unit>`. `number` must be greater than `0`.\nUnit is optional and can be `b` (bytes), `k` (kilobytes), `m`(megabytes), or `g` (gigabytes).\nIf you omit the unit, the system uses bytes. If you omit the size entirely, the system uses `64m`.\n\n**--tls-verify** *bool-value*\n\nRequire HTTPS and verification of certificates when talking to container registries (defaults to true).  TLS verification cannot be used when talking to an insecure registry.\n\n**--ulimit** *type*=*soft-limit*[:*hard-limit*]\n\nSpecifies resource limits to apply to processes launched during `buildah run`.\nThis option can be specified multiple times.  Recognized resource types\ninclude:\n  \"core\": maximum core dump size (ulimit -c)\n  \"cpu\": maximum CPU time (ulimit -t)\n  \"data\": maximum size of a process's data segment (ulimit -d)\n  \"fsize\": maximum size of new files (ulimit -f)\n  \"locks\": maximum number of file locks (ulimit -x)\n  \"memlock\": maximum amount of locked memory (ulimit -l)\n  \"msgqueue\": maximum amount of data in message queues (ulimit -q)\n  \"nice\": niceness adjustment (nice -n, ulimit -e)\n  \"nofile\": maximum number of open files (ulimit -n)\n  \"nofile\": maximum number of open files (1048576); when run by root\n  \"nproc\": maximum number of processes (ulimit -u)\n  \"nproc\": maximum number of processes (1048576); when run by root\n  \"rss\": maximum size of a process's (ulimit -m)\n  \"rtprio\": maximum real-time scheduling priority (ulimit -r)\n  \"rttime\": maximum amount of real-time execution between blocking syscalls\n  \"sigpending\": maximum number of pending signals (ulimit -i)\n  \"stack\": maximum stack size (ulimit -s)\n\n**--userns** *how*\n\nSets the configuration for user namespaces when the container is subsequently\nused for `buildah run`.\nThe configured value can be \"\" (the empty string) or \"container\" to indicate\nthat a new user namespace should be created, it can be \"host\" to indicate that\nthe user namespace in which `Buildah` itself is being run should be reused, or\nit can be the path to an user namespace which is already in use by another\nprocess.\n\n**--userns-uid-map-user** *mapping*\n\nDirectly specifies a UID mapping which should be used to set ownership, at the\nfilesystem level, on the container's contents.\nCommands run using `buildah run` will default to being run in their own user\nnamespaces, configured using the UID and GID maps.\n\nEntries in this map take the form of one or more triples of a starting\nin-container UID, a corresponding starting host-level UID, and the number of\nconsecutive IDs which the map entry represents.\n\nThis option overrides the *remap-uids* setting in the *options* section of\n/etc/containers/storage.conf.\n\nIf this option is not specified, but a global --userns-uid-map setting is\nsupplied, settings from the global option will be used.\n\nIf none of --userns-uid-map-user, --userns-gid-map-group, or --userns-uid-map\nare specified, but --userns-gid-map is specified, the UID map will be set to\nuse the same numeric values as the GID map.\n\n**NOTE:** When this option is specified by a rootless user, the specified mappings are relative to the rootless usernamespace in the container, rather than being relative to the host as it would be when run rootful.\n\n**--userns-gid-map-group** *mapping*\n\nDirectly specifies a GID mapping which should be used to set ownership, at the\nfilesystem level, on the container's contents.\nCommands run using `buildah run` will default to being run in their own user\nnamespaces, configured using the UID and GID maps.\n\nEntries in this map take the form of one or more triples of a starting\nin-container GID, a corresponding starting host-level GID, and the number of\nconsecutive IDs which the map entry represents.\n\nThis option overrides the *remap-gids* setting in the *options* section of\n/etc/containers/storage.conf.\n\nIf this option is not specified, but a global --userns-gid-map setting is\nsupplied, settings from the global option will be used.\n\nIf none of --userns-uid-map-user, --userns-gid-map-group, or --userns-gid-map\nare specified, but --userns-uid-map is specified, the GID map will be set to\nuse the same numeric values as the UID map.\n\n**NOTE:** When this option is specified by a rootless user, the specified mappings are relative to the rootless usernamespace in the container, rather than being relative to the host as it would be when run rootful.\n\n**--userns-uid-map-user** *user*\n\nSpecifies that a UID mapping which should be used to set ownership, at the\nfilesystem level, on the container's contents, can be found in entries in the\n`/etc/subuid` file which correspond to the specified user.\nCommands run using `buildah run` will default to being run in their own user\nnamespaces, configured using the UID and GID maps.\nIf --userns-gid-map-group is specified, but --userns-uid-map-user is not\nspecified, `Buildah` will assume that the specified group name is also a\nsuitable user name to use as the default setting for this option.\n\n**--userns-gid-map-group** *group*\n\nSpecifies that a GID mapping which should be used to set ownership, at the\nfilesystem level, on the container's contents, can be found in entries in the\n`/etc/subgid` file which correspond to the specified group.\nCommands run using `buildah run` will default to being run in their own user\nnamespaces, configured using the UID and GID maps.\nIf --userns-uid-map-user is specified, but --userns-gid-map-group is not\nspecified, `Buildah` will assume that the specified user name is also a\nsuitable group name to use as the default setting for this option.\n\n**--uts** *how*\n\nSets the configuration for UTS namespaces when the container is subsequently\nused for `buildah run`.\nThe configured value can be \"\" (the empty string) or \"container\" to indicate\nthat a new UTS namespace should be created, or it can be \"host\" to indicate\nthat the UTS namespace in which `Buildah` itself is being run should be reused,\nor it can be the path to a UTS namespace which is already in use by another\nprocess.\n\n**--variant**=\"\"\n\nSet the architecture variant of the image to be pulled.\n\n**--volume**, **-v**[=*[HOST-DIR:CONTAINER-DIR[:OPTIONS]]*]\n\n   Create a bind mount. If you specify, ` -v /HOST-DIR:/CONTAINER-DIR`, Buildah\n   bind mounts `/HOST-DIR` in the host to `/CONTAINER-DIR` in the Buildah\n   container. The `OPTIONS` are a comma delimited list and can be: <sup>[[1]](#Footnote1)</sup>\n\n   * [rw|ro]\n   * [U]\n   * [z|Z|O]\n   * [`[r]shared`|`[r]slave`|`[r]private`|`[r]unbindable`]\n\nThe `CONTAINER-DIR` must be an absolute path such as `/src/docs`. The `HOST-DIR`\nmust be an absolute path as well. Buildah bind-mounts the `HOST-DIR` to the\npath you specify. For example, if you supply `/foo` as the host path,\nBuildah copies the contents of `/foo` to the container filesystem on the host\nand bind mounts that into the container.\n\nYou can specify multiple  **-v** options to mount one or more mounts to a\ncontainer.\n\n  `Write Protected Volume Mounts`\n\nYou can add the `:ro` or `:rw` suffix to a volume to mount it read-only or\nread-write mode, respectively. By default, the volumes are mounted read-write.\nSee examples.\n\n  `Chowning Volume Mounts`\n\nBy default, Buildah does not change the owner and group of source volume directories mounted into containers. If a container is created in a new user namespace, the UID and GID in the container may correspond to another UID and GID on the host.\n\nThe `:U` suffix tells Buildah to use the correct host UID and GID based on the UID and GID within the container, to change the owner and group of the source volume.\n\n  `Labeling Volume Mounts`\n\nLabeling systems like SELinux require that proper labels are placed on volume\ncontent mounted into a container. Without a label, the security system might\nprevent the processes running inside the container from using the content. By\ndefault, Buildah does not change the labels set by the OS.\n\nTo change a label in the container context, you can add either of two suffixes\n`:z` or `:Z` to the volume mount. These suffixes tell Buildah to relabel file\nobjects on the shared volumes. The `z` option tells Buildah that two containers\nshare the volume content. As a result, Buildah labels the content with a shared\ncontent label. Shared volume labels allow all containers to read/write content.\nThe `Z` option tells Buildah to label the content with a private unshared label.\nOnly the current container can use a private volume.\n\n  `Overlay Volume Mounts`\n\n   The `:O` flag tells Buildah to mount the directory from the host as a temporary storage using the Overlay file system. The `RUN` command containers are allowed to modify contents within the mountpoint and are stored in the container storage in a separate directory.  In Overlay FS terms the source directory will be the lower, and the container storage directory will be the upper. Modifications to the mount point are destroyed when the `RUN` command finishes executing, similar to a tmpfs mount point.\n\n  Any subsequent execution of `RUN` commands sees the original source directory content, any changes from previous RUN commands no longer exists.\n\n  One use case of the `overlay` mount is sharing the package cache from the host into the container to allow speeding up builds.\n\n  Note:\n\n     - The `O` flag is not allowed to be specified with the `Z` or `z` flags. Content mounted into the container is labeled with the private label.\n       On SELinux systems, labels in the source directory needs to be readable by the container label. If not, SELinux container separation must be disabled for the container to work.\n     - Modification of the directory volume mounted into the container with an overlay mount can cause unexpected failures.  It is recommended that you do not modify the directory until the container finishes running.\n\nBy default bind mounted volumes are `private`. That means any mounts done\ninside container will not be visible on the host and vice versa. This behavior can\nbe changed by specifying a volume mount propagation property.\n\nWhen the mount propagation policy is set to `shared`, any mounts completed inside\nthe container on that volume will be visible to both the host and container. When\nthe mount propagation policy is set to `slave`, one way mount propagation is enabled\nand any mounts completed on the host for that volume will be visible only inside of the container.\nTo control the mount propagation property of the volume use the `:[r]shared`,\n`:[r]slave`, `[r]private` or `[r]unbindable`propagation flag. The propagation property can\nbe specified only for bind mounted volumes and not for internal volumes or\nnamed volumes. For mount propagation to work on the source mount point (the mount point\nwhere source dir is mounted on) it has to have the right propagation properties. For\nshared volumes, the source mount point has to be shared. And for slave volumes,\nthe source mount has to be either shared or slave. <sup>[[1]](#Footnote1)</sup>\n\nUse `df <source-dir>` to determine the source mount and then use\n`findmnt -o TARGET,PROPAGATION <source-mount-dir>` to determine propagation\nproperties of source mount, if `findmnt` utility is not available, the source mount point\ncan be determined by looking at the mount entry in `/proc/self/mountinfo`. Look\nat `optional fields` and see if any propagation properties are specified.\n`shared:X` means the mount is `shared`, `master:X` means the mount is `slave` and if\nnothing is there that means the mount is `private`. <sup>[[1]](#Footnote1)</sup>\n\nTo change propagation properties of a mount point use the `mount` command. For\nexample, to bind mount the source directory `/foo` do\n`mount --bind /foo /foo` and `mount --make-private --make-shared /foo`. This\nwill convert /foo into a `shared` mount point.  The propagation properties of the source\nmount can be changed directly. For instance if `/` is the source mount for\n`/foo`, then use `mount --make-shared /` to convert `/` into a `shared` mount.\n\n## EXAMPLE\n\nbuildah from --pull imagename\n\nbuildah from --pull docker://myregistry.example.com/imagename\n\nbuildah from docker-daemon:imagename:imagetag\n\nbuildah from --name mycontainer docker-archive:filename\n\nbuildah from oci-archive:filename\n\nbuildah from --name mycontainer dir:directoryname\n\nbuildah from --pull-always --name \"mycontainer\" docker://myregistry.example.com/imagename\n\nbuildah from --tls-verify=false myregistry/myrepository/imagename:imagetag\n\nbuildah from --creds=myusername:mypassword --cert-dir ~/auth myregistry/myrepository/imagename:imagetag\n\nbuildah from --authfile=/tmp/auths/myauths.json myregistry/myrepository/imagename:imagetag\n\nbuildah from --memory 40m --cpu-shares 2 --cpuset-cpus 0,2 --security-opt label=level:s0:c100,c200 myregistry/myrepository/imagename:imagetag\n\nbuildah from --ulimit nofile=1024:1028 --cgroup-parent /path/to/cgroup/parent myregistry/myrepository/imagename:imagetag\n\nbuildah from --volume /home/test:/myvol:ro,Z myregistry/myrepository/imagename:imagetag\n\nbuildah from -v /home/test:/myvol:z,U myregistry/myrepository/imagename:imagetag\n\nbuildah from -v /var/lib/yum:/var/lib/yum:O myregistry/myrepository/imagename:imagetag\n\nbuildah from --arch=arm --variant v7 myregistry/myrepository/imagename:imagetag\n\n## ENVIRONMENT\n\n**BUILD\\_REGISTRY\\_SOURCES**\n\nBUILD\\_REGISTRY\\_SOURCES, if set, is treated as a JSON object which contains\nlists of registry names under the keys `insecureRegistries`,\n`blockedRegistries`, and `allowedRegistries`.\n\nWhen pulling an image from a registry, if the name of the registry matches any\nof the items in the `blockedRegistries` list, the image pull attempt is denied.\nIf there are registries in the `allowedRegistries` list, and the registry's\nname is not in the list, the pull attempt is denied.\n\n**TMPDIR**\nThe TMPDIR environment variable allows the user to specify where temporary files\nare stored while pulling and pushing images.  Defaults to '/var/tmp'.\n\n## FILES\n\n**registries.conf** (`/etc/containers/registries.conf`)\n\nregistries.conf is the configuration file which specifies which container registries should be consulted when completing image names which do not include a registry or domain portion.\n\n**policy.json** (`/etc/containers/policy.json`)\n\nSignature policy file.  This defines the trust policy for container images.  Controls which container registries can be used for image, and whether or not the tool should trust the images.\n\n## SEE ALSO\nbuildah(1), buildah-pull(1), buildah-login(1), docker-login(1), namespaces(7), pid\\_namespaces(7), containers-policy.json(5), containers-registries.conf(5), user\\_namespaces(7)\n\n## FOOTNOTES\n<a name=\"Footnote1\">1</a>: The Buildah project is committed to inclusivity, a core value of open source. The `master` and `slave` mount propagation terminology used here is problematic and divisive, and should be changed. However, these terms are currently used within the Linux kernel and must be used as-is at this time. When the kernel maintainers rectify this usage, Buildah will follow suit immediately.\n", "# buildah-run \"1\" \"March 2017\" \"buildah\"\n\n## NAME\nbuildah\\-run - Run a command inside of the container.\n\n## SYNOPSIS\n**buildah run** [*options*] [**--**] *container* *command*\n\n## DESCRIPTION\nLaunches a container and runs the specified command in that container using the\ncontainer's root filesystem as a root filesystem, using configuration settings\ninherited from the container's image or as specified using previous calls to\nthe *buildah config* command.  To execute *buildah run* within an\ninteractive shell, specify the --tty option.\n\n## OPTIONS\n**--add-history**\n\nAdd an entry to the history which will note what command is being invoked.\nDefaults to false.\n\nNote: You can also override the default value of --add-history by setting the\nBUILDAH\\_HISTORY environment variable. `export BUILDAH_HISTORY=true`\n\n**--cap-add**=*CAP\\_xxx*\n\nAdd the specified capability to the set of capabilities which will be granted\nto the specified command.\nCertain capabilities are granted by default; this option can be used to add\nmore beyond the defaults, which may have been modified by **--cap-add** and\n**--cap-drop** options used with the *buildah from* invocation which created\nthe container.\n\n**--cap-drop**=*CAP\\_xxx*\n\nAdd the specified capability from the set of capabilities which will be granted\nto the specified command.\nThe CAP\\_AUDIT\\_WRITE, CAP\\_CHOWN, CAP\\_DAC\\_OVERRIDE, CAP\\_FOWNER,\nCAP\\_FSETID, CAP\\_KILL, CAP\\_MKNOD, CAP\\_NET\\_BIND\\_SERVICE, CAP\\_SETFCAP,\nCAP\\_SETGID, CAP\\_SETPCAP, CAP\\_SETUID, and CAP\\_SYS\\_CHROOT capabilities are\ngranted by default; this option can be used to remove them from the defaults,\nwhich may have been modified by **--cap-add** and **--cap-drop** options used\nwith the *buildah from* invocation which created the container.\n\nIf a capability is specified to both the **--cap-add** and **--cap-drop**\noptions, it will be dropped, regardless of the order in which the options were\ngiven.\n\n**--cni-config-dir**=*directory*\n\nLocation of CNI configuration files which will dictate which plugins will be\nused to configure network interfaces and routing inside the running container,\nif the container will be run in its own network namespace, and networking is\nnot disabled.\n\n**--cni-plugin-path**=*directory[:directory[:directory[...]]]*\n\nList of directories in which the CNI plugins which will be used for configuring\nnetwork namespaces can be found.\n\n**--env**, **-e** *env=value*\n\nTemporarily add a value (e.g. env=*value*) to the environment for the running\nprocess. Unlike `buildah config --env`, the environment will not persist to\nlater calls to `buildah run` or to the built image. Can be used multiple times.\n\n**--hostname**\n\nSet the hostname inside of the running container.\n\n**--ipc** *how*\n\nSets the configuration for the IPC namespaces for the container.\nThe configured value can be \"\" (the empty string) or \"private\" to indicate\nthat a new IPC namespace should be created, or it can be \"host\" to indicate\nthat the IPC namespace in which `buildah` itself is being run should be reused,\nor it can be the path to an IPC namespace which is already in use by another\nprocess.\n\n**--isolation** *type*\n\nControls what type of isolation is used for running the process.  Recognized\ntypes include *oci* (OCI-compatible runtime, the default), *rootless*\n(OCI-compatible runtime invoked using a modified configuration, with\n*--no-new-keyring* added to its *create* invocation, with network and\nUTS namespaces disabled, and IPC, PID, and user namespaces enabled;\nthe default for unprivileged users), and *chroot* (an internal wrapper\nthat leans more toward chroot(1) than container technology).\n\nNote: You can also override the default isolation type by setting the\nBUILDAH\\_ISOLATION environment variable.  `export BUILDAH_ISOLATION=oci`\n\n**--mount**=*type=TYPE,TYPE-SPECIFIC-OPTION[,...]*\n\nAttach a filesystem mount to the container\n\nCurrent supported mount TYPES are bind, and tmpfs. <sup>[[1]](#Footnote1)</sup>\n\n       e.g.\n\n       type=bind,source=/path/on/host,destination=/path/in/container\n\n       type=tmpfs,tmpfs-size=512M,destination=/path/in/container\n\n       Common Options:\n\n              \u00b7 src, source: mount source spec for bind and volume. Mandatory for bind.\n\n              \u00b7 dst, destination, target: mount destination spec.\n\n              \u00b7 ro, read-only: true or false (default).\n\n       Options specific to bind:\n\n              \u00b7 bind-propagation: shared, slave, private, rshared, rslave, or rprivate(default). See also mount(2).\n\n              . bind-nonrecursive: do not setup a recursive bind mount.  By default it is recursive.\n\n       Options specific to tmpfs:\n\n              \u00b7 tmpfs-size: Size of the tmpfs mount in bytes. Unlimited by default in Linux.\n\n              \u00b7 tmpfs-mode: File mode of the tmpfs in octal. (e.g. 700 or 0700.) Defaults to 1777 in Linux.\n\n**--network**, **--net**=*mode*\n\nSets the configuration for the network namespace for the container.\n\n- **none**: no networking;\n- **host**: use the host network stack. Note: the host mode gives the container full access to local system services such as D-bus and is therefore considered insecure;\n- **ns:**_path_: path to a network namespace to join;\n- `private`: create a new namespace for the container (default)\n\n**--pid** *how*\n\nSets the configuration for the PID namespace for the container.\nThe configured value can be \"\" (the empty string) or \"private\" to indicate\nthat a new PID namespace should be created, or it can be \"host\" to indicate\nthat the PID namespace in which `buildah` itself is being run should be reused,\nor it can be the path to a PID namespace which is already in use by another\nprocess.\n\n**--runtime** *path*\n\nThe *path* to an alternate OCI-compatible runtime. Default is `runc`, or `crun` when machine is configured to use cgroups V2.\n\nNote: You can also override the default runtime by setting the BUILDAH\\_RUNTIME\nenvironment variable.  `export BUILDAH_RUNTIME=/usr/bin/crun`\n\n**--runtime-flag** *flag*\n\nAdds global flags for the container runtime. To list the supported flags, please\nconsult the manpages of the selected container runtime.\nNote: Do not pass the leading `--` to the flag. To pass the runc flag `--log-format json`\nto buildah run, the option given would be `--runtime-flag log-format=json`.\n\n**--no-pivot**\n\nDo not use pivot root to jail process inside rootfs. This should be used\nwhenever the rootfs is on top of a ramdisk.\n\nNote: You can make this option the default by setting the BUILDAH\\_NOPIVOT\nenvironment variable.  `export BUILDAH_NOPIVOT=true`\n\n**-t**, **--tty**, **--terminal**\n\nBy default a pseudo-TTY is allocated only when buildah's standard input is\nattached to a pseudo-TTY.  Setting the `--tty` option to `true` will cause a\npseudo-TTY to be allocated inside the container connecting the user's \"terminal\"\nwith the stdin and stdout stream of the container.  Setting the `--tty` option to\n`false` will prevent the pseudo-TTY from being allocated.\n\n**--user** *user*[:*group*]\n\nSet the *user* to be used for running the command in the container.\nThe user can be specified as a user name\nor UID, optionally followed by a group name or GID, separated by a colon (':').\nIf names are used, the container should include entries for those names in its\n*/etc/passwd* and */etc/group* files.\n\n**--uts** *how*\n\nSets the configuration for the UTS namespace for the container.\nThe configured value can be \"\" (the empty string) or \"private\" to indicate\nthat a new UTS namespace should be created, or it can be \"host\" to indicate\nthat the UTS namespace in which `buildah` itself is being run should be reused,\nor it can be the path to a UTS namespace which is already in use by another\nprocess.\n\n**--volume**, **-v** *source*:*destination*:*options*\n\nCreate a bind mount. If you specify, ` -v /HOST-DIR:/CONTAINER-DIR`, Buildah\nbind mounts `/HOST-DIR` in the host to `/CONTAINER-DIR` in the Buildah\ncontainer. The `OPTIONS` are a comma delimited list and can be: <sup>[[1]](#Footnote1)</sup>\n\n   * [rw|ro]\n   * [U]\n   * [z|Z]\n   * [`[r]shared`|`[r]slave`|`[r]private`]\n\nThe `CONTAINER-DIR` must be an absolute path such as `/src/docs`. The `HOST-DIR`\nmust be an absolute path as well. Buildah bind-mounts the `HOST-DIR` to the\npath you specify. For example, if you supply `/foo` as the host path,\nBuildah copies the contents of `/foo` to the container filesystem on the host\nand bind mounts that into the container.\n\nYou can specify multiple  **-v** options to mount one or more mounts to a\ncontainer.\n\n  `Write Protected Volume Mounts`\n\nYou can add the `:ro` or `:rw` suffix to a volume to mount it read-only or\nread-write mode, respectively. By default, the volumes are mounted read-write.\nSee examples.\n\n  `Chowning Volume Mounts`\n\nBy default, Buildah does not change the owner and group of source volume directories mounted into containers. If a container is created in a new user namespace, the UID and GID in the container may correspond to another UID and GID on the host.\n\nThe `:U` suffix tells Buildah to use the correct host UID and GID based on the UID and GID within the container, to change the owner and group of the source volume.\n\n  `Labeling Volume Mounts`\n\nLabeling systems like SELinux require that proper labels are placed on volume\ncontent mounted into a container. Without a label, the security system might\nprevent the processes running inside the container from using the content. By\ndefault, Buildah does not change the labels set by the OS.\n\nTo change a label in the container context, you can add either of two suffixes\n`:z` or `:Z` to the volume mount. These suffixes tell Buildah to relabel file\nobjects on the shared volumes. The `z` option tells Buildah that two containers\nshare the volume content. As a result, Buildah labels the content with a shared\ncontent label. Shared volume labels allow all containers to read/write content.\nThe `Z` option tells Buildah to label the content with a private unshared label.\nOnly the current container can use a private volume.\n\nBy default bind mounted volumes are `private`. That means any mounts done\ninside container will not be visible on the host and vice versa. This behavior can\nbe changed by specifying a volume mount propagation property.\n\nWhen the mount propagation policy is set to `shared`, any mounts completed inside\nthe container on that volume will be visible to both the host and container. When\nthe mount propagation policy is set to `slave`, one way mount propagation is enabled\nand any mounts completed on the host for that volume will be visible only inside of the container.\nTo control the mount propagation property of the volume use the `:[r]shared`,\n`:[r]slave` or `:[r]private` propagation flag. The propagation property can\nbe specified only for bind mounted volumes and not for internal volumes or\nnamed volumes. For mount propagation to work on the source mount point (the mount point\nwhere source dir is mounted on) it has to have the right propagation properties. For\nshared volumes, the source mount point has to be shared. And for slave volumes,\nthe source mount has to be either shared or slave. <sup>[[1]](#Footnote1)</sup>\n\nUse `df <source-dir>` to determine the source mount and then use\n`findmnt -o TARGET,PROPAGATION <source-mount-dir>` to determine propagation\nproperties of source mount, if `findmnt` utility is not available, the source mount point\ncan be determined by looking at the mount entry in `/proc/self/mountinfo`. Look\nat `optional fields` and see if any propagation properties are specified.\n`shared:X` means the mount is `shared`, `master:X` means the mount is `slave` and if\nnothing is there that means the mount is `private`. <sup>[[1]](#Footnote1)</sup>\n\nTo change propagation properties of a mount point use the `mount` command. For\nexample, to bind mount the source directory `/foo` do\n`mount --bind /foo /foo` and `mount --make-private --make-shared /foo`. This\nwill convert /foo into a `shared` mount point.  The propagation properties of the source\nmount can be changed directly. For instance if `/` is the source mount for\n`/foo`, then use `mount --make-shared /` to convert `/` into a `shared` mount.\n\n**--workingdir** *directory*\n\nTemporarily set the working *directory* for the running process. Unlike\n`buildah config --workingdir`, the workingdir will not persist to later\ncalls to `buildah run` or the built image.\n\n\nNOTE: End parsing of options with the `--` option, so that other\noptions can be passed to the command inside of the container.\n\n## EXAMPLE\n\nbuildah run containerID -- ps -auxw\n\nbuildah run --hostname myhost containerID -- ps -auxw\n\nbuildah run containerID -- sh -c 'echo $PATH'\n\nbuildah run --runtime-flag log-format=json containerID /bin/bash\n\nbuildah run --runtime-flag debug containerID /bin/bash\n\nbuildah run --tty containerID /bin/bash\n\nbuildah run --tty=false containerID ls /\n\nbuildah run --volume /path/on/host:/path/in/container:ro,z containerID sh\n\nbuildah run -v /path/on/host:/path/in/container:z,U containerID sh\n\nbuildah run --mount type=bind,src=/tmp/on:host,dst=/in:container,ro containerID sh\n\n## SEE ALSO\nbuildah(1), buildah-from(1), buildah-config(1), namespaces(7), pid\\_namespaces(7), crun(1), runc(8)\n\n## FOOTNOTES\n<a name=\"Footnote1\">1</a>: The Buildah project is committed to inclusivity, a core value of open source. The `master` and `slave` mount propagation terminology used here is problematic and divisive, and should be changed. However, these terms are currently used within the Linux kernel and must be used as-is at this time. When the kernel maintainers rectify this usage, Buildah will follow suit immediately.\n"], "fixing_code": ["// +build linux\n\npackage chroot\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"os/exec\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"syscall\"\n\t\"time\"\n\t\"unsafe\"\n\n\t\"github.com/containers/buildah/bind\"\n\t\"github.com/containers/buildah/copier\"\n\t\"github.com/containers/buildah/util\"\n\t\"github.com/containers/storage/pkg/ioutils\"\n\t\"github.com/containers/storage/pkg/mount\"\n\t\"github.com/containers/storage/pkg/reexec\"\n\t\"github.com/containers/storage/pkg/unshare\"\n\t\"github.com/opencontainers/runc/libcontainer/apparmor\"\n\t\"github.com/opencontainers/runtime-spec/specs-go\"\n\t\"github.com/pkg/errors\"\n\t\"github.com/sirupsen/logrus\"\n\t\"github.com/syndtr/gocapability/capability\"\n\t\"golang.org/x/crypto/ssh/terminal\"\n\t\"golang.org/x/sys/unix\"\n)\n\nconst (\n\t// runUsingChrootCommand is a command we use as a key for reexec\n\trunUsingChrootCommand = \"buildah-chroot-runtime\"\n\t// runUsingChrootExec is a command we use as a key for reexec\n\trunUsingChrootExecCommand = \"buildah-chroot-exec\"\n)\n\nvar (\n\trlimitsMap = map[string]int{\n\t\t\"RLIMIT_AS\":         unix.RLIMIT_AS,\n\t\t\"RLIMIT_CORE\":       unix.RLIMIT_CORE,\n\t\t\"RLIMIT_CPU\":        unix.RLIMIT_CPU,\n\t\t\"RLIMIT_DATA\":       unix.RLIMIT_DATA,\n\t\t\"RLIMIT_FSIZE\":      unix.RLIMIT_FSIZE,\n\t\t\"RLIMIT_LOCKS\":      unix.RLIMIT_LOCKS,\n\t\t\"RLIMIT_MEMLOCK\":    unix.RLIMIT_MEMLOCK,\n\t\t\"RLIMIT_MSGQUEUE\":   unix.RLIMIT_MSGQUEUE,\n\t\t\"RLIMIT_NICE\":       unix.RLIMIT_NICE,\n\t\t\"RLIMIT_NOFILE\":     unix.RLIMIT_NOFILE,\n\t\t\"RLIMIT_NPROC\":      unix.RLIMIT_NPROC,\n\t\t\"RLIMIT_RSS\":        unix.RLIMIT_RSS,\n\t\t\"RLIMIT_RTPRIO\":     unix.RLIMIT_RTPRIO,\n\t\t\"RLIMIT_RTTIME\":     unix.RLIMIT_RTTIME,\n\t\t\"RLIMIT_SIGPENDING\": unix.RLIMIT_SIGPENDING,\n\t\t\"RLIMIT_STACK\":      unix.RLIMIT_STACK,\n\t}\n\trlimitsReverseMap = map[int]string{}\n)\n\nfunc init() {\n\treexec.Register(runUsingChrootCommand, runUsingChrootMain)\n\treexec.Register(runUsingChrootExecCommand, runUsingChrootExecMain)\n\tfor limitName, limitNumber := range rlimitsMap {\n\t\trlimitsReverseMap[limitNumber] = limitName\n\t}\n}\n\ntype runUsingChrootSubprocOptions struct {\n\tSpec        *specs.Spec\n\tBundlePath  string\n\tUIDMappings []syscall.SysProcIDMap\n\tGIDMappings []syscall.SysProcIDMap\n}\n\ntype runUsingChrootExecSubprocOptions struct {\n\tSpec       *specs.Spec\n\tBundlePath string\n}\n\n// RunUsingChroot runs a chrooted process, using some of the settings from the\n// passed-in spec, and using the specified bundlePath to hold temporary files,\n// directories, and mountpoints.\nfunc RunUsingChroot(spec *specs.Spec, bundlePath, homeDir string, stdin io.Reader, stdout, stderr io.Writer) (err error) {\n\tvar confwg sync.WaitGroup\n\tvar homeFound bool\n\tfor _, env := range spec.Process.Env {\n\t\tif strings.HasPrefix(env, \"HOME=\") {\n\t\t\thomeFound = true\n\t\t\tbreak\n\t\t}\n\t}\n\tif !homeFound {\n\t\tspec.Process.Env = append(spec.Process.Env, fmt.Sprintf(\"HOME=%s\", homeDir))\n\t}\n\truntime.LockOSThread()\n\tdefer runtime.UnlockOSThread()\n\n\t// Write the runtime configuration, mainly for debugging.\n\tspecbytes, err := json.Marshal(spec)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif err = ioutils.AtomicWriteFile(filepath.Join(bundlePath, \"config.json\"), specbytes, 0600); err != nil {\n\t\treturn errors.Wrapf(err, \"error storing runtime configuration\")\n\t}\n\tlogrus.Debugf(\"config = %v\", string(specbytes))\n\n\t// Default to using stdin/stdout/stderr if we weren't passed objects to use.\n\tif stdin == nil {\n\t\tstdin = os.Stdin\n\t}\n\tif stdout == nil {\n\t\tstdout = os.Stdout\n\t}\n\tif stderr == nil {\n\t\tstderr = os.Stderr\n\t}\n\n\t// Create a pipe for passing configuration down to the next process.\n\tpreader, pwriter, err := os.Pipe()\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"error creating configuration pipe\")\n\t}\n\tconfig, conferr := json.Marshal(runUsingChrootSubprocOptions{\n\t\tSpec:       spec,\n\t\tBundlePath: bundlePath,\n\t})\n\tif conferr != nil {\n\t\treturn errors.Wrapf(conferr, \"error encoding configuration for %q\", runUsingChrootCommand)\n\t}\n\n\t// Set our terminal's mode to raw, to pass handling of special\n\t// terminal input to the terminal in the container.\n\tif spec.Process.Terminal && terminal.IsTerminal(unix.Stdin) {\n\t\tstate, err := terminal.MakeRaw(unix.Stdin)\n\t\tif err != nil {\n\t\t\tlogrus.Warnf(\"error setting terminal state: %v\", err)\n\t\t} else {\n\t\t\tdefer func() {\n\t\t\t\tif err = terminal.Restore(unix.Stdin, state); err != nil {\n\t\t\t\t\tlogrus.Errorf(\"unable to restore terminal state: %v\", err)\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t}\n\n\t// Raise any resource limits that are higher than they are now, before\n\t// we drop any more privileges.\n\tif err = setRlimits(spec, false, true); err != nil {\n\t\treturn err\n\t}\n\n\t// Start the grandparent subprocess.\n\tcmd := unshare.Command(runUsingChrootCommand)\n\tcmd.Stdin, cmd.Stdout, cmd.Stderr = stdin, stdout, stderr\n\tcmd.Dir = \"/\"\n\tcmd.Env = []string{fmt.Sprintf(\"LOGLEVEL=%d\", logrus.GetLevel())}\n\n\tlogrus.Debugf(\"Running %#v in %#v\", cmd.Cmd, cmd)\n\tconfwg.Add(1)\n\tgo func() {\n\t\t_, conferr = io.Copy(pwriter, bytes.NewReader(config))\n\t\tpwriter.Close()\n\t\tconfwg.Done()\n\t}()\n\tcmd.ExtraFiles = append([]*os.File{preader}, cmd.ExtraFiles...)\n\terr = cmd.Run()\n\tconfwg.Wait()\n\tif err == nil {\n\t\treturn conferr\n\t}\n\treturn err\n}\n\n// main() for grandparent subprocess.  Its main job is to shuttle stdio back\n// and forth, managing a pseudo-terminal if we want one, for our child, the\n// parent subprocess.\nfunc runUsingChrootMain() {\n\tvar options runUsingChrootSubprocOptions\n\n\truntime.LockOSThread()\n\n\t// Set logging.\n\tif level := os.Getenv(\"LOGLEVEL\"); level != \"\" {\n\t\tif ll, err := strconv.Atoi(level); err == nil {\n\t\t\tlogrus.SetLevel(logrus.Level(ll))\n\t\t}\n\t\tos.Unsetenv(\"LOGLEVEL\")\n\t}\n\n\t// Unpack our configuration.\n\tconfPipe := os.NewFile(3, \"confpipe\")\n\tif confPipe == nil {\n\t\tfmt.Fprintf(os.Stderr, \"error reading options pipe\\n\")\n\t\tos.Exit(1)\n\t}\n\tdefer confPipe.Close()\n\tif err := json.NewDecoder(confPipe).Decode(&options); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error decoding options: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\tif options.Spec == nil || options.Spec.Process == nil {\n\t\tfmt.Fprintf(os.Stderr, \"invalid options spec in runUsingChrootMain\\n\")\n\t\tos.Exit(1)\n\t}\n\n\t// Prepare to shuttle stdio back and forth.\n\trootUID32, rootGID32, err := util.GetHostRootIDs(options.Spec)\n\tif err != nil {\n\t\tlogrus.Errorf(\"error determining ownership for container stdio\")\n\t\tos.Exit(1)\n\t}\n\trootUID := int(rootUID32)\n\trootGID := int(rootGID32)\n\trelays := make(map[int]int)\n\tcloseOnceRunning := []*os.File{}\n\tvar ctty *os.File\n\tvar stdin io.Reader\n\tvar stdinCopy io.WriteCloser\n\tvar stdout io.Writer\n\tvar stderr io.Writer\n\tfdDesc := make(map[int]string)\n\tif options.Spec.Process.Terminal {\n\t\t// Create a pseudo-terminal -- open a copy of the master side.\n\t\tptyMasterFd, err := unix.Open(\"/dev/ptmx\", os.O_RDWR, 0600)\n\t\tif err != nil {\n\t\t\tlogrus.Errorf(\"error opening PTY master using /dev/ptmx: %v\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\t// Set the kernel's lock to \"unlocked\".\n\t\tlocked := 0\n\t\tif result, _, err := unix.Syscall(unix.SYS_IOCTL, uintptr(ptyMasterFd), unix.TIOCSPTLCK, uintptr(unsafe.Pointer(&locked))); int(result) == -1 {\n\t\t\tlogrus.Errorf(\"error locking PTY descriptor: %v\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\t// Get a handle for the other end.\n\t\tptyFd, _, err := unix.Syscall(unix.SYS_IOCTL, uintptr(ptyMasterFd), unix.TIOCGPTPEER, unix.O_RDWR|unix.O_NOCTTY)\n\t\tif int(ptyFd) == -1 {\n\t\t\tif errno, isErrno := err.(syscall.Errno); !isErrno || (errno != syscall.EINVAL && errno != syscall.ENOTTY) {\n\t\t\t\tlogrus.Errorf(\"error getting PTY descriptor: %v\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\t// EINVAL means the kernel's too old to understand TIOCGPTPEER.  Try TIOCGPTN.\n\t\t\tptyN, err := unix.IoctlGetInt(ptyMasterFd, unix.TIOCGPTN)\n\t\t\tif err != nil {\n\t\t\t\tlogrus.Errorf(\"error getting PTY number: %v\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tptyName := fmt.Sprintf(\"/dev/pts/%d\", ptyN)\n\t\t\tfd, err := unix.Open(ptyName, unix.O_RDWR|unix.O_NOCTTY, 0620)\n\t\t\tif err != nil {\n\t\t\t\tlogrus.Errorf(\"error opening PTY %q: %v\", ptyName, err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tptyFd = uintptr(fd)\n\t\t}\n\t\t// Make notes about what's going where.\n\t\trelays[ptyMasterFd] = unix.Stdout\n\t\trelays[unix.Stdin] = ptyMasterFd\n\t\tfdDesc[ptyMasterFd] = \"container terminal\"\n\t\tfdDesc[unix.Stdin] = \"stdin\"\n\t\tfdDesc[unix.Stdout] = \"stdout\"\n\t\twinsize := &unix.Winsize{}\n\t\t// Set the pseudoterminal's size to the configured size, or our own.\n\t\tif options.Spec.Process.ConsoleSize != nil {\n\t\t\t// Use configured sizes.\n\t\t\twinsize.Row = uint16(options.Spec.Process.ConsoleSize.Height)\n\t\t\twinsize.Col = uint16(options.Spec.Process.ConsoleSize.Width)\n\t\t} else {\n\t\t\tif terminal.IsTerminal(unix.Stdin) {\n\t\t\t\t// Use the size of our terminal.\n\t\t\t\twinsize, err = unix.IoctlGetWinsize(unix.Stdin, unix.TIOCGWINSZ)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlogrus.Debugf(\"error reading current terminal's size\")\n\t\t\t\t\twinsize.Row = 0\n\t\t\t\t\twinsize.Col = 0\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif winsize.Row != 0 && winsize.Col != 0 {\n\t\t\tif err = unix.IoctlSetWinsize(int(ptyFd), unix.TIOCSWINSZ, winsize); err != nil {\n\t\t\t\tlogrus.Warnf(\"error setting terminal size for pty\")\n\t\t\t}\n\t\t\t// FIXME - if we're connected to a terminal, we should\n\t\t\t// be passing the updated terminal size down when we\n\t\t\t// receive a SIGWINCH.\n\t\t}\n\t\t// Open an *os.File object that we can pass to our child.\n\t\tctty = os.NewFile(ptyFd, \"/dev/tty\")\n\t\t// Set ownership for the PTY.\n\t\tif err = ctty.Chown(rootUID, rootGID); err != nil {\n\t\t\tvar cttyInfo unix.Stat_t\n\t\t\terr2 := unix.Fstat(int(ptyFd), &cttyInfo)\n\t\t\tfrom := \"\"\n\t\t\top := \"setting\"\n\t\t\tif err2 == nil {\n\t\t\t\top = \"changing\"\n\t\t\t\tfrom = fmt.Sprintf(\"from %d/%d \", cttyInfo.Uid, cttyInfo.Gid)\n\t\t\t}\n\t\t\tlogrus.Warnf(\"error %s ownership of container PTY %sto %d/%d: %v\", op, from, rootUID, rootGID, err)\n\t\t}\n\t\t// Set permissions on the PTY.\n\t\tif err = ctty.Chmod(0620); err != nil {\n\t\t\tlogrus.Errorf(\"error setting permissions of container PTY: %v\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\t// Make a note that our child (the parent subprocess) should\n\t\t// have the PTY connected to its stdio, and that we should\n\t\t// close it once it's running.\n\t\tstdin = ctty\n\t\tstdout = ctty\n\t\tstderr = ctty\n\t\tcloseOnceRunning = append(closeOnceRunning, ctty)\n\t} else {\n\t\t// Create pipes for stdio.\n\t\tstdinRead, stdinWrite, err := os.Pipe()\n\t\tif err != nil {\n\t\t\tlogrus.Errorf(\"error opening pipe for stdin: %v\", err)\n\t\t}\n\t\tstdoutRead, stdoutWrite, err := os.Pipe()\n\t\tif err != nil {\n\t\t\tlogrus.Errorf(\"error opening pipe for stdout: %v\", err)\n\t\t}\n\t\tstderrRead, stderrWrite, err := os.Pipe()\n\t\tif err != nil {\n\t\t\tlogrus.Errorf(\"error opening pipe for stderr: %v\", err)\n\t\t}\n\t\t// Make notes about what's going where.\n\t\trelays[unix.Stdin] = int(stdinWrite.Fd())\n\t\trelays[int(stdoutRead.Fd())] = unix.Stdout\n\t\trelays[int(stderrRead.Fd())] = unix.Stderr\n\t\tfdDesc[int(stdinWrite.Fd())] = \"container stdin pipe\"\n\t\tfdDesc[int(stdoutRead.Fd())] = \"container stdout pipe\"\n\t\tfdDesc[int(stderrRead.Fd())] = \"container stderr pipe\"\n\t\tfdDesc[unix.Stdin] = \"stdin\"\n\t\tfdDesc[unix.Stdout] = \"stdout\"\n\t\tfdDesc[unix.Stderr] = \"stderr\"\n\t\t// Set ownership for the pipes.\n\t\tif err = stdinRead.Chown(rootUID, rootGID); err != nil {\n\t\t\tlogrus.Errorf(\"error setting ownership of container stdin pipe: %v\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\tif err = stdoutWrite.Chown(rootUID, rootGID); err != nil {\n\t\t\tlogrus.Errorf(\"error setting ownership of container stdout pipe: %v\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\tif err = stderrWrite.Chown(rootUID, rootGID); err != nil {\n\t\t\tlogrus.Errorf(\"error setting ownership of container stderr pipe: %v\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\t// Make a note that our child (the parent subprocess) should\n\t\t// have the pipes connected to its stdio, and that we should\n\t\t// close its ends of them once it's running.\n\t\tstdin = stdinRead\n\t\tstdout = stdoutWrite\n\t\tstderr = stderrWrite\n\t\tcloseOnceRunning = append(closeOnceRunning, stdinRead, stdoutWrite, stderrWrite)\n\t\tstdinCopy = stdinWrite\n\t\tdefer stdoutRead.Close()\n\t\tdefer stderrRead.Close()\n\t}\n\tfor readFd, writeFd := range relays {\n\t\tif err := unix.SetNonblock(readFd, true); err != nil {\n\t\t\tlogrus.Errorf(\"error setting descriptor %d (%s) non-blocking: %v\", readFd, fdDesc[readFd], err)\n\t\t\treturn\n\t\t}\n\t\tif err := unix.SetNonblock(writeFd, false); err != nil {\n\t\t\tlogrus.Errorf(\"error setting descriptor %d (%s) blocking: %v\", relays[writeFd], fdDesc[writeFd], err)\n\t\t\treturn\n\t\t}\n\t}\n\tif err := unix.SetNonblock(relays[unix.Stdin], true); err != nil {\n\t\tlogrus.Errorf(\"error setting %d to nonblocking: %v\", relays[unix.Stdin], err)\n\t}\n\tgo func() {\n\t\tbuffers := make(map[int]*bytes.Buffer)\n\t\tfor _, writeFd := range relays {\n\t\t\tbuffers[writeFd] = new(bytes.Buffer)\n\t\t}\n\t\tpollTimeout := -1\n\t\tstdinClose := false\n\t\tfor len(relays) > 0 {\n\t\t\tfds := make([]unix.PollFd, 0, len(relays))\n\t\t\tfor fd := range relays {\n\t\t\t\tfds = append(fds, unix.PollFd{Fd: int32(fd), Events: unix.POLLIN | unix.POLLHUP})\n\t\t\t}\n\t\t\t_, err := unix.Poll(fds, pollTimeout)\n\t\t\tif !util.LogIfNotRetryable(err, fmt.Sprintf(\"poll: %v\", err)) {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tremoveFds := make(map[int]struct{})\n\t\t\tfor _, rfd := range fds {\n\t\t\t\tif rfd.Revents&unix.POLLHUP == unix.POLLHUP {\n\t\t\t\t\tremoveFds[int(rfd.Fd)] = struct{}{}\n\t\t\t\t}\n\t\t\t\tif rfd.Revents&unix.POLLNVAL == unix.POLLNVAL {\n\t\t\t\t\tlogrus.Debugf(\"error polling descriptor %s: closed?\", fdDesc[int(rfd.Fd)])\n\t\t\t\t\tremoveFds[int(rfd.Fd)] = struct{}{}\n\t\t\t\t}\n\t\t\t\tif rfd.Revents&unix.POLLIN == 0 {\n\t\t\t\t\tif stdinClose && stdinCopy == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tb := make([]byte, 8192)\n\t\t\t\tnread, err := unix.Read(int(rfd.Fd), b)\n\t\t\t\tutil.LogIfNotRetryable(err, fmt.Sprintf(\"read %s: %v\", fdDesc[int(rfd.Fd)], err))\n\t\t\t\tif nread > 0 {\n\t\t\t\t\tif wfd, ok := relays[int(rfd.Fd)]; ok {\n\t\t\t\t\t\tnwritten, err := buffers[wfd].Write(b[:nread])\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\tlogrus.Debugf(\"buffer: %v\", err)\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif nwritten != nread {\n\t\t\t\t\t\t\tlogrus.Debugf(\"buffer: expected to buffer %d bytes, wrote %d\", nread, nwritten)\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t// If this is the last of the data we'll be able to read\n\t\t\t\t\t// from this descriptor, read as much as there is to read.\n\t\t\t\t\tfor rfd.Revents&unix.POLLHUP == unix.POLLHUP {\n\t\t\t\t\t\tnr, err := unix.Read(int(rfd.Fd), b)\n\t\t\t\t\t\tutil.LogIfUnexpectedWhileDraining(err, fmt.Sprintf(\"read %s: %v\", fdDesc[int(rfd.Fd)], err))\n\t\t\t\t\t\tif nr <= 0 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif wfd, ok := relays[int(rfd.Fd)]; ok {\n\t\t\t\t\t\t\tnwritten, err := buffers[wfd].Write(b[:nr])\n\t\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t\tlogrus.Debugf(\"buffer: %v\", err)\n\t\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif nwritten != nr {\n\t\t\t\t\t\t\t\tlogrus.Debugf(\"buffer: expected to buffer %d bytes, wrote %d\", nr, nwritten)\n\t\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif nread == 0 {\n\t\t\t\t\tremoveFds[int(rfd.Fd)] = struct{}{}\n\t\t\t\t}\n\t\t\t}\n\t\t\tpollTimeout = -1\n\t\t\tfor wfd, buffer := range buffers {\n\t\t\t\tif buffer.Len() > 0 {\n\t\t\t\t\tnwritten, err := unix.Write(wfd, buffer.Bytes())\n\t\t\t\t\tutil.LogIfNotRetryable(err, fmt.Sprintf(\"write %s: %v\", fdDesc[wfd], err))\n\t\t\t\t\tif nwritten >= 0 {\n\t\t\t\t\t\t_ = buffer.Next(nwritten)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif buffer.Len() > 0 {\n\t\t\t\t\tpollTimeout = 100\n\t\t\t\t}\n\t\t\t\tif wfd == relays[unix.Stdin] && stdinClose && buffer.Len() == 0 {\n\t\t\t\t\tstdinCopy.Close()\n\t\t\t\t\tdelete(relays, unix.Stdin)\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor rfd := range removeFds {\n\t\t\t\tif rfd == unix.Stdin {\n\t\t\t\t\tbuffer, found := buffers[relays[unix.Stdin]]\n\t\t\t\t\tif found && buffer.Len() > 0 {\n\t\t\t\t\t\tstdinClose = true\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif !options.Spec.Process.Terminal && rfd == unix.Stdin {\n\t\t\t\t\tstdinCopy.Close()\n\t\t\t\t}\n\t\t\t\tdelete(relays, rfd)\n\t\t\t}\n\t\t}\n\t}()\n\n\t// Set up mounts and namespaces, and run the parent subprocess.\n\tstatus, err := runUsingChroot(options.Spec, options.BundlePath, ctty, stdin, stdout, stderr, closeOnceRunning)\n\tif err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error running subprocess: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Pass the process's exit status back to the caller by exiting with the same status.\n\tif status.Exited() {\n\t\tif status.ExitStatus() != 0 {\n\t\t\tfmt.Fprintf(os.Stderr, \"subprocess exited with status %d\\n\", status.ExitStatus())\n\t\t}\n\t\tos.Exit(status.ExitStatus())\n\t} else if status.Signaled() {\n\t\tfmt.Fprintf(os.Stderr, \"subprocess exited on %s\\n\", status.Signal())\n\t\tos.Exit(1)\n\t}\n}\n\n// runUsingChroot, still in the grandparent process, sets up various bind\n// mounts and then runs the parent process in its own user namespace with the\n// necessary ID mappings.\nfunc runUsingChroot(spec *specs.Spec, bundlePath string, ctty *os.File, stdin io.Reader, stdout, stderr io.Writer, closeOnceRunning []*os.File) (wstatus unix.WaitStatus, err error) {\n\tvar confwg sync.WaitGroup\n\n\t// Create a new mount namespace for ourselves and bind mount everything to a new location.\n\tundoIntermediates, err := bind.SetupIntermediateMountNamespace(spec, bundlePath)\n\tif err != nil {\n\t\treturn 1, err\n\t}\n\tdefer func() {\n\t\tif undoErr := undoIntermediates(); undoErr != nil {\n\t\t\tlogrus.Debugf(\"error cleaning up intermediate mount NS: %v\", err)\n\t\t}\n\t}()\n\n\t// Bind mount in our filesystems.\n\tundoChroots, err := setupChrootBindMounts(spec, bundlePath)\n\tif err != nil {\n\t\treturn 1, err\n\t}\n\tdefer func() {\n\t\tif undoErr := undoChroots(); undoErr != nil {\n\t\t\tlogrus.Debugf(\"error cleaning up intermediate chroot bind mounts: %v\", err)\n\t\t}\n\t}()\n\n\t// Create a pipe for passing configuration down to the next process.\n\tpreader, pwriter, err := os.Pipe()\n\tif err != nil {\n\t\treturn 1, errors.Wrapf(err, \"error creating configuration pipe\")\n\t}\n\tconfig, conferr := json.Marshal(runUsingChrootExecSubprocOptions{\n\t\tSpec:       spec,\n\t\tBundlePath: bundlePath,\n\t})\n\tif conferr != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error re-encoding configuration for %q\", runUsingChrootExecCommand)\n\t\tos.Exit(1)\n\t}\n\n\t// Apologize for the namespace configuration that we're about to ignore.\n\tlogNamespaceDiagnostics(spec)\n\n\t// If we have configured ID mappings, set them here so that they can apply to the child.\n\thostUidmap, hostGidmap, err := unshare.GetHostIDMappings(\"\")\n\tif err != nil {\n\t\treturn 1, err\n\t}\n\tuidmap, gidmap := spec.Linux.UIDMappings, spec.Linux.GIDMappings\n\tif len(uidmap) == 0 {\n\t\t// No UID mappings are configured for the container.  Borrow our parent's mappings.\n\t\tuidmap = append([]specs.LinuxIDMapping{}, hostUidmap...)\n\t\tfor i := range uidmap {\n\t\t\tuidmap[i].HostID = uidmap[i].ContainerID\n\t\t}\n\t}\n\tif len(gidmap) == 0 {\n\t\t// No GID mappings are configured for the container.  Borrow our parent's mappings.\n\t\tgidmap = append([]specs.LinuxIDMapping{}, hostGidmap...)\n\t\tfor i := range gidmap {\n\t\t\tgidmap[i].HostID = gidmap[i].ContainerID\n\t\t}\n\t}\n\n\t// Start the parent subprocess.\n\tcmd := unshare.Command(append([]string{runUsingChrootExecCommand}, spec.Process.Args...)...)\n\tcmd.Stdin, cmd.Stdout, cmd.Stderr = stdin, stdout, stderr\n\tcmd.Dir = \"/\"\n\tcmd.Env = []string{fmt.Sprintf(\"LOGLEVEL=%d\", logrus.GetLevel())}\n\tcmd.UnshareFlags = syscall.CLONE_NEWUTS | syscall.CLONE_NEWNS\n\trequestedUserNS := false\n\tfor _, ns := range spec.Linux.Namespaces {\n\t\tif ns.Type == specs.UserNamespace {\n\t\t\trequestedUserNS = true\n\t\t}\n\t}\n\tif len(spec.Linux.UIDMappings) > 0 || len(spec.Linux.GIDMappings) > 0 || requestedUserNS {\n\t\tcmd.UnshareFlags = cmd.UnshareFlags | syscall.CLONE_NEWUSER\n\t\tcmd.UidMappings = uidmap\n\t\tcmd.GidMappings = gidmap\n\t\tcmd.GidMappingsEnableSetgroups = true\n\t}\n\tif ctty != nil {\n\t\tcmd.Setsid = true\n\t\tcmd.Ctty = ctty\n\t}\n\tcmd.OOMScoreAdj = spec.Process.OOMScoreAdj\n\tcmd.ExtraFiles = append([]*os.File{preader}, cmd.ExtraFiles...)\n\tcmd.Hook = func(int) error {\n\t\tfor _, f := range closeOnceRunning {\n\t\t\tf.Close()\n\t\t}\n\t\treturn nil\n\t}\n\n\tlogrus.Debugf(\"Running %#v in %#v\", cmd.Cmd, cmd)\n\tconfwg.Add(1)\n\tgo func() {\n\t\t_, conferr = io.Copy(pwriter, bytes.NewReader(config))\n\t\tpwriter.Close()\n\t\tconfwg.Done()\n\t}()\n\terr = cmd.Run()\n\tconfwg.Wait()\n\tif err != nil {\n\t\tif exitError, ok := err.(*exec.ExitError); ok {\n\t\t\tif waitStatus, ok := exitError.ProcessState.Sys().(syscall.WaitStatus); ok {\n\t\t\t\tif waitStatus.Exited() {\n\t\t\t\t\tif waitStatus.ExitStatus() != 0 {\n\t\t\t\t\t\tfmt.Fprintf(os.Stderr, \"subprocess exited with status %d\\n\", waitStatus.ExitStatus())\n\t\t\t\t\t}\n\t\t\t\t\tos.Exit(waitStatus.ExitStatus())\n\t\t\t\t} else if waitStatus.Signaled() {\n\t\t\t\t\tfmt.Fprintf(os.Stderr, \"subprocess exited on %s\\n\", waitStatus.Signal())\n\t\t\t\t\tos.Exit(1)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfmt.Fprintf(os.Stderr, \"process exited with error: %v\", err)\n\t\tos.Exit(1)\n\t}\n\n\treturn 0, nil\n}\n\n// main() for parent subprocess.  Its main job is to try to make our\n// environment look like the one described by the runtime configuration blob,\n// and then launch the intended command as a child.\nfunc runUsingChrootExecMain() {\n\targs := os.Args[1:]\n\tvar options runUsingChrootExecSubprocOptions\n\tvar err error\n\n\truntime.LockOSThread()\n\n\t// Set logging.\n\tif level := os.Getenv(\"LOGLEVEL\"); level != \"\" {\n\t\tif ll, err := strconv.Atoi(level); err == nil {\n\t\t\tlogrus.SetLevel(logrus.Level(ll))\n\t\t}\n\t\tos.Unsetenv(\"LOGLEVEL\")\n\t}\n\n\t// Unpack our configuration.\n\tconfPipe := os.NewFile(3, \"confpipe\")\n\tif confPipe == nil {\n\t\tfmt.Fprintf(os.Stderr, \"error reading options pipe\\n\")\n\t\tos.Exit(1)\n\t}\n\tdefer confPipe.Close()\n\tif err := json.NewDecoder(confPipe).Decode(&options); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error decoding options: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Set the hostname.  We're already in a distinct UTS namespace and are admins in the user\n\t// namespace which created it, so we shouldn't get a permissions error, but seccomp policy\n\t// might deny our attempt to call sethostname() anyway, so log a debug message for that.\n\tif options.Spec == nil || options.Spec.Process == nil {\n\t\tfmt.Fprintf(os.Stderr, \"invalid options spec passed in\\n\")\n\t\tos.Exit(1)\n\t}\n\n\tif options.Spec.Hostname != \"\" {\n\t\tif err := unix.Sethostname([]byte(options.Spec.Hostname)); err != nil {\n\t\t\tlogrus.Debugf(\"failed to set hostname %q for process: %v\", options.Spec.Hostname, err)\n\t\t}\n\t}\n\n\t// Try to chroot into the root.  Do this before we potentially block the syscall via the\n\t// seccomp profile.\n\tvar oldst, newst unix.Stat_t\n\tif err := unix.Stat(options.Spec.Root.Path, &oldst); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error stat()ing intended root directory %q: %v\\n\", options.Spec.Root.Path, err)\n\t\tos.Exit(1)\n\t}\n\tif err := unix.Chdir(options.Spec.Root.Path); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error chdir()ing to intended root directory %q: %v\\n\", options.Spec.Root.Path, err)\n\t\tos.Exit(1)\n\t}\n\tif err := unix.Chroot(options.Spec.Root.Path); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error chroot()ing into directory %q: %v\\n\", options.Spec.Root.Path, err)\n\t\tos.Exit(1)\n\t}\n\tif err := unix.Stat(\"/\", &newst); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error stat()ing current root directory: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tif oldst.Dev != newst.Dev || oldst.Ino != newst.Ino {\n\t\tfmt.Fprintf(os.Stderr, \"unknown error chroot()ing into directory %q: %v\\n\", options.Spec.Root.Path, err)\n\t\tos.Exit(1)\n\t}\n\tlogrus.Debugf(\"chrooted into %q\", options.Spec.Root.Path)\n\n\t// not doing because it's still shared: creating devices\n\t// not doing because it's not applicable: setting annotations\n\t// not doing because it's still shared: setting sysctl settings\n\t// not doing because cgroupfs is read only: configuring control groups\n\t// -> this means we can use the freezer to make sure there aren't any lingering processes\n\t// -> this means we ignore cgroups-based controls\n\t// not doing because we don't set any in the config: running hooks\n\t// not doing because we don't set it in the config: setting rootfs read-only\n\t// not doing because we don't set it in the config: setting rootfs propagation\n\tlogrus.Debugf(\"setting apparmor profile\")\n\tif err = setApparmorProfile(options.Spec); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error setting apparmor profile for process: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tif err = setSelinuxLabel(options.Spec); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error setting SELinux label for process: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\tlogrus.Debugf(\"setting resource limits\")\n\tif err = setRlimits(options.Spec, false, false); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error setting process resource limits for process: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Try to change to the directory.\n\tcwd := options.Spec.Process.Cwd\n\tif !filepath.IsAbs(cwd) {\n\t\tcwd = \"/\" + cwd\n\t}\n\tcwd = filepath.Clean(cwd)\n\tif err := unix.Chdir(\"/\"); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error chdir()ing into new root directory %q: %v\\n\", options.Spec.Root.Path, err)\n\t\tos.Exit(1)\n\t}\n\tif err := unix.Chdir(cwd); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error chdir()ing into directory %q under root %q: %v\\n\", cwd, options.Spec.Root.Path, err)\n\t\tos.Exit(1)\n\t}\n\tlogrus.Debugf(\"changed working directory to %q\", cwd)\n\n\t// Drop privileges.\n\tuser := options.Spec.Process.User\n\tif len(user.AdditionalGids) > 0 {\n\t\tgids := make([]int, len(user.AdditionalGids))\n\t\tfor i := range user.AdditionalGids {\n\t\t\tgids[i] = int(user.AdditionalGids[i])\n\t\t}\n\t\tlogrus.Debugf(\"setting supplemental groups\")\n\t\tif err = syscall.Setgroups(gids); err != nil {\n\t\t\tfmt.Fprintf(os.Stderr, \"error setting supplemental groups list: %v\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t} else {\n\t\tsetgroups, _ := ioutil.ReadFile(\"/proc/self/setgroups\")\n\t\tif strings.Trim(string(setgroups), \"\\n\") != \"deny\" {\n\t\t\tlogrus.Debugf(\"clearing supplemental groups\")\n\t\t\tif err = syscall.Setgroups([]int{}); err != nil {\n\t\t\t\tfmt.Fprintf(os.Stderr, \"error clearing supplemental groups list: %v\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t}\n\t}\n\n\tlogrus.Debugf(\"setting gid\")\n\tif err = syscall.Setresgid(int(user.GID), int(user.GID), int(user.GID)); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error setting GID: %v\", err)\n\t\tos.Exit(1)\n\t}\n\n\tif err = setSeccomp(options.Spec); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error setting seccomp filter for process: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\tlogrus.Debugf(\"setting capabilities\")\n\tvar keepCaps []string\n\tif user.UID != 0 {\n\t\tkeepCaps = []string{\"CAP_SETUID\"}\n\t}\n\tif err := setCapabilities(options.Spec, keepCaps...); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error setting capabilities for process: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\tlogrus.Debugf(\"setting uid\")\n\tif err = syscall.Setresuid(int(user.UID), int(user.UID), int(user.UID)); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error setting UID: %v\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Actually run the specified command.\n\tcmd := exec.Command(args[0], args[1:]...)\n\tcmd.Env = options.Spec.Process.Env\n\tcmd.Stdin, cmd.Stdout, cmd.Stderr = os.Stdin, os.Stdout, os.Stderr\n\tcmd.Dir = cwd\n\tlogrus.Debugf(\"Running %#v (PATH = %q)\", cmd, os.Getenv(\"PATH\"))\n\tif err = cmd.Run(); err != nil {\n\t\tif exitError, ok := err.(*exec.ExitError); ok {\n\t\t\tif waitStatus, ok := exitError.ProcessState.Sys().(syscall.WaitStatus); ok {\n\t\t\t\tif waitStatus.Exited() {\n\t\t\t\t\tif waitStatus.ExitStatus() != 0 {\n\t\t\t\t\t\tfmt.Fprintf(os.Stderr, \"subprocess exited with status %d\\n\", waitStatus.ExitStatus())\n\t\t\t\t\t}\n\t\t\t\t\tos.Exit(waitStatus.ExitStatus())\n\t\t\t\t} else if waitStatus.Signaled() {\n\t\t\t\t\tfmt.Fprintf(os.Stderr, \"subprocess exited on %s\\n\", waitStatus.Signal())\n\t\t\t\t\tos.Exit(1)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfmt.Fprintf(os.Stderr, \"process exited with error: %v\", err)\n\t\tos.Exit(1)\n\t}\n}\n\n// logNamespaceDiagnostics knows which namespaces we want to create.\n// Output debug messages when that differs from what we're being asked to do.\nfunc logNamespaceDiagnostics(spec *specs.Spec) {\n\tsawMountNS := false\n\tsawUTSNS := false\n\tfor _, ns := range spec.Linux.Namespaces {\n\t\tswitch ns.Type {\n\t\tcase specs.CgroupNamespace:\n\t\t\tif ns.Path != \"\" {\n\t\t\t\tlogrus.Debugf(\"unable to join cgroup namespace, sorry about that\")\n\t\t\t} else {\n\t\t\t\tlogrus.Debugf(\"unable to create cgroup namespace, sorry about that\")\n\t\t\t}\n\t\tcase specs.IPCNamespace:\n\t\t\tif ns.Path != \"\" {\n\t\t\t\tlogrus.Debugf(\"unable to join IPC namespace, sorry about that\")\n\t\t\t} else {\n\t\t\t\tlogrus.Debugf(\"unable to create IPC namespace, sorry about that\")\n\t\t\t}\n\t\tcase specs.MountNamespace:\n\t\t\tif ns.Path != \"\" {\n\t\t\t\tlogrus.Debugf(\"unable to join mount namespace %q, creating a new one\", ns.Path)\n\t\t\t}\n\t\t\tsawMountNS = true\n\t\tcase specs.NetworkNamespace:\n\t\t\tif ns.Path != \"\" {\n\t\t\t\tlogrus.Debugf(\"unable to join network namespace, sorry about that\")\n\t\t\t} else {\n\t\t\t\tlogrus.Debugf(\"unable to create network namespace, sorry about that\")\n\t\t\t}\n\t\tcase specs.PIDNamespace:\n\t\t\tif ns.Path != \"\" {\n\t\t\t\tlogrus.Debugf(\"unable to join PID namespace, sorry about that\")\n\t\t\t} else {\n\t\t\t\tlogrus.Debugf(\"unable to create PID namespace, sorry about that\")\n\t\t\t}\n\t\tcase specs.UserNamespace:\n\t\t\tif ns.Path != \"\" {\n\t\t\t\tlogrus.Debugf(\"unable to join user namespace, sorry about that\")\n\t\t\t}\n\t\tcase specs.UTSNamespace:\n\t\t\tif ns.Path != \"\" {\n\t\t\t\tlogrus.Debugf(\"unable to join UTS namespace %q, creating a new one\", ns.Path)\n\t\t\t}\n\t\t\tsawUTSNS = true\n\t\t}\n\t}\n\tif !sawMountNS {\n\t\tlogrus.Debugf(\"mount namespace not requested, but creating a new one anyway\")\n\t}\n\tif !sawUTSNS {\n\t\tlogrus.Debugf(\"UTS namespace not requested, but creating a new one anyway\")\n\t}\n}\n\n// setApparmorProfile sets the apparmor profile for ourselves, and hopefully any child processes that we'll start.\nfunc setApparmorProfile(spec *specs.Spec) error {\n\tif !apparmor.IsEnabled() || spec.Process.ApparmorProfile == \"\" {\n\t\treturn nil\n\t}\n\tif err := apparmor.ApplyProfile(spec.Process.ApparmorProfile); err != nil {\n\t\treturn errors.Wrapf(err, \"error setting apparmor profile to %q\", spec.Process.ApparmorProfile)\n\t}\n\treturn nil\n}\n\n// setCapabilities sets capabilities for ourselves, to be more or less inherited by any processes that we'll start.\nfunc setCapabilities(spec *specs.Spec, keepCaps ...string) error {\n\tcurrentCaps, err := capability.NewPid(0)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"error reading capabilities of current process\")\n\t}\n\tcaps, err := capability.NewPid(0)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"error reading capabilities of current process\")\n\t}\n\tcapMap := map[capability.CapType][]string{\n\t\tcapability.BOUNDING:    spec.Process.Capabilities.Bounding,\n\t\tcapability.EFFECTIVE:   spec.Process.Capabilities.Effective,\n\t\tcapability.INHERITABLE: spec.Process.Capabilities.Inheritable,\n\t\tcapability.PERMITTED:   spec.Process.Capabilities.Permitted,\n\t\tcapability.AMBIENT:     spec.Process.Capabilities.Ambient,\n\t}\n\tknownCaps := capability.List()\n\tcaps.Clear(capability.CAPS | capability.BOUNDS | capability.AMBS)\n\tfor capType, capList := range capMap {\n\t\tfor _, capToSet := range capList {\n\t\t\tcap := capability.CAP_LAST_CAP\n\t\t\tfor _, c := range knownCaps {\n\t\t\t\tif strings.EqualFold(\"CAP_\"+c.String(), capToSet) {\n\t\t\t\t\tcap = c\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif cap == capability.CAP_LAST_CAP {\n\t\t\t\treturn errors.Errorf(\"error mapping capability %q to a number\", capToSet)\n\t\t\t}\n\t\t\tcaps.Set(capType, cap)\n\t\t}\n\t\tfor _, capToSet := range keepCaps {\n\t\t\tcap := capability.CAP_LAST_CAP\n\t\t\tfor _, c := range knownCaps {\n\t\t\t\tif strings.EqualFold(\"CAP_\"+c.String(), capToSet) {\n\t\t\t\t\tcap = c\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif cap == capability.CAP_LAST_CAP {\n\t\t\t\treturn errors.Errorf(\"error mapping capability %q to a number\", capToSet)\n\t\t\t}\n\t\t\tif currentCaps.Get(capType, cap) {\n\t\t\t\tcaps.Set(capType, cap)\n\t\t\t}\n\t\t}\n\t}\n\tif err = caps.Apply(capability.CAPS | capability.BOUNDS | capability.AMBS); err != nil {\n\t\treturn errors.Wrapf(err, \"error setting capabilities\")\n\t}\n\treturn nil\n}\n\n// parses the resource limits for ourselves and any processes that\n// we'll start into a format that's more in line with the kernel APIs\nfunc parseRlimits(spec *specs.Spec) (map[int]unix.Rlimit, error) {\n\tif spec.Process == nil {\n\t\treturn nil, nil\n\t}\n\tparsed := make(map[int]unix.Rlimit)\n\tfor _, limit := range spec.Process.Rlimits {\n\t\tresource, recognized := rlimitsMap[strings.ToUpper(limit.Type)]\n\t\tif !recognized {\n\t\t\treturn nil, errors.Errorf(\"error parsing limit type %q\", limit.Type)\n\t\t}\n\t\tparsed[resource] = unix.Rlimit{Cur: limit.Soft, Max: limit.Hard}\n\t}\n\treturn parsed, nil\n}\n\n// setRlimits sets any resource limits that we want to apply to processes that\n// we'll start.\nfunc setRlimits(spec *specs.Spec, onlyLower, onlyRaise bool) error {\n\tlimits, err := parseRlimits(spec)\n\tif err != nil {\n\t\treturn err\n\t}\n\tfor resource, desired := range limits {\n\t\tvar current unix.Rlimit\n\t\tif err := unix.Getrlimit(resource, &current); err != nil {\n\t\t\treturn errors.Wrapf(err, \"error reading %q limit\", rlimitsReverseMap[resource])\n\t\t}\n\t\tif desired.Max > current.Max && onlyLower {\n\t\t\t// this would raise a hard limit, and we're only here to lower them\n\t\t\tcontinue\n\t\t}\n\t\tif desired.Max < current.Max && onlyRaise {\n\t\t\t// this would lower a hard limit, and we're only here to raise them\n\t\t\tcontinue\n\t\t}\n\t\tif err := unix.Setrlimit(resource, &desired); err != nil {\n\t\t\treturn errors.Wrapf(err, \"error setting %q limit to soft=%d,hard=%d (was soft=%d,hard=%d)\", rlimitsReverseMap[resource], desired.Cur, desired.Max, current.Cur, current.Max)\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc makeReadOnly(mntpoint string, flags uintptr) error {\n\tvar fs unix.Statfs_t\n\t// Make sure it's read-only.\n\tif err := unix.Statfs(mntpoint, &fs); err != nil {\n\t\treturn errors.Wrapf(err, \"error checking if directory %q was bound read-only\", mntpoint)\n\t}\n\tif fs.Flags&unix.ST_RDONLY == 0 {\n\t\tif err := unix.Mount(mntpoint, mntpoint, \"bind\", flags|unix.MS_REMOUNT, \"\"); err != nil {\n\t\t\treturn errors.Wrapf(err, \"error remounting %s in mount namespace read-only\", mntpoint)\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc isDevNull(dev os.FileInfo) bool {\n\tif dev.Mode()&os.ModeCharDevice != 0 {\n\t\tstat, _ := dev.Sys().(*syscall.Stat_t)\n\t\tnullStat := syscall.Stat_t{}\n\t\tif err := syscall.Stat(os.DevNull, &nullStat); err != nil {\n\t\t\tlogrus.Warnf(\"unable to stat /dev/null: %v\", err)\n\t\t\treturn false\n\t\t}\n\t\tif stat.Rdev == nullStat.Rdev {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// setupChrootBindMounts actually bind mounts things under the rootfs, and returns a\n// callback that will clean up its work.\nfunc setupChrootBindMounts(spec *specs.Spec, bundlePath string) (undoBinds func() error, err error) {\n\tvar fs unix.Statfs_t\n\tundoBinds = func() error {\n\t\tif err2 := unix.Unmount(spec.Root.Path, unix.MNT_DETACH); err2 != nil {\n\t\t\tretries := 0\n\t\t\tfor (err2 == unix.EBUSY || err2 == unix.EAGAIN) && retries < 50 {\n\t\t\t\ttime.Sleep(50 * time.Millisecond)\n\t\t\t\terr2 = unix.Unmount(spec.Root.Path, unix.MNT_DETACH)\n\t\t\t\tretries++\n\t\t\t}\n\t\t\tif err2 != nil {\n\t\t\t\tlogrus.Warnf(\"pkg/chroot: error unmounting %q (retried %d times): %v\", spec.Root.Path, retries, err2)\n\t\t\t\tif err == nil {\n\t\t\t\t\terr = err2\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn err\n\t}\n\n\t// Now bind mount all of those things to be under the rootfs's location in this\n\t// mount namespace.\n\tcommonFlags := uintptr(unix.MS_BIND | unix.MS_REC | unix.MS_PRIVATE)\n\tbindFlags := commonFlags | unix.MS_NODEV\n\tdevFlags := commonFlags | unix.MS_NOEXEC | unix.MS_NOSUID | unix.MS_RDONLY\n\tprocFlags := devFlags | unix.MS_NODEV\n\tsysFlags := devFlags | unix.MS_NODEV\n\n\t// Bind /dev read-only.\n\tsubDev := filepath.Join(spec.Root.Path, \"/dev\")\n\tif err := unix.Mount(\"/dev\", subDev, \"bind\", devFlags, \"\"); err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\terr = os.Mkdir(subDev, 0755)\n\t\t\tif err == nil {\n\t\t\t\terr = unix.Mount(\"/dev\", subDev, \"bind\", devFlags, \"\")\n\t\t\t}\n\t\t}\n\t\tif err != nil {\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error bind mounting /dev from host into mount namespace\")\n\t\t}\n\t}\n\t// Make sure it's read-only.\n\tif err = unix.Statfs(subDev, &fs); err != nil {\n\t\treturn undoBinds, errors.Wrapf(err, \"error checking if directory %q was bound read-only\", subDev)\n\t}\n\tif fs.Flags&unix.ST_RDONLY == 0 {\n\t\tif err := unix.Mount(subDev, subDev, \"bind\", devFlags|unix.MS_REMOUNT, \"\"); err != nil {\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error remounting /dev in mount namespace read-only\")\n\t\t}\n\t}\n\tlogrus.Debugf(\"bind mounted %q to %q\", \"/dev\", filepath.Join(spec.Root.Path, \"/dev\"))\n\n\t// Bind /proc read-only.\n\tsubProc := filepath.Join(spec.Root.Path, \"/proc\")\n\tif err := unix.Mount(\"/proc\", subProc, \"bind\", procFlags, \"\"); err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\terr = os.Mkdir(subProc, 0755)\n\t\t\tif err == nil {\n\t\t\t\terr = unix.Mount(\"/proc\", subProc, \"bind\", procFlags, \"\")\n\t\t\t}\n\t\t}\n\t\tif err != nil {\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error bind mounting /proc from host into mount namespace\")\n\t\t}\n\t}\n\tlogrus.Debugf(\"bind mounted %q to %q\", \"/proc\", filepath.Join(spec.Root.Path, \"/proc\"))\n\n\t// Bind /sys read-only.\n\tsubSys := filepath.Join(spec.Root.Path, \"/sys\")\n\tif err := unix.Mount(\"/sys\", subSys, \"bind\", sysFlags, \"\"); err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\terr = os.Mkdir(subSys, 0755)\n\t\t\tif err == nil {\n\t\t\t\terr = unix.Mount(\"/sys\", subSys, \"bind\", sysFlags, \"\")\n\t\t\t}\n\t\t}\n\t\tif err != nil {\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error bind mounting /sys from host into mount namespace\")\n\t\t}\n\t}\n\tif err := makeReadOnly(subSys, sysFlags); err != nil {\n\t\treturn undoBinds, err\n\t}\n\n\tmnts, _ := mount.GetMounts()\n\tfor _, m := range mnts {\n\t\tif !strings.HasPrefix(m.Mountpoint, \"/sys/\") &&\n\t\t\tm.Mountpoint != \"/sys\" {\n\t\t\tcontinue\n\t\t}\n\t\tsubSys := filepath.Join(spec.Root.Path, m.Mountpoint)\n\t\tif err := unix.Mount(m.Mountpoint, subSys, \"bind\", sysFlags, \"\"); err != nil {\n\t\t\tmsg := fmt.Sprintf(\"could not bind mount %q, skipping: %v\", m.Mountpoint, err)\n\t\t\tif strings.HasPrefix(m.Mountpoint, \"/sys\") {\n\t\t\t\tlogrus.Infof(msg)\n\t\t\t} else {\n\t\t\t\tlogrus.Warningf(msg)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\tif err := makeReadOnly(subSys, sysFlags); err != nil {\n\t\t\treturn undoBinds, err\n\t\t}\n\t}\n\tlogrus.Debugf(\"bind mounted %q to %q\", \"/sys\", filepath.Join(spec.Root.Path, \"/sys\"))\n\n\t// Bind mount in everything we've been asked to mount.\n\tfor _, m := range spec.Mounts {\n\t\t// Skip anything that we just mounted.\n\t\tswitch m.Destination {\n\t\tcase \"/dev\", \"/proc\", \"/sys\":\n\t\t\tlogrus.Debugf(\"already bind mounted %q on %q\", m.Destination, filepath.Join(spec.Root.Path, m.Destination))\n\t\t\tcontinue\n\t\tdefault:\n\t\t\tif strings.HasPrefix(m.Destination, \"/dev/\") {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif strings.HasPrefix(m.Destination, \"/proc/\") {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif strings.HasPrefix(m.Destination, \"/sys/\") {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\t// Skip anything that isn't a bind or tmpfs mount.\n\t\tif m.Type != \"bind\" && m.Type != \"tmpfs\" && m.Type != \"overlay\" {\n\t\t\tlogrus.Debugf(\"skipping mount of type %q on %q\", m.Type, m.Destination)\n\t\t\tcontinue\n\t\t}\n\t\t// If the target is there, we can just mount it.\n\t\tvar srcinfo os.FileInfo\n\t\tswitch m.Type {\n\t\tcase \"bind\":\n\t\t\tsrcinfo, err = os.Stat(m.Source)\n\t\t\tif err != nil {\n\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error examining %q for mounting in mount namespace\", m.Source)\n\t\t\t}\n\t\tcase \"overlay\":\n\t\t\tfallthrough\n\t\tcase \"tmpfs\":\n\t\t\tsrcinfo, err = os.Stat(\"/\")\n\t\t\tif err != nil {\n\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error examining / to use as a template for a %s\", m.Type)\n\t\t\t}\n\t\t}\n\t\ttarget := filepath.Join(spec.Root.Path, m.Destination)\n\t\t// Check if target is a symlink\n\t\tstat, err := os.Lstat(target)\n\t\t// If target is a symlink, follow the link and ensure the destination exists\n\t\tif err == nil && stat != nil && (stat.Mode()&os.ModeSymlink != 0) {\n\t\t\ttarget, err = copier.Eval(spec.Root.Path, m.Destination, copier.EvalOptions{})\n\t\t\tif err != nil {\n\t\t\t\treturn nil, errors.Wrapf(err, \"evaluating symlink %q\", target)\n\t\t\t}\n\t\t\t// Stat the destination of the evaluated symlink\n\t\t\t_, err = os.Stat(target)\n\t\t}\n\t\tif err != nil {\n\t\t\t// If the target can't be stat()ted, check the error.\n\t\t\tif !os.IsNotExist(err) {\n\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error examining %q for mounting in mount namespace\", target)\n\t\t\t}\n\t\t\t// The target isn't there yet, so create it.\n\t\t\tif srcinfo.IsDir() {\n\t\t\t\tif err = os.MkdirAll(target, 0755); err != nil {\n\t\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error creating mountpoint %q in mount namespace\", target)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif err = os.MkdirAll(filepath.Dir(target), 0755); err != nil {\n\t\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error ensuring parent of mountpoint %q (%q) is present in mount namespace\", target, filepath.Dir(target))\n\t\t\t\t}\n\t\t\t\tvar file *os.File\n\t\t\t\tif file, err = os.OpenFile(target, os.O_WRONLY|os.O_CREATE, 0755); err != nil {\n\t\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error creating mountpoint %q in mount namespace\", target)\n\t\t\t\t}\n\t\t\t\tfile.Close()\n\t\t\t}\n\t\t}\n\t\trequestFlags := bindFlags\n\t\texpectedFlags := uintptr(0)\n\t\tif util.StringInSlice(\"nodev\", m.Options) {\n\t\t\trequestFlags |= unix.MS_NODEV\n\t\t\texpectedFlags |= unix.ST_NODEV\n\t\t}\n\t\tif util.StringInSlice(\"noexec\", m.Options) {\n\t\t\trequestFlags |= unix.MS_NOEXEC\n\t\t\texpectedFlags |= unix.ST_NOEXEC\n\t\t}\n\t\tif util.StringInSlice(\"nosuid\", m.Options) {\n\t\t\trequestFlags |= unix.MS_NOSUID\n\t\t\texpectedFlags |= unix.ST_NOSUID\n\t\t}\n\t\tif util.StringInSlice(\"ro\", m.Options) {\n\t\t\trequestFlags |= unix.MS_RDONLY\n\t\t\texpectedFlags |= unix.ST_RDONLY\n\t\t}\n\t\tswitch m.Type {\n\t\tcase \"bind\":\n\t\t\t// Do the bind mount.\n\t\t\tlogrus.Debugf(\"bind mounting %q on %q\", m.Destination, filepath.Join(spec.Root.Path, m.Destination))\n\t\t\tif err := unix.Mount(m.Source, target, \"\", requestFlags, \"\"); err != nil {\n\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error bind mounting %q from host to %q in mount namespace (%q)\", m.Source, m.Destination, target)\n\t\t\t}\n\t\t\tlogrus.Debugf(\"bind mounted %q to %q\", m.Source, target)\n\t\tcase \"tmpfs\":\n\t\t\t// Mount a tmpfs.\n\t\t\tif err := mount.Mount(m.Source, target, m.Type, strings.Join(append(m.Options, \"private\"), \",\")); err != nil {\n\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error mounting tmpfs to %q in mount namespace (%q, %q)\", m.Destination, target, strings.Join(m.Options, \",\"))\n\t\t\t}\n\t\t\tlogrus.Debugf(\"mounted a tmpfs to %q\", target)\n\t\tcase \"overlay\":\n\t\t\t// Mount a overlay.\n\t\t\tif err := mount.Mount(m.Source, target, m.Type, strings.Join(append(m.Options, \"private\"), \",\")); err != nil {\n\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error mounting overlay to %q in mount namespace (%q, %q)\", m.Destination, target, strings.Join(m.Options, \",\"))\n\t\t\t}\n\t\t\tlogrus.Debugf(\"mounted a overlay to %q\", target)\n\t\t}\n\t\tif err = unix.Statfs(target, &fs); err != nil {\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error checking if directory %q was bound read-only\", target)\n\t\t}\n\t\tif uintptr(fs.Flags)&expectedFlags != expectedFlags {\n\t\t\tif err := unix.Mount(target, target, \"bind\", requestFlags|unix.MS_REMOUNT, \"\"); err != nil {\n\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error remounting %q in mount namespace with expected flags\", target)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Set up any read-only paths that we need to.  If we're running inside\n\t// of a container, some of these locations will already be read-only.\n\tfor _, roPath := range spec.Linux.ReadonlyPaths {\n\t\tr := filepath.Join(spec.Root.Path, roPath)\n\t\ttarget, err := filepath.EvalSymlinks(r)\n\t\tif err != nil {\n\t\t\tif os.IsNotExist(err) {\n\t\t\t\t// No target, no problem.\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error checking %q for symlinks before marking it read-only\", r)\n\t\t}\n\t\t// Check if the location is already read-only.\n\t\tvar fs unix.Statfs_t\n\t\tif err = unix.Statfs(target, &fs); err != nil {\n\t\t\tif os.IsNotExist(err) {\n\t\t\t\t// No target, no problem.\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error checking if directory %q is already read-only\", target)\n\t\t}\n\t\tif fs.Flags&unix.ST_RDONLY != 0 {\n\t\t\tcontinue\n\t\t}\n\t\t// Mount the location over itself, so that we can remount it as read-only.\n\t\troFlags := uintptr(unix.MS_NODEV | unix.MS_NOEXEC | unix.MS_NOSUID | unix.MS_RDONLY)\n\t\tif err := unix.Mount(target, target, \"\", roFlags|unix.MS_BIND|unix.MS_REC, \"\"); err != nil {\n\t\t\tif os.IsNotExist(err) {\n\t\t\t\t// No target, no problem.\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error bind mounting %q onto itself in preparation for making it read-only\", target)\n\t\t}\n\t\t// Remount the location read-only.\n\t\tif err = unix.Statfs(target, &fs); err != nil {\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error checking if directory %q was bound read-only\", target)\n\t\t}\n\t\tif fs.Flags&unix.ST_RDONLY == 0 {\n\t\t\tif err := unix.Mount(target, target, \"\", roFlags|unix.MS_BIND|unix.MS_REMOUNT, \"\"); err != nil {\n\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error remounting %q in mount namespace read-only\", target)\n\t\t\t}\n\t\t}\n\t\t// Check again.\n\t\tif err = unix.Statfs(target, &fs); err != nil {\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error checking if directory %q was remounted read-only\", target)\n\t\t}\n\t\tif fs.Flags&unix.ST_RDONLY == 0 {\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error verifying that %q in mount namespace was remounted read-only\", target)\n\t\t}\n\t}\n\n\t// Create an empty directory for to use for masking directories.\n\troEmptyDir := filepath.Join(bundlePath, \"empty\")\n\tif len(spec.Linux.MaskedPaths) > 0 {\n\t\tif err := os.Mkdir(roEmptyDir, 0700); err != nil {\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error creating empty directory %q\", roEmptyDir)\n\t\t}\n\t}\n\n\t// Set up any masked paths that we need to.  If we're running inside of\n\t// a container, some of these locations will already be read-only tmpfs\n\t// filesystems or bind mounted to os.DevNull.  If we're not running\n\t// inside of a container, and nobody else has done that, we'll do it.\n\tfor _, masked := range spec.Linux.MaskedPaths {\n\t\tt := filepath.Join(spec.Root.Path, masked)\n\t\ttarget, err := filepath.EvalSymlinks(t)\n\t\tif err != nil {\n\t\t\ttarget = t\n\t\t}\n\t\t// Get some info about the target.\n\t\ttargetinfo, err := os.Stat(target)\n\t\tif err != nil {\n\t\t\tif os.IsNotExist(err) {\n\t\t\t\t// No target, no problem.\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn undoBinds, errors.Wrapf(err, \"error examining %q for masking in mount namespace\", target)\n\t\t}\n\t\tif targetinfo.IsDir() {\n\t\t\t// The target's a directory.  Check if it's a read-only filesystem.\n\t\t\tvar statfs unix.Statfs_t\n\t\t\tif err = unix.Statfs(target, &statfs); err != nil {\n\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error checking if directory %q is a mountpoint\", target)\n\t\t\t}\n\t\t\tisReadOnly := statfs.Flags&unix.MS_RDONLY != 0\n\t\t\t// Check if any of the IDs we're mapping could read it.\n\t\t\tvar stat unix.Stat_t\n\t\t\tif err = unix.Stat(target, &stat); err != nil {\n\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error checking permissions on directory %q\", target)\n\t\t\t}\n\t\t\tisAccessible := false\n\t\t\tif stat.Mode&unix.S_IROTH|unix.S_IXOTH != 0 {\n\t\t\t\tisAccessible = true\n\t\t\t}\n\t\t\tif !isAccessible && stat.Mode&unix.S_IROTH|unix.S_IXOTH != 0 {\n\t\t\t\tif len(spec.Linux.GIDMappings) > 0 {\n\t\t\t\t\tfor _, mapping := range spec.Linux.GIDMappings {\n\t\t\t\t\t\tif stat.Gid >= mapping.ContainerID && stat.Gid < mapping.ContainerID+mapping.Size {\n\t\t\t\t\t\t\tisAccessible = true\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !isAccessible && stat.Mode&unix.S_IRUSR|unix.S_IXUSR != 0 {\n\t\t\t\tif len(spec.Linux.UIDMappings) > 0 {\n\t\t\t\t\tfor _, mapping := range spec.Linux.UIDMappings {\n\t\t\t\t\t\tif stat.Uid >= mapping.ContainerID && stat.Uid < mapping.ContainerID+mapping.Size {\n\t\t\t\t\t\t\tisAccessible = true\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Check if it's empty.\n\t\t\thasContent := false\n\t\t\tdirectory, err := os.Open(target)\n\t\t\tif err != nil {\n\t\t\t\tif !os.IsPermission(err) {\n\t\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error opening directory %q\", target)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tnames, err := directory.Readdirnames(0)\n\t\t\t\tdirectory.Close()\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error reading contents of directory %q\", target)\n\t\t\t\t}\n\t\t\t\thasContent = false\n\t\t\t\tfor _, name := range names {\n\t\t\t\t\tswitch name {\n\t\t\t\t\tcase \".\", \"..\":\n\t\t\t\t\t\tcontinue\n\t\t\t\t\tdefault:\n\t\t\t\t\t\thasContent = true\n\t\t\t\t\t}\n\t\t\t\t\tif hasContent {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t// The target's a directory, so read-only bind mount an empty directory on it.\n\t\t\troFlags := uintptr(syscall.MS_BIND | syscall.MS_NOSUID | syscall.MS_NODEV | syscall.MS_NOEXEC | syscall.MS_RDONLY)\n\t\t\tif !isReadOnly || (hasContent && isAccessible) {\n\t\t\t\tif err = unix.Mount(roEmptyDir, target, \"bind\", roFlags, \"\"); err != nil {\n\t\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error masking directory %q in mount namespace\", target)\n\t\t\t\t}\n\t\t\t\tif err = unix.Statfs(target, &fs); err != nil {\n\t\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error checking if directory %q was mounted read-only in mount namespace\", target)\n\t\t\t\t}\n\t\t\t\tif fs.Flags&unix.ST_RDONLY == 0 {\n\t\t\t\t\tif err = unix.Mount(target, target, \"\", roFlags|syscall.MS_REMOUNT, \"\"); err != nil {\n\t\t\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error making sure directory %q in mount namespace is read only\", target)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\t// If the target's is not a directory or os.DevNull, bind mount os.DevNull over it.\n\t\t\tif !isDevNull(targetinfo) {\n\t\t\t\tif err = unix.Mount(os.DevNull, target, \"\", uintptr(syscall.MS_BIND|syscall.MS_RDONLY|syscall.MS_PRIVATE), \"\"); err != nil {\n\t\t\t\t\treturn undoBinds, errors.Wrapf(err, \"error masking non-directory %q in mount namespace\", target)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn undoBinds, nil\n}\n", "# buildah-bud \"1\" \"April 2017\" \"buildah\"\n\n## NAME\nbuildah\\-bud - Build an image using instructions from Containerfiles\n\n## SYNOPSIS\n\n**buildah build-using-dockerfile** [*options*] [*context*]\n\n**buildah bud** [*options*] [*context*]\n\n**bud** is an alias for **build-using-dockerfile**.\n\n## DESCRIPTION\nBuilds an image using instructions from one or more Containerfiles or Dockerfiles and a specified\nbuild context directory.  A Containerfile uses the same syntax as a Dockerfile internally.  For this\ndocument, a file referred to as a Containerfile can be a file named either 'Containerfile' or 'Dockerfile'.\n\nThe build context directory can be specified as the http(s) URL of an archive, git repository or Containerfile.\n\nIf no context directory is specified, then Buildah will assume the current working directory as build context, which should contain a Containerfile.\n\nContainerfiles ending with a \".in\" suffix will be preprocessed via cpp(1).  This can be useful to decompose Containerfiles into several reusable parts that can be used via CPP's **#include** directive.  Notice, a Containerfile.in file can still be used by other tools when manually preprocessing them via `cpp -E`. Any comments ( Lines beginning with `#` ) in included Containerfile(s) that are not preprocess commands, will be printed as warnings during builds.\n\nWhen the URL is an archive, the contents of the URL is downloaded to a temporary location and extracted before execution.\n\nWhen the URL is a Containerfile, the file is downloaded to a temporary location.\n\nWhen a Git repository is set as the URL, the repository is cloned locally and then set as the context.\n\n## OPTIONS\n\n**--add-host**=[]\n\nAdd a custom host-to-IP mapping (host:ip)\n\nAdd a line to /etc/hosts. The format is hostname:ip. The **--add-host** option can be set multiple times.\n\n**--annotation** *annotation*\n\nAdd an image *annotation* (e.g. annotation=*value*) to the image metadata. Can be used multiple times.\n\nNote: this information is not present in Docker image formats, so it is discarded when writing images in Docker formats.\n\n**--arch**=\"ARCH\"\n\nSet the ARCH of the image to be pulled to the provided value instead of using the architecture of the host. (Examples: aarch64, arm, i686, ppc64le, s390x, x86_64)\n\n**--authfile** *path*\n\nPath of the authentication file. Default is ${XDG_\\RUNTIME\\_DIR}/containers/auth.json. If XDG_RUNTIME_DIR is not set, the default is /run/containers/$UID/auth.json. This file is created using using `buildah login`.\n\nIf the authorization state is not found there, $HOME/.docker/config.json is checked, which is set using `docker login`.\n\nNote: You can also override the default path of the authentication file by setting the REGISTRY\\_AUTH\\_FILE\nenvironment variable. `export REGISTRY_AUTH_FILE=path`\n\n**--build-arg** *arg=value*\n\nSpecifies a build argument and its value, which will be interpolated in\ninstructions read from the Containerfiles in the same way that environment\nvariables are, but which will not be added to environment variable list in the\nresulting image's configuration.\n\nPlease refer to the [BUILD TIME VARIABLES](#build-time-variables) section for the\nlist of variables that can be overridden within the Containerfile at run time.\n\n**--cache-from**\n\nImages to utilise as potential cache sources. Buildah does not currently support --cache-from so this is a NOOP.\n\n**--cap-add**=*CAP\\_xxx*\n\nWhen executing RUN instructions, run the command specified in the instruction\nwith the specified capability added to its capability set.\nCertain capabilities are granted by default; this option can be used to add\nmore.\n\n**--cap-drop**=*CAP\\_xxx*\n\nWhen executing RUN instructions, run the command specified in the instruction\nwith the specified capability removed from its capability set.\nThe CAP\\_AUDIT\\_WRITE, CAP\\_CHOWN, CAP\\_DAC\\_OVERRIDE, CAP\\_FOWNER,\nCAP\\_FSETID, CAP\\_KILL, CAP\\_MKNOD, CAP\\_NET\\_BIND\\_SERVICE, CAP\\_SETFCAP,\nCAP\\_SETGID, CAP\\_SETPCAP, CAP\\_SETUID, and CAP\\_SYS\\_CHROOT capabilities are\ngranted by default; this option can be used to remove them.\n\nIf a capability is specified to both the **--cap-add** and **--cap-drop**\noptions, it will be dropped, regardless of the order in which the options were\ngiven.\n\n**--cert-dir** *path*\n\nUse certificates at *path* (\\*.crt, \\*.cert, \\*.key) to connect to the registry.\nThe default certificates directory is _/etc/containers/certs.d_.\n\n**--cgroup-parent**=\"\"\n\nPath to cgroups under which the cgroup for the container will be created. If the path is not absolute, the path is considered to be relative to the cgroups path of the init process. Cgroups will be created if they do not already exist.\n\n**--compress**\n\nThis option is added to be aligned with other containers CLIs.\nBuildah doesn't send a copy of the context directory to a daemon or a remote server.\nThus, compressing the data before sending it is irrelevant to Buildah.\n\n**--cni-config-dir**=*directory*\n\nLocation of CNI configuration files which will dictate which plugins will be\nused to configure network interfaces and routing for containers created for\nhandling `RUN` instructions, if those containers will be run in their own\nnetwork namespaces, and networking is not disabled.\n\n**--cni-plugin-path**=*directory[:directory[:directory[...]]]*\n\nList of directories in which the CNI plugins which will be used for configuring\nnetwork namespaces can be found.\n\n**--cpu-period**=*0*\n\nSet the CPU period for the Completely Fair Scheduler (CFS), which is a\nduration in microseconds. Once the container's CPU quota is used up, it will\nnot be scheduled to run until the current period ends. Defaults to 100000\nmicroseconds.\n\nOn some systems, changing the CPU limits may not be allowed for non-root\nusers. For more details, see\nhttps://github.com/containers/podman/blob/main/troubleshooting.md#26-running-containers-with-cpu-limits-fails-with-a-permissions-error\n\n**--cpu-quota**=*0*\n\nLimit the CPU CFS (Completely Fair Scheduler) quota\n\nLimit the container's CPU usage. By default, containers run with the full\nCPU resource. This flag tell the kernel to restrict the container's CPU usage\nto the quota you specify.\n\nOn some systems, changing the CPU limits may not be allowed for non-root\nusers. For more details, see\nhttps://github.com/containers/podman/blob/main/troubleshooting.md#26-running-containers-with-cpu-limits-fails-with-a-permissions-error\n\n**--cpu-shares**, **-c**=*0*\n\nCPU shares (relative weight)\n\nBy default, all containers get the same proportion of CPU cycles. This proportion\ncan be modified by changing the container's CPU share weighting relative\nto the weighting of all other running containers.\n\nTo modify the proportion from the default of 1024, use the **--cpu-shares**\nflag to set the weighting to 2 or higher.\n\nThe proportion will only apply when CPU-intensive processes are running.\nWhen tasks in one container are idle, other containers can use the\nleft-over CPU time. The actual amount of CPU time will vary depending on\nthe number of containers running on the system.\n\nFor example, consider three containers, one has a cpu-share of 1024 and\ntwo others have a cpu-share setting of 512. When processes in all three\ncontainers attempt to use 100% of CPU, the first container would receive\n50% of the total CPU time. If you add a fourth container with a cpu-share\nof 1024, the first container only gets 33% of the CPU. The remaining containers\nreceive 16.5%, 16.5% and 33% of the CPU.\n\nOn a multi-core system, the shares of CPU time are distributed over all CPU\ncores. Even if a container is limited to less than 100% of CPU time, it can\nuse 100% of each individual CPU core.\n\nFor example, consider a system with more than three cores. If you start one\ncontainer **{C0}** with **-c=512** running one process, and another container\n**{C1}** with **-c=1024** running two processes, this can result in the following\ndivision of CPU shares:\n\n    PID    container\tCPU\tCPU share\n    100    {C0}\t\t0\t100% of CPU0\n    101    {C1}\t\t1\t100% of CPU1\n    102    {C1}\t\t2\t100% of CPU2\n\n**--cpuset-cpus**=\"\"\n\n  CPUs in which to allow execution (0-3, 0,1)\n\n**--cpuset-mems**=\"\"\n\nMemory nodes (MEMs) in which to allow execution (0-3, 0,1). Only effective on NUMA systems.\n\nIf you have four memory nodes on your system (0-3), use `--cpuset-mems=0,1`\nthen processes in your container will only use memory from the first\ntwo memory nodes.\n\n**--creds** *creds*\n\nThe [username[:password]] to use to authenticate with the registry if required.\nIf one or both values are not supplied, a command line prompt will appear and the\nvalue can be entered.  The password is entered without echo.\n\n**--decryption-key** *key[:passphrase]*\n\nThe [key[:passphrase]] to be used for decryption of images. Key can point to keys and/or certificates. Decryption will be tried with all keys. If the key is protected by a passphrase, it is required to be passed in the argument and omitted otherwise.\n\n**--device**=*device*\n\nAdd a host device to the container. Optional *permissions* parameter\ncan be used to specify device permissions, it is combination of\n**r** for read, **w** for write, and **m** for **mknod**(2).\n\nExample: **--device=/dev/sdc:/dev/xvdc:rwm**.\n\nNote: if _host_device_ is a symbolic link then it will be resolved first.\nThe container will only store the major and minor numbers of the host device.\n\nNote: if the user only has access rights via a group, accessing the device\nfrom inside a rootless container will fail. The **crun**(1) runtime offers a\nworkaround for this by adding the option **--annotation run.oci.keep_original_groups=1**.\n\n**--disable-compression**, **-D**\nDon't compress filesystem layers when building the image unless it is required\nby the location where the image is being written.  This is the default setting,\nbecause image layers are compressed automatically when they are pushed to\nregistries, and images being written to local storage would only need to be\ndecompressed again to be stored.  Compression can be forced in all cases by\nspecifying **--disable-compression=false**.\n\n**--disable-content-trust**\n\nThis is a Docker specific option to disable image verification to a Docker\nregistry and is not supported by Buildah.  This flag is a NOOP and provided\nsolely for scripting compatibility.\n\n**--dns**=[]\n\nSet custom DNS servers\n\nThis option can be used to override the DNS configuration passed to the container. Typically this is necessary when the host DNS configuration is invalid for the container (e.g., 127.0.0.1). When this is the case the `--dns` flag is necessary for every run.\n\nThe special value **none** can be specified to disable creation of /etc/resolv.conf in the container by Buildah. The /etc/resolv.conf file in the image will be used without changes.\n\n**--dns-option**=[]\n\nSet custom DNS options\n\n**--dns-search**=[]\n\nSet custom DNS search domains\n\n**--file**, **-f** *Containerfile*\n\nSpecifies a Containerfile which contains instructions for building the image,\neither a local file or an **http** or **https** URL.  If more than one\nContainerfile is specified, *FROM* instructions will only be accepted from the\nfirst specified file.\n\nIf a local file is specified as the Containerfile and it does not exist, the\ncontext directory will be prepended to the local file value.\n\nIf you specify `-f -`, the Containerfile contents will be read from stdin.\n\n**--force-rm** *bool-value*\n\nAlways remove intermediate containers after a build, even if the build fails (default false).\n\n**--format**\n\nControl the format for the built image's manifest and configuration data.\nRecognized formats include *oci* (OCI image-spec v1.0, the default) and\n*docker* (version 2, using schema format 2 for the manifest).\n\nNote: You can also override the default format by setting the BUILDAH\\_FORMAT\nenvironment variable.  `export BUILDAH_FORMAT=docker`\n\n**--from**\n\nOverrides the first `FROM` instruction within the Containerfile.  If there are multiple\nFROM instructions in a Containerfile, only the first is changed.\n\n**-h**, **--help**\n\nPrint usage statement\n\n**--http-proxy**=true\n\nBy default proxy environment variables are passed into the container if set\nfor the buildah process.  This can be disabled by setting the `--http-proxy`\noption to `false`.  The environment variables passed in include `http_proxy`,\n`https_proxy`, `ftp_proxy`, `no_proxy`, and also the upper case versions of\nthose.\n\n**--iidfile** *ImageIDfile*\n\nWrite the image ID to the file.\n\n**--ignorefile** *file*\n\nPath to an alternative .containerignore (.dockerignore) file.\n\n**--ipc** *how*\n\nSets the configuration for IPC namespaces when handling `RUN` instructions.\nThe configured value can be \"\" (the empty string) or \"container\" to indicate\nthat a new IPC namespace should be created, or it can be \"host\" to indicate\nthat the IPC namespace in which `buildah` itself is being run should be reused,\nor it can be the path to an IPC namespace which is already in use by\nanother process.\n\n**--isolation** *type*\n\nControls what type of isolation is used for running processes as part of `RUN`\ninstructions.  Recognized types include *oci* (OCI-compatible runtime, the\ndefault), *rootless* (OCI-compatible runtime invoked using a modified\nconfiguration, with *--no-new-keyring* added to its *create* invocation,\nreusing the host's network and UTS namespaces, and creating private IPC, PID,\nmount, and user namespaces; the default for unprivileged users), and *chroot*\n(an internal wrapper that leans more toward chroot(1) than container\ntechnology, reusing the host's control group, network, IPC, and PID namespaces,\nand creating private mount and UTS namespaces, and creating user namespaces\nonly when they're required for ID mapping).\n\nNote: You can also override the default isolation type by setting the\nBUILDAH\\_ISOLATION environment variable.  `export BUILDAH_ISOLATION=oci`\n\n**--jobs** *N*\n\nRun up to N concurrent stages in parallel.  If the number of jobs is greater than 1,\nstdin will be read from /dev/null.  If 0 is specified, then there is\nno limit in the number of jobs that run in parallel.\n\n**--label** *label*\n\nAdd an image *label* (e.g. label=*value*) to the image metadata. Can be used multiple times.\n\nUsers can set a special LABEL **io.containers.capabilities=CAP1,CAP2,CAP3** in\na Containerfile that specified the list of Linux capabilities required for the\ncontainer to run properly. This label specified in a container image tells\ncontainer engines, like Podman, to run the container with just these\ncapabilities. The container engine launches the container with just the specified\ncapabilities, as long as this list of capabilities is a subset of the default\nlist.\n\nIf the specified capabilities are not in the default set, container engines\nshould print an error message and will run the container with the default\ncapabilities.\n\n**--layers** *bool-value*\n\nCache intermediate images during the build process (Default is `false`).\n\nNote: You can also override the default value of layers by setting the BUILDAH\\_LAYERS\nenvironment variable. `export BUILDAH_LAYERS=true`\n\n**--logfile** *filename*\n\nLog output which would be sent to standard output and standard error to the\nspecified file instead of to standard output and standard error.\n\n**--manifest** \"manifest\"\n\nName of the manifest list to which the image will be added. Creates the manifest list\nif it does not exist. This option is useful for building multi architecture images.\n\n**--memory**, **-m**=\"\"\n\nMemory limit (format: <number>[<unit>], where unit = b, k, m or g)\n\nAllows you to constrain the memory available to a container. If the host\nsupports swap memory, then the **-m** memory setting can be larger than physical\nRAM. If a limit of 0 is specified (not using **-m**), the container's memory is\nnot limited. The actual limit may be rounded up to a multiple of the operating\nsystem's page size (the value would be very large, that's millions of trillions).\n\n**--memory-swap**=\"LIMIT\"\n\nA limit value equal to memory plus swap. Must be used with the  **-m**\n(**--memory**) flag. The swap `LIMIT` should always be larger than **-m**\n(**--memory**) value.  By default, the swap `LIMIT` will be set to double\nthe value of --memory.\n\nThe format of `LIMIT` is `<number>[<unit>]`. Unit can be `b` (bytes),\n`k` (kilobytes), `m` (megabytes), or `g` (gigabytes). If you don't specify a\nunit, `b` is used. Set LIMIT to `-1` to enable unlimited swap.\n\n**--network**, **--net**=*mode*\n\nSets the configuration for network namespaces when handling `RUN` instructions.\n\nValid _mode_ values are:\n\n- **none**: no networking;\n- **host**: use the host network stack. Note: the host mode gives the container full access to local system services such as D-bus and is therefore considered insecure;\n- **ns:**_path_: path to a network namespace to join;\n- `private`: create a new namespace for the container (default)\n\n**--no-cache**\n\nDo not use existing cached images for the container build. Build from the start with a new set of cached layers.\n\n**--os**=\"OS\"\n\nSet the OS of the image to be pulled instead of using the current operating system of the host.\n\n**--pid** *how*\n\nSets the configuration for PID namespaces when handling `RUN` instructions.\nThe configured value can be \"\" (the empty string) or \"private\" to indicate\nthat a new PID namespace should be created, or it can be \"host\" to indicate\nthat the PID namespace in which `buildah` itself is being run should be reused,\nor it can be the path to a PID namespace which is already in use by another\nprocess.\n\n**--platform**=\"OS/ARCH\"\n\nSet the OS/ARCH of the image to the provided value instead of using the current\noperating system and architecture of the host (for example `linux/arm`). If\n`--platform` is set, then the values of the `--arch` and `--os` options will be\noverridden.\n\n**--pull**\n\nWhen the flag is enabled, attempt to pull the latest image from the registries\nlisted in registries.conf if a local image does not exist or the image is newer\nthan the one in storage. Raise an error if the image is not in any listed\nregistry and is not present locally.\n\nIf the flag is disabled (with *--pull=false*), do not pull the image from the\nregistry, unless there is no local image. Raise an error if the image is not\nin any registry and is not present locally.\n\nDefaults to *true*.\n\n**--pull-always**\n\nPull the image from the first registry it is found in as listed in registries.conf.\nRaise an error if not found in the registries, even if the image is present locally.\n\n**--pull-never**\n\nDo not pull the image from the registry, use only the local version. Raise an error\nif the image is not present locally.\n\n**--quiet**, **-q**\n\nSuppress output messages which indicate which instruction is being processed,\nand of progress when pulling images from a registry, and when writing the\noutput image.\n\n**--rm** *bool-value*\n\nRemove intermediate containers after a successful build (default true).\n\n**--runtime** *path*\n\nThe *path* to an alternate OCI-compatible runtime, which will be used to run\ncommands specified by the **RUN** instruction. Default is `runc`, or `crun` when machine is configured to use cgroups V2.\n\nNote: You can also override the default runtime by setting the BUILDAH\\_RUNTIME\nenvironment variable.  `export BUILDAH_RUNTIME=/usr/bin/crun`\n\n**--runtime-flag** *flag*\n\nAdds global flags for the container rutime. To list the supported flags, please\nconsult the manpages of the selected container runtime.\n\nNote: Do not pass the leading `--` to the flag. To pass the runc flag `--log-format json`\nto buildah bud, the option given would be `--runtime-flag log-format=json`.\n\n**--secret**=**id=id,src=path**\nPass secret information to be used in the Containerfile for building images\nin a safe way that will not end up stored in the final image, or be seen in other stages.\nThe secret will be mounted in the container at the default location of `/run/secrets/id`.\n\nTo later use the secret, use the --mount flag in a `RUN` instruction within a `Containerfile`:\n\n`RUN --mount=type=secret,id=mysecret cat /run/secrets/mysecret`\n\n**--security-opt**=[]\n\nSecurity Options\n\n  \"apparmor=unconfined\" : Turn off apparmor confinement for the container\n  \"apparmor=your-profile\" : Set the apparmor confinement profile for the container\n\n  \"label=user:USER\"   : Set the label user for the container\n  \"label=role:ROLE\"   : Set the label role for the container\n  \"label=type:TYPE\"   : Set the label type for the container\n  \"label=level:LEVEL\" : Set the label level for the container\n  \"label=disable\"     : Turn off label confinement for the container\n  \"no-new-privileges\" : Not supported\n\n  \"seccomp=unconfined\" : Turn off seccomp confinement for the container\n  \"seccomp=profile.json :  White listed syscalls seccomp Json file to be used as a seccomp filter\n\n**--shm-size**=\"\"\n\nSize of `/dev/shm`. The format is `<number><unit>`. `number` must be greater than `0`.\nUnit is optional and can be `b` (bytes), `k` (kilobytes), `m`(megabytes), or `g` (gigabytes).\nIf you omit the unit, the system uses bytes. If you omit the size entirely, the system uses `64m`.\n\n**--sign-by** *fingerprint*\n\nSign the built image using the GPG key that matches the specified fingerprint.\n\n**--squash**\n\nSquash all of the image's new layers into a single new layer; any preexisting layers\nare not squashed.\n\n**--stdin**\n\nPass stdin into the RUN containers. Sometime commands being RUN within a Containerfile\nwant to request information from the user. For example apt asking for a confirmation for install.\nUse --stdin to be able to interact from the terminal during the build.\n\n**--tag**, **-t** *imageName*\n\nSpecifies the name which will be assigned to the resulting image if the build\nprocess completes successfully.\nIf _imageName_ does not include a registry name, the registry name *localhost* will be prepended to the image name.\n\n**--target** *stageName*\n\nSet the target build stage to build.  When building a Containerfile with multiple build stages, --target\ncan be used to specify an intermediate build stage by name as the final stage for the resulting image.\nCommands after the target stage will be skipped.\n\n**--timestamp** *seconds*\n\nSet the create timestamp to seconds since epoch to allow for deterministic builds (defaults to current time).\nBy default, the created timestamp is changed and written into the image manifest with every commit,\ncausing the image's sha256 hash to be different even if the sources are exactly the same otherwise.\nWhen --timestamp is set, the created timestamp is always set to the time specified and therefore not changed, allowing the image's sha256 to remain the same. All files committed to the layers of the image will be created with the timestamp.\n\n**--tls-verify** *bool-value*\n\nRequire HTTPS and verification of certificates when talking to container registries (defaults to true).  TLS verification cannot be used when talking to an insecure registry.\n\n**--ulimit** *type*=*soft-limit*[:*hard-limit*]\n\nSpecifies resource limits to apply to processes launched when processing `RUN` instructions.\nThis option can be specified multiple times.  Recognized resource types\ninclude:\n  \"core\": maximum core dump size (ulimit -c)\n  \"cpu\": maximum CPU time (ulimit -t)\n  \"data\": maximum size of a process's data segment (ulimit -d)\n  \"fsize\": maximum size of new files (ulimit -f)\n  \"locks\": maximum number of file locks (ulimit -x)\n  \"memlock\": maximum amount of locked memory (ulimit -l)\n  \"msgqueue\": maximum amount of data in message queues (ulimit -q)\n  \"nice\": niceness adjustment (nice -n, ulimit -e)\n  \"nofile\": maximum number of open files (ulimit -n)\n  \"nofile\": maximum number of open files (1048576); when run by root\n  \"nproc\": maximum number of processes (ulimit -u)\n  \"nproc\": maximum number of processes (1048576); when run by root\n  \"rss\": maximum size of a process's (ulimit -m)\n  \"rtprio\": maximum real-time scheduling priority (ulimit -r)\n  \"rttime\": maximum amount of real-time execution between blocking syscalls\n  \"sigpending\": maximum number of pending signals (ulimit -i)\n  \"stack\": maximum stack size (ulimit -s)\n\n**--userns** *how*\n\nSets the configuration for user namespaces when handling `RUN` instructions.\nThe configured value can be \"\" (the empty string) or \"private\" to indicate\nthat a new user namespace should be created, it can be \"host\" to indicate that\nthe user namespace in which `buildah` itself is being run should be reused, or\nit can be the path to an user namespace which is already in use by another\nprocess.\n\n**--userns-uid-map-user** *user*\n\nSpecifies that a UID mapping which should be used to set ownership, at the\nfilesystem level, on the working container's contents, can be found in entries\nin the `/etc/subuid` file which correspond to the specified user.\nCommands run when handling `RUN` instructions will default to being run in\ntheir own user namespaces, configured using the UID and GID maps.\nIf --userns-gid-map-group is specified, but --userns-uid-map-user is not\nspecified, `buildah` will assume that the specified group name is also a\nsuitable user name to use as the default setting for this option.\n\nUsers can specify the maps directly using `--userns-uid-map` described in the buildah(1) man page.\n\n**NOTE:** When this option is specified by a rootless user, the specified mappings are relative to the rootless usernamespace in the container, rather than being relative to the host as it would be when run rootful.\n\n**--userns-gid-map-group** *group*\n\nSpecifies that a GID mapping which should be used to set ownership, at the\nfilesystem level, on the working container's contents, can be found in entries\nin the `/etc/subgid` file which correspond to the specified group.\nCommands run when handling `RUN` instructions will default to being run in\ntheir own user namespaces, configured using the UID and GID maps.\nIf --userns-uid-map-user is specified, but --userns-gid-map-group is not\nspecified, `buildah` will assume that the specified user name is also a\nsuitable group name to use as the default setting for this option.\n\nUsers can specify the maps directly using `--userns-gid-map` described in the buildah(1) man page.\n\n**NOTE:** When this option is specified by a rootless user, the specified mappings are relative to the rootless usernamespace in the container, rather than being relative to the host as it would be when run rootful.\n\n**--uts** *how*\n\nSets the configuration for UTS namespaces when the handling `RUN` instructions.\nThe configured value can be \"\" (the empty string) or \"container\" to indicate\nthat a new UTS namespace should be created, or it can be \"host\" to indicate\nthat the UTS namespace in which `buildah` itself is being run should be reused,\nor it can be the path to a UTS namespace which is already in use by another\nprocess.\n\n**--variant**=\"\"\n\nSet the architecture variant of the image to be pulled.\n\n**--volume**, **-v**[=*[HOST-DIR:CONTAINER-DIR[:OPTIONS]]*]\n\n   Create a bind mount. If you specify, ` -v /HOST-DIR:/CONTAINER-DIR`, Buildah\n   bind mounts `/HOST-DIR` in the host to `/CONTAINER-DIR` in the Buildah\n   container. The `OPTIONS` are a comma delimited list and can be: <sup>[[1]](#Footnote1)</sup>\n\n   * [rw|ro]\n   * [U]\n   * [z|Z|O]\n   * [`[r]shared`|`[r]slave`|`[r]private`]\n\nThe `CONTAINER-DIR` must be an absolute path such as `/src/docs`. The `HOST-DIR`\nmust be an absolute path as well. Buildah bind-mounts the `HOST-DIR` to the\npath you specify. For example, if you supply `/foo` as the host path,\nBuildah copies the contents of `/foo` to the container filesystem on the host\nand bind mounts that into the container.\n\nYou can specify multiple  **-v** options to mount one or more mounts to a\ncontainer.\n\n  `Write Protected Volume Mounts`\n\nYou can add the `:ro` or `:rw` suffix to a volume to mount it read-only or\nread-write mode, respectively. By default, the volumes are mounted read-write.\nSee examples.\n\n  `Chowning Volume Mounts`\n\nBy default, Buildah does not change the owner and group of source volume directories mounted into containers. If a container is created in a new user namespace, the UID and GID in the container may correspond to another UID and GID on the host.\n\nThe `:U` suffix tells Buildah to use the correct host UID and GID based on the UID and GID within the container, to change the owner and group of the source volume.\n\n  `Labeling Volume Mounts`\n\nLabeling systems like SELinux require that proper labels are placed on volume\ncontent mounted into a container. Without a label, the security system might\nprevent the processes running inside the container from using the content. By\ndefault, Buildah does not change the labels set by the OS.\n\nTo change a label in the container context, you can add either of two suffixes\n`:z` or `:Z` to the volume mount. These suffixes tell Buildah to relabel file\nobjects on the shared volumes. The `z` option tells Buildah that two containers\nshare the volume content. As a result, Buildah labels the content with a shared\ncontent label. Shared volume labels allow all containers to read/write content.\nThe `Z` option tells Buildah to label the content with a private unshared label.\nOnly the current container can use a private volume.\n\n  `Overlay Volume Mounts`\n\n   The `:O` flag tells Buildah to mount the directory from the host as a temporary storage using the Overlay file system. The `RUN` command containers are allowed to modify contents within the mountpoint and are stored in the container storage in a separate directory.  In Overlay FS terms the source directory will be the lower, and the container storage directory will be the upper. Modifications to the mount point are destroyed when the `RUN` command finishes executing, similar to a tmpfs mount point.\n\n  Any subsequent execution of `RUN` commands sees the original source directory content, any changes from previous RUN commands no longer exists.\n\n  One use case of the `overlay` mount is sharing the package cache from the host into the container to allow speeding up builds.\n\n  Note:\n\n     - The `O` flag is not allowed to be specified with the `Z` or `z` flags. Content mounted into the container is labeled with the private label.\n       On SELinux systems, labels in the source directory needs to be readable by the container label. If not, SELinux container separation must be disabled for the container to work.\n     - Modification of the directory volume mounted into the container with an overlay mount can cause unexpected failures.  It is recommended that you do not modify the directory until the container finishes running.\n\nBy default bind mounted volumes are `private`. That means any mounts done\ninside container will not be visible on the host and vice versa. This behavior can\nbe changed by specifying a volume mount propagation property.\n\nWhen the mount propagation policy is set to `shared`, any mounts completed inside\nthe container on that volume will be visible to both the host and container. When\nthe mount propagation policy is set to `slave`, one way mount propagation is enabled\nand any mounts completed on the host for that volume will be visible only inside of the container.\nTo control the mount propagation property of the volume use the `:[r]shared`,\n`:[r]slave` or `:[r]private` propagation flag. The propagation property can\nbe specified only for bind mounted volumes and not for internal volumes or\nnamed volumes. For mount propagation to work on the source mount point (the mount point\nwhere source dir is mounted on) it has to have the right propagation properties. For\nshared volumes, the source mount point has to be shared. And for slave volumes,\nthe source mount has to be either shared or slave. <sup>[[1]](#Footnote1)</sup>\n\nUse `df <source-dir>` to determine the source mount and then use\n`findmnt -o TARGET,PROPAGATION <source-mount-dir>` to determine propagation\nproperties of source mount, if `findmnt` utility is not available, the source mount point\ncan be determined by looking at the mount entry in `/proc/self/mountinfo`. Look\nat `optional fields` and see if any propagation properties are specified.\n`shared:X` means the mount is `shared`, `master:X` means the mount is `slave` and if\nnothing is there that means the mount is `private`. <sup>[[1]](#Footnote1)</sup>\n\nTo change propagation properties of a mount point use the `mount` command. For\nexample, to bind mount the source directory `/foo` do\n`mount --bind /foo /foo` and `mount --make-private --make-shared /foo`. This\nwill convert /foo into a `shared` mount point.  The propagation properties of the source\nmount can be changed directly. For instance if `/` is the source mount for\n`/foo`, then use `mount --make-shared /` to convert `/` into a `shared` mount.\n\n## BUILD TIME VARIABLES\n\nThe ENV instruction in a Containerfile can be used to define variable values.  When the image\nis built, the values will persist in the container image.  At times it is more convenient to\nchange the values in the Containerfile via a command-line option rather than changing the\nvalues within the Containerfile itself.\n\nThe following variables can be used in conjunction with the `--build-arg` option to override the\ncorresponding values set in the Containerfile using the `ENV` instruction.\n\n  * HTTP_PROXY\n  * HTTPS_PROXY\n  * FTP_PROXY\n  * NO_PROXY\n\nPlease refer to the [Using Build Time Variables](#using-build-time-variables) section of the Examples.\n\n## EXAMPLE\n\n### Build an image using local Containerfiles\n\nbuildah bud .\n\nbuildah bud -f Containerfile .\n\ncat ~/Dockerfile | buildah bud -f - .\n\nbuildah bud -f Dockerfile.simple -f Dockerfile.notsosimple .\n\nbuildah bud --timestamp=$(date '+%s') -t imageName .\n\nbuildah bud -t imageName .\n\nbuildah bud --tls-verify=true -t imageName -f Dockerfile.simple .\n\nbuildah bud --tls-verify=false -t imageName .\n\nbuildah bud --runtime-flag log-format=json .\n\nbuildah bud -f Containerfile --runtime-flag debug .\n\nbuildah bud --authfile /tmp/auths/myauths.json --cert-dir ~/auth --tls-verify=true --creds=username:password -t imageName -f Dockerfile.simple .\n\nbuildah bud --memory 40m --cpu-period 10000 --cpu-quota 50000 --ulimit nofile=1024:1028 -t imageName .\n\nbuildah bud --security-opt label=level:s0:c100,c200 --cgroup-parent /path/to/cgroup/parent -t imageName .\n\nbuildah bud --arch=arm --variant v7 -t imageName .\n\nbuildah bud --volume /home/test:/myvol:ro,Z -t imageName .\n\nbuildah bud -v /home/test:/myvol:z,U -t imageName .\n\nbuildah bud -v /var/lib/dnf:/var/lib/dnf:O -t imageName .\n\nbuildah bud --layers -t imageName .\n\nbuildah bud --no-cache -t imageName .\n\nbuildah bud -f Containerfile --layers --force-rm -t imageName .\n\nbuildah bud --no-cache --rm=false -t imageName .\n\nbuildah bud --dns-search=example.com --dns=223.5.5.5 --dns-option=use-vc .\n\nbuildah bud -f Containerfile.in -t imageName .\n\n### Building an multi-architecture image using a --manifest option (Requires emulation software)\n\nbuildah bud --arch arm --manifest myimage /tmp/mysrc\n\nbuildah bud --arch amd64 --manifest myimage /tmp/mysrc\n\nbuildah bud --arch s390x --manifest myimage /tmp/mysrc\n\n### Building an image using a URL\n\n  This will clone the specified GitHub repository from the URL and use it as context. The Containerfile or Dockerfile at the root of the repository is used as the context of the build. This only works if the GitHub repository is a dedicated repository.\n\n  buildah bud github.com/scollier/purpletest\n\n  Note: You can set an arbitrary Git repository via the git:// scheme.\n\n### Building an image using a URL to a tarball'ed context\n  Buildah will fetch the tarball archive, decompress it and use its contents as the build context.  The Containerfile or Dockerfile at the root of the archive and the rest of the archive will get used as the context of the build. If you pass an -f PATH/Containerfile option as well, the system will look for that file inside the contents of the tarball.\n\n  buildah bud -f dev/Containerfile https://10.10.10.1/docker/context.tar.gz\n\n  Note: supported compression formats are 'xz', 'bzip2', 'gzip' and 'identity' (no compression).\n\n### Using Build Time Variables\n#### Replace the value set for the HTTP_PROXY environment variable within the Containerfile.\n\nbuildah bud --build-arg=HTTP_PROXY=\"http://127.0.0.1:8321\"\n\n## ENVIRONMENT\n\n**BUILD\\_REGISTRY\\_SOURCES**\n\nBUILD\\_REGISTRY\\_SOURCES, if set, is treated as a JSON object which contains\nlists of registry names under the keys `insecureRegistries`,\n`blockedRegistries`, and `allowedRegistries`.\n\nWhen pulling an image from a registry, if the name of the registry matches any\nof the items in the `blockedRegistries` list, the image pull attempt is denied.\nIf there are registries in the `allowedRegistries` list, and the registry's\nname is not in the list, the pull attempt is denied.\n\n**TMPDIR**\nThe TMPDIR environment variable allows the user to specify where temporary files\nare stored while pulling and pushing images.  Defaults to '/var/tmp'.\n\n## Files\n\n### `.containerignore`/`.dockerignore`\n\nIf the .containerignore/.dockerignore file exists in the context directory,\n`buildah bud` reads its contents. If both exist, then .containerignore is used.\nUse the `--ignorefile` flag to override the ignore file path location. Buildah uses the content to exclude files and directories from the context directory, when executing COPY and ADD directives in the Containerfile/Dockerfile\n\nUsers can specify a series of Unix shell globals in a\n.containerignore/.dockerignore file to identify files/directories to exclude.\n\nBuildah supports a special wildcard string `**` which matches any number of\ndirectories (including zero). For example, **/*.go will exclude all files that\nend with .go that are found in all directories.\n\nExample .containerignore file:\n\n```\n# exclude this content for image\n*/*.c\n**/output*\nsrc\n```\n\n`*/*.c`\nExcludes files and directories whose names ends with .c in any top level subdirectory. For example, the source file include/rootless.c.\n\n`**/output*`\nExcludes files and directories starting with `output` from any directory.\n\n`src`\nExcludes files named src and the directory src as well as any content in it.\n\nLines starting with ! (exclamation mark) can be used to make exceptions to\nexclusions. The following is an example .containerignore/.dockerignore file that uses this\nmechanism:\n```\n*.doc\n!Help.doc\n```\n\nExclude all doc files except Help.doc from the image.\n\nThis functionality is compatible with the handling of .dockerignore files described here:\n\nhttps://docs.docker.com/engine/reference/builder/#dockerignore-file\n\n**registries.conf** (`/etc/containers/registries.conf`)\n\nregistries.conf is the configuration file which specifies which container registries should be consulted when completing image names which do not include a registry or domain portion.\n\n**policy.json** (`/etc/containers/policy.json`)\n\nSignature policy file.  This defines the trust policy for container images.  Controls which container registries can be used for image, and whether or not the tool should trust the images.\n\n## SEE ALSO\nbuildah(1), cpp(1), buildah-login(1), docker-login(1), namespaces(7), pid\\_namespaces(7), containers-policy.json(5), containers-registries.conf(5), user\\_namespaces(7), crun(1), runc(8)\n\n## FOOTNOTES\n<a name=\"Footnote1\">1</a>: The Buildah project is committed to inclusivity, a core value of open source. The `master` and `slave` mount propagation terminology used here is problematic and divisive, and should be changed. However, these terms are currently used within the Linux kernel and must be used as-is at this time. When the kernel maintainers rectify this usage, Buildah will follow suit immediately.\n", "# buildah-from \"1\" \"March 2017\" \"buildah\"\n\n## NAME\nbuildah\\-from - Creates a new working container, either from scratch or using a specified image as a starting point.\n\n## SYNOPSIS\n**buildah from** [*options*] *image*\n\n## DESCRIPTION\nCreates a working container based upon the specified image name.  If the\nsupplied image name is \"scratch\" a new empty container is created.  Image names\nuse a \"transport\":\"details\" format.\n\nMultiple transports are supported:\n\n  **dir:**_path_\n  An existing local directory _path_ containing the manifest, layer tarballs, and signatures in individual files. This is a non-standardized format, primarily useful for debugging or noninvasive image inspection.\n\n  **docker://**_docker-reference_ (Default)\n  An image in a registry implementing the \"Docker Registry HTTP API V2\". By default, uses the authorization state in `$XDG\\_RUNTIME\\_DIR/containers/auth.json`, which is set using `(buildah login)`.  If XDG_RUNTIME_DIR is not set, the default is /run/containers/$UID/auth.json. If the authorization state is not found there, `$HOME/.docker/config.json` is checked, which is set using `(docker login)`.\n  If _docker-reference_ does not include a registry name, *localhost* will be consulted first, followed by any registries named in the registries configuration.\n\n  **docker-archive:**_path_\n  An image is retrieved as a `docker load` formatted file.\n\n  **docker-daemon:**_docker-reference_\n  An image _docker-reference_ stored in the docker daemon's internal storage.  _docker-reference_ must include either a tag or a digest.  Alternatively, when reading images, the format can also be docker-daemon:algo:digest (an image ID).\n\n  **oci:**_path_**:**_tag_**\n  An image tag in a directory compliant with \"Open Container Image Layout Specification\" at _path_.\n\n  **oci-archive:**_path_**:**_tag_\n  An image _tag_ in a directory compliant with \"Open Container Image Layout Specification\" at _path_.\n\n### DEPENDENCIES\n\nBuildah resolves the path to the registry to pull from by using the /etc/containers/registries.conf\nfile, containers-registries.conf(5).  If the `buildah from` command fails with an \"image not known\" error,\nfirst verify that the registries.conf file is installed and configured appropriately.\n\n## RETURN VALUE\nThe container ID of the container that was created.  On error 1 is returned.\n\n## OPTIONS\n\n**--add-host**=[]\n\nAdd a custom host-to-IP mapping (host:ip)\n\nAdd a line to /etc/hosts. The format is hostname:ip. The **--add-host** option can be set multiple times.\n\n**--arch**=\"ARCH\"\n\nSet the ARCH of the image to be pulled to the provided value instead of using the architecture of the host. (Examples: aarch64, arm, i686, ppc64le, s390x, x86_64)\n\n**--authfile** *path*\n\nPath of the authentication file. Default is ${XDG_\\RUNTIME\\_DIR}/containers/auth.json. If XDG_RUNTIME_DIR is not set, the default is /run/containers/$UID/auth.json. This file is created using using `buildah login`.\n\nIf the authorization state is not found there, $HOME/.docker/config.json is checked, which is set using `docker login`.\n\nNote: You can also override the default path of the authentication file by setting the REGISTRY\\_AUTH\\_FILE\nenvironment variable. `export REGISTRY_AUTH_FILE=path`\n\n**--cap-add**=*CAP\\_xxx*\n\nAdd the specified capability to the default set of capabilities which will be\nsupplied for subsequent *buildah run* invocations which use this container.\nCertain capabilities are granted by default; this option can be used to add\nmore.\n\n**--cap-drop**=*CAP\\_xxx*\n\nRemove the specified capability from the default set of capabilities which will\nbe supplied for subsequent *buildah run* invocations which use this container.\nThe CAP\\_AUDIT\\_WRITE, CAP\\_CHOWN, CAP\\_DAC\\_OVERRIDE, CAP\\_FOWNER,\nCAP\\_FSETID, CAP\\_KILL, CAP\\_MKNOD, CAP\\_NET\\_BIND\\_SERVICE, CAP\\_SETFCAP,\nCAP\\_SETGID, CAP\\_SETPCAP, CAP\\_SETUID, and CAP\\_SYS\\_CHROOT capabilities are\ngranted by default; this option can be used to remove them.\n\nIf a capability is specified to both the **--cap-add** and **--cap-drop**\noptions, it will be dropped, regardless of the order in which the options were\ngiven.\n\n**--cert-dir** *path*\n\nUse certificates at *path* (\\*.crt, \\*.cert, \\*.key) to connect to the registry.\nThe default certificates directory is _/etc/containers/certs.d_.\n\n**--cgroup-parent**=\"\"\n\nPath to cgroups under which the cgroup for the container will be created. If the path is not absolute, the path is considered to be relative to the cgroups path of the init process. Cgroups will be created if they do not already exist.\n\n**--cidfile** *ContainerIDFile*\n\nWrite the container ID to the file.\n\n**--cni-config-dir**=*directory*\n\nLocation of CNI configuration files which will dictate which plugins will be\nused to configure network interfaces and routing when the container is\nsubsequently used for `buildah run`, if processes to be started will be run in\ntheir own network namespaces, and networking is not disabled.\n\n**--cni-plugin-path**=*directory[:directory[:directory[...]]]*\n\nList of directories in which the CNI plugins which will be used for configuring\nnetwork namespaces can be found.\n\n**--cpu-period**=*0*\n\nLimit the CPU CFS (Completely Fair Scheduler) period\n\nLimit the container's CPU usage. This flag tell the kernel to restrict the container's CPU usage to the period you specify.\n\n**--cpu-quota**=*0*\n\nLimit the CPU CFS (Completely Fair Scheduler) quota\n\nLimit the container's CPU usage. By default, containers run with the full\nCPU resource. This flag tell the kernel to restrict the container's CPU usage\nto the quota you specify.\n\n**--cpu-shares**, **-c**=*0*\n\nCPU shares (relative weight)\n\nBy default, all containers get the same proportion of CPU cycles. This proportion\ncan be modified by changing the container's CPU share weighting relative\nto the weighting of all other running containers.\n\nTo modify the proportion from the default of 1024, use the **--cpu-shares**\nflag to set the weighting to 2 or higher.\n\nThe proportion will only apply when CPU-intensive processes are running.\nWhen tasks in one container are idle, other containers can use the\nleft-over CPU time. The actual amount of CPU time will vary depending on\nthe number of containers running on the system.\n\nFor example, consider three containers, one has a cpu-share of 1024 and\ntwo others have a cpu-share setting of 512. When processes in all three\ncontainers attempt to use 100% of CPU, the first container would receive\n50% of the total CPU time. If you add a fourth container with a cpu-share\nof 1024, the first container only gets 33% of the CPU. The remaining containers\nreceive 16.5%, 16.5% and 33% of the CPU.\n\nOn a multi-core system, the shares of CPU time are distributed over all CPU\ncores. Even if a container is limited to less than 100% of CPU time, it can\nuse 100% of each individual CPU core.\n\nFor example, consider a system with more than three cores. If you start one\ncontainer **{C0}** with **-c=512** running one process, and another container\n**{C1}** with **-c=1024** running two processes, this can result in the following\ndivision of CPU shares:\n\n    PID    container\tCPU\tCPU share\n    100    {C0}\t\t0\t100% of CPU0\n    101    {C1}\t\t1\t100% of CPU1\n    102    {C1}\t\t2\t100% of CPU2\n\n**--cpuset-cpus**=\"\"\n\n  CPUs in which to allow execution (0-3, 0,1)\n\n**--cpuset-mems**=\"\"\n\nMemory nodes (MEMs) in which to allow execution (0-3, 0,1). Only effective on NUMA systems.\n\nIf you have four memory nodes on your system (0-3), use `--cpuset-mems=0,1`\nthen processes in your container will only use memory from the first\ntwo memory nodes.\n\n**--creds** *creds*\n\nThe [username[:password]] to use to authenticate with the registry if required.\nIf one or both values are not supplied, a command line prompt will appear and the\nvalue can be entered.  The password is entered without echo.\n\n**--decryption-key** *key[:passphrase]*\n\nThe [key[:passphrase]] to be used for decryption of images. Key can point to keys and/or certificates. Decryption will be tried with all keys. If the key is protected by a passphrase, it is required to be passed in the argument and omitted otherwise.\n\n**--device**=*device*\n\nAdd a host device or devices under a directory to the container. The format is `<device-on-host>[:<device-on-container>][:<permissions>]` (e.g. --device=/dev/sdc:/dev/xvdc:rwm)\n\n**--dns**=[]\n\nSet custom DNS servers\n\nThis option can be used to override the DNS configuration passed to the container. Typically this is necessary when the host DNS configuration is invalid for the container (e.g., 127.0.0.1). When this is the case the `--dns` flag is necessary for every run.\n\nThe special value **none** can be specified to disable creation of /etc/resolv.conf in the container by Buildah. The /etc/resolv.conf file in the image will be used without changes.\n\n**--dns-option**=[]\n\nSet custom DNS options\n\n**--dns-search**=[]\n\nSet custom DNS search domains\n\n**--format**, **-f** *oci* | *docker*\n\nControl the format for the built image's manifest and configuration data.\nRecognized formats include *oci* (OCI image-spec v1.0, the default) and\n*docker* (version 2, using schema format 2 for the manifest).\n\nNote: You can also override the default format by setting the BUILDAH\\_FORMAT\nenvironment variable.  `export BUILDAH_FORMAT=docker`\n\n**--http-proxy**\n\nBy default proxy environment variables are passed into the container if set\nfor the Buildah process.  This can be disabled by setting the `--http-proxy`\noption to `false`.  The environment variables passed in include `http_proxy`,\n`https_proxy`, `ftp_proxy`, `no_proxy`, and also the upper case versions of\nthose.\n\nDefaults to `true`\n\n**--ipc** *how*\n\nSets the configuration for IPC namespaces when the container is subsequently\nused for `buildah run`.\nThe configured value can be \"\" (the empty string) or \"container\" to indicate\nthat a new IPC namespace should be created, or it can be \"host\" to indicate\nthat the IPC namespace in which `Buildah` itself is being run should be reused,\nor it can be the path to an IPC namespace which is already in use by\nanother process.\n\n**--isolation** *type*\n\nControls what type of isolation is used for running processes under `buildah\nrun`.  Recognized types include *oci* (OCI-compatible runtime, the default),\n*rootless* (OCI-compatible runtime invoked using a modified\nconfiguration, with *--no-new-keyring* added to its *create* invocation,\nreusing the host's network and UTS namespaces, and creating private IPC, PID,\nmount, and user namespaces; the default for unprivileged users), and *chroot*\n(an internal wrapper that leans more toward chroot(1) than container\ntechnology, reusing the host's control group, network, IPC, and PID namespaces,\nand creating private mount and UTS namespaces, and creating user namespaces\nonly when they're required for ID mapping).\n\nNote: You can also override the default isolation type by setting the\nBUILDAH\\_ISOLATION environment variable.  `export BUILDAH_ISOLATION=oci`\n\n**--memory**, **-m**=\"\"\n\nMemory limit (format: <number>[<unit>], where unit = b, k, m or g)\n\nAllows you to constrain the memory available to a container. If the host\nsupports swap memory, then the **-m** memory setting can be larger than physical\nRAM. If a limit of 0 is specified (not using **-m**), the container's memory is\nnot limited. The actual limit may be rounded up to a multiple of the operating\nsystem's page size (the value would be very large, that's millions of trillions).\n\n**--memory-swap**=\"LIMIT\"\n\nA limit value equal to memory plus swap. Must be used with the  **-m**\n(**--memory**) flag. The swap `LIMIT` should always be larger than **-m**\n(**--memory**) value.  By default, the swap `LIMIT` will be set to double\nthe value of --memory.\n\nThe format of `LIMIT` is `<number>[<unit>]`. Unit can be `b` (bytes),\n`k` (kilobytes), `m` (megabytes), or `g` (gigabytes). If you don't specify a\nunit, `b` is used. Set LIMIT to `-1` to enable unlimited swap.\n\n**--name** *name*\n\nA *name* for the working container\n\n**--net** *how*\n**--network** *how*\n\nSets the configuration for network namespaces when the container is subsequently\nused for `buildah run`.\nThe configured value can be \"\" (the empty string) or \"container\" to indicate\nthat a new network namespace should be created, or it can be \"host\" to indicate\nthat the network namespace in which `Buildah` itself is being run should be\nreused, or it can be the path to a network namespace which is already in use by\nanother process.\n\n**--os**=\"OS\"\n\nSet the OS of the image to be pulled to the provided value instead of using the current operating system of the host.\n\n**--pid** *how*\n\nSets the configuration for PID namespaces when the container is subsequently\nused for `buildah run`.\nThe configured value can be \"\" (the empty string) or \"container\" to indicate\nthat a new PID namespace should be created, or it can be \"host\" to indicate\nthat the PID namespace in which `Buildah` itself is being run should be reused,\nor it can be the path to a PID namespace which is already in use by another\nprocess.\n\n**--pull**\n\nWhen the flag is enabled, attempt to pull the latest image from the registries\nlisted in registries.conf if a local image does not exist or the image is newer\nthan the one in storage. Raise an error if the image is not in any listed\nregistry and is not present locally.\n\nIf the flag is disabled (with *--pull=false*), do not pull the image from the\nregistry, use only the local version. Raise an error if the image is not\npresent locally.\n\nDefaults to *true*.\n\n**--pull-always**\n\nPull the image from the first registry it is found in as listed in registries.conf.\nRaise an error if not found in the registries, even if the image is present locally.\n\n**--pull-never**\n\nDo not pull the image from the registry, use only the local version. Raise an error\nif the image is not present locally.\n\n**--quiet**, **-q**\n\nIf an image needs to be pulled from the registry, suppress progress output.\n\n**--security-opt**=[]\n\nSecurity Options\n\n  \"label=user:USER\"   : Set the label user for the container\n  \"label=role:ROLE\"   : Set the label role for the container\n  \"label=type:TYPE\"   : Set the label type for the container\n  \"label=level:LEVEL\" : Set the label level for the container\n  \"label=disable\"     : Turn off label confinement for the container\n  \"no-new-privileges\" : Not supported\n\n  \"seccomp=unconfined\" : Turn off seccomp confinement for the container\n  \"seccomp=profile.json :  White listed syscalls seccomp Json file to be used as a seccomp filter\n\n  \"apparmor=unconfined\" : Turn off apparmor confinement for the container\n  \"apparmor=your-profile\" : Set the apparmor confinement profile for the container\n\n**--shm-size**=\"\"\n\nSize of `/dev/shm`. The format is `<number><unit>`. `number` must be greater than `0`.\nUnit is optional and can be `b` (bytes), `k` (kilobytes), `m`(megabytes), or `g` (gigabytes).\nIf you omit the unit, the system uses bytes. If you omit the size entirely, the system uses `64m`.\n\n**--tls-verify** *bool-value*\n\nRequire HTTPS and verification of certificates when talking to container registries (defaults to true).  TLS verification cannot be used when talking to an insecure registry.\n\n**--ulimit** *type*=*soft-limit*[:*hard-limit*]\n\nSpecifies resource limits to apply to processes launched during `buildah run`.\nThis option can be specified multiple times.  Recognized resource types\ninclude:\n  \"core\": maximum core dump size (ulimit -c)\n  \"cpu\": maximum CPU time (ulimit -t)\n  \"data\": maximum size of a process's data segment (ulimit -d)\n  \"fsize\": maximum size of new files (ulimit -f)\n  \"locks\": maximum number of file locks (ulimit -x)\n  \"memlock\": maximum amount of locked memory (ulimit -l)\n  \"msgqueue\": maximum amount of data in message queues (ulimit -q)\n  \"nice\": niceness adjustment (nice -n, ulimit -e)\n  \"nofile\": maximum number of open files (ulimit -n)\n  \"nofile\": maximum number of open files (1048576); when run by root\n  \"nproc\": maximum number of processes (ulimit -u)\n  \"nproc\": maximum number of processes (1048576); when run by root\n  \"rss\": maximum size of a process's (ulimit -m)\n  \"rtprio\": maximum real-time scheduling priority (ulimit -r)\n  \"rttime\": maximum amount of real-time execution between blocking syscalls\n  \"sigpending\": maximum number of pending signals (ulimit -i)\n  \"stack\": maximum stack size (ulimit -s)\n\n**--userns** *how*\n\nSets the configuration for user namespaces when the container is subsequently\nused for `buildah run`.\nThe configured value can be \"\" (the empty string) or \"container\" to indicate\nthat a new user namespace should be created, it can be \"host\" to indicate that\nthe user namespace in which `Buildah` itself is being run should be reused, or\nit can be the path to an user namespace which is already in use by another\nprocess.\n\n**--userns-uid-map-user** *mapping*\n\nDirectly specifies a UID mapping which should be used to set ownership, at the\nfilesystem level, on the container's contents.\nCommands run using `buildah run` will default to being run in their own user\nnamespaces, configured using the UID and GID maps.\n\nEntries in this map take the form of one or more triples of a starting\nin-container UID, a corresponding starting host-level UID, and the number of\nconsecutive IDs which the map entry represents.\n\nThis option overrides the *remap-uids* setting in the *options* section of\n/etc/containers/storage.conf.\n\nIf this option is not specified, but a global --userns-uid-map setting is\nsupplied, settings from the global option will be used.\n\nIf none of --userns-uid-map-user, --userns-gid-map-group, or --userns-uid-map\nare specified, but --userns-gid-map is specified, the UID map will be set to\nuse the same numeric values as the GID map.\n\n**NOTE:** When this option is specified by a rootless user, the specified mappings are relative to the rootless usernamespace in the container, rather than being relative to the host as it would be when run rootful.\n\n**--userns-gid-map-group** *mapping*\n\nDirectly specifies a GID mapping which should be used to set ownership, at the\nfilesystem level, on the container's contents.\nCommands run using `buildah run` will default to being run in their own user\nnamespaces, configured using the UID and GID maps.\n\nEntries in this map take the form of one or more triples of a starting\nin-container GID, a corresponding starting host-level GID, and the number of\nconsecutive IDs which the map entry represents.\n\nThis option overrides the *remap-gids* setting in the *options* section of\n/etc/containers/storage.conf.\n\nIf this option is not specified, but a global --userns-gid-map setting is\nsupplied, settings from the global option will be used.\n\nIf none of --userns-uid-map-user, --userns-gid-map-group, or --userns-gid-map\nare specified, but --userns-uid-map is specified, the GID map will be set to\nuse the same numeric values as the UID map.\n\n**NOTE:** When this option is specified by a rootless user, the specified mappings are relative to the rootless usernamespace in the container, rather than being relative to the host as it would be when run rootful.\n\n**--userns-uid-map-user** *user*\n\nSpecifies that a UID mapping which should be used to set ownership, at the\nfilesystem level, on the container's contents, can be found in entries in the\n`/etc/subuid` file which correspond to the specified user.\nCommands run using `buildah run` will default to being run in their own user\nnamespaces, configured using the UID and GID maps.\nIf --userns-gid-map-group is specified, but --userns-uid-map-user is not\nspecified, `Buildah` will assume that the specified group name is also a\nsuitable user name to use as the default setting for this option.\n\n**--userns-gid-map-group** *group*\n\nSpecifies that a GID mapping which should be used to set ownership, at the\nfilesystem level, on the container's contents, can be found in entries in the\n`/etc/subgid` file which correspond to the specified group.\nCommands run using `buildah run` will default to being run in their own user\nnamespaces, configured using the UID and GID maps.\nIf --userns-uid-map-user is specified, but --userns-gid-map-group is not\nspecified, `Buildah` will assume that the specified user name is also a\nsuitable group name to use as the default setting for this option.\n\n**--uts** *how*\n\nSets the configuration for UTS namespaces when the container is subsequently\nused for `buildah run`.\nThe configured value can be \"\" (the empty string) or \"container\" to indicate\nthat a new UTS namespace should be created, or it can be \"host\" to indicate\nthat the UTS namespace in which `Buildah` itself is being run should be reused,\nor it can be the path to a UTS namespace which is already in use by another\nprocess.\n\n**--variant**=\"\"\n\nSet the architecture variant of the image to be pulled.\n\n**--volume**, **-v**[=*[HOST-DIR:CONTAINER-DIR[:OPTIONS]]*]\n\n   Create a bind mount. If you specify, ` -v /HOST-DIR:/CONTAINER-DIR`, Buildah\n   bind mounts `/HOST-DIR` in the host to `/CONTAINER-DIR` in the Buildah\n   container. The `OPTIONS` are a comma delimited list and can be: <sup>[[1]](#Footnote1)</sup>\n\n   * [rw|ro]\n   * [U]\n   * [z|Z|O]\n   * [`[r]shared`|`[r]slave`|`[r]private`|`[r]unbindable`]\n\nThe `CONTAINER-DIR` must be an absolute path such as `/src/docs`. The `HOST-DIR`\nmust be an absolute path as well. Buildah bind-mounts the `HOST-DIR` to the\npath you specify. For example, if you supply `/foo` as the host path,\nBuildah copies the contents of `/foo` to the container filesystem on the host\nand bind mounts that into the container.\n\nYou can specify multiple  **-v** options to mount one or more mounts to a\ncontainer.\n\n  `Write Protected Volume Mounts`\n\nYou can add the `:ro` or `:rw` suffix to a volume to mount it read-only or\nread-write mode, respectively. By default, the volumes are mounted read-write.\nSee examples.\n\n  `Chowning Volume Mounts`\n\nBy default, Buildah does not change the owner and group of source volume directories mounted into containers. If a container is created in a new user namespace, the UID and GID in the container may correspond to another UID and GID on the host.\n\nThe `:U` suffix tells Buildah to use the correct host UID and GID based on the UID and GID within the container, to change the owner and group of the source volume.\n\n  `Labeling Volume Mounts`\n\nLabeling systems like SELinux require that proper labels are placed on volume\ncontent mounted into a container. Without a label, the security system might\nprevent the processes running inside the container from using the content. By\ndefault, Buildah does not change the labels set by the OS.\n\nTo change a label in the container context, you can add either of two suffixes\n`:z` or `:Z` to the volume mount. These suffixes tell Buildah to relabel file\nobjects on the shared volumes. The `z` option tells Buildah that two containers\nshare the volume content. As a result, Buildah labels the content with a shared\ncontent label. Shared volume labels allow all containers to read/write content.\nThe `Z` option tells Buildah to label the content with a private unshared label.\nOnly the current container can use a private volume.\n\n  `Overlay Volume Mounts`\n\n   The `:O` flag tells Buildah to mount the directory from the host as a temporary storage using the Overlay file system. The `RUN` command containers are allowed to modify contents within the mountpoint and are stored in the container storage in a separate directory.  In Overlay FS terms the source directory will be the lower, and the container storage directory will be the upper. Modifications to the mount point are destroyed when the `RUN` command finishes executing, similar to a tmpfs mount point.\n\n  Any subsequent execution of `RUN` commands sees the original source directory content, any changes from previous RUN commands no longer exists.\n\n  One use case of the `overlay` mount is sharing the package cache from the host into the container to allow speeding up builds.\n\n  Note:\n\n     - The `O` flag is not allowed to be specified with the `Z` or `z` flags. Content mounted into the container is labeled with the private label.\n       On SELinux systems, labels in the source directory needs to be readable by the container label. If not, SELinux container separation must be disabled for the container to work.\n     - Modification of the directory volume mounted into the container with an overlay mount can cause unexpected failures.  It is recommended that you do not modify the directory until the container finishes running.\n\nBy default bind mounted volumes are `private`. That means any mounts done\ninside container will not be visible on the host and vice versa. This behavior can\nbe changed by specifying a volume mount propagation property.\n\nWhen the mount propagation policy is set to `shared`, any mounts completed inside\nthe container on that volume will be visible to both the host and container. When\nthe mount propagation policy is set to `slave`, one way mount propagation is enabled\nand any mounts completed on the host for that volume will be visible only inside of the container.\nTo control the mount propagation property of the volume use the `:[r]shared`,\n`:[r]slave`, `[r]private` or `[r]unbindable`propagation flag. The propagation property can\nbe specified only for bind mounted volumes and not for internal volumes or\nnamed volumes. For mount propagation to work on the source mount point (the mount point\nwhere source dir is mounted on) it has to have the right propagation properties. For\nshared volumes, the source mount point has to be shared. And for slave volumes,\nthe source mount has to be either shared or slave. <sup>[[1]](#Footnote1)</sup>\n\nUse `df <source-dir>` to determine the source mount and then use\n`findmnt -o TARGET,PROPAGATION <source-mount-dir>` to determine propagation\nproperties of source mount, if `findmnt` utility is not available, the source mount point\ncan be determined by looking at the mount entry in `/proc/self/mountinfo`. Look\nat `optional fields` and see if any propagation properties are specified.\n`shared:X` means the mount is `shared`, `master:X` means the mount is `slave` and if\nnothing is there that means the mount is `private`. <sup>[[1]](#Footnote1)</sup>\n\nTo change propagation properties of a mount point use the `mount` command. For\nexample, to bind mount the source directory `/foo` do\n`mount --bind /foo /foo` and `mount --make-private --make-shared /foo`. This\nwill convert /foo into a `shared` mount point.  The propagation properties of the source\nmount can be changed directly. For instance if `/` is the source mount for\n`/foo`, then use `mount --make-shared /` to convert `/` into a `shared` mount.\n\n## EXAMPLE\n\nbuildah from --pull imagename\n\nbuildah from --pull docker://myregistry.example.com/imagename\n\nbuildah from docker-daemon:imagename:imagetag\n\nbuildah from --name mycontainer docker-archive:filename\n\nbuildah from oci-archive:filename\n\nbuildah from --name mycontainer dir:directoryname\n\nbuildah from --pull-always --name \"mycontainer\" docker://myregistry.example.com/imagename\n\nbuildah from --tls-verify=false myregistry/myrepository/imagename:imagetag\n\nbuildah from --creds=myusername:mypassword --cert-dir ~/auth myregistry/myrepository/imagename:imagetag\n\nbuildah from --authfile=/tmp/auths/myauths.json myregistry/myrepository/imagename:imagetag\n\nbuildah from --memory 40m --cpu-shares 2 --cpuset-cpus 0,2 --security-opt label=level:s0:c100,c200 myregistry/myrepository/imagename:imagetag\n\nbuildah from --ulimit nofile=1024:1028 --cgroup-parent /path/to/cgroup/parent myregistry/myrepository/imagename:imagetag\n\nbuildah from --volume /home/test:/myvol:ro,Z myregistry/myrepository/imagename:imagetag\n\nbuildah from -v /home/test:/myvol:z,U myregistry/myrepository/imagename:imagetag\n\nbuildah from -v /var/lib/yum:/var/lib/yum:O myregistry/myrepository/imagename:imagetag\n\nbuildah from --arch=arm --variant v7 myregistry/myrepository/imagename:imagetag\n\n## ENVIRONMENT\n\n**BUILD\\_REGISTRY\\_SOURCES**\n\nBUILD\\_REGISTRY\\_SOURCES, if set, is treated as a JSON object which contains\nlists of registry names under the keys `insecureRegistries`,\n`blockedRegistries`, and `allowedRegistries`.\n\nWhen pulling an image from a registry, if the name of the registry matches any\nof the items in the `blockedRegistries` list, the image pull attempt is denied.\nIf there are registries in the `allowedRegistries` list, and the registry's\nname is not in the list, the pull attempt is denied.\n\n**TMPDIR**\nThe TMPDIR environment variable allows the user to specify where temporary files\nare stored while pulling and pushing images.  Defaults to '/var/tmp'.\n\n## FILES\n\n**registries.conf** (`/etc/containers/registries.conf`)\n\nregistries.conf is the configuration file which specifies which container registries should be consulted when completing image names which do not include a registry or domain portion.\n\n**policy.json** (`/etc/containers/policy.json`)\n\nSignature policy file.  This defines the trust policy for container images.  Controls which container registries can be used for image, and whether or not the tool should trust the images.\n\n## SEE ALSO\nbuildah(1), buildah-pull(1), buildah-login(1), docker-login(1), namespaces(7), pid\\_namespaces(7), containers-policy.json(5), containers-registries.conf(5), user\\_namespaces(7)\n\n## FOOTNOTES\n<a name=\"Footnote1\">1</a>: The Buildah project is committed to inclusivity, a core value of open source. The `master` and `slave` mount propagation terminology used here is problematic and divisive, and should be changed. However, these terms are currently used within the Linux kernel and must be used as-is at this time. When the kernel maintainers rectify this usage, Buildah will follow suit immediately.\n", "# buildah-run \"1\" \"March 2017\" \"buildah\"\n\n## NAME\nbuildah\\-run - Run a command inside of the container.\n\n## SYNOPSIS\n**buildah run** [*options*] [**--**] *container* *command*\n\n## DESCRIPTION\nLaunches a container and runs the specified command in that container using the\ncontainer's root filesystem as a root filesystem, using configuration settings\ninherited from the container's image or as specified using previous calls to\nthe *buildah config* command.  To execute *buildah run* within an\ninteractive shell, specify the --tty option.\n\n## OPTIONS\n**--add-history**\n\nAdd an entry to the history which will note what command is being invoked.\nDefaults to false.\n\nNote: You can also override the default value of --add-history by setting the\nBUILDAH\\_HISTORY environment variable. `export BUILDAH_HISTORY=true`\n\n**--cap-add**=*CAP\\_xxx*\n\nAdd the specified capability to the set of capabilities which will be granted\nto the specified command.\nCertain capabilities are granted by default; this option can be used to add\nmore beyond the defaults, which may have been modified by **--cap-add** and\n**--cap-drop** options used with the *buildah from* invocation which created\nthe container.\n\n**--cap-drop**=*CAP\\_xxx*\n\nAdd the specified capability from the set of capabilities which will be granted\nto the specified command.\nThe CAP\\_AUDIT\\_WRITE, CAP\\_CHOWN, CAP\\_DAC\\_OVERRIDE, CAP\\_FOWNER,\nCAP\\_FSETID, CAP\\_KILL, CAP\\_MKNOD, CAP\\_NET\\_BIND\\_SERVICE, CAP\\_SETFCAP,\nCAP\\_SETGID, CAP\\_SETPCAP, CAP\\_SETUID, and CAP\\_SYS\\_CHROOT capabilities are\ngranted by default; this option can be used to remove them from the defaults,\nwhich may have been modified by **--cap-add** and **--cap-drop** options used\nwith the *buildah from* invocation which created the container.\n\nIf a capability is specified to both the **--cap-add** and **--cap-drop**\noptions, it will be dropped, regardless of the order in which the options were\ngiven.\n\n**--cni-config-dir**=*directory*\n\nLocation of CNI configuration files which will dictate which plugins will be\nused to configure network interfaces and routing inside the running container,\nif the container will be run in its own network namespace, and networking is\nnot disabled.\n\n**--cni-plugin-path**=*directory[:directory[:directory[...]]]*\n\nList of directories in which the CNI plugins which will be used for configuring\nnetwork namespaces can be found.\n\n**--env**, **-e** *env=value*\n\nTemporarily add a value (e.g. env=*value*) to the environment for the running\nprocess. Unlike `buildah config --env`, the environment will not persist to\nlater calls to `buildah run` or to the built image. Can be used multiple times.\n\n**--hostname**\n\nSet the hostname inside of the running container.\n\n**--ipc** *how*\n\nSets the configuration for the IPC namespaces for the container.\nThe configured value can be \"\" (the empty string) or \"private\" to indicate\nthat a new IPC namespace should be created, or it can be \"host\" to indicate\nthat the IPC namespace in which `buildah` itself is being run should be reused,\nor it can be the path to an IPC namespace which is already in use by another\nprocess.\n\n**--isolation** *type*\n\nControls what type of isolation is used for running the process.  Recognized\ntypes include *oci* (OCI-compatible runtime, the default), *rootless*\n(OCI-compatible runtime invoked using a modified configuration, with\n*--no-new-keyring* added to its *create* invocation, reusing the host's network\nand UTS namespaces, and creating private IPC, PID, mount, and user namespaces;\nthe default for unprivileged users), and *chroot* (an internal wrapper that\nleans more toward chroot(1) than container technology, reusing the host's\ncontrol group, network, IPC, and PID namespaces, and creating private mount and\nUTS namespaces, and creating user namespaces only when they're required for ID\nmapping).\n\nNote: You can also override the default isolation type by setting the\nBUILDAH\\_ISOLATION environment variable.  `export BUILDAH_ISOLATION=oci`\n\n**--mount**=*type=TYPE,TYPE-SPECIFIC-OPTION[,...]*\n\nAttach a filesystem mount to the container\n\nCurrent supported mount TYPES are bind, and tmpfs. <sup>[[1]](#Footnote1)</sup>\n\n       e.g.\n\n       type=bind,source=/path/on/host,destination=/path/in/container\n\n       type=tmpfs,tmpfs-size=512M,destination=/path/in/container\n\n       Common Options:\n\n              \u00b7 src, source: mount source spec for bind and volume. Mandatory for bind.\n\n              \u00b7 dst, destination, target: mount destination spec.\n\n              \u00b7 ro, read-only: true or false (default).\n\n       Options specific to bind:\n\n              \u00b7 bind-propagation: shared, slave, private, rshared, rslave, or rprivate(default). See also mount(2).\n\n              . bind-nonrecursive: do not setup a recursive bind mount.  By default it is recursive.\n\n       Options specific to tmpfs:\n\n              \u00b7 tmpfs-size: Size of the tmpfs mount in bytes. Unlimited by default in Linux.\n\n              \u00b7 tmpfs-mode: File mode of the tmpfs in octal. (e.g. 700 or 0700.) Defaults to 1777 in Linux.\n\n**--network**, **--net**=*mode*\n\nSets the configuration for the network namespace for the container.\n\n- **none**: no networking;\n- **host**: use the host network stack. Note: the host mode gives the container full access to local system services such as D-bus and is therefore considered insecure;\n- **ns:**_path_: path to a network namespace to join;\n- `private`: create a new namespace for the container (default)\n\n**--pid** *how*\n\nSets the configuration for the PID namespace for the container.\nThe configured value can be \"\" (the empty string) or \"private\" to indicate\nthat a new PID namespace should be created, or it can be \"host\" to indicate\nthat the PID namespace in which `buildah` itself is being run should be reused,\nor it can be the path to a PID namespace which is already in use by another\nprocess.\n\n**--runtime** *path*\n\nThe *path* to an alternate OCI-compatible runtime. Default is `runc`, or `crun` when machine is configured to use cgroups V2.\n\nNote: You can also override the default runtime by setting the BUILDAH\\_RUNTIME\nenvironment variable.  `export BUILDAH_RUNTIME=/usr/bin/crun`\n\n**--runtime-flag** *flag*\n\nAdds global flags for the container runtime. To list the supported flags, please\nconsult the manpages of the selected container runtime.\nNote: Do not pass the leading `--` to the flag. To pass the runc flag `--log-format json`\nto buildah run, the option given would be `--runtime-flag log-format=json`.\n\n**--no-pivot**\n\nDo not use pivot root to jail process inside rootfs. This should be used\nwhenever the rootfs is on top of a ramdisk.\n\nNote: You can make this option the default by setting the BUILDAH\\_NOPIVOT\nenvironment variable.  `export BUILDAH_NOPIVOT=true`\n\n**-t**, **--tty**, **--terminal**\n\nBy default a pseudo-TTY is allocated only when buildah's standard input is\nattached to a pseudo-TTY.  Setting the `--tty` option to `true` will cause a\npseudo-TTY to be allocated inside the container connecting the user's \"terminal\"\nwith the stdin and stdout stream of the container.  Setting the `--tty` option to\n`false` will prevent the pseudo-TTY from being allocated.\n\n**--user** *user*[:*group*]\n\nSet the *user* to be used for running the command in the container.\nThe user can be specified as a user name\nor UID, optionally followed by a group name or GID, separated by a colon (':').\nIf names are used, the container should include entries for those names in its\n*/etc/passwd* and */etc/group* files.\n\n**--uts** *how*\n\nSets the configuration for the UTS namespace for the container.\nThe configured value can be \"\" (the empty string) or \"private\" to indicate\nthat a new UTS namespace should be created, or it can be \"host\" to indicate\nthat the UTS namespace in which `buildah` itself is being run should be reused,\nor it can be the path to a UTS namespace which is already in use by another\nprocess.\n\n**--volume**, **-v** *source*:*destination*:*options*\n\nCreate a bind mount. If you specify, ` -v /HOST-DIR:/CONTAINER-DIR`, Buildah\nbind mounts `/HOST-DIR` in the host to `/CONTAINER-DIR` in the Buildah\ncontainer. The `OPTIONS` are a comma delimited list and can be: <sup>[[1]](#Footnote1)</sup>\n\n   * [rw|ro]\n   * [U]\n   * [z|Z]\n   * [`[r]shared`|`[r]slave`|`[r]private`]\n\nThe `CONTAINER-DIR` must be an absolute path such as `/src/docs`. The `HOST-DIR`\nmust be an absolute path as well. Buildah bind-mounts the `HOST-DIR` to the\npath you specify. For example, if you supply `/foo` as the host path,\nBuildah copies the contents of `/foo` to the container filesystem on the host\nand bind mounts that into the container.\n\nYou can specify multiple  **-v** options to mount one or more mounts to a\ncontainer.\n\n  `Write Protected Volume Mounts`\n\nYou can add the `:ro` or `:rw` suffix to a volume to mount it read-only or\nread-write mode, respectively. By default, the volumes are mounted read-write.\nSee examples.\n\n  `Chowning Volume Mounts`\n\nBy default, Buildah does not change the owner and group of source volume directories mounted into containers. If a container is created in a new user namespace, the UID and GID in the container may correspond to another UID and GID on the host.\n\nThe `:U` suffix tells Buildah to use the correct host UID and GID based on the UID and GID within the container, to change the owner and group of the source volume.\n\n  `Labeling Volume Mounts`\n\nLabeling systems like SELinux require that proper labels are placed on volume\ncontent mounted into a container. Without a label, the security system might\nprevent the processes running inside the container from using the content. By\ndefault, Buildah does not change the labels set by the OS.\n\nTo change a label in the container context, you can add either of two suffixes\n`:z` or `:Z` to the volume mount. These suffixes tell Buildah to relabel file\nobjects on the shared volumes. The `z` option tells Buildah that two containers\nshare the volume content. As a result, Buildah labels the content with a shared\ncontent label. Shared volume labels allow all containers to read/write content.\nThe `Z` option tells Buildah to label the content with a private unshared label.\nOnly the current container can use a private volume.\n\nBy default bind mounted volumes are `private`. That means any mounts done\ninside container will not be visible on the host and vice versa. This behavior can\nbe changed by specifying a volume mount propagation property.\n\nWhen the mount propagation policy is set to `shared`, any mounts completed inside\nthe container on that volume will be visible to both the host and container. When\nthe mount propagation policy is set to `slave`, one way mount propagation is enabled\nand any mounts completed on the host for that volume will be visible only inside of the container.\nTo control the mount propagation property of the volume use the `:[r]shared`,\n`:[r]slave` or `:[r]private` propagation flag. The propagation property can\nbe specified only for bind mounted volumes and not for internal volumes or\nnamed volumes. For mount propagation to work on the source mount point (the mount point\nwhere source dir is mounted on) it has to have the right propagation properties. For\nshared volumes, the source mount point has to be shared. And for slave volumes,\nthe source mount has to be either shared or slave. <sup>[[1]](#Footnote1)</sup>\n\nUse `df <source-dir>` to determine the source mount and then use\n`findmnt -o TARGET,PROPAGATION <source-mount-dir>` to determine propagation\nproperties of source mount, if `findmnt` utility is not available, the source mount point\ncan be determined by looking at the mount entry in `/proc/self/mountinfo`. Look\nat `optional fields` and see if any propagation properties are specified.\n`shared:X` means the mount is `shared`, `master:X` means the mount is `slave` and if\nnothing is there that means the mount is `private`. <sup>[[1]](#Footnote1)</sup>\n\nTo change propagation properties of a mount point use the `mount` command. For\nexample, to bind mount the source directory `/foo` do\n`mount --bind /foo /foo` and `mount --make-private --make-shared /foo`. This\nwill convert /foo into a `shared` mount point.  The propagation properties of the source\nmount can be changed directly. For instance if `/` is the source mount for\n`/foo`, then use `mount --make-shared /` to convert `/` into a `shared` mount.\n\n**--workingdir** *directory*\n\nTemporarily set the working *directory* for the running process. Unlike\n`buildah config --workingdir`, the workingdir will not persist to later\ncalls to `buildah run` or the built image.\n\n\nNOTE: End parsing of options with the `--` option, so that other\noptions can be passed to the command inside of the container.\n\n## EXAMPLE\n\nbuildah run containerID -- ps -auxw\n\nbuildah run --hostname myhost containerID -- ps -auxw\n\nbuildah run containerID -- sh -c 'echo $PATH'\n\nbuildah run --runtime-flag log-format=json containerID /bin/bash\n\nbuildah run --runtime-flag debug containerID /bin/bash\n\nbuildah run --tty containerID /bin/bash\n\nbuildah run --tty=false containerID ls /\n\nbuildah run --volume /path/on/host:/path/in/container:ro,z containerID sh\n\nbuildah run -v /path/on/host:/path/in/container:z,U containerID sh\n\nbuildah run --mount type=bind,src=/tmp/on:host,dst=/in:container,ro containerID sh\n\n## SEE ALSO\nbuildah(1), buildah-from(1), buildah-config(1), namespaces(7), pid\\_namespaces(7), crun(1), runc(8)\n\n## FOOTNOTES\n<a name=\"Footnote1\">1</a>: The Buildah project is committed to inclusivity, a core value of open source. The `master` and `slave` mount propagation terminology used here is problematic and divisive, and should be changed. However, these terms are currently used within the Linux kernel and must be used as-is at this time. When the kernel maintainers rectify this usage, Buildah will follow suit immediately.\n"], "filenames": ["chroot/run.go", "docs/buildah-bud.md", "docs/buildah-from.md", "docs/buildah-run.md"], "buggy_code_start_loc": [164, 310, 237, 85], "buggy_code_end_loc": [872, 315, 242, 89], "fixing_code_start_loc": [164, 310, 237, 85], "fixing_code_end_loc": [866, 317, 244, 92], "type": "CWE-212", "message": "An information disclosure flaw was found in Buildah, when building containers using chroot isolation. Running processes in container builds (e.g. Dockerfile RUN commands) can access environment variables from parent and grandparent processes. When run in a container in a CI/CD environment, environment variables may include sensitive information that was shared with the container in order to be used only by Buildah itself (e.g. container registry credentials).", "other": {"cve": {"id": "CVE-2021-3602", "sourceIdentifier": "secalert@redhat.com", "published": "2022-03-03T19:15:08.107", "lastModified": "2022-10-24T14:22:45.203", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "An information disclosure flaw was found in Buildah, when building containers using chroot isolation. Running processes in container builds (e.g. Dockerfile RUN commands) can access environment variables from parent and grandparent processes. When run in a container in a CI/CD environment, environment variables may include sensitive information that was shared with the container in order to be used only by Buildah itself (e.g. container registry credentials)."}, {"lang": "es", "value": "Se ha encontrado un fallo de divulgaci\u00f3n de informaci\u00f3n en Buildah, cuando son construidos contenedores usando el aislamiento chroot. Los procesos que son ejecutados en las construcciones de contenedores (por ejemplo, los comandos RUN de Dockerfile) pueden acceder a las variables de entorno de los procesos padres y abuelos. Cuando es ejecutado en un contenedor en un entorno CI/CD, las variables de entorno pueden incluir informaci\u00f3n confidencial que fue compartida con el contenedor para ser usada s\u00f3lo por el propio Buildah (por ejemplo, las credenciales del registro del contenedor)"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:M/Au:N/C:P/I:N/A:N", "accessVector": "LOCAL", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 1.9}, "baseSeverity": "LOW", "exploitabilityScore": 3.4, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-212"}]}, {"source": "secalert@redhat.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-200"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:buildah_project:buildah:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.16.8", "matchCriteriaId": "0CE147BD-61D6-43D8-86A8-3C3CB16D200F"}, {"vulnerable": true, "criteria": "cpe:2.3:a:buildah_project:buildah:*:*:*:*:*:*:*:*", "versionStartIncluding": "1.17.0", "versionEndExcluding": "1.17.2", "matchCriteriaId": "F6A83393-DA38-4D39-93E0-D238F6955564"}, {"vulnerable": true, "criteria": "cpe:2.3:a:buildah_project:buildah:*:*:*:*:*:*:*:*", "versionStartIncluding": "1.19.0", "versionEndExcluding": "1.19.9", "matchCriteriaId": "06B356AF-631F-4568-B0A1-D43673CD212D"}, {"vulnerable": true, "criteria": "cpe:2.3:a:buildah_project:buildah:*:*:*:*:*:*:*:*", "versionStartIncluding": "1.21.0", "versionEndExcluding": "1.21.3", "matchCriteriaId": "69D2AE6F-D695-4079-82CF-0C9E532484B5"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "F4CFF558-3C47-480D-A2F0-BABF26042943"}, {"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux_for_ibm_z_systems:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "87C21FE1-EA5C-498F-9C6C-D05F91A88217"}, {"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux_for_power_little_endian:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "47811209-5CE5-4375-8391-B0A7F6A0E420"}]}]}], "references": [{"url": "https://bugzilla.redhat.com/show_bug.cgi?id=1969264", "source": "secalert@redhat.com", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://github.com/containers/buildah/commit/a468ce0ffd347035d53ee0e26c205ef604097fb0", "source": "secalert@redhat.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/containers/buildah/security/advisories/GHSA-7638-r9r3-rmjj", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "https://ubuntu.com/security/CVE-2021-3602", "source": "secalert@redhat.com", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/containers/buildah/commit/a468ce0ffd347035d53ee0e26c205ef604097fb0"}}
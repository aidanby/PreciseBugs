{"buggy_code": ["import os\nimport posixpath\nimport re\nfrom typing import Any, Dict\nfrom urllib.parse import urlparse\n\nfrom mlflow.data.dataset_source import DatasetSource\nfrom mlflow.exceptions import MlflowException\nfrom mlflow.protos.databricks_pb2 import INVALID_PARAMETER_VALUE\nfrom mlflow.utils.file_utils import create_tmp_dir\nfrom mlflow.utils.rest_utils import augmented_raise_for_status, cloud_storage_http_request\n\n\ndef _is_path(filename: str) -> bool:\n    \"\"\"\n    Return True if `filename` is a path, False otherwise. For example,\n    \"foo/bar\" is a path, but \"bar\" is not.\n    \"\"\"\n    return os.path.basename(filename) != filename\n\n\nclass HTTPDatasetSource(DatasetSource):\n    \"\"\"\n    Represents the source of a dataset stored at a web location and referred to\n    by an HTTP or HTTPS URL.\n    \"\"\"\n\n    def __init__(self, url):\n        self._url = url\n\n    @property\n    def url(self):\n        \"\"\"\n        The HTTP/S URL referring to the dataset source location.\n\n        :return: The HTTP/S URL referring to the dataset source location.\n        \"\"\"\n        return self._url\n\n    @staticmethod\n    def _get_source_type() -> str:\n        return \"http\"\n\n    def load(self, dst_path=None) -> str:\n        \"\"\"\n        Downloads the dataset source to the local filesystem.\n\n        :param dst_path: Path of the local filesystem destination directory to which to download the\n                         dataset source. If the directory does not exist, it is created. If\n                         unspecified, the dataset source is downloaded to a new uniquely-named\n                         directory on the local filesystem.\n        :return: The path to the downloaded dataset source on the local filesystem.\n        \"\"\"\n        resp = cloud_storage_http_request(\n            method=\"GET\",\n            url=self.url,\n            stream=True,\n        )\n        augmented_raise_for_status(resp)\n\n        path = urlparse(self.url).path\n        content_disposition = resp.headers.get(\"Content-Disposition\")\n        if content_disposition is not None and (\n            file_name := next(re.finditer(r\"filename=(.+)\", content_disposition), None)\n        ):\n            # NB: If the filename is quoted, unquote it\n            basename = file_name[1].strip(\"'\\\"\")\n            if _is_path(basename):\n                raise MlflowException.invalid_parameter_value(\n                    f\"Invalid filename in Content-Disposition header: {basename}. \"\n                    \"It must be a file name, not a path.\"\n                )\n        elif path is not None and len(posixpath.basename(path)) > 0:\n            basename = posixpath.basename(path)\n        else:\n            basename = \"dataset_source\"\n\n        if dst_path is None:\n            dst_path = create_tmp_dir()\n\n        dst_path = os.path.join(dst_path, basename)\n        with open(dst_path, \"wb\") as f:\n            chunk_size = 1024 * 1024  # 1 MB\n            for chunk in resp.iter_content(chunk_size=chunk_size):\n                f.write(chunk)\n\n        return dst_path\n\n    @staticmethod\n    def _can_resolve(raw_source: Any) -> bool:\n        \"\"\"\n        :param raw_source: The raw source, e.g. a string like \"http://mysite/mydata.tar.gz\".\n        :return: True if this DatsetSource can resolve the raw source, False otherwise.\n        \"\"\"\n        if not isinstance(raw_source, str):\n            return False\n\n        try:\n            parsed_source = urlparse(str(raw_source))\n            return parsed_source.scheme in [\"http\", \"https\"]\n        except Exception:\n            return False\n\n    @classmethod\n    def _resolve(cls, raw_source: Any) -> \"HTTPDatasetSource\":\n        \"\"\"\n        :param raw_source: The raw source, e.g. a string like \"http://mysite/mydata.tar.gz\".\n        \"\"\"\n        return HTTPDatasetSource(raw_source)\n\n    def _to_dict(self) -> Dict[Any, Any]:\n        \"\"\"\n        :return: A JSON-compatible dictionary representation of the HTTPDatasetSource.\n        \"\"\"\n        return {\n            \"url\": self.url,\n        }\n\n    @classmethod\n    def _from_dict(cls, source_dict: Dict[Any, Any]) -> \"HTTPDatasetSource\":\n        \"\"\"\n        :param source_dict: A dictionary representation of the HTTPDatasetSource.\n        \"\"\"\n        url = source_dict.get(\"url\")\n        if url is None:\n            raise MlflowException(\n                'Failed to parse HTTPDatasetSource. Missing expected key: \"url\"',\n                INVALID_PARAMETER_VALUE,\n            )\n\n        return cls(url=url)\n", "import json\nimport os\nfrom unittest import mock\n\nimport pandas as pd\nimport pytest\n\nfrom mlflow.data.dataset_source_registry import get_dataset_source_from_json, resolve_dataset_source\nfrom mlflow.data.http_dataset_source import HTTPDatasetSource\nfrom mlflow.exceptions import MlflowException\nfrom mlflow.utils.rest_utils import cloud_storage_http_request\n\n\ndef test_source_to_and_from_json():\n    url = \"http://mywebsite.com/path/to/my/dataset.txt\"\n    source = HTTPDatasetSource(url)\n    assert source.to_json() == json.dumps({\"url\": url})\n\n    reloaded_source = get_dataset_source_from_json(\n        source.to_json(), source_type=source._get_source_type()\n    )\n    assert isinstance(reloaded_source, HTTPDatasetSource)\n    assert type(source) == type(reloaded_source)\n    assert source.url == reloaded_source.url == url\n\n\ndef test_http_dataset_source_is_registered_and_resolvable():\n    source1 = resolve_dataset_source(\n        \"http://mywebsite.com/path/to/my/dataset.txt\", candidate_sources=[HTTPDatasetSource]\n    )\n    assert isinstance(source1, HTTPDatasetSource)\n    assert source1.url == \"http://mywebsite.com/path/to/my/dataset.txt\"\n\n    source2 = resolve_dataset_source(\n        \"https://otherwebsite.net\", candidate_sources=[HTTPDatasetSource]\n    )\n    assert isinstance(source2, HTTPDatasetSource)\n    assert source2.url == \"https://otherwebsite.net\"\n\n    with pytest.raises(MlflowException, match=\"Could not find a source information resolver\"):\n        resolve_dataset_source(\"s3://mybucket\", candidate_sources=[HTTPDatasetSource])\n\n    with pytest.raises(MlflowException, match=\"Could not find a source information resolver\"):\n        resolve_dataset_source(\"otherscheme://mybucket\", candidate_sources=[HTTPDatasetSource])\n\n    with pytest.raises(MlflowException, match=\"Could not find a source information resolver\"):\n        resolve_dataset_source(\"htp://mybucket\", candidate_sources=[HTTPDatasetSource])\n\n\ndef test_source_load(tmp_path):\n    source1 = HTTPDatasetSource(\n        \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv\"\n    )\n\n    loaded1 = source1.load()\n    parsed1 = pd.read_csv(loaded1, sep=\";\")\n    # Verify that the expected data was downloaded by checking for an expected column and asserting\n    # that several rows are present\n    assert \"fixed acidity\" in parsed1.columns\n    assert len(parsed1) > 10\n\n    loaded2 = source1.load(dst_path=tmp_path)\n    assert loaded2 == str(tmp_path / \"winequality-red.csv\")\n    parsed2 = pd.read_csv(loaded2, sep=\";\")\n    # Verify that the expected data was downloaded by checking for an expected column and asserting\n    # that several rows are present\n    assert \"fixed acidity\" in parsed2.columns\n    assert len(parsed1) > 10\n\n    source2 = HTTPDatasetSource(\n        \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv#foo?query=param\"\n    )\n    loaded3 = source2.load(dst_path=tmp_path)\n    assert loaded3 == str(tmp_path / \"winequality-red.csv\")\n    parsed3 = pd.read_csv(loaded3, sep=\";\")\n    assert \"fixed acidity\" in parsed3.columns\n    assert len(parsed1) > 10\n\n    source3 = HTTPDatasetSource(\"https://github.com/\")\n    loaded4 = source3.load()\n    assert os.path.exists(loaded4)\n    assert os.path.basename(loaded4) == \"dataset_source\"\n\n    source4 = HTTPDatasetSource(\"https://github.com\")\n    loaded5 = source4.load()\n    assert os.path.exists(loaded5)\n    assert os.path.basename(loaded5) == \"dataset_source\"\n\n    def cloud_storage_http_request_with_fast_fail(*args, **kwargs):\n        kwargs[\"max_retries\"] = 1\n        kwargs[\"timeout\"] = 5\n        return cloud_storage_http_request(*args, **kwargs)\n\n    source5 = HTTPDatasetSource(\"https://nonexistentwebsitebuiltbythemlflowteam112312.com\")\n    with mock.patch(\n        \"mlflow.data.http_dataset_source.cloud_storage_http_request\",\n        side_effect=cloud_storage_http_request_with_fast_fail,\n    ), pytest.raises(Exception, match=\"Max retries exceeded with url\"):\n        source5.load()\n\n\n@pytest.mark.parametrize(\n    (\"attachment_filename\", \"expected_filename\"),\n    [\n        (\"testfile.txt\", \"testfile.txt\"),\n        ('\"testfile.txt\"', \"testfile.txt\"),\n        (\"'testfile.txt'\", \"testfile.txt\"),\n        (None, \"winequality-red.csv\"),\n    ],\n)\ndef test_source_load_with_content_disposition_header(attachment_filename, expected_filename):\n    def download_with_mock_content_disposition_headers(*args, **kwargs):\n        response = cloud_storage_http_request(*args, **kwargs)\n        if attachment_filename is not None:\n            response.headers[\"Content-Disposition\"] = f\"attachment; filename={attachment_filename}\"\n        else:\n            response.headers[\"Content-Disposition\"] = \"attachment\"\n        return response\n\n    with mock.patch(\n        \"mlflow.data.http_dataset_source.cloud_storage_http_request\",\n        side_effect=download_with_mock_content_disposition_headers,\n    ):\n        source = HTTPDatasetSource(\n            \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv\"\n        )\n        source.load()\n        loaded = source.load()\n        assert os.path.exists(loaded)\n        assert os.path.basename(loaded) == expected_filename\n\n\n@pytest.mark.parametrize(\n    \"filename\",\n    [\n        \"/foo/bar.txt\",\n        \"./foo/bar.txt\",\n        \"../foo/bar.txt\",\n        \"foo/bar.txt\",\n    ],\n)\ndef test_source_load_with_content_disposition_header_invalid_filename(filename):\n    def download_with_mock_content_disposition_headers(*args, **kwargs):\n        response = cloud_storage_http_request(*args, **kwargs)\n        response.headers[\"Content-Disposition\"] = f\"attachment; filename={filename}\"\n        return response\n\n    with mock.patch(\n        \"mlflow.data.http_dataset_source.cloud_storage_http_request\",\n        side_effect=download_with_mock_content_disposition_headers,\n    ):\n        source = HTTPDatasetSource(\n            \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv\"\n        )\n\n        with pytest.raises(MlflowException, match=\"Invalid filename in Content-Disposition header\"):\n            source.load()\n"], "fixing_code": ["import os\nimport re\nfrom typing import Any, Dict\nfrom urllib.parse import urlparse\n\nfrom mlflow.data.dataset_source import DatasetSource\nfrom mlflow.exceptions import MlflowException\nfrom mlflow.protos.databricks_pb2 import INVALID_PARAMETER_VALUE\nfrom mlflow.utils.file_utils import create_tmp_dir\nfrom mlflow.utils.rest_utils import augmented_raise_for_status, cloud_storage_http_request\n\n\ndef _is_path(filename: str) -> bool:\n    \"\"\"\n    Return True if `filename` is a path, False otherwise. For example,\n    \"foo/bar\" is a path, but \"bar\" is not.\n    \"\"\"\n    return os.path.basename(filename) != filename\n\n\nclass HTTPDatasetSource(DatasetSource):\n    \"\"\"\n    Represents the source of a dataset stored at a web location and referred to\n    by an HTTP or HTTPS URL.\n    \"\"\"\n\n    def __init__(self, url):\n        self._url = url\n\n    @property\n    def url(self):\n        \"\"\"\n        The HTTP/S URL referring to the dataset source location.\n\n        :return: The HTTP/S URL referring to the dataset source location.\n        \"\"\"\n        return self._url\n\n    @staticmethod\n    def _get_source_type() -> str:\n        return \"http\"\n\n    def _extract_filename(self, response) -> str:\n        \"\"\"\n        Extracts a filename from the Content-Disposition header or the URL's path.\n        \"\"\"\n        if content_disposition := response.headers.get(\"Content-Disposition\"):\n            for match in re.finditer(r\"filename=(.+)\", content_disposition):\n                filename = match[1].strip(\"'\\\"\")\n                if _is_path(filename):\n                    raise MlflowException.invalid_parameter_value(\n                        f\"Invalid filename in Content-Disposition header: {filename}. \"\n                        \"It must be a file name, not a path.\"\n                    )\n                return filename\n\n        # Extract basename from URL if no valid filename in Content-Disposition\n        return os.path.basename(urlparse(self.url).path)\n\n    def load(self, dst_path=None) -> str:\n        \"\"\"\n        Downloads the dataset source to the local filesystem.\n\n        :param dst_path: Path of the local filesystem destination directory to which to download the\n                         dataset source. If the directory does not exist, it is created. If\n                         unspecified, the dataset source is downloaded to a new uniquely-named\n                         directory on the local filesystem.\n        :return: The path to the downloaded dataset source on the local filesystem.\n        \"\"\"\n        resp = cloud_storage_http_request(\n            method=\"GET\",\n            url=self.url,\n            stream=True,\n        )\n        augmented_raise_for_status(resp)\n\n        basename = self._extract_filename(resp)\n\n        if not basename:\n            basename = \"dataset_source\"\n\n        if dst_path is None:\n            dst_path = create_tmp_dir()\n\n        dst_path = os.path.join(dst_path, basename)\n        with open(dst_path, \"wb\") as f:\n            chunk_size = 1024 * 1024  # 1 MB\n            for chunk in resp.iter_content(chunk_size=chunk_size):\n                f.write(chunk)\n\n        return dst_path\n\n    @staticmethod\n    def _can_resolve(raw_source: Any) -> bool:\n        \"\"\"\n        :param raw_source: The raw source, e.g. a string like \"http://mysite/mydata.tar.gz\".\n        :return: True if this DatsetSource can resolve the raw source, False otherwise.\n        \"\"\"\n        if not isinstance(raw_source, str):\n            return False\n\n        try:\n            parsed_source = urlparse(str(raw_source))\n            return parsed_source.scheme in [\"http\", \"https\"]\n        except Exception:\n            return False\n\n    @classmethod\n    def _resolve(cls, raw_source: Any) -> \"HTTPDatasetSource\":\n        \"\"\"\n        :param raw_source: The raw source, e.g. a string like \"http://mysite/mydata.tar.gz\".\n        \"\"\"\n        return HTTPDatasetSource(raw_source)\n\n    def _to_dict(self) -> Dict[Any, Any]:\n        \"\"\"\n        :return: A JSON-compatible dictionary representation of the HTTPDatasetSource.\n        \"\"\"\n        return {\n            \"url\": self.url,\n        }\n\n    @classmethod\n    def _from_dict(cls, source_dict: Dict[Any, Any]) -> \"HTTPDatasetSource\":\n        \"\"\"\n        :param source_dict: A dictionary representation of the HTTPDatasetSource.\n        \"\"\"\n        url = source_dict.get(\"url\")\n        if url is None:\n            raise MlflowException(\n                'Failed to parse HTTPDatasetSource. Missing expected key: \"url\"',\n                INVALID_PARAMETER_VALUE,\n            )\n\n        return cls(url=url)\n", "import json\nimport os\nfrom unittest import mock\n\nimport pandas as pd\nimport pytest\n\nfrom mlflow.data.dataset_source_registry import get_dataset_source_from_json, resolve_dataset_source\nfrom mlflow.data.http_dataset_source import HTTPDatasetSource\nfrom mlflow.exceptions import MlflowException\nfrom mlflow.utils.os import is_windows\nfrom mlflow.utils.rest_utils import cloud_storage_http_request\n\n\ndef test_source_to_and_from_json():\n    url = \"http://mywebsite.com/path/to/my/dataset.txt\"\n    source = HTTPDatasetSource(url)\n    assert source.to_json() == json.dumps({\"url\": url})\n\n    reloaded_source = get_dataset_source_from_json(\n        source.to_json(), source_type=source._get_source_type()\n    )\n    assert isinstance(reloaded_source, HTTPDatasetSource)\n    assert type(source) == type(reloaded_source)\n    assert source.url == reloaded_source.url == url\n\n\ndef test_http_dataset_source_is_registered_and_resolvable():\n    source1 = resolve_dataset_source(\n        \"http://mywebsite.com/path/to/my/dataset.txt\", candidate_sources=[HTTPDatasetSource]\n    )\n    assert isinstance(source1, HTTPDatasetSource)\n    assert source1.url == \"http://mywebsite.com/path/to/my/dataset.txt\"\n\n    source2 = resolve_dataset_source(\n        \"https://otherwebsite.net\", candidate_sources=[HTTPDatasetSource]\n    )\n    assert isinstance(source2, HTTPDatasetSource)\n    assert source2.url == \"https://otherwebsite.net\"\n\n    with pytest.raises(MlflowException, match=\"Could not find a source information resolver\"):\n        resolve_dataset_source(\"s3://mybucket\", candidate_sources=[HTTPDatasetSource])\n\n    with pytest.raises(MlflowException, match=\"Could not find a source information resolver\"):\n        resolve_dataset_source(\"otherscheme://mybucket\", candidate_sources=[HTTPDatasetSource])\n\n    with pytest.raises(MlflowException, match=\"Could not find a source information resolver\"):\n        resolve_dataset_source(\"htp://mybucket\", candidate_sources=[HTTPDatasetSource])\n\n\ndef test_source_load(tmp_path):\n    source1 = HTTPDatasetSource(\n        \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv\"\n    )\n\n    loaded1 = source1.load()\n    parsed1 = pd.read_csv(loaded1, sep=\";\")\n    # Verify that the expected data was downloaded by checking for an expected column and asserting\n    # that several rows are present\n    assert \"fixed acidity\" in parsed1.columns\n    assert len(parsed1) > 10\n\n    loaded2 = source1.load(dst_path=tmp_path)\n    assert loaded2 == str(tmp_path / \"winequality-red.csv\")\n    parsed2 = pd.read_csv(loaded2, sep=\";\")\n    # Verify that the expected data was downloaded by checking for an expected column and asserting\n    # that several rows are present\n    assert \"fixed acidity\" in parsed2.columns\n    assert len(parsed1) > 10\n\n    source2 = HTTPDatasetSource(\n        \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv#foo?query=param\"\n    )\n    loaded3 = source2.load(dst_path=tmp_path)\n    assert loaded3 == str(tmp_path / \"winequality-red.csv\")\n    parsed3 = pd.read_csv(loaded3, sep=\";\")\n    assert \"fixed acidity\" in parsed3.columns\n    assert len(parsed1) > 10\n\n    source3 = HTTPDatasetSource(\"https://github.com/\")\n    loaded4 = source3.load()\n    assert os.path.exists(loaded4)\n    assert os.path.basename(loaded4) == \"dataset_source\"\n\n    source4 = HTTPDatasetSource(\"https://github.com\")\n    loaded5 = source4.load()\n    assert os.path.exists(loaded5)\n    assert os.path.basename(loaded5) == \"dataset_source\"\n\n    def cloud_storage_http_request_with_fast_fail(*args, **kwargs):\n        kwargs[\"max_retries\"] = 1\n        kwargs[\"timeout\"] = 5\n        return cloud_storage_http_request(*args, **kwargs)\n\n    source5 = HTTPDatasetSource(\"https://nonexistentwebsitebuiltbythemlflowteam112312.com\")\n    with mock.patch(\n        \"mlflow.data.http_dataset_source.cloud_storage_http_request\",\n        side_effect=cloud_storage_http_request_with_fast_fail,\n    ), pytest.raises(Exception, match=\"Max retries exceeded with url\"):\n        source5.load()\n\n\n@pytest.mark.parametrize(\n    (\"attachment_filename\", \"expected_filename\"),\n    [\n        (\"testfile.txt\", \"testfile.txt\"),\n        ('\"testfile.txt\"', \"testfile.txt\"),\n        (\"'testfile.txt'\", \"testfile.txt\"),\n        (None, \"winequality-red.csv\"),\n    ],\n)\ndef test_source_load_with_content_disposition_header(attachment_filename, expected_filename):\n    def download_with_mock_content_disposition_headers(*args, **kwargs):\n        response = cloud_storage_http_request(*args, **kwargs)\n        if attachment_filename is not None:\n            response.headers[\"Content-Disposition\"] = f\"attachment; filename={attachment_filename}\"\n        else:\n            response.headers[\"Content-Disposition\"] = \"attachment\"\n        return response\n\n    with mock.patch(\n        \"mlflow.data.http_dataset_source.cloud_storage_http_request\",\n        side_effect=download_with_mock_content_disposition_headers,\n    ):\n        source = HTTPDatasetSource(\n            \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv\"\n        )\n        source.load()\n        loaded = source.load()\n        assert os.path.exists(loaded)\n        assert os.path.basename(loaded) == expected_filename\n\n\n@pytest.mark.parametrize(\n    \"filename\",\n    [\n        \"/foo/bar.txt\",\n        \"./foo/bar.txt\",\n        \"../foo/bar.txt\",\n        \"foo/bar.txt\",\n    ],\n)\ndef test_source_load_with_content_disposition_header_invalid_filename(filename):\n    def download_with_mock_content_disposition_headers(*args, **kwargs):\n        response = cloud_storage_http_request(*args, **kwargs)\n        response.headers[\"Content-Disposition\"] = f\"attachment; filename={filename}\"\n        return response\n\n    with mock.patch(\n        \"mlflow.data.http_dataset_source.cloud_storage_http_request\",\n        side_effect=download_with_mock_content_disposition_headers,\n    ):\n        source = HTTPDatasetSource(\n            \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv\"\n        )\n\n        with pytest.raises(MlflowException, match=\"Invalid filename in Content-Disposition header\"):\n            source.load()\n\n\n@pytest.mark.skipif(not is_windows(), reason=\"This test only passes on Windows\")\n@pytest.mark.parametrize(\n    \"filename\",\n    [\n        r\"..\\..\\poc.txt\",\n        r\"Users\\User\\poc.txt\",\n    ],\n)\ndef test_source_load_with_content_disposition_header_invalid_filename_windows(filename):\n    def download_with_mock_content_disposition_headers(*args, **kwargs):\n        response = cloud_storage_http_request(*args, **kwargs)\n        response.headers = {\"Content-Disposition\": f\"attachment; filename={filename}\"}\n        return response\n\n    with mock.patch(\n        \"mlflow.data.http_dataset_source.cloud_storage_http_request\",\n        side_effect=download_with_mock_content_disposition_headers,\n    ):\n        source = HTTPDatasetSource(\n            \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv\"\n        )\n\n        # Expect an MlflowException for invalid filenames\n        with pytest.raises(MlflowException, match=\"Invalid filename in Content-Disposition header\"):\n            source.load()\n"], "filenames": ["mlflow/data/http_dataset_source.py", "tests/data/test_http_dataset_source.py"], "buggy_code_start_loc": [2, 10], "buggy_code_end_loc": [76, 157], "fixing_code_start_loc": [1, 11], "fixing_code_end_loc": [80, 186], "type": "CWE-22", "message": "Path Traversal in GitHub repository mlflow/mlflow prior to 2.9.2.", "other": {"cve": {"id": "CVE-2023-6753", "sourceIdentifier": "security@huntr.dev", "published": "2023-12-13T00:15:07.330", "lastModified": "2023-12-15T18:39:14.077", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Path Traversal in GitHub repository mlflow/mlflow prior to 2.9.2."}, {"lang": "es", "value": "Path traversal en el repositorio de GitHub mlflow/mlflow anterior a 2.9.2."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.8, "impactScore": 5.9}], "cvssMetricV30": [{"source": "security@huntr.dev", "type": "Secondary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "CHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.6, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 2.8, "impactScore": 6.0}]}, "weaknesses": [{"source": "security@huntr.dev", "type": "Primary", "description": [{"lang": "en", "value": "CWE-22"}]}], "configurations": [{"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:lfprojects:mlflow:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.9.2", "matchCriteriaId": "6B5585E2-CC70-4BED-AA89-B791F081ACFC"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:o:microsoft:windows:-:*:*:*:*:*:*:*", "matchCriteriaId": "A2572D17-1DE6-457B-99CC-64AFD54487EA"}]}]}], "references": [{"url": "https://github.com/mlflow/mlflow/commit/1c6309f884798fbf56017a3cc808016869ee8de4", "source": "security@huntr.dev", "tags": ["Patch"]}, {"url": "https://huntr.com/bounties/b397b83a-527a-47e7-b912-a12a17a6cfb4", "source": "security@huntr.dev", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/mlflow/mlflow/commit/1c6309f884798fbf56017a3cc808016869ee8de4"}}
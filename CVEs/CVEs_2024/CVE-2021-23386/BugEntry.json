{"buggy_code": ["'use strict'\n\nconst types = require('./types')\nconst rcodes = require('./rcodes')\nconst opcodes = require('./opcodes')\nconst classes = require('./classes')\nconst optioncodes = require('./optioncodes')\nconst ip = require('ip')\n\nconst QUERY_FLAG = 0\nconst RESPONSE_FLAG = 1 << 15\nconst FLUSH_MASK = 1 << 15\nconst NOT_FLUSH_MASK = ~FLUSH_MASK\nconst QU_MASK = 1 << 15\nconst NOT_QU_MASK = ~QU_MASK\n\nconst name = exports.txt = exports.name = {}\n\nname.encode = function (str, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(name.encodingLength(str))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  // strip leading and trailing .\n  const n = str.replace(/^\\.|\\.$/gm, '')\n  if (n.length) {\n    const list = n.split('.')\n\n    for (let i = 0; i < list.length; i++) {\n      const len = buf.write(list[i], offset + 1)\n      buf[offset] = len\n      offset += len + 1\n    }\n  }\n\n  buf[offset++] = 0\n\n  name.encode.bytes = offset - oldOffset\n  return buf\n}\n\nname.encode.bytes = 0\n\nname.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const list = []\n  const oldOffset = offset\n  let len = buf[offset++]\n\n  if (len === 0) {\n    name.decode.bytes = 1\n    return '.'\n  }\n  if (len >= 0xc0) {\n    const res = name.decode(buf, buf.readUInt16BE(offset - 1) - 0xc000)\n    name.decode.bytes = 2\n    return res\n  }\n\n  while (len) {\n    if (len >= 0xc0) {\n      list.push(name.decode(buf, buf.readUInt16BE(offset - 1) - 0xc000))\n      offset++\n      break\n    }\n\n    list.push(buf.toString('utf-8', offset, offset + len))\n    offset += len\n    len = buf[offset++]\n  }\n\n  name.decode.bytes = offset - oldOffset\n  return list.join('.')\n}\n\nname.decode.bytes = 0\n\nname.encodingLength = function (n) {\n  if (n === '.') return 1\n  return Buffer.byteLength(n) + 2\n}\n\nconst string = {}\n\nstring.encode = function (s, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(string.encodingLength(s))\n  if (!offset) offset = 0\n\n  const len = buf.write(s, offset + 1)\n  buf[offset] = len\n  string.encode.bytes = len + 1\n  return buf\n}\n\nstring.encode.bytes = 0\n\nstring.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const len = buf[offset]\n  const s = buf.toString('utf-8', offset + 1, offset + 1 + len)\n  string.decode.bytes = len + 1\n  return s\n}\n\nstring.decode.bytes = 0\n\nstring.encodingLength = function (s) {\n  return Buffer.byteLength(s) + 1\n}\n\nconst header = {}\n\nheader.encode = function (h, buf, offset) {\n  if (!buf) buf = header.encodingLength(h)\n  if (!offset) offset = 0\n\n  const flags = (h.flags || 0) & 32767\n  const type = h.type === 'response' ? RESPONSE_FLAG : QUERY_FLAG\n\n  buf.writeUInt16BE(h.id || 0, offset)\n  buf.writeUInt16BE(flags | type, offset + 2)\n  buf.writeUInt16BE(h.questions.length, offset + 4)\n  buf.writeUInt16BE(h.answers.length, offset + 6)\n  buf.writeUInt16BE(h.authorities.length, offset + 8)\n  buf.writeUInt16BE(h.additionals.length, offset + 10)\n\n  return buf\n}\n\nheader.encode.bytes = 12\n\nheader.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  if (buf.length < 12) throw new Error('Header must be 12 bytes')\n  const flags = buf.readUInt16BE(offset + 2)\n\n  return {\n    id: buf.readUInt16BE(offset),\n    type: flags & RESPONSE_FLAG ? 'response' : 'query',\n    flags: flags & 32767,\n    flag_qr: ((flags >> 15) & 0x1) === 1,\n    opcode: opcodes.toString((flags >> 11) & 0xf),\n    flag_aa: ((flags >> 10) & 0x1) === 1,\n    flag_tc: ((flags >> 9) & 0x1) === 1,\n    flag_rd: ((flags >> 8) & 0x1) === 1,\n    flag_ra: ((flags >> 7) & 0x1) === 1,\n    flag_z: ((flags >> 6) & 0x1) === 1,\n    flag_ad: ((flags >> 5) & 0x1) === 1,\n    flag_cd: ((flags >> 4) & 0x1) === 1,\n    rcode: rcodes.toString(flags & 0xf),\n    questions: new Array(buf.readUInt16BE(offset + 4)),\n    answers: new Array(buf.readUInt16BE(offset + 6)),\n    authorities: new Array(buf.readUInt16BE(offset + 8)),\n    additionals: new Array(buf.readUInt16BE(offset + 10))\n  }\n}\n\nheader.decode.bytes = 12\n\nheader.encodingLength = function () {\n  return 12\n}\n\nconst runknown = exports.unknown = {}\n\nrunknown.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(runknown.encodingLength(data))\n  if (!offset) offset = 0\n\n  buf.writeUInt16BE(data.length, offset)\n  data.copy(buf, offset + 2)\n\n  runknown.encode.bytes = data.length + 2\n  return buf\n}\n\nrunknown.encode.bytes = 0\n\nrunknown.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const len = buf.readUInt16BE(offset)\n  const data = buf.slice(offset + 2, offset + 2 + len)\n  runknown.decode.bytes = len + 2\n  return data\n}\n\nrunknown.decode.bytes = 0\n\nrunknown.encodingLength = function (data) {\n  return data.length + 2\n}\n\nconst rns = exports.ns = {}\n\nrns.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rns.encodingLength(data))\n  if (!offset) offset = 0\n\n  name.encode(data, buf, offset + 2)\n  buf.writeUInt16BE(name.encode.bytes, offset)\n  rns.encode.bytes = name.encode.bytes + 2\n  return buf\n}\n\nrns.encode.bytes = 0\n\nrns.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const len = buf.readUInt16BE(offset)\n  const dd = name.decode(buf, offset + 2)\n\n  rns.decode.bytes = len + 2\n  return dd\n}\n\nrns.decode.bytes = 0\n\nrns.encodingLength = function (data) {\n  return name.encodingLength(data) + 2\n}\n\nconst rsoa = exports.soa = {}\n\nrsoa.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rsoa.encodingLength(data))\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n  offset += 2\n  name.encode(data.mname, buf, offset)\n  offset += name.encode.bytes\n  name.encode(data.rname, buf, offset)\n  offset += name.encode.bytes\n  buf.writeUInt32BE(data.serial || 0, offset)\n  offset += 4\n  buf.writeUInt32BE(data.refresh || 0, offset)\n  offset += 4\n  buf.writeUInt32BE(data.retry || 0, offset)\n  offset += 4\n  buf.writeUInt32BE(data.expire || 0, offset)\n  offset += 4\n  buf.writeUInt32BE(data.minimum || 0, offset)\n  offset += 4\n\n  buf.writeUInt16BE(offset - oldOffset - 2, oldOffset)\n  rsoa.encode.bytes = offset - oldOffset\n  return buf\n}\n\nrsoa.encode.bytes = 0\n\nrsoa.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n\n  const data = {}\n  offset += 2\n  data.mname = name.decode(buf, offset)\n  offset += name.decode.bytes\n  data.rname = name.decode(buf, offset)\n  offset += name.decode.bytes\n  data.serial = buf.readUInt32BE(offset)\n  offset += 4\n  data.refresh = buf.readUInt32BE(offset)\n  offset += 4\n  data.retry = buf.readUInt32BE(offset)\n  offset += 4\n  data.expire = buf.readUInt32BE(offset)\n  offset += 4\n  data.minimum = buf.readUInt32BE(offset)\n  offset += 4\n\n  rsoa.decode.bytes = offset - oldOffset\n  return data\n}\n\nrsoa.decode.bytes = 0\n\nrsoa.encodingLength = function (data) {\n  return 22 + name.encodingLength(data.mname) + name.encodingLength(data.rname)\n}\n\nconst rtxt = exports.txt = {}\n\nrtxt.encode = function (data, buf, offset) {\n  if (!Array.isArray(data)) data = [data]\n  for (let i = 0; i < data.length; i++) {\n    if (typeof data[i] === 'string') {\n      data[i] = Buffer.from(data[i])\n    }\n    if (!Buffer.isBuffer(data[i])) {\n      throw new Error('Must be a Buffer')\n    }\n  }\n\n  if (!buf) buf = Buffer.allocUnsafe(rtxt.encodingLength(data))\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n  offset += 2\n\n  data.forEach(function (d) {\n    buf[offset++] = d.length\n    d.copy(buf, offset, 0, d.length)\n    offset += d.length\n  })\n\n  buf.writeUInt16BE(offset - oldOffset - 2, oldOffset)\n  rtxt.encode.bytes = offset - oldOffset\n  return buf\n}\n\nrtxt.encode.bytes = 0\n\nrtxt.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n  let remaining = buf.readUInt16BE(offset)\n  offset += 2\n\n  let data = []\n  while (remaining > 0) {\n    const len = buf[offset++]\n    --remaining\n    if (remaining < len) {\n      throw new Error('Buffer overflow')\n    }\n    data.push(buf.slice(offset, offset + len))\n    offset += len\n    remaining -= len\n  }\n\n  rtxt.decode.bytes = offset - oldOffset\n  return data\n}\n\nrtxt.decode.bytes = 0\n\nrtxt.encodingLength = function (data) {\n  if (!Array.isArray(data)) data = [data]\n  let length = 2\n  data.forEach(function (buf) {\n    if (typeof buf === 'string') {\n      length += Buffer.byteLength(buf) + 1\n    } else {\n      length += buf.length + 1\n    }\n  })\n  return length\n}\n\nconst rnull = exports.null = {}\n\nrnull.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rnull.encodingLength(data))\n  if (!offset) offset = 0\n\n  if (typeof data === 'string') data = Buffer.from(data)\n  if (!data) data = Buffer.allocUnsafe(0)\n\n  const oldOffset = offset\n  offset += 2\n\n  const len = data.length\n  data.copy(buf, offset, 0, len)\n  offset += len\n\n  buf.writeUInt16BE(offset - oldOffset - 2, oldOffset)\n  rnull.encode.bytes = offset - oldOffset\n  return buf\n}\n\nrnull.encode.bytes = 0\n\nrnull.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n  const len = buf.readUInt16BE(offset)\n\n  offset += 2\n\n  const data = buf.slice(offset, offset + len)\n  offset += len\n\n  rnull.decode.bytes = offset - oldOffset\n  return data\n}\n\nrnull.decode.bytes = 0\n\nrnull.encodingLength = function (data) {\n  if (!data) return 2\n  return (Buffer.isBuffer(data) ? data.length : Buffer.byteLength(data)) + 2\n}\n\nconst rhinfo = exports.hinfo = {}\n\nrhinfo.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rhinfo.encodingLength(data))\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n  offset += 2\n  string.encode(data.cpu, buf, offset)\n  offset += string.encode.bytes\n  string.encode(data.os, buf, offset)\n  offset += string.encode.bytes\n  buf.writeUInt16BE(offset - oldOffset - 2, oldOffset)\n  rhinfo.encode.bytes = offset - oldOffset\n  return buf\n}\n\nrhinfo.encode.bytes = 0\n\nrhinfo.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n\n  const data = {}\n  offset += 2\n  data.cpu = string.decode(buf, offset)\n  offset += string.decode.bytes\n  data.os = string.decode(buf, offset)\n  offset += string.decode.bytes\n  rhinfo.decode.bytes = offset - oldOffset\n  return data\n}\n\nrhinfo.decode.bytes = 0\n\nrhinfo.encodingLength = function (data) {\n  return string.encodingLength(data.cpu) + string.encodingLength(data.os) + 2\n}\n\nconst rptr = exports.ptr = {}\nconst rcname = exports.cname = rptr\nconst rdname = exports.dname = rptr\n\nrptr.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rptr.encodingLength(data))\n  if (!offset) offset = 0\n\n  name.encode(data, buf, offset + 2)\n  buf.writeUInt16BE(name.encode.bytes, offset)\n  rptr.encode.bytes = name.encode.bytes + 2\n  return buf\n}\n\nrptr.encode.bytes = 0\n\nrptr.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const data = name.decode(buf, offset + 2)\n  rptr.decode.bytes = name.decode.bytes + 2\n  return data\n}\n\nrptr.decode.bytes = 0\n\nrptr.encodingLength = function (data) {\n  return name.encodingLength(data) + 2\n}\n\nconst rsrv = exports.srv = {}\n\nrsrv.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rsrv.encodingLength(data))\n  if (!offset) offset = 0\n\n  buf.writeUInt16BE(data.priority || 0, offset + 2)\n  buf.writeUInt16BE(data.weight || 0, offset + 4)\n  buf.writeUInt16BE(data.port || 0, offset + 6)\n  name.encode(data.target, buf, offset + 8)\n\n  const len = name.encode.bytes + 6\n  buf.writeUInt16BE(len, offset)\n\n  rsrv.encode.bytes = len + 2\n  return buf\n}\n\nrsrv.encode.bytes = 0\n\nrsrv.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const len = buf.readUInt16BE(offset)\n\n  const data = {}\n  data.priority = buf.readUInt16BE(offset + 2)\n  data.weight = buf.readUInt16BE(offset + 4)\n  data.port = buf.readUInt16BE(offset + 6)\n  data.target = name.decode(buf, offset + 8)\n\n  rsrv.decode.bytes = len + 2\n  return data\n}\n\nrsrv.decode.bytes = 0\n\nrsrv.encodingLength = function (data) {\n  return 8 + name.encodingLength(data.target)\n}\n\nconst rcaa = exports.caa = {}\n\nrcaa.ISSUER_CRITICAL = 1 << 7\n\nrcaa.encode = function (data, buf, offset) {\n  const len = rcaa.encodingLength(data)\n\n  if (!buf) buf = Buffer.allocUnsafe(rcaa.encodingLength(data))\n  if (!offset) offset = 0\n\n  if (data.issuerCritical) {\n    data.flags = rcaa.ISSUER_CRITICAL\n  }\n\n  buf.writeUInt16BE(len - 2, offset)\n  offset += 2\n  buf.writeUInt8(data.flags || 0, offset)\n  offset += 1\n  string.encode(data.tag, buf, offset)\n  offset += string.encode.bytes\n  buf.write(data.value, offset)\n  offset += Buffer.byteLength(data.value)\n\n  rcaa.encode.bytes = len\n  return buf\n}\n\nrcaa.encode.bytes = 0\n\nrcaa.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const len = buf.readUInt16BE(offset)\n  offset += 2\n\n  const oldOffset = offset\n  const data = {}\n  data.flags = buf.readUInt8(offset)\n  offset += 1\n  data.tag = string.decode(buf, offset)\n  offset += string.decode.bytes\n  data.value = buf.toString('utf-8', offset, oldOffset + len)\n\n  data.issuerCritical = !!(data.flags & rcaa.ISSUER_CRITICAL)\n\n  rcaa.decode.bytes = len + 2\n\n  return data\n}\n\nrcaa.decode.bytes = 0\n\nrcaa.encodingLength = function (data) {\n  return string.encodingLength(data.tag) + string.encodingLength(data.value) + 2\n}\n\nconst rmx = exports.mx = {}\n\nrmx.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rmx.encodingLength(data))\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n  offset += 2\n  buf.writeUInt16BE(data.preference || 0, offset)\n  offset += 2\n  name.encode(data.exchange, buf, offset)\n  offset += name.encode.bytes\n\n  buf.writeUInt16BE(offset - oldOffset - 2, oldOffset)\n  rmx.encode.bytes = offset - oldOffset\n  return buf\n}\n\nrmx.encode.bytes = 0\n\nrmx.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n\n  const data = {}\n  offset += 2\n  data.preference = buf.readUInt16BE(offset)\n  offset += 2\n  data.exchange = name.decode(buf, offset)\n  offset += name.decode.bytes\n\n  rmx.decode.bytes = offset - oldOffset\n  return data\n}\n\nrmx.encodingLength = function (data) {\n  return 4 + name.encodingLength(data.exchange)\n}\n\nconst ra = exports.a = {}\n\nra.encode = function (host, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(ra.encodingLength(host))\n  if (!offset) offset = 0\n\n  buf.writeUInt16BE(4, offset)\n  offset += 2\n  ip.toBuffer(host, buf, offset)\n  ra.encode.bytes = 6\n  return buf\n}\n\nra.encode.bytes = 0\n\nra.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  offset += 2\n  const host = ip.toString(buf, offset, 4)\n  ra.decode.bytes = 6\n  return host\n}\n\nra.decode.bytes = 0\n\nra.encodingLength = function () {\n  return 6\n}\n\nconst raaaa = exports.aaaa = {}\n\nraaaa.encode = function (host, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(raaaa.encodingLength(host))\n  if (!offset) offset = 0\n\n  buf.writeUInt16BE(16, offset)\n  offset += 2\n  ip.toBuffer(host, buf, offset)\n  raaaa.encode.bytes = 18\n  return buf\n}\n\nraaaa.encode.bytes = 0\n\nraaaa.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  offset += 2\n  const host = ip.toString(buf, offset, 16)\n  raaaa.decode.bytes = 18\n  return host\n}\n\nraaaa.decode.bytes = 0\n\nraaaa.encodingLength = function () {\n  return 18\n}\n\nconst roption = exports.option = {}\n\nroption.encode = function (option, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(roption.encodingLength(option))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const code = optioncodes.toCode(option.code)\n  buf.writeUInt16BE(code, offset)\n  offset += 2\n  if (option.data) {\n    buf.writeUInt16BE(option.data.length, offset)\n    offset += 2\n    option.data.copy(buf, offset)\n    offset += option.data.length\n  } else {\n    switch (code) {\n      // case 3: NSID.  No encode makes sense.\n      // case 5,6,7: Not implementable\n      case 8: // ECS\n        // note: do IP math before calling\n        const spl = option.sourcePrefixLength || 0\n        const fam = option.family || (ip.isV4Format(option.ip) ? 1 : 2)\n        const ipBuf = ip.toBuffer(option.ip)\n        const ipLen = Math.ceil(spl / 8)\n        buf.writeUInt16BE(ipLen + 4, offset)\n        offset += 2\n        buf.writeUInt16BE(fam, offset)\n        offset += 2\n        buf.writeUInt8(spl, offset++)\n        buf.writeUInt8(option.scopePrefixLength || 0, offset++)\n\n        ipBuf.copy(buf, offset, 0, ipLen)\n        offset += ipLen\n        break\n      // case 9: EXPIRE (experimental)\n      // case 10: COOKIE.  No encode makes sense.\n      case 11: // KEEP-ALIVE\n        if (option.timeout) {\n          buf.writeUInt16BE(2, offset)\n          offset += 2\n          buf.writeUInt16BE(option.timeout, offset)\n          offset += 2\n        } else {\n          buf.writeUInt16BE(0, offset)\n          offset += 2\n        }\n        break\n      case 12: // PADDING\n        const len = option.length || 0\n        buf.writeUInt16BE(len, offset)\n        offset += 2\n        buf.fill(0, offset, offset + len)\n        offset += len\n        break\n      // case 13:  CHAIN.  Experimental.\n      case 14: // KEY-TAG\n        const tagsLen = option.tags.length * 2\n        buf.writeUInt16BE(tagsLen, offset)\n        offset += 2\n        for (const tag of option.tags) {\n          buf.writeUInt16BE(tag, offset)\n          offset += 2\n        }\n        break\n      default:\n        throw new Error(`Unknown roption code: ${option.code}`)\n    }\n  }\n\n  roption.encode.bytes = offset - oldOffset\n  return buf\n}\n\nroption.encode.bytes = 0\n\nroption.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const option = {}\n  option.code = buf.readUInt16BE(offset)\n  option.type = optioncodes.toString(option.code)\n  offset += 2\n  const len = buf.readUInt16BE(offset)\n  offset += 2\n  option.data = buf.slice(offset, offset + len)\n  switch (option.code) {\n    // case 3: NSID.  No decode makes sense.\n    case 8: // ECS\n      option.family = buf.readUInt16BE(offset)\n      offset += 2\n      option.sourcePrefixLength = buf.readUInt8(offset++)\n      option.scopePrefixLength = buf.readUInt8(offset++)\n      const padded = Buffer.alloc((option.family === 1) ? 4 : 16)\n      buf.copy(padded, 0, offset, offset + len - 4)\n      option.ip = ip.toString(padded)\n      break\n    // case 12: Padding.  No decode makes sense.\n    case 11: // KEEP-ALIVE\n      if (len > 0) {\n        option.timeout = buf.readUInt16BE(offset)\n        offset += 2\n      }\n      break\n    case 14:\n      option.tags = []\n      for (let i = 0; i < len; i += 2) {\n        option.tags.push(buf.readUInt16BE(offset))\n        offset += 2\n      }\n    // don't worry about default.  caller will use data if desired\n  }\n\n  roption.decode.bytes = len + 4\n  return option\n}\n\nroption.decode.bytes = 0\n\nroption.encodingLength = function (option) {\n  if (option.data) {\n    return option.data.length + 4\n  }\n  const code = optioncodes.toCode(option.code)\n  switch (code) {\n    case 8: // ECS\n      const spl = option.sourcePrefixLength || 0\n      return Math.ceil(spl / 8) + 8\n    case 11: // KEEP-ALIVE\n      return (typeof option.timeout === 'number') ? 6 : 4\n    case 12: // PADDING\n      return option.length + 4\n    case 14: // KEY-TAG\n      return 4 + (option.tags.length * 2)\n  }\n  throw new Error(`Unknown roption code: ${option.code}`)\n}\n\nconst ropt = exports.opt = {}\n\nropt.encode = function (options, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(ropt.encodingLength(options))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const rdlen = encodingLengthList(options, roption)\n  buf.writeUInt16BE(rdlen, offset)\n  offset = encodeList(options, roption, buf, offset + 2)\n\n  ropt.encode.bytes = offset - oldOffset\n  return buf\n}\n\nropt.encode.bytes = 0\n\nropt.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const options = []\n  let rdlen = buf.readUInt16BE(offset)\n  offset += 2\n  let o = 0\n  while (rdlen > 0) {\n    options[o++] = roption.decode(buf, offset)\n    offset += roption.decode.bytes\n    rdlen -= roption.decode.bytes\n  }\n  ropt.decode.bytes = offset - oldOffset\n  return options\n}\n\nropt.decode.bytes = 0\n\nropt.encodingLength = function (options) {\n  return 2 + encodingLengthList(options || [], roption)\n}\n\nconst rdnskey = exports.dnskey = {}\n\nrdnskey.PROTOCOL_DNSSEC = 3\nrdnskey.ZONE_KEY = 0x80\nrdnskey.SECURE_ENTRYPOINT = 0x8000\n\nrdnskey.encode = function (key, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rdnskey.encodingLength(key))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const keydata = key.key\n  if (!Buffer.isBuffer(keydata)) {\n    throw new Error('Key must be a Buffer')\n  }\n\n  offset += 2 // Leave space for length\n  buf.writeUInt16BE(key.flags, offset)\n  offset += 2\n  buf.writeUInt8(rdnskey.PROTOCOL_DNSSEC, offset)\n  offset += 1\n  buf.writeUInt8(key.algorithm, offset)\n  offset += 1\n  keydata.copy(buf, offset, 0, keydata.length)\n  offset += keydata.length\n\n  rdnskey.encode.bytes = offset - oldOffset\n  buf.writeUInt16BE(rdnskey.encode.bytes - 2, oldOffset)\n  return buf\n}\n\nrdnskey.encode.bytes = 0\n\nrdnskey.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  var key = {}\n  var length = buf.readUInt16BE(offset)\n  offset += 2\n  key.flags = buf.readUInt16BE(offset)\n  offset += 2\n  if (buf.readUInt8(offset) !== rdnskey.PROTOCOL_DNSSEC) {\n    throw new Error('Protocol must be 3')\n  }\n  offset += 1\n  key.algorithm = buf.readUInt8(offset)\n  offset += 1\n  key.key = buf.slice(offset, oldOffset + length + 2)\n  offset += key.key.length\n  rdnskey.decode.bytes = offset - oldOffset\n  return key\n}\n\nrdnskey.decode.bytes = 0\n\nrdnskey.encodingLength = function (key) {\n  return 6 + Buffer.byteLength(key.key)\n}\n\nconst rrrsig = exports.rrsig = {}\n\nrrrsig.encode = function (sig, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rrrsig.encodingLength(sig))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const signature = sig.signature\n  if (!Buffer.isBuffer(signature)) {\n    throw new Error('Signature must be a Buffer')\n  }\n\n  offset += 2 // Leave space for length\n  buf.writeUInt16BE(types.toType(sig.typeCovered), offset)\n  offset += 2\n  buf.writeUInt8(sig.algorithm, offset)\n  offset += 1\n  buf.writeUInt8(sig.labels, offset)\n  offset += 1\n  buf.writeUInt32BE(sig.originalTTL, offset)\n  offset += 4\n  buf.writeUInt32BE(sig.expiration, offset)\n  offset += 4\n  buf.writeUInt32BE(sig.inception, offset)\n  offset += 4\n  buf.writeUInt16BE(sig.keyTag, offset)\n  offset += 2\n  name.encode(sig.signersName, buf, offset)\n  offset += name.encode.bytes\n  signature.copy(buf, offset, 0, signature.length)\n  offset += signature.length\n\n  rrrsig.encode.bytes = offset - oldOffset\n  buf.writeUInt16BE(rrrsig.encode.bytes - 2, oldOffset)\n  return buf\n}\n\nrrrsig.encode.bytes = 0\n\nrrrsig.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  var sig = {}\n  var length = buf.readUInt16BE(offset)\n  offset += 2\n  sig.typeCovered = types.toString(buf.readUInt16BE(offset))\n  offset += 2\n  sig.algorithm = buf.readUInt8(offset)\n  offset += 1\n  sig.labels = buf.readUInt8(offset)\n  offset += 1\n  sig.originalTTL = buf.readUInt32BE(offset)\n  offset += 4\n  sig.expiration = buf.readUInt32BE(offset)\n  offset += 4\n  sig.inception = buf.readUInt32BE(offset)\n  offset += 4\n  sig.keyTag = buf.readUInt16BE(offset)\n  offset += 2\n  sig.signersName = name.decode(buf, offset)\n  offset += name.decode.bytes\n  sig.signature = buf.slice(offset, oldOffset + length + 2)\n  offset += sig.signature.length\n  rrrsig.decode.bytes = offset - oldOffset\n  return sig\n}\n\nrrrsig.decode.bytes = 0\n\nrrrsig.encodingLength = function (sig) {\n  return 20 +\n    name.encodingLength(sig.signersName) +\n    Buffer.byteLength(sig.signature)\n}\n\nconst rrp = exports.rp = {}\n\nrrp.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rrp.encodingLength(data))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  offset += 2 // Leave space for length\n  name.encode(data.mbox || '.', buf, offset)\n  offset += name.encode.bytes\n  name.encode(data.txt || '.', buf, offset)\n  offset += name.encode.bytes\n  rrp.encode.bytes = offset - oldOffset\n  buf.writeUInt16BE(rrp.encode.bytes - 2, oldOffset)\n  return buf\n}\n\nrrp.encode.bytes = 0\n\nrrp.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const data = {}\n  offset += 2\n  data.mbox = name.decode(buf, offset) || '.'\n  offset += name.decode.bytes\n  data.txt = name.decode(buf, offset) || '.'\n  offset += name.decode.bytes\n  rrp.decode.bytes = offset - oldOffset\n  return data\n}\n\nrrp.decode.bytes = 0\n\nrrp.encodingLength = function (data) {\n  return 2 + name.encodingLength(data.mbox || '.') + name.encodingLength(data.txt || '.')\n}\n\nconst typebitmap = {}\n\ntypebitmap.encode = function (typelist, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(typebitmap.encodingLength(typelist))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  var typesByWindow = []\n  for (var i = 0; i < typelist.length; i++) {\n    var typeid = types.toType(typelist[i])\n    if (typesByWindow[typeid >> 8] === undefined) {\n      typesByWindow[typeid >> 8] = []\n    }\n    typesByWindow[typeid >> 8][(typeid >> 3) & 0x1F] |= 1 << (7 - (typeid & 0x7))\n  }\n\n  for (i = 0; i < typesByWindow.length; i++) {\n    if (typesByWindow[i] !== undefined) {\n      var windowBuf = Buffer.from(typesByWindow[i])\n      buf.writeUInt8(i, offset)\n      offset += 1\n      buf.writeUInt8(windowBuf.length, offset)\n      offset += 1\n      windowBuf.copy(buf, offset)\n      offset += windowBuf.length\n    }\n  }\n\n  typebitmap.encode.bytes = offset - oldOffset\n  return buf\n}\n\ntypebitmap.encode.bytes = 0\n\ntypebitmap.decode = function (buf, offset, length) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  var typelist = []\n  while (offset - oldOffset < length) {\n    var window = buf.readUInt8(offset)\n    offset += 1\n    var windowLength = buf.readUInt8(offset)\n    offset += 1\n    for (var i = 0; i < windowLength; i++) {\n      var b = buf.readUInt8(offset + i)\n      for (var j = 0; j < 8; j++) {\n        if (b & (1 << (7 - j))) {\n          var typeid = types.toString((window << 8) | (i << 3) | j)\n          typelist.push(typeid)\n        }\n      }\n    }\n    offset += windowLength\n  }\n\n  typebitmap.decode.bytes = offset - oldOffset\n  return typelist\n}\n\ntypebitmap.decode.bytes = 0\n\ntypebitmap.encodingLength = function (typelist) {\n  var extents = []\n  for (var i = 0; i < typelist.length; i++) {\n    var typeid = types.toType(typelist[i])\n    extents[typeid >> 8] = Math.max(extents[typeid >> 8] || 0, typeid & 0xFF)\n  }\n\n  var len = 0\n  for (i = 0; i < extents.length; i++) {\n    if (extents[i] !== undefined) {\n      len += 2 + Math.ceil((extents[i] + 1) / 8)\n    }\n  }\n\n  return len\n}\n\nconst rnsec = exports.nsec = {}\n\nrnsec.encode = function (record, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rnsec.encodingLength(record))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  offset += 2 // Leave space for length\n  name.encode(record.nextDomain, buf, offset)\n  offset += name.encode.bytes\n  typebitmap.encode(record.rrtypes, buf, offset)\n  offset += typebitmap.encode.bytes\n\n  rnsec.encode.bytes = offset - oldOffset\n  buf.writeUInt16BE(rnsec.encode.bytes - 2, oldOffset)\n  return buf\n}\n\nrnsec.encode.bytes = 0\n\nrnsec.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  var record = {}\n  var length = buf.readUInt16BE(offset)\n  offset += 2\n  record.nextDomain = name.decode(buf, offset)\n  offset += name.decode.bytes\n  record.rrtypes = typebitmap.decode(buf, offset, length - (offset - oldOffset))\n  offset += typebitmap.decode.bytes\n\n  rnsec.decode.bytes = offset - oldOffset\n  return record\n}\n\nrnsec.decode.bytes = 0\n\nrnsec.encodingLength = function (record) {\n  return 2 +\n    name.encodingLength(record.nextDomain) +\n    typebitmap.encodingLength(record.rrtypes)\n}\n\nconst rnsec3 = exports.nsec3 = {}\n\nrnsec3.encode = function (record, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rnsec3.encodingLength(record))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const salt = record.salt\n  if (!Buffer.isBuffer(salt)) {\n    throw new Error('salt must be a Buffer')\n  }\n\n  const nextDomain = record.nextDomain\n  if (!Buffer.isBuffer(nextDomain)) {\n    throw new Error('nextDomain must be a Buffer')\n  }\n\n  offset += 2 // Leave space for length\n  buf.writeUInt8(record.algorithm, offset)\n  offset += 1\n  buf.writeUInt8(record.flags, offset)\n  offset += 1\n  buf.writeUInt16BE(record.iterations, offset)\n  offset += 2\n  buf.writeUInt8(salt.length, offset)\n  offset += 1\n  salt.copy(buf, offset, 0, salt.length)\n  offset += salt.length\n  buf.writeUInt8(nextDomain.length, offset)\n  offset += 1\n  nextDomain.copy(buf, offset, 0, nextDomain.length)\n  offset += nextDomain.length\n  typebitmap.encode(record.rrtypes, buf, offset)\n  offset += typebitmap.encode.bytes\n\n  rnsec3.encode.bytes = offset - oldOffset\n  buf.writeUInt16BE(rnsec3.encode.bytes - 2, oldOffset)\n  return buf\n}\n\nrnsec3.encode.bytes = 0\n\nrnsec3.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  var record = {}\n  var length = buf.readUInt16BE(offset)\n  offset += 2\n  record.algorithm = buf.readUInt8(offset)\n  offset += 1\n  record.flags = buf.readUInt8(offset)\n  offset += 1\n  record.iterations = buf.readUInt16BE(offset)\n  offset += 2\n  const saltLength = buf.readUInt8(offset)\n  offset += 1\n  record.salt = buf.slice(offset, offset + saltLength)\n  offset += saltLength\n  const hashLength = buf.readUInt8(offset)\n  offset += 1\n  record.nextDomain = buf.slice(offset, offset + hashLength)\n  offset += hashLength\n  record.rrtypes = typebitmap.decode(buf, offset, length - (offset - oldOffset))\n  offset += typebitmap.decode.bytes\n\n  rnsec3.decode.bytes = offset - oldOffset\n  return record\n}\n\nrnsec3.decode.bytes = 0\n\nrnsec3.encodingLength = function (record) {\n  return 8 +\n    record.salt.length +\n    record.nextDomain.length +\n    typebitmap.encodingLength(record.rrtypes)\n}\n\nconst rds = exports.ds = {}\n\nrds.encode = function (digest, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rds.encodingLength(digest))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const digestdata = digest.digest\n  if (!Buffer.isBuffer(digestdata)) {\n    throw new Error('Digest must be a Buffer')\n  }\n\n  offset += 2 // Leave space for length\n  buf.writeUInt16BE(digest.keyTag, offset)\n  offset += 2\n  buf.writeUInt8(digest.algorithm, offset)\n  offset += 1\n  buf.writeUInt8(digest.digestType, offset)\n  offset += 1\n  digestdata.copy(buf, offset, 0, digestdata.length)\n  offset += digestdata.length\n\n  rds.encode.bytes = offset - oldOffset\n  buf.writeUInt16BE(rds.encode.bytes - 2, oldOffset)\n  return buf\n}\n\nrds.encode.bytes = 0\n\nrds.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  var digest = {}\n  var length = buf.readUInt16BE(offset)\n  offset += 2\n  digest.keyTag = buf.readUInt16BE(offset)\n  offset += 2\n  digest.algorithm = buf.readUInt8(offset)\n  offset += 1\n  digest.digestType = buf.readUInt8(offset)\n  offset += 1\n  digest.digest = buf.slice(offset, oldOffset + length + 2)\n  offset += digest.digest.length\n  rds.decode.bytes = offset - oldOffset\n  return digest\n}\n\nrds.decode.bytes = 0\n\nrds.encodingLength = function (digest) {\n  return 6 + Buffer.byteLength(digest.digest)\n}\n\nconst renc = exports.record = function (type) {\n  switch (type.toUpperCase()) {\n    case 'A': return ra\n    case 'PTR': return rptr\n    case 'CNAME': return rcname\n    case 'DNAME': return rdname\n    case 'TXT': return rtxt\n    case 'NULL': return rnull\n    case 'AAAA': return raaaa\n    case 'SRV': return rsrv\n    case 'HINFO': return rhinfo\n    case 'CAA': return rcaa\n    case 'NS': return rns\n    case 'SOA': return rsoa\n    case 'MX': return rmx\n    case 'OPT': return ropt\n    case 'DNSKEY': return rdnskey\n    case 'RRSIG': return rrrsig\n    case 'RP': return rrp\n    case 'NSEC': return rnsec\n    case 'NSEC3': return rnsec3\n    case 'DS': return rds\n  }\n  return runknown\n}\n\nconst answer = exports.answer = {}\n\nanswer.encode = function (a, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(answer.encodingLength(a))\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n\n  name.encode(a.name, buf, offset)\n  offset += name.encode.bytes\n\n  buf.writeUInt16BE(types.toType(a.type), offset)\n\n  if (a.type.toUpperCase() === 'OPT') {\n    if (a.name !== '.') {\n      throw new Error('OPT name must be root.')\n    }\n    buf.writeUInt16BE(a.udpPayloadSize || 4096, offset + 2)\n    buf.writeUInt8(a.extendedRcode || 0, offset + 4)\n    buf.writeUInt8(a.ednsVersion || 0, offset + 5)\n    buf.writeUInt16BE(a.flags || 0, offset + 6)\n\n    offset += 8\n    ropt.encode(a.options || [], buf, offset)\n    offset += ropt.encode.bytes\n  } else {\n    let klass = classes.toClass(a.class === undefined ? 'IN' : a.class)\n    if (a.flush) klass |= FLUSH_MASK // the 1st bit of the class is the flush bit\n    buf.writeUInt16BE(klass, offset + 2)\n    buf.writeUInt32BE(a.ttl || 0, offset + 4)\n\n    offset += 8\n    const enc = renc(a.type)\n    enc.encode(a.data, buf, offset)\n    offset += enc.encode.bytes\n  }\n\n  answer.encode.bytes = offset - oldOffset\n  return buf\n}\n\nanswer.encode.bytes = 0\n\nanswer.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const a = {}\n  const oldOffset = offset\n\n  a.name = name.decode(buf, offset)\n  offset += name.decode.bytes\n  a.type = types.toString(buf.readUInt16BE(offset))\n  if (a.type === 'OPT') {\n    a.udpPayloadSize = buf.readUInt16BE(offset + 2)\n    a.extendedRcode = buf.readUInt8(offset + 4)\n    a.ednsVersion = buf.readUInt8(offset + 5)\n    a.flags = buf.readUInt16BE(offset + 6)\n    a.flag_do = ((a.flags >> 15) & 0x1) === 1\n    a.options = ropt.decode(buf, offset + 8)\n    offset += 8 + ropt.decode.bytes\n  } else {\n    const klass = buf.readUInt16BE(offset + 2)\n    a.ttl = buf.readUInt32BE(offset + 4)\n\n    a.class = classes.toString(klass & NOT_FLUSH_MASK)\n    a.flush = !!(klass & FLUSH_MASK)\n\n    const enc = renc(a.type)\n    a.data = enc.decode(buf, offset + 8)\n    offset += 8 + enc.decode.bytes\n  }\n\n  answer.decode.bytes = offset - oldOffset\n  return a\n}\n\nanswer.decode.bytes = 0\n\nanswer.encodingLength = function (a) {\n  const data = (a.data !== null && a.data !== undefined) ? a.data : a.options\n  return name.encodingLength(a.name) + 8 + renc(a.type).encodingLength(data)\n}\n\nconst question = exports.question = {}\n\nquestion.encode = function (q, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(question.encodingLength(q))\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n\n  name.encode(q.name, buf, offset)\n  offset += name.encode.bytes\n\n  buf.writeUInt16BE(types.toType(q.type), offset)\n  offset += 2\n\n  buf.writeUInt16BE(classes.toClass(q.class === undefined ? 'IN' : q.class), offset)\n  offset += 2\n\n  question.encode.bytes = offset - oldOffset\n  return q\n}\n\nquestion.encode.bytes = 0\n\nquestion.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n  const q = {}\n\n  q.name = name.decode(buf, offset)\n  offset += name.decode.bytes\n\n  q.type = types.toString(buf.readUInt16BE(offset))\n  offset += 2\n\n  q.class = classes.toString(buf.readUInt16BE(offset))\n  offset += 2\n\n  const qu = !!(q.class & QU_MASK)\n  if (qu) q.class &= NOT_QU_MASK\n\n  question.decode.bytes = offset - oldOffset\n  return q\n}\n\nquestion.decode.bytes = 0\n\nquestion.encodingLength = function (q) {\n  return name.encodingLength(q.name) + 4\n}\n\nexports.AUTHORITATIVE_ANSWER = 1 << 10\nexports.TRUNCATED_RESPONSE = 1 << 9\nexports.RECURSION_DESIRED = 1 << 8\nexports.RECURSION_AVAILABLE = 1 << 7\nexports.AUTHENTIC_DATA = 1 << 5\nexports.CHECKING_DISABLED = 1 << 4\nexports.DNSSEC_OK = 1 << 15\n\nexports.encode = function (result, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(exports.encodingLength(result))\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n\n  if (!result.questions) result.questions = []\n  if (!result.answers) result.answers = []\n  if (!result.authorities) result.authorities = []\n  if (!result.additionals) result.additionals = []\n\n  header.encode(result, buf, offset)\n  offset += header.encode.bytes\n\n  offset = encodeList(result.questions, question, buf, offset)\n  offset = encodeList(result.answers, answer, buf, offset)\n  offset = encodeList(result.authorities, answer, buf, offset)\n  offset = encodeList(result.additionals, answer, buf, offset)\n\n  exports.encode.bytes = offset - oldOffset\n\n  return buf\n}\n\nexports.encode.bytes = 0\n\nexports.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n  const result = header.decode(buf, offset)\n  offset += header.decode.bytes\n\n  offset = decodeList(result.questions, question, buf, offset)\n  offset = decodeList(result.answers, answer, buf, offset)\n  offset = decodeList(result.authorities, answer, buf, offset)\n  offset = decodeList(result.additionals, answer, buf, offset)\n\n  exports.decode.bytes = offset - oldOffset\n\n  return result\n}\n\nexports.decode.bytes = 0\n\nexports.encodingLength = function (result) {\n  return header.encodingLength(result) +\n    encodingLengthList(result.questions || [], question) +\n    encodingLengthList(result.answers || [], answer) +\n    encodingLengthList(result.authorities || [], answer) +\n    encodingLengthList(result.additionals || [], answer)\n}\n\nexports.streamEncode = function (result) {\n  const buf = exports.encode(result)\n  const sbuf = Buffer.allocUnsafe(2)\n  sbuf.writeUInt16BE(buf.byteLength)\n  const combine = Buffer.concat([sbuf, buf])\n  exports.streamEncode.bytes = combine.byteLength\n  return combine\n}\n\nexports.streamEncode.bytes = 0\n\nexports.streamDecode = function (sbuf) {\n  const len = sbuf.readUInt16BE(0)\n  if (sbuf.byteLength < len + 2) {\n    // not enough data\n    return null\n  }\n  const result = exports.decode(sbuf.slice(2))\n  exports.streamDecode.bytes = exports.decode.bytes\n  return result\n}\n\nexports.streamDecode.bytes = 0\n\nfunction encodingLengthList (list, enc) {\n  let len = 0\n  for (let i = 0; i < list.length; i++) len += enc.encodingLength(list[i])\n  return len\n}\n\nfunction encodeList (list, enc, buf, offset) {\n  for (let i = 0; i < list.length; i++) {\n    enc.encode(list[i], buf, offset)\n    offset += enc.encode.bytes\n  }\n  return offset\n}\n\nfunction decodeList (list, enc, buf, offset) {\n  for (let i = 0; i < list.length; i++) {\n    list[i] = enc.decode(buf, offset)\n    offset += enc.decode.bytes\n  }\n  return offset\n}\n"], "fixing_code": ["'use strict'\n\nconst types = require('./types')\nconst rcodes = require('./rcodes')\nconst opcodes = require('./opcodes')\nconst classes = require('./classes')\nconst optioncodes = require('./optioncodes')\nconst ip = require('ip')\n\nconst QUERY_FLAG = 0\nconst RESPONSE_FLAG = 1 << 15\nconst FLUSH_MASK = 1 << 15\nconst NOT_FLUSH_MASK = ~FLUSH_MASK\nconst QU_MASK = 1 << 15\nconst NOT_QU_MASK = ~QU_MASK\n\nconst name = exports.txt = exports.name = {}\n\nname.encode = function (str, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(name.encodingLength(str))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  // strip leading and trailing .\n  const n = str.replace(/^\\.|\\.$/gm, '')\n  if (n.length) {\n    const list = n.split('.')\n\n    for (let i = 0; i < list.length; i++) {\n      const len = buf.write(list[i], offset + 1)\n      buf[offset] = len\n      offset += len + 1\n    }\n  }\n\n  buf[offset++] = 0\n\n  name.encode.bytes = offset - oldOffset\n  return buf\n}\n\nname.encode.bytes = 0\n\nname.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const list = []\n  const oldOffset = offset\n  let len = buf[offset++]\n\n  if (len === 0) {\n    name.decode.bytes = 1\n    return '.'\n  }\n  if (len >= 0xc0) {\n    const res = name.decode(buf, buf.readUInt16BE(offset - 1) - 0xc000)\n    name.decode.bytes = 2\n    return res\n  }\n\n  while (len) {\n    if (len >= 0xc0) {\n      list.push(name.decode(buf, buf.readUInt16BE(offset - 1) - 0xc000))\n      offset++\n      break\n    }\n\n    list.push(buf.toString('utf-8', offset, offset + len))\n    offset += len\n    len = buf[offset++]\n  }\n\n  name.decode.bytes = offset - oldOffset\n  return list.join('.')\n}\n\nname.decode.bytes = 0\n\nname.encodingLength = function (n) {\n  if (n === '.') return 1\n  return Buffer.byteLength(n.replace(/^\\.|\\.$/gm, '')) + 2\n}\n\nconst string = {}\n\nstring.encode = function (s, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(string.encodingLength(s))\n  if (!offset) offset = 0\n\n  const len = buf.write(s, offset + 1)\n  buf[offset] = len\n  string.encode.bytes = len + 1\n  return buf\n}\n\nstring.encode.bytes = 0\n\nstring.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const len = buf[offset]\n  const s = buf.toString('utf-8', offset + 1, offset + 1 + len)\n  string.decode.bytes = len + 1\n  return s\n}\n\nstring.decode.bytes = 0\n\nstring.encodingLength = function (s) {\n  return Buffer.byteLength(s) + 1\n}\n\nconst header = {}\n\nheader.encode = function (h, buf, offset) {\n  if (!buf) buf = header.encodingLength(h)\n  if (!offset) offset = 0\n\n  const flags = (h.flags || 0) & 32767\n  const type = h.type === 'response' ? RESPONSE_FLAG : QUERY_FLAG\n\n  buf.writeUInt16BE(h.id || 0, offset)\n  buf.writeUInt16BE(flags | type, offset + 2)\n  buf.writeUInt16BE(h.questions.length, offset + 4)\n  buf.writeUInt16BE(h.answers.length, offset + 6)\n  buf.writeUInt16BE(h.authorities.length, offset + 8)\n  buf.writeUInt16BE(h.additionals.length, offset + 10)\n\n  return buf\n}\n\nheader.encode.bytes = 12\n\nheader.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  if (buf.length < 12) throw new Error('Header must be 12 bytes')\n  const flags = buf.readUInt16BE(offset + 2)\n\n  return {\n    id: buf.readUInt16BE(offset),\n    type: flags & RESPONSE_FLAG ? 'response' : 'query',\n    flags: flags & 32767,\n    flag_qr: ((flags >> 15) & 0x1) === 1,\n    opcode: opcodes.toString((flags >> 11) & 0xf),\n    flag_aa: ((flags >> 10) & 0x1) === 1,\n    flag_tc: ((flags >> 9) & 0x1) === 1,\n    flag_rd: ((flags >> 8) & 0x1) === 1,\n    flag_ra: ((flags >> 7) & 0x1) === 1,\n    flag_z: ((flags >> 6) & 0x1) === 1,\n    flag_ad: ((flags >> 5) & 0x1) === 1,\n    flag_cd: ((flags >> 4) & 0x1) === 1,\n    rcode: rcodes.toString(flags & 0xf),\n    questions: new Array(buf.readUInt16BE(offset + 4)),\n    answers: new Array(buf.readUInt16BE(offset + 6)),\n    authorities: new Array(buf.readUInt16BE(offset + 8)),\n    additionals: new Array(buf.readUInt16BE(offset + 10))\n  }\n}\n\nheader.decode.bytes = 12\n\nheader.encodingLength = function () {\n  return 12\n}\n\nconst runknown = exports.unknown = {}\n\nrunknown.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(runknown.encodingLength(data))\n  if (!offset) offset = 0\n\n  buf.writeUInt16BE(data.length, offset)\n  data.copy(buf, offset + 2)\n\n  runknown.encode.bytes = data.length + 2\n  return buf\n}\n\nrunknown.encode.bytes = 0\n\nrunknown.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const len = buf.readUInt16BE(offset)\n  const data = buf.slice(offset + 2, offset + 2 + len)\n  runknown.decode.bytes = len + 2\n  return data\n}\n\nrunknown.decode.bytes = 0\n\nrunknown.encodingLength = function (data) {\n  return data.length + 2\n}\n\nconst rns = exports.ns = {}\n\nrns.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rns.encodingLength(data))\n  if (!offset) offset = 0\n\n  name.encode(data, buf, offset + 2)\n  buf.writeUInt16BE(name.encode.bytes, offset)\n  rns.encode.bytes = name.encode.bytes + 2\n  return buf\n}\n\nrns.encode.bytes = 0\n\nrns.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const len = buf.readUInt16BE(offset)\n  const dd = name.decode(buf, offset + 2)\n\n  rns.decode.bytes = len + 2\n  return dd\n}\n\nrns.decode.bytes = 0\n\nrns.encodingLength = function (data) {\n  return name.encodingLength(data) + 2\n}\n\nconst rsoa = exports.soa = {}\n\nrsoa.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rsoa.encodingLength(data))\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n  offset += 2\n  name.encode(data.mname, buf, offset)\n  offset += name.encode.bytes\n  name.encode(data.rname, buf, offset)\n  offset += name.encode.bytes\n  buf.writeUInt32BE(data.serial || 0, offset)\n  offset += 4\n  buf.writeUInt32BE(data.refresh || 0, offset)\n  offset += 4\n  buf.writeUInt32BE(data.retry || 0, offset)\n  offset += 4\n  buf.writeUInt32BE(data.expire || 0, offset)\n  offset += 4\n  buf.writeUInt32BE(data.minimum || 0, offset)\n  offset += 4\n\n  buf.writeUInt16BE(offset - oldOffset - 2, oldOffset)\n  rsoa.encode.bytes = offset - oldOffset\n  return buf\n}\n\nrsoa.encode.bytes = 0\n\nrsoa.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n\n  const data = {}\n  offset += 2\n  data.mname = name.decode(buf, offset)\n  offset += name.decode.bytes\n  data.rname = name.decode(buf, offset)\n  offset += name.decode.bytes\n  data.serial = buf.readUInt32BE(offset)\n  offset += 4\n  data.refresh = buf.readUInt32BE(offset)\n  offset += 4\n  data.retry = buf.readUInt32BE(offset)\n  offset += 4\n  data.expire = buf.readUInt32BE(offset)\n  offset += 4\n  data.minimum = buf.readUInt32BE(offset)\n  offset += 4\n\n  rsoa.decode.bytes = offset - oldOffset\n  return data\n}\n\nrsoa.decode.bytes = 0\n\nrsoa.encodingLength = function (data) {\n  return 22 + name.encodingLength(data.mname) + name.encodingLength(data.rname)\n}\n\nconst rtxt = exports.txt = {}\n\nrtxt.encode = function (data, buf, offset) {\n  if (!Array.isArray(data)) data = [data]\n  for (let i = 0; i < data.length; i++) {\n    if (typeof data[i] === 'string') {\n      data[i] = Buffer.from(data[i])\n    }\n    if (!Buffer.isBuffer(data[i])) {\n      throw new Error('Must be a Buffer')\n    }\n  }\n\n  if (!buf) buf = Buffer.allocUnsafe(rtxt.encodingLength(data))\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n  offset += 2\n\n  data.forEach(function (d) {\n    buf[offset++] = d.length\n    d.copy(buf, offset, 0, d.length)\n    offset += d.length\n  })\n\n  buf.writeUInt16BE(offset - oldOffset - 2, oldOffset)\n  rtxt.encode.bytes = offset - oldOffset\n  return buf\n}\n\nrtxt.encode.bytes = 0\n\nrtxt.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n  let remaining = buf.readUInt16BE(offset)\n  offset += 2\n\n  let data = []\n  while (remaining > 0) {\n    const len = buf[offset++]\n    --remaining\n    if (remaining < len) {\n      throw new Error('Buffer overflow')\n    }\n    data.push(buf.slice(offset, offset + len))\n    offset += len\n    remaining -= len\n  }\n\n  rtxt.decode.bytes = offset - oldOffset\n  return data\n}\n\nrtxt.decode.bytes = 0\n\nrtxt.encodingLength = function (data) {\n  if (!Array.isArray(data)) data = [data]\n  let length = 2\n  data.forEach(function (buf) {\n    if (typeof buf === 'string') {\n      length += Buffer.byteLength(buf) + 1\n    } else {\n      length += buf.length + 1\n    }\n  })\n  return length\n}\n\nconst rnull = exports.null = {}\n\nrnull.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rnull.encodingLength(data))\n  if (!offset) offset = 0\n\n  if (typeof data === 'string') data = Buffer.from(data)\n  if (!data) data = Buffer.allocUnsafe(0)\n\n  const oldOffset = offset\n  offset += 2\n\n  const len = data.length\n  data.copy(buf, offset, 0, len)\n  offset += len\n\n  buf.writeUInt16BE(offset - oldOffset - 2, oldOffset)\n  rnull.encode.bytes = offset - oldOffset\n  return buf\n}\n\nrnull.encode.bytes = 0\n\nrnull.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n  const len = buf.readUInt16BE(offset)\n\n  offset += 2\n\n  const data = buf.slice(offset, offset + len)\n  offset += len\n\n  rnull.decode.bytes = offset - oldOffset\n  return data\n}\n\nrnull.decode.bytes = 0\n\nrnull.encodingLength = function (data) {\n  if (!data) return 2\n  return (Buffer.isBuffer(data) ? data.length : Buffer.byteLength(data)) + 2\n}\n\nconst rhinfo = exports.hinfo = {}\n\nrhinfo.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rhinfo.encodingLength(data))\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n  offset += 2\n  string.encode(data.cpu, buf, offset)\n  offset += string.encode.bytes\n  string.encode(data.os, buf, offset)\n  offset += string.encode.bytes\n  buf.writeUInt16BE(offset - oldOffset - 2, oldOffset)\n  rhinfo.encode.bytes = offset - oldOffset\n  return buf\n}\n\nrhinfo.encode.bytes = 0\n\nrhinfo.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n\n  const data = {}\n  offset += 2\n  data.cpu = string.decode(buf, offset)\n  offset += string.decode.bytes\n  data.os = string.decode(buf, offset)\n  offset += string.decode.bytes\n  rhinfo.decode.bytes = offset - oldOffset\n  return data\n}\n\nrhinfo.decode.bytes = 0\n\nrhinfo.encodingLength = function (data) {\n  return string.encodingLength(data.cpu) + string.encodingLength(data.os) + 2\n}\n\nconst rptr = exports.ptr = {}\nconst rcname = exports.cname = rptr\nconst rdname = exports.dname = rptr\n\nrptr.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rptr.encodingLength(data))\n  if (!offset) offset = 0\n\n  name.encode(data, buf, offset + 2)\n  buf.writeUInt16BE(name.encode.bytes, offset)\n  rptr.encode.bytes = name.encode.bytes + 2\n  return buf\n}\n\nrptr.encode.bytes = 0\n\nrptr.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const data = name.decode(buf, offset + 2)\n  rptr.decode.bytes = name.decode.bytes + 2\n  return data\n}\n\nrptr.decode.bytes = 0\n\nrptr.encodingLength = function (data) {\n  return name.encodingLength(data) + 2\n}\n\nconst rsrv = exports.srv = {}\n\nrsrv.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rsrv.encodingLength(data))\n  if (!offset) offset = 0\n\n  buf.writeUInt16BE(data.priority || 0, offset + 2)\n  buf.writeUInt16BE(data.weight || 0, offset + 4)\n  buf.writeUInt16BE(data.port || 0, offset + 6)\n  name.encode(data.target, buf, offset + 8)\n\n  const len = name.encode.bytes + 6\n  buf.writeUInt16BE(len, offset)\n\n  rsrv.encode.bytes = len + 2\n  return buf\n}\n\nrsrv.encode.bytes = 0\n\nrsrv.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const len = buf.readUInt16BE(offset)\n\n  const data = {}\n  data.priority = buf.readUInt16BE(offset + 2)\n  data.weight = buf.readUInt16BE(offset + 4)\n  data.port = buf.readUInt16BE(offset + 6)\n  data.target = name.decode(buf, offset + 8)\n\n  rsrv.decode.bytes = len + 2\n  return data\n}\n\nrsrv.decode.bytes = 0\n\nrsrv.encodingLength = function (data) {\n  return 8 + name.encodingLength(data.target)\n}\n\nconst rcaa = exports.caa = {}\n\nrcaa.ISSUER_CRITICAL = 1 << 7\n\nrcaa.encode = function (data, buf, offset) {\n  const len = rcaa.encodingLength(data)\n\n  if (!buf) buf = Buffer.allocUnsafe(rcaa.encodingLength(data))\n  if (!offset) offset = 0\n\n  if (data.issuerCritical) {\n    data.flags = rcaa.ISSUER_CRITICAL\n  }\n\n  buf.writeUInt16BE(len - 2, offset)\n  offset += 2\n  buf.writeUInt8(data.flags || 0, offset)\n  offset += 1\n  string.encode(data.tag, buf, offset)\n  offset += string.encode.bytes\n  buf.write(data.value, offset)\n  offset += Buffer.byteLength(data.value)\n\n  rcaa.encode.bytes = len\n  return buf\n}\n\nrcaa.encode.bytes = 0\n\nrcaa.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const len = buf.readUInt16BE(offset)\n  offset += 2\n\n  const oldOffset = offset\n  const data = {}\n  data.flags = buf.readUInt8(offset)\n  offset += 1\n  data.tag = string.decode(buf, offset)\n  offset += string.decode.bytes\n  data.value = buf.toString('utf-8', offset, oldOffset + len)\n\n  data.issuerCritical = !!(data.flags & rcaa.ISSUER_CRITICAL)\n\n  rcaa.decode.bytes = len + 2\n\n  return data\n}\n\nrcaa.decode.bytes = 0\n\nrcaa.encodingLength = function (data) {\n  return string.encodingLength(data.tag) + string.encodingLength(data.value) + 2\n}\n\nconst rmx = exports.mx = {}\n\nrmx.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rmx.encodingLength(data))\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n  offset += 2\n  buf.writeUInt16BE(data.preference || 0, offset)\n  offset += 2\n  name.encode(data.exchange, buf, offset)\n  offset += name.encode.bytes\n\n  buf.writeUInt16BE(offset - oldOffset - 2, oldOffset)\n  rmx.encode.bytes = offset - oldOffset\n  return buf\n}\n\nrmx.encode.bytes = 0\n\nrmx.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n\n  const data = {}\n  offset += 2\n  data.preference = buf.readUInt16BE(offset)\n  offset += 2\n  data.exchange = name.decode(buf, offset)\n  offset += name.decode.bytes\n\n  rmx.decode.bytes = offset - oldOffset\n  return data\n}\n\nrmx.encodingLength = function (data) {\n  return 4 + name.encodingLength(data.exchange)\n}\n\nconst ra = exports.a = {}\n\nra.encode = function (host, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(ra.encodingLength(host))\n  if (!offset) offset = 0\n\n  buf.writeUInt16BE(4, offset)\n  offset += 2\n  ip.toBuffer(host, buf, offset)\n  ra.encode.bytes = 6\n  return buf\n}\n\nra.encode.bytes = 0\n\nra.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  offset += 2\n  const host = ip.toString(buf, offset, 4)\n  ra.decode.bytes = 6\n  return host\n}\n\nra.decode.bytes = 0\n\nra.encodingLength = function () {\n  return 6\n}\n\nconst raaaa = exports.aaaa = {}\n\nraaaa.encode = function (host, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(raaaa.encodingLength(host))\n  if (!offset) offset = 0\n\n  buf.writeUInt16BE(16, offset)\n  offset += 2\n  ip.toBuffer(host, buf, offset)\n  raaaa.encode.bytes = 18\n  return buf\n}\n\nraaaa.encode.bytes = 0\n\nraaaa.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  offset += 2\n  const host = ip.toString(buf, offset, 16)\n  raaaa.decode.bytes = 18\n  return host\n}\n\nraaaa.decode.bytes = 0\n\nraaaa.encodingLength = function () {\n  return 18\n}\n\nconst roption = exports.option = {}\n\nroption.encode = function (option, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(roption.encodingLength(option))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const code = optioncodes.toCode(option.code)\n  buf.writeUInt16BE(code, offset)\n  offset += 2\n  if (option.data) {\n    buf.writeUInt16BE(option.data.length, offset)\n    offset += 2\n    option.data.copy(buf, offset)\n    offset += option.data.length\n  } else {\n    switch (code) {\n      // case 3: NSID.  No encode makes sense.\n      // case 5,6,7: Not implementable\n      case 8: // ECS\n        // note: do IP math before calling\n        const spl = option.sourcePrefixLength || 0\n        const fam = option.family || (ip.isV4Format(option.ip) ? 1 : 2)\n        const ipBuf = ip.toBuffer(option.ip)\n        const ipLen = Math.ceil(spl / 8)\n        buf.writeUInt16BE(ipLen + 4, offset)\n        offset += 2\n        buf.writeUInt16BE(fam, offset)\n        offset += 2\n        buf.writeUInt8(spl, offset++)\n        buf.writeUInt8(option.scopePrefixLength || 0, offset++)\n\n        ipBuf.copy(buf, offset, 0, ipLen)\n        offset += ipLen\n        break\n      // case 9: EXPIRE (experimental)\n      // case 10: COOKIE.  No encode makes sense.\n      case 11: // KEEP-ALIVE\n        if (option.timeout) {\n          buf.writeUInt16BE(2, offset)\n          offset += 2\n          buf.writeUInt16BE(option.timeout, offset)\n          offset += 2\n        } else {\n          buf.writeUInt16BE(0, offset)\n          offset += 2\n        }\n        break\n      case 12: // PADDING\n        const len = option.length || 0\n        buf.writeUInt16BE(len, offset)\n        offset += 2\n        buf.fill(0, offset, offset + len)\n        offset += len\n        break\n      // case 13:  CHAIN.  Experimental.\n      case 14: // KEY-TAG\n        const tagsLen = option.tags.length * 2\n        buf.writeUInt16BE(tagsLen, offset)\n        offset += 2\n        for (const tag of option.tags) {\n          buf.writeUInt16BE(tag, offset)\n          offset += 2\n        }\n        break\n      default:\n        throw new Error(`Unknown roption code: ${option.code}`)\n    }\n  }\n\n  roption.encode.bytes = offset - oldOffset\n  return buf\n}\n\nroption.encode.bytes = 0\n\nroption.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const option = {}\n  option.code = buf.readUInt16BE(offset)\n  option.type = optioncodes.toString(option.code)\n  offset += 2\n  const len = buf.readUInt16BE(offset)\n  offset += 2\n  option.data = buf.slice(offset, offset + len)\n  switch (option.code) {\n    // case 3: NSID.  No decode makes sense.\n    case 8: // ECS\n      option.family = buf.readUInt16BE(offset)\n      offset += 2\n      option.sourcePrefixLength = buf.readUInt8(offset++)\n      option.scopePrefixLength = buf.readUInt8(offset++)\n      const padded = Buffer.alloc((option.family === 1) ? 4 : 16)\n      buf.copy(padded, 0, offset, offset + len - 4)\n      option.ip = ip.toString(padded)\n      break\n    // case 12: Padding.  No decode makes sense.\n    case 11: // KEEP-ALIVE\n      if (len > 0) {\n        option.timeout = buf.readUInt16BE(offset)\n        offset += 2\n      }\n      break\n    case 14:\n      option.tags = []\n      for (let i = 0; i < len; i += 2) {\n        option.tags.push(buf.readUInt16BE(offset))\n        offset += 2\n      }\n    // don't worry about default.  caller will use data if desired\n  }\n\n  roption.decode.bytes = len + 4\n  return option\n}\n\nroption.decode.bytes = 0\n\nroption.encodingLength = function (option) {\n  if (option.data) {\n    return option.data.length + 4\n  }\n  const code = optioncodes.toCode(option.code)\n  switch (code) {\n    case 8: // ECS\n      const spl = option.sourcePrefixLength || 0\n      return Math.ceil(spl / 8) + 8\n    case 11: // KEEP-ALIVE\n      return (typeof option.timeout === 'number') ? 6 : 4\n    case 12: // PADDING\n      return option.length + 4\n    case 14: // KEY-TAG\n      return 4 + (option.tags.length * 2)\n  }\n  throw new Error(`Unknown roption code: ${option.code}`)\n}\n\nconst ropt = exports.opt = {}\n\nropt.encode = function (options, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(ropt.encodingLength(options))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const rdlen = encodingLengthList(options, roption)\n  buf.writeUInt16BE(rdlen, offset)\n  offset = encodeList(options, roption, buf, offset + 2)\n\n  ropt.encode.bytes = offset - oldOffset\n  return buf\n}\n\nropt.encode.bytes = 0\n\nropt.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const options = []\n  let rdlen = buf.readUInt16BE(offset)\n  offset += 2\n  let o = 0\n  while (rdlen > 0) {\n    options[o++] = roption.decode(buf, offset)\n    offset += roption.decode.bytes\n    rdlen -= roption.decode.bytes\n  }\n  ropt.decode.bytes = offset - oldOffset\n  return options\n}\n\nropt.decode.bytes = 0\n\nropt.encodingLength = function (options) {\n  return 2 + encodingLengthList(options || [], roption)\n}\n\nconst rdnskey = exports.dnskey = {}\n\nrdnskey.PROTOCOL_DNSSEC = 3\nrdnskey.ZONE_KEY = 0x80\nrdnskey.SECURE_ENTRYPOINT = 0x8000\n\nrdnskey.encode = function (key, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rdnskey.encodingLength(key))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const keydata = key.key\n  if (!Buffer.isBuffer(keydata)) {\n    throw new Error('Key must be a Buffer')\n  }\n\n  offset += 2 // Leave space for length\n  buf.writeUInt16BE(key.flags, offset)\n  offset += 2\n  buf.writeUInt8(rdnskey.PROTOCOL_DNSSEC, offset)\n  offset += 1\n  buf.writeUInt8(key.algorithm, offset)\n  offset += 1\n  keydata.copy(buf, offset, 0, keydata.length)\n  offset += keydata.length\n\n  rdnskey.encode.bytes = offset - oldOffset\n  buf.writeUInt16BE(rdnskey.encode.bytes - 2, oldOffset)\n  return buf\n}\n\nrdnskey.encode.bytes = 0\n\nrdnskey.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  var key = {}\n  var length = buf.readUInt16BE(offset)\n  offset += 2\n  key.flags = buf.readUInt16BE(offset)\n  offset += 2\n  if (buf.readUInt8(offset) !== rdnskey.PROTOCOL_DNSSEC) {\n    throw new Error('Protocol must be 3')\n  }\n  offset += 1\n  key.algorithm = buf.readUInt8(offset)\n  offset += 1\n  key.key = buf.slice(offset, oldOffset + length + 2)\n  offset += key.key.length\n  rdnskey.decode.bytes = offset - oldOffset\n  return key\n}\n\nrdnskey.decode.bytes = 0\n\nrdnskey.encodingLength = function (key) {\n  return 6 + Buffer.byteLength(key.key)\n}\n\nconst rrrsig = exports.rrsig = {}\n\nrrrsig.encode = function (sig, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rrrsig.encodingLength(sig))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const signature = sig.signature\n  if (!Buffer.isBuffer(signature)) {\n    throw new Error('Signature must be a Buffer')\n  }\n\n  offset += 2 // Leave space for length\n  buf.writeUInt16BE(types.toType(sig.typeCovered), offset)\n  offset += 2\n  buf.writeUInt8(sig.algorithm, offset)\n  offset += 1\n  buf.writeUInt8(sig.labels, offset)\n  offset += 1\n  buf.writeUInt32BE(sig.originalTTL, offset)\n  offset += 4\n  buf.writeUInt32BE(sig.expiration, offset)\n  offset += 4\n  buf.writeUInt32BE(sig.inception, offset)\n  offset += 4\n  buf.writeUInt16BE(sig.keyTag, offset)\n  offset += 2\n  name.encode(sig.signersName, buf, offset)\n  offset += name.encode.bytes\n  signature.copy(buf, offset, 0, signature.length)\n  offset += signature.length\n\n  rrrsig.encode.bytes = offset - oldOffset\n  buf.writeUInt16BE(rrrsig.encode.bytes - 2, oldOffset)\n  return buf\n}\n\nrrrsig.encode.bytes = 0\n\nrrrsig.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  var sig = {}\n  var length = buf.readUInt16BE(offset)\n  offset += 2\n  sig.typeCovered = types.toString(buf.readUInt16BE(offset))\n  offset += 2\n  sig.algorithm = buf.readUInt8(offset)\n  offset += 1\n  sig.labels = buf.readUInt8(offset)\n  offset += 1\n  sig.originalTTL = buf.readUInt32BE(offset)\n  offset += 4\n  sig.expiration = buf.readUInt32BE(offset)\n  offset += 4\n  sig.inception = buf.readUInt32BE(offset)\n  offset += 4\n  sig.keyTag = buf.readUInt16BE(offset)\n  offset += 2\n  sig.signersName = name.decode(buf, offset)\n  offset += name.decode.bytes\n  sig.signature = buf.slice(offset, oldOffset + length + 2)\n  offset += sig.signature.length\n  rrrsig.decode.bytes = offset - oldOffset\n  return sig\n}\n\nrrrsig.decode.bytes = 0\n\nrrrsig.encodingLength = function (sig) {\n  return 20 +\n    name.encodingLength(sig.signersName) +\n    Buffer.byteLength(sig.signature)\n}\n\nconst rrp = exports.rp = {}\n\nrrp.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rrp.encodingLength(data))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  offset += 2 // Leave space for length\n  name.encode(data.mbox || '.', buf, offset)\n  offset += name.encode.bytes\n  name.encode(data.txt || '.', buf, offset)\n  offset += name.encode.bytes\n  rrp.encode.bytes = offset - oldOffset\n  buf.writeUInt16BE(rrp.encode.bytes - 2, oldOffset)\n  return buf\n}\n\nrrp.encode.bytes = 0\n\nrrp.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const data = {}\n  offset += 2\n  data.mbox = name.decode(buf, offset) || '.'\n  offset += name.decode.bytes\n  data.txt = name.decode(buf, offset) || '.'\n  offset += name.decode.bytes\n  rrp.decode.bytes = offset - oldOffset\n  return data\n}\n\nrrp.decode.bytes = 0\n\nrrp.encodingLength = function (data) {\n  return 2 + name.encodingLength(data.mbox || '.') + name.encodingLength(data.txt || '.')\n}\n\nconst typebitmap = {}\n\ntypebitmap.encode = function (typelist, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(typebitmap.encodingLength(typelist))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  var typesByWindow = []\n  for (var i = 0; i < typelist.length; i++) {\n    var typeid = types.toType(typelist[i])\n    if (typesByWindow[typeid >> 8] === undefined) {\n      typesByWindow[typeid >> 8] = []\n    }\n    typesByWindow[typeid >> 8][(typeid >> 3) & 0x1F] |= 1 << (7 - (typeid & 0x7))\n  }\n\n  for (i = 0; i < typesByWindow.length; i++) {\n    if (typesByWindow[i] !== undefined) {\n      var windowBuf = Buffer.from(typesByWindow[i])\n      buf.writeUInt8(i, offset)\n      offset += 1\n      buf.writeUInt8(windowBuf.length, offset)\n      offset += 1\n      windowBuf.copy(buf, offset)\n      offset += windowBuf.length\n    }\n  }\n\n  typebitmap.encode.bytes = offset - oldOffset\n  return buf\n}\n\ntypebitmap.encode.bytes = 0\n\ntypebitmap.decode = function (buf, offset, length) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  var typelist = []\n  while (offset - oldOffset < length) {\n    var window = buf.readUInt8(offset)\n    offset += 1\n    var windowLength = buf.readUInt8(offset)\n    offset += 1\n    for (var i = 0; i < windowLength; i++) {\n      var b = buf.readUInt8(offset + i)\n      for (var j = 0; j < 8; j++) {\n        if (b & (1 << (7 - j))) {\n          var typeid = types.toString((window << 8) | (i << 3) | j)\n          typelist.push(typeid)\n        }\n      }\n    }\n    offset += windowLength\n  }\n\n  typebitmap.decode.bytes = offset - oldOffset\n  return typelist\n}\n\ntypebitmap.decode.bytes = 0\n\ntypebitmap.encodingLength = function (typelist) {\n  var extents = []\n  for (var i = 0; i < typelist.length; i++) {\n    var typeid = types.toType(typelist[i])\n    extents[typeid >> 8] = Math.max(extents[typeid >> 8] || 0, typeid & 0xFF)\n  }\n\n  var len = 0\n  for (i = 0; i < extents.length; i++) {\n    if (extents[i] !== undefined) {\n      len += 2 + Math.ceil((extents[i] + 1) / 8)\n    }\n  }\n\n  return len\n}\n\nconst rnsec = exports.nsec = {}\n\nrnsec.encode = function (record, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rnsec.encodingLength(record))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  offset += 2 // Leave space for length\n  name.encode(record.nextDomain, buf, offset)\n  offset += name.encode.bytes\n  typebitmap.encode(record.rrtypes, buf, offset)\n  offset += typebitmap.encode.bytes\n\n  rnsec.encode.bytes = offset - oldOffset\n  buf.writeUInt16BE(rnsec.encode.bytes - 2, oldOffset)\n  return buf\n}\n\nrnsec.encode.bytes = 0\n\nrnsec.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  var record = {}\n  var length = buf.readUInt16BE(offset)\n  offset += 2\n  record.nextDomain = name.decode(buf, offset)\n  offset += name.decode.bytes\n  record.rrtypes = typebitmap.decode(buf, offset, length - (offset - oldOffset))\n  offset += typebitmap.decode.bytes\n\n  rnsec.decode.bytes = offset - oldOffset\n  return record\n}\n\nrnsec.decode.bytes = 0\n\nrnsec.encodingLength = function (record) {\n  return 2 +\n    name.encodingLength(record.nextDomain) +\n    typebitmap.encodingLength(record.rrtypes)\n}\n\nconst rnsec3 = exports.nsec3 = {}\n\nrnsec3.encode = function (record, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rnsec3.encodingLength(record))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const salt = record.salt\n  if (!Buffer.isBuffer(salt)) {\n    throw new Error('salt must be a Buffer')\n  }\n\n  const nextDomain = record.nextDomain\n  if (!Buffer.isBuffer(nextDomain)) {\n    throw new Error('nextDomain must be a Buffer')\n  }\n\n  offset += 2 // Leave space for length\n  buf.writeUInt8(record.algorithm, offset)\n  offset += 1\n  buf.writeUInt8(record.flags, offset)\n  offset += 1\n  buf.writeUInt16BE(record.iterations, offset)\n  offset += 2\n  buf.writeUInt8(salt.length, offset)\n  offset += 1\n  salt.copy(buf, offset, 0, salt.length)\n  offset += salt.length\n  buf.writeUInt8(nextDomain.length, offset)\n  offset += 1\n  nextDomain.copy(buf, offset, 0, nextDomain.length)\n  offset += nextDomain.length\n  typebitmap.encode(record.rrtypes, buf, offset)\n  offset += typebitmap.encode.bytes\n\n  rnsec3.encode.bytes = offset - oldOffset\n  buf.writeUInt16BE(rnsec3.encode.bytes - 2, oldOffset)\n  return buf\n}\n\nrnsec3.encode.bytes = 0\n\nrnsec3.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  var record = {}\n  var length = buf.readUInt16BE(offset)\n  offset += 2\n  record.algorithm = buf.readUInt8(offset)\n  offset += 1\n  record.flags = buf.readUInt8(offset)\n  offset += 1\n  record.iterations = buf.readUInt16BE(offset)\n  offset += 2\n  const saltLength = buf.readUInt8(offset)\n  offset += 1\n  record.salt = buf.slice(offset, offset + saltLength)\n  offset += saltLength\n  const hashLength = buf.readUInt8(offset)\n  offset += 1\n  record.nextDomain = buf.slice(offset, offset + hashLength)\n  offset += hashLength\n  record.rrtypes = typebitmap.decode(buf, offset, length - (offset - oldOffset))\n  offset += typebitmap.decode.bytes\n\n  rnsec3.decode.bytes = offset - oldOffset\n  return record\n}\n\nrnsec3.decode.bytes = 0\n\nrnsec3.encodingLength = function (record) {\n  return 8 +\n    record.salt.length +\n    record.nextDomain.length +\n    typebitmap.encodingLength(record.rrtypes)\n}\n\nconst rds = exports.ds = {}\n\nrds.encode = function (digest, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(rds.encodingLength(digest))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const digestdata = digest.digest\n  if (!Buffer.isBuffer(digestdata)) {\n    throw new Error('Digest must be a Buffer')\n  }\n\n  offset += 2 // Leave space for length\n  buf.writeUInt16BE(digest.keyTag, offset)\n  offset += 2\n  buf.writeUInt8(digest.algorithm, offset)\n  offset += 1\n  buf.writeUInt8(digest.digestType, offset)\n  offset += 1\n  digestdata.copy(buf, offset, 0, digestdata.length)\n  offset += digestdata.length\n\n  rds.encode.bytes = offset - oldOffset\n  buf.writeUInt16BE(rds.encode.bytes - 2, oldOffset)\n  return buf\n}\n\nrds.encode.bytes = 0\n\nrds.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  var digest = {}\n  var length = buf.readUInt16BE(offset)\n  offset += 2\n  digest.keyTag = buf.readUInt16BE(offset)\n  offset += 2\n  digest.algorithm = buf.readUInt8(offset)\n  offset += 1\n  digest.digestType = buf.readUInt8(offset)\n  offset += 1\n  digest.digest = buf.slice(offset, oldOffset + length + 2)\n  offset += digest.digest.length\n  rds.decode.bytes = offset - oldOffset\n  return digest\n}\n\nrds.decode.bytes = 0\n\nrds.encodingLength = function (digest) {\n  return 6 + Buffer.byteLength(digest.digest)\n}\n\nconst renc = exports.record = function (type) {\n  switch (type.toUpperCase()) {\n    case 'A': return ra\n    case 'PTR': return rptr\n    case 'CNAME': return rcname\n    case 'DNAME': return rdname\n    case 'TXT': return rtxt\n    case 'NULL': return rnull\n    case 'AAAA': return raaaa\n    case 'SRV': return rsrv\n    case 'HINFO': return rhinfo\n    case 'CAA': return rcaa\n    case 'NS': return rns\n    case 'SOA': return rsoa\n    case 'MX': return rmx\n    case 'OPT': return ropt\n    case 'DNSKEY': return rdnskey\n    case 'RRSIG': return rrrsig\n    case 'RP': return rrp\n    case 'NSEC': return rnsec\n    case 'NSEC3': return rnsec3\n    case 'DS': return rds\n  }\n  return runknown\n}\n\nconst answer = exports.answer = {}\n\nanswer.encode = function (a, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(answer.encodingLength(a))\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n\n  name.encode(a.name, buf, offset)\n  offset += name.encode.bytes\n\n  buf.writeUInt16BE(types.toType(a.type), offset)\n\n  if (a.type.toUpperCase() === 'OPT') {\n    if (a.name !== '.') {\n      throw new Error('OPT name must be root.')\n    }\n    buf.writeUInt16BE(a.udpPayloadSize || 4096, offset + 2)\n    buf.writeUInt8(a.extendedRcode || 0, offset + 4)\n    buf.writeUInt8(a.ednsVersion || 0, offset + 5)\n    buf.writeUInt16BE(a.flags || 0, offset + 6)\n\n    offset += 8\n    ropt.encode(a.options || [], buf, offset)\n    offset += ropt.encode.bytes\n  } else {\n    let klass = classes.toClass(a.class === undefined ? 'IN' : a.class)\n    if (a.flush) klass |= FLUSH_MASK // the 1st bit of the class is the flush bit\n    buf.writeUInt16BE(klass, offset + 2)\n    buf.writeUInt32BE(a.ttl || 0, offset + 4)\n\n    offset += 8\n    const enc = renc(a.type)\n    enc.encode(a.data, buf, offset)\n    offset += enc.encode.bytes\n  }\n\n  answer.encode.bytes = offset - oldOffset\n  return buf\n}\n\nanswer.encode.bytes = 0\n\nanswer.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const a = {}\n  const oldOffset = offset\n\n  a.name = name.decode(buf, offset)\n  offset += name.decode.bytes\n  a.type = types.toString(buf.readUInt16BE(offset))\n  if (a.type === 'OPT') {\n    a.udpPayloadSize = buf.readUInt16BE(offset + 2)\n    a.extendedRcode = buf.readUInt8(offset + 4)\n    a.ednsVersion = buf.readUInt8(offset + 5)\n    a.flags = buf.readUInt16BE(offset + 6)\n    a.flag_do = ((a.flags >> 15) & 0x1) === 1\n    a.options = ropt.decode(buf, offset + 8)\n    offset += 8 + ropt.decode.bytes\n  } else {\n    const klass = buf.readUInt16BE(offset + 2)\n    a.ttl = buf.readUInt32BE(offset + 4)\n\n    a.class = classes.toString(klass & NOT_FLUSH_MASK)\n    a.flush = !!(klass & FLUSH_MASK)\n\n    const enc = renc(a.type)\n    a.data = enc.decode(buf, offset + 8)\n    offset += 8 + enc.decode.bytes\n  }\n\n  answer.decode.bytes = offset - oldOffset\n  return a\n}\n\nanswer.decode.bytes = 0\n\nanswer.encodingLength = function (a) {\n  const data = (a.data !== null && a.data !== undefined) ? a.data : a.options\n  return name.encodingLength(a.name) + 8 + renc(a.type).encodingLength(data)\n}\n\nconst question = exports.question = {}\n\nquestion.encode = function (q, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(question.encodingLength(q))\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n\n  name.encode(q.name, buf, offset)\n  offset += name.encode.bytes\n\n  buf.writeUInt16BE(types.toType(q.type), offset)\n  offset += 2\n\n  buf.writeUInt16BE(classes.toClass(q.class === undefined ? 'IN' : q.class), offset)\n  offset += 2\n\n  question.encode.bytes = offset - oldOffset\n  return q\n}\n\nquestion.encode.bytes = 0\n\nquestion.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n  const q = {}\n\n  q.name = name.decode(buf, offset)\n  offset += name.decode.bytes\n\n  q.type = types.toString(buf.readUInt16BE(offset))\n  offset += 2\n\n  q.class = classes.toString(buf.readUInt16BE(offset))\n  offset += 2\n\n  const qu = !!(q.class & QU_MASK)\n  if (qu) q.class &= NOT_QU_MASK\n\n  question.decode.bytes = offset - oldOffset\n  return q\n}\n\nquestion.decode.bytes = 0\n\nquestion.encodingLength = function (q) {\n  return name.encodingLength(q.name) + 4\n}\n\nexports.AUTHORITATIVE_ANSWER = 1 << 10\nexports.TRUNCATED_RESPONSE = 1 << 9\nexports.RECURSION_DESIRED = 1 << 8\nexports.RECURSION_AVAILABLE = 1 << 7\nexports.AUTHENTIC_DATA = 1 << 5\nexports.CHECKING_DISABLED = 1 << 4\nexports.DNSSEC_OK = 1 << 15\n\nexports.encode = function (result, buf, offset) {\n  if (!buf) buf = Buffer.allocUnsafe(exports.encodingLength(result))\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n\n  if (!result.questions) result.questions = []\n  if (!result.answers) result.answers = []\n  if (!result.authorities) result.authorities = []\n  if (!result.additionals) result.additionals = []\n\n  header.encode(result, buf, offset)\n  offset += header.encode.bytes\n\n  offset = encodeList(result.questions, question, buf, offset)\n  offset = encodeList(result.answers, answer, buf, offset)\n  offset = encodeList(result.authorities, answer, buf, offset)\n  offset = encodeList(result.additionals, answer, buf, offset)\n\n  exports.encode.bytes = offset - oldOffset\n\n  return buf\n}\n\nexports.encode.bytes = 0\n\nexports.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n  const result = header.decode(buf, offset)\n  offset += header.decode.bytes\n\n  offset = decodeList(result.questions, question, buf, offset)\n  offset = decodeList(result.answers, answer, buf, offset)\n  offset = decodeList(result.authorities, answer, buf, offset)\n  offset = decodeList(result.additionals, answer, buf, offset)\n\n  exports.decode.bytes = offset - oldOffset\n\n  return result\n}\n\nexports.decode.bytes = 0\n\nexports.encodingLength = function (result) {\n  return header.encodingLength(result) +\n    encodingLengthList(result.questions || [], question) +\n    encodingLengthList(result.answers || [], answer) +\n    encodingLengthList(result.authorities || [], answer) +\n    encodingLengthList(result.additionals || [], answer)\n}\n\nexports.streamEncode = function (result) {\n  const buf = exports.encode(result)\n  const sbuf = Buffer.allocUnsafe(2)\n  sbuf.writeUInt16BE(buf.byteLength)\n  const combine = Buffer.concat([sbuf, buf])\n  exports.streamEncode.bytes = combine.byteLength\n  return combine\n}\n\nexports.streamEncode.bytes = 0\n\nexports.streamDecode = function (sbuf) {\n  const len = sbuf.readUInt16BE(0)\n  if (sbuf.byteLength < len + 2) {\n    // not enough data\n    return null\n  }\n  const result = exports.decode(sbuf.slice(2))\n  exports.streamDecode.bytes = exports.decode.bytes\n  return result\n}\n\nexports.streamDecode.bytes = 0\n\nfunction encodingLengthList (list, enc) {\n  let len = 0\n  for (let i = 0; i < list.length; i++) len += enc.encodingLength(list[i])\n  return len\n}\n\nfunction encodeList (list, enc, buf, offset) {\n  for (let i = 0; i < list.length; i++) {\n    enc.encode(list[i], buf, offset)\n    offset += enc.encode.bytes\n  }\n  return offset\n}\n\nfunction decodeList (list, enc, buf, offset) {\n  for (let i = 0; i < list.length; i++) {\n    list[i] = enc.decode(buf, offset)\n    offset += enc.decode.bytes\n  }\n  return offset\n}\n"], "filenames": ["index.js"], "buggy_code_start_loc": [81], "buggy_code_end_loc": [82], "fixing_code_start_loc": [81], "fixing_code_end_loc": [82], "type": "CWE-909", "message": "This affects the package dns-packet before 5.2.2. It creates buffers with allocUnsafe and does not always fill them before forming network packets. This can expose internal application memory over unencrypted network when querying crafted invalid domain names.", "other": {"cve": {"id": "CVE-2021-23386", "sourceIdentifier": "report@snyk.io", "published": "2021-05-20T17:15:07.567", "lastModified": "2022-07-12T17:42:04.277", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "This affects the package dns-packet before 5.2.2. It creates buffers with allocUnsafe and does not always fill them before forming network packets. This can expose internal application memory over unencrypted network when querying crafted invalid domain names."}, {"lang": "es", "value": "Esto afecta al paquete dns-packet  versi\u00f3n anterior a 5.2.2.&#xa0;Crea b\u00faferes con el par\u00e1metro allocUnsafe y no siempre los llena antes de formar paquetes de red.&#xa0;Esto puede exponer la memoria interna de la aplicaci\u00f3n por medio de una red no cifrada cuando se consultan nombres de dominio no v\u00e1lidos dise\u00f1ados"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 6.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 3.6}, {"source": "report@snyk.io", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:L/UI:N/S:C/C:H/I:L/A:L", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "CHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "LOW", "availabilityImpact": "LOW", "baseScore": 7.7, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.3}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:S/C:P/I:N/A:N", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "SINGLE", "confidentialityImpact": "PARTIAL", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 4.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-909"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:dns-packet_project:dns-packet:*:*:*:*:*:node.js:*:*", "versionEndExcluding": "1.3.4", "matchCriteriaId": "762967F6-7E35-496E-B72E-4CDD935C42B8"}, {"vulnerable": true, "criteria": "cpe:2.3:a:dns-packet_project:dns-packet:*:*:*:*:*:node.js:*:*", "versionStartIncluding": "2.0.0", "versionEndExcluding": "5.2.2", "matchCriteriaId": "D5C4FFB0-2B90-4CDA-99CF-DE77EC8643CF"}]}]}], "references": [{"url": "https://github.com/mafintosh/dns-packet/commit/25f15dd0fedc53688b25fd053ebbdffe3d5c1c56", "source": "report@snyk.io", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://hackerone.com/bugs?subject=user&amp%3Breport_id=968858", "source": "report@snyk.io", "tags": ["Permissions Required", "Third Party Advisory"]}, {"url": "https://snyk.io/vuln/SNYK-JAVA-ORGWEBJARSNPM-1295719", "source": "report@snyk.io", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://snyk.io/vuln/SNYK-JS-DNSPACKET-1293563", "source": "report@snyk.io", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/mafintosh/dns-packet/commit/25f15dd0fedc53688b25fd053ebbdffe3d5c1c56"}}
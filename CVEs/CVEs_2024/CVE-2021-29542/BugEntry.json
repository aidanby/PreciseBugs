{"buggy_code": ["/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include <locale>\n#include <string>\n\n#include \"absl/strings/ascii.h\"\n#include \"absl/strings/str_cat.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/platform/errors.h\"\n\nnamespace tensorflow {\nnamespace text {\n\nnamespace {\ntemplate <typename SPLITS_TYPE>\nclass StringNGramsOp : public tensorflow::OpKernel {\n public:\n  explicit StringNGramsOp(tensorflow::OpKernelConstruction* context)\n      : tensorflow::OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(\"separator\", &separator_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"ngram_widths\", &ngram_widths_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"left_pad\", &left_pad_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"right_pad\", &right_pad_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"pad_width\", &pad_width_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"preserve_short_sequences\",\n                                             &preserve_short_));\n  }\n\n  int get_pad_width(const int ngram_width) const {\n    // Ngrams can be padded with either a fixed pad width or a dynamic pad\n    // width depending on the 'pad_width' arg, but in no case should the padding\n    // ever be wider than 'ngram_width' - 1.\n    return std::min(pad_width_ < 0 ? ngram_width - 1 : pad_width_,\n                    ngram_width - 1);\n  }\n\n  int get_num_ngrams(const int length, const int ngram_width) const {\n    int pad_width = get_pad_width(ngram_width);\n    return std::max(0, ((length + 2 * pad_width) - ngram_width) + 1);\n  }\n\n  void Compute(tensorflow::OpKernelContext* context) override {\n    const tensorflow::Tensor* data;\n    OP_REQUIRES_OK(context, context->input(\"data\", &data));\n    const auto& input_data = data->flat<tstring>().data();\n\n    const tensorflow::Tensor* splits;\n    OP_REQUIRES_OK(context, context->input(\"data_splits\", &splits));\n    const auto& splits_vec = splits->flat<SPLITS_TYPE>();\n\n    // Validate that the splits are valid indices into data\n    const int input_data_size = data->flat<tstring>().size();\n    const int splits_vec_size = splits_vec.size();\n    for (int i = 0; i < splits_vec_size; ++i) {\n      bool valid_splits = splits_vec(i) >= 0;\n      valid_splits = valid_splits && (splits_vec(i) <= input_data_size);\n      OP_REQUIRES(\n          context, valid_splits,\n          errors::InvalidArgument(\"Invalid split value \", splits_vec(i),\n                                  \", must be in [0,\", input_data_size, \"]\"));\n    }\n\n    int num_batch_items = splits_vec.size() - 1;\n    tensorflow::Tensor* ngrams_splits;\n    OP_REQUIRES_OK(\n        context, context->allocate_output(1, splits->shape(), &ngrams_splits));\n    auto ngrams_splits_data = ngrams_splits->flat<SPLITS_TYPE>().data();\n\n    // If there is no data or size, return an empty RT.\n    if (data->flat<tstring>().size() == 0 || splits_vec.size() == 0) {\n      tensorflow::Tensor* empty;\n      OP_REQUIRES_OK(context,\n                     context->allocate_output(0, data->shape(), &empty));\n      for (int i = 0; i <= num_batch_items; ++i) {\n        ngrams_splits_data[i] = 0;\n      }\n      return;\n    }\n\n    ngrams_splits_data[0] = 0;\n    for (int i = 1; i <= num_batch_items; ++i) {\n      int length = splits_vec(i) - splits_vec(i - 1);\n      int num_ngrams = 0;\n      for (int ngram_width : ngram_widths_)\n        num_ngrams += get_num_ngrams(length, ngram_width);\n      if (preserve_short_ && length > 0 && num_ngrams == 0) {\n        num_ngrams = 1;\n      }\n      ngrams_splits_data[i] = ngrams_splits_data[i - 1] + num_ngrams;\n    }\n\n    tensorflow::Tensor* ngrams;\n    OP_REQUIRES_OK(\n        context,\n        context->allocate_output(\n            0, TensorShape({ngrams_splits_data[num_batch_items]}), &ngrams));\n    auto ngrams_data = ngrams->flat<tstring>().data();\n\n    for (int i = 0; i < num_batch_items; ++i) {\n      auto data_start = &input_data[splits_vec(i)];\n      int output_start_idx = ngrams_splits_data[i];\n      for (int ngram_width : ngram_widths_) {\n        auto output_start = &ngrams_data[output_start_idx];\n        int length = splits_vec(i + 1) - splits_vec(i);\n        int num_ngrams = get_num_ngrams(length, ngram_width);\n        CreateNgrams(data_start, output_start, num_ngrams, ngram_width);\n        output_start_idx += num_ngrams;\n      }\n      // If we're preserving short sequences, check to see if no sequence was\n      // generated by comparing the current output start idx to the original\n      // one (ngram_splits_data). If no ngrams were generated, then they will\n      // be equal (since we increment output_start_idx by num_ngrams every\n      // time we create a set of ngrams.)\n      if (preserve_short_ && output_start_idx == ngrams_splits_data[i]) {\n        int data_length = splits_vec(i + 1) - splits_vec(i);\n        // One legitimate reason to not have any ngrams when preserve_short_\n        // is true is if the sequence itself is empty. In that case, move on.\n        if (data_length == 0) {\n          continue;\n        }\n        // We don't have to worry about dynamic padding sizes here: if padding\n        // was dynamic, every sequence would have had sufficient padding to\n        // generate at least one ngram.\n        int ngram_width = data_length + 2 * pad_width_;\n        auto output_start = &ngrams_data[output_start_idx];\n        int num_ngrams = 1;\n        CreateNgrams(data_start, output_start, num_ngrams, ngram_width);\n      }\n    }\n  }\n\n  void CreateNgrams(const tstring* data, tstring* output, int num_ngrams,\n                    int ngram_width) const {\n    for (int ngram_index = 0; ngram_index < num_ngrams; ++ngram_index) {\n      int pad_width = get_pad_width(ngram_width);\n      int left_padding = std::max(0, pad_width - ngram_index);\n      int right_padding =\n          std::max(0, pad_width - (num_ngrams - (ngram_index + 1)));\n      int num_tokens = ngram_width - (left_padding + right_padding);\n      int data_start_index = left_padding > 0 ? 0 : ngram_index - pad_width;\n\n      // Calculate the total expected size of the ngram so we can reserve the\n      // correct amount of space in the string.\n      int ngram_size = 0;\n      // Size of the left padding.\n      ngram_size += left_padding * left_pad_.length();\n      // Size of the tokens.\n      for (int n = 0; n < num_tokens; ++n) {\n        ngram_size += data[data_start_index + n].length();\n      }\n      // Size of the right padding.\n      ngram_size += right_padding * right_pad_.length();\n      // Size of the separators.\n      int num_separators = left_padding + right_padding + num_tokens - 1;\n      ngram_size += num_separators * separator_.length();\n\n      // Build the ngram.\n      tstring* ngram = &output[ngram_index];\n      ngram->reserve(ngram_size);\n      for (int n = 0; n < left_padding; ++n) {\n        ngram->append(left_pad_);\n        ngram->append(separator_);\n      }\n      for (int n = 0; n < num_tokens - 1; ++n) {\n        ngram->append(data[data_start_index + n]);\n        ngram->append(separator_);\n      }\n      ngram->append(data[data_start_index + num_tokens - 1]);\n      for (int n = 0; n < right_padding; ++n) {\n        ngram->append(separator_);\n        ngram->append(right_pad_);\n      }\n\n      // In debug mode only: validate that we've reserved enough space for the\n      // ngram.\n      DCHECK_EQ(ngram_size, ngram->size());\n    }\n  }\n\n  string separator_;\n  string left_pad_;\n  string right_pad_;\n  bool use_pad_;\n  bool extend_pad_;\n  bool preserve_short_;\n\n  std::vector<int> ngram_widths_;\n  int pad_width_;\n};\n\n}  // namespace\nREGISTER_KERNEL_BUILDER(Name(\"StringNGrams\")\n                            .Device(tensorflow::DEVICE_CPU)\n                            .TypeConstraint<int32>(\"Tsplits\"),\n                        StringNGramsOp<int32>);\nREGISTER_KERNEL_BUILDER(Name(\"StringNGrams\")\n                            .Device(tensorflow::DEVICE_CPU)\n                            .TypeConstraint<int64>(\"Tsplits\"),\n                        StringNGramsOp<int64>);\n\n}  // namespace text\n}  // namespace tensorflow\n", "/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include <vector>\n\n#include \"tensorflow/core/framework/fake_input.h\"\n#include \"tensorflow/core/framework/node_def_builder.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n#include \"tensorflow/core/framework/shape_inference_testutil.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/framework/tensor_testutil.h\"\n#include \"tensorflow/core/framework/types.pb.h\"\n#include \"tensorflow/core/kernels/ops_testutil.h\"\n#include \"tensorflow/core/lib/core/status.h\"\n#include \"tensorflow/core/lib/core/status_test_util.h\"\n\nnamespace tensorflow {\nnamespace text {\n\nusing tensorflow::FakeInput;\nusing tensorflow::NodeDefBuilder;\nusing tensorflow::Status;\nusing tensorflow::TensorShape;\n\nclass NgramKernelTest : public tensorflow::OpsTestBase {\n public:\n  void MakeOp(string separator, std::vector<int> ngram_width, string left_pad,\n              string right_pad, int pad_width, bool preserve) {\n    TF_ASSERT_OK(NodeDefBuilder(\"tested_op\", \"StringNGrams\")\n                     .Attr(\"separator\", separator)\n                     .Attr(\"ngram_widths\", ngram_width)\n                     .Attr(\"left_pad\", left_pad)\n                     .Attr(\"right_pad\", right_pad)\n                     .Attr(\"pad_width\", pad_width)\n                     .Attr(\"preserve_short_sequences\", preserve)\n                     .Input(FakeInput())\n                     .Input(FakeInput())\n                     .Finalize(node_def()));\n    TF_ASSERT_OK(InitOp());\n  }\n\n  void assert_string_equal(const std::vector<tstring> &expected,\n                           const Tensor &value) {\n    Tensor expected_tensor(allocator(), DT_STRING,\n                           TensorShape({static_cast<int64>(expected.size())}));\n    test::FillValues<tstring>(&expected_tensor, expected);\n    test::ExpectTensorEqual<tstring>(expected_tensor, value);\n  }\n  void assert_int64_equal(const std::vector<int64> &expected,\n                          const Tensor &value) {\n    Tensor expected_tensor(allocator(), DT_INT64,\n                           TensorShape({static_cast<int64>(expected.size())}));\n    test::FillValues<int64>(&expected_tensor, expected);\n    test::ExpectTensorEqual<int64>(expected_tensor, value);\n  }\n};\n\nTEST_F(NgramKernelTest, TestPaddedTrigrams) {\n  MakeOp(\"|\", {3}, \"LP\", \"RP\", -1, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(                             //\n      {\"LP|LP|a\", \"LP|a|b\", \"a|b|c\", \"b|c|d\", \"c|d|RP\", \"d|RP|RP\",  // 0\n       \"LP|LP|e\", \"LP|e|f\", \"e|f|RP\", \"f|RP|RP\"});                  // 1\n  std::vector<int64> expected_splits({0, 6, 10});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestPaddedBigramsAndTrigrams) {\n  MakeOp(\"|\", {2, 3}, \"LP\", \"RP\", -1, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(\n      {\"LP|a\", \"a|b\", \"b|c\", \"c|d\", \"d|RP\", \"LP|LP|a\", \"LP|a|b\", \"a|b|c\",\n       \"b|c|d\", \"c|d|RP\", \"d|RP|RP\",                                       // 0\n       \"LP|e\", \"e|f\", \"f|RP\", \"LP|LP|e\", \"LP|e|f\", \"e|f|RP\", \"f|RP|RP\"});  // 1\n  std::vector<int64> expected_splits({0, 11, 18});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestPaddedBigrams) {\n  MakeOp(\"|\", {2}, \"LP\", \"RP\", -1, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(      //\n      {\"LP|a\", \"a|b\", \"b|c\", \"c|d\", \"d|RP\",  // 0\n       \"LP|e\", \"e|f\", \"f|RP\"});              // 1\n  std::vector<int64> expected_splits({0, 5, 8});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestPaddingIsAtMostNGramSizeMinus1) {\n  MakeOp(\"|\", {2}, \"LP\", \"RP\", 4, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(      //\n      {\"LP|a\", \"a|b\", \"b|c\", \"c|d\", \"d|RP\",  // 0\n       \"LP|e\", \"e|f\", \"f|RP\"});              // 1\n  std::vector<int64> expected_splits({0, 5, 8});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestPaddedUnigramAndBigrams) {\n  MakeOp(\"|\", {1, 2}, \"LP\", \"RP\", -1, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(                          //\n      {\"a\", \"b\", \"c\", \"d\", \"LP|a\", \"a|b\", \"b|c\", \"c|d\", \"d|RP\",  // 0\n       \"e\", \"f\", \"LP|e\", \"e|f\", \"f|RP\"});                        // 1\n  std::vector<int64> expected_splits({0, 9, 14});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestOverlappingPaddedNGrams) {\n  // This test validates that n-grams with both left and right padding in a\n  // single ngram token are created correctly.\n  MakeOp(\"|\", {3}, \"LP\", \"RP\", -1, false);\n  // Batch items are:\n  // 0: \"a\"\n  // 1: \"b\", \"c\", \"d\"\n  // 2: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({4}), {0, 1, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(                    //\n      {\"LP|LP|a\", \"LP|a|RP\", \"a|RP|RP\",                    // ngrams for elem. 0\n       \"LP|LP|b\", \"LP|b|c\", \"b|c|d\", \"c|d|RP\", \"d|RP|RP\",  // ngrams for elem. 1\n       \"LP|LP|e\", \"LP|e|f\", \"e|f|RP\", \"f|RP|RP\"});         // ngrams for elem. 2\n  std::vector<int64> expected_splits({0, 3, 8, 12});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestOverlappingPaddedMultiCharNGrams) {\n  MakeOp(\"|\", {3}, \"LP\", \"RP\", -1, false);\n  // Batch items are:\n  // 0: \"a\"\n  // 1: \"b\", \"c\", \"d\"\n  // 2: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}),\n                             {\"aa\", \"bb\", \"cc\", \"dd\", \"ee\", \"ff\"});\n  AddInputFromArray<int64>(TensorShape({4}), {0, 1, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(                             //\n      {\"LP|LP|aa\", \"LP|aa|RP\", \"aa|RP|RP\",                          //\n       \"LP|LP|bb\", \"LP|bb|cc\", \"bb|cc|dd\", \"cc|dd|RP\", \"dd|RP|RP\",  //\n       \"LP|LP|ee\", \"LP|ee|ff\", \"ee|ff|RP\", \"ff|RP|RP\"});            //\n  std::vector<int64> expected_splits({0, 3, 8, 12});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestMultiOverlappingPaddedNGrams) {\n  // This test validates that n-grams with more than 1 padding value on each\n  // side are created correctly.\n  MakeOp(\"|\", {5}, \"LP\", \"RP\", -1, false);\n  // Batch items are:\n  // 0: \"a\"\n  AddInputFromArray<tstring>(TensorShape({1}), {\"a\"});\n  AddInputFromArray<int64>(TensorShape({2}), {0, 1});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"LP|LP|LP|LP|a\", \"LP|LP|LP|a|RP\",\n                                        \"LP|LP|a|RP|RP\", \"LP|a|RP|RP|RP\",\n                                        \"a|RP|RP|RP|RP\"});\n  std::vector<int64> expected_splits({0, 5});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestUnpaddedTrigrams) {\n  MakeOp(\"|\", {3}, \"\", \"\", 0, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"a|b|c\", \"b|c|d\"});\n  std::vector<int64> expected_splits({0, 2, 2});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestUnpaddedTrigramsWithEmptySequence) {\n  MakeOp(\"|\", {3}, \"\", \"\", 0, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({4}), {0, 4, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"a|b|c\", \"b|c|d\"});\n  std::vector<int64> expected_splits({0, 2, 2, 2});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestUnpaddedTrigramsWithPreserveShort) {\n  MakeOp(\"|\", {3}, \"\", \"\", 0, true);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"a|b|c\", \"b|c|d\", \"e|f\"});\n  std::vector<int64> expected_splits({0, 2, 3});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestUnpaddedTrigramsWithPreserveShortAndEmptySequence) {\n  MakeOp(\"|\", {3}, \"\", \"\", 0, true);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({4}), {0, 4, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"a|b|c\", \"b|c|d\", \"e|f\"});\n  std::vector<int64> expected_splits({0, 2, 2, 3});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestUnpaddedTrigramsAndQuadgramsWithPreserveShort) {\n  MakeOp(\"|\", {4, 3}, \"\", \"\", 0, true);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"a|b|c|d\", \"a|b|c\", \"b|c|d\", \"e|f\"});\n  std::vector<int64> expected_splits({0, 3, 4});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestUnpaddedBigramsAndTrigrams) {\n  MakeOp(\"|\", {2, 3}, \"\", \"\", 0, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(\n      {\"a|b\", \"b|c\", \"c|d\", \"a|b|c\", \"b|c|d\", \"e|f\"});\n  std::vector<int64> expected_splits({0, 5, 6});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestUnpaddedBigramsAndTrigramsWithPreserveShort) {\n  MakeOp(\"|\", {2, 3}, \"\", \"\", 0, true);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  // Note that in this case, because the bigram 'e|f' was already generated,\n  // the op will not generate a special preserve_short bigram.\n  std::vector<tstring> expected_values(\n      {\"a|b\", \"b|c\", \"c|d\", \"a|b|c\", \"b|c|d\", \"e|f\"});\n  std::vector<int64> expected_splits({0, 5, 6});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestUnpaddedTrigramsAndBigramsWithPreserveShort) {\n  MakeOp(\"|\", {3, 2}, \"\", \"\", 0, true);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  // Note that in this case, because the bigram 'e|f' was already generated,\n  // the op will not generate a special preserve_short bigram.\n  std::vector<tstring> expected_values(\n      {\"a|b|c\", \"b|c|d\", \"a|b\", \"b|c\", \"c|d\", \"e|f\"});\n  std::vector<int64> expected_splits({0, 5, 6});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestUnpaddedBigrams) {\n  MakeOp(\"|\", {2}, \"\", \"\", 0, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"a|b\", \"b|c\", \"c|d\", \"e|f\"});\n  std::vector<int64> expected_splits({0, 3, 4});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestOverlappingUnpaddedNGrams) {\n  MakeOp(\"|\", {3}, \"\", \"\", 0, false);\n  // Batch items are:\n  // 0: \"a\"\n  // 1: \"b\", \"c\", \"d\"\n  // 2: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({4}), {0, 1, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"b|c|d\"});\n  std::vector<int64> expected_splits({0, 0, 1, 1});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestOverlappingUnpaddedNGramsNoOutput) {\n  MakeOp(\"|\", {5}, \"\", \"\", 0, false);\n  // Batch items are:\n  // 0: \"a\"\n  // 1: \"b\", \"c\", \"d\"\n  // 2: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({4}), {0, 1, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({});\n  std::vector<int64> expected_splits({0, 0, 0, 0});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestSinglyPaddedTrigrams) {\n  MakeOp(\"|\", {3}, \"LP\", \"RP\", 1, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"LP|a|b\", \"a|b|c\", \"b|c|d\",\n                                        \"c|d|RP\",  //\n                                        \"LP|e|f\", \"e|f|RP\"});\n  std::vector<int64> expected_splits({0, 4, 6});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestSinglyPaddedBigrams) {\n  MakeOp(\"|\", {2}, \"LP\", \"RP\", 1, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"LP|a\", \"a|b\", \"b|c\", \"c|d\", \"d|RP\",  //\n                                        \"LP|e\", \"e|f\", \"f|RP\"});\n  std::vector<int64> expected_splits({0, 5, 8});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestSinglyPaddedBigramsAnd5grams) {\n  MakeOp(\"|\", {2, 5}, \"LP\", \"RP\", 1, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(                                  //\n      {\"LP|a\", \"a|b\", \"b|c\", \"c|d\", \"d|RP\", \"LP|a|b|c|d\", \"a|b|c|d|RP\",  //\n       \"LP|e\", \"e|f\", \"f|RP\"});\n  std::vector<int64> expected_splits({0, 7, 10});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestSinglyPadded5gramsWithPreserveShort) {\n  MakeOp(\"|\", {5}, \"LP\", \"RP\", 1, true);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(  //\n      {\"LP|a|b|c|d\", \"a|b|c|d|RP\",       //\n       \"LP|e|f|RP\"});\n  std::vector<int64> expected_splits({0, 2, 3});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestOverlappingSinglyPaddedNGrams) {\n  MakeOp(\"|\", {3}, \"LP\", \"RP\", 1, false);\n  // Batch items are:\n  // 0: \"a\"\n  // 1: \"b\", \"c\", \"d\"\n  // 2: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({4}), {0, 1, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(\n      {\"LP|a|RP\",                    // ngrams for elem. 0\n       \"LP|b|c\", \"b|c|d\", \"c|d|RP\",  // ngrams for elem. 1\n       \"LP|e|f\", \"e|f|RP\"});         // ngrams for elem. 2\n  std::vector<int64> expected_splits({0, 1, 4, 6});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestOverlappingSinglyPaddedNGramsNoOutput) {\n  MakeOp(\"|\", {5}, \"LP\", \"RP\", 1, false);\n  // Batch items are:\n  // 0: \"a\"\n  // 1: \"b\", \"c\", \"d\"\n  // 2: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({4}), {0, 1, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"LP|b|c|d|RP\"});\n  std::vector<int64> expected_splits({0, 0, 1, 1});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestSinglyPaddedUnigrams) {\n  MakeOp(\"|\", {1}, \"LP\", \"RP\", 1, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  std::vector<int64> expected_splits({0, 4, 6});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestEmptyInput) {\n  MakeOp(\"|\", {1}, \"LP\", \"RP\", 3, false);\n  AddInputFromArray<tstring>(TensorShape({0}), {});\n  AddInputFromArray<int64>(TensorShape({0}), {});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({});\n  std::vector<int64> expected_splits({});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, ShapeFn) {\n  ShapeInferenceTestOp op(\"StringNGrams\");\n  INFER_OK(op, \"?;?\", \"[?];[?]\");\n  INFER_OK(op, \"[1];?\", \"[?];[?]\");\n  INFER_OK(op, \"[1];[2]\", \"[?];in1\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"[];?\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"?;[]\");\n}\n\n}  // namespace text\n}  // namespace tensorflow\n"], "fixing_code": ["/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include <locale>\n#include <string>\n\n#include \"absl/strings/ascii.h\"\n#include \"absl/strings/str_cat.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/platform/errors.h\"\n\nnamespace tensorflow {\nnamespace text {\n\nnamespace {\ntemplate <typename SPLITS_TYPE>\nclass StringNGramsOp : public tensorflow::OpKernel {\n public:\n  explicit StringNGramsOp(tensorflow::OpKernelConstruction* context)\n      : tensorflow::OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(\"separator\", &separator_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"ngram_widths\", &ngram_widths_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"left_pad\", &left_pad_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"right_pad\", &right_pad_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"pad_width\", &pad_width_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"preserve_short_sequences\",\n                                             &preserve_short_));\n  }\n\n  int get_pad_width(const int ngram_width) const {\n    // Ngrams can be padded with either a fixed pad width or a dynamic pad\n    // width depending on the 'pad_width' arg, but in no case should the padding\n    // ever be wider than 'ngram_width' - 1.\n    return std::min(pad_width_ < 0 ? ngram_width - 1 : pad_width_,\n                    ngram_width - 1);\n  }\n\n  int get_num_ngrams(const int length, const int ngram_width) const {\n    int pad_width = get_pad_width(ngram_width);\n    return std::max(0, ((length + 2 * pad_width) - ngram_width) + 1);\n  }\n\n  void Compute(tensorflow::OpKernelContext* context) override {\n    const tensorflow::Tensor* data;\n    OP_REQUIRES_OK(context, context->input(\"data\", &data));\n    const auto& input_data = data->flat<tstring>().data();\n\n    const tensorflow::Tensor* splits;\n    OP_REQUIRES_OK(context, context->input(\"data_splits\", &splits));\n    const auto& splits_vec = splits->flat<SPLITS_TYPE>();\n\n    // Validate that the splits are valid indices into data, only if there are\n    // splits specified.\n    const int input_data_size = data->flat<tstring>().size();\n    const int splits_vec_size = splits_vec.size();\n    if (splits_vec_size > 0) {\n      int prev_split = splits_vec(0);\n      OP_REQUIRES(context, prev_split == 0,\n                  errors::InvalidArgument(\"First split value must be 0, got \",\n                                          prev_split));\n      for (int i = 1; i < splits_vec_size; ++i) {\n        bool valid_splits = splits_vec(i) >= prev_split;\n        valid_splits = valid_splits && (splits_vec(i) <= input_data_size);\n        OP_REQUIRES(context, valid_splits,\n                    errors::InvalidArgument(\n                        \"Invalid split value \", splits_vec(i), \", must be in [\",\n                        prev_split, \", \", input_data_size, \"]\"));\n        prev_split = splits_vec(i);\n      }\n      OP_REQUIRES(context, prev_split == input_data_size,\n                  errors::InvalidArgument(\n                      \"Last split value must be data size. Expected \",\n                      input_data_size, \", got \", prev_split));\n    }\n\n    int num_batch_items = splits_vec.size() - 1;\n    tensorflow::Tensor* ngrams_splits;\n    OP_REQUIRES_OK(\n        context, context->allocate_output(1, splits->shape(), &ngrams_splits));\n    auto ngrams_splits_data = ngrams_splits->flat<SPLITS_TYPE>().data();\n\n    // If there is no data or size, return an empty RT.\n    if (data->flat<tstring>().size() == 0 || splits_vec.size() == 0) {\n      tensorflow::Tensor* empty;\n      OP_REQUIRES_OK(context,\n                     context->allocate_output(0, data->shape(), &empty));\n      for (int i = 0; i <= num_batch_items; ++i) {\n        ngrams_splits_data[i] = 0;\n      }\n      return;\n    }\n\n    ngrams_splits_data[0] = 0;\n    for (int i = 1; i <= num_batch_items; ++i) {\n      int length = splits_vec(i) - splits_vec(i - 1);\n      int num_ngrams = 0;\n      for (int ngram_width : ngram_widths_)\n        num_ngrams += get_num_ngrams(length, ngram_width);\n      if (preserve_short_ && length > 0 && num_ngrams == 0) {\n        num_ngrams = 1;\n      }\n      ngrams_splits_data[i] = ngrams_splits_data[i - 1] + num_ngrams;\n    }\n\n    tensorflow::Tensor* ngrams;\n    OP_REQUIRES_OK(\n        context,\n        context->allocate_output(\n            0, TensorShape({ngrams_splits_data[num_batch_items]}), &ngrams));\n    auto ngrams_data = ngrams->flat<tstring>().data();\n\n    for (int i = 0; i < num_batch_items; ++i) {\n      auto data_start = &input_data[splits_vec(i)];\n      int output_start_idx = ngrams_splits_data[i];\n      for (int ngram_width : ngram_widths_) {\n        auto output_start = &ngrams_data[output_start_idx];\n        int length = splits_vec(i + 1) - splits_vec(i);\n        int num_ngrams = get_num_ngrams(length, ngram_width);\n        CreateNgrams(data_start, output_start, num_ngrams, ngram_width);\n        output_start_idx += num_ngrams;\n      }\n      // If we're preserving short sequences, check to see if no sequence was\n      // generated by comparing the current output start idx to the original\n      // one (ngram_splits_data). If no ngrams were generated, then they will\n      // be equal (since we increment output_start_idx by num_ngrams every\n      // time we create a set of ngrams.)\n      if (preserve_short_ && output_start_idx == ngrams_splits_data[i]) {\n        int data_length = splits_vec(i + 1) - splits_vec(i);\n        // One legitimate reason to not have any ngrams when preserve_short_\n        // is true is if the sequence itself is empty. In that case, move on.\n        if (data_length == 0) {\n          continue;\n        }\n        // We don't have to worry about dynamic padding sizes here: if padding\n        // was dynamic, every sequence would have had sufficient padding to\n        // generate at least one ngram.\n        int ngram_width = data_length + 2 * pad_width_;\n        auto output_start = &ngrams_data[output_start_idx];\n        int num_ngrams = 1;\n        CreateNgrams(data_start, output_start, num_ngrams, ngram_width);\n      }\n    }\n  }\n\n  void CreateNgrams(const tstring* data, tstring* output, int num_ngrams,\n                    int ngram_width) const {\n    for (int ngram_index = 0; ngram_index < num_ngrams; ++ngram_index) {\n      int pad_width = get_pad_width(ngram_width);\n      int left_padding = std::max(0, pad_width - ngram_index);\n      int right_padding =\n          std::max(0, pad_width - (num_ngrams - (ngram_index + 1)));\n      int num_tokens = ngram_width - (left_padding + right_padding);\n      int data_start_index = left_padding > 0 ? 0 : ngram_index - pad_width;\n\n      // Calculate the total expected size of the ngram so we can reserve the\n      // correct amount of space in the string.\n      int ngram_size = 0;\n      // Size of the left padding.\n      ngram_size += left_padding * left_pad_.length();\n      // Size of the tokens.\n      for (int n = 0; n < num_tokens; ++n) {\n        ngram_size += data[data_start_index + n].length();\n      }\n      // Size of the right padding.\n      ngram_size += right_padding * right_pad_.length();\n      // Size of the separators.\n      int num_separators = left_padding + right_padding + num_tokens - 1;\n      ngram_size += num_separators * separator_.length();\n\n      // Build the ngram.\n      tstring* ngram = &output[ngram_index];\n      ngram->reserve(ngram_size);\n      for (int n = 0; n < left_padding; ++n) {\n        ngram->append(left_pad_);\n        ngram->append(separator_);\n      }\n      // Only output first num_tokens - 1 pairs of data and separator\n      for (int n = 0; n < num_tokens - 1; ++n) {\n        ngram->append(data[data_start_index + n]);\n        ngram->append(separator_);\n      }\n      // Handle case when there are no tokens or no right padding as these can\n      // result in consecutive separators.\n      if (num_tokens > 0) {\n        // If we have tokens, then output last and then pair each separator with\n        // the right padding that follows, to ensure ngram ends either with the\n        // token or with the right pad.\n        ngram->append(data[data_start_index + num_tokens - 1]);\n        for (int n = 0; n < right_padding; ++n) {\n          ngram->append(separator_);\n          ngram->append(right_pad_);\n        }\n      } else {\n        // If we don't have tokens, then the last item inserted into the ngram\n        // has been the separator from the left padding loop above. Hence,\n        // output right pad and separator and make sure to finish with a\n        // padding, not a separator.\n        for (int n = 0; n < right_padding - 1; ++n) {\n          ngram->append(right_pad_);\n          ngram->append(separator_);\n        }\n        ngram->append(right_pad_);\n      }\n\n      // In debug mode only: validate that we've reserved enough space for the\n      // ngram.\n      DCHECK_EQ(ngram_size, ngram->size());\n    }\n  }\n\n  string separator_;\n  string left_pad_;\n  string right_pad_;\n  bool use_pad_;\n  bool extend_pad_;\n  bool preserve_short_;\n\n  std::vector<int> ngram_widths_;\n  int pad_width_;\n};\n\n}  // namespace\nREGISTER_KERNEL_BUILDER(Name(\"StringNGrams\")\n                            .Device(tensorflow::DEVICE_CPU)\n                            .TypeConstraint<int32>(\"Tsplits\"),\n                        StringNGramsOp<int32>);\nREGISTER_KERNEL_BUILDER(Name(\"StringNGrams\")\n                            .Device(tensorflow::DEVICE_CPU)\n                            .TypeConstraint<int64>(\"Tsplits\"),\n                        StringNGramsOp<int64>);\n\n}  // namespace text\n}  // namespace tensorflow\n", "/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include <vector>\n\n#include \"tensorflow/core/framework/fake_input.h\"\n#include \"tensorflow/core/framework/node_def_builder.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n#include \"tensorflow/core/framework/shape_inference_testutil.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/framework/tensor_testutil.h\"\n#include \"tensorflow/core/framework/types.pb.h\"\n#include \"tensorflow/core/kernels/ops_testutil.h\"\n#include \"tensorflow/core/lib/core/status.h\"\n#include \"tensorflow/core/lib/core/status_test_util.h\"\n\nnamespace tensorflow {\nnamespace text {\n\nusing tensorflow::FakeInput;\nusing tensorflow::NodeDefBuilder;\nusing tensorflow::Status;\nusing tensorflow::TensorShape;\n\nclass NgramKernelTest : public tensorflow::OpsTestBase {\n public:\n  void MakeOp(string separator, std::vector<int> ngram_width, string left_pad,\n              string right_pad, int pad_width, bool preserve) {\n    TF_ASSERT_OK(NodeDefBuilder(\"tested_op\", \"StringNGrams\")\n                     .Attr(\"separator\", separator)\n                     .Attr(\"ngram_widths\", ngram_width)\n                     .Attr(\"left_pad\", left_pad)\n                     .Attr(\"right_pad\", right_pad)\n                     .Attr(\"pad_width\", pad_width)\n                     .Attr(\"preserve_short_sequences\", preserve)\n                     .Input(FakeInput())\n                     .Input(FakeInput())\n                     .Finalize(node_def()));\n    TF_ASSERT_OK(InitOp());\n  }\n\n  void assert_string_equal(const std::vector<tstring> &expected,\n                           const Tensor &value) {\n    Tensor expected_tensor(allocator(), DT_STRING,\n                           TensorShape({static_cast<int64>(expected.size())}));\n    test::FillValues<tstring>(&expected_tensor, expected);\n    test::ExpectTensorEqual<tstring>(expected_tensor, value);\n  }\n  void assert_int64_equal(const std::vector<int64> &expected,\n                          const Tensor &value) {\n    Tensor expected_tensor(allocator(), DT_INT64,\n                           TensorShape({static_cast<int64>(expected.size())}));\n    test::FillValues<int64>(&expected_tensor, expected);\n    test::ExpectTensorEqual<int64>(expected_tensor, value);\n  }\n};\n\nTEST_F(NgramKernelTest, TestPaddedTrigrams) {\n  MakeOp(\"|\", {3}, \"LP\", \"RP\", -1, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(                             //\n      {\"LP|LP|a\", \"LP|a|b\", \"a|b|c\", \"b|c|d\", \"c|d|RP\", \"d|RP|RP\",  // 0\n       \"LP|LP|e\", \"LP|e|f\", \"e|f|RP\", \"f|RP|RP\"});                  // 1\n  std::vector<int64> expected_splits({0, 6, 10});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestPaddedBigramsAndTrigrams) {\n  MakeOp(\"|\", {2, 3}, \"LP\", \"RP\", -1, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(\n      {\"LP|a\", \"a|b\", \"b|c\", \"c|d\", \"d|RP\", \"LP|LP|a\", \"LP|a|b\", \"a|b|c\",\n       \"b|c|d\", \"c|d|RP\", \"d|RP|RP\",                                       // 0\n       \"LP|e\", \"e|f\", \"f|RP\", \"LP|LP|e\", \"LP|e|f\", \"e|f|RP\", \"f|RP|RP\"});  // 1\n  std::vector<int64> expected_splits({0, 11, 18});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestPaddedBigrams) {\n  MakeOp(\"|\", {2}, \"LP\", \"RP\", -1, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(      //\n      {\"LP|a\", \"a|b\", \"b|c\", \"c|d\", \"d|RP\",  // 0\n       \"LP|e\", \"e|f\", \"f|RP\"});              // 1\n  std::vector<int64> expected_splits({0, 5, 8});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestPaddingIsAtMostNGramSizeMinus1) {\n  MakeOp(\"|\", {2}, \"LP\", \"RP\", 4, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(      //\n      {\"LP|a\", \"a|b\", \"b|c\", \"c|d\", \"d|RP\",  // 0\n       \"LP|e\", \"e|f\", \"f|RP\"});              // 1\n  std::vector<int64> expected_splits({0, 5, 8});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestPaddedUnigramAndBigrams) {\n  MakeOp(\"|\", {1, 2}, \"LP\", \"RP\", -1, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(                          //\n      {\"a\", \"b\", \"c\", \"d\", \"LP|a\", \"a|b\", \"b|c\", \"c|d\", \"d|RP\",  // 0\n       \"e\", \"f\", \"LP|e\", \"e|f\", \"f|RP\"});                        // 1\n  std::vector<int64> expected_splits({0, 9, 14});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestOverlappingPaddedNGrams) {\n  // This test validates that n-grams with both left and right padding in a\n  // single ngram token are created correctly.\n  MakeOp(\"|\", {3}, \"LP\", \"RP\", -1, false);\n  // Batch items are:\n  // 0: \"a\"\n  // 1: \"b\", \"c\", \"d\"\n  // 2: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({4}), {0, 1, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(                    //\n      {\"LP|LP|a\", \"LP|a|RP\", \"a|RP|RP\",                    // ngrams for elem. 0\n       \"LP|LP|b\", \"LP|b|c\", \"b|c|d\", \"c|d|RP\", \"d|RP|RP\",  // ngrams for elem. 1\n       \"LP|LP|e\", \"LP|e|f\", \"e|f|RP\", \"f|RP|RP\"});         // ngrams for elem. 2\n  std::vector<int64> expected_splits({0, 3, 8, 12});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestOverlappingPaddedMultiCharNGrams) {\n  MakeOp(\"|\", {3}, \"LP\", \"RP\", -1, false);\n  // Batch items are:\n  // 0: \"a\"\n  // 1: \"b\", \"c\", \"d\"\n  // 2: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}),\n                             {\"aa\", \"bb\", \"cc\", \"dd\", \"ee\", \"ff\"});\n  AddInputFromArray<int64>(TensorShape({4}), {0, 1, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(                             //\n      {\"LP|LP|aa\", \"LP|aa|RP\", \"aa|RP|RP\",                          //\n       \"LP|LP|bb\", \"LP|bb|cc\", \"bb|cc|dd\", \"cc|dd|RP\", \"dd|RP|RP\",  //\n       \"LP|LP|ee\", \"LP|ee|ff\", \"ee|ff|RP\", \"ff|RP|RP\"});            //\n  std::vector<int64> expected_splits({0, 3, 8, 12});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestMultiOverlappingPaddedNGrams) {\n  // This test validates that n-grams with more than 1 padding value on each\n  // side are created correctly.\n  MakeOp(\"|\", {5}, \"LP\", \"RP\", -1, false);\n  // Batch items are:\n  // 0: \"a\"\n  AddInputFromArray<tstring>(TensorShape({1}), {\"a\"});\n  AddInputFromArray<int64>(TensorShape({2}), {0, 1});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"LP|LP|LP|LP|a\", \"LP|LP|LP|a|RP\",\n                                        \"LP|LP|a|RP|RP\", \"LP|a|RP|RP|RP\",\n                                        \"a|RP|RP|RP|RP\"});\n  std::vector<int64> expected_splits({0, 5});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestUnpaddedTrigrams) {\n  MakeOp(\"|\", {3}, \"\", \"\", 0, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"a|b|c\", \"b|c|d\"});\n  std::vector<int64> expected_splits({0, 2, 2});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestUnpaddedTrigramsWithEmptySequence) {\n  MakeOp(\"|\", {3}, \"\", \"\", 0, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({4}), {0, 4, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"a|b|c\", \"b|c|d\"});\n  std::vector<int64> expected_splits({0, 2, 2, 2});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestUnpaddedTrigramsWithPreserveShort) {\n  MakeOp(\"|\", {3}, \"\", \"\", 0, true);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"a|b|c\", \"b|c|d\", \"e|f\"});\n  std::vector<int64> expected_splits({0, 2, 3});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestUnpaddedTrigramsWithPreserveShortAndEmptySequence) {\n  MakeOp(\"|\", {3}, \"\", \"\", 0, true);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({4}), {0, 4, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"a|b|c\", \"b|c|d\", \"e|f\"});\n  std::vector<int64> expected_splits({0, 2, 2, 3});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestUnpaddedTrigramsAndQuadgramsWithPreserveShort) {\n  MakeOp(\"|\", {4, 3}, \"\", \"\", 0, true);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"a|b|c|d\", \"a|b|c\", \"b|c|d\", \"e|f\"});\n  std::vector<int64> expected_splits({0, 3, 4});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestUnpaddedBigramsAndTrigrams) {\n  MakeOp(\"|\", {2, 3}, \"\", \"\", 0, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(\n      {\"a|b\", \"b|c\", \"c|d\", \"a|b|c\", \"b|c|d\", \"e|f\"});\n  std::vector<int64> expected_splits({0, 5, 6});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestUnpaddedBigramsAndTrigramsWithPreserveShort) {\n  MakeOp(\"|\", {2, 3}, \"\", \"\", 0, true);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  // Note that in this case, because the bigram 'e|f' was already generated,\n  // the op will not generate a special preserve_short bigram.\n  std::vector<tstring> expected_values(\n      {\"a|b\", \"b|c\", \"c|d\", \"a|b|c\", \"b|c|d\", \"e|f\"});\n  std::vector<int64> expected_splits({0, 5, 6});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestUnpaddedTrigramsAndBigramsWithPreserveShort) {\n  MakeOp(\"|\", {3, 2}, \"\", \"\", 0, true);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  // Note that in this case, because the bigram 'e|f' was already generated,\n  // the op will not generate a special preserve_short bigram.\n  std::vector<tstring> expected_values(\n      {\"a|b|c\", \"b|c|d\", \"a|b\", \"b|c\", \"c|d\", \"e|f\"});\n  std::vector<int64> expected_splits({0, 5, 6});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestUnpaddedBigrams) {\n  MakeOp(\"|\", {2}, \"\", \"\", 0, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"a|b\", \"b|c\", \"c|d\", \"e|f\"});\n  std::vector<int64> expected_splits({0, 3, 4});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestOverlappingUnpaddedNGrams) {\n  MakeOp(\"|\", {3}, \"\", \"\", 0, false);\n  // Batch items are:\n  // 0: \"a\"\n  // 1: \"b\", \"c\", \"d\"\n  // 2: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({4}), {0, 1, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"b|c|d\"});\n  std::vector<int64> expected_splits({0, 0, 1, 1});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestOverlappingUnpaddedNGramsNoOutput) {\n  MakeOp(\"|\", {5}, \"\", \"\", 0, false);\n  // Batch items are:\n  // 0: \"a\"\n  // 1: \"b\", \"c\", \"d\"\n  // 2: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({4}), {0, 1, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({});\n  std::vector<int64> expected_splits({0, 0, 0, 0});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestSinglyPaddedTrigrams) {\n  MakeOp(\"|\", {3}, \"LP\", \"RP\", 1, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"LP|a|b\", \"a|b|c\", \"b|c|d\",\n                                        \"c|d|RP\",  //\n                                        \"LP|e|f\", \"e|f|RP\"});\n  std::vector<int64> expected_splits({0, 4, 6});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestSinglyPaddedBigrams) {\n  MakeOp(\"|\", {2}, \"LP\", \"RP\", 1, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"LP|a\", \"a|b\", \"b|c\", \"c|d\", \"d|RP\",  //\n                                        \"LP|e\", \"e|f\", \"f|RP\"});\n  std::vector<int64> expected_splits({0, 5, 8});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestSinglyPaddedBigramsAnd5grams) {\n  MakeOp(\"|\", {2, 5}, \"LP\", \"RP\", 1, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(                                  //\n      {\"LP|a\", \"a|b\", \"b|c\", \"c|d\", \"d|RP\", \"LP|a|b|c|d\", \"a|b|c|d|RP\",  //\n       \"LP|e\", \"e|f\", \"f|RP\"});\n  std::vector<int64> expected_splits({0, 7, 10});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestSinglyPadded5gramsWithPreserveShort) {\n  MakeOp(\"|\", {5}, \"LP\", \"RP\", 1, true);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(  //\n      {\"LP|a|b|c|d\", \"a|b|c|d|RP\",       //\n       \"LP|e|f|RP\"});\n  std::vector<int64> expected_splits({0, 2, 3});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestOverlappingSinglyPaddedNGrams) {\n  MakeOp(\"|\", {3}, \"LP\", \"RP\", 1, false);\n  // Batch items are:\n  // 0: \"a\"\n  // 1: \"b\", \"c\", \"d\"\n  // 2: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({4}), {0, 1, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(\n      {\"LP|a|RP\",                    // ngrams for elem. 0\n       \"LP|b|c\", \"b|c|d\", \"c|d|RP\",  // ngrams for elem. 1\n       \"LP|e|f\", \"e|f|RP\"});         // ngrams for elem. 2\n  std::vector<int64> expected_splits({0, 1, 4, 6});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestOverlappingSinglyPaddedNGramsNoOutput) {\n  MakeOp(\"|\", {5}, \"LP\", \"RP\", 1, false);\n  // Batch items are:\n  // 0: \"a\"\n  // 1: \"b\", \"c\", \"d\"\n  // 2: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({4}), {0, 1, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"LP|b|c|d|RP\"});\n  std::vector<int64> expected_splits({0, 0, 1, 1});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestSinglyPaddedUnigrams) {\n  MakeOp(\"|\", {1}, \"LP\", \"RP\", 1, false);\n  // Batch items are:\n  // 0: \"a\", \"b\", \"c\", \"d\"\n  // 1: \"e\", \"f\"\n  AddInputFromArray<tstring>(TensorShape({6}), {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 4, 6});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"});\n  std::vector<int64> expected_splits({0, 4, 6});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestEmptyInput) {\n  MakeOp(\"|\", {1}, \"LP\", \"RP\", 3, false);\n  AddInputFromArray<tstring>(TensorShape({0}), {});\n  AddInputFromArray<int64>(TensorShape({0}), {});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({});\n  std::vector<int64> expected_splits({});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestNoTokens) {\n  MakeOp(\"|\", {3}, \"L\", \"R\", -1, false);\n  // Batch items are:\n  // 0:\n  // 1: \"a\"\n  AddInputFromArray<tstring>(TensorShape({1}), {\"a\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 0, 1});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values(\n      {\"L|L|R\", \"L|R|R\",             // no input in first split\n       \"L|L|a\", \"L|a|R\", \"a|R|R\"});  // second split\n  std::vector<int64> expected_splits({0, 2, 5});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, TestNoTokensNoPad) {\n  MakeOp(\"|\", {3}, \"\", \"\", 0, false);\n  // Batch items are:\n  // 0:\n  // 1: \"a\"\n  AddInputFromArray<tstring>(TensorShape({1}), {\"a\"});\n  AddInputFromArray<int64>(TensorShape({3}), {0, 0, 1});\n  TF_ASSERT_OK(RunOpKernel());\n\n  std::vector<tstring> expected_values({});\n  std::vector<int64> expected_splits({0, 0, 0});\n\n  assert_string_equal(expected_values, *GetOutput(0));\n  assert_int64_equal(expected_splits, *GetOutput(1));\n}\n\nTEST_F(NgramKernelTest, ShapeFn) {\n  ShapeInferenceTestOp op(\"StringNGrams\");\n  INFER_OK(op, \"?;?\", \"[?];[?]\");\n  INFER_OK(op, \"[1];?\", \"[?];[?]\");\n  INFER_OK(op, \"[1];[2]\", \"[?];in1\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"[];?\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"?;[]\");\n}\n\n}  // namespace text\n}  // namespace tensorflow\n"], "filenames": ["tensorflow/core/kernels/string_ngrams_op.cc", "tensorflow/core/kernels/string_ngrams_op_test.cc"], "buggy_code_start_loc": [64, 544], "buggy_code_end_loc": [184, 544], "fixing_code_start_loc": [64, 545], "fixing_code_end_loc": [214, 579], "type": "CWE-787", "message": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a heap buffer overflow by passing crafted inputs to `tf.raw_ops.StringNGrams`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/1cdd4da14282210cc759e468d9781741ac7d01bf/tensorflow/core/kernels/string_ngrams_op.cc#L171-L185) fails to consider corner cases where input would be split in such a way that the generated tokens should only contain padding elements. If input is such that `num_tokens` is 0, then, for `data_start_index=0` (when left padding is present), the marked line would result in reading `data[-1]`. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.", "other": {"cve": {"id": "CVE-2021-29542", "sourceIdentifier": "security-advisories@github.com", "published": "2021-05-14T20:15:12.537", "lastModified": "2022-04-25T20:03:53.697", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a heap buffer overflow by passing crafted inputs to `tf.raw_ops.StringNGrams`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/1cdd4da14282210cc759e468d9781741ac7d01bf/tensorflow/core/kernels/string_ngrams_op.cc#L171-L185) fails to consider corner cases where input would be split in such a way that the generated tokens should only contain padding elements. If input is such that `num_tokens` is 0, then, for `data_start_index=0` (when left padding is present), the marked line would result in reading `data[-1]`. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto de extremo a extremo para el aprendizaje autom\u00e1tico.&#xa0;Un atacante puede causar un desbordamiento del b\u00fafer al pasar entradas dise\u00f1adas a \"tf.raw_ops.StringNGrams\".&#xa0;Esto es debido a que la implementaci\u00f3n (https://github.com/tensorflow/tensorflow/blob/1cdd4da14282210cc759e468d9781741ac7d01bf/tensorflow/core/kernels/string_ngrams_op.cc#L171-L185) no considera los casos de esquina donde la entrada se dividir\u00eda de tal manera que los tokens generados solo deben contener elementos de relleno.&#xa0;Si la entrada es tal que \"num_tokens\" es 0, entonces, para \"data_start_index=0\" (cuando el relleno a la izquierda est\u00e1 presente), la l\u00ednea marcada dar\u00eda como resultado la lectura de \"data [-1]\".&#xa0;La correcci\u00f3n ser\u00e1 incluida en TensorFlow versi\u00f3n 2.5.0.&#xa0;Tambi\u00e9n seleccionaremos este commit en TensorFlow versi\u00f3n 2.4.2, TensorFlow versi\u00f3n 2.3.3, TensorFlow versi\u00f3n 2.2.3 y TensorFlow versi\u00f3n 2.1.4, ya que estos tambi\u00e9n est\u00e1n afectados y a\u00fan est\u00e1n en el rango compatible"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:H/PR:L/UI:N/S:U/C:N/I:N/A:L", "attackVector": "LOCAL", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "LOW", "baseScore": 2.5, "baseSeverity": "LOW"}, "exploitabilityScore": 1.0, "impactScore": 1.4}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 2.1}, "baseSeverity": "LOW", "exploitabilityScore": 3.9, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-787"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-131"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.1.4", "matchCriteriaId": "323ABCCE-24EB-47CC-87F6-48C101477587"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.2.0", "versionEndExcluding": "2.2.3", "matchCriteriaId": "64ABA90C-0649-4BB0-89C9-83C14BBDCC0F"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.3.0", "versionEndExcluding": "2.3.3", "matchCriteriaId": "0F83E0CF-CBF6-4C24-8683-3E7A5DC95BA9"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.4.0", "versionEndExcluding": "2.4.2", "matchCriteriaId": "8259531B-A8AC-4F8B-B60F-B69DE4767C03"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/ba424dd8f16f7110eea526a8086f1a155f14f22b", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-4hrh-9vmp-2jgg", "source": "security-advisories@github.com", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/ba424dd8f16f7110eea526a8086f1a155f14f22b"}}
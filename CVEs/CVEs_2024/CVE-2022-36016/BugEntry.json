{"buggy_code": ["/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/framework/full_type_util.h\"\n\n#include <algorithm>\n#include <string>\n\n#include \"absl/container/flat_hash_map.h\"\n#include \"tensorflow/core/framework/attr_value.pb.h\"\n#include \"tensorflow/core/framework/full_type.pb.h\"\n#include \"tensorflow/core/framework/node_def.pb.h\"\n#include \"tensorflow/core/framework/node_def_util.h\"\n#include \"tensorflow/core/framework/op_def.pb.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/platform/errors.h\"\n#include \"tensorflow/core/platform/hash.h\"\n#include \"tensorflow/core/platform/statusor.h\"\n#include \"tensorflow/core/protobuf/error_codes.pb.h\"\n\nnamespace tensorflow {\n\nnamespace full_type {\n\nOpTypeConstructor NoOp() {\n  return nullptr;\n}\n\nOpTypeConstructor NoOutputs() {\n  return [](OpDef* op_def) {\n    op_def->mutable_output_arg();\n    return OkStatus();\n  };\n}\n\nOpTypeConstructor Nullary(FullTypeId t) {\n  return [t](OpDef* op_def) {\n    FullTypeDef* tdef =\n        op_def->mutable_output_arg(0)->mutable_experimental_full_type();\n    tdef->set_type_id(t);\n    return OkStatus();\n  };\n}\n\nOpTypeConstructor Unary(FullTypeId t, const string& var_name) {\n  return [t, var_name](OpDef* op_def) {\n    FullTypeDef* tdef =\n        op_def->mutable_output_arg(0)->mutable_experimental_full_type();\n    tdef->set_type_id(t);\n\n    FullTypeDef* arg = tdef->add_args();\n    arg->set_type_id(TFT_VAR);\n    arg->set_s(var_name);\n\n    return OkStatus();\n  };\n}\n\nOpTypeConstructor UnaryGeneric(FullTypeId t) {\n  return [t](OpDef* op_def) {\n    FullTypeDef* tdef =\n        op_def->mutable_output_arg(0)->mutable_experimental_full_type();\n    tdef->set_type_id(t);\n\n    FullTypeDef* arg = tdef->add_args();\n    arg->set_type_id(TFT_ANY);\n\n    return OkStatus();\n  };\n}\n\nOpTypeConstructor UnaryTensorContainer(FullTypeId t, FullTypeId dtype) {\n  return [t, dtype](OpDef* op_def) {\n    FullTypeDef* tdef =\n        op_def->mutable_output_arg(0)->mutable_experimental_full_type();\n    tdef->set_type_id(t);\n\n    FullTypeDef* arg = tdef->add_args();\n    arg->set_type_id(TFT_TENSOR);\n    FullTypeDef* targ = arg->add_args();\n    targ->set_type_id(dtype);\n\n    return OkStatus();\n  };\n}\n\nOpTypeConstructor UnaryTensorContainer(FullTypeId t, const string& var_name) {\n  return [t, var_name](OpDef* op_def) {\n    FullTypeDef* tdef =\n        op_def->mutable_output_arg(0)->mutable_experimental_full_type();\n    tdef->set_type_id(t);\n\n    FullTypeDef* targ = tdef->add_args();\n    targ->set_type_id(TFT_TENSOR);\n    FullTypeDef* varg = targ->add_args();\n    varg->set_type_id(TFT_VAR);\n    varg->set_s(var_name);\n\n    return OkStatus();\n  };\n}\n\nOpTypeConstructor VariadicTensorContainer(FullTypeId t,\n                                          const string& var_name) {\n  return [t, var_name](OpDef* op_def) {\n    FullTypeDef* tdef =\n        op_def->mutable_output_arg(0)->mutable_experimental_full_type();\n    tdef->set_type_id(t);\n\n    FullTypeDef* for_each = tdef->add_args();\n    for_each->set_type_id(TFT_FOR_EACH);\n    for_each->add_args()->set_type_id(TFT_PRODUCT);\n\n    FullTypeDef* tpl = for_each->add_args();\n    tpl->set_type_id(TFT_TENSOR);\n    FullTypeDef* targ = tpl->add_args();\n    targ->set_type_id(TFT_VAR);\n    targ->set_s(var_name);\n\n    FullTypeDef* tvar = for_each->add_args();\n    tvar->set_type_id(TFT_VAR);\n    tvar->set_s(var_name);\n\n    return OkStatus();\n  };\n}\n\nnamespace {\n\ntypedef absl::flat_hash_map<StringPiece, const AttrValue*> AttrMap;\n\ninline Status SubstituteFromAttrs(AttrMap& attrs, FullTypeDef& t);\n\nStatus SubstituteVar(AttrMap& attrs, FullTypeDef& t) {\n  DCHECK_EQ(t.args_size(), 0);\n\n  StringPiece var_name = t.s();\n  if (!attrs.contains(var_name)) {\n    return Status(\n        error::INVALID_ARGUMENT,\n        absl::StrCat(\"could not find an attribute for key '\", var_name, \"'\"));\n  }\n  const AttrValue* attr = attrs.at(var_name);\n\n  const auto attr_type = attr->value_case();\n  if (attr_type == AttrValue::kType) {\n    map_dtype_to_tensor(attr->type(), t);\n  } else if (attr_type == AttrValue::kList) {\n    const auto& attr_list = attr->list();\n    if (attr_list.type_size() != 1) {\n      return Status(error::UNIMPLEMENTED,\n                    absl::StrCat(\"lists or other than one type element\\n\",\n                                 attr_list.DebugString(), \"\\nkey=\", var_name));\n    }\n    map_dtype_to_tensor(attr_list.type(0), t);\n  } else {\n    return Status(error::UNIMPLEMENTED,\n                  absl::StrCat(\"unsupported attribute type \",\n                               attr->DebugString(), \" for name \", var_name));\n  }\n  t.clear_s();\n  return OkStatus();\n}\n\nStatus SubstituteForEach(AttrMap& attrs, FullTypeDef& t) {\n  DCHECK_EQ(t.args_size(), 3);\n\n  const auto& cont = t.args(0);\n  const auto& tmpl = t.args(1);\n  const auto& t_var = t.args(2);\n\n  StringPiece var_name = t_var.s();\n  if (!attrs.contains(var_name)) {\n    return Status(\n        error::INVALID_ARGUMENT,\n        absl::StrCat(\"could not find an attribute for key '\", var_name, \"'\"));\n  }\n  const AttrValue* attr = attrs.at(var_name);\n\n  FullTypeDef result;\n  result.set_type_id(cont.type_id());\n\n  const auto attr_type = attr->value_case();\n  if (attr_type == AttrValue::kType) {\n    FullTypeDef* target = result.add_args();\n    *target = tmpl;\n    TF_RETURN_WITH_CONTEXT_IF_ERROR(\n        SubstituteFromAttrs(attrs, *target), \"while substituting '\", var_name,\n        \"' from\\n\", attr->DebugString(), \"\\ninto \", target->DebugString());\n\n  } else if (attr_type == AttrValue::kList) {\n    const auto& attr_list = attr->list();\n    int tsize = attr_list.type_size();\n    if (tsize == 0) {\n      return Status(error::UNIMPLEMENTED,\n                    absl::StrCat(\"unsupported list attribute type\\n\",\n                                 attr_list.DebugString(), \"\\nkey=\", var_name));\n    }\n    AttrValue replacement;\n    attrs[var_name] = &replacement;\n    for (int i = 0; i < tsize; i++) {\n      replacement.set_type(attr_list.type(i));\n      FullTypeDef* target = result.add_args();\n      *target = tmpl;\n      TF_RETURN_WITH_CONTEXT_IF_ERROR(SubstituteFromAttrs(attrs, *target),\n                                      \"while substituting '\", var_name,\n                                      \"' from\\n\", attr->DebugString(), \"\\n[\", i,\n                                      \"] into\\n\", target->DebugString());\n    }\n    // In case of error, it's ok for the attributes map to remain in an invalid\n    // state.\n    attrs[var_name] = attr;\n\n  } else {\n    return Status(error::UNIMPLEMENTED,\n                  absl::StrCat(\"unsupported attribute type\\n\",\n                               attr->DebugString(), \"\\nfor name \", var_name));\n  }\n  t = result;\n  return OkStatus();\n}\n\nStatus SubstituteGeneric(AttrMap& attrs, FullTypeDef& t) {\n  int nargs = t.args_size();\n  for (int j = 0; j < nargs; j++) {\n    FullTypeDef* arg_t = t.mutable_args(j);\n    TF_RETURN_WITH_CONTEXT_IF_ERROR(SubstituteFromAttrs(attrs, *arg_t),\n                                    \"while substituting arg \", j, \": \",\n                                    arg_t->DebugString());\n\n    // Special case for DT_VARIANT tensors. We leave those unset to avoid even\n    // more special casing downstream.\n    if (arg_t->type_id() == TFT_TENSOR && arg_t->args_size() &&\n        arg_t->args(0).type_id() == TFT_LEGACY_VARIANT) {\n      t.clear_args();\n      break;\n    }\n  }\n  return OkStatus();\n}\n\ninline Status SubstituteFromAttrs(AttrMap& attrs, FullTypeDef& t) {\n  // Resolve dependent types. The convention for op registrations is to use\n  // attributes as type variables.\n  // See https://www.tensorflow.org/guide/create_op#type_polymorphism.\n  // Once the op signature can be defined entirely in FullType, this\n  // convention can be deprecated.\n  //\n  // Note: While this code performs some basic verifications, it generally\n  // assumes consistent op defs and attributes. If more complete\n  // verifications are needed, they should be done by separately, and in a\n  // way that can be reused for type inference.\n  switch (t.type_id()) {\n    case TFT_VAR:\n      return SubstituteVar(attrs, t);\n\n    case TFT_FOR_EACH:\n      return SubstituteForEach(attrs, t);\n\n    default:\n      return SubstituteGeneric(attrs, t);\n  }\n  return OkStatus();\n}\n\n}  // namespace\n\nStatus SpecializeType(const AttrSlice& attrs, const OpDef& op_def,\n                      FullTypeDef& target) {\n  target.Clear();\n  target.set_type_id(TFT_PRODUCT);\n\n  AttrMap map;\n  for (const auto& attr : attrs) {\n    map.emplace(attr.first, &attr.second);\n  }\n\n  int nargs = op_def.output_arg_size();\n  for (int i = 0; i < nargs; i++) {\n    auto& t = *(target.add_args());\n    t = op_def.output_arg(i).experimental_full_type();\n    TF_RETURN_WITH_CONTEXT_IF_ERROR(\n        SubstituteFromAttrs(map, t), \"while expanding vars of\\n\",\n        t.DebugString(), \"\\nfrom\\n\", attrs.SummarizeNode());\n  }\n\n  return OkStatus();\n}\n\nconst FullTypeDef& GetArgDefaultUnset(const FullTypeDef& t, int i) {\n  static FullTypeDef* unset_type = []() {\n    FullTypeDef* t = new FullTypeDef();\n    return t;\n  }();\n\n  if (i < t.args_size()) {\n    return t.args(i);\n  }\n  return *unset_type;\n}\n\nconst FullTypeDef& GetArgDefaultAny(const FullTypeDef& t, int i) {\n  static FullTypeDef* any_type = []() {\n    FullTypeDef* t = new FullTypeDef();\n    t->set_type_id(TFT_ANY);\n    return t;\n  }();\n\n  if (i < t.args_size()) {\n    const FullTypeDef& f_val = t.args(i);\n    if (f_val.type_id() == TFT_UNSET) {\n      return *any_type;\n    }\n    return f_val;\n  }\n  return *any_type;\n}\n\nbool IsEqual(const FullTypeDef& lhs, const FullTypeDef& rhs) {\n  if (lhs.type_id() != rhs.type_id()) {\n    return false;\n  }\n  const auto& lhs_s = lhs.s();\n  const auto& rhs_s = rhs.s();\n  if (lhs_s.empty()) {\n    if (!rhs_s.empty()) {\n      return false;\n    }\n  } else if (rhs_s != lhs_s) {\n    return false;\n  }\n  for (int i = 0; i < std::max(lhs.args_size(), rhs.args_size()); i++) {\n    const FullTypeDef& lhs_arg = GetArgDefaultAny(lhs, i);\n    const FullTypeDef& rhs_arg = GetArgDefaultAny(rhs, i);\n\n    if (!IsEqual(lhs_arg, rhs_arg)) {\n      return false;\n    }\n  }\n  return true;\n}\n\nuint64_t Hash(const FullTypeDef& arg) {\n  // Following style of IsEqual above and walking across FullTypeDef.\n  uint64_t val = Hash64Combine(arg.type_id(), 0);\n\n  const auto& arg_s = arg.s();\n  val = Hash64Combine(val, Hash64(arg_s));\n  for (int i = 0, e = arg.args_size(); i < e; ++i) {\n    const FullTypeDef& arg_arg = GetArgDefaultAny(arg, i);\n    val = Hash64Combine(val, Hash(arg_arg));\n  }\n\n  return val;\n}\n\nbool IsSubtype(const FullTypeDef& lhs, const FullTypeDef& rhs, bool covariant) {\n  // Rule: ANY is a supertype of all types.\n  if (rhs.type_id() == TFT_ANY) {\n    return true;\n  }\n  // Compatibility rule: UNSET is treated as ANY for the purpose of subtyping.\n  if (rhs.type_id() == TFT_UNSET) {\n    return true;\n  }\n  // Compatibility rule: TENSOR[LEGACY_VARIANT] is treated as ANY for the\n  // purpose of subtyping.\n  if ((rhs.type_id() == TFT_TENSOR) &&\n      (GetArgDefaultUnset(rhs, 0).type_id() == TFT_LEGACY_VARIANT)) {\n    return true;\n  }\n  // Rule: encodings are subtypes of the encoding type.\n  if (lhs.type_id() == TFT_ENCODED) {\n    return IsSubtype(GetArgDefaultAny(lhs, 1), rhs, true);\n  }\n\n  // Default rule: type IDs must match.\n  if (lhs.type_id() != rhs.type_id()) {\n    return false;\n  }\n\n  // Arguments must be subtypes of one another.\n  for (int i = 0; i < std::max(lhs.args_size(), rhs.args_size()); i++) {\n    const FullTypeDef& lhs_arg = GetArgDefaultAny(lhs, i);\n    const FullTypeDef& rhs_arg = GetArgDefaultAny(rhs, i);\n\n    if (covariant) {\n      if (!IsSubtype(lhs_arg, rhs_arg)) {\n        return false;\n      }\n    } else {\n      if (!IsSubtype(rhs_arg, lhs_arg)) {\n        return false;\n      }\n    }\n  }\n\n  // Invariant: type IDs are equal, and all args are subtype of one another.\n  return true;\n}\n\n}  // namespace full_type\n\n}  // namespace tensorflow\n", "/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/framework/attr_value.pb.h\"\n#include \"tensorflow/core/framework/full_type.pb.h\"\n#include \"tensorflow/core/framework/node_def.pb.h\"\n#include \"tensorflow/core/framework/node_def_util.h\"\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/types.pb.h\"\n#include \"tensorflow/core/lib/core/status_test_util.h\"\n#include \"tensorflow/core/platform/test.h\"\n\nnamespace tensorflow {\n\nnamespace full_type {\n\nnamespace {\n\n// TODO(mdan): Use ParseTextProto, ProtoEquals when available in a clean lib.\n\nTEST(Nullary, Basic) {\n  OpTypeConstructor ctor = Nullary(TFT_TENSOR);\n\n  OpDef op;\n  op.add_output_arg();\n\n  TF_ASSERT_OK(ctor(&op));\n\n  const FullTypeDef& t = op.output_arg(0).experimental_full_type();\n  EXPECT_EQ(t.type_id(), TFT_TENSOR);\n  EXPECT_EQ(t.args_size(), 0);\n}\n\nTEST(Unary, Basic) {\n  OpTypeConstructor ctor = Unary(TFT_TENSOR, \"T\");\n\n  OpDef op;\n  op.add_output_arg();\n\n  TF_ASSERT_OK(ctor(&op));\n\n  const FullTypeDef& t = op.output_arg(0).experimental_full_type();\n  EXPECT_EQ(t.type_id(), TFT_TENSOR);\n  EXPECT_EQ(t.args_size(), 1);\n  EXPECT_EQ(t.args(0).type_id(), TFT_VAR);\n  EXPECT_EQ(t.args(0).args_size(), 0);\n  EXPECT_EQ(t.args(0).s(), \"T\");\n}\n\nTEST(UnaryGeneric, Basic) {\n  OpTypeConstructor ctor = UnaryGeneric(TFT_TENSOR);\n\n  OpDef op;\n  op.add_output_arg();\n\n  TF_ASSERT_OK(ctor(&op));\n\n  const FullTypeDef& t = op.output_arg(0).experimental_full_type();\n  EXPECT_EQ(t.type_id(), TFT_TENSOR);\n  EXPECT_EQ(t.args_size(), 1);\n  EXPECT_EQ(t.args(0).type_id(), TFT_ANY);\n  EXPECT_EQ(t.args(0).args_size(), 0);\n}\n\nTEST(UnaryTensorContainer, Fixed) {\n  OpTypeConstructor ctor = UnaryTensorContainer(TFT_ARRAY, TFT_INT32);\n\n  OpDef op;\n  op.add_output_arg();\n\n  TF_ASSERT_OK(ctor(&op));\n\n  const FullTypeDef& t = op.output_arg(0).experimental_full_type();\n  EXPECT_EQ(t.type_id(), TFT_ARRAY);\n  EXPECT_EQ(t.args_size(), 1);\n  EXPECT_EQ(t.args(0).type_id(), TFT_TENSOR);\n  EXPECT_EQ(t.args(0).args_size(), 1);\n  EXPECT_EQ(t.args(0).args(0).type_id(), TFT_INT32);\n  EXPECT_EQ(t.args(0).args(0).args_size(), 0);\n}\n\nTEST(UnaryTensorContainer, Dependent) {\n  OpTypeConstructor ctor = UnaryTensorContainer(TFT_ARRAY, \"T\");\n\n  OpDef op;\n  op.add_output_arg();\n\n  TF_ASSERT_OK(ctor(&op));\n\n  const FullTypeDef& t = op.output_arg(0).experimental_full_type();\n  EXPECT_EQ(t.type_id(), TFT_ARRAY);\n  EXPECT_EQ(t.args_size(), 1);\n  EXPECT_EQ(t.args(0).type_id(), TFT_TENSOR);\n  EXPECT_EQ(t.args(0).args_size(), 1);\n  EXPECT_EQ(t.args(0).args(0).type_id(), TFT_VAR);\n  EXPECT_EQ(t.args(0).args(0).args_size(), 0);\n  EXPECT_EQ(t.args(0).args(0).s(), \"T\");\n}\n\nTEST(VariadicTensorContainer, Basic) {\n  OpTypeConstructor ctor = VariadicTensorContainer(TFT_ARRAY, \"T\");\n\n  OpDef op;\n  op.add_output_arg();\n\n  TF_ASSERT_OK(ctor(&op));\n\n  const FullTypeDef& t = op.output_arg(0).experimental_full_type();\n  EXPECT_EQ(t.type_id(), TFT_ARRAY);\n  EXPECT_EQ(t.args_size(), 1);\n  EXPECT_EQ(t.args(0).type_id(), TFT_FOR_EACH);\n  EXPECT_EQ(t.args(0).args_size(), 3);\n  EXPECT_EQ(t.args(0).args(0).type_id(), TFT_PRODUCT);\n  EXPECT_EQ(t.args(0).args(0).args_size(), 0);\n  EXPECT_EQ(t.args(0).args(1).type_id(), TFT_TENSOR);\n  EXPECT_EQ(t.args(0).args(1).args_size(), 1);\n  EXPECT_EQ(t.args(0).args(1).args(0).type_id(), TFT_VAR);\n  EXPECT_EQ(t.args(0).args(1).args(0).args_size(), 0);\n  EXPECT_EQ(t.args(0).args(1).args(0).s(), \"T\");\n  EXPECT_EQ(t.args(0).args(2).type_id(), TFT_VAR);\n  EXPECT_EQ(t.args(0).args(2).args_size(), 0);\n  EXPECT_EQ(t.args(0).args(2).s(), \"T\");\n}\n\nTEST(SpecializeType, Fixed) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_ARRAY);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(0)->add_args()->set_type_id(TFT_INT32);\n  t->add_args()->set_type_id(TFT_DATASET);\n  t->mutable_args(1)->add_args()->set_type_id(TFT_FLOAT);\n\n  AttrSlice empty;\n\n  FullTypeDef ft;\n  TF_ASSERT_OK(SpecializeType(empty, op, ft));\n\n  EXPECT_EQ(ft.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(ft.args_size(), 1);\n\n  const FullTypeDef& t_actual = ft.args(0);\n  EXPECT_EQ(t_actual.type_id(), TFT_ARRAY);\n  EXPECT_EQ(t_actual.args_size(), 2);\n  EXPECT_EQ(t_actual.args(0).type_id(), TFT_TENSOR);\n  EXPECT_EQ(t_actual.args(0).args_size(), 1);\n  EXPECT_EQ(t_actual.args(0).args(0).type_id(), TFT_INT32);\n  EXPECT_EQ(t_actual.args(0).args(0).args_size(), 0);\n  EXPECT_EQ(t_actual.args(1).type_id(), TFT_DATASET);\n  EXPECT_EQ(t_actual.args(1).args_size(), 1);\n  EXPECT_EQ(t_actual.args(1).args(0).type_id(), TFT_FLOAT);\n  EXPECT_EQ(t_actual.args(1).args(0).args_size(), 0);\n}\n\nTEST(SpecializeType, Idempotence) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_ARRAY);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(0)->add_args()->set_type_id(TFT_INT32);\n  t->add_args()->set_type_id(TFT_DATASET);\n  t->mutable_args(1)->add_args()->set_type_id(TFT_FLOAT);\n\n  AttrSlice empty;\n\n  FullTypeDef ft;\n  TF_ASSERT_OK(SpecializeType(empty, op, ft));\n  TF_ASSERT_OK(SpecializeType(empty, op, ft));\n\n  EXPECT_EQ(ft.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(ft.args_size(), 1);\n}\n\nTEST(SpecializeType, VarExpandsFromSingleAttribute) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_ARRAY);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(0)->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(0)->mutable_args(0)->set_s(\"T\");\n\n  AttrValue attr;\n  attr.set_type(DT_INT32);\n  NodeDef ndef;\n  (*ndef.mutable_attr())[\"T\"] = attr;\n\n  AttrSlice attrs(ndef);\n\n  FullTypeDef ft;\n  TF_ASSERT_OK(SpecializeType(attrs, op, ft));\n\n  EXPECT_EQ(ft.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(ft.args_size(), 1);\n\n  const FullTypeDef& t_actual = ft.args(0);\n  EXPECT_EQ(t_actual.type_id(), TFT_ARRAY);\n  EXPECT_EQ(t_actual.args_size(), 1);\n  EXPECT_EQ(t_actual.args(0).type_id(), TFT_TENSOR);\n  EXPECT_EQ(t_actual.args(0).args_size(), 1);\n  EXPECT_EQ(t_actual.args(0).args(0).type_id(), TFT_INT32);\n  EXPECT_EQ(t_actual.args(0).args(0).args_size(), 0);\n}\n\nTEST(SpecializeType, VarExpandsFromSingleElementTypeListAttribute) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_ARRAY);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(0)->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(0)->mutable_args(0)->set_s(\"T\");\n\n  AttrValue attr;\n  attr.mutable_list()->add_type(DT_INT32);\n  NodeDef ndef;\n  (*ndef.mutable_attr())[\"T\"] = attr;\n\n  AttrSlice attrs(ndef);\n\n  FullTypeDef ft;\n  TF_ASSERT_OK(SpecializeType(attrs, op, ft));\n\n  EXPECT_EQ(ft.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(ft.args_size(), 1);\n\n  const FullTypeDef& t_actual = ft.args(0);\n  EXPECT_EQ(t_actual.type_id(), TFT_ARRAY);\n  EXPECT_EQ(t_actual.args_size(), 1);\n  EXPECT_EQ(t_actual.args(0).type_id(), TFT_TENSOR);\n  EXPECT_EQ(t_actual.args(0).args_size(), 1);\n  EXPECT_EQ(t_actual.args(0).args(0).type_id(), TFT_INT32);\n  EXPECT_EQ(t_actual.args(0).args(0).args_size(), 0);\n}\n\nTEST(SpecializeType, VarRejectsMultipleElementTypeListAttribute) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_ARRAY);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(0)->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(0)->mutable_args(0)->set_s(\"T\");\n\n  AttrValue attr;\n  attr.mutable_list()->add_type(DT_INT32);\n  attr.mutable_list()->add_type(DT_FLOAT);\n  NodeDef ndef;\n  (*ndef.mutable_attr())[\"T\"] = attr;\n\n  AttrSlice attrs(ndef);\n\n  FullTypeDef ft;\n  EXPECT_FALSE(SpecializeType(attrs, op, ft).ok());\n}\n\nTEST(SpecializeType, VarRejectsEmptyTypeListAttribute) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_ARRAY);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(0)->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(0)->mutable_args(0)->set_s(\"T\");\n\n  AttrValue attr;\n  attr.mutable_list();\n  NodeDef ndef;\n  (*ndef.mutable_attr())[\"T\"] = attr;\n\n  AttrSlice attrs(ndef);\n\n  FullTypeDef ft;\n  EXPECT_FALSE(SpecializeType(attrs, op, ft).ok());\n}\n\nTEST(SpecializeType, ForEachExpandsFromSingleAttribute) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_FOR_EACH);\n  t->add_args()->set_type_id(TFT_PRODUCT);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(1)->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(1)->mutable_args(0)->set_s(\"T\");\n  t->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(2)->set_s(\"T\");\n\n  AttrValue attr;\n  attr.set_type(DT_INT32);\n  NodeDef ndef;\n  (*ndef.mutable_attr())[\"T\"] = attr;\n\n  AttrSlice attrs(ndef);\n\n  FullTypeDef ft;\n  TF_ASSERT_OK(SpecializeType(attrs, op, ft));\n\n  EXPECT_EQ(ft.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(ft.args_size(), 1);\n\n  const FullTypeDef& t_actual = ft.args(0);\n  EXPECT_EQ(t_actual.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(t_actual.args_size(), 1);\n  EXPECT_EQ(t_actual.args(0).type_id(), TFT_TENSOR);\n  EXPECT_EQ(t_actual.args(0).args_size(), 1);\n  EXPECT_EQ(t_actual.args(0).args(0).type_id(), TFT_INT32);\n  EXPECT_EQ(t_actual.args(0).args(0).args_size(), 0);\n}\n\nTEST(SpecializeType, ForEachExpandsFromListAttribute) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_FOR_EACH);\n  t->add_args()->set_type_id(TFT_PRODUCT);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(1)->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(1)->mutable_args(0)->set_s(\"T\");\n  t->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(2)->set_s(\"T\");\n\n  AttrValue attr;\n  attr.mutable_list()->add_type(DT_INT32);\n  attr.mutable_list()->add_type(DT_FLOAT);\n  NodeDef ndef;\n  (*ndef.mutable_attr())[\"T\"] = attr;\n\n  AttrSlice attrs(ndef);\n\n  FullTypeDef ft;\n  TF_ASSERT_OK(SpecializeType(attrs, op, ft));\n\n  EXPECT_EQ(ft.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(ft.args_size(), 1);\n\n  const FullTypeDef& t_actual = ft.args(0);\n  EXPECT_EQ(t_actual.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(t_actual.args_size(), 2);\n  EXPECT_EQ(t_actual.args(0).type_id(), TFT_TENSOR);\n  EXPECT_EQ(t_actual.args(0).args_size(), 1);\n  EXPECT_EQ(t_actual.args(0).args(0).type_id(), TFT_INT32);\n  EXPECT_EQ(t_actual.args(0).args(0).args_size(), 0);\n  EXPECT_EQ(t_actual.args(1).type_id(), TFT_TENSOR);\n  EXPECT_EQ(t_actual.args(1).args_size(), 1);\n  EXPECT_EQ(t_actual.args(1).args(0).type_id(), TFT_FLOAT);\n  EXPECT_EQ(t_actual.args(1).args(0).args_size(), 0);\n}\n\nTEST(SpecializeType, ForEachDistributesNestedVar) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_FOR_EACH);\n  t->add_args()->set_type_id(TFT_PRODUCT);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(1)->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(1)->mutable_args(0)->set_s(\"ForEachTarget\");\n  t->mutable_args(1)->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(1)->mutable_args(1)->set_s(\"GlobalVar\");\n  t->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(2)->set_s(\"ForEachTarget\");\n\n  NodeDef ndef;\n  AttrValue attr;\n\n  attr.mutable_list()->add_type(DT_INT32);\n  attr.mutable_list()->add_type(DT_INT64);\n  (*ndef.mutable_attr())[\"ForEachTarget\"] = attr;\n\n  attr.set_type(DT_FLOAT);\n  (*ndef.mutable_attr())[\"GlobalVar\"] = attr;\n\n  AttrSlice attrs(ndef);\n\n  FullTypeDef ft;\n  TF_ASSERT_OK(SpecializeType(attrs, op, ft));\n\n  EXPECT_EQ(ft.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(ft.args_size(), 1);\n\n  const FullTypeDef& t_actual = ft.args(0);\n  EXPECT_EQ(t_actual.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(t_actual.args_size(), 2);\n  EXPECT_EQ(t_actual.args(0).type_id(), TFT_TENSOR);\n  EXPECT_EQ(t_actual.args(0).args_size(), 2);\n  EXPECT_EQ(t_actual.args(0).args(0).type_id(), TFT_INT32);\n  EXPECT_EQ(t_actual.args(0).args(0).args_size(), 0);\n  EXPECT_EQ(t_actual.args(0).args(1).type_id(), TFT_FLOAT);\n  EXPECT_EQ(t_actual.args(0).args(1).args_size(), 0);\n  EXPECT_EQ(t_actual.args(1).type_id(), TFT_TENSOR);\n  EXPECT_EQ(t_actual.args(1).args_size(), 2);\n  EXPECT_EQ(t_actual.args(1).args(0).type_id(), TFT_INT64);\n  EXPECT_EQ(t_actual.args(1).args(0).args_size(), 0);\n  EXPECT_EQ(t_actual.args(1).args(1).type_id(), TFT_FLOAT);\n  EXPECT_EQ(t_actual.args(1).args(1).args_size(), 0);\n}\n\nTEST(SpecializeType, ForEachDistributesNestedForEach) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_FOR_EACH);\n  t->add_args()->set_type_id(TFT_PRODUCT);\n\n  FullTypeDef* inner = t->add_args();\n  inner->set_type_id(TFT_FOR_EACH);\n  inner->add_args()->set_type_id(TFT_PRODUCT);\n  inner->add_args()->set_type_id(TFT_ARRAY);\n  inner->mutable_args(1)->add_args()->set_type_id(TFT_VAR);\n  inner->mutable_args(1)->mutable_args(0)->set_s(\"InnerForEach\");\n  inner->mutable_args(1)->add_args()->set_type_id(TFT_VAR);\n  inner->mutable_args(1)->mutable_args(1)->set_s(\"OuterForEach\");\n  inner->add_args()->set_type_id(TFT_VAR);\n  inner->mutable_args(2)->set_s(\"InnerForEach\");\n\n  t->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(2)->set_s(\"OuterForEach\");\n\n  NodeDef ndef;\n  AttrValue attr;\n\n  attr.mutable_list()->add_type(DT_INT32);\n  attr.mutable_list()->add_type(DT_INT64);\n  (*ndef.mutable_attr())[\"OuterForEach\"] = attr;\n\n  attr.set_type(DT_FLOAT);\n  (*ndef.mutable_attr())[\"InnerForEach\"] = attr;\n\n  AttrSlice attrs(ndef);\n\n  FullTypeDef ft;\n  TF_ASSERT_OK(SpecializeType(attrs, op, ft));\n\n  EXPECT_EQ(ft.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(ft.args_size(), 1);\n\n  const FullTypeDef& t_actual = ft.args(0);\n  EXPECT_EQ(t_actual.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(t_actual.args_size(), 2);\n  EXPECT_EQ(t_actual.args(0).type_id(), TFT_PRODUCT);\n  EXPECT_EQ(t_actual.args(0).args_size(), 1);\n  EXPECT_EQ(t_actual.args(0).args(0).type_id(), TFT_ARRAY);\n  EXPECT_EQ(t_actual.args(0).args(0).args_size(), 2);\n  EXPECT_EQ(t_actual.args(0).args(0).args(0).type_id(), TFT_FLOAT);\n  EXPECT_EQ(t_actual.args(0).args(0).args(0).args_size(), 0);\n  EXPECT_EQ(t_actual.args(0).args(0).args(1).type_id(), TFT_INT32);\n  EXPECT_EQ(t_actual.args(0).args(0).args(1).args_size(), 0);\n  EXPECT_EQ(t_actual.args(1).type_id(), TFT_PRODUCT);\n  EXPECT_EQ(t_actual.args(1).args_size(), 1);\n  EXPECT_EQ(t_actual.args(1).args(0).type_id(), TFT_ARRAY);\n  EXPECT_EQ(t_actual.args(1).args(0).args_size(), 2);\n  EXPECT_EQ(t_actual.args(1).args(0).args(0).type_id(), TFT_FLOAT);\n  EXPECT_EQ(t_actual.args(1).args(0).args(0).args_size(), 0);\n  EXPECT_EQ(t_actual.args(1).args(0).args(1).type_id(), TFT_INT64);\n  EXPECT_EQ(t_actual.args(1).args(0).args(1).args_size(), 0);\n}\n\nTEST(SpecializeType, ForEachOverridesTargetOfNestedForEach) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_FOR_EACH);\n  t->add_args()->set_type_id(TFT_PRODUCT);\n\n  FullTypeDef* inner = t->add_args();\n  inner->set_type_id(TFT_FOR_EACH);\n  inner->add_args()->set_type_id(TFT_PRODUCT);\n  inner->add_args()->set_type_id(TFT_ARRAY);\n  inner->mutable_args(1)->add_args()->set_type_id(TFT_VAR);\n  inner->mutable_args(1)->mutable_args(0)->set_s(\"T\");\n  inner->add_args()->set_type_id(TFT_VAR);\n  inner->mutable_args(2)->set_s(\"T\");\n\n  t->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(2)->set_s(\"T\");\n\n  NodeDef ndef;\n  AttrValue attr;\n\n  attr.mutable_list()->add_type(DT_FLOAT);\n  attr.mutable_list()->add_type(DT_DOUBLE);\n  (*ndef.mutable_attr())[\"T\"] = attr;\n\n  AttrSlice attrs(ndef);\n\n  FullTypeDef ft;\n  TF_ASSERT_OK(SpecializeType(attrs, op, ft));\n\n  EXPECT_EQ(ft.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(ft.args_size(), 1);\n\n  const FullTypeDef& t_actual = ft.args(0);\n  EXPECT_EQ(t_actual.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(t_actual.args_size(), 2);\n  EXPECT_EQ(t_actual.args(0).type_id(), TFT_PRODUCT);\n  EXPECT_EQ(t_actual.args(0).args_size(), 1);\n  EXPECT_EQ(t_actual.args(0).args(0).type_id(), TFT_ARRAY);\n  EXPECT_EQ(t_actual.args(0).args(0).args_size(), 1);\n  EXPECT_EQ(t_actual.args(0).args(0).args(0).type_id(), TFT_FLOAT);\n  EXPECT_EQ(t_actual.args(0).args(0).args(0).args_size(), 0);\n  EXPECT_EQ(t_actual.args(1).type_id(), TFT_PRODUCT);\n  EXPECT_EQ(t_actual.args(1).args_size(), 1);\n  EXPECT_EQ(t_actual.args(1).args(0).type_id(), TFT_ARRAY);\n  EXPECT_EQ(t_actual.args(1).args(0).args_size(), 1);\n  EXPECT_EQ(t_actual.args(1).args(0).args(0).type_id(), TFT_DOUBLE);\n  EXPECT_EQ(t_actual.args(1).args(0).args(0).args_size(), 0);\n}\n\nTEST(SpecializeType, RemovesLegacyVariant) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_ARRAY);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(0)->add_args()->set_type_id(TFT_LEGACY_VARIANT);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(1)->add_args()->set_type_id(TFT_FLOAT);\n\n  AttrSlice empty;\n\n  FullTypeDef ft;\n  TF_ASSERT_OK(SpecializeType(empty, op, ft));\n\n  EXPECT_EQ(ft.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(ft.args_size(), 1);\n\n  const FullTypeDef& t_actual = ft.args(0);\n  EXPECT_EQ(t_actual.type_id(), TFT_ARRAY);\n  EXPECT_EQ(t_actual.args_size(), 0);\n}\n\nTEST(SpecializeType, RemovesLegacyVariantAfterExpansion) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_ARRAY);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(0)->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(0)->mutable_args(0)->set_s(\"T\");\n\n  AttrValue attr;\n  attr.set_type(DT_VARIANT);\n  NodeDef ndef;\n  (*ndef.mutable_attr())[\"T\"] = attr;\n\n  AttrSlice attrs(ndef);\n\n  FullTypeDef ft;\n  TF_ASSERT_OK(SpecializeType(attrs, op, ft));\n\n  EXPECT_EQ(ft.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(ft.args_size(), 1);\n\n  const FullTypeDef& t_actual = ft.args(0);\n  EXPECT_EQ(t_actual.type_id(), TFT_ARRAY);\n  EXPECT_EQ(t_actual.args_size(), 0);\n}\n\nTEST(GetArgDefaults, DefaultUnsetFromNoArgs) {\n  FullTypeDef t;\n\n  const auto& d = GetArgDefaultUnset(t, 0);\n\n  EXPECT_EQ(d.type_id(), TFT_UNSET);\n}\n\nTEST(GetArgDefaults, DefaultUnsetFromOutOfBounds) {\n  FullTypeDef t;\n  t.add_args()->set_type_id(TFT_TENSOR);\n\n  const auto& d = GetArgDefaultUnset(t, 1);\n\n  EXPECT_EQ(d.type_id(), TFT_UNSET);\n}\n\nTEST(GetArgDefaults, NoDefaultUnsetFromArg) {\n  FullTypeDef t;\n  t.add_args()->set_type_id(TFT_TENSOR);\n  t.mutable_args(0)->add_args();\n\n  const auto& d = GetArgDefaultUnset(t, 0);\n\n  EXPECT_EQ(d.type_id(), TFT_TENSOR);\n  EXPECT_EQ(d.args_size(), 1);\n}\n\nTEST(GetArgDefaults, DefaultAnyFromNoArgs) {\n  FullTypeDef t;\n\n  const auto& d = GetArgDefaultAny(t, 0);\n\n  EXPECT_EQ(d.type_id(), TFT_ANY);\n}\n\nTEST(GetArgDefaults, DefaultAnyFromOutOfBounds) {\n  FullTypeDef t;\n  t.add_args()->set_type_id(TFT_TENSOR);\n\n  const auto& d = GetArgDefaultAny(t, 1);\n\n  EXPECT_EQ(d.type_id(), TFT_ANY);\n}\n\nTEST(GetArgDefaults, DefaultAnyFromUnset) {\n  FullTypeDef t;\n  t.add_args();\n\n  const auto& d = GetArgDefaultAny(t, 0);\n\n  EXPECT_EQ(d.type_id(), TFT_ANY);\n}\n\nTEST(GetArgDefaults, NoDefaultAnyFromArg) {\n  FullTypeDef t;\n  t.add_args()->set_type_id(TFT_TENSOR);\n  t.mutable_args(0)->add_args();\n\n  const auto& d = GetArgDefaultAny(t, 0);\n\n  EXPECT_EQ(d.type_id(), TFT_TENSOR);\n  EXPECT_EQ(d.args_size(), 1);\n}\n\nTEST(IsEqual, Reflexivity) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  EXPECT_TRUE(IsEqual(t, t));\n}\n\nTEST(IsEqual, Copy) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  FullTypeDef u;\n  u = t;\n  EXPECT_TRUE(IsEqual(t, u));\n  EXPECT_TRUE(IsEqual(u, t));\n}\n\nTEST(IsEqual, DifferentTypesNotEqual) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  FullTypeDef u;\n  u = t;\n  u.set_type_id(TFT_ARRAY);\n\n  EXPECT_FALSE(IsEqual(t, u));\n  EXPECT_FALSE(IsEqual(u, t));\n}\n\nTEST(IsEqual, DifferentAritiesNotEqual) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  FullTypeDef u;\n  u = t;\n  u.add_args()->set_type_id(TFT_FLOAT);\n\n  EXPECT_FALSE(IsEqual(t, u));\n  EXPECT_FALSE(IsEqual(u, t));\n}\n\nTEST(IsEqual, MissingArgsEquivalentToAny) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n\n  FullTypeDef u;\n  u = t;\n  u.add_args()->set_type_id(TFT_ANY);\n\n  EXPECT_TRUE(IsEqual(t, u));\n  EXPECT_TRUE(IsEqual(u, t));\n}\n\nTEST(IsEqual, DifferentArgsNotEqual) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  FullTypeDef u;\n  u = t;\n  u.mutable_args(1)->set_type_id(TFT_FLOAT);\n\n  EXPECT_FALSE(IsEqual(t, u));\n  EXPECT_FALSE(IsEqual(u, t));\n}\n\nTEST(IsEqual, DifferentStringValuesNotEqual) {\n  FullTypeDef t;\n  t.set_type_id(TFT_VAR);\n  t.set_s(\"T\");\n\n  FullTypeDef u;\n  u = t;\n  u.set_type_id(TFT_VAR);\n  u.set_s(\"U\");\n\n  EXPECT_FALSE(IsEqual(t, u));\n  EXPECT_FALSE(IsEqual(u, t));\n}\n\nTEST(IsSubtype, Reflexivity) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  EXPECT_TRUE(IsSubtype(t, t));\n}\n\nTEST(IsSubtype, Copy) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  FullTypeDef u;\n  u = t;\n  EXPECT_TRUE(IsSubtype(t, u));\n}\n\nTEST(IsSubtype, Any) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  FullTypeDef u;\n  u.set_type_id(TFT_ANY);\n\n  EXPECT_TRUE(IsSubtype(t, u));\n  EXPECT_FALSE(IsSubtype(u, t));\n}\n\nTEST(IsSubtype, Unset) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  FullTypeDef u;\n  u.set_type_id(TFT_UNSET);\n\n  EXPECT_TRUE(IsSubtype(t, u));\n  EXPECT_FALSE(IsSubtype(u, t));\n}\n\nTEST(IsSubtype, Covariance) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_ARRAY);\n  t.mutable_args(0)->add_args()->set_type_id(TFT_INT32);\n\n  FullTypeDef u;\n  u.set_type_id(TFT_TENSOR);\n  u.add_args()->set_type_id(TFT_ANY);\n\n  EXPECT_TRUE(IsSubtype(t, u, /*covariant=*/true));\n  EXPECT_FALSE(IsSubtype(u, t, /*covariant=*/true));\n\n  EXPECT_FALSE(IsSubtype(t, u, /*covariant=*/false));\n  EXPECT_TRUE(IsSubtype(u, t, /*covariant=*/false));\n}\n\nTEST(IsSubtype, DifferentTypesNotSubtype) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  FullTypeDef u;\n  u = t;\n  u.set_type_id(TFT_ARRAY);\n\n  EXPECT_FALSE(IsSubtype(t, u));\n  EXPECT_FALSE(IsSubtype(u, t));\n}\n\nTEST(IsSubtype, DifferentAritiesDefaultToAny) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  FullTypeDef u;\n  u = t;\n  u.add_args()->set_type_id(TFT_FLOAT);\n\n  EXPECT_FALSE(IsSubtype(t, u));\n  EXPECT_TRUE(IsSubtype(u, t));\n}\n\nTEST(IsSubtype, DifferentArgsNotSubtype) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  FullTypeDef u;\n  u = t;\n  u.mutable_args(1)->set_type_id(TFT_FLOAT);\n\n  EXPECT_FALSE(IsSubtype(t, u));\n  EXPECT_FALSE(IsSubtype(u, t));\n}\n\n}  // namespace\n\n}  // namespace full_type\n\n}  // namespace tensorflow\n"], "fixing_code": ["/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/framework/full_type_util.h\"\n\n#include <algorithm>\n#include <string>\n\n#include \"absl/container/flat_hash_map.h\"\n#include \"tensorflow/core/framework/attr_value.pb.h\"\n#include \"tensorflow/core/framework/full_type.pb.h\"\n#include \"tensorflow/core/framework/node_def.pb.h\"\n#include \"tensorflow/core/framework/node_def_util.h\"\n#include \"tensorflow/core/framework/op_def.pb.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/platform/errors.h\"\n#include \"tensorflow/core/platform/hash.h\"\n#include \"tensorflow/core/platform/statusor.h\"\n#include \"tensorflow/core/protobuf/error_codes.pb.h\"\n\nnamespace tensorflow {\n\nnamespace full_type {\n\nOpTypeConstructor NoOp() {\n  return nullptr;\n}\n\nOpTypeConstructor NoOutputs() {\n  return [](OpDef* op_def) {\n    op_def->mutable_output_arg();\n    return OkStatus();\n  };\n}\n\nOpTypeConstructor Nullary(FullTypeId t) {\n  return [t](OpDef* op_def) {\n    FullTypeDef* tdef =\n        op_def->mutable_output_arg(0)->mutable_experimental_full_type();\n    tdef->set_type_id(t);\n    return OkStatus();\n  };\n}\n\nOpTypeConstructor Unary(FullTypeId t, const string& var_name) {\n  return [t, var_name](OpDef* op_def) {\n    FullTypeDef* tdef =\n        op_def->mutable_output_arg(0)->mutable_experimental_full_type();\n    tdef->set_type_id(t);\n\n    FullTypeDef* arg = tdef->add_args();\n    arg->set_type_id(TFT_VAR);\n    arg->set_s(var_name);\n\n    return OkStatus();\n  };\n}\n\nOpTypeConstructor UnaryGeneric(FullTypeId t) {\n  return [t](OpDef* op_def) {\n    FullTypeDef* tdef =\n        op_def->mutable_output_arg(0)->mutable_experimental_full_type();\n    tdef->set_type_id(t);\n\n    FullTypeDef* arg = tdef->add_args();\n    arg->set_type_id(TFT_ANY);\n\n    return OkStatus();\n  };\n}\n\nOpTypeConstructor UnaryTensorContainer(FullTypeId t, FullTypeId dtype) {\n  return [t, dtype](OpDef* op_def) {\n    FullTypeDef* tdef =\n        op_def->mutable_output_arg(0)->mutable_experimental_full_type();\n    tdef->set_type_id(t);\n\n    FullTypeDef* arg = tdef->add_args();\n    arg->set_type_id(TFT_TENSOR);\n    FullTypeDef* targ = arg->add_args();\n    targ->set_type_id(dtype);\n\n    return OkStatus();\n  };\n}\n\nOpTypeConstructor UnaryTensorContainer(FullTypeId t, const string& var_name) {\n  return [t, var_name](OpDef* op_def) {\n    FullTypeDef* tdef =\n        op_def->mutable_output_arg(0)->mutable_experimental_full_type();\n    tdef->set_type_id(t);\n\n    FullTypeDef* targ = tdef->add_args();\n    targ->set_type_id(TFT_TENSOR);\n    FullTypeDef* varg = targ->add_args();\n    varg->set_type_id(TFT_VAR);\n    varg->set_s(var_name);\n\n    return OkStatus();\n  };\n}\n\nOpTypeConstructor VariadicTensorContainer(FullTypeId t,\n                                          const string& var_name) {\n  return [t, var_name](OpDef* op_def) {\n    FullTypeDef* tdef =\n        op_def->mutable_output_arg(0)->mutable_experimental_full_type();\n    tdef->set_type_id(t);\n\n    FullTypeDef* for_each = tdef->add_args();\n    for_each->set_type_id(TFT_FOR_EACH);\n    for_each->add_args()->set_type_id(TFT_PRODUCT);\n\n    FullTypeDef* tpl = for_each->add_args();\n    tpl->set_type_id(TFT_TENSOR);\n    FullTypeDef* targ = tpl->add_args();\n    targ->set_type_id(TFT_VAR);\n    targ->set_s(var_name);\n\n    FullTypeDef* tvar = for_each->add_args();\n    tvar->set_type_id(TFT_VAR);\n    tvar->set_s(var_name);\n\n    return OkStatus();\n  };\n}\n\nnamespace {\n\ntypedef absl::flat_hash_map<StringPiece, const AttrValue*> AttrMap;\n\ninline Status SubstituteFromAttrs(AttrMap& attrs, FullTypeDef& t);\n\nStatus SubstituteVar(AttrMap& attrs, FullTypeDef& t) {\n  DCHECK_EQ(t.args_size(), 0);\n\n  StringPiece var_name = t.s();\n  if (!attrs.contains(var_name)) {\n    return Status(\n        error::INVALID_ARGUMENT,\n        absl::StrCat(\"could not find an attribute for key '\", var_name, \"'\"));\n  }\n  const AttrValue* attr = attrs.at(var_name);\n\n  const auto attr_type = attr->value_case();\n  if (attr_type == AttrValue::kType) {\n    map_dtype_to_tensor(attr->type(), t);\n  } else if (attr_type == AttrValue::kList) {\n    const auto& attr_list = attr->list();\n    if (attr_list.type_size() != 1) {\n      return Status(error::UNIMPLEMENTED,\n                    absl::StrCat(\"lists or other than one type element\\n\",\n                                 attr_list.DebugString(), \"\\nkey=\", var_name));\n    }\n    map_dtype_to_tensor(attr_list.type(0), t);\n  } else {\n    return Status(error::UNIMPLEMENTED,\n                  absl::StrCat(\"unsupported attribute type \",\n                               attr->DebugString(), \" for name \", var_name));\n  }\n  t.clear_s();\n  return OkStatus();\n}\n\nStatus SubstituteForEach(AttrMap& attrs, FullTypeDef& t) {\n  if (t.args_size() != 3) {\n    return Status(error::INVALID_ARGUMENT,\n                  absl::StrCat(\"illegal FOR_EACH type, expected 3 args, got \",\n                               t.args_size()));\n  }\n\n  const auto& cont = t.args(0);\n  const auto& tmpl = t.args(1);\n  const auto& t_var = t.args(2);\n\n  StringPiece var_name = t_var.s();\n  if (!attrs.contains(var_name)) {\n    return Status(\n        error::INVALID_ARGUMENT,\n        absl::StrCat(\"could not find an attribute for key '\", var_name, \"'\"));\n  }\n  const AttrValue* attr = attrs.at(var_name);\n\n  FullTypeDef result;\n  result.set_type_id(cont.type_id());\n\n  const auto attr_type = attr->value_case();\n  if (attr_type == AttrValue::kType) {\n    FullTypeDef* target = result.add_args();\n    *target = tmpl;\n    TF_RETURN_WITH_CONTEXT_IF_ERROR(\n        SubstituteFromAttrs(attrs, *target), \"while substituting '\", var_name,\n        \"' from\\n\", attr->DebugString(), \"\\ninto \", target->DebugString());\n\n  } else if (attr_type == AttrValue::kList) {\n    const auto& attr_list = attr->list();\n    int tsize = attr_list.type_size();\n    if (tsize == 0) {\n      return Status(error::UNIMPLEMENTED,\n                    absl::StrCat(\"unsupported list attribute type\\n\",\n                                 attr_list.DebugString(), \"\\nkey=\", var_name));\n    }\n    AttrValue replacement;\n    attrs[var_name] = &replacement;\n    for (int i = 0; i < tsize; i++) {\n      replacement.set_type(attr_list.type(i));\n      FullTypeDef* target = result.add_args();\n      *target = tmpl;\n      TF_RETURN_WITH_CONTEXT_IF_ERROR(SubstituteFromAttrs(attrs, *target),\n                                      \"while substituting '\", var_name,\n                                      \"' from\\n\", attr->DebugString(), \"\\n[\", i,\n                                      \"] into\\n\", target->DebugString());\n    }\n    // In case of error, it's ok for the attributes map to remain in an invalid\n    // state.\n    attrs[var_name] = attr;\n\n  } else {\n    return Status(error::UNIMPLEMENTED,\n                  absl::StrCat(\"unsupported attribute type\\n\",\n                               attr->DebugString(), \"\\nfor name \", var_name));\n  }\n  t = result;\n  return OkStatus();\n}\n\nStatus SubstituteGeneric(AttrMap& attrs, FullTypeDef& t) {\n  int nargs = t.args_size();\n  for (int j = 0; j < nargs; j++) {\n    FullTypeDef* arg_t = t.mutable_args(j);\n    TF_RETURN_WITH_CONTEXT_IF_ERROR(SubstituteFromAttrs(attrs, *arg_t),\n                                    \"while substituting arg \", j, \": \",\n                                    arg_t->DebugString());\n\n    // Special case for DT_VARIANT tensors. We leave those unset to avoid even\n    // more special casing downstream.\n    if (arg_t->type_id() == TFT_TENSOR && arg_t->args_size() &&\n        arg_t->args(0).type_id() == TFT_LEGACY_VARIANT) {\n      t.clear_args();\n      break;\n    }\n  }\n  return OkStatus();\n}\n\ninline Status SubstituteFromAttrs(AttrMap& attrs, FullTypeDef& t) {\n  // Resolve dependent types. The convention for op registrations is to use\n  // attributes as type variables.\n  // See https://www.tensorflow.org/guide/create_op#type_polymorphism.\n  // Once the op signature can be defined entirely in FullType, this\n  // convention can be deprecated.\n  //\n  // Note: While this code performs some basic verifications, it generally\n  // assumes consistent op defs and attributes. If more complete\n  // verifications are needed, they should be done by separately, and in a\n  // way that can be reused for type inference.\n  switch (t.type_id()) {\n    case TFT_VAR:\n      return SubstituteVar(attrs, t);\n\n    case TFT_FOR_EACH:\n      return SubstituteForEach(attrs, t);\n\n    default:\n      return SubstituteGeneric(attrs, t);\n  }\n  return OkStatus();\n}\n\n}  // namespace\n\nStatus SpecializeType(const AttrSlice& attrs, const OpDef& op_def,\n                      FullTypeDef& target) {\n  target.Clear();\n  target.set_type_id(TFT_PRODUCT);\n\n  AttrMap map;\n  for (const auto& attr : attrs) {\n    map.emplace(attr.first, &attr.second);\n  }\n\n  int nargs = op_def.output_arg_size();\n  for (int i = 0; i < nargs; i++) {\n    auto& t = *(target.add_args());\n    t = op_def.output_arg(i).experimental_full_type();\n    TF_RETURN_WITH_CONTEXT_IF_ERROR(\n        SubstituteFromAttrs(map, t), \"while expanding vars of\\n\",\n        t.DebugString(), \"\\nfrom\\n\", attrs.SummarizeNode());\n  }\n\n  return OkStatus();\n}\n\nconst FullTypeDef& GetArgDefaultUnset(const FullTypeDef& t, int i) {\n  static FullTypeDef* unset_type = []() {\n    FullTypeDef* t = new FullTypeDef();\n    return t;\n  }();\n\n  if (i < t.args_size()) {\n    return t.args(i);\n  }\n  return *unset_type;\n}\n\nconst FullTypeDef& GetArgDefaultAny(const FullTypeDef& t, int i) {\n  static FullTypeDef* any_type = []() {\n    FullTypeDef* t = new FullTypeDef();\n    t->set_type_id(TFT_ANY);\n    return t;\n  }();\n\n  if (i < t.args_size()) {\n    const FullTypeDef& f_val = t.args(i);\n    if (f_val.type_id() == TFT_UNSET) {\n      return *any_type;\n    }\n    return f_val;\n  }\n  return *any_type;\n}\n\nbool IsEqual(const FullTypeDef& lhs, const FullTypeDef& rhs) {\n  if (lhs.type_id() != rhs.type_id()) {\n    return false;\n  }\n  const auto& lhs_s = lhs.s();\n  const auto& rhs_s = rhs.s();\n  if (lhs_s.empty()) {\n    if (!rhs_s.empty()) {\n      return false;\n    }\n  } else if (rhs_s != lhs_s) {\n    return false;\n  }\n  for (int i = 0; i < std::max(lhs.args_size(), rhs.args_size()); i++) {\n    const FullTypeDef& lhs_arg = GetArgDefaultAny(lhs, i);\n    const FullTypeDef& rhs_arg = GetArgDefaultAny(rhs, i);\n\n    if (!IsEqual(lhs_arg, rhs_arg)) {\n      return false;\n    }\n  }\n  return true;\n}\n\nuint64_t Hash(const FullTypeDef& arg) {\n  // Following style of IsEqual above and walking across FullTypeDef.\n  uint64_t val = Hash64Combine(arg.type_id(), 0);\n\n  const auto& arg_s = arg.s();\n  val = Hash64Combine(val, Hash64(arg_s));\n  for (int i = 0, e = arg.args_size(); i < e; ++i) {\n    const FullTypeDef& arg_arg = GetArgDefaultAny(arg, i);\n    val = Hash64Combine(val, Hash(arg_arg));\n  }\n\n  return val;\n}\n\nbool IsSubtype(const FullTypeDef& lhs, const FullTypeDef& rhs, bool covariant) {\n  // Rule: ANY is a supertype of all types.\n  if (rhs.type_id() == TFT_ANY) {\n    return true;\n  }\n  // Compatibility rule: UNSET is treated as ANY for the purpose of subtyping.\n  if (rhs.type_id() == TFT_UNSET) {\n    return true;\n  }\n  // Compatibility rule: TENSOR[LEGACY_VARIANT] is treated as ANY for the\n  // purpose of subtyping.\n  if ((rhs.type_id() == TFT_TENSOR) &&\n      (GetArgDefaultUnset(rhs, 0).type_id() == TFT_LEGACY_VARIANT)) {\n    return true;\n  }\n  // Rule: encodings are subtypes of the encoding type.\n  if (lhs.type_id() == TFT_ENCODED) {\n    return IsSubtype(GetArgDefaultAny(lhs, 1), rhs, true);\n  }\n\n  // Default rule: type IDs must match.\n  if (lhs.type_id() != rhs.type_id()) {\n    return false;\n  }\n\n  // Arguments must be subtypes of one another.\n  for (int i = 0; i < std::max(lhs.args_size(), rhs.args_size()); i++) {\n    const FullTypeDef& lhs_arg = GetArgDefaultAny(lhs, i);\n    const FullTypeDef& rhs_arg = GetArgDefaultAny(rhs, i);\n\n    if (covariant) {\n      if (!IsSubtype(lhs_arg, rhs_arg)) {\n        return false;\n      }\n    } else {\n      if (!IsSubtype(rhs_arg, lhs_arg)) {\n        return false;\n      }\n    }\n  }\n\n  // Invariant: type IDs are equal, and all args are subtype of one another.\n  return true;\n}\n\n}  // namespace full_type\n\n}  // namespace tensorflow\n", "/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/framework/attr_value.pb.h\"\n#include \"tensorflow/core/framework/full_type.pb.h\"\n#include \"tensorflow/core/framework/node_def.pb.h\"\n#include \"tensorflow/core/framework/node_def_util.h\"\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/types.pb.h\"\n#include \"tensorflow/core/lib/core/status_test_util.h\"\n#include \"tensorflow/core/platform/test.h\"\n\nnamespace tensorflow {\n\nnamespace full_type {\n\nnamespace {\n\n// TODO(mdan): Use ParseTextProto, ProtoEquals when available in a clean lib.\n\nTEST(Nullary, Basic) {\n  OpTypeConstructor ctor = Nullary(TFT_TENSOR);\n\n  OpDef op;\n  op.add_output_arg();\n\n  TF_ASSERT_OK(ctor(&op));\n\n  const FullTypeDef& t = op.output_arg(0).experimental_full_type();\n  EXPECT_EQ(t.type_id(), TFT_TENSOR);\n  EXPECT_EQ(t.args_size(), 0);\n}\n\nTEST(Unary, Basic) {\n  OpTypeConstructor ctor = Unary(TFT_TENSOR, \"T\");\n\n  OpDef op;\n  op.add_output_arg();\n\n  TF_ASSERT_OK(ctor(&op));\n\n  const FullTypeDef& t = op.output_arg(0).experimental_full_type();\n  EXPECT_EQ(t.type_id(), TFT_TENSOR);\n  EXPECT_EQ(t.args_size(), 1);\n  EXPECT_EQ(t.args(0).type_id(), TFT_VAR);\n  EXPECT_EQ(t.args(0).args_size(), 0);\n  EXPECT_EQ(t.args(0).s(), \"T\");\n}\n\nTEST(UnaryGeneric, Basic) {\n  OpTypeConstructor ctor = UnaryGeneric(TFT_TENSOR);\n\n  OpDef op;\n  op.add_output_arg();\n\n  TF_ASSERT_OK(ctor(&op));\n\n  const FullTypeDef& t = op.output_arg(0).experimental_full_type();\n  EXPECT_EQ(t.type_id(), TFT_TENSOR);\n  EXPECT_EQ(t.args_size(), 1);\n  EXPECT_EQ(t.args(0).type_id(), TFT_ANY);\n  EXPECT_EQ(t.args(0).args_size(), 0);\n}\n\nTEST(UnaryTensorContainer, Fixed) {\n  OpTypeConstructor ctor = UnaryTensorContainer(TFT_ARRAY, TFT_INT32);\n\n  OpDef op;\n  op.add_output_arg();\n\n  TF_ASSERT_OK(ctor(&op));\n\n  const FullTypeDef& t = op.output_arg(0).experimental_full_type();\n  EXPECT_EQ(t.type_id(), TFT_ARRAY);\n  EXPECT_EQ(t.args_size(), 1);\n  EXPECT_EQ(t.args(0).type_id(), TFT_TENSOR);\n  EXPECT_EQ(t.args(0).args_size(), 1);\n  EXPECT_EQ(t.args(0).args(0).type_id(), TFT_INT32);\n  EXPECT_EQ(t.args(0).args(0).args_size(), 0);\n}\n\nTEST(UnaryTensorContainer, Dependent) {\n  OpTypeConstructor ctor = UnaryTensorContainer(TFT_ARRAY, \"T\");\n\n  OpDef op;\n  op.add_output_arg();\n\n  TF_ASSERT_OK(ctor(&op));\n\n  const FullTypeDef& t = op.output_arg(0).experimental_full_type();\n  EXPECT_EQ(t.type_id(), TFT_ARRAY);\n  EXPECT_EQ(t.args_size(), 1);\n  EXPECT_EQ(t.args(0).type_id(), TFT_TENSOR);\n  EXPECT_EQ(t.args(0).args_size(), 1);\n  EXPECT_EQ(t.args(0).args(0).type_id(), TFT_VAR);\n  EXPECT_EQ(t.args(0).args(0).args_size(), 0);\n  EXPECT_EQ(t.args(0).args(0).s(), \"T\");\n}\n\nTEST(VariadicTensorContainer, Basic) {\n  OpTypeConstructor ctor = VariadicTensorContainer(TFT_ARRAY, \"T\");\n\n  OpDef op;\n  op.add_output_arg();\n\n  TF_ASSERT_OK(ctor(&op));\n\n  const FullTypeDef& t = op.output_arg(0).experimental_full_type();\n  EXPECT_EQ(t.type_id(), TFT_ARRAY);\n  EXPECT_EQ(t.args_size(), 1);\n  EXPECT_EQ(t.args(0).type_id(), TFT_FOR_EACH);\n  EXPECT_EQ(t.args(0).args_size(), 3);\n  EXPECT_EQ(t.args(0).args(0).type_id(), TFT_PRODUCT);\n  EXPECT_EQ(t.args(0).args(0).args_size(), 0);\n  EXPECT_EQ(t.args(0).args(1).type_id(), TFT_TENSOR);\n  EXPECT_EQ(t.args(0).args(1).args_size(), 1);\n  EXPECT_EQ(t.args(0).args(1).args(0).type_id(), TFT_VAR);\n  EXPECT_EQ(t.args(0).args(1).args(0).args_size(), 0);\n  EXPECT_EQ(t.args(0).args(1).args(0).s(), \"T\");\n  EXPECT_EQ(t.args(0).args(2).type_id(), TFT_VAR);\n  EXPECT_EQ(t.args(0).args(2).args_size(), 0);\n  EXPECT_EQ(t.args(0).args(2).s(), \"T\");\n}\n\nTEST(SpecializeType, Fixed) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_ARRAY);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(0)->add_args()->set_type_id(TFT_INT32);\n  t->add_args()->set_type_id(TFT_DATASET);\n  t->mutable_args(1)->add_args()->set_type_id(TFT_FLOAT);\n\n  AttrSlice empty;\n\n  FullTypeDef ft;\n  TF_ASSERT_OK(SpecializeType(empty, op, ft));\n\n  EXPECT_EQ(ft.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(ft.args_size(), 1);\n\n  const FullTypeDef& t_actual = ft.args(0);\n  EXPECT_EQ(t_actual.type_id(), TFT_ARRAY);\n  EXPECT_EQ(t_actual.args_size(), 2);\n  EXPECT_EQ(t_actual.args(0).type_id(), TFT_TENSOR);\n  EXPECT_EQ(t_actual.args(0).args_size(), 1);\n  EXPECT_EQ(t_actual.args(0).args(0).type_id(), TFT_INT32);\n  EXPECT_EQ(t_actual.args(0).args(0).args_size(), 0);\n  EXPECT_EQ(t_actual.args(1).type_id(), TFT_DATASET);\n  EXPECT_EQ(t_actual.args(1).args_size(), 1);\n  EXPECT_EQ(t_actual.args(1).args(0).type_id(), TFT_FLOAT);\n  EXPECT_EQ(t_actual.args(1).args(0).args_size(), 0);\n}\n\nTEST(SpecializeType, Idempotence) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_ARRAY);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(0)->add_args()->set_type_id(TFT_INT32);\n  t->add_args()->set_type_id(TFT_DATASET);\n  t->mutable_args(1)->add_args()->set_type_id(TFT_FLOAT);\n\n  AttrSlice empty;\n\n  FullTypeDef ft;\n  TF_ASSERT_OK(SpecializeType(empty, op, ft));\n  TF_ASSERT_OK(SpecializeType(empty, op, ft));\n\n  EXPECT_EQ(ft.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(ft.args_size(), 1);\n}\n\nTEST(SpecializeType, VarExpandsFromSingleAttribute) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_ARRAY);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(0)->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(0)->mutable_args(0)->set_s(\"T\");\n\n  AttrValue attr;\n  attr.set_type(DT_INT32);\n  NodeDef ndef;\n  (*ndef.mutable_attr())[\"T\"] = attr;\n\n  AttrSlice attrs(ndef);\n\n  FullTypeDef ft;\n  TF_ASSERT_OK(SpecializeType(attrs, op, ft));\n\n  EXPECT_EQ(ft.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(ft.args_size(), 1);\n\n  const FullTypeDef& t_actual = ft.args(0);\n  EXPECT_EQ(t_actual.type_id(), TFT_ARRAY);\n  EXPECT_EQ(t_actual.args_size(), 1);\n  EXPECT_EQ(t_actual.args(0).type_id(), TFT_TENSOR);\n  EXPECT_EQ(t_actual.args(0).args_size(), 1);\n  EXPECT_EQ(t_actual.args(0).args(0).type_id(), TFT_INT32);\n  EXPECT_EQ(t_actual.args(0).args(0).args_size(), 0);\n}\n\nTEST(SpecializeType, VarExpandsFromSingleElementTypeListAttribute) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_ARRAY);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(0)->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(0)->mutable_args(0)->set_s(\"T\");\n\n  AttrValue attr;\n  attr.mutable_list()->add_type(DT_INT32);\n  NodeDef ndef;\n  (*ndef.mutable_attr())[\"T\"] = attr;\n\n  AttrSlice attrs(ndef);\n\n  FullTypeDef ft;\n  TF_ASSERT_OK(SpecializeType(attrs, op, ft));\n\n  EXPECT_EQ(ft.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(ft.args_size(), 1);\n\n  const FullTypeDef& t_actual = ft.args(0);\n  EXPECT_EQ(t_actual.type_id(), TFT_ARRAY);\n  EXPECT_EQ(t_actual.args_size(), 1);\n  EXPECT_EQ(t_actual.args(0).type_id(), TFT_TENSOR);\n  EXPECT_EQ(t_actual.args(0).args_size(), 1);\n  EXPECT_EQ(t_actual.args(0).args(0).type_id(), TFT_INT32);\n  EXPECT_EQ(t_actual.args(0).args(0).args_size(), 0);\n}\n\nTEST(SpecializeType, VarRejectsMultipleElementTypeListAttribute) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_ARRAY);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(0)->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(0)->mutable_args(0)->set_s(\"T\");\n\n  AttrValue attr;\n  attr.mutable_list()->add_type(DT_INT32);\n  attr.mutable_list()->add_type(DT_FLOAT);\n  NodeDef ndef;\n  (*ndef.mutable_attr())[\"T\"] = attr;\n\n  AttrSlice attrs(ndef);\n\n  FullTypeDef ft;\n  EXPECT_FALSE(SpecializeType(attrs, op, ft).ok());\n}\n\nTEST(SpecializeType, VarRejectsEmptyTypeListAttribute) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_ARRAY);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(0)->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(0)->mutable_args(0)->set_s(\"T\");\n\n  AttrValue attr;\n  attr.mutable_list();\n  NodeDef ndef;\n  (*ndef.mutable_attr())[\"T\"] = attr;\n\n  AttrSlice attrs(ndef);\n\n  FullTypeDef ft;\n  EXPECT_FALSE(SpecializeType(attrs, op, ft).ok());\n}\n\nTEST(SpecializeType, ForEachExpandsFromSingleAttribute) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_FOR_EACH);\n  t->add_args()->set_type_id(TFT_PRODUCT);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(1)->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(1)->mutable_args(0)->set_s(\"T\");\n  t->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(2)->set_s(\"T\");\n\n  AttrValue attr;\n  attr.set_type(DT_INT32);\n  NodeDef ndef;\n  (*ndef.mutable_attr())[\"T\"] = attr;\n\n  AttrSlice attrs(ndef);\n\n  FullTypeDef ft;\n  TF_ASSERT_OK(SpecializeType(attrs, op, ft));\n\n  EXPECT_EQ(ft.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(ft.args_size(), 1);\n\n  const FullTypeDef& t_actual = ft.args(0);\n  EXPECT_EQ(t_actual.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(t_actual.args_size(), 1);\n  EXPECT_EQ(t_actual.args(0).type_id(), TFT_TENSOR);\n  EXPECT_EQ(t_actual.args(0).args_size(), 1);\n  EXPECT_EQ(t_actual.args(0).args(0).type_id(), TFT_INT32);\n  EXPECT_EQ(t_actual.args(0).args(0).args_size(), 0);\n}\n\nTEST(SpecializeType, ForEachExpandsFromListAttribute) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_FOR_EACH);\n  t->add_args()->set_type_id(TFT_PRODUCT);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(1)->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(1)->mutable_args(0)->set_s(\"T\");\n  t->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(2)->set_s(\"T\");\n\n  AttrValue attr;\n  attr.mutable_list()->add_type(DT_INT32);\n  attr.mutable_list()->add_type(DT_FLOAT);\n  NodeDef ndef;\n  (*ndef.mutable_attr())[\"T\"] = attr;\n\n  AttrSlice attrs(ndef);\n\n  FullTypeDef ft;\n  TF_ASSERT_OK(SpecializeType(attrs, op, ft));\n\n  EXPECT_EQ(ft.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(ft.args_size(), 1);\n\n  const FullTypeDef& t_actual = ft.args(0);\n  EXPECT_EQ(t_actual.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(t_actual.args_size(), 2);\n  EXPECT_EQ(t_actual.args(0).type_id(), TFT_TENSOR);\n  EXPECT_EQ(t_actual.args(0).args_size(), 1);\n  EXPECT_EQ(t_actual.args(0).args(0).type_id(), TFT_INT32);\n  EXPECT_EQ(t_actual.args(0).args(0).args_size(), 0);\n  EXPECT_EQ(t_actual.args(1).type_id(), TFT_TENSOR);\n  EXPECT_EQ(t_actual.args(1).args_size(), 1);\n  EXPECT_EQ(t_actual.args(1).args(0).type_id(), TFT_FLOAT);\n  EXPECT_EQ(t_actual.args(1).args(0).args_size(), 0);\n}\n\nTEST(SpecializeType, ForEachDistributesNestedVar) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_FOR_EACH);\n  t->add_args()->set_type_id(TFT_PRODUCT);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(1)->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(1)->mutable_args(0)->set_s(\"ForEachTarget\");\n  t->mutable_args(1)->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(1)->mutable_args(1)->set_s(\"GlobalVar\");\n  t->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(2)->set_s(\"ForEachTarget\");\n\n  NodeDef ndef;\n  AttrValue attr;\n\n  attr.mutable_list()->add_type(DT_INT32);\n  attr.mutable_list()->add_type(DT_INT64);\n  (*ndef.mutable_attr())[\"ForEachTarget\"] = attr;\n\n  attr.set_type(DT_FLOAT);\n  (*ndef.mutable_attr())[\"GlobalVar\"] = attr;\n\n  AttrSlice attrs(ndef);\n\n  FullTypeDef ft;\n  TF_ASSERT_OK(SpecializeType(attrs, op, ft));\n\n  EXPECT_EQ(ft.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(ft.args_size(), 1);\n\n  const FullTypeDef& t_actual = ft.args(0);\n  EXPECT_EQ(t_actual.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(t_actual.args_size(), 2);\n  EXPECT_EQ(t_actual.args(0).type_id(), TFT_TENSOR);\n  EXPECT_EQ(t_actual.args(0).args_size(), 2);\n  EXPECT_EQ(t_actual.args(0).args(0).type_id(), TFT_INT32);\n  EXPECT_EQ(t_actual.args(0).args(0).args_size(), 0);\n  EXPECT_EQ(t_actual.args(0).args(1).type_id(), TFT_FLOAT);\n  EXPECT_EQ(t_actual.args(0).args(1).args_size(), 0);\n  EXPECT_EQ(t_actual.args(1).type_id(), TFT_TENSOR);\n  EXPECT_EQ(t_actual.args(1).args_size(), 2);\n  EXPECT_EQ(t_actual.args(1).args(0).type_id(), TFT_INT64);\n  EXPECT_EQ(t_actual.args(1).args(0).args_size(), 0);\n  EXPECT_EQ(t_actual.args(1).args(1).type_id(), TFT_FLOAT);\n  EXPECT_EQ(t_actual.args(1).args(1).args_size(), 0);\n}\n\nTEST(SpecializeType, ForEachDistributesNestedForEach) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_FOR_EACH);\n  t->add_args()->set_type_id(TFT_PRODUCT);\n\n  FullTypeDef* inner = t->add_args();\n  inner->set_type_id(TFT_FOR_EACH);\n  inner->add_args()->set_type_id(TFT_PRODUCT);\n  inner->add_args()->set_type_id(TFT_ARRAY);\n  inner->mutable_args(1)->add_args()->set_type_id(TFT_VAR);\n  inner->mutable_args(1)->mutable_args(0)->set_s(\"InnerForEach\");\n  inner->mutable_args(1)->add_args()->set_type_id(TFT_VAR);\n  inner->mutable_args(1)->mutable_args(1)->set_s(\"OuterForEach\");\n  inner->add_args()->set_type_id(TFT_VAR);\n  inner->mutable_args(2)->set_s(\"InnerForEach\");\n\n  t->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(2)->set_s(\"OuterForEach\");\n\n  NodeDef ndef;\n  AttrValue attr;\n\n  attr.mutable_list()->add_type(DT_INT32);\n  attr.mutable_list()->add_type(DT_INT64);\n  (*ndef.mutable_attr())[\"OuterForEach\"] = attr;\n\n  attr.set_type(DT_FLOAT);\n  (*ndef.mutable_attr())[\"InnerForEach\"] = attr;\n\n  AttrSlice attrs(ndef);\n\n  FullTypeDef ft;\n  TF_ASSERT_OK(SpecializeType(attrs, op, ft));\n\n  EXPECT_EQ(ft.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(ft.args_size(), 1);\n\n  const FullTypeDef& t_actual = ft.args(0);\n  EXPECT_EQ(t_actual.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(t_actual.args_size(), 2);\n  EXPECT_EQ(t_actual.args(0).type_id(), TFT_PRODUCT);\n  EXPECT_EQ(t_actual.args(0).args_size(), 1);\n  EXPECT_EQ(t_actual.args(0).args(0).type_id(), TFT_ARRAY);\n  EXPECT_EQ(t_actual.args(0).args(0).args_size(), 2);\n  EXPECT_EQ(t_actual.args(0).args(0).args(0).type_id(), TFT_FLOAT);\n  EXPECT_EQ(t_actual.args(0).args(0).args(0).args_size(), 0);\n  EXPECT_EQ(t_actual.args(0).args(0).args(1).type_id(), TFT_INT32);\n  EXPECT_EQ(t_actual.args(0).args(0).args(1).args_size(), 0);\n  EXPECT_EQ(t_actual.args(1).type_id(), TFT_PRODUCT);\n  EXPECT_EQ(t_actual.args(1).args_size(), 1);\n  EXPECT_EQ(t_actual.args(1).args(0).type_id(), TFT_ARRAY);\n  EXPECT_EQ(t_actual.args(1).args(0).args_size(), 2);\n  EXPECT_EQ(t_actual.args(1).args(0).args(0).type_id(), TFT_FLOAT);\n  EXPECT_EQ(t_actual.args(1).args(0).args(0).args_size(), 0);\n  EXPECT_EQ(t_actual.args(1).args(0).args(1).type_id(), TFT_INT64);\n  EXPECT_EQ(t_actual.args(1).args(0).args(1).args_size(), 0);\n}\n\nTEST(SpecializeType, ForEachOverridesTargetOfNestedForEach) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_FOR_EACH);\n  t->add_args()->set_type_id(TFT_PRODUCT);\n\n  FullTypeDef* inner = t->add_args();\n  inner->set_type_id(TFT_FOR_EACH);\n  inner->add_args()->set_type_id(TFT_PRODUCT);\n  inner->add_args()->set_type_id(TFT_ARRAY);\n  inner->mutable_args(1)->add_args()->set_type_id(TFT_VAR);\n  inner->mutable_args(1)->mutable_args(0)->set_s(\"T\");\n  inner->add_args()->set_type_id(TFT_VAR);\n  inner->mutable_args(2)->set_s(\"T\");\n\n  t->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(2)->set_s(\"T\");\n\n  NodeDef ndef;\n  AttrValue attr;\n\n  attr.mutable_list()->add_type(DT_FLOAT);\n  attr.mutable_list()->add_type(DT_DOUBLE);\n  (*ndef.mutable_attr())[\"T\"] = attr;\n\n  AttrSlice attrs(ndef);\n\n  FullTypeDef ft;\n  TF_ASSERT_OK(SpecializeType(attrs, op, ft));\n\n  EXPECT_EQ(ft.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(ft.args_size(), 1);\n\n  const FullTypeDef& t_actual = ft.args(0);\n  EXPECT_EQ(t_actual.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(t_actual.args_size(), 2);\n  EXPECT_EQ(t_actual.args(0).type_id(), TFT_PRODUCT);\n  EXPECT_EQ(t_actual.args(0).args_size(), 1);\n  EXPECT_EQ(t_actual.args(0).args(0).type_id(), TFT_ARRAY);\n  EXPECT_EQ(t_actual.args(0).args(0).args_size(), 1);\n  EXPECT_EQ(t_actual.args(0).args(0).args(0).type_id(), TFT_FLOAT);\n  EXPECT_EQ(t_actual.args(0).args(0).args(0).args_size(), 0);\n  EXPECT_EQ(t_actual.args(1).type_id(), TFT_PRODUCT);\n  EXPECT_EQ(t_actual.args(1).args_size(), 1);\n  EXPECT_EQ(t_actual.args(1).args(0).type_id(), TFT_ARRAY);\n  EXPECT_EQ(t_actual.args(1).args(0).args_size(), 1);\n  EXPECT_EQ(t_actual.args(1).args(0).args(0).type_id(), TFT_DOUBLE);\n  EXPECT_EQ(t_actual.args(1).args(0).args(0).args_size(), 0);\n}\n\nTEST(SpecializeType, ForEachRejectsMalformedInput) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_FOR_EACH);\n  t->add_args()->set_type_id(TFT_PRODUCT);\n\n  NodeDef ndef;\n  AttrSlice attrs(ndef);\n\n  FullTypeDef ft;\n  EXPECT_FALSE(SpecializeType(attrs, op, ft).ok());\n}\n\nTEST(SpecializeType, RemovesLegacyVariant) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_ARRAY);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(0)->add_args()->set_type_id(TFT_LEGACY_VARIANT);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(1)->add_args()->set_type_id(TFT_FLOAT);\n\n  AttrSlice empty;\n\n  FullTypeDef ft;\n  TF_ASSERT_OK(SpecializeType(empty, op, ft));\n\n  EXPECT_EQ(ft.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(ft.args_size(), 1);\n\n  const FullTypeDef& t_actual = ft.args(0);\n  EXPECT_EQ(t_actual.type_id(), TFT_ARRAY);\n  EXPECT_EQ(t_actual.args_size(), 0);\n}\n\nTEST(SpecializeType, RemovesLegacyVariantAfterExpansion) {\n  OpDef op;\n  FullTypeDef* t = op.add_output_arg()->mutable_experimental_full_type();\n  t->set_type_id(TFT_ARRAY);\n  t->add_args()->set_type_id(TFT_TENSOR);\n  t->mutable_args(0)->add_args()->set_type_id(TFT_VAR);\n  t->mutable_args(0)->mutable_args(0)->set_s(\"T\");\n\n  AttrValue attr;\n  attr.set_type(DT_VARIANT);\n  NodeDef ndef;\n  (*ndef.mutable_attr())[\"T\"] = attr;\n\n  AttrSlice attrs(ndef);\n\n  FullTypeDef ft;\n  TF_ASSERT_OK(SpecializeType(attrs, op, ft));\n\n  EXPECT_EQ(ft.type_id(), TFT_PRODUCT);\n  EXPECT_EQ(ft.args_size(), 1);\n\n  const FullTypeDef& t_actual = ft.args(0);\n  EXPECT_EQ(t_actual.type_id(), TFT_ARRAY);\n  EXPECT_EQ(t_actual.args_size(), 0);\n}\n\nTEST(GetArgDefaults, DefaultUnsetFromNoArgs) {\n  FullTypeDef t;\n\n  const auto& d = GetArgDefaultUnset(t, 0);\n\n  EXPECT_EQ(d.type_id(), TFT_UNSET);\n}\n\nTEST(GetArgDefaults, DefaultUnsetFromOutOfBounds) {\n  FullTypeDef t;\n  t.add_args()->set_type_id(TFT_TENSOR);\n\n  const auto& d = GetArgDefaultUnset(t, 1);\n\n  EXPECT_EQ(d.type_id(), TFT_UNSET);\n}\n\nTEST(GetArgDefaults, NoDefaultUnsetFromArg) {\n  FullTypeDef t;\n  t.add_args()->set_type_id(TFT_TENSOR);\n  t.mutable_args(0)->add_args();\n\n  const auto& d = GetArgDefaultUnset(t, 0);\n\n  EXPECT_EQ(d.type_id(), TFT_TENSOR);\n  EXPECT_EQ(d.args_size(), 1);\n}\n\nTEST(GetArgDefaults, DefaultAnyFromNoArgs) {\n  FullTypeDef t;\n\n  const auto& d = GetArgDefaultAny(t, 0);\n\n  EXPECT_EQ(d.type_id(), TFT_ANY);\n}\n\nTEST(GetArgDefaults, DefaultAnyFromOutOfBounds) {\n  FullTypeDef t;\n  t.add_args()->set_type_id(TFT_TENSOR);\n\n  const auto& d = GetArgDefaultAny(t, 1);\n\n  EXPECT_EQ(d.type_id(), TFT_ANY);\n}\n\nTEST(GetArgDefaults, DefaultAnyFromUnset) {\n  FullTypeDef t;\n  t.add_args();\n\n  const auto& d = GetArgDefaultAny(t, 0);\n\n  EXPECT_EQ(d.type_id(), TFT_ANY);\n}\n\nTEST(GetArgDefaults, NoDefaultAnyFromArg) {\n  FullTypeDef t;\n  t.add_args()->set_type_id(TFT_TENSOR);\n  t.mutable_args(0)->add_args();\n\n  const auto& d = GetArgDefaultAny(t, 0);\n\n  EXPECT_EQ(d.type_id(), TFT_TENSOR);\n  EXPECT_EQ(d.args_size(), 1);\n}\n\nTEST(IsEqual, Reflexivity) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  EXPECT_TRUE(IsEqual(t, t));\n}\n\nTEST(IsEqual, Copy) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  FullTypeDef u;\n  u = t;\n  EXPECT_TRUE(IsEqual(t, u));\n  EXPECT_TRUE(IsEqual(u, t));\n}\n\nTEST(IsEqual, DifferentTypesNotEqual) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  FullTypeDef u;\n  u = t;\n  u.set_type_id(TFT_ARRAY);\n\n  EXPECT_FALSE(IsEqual(t, u));\n  EXPECT_FALSE(IsEqual(u, t));\n}\n\nTEST(IsEqual, DifferentAritiesNotEqual) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  FullTypeDef u;\n  u = t;\n  u.add_args()->set_type_id(TFT_FLOAT);\n\n  EXPECT_FALSE(IsEqual(t, u));\n  EXPECT_FALSE(IsEqual(u, t));\n}\n\nTEST(IsEqual, MissingArgsEquivalentToAny) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n\n  FullTypeDef u;\n  u = t;\n  u.add_args()->set_type_id(TFT_ANY);\n\n  EXPECT_TRUE(IsEqual(t, u));\n  EXPECT_TRUE(IsEqual(u, t));\n}\n\nTEST(IsEqual, DifferentArgsNotEqual) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  FullTypeDef u;\n  u = t;\n  u.mutable_args(1)->set_type_id(TFT_FLOAT);\n\n  EXPECT_FALSE(IsEqual(t, u));\n  EXPECT_FALSE(IsEqual(u, t));\n}\n\nTEST(IsEqual, DifferentStringValuesNotEqual) {\n  FullTypeDef t;\n  t.set_type_id(TFT_VAR);\n  t.set_s(\"T\");\n\n  FullTypeDef u;\n  u = t;\n  u.set_type_id(TFT_VAR);\n  u.set_s(\"U\");\n\n  EXPECT_FALSE(IsEqual(t, u));\n  EXPECT_FALSE(IsEqual(u, t));\n}\n\nTEST(IsSubtype, Reflexivity) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  EXPECT_TRUE(IsSubtype(t, t));\n}\n\nTEST(IsSubtype, Copy) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  FullTypeDef u;\n  u = t;\n  EXPECT_TRUE(IsSubtype(t, u));\n}\n\nTEST(IsSubtype, Any) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  FullTypeDef u;\n  u.set_type_id(TFT_ANY);\n\n  EXPECT_TRUE(IsSubtype(t, u));\n  EXPECT_FALSE(IsSubtype(u, t));\n}\n\nTEST(IsSubtype, Unset) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  FullTypeDef u;\n  u.set_type_id(TFT_UNSET);\n\n  EXPECT_TRUE(IsSubtype(t, u));\n  EXPECT_FALSE(IsSubtype(u, t));\n}\n\nTEST(IsSubtype, Covariance) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_ARRAY);\n  t.mutable_args(0)->add_args()->set_type_id(TFT_INT32);\n\n  FullTypeDef u;\n  u.set_type_id(TFT_TENSOR);\n  u.add_args()->set_type_id(TFT_ANY);\n\n  EXPECT_TRUE(IsSubtype(t, u, /*covariant=*/true));\n  EXPECT_FALSE(IsSubtype(u, t, /*covariant=*/true));\n\n  EXPECT_FALSE(IsSubtype(t, u, /*covariant=*/false));\n  EXPECT_TRUE(IsSubtype(u, t, /*covariant=*/false));\n}\n\nTEST(IsSubtype, DifferentTypesNotSubtype) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  FullTypeDef u;\n  u = t;\n  u.set_type_id(TFT_ARRAY);\n\n  EXPECT_FALSE(IsSubtype(t, u));\n  EXPECT_FALSE(IsSubtype(u, t));\n}\n\nTEST(IsSubtype, DifferentAritiesDefaultToAny) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  FullTypeDef u;\n  u = t;\n  u.add_args()->set_type_id(TFT_FLOAT);\n\n  EXPECT_FALSE(IsSubtype(t, u));\n  EXPECT_TRUE(IsSubtype(u, t));\n}\n\nTEST(IsSubtype, DifferentArgsNotSubtype) {\n  FullTypeDef t;\n  t.set_type_id(TFT_TENSOR);\n  t.add_args()->set_type_id(TFT_INT32);\n  t.add_args()->set_type_id(TFT_INT64);\n\n  FullTypeDef u;\n  u = t;\n  u.mutable_args(1)->set_type_id(TFT_FLOAT);\n\n  EXPECT_FALSE(IsSubtype(t, u));\n  EXPECT_FALSE(IsSubtype(u, t));\n}\n\n}  // namespace\n\n}  // namespace full_type\n\n}  // namespace tensorflow\n"], "filenames": ["tensorflow/core/framework/full_type_util.cc", "tensorflow/core/framework/full_type_util_test.cc"], "buggy_code_start_loc": [178, 512], "buggy_code_end_loc": [179, 512], "fixing_code_start_loc": [178, 513], "fixing_code_end_loc": [183, 526], "type": "CWE-617", "message": "TensorFlow is an open source platform for machine learning. When `tensorflow::full_type::SubstituteFromAttrs` receives a `FullTypeDef& t` that is not exactly three args, it triggers a `CHECK`-fail instead of returning a status. We have patched the issue in GitHub commit 6104f0d4091c260ce9352f9155f7e9b725eab012. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.", "other": {"cve": {"id": "CVE-2022-36016", "sourceIdentifier": "security-advisories@github.com", "published": "2022-09-16T23:15:11.307", "lastModified": "2022-09-20T14:39:13.337", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an open source platform for machine learning. When `tensorflow::full_type::SubstituteFromAttrs` receives a `FullTypeDef& t` that is not exactly three args, it triggers a `CHECK`-fail instead of returning a status. We have patched the issue in GitHub commit 6104f0d4091c260ce9352f9155f7e9b725eab012. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto para el aprendizaje autom\u00e1tico. Cuando \"tensorflow::full_type::SubstituteFromAttrs\" recibe un \"FullTypeDef&amp; t\" que no presenta exactamente tres argumentos, desencadena un fallo de \"CHECK\" en lugar de devolver un estado. Hemos parcheado el problema en el commit 6104f0d4091c260ce9352f9155f7e9b725eab012 de GitHub. La correcci\u00f3n ser\u00e1 incluida en TensorFlow versi\u00f3n 2.10.0. Tambi\u00e9n seleccionaremos este compromiso en TensorFlow versi\u00f3n 2.9.1, TensorFlow versi\u00f3n 2.8.1, y TensorFlow versi\u00f3n 2.7.2, ya que estos tambi\u00e9n est\u00e1n afectados y todav\u00eda est\u00e1n en el rango admitido. No se presentan mitigaciones conocidas para este problema"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.9, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.2, "impactScore": 3.6}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-617"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.7.2", "matchCriteriaId": "C6622D95-1C86-45C5-AB55-E6EEEA0996DF"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.8.0", "versionEndExcluding": "2.8.1", "matchCriteriaId": "0F9D273D-02DC-441E-AA91-EAC8DEAA4B44"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.9.0", "versionEndExcluding": "2.9.1", "matchCriteriaId": "FE4F8A81-6CC2-4F7F-9602-C170FDD926E7"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc0:*:*:*:*:*:*", "matchCriteriaId": "1DBFBCE2-0A01-4575-BE45-6775ABFB8B28"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc1:*:*:*:*:*:*", "matchCriteriaId": "89806CF9-E423-4CA6-A01A-8175C260CB24"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc2:*:*:*:*:*:*", "matchCriteriaId": "F2B80690-A257-4E16-BD27-9AE045BC56ED"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc3:*:*:*:*:*:*", "matchCriteriaId": "F335F9A4-5AB8-4E53-BC18-E01F7C653E5E"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/math_ops.cc", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/commit/6104f0d4091c260ce9352f9155f7e9b725eab012", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-g468-qj8g-vcjc", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/6104f0d4091c260ce9352f9155f7e9b725eab012"}}
{"buggy_code": ["import pytest\nfrom hexbytes import HexBytes\n\nfrom vyper.builtins.functions import eip1167_bytecode\nfrom vyper.exceptions import ArgumentException, InvalidType, StateAccessViolation\n\npytestmark = pytest.mark.usefixtures(\"memory_mocker\")\n\n\ndef test_max_outsize_exceeds_returndatasize(get_contract):\n    source_code = \"\"\"\n@external\ndef foo() -> Bytes[7]:\n    return raw_call(0x0000000000000000000000000000000000000004, b\"moose\", max_outsize=7)\n    \"\"\"\n    c = get_contract(source_code)\n    assert c.foo() == b\"moose\"\n\n\ndef test_raw_call_non_memory(get_contract):\n    source_code = \"\"\"\n_foo: Bytes[5]\n@external\ndef foo() -> Bytes[5]:\n    self._foo = b\"moose\"\n    return raw_call(0x0000000000000000000000000000000000000004, self._foo, max_outsize=5)\n    \"\"\"\n    c = get_contract(source_code)\n    assert c.foo() == b\"moose\"\n\n\ndef test_returndatasize_exceeds_max_outsize(get_contract):\n    source_code = \"\"\"\n@external\ndef foo() -> Bytes[3]:\n    return raw_call(0x0000000000000000000000000000000000000004, b\"moose\", max_outsize=3)\n    \"\"\"\n    c = get_contract(source_code)\n    assert c.foo() == b\"moo\"\n\n\ndef test_returndatasize_matches_max_outsize(get_contract):\n    source_code = \"\"\"\n@external\ndef foo() -> Bytes[5]:\n    return raw_call(0x0000000000000000000000000000000000000004, b\"moose\", max_outsize=5)\n    \"\"\"\n    c = get_contract(source_code)\n    assert c.foo() == b\"moose\"\n\n\ndef test_multiple_levels(w3, get_contract_with_gas_estimation):\n    inner_code = \"\"\"\n@external\ndef returnten() -> int128:\n    return 10\n    \"\"\"\n\n    c = get_contract_with_gas_estimation(inner_code)\n\n    outer_code = \"\"\"\n@external\ndef create_and_call_returnten(inp: address) -> int128:\n    x: address = create_minimal_proxy_to(inp)\n    o: int128 = extract32(raw_call(x, b\"\\\\xd0\\\\x1f\\\\xb1\\\\xb8\", max_outsize=32, gas=50000), 0, output_type=int128)  # noqa: E501\n    return o\n\n@external\ndef create_and_return_proxy(inp: address) -> address:\n    x: address = create_minimal_proxy_to(inp)\n    return x\n    \"\"\"\n\n    c2 = get_contract_with_gas_estimation(outer_code)\n    assert c2.create_and_call_returnten(c.address) == 10\n    c2.create_and_call_returnten(c.address, transact={})\n\n    _, preamble, callcode = eip1167_bytecode()\n\n    c3 = c2.create_and_return_proxy(c.address, call={})\n    c2.create_and_return_proxy(c.address, transact={})\n\n    c3_contract_code = w3.to_bytes(w3.eth.get_code(c3))\n\n    assert c3_contract_code[:10] == HexBytes(preamble)\n    assert c3_contract_code[-15:] == HexBytes(callcode)\n\n    print(\"Passed proxy test\")\n    # TODO: This one is special\n    # print(f'Gas consumed: {(chain.head_state.receipts[-1].gas_used - chain.head_state.receipts[-2].gas_used - chain.last_tx.intrinsic_gas_used)}')  # noqa: E501\n\n\ndef test_multiple_levels2(assert_tx_failed, get_contract_with_gas_estimation):\n    inner_code = \"\"\"\n@external\ndef returnten() -> int128:\n    raise\n    \"\"\"\n\n    c = get_contract_with_gas_estimation(inner_code)\n\n    outer_code = \"\"\"\n@external\ndef create_and_call_returnten(inp: address) -> int128:\n    x: address = create_minimal_proxy_to(inp)\n    o: int128 = extract32(raw_call(x, b\"\\\\xd0\\\\x1f\\\\xb1\\\\xb8\", max_outsize=32, gas=50000), 0, output_type=int128)  # noqa: E501\n    return o\n\n@external\ndef create_and_return_proxy(inp: address) -> address:\n    return create_minimal_proxy_to(inp)\n    \"\"\"\n\n    c2 = get_contract_with_gas_estimation(outer_code)\n\n    assert_tx_failed(lambda: c2.create_and_call_returnten(c.address))\n\n    print(\"Passed minimal proxy exception test\")\n\n\ndef test_delegate_call(w3, get_contract):\n    inner_code = \"\"\"\na: address  # this is required for storage alignment...\nowners: public(address[5])\n\n@external\ndef set_owner(i: int128, o: address):\n    self.owners[i] = o\n    \"\"\"\n\n    inner_contract = get_contract(inner_code)\n\n    outer_code = \"\"\"\nowner_setter_contract: public(address)\nowners: public(address[5])\n\n\n@external\ndef __init__(_owner_setter: address):\n    self.owner_setter_contract = _owner_setter\n\n\n@external\ndef set(i: int128, owner: address):\n    # delegate setting owners to other contract.s\n    cdata: Bytes[68] = concat(method_id(\"set_owner(int128,address)\"), convert(i, bytes32), convert(owner, bytes32))  # noqa: E501\n    raw_call(\n        self.owner_setter_contract,\n        cdata,\n        gas=msg.gas,\n        max_outsize=0,\n        is_delegate_call=True\n    )\n    \"\"\"\n\n    a0, a1, a2 = w3.eth.accounts[:3]\n    outer_contract = get_contract(outer_code, *[inner_contract.address])\n\n    # Test setting on inners contract's state setting works.\n    inner_contract.set_owner(1, a2, transact={})\n    assert inner_contract.owners(1) == a2\n\n    # Confirm outer contract's state is empty and contract to call has been set.\n    assert outer_contract.owner_setter_contract() == inner_contract.address\n    assert outer_contract.owners(1) is None\n\n    # Call outer contract, that make a delegate call to inner_contract.\n    tx_hash = outer_contract.set(1, a1, transact={})\n    assert w3.eth.get_transaction_receipt(tx_hash)[\"status\"] == 1\n    assert outer_contract.owners(1) == a1\n\n\ndef test_gas(get_contract, assert_tx_failed):\n    inner_code = \"\"\"\nbar: bytes32\n\n@external\ndef foo(_bar: bytes32):\n    self.bar = _bar\n    \"\"\"\n\n    inner_contract = get_contract(inner_code)\n\n    outer_code = \"\"\"\n@external\ndef foo_call(_addr: address):\n    cdata: Bytes[40] = concat(\n        method_id(\"foo(bytes32)\"),\n        0x0000000000000000000000000000000000000000000000000000000000000001\n    )\n    raw_call(_addr, cdata, max_outsize=0{})\n    \"\"\"\n\n    # with no gas value given, enough will be forwarded to complete the call\n    outer_contract = get_contract(outer_code.format(\"\"))\n    outer_contract.foo_call(inner_contract.address)\n\n    # manually specifying a sufficient amount should succeed\n    outer_contract = get_contract(outer_code.format(\", gas=50000\"))\n    outer_contract.foo_call(inner_contract.address)\n\n    # manually specifying an insufficient amount should fail\n    outer_contract = get_contract(outer_code.format(\", gas=15000\"))\n    assert_tx_failed(lambda: outer_contract.foo_call(inner_contract.address))\n\n\ndef test_static_call(get_contract):\n    target_source = \"\"\"\n@external\n@view\ndef foo() -> int128:\n    return 42\n\"\"\"\n\n    caller_source = \"\"\"\n@external\n@view\ndef foo(_addr: address) -> int128:\n    _response: Bytes[32] = raw_call(\n        _addr,\n        method_id(\"foo()\"),\n        max_outsize=32,\n        is_static_call=True,\n    )\n    return convert(_response, int128)\n    \"\"\"\n\n    target = get_contract(target_source)\n    caller = get_contract(caller_source)\n\n    assert caller.foo(target.address) == 42\n\n\ndef test_forward_calldata(get_contract, w3, keccak):\n    target_source = \"\"\"\n@external\ndef foo() -> uint256:\n    return 123\n    \"\"\"\n\n    caller_source = \"\"\"\ntarget: address\n\n@external\ndef set_target(target: address):\n    self.target = target\n\n@external\ndef __default__():\n    assert 123 == _abi_decode(raw_call(self.target, msg.data, max_outsize=32), uint256)\n    \"\"\"\n\n    target = get_contract(target_source)\n\n    caller = get_contract(caller_source)\n    caller.set_target(target.address, transact={})\n\n    # manually construct msg.data for `caller` contract\n    sig = keccak(\"foo()\".encode()).hex()[:10]\n    w3.eth.send_transaction({\"to\": caller.address, \"data\": sig})\n\n\ndef test_static_call_fails_nonpayable(get_contract, assert_tx_failed):\n    target_source = \"\"\"\nbaz: int128\n\n@external\ndef foo() -> int128:\n    self.baz = 31337\n    return self.baz\n\"\"\"\n\n    caller_source = \"\"\"\n@external\n@view\ndef foo(_addr: address) -> int128:\n    _response: Bytes[32] = raw_call(\n        _addr,\n        method_id(\"foo()\"),\n        max_outsize=32,\n        is_static_call=True,\n    )\n    return convert(_response, int128)\n    \"\"\"\n\n    target = get_contract(target_source)\n    caller = get_contract(caller_source)\n\n    assert_tx_failed(lambda: caller.foo(target.address))\n\n\ndef test_checkable_raw_call(get_contract, assert_tx_failed):\n    target_source = \"\"\"\nbaz: int128\n@external\ndef fail1(should_raise: bool):\n    if should_raise:\n        raise \"fail\"\n# test both paths for raw_call -\n# they are different depending if callee has or doesn't have returntype\n@external\ndef fail2(should_raise: bool) -> int128:\n    if should_raise:\n        self.baz = self.baz + 1\n    return self.baz\n\"\"\"\n\n    caller_source = \"\"\"\n@external\n@view\ndef foo(_addr: address, should_raise: bool) -> uint256:\n    success: bool = True\n    response: Bytes[32] = b\"\"\n    success, response = raw_call(\n        _addr,\n        _abi_encode(should_raise, method_id=method_id(\"fail1(bool)\")),\n        max_outsize=32,\n        is_static_call=True,\n        revert_on_failure=False,\n    )\n    assert success == (not should_raise)\n    return 1\n@external\n@view\ndef bar(_addr: address, should_raise: bool) -> uint256:\n    success: bool = True\n    response: Bytes[32] = b\"\"\n    success, response = raw_call(\n        _addr,\n        _abi_encode(should_raise, method_id=method_id(\"fail2(bool)\")),\n        max_outsize=32,\n        is_static_call=True,\n        revert_on_failure=False,\n    )\n    assert success == (not should_raise)\n    return 2\n    \"\"\"\n\n    target = get_contract(target_source)\n    caller = get_contract(caller_source)\n\n    assert caller.foo(target.address, True) == 1\n    assert caller.foo(target.address, False) == 1\n    assert caller.bar(target.address, True) == 2\n    assert caller.bar(target.address, False) == 2\n\n\nuncompilable_code = [\n    (\n        \"\"\"\n@external\n@view\ndef foo(_addr: address):\n    raw_call(_addr, method_id(\"foo()\"))\n    \"\"\",\n        StateAccessViolation,\n    ),\n    (\n        \"\"\"\n@external\ndef foo(_addr: address):\n    raw_call(_addr, method_id(\"foo()\"), is_delegate_call=True, is_static_call=True)\n    \"\"\",\n        ArgumentException,\n    ),\n    (\n        \"\"\"\n@external\n@view\ndef foo(_addr: address):\n    raw_call(_addr, 256)\n    \"\"\",\n        InvalidType,\n    ),\n]\n\n\n@pytest.mark.parametrize(\"source_code,exc\", uncompilable_code)\ndef test_invalid_type_exception(\n    assert_compile_failed, get_contract_with_gas_estimation, source_code, exc\n):\n    assert_compile_failed(lambda: get_contract_with_gas_estimation(source_code), exc)\n", "import hashlib\nimport math\nimport operator\nfrom decimal import Decimal\n\nfrom vyper import ast as vy_ast\nfrom vyper.abi_types import ABI_Tuple\nfrom vyper.address_space import MEMORY, STORAGE\nfrom vyper.ast.validation import validate_call_args\nfrom vyper.codegen.abi_encoder import abi_encode\nfrom vyper.codegen.context import Context, VariableRecord\nfrom vyper.codegen.core import (\n    STORE,\n    IRnode,\n    _freshname,\n    add_ofst,\n    bytes_data_ptr,\n    calculate_type_for_external_return,\n    check_external_call,\n    clamp,\n    clamp2,\n    clamp_basetype,\n    clamp_nonzero,\n    copy_bytes,\n    ensure_in_memory,\n    eval_once_check,\n    eval_seq,\n    get_bytearray_length,\n    get_element_ptr,\n    get_type_for_exact_size,\n    ir_tuple_from_args,\n    needs_external_call_wrap,\n    promote_signed_int,\n    sar,\n    shl,\n    shr,\n    unwrap_location,\n)\nfrom vyper.codegen.expr import Expr\nfrom vyper.codegen.ir_node import Encoding\nfrom vyper.codegen.keccak256_helper import keccak256_helper\nfrom vyper.exceptions import (\n    ArgumentException,\n    CompilerPanic,\n    InvalidLiteral,\n    InvalidType,\n    OverflowException,\n    StateAccessViolation,\n    StructureException,\n    TypeMismatch,\n    UnfoldableNode,\n    ZeroDivisionException,\n)\nfrom vyper.semantics.analysis.base import VarInfo\nfrom vyper.semantics.analysis.utils import (\n    get_common_types,\n    get_exact_type_from_node,\n    get_possible_types_from_node,\n    validate_expected_type,\n)\nfrom vyper.semantics.types import (\n    TYPE_T,\n    AddressT,\n    BoolT,\n    BytesM_T,\n    BytesT,\n    DArrayT,\n    DecimalT,\n    HashMapT,\n    IntegerT,\n    KwargSettings,\n    SArrayT,\n    StringT,\n    TupleT,\n)\nfrom vyper.semantics.types.bytestrings import _BytestringT\nfrom vyper.semantics.types.shortcuts import (\n    BYTES4_T,\n    BYTES32_T,\n    INT128_T,\n    INT256_T,\n    UINT8_T,\n    UINT256_T,\n)\nfrom vyper.semantics.types.utils import type_from_annotation\nfrom vyper.utils import (\n    DECIMAL_DIVISOR,\n    EIP_170_LIMIT,\n    SHA3_PER_WORD,\n    MemoryPositions,\n    SizeLimits,\n    bytes_to_int,\n    ceil32,\n    fourbytes_to_int,\n    keccak256,\n    method_id_int,\n    vyper_warn,\n)\n\nfrom ._convert import convert\nfrom ._signatures import BuiltinFunction, process_inputs\n\nSHA256_ADDRESS = 2\nSHA256_BASE_GAS = 60\nSHA256_PER_WORD_GAS = 12\n\n\nclass FoldedFunction(BuiltinFunction):\n    # Base class for nodes which should always be folded\n\n    # Since foldable builtin functions are not folded before semantics validation,\n    # this flag is used for `check_kwargable` in semantics validation.\n    _kwargable = True\n\n\nclass TypenameFoldedFunction(FoldedFunction):\n    # Base class for builtin functions that:\n    # (1) take a typename as the only argument; and\n    # (2) should always be folded.\n\n    # \"TYPE_DEFINITION\" is a placeholder value for a type definition string, and\n    # will be replaced by a `TypeTypeDefinition` object in `infer_arg_types`.\n    _inputs = [(\"typename\", \"TYPE_DEFINITION\")]\n\n    def fetch_call_return(self, node):\n        type_ = self.infer_arg_types(node)[0].typedef\n        return type_\n\n    def infer_arg_types(self, node):\n        validate_call_args(node, 1)\n        input_typedef = TYPE_T(type_from_annotation(node.args[0]))\n        return [input_typedef]\n\n\nclass Floor(BuiltinFunction):\n    _id = \"floor\"\n    _inputs = [(\"value\", DecimalT())]\n    # TODO: maybe use int136?\n    _return_type = INT256_T\n\n    def evaluate(self, node):\n        validate_call_args(node, 1)\n        if not isinstance(node.args[0], vy_ast.Decimal):\n            raise UnfoldableNode\n\n        value = math.floor(node.args[0].value)\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list(\n            [\n                \"if\",\n                [\"slt\", args[0], 0],\n                [\"sdiv\", [\"sub\", args[0], DECIMAL_DIVISOR - 1], DECIMAL_DIVISOR],\n                [\"sdiv\", args[0], DECIMAL_DIVISOR],\n            ],\n            typ=INT256_T,\n        )\n\n\nclass Ceil(BuiltinFunction):\n    _id = \"ceil\"\n    _inputs = [(\"value\", DecimalT())]\n    # TODO: maybe use int136?\n    _return_type = INT256_T\n\n    def evaluate(self, node):\n        validate_call_args(node, 1)\n        if not isinstance(node.args[0], vy_ast.Decimal):\n            raise UnfoldableNode\n\n        value = math.ceil(node.args[0].value)\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list(\n            [\n                \"if\",\n                [\"slt\", args[0], 0],\n                [\"sdiv\", args[0], DECIMAL_DIVISOR],\n                [\"sdiv\", [\"add\", args[0], DECIMAL_DIVISOR - 1], DECIMAL_DIVISOR],\n            ],\n            typ=INT256_T,\n        )\n\n\nclass Convert(BuiltinFunction):\n    _id = \"convert\"\n\n    def fetch_call_return(self, node):\n        _, target_typedef = self.infer_arg_types(node)\n\n        # note: more type conversion validation happens in convert.py\n        return target_typedef.typedef\n\n    # TODO: push this down into convert.py for more consistency\n    def infer_arg_types(self, node):\n        validate_call_args(node, 2)\n\n        target_type = type_from_annotation(node.args[1])\n        value_types = get_possible_types_from_node(node.args[0])\n\n        # For `convert` of integer literals, we need to match type inference rules in\n        # convert.py codegen routines.\n        # TODO: This can probably be removed once constant folding for `convert` is implemented\n        if len(value_types) > 1 and all(isinstance(v, IntegerT) for v in value_types):\n            # Get the smallest (and unsigned if available) type for non-integer target types\n            # (note this is different from the ordering returned by `get_possible_types_from_node`)\n            if not isinstance(target_type, IntegerT):\n                value_types = sorted(value_types, key=lambda v: (v.is_signed, v.bits), reverse=True)\n            else:\n                # filter out the target type from list of possible types\n                value_types = [i for i in value_types if not target_type.compare_type(i)]\n\n        value_type = value_types.pop()\n\n        # block conversions between same type\n        if target_type.compare_type(value_type):\n            raise InvalidType(f\"Value and target type are both '{target_type}'\", node)\n\n        return [value_type, TYPE_T(target_type)]\n\n    def build_IR(self, expr, context):\n        return convert(expr, context)\n\n\nADHOC_SLICE_NODE_MACROS = [\"~calldata\", \"~selfcode\", \"~extcode\"]\n\n\ndef _build_adhoc_slice_node(sub: IRnode, start: IRnode, length: IRnode, context: Context) -> IRnode:\n    assert length.is_literal, \"typechecker failed\"\n    assert isinstance(length.value, int)  # mypy hint\n\n    dst_typ = BytesT(length.value)\n    # allocate a buffer for the return value\n    np = context.new_internal_variable(dst_typ)\n\n    # `msg.data` by `calldatacopy`\n    if sub.value == \"~calldata\":\n        node = [\n            \"seq\",\n            [\"assert\", [\"le\", [\"add\", start, length], \"calldatasize\"]],  # runtime bounds check\n            [\"mstore\", np, length],\n            [\"calldatacopy\", np + 32, start, length],\n            np,\n        ]\n\n    # `self.code` by `codecopy`\n    elif sub.value == \"~selfcode\":\n        node = [\n            \"seq\",\n            [\"assert\", [\"le\", [\"add\", start, length], \"codesize\"]],  # runtime bounds check\n            [\"mstore\", np, length],\n            [\"codecopy\", np + 32, start, length],\n            np,\n        ]\n\n    # `<address>.code` by `extcodecopy`\n    else:\n        assert sub.value == \"~extcode\" and len(sub.args) == 1\n        node = [\n            \"with\",\n            \"_extcode_address\",\n            sub.args[0],\n            [\n                \"seq\",\n                # runtime bounds check\n                [\"assert\", [\"le\", [\"add\", start, length], [\"extcodesize\", \"_extcode_address\"]]],\n                [\"mstore\", np, length],\n                [\"extcodecopy\", \"_extcode_address\", np + 32, start, length],\n                np,\n            ],\n        ]\n\n    assert isinstance(length.value, int)  # mypy hint\n    return IRnode.from_list(node, typ=BytesT(length.value), location=MEMORY)\n\n\n# note: this and a lot of other builtins could be refactored to accept any uint type\nclass Slice(BuiltinFunction):\n    _id = \"slice\"\n    _inputs = [\n        (\"b\", (BYTES32_T, BytesT.any(), StringT.any())),\n        (\"start\", UINT256_T),\n        (\"length\", UINT256_T),\n    ]\n    _return_type = None\n\n    def fetch_call_return(self, node):\n        arg_type, _, _ = self.infer_arg_types(node)\n\n        if isinstance(arg_type, StringT):\n            return_type = StringT()\n        else:\n            return_type = BytesT()\n\n        # validate start and length are in bounds\n\n        arg = node.args[0]\n        start_expr = node.args[1]\n        length_expr = node.args[2]\n\n        # CMC 2022-03-22 NOTE slight code duplication with semantics/analysis/local\n        is_adhoc_slice = arg.get(\"attr\") == \"code\" or (\n            arg.get(\"value.id\") == \"msg\" and arg.get(\"attr\") == \"data\"\n        )\n\n        start_literal = start_expr.value if isinstance(start_expr, vy_ast.Int) else None\n        length_literal = length_expr.value if isinstance(length_expr, vy_ast.Int) else None\n\n        if not is_adhoc_slice:\n            if length_literal is not None:\n                if length_literal < 1:\n                    raise ArgumentException(\"Length cannot be less than 1\", length_expr)\n\n                if length_literal > arg_type.length:\n                    raise ArgumentException(f\"slice out of bounds for {arg_type}\", length_expr)\n\n            if start_literal is not None:\n                if start_literal > arg_type.length:\n                    raise ArgumentException(f\"slice out of bounds for {arg_type}\", start_expr)\n                if length_literal is not None and start_literal + length_literal > arg_type.length:\n                    raise ArgumentException(f\"slice out of bounds for {arg_type}\", node)\n\n        # we know the length statically\n        if length_literal is not None:\n            return_type.set_length(length_literal)\n        else:\n            return_type.set_min_length(arg_type.length)\n\n        return return_type\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n        # return a concrete type for `b`\n        b_type = get_possible_types_from_node(node.args[0]).pop()\n        return [b_type, self._inputs[1][1], self._inputs[2][1]]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        src, start, length = args\n\n        # Handle `msg.data`, `self.code`, and `<address>.code`\n        if src.value in ADHOC_SLICE_NODE_MACROS:\n            return _build_adhoc_slice_node(src, start, length, context)\n\n        is_bytes32 = src.typ == BYTES32_T\n        if src.location is None:\n            # it's not a pointer; force it to be one since\n            # copy_bytes works on pointers.\n            assert is_bytes32, src\n            src = ensure_in_memory(src, context)\n\n        with src.cache_when_complex(\"src\") as (b1, src), start.cache_when_complex(\"start\") as (\n            b2,\n            start,\n        ), length.cache_when_complex(\"length\") as (b3, length):\n            if is_bytes32:\n                src_maxlen = 32\n            else:\n                src_maxlen = src.typ.maxlen\n\n            dst_maxlen = length.value if length.is_literal else src_maxlen\n\n            buflen = dst_maxlen\n\n            # add 32 bytes to the buffer size bc word access might\n            # be unaligned (see below)\n            if src.location == STORAGE:\n                buflen += 32\n\n            # Get returntype string or bytes\n            assert isinstance(src.typ, _BytestringT) or is_bytes32\n            # TODO: try to get dst_typ from semantic analysis\n            if isinstance(src.typ, StringT):\n                dst_typ = StringT(dst_maxlen)\n            else:\n                dst_typ = BytesT(dst_maxlen)\n\n            # allocate a buffer for the return value\n            buf = context.new_internal_variable(BytesT(buflen))\n            # assign it the correct return type.\n            # (note mismatch between dst_maxlen and buflen)\n            dst = IRnode.from_list(buf, typ=dst_typ, location=MEMORY)\n\n            dst_data = bytes_data_ptr(dst)\n\n            if is_bytes32:\n                src_len = 32\n                src_data = src\n            else:\n                src_len = get_bytearray_length(src)\n                src_data = bytes_data_ptr(src)\n\n            # general case. byte-for-byte copy\n            if src.location == STORAGE:\n                # because slice uses byte-addressing but storage\n                # is word-aligned, this algorithm starts at some number\n                # of bytes before the data section starts, and might copy\n                # an extra word. the pseudocode is:\n                #   dst_data = dst + 32\n                #   copy_dst = dst_data - start % 32\n                #   src_data = src + 32\n                #   copy_src = src_data + (start - start % 32) / 32\n                #            = src_data + (start // 32)\n                #   copy_bytes(copy_dst, copy_src, length)\n                #   //set length AFTER copy because the length word has been clobbered!\n                #   mstore(src, length)\n\n                # start at the first word-aligned address before `start`\n                # e.g. start == byte 7 -> we start copying from byte 0\n                #      start == byte 32 -> we start copying from byte 32\n                copy_src = IRnode.from_list(\n                    [\"add\", src_data, [\"div\", start, 32]], location=src.location\n                )\n\n                # e.g. start == byte 0 -> we copy to dst_data + 0\n                #      start == byte 7 -> we copy to dst_data - 7\n                #      start == byte 33 -> we copy to dst_data - 1\n                copy_dst = IRnode.from_list(\n                    [\"sub\", dst_data, [\"mod\", start, 32]], location=dst.location\n                )\n\n                # len + (32 if start % 32 > 0 else 0)\n                copy_len = [\"add\", length, [\"mul\", 32, [\"iszero\", [\"iszero\", [\"mod\", start, 32]]]]]\n                copy_maxlen = buflen\n\n            else:\n                # all other address spaces (mem, calldata, code) we have\n                # byte-aligned access so we can just do the easy thing,\n                # memcopy(dst_data, src_data + dst_data)\n\n                copy_src = add_ofst(src_data, start)\n                copy_dst = dst_data\n                copy_len = length\n                copy_maxlen = buflen\n\n            do_copy = copy_bytes(copy_dst, copy_src, copy_len, copy_maxlen)\n\n            ret = [\n                \"seq\",\n                # make sure we don't overrun the source buffer\n                [\"assert\", [\"le\", [\"add\", start, length], src_len]],  # bounds check\n                do_copy,\n                [\"mstore\", dst, length],  # set length\n                dst,  # return pointer to dst\n            ]\n            ret = IRnode.from_list(ret, typ=dst_typ, location=MEMORY)\n            return b1.resolve(b2.resolve(b3.resolve(ret)))\n\n\nclass Len(BuiltinFunction):\n    _id = \"len\"\n    _inputs = [(\"b\", (StringT.any(), BytesT.any(), DArrayT.any()))]\n    _return_type = UINT256_T\n\n    def evaluate(self, node):\n        validate_call_args(node, 1)\n        arg = node.args[0]\n        if isinstance(arg, (vy_ast.Str, vy_ast.Bytes)):\n            length = len(arg.value)\n        elif isinstance(arg, vy_ast.Hex):\n            # 2 characters represent 1 byte and we subtract 1 to ignore the leading `0x`\n            length = len(arg.value) // 2 - 1\n        else:\n            raise UnfoldableNode\n\n        return vy_ast.Int.from_node(node, value=length)\n\n    def build_IR(self, node, context):\n        arg = Expr(node.args[0], context).ir_node\n        if arg.value == \"~calldata\":\n            return IRnode.from_list([\"calldatasize\"], typ=UINT256_T)\n        return get_bytearray_length(arg)\n\n\nclass Concat(BuiltinFunction):\n    _id = \"concat\"\n\n    def fetch_call_return(self, node):\n        arg_types = self.infer_arg_types(node)\n\n        length = 0\n        for arg_t in arg_types:\n            length += arg_t.length\n\n        if isinstance(arg_types[0], (StringT)):\n            return_type = StringT()\n        else:\n            return_type = BytesT()\n        return_type.set_length(length)\n        return return_type\n\n    def infer_arg_types(self, node):\n        if len(node.args) < 2:\n            raise ArgumentException(\"Invalid argument count: expected at least 2\", node)\n\n        if node.keywords:\n            raise ArgumentException(\"Keyword arguments are not accepted here\", node.keywords[0])\n\n        ret = []\n        prev_typeclass = None\n        for arg in node.args:\n            validate_expected_type(arg, (BytesT.any(), StringT.any(), BytesM_T.any()))\n            arg_t = get_possible_types_from_node(arg).pop()\n            current_typeclass = \"String\" if isinstance(arg_t, StringT) else \"Bytes\"\n            if prev_typeclass and current_typeclass != prev_typeclass:\n                raise TypeMismatch(\n                    (\n                        \"Concat expects consistent use of string or bytes types, \"\n                        \"use either string or bytes.\"\n                    ),\n                    arg,\n                )\n            prev_typeclass = current_typeclass\n            ret.append(arg_t)\n\n        return ret\n\n    def build_IR(self, expr, context):\n        args = [Expr(arg, context).ir_node for arg in expr.args]\n        if len(args) < 2:\n            raise StructureException(\"Concat expects at least two arguments\", expr)\n\n        # Maximum length of the output\n        dst_maxlen = sum(\n            [arg.typ.maxlen if isinstance(arg.typ, _BytestringT) else arg.typ.m for arg in args]\n        )\n\n        # TODO: try to grab these from semantic analysis\n        if isinstance(args[0].typ, StringT):\n            ret_typ = StringT(dst_maxlen)\n        else:\n            ret_typ = BytesT(dst_maxlen)\n\n        # Node representing the position of the output in memory\n        dst = IRnode.from_list(\n            context.new_internal_variable(ret_typ),\n            typ=ret_typ,\n            location=MEMORY,\n            annotation=\"concat destination\",\n        )\n\n        ret = [\"seq\"]\n        # stack item representing our current offset in the dst buffer\n        ofst = \"concat_ofst\"\n\n        # TODO: optimize for the case where all lengths are statically known.\n        for arg in args:\n            dst_data = add_ofst(bytes_data_ptr(dst), ofst)\n\n            if isinstance(arg.typ, _BytestringT):\n                # Ignore empty strings\n                if arg.typ.maxlen == 0:\n                    continue\n\n                with arg.cache_when_complex(\"arg\") as (b1, arg):\n                    argdata = bytes_data_ptr(arg)\n\n                    with get_bytearray_length(arg).cache_when_complex(\"len\") as (b2, arglen):\n                        do_copy = [\n                            \"seq\",\n                            copy_bytes(dst_data, argdata, arglen, arg.typ.maxlen),\n                            [\"set\", ofst, [\"add\", ofst, arglen]],\n                        ]\n                        ret.append(b1.resolve(b2.resolve(do_copy)))\n\n            else:\n                ret.append(STORE(dst_data, unwrap_location(arg)))\n                ret.append([\"set\", ofst, [\"add\", ofst, arg.typ.m]])\n\n        ret.append(STORE(dst, ofst))\n\n        # Memory location of the output\n        ret.append(dst)\n\n        return IRnode.from_list(\n            [\"with\", ofst, 0, ret], typ=ret_typ, location=MEMORY, annotation=\"concat\"\n        )\n\n\nclass Keccak256(BuiltinFunction):\n    _id = \"keccak256\"\n    # TODO allow any BytesM_T\n    _inputs = [(\"value\", (BytesT.any(), BYTES32_T, StringT.any()))]\n    _return_type = BYTES32_T\n\n    def evaluate(self, node):\n        validate_call_args(node, 1)\n        if isinstance(node.args[0], vy_ast.Bytes):\n            value = node.args[0].value\n        elif isinstance(node.args[0], vy_ast.Str):\n            value = node.args[0].value.encode()\n        elif isinstance(node.args[0], vy_ast.Hex):\n            length = len(node.args[0].value) // 2 - 1\n            value = int(node.args[0].value, 16).to_bytes(length, \"big\")\n        else:\n            raise UnfoldableNode\n\n        hash_ = f\"0x{keccak256(value).hex()}\"\n        return vy_ast.Hex.from_node(node, value=hash_)\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n        # return a concrete type for `value`\n        value_type = get_possible_types_from_node(node.args[0]).pop()\n        return [value_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        assert len(args) == 1\n        return keccak256_helper(expr, args[0], context)\n\n\ndef _make_sha256_call(inp_start, inp_len, out_start, out_len):\n    return [\n        \"assert\",\n        [\n            \"staticcall\",\n            [\"gas\"],  # gas\n            SHA256_ADDRESS,  # address\n            inp_start,\n            inp_len,\n            out_start,\n            out_len,\n        ],\n    ]\n\n\nclass Sha256(BuiltinFunction):\n    _id = \"sha256\"\n    _inputs = [(\"value\", (BYTES32_T, BytesT.any(), StringT.any()))]\n    _return_type = BYTES32_T\n\n    def evaluate(self, node):\n        validate_call_args(node, 1)\n        if isinstance(node.args[0], vy_ast.Bytes):\n            value = node.args[0].value\n        elif isinstance(node.args[0], vy_ast.Str):\n            value = node.args[0].value.encode()\n        elif isinstance(node.args[0], vy_ast.Hex):\n            length = len(node.args[0].value) // 2 - 1\n            value = int(node.args[0].value, 16).to_bytes(length, \"big\")\n        else:\n            raise UnfoldableNode\n\n        hash_ = f\"0x{hashlib.sha256(value).hexdigest()}\"\n        return vy_ast.Hex.from_node(node, value=hash_)\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n        # return a concrete type for `value`\n        value_type = get_possible_types_from_node(node.args[0]).pop()\n        return [value_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        sub = args[0]\n        # bytes32 input\n        if sub.typ == BYTES32_T:\n            return IRnode.from_list(\n                [\n                    \"seq\",\n                    [\"mstore\", MemoryPositions.FREE_VAR_SPACE, sub],\n                    _make_sha256_call(\n                        inp_start=MemoryPositions.FREE_VAR_SPACE,\n                        inp_len=32,\n                        out_start=MemoryPositions.FREE_VAR_SPACE,\n                        out_len=32,\n                    ),\n                    [\"mload\", MemoryPositions.FREE_VAR_SPACE],  # push value onto stack\n                ],\n                typ=BYTES32_T,\n                add_gas_estimate=SHA256_BASE_GAS + 1 * SHA256_PER_WORD_GAS,\n            )\n        # bytearay-like input\n        # special case if it's already in memory\n        sub = ensure_in_memory(sub, context)\n\n        return IRnode.from_list(\n            [\n                \"with\",\n                \"_sub\",\n                sub,\n                [\n                    \"seq\",\n                    _make_sha256_call(\n                        # TODO use add_ofst if sub is statically known\n                        inp_start=[\"add\", \"_sub\", 32],\n                        inp_len=[\"mload\", \"_sub\"],\n                        out_start=MemoryPositions.FREE_VAR_SPACE,\n                        out_len=32,\n                    ),\n                    [\"mload\", MemoryPositions.FREE_VAR_SPACE],\n                ],\n            ],\n            typ=BYTES32_T,\n            add_gas_estimate=SHA256_BASE_GAS + sub.typ.maxlen * SHA256_PER_WORD_GAS,\n        )\n\n\nclass MethodID(FoldedFunction):\n    _id = \"method_id\"\n\n    def evaluate(self, node):\n        validate_call_args(node, 1, [\"output_type\"])\n\n        args = node.args\n        if not isinstance(args[0], vy_ast.Str):\n            raise InvalidType(\"method id must be given as a literal string\", args[0])\n        if \" \" in args[0].value:\n            raise InvalidLiteral(\"Invalid function signature - no spaces allowed.\")\n\n        return_type = self.infer_kwarg_types(node)\n        value = method_id_int(args[0].value)\n\n        if return_type.compare_type(BYTES4_T):\n            return vy_ast.Hex.from_node(node, value=hex(value))\n        else:\n            return vy_ast.Bytes.from_node(node, value=value.to_bytes(4, \"big\"))\n\n    def fetch_call_return(self, node):\n        validate_call_args(node, 1, [\"output_type\"])\n\n        type_ = self.infer_kwarg_types(node)\n        return type_\n\n    def infer_kwarg_types(self, node):\n        if node.keywords:\n            return_type = type_from_annotation(node.keywords[0].value)\n            if return_type.compare_type(BYTES4_T):\n                return BYTES4_T\n            elif isinstance(return_type, BytesT) and return_type.length == 4:\n                return BytesT(4)\n            else:\n                raise ArgumentException(\"output_type must be Bytes[4] or bytes4\", node.keywords[0])\n\n        # If `output_type` is not given, default to `Bytes[4]`\n        return BytesT(4)\n\n\nclass ECRecover(BuiltinFunction):\n    _id = \"ecrecover\"\n    _inputs = [\n        (\"hash\", BYTES32_T),\n        (\"v\", (UINT256_T, UINT8_T)),\n        (\"r\", (UINT256_T, BYTES32_T)),\n        (\"s\", (UINT256_T, BYTES32_T)),\n    ]\n    _return_type = AddressT()\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n        v_t, r_t, s_t = [get_possible_types_from_node(arg).pop() for arg in node.args[1:]]\n        return [BYTES32_T, v_t, r_t, s_t]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        placeholder_node = IRnode.from_list(\n            context.new_internal_variable(BytesT(128)), typ=BytesT(128), location=MEMORY\n        )\n        return IRnode.from_list(\n            [\n                \"seq\",\n                [\"mstore\", placeholder_node, args[0]],\n                [\"mstore\", [\"add\", placeholder_node, 32], args[1]],\n                [\"mstore\", [\"add\", placeholder_node, 64], args[2]],\n                [\"mstore\", [\"add\", placeholder_node, 96], args[3]],\n                [\n                    \"pop\",\n                    [\n                        \"staticcall\",\n                        [\"gas\"],\n                        1,\n                        placeholder_node,\n                        128,\n                        MemoryPositions.FREE_VAR_SPACE,\n                        32,\n                    ],\n                ],\n                [\"mload\", MemoryPositions.FREE_VAR_SPACE],\n            ],\n            typ=AddressT(),\n        )\n\n\ndef _getelem(arg, ind):\n    return unwrap_location(get_element_ptr(arg, IRnode.from_list(ind, typ=INT128_T)))\n\n\nclass ECAdd(BuiltinFunction):\n    _id = \"ecadd\"\n    _inputs = [(\"a\", SArrayT(UINT256_T, 2)), (\"b\", SArrayT(UINT256_T, 2))]\n    _return_type = SArrayT(UINT256_T, 2)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        placeholder_node = IRnode.from_list(\n            context.new_internal_variable(BytesT(128)), typ=BytesT(128), location=MEMORY\n        )\n        o = IRnode.from_list(\n            [\n                \"seq\",\n                [\"mstore\", placeholder_node, _getelem(args[0], 0)],\n                [\"mstore\", [\"add\", placeholder_node, 32], _getelem(args[0], 1)],\n                [\"mstore\", [\"add\", placeholder_node, 64], _getelem(args[1], 0)],\n                [\"mstore\", [\"add\", placeholder_node, 96], _getelem(args[1], 1)],\n                [\"assert\", [\"staticcall\", [\"gas\"], 6, placeholder_node, 128, placeholder_node, 64]],\n                placeholder_node,\n            ],\n            typ=SArrayT(UINT256_T, 2),\n            location=MEMORY,\n        )\n        return o\n\n\nclass ECMul(BuiltinFunction):\n    _id = \"ecmul\"\n    _inputs = [(\"point\", SArrayT(UINT256_T, 2)), (\"scalar\", UINT256_T)]\n    _return_type = SArrayT(UINT256_T, 2)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        placeholder_node = IRnode.from_list(\n            context.new_internal_variable(BytesT(128)), typ=BytesT(128), location=MEMORY\n        )\n        o = IRnode.from_list(\n            [\n                \"seq\",\n                [\"mstore\", placeholder_node, _getelem(args[0], 0)],\n                [\"mstore\", [\"add\", placeholder_node, 32], _getelem(args[0], 1)],\n                [\"mstore\", [\"add\", placeholder_node, 64], args[1]],\n                [\"assert\", [\"staticcall\", [\"gas\"], 7, placeholder_node, 96, placeholder_node, 64]],\n                placeholder_node,\n            ],\n            typ=SArrayT(UINT256_T, 2),\n            location=MEMORY,\n        )\n        return o\n\n\ndef _generic_element_getter(op):\n    def f(index):\n        return IRnode.from_list(\n            [op, [\"add\", \"_sub\", [\"add\", 32, [\"mul\", 32, index]]]], typ=INT128_T\n        )\n\n    return f\n\n\ndef _storage_element_getter(index):\n    return IRnode.from_list([\"sload\", [\"add\", \"_sub\", [\"add\", 1, index]]], typ=INT128_T)\n\n\nclass Extract32(BuiltinFunction):\n    _id = \"extract32\"\n    _inputs = [(\"b\", BytesT.any()), (\"start\", IntegerT.unsigneds())]\n    # \"TYPE_DEFINITION\" is a placeholder value for a type definition string, and\n    # will be replaced by a `TYPE_T` object in `infer_kwarg_types`\n    # (note that it is ignored in _validate_arg_types)\n    _kwargs = {\"output_type\": KwargSettings(\"TYPE_DEFINITION\", BYTES32_T)}\n    _return_type = None\n\n    def fetch_call_return(self, node):\n        self._validate_arg_types(node)\n        return_type = self.infer_kwarg_types(node)[\"output_type\"].typedef\n        return return_type\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n        input_type = get_possible_types_from_node(node.args[0]).pop()\n        return [input_type, UINT256_T]\n\n    def infer_kwarg_types(self, node):\n        if node.keywords:\n            output_type = type_from_annotation(node.keywords[0].value)\n            if not isinstance(output_type, (AddressT, BytesM_T, IntegerT)):\n                raise InvalidType(\n                    \"Output type must be one of integer, bytes32 or address\", node.keywords[0].value\n                )\n            output_typedef = TYPE_T(output_type)\n            node.keywords[0].value._metadata[\"type\"] = output_typedef\n        else:\n            output_typedef = TYPE_T(BYTES32_T)\n\n        return {\"output_type\": output_typedef}\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        sub, index = args\n        ret_type = kwargs[\"output_type\"]\n\n        # Get length and specific element\n        if sub.location == STORAGE:\n            lengetter = IRnode.from_list([\"sload\", \"_sub\"], typ=INT128_T)\n            elementgetter = _storage_element_getter\n\n        else:\n            op = sub.location.load_op\n            lengetter = IRnode.from_list([op, \"_sub\"], typ=INT128_T)\n            elementgetter = _generic_element_getter(op)\n\n        # TODO rewrite all this with cache_when_complex and bitshifts\n\n        # Special case: index known to be a multiple of 32\n        if isinstance(index.value, int) and not index.value % 32:\n            o = IRnode.from_list(\n                [\n                    \"with\",\n                    \"_sub\",\n                    sub,\n                    elementgetter(\n                        [\"div\", clamp2(0, index, [\"sub\", lengetter, 32], signed=True), 32]\n                    ),\n                ],\n                typ=ret_type,\n                annotation=\"extracting 32 bytes\",\n            )\n        # General case\n        else:\n            o = IRnode.from_list(\n                [\n                    \"with\",\n                    \"_sub\",\n                    sub,\n                    [\n                        \"with\",\n                        \"_len\",\n                        lengetter,\n                        [\n                            \"with\",\n                            \"_index\",\n                            clamp2(0, index, [\"sub\", \"_len\", 32], signed=True),\n                            [\n                                \"with\",\n                                \"_mi32\",\n                                [\"mod\", \"_index\", 32],\n                                [\n                                    \"with\",\n                                    \"_di32\",\n                                    [\"div\", \"_index\", 32],\n                                    [\n                                        \"if\",\n                                        \"_mi32\",\n                                        [\n                                            \"add\",\n                                            [\"mul\", elementgetter(\"_di32\"), [\"exp\", 256, \"_mi32\"]],\n                                            [\n                                                \"div\",\n                                                elementgetter([\"add\", \"_di32\", 1]),\n                                                [\"exp\", 256, [\"sub\", 32, \"_mi32\"]],\n                                            ],\n                                        ],\n                                        elementgetter(\"_di32\"),\n                                    ],\n                                ],\n                            ],\n                        ],\n                    ],\n                ],\n                typ=ret_type,\n                annotation=\"extract32\",\n            )\n        return IRnode.from_list(clamp_basetype(o), typ=ret_type)\n\n\nclass AsWeiValue(BuiltinFunction):\n    _id = \"as_wei_value\"\n    _inputs = [(\"value\", (IntegerT.any(), DecimalT())), (\"unit\", StringT.any())]\n    _return_type = UINT256_T\n\n    wei_denoms = {\n        (\"wei\",): 1,\n        (\"femtoether\", \"kwei\", \"babbage\"): 10**3,\n        (\"picoether\", \"mwei\", \"lovelace\"): 10**6,\n        (\"nanoether\", \"gwei\", \"shannon\"): 10**9,\n        (\"microether\", \"szabo\"): 10**12,\n        (\"milliether\", \"finney\"): 10**15,\n        (\"ether\",): 10**18,\n        (\"kether\", \"grand\"): 10**21,\n    }\n\n    def get_denomination(self, node):\n        if not isinstance(node.args[1], vy_ast.Str):\n            raise ArgumentException(\n                \"Wei denomination must be given as a literal string\", node.args[1]\n            )\n        try:\n            denom = next(v for k, v in self.wei_denoms.items() if node.args[1].value in k)\n        except StopIteration:\n            raise ArgumentException(\n                f\"Unknown denomination: {node.args[1].value}\", node.args[1]\n            ) from None\n\n        return denom\n\n    def evaluate(self, node):\n        validate_call_args(node, 2)\n        denom = self.get_denomination(node)\n\n        if not isinstance(node.args[0], (vy_ast.Decimal, vy_ast.Int)):\n            raise UnfoldableNode\n        value = node.args[0].value\n\n        if value < 0:\n            raise InvalidLiteral(\"Negative wei value not allowed\", node.args[0])\n\n        if isinstance(value, int) and value >= 2**256:\n            raise InvalidLiteral(\"Value out of range for uint256\", node.args[0])\n        if isinstance(value, Decimal) and value > SizeLimits.MAX_AST_DECIMAL:\n            raise InvalidLiteral(\"Value out of range for decimal\", node.args[0])\n\n        return vy_ast.Int.from_node(node, value=int(value * denom))\n\n    def fetch_call_return(self, node):\n        self.infer_arg_types(node)\n        return self._return_type\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n        # return a concrete type instead of abstract type\n        value_type = get_possible_types_from_node(node.args[0]).pop()\n        unit_type = get_possible_types_from_node(node.args[1]).pop()\n        return [value_type, unit_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        value = args[0]\n\n        denom_divisor = self.get_denomination(expr)\n        if value.typ in (UINT256_T, UINT8_T):\n            sub = [\n                \"with\",\n                \"ans\",\n                [\"mul\", value, denom_divisor],\n                [\n                    \"seq\",\n                    [\n                        \"assert\",\n                        [\"or\", [\"eq\", [\"div\", \"ans\", value], denom_divisor], [\"iszero\", value]],\n                    ],\n                    \"ans\",\n                ],\n            ]\n        elif value.typ == INT128_T:\n            # signed types do not require bounds checks because the\n            # largest possible converted value will not overflow 2**256\n            sub = [\"seq\", [\"assert\", [\"sgt\", value, -1]], [\"mul\", value, denom_divisor]]\n        elif value.typ == DecimalT():\n            sub = [\n                \"seq\",\n                [\"assert\", [\"sgt\", value, -1]],\n                [\"div\", [\"mul\", value, denom_divisor], DECIMAL_DIVISOR],\n            ]\n        else:\n            raise CompilerPanic(f\"Unexpected type: {value.typ}\")\n\n        return IRnode.from_list(sub, typ=UINT256_T)\n\n\nzero_value = IRnode.from_list(0, typ=UINT256_T)\nempty_value = IRnode.from_list(0, typ=BYTES32_T)\n\n\nclass RawCall(BuiltinFunction):\n    _id = \"raw_call\"\n    _inputs = [(\"to\", AddressT()), (\"data\", BytesT.any())]\n    _kwargs = {\n        \"max_outsize\": KwargSettings(UINT256_T, 0, require_literal=True),\n        \"gas\": KwargSettings(UINT256_T, \"gas\"),\n        \"value\": KwargSettings(UINT256_T, zero_value),\n        \"is_delegate_call\": KwargSettings(BoolT(), False, require_literal=True),\n        \"is_static_call\": KwargSettings(BoolT(), False, require_literal=True),\n        \"revert_on_failure\": KwargSettings(BoolT(), True, require_literal=True),\n    }\n    _return_type = None\n\n    def fetch_call_return(self, node):\n        self._validate_arg_types(node)\n\n        kwargz = {i.arg: i.value for i in node.keywords}\n\n        outsize = kwargz.get(\"max_outsize\")\n        revert_on_failure = kwargz.get(\"revert_on_failure\")\n        revert_on_failure = revert_on_failure.value if revert_on_failure is not None else True\n\n        if outsize is None:\n            if revert_on_failure:\n                return None\n            return BoolT()\n\n        if not isinstance(outsize, vy_ast.Int) or outsize.value < 0:\n            raise\n\n        if outsize.value:\n            return_type = BytesT()\n            return_type.set_min_length(outsize.value)\n\n            if revert_on_failure:\n                return return_type\n            return TupleT([BoolT(), return_type])\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n        # return a concrete type for `data`\n        data_type = get_possible_types_from_node(node.args[1]).pop()\n        return [self._inputs[0][1], data_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        to, data = args\n        # TODO: must compile in source code order, left-to-right\n        gas, value, outsize, delegate_call, static_call, revert_on_failure = (\n            kwargs[\"gas\"],\n            kwargs[\"value\"],\n            kwargs[\"max_outsize\"],\n            kwargs[\"is_delegate_call\"],\n            kwargs[\"is_static_call\"],\n            kwargs[\"revert_on_failure\"],\n        )\n\n        if delegate_call and static_call:\n            raise ArgumentException(\n                \"Call may use one of `is_delegate_call` or `is_static_call`, not both\", expr\n            )\n        if not static_call and context.is_constant():\n            raise StateAccessViolation(\n                f\"Cannot make modifying calls from {context.pp_constancy()},\"\n                \" use `is_static_call=True` to perform this action\",\n                expr,\n            )\n\n        if data.value == \"~calldata\":\n            call_ir = [\"with\", \"mem_ofst\", \"msize\"]\n            args_ofst = [\"seq\", [\"calldatacopy\", \"mem_ofst\", 0, \"calldatasize\"], \"mem_ofst\"]\n            args_len = \"calldatasize\"\n        else:\n            # some gymnastics to propagate constants (if eval_input_buf\n            # returns a static memory location)\n            eval_input_buf = ensure_in_memory(data, context)\n\n            input_buf = eval_seq(eval_input_buf)\n\n            if input_buf is None:\n                call_ir = [\"with\", \"arg_buf\", eval_input_buf]\n                input_buf = IRnode.from_list(\"arg_buf\")\n            else:\n                call_ir = [\"seq\", eval_input_buf]\n\n            args_ofst = add_ofst(input_buf, 32)\n            args_len = [\"mload\", input_buf]\n\n        output_node = IRnode.from_list(\n            context.new_internal_variable(BytesT(outsize)), typ=BytesT(outsize), location=MEMORY\n        )\n\n        bool_ty = BoolT()\n\n        # build IR for call or delegatecall\n        common_call_args = [\n            args_ofst,\n            args_len,\n            # if there is no return value, the return offset can be 0\n            add_ofst(output_node, 32) if outsize else 0,\n            outsize,\n        ]\n\n        if delegate_call:\n            call_op = [\"delegatecall\", gas, to, *common_call_args]\n        elif static_call:\n            call_op = [\"staticcall\", gas, to, *common_call_args]\n        else:\n            call_op = [\"call\", gas, to, value, *common_call_args]\n\n        call_ir += [call_op]\n\n        # build sequence IR\n        if outsize:\n            # return minimum of outsize and returndatasize\n            size = [\"select\", [\"lt\", outsize, \"returndatasize\"], outsize, \"returndatasize\"]\n\n            # store output size and return output location\n            store_output_size = [\"seq\", [\"mstore\", output_node, size], output_node]\n\n            bytes_ty = BytesT(outsize)\n\n            if revert_on_failure:\n                typ = bytes_ty\n                ret_ir = [\"seq\", check_external_call(call_ir), store_output_size]\n            else:\n                typ = TupleT([bool_ty, bytes_ty])\n                ret_ir = [\n                    \"multi\",\n                    # use IRnode.from_list to make sure the types are\n                    # set properly on the \"multi\" members\n                    IRnode.from_list(call_ir, typ=bool_ty),\n                    IRnode.from_list(store_output_size, typ=bytes_ty, location=MEMORY),\n                ]\n\n        else:\n            if revert_on_failure:\n                typ = None\n                ret_ir = check_external_call(call_ir)\n            else:\n                typ = bool_ty\n                ret_ir = call_ir\n\n        return IRnode.from_list(ret_ir, typ=typ, location=MEMORY)\n\n\nclass Send(BuiltinFunction):\n    _id = \"send\"\n    _inputs = [(\"to\", AddressT()), (\"value\", UINT256_T)]\n    # default gas stipend is 0\n    _kwargs = {\"gas\": KwargSettings(UINT256_T, 0)}\n    _return_type = None\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        to, value = args\n        gas = kwargs[\"gas\"]\n        context.check_is_not_constant(\"send ether\", expr)\n        return IRnode.from_list([\"assert\", [\"call\", gas, to, value, 0, 0, 0, 0]])\n\n\nclass SelfDestruct(BuiltinFunction):\n    _id = \"selfdestruct\"\n    _inputs = [(\"to\", AddressT())]\n    _return_type = None\n    _is_terminus = True\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        context.check_is_not_constant(\"selfdestruct\", expr)\n        return IRnode.from_list(\n            [\"seq\", eval_once_check(_freshname(\"selfdestruct\")), [\"selfdestruct\", args[0]]]\n        )\n\n\nclass BlockHash(BuiltinFunction):\n    _id = \"blockhash\"\n    _inputs = [(\"block_num\", UINT256_T)]\n    _return_type = BYTES32_T\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, contact):\n        return IRnode.from_list(\n            [\"blockhash\", clamp(\"lt\", clamp(\"sge\", args[0], [\"sub\", [\"number\"], 256]), \"number\")],\n            typ=BYTES32_T,\n        )\n\n\nclass RawRevert(BuiltinFunction):\n    _id = \"raw_revert\"\n    _inputs = [(\"data\", BytesT.any())]\n    _return_type = None\n    _is_terminus = True\n\n    def fetch_call_return(self, node):\n        return None\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n        data_type = get_possible_types_from_node(node.args[0]).pop()\n        return [data_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        with ensure_in_memory(args[0], context).cache_when_complex(\"err_buf\") as (b, buf):\n            data = bytes_data_ptr(buf)\n            len_ = get_bytearray_length(buf)\n            return b.resolve(IRnode.from_list([\"revert\", data, len_]))\n\n\nclass RawLog(BuiltinFunction):\n    _id = \"raw_log\"\n    _inputs = [(\"topics\", DArrayT(BYTES32_T, 4)), (\"data\", (BYTES32_T, BytesT.any()))]\n\n    def fetch_call_return(self, node):\n        self.infer_arg_types(node)\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n\n        if not isinstance(node.args[0], vy_ast.List) or len(node.args[0].elements) > 4:\n            raise InvalidType(\"Expecting a list of 0-4 topics as first argument\", node.args[0])\n\n        # return a concrete type for `data`\n        data_type = get_possible_types_from_node(node.args[1]).pop()\n\n        return [self._inputs[0][1], data_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        topics_length = len(expr.args[0].elements)\n        topics = args[0].args\n\n        # sanity check topics is a literal list\n        assert args[0].value in (\"~empty\", \"multi\")\n\n        data = args[1]\n\n        if data.typ == BYTES32_T:\n            placeholder = context.new_internal_variable(BYTES32_T)\n            return IRnode.from_list(\n                [\n                    \"seq\",\n                    # TODO use make_setter\n                    [\"mstore\", placeholder, unwrap_location(data)],\n                    [\"log\" + str(topics_length), placeholder, 32] + topics,\n                ]\n            )\n\n        input_buf = ensure_in_memory(data, context)\n\n        return IRnode.from_list(\n            [\n                \"with\",\n                \"_sub\",\n                input_buf,\n                [\"log\" + str(topics_length), [\"add\", \"_sub\", 32], [\"mload\", \"_sub\"], *topics],\n            ]\n        )\n\n\nclass BitwiseAnd(BuiltinFunction):\n    _id = \"bitwise_and\"\n    _inputs = [(\"x\", UINT256_T), (\"y\", UINT256_T)]\n    _return_type = UINT256_T\n    _warned = False\n\n    def evaluate(self, node):\n        if not self.__class__._warned:\n            vyper_warn(\"`bitwise_and()` is deprecated! Please use the & operator instead.\")\n            self.__class__._warned = True\n\n        validate_call_args(node, 2)\n        for arg in node.args:\n            if not isinstance(arg, vy_ast.Num):\n                raise UnfoldableNode\n            if arg.value < 0 or arg.value >= 2**256:\n                raise InvalidLiteral(\"Value out of range for uint256\", arg)\n\n        value = node.args[0].value & node.args[1].value\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list([\"and\", args[0], args[1]], typ=UINT256_T)\n\n\nclass BitwiseOr(BuiltinFunction):\n    _id = \"bitwise_or\"\n    _inputs = [(\"x\", UINT256_T), (\"y\", UINT256_T)]\n    _return_type = UINT256_T\n    _warned = False\n\n    def evaluate(self, node):\n        if not self.__class__._warned:\n            vyper_warn(\"`bitwise_or()` is deprecated! Please use the | operator instead.\")\n            self.__class__._warned = True\n\n        validate_call_args(node, 2)\n        for arg in node.args:\n            if not isinstance(arg, vy_ast.Num):\n                raise UnfoldableNode\n            if arg.value < 0 or arg.value >= 2**256:\n                raise InvalidLiteral(\"Value out of range for uint256\", arg)\n\n        value = node.args[0].value | node.args[1].value\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list([\"or\", args[0], args[1]], typ=UINT256_T)\n\n\nclass BitwiseXor(BuiltinFunction):\n    _id = \"bitwise_xor\"\n    _inputs = [(\"x\", UINT256_T), (\"y\", UINT256_T)]\n    _return_type = UINT256_T\n    _warned = False\n\n    def evaluate(self, node):\n        if not self.__class__._warned:\n            vyper_warn(\"`bitwise_xor()` is deprecated! Please use the ^ operator instead.\")\n            self.__class__._warned = True\n\n        validate_call_args(node, 2)\n        for arg in node.args:\n            if not isinstance(arg, vy_ast.Num):\n                raise UnfoldableNode\n            if arg.value < 0 or arg.value >= 2**256:\n                raise InvalidLiteral(\"Value out of range for uint256\", arg)\n\n        value = node.args[0].value ^ node.args[1].value\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list([\"xor\", args[0], args[1]], typ=UINT256_T)\n\n\nclass BitwiseNot(BuiltinFunction):\n    _id = \"bitwise_not\"\n    _inputs = [(\"x\", UINT256_T)]\n    _return_type = UINT256_T\n    _warned = False\n\n    def evaluate(self, node):\n        if not self.__class__._warned:\n            vyper_warn(\"`bitwise_not()` is deprecated! Please use the ^ operator instead.\")\n            self.__class__._warned = True\n\n        validate_call_args(node, 1)\n        if not isinstance(node.args[0], vy_ast.Num):\n            raise UnfoldableNode\n\n        value = node.args[0].value\n        if value < 0 or value >= 2**256:\n            raise InvalidLiteral(\"Value out of range for uint256\", node.args[0])\n\n        value = (2**256 - 1) - value\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list([\"not\", args[0]], typ=UINT256_T)\n\n\nclass Shift(BuiltinFunction):\n    _id = \"shift\"\n    _inputs = [(\"x\", (UINT256_T, INT256_T)), (\"_shift\", IntegerT.any())]\n    _return_type = UINT256_T\n\n    def evaluate(self, node):\n        validate_call_args(node, 2)\n        if [i for i in node.args if not isinstance(i, vy_ast.Num)]:\n            raise UnfoldableNode\n        value, shift = [i.value for i in node.args]\n        if value < 0 or value >= 2**256:\n            raise InvalidLiteral(\"Value out of range for uint256\", node.args[0])\n        if shift < -256 or shift > 256:\n            # this validation is performed to prevent the compiler from hanging\n            # rather than for correctness because the post-folded constant would\n            # have been validated anyway\n            raise InvalidLiteral(\"Shift must be between -256 and 256\", node.args[1])\n\n        if shift < 0:\n            value = value >> -shift\n        else:\n            value = (value << shift) % (2**256)\n        return vy_ast.Int.from_node(node, value=value)\n\n    def fetch_call_return(self, node):\n        # return type is the type of the first argument\n        return self.infer_arg_types(node)[0]\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n        # return a concrete type instead of SignedIntegerAbstractType\n        arg_ty = get_possible_types_from_node(node.args[0])[0]\n        shift_ty = get_possible_types_from_node(node.args[1])[0]\n        return [arg_ty, shift_ty]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        # \"gshr\" -- generalized right shift\n        argty = args[0].typ\n        GSHR = sar if argty.is_signed else shr\n\n        with args[0].cache_when_complex(\"to_shift\") as (b1, arg), args[1].cache_when_complex(\n            \"bits\"\n        ) as (b2, bits):\n            neg_bits = [\"sub\", 0, bits]\n            ret = [\"if\", [\"slt\", bits, 0], GSHR(neg_bits, arg), shl(bits, arg)]\n            return b1.resolve(b2.resolve(IRnode.from_list(ret, typ=argty)))\n\n\nclass _AddMulMod(BuiltinFunction):\n    _inputs = [(\"a\", UINT256_T), (\"b\", UINT256_T), (\"c\", UINT256_T)]\n    _return_type = UINT256_T\n\n    def evaluate(self, node):\n        validate_call_args(node, 3)\n        if isinstance(node.args[2], vy_ast.Num) and node.args[2].value == 0:\n            raise ZeroDivisionException(\"Modulo by 0\", node.args[2])\n        for arg in node.args:\n            if not isinstance(arg, vy_ast.Num):\n                raise UnfoldableNode\n            if arg.value < 0 or arg.value >= 2**256:\n                raise InvalidLiteral(\"Value out of range for uint256\", arg)\n\n        value = self._eval_fn(node.args[0].value, node.args[1].value) % node.args[2].value\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list(\n            [\"seq\", [\"assert\", args[2]], [self._opcode, args[0], args[1], args[2]]], typ=UINT256_T\n        )\n\n\nclass AddMod(_AddMulMod):\n    _id = \"uint256_addmod\"\n    _eval_fn = operator.add\n    _opcode = \"addmod\"\n\n\nclass MulMod(_AddMulMod):\n    _id = \"uint256_mulmod\"\n    _eval_fn = operator.mul\n    _opcode = \"mulmod\"\n\n\nclass PowMod256(BuiltinFunction):\n    _id = \"pow_mod256\"\n    _inputs = [(\"a\", UINT256_T), (\"b\", UINT256_T)]\n    _return_type = UINT256_T\n\n    def evaluate(self, node):\n        validate_call_args(node, 2)\n        if next((i for i in node.args if not isinstance(i, vy_ast.Int)), None):\n            raise UnfoldableNode\n\n        left, right = node.args\n        if left.value < 0 or right.value < 0:\n            raise UnfoldableNode\n\n        value = pow(left.value, right.value, 2**256)\n        return vy_ast.Int.from_node(node, value=value)\n\n    def build_IR(self, expr, context):\n        left = Expr.parse_value_expr(expr.args[0], context)\n        right = Expr.parse_value_expr(expr.args[1], context)\n        return IRnode.from_list([\"exp\", left, right], typ=left.typ)\n\n\nclass Abs(BuiltinFunction):\n    _id = \"abs\"\n    _inputs = [(\"value\", INT256_T)]\n    _return_type = INT256_T\n\n    def evaluate(self, node):\n        validate_call_args(node, 1)\n        if not isinstance(node.args[0], vy_ast.Int):\n            raise UnfoldableNode\n\n        value = node.args[0].value\n        if not SizeLimits.MIN_INT256 <= value <= SizeLimits.MAX_INT256:\n            raise OverflowException(\"Literal is outside of allowable range for int256\")\n        value = abs(value)\n        if not SizeLimits.MIN_INT256 <= value <= SizeLimits.MAX_INT256:\n            raise OverflowException(\"Absolute literal value is outside allowable range for int256\")\n\n        return vy_ast.Int.from_node(node, value=value)\n\n    def build_IR(self, expr, context):\n        value = Expr.parse_value_expr(expr.args[0], context)\n        sub = [\n            \"with\",\n            \"orig\",\n            value,\n            [\n                \"if\",\n                [\"slt\", \"orig\", 0],\n                # clamp orig != -2**255 (because it maps to itself under negation)\n                [\"seq\", [\"assert\", [\"ne\", \"orig\", [\"sub\", 0, \"orig\"]]], [\"sub\", 0, \"orig\"]],\n                \"orig\",\n            ],\n        ]\n        return IRnode.from_list(sub, typ=INT256_T)\n\n\n# CREATE* functions\n\n\n# create helper functions\n# generates CREATE op sequence + zero check for result\ndef _create_ir(value, buf, length, salt=None, checked=True):\n    args = [value, buf, length]\n    create_op = \"create\"\n    if salt is not None:\n        create_op = \"create2\"\n        args.append(salt)\n\n    ret = IRnode.from_list(\n        [\"seq\", eval_once_check(_freshname(\"create_builtin\")), [create_op, *args]]\n    )\n\n    if not checked:\n        return ret\n\n    return clamp_nonzero(ret)\n\n\n# calculate the gas used by create for a given number of bytes\ndef _create_addl_gas_estimate(size, should_use_create2):\n    ret = 200 * size\n    if should_use_create2:\n        ret += SHA3_PER_WORD * ceil32(size) // 32\n    return ret\n\n\ndef eip1167_bytecode():\n    # NOTE cyclic import?\n    from vyper.ir.compile_ir import assembly_to_evm\n\n    loader_asm = [\n        \"PUSH1\",\n        0x2D,\n        \"RETURNDATASIZE\",\n        \"DUP2\",\n        \"PUSH1\",\n        0x09,\n        \"RETURNDATASIZE\",\n        \"CODECOPY\",\n        \"RETURN\",\n    ]\n    forwarder_pre_asm = [\n        \"CALLDATASIZE\",\n        \"RETURNDATASIZE\",\n        \"RETURNDATASIZE\",\n        \"CALLDATACOPY\",\n        \"RETURNDATASIZE\",\n        \"RETURNDATASIZE\",\n        \"RETURNDATASIZE\",\n        \"CALLDATASIZE\",\n        \"RETURNDATASIZE\",\n        \"PUSH20\",  # [address to delegate to]\n    ]\n    forwarder_post_asm = [\n        \"GAS\",\n        \"DELEGATECALL\",\n        \"RETURNDATASIZE\",\n        \"DUP3\",\n        \"DUP1\",\n        \"RETURNDATACOPY\",\n        \"SWAP1\",\n        \"RETURNDATASIZE\",\n        \"SWAP2\",\n        \"PUSH1\",\n        0x2B,  # jumpdest of whole program.\n        \"JUMPI\",\n        \"REVERT\",\n        \"JUMPDEST\",\n        \"RETURN\",\n    ]\n    return (\n        assembly_to_evm(loader_asm)[0],\n        assembly_to_evm(forwarder_pre_asm)[0],\n        assembly_to_evm(forwarder_post_asm)[0],\n    )\n\n\n# \"standard\" initcode for code which can be larger than 256 bytes.\n# returns the code starting from 0x0b with len `codesize`.\n# NOTE: it assumes codesize <= 2**24.\ndef _create_preamble(codesize):\n    from vyper.ir.compile_ir import assembly_to_evm\n\n    evm_len = 0x0B  # 11 bytes\n    asm = [\n        # use PUSH3 to be able to deal with larger contracts\n        \"PUSH3\",\n        # blank space for codesize\n        0x00,\n        0x00,\n        0x00,\n        \"RETURNDATASIZE\",\n        \"DUP2\",\n        \"PUSH1\",\n        evm_len,\n        \"RETURNDATASIZE\",\n        \"CODECOPY\",\n        \"RETURN\",\n    ]\n    evm = assembly_to_evm(asm)[0]\n    assert len(evm) == evm_len, evm\n\n    shl_bits = (evm_len - 4) * 8  # codesize needs to go right after the PUSH3\n    # mask codesize into the aforementioned \"blank space\"\n    return [\"or\", bytes_to_int(evm), shl(shl_bits, codesize)], evm_len\n\n\nclass _CreateBase(BuiltinFunction):\n    _kwargs = {\n        \"value\": KwargSettings(UINT256_T, zero_value),\n        \"salt\": KwargSettings(BYTES32_T, empty_value),\n    }\n    _return_type = AddressT()\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        # errmsg something like \"Cannot use {self._id} in pure fn\"\n        context.check_is_not_constant(\"use {self._id}\", expr)\n\n        should_use_create2 = \"salt\" in [kwarg.arg for kwarg in expr.keywords]\n        if not should_use_create2:\n            kwargs[\"salt\"] = None\n\n        ir_builder = self._build_create_IR(expr, args, context, **kwargs)\n\n        add_gas_estimate = self._add_gas_estimate(args, should_use_create2)\n\n        return IRnode.from_list(\n            ir_builder, typ=AddressT(), annotation=self._id, add_gas_estimate=add_gas_estimate\n        )\n\n\nclass CreateMinimalProxyTo(_CreateBase):\n    # create an EIP1167 \"minimal proxy\" to the target contract\n\n    _id = \"create_minimal_proxy_to\"\n    _inputs = [(\"target\", AddressT())]\n\n    def _add_gas_estimate(self, args, should_use_create2):\n        a, b, c = eip1167_bytecode()\n        bytecode_len = 20 + len(b) + len(c)\n        return _create_addl_gas_estimate(bytecode_len, should_use_create2)\n\n    def _build_create_IR(self, expr, args, context, value, salt):\n        target_address = args[0]\n\n        buf = context.new_internal_variable(BytesT(96))\n\n        loader_evm, forwarder_pre_evm, forwarder_post_evm = eip1167_bytecode()\n        # Adjust to 32-byte boundaries\n        preamble_length = len(loader_evm) + len(forwarder_pre_evm)\n        forwarder_preamble = bytes_to_int(\n            loader_evm + forwarder_pre_evm + b\"\\x00\" * (32 - preamble_length)\n        )\n        forwarder_post = bytes_to_int(forwarder_post_evm + b\"\\x00\" * (32 - len(forwarder_post_evm)))\n\n        # left-align the target\n        if target_address.is_literal:\n            # note: should move to optimizer once we have\n            # codesize optimization pipeline\n            aligned_target = args[0].value << 96\n        else:\n            aligned_target = shl(96, target_address)\n\n        buf_len = preamble_length + 20 + len(forwarder_post_evm)\n\n        return [\n            \"seq\",\n            [\"mstore\", buf, forwarder_preamble],\n            [\"mstore\", [\"add\", buf, preamble_length], aligned_target],\n            [\"mstore\", [\"add\", buf, preamble_length + 20], forwarder_post],\n            _create_ir(value, buf, buf_len, salt=salt),\n        ]\n\n\nclass CreateForwarderTo(CreateMinimalProxyTo):\n    _warned = False\n\n    def build_IR(self, expr, context):\n        if not self._warned:\n            vyper_warn(\"`create_forwarder_to` is a deprecated alias of `create_minimal_proxy_to`!\")\n            self._warned = True\n\n        return super().build_IR(expr, context)\n\n\nclass CreateCopyOf(_CreateBase):\n    _id = \"create_copy_of\"\n    _inputs = [(\"target\", AddressT())]\n\n    @property\n    def _preamble_len(self):\n        return 11\n\n    def _add_gas_estimate(self, args, should_use_create2):\n        # max possible runtime length + preamble length\n        return _create_addl_gas_estimate(EIP_170_LIMIT + self._preamble_len, should_use_create2)\n\n    def _build_create_IR(self, expr, args, context, value, salt):\n        target = args[0]\n\n        with target.cache_when_complex(\"create_target\") as (b1, target):\n            codesize = IRnode.from_list([\"extcodesize\", target])\n            msize = IRnode.from_list([\"msize\"])\n            with codesize.cache_when_complex(\"target_codesize\") as (\n                b2,\n                codesize,\n            ), msize.cache_when_complex(\"mem_ofst\") as (b3, mem_ofst):\n                ir = [\"seq\"]\n\n                # make sure there is actually code at the target\n                ir.append([\"assert\", codesize])\n\n                # store the preamble at msize + 22 (zero padding)\n                preamble, preamble_len = _create_preamble(codesize)\n                assert preamble_len == self._preamble_len\n\n                ir.append([\"mstore\", mem_ofst, preamble])\n\n                # copy the target code into memory. current layout:\n                # msize | 00...00 (22 0's) | preamble | bytecode\n                ir.append([\"extcodecopy\", target, add_ofst(mem_ofst, 32), 0, codesize])\n\n                buf = add_ofst(mem_ofst, 32 - preamble_len)\n                buf_len = [\"add\", codesize, preamble_len]\n\n                ir.append(_create_ir(value, buf, buf_len, salt))\n\n                return b1.resolve(b2.resolve(b3.resolve(ir)))\n\n\nclass CreateFromBlueprint(_CreateBase):\n    _id = \"create_from_blueprint\"\n    _inputs = [(\"target\", AddressT())]\n    _kwargs = {\n        \"value\": KwargSettings(UINT256_T, zero_value),\n        \"salt\": KwargSettings(BYTES32_T, empty_value),\n        \"raw_args\": KwargSettings(BoolT(), False, require_literal=True),\n        \"code_offset\": KwargSettings(UINT256_T, zero_value),\n    }\n    _has_varargs = True\n\n    def _add_gas_estimate(self, args, should_use_create2):\n        ctor_args = ir_tuple_from_args(args[1:])\n        # max possible size of init code\n        maxlen = EIP_170_LIMIT + ctor_args.typ.abi_type.size_bound()\n        return _create_addl_gas_estimate(maxlen, should_use_create2)\n\n    def _build_create_IR(self, expr, args, context, value, salt, code_offset, raw_args):\n        target = args[0]\n        ctor_args = args[1:]\n\n        ctor_args = [ensure_in_memory(arg, context) for arg in ctor_args]\n\n        if raw_args:\n            if len(ctor_args) != 1 or not isinstance(ctor_args[0].typ, BytesT):\n                raise StructureException(\"raw_args must be used with exactly 1 bytes argument\")\n\n            argbuf = bytes_data_ptr(ctor_args[0])\n            argslen = get_bytearray_length(ctor_args[0])\n            bufsz = ctor_args[0].typ.maxlen\n        else:\n            # encode the varargs\n            to_encode = ir_tuple_from_args(ctor_args)\n\n            # pretend we allocated enough memory for the encoder\n            # (we didn't, but we are clobbering unused memory so it's safe.)\n            bufsz = to_encode.typ.abi_type.size_bound()\n            argbuf = IRnode.from_list(\n                context.new_internal_variable(get_type_for_exact_size(bufsz)), location=MEMORY\n            )\n\n            # return a complex expression which writes to memory and returns\n            # the length of the encoded data\n            argslen = abi_encode(argbuf, to_encode, context, bufsz=bufsz, returns_len=True)\n\n        # NOTE: we need to invoke the abi encoder before evaluating MSIZE,\n        # then copy the abi encoded buffer to past-the-end of the initcode\n        # (since the abi encoder could write to fresh memory).\n        # it would be good to not require the memory copy, but need\n        # to evaluate memory safety.\n        with target.cache_when_complex(\"create_target\") as (b1, target), argslen.cache_when_complex(\n            \"encoded_args_len\"\n        ) as (b2, encoded_args_len), code_offset.cache_when_complex(\"code_ofst\") as (b3, codeofst):\n            codesize = IRnode.from_list([\"sub\", [\"extcodesize\", target], codeofst])\n            # copy code to memory starting from msize. we are clobbering\n            # unused memory so it's safe.\n            msize = IRnode.from_list([\"msize\"], location=MEMORY)\n            with codesize.cache_when_complex(\"target_codesize\") as (\n                b4,\n                codesize,\n            ), msize.cache_when_complex(\"mem_ofst\") as (b5, mem_ofst):\n                ir = [\"seq\"]\n\n                # make sure there is code at the target, and that\n                # code_ofst <= (extcodesize target).\n                # (note if code_ofst > (extcodesize target), would be\n                # OOG on the EXTCODECOPY)\n                # (code_ofst == (extcodesize target) would be empty\n                # initcode, which we disallow for hygiene reasons -\n                # same as `create_copy_of` on an empty target).\n                ir.append([\"assert\", [\"sgt\", codesize, 0]])\n\n                # copy the target code into memory.\n                # layout starting from mem_ofst:\n                # 00...00 (22 0's) | preamble | bytecode\n                ir.append([\"extcodecopy\", target, mem_ofst, codeofst, codesize])\n\n                ir.append(copy_bytes(add_ofst(mem_ofst, codesize), argbuf, encoded_args_len, bufsz))\n\n                # theoretically, dst = \"msize\", but just be safe.\n                # if len(ctor_args) > 0:\n                #    dst = add_ofst(mem_ofst, codesize)\n                #    encoded_args_len = self._encode_args(dst, ctor_args, context)\n                # else:\n                #    encoded_args_len = 0\n\n                length = [\"add\", codesize, encoded_args_len]\n\n                ir.append(_create_ir(value, mem_ofst, length, salt))\n\n                return b1.resolve(b2.resolve(b3.resolve(b4.resolve(b5.resolve(ir)))))\n\n\nclass _UnsafeMath(BuiltinFunction):\n    # TODO add unsafe math for `decimal`s\n    _inputs = [(\"a\", IntegerT.any()), (\"b\", IntegerT.any())]\n\n    def __repr__(self):\n        return f\"builtin function unsafe_{self.op}\"\n\n    def fetch_call_return(self, node):\n        return_type = self.infer_arg_types(node).pop()\n        return return_type\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n\n        types_list = get_common_types(*node.args, filter_fn=lambda x: isinstance(x, IntegerT))\n        if not types_list:\n            raise TypeMismatch(f\"unsafe_{self.op} called on dislike types\", node)\n\n        type_ = types_list.pop()\n        return [type_, type_]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        (a, b) = args\n        op = self.op\n\n        assert a.typ == b.typ, \"unreachable\"\n\n        otyp = a.typ\n\n        if op == \"div\" and a.typ.is_signed:\n            op = \"sdiv\"\n\n        ret = [op, a, b]\n\n        if a.typ.bits < 256:\n            # wrap for ops which could under/overflow\n            if a.typ.is_signed:\n                # e.g. int128 -> (signextend 15 (add x y))\n                ret = promote_signed_int(ret, a.typ.bits)\n            else:\n                # e.g. uint8 -> (mod (add x y) 256)\n                # TODO mod_bound could be a really large literal\n                ret = [\"mod\", ret, 2**a.typ.bits]\n\n        return IRnode.from_list(ret, typ=otyp)\n\n        # TODO handle decimal case\n\n\nclass UnsafeAdd(_UnsafeMath):\n    op = \"add\"\n\n\nclass UnsafeSub(_UnsafeMath):\n    op = \"sub\"\n\n\nclass UnsafeMul(_UnsafeMath):\n    op = \"mul\"\n\n\nclass UnsafeDiv(_UnsafeMath):\n    op = \"div\"\n\n\nclass _MinMax(BuiltinFunction):\n    _inputs = [(\"a\", (DecimalT(), IntegerT.any())), (\"b\", (DecimalT(), IntegerT.any()))]\n\n    def evaluate(self, node):\n        validate_call_args(node, 2)\n        if not isinstance(node.args[0], type(node.args[1])):\n            raise UnfoldableNode\n        if not isinstance(node.args[0], (vy_ast.Decimal, vy_ast.Int)):\n            raise UnfoldableNode\n\n        left, right = (i.value for i in node.args)\n        if isinstance(left, Decimal) and (\n            min(left, right) < SizeLimits.MIN_AST_DECIMAL\n            or max(left, right) > SizeLimits.MAX_AST_DECIMAL\n        ):\n            raise InvalidType(\"Decimal value is outside of allowable range\", node)\n\n        types_list = get_common_types(\n            *node.args, filter_fn=lambda x: isinstance(x, (IntegerT, DecimalT))\n        )\n        if not types_list:\n            raise TypeMismatch(\"Cannot perform action between dislike numeric types\", node)\n\n        value = self._eval_fn(left, right)\n        return type(node.args[0]).from_node(node, value=value)\n\n    def fetch_call_return(self, node):\n        return_type = self.infer_arg_types(node).pop()\n        return return_type\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n\n        types_list = get_common_types(\n            *node.args, filter_fn=lambda x: isinstance(x, (IntegerT, DecimalT))\n        )\n        if not types_list:\n            raise TypeMismatch(\"Cannot perform action between dislike numeric types\", node)\n\n        type_ = types_list.pop()\n        return [type_, type_]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        op = self._opcode\n\n        with args[0].cache_when_complex(\"_l\") as (b1, left), args[1].cache_when_complex(\"_r\") as (\n            b2,\n            right,\n        ):\n            if left.typ == right.typ:\n                if left.typ != UINT256_T:\n                    # if comparing like types that are not uint256, use SLT or SGT\n                    op = f\"s{op}\"\n                o = [\"select\", [op, left, right], left, right]\n                otyp = left.typ\n\n            else:\n                raise TypeMismatch(f\"Minmax types incompatible: {left.typ.typ} {right.typ.typ}\")\n            return IRnode.from_list(b1.resolve(b2.resolve(o)), typ=otyp)\n\n\nclass Min(_MinMax):\n    _id = \"min\"\n    _eval_fn = min\n    _opcode = \"lt\"\n\n\nclass Max(_MinMax):\n    _id = \"max\"\n    _eval_fn = max\n    _opcode = \"gt\"\n\n\nclass Uint2Str(BuiltinFunction):\n    _id = \"uint2str\"\n    _inputs = [(\"x\", IntegerT.unsigneds())]\n\n    def fetch_call_return(self, node):\n        arg_t = self.infer_arg_types(node)[0]\n        bits = arg_t.bits\n        len_needed = math.ceil(bits * math.log(2) / math.log(10))\n        return StringT(len_needed)\n\n    def evaluate(self, node):\n        validate_call_args(node, 1)\n        if not isinstance(node.args[0], vy_ast.Int):\n            raise UnfoldableNode\n\n        value = str(node.args[0].value)\n        return vy_ast.Str.from_node(node, value=value)\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n        input_type = get_possible_types_from_node(node.args[0]).pop()\n        return [input_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return_t = self.fetch_call_return(expr)\n        n_digits = return_t.maxlen\n\n        with args[0].cache_when_complex(\"val\") as (b1, val):\n            buf = context.new_internal_variable(return_t)\n\n            i = IRnode.from_list(context.fresh_varname(\"uint2str_i\"), typ=UINT256_T)\n\n            ret = [\"repeat\", i, 0, n_digits + 1, n_digits + 1]\n\n            body = [\n                \"seq\",\n                [\n                    \"if\",\n                    [\"eq\", val, 0],\n                    # clobber val, and return it as a pointer\n                    [\n                        \"seq\",\n                        [\"mstore\", [\"sub\", buf + n_digits, i], i],\n                        [\"set\", val, [\"sub\", buf + n_digits, i]],\n                        \"break\",\n                    ],\n                    [\n                        \"seq\",\n                        [\"mstore\", [\"sub\", buf + n_digits, i], [\"add\", 48, [\"mod\", val, 10]]],\n                        [\"set\", val, [\"div\", val, 10]],\n                    ],\n                ],\n            ]\n            ret.append(body)\n\n            # \"0\" has hex representation 0x00..0130..00\n            # if (val == 0) {\n            #   return \"0\"\n            # } else {\n            #   do the loop\n            # }\n            ret = [\n                \"if\",\n                [\"eq\", val, 0],\n                [\"seq\", [\"mstore\", buf + 1, ord(\"0\")], [\"mstore\", buf, 1], buf],\n                [\"seq\", ret, val],\n            ]\n\n            return b1.resolve(IRnode.from_list(ret, location=MEMORY, typ=return_t))\n\n\nclass Sqrt(BuiltinFunction):\n    _id = \"sqrt\"\n    _inputs = [(\"d\", DecimalT())]\n    _return_type = DecimalT()\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        # TODO fix cyclic dependency with codegen/stmt.py\n        from ._utils import generate_inline_function\n\n        arg = args[0]\n        # TODO: reify decimal and integer sqrt paths (see isqrt)\n        sqrt_code = \"\"\"\nassert x >= 0.0\nz: decimal = 0.0\n\nif x == 0.0:\n    z = 0.0\nelse:\n    z = x / 2.0 + 0.5\n    y: decimal = x\n\n    for i in range(256):\n        if z == y:\n            break\n        y = z\n        z = (x / z + z) / 2.0\n        \"\"\"\n\n        x_type = DecimalT()\n        placeholder_copy = [\"pass\"]\n        # Steal current position if variable is already allocated.\n        if arg.value == \"mload\":\n            new_var_pos = arg.args[0]\n        # Other locations need to be copied.\n        else:\n            new_var_pos = context.new_internal_variable(x_type)\n            placeholder_copy = [\"mstore\", new_var_pos, arg]\n        # Create input variables.\n        variables = {\"x\": VariableRecord(name=\"x\", pos=new_var_pos, typ=x_type, mutable=False)}\n        # Dictionary to update new (i.e. typecheck) namespace\n        variables_2 = {\"x\": VarInfo(DecimalT())}\n        # Generate inline IR.\n        new_ctx, sqrt_ir = generate_inline_function(\n            code=sqrt_code,\n            variables=variables,\n            variables_2=variables_2,\n            memory_allocator=context.memory_allocator,\n        )\n        return IRnode.from_list(\n            [\"seq\", placeholder_copy, sqrt_ir, new_ctx.vars[\"z\"].pos],  # load x variable\n            typ=DecimalT(),\n            location=MEMORY,\n        )\n\n\nclass ISqrt(BuiltinFunction):\n    _id = \"isqrt\"\n    _inputs = [(\"d\", UINT256_T)]\n    _return_type = UINT256_T\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        # calculate isqrt using the babylonian method\n\n        y, z = \"y\", \"z\"\n        arg = args[0]\n        with arg.cache_when_complex(\"x\") as (b1, x):\n            ret = [\n                \"seq\",\n                [\n                    \"if\",\n                    [\"ge\", y, 2 ** (128 + 8)],\n                    [\"seq\", [\"set\", y, shr(128, y)], [\"set\", z, shl(64, z)]],\n                ],\n                [\n                    \"if\",\n                    [\"ge\", y, 2 ** (64 + 8)],\n                    [\"seq\", [\"set\", y, shr(64, y)], [\"set\", z, shl(32, z)]],\n                ],\n                [\n                    \"if\",\n                    [\"ge\", y, 2 ** (32 + 8)],\n                    [\"seq\", [\"set\", y, shr(32, y)], [\"set\", z, shl(16, z)]],\n                ],\n                [\n                    \"if\",\n                    [\"ge\", y, 2 ** (16 + 8)],\n                    [\"seq\", [\"set\", y, shr(16, y)], [\"set\", z, shl(8, z)]],\n                ],\n            ]\n            ret.append([\"set\", z, [\"div\", [\"mul\", z, [\"add\", y, 2**16]], 2**18]])\n\n            for _ in range(7):\n                ret.append([\"set\", z, [\"div\", [\"add\", [\"div\", x, z], z], 2]])\n\n            # note: If ``x+1`` is a perfect square, then the Babylonian\n            # algorithm oscillates between floor(sqrt(x)) and ceil(sqrt(x)) in\n            # consecutive iterations. return the floor value always.\n\n            ret.append([\"with\", \"t\", [\"div\", x, z], [\"select\", [\"lt\", z, \"t\"], z, \"t\"]])\n\n            ret = [\"with\", y, x, [\"with\", z, 181, ret]]\n            return b1.resolve(IRnode.from_list(ret, typ=UINT256_T))\n\n\nclass Empty(TypenameFoldedFunction):\n    _id = \"empty\"\n\n    def fetch_call_return(self, node):\n        type_ = self.infer_arg_types(node)[0].typedef\n        if isinstance(type_, HashMapT):\n            raise TypeMismatch(\"Cannot use empty on HashMap\", node)\n        return type_\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        output_type = args[0]\n        return IRnode(\"~empty\", typ=output_type)\n\n\nclass Breakpoint(BuiltinFunction):\n    _id = \"breakpoint\"\n    _inputs: list = []\n\n    _warned = False\n\n    def fetch_call_return(self, node):\n        if not self._warned:\n            vyper_warn(\"`breakpoint` should only be used for debugging!\\n\" + node._annotated_source)\n            self._warned = True\n\n        return None\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list(\"breakpoint\", annotation=\"breakpoint()\")\n\n\nclass Print(BuiltinFunction):\n    _id = \"print\"\n    _inputs: list = []\n    _has_varargs = True\n    _kwargs = {\"hardhat_compat\": KwargSettings(BoolT(), False, require_literal=True)}\n\n    _warned = False\n\n    def fetch_call_return(self, node):\n        if not self._warned:\n            vyper_warn(\"`print` should only be used for debugging!\\n\" + node._annotated_source)\n            self._warned = True\n\n        return None\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        args_as_tuple = ir_tuple_from_args(args)\n        args_abi_t = args_as_tuple.typ.abi_type\n\n        # create a signature like \"log(uint256)\"\n        sig = \"log\" + \"(\" + \",\".join([arg.typ.abi_type.selector_name() for arg in args]) + \")\"\n\n        if kwargs[\"hardhat_compat\"] is True:\n            method_id = method_id_int(sig)\n            buflen = 32 + args_abi_t.size_bound()\n\n            # 32 bytes extra space for the method id\n            buf = context.new_internal_variable(get_type_for_exact_size(buflen))\n\n            ret = [\"seq\"]\n            ret.append([\"mstore\", buf, method_id])\n            encode = abi_encode(buf + 32, args_as_tuple, context, buflen, returns_len=True)\n\n        else:\n            method_id = method_id_int(\"log(string,bytes)\")\n            schema = args_abi_t.selector_name().encode(\"utf-8\")\n            if len(schema) > 32:\n                raise CompilerPanic(\"print signature too long: {schema}\")\n\n            schema_t = StringT(len(schema))\n            schema_buf = context.new_internal_variable(schema_t)\n            ret = [\"seq\"]\n            ret.append([\"mstore\", schema_buf, len(schema)])\n\n            # TODO use Expr.make_bytelike, or better have a `bytestring` IRnode type\n            ret.append([\"mstore\", schema_buf + 32, bytes_to_int(schema.ljust(32, b\"\\x00\"))])\n\n            payload_buflen = args_abi_t.size_bound()\n            payload_t = BytesT(payload_buflen)\n\n            # 32 bytes extra space for the method id\n            payload_buf = context.new_internal_variable(payload_t)\n            encode_payload = abi_encode(\n                payload_buf + 32, args_as_tuple, context, payload_buflen, returns_len=True\n            )\n\n            ret.append([\"mstore\", payload_buf, encode_payload])\n            args_as_tuple = ir_tuple_from_args(\n                [\n                    IRnode.from_list(schema_buf, typ=schema_t, location=MEMORY),\n                    IRnode.from_list(payload_buf, typ=payload_t, location=MEMORY),\n                ]\n            )\n\n            # add 32 for method id padding\n            buflen = 32 + args_as_tuple.typ.abi_type.size_bound()\n            buf = context.new_internal_variable(get_type_for_exact_size(buflen))\n            ret.append([\"mstore\", buf, method_id])\n            encode = abi_encode(buf + 32, args_as_tuple, context, buflen, returns_len=True)\n\n        # debug address that tooling uses\n        CONSOLE_ADDRESS = 0x000000000000000000636F6E736F6C652E6C6F67\n        ret.append([\"staticcall\", \"gas\", CONSOLE_ADDRESS, buf + 28, [\"add\", 4, encode], 0, 0])\n\n        return IRnode.from_list(ret, annotation=\"print:\" + sig)\n\n\nclass ABIEncode(BuiltinFunction):\n    _id = \"_abi_encode\"  # TODO prettier to rename this to abi.encode\n    # signature: *, ensure_tuple=<literal_bool> -> Bytes[<calculated len>]\n    # (check the signature manually since we have no utility methods\n    # to handle varargs.)\n    # explanation of ensure_tuple:\n    # default is to force even a single value into a tuple,\n    # e.g. _abi_encode(bytes) -> _abi_encode((bytes,))\n    #      _abi_encode((bytes,)) -> _abi_encode(((bytes,),))\n    # this follows the encoding convention for functions:\n    # ://docs.soliditylang.org/en/v0.8.6/abi-spec.html#function-selector-and-argument-encoding\n    # if this is turned off, then bytes will be encoded as bytes.\n\n    _inputs: list = []\n    _has_varargs = True\n\n    _kwargs = {\n        \"ensure_tuple\": KwargSettings(BoolT(), True, require_literal=True),\n        \"method_id\": KwargSettings((BYTES4_T, BytesT(4)), None, require_literal=True),\n    }\n\n    def infer_kwarg_types(self, node):\n        ret = {}\n        for kwarg in node.keywords:\n            kwarg_name = kwarg.arg\n            validate_expected_type(kwarg.value, self._kwargs[kwarg_name].typ)\n            ret[kwarg_name] = get_exact_type_from_node(kwarg.value)\n        return ret\n\n    def fetch_call_return(self, node):\n        self._validate_arg_types(node)\n        ensure_tuple = next(\n            (arg.value.value for arg in node.keywords if arg.arg == \"ensure_tuple\"), True\n        )\n        assert isinstance(ensure_tuple, bool)\n        has_method_id = \"method_id\" in [arg.arg for arg in node.keywords]\n\n        # figure out the output type by converting\n        # the types to ABI_Types and calling size_bound API\n        arg_abi_types = []\n        arg_types = self.infer_arg_types(node)\n        for arg_t in arg_types:\n            arg_abi_types.append(arg_t.abi_type)\n\n        # special case, no tuple\n        if len(arg_abi_types) == 1 and not ensure_tuple:\n            arg_abi_t = arg_abi_types[0]\n        else:\n            arg_abi_t = ABI_Tuple(arg_abi_types)\n\n        maxlen = arg_abi_t.size_bound()\n\n        if has_method_id:\n            # the output includes 4 bytes for the method_id.\n            maxlen += 4\n\n        ret = BytesT()\n        ret.set_length(maxlen)\n        return ret\n\n    @staticmethod\n    def _parse_method_id(method_id_literal):\n        if method_id_literal is None:\n            return None\n        if isinstance(method_id_literal, bytes):\n            assert len(method_id_literal) == 4\n            return fourbytes_to_int(method_id_literal)\n        if method_id_literal.startswith(\"0x\"):\n            method_id_literal = method_id_literal[2:]\n        return fourbytes_to_int(bytes.fromhex(method_id_literal))\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        ensure_tuple = kwargs[\"ensure_tuple\"]\n        method_id = self._parse_method_id(kwargs[\"method_id\"])\n\n        if len(args) < 1:\n            raise StructureException(\"abi_encode expects at least one argument\", expr)\n\n        # figure out the required length for the output buffer\n        if len(args) == 1 and not ensure_tuple:\n            # special case, no tuple\n            encode_input = args[0]\n        else:\n            encode_input = ir_tuple_from_args(args)\n\n        input_abi_t = encode_input.typ.abi_type\n        maxlen = input_abi_t.size_bound()\n        if method_id is not None:\n            maxlen += 4\n\n        buf_t = BytesT(maxlen)\n        assert self.fetch_call_return(expr).length == maxlen\n        buf = context.new_internal_variable(buf_t)\n\n        ret = [\"seq\"]\n        if method_id is not None:\n            # <32 bytes length> | <4 bytes method_id> | <everything else>\n            # write the unaligned method_id first, then we will\n            # overwrite the 28 bytes of zeros with the bytestring length\n            ret += [[\"mstore\", buf + 4, method_id]]\n            # abi encode, and grab length as stack item\n            length = abi_encode(buf + 36, encode_input, context, returns_len=True, bufsz=maxlen)\n            # write the output length to where bytestring stores its length\n            ret += [[\"mstore\", buf, [\"add\", length, 4]]]\n\n        else:\n            # abi encode and grab length as stack item\n            length = abi_encode(buf + 32, encode_input, context, returns_len=True, bufsz=maxlen)\n            # write the output length to where bytestring stores its length\n            ret += [[\"mstore\", buf, length]]\n\n        # return the buf location\n        # TODO location is statically known, optimize this out\n        ret += [buf]\n\n        return IRnode.from_list(ret, location=MEMORY, typ=buf_t)\n\n\nclass ABIDecode(BuiltinFunction):\n    _id = \"_abi_decode\"\n    _inputs = [(\"data\", BytesT.any()), (\"output_type\", \"TYPE_DEFINITION\")]\n    _kwargs = {\"unwrap_tuple\": KwargSettings(BoolT(), True, require_literal=True)}\n\n    def fetch_call_return(self, node):\n        _, output_type = self.infer_arg_types(node)\n        return output_type.typedef\n\n    def infer_arg_types(self, node):\n        validate_call_args(node, 2, [\"unwrap_tuple\"])\n\n        data_type = get_exact_type_from_node(node.args[0])\n        output_typedef = TYPE_T(type_from_annotation(node.args[1]))\n\n        return [data_type, output_typedef]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        unwrap_tuple = kwargs[\"unwrap_tuple\"]\n\n        data = args[0]\n        output_typ = args[1]\n        wrapped_typ = output_typ\n\n        if unwrap_tuple is True:\n            wrapped_typ = calculate_type_for_external_return(output_typ)\n\n        abi_size_bound = wrapped_typ.abi_type.size_bound()\n        abi_min_size = wrapped_typ.abi_type.min_size()\n\n        # Get the size of data\n        input_max_len = data.typ.maxlen\n\n        assert abi_min_size <= abi_size_bound, \"bad abi type\"\n        if input_max_len < abi_size_bound:\n            raise StructureException(\n                (\n                    \"Mismatch between size of input and size of decoded types. \"\n                    f\"length of ABI-encoded {wrapped_typ} must be equal to or greater \"\n                    f\"than {abi_size_bound}\"\n                ),\n                expr.args[0],\n            )\n\n        data = ensure_in_memory(data, context)\n        with data.cache_when_complex(\"to_decode\") as (b1, data):\n            data_ptr = bytes_data_ptr(data)\n            data_len = get_bytearray_length(data)\n\n            # Normally, ABI-encoded data assumes the argument is a tuple\n            # (See comments for `wrap_value_for_external_return`)\n            # However, we do not want to use `wrap_value_for_external_return`\n            # technique as used in external call codegen because in order to be\n            # type-safe we would need an extra memory copy. To avoid a copy,\n            # we manually add the ABI-dynamic offset so that it is\n            # re-interpreted in-place.\n            if (\n                unwrap_tuple is True\n                and needs_external_call_wrap(output_typ)\n                and output_typ.abi_type.is_dynamic()\n            ):\n                data_ptr = add_ofst(data_ptr, 32)\n\n            ret = [\"seq\"]\n\n            if abi_min_size == abi_size_bound:\n                ret.append([\"assert\", [\"eq\", abi_min_size, data_len]])\n            else:\n                # runtime assert: abi_min_size <= data_len <= abi_size_bound\n                ret.append(clamp2(abi_min_size, data_len, abi_size_bound, signed=False))\n\n            # return pointer to the buffer\n            ret.append(data_ptr)\n\n            return b1.resolve(\n                IRnode.from_list(\n                    ret,\n                    typ=output_typ,\n                    location=data.location,\n                    encoding=Encoding.ABI,\n                    annotation=f\"abi_decode({output_typ})\",\n                )\n            )\n\n\nclass _MinMaxValue(TypenameFoldedFunction):\n    def evaluate(self, node):\n        self._validate_arg_types(node)\n        input_type = type_from_annotation(node.args[0])\n\n        if not isinstance(input_type, (IntegerT, DecimalT)):\n            raise InvalidType(f\"Expected numeric type but got {input_type} instead\", node)\n\n        val = self._eval(input_type)\n\n        if isinstance(input_type, DecimalT):\n            ret = vy_ast.Decimal.from_node(node, value=val)\n\n        if isinstance(input_type, IntegerT):\n            ret = vy_ast.Int.from_node(node, value=val)\n\n        # TODO: to change to known_type once #3213 is merged\n        ret._metadata[\"type\"] = input_type\n        return ret\n\n\nclass MinValue(_MinMaxValue):\n    _id = \"min_value\"\n\n    def _eval(self, type_):\n        return type_.ast_bounds[0]\n\n\nclass MaxValue(_MinMaxValue):\n    _id = \"max_value\"\n\n    def _eval(self, type_):\n        return type_.ast_bounds[1]\n\n\nclass Epsilon(TypenameFoldedFunction):\n    _id = \"epsilon\"\n\n    def evaluate(self, node):\n        self._validate_arg_types(node)\n        input_type = type_from_annotation(node.args[0])\n\n        if not input_type.compare_type(DecimalT()):\n            raise InvalidType(f\"Expected decimal type but got {input_type} instead\", node)\n\n        return vy_ast.Decimal.from_node(node, value=input_type.epsilon)\n\n\nDISPATCH_TABLE = {\n    \"_abi_encode\": ABIEncode(),\n    \"_abi_decode\": ABIDecode(),\n    \"floor\": Floor(),\n    \"ceil\": Ceil(),\n    \"convert\": Convert(),\n    \"slice\": Slice(),\n    \"len\": Len(),\n    \"concat\": Concat(),\n    \"sha256\": Sha256(),\n    \"method_id\": MethodID(),\n    \"keccak256\": Keccak256(),\n    \"ecrecover\": ECRecover(),\n    \"ecadd\": ECAdd(),\n    \"ecmul\": ECMul(),\n    \"extract32\": Extract32(),\n    \"as_wei_value\": AsWeiValue(),\n    \"raw_call\": RawCall(),\n    \"blockhash\": BlockHash(),\n    \"bitwise_and\": BitwiseAnd(),\n    \"bitwise_or\": BitwiseOr(),\n    \"bitwise_xor\": BitwiseXor(),\n    \"bitwise_not\": BitwiseNot(),\n    \"uint256_addmod\": AddMod(),\n    \"uint256_mulmod\": MulMod(),\n    \"unsafe_add\": UnsafeAdd(),\n    \"unsafe_sub\": UnsafeSub(),\n    \"unsafe_mul\": UnsafeMul(),\n    \"unsafe_div\": UnsafeDiv(),\n    \"pow_mod256\": PowMod256(),\n    \"uint2str\": Uint2Str(),\n    \"isqrt\": ISqrt(),\n    \"sqrt\": Sqrt(),\n    \"shift\": Shift(),\n    \"create_minimal_proxy_to\": CreateMinimalProxyTo(),\n    \"create_forwarder_to\": CreateForwarderTo(),\n    \"create_copy_of\": CreateCopyOf(),\n    \"create_from_blueprint\": CreateFromBlueprint(),\n    \"min\": Min(),\n    \"max\": Max(),\n    \"empty\": Empty(),\n    \"abs\": Abs(),\n    \"min_value\": MinValue(),\n    \"max_value\": MaxValue(),\n    \"epsilon\": Epsilon(),\n}\n\nSTMT_DISPATCH_TABLE = {\n    \"send\": Send(),\n    \"print\": Print(),\n    \"breakpoint\": Breakpoint(),\n    \"selfdestruct\": SelfDestruct(),\n    \"raw_call\": RawCall(),\n    \"raw_log\": RawLog(),\n    \"raw_revert\": RawRevert(),\n    \"create_minimal_proxy_to\": CreateMinimalProxyTo(),\n    \"create_forwarder_to\": CreateForwarderTo(),\n    \"create_copy_of\": CreateCopyOf(),\n    \"create_from_blueprint\": CreateFromBlueprint(),\n}\n\nBUILTIN_FUNCTIONS = {**STMT_DISPATCH_TABLE, **DISPATCH_TABLE}.keys()\n\n\ndef get_builtin_functions():\n    return {**STMT_DISPATCH_TABLE, **DISPATCH_TABLE}\n"], "fixing_code": ["import pytest\nfrom hexbytes import HexBytes\n\nfrom vyper.builtins.functions import eip1167_bytecode\nfrom vyper.exceptions import ArgumentException, InvalidType, StateAccessViolation\n\npytestmark = pytest.mark.usefixtures(\"memory_mocker\")\n\n\ndef test_max_outsize_exceeds_returndatasize(get_contract):\n    source_code = \"\"\"\n@external\ndef foo() -> Bytes[7]:\n    return raw_call(0x0000000000000000000000000000000000000004, b\"moose\", max_outsize=7)\n    \"\"\"\n    c = get_contract(source_code)\n    assert c.foo() == b\"moose\"\n\n\ndef test_raw_call_non_memory(get_contract):\n    source_code = \"\"\"\n_foo: Bytes[5]\n@external\ndef foo() -> Bytes[5]:\n    self._foo = b\"moose\"\n    return raw_call(0x0000000000000000000000000000000000000004, self._foo, max_outsize=5)\n    \"\"\"\n    c = get_contract(source_code)\n    assert c.foo() == b\"moose\"\n\n\ndef test_returndatasize_exceeds_max_outsize(get_contract):\n    source_code = \"\"\"\n@external\ndef foo() -> Bytes[3]:\n    return raw_call(0x0000000000000000000000000000000000000004, b\"moose\", max_outsize=3)\n    \"\"\"\n    c = get_contract(source_code)\n    assert c.foo() == b\"moo\"\n\n\ndef test_returndatasize_matches_max_outsize(get_contract):\n    source_code = \"\"\"\n@external\ndef foo() -> Bytes[5]:\n    return raw_call(0x0000000000000000000000000000000000000004, b\"moose\", max_outsize=5)\n    \"\"\"\n    c = get_contract(source_code)\n    assert c.foo() == b\"moose\"\n\n\ndef test_multiple_levels(w3, get_contract_with_gas_estimation):\n    inner_code = \"\"\"\n@external\ndef returnten() -> int128:\n    return 10\n    \"\"\"\n\n    c = get_contract_with_gas_estimation(inner_code)\n\n    outer_code = \"\"\"\n@external\ndef create_and_call_returnten(inp: address) -> int128:\n    x: address = create_minimal_proxy_to(inp)\n    o: int128 = extract32(raw_call(x, b\"\\\\xd0\\\\x1f\\\\xb1\\\\xb8\", max_outsize=32, gas=50000), 0, output_type=int128)  # noqa: E501\n    return o\n\n@external\ndef create_and_return_proxy(inp: address) -> address:\n    x: address = create_minimal_proxy_to(inp)\n    return x\n    \"\"\"\n\n    c2 = get_contract_with_gas_estimation(outer_code)\n    assert c2.create_and_call_returnten(c.address) == 10\n    c2.create_and_call_returnten(c.address, transact={})\n\n    _, preamble, callcode = eip1167_bytecode()\n\n    c3 = c2.create_and_return_proxy(c.address, call={})\n    c2.create_and_return_proxy(c.address, transact={})\n\n    c3_contract_code = w3.to_bytes(w3.eth.get_code(c3))\n\n    assert c3_contract_code[:10] == HexBytes(preamble)\n    assert c3_contract_code[-15:] == HexBytes(callcode)\n\n    print(\"Passed proxy test\")\n    # TODO: This one is special\n    # print(f'Gas consumed: {(chain.head_state.receipts[-1].gas_used - chain.head_state.receipts[-2].gas_used - chain.last_tx.intrinsic_gas_used)}')  # noqa: E501\n\n\ndef test_multiple_levels2(assert_tx_failed, get_contract_with_gas_estimation):\n    inner_code = \"\"\"\n@external\ndef returnten() -> int128:\n    raise\n    \"\"\"\n\n    c = get_contract_with_gas_estimation(inner_code)\n\n    outer_code = \"\"\"\n@external\ndef create_and_call_returnten(inp: address) -> int128:\n    x: address = create_minimal_proxy_to(inp)\n    o: int128 = extract32(raw_call(x, b\"\\\\xd0\\\\x1f\\\\xb1\\\\xb8\", max_outsize=32, gas=50000), 0, output_type=int128)  # noqa: E501\n    return o\n\n@external\ndef create_and_return_proxy(inp: address) -> address:\n    return create_minimal_proxy_to(inp)\n    \"\"\"\n\n    c2 = get_contract_with_gas_estimation(outer_code)\n\n    assert_tx_failed(lambda: c2.create_and_call_returnten(c.address))\n\n    print(\"Passed minimal proxy exception test\")\n\n\ndef test_delegate_call(w3, get_contract):\n    inner_code = \"\"\"\na: address  # this is required for storage alignment...\nowners: public(address[5])\n\n@external\ndef set_owner(i: int128, o: address):\n    self.owners[i] = o\n    \"\"\"\n\n    inner_contract = get_contract(inner_code)\n\n    outer_code = \"\"\"\nowner_setter_contract: public(address)\nowners: public(address[5])\n\n\n@external\ndef __init__(_owner_setter: address):\n    self.owner_setter_contract = _owner_setter\n\n\n@external\ndef set(i: int128, owner: address):\n    # delegate setting owners to other contract.s\n    cdata: Bytes[68] = concat(method_id(\"set_owner(int128,address)\"), convert(i, bytes32), convert(owner, bytes32))  # noqa: E501\n    raw_call(\n        self.owner_setter_contract,\n        cdata,\n        gas=msg.gas,\n        max_outsize=0,\n        is_delegate_call=True\n    )\n    \"\"\"\n\n    a0, a1, a2 = w3.eth.accounts[:3]\n    outer_contract = get_contract(outer_code, *[inner_contract.address])\n\n    # Test setting on inners contract's state setting works.\n    inner_contract.set_owner(1, a2, transact={})\n    assert inner_contract.owners(1) == a2\n\n    # Confirm outer contract's state is empty and contract to call has been set.\n    assert outer_contract.owner_setter_contract() == inner_contract.address\n    assert outer_contract.owners(1) is None\n\n    # Call outer contract, that make a delegate call to inner_contract.\n    tx_hash = outer_contract.set(1, a1, transact={})\n    assert w3.eth.get_transaction_receipt(tx_hash)[\"status\"] == 1\n    assert outer_contract.owners(1) == a1\n\n\ndef test_gas(get_contract, assert_tx_failed):\n    inner_code = \"\"\"\nbar: bytes32\n\n@external\ndef foo(_bar: bytes32):\n    self.bar = _bar\n    \"\"\"\n\n    inner_contract = get_contract(inner_code)\n\n    outer_code = \"\"\"\n@external\ndef foo_call(_addr: address):\n    cdata: Bytes[40] = concat(\n        method_id(\"foo(bytes32)\"),\n        0x0000000000000000000000000000000000000000000000000000000000000001\n    )\n    raw_call(_addr, cdata, max_outsize=0{})\n    \"\"\"\n\n    # with no gas value given, enough will be forwarded to complete the call\n    outer_contract = get_contract(outer_code.format(\"\"))\n    outer_contract.foo_call(inner_contract.address)\n\n    # manually specifying a sufficient amount should succeed\n    outer_contract = get_contract(outer_code.format(\", gas=50000\"))\n    outer_contract.foo_call(inner_contract.address)\n\n    # manually specifying an insufficient amount should fail\n    outer_contract = get_contract(outer_code.format(\", gas=15000\"))\n    assert_tx_failed(lambda: outer_contract.foo_call(inner_contract.address))\n\n\ndef test_static_call(get_contract):\n    target_source = \"\"\"\n@external\n@view\ndef foo() -> int128:\n    return 42\n\"\"\"\n\n    caller_source = \"\"\"\n@external\n@view\ndef foo(_addr: address) -> int128:\n    _response: Bytes[32] = raw_call(\n        _addr,\n        method_id(\"foo()\"),\n        max_outsize=32,\n        is_static_call=True,\n    )\n    return convert(_response, int128)\n    \"\"\"\n\n    target = get_contract(target_source)\n    caller = get_contract(caller_source)\n\n    assert caller.foo(target.address) == 42\n\n\ndef test_forward_calldata(get_contract, w3, keccak):\n    target_source = \"\"\"\n@external\ndef foo() -> uint256:\n    return 123\n    \"\"\"\n\n    caller_source = \"\"\"\ntarget: address\n\n@external\ndef set_target(target: address):\n    self.target = target\n\n@external\ndef __default__():\n    assert 123 == _abi_decode(raw_call(self.target, msg.data, max_outsize=32), uint256)\n    \"\"\"\n\n    target = get_contract(target_source)\n\n    caller = get_contract(caller_source)\n    caller.set_target(target.address, transact={})\n\n    # manually construct msg.data for `caller` contract\n    sig = keccak(\"foo()\".encode()).hex()[:10]\n    w3.eth.send_transaction({\"to\": caller.address, \"data\": sig})\n\n\ndef test_static_call_fails_nonpayable(get_contract, assert_tx_failed):\n    target_source = \"\"\"\nbaz: int128\n\n@external\ndef foo() -> int128:\n    self.baz = 31337\n    return self.baz\n\"\"\"\n\n    caller_source = \"\"\"\n@external\n@view\ndef foo(_addr: address) -> int128:\n    _response: Bytes[32] = raw_call(\n        _addr,\n        method_id(\"foo()\"),\n        max_outsize=32,\n        is_static_call=True,\n    )\n    return convert(_response, int128)\n    \"\"\"\n\n    target = get_contract(target_source)\n    caller = get_contract(caller_source)\n\n    assert_tx_failed(lambda: caller.foo(target.address))\n\n\ndef test_checkable_raw_call(get_contract, assert_tx_failed):\n    target_source = \"\"\"\nbaz: int128\n@external\ndef fail1(should_raise: bool):\n    if should_raise:\n        raise \"fail\"\n\n# test both paths for raw_call -\n# they are different depending if callee has or doesn't have returntype\n# (fail2 fails because of staticcall)\n@external\ndef fail2(should_raise: bool) -> int128:\n    if should_raise:\n        self.baz = self.baz + 1\n    return self.baz\n\"\"\"\n\n    caller_source = \"\"\"\n@external\n@view\ndef foo(_addr: address, should_raise: bool) -> uint256:\n    success: bool = True\n    response: Bytes[32] = b\"\"\n    success, response = raw_call(\n        _addr,\n        _abi_encode(should_raise, method_id=method_id(\"fail1(bool)\")),\n        max_outsize=32,\n        is_static_call=True,\n        revert_on_failure=False,\n    )\n    assert success == (not should_raise)\n    return 1\n\n@external\n@view\ndef bar(_addr: address, should_raise: bool) -> uint256:\n    success: bool = True\n    response: Bytes[32] = b\"\"\n    success, response = raw_call(\n        _addr,\n        _abi_encode(should_raise, method_id=method_id(\"fail2(bool)\")),\n        max_outsize=32,\n        is_static_call=True,\n        revert_on_failure=False,\n    )\n    assert success == (not should_raise)\n    return 2\n\n# test max_outsize not set case\n@external\n@nonpayable\ndef baz(_addr: address, should_raise: bool) -> uint256:\n    success: bool = True\n    success = raw_call(\n        _addr,\n        _abi_encode(should_raise, method_id=method_id(\"fail1(bool)\")),\n        revert_on_failure=False,\n    )\n    assert success == (not should_raise)\n    return 3\n    \"\"\"\n\n    target = get_contract(target_source)\n    caller = get_contract(caller_source)\n\n    assert caller.foo(target.address, True) == 1\n    assert caller.foo(target.address, False) == 1\n    assert caller.bar(target.address, True) == 2\n    assert caller.bar(target.address, False) == 2\n    assert caller.baz(target.address, True) == 3\n    assert caller.baz(target.address, False) == 3\n\n\nuncompilable_code = [\n    (\n        \"\"\"\n@external\n@view\ndef foo(_addr: address):\n    raw_call(_addr, method_id(\"foo()\"))\n    \"\"\",\n        StateAccessViolation,\n    ),\n    (\n        \"\"\"\n@external\ndef foo(_addr: address):\n    raw_call(_addr, method_id(\"foo()\"), is_delegate_call=True, is_static_call=True)\n    \"\"\",\n        ArgumentException,\n    ),\n    (\n        \"\"\"\n@external\n@view\ndef foo(_addr: address):\n    raw_call(_addr, 256)\n    \"\"\",\n        InvalidType,\n    ),\n]\n\n\n@pytest.mark.parametrize(\"source_code,exc\", uncompilable_code)\ndef test_invalid_type_exception(\n    assert_compile_failed, get_contract_with_gas_estimation, source_code, exc\n):\n    assert_compile_failed(lambda: get_contract_with_gas_estimation(source_code), exc)\n", "import hashlib\nimport math\nimport operator\nfrom decimal import Decimal\n\nfrom vyper import ast as vy_ast\nfrom vyper.abi_types import ABI_Tuple\nfrom vyper.address_space import MEMORY, STORAGE\nfrom vyper.ast.validation import validate_call_args\nfrom vyper.codegen.abi_encoder import abi_encode\nfrom vyper.codegen.context import Context, VariableRecord\nfrom vyper.codegen.core import (\n    STORE,\n    IRnode,\n    _freshname,\n    add_ofst,\n    bytes_data_ptr,\n    calculate_type_for_external_return,\n    check_external_call,\n    clamp,\n    clamp2,\n    clamp_basetype,\n    clamp_nonzero,\n    copy_bytes,\n    ensure_in_memory,\n    eval_once_check,\n    eval_seq,\n    get_bytearray_length,\n    get_element_ptr,\n    get_type_for_exact_size,\n    ir_tuple_from_args,\n    needs_external_call_wrap,\n    promote_signed_int,\n    sar,\n    shl,\n    shr,\n    unwrap_location,\n)\nfrom vyper.codegen.expr import Expr\nfrom vyper.codegen.ir_node import Encoding\nfrom vyper.codegen.keccak256_helper import keccak256_helper\nfrom vyper.exceptions import (\n    ArgumentException,\n    CompilerPanic,\n    InvalidLiteral,\n    InvalidType,\n    OverflowException,\n    StateAccessViolation,\n    StructureException,\n    TypeMismatch,\n    UnfoldableNode,\n    ZeroDivisionException,\n)\nfrom vyper.semantics.analysis.base import VarInfo\nfrom vyper.semantics.analysis.utils import (\n    get_common_types,\n    get_exact_type_from_node,\n    get_possible_types_from_node,\n    validate_expected_type,\n)\nfrom vyper.semantics.types import (\n    TYPE_T,\n    AddressT,\n    BoolT,\n    BytesM_T,\n    BytesT,\n    DArrayT,\n    DecimalT,\n    HashMapT,\n    IntegerT,\n    KwargSettings,\n    SArrayT,\n    StringT,\n    TupleT,\n)\nfrom vyper.semantics.types.bytestrings import _BytestringT\nfrom vyper.semantics.types.shortcuts import (\n    BYTES4_T,\n    BYTES32_T,\n    INT128_T,\n    INT256_T,\n    UINT8_T,\n    UINT256_T,\n)\nfrom vyper.semantics.types.utils import type_from_annotation\nfrom vyper.utils import (\n    DECIMAL_DIVISOR,\n    EIP_170_LIMIT,\n    SHA3_PER_WORD,\n    MemoryPositions,\n    SizeLimits,\n    bytes_to_int,\n    ceil32,\n    fourbytes_to_int,\n    keccak256,\n    method_id_int,\n    vyper_warn,\n)\n\nfrom ._convert import convert\nfrom ._signatures import BuiltinFunction, process_inputs\n\nSHA256_ADDRESS = 2\nSHA256_BASE_GAS = 60\nSHA256_PER_WORD_GAS = 12\n\n\nclass FoldedFunction(BuiltinFunction):\n    # Base class for nodes which should always be folded\n\n    # Since foldable builtin functions are not folded before semantics validation,\n    # this flag is used for `check_kwargable` in semantics validation.\n    _kwargable = True\n\n\nclass TypenameFoldedFunction(FoldedFunction):\n    # Base class for builtin functions that:\n    # (1) take a typename as the only argument; and\n    # (2) should always be folded.\n\n    # \"TYPE_DEFINITION\" is a placeholder value for a type definition string, and\n    # will be replaced by a `TypeTypeDefinition` object in `infer_arg_types`.\n    _inputs = [(\"typename\", \"TYPE_DEFINITION\")]\n\n    def fetch_call_return(self, node):\n        type_ = self.infer_arg_types(node)[0].typedef\n        return type_\n\n    def infer_arg_types(self, node):\n        validate_call_args(node, 1)\n        input_typedef = TYPE_T(type_from_annotation(node.args[0]))\n        return [input_typedef]\n\n\nclass Floor(BuiltinFunction):\n    _id = \"floor\"\n    _inputs = [(\"value\", DecimalT())]\n    # TODO: maybe use int136?\n    _return_type = INT256_T\n\n    def evaluate(self, node):\n        validate_call_args(node, 1)\n        if not isinstance(node.args[0], vy_ast.Decimal):\n            raise UnfoldableNode\n\n        value = math.floor(node.args[0].value)\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list(\n            [\n                \"if\",\n                [\"slt\", args[0], 0],\n                [\"sdiv\", [\"sub\", args[0], DECIMAL_DIVISOR - 1], DECIMAL_DIVISOR],\n                [\"sdiv\", args[0], DECIMAL_DIVISOR],\n            ],\n            typ=INT256_T,\n        )\n\n\nclass Ceil(BuiltinFunction):\n    _id = \"ceil\"\n    _inputs = [(\"value\", DecimalT())]\n    # TODO: maybe use int136?\n    _return_type = INT256_T\n\n    def evaluate(self, node):\n        validate_call_args(node, 1)\n        if not isinstance(node.args[0], vy_ast.Decimal):\n            raise UnfoldableNode\n\n        value = math.ceil(node.args[0].value)\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list(\n            [\n                \"if\",\n                [\"slt\", args[0], 0],\n                [\"sdiv\", args[0], DECIMAL_DIVISOR],\n                [\"sdiv\", [\"add\", args[0], DECIMAL_DIVISOR - 1], DECIMAL_DIVISOR],\n            ],\n            typ=INT256_T,\n        )\n\n\nclass Convert(BuiltinFunction):\n    _id = \"convert\"\n\n    def fetch_call_return(self, node):\n        _, target_typedef = self.infer_arg_types(node)\n\n        # note: more type conversion validation happens in convert.py\n        return target_typedef.typedef\n\n    # TODO: push this down into convert.py for more consistency\n    def infer_arg_types(self, node):\n        validate_call_args(node, 2)\n\n        target_type = type_from_annotation(node.args[1])\n        value_types = get_possible_types_from_node(node.args[0])\n\n        # For `convert` of integer literals, we need to match type inference rules in\n        # convert.py codegen routines.\n        # TODO: This can probably be removed once constant folding for `convert` is implemented\n        if len(value_types) > 1 and all(isinstance(v, IntegerT) for v in value_types):\n            # Get the smallest (and unsigned if available) type for non-integer target types\n            # (note this is different from the ordering returned by `get_possible_types_from_node`)\n            if not isinstance(target_type, IntegerT):\n                value_types = sorted(value_types, key=lambda v: (v.is_signed, v.bits), reverse=True)\n            else:\n                # filter out the target type from list of possible types\n                value_types = [i for i in value_types if not target_type.compare_type(i)]\n\n        value_type = value_types.pop()\n\n        # block conversions between same type\n        if target_type.compare_type(value_type):\n            raise InvalidType(f\"Value and target type are both '{target_type}'\", node)\n\n        return [value_type, TYPE_T(target_type)]\n\n    def build_IR(self, expr, context):\n        return convert(expr, context)\n\n\nADHOC_SLICE_NODE_MACROS = [\"~calldata\", \"~selfcode\", \"~extcode\"]\n\n\ndef _build_adhoc_slice_node(sub: IRnode, start: IRnode, length: IRnode, context: Context) -> IRnode:\n    assert length.is_literal, \"typechecker failed\"\n    assert isinstance(length.value, int)  # mypy hint\n\n    dst_typ = BytesT(length.value)\n    # allocate a buffer for the return value\n    np = context.new_internal_variable(dst_typ)\n\n    # `msg.data` by `calldatacopy`\n    if sub.value == \"~calldata\":\n        node = [\n            \"seq\",\n            [\"assert\", [\"le\", [\"add\", start, length], \"calldatasize\"]],  # runtime bounds check\n            [\"mstore\", np, length],\n            [\"calldatacopy\", np + 32, start, length],\n            np,\n        ]\n\n    # `self.code` by `codecopy`\n    elif sub.value == \"~selfcode\":\n        node = [\n            \"seq\",\n            [\"assert\", [\"le\", [\"add\", start, length], \"codesize\"]],  # runtime bounds check\n            [\"mstore\", np, length],\n            [\"codecopy\", np + 32, start, length],\n            np,\n        ]\n\n    # `<address>.code` by `extcodecopy`\n    else:\n        assert sub.value == \"~extcode\" and len(sub.args) == 1\n        node = [\n            \"with\",\n            \"_extcode_address\",\n            sub.args[0],\n            [\n                \"seq\",\n                # runtime bounds check\n                [\"assert\", [\"le\", [\"add\", start, length], [\"extcodesize\", \"_extcode_address\"]]],\n                [\"mstore\", np, length],\n                [\"extcodecopy\", \"_extcode_address\", np + 32, start, length],\n                np,\n            ],\n        ]\n\n    assert isinstance(length.value, int)  # mypy hint\n    return IRnode.from_list(node, typ=BytesT(length.value), location=MEMORY)\n\n\n# note: this and a lot of other builtins could be refactored to accept any uint type\nclass Slice(BuiltinFunction):\n    _id = \"slice\"\n    _inputs = [\n        (\"b\", (BYTES32_T, BytesT.any(), StringT.any())),\n        (\"start\", UINT256_T),\n        (\"length\", UINT256_T),\n    ]\n    _return_type = None\n\n    def fetch_call_return(self, node):\n        arg_type, _, _ = self.infer_arg_types(node)\n\n        if isinstance(arg_type, StringT):\n            return_type = StringT()\n        else:\n            return_type = BytesT()\n\n        # validate start and length are in bounds\n\n        arg = node.args[0]\n        start_expr = node.args[1]\n        length_expr = node.args[2]\n\n        # CMC 2022-03-22 NOTE slight code duplication with semantics/analysis/local\n        is_adhoc_slice = arg.get(\"attr\") == \"code\" or (\n            arg.get(\"value.id\") == \"msg\" and arg.get(\"attr\") == \"data\"\n        )\n\n        start_literal = start_expr.value if isinstance(start_expr, vy_ast.Int) else None\n        length_literal = length_expr.value if isinstance(length_expr, vy_ast.Int) else None\n\n        if not is_adhoc_slice:\n            if length_literal is not None:\n                if length_literal < 1:\n                    raise ArgumentException(\"Length cannot be less than 1\", length_expr)\n\n                if length_literal > arg_type.length:\n                    raise ArgumentException(f\"slice out of bounds for {arg_type}\", length_expr)\n\n            if start_literal is not None:\n                if start_literal > arg_type.length:\n                    raise ArgumentException(f\"slice out of bounds for {arg_type}\", start_expr)\n                if length_literal is not None and start_literal + length_literal > arg_type.length:\n                    raise ArgumentException(f\"slice out of bounds for {arg_type}\", node)\n\n        # we know the length statically\n        if length_literal is not None:\n            return_type.set_length(length_literal)\n        else:\n            return_type.set_min_length(arg_type.length)\n\n        return return_type\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n        # return a concrete type for `b`\n        b_type = get_possible_types_from_node(node.args[0]).pop()\n        return [b_type, self._inputs[1][1], self._inputs[2][1]]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        src, start, length = args\n\n        # Handle `msg.data`, `self.code`, and `<address>.code`\n        if src.value in ADHOC_SLICE_NODE_MACROS:\n            return _build_adhoc_slice_node(src, start, length, context)\n\n        is_bytes32 = src.typ == BYTES32_T\n        if src.location is None:\n            # it's not a pointer; force it to be one since\n            # copy_bytes works on pointers.\n            assert is_bytes32, src\n            src = ensure_in_memory(src, context)\n\n        with src.cache_when_complex(\"src\") as (b1, src), start.cache_when_complex(\"start\") as (\n            b2,\n            start,\n        ), length.cache_when_complex(\"length\") as (b3, length):\n            if is_bytes32:\n                src_maxlen = 32\n            else:\n                src_maxlen = src.typ.maxlen\n\n            dst_maxlen = length.value if length.is_literal else src_maxlen\n\n            buflen = dst_maxlen\n\n            # add 32 bytes to the buffer size bc word access might\n            # be unaligned (see below)\n            if src.location == STORAGE:\n                buflen += 32\n\n            # Get returntype string or bytes\n            assert isinstance(src.typ, _BytestringT) or is_bytes32\n            # TODO: try to get dst_typ from semantic analysis\n            if isinstance(src.typ, StringT):\n                dst_typ = StringT(dst_maxlen)\n            else:\n                dst_typ = BytesT(dst_maxlen)\n\n            # allocate a buffer for the return value\n            buf = context.new_internal_variable(BytesT(buflen))\n            # assign it the correct return type.\n            # (note mismatch between dst_maxlen and buflen)\n            dst = IRnode.from_list(buf, typ=dst_typ, location=MEMORY)\n\n            dst_data = bytes_data_ptr(dst)\n\n            if is_bytes32:\n                src_len = 32\n                src_data = src\n            else:\n                src_len = get_bytearray_length(src)\n                src_data = bytes_data_ptr(src)\n\n            # general case. byte-for-byte copy\n            if src.location == STORAGE:\n                # because slice uses byte-addressing but storage\n                # is word-aligned, this algorithm starts at some number\n                # of bytes before the data section starts, and might copy\n                # an extra word. the pseudocode is:\n                #   dst_data = dst + 32\n                #   copy_dst = dst_data - start % 32\n                #   src_data = src + 32\n                #   copy_src = src_data + (start - start % 32) / 32\n                #            = src_data + (start // 32)\n                #   copy_bytes(copy_dst, copy_src, length)\n                #   //set length AFTER copy because the length word has been clobbered!\n                #   mstore(src, length)\n\n                # start at the first word-aligned address before `start`\n                # e.g. start == byte 7 -> we start copying from byte 0\n                #      start == byte 32 -> we start copying from byte 32\n                copy_src = IRnode.from_list(\n                    [\"add\", src_data, [\"div\", start, 32]], location=src.location\n                )\n\n                # e.g. start == byte 0 -> we copy to dst_data + 0\n                #      start == byte 7 -> we copy to dst_data - 7\n                #      start == byte 33 -> we copy to dst_data - 1\n                copy_dst = IRnode.from_list(\n                    [\"sub\", dst_data, [\"mod\", start, 32]], location=dst.location\n                )\n\n                # len + (32 if start % 32 > 0 else 0)\n                copy_len = [\"add\", length, [\"mul\", 32, [\"iszero\", [\"iszero\", [\"mod\", start, 32]]]]]\n                copy_maxlen = buflen\n\n            else:\n                # all other address spaces (mem, calldata, code) we have\n                # byte-aligned access so we can just do the easy thing,\n                # memcopy(dst_data, src_data + dst_data)\n\n                copy_src = add_ofst(src_data, start)\n                copy_dst = dst_data\n                copy_len = length\n                copy_maxlen = buflen\n\n            do_copy = copy_bytes(copy_dst, copy_src, copy_len, copy_maxlen)\n\n            ret = [\n                \"seq\",\n                # make sure we don't overrun the source buffer\n                [\"assert\", [\"le\", [\"add\", start, length], src_len]],  # bounds check\n                do_copy,\n                [\"mstore\", dst, length],  # set length\n                dst,  # return pointer to dst\n            ]\n            ret = IRnode.from_list(ret, typ=dst_typ, location=MEMORY)\n            return b1.resolve(b2.resolve(b3.resolve(ret)))\n\n\nclass Len(BuiltinFunction):\n    _id = \"len\"\n    _inputs = [(\"b\", (StringT.any(), BytesT.any(), DArrayT.any()))]\n    _return_type = UINT256_T\n\n    def evaluate(self, node):\n        validate_call_args(node, 1)\n        arg = node.args[0]\n        if isinstance(arg, (vy_ast.Str, vy_ast.Bytes)):\n            length = len(arg.value)\n        elif isinstance(arg, vy_ast.Hex):\n            # 2 characters represent 1 byte and we subtract 1 to ignore the leading `0x`\n            length = len(arg.value) // 2 - 1\n        else:\n            raise UnfoldableNode\n\n        return vy_ast.Int.from_node(node, value=length)\n\n    def build_IR(self, node, context):\n        arg = Expr(node.args[0], context).ir_node\n        if arg.value == \"~calldata\":\n            return IRnode.from_list([\"calldatasize\"], typ=UINT256_T)\n        return get_bytearray_length(arg)\n\n\nclass Concat(BuiltinFunction):\n    _id = \"concat\"\n\n    def fetch_call_return(self, node):\n        arg_types = self.infer_arg_types(node)\n\n        length = 0\n        for arg_t in arg_types:\n            length += arg_t.length\n\n        if isinstance(arg_types[0], (StringT)):\n            return_type = StringT()\n        else:\n            return_type = BytesT()\n        return_type.set_length(length)\n        return return_type\n\n    def infer_arg_types(self, node):\n        if len(node.args) < 2:\n            raise ArgumentException(\"Invalid argument count: expected at least 2\", node)\n\n        if node.keywords:\n            raise ArgumentException(\"Keyword arguments are not accepted here\", node.keywords[0])\n\n        ret = []\n        prev_typeclass = None\n        for arg in node.args:\n            validate_expected_type(arg, (BytesT.any(), StringT.any(), BytesM_T.any()))\n            arg_t = get_possible_types_from_node(arg).pop()\n            current_typeclass = \"String\" if isinstance(arg_t, StringT) else \"Bytes\"\n            if prev_typeclass and current_typeclass != prev_typeclass:\n                raise TypeMismatch(\n                    (\n                        \"Concat expects consistent use of string or bytes types, \"\n                        \"use either string or bytes.\"\n                    ),\n                    arg,\n                )\n            prev_typeclass = current_typeclass\n            ret.append(arg_t)\n\n        return ret\n\n    def build_IR(self, expr, context):\n        args = [Expr(arg, context).ir_node for arg in expr.args]\n        if len(args) < 2:\n            raise StructureException(\"Concat expects at least two arguments\", expr)\n\n        # Maximum length of the output\n        dst_maxlen = sum(\n            [arg.typ.maxlen if isinstance(arg.typ, _BytestringT) else arg.typ.m for arg in args]\n        )\n\n        # TODO: try to grab these from semantic analysis\n        if isinstance(args[0].typ, StringT):\n            ret_typ = StringT(dst_maxlen)\n        else:\n            ret_typ = BytesT(dst_maxlen)\n\n        # Node representing the position of the output in memory\n        dst = IRnode.from_list(\n            context.new_internal_variable(ret_typ),\n            typ=ret_typ,\n            location=MEMORY,\n            annotation=\"concat destination\",\n        )\n\n        ret = [\"seq\"]\n        # stack item representing our current offset in the dst buffer\n        ofst = \"concat_ofst\"\n\n        # TODO: optimize for the case where all lengths are statically known.\n        for arg in args:\n            dst_data = add_ofst(bytes_data_ptr(dst), ofst)\n\n            if isinstance(arg.typ, _BytestringT):\n                # Ignore empty strings\n                if arg.typ.maxlen == 0:\n                    continue\n\n                with arg.cache_when_complex(\"arg\") as (b1, arg):\n                    argdata = bytes_data_ptr(arg)\n\n                    with get_bytearray_length(arg).cache_when_complex(\"len\") as (b2, arglen):\n                        do_copy = [\n                            \"seq\",\n                            copy_bytes(dst_data, argdata, arglen, arg.typ.maxlen),\n                            [\"set\", ofst, [\"add\", ofst, arglen]],\n                        ]\n                        ret.append(b1.resolve(b2.resolve(do_copy)))\n\n            else:\n                ret.append(STORE(dst_data, unwrap_location(arg)))\n                ret.append([\"set\", ofst, [\"add\", ofst, arg.typ.m]])\n\n        ret.append(STORE(dst, ofst))\n\n        # Memory location of the output\n        ret.append(dst)\n\n        return IRnode.from_list(\n            [\"with\", ofst, 0, ret], typ=ret_typ, location=MEMORY, annotation=\"concat\"\n        )\n\n\nclass Keccak256(BuiltinFunction):\n    _id = \"keccak256\"\n    # TODO allow any BytesM_T\n    _inputs = [(\"value\", (BytesT.any(), BYTES32_T, StringT.any()))]\n    _return_type = BYTES32_T\n\n    def evaluate(self, node):\n        validate_call_args(node, 1)\n        if isinstance(node.args[0], vy_ast.Bytes):\n            value = node.args[0].value\n        elif isinstance(node.args[0], vy_ast.Str):\n            value = node.args[0].value.encode()\n        elif isinstance(node.args[0], vy_ast.Hex):\n            length = len(node.args[0].value) // 2 - 1\n            value = int(node.args[0].value, 16).to_bytes(length, \"big\")\n        else:\n            raise UnfoldableNode\n\n        hash_ = f\"0x{keccak256(value).hex()}\"\n        return vy_ast.Hex.from_node(node, value=hash_)\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n        # return a concrete type for `value`\n        value_type = get_possible_types_from_node(node.args[0]).pop()\n        return [value_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        assert len(args) == 1\n        return keccak256_helper(expr, args[0], context)\n\n\ndef _make_sha256_call(inp_start, inp_len, out_start, out_len):\n    return [\n        \"assert\",\n        [\n            \"staticcall\",\n            [\"gas\"],  # gas\n            SHA256_ADDRESS,  # address\n            inp_start,\n            inp_len,\n            out_start,\n            out_len,\n        ],\n    ]\n\n\nclass Sha256(BuiltinFunction):\n    _id = \"sha256\"\n    _inputs = [(\"value\", (BYTES32_T, BytesT.any(), StringT.any()))]\n    _return_type = BYTES32_T\n\n    def evaluate(self, node):\n        validate_call_args(node, 1)\n        if isinstance(node.args[0], vy_ast.Bytes):\n            value = node.args[0].value\n        elif isinstance(node.args[0], vy_ast.Str):\n            value = node.args[0].value.encode()\n        elif isinstance(node.args[0], vy_ast.Hex):\n            length = len(node.args[0].value) // 2 - 1\n            value = int(node.args[0].value, 16).to_bytes(length, \"big\")\n        else:\n            raise UnfoldableNode\n\n        hash_ = f\"0x{hashlib.sha256(value).hexdigest()}\"\n        return vy_ast.Hex.from_node(node, value=hash_)\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n        # return a concrete type for `value`\n        value_type = get_possible_types_from_node(node.args[0]).pop()\n        return [value_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        sub = args[0]\n        # bytes32 input\n        if sub.typ == BYTES32_T:\n            return IRnode.from_list(\n                [\n                    \"seq\",\n                    [\"mstore\", MemoryPositions.FREE_VAR_SPACE, sub],\n                    _make_sha256_call(\n                        inp_start=MemoryPositions.FREE_VAR_SPACE,\n                        inp_len=32,\n                        out_start=MemoryPositions.FREE_VAR_SPACE,\n                        out_len=32,\n                    ),\n                    [\"mload\", MemoryPositions.FREE_VAR_SPACE],  # push value onto stack\n                ],\n                typ=BYTES32_T,\n                add_gas_estimate=SHA256_BASE_GAS + 1 * SHA256_PER_WORD_GAS,\n            )\n        # bytearay-like input\n        # special case if it's already in memory\n        sub = ensure_in_memory(sub, context)\n\n        return IRnode.from_list(\n            [\n                \"with\",\n                \"_sub\",\n                sub,\n                [\n                    \"seq\",\n                    _make_sha256_call(\n                        # TODO use add_ofst if sub is statically known\n                        inp_start=[\"add\", \"_sub\", 32],\n                        inp_len=[\"mload\", \"_sub\"],\n                        out_start=MemoryPositions.FREE_VAR_SPACE,\n                        out_len=32,\n                    ),\n                    [\"mload\", MemoryPositions.FREE_VAR_SPACE],\n                ],\n            ],\n            typ=BYTES32_T,\n            add_gas_estimate=SHA256_BASE_GAS + sub.typ.maxlen * SHA256_PER_WORD_GAS,\n        )\n\n\nclass MethodID(FoldedFunction):\n    _id = \"method_id\"\n\n    def evaluate(self, node):\n        validate_call_args(node, 1, [\"output_type\"])\n\n        args = node.args\n        if not isinstance(args[0], vy_ast.Str):\n            raise InvalidType(\"method id must be given as a literal string\", args[0])\n        if \" \" in args[0].value:\n            raise InvalidLiteral(\"Invalid function signature - no spaces allowed.\")\n\n        return_type = self.infer_kwarg_types(node)\n        value = method_id_int(args[0].value)\n\n        if return_type.compare_type(BYTES4_T):\n            return vy_ast.Hex.from_node(node, value=hex(value))\n        else:\n            return vy_ast.Bytes.from_node(node, value=value.to_bytes(4, \"big\"))\n\n    def fetch_call_return(self, node):\n        validate_call_args(node, 1, [\"output_type\"])\n\n        type_ = self.infer_kwarg_types(node)\n        return type_\n\n    def infer_kwarg_types(self, node):\n        if node.keywords:\n            return_type = type_from_annotation(node.keywords[0].value)\n            if return_type.compare_type(BYTES4_T):\n                return BYTES4_T\n            elif isinstance(return_type, BytesT) and return_type.length == 4:\n                return BytesT(4)\n            else:\n                raise ArgumentException(\"output_type must be Bytes[4] or bytes4\", node.keywords[0])\n\n        # If `output_type` is not given, default to `Bytes[4]`\n        return BytesT(4)\n\n\nclass ECRecover(BuiltinFunction):\n    _id = \"ecrecover\"\n    _inputs = [\n        (\"hash\", BYTES32_T),\n        (\"v\", (UINT256_T, UINT8_T)),\n        (\"r\", (UINT256_T, BYTES32_T)),\n        (\"s\", (UINT256_T, BYTES32_T)),\n    ]\n    _return_type = AddressT()\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n        v_t, r_t, s_t = [get_possible_types_from_node(arg).pop() for arg in node.args[1:]]\n        return [BYTES32_T, v_t, r_t, s_t]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        placeholder_node = IRnode.from_list(\n            context.new_internal_variable(BytesT(128)), typ=BytesT(128), location=MEMORY\n        )\n        return IRnode.from_list(\n            [\n                \"seq\",\n                [\"mstore\", placeholder_node, args[0]],\n                [\"mstore\", [\"add\", placeholder_node, 32], args[1]],\n                [\"mstore\", [\"add\", placeholder_node, 64], args[2]],\n                [\"mstore\", [\"add\", placeholder_node, 96], args[3]],\n                [\n                    \"pop\",\n                    [\n                        \"staticcall\",\n                        [\"gas\"],\n                        1,\n                        placeholder_node,\n                        128,\n                        MemoryPositions.FREE_VAR_SPACE,\n                        32,\n                    ],\n                ],\n                [\"mload\", MemoryPositions.FREE_VAR_SPACE],\n            ],\n            typ=AddressT(),\n        )\n\n\ndef _getelem(arg, ind):\n    return unwrap_location(get_element_ptr(arg, IRnode.from_list(ind, typ=INT128_T)))\n\n\nclass ECAdd(BuiltinFunction):\n    _id = \"ecadd\"\n    _inputs = [(\"a\", SArrayT(UINT256_T, 2)), (\"b\", SArrayT(UINT256_T, 2))]\n    _return_type = SArrayT(UINT256_T, 2)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        placeholder_node = IRnode.from_list(\n            context.new_internal_variable(BytesT(128)), typ=BytesT(128), location=MEMORY\n        )\n        o = IRnode.from_list(\n            [\n                \"seq\",\n                [\"mstore\", placeholder_node, _getelem(args[0], 0)],\n                [\"mstore\", [\"add\", placeholder_node, 32], _getelem(args[0], 1)],\n                [\"mstore\", [\"add\", placeholder_node, 64], _getelem(args[1], 0)],\n                [\"mstore\", [\"add\", placeholder_node, 96], _getelem(args[1], 1)],\n                [\"assert\", [\"staticcall\", [\"gas\"], 6, placeholder_node, 128, placeholder_node, 64]],\n                placeholder_node,\n            ],\n            typ=SArrayT(UINT256_T, 2),\n            location=MEMORY,\n        )\n        return o\n\n\nclass ECMul(BuiltinFunction):\n    _id = \"ecmul\"\n    _inputs = [(\"point\", SArrayT(UINT256_T, 2)), (\"scalar\", UINT256_T)]\n    _return_type = SArrayT(UINT256_T, 2)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        placeholder_node = IRnode.from_list(\n            context.new_internal_variable(BytesT(128)), typ=BytesT(128), location=MEMORY\n        )\n        o = IRnode.from_list(\n            [\n                \"seq\",\n                [\"mstore\", placeholder_node, _getelem(args[0], 0)],\n                [\"mstore\", [\"add\", placeholder_node, 32], _getelem(args[0], 1)],\n                [\"mstore\", [\"add\", placeholder_node, 64], args[1]],\n                [\"assert\", [\"staticcall\", [\"gas\"], 7, placeholder_node, 96, placeholder_node, 64]],\n                placeholder_node,\n            ],\n            typ=SArrayT(UINT256_T, 2),\n            location=MEMORY,\n        )\n        return o\n\n\ndef _generic_element_getter(op):\n    def f(index):\n        return IRnode.from_list(\n            [op, [\"add\", \"_sub\", [\"add\", 32, [\"mul\", 32, index]]]], typ=INT128_T\n        )\n\n    return f\n\n\ndef _storage_element_getter(index):\n    return IRnode.from_list([\"sload\", [\"add\", \"_sub\", [\"add\", 1, index]]], typ=INT128_T)\n\n\nclass Extract32(BuiltinFunction):\n    _id = \"extract32\"\n    _inputs = [(\"b\", BytesT.any()), (\"start\", IntegerT.unsigneds())]\n    # \"TYPE_DEFINITION\" is a placeholder value for a type definition string, and\n    # will be replaced by a `TYPE_T` object in `infer_kwarg_types`\n    # (note that it is ignored in _validate_arg_types)\n    _kwargs = {\"output_type\": KwargSettings(\"TYPE_DEFINITION\", BYTES32_T)}\n    _return_type = None\n\n    def fetch_call_return(self, node):\n        self._validate_arg_types(node)\n        return_type = self.infer_kwarg_types(node)[\"output_type\"].typedef\n        return return_type\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n        input_type = get_possible_types_from_node(node.args[0]).pop()\n        return [input_type, UINT256_T]\n\n    def infer_kwarg_types(self, node):\n        if node.keywords:\n            output_type = type_from_annotation(node.keywords[0].value)\n            if not isinstance(output_type, (AddressT, BytesM_T, IntegerT)):\n                raise InvalidType(\n                    \"Output type must be one of integer, bytes32 or address\", node.keywords[0].value\n                )\n            output_typedef = TYPE_T(output_type)\n            node.keywords[0].value._metadata[\"type\"] = output_typedef\n        else:\n            output_typedef = TYPE_T(BYTES32_T)\n\n        return {\"output_type\": output_typedef}\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        sub, index = args\n        ret_type = kwargs[\"output_type\"]\n\n        # Get length and specific element\n        if sub.location == STORAGE:\n            lengetter = IRnode.from_list([\"sload\", \"_sub\"], typ=INT128_T)\n            elementgetter = _storage_element_getter\n\n        else:\n            op = sub.location.load_op\n            lengetter = IRnode.from_list([op, \"_sub\"], typ=INT128_T)\n            elementgetter = _generic_element_getter(op)\n\n        # TODO rewrite all this with cache_when_complex and bitshifts\n\n        # Special case: index known to be a multiple of 32\n        if isinstance(index.value, int) and not index.value % 32:\n            o = IRnode.from_list(\n                [\n                    \"with\",\n                    \"_sub\",\n                    sub,\n                    elementgetter(\n                        [\"div\", clamp2(0, index, [\"sub\", lengetter, 32], signed=True), 32]\n                    ),\n                ],\n                typ=ret_type,\n                annotation=\"extracting 32 bytes\",\n            )\n        # General case\n        else:\n            o = IRnode.from_list(\n                [\n                    \"with\",\n                    \"_sub\",\n                    sub,\n                    [\n                        \"with\",\n                        \"_len\",\n                        lengetter,\n                        [\n                            \"with\",\n                            \"_index\",\n                            clamp2(0, index, [\"sub\", \"_len\", 32], signed=True),\n                            [\n                                \"with\",\n                                \"_mi32\",\n                                [\"mod\", \"_index\", 32],\n                                [\n                                    \"with\",\n                                    \"_di32\",\n                                    [\"div\", \"_index\", 32],\n                                    [\n                                        \"if\",\n                                        \"_mi32\",\n                                        [\n                                            \"add\",\n                                            [\"mul\", elementgetter(\"_di32\"), [\"exp\", 256, \"_mi32\"]],\n                                            [\n                                                \"div\",\n                                                elementgetter([\"add\", \"_di32\", 1]),\n                                                [\"exp\", 256, [\"sub\", 32, \"_mi32\"]],\n                                            ],\n                                        ],\n                                        elementgetter(\"_di32\"),\n                                    ],\n                                ],\n                            ],\n                        ],\n                    ],\n                ],\n                typ=ret_type,\n                annotation=\"extract32\",\n            )\n        return IRnode.from_list(clamp_basetype(o), typ=ret_type)\n\n\nclass AsWeiValue(BuiltinFunction):\n    _id = \"as_wei_value\"\n    _inputs = [(\"value\", (IntegerT.any(), DecimalT())), (\"unit\", StringT.any())]\n    _return_type = UINT256_T\n\n    wei_denoms = {\n        (\"wei\",): 1,\n        (\"femtoether\", \"kwei\", \"babbage\"): 10**3,\n        (\"picoether\", \"mwei\", \"lovelace\"): 10**6,\n        (\"nanoether\", \"gwei\", \"shannon\"): 10**9,\n        (\"microether\", \"szabo\"): 10**12,\n        (\"milliether\", \"finney\"): 10**15,\n        (\"ether\",): 10**18,\n        (\"kether\", \"grand\"): 10**21,\n    }\n\n    def get_denomination(self, node):\n        if not isinstance(node.args[1], vy_ast.Str):\n            raise ArgumentException(\n                \"Wei denomination must be given as a literal string\", node.args[1]\n            )\n        try:\n            denom = next(v for k, v in self.wei_denoms.items() if node.args[1].value in k)\n        except StopIteration:\n            raise ArgumentException(\n                f\"Unknown denomination: {node.args[1].value}\", node.args[1]\n            ) from None\n\n        return denom\n\n    def evaluate(self, node):\n        validate_call_args(node, 2)\n        denom = self.get_denomination(node)\n\n        if not isinstance(node.args[0], (vy_ast.Decimal, vy_ast.Int)):\n            raise UnfoldableNode\n        value = node.args[0].value\n\n        if value < 0:\n            raise InvalidLiteral(\"Negative wei value not allowed\", node.args[0])\n\n        if isinstance(value, int) and value >= 2**256:\n            raise InvalidLiteral(\"Value out of range for uint256\", node.args[0])\n        if isinstance(value, Decimal) and value > SizeLimits.MAX_AST_DECIMAL:\n            raise InvalidLiteral(\"Value out of range for decimal\", node.args[0])\n\n        return vy_ast.Int.from_node(node, value=int(value * denom))\n\n    def fetch_call_return(self, node):\n        self.infer_arg_types(node)\n        return self._return_type\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n        # return a concrete type instead of abstract type\n        value_type = get_possible_types_from_node(node.args[0]).pop()\n        unit_type = get_possible_types_from_node(node.args[1]).pop()\n        return [value_type, unit_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        value = args[0]\n\n        denom_divisor = self.get_denomination(expr)\n        if value.typ in (UINT256_T, UINT8_T):\n            sub = [\n                \"with\",\n                \"ans\",\n                [\"mul\", value, denom_divisor],\n                [\n                    \"seq\",\n                    [\n                        \"assert\",\n                        [\"or\", [\"eq\", [\"div\", \"ans\", value], denom_divisor], [\"iszero\", value]],\n                    ],\n                    \"ans\",\n                ],\n            ]\n        elif value.typ == INT128_T:\n            # signed types do not require bounds checks because the\n            # largest possible converted value will not overflow 2**256\n            sub = [\"seq\", [\"assert\", [\"sgt\", value, -1]], [\"mul\", value, denom_divisor]]\n        elif value.typ == DecimalT():\n            sub = [\n                \"seq\",\n                [\"assert\", [\"sgt\", value, -1]],\n                [\"div\", [\"mul\", value, denom_divisor], DECIMAL_DIVISOR],\n            ]\n        else:\n            raise CompilerPanic(f\"Unexpected type: {value.typ}\")\n\n        return IRnode.from_list(sub, typ=UINT256_T)\n\n\nzero_value = IRnode.from_list(0, typ=UINT256_T)\nempty_value = IRnode.from_list(0, typ=BYTES32_T)\n\n\nclass RawCall(BuiltinFunction):\n    _id = \"raw_call\"\n    _inputs = [(\"to\", AddressT()), (\"data\", BytesT.any())]\n    _kwargs = {\n        \"max_outsize\": KwargSettings(UINT256_T, 0, require_literal=True),\n        \"gas\": KwargSettings(UINT256_T, \"gas\"),\n        \"value\": KwargSettings(UINT256_T, zero_value),\n        \"is_delegate_call\": KwargSettings(BoolT(), False, require_literal=True),\n        \"is_static_call\": KwargSettings(BoolT(), False, require_literal=True),\n        \"revert_on_failure\": KwargSettings(BoolT(), True, require_literal=True),\n    }\n    _return_type = None\n\n    def fetch_call_return(self, node):\n        self._validate_arg_types(node)\n\n        kwargz = {i.arg: i.value for i in node.keywords}\n\n        outsize = kwargz.get(\"max_outsize\")\n        revert_on_failure = kwargz.get(\"revert_on_failure\")\n        revert_on_failure = revert_on_failure.value if revert_on_failure is not None else True\n\n        if outsize is None:\n            if revert_on_failure:\n                return None\n            return BoolT()\n\n        if not isinstance(outsize, vy_ast.Int) or outsize.value < 0:\n            raise\n\n        if outsize.value:\n            return_type = BytesT()\n            return_type.set_min_length(outsize.value)\n\n            if revert_on_failure:\n                return return_type\n            return TupleT([BoolT(), return_type])\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n        # return a concrete type for `data`\n        data_type = get_possible_types_from_node(node.args[1]).pop()\n        return [self._inputs[0][1], data_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        to, data = args\n        # TODO: must compile in source code order, left-to-right\n        gas, value, outsize, delegate_call, static_call, revert_on_failure = (\n            kwargs[\"gas\"],\n            kwargs[\"value\"],\n            kwargs[\"max_outsize\"],\n            kwargs[\"is_delegate_call\"],\n            kwargs[\"is_static_call\"],\n            kwargs[\"revert_on_failure\"],\n        )\n\n        if delegate_call and static_call:\n            raise ArgumentException(\n                \"Call may use one of `is_delegate_call` or `is_static_call`, not both\", expr\n            )\n        if not static_call and context.is_constant():\n            raise StateAccessViolation(\n                f\"Cannot make modifying calls from {context.pp_constancy()},\"\n                \" use `is_static_call=True` to perform this action\",\n                expr,\n            )\n\n        if data.value == \"~calldata\":\n            call_ir = [\"with\", \"mem_ofst\", \"msize\"]\n            args_ofst = [\"seq\", [\"calldatacopy\", \"mem_ofst\", 0, \"calldatasize\"], \"mem_ofst\"]\n            args_len = \"calldatasize\"\n        else:\n            # some gymnastics to propagate constants (if eval_input_buf\n            # returns a static memory location)\n            eval_input_buf = ensure_in_memory(data, context)\n\n            input_buf = eval_seq(eval_input_buf)\n\n            if input_buf is None:\n                call_ir = [\"with\", \"arg_buf\", eval_input_buf]\n                input_buf = IRnode.from_list(\"arg_buf\")\n            else:\n                call_ir = [\"seq\", eval_input_buf]\n\n            args_ofst = add_ofst(input_buf, 32)\n            args_len = [\"mload\", input_buf]\n\n        output_node = IRnode.from_list(\n            context.new_internal_variable(BytesT(outsize)), typ=BytesT(outsize), location=MEMORY\n        )\n\n        bool_ty = BoolT()\n\n        # build IR for call or delegatecall\n        common_call_args = [\n            args_ofst,\n            args_len,\n            # if there is no return value, the return offset can be 0\n            add_ofst(output_node, 32) if outsize else 0,\n            outsize,\n        ]\n\n        if delegate_call:\n            call_op = [\"delegatecall\", gas, to, *common_call_args]\n        elif static_call:\n            call_op = [\"staticcall\", gas, to, *common_call_args]\n        else:\n            call_op = [\"call\", gas, to, value, *common_call_args]\n\n        call_ir += [call_op]\n\n        # build sequence IR\n        if outsize:\n            # return minimum of outsize and returndatasize\n            size = [\"select\", [\"lt\", outsize, \"returndatasize\"], outsize, \"returndatasize\"]\n\n            # store output size and return output location\n            store_output_size = [\"seq\", [\"mstore\", output_node, size], output_node]\n\n            bytes_ty = BytesT(outsize)\n\n            if revert_on_failure:\n                typ = bytes_ty\n                # check the call success flag, and store returndata in memory\n                ret_ir = [\"seq\", check_external_call(call_ir), store_output_size]\n                return IRnode.from_list(ret_ir, typ=typ, location=MEMORY)\n            else:\n                typ = TupleT([bool_ty, bytes_ty])\n                ret_ir = [\n                    \"multi\",\n                    # use IRnode.from_list to make sure the types are\n                    # set properly on the \"multi\" members\n                    IRnode.from_list(call_ir, typ=bool_ty),\n                    IRnode.from_list(store_output_size, typ=bytes_ty, location=MEMORY),\n                ]\n                # return an IR tuple of call success flag and returndata pointer\n                return IRnode.from_list(ret_ir, typ=typ)\n\n        # max_outsize is 0.\n\n        if not revert_on_failure:\n            # return call flag as stack item\n            typ = bool_ty\n            return IRnode.from_list(call_ir, typ=typ)\n\n        else:\n            # check the call success flag and don't return anything\n            ret_ir = check_external_call(call_ir)\n            return IRnode.from_list(ret_ir, typ=None)\n\n        raise CompilerPanic(\"unreachable!\")\n\n\nclass Send(BuiltinFunction):\n    _id = \"send\"\n    _inputs = [(\"to\", AddressT()), (\"value\", UINT256_T)]\n    # default gas stipend is 0\n    _kwargs = {\"gas\": KwargSettings(UINT256_T, 0)}\n    _return_type = None\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        to, value = args\n        gas = kwargs[\"gas\"]\n        context.check_is_not_constant(\"send ether\", expr)\n        return IRnode.from_list([\"assert\", [\"call\", gas, to, value, 0, 0, 0, 0]])\n\n\nclass SelfDestruct(BuiltinFunction):\n    _id = \"selfdestruct\"\n    _inputs = [(\"to\", AddressT())]\n    _return_type = None\n    _is_terminus = True\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        context.check_is_not_constant(\"selfdestruct\", expr)\n        return IRnode.from_list(\n            [\"seq\", eval_once_check(_freshname(\"selfdestruct\")), [\"selfdestruct\", args[0]]]\n        )\n\n\nclass BlockHash(BuiltinFunction):\n    _id = \"blockhash\"\n    _inputs = [(\"block_num\", UINT256_T)]\n    _return_type = BYTES32_T\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, contact):\n        return IRnode.from_list(\n            [\"blockhash\", clamp(\"lt\", clamp(\"sge\", args[0], [\"sub\", [\"number\"], 256]), \"number\")],\n            typ=BYTES32_T,\n        )\n\n\nclass RawRevert(BuiltinFunction):\n    _id = \"raw_revert\"\n    _inputs = [(\"data\", BytesT.any())]\n    _return_type = None\n    _is_terminus = True\n\n    def fetch_call_return(self, node):\n        return None\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n        data_type = get_possible_types_from_node(node.args[0]).pop()\n        return [data_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        with ensure_in_memory(args[0], context).cache_when_complex(\"err_buf\") as (b, buf):\n            data = bytes_data_ptr(buf)\n            len_ = get_bytearray_length(buf)\n            return b.resolve(IRnode.from_list([\"revert\", data, len_]))\n\n\nclass RawLog(BuiltinFunction):\n    _id = \"raw_log\"\n    _inputs = [(\"topics\", DArrayT(BYTES32_T, 4)), (\"data\", (BYTES32_T, BytesT.any()))]\n\n    def fetch_call_return(self, node):\n        self.infer_arg_types(node)\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n\n        if not isinstance(node.args[0], vy_ast.List) or len(node.args[0].elements) > 4:\n            raise InvalidType(\"Expecting a list of 0-4 topics as first argument\", node.args[0])\n\n        # return a concrete type for `data`\n        data_type = get_possible_types_from_node(node.args[1]).pop()\n\n        return [self._inputs[0][1], data_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        topics_length = len(expr.args[0].elements)\n        topics = args[0].args\n\n        # sanity check topics is a literal list\n        assert args[0].value in (\"~empty\", \"multi\")\n\n        data = args[1]\n\n        if data.typ == BYTES32_T:\n            placeholder = context.new_internal_variable(BYTES32_T)\n            return IRnode.from_list(\n                [\n                    \"seq\",\n                    # TODO use make_setter\n                    [\"mstore\", placeholder, unwrap_location(data)],\n                    [\"log\" + str(topics_length), placeholder, 32] + topics,\n                ]\n            )\n\n        input_buf = ensure_in_memory(data, context)\n\n        return IRnode.from_list(\n            [\n                \"with\",\n                \"_sub\",\n                input_buf,\n                [\"log\" + str(topics_length), [\"add\", \"_sub\", 32], [\"mload\", \"_sub\"], *topics],\n            ]\n        )\n\n\nclass BitwiseAnd(BuiltinFunction):\n    _id = \"bitwise_and\"\n    _inputs = [(\"x\", UINT256_T), (\"y\", UINT256_T)]\n    _return_type = UINT256_T\n    _warned = False\n\n    def evaluate(self, node):\n        if not self.__class__._warned:\n            vyper_warn(\"`bitwise_and()` is deprecated! Please use the & operator instead.\")\n            self.__class__._warned = True\n\n        validate_call_args(node, 2)\n        for arg in node.args:\n            if not isinstance(arg, vy_ast.Num):\n                raise UnfoldableNode\n            if arg.value < 0 or arg.value >= 2**256:\n                raise InvalidLiteral(\"Value out of range for uint256\", arg)\n\n        value = node.args[0].value & node.args[1].value\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list([\"and\", args[0], args[1]], typ=UINT256_T)\n\n\nclass BitwiseOr(BuiltinFunction):\n    _id = \"bitwise_or\"\n    _inputs = [(\"x\", UINT256_T), (\"y\", UINT256_T)]\n    _return_type = UINT256_T\n    _warned = False\n\n    def evaluate(self, node):\n        if not self.__class__._warned:\n            vyper_warn(\"`bitwise_or()` is deprecated! Please use the | operator instead.\")\n            self.__class__._warned = True\n\n        validate_call_args(node, 2)\n        for arg in node.args:\n            if not isinstance(arg, vy_ast.Num):\n                raise UnfoldableNode\n            if arg.value < 0 or arg.value >= 2**256:\n                raise InvalidLiteral(\"Value out of range for uint256\", arg)\n\n        value = node.args[0].value | node.args[1].value\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list([\"or\", args[0], args[1]], typ=UINT256_T)\n\n\nclass BitwiseXor(BuiltinFunction):\n    _id = \"bitwise_xor\"\n    _inputs = [(\"x\", UINT256_T), (\"y\", UINT256_T)]\n    _return_type = UINT256_T\n    _warned = False\n\n    def evaluate(self, node):\n        if not self.__class__._warned:\n            vyper_warn(\"`bitwise_xor()` is deprecated! Please use the ^ operator instead.\")\n            self.__class__._warned = True\n\n        validate_call_args(node, 2)\n        for arg in node.args:\n            if not isinstance(arg, vy_ast.Num):\n                raise UnfoldableNode\n            if arg.value < 0 or arg.value >= 2**256:\n                raise InvalidLiteral(\"Value out of range for uint256\", arg)\n\n        value = node.args[0].value ^ node.args[1].value\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list([\"xor\", args[0], args[1]], typ=UINT256_T)\n\n\nclass BitwiseNot(BuiltinFunction):\n    _id = \"bitwise_not\"\n    _inputs = [(\"x\", UINT256_T)]\n    _return_type = UINT256_T\n    _warned = False\n\n    def evaluate(self, node):\n        if not self.__class__._warned:\n            vyper_warn(\"`bitwise_not()` is deprecated! Please use the ^ operator instead.\")\n            self.__class__._warned = True\n\n        validate_call_args(node, 1)\n        if not isinstance(node.args[0], vy_ast.Num):\n            raise UnfoldableNode\n\n        value = node.args[0].value\n        if value < 0 or value >= 2**256:\n            raise InvalidLiteral(\"Value out of range for uint256\", node.args[0])\n\n        value = (2**256 - 1) - value\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list([\"not\", args[0]], typ=UINT256_T)\n\n\nclass Shift(BuiltinFunction):\n    _id = \"shift\"\n    _inputs = [(\"x\", (UINT256_T, INT256_T)), (\"_shift\", IntegerT.any())]\n    _return_type = UINT256_T\n\n    def evaluate(self, node):\n        validate_call_args(node, 2)\n        if [i for i in node.args if not isinstance(i, vy_ast.Num)]:\n            raise UnfoldableNode\n        value, shift = [i.value for i in node.args]\n        if value < 0 or value >= 2**256:\n            raise InvalidLiteral(\"Value out of range for uint256\", node.args[0])\n        if shift < -256 or shift > 256:\n            # this validation is performed to prevent the compiler from hanging\n            # rather than for correctness because the post-folded constant would\n            # have been validated anyway\n            raise InvalidLiteral(\"Shift must be between -256 and 256\", node.args[1])\n\n        if shift < 0:\n            value = value >> -shift\n        else:\n            value = (value << shift) % (2**256)\n        return vy_ast.Int.from_node(node, value=value)\n\n    def fetch_call_return(self, node):\n        # return type is the type of the first argument\n        return self.infer_arg_types(node)[0]\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n        # return a concrete type instead of SignedIntegerAbstractType\n        arg_ty = get_possible_types_from_node(node.args[0])[0]\n        shift_ty = get_possible_types_from_node(node.args[1])[0]\n        return [arg_ty, shift_ty]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        # \"gshr\" -- generalized right shift\n        argty = args[0].typ\n        GSHR = sar if argty.is_signed else shr\n\n        with args[0].cache_when_complex(\"to_shift\") as (b1, arg), args[1].cache_when_complex(\n            \"bits\"\n        ) as (b2, bits):\n            neg_bits = [\"sub\", 0, bits]\n            ret = [\"if\", [\"slt\", bits, 0], GSHR(neg_bits, arg), shl(bits, arg)]\n            return b1.resolve(b2.resolve(IRnode.from_list(ret, typ=argty)))\n\n\nclass _AddMulMod(BuiltinFunction):\n    _inputs = [(\"a\", UINT256_T), (\"b\", UINT256_T), (\"c\", UINT256_T)]\n    _return_type = UINT256_T\n\n    def evaluate(self, node):\n        validate_call_args(node, 3)\n        if isinstance(node.args[2], vy_ast.Num) and node.args[2].value == 0:\n            raise ZeroDivisionException(\"Modulo by 0\", node.args[2])\n        for arg in node.args:\n            if not isinstance(arg, vy_ast.Num):\n                raise UnfoldableNode\n            if arg.value < 0 or arg.value >= 2**256:\n                raise InvalidLiteral(\"Value out of range for uint256\", arg)\n\n        value = self._eval_fn(node.args[0].value, node.args[1].value) % node.args[2].value\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list(\n            [\"seq\", [\"assert\", args[2]], [self._opcode, args[0], args[1], args[2]]], typ=UINT256_T\n        )\n\n\nclass AddMod(_AddMulMod):\n    _id = \"uint256_addmod\"\n    _eval_fn = operator.add\n    _opcode = \"addmod\"\n\n\nclass MulMod(_AddMulMod):\n    _id = \"uint256_mulmod\"\n    _eval_fn = operator.mul\n    _opcode = \"mulmod\"\n\n\nclass PowMod256(BuiltinFunction):\n    _id = \"pow_mod256\"\n    _inputs = [(\"a\", UINT256_T), (\"b\", UINT256_T)]\n    _return_type = UINT256_T\n\n    def evaluate(self, node):\n        validate_call_args(node, 2)\n        if next((i for i in node.args if not isinstance(i, vy_ast.Int)), None):\n            raise UnfoldableNode\n\n        left, right = node.args\n        if left.value < 0 or right.value < 0:\n            raise UnfoldableNode\n\n        value = pow(left.value, right.value, 2**256)\n        return vy_ast.Int.from_node(node, value=value)\n\n    def build_IR(self, expr, context):\n        left = Expr.parse_value_expr(expr.args[0], context)\n        right = Expr.parse_value_expr(expr.args[1], context)\n        return IRnode.from_list([\"exp\", left, right], typ=left.typ)\n\n\nclass Abs(BuiltinFunction):\n    _id = \"abs\"\n    _inputs = [(\"value\", INT256_T)]\n    _return_type = INT256_T\n\n    def evaluate(self, node):\n        validate_call_args(node, 1)\n        if not isinstance(node.args[0], vy_ast.Int):\n            raise UnfoldableNode\n\n        value = node.args[0].value\n        if not SizeLimits.MIN_INT256 <= value <= SizeLimits.MAX_INT256:\n            raise OverflowException(\"Literal is outside of allowable range for int256\")\n        value = abs(value)\n        if not SizeLimits.MIN_INT256 <= value <= SizeLimits.MAX_INT256:\n            raise OverflowException(\"Absolute literal value is outside allowable range for int256\")\n\n        return vy_ast.Int.from_node(node, value=value)\n\n    def build_IR(self, expr, context):\n        value = Expr.parse_value_expr(expr.args[0], context)\n        sub = [\n            \"with\",\n            \"orig\",\n            value,\n            [\n                \"if\",\n                [\"slt\", \"orig\", 0],\n                # clamp orig != -2**255 (because it maps to itself under negation)\n                [\"seq\", [\"assert\", [\"ne\", \"orig\", [\"sub\", 0, \"orig\"]]], [\"sub\", 0, \"orig\"]],\n                \"orig\",\n            ],\n        ]\n        return IRnode.from_list(sub, typ=INT256_T)\n\n\n# CREATE* functions\n\n\n# create helper functions\n# generates CREATE op sequence + zero check for result\ndef _create_ir(value, buf, length, salt=None, checked=True):\n    args = [value, buf, length]\n    create_op = \"create\"\n    if salt is not None:\n        create_op = \"create2\"\n        args.append(salt)\n\n    ret = IRnode.from_list(\n        [\"seq\", eval_once_check(_freshname(\"create_builtin\")), [create_op, *args]]\n    )\n\n    if not checked:\n        return ret\n\n    return clamp_nonzero(ret)\n\n\n# calculate the gas used by create for a given number of bytes\ndef _create_addl_gas_estimate(size, should_use_create2):\n    ret = 200 * size\n    if should_use_create2:\n        ret += SHA3_PER_WORD * ceil32(size) // 32\n    return ret\n\n\ndef eip1167_bytecode():\n    # NOTE cyclic import?\n    from vyper.ir.compile_ir import assembly_to_evm\n\n    loader_asm = [\n        \"PUSH1\",\n        0x2D,\n        \"RETURNDATASIZE\",\n        \"DUP2\",\n        \"PUSH1\",\n        0x09,\n        \"RETURNDATASIZE\",\n        \"CODECOPY\",\n        \"RETURN\",\n    ]\n    forwarder_pre_asm = [\n        \"CALLDATASIZE\",\n        \"RETURNDATASIZE\",\n        \"RETURNDATASIZE\",\n        \"CALLDATACOPY\",\n        \"RETURNDATASIZE\",\n        \"RETURNDATASIZE\",\n        \"RETURNDATASIZE\",\n        \"CALLDATASIZE\",\n        \"RETURNDATASIZE\",\n        \"PUSH20\",  # [address to delegate to]\n    ]\n    forwarder_post_asm = [\n        \"GAS\",\n        \"DELEGATECALL\",\n        \"RETURNDATASIZE\",\n        \"DUP3\",\n        \"DUP1\",\n        \"RETURNDATACOPY\",\n        \"SWAP1\",\n        \"RETURNDATASIZE\",\n        \"SWAP2\",\n        \"PUSH1\",\n        0x2B,  # jumpdest of whole program.\n        \"JUMPI\",\n        \"REVERT\",\n        \"JUMPDEST\",\n        \"RETURN\",\n    ]\n    return (\n        assembly_to_evm(loader_asm)[0],\n        assembly_to_evm(forwarder_pre_asm)[0],\n        assembly_to_evm(forwarder_post_asm)[0],\n    )\n\n\n# \"standard\" initcode for code which can be larger than 256 bytes.\n# returns the code starting from 0x0b with len `codesize`.\n# NOTE: it assumes codesize <= 2**24.\ndef _create_preamble(codesize):\n    from vyper.ir.compile_ir import assembly_to_evm\n\n    evm_len = 0x0B  # 11 bytes\n    asm = [\n        # use PUSH3 to be able to deal with larger contracts\n        \"PUSH3\",\n        # blank space for codesize\n        0x00,\n        0x00,\n        0x00,\n        \"RETURNDATASIZE\",\n        \"DUP2\",\n        \"PUSH1\",\n        evm_len,\n        \"RETURNDATASIZE\",\n        \"CODECOPY\",\n        \"RETURN\",\n    ]\n    evm = assembly_to_evm(asm)[0]\n    assert len(evm) == evm_len, evm\n\n    shl_bits = (evm_len - 4) * 8  # codesize needs to go right after the PUSH3\n    # mask codesize into the aforementioned \"blank space\"\n    return [\"or\", bytes_to_int(evm), shl(shl_bits, codesize)], evm_len\n\n\nclass _CreateBase(BuiltinFunction):\n    _kwargs = {\n        \"value\": KwargSettings(UINT256_T, zero_value),\n        \"salt\": KwargSettings(BYTES32_T, empty_value),\n    }\n    _return_type = AddressT()\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        # errmsg something like \"Cannot use {self._id} in pure fn\"\n        context.check_is_not_constant(\"use {self._id}\", expr)\n\n        should_use_create2 = \"salt\" in [kwarg.arg for kwarg in expr.keywords]\n        if not should_use_create2:\n            kwargs[\"salt\"] = None\n\n        ir_builder = self._build_create_IR(expr, args, context, **kwargs)\n\n        add_gas_estimate = self._add_gas_estimate(args, should_use_create2)\n\n        return IRnode.from_list(\n            ir_builder, typ=AddressT(), annotation=self._id, add_gas_estimate=add_gas_estimate\n        )\n\n\nclass CreateMinimalProxyTo(_CreateBase):\n    # create an EIP1167 \"minimal proxy\" to the target contract\n\n    _id = \"create_minimal_proxy_to\"\n    _inputs = [(\"target\", AddressT())]\n\n    def _add_gas_estimate(self, args, should_use_create2):\n        a, b, c = eip1167_bytecode()\n        bytecode_len = 20 + len(b) + len(c)\n        return _create_addl_gas_estimate(bytecode_len, should_use_create2)\n\n    def _build_create_IR(self, expr, args, context, value, salt):\n        target_address = args[0]\n\n        buf = context.new_internal_variable(BytesT(96))\n\n        loader_evm, forwarder_pre_evm, forwarder_post_evm = eip1167_bytecode()\n        # Adjust to 32-byte boundaries\n        preamble_length = len(loader_evm) + len(forwarder_pre_evm)\n        forwarder_preamble = bytes_to_int(\n            loader_evm + forwarder_pre_evm + b\"\\x00\" * (32 - preamble_length)\n        )\n        forwarder_post = bytes_to_int(forwarder_post_evm + b\"\\x00\" * (32 - len(forwarder_post_evm)))\n\n        # left-align the target\n        if target_address.is_literal:\n            # note: should move to optimizer once we have\n            # codesize optimization pipeline\n            aligned_target = args[0].value << 96\n        else:\n            aligned_target = shl(96, target_address)\n\n        buf_len = preamble_length + 20 + len(forwarder_post_evm)\n\n        return [\n            \"seq\",\n            [\"mstore\", buf, forwarder_preamble],\n            [\"mstore\", [\"add\", buf, preamble_length], aligned_target],\n            [\"mstore\", [\"add\", buf, preamble_length + 20], forwarder_post],\n            _create_ir(value, buf, buf_len, salt=salt),\n        ]\n\n\nclass CreateForwarderTo(CreateMinimalProxyTo):\n    _warned = False\n\n    def build_IR(self, expr, context):\n        if not self._warned:\n            vyper_warn(\"`create_forwarder_to` is a deprecated alias of `create_minimal_proxy_to`!\")\n            self._warned = True\n\n        return super().build_IR(expr, context)\n\n\nclass CreateCopyOf(_CreateBase):\n    _id = \"create_copy_of\"\n    _inputs = [(\"target\", AddressT())]\n\n    @property\n    def _preamble_len(self):\n        return 11\n\n    def _add_gas_estimate(self, args, should_use_create2):\n        # max possible runtime length + preamble length\n        return _create_addl_gas_estimate(EIP_170_LIMIT + self._preamble_len, should_use_create2)\n\n    def _build_create_IR(self, expr, args, context, value, salt):\n        target = args[0]\n\n        with target.cache_when_complex(\"create_target\") as (b1, target):\n            codesize = IRnode.from_list([\"extcodesize\", target])\n            msize = IRnode.from_list([\"msize\"])\n            with codesize.cache_when_complex(\"target_codesize\") as (\n                b2,\n                codesize,\n            ), msize.cache_when_complex(\"mem_ofst\") as (b3, mem_ofst):\n                ir = [\"seq\"]\n\n                # make sure there is actually code at the target\n                ir.append([\"assert\", codesize])\n\n                # store the preamble at msize + 22 (zero padding)\n                preamble, preamble_len = _create_preamble(codesize)\n                assert preamble_len == self._preamble_len\n\n                ir.append([\"mstore\", mem_ofst, preamble])\n\n                # copy the target code into memory. current layout:\n                # msize | 00...00 (22 0's) | preamble | bytecode\n                ir.append([\"extcodecopy\", target, add_ofst(mem_ofst, 32), 0, codesize])\n\n                buf = add_ofst(mem_ofst, 32 - preamble_len)\n                buf_len = [\"add\", codesize, preamble_len]\n\n                ir.append(_create_ir(value, buf, buf_len, salt))\n\n                return b1.resolve(b2.resolve(b3.resolve(ir)))\n\n\nclass CreateFromBlueprint(_CreateBase):\n    _id = \"create_from_blueprint\"\n    _inputs = [(\"target\", AddressT())]\n    _kwargs = {\n        \"value\": KwargSettings(UINT256_T, zero_value),\n        \"salt\": KwargSettings(BYTES32_T, empty_value),\n        \"raw_args\": KwargSettings(BoolT(), False, require_literal=True),\n        \"code_offset\": KwargSettings(UINT256_T, zero_value),\n    }\n    _has_varargs = True\n\n    def _add_gas_estimate(self, args, should_use_create2):\n        ctor_args = ir_tuple_from_args(args[1:])\n        # max possible size of init code\n        maxlen = EIP_170_LIMIT + ctor_args.typ.abi_type.size_bound()\n        return _create_addl_gas_estimate(maxlen, should_use_create2)\n\n    def _build_create_IR(self, expr, args, context, value, salt, code_offset, raw_args):\n        target = args[0]\n        ctor_args = args[1:]\n\n        ctor_args = [ensure_in_memory(arg, context) for arg in ctor_args]\n\n        if raw_args:\n            if len(ctor_args) != 1 or not isinstance(ctor_args[0].typ, BytesT):\n                raise StructureException(\"raw_args must be used with exactly 1 bytes argument\")\n\n            argbuf = bytes_data_ptr(ctor_args[0])\n            argslen = get_bytearray_length(ctor_args[0])\n            bufsz = ctor_args[0].typ.maxlen\n        else:\n            # encode the varargs\n            to_encode = ir_tuple_from_args(ctor_args)\n\n            # pretend we allocated enough memory for the encoder\n            # (we didn't, but we are clobbering unused memory so it's safe.)\n            bufsz = to_encode.typ.abi_type.size_bound()\n            argbuf = IRnode.from_list(\n                context.new_internal_variable(get_type_for_exact_size(bufsz)), location=MEMORY\n            )\n\n            # return a complex expression which writes to memory and returns\n            # the length of the encoded data\n            argslen = abi_encode(argbuf, to_encode, context, bufsz=bufsz, returns_len=True)\n\n        # NOTE: we need to invoke the abi encoder before evaluating MSIZE,\n        # then copy the abi encoded buffer to past-the-end of the initcode\n        # (since the abi encoder could write to fresh memory).\n        # it would be good to not require the memory copy, but need\n        # to evaluate memory safety.\n        with target.cache_when_complex(\"create_target\") as (b1, target), argslen.cache_when_complex(\n            \"encoded_args_len\"\n        ) as (b2, encoded_args_len), code_offset.cache_when_complex(\"code_ofst\") as (b3, codeofst):\n            codesize = IRnode.from_list([\"sub\", [\"extcodesize\", target], codeofst])\n            # copy code to memory starting from msize. we are clobbering\n            # unused memory so it's safe.\n            msize = IRnode.from_list([\"msize\"], location=MEMORY)\n            with codesize.cache_when_complex(\"target_codesize\") as (\n                b4,\n                codesize,\n            ), msize.cache_when_complex(\"mem_ofst\") as (b5, mem_ofst):\n                ir = [\"seq\"]\n\n                # make sure there is code at the target, and that\n                # code_ofst <= (extcodesize target).\n                # (note if code_ofst > (extcodesize target), would be\n                # OOG on the EXTCODECOPY)\n                # (code_ofst == (extcodesize target) would be empty\n                # initcode, which we disallow for hygiene reasons -\n                # same as `create_copy_of` on an empty target).\n                ir.append([\"assert\", [\"sgt\", codesize, 0]])\n\n                # copy the target code into memory.\n                # layout starting from mem_ofst:\n                # 00...00 (22 0's) | preamble | bytecode\n                ir.append([\"extcodecopy\", target, mem_ofst, codeofst, codesize])\n\n                ir.append(copy_bytes(add_ofst(mem_ofst, codesize), argbuf, encoded_args_len, bufsz))\n\n                # theoretically, dst = \"msize\", but just be safe.\n                # if len(ctor_args) > 0:\n                #    dst = add_ofst(mem_ofst, codesize)\n                #    encoded_args_len = self._encode_args(dst, ctor_args, context)\n                # else:\n                #    encoded_args_len = 0\n\n                length = [\"add\", codesize, encoded_args_len]\n\n                ir.append(_create_ir(value, mem_ofst, length, salt))\n\n                return b1.resolve(b2.resolve(b3.resolve(b4.resolve(b5.resolve(ir)))))\n\n\nclass _UnsafeMath(BuiltinFunction):\n    # TODO add unsafe math for `decimal`s\n    _inputs = [(\"a\", IntegerT.any()), (\"b\", IntegerT.any())]\n\n    def __repr__(self):\n        return f\"builtin function unsafe_{self.op}\"\n\n    def fetch_call_return(self, node):\n        return_type = self.infer_arg_types(node).pop()\n        return return_type\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n\n        types_list = get_common_types(*node.args, filter_fn=lambda x: isinstance(x, IntegerT))\n        if not types_list:\n            raise TypeMismatch(f\"unsafe_{self.op} called on dislike types\", node)\n\n        type_ = types_list.pop()\n        return [type_, type_]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        (a, b) = args\n        op = self.op\n\n        assert a.typ == b.typ, \"unreachable\"\n\n        otyp = a.typ\n\n        if op == \"div\" and a.typ.is_signed:\n            op = \"sdiv\"\n\n        ret = [op, a, b]\n\n        if a.typ.bits < 256:\n            # wrap for ops which could under/overflow\n            if a.typ.is_signed:\n                # e.g. int128 -> (signextend 15 (add x y))\n                ret = promote_signed_int(ret, a.typ.bits)\n            else:\n                # e.g. uint8 -> (mod (add x y) 256)\n                # TODO mod_bound could be a really large literal\n                ret = [\"mod\", ret, 2**a.typ.bits]\n\n        return IRnode.from_list(ret, typ=otyp)\n\n        # TODO handle decimal case\n\n\nclass UnsafeAdd(_UnsafeMath):\n    op = \"add\"\n\n\nclass UnsafeSub(_UnsafeMath):\n    op = \"sub\"\n\n\nclass UnsafeMul(_UnsafeMath):\n    op = \"mul\"\n\n\nclass UnsafeDiv(_UnsafeMath):\n    op = \"div\"\n\n\nclass _MinMax(BuiltinFunction):\n    _inputs = [(\"a\", (DecimalT(), IntegerT.any())), (\"b\", (DecimalT(), IntegerT.any()))]\n\n    def evaluate(self, node):\n        validate_call_args(node, 2)\n        if not isinstance(node.args[0], type(node.args[1])):\n            raise UnfoldableNode\n        if not isinstance(node.args[0], (vy_ast.Decimal, vy_ast.Int)):\n            raise UnfoldableNode\n\n        left, right = (i.value for i in node.args)\n        if isinstance(left, Decimal) and (\n            min(left, right) < SizeLimits.MIN_AST_DECIMAL\n            or max(left, right) > SizeLimits.MAX_AST_DECIMAL\n        ):\n            raise InvalidType(\"Decimal value is outside of allowable range\", node)\n\n        types_list = get_common_types(\n            *node.args, filter_fn=lambda x: isinstance(x, (IntegerT, DecimalT))\n        )\n        if not types_list:\n            raise TypeMismatch(\"Cannot perform action between dislike numeric types\", node)\n\n        value = self._eval_fn(left, right)\n        return type(node.args[0]).from_node(node, value=value)\n\n    def fetch_call_return(self, node):\n        return_type = self.infer_arg_types(node).pop()\n        return return_type\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n\n        types_list = get_common_types(\n            *node.args, filter_fn=lambda x: isinstance(x, (IntegerT, DecimalT))\n        )\n        if not types_list:\n            raise TypeMismatch(\"Cannot perform action between dislike numeric types\", node)\n\n        type_ = types_list.pop()\n        return [type_, type_]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        op = self._opcode\n\n        with args[0].cache_when_complex(\"_l\") as (b1, left), args[1].cache_when_complex(\"_r\") as (\n            b2,\n            right,\n        ):\n            if left.typ == right.typ:\n                if left.typ != UINT256_T:\n                    # if comparing like types that are not uint256, use SLT or SGT\n                    op = f\"s{op}\"\n                o = [\"select\", [op, left, right], left, right]\n                otyp = left.typ\n\n            else:\n                raise TypeMismatch(f\"Minmax types incompatible: {left.typ.typ} {right.typ.typ}\")\n            return IRnode.from_list(b1.resolve(b2.resolve(o)), typ=otyp)\n\n\nclass Min(_MinMax):\n    _id = \"min\"\n    _eval_fn = min\n    _opcode = \"lt\"\n\n\nclass Max(_MinMax):\n    _id = \"max\"\n    _eval_fn = max\n    _opcode = \"gt\"\n\n\nclass Uint2Str(BuiltinFunction):\n    _id = \"uint2str\"\n    _inputs = [(\"x\", IntegerT.unsigneds())]\n\n    def fetch_call_return(self, node):\n        arg_t = self.infer_arg_types(node)[0]\n        bits = arg_t.bits\n        len_needed = math.ceil(bits * math.log(2) / math.log(10))\n        return StringT(len_needed)\n\n    def evaluate(self, node):\n        validate_call_args(node, 1)\n        if not isinstance(node.args[0], vy_ast.Int):\n            raise UnfoldableNode\n\n        value = str(node.args[0].value)\n        return vy_ast.Str.from_node(node, value=value)\n\n    def infer_arg_types(self, node):\n        self._validate_arg_types(node)\n        input_type = get_possible_types_from_node(node.args[0]).pop()\n        return [input_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return_t = self.fetch_call_return(expr)\n        n_digits = return_t.maxlen\n\n        with args[0].cache_when_complex(\"val\") as (b1, val):\n            buf = context.new_internal_variable(return_t)\n\n            i = IRnode.from_list(context.fresh_varname(\"uint2str_i\"), typ=UINT256_T)\n\n            ret = [\"repeat\", i, 0, n_digits + 1, n_digits + 1]\n\n            body = [\n                \"seq\",\n                [\n                    \"if\",\n                    [\"eq\", val, 0],\n                    # clobber val, and return it as a pointer\n                    [\n                        \"seq\",\n                        [\"mstore\", [\"sub\", buf + n_digits, i], i],\n                        [\"set\", val, [\"sub\", buf + n_digits, i]],\n                        \"break\",\n                    ],\n                    [\n                        \"seq\",\n                        [\"mstore\", [\"sub\", buf + n_digits, i], [\"add\", 48, [\"mod\", val, 10]]],\n                        [\"set\", val, [\"div\", val, 10]],\n                    ],\n                ],\n            ]\n            ret.append(body)\n\n            # \"0\" has hex representation 0x00..0130..00\n            # if (val == 0) {\n            #   return \"0\"\n            # } else {\n            #   do the loop\n            # }\n            ret = [\n                \"if\",\n                [\"eq\", val, 0],\n                [\"seq\", [\"mstore\", buf + 1, ord(\"0\")], [\"mstore\", buf, 1], buf],\n                [\"seq\", ret, val],\n            ]\n\n            return b1.resolve(IRnode.from_list(ret, location=MEMORY, typ=return_t))\n\n\nclass Sqrt(BuiltinFunction):\n    _id = \"sqrt\"\n    _inputs = [(\"d\", DecimalT())]\n    _return_type = DecimalT()\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        # TODO fix cyclic dependency with codegen/stmt.py\n        from ._utils import generate_inline_function\n\n        arg = args[0]\n        # TODO: reify decimal and integer sqrt paths (see isqrt)\n        sqrt_code = \"\"\"\nassert x >= 0.0\nz: decimal = 0.0\n\nif x == 0.0:\n    z = 0.0\nelse:\n    z = x / 2.0 + 0.5\n    y: decimal = x\n\n    for i in range(256):\n        if z == y:\n            break\n        y = z\n        z = (x / z + z) / 2.0\n        \"\"\"\n\n        x_type = DecimalT()\n        placeholder_copy = [\"pass\"]\n        # Steal current position if variable is already allocated.\n        if arg.value == \"mload\":\n            new_var_pos = arg.args[0]\n        # Other locations need to be copied.\n        else:\n            new_var_pos = context.new_internal_variable(x_type)\n            placeholder_copy = [\"mstore\", new_var_pos, arg]\n        # Create input variables.\n        variables = {\"x\": VariableRecord(name=\"x\", pos=new_var_pos, typ=x_type, mutable=False)}\n        # Dictionary to update new (i.e. typecheck) namespace\n        variables_2 = {\"x\": VarInfo(DecimalT())}\n        # Generate inline IR.\n        new_ctx, sqrt_ir = generate_inline_function(\n            code=sqrt_code,\n            variables=variables,\n            variables_2=variables_2,\n            memory_allocator=context.memory_allocator,\n        )\n        return IRnode.from_list(\n            [\"seq\", placeholder_copy, sqrt_ir, new_ctx.vars[\"z\"].pos],  # load x variable\n            typ=DecimalT(),\n            location=MEMORY,\n        )\n\n\nclass ISqrt(BuiltinFunction):\n    _id = \"isqrt\"\n    _inputs = [(\"d\", UINT256_T)]\n    _return_type = UINT256_T\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        # calculate isqrt using the babylonian method\n\n        y, z = \"y\", \"z\"\n        arg = args[0]\n        with arg.cache_when_complex(\"x\") as (b1, x):\n            ret = [\n                \"seq\",\n                [\n                    \"if\",\n                    [\"ge\", y, 2 ** (128 + 8)],\n                    [\"seq\", [\"set\", y, shr(128, y)], [\"set\", z, shl(64, z)]],\n                ],\n                [\n                    \"if\",\n                    [\"ge\", y, 2 ** (64 + 8)],\n                    [\"seq\", [\"set\", y, shr(64, y)], [\"set\", z, shl(32, z)]],\n                ],\n                [\n                    \"if\",\n                    [\"ge\", y, 2 ** (32 + 8)],\n                    [\"seq\", [\"set\", y, shr(32, y)], [\"set\", z, shl(16, z)]],\n                ],\n                [\n                    \"if\",\n                    [\"ge\", y, 2 ** (16 + 8)],\n                    [\"seq\", [\"set\", y, shr(16, y)], [\"set\", z, shl(8, z)]],\n                ],\n            ]\n            ret.append([\"set\", z, [\"div\", [\"mul\", z, [\"add\", y, 2**16]], 2**18]])\n\n            for _ in range(7):\n                ret.append([\"set\", z, [\"div\", [\"add\", [\"div\", x, z], z], 2]])\n\n            # note: If ``x+1`` is a perfect square, then the Babylonian\n            # algorithm oscillates between floor(sqrt(x)) and ceil(sqrt(x)) in\n            # consecutive iterations. return the floor value always.\n\n            ret.append([\"with\", \"t\", [\"div\", x, z], [\"select\", [\"lt\", z, \"t\"], z, \"t\"]])\n\n            ret = [\"with\", y, x, [\"with\", z, 181, ret]]\n            return b1.resolve(IRnode.from_list(ret, typ=UINT256_T))\n\n\nclass Empty(TypenameFoldedFunction):\n    _id = \"empty\"\n\n    def fetch_call_return(self, node):\n        type_ = self.infer_arg_types(node)[0].typedef\n        if isinstance(type_, HashMapT):\n            raise TypeMismatch(\"Cannot use empty on HashMap\", node)\n        return type_\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        output_type = args[0]\n        return IRnode(\"~empty\", typ=output_type)\n\n\nclass Breakpoint(BuiltinFunction):\n    _id = \"breakpoint\"\n    _inputs: list = []\n\n    _warned = False\n\n    def fetch_call_return(self, node):\n        if not self._warned:\n            vyper_warn(\"`breakpoint` should only be used for debugging!\\n\" + node._annotated_source)\n            self._warned = True\n\n        return None\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list(\"breakpoint\", annotation=\"breakpoint()\")\n\n\nclass Print(BuiltinFunction):\n    _id = \"print\"\n    _inputs: list = []\n    _has_varargs = True\n    _kwargs = {\"hardhat_compat\": KwargSettings(BoolT(), False, require_literal=True)}\n\n    _warned = False\n\n    def fetch_call_return(self, node):\n        if not self._warned:\n            vyper_warn(\"`print` should only be used for debugging!\\n\" + node._annotated_source)\n            self._warned = True\n\n        return None\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        args_as_tuple = ir_tuple_from_args(args)\n        args_abi_t = args_as_tuple.typ.abi_type\n\n        # create a signature like \"log(uint256)\"\n        sig = \"log\" + \"(\" + \",\".join([arg.typ.abi_type.selector_name() for arg in args]) + \")\"\n\n        if kwargs[\"hardhat_compat\"] is True:\n            method_id = method_id_int(sig)\n            buflen = 32 + args_abi_t.size_bound()\n\n            # 32 bytes extra space for the method id\n            buf = context.new_internal_variable(get_type_for_exact_size(buflen))\n\n            ret = [\"seq\"]\n            ret.append([\"mstore\", buf, method_id])\n            encode = abi_encode(buf + 32, args_as_tuple, context, buflen, returns_len=True)\n\n        else:\n            method_id = method_id_int(\"log(string,bytes)\")\n            schema = args_abi_t.selector_name().encode(\"utf-8\")\n            if len(schema) > 32:\n                raise CompilerPanic(\"print signature too long: {schema}\")\n\n            schema_t = StringT(len(schema))\n            schema_buf = context.new_internal_variable(schema_t)\n            ret = [\"seq\"]\n            ret.append([\"mstore\", schema_buf, len(schema)])\n\n            # TODO use Expr.make_bytelike, or better have a `bytestring` IRnode type\n            ret.append([\"mstore\", schema_buf + 32, bytes_to_int(schema.ljust(32, b\"\\x00\"))])\n\n            payload_buflen = args_abi_t.size_bound()\n            payload_t = BytesT(payload_buflen)\n\n            # 32 bytes extra space for the method id\n            payload_buf = context.new_internal_variable(payload_t)\n            encode_payload = abi_encode(\n                payload_buf + 32, args_as_tuple, context, payload_buflen, returns_len=True\n            )\n\n            ret.append([\"mstore\", payload_buf, encode_payload])\n            args_as_tuple = ir_tuple_from_args(\n                [\n                    IRnode.from_list(schema_buf, typ=schema_t, location=MEMORY),\n                    IRnode.from_list(payload_buf, typ=payload_t, location=MEMORY),\n                ]\n            )\n\n            # add 32 for method id padding\n            buflen = 32 + args_as_tuple.typ.abi_type.size_bound()\n            buf = context.new_internal_variable(get_type_for_exact_size(buflen))\n            ret.append([\"mstore\", buf, method_id])\n            encode = abi_encode(buf + 32, args_as_tuple, context, buflen, returns_len=True)\n\n        # debug address that tooling uses\n        CONSOLE_ADDRESS = 0x000000000000000000636F6E736F6C652E6C6F67\n        ret.append([\"staticcall\", \"gas\", CONSOLE_ADDRESS, buf + 28, [\"add\", 4, encode], 0, 0])\n\n        return IRnode.from_list(ret, annotation=\"print:\" + sig)\n\n\nclass ABIEncode(BuiltinFunction):\n    _id = \"_abi_encode\"  # TODO prettier to rename this to abi.encode\n    # signature: *, ensure_tuple=<literal_bool> -> Bytes[<calculated len>]\n    # (check the signature manually since we have no utility methods\n    # to handle varargs.)\n    # explanation of ensure_tuple:\n    # default is to force even a single value into a tuple,\n    # e.g. _abi_encode(bytes) -> _abi_encode((bytes,))\n    #      _abi_encode((bytes,)) -> _abi_encode(((bytes,),))\n    # this follows the encoding convention for functions:\n    # ://docs.soliditylang.org/en/v0.8.6/abi-spec.html#function-selector-and-argument-encoding\n    # if this is turned off, then bytes will be encoded as bytes.\n\n    _inputs: list = []\n    _has_varargs = True\n\n    _kwargs = {\n        \"ensure_tuple\": KwargSettings(BoolT(), True, require_literal=True),\n        \"method_id\": KwargSettings((BYTES4_T, BytesT(4)), None, require_literal=True),\n    }\n\n    def infer_kwarg_types(self, node):\n        ret = {}\n        for kwarg in node.keywords:\n            kwarg_name = kwarg.arg\n            validate_expected_type(kwarg.value, self._kwargs[kwarg_name].typ)\n            ret[kwarg_name] = get_exact_type_from_node(kwarg.value)\n        return ret\n\n    def fetch_call_return(self, node):\n        self._validate_arg_types(node)\n        ensure_tuple = next(\n            (arg.value.value for arg in node.keywords if arg.arg == \"ensure_tuple\"), True\n        )\n        assert isinstance(ensure_tuple, bool)\n        has_method_id = \"method_id\" in [arg.arg for arg in node.keywords]\n\n        # figure out the output type by converting\n        # the types to ABI_Types and calling size_bound API\n        arg_abi_types = []\n        arg_types = self.infer_arg_types(node)\n        for arg_t in arg_types:\n            arg_abi_types.append(arg_t.abi_type)\n\n        # special case, no tuple\n        if len(arg_abi_types) == 1 and not ensure_tuple:\n            arg_abi_t = arg_abi_types[0]\n        else:\n            arg_abi_t = ABI_Tuple(arg_abi_types)\n\n        maxlen = arg_abi_t.size_bound()\n\n        if has_method_id:\n            # the output includes 4 bytes for the method_id.\n            maxlen += 4\n\n        ret = BytesT()\n        ret.set_length(maxlen)\n        return ret\n\n    @staticmethod\n    def _parse_method_id(method_id_literal):\n        if method_id_literal is None:\n            return None\n        if isinstance(method_id_literal, bytes):\n            assert len(method_id_literal) == 4\n            return fourbytes_to_int(method_id_literal)\n        if method_id_literal.startswith(\"0x\"):\n            method_id_literal = method_id_literal[2:]\n        return fourbytes_to_int(bytes.fromhex(method_id_literal))\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        ensure_tuple = kwargs[\"ensure_tuple\"]\n        method_id = self._parse_method_id(kwargs[\"method_id\"])\n\n        if len(args) < 1:\n            raise StructureException(\"abi_encode expects at least one argument\", expr)\n\n        # figure out the required length for the output buffer\n        if len(args) == 1 and not ensure_tuple:\n            # special case, no tuple\n            encode_input = args[0]\n        else:\n            encode_input = ir_tuple_from_args(args)\n\n        input_abi_t = encode_input.typ.abi_type\n        maxlen = input_abi_t.size_bound()\n        if method_id is not None:\n            maxlen += 4\n\n        buf_t = BytesT(maxlen)\n        assert self.fetch_call_return(expr).length == maxlen\n        buf = context.new_internal_variable(buf_t)\n\n        ret = [\"seq\"]\n        if method_id is not None:\n            # <32 bytes length> | <4 bytes method_id> | <everything else>\n            # write the unaligned method_id first, then we will\n            # overwrite the 28 bytes of zeros with the bytestring length\n            ret += [[\"mstore\", buf + 4, method_id]]\n            # abi encode, and grab length as stack item\n            length = abi_encode(buf + 36, encode_input, context, returns_len=True, bufsz=maxlen)\n            # write the output length to where bytestring stores its length\n            ret += [[\"mstore\", buf, [\"add\", length, 4]]]\n\n        else:\n            # abi encode and grab length as stack item\n            length = abi_encode(buf + 32, encode_input, context, returns_len=True, bufsz=maxlen)\n            # write the output length to where bytestring stores its length\n            ret += [[\"mstore\", buf, length]]\n\n        # return the buf location\n        # TODO location is statically known, optimize this out\n        ret += [buf]\n\n        return IRnode.from_list(ret, location=MEMORY, typ=buf_t)\n\n\nclass ABIDecode(BuiltinFunction):\n    _id = \"_abi_decode\"\n    _inputs = [(\"data\", BytesT.any()), (\"output_type\", \"TYPE_DEFINITION\")]\n    _kwargs = {\"unwrap_tuple\": KwargSettings(BoolT(), True, require_literal=True)}\n\n    def fetch_call_return(self, node):\n        _, output_type = self.infer_arg_types(node)\n        return output_type.typedef\n\n    def infer_arg_types(self, node):\n        validate_call_args(node, 2, [\"unwrap_tuple\"])\n\n        data_type = get_exact_type_from_node(node.args[0])\n        output_typedef = TYPE_T(type_from_annotation(node.args[1]))\n\n        return [data_type, output_typedef]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        unwrap_tuple = kwargs[\"unwrap_tuple\"]\n\n        data = args[0]\n        output_typ = args[1]\n        wrapped_typ = output_typ\n\n        if unwrap_tuple is True:\n            wrapped_typ = calculate_type_for_external_return(output_typ)\n\n        abi_size_bound = wrapped_typ.abi_type.size_bound()\n        abi_min_size = wrapped_typ.abi_type.min_size()\n\n        # Get the size of data\n        input_max_len = data.typ.maxlen\n\n        assert abi_min_size <= abi_size_bound, \"bad abi type\"\n        if input_max_len < abi_size_bound:\n            raise StructureException(\n                (\n                    \"Mismatch between size of input and size of decoded types. \"\n                    f\"length of ABI-encoded {wrapped_typ} must be equal to or greater \"\n                    f\"than {abi_size_bound}\"\n                ),\n                expr.args[0],\n            )\n\n        data = ensure_in_memory(data, context)\n        with data.cache_when_complex(\"to_decode\") as (b1, data):\n            data_ptr = bytes_data_ptr(data)\n            data_len = get_bytearray_length(data)\n\n            # Normally, ABI-encoded data assumes the argument is a tuple\n            # (See comments for `wrap_value_for_external_return`)\n            # However, we do not want to use `wrap_value_for_external_return`\n            # technique as used in external call codegen because in order to be\n            # type-safe we would need an extra memory copy. To avoid a copy,\n            # we manually add the ABI-dynamic offset so that it is\n            # re-interpreted in-place.\n            if (\n                unwrap_tuple is True\n                and needs_external_call_wrap(output_typ)\n                and output_typ.abi_type.is_dynamic()\n            ):\n                data_ptr = add_ofst(data_ptr, 32)\n\n            ret = [\"seq\"]\n\n            if abi_min_size == abi_size_bound:\n                ret.append([\"assert\", [\"eq\", abi_min_size, data_len]])\n            else:\n                # runtime assert: abi_min_size <= data_len <= abi_size_bound\n                ret.append(clamp2(abi_min_size, data_len, abi_size_bound, signed=False))\n\n            # return pointer to the buffer\n            ret.append(data_ptr)\n\n            return b1.resolve(\n                IRnode.from_list(\n                    ret,\n                    typ=output_typ,\n                    location=data.location,\n                    encoding=Encoding.ABI,\n                    annotation=f\"abi_decode({output_typ})\",\n                )\n            )\n\n\nclass _MinMaxValue(TypenameFoldedFunction):\n    def evaluate(self, node):\n        self._validate_arg_types(node)\n        input_type = type_from_annotation(node.args[0])\n\n        if not isinstance(input_type, (IntegerT, DecimalT)):\n            raise InvalidType(f\"Expected numeric type but got {input_type} instead\", node)\n\n        val = self._eval(input_type)\n\n        if isinstance(input_type, DecimalT):\n            ret = vy_ast.Decimal.from_node(node, value=val)\n\n        if isinstance(input_type, IntegerT):\n            ret = vy_ast.Int.from_node(node, value=val)\n\n        # TODO: to change to known_type once #3213 is merged\n        ret._metadata[\"type\"] = input_type\n        return ret\n\n\nclass MinValue(_MinMaxValue):\n    _id = \"min_value\"\n\n    def _eval(self, type_):\n        return type_.ast_bounds[0]\n\n\nclass MaxValue(_MinMaxValue):\n    _id = \"max_value\"\n\n    def _eval(self, type_):\n        return type_.ast_bounds[1]\n\n\nclass Epsilon(TypenameFoldedFunction):\n    _id = \"epsilon\"\n\n    def evaluate(self, node):\n        self._validate_arg_types(node)\n        input_type = type_from_annotation(node.args[0])\n\n        if not input_type.compare_type(DecimalT()):\n            raise InvalidType(f\"Expected decimal type but got {input_type} instead\", node)\n\n        return vy_ast.Decimal.from_node(node, value=input_type.epsilon)\n\n\nDISPATCH_TABLE = {\n    \"_abi_encode\": ABIEncode(),\n    \"_abi_decode\": ABIDecode(),\n    \"floor\": Floor(),\n    \"ceil\": Ceil(),\n    \"convert\": Convert(),\n    \"slice\": Slice(),\n    \"len\": Len(),\n    \"concat\": Concat(),\n    \"sha256\": Sha256(),\n    \"method_id\": MethodID(),\n    \"keccak256\": Keccak256(),\n    \"ecrecover\": ECRecover(),\n    \"ecadd\": ECAdd(),\n    \"ecmul\": ECMul(),\n    \"extract32\": Extract32(),\n    \"as_wei_value\": AsWeiValue(),\n    \"raw_call\": RawCall(),\n    \"blockhash\": BlockHash(),\n    \"bitwise_and\": BitwiseAnd(),\n    \"bitwise_or\": BitwiseOr(),\n    \"bitwise_xor\": BitwiseXor(),\n    \"bitwise_not\": BitwiseNot(),\n    \"uint256_addmod\": AddMod(),\n    \"uint256_mulmod\": MulMod(),\n    \"unsafe_add\": UnsafeAdd(),\n    \"unsafe_sub\": UnsafeSub(),\n    \"unsafe_mul\": UnsafeMul(),\n    \"unsafe_div\": UnsafeDiv(),\n    \"pow_mod256\": PowMod256(),\n    \"uint2str\": Uint2Str(),\n    \"isqrt\": ISqrt(),\n    \"sqrt\": Sqrt(),\n    \"shift\": Shift(),\n    \"create_minimal_proxy_to\": CreateMinimalProxyTo(),\n    \"create_forwarder_to\": CreateForwarderTo(),\n    \"create_copy_of\": CreateCopyOf(),\n    \"create_from_blueprint\": CreateFromBlueprint(),\n    \"min\": Min(),\n    \"max\": Max(),\n    \"empty\": Empty(),\n    \"abs\": Abs(),\n    \"min_value\": MinValue(),\n    \"max_value\": MaxValue(),\n    \"epsilon\": Epsilon(),\n}\n\nSTMT_DISPATCH_TABLE = {\n    \"send\": Send(),\n    \"print\": Print(),\n    \"breakpoint\": Breakpoint(),\n    \"selfdestruct\": SelfDestruct(),\n    \"raw_call\": RawCall(),\n    \"raw_log\": RawLog(),\n    \"raw_revert\": RawRevert(),\n    \"create_minimal_proxy_to\": CreateMinimalProxyTo(),\n    \"create_forwarder_to\": CreateForwarderTo(),\n    \"create_copy_of\": CreateCopyOf(),\n    \"create_from_blueprint\": CreateFromBlueprint(),\n}\n\nBUILTIN_FUNCTIONS = {**STMT_DISPATCH_TABLE, **DISPATCH_TABLE}.keys()\n\n\ndef get_builtin_functions():\n    return {**STMT_DISPATCH_TABLE, **DISPATCH_TABLE}\n"], "filenames": ["tests/parser/functions/test_raw_call.py", "vyper/builtins/functions.py"], "buggy_code_start_loc": [298, 1190], "buggy_code_end_loc": [345, 1211], "fixing_code_start_loc": [299, 1191], "fixing_code_end_loc": [364, 1219], "type": "CWE-670", "message": "Vyper is a Pythonic Smart Contract Language for the ethereum virtual machine. In versions 0.3.1 through 0.3.7, the Vyper compiler generates the wrong bytecode. Any contract that uses the `raw_call` with `revert_on_failure=False` and `max_outsize=0` receives the wrong response from `raw_call`. Depending on the memory garbage, the result can be either `True` or `False`. A patch is available and, as of time of publication, anticipated to be part of Vyper 0.3.8. As a workaround, one may always put  `max_outsize>0`.", "other": {"cve": {"id": "CVE-2023-30629", "sourceIdentifier": "security-advisories@github.com", "published": "2023-04-24T22:15:10.030", "lastModified": "2023-05-04T18:22:10.567", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Vyper is a Pythonic Smart Contract Language for the ethereum virtual machine. In versions 0.3.1 through 0.3.7, the Vyper compiler generates the wrong bytecode. Any contract that uses the `raw_call` with `revert_on_failure=False` and `max_outsize=0` receives the wrong response from `raw_call`. Depending on the memory garbage, the result can be either `True` or `False`. A patch is available and, as of time of publication, anticipated to be part of Vyper 0.3.8. As a workaround, one may always put  `max_outsize>0`."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:H/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "HIGH", "availabilityImpact": "NONE", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:H/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "HIGH", "availabilityImpact": "NONE", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-670"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:vyper_project:vyper:*:*:*:*:*:*:*:*", "versionStartIncluding": "0.3.1", "versionEndExcluding": "0.3.8", "matchCriteriaId": "AAB49684-EB30-49CD-9385-AD790BEB56F9"}]}]}], "references": [{"url": "https://docs.vyperlang.org/en/v0.3.7/built-in-functions.html#raw_call", "source": "security-advisories@github.com", "tags": ["Product"]}, {"url": "https://github.com/lidofinance/gate-seals/blob/051593e74df01a4131c485b4fda52e691cd4b7d8/contracts/GateSeal.vy#L164", "source": "security-advisories@github.com", "tags": ["Product"]}, {"url": "https://github.com/lidofinance/gate-seals/pull/5/files", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/vyperlang/vyper/commit/851f7a1b3aa2a36fd041e3d0ed38f9355a58c8ae", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/vyperlang/vyper/security/advisories/GHSA-w9g2-3w7p-72g9", "source": "security-advisories@github.com", "tags": ["Exploit", "Vendor Advisory"]}]}, "github_commit_url": "https://github.com/vyperlang/vyper/commit/851f7a1b3aa2a36fd041e3d0ed38f9355a58c8ae"}}
{"buggy_code": ["/*\n * Cryptographic API.\n *\n * HMAC: Keyed-Hashing for Message Authentication (RFC2104).\n *\n * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>\n * Copyright (c) 2006 Herbert Xu <herbert@gondor.apana.org.au>\n *\n * The HMAC implementation is derived from USAGI.\n * Copyright (c) 2002 Kazunori Miyazawa <miyazawa@linux-ipv6.org> / USAGI\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#include <crypto/hmac.h>\n#include <crypto/internal/hash.h>\n#include <crypto/scatterwalk.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/scatterlist.h>\n#include <linux/string.h>\n\nstruct hmac_ctx {\n\tstruct crypto_shash *hash;\n};\n\nstatic inline void *align_ptr(void *p, unsigned int align)\n{\n\treturn (void *)ALIGN((unsigned long)p, align);\n}\n\nstatic inline struct hmac_ctx *hmac_ctx(struct crypto_shash *tfm)\n{\n\treturn align_ptr(crypto_shash_ctx_aligned(tfm) +\n\t\t\t crypto_shash_statesize(tfm) * 2,\n\t\t\t crypto_tfm_ctx_alignment());\n}\n\nstatic int hmac_setkey(struct crypto_shash *parent,\n\t\t       const u8 *inkey, unsigned int keylen)\n{\n\tint bs = crypto_shash_blocksize(parent);\n\tint ds = crypto_shash_digestsize(parent);\n\tint ss = crypto_shash_statesize(parent);\n\tchar *ipad = crypto_shash_ctx_aligned(parent);\n\tchar *opad = ipad + ss;\n\tstruct hmac_ctx *ctx = align_ptr(opad + ss,\n\t\t\t\t\t crypto_tfm_ctx_alignment());\n\tstruct crypto_shash *hash = ctx->hash;\n\tSHASH_DESC_ON_STACK(shash, hash);\n\tunsigned int i;\n\n\tshash->tfm = hash;\n\tshash->flags = crypto_shash_get_flags(parent)\n\t\t& CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tif (keylen > bs) {\n\t\tint err;\n\n\t\terr = crypto_shash_digest(shash, inkey, keylen, ipad);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tkeylen = ds;\n\t} else\n\t\tmemcpy(ipad, inkey, keylen);\n\n\tmemset(ipad + keylen, 0, bs - keylen);\n\tmemcpy(opad, ipad, bs);\n\n\tfor (i = 0; i < bs; i++) {\n\t\tipad[i] ^= HMAC_IPAD_VALUE;\n\t\topad[i] ^= HMAC_OPAD_VALUE;\n\t}\n\n\treturn crypto_shash_init(shash) ?:\n\t       crypto_shash_update(shash, ipad, bs) ?:\n\t       crypto_shash_export(shash, ipad) ?:\n\t       crypto_shash_init(shash) ?:\n\t       crypto_shash_update(shash, opad, bs) ?:\n\t       crypto_shash_export(shash, opad);\n}\n\nstatic int hmac_export(struct shash_desc *pdesc, void *out)\n{\n\tstruct shash_desc *desc = shash_desc_ctx(pdesc);\n\n\tdesc->flags = pdesc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\treturn crypto_shash_export(desc, out);\n}\n\nstatic int hmac_import(struct shash_desc *pdesc, const void *in)\n{\n\tstruct shash_desc *desc = shash_desc_ctx(pdesc);\n\tstruct hmac_ctx *ctx = hmac_ctx(pdesc->tfm);\n\n\tdesc->tfm = ctx->hash;\n\tdesc->flags = pdesc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\treturn crypto_shash_import(desc, in);\n}\n\nstatic int hmac_init(struct shash_desc *pdesc)\n{\n\treturn hmac_import(pdesc, crypto_shash_ctx_aligned(pdesc->tfm));\n}\n\nstatic int hmac_update(struct shash_desc *pdesc,\n\t\t       const u8 *data, unsigned int nbytes)\n{\n\tstruct shash_desc *desc = shash_desc_ctx(pdesc);\n\n\tdesc->flags = pdesc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\treturn crypto_shash_update(desc, data, nbytes);\n}\n\nstatic int hmac_final(struct shash_desc *pdesc, u8 *out)\n{\n\tstruct crypto_shash *parent = pdesc->tfm;\n\tint ds = crypto_shash_digestsize(parent);\n\tint ss = crypto_shash_statesize(parent);\n\tchar *opad = crypto_shash_ctx_aligned(parent) + ss;\n\tstruct shash_desc *desc = shash_desc_ctx(pdesc);\n\n\tdesc->flags = pdesc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\treturn crypto_shash_final(desc, out) ?:\n\t       crypto_shash_import(desc, opad) ?:\n\t       crypto_shash_finup(desc, out, ds, out);\n}\n\nstatic int hmac_finup(struct shash_desc *pdesc, const u8 *data,\n\t\t      unsigned int nbytes, u8 *out)\n{\n\n\tstruct crypto_shash *parent = pdesc->tfm;\n\tint ds = crypto_shash_digestsize(parent);\n\tint ss = crypto_shash_statesize(parent);\n\tchar *opad = crypto_shash_ctx_aligned(parent) + ss;\n\tstruct shash_desc *desc = shash_desc_ctx(pdesc);\n\n\tdesc->flags = pdesc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\treturn crypto_shash_finup(desc, data, nbytes, out) ?:\n\t       crypto_shash_import(desc, opad) ?:\n\t       crypto_shash_finup(desc, out, ds, out);\n}\n\nstatic int hmac_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_shash *parent = __crypto_shash_cast(tfm);\n\tstruct crypto_shash *hash;\n\tstruct crypto_instance *inst = (void *)tfm->__crt_alg;\n\tstruct crypto_shash_spawn *spawn = crypto_instance_ctx(inst);\n\tstruct hmac_ctx *ctx = hmac_ctx(parent);\n\n\thash = crypto_spawn_shash(spawn);\n\tif (IS_ERR(hash))\n\t\treturn PTR_ERR(hash);\n\n\tparent->descsize = sizeof(struct shash_desc) +\n\t\t\t   crypto_shash_descsize(hash);\n\n\tctx->hash = hash;\n\treturn 0;\n}\n\nstatic void hmac_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct hmac_ctx *ctx = hmac_ctx(__crypto_shash_cast(tfm));\n\tcrypto_free_shash(ctx->hash);\n}\n\nstatic int hmac_create(struct crypto_template *tmpl, struct rtattr **tb)\n{\n\tstruct shash_instance *inst;\n\tstruct crypto_alg *alg;\n\tstruct shash_alg *salg;\n\tint err;\n\tint ds;\n\tint ss;\n\n\terr = crypto_check_attr_type(tb, CRYPTO_ALG_TYPE_SHASH);\n\tif (err)\n\t\treturn err;\n\n\tsalg = shash_attr_alg(tb[1], 0, 0);\n\tif (IS_ERR(salg))\n\t\treturn PTR_ERR(salg);\n\n\terr = -EINVAL;\n\tds = salg->digestsize;\n\tss = salg->statesize;\n\talg = &salg->base;\n\tif (ds > alg->cra_blocksize ||\n\t    ss < alg->cra_blocksize)\n\t\tgoto out_put_alg;\n\n\tinst = shash_alloc_instance(\"hmac\", alg);\n\terr = PTR_ERR(inst);\n\tif (IS_ERR(inst))\n\t\tgoto out_put_alg;\n\n\terr = crypto_init_shash_spawn(shash_instance_ctx(inst), salg,\n\t\t\t\t      shash_crypto_instance(inst));\n\tif (err)\n\t\tgoto out_free_inst;\n\n\tinst->alg.base.cra_priority = alg->cra_priority;\n\tinst->alg.base.cra_blocksize = alg->cra_blocksize;\n\tinst->alg.base.cra_alignmask = alg->cra_alignmask;\n\n\tss = ALIGN(ss, alg->cra_alignmask + 1);\n\tinst->alg.digestsize = ds;\n\tinst->alg.statesize = ss;\n\n\tinst->alg.base.cra_ctxsize = sizeof(struct hmac_ctx) +\n\t\t\t\t     ALIGN(ss * 2, crypto_tfm_ctx_alignment());\n\n\tinst->alg.base.cra_init = hmac_init_tfm;\n\tinst->alg.base.cra_exit = hmac_exit_tfm;\n\n\tinst->alg.init = hmac_init;\n\tinst->alg.update = hmac_update;\n\tinst->alg.final = hmac_final;\n\tinst->alg.finup = hmac_finup;\n\tinst->alg.export = hmac_export;\n\tinst->alg.import = hmac_import;\n\tinst->alg.setkey = hmac_setkey;\n\n\terr = shash_register_instance(tmpl, inst);\n\tif (err) {\nout_free_inst:\n\t\tshash_free_instance(shash_crypto_instance(inst));\n\t}\n\nout_put_alg:\n\tcrypto_mod_put(alg);\n\treturn err;\n}\n\nstatic struct crypto_template hmac_tmpl = {\n\t.name = \"hmac\",\n\t.create = hmac_create,\n\t.free = shash_free_instance,\n\t.module = THIS_MODULE,\n};\n\nstatic int __init hmac_module_init(void)\n{\n\treturn crypto_register_template(&hmac_tmpl);\n}\n\nstatic void __exit hmac_module_exit(void)\n{\n\tcrypto_unregister_template(&hmac_tmpl);\n}\n\nmodule_init(hmac_module_init);\nmodule_exit(hmac_module_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"HMAC hash algorithm\");\nMODULE_ALIAS_CRYPTO(\"hmac\");\n", "/*\n * Synchronous Cryptographic Hash operations.\n *\n * Copyright (c) 2008 Herbert Xu <herbert@gondor.apana.org.au>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#include <crypto/scatterwalk.h>\n#include <crypto/internal/hash.h>\n#include <linux/err.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/slab.h>\n#include <linux/seq_file.h>\n#include <linux/cryptouser.h>\n#include <net/netlink.h>\n#include <linux/compiler.h>\n\n#include \"internal.h\"\n\nstatic const struct crypto_type crypto_shash_type;\n\nstatic int shash_no_setkey(struct crypto_shash *tfm, const u8 *key,\n\t\t\t   unsigned int keylen)\n{\n\treturn -ENOSYS;\n}\n\nstatic int shash_setkey_unaligned(struct crypto_shash *tfm, const u8 *key,\n\t\t\t\t  unsigned int keylen)\n{\n\tstruct shash_alg *shash = crypto_shash_alg(tfm);\n\tunsigned long alignmask = crypto_shash_alignmask(tfm);\n\tunsigned long absize;\n\tu8 *buffer, *alignbuffer;\n\tint err;\n\n\tabsize = keylen + (alignmask & ~(crypto_tfm_ctx_alignment() - 1));\n\tbuffer = kmalloc(absize, GFP_ATOMIC);\n\tif (!buffer)\n\t\treturn -ENOMEM;\n\n\talignbuffer = (u8 *)ALIGN((unsigned long)buffer, alignmask + 1);\n\tmemcpy(alignbuffer, key, keylen);\n\terr = shash->setkey(tfm, alignbuffer, keylen);\n\tkzfree(buffer);\n\treturn err;\n}\n\nint crypto_shash_setkey(struct crypto_shash *tfm, const u8 *key,\n\t\t\tunsigned int keylen)\n{\n\tstruct shash_alg *shash = crypto_shash_alg(tfm);\n\tunsigned long alignmask = crypto_shash_alignmask(tfm);\n\n\tif ((unsigned long)key & alignmask)\n\t\treturn shash_setkey_unaligned(tfm, key, keylen);\n\n\treturn shash->setkey(tfm, key, keylen);\n}\nEXPORT_SYMBOL_GPL(crypto_shash_setkey);\n\nstatic inline unsigned int shash_align_buffer_size(unsigned len,\n\t\t\t\t\t\t   unsigned long mask)\n{\n\ttypedef u8 __aligned_largest u8_aligned;\n\treturn len + (mask & ~(__alignof__(u8_aligned) - 1));\n}\n\nstatic int shash_update_unaligned(struct shash_desc *desc, const u8 *data,\n\t\t\t\t  unsigned int len)\n{\n\tstruct crypto_shash *tfm = desc->tfm;\n\tstruct shash_alg *shash = crypto_shash_alg(tfm);\n\tunsigned long alignmask = crypto_shash_alignmask(tfm);\n\tunsigned int unaligned_len = alignmask + 1 -\n\t\t\t\t     ((unsigned long)data & alignmask);\n\tu8 ubuf[shash_align_buffer_size(unaligned_len, alignmask)]\n\t\t__aligned_largest;\n\tu8 *buf = PTR_ALIGN(&ubuf[0], alignmask + 1);\n\tint err;\n\n\tif (unaligned_len > len)\n\t\tunaligned_len = len;\n\n\tmemcpy(buf, data, unaligned_len);\n\terr = shash->update(desc, buf, unaligned_len);\n\tmemset(buf, 0, unaligned_len);\n\n\treturn err ?:\n\t       shash->update(desc, data + unaligned_len, len - unaligned_len);\n}\n\nint crypto_shash_update(struct shash_desc *desc, const u8 *data,\n\t\t\tunsigned int len)\n{\n\tstruct crypto_shash *tfm = desc->tfm;\n\tstruct shash_alg *shash = crypto_shash_alg(tfm);\n\tunsigned long alignmask = crypto_shash_alignmask(tfm);\n\n\tif ((unsigned long)data & alignmask)\n\t\treturn shash_update_unaligned(desc, data, len);\n\n\treturn shash->update(desc, data, len);\n}\nEXPORT_SYMBOL_GPL(crypto_shash_update);\n\nstatic int shash_final_unaligned(struct shash_desc *desc, u8 *out)\n{\n\tstruct crypto_shash *tfm = desc->tfm;\n\tunsigned long alignmask = crypto_shash_alignmask(tfm);\n\tstruct shash_alg *shash = crypto_shash_alg(tfm);\n\tunsigned int ds = crypto_shash_digestsize(tfm);\n\tu8 ubuf[shash_align_buffer_size(ds, alignmask)]\n\t\t__aligned_largest;\n\tu8 *buf = PTR_ALIGN(&ubuf[0], alignmask + 1);\n\tint err;\n\n\terr = shash->final(desc, buf);\n\tif (err)\n\t\tgoto out;\n\n\tmemcpy(out, buf, ds);\n\nout:\n\tmemset(buf, 0, ds);\n\treturn err;\n}\n\nint crypto_shash_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct crypto_shash *tfm = desc->tfm;\n\tstruct shash_alg *shash = crypto_shash_alg(tfm);\n\tunsigned long alignmask = crypto_shash_alignmask(tfm);\n\n\tif ((unsigned long)out & alignmask)\n\t\treturn shash_final_unaligned(desc, out);\n\n\treturn shash->final(desc, out);\n}\nEXPORT_SYMBOL_GPL(crypto_shash_final);\n\nstatic int shash_finup_unaligned(struct shash_desc *desc, const u8 *data,\n\t\t\t\t unsigned int len, u8 *out)\n{\n\treturn crypto_shash_update(desc, data, len) ?:\n\t       crypto_shash_final(desc, out);\n}\n\nint crypto_shash_finup(struct shash_desc *desc, const u8 *data,\n\t\t       unsigned int len, u8 *out)\n{\n\tstruct crypto_shash *tfm = desc->tfm;\n\tstruct shash_alg *shash = crypto_shash_alg(tfm);\n\tunsigned long alignmask = crypto_shash_alignmask(tfm);\n\n\tif (((unsigned long)data | (unsigned long)out) & alignmask)\n\t\treturn shash_finup_unaligned(desc, data, len, out);\n\n\treturn shash->finup(desc, data, len, out);\n}\nEXPORT_SYMBOL_GPL(crypto_shash_finup);\n\nstatic int shash_digest_unaligned(struct shash_desc *desc, const u8 *data,\n\t\t\t\t  unsigned int len, u8 *out)\n{\n\treturn crypto_shash_init(desc) ?:\n\t       crypto_shash_finup(desc, data, len, out);\n}\n\nint crypto_shash_digest(struct shash_desc *desc, const u8 *data,\n\t\t\tunsigned int len, u8 *out)\n{\n\tstruct crypto_shash *tfm = desc->tfm;\n\tstruct shash_alg *shash = crypto_shash_alg(tfm);\n\tunsigned long alignmask = crypto_shash_alignmask(tfm);\n\n\tif (((unsigned long)data | (unsigned long)out) & alignmask)\n\t\treturn shash_digest_unaligned(desc, data, len, out);\n\n\treturn shash->digest(desc, data, len, out);\n}\nEXPORT_SYMBOL_GPL(crypto_shash_digest);\n\nstatic int shash_default_export(struct shash_desc *desc, void *out)\n{\n\tmemcpy(out, shash_desc_ctx(desc), crypto_shash_descsize(desc->tfm));\n\treturn 0;\n}\n\nstatic int shash_default_import(struct shash_desc *desc, const void *in)\n{\n\tmemcpy(shash_desc_ctx(desc), in, crypto_shash_descsize(desc->tfm));\n\treturn 0;\n}\n\nstatic int shash_async_setkey(struct crypto_ahash *tfm, const u8 *key,\n\t\t\t      unsigned int keylen)\n{\n\tstruct crypto_shash **ctx = crypto_ahash_ctx(tfm);\n\n\treturn crypto_shash_setkey(*ctx, key, keylen);\n}\n\nstatic int shash_async_init(struct ahash_request *req)\n{\n\tstruct crypto_shash **ctx = crypto_ahash_ctx(crypto_ahash_reqtfm(req));\n\tstruct shash_desc *desc = ahash_request_ctx(req);\n\n\tdesc->tfm = *ctx;\n\tdesc->flags = req->base.flags;\n\n\treturn crypto_shash_init(desc);\n}\n\nint shash_ahash_update(struct ahash_request *req, struct shash_desc *desc)\n{\n\tstruct crypto_hash_walk walk;\n\tint nbytes;\n\n\tfor (nbytes = crypto_hash_walk_first(req, &walk); nbytes > 0;\n\t     nbytes = crypto_hash_walk_done(&walk, nbytes))\n\t\tnbytes = crypto_shash_update(desc, walk.data, nbytes);\n\n\treturn nbytes;\n}\nEXPORT_SYMBOL_GPL(shash_ahash_update);\n\nstatic int shash_async_update(struct ahash_request *req)\n{\n\treturn shash_ahash_update(req, ahash_request_ctx(req));\n}\n\nstatic int shash_async_final(struct ahash_request *req)\n{\n\treturn crypto_shash_final(ahash_request_ctx(req), req->result);\n}\n\nint shash_ahash_finup(struct ahash_request *req, struct shash_desc *desc)\n{\n\tstruct crypto_hash_walk walk;\n\tint nbytes;\n\n\tnbytes = crypto_hash_walk_first(req, &walk);\n\tif (!nbytes)\n\t\treturn crypto_shash_final(desc, req->result);\n\n\tdo {\n\t\tnbytes = crypto_hash_walk_last(&walk) ?\n\t\t\t crypto_shash_finup(desc, walk.data, nbytes,\n\t\t\t\t\t    req->result) :\n\t\t\t crypto_shash_update(desc, walk.data, nbytes);\n\t\tnbytes = crypto_hash_walk_done(&walk, nbytes);\n\t} while (nbytes > 0);\n\n\treturn nbytes;\n}\nEXPORT_SYMBOL_GPL(shash_ahash_finup);\n\nstatic int shash_async_finup(struct ahash_request *req)\n{\n\tstruct crypto_shash **ctx = crypto_ahash_ctx(crypto_ahash_reqtfm(req));\n\tstruct shash_desc *desc = ahash_request_ctx(req);\n\n\tdesc->tfm = *ctx;\n\tdesc->flags = req->base.flags;\n\n\treturn shash_ahash_finup(req, desc);\n}\n\nint shash_ahash_digest(struct ahash_request *req, struct shash_desc *desc)\n{\n\tunsigned int nbytes = req->nbytes;\n\tstruct scatterlist *sg;\n\tunsigned int offset;\n\tint err;\n\n\tif (nbytes &&\n\t    (sg = req->src, offset = sg->offset,\n\t     nbytes < min(sg->length, ((unsigned int)(PAGE_SIZE)) - offset))) {\n\t\tvoid *data;\n\n\t\tdata = kmap_atomic(sg_page(sg));\n\t\terr = crypto_shash_digest(desc, data + offset, nbytes,\n\t\t\t\t\t  req->result);\n\t\tkunmap_atomic(data);\n\t\tcrypto_yield(desc->flags);\n\t} else\n\t\terr = crypto_shash_init(desc) ?:\n\t\t      shash_ahash_finup(req, desc);\n\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(shash_ahash_digest);\n\nstatic int shash_async_digest(struct ahash_request *req)\n{\n\tstruct crypto_shash **ctx = crypto_ahash_ctx(crypto_ahash_reqtfm(req));\n\tstruct shash_desc *desc = ahash_request_ctx(req);\n\n\tdesc->tfm = *ctx;\n\tdesc->flags = req->base.flags;\n\n\treturn shash_ahash_digest(req, desc);\n}\n\nstatic int shash_async_export(struct ahash_request *req, void *out)\n{\n\treturn crypto_shash_export(ahash_request_ctx(req), out);\n}\n\nstatic int shash_async_import(struct ahash_request *req, const void *in)\n{\n\tstruct crypto_shash **ctx = crypto_ahash_ctx(crypto_ahash_reqtfm(req));\n\tstruct shash_desc *desc = ahash_request_ctx(req);\n\n\tdesc->tfm = *ctx;\n\tdesc->flags = req->base.flags;\n\n\treturn crypto_shash_import(desc, in);\n}\n\nstatic void crypto_exit_shash_ops_async(struct crypto_tfm *tfm)\n{\n\tstruct crypto_shash **ctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_shash(*ctx);\n}\n\nint crypto_init_shash_ops_async(struct crypto_tfm *tfm)\n{\n\tstruct crypto_alg *calg = tfm->__crt_alg;\n\tstruct shash_alg *alg = __crypto_shash_alg(calg);\n\tstruct crypto_ahash *crt = __crypto_ahash_cast(tfm);\n\tstruct crypto_shash **ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_shash *shash;\n\n\tif (!crypto_mod_get(calg))\n\t\treturn -EAGAIN;\n\n\tshash = crypto_create_tfm(calg, &crypto_shash_type);\n\tif (IS_ERR(shash)) {\n\t\tcrypto_mod_put(calg);\n\t\treturn PTR_ERR(shash);\n\t}\n\n\t*ctx = shash;\n\ttfm->exit = crypto_exit_shash_ops_async;\n\n\tcrt->init = shash_async_init;\n\tcrt->update = shash_async_update;\n\tcrt->final = shash_async_final;\n\tcrt->finup = shash_async_finup;\n\tcrt->digest = shash_async_digest;\n\tcrt->setkey = shash_async_setkey;\n\n\tcrt->has_setkey = alg->setkey != shash_no_setkey;\n\n\tif (alg->export)\n\t\tcrt->export = shash_async_export;\n\tif (alg->import)\n\t\tcrt->import = shash_async_import;\n\n\tcrt->reqsize = sizeof(struct shash_desc) + crypto_shash_descsize(shash);\n\n\treturn 0;\n}\n\nstatic int crypto_shash_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_shash *hash = __crypto_shash_cast(tfm);\n\n\thash->descsize = crypto_shash_alg(hash)->descsize;\n\treturn 0;\n}\n\n#ifdef CONFIG_NET\nstatic int crypto_shash_report(struct sk_buff *skb, struct crypto_alg *alg)\n{\n\tstruct crypto_report_hash rhash;\n\tstruct shash_alg *salg = __crypto_shash_alg(alg);\n\n\tstrncpy(rhash.type, \"shash\", sizeof(rhash.type));\n\n\trhash.blocksize = alg->cra_blocksize;\n\trhash.digestsize = salg->digestsize;\n\n\tif (nla_put(skb, CRYPTOCFGA_REPORT_HASH,\n\t\t    sizeof(struct crypto_report_hash), &rhash))\n\t\tgoto nla_put_failure;\n\treturn 0;\n\nnla_put_failure:\n\treturn -EMSGSIZE;\n}\n#else\nstatic int crypto_shash_report(struct sk_buff *skb, struct crypto_alg *alg)\n{\n\treturn -ENOSYS;\n}\n#endif\n\nstatic void crypto_shash_show(struct seq_file *m, struct crypto_alg *alg)\n\t__maybe_unused;\nstatic void crypto_shash_show(struct seq_file *m, struct crypto_alg *alg)\n{\n\tstruct shash_alg *salg = __crypto_shash_alg(alg);\n\n\tseq_printf(m, \"type         : shash\\n\");\n\tseq_printf(m, \"blocksize    : %u\\n\", alg->cra_blocksize);\n\tseq_printf(m, \"digestsize   : %u\\n\", salg->digestsize);\n}\n\nstatic const struct crypto_type crypto_shash_type = {\n\t.extsize = crypto_alg_extsize,\n\t.init_tfm = crypto_shash_init_tfm,\n#ifdef CONFIG_PROC_FS\n\t.show = crypto_shash_show,\n#endif\n\t.report = crypto_shash_report,\n\t.maskclear = ~CRYPTO_ALG_TYPE_MASK,\n\t.maskset = CRYPTO_ALG_TYPE_MASK,\n\t.type = CRYPTO_ALG_TYPE_SHASH,\n\t.tfmsize = offsetof(struct crypto_shash, base),\n};\n\nstruct crypto_shash *crypto_alloc_shash(const char *alg_name, u32 type,\n\t\t\t\t\tu32 mask)\n{\n\treturn crypto_alloc_tfm(alg_name, &crypto_shash_type, type, mask);\n}\nEXPORT_SYMBOL_GPL(crypto_alloc_shash);\n\nstatic int shash_prepare_alg(struct shash_alg *alg)\n{\n\tstruct crypto_alg *base = &alg->base;\n\n\tif (alg->digestsize > PAGE_SIZE / 8 ||\n\t    alg->descsize > PAGE_SIZE / 8 ||\n\t    alg->statesize > PAGE_SIZE / 8)\n\t\treturn -EINVAL;\n\n\tbase->cra_type = &crypto_shash_type;\n\tbase->cra_flags &= ~CRYPTO_ALG_TYPE_MASK;\n\tbase->cra_flags |= CRYPTO_ALG_TYPE_SHASH;\n\n\tif (!alg->finup)\n\t\talg->finup = shash_finup_unaligned;\n\tif (!alg->digest)\n\t\talg->digest = shash_digest_unaligned;\n\tif (!alg->export) {\n\t\talg->export = shash_default_export;\n\t\talg->import = shash_default_import;\n\t\talg->statesize = alg->descsize;\n\t}\n\tif (!alg->setkey)\n\t\talg->setkey = shash_no_setkey;\n\n\treturn 0;\n}\n\nint crypto_register_shash(struct shash_alg *alg)\n{\n\tstruct crypto_alg *base = &alg->base;\n\tint err;\n\n\terr = shash_prepare_alg(alg);\n\tif (err)\n\t\treturn err;\n\n\treturn crypto_register_alg(base);\n}\nEXPORT_SYMBOL_GPL(crypto_register_shash);\n\nint crypto_unregister_shash(struct shash_alg *alg)\n{\n\treturn crypto_unregister_alg(&alg->base);\n}\nEXPORT_SYMBOL_GPL(crypto_unregister_shash);\n\nint crypto_register_shashes(struct shash_alg *algs, int count)\n{\n\tint i, ret;\n\n\tfor (i = 0; i < count; i++) {\n\t\tret = crypto_register_shash(&algs[i]);\n\t\tif (ret)\n\t\t\tgoto err;\n\t}\n\n\treturn 0;\n\nerr:\n\tfor (--i; i >= 0; --i)\n\t\tcrypto_unregister_shash(&algs[i]);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(crypto_register_shashes);\n\nint crypto_unregister_shashes(struct shash_alg *algs, int count)\n{\n\tint i, ret;\n\n\tfor (i = count - 1; i >= 0; --i) {\n\t\tret = crypto_unregister_shash(&algs[i]);\n\t\tif (ret)\n\t\t\tpr_err(\"Failed to unregister %s %s: %d\\n\",\n\t\t\t       algs[i].base.cra_driver_name,\n\t\t\t       algs[i].base.cra_name, ret);\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(crypto_unregister_shashes);\n\nint shash_register_instance(struct crypto_template *tmpl,\n\t\t\t    struct shash_instance *inst)\n{\n\tint err;\n\n\terr = shash_prepare_alg(&inst->alg);\n\tif (err)\n\t\treturn err;\n\n\treturn crypto_register_instance(tmpl, shash_crypto_instance(inst));\n}\nEXPORT_SYMBOL_GPL(shash_register_instance);\n\nvoid shash_free_instance(struct crypto_instance *inst)\n{\n\tcrypto_drop_spawn(crypto_instance_ctx(inst));\n\tkfree(shash_instance(inst));\n}\nEXPORT_SYMBOL_GPL(shash_free_instance);\n\nint crypto_init_shash_spawn(struct crypto_shash_spawn *spawn,\n\t\t\t    struct shash_alg *alg,\n\t\t\t    struct crypto_instance *inst)\n{\n\treturn crypto_init_spawn2(&spawn->base, &alg->base, inst,\n\t\t\t\t  &crypto_shash_type);\n}\nEXPORT_SYMBOL_GPL(crypto_init_shash_spawn);\n\nstruct shash_alg *shash_attr_alg(struct rtattr *rta, u32 type, u32 mask)\n{\n\tstruct crypto_alg *alg;\n\n\talg = crypto_attr_alg2(rta, &crypto_shash_type, type, mask);\n\treturn IS_ERR(alg) ? ERR_CAST(alg) :\n\t       container_of(alg, struct shash_alg, base);\n}\nEXPORT_SYMBOL_GPL(shash_attr_alg);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Synchronous cryptographic hash type\");\n", "/*\n * Hash algorithms.\n * \n * Copyright (c) 2008 Herbert Xu <herbert@gondor.apana.org.au>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option) \n * any later version.\n *\n */\n\n#ifndef _CRYPTO_INTERNAL_HASH_H\n#define _CRYPTO_INTERNAL_HASH_H\n\n#include <crypto/algapi.h>\n#include <crypto/hash.h>\n\nstruct ahash_request;\nstruct scatterlist;\n\nstruct crypto_hash_walk {\n\tchar *data;\n\n\tunsigned int offset;\n\tunsigned int alignmask;\n\n\tstruct page *pg;\n\tunsigned int entrylen;\n\n\tunsigned int total;\n\tstruct scatterlist *sg;\n\n\tunsigned int flags;\n};\n\nstruct ahash_instance {\n\tstruct ahash_alg alg;\n};\n\nstruct shash_instance {\n\tstruct shash_alg alg;\n};\n\nstruct crypto_ahash_spawn {\n\tstruct crypto_spawn base;\n};\n\nstruct crypto_shash_spawn {\n\tstruct crypto_spawn base;\n};\n\nextern const struct crypto_type crypto_ahash_type;\n\nint crypto_hash_walk_done(struct crypto_hash_walk *walk, int err);\nint crypto_hash_walk_first(struct ahash_request *req,\n\t\t\t   struct crypto_hash_walk *walk);\nint crypto_ahash_walk_first(struct ahash_request *req,\n\t\t\t   struct crypto_hash_walk *walk);\n\nstatic inline int crypto_ahash_walk_done(struct crypto_hash_walk *walk,\n\t\t\t\t\t int err)\n{\n\treturn crypto_hash_walk_done(walk, err);\n}\n\nstatic inline int crypto_hash_walk_last(struct crypto_hash_walk *walk)\n{\n\treturn !(walk->entrylen | walk->total);\n}\n\nstatic inline int crypto_ahash_walk_last(struct crypto_hash_walk *walk)\n{\n\treturn crypto_hash_walk_last(walk);\n}\n\nint crypto_register_ahash(struct ahash_alg *alg);\nint crypto_unregister_ahash(struct ahash_alg *alg);\nint crypto_register_ahashes(struct ahash_alg *algs, int count);\nvoid crypto_unregister_ahashes(struct ahash_alg *algs, int count);\nint ahash_register_instance(struct crypto_template *tmpl,\n\t\t\t    struct ahash_instance *inst);\nvoid ahash_free_instance(struct crypto_instance *inst);\n\nint crypto_init_ahash_spawn(struct crypto_ahash_spawn *spawn,\n\t\t\t    struct hash_alg_common *alg,\n\t\t\t    struct crypto_instance *inst);\n\nstatic inline void crypto_drop_ahash(struct crypto_ahash_spawn *spawn)\n{\n\tcrypto_drop_spawn(&spawn->base);\n}\n\nstruct hash_alg_common *ahash_attr_alg(struct rtattr *rta, u32 type, u32 mask);\n\nint crypto_register_shash(struct shash_alg *alg);\nint crypto_unregister_shash(struct shash_alg *alg);\nint crypto_register_shashes(struct shash_alg *algs, int count);\nint crypto_unregister_shashes(struct shash_alg *algs, int count);\nint shash_register_instance(struct crypto_template *tmpl,\n\t\t\t    struct shash_instance *inst);\nvoid shash_free_instance(struct crypto_instance *inst);\n\nint crypto_init_shash_spawn(struct crypto_shash_spawn *spawn,\n\t\t\t    struct shash_alg *alg,\n\t\t\t    struct crypto_instance *inst);\n\nstatic inline void crypto_drop_shash(struct crypto_shash_spawn *spawn)\n{\n\tcrypto_drop_spawn(&spawn->base);\n}\n\nstruct shash_alg *shash_attr_alg(struct rtattr *rta, u32 type, u32 mask);\n\nint shash_ahash_update(struct ahash_request *req, struct shash_desc *desc);\nint shash_ahash_finup(struct ahash_request *req, struct shash_desc *desc);\nint shash_ahash_digest(struct ahash_request *req, struct shash_desc *desc);\n\nint ahash_mcryptd_update(struct ahash_request *desc);\nint ahash_mcryptd_final(struct ahash_request *desc);\nint ahash_mcryptd_finup(struct ahash_request *desc);\nint ahash_mcryptd_digest(struct ahash_request *desc);\n\nint crypto_init_shash_ops_async(struct crypto_tfm *tfm);\n\nstatic inline void *crypto_ahash_ctx(struct crypto_ahash *tfm)\n{\n\treturn crypto_tfm_ctx(crypto_ahash_tfm(tfm));\n}\n\nstatic inline struct ahash_alg *__crypto_ahash_alg(struct crypto_alg *alg)\n{\n\treturn container_of(__crypto_hash_alg_common(alg), struct ahash_alg,\n\t\t\t    halg);\n}\n\nstatic inline void crypto_ahash_set_reqsize(struct crypto_ahash *tfm,\n\t\t\t\t\t    unsigned int reqsize)\n{\n\ttfm->reqsize = reqsize;\n}\n\nstatic inline struct crypto_instance *ahash_crypto_instance(\n\tstruct ahash_instance *inst)\n{\n\treturn container_of(&inst->alg.halg.base, struct crypto_instance, alg);\n}\n\nstatic inline struct ahash_instance *ahash_instance(\n\tstruct crypto_instance *inst)\n{\n\treturn container_of(&inst->alg, struct ahash_instance, alg.halg.base);\n}\n\nstatic inline void *ahash_instance_ctx(struct ahash_instance *inst)\n{\n\treturn crypto_instance_ctx(ahash_crypto_instance(inst));\n}\n\nstatic inline unsigned int ahash_instance_headroom(void)\n{\n\treturn sizeof(struct ahash_alg) - sizeof(struct crypto_alg);\n}\n\nstatic inline struct ahash_instance *ahash_alloc_instance(\n\tconst char *name, struct crypto_alg *alg)\n{\n\treturn crypto_alloc_instance2(name, alg, ahash_instance_headroom());\n}\n\nstatic inline void ahash_request_complete(struct ahash_request *req, int err)\n{\n\treq->base.complete(&req->base, err);\n}\n\nstatic inline u32 ahash_request_flags(struct ahash_request *req)\n{\n\treturn req->base.flags;\n}\n\nstatic inline struct crypto_ahash *crypto_spawn_ahash(\n\tstruct crypto_ahash_spawn *spawn)\n{\n\treturn crypto_spawn_tfm2(&spawn->base);\n}\n\nstatic inline int ahash_enqueue_request(struct crypto_queue *queue,\n\t\t\t\t\t     struct ahash_request *request)\n{\n\treturn crypto_enqueue_request(queue, &request->base);\n}\n\nstatic inline struct ahash_request *ahash_dequeue_request(\n\tstruct crypto_queue *queue)\n{\n\treturn ahash_request_cast(crypto_dequeue_request(queue));\n}\n\nstatic inline int ahash_tfm_in_queue(struct crypto_queue *queue,\n\t\t\t\t\t  struct crypto_ahash *tfm)\n{\n\treturn crypto_tfm_in_queue(queue, crypto_ahash_tfm(tfm));\n}\n\nstatic inline void *crypto_shash_ctx(struct crypto_shash *tfm)\n{\n\treturn crypto_tfm_ctx(&tfm->base);\n}\n\nstatic inline struct crypto_instance *shash_crypto_instance(\n\tstruct shash_instance *inst)\n{\n\treturn container_of(&inst->alg.base, struct crypto_instance, alg);\n}\n\nstatic inline struct shash_instance *shash_instance(\n\tstruct crypto_instance *inst)\n{\n\treturn container_of(__crypto_shash_alg(&inst->alg),\n\t\t\t    struct shash_instance, alg);\n}\n\nstatic inline void *shash_instance_ctx(struct shash_instance *inst)\n{\n\treturn crypto_instance_ctx(shash_crypto_instance(inst));\n}\n\nstatic inline struct shash_instance *shash_alloc_instance(\n\tconst char *name, struct crypto_alg *alg)\n{\n\treturn crypto_alloc_instance2(name, alg,\n\t\t\t\t      sizeof(struct shash_alg) - sizeof(*alg));\n}\n\nstatic inline struct crypto_shash *crypto_spawn_shash(\n\tstruct crypto_shash_spawn *spawn)\n{\n\treturn crypto_spawn_tfm2(&spawn->base);\n}\n\nstatic inline void *crypto_shash_ctx_aligned(struct crypto_shash *tfm)\n{\n\treturn crypto_tfm_ctx_aligned(&tfm->base);\n}\n\nstatic inline struct crypto_shash *__crypto_shash_cast(struct crypto_tfm *tfm)\n{\n\treturn container_of(tfm, struct crypto_shash, base);\n}\n\n#endif\t/* _CRYPTO_INTERNAL_HASH_H */\n\n"], "fixing_code": ["/*\n * Cryptographic API.\n *\n * HMAC: Keyed-Hashing for Message Authentication (RFC2104).\n *\n * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>\n * Copyright (c) 2006 Herbert Xu <herbert@gondor.apana.org.au>\n *\n * The HMAC implementation is derived from USAGI.\n * Copyright (c) 2002 Kazunori Miyazawa <miyazawa@linux-ipv6.org> / USAGI\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#include <crypto/hmac.h>\n#include <crypto/internal/hash.h>\n#include <crypto/scatterwalk.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/scatterlist.h>\n#include <linux/string.h>\n\nstruct hmac_ctx {\n\tstruct crypto_shash *hash;\n};\n\nstatic inline void *align_ptr(void *p, unsigned int align)\n{\n\treturn (void *)ALIGN((unsigned long)p, align);\n}\n\nstatic inline struct hmac_ctx *hmac_ctx(struct crypto_shash *tfm)\n{\n\treturn align_ptr(crypto_shash_ctx_aligned(tfm) +\n\t\t\t crypto_shash_statesize(tfm) * 2,\n\t\t\t crypto_tfm_ctx_alignment());\n}\n\nstatic int hmac_setkey(struct crypto_shash *parent,\n\t\t       const u8 *inkey, unsigned int keylen)\n{\n\tint bs = crypto_shash_blocksize(parent);\n\tint ds = crypto_shash_digestsize(parent);\n\tint ss = crypto_shash_statesize(parent);\n\tchar *ipad = crypto_shash_ctx_aligned(parent);\n\tchar *opad = ipad + ss;\n\tstruct hmac_ctx *ctx = align_ptr(opad + ss,\n\t\t\t\t\t crypto_tfm_ctx_alignment());\n\tstruct crypto_shash *hash = ctx->hash;\n\tSHASH_DESC_ON_STACK(shash, hash);\n\tunsigned int i;\n\n\tshash->tfm = hash;\n\tshash->flags = crypto_shash_get_flags(parent)\n\t\t& CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tif (keylen > bs) {\n\t\tint err;\n\n\t\terr = crypto_shash_digest(shash, inkey, keylen, ipad);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tkeylen = ds;\n\t} else\n\t\tmemcpy(ipad, inkey, keylen);\n\n\tmemset(ipad + keylen, 0, bs - keylen);\n\tmemcpy(opad, ipad, bs);\n\n\tfor (i = 0; i < bs; i++) {\n\t\tipad[i] ^= HMAC_IPAD_VALUE;\n\t\topad[i] ^= HMAC_OPAD_VALUE;\n\t}\n\n\treturn crypto_shash_init(shash) ?:\n\t       crypto_shash_update(shash, ipad, bs) ?:\n\t       crypto_shash_export(shash, ipad) ?:\n\t       crypto_shash_init(shash) ?:\n\t       crypto_shash_update(shash, opad, bs) ?:\n\t       crypto_shash_export(shash, opad);\n}\n\nstatic int hmac_export(struct shash_desc *pdesc, void *out)\n{\n\tstruct shash_desc *desc = shash_desc_ctx(pdesc);\n\n\tdesc->flags = pdesc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\treturn crypto_shash_export(desc, out);\n}\n\nstatic int hmac_import(struct shash_desc *pdesc, const void *in)\n{\n\tstruct shash_desc *desc = shash_desc_ctx(pdesc);\n\tstruct hmac_ctx *ctx = hmac_ctx(pdesc->tfm);\n\n\tdesc->tfm = ctx->hash;\n\tdesc->flags = pdesc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\treturn crypto_shash_import(desc, in);\n}\n\nstatic int hmac_init(struct shash_desc *pdesc)\n{\n\treturn hmac_import(pdesc, crypto_shash_ctx_aligned(pdesc->tfm));\n}\n\nstatic int hmac_update(struct shash_desc *pdesc,\n\t\t       const u8 *data, unsigned int nbytes)\n{\n\tstruct shash_desc *desc = shash_desc_ctx(pdesc);\n\n\tdesc->flags = pdesc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\treturn crypto_shash_update(desc, data, nbytes);\n}\n\nstatic int hmac_final(struct shash_desc *pdesc, u8 *out)\n{\n\tstruct crypto_shash *parent = pdesc->tfm;\n\tint ds = crypto_shash_digestsize(parent);\n\tint ss = crypto_shash_statesize(parent);\n\tchar *opad = crypto_shash_ctx_aligned(parent) + ss;\n\tstruct shash_desc *desc = shash_desc_ctx(pdesc);\n\n\tdesc->flags = pdesc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\treturn crypto_shash_final(desc, out) ?:\n\t       crypto_shash_import(desc, opad) ?:\n\t       crypto_shash_finup(desc, out, ds, out);\n}\n\nstatic int hmac_finup(struct shash_desc *pdesc, const u8 *data,\n\t\t      unsigned int nbytes, u8 *out)\n{\n\n\tstruct crypto_shash *parent = pdesc->tfm;\n\tint ds = crypto_shash_digestsize(parent);\n\tint ss = crypto_shash_statesize(parent);\n\tchar *opad = crypto_shash_ctx_aligned(parent) + ss;\n\tstruct shash_desc *desc = shash_desc_ctx(pdesc);\n\n\tdesc->flags = pdesc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\treturn crypto_shash_finup(desc, data, nbytes, out) ?:\n\t       crypto_shash_import(desc, opad) ?:\n\t       crypto_shash_finup(desc, out, ds, out);\n}\n\nstatic int hmac_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_shash *parent = __crypto_shash_cast(tfm);\n\tstruct crypto_shash *hash;\n\tstruct crypto_instance *inst = (void *)tfm->__crt_alg;\n\tstruct crypto_shash_spawn *spawn = crypto_instance_ctx(inst);\n\tstruct hmac_ctx *ctx = hmac_ctx(parent);\n\n\thash = crypto_spawn_shash(spawn);\n\tif (IS_ERR(hash))\n\t\treturn PTR_ERR(hash);\n\n\tparent->descsize = sizeof(struct shash_desc) +\n\t\t\t   crypto_shash_descsize(hash);\n\n\tctx->hash = hash;\n\treturn 0;\n}\n\nstatic void hmac_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct hmac_ctx *ctx = hmac_ctx(__crypto_shash_cast(tfm));\n\tcrypto_free_shash(ctx->hash);\n}\n\nstatic int hmac_create(struct crypto_template *tmpl, struct rtattr **tb)\n{\n\tstruct shash_instance *inst;\n\tstruct crypto_alg *alg;\n\tstruct shash_alg *salg;\n\tint err;\n\tint ds;\n\tint ss;\n\n\terr = crypto_check_attr_type(tb, CRYPTO_ALG_TYPE_SHASH);\n\tif (err)\n\t\treturn err;\n\n\tsalg = shash_attr_alg(tb[1], 0, 0);\n\tif (IS_ERR(salg))\n\t\treturn PTR_ERR(salg);\n\talg = &salg->base;\n\n\t/* The underlying hash algorithm must be unkeyed */\n\terr = -EINVAL;\n\tif (crypto_shash_alg_has_setkey(salg))\n\t\tgoto out_put_alg;\n\n\tds = salg->digestsize;\n\tss = salg->statesize;\n\tif (ds > alg->cra_blocksize ||\n\t    ss < alg->cra_blocksize)\n\t\tgoto out_put_alg;\n\n\tinst = shash_alloc_instance(\"hmac\", alg);\n\terr = PTR_ERR(inst);\n\tif (IS_ERR(inst))\n\t\tgoto out_put_alg;\n\n\terr = crypto_init_shash_spawn(shash_instance_ctx(inst), salg,\n\t\t\t\t      shash_crypto_instance(inst));\n\tif (err)\n\t\tgoto out_free_inst;\n\n\tinst->alg.base.cra_priority = alg->cra_priority;\n\tinst->alg.base.cra_blocksize = alg->cra_blocksize;\n\tinst->alg.base.cra_alignmask = alg->cra_alignmask;\n\n\tss = ALIGN(ss, alg->cra_alignmask + 1);\n\tinst->alg.digestsize = ds;\n\tinst->alg.statesize = ss;\n\n\tinst->alg.base.cra_ctxsize = sizeof(struct hmac_ctx) +\n\t\t\t\t     ALIGN(ss * 2, crypto_tfm_ctx_alignment());\n\n\tinst->alg.base.cra_init = hmac_init_tfm;\n\tinst->alg.base.cra_exit = hmac_exit_tfm;\n\n\tinst->alg.init = hmac_init;\n\tinst->alg.update = hmac_update;\n\tinst->alg.final = hmac_final;\n\tinst->alg.finup = hmac_finup;\n\tinst->alg.export = hmac_export;\n\tinst->alg.import = hmac_import;\n\tinst->alg.setkey = hmac_setkey;\n\n\terr = shash_register_instance(tmpl, inst);\n\tif (err) {\nout_free_inst:\n\t\tshash_free_instance(shash_crypto_instance(inst));\n\t}\n\nout_put_alg:\n\tcrypto_mod_put(alg);\n\treturn err;\n}\n\nstatic struct crypto_template hmac_tmpl = {\n\t.name = \"hmac\",\n\t.create = hmac_create,\n\t.free = shash_free_instance,\n\t.module = THIS_MODULE,\n};\n\nstatic int __init hmac_module_init(void)\n{\n\treturn crypto_register_template(&hmac_tmpl);\n}\n\nstatic void __exit hmac_module_exit(void)\n{\n\tcrypto_unregister_template(&hmac_tmpl);\n}\n\nmodule_init(hmac_module_init);\nmodule_exit(hmac_module_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"HMAC hash algorithm\");\nMODULE_ALIAS_CRYPTO(\"hmac\");\n", "/*\n * Synchronous Cryptographic Hash operations.\n *\n * Copyright (c) 2008 Herbert Xu <herbert@gondor.apana.org.au>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option)\n * any later version.\n *\n */\n\n#include <crypto/scatterwalk.h>\n#include <crypto/internal/hash.h>\n#include <linux/err.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/slab.h>\n#include <linux/seq_file.h>\n#include <linux/cryptouser.h>\n#include <net/netlink.h>\n#include <linux/compiler.h>\n\n#include \"internal.h\"\n\nstatic const struct crypto_type crypto_shash_type;\n\nint shash_no_setkey(struct crypto_shash *tfm, const u8 *key,\n\t\t    unsigned int keylen)\n{\n\treturn -ENOSYS;\n}\nEXPORT_SYMBOL_GPL(shash_no_setkey);\n\nstatic int shash_setkey_unaligned(struct crypto_shash *tfm, const u8 *key,\n\t\t\t\t  unsigned int keylen)\n{\n\tstruct shash_alg *shash = crypto_shash_alg(tfm);\n\tunsigned long alignmask = crypto_shash_alignmask(tfm);\n\tunsigned long absize;\n\tu8 *buffer, *alignbuffer;\n\tint err;\n\n\tabsize = keylen + (alignmask & ~(crypto_tfm_ctx_alignment() - 1));\n\tbuffer = kmalloc(absize, GFP_ATOMIC);\n\tif (!buffer)\n\t\treturn -ENOMEM;\n\n\talignbuffer = (u8 *)ALIGN((unsigned long)buffer, alignmask + 1);\n\tmemcpy(alignbuffer, key, keylen);\n\terr = shash->setkey(tfm, alignbuffer, keylen);\n\tkzfree(buffer);\n\treturn err;\n}\n\nint crypto_shash_setkey(struct crypto_shash *tfm, const u8 *key,\n\t\t\tunsigned int keylen)\n{\n\tstruct shash_alg *shash = crypto_shash_alg(tfm);\n\tunsigned long alignmask = crypto_shash_alignmask(tfm);\n\n\tif ((unsigned long)key & alignmask)\n\t\treturn shash_setkey_unaligned(tfm, key, keylen);\n\n\treturn shash->setkey(tfm, key, keylen);\n}\nEXPORT_SYMBOL_GPL(crypto_shash_setkey);\n\nstatic inline unsigned int shash_align_buffer_size(unsigned len,\n\t\t\t\t\t\t   unsigned long mask)\n{\n\ttypedef u8 __aligned_largest u8_aligned;\n\treturn len + (mask & ~(__alignof__(u8_aligned) - 1));\n}\n\nstatic int shash_update_unaligned(struct shash_desc *desc, const u8 *data,\n\t\t\t\t  unsigned int len)\n{\n\tstruct crypto_shash *tfm = desc->tfm;\n\tstruct shash_alg *shash = crypto_shash_alg(tfm);\n\tunsigned long alignmask = crypto_shash_alignmask(tfm);\n\tunsigned int unaligned_len = alignmask + 1 -\n\t\t\t\t     ((unsigned long)data & alignmask);\n\tu8 ubuf[shash_align_buffer_size(unaligned_len, alignmask)]\n\t\t__aligned_largest;\n\tu8 *buf = PTR_ALIGN(&ubuf[0], alignmask + 1);\n\tint err;\n\n\tif (unaligned_len > len)\n\t\tunaligned_len = len;\n\n\tmemcpy(buf, data, unaligned_len);\n\terr = shash->update(desc, buf, unaligned_len);\n\tmemset(buf, 0, unaligned_len);\n\n\treturn err ?:\n\t       shash->update(desc, data + unaligned_len, len - unaligned_len);\n}\n\nint crypto_shash_update(struct shash_desc *desc, const u8 *data,\n\t\t\tunsigned int len)\n{\n\tstruct crypto_shash *tfm = desc->tfm;\n\tstruct shash_alg *shash = crypto_shash_alg(tfm);\n\tunsigned long alignmask = crypto_shash_alignmask(tfm);\n\n\tif ((unsigned long)data & alignmask)\n\t\treturn shash_update_unaligned(desc, data, len);\n\n\treturn shash->update(desc, data, len);\n}\nEXPORT_SYMBOL_GPL(crypto_shash_update);\n\nstatic int shash_final_unaligned(struct shash_desc *desc, u8 *out)\n{\n\tstruct crypto_shash *tfm = desc->tfm;\n\tunsigned long alignmask = crypto_shash_alignmask(tfm);\n\tstruct shash_alg *shash = crypto_shash_alg(tfm);\n\tunsigned int ds = crypto_shash_digestsize(tfm);\n\tu8 ubuf[shash_align_buffer_size(ds, alignmask)]\n\t\t__aligned_largest;\n\tu8 *buf = PTR_ALIGN(&ubuf[0], alignmask + 1);\n\tint err;\n\n\terr = shash->final(desc, buf);\n\tif (err)\n\t\tgoto out;\n\n\tmemcpy(out, buf, ds);\n\nout:\n\tmemset(buf, 0, ds);\n\treturn err;\n}\n\nint crypto_shash_final(struct shash_desc *desc, u8 *out)\n{\n\tstruct crypto_shash *tfm = desc->tfm;\n\tstruct shash_alg *shash = crypto_shash_alg(tfm);\n\tunsigned long alignmask = crypto_shash_alignmask(tfm);\n\n\tif ((unsigned long)out & alignmask)\n\t\treturn shash_final_unaligned(desc, out);\n\n\treturn shash->final(desc, out);\n}\nEXPORT_SYMBOL_GPL(crypto_shash_final);\n\nstatic int shash_finup_unaligned(struct shash_desc *desc, const u8 *data,\n\t\t\t\t unsigned int len, u8 *out)\n{\n\treturn crypto_shash_update(desc, data, len) ?:\n\t       crypto_shash_final(desc, out);\n}\n\nint crypto_shash_finup(struct shash_desc *desc, const u8 *data,\n\t\t       unsigned int len, u8 *out)\n{\n\tstruct crypto_shash *tfm = desc->tfm;\n\tstruct shash_alg *shash = crypto_shash_alg(tfm);\n\tunsigned long alignmask = crypto_shash_alignmask(tfm);\n\n\tif (((unsigned long)data | (unsigned long)out) & alignmask)\n\t\treturn shash_finup_unaligned(desc, data, len, out);\n\n\treturn shash->finup(desc, data, len, out);\n}\nEXPORT_SYMBOL_GPL(crypto_shash_finup);\n\nstatic int shash_digest_unaligned(struct shash_desc *desc, const u8 *data,\n\t\t\t\t  unsigned int len, u8 *out)\n{\n\treturn crypto_shash_init(desc) ?:\n\t       crypto_shash_finup(desc, data, len, out);\n}\n\nint crypto_shash_digest(struct shash_desc *desc, const u8 *data,\n\t\t\tunsigned int len, u8 *out)\n{\n\tstruct crypto_shash *tfm = desc->tfm;\n\tstruct shash_alg *shash = crypto_shash_alg(tfm);\n\tunsigned long alignmask = crypto_shash_alignmask(tfm);\n\n\tif (((unsigned long)data | (unsigned long)out) & alignmask)\n\t\treturn shash_digest_unaligned(desc, data, len, out);\n\n\treturn shash->digest(desc, data, len, out);\n}\nEXPORT_SYMBOL_GPL(crypto_shash_digest);\n\nstatic int shash_default_export(struct shash_desc *desc, void *out)\n{\n\tmemcpy(out, shash_desc_ctx(desc), crypto_shash_descsize(desc->tfm));\n\treturn 0;\n}\n\nstatic int shash_default_import(struct shash_desc *desc, const void *in)\n{\n\tmemcpy(shash_desc_ctx(desc), in, crypto_shash_descsize(desc->tfm));\n\treturn 0;\n}\n\nstatic int shash_async_setkey(struct crypto_ahash *tfm, const u8 *key,\n\t\t\t      unsigned int keylen)\n{\n\tstruct crypto_shash **ctx = crypto_ahash_ctx(tfm);\n\n\treturn crypto_shash_setkey(*ctx, key, keylen);\n}\n\nstatic int shash_async_init(struct ahash_request *req)\n{\n\tstruct crypto_shash **ctx = crypto_ahash_ctx(crypto_ahash_reqtfm(req));\n\tstruct shash_desc *desc = ahash_request_ctx(req);\n\n\tdesc->tfm = *ctx;\n\tdesc->flags = req->base.flags;\n\n\treturn crypto_shash_init(desc);\n}\n\nint shash_ahash_update(struct ahash_request *req, struct shash_desc *desc)\n{\n\tstruct crypto_hash_walk walk;\n\tint nbytes;\n\n\tfor (nbytes = crypto_hash_walk_first(req, &walk); nbytes > 0;\n\t     nbytes = crypto_hash_walk_done(&walk, nbytes))\n\t\tnbytes = crypto_shash_update(desc, walk.data, nbytes);\n\n\treturn nbytes;\n}\nEXPORT_SYMBOL_GPL(shash_ahash_update);\n\nstatic int shash_async_update(struct ahash_request *req)\n{\n\treturn shash_ahash_update(req, ahash_request_ctx(req));\n}\n\nstatic int shash_async_final(struct ahash_request *req)\n{\n\treturn crypto_shash_final(ahash_request_ctx(req), req->result);\n}\n\nint shash_ahash_finup(struct ahash_request *req, struct shash_desc *desc)\n{\n\tstruct crypto_hash_walk walk;\n\tint nbytes;\n\n\tnbytes = crypto_hash_walk_first(req, &walk);\n\tif (!nbytes)\n\t\treturn crypto_shash_final(desc, req->result);\n\n\tdo {\n\t\tnbytes = crypto_hash_walk_last(&walk) ?\n\t\t\t crypto_shash_finup(desc, walk.data, nbytes,\n\t\t\t\t\t    req->result) :\n\t\t\t crypto_shash_update(desc, walk.data, nbytes);\n\t\tnbytes = crypto_hash_walk_done(&walk, nbytes);\n\t} while (nbytes > 0);\n\n\treturn nbytes;\n}\nEXPORT_SYMBOL_GPL(shash_ahash_finup);\n\nstatic int shash_async_finup(struct ahash_request *req)\n{\n\tstruct crypto_shash **ctx = crypto_ahash_ctx(crypto_ahash_reqtfm(req));\n\tstruct shash_desc *desc = ahash_request_ctx(req);\n\n\tdesc->tfm = *ctx;\n\tdesc->flags = req->base.flags;\n\n\treturn shash_ahash_finup(req, desc);\n}\n\nint shash_ahash_digest(struct ahash_request *req, struct shash_desc *desc)\n{\n\tunsigned int nbytes = req->nbytes;\n\tstruct scatterlist *sg;\n\tunsigned int offset;\n\tint err;\n\n\tif (nbytes &&\n\t    (sg = req->src, offset = sg->offset,\n\t     nbytes < min(sg->length, ((unsigned int)(PAGE_SIZE)) - offset))) {\n\t\tvoid *data;\n\n\t\tdata = kmap_atomic(sg_page(sg));\n\t\terr = crypto_shash_digest(desc, data + offset, nbytes,\n\t\t\t\t\t  req->result);\n\t\tkunmap_atomic(data);\n\t\tcrypto_yield(desc->flags);\n\t} else\n\t\terr = crypto_shash_init(desc) ?:\n\t\t      shash_ahash_finup(req, desc);\n\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(shash_ahash_digest);\n\nstatic int shash_async_digest(struct ahash_request *req)\n{\n\tstruct crypto_shash **ctx = crypto_ahash_ctx(crypto_ahash_reqtfm(req));\n\tstruct shash_desc *desc = ahash_request_ctx(req);\n\n\tdesc->tfm = *ctx;\n\tdesc->flags = req->base.flags;\n\n\treturn shash_ahash_digest(req, desc);\n}\n\nstatic int shash_async_export(struct ahash_request *req, void *out)\n{\n\treturn crypto_shash_export(ahash_request_ctx(req), out);\n}\n\nstatic int shash_async_import(struct ahash_request *req, const void *in)\n{\n\tstruct crypto_shash **ctx = crypto_ahash_ctx(crypto_ahash_reqtfm(req));\n\tstruct shash_desc *desc = ahash_request_ctx(req);\n\n\tdesc->tfm = *ctx;\n\tdesc->flags = req->base.flags;\n\n\treturn crypto_shash_import(desc, in);\n}\n\nstatic void crypto_exit_shash_ops_async(struct crypto_tfm *tfm)\n{\n\tstruct crypto_shash **ctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_shash(*ctx);\n}\n\nint crypto_init_shash_ops_async(struct crypto_tfm *tfm)\n{\n\tstruct crypto_alg *calg = tfm->__crt_alg;\n\tstruct shash_alg *alg = __crypto_shash_alg(calg);\n\tstruct crypto_ahash *crt = __crypto_ahash_cast(tfm);\n\tstruct crypto_shash **ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_shash *shash;\n\n\tif (!crypto_mod_get(calg))\n\t\treturn -EAGAIN;\n\n\tshash = crypto_create_tfm(calg, &crypto_shash_type);\n\tif (IS_ERR(shash)) {\n\t\tcrypto_mod_put(calg);\n\t\treturn PTR_ERR(shash);\n\t}\n\n\t*ctx = shash;\n\ttfm->exit = crypto_exit_shash_ops_async;\n\n\tcrt->init = shash_async_init;\n\tcrt->update = shash_async_update;\n\tcrt->final = shash_async_final;\n\tcrt->finup = shash_async_finup;\n\tcrt->digest = shash_async_digest;\n\tcrt->setkey = shash_async_setkey;\n\n\tcrt->has_setkey = alg->setkey != shash_no_setkey;\n\n\tif (alg->export)\n\t\tcrt->export = shash_async_export;\n\tif (alg->import)\n\t\tcrt->import = shash_async_import;\n\n\tcrt->reqsize = sizeof(struct shash_desc) + crypto_shash_descsize(shash);\n\n\treturn 0;\n}\n\nstatic int crypto_shash_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_shash *hash = __crypto_shash_cast(tfm);\n\n\thash->descsize = crypto_shash_alg(hash)->descsize;\n\treturn 0;\n}\n\n#ifdef CONFIG_NET\nstatic int crypto_shash_report(struct sk_buff *skb, struct crypto_alg *alg)\n{\n\tstruct crypto_report_hash rhash;\n\tstruct shash_alg *salg = __crypto_shash_alg(alg);\n\n\tstrncpy(rhash.type, \"shash\", sizeof(rhash.type));\n\n\trhash.blocksize = alg->cra_blocksize;\n\trhash.digestsize = salg->digestsize;\n\n\tif (nla_put(skb, CRYPTOCFGA_REPORT_HASH,\n\t\t    sizeof(struct crypto_report_hash), &rhash))\n\t\tgoto nla_put_failure;\n\treturn 0;\n\nnla_put_failure:\n\treturn -EMSGSIZE;\n}\n#else\nstatic int crypto_shash_report(struct sk_buff *skb, struct crypto_alg *alg)\n{\n\treturn -ENOSYS;\n}\n#endif\n\nstatic void crypto_shash_show(struct seq_file *m, struct crypto_alg *alg)\n\t__maybe_unused;\nstatic void crypto_shash_show(struct seq_file *m, struct crypto_alg *alg)\n{\n\tstruct shash_alg *salg = __crypto_shash_alg(alg);\n\n\tseq_printf(m, \"type         : shash\\n\");\n\tseq_printf(m, \"blocksize    : %u\\n\", alg->cra_blocksize);\n\tseq_printf(m, \"digestsize   : %u\\n\", salg->digestsize);\n}\n\nstatic const struct crypto_type crypto_shash_type = {\n\t.extsize = crypto_alg_extsize,\n\t.init_tfm = crypto_shash_init_tfm,\n#ifdef CONFIG_PROC_FS\n\t.show = crypto_shash_show,\n#endif\n\t.report = crypto_shash_report,\n\t.maskclear = ~CRYPTO_ALG_TYPE_MASK,\n\t.maskset = CRYPTO_ALG_TYPE_MASK,\n\t.type = CRYPTO_ALG_TYPE_SHASH,\n\t.tfmsize = offsetof(struct crypto_shash, base),\n};\n\nstruct crypto_shash *crypto_alloc_shash(const char *alg_name, u32 type,\n\t\t\t\t\tu32 mask)\n{\n\treturn crypto_alloc_tfm(alg_name, &crypto_shash_type, type, mask);\n}\nEXPORT_SYMBOL_GPL(crypto_alloc_shash);\n\nstatic int shash_prepare_alg(struct shash_alg *alg)\n{\n\tstruct crypto_alg *base = &alg->base;\n\n\tif (alg->digestsize > PAGE_SIZE / 8 ||\n\t    alg->descsize > PAGE_SIZE / 8 ||\n\t    alg->statesize > PAGE_SIZE / 8)\n\t\treturn -EINVAL;\n\n\tbase->cra_type = &crypto_shash_type;\n\tbase->cra_flags &= ~CRYPTO_ALG_TYPE_MASK;\n\tbase->cra_flags |= CRYPTO_ALG_TYPE_SHASH;\n\n\tif (!alg->finup)\n\t\talg->finup = shash_finup_unaligned;\n\tif (!alg->digest)\n\t\talg->digest = shash_digest_unaligned;\n\tif (!alg->export) {\n\t\talg->export = shash_default_export;\n\t\talg->import = shash_default_import;\n\t\talg->statesize = alg->descsize;\n\t}\n\tif (!alg->setkey)\n\t\talg->setkey = shash_no_setkey;\n\n\treturn 0;\n}\n\nint crypto_register_shash(struct shash_alg *alg)\n{\n\tstruct crypto_alg *base = &alg->base;\n\tint err;\n\n\terr = shash_prepare_alg(alg);\n\tif (err)\n\t\treturn err;\n\n\treturn crypto_register_alg(base);\n}\nEXPORT_SYMBOL_GPL(crypto_register_shash);\n\nint crypto_unregister_shash(struct shash_alg *alg)\n{\n\treturn crypto_unregister_alg(&alg->base);\n}\nEXPORT_SYMBOL_GPL(crypto_unregister_shash);\n\nint crypto_register_shashes(struct shash_alg *algs, int count)\n{\n\tint i, ret;\n\n\tfor (i = 0; i < count; i++) {\n\t\tret = crypto_register_shash(&algs[i]);\n\t\tif (ret)\n\t\t\tgoto err;\n\t}\n\n\treturn 0;\n\nerr:\n\tfor (--i; i >= 0; --i)\n\t\tcrypto_unregister_shash(&algs[i]);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(crypto_register_shashes);\n\nint crypto_unregister_shashes(struct shash_alg *algs, int count)\n{\n\tint i, ret;\n\n\tfor (i = count - 1; i >= 0; --i) {\n\t\tret = crypto_unregister_shash(&algs[i]);\n\t\tif (ret)\n\t\t\tpr_err(\"Failed to unregister %s %s: %d\\n\",\n\t\t\t       algs[i].base.cra_driver_name,\n\t\t\t       algs[i].base.cra_name, ret);\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(crypto_unregister_shashes);\n\nint shash_register_instance(struct crypto_template *tmpl,\n\t\t\t    struct shash_instance *inst)\n{\n\tint err;\n\n\terr = shash_prepare_alg(&inst->alg);\n\tif (err)\n\t\treturn err;\n\n\treturn crypto_register_instance(tmpl, shash_crypto_instance(inst));\n}\nEXPORT_SYMBOL_GPL(shash_register_instance);\n\nvoid shash_free_instance(struct crypto_instance *inst)\n{\n\tcrypto_drop_spawn(crypto_instance_ctx(inst));\n\tkfree(shash_instance(inst));\n}\nEXPORT_SYMBOL_GPL(shash_free_instance);\n\nint crypto_init_shash_spawn(struct crypto_shash_spawn *spawn,\n\t\t\t    struct shash_alg *alg,\n\t\t\t    struct crypto_instance *inst)\n{\n\treturn crypto_init_spawn2(&spawn->base, &alg->base, inst,\n\t\t\t\t  &crypto_shash_type);\n}\nEXPORT_SYMBOL_GPL(crypto_init_shash_spawn);\n\nstruct shash_alg *shash_attr_alg(struct rtattr *rta, u32 type, u32 mask)\n{\n\tstruct crypto_alg *alg;\n\n\talg = crypto_attr_alg2(rta, &crypto_shash_type, type, mask);\n\treturn IS_ERR(alg) ? ERR_CAST(alg) :\n\t       container_of(alg, struct shash_alg, base);\n}\nEXPORT_SYMBOL_GPL(shash_attr_alg);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Synchronous cryptographic hash type\");\n", "/*\n * Hash algorithms.\n * \n * Copyright (c) 2008 Herbert Xu <herbert@gondor.apana.org.au>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License as published by the Free\n * Software Foundation; either version 2 of the License, or (at your option) \n * any later version.\n *\n */\n\n#ifndef _CRYPTO_INTERNAL_HASH_H\n#define _CRYPTO_INTERNAL_HASH_H\n\n#include <crypto/algapi.h>\n#include <crypto/hash.h>\n\nstruct ahash_request;\nstruct scatterlist;\n\nstruct crypto_hash_walk {\n\tchar *data;\n\n\tunsigned int offset;\n\tunsigned int alignmask;\n\n\tstruct page *pg;\n\tunsigned int entrylen;\n\n\tunsigned int total;\n\tstruct scatterlist *sg;\n\n\tunsigned int flags;\n};\n\nstruct ahash_instance {\n\tstruct ahash_alg alg;\n};\n\nstruct shash_instance {\n\tstruct shash_alg alg;\n};\n\nstruct crypto_ahash_spawn {\n\tstruct crypto_spawn base;\n};\n\nstruct crypto_shash_spawn {\n\tstruct crypto_spawn base;\n};\n\nextern const struct crypto_type crypto_ahash_type;\n\nint crypto_hash_walk_done(struct crypto_hash_walk *walk, int err);\nint crypto_hash_walk_first(struct ahash_request *req,\n\t\t\t   struct crypto_hash_walk *walk);\nint crypto_ahash_walk_first(struct ahash_request *req,\n\t\t\t   struct crypto_hash_walk *walk);\n\nstatic inline int crypto_ahash_walk_done(struct crypto_hash_walk *walk,\n\t\t\t\t\t int err)\n{\n\treturn crypto_hash_walk_done(walk, err);\n}\n\nstatic inline int crypto_hash_walk_last(struct crypto_hash_walk *walk)\n{\n\treturn !(walk->entrylen | walk->total);\n}\n\nstatic inline int crypto_ahash_walk_last(struct crypto_hash_walk *walk)\n{\n\treturn crypto_hash_walk_last(walk);\n}\n\nint crypto_register_ahash(struct ahash_alg *alg);\nint crypto_unregister_ahash(struct ahash_alg *alg);\nint crypto_register_ahashes(struct ahash_alg *algs, int count);\nvoid crypto_unregister_ahashes(struct ahash_alg *algs, int count);\nint ahash_register_instance(struct crypto_template *tmpl,\n\t\t\t    struct ahash_instance *inst);\nvoid ahash_free_instance(struct crypto_instance *inst);\n\nint shash_no_setkey(struct crypto_shash *tfm, const u8 *key,\n\t\t    unsigned int keylen);\n\nstatic inline bool crypto_shash_alg_has_setkey(struct shash_alg *alg)\n{\n\treturn alg->setkey != shash_no_setkey;\n}\n\nint crypto_init_ahash_spawn(struct crypto_ahash_spawn *spawn,\n\t\t\t    struct hash_alg_common *alg,\n\t\t\t    struct crypto_instance *inst);\n\nstatic inline void crypto_drop_ahash(struct crypto_ahash_spawn *spawn)\n{\n\tcrypto_drop_spawn(&spawn->base);\n}\n\nstruct hash_alg_common *ahash_attr_alg(struct rtattr *rta, u32 type, u32 mask);\n\nint crypto_register_shash(struct shash_alg *alg);\nint crypto_unregister_shash(struct shash_alg *alg);\nint crypto_register_shashes(struct shash_alg *algs, int count);\nint crypto_unregister_shashes(struct shash_alg *algs, int count);\nint shash_register_instance(struct crypto_template *tmpl,\n\t\t\t    struct shash_instance *inst);\nvoid shash_free_instance(struct crypto_instance *inst);\n\nint crypto_init_shash_spawn(struct crypto_shash_spawn *spawn,\n\t\t\t    struct shash_alg *alg,\n\t\t\t    struct crypto_instance *inst);\n\nstatic inline void crypto_drop_shash(struct crypto_shash_spawn *spawn)\n{\n\tcrypto_drop_spawn(&spawn->base);\n}\n\nstruct shash_alg *shash_attr_alg(struct rtattr *rta, u32 type, u32 mask);\n\nint shash_ahash_update(struct ahash_request *req, struct shash_desc *desc);\nint shash_ahash_finup(struct ahash_request *req, struct shash_desc *desc);\nint shash_ahash_digest(struct ahash_request *req, struct shash_desc *desc);\n\nint ahash_mcryptd_update(struct ahash_request *desc);\nint ahash_mcryptd_final(struct ahash_request *desc);\nint ahash_mcryptd_finup(struct ahash_request *desc);\nint ahash_mcryptd_digest(struct ahash_request *desc);\n\nint crypto_init_shash_ops_async(struct crypto_tfm *tfm);\n\nstatic inline void *crypto_ahash_ctx(struct crypto_ahash *tfm)\n{\n\treturn crypto_tfm_ctx(crypto_ahash_tfm(tfm));\n}\n\nstatic inline struct ahash_alg *__crypto_ahash_alg(struct crypto_alg *alg)\n{\n\treturn container_of(__crypto_hash_alg_common(alg), struct ahash_alg,\n\t\t\t    halg);\n}\n\nstatic inline void crypto_ahash_set_reqsize(struct crypto_ahash *tfm,\n\t\t\t\t\t    unsigned int reqsize)\n{\n\ttfm->reqsize = reqsize;\n}\n\nstatic inline struct crypto_instance *ahash_crypto_instance(\n\tstruct ahash_instance *inst)\n{\n\treturn container_of(&inst->alg.halg.base, struct crypto_instance, alg);\n}\n\nstatic inline struct ahash_instance *ahash_instance(\n\tstruct crypto_instance *inst)\n{\n\treturn container_of(&inst->alg, struct ahash_instance, alg.halg.base);\n}\n\nstatic inline void *ahash_instance_ctx(struct ahash_instance *inst)\n{\n\treturn crypto_instance_ctx(ahash_crypto_instance(inst));\n}\n\nstatic inline unsigned int ahash_instance_headroom(void)\n{\n\treturn sizeof(struct ahash_alg) - sizeof(struct crypto_alg);\n}\n\nstatic inline struct ahash_instance *ahash_alloc_instance(\n\tconst char *name, struct crypto_alg *alg)\n{\n\treturn crypto_alloc_instance2(name, alg, ahash_instance_headroom());\n}\n\nstatic inline void ahash_request_complete(struct ahash_request *req, int err)\n{\n\treq->base.complete(&req->base, err);\n}\n\nstatic inline u32 ahash_request_flags(struct ahash_request *req)\n{\n\treturn req->base.flags;\n}\n\nstatic inline struct crypto_ahash *crypto_spawn_ahash(\n\tstruct crypto_ahash_spawn *spawn)\n{\n\treturn crypto_spawn_tfm2(&spawn->base);\n}\n\nstatic inline int ahash_enqueue_request(struct crypto_queue *queue,\n\t\t\t\t\t     struct ahash_request *request)\n{\n\treturn crypto_enqueue_request(queue, &request->base);\n}\n\nstatic inline struct ahash_request *ahash_dequeue_request(\n\tstruct crypto_queue *queue)\n{\n\treturn ahash_request_cast(crypto_dequeue_request(queue));\n}\n\nstatic inline int ahash_tfm_in_queue(struct crypto_queue *queue,\n\t\t\t\t\t  struct crypto_ahash *tfm)\n{\n\treturn crypto_tfm_in_queue(queue, crypto_ahash_tfm(tfm));\n}\n\nstatic inline void *crypto_shash_ctx(struct crypto_shash *tfm)\n{\n\treturn crypto_tfm_ctx(&tfm->base);\n}\n\nstatic inline struct crypto_instance *shash_crypto_instance(\n\tstruct shash_instance *inst)\n{\n\treturn container_of(&inst->alg.base, struct crypto_instance, alg);\n}\n\nstatic inline struct shash_instance *shash_instance(\n\tstruct crypto_instance *inst)\n{\n\treturn container_of(__crypto_shash_alg(&inst->alg),\n\t\t\t    struct shash_instance, alg);\n}\n\nstatic inline void *shash_instance_ctx(struct shash_instance *inst)\n{\n\treturn crypto_instance_ctx(shash_crypto_instance(inst));\n}\n\nstatic inline struct shash_instance *shash_alloc_instance(\n\tconst char *name, struct crypto_alg *alg)\n{\n\treturn crypto_alloc_instance2(name, alg,\n\t\t\t\t      sizeof(struct shash_alg) - sizeof(*alg));\n}\n\nstatic inline struct crypto_shash *crypto_spawn_shash(\n\tstruct crypto_shash_spawn *spawn)\n{\n\treturn crypto_spawn_tfm2(&spawn->base);\n}\n\nstatic inline void *crypto_shash_ctx_aligned(struct crypto_shash *tfm)\n{\n\treturn crypto_tfm_ctx_aligned(&tfm->base);\n}\n\nstatic inline struct crypto_shash *__crypto_shash_cast(struct crypto_tfm *tfm)\n{\n\treturn container_of(tfm, struct crypto_shash, base);\n}\n\n#endif\t/* _CRYPTO_INTERNAL_HASH_H */\n\n"], "filenames": ["crypto/hmac.c", "crypto/shash.c", "include/crypto/internal/hash.h"], "buggy_code_start_loc": [198, 28, 84], "buggy_code_end_loc": [203, 32, 84], "fixing_code_start_loc": [198, 28, 85], "fixing_code_end_loc": [206, 34, 93], "type": "CWE-787", "message": "The HMAC implementation (crypto/hmac.c) in the Linux kernel before 4.14.8 does not validate that the underlying cryptographic hash algorithm is unkeyed, allowing a local attacker able to use the AF_ALG-based hash interface (CONFIG_CRYPTO_USER_API_HASH) and the SHA-3 hash algorithm (CONFIG_CRYPTO_SHA3) to cause a kernel stack buffer overflow by executing a crafted sequence of system calls that encounter a missing SHA-3 initialization.", "other": {"cve": {"id": "CVE-2017-17806", "sourceIdentifier": "cve@mitre.org", "published": "2017-12-20T23:29:00.377", "lastModified": "2023-01-19T16:26:25.123", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "The HMAC implementation (crypto/hmac.c) in the Linux kernel before 4.14.8 does not validate that the underlying cryptographic hash algorithm is unkeyed, allowing a local attacker able to use the AF_ALG-based hash interface (CONFIG_CRYPTO_USER_API_HASH) and the SHA-3 hash algorithm (CONFIG_CRYPTO_SHA3) to cause a kernel stack buffer overflow by executing a crafted sequence of system calls that encounter a missing SHA-3 initialization."}, {"lang": "es", "value": "La implementaci\u00f3n HMAC (crypto/hmac.c) en el kernel de Linux en versiones anteriores a la 4.14.8 no valida que el algoritmo de hash criptogr\u00e1fico subyacente no tenga clave, lo que permite que un atacante local capaz de utilizar la interfaz hash basada en AF_ALG (CONFIG_CRYPTO_USER_API_HASH) y el algoritmo hash basado en SHA-3 (CONFIG_CRYPTO_SHA3) provoque un desbordamiento de b\u00fafer de pila de kernel ejecutando una secuencia manipulada de llamadas al sistema para encontrar una inicializaci\u00f3n SHA-3 ausente."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:C/I:C/A:C", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "COMPLETE", "integrityImpact": "COMPLETE", "availabilityImpact": "COMPLETE", "baseScore": 7.2}, "baseSeverity": "HIGH", "exploitabilityScore": 3.9, "impactScore": 10.0, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-787"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndExcluding": "3.2.97", "matchCriteriaId": "3B86887F-D4E3-4F47-98BC-697EE11A74CE"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.3", "versionEndExcluding": "3.16.52", "matchCriteriaId": "B97C01AC-F470-4190-AC38-30DE3DFDCCAC"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.17", "versionEndExcluding": "3.18.89", "matchCriteriaId": "BBA93779-9E2C-4161-9DC3-569588ECB754"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.19", "versionEndExcluding": "4.1.49", "matchCriteriaId": "F3C1F309-D954-4BB7-AC02-30FC58BE76F9"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.2", "versionEndExcluding": "4.4.107", "matchCriteriaId": "EEE9C869-86BF-4DBF-8EBB-FC14AD5A7019"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.5", "versionEndExcluding": "4.9.71", "matchCriteriaId": "A25E81B4-C400-4932-8841-3116C21DF3DF"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.10", "versionEndExcluding": "4.14.8", "matchCriteriaId": "342F6BB8-126D-4E05-915F-4CDC362F5C51"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "C11E6FB0-C8C0-4527-9AA0-CB9B316F8F43"}, {"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:9.0:*:*:*:*:*:*:*", "matchCriteriaId": "DEECE5FC-CACF-4496-A3E7-164736409252"}, {"vulnerable": true, "criteria": "cpe:2.3:o:opensuse:leap:42.2:*:*:*:*:*:*:*", "matchCriteriaId": "1EA337A3-B9A3-4962-B8BD-8E0C7C5B28EB"}, {"vulnerable": true, "criteria": "cpe:2.3:o:opensuse_project:leap:42.3:*:*:*:*:*:*:*", "matchCriteriaId": "D8CD4569-8BFA-4654-9CAB-2882D4CAE57D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:suse:linux_enterprise_desktop:12:sp2:*:*:*:*:*:*", "matchCriteriaId": "57CFAD92-EECD-417D-ADDB-8178C320B204"}, {"vulnerable": true, "criteria": "cpe:2.3:o:suse:linux_enterprise_desktop:12:sp3:*:*:*:*:*:*", "matchCriteriaId": "C1DCD75C-9775-4922-8A44-C4707C640946"}, {"vulnerable": true, "criteria": "cpe:2.3:o:suse:linux_enterprise_server:11:extra:*:*:*:*:*:*", "matchCriteriaId": "AD1AEFA5-9D43-4DD2-9088-7B37D5F220C4"}, {"vulnerable": true, "criteria": "cpe:2.3:o:suse:linux_enterprise_server:11:sp4:*:*:*:*:*:*", "matchCriteriaId": "55C5561F-BE86-4EEA-99D4-8697F8BD9DFE"}, {"vulnerable": true, "criteria": "cpe:2.3:o:suse:linux_enterprise_server:12:sp2:*:*:*:*:*:*", "matchCriteriaId": "F84B2729-7B52-4505-9656-1BD31B980705"}, {"vulnerable": true, "criteria": "cpe:2.3:o:suse:linux_enterprise_server:12:sp3:*:*:*:*:*:*", "matchCriteriaId": "631BB7F0-5F27-4244-8E72-428DA824C75B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:suse:linux_enterprise_server_for_raspberry_pi:12:sp2:*:*:*:*:*:*", "matchCriteriaId": "4605D055-EA6E-4C90-9277-AC067E1BD02D"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:12.04:*:*:*:-:*:*:*", "matchCriteriaId": "CB66DB75-2B16-4EBF-9B93-CE49D8086E41"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:14.04:*:*:*:esm:*:*:*", "matchCriteriaId": "815D70A8-47D3-459C-A32C-9FEACA0659D1"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:16.04:*:*:*:esm:*:*:*", "matchCriteriaId": "7A5301BF-1402-4BE0-A0F8-69FBE79BC6D6"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:17.10:*:*:*:*:*:*:*", "matchCriteriaId": "9070C9D8-A14A-467F-8253-33B966C16886"}]}]}], "references": [{"url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=af3ff8045bbf3e32f1a448542e73abb4c8ceb6f1", "source": "cve@mitre.org", "tags": ["Patch"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2018-01/msg00006.html", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2018-01/msg00007.html", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2018-01/msg00008.html", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2018-01/msg00014.html", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2018-01/msg00016.html", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Third Party Advisory"]}, {"url": "http://www.securityfocus.com/bid/102293", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://access.redhat.com/errata/RHSA-2018:2948", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/af3ff8045bbf3e32f1a448542e73abb4c8ceb6f1", "source": "cve@mitre.org", "tags": ["Patch"]}, {"url": "https://lists.debian.org/debian-lts-announce/2018/01/msg00004.html", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/3583-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/3583-2/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/3617-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/3617-2/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/3617-3/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/3619-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/3619-2/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/3632-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://www.debian.org/security/2017/dsa-4073", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://www.debian.org/security/2018/dsa-4082", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://www.kernel.org/pub/linux/kernel/v4.x/ChangeLog-4.14.8", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Release Notes"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/af3ff8045bbf3e32f1a448542e73abb4c8ceb6f1"}}
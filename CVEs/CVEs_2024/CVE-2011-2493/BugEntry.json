{"buggy_code": ["/*\n *  linux/fs/ext4/super.c\n *\n * Copyright (C) 1992, 1993, 1994, 1995\n * Remy Card (card@masi.ibp.fr)\n * Laboratoire MASI - Institut Blaise Pascal\n * Universite Pierre et Marie Curie (Paris VI)\n *\n *  from\n *\n *  linux/fs/minix/inode.c\n *\n *  Copyright (C) 1991, 1992  Linus Torvalds\n *\n *  Big-endian to little-endian byte-swapping/bitmaps by\n *        David S. Miller (davem@caip.rutgers.edu), 1995\n */\n\n#include <linux/module.h>\n#include <linux/string.h>\n#include <linux/fs.h>\n#include <linux/time.h>\n#include <linux/vmalloc.h>\n#include <linux/jbd2.h>\n#include <linux/slab.h>\n#include <linux/init.h>\n#include <linux/blkdev.h>\n#include <linux/parser.h>\n#include <linux/buffer_head.h>\n#include <linux/exportfs.h>\n#include <linux/vfs.h>\n#include <linux/random.h>\n#include <linux/mount.h>\n#include <linux/namei.h>\n#include <linux/quotaops.h>\n#include <linux/seq_file.h>\n#include <linux/proc_fs.h>\n#include <linux/ctype.h>\n#include <linux/log2.h>\n#include <linux/crc16.h>\n#include <asm/uaccess.h>\n\n#include <linux/kthread.h>\n#include <linux/freezer.h>\n\n#include \"ext4.h\"\n#include \"ext4_jbd2.h\"\n#include \"xattr.h\"\n#include \"acl.h\"\n#include \"mballoc.h\"\n\n#define CREATE_TRACE_POINTS\n#include <trace/events/ext4.h>\n\nstatic struct proc_dir_entry *ext4_proc_root;\nstatic struct kset *ext4_kset;\nstatic struct ext4_lazy_init *ext4_li_info;\nstatic struct mutex ext4_li_mtx;\nstatic struct ext4_features *ext4_feat;\n\nstatic int ext4_load_journal(struct super_block *, struct ext4_super_block *,\n\t\t\t     unsigned long journal_devnum);\nstatic int ext4_commit_super(struct super_block *sb, int sync);\nstatic void ext4_mark_recovery_complete(struct super_block *sb,\n\t\t\t\t\tstruct ext4_super_block *es);\nstatic void ext4_clear_journal_err(struct super_block *sb,\n\t\t\t\t   struct ext4_super_block *es);\nstatic int ext4_sync_fs(struct super_block *sb, int wait);\nstatic const char *ext4_decode_error(struct super_block *sb, int errno,\n\t\t\t\t     char nbuf[16]);\nstatic int ext4_remount(struct super_block *sb, int *flags, char *data);\nstatic int ext4_statfs(struct dentry *dentry, struct kstatfs *buf);\nstatic int ext4_unfreeze(struct super_block *sb);\nstatic void ext4_write_super(struct super_block *sb);\nstatic int ext4_freeze(struct super_block *sb);\nstatic struct dentry *ext4_mount(struct file_system_type *fs_type, int flags,\n\t\t       const char *dev_name, void *data);\nstatic int ext4_feature_set_ok(struct super_block *sb, int readonly);\nstatic void ext4_destroy_lazyinit_thread(void);\nstatic void ext4_unregister_li_request(struct super_block *sb);\nstatic void ext4_clear_request_list(void);\n\n#if !defined(CONFIG_EXT3_FS) && !defined(CONFIG_EXT3_FS_MODULE) && defined(CONFIG_EXT4_USE_FOR_EXT23)\nstatic struct file_system_type ext3_fs_type = {\n\t.owner\t\t= THIS_MODULE,\n\t.name\t\t= \"ext3\",\n\t.mount\t\t= ext4_mount,\n\t.kill_sb\t= kill_block_super,\n\t.fs_flags\t= FS_REQUIRES_DEV,\n};\n#define IS_EXT3_SB(sb) ((sb)->s_bdev->bd_holder == &ext3_fs_type)\n#else\n#define IS_EXT3_SB(sb) (0)\n#endif\n\next4_fsblk_t ext4_block_bitmap(struct super_block *sb,\n\t\t\t       struct ext4_group_desc *bg)\n{\n\treturn le32_to_cpu(bg->bg_block_bitmap_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (ext4_fsblk_t)le32_to_cpu(bg->bg_block_bitmap_hi) << 32 : 0);\n}\n\next4_fsblk_t ext4_inode_bitmap(struct super_block *sb,\n\t\t\t       struct ext4_group_desc *bg)\n{\n\treturn le32_to_cpu(bg->bg_inode_bitmap_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (ext4_fsblk_t)le32_to_cpu(bg->bg_inode_bitmap_hi) << 32 : 0);\n}\n\next4_fsblk_t ext4_inode_table(struct super_block *sb,\n\t\t\t      struct ext4_group_desc *bg)\n{\n\treturn le32_to_cpu(bg->bg_inode_table_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (ext4_fsblk_t)le32_to_cpu(bg->bg_inode_table_hi) << 32 : 0);\n}\n\n__u32 ext4_free_blks_count(struct super_block *sb,\n\t\t\t      struct ext4_group_desc *bg)\n{\n\treturn le16_to_cpu(bg->bg_free_blocks_count_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (__u32)le16_to_cpu(bg->bg_free_blocks_count_hi) << 16 : 0);\n}\n\n__u32 ext4_free_inodes_count(struct super_block *sb,\n\t\t\t      struct ext4_group_desc *bg)\n{\n\treturn le16_to_cpu(bg->bg_free_inodes_count_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (__u32)le16_to_cpu(bg->bg_free_inodes_count_hi) << 16 : 0);\n}\n\n__u32 ext4_used_dirs_count(struct super_block *sb,\n\t\t\t      struct ext4_group_desc *bg)\n{\n\treturn le16_to_cpu(bg->bg_used_dirs_count_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (__u32)le16_to_cpu(bg->bg_used_dirs_count_hi) << 16 : 0);\n}\n\n__u32 ext4_itable_unused_count(struct super_block *sb,\n\t\t\t      struct ext4_group_desc *bg)\n{\n\treturn le16_to_cpu(bg->bg_itable_unused_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (__u32)le16_to_cpu(bg->bg_itable_unused_hi) << 16 : 0);\n}\n\nvoid ext4_block_bitmap_set(struct super_block *sb,\n\t\t\t   struct ext4_group_desc *bg, ext4_fsblk_t blk)\n{\n\tbg->bg_block_bitmap_lo = cpu_to_le32((u32)blk);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_block_bitmap_hi = cpu_to_le32(blk >> 32);\n}\n\nvoid ext4_inode_bitmap_set(struct super_block *sb,\n\t\t\t   struct ext4_group_desc *bg, ext4_fsblk_t blk)\n{\n\tbg->bg_inode_bitmap_lo  = cpu_to_le32((u32)blk);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_inode_bitmap_hi = cpu_to_le32(blk >> 32);\n}\n\nvoid ext4_inode_table_set(struct super_block *sb,\n\t\t\t  struct ext4_group_desc *bg, ext4_fsblk_t blk)\n{\n\tbg->bg_inode_table_lo = cpu_to_le32((u32)blk);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_inode_table_hi = cpu_to_le32(blk >> 32);\n}\n\nvoid ext4_free_blks_set(struct super_block *sb,\n\t\t\t  struct ext4_group_desc *bg, __u32 count)\n{\n\tbg->bg_free_blocks_count_lo = cpu_to_le16((__u16)count);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_free_blocks_count_hi = cpu_to_le16(count >> 16);\n}\n\nvoid ext4_free_inodes_set(struct super_block *sb,\n\t\t\t  struct ext4_group_desc *bg, __u32 count)\n{\n\tbg->bg_free_inodes_count_lo = cpu_to_le16((__u16)count);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_free_inodes_count_hi = cpu_to_le16(count >> 16);\n}\n\nvoid ext4_used_dirs_set(struct super_block *sb,\n\t\t\t  struct ext4_group_desc *bg, __u32 count)\n{\n\tbg->bg_used_dirs_count_lo = cpu_to_le16((__u16)count);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_used_dirs_count_hi = cpu_to_le16(count >> 16);\n}\n\nvoid ext4_itable_unused_set(struct super_block *sb,\n\t\t\t  struct ext4_group_desc *bg, __u32 count)\n{\n\tbg->bg_itable_unused_lo = cpu_to_le16((__u16)count);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_itable_unused_hi = cpu_to_le16(count >> 16);\n}\n\n\n/* Just increment the non-pointer handle value */\nstatic handle_t *ext4_get_nojournal(void)\n{\n\thandle_t *handle = current->journal_info;\n\tunsigned long ref_cnt = (unsigned long)handle;\n\n\tBUG_ON(ref_cnt >= EXT4_NOJOURNAL_MAX_REF_COUNT);\n\n\tref_cnt++;\n\thandle = (handle_t *)ref_cnt;\n\n\tcurrent->journal_info = handle;\n\treturn handle;\n}\n\n\n/* Decrement the non-pointer handle value */\nstatic void ext4_put_nojournal(handle_t *handle)\n{\n\tunsigned long ref_cnt = (unsigned long)handle;\n\n\tBUG_ON(ref_cnt == 0);\n\n\tref_cnt--;\n\thandle = (handle_t *)ref_cnt;\n\n\tcurrent->journal_info = handle;\n}\n\n/*\n * Wrappers for jbd2_journal_start/end.\n *\n * The only special thing we need to do here is to make sure that all\n * journal_end calls result in the superblock being marked dirty, so\n * that sync() will call the filesystem's write_super callback if\n * appropriate.\n */\nhandle_t *ext4_journal_start_sb(struct super_block *sb, int nblocks)\n{\n\tjournal_t *journal;\n\n\tif (sb->s_flags & MS_RDONLY)\n\t\treturn ERR_PTR(-EROFS);\n\n\tvfs_check_frozen(sb, SB_FREEZE_TRANS);\n\t/* Special case here: if the journal has aborted behind our\n\t * backs (eg. EIO in the commit thread), then we still need to\n\t * take the FS itself readonly cleanly. */\n\tjournal = EXT4_SB(sb)->s_journal;\n\tif (journal) {\n\t\tif (is_journal_aborted(journal)) {\n\t\t\text4_abort(sb, \"Detected aborted journal\");\n\t\t\treturn ERR_PTR(-EROFS);\n\t\t}\n\t\treturn jbd2_journal_start(journal, nblocks);\n\t}\n\treturn ext4_get_nojournal();\n}\n\n/*\n * The only special thing we need to do here is to make sure that all\n * jbd2_journal_stop calls result in the superblock being marked dirty, so\n * that sync() will call the filesystem's write_super callback if\n * appropriate.\n */\nint __ext4_journal_stop(const char *where, unsigned int line, handle_t *handle)\n{\n\tstruct super_block *sb;\n\tint err;\n\tint rc;\n\n\tif (!ext4_handle_valid(handle)) {\n\t\text4_put_nojournal(handle);\n\t\treturn 0;\n\t}\n\tsb = handle->h_transaction->t_journal->j_private;\n\terr = handle->h_err;\n\trc = jbd2_journal_stop(handle);\n\n\tif (!err)\n\t\terr = rc;\n\tif (err)\n\t\t__ext4_std_error(sb, where, line, err);\n\treturn err;\n}\n\nvoid ext4_journal_abort_handle(const char *caller, unsigned int line,\n\t\t\t       const char *err_fn, struct buffer_head *bh,\n\t\t\t       handle_t *handle, int err)\n{\n\tchar nbuf[16];\n\tconst char *errstr = ext4_decode_error(NULL, err, nbuf);\n\n\tBUG_ON(!ext4_handle_valid(handle));\n\n\tif (bh)\n\t\tBUFFER_TRACE(bh, \"abort\");\n\n\tif (!handle->h_err)\n\t\thandle->h_err = err;\n\n\tif (is_handle_aborted(handle))\n\t\treturn;\n\n\tprintk(KERN_ERR \"%s:%d: aborting transaction: %s in %s\\n\",\n\t       caller, line, errstr, err_fn);\n\n\tjbd2_journal_abort_handle(handle);\n}\n\nstatic void __save_error_info(struct super_block *sb, const char *func,\n\t\t\t    unsigned int line)\n{\n\tstruct ext4_super_block *es = EXT4_SB(sb)->s_es;\n\n\tEXT4_SB(sb)->s_mount_state |= EXT4_ERROR_FS;\n\tes->s_state |= cpu_to_le16(EXT4_ERROR_FS);\n\tes->s_last_error_time = cpu_to_le32(get_seconds());\n\tstrncpy(es->s_last_error_func, func, sizeof(es->s_last_error_func));\n\tes->s_last_error_line = cpu_to_le32(line);\n\tif (!es->s_first_error_time) {\n\t\tes->s_first_error_time = es->s_last_error_time;\n\t\tstrncpy(es->s_first_error_func, func,\n\t\t\tsizeof(es->s_first_error_func));\n\t\tes->s_first_error_line = cpu_to_le32(line);\n\t\tes->s_first_error_ino = es->s_last_error_ino;\n\t\tes->s_first_error_block = es->s_last_error_block;\n\t}\n\t/*\n\t * Start the daily error reporting function if it hasn't been\n\t * started already\n\t */\n\tif (!es->s_error_count)\n\t\tmod_timer(&EXT4_SB(sb)->s_err_report, jiffies + 24*60*60*HZ);\n\tes->s_error_count = cpu_to_le32(le32_to_cpu(es->s_error_count) + 1);\n}\n\nstatic void save_error_info(struct super_block *sb, const char *func,\n\t\t\t    unsigned int line)\n{\n\t__save_error_info(sb, func, line);\n\text4_commit_super(sb, 1);\n}\n\n\n/* Deal with the reporting of failure conditions on a filesystem such as\n * inconsistencies detected or read IO failures.\n *\n * On ext2, we can store the error state of the filesystem in the\n * superblock.  That is not possible on ext4, because we may have other\n * write ordering constraints on the superblock which prevent us from\n * writing it out straight away; and given that the journal is about to\n * be aborted, we can't rely on the current, or future, transactions to\n * write out the superblock safely.\n *\n * We'll just use the jbd2_journal_abort() error code to record an error in\n * the journal instead.  On recovery, the journal will complain about\n * that error until we've noted it down and cleared it.\n */\n\nstatic void ext4_handle_error(struct super_block *sb)\n{\n\tif (sb->s_flags & MS_RDONLY)\n\t\treturn;\n\n\tif (!test_opt(sb, ERRORS_CONT)) {\n\t\tjournal_t *journal = EXT4_SB(sb)->s_journal;\n\n\t\tEXT4_SB(sb)->s_mount_flags |= EXT4_MF_FS_ABORTED;\n\t\tif (journal)\n\t\t\tjbd2_journal_abort(journal, -EIO);\n\t}\n\tif (test_opt(sb, ERRORS_RO)) {\n\t\text4_msg(sb, KERN_CRIT, \"Remounting filesystem read-only\");\n\t\tsb->s_flags |= MS_RDONLY;\n\t}\n\tif (test_opt(sb, ERRORS_PANIC))\n\t\tpanic(\"EXT4-fs (device %s): panic forced after error\\n\",\n\t\t\tsb->s_id);\n}\n\nvoid __ext4_error(struct super_block *sb, const char *function,\n\t\t  unsigned int line, const char *fmt, ...)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\n\tva_start(args, fmt);\n\tvaf.fmt = fmt;\n\tvaf.va = &args;\n\tprintk(KERN_CRIT \"EXT4-fs error (device %s): %s:%d: comm %s: %pV\\n\",\n\t       sb->s_id, function, line, current->comm, &vaf);\n\tva_end(args);\n\n\text4_handle_error(sb);\n}\n\nvoid ext4_error_inode(struct inode *inode, const char *function,\n\t\t      unsigned int line, ext4_fsblk_t block,\n\t\t      const char *fmt, ...)\n{\n\tva_list args;\n\tstruct va_format vaf;\n\tstruct ext4_super_block *es = EXT4_SB(inode->i_sb)->s_es;\n\n\tes->s_last_error_ino = cpu_to_le32(inode->i_ino);\n\tes->s_last_error_block = cpu_to_le64(block);\n\tsave_error_info(inode->i_sb, function, line);\n\tva_start(args, fmt);\n\tvaf.fmt = fmt;\n\tvaf.va = &args;\n\tprintk(KERN_CRIT \"EXT4-fs error (device %s): %s:%d: inode #%lu: \",\n\t       inode->i_sb->s_id, function, line, inode->i_ino);\n\tif (block)\n\t\tprintk(KERN_CONT \"block %llu: \", block);\n\tprintk(KERN_CONT \"comm %s: %pV\\n\", current->comm, &vaf);\n\tva_end(args);\n\n\text4_handle_error(inode->i_sb);\n}\n\nvoid ext4_error_file(struct file *file, const char *function,\n\t\t     unsigned int line, ext4_fsblk_t block,\n\t\t     const char *fmt, ...)\n{\n\tva_list args;\n\tstruct va_format vaf;\n\tstruct ext4_super_block *es;\n\tstruct inode *inode = file->f_dentry->d_inode;\n\tchar pathname[80], *path;\n\n\tes = EXT4_SB(inode->i_sb)->s_es;\n\tes->s_last_error_ino = cpu_to_le32(inode->i_ino);\n\tsave_error_info(inode->i_sb, function, line);\n\tpath = d_path(&(file->f_path), pathname, sizeof(pathname));\n\tif (IS_ERR(path))\n\t\tpath = \"(unknown)\";\n\tprintk(KERN_CRIT\n\t       \"EXT4-fs error (device %s): %s:%d: inode #%lu: \",\n\t       inode->i_sb->s_id, function, line, inode->i_ino);\n\tif (block)\n\t\tprintk(KERN_CONT \"block %llu: \", block);\n\tva_start(args, fmt);\n\tvaf.fmt = fmt;\n\tvaf.va = &args;\n\tprintk(KERN_CONT \"comm %s: path %s: %pV\\n\", current->comm, path, &vaf);\n\tva_end(args);\n\n\text4_handle_error(inode->i_sb);\n}\n\nstatic const char *ext4_decode_error(struct super_block *sb, int errno,\n\t\t\t\t     char nbuf[16])\n{\n\tchar *errstr = NULL;\n\n\tswitch (errno) {\n\tcase -EIO:\n\t\terrstr = \"IO failure\";\n\t\tbreak;\n\tcase -ENOMEM:\n\t\terrstr = \"Out of memory\";\n\t\tbreak;\n\tcase -EROFS:\n\t\tif (!sb || (EXT4_SB(sb)->s_journal &&\n\t\t\t    EXT4_SB(sb)->s_journal->j_flags & JBD2_ABORT))\n\t\t\terrstr = \"Journal has aborted\";\n\t\telse\n\t\t\terrstr = \"Readonly filesystem\";\n\t\tbreak;\n\tdefault:\n\t\t/* If the caller passed in an extra buffer for unknown\n\t\t * errors, textualise them now.  Else we just return\n\t\t * NULL. */\n\t\tif (nbuf) {\n\t\t\t/* Check for truncated error codes... */\n\t\t\tif (snprintf(nbuf, 16, \"error %d\", -errno) >= 0)\n\t\t\t\terrstr = nbuf;\n\t\t}\n\t\tbreak;\n\t}\n\n\treturn errstr;\n}\n\n/* __ext4_std_error decodes expected errors from journaling functions\n * automatically and invokes the appropriate error response.  */\n\nvoid __ext4_std_error(struct super_block *sb, const char *function,\n\t\t      unsigned int line, int errno)\n{\n\tchar nbuf[16];\n\tconst char *errstr;\n\n\t/* Special case: if the error is EROFS, and we're not already\n\t * inside a transaction, then there's really no point in logging\n\t * an error. */\n\tif (errno == -EROFS && journal_current_handle() == NULL &&\n\t    (sb->s_flags & MS_RDONLY))\n\t\treturn;\n\n\terrstr = ext4_decode_error(sb, errno, nbuf);\n\tprintk(KERN_CRIT \"EXT4-fs error (device %s) in %s:%d: %s\\n\",\n\t       sb->s_id, function, line, errstr);\n\tsave_error_info(sb, function, line);\n\n\text4_handle_error(sb);\n}\n\n/*\n * ext4_abort is a much stronger failure handler than ext4_error.  The\n * abort function may be used to deal with unrecoverable failures such\n * as journal IO errors or ENOMEM at a critical moment in log management.\n *\n * We unconditionally force the filesystem into an ABORT|READONLY state,\n * unless the error response on the fs has been set to panic in which\n * case we take the easy way out and panic immediately.\n */\n\nvoid __ext4_abort(struct super_block *sb, const char *function,\n\t\tunsigned int line, const char *fmt, ...)\n{\n\tva_list args;\n\n\tsave_error_info(sb, function, line);\n\tva_start(args, fmt);\n\tprintk(KERN_CRIT \"EXT4-fs error (device %s): %s:%d: \", sb->s_id,\n\t       function, line);\n\tvprintk(fmt, args);\n\tprintk(\"\\n\");\n\tva_end(args);\n\n\tif ((sb->s_flags & MS_RDONLY) == 0) {\n\t\text4_msg(sb, KERN_CRIT, \"Remounting filesystem read-only\");\n\t\tsb->s_flags |= MS_RDONLY;\n\t\tEXT4_SB(sb)->s_mount_flags |= EXT4_MF_FS_ABORTED;\n\t\tif (EXT4_SB(sb)->s_journal)\n\t\t\tjbd2_journal_abort(EXT4_SB(sb)->s_journal, -EIO);\n\t\tsave_error_info(sb, function, line);\n\t}\n\tif (test_opt(sb, ERRORS_PANIC))\n\t\tpanic(\"EXT4-fs panic from previous error\\n\");\n}\n\nvoid ext4_msg(struct super_block *sb, const char *prefix, const char *fmt, ...)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\n\tva_start(args, fmt);\n\tvaf.fmt = fmt;\n\tvaf.va = &args;\n\tprintk(\"%sEXT4-fs (%s): %pV\\n\", prefix, sb->s_id, &vaf);\n\tva_end(args);\n}\n\nvoid __ext4_warning(struct super_block *sb, const char *function,\n\t\t    unsigned int line, const char *fmt, ...)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\n\tva_start(args, fmt);\n\tvaf.fmt = fmt;\n\tvaf.va = &args;\n\tprintk(KERN_WARNING \"EXT4-fs warning (device %s): %s:%d: %pV\\n\",\n\t       sb->s_id, function, line, &vaf);\n\tva_end(args);\n}\n\nvoid __ext4_grp_locked_error(const char *function, unsigned int line,\n\t\t\t     struct super_block *sb, ext4_group_t grp,\n\t\t\t     unsigned long ino, ext4_fsblk_t block,\n\t\t\t     const char *fmt, ...)\n__releases(bitlock)\n__acquires(bitlock)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\tstruct ext4_super_block *es = EXT4_SB(sb)->s_es;\n\n\tes->s_last_error_ino = cpu_to_le32(ino);\n\tes->s_last_error_block = cpu_to_le64(block);\n\t__save_error_info(sb, function, line);\n\n\tva_start(args, fmt);\n\n\tvaf.fmt = fmt;\n\tvaf.va = &args;\n\tprintk(KERN_CRIT \"EXT4-fs error (device %s): %s:%d: group %u, \",\n\t       sb->s_id, function, line, grp);\n\tif (ino)\n\t\tprintk(KERN_CONT \"inode %lu: \", ino);\n\tif (block)\n\t\tprintk(KERN_CONT \"block %llu:\", (unsigned long long) block);\n\tprintk(KERN_CONT \"%pV\\n\", &vaf);\n\tva_end(args);\n\n\tif (test_opt(sb, ERRORS_CONT)) {\n\t\text4_commit_super(sb, 0);\n\t\treturn;\n\t}\n\n\text4_unlock_group(sb, grp);\n\text4_handle_error(sb);\n\t/*\n\t * We only get here in the ERRORS_RO case; relocking the group\n\t * may be dangerous, but nothing bad will happen since the\n\t * filesystem will have already been marked read/only and the\n\t * journal has been aborted.  We return 1 as a hint to callers\n\t * who might what to use the return value from\n\t * ext4_grp_locked_error() to distinguish beween the\n\t * ERRORS_CONT and ERRORS_RO case, and perhaps return more\n\t * aggressively from the ext4 function in question, with a\n\t * more appropriate error code.\n\t */\n\text4_lock_group(sb, grp);\n\treturn;\n}\n\nvoid ext4_update_dynamic_rev(struct super_block *sb)\n{\n\tstruct ext4_super_block *es = EXT4_SB(sb)->s_es;\n\n\tif (le32_to_cpu(es->s_rev_level) > EXT4_GOOD_OLD_REV)\n\t\treturn;\n\n\text4_warning(sb,\n\t\t     \"updating to rev %d because of new feature flag, \"\n\t\t     \"running e2fsck is recommended\",\n\t\t     EXT4_DYNAMIC_REV);\n\n\tes->s_first_ino = cpu_to_le32(EXT4_GOOD_OLD_FIRST_INO);\n\tes->s_inode_size = cpu_to_le16(EXT4_GOOD_OLD_INODE_SIZE);\n\tes->s_rev_level = cpu_to_le32(EXT4_DYNAMIC_REV);\n\t/* leave es->s_feature_*compat flags alone */\n\t/* es->s_uuid will be set by e2fsck if empty */\n\n\t/*\n\t * The rest of the superblock fields should be zero, and if not it\n\t * means they are likely already in use, so leave them alone.  We\n\t * can leave it up to e2fsck to clean up any inconsistencies there.\n\t */\n}\n\n/*\n * Open the external journal device\n */\nstatic struct block_device *ext4_blkdev_get(dev_t dev, struct super_block *sb)\n{\n\tstruct block_device *bdev;\n\tchar b[BDEVNAME_SIZE];\n\n\tbdev = blkdev_get_by_dev(dev, FMODE_READ|FMODE_WRITE|FMODE_EXCL, sb);\n\tif (IS_ERR(bdev))\n\t\tgoto fail;\n\treturn bdev;\n\nfail:\n\text4_msg(sb, KERN_ERR, \"failed to open journal device %s: %ld\",\n\t\t\t__bdevname(dev, b), PTR_ERR(bdev));\n\treturn NULL;\n}\n\n/*\n * Release the journal device\n */\nstatic int ext4_blkdev_put(struct block_device *bdev)\n{\n\treturn blkdev_put(bdev, FMODE_READ|FMODE_WRITE|FMODE_EXCL);\n}\n\nstatic int ext4_blkdev_remove(struct ext4_sb_info *sbi)\n{\n\tstruct block_device *bdev;\n\tint ret = -ENODEV;\n\n\tbdev = sbi->journal_bdev;\n\tif (bdev) {\n\t\tret = ext4_blkdev_put(bdev);\n\t\tsbi->journal_bdev = NULL;\n\t}\n\treturn ret;\n}\n\nstatic inline struct inode *orphan_list_entry(struct list_head *l)\n{\n\treturn &list_entry(l, struct ext4_inode_info, i_orphan)->vfs_inode;\n}\n\nstatic void dump_orphan_list(struct super_block *sb, struct ext4_sb_info *sbi)\n{\n\tstruct list_head *l;\n\n\text4_msg(sb, KERN_ERR, \"sb orphan head is %d\",\n\t\t le32_to_cpu(sbi->s_es->s_last_orphan));\n\n\tprintk(KERN_ERR \"sb_info orphan list:\\n\");\n\tlist_for_each(l, &sbi->s_orphan) {\n\t\tstruct inode *inode = orphan_list_entry(l);\n\t\tprintk(KERN_ERR \"  \"\n\t\t       \"inode %s:%lu at %p: mode %o, nlink %d, next %d\\n\",\n\t\t       inode->i_sb->s_id, inode->i_ino, inode,\n\t\t       inode->i_mode, inode->i_nlink,\n\t\t       NEXT_ORPHAN(inode));\n\t}\n}\n\nstatic void ext4_put_super(struct super_block *sb)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_super_block *es = sbi->s_es;\n\tint i, err;\n\n\text4_unregister_li_request(sb);\n\tdquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);\n\n\tflush_workqueue(sbi->dio_unwritten_wq);\n\tdestroy_workqueue(sbi->dio_unwritten_wq);\n\n\tlock_super(sb);\n\tif (sb->s_dirt)\n\t\text4_commit_super(sb, 1);\n\n\tif (sbi->s_journal) {\n\t\terr = jbd2_journal_destroy(sbi->s_journal);\n\t\tsbi->s_journal = NULL;\n\t\tif (err < 0)\n\t\t\text4_abort(sb, \"Couldn't clean up the journal\");\n\t}\n\n\tdel_timer(&sbi->s_err_report);\n\text4_release_system_zone(sb);\n\text4_mb_release(sb);\n\text4_ext_release(sb);\n\text4_xattr_put_super(sb);\n\n\tif (!(sb->s_flags & MS_RDONLY)) {\n\t\tEXT4_CLEAR_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_RECOVER);\n\t\tes->s_state = cpu_to_le16(sbi->s_mount_state);\n\t\text4_commit_super(sb, 1);\n\t}\n\tif (sbi->s_proc) {\n\t\tremove_proc_entry(sb->s_id, ext4_proc_root);\n\t}\n\tkobject_del(&sbi->s_kobj);\n\n\tfor (i = 0; i < sbi->s_gdb_count; i++)\n\t\tbrelse(sbi->s_group_desc[i]);\n\tkfree(sbi->s_group_desc);\n\tif (is_vmalloc_addr(sbi->s_flex_groups))\n\t\tvfree(sbi->s_flex_groups);\n\telse\n\t\tkfree(sbi->s_flex_groups);\n\tpercpu_counter_destroy(&sbi->s_freeblocks_counter);\n\tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n\tpercpu_counter_destroy(&sbi->s_dirs_counter);\n\tpercpu_counter_destroy(&sbi->s_dirtyblocks_counter);\n\tbrelse(sbi->s_sbh);\n#ifdef CONFIG_QUOTA\n\tfor (i = 0; i < MAXQUOTAS; i++)\n\t\tkfree(sbi->s_qf_names[i]);\n#endif\n\n\t/* Debugging code just in case the in-memory inode orphan list\n\t * isn't empty.  The on-disk one can be non-empty if we've\n\t * detected an error and taken the fs readonly, but the\n\t * in-memory list had better be clean by this point. */\n\tif (!list_empty(&sbi->s_orphan))\n\t\tdump_orphan_list(sb, sbi);\n\tJ_ASSERT(list_empty(&sbi->s_orphan));\n\n\tinvalidate_bdev(sb->s_bdev);\n\tif (sbi->journal_bdev && sbi->journal_bdev != sb->s_bdev) {\n\t\t/*\n\t\t * Invalidate the journal device's buffers.  We don't want them\n\t\t * floating about in memory - the physical journal device may\n\t\t * hotswapped, and it breaks the `ro-after' testing code.\n\t\t */\n\t\tsync_blockdev(sbi->journal_bdev);\n\t\tinvalidate_bdev(sbi->journal_bdev);\n\t\text4_blkdev_remove(sbi);\n\t}\n\tsb->s_fs_info = NULL;\n\t/*\n\t * Now that we are completely done shutting down the\n\t * superblock, we need to actually destroy the kobject.\n\t */\n\tunlock_super(sb);\n\tkobject_put(&sbi->s_kobj);\n\twait_for_completion(&sbi->s_kobj_unregister);\n\tkfree(sbi->s_blockgroup_lock);\n\tkfree(sbi);\n}\n\nstatic struct kmem_cache *ext4_inode_cachep;\n\n/*\n * Called inside transaction, so use GFP_NOFS\n */\nstatic struct inode *ext4_alloc_inode(struct super_block *sb)\n{\n\tstruct ext4_inode_info *ei;\n\n\tei = kmem_cache_alloc(ext4_inode_cachep, GFP_NOFS);\n\tif (!ei)\n\t\treturn NULL;\n\n\tei->vfs_inode.i_version = 1;\n\tei->vfs_inode.i_data.writeback_index = 0;\n\tmemset(&ei->i_cached_extent, 0, sizeof(struct ext4_ext_cache));\n\tINIT_LIST_HEAD(&ei->i_prealloc_list);\n\tspin_lock_init(&ei->i_prealloc_lock);\n\tei->i_reserved_data_blocks = 0;\n\tei->i_reserved_meta_blocks = 0;\n\tei->i_allocated_meta_blocks = 0;\n\tei->i_da_metadata_calc_len = 0;\n\tspin_lock_init(&(ei->i_block_reservation_lock));\n#ifdef CONFIG_QUOTA\n\tei->i_reserved_quota = 0;\n#endif\n\tei->jinode = NULL;\n\tINIT_LIST_HEAD(&ei->i_completed_io_list);\n\tspin_lock_init(&ei->i_completed_io_lock);\n\tei->cur_aio_dio = NULL;\n\tei->i_sync_tid = 0;\n\tei->i_datasync_tid = 0;\n\tatomic_set(&ei->i_ioend_count, 0);\n\tatomic_set(&ei->i_aiodio_unwritten, 0);\n\n\treturn &ei->vfs_inode;\n}\n\nstatic int ext4_drop_inode(struct inode *inode)\n{\n\tint drop = generic_drop_inode(inode);\n\n\ttrace_ext4_drop_inode(inode, drop);\n\treturn drop;\n}\n\nstatic void ext4_i_callback(struct rcu_head *head)\n{\n\tstruct inode *inode = container_of(head, struct inode, i_rcu);\n\tINIT_LIST_HEAD(&inode->i_dentry);\n\tkmem_cache_free(ext4_inode_cachep, EXT4_I(inode));\n}\n\nstatic void ext4_destroy_inode(struct inode *inode)\n{\n\text4_ioend_wait(inode);\n\tif (!list_empty(&(EXT4_I(inode)->i_orphan))) {\n\t\text4_msg(inode->i_sb, KERN_ERR,\n\t\t\t \"Inode %lu (%p): orphan list check failed!\",\n\t\t\t inode->i_ino, EXT4_I(inode));\n\t\tprint_hex_dump(KERN_INFO, \"\", DUMP_PREFIX_ADDRESS, 16, 4,\n\t\t\t\tEXT4_I(inode), sizeof(struct ext4_inode_info),\n\t\t\t\ttrue);\n\t\tdump_stack();\n\t}\n\tcall_rcu(&inode->i_rcu, ext4_i_callback);\n}\n\nstatic void init_once(void *foo)\n{\n\tstruct ext4_inode_info *ei = (struct ext4_inode_info *) foo;\n\n\tINIT_LIST_HEAD(&ei->i_orphan);\n#ifdef CONFIG_EXT4_FS_XATTR\n\tinit_rwsem(&ei->xattr_sem);\n#endif\n\tinit_rwsem(&ei->i_data_sem);\n\tinode_init_once(&ei->vfs_inode);\n}\n\nstatic int init_inodecache(void)\n{\n\text4_inode_cachep = kmem_cache_create(\"ext4_inode_cache\",\n\t\t\t\t\t     sizeof(struct ext4_inode_info),\n\t\t\t\t\t     0, (SLAB_RECLAIM_ACCOUNT|\n\t\t\t\t\t\tSLAB_MEM_SPREAD),\n\t\t\t\t\t     init_once);\n\tif (ext4_inode_cachep == NULL)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nstatic void destroy_inodecache(void)\n{\n\tkmem_cache_destroy(ext4_inode_cachep);\n}\n\nvoid ext4_clear_inode(struct inode *inode)\n{\n\tinvalidate_inode_buffers(inode);\n\tend_writeback(inode);\n\tdquot_drop(inode);\n\text4_discard_preallocations(inode);\n\tif (EXT4_I(inode)->jinode) {\n\t\tjbd2_journal_release_jbd_inode(EXT4_JOURNAL(inode),\n\t\t\t\t\t       EXT4_I(inode)->jinode);\n\t\tjbd2_free_inode(EXT4_I(inode)->jinode);\n\t\tEXT4_I(inode)->jinode = NULL;\n\t}\n}\n\nstatic inline void ext4_show_quota_options(struct seq_file *seq,\n\t\t\t\t\t   struct super_block *sb)\n{\n#if defined(CONFIG_QUOTA)\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\tif (sbi->s_jquota_fmt) {\n\t\tchar *fmtname = \"\";\n\n\t\tswitch (sbi->s_jquota_fmt) {\n\t\tcase QFMT_VFS_OLD:\n\t\t\tfmtname = \"vfsold\";\n\t\t\tbreak;\n\t\tcase QFMT_VFS_V0:\n\t\t\tfmtname = \"vfsv0\";\n\t\t\tbreak;\n\t\tcase QFMT_VFS_V1:\n\t\t\tfmtname = \"vfsv1\";\n\t\t\tbreak;\n\t\t}\n\t\tseq_printf(seq, \",jqfmt=%s\", fmtname);\n\t}\n\n\tif (sbi->s_qf_names[USRQUOTA])\n\t\tseq_printf(seq, \",usrjquota=%s\", sbi->s_qf_names[USRQUOTA]);\n\n\tif (sbi->s_qf_names[GRPQUOTA])\n\t\tseq_printf(seq, \",grpjquota=%s\", sbi->s_qf_names[GRPQUOTA]);\n\n\tif (test_opt(sb, USRQUOTA))\n\t\tseq_puts(seq, \",usrquota\");\n\n\tif (test_opt(sb, GRPQUOTA))\n\t\tseq_puts(seq, \",grpquota\");\n#endif\n}\n\n/*\n * Show an option if\n *  - it's set to a non-default value OR\n *  - if the per-sb default is different from the global default\n */\nstatic int ext4_show_options(struct seq_file *seq, struct vfsmount *vfs)\n{\n\tint def_errors;\n\tunsigned long def_mount_opts;\n\tstruct super_block *sb = vfs->mnt_sb;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_super_block *es = sbi->s_es;\n\n\tdef_mount_opts = le32_to_cpu(es->s_default_mount_opts);\n\tdef_errors     = le16_to_cpu(es->s_errors);\n\n\tif (sbi->s_sb_block != 1)\n\t\tseq_printf(seq, \",sb=%llu\", sbi->s_sb_block);\n\tif (test_opt(sb, MINIX_DF))\n\t\tseq_puts(seq, \",minixdf\");\n\tif (test_opt(sb, GRPID) && !(def_mount_opts & EXT4_DEFM_BSDGROUPS))\n\t\tseq_puts(seq, \",grpid\");\n\tif (!test_opt(sb, GRPID) && (def_mount_opts & EXT4_DEFM_BSDGROUPS))\n\t\tseq_puts(seq, \",nogrpid\");\n\tif (sbi->s_resuid != EXT4_DEF_RESUID ||\n\t    le16_to_cpu(es->s_def_resuid) != EXT4_DEF_RESUID) {\n\t\tseq_printf(seq, \",resuid=%u\", sbi->s_resuid);\n\t}\n\tif (sbi->s_resgid != EXT4_DEF_RESGID ||\n\t    le16_to_cpu(es->s_def_resgid) != EXT4_DEF_RESGID) {\n\t\tseq_printf(seq, \",resgid=%u\", sbi->s_resgid);\n\t}\n\tif (test_opt(sb, ERRORS_RO)) {\n\t\tif (def_errors == EXT4_ERRORS_PANIC ||\n\t\t    def_errors == EXT4_ERRORS_CONTINUE) {\n\t\t\tseq_puts(seq, \",errors=remount-ro\");\n\t\t}\n\t}\n\tif (test_opt(sb, ERRORS_CONT) && def_errors != EXT4_ERRORS_CONTINUE)\n\t\tseq_puts(seq, \",errors=continue\");\n\tif (test_opt(sb, ERRORS_PANIC) && def_errors != EXT4_ERRORS_PANIC)\n\t\tseq_puts(seq, \",errors=panic\");\n\tif (test_opt(sb, NO_UID32) && !(def_mount_opts & EXT4_DEFM_UID16))\n\t\tseq_puts(seq, \",nouid32\");\n\tif (test_opt(sb, DEBUG) && !(def_mount_opts & EXT4_DEFM_DEBUG))\n\t\tseq_puts(seq, \",debug\");\n\tif (test_opt(sb, OLDALLOC))\n\t\tseq_puts(seq, \",oldalloc\");\n#ifdef CONFIG_EXT4_FS_XATTR\n\tif (test_opt(sb, XATTR_USER))\n\t\tseq_puts(seq, \",user_xattr\");\n\tif (!test_opt(sb, XATTR_USER))\n\t\tseq_puts(seq, \",nouser_xattr\");\n#endif\n#ifdef CONFIG_EXT4_FS_POSIX_ACL\n\tif (test_opt(sb, POSIX_ACL) && !(def_mount_opts & EXT4_DEFM_ACL))\n\t\tseq_puts(seq, \",acl\");\n\tif (!test_opt(sb, POSIX_ACL) && (def_mount_opts & EXT4_DEFM_ACL))\n\t\tseq_puts(seq, \",noacl\");\n#endif\n\tif (sbi->s_commit_interval != JBD2_DEFAULT_MAX_COMMIT_AGE*HZ) {\n\t\tseq_printf(seq, \",commit=%u\",\n\t\t\t   (unsigned) (sbi->s_commit_interval / HZ));\n\t}\n\tif (sbi->s_min_batch_time != EXT4_DEF_MIN_BATCH_TIME) {\n\t\tseq_printf(seq, \",min_batch_time=%u\",\n\t\t\t   (unsigned) sbi->s_min_batch_time);\n\t}\n\tif (sbi->s_max_batch_time != EXT4_DEF_MAX_BATCH_TIME) {\n\t\tseq_printf(seq, \",max_batch_time=%u\",\n\t\t\t   (unsigned) sbi->s_min_batch_time);\n\t}\n\n\t/*\n\t * We're changing the default of barrier mount option, so\n\t * let's always display its mount state so it's clear what its\n\t * status is.\n\t */\n\tseq_puts(seq, \",barrier=\");\n\tseq_puts(seq, test_opt(sb, BARRIER) ? \"1\" : \"0\");\n\tif (test_opt(sb, JOURNAL_ASYNC_COMMIT))\n\t\tseq_puts(seq, \",journal_async_commit\");\n\telse if (test_opt(sb, JOURNAL_CHECKSUM))\n\t\tseq_puts(seq, \",journal_checksum\");\n\tif (test_opt(sb, I_VERSION))\n\t\tseq_puts(seq, \",i_version\");\n\tif (!test_opt(sb, DELALLOC) &&\n\t    !(def_mount_opts & EXT4_DEFM_NODELALLOC))\n\t\tseq_puts(seq, \",nodelalloc\");\n\n\tif (!test_opt(sb, MBLK_IO_SUBMIT))\n\t\tseq_puts(seq, \",nomblk_io_submit\");\n\tif (sbi->s_stripe)\n\t\tseq_printf(seq, \",stripe=%lu\", sbi->s_stripe);\n\t/*\n\t * journal mode get enabled in different ways\n\t * So just print the value even if we didn't specify it\n\t */\n\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA)\n\t\tseq_puts(seq, \",data=journal\");\n\telse if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA)\n\t\tseq_puts(seq, \",data=ordered\");\n\telse if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_WRITEBACK_DATA)\n\t\tseq_puts(seq, \",data=writeback\");\n\n\tif (sbi->s_inode_readahead_blks != EXT4_DEF_INODE_READAHEAD_BLKS)\n\t\tseq_printf(seq, \",inode_readahead_blks=%u\",\n\t\t\t   sbi->s_inode_readahead_blks);\n\n\tif (test_opt(sb, DATA_ERR_ABORT))\n\t\tseq_puts(seq, \",data_err=abort\");\n\n\tif (test_opt(sb, NO_AUTO_DA_ALLOC))\n\t\tseq_puts(seq, \",noauto_da_alloc\");\n\n\tif (test_opt(sb, DISCARD) && !(def_mount_opts & EXT4_DEFM_DISCARD))\n\t\tseq_puts(seq, \",discard\");\n\n\tif (test_opt(sb, NOLOAD))\n\t\tseq_puts(seq, \",norecovery\");\n\n\tif (test_opt(sb, DIOREAD_NOLOCK))\n\t\tseq_puts(seq, \",dioread_nolock\");\n\n\tif (test_opt(sb, BLOCK_VALIDITY) &&\n\t    !(def_mount_opts & EXT4_DEFM_BLOCK_VALIDITY))\n\t\tseq_puts(seq, \",block_validity\");\n\n\tif (!test_opt(sb, INIT_INODE_TABLE))\n\t\tseq_puts(seq, \",noinit_inode_table\");\n\telse if (sbi->s_li_wait_mult)\n\t\tseq_printf(seq, \",init_inode_table=%u\",\n\t\t\t   (unsigned) sbi->s_li_wait_mult);\n\n\text4_show_quota_options(seq, sb);\n\n\treturn 0;\n}\n\nstatic struct inode *ext4_nfs_get_inode(struct super_block *sb,\n\t\t\t\t\tu64 ino, u32 generation)\n{\n\tstruct inode *inode;\n\n\tif (ino < EXT4_FIRST_INO(sb) && ino != EXT4_ROOT_INO)\n\t\treturn ERR_PTR(-ESTALE);\n\tif (ino > le32_to_cpu(EXT4_SB(sb)->s_es->s_inodes_count))\n\t\treturn ERR_PTR(-ESTALE);\n\n\t/* iget isn't really right if the inode is currently unallocated!!\n\t *\n\t * ext4_read_inode will return a bad_inode if the inode had been\n\t * deleted, so we should be safe.\n\t *\n\t * Currently we don't know the generation for parent directory, so\n\t * a generation of 0 means \"accept any\"\n\t */\n\tinode = ext4_iget(sb, ino);\n\tif (IS_ERR(inode))\n\t\treturn ERR_CAST(inode);\n\tif (generation && inode->i_generation != generation) {\n\t\tiput(inode);\n\t\treturn ERR_PTR(-ESTALE);\n\t}\n\n\treturn inode;\n}\n\nstatic struct dentry *ext4_fh_to_dentry(struct super_block *sb, struct fid *fid,\n\t\t\t\t\tint fh_len, int fh_type)\n{\n\treturn generic_fh_to_dentry(sb, fid, fh_len, fh_type,\n\t\t\t\t    ext4_nfs_get_inode);\n}\n\nstatic struct dentry *ext4_fh_to_parent(struct super_block *sb, struct fid *fid,\n\t\t\t\t\tint fh_len, int fh_type)\n{\n\treturn generic_fh_to_parent(sb, fid, fh_len, fh_type,\n\t\t\t\t    ext4_nfs_get_inode);\n}\n\n/*\n * Try to release metadata pages (indirect blocks, directories) which are\n * mapped via the block device.  Since these pages could have journal heads\n * which would prevent try_to_free_buffers() from freeing them, we must use\n * jbd2 layer's try_to_free_buffers() function to release them.\n */\nstatic int bdev_try_to_free_page(struct super_block *sb, struct page *page,\n\t\t\t\t gfp_t wait)\n{\n\tjournal_t *journal = EXT4_SB(sb)->s_journal;\n\n\tWARN_ON(PageChecked(page));\n\tif (!page_has_buffers(page))\n\t\treturn 0;\n\tif (journal)\n\t\treturn jbd2_journal_try_to_free_buffers(journal, page,\n\t\t\t\t\t\t\twait & ~__GFP_WAIT);\n\treturn try_to_free_buffers(page);\n}\n\n#ifdef CONFIG_QUOTA\n#define QTYPE2NAME(t) ((t) == USRQUOTA ? \"user\" : \"group\")\n#define QTYPE2MOPT(on, t) ((t) == USRQUOTA?((on)##USRJQUOTA):((on)##GRPJQUOTA))\n\nstatic int ext4_write_dquot(struct dquot *dquot);\nstatic int ext4_acquire_dquot(struct dquot *dquot);\nstatic int ext4_release_dquot(struct dquot *dquot);\nstatic int ext4_mark_dquot_dirty(struct dquot *dquot);\nstatic int ext4_write_info(struct super_block *sb, int type);\nstatic int ext4_quota_on(struct super_block *sb, int type, int format_id,\n\t\t\t struct path *path);\nstatic int ext4_quota_off(struct super_block *sb, int type);\nstatic int ext4_quota_on_mount(struct super_block *sb, int type);\nstatic ssize_t ext4_quota_read(struct super_block *sb, int type, char *data,\n\t\t\t       size_t len, loff_t off);\nstatic ssize_t ext4_quota_write(struct super_block *sb, int type,\n\t\t\t\tconst char *data, size_t len, loff_t off);\n\nstatic const struct dquot_operations ext4_quota_operations = {\n#ifdef CONFIG_QUOTA\n\t.get_reserved_space = ext4_get_reserved_space,\n#endif\n\t.write_dquot\t= ext4_write_dquot,\n\t.acquire_dquot\t= ext4_acquire_dquot,\n\t.release_dquot\t= ext4_release_dquot,\n\t.mark_dirty\t= ext4_mark_dquot_dirty,\n\t.write_info\t= ext4_write_info,\n\t.alloc_dquot\t= dquot_alloc,\n\t.destroy_dquot\t= dquot_destroy,\n};\n\nstatic const struct quotactl_ops ext4_qctl_operations = {\n\t.quota_on\t= ext4_quota_on,\n\t.quota_off\t= ext4_quota_off,\n\t.quota_sync\t= dquot_quota_sync,\n\t.get_info\t= dquot_get_dqinfo,\n\t.set_info\t= dquot_set_dqinfo,\n\t.get_dqblk\t= dquot_get_dqblk,\n\t.set_dqblk\t= dquot_set_dqblk\n};\n#endif\n\nstatic const struct super_operations ext4_sops = {\n\t.alloc_inode\t= ext4_alloc_inode,\n\t.destroy_inode\t= ext4_destroy_inode,\n\t.write_inode\t= ext4_write_inode,\n\t.dirty_inode\t= ext4_dirty_inode,\n\t.drop_inode\t= ext4_drop_inode,\n\t.evict_inode\t= ext4_evict_inode,\n\t.put_super\t= ext4_put_super,\n\t.sync_fs\t= ext4_sync_fs,\n\t.freeze_fs\t= ext4_freeze,\n\t.unfreeze_fs\t= ext4_unfreeze,\n\t.statfs\t\t= ext4_statfs,\n\t.remount_fs\t= ext4_remount,\n\t.show_options\t= ext4_show_options,\n#ifdef CONFIG_QUOTA\n\t.quota_read\t= ext4_quota_read,\n\t.quota_write\t= ext4_quota_write,\n#endif\n\t.bdev_try_to_free_page = bdev_try_to_free_page,\n};\n\nstatic const struct super_operations ext4_nojournal_sops = {\n\t.alloc_inode\t= ext4_alloc_inode,\n\t.destroy_inode\t= ext4_destroy_inode,\n\t.write_inode\t= ext4_write_inode,\n\t.dirty_inode\t= ext4_dirty_inode,\n\t.drop_inode\t= ext4_drop_inode,\n\t.evict_inode\t= ext4_evict_inode,\n\t.write_super\t= ext4_write_super,\n\t.put_super\t= ext4_put_super,\n\t.statfs\t\t= ext4_statfs,\n\t.remount_fs\t= ext4_remount,\n\t.show_options\t= ext4_show_options,\n#ifdef CONFIG_QUOTA\n\t.quota_read\t= ext4_quota_read,\n\t.quota_write\t= ext4_quota_write,\n#endif\n\t.bdev_try_to_free_page = bdev_try_to_free_page,\n};\n\nstatic const struct export_operations ext4_export_ops = {\n\t.fh_to_dentry = ext4_fh_to_dentry,\n\t.fh_to_parent = ext4_fh_to_parent,\n\t.get_parent = ext4_get_parent,\n};\n\nenum {\n\tOpt_bsd_df, Opt_minix_df, Opt_grpid, Opt_nogrpid,\n\tOpt_resgid, Opt_resuid, Opt_sb, Opt_err_cont, Opt_err_panic, Opt_err_ro,\n\tOpt_nouid32, Opt_debug, Opt_oldalloc, Opt_orlov,\n\tOpt_user_xattr, Opt_nouser_xattr, Opt_acl, Opt_noacl,\n\tOpt_auto_da_alloc, Opt_noauto_da_alloc, Opt_noload, Opt_nobh, Opt_bh,\n\tOpt_commit, Opt_min_batch_time, Opt_max_batch_time,\n\tOpt_journal_update, Opt_journal_dev,\n\tOpt_journal_checksum, Opt_journal_async_commit,\n\tOpt_abort, Opt_data_journal, Opt_data_ordered, Opt_data_writeback,\n\tOpt_data_err_abort, Opt_data_err_ignore,\n\tOpt_usrjquota, Opt_grpjquota, Opt_offusrjquota, Opt_offgrpjquota,\n\tOpt_jqfmt_vfsold, Opt_jqfmt_vfsv0, Opt_jqfmt_vfsv1, Opt_quota,\n\tOpt_noquota, Opt_ignore, Opt_barrier, Opt_nobarrier, Opt_err,\n\tOpt_resize, Opt_usrquota, Opt_grpquota, Opt_i_version,\n\tOpt_stripe, Opt_delalloc, Opt_nodelalloc, Opt_mblk_io_submit,\n\tOpt_nomblk_io_submit, Opt_block_validity, Opt_noblock_validity,\n\tOpt_inode_readahead_blks, Opt_journal_ioprio,\n\tOpt_dioread_nolock, Opt_dioread_lock,\n\tOpt_discard, Opt_nodiscard,\n\tOpt_init_inode_table, Opt_noinit_inode_table,\n};\n\nstatic const match_table_t tokens = {\n\t{Opt_bsd_df, \"bsddf\"},\n\t{Opt_minix_df, \"minixdf\"},\n\t{Opt_grpid, \"grpid\"},\n\t{Opt_grpid, \"bsdgroups\"},\n\t{Opt_nogrpid, \"nogrpid\"},\n\t{Opt_nogrpid, \"sysvgroups\"},\n\t{Opt_resgid, \"resgid=%u\"},\n\t{Opt_resuid, \"resuid=%u\"},\n\t{Opt_sb, \"sb=%u\"},\n\t{Opt_err_cont, \"errors=continue\"},\n\t{Opt_err_panic, \"errors=panic\"},\n\t{Opt_err_ro, \"errors=remount-ro\"},\n\t{Opt_nouid32, \"nouid32\"},\n\t{Opt_debug, \"debug\"},\n\t{Opt_oldalloc, \"oldalloc\"},\n\t{Opt_orlov, \"orlov\"},\n\t{Opt_user_xattr, \"user_xattr\"},\n\t{Opt_nouser_xattr, \"nouser_xattr\"},\n\t{Opt_acl, \"acl\"},\n\t{Opt_noacl, \"noacl\"},\n\t{Opt_noload, \"noload\"},\n\t{Opt_noload, \"norecovery\"},\n\t{Opt_nobh, \"nobh\"},\n\t{Opt_bh, \"bh\"},\n\t{Opt_commit, \"commit=%u\"},\n\t{Opt_min_batch_time, \"min_batch_time=%u\"},\n\t{Opt_max_batch_time, \"max_batch_time=%u\"},\n\t{Opt_journal_update, \"journal=update\"},\n\t{Opt_journal_dev, \"journal_dev=%u\"},\n\t{Opt_journal_checksum, \"journal_checksum\"},\n\t{Opt_journal_async_commit, \"journal_async_commit\"},\n\t{Opt_abort, \"abort\"},\n\t{Opt_data_journal, \"data=journal\"},\n\t{Opt_data_ordered, \"data=ordered\"},\n\t{Opt_data_writeback, \"data=writeback\"},\n\t{Opt_data_err_abort, \"data_err=abort\"},\n\t{Opt_data_err_ignore, \"data_err=ignore\"},\n\t{Opt_offusrjquota, \"usrjquota=\"},\n\t{Opt_usrjquota, \"usrjquota=%s\"},\n\t{Opt_offgrpjquota, \"grpjquota=\"},\n\t{Opt_grpjquota, \"grpjquota=%s\"},\n\t{Opt_jqfmt_vfsold, \"jqfmt=vfsold\"},\n\t{Opt_jqfmt_vfsv0, \"jqfmt=vfsv0\"},\n\t{Opt_jqfmt_vfsv1, \"jqfmt=vfsv1\"},\n\t{Opt_grpquota, \"grpquota\"},\n\t{Opt_noquota, \"noquota\"},\n\t{Opt_quota, \"quota\"},\n\t{Opt_usrquota, \"usrquota\"},\n\t{Opt_barrier, \"barrier=%u\"},\n\t{Opt_barrier, \"barrier\"},\n\t{Opt_nobarrier, \"nobarrier\"},\n\t{Opt_i_version, \"i_version\"},\n\t{Opt_stripe, \"stripe=%u\"},\n\t{Opt_resize, \"resize\"},\n\t{Opt_delalloc, \"delalloc\"},\n\t{Opt_nodelalloc, \"nodelalloc\"},\n\t{Opt_mblk_io_submit, \"mblk_io_submit\"},\n\t{Opt_nomblk_io_submit, \"nomblk_io_submit\"},\n\t{Opt_block_validity, \"block_validity\"},\n\t{Opt_noblock_validity, \"noblock_validity\"},\n\t{Opt_inode_readahead_blks, \"inode_readahead_blks=%u\"},\n\t{Opt_journal_ioprio, \"journal_ioprio=%u\"},\n\t{Opt_auto_da_alloc, \"auto_da_alloc=%u\"},\n\t{Opt_auto_da_alloc, \"auto_da_alloc\"},\n\t{Opt_noauto_da_alloc, \"noauto_da_alloc\"},\n\t{Opt_dioread_nolock, \"dioread_nolock\"},\n\t{Opt_dioread_lock, \"dioread_lock\"},\n\t{Opt_discard, \"discard\"},\n\t{Opt_nodiscard, \"nodiscard\"},\n\t{Opt_init_inode_table, \"init_itable=%u\"},\n\t{Opt_init_inode_table, \"init_itable\"},\n\t{Opt_noinit_inode_table, \"noinit_itable\"},\n\t{Opt_err, NULL},\n};\n\nstatic ext4_fsblk_t get_sb_block(void **data)\n{\n\text4_fsblk_t\tsb_block;\n\tchar\t\t*options = (char *) *data;\n\n\tif (!options || strncmp(options, \"sb=\", 3) != 0)\n\t\treturn 1;\t/* Default location */\n\n\toptions += 3;\n\t/* TODO: use simple_strtoll with >32bit ext4 */\n\tsb_block = simple_strtoul(options, &options, 0);\n\tif (*options && *options != ',') {\n\t\tprintk(KERN_ERR \"EXT4-fs: Invalid sb specification: %s\\n\",\n\t\t       (char *) *data);\n\t\treturn 1;\n\t}\n\tif (*options == ',')\n\t\toptions++;\n\t*data = (void *) options;\n\n\treturn sb_block;\n}\n\n#define DEFAULT_JOURNAL_IOPRIO (IOPRIO_PRIO_VALUE(IOPRIO_CLASS_BE, 3))\nstatic char deprecated_msg[] = \"Mount option \\\"%s\\\" will be removed by %s\\n\"\n\t\"Contact linux-ext4@vger.kernel.org if you think we should keep it.\\n\";\n\n#ifdef CONFIG_QUOTA\nstatic int set_qf_name(struct super_block *sb, int qtype, substring_t *args)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tchar *qname;\n\n\tif (sb_any_quota_loaded(sb) &&\n\t\t!sbi->s_qf_names[qtype]) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t\"Cannot change journaled \"\n\t\t\t\"quota options when quota turned on\");\n\t\treturn 0;\n\t}\n\tqname = match_strdup(args);\n\tif (!qname) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t\"Not enough memory for storing quotafile name\");\n\t\treturn 0;\n\t}\n\tif (sbi->s_qf_names[qtype] &&\n\t\tstrcmp(sbi->s_qf_names[qtype], qname)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t\"%s quota file already specified\", QTYPE2NAME(qtype));\n\t\tkfree(qname);\n\t\treturn 0;\n\t}\n\tsbi->s_qf_names[qtype] = qname;\n\tif (strchr(sbi->s_qf_names[qtype], '/')) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t\"quotafile must be on filesystem root\");\n\t\tkfree(sbi->s_qf_names[qtype]);\n\t\tsbi->s_qf_names[qtype] = NULL;\n\t\treturn 0;\n\t}\n\tset_opt(sb, QUOTA);\n\treturn 1;\n}\n\nstatic int clear_qf_name(struct super_block *sb, int qtype)\n{\n\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\tif (sb_any_quota_loaded(sb) &&\n\t\tsbi->s_qf_names[qtype]) {\n\t\text4_msg(sb, KERN_ERR, \"Cannot change journaled quota options\"\n\t\t\t\" when quota turned on\");\n\t\treturn 0;\n\t}\n\t/*\n\t * The space will be released later when all options are confirmed\n\t * to be correct\n\t */\n\tsbi->s_qf_names[qtype] = NULL;\n\treturn 1;\n}\n#endif\n\nstatic int parse_options(char *options, struct super_block *sb,\n\t\t\t unsigned long *journal_devnum,\n\t\t\t unsigned int *journal_ioprio,\n\t\t\t ext4_fsblk_t *n_blocks_count, int is_remount)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tchar *p;\n\tsubstring_t args[MAX_OPT_ARGS];\n\tint data_opt = 0;\n\tint option;\n#ifdef CONFIG_QUOTA\n\tint qfmt;\n#endif\n\n\tif (!options)\n\t\treturn 1;\n\n\twhile ((p = strsep(&options, \",\")) != NULL) {\n\t\tint token;\n\t\tif (!*p)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * Initialize args struct so we know whether arg was\n\t\t * found; some options take optional arguments.\n\t\t */\n\t\targs[0].to = args[0].from = NULL;\n\t\ttoken = match_token(p, tokens, args);\n\t\tswitch (token) {\n\t\tcase Opt_bsd_df:\n\t\t\text4_msg(sb, KERN_WARNING, deprecated_msg, p, \"2.6.38\");\n\t\t\tclear_opt(sb, MINIX_DF);\n\t\t\tbreak;\n\t\tcase Opt_minix_df:\n\t\t\text4_msg(sb, KERN_WARNING, deprecated_msg, p, \"2.6.38\");\n\t\t\tset_opt(sb, MINIX_DF);\n\n\t\t\tbreak;\n\t\tcase Opt_grpid:\n\t\t\text4_msg(sb, KERN_WARNING, deprecated_msg, p, \"2.6.38\");\n\t\t\tset_opt(sb, GRPID);\n\n\t\t\tbreak;\n\t\tcase Opt_nogrpid:\n\t\t\text4_msg(sb, KERN_WARNING, deprecated_msg, p, \"2.6.38\");\n\t\t\tclear_opt(sb, GRPID);\n\n\t\t\tbreak;\n\t\tcase Opt_resuid:\n\t\t\tif (match_int(&args[0], &option))\n\t\t\t\treturn 0;\n\t\t\tsbi->s_resuid = option;\n\t\t\tbreak;\n\t\tcase Opt_resgid:\n\t\t\tif (match_int(&args[0], &option))\n\t\t\t\treturn 0;\n\t\t\tsbi->s_resgid = option;\n\t\t\tbreak;\n\t\tcase Opt_sb:\n\t\t\t/* handled by get_sb_block() instead of here */\n\t\t\t/* *sb_block = match_int(&args[0]); */\n\t\t\tbreak;\n\t\tcase Opt_err_panic:\n\t\t\tclear_opt(sb, ERRORS_CONT);\n\t\t\tclear_opt(sb, ERRORS_RO);\n\t\t\tset_opt(sb, ERRORS_PANIC);\n\t\t\tbreak;\n\t\tcase Opt_err_ro:\n\t\t\tclear_opt(sb, ERRORS_CONT);\n\t\t\tclear_opt(sb, ERRORS_PANIC);\n\t\t\tset_opt(sb, ERRORS_RO);\n\t\t\tbreak;\n\t\tcase Opt_err_cont:\n\t\t\tclear_opt(sb, ERRORS_RO);\n\t\t\tclear_opt(sb, ERRORS_PANIC);\n\t\t\tset_opt(sb, ERRORS_CONT);\n\t\t\tbreak;\n\t\tcase Opt_nouid32:\n\t\t\tset_opt(sb, NO_UID32);\n\t\t\tbreak;\n\t\tcase Opt_debug:\n\t\t\tset_opt(sb, DEBUG);\n\t\t\tbreak;\n\t\tcase Opt_oldalloc:\n\t\t\tset_opt(sb, OLDALLOC);\n\t\t\tbreak;\n\t\tcase Opt_orlov:\n\t\t\tclear_opt(sb, OLDALLOC);\n\t\t\tbreak;\n#ifdef CONFIG_EXT4_FS_XATTR\n\t\tcase Opt_user_xattr:\n\t\t\tset_opt(sb, XATTR_USER);\n\t\t\tbreak;\n\t\tcase Opt_nouser_xattr:\n\t\t\tclear_opt(sb, XATTR_USER);\n\t\t\tbreak;\n#else\n\t\tcase Opt_user_xattr:\n\t\tcase Opt_nouser_xattr:\n\t\t\text4_msg(sb, KERN_ERR, \"(no)user_xattr options not supported\");\n\t\t\tbreak;\n#endif\n#ifdef CONFIG_EXT4_FS_POSIX_ACL\n\t\tcase Opt_acl:\n\t\t\tset_opt(sb, POSIX_ACL);\n\t\t\tbreak;\n\t\tcase Opt_noacl:\n\t\t\tclear_opt(sb, POSIX_ACL);\n\t\t\tbreak;\n#else\n\t\tcase Opt_acl:\n\t\tcase Opt_noacl:\n\t\t\text4_msg(sb, KERN_ERR, \"(no)acl options not supported\");\n\t\t\tbreak;\n#endif\n\t\tcase Opt_journal_update:\n\t\t\t/* @@@ FIXME */\n\t\t\t/* Eventually we will want to be able to create\n\t\t\t   a journal file here.  For now, only allow the\n\t\t\t   user to specify an existing inode to be the\n\t\t\t   journal file. */\n\t\t\tif (is_remount) {\n\t\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\t \"Cannot specify journal on remount\");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tset_opt(sb, UPDATE_JOURNAL);\n\t\t\tbreak;\n\t\tcase Opt_journal_dev:\n\t\t\tif (is_remount) {\n\t\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\t\"Cannot specify journal on remount\");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tif (match_int(&args[0], &option))\n\t\t\t\treturn 0;\n\t\t\t*journal_devnum = option;\n\t\t\tbreak;\n\t\tcase Opt_journal_checksum:\n\t\t\tset_opt(sb, JOURNAL_CHECKSUM);\n\t\t\tbreak;\n\t\tcase Opt_journal_async_commit:\n\t\t\tset_opt(sb, JOURNAL_ASYNC_COMMIT);\n\t\t\tset_opt(sb, JOURNAL_CHECKSUM);\n\t\t\tbreak;\n\t\tcase Opt_noload:\n\t\t\tset_opt(sb, NOLOAD);\n\t\t\tbreak;\n\t\tcase Opt_commit:\n\t\t\tif (match_int(&args[0], &option))\n\t\t\t\treturn 0;\n\t\t\tif (option < 0)\n\t\t\t\treturn 0;\n\t\t\tif (option == 0)\n\t\t\t\toption = JBD2_DEFAULT_MAX_COMMIT_AGE;\n\t\t\tsbi->s_commit_interval = HZ * option;\n\t\t\tbreak;\n\t\tcase Opt_max_batch_time:\n\t\t\tif (match_int(&args[0], &option))\n\t\t\t\treturn 0;\n\t\t\tif (option < 0)\n\t\t\t\treturn 0;\n\t\t\tif (option == 0)\n\t\t\t\toption = EXT4_DEF_MAX_BATCH_TIME;\n\t\t\tsbi->s_max_batch_time = option;\n\t\t\tbreak;\n\t\tcase Opt_min_batch_time:\n\t\t\tif (match_int(&args[0], &option))\n\t\t\t\treturn 0;\n\t\t\tif (option < 0)\n\t\t\t\treturn 0;\n\t\t\tsbi->s_min_batch_time = option;\n\t\t\tbreak;\n\t\tcase Opt_data_journal:\n\t\t\tdata_opt = EXT4_MOUNT_JOURNAL_DATA;\n\t\t\tgoto datacheck;\n\t\tcase Opt_data_ordered:\n\t\t\tdata_opt = EXT4_MOUNT_ORDERED_DATA;\n\t\t\tgoto datacheck;\n\t\tcase Opt_data_writeback:\n\t\t\tdata_opt = EXT4_MOUNT_WRITEBACK_DATA;\n\t\tdatacheck:\n\t\t\tif (is_remount) {\n\t\t\t\tif (test_opt(sb, DATA_FLAGS) != data_opt) {\n\t\t\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\t\t\"Cannot change data mode on remount\");\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tclear_opt(sb, DATA_FLAGS);\n\t\t\t\tsbi->s_mount_opt |= data_opt;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase Opt_data_err_abort:\n\t\t\tset_opt(sb, DATA_ERR_ABORT);\n\t\t\tbreak;\n\t\tcase Opt_data_err_ignore:\n\t\t\tclear_opt(sb, DATA_ERR_ABORT);\n\t\t\tbreak;\n#ifdef CONFIG_QUOTA\n\t\tcase Opt_usrjquota:\n\t\t\tif (!set_qf_name(sb, USRQUOTA, &args[0]))\n\t\t\t\treturn 0;\n\t\t\tbreak;\n\t\tcase Opt_grpjquota:\n\t\t\tif (!set_qf_name(sb, GRPQUOTA, &args[0]))\n\t\t\t\treturn 0;\n\t\t\tbreak;\n\t\tcase Opt_offusrjquota:\n\t\t\tif (!clear_qf_name(sb, USRQUOTA))\n\t\t\t\treturn 0;\n\t\t\tbreak;\n\t\tcase Opt_offgrpjquota:\n\t\t\tif (!clear_qf_name(sb, GRPQUOTA))\n\t\t\t\treturn 0;\n\t\t\tbreak;\n\n\t\tcase Opt_jqfmt_vfsold:\n\t\t\tqfmt = QFMT_VFS_OLD;\n\t\t\tgoto set_qf_format;\n\t\tcase Opt_jqfmt_vfsv0:\n\t\t\tqfmt = QFMT_VFS_V0;\n\t\t\tgoto set_qf_format;\n\t\tcase Opt_jqfmt_vfsv1:\n\t\t\tqfmt = QFMT_VFS_V1;\nset_qf_format:\n\t\t\tif (sb_any_quota_loaded(sb) &&\n\t\t\t    sbi->s_jquota_fmt != qfmt) {\n\t\t\t\text4_msg(sb, KERN_ERR, \"Cannot change \"\n\t\t\t\t\t\"journaled quota options when \"\n\t\t\t\t\t\"quota turned on\");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tsbi->s_jquota_fmt = qfmt;\n\t\t\tbreak;\n\t\tcase Opt_quota:\n\t\tcase Opt_usrquota:\n\t\t\tset_opt(sb, QUOTA);\n\t\t\tset_opt(sb, USRQUOTA);\n\t\t\tbreak;\n\t\tcase Opt_grpquota:\n\t\t\tset_opt(sb, QUOTA);\n\t\t\tset_opt(sb, GRPQUOTA);\n\t\t\tbreak;\n\t\tcase Opt_noquota:\n\t\t\tif (sb_any_quota_loaded(sb)) {\n\t\t\t\text4_msg(sb, KERN_ERR, \"Cannot change quota \"\n\t\t\t\t\t\"options when quota turned on\");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tclear_opt(sb, QUOTA);\n\t\t\tclear_opt(sb, USRQUOTA);\n\t\t\tclear_opt(sb, GRPQUOTA);\n\t\t\tbreak;\n#else\n\t\tcase Opt_quota:\n\t\tcase Opt_usrquota:\n\t\tcase Opt_grpquota:\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\"quota options not supported\");\n\t\t\tbreak;\n\t\tcase Opt_usrjquota:\n\t\tcase Opt_grpjquota:\n\t\tcase Opt_offusrjquota:\n\t\tcase Opt_offgrpjquota:\n\t\tcase Opt_jqfmt_vfsold:\n\t\tcase Opt_jqfmt_vfsv0:\n\t\tcase Opt_jqfmt_vfsv1:\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\"journaled quota options not supported\");\n\t\t\tbreak;\n\t\tcase Opt_noquota:\n\t\t\tbreak;\n#endif\n\t\tcase Opt_abort:\n\t\t\tsbi->s_mount_flags |= EXT4_MF_FS_ABORTED;\n\t\t\tbreak;\n\t\tcase Opt_nobarrier:\n\t\t\tclear_opt(sb, BARRIER);\n\t\t\tbreak;\n\t\tcase Opt_barrier:\n\t\t\tif (args[0].from) {\n\t\t\t\tif (match_int(&args[0], &option))\n\t\t\t\t\treturn 0;\n\t\t\t} else\n\t\t\t\toption = 1;\t/* No argument, default to 1 */\n\t\t\tif (option)\n\t\t\t\tset_opt(sb, BARRIER);\n\t\t\telse\n\t\t\t\tclear_opt(sb, BARRIER);\n\t\t\tbreak;\n\t\tcase Opt_ignore:\n\t\t\tbreak;\n\t\tcase Opt_resize:\n\t\t\tif (!is_remount) {\n\t\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\t\"resize option only available \"\n\t\t\t\t\t\"for remount\");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tif (match_int(&args[0], &option) != 0)\n\t\t\t\treturn 0;\n\t\t\t*n_blocks_count = option;\n\t\t\tbreak;\n\t\tcase Opt_nobh:\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"Ignoring deprecated nobh option\");\n\t\t\tbreak;\n\t\tcase Opt_bh:\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"Ignoring deprecated bh option\");\n\t\t\tbreak;\n\t\tcase Opt_i_version:\n\t\t\tset_opt(sb, I_VERSION);\n\t\t\tsb->s_flags |= MS_I_VERSION;\n\t\t\tbreak;\n\t\tcase Opt_nodelalloc:\n\t\t\tclear_opt(sb, DELALLOC);\n\t\t\tbreak;\n\t\tcase Opt_mblk_io_submit:\n\t\t\tset_opt(sb, MBLK_IO_SUBMIT);\n\t\t\tbreak;\n\t\tcase Opt_nomblk_io_submit:\n\t\t\tclear_opt(sb, MBLK_IO_SUBMIT);\n\t\t\tbreak;\n\t\tcase Opt_stripe:\n\t\t\tif (match_int(&args[0], &option))\n\t\t\t\treturn 0;\n\t\t\tif (option < 0)\n\t\t\t\treturn 0;\n\t\t\tsbi->s_stripe = option;\n\t\t\tbreak;\n\t\tcase Opt_delalloc:\n\t\t\tset_opt(sb, DELALLOC);\n\t\t\tbreak;\n\t\tcase Opt_block_validity:\n\t\t\tset_opt(sb, BLOCK_VALIDITY);\n\t\t\tbreak;\n\t\tcase Opt_noblock_validity:\n\t\t\tclear_opt(sb, BLOCK_VALIDITY);\n\t\t\tbreak;\n\t\tcase Opt_inode_readahead_blks:\n\t\t\tif (match_int(&args[0], &option))\n\t\t\t\treturn 0;\n\t\t\tif (option < 0 || option > (1 << 30))\n\t\t\t\treturn 0;\n\t\t\tif (option && !is_power_of_2(option)) {\n\t\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\t \"EXT4-fs: inode_readahead_blks\"\n\t\t\t\t\t \" must be a power of 2\");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tsbi->s_inode_readahead_blks = option;\n\t\t\tbreak;\n\t\tcase Opt_journal_ioprio:\n\t\t\tif (match_int(&args[0], &option))\n\t\t\t\treturn 0;\n\t\t\tif (option < 0 || option > 7)\n\t\t\t\tbreak;\n\t\t\t*journal_ioprio = IOPRIO_PRIO_VALUE(IOPRIO_CLASS_BE,\n\t\t\t\t\t\t\t    option);\n\t\t\tbreak;\n\t\tcase Opt_noauto_da_alloc:\n\t\t\tset_opt(sb, NO_AUTO_DA_ALLOC);\n\t\t\tbreak;\n\t\tcase Opt_auto_da_alloc:\n\t\t\tif (args[0].from) {\n\t\t\t\tif (match_int(&args[0], &option))\n\t\t\t\t\treturn 0;\n\t\t\t} else\n\t\t\t\toption = 1;\t/* No argument, default to 1 */\n\t\t\tif (option)\n\t\t\t\tclear_opt(sb, NO_AUTO_DA_ALLOC);\n\t\t\telse\n\t\t\t\tset_opt(sb,NO_AUTO_DA_ALLOC);\n\t\t\tbreak;\n\t\tcase Opt_discard:\n\t\t\tset_opt(sb, DISCARD);\n\t\t\tbreak;\n\t\tcase Opt_nodiscard:\n\t\t\tclear_opt(sb, DISCARD);\n\t\t\tbreak;\n\t\tcase Opt_dioread_nolock:\n\t\t\tset_opt(sb, DIOREAD_NOLOCK);\n\t\t\tbreak;\n\t\tcase Opt_dioread_lock:\n\t\t\tclear_opt(sb, DIOREAD_NOLOCK);\n\t\t\tbreak;\n\t\tcase Opt_init_inode_table:\n\t\t\tset_opt(sb, INIT_INODE_TABLE);\n\t\t\tif (args[0].from) {\n\t\t\t\tif (match_int(&args[0], &option))\n\t\t\t\t\treturn 0;\n\t\t\t} else\n\t\t\t\toption = EXT4_DEF_LI_WAIT_MULT;\n\t\t\tif (option < 0)\n\t\t\t\treturn 0;\n\t\t\tsbi->s_li_wait_mult = option;\n\t\t\tbreak;\n\t\tcase Opt_noinit_inode_table:\n\t\t\tclear_opt(sb, INIT_INODE_TABLE);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Unrecognized mount option \\\"%s\\\" \"\n\t\t\t       \"or missing value\", p);\n\t\t\treturn 0;\n\t\t}\n\t}\n#ifdef CONFIG_QUOTA\n\tif (sbi->s_qf_names[USRQUOTA] || sbi->s_qf_names[GRPQUOTA]) {\n\t\tif (test_opt(sb, USRQUOTA) && sbi->s_qf_names[USRQUOTA])\n\t\t\tclear_opt(sb, USRQUOTA);\n\n\t\tif (test_opt(sb, GRPQUOTA) && sbi->s_qf_names[GRPQUOTA])\n\t\t\tclear_opt(sb, GRPQUOTA);\n\n\t\tif (test_opt(sb, GRPQUOTA) || test_opt(sb, USRQUOTA)) {\n\t\t\text4_msg(sb, KERN_ERR, \"old and new quota \"\n\t\t\t\t\t\"format mixing\");\n\t\t\treturn 0;\n\t\t}\n\n\t\tif (!sbi->s_jquota_fmt) {\n\t\t\text4_msg(sb, KERN_ERR, \"journaled quota format \"\n\t\t\t\t\t\"not specified\");\n\t\t\treturn 0;\n\t\t}\n\t} else {\n\t\tif (sbi->s_jquota_fmt) {\n\t\t\text4_msg(sb, KERN_ERR, \"journaled quota format \"\n\t\t\t\t\t\"specified with no journaling \"\n\t\t\t\t\t\"enabled\");\n\t\t\treturn 0;\n\t\t}\n\t}\n#endif\n\treturn 1;\n}\n\nstatic int ext4_setup_super(struct super_block *sb, struct ext4_super_block *es,\n\t\t\t    int read_only)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tint res = 0;\n\n\tif (le32_to_cpu(es->s_rev_level) > EXT4_MAX_SUPP_REV) {\n\t\text4_msg(sb, KERN_ERR, \"revision level too high, \"\n\t\t\t \"forcing read-only mode\");\n\t\tres = MS_RDONLY;\n\t}\n\tif (read_only)\n\t\treturn res;\n\tif (!(sbi->s_mount_state & EXT4_VALID_FS))\n\t\text4_msg(sb, KERN_WARNING, \"warning: mounting unchecked fs, \"\n\t\t\t \"running e2fsck is recommended\");\n\telse if ((sbi->s_mount_state & EXT4_ERROR_FS))\n\t\text4_msg(sb, KERN_WARNING,\n\t\t\t \"warning: mounting fs with errors, \"\n\t\t\t \"running e2fsck is recommended\");\n\telse if ((__s16) le16_to_cpu(es->s_max_mnt_count) >= 0 &&\n\t\t le16_to_cpu(es->s_mnt_count) >=\n\t\t (unsigned short) (__s16) le16_to_cpu(es->s_max_mnt_count))\n\t\text4_msg(sb, KERN_WARNING,\n\t\t\t \"warning: maximal mount count reached, \"\n\t\t\t \"running e2fsck is recommended\");\n\telse if (le32_to_cpu(es->s_checkinterval) &&\n\t\t(le32_to_cpu(es->s_lastcheck) +\n\t\t\tle32_to_cpu(es->s_checkinterval) <= get_seconds()))\n\t\text4_msg(sb, KERN_WARNING,\n\t\t\t \"warning: checktime reached, \"\n\t\t\t \"running e2fsck is recommended\");\n\tif (!sbi->s_journal)\n\t\tes->s_state &= cpu_to_le16(~EXT4_VALID_FS);\n\tif (!(__s16) le16_to_cpu(es->s_max_mnt_count))\n\t\tes->s_max_mnt_count = cpu_to_le16(EXT4_DFL_MAX_MNT_COUNT);\n\tle16_add_cpu(&es->s_mnt_count, 1);\n\tes->s_mtime = cpu_to_le32(get_seconds());\n\text4_update_dynamic_rev(sb);\n\tif (sbi->s_journal)\n\t\tEXT4_SET_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_RECOVER);\n\n\text4_commit_super(sb, 1);\n\tif (test_opt(sb, DEBUG))\n\t\tprintk(KERN_INFO \"[EXT4 FS bs=%lu, gc=%u, \"\n\t\t\t\t\"bpg=%lu, ipg=%lu, mo=%04x, mo2=%04x]\\n\",\n\t\t\tsb->s_blocksize,\n\t\t\tsbi->s_groups_count,\n\t\t\tEXT4_BLOCKS_PER_GROUP(sb),\n\t\t\tEXT4_INODES_PER_GROUP(sb),\n\t\t\tsbi->s_mount_opt, sbi->s_mount_opt2);\n\n\treturn res;\n}\n\nstatic int ext4_fill_flex_info(struct super_block *sb)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_group_desc *gdp = NULL;\n\text4_group_t flex_group_count;\n\text4_group_t flex_group;\n\tint groups_per_flex = 0;\n\tsize_t size;\n\tint i;\n\n\tsbi->s_log_groups_per_flex = sbi->s_es->s_log_groups_per_flex;\n\tgroups_per_flex = 1 << sbi->s_log_groups_per_flex;\n\n\tif (groups_per_flex < 2) {\n\t\tsbi->s_log_groups_per_flex = 0;\n\t\treturn 1;\n\t}\n\n\t/* We allocate both existing and potentially added groups */\n\tflex_group_count = ((sbi->s_groups_count + groups_per_flex - 1) +\n\t\t\t((le16_to_cpu(sbi->s_es->s_reserved_gdt_blocks) + 1) <<\n\t\t\t      EXT4_DESC_PER_BLOCK_BITS(sb))) / groups_per_flex;\n\tsize = flex_group_count * sizeof(struct flex_groups);\n\tsbi->s_flex_groups = kzalloc(size, GFP_KERNEL);\n\tif (sbi->s_flex_groups == NULL) {\n\t\tsbi->s_flex_groups = vzalloc(size);\n\t\tif (sbi->s_flex_groups == NULL) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"not enough memory for %u flex groups\",\n\t\t\t\t flex_group_count);\n\t\t\tgoto failed;\n\t\t}\n\t}\n\n\tfor (i = 0; i < sbi->s_groups_count; i++) {\n\t\tgdp = ext4_get_group_desc(sb, i, NULL);\n\n\t\tflex_group = ext4_flex_group(sbi, i);\n\t\tatomic_add(ext4_free_inodes_count(sb, gdp),\n\t\t\t   &sbi->s_flex_groups[flex_group].free_inodes);\n\t\tatomic_add(ext4_free_blks_count(sb, gdp),\n\t\t\t   &sbi->s_flex_groups[flex_group].free_blocks);\n\t\tatomic_add(ext4_used_dirs_count(sb, gdp),\n\t\t\t   &sbi->s_flex_groups[flex_group].used_dirs);\n\t}\n\n\treturn 1;\nfailed:\n\treturn 0;\n}\n\n__le16 ext4_group_desc_csum(struct ext4_sb_info *sbi, __u32 block_group,\n\t\t\t    struct ext4_group_desc *gdp)\n{\n\t__u16 crc = 0;\n\n\tif (sbi->s_es->s_feature_ro_compat &\n\t    cpu_to_le32(EXT4_FEATURE_RO_COMPAT_GDT_CSUM)) {\n\t\tint offset = offsetof(struct ext4_group_desc, bg_checksum);\n\t\t__le32 le_group = cpu_to_le32(block_group);\n\n\t\tcrc = crc16(~0, sbi->s_es->s_uuid, sizeof(sbi->s_es->s_uuid));\n\t\tcrc = crc16(crc, (__u8 *)&le_group, sizeof(le_group));\n\t\tcrc = crc16(crc, (__u8 *)gdp, offset);\n\t\toffset += sizeof(gdp->bg_checksum); /* skip checksum */\n\t\t/* for checksum of struct ext4_group_desc do the rest...*/\n\t\tif ((sbi->s_es->s_feature_incompat &\n\t\t     cpu_to_le32(EXT4_FEATURE_INCOMPAT_64BIT)) &&\n\t\t    offset < le16_to_cpu(sbi->s_es->s_desc_size))\n\t\t\tcrc = crc16(crc, (__u8 *)gdp + offset,\n\t\t\t\t    le16_to_cpu(sbi->s_es->s_desc_size) -\n\t\t\t\t\toffset);\n\t}\n\n\treturn cpu_to_le16(crc);\n}\n\nint ext4_group_desc_csum_verify(struct ext4_sb_info *sbi, __u32 block_group,\n\t\t\t\tstruct ext4_group_desc *gdp)\n{\n\tif ((sbi->s_es->s_feature_ro_compat &\n\t     cpu_to_le32(EXT4_FEATURE_RO_COMPAT_GDT_CSUM)) &&\n\t    (gdp->bg_checksum != ext4_group_desc_csum(sbi, block_group, gdp)))\n\t\treturn 0;\n\n\treturn 1;\n}\n\n/* Called at mount-time, super-block is locked */\nstatic int ext4_check_descriptors(struct super_block *sb,\n\t\t\t\t  ext4_group_t *first_not_zeroed)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\text4_fsblk_t first_block = le32_to_cpu(sbi->s_es->s_first_data_block);\n\text4_fsblk_t last_block;\n\text4_fsblk_t block_bitmap;\n\text4_fsblk_t inode_bitmap;\n\text4_fsblk_t inode_table;\n\tint flexbg_flag = 0;\n\text4_group_t i, grp = sbi->s_groups_count;\n\n\tif (EXT4_HAS_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_FLEX_BG))\n\t\tflexbg_flag = 1;\n\n\text4_debug(\"Checking group descriptors\");\n\n\tfor (i = 0; i < sbi->s_groups_count; i++) {\n\t\tstruct ext4_group_desc *gdp = ext4_get_group_desc(sb, i, NULL);\n\n\t\tif (i == sbi->s_groups_count - 1 || flexbg_flag)\n\t\t\tlast_block = ext4_blocks_count(sbi->s_es) - 1;\n\t\telse\n\t\t\tlast_block = first_block +\n\t\t\t\t(EXT4_BLOCKS_PER_GROUP(sb) - 1);\n\n\t\tif ((grp == sbi->s_groups_count) &&\n\t\t   !(gdp->bg_flags & cpu_to_le16(EXT4_BG_INODE_ZEROED)))\n\t\t\tgrp = i;\n\n\t\tblock_bitmap = ext4_block_bitmap(sb, gdp);\n\t\tif (block_bitmap < first_block || block_bitmap > last_block) {\n\t\t\text4_msg(sb, KERN_ERR, \"ext4_check_descriptors: \"\n\t\t\t       \"Block bitmap for group %u not in group \"\n\t\t\t       \"(block %llu)!\", i, block_bitmap);\n\t\t\treturn 0;\n\t\t}\n\t\tinode_bitmap = ext4_inode_bitmap(sb, gdp);\n\t\tif (inode_bitmap < first_block || inode_bitmap > last_block) {\n\t\t\text4_msg(sb, KERN_ERR, \"ext4_check_descriptors: \"\n\t\t\t       \"Inode bitmap for group %u not in group \"\n\t\t\t       \"(block %llu)!\", i, inode_bitmap);\n\t\t\treturn 0;\n\t\t}\n\t\tinode_table = ext4_inode_table(sb, gdp);\n\t\tif (inode_table < first_block ||\n\t\t    inode_table + sbi->s_itb_per_group - 1 > last_block) {\n\t\t\text4_msg(sb, KERN_ERR, \"ext4_check_descriptors: \"\n\t\t\t       \"Inode table for group %u not in group \"\n\t\t\t       \"(block %llu)!\", i, inode_table);\n\t\t\treturn 0;\n\t\t}\n\t\text4_lock_group(sb, i);\n\t\tif (!ext4_group_desc_csum_verify(sbi, i, gdp)) {\n\t\t\text4_msg(sb, KERN_ERR, \"ext4_check_descriptors: \"\n\t\t\t\t \"Checksum for group %u failed (%u!=%u)\",\n\t\t\t\t i, le16_to_cpu(ext4_group_desc_csum(sbi, i,\n\t\t\t\t     gdp)), le16_to_cpu(gdp->bg_checksum));\n\t\t\tif (!(sb->s_flags & MS_RDONLY)) {\n\t\t\t\text4_unlock_group(sb, i);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t\text4_unlock_group(sb, i);\n\t\tif (!flexbg_flag)\n\t\t\tfirst_block += EXT4_BLOCKS_PER_GROUP(sb);\n\t}\n\tif (NULL != first_not_zeroed)\n\t\t*first_not_zeroed = grp;\n\n\text4_free_blocks_count_set(sbi->s_es, ext4_count_free_blocks(sb));\n\tsbi->s_es->s_free_inodes_count =cpu_to_le32(ext4_count_free_inodes(sb));\n\treturn 1;\n}\n\n/* ext4_orphan_cleanup() walks a singly-linked list of inodes (starting at\n * the superblock) which were deleted from all directories, but held open by\n * a process at the time of a crash.  We walk the list and try to delete these\n * inodes at recovery time (only with a read-write filesystem).\n *\n * In order to keep the orphan inode chain consistent during traversal (in\n * case of crash during recovery), we link each inode into the superblock\n * orphan list_head and handle it the same way as an inode deletion during\n * normal operation (which journals the operations for us).\n *\n * We only do an iget() and an iput() on each inode, which is very safe if we\n * accidentally point at an in-use or already deleted inode.  The worst that\n * can happen in this case is that we get a \"bit already cleared\" message from\n * ext4_free_inode().  The only reason we would point at a wrong inode is if\n * e2fsck was run on this filesystem, and it must have already done the orphan\n * inode cleanup for us, so we can safely abort without any further action.\n */\nstatic void ext4_orphan_cleanup(struct super_block *sb,\n\t\t\t\tstruct ext4_super_block *es)\n{\n\tunsigned int s_flags = sb->s_flags;\n\tint nr_orphans = 0, nr_truncates = 0;\n#ifdef CONFIG_QUOTA\n\tint i;\n#endif\n\tif (!es->s_last_orphan) {\n\t\tjbd_debug(4, \"no orphan inodes to clean up\\n\");\n\t\treturn;\n\t}\n\n\tif (bdev_read_only(sb->s_bdev)) {\n\t\text4_msg(sb, KERN_ERR, \"write access \"\n\t\t\t\"unavailable, skipping orphan cleanup\");\n\t\treturn;\n\t}\n\n\t/* Check if feature set would not allow a r/w mount */\n\tif (!ext4_feature_set_ok(sb, 0)) {\n\t\text4_msg(sb, KERN_INFO, \"Skipping orphan cleanup due to \"\n\t\t\t \"unknown ROCOMPAT features\");\n\t\treturn;\n\t}\n\n\tif (EXT4_SB(sb)->s_mount_state & EXT4_ERROR_FS) {\n\t\tif (es->s_last_orphan)\n\t\t\tjbd_debug(1, \"Errors on filesystem, \"\n\t\t\t\t  \"clearing orphan list.\\n\");\n\t\tes->s_last_orphan = 0;\n\t\tjbd_debug(1, \"Skipping orphan recovery on fs with errors.\\n\");\n\t\treturn;\n\t}\n\n\tif (s_flags & MS_RDONLY) {\n\t\text4_msg(sb, KERN_INFO, \"orphan cleanup on readonly fs\");\n\t\tsb->s_flags &= ~MS_RDONLY;\n\t}\n#ifdef CONFIG_QUOTA\n\t/* Needed for iput() to work correctly and not trash data */\n\tsb->s_flags |= MS_ACTIVE;\n\t/* Turn on quotas so that they are updated correctly */\n\tfor (i = 0; i < MAXQUOTAS; i++) {\n\t\tif (EXT4_SB(sb)->s_qf_names[i]) {\n\t\t\tint ret = ext4_quota_on_mount(sb, i);\n\t\t\tif (ret < 0)\n\t\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\t\"Cannot turn on journaled \"\n\t\t\t\t\t\"quota: error %d\", ret);\n\t\t}\n\t}\n#endif\n\n\twhile (es->s_last_orphan) {\n\t\tstruct inode *inode;\n\n\t\tinode = ext4_orphan_get(sb, le32_to_cpu(es->s_last_orphan));\n\t\tif (IS_ERR(inode)) {\n\t\t\tes->s_last_orphan = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\tlist_add(&EXT4_I(inode)->i_orphan, &EXT4_SB(sb)->s_orphan);\n\t\tdquot_initialize(inode);\n\t\tif (inode->i_nlink) {\n\t\t\text4_msg(sb, KERN_DEBUG,\n\t\t\t\t\"%s: truncating inode %lu to %lld bytes\",\n\t\t\t\t__func__, inode->i_ino, inode->i_size);\n\t\t\tjbd_debug(2, \"truncating inode %lu to %lld bytes\\n\",\n\t\t\t\t  inode->i_ino, inode->i_size);\n\t\t\text4_truncate(inode);\n\t\t\tnr_truncates++;\n\t\t} else {\n\t\t\text4_msg(sb, KERN_DEBUG,\n\t\t\t\t\"%s: deleting unreferenced inode %lu\",\n\t\t\t\t__func__, inode->i_ino);\n\t\t\tjbd_debug(2, \"deleting unreferenced inode %lu\\n\",\n\t\t\t\t  inode->i_ino);\n\t\t\tnr_orphans++;\n\t\t}\n\t\tiput(inode);  /* The delete magic happens here! */\n\t}\n\n#define PLURAL(x) (x), ((x) == 1) ? \"\" : \"s\"\n\n\tif (nr_orphans)\n\t\text4_msg(sb, KERN_INFO, \"%d orphan inode%s deleted\",\n\t\t       PLURAL(nr_orphans));\n\tif (nr_truncates)\n\t\text4_msg(sb, KERN_INFO, \"%d truncate%s cleaned up\",\n\t\t       PLURAL(nr_truncates));\n#ifdef CONFIG_QUOTA\n\t/* Turn quotas off */\n\tfor (i = 0; i < MAXQUOTAS; i++) {\n\t\tif (sb_dqopt(sb)->files[i])\n\t\t\tdquot_quota_off(sb, i);\n\t}\n#endif\n\tsb->s_flags = s_flags; /* Restore MS_RDONLY status */\n}\n\n/*\n * Maximal extent format file size.\n * Resulting logical blkno at s_maxbytes must fit in our on-disk\n * extent format containers, within a sector_t, and within i_blocks\n * in the vfs.  ext4 inode has 48 bits of i_block in fsblock units,\n * so that won't be a limiting factor.\n *\n * Note, this does *not* consider any metadata overhead for vfs i_blocks.\n */\nstatic loff_t ext4_max_size(int blkbits, int has_huge_files)\n{\n\tloff_t res;\n\tloff_t upper_limit = MAX_LFS_FILESIZE;\n\n\t/* small i_blocks in vfs inode? */\n\tif (!has_huge_files || sizeof(blkcnt_t) < sizeof(u64)) {\n\t\t/*\n\t\t * CONFIG_LBDAF is not enabled implies the inode\n\t\t * i_block represent total blocks in 512 bytes\n\t\t * 32 == size of vfs inode i_blocks * 8\n\t\t */\n\t\tupper_limit = (1LL << 32) - 1;\n\n\t\t/* total blocks in file system block size */\n\t\tupper_limit >>= (blkbits - 9);\n\t\tupper_limit <<= blkbits;\n\t}\n\n\t/* 32-bit extent-start container, ee_block */\n\tres = 1LL << 32;\n\tres <<= blkbits;\n\tres -= 1;\n\n\t/* Sanity check against vm- & vfs- imposed limits */\n\tif (res > upper_limit)\n\t\tres = upper_limit;\n\n\treturn res;\n}\n\n/*\n * Maximal bitmap file size.  There is a direct, and {,double-,triple-}indirect\n * block limit, and also a limit of (2^48 - 1) 512-byte sectors in i_blocks.\n * We need to be 1 filesystem block less than the 2^48 sector limit.\n */\nstatic loff_t ext4_max_bitmap_size(int bits, int has_huge_files)\n{\n\tloff_t res = EXT4_NDIR_BLOCKS;\n\tint meta_blocks;\n\tloff_t upper_limit;\n\t/* This is calculated to be the largest file size for a dense, block\n\t * mapped file such that the file's total number of 512-byte sectors,\n\t * including data and all indirect blocks, does not exceed (2^48 - 1).\n\t *\n\t * __u32 i_blocks_lo and _u16 i_blocks_high represent the total\n\t * number of 512-byte sectors of the file.\n\t */\n\n\tif (!has_huge_files || sizeof(blkcnt_t) < sizeof(u64)) {\n\t\t/*\n\t\t * !has_huge_files or CONFIG_LBDAF not enabled implies that\n\t\t * the inode i_block field represents total file blocks in\n\t\t * 2^32 512-byte sectors == size of vfs inode i_blocks * 8\n\t\t */\n\t\tupper_limit = (1LL << 32) - 1;\n\n\t\t/* total blocks in file system block size */\n\t\tupper_limit >>= (bits - 9);\n\n\t} else {\n\t\t/*\n\t\t * We use 48 bit ext4_inode i_blocks\n\t\t * With EXT4_HUGE_FILE_FL set the i_blocks\n\t\t * represent total number of blocks in\n\t\t * file system block size\n\t\t */\n\t\tupper_limit = (1LL << 48) - 1;\n\n\t}\n\n\t/* indirect blocks */\n\tmeta_blocks = 1;\n\t/* double indirect blocks */\n\tmeta_blocks += 1 + (1LL << (bits-2));\n\t/* tripple indirect blocks */\n\tmeta_blocks += 1 + (1LL << (bits-2)) + (1LL << (2*(bits-2)));\n\n\tupper_limit -= meta_blocks;\n\tupper_limit <<= bits;\n\n\tres += 1LL << (bits-2);\n\tres += 1LL << (2*(bits-2));\n\tres += 1LL << (3*(bits-2));\n\tres <<= bits;\n\tif (res > upper_limit)\n\t\tres = upper_limit;\n\n\tif (res > MAX_LFS_FILESIZE)\n\t\tres = MAX_LFS_FILESIZE;\n\n\treturn res;\n}\n\nstatic ext4_fsblk_t descriptor_loc(struct super_block *sb,\n\t\t\t\t   ext4_fsblk_t logical_sb_block, int nr)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\text4_group_t bg, first_meta_bg;\n\tint has_super = 0;\n\n\tfirst_meta_bg = le32_to_cpu(sbi->s_es->s_first_meta_bg);\n\n\tif (!EXT4_HAS_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_META_BG) ||\n\t    nr < first_meta_bg)\n\t\treturn logical_sb_block + nr + 1;\n\tbg = sbi->s_desc_per_block * nr;\n\tif (ext4_bg_has_super(sb, bg))\n\t\thas_super = 1;\n\n\treturn (has_super + ext4_group_first_block_no(sb, bg));\n}\n\n/**\n * ext4_get_stripe_size: Get the stripe size.\n * @sbi: In memory super block info\n *\n * If we have specified it via mount option, then\n * use the mount option value. If the value specified at mount time is\n * greater than the blocks per group use the super block value.\n * If the super block value is greater than blocks per group return 0.\n * Allocator needs it be less than blocks per group.\n *\n */\nstatic unsigned long ext4_get_stripe_size(struct ext4_sb_info *sbi)\n{\n\tunsigned long stride = le16_to_cpu(sbi->s_es->s_raid_stride);\n\tunsigned long stripe_width =\n\t\t\tle32_to_cpu(sbi->s_es->s_raid_stripe_width);\n\n\tif (sbi->s_stripe && sbi->s_stripe <= sbi->s_blocks_per_group)\n\t\treturn sbi->s_stripe;\n\n\tif (stripe_width <= sbi->s_blocks_per_group)\n\t\treturn stripe_width;\n\n\tif (stride <= sbi->s_blocks_per_group)\n\t\treturn stride;\n\n\treturn 0;\n}\n\n/* sysfs supprt */\n\nstruct ext4_attr {\n\tstruct attribute attr;\n\tssize_t (*show)(struct ext4_attr *, struct ext4_sb_info *, char *);\n\tssize_t (*store)(struct ext4_attr *, struct ext4_sb_info *,\n\t\t\t const char *, size_t);\n\tint offset;\n};\n\nstatic int parse_strtoul(const char *buf,\n\t\tunsigned long max, unsigned long *value)\n{\n\tchar *endp;\n\n\t*value = simple_strtoul(skip_spaces(buf), &endp, 0);\n\tendp = skip_spaces(endp);\n\tif (*endp || *value > max)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic ssize_t delayed_allocation_blocks_show(struct ext4_attr *a,\n\t\t\t\t\t      struct ext4_sb_info *sbi,\n\t\t\t\t\t      char *buf)\n{\n\treturn snprintf(buf, PAGE_SIZE, \"%llu\\n\",\n\t\t\t(s64) percpu_counter_sum(&sbi->s_dirtyblocks_counter));\n}\n\nstatic ssize_t session_write_kbytes_show(struct ext4_attr *a,\n\t\t\t\t\t struct ext4_sb_info *sbi, char *buf)\n{\n\tstruct super_block *sb = sbi->s_buddy_cache->i_sb;\n\n\tif (!sb->s_bdev->bd_part)\n\t\treturn snprintf(buf, PAGE_SIZE, \"0\\n\");\n\treturn snprintf(buf, PAGE_SIZE, \"%lu\\n\",\n\t\t\t(part_stat_read(sb->s_bdev->bd_part, sectors[1]) -\n\t\t\t sbi->s_sectors_written_start) >> 1);\n}\n\nstatic ssize_t lifetime_write_kbytes_show(struct ext4_attr *a,\n\t\t\t\t\t  struct ext4_sb_info *sbi, char *buf)\n{\n\tstruct super_block *sb = sbi->s_buddy_cache->i_sb;\n\n\tif (!sb->s_bdev->bd_part)\n\t\treturn snprintf(buf, PAGE_SIZE, \"0\\n\");\n\treturn snprintf(buf, PAGE_SIZE, \"%llu\\n\",\n\t\t\t(unsigned long long)(sbi->s_kbytes_written +\n\t\t\t((part_stat_read(sb->s_bdev->bd_part, sectors[1]) -\n\t\t\t  EXT4_SB(sb)->s_sectors_written_start) >> 1)));\n}\n\nstatic ssize_t inode_readahead_blks_store(struct ext4_attr *a,\n\t\t\t\t\t  struct ext4_sb_info *sbi,\n\t\t\t\t\t  const char *buf, size_t count)\n{\n\tunsigned long t;\n\n\tif (parse_strtoul(buf, 0x40000000, &t))\n\t\treturn -EINVAL;\n\n\tif (t && !is_power_of_2(t))\n\t\treturn -EINVAL;\n\n\tsbi->s_inode_readahead_blks = t;\n\treturn count;\n}\n\nstatic ssize_t sbi_ui_show(struct ext4_attr *a,\n\t\t\t   struct ext4_sb_info *sbi, char *buf)\n{\n\tunsigned int *ui = (unsigned int *) (((char *) sbi) + a->offset);\n\n\treturn snprintf(buf, PAGE_SIZE, \"%u\\n\", *ui);\n}\n\nstatic ssize_t sbi_ui_store(struct ext4_attr *a,\n\t\t\t    struct ext4_sb_info *sbi,\n\t\t\t    const char *buf, size_t count)\n{\n\tunsigned int *ui = (unsigned int *) (((char *) sbi) + a->offset);\n\tunsigned long t;\n\n\tif (parse_strtoul(buf, 0xffffffff, &t))\n\t\treturn -EINVAL;\n\t*ui = t;\n\treturn count;\n}\n\n#define EXT4_ATTR_OFFSET(_name,_mode,_show,_store,_elname) \\\nstatic struct ext4_attr ext4_attr_##_name = {\t\t\t\\\n\t.attr = {.name = __stringify(_name), .mode = _mode },\t\\\n\t.show\t= _show,\t\t\t\t\t\\\n\t.store\t= _store,\t\t\t\t\t\\\n\t.offset = offsetof(struct ext4_sb_info, _elname),\t\\\n}\n#define EXT4_ATTR(name, mode, show, store) \\\nstatic struct ext4_attr ext4_attr_##name = __ATTR(name, mode, show, store)\n\n#define EXT4_INFO_ATTR(name) EXT4_ATTR(name, 0444, NULL, NULL)\n#define EXT4_RO_ATTR(name) EXT4_ATTR(name, 0444, name##_show, NULL)\n#define EXT4_RW_ATTR(name) EXT4_ATTR(name, 0644, name##_show, name##_store)\n#define EXT4_RW_ATTR_SBI_UI(name, elname)\t\\\n\tEXT4_ATTR_OFFSET(name, 0644, sbi_ui_show, sbi_ui_store, elname)\n#define ATTR_LIST(name) &ext4_attr_##name.attr\n\nEXT4_RO_ATTR(delayed_allocation_blocks);\nEXT4_RO_ATTR(session_write_kbytes);\nEXT4_RO_ATTR(lifetime_write_kbytes);\nEXT4_ATTR_OFFSET(inode_readahead_blks, 0644, sbi_ui_show,\n\t\t inode_readahead_blks_store, s_inode_readahead_blks);\nEXT4_RW_ATTR_SBI_UI(inode_goal, s_inode_goal);\nEXT4_RW_ATTR_SBI_UI(mb_stats, s_mb_stats);\nEXT4_RW_ATTR_SBI_UI(mb_max_to_scan, s_mb_max_to_scan);\nEXT4_RW_ATTR_SBI_UI(mb_min_to_scan, s_mb_min_to_scan);\nEXT4_RW_ATTR_SBI_UI(mb_order2_req, s_mb_order2_reqs);\nEXT4_RW_ATTR_SBI_UI(mb_stream_req, s_mb_stream_request);\nEXT4_RW_ATTR_SBI_UI(mb_group_prealloc, s_mb_group_prealloc);\nEXT4_RW_ATTR_SBI_UI(max_writeback_mb_bump, s_max_writeback_mb_bump);\n\nstatic struct attribute *ext4_attrs[] = {\n\tATTR_LIST(delayed_allocation_blocks),\n\tATTR_LIST(session_write_kbytes),\n\tATTR_LIST(lifetime_write_kbytes),\n\tATTR_LIST(inode_readahead_blks),\n\tATTR_LIST(inode_goal),\n\tATTR_LIST(mb_stats),\n\tATTR_LIST(mb_max_to_scan),\n\tATTR_LIST(mb_min_to_scan),\n\tATTR_LIST(mb_order2_req),\n\tATTR_LIST(mb_stream_req),\n\tATTR_LIST(mb_group_prealloc),\n\tATTR_LIST(max_writeback_mb_bump),\n\tNULL,\n};\n\n/* Features this copy of ext4 supports */\nEXT4_INFO_ATTR(lazy_itable_init);\nEXT4_INFO_ATTR(batched_discard);\n\nstatic struct attribute *ext4_feat_attrs[] = {\n\tATTR_LIST(lazy_itable_init),\n\tATTR_LIST(batched_discard),\n\tNULL,\n};\n\nstatic ssize_t ext4_attr_show(struct kobject *kobj,\n\t\t\t      struct attribute *attr, char *buf)\n{\n\tstruct ext4_sb_info *sbi = container_of(kobj, struct ext4_sb_info,\n\t\t\t\t\t\ts_kobj);\n\tstruct ext4_attr *a = container_of(attr, struct ext4_attr, attr);\n\n\treturn a->show ? a->show(a, sbi, buf) : 0;\n}\n\nstatic ssize_t ext4_attr_store(struct kobject *kobj,\n\t\t\t       struct attribute *attr,\n\t\t\t       const char *buf, size_t len)\n{\n\tstruct ext4_sb_info *sbi = container_of(kobj, struct ext4_sb_info,\n\t\t\t\t\t\ts_kobj);\n\tstruct ext4_attr *a = container_of(attr, struct ext4_attr, attr);\n\n\treturn a->store ? a->store(a, sbi, buf, len) : 0;\n}\n\nstatic void ext4_sb_release(struct kobject *kobj)\n{\n\tstruct ext4_sb_info *sbi = container_of(kobj, struct ext4_sb_info,\n\t\t\t\t\t\ts_kobj);\n\tcomplete(&sbi->s_kobj_unregister);\n}\n\nstatic const struct sysfs_ops ext4_attr_ops = {\n\t.show\t= ext4_attr_show,\n\t.store\t= ext4_attr_store,\n};\n\nstatic struct kobj_type ext4_ktype = {\n\t.default_attrs\t= ext4_attrs,\n\t.sysfs_ops\t= &ext4_attr_ops,\n\t.release\t= ext4_sb_release,\n};\n\nstatic void ext4_feat_release(struct kobject *kobj)\n{\n\tcomplete(&ext4_feat->f_kobj_unregister);\n}\n\nstatic struct kobj_type ext4_feat_ktype = {\n\t.default_attrs\t= ext4_feat_attrs,\n\t.sysfs_ops\t= &ext4_attr_ops,\n\t.release\t= ext4_feat_release,\n};\n\n/*\n * Check whether this filesystem can be mounted based on\n * the features present and the RDONLY/RDWR mount requested.\n * Returns 1 if this filesystem can be mounted as requested,\n * 0 if it cannot be.\n */\nstatic int ext4_feature_set_ok(struct super_block *sb, int readonly)\n{\n\tif (EXT4_HAS_INCOMPAT_FEATURE(sb, ~EXT4_FEATURE_INCOMPAT_SUPP)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t\"Couldn't mount because of \"\n\t\t\t\"unsupported optional features (%x)\",\n\t\t\t(le32_to_cpu(EXT4_SB(sb)->s_es->s_feature_incompat) &\n\t\t\t~EXT4_FEATURE_INCOMPAT_SUPP));\n\t\treturn 0;\n\t}\n\n\tif (readonly)\n\t\treturn 1;\n\n\t/* Check that feature set is OK for a read-write mount */\n\tif (EXT4_HAS_RO_COMPAT_FEATURE(sb, ~EXT4_FEATURE_RO_COMPAT_SUPP)) {\n\t\text4_msg(sb, KERN_ERR, \"couldn't mount RDWR because of \"\n\t\t\t \"unsupported optional features (%x)\",\n\t\t\t (le32_to_cpu(EXT4_SB(sb)->s_es->s_feature_ro_compat) &\n\t\t\t\t~EXT4_FEATURE_RO_COMPAT_SUPP));\n\t\treturn 0;\n\t}\n\t/*\n\t * Large file size enabled file system can only be mounted\n\t * read-write on 32-bit systems if kernel is built with CONFIG_LBDAF\n\t */\n\tif (EXT4_HAS_RO_COMPAT_FEATURE(sb, EXT4_FEATURE_RO_COMPAT_HUGE_FILE)) {\n\t\tif (sizeof(blkcnt_t) < sizeof(u64)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Filesystem with huge files \"\n\t\t\t\t \"cannot be mounted RDWR without \"\n\t\t\t\t \"CONFIG_LBDAF\");\n\t\t\treturn 0;\n\t\t}\n\t}\n\treturn 1;\n}\n\n/*\n * This function is called once a day if we have errors logged\n * on the file system\n */\nstatic void print_daily_error_info(unsigned long arg)\n{\n\tstruct super_block *sb = (struct super_block *) arg;\n\tstruct ext4_sb_info *sbi;\n\tstruct ext4_super_block *es;\n\n\tsbi = EXT4_SB(sb);\n\tes = sbi->s_es;\n\n\tif (es->s_error_count)\n\t\text4_msg(sb, KERN_NOTICE, \"error count: %u\",\n\t\t\t le32_to_cpu(es->s_error_count));\n\tif (es->s_first_error_time) {\n\t\tprintk(KERN_NOTICE \"EXT4-fs (%s): initial error at %u: %.*s:%d\",\n\t\t       sb->s_id, le32_to_cpu(es->s_first_error_time),\n\t\t       (int) sizeof(es->s_first_error_func),\n\t\t       es->s_first_error_func,\n\t\t       le32_to_cpu(es->s_first_error_line));\n\t\tif (es->s_first_error_ino)\n\t\t\tprintk(\": inode %u\",\n\t\t\t       le32_to_cpu(es->s_first_error_ino));\n\t\tif (es->s_first_error_block)\n\t\t\tprintk(\": block %llu\", (unsigned long long)\n\t\t\t       le64_to_cpu(es->s_first_error_block));\n\t\tprintk(\"\\n\");\n\t}\n\tif (es->s_last_error_time) {\n\t\tprintk(KERN_NOTICE \"EXT4-fs (%s): last error at %u: %.*s:%d\",\n\t\t       sb->s_id, le32_to_cpu(es->s_last_error_time),\n\t\t       (int) sizeof(es->s_last_error_func),\n\t\t       es->s_last_error_func,\n\t\t       le32_to_cpu(es->s_last_error_line));\n\t\tif (es->s_last_error_ino)\n\t\t\tprintk(\": inode %u\",\n\t\t\t       le32_to_cpu(es->s_last_error_ino));\n\t\tif (es->s_last_error_block)\n\t\t\tprintk(\": block %llu\", (unsigned long long)\n\t\t\t       le64_to_cpu(es->s_last_error_block));\n\t\tprintk(\"\\n\");\n\t}\n\tmod_timer(&sbi->s_err_report, jiffies + 24*60*60*HZ);  /* Once a day */\n}\n\nstatic void ext4_lazyinode_timeout(unsigned long data)\n{\n\tstruct task_struct *p = (struct task_struct *)data;\n\twake_up_process(p);\n}\n\n/* Find next suitable group and run ext4_init_inode_table */\nstatic int ext4_run_li_request(struct ext4_li_request *elr)\n{\n\tstruct ext4_group_desc *gdp = NULL;\n\text4_group_t group, ngroups;\n\tstruct super_block *sb;\n\tunsigned long timeout = 0;\n\tint ret = 0;\n\n\tsb = elr->lr_super;\n\tngroups = EXT4_SB(sb)->s_groups_count;\n\n\tfor (group = elr->lr_next_group; group < ngroups; group++) {\n\t\tgdp = ext4_get_group_desc(sb, group, NULL);\n\t\tif (!gdp) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!(gdp->bg_flags & cpu_to_le16(EXT4_BG_INODE_ZEROED)))\n\t\t\tbreak;\n\t}\n\n\tif (group == ngroups)\n\t\tret = 1;\n\n\tif (!ret) {\n\t\ttimeout = jiffies;\n\t\tret = ext4_init_inode_table(sb, group,\n\t\t\t\t\t    elr->lr_timeout ? 0 : 1);\n\t\tif (elr->lr_timeout == 0) {\n\t\t\ttimeout = jiffies - timeout;\n\t\t\tif (elr->lr_sbi->s_li_wait_mult)\n\t\t\t\ttimeout *= elr->lr_sbi->s_li_wait_mult;\n\t\t\telse\n\t\t\t\ttimeout *= 20;\n\t\t\telr->lr_timeout = timeout;\n\t\t}\n\t\telr->lr_next_sched = jiffies + elr->lr_timeout;\n\t\telr->lr_next_group = group + 1;\n\t}\n\n\treturn ret;\n}\n\n/*\n * Remove lr_request from the list_request and free the\n * request tructure. Should be called with li_list_mtx held\n */\nstatic void ext4_remove_li_request(struct ext4_li_request *elr)\n{\n\tstruct ext4_sb_info *sbi;\n\n\tif (!elr)\n\t\treturn;\n\n\tsbi = elr->lr_sbi;\n\n\tlist_del(&elr->lr_request);\n\tsbi->s_li_request = NULL;\n\tkfree(elr);\n}\n\nstatic void ext4_unregister_li_request(struct super_block *sb)\n{\n\tstruct ext4_li_request *elr = EXT4_SB(sb)->s_li_request;\n\n\tif (!ext4_li_info)\n\t\treturn;\n\n\tmutex_lock(&ext4_li_info->li_list_mtx);\n\text4_remove_li_request(elr);\n\tmutex_unlock(&ext4_li_info->li_list_mtx);\n}\n\nstatic struct task_struct *ext4_lazyinit_task;\n\n/*\n * This is the function where ext4lazyinit thread lives. It walks\n * through the request list searching for next scheduled filesystem.\n * When such a fs is found, run the lazy initialization request\n * (ext4_rn_li_request) and keep track of the time spend in this\n * function. Based on that time we compute next schedule time of\n * the request. When walking through the list is complete, compute\n * next waking time and put itself into sleep.\n */\nstatic int ext4_lazyinit_thread(void *arg)\n{\n\tstruct ext4_lazy_init *eli = (struct ext4_lazy_init *)arg;\n\tstruct list_head *pos, *n;\n\tstruct ext4_li_request *elr;\n\tunsigned long next_wakeup;\n\tDEFINE_WAIT(wait);\n\n\tBUG_ON(NULL == eli);\n\n\teli->li_timer.data = (unsigned long)current;\n\teli->li_timer.function = ext4_lazyinode_timeout;\n\n\teli->li_task = current;\n\twake_up(&eli->li_wait_task);\n\ncont_thread:\n\twhile (true) {\n\t\tnext_wakeup = MAX_JIFFY_OFFSET;\n\n\t\tmutex_lock(&eli->li_list_mtx);\n\t\tif (list_empty(&eli->li_request_list)) {\n\t\t\tmutex_unlock(&eli->li_list_mtx);\n\t\t\tgoto exit_thread;\n\t\t}\n\n\t\tlist_for_each_safe(pos, n, &eli->li_request_list) {\n\t\t\telr = list_entry(pos, struct ext4_li_request,\n\t\t\t\t\t lr_request);\n\n\t\t\tif (time_after_eq(jiffies, elr->lr_next_sched)) {\n\t\t\t\tif (ext4_run_li_request(elr) != 0) {\n\t\t\t\t\t/* error, remove the lazy_init job */\n\t\t\t\t\text4_remove_li_request(elr);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (time_before(elr->lr_next_sched, next_wakeup))\n\t\t\t\tnext_wakeup = elr->lr_next_sched;\n\t\t}\n\t\tmutex_unlock(&eli->li_list_mtx);\n\n\t\tif (freezing(current))\n\t\t\trefrigerator();\n\n\t\tif ((time_after_eq(jiffies, next_wakeup)) ||\n\t\t    (MAX_JIFFY_OFFSET == next_wakeup)) {\n\t\t\tcond_resched();\n\t\t\tcontinue;\n\t\t}\n\n\t\teli->li_timer.expires = next_wakeup;\n\t\tadd_timer(&eli->li_timer);\n\t\tprepare_to_wait(&eli->li_wait_daemon, &wait,\n\t\t\t\tTASK_INTERRUPTIBLE);\n\t\tif (time_before(jiffies, next_wakeup))\n\t\t\tschedule();\n\t\tfinish_wait(&eli->li_wait_daemon, &wait);\n\t\tif (kthread_should_stop()) {\n\t\t\text4_clear_request_list();\n\t\t\tgoto exit_thread;\n\t\t}\n\t}\n\nexit_thread:\n\t/*\n\t * It looks like the request list is empty, but we need\n\t * to check it under the li_list_mtx lock, to prevent any\n\t * additions into it, and of course we should lock ext4_li_mtx\n\t * to atomically free the list and ext4_li_info, because at\n\t * this point another ext4 filesystem could be registering\n\t * new one.\n\t */\n\tmutex_lock(&ext4_li_mtx);\n\tmutex_lock(&eli->li_list_mtx);\n\tif (!list_empty(&eli->li_request_list)) {\n\t\tmutex_unlock(&eli->li_list_mtx);\n\t\tmutex_unlock(&ext4_li_mtx);\n\t\tgoto cont_thread;\n\t}\n\tmutex_unlock(&eli->li_list_mtx);\n\tdel_timer_sync(&ext4_li_info->li_timer);\n\teli->li_task = NULL;\n\twake_up(&eli->li_wait_task);\n\n\tkfree(ext4_li_info);\n\text4_lazyinit_task = NULL;\n\text4_li_info = NULL;\n\tmutex_unlock(&ext4_li_mtx);\n\n\treturn 0;\n}\n\nstatic void ext4_clear_request_list(void)\n{\n\tstruct list_head *pos, *n;\n\tstruct ext4_li_request *elr;\n\n\tmutex_lock(&ext4_li_info->li_list_mtx);\n\tlist_for_each_safe(pos, n, &ext4_li_info->li_request_list) {\n\t\telr = list_entry(pos, struct ext4_li_request,\n\t\t\t\t lr_request);\n\t\text4_remove_li_request(elr);\n\t}\n\tmutex_unlock(&ext4_li_info->li_list_mtx);\n}\n\nstatic int ext4_run_lazyinit_thread(void)\n{\n\text4_lazyinit_task = kthread_run(ext4_lazyinit_thread,\n\t\t\t\t\t ext4_li_info, \"ext4lazyinit\");\n\tif (IS_ERR(ext4_lazyinit_task)) {\n\t\tint err = PTR_ERR(ext4_lazyinit_task);\n\t\text4_clear_request_list();\n\t\tdel_timer_sync(&ext4_li_info->li_timer);\n\t\tkfree(ext4_li_info);\n\t\text4_li_info = NULL;\n\t\tprintk(KERN_CRIT \"EXT4: error %d creating inode table \"\n\t\t\t\t \"initialization thread\\n\",\n\t\t\t\t err);\n\t\treturn err;\n\t}\n\text4_li_info->li_state |= EXT4_LAZYINIT_RUNNING;\n\n\twait_event(ext4_li_info->li_wait_task, ext4_li_info->li_task != NULL);\n\treturn 0;\n}\n\n/*\n * Check whether it make sense to run itable init. thread or not.\n * If there is at least one uninitialized inode table, return\n * corresponding group number, else the loop goes through all\n * groups and return total number of groups.\n */\nstatic ext4_group_t ext4_has_uninit_itable(struct super_block *sb)\n{\n\text4_group_t group, ngroups = EXT4_SB(sb)->s_groups_count;\n\tstruct ext4_group_desc *gdp = NULL;\n\n\tfor (group = 0; group < ngroups; group++) {\n\t\tgdp = ext4_get_group_desc(sb, group, NULL);\n\t\tif (!gdp)\n\t\t\tcontinue;\n\n\t\tif (!(gdp->bg_flags & cpu_to_le16(EXT4_BG_INODE_ZEROED)))\n\t\t\tbreak;\n\t}\n\n\treturn group;\n}\n\nstatic int ext4_li_info_new(void)\n{\n\tstruct ext4_lazy_init *eli = NULL;\n\n\teli = kzalloc(sizeof(*eli), GFP_KERNEL);\n\tif (!eli)\n\t\treturn -ENOMEM;\n\n\teli->li_task = NULL;\n\tINIT_LIST_HEAD(&eli->li_request_list);\n\tmutex_init(&eli->li_list_mtx);\n\n\tinit_waitqueue_head(&eli->li_wait_daemon);\n\tinit_waitqueue_head(&eli->li_wait_task);\n\tinit_timer(&eli->li_timer);\n\teli->li_state |= EXT4_LAZYINIT_QUIT;\n\n\text4_li_info = eli;\n\n\treturn 0;\n}\n\nstatic struct ext4_li_request *ext4_li_request_new(struct super_block *sb,\n\t\t\t\t\t    ext4_group_t start)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_li_request *elr;\n\tunsigned long rnd;\n\n\telr = kzalloc(sizeof(*elr), GFP_KERNEL);\n\tif (!elr)\n\t\treturn NULL;\n\n\telr->lr_super = sb;\n\telr->lr_sbi = sbi;\n\telr->lr_next_group = start;\n\n\t/*\n\t * Randomize first schedule time of the request to\n\t * spread the inode table initialization requests\n\t * better.\n\t */\n\tget_random_bytes(&rnd, sizeof(rnd));\n\telr->lr_next_sched = jiffies + (unsigned long)rnd %\n\t\t\t     (EXT4_DEF_LI_MAX_START_DELAY * HZ);\n\n\treturn elr;\n}\n\nstatic int ext4_register_li_request(struct super_block *sb,\n\t\t\t\t    ext4_group_t first_not_zeroed)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_li_request *elr;\n\text4_group_t ngroups = EXT4_SB(sb)->s_groups_count;\n\tint ret = 0;\n\n\tif (sbi->s_li_request != NULL)\n\t\treturn 0;\n\n\tif (first_not_zeroed == ngroups ||\n\t    (sb->s_flags & MS_RDONLY) ||\n\t    !test_opt(sb, INIT_INODE_TABLE)) {\n\t\tsbi->s_li_request = NULL;\n\t\treturn 0;\n\t}\n\n\tif (first_not_zeroed == ngroups) {\n\t\tsbi->s_li_request = NULL;\n\t\treturn 0;\n\t}\n\n\telr = ext4_li_request_new(sb, first_not_zeroed);\n\tif (!elr)\n\t\treturn -ENOMEM;\n\n\tmutex_lock(&ext4_li_mtx);\n\n\tif (NULL == ext4_li_info) {\n\t\tret = ext4_li_info_new();\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\n\tmutex_lock(&ext4_li_info->li_list_mtx);\n\tlist_add(&elr->lr_request, &ext4_li_info->li_request_list);\n\tmutex_unlock(&ext4_li_info->li_list_mtx);\n\n\tsbi->s_li_request = elr;\n\t/*\n\t * set elr to NULL here since it has been inserted to\n\t * the request_list and the removal and free of it is\n\t * handled by ext4_clear_request_list from now on.\n\t */\n\telr = NULL;\n\n\tif (!(ext4_li_info->li_state & EXT4_LAZYINIT_RUNNING)) {\n\t\tret = ext4_run_lazyinit_thread();\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\nout:\n\tmutex_unlock(&ext4_li_mtx);\n\tif (ret)\n\t\tkfree(elr);\n\treturn ret;\n}\n\n/*\n * We do not need to lock anything since this is called on\n * module unload.\n */\nstatic void ext4_destroy_lazyinit_thread(void)\n{\n\t/*\n\t * If thread exited earlier\n\t * there's nothing to be done.\n\t */\n\tif (!ext4_li_info || !ext4_lazyinit_task)\n\t\treturn;\n\n\tkthread_stop(ext4_lazyinit_task);\n}\n\nstatic int ext4_fill_super(struct super_block *sb, void *data, int silent)\n\t\t\t\t__releases(kernel_lock)\n\t\t\t\t__acquires(kernel_lock)\n{\n\tchar *orig_data = kstrdup(data, GFP_KERNEL);\n\tstruct buffer_head *bh;\n\tstruct ext4_super_block *es = NULL;\n\tstruct ext4_sb_info *sbi;\n\text4_fsblk_t block;\n\text4_fsblk_t sb_block = get_sb_block(&data);\n\text4_fsblk_t logical_sb_block;\n\tunsigned long offset = 0;\n\tunsigned long journal_devnum = 0;\n\tunsigned long def_mount_opts;\n\tstruct inode *root;\n\tchar *cp;\n\tconst char *descr;\n\tint ret = -ENOMEM;\n\tint blocksize;\n\tunsigned int db_count;\n\tunsigned int i;\n\tint needs_recovery, has_huge_files;\n\t__u64 blocks_count;\n\tint err;\n\tunsigned int journal_ioprio = DEFAULT_JOURNAL_IOPRIO;\n\text4_group_t first_not_zeroed;\n\n\tsbi = kzalloc(sizeof(*sbi), GFP_KERNEL);\n\tif (!sbi)\n\t\tgoto out_free_orig;\n\n\tsbi->s_blockgroup_lock =\n\t\tkzalloc(sizeof(struct blockgroup_lock), GFP_KERNEL);\n\tif (!sbi->s_blockgroup_lock) {\n\t\tkfree(sbi);\n\t\tgoto out_free_orig;\n\t}\n\tsb->s_fs_info = sbi;\n\tsbi->s_mount_opt = 0;\n\tsbi->s_resuid = EXT4_DEF_RESUID;\n\tsbi->s_resgid = EXT4_DEF_RESGID;\n\tsbi->s_inode_readahead_blks = EXT4_DEF_INODE_READAHEAD_BLKS;\n\tsbi->s_sb_block = sb_block;\n\tif (sb->s_bdev->bd_part)\n\t\tsbi->s_sectors_written_start =\n\t\t\tpart_stat_read(sb->s_bdev->bd_part, sectors[1]);\n\n\t/* Cleanup superblock name */\n\tfor (cp = sb->s_id; (cp = strchr(cp, '/'));)\n\t\t*cp = '!';\n\n\tret = -EINVAL;\n\tblocksize = sb_min_blocksize(sb, EXT4_MIN_BLOCK_SIZE);\n\tif (!blocksize) {\n\t\text4_msg(sb, KERN_ERR, \"unable to set blocksize\");\n\t\tgoto out_fail;\n\t}\n\n\t/*\n\t * The ext4 superblock will not be buffer aligned for other than 1kB\n\t * block sizes.  We need to calculate the offset from buffer start.\n\t */\n\tif (blocksize != EXT4_MIN_BLOCK_SIZE) {\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t} else {\n\t\tlogical_sb_block = sb_block;\n\t}\n\n\tif (!(bh = sb_bread(sb, logical_sb_block))) {\n\t\text4_msg(sb, KERN_ERR, \"unable to read superblock\");\n\t\tgoto out_fail;\n\t}\n\t/*\n\t * Note: s_es must be initialized as soon as possible because\n\t *       some ext4 macro-instructions depend on its value\n\t */\n\tes = (struct ext4_super_block *) (((char *)bh->b_data) + offset);\n\tsbi->s_es = es;\n\tsb->s_magic = le16_to_cpu(es->s_magic);\n\tif (sb->s_magic != EXT4_SUPER_MAGIC)\n\t\tgoto cantfind_ext4;\n\tsbi->s_kbytes_written = le64_to_cpu(es->s_kbytes_written);\n\n\t/* Set defaults before we parse the mount options */\n\tdef_mount_opts = le32_to_cpu(es->s_default_mount_opts);\n\tset_opt(sb, INIT_INODE_TABLE);\n\tif (def_mount_opts & EXT4_DEFM_DEBUG)\n\t\tset_opt(sb, DEBUG);\n\tif (def_mount_opts & EXT4_DEFM_BSDGROUPS) {\n\t\text4_msg(sb, KERN_WARNING, deprecated_msg, \"bsdgroups\",\n\t\t\t\"2.6.38\");\n\t\tset_opt(sb, GRPID);\n\t}\n\tif (def_mount_opts & EXT4_DEFM_UID16)\n\t\tset_opt(sb, NO_UID32);\n\t/* xattr user namespace & acls are now defaulted on */\n#ifdef CONFIG_EXT4_FS_XATTR\n\tset_opt(sb, XATTR_USER);\n#endif\n#ifdef CONFIG_EXT4_FS_POSIX_ACL\n\tset_opt(sb, POSIX_ACL);\n#endif\n\tset_opt(sb, MBLK_IO_SUBMIT);\n\tif ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_DATA)\n\t\tset_opt(sb, JOURNAL_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_ORDERED)\n\t\tset_opt(sb, ORDERED_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_WBACK)\n\t\tset_opt(sb, WRITEBACK_DATA);\n\n\tif (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_PANIC)\n\t\tset_opt(sb, ERRORS_PANIC);\n\telse if (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_CONTINUE)\n\t\tset_opt(sb, ERRORS_CONT);\n\telse\n\t\tset_opt(sb, ERRORS_RO);\n\tif (def_mount_opts & EXT4_DEFM_BLOCK_VALIDITY)\n\t\tset_opt(sb, BLOCK_VALIDITY);\n\tif (def_mount_opts & EXT4_DEFM_DISCARD)\n\t\tset_opt(sb, DISCARD);\n\n\tsbi->s_resuid = le16_to_cpu(es->s_def_resuid);\n\tsbi->s_resgid = le16_to_cpu(es->s_def_resgid);\n\tsbi->s_commit_interval = JBD2_DEFAULT_MAX_COMMIT_AGE * HZ;\n\tsbi->s_min_batch_time = EXT4_DEF_MIN_BATCH_TIME;\n\tsbi->s_max_batch_time = EXT4_DEF_MAX_BATCH_TIME;\n\n\tif ((def_mount_opts & EXT4_DEFM_NOBARRIER) == 0)\n\t\tset_opt(sb, BARRIER);\n\n\t/*\n\t * enable delayed allocation by default\n\t * Use -o nodelalloc to turn it off\n\t */\n\tif (!IS_EXT3_SB(sb) &&\n\t    ((def_mount_opts & EXT4_DEFM_NODELALLOC) == 0))\n\t\tset_opt(sb, DELALLOC);\n\n\tif (!parse_options((char *) sbi->s_es->s_mount_opts, sb,\n\t\t\t   &journal_devnum, &journal_ioprio, NULL, 0)) {\n\t\text4_msg(sb, KERN_WARNING,\n\t\t\t \"failed to parse options in superblock: %s\",\n\t\t\t sbi->s_es->s_mount_opts);\n\t}\n\tif (!parse_options((char *) data, sb, &journal_devnum,\n\t\t\t   &journal_ioprio, NULL, 0))\n\t\tgoto failed_mount;\n\n\tsb->s_flags = (sb->s_flags & ~MS_POSIXACL) |\n\t\t(test_opt(sb, POSIX_ACL) ? MS_POSIXACL : 0);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV &&\n\t    (EXT4_HAS_COMPAT_FEATURE(sb, ~0U) ||\n\t     EXT4_HAS_RO_COMPAT_FEATURE(sb, ~0U) ||\n\t     EXT4_HAS_INCOMPAT_FEATURE(sb, ~0U)))\n\t\text4_msg(sb, KERN_WARNING,\n\t\t       \"feature flags set on rev 0 fs, \"\n\t\t       \"running e2fsck is recommended\");\n\n\t/*\n\t * Check feature flags regardless of the revision level, since we\n\t * previously didn't change the revision level when setting the flags,\n\t * so there is a chance incompat flags are set on a rev 0 filesystem.\n\t */\n\tif (!ext4_feature_set_ok(sb, (sb->s_flags & MS_RDONLY)))\n\t\tgoto failed_mount;\n\n\tblocksize = BLOCK_SIZE << le32_to_cpu(es->s_log_block_size);\n\n\tif (blocksize < EXT4_MIN_BLOCK_SIZE ||\n\t    blocksize > EXT4_MAX_BLOCK_SIZE) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t       \"Unsupported filesystem blocksize %d\", blocksize);\n\t\tgoto failed_mount;\n\t}\n\n\tif (sb->s_blocksize != blocksize) {\n\t\t/* Validate the filesystem blocksize */\n\t\tif (!sb_set_blocksize(sb, blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR, \"bad block size %d\",\n\t\t\t\t\tblocksize);\n\t\t\tgoto failed_mount;\n\t\t}\n\n\t\tbrelse(bh);\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t\tbh = sb_bread(sb, logical_sb_block);\n\t\tif (!bh) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Can't read superblock on 2nd try\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tes = (struct ext4_super_block *)(((char *)bh->b_data) + offset);\n\t\tsbi->s_es = es;\n\t\tif (es->s_magic != cpu_to_le16(EXT4_SUPER_MAGIC)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Magic mismatch, very weird!\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\thas_huge_files = EXT4_HAS_RO_COMPAT_FEATURE(sb,\n\t\t\t\tEXT4_FEATURE_RO_COMPAT_HUGE_FILE);\n\tsbi->s_bitmap_maxbytes = ext4_max_bitmap_size(sb->s_blocksize_bits,\n\t\t\t\t\t\t      has_huge_files);\n\tsb->s_maxbytes = ext4_max_size(sb->s_blocksize_bits, has_huge_files);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV) {\n\t\tsbi->s_inode_size = EXT4_GOOD_OLD_INODE_SIZE;\n\t\tsbi->s_first_ino = EXT4_GOOD_OLD_FIRST_INO;\n\t} else {\n\t\tsbi->s_inode_size = le16_to_cpu(es->s_inode_size);\n\t\tsbi->s_first_ino = le32_to_cpu(es->s_first_ino);\n\t\tif ((sbi->s_inode_size < EXT4_GOOD_OLD_INODE_SIZE) ||\n\t\t    (!is_power_of_2(sbi->s_inode_size)) ||\n\t\t    (sbi->s_inode_size > blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported inode size: %d\",\n\t\t\t       sbi->s_inode_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE)\n\t\t\tsb->s_time_gran = 1 << (EXT4_EPOCH_BITS - 2);\n\t}\n\n\tsbi->s_desc_size = le16_to_cpu(es->s_desc_size);\n\tif (EXT4_HAS_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_64BIT)) {\n\t\tif (sbi->s_desc_size < EXT4_MIN_DESC_SIZE_64BIT ||\n\t\t    sbi->s_desc_size > EXT4_MAX_DESC_SIZE ||\n\t\t    !is_power_of_2(sbi->s_desc_size)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported descriptor size %lu\",\n\t\t\t       sbi->s_desc_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t} else\n\t\tsbi->s_desc_size = EXT4_MIN_DESC_SIZE;\n\n\tsbi->s_blocks_per_group = le32_to_cpu(es->s_blocks_per_group);\n\tsbi->s_inodes_per_group = le32_to_cpu(es->s_inodes_per_group);\n\tif (EXT4_INODE_SIZE(sb) == 0 || EXT4_INODES_PER_GROUP(sb) == 0)\n\t\tgoto cantfind_ext4;\n\n\tsbi->s_inodes_per_block = blocksize / EXT4_INODE_SIZE(sb);\n\tif (sbi->s_inodes_per_block == 0)\n\t\tgoto cantfind_ext4;\n\tsbi->s_itb_per_group = sbi->s_inodes_per_group /\n\t\t\t\t\tsbi->s_inodes_per_block;\n\tsbi->s_desc_per_block = blocksize / EXT4_DESC_SIZE(sb);\n\tsbi->s_sbh = bh;\n\tsbi->s_mount_state = le16_to_cpu(es->s_state);\n\tsbi->s_addr_per_block_bits = ilog2(EXT4_ADDR_PER_BLOCK(sb));\n\tsbi->s_desc_per_block_bits = ilog2(EXT4_DESC_PER_BLOCK(sb));\n\n\tfor (i = 0; i < 4; i++)\n\t\tsbi->s_hash_seed[i] = le32_to_cpu(es->s_hash_seed[i]);\n\tsbi->s_def_hash_version = es->s_def_hash_version;\n\ti = le32_to_cpu(es->s_flags);\n\tif (i & EXT2_FLAGS_UNSIGNED_HASH)\n\t\tsbi->s_hash_unsigned = 3;\n\telse if ((i & EXT2_FLAGS_SIGNED_HASH) == 0) {\n#ifdef __CHAR_UNSIGNED__\n\t\tes->s_flags |= cpu_to_le32(EXT2_FLAGS_UNSIGNED_HASH);\n\t\tsbi->s_hash_unsigned = 3;\n#else\n\t\tes->s_flags |= cpu_to_le32(EXT2_FLAGS_SIGNED_HASH);\n#endif\n\t\tsb->s_dirt = 1;\n\t}\n\n\tif (sbi->s_blocks_per_group > blocksize * 8) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t       \"#blocks per group too big: %lu\",\n\t\t       sbi->s_blocks_per_group);\n\t\tgoto failed_mount;\n\t}\n\tif (sbi->s_inodes_per_group > blocksize * 8) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t       \"#inodes per group too big: %lu\",\n\t\t       sbi->s_inodes_per_group);\n\t\tgoto failed_mount;\n\t}\n\n\t/*\n\t * Test whether we have more sectors than will fit in sector_t,\n\t * and whether the max offset is addressable by the page cache.\n\t */\n\terr = generic_check_addressable(sb->s_blocksize_bits,\n\t\t\t\t\text4_blocks_count(es));\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"filesystem\"\n\t\t\t \" too large to mount safely on this system\");\n\t\tif (sizeof(sector_t) < 8)\n\t\t\text4_msg(sb, KERN_WARNING, \"CONFIG_LBDAF not enabled\");\n\t\tret = err;\n\t\tgoto failed_mount;\n\t}\n\n\tif (EXT4_BLOCKS_PER_GROUP(sb) == 0)\n\t\tgoto cantfind_ext4;\n\n\t/* check blocks count against device size */\n\tblocks_count = sb->s_bdev->bd_inode->i_size >> sb->s_blocksize_bits;\n\tif (blocks_count && ext4_blocks_count(es) > blocks_count) {\n\t\text4_msg(sb, KERN_WARNING, \"bad geometry: block count %llu \"\n\t\t       \"exceeds size of device (%llu blocks)\",\n\t\t       ext4_blocks_count(es), blocks_count);\n\t\tgoto failed_mount;\n\t}\n\n\t/*\n\t * It makes no sense for the first data block to be beyond the end\n\t * of the filesystem.\n\t */\n\tif (le32_to_cpu(es->s_first_data_block) >= ext4_blocks_count(es)) {\n                ext4_msg(sb, KERN_WARNING, \"bad geometry: first data\"\n\t\t\t \"block %u is beyond end of filesystem (%llu)\",\n\t\t\t le32_to_cpu(es->s_first_data_block),\n\t\t\t ext4_blocks_count(es));\n\t\tgoto failed_mount;\n\t}\n\tblocks_count = (ext4_blocks_count(es) -\n\t\t\tle32_to_cpu(es->s_first_data_block) +\n\t\t\tEXT4_BLOCKS_PER_GROUP(sb) - 1);\n\tdo_div(blocks_count, EXT4_BLOCKS_PER_GROUP(sb));\n\tif (blocks_count > ((uint64_t)1<<32) - EXT4_DESC_PER_BLOCK(sb)) {\n\t\text4_msg(sb, KERN_WARNING, \"groups count too large: %u \"\n\t\t       \"(block count %llu, first data block %u, \"\n\t\t       \"blocks per group %lu)\", sbi->s_groups_count,\n\t\t       ext4_blocks_count(es),\n\t\t       le32_to_cpu(es->s_first_data_block),\n\t\t       EXT4_BLOCKS_PER_GROUP(sb));\n\t\tgoto failed_mount;\n\t}\n\tsbi->s_groups_count = blocks_count;\n\tsbi->s_blockfile_groups = min_t(ext4_group_t, sbi->s_groups_count,\n\t\t\t(EXT4_MAX_BLOCK_FILE_PHYS / EXT4_BLOCKS_PER_GROUP(sb)));\n\tdb_count = (sbi->s_groups_count + EXT4_DESC_PER_BLOCK(sb) - 1) /\n\t\t   EXT4_DESC_PER_BLOCK(sb);\n\tsbi->s_group_desc = kmalloc(db_count * sizeof(struct buffer_head *),\n\t\t\t\t    GFP_KERNEL);\n\tif (sbi->s_group_desc == NULL) {\n\t\text4_msg(sb, KERN_ERR, \"not enough memory\");\n\t\tgoto failed_mount;\n\t}\n\n#ifdef CONFIG_PROC_FS\n\tif (ext4_proc_root)\n\t\tsbi->s_proc = proc_mkdir(sb->s_id, ext4_proc_root);\n#endif\n\n\tbgl_lock_init(sbi->s_blockgroup_lock);\n\n\tfor (i = 0; i < db_count; i++) {\n\t\tblock = descriptor_loc(sb, logical_sb_block, i);\n\t\tsbi->s_group_desc[i] = sb_bread(sb, block);\n\t\tif (!sbi->s_group_desc[i]) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"can't read group descriptor %d\", i);\n\t\t\tdb_count = i;\n\t\t\tgoto failed_mount2;\n\t\t}\n\t}\n\tif (!ext4_check_descriptors(sb, &first_not_zeroed)) {\n\t\text4_msg(sb, KERN_ERR, \"group descriptors corrupted!\");\n\t\tgoto failed_mount2;\n\t}\n\tif (EXT4_HAS_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_FLEX_BG))\n\t\tif (!ext4_fill_flex_info(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unable to initialize \"\n\t\t\t       \"flex_bg meta info!\");\n\t\t\tgoto failed_mount2;\n\t\t}\n\n\tsbi->s_gdb_count = db_count;\n\tget_random_bytes(&sbi->s_next_generation, sizeof(u32));\n\tspin_lock_init(&sbi->s_next_gen_lock);\n\n\terr = percpu_counter_init(&sbi->s_freeblocks_counter,\n\t\t\text4_count_free_blocks(sb));\n\tif (!err) {\n\t\terr = percpu_counter_init(&sbi->s_freeinodes_counter,\n\t\t\t\text4_count_free_inodes(sb));\n\t}\n\tif (!err) {\n\t\terr = percpu_counter_init(&sbi->s_dirs_counter,\n\t\t\t\text4_count_dirs(sb));\n\t}\n\tif (!err) {\n\t\terr = percpu_counter_init(&sbi->s_dirtyblocks_counter, 0);\n\t}\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"insufficient memory\");\n\t\tgoto failed_mount3;\n\t}\n\n\tsbi->s_stripe = ext4_get_stripe_size(sbi);\n\tsbi->s_max_writeback_mb_bump = 128;\n\n\t/*\n\t * set up enough so that it can read an inode\n\t */\n\tif (!test_opt(sb, NOLOAD) &&\n\t    EXT4_HAS_COMPAT_FEATURE(sb, EXT4_FEATURE_COMPAT_HAS_JOURNAL))\n\t\tsb->s_op = &ext4_sops;\n\telse\n\t\tsb->s_op = &ext4_nojournal_sops;\n\tsb->s_export_op = &ext4_export_ops;\n\tsb->s_xattr = ext4_xattr_handlers;\n#ifdef CONFIG_QUOTA\n\tsb->s_qcop = &ext4_qctl_operations;\n\tsb->dq_op = &ext4_quota_operations;\n#endif\n\tmemcpy(sb->s_uuid, es->s_uuid, sizeof(es->s_uuid));\n\n\tINIT_LIST_HEAD(&sbi->s_orphan); /* unlinked but open files */\n\tmutex_init(&sbi->s_orphan_lock);\n\tmutex_init(&sbi->s_resize_lock);\n\n\tsb->s_root = NULL;\n\n\tneeds_recovery = (es->s_last_orphan != 0 ||\n\t\t\t  EXT4_HAS_INCOMPAT_FEATURE(sb,\n\t\t\t\t    EXT4_FEATURE_INCOMPAT_RECOVER));\n\n\t/*\n\t * The first inode we look at is the journal inode.  Don't try\n\t * root first: it may be modified in the journal!\n\t */\n\tif (!test_opt(sb, NOLOAD) &&\n\t    EXT4_HAS_COMPAT_FEATURE(sb, EXT4_FEATURE_COMPAT_HAS_JOURNAL)) {\n\t\tif (ext4_load_journal(sb, es, journal_devnum))\n\t\t\tgoto failed_mount3;\n\t} else if (test_opt(sb, NOLOAD) && !(sb->s_flags & MS_RDONLY) &&\n\t      EXT4_HAS_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_RECOVER)) {\n\t\text4_msg(sb, KERN_ERR, \"required journal recovery \"\n\t\t       \"suppressed and not mounted read-only\");\n\t\tgoto failed_mount_wq;\n\t} else {\n\t\tclear_opt(sb, DATA_FLAGS);\n\t\tset_opt(sb, WRITEBACK_DATA);\n\t\tsbi->s_journal = NULL;\n\t\tneeds_recovery = 0;\n\t\tgoto no_journal;\n\t}\n\n\tif (ext4_blocks_count(es) > 0xffffffffULL &&\n\t    !jbd2_journal_set_features(EXT4_SB(sb)->s_journal, 0, 0,\n\t\t\t\t       JBD2_FEATURE_INCOMPAT_64BIT)) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to set 64-bit journal feature\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif (test_opt(sb, JOURNAL_ASYNC_COMMIT)) {\n\t\tjbd2_journal_set_features(sbi->s_journal,\n\t\t\t\tJBD2_FEATURE_COMPAT_CHECKSUM, 0,\n\t\t\t\tJBD2_FEATURE_INCOMPAT_ASYNC_COMMIT);\n\t} else if (test_opt(sb, JOURNAL_CHECKSUM)) {\n\t\tjbd2_journal_set_features(sbi->s_journal,\n\t\t\t\tJBD2_FEATURE_COMPAT_CHECKSUM, 0, 0);\n\t\tjbd2_journal_clear_features(sbi->s_journal, 0, 0,\n\t\t\t\tJBD2_FEATURE_INCOMPAT_ASYNC_COMMIT);\n\t} else {\n\t\tjbd2_journal_clear_features(sbi->s_journal,\n\t\t\t\tJBD2_FEATURE_COMPAT_CHECKSUM, 0,\n\t\t\t\tJBD2_FEATURE_INCOMPAT_ASYNC_COMMIT);\n\t}\n\n\t/* We have now updated the journal if required, so we can\n\t * validate the data journaling mode. */\n\tswitch (test_opt(sb, DATA_FLAGS)) {\n\tcase 0:\n\t\t/* No mode set, assume a default based on the journal\n\t\t * capabilities: ORDERED_DATA if the journal can\n\t\t * cope, else JOURNAL_DATA\n\t\t */\n\t\tif (jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE))\n\t\t\tset_opt(sb, ORDERED_DATA);\n\t\telse\n\t\t\tset_opt(sb, JOURNAL_DATA);\n\t\tbreak;\n\n\tcase EXT4_MOUNT_ORDERED_DATA:\n\tcase EXT4_MOUNT_WRITEBACK_DATA:\n\t\tif (!jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Journal does not support \"\n\t\t\t       \"requested data journaling mode\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\tdefault:\n\t\tbreak;\n\t}\n\tset_task_ioprio(sbi->s_journal->j_task, journal_ioprio);\n\n\t/*\n\t * The journal may have updated the bg summary counts, so we\n\t * need to update the global counters.\n\t */\n\tpercpu_counter_set(&sbi->s_freeblocks_counter,\n\t\t\t   ext4_count_free_blocks(sb));\n\tpercpu_counter_set(&sbi->s_freeinodes_counter,\n\t\t\t   ext4_count_free_inodes(sb));\n\tpercpu_counter_set(&sbi->s_dirs_counter,\n\t\t\t   ext4_count_dirs(sb));\n\tpercpu_counter_set(&sbi->s_dirtyblocks_counter, 0);\n\nno_journal:\n\t/*\n\t * The maximum number of concurrent works can be high and\n\t * concurrency isn't really necessary.  Limit it to 1.\n\t */\n\tEXT4_SB(sb)->dio_unwritten_wq =\n\t\talloc_workqueue(\"ext4-dio-unwritten\", WQ_MEM_RECLAIM | WQ_UNBOUND, 1);\n\tif (!EXT4_SB(sb)->dio_unwritten_wq) {\n\t\tprintk(KERN_ERR \"EXT4-fs: failed to create DIO workqueue\\n\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\t/*\n\t * The jbd2_journal_load will have done any necessary log recovery,\n\t * so we can safely mount the rest of the filesystem now.\n\t */\n\n\troot = ext4_iget(sb, EXT4_ROOT_INO);\n\tif (IS_ERR(root)) {\n\t\text4_msg(sb, KERN_ERR, \"get root inode failed\");\n\t\tret = PTR_ERR(root);\n\t\troot = NULL;\n\t\tgoto failed_mount4;\n\t}\n\tif (!S_ISDIR(root->i_mode) || !root->i_blocks || !root->i_size) {\n\t\text4_msg(sb, KERN_ERR, \"corrupt root inode, run e2fsck\");\n\t\tgoto failed_mount4;\n\t}\n\tsb->s_root = d_alloc_root(root);\n\tif (!sb->s_root) {\n\t\text4_msg(sb, KERN_ERR, \"get root dentry failed\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount4;\n\t}\n\n\text4_setup_super(sb, es, sb->s_flags & MS_RDONLY);\n\n\t/* determine the minimum size of new large inodes, if present */\n\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t     EXT4_GOOD_OLD_INODE_SIZE;\n\t\tif (EXT4_HAS_RO_COMPAT_FEATURE(sb,\n\t\t\t\t       EXT4_FEATURE_RO_COMPAT_EXTRA_ISIZE)) {\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_want_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_want_extra_isize);\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_min_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_min_extra_isize);\n\t\t}\n\t}\n\t/* Check if enough inode space is available */\n\tif (EXT4_GOOD_OLD_INODE_SIZE + sbi->s_want_extra_isize >\n\t\t\t\t\t\t\tsbi->s_inode_size) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t       EXT4_GOOD_OLD_INODE_SIZE;\n\t\text4_msg(sb, KERN_INFO, \"required extra inode space not\"\n\t\t\t \"available\");\n\t}\n\n\tif (test_opt(sb, DELALLOC) &&\n\t    (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA)) {\n\t\text4_msg(sb, KERN_WARNING, \"Ignoring delalloc option - \"\n\t\t\t \"requested data journaling mode\");\n\t\tclear_opt(sb, DELALLOC);\n\t}\n\tif (test_opt(sb, DIOREAD_NOLOCK)) {\n\t\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA) {\n\t\t\text4_msg(sb, KERN_WARNING, \"Ignoring dioread_nolock \"\n\t\t\t\t\"option - requested data journaling mode\");\n\t\t\tclear_opt(sb, DIOREAD_NOLOCK);\n\t\t}\n\t\tif (sb->s_blocksize < PAGE_SIZE) {\n\t\t\text4_msg(sb, KERN_WARNING, \"Ignoring dioread_nolock \"\n\t\t\t\t\"option - block size is too small\");\n\t\t\tclear_opt(sb, DIOREAD_NOLOCK);\n\t\t}\n\t}\n\n\terr = ext4_setup_system_zone(sb);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize system \"\n\t\t\t \"zone (%d)\", err);\n\t\tgoto failed_mount4;\n\t}\n\n\text4_ext_init(sb);\n\terr = ext4_mb_init(sb, needs_recovery);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize mballoc (%d)\",\n\t\t\t err);\n\t\tgoto failed_mount4;\n\t}\n\n\terr = ext4_register_li_request(sb, first_not_zeroed);\n\tif (err)\n\t\tgoto failed_mount4;\n\n\tsbi->s_kobj.kset = ext4_kset;\n\tinit_completion(&sbi->s_kobj_unregister);\n\terr = kobject_init_and_add(&sbi->s_kobj, &ext4_ktype, NULL,\n\t\t\t\t   \"%s\", sb->s_id);\n\tif (err) {\n\t\text4_mb_release(sb);\n\t\text4_ext_release(sb);\n\t\tgoto failed_mount4;\n\t};\n\n\tEXT4_SB(sb)->s_mount_state |= EXT4_ORPHAN_FS;\n\text4_orphan_cleanup(sb, es);\n\tEXT4_SB(sb)->s_mount_state &= ~EXT4_ORPHAN_FS;\n\tif (needs_recovery) {\n\t\text4_msg(sb, KERN_INFO, \"recovery complete\");\n\t\text4_mark_recovery_complete(sb, es);\n\t}\n\tif (EXT4_SB(sb)->s_journal) {\n\t\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA)\n\t\t\tdescr = \" journalled data mode\";\n\t\telse if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA)\n\t\t\tdescr = \" ordered data mode\";\n\t\telse\n\t\t\tdescr = \" writeback data mode\";\n\t} else\n\t\tdescr = \"out journal\";\n\n\text4_msg(sb, KERN_INFO, \"mounted filesystem with%s. \"\n\t\t \"Opts: %s%s%s\", descr, sbi->s_es->s_mount_opts,\n\t\t *sbi->s_es->s_mount_opts ? \"; \" : \"\", orig_data);\n\n\tinit_timer(&sbi->s_err_report);\n\tsbi->s_err_report.function = print_daily_error_info;\n\tsbi->s_err_report.data = (unsigned long) sb;\n\tif (es->s_error_count)\n\t\tmod_timer(&sbi->s_err_report, jiffies + 300*HZ); /* 5 minutes */\n\n\tkfree(orig_data);\n\treturn 0;\n\ncantfind_ext4:\n\tif (!silent)\n\t\text4_msg(sb, KERN_ERR, \"VFS: Can't find ext4 filesystem\");\n\tgoto failed_mount;\n\nfailed_mount4:\n\tiput(root);\n\tsb->s_root = NULL;\n\text4_msg(sb, KERN_ERR, \"mount failed\");\n\tdestroy_workqueue(EXT4_SB(sb)->dio_unwritten_wq);\nfailed_mount_wq:\n\text4_release_system_zone(sb);\n\tif (sbi->s_journal) {\n\t\tjbd2_journal_destroy(sbi->s_journal);\n\t\tsbi->s_journal = NULL;\n\t}\nfailed_mount3:\n\tif (sbi->s_flex_groups) {\n\t\tif (is_vmalloc_addr(sbi->s_flex_groups))\n\t\t\tvfree(sbi->s_flex_groups);\n\t\telse\n\t\t\tkfree(sbi->s_flex_groups);\n\t}\n\tpercpu_counter_destroy(&sbi->s_freeblocks_counter);\n\tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n\tpercpu_counter_destroy(&sbi->s_dirs_counter);\n\tpercpu_counter_destroy(&sbi->s_dirtyblocks_counter);\nfailed_mount2:\n\tfor (i = 0; i < db_count; i++)\n\t\tbrelse(sbi->s_group_desc[i]);\n\tkfree(sbi->s_group_desc);\nfailed_mount:\n\tif (sbi->s_proc) {\n\t\tremove_proc_entry(sb->s_id, ext4_proc_root);\n\t}\n#ifdef CONFIG_QUOTA\n\tfor (i = 0; i < MAXQUOTAS; i++)\n\t\tkfree(sbi->s_qf_names[i]);\n#endif\n\text4_blkdev_remove(sbi);\n\tbrelse(bh);\nout_fail:\n\tsb->s_fs_info = NULL;\n\tkfree(sbi->s_blockgroup_lock);\n\tkfree(sbi);\nout_free_orig:\n\tkfree(orig_data);\n\treturn ret;\n}\n\n/*\n * Setup any per-fs journal parameters now.  We'll do this both on\n * initial mount, once the journal has been initialised but before we've\n * done any recovery; and again on any subsequent remount.\n */\nstatic void ext4_init_journal_params(struct super_block *sb, journal_t *journal)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\tjournal->j_commit_interval = sbi->s_commit_interval;\n\tjournal->j_min_batch_time = sbi->s_min_batch_time;\n\tjournal->j_max_batch_time = sbi->s_max_batch_time;\n\n\twrite_lock(&journal->j_state_lock);\n\tif (test_opt(sb, BARRIER))\n\t\tjournal->j_flags |= JBD2_BARRIER;\n\telse\n\t\tjournal->j_flags &= ~JBD2_BARRIER;\n\tif (test_opt(sb, DATA_ERR_ABORT))\n\t\tjournal->j_flags |= JBD2_ABORT_ON_SYNCDATA_ERR;\n\telse\n\t\tjournal->j_flags &= ~JBD2_ABORT_ON_SYNCDATA_ERR;\n\twrite_unlock(&journal->j_state_lock);\n}\n\nstatic journal_t *ext4_get_journal(struct super_block *sb,\n\t\t\t\t   unsigned int journal_inum)\n{\n\tstruct inode *journal_inode;\n\tjournal_t *journal;\n\n\tBUG_ON(!EXT4_HAS_COMPAT_FEATURE(sb, EXT4_FEATURE_COMPAT_HAS_JOURNAL));\n\n\t/* First, test for the existence of a valid inode on disk.  Bad\n\t * things happen if we iget() an unused inode, as the subsequent\n\t * iput() will try to delete it. */\n\n\tjournal_inode = ext4_iget(sb, journal_inum);\n\tif (IS_ERR(journal_inode)) {\n\t\text4_msg(sb, KERN_ERR, \"no journal found\");\n\t\treturn NULL;\n\t}\n\tif (!journal_inode->i_nlink) {\n\t\tmake_bad_inode(journal_inode);\n\t\tiput(journal_inode);\n\t\text4_msg(sb, KERN_ERR, \"journal inode is deleted\");\n\t\treturn NULL;\n\t}\n\n\tjbd_debug(2, \"Journal inode found at %p: %lld bytes\\n\",\n\t\t  journal_inode, journal_inode->i_size);\n\tif (!S_ISREG(journal_inode->i_mode)) {\n\t\text4_msg(sb, KERN_ERR, \"invalid journal inode\");\n\t\tiput(journal_inode);\n\t\treturn NULL;\n\t}\n\n\tjournal = jbd2_journal_init_inode(journal_inode);\n\tif (!journal) {\n\t\text4_msg(sb, KERN_ERR, \"Could not load journal inode\");\n\t\tiput(journal_inode);\n\t\treturn NULL;\n\t}\n\tjournal->j_private = sb;\n\text4_init_journal_params(sb, journal);\n\treturn journal;\n}\n\nstatic journal_t *ext4_get_dev_journal(struct super_block *sb,\n\t\t\t\t       dev_t j_dev)\n{\n\tstruct buffer_head *bh;\n\tjournal_t *journal;\n\text4_fsblk_t start;\n\text4_fsblk_t len;\n\tint hblock, blocksize;\n\text4_fsblk_t sb_block;\n\tunsigned long offset;\n\tstruct ext4_super_block *es;\n\tstruct block_device *bdev;\n\n\tBUG_ON(!EXT4_HAS_COMPAT_FEATURE(sb, EXT4_FEATURE_COMPAT_HAS_JOURNAL));\n\n\tbdev = ext4_blkdev_get(j_dev, sb);\n\tif (bdev == NULL)\n\t\treturn NULL;\n\n\tblocksize = sb->s_blocksize;\n\thblock = bdev_logical_block_size(bdev);\n\tif (blocksize < hblock) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t\"blocksize too small for journal device\");\n\t\tgoto out_bdev;\n\t}\n\n\tsb_block = EXT4_MIN_BLOCK_SIZE / blocksize;\n\toffset = EXT4_MIN_BLOCK_SIZE % blocksize;\n\tset_blocksize(bdev, blocksize);\n\tif (!(bh = __bread(bdev, sb_block, blocksize))) {\n\t\text4_msg(sb, KERN_ERR, \"couldn't read superblock of \"\n\t\t       \"external journal\");\n\t\tgoto out_bdev;\n\t}\n\n\tes = (struct ext4_super_block *) (((char *)bh->b_data) + offset);\n\tif ((le16_to_cpu(es->s_magic) != EXT4_SUPER_MAGIC) ||\n\t    !(le32_to_cpu(es->s_feature_incompat) &\n\t      EXT4_FEATURE_INCOMPAT_JOURNAL_DEV)) {\n\t\text4_msg(sb, KERN_ERR, \"external journal has \"\n\t\t\t\t\t\"bad superblock\");\n\t\tbrelse(bh);\n\t\tgoto out_bdev;\n\t}\n\n\tif (memcmp(EXT4_SB(sb)->s_es->s_journal_uuid, es->s_uuid, 16)) {\n\t\text4_msg(sb, KERN_ERR, \"journal UUID does not match\");\n\t\tbrelse(bh);\n\t\tgoto out_bdev;\n\t}\n\n\tlen = ext4_blocks_count(es);\n\tstart = sb_block + 1;\n\tbrelse(bh);\t/* we're done with the superblock */\n\n\tjournal = jbd2_journal_init_dev(bdev, sb->s_bdev,\n\t\t\t\t\tstart, len, blocksize);\n\tif (!journal) {\n\t\text4_msg(sb, KERN_ERR, \"failed to create device journal\");\n\t\tgoto out_bdev;\n\t}\n\tjournal->j_private = sb;\n\tll_rw_block(READ, 1, &journal->j_sb_buffer);\n\twait_on_buffer(journal->j_sb_buffer);\n\tif (!buffer_uptodate(journal->j_sb_buffer)) {\n\t\text4_msg(sb, KERN_ERR, \"I/O error on journal device\");\n\t\tgoto out_journal;\n\t}\n\tif (be32_to_cpu(journal->j_superblock->s_nr_users) != 1) {\n\t\text4_msg(sb, KERN_ERR, \"External journal has more than one \"\n\t\t\t\t\t\"user (unsupported) - %d\",\n\t\t\tbe32_to_cpu(journal->j_superblock->s_nr_users));\n\t\tgoto out_journal;\n\t}\n\tEXT4_SB(sb)->journal_bdev = bdev;\n\text4_init_journal_params(sb, journal);\n\treturn journal;\n\nout_journal:\n\tjbd2_journal_destroy(journal);\nout_bdev:\n\text4_blkdev_put(bdev);\n\treturn NULL;\n}\n\nstatic int ext4_load_journal(struct super_block *sb,\n\t\t\t     struct ext4_super_block *es,\n\t\t\t     unsigned long journal_devnum)\n{\n\tjournal_t *journal;\n\tunsigned int journal_inum = le32_to_cpu(es->s_journal_inum);\n\tdev_t journal_dev;\n\tint err = 0;\n\tint really_read_only;\n\n\tBUG_ON(!EXT4_HAS_COMPAT_FEATURE(sb, EXT4_FEATURE_COMPAT_HAS_JOURNAL));\n\n\tif (journal_devnum &&\n\t    journal_devnum != le32_to_cpu(es->s_journal_dev)) {\n\t\text4_msg(sb, KERN_INFO, \"external journal device major/minor \"\n\t\t\t\"numbers have changed\");\n\t\tjournal_dev = new_decode_dev(journal_devnum);\n\t} else\n\t\tjournal_dev = new_decode_dev(le32_to_cpu(es->s_journal_dev));\n\n\treally_read_only = bdev_read_only(sb->s_bdev);\n\n\t/*\n\t * Are we loading a blank journal or performing recovery after a\n\t * crash?  For recovery, we need to check in advance whether we\n\t * can get read-write access to the device.\n\t */\n\tif (EXT4_HAS_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_RECOVER)) {\n\t\tif (sb->s_flags & MS_RDONLY) {\n\t\t\text4_msg(sb, KERN_INFO, \"INFO: recovery \"\n\t\t\t\t\t\"required on readonly filesystem\");\n\t\t\tif (really_read_only) {\n\t\t\t\text4_msg(sb, KERN_ERR, \"write access \"\n\t\t\t\t\t\"unavailable, cannot proceed\");\n\t\t\t\treturn -EROFS;\n\t\t\t}\n\t\t\text4_msg(sb, KERN_INFO, \"write access will \"\n\t\t\t       \"be enabled during recovery\");\n\t\t}\n\t}\n\n\tif (journal_inum && journal_dev) {\n\t\text4_msg(sb, KERN_ERR, \"filesystem has both journal \"\n\t\t       \"and inode journals!\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (journal_inum) {\n\t\tif (!(journal = ext4_get_journal(sb, journal_inum)))\n\t\t\treturn -EINVAL;\n\t} else {\n\t\tif (!(journal = ext4_get_dev_journal(sb, journal_dev)))\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (!(journal->j_flags & JBD2_BARRIER))\n\t\text4_msg(sb, KERN_INFO, \"barriers disabled\");\n\n\tif (!really_read_only && test_opt(sb, UPDATE_JOURNAL)) {\n\t\terr = jbd2_journal_update_format(journal);\n\t\tif (err)  {\n\t\t\text4_msg(sb, KERN_ERR, \"error updating journal\");\n\t\t\tjbd2_journal_destroy(journal);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\tif (!EXT4_HAS_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_RECOVER))\n\t\terr = jbd2_journal_wipe(journal, !really_read_only);\n\tif (!err) {\n\t\tchar *save = kmalloc(EXT4_S_ERR_LEN, GFP_KERNEL);\n\t\tif (save)\n\t\t\tmemcpy(save, ((char *) es) +\n\t\t\t       EXT4_S_ERR_START, EXT4_S_ERR_LEN);\n\t\terr = jbd2_journal_load(journal);\n\t\tif (save)\n\t\t\tmemcpy(((char *) es) + EXT4_S_ERR_START,\n\t\t\t       save, EXT4_S_ERR_LEN);\n\t\tkfree(save);\n\t}\n\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"error loading journal\");\n\t\tjbd2_journal_destroy(journal);\n\t\treturn err;\n\t}\n\n\tEXT4_SB(sb)->s_journal = journal;\n\text4_clear_journal_err(sb, es);\n\n\tif (!really_read_only && journal_devnum &&\n\t    journal_devnum != le32_to_cpu(es->s_journal_dev)) {\n\t\tes->s_journal_dev = cpu_to_le32(journal_devnum);\n\n\t\t/* Make sure we flush the recovery flag to disk. */\n\t\text4_commit_super(sb, 1);\n\t}\n\n\treturn 0;\n}\n\nstatic int ext4_commit_super(struct super_block *sb, int sync)\n{\n\tstruct ext4_super_block *es = EXT4_SB(sb)->s_es;\n\tstruct buffer_head *sbh = EXT4_SB(sb)->s_sbh;\n\tint error = 0;\n\n\tif (!sbh)\n\t\treturn error;\n\tif (buffer_write_io_error(sbh)) {\n\t\t/*\n\t\t * Oh, dear.  A previous attempt to write the\n\t\t * superblock failed.  This could happen because the\n\t\t * USB device was yanked out.  Or it could happen to\n\t\t * be a transient write error and maybe the block will\n\t\t * be remapped.  Nothing we can do but to retry the\n\t\t * write and hope for the best.\n\t\t */\n\t\text4_msg(sb, KERN_ERR, \"previous I/O error to \"\n\t\t       \"superblock detected\");\n\t\tclear_buffer_write_io_error(sbh);\n\t\tset_buffer_uptodate(sbh);\n\t}\n\t/*\n\t * If the file system is mounted read-only, don't update the\n\t * superblock write time.  This avoids updating the superblock\n\t * write time when we are mounting the root file system\n\t * read/only but we need to replay the journal; at that point,\n\t * for people who are east of GMT and who make their clock\n\t * tick in localtime for Windows bug-for-bug compatibility,\n\t * the clock is set in the future, and this will cause e2fsck\n\t * to complain and force a full file system check.\n\t */\n\tif (!(sb->s_flags & MS_RDONLY))\n\t\tes->s_wtime = cpu_to_le32(get_seconds());\n\tif (sb->s_bdev->bd_part)\n\t\tes->s_kbytes_written =\n\t\t\tcpu_to_le64(EXT4_SB(sb)->s_kbytes_written +\n\t\t\t    ((part_stat_read(sb->s_bdev->bd_part, sectors[1]) -\n\t\t\t      EXT4_SB(sb)->s_sectors_written_start) >> 1));\n\telse\n\t\tes->s_kbytes_written =\n\t\t\tcpu_to_le64(EXT4_SB(sb)->s_kbytes_written);\n\text4_free_blocks_count_set(es, percpu_counter_sum_positive(\n\t\t\t\t\t   &EXT4_SB(sb)->s_freeblocks_counter));\n\tes->s_free_inodes_count =\n\t\tcpu_to_le32(percpu_counter_sum_positive(\n\t\t\t\t&EXT4_SB(sb)->s_freeinodes_counter));\n\tsb->s_dirt = 0;\n\tBUFFER_TRACE(sbh, \"marking dirty\");\n\tmark_buffer_dirty(sbh);\n\tif (sync) {\n\t\terror = sync_dirty_buffer(sbh);\n\t\tif (error)\n\t\t\treturn error;\n\n\t\terror = buffer_write_io_error(sbh);\n\t\tif (error) {\n\t\t\text4_msg(sb, KERN_ERR, \"I/O error while writing \"\n\t\t\t       \"superblock\");\n\t\t\tclear_buffer_write_io_error(sbh);\n\t\t\tset_buffer_uptodate(sbh);\n\t\t}\n\t}\n\treturn error;\n}\n\n/*\n * Have we just finished recovery?  If so, and if we are mounting (or\n * remounting) the filesystem readonly, then we will end up with a\n * consistent fs on disk.  Record that fact.\n */\nstatic void ext4_mark_recovery_complete(struct super_block *sb,\n\t\t\t\t\tstruct ext4_super_block *es)\n{\n\tjournal_t *journal = EXT4_SB(sb)->s_journal;\n\n\tif (!EXT4_HAS_COMPAT_FEATURE(sb, EXT4_FEATURE_COMPAT_HAS_JOURNAL)) {\n\t\tBUG_ON(journal != NULL);\n\t\treturn;\n\t}\n\tjbd2_journal_lock_updates(journal);\n\tif (jbd2_journal_flush(journal) < 0)\n\t\tgoto out;\n\n\tif (EXT4_HAS_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_RECOVER) &&\n\t    sb->s_flags & MS_RDONLY) {\n\t\tEXT4_CLEAR_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_RECOVER);\n\t\text4_commit_super(sb, 1);\n\t}\n\nout:\n\tjbd2_journal_unlock_updates(journal);\n}\n\n/*\n * If we are mounting (or read-write remounting) a filesystem whose journal\n * has recorded an error from a previous lifetime, move that error to the\n * main filesystem now.\n */\nstatic void ext4_clear_journal_err(struct super_block *sb,\n\t\t\t\t   struct ext4_super_block *es)\n{\n\tjournal_t *journal;\n\tint j_errno;\n\tconst char *errstr;\n\n\tBUG_ON(!EXT4_HAS_COMPAT_FEATURE(sb, EXT4_FEATURE_COMPAT_HAS_JOURNAL));\n\n\tjournal = EXT4_SB(sb)->s_journal;\n\n\t/*\n\t * Now check for any error status which may have been recorded in the\n\t * journal by a prior ext4_error() or ext4_abort()\n\t */\n\n\tj_errno = jbd2_journal_errno(journal);\n\tif (j_errno) {\n\t\tchar nbuf[16];\n\n\t\terrstr = ext4_decode_error(sb, j_errno, nbuf);\n\t\text4_warning(sb, \"Filesystem error recorded \"\n\t\t\t     \"from previous mount: %s\", errstr);\n\t\text4_warning(sb, \"Marking fs in need of filesystem check.\");\n\n\t\tEXT4_SB(sb)->s_mount_state |= EXT4_ERROR_FS;\n\t\tes->s_state |= cpu_to_le16(EXT4_ERROR_FS);\n\t\text4_commit_super(sb, 1);\n\n\t\tjbd2_journal_clear_err(journal);\n\t}\n}\n\n/*\n * Force the running and committing transactions to commit,\n * and wait on the commit.\n */\nint ext4_force_commit(struct super_block *sb)\n{\n\tjournal_t *journal;\n\tint ret = 0;\n\n\tif (sb->s_flags & MS_RDONLY)\n\t\treturn 0;\n\n\tjournal = EXT4_SB(sb)->s_journal;\n\tif (journal) {\n\t\tvfs_check_frozen(sb, SB_FREEZE_TRANS);\n\t\tret = ext4_journal_force_commit(journal);\n\t}\n\n\treturn ret;\n}\n\nstatic void ext4_write_super(struct super_block *sb)\n{\n\tlock_super(sb);\n\text4_commit_super(sb, 1);\n\tunlock_super(sb);\n}\n\nstatic int ext4_sync_fs(struct super_block *sb, int wait)\n{\n\tint ret = 0;\n\ttid_t target;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\ttrace_ext4_sync_fs(sb, wait);\n\tflush_workqueue(sbi->dio_unwritten_wq);\n\tif (jbd2_journal_start_commit(sbi->s_journal, &target)) {\n\t\tif (wait)\n\t\t\tjbd2_log_wait_commit(sbi->s_journal, target);\n\t}\n\treturn ret;\n}\n\n/*\n * LVM calls this function before a (read-only) snapshot is created.  This\n * gives us a chance to flush the journal completely and mark the fs clean.\n */\nstatic int ext4_freeze(struct super_block *sb)\n{\n\tint error = 0;\n\tjournal_t *journal;\n\n\tif (sb->s_flags & MS_RDONLY)\n\t\treturn 0;\n\n\tjournal = EXT4_SB(sb)->s_journal;\n\n\t/* Now we set up the journal barrier. */\n\tjbd2_journal_lock_updates(journal);\n\n\t/*\n\t * Don't clear the needs_recovery flag if we failed to flush\n\t * the journal.\n\t */\n\terror = jbd2_journal_flush(journal);\n\tif (error < 0)\n\t\tgoto out;\n\n\t/* Journal blocked and flushed, clear needs_recovery flag. */\n\tEXT4_CLEAR_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_RECOVER);\n\terror = ext4_commit_super(sb, 1);\nout:\n\t/* we rely on s_frozen to stop further updates */\n\tjbd2_journal_unlock_updates(EXT4_SB(sb)->s_journal);\n\treturn error;\n}\n\n/*\n * Called by LVM after the snapshot is done.  We need to reset the RECOVER\n * flag here, even though the filesystem is not technically dirty yet.\n */\nstatic int ext4_unfreeze(struct super_block *sb)\n{\n\tif (sb->s_flags & MS_RDONLY)\n\t\treturn 0;\n\n\tlock_super(sb);\n\t/* Reset the needs_recovery flag before the fs is unlocked. */\n\tEXT4_SET_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_RECOVER);\n\text4_commit_super(sb, 1);\n\tunlock_super(sb);\n\treturn 0;\n}\n\n/*\n * Structure to save mount options for ext4_remount's benefit\n */\nstruct ext4_mount_options {\n\tunsigned long s_mount_opt;\n\tunsigned long s_mount_opt2;\n\tuid_t s_resuid;\n\tgid_t s_resgid;\n\tunsigned long s_commit_interval;\n\tu32 s_min_batch_time, s_max_batch_time;\n#ifdef CONFIG_QUOTA\n\tint s_jquota_fmt;\n\tchar *s_qf_names[MAXQUOTAS];\n#endif\n};\n\nstatic int ext4_remount(struct super_block *sb, int *flags, char *data)\n{\n\tstruct ext4_super_block *es;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\text4_fsblk_t n_blocks_count = 0;\n\tunsigned long old_sb_flags;\n\tstruct ext4_mount_options old_opts;\n\tint enable_quota = 0;\n\text4_group_t g;\n\tunsigned int journal_ioprio = DEFAULT_JOURNAL_IOPRIO;\n\tint err;\n#ifdef CONFIG_QUOTA\n\tint i;\n#endif\n\tchar *orig_data = kstrdup(data, GFP_KERNEL);\n\n\t/* Store the original options */\n\tlock_super(sb);\n\told_sb_flags = sb->s_flags;\n\told_opts.s_mount_opt = sbi->s_mount_opt;\n\told_opts.s_mount_opt2 = sbi->s_mount_opt2;\n\told_opts.s_resuid = sbi->s_resuid;\n\told_opts.s_resgid = sbi->s_resgid;\n\told_opts.s_commit_interval = sbi->s_commit_interval;\n\told_opts.s_min_batch_time = sbi->s_min_batch_time;\n\told_opts.s_max_batch_time = sbi->s_max_batch_time;\n#ifdef CONFIG_QUOTA\n\told_opts.s_jquota_fmt = sbi->s_jquota_fmt;\n\tfor (i = 0; i < MAXQUOTAS; i++)\n\t\told_opts.s_qf_names[i] = sbi->s_qf_names[i];\n#endif\n\tif (sbi->s_journal && sbi->s_journal->j_task->io_context)\n\t\tjournal_ioprio = sbi->s_journal->j_task->io_context->ioprio;\n\n\t/*\n\t * Allow the \"check\" option to be passed as a remount option.\n\t */\n\tif (!parse_options(data, sb, NULL, &journal_ioprio,\n\t\t\t   &n_blocks_count, 1)) {\n\t\terr = -EINVAL;\n\t\tgoto restore_opts;\n\t}\n\n\tif (sbi->s_mount_flags & EXT4_MF_FS_ABORTED)\n\t\text4_abort(sb, \"Abort forced by user\");\n\n\tsb->s_flags = (sb->s_flags & ~MS_POSIXACL) |\n\t\t(test_opt(sb, POSIX_ACL) ? MS_POSIXACL : 0);\n\n\tes = sbi->s_es;\n\n\tif (sbi->s_journal) {\n\t\text4_init_journal_params(sb, sbi->s_journal);\n\t\tset_task_ioprio(sbi->s_journal->j_task, journal_ioprio);\n\t}\n\n\tif ((*flags & MS_RDONLY) != (sb->s_flags & MS_RDONLY) ||\n\t\tn_blocks_count > ext4_blocks_count(es)) {\n\t\tif (sbi->s_mount_flags & EXT4_MF_FS_ABORTED) {\n\t\t\terr = -EROFS;\n\t\t\tgoto restore_opts;\n\t\t}\n\n\t\tif (*flags & MS_RDONLY) {\n\t\t\terr = dquot_suspend(sb, -1);\n\t\t\tif (err < 0)\n\t\t\t\tgoto restore_opts;\n\n\t\t\t/*\n\t\t\t * First of all, the unconditional stuff we have to do\n\t\t\t * to disable replay of the journal when we next remount\n\t\t\t */\n\t\t\tsb->s_flags |= MS_RDONLY;\n\n\t\t\t/*\n\t\t\t * OK, test if we are remounting a valid rw partition\n\t\t\t * readonly, and if so set the rdonly flag and then\n\t\t\t * mark the partition as valid again.\n\t\t\t */\n\t\t\tif (!(es->s_state & cpu_to_le16(EXT4_VALID_FS)) &&\n\t\t\t    (sbi->s_mount_state & EXT4_VALID_FS))\n\t\t\t\tes->s_state = cpu_to_le16(sbi->s_mount_state);\n\n\t\t\tif (sbi->s_journal)\n\t\t\t\text4_mark_recovery_complete(sb, es);\n\t\t} else {\n\t\t\t/* Make sure we can mount this feature set readwrite */\n\t\t\tif (!ext4_feature_set_ok(sb, 0)) {\n\t\t\t\terr = -EROFS;\n\t\t\t\tgoto restore_opts;\n\t\t\t}\n\t\t\t/*\n\t\t\t * Make sure the group descriptor checksums\n\t\t\t * are sane.  If they aren't, refuse to remount r/w.\n\t\t\t */\n\t\t\tfor (g = 0; g < sbi->s_groups_count; g++) {\n\t\t\t\tstruct ext4_group_desc *gdp =\n\t\t\t\t\text4_get_group_desc(sb, g, NULL);\n\n\t\t\t\tif (!ext4_group_desc_csum_verify(sbi, g, gdp)) {\n\t\t\t\t\text4_msg(sb, KERN_ERR,\n\t       \"ext4_remount: Checksum for group %u failed (%u!=%u)\",\n\t\tg, le16_to_cpu(ext4_group_desc_csum(sbi, g, gdp)),\n\t\t\t\t\t       le16_to_cpu(gdp->bg_checksum));\n\t\t\t\t\terr = -EINVAL;\n\t\t\t\t\tgoto restore_opts;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * If we have an unprocessed orphan list hanging\n\t\t\t * around from a previously readonly bdev mount,\n\t\t\t * require a full umount/remount for now.\n\t\t\t */\n\t\t\tif (es->s_last_orphan) {\n\t\t\t\text4_msg(sb, KERN_WARNING, \"Couldn't \"\n\t\t\t\t       \"remount RDWR because of unprocessed \"\n\t\t\t\t       \"orphan inode list.  Please \"\n\t\t\t\t       \"umount/remount instead\");\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto restore_opts;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * Mounting a RDONLY partition read-write, so reread\n\t\t\t * and store the current valid flag.  (It may have\n\t\t\t * been changed by e2fsck since we originally mounted\n\t\t\t * the partition.)\n\t\t\t */\n\t\t\tif (sbi->s_journal)\n\t\t\t\text4_clear_journal_err(sb, es);\n\t\t\tsbi->s_mount_state = le16_to_cpu(es->s_state);\n\t\t\tif ((err = ext4_group_extend(sb, es, n_blocks_count)))\n\t\t\t\tgoto restore_opts;\n\t\t\tif (!ext4_setup_super(sb, es, 0))\n\t\t\t\tsb->s_flags &= ~MS_RDONLY;\n\t\t\tenable_quota = 1;\n\t\t}\n\t}\n\n\t/*\n\t * Reinitialize lazy itable initialization thread based on\n\t * current settings\n\t */\n\tif ((sb->s_flags & MS_RDONLY) || !test_opt(sb, INIT_INODE_TABLE))\n\t\text4_unregister_li_request(sb);\n\telse {\n\t\text4_group_t first_not_zeroed;\n\t\tfirst_not_zeroed = ext4_has_uninit_itable(sb);\n\t\text4_register_li_request(sb, first_not_zeroed);\n\t}\n\n\text4_setup_system_zone(sb);\n\tif (sbi->s_journal == NULL)\n\t\text4_commit_super(sb, 1);\n\n#ifdef CONFIG_QUOTA\n\t/* Release old quota file names */\n\tfor (i = 0; i < MAXQUOTAS; i++)\n\t\tif (old_opts.s_qf_names[i] &&\n\t\t    old_opts.s_qf_names[i] != sbi->s_qf_names[i])\n\t\t\tkfree(old_opts.s_qf_names[i]);\n#endif\n\tunlock_super(sb);\n\tif (enable_quota)\n\t\tdquot_resume(sb, -1);\n\n\text4_msg(sb, KERN_INFO, \"re-mounted. Opts: %s\", orig_data);\n\tkfree(orig_data);\n\treturn 0;\n\nrestore_opts:\n\tsb->s_flags = old_sb_flags;\n\tsbi->s_mount_opt = old_opts.s_mount_opt;\n\tsbi->s_mount_opt2 = old_opts.s_mount_opt2;\n\tsbi->s_resuid = old_opts.s_resuid;\n\tsbi->s_resgid = old_opts.s_resgid;\n\tsbi->s_commit_interval = old_opts.s_commit_interval;\n\tsbi->s_min_batch_time = old_opts.s_min_batch_time;\n\tsbi->s_max_batch_time = old_opts.s_max_batch_time;\n#ifdef CONFIG_QUOTA\n\tsbi->s_jquota_fmt = old_opts.s_jquota_fmt;\n\tfor (i = 0; i < MAXQUOTAS; i++) {\n\t\tif (sbi->s_qf_names[i] &&\n\t\t    old_opts.s_qf_names[i] != sbi->s_qf_names[i])\n\t\t\tkfree(sbi->s_qf_names[i]);\n\t\tsbi->s_qf_names[i] = old_opts.s_qf_names[i];\n\t}\n#endif\n\tunlock_super(sb);\n\tkfree(orig_data);\n\treturn err;\n}\n\nstatic int ext4_statfs(struct dentry *dentry, struct kstatfs *buf)\n{\n\tstruct super_block *sb = dentry->d_sb;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_super_block *es = sbi->s_es;\n\tu64 fsid;\n\n\tif (test_opt(sb, MINIX_DF)) {\n\t\tsbi->s_overhead_last = 0;\n\t} else if (sbi->s_blocks_last != ext4_blocks_count(es)) {\n\t\text4_group_t i, ngroups = ext4_get_groups_count(sb);\n\t\text4_fsblk_t overhead = 0;\n\n\t\t/*\n\t\t * Compute the overhead (FS structures).  This is constant\n\t\t * for a given filesystem unless the number of block groups\n\t\t * changes so we cache the previous value until it does.\n\t\t */\n\n\t\t/*\n\t\t * All of the blocks before first_data_block are\n\t\t * overhead\n\t\t */\n\t\toverhead = le32_to_cpu(es->s_first_data_block);\n\n\t\t/*\n\t\t * Add the overhead attributed to the superblock and\n\t\t * block group descriptors.  If the sparse superblocks\n\t\t * feature is turned on, then not all groups have this.\n\t\t */\n\t\tfor (i = 0; i < ngroups; i++) {\n\t\t\toverhead += ext4_bg_has_super(sb, i) +\n\t\t\t\text4_bg_num_gdb(sb, i);\n\t\t\tcond_resched();\n\t\t}\n\n\t\t/*\n\t\t * Every block group has an inode bitmap, a block\n\t\t * bitmap, and an inode table.\n\t\t */\n\t\toverhead += ngroups * (2 + sbi->s_itb_per_group);\n\t\tsbi->s_overhead_last = overhead;\n\t\tsmp_wmb();\n\t\tsbi->s_blocks_last = ext4_blocks_count(es);\n\t}\n\n\tbuf->f_type = EXT4_SUPER_MAGIC;\n\tbuf->f_bsize = sb->s_blocksize;\n\tbuf->f_blocks = ext4_blocks_count(es) - sbi->s_overhead_last;\n\tbuf->f_bfree = percpu_counter_sum_positive(&sbi->s_freeblocks_counter) -\n\t\t       percpu_counter_sum_positive(&sbi->s_dirtyblocks_counter);\n\tbuf->f_bavail = buf->f_bfree - ext4_r_blocks_count(es);\n\tif (buf->f_bfree < ext4_r_blocks_count(es))\n\t\tbuf->f_bavail = 0;\n\tbuf->f_files = le32_to_cpu(es->s_inodes_count);\n\tbuf->f_ffree = percpu_counter_sum_positive(&sbi->s_freeinodes_counter);\n\tbuf->f_namelen = EXT4_NAME_LEN;\n\tfsid = le64_to_cpup((void *)es->s_uuid) ^\n\t       le64_to_cpup((void *)es->s_uuid + sizeof(u64));\n\tbuf->f_fsid.val[0] = fsid & 0xFFFFFFFFUL;\n\tbuf->f_fsid.val[1] = (fsid >> 32) & 0xFFFFFFFFUL;\n\n\treturn 0;\n}\n\n/* Helper function for writing quotas on sync - we need to start transaction\n * before quota file is locked for write. Otherwise the are possible deadlocks:\n * Process 1                         Process 2\n * ext4_create()                     quota_sync()\n *   jbd2_journal_start()                  write_dquot()\n *   dquot_initialize()                         down(dqio_mutex)\n *     down(dqio_mutex)                    jbd2_journal_start()\n *\n */\n\n#ifdef CONFIG_QUOTA\n\nstatic inline struct inode *dquot_to_inode(struct dquot *dquot)\n{\n\treturn sb_dqopt(dquot->dq_sb)->files[dquot->dq_type];\n}\n\nstatic int ext4_write_dquot(struct dquot *dquot)\n{\n\tint ret, err;\n\thandle_t *handle;\n\tstruct inode *inode;\n\n\tinode = dquot_to_inode(dquot);\n\thandle = ext4_journal_start(inode,\n\t\t\t\t    EXT4_QUOTA_TRANS_BLOCKS(dquot->dq_sb));\n\tif (IS_ERR(handle))\n\t\treturn PTR_ERR(handle);\n\tret = dquot_commit(dquot);\n\terr = ext4_journal_stop(handle);\n\tif (!ret)\n\t\tret = err;\n\treturn ret;\n}\n\nstatic int ext4_acquire_dquot(struct dquot *dquot)\n{\n\tint ret, err;\n\thandle_t *handle;\n\n\thandle = ext4_journal_start(dquot_to_inode(dquot),\n\t\t\t\t    EXT4_QUOTA_INIT_BLOCKS(dquot->dq_sb));\n\tif (IS_ERR(handle))\n\t\treturn PTR_ERR(handle);\n\tret = dquot_acquire(dquot);\n\terr = ext4_journal_stop(handle);\n\tif (!ret)\n\t\tret = err;\n\treturn ret;\n}\n\nstatic int ext4_release_dquot(struct dquot *dquot)\n{\n\tint ret, err;\n\thandle_t *handle;\n\n\thandle = ext4_journal_start(dquot_to_inode(dquot),\n\t\t\t\t    EXT4_QUOTA_DEL_BLOCKS(dquot->dq_sb));\n\tif (IS_ERR(handle)) {\n\t\t/* Release dquot anyway to avoid endless cycle in dqput() */\n\t\tdquot_release(dquot);\n\t\treturn PTR_ERR(handle);\n\t}\n\tret = dquot_release(dquot);\n\terr = ext4_journal_stop(handle);\n\tif (!ret)\n\t\tret = err;\n\treturn ret;\n}\n\nstatic int ext4_mark_dquot_dirty(struct dquot *dquot)\n{\n\t/* Are we journaling quotas? */\n\tif (EXT4_SB(dquot->dq_sb)->s_qf_names[USRQUOTA] ||\n\t    EXT4_SB(dquot->dq_sb)->s_qf_names[GRPQUOTA]) {\n\t\tdquot_mark_dquot_dirty(dquot);\n\t\treturn ext4_write_dquot(dquot);\n\t} else {\n\t\treturn dquot_mark_dquot_dirty(dquot);\n\t}\n}\n\nstatic int ext4_write_info(struct super_block *sb, int type)\n{\n\tint ret, err;\n\thandle_t *handle;\n\n\t/* Data block + inode block */\n\thandle = ext4_journal_start(sb->s_root->d_inode, 2);\n\tif (IS_ERR(handle))\n\t\treturn PTR_ERR(handle);\n\tret = dquot_commit_info(sb, type);\n\terr = ext4_journal_stop(handle);\n\tif (!ret)\n\t\tret = err;\n\treturn ret;\n}\n\n/*\n * Turn on quotas during mount time - we need to find\n * the quota file and such...\n */\nstatic int ext4_quota_on_mount(struct super_block *sb, int type)\n{\n\treturn dquot_quota_on_mount(sb, EXT4_SB(sb)->s_qf_names[type],\n\t\t\t\t\tEXT4_SB(sb)->s_jquota_fmt, type);\n}\n\n/*\n * Standard function to be called on quota_on\n */\nstatic int ext4_quota_on(struct super_block *sb, int type, int format_id,\n\t\t\t struct path *path)\n{\n\tint err;\n\n\tif (!test_opt(sb, QUOTA))\n\t\treturn -EINVAL;\n\n\t/* Quotafile not on the same filesystem? */\n\tif (path->mnt->mnt_sb != sb)\n\t\treturn -EXDEV;\n\t/* Journaling quota? */\n\tif (EXT4_SB(sb)->s_qf_names[type]) {\n\t\t/* Quotafile not in fs root? */\n\t\tif (path->dentry->d_parent != sb->s_root)\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t\"Quota file not on filesystem root. \"\n\t\t\t\t\"Journaled quota will not work\");\n\t}\n\n\t/*\n\t * When we journal data on quota file, we have to flush journal to see\n\t * all updates to the file when we bypass pagecache...\n\t */\n\tif (EXT4_SB(sb)->s_journal &&\n\t    ext4_should_journal_data(path->dentry->d_inode)) {\n\t\t/*\n\t\t * We don't need to lock updates but journal_flush() could\n\t\t * otherwise be livelocked...\n\t\t */\n\t\tjbd2_journal_lock_updates(EXT4_SB(sb)->s_journal);\n\t\terr = jbd2_journal_flush(EXT4_SB(sb)->s_journal);\n\t\tjbd2_journal_unlock_updates(EXT4_SB(sb)->s_journal);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn dquot_quota_on(sb, type, format_id, path);\n}\n\nstatic int ext4_quota_off(struct super_block *sb, int type)\n{\n\tstruct inode *inode = sb_dqopt(sb)->files[type];\n\thandle_t *handle;\n\n\t/* Force all delayed allocation blocks to be allocated.\n\t * Caller already holds s_umount sem */\n\tif (test_opt(sb, DELALLOC))\n\t\tsync_filesystem(sb);\n\n\t/* Update modification times of quota files when userspace can\n\t * start looking at them */\n\thandle = ext4_journal_start(inode, 1);\n\tif (IS_ERR(handle))\n\t\tgoto out;\n\tinode->i_mtime = inode->i_ctime = CURRENT_TIME;\n\text4_mark_inode_dirty(handle, inode);\n\text4_journal_stop(handle);\n\nout:\n\treturn dquot_quota_off(sb, type);\n}\n\n/* Read data from quotafile - avoid pagecache and such because we cannot afford\n * acquiring the locks... As quota files are never truncated and quota code\n * itself serializes the operations (and noone else should touch the files)\n * we don't have to be afraid of races */\nstatic ssize_t ext4_quota_read(struct super_block *sb, int type, char *data,\n\t\t\t       size_t len, loff_t off)\n{\n\tstruct inode *inode = sb_dqopt(sb)->files[type];\n\text4_lblk_t blk = off >> EXT4_BLOCK_SIZE_BITS(sb);\n\tint err = 0;\n\tint offset = off & (sb->s_blocksize - 1);\n\tint tocopy;\n\tsize_t toread;\n\tstruct buffer_head *bh;\n\tloff_t i_size = i_size_read(inode);\n\n\tif (off > i_size)\n\t\treturn 0;\n\tif (off+len > i_size)\n\t\tlen = i_size-off;\n\ttoread = len;\n\twhile (toread > 0) {\n\t\ttocopy = sb->s_blocksize - offset < toread ?\n\t\t\t\tsb->s_blocksize - offset : toread;\n\t\tbh = ext4_bread(NULL, inode, blk, 0, &err);\n\t\tif (err)\n\t\t\treturn err;\n\t\tif (!bh)\t/* A hole? */\n\t\t\tmemset(data, 0, tocopy);\n\t\telse\n\t\t\tmemcpy(data, bh->b_data+offset, tocopy);\n\t\tbrelse(bh);\n\t\toffset = 0;\n\t\ttoread -= tocopy;\n\t\tdata += tocopy;\n\t\tblk++;\n\t}\n\treturn len;\n}\n\n/* Write to quotafile (we know the transaction is already started and has\n * enough credits) */\nstatic ssize_t ext4_quota_write(struct super_block *sb, int type,\n\t\t\t\tconst char *data, size_t len, loff_t off)\n{\n\tstruct inode *inode = sb_dqopt(sb)->files[type];\n\text4_lblk_t blk = off >> EXT4_BLOCK_SIZE_BITS(sb);\n\tint err = 0;\n\tint offset = off & (sb->s_blocksize - 1);\n\tstruct buffer_head *bh;\n\thandle_t *handle = journal_current_handle();\n\n\tif (EXT4_SB(sb)->s_journal && !handle) {\n\t\text4_msg(sb, KERN_WARNING, \"Quota write (off=%llu, len=%llu)\"\n\t\t\t\" cancelled because transaction is not started\",\n\t\t\t(unsigned long long)off, (unsigned long long)len);\n\t\treturn -EIO;\n\t}\n\t/*\n\t * Since we account only one data block in transaction credits,\n\t * then it is impossible to cross a block boundary.\n\t */\n\tif (sb->s_blocksize - offset < len) {\n\t\text4_msg(sb, KERN_WARNING, \"Quota write (off=%llu, len=%llu)\"\n\t\t\t\" cancelled because not block aligned\",\n\t\t\t(unsigned long long)off, (unsigned long long)len);\n\t\treturn -EIO;\n\t}\n\n\tmutex_lock_nested(&inode->i_mutex, I_MUTEX_QUOTA);\n\tbh = ext4_bread(handle, inode, blk, 1, &err);\n\tif (!bh)\n\t\tgoto out;\n\terr = ext4_journal_get_write_access(handle, bh);\n\tif (err) {\n\t\tbrelse(bh);\n\t\tgoto out;\n\t}\n\tlock_buffer(bh);\n\tmemcpy(bh->b_data+offset, data, len);\n\tflush_dcache_page(bh->b_page);\n\tunlock_buffer(bh);\n\terr = ext4_handle_dirty_metadata(handle, NULL, bh);\n\tbrelse(bh);\nout:\n\tif (err) {\n\t\tmutex_unlock(&inode->i_mutex);\n\t\treturn err;\n\t}\n\tif (inode->i_size < off + len) {\n\t\ti_size_write(inode, off + len);\n\t\tEXT4_I(inode)->i_disksize = inode->i_size;\n\t\text4_mark_inode_dirty(handle, inode);\n\t}\n\tmutex_unlock(&inode->i_mutex);\n\treturn len;\n}\n\n#endif\n\nstatic struct dentry *ext4_mount(struct file_system_type *fs_type, int flags,\n\t\t       const char *dev_name, void *data)\n{\n\treturn mount_bdev(fs_type, flags, dev_name, data, ext4_fill_super);\n}\n\n#if !defined(CONFIG_EXT2_FS) && !defined(CONFIG_EXT2_FS_MODULE) && defined(CONFIG_EXT4_USE_FOR_EXT23)\nstatic struct file_system_type ext2_fs_type = {\n\t.owner\t\t= THIS_MODULE,\n\t.name\t\t= \"ext2\",\n\t.mount\t\t= ext4_mount,\n\t.kill_sb\t= kill_block_super,\n\t.fs_flags\t= FS_REQUIRES_DEV,\n};\n\nstatic inline void register_as_ext2(void)\n{\n\tint err = register_filesystem(&ext2_fs_type);\n\tif (err)\n\t\tprintk(KERN_WARNING\n\t\t       \"EXT4-fs: Unable to register as ext2 (%d)\\n\", err);\n}\n\nstatic inline void unregister_as_ext2(void)\n{\n\tunregister_filesystem(&ext2_fs_type);\n}\nMODULE_ALIAS(\"ext2\");\n#else\nstatic inline void register_as_ext2(void) { }\nstatic inline void unregister_as_ext2(void) { }\n#endif\n\n#if !defined(CONFIG_EXT3_FS) && !defined(CONFIG_EXT3_FS_MODULE) && defined(CONFIG_EXT4_USE_FOR_EXT23)\nstatic inline void register_as_ext3(void)\n{\n\tint err = register_filesystem(&ext3_fs_type);\n\tif (err)\n\t\tprintk(KERN_WARNING\n\t\t       \"EXT4-fs: Unable to register as ext3 (%d)\\n\", err);\n}\n\nstatic inline void unregister_as_ext3(void)\n{\n\tunregister_filesystem(&ext3_fs_type);\n}\nMODULE_ALIAS(\"ext3\");\n#else\nstatic inline void register_as_ext3(void) { }\nstatic inline void unregister_as_ext3(void) { }\n#endif\n\nstatic struct file_system_type ext4_fs_type = {\n\t.owner\t\t= THIS_MODULE,\n\t.name\t\t= \"ext4\",\n\t.mount\t\t= ext4_mount,\n\t.kill_sb\t= kill_block_super,\n\t.fs_flags\t= FS_REQUIRES_DEV,\n};\n\nstatic int __init ext4_init_feat_adverts(void)\n{\n\tstruct ext4_features *ef;\n\tint ret = -ENOMEM;\n\n\tef = kzalloc(sizeof(struct ext4_features), GFP_KERNEL);\n\tif (!ef)\n\t\tgoto out;\n\n\tef->f_kobj.kset = ext4_kset;\n\tinit_completion(&ef->f_kobj_unregister);\n\tret = kobject_init_and_add(&ef->f_kobj, &ext4_feat_ktype, NULL,\n\t\t\t\t   \"features\");\n\tif (ret) {\n\t\tkfree(ef);\n\t\tgoto out;\n\t}\n\n\text4_feat = ef;\n\tret = 0;\nout:\n\treturn ret;\n}\n\nstatic void ext4_exit_feat_adverts(void)\n{\n\tkobject_put(&ext4_feat->f_kobj);\n\twait_for_completion(&ext4_feat->f_kobj_unregister);\n\tkfree(ext4_feat);\n}\n\n/* Shared across all ext4 file systems */\nwait_queue_head_t ext4__ioend_wq[EXT4_WQ_HASH_SZ];\nstruct mutex ext4__aio_mutex[EXT4_WQ_HASH_SZ];\n\nstatic int __init ext4_init_fs(void)\n{\n\tint i, err;\n\n\text4_check_flag_values();\n\n\tfor (i = 0; i < EXT4_WQ_HASH_SZ; i++) {\n\t\tmutex_init(&ext4__aio_mutex[i]);\n\t\tinit_waitqueue_head(&ext4__ioend_wq[i]);\n\t}\n\n\terr = ext4_init_pageio();\n\tif (err)\n\t\treturn err;\n\terr = ext4_init_system_zone();\n\tif (err)\n\t\tgoto out7;\n\text4_kset = kset_create_and_add(\"ext4\", NULL, fs_kobj);\n\tif (!ext4_kset)\n\t\tgoto out6;\n\text4_proc_root = proc_mkdir(\"fs/ext4\", NULL);\n\tif (!ext4_proc_root)\n\t\tgoto out5;\n\n\terr = ext4_init_feat_adverts();\n\tif (err)\n\t\tgoto out4;\n\n\terr = ext4_init_mballoc();\n\tif (err)\n\t\tgoto out3;\n\n\terr = ext4_init_xattr();\n\tif (err)\n\t\tgoto out2;\n\terr = init_inodecache();\n\tif (err)\n\t\tgoto out1;\n\tregister_as_ext2();\n\tregister_as_ext3();\n\terr = register_filesystem(&ext4_fs_type);\n\tif (err)\n\t\tgoto out;\n\n\text4_li_info = NULL;\n\tmutex_init(&ext4_li_mtx);\n\treturn 0;\nout:\n\tunregister_as_ext2();\n\tunregister_as_ext3();\n\tdestroy_inodecache();\nout1:\n\text4_exit_xattr();\nout2:\n\text4_exit_mballoc();\nout3:\n\text4_exit_feat_adverts();\nout4:\n\tremove_proc_entry(\"fs/ext4\", NULL);\nout5:\n\tkset_unregister(ext4_kset);\nout6:\n\text4_exit_system_zone();\nout7:\n\text4_exit_pageio();\n\treturn err;\n}\n\nstatic void __exit ext4_exit_fs(void)\n{\n\text4_destroy_lazyinit_thread();\n\tunregister_as_ext2();\n\tunregister_as_ext3();\n\tunregister_filesystem(&ext4_fs_type);\n\tdestroy_inodecache();\n\text4_exit_xattr();\n\text4_exit_mballoc();\n\text4_exit_feat_adverts();\n\tremove_proc_entry(\"fs/ext4\", NULL);\n\tkset_unregister(ext4_kset);\n\text4_exit_system_zone();\n\text4_exit_pageio();\n}\n\nMODULE_AUTHOR(\"Remy Card, Stephen Tweedie, Andrew Morton, Andreas Dilger, Theodore Ts'o and others\");\nMODULE_DESCRIPTION(\"Fourth Extended Filesystem\");\nMODULE_LICENSE(\"GPL\");\nmodule_init(ext4_init_fs)\nmodule_exit(ext4_exit_fs)\n"], "fixing_code": ["/*\n *  linux/fs/ext4/super.c\n *\n * Copyright (C) 1992, 1993, 1994, 1995\n * Remy Card (card@masi.ibp.fr)\n * Laboratoire MASI - Institut Blaise Pascal\n * Universite Pierre et Marie Curie (Paris VI)\n *\n *  from\n *\n *  linux/fs/minix/inode.c\n *\n *  Copyright (C) 1991, 1992  Linus Torvalds\n *\n *  Big-endian to little-endian byte-swapping/bitmaps by\n *        David S. Miller (davem@caip.rutgers.edu), 1995\n */\n\n#include <linux/module.h>\n#include <linux/string.h>\n#include <linux/fs.h>\n#include <linux/time.h>\n#include <linux/vmalloc.h>\n#include <linux/jbd2.h>\n#include <linux/slab.h>\n#include <linux/init.h>\n#include <linux/blkdev.h>\n#include <linux/parser.h>\n#include <linux/buffer_head.h>\n#include <linux/exportfs.h>\n#include <linux/vfs.h>\n#include <linux/random.h>\n#include <linux/mount.h>\n#include <linux/namei.h>\n#include <linux/quotaops.h>\n#include <linux/seq_file.h>\n#include <linux/proc_fs.h>\n#include <linux/ctype.h>\n#include <linux/log2.h>\n#include <linux/crc16.h>\n#include <asm/uaccess.h>\n\n#include <linux/kthread.h>\n#include <linux/freezer.h>\n\n#include \"ext4.h\"\n#include \"ext4_jbd2.h\"\n#include \"xattr.h\"\n#include \"acl.h\"\n#include \"mballoc.h\"\n\n#define CREATE_TRACE_POINTS\n#include <trace/events/ext4.h>\n\nstatic struct proc_dir_entry *ext4_proc_root;\nstatic struct kset *ext4_kset;\nstatic struct ext4_lazy_init *ext4_li_info;\nstatic struct mutex ext4_li_mtx;\nstatic struct ext4_features *ext4_feat;\n\nstatic int ext4_load_journal(struct super_block *, struct ext4_super_block *,\n\t\t\t     unsigned long journal_devnum);\nstatic int ext4_commit_super(struct super_block *sb, int sync);\nstatic void ext4_mark_recovery_complete(struct super_block *sb,\n\t\t\t\t\tstruct ext4_super_block *es);\nstatic void ext4_clear_journal_err(struct super_block *sb,\n\t\t\t\t   struct ext4_super_block *es);\nstatic int ext4_sync_fs(struct super_block *sb, int wait);\nstatic const char *ext4_decode_error(struct super_block *sb, int errno,\n\t\t\t\t     char nbuf[16]);\nstatic int ext4_remount(struct super_block *sb, int *flags, char *data);\nstatic int ext4_statfs(struct dentry *dentry, struct kstatfs *buf);\nstatic int ext4_unfreeze(struct super_block *sb);\nstatic void ext4_write_super(struct super_block *sb);\nstatic int ext4_freeze(struct super_block *sb);\nstatic struct dentry *ext4_mount(struct file_system_type *fs_type, int flags,\n\t\t       const char *dev_name, void *data);\nstatic int ext4_feature_set_ok(struct super_block *sb, int readonly);\nstatic void ext4_destroy_lazyinit_thread(void);\nstatic void ext4_unregister_li_request(struct super_block *sb);\nstatic void ext4_clear_request_list(void);\n\n#if !defined(CONFIG_EXT3_FS) && !defined(CONFIG_EXT3_FS_MODULE) && defined(CONFIG_EXT4_USE_FOR_EXT23)\nstatic struct file_system_type ext3_fs_type = {\n\t.owner\t\t= THIS_MODULE,\n\t.name\t\t= \"ext3\",\n\t.mount\t\t= ext4_mount,\n\t.kill_sb\t= kill_block_super,\n\t.fs_flags\t= FS_REQUIRES_DEV,\n};\n#define IS_EXT3_SB(sb) ((sb)->s_bdev->bd_holder == &ext3_fs_type)\n#else\n#define IS_EXT3_SB(sb) (0)\n#endif\n\next4_fsblk_t ext4_block_bitmap(struct super_block *sb,\n\t\t\t       struct ext4_group_desc *bg)\n{\n\treturn le32_to_cpu(bg->bg_block_bitmap_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (ext4_fsblk_t)le32_to_cpu(bg->bg_block_bitmap_hi) << 32 : 0);\n}\n\next4_fsblk_t ext4_inode_bitmap(struct super_block *sb,\n\t\t\t       struct ext4_group_desc *bg)\n{\n\treturn le32_to_cpu(bg->bg_inode_bitmap_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (ext4_fsblk_t)le32_to_cpu(bg->bg_inode_bitmap_hi) << 32 : 0);\n}\n\next4_fsblk_t ext4_inode_table(struct super_block *sb,\n\t\t\t      struct ext4_group_desc *bg)\n{\n\treturn le32_to_cpu(bg->bg_inode_table_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (ext4_fsblk_t)le32_to_cpu(bg->bg_inode_table_hi) << 32 : 0);\n}\n\n__u32 ext4_free_blks_count(struct super_block *sb,\n\t\t\t      struct ext4_group_desc *bg)\n{\n\treturn le16_to_cpu(bg->bg_free_blocks_count_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (__u32)le16_to_cpu(bg->bg_free_blocks_count_hi) << 16 : 0);\n}\n\n__u32 ext4_free_inodes_count(struct super_block *sb,\n\t\t\t      struct ext4_group_desc *bg)\n{\n\treturn le16_to_cpu(bg->bg_free_inodes_count_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (__u32)le16_to_cpu(bg->bg_free_inodes_count_hi) << 16 : 0);\n}\n\n__u32 ext4_used_dirs_count(struct super_block *sb,\n\t\t\t      struct ext4_group_desc *bg)\n{\n\treturn le16_to_cpu(bg->bg_used_dirs_count_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (__u32)le16_to_cpu(bg->bg_used_dirs_count_hi) << 16 : 0);\n}\n\n__u32 ext4_itable_unused_count(struct super_block *sb,\n\t\t\t      struct ext4_group_desc *bg)\n{\n\treturn le16_to_cpu(bg->bg_itable_unused_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (__u32)le16_to_cpu(bg->bg_itable_unused_hi) << 16 : 0);\n}\n\nvoid ext4_block_bitmap_set(struct super_block *sb,\n\t\t\t   struct ext4_group_desc *bg, ext4_fsblk_t blk)\n{\n\tbg->bg_block_bitmap_lo = cpu_to_le32((u32)blk);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_block_bitmap_hi = cpu_to_le32(blk >> 32);\n}\n\nvoid ext4_inode_bitmap_set(struct super_block *sb,\n\t\t\t   struct ext4_group_desc *bg, ext4_fsblk_t blk)\n{\n\tbg->bg_inode_bitmap_lo  = cpu_to_le32((u32)blk);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_inode_bitmap_hi = cpu_to_le32(blk >> 32);\n}\n\nvoid ext4_inode_table_set(struct super_block *sb,\n\t\t\t  struct ext4_group_desc *bg, ext4_fsblk_t blk)\n{\n\tbg->bg_inode_table_lo = cpu_to_le32((u32)blk);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_inode_table_hi = cpu_to_le32(blk >> 32);\n}\n\nvoid ext4_free_blks_set(struct super_block *sb,\n\t\t\t  struct ext4_group_desc *bg, __u32 count)\n{\n\tbg->bg_free_blocks_count_lo = cpu_to_le16((__u16)count);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_free_blocks_count_hi = cpu_to_le16(count >> 16);\n}\n\nvoid ext4_free_inodes_set(struct super_block *sb,\n\t\t\t  struct ext4_group_desc *bg, __u32 count)\n{\n\tbg->bg_free_inodes_count_lo = cpu_to_le16((__u16)count);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_free_inodes_count_hi = cpu_to_le16(count >> 16);\n}\n\nvoid ext4_used_dirs_set(struct super_block *sb,\n\t\t\t  struct ext4_group_desc *bg, __u32 count)\n{\n\tbg->bg_used_dirs_count_lo = cpu_to_le16((__u16)count);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_used_dirs_count_hi = cpu_to_le16(count >> 16);\n}\n\nvoid ext4_itable_unused_set(struct super_block *sb,\n\t\t\t  struct ext4_group_desc *bg, __u32 count)\n{\n\tbg->bg_itable_unused_lo = cpu_to_le16((__u16)count);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_itable_unused_hi = cpu_to_le16(count >> 16);\n}\n\n\n/* Just increment the non-pointer handle value */\nstatic handle_t *ext4_get_nojournal(void)\n{\n\thandle_t *handle = current->journal_info;\n\tunsigned long ref_cnt = (unsigned long)handle;\n\n\tBUG_ON(ref_cnt >= EXT4_NOJOURNAL_MAX_REF_COUNT);\n\n\tref_cnt++;\n\thandle = (handle_t *)ref_cnt;\n\n\tcurrent->journal_info = handle;\n\treturn handle;\n}\n\n\n/* Decrement the non-pointer handle value */\nstatic void ext4_put_nojournal(handle_t *handle)\n{\n\tunsigned long ref_cnt = (unsigned long)handle;\n\n\tBUG_ON(ref_cnt == 0);\n\n\tref_cnt--;\n\thandle = (handle_t *)ref_cnt;\n\n\tcurrent->journal_info = handle;\n}\n\n/*\n * Wrappers for jbd2_journal_start/end.\n *\n * The only special thing we need to do here is to make sure that all\n * journal_end calls result in the superblock being marked dirty, so\n * that sync() will call the filesystem's write_super callback if\n * appropriate.\n */\nhandle_t *ext4_journal_start_sb(struct super_block *sb, int nblocks)\n{\n\tjournal_t *journal;\n\n\tif (sb->s_flags & MS_RDONLY)\n\t\treturn ERR_PTR(-EROFS);\n\n\tvfs_check_frozen(sb, SB_FREEZE_TRANS);\n\t/* Special case here: if the journal has aborted behind our\n\t * backs (eg. EIO in the commit thread), then we still need to\n\t * take the FS itself readonly cleanly. */\n\tjournal = EXT4_SB(sb)->s_journal;\n\tif (journal) {\n\t\tif (is_journal_aborted(journal)) {\n\t\t\text4_abort(sb, \"Detected aborted journal\");\n\t\t\treturn ERR_PTR(-EROFS);\n\t\t}\n\t\treturn jbd2_journal_start(journal, nblocks);\n\t}\n\treturn ext4_get_nojournal();\n}\n\n/*\n * The only special thing we need to do here is to make sure that all\n * jbd2_journal_stop calls result in the superblock being marked dirty, so\n * that sync() will call the filesystem's write_super callback if\n * appropriate.\n */\nint __ext4_journal_stop(const char *where, unsigned int line, handle_t *handle)\n{\n\tstruct super_block *sb;\n\tint err;\n\tint rc;\n\n\tif (!ext4_handle_valid(handle)) {\n\t\text4_put_nojournal(handle);\n\t\treturn 0;\n\t}\n\tsb = handle->h_transaction->t_journal->j_private;\n\terr = handle->h_err;\n\trc = jbd2_journal_stop(handle);\n\n\tif (!err)\n\t\terr = rc;\n\tif (err)\n\t\t__ext4_std_error(sb, where, line, err);\n\treturn err;\n}\n\nvoid ext4_journal_abort_handle(const char *caller, unsigned int line,\n\t\t\t       const char *err_fn, struct buffer_head *bh,\n\t\t\t       handle_t *handle, int err)\n{\n\tchar nbuf[16];\n\tconst char *errstr = ext4_decode_error(NULL, err, nbuf);\n\n\tBUG_ON(!ext4_handle_valid(handle));\n\n\tif (bh)\n\t\tBUFFER_TRACE(bh, \"abort\");\n\n\tif (!handle->h_err)\n\t\thandle->h_err = err;\n\n\tif (is_handle_aborted(handle))\n\t\treturn;\n\n\tprintk(KERN_ERR \"%s:%d: aborting transaction: %s in %s\\n\",\n\t       caller, line, errstr, err_fn);\n\n\tjbd2_journal_abort_handle(handle);\n}\n\nstatic void __save_error_info(struct super_block *sb, const char *func,\n\t\t\t    unsigned int line)\n{\n\tstruct ext4_super_block *es = EXT4_SB(sb)->s_es;\n\n\tEXT4_SB(sb)->s_mount_state |= EXT4_ERROR_FS;\n\tes->s_state |= cpu_to_le16(EXT4_ERROR_FS);\n\tes->s_last_error_time = cpu_to_le32(get_seconds());\n\tstrncpy(es->s_last_error_func, func, sizeof(es->s_last_error_func));\n\tes->s_last_error_line = cpu_to_le32(line);\n\tif (!es->s_first_error_time) {\n\t\tes->s_first_error_time = es->s_last_error_time;\n\t\tstrncpy(es->s_first_error_func, func,\n\t\t\tsizeof(es->s_first_error_func));\n\t\tes->s_first_error_line = cpu_to_le32(line);\n\t\tes->s_first_error_ino = es->s_last_error_ino;\n\t\tes->s_first_error_block = es->s_last_error_block;\n\t}\n\t/*\n\t * Start the daily error reporting function if it hasn't been\n\t * started already\n\t */\n\tif (!es->s_error_count)\n\t\tmod_timer(&EXT4_SB(sb)->s_err_report, jiffies + 24*60*60*HZ);\n\tes->s_error_count = cpu_to_le32(le32_to_cpu(es->s_error_count) + 1);\n}\n\nstatic void save_error_info(struct super_block *sb, const char *func,\n\t\t\t    unsigned int line)\n{\n\t__save_error_info(sb, func, line);\n\text4_commit_super(sb, 1);\n}\n\n\n/* Deal with the reporting of failure conditions on a filesystem such as\n * inconsistencies detected or read IO failures.\n *\n * On ext2, we can store the error state of the filesystem in the\n * superblock.  That is not possible on ext4, because we may have other\n * write ordering constraints on the superblock which prevent us from\n * writing it out straight away; and given that the journal is about to\n * be aborted, we can't rely on the current, or future, transactions to\n * write out the superblock safely.\n *\n * We'll just use the jbd2_journal_abort() error code to record an error in\n * the journal instead.  On recovery, the journal will complain about\n * that error until we've noted it down and cleared it.\n */\n\nstatic void ext4_handle_error(struct super_block *sb)\n{\n\tif (sb->s_flags & MS_RDONLY)\n\t\treturn;\n\n\tif (!test_opt(sb, ERRORS_CONT)) {\n\t\tjournal_t *journal = EXT4_SB(sb)->s_journal;\n\n\t\tEXT4_SB(sb)->s_mount_flags |= EXT4_MF_FS_ABORTED;\n\t\tif (journal)\n\t\t\tjbd2_journal_abort(journal, -EIO);\n\t}\n\tif (test_opt(sb, ERRORS_RO)) {\n\t\text4_msg(sb, KERN_CRIT, \"Remounting filesystem read-only\");\n\t\tsb->s_flags |= MS_RDONLY;\n\t}\n\tif (test_opt(sb, ERRORS_PANIC))\n\t\tpanic(\"EXT4-fs (device %s): panic forced after error\\n\",\n\t\t\tsb->s_id);\n}\n\nvoid __ext4_error(struct super_block *sb, const char *function,\n\t\t  unsigned int line, const char *fmt, ...)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\n\tva_start(args, fmt);\n\tvaf.fmt = fmt;\n\tvaf.va = &args;\n\tprintk(KERN_CRIT \"EXT4-fs error (device %s): %s:%d: comm %s: %pV\\n\",\n\t       sb->s_id, function, line, current->comm, &vaf);\n\tva_end(args);\n\n\text4_handle_error(sb);\n}\n\nvoid ext4_error_inode(struct inode *inode, const char *function,\n\t\t      unsigned int line, ext4_fsblk_t block,\n\t\t      const char *fmt, ...)\n{\n\tva_list args;\n\tstruct va_format vaf;\n\tstruct ext4_super_block *es = EXT4_SB(inode->i_sb)->s_es;\n\n\tes->s_last_error_ino = cpu_to_le32(inode->i_ino);\n\tes->s_last_error_block = cpu_to_le64(block);\n\tsave_error_info(inode->i_sb, function, line);\n\tva_start(args, fmt);\n\tvaf.fmt = fmt;\n\tvaf.va = &args;\n\tprintk(KERN_CRIT \"EXT4-fs error (device %s): %s:%d: inode #%lu: \",\n\t       inode->i_sb->s_id, function, line, inode->i_ino);\n\tif (block)\n\t\tprintk(KERN_CONT \"block %llu: \", block);\n\tprintk(KERN_CONT \"comm %s: %pV\\n\", current->comm, &vaf);\n\tva_end(args);\n\n\text4_handle_error(inode->i_sb);\n}\n\nvoid ext4_error_file(struct file *file, const char *function,\n\t\t     unsigned int line, ext4_fsblk_t block,\n\t\t     const char *fmt, ...)\n{\n\tva_list args;\n\tstruct va_format vaf;\n\tstruct ext4_super_block *es;\n\tstruct inode *inode = file->f_dentry->d_inode;\n\tchar pathname[80], *path;\n\n\tes = EXT4_SB(inode->i_sb)->s_es;\n\tes->s_last_error_ino = cpu_to_le32(inode->i_ino);\n\tsave_error_info(inode->i_sb, function, line);\n\tpath = d_path(&(file->f_path), pathname, sizeof(pathname));\n\tif (IS_ERR(path))\n\t\tpath = \"(unknown)\";\n\tprintk(KERN_CRIT\n\t       \"EXT4-fs error (device %s): %s:%d: inode #%lu: \",\n\t       inode->i_sb->s_id, function, line, inode->i_ino);\n\tif (block)\n\t\tprintk(KERN_CONT \"block %llu: \", block);\n\tva_start(args, fmt);\n\tvaf.fmt = fmt;\n\tvaf.va = &args;\n\tprintk(KERN_CONT \"comm %s: path %s: %pV\\n\", current->comm, path, &vaf);\n\tva_end(args);\n\n\text4_handle_error(inode->i_sb);\n}\n\nstatic const char *ext4_decode_error(struct super_block *sb, int errno,\n\t\t\t\t     char nbuf[16])\n{\n\tchar *errstr = NULL;\n\n\tswitch (errno) {\n\tcase -EIO:\n\t\terrstr = \"IO failure\";\n\t\tbreak;\n\tcase -ENOMEM:\n\t\terrstr = \"Out of memory\";\n\t\tbreak;\n\tcase -EROFS:\n\t\tif (!sb || (EXT4_SB(sb)->s_journal &&\n\t\t\t    EXT4_SB(sb)->s_journal->j_flags & JBD2_ABORT))\n\t\t\terrstr = \"Journal has aborted\";\n\t\telse\n\t\t\terrstr = \"Readonly filesystem\";\n\t\tbreak;\n\tdefault:\n\t\t/* If the caller passed in an extra buffer for unknown\n\t\t * errors, textualise them now.  Else we just return\n\t\t * NULL. */\n\t\tif (nbuf) {\n\t\t\t/* Check for truncated error codes... */\n\t\t\tif (snprintf(nbuf, 16, \"error %d\", -errno) >= 0)\n\t\t\t\terrstr = nbuf;\n\t\t}\n\t\tbreak;\n\t}\n\n\treturn errstr;\n}\n\n/* __ext4_std_error decodes expected errors from journaling functions\n * automatically and invokes the appropriate error response.  */\n\nvoid __ext4_std_error(struct super_block *sb, const char *function,\n\t\t      unsigned int line, int errno)\n{\n\tchar nbuf[16];\n\tconst char *errstr;\n\n\t/* Special case: if the error is EROFS, and we're not already\n\t * inside a transaction, then there's really no point in logging\n\t * an error. */\n\tif (errno == -EROFS && journal_current_handle() == NULL &&\n\t    (sb->s_flags & MS_RDONLY))\n\t\treturn;\n\n\terrstr = ext4_decode_error(sb, errno, nbuf);\n\tprintk(KERN_CRIT \"EXT4-fs error (device %s) in %s:%d: %s\\n\",\n\t       sb->s_id, function, line, errstr);\n\tsave_error_info(sb, function, line);\n\n\text4_handle_error(sb);\n}\n\n/*\n * ext4_abort is a much stronger failure handler than ext4_error.  The\n * abort function may be used to deal with unrecoverable failures such\n * as journal IO errors or ENOMEM at a critical moment in log management.\n *\n * We unconditionally force the filesystem into an ABORT|READONLY state,\n * unless the error response on the fs has been set to panic in which\n * case we take the easy way out and panic immediately.\n */\n\nvoid __ext4_abort(struct super_block *sb, const char *function,\n\t\tunsigned int line, const char *fmt, ...)\n{\n\tva_list args;\n\n\tsave_error_info(sb, function, line);\n\tva_start(args, fmt);\n\tprintk(KERN_CRIT \"EXT4-fs error (device %s): %s:%d: \", sb->s_id,\n\t       function, line);\n\tvprintk(fmt, args);\n\tprintk(\"\\n\");\n\tva_end(args);\n\n\tif ((sb->s_flags & MS_RDONLY) == 0) {\n\t\text4_msg(sb, KERN_CRIT, \"Remounting filesystem read-only\");\n\t\tsb->s_flags |= MS_RDONLY;\n\t\tEXT4_SB(sb)->s_mount_flags |= EXT4_MF_FS_ABORTED;\n\t\tif (EXT4_SB(sb)->s_journal)\n\t\t\tjbd2_journal_abort(EXT4_SB(sb)->s_journal, -EIO);\n\t\tsave_error_info(sb, function, line);\n\t}\n\tif (test_opt(sb, ERRORS_PANIC))\n\t\tpanic(\"EXT4-fs panic from previous error\\n\");\n}\n\nvoid ext4_msg(struct super_block *sb, const char *prefix, const char *fmt, ...)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\n\tva_start(args, fmt);\n\tvaf.fmt = fmt;\n\tvaf.va = &args;\n\tprintk(\"%sEXT4-fs (%s): %pV\\n\", prefix, sb->s_id, &vaf);\n\tva_end(args);\n}\n\nvoid __ext4_warning(struct super_block *sb, const char *function,\n\t\t    unsigned int line, const char *fmt, ...)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\n\tva_start(args, fmt);\n\tvaf.fmt = fmt;\n\tvaf.va = &args;\n\tprintk(KERN_WARNING \"EXT4-fs warning (device %s): %s:%d: %pV\\n\",\n\t       sb->s_id, function, line, &vaf);\n\tva_end(args);\n}\n\nvoid __ext4_grp_locked_error(const char *function, unsigned int line,\n\t\t\t     struct super_block *sb, ext4_group_t grp,\n\t\t\t     unsigned long ino, ext4_fsblk_t block,\n\t\t\t     const char *fmt, ...)\n__releases(bitlock)\n__acquires(bitlock)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\tstruct ext4_super_block *es = EXT4_SB(sb)->s_es;\n\n\tes->s_last_error_ino = cpu_to_le32(ino);\n\tes->s_last_error_block = cpu_to_le64(block);\n\t__save_error_info(sb, function, line);\n\n\tva_start(args, fmt);\n\n\tvaf.fmt = fmt;\n\tvaf.va = &args;\n\tprintk(KERN_CRIT \"EXT4-fs error (device %s): %s:%d: group %u, \",\n\t       sb->s_id, function, line, grp);\n\tif (ino)\n\t\tprintk(KERN_CONT \"inode %lu: \", ino);\n\tif (block)\n\t\tprintk(KERN_CONT \"block %llu:\", (unsigned long long) block);\n\tprintk(KERN_CONT \"%pV\\n\", &vaf);\n\tva_end(args);\n\n\tif (test_opt(sb, ERRORS_CONT)) {\n\t\text4_commit_super(sb, 0);\n\t\treturn;\n\t}\n\n\text4_unlock_group(sb, grp);\n\text4_handle_error(sb);\n\t/*\n\t * We only get here in the ERRORS_RO case; relocking the group\n\t * may be dangerous, but nothing bad will happen since the\n\t * filesystem will have already been marked read/only and the\n\t * journal has been aborted.  We return 1 as a hint to callers\n\t * who might what to use the return value from\n\t * ext4_grp_locked_error() to distinguish beween the\n\t * ERRORS_CONT and ERRORS_RO case, and perhaps return more\n\t * aggressively from the ext4 function in question, with a\n\t * more appropriate error code.\n\t */\n\text4_lock_group(sb, grp);\n\treturn;\n}\n\nvoid ext4_update_dynamic_rev(struct super_block *sb)\n{\n\tstruct ext4_super_block *es = EXT4_SB(sb)->s_es;\n\n\tif (le32_to_cpu(es->s_rev_level) > EXT4_GOOD_OLD_REV)\n\t\treturn;\n\n\text4_warning(sb,\n\t\t     \"updating to rev %d because of new feature flag, \"\n\t\t     \"running e2fsck is recommended\",\n\t\t     EXT4_DYNAMIC_REV);\n\n\tes->s_first_ino = cpu_to_le32(EXT4_GOOD_OLD_FIRST_INO);\n\tes->s_inode_size = cpu_to_le16(EXT4_GOOD_OLD_INODE_SIZE);\n\tes->s_rev_level = cpu_to_le32(EXT4_DYNAMIC_REV);\n\t/* leave es->s_feature_*compat flags alone */\n\t/* es->s_uuid will be set by e2fsck if empty */\n\n\t/*\n\t * The rest of the superblock fields should be zero, and if not it\n\t * means they are likely already in use, so leave them alone.  We\n\t * can leave it up to e2fsck to clean up any inconsistencies there.\n\t */\n}\n\n/*\n * Open the external journal device\n */\nstatic struct block_device *ext4_blkdev_get(dev_t dev, struct super_block *sb)\n{\n\tstruct block_device *bdev;\n\tchar b[BDEVNAME_SIZE];\n\n\tbdev = blkdev_get_by_dev(dev, FMODE_READ|FMODE_WRITE|FMODE_EXCL, sb);\n\tif (IS_ERR(bdev))\n\t\tgoto fail;\n\treturn bdev;\n\nfail:\n\text4_msg(sb, KERN_ERR, \"failed to open journal device %s: %ld\",\n\t\t\t__bdevname(dev, b), PTR_ERR(bdev));\n\treturn NULL;\n}\n\n/*\n * Release the journal device\n */\nstatic int ext4_blkdev_put(struct block_device *bdev)\n{\n\treturn blkdev_put(bdev, FMODE_READ|FMODE_WRITE|FMODE_EXCL);\n}\n\nstatic int ext4_blkdev_remove(struct ext4_sb_info *sbi)\n{\n\tstruct block_device *bdev;\n\tint ret = -ENODEV;\n\n\tbdev = sbi->journal_bdev;\n\tif (bdev) {\n\t\tret = ext4_blkdev_put(bdev);\n\t\tsbi->journal_bdev = NULL;\n\t}\n\treturn ret;\n}\n\nstatic inline struct inode *orphan_list_entry(struct list_head *l)\n{\n\treturn &list_entry(l, struct ext4_inode_info, i_orphan)->vfs_inode;\n}\n\nstatic void dump_orphan_list(struct super_block *sb, struct ext4_sb_info *sbi)\n{\n\tstruct list_head *l;\n\n\text4_msg(sb, KERN_ERR, \"sb orphan head is %d\",\n\t\t le32_to_cpu(sbi->s_es->s_last_orphan));\n\n\tprintk(KERN_ERR \"sb_info orphan list:\\n\");\n\tlist_for_each(l, &sbi->s_orphan) {\n\t\tstruct inode *inode = orphan_list_entry(l);\n\t\tprintk(KERN_ERR \"  \"\n\t\t       \"inode %s:%lu at %p: mode %o, nlink %d, next %d\\n\",\n\t\t       inode->i_sb->s_id, inode->i_ino, inode,\n\t\t       inode->i_mode, inode->i_nlink,\n\t\t       NEXT_ORPHAN(inode));\n\t}\n}\n\nstatic void ext4_put_super(struct super_block *sb)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_super_block *es = sbi->s_es;\n\tint i, err;\n\n\text4_unregister_li_request(sb);\n\tdquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);\n\n\tflush_workqueue(sbi->dio_unwritten_wq);\n\tdestroy_workqueue(sbi->dio_unwritten_wq);\n\n\tlock_super(sb);\n\tif (sb->s_dirt)\n\t\text4_commit_super(sb, 1);\n\n\tif (sbi->s_journal) {\n\t\terr = jbd2_journal_destroy(sbi->s_journal);\n\t\tsbi->s_journal = NULL;\n\t\tif (err < 0)\n\t\t\text4_abort(sb, \"Couldn't clean up the journal\");\n\t}\n\n\tdel_timer(&sbi->s_err_report);\n\text4_release_system_zone(sb);\n\text4_mb_release(sb);\n\text4_ext_release(sb);\n\text4_xattr_put_super(sb);\n\n\tif (!(sb->s_flags & MS_RDONLY)) {\n\t\tEXT4_CLEAR_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_RECOVER);\n\t\tes->s_state = cpu_to_le16(sbi->s_mount_state);\n\t\text4_commit_super(sb, 1);\n\t}\n\tif (sbi->s_proc) {\n\t\tremove_proc_entry(sb->s_id, ext4_proc_root);\n\t}\n\tkobject_del(&sbi->s_kobj);\n\n\tfor (i = 0; i < sbi->s_gdb_count; i++)\n\t\tbrelse(sbi->s_group_desc[i]);\n\tkfree(sbi->s_group_desc);\n\tif (is_vmalloc_addr(sbi->s_flex_groups))\n\t\tvfree(sbi->s_flex_groups);\n\telse\n\t\tkfree(sbi->s_flex_groups);\n\tpercpu_counter_destroy(&sbi->s_freeblocks_counter);\n\tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n\tpercpu_counter_destroy(&sbi->s_dirs_counter);\n\tpercpu_counter_destroy(&sbi->s_dirtyblocks_counter);\n\tbrelse(sbi->s_sbh);\n#ifdef CONFIG_QUOTA\n\tfor (i = 0; i < MAXQUOTAS; i++)\n\t\tkfree(sbi->s_qf_names[i]);\n#endif\n\n\t/* Debugging code just in case the in-memory inode orphan list\n\t * isn't empty.  The on-disk one can be non-empty if we've\n\t * detected an error and taken the fs readonly, but the\n\t * in-memory list had better be clean by this point. */\n\tif (!list_empty(&sbi->s_orphan))\n\t\tdump_orphan_list(sb, sbi);\n\tJ_ASSERT(list_empty(&sbi->s_orphan));\n\n\tinvalidate_bdev(sb->s_bdev);\n\tif (sbi->journal_bdev && sbi->journal_bdev != sb->s_bdev) {\n\t\t/*\n\t\t * Invalidate the journal device's buffers.  We don't want them\n\t\t * floating about in memory - the physical journal device may\n\t\t * hotswapped, and it breaks the `ro-after' testing code.\n\t\t */\n\t\tsync_blockdev(sbi->journal_bdev);\n\t\tinvalidate_bdev(sbi->journal_bdev);\n\t\text4_blkdev_remove(sbi);\n\t}\n\tsb->s_fs_info = NULL;\n\t/*\n\t * Now that we are completely done shutting down the\n\t * superblock, we need to actually destroy the kobject.\n\t */\n\tunlock_super(sb);\n\tkobject_put(&sbi->s_kobj);\n\twait_for_completion(&sbi->s_kobj_unregister);\n\tkfree(sbi->s_blockgroup_lock);\n\tkfree(sbi);\n}\n\nstatic struct kmem_cache *ext4_inode_cachep;\n\n/*\n * Called inside transaction, so use GFP_NOFS\n */\nstatic struct inode *ext4_alloc_inode(struct super_block *sb)\n{\n\tstruct ext4_inode_info *ei;\n\n\tei = kmem_cache_alloc(ext4_inode_cachep, GFP_NOFS);\n\tif (!ei)\n\t\treturn NULL;\n\n\tei->vfs_inode.i_version = 1;\n\tei->vfs_inode.i_data.writeback_index = 0;\n\tmemset(&ei->i_cached_extent, 0, sizeof(struct ext4_ext_cache));\n\tINIT_LIST_HEAD(&ei->i_prealloc_list);\n\tspin_lock_init(&ei->i_prealloc_lock);\n\tei->i_reserved_data_blocks = 0;\n\tei->i_reserved_meta_blocks = 0;\n\tei->i_allocated_meta_blocks = 0;\n\tei->i_da_metadata_calc_len = 0;\n\tspin_lock_init(&(ei->i_block_reservation_lock));\n#ifdef CONFIG_QUOTA\n\tei->i_reserved_quota = 0;\n#endif\n\tei->jinode = NULL;\n\tINIT_LIST_HEAD(&ei->i_completed_io_list);\n\tspin_lock_init(&ei->i_completed_io_lock);\n\tei->cur_aio_dio = NULL;\n\tei->i_sync_tid = 0;\n\tei->i_datasync_tid = 0;\n\tatomic_set(&ei->i_ioend_count, 0);\n\tatomic_set(&ei->i_aiodio_unwritten, 0);\n\n\treturn &ei->vfs_inode;\n}\n\nstatic int ext4_drop_inode(struct inode *inode)\n{\n\tint drop = generic_drop_inode(inode);\n\n\ttrace_ext4_drop_inode(inode, drop);\n\treturn drop;\n}\n\nstatic void ext4_i_callback(struct rcu_head *head)\n{\n\tstruct inode *inode = container_of(head, struct inode, i_rcu);\n\tINIT_LIST_HEAD(&inode->i_dentry);\n\tkmem_cache_free(ext4_inode_cachep, EXT4_I(inode));\n}\n\nstatic void ext4_destroy_inode(struct inode *inode)\n{\n\text4_ioend_wait(inode);\n\tif (!list_empty(&(EXT4_I(inode)->i_orphan))) {\n\t\text4_msg(inode->i_sb, KERN_ERR,\n\t\t\t \"Inode %lu (%p): orphan list check failed!\",\n\t\t\t inode->i_ino, EXT4_I(inode));\n\t\tprint_hex_dump(KERN_INFO, \"\", DUMP_PREFIX_ADDRESS, 16, 4,\n\t\t\t\tEXT4_I(inode), sizeof(struct ext4_inode_info),\n\t\t\t\ttrue);\n\t\tdump_stack();\n\t}\n\tcall_rcu(&inode->i_rcu, ext4_i_callback);\n}\n\nstatic void init_once(void *foo)\n{\n\tstruct ext4_inode_info *ei = (struct ext4_inode_info *) foo;\n\n\tINIT_LIST_HEAD(&ei->i_orphan);\n#ifdef CONFIG_EXT4_FS_XATTR\n\tinit_rwsem(&ei->xattr_sem);\n#endif\n\tinit_rwsem(&ei->i_data_sem);\n\tinode_init_once(&ei->vfs_inode);\n}\n\nstatic int init_inodecache(void)\n{\n\text4_inode_cachep = kmem_cache_create(\"ext4_inode_cache\",\n\t\t\t\t\t     sizeof(struct ext4_inode_info),\n\t\t\t\t\t     0, (SLAB_RECLAIM_ACCOUNT|\n\t\t\t\t\t\tSLAB_MEM_SPREAD),\n\t\t\t\t\t     init_once);\n\tif (ext4_inode_cachep == NULL)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nstatic void destroy_inodecache(void)\n{\n\tkmem_cache_destroy(ext4_inode_cachep);\n}\n\nvoid ext4_clear_inode(struct inode *inode)\n{\n\tinvalidate_inode_buffers(inode);\n\tend_writeback(inode);\n\tdquot_drop(inode);\n\text4_discard_preallocations(inode);\n\tif (EXT4_I(inode)->jinode) {\n\t\tjbd2_journal_release_jbd_inode(EXT4_JOURNAL(inode),\n\t\t\t\t\t       EXT4_I(inode)->jinode);\n\t\tjbd2_free_inode(EXT4_I(inode)->jinode);\n\t\tEXT4_I(inode)->jinode = NULL;\n\t}\n}\n\nstatic inline void ext4_show_quota_options(struct seq_file *seq,\n\t\t\t\t\t   struct super_block *sb)\n{\n#if defined(CONFIG_QUOTA)\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\tif (sbi->s_jquota_fmt) {\n\t\tchar *fmtname = \"\";\n\n\t\tswitch (sbi->s_jquota_fmt) {\n\t\tcase QFMT_VFS_OLD:\n\t\t\tfmtname = \"vfsold\";\n\t\t\tbreak;\n\t\tcase QFMT_VFS_V0:\n\t\t\tfmtname = \"vfsv0\";\n\t\t\tbreak;\n\t\tcase QFMT_VFS_V1:\n\t\t\tfmtname = \"vfsv1\";\n\t\t\tbreak;\n\t\t}\n\t\tseq_printf(seq, \",jqfmt=%s\", fmtname);\n\t}\n\n\tif (sbi->s_qf_names[USRQUOTA])\n\t\tseq_printf(seq, \",usrjquota=%s\", sbi->s_qf_names[USRQUOTA]);\n\n\tif (sbi->s_qf_names[GRPQUOTA])\n\t\tseq_printf(seq, \",grpjquota=%s\", sbi->s_qf_names[GRPQUOTA]);\n\n\tif (test_opt(sb, USRQUOTA))\n\t\tseq_puts(seq, \",usrquota\");\n\n\tif (test_opt(sb, GRPQUOTA))\n\t\tseq_puts(seq, \",grpquota\");\n#endif\n}\n\n/*\n * Show an option if\n *  - it's set to a non-default value OR\n *  - if the per-sb default is different from the global default\n */\nstatic int ext4_show_options(struct seq_file *seq, struct vfsmount *vfs)\n{\n\tint def_errors;\n\tunsigned long def_mount_opts;\n\tstruct super_block *sb = vfs->mnt_sb;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_super_block *es = sbi->s_es;\n\n\tdef_mount_opts = le32_to_cpu(es->s_default_mount_opts);\n\tdef_errors     = le16_to_cpu(es->s_errors);\n\n\tif (sbi->s_sb_block != 1)\n\t\tseq_printf(seq, \",sb=%llu\", sbi->s_sb_block);\n\tif (test_opt(sb, MINIX_DF))\n\t\tseq_puts(seq, \",minixdf\");\n\tif (test_opt(sb, GRPID) && !(def_mount_opts & EXT4_DEFM_BSDGROUPS))\n\t\tseq_puts(seq, \",grpid\");\n\tif (!test_opt(sb, GRPID) && (def_mount_opts & EXT4_DEFM_BSDGROUPS))\n\t\tseq_puts(seq, \",nogrpid\");\n\tif (sbi->s_resuid != EXT4_DEF_RESUID ||\n\t    le16_to_cpu(es->s_def_resuid) != EXT4_DEF_RESUID) {\n\t\tseq_printf(seq, \",resuid=%u\", sbi->s_resuid);\n\t}\n\tif (sbi->s_resgid != EXT4_DEF_RESGID ||\n\t    le16_to_cpu(es->s_def_resgid) != EXT4_DEF_RESGID) {\n\t\tseq_printf(seq, \",resgid=%u\", sbi->s_resgid);\n\t}\n\tif (test_opt(sb, ERRORS_RO)) {\n\t\tif (def_errors == EXT4_ERRORS_PANIC ||\n\t\t    def_errors == EXT4_ERRORS_CONTINUE) {\n\t\t\tseq_puts(seq, \",errors=remount-ro\");\n\t\t}\n\t}\n\tif (test_opt(sb, ERRORS_CONT) && def_errors != EXT4_ERRORS_CONTINUE)\n\t\tseq_puts(seq, \",errors=continue\");\n\tif (test_opt(sb, ERRORS_PANIC) && def_errors != EXT4_ERRORS_PANIC)\n\t\tseq_puts(seq, \",errors=panic\");\n\tif (test_opt(sb, NO_UID32) && !(def_mount_opts & EXT4_DEFM_UID16))\n\t\tseq_puts(seq, \",nouid32\");\n\tif (test_opt(sb, DEBUG) && !(def_mount_opts & EXT4_DEFM_DEBUG))\n\t\tseq_puts(seq, \",debug\");\n\tif (test_opt(sb, OLDALLOC))\n\t\tseq_puts(seq, \",oldalloc\");\n#ifdef CONFIG_EXT4_FS_XATTR\n\tif (test_opt(sb, XATTR_USER))\n\t\tseq_puts(seq, \",user_xattr\");\n\tif (!test_opt(sb, XATTR_USER))\n\t\tseq_puts(seq, \",nouser_xattr\");\n#endif\n#ifdef CONFIG_EXT4_FS_POSIX_ACL\n\tif (test_opt(sb, POSIX_ACL) && !(def_mount_opts & EXT4_DEFM_ACL))\n\t\tseq_puts(seq, \",acl\");\n\tif (!test_opt(sb, POSIX_ACL) && (def_mount_opts & EXT4_DEFM_ACL))\n\t\tseq_puts(seq, \",noacl\");\n#endif\n\tif (sbi->s_commit_interval != JBD2_DEFAULT_MAX_COMMIT_AGE*HZ) {\n\t\tseq_printf(seq, \",commit=%u\",\n\t\t\t   (unsigned) (sbi->s_commit_interval / HZ));\n\t}\n\tif (sbi->s_min_batch_time != EXT4_DEF_MIN_BATCH_TIME) {\n\t\tseq_printf(seq, \",min_batch_time=%u\",\n\t\t\t   (unsigned) sbi->s_min_batch_time);\n\t}\n\tif (sbi->s_max_batch_time != EXT4_DEF_MAX_BATCH_TIME) {\n\t\tseq_printf(seq, \",max_batch_time=%u\",\n\t\t\t   (unsigned) sbi->s_min_batch_time);\n\t}\n\n\t/*\n\t * We're changing the default of barrier mount option, so\n\t * let's always display its mount state so it's clear what its\n\t * status is.\n\t */\n\tseq_puts(seq, \",barrier=\");\n\tseq_puts(seq, test_opt(sb, BARRIER) ? \"1\" : \"0\");\n\tif (test_opt(sb, JOURNAL_ASYNC_COMMIT))\n\t\tseq_puts(seq, \",journal_async_commit\");\n\telse if (test_opt(sb, JOURNAL_CHECKSUM))\n\t\tseq_puts(seq, \",journal_checksum\");\n\tif (test_opt(sb, I_VERSION))\n\t\tseq_puts(seq, \",i_version\");\n\tif (!test_opt(sb, DELALLOC) &&\n\t    !(def_mount_opts & EXT4_DEFM_NODELALLOC))\n\t\tseq_puts(seq, \",nodelalloc\");\n\n\tif (!test_opt(sb, MBLK_IO_SUBMIT))\n\t\tseq_puts(seq, \",nomblk_io_submit\");\n\tif (sbi->s_stripe)\n\t\tseq_printf(seq, \",stripe=%lu\", sbi->s_stripe);\n\t/*\n\t * journal mode get enabled in different ways\n\t * So just print the value even if we didn't specify it\n\t */\n\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA)\n\t\tseq_puts(seq, \",data=journal\");\n\telse if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA)\n\t\tseq_puts(seq, \",data=ordered\");\n\telse if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_WRITEBACK_DATA)\n\t\tseq_puts(seq, \",data=writeback\");\n\n\tif (sbi->s_inode_readahead_blks != EXT4_DEF_INODE_READAHEAD_BLKS)\n\t\tseq_printf(seq, \",inode_readahead_blks=%u\",\n\t\t\t   sbi->s_inode_readahead_blks);\n\n\tif (test_opt(sb, DATA_ERR_ABORT))\n\t\tseq_puts(seq, \",data_err=abort\");\n\n\tif (test_opt(sb, NO_AUTO_DA_ALLOC))\n\t\tseq_puts(seq, \",noauto_da_alloc\");\n\n\tif (test_opt(sb, DISCARD) && !(def_mount_opts & EXT4_DEFM_DISCARD))\n\t\tseq_puts(seq, \",discard\");\n\n\tif (test_opt(sb, NOLOAD))\n\t\tseq_puts(seq, \",norecovery\");\n\n\tif (test_opt(sb, DIOREAD_NOLOCK))\n\t\tseq_puts(seq, \",dioread_nolock\");\n\n\tif (test_opt(sb, BLOCK_VALIDITY) &&\n\t    !(def_mount_opts & EXT4_DEFM_BLOCK_VALIDITY))\n\t\tseq_puts(seq, \",block_validity\");\n\n\tif (!test_opt(sb, INIT_INODE_TABLE))\n\t\tseq_puts(seq, \",noinit_inode_table\");\n\telse if (sbi->s_li_wait_mult)\n\t\tseq_printf(seq, \",init_inode_table=%u\",\n\t\t\t   (unsigned) sbi->s_li_wait_mult);\n\n\text4_show_quota_options(seq, sb);\n\n\treturn 0;\n}\n\nstatic struct inode *ext4_nfs_get_inode(struct super_block *sb,\n\t\t\t\t\tu64 ino, u32 generation)\n{\n\tstruct inode *inode;\n\n\tif (ino < EXT4_FIRST_INO(sb) && ino != EXT4_ROOT_INO)\n\t\treturn ERR_PTR(-ESTALE);\n\tif (ino > le32_to_cpu(EXT4_SB(sb)->s_es->s_inodes_count))\n\t\treturn ERR_PTR(-ESTALE);\n\n\t/* iget isn't really right if the inode is currently unallocated!!\n\t *\n\t * ext4_read_inode will return a bad_inode if the inode had been\n\t * deleted, so we should be safe.\n\t *\n\t * Currently we don't know the generation for parent directory, so\n\t * a generation of 0 means \"accept any\"\n\t */\n\tinode = ext4_iget(sb, ino);\n\tif (IS_ERR(inode))\n\t\treturn ERR_CAST(inode);\n\tif (generation && inode->i_generation != generation) {\n\t\tiput(inode);\n\t\treturn ERR_PTR(-ESTALE);\n\t}\n\n\treturn inode;\n}\n\nstatic struct dentry *ext4_fh_to_dentry(struct super_block *sb, struct fid *fid,\n\t\t\t\t\tint fh_len, int fh_type)\n{\n\treturn generic_fh_to_dentry(sb, fid, fh_len, fh_type,\n\t\t\t\t    ext4_nfs_get_inode);\n}\n\nstatic struct dentry *ext4_fh_to_parent(struct super_block *sb, struct fid *fid,\n\t\t\t\t\tint fh_len, int fh_type)\n{\n\treturn generic_fh_to_parent(sb, fid, fh_len, fh_type,\n\t\t\t\t    ext4_nfs_get_inode);\n}\n\n/*\n * Try to release metadata pages (indirect blocks, directories) which are\n * mapped via the block device.  Since these pages could have journal heads\n * which would prevent try_to_free_buffers() from freeing them, we must use\n * jbd2 layer's try_to_free_buffers() function to release them.\n */\nstatic int bdev_try_to_free_page(struct super_block *sb, struct page *page,\n\t\t\t\t gfp_t wait)\n{\n\tjournal_t *journal = EXT4_SB(sb)->s_journal;\n\n\tWARN_ON(PageChecked(page));\n\tif (!page_has_buffers(page))\n\t\treturn 0;\n\tif (journal)\n\t\treturn jbd2_journal_try_to_free_buffers(journal, page,\n\t\t\t\t\t\t\twait & ~__GFP_WAIT);\n\treturn try_to_free_buffers(page);\n}\n\n#ifdef CONFIG_QUOTA\n#define QTYPE2NAME(t) ((t) == USRQUOTA ? \"user\" : \"group\")\n#define QTYPE2MOPT(on, t) ((t) == USRQUOTA?((on)##USRJQUOTA):((on)##GRPJQUOTA))\n\nstatic int ext4_write_dquot(struct dquot *dquot);\nstatic int ext4_acquire_dquot(struct dquot *dquot);\nstatic int ext4_release_dquot(struct dquot *dquot);\nstatic int ext4_mark_dquot_dirty(struct dquot *dquot);\nstatic int ext4_write_info(struct super_block *sb, int type);\nstatic int ext4_quota_on(struct super_block *sb, int type, int format_id,\n\t\t\t struct path *path);\nstatic int ext4_quota_off(struct super_block *sb, int type);\nstatic int ext4_quota_on_mount(struct super_block *sb, int type);\nstatic ssize_t ext4_quota_read(struct super_block *sb, int type, char *data,\n\t\t\t       size_t len, loff_t off);\nstatic ssize_t ext4_quota_write(struct super_block *sb, int type,\n\t\t\t\tconst char *data, size_t len, loff_t off);\n\nstatic const struct dquot_operations ext4_quota_operations = {\n#ifdef CONFIG_QUOTA\n\t.get_reserved_space = ext4_get_reserved_space,\n#endif\n\t.write_dquot\t= ext4_write_dquot,\n\t.acquire_dquot\t= ext4_acquire_dquot,\n\t.release_dquot\t= ext4_release_dquot,\n\t.mark_dirty\t= ext4_mark_dquot_dirty,\n\t.write_info\t= ext4_write_info,\n\t.alloc_dquot\t= dquot_alloc,\n\t.destroy_dquot\t= dquot_destroy,\n};\n\nstatic const struct quotactl_ops ext4_qctl_operations = {\n\t.quota_on\t= ext4_quota_on,\n\t.quota_off\t= ext4_quota_off,\n\t.quota_sync\t= dquot_quota_sync,\n\t.get_info\t= dquot_get_dqinfo,\n\t.set_info\t= dquot_set_dqinfo,\n\t.get_dqblk\t= dquot_get_dqblk,\n\t.set_dqblk\t= dquot_set_dqblk\n};\n#endif\n\nstatic const struct super_operations ext4_sops = {\n\t.alloc_inode\t= ext4_alloc_inode,\n\t.destroy_inode\t= ext4_destroy_inode,\n\t.write_inode\t= ext4_write_inode,\n\t.dirty_inode\t= ext4_dirty_inode,\n\t.drop_inode\t= ext4_drop_inode,\n\t.evict_inode\t= ext4_evict_inode,\n\t.put_super\t= ext4_put_super,\n\t.sync_fs\t= ext4_sync_fs,\n\t.freeze_fs\t= ext4_freeze,\n\t.unfreeze_fs\t= ext4_unfreeze,\n\t.statfs\t\t= ext4_statfs,\n\t.remount_fs\t= ext4_remount,\n\t.show_options\t= ext4_show_options,\n#ifdef CONFIG_QUOTA\n\t.quota_read\t= ext4_quota_read,\n\t.quota_write\t= ext4_quota_write,\n#endif\n\t.bdev_try_to_free_page = bdev_try_to_free_page,\n};\n\nstatic const struct super_operations ext4_nojournal_sops = {\n\t.alloc_inode\t= ext4_alloc_inode,\n\t.destroy_inode\t= ext4_destroy_inode,\n\t.write_inode\t= ext4_write_inode,\n\t.dirty_inode\t= ext4_dirty_inode,\n\t.drop_inode\t= ext4_drop_inode,\n\t.evict_inode\t= ext4_evict_inode,\n\t.write_super\t= ext4_write_super,\n\t.put_super\t= ext4_put_super,\n\t.statfs\t\t= ext4_statfs,\n\t.remount_fs\t= ext4_remount,\n\t.show_options\t= ext4_show_options,\n#ifdef CONFIG_QUOTA\n\t.quota_read\t= ext4_quota_read,\n\t.quota_write\t= ext4_quota_write,\n#endif\n\t.bdev_try_to_free_page = bdev_try_to_free_page,\n};\n\nstatic const struct export_operations ext4_export_ops = {\n\t.fh_to_dentry = ext4_fh_to_dentry,\n\t.fh_to_parent = ext4_fh_to_parent,\n\t.get_parent = ext4_get_parent,\n};\n\nenum {\n\tOpt_bsd_df, Opt_minix_df, Opt_grpid, Opt_nogrpid,\n\tOpt_resgid, Opt_resuid, Opt_sb, Opt_err_cont, Opt_err_panic, Opt_err_ro,\n\tOpt_nouid32, Opt_debug, Opt_oldalloc, Opt_orlov,\n\tOpt_user_xattr, Opt_nouser_xattr, Opt_acl, Opt_noacl,\n\tOpt_auto_da_alloc, Opt_noauto_da_alloc, Opt_noload, Opt_nobh, Opt_bh,\n\tOpt_commit, Opt_min_batch_time, Opt_max_batch_time,\n\tOpt_journal_update, Opt_journal_dev,\n\tOpt_journal_checksum, Opt_journal_async_commit,\n\tOpt_abort, Opt_data_journal, Opt_data_ordered, Opt_data_writeback,\n\tOpt_data_err_abort, Opt_data_err_ignore,\n\tOpt_usrjquota, Opt_grpjquota, Opt_offusrjquota, Opt_offgrpjquota,\n\tOpt_jqfmt_vfsold, Opt_jqfmt_vfsv0, Opt_jqfmt_vfsv1, Opt_quota,\n\tOpt_noquota, Opt_ignore, Opt_barrier, Opt_nobarrier, Opt_err,\n\tOpt_resize, Opt_usrquota, Opt_grpquota, Opt_i_version,\n\tOpt_stripe, Opt_delalloc, Opt_nodelalloc, Opt_mblk_io_submit,\n\tOpt_nomblk_io_submit, Opt_block_validity, Opt_noblock_validity,\n\tOpt_inode_readahead_blks, Opt_journal_ioprio,\n\tOpt_dioread_nolock, Opt_dioread_lock,\n\tOpt_discard, Opt_nodiscard,\n\tOpt_init_inode_table, Opt_noinit_inode_table,\n};\n\nstatic const match_table_t tokens = {\n\t{Opt_bsd_df, \"bsddf\"},\n\t{Opt_minix_df, \"minixdf\"},\n\t{Opt_grpid, \"grpid\"},\n\t{Opt_grpid, \"bsdgroups\"},\n\t{Opt_nogrpid, \"nogrpid\"},\n\t{Opt_nogrpid, \"sysvgroups\"},\n\t{Opt_resgid, \"resgid=%u\"},\n\t{Opt_resuid, \"resuid=%u\"},\n\t{Opt_sb, \"sb=%u\"},\n\t{Opt_err_cont, \"errors=continue\"},\n\t{Opt_err_panic, \"errors=panic\"},\n\t{Opt_err_ro, \"errors=remount-ro\"},\n\t{Opt_nouid32, \"nouid32\"},\n\t{Opt_debug, \"debug\"},\n\t{Opt_oldalloc, \"oldalloc\"},\n\t{Opt_orlov, \"orlov\"},\n\t{Opt_user_xattr, \"user_xattr\"},\n\t{Opt_nouser_xattr, \"nouser_xattr\"},\n\t{Opt_acl, \"acl\"},\n\t{Opt_noacl, \"noacl\"},\n\t{Opt_noload, \"noload\"},\n\t{Opt_noload, \"norecovery\"},\n\t{Opt_nobh, \"nobh\"},\n\t{Opt_bh, \"bh\"},\n\t{Opt_commit, \"commit=%u\"},\n\t{Opt_min_batch_time, \"min_batch_time=%u\"},\n\t{Opt_max_batch_time, \"max_batch_time=%u\"},\n\t{Opt_journal_update, \"journal=update\"},\n\t{Opt_journal_dev, \"journal_dev=%u\"},\n\t{Opt_journal_checksum, \"journal_checksum\"},\n\t{Opt_journal_async_commit, \"journal_async_commit\"},\n\t{Opt_abort, \"abort\"},\n\t{Opt_data_journal, \"data=journal\"},\n\t{Opt_data_ordered, \"data=ordered\"},\n\t{Opt_data_writeback, \"data=writeback\"},\n\t{Opt_data_err_abort, \"data_err=abort\"},\n\t{Opt_data_err_ignore, \"data_err=ignore\"},\n\t{Opt_offusrjquota, \"usrjquota=\"},\n\t{Opt_usrjquota, \"usrjquota=%s\"},\n\t{Opt_offgrpjquota, \"grpjquota=\"},\n\t{Opt_grpjquota, \"grpjquota=%s\"},\n\t{Opt_jqfmt_vfsold, \"jqfmt=vfsold\"},\n\t{Opt_jqfmt_vfsv0, \"jqfmt=vfsv0\"},\n\t{Opt_jqfmt_vfsv1, \"jqfmt=vfsv1\"},\n\t{Opt_grpquota, \"grpquota\"},\n\t{Opt_noquota, \"noquota\"},\n\t{Opt_quota, \"quota\"},\n\t{Opt_usrquota, \"usrquota\"},\n\t{Opt_barrier, \"barrier=%u\"},\n\t{Opt_barrier, \"barrier\"},\n\t{Opt_nobarrier, \"nobarrier\"},\n\t{Opt_i_version, \"i_version\"},\n\t{Opt_stripe, \"stripe=%u\"},\n\t{Opt_resize, \"resize\"},\n\t{Opt_delalloc, \"delalloc\"},\n\t{Opt_nodelalloc, \"nodelalloc\"},\n\t{Opt_mblk_io_submit, \"mblk_io_submit\"},\n\t{Opt_nomblk_io_submit, \"nomblk_io_submit\"},\n\t{Opt_block_validity, \"block_validity\"},\n\t{Opt_noblock_validity, \"noblock_validity\"},\n\t{Opt_inode_readahead_blks, \"inode_readahead_blks=%u\"},\n\t{Opt_journal_ioprio, \"journal_ioprio=%u\"},\n\t{Opt_auto_da_alloc, \"auto_da_alloc=%u\"},\n\t{Opt_auto_da_alloc, \"auto_da_alloc\"},\n\t{Opt_noauto_da_alloc, \"noauto_da_alloc\"},\n\t{Opt_dioread_nolock, \"dioread_nolock\"},\n\t{Opt_dioread_lock, \"dioread_lock\"},\n\t{Opt_discard, \"discard\"},\n\t{Opt_nodiscard, \"nodiscard\"},\n\t{Opt_init_inode_table, \"init_itable=%u\"},\n\t{Opt_init_inode_table, \"init_itable\"},\n\t{Opt_noinit_inode_table, \"noinit_itable\"},\n\t{Opt_err, NULL},\n};\n\nstatic ext4_fsblk_t get_sb_block(void **data)\n{\n\text4_fsblk_t\tsb_block;\n\tchar\t\t*options = (char *) *data;\n\n\tif (!options || strncmp(options, \"sb=\", 3) != 0)\n\t\treturn 1;\t/* Default location */\n\n\toptions += 3;\n\t/* TODO: use simple_strtoll with >32bit ext4 */\n\tsb_block = simple_strtoul(options, &options, 0);\n\tif (*options && *options != ',') {\n\t\tprintk(KERN_ERR \"EXT4-fs: Invalid sb specification: %s\\n\",\n\t\t       (char *) *data);\n\t\treturn 1;\n\t}\n\tif (*options == ',')\n\t\toptions++;\n\t*data = (void *) options;\n\n\treturn sb_block;\n}\n\n#define DEFAULT_JOURNAL_IOPRIO (IOPRIO_PRIO_VALUE(IOPRIO_CLASS_BE, 3))\nstatic char deprecated_msg[] = \"Mount option \\\"%s\\\" will be removed by %s\\n\"\n\t\"Contact linux-ext4@vger.kernel.org if you think we should keep it.\\n\";\n\n#ifdef CONFIG_QUOTA\nstatic int set_qf_name(struct super_block *sb, int qtype, substring_t *args)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tchar *qname;\n\n\tif (sb_any_quota_loaded(sb) &&\n\t\t!sbi->s_qf_names[qtype]) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t\"Cannot change journaled \"\n\t\t\t\"quota options when quota turned on\");\n\t\treturn 0;\n\t}\n\tqname = match_strdup(args);\n\tif (!qname) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t\"Not enough memory for storing quotafile name\");\n\t\treturn 0;\n\t}\n\tif (sbi->s_qf_names[qtype] &&\n\t\tstrcmp(sbi->s_qf_names[qtype], qname)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t\"%s quota file already specified\", QTYPE2NAME(qtype));\n\t\tkfree(qname);\n\t\treturn 0;\n\t}\n\tsbi->s_qf_names[qtype] = qname;\n\tif (strchr(sbi->s_qf_names[qtype], '/')) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t\"quotafile must be on filesystem root\");\n\t\tkfree(sbi->s_qf_names[qtype]);\n\t\tsbi->s_qf_names[qtype] = NULL;\n\t\treturn 0;\n\t}\n\tset_opt(sb, QUOTA);\n\treturn 1;\n}\n\nstatic int clear_qf_name(struct super_block *sb, int qtype)\n{\n\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\tif (sb_any_quota_loaded(sb) &&\n\t\tsbi->s_qf_names[qtype]) {\n\t\text4_msg(sb, KERN_ERR, \"Cannot change journaled quota options\"\n\t\t\t\" when quota turned on\");\n\t\treturn 0;\n\t}\n\t/*\n\t * The space will be released later when all options are confirmed\n\t * to be correct\n\t */\n\tsbi->s_qf_names[qtype] = NULL;\n\treturn 1;\n}\n#endif\n\nstatic int parse_options(char *options, struct super_block *sb,\n\t\t\t unsigned long *journal_devnum,\n\t\t\t unsigned int *journal_ioprio,\n\t\t\t ext4_fsblk_t *n_blocks_count, int is_remount)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tchar *p;\n\tsubstring_t args[MAX_OPT_ARGS];\n\tint data_opt = 0;\n\tint option;\n#ifdef CONFIG_QUOTA\n\tint qfmt;\n#endif\n\n\tif (!options)\n\t\treturn 1;\n\n\twhile ((p = strsep(&options, \",\")) != NULL) {\n\t\tint token;\n\t\tif (!*p)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * Initialize args struct so we know whether arg was\n\t\t * found; some options take optional arguments.\n\t\t */\n\t\targs[0].to = args[0].from = NULL;\n\t\ttoken = match_token(p, tokens, args);\n\t\tswitch (token) {\n\t\tcase Opt_bsd_df:\n\t\t\text4_msg(sb, KERN_WARNING, deprecated_msg, p, \"2.6.38\");\n\t\t\tclear_opt(sb, MINIX_DF);\n\t\t\tbreak;\n\t\tcase Opt_minix_df:\n\t\t\text4_msg(sb, KERN_WARNING, deprecated_msg, p, \"2.6.38\");\n\t\t\tset_opt(sb, MINIX_DF);\n\n\t\t\tbreak;\n\t\tcase Opt_grpid:\n\t\t\text4_msg(sb, KERN_WARNING, deprecated_msg, p, \"2.6.38\");\n\t\t\tset_opt(sb, GRPID);\n\n\t\t\tbreak;\n\t\tcase Opt_nogrpid:\n\t\t\text4_msg(sb, KERN_WARNING, deprecated_msg, p, \"2.6.38\");\n\t\t\tclear_opt(sb, GRPID);\n\n\t\t\tbreak;\n\t\tcase Opt_resuid:\n\t\t\tif (match_int(&args[0], &option))\n\t\t\t\treturn 0;\n\t\t\tsbi->s_resuid = option;\n\t\t\tbreak;\n\t\tcase Opt_resgid:\n\t\t\tif (match_int(&args[0], &option))\n\t\t\t\treturn 0;\n\t\t\tsbi->s_resgid = option;\n\t\t\tbreak;\n\t\tcase Opt_sb:\n\t\t\t/* handled by get_sb_block() instead of here */\n\t\t\t/* *sb_block = match_int(&args[0]); */\n\t\t\tbreak;\n\t\tcase Opt_err_panic:\n\t\t\tclear_opt(sb, ERRORS_CONT);\n\t\t\tclear_opt(sb, ERRORS_RO);\n\t\t\tset_opt(sb, ERRORS_PANIC);\n\t\t\tbreak;\n\t\tcase Opt_err_ro:\n\t\t\tclear_opt(sb, ERRORS_CONT);\n\t\t\tclear_opt(sb, ERRORS_PANIC);\n\t\t\tset_opt(sb, ERRORS_RO);\n\t\t\tbreak;\n\t\tcase Opt_err_cont:\n\t\t\tclear_opt(sb, ERRORS_RO);\n\t\t\tclear_opt(sb, ERRORS_PANIC);\n\t\t\tset_opt(sb, ERRORS_CONT);\n\t\t\tbreak;\n\t\tcase Opt_nouid32:\n\t\t\tset_opt(sb, NO_UID32);\n\t\t\tbreak;\n\t\tcase Opt_debug:\n\t\t\tset_opt(sb, DEBUG);\n\t\t\tbreak;\n\t\tcase Opt_oldalloc:\n\t\t\tset_opt(sb, OLDALLOC);\n\t\t\tbreak;\n\t\tcase Opt_orlov:\n\t\t\tclear_opt(sb, OLDALLOC);\n\t\t\tbreak;\n#ifdef CONFIG_EXT4_FS_XATTR\n\t\tcase Opt_user_xattr:\n\t\t\tset_opt(sb, XATTR_USER);\n\t\t\tbreak;\n\t\tcase Opt_nouser_xattr:\n\t\t\tclear_opt(sb, XATTR_USER);\n\t\t\tbreak;\n#else\n\t\tcase Opt_user_xattr:\n\t\tcase Opt_nouser_xattr:\n\t\t\text4_msg(sb, KERN_ERR, \"(no)user_xattr options not supported\");\n\t\t\tbreak;\n#endif\n#ifdef CONFIG_EXT4_FS_POSIX_ACL\n\t\tcase Opt_acl:\n\t\t\tset_opt(sb, POSIX_ACL);\n\t\t\tbreak;\n\t\tcase Opt_noacl:\n\t\t\tclear_opt(sb, POSIX_ACL);\n\t\t\tbreak;\n#else\n\t\tcase Opt_acl:\n\t\tcase Opt_noacl:\n\t\t\text4_msg(sb, KERN_ERR, \"(no)acl options not supported\");\n\t\t\tbreak;\n#endif\n\t\tcase Opt_journal_update:\n\t\t\t/* @@@ FIXME */\n\t\t\t/* Eventually we will want to be able to create\n\t\t\t   a journal file here.  For now, only allow the\n\t\t\t   user to specify an existing inode to be the\n\t\t\t   journal file. */\n\t\t\tif (is_remount) {\n\t\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\t \"Cannot specify journal on remount\");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tset_opt(sb, UPDATE_JOURNAL);\n\t\t\tbreak;\n\t\tcase Opt_journal_dev:\n\t\t\tif (is_remount) {\n\t\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\t\"Cannot specify journal on remount\");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tif (match_int(&args[0], &option))\n\t\t\t\treturn 0;\n\t\t\t*journal_devnum = option;\n\t\t\tbreak;\n\t\tcase Opt_journal_checksum:\n\t\t\tset_opt(sb, JOURNAL_CHECKSUM);\n\t\t\tbreak;\n\t\tcase Opt_journal_async_commit:\n\t\t\tset_opt(sb, JOURNAL_ASYNC_COMMIT);\n\t\t\tset_opt(sb, JOURNAL_CHECKSUM);\n\t\t\tbreak;\n\t\tcase Opt_noload:\n\t\t\tset_opt(sb, NOLOAD);\n\t\t\tbreak;\n\t\tcase Opt_commit:\n\t\t\tif (match_int(&args[0], &option))\n\t\t\t\treturn 0;\n\t\t\tif (option < 0)\n\t\t\t\treturn 0;\n\t\t\tif (option == 0)\n\t\t\t\toption = JBD2_DEFAULT_MAX_COMMIT_AGE;\n\t\t\tsbi->s_commit_interval = HZ * option;\n\t\t\tbreak;\n\t\tcase Opt_max_batch_time:\n\t\t\tif (match_int(&args[0], &option))\n\t\t\t\treturn 0;\n\t\t\tif (option < 0)\n\t\t\t\treturn 0;\n\t\t\tif (option == 0)\n\t\t\t\toption = EXT4_DEF_MAX_BATCH_TIME;\n\t\t\tsbi->s_max_batch_time = option;\n\t\t\tbreak;\n\t\tcase Opt_min_batch_time:\n\t\t\tif (match_int(&args[0], &option))\n\t\t\t\treturn 0;\n\t\t\tif (option < 0)\n\t\t\t\treturn 0;\n\t\t\tsbi->s_min_batch_time = option;\n\t\t\tbreak;\n\t\tcase Opt_data_journal:\n\t\t\tdata_opt = EXT4_MOUNT_JOURNAL_DATA;\n\t\t\tgoto datacheck;\n\t\tcase Opt_data_ordered:\n\t\t\tdata_opt = EXT4_MOUNT_ORDERED_DATA;\n\t\t\tgoto datacheck;\n\t\tcase Opt_data_writeback:\n\t\t\tdata_opt = EXT4_MOUNT_WRITEBACK_DATA;\n\t\tdatacheck:\n\t\t\tif (is_remount) {\n\t\t\t\tif (test_opt(sb, DATA_FLAGS) != data_opt) {\n\t\t\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\t\t\"Cannot change data mode on remount\");\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tclear_opt(sb, DATA_FLAGS);\n\t\t\t\tsbi->s_mount_opt |= data_opt;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase Opt_data_err_abort:\n\t\t\tset_opt(sb, DATA_ERR_ABORT);\n\t\t\tbreak;\n\t\tcase Opt_data_err_ignore:\n\t\t\tclear_opt(sb, DATA_ERR_ABORT);\n\t\t\tbreak;\n#ifdef CONFIG_QUOTA\n\t\tcase Opt_usrjquota:\n\t\t\tif (!set_qf_name(sb, USRQUOTA, &args[0]))\n\t\t\t\treturn 0;\n\t\t\tbreak;\n\t\tcase Opt_grpjquota:\n\t\t\tif (!set_qf_name(sb, GRPQUOTA, &args[0]))\n\t\t\t\treturn 0;\n\t\t\tbreak;\n\t\tcase Opt_offusrjquota:\n\t\t\tif (!clear_qf_name(sb, USRQUOTA))\n\t\t\t\treturn 0;\n\t\t\tbreak;\n\t\tcase Opt_offgrpjquota:\n\t\t\tif (!clear_qf_name(sb, GRPQUOTA))\n\t\t\t\treturn 0;\n\t\t\tbreak;\n\n\t\tcase Opt_jqfmt_vfsold:\n\t\t\tqfmt = QFMT_VFS_OLD;\n\t\t\tgoto set_qf_format;\n\t\tcase Opt_jqfmt_vfsv0:\n\t\t\tqfmt = QFMT_VFS_V0;\n\t\t\tgoto set_qf_format;\n\t\tcase Opt_jqfmt_vfsv1:\n\t\t\tqfmt = QFMT_VFS_V1;\nset_qf_format:\n\t\t\tif (sb_any_quota_loaded(sb) &&\n\t\t\t    sbi->s_jquota_fmt != qfmt) {\n\t\t\t\text4_msg(sb, KERN_ERR, \"Cannot change \"\n\t\t\t\t\t\"journaled quota options when \"\n\t\t\t\t\t\"quota turned on\");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tsbi->s_jquota_fmt = qfmt;\n\t\t\tbreak;\n\t\tcase Opt_quota:\n\t\tcase Opt_usrquota:\n\t\t\tset_opt(sb, QUOTA);\n\t\t\tset_opt(sb, USRQUOTA);\n\t\t\tbreak;\n\t\tcase Opt_grpquota:\n\t\t\tset_opt(sb, QUOTA);\n\t\t\tset_opt(sb, GRPQUOTA);\n\t\t\tbreak;\n\t\tcase Opt_noquota:\n\t\t\tif (sb_any_quota_loaded(sb)) {\n\t\t\t\text4_msg(sb, KERN_ERR, \"Cannot change quota \"\n\t\t\t\t\t\"options when quota turned on\");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tclear_opt(sb, QUOTA);\n\t\t\tclear_opt(sb, USRQUOTA);\n\t\t\tclear_opt(sb, GRPQUOTA);\n\t\t\tbreak;\n#else\n\t\tcase Opt_quota:\n\t\tcase Opt_usrquota:\n\t\tcase Opt_grpquota:\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\"quota options not supported\");\n\t\t\tbreak;\n\t\tcase Opt_usrjquota:\n\t\tcase Opt_grpjquota:\n\t\tcase Opt_offusrjquota:\n\t\tcase Opt_offgrpjquota:\n\t\tcase Opt_jqfmt_vfsold:\n\t\tcase Opt_jqfmt_vfsv0:\n\t\tcase Opt_jqfmt_vfsv1:\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\"journaled quota options not supported\");\n\t\t\tbreak;\n\t\tcase Opt_noquota:\n\t\t\tbreak;\n#endif\n\t\tcase Opt_abort:\n\t\t\tsbi->s_mount_flags |= EXT4_MF_FS_ABORTED;\n\t\t\tbreak;\n\t\tcase Opt_nobarrier:\n\t\t\tclear_opt(sb, BARRIER);\n\t\t\tbreak;\n\t\tcase Opt_barrier:\n\t\t\tif (args[0].from) {\n\t\t\t\tif (match_int(&args[0], &option))\n\t\t\t\t\treturn 0;\n\t\t\t} else\n\t\t\t\toption = 1;\t/* No argument, default to 1 */\n\t\t\tif (option)\n\t\t\t\tset_opt(sb, BARRIER);\n\t\t\telse\n\t\t\t\tclear_opt(sb, BARRIER);\n\t\t\tbreak;\n\t\tcase Opt_ignore:\n\t\t\tbreak;\n\t\tcase Opt_resize:\n\t\t\tif (!is_remount) {\n\t\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\t\"resize option only available \"\n\t\t\t\t\t\"for remount\");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tif (match_int(&args[0], &option) != 0)\n\t\t\t\treturn 0;\n\t\t\t*n_blocks_count = option;\n\t\t\tbreak;\n\t\tcase Opt_nobh:\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"Ignoring deprecated nobh option\");\n\t\t\tbreak;\n\t\tcase Opt_bh:\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"Ignoring deprecated bh option\");\n\t\t\tbreak;\n\t\tcase Opt_i_version:\n\t\t\tset_opt(sb, I_VERSION);\n\t\t\tsb->s_flags |= MS_I_VERSION;\n\t\t\tbreak;\n\t\tcase Opt_nodelalloc:\n\t\t\tclear_opt(sb, DELALLOC);\n\t\t\tbreak;\n\t\tcase Opt_mblk_io_submit:\n\t\t\tset_opt(sb, MBLK_IO_SUBMIT);\n\t\t\tbreak;\n\t\tcase Opt_nomblk_io_submit:\n\t\t\tclear_opt(sb, MBLK_IO_SUBMIT);\n\t\t\tbreak;\n\t\tcase Opt_stripe:\n\t\t\tif (match_int(&args[0], &option))\n\t\t\t\treturn 0;\n\t\t\tif (option < 0)\n\t\t\t\treturn 0;\n\t\t\tsbi->s_stripe = option;\n\t\t\tbreak;\n\t\tcase Opt_delalloc:\n\t\t\tset_opt(sb, DELALLOC);\n\t\t\tbreak;\n\t\tcase Opt_block_validity:\n\t\t\tset_opt(sb, BLOCK_VALIDITY);\n\t\t\tbreak;\n\t\tcase Opt_noblock_validity:\n\t\t\tclear_opt(sb, BLOCK_VALIDITY);\n\t\t\tbreak;\n\t\tcase Opt_inode_readahead_blks:\n\t\t\tif (match_int(&args[0], &option))\n\t\t\t\treturn 0;\n\t\t\tif (option < 0 || option > (1 << 30))\n\t\t\t\treturn 0;\n\t\t\tif (option && !is_power_of_2(option)) {\n\t\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\t \"EXT4-fs: inode_readahead_blks\"\n\t\t\t\t\t \" must be a power of 2\");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tsbi->s_inode_readahead_blks = option;\n\t\t\tbreak;\n\t\tcase Opt_journal_ioprio:\n\t\t\tif (match_int(&args[0], &option))\n\t\t\t\treturn 0;\n\t\t\tif (option < 0 || option > 7)\n\t\t\t\tbreak;\n\t\t\t*journal_ioprio = IOPRIO_PRIO_VALUE(IOPRIO_CLASS_BE,\n\t\t\t\t\t\t\t    option);\n\t\t\tbreak;\n\t\tcase Opt_noauto_da_alloc:\n\t\t\tset_opt(sb, NO_AUTO_DA_ALLOC);\n\t\t\tbreak;\n\t\tcase Opt_auto_da_alloc:\n\t\t\tif (args[0].from) {\n\t\t\t\tif (match_int(&args[0], &option))\n\t\t\t\t\treturn 0;\n\t\t\t} else\n\t\t\t\toption = 1;\t/* No argument, default to 1 */\n\t\t\tif (option)\n\t\t\t\tclear_opt(sb, NO_AUTO_DA_ALLOC);\n\t\t\telse\n\t\t\t\tset_opt(sb,NO_AUTO_DA_ALLOC);\n\t\t\tbreak;\n\t\tcase Opt_discard:\n\t\t\tset_opt(sb, DISCARD);\n\t\t\tbreak;\n\t\tcase Opt_nodiscard:\n\t\t\tclear_opt(sb, DISCARD);\n\t\t\tbreak;\n\t\tcase Opt_dioread_nolock:\n\t\t\tset_opt(sb, DIOREAD_NOLOCK);\n\t\t\tbreak;\n\t\tcase Opt_dioread_lock:\n\t\t\tclear_opt(sb, DIOREAD_NOLOCK);\n\t\t\tbreak;\n\t\tcase Opt_init_inode_table:\n\t\t\tset_opt(sb, INIT_INODE_TABLE);\n\t\t\tif (args[0].from) {\n\t\t\t\tif (match_int(&args[0], &option))\n\t\t\t\t\treturn 0;\n\t\t\t} else\n\t\t\t\toption = EXT4_DEF_LI_WAIT_MULT;\n\t\t\tif (option < 0)\n\t\t\t\treturn 0;\n\t\t\tsbi->s_li_wait_mult = option;\n\t\t\tbreak;\n\t\tcase Opt_noinit_inode_table:\n\t\t\tclear_opt(sb, INIT_INODE_TABLE);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Unrecognized mount option \\\"%s\\\" \"\n\t\t\t       \"or missing value\", p);\n\t\t\treturn 0;\n\t\t}\n\t}\n#ifdef CONFIG_QUOTA\n\tif (sbi->s_qf_names[USRQUOTA] || sbi->s_qf_names[GRPQUOTA]) {\n\t\tif (test_opt(sb, USRQUOTA) && sbi->s_qf_names[USRQUOTA])\n\t\t\tclear_opt(sb, USRQUOTA);\n\n\t\tif (test_opt(sb, GRPQUOTA) && sbi->s_qf_names[GRPQUOTA])\n\t\t\tclear_opt(sb, GRPQUOTA);\n\n\t\tif (test_opt(sb, GRPQUOTA) || test_opt(sb, USRQUOTA)) {\n\t\t\text4_msg(sb, KERN_ERR, \"old and new quota \"\n\t\t\t\t\t\"format mixing\");\n\t\t\treturn 0;\n\t\t}\n\n\t\tif (!sbi->s_jquota_fmt) {\n\t\t\text4_msg(sb, KERN_ERR, \"journaled quota format \"\n\t\t\t\t\t\"not specified\");\n\t\t\treturn 0;\n\t\t}\n\t} else {\n\t\tif (sbi->s_jquota_fmt) {\n\t\t\text4_msg(sb, KERN_ERR, \"journaled quota format \"\n\t\t\t\t\t\"specified with no journaling \"\n\t\t\t\t\t\"enabled\");\n\t\t\treturn 0;\n\t\t}\n\t}\n#endif\n\treturn 1;\n}\n\nstatic int ext4_setup_super(struct super_block *sb, struct ext4_super_block *es,\n\t\t\t    int read_only)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tint res = 0;\n\n\tif (le32_to_cpu(es->s_rev_level) > EXT4_MAX_SUPP_REV) {\n\t\text4_msg(sb, KERN_ERR, \"revision level too high, \"\n\t\t\t \"forcing read-only mode\");\n\t\tres = MS_RDONLY;\n\t}\n\tif (read_only)\n\t\treturn res;\n\tif (!(sbi->s_mount_state & EXT4_VALID_FS))\n\t\text4_msg(sb, KERN_WARNING, \"warning: mounting unchecked fs, \"\n\t\t\t \"running e2fsck is recommended\");\n\telse if ((sbi->s_mount_state & EXT4_ERROR_FS))\n\t\text4_msg(sb, KERN_WARNING,\n\t\t\t \"warning: mounting fs with errors, \"\n\t\t\t \"running e2fsck is recommended\");\n\telse if ((__s16) le16_to_cpu(es->s_max_mnt_count) >= 0 &&\n\t\t le16_to_cpu(es->s_mnt_count) >=\n\t\t (unsigned short) (__s16) le16_to_cpu(es->s_max_mnt_count))\n\t\text4_msg(sb, KERN_WARNING,\n\t\t\t \"warning: maximal mount count reached, \"\n\t\t\t \"running e2fsck is recommended\");\n\telse if (le32_to_cpu(es->s_checkinterval) &&\n\t\t(le32_to_cpu(es->s_lastcheck) +\n\t\t\tle32_to_cpu(es->s_checkinterval) <= get_seconds()))\n\t\text4_msg(sb, KERN_WARNING,\n\t\t\t \"warning: checktime reached, \"\n\t\t\t \"running e2fsck is recommended\");\n\tif (!sbi->s_journal)\n\t\tes->s_state &= cpu_to_le16(~EXT4_VALID_FS);\n\tif (!(__s16) le16_to_cpu(es->s_max_mnt_count))\n\t\tes->s_max_mnt_count = cpu_to_le16(EXT4_DFL_MAX_MNT_COUNT);\n\tle16_add_cpu(&es->s_mnt_count, 1);\n\tes->s_mtime = cpu_to_le32(get_seconds());\n\text4_update_dynamic_rev(sb);\n\tif (sbi->s_journal)\n\t\tEXT4_SET_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_RECOVER);\n\n\text4_commit_super(sb, 1);\n\tif (test_opt(sb, DEBUG))\n\t\tprintk(KERN_INFO \"[EXT4 FS bs=%lu, gc=%u, \"\n\t\t\t\t\"bpg=%lu, ipg=%lu, mo=%04x, mo2=%04x]\\n\",\n\t\t\tsb->s_blocksize,\n\t\t\tsbi->s_groups_count,\n\t\t\tEXT4_BLOCKS_PER_GROUP(sb),\n\t\t\tEXT4_INODES_PER_GROUP(sb),\n\t\t\tsbi->s_mount_opt, sbi->s_mount_opt2);\n\n\treturn res;\n}\n\nstatic int ext4_fill_flex_info(struct super_block *sb)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_group_desc *gdp = NULL;\n\text4_group_t flex_group_count;\n\text4_group_t flex_group;\n\tint groups_per_flex = 0;\n\tsize_t size;\n\tint i;\n\n\tsbi->s_log_groups_per_flex = sbi->s_es->s_log_groups_per_flex;\n\tgroups_per_flex = 1 << sbi->s_log_groups_per_flex;\n\n\tif (groups_per_flex < 2) {\n\t\tsbi->s_log_groups_per_flex = 0;\n\t\treturn 1;\n\t}\n\n\t/* We allocate both existing and potentially added groups */\n\tflex_group_count = ((sbi->s_groups_count + groups_per_flex - 1) +\n\t\t\t((le16_to_cpu(sbi->s_es->s_reserved_gdt_blocks) + 1) <<\n\t\t\t      EXT4_DESC_PER_BLOCK_BITS(sb))) / groups_per_flex;\n\tsize = flex_group_count * sizeof(struct flex_groups);\n\tsbi->s_flex_groups = kzalloc(size, GFP_KERNEL);\n\tif (sbi->s_flex_groups == NULL) {\n\t\tsbi->s_flex_groups = vzalloc(size);\n\t\tif (sbi->s_flex_groups == NULL) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"not enough memory for %u flex groups\",\n\t\t\t\t flex_group_count);\n\t\t\tgoto failed;\n\t\t}\n\t}\n\n\tfor (i = 0; i < sbi->s_groups_count; i++) {\n\t\tgdp = ext4_get_group_desc(sb, i, NULL);\n\n\t\tflex_group = ext4_flex_group(sbi, i);\n\t\tatomic_add(ext4_free_inodes_count(sb, gdp),\n\t\t\t   &sbi->s_flex_groups[flex_group].free_inodes);\n\t\tatomic_add(ext4_free_blks_count(sb, gdp),\n\t\t\t   &sbi->s_flex_groups[flex_group].free_blocks);\n\t\tatomic_add(ext4_used_dirs_count(sb, gdp),\n\t\t\t   &sbi->s_flex_groups[flex_group].used_dirs);\n\t}\n\n\treturn 1;\nfailed:\n\treturn 0;\n}\n\n__le16 ext4_group_desc_csum(struct ext4_sb_info *sbi, __u32 block_group,\n\t\t\t    struct ext4_group_desc *gdp)\n{\n\t__u16 crc = 0;\n\n\tif (sbi->s_es->s_feature_ro_compat &\n\t    cpu_to_le32(EXT4_FEATURE_RO_COMPAT_GDT_CSUM)) {\n\t\tint offset = offsetof(struct ext4_group_desc, bg_checksum);\n\t\t__le32 le_group = cpu_to_le32(block_group);\n\n\t\tcrc = crc16(~0, sbi->s_es->s_uuid, sizeof(sbi->s_es->s_uuid));\n\t\tcrc = crc16(crc, (__u8 *)&le_group, sizeof(le_group));\n\t\tcrc = crc16(crc, (__u8 *)gdp, offset);\n\t\toffset += sizeof(gdp->bg_checksum); /* skip checksum */\n\t\t/* for checksum of struct ext4_group_desc do the rest...*/\n\t\tif ((sbi->s_es->s_feature_incompat &\n\t\t     cpu_to_le32(EXT4_FEATURE_INCOMPAT_64BIT)) &&\n\t\t    offset < le16_to_cpu(sbi->s_es->s_desc_size))\n\t\t\tcrc = crc16(crc, (__u8 *)gdp + offset,\n\t\t\t\t    le16_to_cpu(sbi->s_es->s_desc_size) -\n\t\t\t\t\toffset);\n\t}\n\n\treturn cpu_to_le16(crc);\n}\n\nint ext4_group_desc_csum_verify(struct ext4_sb_info *sbi, __u32 block_group,\n\t\t\t\tstruct ext4_group_desc *gdp)\n{\n\tif ((sbi->s_es->s_feature_ro_compat &\n\t     cpu_to_le32(EXT4_FEATURE_RO_COMPAT_GDT_CSUM)) &&\n\t    (gdp->bg_checksum != ext4_group_desc_csum(sbi, block_group, gdp)))\n\t\treturn 0;\n\n\treturn 1;\n}\n\n/* Called at mount-time, super-block is locked */\nstatic int ext4_check_descriptors(struct super_block *sb,\n\t\t\t\t  ext4_group_t *first_not_zeroed)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\text4_fsblk_t first_block = le32_to_cpu(sbi->s_es->s_first_data_block);\n\text4_fsblk_t last_block;\n\text4_fsblk_t block_bitmap;\n\text4_fsblk_t inode_bitmap;\n\text4_fsblk_t inode_table;\n\tint flexbg_flag = 0;\n\text4_group_t i, grp = sbi->s_groups_count;\n\n\tif (EXT4_HAS_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_FLEX_BG))\n\t\tflexbg_flag = 1;\n\n\text4_debug(\"Checking group descriptors\");\n\n\tfor (i = 0; i < sbi->s_groups_count; i++) {\n\t\tstruct ext4_group_desc *gdp = ext4_get_group_desc(sb, i, NULL);\n\n\t\tif (i == sbi->s_groups_count - 1 || flexbg_flag)\n\t\t\tlast_block = ext4_blocks_count(sbi->s_es) - 1;\n\t\telse\n\t\t\tlast_block = first_block +\n\t\t\t\t(EXT4_BLOCKS_PER_GROUP(sb) - 1);\n\n\t\tif ((grp == sbi->s_groups_count) &&\n\t\t   !(gdp->bg_flags & cpu_to_le16(EXT4_BG_INODE_ZEROED)))\n\t\t\tgrp = i;\n\n\t\tblock_bitmap = ext4_block_bitmap(sb, gdp);\n\t\tif (block_bitmap < first_block || block_bitmap > last_block) {\n\t\t\text4_msg(sb, KERN_ERR, \"ext4_check_descriptors: \"\n\t\t\t       \"Block bitmap for group %u not in group \"\n\t\t\t       \"(block %llu)!\", i, block_bitmap);\n\t\t\treturn 0;\n\t\t}\n\t\tinode_bitmap = ext4_inode_bitmap(sb, gdp);\n\t\tif (inode_bitmap < first_block || inode_bitmap > last_block) {\n\t\t\text4_msg(sb, KERN_ERR, \"ext4_check_descriptors: \"\n\t\t\t       \"Inode bitmap for group %u not in group \"\n\t\t\t       \"(block %llu)!\", i, inode_bitmap);\n\t\t\treturn 0;\n\t\t}\n\t\tinode_table = ext4_inode_table(sb, gdp);\n\t\tif (inode_table < first_block ||\n\t\t    inode_table + sbi->s_itb_per_group - 1 > last_block) {\n\t\t\text4_msg(sb, KERN_ERR, \"ext4_check_descriptors: \"\n\t\t\t       \"Inode table for group %u not in group \"\n\t\t\t       \"(block %llu)!\", i, inode_table);\n\t\t\treturn 0;\n\t\t}\n\t\text4_lock_group(sb, i);\n\t\tif (!ext4_group_desc_csum_verify(sbi, i, gdp)) {\n\t\t\text4_msg(sb, KERN_ERR, \"ext4_check_descriptors: \"\n\t\t\t\t \"Checksum for group %u failed (%u!=%u)\",\n\t\t\t\t i, le16_to_cpu(ext4_group_desc_csum(sbi, i,\n\t\t\t\t     gdp)), le16_to_cpu(gdp->bg_checksum));\n\t\t\tif (!(sb->s_flags & MS_RDONLY)) {\n\t\t\t\text4_unlock_group(sb, i);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t\text4_unlock_group(sb, i);\n\t\tif (!flexbg_flag)\n\t\t\tfirst_block += EXT4_BLOCKS_PER_GROUP(sb);\n\t}\n\tif (NULL != first_not_zeroed)\n\t\t*first_not_zeroed = grp;\n\n\text4_free_blocks_count_set(sbi->s_es, ext4_count_free_blocks(sb));\n\tsbi->s_es->s_free_inodes_count =cpu_to_le32(ext4_count_free_inodes(sb));\n\treturn 1;\n}\n\n/* ext4_orphan_cleanup() walks a singly-linked list of inodes (starting at\n * the superblock) which were deleted from all directories, but held open by\n * a process at the time of a crash.  We walk the list and try to delete these\n * inodes at recovery time (only with a read-write filesystem).\n *\n * In order to keep the orphan inode chain consistent during traversal (in\n * case of crash during recovery), we link each inode into the superblock\n * orphan list_head and handle it the same way as an inode deletion during\n * normal operation (which journals the operations for us).\n *\n * We only do an iget() and an iput() on each inode, which is very safe if we\n * accidentally point at an in-use or already deleted inode.  The worst that\n * can happen in this case is that we get a \"bit already cleared\" message from\n * ext4_free_inode().  The only reason we would point at a wrong inode is if\n * e2fsck was run on this filesystem, and it must have already done the orphan\n * inode cleanup for us, so we can safely abort without any further action.\n */\nstatic void ext4_orphan_cleanup(struct super_block *sb,\n\t\t\t\tstruct ext4_super_block *es)\n{\n\tunsigned int s_flags = sb->s_flags;\n\tint nr_orphans = 0, nr_truncates = 0;\n#ifdef CONFIG_QUOTA\n\tint i;\n#endif\n\tif (!es->s_last_orphan) {\n\t\tjbd_debug(4, \"no orphan inodes to clean up\\n\");\n\t\treturn;\n\t}\n\n\tif (bdev_read_only(sb->s_bdev)) {\n\t\text4_msg(sb, KERN_ERR, \"write access \"\n\t\t\t\"unavailable, skipping orphan cleanup\");\n\t\treturn;\n\t}\n\n\t/* Check if feature set would not allow a r/w mount */\n\tif (!ext4_feature_set_ok(sb, 0)) {\n\t\text4_msg(sb, KERN_INFO, \"Skipping orphan cleanup due to \"\n\t\t\t \"unknown ROCOMPAT features\");\n\t\treturn;\n\t}\n\n\tif (EXT4_SB(sb)->s_mount_state & EXT4_ERROR_FS) {\n\t\tif (es->s_last_orphan)\n\t\t\tjbd_debug(1, \"Errors on filesystem, \"\n\t\t\t\t  \"clearing orphan list.\\n\");\n\t\tes->s_last_orphan = 0;\n\t\tjbd_debug(1, \"Skipping orphan recovery on fs with errors.\\n\");\n\t\treturn;\n\t}\n\n\tif (s_flags & MS_RDONLY) {\n\t\text4_msg(sb, KERN_INFO, \"orphan cleanup on readonly fs\");\n\t\tsb->s_flags &= ~MS_RDONLY;\n\t}\n#ifdef CONFIG_QUOTA\n\t/* Needed for iput() to work correctly and not trash data */\n\tsb->s_flags |= MS_ACTIVE;\n\t/* Turn on quotas so that they are updated correctly */\n\tfor (i = 0; i < MAXQUOTAS; i++) {\n\t\tif (EXT4_SB(sb)->s_qf_names[i]) {\n\t\t\tint ret = ext4_quota_on_mount(sb, i);\n\t\t\tif (ret < 0)\n\t\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\t\"Cannot turn on journaled \"\n\t\t\t\t\t\"quota: error %d\", ret);\n\t\t}\n\t}\n#endif\n\n\twhile (es->s_last_orphan) {\n\t\tstruct inode *inode;\n\n\t\tinode = ext4_orphan_get(sb, le32_to_cpu(es->s_last_orphan));\n\t\tif (IS_ERR(inode)) {\n\t\t\tes->s_last_orphan = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\tlist_add(&EXT4_I(inode)->i_orphan, &EXT4_SB(sb)->s_orphan);\n\t\tdquot_initialize(inode);\n\t\tif (inode->i_nlink) {\n\t\t\text4_msg(sb, KERN_DEBUG,\n\t\t\t\t\"%s: truncating inode %lu to %lld bytes\",\n\t\t\t\t__func__, inode->i_ino, inode->i_size);\n\t\t\tjbd_debug(2, \"truncating inode %lu to %lld bytes\\n\",\n\t\t\t\t  inode->i_ino, inode->i_size);\n\t\t\text4_truncate(inode);\n\t\t\tnr_truncates++;\n\t\t} else {\n\t\t\text4_msg(sb, KERN_DEBUG,\n\t\t\t\t\"%s: deleting unreferenced inode %lu\",\n\t\t\t\t__func__, inode->i_ino);\n\t\t\tjbd_debug(2, \"deleting unreferenced inode %lu\\n\",\n\t\t\t\t  inode->i_ino);\n\t\t\tnr_orphans++;\n\t\t}\n\t\tiput(inode);  /* The delete magic happens here! */\n\t}\n\n#define PLURAL(x) (x), ((x) == 1) ? \"\" : \"s\"\n\n\tif (nr_orphans)\n\t\text4_msg(sb, KERN_INFO, \"%d orphan inode%s deleted\",\n\t\t       PLURAL(nr_orphans));\n\tif (nr_truncates)\n\t\text4_msg(sb, KERN_INFO, \"%d truncate%s cleaned up\",\n\t\t       PLURAL(nr_truncates));\n#ifdef CONFIG_QUOTA\n\t/* Turn quotas off */\n\tfor (i = 0; i < MAXQUOTAS; i++) {\n\t\tif (sb_dqopt(sb)->files[i])\n\t\t\tdquot_quota_off(sb, i);\n\t}\n#endif\n\tsb->s_flags = s_flags; /* Restore MS_RDONLY status */\n}\n\n/*\n * Maximal extent format file size.\n * Resulting logical blkno at s_maxbytes must fit in our on-disk\n * extent format containers, within a sector_t, and within i_blocks\n * in the vfs.  ext4 inode has 48 bits of i_block in fsblock units,\n * so that won't be a limiting factor.\n *\n * Note, this does *not* consider any metadata overhead for vfs i_blocks.\n */\nstatic loff_t ext4_max_size(int blkbits, int has_huge_files)\n{\n\tloff_t res;\n\tloff_t upper_limit = MAX_LFS_FILESIZE;\n\n\t/* small i_blocks in vfs inode? */\n\tif (!has_huge_files || sizeof(blkcnt_t) < sizeof(u64)) {\n\t\t/*\n\t\t * CONFIG_LBDAF is not enabled implies the inode\n\t\t * i_block represent total blocks in 512 bytes\n\t\t * 32 == size of vfs inode i_blocks * 8\n\t\t */\n\t\tupper_limit = (1LL << 32) - 1;\n\n\t\t/* total blocks in file system block size */\n\t\tupper_limit >>= (blkbits - 9);\n\t\tupper_limit <<= blkbits;\n\t}\n\n\t/* 32-bit extent-start container, ee_block */\n\tres = 1LL << 32;\n\tres <<= blkbits;\n\tres -= 1;\n\n\t/* Sanity check against vm- & vfs- imposed limits */\n\tif (res > upper_limit)\n\t\tres = upper_limit;\n\n\treturn res;\n}\n\n/*\n * Maximal bitmap file size.  There is a direct, and {,double-,triple-}indirect\n * block limit, and also a limit of (2^48 - 1) 512-byte sectors in i_blocks.\n * We need to be 1 filesystem block less than the 2^48 sector limit.\n */\nstatic loff_t ext4_max_bitmap_size(int bits, int has_huge_files)\n{\n\tloff_t res = EXT4_NDIR_BLOCKS;\n\tint meta_blocks;\n\tloff_t upper_limit;\n\t/* This is calculated to be the largest file size for a dense, block\n\t * mapped file such that the file's total number of 512-byte sectors,\n\t * including data and all indirect blocks, does not exceed (2^48 - 1).\n\t *\n\t * __u32 i_blocks_lo and _u16 i_blocks_high represent the total\n\t * number of 512-byte sectors of the file.\n\t */\n\n\tif (!has_huge_files || sizeof(blkcnt_t) < sizeof(u64)) {\n\t\t/*\n\t\t * !has_huge_files or CONFIG_LBDAF not enabled implies that\n\t\t * the inode i_block field represents total file blocks in\n\t\t * 2^32 512-byte sectors == size of vfs inode i_blocks * 8\n\t\t */\n\t\tupper_limit = (1LL << 32) - 1;\n\n\t\t/* total blocks in file system block size */\n\t\tupper_limit >>= (bits - 9);\n\n\t} else {\n\t\t/*\n\t\t * We use 48 bit ext4_inode i_blocks\n\t\t * With EXT4_HUGE_FILE_FL set the i_blocks\n\t\t * represent total number of blocks in\n\t\t * file system block size\n\t\t */\n\t\tupper_limit = (1LL << 48) - 1;\n\n\t}\n\n\t/* indirect blocks */\n\tmeta_blocks = 1;\n\t/* double indirect blocks */\n\tmeta_blocks += 1 + (1LL << (bits-2));\n\t/* tripple indirect blocks */\n\tmeta_blocks += 1 + (1LL << (bits-2)) + (1LL << (2*(bits-2)));\n\n\tupper_limit -= meta_blocks;\n\tupper_limit <<= bits;\n\n\tres += 1LL << (bits-2);\n\tres += 1LL << (2*(bits-2));\n\tres += 1LL << (3*(bits-2));\n\tres <<= bits;\n\tif (res > upper_limit)\n\t\tres = upper_limit;\n\n\tif (res > MAX_LFS_FILESIZE)\n\t\tres = MAX_LFS_FILESIZE;\n\n\treturn res;\n}\n\nstatic ext4_fsblk_t descriptor_loc(struct super_block *sb,\n\t\t\t\t   ext4_fsblk_t logical_sb_block, int nr)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\text4_group_t bg, first_meta_bg;\n\tint has_super = 0;\n\n\tfirst_meta_bg = le32_to_cpu(sbi->s_es->s_first_meta_bg);\n\n\tif (!EXT4_HAS_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_META_BG) ||\n\t    nr < first_meta_bg)\n\t\treturn logical_sb_block + nr + 1;\n\tbg = sbi->s_desc_per_block * nr;\n\tif (ext4_bg_has_super(sb, bg))\n\t\thas_super = 1;\n\n\treturn (has_super + ext4_group_first_block_no(sb, bg));\n}\n\n/**\n * ext4_get_stripe_size: Get the stripe size.\n * @sbi: In memory super block info\n *\n * If we have specified it via mount option, then\n * use the mount option value. If the value specified at mount time is\n * greater than the blocks per group use the super block value.\n * If the super block value is greater than blocks per group return 0.\n * Allocator needs it be less than blocks per group.\n *\n */\nstatic unsigned long ext4_get_stripe_size(struct ext4_sb_info *sbi)\n{\n\tunsigned long stride = le16_to_cpu(sbi->s_es->s_raid_stride);\n\tunsigned long stripe_width =\n\t\t\tle32_to_cpu(sbi->s_es->s_raid_stripe_width);\n\n\tif (sbi->s_stripe && sbi->s_stripe <= sbi->s_blocks_per_group)\n\t\treturn sbi->s_stripe;\n\n\tif (stripe_width <= sbi->s_blocks_per_group)\n\t\treturn stripe_width;\n\n\tif (stride <= sbi->s_blocks_per_group)\n\t\treturn stride;\n\n\treturn 0;\n}\n\n/* sysfs supprt */\n\nstruct ext4_attr {\n\tstruct attribute attr;\n\tssize_t (*show)(struct ext4_attr *, struct ext4_sb_info *, char *);\n\tssize_t (*store)(struct ext4_attr *, struct ext4_sb_info *,\n\t\t\t const char *, size_t);\n\tint offset;\n};\n\nstatic int parse_strtoul(const char *buf,\n\t\tunsigned long max, unsigned long *value)\n{\n\tchar *endp;\n\n\t*value = simple_strtoul(skip_spaces(buf), &endp, 0);\n\tendp = skip_spaces(endp);\n\tif (*endp || *value > max)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic ssize_t delayed_allocation_blocks_show(struct ext4_attr *a,\n\t\t\t\t\t      struct ext4_sb_info *sbi,\n\t\t\t\t\t      char *buf)\n{\n\treturn snprintf(buf, PAGE_SIZE, \"%llu\\n\",\n\t\t\t(s64) percpu_counter_sum(&sbi->s_dirtyblocks_counter));\n}\n\nstatic ssize_t session_write_kbytes_show(struct ext4_attr *a,\n\t\t\t\t\t struct ext4_sb_info *sbi, char *buf)\n{\n\tstruct super_block *sb = sbi->s_buddy_cache->i_sb;\n\n\tif (!sb->s_bdev->bd_part)\n\t\treturn snprintf(buf, PAGE_SIZE, \"0\\n\");\n\treturn snprintf(buf, PAGE_SIZE, \"%lu\\n\",\n\t\t\t(part_stat_read(sb->s_bdev->bd_part, sectors[1]) -\n\t\t\t sbi->s_sectors_written_start) >> 1);\n}\n\nstatic ssize_t lifetime_write_kbytes_show(struct ext4_attr *a,\n\t\t\t\t\t  struct ext4_sb_info *sbi, char *buf)\n{\n\tstruct super_block *sb = sbi->s_buddy_cache->i_sb;\n\n\tif (!sb->s_bdev->bd_part)\n\t\treturn snprintf(buf, PAGE_SIZE, \"0\\n\");\n\treturn snprintf(buf, PAGE_SIZE, \"%llu\\n\",\n\t\t\t(unsigned long long)(sbi->s_kbytes_written +\n\t\t\t((part_stat_read(sb->s_bdev->bd_part, sectors[1]) -\n\t\t\t  EXT4_SB(sb)->s_sectors_written_start) >> 1)));\n}\n\nstatic ssize_t inode_readahead_blks_store(struct ext4_attr *a,\n\t\t\t\t\t  struct ext4_sb_info *sbi,\n\t\t\t\t\t  const char *buf, size_t count)\n{\n\tunsigned long t;\n\n\tif (parse_strtoul(buf, 0x40000000, &t))\n\t\treturn -EINVAL;\n\n\tif (t && !is_power_of_2(t))\n\t\treturn -EINVAL;\n\n\tsbi->s_inode_readahead_blks = t;\n\treturn count;\n}\n\nstatic ssize_t sbi_ui_show(struct ext4_attr *a,\n\t\t\t   struct ext4_sb_info *sbi, char *buf)\n{\n\tunsigned int *ui = (unsigned int *) (((char *) sbi) + a->offset);\n\n\treturn snprintf(buf, PAGE_SIZE, \"%u\\n\", *ui);\n}\n\nstatic ssize_t sbi_ui_store(struct ext4_attr *a,\n\t\t\t    struct ext4_sb_info *sbi,\n\t\t\t    const char *buf, size_t count)\n{\n\tunsigned int *ui = (unsigned int *) (((char *) sbi) + a->offset);\n\tunsigned long t;\n\n\tif (parse_strtoul(buf, 0xffffffff, &t))\n\t\treturn -EINVAL;\n\t*ui = t;\n\treturn count;\n}\n\n#define EXT4_ATTR_OFFSET(_name,_mode,_show,_store,_elname) \\\nstatic struct ext4_attr ext4_attr_##_name = {\t\t\t\\\n\t.attr = {.name = __stringify(_name), .mode = _mode },\t\\\n\t.show\t= _show,\t\t\t\t\t\\\n\t.store\t= _store,\t\t\t\t\t\\\n\t.offset = offsetof(struct ext4_sb_info, _elname),\t\\\n}\n#define EXT4_ATTR(name, mode, show, store) \\\nstatic struct ext4_attr ext4_attr_##name = __ATTR(name, mode, show, store)\n\n#define EXT4_INFO_ATTR(name) EXT4_ATTR(name, 0444, NULL, NULL)\n#define EXT4_RO_ATTR(name) EXT4_ATTR(name, 0444, name##_show, NULL)\n#define EXT4_RW_ATTR(name) EXT4_ATTR(name, 0644, name##_show, name##_store)\n#define EXT4_RW_ATTR_SBI_UI(name, elname)\t\\\n\tEXT4_ATTR_OFFSET(name, 0644, sbi_ui_show, sbi_ui_store, elname)\n#define ATTR_LIST(name) &ext4_attr_##name.attr\n\nEXT4_RO_ATTR(delayed_allocation_blocks);\nEXT4_RO_ATTR(session_write_kbytes);\nEXT4_RO_ATTR(lifetime_write_kbytes);\nEXT4_ATTR_OFFSET(inode_readahead_blks, 0644, sbi_ui_show,\n\t\t inode_readahead_blks_store, s_inode_readahead_blks);\nEXT4_RW_ATTR_SBI_UI(inode_goal, s_inode_goal);\nEXT4_RW_ATTR_SBI_UI(mb_stats, s_mb_stats);\nEXT4_RW_ATTR_SBI_UI(mb_max_to_scan, s_mb_max_to_scan);\nEXT4_RW_ATTR_SBI_UI(mb_min_to_scan, s_mb_min_to_scan);\nEXT4_RW_ATTR_SBI_UI(mb_order2_req, s_mb_order2_reqs);\nEXT4_RW_ATTR_SBI_UI(mb_stream_req, s_mb_stream_request);\nEXT4_RW_ATTR_SBI_UI(mb_group_prealloc, s_mb_group_prealloc);\nEXT4_RW_ATTR_SBI_UI(max_writeback_mb_bump, s_max_writeback_mb_bump);\n\nstatic struct attribute *ext4_attrs[] = {\n\tATTR_LIST(delayed_allocation_blocks),\n\tATTR_LIST(session_write_kbytes),\n\tATTR_LIST(lifetime_write_kbytes),\n\tATTR_LIST(inode_readahead_blks),\n\tATTR_LIST(inode_goal),\n\tATTR_LIST(mb_stats),\n\tATTR_LIST(mb_max_to_scan),\n\tATTR_LIST(mb_min_to_scan),\n\tATTR_LIST(mb_order2_req),\n\tATTR_LIST(mb_stream_req),\n\tATTR_LIST(mb_group_prealloc),\n\tATTR_LIST(max_writeback_mb_bump),\n\tNULL,\n};\n\n/* Features this copy of ext4 supports */\nEXT4_INFO_ATTR(lazy_itable_init);\nEXT4_INFO_ATTR(batched_discard);\n\nstatic struct attribute *ext4_feat_attrs[] = {\n\tATTR_LIST(lazy_itable_init),\n\tATTR_LIST(batched_discard),\n\tNULL,\n};\n\nstatic ssize_t ext4_attr_show(struct kobject *kobj,\n\t\t\t      struct attribute *attr, char *buf)\n{\n\tstruct ext4_sb_info *sbi = container_of(kobj, struct ext4_sb_info,\n\t\t\t\t\t\ts_kobj);\n\tstruct ext4_attr *a = container_of(attr, struct ext4_attr, attr);\n\n\treturn a->show ? a->show(a, sbi, buf) : 0;\n}\n\nstatic ssize_t ext4_attr_store(struct kobject *kobj,\n\t\t\t       struct attribute *attr,\n\t\t\t       const char *buf, size_t len)\n{\n\tstruct ext4_sb_info *sbi = container_of(kobj, struct ext4_sb_info,\n\t\t\t\t\t\ts_kobj);\n\tstruct ext4_attr *a = container_of(attr, struct ext4_attr, attr);\n\n\treturn a->store ? a->store(a, sbi, buf, len) : 0;\n}\n\nstatic void ext4_sb_release(struct kobject *kobj)\n{\n\tstruct ext4_sb_info *sbi = container_of(kobj, struct ext4_sb_info,\n\t\t\t\t\t\ts_kobj);\n\tcomplete(&sbi->s_kobj_unregister);\n}\n\nstatic const struct sysfs_ops ext4_attr_ops = {\n\t.show\t= ext4_attr_show,\n\t.store\t= ext4_attr_store,\n};\n\nstatic struct kobj_type ext4_ktype = {\n\t.default_attrs\t= ext4_attrs,\n\t.sysfs_ops\t= &ext4_attr_ops,\n\t.release\t= ext4_sb_release,\n};\n\nstatic void ext4_feat_release(struct kobject *kobj)\n{\n\tcomplete(&ext4_feat->f_kobj_unregister);\n}\n\nstatic struct kobj_type ext4_feat_ktype = {\n\t.default_attrs\t= ext4_feat_attrs,\n\t.sysfs_ops\t= &ext4_attr_ops,\n\t.release\t= ext4_feat_release,\n};\n\n/*\n * Check whether this filesystem can be mounted based on\n * the features present and the RDONLY/RDWR mount requested.\n * Returns 1 if this filesystem can be mounted as requested,\n * 0 if it cannot be.\n */\nstatic int ext4_feature_set_ok(struct super_block *sb, int readonly)\n{\n\tif (EXT4_HAS_INCOMPAT_FEATURE(sb, ~EXT4_FEATURE_INCOMPAT_SUPP)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t\"Couldn't mount because of \"\n\t\t\t\"unsupported optional features (%x)\",\n\t\t\t(le32_to_cpu(EXT4_SB(sb)->s_es->s_feature_incompat) &\n\t\t\t~EXT4_FEATURE_INCOMPAT_SUPP));\n\t\treturn 0;\n\t}\n\n\tif (readonly)\n\t\treturn 1;\n\n\t/* Check that feature set is OK for a read-write mount */\n\tif (EXT4_HAS_RO_COMPAT_FEATURE(sb, ~EXT4_FEATURE_RO_COMPAT_SUPP)) {\n\t\text4_msg(sb, KERN_ERR, \"couldn't mount RDWR because of \"\n\t\t\t \"unsupported optional features (%x)\",\n\t\t\t (le32_to_cpu(EXT4_SB(sb)->s_es->s_feature_ro_compat) &\n\t\t\t\t~EXT4_FEATURE_RO_COMPAT_SUPP));\n\t\treturn 0;\n\t}\n\t/*\n\t * Large file size enabled file system can only be mounted\n\t * read-write on 32-bit systems if kernel is built with CONFIG_LBDAF\n\t */\n\tif (EXT4_HAS_RO_COMPAT_FEATURE(sb, EXT4_FEATURE_RO_COMPAT_HUGE_FILE)) {\n\t\tif (sizeof(blkcnt_t) < sizeof(u64)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Filesystem with huge files \"\n\t\t\t\t \"cannot be mounted RDWR without \"\n\t\t\t\t \"CONFIG_LBDAF\");\n\t\t\treturn 0;\n\t\t}\n\t}\n\treturn 1;\n}\n\n/*\n * This function is called once a day if we have errors logged\n * on the file system\n */\nstatic void print_daily_error_info(unsigned long arg)\n{\n\tstruct super_block *sb = (struct super_block *) arg;\n\tstruct ext4_sb_info *sbi;\n\tstruct ext4_super_block *es;\n\n\tsbi = EXT4_SB(sb);\n\tes = sbi->s_es;\n\n\tif (es->s_error_count)\n\t\text4_msg(sb, KERN_NOTICE, \"error count: %u\",\n\t\t\t le32_to_cpu(es->s_error_count));\n\tif (es->s_first_error_time) {\n\t\tprintk(KERN_NOTICE \"EXT4-fs (%s): initial error at %u: %.*s:%d\",\n\t\t       sb->s_id, le32_to_cpu(es->s_first_error_time),\n\t\t       (int) sizeof(es->s_first_error_func),\n\t\t       es->s_first_error_func,\n\t\t       le32_to_cpu(es->s_first_error_line));\n\t\tif (es->s_first_error_ino)\n\t\t\tprintk(\": inode %u\",\n\t\t\t       le32_to_cpu(es->s_first_error_ino));\n\t\tif (es->s_first_error_block)\n\t\t\tprintk(\": block %llu\", (unsigned long long)\n\t\t\t       le64_to_cpu(es->s_first_error_block));\n\t\tprintk(\"\\n\");\n\t}\n\tif (es->s_last_error_time) {\n\t\tprintk(KERN_NOTICE \"EXT4-fs (%s): last error at %u: %.*s:%d\",\n\t\t       sb->s_id, le32_to_cpu(es->s_last_error_time),\n\t\t       (int) sizeof(es->s_last_error_func),\n\t\t       es->s_last_error_func,\n\t\t       le32_to_cpu(es->s_last_error_line));\n\t\tif (es->s_last_error_ino)\n\t\t\tprintk(\": inode %u\",\n\t\t\t       le32_to_cpu(es->s_last_error_ino));\n\t\tif (es->s_last_error_block)\n\t\t\tprintk(\": block %llu\", (unsigned long long)\n\t\t\t       le64_to_cpu(es->s_last_error_block));\n\t\tprintk(\"\\n\");\n\t}\n\tmod_timer(&sbi->s_err_report, jiffies + 24*60*60*HZ);  /* Once a day */\n}\n\nstatic void ext4_lazyinode_timeout(unsigned long data)\n{\n\tstruct task_struct *p = (struct task_struct *)data;\n\twake_up_process(p);\n}\n\n/* Find next suitable group and run ext4_init_inode_table */\nstatic int ext4_run_li_request(struct ext4_li_request *elr)\n{\n\tstruct ext4_group_desc *gdp = NULL;\n\text4_group_t group, ngroups;\n\tstruct super_block *sb;\n\tunsigned long timeout = 0;\n\tint ret = 0;\n\n\tsb = elr->lr_super;\n\tngroups = EXT4_SB(sb)->s_groups_count;\n\n\tfor (group = elr->lr_next_group; group < ngroups; group++) {\n\t\tgdp = ext4_get_group_desc(sb, group, NULL);\n\t\tif (!gdp) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!(gdp->bg_flags & cpu_to_le16(EXT4_BG_INODE_ZEROED)))\n\t\t\tbreak;\n\t}\n\n\tif (group == ngroups)\n\t\tret = 1;\n\n\tif (!ret) {\n\t\ttimeout = jiffies;\n\t\tret = ext4_init_inode_table(sb, group,\n\t\t\t\t\t    elr->lr_timeout ? 0 : 1);\n\t\tif (elr->lr_timeout == 0) {\n\t\t\ttimeout = jiffies - timeout;\n\t\t\tif (elr->lr_sbi->s_li_wait_mult)\n\t\t\t\ttimeout *= elr->lr_sbi->s_li_wait_mult;\n\t\t\telse\n\t\t\t\ttimeout *= 20;\n\t\t\telr->lr_timeout = timeout;\n\t\t}\n\t\telr->lr_next_sched = jiffies + elr->lr_timeout;\n\t\telr->lr_next_group = group + 1;\n\t}\n\n\treturn ret;\n}\n\n/*\n * Remove lr_request from the list_request and free the\n * request tructure. Should be called with li_list_mtx held\n */\nstatic void ext4_remove_li_request(struct ext4_li_request *elr)\n{\n\tstruct ext4_sb_info *sbi;\n\n\tif (!elr)\n\t\treturn;\n\n\tsbi = elr->lr_sbi;\n\n\tlist_del(&elr->lr_request);\n\tsbi->s_li_request = NULL;\n\tkfree(elr);\n}\n\nstatic void ext4_unregister_li_request(struct super_block *sb)\n{\n\tstruct ext4_li_request *elr = EXT4_SB(sb)->s_li_request;\n\n\tif (!ext4_li_info)\n\t\treturn;\n\n\tmutex_lock(&ext4_li_info->li_list_mtx);\n\text4_remove_li_request(elr);\n\tmutex_unlock(&ext4_li_info->li_list_mtx);\n}\n\nstatic struct task_struct *ext4_lazyinit_task;\n\n/*\n * This is the function where ext4lazyinit thread lives. It walks\n * through the request list searching for next scheduled filesystem.\n * When such a fs is found, run the lazy initialization request\n * (ext4_rn_li_request) and keep track of the time spend in this\n * function. Based on that time we compute next schedule time of\n * the request. When walking through the list is complete, compute\n * next waking time and put itself into sleep.\n */\nstatic int ext4_lazyinit_thread(void *arg)\n{\n\tstruct ext4_lazy_init *eli = (struct ext4_lazy_init *)arg;\n\tstruct list_head *pos, *n;\n\tstruct ext4_li_request *elr;\n\tunsigned long next_wakeup;\n\tDEFINE_WAIT(wait);\n\n\tBUG_ON(NULL == eli);\n\n\teli->li_timer.data = (unsigned long)current;\n\teli->li_timer.function = ext4_lazyinode_timeout;\n\n\teli->li_task = current;\n\twake_up(&eli->li_wait_task);\n\ncont_thread:\n\twhile (true) {\n\t\tnext_wakeup = MAX_JIFFY_OFFSET;\n\n\t\tmutex_lock(&eli->li_list_mtx);\n\t\tif (list_empty(&eli->li_request_list)) {\n\t\t\tmutex_unlock(&eli->li_list_mtx);\n\t\t\tgoto exit_thread;\n\t\t}\n\n\t\tlist_for_each_safe(pos, n, &eli->li_request_list) {\n\t\t\telr = list_entry(pos, struct ext4_li_request,\n\t\t\t\t\t lr_request);\n\n\t\t\tif (time_after_eq(jiffies, elr->lr_next_sched)) {\n\t\t\t\tif (ext4_run_li_request(elr) != 0) {\n\t\t\t\t\t/* error, remove the lazy_init job */\n\t\t\t\t\text4_remove_li_request(elr);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (time_before(elr->lr_next_sched, next_wakeup))\n\t\t\t\tnext_wakeup = elr->lr_next_sched;\n\t\t}\n\t\tmutex_unlock(&eli->li_list_mtx);\n\n\t\tif (freezing(current))\n\t\t\trefrigerator();\n\n\t\tif ((time_after_eq(jiffies, next_wakeup)) ||\n\t\t    (MAX_JIFFY_OFFSET == next_wakeup)) {\n\t\t\tcond_resched();\n\t\t\tcontinue;\n\t\t}\n\n\t\teli->li_timer.expires = next_wakeup;\n\t\tadd_timer(&eli->li_timer);\n\t\tprepare_to_wait(&eli->li_wait_daemon, &wait,\n\t\t\t\tTASK_INTERRUPTIBLE);\n\t\tif (time_before(jiffies, next_wakeup))\n\t\t\tschedule();\n\t\tfinish_wait(&eli->li_wait_daemon, &wait);\n\t\tif (kthread_should_stop()) {\n\t\t\text4_clear_request_list();\n\t\t\tgoto exit_thread;\n\t\t}\n\t}\n\nexit_thread:\n\t/*\n\t * It looks like the request list is empty, but we need\n\t * to check it under the li_list_mtx lock, to prevent any\n\t * additions into it, and of course we should lock ext4_li_mtx\n\t * to atomically free the list and ext4_li_info, because at\n\t * this point another ext4 filesystem could be registering\n\t * new one.\n\t */\n\tmutex_lock(&ext4_li_mtx);\n\tmutex_lock(&eli->li_list_mtx);\n\tif (!list_empty(&eli->li_request_list)) {\n\t\tmutex_unlock(&eli->li_list_mtx);\n\t\tmutex_unlock(&ext4_li_mtx);\n\t\tgoto cont_thread;\n\t}\n\tmutex_unlock(&eli->li_list_mtx);\n\tdel_timer_sync(&ext4_li_info->li_timer);\n\teli->li_task = NULL;\n\twake_up(&eli->li_wait_task);\n\n\tkfree(ext4_li_info);\n\text4_lazyinit_task = NULL;\n\text4_li_info = NULL;\n\tmutex_unlock(&ext4_li_mtx);\n\n\treturn 0;\n}\n\nstatic void ext4_clear_request_list(void)\n{\n\tstruct list_head *pos, *n;\n\tstruct ext4_li_request *elr;\n\n\tmutex_lock(&ext4_li_info->li_list_mtx);\n\tlist_for_each_safe(pos, n, &ext4_li_info->li_request_list) {\n\t\telr = list_entry(pos, struct ext4_li_request,\n\t\t\t\t lr_request);\n\t\text4_remove_li_request(elr);\n\t}\n\tmutex_unlock(&ext4_li_info->li_list_mtx);\n}\n\nstatic int ext4_run_lazyinit_thread(void)\n{\n\text4_lazyinit_task = kthread_run(ext4_lazyinit_thread,\n\t\t\t\t\t ext4_li_info, \"ext4lazyinit\");\n\tif (IS_ERR(ext4_lazyinit_task)) {\n\t\tint err = PTR_ERR(ext4_lazyinit_task);\n\t\text4_clear_request_list();\n\t\tdel_timer_sync(&ext4_li_info->li_timer);\n\t\tkfree(ext4_li_info);\n\t\text4_li_info = NULL;\n\t\tprintk(KERN_CRIT \"EXT4: error %d creating inode table \"\n\t\t\t\t \"initialization thread\\n\",\n\t\t\t\t err);\n\t\treturn err;\n\t}\n\text4_li_info->li_state |= EXT4_LAZYINIT_RUNNING;\n\n\twait_event(ext4_li_info->li_wait_task, ext4_li_info->li_task != NULL);\n\treturn 0;\n}\n\n/*\n * Check whether it make sense to run itable init. thread or not.\n * If there is at least one uninitialized inode table, return\n * corresponding group number, else the loop goes through all\n * groups and return total number of groups.\n */\nstatic ext4_group_t ext4_has_uninit_itable(struct super_block *sb)\n{\n\text4_group_t group, ngroups = EXT4_SB(sb)->s_groups_count;\n\tstruct ext4_group_desc *gdp = NULL;\n\n\tfor (group = 0; group < ngroups; group++) {\n\t\tgdp = ext4_get_group_desc(sb, group, NULL);\n\t\tif (!gdp)\n\t\t\tcontinue;\n\n\t\tif (!(gdp->bg_flags & cpu_to_le16(EXT4_BG_INODE_ZEROED)))\n\t\t\tbreak;\n\t}\n\n\treturn group;\n}\n\nstatic int ext4_li_info_new(void)\n{\n\tstruct ext4_lazy_init *eli = NULL;\n\n\teli = kzalloc(sizeof(*eli), GFP_KERNEL);\n\tif (!eli)\n\t\treturn -ENOMEM;\n\n\teli->li_task = NULL;\n\tINIT_LIST_HEAD(&eli->li_request_list);\n\tmutex_init(&eli->li_list_mtx);\n\n\tinit_waitqueue_head(&eli->li_wait_daemon);\n\tinit_waitqueue_head(&eli->li_wait_task);\n\tinit_timer(&eli->li_timer);\n\teli->li_state |= EXT4_LAZYINIT_QUIT;\n\n\text4_li_info = eli;\n\n\treturn 0;\n}\n\nstatic struct ext4_li_request *ext4_li_request_new(struct super_block *sb,\n\t\t\t\t\t    ext4_group_t start)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_li_request *elr;\n\tunsigned long rnd;\n\n\telr = kzalloc(sizeof(*elr), GFP_KERNEL);\n\tif (!elr)\n\t\treturn NULL;\n\n\telr->lr_super = sb;\n\telr->lr_sbi = sbi;\n\telr->lr_next_group = start;\n\n\t/*\n\t * Randomize first schedule time of the request to\n\t * spread the inode table initialization requests\n\t * better.\n\t */\n\tget_random_bytes(&rnd, sizeof(rnd));\n\telr->lr_next_sched = jiffies + (unsigned long)rnd %\n\t\t\t     (EXT4_DEF_LI_MAX_START_DELAY * HZ);\n\n\treturn elr;\n}\n\nstatic int ext4_register_li_request(struct super_block *sb,\n\t\t\t\t    ext4_group_t first_not_zeroed)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_li_request *elr;\n\text4_group_t ngroups = EXT4_SB(sb)->s_groups_count;\n\tint ret = 0;\n\n\tif (sbi->s_li_request != NULL)\n\t\treturn 0;\n\n\tif (first_not_zeroed == ngroups ||\n\t    (sb->s_flags & MS_RDONLY) ||\n\t    !test_opt(sb, INIT_INODE_TABLE)) {\n\t\tsbi->s_li_request = NULL;\n\t\treturn 0;\n\t}\n\n\tif (first_not_zeroed == ngroups) {\n\t\tsbi->s_li_request = NULL;\n\t\treturn 0;\n\t}\n\n\telr = ext4_li_request_new(sb, first_not_zeroed);\n\tif (!elr)\n\t\treturn -ENOMEM;\n\n\tmutex_lock(&ext4_li_mtx);\n\n\tif (NULL == ext4_li_info) {\n\t\tret = ext4_li_info_new();\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\n\tmutex_lock(&ext4_li_info->li_list_mtx);\n\tlist_add(&elr->lr_request, &ext4_li_info->li_request_list);\n\tmutex_unlock(&ext4_li_info->li_list_mtx);\n\n\tsbi->s_li_request = elr;\n\t/*\n\t * set elr to NULL here since it has been inserted to\n\t * the request_list and the removal and free of it is\n\t * handled by ext4_clear_request_list from now on.\n\t */\n\telr = NULL;\n\n\tif (!(ext4_li_info->li_state & EXT4_LAZYINIT_RUNNING)) {\n\t\tret = ext4_run_lazyinit_thread();\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\nout:\n\tmutex_unlock(&ext4_li_mtx);\n\tif (ret)\n\t\tkfree(elr);\n\treturn ret;\n}\n\n/*\n * We do not need to lock anything since this is called on\n * module unload.\n */\nstatic void ext4_destroy_lazyinit_thread(void)\n{\n\t/*\n\t * If thread exited earlier\n\t * there's nothing to be done.\n\t */\n\tif (!ext4_li_info || !ext4_lazyinit_task)\n\t\treturn;\n\n\tkthread_stop(ext4_lazyinit_task);\n}\n\nstatic int ext4_fill_super(struct super_block *sb, void *data, int silent)\n\t\t\t\t__releases(kernel_lock)\n\t\t\t\t__acquires(kernel_lock)\n{\n\tchar *orig_data = kstrdup(data, GFP_KERNEL);\n\tstruct buffer_head *bh;\n\tstruct ext4_super_block *es = NULL;\n\tstruct ext4_sb_info *sbi;\n\text4_fsblk_t block;\n\text4_fsblk_t sb_block = get_sb_block(&data);\n\text4_fsblk_t logical_sb_block;\n\tunsigned long offset = 0;\n\tunsigned long journal_devnum = 0;\n\tunsigned long def_mount_opts;\n\tstruct inode *root;\n\tchar *cp;\n\tconst char *descr;\n\tint ret = -ENOMEM;\n\tint blocksize;\n\tunsigned int db_count;\n\tunsigned int i;\n\tint needs_recovery, has_huge_files;\n\t__u64 blocks_count;\n\tint err;\n\tunsigned int journal_ioprio = DEFAULT_JOURNAL_IOPRIO;\n\text4_group_t first_not_zeroed;\n\n\tsbi = kzalloc(sizeof(*sbi), GFP_KERNEL);\n\tif (!sbi)\n\t\tgoto out_free_orig;\n\n\tsbi->s_blockgroup_lock =\n\t\tkzalloc(sizeof(struct blockgroup_lock), GFP_KERNEL);\n\tif (!sbi->s_blockgroup_lock) {\n\t\tkfree(sbi);\n\t\tgoto out_free_orig;\n\t}\n\tsb->s_fs_info = sbi;\n\tsbi->s_mount_opt = 0;\n\tsbi->s_resuid = EXT4_DEF_RESUID;\n\tsbi->s_resgid = EXT4_DEF_RESGID;\n\tsbi->s_inode_readahead_blks = EXT4_DEF_INODE_READAHEAD_BLKS;\n\tsbi->s_sb_block = sb_block;\n\tif (sb->s_bdev->bd_part)\n\t\tsbi->s_sectors_written_start =\n\t\t\tpart_stat_read(sb->s_bdev->bd_part, sectors[1]);\n\n\t/* Cleanup superblock name */\n\tfor (cp = sb->s_id; (cp = strchr(cp, '/'));)\n\t\t*cp = '!';\n\n\tret = -EINVAL;\n\tblocksize = sb_min_blocksize(sb, EXT4_MIN_BLOCK_SIZE);\n\tif (!blocksize) {\n\t\text4_msg(sb, KERN_ERR, \"unable to set blocksize\");\n\t\tgoto out_fail;\n\t}\n\n\t/*\n\t * The ext4 superblock will not be buffer aligned for other than 1kB\n\t * block sizes.  We need to calculate the offset from buffer start.\n\t */\n\tif (blocksize != EXT4_MIN_BLOCK_SIZE) {\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t} else {\n\t\tlogical_sb_block = sb_block;\n\t}\n\n\tif (!(bh = sb_bread(sb, logical_sb_block))) {\n\t\text4_msg(sb, KERN_ERR, \"unable to read superblock\");\n\t\tgoto out_fail;\n\t}\n\t/*\n\t * Note: s_es must be initialized as soon as possible because\n\t *       some ext4 macro-instructions depend on its value\n\t */\n\tes = (struct ext4_super_block *) (((char *)bh->b_data) + offset);\n\tsbi->s_es = es;\n\tsb->s_magic = le16_to_cpu(es->s_magic);\n\tif (sb->s_magic != EXT4_SUPER_MAGIC)\n\t\tgoto cantfind_ext4;\n\tsbi->s_kbytes_written = le64_to_cpu(es->s_kbytes_written);\n\n\t/* Set defaults before we parse the mount options */\n\tdef_mount_opts = le32_to_cpu(es->s_default_mount_opts);\n\tset_opt(sb, INIT_INODE_TABLE);\n\tif (def_mount_opts & EXT4_DEFM_DEBUG)\n\t\tset_opt(sb, DEBUG);\n\tif (def_mount_opts & EXT4_DEFM_BSDGROUPS) {\n\t\text4_msg(sb, KERN_WARNING, deprecated_msg, \"bsdgroups\",\n\t\t\t\"2.6.38\");\n\t\tset_opt(sb, GRPID);\n\t}\n\tif (def_mount_opts & EXT4_DEFM_UID16)\n\t\tset_opt(sb, NO_UID32);\n\t/* xattr user namespace & acls are now defaulted on */\n#ifdef CONFIG_EXT4_FS_XATTR\n\tset_opt(sb, XATTR_USER);\n#endif\n#ifdef CONFIG_EXT4_FS_POSIX_ACL\n\tset_opt(sb, POSIX_ACL);\n#endif\n\tset_opt(sb, MBLK_IO_SUBMIT);\n\tif ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_DATA)\n\t\tset_opt(sb, JOURNAL_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_ORDERED)\n\t\tset_opt(sb, ORDERED_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_WBACK)\n\t\tset_opt(sb, WRITEBACK_DATA);\n\n\tif (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_PANIC)\n\t\tset_opt(sb, ERRORS_PANIC);\n\telse if (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_CONTINUE)\n\t\tset_opt(sb, ERRORS_CONT);\n\telse\n\t\tset_opt(sb, ERRORS_RO);\n\tif (def_mount_opts & EXT4_DEFM_BLOCK_VALIDITY)\n\t\tset_opt(sb, BLOCK_VALIDITY);\n\tif (def_mount_opts & EXT4_DEFM_DISCARD)\n\t\tset_opt(sb, DISCARD);\n\n\tsbi->s_resuid = le16_to_cpu(es->s_def_resuid);\n\tsbi->s_resgid = le16_to_cpu(es->s_def_resgid);\n\tsbi->s_commit_interval = JBD2_DEFAULT_MAX_COMMIT_AGE * HZ;\n\tsbi->s_min_batch_time = EXT4_DEF_MIN_BATCH_TIME;\n\tsbi->s_max_batch_time = EXT4_DEF_MAX_BATCH_TIME;\n\n\tif ((def_mount_opts & EXT4_DEFM_NOBARRIER) == 0)\n\t\tset_opt(sb, BARRIER);\n\n\t/*\n\t * enable delayed allocation by default\n\t * Use -o nodelalloc to turn it off\n\t */\n\tif (!IS_EXT3_SB(sb) &&\n\t    ((def_mount_opts & EXT4_DEFM_NODELALLOC) == 0))\n\t\tset_opt(sb, DELALLOC);\n\n\tif (!parse_options((char *) sbi->s_es->s_mount_opts, sb,\n\t\t\t   &journal_devnum, &journal_ioprio, NULL, 0)) {\n\t\text4_msg(sb, KERN_WARNING,\n\t\t\t \"failed to parse options in superblock: %s\",\n\t\t\t sbi->s_es->s_mount_opts);\n\t}\n\tif (!parse_options((char *) data, sb, &journal_devnum,\n\t\t\t   &journal_ioprio, NULL, 0))\n\t\tgoto failed_mount;\n\n\tsb->s_flags = (sb->s_flags & ~MS_POSIXACL) |\n\t\t(test_opt(sb, POSIX_ACL) ? MS_POSIXACL : 0);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV &&\n\t    (EXT4_HAS_COMPAT_FEATURE(sb, ~0U) ||\n\t     EXT4_HAS_RO_COMPAT_FEATURE(sb, ~0U) ||\n\t     EXT4_HAS_INCOMPAT_FEATURE(sb, ~0U)))\n\t\text4_msg(sb, KERN_WARNING,\n\t\t       \"feature flags set on rev 0 fs, \"\n\t\t       \"running e2fsck is recommended\");\n\n\t/*\n\t * Check feature flags regardless of the revision level, since we\n\t * previously didn't change the revision level when setting the flags,\n\t * so there is a chance incompat flags are set on a rev 0 filesystem.\n\t */\n\tif (!ext4_feature_set_ok(sb, (sb->s_flags & MS_RDONLY)))\n\t\tgoto failed_mount;\n\n\tblocksize = BLOCK_SIZE << le32_to_cpu(es->s_log_block_size);\n\n\tif (blocksize < EXT4_MIN_BLOCK_SIZE ||\n\t    blocksize > EXT4_MAX_BLOCK_SIZE) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t       \"Unsupported filesystem blocksize %d\", blocksize);\n\t\tgoto failed_mount;\n\t}\n\n\tif (sb->s_blocksize != blocksize) {\n\t\t/* Validate the filesystem blocksize */\n\t\tif (!sb_set_blocksize(sb, blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR, \"bad block size %d\",\n\t\t\t\t\tblocksize);\n\t\t\tgoto failed_mount;\n\t\t}\n\n\t\tbrelse(bh);\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t\tbh = sb_bread(sb, logical_sb_block);\n\t\tif (!bh) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Can't read superblock on 2nd try\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tes = (struct ext4_super_block *)(((char *)bh->b_data) + offset);\n\t\tsbi->s_es = es;\n\t\tif (es->s_magic != cpu_to_le16(EXT4_SUPER_MAGIC)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Magic mismatch, very weird!\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\thas_huge_files = EXT4_HAS_RO_COMPAT_FEATURE(sb,\n\t\t\t\tEXT4_FEATURE_RO_COMPAT_HUGE_FILE);\n\tsbi->s_bitmap_maxbytes = ext4_max_bitmap_size(sb->s_blocksize_bits,\n\t\t\t\t\t\t      has_huge_files);\n\tsb->s_maxbytes = ext4_max_size(sb->s_blocksize_bits, has_huge_files);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV) {\n\t\tsbi->s_inode_size = EXT4_GOOD_OLD_INODE_SIZE;\n\t\tsbi->s_first_ino = EXT4_GOOD_OLD_FIRST_INO;\n\t} else {\n\t\tsbi->s_inode_size = le16_to_cpu(es->s_inode_size);\n\t\tsbi->s_first_ino = le32_to_cpu(es->s_first_ino);\n\t\tif ((sbi->s_inode_size < EXT4_GOOD_OLD_INODE_SIZE) ||\n\t\t    (!is_power_of_2(sbi->s_inode_size)) ||\n\t\t    (sbi->s_inode_size > blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported inode size: %d\",\n\t\t\t       sbi->s_inode_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE)\n\t\t\tsb->s_time_gran = 1 << (EXT4_EPOCH_BITS - 2);\n\t}\n\n\tsbi->s_desc_size = le16_to_cpu(es->s_desc_size);\n\tif (EXT4_HAS_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_64BIT)) {\n\t\tif (sbi->s_desc_size < EXT4_MIN_DESC_SIZE_64BIT ||\n\t\t    sbi->s_desc_size > EXT4_MAX_DESC_SIZE ||\n\t\t    !is_power_of_2(sbi->s_desc_size)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported descriptor size %lu\",\n\t\t\t       sbi->s_desc_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t} else\n\t\tsbi->s_desc_size = EXT4_MIN_DESC_SIZE;\n\n\tsbi->s_blocks_per_group = le32_to_cpu(es->s_blocks_per_group);\n\tsbi->s_inodes_per_group = le32_to_cpu(es->s_inodes_per_group);\n\tif (EXT4_INODE_SIZE(sb) == 0 || EXT4_INODES_PER_GROUP(sb) == 0)\n\t\tgoto cantfind_ext4;\n\n\tsbi->s_inodes_per_block = blocksize / EXT4_INODE_SIZE(sb);\n\tif (sbi->s_inodes_per_block == 0)\n\t\tgoto cantfind_ext4;\n\tsbi->s_itb_per_group = sbi->s_inodes_per_group /\n\t\t\t\t\tsbi->s_inodes_per_block;\n\tsbi->s_desc_per_block = blocksize / EXT4_DESC_SIZE(sb);\n\tsbi->s_sbh = bh;\n\tsbi->s_mount_state = le16_to_cpu(es->s_state);\n\tsbi->s_addr_per_block_bits = ilog2(EXT4_ADDR_PER_BLOCK(sb));\n\tsbi->s_desc_per_block_bits = ilog2(EXT4_DESC_PER_BLOCK(sb));\n\n\tfor (i = 0; i < 4; i++)\n\t\tsbi->s_hash_seed[i] = le32_to_cpu(es->s_hash_seed[i]);\n\tsbi->s_def_hash_version = es->s_def_hash_version;\n\ti = le32_to_cpu(es->s_flags);\n\tif (i & EXT2_FLAGS_UNSIGNED_HASH)\n\t\tsbi->s_hash_unsigned = 3;\n\telse if ((i & EXT2_FLAGS_SIGNED_HASH) == 0) {\n#ifdef __CHAR_UNSIGNED__\n\t\tes->s_flags |= cpu_to_le32(EXT2_FLAGS_UNSIGNED_HASH);\n\t\tsbi->s_hash_unsigned = 3;\n#else\n\t\tes->s_flags |= cpu_to_le32(EXT2_FLAGS_SIGNED_HASH);\n#endif\n\t\tsb->s_dirt = 1;\n\t}\n\n\tif (sbi->s_blocks_per_group > blocksize * 8) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t       \"#blocks per group too big: %lu\",\n\t\t       sbi->s_blocks_per_group);\n\t\tgoto failed_mount;\n\t}\n\tif (sbi->s_inodes_per_group > blocksize * 8) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t       \"#inodes per group too big: %lu\",\n\t\t       sbi->s_inodes_per_group);\n\t\tgoto failed_mount;\n\t}\n\n\t/*\n\t * Test whether we have more sectors than will fit in sector_t,\n\t * and whether the max offset is addressable by the page cache.\n\t */\n\terr = generic_check_addressable(sb->s_blocksize_bits,\n\t\t\t\t\text4_blocks_count(es));\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"filesystem\"\n\t\t\t \" too large to mount safely on this system\");\n\t\tif (sizeof(sector_t) < 8)\n\t\t\text4_msg(sb, KERN_WARNING, \"CONFIG_LBDAF not enabled\");\n\t\tret = err;\n\t\tgoto failed_mount;\n\t}\n\n\tif (EXT4_BLOCKS_PER_GROUP(sb) == 0)\n\t\tgoto cantfind_ext4;\n\n\t/* check blocks count against device size */\n\tblocks_count = sb->s_bdev->bd_inode->i_size >> sb->s_blocksize_bits;\n\tif (blocks_count && ext4_blocks_count(es) > blocks_count) {\n\t\text4_msg(sb, KERN_WARNING, \"bad geometry: block count %llu \"\n\t\t       \"exceeds size of device (%llu blocks)\",\n\t\t       ext4_blocks_count(es), blocks_count);\n\t\tgoto failed_mount;\n\t}\n\n\t/*\n\t * It makes no sense for the first data block to be beyond the end\n\t * of the filesystem.\n\t */\n\tif (le32_to_cpu(es->s_first_data_block) >= ext4_blocks_count(es)) {\n                ext4_msg(sb, KERN_WARNING, \"bad geometry: first data\"\n\t\t\t \"block %u is beyond end of filesystem (%llu)\",\n\t\t\t le32_to_cpu(es->s_first_data_block),\n\t\t\t ext4_blocks_count(es));\n\t\tgoto failed_mount;\n\t}\n\tblocks_count = (ext4_blocks_count(es) -\n\t\t\tle32_to_cpu(es->s_first_data_block) +\n\t\t\tEXT4_BLOCKS_PER_GROUP(sb) - 1);\n\tdo_div(blocks_count, EXT4_BLOCKS_PER_GROUP(sb));\n\tif (blocks_count > ((uint64_t)1<<32) - EXT4_DESC_PER_BLOCK(sb)) {\n\t\text4_msg(sb, KERN_WARNING, \"groups count too large: %u \"\n\t\t       \"(block count %llu, first data block %u, \"\n\t\t       \"blocks per group %lu)\", sbi->s_groups_count,\n\t\t       ext4_blocks_count(es),\n\t\t       le32_to_cpu(es->s_first_data_block),\n\t\t       EXT4_BLOCKS_PER_GROUP(sb));\n\t\tgoto failed_mount;\n\t}\n\tsbi->s_groups_count = blocks_count;\n\tsbi->s_blockfile_groups = min_t(ext4_group_t, sbi->s_groups_count,\n\t\t\t(EXT4_MAX_BLOCK_FILE_PHYS / EXT4_BLOCKS_PER_GROUP(sb)));\n\tdb_count = (sbi->s_groups_count + EXT4_DESC_PER_BLOCK(sb) - 1) /\n\t\t   EXT4_DESC_PER_BLOCK(sb);\n\tsbi->s_group_desc = kmalloc(db_count * sizeof(struct buffer_head *),\n\t\t\t\t    GFP_KERNEL);\n\tif (sbi->s_group_desc == NULL) {\n\t\text4_msg(sb, KERN_ERR, \"not enough memory\");\n\t\tgoto failed_mount;\n\t}\n\n#ifdef CONFIG_PROC_FS\n\tif (ext4_proc_root)\n\t\tsbi->s_proc = proc_mkdir(sb->s_id, ext4_proc_root);\n#endif\n\n\tbgl_lock_init(sbi->s_blockgroup_lock);\n\n\tfor (i = 0; i < db_count; i++) {\n\t\tblock = descriptor_loc(sb, logical_sb_block, i);\n\t\tsbi->s_group_desc[i] = sb_bread(sb, block);\n\t\tif (!sbi->s_group_desc[i]) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"can't read group descriptor %d\", i);\n\t\t\tdb_count = i;\n\t\t\tgoto failed_mount2;\n\t\t}\n\t}\n\tif (!ext4_check_descriptors(sb, &first_not_zeroed)) {\n\t\text4_msg(sb, KERN_ERR, \"group descriptors corrupted!\");\n\t\tgoto failed_mount2;\n\t}\n\tif (EXT4_HAS_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_FLEX_BG))\n\t\tif (!ext4_fill_flex_info(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unable to initialize \"\n\t\t\t       \"flex_bg meta info!\");\n\t\t\tgoto failed_mount2;\n\t\t}\n\n\tsbi->s_gdb_count = db_count;\n\tget_random_bytes(&sbi->s_next_generation, sizeof(u32));\n\tspin_lock_init(&sbi->s_next_gen_lock);\n\n\tinit_timer(&sbi->s_err_report);\n\tsbi->s_err_report.function = print_daily_error_info;\n\tsbi->s_err_report.data = (unsigned long) sb;\n\n\terr = percpu_counter_init(&sbi->s_freeblocks_counter,\n\t\t\text4_count_free_blocks(sb));\n\tif (!err) {\n\t\terr = percpu_counter_init(&sbi->s_freeinodes_counter,\n\t\t\t\text4_count_free_inodes(sb));\n\t}\n\tif (!err) {\n\t\terr = percpu_counter_init(&sbi->s_dirs_counter,\n\t\t\t\text4_count_dirs(sb));\n\t}\n\tif (!err) {\n\t\terr = percpu_counter_init(&sbi->s_dirtyblocks_counter, 0);\n\t}\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"insufficient memory\");\n\t\tgoto failed_mount3;\n\t}\n\n\tsbi->s_stripe = ext4_get_stripe_size(sbi);\n\tsbi->s_max_writeback_mb_bump = 128;\n\n\t/*\n\t * set up enough so that it can read an inode\n\t */\n\tif (!test_opt(sb, NOLOAD) &&\n\t    EXT4_HAS_COMPAT_FEATURE(sb, EXT4_FEATURE_COMPAT_HAS_JOURNAL))\n\t\tsb->s_op = &ext4_sops;\n\telse\n\t\tsb->s_op = &ext4_nojournal_sops;\n\tsb->s_export_op = &ext4_export_ops;\n\tsb->s_xattr = ext4_xattr_handlers;\n#ifdef CONFIG_QUOTA\n\tsb->s_qcop = &ext4_qctl_operations;\n\tsb->dq_op = &ext4_quota_operations;\n#endif\n\tmemcpy(sb->s_uuid, es->s_uuid, sizeof(es->s_uuid));\n\n\tINIT_LIST_HEAD(&sbi->s_orphan); /* unlinked but open files */\n\tmutex_init(&sbi->s_orphan_lock);\n\tmutex_init(&sbi->s_resize_lock);\n\n\tsb->s_root = NULL;\n\n\tneeds_recovery = (es->s_last_orphan != 0 ||\n\t\t\t  EXT4_HAS_INCOMPAT_FEATURE(sb,\n\t\t\t\t    EXT4_FEATURE_INCOMPAT_RECOVER));\n\n\t/*\n\t * The first inode we look at is the journal inode.  Don't try\n\t * root first: it may be modified in the journal!\n\t */\n\tif (!test_opt(sb, NOLOAD) &&\n\t    EXT4_HAS_COMPAT_FEATURE(sb, EXT4_FEATURE_COMPAT_HAS_JOURNAL)) {\n\t\tif (ext4_load_journal(sb, es, journal_devnum))\n\t\t\tgoto failed_mount3;\n\t} else if (test_opt(sb, NOLOAD) && !(sb->s_flags & MS_RDONLY) &&\n\t      EXT4_HAS_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_RECOVER)) {\n\t\text4_msg(sb, KERN_ERR, \"required journal recovery \"\n\t\t       \"suppressed and not mounted read-only\");\n\t\tgoto failed_mount_wq;\n\t} else {\n\t\tclear_opt(sb, DATA_FLAGS);\n\t\tset_opt(sb, WRITEBACK_DATA);\n\t\tsbi->s_journal = NULL;\n\t\tneeds_recovery = 0;\n\t\tgoto no_journal;\n\t}\n\n\tif (ext4_blocks_count(es) > 0xffffffffULL &&\n\t    !jbd2_journal_set_features(EXT4_SB(sb)->s_journal, 0, 0,\n\t\t\t\t       JBD2_FEATURE_INCOMPAT_64BIT)) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to set 64-bit journal feature\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif (test_opt(sb, JOURNAL_ASYNC_COMMIT)) {\n\t\tjbd2_journal_set_features(sbi->s_journal,\n\t\t\t\tJBD2_FEATURE_COMPAT_CHECKSUM, 0,\n\t\t\t\tJBD2_FEATURE_INCOMPAT_ASYNC_COMMIT);\n\t} else if (test_opt(sb, JOURNAL_CHECKSUM)) {\n\t\tjbd2_journal_set_features(sbi->s_journal,\n\t\t\t\tJBD2_FEATURE_COMPAT_CHECKSUM, 0, 0);\n\t\tjbd2_journal_clear_features(sbi->s_journal, 0, 0,\n\t\t\t\tJBD2_FEATURE_INCOMPAT_ASYNC_COMMIT);\n\t} else {\n\t\tjbd2_journal_clear_features(sbi->s_journal,\n\t\t\t\tJBD2_FEATURE_COMPAT_CHECKSUM, 0,\n\t\t\t\tJBD2_FEATURE_INCOMPAT_ASYNC_COMMIT);\n\t}\n\n\t/* We have now updated the journal if required, so we can\n\t * validate the data journaling mode. */\n\tswitch (test_opt(sb, DATA_FLAGS)) {\n\tcase 0:\n\t\t/* No mode set, assume a default based on the journal\n\t\t * capabilities: ORDERED_DATA if the journal can\n\t\t * cope, else JOURNAL_DATA\n\t\t */\n\t\tif (jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE))\n\t\t\tset_opt(sb, ORDERED_DATA);\n\t\telse\n\t\t\tset_opt(sb, JOURNAL_DATA);\n\t\tbreak;\n\n\tcase EXT4_MOUNT_ORDERED_DATA:\n\tcase EXT4_MOUNT_WRITEBACK_DATA:\n\t\tif (!jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Journal does not support \"\n\t\t\t       \"requested data journaling mode\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\tdefault:\n\t\tbreak;\n\t}\n\tset_task_ioprio(sbi->s_journal->j_task, journal_ioprio);\n\n\t/*\n\t * The journal may have updated the bg summary counts, so we\n\t * need to update the global counters.\n\t */\n\tpercpu_counter_set(&sbi->s_freeblocks_counter,\n\t\t\t   ext4_count_free_blocks(sb));\n\tpercpu_counter_set(&sbi->s_freeinodes_counter,\n\t\t\t   ext4_count_free_inodes(sb));\n\tpercpu_counter_set(&sbi->s_dirs_counter,\n\t\t\t   ext4_count_dirs(sb));\n\tpercpu_counter_set(&sbi->s_dirtyblocks_counter, 0);\n\nno_journal:\n\t/*\n\t * The maximum number of concurrent works can be high and\n\t * concurrency isn't really necessary.  Limit it to 1.\n\t */\n\tEXT4_SB(sb)->dio_unwritten_wq =\n\t\talloc_workqueue(\"ext4-dio-unwritten\", WQ_MEM_RECLAIM | WQ_UNBOUND, 1);\n\tif (!EXT4_SB(sb)->dio_unwritten_wq) {\n\t\tprintk(KERN_ERR \"EXT4-fs: failed to create DIO workqueue\\n\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\t/*\n\t * The jbd2_journal_load will have done any necessary log recovery,\n\t * so we can safely mount the rest of the filesystem now.\n\t */\n\n\troot = ext4_iget(sb, EXT4_ROOT_INO);\n\tif (IS_ERR(root)) {\n\t\text4_msg(sb, KERN_ERR, \"get root inode failed\");\n\t\tret = PTR_ERR(root);\n\t\troot = NULL;\n\t\tgoto failed_mount4;\n\t}\n\tif (!S_ISDIR(root->i_mode) || !root->i_blocks || !root->i_size) {\n\t\text4_msg(sb, KERN_ERR, \"corrupt root inode, run e2fsck\");\n\t\tgoto failed_mount4;\n\t}\n\tsb->s_root = d_alloc_root(root);\n\tif (!sb->s_root) {\n\t\text4_msg(sb, KERN_ERR, \"get root dentry failed\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount4;\n\t}\n\n\text4_setup_super(sb, es, sb->s_flags & MS_RDONLY);\n\n\t/* determine the minimum size of new large inodes, if present */\n\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t     EXT4_GOOD_OLD_INODE_SIZE;\n\t\tif (EXT4_HAS_RO_COMPAT_FEATURE(sb,\n\t\t\t\t       EXT4_FEATURE_RO_COMPAT_EXTRA_ISIZE)) {\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_want_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_want_extra_isize);\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_min_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_min_extra_isize);\n\t\t}\n\t}\n\t/* Check if enough inode space is available */\n\tif (EXT4_GOOD_OLD_INODE_SIZE + sbi->s_want_extra_isize >\n\t\t\t\t\t\t\tsbi->s_inode_size) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t       EXT4_GOOD_OLD_INODE_SIZE;\n\t\text4_msg(sb, KERN_INFO, \"required extra inode space not\"\n\t\t\t \"available\");\n\t}\n\n\tif (test_opt(sb, DELALLOC) &&\n\t    (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA)) {\n\t\text4_msg(sb, KERN_WARNING, \"Ignoring delalloc option - \"\n\t\t\t \"requested data journaling mode\");\n\t\tclear_opt(sb, DELALLOC);\n\t}\n\tif (test_opt(sb, DIOREAD_NOLOCK)) {\n\t\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA) {\n\t\t\text4_msg(sb, KERN_WARNING, \"Ignoring dioread_nolock \"\n\t\t\t\t\"option - requested data journaling mode\");\n\t\t\tclear_opt(sb, DIOREAD_NOLOCK);\n\t\t}\n\t\tif (sb->s_blocksize < PAGE_SIZE) {\n\t\t\text4_msg(sb, KERN_WARNING, \"Ignoring dioread_nolock \"\n\t\t\t\t\"option - block size is too small\");\n\t\t\tclear_opt(sb, DIOREAD_NOLOCK);\n\t\t}\n\t}\n\n\terr = ext4_setup_system_zone(sb);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize system \"\n\t\t\t \"zone (%d)\", err);\n\t\tgoto failed_mount4;\n\t}\n\n\text4_ext_init(sb);\n\terr = ext4_mb_init(sb, needs_recovery);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize mballoc (%d)\",\n\t\t\t err);\n\t\tgoto failed_mount4;\n\t}\n\n\terr = ext4_register_li_request(sb, first_not_zeroed);\n\tif (err)\n\t\tgoto failed_mount4;\n\n\tsbi->s_kobj.kset = ext4_kset;\n\tinit_completion(&sbi->s_kobj_unregister);\n\terr = kobject_init_and_add(&sbi->s_kobj, &ext4_ktype, NULL,\n\t\t\t\t   \"%s\", sb->s_id);\n\tif (err) {\n\t\text4_mb_release(sb);\n\t\text4_ext_release(sb);\n\t\tgoto failed_mount4;\n\t};\n\n\tEXT4_SB(sb)->s_mount_state |= EXT4_ORPHAN_FS;\n\text4_orphan_cleanup(sb, es);\n\tEXT4_SB(sb)->s_mount_state &= ~EXT4_ORPHAN_FS;\n\tif (needs_recovery) {\n\t\text4_msg(sb, KERN_INFO, \"recovery complete\");\n\t\text4_mark_recovery_complete(sb, es);\n\t}\n\tif (EXT4_SB(sb)->s_journal) {\n\t\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA)\n\t\t\tdescr = \" journalled data mode\";\n\t\telse if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA)\n\t\t\tdescr = \" ordered data mode\";\n\t\telse\n\t\t\tdescr = \" writeback data mode\";\n\t} else\n\t\tdescr = \"out journal\";\n\n\text4_msg(sb, KERN_INFO, \"mounted filesystem with%s. \"\n\t\t \"Opts: %s%s%s\", descr, sbi->s_es->s_mount_opts,\n\t\t *sbi->s_es->s_mount_opts ? \"; \" : \"\", orig_data);\n\n\tif (es->s_error_count)\n\t\tmod_timer(&sbi->s_err_report, jiffies + 300*HZ); /* 5 minutes */\n\n\tkfree(orig_data);\n\treturn 0;\n\ncantfind_ext4:\n\tif (!silent)\n\t\text4_msg(sb, KERN_ERR, \"VFS: Can't find ext4 filesystem\");\n\tgoto failed_mount;\n\nfailed_mount4:\n\tiput(root);\n\tsb->s_root = NULL;\n\text4_msg(sb, KERN_ERR, \"mount failed\");\n\tdestroy_workqueue(EXT4_SB(sb)->dio_unwritten_wq);\nfailed_mount_wq:\n\text4_release_system_zone(sb);\n\tif (sbi->s_journal) {\n\t\tjbd2_journal_destroy(sbi->s_journal);\n\t\tsbi->s_journal = NULL;\n\t}\nfailed_mount3:\n\tdel_timer(&sbi->s_err_report);\n\tif (sbi->s_flex_groups) {\n\t\tif (is_vmalloc_addr(sbi->s_flex_groups))\n\t\t\tvfree(sbi->s_flex_groups);\n\t\telse\n\t\t\tkfree(sbi->s_flex_groups);\n\t}\n\tpercpu_counter_destroy(&sbi->s_freeblocks_counter);\n\tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n\tpercpu_counter_destroy(&sbi->s_dirs_counter);\n\tpercpu_counter_destroy(&sbi->s_dirtyblocks_counter);\nfailed_mount2:\n\tfor (i = 0; i < db_count; i++)\n\t\tbrelse(sbi->s_group_desc[i]);\n\tkfree(sbi->s_group_desc);\nfailed_mount:\n\tif (sbi->s_proc) {\n\t\tremove_proc_entry(sb->s_id, ext4_proc_root);\n\t}\n#ifdef CONFIG_QUOTA\n\tfor (i = 0; i < MAXQUOTAS; i++)\n\t\tkfree(sbi->s_qf_names[i]);\n#endif\n\text4_blkdev_remove(sbi);\n\tbrelse(bh);\nout_fail:\n\tsb->s_fs_info = NULL;\n\tkfree(sbi->s_blockgroup_lock);\n\tkfree(sbi);\nout_free_orig:\n\tkfree(orig_data);\n\treturn ret;\n}\n\n/*\n * Setup any per-fs journal parameters now.  We'll do this both on\n * initial mount, once the journal has been initialised but before we've\n * done any recovery; and again on any subsequent remount.\n */\nstatic void ext4_init_journal_params(struct super_block *sb, journal_t *journal)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\tjournal->j_commit_interval = sbi->s_commit_interval;\n\tjournal->j_min_batch_time = sbi->s_min_batch_time;\n\tjournal->j_max_batch_time = sbi->s_max_batch_time;\n\n\twrite_lock(&journal->j_state_lock);\n\tif (test_opt(sb, BARRIER))\n\t\tjournal->j_flags |= JBD2_BARRIER;\n\telse\n\t\tjournal->j_flags &= ~JBD2_BARRIER;\n\tif (test_opt(sb, DATA_ERR_ABORT))\n\t\tjournal->j_flags |= JBD2_ABORT_ON_SYNCDATA_ERR;\n\telse\n\t\tjournal->j_flags &= ~JBD2_ABORT_ON_SYNCDATA_ERR;\n\twrite_unlock(&journal->j_state_lock);\n}\n\nstatic journal_t *ext4_get_journal(struct super_block *sb,\n\t\t\t\t   unsigned int journal_inum)\n{\n\tstruct inode *journal_inode;\n\tjournal_t *journal;\n\n\tBUG_ON(!EXT4_HAS_COMPAT_FEATURE(sb, EXT4_FEATURE_COMPAT_HAS_JOURNAL));\n\n\t/* First, test for the existence of a valid inode on disk.  Bad\n\t * things happen if we iget() an unused inode, as the subsequent\n\t * iput() will try to delete it. */\n\n\tjournal_inode = ext4_iget(sb, journal_inum);\n\tif (IS_ERR(journal_inode)) {\n\t\text4_msg(sb, KERN_ERR, \"no journal found\");\n\t\treturn NULL;\n\t}\n\tif (!journal_inode->i_nlink) {\n\t\tmake_bad_inode(journal_inode);\n\t\tiput(journal_inode);\n\t\text4_msg(sb, KERN_ERR, \"journal inode is deleted\");\n\t\treturn NULL;\n\t}\n\n\tjbd_debug(2, \"Journal inode found at %p: %lld bytes\\n\",\n\t\t  journal_inode, journal_inode->i_size);\n\tif (!S_ISREG(journal_inode->i_mode)) {\n\t\text4_msg(sb, KERN_ERR, \"invalid journal inode\");\n\t\tiput(journal_inode);\n\t\treturn NULL;\n\t}\n\n\tjournal = jbd2_journal_init_inode(journal_inode);\n\tif (!journal) {\n\t\text4_msg(sb, KERN_ERR, \"Could not load journal inode\");\n\t\tiput(journal_inode);\n\t\treturn NULL;\n\t}\n\tjournal->j_private = sb;\n\text4_init_journal_params(sb, journal);\n\treturn journal;\n}\n\nstatic journal_t *ext4_get_dev_journal(struct super_block *sb,\n\t\t\t\t       dev_t j_dev)\n{\n\tstruct buffer_head *bh;\n\tjournal_t *journal;\n\text4_fsblk_t start;\n\text4_fsblk_t len;\n\tint hblock, blocksize;\n\text4_fsblk_t sb_block;\n\tunsigned long offset;\n\tstruct ext4_super_block *es;\n\tstruct block_device *bdev;\n\n\tBUG_ON(!EXT4_HAS_COMPAT_FEATURE(sb, EXT4_FEATURE_COMPAT_HAS_JOURNAL));\n\n\tbdev = ext4_blkdev_get(j_dev, sb);\n\tif (bdev == NULL)\n\t\treturn NULL;\n\n\tblocksize = sb->s_blocksize;\n\thblock = bdev_logical_block_size(bdev);\n\tif (blocksize < hblock) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t\"blocksize too small for journal device\");\n\t\tgoto out_bdev;\n\t}\n\n\tsb_block = EXT4_MIN_BLOCK_SIZE / blocksize;\n\toffset = EXT4_MIN_BLOCK_SIZE % blocksize;\n\tset_blocksize(bdev, blocksize);\n\tif (!(bh = __bread(bdev, sb_block, blocksize))) {\n\t\text4_msg(sb, KERN_ERR, \"couldn't read superblock of \"\n\t\t       \"external journal\");\n\t\tgoto out_bdev;\n\t}\n\n\tes = (struct ext4_super_block *) (((char *)bh->b_data) + offset);\n\tif ((le16_to_cpu(es->s_magic) != EXT4_SUPER_MAGIC) ||\n\t    !(le32_to_cpu(es->s_feature_incompat) &\n\t      EXT4_FEATURE_INCOMPAT_JOURNAL_DEV)) {\n\t\text4_msg(sb, KERN_ERR, \"external journal has \"\n\t\t\t\t\t\"bad superblock\");\n\t\tbrelse(bh);\n\t\tgoto out_bdev;\n\t}\n\n\tif (memcmp(EXT4_SB(sb)->s_es->s_journal_uuid, es->s_uuid, 16)) {\n\t\text4_msg(sb, KERN_ERR, \"journal UUID does not match\");\n\t\tbrelse(bh);\n\t\tgoto out_bdev;\n\t}\n\n\tlen = ext4_blocks_count(es);\n\tstart = sb_block + 1;\n\tbrelse(bh);\t/* we're done with the superblock */\n\n\tjournal = jbd2_journal_init_dev(bdev, sb->s_bdev,\n\t\t\t\t\tstart, len, blocksize);\n\tif (!journal) {\n\t\text4_msg(sb, KERN_ERR, \"failed to create device journal\");\n\t\tgoto out_bdev;\n\t}\n\tjournal->j_private = sb;\n\tll_rw_block(READ, 1, &journal->j_sb_buffer);\n\twait_on_buffer(journal->j_sb_buffer);\n\tif (!buffer_uptodate(journal->j_sb_buffer)) {\n\t\text4_msg(sb, KERN_ERR, \"I/O error on journal device\");\n\t\tgoto out_journal;\n\t}\n\tif (be32_to_cpu(journal->j_superblock->s_nr_users) != 1) {\n\t\text4_msg(sb, KERN_ERR, \"External journal has more than one \"\n\t\t\t\t\t\"user (unsupported) - %d\",\n\t\t\tbe32_to_cpu(journal->j_superblock->s_nr_users));\n\t\tgoto out_journal;\n\t}\n\tEXT4_SB(sb)->journal_bdev = bdev;\n\text4_init_journal_params(sb, journal);\n\treturn journal;\n\nout_journal:\n\tjbd2_journal_destroy(journal);\nout_bdev:\n\text4_blkdev_put(bdev);\n\treturn NULL;\n}\n\nstatic int ext4_load_journal(struct super_block *sb,\n\t\t\t     struct ext4_super_block *es,\n\t\t\t     unsigned long journal_devnum)\n{\n\tjournal_t *journal;\n\tunsigned int journal_inum = le32_to_cpu(es->s_journal_inum);\n\tdev_t journal_dev;\n\tint err = 0;\n\tint really_read_only;\n\n\tBUG_ON(!EXT4_HAS_COMPAT_FEATURE(sb, EXT4_FEATURE_COMPAT_HAS_JOURNAL));\n\n\tif (journal_devnum &&\n\t    journal_devnum != le32_to_cpu(es->s_journal_dev)) {\n\t\text4_msg(sb, KERN_INFO, \"external journal device major/minor \"\n\t\t\t\"numbers have changed\");\n\t\tjournal_dev = new_decode_dev(journal_devnum);\n\t} else\n\t\tjournal_dev = new_decode_dev(le32_to_cpu(es->s_journal_dev));\n\n\treally_read_only = bdev_read_only(sb->s_bdev);\n\n\t/*\n\t * Are we loading a blank journal or performing recovery after a\n\t * crash?  For recovery, we need to check in advance whether we\n\t * can get read-write access to the device.\n\t */\n\tif (EXT4_HAS_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_RECOVER)) {\n\t\tif (sb->s_flags & MS_RDONLY) {\n\t\t\text4_msg(sb, KERN_INFO, \"INFO: recovery \"\n\t\t\t\t\t\"required on readonly filesystem\");\n\t\t\tif (really_read_only) {\n\t\t\t\text4_msg(sb, KERN_ERR, \"write access \"\n\t\t\t\t\t\"unavailable, cannot proceed\");\n\t\t\t\treturn -EROFS;\n\t\t\t}\n\t\t\text4_msg(sb, KERN_INFO, \"write access will \"\n\t\t\t       \"be enabled during recovery\");\n\t\t}\n\t}\n\n\tif (journal_inum && journal_dev) {\n\t\text4_msg(sb, KERN_ERR, \"filesystem has both journal \"\n\t\t       \"and inode journals!\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (journal_inum) {\n\t\tif (!(journal = ext4_get_journal(sb, journal_inum)))\n\t\t\treturn -EINVAL;\n\t} else {\n\t\tif (!(journal = ext4_get_dev_journal(sb, journal_dev)))\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (!(journal->j_flags & JBD2_BARRIER))\n\t\text4_msg(sb, KERN_INFO, \"barriers disabled\");\n\n\tif (!really_read_only && test_opt(sb, UPDATE_JOURNAL)) {\n\t\terr = jbd2_journal_update_format(journal);\n\t\tif (err)  {\n\t\t\text4_msg(sb, KERN_ERR, \"error updating journal\");\n\t\t\tjbd2_journal_destroy(journal);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\tif (!EXT4_HAS_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_RECOVER))\n\t\terr = jbd2_journal_wipe(journal, !really_read_only);\n\tif (!err) {\n\t\tchar *save = kmalloc(EXT4_S_ERR_LEN, GFP_KERNEL);\n\t\tif (save)\n\t\t\tmemcpy(save, ((char *) es) +\n\t\t\t       EXT4_S_ERR_START, EXT4_S_ERR_LEN);\n\t\terr = jbd2_journal_load(journal);\n\t\tif (save)\n\t\t\tmemcpy(((char *) es) + EXT4_S_ERR_START,\n\t\t\t       save, EXT4_S_ERR_LEN);\n\t\tkfree(save);\n\t}\n\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"error loading journal\");\n\t\tjbd2_journal_destroy(journal);\n\t\treturn err;\n\t}\n\n\tEXT4_SB(sb)->s_journal = journal;\n\text4_clear_journal_err(sb, es);\n\n\tif (!really_read_only && journal_devnum &&\n\t    journal_devnum != le32_to_cpu(es->s_journal_dev)) {\n\t\tes->s_journal_dev = cpu_to_le32(journal_devnum);\n\n\t\t/* Make sure we flush the recovery flag to disk. */\n\t\text4_commit_super(sb, 1);\n\t}\n\n\treturn 0;\n}\n\nstatic int ext4_commit_super(struct super_block *sb, int sync)\n{\n\tstruct ext4_super_block *es = EXT4_SB(sb)->s_es;\n\tstruct buffer_head *sbh = EXT4_SB(sb)->s_sbh;\n\tint error = 0;\n\n\tif (!sbh)\n\t\treturn error;\n\tif (buffer_write_io_error(sbh)) {\n\t\t/*\n\t\t * Oh, dear.  A previous attempt to write the\n\t\t * superblock failed.  This could happen because the\n\t\t * USB device was yanked out.  Or it could happen to\n\t\t * be a transient write error and maybe the block will\n\t\t * be remapped.  Nothing we can do but to retry the\n\t\t * write and hope for the best.\n\t\t */\n\t\text4_msg(sb, KERN_ERR, \"previous I/O error to \"\n\t\t       \"superblock detected\");\n\t\tclear_buffer_write_io_error(sbh);\n\t\tset_buffer_uptodate(sbh);\n\t}\n\t/*\n\t * If the file system is mounted read-only, don't update the\n\t * superblock write time.  This avoids updating the superblock\n\t * write time when we are mounting the root file system\n\t * read/only but we need to replay the journal; at that point,\n\t * for people who are east of GMT and who make their clock\n\t * tick in localtime for Windows bug-for-bug compatibility,\n\t * the clock is set in the future, and this will cause e2fsck\n\t * to complain and force a full file system check.\n\t */\n\tif (!(sb->s_flags & MS_RDONLY))\n\t\tes->s_wtime = cpu_to_le32(get_seconds());\n\tif (sb->s_bdev->bd_part)\n\t\tes->s_kbytes_written =\n\t\t\tcpu_to_le64(EXT4_SB(sb)->s_kbytes_written +\n\t\t\t    ((part_stat_read(sb->s_bdev->bd_part, sectors[1]) -\n\t\t\t      EXT4_SB(sb)->s_sectors_written_start) >> 1));\n\telse\n\t\tes->s_kbytes_written =\n\t\t\tcpu_to_le64(EXT4_SB(sb)->s_kbytes_written);\n\text4_free_blocks_count_set(es, percpu_counter_sum_positive(\n\t\t\t\t\t   &EXT4_SB(sb)->s_freeblocks_counter));\n\tes->s_free_inodes_count =\n\t\tcpu_to_le32(percpu_counter_sum_positive(\n\t\t\t\t&EXT4_SB(sb)->s_freeinodes_counter));\n\tsb->s_dirt = 0;\n\tBUFFER_TRACE(sbh, \"marking dirty\");\n\tmark_buffer_dirty(sbh);\n\tif (sync) {\n\t\terror = sync_dirty_buffer(sbh);\n\t\tif (error)\n\t\t\treturn error;\n\n\t\terror = buffer_write_io_error(sbh);\n\t\tif (error) {\n\t\t\text4_msg(sb, KERN_ERR, \"I/O error while writing \"\n\t\t\t       \"superblock\");\n\t\t\tclear_buffer_write_io_error(sbh);\n\t\t\tset_buffer_uptodate(sbh);\n\t\t}\n\t}\n\treturn error;\n}\n\n/*\n * Have we just finished recovery?  If so, and if we are mounting (or\n * remounting) the filesystem readonly, then we will end up with a\n * consistent fs on disk.  Record that fact.\n */\nstatic void ext4_mark_recovery_complete(struct super_block *sb,\n\t\t\t\t\tstruct ext4_super_block *es)\n{\n\tjournal_t *journal = EXT4_SB(sb)->s_journal;\n\n\tif (!EXT4_HAS_COMPAT_FEATURE(sb, EXT4_FEATURE_COMPAT_HAS_JOURNAL)) {\n\t\tBUG_ON(journal != NULL);\n\t\treturn;\n\t}\n\tjbd2_journal_lock_updates(journal);\n\tif (jbd2_journal_flush(journal) < 0)\n\t\tgoto out;\n\n\tif (EXT4_HAS_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_RECOVER) &&\n\t    sb->s_flags & MS_RDONLY) {\n\t\tEXT4_CLEAR_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_RECOVER);\n\t\text4_commit_super(sb, 1);\n\t}\n\nout:\n\tjbd2_journal_unlock_updates(journal);\n}\n\n/*\n * If we are mounting (or read-write remounting) a filesystem whose journal\n * has recorded an error from a previous lifetime, move that error to the\n * main filesystem now.\n */\nstatic void ext4_clear_journal_err(struct super_block *sb,\n\t\t\t\t   struct ext4_super_block *es)\n{\n\tjournal_t *journal;\n\tint j_errno;\n\tconst char *errstr;\n\n\tBUG_ON(!EXT4_HAS_COMPAT_FEATURE(sb, EXT4_FEATURE_COMPAT_HAS_JOURNAL));\n\n\tjournal = EXT4_SB(sb)->s_journal;\n\n\t/*\n\t * Now check for any error status which may have been recorded in the\n\t * journal by a prior ext4_error() or ext4_abort()\n\t */\n\n\tj_errno = jbd2_journal_errno(journal);\n\tif (j_errno) {\n\t\tchar nbuf[16];\n\n\t\terrstr = ext4_decode_error(sb, j_errno, nbuf);\n\t\text4_warning(sb, \"Filesystem error recorded \"\n\t\t\t     \"from previous mount: %s\", errstr);\n\t\text4_warning(sb, \"Marking fs in need of filesystem check.\");\n\n\t\tEXT4_SB(sb)->s_mount_state |= EXT4_ERROR_FS;\n\t\tes->s_state |= cpu_to_le16(EXT4_ERROR_FS);\n\t\text4_commit_super(sb, 1);\n\n\t\tjbd2_journal_clear_err(journal);\n\t}\n}\n\n/*\n * Force the running and committing transactions to commit,\n * and wait on the commit.\n */\nint ext4_force_commit(struct super_block *sb)\n{\n\tjournal_t *journal;\n\tint ret = 0;\n\n\tif (sb->s_flags & MS_RDONLY)\n\t\treturn 0;\n\n\tjournal = EXT4_SB(sb)->s_journal;\n\tif (journal) {\n\t\tvfs_check_frozen(sb, SB_FREEZE_TRANS);\n\t\tret = ext4_journal_force_commit(journal);\n\t}\n\n\treturn ret;\n}\n\nstatic void ext4_write_super(struct super_block *sb)\n{\n\tlock_super(sb);\n\text4_commit_super(sb, 1);\n\tunlock_super(sb);\n}\n\nstatic int ext4_sync_fs(struct super_block *sb, int wait)\n{\n\tint ret = 0;\n\ttid_t target;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\ttrace_ext4_sync_fs(sb, wait);\n\tflush_workqueue(sbi->dio_unwritten_wq);\n\tif (jbd2_journal_start_commit(sbi->s_journal, &target)) {\n\t\tif (wait)\n\t\t\tjbd2_log_wait_commit(sbi->s_journal, target);\n\t}\n\treturn ret;\n}\n\n/*\n * LVM calls this function before a (read-only) snapshot is created.  This\n * gives us a chance to flush the journal completely and mark the fs clean.\n */\nstatic int ext4_freeze(struct super_block *sb)\n{\n\tint error = 0;\n\tjournal_t *journal;\n\n\tif (sb->s_flags & MS_RDONLY)\n\t\treturn 0;\n\n\tjournal = EXT4_SB(sb)->s_journal;\n\n\t/* Now we set up the journal barrier. */\n\tjbd2_journal_lock_updates(journal);\n\n\t/*\n\t * Don't clear the needs_recovery flag if we failed to flush\n\t * the journal.\n\t */\n\terror = jbd2_journal_flush(journal);\n\tif (error < 0)\n\t\tgoto out;\n\n\t/* Journal blocked and flushed, clear needs_recovery flag. */\n\tEXT4_CLEAR_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_RECOVER);\n\terror = ext4_commit_super(sb, 1);\nout:\n\t/* we rely on s_frozen to stop further updates */\n\tjbd2_journal_unlock_updates(EXT4_SB(sb)->s_journal);\n\treturn error;\n}\n\n/*\n * Called by LVM after the snapshot is done.  We need to reset the RECOVER\n * flag here, even though the filesystem is not technically dirty yet.\n */\nstatic int ext4_unfreeze(struct super_block *sb)\n{\n\tif (sb->s_flags & MS_RDONLY)\n\t\treturn 0;\n\n\tlock_super(sb);\n\t/* Reset the needs_recovery flag before the fs is unlocked. */\n\tEXT4_SET_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_RECOVER);\n\text4_commit_super(sb, 1);\n\tunlock_super(sb);\n\treturn 0;\n}\n\n/*\n * Structure to save mount options for ext4_remount's benefit\n */\nstruct ext4_mount_options {\n\tunsigned long s_mount_opt;\n\tunsigned long s_mount_opt2;\n\tuid_t s_resuid;\n\tgid_t s_resgid;\n\tunsigned long s_commit_interval;\n\tu32 s_min_batch_time, s_max_batch_time;\n#ifdef CONFIG_QUOTA\n\tint s_jquota_fmt;\n\tchar *s_qf_names[MAXQUOTAS];\n#endif\n};\n\nstatic int ext4_remount(struct super_block *sb, int *flags, char *data)\n{\n\tstruct ext4_super_block *es;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\text4_fsblk_t n_blocks_count = 0;\n\tunsigned long old_sb_flags;\n\tstruct ext4_mount_options old_opts;\n\tint enable_quota = 0;\n\text4_group_t g;\n\tunsigned int journal_ioprio = DEFAULT_JOURNAL_IOPRIO;\n\tint err;\n#ifdef CONFIG_QUOTA\n\tint i;\n#endif\n\tchar *orig_data = kstrdup(data, GFP_KERNEL);\n\n\t/* Store the original options */\n\tlock_super(sb);\n\told_sb_flags = sb->s_flags;\n\told_opts.s_mount_opt = sbi->s_mount_opt;\n\told_opts.s_mount_opt2 = sbi->s_mount_opt2;\n\told_opts.s_resuid = sbi->s_resuid;\n\told_opts.s_resgid = sbi->s_resgid;\n\told_opts.s_commit_interval = sbi->s_commit_interval;\n\told_opts.s_min_batch_time = sbi->s_min_batch_time;\n\told_opts.s_max_batch_time = sbi->s_max_batch_time;\n#ifdef CONFIG_QUOTA\n\told_opts.s_jquota_fmt = sbi->s_jquota_fmt;\n\tfor (i = 0; i < MAXQUOTAS; i++)\n\t\told_opts.s_qf_names[i] = sbi->s_qf_names[i];\n#endif\n\tif (sbi->s_journal && sbi->s_journal->j_task->io_context)\n\t\tjournal_ioprio = sbi->s_journal->j_task->io_context->ioprio;\n\n\t/*\n\t * Allow the \"check\" option to be passed as a remount option.\n\t */\n\tif (!parse_options(data, sb, NULL, &journal_ioprio,\n\t\t\t   &n_blocks_count, 1)) {\n\t\terr = -EINVAL;\n\t\tgoto restore_opts;\n\t}\n\n\tif (sbi->s_mount_flags & EXT4_MF_FS_ABORTED)\n\t\text4_abort(sb, \"Abort forced by user\");\n\n\tsb->s_flags = (sb->s_flags & ~MS_POSIXACL) |\n\t\t(test_opt(sb, POSIX_ACL) ? MS_POSIXACL : 0);\n\n\tes = sbi->s_es;\n\n\tif (sbi->s_journal) {\n\t\text4_init_journal_params(sb, sbi->s_journal);\n\t\tset_task_ioprio(sbi->s_journal->j_task, journal_ioprio);\n\t}\n\n\tif ((*flags & MS_RDONLY) != (sb->s_flags & MS_RDONLY) ||\n\t\tn_blocks_count > ext4_blocks_count(es)) {\n\t\tif (sbi->s_mount_flags & EXT4_MF_FS_ABORTED) {\n\t\t\terr = -EROFS;\n\t\t\tgoto restore_opts;\n\t\t}\n\n\t\tif (*flags & MS_RDONLY) {\n\t\t\terr = dquot_suspend(sb, -1);\n\t\t\tif (err < 0)\n\t\t\t\tgoto restore_opts;\n\n\t\t\t/*\n\t\t\t * First of all, the unconditional stuff we have to do\n\t\t\t * to disable replay of the journal when we next remount\n\t\t\t */\n\t\t\tsb->s_flags |= MS_RDONLY;\n\n\t\t\t/*\n\t\t\t * OK, test if we are remounting a valid rw partition\n\t\t\t * readonly, and if so set the rdonly flag and then\n\t\t\t * mark the partition as valid again.\n\t\t\t */\n\t\t\tif (!(es->s_state & cpu_to_le16(EXT4_VALID_FS)) &&\n\t\t\t    (sbi->s_mount_state & EXT4_VALID_FS))\n\t\t\t\tes->s_state = cpu_to_le16(sbi->s_mount_state);\n\n\t\t\tif (sbi->s_journal)\n\t\t\t\text4_mark_recovery_complete(sb, es);\n\t\t} else {\n\t\t\t/* Make sure we can mount this feature set readwrite */\n\t\t\tif (!ext4_feature_set_ok(sb, 0)) {\n\t\t\t\terr = -EROFS;\n\t\t\t\tgoto restore_opts;\n\t\t\t}\n\t\t\t/*\n\t\t\t * Make sure the group descriptor checksums\n\t\t\t * are sane.  If they aren't, refuse to remount r/w.\n\t\t\t */\n\t\t\tfor (g = 0; g < sbi->s_groups_count; g++) {\n\t\t\t\tstruct ext4_group_desc *gdp =\n\t\t\t\t\text4_get_group_desc(sb, g, NULL);\n\n\t\t\t\tif (!ext4_group_desc_csum_verify(sbi, g, gdp)) {\n\t\t\t\t\text4_msg(sb, KERN_ERR,\n\t       \"ext4_remount: Checksum for group %u failed (%u!=%u)\",\n\t\tg, le16_to_cpu(ext4_group_desc_csum(sbi, g, gdp)),\n\t\t\t\t\t       le16_to_cpu(gdp->bg_checksum));\n\t\t\t\t\terr = -EINVAL;\n\t\t\t\t\tgoto restore_opts;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * If we have an unprocessed orphan list hanging\n\t\t\t * around from a previously readonly bdev mount,\n\t\t\t * require a full umount/remount for now.\n\t\t\t */\n\t\t\tif (es->s_last_orphan) {\n\t\t\t\text4_msg(sb, KERN_WARNING, \"Couldn't \"\n\t\t\t\t       \"remount RDWR because of unprocessed \"\n\t\t\t\t       \"orphan inode list.  Please \"\n\t\t\t\t       \"umount/remount instead\");\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto restore_opts;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * Mounting a RDONLY partition read-write, so reread\n\t\t\t * and store the current valid flag.  (It may have\n\t\t\t * been changed by e2fsck since we originally mounted\n\t\t\t * the partition.)\n\t\t\t */\n\t\t\tif (sbi->s_journal)\n\t\t\t\text4_clear_journal_err(sb, es);\n\t\t\tsbi->s_mount_state = le16_to_cpu(es->s_state);\n\t\t\tif ((err = ext4_group_extend(sb, es, n_blocks_count)))\n\t\t\t\tgoto restore_opts;\n\t\t\tif (!ext4_setup_super(sb, es, 0))\n\t\t\t\tsb->s_flags &= ~MS_RDONLY;\n\t\t\tenable_quota = 1;\n\t\t}\n\t}\n\n\t/*\n\t * Reinitialize lazy itable initialization thread based on\n\t * current settings\n\t */\n\tif ((sb->s_flags & MS_RDONLY) || !test_opt(sb, INIT_INODE_TABLE))\n\t\text4_unregister_li_request(sb);\n\telse {\n\t\text4_group_t first_not_zeroed;\n\t\tfirst_not_zeroed = ext4_has_uninit_itable(sb);\n\t\text4_register_li_request(sb, first_not_zeroed);\n\t}\n\n\text4_setup_system_zone(sb);\n\tif (sbi->s_journal == NULL)\n\t\text4_commit_super(sb, 1);\n\n#ifdef CONFIG_QUOTA\n\t/* Release old quota file names */\n\tfor (i = 0; i < MAXQUOTAS; i++)\n\t\tif (old_opts.s_qf_names[i] &&\n\t\t    old_opts.s_qf_names[i] != sbi->s_qf_names[i])\n\t\t\tkfree(old_opts.s_qf_names[i]);\n#endif\n\tunlock_super(sb);\n\tif (enable_quota)\n\t\tdquot_resume(sb, -1);\n\n\text4_msg(sb, KERN_INFO, \"re-mounted. Opts: %s\", orig_data);\n\tkfree(orig_data);\n\treturn 0;\n\nrestore_opts:\n\tsb->s_flags = old_sb_flags;\n\tsbi->s_mount_opt = old_opts.s_mount_opt;\n\tsbi->s_mount_opt2 = old_opts.s_mount_opt2;\n\tsbi->s_resuid = old_opts.s_resuid;\n\tsbi->s_resgid = old_opts.s_resgid;\n\tsbi->s_commit_interval = old_opts.s_commit_interval;\n\tsbi->s_min_batch_time = old_opts.s_min_batch_time;\n\tsbi->s_max_batch_time = old_opts.s_max_batch_time;\n#ifdef CONFIG_QUOTA\n\tsbi->s_jquota_fmt = old_opts.s_jquota_fmt;\n\tfor (i = 0; i < MAXQUOTAS; i++) {\n\t\tif (sbi->s_qf_names[i] &&\n\t\t    old_opts.s_qf_names[i] != sbi->s_qf_names[i])\n\t\t\tkfree(sbi->s_qf_names[i]);\n\t\tsbi->s_qf_names[i] = old_opts.s_qf_names[i];\n\t}\n#endif\n\tunlock_super(sb);\n\tkfree(orig_data);\n\treturn err;\n}\n\nstatic int ext4_statfs(struct dentry *dentry, struct kstatfs *buf)\n{\n\tstruct super_block *sb = dentry->d_sb;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_super_block *es = sbi->s_es;\n\tu64 fsid;\n\n\tif (test_opt(sb, MINIX_DF)) {\n\t\tsbi->s_overhead_last = 0;\n\t} else if (sbi->s_blocks_last != ext4_blocks_count(es)) {\n\t\text4_group_t i, ngroups = ext4_get_groups_count(sb);\n\t\text4_fsblk_t overhead = 0;\n\n\t\t/*\n\t\t * Compute the overhead (FS structures).  This is constant\n\t\t * for a given filesystem unless the number of block groups\n\t\t * changes so we cache the previous value until it does.\n\t\t */\n\n\t\t/*\n\t\t * All of the blocks before first_data_block are\n\t\t * overhead\n\t\t */\n\t\toverhead = le32_to_cpu(es->s_first_data_block);\n\n\t\t/*\n\t\t * Add the overhead attributed to the superblock and\n\t\t * block group descriptors.  If the sparse superblocks\n\t\t * feature is turned on, then not all groups have this.\n\t\t */\n\t\tfor (i = 0; i < ngroups; i++) {\n\t\t\toverhead += ext4_bg_has_super(sb, i) +\n\t\t\t\text4_bg_num_gdb(sb, i);\n\t\t\tcond_resched();\n\t\t}\n\n\t\t/*\n\t\t * Every block group has an inode bitmap, a block\n\t\t * bitmap, and an inode table.\n\t\t */\n\t\toverhead += ngroups * (2 + sbi->s_itb_per_group);\n\t\tsbi->s_overhead_last = overhead;\n\t\tsmp_wmb();\n\t\tsbi->s_blocks_last = ext4_blocks_count(es);\n\t}\n\n\tbuf->f_type = EXT4_SUPER_MAGIC;\n\tbuf->f_bsize = sb->s_blocksize;\n\tbuf->f_blocks = ext4_blocks_count(es) - sbi->s_overhead_last;\n\tbuf->f_bfree = percpu_counter_sum_positive(&sbi->s_freeblocks_counter) -\n\t\t       percpu_counter_sum_positive(&sbi->s_dirtyblocks_counter);\n\tbuf->f_bavail = buf->f_bfree - ext4_r_blocks_count(es);\n\tif (buf->f_bfree < ext4_r_blocks_count(es))\n\t\tbuf->f_bavail = 0;\n\tbuf->f_files = le32_to_cpu(es->s_inodes_count);\n\tbuf->f_ffree = percpu_counter_sum_positive(&sbi->s_freeinodes_counter);\n\tbuf->f_namelen = EXT4_NAME_LEN;\n\tfsid = le64_to_cpup((void *)es->s_uuid) ^\n\t       le64_to_cpup((void *)es->s_uuid + sizeof(u64));\n\tbuf->f_fsid.val[0] = fsid & 0xFFFFFFFFUL;\n\tbuf->f_fsid.val[1] = (fsid >> 32) & 0xFFFFFFFFUL;\n\n\treturn 0;\n}\n\n/* Helper function for writing quotas on sync - we need to start transaction\n * before quota file is locked for write. Otherwise the are possible deadlocks:\n * Process 1                         Process 2\n * ext4_create()                     quota_sync()\n *   jbd2_journal_start()                  write_dquot()\n *   dquot_initialize()                         down(dqio_mutex)\n *     down(dqio_mutex)                    jbd2_journal_start()\n *\n */\n\n#ifdef CONFIG_QUOTA\n\nstatic inline struct inode *dquot_to_inode(struct dquot *dquot)\n{\n\treturn sb_dqopt(dquot->dq_sb)->files[dquot->dq_type];\n}\n\nstatic int ext4_write_dquot(struct dquot *dquot)\n{\n\tint ret, err;\n\thandle_t *handle;\n\tstruct inode *inode;\n\n\tinode = dquot_to_inode(dquot);\n\thandle = ext4_journal_start(inode,\n\t\t\t\t    EXT4_QUOTA_TRANS_BLOCKS(dquot->dq_sb));\n\tif (IS_ERR(handle))\n\t\treturn PTR_ERR(handle);\n\tret = dquot_commit(dquot);\n\terr = ext4_journal_stop(handle);\n\tif (!ret)\n\t\tret = err;\n\treturn ret;\n}\n\nstatic int ext4_acquire_dquot(struct dquot *dquot)\n{\n\tint ret, err;\n\thandle_t *handle;\n\n\thandle = ext4_journal_start(dquot_to_inode(dquot),\n\t\t\t\t    EXT4_QUOTA_INIT_BLOCKS(dquot->dq_sb));\n\tif (IS_ERR(handle))\n\t\treturn PTR_ERR(handle);\n\tret = dquot_acquire(dquot);\n\terr = ext4_journal_stop(handle);\n\tif (!ret)\n\t\tret = err;\n\treturn ret;\n}\n\nstatic int ext4_release_dquot(struct dquot *dquot)\n{\n\tint ret, err;\n\thandle_t *handle;\n\n\thandle = ext4_journal_start(dquot_to_inode(dquot),\n\t\t\t\t    EXT4_QUOTA_DEL_BLOCKS(dquot->dq_sb));\n\tif (IS_ERR(handle)) {\n\t\t/* Release dquot anyway to avoid endless cycle in dqput() */\n\t\tdquot_release(dquot);\n\t\treturn PTR_ERR(handle);\n\t}\n\tret = dquot_release(dquot);\n\terr = ext4_journal_stop(handle);\n\tif (!ret)\n\t\tret = err;\n\treturn ret;\n}\n\nstatic int ext4_mark_dquot_dirty(struct dquot *dquot)\n{\n\t/* Are we journaling quotas? */\n\tif (EXT4_SB(dquot->dq_sb)->s_qf_names[USRQUOTA] ||\n\t    EXT4_SB(dquot->dq_sb)->s_qf_names[GRPQUOTA]) {\n\t\tdquot_mark_dquot_dirty(dquot);\n\t\treturn ext4_write_dquot(dquot);\n\t} else {\n\t\treturn dquot_mark_dquot_dirty(dquot);\n\t}\n}\n\nstatic int ext4_write_info(struct super_block *sb, int type)\n{\n\tint ret, err;\n\thandle_t *handle;\n\n\t/* Data block + inode block */\n\thandle = ext4_journal_start(sb->s_root->d_inode, 2);\n\tif (IS_ERR(handle))\n\t\treturn PTR_ERR(handle);\n\tret = dquot_commit_info(sb, type);\n\terr = ext4_journal_stop(handle);\n\tif (!ret)\n\t\tret = err;\n\treturn ret;\n}\n\n/*\n * Turn on quotas during mount time - we need to find\n * the quota file and such...\n */\nstatic int ext4_quota_on_mount(struct super_block *sb, int type)\n{\n\treturn dquot_quota_on_mount(sb, EXT4_SB(sb)->s_qf_names[type],\n\t\t\t\t\tEXT4_SB(sb)->s_jquota_fmt, type);\n}\n\n/*\n * Standard function to be called on quota_on\n */\nstatic int ext4_quota_on(struct super_block *sb, int type, int format_id,\n\t\t\t struct path *path)\n{\n\tint err;\n\n\tif (!test_opt(sb, QUOTA))\n\t\treturn -EINVAL;\n\n\t/* Quotafile not on the same filesystem? */\n\tif (path->mnt->mnt_sb != sb)\n\t\treturn -EXDEV;\n\t/* Journaling quota? */\n\tif (EXT4_SB(sb)->s_qf_names[type]) {\n\t\t/* Quotafile not in fs root? */\n\t\tif (path->dentry->d_parent != sb->s_root)\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t\"Quota file not on filesystem root. \"\n\t\t\t\t\"Journaled quota will not work\");\n\t}\n\n\t/*\n\t * When we journal data on quota file, we have to flush journal to see\n\t * all updates to the file when we bypass pagecache...\n\t */\n\tif (EXT4_SB(sb)->s_journal &&\n\t    ext4_should_journal_data(path->dentry->d_inode)) {\n\t\t/*\n\t\t * We don't need to lock updates but journal_flush() could\n\t\t * otherwise be livelocked...\n\t\t */\n\t\tjbd2_journal_lock_updates(EXT4_SB(sb)->s_journal);\n\t\terr = jbd2_journal_flush(EXT4_SB(sb)->s_journal);\n\t\tjbd2_journal_unlock_updates(EXT4_SB(sb)->s_journal);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn dquot_quota_on(sb, type, format_id, path);\n}\n\nstatic int ext4_quota_off(struct super_block *sb, int type)\n{\n\tstruct inode *inode = sb_dqopt(sb)->files[type];\n\thandle_t *handle;\n\n\t/* Force all delayed allocation blocks to be allocated.\n\t * Caller already holds s_umount sem */\n\tif (test_opt(sb, DELALLOC))\n\t\tsync_filesystem(sb);\n\n\t/* Update modification times of quota files when userspace can\n\t * start looking at them */\n\thandle = ext4_journal_start(inode, 1);\n\tif (IS_ERR(handle))\n\t\tgoto out;\n\tinode->i_mtime = inode->i_ctime = CURRENT_TIME;\n\text4_mark_inode_dirty(handle, inode);\n\text4_journal_stop(handle);\n\nout:\n\treturn dquot_quota_off(sb, type);\n}\n\n/* Read data from quotafile - avoid pagecache and such because we cannot afford\n * acquiring the locks... As quota files are never truncated and quota code\n * itself serializes the operations (and noone else should touch the files)\n * we don't have to be afraid of races */\nstatic ssize_t ext4_quota_read(struct super_block *sb, int type, char *data,\n\t\t\t       size_t len, loff_t off)\n{\n\tstruct inode *inode = sb_dqopt(sb)->files[type];\n\text4_lblk_t blk = off >> EXT4_BLOCK_SIZE_BITS(sb);\n\tint err = 0;\n\tint offset = off & (sb->s_blocksize - 1);\n\tint tocopy;\n\tsize_t toread;\n\tstruct buffer_head *bh;\n\tloff_t i_size = i_size_read(inode);\n\n\tif (off > i_size)\n\t\treturn 0;\n\tif (off+len > i_size)\n\t\tlen = i_size-off;\n\ttoread = len;\n\twhile (toread > 0) {\n\t\ttocopy = sb->s_blocksize - offset < toread ?\n\t\t\t\tsb->s_blocksize - offset : toread;\n\t\tbh = ext4_bread(NULL, inode, blk, 0, &err);\n\t\tif (err)\n\t\t\treturn err;\n\t\tif (!bh)\t/* A hole? */\n\t\t\tmemset(data, 0, tocopy);\n\t\telse\n\t\t\tmemcpy(data, bh->b_data+offset, tocopy);\n\t\tbrelse(bh);\n\t\toffset = 0;\n\t\ttoread -= tocopy;\n\t\tdata += tocopy;\n\t\tblk++;\n\t}\n\treturn len;\n}\n\n/* Write to quotafile (we know the transaction is already started and has\n * enough credits) */\nstatic ssize_t ext4_quota_write(struct super_block *sb, int type,\n\t\t\t\tconst char *data, size_t len, loff_t off)\n{\n\tstruct inode *inode = sb_dqopt(sb)->files[type];\n\text4_lblk_t blk = off >> EXT4_BLOCK_SIZE_BITS(sb);\n\tint err = 0;\n\tint offset = off & (sb->s_blocksize - 1);\n\tstruct buffer_head *bh;\n\thandle_t *handle = journal_current_handle();\n\n\tif (EXT4_SB(sb)->s_journal && !handle) {\n\t\text4_msg(sb, KERN_WARNING, \"Quota write (off=%llu, len=%llu)\"\n\t\t\t\" cancelled because transaction is not started\",\n\t\t\t(unsigned long long)off, (unsigned long long)len);\n\t\treturn -EIO;\n\t}\n\t/*\n\t * Since we account only one data block in transaction credits,\n\t * then it is impossible to cross a block boundary.\n\t */\n\tif (sb->s_blocksize - offset < len) {\n\t\text4_msg(sb, KERN_WARNING, \"Quota write (off=%llu, len=%llu)\"\n\t\t\t\" cancelled because not block aligned\",\n\t\t\t(unsigned long long)off, (unsigned long long)len);\n\t\treturn -EIO;\n\t}\n\n\tmutex_lock_nested(&inode->i_mutex, I_MUTEX_QUOTA);\n\tbh = ext4_bread(handle, inode, blk, 1, &err);\n\tif (!bh)\n\t\tgoto out;\n\terr = ext4_journal_get_write_access(handle, bh);\n\tif (err) {\n\t\tbrelse(bh);\n\t\tgoto out;\n\t}\n\tlock_buffer(bh);\n\tmemcpy(bh->b_data+offset, data, len);\n\tflush_dcache_page(bh->b_page);\n\tunlock_buffer(bh);\n\terr = ext4_handle_dirty_metadata(handle, NULL, bh);\n\tbrelse(bh);\nout:\n\tif (err) {\n\t\tmutex_unlock(&inode->i_mutex);\n\t\treturn err;\n\t}\n\tif (inode->i_size < off + len) {\n\t\ti_size_write(inode, off + len);\n\t\tEXT4_I(inode)->i_disksize = inode->i_size;\n\t\text4_mark_inode_dirty(handle, inode);\n\t}\n\tmutex_unlock(&inode->i_mutex);\n\treturn len;\n}\n\n#endif\n\nstatic struct dentry *ext4_mount(struct file_system_type *fs_type, int flags,\n\t\t       const char *dev_name, void *data)\n{\n\treturn mount_bdev(fs_type, flags, dev_name, data, ext4_fill_super);\n}\n\n#if !defined(CONFIG_EXT2_FS) && !defined(CONFIG_EXT2_FS_MODULE) && defined(CONFIG_EXT4_USE_FOR_EXT23)\nstatic struct file_system_type ext2_fs_type = {\n\t.owner\t\t= THIS_MODULE,\n\t.name\t\t= \"ext2\",\n\t.mount\t\t= ext4_mount,\n\t.kill_sb\t= kill_block_super,\n\t.fs_flags\t= FS_REQUIRES_DEV,\n};\n\nstatic inline void register_as_ext2(void)\n{\n\tint err = register_filesystem(&ext2_fs_type);\n\tif (err)\n\t\tprintk(KERN_WARNING\n\t\t       \"EXT4-fs: Unable to register as ext2 (%d)\\n\", err);\n}\n\nstatic inline void unregister_as_ext2(void)\n{\n\tunregister_filesystem(&ext2_fs_type);\n}\nMODULE_ALIAS(\"ext2\");\n#else\nstatic inline void register_as_ext2(void) { }\nstatic inline void unregister_as_ext2(void) { }\n#endif\n\n#if !defined(CONFIG_EXT3_FS) && !defined(CONFIG_EXT3_FS_MODULE) && defined(CONFIG_EXT4_USE_FOR_EXT23)\nstatic inline void register_as_ext3(void)\n{\n\tint err = register_filesystem(&ext3_fs_type);\n\tif (err)\n\t\tprintk(KERN_WARNING\n\t\t       \"EXT4-fs: Unable to register as ext3 (%d)\\n\", err);\n}\n\nstatic inline void unregister_as_ext3(void)\n{\n\tunregister_filesystem(&ext3_fs_type);\n}\nMODULE_ALIAS(\"ext3\");\n#else\nstatic inline void register_as_ext3(void) { }\nstatic inline void unregister_as_ext3(void) { }\n#endif\n\nstatic struct file_system_type ext4_fs_type = {\n\t.owner\t\t= THIS_MODULE,\n\t.name\t\t= \"ext4\",\n\t.mount\t\t= ext4_mount,\n\t.kill_sb\t= kill_block_super,\n\t.fs_flags\t= FS_REQUIRES_DEV,\n};\n\nstatic int __init ext4_init_feat_adverts(void)\n{\n\tstruct ext4_features *ef;\n\tint ret = -ENOMEM;\n\n\tef = kzalloc(sizeof(struct ext4_features), GFP_KERNEL);\n\tif (!ef)\n\t\tgoto out;\n\n\tef->f_kobj.kset = ext4_kset;\n\tinit_completion(&ef->f_kobj_unregister);\n\tret = kobject_init_and_add(&ef->f_kobj, &ext4_feat_ktype, NULL,\n\t\t\t\t   \"features\");\n\tif (ret) {\n\t\tkfree(ef);\n\t\tgoto out;\n\t}\n\n\text4_feat = ef;\n\tret = 0;\nout:\n\treturn ret;\n}\n\nstatic void ext4_exit_feat_adverts(void)\n{\n\tkobject_put(&ext4_feat->f_kobj);\n\twait_for_completion(&ext4_feat->f_kobj_unregister);\n\tkfree(ext4_feat);\n}\n\n/* Shared across all ext4 file systems */\nwait_queue_head_t ext4__ioend_wq[EXT4_WQ_HASH_SZ];\nstruct mutex ext4__aio_mutex[EXT4_WQ_HASH_SZ];\n\nstatic int __init ext4_init_fs(void)\n{\n\tint i, err;\n\n\text4_check_flag_values();\n\n\tfor (i = 0; i < EXT4_WQ_HASH_SZ; i++) {\n\t\tmutex_init(&ext4__aio_mutex[i]);\n\t\tinit_waitqueue_head(&ext4__ioend_wq[i]);\n\t}\n\n\terr = ext4_init_pageio();\n\tif (err)\n\t\treturn err;\n\terr = ext4_init_system_zone();\n\tif (err)\n\t\tgoto out7;\n\text4_kset = kset_create_and_add(\"ext4\", NULL, fs_kobj);\n\tif (!ext4_kset)\n\t\tgoto out6;\n\text4_proc_root = proc_mkdir(\"fs/ext4\", NULL);\n\tif (!ext4_proc_root)\n\t\tgoto out5;\n\n\terr = ext4_init_feat_adverts();\n\tif (err)\n\t\tgoto out4;\n\n\terr = ext4_init_mballoc();\n\tif (err)\n\t\tgoto out3;\n\n\terr = ext4_init_xattr();\n\tif (err)\n\t\tgoto out2;\n\terr = init_inodecache();\n\tif (err)\n\t\tgoto out1;\n\tregister_as_ext2();\n\tregister_as_ext3();\n\terr = register_filesystem(&ext4_fs_type);\n\tif (err)\n\t\tgoto out;\n\n\text4_li_info = NULL;\n\tmutex_init(&ext4_li_mtx);\n\treturn 0;\nout:\n\tunregister_as_ext2();\n\tunregister_as_ext3();\n\tdestroy_inodecache();\nout1:\n\text4_exit_xattr();\nout2:\n\text4_exit_mballoc();\nout3:\n\text4_exit_feat_adverts();\nout4:\n\tremove_proc_entry(\"fs/ext4\", NULL);\nout5:\n\tkset_unregister(ext4_kset);\nout6:\n\text4_exit_system_zone();\nout7:\n\text4_exit_pageio();\n\treturn err;\n}\n\nstatic void __exit ext4_exit_fs(void)\n{\n\text4_destroy_lazyinit_thread();\n\tunregister_as_ext2();\n\tunregister_as_ext3();\n\tunregister_filesystem(&ext4_fs_type);\n\tdestroy_inodecache();\n\text4_exit_xattr();\n\text4_exit_mballoc();\n\text4_exit_feat_adverts();\n\tremove_proc_entry(\"fs/ext4\", NULL);\n\tkset_unregister(ext4_kset);\n\text4_exit_system_zone();\n\text4_exit_pageio();\n}\n\nMODULE_AUTHOR(\"Remy Card, Stephen Tweedie, Andrew Morton, Andreas Dilger, Theodore Ts'o and others\");\nMODULE_DESCRIPTION(\"Fourth Extended Filesystem\");\nMODULE_LICENSE(\"GPL\");\nmodule_init(ext4_init_fs)\nmodule_exit(ext4_exit_fs)\n"], "filenames": ["fs/ext4/super.c"], "buggy_code_start_loc": [3393], "buggy_code_end_loc": [3680], "fixing_code_start_loc": [3394], "fixing_code_end_loc": [3683], "type": "NVD-CWE-Other", "message": "The ext4_fill_super function in fs/ext4/super.c in the Linux kernel before 2.6.39 does not properly initialize a certain error-report data structure, which allows local users to cause a denial of service (OOPS) by attempting to mount a crafted ext4 filesystem.", "other": {"cve": {"id": "CVE-2011-2493", "sourceIdentifier": "secalert@redhat.com", "published": "2012-06-13T10:24:54.657", "lastModified": "2023-02-13T01:19:54.173", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "The ext4_fill_super function in fs/ext4/super.c in the Linux kernel before 2.6.39 does not properly initialize a certain error-report data structure, which allows local users to cause a denial of service (OOPS) by attempting to mount a crafted ext4 filesystem."}, {"lang": "es", "value": "La funci\u00f3n ext4_fill_super de fs/ext4/super.c del kernel de Linux en versiones anteriores a la 2.6.39 no inicializa apropiadamente una determinada estructura de datos de error-report. Lo que permite a usuarios locales provocar una denegaci\u00f3n de servicio (OOPS) tratando de montar un sistema de archivos ext4 modificado."}], "metrics": {"cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 2.1}, "baseSeverity": "LOW", "exploitabilityScore": 3.9, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "NVD-CWE-Other"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndIncluding": "2.6.38.8", "matchCriteriaId": "57A0A2B0-3B9F-40C2-8C7A-CD9590B51315"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38:*:*:*:*:*:*:*", "matchCriteriaId": "7462DB6D-E0A6-4DBB-8E21-66B875184FFC"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38:rc1:*:*:*:*:*:*", "matchCriteriaId": "2DDCB342-4F5F-4BF1-9624-882BBC57330D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38:rc2:*:*:*:*:*:*", "matchCriteriaId": "C3AB4113-BF83-4587-8A85-0E4FECEE7D9B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38:rc3:*:*:*:*:*:*", "matchCriteriaId": "4B57F5AD-A697-4090-89B9-81BC12993A1A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38:rc4:*:*:*:*:*:*", "matchCriteriaId": "CA141BCB-A705-4DF5-9EED-746B62C86111"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38:rc5:*:*:*:*:*:*", "matchCriteriaId": "E9ECE134-58A3-4B9D-B9B3-F836C0EDD64C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38:rc6:*:*:*:*:*:*", "matchCriteriaId": "56186720-6B4C-4D71-85C5-7EAC5C5D84A1"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38:rc7:*:*:*:*:*:*", "matchCriteriaId": "9BBB4630-CBED-43B9-B203-BE65BBF011AA"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38:rc8:*:*:*:*:*:*", "matchCriteriaId": "FD375A78-63D7-441A-9FB0-7BC878AB4EDD"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38.1:*:*:*:*:*:*:*", "matchCriteriaId": "A5BEFFDD-02BB-4A05-8372-891DBDB9AC5A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38.2:*:*:*:*:*:*:*", "matchCriteriaId": "766E193D-819C-42EA-8411-AE0013AC15FA"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38.3:*:*:*:*:*:*:*", "matchCriteriaId": "3B39B6AF-6A83-48C2-BED2-79228F8513A6"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38.4:*:*:*:*:*:*:*", "matchCriteriaId": "CD8A68D1-DFE9-4ADB-9FB8-4D69AB4CAFF8"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38.5:*:*:*:*:*:*:*", "matchCriteriaId": "0D6EF951-AF15-4C30-A3A5-3392AA61813C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38.6:*:*:*:*:*:*:*", "matchCriteriaId": "15154FA0-65DC-4855-AC70-3ACF92313F49"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38.7:*:*:*:*:*:*:*", "matchCriteriaId": "F4B3A9F4-A61F-4919-A173-3E459F0C5AF8"}]}]}], "references": [{"url": "http://ftp.osuosl.org/pub/linux/kernel/v2.6/ChangeLog-2.6.39", "source": "secalert@redhat.com"}, {"url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git%3Ba=commit%3Bh=0449641130f5652b344ef6fa39fa019d7e94660a", "source": "secalert@redhat.com"}, {"url": "http://www.openwall.com/lists/oss-security/2011/06/24/4", "source": "secalert@redhat.com"}, {"url": "https://github.com/torvalds/linux/commit/0449641130f5652b344ef6fa39fa019d7e94660a", "source": "secalert@redhat.com", "tags": ["Exploit", "Patch"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/0449641130f5652b344ef6fa39fa019d7e94660a"}}
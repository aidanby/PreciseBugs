{"buggy_code": ["2.1.0\n-----\n\nPython Version Support\n~~~~~~~~~~~~~~~~~~~~~~\n\n- Python 3.6 is no longer supported by Waitress\n\n- Python 3.10 is fully supported by Waitress\n\nBugfix\n~~~~~~\n\n- ``wsgi.file_wrapper`` now sets the ``seekable``, ``seek``, and ``tell``\n  attributes from the underlying file if the underlying file is seekable. This\n  allows WSGI middleware to implement things like range requests for example\n\n  See https://github.com/Pylons/waitress/issues/359 and\n  https://github.com/Pylons/waitress/pull/363\n\n- In Python 3 ``OSError`` is no longer subscriptable, this caused failures on\n  Windows attempting to loop to find an socket that would work for use in the\n  trigger.\n\n  See https://github.com/Pylons/waitress/pull/361\n\n- Fixed an issue whereby ``BytesIO`` objects were not properly closed, and\n  thereby would not get cleaned up until garbage collection would get around to\n  it.\n\n  This led to potential for random memory spikes/memory issues, see\n  https://github.com/Pylons/waitress/pull/358 and\n  https://github.com/Pylons/waitress/issues/357 .\n\n  With thanks to Florian Schulze for testing/vaidating this fix!\n\nFeatures\n~~~~~~~~\n\n- When the WSGI app starts sending data to the output buffer, we now attempt to\n  send data directly to the socket. This avoids needing to wake up the main\n  thread to start sending data. Allowing faster transmission of the first byte.\n  See https://github.com/Pylons/waitress/pull/364\n\n  With thanks to Michael Merickel for being a great rubber ducky!\n\n- Add REQUEST_URI to the WSGI environment.\n\n  REQUEST_URI is similar to ``request_uri`` in nginx. It is a string that\n  contains the request path before separating the query string and\n  decoding ``%``-escaped characters. \n", "[metadata]\nname = waitress\nversion = 2.1.0\ndescription = Waitress WSGI server\nlong_description = file: README.rst, CHANGES.txt\nlong_description_content_type = text/x-rst\nkeywords = waitress wsgi server http\nlicense = ZPL 2.1\nclassifiers =\n    Development Status :: 6 - Mature\n    Environment :: Web Environment\n    Intended Audience :: Developers\n    License :: OSI Approved :: Zope Public License\n    Programming Language :: Python\n    Programming Language :: Python :: 3\n    Programming Language :: Python :: 3.7\n    Programming Language :: Python :: 3.8\n    Programming Language :: Python :: 3.9\n    Programming Language :: Python :: 3.10\n    Programming Language :: Python :: Implementation :: CPython\n    Programming Language :: Python :: Implementation :: PyPy\n    Operating System :: OS Independent\n    Topic :: Internet :: WWW/HTTP\n    Topic :: Internet :: WWW/HTTP :: WSGI\nurl = https://github.com/Pylons/waitress\nproject_urls =\n    Documentation = https://docs.pylonsproject.org/projects/waitress/en/latest/index.html\n    Changelog = https://docs.pylonsproject.org/projects/waitress/en/latest/index.html#change-history\n    Issue Tracker = https://github.com/Pylons/waitress/issues\n\nauthor = Zope Foundation and Contributors\nauthor_email = zope-dev@zope.org\nmaintainer = Pylons Project\nmaintainer_email = pylons-discuss@googlegroups.com\n\n[options]\npackage_dir=\n    =src\npackages=find:\npython_requires = >=3.7.0\n\n[options.entry_points]\npaste.server_runner =\n    main = waitress:serve_paste\nconsole_scripts =\n    waitress-serve = waitress.runner:run\n\n[options.packages.find]\nwhere=src\n\n[options.extras_require]\ntesting =\n    pytest\n    pytest-cover\n    coverage>=5.0\n\ndocs =\n    Sphinx>=1.8.1\n    docutils\n    pylons-sphinx-themes>=1.0.9\n\n[tool:pytest]\npython_files = test_*.py\n# For the benefit of test_wasyncore.py\npython_classes = Test*\ntestpaths =\n    tests\naddopts = --cov -W always\n", "##############################################################################\n#\n# Copyright (c) 2001, 2002 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\n\"\"\"HTTP Request Parser\n\nThis server uses asyncore to accept connections and do initial\nprocessing but threads to do work.\n\"\"\"\nfrom io import BytesIO\nimport re\nfrom urllib import parse\nfrom urllib.parse import unquote_to_bytes\n\nfrom waitress.buffers import OverflowableBuffer\nfrom waitress.receiver import ChunkedReceiver, FixedStreamReceiver\nfrom waitress.utilities import (\n    BadRequest,\n    RequestEntityTooLarge,\n    RequestHeaderFieldsTooLarge,\n    ServerNotImplemented,\n    find_double_newline,\n)\n\nfrom .rfc7230 import HEADER_FIELD\n\n\ndef unquote_bytes_to_wsgi(bytestring):\n    return unquote_to_bytes(bytestring).decode(\"latin-1\")\n\n\nclass ParsingError(Exception):\n    pass\n\n\nclass TransferEncodingNotImplemented(Exception):\n    pass\n\n\nclass HTTPRequestParser:\n    \"\"\"A structure that collects the HTTP request.\n\n    Once the stream is completed, the instance is passed to\n    a server task constructor.\n    \"\"\"\n\n    completed = False  # Set once request is completed.\n    empty = False  # Set if no request was made.\n    expect_continue = False  # client sent \"Expect: 100-continue\" header\n    headers_finished = False  # True when headers have been read\n    header_plus = b\"\"\n    chunked = False\n    content_length = 0\n    header_bytes_received = 0\n    body_bytes_received = 0\n    body_rcv = None\n    version = \"1.0\"\n    error = None\n    connection_close = False\n\n    # Other attributes: first_line, header, headers, command, uri, version,\n    # path, query, fragment\n\n    def __init__(self, adj):\n        \"\"\"\n        adj is an Adjustments object.\n        \"\"\"\n        # headers is a mapping containing keys translated to uppercase\n        # with dashes turned into underscores.\n        self.headers = {}\n        self.adj = adj\n\n    def received(self, data):\n        \"\"\"\n        Receives the HTTP stream for one request.  Returns the number of\n        bytes consumed.  Sets the completed flag once both the header and the\n        body have been received.\n        \"\"\"\n\n        if self.completed:\n            return 0  # Can't consume any more.\n\n        datalen = len(data)\n        br = self.body_rcv\n\n        if br is None:\n            # In header.\n            max_header = self.adj.max_request_header_size\n\n            s = self.header_plus + data\n            index = find_double_newline(s)\n            consumed = 0\n\n            if index >= 0:\n                # If the headers have ended, and we also have part of the body\n                # message in data we still want to validate we aren't going\n                # over our limit for received headers.\n                self.header_bytes_received += index\n                consumed = datalen - (len(s) - index)\n            else:\n                self.header_bytes_received += datalen\n                consumed = datalen\n\n            # If the first line + headers is over the max length, we return a\n            # RequestHeaderFieldsTooLarge error rather than continuing to\n            # attempt to parse the headers.\n\n            if self.header_bytes_received >= max_header:\n                self.parse_header(b\"GET / HTTP/1.0\\r\\n\")\n                self.error = RequestHeaderFieldsTooLarge(\n                    \"exceeds max_header of %s\" % max_header\n                )\n                self.completed = True\n\n                return consumed\n\n            if index >= 0:\n                # Header finished.\n                header_plus = s[:index]\n\n                # Remove preceeding blank lines. This is suggested by\n                # https://tools.ietf.org/html/rfc7230#section-3.5 to support\n                # clients sending an extra CR LF after another request when\n                # using HTTP pipelining\n                header_plus = header_plus.lstrip()\n\n                if not header_plus:\n                    self.empty = True\n                    self.completed = True\n                else:\n                    try:\n                        self.parse_header(header_plus)\n                    except ParsingError as e:\n                        self.error = BadRequest(e.args[0])\n                        self.completed = True\n                    except TransferEncodingNotImplemented as e:\n                        self.error = ServerNotImplemented(e.args[0])\n                        self.completed = True\n                    else:\n                        if self.body_rcv is None:\n                            # no content-length header and not a t-e: chunked\n                            # request\n                            self.completed = True\n\n                        if self.content_length > 0:\n                            max_body = self.adj.max_request_body_size\n                            # we won't accept this request if the content-length\n                            # is too large\n\n                            if self.content_length >= max_body:\n                                self.error = RequestEntityTooLarge(\n                                    \"exceeds max_body of %s\" % max_body\n                                )\n                                self.completed = True\n                self.headers_finished = True\n\n                return consumed\n\n            # Header not finished yet.\n            self.header_plus = s\n\n            return datalen\n        else:\n            # In body.\n            consumed = br.received(data)\n            self.body_bytes_received += consumed\n            max_body = self.adj.max_request_body_size\n\n            if self.body_bytes_received >= max_body:\n                # this will only be raised during t-e: chunked requests\n                self.error = RequestEntityTooLarge(\"exceeds max_body of %s\" % max_body)\n                self.completed = True\n            elif br.error:\n                # garbage in chunked encoding input probably\n                self.error = br.error\n                self.completed = True\n            elif br.completed:\n                # The request (with the body) is ready to use.\n                self.completed = True\n\n                if self.chunked:\n                    # We've converted the chunked transfer encoding request\n                    # body into a normal request body, so we know its content\n                    # length; set the header here.  We already popped the\n                    # TRANSFER_ENCODING header in parse_header, so this will\n                    # appear to the client to be an entirely non-chunked HTTP\n                    # request with a valid content-length.\n                    self.headers[\"CONTENT_LENGTH\"] = str(br.__len__())\n\n            return consumed\n\n    def parse_header(self, header_plus):\n        \"\"\"\n        Parses the header_plus block of text (the headers plus the\n        first line of the request).\n        \"\"\"\n        index = header_plus.find(b\"\\r\\n\")\n\n        if index >= 0:\n            first_line = header_plus[:index].rstrip()\n            header = header_plus[index + 2 :]\n        else:\n            raise ParsingError(\"HTTP message header invalid\")\n\n        if b\"\\r\" in first_line or b\"\\n\" in first_line:\n            raise ParsingError(\"Bare CR or LF found in HTTP message\")\n\n        self.first_line = first_line  # for testing\n\n        lines = get_header_lines(header)\n\n        headers = self.headers\n\n        for line in lines:\n            header = HEADER_FIELD.match(line)\n\n            if not header:\n                raise ParsingError(\"Invalid header\")\n\n            key, value = header.group(\"name\", \"value\")\n\n            if b\"_\" in key:\n                # TODO(xistence): Should we drop this request instead?\n\n                continue\n\n            # Only strip off whitespace that is considered valid whitespace by\n            # RFC7230, don't strip the rest\n            value = value.strip(b\" \\t\")\n            key1 = key.upper().replace(b\"-\", b\"_\").decode(\"latin-1\")\n            # If a header already exists, we append subsequent values\n            # separated by a comma. Applications already need to handle\n            # the comma separated values, as HTTP front ends might do\n            # the concatenation for you (behavior specified in RFC2616).\n            try:\n                headers[key1] += (b\", \" + value).decode(\"latin-1\")\n            except KeyError:\n                headers[key1] = value.decode(\"latin-1\")\n\n        # command, uri, version will be bytes\n        command, uri, version = crack_first_line(first_line)\n        # self.request_uri is like nginx's request_uri:\n        # \"full original request URI (with arguments)\"\n        self.request_uri = uri.decode(\"latin-1\")\n        version = version.decode(\"latin-1\")\n        command = command.decode(\"latin-1\")\n        self.command = command\n        self.version = version\n        (\n            self.proxy_scheme,\n            self.proxy_netloc,\n            self.path,\n            self.query,\n            self.fragment,\n        ) = split_uri(uri)\n        self.url_scheme = self.adj.url_scheme\n        connection = headers.get(\"CONNECTION\", \"\")\n\n        if version == \"1.0\":\n            if connection.lower() != \"keep-alive\":\n                self.connection_close = True\n\n        if version == \"1.1\":\n            # since the server buffers data from chunked transfers and clients\n            # never need to deal with chunked requests, downstream clients\n            # should not see the HTTP_TRANSFER_ENCODING header; we pop it\n            # here\n            te = headers.pop(\"TRANSFER_ENCODING\", \"\")\n\n            # NB: We can not just call bare strip() here because it will also\n            # remove other non-printable characters that we explicitly do not\n            # want removed so that if someone attempts to smuggle a request\n            # with these characters we don't fall prey to it.\n            #\n            # For example \\x85 is stripped by default, but it is not considered\n            # valid whitespace to be stripped by RFC7230.\n            encodings = [\n                encoding.strip(\" \\t\").lower() for encoding in te.split(\",\") if encoding\n            ]\n\n            for encoding in encodings:\n                # Out of the transfer-codings listed in\n                # https://tools.ietf.org/html/rfc7230#section-4 we only support\n                # chunked at this time.\n\n                # Note: the identity transfer-coding was removed in RFC7230:\n                # https://tools.ietf.org/html/rfc7230#appendix-A.2 and is thus\n                # not supported\n\n                if encoding not in {\"chunked\"}:\n                    raise TransferEncodingNotImplemented(\n                        \"Transfer-Encoding requested is not supported.\"\n                    )\n\n            if encodings and encodings[-1] == \"chunked\":\n                self.chunked = True\n                buf = OverflowableBuffer(self.adj.inbuf_overflow)\n                self.body_rcv = ChunkedReceiver(buf)\n            elif encodings:  # pragma: nocover\n                raise TransferEncodingNotImplemented(\n                    \"Transfer-Encoding requested is not supported.\"\n                )\n\n            expect = headers.get(\"EXPECT\", \"\").lower()\n            self.expect_continue = expect == \"100-continue\"\n\n            if connection.lower() == \"close\":\n                self.connection_close = True\n\n        if not self.chunked:\n            try:\n                cl = int(headers.get(\"CONTENT_LENGTH\", 0))\n            except ValueError:\n                raise ParsingError(\"Content-Length is invalid\")\n\n            self.content_length = cl\n\n            if cl > 0:\n                buf = OverflowableBuffer(self.adj.inbuf_overflow)\n                self.body_rcv = FixedStreamReceiver(cl, buf)\n\n    def get_body_stream(self):\n        body_rcv = self.body_rcv\n\n        if body_rcv is not None:\n            return body_rcv.getfile()\n        else:\n            return BytesIO()\n\n    def close(self):\n        body_rcv = self.body_rcv\n\n        if body_rcv is not None:\n            body_rcv.getbuf().close()\n\n\ndef split_uri(uri):\n    # urlsplit handles byte input by returning bytes on py3, so\n    # scheme, netloc, path, query, and fragment are bytes\n\n    scheme = netloc = path = query = fragment = b\"\"\n\n    # urlsplit below will treat this as a scheme-less netloc, thereby losing\n    # the original intent of the request. Here we shamelessly stole 4 lines of\n    # code from the CPython stdlib to parse out the fragment and query but\n    # leave the path alone. See\n    # https://github.com/python/cpython/blob/8c9e9b0cd5b24dfbf1424d1f253d02de80e8f5ef/Lib/urllib/parse.py#L465-L468\n    # and https://github.com/Pylons/waitress/issues/260\n\n    if uri[:2] == b\"//\":\n        path = uri\n\n        if b\"#\" in path:\n            path, fragment = path.split(b\"#\", 1)\n\n        if b\"?\" in path:\n            path, query = path.split(b\"?\", 1)\n    else:\n        try:\n            scheme, netloc, path, query, fragment = parse.urlsplit(uri)\n        except UnicodeError:\n            raise ParsingError(\"Bad URI\")\n\n    return (\n        scheme.decode(\"latin-1\"),\n        netloc.decode(\"latin-1\"),\n        unquote_bytes_to_wsgi(path),\n        query.decode(\"latin-1\"),\n        fragment.decode(\"latin-1\"),\n    )\n\n\ndef get_header_lines(header):\n    \"\"\"\n    Splits the header into lines, putting multi-line headers together.\n    \"\"\"\n    r = []\n    lines = header.split(b\"\\r\\n\")\n\n    for line in lines:\n        if not line:\n            continue\n\n        if b\"\\r\" in line or b\"\\n\" in line:\n            raise ParsingError(\n                'Bare CR or LF found in header line \"%s\"' % str(line, \"latin-1\")\n            )\n\n        if line.startswith((b\" \", b\"\\t\")):\n            if not r:\n                # https://corte.si/posts/code/pathod/pythonservers/index.html\n                raise ParsingError('Malformed header line \"%s\"' % str(line, \"latin-1\"))\n            r[-1] += line\n        else:\n            r.append(line)\n\n    return r\n\n\nfirst_line_re = re.compile(\n    b\"([^ ]+) \"\n    b\"((?:[^ :?#]+://[^ ?#/]*(?:[0-9]{1,5})?)?[^ ]+)\"\n    b\"(( HTTP/([0-9.]+))$|$)\"\n)\n\n\ndef crack_first_line(line):\n    m = first_line_re.match(line)\n\n    if m is not None and m.end() == len(line):\n        if m.group(3):\n            version = m.group(5)\n        else:\n            version = b\"\"\n        method = m.group(1)\n\n        # the request methods that are currently defined are all uppercase:\n        # https://www.iana.org/assignments/http-methods/http-methods.xhtml and\n        # the request method is case sensitive according to\n        # https://tools.ietf.org/html/rfc7231#section-4.1\n\n        # By disallowing anything but uppercase methods we save poor\n        # unsuspecting souls from sending lowercase HTTP methods to waitress\n        # and having the request complete, while servers like nginx drop the\n        # request onto the floor.\n\n        if method != method.upper():\n            raise ParsingError('Malformed HTTP method \"%s\"' % str(method, \"latin-1\"))\n        uri = m.group(2)\n\n        return method, uri, version\n    else:\n        return b\"\", b\"\", b\"\"\n", "##############################################################################\n#\n# Copyright (c) 2001, 2002 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\n\"\"\"Data Chunk Receiver\n\"\"\"\n\nfrom waitress.utilities import BadRequest, find_double_newline\n\n\nclass FixedStreamReceiver:\n\n    # See IStreamConsumer\n    completed = False\n    error = None\n\n    def __init__(self, cl, buf):\n        self.remain = cl\n        self.buf = buf\n\n    def __len__(self):\n        return self.buf.__len__()\n\n    def received(self, data):\n        \"See IStreamConsumer\"\n        rm = self.remain\n\n        if rm < 1:\n            self.completed = True  # Avoid any chance of spinning\n\n            return 0\n        datalen = len(data)\n\n        if rm <= datalen:\n            self.buf.append(data[:rm])\n            self.remain = 0\n            self.completed = True\n\n            return rm\n        else:\n            self.buf.append(data)\n            self.remain -= datalen\n\n            return datalen\n\n    def getfile(self):\n        return self.buf.getfile()\n\n    def getbuf(self):\n        return self.buf\n\n\nclass ChunkedReceiver:\n\n    chunk_remainder = 0\n    validate_chunk_end = False\n    control_line = b\"\"\n    chunk_end = b\"\"\n    all_chunks_received = False\n    trailer = b\"\"\n    completed = False\n    error = None\n\n    # max_control_line = 1024\n    # max_trailer = 65536\n\n    def __init__(self, buf):\n        self.buf = buf\n\n    def __len__(self):\n        return self.buf.__len__()\n\n    def received(self, s):\n        # Returns the number of bytes consumed.\n\n        if self.completed:\n            return 0\n        orig_size = len(s)\n\n        while s:\n            rm = self.chunk_remainder\n\n            if rm > 0:\n                # Receive the remainder of a chunk.\n                to_write = s[:rm]\n                self.buf.append(to_write)\n                written = len(to_write)\n                s = s[written:]\n\n                self.chunk_remainder -= written\n\n                if self.chunk_remainder == 0:\n                    self.validate_chunk_end = True\n            elif self.validate_chunk_end:\n                s = self.chunk_end + s\n\n                pos = s.find(b\"\\r\\n\")\n\n                if pos < 0 and len(s) < 2:\n                    self.chunk_end = s\n                    s = b\"\"\n                else:\n                    self.chunk_end = b\"\"\n                    if pos == 0:\n                        # Chop off the terminating CR LF from the chunk\n                        s = s[2:]\n                    else:\n                        self.error = BadRequest(\"Chunk not properly terminated\")\n                        self.all_chunks_received = True\n\n                    # Always exit this loop\n                    self.validate_chunk_end = False\n            elif not self.all_chunks_received:\n                # Receive a control line.\n                s = self.control_line + s\n                pos = s.find(b\"\\r\\n\")\n\n                if pos < 0:\n                    # Control line not finished.\n                    self.control_line = s\n                    s = b\"\"\n                else:\n                    # Control line finished.\n                    line = s[:pos]\n                    s = s[pos + 2 :]\n                    self.control_line = b\"\"\n                    line = line.strip()\n\n                    if line:\n                        # Begin a new chunk.\n                        semi = line.find(b\";\")\n\n                        if semi >= 0:\n                            # discard extension info.\n                            line = line[:semi]\n                        try:\n                            sz = int(line.strip(), 16)  # hexadecimal\n                        except ValueError:  # garbage in input\n                            self.error = BadRequest(\"garbage in chunked encoding input\")\n                            sz = 0\n\n                        if sz > 0:\n                            # Start a new chunk.\n                            self.chunk_remainder = sz\n                        else:\n                            # Finished chunks.\n                            self.all_chunks_received = True\n                    # else expect a control line.\n            else:\n                # Receive the trailer.\n                trailer = self.trailer + s\n\n                if trailer.startswith(b\"\\r\\n\"):\n                    # No trailer.\n                    self.completed = True\n\n                    return orig_size - (len(trailer) - 2)\n                pos = find_double_newline(trailer)\n\n                if pos < 0:\n                    # Trailer not finished.\n                    self.trailer = trailer\n                    s = b\"\"\n                else:\n                    # Finished the trailer.\n                    self.completed = True\n                    self.trailer = trailer[:pos]\n\n                    return orig_size - (len(trailer) - pos)\n\n        return orig_size\n\n    def getfile(self):\n        return self.buf.getfile()\n\n    def getbuf(self):\n        return self.buf\n", "\"\"\"\nThis contains a bunch of RFC7230 definitions and regular expressions that are\nneeded to properly parse HTTP messages.\n\"\"\"\n\nimport re\n\nWS = \"[ \\t]\"\nOWS = WS + \"{0,}?\"\nRWS = WS + \"{1,}?\"\nBWS = OWS\n\n# RFC 7230 Section 3.2.6 \"Field Value Components\":\n# tchar          = \"!\" / \"#\" / \"$\" / \"%\" / \"&\" / \"'\" / \"*\"\n#                / \"+\" / \"-\" / \".\" / \"^\" / \"_\" / \"`\" / \"|\" / \"~\"\n#                / DIGIT / ALPHA\n# obs-text      = %x80-FF\nTCHAR = r\"[!#$%&'*+\\-.^_`|~0-9A-Za-z]\"\nOBS_TEXT = r\"\\x80-\\xff\"\n\nTOKEN = TCHAR + \"{1,}\"\n\n# RFC 5234 Appendix B.1 \"Core Rules\":\n# VCHAR         =  %x21-7E\n#                  ; visible (printing) characters\nVCHAR = r\"\\x21-\\x7e\"\n\n# header-field   = field-name \":\" OWS field-value OWS\n# field-name     = token\n# field-value    = *( field-content / obs-fold )\n# field-content  = field-vchar [ 1*( SP / HTAB ) field-vchar ]\n# field-vchar    = VCHAR / obs-text\n\n# Errata from: https://www.rfc-editor.org/errata_search.php?rfc=7230&eid=4189\n# changes field-content to:\n#\n# field-content  = field-vchar [ 1*( SP / HTAB / field-vchar )\n#                  field-vchar ]\n\nFIELD_VCHAR = \"[\" + VCHAR + OBS_TEXT + \"]\"\n# Field content is more greedy than the ABNF, in that it will match the whole value\nFIELD_CONTENT = FIELD_VCHAR + \"+(?:[ \\t]+\" + FIELD_VCHAR + \"+)*\"\n# Which allows the field value here to just see if there is even a value in the first place\nFIELD_VALUE = \"(?:\" + FIELD_CONTENT + \")?\"\n\nHEADER_FIELD = re.compile(\n    (\n        \"^(?P<name>\" + TOKEN + \"):\" + OWS + \"(?P<value>\" + FIELD_VALUE + \")\" + OWS + \"$\"\n    ).encode(\"latin-1\")\n)\n", "##############################################################################\n#\n# Copyright (c) 2004 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\n\"\"\"Utility functions\n\"\"\"\n\nimport calendar\nimport errno\nimport logging\nimport os\nimport re\nimport stat\nimport time\n\nfrom .rfc7230 import OBS_TEXT, VCHAR\n\nlogger = logging.getLogger(\"waitress\")\nqueue_logger = logging.getLogger(\"waitress.queue\")\n\n\ndef find_double_newline(s):\n    \"\"\"Returns the position just after a double newline in the given string.\"\"\"\n    pos = s.find(b\"\\r\\n\\r\\n\")\n\n    if pos >= 0:\n        pos += 4\n\n    return pos\n\n\ndef concat(*args):\n    return \"\".join(args)\n\n\ndef join(seq, field=\" \"):\n    return field.join(seq)\n\n\ndef group(s):\n    return \"(\" + s + \")\"\n\n\nshort_days = [\"sun\", \"mon\", \"tue\", \"wed\", \"thu\", \"fri\", \"sat\"]\nlong_days = [\n    \"sunday\",\n    \"monday\",\n    \"tuesday\",\n    \"wednesday\",\n    \"thursday\",\n    \"friday\",\n    \"saturday\",\n]\n\nshort_day_reg = group(join(short_days, \"|\"))\nlong_day_reg = group(join(long_days, \"|\"))\n\ndaymap = {}\n\nfor i in range(7):\n    daymap[short_days[i]] = i\n    daymap[long_days[i]] = i\n\nhms_reg = join(3 * [group(\"[0-9][0-9]\")], \":\")\n\nmonths = [\n    \"jan\",\n    \"feb\",\n    \"mar\",\n    \"apr\",\n    \"may\",\n    \"jun\",\n    \"jul\",\n    \"aug\",\n    \"sep\",\n    \"oct\",\n    \"nov\",\n    \"dec\",\n]\n\nmonmap = {}\n\nfor i in range(12):\n    monmap[months[i]] = i + 1\n\nmonths_reg = group(join(months, \"|\"))\n\n# From draft-ietf-http-v11-spec-07.txt/3.3.1\n#       Sun, 06 Nov 1994 08:49:37 GMT  ; RFC 822, updated by RFC 1123\n#       Sunday, 06-Nov-94 08:49:37 GMT ; RFC 850, obsoleted by RFC 1036\n#       Sun Nov  6 08:49:37 1994       ; ANSI C's asctime() format\n\n# rfc822 format\nrfc822_date = join(\n    [\n        concat(short_day_reg, \",\"),  # day\n        group(\"[0-9][0-9]?\"),  # date\n        months_reg,  # month\n        group(\"[0-9]+\"),  # year\n        hms_reg,  # hour minute second\n        \"gmt\",\n    ],\n    \" \",\n)\n\nrfc822_reg = re.compile(rfc822_date)\n\n\ndef unpack_rfc822(m):\n    g = m.group\n\n    return (\n        int(g(4)),  # year\n        monmap[g(3)],  # month\n        int(g(2)),  # day\n        int(g(5)),  # hour\n        int(g(6)),  # minute\n        int(g(7)),  # second\n        0,\n        0,\n        0,\n    )\n\n\n# rfc850 format\nrfc850_date = join(\n    [\n        concat(long_day_reg, \",\"),\n        join([group(\"[0-9][0-9]?\"), months_reg, group(\"[0-9]+\")], \"-\"),\n        hms_reg,\n        \"gmt\",\n    ],\n    \" \",\n)\n\nrfc850_reg = re.compile(rfc850_date)\n# they actually unpack the same way\ndef unpack_rfc850(m):\n    g = m.group\n    yr = g(4)\n\n    if len(yr) == 2:\n        yr = \"19\" + yr\n\n    return (\n        int(yr),  # year\n        monmap[g(3)],  # month\n        int(g(2)),  # day\n        int(g(5)),  # hour\n        int(g(6)),  # minute\n        int(g(7)),  # second\n        0,\n        0,\n        0,\n    )\n\n\n# parsdate.parsedate - ~700/sec.\n# parse_http_date    - ~1333/sec.\n\nweekdayname = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\nmonthname = [\n    None,\n    \"Jan\",\n    \"Feb\",\n    \"Mar\",\n    \"Apr\",\n    \"May\",\n    \"Jun\",\n    \"Jul\",\n    \"Aug\",\n    \"Sep\",\n    \"Oct\",\n    \"Nov\",\n    \"Dec\",\n]\n\n\ndef build_http_date(when):\n    year, month, day, hh, mm, ss, wd, y, z = time.gmtime(when)\n\n    return \"%s, %02d %3s %4d %02d:%02d:%02d GMT\" % (\n        weekdayname[wd],\n        day,\n        monthname[month],\n        year,\n        hh,\n        mm,\n        ss,\n    )\n\n\ndef parse_http_date(d):\n    d = d.lower()\n    m = rfc850_reg.match(d)\n\n    if m and m.end() == len(d):\n        retval = int(calendar.timegm(unpack_rfc850(m)))\n    else:\n        m = rfc822_reg.match(d)\n\n        if m and m.end() == len(d):\n            retval = int(calendar.timegm(unpack_rfc822(m)))\n        else:\n            return 0\n\n    return retval\n\n\n# RFC 5234 Appendix B.1 \"Core Rules\":\n# VCHAR         =  %x21-7E\n#                  ; visible (printing) characters\nvchar_re = VCHAR\n\n# RFC 7230 Section 3.2.6 \"Field Value Components\":\n# quoted-string = DQUOTE *( qdtext / quoted-pair ) DQUOTE\n# qdtext        = HTAB / SP /%x21 / %x23-5B / %x5D-7E / obs-text\n# obs-text      = %x80-FF\n# quoted-pair   = \"\\\" ( HTAB / SP / VCHAR / obs-text )\nobs_text_re = OBS_TEXT\n\n# The '\\\\' between \\x5b and \\x5d is needed to escape \\x5d (']')\nqdtext_re = \"[\\t \\x21\\x23-\\x5b\\\\\\x5d-\\x7e\" + obs_text_re + \"]\"\n\nquoted_pair_re = r\"\\\\\" + \"([\\t \" + vchar_re + obs_text_re + \"])\"\nquoted_string_re = '\"(?:(?:' + qdtext_re + \")|(?:\" + quoted_pair_re + '))*\"'\n\nquoted_string = re.compile(quoted_string_re)\nquoted_pair = re.compile(quoted_pair_re)\n\n\ndef undquote(value):\n    if value.startswith('\"') and value.endswith('\"'):\n        # So it claims to be DQUOTE'ed, let's validate that\n        matches = quoted_string.match(value)\n\n        if matches and matches.end() == len(value):\n            # Remove the DQUOTE's from the value\n            value = value[1:-1]\n\n            # Remove all backslashes that are followed by a valid vchar or\n            # obs-text\n            value = quoted_pair.sub(r\"\\1\", value)\n\n            return value\n    elif not value.startswith('\"') and not value.endswith('\"'):\n        return value\n\n    raise ValueError(\"Invalid quoting in value\")\n\n\ndef cleanup_unix_socket(path):\n    try:\n        st = os.stat(path)\n    except OSError as exc:\n        if exc.errno != errno.ENOENT:\n            raise  # pragma: no cover\n    else:\n        if stat.S_ISSOCK(st.st_mode):\n            try:\n                os.remove(path)\n            except OSError:  # pragma: no cover\n                # avoid race condition error during tests\n                pass\n\n\nclass Error:\n    code = 500\n    reason = \"Internal Server Error\"\n\n    def __init__(self, body):\n        self.body = body\n\n    def to_response(self):\n        status = \"%s %s\" % (self.code, self.reason)\n        body = \"%s\\r\\n\\r\\n%s\" % (self.reason, self.body)\n        tag = \"\\r\\n\\r\\n(generated by waitress)\"\n        body = body + tag\n        headers = [(\"Content-Type\", \"text/plain\")]\n\n        return status, headers, body\n\n    def wsgi_response(self, environ, start_response):\n        status, headers, body = self.to_response()\n        start_response(status, headers)\n        yield body\n\n\nclass BadRequest(Error):\n    code = 400\n    reason = \"Bad Request\"\n\n\nclass RequestHeaderFieldsTooLarge(BadRequest):\n    code = 431\n    reason = \"Request Header Fields Too Large\"\n\n\nclass RequestEntityTooLarge(BadRequest):\n    code = 413\n    reason = \"Request Entity Too Large\"\n\n\nclass InternalServerError(Error):\n    code = 500\n    reason = \"Internal Server Error\"\n\n\nclass ServerNotImplemented(Error):\n    code = 501\n    reason = \"Not Implemented\"\n", "import errno\nfrom http import client as httplib\nimport logging\nimport multiprocessing\nimport os\nimport signal\nimport socket\nimport string\nimport subprocess\nimport sys\nimport time\nimport unittest\n\nfrom waitress import server\nfrom waitress.compat import WIN\nfrom waitress.utilities import cleanup_unix_socket\n\ndn = os.path.dirname\nhere = dn(__file__)\n\n\nclass NullHandler(logging.Handler):  # pragma: no cover\n    \"\"\"A logging handler that swallows all emitted messages.\"\"\"\n\n    def emit(self, record):\n        pass\n\n\ndef start_server(app, svr, queue, **kwargs):  # pragma: no cover\n    \"\"\"Run a fixture application.\"\"\"\n    logging.getLogger(\"waitress\").addHandler(NullHandler())\n    try_register_coverage()\n    svr(app, queue, **kwargs).run()\n\n\ndef try_register_coverage():  # pragma: no cover\n    # Hack around multiprocessing exiting early and not triggering coverage's\n    # atexit handler by always registering a signal handler\n\n    if \"COVERAGE_PROCESS_START\" in os.environ:\n\n        def sigterm(*args):\n            sys.exit(0)\n\n        signal.signal(signal.SIGTERM, sigterm)\n\n\nclass FixtureTcpWSGIServer(server.TcpWSGIServer):\n    \"\"\"A version of TcpWSGIServer that relays back what it's bound to.\"\"\"\n\n    family = socket.AF_INET  # Testing\n\n    def __init__(self, application, queue, **kw):  # pragma: no cover\n        # Coverage doesn't see this as it's ran in a separate process.\n        kw[\"host\"] = \"127.0.0.1\"\n        kw[\"port\"] = 0  # Bind to any available port.\n        super().__init__(application, **kw)\n        host, port = self.socket.getsockname()\n\n        if os.name == \"nt\":\n            host = \"127.0.0.1\"\n        queue.put((host, port))\n\n\nclass SubprocessTests:\n\n    exe = sys.executable\n\n    server = None\n\n    def start_subprocess(self, target, **kw):\n        # Spawn a server process.\n        self.queue = multiprocessing.Queue()\n\n        if \"COVERAGE_RCFILE\" in os.environ:\n            os.environ[\"COVERAGE_PROCESS_START\"] = os.environ[\"COVERAGE_RCFILE\"]\n\n        if not WIN:\n            ctx = multiprocessing.get_context(\"fork\")\n        else:\n            ctx = multiprocessing.get_context(\"spawn\")\n\n        self.proc = ctx.Process(\n            target=start_server,\n            args=(target, self.server, self.queue),\n            kwargs=kw,\n        )\n        self.proc.start()\n\n        if self.proc.exitcode is not None:  # pragma: no cover\n            raise RuntimeError(\"%s didn't start\" % str(target))\n        # Get the socket the server is listening on.\n        self.bound_to = self.queue.get(timeout=5)\n        self.sock = self.create_socket()\n\n    def stop_subprocess(self):\n        if self.proc.exitcode is None:\n            self.proc.terminate()\n        self.sock.close()\n        # This give us one FD back ...\n        self.proc.join()\n        self.proc.close()\n        self.queue.close()\n        self.queue.join_thread()\n\n        # The following is for the benefit of PyPy 3, for some reason it is\n        # holding on to some resources way longer than necessary causing tests\n        # to fail with file desctriptor exceeded errors on macOS which defaults\n        # to 256 file desctriptors per process. While we could use ulimit to\n        # increase the limits before running tests, this works as well and\n        # means we don't need to remember to do that.\n        import gc\n\n        gc.collect()\n\n    def assertline(self, line, status, reason, version):\n        v, s, r = (x.strip() for x in line.split(None, 2))\n        self.assertEqual(s, status.encode(\"latin-1\"))\n        self.assertEqual(r, reason.encode(\"latin-1\"))\n        self.assertEqual(v, version.encode(\"latin-1\"))\n\n    def create_socket(self):\n        return socket.socket(self.server.family, socket.SOCK_STREAM)\n\n    def connect(self):\n        self.sock.connect(self.bound_to)\n\n    def make_http_connection(self):\n        raise NotImplementedError  # pragma: no cover\n\n    def send_check_error(self, to_send):\n        self.sock.send(to_send)\n\n\nclass TcpTests(SubprocessTests):\n\n    server = FixtureTcpWSGIServer\n\n    def make_http_connection(self):\n        return httplib.HTTPConnection(*self.bound_to)\n\n\nclass SleepyThreadTests(TcpTests, unittest.TestCase):\n    # test that sleepy thread doesnt block other requests\n\n    def setUp(self):\n        from tests.fixtureapps import sleepy\n\n        self.start_subprocess(sleepy.app)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_it(self):\n        getline = os.path.join(here, \"fixtureapps\", \"getline.py\")\n        cmds = (\n            [self.exe, getline, \"http://%s:%d/sleepy\" % self.bound_to],\n            [self.exe, getline, \"http://%s:%d/\" % self.bound_to],\n        )\n        r, w = os.pipe()\n        procs = []\n\n        for cmd in cmds:\n            procs.append(subprocess.Popen(cmd, stdout=w))\n        time.sleep(3)\n\n        for proc in procs:\n            if proc.returncode is not None:  # pragma: no cover\n                proc.terminate()\n            proc.wait()\n        # the notsleepy response should always be first returned (it sleeps\n        # for 2 seconds, then returns; the notsleepy response should be\n        # processed in the meantime)\n        result = os.read(r, 10000)\n        os.close(r)\n        os.close(w)\n        self.assertEqual(result, b\"notsleepy returnedsleepy returned\")\n\n\nclass EchoTests:\n    def setUp(self):\n        from tests.fixtureapps import echo\n\n        self.start_subprocess(\n            echo.app,\n            trusted_proxy=\"*\",\n            trusted_proxy_count=1,\n            trusted_proxy_headers={\"x-forwarded-for\", \"x-forwarded-proto\"},\n            clear_untrusted_proxy_headers=True,\n        )\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def _read_echo(self, fp):\n        from tests.fixtureapps import echo\n\n        line, headers, body = read_http(fp)\n\n        return line, headers, echo.parse_response(body)\n\n    def test_date_and_server(self):\n        to_send = b\"GET / HTTP/1.0\\r\\nContent-Length: 0\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, echo = self._read_echo(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            self.assertEqual(headers.get(\"server\"), \"waitress\")\n            self.assertTrue(headers.get(\"date\"))\n\n    def test_bad_host_header(self):\n        # https://corte.si/posts/code/pathod/pythonservers/index.html\n        to_send = b\"GET / HTTP/1.0\\r\\n Host: 0\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"400\", \"Bad Request\", \"HTTP/1.0\")\n            self.assertEqual(headers.get(\"server\"), \"waitress\")\n            self.assertTrue(headers.get(\"date\"))\n\n    def test_send_with_body(self):\n        to_send = b\"GET / HTTP/1.0\\r\\nContent-Length: 5\\r\\n\\r\\n\"\n        to_send += b\"hello\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, echo = self._read_echo(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            self.assertEqual(echo.content_length, \"5\")\n            self.assertEqual(echo.body, b\"hello\")\n\n    def test_send_empty_body(self):\n        to_send = b\"GET / HTTP/1.0\\r\\nContent-Length: 0\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, echo = self._read_echo(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            self.assertEqual(echo.content_length, \"0\")\n            self.assertEqual(echo.body, b\"\")\n\n    def test_multiple_requests_with_body(self):\n        orig_sock = self.sock\n\n        for x in range(3):\n            self.sock = self.create_socket()\n            self.test_send_with_body()\n            self.sock.close()\n        self.sock = orig_sock\n\n    def test_multiple_requests_without_body(self):\n        orig_sock = self.sock\n\n        for x in range(3):\n            self.sock = self.create_socket()\n            self.test_send_empty_body()\n            self.sock.close()\n        self.sock = orig_sock\n\n    def test_without_crlf(self):\n        data = b\"Echo\\r\\nthis\\r\\nplease\"\n        s = (\n            b\"GET / HTTP/1.0\\r\\n\"\n            b\"Connection: close\\r\\n\"\n            b\"Content-Length: %d\\r\\n\"\n            b\"\\r\\n\"\n            b\"%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(s)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, echo = self._read_echo(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            self.assertEqual(int(echo.content_length), len(data))\n            self.assertEqual(len(echo.body), len(data))\n            self.assertEqual(echo.body, (data))\n\n    def test_large_body(self):\n        # 1024 characters.\n        body = b\"This string has 32 characters.\\r\\n\" * 32\n        s = b\"GET / HTTP/1.0\\r\\nContent-Length: %d\\r\\n\\r\\n%s\" % (len(body), body)\n        self.connect()\n        self.sock.send(s)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, echo = self._read_echo(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            self.assertEqual(echo.content_length, \"1024\")\n            self.assertEqual(echo.body, body)\n\n    def test_many_clients(self):\n        conns = []\n\n        for n in range(50):\n            h = self.make_http_connection()\n            h.request(\"GET\", \"/\", headers={\"Accept\": \"text/plain\"})\n            conns.append(h)\n        responses = []\n\n        for h in conns:\n            response = h.getresponse()\n            self.assertEqual(response.status, 200)\n            responses.append(response)\n\n        for response in responses:\n            response.read()\n\n        for h in conns:\n            h.close()\n\n    def test_chunking_request_without_content(self):\n        header = b\"GET / HTTP/1.1\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(header)\n        self.sock.send(b\"0\\r\\n\\r\\n\")\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, echo = self._read_echo(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            self.assertEqual(echo.body, b\"\")\n            self.assertEqual(echo.content_length, \"0\")\n            self.assertFalse(\"transfer-encoding\" in headers)\n\n    def test_chunking_request_with_content(self):\n        control_line = b\"20;\\r\\n\"  # 20 hex = 32 dec\n        s = b\"This string has 32 characters.\\r\\n\"\n        expected = s * 12\n        header = b\"GET / HTTP/1.1\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(header)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            for n in range(12):\n                self.sock.send(control_line)\n                self.sock.send(s)\n                self.sock.send(b\"\\r\\n\")  # End the chunk\n            self.sock.send(b\"0\\r\\n\\r\\n\")\n            line, headers, echo = self._read_echo(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            self.assertEqual(echo.body, expected)\n            self.assertEqual(echo.content_length, str(len(expected)))\n            self.assertFalse(\"transfer-encoding\" in headers)\n\n    def test_broken_chunked_encoding(self):\n        control_line = b\"20;\\r\\n\"  # 20 hex = 32 dec\n        s = b\"This string has 32 characters.\\r\\n\"\n        to_send = b\"GET / HTTP/1.1\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n\"\n        to_send += control_line + s + b\"\\r\\n\"\n        # garbage in input\n        to_send += b\"garbage\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            # receiver caught garbage and turned it into a 400\n            self.assertline(line, \"400\", \"Bad Request\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            self.assertEqual(\n                sorted(headers.keys()),\n                [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"],\n            )\n            self.assertEqual(headers[\"content-type\"], \"text/plain\")\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_broken_chunked_encoding_missing_chunk_end(self):\n        control_line = b\"20;\\r\\n\"  # 20 hex = 32 dec\n        s = b\"This string has 32 characters.\\r\\n\"\n        to_send = b\"GET / HTTP/1.1\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n\"\n        to_send += control_line + s\n        # garbage in input\n        to_send += b\"garbage\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            # receiver caught garbage and turned it into a 400\n            self.assertline(line, \"400\", \"Bad Request\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            self.assertTrue(b\"Chunk not properly terminated\" in response_body)\n            self.assertEqual(\n                sorted(headers.keys()),\n                [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"],\n            )\n            self.assertEqual(headers[\"content-type\"], \"text/plain\")\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_keepalive_http_10(self):\n        # Handling of Keep-Alive within HTTP 1.0\n        data = b\"Default: Don't keep me alive\"\n        s = b\"GET / HTTP/1.0\\r\\nContent-Length: %d\\r\\n\\r\\n%s\" % (len(data), data)\n        self.connect()\n        self.sock.send(s)\n        response = httplib.HTTPResponse(self.sock)\n        response.begin()\n        self.assertEqual(int(response.status), 200)\n        connection = response.getheader(\"Connection\", \"\")\n        # We sent no Connection: Keep-Alive header\n        # Connection: close (or no header) is default.\n        self.assertTrue(connection != \"Keep-Alive\")\n\n    def test_keepalive_http10_explicit(self):\n        # If header Connection: Keep-Alive is explicitly sent,\n        # we want to keept the connection open, we also need to return\n        # the corresponding header\n        data = b\"Keep me alive\"\n        s = (\n            b\"GET / HTTP/1.0\\r\\n\"\n            b\"Connection: Keep-Alive\\r\\n\"\n            b\"Content-Length: %d\\r\\n\"\n            b\"\\r\\n\"\n            b\"%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(s)\n        response = httplib.HTTPResponse(self.sock)\n        response.begin()\n        self.assertEqual(int(response.status), 200)\n        connection = response.getheader(\"Connection\", \"\")\n        self.assertEqual(connection, \"Keep-Alive\")\n\n    def test_keepalive_http_11(self):\n        # Handling of Keep-Alive within HTTP 1.1\n\n        # All connections are kept alive, unless stated otherwise\n        data = b\"Default: Keep me alive\"\n        s = b\"GET / HTTP/1.1\\r\\nContent-Length: %d\\r\\n\\r\\n%s\" % (len(data), data)\n        self.connect()\n        self.sock.send(s)\n        response = httplib.HTTPResponse(self.sock)\n        response.begin()\n        self.assertEqual(int(response.status), 200)\n        self.assertTrue(response.getheader(\"connection\") != \"close\")\n\n    def test_keepalive_http11_explicit(self):\n        # Explicitly set keep-alive\n        data = b\"Default: Keep me alive\"\n        s = (\n            b\"GET / HTTP/1.1\\r\\n\"\n            b\"Connection: keep-alive\\r\\n\"\n            b\"Content-Length: %d\\r\\n\"\n            b\"\\r\\n\"\n            b\"%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(s)\n        response = httplib.HTTPResponse(self.sock)\n        response.begin()\n        self.assertEqual(int(response.status), 200)\n        self.assertTrue(response.getheader(\"connection\") != \"close\")\n\n    def test_keepalive_http11_connclose(self):\n        # specifying Connection: close explicitly\n        data = b\"Don't keep me alive\"\n        s = (\n            b\"GET / HTTP/1.1\\r\\n\"\n            b\"Connection: close\\r\\n\"\n            b\"Content-Length: %d\\r\\n\"\n            b\"\\r\\n\"\n            b\"%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(s)\n        response = httplib.HTTPResponse(self.sock)\n        response.begin()\n        self.assertEqual(int(response.status), 200)\n        self.assertEqual(response.getheader(\"connection\"), \"close\")\n\n    def test_proxy_headers(self):\n        to_send = (\n            b\"GET / HTTP/1.0\\r\\n\"\n            b\"Content-Length: 0\\r\\n\"\n            b\"Host: www.google.com:8080\\r\\n\"\n            b\"X-Forwarded-For: 192.168.1.1\\r\\n\"\n            b\"X-Forwarded-Proto: https\\r\\n\"\n            b\"X-Forwarded-Port: 5000\\r\\n\\r\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, echo = self._read_echo(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            self.assertEqual(headers.get(\"server\"), \"waitress\")\n            self.assertTrue(headers.get(\"date\"))\n            self.assertIsNone(echo.headers.get(\"X_FORWARDED_PORT\"))\n            self.assertEqual(echo.headers[\"HOST\"], \"www.google.com:8080\")\n            self.assertEqual(echo.scheme, \"https\")\n            self.assertEqual(echo.remote_addr, \"192.168.1.1\")\n            self.assertEqual(echo.remote_host, \"192.168.1.1\")\n\n\nclass PipeliningTests:\n    def setUp(self):\n        from tests.fixtureapps import echo\n\n        self.start_subprocess(echo.app_body_only)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_pipelining(self):\n        s = (\n            b\"GET / HTTP/1.0\\r\\n\"\n            b\"Connection: %s\\r\\n\"\n            b\"Content-Length: %d\\r\\n\"\n            b\"\\r\\n\"\n            b\"%s\"\n        )\n        to_send = b\"\"\n        count = 25\n\n        for n in range(count):\n            body = b\"Response #%d\\r\\n\" % (n + 1)\n\n            if n + 1 < count:\n                conn = b\"keep-alive\"\n            else:\n                conn = b\"close\"\n            to_send += s % (conn, len(body), body)\n\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            for n in range(count):\n                expect_body = b\"Response #%d\\r\\n\" % (n + 1)\n                line = fp.readline()  # status line\n                version, status, reason = (x.strip() for x in line.split(None, 2))\n                headers = parse_headers(fp)\n                length = int(headers.get(\"content-length\")) or None\n                response_body = fp.read(length)\n                self.assertEqual(int(status), 200)\n                self.assertEqual(length, len(response_body))\n                self.assertEqual(response_body, expect_body)\n\n\nclass ExpectContinueTests:\n    def setUp(self):\n        from tests.fixtureapps import echo\n\n        self.start_subprocess(echo.app_body_only)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_expect_continue(self):\n        # specifying Connection: close explicitly\n        data = b\"I have expectations\"\n        to_send = (\n            b\"GET / HTTP/1.1\\r\\n\"\n            b\"Connection: close\\r\\n\"\n            b\"Content-Length: %d\\r\\n\"\n            b\"Expect: 100-continue\\r\\n\"\n            b\"\\r\\n\"\n            b\"%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line = fp.readline()  # continue status line\n            version, status, reason = (x.strip() for x in line.split(None, 2))\n            self.assertEqual(int(status), 100)\n            self.assertEqual(reason, b\"Continue\")\n            self.assertEqual(version, b\"HTTP/1.1\")\n            fp.readline()  # blank line\n            line = fp.readline()  # next status line\n            version, status, reason = (x.strip() for x in line.split(None, 2))\n            headers = parse_headers(fp)\n            length = int(headers.get(\"content-length\")) or None\n            response_body = fp.read(length)\n            self.assertEqual(int(status), 200)\n            self.assertEqual(length, len(response_body))\n            self.assertEqual(response_body, data)\n\n\nclass BadContentLengthTests:\n    def setUp(self):\n        from tests.fixtureapps import badcl\n\n        self.start_subprocess(badcl.app)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_short_body(self):\n        # check to see if server closes connection when body is too short\n        # for cl header\n        to_send = (\n            b\"GET /short_body HTTP/1.0\\r\\n\"\n            b\"Connection: Keep-Alive\\r\\n\"\n            b\"Content-Length: 0\\r\\n\"\n            b\"\\r\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line = fp.readline()  # status line\n            version, status, reason = (x.strip() for x in line.split(None, 2))\n            headers = parse_headers(fp)\n            content_length = int(headers.get(\"content-length\"))\n            response_body = fp.read(content_length)\n            self.assertEqual(int(status), 200)\n            self.assertNotEqual(content_length, len(response_body))\n            self.assertEqual(len(response_body), content_length - 1)\n            self.assertEqual(response_body, b\"abcdefghi\")\n            # remote closed connection (despite keepalive header); not sure why\n            # first send succeeds\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_long_body(self):\n        # check server doesnt close connection when body is too short\n        # for cl header\n        to_send = (\n            b\"GET /long_body HTTP/1.0\\r\\n\"\n            b\"Connection: Keep-Alive\\r\\n\"\n            b\"Content-Length: 0\\r\\n\"\n            b\"\\r\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line = fp.readline()  # status line\n            version, status, reason = (x.strip() for x in line.split(None, 2))\n            headers = parse_headers(fp)\n            content_length = int(headers.get(\"content-length\")) or None\n            response_body = fp.read(content_length)\n            self.assertEqual(int(status), 200)\n            self.assertEqual(content_length, len(response_body))\n            self.assertEqual(response_body, b\"abcdefgh\")\n            # remote does not close connection (keepalive header)\n            self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line = fp.readline()  # status line\n            version, status, reason = (x.strip() for x in line.split(None, 2))\n            headers = parse_headers(fp)\n            content_length = int(headers.get(\"content-length\")) or None\n            response_body = fp.read(content_length)\n            self.assertEqual(int(status), 200)\n\n\nclass NoContentLengthTests:\n    def setUp(self):\n        from tests.fixtureapps import nocl\n\n        self.start_subprocess(nocl.app)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_http10_generator(self):\n        body = string.ascii_letters.encode(\"latin-1\")\n        to_send = (\n            b\"GET / HTTP/1.0\\r\\n\"\n            b\"Connection: Keep-Alive\\r\\n\"\n            b\"Content-Length: %d\\r\\n\\r\\n\" % len(body)\n        )\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            self.assertEqual(headers.get(\"content-length\"), None)\n            self.assertEqual(headers.get(\"connection\"), \"close\")\n            self.assertEqual(response_body, body)\n            # remote closed connection (despite keepalive header), because\n            # generators cannot have a content-length divined\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_http10_list(self):\n        body = string.ascii_letters.encode(\"latin-1\")\n        to_send = (\n            b\"GET /list HTTP/1.0\\r\\n\"\n            b\"Connection: Keep-Alive\\r\\n\"\n            b\"Content-Length: %d\\r\\n\\r\\n\" % len(body)\n        )\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            self.assertEqual(headers[\"content-length\"], str(len(body)))\n            self.assertEqual(headers.get(\"connection\"), \"Keep-Alive\")\n            self.assertEqual(response_body, body)\n            # remote keeps connection open because it divined the content length\n            # from a length-1 list\n            self.sock.send(to_send)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n\n    def test_http10_listlentwo(self):\n        body = string.ascii_letters.encode(\"latin-1\")\n        to_send = (\n            b\"GET /list_lentwo HTTP/1.0\\r\\n\"\n            b\"Connection: Keep-Alive\\r\\n\"\n            b\"Content-Length: %d\\r\\n\\r\\n\" % len(body)\n        )\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            self.assertEqual(headers.get(\"content-length\"), None)\n            self.assertEqual(headers.get(\"connection\"), \"close\")\n            self.assertEqual(response_body, body)\n            # remote closed connection (despite keepalive header), because\n            # lists of length > 1 cannot have their content length divined\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_http11_generator(self):\n        body = string.ascii_letters\n        body = body.encode(\"latin-1\")\n        to_send = b\"GET / HTTP/1.1\\r\\nContent-Length: %d\\r\\n\\r\\n\" % len(body)\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\") as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            expected = b\"\"\n\n            for chunk in chunks(body, 10):\n                expected += b\"%s\\r\\n%s\\r\\n\" % (\n                    hex(len(chunk))[2:].upper().encode(\"latin-1\"),\n                    chunk,\n                )\n            expected += b\"0\\r\\n\\r\\n\"\n            self.assertEqual(response_body, expected)\n            # connection is always closed at the end of a chunked response\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_http11_list(self):\n        body = string.ascii_letters.encode(\"latin-1\")\n        to_send = b\"GET /list HTTP/1.1\\r\\nContent-Length: %d\\r\\n\\r\\n\" % len(body)\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            self.assertEqual(headers[\"content-length\"], str(len(body)))\n            self.assertEqual(response_body, body)\n            # remote keeps connection open because it divined the content length\n            # from a length-1 list\n            self.sock.send(to_send)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n\n    def test_http11_listlentwo(self):\n        body = string.ascii_letters.encode(\"latin-1\")\n        to_send = b\"GET /list_lentwo HTTP/1.1\\r\\nContent-Length: %d\\r\\n\\r\\n\" % len(body)\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\") as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            expected = b\"\"\n\n            for chunk in (body[:1], body[1:]):\n                expected += b\"%s\\r\\n%s\\r\\n\" % (\n                    (hex(len(chunk))[2:].upper().encode(\"latin-1\")),\n                    chunk,\n                )\n            expected += b\"0\\r\\n\\r\\n\"\n            self.assertEqual(response_body, expected)\n            # connection is always closed at the end of a chunked response\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n\nclass WriteCallbackTests:\n    def setUp(self):\n        from tests.fixtureapps import writecb\n\n        self.start_subprocess(writecb.app)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_short_body(self):\n        # check to see if server closes connection when body is too short\n        # for cl header\n        to_send = (\n            b\"GET /short_body HTTP/1.0\\r\\n\"\n            b\"Connection: Keep-Alive\\r\\n\"\n            b\"Content-Length: 0\\r\\n\"\n            b\"\\r\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            # server trusts the content-length header (5)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, 9)\n            self.assertNotEqual(cl, len(response_body))\n            self.assertEqual(len(response_body), cl - 1)\n            self.assertEqual(response_body, b\"abcdefgh\")\n            # remote closed connection (despite keepalive header)\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_long_body(self):\n        # check server doesnt close connection when body is too long\n        # for cl header\n        to_send = (\n            b\"GET /long_body HTTP/1.0\\r\\n\"\n            b\"Connection: Keep-Alive\\r\\n\"\n            b\"Content-Length: 0\\r\\n\"\n            b\"\\r\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            content_length = int(headers.get(\"content-length\")) or None\n            self.assertEqual(content_length, 9)\n            self.assertEqual(content_length, len(response_body))\n            self.assertEqual(response_body, b\"abcdefghi\")\n            # remote does not close connection (keepalive header)\n            self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n\n    def test_equal_body(self):\n        # check server doesnt close connection when body is equal to\n        # cl header\n        to_send = (\n            b\"GET /equal_body HTTP/1.0\\r\\n\"\n            b\"Connection: Keep-Alive\\r\\n\"\n            b\"Content-Length: 0\\r\\n\"\n            b\"\\r\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            content_length = int(headers.get(\"content-length\")) or None\n            self.assertEqual(content_length, 9)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            self.assertEqual(content_length, len(response_body))\n            self.assertEqual(response_body, b\"abcdefghi\")\n            # remote does not close connection (keepalive header)\n            self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n\n    def test_no_content_length(self):\n        # wtf happens when there's no content-length\n        to_send = (\n            b\"GET /no_content_length HTTP/1.0\\r\\n\"\n            b\"Connection: Keep-Alive\\r\\n\"\n            b\"Content-Length: 0\\r\\n\"\n            b\"\\r\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line = fp.readline()  # status line\n            line, headers, response_body = read_http(fp)\n            content_length = headers.get(\"content-length\")\n            self.assertEqual(content_length, None)\n            self.assertEqual(response_body, b\"abcdefghi\")\n            # remote closed connection (despite keepalive header)\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n\nclass TooLargeTests:\n\n    toobig = 1050\n\n    def setUp(self):\n        from tests.fixtureapps import toolarge\n\n        self.start_subprocess(\n            toolarge.app, max_request_header_size=1000, max_request_body_size=1000\n        )\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_request_headers_too_large_http11(self):\n        body = b\"\"\n        bad_headers = b\"X-Random-Header: 100\\r\\n\" * int(self.toobig / 20)\n        to_send = b\"GET / HTTP/1.1\\r\\nContent-Length: 0\\r\\n\"\n        to_send += bad_headers\n        to_send += b\"\\r\\n\\r\\n\"\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\") as fp:\n            response_line, headers, response_body = read_http(fp)\n            self.assertline(\n                response_line, \"431\", \"Request Header Fields Too Large\", \"HTTP/1.0\"\n            )\n            self.assertEqual(headers[\"connection\"], \"close\")\n\n    def test_request_body_too_large_with_wrong_cl_http10(self):\n        body = b\"a\" * self.toobig\n        to_send = b\"GET / HTTP/1.0\\r\\nContent-Length: 5\\r\\n\\r\\n\"\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\") as fp:\n            # first request succeeds (content-length 5)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            # server trusts the content-length header; no pipelining,\n            # so request fulfilled, extra bytes are thrown away\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_wrong_cl_http10_keepalive(self):\n        body = b\"a\" * self.toobig\n        to_send = (\n            b\"GET / HTTP/1.0\\r\\nContent-Length: 5\\r\\nConnection: Keep-Alive\\r\\n\\r\\n\"\n        )\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\") as fp:\n            # first request succeeds (content-length 5)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"431\", \"Request Header Fields Too Large\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_no_cl_http10(self):\n        body = b\"a\" * self.toobig\n        to_send = b\"GET / HTTP/1.0\\r\\n\\r\\n\"\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            # extra bytes are thrown away (no pipelining), connection closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_no_cl_http10_keepalive(self):\n        body = b\"a\" * self.toobig\n        to_send = b\"GET / HTTP/1.0\\r\\nConnection: Keep-Alive\\r\\n\\r\\n\"\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            # server trusts the content-length header (assumed zero)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            line, headers, response_body = read_http(fp)\n            # next response overruns because the extra data appears to be\n            # header data\n            self.assertline(line, \"431\", \"Request Header Fields Too Large\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_wrong_cl_http11(self):\n        body = b\"a\" * self.toobig\n        to_send = b\"GET / HTTP/1.1\\r\\nContent-Length: 5\\r\\n\\r\\n\"\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\") as fp:\n            # first request succeeds (content-length 5)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            # second response is an error response\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"431\", \"Request Header Fields Too Large\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_wrong_cl_http11_connclose(self):\n        body = b\"a\" * self.toobig\n        to_send = b\"GET / HTTP/1.1\\r\\nContent-Length: 5\\r\\nConnection: close\\r\\n\\r\\n\"\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            # server trusts the content-length header (5)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_no_cl_http11(self):\n        body = b\"a\" * self.toobig\n        to_send = b\"GET / HTTP/1.1\\r\\n\\r\\n\"\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\") as fp:\n            # server trusts the content-length header (assumed 0)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            # server assumes pipelined requests due to http/1.1, and the first\n            # request was assumed c-l 0 because it had no content-length header,\n            # so entire body looks like the header of the subsequent request\n            # second response is an error response\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"431\", \"Request Header Fields Too Large\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_no_cl_http11_connclose(self):\n        body = b\"a\" * self.toobig\n        to_send = b\"GET / HTTP/1.1\\r\\nConnection: close\\r\\n\\r\\n\"\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            # server trusts the content-length header (assumed 0)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_chunked_encoding(self):\n        control_line = b\"20;\\r\\n\"  # 20 hex = 32 dec\n        s = b\"This string has 32 characters.\\r\\n\"\n        to_send = b\"GET / HTTP/1.1\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n\"\n        repeat = control_line + s\n        to_send += repeat * ((self.toobig // len(repeat)) + 1)\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            # body bytes counter caught a max_request_body_size overrun\n            self.assertline(line, \"413\", \"Request Entity Too Large\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            self.assertEqual(headers[\"content-type\"], \"text/plain\")\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n\nclass InternalServerErrorTests:\n    def setUp(self):\n        from tests.fixtureapps import error\n\n        self.start_subprocess(error.app, expose_tracebacks=True)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_before_start_response_http_10(self):\n        to_send = b\"GET /before_start_response HTTP/1.0\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n            self.assertEqual(headers[\"connection\"], \"close\")\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_before_start_response_http_11(self):\n        to_send = b\"GET /before_start_response HTTP/1.1\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n            self.assertEqual(\n                sorted(headers.keys()),\n                [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"],\n            )\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_before_start_response_http_11_close(self):\n        to_send = b\"GET /before_start_response HTTP/1.1\\r\\nConnection: close\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n            self.assertEqual(\n                sorted(headers.keys()),\n                [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"],\n            )\n            self.assertEqual(headers[\"connection\"], \"close\")\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_after_start_response_http10(self):\n        to_send = b\"GET /after_start_response HTTP/1.0\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n            self.assertEqual(\n                sorted(headers.keys()),\n                [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"],\n            )\n            self.assertEqual(headers[\"connection\"], \"close\")\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_after_start_response_http11(self):\n        to_send = b\"GET /after_start_response HTTP/1.1\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n            self.assertEqual(\n                sorted(headers.keys()),\n                [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"],\n            )\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_after_start_response_http11_close(self):\n        to_send = b\"GET /after_start_response HTTP/1.1\\r\\nConnection: close\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n            self.assertEqual(\n                sorted(headers.keys()),\n                [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"],\n            )\n            self.assertEqual(headers[\"connection\"], \"close\")\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_after_write_cb(self):\n        to_send = b\"GET /after_write_cb HTTP/1.1\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            self.assertEqual(response_body, b\"\")\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_in_generator(self):\n        to_send = b\"GET /in_generator HTTP/1.1\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            self.assertEqual(response_body, b\"\")\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n\nclass FileWrapperTests:\n    def setUp(self):\n        from tests.fixtureapps import filewrapper\n\n        self.start_subprocess(filewrapper.app)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_filelike_http11(self):\n        to_send = b\"GET /filelike HTTP/1.1\\r\\n\\r\\n\"\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            with self.sock.makefile(\"rb\", 0) as fp:\n                line, headers, response_body = read_http(fp)\n                self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n                cl = int(headers[\"content-length\"])\n                self.assertEqual(cl, len(response_body))\n                ct = headers[\"content-type\"]\n                self.assertEqual(ct, \"image/jpeg\")\n                self.assertTrue(b\"\\377\\330\\377\" in response_body)\n                # connection has not been closed\n\n    def test_filelike_nocl_http11(self):\n        to_send = b\"GET /filelike_nocl HTTP/1.1\\r\\n\\r\\n\"\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            with self.sock.makefile(\"rb\", 0) as fp:\n                line, headers, response_body = read_http(fp)\n                self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n                cl = int(headers[\"content-length\"])\n                self.assertEqual(cl, len(response_body))\n                ct = headers[\"content-type\"]\n                self.assertEqual(ct, \"image/jpeg\")\n                self.assertTrue(b\"\\377\\330\\377\" in response_body)\n                # connection has not been closed\n\n    def test_filelike_shortcl_http11(self):\n        to_send = b\"GET /filelike_shortcl HTTP/1.1\\r\\n\\r\\n\"\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            with self.sock.makefile(\"rb\", 0) as fp:\n                line, headers, response_body = read_http(fp)\n                self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n                cl = int(headers[\"content-length\"])\n                self.assertEqual(cl, 1)\n                self.assertEqual(cl, len(response_body))\n                ct = headers[\"content-type\"]\n                self.assertEqual(ct, \"image/jpeg\")\n                self.assertTrue(b\"\\377\" in response_body)\n                # connection has not been closed\n\n    def test_filelike_longcl_http11(self):\n        to_send = b\"GET /filelike_longcl HTTP/1.1\\r\\n\\r\\n\"\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            with self.sock.makefile(\"rb\", 0) as fp:\n                line, headers, response_body = read_http(fp)\n                self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n                cl = int(headers[\"content-length\"])\n                self.assertEqual(cl, len(response_body))\n                ct = headers[\"content-type\"]\n                self.assertEqual(ct, \"image/jpeg\")\n                self.assertTrue(b\"\\377\\330\\377\" in response_body)\n                # connection has not been closed\n\n    def test_notfilelike_http11(self):\n        to_send = b\"GET /notfilelike HTTP/1.1\\r\\n\\r\\n\"\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            with self.sock.makefile(\"rb\", 0) as fp:\n                line, headers, response_body = read_http(fp)\n                self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n                cl = int(headers[\"content-length\"])\n                self.assertEqual(cl, len(response_body))\n                ct = headers[\"content-type\"]\n                self.assertEqual(ct, \"image/jpeg\")\n                self.assertTrue(b\"\\377\\330\\377\" in response_body)\n                # connection has not been closed\n\n    def test_notfilelike_iobase_http11(self):\n        to_send = b\"GET /notfilelike_iobase HTTP/1.1\\r\\n\\r\\n\"\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            with self.sock.makefile(\"rb\", 0) as fp:\n                line, headers, response_body = read_http(fp)\n                self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n                cl = int(headers[\"content-length\"])\n                self.assertEqual(cl, len(response_body))\n                ct = headers[\"content-type\"]\n                self.assertEqual(ct, \"image/jpeg\")\n                self.assertTrue(b\"\\377\\330\\377\" in response_body)\n                # connection has not been closed\n\n    def test_notfilelike_nocl_http11(self):\n        to_send = b\"GET /notfilelike_nocl HTTP/1.1\\r\\n\\r\\n\"\n\n        self.connect()\n\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\\330\\377\" in response_body)\n            # connection has been closed (no content-length)\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_notfilelike_shortcl_http11(self):\n        to_send = b\"GET /notfilelike_shortcl HTTP/1.1\\r\\n\\r\\n\"\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            with self.sock.makefile(\"rb\", 0) as fp:\n                line, headers, response_body = read_http(fp)\n                self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n                cl = int(headers[\"content-length\"])\n                self.assertEqual(cl, 1)\n                self.assertEqual(cl, len(response_body))\n                ct = headers[\"content-type\"]\n                self.assertEqual(ct, \"image/jpeg\")\n                self.assertTrue(b\"\\377\" in response_body)\n                # connection has not been closed\n\n    def test_notfilelike_longcl_http11(self):\n        to_send = b\"GET /notfilelike_longcl HTTP/1.1\\r\\n\\r\\n\"\n\n        self.connect()\n\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body) + 10)\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\\330\\377\" in response_body)\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_filelike_http10(self):\n        to_send = b\"GET /filelike HTTP/1.0\\r\\n\\r\\n\"\n\n        self.connect()\n\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\\330\\377\" in response_body)\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_filelike_nocl_http10(self):\n        to_send = b\"GET /filelike_nocl HTTP/1.0\\r\\n\\r\\n\"\n\n        self.connect()\n\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\\330\\377\" in response_body)\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_notfilelike_http10(self):\n        to_send = b\"GET /notfilelike HTTP/1.0\\r\\n\\r\\n\"\n\n        self.connect()\n\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\\330\\377\" in response_body)\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_notfilelike_nocl_http10(self):\n        to_send = b\"GET /notfilelike_nocl HTTP/1.0\\r\\n\\r\\n\"\n\n        self.connect()\n\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\\330\\377\" in response_body)\n            # connection has been closed (no content-length)\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n\nclass TcpEchoTests(EchoTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpPipeliningTests(PipeliningTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpExpectContinueTests(ExpectContinueTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpBadContentLengthTests(BadContentLengthTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpNoContentLengthTests(NoContentLengthTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpWriteCallbackTests(WriteCallbackTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpTooLargeTests(TooLargeTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpInternalServerErrorTests(\n    InternalServerErrorTests, TcpTests, unittest.TestCase\n):\n    pass\n\n\nclass TcpFileWrapperTests(FileWrapperTests, TcpTests, unittest.TestCase):\n    pass\n\n\nif hasattr(socket, \"AF_UNIX\"):\n\n    class FixtureUnixWSGIServer(server.UnixWSGIServer):\n        \"\"\"A version of UnixWSGIServer that relays back what it's bound to.\"\"\"\n\n        family = socket.AF_UNIX  # Testing\n\n        def __init__(self, application, queue, **kw):  # pragma: no cover\n            # Coverage doesn't see this as it's ran in a separate process.\n            # To permit parallel testing, use a PID-dependent socket.\n            kw[\"unix_socket\"] = \"/tmp/waitress.test-%d.sock\" % os.getpid()\n            super().__init__(application, **kw)\n            queue.put(self.socket.getsockname())\n\n    class UnixTests(SubprocessTests):\n\n        server = FixtureUnixWSGIServer\n\n        def make_http_connection(self):\n            return UnixHTTPConnection(self.bound_to)\n\n        def stop_subprocess(self):\n            super().stop_subprocess()\n            cleanup_unix_socket(self.bound_to)\n\n        def send_check_error(self, to_send):\n            # Unlike inet domain sockets, Unix domain sockets can trigger a\n            # 'Broken pipe' error when the socket it closed.\n            try:\n                self.sock.send(to_send)\n            except OSError as exc:\n                valid_errors = {errno.EPIPE, errno.ENOTCONN}\n                self.assertIn(get_errno(exc), valid_errors)\n\n    class UnixEchoTests(EchoTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixPipeliningTests(PipeliningTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixExpectContinueTests(ExpectContinueTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixBadContentLengthTests(\n        BadContentLengthTests, UnixTests, unittest.TestCase\n    ):\n        pass\n\n    class UnixNoContentLengthTests(NoContentLengthTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixWriteCallbackTests(WriteCallbackTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixTooLargeTests(TooLargeTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixInternalServerErrorTests(\n        InternalServerErrorTests, UnixTests, unittest.TestCase\n    ):\n        pass\n\n    class UnixFileWrapperTests(FileWrapperTests, UnixTests, unittest.TestCase):\n        pass\n\n\ndef parse_headers(fp):\n    \"\"\"Parses only RFC2822 headers from a file pointer.\"\"\"\n    headers = {}\n\n    while True:\n        line = fp.readline()\n\n        if line in (b\"\\r\\n\", b\"\\n\", b\"\"):\n            break\n        line = line.decode(\"iso-8859-1\")\n        name, value = line.strip().split(\":\", 1)\n        headers[name.lower().strip()] = value.lower().strip()\n\n    return headers\n\n\nclass UnixHTTPConnection(httplib.HTTPConnection):\n    \"\"\"Patched version of HTTPConnection that uses Unix domain sockets.\"\"\"\n\n    def __init__(self, path):\n        httplib.HTTPConnection.__init__(self, \"localhost\")\n        self.path = path\n\n    def connect(self):\n        sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n        sock.connect(self.path)\n        self.sock = sock\n\n    def close(self):\n        self.sock.close()\n\n\nclass ConnectionClosed(Exception):\n    pass\n\n\n# stolen from gevent\ndef read_http(fp):  # pragma: no cover\n    try:\n        response_line = fp.readline()\n    except OSError as exc:\n        fp.close()\n        # errno 104 is ENOTRECOVERABLE, In WinSock 10054 is ECONNRESET\n\n        if get_errno(exc) in (errno.ECONNABORTED, errno.ECONNRESET, 104, 10054):\n            raise ConnectionClosed\n        raise\n\n    if not response_line:\n        raise ConnectionClosed\n\n    header_lines = []\n\n    while True:\n        line = fp.readline()\n\n        if line in (b\"\\r\\n\", b\"\\r\\n\", b\"\"):\n            break\n        else:\n            header_lines.append(line)\n    headers = dict()\n\n    for x in header_lines:\n        x = x.strip()\n\n        if not x:\n            continue\n        key, value = x.split(b\": \", 1)\n        key = key.decode(\"iso-8859-1\").lower()\n        value = value.decode(\"iso-8859-1\")\n        assert key not in headers, \"%s header duplicated\" % key\n        headers[key] = value\n\n    if \"content-length\" in headers:\n        num = int(headers[\"content-length\"])\n        body = b\"\"\n        left = num\n\n        while left > 0:\n            data = fp.read(left)\n\n            if not data:\n                break\n            body += data\n            left -= len(data)\n    else:\n        # read until EOF\n        body = fp.read()\n\n    return response_line, headers, body\n\n\n# stolen from gevent\ndef get_errno(exc):  # pragma: no cover\n    \"\"\"Get the error code out of socket.error objects.\n    socket.error in <2.5 does not have errno attribute\n    socket.error in 3.x does not allow indexing access\n    e.args[0] works for all.\n    There are cases when args[0] is not errno.\n    i.e. http://bugs.python.org/issue6471\n    Maybe there are cases when errno is set, but it is not the first argument?\n    \"\"\"\n    try:\n        if exc.errno is not None:\n            return exc.errno\n    except AttributeError:\n        pass\n    try:\n        return exc.args[0]\n    except IndexError:\n        return None\n\n\ndef chunks(l, n):\n    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n\n    for i in range(0, len(l), n):\n        yield l[i : i + n]\n", "##############################################################################\n#\n# Copyright (c) 2002 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\n\"\"\"HTTP Request Parser tests\n\"\"\"\nimport unittest\n\nfrom waitress.adjustments import Adjustments\nfrom waitress.parser import (\n    HTTPRequestParser,\n    ParsingError,\n    TransferEncodingNotImplemented,\n    crack_first_line,\n    get_header_lines,\n    split_uri,\n    unquote_bytes_to_wsgi,\n)\nfrom waitress.utilities import (\n    BadRequest,\n    RequestEntityTooLarge,\n    RequestHeaderFieldsTooLarge,\n    ServerNotImplemented,\n)\n\n\nclass TestHTTPRequestParser(unittest.TestCase):\n    def setUp(self):\n\n        my_adj = Adjustments()\n        self.parser = HTTPRequestParser(my_adj)\n\n    def test_get_body_stream_None(self):\n        self.parser.body_recv = None\n        result = self.parser.get_body_stream()\n        self.assertEqual(result.getvalue(), b\"\")\n\n    def test_get_body_stream_nonNone(self):\n        body_rcv = DummyBodyStream()\n        self.parser.body_rcv = body_rcv\n        result = self.parser.get_body_stream()\n        self.assertEqual(result, body_rcv)\n\n    def test_received_get_no_headers(self):\n        data = b\"HTTP/1.0 GET /foobar\\r\\n\\r\\n\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 24)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(self.parser.headers, {})\n\n    def test_received_bad_host_header(self):\n        data = b\"HTTP/1.0 GET /foobar\\r\\n Host: foo\\r\\n\\r\\n\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 36)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(self.parser.error.__class__, BadRequest)\n\n    def test_received_bad_transfer_encoding(self):\n        data = (\n            b\"GET /foobar HTTP/1.1\\r\\n\"\n            b\"Transfer-Encoding: foo\\r\\n\"\n            b\"\\r\\n\"\n            b\"1d;\\r\\n\"\n            b\"This string has 29 characters\\r\\n\"\n            b\"0\\r\\n\\r\\n\"\n        )\n        result = self.parser.received(data)\n        self.assertEqual(result, 48)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(self.parser.error.__class__, ServerNotImplemented)\n\n    def test_received_nonsense_nothing(self):\n        data = b\"\\r\\n\\r\\n\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 4)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(self.parser.headers, {})\n\n    def test_received_no_doublecr(self):\n        data = b\"GET /foobar HTTP/8.4\\r\\n\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 22)\n        self.assertFalse(self.parser.completed)\n        self.assertEqual(self.parser.headers, {})\n\n    def test_received_already_completed(self):\n        self.parser.completed = True\n        result = self.parser.received(b\"a\")\n        self.assertEqual(result, 0)\n\n    def test_received_cl_too_large(self):\n\n        self.parser.adj.max_request_body_size = 2\n        data = b\"GET /foobar HTTP/8.4\\r\\nContent-Length: 10\\r\\n\\r\\n\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 44)\n        self.assertTrue(self.parser.completed)\n        self.assertTrue(isinstance(self.parser.error, RequestEntityTooLarge))\n\n    def test_received_headers_too_large(self):\n\n        self.parser.adj.max_request_header_size = 2\n        data = b\"GET /foobar HTTP/8.4\\r\\nX-Foo: 1\\r\\n\\r\\n\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 34)\n        self.assertTrue(self.parser.completed)\n        self.assertTrue(isinstance(self.parser.error, RequestHeaderFieldsTooLarge))\n\n    def test_received_body_too_large(self):\n        self.parser.adj.max_request_body_size = 2\n        data = (\n            b\"GET /foobar HTTP/1.1\\r\\n\"\n            b\"Transfer-Encoding: chunked\\r\\n\"\n            b\"X-Foo: 1\\r\\n\"\n            b\"\\r\\n\"\n            b\"1d;\\r\\n\"\n            b\"This string has 29 characters\\r\\n\"\n            b\"0\\r\\n\\r\\n\"\n        )\n\n        result = self.parser.received(data)\n        self.assertEqual(result, 62)\n        self.parser.received(data[result:])\n        self.assertTrue(self.parser.completed)\n        self.assertTrue(isinstance(self.parser.error, RequestEntityTooLarge))\n\n    def test_received_error_from_parser(self):\n        data = (\n            b\"GET /foobar HTTP/1.1\\r\\n\"\n            b\"Transfer-Encoding: chunked\\r\\n\"\n            b\"X-Foo: 1\\r\\n\"\n            b\"\\r\\n\"\n            b\"garbage\\r\\n\"\n        )\n        # header\n        result = self.parser.received(data)\n        # body\n        result = self.parser.received(data[result:])\n        self.assertEqual(result, 9)\n        self.assertTrue(self.parser.completed)\n        self.assertTrue(isinstance(self.parser.error, BadRequest))\n\n    def test_received_chunked_completed_sets_content_length(self):\n        data = (\n            b\"GET /foobar HTTP/1.1\\r\\n\"\n            b\"Transfer-Encoding: chunked\\r\\n\"\n            b\"X-Foo: 1\\r\\n\"\n            b\"\\r\\n\"\n            b\"1d;\\r\\n\"\n            b\"This string has 29 characters\\r\\n\"\n            b\"0\\r\\n\\r\\n\"\n        )\n        result = self.parser.received(data)\n        self.assertEqual(result, 62)\n        data = data[result:]\n        result = self.parser.received(data)\n        self.assertTrue(self.parser.completed)\n        self.assertTrue(self.parser.error is None)\n        self.assertEqual(self.parser.headers[\"CONTENT_LENGTH\"], \"29\")\n\n    def test_parse_header_gardenpath(self):\n        data = b\"GET /foobar HTTP/8.4\\r\\nfoo: bar\\r\\n\"\n        self.parser.parse_header(data)\n        self.assertEqual(self.parser.first_line, b\"GET /foobar HTTP/8.4\")\n        self.assertEqual(self.parser.headers[\"FOO\"], \"bar\")\n\n    def test_parse_header_no_cr_in_headerplus(self):\n        data = b\"GET /foobar HTTP/8.4\"\n\n        try:\n            self.parser.parse_header(data)\n        except ParsingError:\n            pass\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_bad_content_length(self):\n        data = b\"GET /foobar HTTP/8.4\\r\\ncontent-length: abc\\r\\n\"\n\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Content-Length is invalid\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_multiple_content_length(self):\n        data = b\"GET /foobar HTTP/8.4\\r\\ncontent-length: 10\\r\\ncontent-length: 20\\r\\n\"\n\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Content-Length is invalid\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_11_te_chunked(self):\n        # NB: test that capitalization of header value is unimportant\n        data = b\"GET /foobar HTTP/1.1\\r\\ntransfer-encoding: ChUnKed\\r\\n\"\n        self.parser.parse_header(data)\n        self.assertEqual(self.parser.body_rcv.__class__.__name__, \"ChunkedReceiver\")\n\n    def test_parse_header_transfer_encoding_invalid(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\ntransfer-encoding: gzip\\r\\n\"\n\n        try:\n            self.parser.parse_header(data)\n        except TransferEncodingNotImplemented as e:\n            self.assertIn(\"Transfer-Encoding requested is not supported.\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_transfer_encoding_invalid_multiple(self):\n\n        data = b\"GET /foobar HTTP/1.1\\r\\ntransfer-encoding: gzip\\r\\ntransfer-encoding: chunked\\r\\n\"\n\n        try:\n            self.parser.parse_header(data)\n        except TransferEncodingNotImplemented as e:\n            self.assertIn(\"Transfer-Encoding requested is not supported.\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_transfer_encoding_invalid_whitespace(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nTransfer-Encoding:\\x85chunked\\r\\n\"\n\n        try:\n            self.parser.parse_header(data)\n        except TransferEncodingNotImplemented as e:\n            self.assertIn(\"Transfer-Encoding requested is not supported.\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_transfer_encoding_invalid_unicode(self):\n        # This is the binary encoding for the UTF-8 character\n        # https://www.compart.com/en/unicode/U+212A \"unicode character \"K\"\"\n        # which if waitress were to accidentally do the wrong thing get\n        # lowercased to just the ascii \"k\" due to unicode collisions during\n        # transformation\n        data = b\"GET /foobar HTTP/1.1\\r\\nTransfer-Encoding: chun\\xe2\\x84\\xaaed\\r\\n\"\n\n        try:\n            self.parser.parse_header(data)\n        except TransferEncodingNotImplemented as e:\n            self.assertIn(\"Transfer-Encoding requested is not supported.\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_11_expect_continue(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nexpect: 100-continue\\r\\n\"\n        self.parser.parse_header(data)\n        self.assertEqual(self.parser.expect_continue, True)\n\n    def test_parse_header_connection_close(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nConnection: close\\r\\n\"\n        self.parser.parse_header(data)\n        self.assertEqual(self.parser.connection_close, True)\n\n    def test_close_with_body_rcv(self):\n        body_rcv = DummyBodyStream()\n        self.parser.body_rcv = body_rcv\n        self.parser.close()\n        self.assertTrue(body_rcv.closed)\n\n    def test_close_with_no_body_rcv(self):\n        self.parser.body_rcv = None\n        self.parser.close()  # doesn't raise\n\n    def test_parse_header_lf_only(self):\n        data = b\"GET /foobar HTTP/8.4\\nfoo: bar\"\n\n        try:\n            self.parser.parse_header(data)\n        except ParsingError:\n            pass\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_cr_only(self):\n        data = b\"GET /foobar HTTP/8.4\\rfoo: bar\"\n        try:\n            self.parser.parse_header(data)\n        except ParsingError:\n            pass\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_extra_lf_in_header(self):\n        data = b\"GET /foobar HTTP/8.4\\r\\nfoo: \\nbar\\r\\n\"\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Bare CR or LF found in header line\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_extra_lf_in_first_line(self):\n        data = b\"GET /foobar\\n HTTP/8.4\\r\\n\"\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Bare CR or LF found in HTTP message\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_invalid_whitespace(self):\n        data = b\"GET /foobar HTTP/8.4\\r\\nfoo : bar\\r\\n\"\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Invalid header\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_invalid_whitespace_vtab(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nfoo:\\x0bbar\\r\\n\"\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Invalid header\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_invalid_no_colon(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nfoo: bar\\r\\nnotvalid\\r\\n\"\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Invalid header\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_invalid_folding_spacing(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nfoo: bar\\r\\n\\t\\x0bbaz\\r\\n\"\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Invalid header\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_invalid_chars(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nfoo: bar\\r\\nfoo: \\x0bbaz\\r\\n\"\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Invalid header\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_empty(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nfoo: bar\\r\\nempty:\\r\\n\"\n        self.parser.parse_header(data)\n\n        self.assertIn(\"EMPTY\", self.parser.headers)\n        self.assertIn(\"FOO\", self.parser.headers)\n        self.assertEqual(self.parser.headers[\"EMPTY\"], \"\")\n        self.assertEqual(self.parser.headers[\"FOO\"], \"bar\")\n\n    def test_parse_header_multiple_values(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nfoo: bar, whatever, more, please, yes\\r\\n\"\n        self.parser.parse_header(data)\n\n        self.assertIn(\"FOO\", self.parser.headers)\n        self.assertEqual(self.parser.headers[\"FOO\"], \"bar, whatever, more, please, yes\")\n\n    def test_parse_header_multiple_values_header_folded(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nfoo: bar, whatever,\\r\\n more, please, yes\\r\\n\"\n        self.parser.parse_header(data)\n\n        self.assertIn(\"FOO\", self.parser.headers)\n        self.assertEqual(self.parser.headers[\"FOO\"], \"bar, whatever, more, please, yes\")\n\n    def test_parse_header_multiple_values_header_folded_multiple(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nfoo: bar, whatever,\\r\\n more\\r\\nfoo: please, yes\\r\\n\"\n        self.parser.parse_header(data)\n\n        self.assertIn(\"FOO\", self.parser.headers)\n        self.assertEqual(self.parser.headers[\"FOO\"], \"bar, whatever, more, please, yes\")\n\n    def test_parse_header_multiple_values_extra_space(self):\n        # Tests errata from: https://www.rfc-editor.org/errata_search.php?rfc=7230&eid=4189\n        data = b\"GET /foobar HTTP/1.1\\r\\nfoo: abrowser/0.001 (C O M M E N T)\\r\\n\"\n        self.parser.parse_header(data)\n\n        self.assertIn(\"FOO\", self.parser.headers)\n        self.assertEqual(self.parser.headers[\"FOO\"], \"abrowser/0.001 (C O M M E N T)\")\n\n    def test_parse_header_invalid_backtrack_bad(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nfoo: bar\\r\\nfoo: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\\x10\\r\\n\"\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Invalid header\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_short_values(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\none: 1\\r\\ntwo: 22\\r\\n\"\n        self.parser.parse_header(data)\n\n        self.assertIn(\"ONE\", self.parser.headers)\n        self.assertIn(\"TWO\", self.parser.headers)\n        self.assertEqual(self.parser.headers[\"ONE\"], \"1\")\n        self.assertEqual(self.parser.headers[\"TWO\"], \"22\")\n\n\nclass Test_split_uri(unittest.TestCase):\n    def _callFUT(self, uri):\n        (\n            self.proxy_scheme,\n            self.proxy_netloc,\n            self.path,\n            self.query,\n            self.fragment,\n        ) = split_uri(uri)\n\n    def test_split_uri_unquoting_unneeded(self):\n        self._callFUT(b\"http://localhost:8080/abc def\")\n        self.assertEqual(self.path, \"/abc def\")\n\n    def test_split_uri_unquoting_needed(self):\n        self._callFUT(b\"http://localhost:8080/abc%20def\")\n        self.assertEqual(self.path, \"/abc def\")\n\n    def test_split_url_with_query(self):\n        self._callFUT(b\"http://localhost:8080/abc?a=1&b=2\")\n        self.assertEqual(self.path, \"/abc\")\n        self.assertEqual(self.query, \"a=1&b=2\")\n\n    def test_split_url_with_query_empty(self):\n        self._callFUT(b\"http://localhost:8080/abc?\")\n        self.assertEqual(self.path, \"/abc\")\n        self.assertEqual(self.query, \"\")\n\n    def test_split_url_with_fragment(self):\n        self._callFUT(b\"http://localhost:8080/#foo\")\n        self.assertEqual(self.path, \"/\")\n        self.assertEqual(self.fragment, \"foo\")\n\n    def test_split_url_https(self):\n        self._callFUT(b\"https://localhost:8080/\")\n        self.assertEqual(self.path, \"/\")\n        self.assertEqual(self.proxy_scheme, \"https\")\n        self.assertEqual(self.proxy_netloc, \"localhost:8080\")\n\n    def test_split_uri_unicode_error_raises_parsing_error(self):\n        # See https://github.com/Pylons/waitress/issues/64\n\n        # Either pass or throw a ParsingError, just don't throw another type of\n        # exception as that will cause the connection to close badly:\n        try:\n            self._callFUT(b\"/\\xd0\")\n        except ParsingError:\n            pass\n\n    def test_split_uri_path(self):\n        self._callFUT(b\"//testing/whatever\")\n        self.assertEqual(self.path, \"//testing/whatever\")\n        self.assertEqual(self.proxy_scheme, \"\")\n        self.assertEqual(self.proxy_netloc, \"\")\n        self.assertEqual(self.query, \"\")\n        self.assertEqual(self.fragment, \"\")\n\n    def test_split_uri_path_query(self):\n        self._callFUT(b\"//testing/whatever?a=1&b=2\")\n        self.assertEqual(self.path, \"//testing/whatever\")\n        self.assertEqual(self.proxy_scheme, \"\")\n        self.assertEqual(self.proxy_netloc, \"\")\n        self.assertEqual(self.query, \"a=1&b=2\")\n        self.assertEqual(self.fragment, \"\")\n\n    def test_split_uri_path_query_fragment(self):\n        self._callFUT(b\"//testing/whatever?a=1&b=2#fragment\")\n        self.assertEqual(self.path, \"//testing/whatever\")\n        self.assertEqual(self.proxy_scheme, \"\")\n        self.assertEqual(self.proxy_netloc, \"\")\n        self.assertEqual(self.query, \"a=1&b=2\")\n        self.assertEqual(self.fragment, \"fragment\")\n\n\nclass Test_get_header_lines(unittest.TestCase):\n    def _callFUT(self, data):\n        return get_header_lines(data)\n\n    def test_get_header_lines(self):\n        result = self._callFUT(b\"slam\\r\\nslim\")\n        self.assertEqual(result, [b\"slam\", b\"slim\"])\n\n    def test_get_header_lines_folded(self):\n        # From RFC2616:\n        # HTTP/1.1 header field values can be folded onto multiple lines if the\n        # continuation line begins with a space or horizontal tab. All linear\n        # white space, including folding, has the same semantics as SP. A\n        # recipient MAY replace any linear white space with a single SP before\n        # interpreting the field value or forwarding the message downstream.\n\n        # We are just preserving the whitespace that indicates folding.\n        result = self._callFUT(b\"slim\\r\\n slam\")\n        self.assertEqual(result, [b\"slim slam\"])\n\n    def test_get_header_lines_tabbed(self):\n        result = self._callFUT(b\"slam\\r\\n\\tslim\")\n        self.assertEqual(result, [b\"slam\\tslim\"])\n\n    def test_get_header_lines_malformed(self):\n        # https://corte.si/posts/code/pathod/pythonservers/index.html\n        self.assertRaises(ParsingError, self._callFUT, b\" Host: localhost\\r\\n\\r\\n\")\n\n\nclass Test_crack_first_line(unittest.TestCase):\n    def _callFUT(self, line):\n        return crack_first_line(line)\n\n    def test_crack_first_line_matchok(self):\n        result = self._callFUT(b\"GET / HTTP/1.0\")\n        self.assertEqual(result, (b\"GET\", b\"/\", b\"1.0\"))\n\n    def test_crack_first_line_lowercase_method(self):\n        self.assertRaises(ParsingError, self._callFUT, b\"get / HTTP/1.0\")\n\n    def test_crack_first_line_nomatch(self):\n        result = self._callFUT(b\"GET / bleh\")\n        self.assertEqual(result, (b\"\", b\"\", b\"\"))\n\n        result = self._callFUT(b\"GET /info?txtAirPlay&txtRAOP RTSP/1.0\")\n        self.assertEqual(result, (b\"\", b\"\", b\"\"))\n\n    def test_crack_first_line_missing_version(self):\n        result = self._callFUT(b\"GET /\")\n        self.assertEqual(result, (b\"GET\", b\"/\", b\"\"))\n\n\nclass TestHTTPRequestParserIntegration(unittest.TestCase):\n    def setUp(self):\n        my_adj = Adjustments()\n        self.parser = HTTPRequestParser(my_adj)\n\n    def feed(self, data):\n        parser = self.parser\n\n        for n in range(100):  # make sure we never loop forever\n            consumed = parser.received(data)\n            data = data[consumed:]\n\n            if parser.completed:\n                return\n        raise ValueError(\"Looping\")  # pragma: no cover\n\n    def testSimpleGET(self):\n        data = (\n            b\"GET /foobar HTTP/8.4\\r\\n\"\n            b\"FirstName: mickey\\r\\n\"\n            b\"lastname: Mouse\\r\\n\"\n            b\"content-length: 6\\r\\n\"\n            b\"\\r\\n\"\n            b\"Hello.\"\n        )\n        parser = self.parser\n        self.feed(data)\n        self.assertTrue(parser.completed)\n        self.assertEqual(parser.version, \"8.4\")\n        self.assertFalse(parser.empty)\n        self.assertEqual(\n            parser.headers,\n            {\n                \"FIRSTNAME\": \"mickey\",\n                \"LASTNAME\": \"Mouse\",\n                \"CONTENT_LENGTH\": \"6\",\n            },\n        )\n        self.assertEqual(parser.path, \"/foobar\")\n        self.assertEqual(parser.command, \"GET\")\n        self.assertEqual(parser.query, \"\")\n        self.assertEqual(parser.proxy_scheme, \"\")\n        self.assertEqual(parser.proxy_netloc, \"\")\n        self.assertEqual(parser.get_body_stream().getvalue(), b\"Hello.\")\n\n    def testComplexGET(self):\n        data = (\n            b\"GET /foo/a+%2B%2F%C3%A4%3D%26a%3Aint?d=b+%2B%2F%3D%26b%3Aint&c+%2B%2F%3D%26c%3Aint=6 HTTP/8.4\\r\\n\"\n            b\"FirstName: mickey\\r\\n\"\n            b\"lastname: Mouse\\r\\n\"\n            b\"content-length: 10\\r\\n\"\n            b\"\\r\\n\"\n            b\"Hello mickey.\"\n        )\n        parser = self.parser\n        self.feed(data)\n        self.assertEqual(parser.command, \"GET\")\n        self.assertEqual(parser.version, \"8.4\")\n        self.assertFalse(parser.empty)\n        self.assertEqual(\n            parser.headers,\n            {\"FIRSTNAME\": \"mickey\", \"LASTNAME\": \"Mouse\", \"CONTENT_LENGTH\": \"10\"},\n        )\n        # path should be utf-8 encoded\n        self.assertEqual(\n            parser.path.encode(\"latin-1\").decode(\"utf-8\"),\n            b\"/foo/a++/\\xc3\\xa4=&a:int\".decode(\"utf-8\"),\n        )\n        # parser.request_uri should preserve the % escape sequences and the query string.\n        self.assertEqual(\n            parser.request_uri,\n            \"/foo/a+%2B%2F%C3%A4%3D%26a%3Aint?d=b+%2B%2F%3D%26b%3Aint&c+%2B%2F%3D%26c%3Aint=6\",\n        )\n        self.assertEqual(\n            parser.query, \"d=b+%2B%2F%3D%26b%3Aint&c+%2B%2F%3D%26c%3Aint=6\"\n        )\n        self.assertEqual(parser.get_body_stream().getvalue(), b\"Hello mick\")\n\n    def testProxyGET(self):\n        data = (\n            b\"GET https://example.com:8080/foobar HTTP/8.4\\r\\n\"\n            b\"content-length: 6\\r\\n\"\n            b\"\\r\\n\"\n            b\"Hello.\"\n        )\n        parser = self.parser\n        self.feed(data)\n        self.assertTrue(parser.completed)\n        self.assertEqual(parser.version, \"8.4\")\n        self.assertFalse(parser.empty)\n        self.assertEqual(parser.headers, {\"CONTENT_LENGTH\": \"6\"})\n        self.assertEqual(parser.path, \"/foobar\")\n        self.assertEqual(parser.command, \"GET\")\n        self.assertEqual(parser.proxy_scheme, \"https\")\n        self.assertEqual(parser.proxy_netloc, \"example.com:8080\")\n        self.assertEqual(parser.command, \"GET\")\n        self.assertEqual(parser.query, \"\")\n        self.assertEqual(parser.get_body_stream().getvalue(), b\"Hello.\")\n\n    def testDuplicateHeaders(self):\n        # Ensure that headers with the same key get concatenated as per\n        # RFC2616.\n        data = (\n            b\"GET /foobar HTTP/8.4\\r\\n\"\n            b\"x-forwarded-for: 10.11.12.13\\r\\n\"\n            b\"x-forwarded-for: unknown,127.0.0.1\\r\\n\"\n            b\"X-Forwarded_for: 255.255.255.255\\r\\n\"\n            b\"content-length: 6\\r\\n\"\n            b\"\\r\\n\"\n            b\"Hello.\"\n        )\n        self.feed(data)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(\n            self.parser.headers,\n            {\n                \"CONTENT_LENGTH\": \"6\",\n                \"X_FORWARDED_FOR\": \"10.11.12.13, unknown,127.0.0.1\",\n            },\n        )\n\n    def testSpoofedHeadersDropped(self):\n        data = (\n            b\"GET /foobar HTTP/8.4\\r\\n\"\n            b\"x-auth_user: bob\\r\\n\"\n            b\"content-length: 6\\r\\n\"\n            b\"\\r\\n\"\n            b\"Hello.\"\n        )\n        self.feed(data)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(\n            self.parser.headers,\n            {\n                \"CONTENT_LENGTH\": \"6\",\n            },\n        )\n\n\nclass Test_unquote_bytes_to_wsgi(unittest.TestCase):\n    def _callFUT(self, v):\n\n        return unquote_bytes_to_wsgi(v)\n\n    def test_highorder(self):\n        val = b\"/a%C5%9B\"\n        result = self._callFUT(val)\n        # PEP 3333 urlunquoted-latin1-decoded-bytes\n        self.assertEqual(result, \"/a\u00c5\\x9b\")\n\n\nclass DummyBodyStream:\n    def getfile(self):\n        return self\n\n    def getbuf(self):\n        return self\n\n    def close(self):\n        self.closed = True\n", "import unittest\n\n\nclass TestFixedStreamReceiver(unittest.TestCase):\n    def _makeOne(self, cl, buf):\n        from waitress.receiver import FixedStreamReceiver\n\n        return FixedStreamReceiver(cl, buf)\n\n    def test_received_remain_lt_1(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(0, buf)\n        result = inst.received(\"a\")\n        self.assertEqual(result, 0)\n        self.assertEqual(inst.completed, True)\n\n    def test_received_remain_lte_datalen(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(1, buf)\n        result = inst.received(\"aa\")\n        self.assertEqual(result, 1)\n        self.assertEqual(inst.completed, True)\n        self.assertEqual(inst.completed, 1)\n        self.assertEqual(inst.remain, 0)\n        self.assertEqual(buf.data, [\"a\"])\n\n    def test_received_remain_gt_datalen(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(10, buf)\n        result = inst.received(\"aa\")\n        self.assertEqual(result, 2)\n        self.assertEqual(inst.completed, False)\n        self.assertEqual(inst.remain, 8)\n        self.assertEqual(buf.data, [\"aa\"])\n\n    def test_getfile(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(10, buf)\n        self.assertEqual(inst.getfile(), buf)\n\n    def test_getbuf(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(10, buf)\n        self.assertEqual(inst.getbuf(), buf)\n\n    def test___len__(self):\n        buf = DummyBuffer([\"1\", \"2\"])\n        inst = self._makeOne(10, buf)\n        self.assertEqual(inst.__len__(), 2)\n\n\nclass TestChunkedReceiver(unittest.TestCase):\n    def _makeOne(self, buf):\n        from waitress.receiver import ChunkedReceiver\n\n        return ChunkedReceiver(buf)\n\n    def test_alreadycompleted(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.completed = True\n        result = inst.received(b\"a\")\n        self.assertEqual(result, 0)\n        self.assertEqual(inst.completed, True)\n\n    def test_received_remain_gt_zero(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.chunk_remainder = 100\n        result = inst.received(b\"a\")\n        self.assertEqual(inst.chunk_remainder, 99)\n        self.assertEqual(result, 1)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_control_line_notfinished(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        result = inst.received(b\"a\")\n        self.assertEqual(inst.control_line, b\"a\")\n        self.assertEqual(result, 1)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_control_line_finished_garbage_in_input(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        result = inst.received(b\"garbage\\r\\n\")\n        self.assertEqual(result, 9)\n        self.assertTrue(inst.error)\n\n    def test_received_control_line_finished_all_chunks_not_received(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        result = inst.received(b\"a;discard\\r\\n\")\n        self.assertEqual(inst.control_line, b\"\")\n        self.assertEqual(inst.chunk_remainder, 10)\n        self.assertEqual(inst.all_chunks_received, False)\n        self.assertEqual(result, 11)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_control_line_finished_all_chunks_received(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        result = inst.received(b\"0;discard\\r\\n\")\n        self.assertEqual(inst.control_line, b\"\")\n        self.assertEqual(inst.all_chunks_received, True)\n        self.assertEqual(result, 11)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_trailer_startswith_crlf(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.all_chunks_received = True\n        result = inst.received(b\"\\r\\n\")\n        self.assertEqual(result, 2)\n        self.assertEqual(inst.completed, True)\n\n    def test_received_trailer_startswith_lf(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.all_chunks_received = True\n        result = inst.received(b\"\\n\")\n        self.assertEqual(result, 1)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_trailer_not_finished(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.all_chunks_received = True\n        result = inst.received(b\"a\")\n        self.assertEqual(result, 1)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_trailer_finished(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.all_chunks_received = True\n        result = inst.received(b\"abc\\r\\n\\r\\n\")\n        self.assertEqual(inst.trailer, b\"abc\\r\\n\\r\\n\")\n        self.assertEqual(result, 7)\n        self.assertEqual(inst.completed, True)\n\n    def test_getfile(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        self.assertEqual(inst.getfile(), buf)\n\n    def test_getbuf(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        self.assertEqual(inst.getbuf(), buf)\n\n    def test___len__(self):\n        buf = DummyBuffer([\"1\", \"2\"])\n        inst = self._makeOne(buf)\n        self.assertEqual(inst.__len__(), 2)\n\n    def test_received_chunk_is_properly_terminated(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        data = b\"4\\r\\nWiki\\r\\n\"\n        result = inst.received(data)\n        self.assertEqual(result, len(data))\n        self.assertEqual(inst.completed, False)\n        self.assertEqual(buf.data[0], b\"Wiki\")\n\n    def test_received_chunk_not_properly_terminated(self):\n        from waitress.utilities import BadRequest\n\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        data = b\"4\\r\\nWikibadchunk\\r\\n\"\n        result = inst.received(data)\n        self.assertEqual(result, len(data))\n        self.assertEqual(inst.completed, False)\n        self.assertEqual(buf.data[0], b\"Wiki\")\n        self.assertEqual(inst.error.__class__, BadRequest)\n\n    def test_received_multiple_chunks(self):\n        from waitress.utilities import BadRequest\n\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        data = (\n            b\"4\\r\\n\"\n            b\"Wiki\\r\\n\"\n            b\"5\\r\\n\"\n            b\"pedia\\r\\n\"\n            b\"E\\r\\n\"\n            b\" in\\r\\n\"\n            b\"\\r\\n\"\n            b\"chunks.\\r\\n\"\n            b\"0\\r\\n\"\n            b\"\\r\\n\"\n        )\n        result = inst.received(data)\n        self.assertEqual(result, len(data))\n        self.assertEqual(inst.completed, True)\n        self.assertEqual(b\"\".join(buf.data), b\"Wikipedia in\\r\\n\\r\\nchunks.\")\n        self.assertEqual(inst.error, None)\n\n    def test_received_multiple_chunks_split(self):\n        from waitress.utilities import BadRequest\n\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        data1 = b\"4\\r\\nWiki\\r\"\n        result = inst.received(data1)\n        self.assertEqual(result, len(data1))\n\n        data2 = (\n            b\"\\n5\\r\\n\"\n            b\"pedia\\r\\n\"\n            b\"E\\r\\n\"\n            b\" in\\r\\n\"\n            b\"\\r\\n\"\n            b\"chunks.\\r\\n\"\n            b\"0\\r\\n\"\n            b\"\\r\\n\"\n        )\n\n        result = inst.received(data2)\n        self.assertEqual(result, len(data2))\n\n        self.assertEqual(inst.completed, True)\n        self.assertEqual(b\"\".join(buf.data), b\"Wikipedia in\\r\\n\\r\\nchunks.\")\n        self.assertEqual(inst.error, None)\n\n\nclass DummyBuffer:\n    def __init__(self, data=None):\n        if data is None:\n            data = []\n        self.data = data\n\n    def append(self, s):\n        self.data.append(s)\n\n    def getfile(self):\n        return self\n\n    def __len__(self):\n        return len(self.data)\n"], "fixing_code": ["2.1.1\n-----\n\nSecurity Bugfix\n~~~~~~~~~~~~~~~\n\n- Waitress now validates that chunked encoding extensions are valid, and don't\n  contain invalid characters that are not allowed. They are still skipped/not\n  processed, but if they contain invalid data we no longer continue in and\n  return a 400 Bad Request. This stops potential HTTP desync/HTTP request\n  smuggling. Thanks to Zhang Zeyu for reporting this issue. See\n  https://github.com/Pylons/waitress/security/advisories/GHSA-4f7p-27jc-3c36\n\n- Waitress now validates that the chunk length is only valid hex digits when\n  parsing chunked encoding, and values such as ``0x01`` and ``+01`` are no\n  longer supported. This stops potential HTTP desync/HTTP request smuggling.\n  Thanks to Zhang Zeyu for reporting this issue. See\n  https://github.com/Pylons/waitress/security/advisories/GHSA-4f7p-27jc-3c36\n\n- Waitress now validates that the Content-Length sent by a remote contains only\n  digits in accordance with RFC7230 and will return a 400 Bad Request when the\n  Content-Length header contains invalid data, such as ``+10`` which would\n  previously get parsed as ``10`` and accepted. This stops potential HTTP\n  desync/HTTP request smuggling Thanks to Zhang Zeyu for reporting this issue. See\n  https://github.com/Pylons/waitress/security/advisories/GHSA-4f7p-27jc-3c36\n\n2.1.0\n-----\n\nPython Version Support\n~~~~~~~~~~~~~~~~~~~~~~\n\n- Python 3.6 is no longer supported by Waitress\n\n- Python 3.10 is fully supported by Waitress\n\nBugfix\n~~~~~~\n\n- ``wsgi.file_wrapper`` now sets the ``seekable``, ``seek``, and ``tell``\n  attributes from the underlying file if the underlying file is seekable. This\n  allows WSGI middleware to implement things like range requests for example\n\n  See https://github.com/Pylons/waitress/issues/359 and\n  https://github.com/Pylons/waitress/pull/363\n\n- In Python 3 ``OSError`` is no longer subscriptable, this caused failures on\n  Windows attempting to loop to find an socket that would work for use in the\n  trigger.\n\n  See https://github.com/Pylons/waitress/pull/361\n\n- Fixed an issue whereby ``BytesIO`` objects were not properly closed, and\n  thereby would not get cleaned up until garbage collection would get around to\n  it.\n\n  This led to potential for random memory spikes/memory issues, see\n  https://github.com/Pylons/waitress/pull/358 and\n  https://github.com/Pylons/waitress/issues/357 .\n\n  With thanks to Florian Schulze for testing/vaidating this fix!\n\nFeatures\n~~~~~~~~\n\n- When the WSGI app starts sending data to the output buffer, we now attempt to\n  send data directly to the socket. This avoids needing to wake up the main\n  thread to start sending data. Allowing faster transmission of the first byte.\n  See https://github.com/Pylons/waitress/pull/364\n\n  With thanks to Michael Merickel for being a great rubber ducky!\n\n- Add REQUEST_URI to the WSGI environment.\n\n  REQUEST_URI is similar to ``request_uri`` in nginx. It is a string that\n  contains the request path before separating the query string and\n  decoding ``%``-escaped characters. \n", "[metadata]\nname = waitress\nversion = 2.1.1\ndescription = Waitress WSGI server\nlong_description = file: README.rst, CHANGES.txt\nlong_description_content_type = text/x-rst\nkeywords = waitress wsgi server http\nlicense = ZPL 2.1\nclassifiers =\n    Development Status :: 6 - Mature\n    Environment :: Web Environment\n    Intended Audience :: Developers\n    License :: OSI Approved :: Zope Public License\n    Programming Language :: Python\n    Programming Language :: Python :: 3\n    Programming Language :: Python :: 3.7\n    Programming Language :: Python :: 3.8\n    Programming Language :: Python :: 3.9\n    Programming Language :: Python :: 3.10\n    Programming Language :: Python :: Implementation :: CPython\n    Programming Language :: Python :: Implementation :: PyPy\n    Operating System :: OS Independent\n    Topic :: Internet :: WWW/HTTP\n    Topic :: Internet :: WWW/HTTP :: WSGI\nurl = https://github.com/Pylons/waitress\nproject_urls =\n    Documentation = https://docs.pylonsproject.org/projects/waitress/en/latest/index.html\n    Changelog = https://docs.pylonsproject.org/projects/waitress/en/latest/index.html#change-history\n    Issue Tracker = https://github.com/Pylons/waitress/issues\n\nauthor = Zope Foundation and Contributors\nauthor_email = zope-dev@zope.org\nmaintainer = Pylons Project\nmaintainer_email = pylons-discuss@googlegroups.com\n\n[options]\npackage_dir=\n    =src\npackages=find:\npython_requires = >=3.7.0\n\n[options.entry_points]\npaste.server_runner =\n    main = waitress:serve_paste\nconsole_scripts =\n    waitress-serve = waitress.runner:run\n\n[options.packages.find]\nwhere=src\n\n[options.extras_require]\ntesting =\n    pytest\n    pytest-cover\n    coverage>=5.0\n\ndocs =\n    Sphinx>=1.8.1\n    docutils\n    pylons-sphinx-themes>=1.0.9\n\n[tool:pytest]\npython_files = test_*.py\n# For the benefit of test_wasyncore.py\npython_classes = Test*\ntestpaths =\n    tests\naddopts = --cov -W always\n", "##############################################################################\n#\n# Copyright (c) 2001, 2002 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\n\"\"\"HTTP Request Parser\n\nThis server uses asyncore to accept connections and do initial\nprocessing but threads to do work.\n\"\"\"\nfrom io import BytesIO\nimport re\nfrom urllib import parse\nfrom urllib.parse import unquote_to_bytes\n\nfrom waitress.buffers import OverflowableBuffer\nfrom waitress.receiver import ChunkedReceiver, FixedStreamReceiver\nfrom waitress.rfc7230 import HEADER_FIELD_RE, ONLY_DIGIT_RE\nfrom waitress.utilities import (\n    BadRequest,\n    RequestEntityTooLarge,\n    RequestHeaderFieldsTooLarge,\n    ServerNotImplemented,\n    find_double_newline,\n)\n\n\ndef unquote_bytes_to_wsgi(bytestring):\n    return unquote_to_bytes(bytestring).decode(\"latin-1\")\n\n\nclass ParsingError(Exception):\n    pass\n\n\nclass TransferEncodingNotImplemented(Exception):\n    pass\n\n\nclass HTTPRequestParser:\n    \"\"\"A structure that collects the HTTP request.\n\n    Once the stream is completed, the instance is passed to\n    a server task constructor.\n    \"\"\"\n\n    completed = False  # Set once request is completed.\n    empty = False  # Set if no request was made.\n    expect_continue = False  # client sent \"Expect: 100-continue\" header\n    headers_finished = False  # True when headers have been read\n    header_plus = b\"\"\n    chunked = False\n    content_length = 0\n    header_bytes_received = 0\n    body_bytes_received = 0\n    body_rcv = None\n    version = \"1.0\"\n    error = None\n    connection_close = False\n\n    # Other attributes: first_line, header, headers, command, uri, version,\n    # path, query, fragment\n\n    def __init__(self, adj):\n        \"\"\"\n        adj is an Adjustments object.\n        \"\"\"\n        # headers is a mapping containing keys translated to uppercase\n        # with dashes turned into underscores.\n        self.headers = {}\n        self.adj = adj\n\n    def received(self, data):\n        \"\"\"\n        Receives the HTTP stream for one request.  Returns the number of\n        bytes consumed.  Sets the completed flag once both the header and the\n        body have been received.\n        \"\"\"\n\n        if self.completed:\n            return 0  # Can't consume any more.\n\n        datalen = len(data)\n        br = self.body_rcv\n\n        if br is None:\n            # In header.\n            max_header = self.adj.max_request_header_size\n\n            s = self.header_plus + data\n            index = find_double_newline(s)\n            consumed = 0\n\n            if index >= 0:\n                # If the headers have ended, and we also have part of the body\n                # message in data we still want to validate we aren't going\n                # over our limit for received headers.\n                self.header_bytes_received += index\n                consumed = datalen - (len(s) - index)\n            else:\n                self.header_bytes_received += datalen\n                consumed = datalen\n\n            # If the first line + headers is over the max length, we return a\n            # RequestHeaderFieldsTooLarge error rather than continuing to\n            # attempt to parse the headers.\n\n            if self.header_bytes_received >= max_header:\n                self.parse_header(b\"GET / HTTP/1.0\\r\\n\")\n                self.error = RequestHeaderFieldsTooLarge(\n                    \"exceeds max_header of %s\" % max_header\n                )\n                self.completed = True\n\n                return consumed\n\n            if index >= 0:\n                # Header finished.\n                header_plus = s[:index]\n\n                # Remove preceeding blank lines. This is suggested by\n                # https://tools.ietf.org/html/rfc7230#section-3.5 to support\n                # clients sending an extra CR LF after another request when\n                # using HTTP pipelining\n                header_plus = header_plus.lstrip()\n\n                if not header_plus:\n                    self.empty = True\n                    self.completed = True\n                else:\n                    try:\n                        self.parse_header(header_plus)\n                    except ParsingError as e:\n                        self.error = BadRequest(e.args[0])\n                        self.completed = True\n                    except TransferEncodingNotImplemented as e:\n                        self.error = ServerNotImplemented(e.args[0])\n                        self.completed = True\n                    else:\n                        if self.body_rcv is None:\n                            # no content-length header and not a t-e: chunked\n                            # request\n                            self.completed = True\n\n                        if self.content_length > 0:\n                            max_body = self.adj.max_request_body_size\n                            # we won't accept this request if the content-length\n                            # is too large\n\n                            if self.content_length >= max_body:\n                                self.error = RequestEntityTooLarge(\n                                    \"exceeds max_body of %s\" % max_body\n                                )\n                                self.completed = True\n                self.headers_finished = True\n\n                return consumed\n\n            # Header not finished yet.\n            self.header_plus = s\n\n            return datalen\n        else:\n            # In body.\n            consumed = br.received(data)\n            self.body_bytes_received += consumed\n            max_body = self.adj.max_request_body_size\n\n            if self.body_bytes_received >= max_body:\n                # this will only be raised during t-e: chunked requests\n                self.error = RequestEntityTooLarge(\"exceeds max_body of %s\" % max_body)\n                self.completed = True\n            elif br.error:\n                # garbage in chunked encoding input probably\n                self.error = br.error\n                self.completed = True\n            elif br.completed:\n                # The request (with the body) is ready to use.\n                self.completed = True\n\n                if self.chunked:\n                    # We've converted the chunked transfer encoding request\n                    # body into a normal request body, so we know its content\n                    # length; set the header here.  We already popped the\n                    # TRANSFER_ENCODING header in parse_header, so this will\n                    # appear to the client to be an entirely non-chunked HTTP\n                    # request with a valid content-length.\n                    self.headers[\"CONTENT_LENGTH\"] = str(br.__len__())\n\n            return consumed\n\n    def parse_header(self, header_plus):\n        \"\"\"\n        Parses the header_plus block of text (the headers plus the\n        first line of the request).\n        \"\"\"\n        index = header_plus.find(b\"\\r\\n\")\n\n        if index >= 0:\n            first_line = header_plus[:index].rstrip()\n            header = header_plus[index + 2 :]\n        else:\n            raise ParsingError(\"HTTP message header invalid\")\n\n        if b\"\\r\" in first_line or b\"\\n\" in first_line:\n            raise ParsingError(\"Bare CR or LF found in HTTP message\")\n\n        self.first_line = first_line  # for testing\n\n        lines = get_header_lines(header)\n\n        headers = self.headers\n\n        for line in lines:\n            header = HEADER_FIELD_RE.match(line)\n\n            if not header:\n                raise ParsingError(\"Invalid header\")\n\n            key, value = header.group(\"name\", \"value\")\n\n            if b\"_\" in key:\n                # TODO(xistence): Should we drop this request instead?\n\n                continue\n\n            # Only strip off whitespace that is considered valid whitespace by\n            # RFC7230, don't strip the rest\n            value = value.strip(b\" \\t\")\n            key1 = key.upper().replace(b\"-\", b\"_\").decode(\"latin-1\")\n            # If a header already exists, we append subsequent values\n            # separated by a comma. Applications already need to handle\n            # the comma separated values, as HTTP front ends might do\n            # the concatenation for you (behavior specified in RFC2616).\n            try:\n                headers[key1] += (b\", \" + value).decode(\"latin-1\")\n            except KeyError:\n                headers[key1] = value.decode(\"latin-1\")\n\n        # command, uri, version will be bytes\n        command, uri, version = crack_first_line(first_line)\n        # self.request_uri is like nginx's request_uri:\n        # \"full original request URI (with arguments)\"\n        self.request_uri = uri.decode(\"latin-1\")\n        version = version.decode(\"latin-1\")\n        command = command.decode(\"latin-1\")\n        self.command = command\n        self.version = version\n        (\n            self.proxy_scheme,\n            self.proxy_netloc,\n            self.path,\n            self.query,\n            self.fragment,\n        ) = split_uri(uri)\n        self.url_scheme = self.adj.url_scheme\n        connection = headers.get(\"CONNECTION\", \"\")\n\n        if version == \"1.0\":\n            if connection.lower() != \"keep-alive\":\n                self.connection_close = True\n\n        if version == \"1.1\":\n            # since the server buffers data from chunked transfers and clients\n            # never need to deal with chunked requests, downstream clients\n            # should not see the HTTP_TRANSFER_ENCODING header; we pop it\n            # here\n            te = headers.pop(\"TRANSFER_ENCODING\", \"\")\n\n            # NB: We can not just call bare strip() here because it will also\n            # remove other non-printable characters that we explicitly do not\n            # want removed so that if someone attempts to smuggle a request\n            # with these characters we don't fall prey to it.\n            #\n            # For example \\x85 is stripped by default, but it is not considered\n            # valid whitespace to be stripped by RFC7230.\n            encodings = [\n                encoding.strip(\" \\t\").lower() for encoding in te.split(\",\") if encoding\n            ]\n\n            for encoding in encodings:\n                # Out of the transfer-codings listed in\n                # https://tools.ietf.org/html/rfc7230#section-4 we only support\n                # chunked at this time.\n\n                # Note: the identity transfer-coding was removed in RFC7230:\n                # https://tools.ietf.org/html/rfc7230#appendix-A.2 and is thus\n                # not supported\n\n                if encoding not in {\"chunked\"}:\n                    raise TransferEncodingNotImplemented(\n                        \"Transfer-Encoding requested is not supported.\"\n                    )\n\n            if encodings and encodings[-1] == \"chunked\":\n                self.chunked = True\n                buf = OverflowableBuffer(self.adj.inbuf_overflow)\n                self.body_rcv = ChunkedReceiver(buf)\n            elif encodings:  # pragma: nocover\n                raise TransferEncodingNotImplemented(\n                    \"Transfer-Encoding requested is not supported.\"\n                )\n\n            expect = headers.get(\"EXPECT\", \"\").lower()\n            self.expect_continue = expect == \"100-continue\"\n\n            if connection.lower() == \"close\":\n                self.connection_close = True\n\n        if not self.chunked:\n            cl = headers.get(\"CONTENT_LENGTH\", \"0\")\n\n            if not ONLY_DIGIT_RE.match(cl.encode(\"latin-1\")):\n                raise ParsingError(\"Content-Length is invalid\")\n\n            cl = int(cl)\n            self.content_length = cl\n\n            if cl > 0:\n                buf = OverflowableBuffer(self.adj.inbuf_overflow)\n                self.body_rcv = FixedStreamReceiver(cl, buf)\n\n    def get_body_stream(self):\n        body_rcv = self.body_rcv\n\n        if body_rcv is not None:\n            return body_rcv.getfile()\n        else:\n            return BytesIO()\n\n    def close(self):\n        body_rcv = self.body_rcv\n\n        if body_rcv is not None:\n            body_rcv.getbuf().close()\n\n\ndef split_uri(uri):\n    # urlsplit handles byte input by returning bytes on py3, so\n    # scheme, netloc, path, query, and fragment are bytes\n\n    scheme = netloc = path = query = fragment = b\"\"\n\n    # urlsplit below will treat this as a scheme-less netloc, thereby losing\n    # the original intent of the request. Here we shamelessly stole 4 lines of\n    # code from the CPython stdlib to parse out the fragment and query but\n    # leave the path alone. See\n    # https://github.com/python/cpython/blob/8c9e9b0cd5b24dfbf1424d1f253d02de80e8f5ef/Lib/urllib/parse.py#L465-L468\n    # and https://github.com/Pylons/waitress/issues/260\n\n    if uri[:2] == b\"//\":\n        path = uri\n\n        if b\"#\" in path:\n            path, fragment = path.split(b\"#\", 1)\n\n        if b\"?\" in path:\n            path, query = path.split(b\"?\", 1)\n    else:\n        try:\n            scheme, netloc, path, query, fragment = parse.urlsplit(uri)\n        except UnicodeError:\n            raise ParsingError(\"Bad URI\")\n\n    return (\n        scheme.decode(\"latin-1\"),\n        netloc.decode(\"latin-1\"),\n        unquote_bytes_to_wsgi(path),\n        query.decode(\"latin-1\"),\n        fragment.decode(\"latin-1\"),\n    )\n\n\ndef get_header_lines(header):\n    \"\"\"\n    Splits the header into lines, putting multi-line headers together.\n    \"\"\"\n    r = []\n    lines = header.split(b\"\\r\\n\")\n\n    for line in lines:\n        if not line:\n            continue\n\n        if b\"\\r\" in line or b\"\\n\" in line:\n            raise ParsingError(\n                'Bare CR or LF found in header line \"%s\"' % str(line, \"latin-1\")\n            )\n\n        if line.startswith((b\" \", b\"\\t\")):\n            if not r:\n                # https://corte.si/posts/code/pathod/pythonservers/index.html\n                raise ParsingError('Malformed header line \"%s\"' % str(line, \"latin-1\"))\n            r[-1] += line\n        else:\n            r.append(line)\n\n    return r\n\n\nfirst_line_re = re.compile(\n    b\"([^ ]+) \"\n    b\"((?:[^ :?#]+://[^ ?#/]*(?:[0-9]{1,5})?)?[^ ]+)\"\n    b\"(( HTTP/([0-9.]+))$|$)\"\n)\n\n\ndef crack_first_line(line):\n    m = first_line_re.match(line)\n\n    if m is not None and m.end() == len(line):\n        if m.group(3):\n            version = m.group(5)\n        else:\n            version = b\"\"\n        method = m.group(1)\n\n        # the request methods that are currently defined are all uppercase:\n        # https://www.iana.org/assignments/http-methods/http-methods.xhtml and\n        # the request method is case sensitive according to\n        # https://tools.ietf.org/html/rfc7231#section-4.1\n\n        # By disallowing anything but uppercase methods we save poor\n        # unsuspecting souls from sending lowercase HTTP methods to waitress\n        # and having the request complete, while servers like nginx drop the\n        # request onto the floor.\n\n        if method != method.upper():\n            raise ParsingError('Malformed HTTP method \"%s\"' % str(method, \"latin-1\"))\n        uri = m.group(2)\n\n        return method, uri, version\n    else:\n        return b\"\", b\"\", b\"\"\n", "##############################################################################\n#\n# Copyright (c) 2001, 2002 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\n\"\"\"Data Chunk Receiver\n\"\"\"\n\nfrom waitress.rfc7230 import CHUNK_EXT_RE, ONLY_HEXDIG_RE\nfrom waitress.utilities import BadRequest, find_double_newline\n\n\nclass FixedStreamReceiver:\n\n    # See IStreamConsumer\n    completed = False\n    error = None\n\n    def __init__(self, cl, buf):\n        self.remain = cl\n        self.buf = buf\n\n    def __len__(self):\n        return self.buf.__len__()\n\n    def received(self, data):\n        \"See IStreamConsumer\"\n        rm = self.remain\n\n        if rm < 1:\n            self.completed = True  # Avoid any chance of spinning\n\n            return 0\n        datalen = len(data)\n\n        if rm <= datalen:\n            self.buf.append(data[:rm])\n            self.remain = 0\n            self.completed = True\n\n            return rm\n        else:\n            self.buf.append(data)\n            self.remain -= datalen\n\n            return datalen\n\n    def getfile(self):\n        return self.buf.getfile()\n\n    def getbuf(self):\n        return self.buf\n\n\nclass ChunkedReceiver:\n\n    chunk_remainder = 0\n    validate_chunk_end = False\n    control_line = b\"\"\n    chunk_end = b\"\"\n    all_chunks_received = False\n    trailer = b\"\"\n    completed = False\n    error = None\n\n    # max_control_line = 1024\n    # max_trailer = 65536\n\n    def __init__(self, buf):\n        self.buf = buf\n\n    def __len__(self):\n        return self.buf.__len__()\n\n    def received(self, s):\n        # Returns the number of bytes consumed.\n\n        if self.completed:\n            return 0\n        orig_size = len(s)\n\n        while s:\n            rm = self.chunk_remainder\n\n            if rm > 0:\n                # Receive the remainder of a chunk.\n                to_write = s[:rm]\n                self.buf.append(to_write)\n                written = len(to_write)\n                s = s[written:]\n\n                self.chunk_remainder -= written\n\n                if self.chunk_remainder == 0:\n                    self.validate_chunk_end = True\n            elif self.validate_chunk_end:\n                s = self.chunk_end + s\n\n                pos = s.find(b\"\\r\\n\")\n\n                if pos < 0 and len(s) < 2:\n                    self.chunk_end = s\n                    s = b\"\"\n                else:\n                    self.chunk_end = b\"\"\n\n                    if pos == 0:\n                        # Chop off the terminating CR LF from the chunk\n                        s = s[2:]\n                    else:\n                        self.error = BadRequest(\"Chunk not properly terminated\")\n                        self.all_chunks_received = True\n\n                    # Always exit this loop\n                    self.validate_chunk_end = False\n            elif not self.all_chunks_received:\n                # Receive a control line.\n                s = self.control_line + s\n                pos = s.find(b\"\\r\\n\")\n\n                if pos < 0:\n                    # Control line not finished.\n                    self.control_line = s\n                    s = b\"\"\n                else:\n                    # Control line finished.\n                    line = s[:pos]\n                    s = s[pos + 2 :]\n                    self.control_line = b\"\"\n\n                    if line:\n                        # Begin a new chunk.\n                        semi = line.find(b\";\")\n\n                        if semi >= 0:\n                            extinfo = line[semi:]\n                            valid_ext_info = CHUNK_EXT_RE.match(extinfo)\n\n                            if not valid_ext_info:\n                                self.error = BadRequest(\"Invalid chunk extension\")\n                                self.all_chunks_received = True\n\n                                break\n\n                            line = line[:semi]\n\n                        if not ONLY_HEXDIG_RE.match(line):\n                            self.error = BadRequest(\"Invalid chunk size\")\n                            self.all_chunks_received = True\n\n                            break\n\n                        # Can not fail due to matching against the regular\n                        # expression above\n                        sz = int(line, 16)  # hexadecimal\n\n                        if sz > 0:\n                            # Start a new chunk.\n                            self.chunk_remainder = sz\n                        else:\n                            # Finished chunks.\n                            self.all_chunks_received = True\n                    # else expect a control line.\n            else:\n                # Receive the trailer.\n                trailer = self.trailer + s\n\n                if trailer.startswith(b\"\\r\\n\"):\n                    # No trailer.\n                    self.completed = True\n\n                    return orig_size - (len(trailer) - 2)\n                pos = find_double_newline(trailer)\n\n                if pos < 0:\n                    # Trailer not finished.\n                    self.trailer = trailer\n                    s = b\"\"\n                else:\n                    # Finished the trailer.\n                    self.completed = True\n                    self.trailer = trailer[:pos]\n\n                    return orig_size - (len(trailer) - pos)\n\n        return orig_size\n\n    def getfile(self):\n        return self.buf.getfile()\n\n    def getbuf(self):\n        return self.buf\n", "\"\"\"\nThis contains a bunch of RFC7230 definitions and regular expressions that are\nneeded to properly parse HTTP messages.\n\"\"\"\n\nimport re\n\nHEXDIG = \"[0-9a-fA-F]\"\nDIGIT = \"[0-9]\"\n\nWS = \"[ \\t]\"\nOWS = WS + \"{0,}?\"\nRWS = WS + \"{1,}?\"\nBWS = OWS\n\n# RFC 7230 Section 3.2.6 \"Field Value Components\":\n# tchar          = \"!\" / \"#\" / \"$\" / \"%\" / \"&\" / \"'\" / \"*\"\n#                / \"+\" / \"-\" / \".\" / \"^\" / \"_\" / \"`\" / \"|\" / \"~\"\n#                / DIGIT / ALPHA\n# obs-text      = %x80-FF\nTCHAR = r\"[!#$%&'*+\\-.^_`|~0-9A-Za-z]\"\nOBS_TEXT = r\"\\x80-\\xff\"\n\nTOKEN = TCHAR + \"{1,}\"\n\n# RFC 5234 Appendix B.1 \"Core Rules\":\n# VCHAR         =  %x21-7E\n#                  ; visible (printing) characters\nVCHAR = r\"\\x21-\\x7e\"\n\n# The '\\\\' between \\x5b and \\x5d is needed to escape \\x5d (']')\nQDTEXT = \"[\\t \\x21\\x23-\\x5b\\\\\\x5d-\\x7e\" + OBS_TEXT + \"]\"\n\nQUOTED_PAIR = r\"\\\\\" + \"([\\t \" + VCHAR + OBS_TEXT + \"])\"\nQUOTED_STRING = '\"(?:(?:' + QDTEXT + \")|(?:\" + QUOTED_PAIR + '))*\"'\n\n# header-field   = field-name \":\" OWS field-value OWS\n# field-name     = token\n# field-value    = *( field-content / obs-fold )\n# field-content  = field-vchar [ 1*( SP / HTAB ) field-vchar ]\n# field-vchar    = VCHAR / obs-text\n\n# Errata from: https://www.rfc-editor.org/errata_search.php?rfc=7230&eid=4189\n# changes field-content to:\n#\n# field-content  = field-vchar [ 1*( SP / HTAB / field-vchar )\n#                  field-vchar ]\n\nFIELD_VCHAR = \"[\" + VCHAR + OBS_TEXT + \"]\"\n# Field content is more greedy than the ABNF, in that it will match the whole value\nFIELD_CONTENT = FIELD_VCHAR + \"+(?:[ \\t]+\" + FIELD_VCHAR + \"+)*\"\n# Which allows the field value here to just see if there is even a value in the first place\nFIELD_VALUE = \"(?:\" + FIELD_CONTENT + \")?\"\n\n# chunk-ext      = *( \";\" chunk-ext-name [ \"=\" chunk-ext-val ] )\n# chunk-ext-name = token\n# chunk-ext-val  = token / quoted-string\n\nCHUNK_EXT_NAME = TOKEN\nCHUNK_EXT_VAL = \"(?:\" + TOKEN + \")|(?:\" + QUOTED_STRING + \")\"\nCHUNK_EXT = (\n    \"(?:;(?P<extension>\" + CHUNK_EXT_NAME + \")(?:=(?P<value>\" + CHUNK_EXT_VAL + \"))?)*\"\n)\n\n# Pre-compiled regular expressions for use elsewhere\nONLY_HEXDIG_RE = re.compile((\"^\" + HEXDIG + \"+$\").encode(\"latin-1\"))\nONLY_DIGIT_RE = re.compile((\"^\" + DIGIT + \"+$\").encode(\"latin-1\"))\nHEADER_FIELD_RE = re.compile(\n    (\n        \"^(?P<name>\" + TOKEN + \"):\" + OWS + \"(?P<value>\" + FIELD_VALUE + \")\" + OWS + \"$\"\n    ).encode(\"latin-1\")\n)\nQUOTED_PAIR_RE = re.compile(QUOTED_PAIR)\nQUOTED_STRING_RE = re.compile(QUOTED_STRING)\nCHUNK_EXT_RE = re.compile((\"^\" + CHUNK_EXT + \"$\").encode(\"latin-1\"))\n", "##############################################################################\n#\n# Copyright (c) 2004 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\n\"\"\"Utility functions\n\"\"\"\n\nimport calendar\nimport errno\nimport logging\nimport os\nimport re\nimport stat\nimport time\n\nfrom .rfc7230 import QUOTED_PAIR_RE, QUOTED_STRING_RE\n\nlogger = logging.getLogger(\"waitress\")\nqueue_logger = logging.getLogger(\"waitress.queue\")\n\n\ndef find_double_newline(s):\n    \"\"\"Returns the position just after a double newline in the given string.\"\"\"\n    pos = s.find(b\"\\r\\n\\r\\n\")\n\n    if pos >= 0:\n        pos += 4\n\n    return pos\n\n\ndef concat(*args):\n    return \"\".join(args)\n\n\ndef join(seq, field=\" \"):\n    return field.join(seq)\n\n\ndef group(s):\n    return \"(\" + s + \")\"\n\n\nshort_days = [\"sun\", \"mon\", \"tue\", \"wed\", \"thu\", \"fri\", \"sat\"]\nlong_days = [\n    \"sunday\",\n    \"monday\",\n    \"tuesday\",\n    \"wednesday\",\n    \"thursday\",\n    \"friday\",\n    \"saturday\",\n]\n\nshort_day_reg = group(join(short_days, \"|\"))\nlong_day_reg = group(join(long_days, \"|\"))\n\ndaymap = {}\n\nfor i in range(7):\n    daymap[short_days[i]] = i\n    daymap[long_days[i]] = i\n\nhms_reg = join(3 * [group(\"[0-9][0-9]\")], \":\")\n\nmonths = [\n    \"jan\",\n    \"feb\",\n    \"mar\",\n    \"apr\",\n    \"may\",\n    \"jun\",\n    \"jul\",\n    \"aug\",\n    \"sep\",\n    \"oct\",\n    \"nov\",\n    \"dec\",\n]\n\nmonmap = {}\n\nfor i in range(12):\n    monmap[months[i]] = i + 1\n\nmonths_reg = group(join(months, \"|\"))\n\n# From draft-ietf-http-v11-spec-07.txt/3.3.1\n#       Sun, 06 Nov 1994 08:49:37 GMT  ; RFC 822, updated by RFC 1123\n#       Sunday, 06-Nov-94 08:49:37 GMT ; RFC 850, obsoleted by RFC 1036\n#       Sun Nov  6 08:49:37 1994       ; ANSI C's asctime() format\n\n# rfc822 format\nrfc822_date = join(\n    [\n        concat(short_day_reg, \",\"),  # day\n        group(\"[0-9][0-9]?\"),  # date\n        months_reg,  # month\n        group(\"[0-9]+\"),  # year\n        hms_reg,  # hour minute second\n        \"gmt\",\n    ],\n    \" \",\n)\n\nrfc822_reg = re.compile(rfc822_date)\n\n\ndef unpack_rfc822(m):\n    g = m.group\n\n    return (\n        int(g(4)),  # year\n        monmap[g(3)],  # month\n        int(g(2)),  # day\n        int(g(5)),  # hour\n        int(g(6)),  # minute\n        int(g(7)),  # second\n        0,\n        0,\n        0,\n    )\n\n\n# rfc850 format\nrfc850_date = join(\n    [\n        concat(long_day_reg, \",\"),\n        join([group(\"[0-9][0-9]?\"), months_reg, group(\"[0-9]+\")], \"-\"),\n        hms_reg,\n        \"gmt\",\n    ],\n    \" \",\n)\n\nrfc850_reg = re.compile(rfc850_date)\n# they actually unpack the same way\ndef unpack_rfc850(m):\n    g = m.group\n    yr = g(4)\n\n    if len(yr) == 2:\n        yr = \"19\" + yr\n\n    return (\n        int(yr),  # year\n        monmap[g(3)],  # month\n        int(g(2)),  # day\n        int(g(5)),  # hour\n        int(g(6)),  # minute\n        int(g(7)),  # second\n        0,\n        0,\n        0,\n    )\n\n\n# parsdate.parsedate - ~700/sec.\n# parse_http_date    - ~1333/sec.\n\nweekdayname = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\nmonthname = [\n    None,\n    \"Jan\",\n    \"Feb\",\n    \"Mar\",\n    \"Apr\",\n    \"May\",\n    \"Jun\",\n    \"Jul\",\n    \"Aug\",\n    \"Sep\",\n    \"Oct\",\n    \"Nov\",\n    \"Dec\",\n]\n\n\ndef build_http_date(when):\n    year, month, day, hh, mm, ss, wd, y, z = time.gmtime(when)\n\n    return \"%s, %02d %3s %4d %02d:%02d:%02d GMT\" % (\n        weekdayname[wd],\n        day,\n        monthname[month],\n        year,\n        hh,\n        mm,\n        ss,\n    )\n\n\ndef parse_http_date(d):\n    d = d.lower()\n    m = rfc850_reg.match(d)\n\n    if m and m.end() == len(d):\n        retval = int(calendar.timegm(unpack_rfc850(m)))\n    else:\n        m = rfc822_reg.match(d)\n\n        if m and m.end() == len(d):\n            retval = int(calendar.timegm(unpack_rfc822(m)))\n        else:\n            return 0\n\n    return retval\n\n\ndef undquote(value):\n    if value.startswith('\"') and value.endswith('\"'):\n        # So it claims to be DQUOTE'ed, let's validate that\n        matches = QUOTED_STRING_RE.match(value)\n\n        if matches and matches.end() == len(value):\n            # Remove the DQUOTE's from the value\n            value = value[1:-1]\n\n            # Remove all backslashes that are followed by a valid vchar or\n            # obs-text\n            value = QUOTED_PAIR_RE.sub(r\"\\1\", value)\n\n            return value\n    elif not value.startswith('\"') and not value.endswith('\"'):\n        return value\n\n    raise ValueError(\"Invalid quoting in value\")\n\n\ndef cleanup_unix_socket(path):\n    try:\n        st = os.stat(path)\n    except OSError as exc:\n        if exc.errno != errno.ENOENT:\n            raise  # pragma: no cover\n    else:\n        if stat.S_ISSOCK(st.st_mode):\n            try:\n                os.remove(path)\n            except OSError:  # pragma: no cover\n                # avoid race condition error during tests\n                pass\n\n\nclass Error:\n    code = 500\n    reason = \"Internal Server Error\"\n\n    def __init__(self, body):\n        self.body = body\n\n    def to_response(self):\n        status = \"%s %s\" % (self.code, self.reason)\n        body = \"%s\\r\\n\\r\\n%s\" % (self.reason, self.body)\n        tag = \"\\r\\n\\r\\n(generated by waitress)\"\n        body = body + tag\n        headers = [(\"Content-Type\", \"text/plain\")]\n\n        return status, headers, body\n\n    def wsgi_response(self, environ, start_response):\n        status, headers, body = self.to_response()\n        start_response(status, headers)\n        yield body\n\n\nclass BadRequest(Error):\n    code = 400\n    reason = \"Bad Request\"\n\n\nclass RequestHeaderFieldsTooLarge(BadRequest):\n    code = 431\n    reason = \"Request Header Fields Too Large\"\n\n\nclass RequestEntityTooLarge(BadRequest):\n    code = 413\n    reason = \"Request Entity Too Large\"\n\n\nclass InternalServerError(Error):\n    code = 500\n    reason = \"Internal Server Error\"\n\n\nclass ServerNotImplemented(Error):\n    code = 501\n    reason = \"Not Implemented\"\n", "import errno\nfrom http import client as httplib\nimport logging\nimport multiprocessing\nimport os\nimport signal\nimport socket\nimport string\nimport subprocess\nimport sys\nimport time\nimport unittest\n\nfrom waitress import server\nfrom waitress.compat import WIN\nfrom waitress.utilities import cleanup_unix_socket\n\ndn = os.path.dirname\nhere = dn(__file__)\n\n\nclass NullHandler(logging.Handler):  # pragma: no cover\n    \"\"\"A logging handler that swallows all emitted messages.\"\"\"\n\n    def emit(self, record):\n        pass\n\n\ndef start_server(app, svr, queue, **kwargs):  # pragma: no cover\n    \"\"\"Run a fixture application.\"\"\"\n    logging.getLogger(\"waitress\").addHandler(NullHandler())\n    try_register_coverage()\n    svr(app, queue, **kwargs).run()\n\n\ndef try_register_coverage():  # pragma: no cover\n    # Hack around multiprocessing exiting early and not triggering coverage's\n    # atexit handler by always registering a signal handler\n\n    if \"COVERAGE_PROCESS_START\" in os.environ:\n\n        def sigterm(*args):\n            sys.exit(0)\n\n        signal.signal(signal.SIGTERM, sigterm)\n\n\nclass FixtureTcpWSGIServer(server.TcpWSGIServer):\n    \"\"\"A version of TcpWSGIServer that relays back what it's bound to.\"\"\"\n\n    family = socket.AF_INET  # Testing\n\n    def __init__(self, application, queue, **kw):  # pragma: no cover\n        # Coverage doesn't see this as it's ran in a separate process.\n        kw[\"host\"] = \"127.0.0.1\"\n        kw[\"port\"] = 0  # Bind to any available port.\n        super().__init__(application, **kw)\n        host, port = self.socket.getsockname()\n\n        if os.name == \"nt\":\n            host = \"127.0.0.1\"\n        queue.put((host, port))\n\n\nclass SubprocessTests:\n\n    exe = sys.executable\n\n    server = None\n\n    def start_subprocess(self, target, **kw):\n        # Spawn a server process.\n        self.queue = multiprocessing.Queue()\n\n        if \"COVERAGE_RCFILE\" in os.environ:\n            os.environ[\"COVERAGE_PROCESS_START\"] = os.environ[\"COVERAGE_RCFILE\"]\n\n        if not WIN:\n            ctx = multiprocessing.get_context(\"fork\")\n        else:\n            ctx = multiprocessing.get_context(\"spawn\")\n\n        self.proc = ctx.Process(\n            target=start_server,\n            args=(target, self.server, self.queue),\n            kwargs=kw,\n        )\n        self.proc.start()\n\n        if self.proc.exitcode is not None:  # pragma: no cover\n            raise RuntimeError(\"%s didn't start\" % str(target))\n        # Get the socket the server is listening on.\n        self.bound_to = self.queue.get(timeout=5)\n        self.sock = self.create_socket()\n\n    def stop_subprocess(self):\n        if self.proc.exitcode is None:\n            self.proc.terminate()\n        self.sock.close()\n        # This give us one FD back ...\n        self.proc.join()\n        self.proc.close()\n        self.queue.close()\n        self.queue.join_thread()\n\n        # The following is for the benefit of PyPy 3, for some reason it is\n        # holding on to some resources way longer than necessary causing tests\n        # to fail with file desctriptor exceeded errors on macOS which defaults\n        # to 256 file desctriptors per process. While we could use ulimit to\n        # increase the limits before running tests, this works as well and\n        # means we don't need to remember to do that.\n        import gc\n\n        gc.collect()\n\n    def assertline(self, line, status, reason, version):\n        v, s, r = (x.strip() for x in line.split(None, 2))\n        self.assertEqual(s, status.encode(\"latin-1\"))\n        self.assertEqual(r, reason.encode(\"latin-1\"))\n        self.assertEqual(v, version.encode(\"latin-1\"))\n\n    def create_socket(self):\n        return socket.socket(self.server.family, socket.SOCK_STREAM)\n\n    def connect(self):\n        self.sock.connect(self.bound_to)\n\n    def make_http_connection(self):\n        raise NotImplementedError  # pragma: no cover\n\n    def send_check_error(self, to_send):\n        self.sock.send(to_send)\n\n\nclass TcpTests(SubprocessTests):\n\n    server = FixtureTcpWSGIServer\n\n    def make_http_connection(self):\n        return httplib.HTTPConnection(*self.bound_to)\n\n\nclass SleepyThreadTests(TcpTests, unittest.TestCase):\n    # test that sleepy thread doesnt block other requests\n\n    def setUp(self):\n        from tests.fixtureapps import sleepy\n\n        self.start_subprocess(sleepy.app)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_it(self):\n        getline = os.path.join(here, \"fixtureapps\", \"getline.py\")\n        cmds = (\n            [self.exe, getline, \"http://%s:%d/sleepy\" % self.bound_to],\n            [self.exe, getline, \"http://%s:%d/\" % self.bound_to],\n        )\n        r, w = os.pipe()\n        procs = []\n\n        for cmd in cmds:\n            procs.append(subprocess.Popen(cmd, stdout=w))\n        time.sleep(3)\n\n        for proc in procs:\n            if proc.returncode is not None:  # pragma: no cover\n                proc.terminate()\n            proc.wait()\n        # the notsleepy response should always be first returned (it sleeps\n        # for 2 seconds, then returns; the notsleepy response should be\n        # processed in the meantime)\n        result = os.read(r, 10000)\n        os.close(r)\n        os.close(w)\n        self.assertEqual(result, b\"notsleepy returnedsleepy returned\")\n\n\nclass EchoTests:\n    def setUp(self):\n        from tests.fixtureapps import echo\n\n        self.start_subprocess(\n            echo.app,\n            trusted_proxy=\"*\",\n            trusted_proxy_count=1,\n            trusted_proxy_headers={\"x-forwarded-for\", \"x-forwarded-proto\"},\n            clear_untrusted_proxy_headers=True,\n        )\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def _read_echo(self, fp):\n        from tests.fixtureapps import echo\n\n        line, headers, body = read_http(fp)\n\n        return line, headers, echo.parse_response(body)\n\n    def test_date_and_server(self):\n        to_send = b\"GET / HTTP/1.0\\r\\nContent-Length: 0\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, echo = self._read_echo(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            self.assertEqual(headers.get(\"server\"), \"waitress\")\n            self.assertTrue(headers.get(\"date\"))\n\n    def test_bad_host_header(self):\n        # https://corte.si/posts/code/pathod/pythonservers/index.html\n        to_send = b\"GET / HTTP/1.0\\r\\n Host: 0\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"400\", \"Bad Request\", \"HTTP/1.0\")\n            self.assertEqual(headers.get(\"server\"), \"waitress\")\n            self.assertTrue(headers.get(\"date\"))\n\n    def test_send_with_body(self):\n        to_send = b\"GET / HTTP/1.0\\r\\nContent-Length: 5\\r\\n\\r\\n\"\n        to_send += b\"hello\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, echo = self._read_echo(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            self.assertEqual(echo.content_length, \"5\")\n            self.assertEqual(echo.body, b\"hello\")\n\n    def test_send_empty_body(self):\n        to_send = b\"GET / HTTP/1.0\\r\\nContent-Length: 0\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, echo = self._read_echo(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            self.assertEqual(echo.content_length, \"0\")\n            self.assertEqual(echo.body, b\"\")\n\n    def test_multiple_requests_with_body(self):\n        orig_sock = self.sock\n\n        for x in range(3):\n            self.sock = self.create_socket()\n            self.test_send_with_body()\n            self.sock.close()\n        self.sock = orig_sock\n\n    def test_multiple_requests_without_body(self):\n        orig_sock = self.sock\n\n        for x in range(3):\n            self.sock = self.create_socket()\n            self.test_send_empty_body()\n            self.sock.close()\n        self.sock = orig_sock\n\n    def test_without_crlf(self):\n        data = b\"Echo\\r\\nthis\\r\\nplease\"\n        s = (\n            b\"GET / HTTP/1.0\\r\\n\"\n            b\"Connection: close\\r\\n\"\n            b\"Content-Length: %d\\r\\n\"\n            b\"\\r\\n\"\n            b\"%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(s)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, echo = self._read_echo(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            self.assertEqual(int(echo.content_length), len(data))\n            self.assertEqual(len(echo.body), len(data))\n            self.assertEqual(echo.body, (data))\n\n    def test_large_body(self):\n        # 1024 characters.\n        body = b\"This string has 32 characters.\\r\\n\" * 32\n        s = b\"GET / HTTP/1.0\\r\\nContent-Length: %d\\r\\n\\r\\n%s\" % (len(body), body)\n        self.connect()\n        self.sock.send(s)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, echo = self._read_echo(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            self.assertEqual(echo.content_length, \"1024\")\n            self.assertEqual(echo.body, body)\n\n    def test_many_clients(self):\n        conns = []\n\n        for n in range(50):\n            h = self.make_http_connection()\n            h.request(\"GET\", \"/\", headers={\"Accept\": \"text/plain\"})\n            conns.append(h)\n        responses = []\n\n        for h in conns:\n            response = h.getresponse()\n            self.assertEqual(response.status, 200)\n            responses.append(response)\n\n        for response in responses:\n            response.read()\n\n        for h in conns:\n            h.close()\n\n    def test_chunking_request_without_content(self):\n        header = b\"GET / HTTP/1.1\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(header)\n        self.sock.send(b\"0\\r\\n\\r\\n\")\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, echo = self._read_echo(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            self.assertEqual(echo.body, b\"\")\n            self.assertEqual(echo.content_length, \"0\")\n            self.assertFalse(\"transfer-encoding\" in headers)\n\n    def test_chunking_request_with_content(self):\n        control_line = b\"20\\r\\n\"  # 20 hex = 32 dec\n        s = b\"This string has 32 characters.\\r\\n\"\n        expected = s * 12\n        header = b\"GET / HTTP/1.1\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(header)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            for n in range(12):\n                self.sock.send(control_line)\n                self.sock.send(s)\n                self.sock.send(b\"\\r\\n\")  # End the chunk\n            self.sock.send(b\"0\\r\\n\\r\\n\")\n            line, headers, echo = self._read_echo(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            self.assertEqual(echo.body, expected)\n            self.assertEqual(echo.content_length, str(len(expected)))\n            self.assertFalse(\"transfer-encoding\" in headers)\n\n    def test_broken_chunked_encoding(self):\n        control_line = b\"20\\r\\n\"  # 20 hex = 32 dec\n        s = b\"This string has 32 characters.\\r\\n\"\n        to_send = b\"GET / HTTP/1.1\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n\"\n        to_send += control_line + s + b\"\\r\\n\"\n        # garbage in input\n        to_send += b\"garbage\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            # receiver caught garbage and turned it into a 400\n            self.assertline(line, \"400\", \"Bad Request\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            self.assertEqual(\n                sorted(headers.keys()),\n                [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"],\n            )\n            self.assertEqual(headers[\"content-type\"], \"text/plain\")\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_broken_chunked_encoding_invalid_hex(self):\n        control_line = b\"0x20\\r\\n\"  # 20 hex = 32 dec\n        s = b\"This string has 32 characters.\\r\\n\"\n        to_send = b\"GET / HTTP/1.1\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n\"\n        to_send += control_line + s + b\"\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"400\", \"Bad Request\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            self.assertIn(b\"Invalid chunk size\", response_body)\n            self.assertEqual(\n                sorted(headers.keys()),\n                [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"],\n            )\n            self.assertEqual(headers[\"content-type\"], \"text/plain\")\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_broken_chunked_encoding_invalid_extension(self):\n        control_line = b\"20;invalid=\\r\\n\"  # 20 hex = 32 dec\n        s = b\"This string has 32 characters.\\r\\n\"\n        to_send = b\"GET / HTTP/1.1\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n\"\n        to_send += control_line + s + b\"\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"400\", \"Bad Request\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            self.assertIn(b\"Invalid chunk extension\", response_body)\n            self.assertEqual(\n                sorted(headers.keys()),\n                [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"],\n            )\n            self.assertEqual(headers[\"content-type\"], \"text/plain\")\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_broken_chunked_encoding_missing_chunk_end(self):\n        control_line = b\"20\\r\\n\"  # 20 hex = 32 dec\n        s = b\"This string has 32 characters.\\r\\n\"\n        to_send = b\"GET / HTTP/1.1\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n\"\n        to_send += control_line + s\n        # garbage in input\n        to_send += b\"garbage\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            # receiver caught garbage and turned it into a 400\n            self.assertline(line, \"400\", \"Bad Request\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            self.assertTrue(b\"Chunk not properly terminated\" in response_body)\n            self.assertEqual(\n                sorted(headers.keys()),\n                [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"],\n            )\n            self.assertEqual(headers[\"content-type\"], \"text/plain\")\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_keepalive_http_10(self):\n        # Handling of Keep-Alive within HTTP 1.0\n        data = b\"Default: Don't keep me alive\"\n        s = b\"GET / HTTP/1.0\\r\\nContent-Length: %d\\r\\n\\r\\n%s\" % (len(data), data)\n        self.connect()\n        self.sock.send(s)\n        response = httplib.HTTPResponse(self.sock)\n        response.begin()\n        self.assertEqual(int(response.status), 200)\n        connection = response.getheader(\"Connection\", \"\")\n        # We sent no Connection: Keep-Alive header\n        # Connection: close (or no header) is default.\n        self.assertTrue(connection != \"Keep-Alive\")\n\n    def test_keepalive_http10_explicit(self):\n        # If header Connection: Keep-Alive is explicitly sent,\n        # we want to keept the connection open, we also need to return\n        # the corresponding header\n        data = b\"Keep me alive\"\n        s = (\n            b\"GET / HTTP/1.0\\r\\n\"\n            b\"Connection: Keep-Alive\\r\\n\"\n            b\"Content-Length: %d\\r\\n\"\n            b\"\\r\\n\"\n            b\"%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(s)\n        response = httplib.HTTPResponse(self.sock)\n        response.begin()\n        self.assertEqual(int(response.status), 200)\n        connection = response.getheader(\"Connection\", \"\")\n        self.assertEqual(connection, \"Keep-Alive\")\n\n    def test_keepalive_http_11(self):\n        # Handling of Keep-Alive within HTTP 1.1\n\n        # All connections are kept alive, unless stated otherwise\n        data = b\"Default: Keep me alive\"\n        s = b\"GET / HTTP/1.1\\r\\nContent-Length: %d\\r\\n\\r\\n%s\" % (len(data), data)\n        self.connect()\n        self.sock.send(s)\n        response = httplib.HTTPResponse(self.sock)\n        response.begin()\n        self.assertEqual(int(response.status), 200)\n        self.assertTrue(response.getheader(\"connection\") != \"close\")\n\n    def test_keepalive_http11_explicit(self):\n        # Explicitly set keep-alive\n        data = b\"Default: Keep me alive\"\n        s = (\n            b\"GET / HTTP/1.1\\r\\n\"\n            b\"Connection: keep-alive\\r\\n\"\n            b\"Content-Length: %d\\r\\n\"\n            b\"\\r\\n\"\n            b\"%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(s)\n        response = httplib.HTTPResponse(self.sock)\n        response.begin()\n        self.assertEqual(int(response.status), 200)\n        self.assertTrue(response.getheader(\"connection\") != \"close\")\n\n    def test_keepalive_http11_connclose(self):\n        # specifying Connection: close explicitly\n        data = b\"Don't keep me alive\"\n        s = (\n            b\"GET / HTTP/1.1\\r\\n\"\n            b\"Connection: close\\r\\n\"\n            b\"Content-Length: %d\\r\\n\"\n            b\"\\r\\n\"\n            b\"%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(s)\n        response = httplib.HTTPResponse(self.sock)\n        response.begin()\n        self.assertEqual(int(response.status), 200)\n        self.assertEqual(response.getheader(\"connection\"), \"close\")\n\n    def test_proxy_headers(self):\n        to_send = (\n            b\"GET / HTTP/1.0\\r\\n\"\n            b\"Content-Length: 0\\r\\n\"\n            b\"Host: www.google.com:8080\\r\\n\"\n            b\"X-Forwarded-For: 192.168.1.1\\r\\n\"\n            b\"X-Forwarded-Proto: https\\r\\n\"\n            b\"X-Forwarded-Port: 5000\\r\\n\\r\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, echo = self._read_echo(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            self.assertEqual(headers.get(\"server\"), \"waitress\")\n            self.assertTrue(headers.get(\"date\"))\n            self.assertIsNone(echo.headers.get(\"X_FORWARDED_PORT\"))\n            self.assertEqual(echo.headers[\"HOST\"], \"www.google.com:8080\")\n            self.assertEqual(echo.scheme, \"https\")\n            self.assertEqual(echo.remote_addr, \"192.168.1.1\")\n            self.assertEqual(echo.remote_host, \"192.168.1.1\")\n\n\nclass PipeliningTests:\n    def setUp(self):\n        from tests.fixtureapps import echo\n\n        self.start_subprocess(echo.app_body_only)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_pipelining(self):\n        s = (\n            b\"GET / HTTP/1.0\\r\\n\"\n            b\"Connection: %s\\r\\n\"\n            b\"Content-Length: %d\\r\\n\"\n            b\"\\r\\n\"\n            b\"%s\"\n        )\n        to_send = b\"\"\n        count = 25\n\n        for n in range(count):\n            body = b\"Response #%d\\r\\n\" % (n + 1)\n\n            if n + 1 < count:\n                conn = b\"keep-alive\"\n            else:\n                conn = b\"close\"\n            to_send += s % (conn, len(body), body)\n\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            for n in range(count):\n                expect_body = b\"Response #%d\\r\\n\" % (n + 1)\n                line = fp.readline()  # status line\n                version, status, reason = (x.strip() for x in line.split(None, 2))\n                headers = parse_headers(fp)\n                length = int(headers.get(\"content-length\")) or None\n                response_body = fp.read(length)\n                self.assertEqual(int(status), 200)\n                self.assertEqual(length, len(response_body))\n                self.assertEqual(response_body, expect_body)\n\n\nclass ExpectContinueTests:\n    def setUp(self):\n        from tests.fixtureapps import echo\n\n        self.start_subprocess(echo.app_body_only)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_expect_continue(self):\n        # specifying Connection: close explicitly\n        data = b\"I have expectations\"\n        to_send = (\n            b\"GET / HTTP/1.1\\r\\n\"\n            b\"Connection: close\\r\\n\"\n            b\"Content-Length: %d\\r\\n\"\n            b\"Expect: 100-continue\\r\\n\"\n            b\"\\r\\n\"\n            b\"%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line = fp.readline()  # continue status line\n            version, status, reason = (x.strip() for x in line.split(None, 2))\n            self.assertEqual(int(status), 100)\n            self.assertEqual(reason, b\"Continue\")\n            self.assertEqual(version, b\"HTTP/1.1\")\n            fp.readline()  # blank line\n            line = fp.readline()  # next status line\n            version, status, reason = (x.strip() for x in line.split(None, 2))\n            headers = parse_headers(fp)\n            length = int(headers.get(\"content-length\")) or None\n            response_body = fp.read(length)\n            self.assertEqual(int(status), 200)\n            self.assertEqual(length, len(response_body))\n            self.assertEqual(response_body, data)\n\n\nclass BadContentLengthTests:\n    def setUp(self):\n        from tests.fixtureapps import badcl\n\n        self.start_subprocess(badcl.app)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_short_body(self):\n        # check to see if server closes connection when body is too short\n        # for cl header\n        to_send = (\n            b\"GET /short_body HTTP/1.0\\r\\n\"\n            b\"Connection: Keep-Alive\\r\\n\"\n            b\"Content-Length: 0\\r\\n\"\n            b\"\\r\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line = fp.readline()  # status line\n            version, status, reason = (x.strip() for x in line.split(None, 2))\n            headers = parse_headers(fp)\n            content_length = int(headers.get(\"content-length\"))\n            response_body = fp.read(content_length)\n            self.assertEqual(int(status), 200)\n            self.assertNotEqual(content_length, len(response_body))\n            self.assertEqual(len(response_body), content_length - 1)\n            self.assertEqual(response_body, b\"abcdefghi\")\n            # remote closed connection (despite keepalive header); not sure why\n            # first send succeeds\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_long_body(self):\n        # check server doesnt close connection when body is too short\n        # for cl header\n        to_send = (\n            b\"GET /long_body HTTP/1.0\\r\\n\"\n            b\"Connection: Keep-Alive\\r\\n\"\n            b\"Content-Length: 0\\r\\n\"\n            b\"\\r\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line = fp.readline()  # status line\n            version, status, reason = (x.strip() for x in line.split(None, 2))\n            headers = parse_headers(fp)\n            content_length = int(headers.get(\"content-length\")) or None\n            response_body = fp.read(content_length)\n            self.assertEqual(int(status), 200)\n            self.assertEqual(content_length, len(response_body))\n            self.assertEqual(response_body, b\"abcdefgh\")\n            # remote does not close connection (keepalive header)\n            self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line = fp.readline()  # status line\n            version, status, reason = (x.strip() for x in line.split(None, 2))\n            headers = parse_headers(fp)\n            content_length = int(headers.get(\"content-length\")) or None\n            response_body = fp.read(content_length)\n            self.assertEqual(int(status), 200)\n\n\nclass NoContentLengthTests:\n    def setUp(self):\n        from tests.fixtureapps import nocl\n\n        self.start_subprocess(nocl.app)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_http10_generator(self):\n        body = string.ascii_letters.encode(\"latin-1\")\n        to_send = (\n            b\"GET / HTTP/1.0\\r\\n\"\n            b\"Connection: Keep-Alive\\r\\n\"\n            b\"Content-Length: %d\\r\\n\\r\\n\" % len(body)\n        )\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            self.assertEqual(headers.get(\"content-length\"), None)\n            self.assertEqual(headers.get(\"connection\"), \"close\")\n            self.assertEqual(response_body, body)\n            # remote closed connection (despite keepalive header), because\n            # generators cannot have a content-length divined\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_http10_list(self):\n        body = string.ascii_letters.encode(\"latin-1\")\n        to_send = (\n            b\"GET /list HTTP/1.0\\r\\n\"\n            b\"Connection: Keep-Alive\\r\\n\"\n            b\"Content-Length: %d\\r\\n\\r\\n\" % len(body)\n        )\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            self.assertEqual(headers[\"content-length\"], str(len(body)))\n            self.assertEqual(headers.get(\"connection\"), \"Keep-Alive\")\n            self.assertEqual(response_body, body)\n            # remote keeps connection open because it divined the content length\n            # from a length-1 list\n            self.sock.send(to_send)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n\n    def test_http10_listlentwo(self):\n        body = string.ascii_letters.encode(\"latin-1\")\n        to_send = (\n            b\"GET /list_lentwo HTTP/1.0\\r\\n\"\n            b\"Connection: Keep-Alive\\r\\n\"\n            b\"Content-Length: %d\\r\\n\\r\\n\" % len(body)\n        )\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            self.assertEqual(headers.get(\"content-length\"), None)\n            self.assertEqual(headers.get(\"connection\"), \"close\")\n            self.assertEqual(response_body, body)\n            # remote closed connection (despite keepalive header), because\n            # lists of length > 1 cannot have their content length divined\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_http11_generator(self):\n        body = string.ascii_letters\n        body = body.encode(\"latin-1\")\n        to_send = b\"GET / HTTP/1.1\\r\\nContent-Length: %d\\r\\n\\r\\n\" % len(body)\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\") as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            expected = b\"\"\n\n            for chunk in chunks(body, 10):\n                expected += b\"%s\\r\\n%s\\r\\n\" % (\n                    hex(len(chunk))[2:].upper().encode(\"latin-1\"),\n                    chunk,\n                )\n            expected += b\"0\\r\\n\\r\\n\"\n            self.assertEqual(response_body, expected)\n            # connection is always closed at the end of a chunked response\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_http11_list(self):\n        body = string.ascii_letters.encode(\"latin-1\")\n        to_send = b\"GET /list HTTP/1.1\\r\\nContent-Length: %d\\r\\n\\r\\n\" % len(body)\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            self.assertEqual(headers[\"content-length\"], str(len(body)))\n            self.assertEqual(response_body, body)\n            # remote keeps connection open because it divined the content length\n            # from a length-1 list\n            self.sock.send(to_send)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n\n    def test_http11_listlentwo(self):\n        body = string.ascii_letters.encode(\"latin-1\")\n        to_send = b\"GET /list_lentwo HTTP/1.1\\r\\nContent-Length: %d\\r\\n\\r\\n\" % len(body)\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\") as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            expected = b\"\"\n\n            for chunk in (body[:1], body[1:]):\n                expected += b\"%s\\r\\n%s\\r\\n\" % (\n                    (hex(len(chunk))[2:].upper().encode(\"latin-1\")),\n                    chunk,\n                )\n            expected += b\"0\\r\\n\\r\\n\"\n            self.assertEqual(response_body, expected)\n            # connection is always closed at the end of a chunked response\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n\nclass WriteCallbackTests:\n    def setUp(self):\n        from tests.fixtureapps import writecb\n\n        self.start_subprocess(writecb.app)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_short_body(self):\n        # check to see if server closes connection when body is too short\n        # for cl header\n        to_send = (\n            b\"GET /short_body HTTP/1.0\\r\\n\"\n            b\"Connection: Keep-Alive\\r\\n\"\n            b\"Content-Length: 0\\r\\n\"\n            b\"\\r\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            # server trusts the content-length header (5)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, 9)\n            self.assertNotEqual(cl, len(response_body))\n            self.assertEqual(len(response_body), cl - 1)\n            self.assertEqual(response_body, b\"abcdefgh\")\n            # remote closed connection (despite keepalive header)\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_long_body(self):\n        # check server doesnt close connection when body is too long\n        # for cl header\n        to_send = (\n            b\"GET /long_body HTTP/1.0\\r\\n\"\n            b\"Connection: Keep-Alive\\r\\n\"\n            b\"Content-Length: 0\\r\\n\"\n            b\"\\r\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            content_length = int(headers.get(\"content-length\")) or None\n            self.assertEqual(content_length, 9)\n            self.assertEqual(content_length, len(response_body))\n            self.assertEqual(response_body, b\"abcdefghi\")\n            # remote does not close connection (keepalive header)\n            self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n\n    def test_equal_body(self):\n        # check server doesnt close connection when body is equal to\n        # cl header\n        to_send = (\n            b\"GET /equal_body HTTP/1.0\\r\\n\"\n            b\"Connection: Keep-Alive\\r\\n\"\n            b\"Content-Length: 0\\r\\n\"\n            b\"\\r\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            content_length = int(headers.get(\"content-length\")) or None\n            self.assertEqual(content_length, 9)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            self.assertEqual(content_length, len(response_body))\n            self.assertEqual(response_body, b\"abcdefghi\")\n            # remote does not close connection (keepalive header)\n            self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n\n    def test_no_content_length(self):\n        # wtf happens when there's no content-length\n        to_send = (\n            b\"GET /no_content_length HTTP/1.0\\r\\n\"\n            b\"Connection: Keep-Alive\\r\\n\"\n            b\"Content-Length: 0\\r\\n\"\n            b\"\\r\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line = fp.readline()  # status line\n            line, headers, response_body = read_http(fp)\n            content_length = headers.get(\"content-length\")\n            self.assertEqual(content_length, None)\n            self.assertEqual(response_body, b\"abcdefghi\")\n            # remote closed connection (despite keepalive header)\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n\nclass TooLargeTests:\n\n    toobig = 1050\n\n    def setUp(self):\n        from tests.fixtureapps import toolarge\n\n        self.start_subprocess(\n            toolarge.app, max_request_header_size=1000, max_request_body_size=1000\n        )\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_request_headers_too_large_http11(self):\n        body = b\"\"\n        bad_headers = b\"X-Random-Header: 100\\r\\n\" * int(self.toobig / 20)\n        to_send = b\"GET / HTTP/1.1\\r\\nContent-Length: 0\\r\\n\"\n        to_send += bad_headers\n        to_send += b\"\\r\\n\\r\\n\"\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\") as fp:\n            response_line, headers, response_body = read_http(fp)\n            self.assertline(\n                response_line, \"431\", \"Request Header Fields Too Large\", \"HTTP/1.0\"\n            )\n            self.assertEqual(headers[\"connection\"], \"close\")\n\n    def test_request_body_too_large_with_wrong_cl_http10(self):\n        body = b\"a\" * self.toobig\n        to_send = b\"GET / HTTP/1.0\\r\\nContent-Length: 5\\r\\n\\r\\n\"\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\") as fp:\n            # first request succeeds (content-length 5)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            # server trusts the content-length header; no pipelining,\n            # so request fulfilled, extra bytes are thrown away\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_wrong_cl_http10_keepalive(self):\n        body = b\"a\" * self.toobig\n        to_send = (\n            b\"GET / HTTP/1.0\\r\\nContent-Length: 5\\r\\nConnection: Keep-Alive\\r\\n\\r\\n\"\n        )\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\") as fp:\n            # first request succeeds (content-length 5)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"431\", \"Request Header Fields Too Large\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_no_cl_http10(self):\n        body = b\"a\" * self.toobig\n        to_send = b\"GET / HTTP/1.0\\r\\n\\r\\n\"\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            # extra bytes are thrown away (no pipelining), connection closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_no_cl_http10_keepalive(self):\n        body = b\"a\" * self.toobig\n        to_send = b\"GET / HTTP/1.0\\r\\nConnection: Keep-Alive\\r\\n\\r\\n\"\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            # server trusts the content-length header (assumed zero)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            line, headers, response_body = read_http(fp)\n            # next response overruns because the extra data appears to be\n            # header data\n            self.assertline(line, \"431\", \"Request Header Fields Too Large\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_wrong_cl_http11(self):\n        body = b\"a\" * self.toobig\n        to_send = b\"GET / HTTP/1.1\\r\\nContent-Length: 5\\r\\n\\r\\n\"\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\") as fp:\n            # first request succeeds (content-length 5)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            # second response is an error response\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"431\", \"Request Header Fields Too Large\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_wrong_cl_http11_connclose(self):\n        body = b\"a\" * self.toobig\n        to_send = b\"GET / HTTP/1.1\\r\\nContent-Length: 5\\r\\nConnection: close\\r\\n\\r\\n\"\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            # server trusts the content-length header (5)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_no_cl_http11(self):\n        body = b\"a\" * self.toobig\n        to_send = b\"GET / HTTP/1.1\\r\\n\\r\\n\"\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\") as fp:\n            # server trusts the content-length header (assumed 0)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            # server assumes pipelined requests due to http/1.1, and the first\n            # request was assumed c-l 0 because it had no content-length header,\n            # so entire body looks like the header of the subsequent request\n            # second response is an error response\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"431\", \"Request Header Fields Too Large\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_no_cl_http11_connclose(self):\n        body = b\"a\" * self.toobig\n        to_send = b\"GET / HTTP/1.1\\r\\nConnection: close\\r\\n\\r\\n\"\n        to_send += body\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            # server trusts the content-length header (assumed 0)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_chunked_encoding(self):\n        control_line = b\"20;\\r\\n\"  # 20 hex = 32 dec\n        s = b\"This string has 32 characters.\\r\\n\"\n        to_send = b\"GET / HTTP/1.1\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n\"\n        repeat = control_line + s\n        to_send += repeat * ((self.toobig // len(repeat)) + 1)\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            # body bytes counter caught a max_request_body_size overrun\n            self.assertline(line, \"413\", \"Request Entity Too Large\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            self.assertEqual(headers[\"content-type\"], \"text/plain\")\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n\nclass InternalServerErrorTests:\n    def setUp(self):\n        from tests.fixtureapps import error\n\n        self.start_subprocess(error.app, expose_tracebacks=True)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_before_start_response_http_10(self):\n        to_send = b\"GET /before_start_response HTTP/1.0\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n            self.assertEqual(headers[\"connection\"], \"close\")\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_before_start_response_http_11(self):\n        to_send = b\"GET /before_start_response HTTP/1.1\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n            self.assertEqual(\n                sorted(headers.keys()),\n                [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"],\n            )\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_before_start_response_http_11_close(self):\n        to_send = b\"GET /before_start_response HTTP/1.1\\r\\nConnection: close\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n            self.assertEqual(\n                sorted(headers.keys()),\n                [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"],\n            )\n            self.assertEqual(headers[\"connection\"], \"close\")\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_after_start_response_http10(self):\n        to_send = b\"GET /after_start_response HTTP/1.0\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n            self.assertEqual(\n                sorted(headers.keys()),\n                [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"],\n            )\n            self.assertEqual(headers[\"connection\"], \"close\")\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_after_start_response_http11(self):\n        to_send = b\"GET /after_start_response HTTP/1.1\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n            self.assertEqual(\n                sorted(headers.keys()),\n                [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"],\n            )\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_after_start_response_http11_close(self):\n        to_send = b\"GET /after_start_response HTTP/1.1\\r\\nConnection: close\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n            self.assertEqual(\n                sorted(headers.keys()),\n                [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"],\n            )\n            self.assertEqual(headers[\"connection\"], \"close\")\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_after_write_cb(self):\n        to_send = b\"GET /after_write_cb HTTP/1.1\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            self.assertEqual(response_body, b\"\")\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_in_generator(self):\n        to_send = b\"GET /in_generator HTTP/1.1\\r\\n\\r\\n\"\n        self.connect()\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            self.assertEqual(response_body, b\"\")\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n\nclass FileWrapperTests:\n    def setUp(self):\n        from tests.fixtureapps import filewrapper\n\n        self.start_subprocess(filewrapper.app)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_filelike_http11(self):\n        to_send = b\"GET /filelike HTTP/1.1\\r\\n\\r\\n\"\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            with self.sock.makefile(\"rb\", 0) as fp:\n                line, headers, response_body = read_http(fp)\n                self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n                cl = int(headers[\"content-length\"])\n                self.assertEqual(cl, len(response_body))\n                ct = headers[\"content-type\"]\n                self.assertEqual(ct, \"image/jpeg\")\n                self.assertTrue(b\"\\377\\330\\377\" in response_body)\n                # connection has not been closed\n\n    def test_filelike_nocl_http11(self):\n        to_send = b\"GET /filelike_nocl HTTP/1.1\\r\\n\\r\\n\"\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            with self.sock.makefile(\"rb\", 0) as fp:\n                line, headers, response_body = read_http(fp)\n                self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n                cl = int(headers[\"content-length\"])\n                self.assertEqual(cl, len(response_body))\n                ct = headers[\"content-type\"]\n                self.assertEqual(ct, \"image/jpeg\")\n                self.assertTrue(b\"\\377\\330\\377\" in response_body)\n                # connection has not been closed\n\n    def test_filelike_shortcl_http11(self):\n        to_send = b\"GET /filelike_shortcl HTTP/1.1\\r\\n\\r\\n\"\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            with self.sock.makefile(\"rb\", 0) as fp:\n                line, headers, response_body = read_http(fp)\n                self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n                cl = int(headers[\"content-length\"])\n                self.assertEqual(cl, 1)\n                self.assertEqual(cl, len(response_body))\n                ct = headers[\"content-type\"]\n                self.assertEqual(ct, \"image/jpeg\")\n                self.assertTrue(b\"\\377\" in response_body)\n                # connection has not been closed\n\n    def test_filelike_longcl_http11(self):\n        to_send = b\"GET /filelike_longcl HTTP/1.1\\r\\n\\r\\n\"\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            with self.sock.makefile(\"rb\", 0) as fp:\n                line, headers, response_body = read_http(fp)\n                self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n                cl = int(headers[\"content-length\"])\n                self.assertEqual(cl, len(response_body))\n                ct = headers[\"content-type\"]\n                self.assertEqual(ct, \"image/jpeg\")\n                self.assertTrue(b\"\\377\\330\\377\" in response_body)\n                # connection has not been closed\n\n    def test_notfilelike_http11(self):\n        to_send = b\"GET /notfilelike HTTP/1.1\\r\\n\\r\\n\"\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            with self.sock.makefile(\"rb\", 0) as fp:\n                line, headers, response_body = read_http(fp)\n                self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n                cl = int(headers[\"content-length\"])\n                self.assertEqual(cl, len(response_body))\n                ct = headers[\"content-type\"]\n                self.assertEqual(ct, \"image/jpeg\")\n                self.assertTrue(b\"\\377\\330\\377\" in response_body)\n                # connection has not been closed\n\n    def test_notfilelike_iobase_http11(self):\n        to_send = b\"GET /notfilelike_iobase HTTP/1.1\\r\\n\\r\\n\"\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            with self.sock.makefile(\"rb\", 0) as fp:\n                line, headers, response_body = read_http(fp)\n                self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n                cl = int(headers[\"content-length\"])\n                self.assertEqual(cl, len(response_body))\n                ct = headers[\"content-type\"]\n                self.assertEqual(ct, \"image/jpeg\")\n                self.assertTrue(b\"\\377\\330\\377\" in response_body)\n                # connection has not been closed\n\n    def test_notfilelike_nocl_http11(self):\n        to_send = b\"GET /notfilelike_nocl HTTP/1.1\\r\\n\\r\\n\"\n\n        self.connect()\n\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\\330\\377\" in response_body)\n            # connection has been closed (no content-length)\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_notfilelike_shortcl_http11(self):\n        to_send = b\"GET /notfilelike_shortcl HTTP/1.1\\r\\n\\r\\n\"\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            with self.sock.makefile(\"rb\", 0) as fp:\n                line, headers, response_body = read_http(fp)\n                self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n                cl = int(headers[\"content-length\"])\n                self.assertEqual(cl, 1)\n                self.assertEqual(cl, len(response_body))\n                ct = headers[\"content-type\"]\n                self.assertEqual(ct, \"image/jpeg\")\n                self.assertTrue(b\"\\377\" in response_body)\n                # connection has not been closed\n\n    def test_notfilelike_longcl_http11(self):\n        to_send = b\"GET /notfilelike_longcl HTTP/1.1\\r\\n\\r\\n\"\n\n        self.connect()\n\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body) + 10)\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\\330\\377\" in response_body)\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_filelike_http10(self):\n        to_send = b\"GET /filelike HTTP/1.0\\r\\n\\r\\n\"\n\n        self.connect()\n\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\\330\\377\" in response_body)\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_filelike_nocl_http10(self):\n        to_send = b\"GET /filelike_nocl HTTP/1.0\\r\\n\\r\\n\"\n\n        self.connect()\n\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\\330\\377\" in response_body)\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_notfilelike_http10(self):\n        to_send = b\"GET /notfilelike HTTP/1.0\\r\\n\\r\\n\"\n\n        self.connect()\n\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\\330\\377\" in response_body)\n            # connection has been closed\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_notfilelike_nocl_http10(self):\n        to_send = b\"GET /notfilelike_nocl HTTP/1.0\\r\\n\\r\\n\"\n\n        self.connect()\n\n        self.sock.send(to_send)\n        with self.sock.makefile(\"rb\", 0) as fp:\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\\330\\377\" in response_body)\n            # connection has been closed (no content-length)\n            self.send_check_error(to_send)\n            self.assertRaises(ConnectionClosed, read_http, fp)\n\n\nclass TcpEchoTests(EchoTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpPipeliningTests(PipeliningTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpExpectContinueTests(ExpectContinueTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpBadContentLengthTests(BadContentLengthTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpNoContentLengthTests(NoContentLengthTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpWriteCallbackTests(WriteCallbackTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpTooLargeTests(TooLargeTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpInternalServerErrorTests(\n    InternalServerErrorTests, TcpTests, unittest.TestCase\n):\n    pass\n\n\nclass TcpFileWrapperTests(FileWrapperTests, TcpTests, unittest.TestCase):\n    pass\n\n\nif hasattr(socket, \"AF_UNIX\"):\n\n    class FixtureUnixWSGIServer(server.UnixWSGIServer):\n        \"\"\"A version of UnixWSGIServer that relays back what it's bound to.\"\"\"\n\n        family = socket.AF_UNIX  # Testing\n\n        def __init__(self, application, queue, **kw):  # pragma: no cover\n            # Coverage doesn't see this as it's ran in a separate process.\n            # To permit parallel testing, use a PID-dependent socket.\n            kw[\"unix_socket\"] = \"/tmp/waitress.test-%d.sock\" % os.getpid()\n            super().__init__(application, **kw)\n            queue.put(self.socket.getsockname())\n\n    class UnixTests(SubprocessTests):\n\n        server = FixtureUnixWSGIServer\n\n        def make_http_connection(self):\n            return UnixHTTPConnection(self.bound_to)\n\n        def stop_subprocess(self):\n            super().stop_subprocess()\n            cleanup_unix_socket(self.bound_to)\n\n        def send_check_error(self, to_send):\n            # Unlike inet domain sockets, Unix domain sockets can trigger a\n            # 'Broken pipe' error when the socket it closed.\n            try:\n                self.sock.send(to_send)\n            except OSError as exc:\n                valid_errors = {errno.EPIPE, errno.ENOTCONN}\n                self.assertIn(get_errno(exc), valid_errors)\n\n    class UnixEchoTests(EchoTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixPipeliningTests(PipeliningTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixExpectContinueTests(ExpectContinueTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixBadContentLengthTests(\n        BadContentLengthTests, UnixTests, unittest.TestCase\n    ):\n        pass\n\n    class UnixNoContentLengthTests(NoContentLengthTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixWriteCallbackTests(WriteCallbackTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixTooLargeTests(TooLargeTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixInternalServerErrorTests(\n        InternalServerErrorTests, UnixTests, unittest.TestCase\n    ):\n        pass\n\n    class UnixFileWrapperTests(FileWrapperTests, UnixTests, unittest.TestCase):\n        pass\n\n\ndef parse_headers(fp):\n    \"\"\"Parses only RFC2822 headers from a file pointer.\"\"\"\n    headers = {}\n\n    while True:\n        line = fp.readline()\n\n        if line in (b\"\\r\\n\", b\"\\n\", b\"\"):\n            break\n        line = line.decode(\"iso-8859-1\")\n        name, value = line.strip().split(\":\", 1)\n        headers[name.lower().strip()] = value.lower().strip()\n\n    return headers\n\n\nclass UnixHTTPConnection(httplib.HTTPConnection):\n    \"\"\"Patched version of HTTPConnection that uses Unix domain sockets.\"\"\"\n\n    def __init__(self, path):\n        httplib.HTTPConnection.__init__(self, \"localhost\")\n        self.path = path\n\n    def connect(self):\n        sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n        sock.connect(self.path)\n        self.sock = sock\n\n    def close(self):\n        self.sock.close()\n\n\nclass ConnectionClosed(Exception):\n    pass\n\n\n# stolen from gevent\ndef read_http(fp):  # pragma: no cover\n    try:\n        response_line = fp.readline()\n    except OSError as exc:\n        fp.close()\n        # errno 104 is ENOTRECOVERABLE, In WinSock 10054 is ECONNRESET\n\n        if get_errno(exc) in (errno.ECONNABORTED, errno.ECONNRESET, 104, 10054):\n            raise ConnectionClosed\n        raise\n\n    if not response_line:\n        raise ConnectionClosed\n\n    header_lines = []\n\n    while True:\n        line = fp.readline()\n\n        if line in (b\"\\r\\n\", b\"\\r\\n\", b\"\"):\n            break\n        else:\n            header_lines.append(line)\n    headers = dict()\n\n    for x in header_lines:\n        x = x.strip()\n\n        if not x:\n            continue\n        key, value = x.split(b\": \", 1)\n        key = key.decode(\"iso-8859-1\").lower()\n        value = value.decode(\"iso-8859-1\")\n        assert key not in headers, \"%s header duplicated\" % key\n        headers[key] = value\n\n    if \"content-length\" in headers:\n        num = int(headers[\"content-length\"])\n        body = b\"\"\n        left = num\n\n        while left > 0:\n            data = fp.read(left)\n\n            if not data:\n                break\n            body += data\n            left -= len(data)\n    else:\n        # read until EOF\n        body = fp.read()\n\n    return response_line, headers, body\n\n\n# stolen from gevent\ndef get_errno(exc):  # pragma: no cover\n    \"\"\"Get the error code out of socket.error objects.\n    socket.error in <2.5 does not have errno attribute\n    socket.error in 3.x does not allow indexing access\n    e.args[0] works for all.\n    There are cases when args[0] is not errno.\n    i.e. http://bugs.python.org/issue6471\n    Maybe there are cases when errno is set, but it is not the first argument?\n    \"\"\"\n    try:\n        if exc.errno is not None:\n            return exc.errno\n    except AttributeError:\n        pass\n    try:\n        return exc.args[0]\n    except IndexError:\n        return None\n\n\ndef chunks(l, n):\n    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n\n    for i in range(0, len(l), n):\n        yield l[i : i + n]\n", "##############################################################################\n#\n# Copyright (c) 2002 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\n\"\"\"HTTP Request Parser tests\n\"\"\"\nimport unittest\n\nfrom waitress.adjustments import Adjustments\nfrom waitress.parser import (\n    HTTPRequestParser,\n    ParsingError,\n    TransferEncodingNotImplemented,\n    crack_first_line,\n    get_header_lines,\n    split_uri,\n    unquote_bytes_to_wsgi,\n)\nfrom waitress.utilities import (\n    BadRequest,\n    RequestEntityTooLarge,\n    RequestHeaderFieldsTooLarge,\n    ServerNotImplemented,\n)\n\n\nclass TestHTTPRequestParser(unittest.TestCase):\n    def setUp(self):\n\n        my_adj = Adjustments()\n        self.parser = HTTPRequestParser(my_adj)\n\n    def test_get_body_stream_None(self):\n        self.parser.body_recv = None\n        result = self.parser.get_body_stream()\n        self.assertEqual(result.getvalue(), b\"\")\n\n    def test_get_body_stream_nonNone(self):\n        body_rcv = DummyBodyStream()\n        self.parser.body_rcv = body_rcv\n        result = self.parser.get_body_stream()\n        self.assertEqual(result, body_rcv)\n\n    def test_received_get_no_headers(self):\n        data = b\"HTTP/1.0 GET /foobar\\r\\n\\r\\n\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 24)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(self.parser.headers, {})\n\n    def test_received_bad_host_header(self):\n        data = b\"HTTP/1.0 GET /foobar\\r\\n Host: foo\\r\\n\\r\\n\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 36)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(self.parser.error.__class__, BadRequest)\n\n    def test_received_bad_transfer_encoding(self):\n        data = (\n            b\"GET /foobar HTTP/1.1\\r\\n\"\n            b\"Transfer-Encoding: foo\\r\\n\"\n            b\"\\r\\n\"\n            b\"1d;\\r\\n\"\n            b\"This string has 29 characters\\r\\n\"\n            b\"0\\r\\n\\r\\n\"\n        )\n        result = self.parser.received(data)\n        self.assertEqual(result, 48)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(self.parser.error.__class__, ServerNotImplemented)\n\n    def test_received_nonsense_nothing(self):\n        data = b\"\\r\\n\\r\\n\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 4)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(self.parser.headers, {})\n\n    def test_received_no_doublecr(self):\n        data = b\"GET /foobar HTTP/8.4\\r\\n\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 22)\n        self.assertFalse(self.parser.completed)\n        self.assertEqual(self.parser.headers, {})\n\n    def test_received_already_completed(self):\n        self.parser.completed = True\n        result = self.parser.received(b\"a\")\n        self.assertEqual(result, 0)\n\n    def test_received_cl_too_large(self):\n\n        self.parser.adj.max_request_body_size = 2\n        data = b\"GET /foobar HTTP/8.4\\r\\nContent-Length: 10\\r\\n\\r\\n\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 44)\n        self.assertTrue(self.parser.completed)\n        self.assertTrue(isinstance(self.parser.error, RequestEntityTooLarge))\n\n    def test_received_headers_too_large(self):\n\n        self.parser.adj.max_request_header_size = 2\n        data = b\"GET /foobar HTTP/8.4\\r\\nX-Foo: 1\\r\\n\\r\\n\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 34)\n        self.assertTrue(self.parser.completed)\n        self.assertTrue(isinstance(self.parser.error, RequestHeaderFieldsTooLarge))\n\n    def test_received_body_too_large(self):\n        self.parser.adj.max_request_body_size = 2\n        data = (\n            b\"GET /foobar HTTP/1.1\\r\\n\"\n            b\"Transfer-Encoding: chunked\\r\\n\"\n            b\"X-Foo: 1\\r\\n\"\n            b\"\\r\\n\"\n            b\"1d;\\r\\n\"\n            b\"This string has 29 characters\\r\\n\"\n            b\"0\\r\\n\\r\\n\"\n        )\n\n        result = self.parser.received(data)\n        self.assertEqual(result, 62)\n        self.parser.received(data[result:])\n        self.assertTrue(self.parser.completed)\n        self.assertTrue(isinstance(self.parser.error, RequestEntityTooLarge))\n\n    def test_received_error_from_parser(self):\n        data = (\n            b\"GET /foobar HTTP/1.1\\r\\n\"\n            b\"Transfer-Encoding: chunked\\r\\n\"\n            b\"X-Foo: 1\\r\\n\"\n            b\"\\r\\n\"\n            b\"garbage\\r\\n\"\n        )\n        # header\n        result = self.parser.received(data)\n        # body\n        result = self.parser.received(data[result:])\n        self.assertEqual(result, 9)\n        self.assertTrue(self.parser.completed)\n        self.assertTrue(isinstance(self.parser.error, BadRequest))\n\n    def test_received_chunked_completed_sets_content_length(self):\n        data = (\n            b\"GET /foobar HTTP/1.1\\r\\n\"\n            b\"Transfer-Encoding: chunked\\r\\n\"\n            b\"X-Foo: 1\\r\\n\"\n            b\"\\r\\n\"\n            b\"1d\\r\\n\"\n            b\"This string has 29 characters\\r\\n\"\n            b\"0\\r\\n\\r\\n\"\n        )\n        result = self.parser.received(data)\n        self.assertEqual(result, 62)\n        data = data[result:]\n        result = self.parser.received(data)\n        self.assertTrue(self.parser.completed)\n        self.assertTrue(self.parser.error is None)\n        self.assertEqual(self.parser.headers[\"CONTENT_LENGTH\"], \"29\")\n\n    def test_parse_header_gardenpath(self):\n        data = b\"GET /foobar HTTP/8.4\\r\\nfoo: bar\\r\\n\"\n        self.parser.parse_header(data)\n        self.assertEqual(self.parser.first_line, b\"GET /foobar HTTP/8.4\")\n        self.assertEqual(self.parser.headers[\"FOO\"], \"bar\")\n\n    def test_parse_header_no_cr_in_headerplus(self):\n        data = b\"GET /foobar HTTP/8.4\"\n\n        try:\n            self.parser.parse_header(data)\n        except ParsingError:\n            pass\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_bad_content_length(self):\n        data = b\"GET /foobar HTTP/8.4\\r\\ncontent-length: abc\\r\\n\"\n\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Content-Length is invalid\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_bad_content_length_plus(self):\n        data = b\"GET /foobar HTTP/8.4\\r\\ncontent-length: +10\\r\\n\"\n\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Content-Length is invalid\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_bad_content_length_minus(self):\n        data = b\"GET /foobar HTTP/8.4\\r\\ncontent-length: -10\\r\\n\"\n\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Content-Length is invalid\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_multiple_content_length(self):\n        data = b\"GET /foobar HTTP/8.4\\r\\ncontent-length: 10\\r\\ncontent-length: 20\\r\\n\"\n\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Content-Length is invalid\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_11_te_chunked(self):\n        # NB: test that capitalization of header value is unimportant\n        data = b\"GET /foobar HTTP/1.1\\r\\ntransfer-encoding: ChUnKed\\r\\n\"\n        self.parser.parse_header(data)\n        self.assertEqual(self.parser.body_rcv.__class__.__name__, \"ChunkedReceiver\")\n\n    def test_parse_header_transfer_encoding_invalid(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\ntransfer-encoding: gzip\\r\\n\"\n\n        try:\n            self.parser.parse_header(data)\n        except TransferEncodingNotImplemented as e:\n            self.assertIn(\"Transfer-Encoding requested is not supported.\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_transfer_encoding_invalid_multiple(self):\n\n        data = b\"GET /foobar HTTP/1.1\\r\\ntransfer-encoding: gzip\\r\\ntransfer-encoding: chunked\\r\\n\"\n\n        try:\n            self.parser.parse_header(data)\n        except TransferEncodingNotImplemented as e:\n            self.assertIn(\"Transfer-Encoding requested is not supported.\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_transfer_encoding_invalid_whitespace(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nTransfer-Encoding:\\x85chunked\\r\\n\"\n\n        try:\n            self.parser.parse_header(data)\n        except TransferEncodingNotImplemented as e:\n            self.assertIn(\"Transfer-Encoding requested is not supported.\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_transfer_encoding_invalid_unicode(self):\n        # This is the binary encoding for the UTF-8 character\n        # https://www.compart.com/en/unicode/U+212A \"unicode character \"K\"\"\n        # which if waitress were to accidentally do the wrong thing get\n        # lowercased to just the ascii \"k\" due to unicode collisions during\n        # transformation\n        data = b\"GET /foobar HTTP/1.1\\r\\nTransfer-Encoding: chun\\xe2\\x84\\xaaed\\r\\n\"\n\n        try:\n            self.parser.parse_header(data)\n        except TransferEncodingNotImplemented as e:\n            self.assertIn(\"Transfer-Encoding requested is not supported.\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_11_expect_continue(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nexpect: 100-continue\\r\\n\"\n        self.parser.parse_header(data)\n        self.assertEqual(self.parser.expect_continue, True)\n\n    def test_parse_header_connection_close(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nConnection: close\\r\\n\"\n        self.parser.parse_header(data)\n        self.assertEqual(self.parser.connection_close, True)\n\n    def test_close_with_body_rcv(self):\n        body_rcv = DummyBodyStream()\n        self.parser.body_rcv = body_rcv\n        self.parser.close()\n        self.assertTrue(body_rcv.closed)\n\n    def test_close_with_no_body_rcv(self):\n        self.parser.body_rcv = None\n        self.parser.close()  # doesn't raise\n\n    def test_parse_header_lf_only(self):\n        data = b\"GET /foobar HTTP/8.4\\nfoo: bar\"\n\n        try:\n            self.parser.parse_header(data)\n        except ParsingError:\n            pass\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_cr_only(self):\n        data = b\"GET /foobar HTTP/8.4\\rfoo: bar\"\n        try:\n            self.parser.parse_header(data)\n        except ParsingError:\n            pass\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_extra_lf_in_header(self):\n        data = b\"GET /foobar HTTP/8.4\\r\\nfoo: \\nbar\\r\\n\"\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Bare CR or LF found in header line\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_extra_lf_in_first_line(self):\n        data = b\"GET /foobar\\n HTTP/8.4\\r\\n\"\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Bare CR or LF found in HTTP message\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_invalid_whitespace(self):\n        data = b\"GET /foobar HTTP/8.4\\r\\nfoo : bar\\r\\n\"\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Invalid header\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_invalid_whitespace_vtab(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nfoo:\\x0bbar\\r\\n\"\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Invalid header\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_invalid_no_colon(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nfoo: bar\\r\\nnotvalid\\r\\n\"\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Invalid header\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_invalid_folding_spacing(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nfoo: bar\\r\\n\\t\\x0bbaz\\r\\n\"\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Invalid header\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_invalid_chars(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nfoo: bar\\r\\nfoo: \\x0bbaz\\r\\n\"\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Invalid header\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_empty(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nfoo: bar\\r\\nempty:\\r\\n\"\n        self.parser.parse_header(data)\n\n        self.assertIn(\"EMPTY\", self.parser.headers)\n        self.assertIn(\"FOO\", self.parser.headers)\n        self.assertEqual(self.parser.headers[\"EMPTY\"], \"\")\n        self.assertEqual(self.parser.headers[\"FOO\"], \"bar\")\n\n    def test_parse_header_multiple_values(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nfoo: bar, whatever, more, please, yes\\r\\n\"\n        self.parser.parse_header(data)\n\n        self.assertIn(\"FOO\", self.parser.headers)\n        self.assertEqual(self.parser.headers[\"FOO\"], \"bar, whatever, more, please, yes\")\n\n    def test_parse_header_multiple_values_header_folded(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nfoo: bar, whatever,\\r\\n more, please, yes\\r\\n\"\n        self.parser.parse_header(data)\n\n        self.assertIn(\"FOO\", self.parser.headers)\n        self.assertEqual(self.parser.headers[\"FOO\"], \"bar, whatever, more, please, yes\")\n\n    def test_parse_header_multiple_values_header_folded_multiple(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nfoo: bar, whatever,\\r\\n more\\r\\nfoo: please, yes\\r\\n\"\n        self.parser.parse_header(data)\n\n        self.assertIn(\"FOO\", self.parser.headers)\n        self.assertEqual(self.parser.headers[\"FOO\"], \"bar, whatever, more, please, yes\")\n\n    def test_parse_header_multiple_values_extra_space(self):\n        # Tests errata from: https://www.rfc-editor.org/errata_search.php?rfc=7230&eid=4189\n        data = b\"GET /foobar HTTP/1.1\\r\\nfoo: abrowser/0.001 (C O M M E N T)\\r\\n\"\n        self.parser.parse_header(data)\n\n        self.assertIn(\"FOO\", self.parser.headers)\n        self.assertEqual(self.parser.headers[\"FOO\"], \"abrowser/0.001 (C O M M E N T)\")\n\n    def test_parse_header_invalid_backtrack_bad(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nfoo: bar\\r\\nfoo: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\\x10\\r\\n\"\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Invalid header\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_short_values(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\none: 1\\r\\ntwo: 22\\r\\n\"\n        self.parser.parse_header(data)\n\n        self.assertIn(\"ONE\", self.parser.headers)\n        self.assertIn(\"TWO\", self.parser.headers)\n        self.assertEqual(self.parser.headers[\"ONE\"], \"1\")\n        self.assertEqual(self.parser.headers[\"TWO\"], \"22\")\n\n\nclass Test_split_uri(unittest.TestCase):\n    def _callFUT(self, uri):\n        (\n            self.proxy_scheme,\n            self.proxy_netloc,\n            self.path,\n            self.query,\n            self.fragment,\n        ) = split_uri(uri)\n\n    def test_split_uri_unquoting_unneeded(self):\n        self._callFUT(b\"http://localhost:8080/abc def\")\n        self.assertEqual(self.path, \"/abc def\")\n\n    def test_split_uri_unquoting_needed(self):\n        self._callFUT(b\"http://localhost:8080/abc%20def\")\n        self.assertEqual(self.path, \"/abc def\")\n\n    def test_split_url_with_query(self):\n        self._callFUT(b\"http://localhost:8080/abc?a=1&b=2\")\n        self.assertEqual(self.path, \"/abc\")\n        self.assertEqual(self.query, \"a=1&b=2\")\n\n    def test_split_url_with_query_empty(self):\n        self._callFUT(b\"http://localhost:8080/abc?\")\n        self.assertEqual(self.path, \"/abc\")\n        self.assertEqual(self.query, \"\")\n\n    def test_split_url_with_fragment(self):\n        self._callFUT(b\"http://localhost:8080/#foo\")\n        self.assertEqual(self.path, \"/\")\n        self.assertEqual(self.fragment, \"foo\")\n\n    def test_split_url_https(self):\n        self._callFUT(b\"https://localhost:8080/\")\n        self.assertEqual(self.path, \"/\")\n        self.assertEqual(self.proxy_scheme, \"https\")\n        self.assertEqual(self.proxy_netloc, \"localhost:8080\")\n\n    def test_split_uri_unicode_error_raises_parsing_error(self):\n        # See https://github.com/Pylons/waitress/issues/64\n\n        # Either pass or throw a ParsingError, just don't throw another type of\n        # exception as that will cause the connection to close badly:\n        try:\n            self._callFUT(b\"/\\xd0\")\n        except ParsingError:\n            pass\n\n    def test_split_uri_path(self):\n        self._callFUT(b\"//testing/whatever\")\n        self.assertEqual(self.path, \"//testing/whatever\")\n        self.assertEqual(self.proxy_scheme, \"\")\n        self.assertEqual(self.proxy_netloc, \"\")\n        self.assertEqual(self.query, \"\")\n        self.assertEqual(self.fragment, \"\")\n\n    def test_split_uri_path_query(self):\n        self._callFUT(b\"//testing/whatever?a=1&b=2\")\n        self.assertEqual(self.path, \"//testing/whatever\")\n        self.assertEqual(self.proxy_scheme, \"\")\n        self.assertEqual(self.proxy_netloc, \"\")\n        self.assertEqual(self.query, \"a=1&b=2\")\n        self.assertEqual(self.fragment, \"\")\n\n    def test_split_uri_path_query_fragment(self):\n        self._callFUT(b\"//testing/whatever?a=1&b=2#fragment\")\n        self.assertEqual(self.path, \"//testing/whatever\")\n        self.assertEqual(self.proxy_scheme, \"\")\n        self.assertEqual(self.proxy_netloc, \"\")\n        self.assertEqual(self.query, \"a=1&b=2\")\n        self.assertEqual(self.fragment, \"fragment\")\n\n\nclass Test_get_header_lines(unittest.TestCase):\n    def _callFUT(self, data):\n        return get_header_lines(data)\n\n    def test_get_header_lines(self):\n        result = self._callFUT(b\"slam\\r\\nslim\")\n        self.assertEqual(result, [b\"slam\", b\"slim\"])\n\n    def test_get_header_lines_folded(self):\n        # From RFC2616:\n        # HTTP/1.1 header field values can be folded onto multiple lines if the\n        # continuation line begins with a space or horizontal tab. All linear\n        # white space, including folding, has the same semantics as SP. A\n        # recipient MAY replace any linear white space with a single SP before\n        # interpreting the field value or forwarding the message downstream.\n\n        # We are just preserving the whitespace that indicates folding.\n        result = self._callFUT(b\"slim\\r\\n slam\")\n        self.assertEqual(result, [b\"slim slam\"])\n\n    def test_get_header_lines_tabbed(self):\n        result = self._callFUT(b\"slam\\r\\n\\tslim\")\n        self.assertEqual(result, [b\"slam\\tslim\"])\n\n    def test_get_header_lines_malformed(self):\n        # https://corte.si/posts/code/pathod/pythonservers/index.html\n        self.assertRaises(ParsingError, self._callFUT, b\" Host: localhost\\r\\n\\r\\n\")\n\n\nclass Test_crack_first_line(unittest.TestCase):\n    def _callFUT(self, line):\n        return crack_first_line(line)\n\n    def test_crack_first_line_matchok(self):\n        result = self._callFUT(b\"GET / HTTP/1.0\")\n        self.assertEqual(result, (b\"GET\", b\"/\", b\"1.0\"))\n\n    def test_crack_first_line_lowercase_method(self):\n        self.assertRaises(ParsingError, self._callFUT, b\"get / HTTP/1.0\")\n\n    def test_crack_first_line_nomatch(self):\n        result = self._callFUT(b\"GET / bleh\")\n        self.assertEqual(result, (b\"\", b\"\", b\"\"))\n\n        result = self._callFUT(b\"GET /info?txtAirPlay&txtRAOP RTSP/1.0\")\n        self.assertEqual(result, (b\"\", b\"\", b\"\"))\n\n    def test_crack_first_line_missing_version(self):\n        result = self._callFUT(b\"GET /\")\n        self.assertEqual(result, (b\"GET\", b\"/\", b\"\"))\n\n\nclass TestHTTPRequestParserIntegration(unittest.TestCase):\n    def setUp(self):\n        my_adj = Adjustments()\n        self.parser = HTTPRequestParser(my_adj)\n\n    def feed(self, data):\n        parser = self.parser\n\n        for n in range(100):  # make sure we never loop forever\n            consumed = parser.received(data)\n            data = data[consumed:]\n\n            if parser.completed:\n                return\n        raise ValueError(\"Looping\")  # pragma: no cover\n\n    def testSimpleGET(self):\n        data = (\n            b\"GET /foobar HTTP/8.4\\r\\n\"\n            b\"FirstName: mickey\\r\\n\"\n            b\"lastname: Mouse\\r\\n\"\n            b\"content-length: 6\\r\\n\"\n            b\"\\r\\n\"\n            b\"Hello.\"\n        )\n        parser = self.parser\n        self.feed(data)\n        self.assertTrue(parser.completed)\n        self.assertEqual(parser.version, \"8.4\")\n        self.assertFalse(parser.empty)\n        self.assertEqual(\n            parser.headers,\n            {\n                \"FIRSTNAME\": \"mickey\",\n                \"LASTNAME\": \"Mouse\",\n                \"CONTENT_LENGTH\": \"6\",\n            },\n        )\n        self.assertEqual(parser.path, \"/foobar\")\n        self.assertEqual(parser.command, \"GET\")\n        self.assertEqual(parser.query, \"\")\n        self.assertEqual(parser.proxy_scheme, \"\")\n        self.assertEqual(parser.proxy_netloc, \"\")\n        self.assertEqual(parser.get_body_stream().getvalue(), b\"Hello.\")\n\n    def testComplexGET(self):\n        data = (\n            b\"GET /foo/a+%2B%2F%C3%A4%3D%26a%3Aint?d=b+%2B%2F%3D%26b%3Aint&c+%2B%2F%3D%26c%3Aint=6 HTTP/8.4\\r\\n\"\n            b\"FirstName: mickey\\r\\n\"\n            b\"lastname: Mouse\\r\\n\"\n            b\"content-length: 10\\r\\n\"\n            b\"\\r\\n\"\n            b\"Hello mickey.\"\n        )\n        parser = self.parser\n        self.feed(data)\n        self.assertEqual(parser.command, \"GET\")\n        self.assertEqual(parser.version, \"8.4\")\n        self.assertFalse(parser.empty)\n        self.assertEqual(\n            parser.headers,\n            {\"FIRSTNAME\": \"mickey\", \"LASTNAME\": \"Mouse\", \"CONTENT_LENGTH\": \"10\"},\n        )\n        # path should be utf-8 encoded\n        self.assertEqual(\n            parser.path.encode(\"latin-1\").decode(\"utf-8\"),\n            b\"/foo/a++/\\xc3\\xa4=&a:int\".decode(\"utf-8\"),\n        )\n        # parser.request_uri should preserve the % escape sequences and the query string.\n        self.assertEqual(\n            parser.request_uri,\n            \"/foo/a+%2B%2F%C3%A4%3D%26a%3Aint?d=b+%2B%2F%3D%26b%3Aint&c+%2B%2F%3D%26c%3Aint=6\",\n        )\n        self.assertEqual(\n            parser.query, \"d=b+%2B%2F%3D%26b%3Aint&c+%2B%2F%3D%26c%3Aint=6\"\n        )\n        self.assertEqual(parser.get_body_stream().getvalue(), b\"Hello mick\")\n\n    def testProxyGET(self):\n        data = (\n            b\"GET https://example.com:8080/foobar HTTP/8.4\\r\\n\"\n            b\"content-length: 6\\r\\n\"\n            b\"\\r\\n\"\n            b\"Hello.\"\n        )\n        parser = self.parser\n        self.feed(data)\n        self.assertTrue(parser.completed)\n        self.assertEqual(parser.version, \"8.4\")\n        self.assertFalse(parser.empty)\n        self.assertEqual(parser.headers, {\"CONTENT_LENGTH\": \"6\"})\n        self.assertEqual(parser.path, \"/foobar\")\n        self.assertEqual(parser.command, \"GET\")\n        self.assertEqual(parser.proxy_scheme, \"https\")\n        self.assertEqual(parser.proxy_netloc, \"example.com:8080\")\n        self.assertEqual(parser.command, \"GET\")\n        self.assertEqual(parser.query, \"\")\n        self.assertEqual(parser.get_body_stream().getvalue(), b\"Hello.\")\n\n    def testDuplicateHeaders(self):\n        # Ensure that headers with the same key get concatenated as per\n        # RFC2616.\n        data = (\n            b\"GET /foobar HTTP/8.4\\r\\n\"\n            b\"x-forwarded-for: 10.11.12.13\\r\\n\"\n            b\"x-forwarded-for: unknown,127.0.0.1\\r\\n\"\n            b\"X-Forwarded_for: 255.255.255.255\\r\\n\"\n            b\"content-length: 6\\r\\n\"\n            b\"\\r\\n\"\n            b\"Hello.\"\n        )\n        self.feed(data)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(\n            self.parser.headers,\n            {\n                \"CONTENT_LENGTH\": \"6\",\n                \"X_FORWARDED_FOR\": \"10.11.12.13, unknown,127.0.0.1\",\n            },\n        )\n\n    def testSpoofedHeadersDropped(self):\n        data = (\n            b\"GET /foobar HTTP/8.4\\r\\n\"\n            b\"x-auth_user: bob\\r\\n\"\n            b\"content-length: 6\\r\\n\"\n            b\"\\r\\n\"\n            b\"Hello.\"\n        )\n        self.feed(data)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(\n            self.parser.headers,\n            {\n                \"CONTENT_LENGTH\": \"6\",\n            },\n        )\n\n\nclass Test_unquote_bytes_to_wsgi(unittest.TestCase):\n    def _callFUT(self, v):\n\n        return unquote_bytes_to_wsgi(v)\n\n    def test_highorder(self):\n        val = b\"/a%C5%9B\"\n        result = self._callFUT(val)\n        # PEP 3333 urlunquoted-latin1-decoded-bytes\n        self.assertEqual(result, \"/a\u00c5\\x9b\")\n\n\nclass DummyBodyStream:\n    def getfile(self):\n        return self\n\n    def getbuf(self):\n        return self\n\n    def close(self):\n        self.closed = True\n", "import unittest\n\nimport pytest\n\n\nclass TestFixedStreamReceiver(unittest.TestCase):\n    def _makeOne(self, cl, buf):\n        from waitress.receiver import FixedStreamReceiver\n\n        return FixedStreamReceiver(cl, buf)\n\n    def test_received_remain_lt_1(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(0, buf)\n        result = inst.received(\"a\")\n        self.assertEqual(result, 0)\n        self.assertEqual(inst.completed, True)\n\n    def test_received_remain_lte_datalen(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(1, buf)\n        result = inst.received(\"aa\")\n        self.assertEqual(result, 1)\n        self.assertEqual(inst.completed, True)\n        self.assertEqual(inst.completed, 1)\n        self.assertEqual(inst.remain, 0)\n        self.assertEqual(buf.data, [\"a\"])\n\n    def test_received_remain_gt_datalen(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(10, buf)\n        result = inst.received(\"aa\")\n        self.assertEqual(result, 2)\n        self.assertEqual(inst.completed, False)\n        self.assertEqual(inst.remain, 8)\n        self.assertEqual(buf.data, [\"aa\"])\n\n    def test_getfile(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(10, buf)\n        self.assertEqual(inst.getfile(), buf)\n\n    def test_getbuf(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(10, buf)\n        self.assertEqual(inst.getbuf(), buf)\n\n    def test___len__(self):\n        buf = DummyBuffer([\"1\", \"2\"])\n        inst = self._makeOne(10, buf)\n        self.assertEqual(inst.__len__(), 2)\n\n\nclass TestChunkedReceiver(unittest.TestCase):\n    def _makeOne(self, buf):\n        from waitress.receiver import ChunkedReceiver\n\n        return ChunkedReceiver(buf)\n\n    def test_alreadycompleted(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.completed = True\n        result = inst.received(b\"a\")\n        self.assertEqual(result, 0)\n        self.assertEqual(inst.completed, True)\n\n    def test_received_remain_gt_zero(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.chunk_remainder = 100\n        result = inst.received(b\"a\")\n        self.assertEqual(inst.chunk_remainder, 99)\n        self.assertEqual(result, 1)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_control_line_notfinished(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        result = inst.received(b\"a\")\n        self.assertEqual(inst.control_line, b\"a\")\n        self.assertEqual(result, 1)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_control_line_finished_garbage_in_input(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        result = inst.received(b\"garbage\\r\\n\")\n        self.assertEqual(result, 9)\n        self.assertTrue(inst.error)\n\n    def test_received_control_line_finished_all_chunks_not_received(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        result = inst.received(b\"a;discard\\r\\n\")\n        self.assertEqual(inst.control_line, b\"\")\n        self.assertEqual(inst.chunk_remainder, 10)\n        self.assertEqual(inst.all_chunks_received, False)\n        self.assertEqual(result, 11)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_control_line_finished_all_chunks_received(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        result = inst.received(b\"0;discard\\r\\n\")\n        self.assertEqual(inst.control_line, b\"\")\n        self.assertEqual(inst.all_chunks_received, True)\n        self.assertEqual(result, 11)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_trailer_startswith_crlf(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.all_chunks_received = True\n        result = inst.received(b\"\\r\\n\")\n        self.assertEqual(result, 2)\n        self.assertEqual(inst.completed, True)\n\n    def test_received_trailer_startswith_lf(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.all_chunks_received = True\n        result = inst.received(b\"\\n\")\n        self.assertEqual(result, 1)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_trailer_not_finished(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.all_chunks_received = True\n        result = inst.received(b\"a\")\n        self.assertEqual(result, 1)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_trailer_finished(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.all_chunks_received = True\n        result = inst.received(b\"abc\\r\\n\\r\\n\")\n        self.assertEqual(inst.trailer, b\"abc\\r\\n\\r\\n\")\n        self.assertEqual(result, 7)\n        self.assertEqual(inst.completed, True)\n\n    def test_getfile(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        self.assertEqual(inst.getfile(), buf)\n\n    def test_getbuf(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        self.assertEqual(inst.getbuf(), buf)\n\n    def test___len__(self):\n        buf = DummyBuffer([\"1\", \"2\"])\n        inst = self._makeOne(buf)\n        self.assertEqual(inst.__len__(), 2)\n\n    def test_received_chunk_is_properly_terminated(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        data = b\"4\\r\\nWiki\\r\\n\"\n        result = inst.received(data)\n        self.assertEqual(result, len(data))\n        self.assertEqual(inst.completed, False)\n        self.assertEqual(buf.data[0], b\"Wiki\")\n\n    def test_received_chunk_not_properly_terminated(self):\n        from waitress.utilities import BadRequest\n\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        data = b\"4\\r\\nWikibadchunk\\r\\n\"\n        result = inst.received(data)\n        self.assertEqual(result, len(data))\n        self.assertEqual(inst.completed, False)\n        self.assertEqual(buf.data[0], b\"Wiki\")\n        self.assertEqual(inst.error.__class__, BadRequest)\n\n    def test_received_multiple_chunks(self):\n        from waitress.utilities import BadRequest\n\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        data = (\n            b\"4\\r\\n\"\n            b\"Wiki\\r\\n\"\n            b\"5\\r\\n\"\n            b\"pedia\\r\\n\"\n            b\"E\\r\\n\"\n            b\" in\\r\\n\"\n            b\"\\r\\n\"\n            b\"chunks.\\r\\n\"\n            b\"0\\r\\n\"\n            b\"\\r\\n\"\n        )\n        result = inst.received(data)\n        self.assertEqual(result, len(data))\n        self.assertEqual(inst.completed, True)\n        self.assertEqual(b\"\".join(buf.data), b\"Wikipedia in\\r\\n\\r\\nchunks.\")\n        self.assertEqual(inst.error, None)\n\n    def test_received_multiple_chunks_split(self):\n        from waitress.utilities import BadRequest\n\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        data1 = b\"4\\r\\nWiki\\r\"\n        result = inst.received(data1)\n        self.assertEqual(result, len(data1))\n\n        data2 = (\n            b\"\\n5\\r\\n\"\n            b\"pedia\\r\\n\"\n            b\"E\\r\\n\"\n            b\" in\\r\\n\"\n            b\"\\r\\n\"\n            b\"chunks.\\r\\n\"\n            b\"0\\r\\n\"\n            b\"\\r\\n\"\n        )\n\n        result = inst.received(data2)\n        self.assertEqual(result, len(data2))\n\n        self.assertEqual(inst.completed, True)\n        self.assertEqual(b\"\".join(buf.data), b\"Wikipedia in\\r\\n\\r\\nchunks.\")\n        self.assertEqual(inst.error, None)\n\n\nclass TestChunkedReceiverParametrized:\n    def _makeOne(self, buf):\n        from waitress.receiver import ChunkedReceiver\n\n        return ChunkedReceiver(buf)\n\n    @pytest.mark.parametrize(\n        \"invalid_extension\", [b\"\\n\", b\"invalid=\", b\"\\r\", b\"invalid = true\"]\n    )\n    def test_received_invalid_extensions(self, invalid_extension):\n        from waitress.utilities import BadRequest\n\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        data = b\"4;\" + invalid_extension + b\"\\r\\ntest\\r\\n\"\n        result = inst.received(data)\n        assert result == len(data)\n        assert inst.error.__class__ == BadRequest\n        assert inst.error.body == \"Invalid chunk extension\"\n\n    @pytest.mark.parametrize(\n        \"valid_extension\", [b\"test\", b\"valid=true\", b\"valid=true;other=true\"]\n    )\n    def test_received_valid_extensions(self, valid_extension):\n        # While waitress may ignore extensions in Chunked Encoding, we do want\n        # to make sure that we don't fail when we do encounter one that is\n        # valid\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        data = b\"4;\" + valid_extension + b\"\\r\\ntest\\r\\n\"\n        result = inst.received(data)\n        assert result == len(data)\n        assert inst.error == None\n\n    @pytest.mark.parametrize(\n        \"invalid_size\", [b\"0x04\", b\"+0x04\", b\"x04\", b\"+04\", b\" 04\", b\" 0x04\"]\n    )\n    def test_received_invalid_size(self, invalid_size):\n        from waitress.utilities import BadRequest\n\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        data = invalid_size + b\"\\r\\ntest\\r\\n\"\n        result = inst.received(data)\n        assert result == len(data)\n        assert inst.error.__class__ == BadRequest\n        assert inst.error.body == \"Invalid chunk size\"\n\n\nclass DummyBuffer:\n    def __init__(self, data=None):\n        if data is None:\n            data = []\n        self.data = data\n\n    def append(self, s):\n        self.data.append(s)\n\n    def getfile(self):\n        return self\n\n    def __len__(self):\n        return len(self.data)\n"], "filenames": ["CHANGES.txt", "setup.cfg", "src/waitress/parser.py", "src/waitress/receiver.py", "src/waitress/rfc7230.py", "src/waitress/utilities.py", "tests/test_functional.py", "tests/test_parser.py", "tests/test_receiver.py"], "buggy_code_start_loc": [0, 3, 25, 16, 6, 25, 325, 158, 1], "buggy_code_end_loc": [0, 4, 324, 150, 50, 253, 369, 187, 228], "fixing_code_start_loc": [1, 3, 26, 17, 7, 25, 325, 158, 2], "fixing_code_end_loc": [27, 4, 325, 164, 76, 231, 413, 208, 280], "type": "CWE-444", "message": "Waitress is a Web Server Gateway Interface server for Python 2 and 3. When using Waitress versions 2.1.0 and prior behind a proxy that does not properly validate the incoming HTTP request matches the RFC7230 standard, Waitress and the frontend proxy may disagree on where one request starts and where it ends. This would allow requests to be smuggled via the front-end proxy to waitress and later behavior. There are two classes of vulnerability that may lead to request smuggling that are addressed by this advisory: The use of Python's `int()` to parse strings into integers, leading to `+10` to be parsed as `10`, or `0x01` to be parsed as `1`, where as the standard specifies that the string should contain only digits or hex digits; and Waitress does not support chunk extensions, however it was discarding them without validating that they did not contain illegal characters. This vulnerability has been patched in Waitress 2.1.1. A workaround is available. When deploying a proxy in front of waitress, turning on any and all functionality to make sure that the request matches the RFC7230 standard. Certain proxy servers may not have this functionality though and users are encouraged to upgrade to the latest version of waitress instead.", "other": {"cve": {"id": "CVE-2022-24761", "sourceIdentifier": "security-advisories@github.com", "published": "2022-03-17T13:15:07.647", "lastModified": "2022-09-23T18:57:46.387", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Waitress is a Web Server Gateway Interface server for Python 2 and 3. When using Waitress versions 2.1.0 and prior behind a proxy that does not properly validate the incoming HTTP request matches the RFC7230 standard, Waitress and the frontend proxy may disagree on where one request starts and where it ends. This would allow requests to be smuggled via the front-end proxy to waitress and later behavior. There are two classes of vulnerability that may lead to request smuggling that are addressed by this advisory: The use of Python's `int()` to parse strings into integers, leading to `+10` to be parsed as `10`, or `0x01` to be parsed as `1`, where as the standard specifies that the string should contain only digits or hex digits; and Waitress does not support chunk extensions, however it was discarding them without validating that they did not contain illegal characters. This vulnerability has been patched in Waitress 2.1.1. A workaround is available. When deploying a proxy in front of waitress, turning on any and all functionality to make sure that the request matches the RFC7230 standard. Certain proxy servers may not have this functionality though and users are encouraged to upgrade to the latest version of waitress instead."}, {"lang": "es", "value": "Waitress es un servidor de Interfaz de Puerta de Entrada de Servidores Web para Python 2 y 3. Cuando son usadas las versiones 2.1.0 y anteriores de Waitress detr\u00e1s de un proxy que no comprueba inapropiadamente una petici\u00f3n HTTP entrante coincide con el est\u00e1ndar RFC7230, Waitress y el proxy del front-end pueden no estar de acuerdo en d\u00f3nde empieza una petici\u00f3n y d\u00f3nde termina. Esto permitir\u00eda contrabandear peticiones por medio del proxy del front-end a Waitress y su posterior comportamiento. Se presentan dos clases de vulnerabilidad que pueden conllevar a un contrabando de peticiones que son abordadas en este aviso: El uso de \"int()`\"de Python para analizar cadenas en enteros, conllevando a que \"+10\" sea analizado como \"10\", o que \"0x01\" sea analizado como \"1\", cuando el est\u00e1ndar especifica que la cadena debe contener s\u00f3lo d\u00edgitos o d\u00edgitos hexadecimales; y que Waitress no soporta extensiones de chunk, sin embargo las estaba descartando sin comprender que no conten\u00edan caracteres ilegales. Esta vulnerabilidad ha sido parcheada en Waitress versi\u00f3n 2.1.1. Se presenta una medida de mitigaci\u00f3n disponible. Cuando despliegue un proxy frente a Waitress, habilite todas las funciones para asegurarse de que la petici\u00f3n es ajustada al est\u00e1ndar RFC7230. Sin embargo, algunos servidores proxy pueden no tener esta funcionalidad y es recomendado a usuarios actualizar a la \u00faltima versi\u00f3n de waitress en su lugar"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:H/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "HIGH", "availabilityImpact": "NONE", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:H/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "HIGH", "availabilityImpact": "NONE", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:P/A:N", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "PARTIAL", "availabilityImpact": "NONE", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-444"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-444"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:agendaless:waitress:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.1.1", "matchCriteriaId": "8533846E-1747-432C-99AB-165118CCDFCF"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:9.0:*:*:*:*:*:*:*", "matchCriteriaId": "DEECE5FC-CACF-4496-A3E7-164736409252"}]}]}], "references": [{"url": "https://github.com/Pylons/waitress/commit/9e0b8c801e4d505c2ffc91b891af4ba48af715e0", "source": "security-advisories@github.com", "tags": ["Patch", "Release Notes", "Third Party Advisory"]}, {"url": "https://github.com/Pylons/waitress/releases/tag/v2.1.1", "source": "security-advisories@github.com", "tags": ["Release Notes", "Third Party Advisory"]}, {"url": "https://github.com/Pylons/waitress/security/advisories/GHSA-4f7p-27jc-3c36", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2022/05/msg00011.html", "source": "security-advisories@github.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://www.debian.org/security/2022/dsa-5138", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/Pylons/waitress/commit/9e0b8c801e4d505c2ffc91b891af4ba48af715e0"}}
{"buggy_code": ["# frozen_string_literal: true\n\nrequire 'ipaddr'\nrequire 'socket'\nrequire 'resolv'\n\n# Monkey-patch the HTTP.rb timeout class to avoid using a timeout block\n# around the Socket#open method, since we use our own timeout blocks inside\n# that method\nclass HTTP::Timeout::PerOperation\n  def connect(socket_class, host, port, nodelay = false)\n    @socket = socket_class.open(host, port)\n    @socket.setsockopt(Socket::IPPROTO_TCP, Socket::TCP_NODELAY, 1) if nodelay\n  end\nend\n\nclass Request\n  REQUEST_TARGET = '(request-target)'\n\n  # We enforce a 5s timeout on DNS resolving, 5s timeout on socket opening\n  # and 5s timeout on the TLS handshake, meaning the worst case should take\n  # about 15s in total\n  TIMEOUT = { connect: 5, read: 10, write: 10 }.freeze\n\n  include RoutingHelper\n\n  def initialize(verb, url, **options)\n    raise ArgumentError if url.blank?\n\n    @verb        = verb\n    @url         = Addressable::URI.parse(url).normalize\n    @http_client = options.delete(:http_client)\n    @allow_local = options.delete(:allow_local)\n    @options     = options.merge(socket_class: use_proxy? || @allow_local ? ProxySocket : Socket)\n    @options     = @options.merge(proxy_url) if use_proxy?\n    @headers     = {}\n\n    raise Mastodon::HostValidationError, 'Instance does not support hidden service connections' if block_hidden_service?\n\n    set_common_headers!\n    set_digest! if options.key?(:body)\n  end\n\n  def on_behalf_of(actor, sign_with: nil)\n    raise ArgumentError, 'actor must not be nil' if actor.nil?\n\n    @actor         = actor\n    @keypair       = sign_with.present? ? OpenSSL::PKey::RSA.new(sign_with) : @actor.keypair\n\n    self\n  end\n\n  def add_headers(new_headers)\n    @headers.merge!(new_headers)\n    self\n  end\n\n  def perform\n    begin\n      response = http_client.public_send(@verb, @url.to_s, @options.merge(headers: headers))\n    rescue => e\n      raise e.class, \"#{e.message} on #{@url}\", e.backtrace[0]\n    end\n\n    begin\n      # If we are using a persistent connection, we have to\n      # read every response to be able to move forward at all.\n      # However, simply calling #to_s or #flush may not be safe,\n      # as the response body, if malicious, could be too big\n      # for our memory. So we use the #body_with_limit method\n      response.body_with_limit if http_client.persistent?\n\n      yield response if block_given?\n    ensure\n      http_client.close unless http_client.persistent?\n    end\n  end\n\n  def headers\n    (@actor ? @headers.merge('Signature' => signature) : @headers).without(REQUEST_TARGET)\n  end\n\n  class << self\n    def valid_url?(url)\n      begin\n        parsed_url = Addressable::URI.parse(url)\n      rescue Addressable::URI::InvalidURIError\n        return false\n      end\n\n      %w(http https).include?(parsed_url.scheme) && parsed_url.host.present?\n    end\n\n    def http_client\n      HTTP.use(:auto_inflate).timeout(TIMEOUT.dup).follow(max_hops: 3)\n    end\n  end\n\n  private\n\n  def set_common_headers!\n    @headers[REQUEST_TARGET]    = \"#{@verb} #{@url.path}\"\n    @headers['User-Agent']      = Mastodon::Version.user_agent\n    @headers['Host']            = @url.host\n    @headers['Date']            = Time.now.utc.httpdate\n    @headers['Accept-Encoding'] = 'gzip' if @verb != :head\n  end\n\n  def set_digest!\n    @headers['Digest'] = \"SHA-256=#{Digest::SHA256.base64digest(@options[:body])}\"\n  end\n\n  def signature\n    algorithm = 'rsa-sha256'\n    signature = Base64.strict_encode64(@keypair.sign(OpenSSL::Digest.new('SHA256'), signed_string))\n\n    \"keyId=\\\"#{key_id}\\\",algorithm=\\\"#{algorithm}\\\",headers=\\\"#{signed_headers.keys.join(' ').downcase}\\\",signature=\\\"#{signature}\\\"\"\n  end\n\n  def signed_string\n    signed_headers.map { |key, value| \"#{key.downcase}: #{value}\" }.join(\"\\n\")\n  end\n\n  def signed_headers\n    @headers.without('User-Agent', 'Accept-Encoding')\n  end\n\n  def key_id\n    ActivityPub::TagManager.instance.key_uri_for(@actor)\n  end\n\n  def http_client\n    @http_client ||= Request.http_client\n  end\n\n  def use_proxy?\n    proxy_url.present?\n  end\n\n  def proxy_url\n    if hidden_service? && Rails.configuration.x.http_client_hidden_proxy.present?\n      Rails.configuration.x.http_client_hidden_proxy\n    else\n      Rails.configuration.x.http_client_proxy\n    end\n  end\n\n  def block_hidden_service?\n    !Rails.configuration.x.access_to_hidden_service && hidden_service?\n  end\n\n  def hidden_service?\n    /\\.(onion|i2p)$/.match?(@url.host)\n  end\n\n  module ClientLimit\n    def truncated_body(limit = 1.megabyte)\n      if charset.nil?\n        encoding = Encoding::BINARY\n      else\n        begin\n          encoding = Encoding.find(charset)\n        rescue ArgumentError\n          encoding = Encoding::BINARY\n        end\n      end\n\n      contents = String.new(encoding: encoding)\n\n      while (chunk = readpartial)\n        contents << chunk\n        chunk.clear\n\n        break if contents.bytesize > limit\n      end\n\n      contents\n    end\n\n    def body_with_limit(limit = 1.megabyte)\n      raise Mastodon::LengthValidationError if content_length.present? && content_length > limit\n\n      contents = truncated_body(limit)\n      raise Mastodon::LengthValidationError if contents.bytesize > limit\n\n      contents\n    end\n  end\n\n  if ::HTTP::Response.methods.include?(:body_with_limit) && !Rails.env.production?\n    abort 'HTTP::Response#body_with_limit is already defined, the monkey patch will not be applied'\n  else\n    class ::HTTP::Response\n      include Request::ClientLimit\n    end\n  end\n\n  class Socket < TCPSocket\n    class << self\n      def open(host, *args)\n        outer_e = nil\n        port    = args.first\n\n        addresses = []\n        begin\n          addresses = [IPAddr.new(host)]\n        rescue IPAddr::InvalidAddressError\n          Resolv::DNS.open do |dns|\n            dns.timeouts = 5\n            addresses = dns.getaddresses(host)\n            addresses = addresses.filter { |addr| addr.is_a?(Resolv::IPv6) }.take(2) + addresses.filter { |addr| !addr.is_a?(Resolv::IPv6) }.take(2)\n          end\n        end\n\n        socks = []\n        addr_by_socket = {}\n\n        addresses.each do |address|\n          check_private_address(address, host)\n\n          sock     = ::Socket.new(address.is_a?(Resolv::IPv6) ? ::Socket::AF_INET6 : ::Socket::AF_INET, ::Socket::SOCK_STREAM, 0)\n          sockaddr = ::Socket.pack_sockaddr_in(port, address.to_s)\n\n          sock.setsockopt(::Socket::IPPROTO_TCP, ::Socket::TCP_NODELAY, 1)\n\n          sock.connect_nonblock(sockaddr)\n\n          # If that hasn't raised an exception, we somehow managed to connect\n          # immediately, close pending sockets and return immediately\n          socks.each(&:close)\n          return sock\n        rescue IO::WaitWritable\n          socks << sock\n          addr_by_socket[sock] = sockaddr\n        rescue => e\n          outer_e = e\n        end\n\n        until socks.empty?\n          _, available_socks, = IO.select(nil, socks, nil, Request::TIMEOUT[:connect])\n\n          if available_socks.nil?\n            socks.each(&:close)\n            raise HTTP::TimeoutError, \"Connect timed out after #{Request::TIMEOUT[:connect]} seconds\"\n          end\n\n          available_socks.each do |sock|\n            socks.delete(sock)\n\n            begin\n              sock.connect_nonblock(addr_by_socket[sock])\n            rescue Errno::EISCONN\n              # Do nothing\n            rescue => e\n              sock.close\n              outer_e = e\n              next\n            end\n\n            socks.each(&:close)\n            return sock\n          end\n        end\n\n        if outer_e\n          raise outer_e\n        else\n          raise SocketError, \"No address for #{host}\"\n        end\n      end\n\n      alias new open\n\n      def check_private_address(address, host)\n        addr = IPAddr.new(address.to_s)\n\n        return if Rails.env.development? || private_address_exceptions.any? { |range| range.include?(addr) }\n\n        raise Mastodon::PrivateNetworkAddressError, host if PrivateAddressCheck.private_address?(addr)\n      end\n\n      def private_address_exceptions\n        @private_address_exceptions = (ENV['ALLOWED_PRIVATE_ADDRESSES'] || '').split(',').map { |addr| IPAddr.new(addr) }\n      end\n    end\n  end\n\n  class ProxySocket < Socket\n    class << self\n      def check_private_address(_address, _host)\n        # Accept connections to private addresses as HTTP proxies will usually\n        # be on local addresses\n        nil\n      end\n    end\n  end\n\n  private_constant :ClientLimit, :Socket, :ProxySocket\nend\n"], "fixing_code": ["# frozen_string_literal: true\n\nrequire 'ipaddr'\nrequire 'socket'\nrequire 'resolv'\n\n# Monkey-patch the HTTP.rb timeout class to avoid using a timeout block\n# around the Socket#open method, since we use our own timeout blocks inside\n# that method\n#\n# Also changes how the read timeout behaves so that it is cumulative (closer\n# to HTTP::Timeout::Global, but still having distinct timeouts for other\n# operation types)\nclass HTTP::Timeout::PerOperation\n  def connect(socket_class, host, port, nodelay = false)\n    @socket = socket_class.open(host, port)\n    @socket.setsockopt(Socket::IPPROTO_TCP, Socket::TCP_NODELAY, 1) if nodelay\n  end\n\n  # Reset deadline when the connection is re-used for different requests\n  def reset_counter\n    @deadline = nil\n  end\n\n  # Read data from the socket\n  def readpartial(size, buffer = nil)\n    @deadline ||= Process.clock_gettime(Process::CLOCK_MONOTONIC) + @read_timeout\n\n    timeout = false\n    loop do\n      result = @socket.read_nonblock(size, buffer, exception: false)\n\n      return :eof if result.nil?\n\n      remaining_time = @deadline - Process.clock_gettime(Process::CLOCK_MONOTONIC)\n      raise HTTP::TimeoutError, \"Read timed out after #{@read_timeout} seconds\" if timeout || remaining_time <= 0\n      return result if result != :wait_readable\n\n      # marking the socket for timeout. Why is this not being raised immediately?\n      # it seems there is some race-condition on the network level between calling\n      # #read_nonblock and #wait_readable, in which #read_nonblock signalizes waiting\n      # for reads, and when waiting for x seconds, it returns nil suddenly without completing\n      # the x seconds. In a normal case this would be a timeout on wait/read, but it can\n      # also mean that the socket has been closed by the server. Therefore we \"mark\" the\n      # socket for timeout and try to read more bytes. If it returns :eof, it's all good, no\n      # timeout. Else, the first timeout was a proper timeout.\n      # This hack has to be done because io/wait#wait_readable doesn't provide a value for when\n      # the socket is closed by the server, and HTTP::Parser doesn't provide the limit for the chunks.\n      timeout = true unless @socket.to_io.wait_readable(remaining_time)\n    end\n  end\nend\n\nclass Request\n  REQUEST_TARGET = '(request-target)'\n\n  # We enforce a 5s timeout on DNS resolving, 5s timeout on socket opening\n  # and 5s timeout on the TLS handshake, meaning the worst case should take\n  # about 15s in total\n  TIMEOUT = { connect: 5, read: 10, write: 10 }.freeze\n\n  include RoutingHelper\n\n  def initialize(verb, url, **options)\n    raise ArgumentError if url.blank?\n\n    @verb        = verb\n    @url         = Addressable::URI.parse(url).normalize\n    @http_client = options.delete(:http_client)\n    @allow_local = options.delete(:allow_local)\n    @options     = options.merge(socket_class: use_proxy? || @allow_local ? ProxySocket : Socket)\n    @options     = @options.merge(proxy_url) if use_proxy?\n    @headers     = {}\n\n    raise Mastodon::HostValidationError, 'Instance does not support hidden service connections' if block_hidden_service?\n\n    set_common_headers!\n    set_digest! if options.key?(:body)\n  end\n\n  def on_behalf_of(actor, sign_with: nil)\n    raise ArgumentError, 'actor must not be nil' if actor.nil?\n\n    @actor         = actor\n    @keypair       = sign_with.present? ? OpenSSL::PKey::RSA.new(sign_with) : @actor.keypair\n\n    self\n  end\n\n  def add_headers(new_headers)\n    @headers.merge!(new_headers)\n    self\n  end\n\n  def perform\n    begin\n      response = http_client.public_send(@verb, @url.to_s, @options.merge(headers: headers))\n    rescue => e\n      raise e.class, \"#{e.message} on #{@url}\", e.backtrace[0]\n    end\n\n    begin\n      # If we are using a persistent connection, we have to\n      # read every response to be able to move forward at all.\n      # However, simply calling #to_s or #flush may not be safe,\n      # as the response body, if malicious, could be too big\n      # for our memory. So we use the #body_with_limit method\n      response.body_with_limit if http_client.persistent?\n\n      yield response if block_given?\n    ensure\n      http_client.close unless http_client.persistent?\n    end\n  end\n\n  def headers\n    (@actor ? @headers.merge('Signature' => signature) : @headers).without(REQUEST_TARGET)\n  end\n\n  class << self\n    def valid_url?(url)\n      begin\n        parsed_url = Addressable::URI.parse(url)\n      rescue Addressable::URI::InvalidURIError\n        return false\n      end\n\n      %w(http https).include?(parsed_url.scheme) && parsed_url.host.present?\n    end\n\n    def http_client\n      HTTP.use(:auto_inflate).timeout(TIMEOUT.dup).follow(max_hops: 3)\n    end\n  end\n\n  private\n\n  def set_common_headers!\n    @headers[REQUEST_TARGET]    = \"#{@verb} #{@url.path}\"\n    @headers['User-Agent']      = Mastodon::Version.user_agent\n    @headers['Host']            = @url.host\n    @headers['Date']            = Time.now.utc.httpdate\n    @headers['Accept-Encoding'] = 'gzip' if @verb != :head\n  end\n\n  def set_digest!\n    @headers['Digest'] = \"SHA-256=#{Digest::SHA256.base64digest(@options[:body])}\"\n  end\n\n  def signature\n    algorithm = 'rsa-sha256'\n    signature = Base64.strict_encode64(@keypair.sign(OpenSSL::Digest.new('SHA256'), signed_string))\n\n    \"keyId=\\\"#{key_id}\\\",algorithm=\\\"#{algorithm}\\\",headers=\\\"#{signed_headers.keys.join(' ').downcase}\\\",signature=\\\"#{signature}\\\"\"\n  end\n\n  def signed_string\n    signed_headers.map { |key, value| \"#{key.downcase}: #{value}\" }.join(\"\\n\")\n  end\n\n  def signed_headers\n    @headers.without('User-Agent', 'Accept-Encoding')\n  end\n\n  def key_id\n    ActivityPub::TagManager.instance.key_uri_for(@actor)\n  end\n\n  def http_client\n    @http_client ||= Request.http_client\n  end\n\n  def use_proxy?\n    proxy_url.present?\n  end\n\n  def proxy_url\n    if hidden_service? && Rails.configuration.x.http_client_hidden_proxy.present?\n      Rails.configuration.x.http_client_hidden_proxy\n    else\n      Rails.configuration.x.http_client_proxy\n    end\n  end\n\n  def block_hidden_service?\n    !Rails.configuration.x.access_to_hidden_service && hidden_service?\n  end\n\n  def hidden_service?\n    /\\.(onion|i2p)$/.match?(@url.host)\n  end\n\n  module ClientLimit\n    def truncated_body(limit = 1.megabyte)\n      if charset.nil?\n        encoding = Encoding::BINARY\n      else\n        begin\n          encoding = Encoding.find(charset)\n        rescue ArgumentError\n          encoding = Encoding::BINARY\n        end\n      end\n\n      contents = String.new(encoding: encoding)\n\n      while (chunk = readpartial)\n        contents << chunk\n        chunk.clear\n\n        break if contents.bytesize > limit\n      end\n\n      contents\n    end\n\n    def body_with_limit(limit = 1.megabyte)\n      raise Mastodon::LengthValidationError if content_length.present? && content_length > limit\n\n      contents = truncated_body(limit)\n      raise Mastodon::LengthValidationError if contents.bytesize > limit\n\n      contents\n    end\n  end\n\n  if ::HTTP::Response.methods.include?(:body_with_limit) && !Rails.env.production?\n    abort 'HTTP::Response#body_with_limit is already defined, the monkey patch will not be applied'\n  else\n    class ::HTTP::Response\n      include Request::ClientLimit\n    end\n  end\n\n  class Socket < TCPSocket\n    class << self\n      def open(host, *args)\n        outer_e = nil\n        port    = args.first\n\n        addresses = []\n        begin\n          addresses = [IPAddr.new(host)]\n        rescue IPAddr::InvalidAddressError\n          Resolv::DNS.open do |dns|\n            dns.timeouts = 5\n            addresses = dns.getaddresses(host)\n            addresses = addresses.filter { |addr| addr.is_a?(Resolv::IPv6) }.take(2) + addresses.filter { |addr| !addr.is_a?(Resolv::IPv6) }.take(2)\n          end\n        end\n\n        socks = []\n        addr_by_socket = {}\n\n        addresses.each do |address|\n          check_private_address(address, host)\n\n          sock     = ::Socket.new(address.is_a?(Resolv::IPv6) ? ::Socket::AF_INET6 : ::Socket::AF_INET, ::Socket::SOCK_STREAM, 0)\n          sockaddr = ::Socket.pack_sockaddr_in(port, address.to_s)\n\n          sock.setsockopt(::Socket::IPPROTO_TCP, ::Socket::TCP_NODELAY, 1)\n\n          sock.connect_nonblock(sockaddr)\n\n          # If that hasn't raised an exception, we somehow managed to connect\n          # immediately, close pending sockets and return immediately\n          socks.each(&:close)\n          return sock\n        rescue IO::WaitWritable\n          socks << sock\n          addr_by_socket[sock] = sockaddr\n        rescue => e\n          outer_e = e\n        end\n\n        until socks.empty?\n          _, available_socks, = IO.select(nil, socks, nil, Request::TIMEOUT[:connect])\n\n          if available_socks.nil?\n            socks.each(&:close)\n            raise HTTP::TimeoutError, \"Connect timed out after #{Request::TIMEOUT[:connect]} seconds\"\n          end\n\n          available_socks.each do |sock|\n            socks.delete(sock)\n\n            begin\n              sock.connect_nonblock(addr_by_socket[sock])\n            rescue Errno::EISCONN\n              # Do nothing\n            rescue => e\n              sock.close\n              outer_e = e\n              next\n            end\n\n            socks.each(&:close)\n            return sock\n          end\n        end\n\n        if outer_e\n          raise outer_e\n        else\n          raise SocketError, \"No address for #{host}\"\n        end\n      end\n\n      alias new open\n\n      def check_private_address(address, host)\n        addr = IPAddr.new(address.to_s)\n\n        return if Rails.env.development? || private_address_exceptions.any? { |range| range.include?(addr) }\n\n        raise Mastodon::PrivateNetworkAddressError, host if PrivateAddressCheck.private_address?(addr)\n      end\n\n      def private_address_exceptions\n        @private_address_exceptions = (ENV['ALLOWED_PRIVATE_ADDRESSES'] || '').split(',').map { |addr| IPAddr.new(addr) }\n      end\n    end\n  end\n\n  class ProxySocket < Socket\n    class << self\n      def check_private_address(_address, _host)\n        # Accept connections to private addresses as HTTP proxies will usually\n        # be on local addresses\n        nil\n      end\n    end\n  end\n\n  private_constant :ClientLimit, :Socket, :ProxySocket\nend\n"], "filenames": ["app/lib/request.rb"], "buggy_code_start_loc": [9], "buggy_code_end_loc": [13], "fixing_code_start_loc": [10], "fixing_code_end_loc": [51], "type": "CWE-770", "message": "Mastodon is a free, open-source social network server based on ActivityPub. When performing outgoing HTTP queries, Mastodon sets a timeout on individual read operations. Prior to versions 3.5.9, 4.0.5, and 4.1.3, a malicious server can indefinitely extend the duration of the response through slowloris-type attacks. This vulnerability can be used to keep all Mastodon workers busy for an extended duration of time, leading to the server becoming unresponsive. Versions 3.5.9, 4.0.5, and 4.1.3 contain a patch for this issue.", "other": {"cve": {"id": "CVE-2023-36461", "sourceIdentifier": "security-advisories@github.com", "published": "2023-07-06T19:15:10.880", "lastModified": "2023-07-14T19:25:23.220", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Mastodon is a free, open-source social network server based on ActivityPub. When performing outgoing HTTP queries, Mastodon sets a timeout on individual read operations. Prior to versions 3.5.9, 4.0.5, and 4.1.3, a malicious server can indefinitely extend the duration of the response through slowloris-type attacks. This vulnerability can be used to keep all Mastodon workers busy for an extended duration of time, leading to the server becoming unresponsive. Versions 3.5.9, 4.0.5, and 4.1.3 contain a patch for this issue."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-770"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:joinmastodon:mastodon:*:*:*:*:*:*:*:*", "versionEndExcluding": "3.5.9", "matchCriteriaId": "CDD53D86-018D-4C06-94B3-36E2FDE03963"}, {"vulnerable": true, "criteria": "cpe:2.3:a:joinmastodon:mastodon:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.0.0", "versionEndExcluding": "4.0.5", "matchCriteriaId": "51150E6A-F99E-4905-A464-2BAC2B1C36C3"}, {"vulnerable": true, "criteria": "cpe:2.3:a:joinmastodon:mastodon:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.1.0", "versionEndExcluding": "4.1.3", "matchCriteriaId": "8AB4CC5C-A9AE-4CD1-8912-B570E2F6E170"}]}]}], "references": [{"url": "http://www.openwall.com/lists/oss-security/2023/07/06/7", "source": "security-advisories@github.com", "tags": ["Mailing List"]}, {"url": "https://github.com/mastodon/mastodon/commit/c5929798bf7e56cc2c79b15bed0c4692ded3dcb6", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/mastodon/mastodon/releases/tag/v3.5.9", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}, {"url": "https://github.com/mastodon/mastodon/releases/tag/v4.0.5", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}, {"url": "https://github.com/mastodon/mastodon/releases/tag/v4.1.3", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}, {"url": "https://github.com/mastodon/mastodon/security/advisories/GHSA-9pxv-6qvf-pjwc", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/mastodon/mastodon/commit/c5929798bf7e56cc2c79b15bed0c4692ded3dcb6"}}
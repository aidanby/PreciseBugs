{"buggy_code": ["/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage common\n\nimport (\n\t\"context\"\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"hash/fnv\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"os\"\n\t\"reflect\"\n\t\"strings\"\n\n\t\"github.com/pkg/errors\"\n\tcorev1 \"k8s.io/api/core/v1\"\n\tv1 \"k8s.io/api/core/v1\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/client-go/kubernetes\"\n\t\"k8s.io/client-go/rest\"\n\t\"k8s.io/client-go/tools/clientcmd\"\n\n\tapicommon \"github.com/argoproj/argo-events/pkg/apis/common\"\n)\n\n// GetClientConfig return rest config, if path not specified, assume in cluster config\nfunc GetClientConfig(kubeconfig string) (*rest.Config, error) {\n\tif kubeconfig != \"\" {\n\t\treturn clientcmd.BuildConfigFromFlags(\"\", kubeconfig)\n\t}\n\treturn rest.InClusterConfig()\n}\n\n// SendSuccessResponse sends http success response\nfunc SendSuccessResponse(writer http.ResponseWriter, response string) {\n\twriter.WriteHeader(http.StatusOK)\n\tif _, err := writer.Write([]byte(response)); err != nil {\n\t\tfmt.Printf(\"failed to write the response. err: %+v\\n\", err)\n\t}\n}\n\n// SendErrorResponse sends http error response\nfunc SendErrorResponse(writer http.ResponseWriter, response string) {\n\twriter.WriteHeader(http.StatusBadRequest)\n\tif _, err := writer.Write([]byte(response)); err != nil {\n\t\tfmt.Printf(\"failed to write the response. err: %+v\\n\", err)\n\t}\n}\n\n// SendInternalErrorResponse sends http internal error response\nfunc SendInternalErrorResponse(writer http.ResponseWriter, response string) {\n\twriter.WriteHeader(http.StatusInternalServerError)\n\tif _, err := writer.Write([]byte(response)); err != nil {\n\t\tfmt.Printf(\"failed to write the response. err: %+v\\n\", err)\n\t}\n}\n\n// SendResponse sends http response with given status code\nfunc SendResponse(writer http.ResponseWriter, statusCode int, response string) {\n\twriter.WriteHeader(statusCode)\n\tif _, err := writer.Write([]byte(response)); err != nil {\n\t\tfmt.Printf(\"failed to write the response. err: %+v\\n\", err)\n\t}\n}\n\n// Hasher hashes a string\nfunc Hasher(value string) string {\n\th := fnv.New32a()\n\t_, _ = h.Write([]byte(value))\n\treturn fmt.Sprintf(\"%v\", h.Sum32())\n}\n\n// GetObjectHash returns hash of a given object\nfunc GetObjectHash(obj metav1.Object) (string, error) {\n\tb, err := json.Marshal(obj)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"failed to marshal resource\")\n\t}\n\treturn Hasher(string(b)), nil\n}\n\n// FormatEndpoint returns a formatted api endpoint\nfunc FormatEndpoint(endpoint string) string {\n\tif !strings.HasPrefix(endpoint, \"/\") {\n\t\treturn fmt.Sprintf(\"/%s\", endpoint)\n\t}\n\treturn endpoint\n}\n\n// FormattedURL returns a formatted url\nfunc FormattedURL(url, endpoint string) string {\n\treturn fmt.Sprintf(\"%s%s\", url, FormatEndpoint(endpoint))\n}\n\nfunc ErrEventSourceTypeMismatch(eventSourceType string) string {\n\treturn fmt.Sprintf(\"event source is not type of %s\", eventSourceType)\n}\n\n// GetSecretValue retrieves the secret value from the secret in namespace with name and key\nfunc GetSecretValue(ctx context.Context, client kubernetes.Interface, namespace string, selector *v1.SecretKeySelector) (string, error) {\n\tsecret, err := client.CoreV1().Secrets(namespace).Get(ctx, selector.Name, metav1.GetOptions{})\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tval, ok := secret.Data[selector.Key]\n\tif !ok {\n\t\treturn \"\", errors.Errorf(\"secret '%s' does not have the key '%s'\", selector.Name, selector.Key)\n\t}\n\treturn string(val), nil\n}\n\n// GetEnvFromSecret retrieves the value of envFrom.secretRef\n// \"${secretRef.name}_\" is expected to be defined as \"prefix\"\nfunc GetEnvFromSecret(selector *v1.SecretKeySelector) (string, bool) {\n\treturn os.LookupEnv(fmt.Sprintf(\"%s_%s\", selector.Name, selector.Key))\n}\n\n// GenerateEnvFromSecretSpec builds a \"envFrom\" spec with a secretKeySelector\nfunc GenerateEnvFromSecretSpec(selector *v1.SecretKeySelector) v1.EnvFromSource {\n\treturn v1.EnvFromSource{\n\t\tPrefix: selector.Name + \"_\",\n\t\tSecretRef: &v1.SecretEnvSource{\n\t\t\tLocalObjectReference: v1.LocalObjectReference{\n\t\t\t\tName: selector.Name,\n\t\t\t},\n\t\t},\n\t}\n}\n\n// GetSecretFromVolume retrieves the value of mounted secret volume\n// \"/argo-events/secrets/${secretRef.name}/${secretRef.key}\" is expected to be the file path\nfunc GetSecretFromVolume(selector *v1.SecretKeySelector) (string, error) {\n\tfilePath, err := GetSecretVolumePath(selector)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tdata, err := ioutil.ReadFile(filePath)\n\tif err != nil {\n\t\treturn \"\", errors.Wrapf(err, \"failed to get secret value of name: %s, key: %s\", selector.Name, selector.Key)\n\t}\n\t// Secrets edited by tools like \"vim\" always have an extra invisible \"\\n\" in the end,\n\t// and it's often neglected, but it makes differences for some of the applications.\n\treturn strings.TrimSuffix(string(data), \"\\n\"), nil\n}\n\n// GetSecretVolumePath returns the path of the mounted secret\nfunc GetSecretVolumePath(selector *v1.SecretKeySelector) (string, error) {\n\tif selector == nil {\n\t\treturn \"\", errors.New(\"secret key selector is nil\")\n\t}\n\treturn fmt.Sprintf(\"/argo-events/secrets/%s/%s\", selector.Name, selector.Key), nil\n}\n\n// GetConfigMapFromVolume retrieves the value of mounted config map volume\n// \"/argo-events/config/${configMapRef.name}/${configMapRef.key}\" is expected to be the file path\nfunc GetConfigMapFromVolume(selector *v1.ConfigMapKeySelector) (string, error) {\n\tfilePath, err := GetConfigMapVolumePath(selector)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tdata, err := ioutil.ReadFile(filePath)\n\tif err != nil {\n\t\treturn \"\", errors.Wrapf(err, \"failed to get configMap value of name: %s, key: %s\", selector.Name, selector.Key)\n\t}\n\t// Contents edied by tools like \"vim\" always have an extra invisible \"\\n\" in the end,\n\t// and it's often negleted, but it makes differences for some of the applications.\n\treturn strings.TrimSuffix(string(data), \"\\n\"), nil\n}\n\n// GetConfigMapVolumePath returns the path of the mounted configmap\nfunc GetConfigMapVolumePath(selector *v1.ConfigMapKeySelector) (string, error) {\n\tif selector == nil {\n\t\treturn \"\", errors.New(\"configmap key selector is nil\")\n\t}\n\treturn fmt.Sprintf(\"/argo-events/config/%s/%s\", selector.Name, selector.Key), nil\n}\n\n// GetEnvFromConfigMap retrieves the value of envFrom.configMapRef\n// \"${configMapRef.name}_\" is expected to be defined as \"prefix\"\nfunc GetEnvFromConfigMap(selector *v1.ConfigMapKeySelector) (string, bool) {\n\treturn os.LookupEnv(fmt.Sprintf(\"%s_%s\", selector.Name, selector.Key))\n}\n\n// GenerateEnvFromConfigMapSpec builds a \"envFrom\" spec with a configMapKeySelector\nfunc GenerateEnvFromConfigMapSpec(selector *v1.ConfigMapKeySelector) v1.EnvFromSource {\n\treturn v1.EnvFromSource{\n\t\tPrefix: selector.Name + \"_\",\n\t\tConfigMapRef: &v1.ConfigMapEnvSource{\n\t\t\tLocalObjectReference: v1.LocalObjectReference{\n\t\t\t\tName: selector.Name,\n\t\t\t},\n\t\t},\n\t}\n}\n\n// GetTLSConfig returns a tls configuration for given cert and key or skips the certs if InsecureSkipVerify is true.\nfunc GetTLSConfig(config *apicommon.TLSConfig) (*tls.Config, error) {\n\tif config == nil {\n\t\treturn nil, errors.New(\"TLSConfig is nil\")\n\t}\n\n\tif config.InsecureSkipVerify {\n\t\ttlsConfig := &tls.Config{\n\t\t\tInsecureSkipVerify: true,\n\t\t\tClientAuth:         0,\n\t\t}\n\t\treturn tlsConfig, nil\n\t}\n\n\tvar caCertPath, clientCertPath, clientKeyPath string\n\tvar err error\n\tif config.CACertSecret != nil {\n\t\tcaCertPath, err = GetSecretVolumePath(config.CACertSecret)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif config.ClientCertSecret != nil {\n\t\tclientCertPath, err = GetSecretVolumePath(config.ClientCertSecret)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif config.ClientKeySecret != nil {\n\t\tclientKeyPath, err = GetSecretVolumePath(config.ClientKeySecret)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif len(caCertPath)+len(clientCertPath)+len(clientKeyPath) == 0 {\n\t\t// None of 3 is configured\n\t\treturn nil, errors.New(\"invalid tls config, neither of caCertSecret, clientCertSecret and clientKeySecret is configured\")\n\t}\n\n\tif len(clientCertPath)+len(clientKeyPath) > 0 && len(clientCertPath)*len(clientKeyPath) == 0 {\n\t\t// Only one of clientCertSecret and clientKeySecret is configured\n\t\treturn nil, errors.New(\"invalid tls config, both of clientCertSecret and clientKeySecret need to be configured\")\n\t}\n\n\tc := &tls.Config{}\n\tif len(caCertPath) > 0 {\n\t\tcaCert, err := ioutil.ReadFile(caCertPath)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"failed to read ca cert file %s\", caCertPath)\n\t\t}\n\t\tpool := x509.NewCertPool()\n\t\tpool.AppendCertsFromPEM(caCert)\n\t\tc.RootCAs = pool\n\t}\n\n\tif len(clientCertPath) > 0 && len(clientKeyPath) > 0 {\n\t\tclientCert, err := tls.LoadX509KeyPair(clientCertPath, clientKeyPath)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"failed to load client cert key pair %s\", caCertPath)\n\t\t}\n\t\tc.Certificates = []tls.Certificate{clientCert}\n\t}\n\treturn c, nil\n}\n\n// VolumesFromSecretsOrConfigMaps builds volumes and volumeMounts spec based on\n// the obj and its children's secretKeyselector or configMapKeySelector\nfunc VolumesFromSecretsOrConfigMaps(obj interface{}, t reflect.Type) ([]v1.Volume, []v1.VolumeMount) {\n\tresultVolumes := []v1.Volume{}\n\tresultMounts := []v1.VolumeMount{}\n\tvalues := findTypeValues(obj, t)\n\tif len(values) == 0 {\n\t\treturn resultVolumes, resultMounts\n\t}\n\tswitch t {\n\tcase SecretKeySelectorType:\n\t\tfor _, v := range values {\n\t\t\tselector := v.(*v1.SecretKeySelector)\n\t\t\tvol, mount := GenerateSecretVolumeSpecs(selector)\n\t\t\tresultVolumes = append(resultVolumes, vol)\n\t\t\tresultMounts = append(resultMounts, mount)\n\t\t}\n\tcase ConfigMapKeySelectorType:\n\t\tfor _, v := range values {\n\t\t\tselector := v.(*v1.ConfigMapKeySelector)\n\t\t\tvol, mount := GenerateConfigMapVolumeSpecs(selector)\n\t\t\tresultVolumes = append(resultVolumes, vol)\n\t\t\tresultMounts = append(resultMounts, mount)\n\t\t}\n\tdefault:\n\t}\n\treturn uniqueVolumes(resultVolumes), uniqueVolumeMounts(resultMounts)\n}\n\n// Find all the values obj's children matching provided type, type needs to be a pointer\nfunc findTypeValues(obj interface{}, t reflect.Type) []interface{} {\n\tresult := []interface{}{}\n\tvalue := reflect.ValueOf(obj)\n\tfindTypesRecursive(&result, value, t)\n\treturn result\n}\n\nfunc findTypesRecursive(result *[]interface{}, obj reflect.Value, t reflect.Type) {\n\tif obj.Type() == t && obj.CanInterface() && !obj.IsNil() {\n\t\t*result = append(*result, obj.Interface())\n\t}\n\tswitch obj.Kind() {\n\tcase reflect.Ptr:\n\t\tobjValue := obj.Elem()\n\t\t// Check if it is nil\n\t\tif !objValue.IsValid() {\n\t\t\treturn\n\t\t}\n\t\tfindTypesRecursive(result, objValue, t)\n\tcase reflect.Interface:\n\t\tobjValue := obj.Elem()\n\t\t// Check if it is nil\n\t\tif !objValue.IsValid() {\n\t\t\treturn\n\t\t}\n\t\tfindTypesRecursive(result, objValue, t)\n\tcase reflect.Struct:\n\t\tfor i := 0; i < obj.NumField(); i++ {\n\t\t\tif obj.Field(i).CanInterface() {\n\t\t\t\tfindTypesRecursive(result, obj.Field(i), t)\n\t\t\t}\n\t\t}\n\tcase reflect.Slice:\n\t\tfor i := 0; i < obj.Len(); i++ {\n\t\t\tfindTypesRecursive(result, obj.Index(i), t)\n\t\t}\n\tcase reflect.Map:\n\t\titer := obj.MapRange()\n\t\tfor iter.Next() {\n\t\t\tfindTypesRecursive(result, iter.Value(), t)\n\t\t}\n\tdefault:\n\t\treturn\n\t}\n}\n\n// GenerateSecretVolumeSpecs builds a \"volume\" and \"volumeMount\"spec with a secretKeySelector\nfunc GenerateSecretVolumeSpecs(selector *v1.SecretKeySelector) (v1.Volume, v1.VolumeMount) {\n\tvolName := strings.ReplaceAll(\"secret-\"+selector.Name, \"_\", \"-\")\n\treturn v1.Volume{\n\t\t\tName: volName,\n\t\t\tVolumeSource: v1.VolumeSource{\n\t\t\t\tSecret: &v1.SecretVolumeSource{\n\t\t\t\t\tSecretName: selector.Name,\n\t\t\t\t},\n\t\t\t},\n\t\t}, v1.VolumeMount{\n\t\t\tName:      volName,\n\t\t\tReadOnly:  true,\n\t\t\tMountPath: \"/argo-events/secrets/\" + selector.Name,\n\t\t}\n}\n\n// GenerateConfigMapVolumeSpecs builds a \"volume\" and \"volumeMount\"spec with a configMapKeySelector\nfunc GenerateConfigMapVolumeSpecs(selector *v1.ConfigMapKeySelector) (v1.Volume, v1.VolumeMount) {\n\tvolName := strings.ReplaceAll(\"cm-\"+selector.Name, \"_\", \"-\")\n\treturn v1.Volume{\n\t\t\tName: volName,\n\t\t\tVolumeSource: v1.VolumeSource{\n\t\t\t\tConfigMap: &v1.ConfigMapVolumeSource{\n\t\t\t\t\tLocalObjectReference: v1.LocalObjectReference{\n\t\t\t\t\t\tName: selector.Name,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}, v1.VolumeMount{\n\t\t\tName:      volName,\n\t\t\tReadOnly:  true,\n\t\t\tMountPath: \"/argo-events/config/\" + selector.Name,\n\t\t}\n}\n\nfunc uniqueVolumes(vols []v1.Volume) []v1.Volume {\n\trVols := []v1.Volume{}\n\tkeys := make(map[string]bool)\n\tfor _, e := range vols {\n\t\tif _, value := keys[e.Name]; !value {\n\t\t\tkeys[e.Name] = true\n\t\t\trVols = append(rVols, e)\n\t\t}\n\t}\n\treturn rVols\n}\n\nfunc uniqueVolumeMounts(mounts []v1.VolumeMount) []v1.VolumeMount {\n\trMounts := []v1.VolumeMount{}\n\tkeys := make(map[string]bool)\n\tfor _, e := range mounts {\n\t\tif _, value := keys[e.Name]; !value {\n\t\t\tkeys[e.Name] = true\n\t\t\trMounts = append(rMounts, e)\n\t\t}\n\t}\n\treturn rMounts\n}\n\n// ElementsMatch returns true if the two provided string slices contain the same elements while avoiding duplications.\n// WARN: this method avoids duplications.\nfunc ElementsMatch(first []string, second []string) bool {\n\tif len(first) == 0 && len(second) == 0 {\n\t\treturn true\n\t}\n\tif len(first) == 0 || len(second) == 0 {\n\t\treturn false\n\t}\n\n\tdiff := make(map[string]int)\n\tfor _, str := range first {\n\t\tdiff[str] = 1\n\t}\n\n\tfor _, str := range second {\n\t\tif _, ok := diff[str]; !ok {\n\t\t\treturn false\n\t\t} else {\n\t\t\tdiff[str] = 2\n\t\t}\n\t}\n\n\tfor _, v := range diff {\n\t\t// 1: only exists in first\n\t\t// 2: exists in both\n\t\tif v < 2 {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\n// SliceContains checks if a string slice contains a specific string\nfunc SliceContains(strSlice []string, targetStr string) bool {\n\tfor _, curr := range strSlice {\n\t\tif curr == targetStr {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc GetImagePullPolicy() corev1.PullPolicy {\n\timgPullPolicy := corev1.PullAlways\n\tif x := os.Getenv(EnvImagePullPolicy); x != \"\" {\n\t\timgPullPolicy = corev1.PullPolicy(x)\n\t}\n\treturn imgPullPolicy\n}\n\nfunc StructToMap(obj interface{}, output map[string]interface{}) error {\n\tdata, err := json.Marshal(obj) // Convert to a json string\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn json.Unmarshal(data, &output) // Convert to a map\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage sensor\n\nimport (\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"strings\"\n\t\"testing\"\n\n\teventbusv1alpha1 \"github.com/argoproj/argo-events/pkg/apis/eventbus/v1alpha1\"\n\t\"github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n)\n\nfunc TestValidateSensor(t *testing.T) {\n\tdir := \"../../examples/sensors\"\n\tfiles, dirErr := ioutil.ReadDir(dir)\n\trequire.NoError(t, dirErr)\n\n\tfor _, file := range files {\n\t\tt.Run(\n\t\t\tfmt.Sprintf(\"test example load: %s/%s\", dir, file.Name()),\n\t\t\tfunc(t *testing.T) {\n\t\t\t\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", dir, file.Name()))\n\t\t\t\tassert.NoError(t, err)\n\n\t\t\t\tvar sensor *v1alpha1.Sensor\n\t\t\t\teventBus := &eventbusv1alpha1.EventBus{Spec: eventbusv1alpha1.EventBusSpec{JetStream: &eventbusv1alpha1.JetStreamBus{}}}\n\t\t\t\terr = yaml.Unmarshal(content, &sensor)\n\t\t\t\tassert.NoError(t, err)\n\n\t\t\t\terr = ValidateSensor(sensor, eventBus)\n\t\t\t\tassert.NoError(t, err)\n\t\t\t})\n\t}\n}\n\nfunc TestValidDependencies(t *testing.T) {\n\tjetstreamBus := &eventbusv1alpha1.EventBus{Spec: eventbusv1alpha1.EventBusSpec{JetStream: &eventbusv1alpha1.JetStreamBus{}}}\n\tstanBus := &eventbusv1alpha1.EventBus{Spec: eventbusv1alpha1.EventBusSpec{NATS: &eventbusv1alpha1.NATSBus{}}}\n\n\tt.Run(\"test duplicate deps fail for STAN\", func(t *testing.T) {\n\t\tsObj := sensorObj.DeepCopy()\n\t\tsObj.Spec.Dependencies = append(sObj.Spec.Dependencies, v1alpha1.EventDependency{\n\t\t\tName:            \"fake-dep2\",\n\t\t\tEventSourceName: \"fake-source\",\n\t\t\tEventName:       \"fake-one\",\n\t\t})\n\t\terr := ValidateSensor(sObj, stanBus)\n\t\tassert.NotNil(t, err)\n\t\tassert.Equal(t, true, strings.Contains(err.Error(), \"is referenced for more than one dependency\"))\n\t})\n\n\tt.Run(\"test duplicate deps are fine for Jetstream\", func(t *testing.T) {\n\t\tsObj := sensorObj.DeepCopy()\n\t\tsObj.Spec.Dependencies = append(sObj.Spec.Dependencies, v1alpha1.EventDependency{\n\t\t\tName:            \"fake-dep2\",\n\t\t\tEventSourceName: \"fake-source\",\n\t\t\tEventName:       \"fake-one\",\n\t\t})\n\t\terr := ValidateSensor(sObj, jetstreamBus)\n\t\tassert.Nil(t, err)\n\t})\n\n\tt.Run(\"test empty event source name\", func(t *testing.T) {\n\t\tsObj := sensorObj.DeepCopy()\n\t\tsObj.Spec.Dependencies = append(sObj.Spec.Dependencies, v1alpha1.EventDependency{\n\t\t\tName:      \"fake-dep2\",\n\t\t\tEventName: \"fake-one\",\n\t\t})\n\t\terr := ValidateSensor(sObj, jetstreamBus)\n\t\tassert.NotNil(t, err)\n\t\tassert.Equal(t, true, strings.Contains(err.Error(), \"must define the EventSourceName\"))\n\t})\n\n\tt.Run(\"test empty event name\", func(t *testing.T) {\n\t\tsObj := sensorObj.DeepCopy()\n\t\tsObj.Spec.Dependencies = append(sObj.Spec.Dependencies, v1alpha1.EventDependency{\n\t\t\tName:            \"fake-dep2\",\n\t\t\tEventSourceName: \"fake-source\",\n\t\t})\n\t\terr := ValidateSensor(sObj, jetstreamBus)\n\t\tassert.NotNil(t, err)\n\t\tassert.Equal(t, true, strings.Contains(err.Error(), \"must define the EventName\"))\n\t})\n\n\tt.Run(\"test empty event name\", func(t *testing.T) {\n\t\tsObj := sensorObj.DeepCopy()\n\t\tsObj.Spec.Dependencies = append(sObj.Spec.Dependencies, v1alpha1.EventDependency{\n\t\t\tEventSourceName: \"fake-source2\",\n\t\t\tEventName:       \"fake-one2\",\n\t\t})\n\t\terr := ValidateSensor(sObj, jetstreamBus)\n\t\tassert.NotNil(t, err)\n\t\tassert.Equal(t, true, strings.Contains(err.Error(), \"must define a name\"))\n\t})\n}\n\nfunc TestValidateLogicalOperator(t *testing.T) {\n\tt.Run(\"test valid\", func(t *testing.T) {\n\t\tlogOp := v1alpha1.OrLogicalOperator\n\n\t\terr := validateLogicalOperator(logOp)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test not valid\", func(t *testing.T) {\n\t\tlogOp := v1alpha1.LogicalOperator(\"fake\")\n\n\t\terr := validateLogicalOperator(logOp)\n\n\t\tassert.Error(t, err)\n\t})\n}\n\nfunc TestValidateComparator(t *testing.T) {\n\tt.Run(\"test valid\", func(t *testing.T) {\n\t\tcomp := v1alpha1.NotEqualTo\n\n\t\terr := validateComparator(comp)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test not valid\", func(t *testing.T) {\n\t\tcomp := v1alpha1.Comparator(\"fake\")\n\n\t\terr := validateComparator(comp)\n\n\t\tassert.Error(t, err)\n\t})\n}\n\nfunc TestValidateEventFilter(t *testing.T) {\n\tt.Run(\"test empty\", func(t *testing.T) {\n\t\tfilter := &v1alpha1.EventDependencyFilter{}\n\n\t\terr := validateEventFilter(filter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test valid, all\", func(t *testing.T) {\n\t\tfilter := &v1alpha1.EventDependencyFilter{\n\t\t\tExprLogicalOperator: v1alpha1.OrLogicalOperator,\n\t\t\tExprs: []v1alpha1.ExprFilter{\n\t\t\t\t{\n\t\t\t\t\tExpr: \"fake-expr\",\n\t\t\t\t\tFields: []v1alpha1.PayloadField{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tPath: \"fake-path\",\n\t\t\t\t\t\t\tName: \"fake-name\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tDataLogicalOperator: v1alpha1.OrLogicalOperator,\n\t\t\tData: []v1alpha1.DataFilter{\n\t\t\t\t{\n\t\t\t\t\tPath: \"fake-path\",\n\t\t\t\t\tType: \"fake-type\",\n\t\t\t\t\tValue: []string{\n\t\t\t\t\t\t\"fake-value\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tContext: &v1alpha1.EventContext{\n\t\t\t\tType:            \"type\",\n\t\t\t\tSubject:         \"subject\",\n\t\t\t\tSource:          \"source\",\n\t\t\t\tDataContentType: \"fake-content-type\",\n\t\t\t},\n\t\t\tTime: &v1alpha1.TimeFilter{\n\t\t\t\tStart: \"00:00:00\",\n\t\t\t\tStop:  \"06:00:00\",\n\t\t\t},\n\t\t}\n\n\t\terr := validateEventFilter(filter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test valid, expr only\", func(t *testing.T) {\n\t\tfilter := &v1alpha1.EventDependencyFilter{\n\t\t\tExprs: []v1alpha1.ExprFilter{\n\t\t\t\t{\n\t\t\t\t\tExpr: \"fake-expr\",\n\t\t\t\t\tFields: []v1alpha1.PayloadField{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tPath: \"fake-path\",\n\t\t\t\t\t\t\tName: \"fake-name\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\n\t\terr := validateEventFilter(filter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test valid, data only\", func(t *testing.T) {\n\t\tfilter := &v1alpha1.EventDependencyFilter{\n\t\t\tData: []v1alpha1.DataFilter{\n\t\t\t\t{\n\t\t\t\t\tPath: \"fake-path\",\n\t\t\t\t\tType: \"fake-type\",\n\t\t\t\t\tValue: []string{\n\t\t\t\t\t\t\"fake-value\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\n\t\terr := validateEventFilter(filter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test valid, ctx only\", func(t *testing.T) {\n\t\tfilter := &v1alpha1.EventDependencyFilter{\n\t\t\tContext: &v1alpha1.EventContext{\n\t\t\t\tType:            \"type\",\n\t\t\t\tSubject:         \"subject\",\n\t\t\t\tSource:          \"source\",\n\t\t\t\tDataContentType: \"fake-content-type\",\n\t\t\t},\n\t\t}\n\n\t\terr := validateEventFilter(filter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test valid, time only\", func(t *testing.T) {\n\t\tfilter := &v1alpha1.EventDependencyFilter{\n\t\t\tTime: &v1alpha1.TimeFilter{\n\t\t\t\tStart: \"00:00:00\",\n\t\t\t\tStop:  \"06:00:00\",\n\t\t\t},\n\t\t}\n\n\t\terr := validateEventFilter(filter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test not valid, wrong logical operator\", func(t *testing.T) {\n\t\tfilter := &v1alpha1.EventDependencyFilter{\n\t\t\tDataLogicalOperator: \"fake\",\n\t\t}\n\n\t\terr := validateEventFilter(filter)\n\n\t\tassert.Error(t, err)\n\t})\n}\n\nfunc TestValidateEventExprFilter(t *testing.T) {\n\tt.Run(\"test valid\", func(t *testing.T) {\n\t\texprFilter := &v1alpha1.ExprFilter{\n\t\t\tExpr: \"fake-expr\",\n\t\t\tFields: []v1alpha1.PayloadField{\n\t\t\t\t{\n\t\t\t\t\tPath: \"fake-path\",\n\t\t\t\t\tName: \"fake-name\",\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\n\t\terr := validateEventExprFilter(exprFilter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test not valid, no expr\", func(t *testing.T) {\n\t\texprFilter := &v1alpha1.ExprFilter{\n\t\t\tFields: []v1alpha1.PayloadField{\n\t\t\t\t{\n\t\t\t\t\tPath: \"fake-path\",\n\t\t\t\t\tName: \"fake-name\",\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\n\t\terr := validateEventExprFilter(exprFilter)\n\n\t\tassert.Error(t, err)\n\t})\n\n\tt.Run(\"test not valid, no field name\", func(t *testing.T) {\n\t\texprFilter := &v1alpha1.ExprFilter{\n\t\t\tExpr: \"fake-expr\",\n\t\t\tFields: []v1alpha1.PayloadField{\n\t\t\t\t{\n\t\t\t\t\tPath: \"fake-path\",\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\n\t\terr := validateEventExprFilter(exprFilter)\n\n\t\tassert.Error(t, err)\n\t})\n}\n\nfunc TestValidateEventDataFilter(t *testing.T) {\n\tt.Run(\"test valid\", func(t *testing.T) {\n\t\tdataFilter := &v1alpha1.DataFilter{\n\t\t\tPath:  \"body.value\",\n\t\t\tType:  \"number\",\n\t\t\tValue: []string{\"50.0\"},\n\t\t}\n\n\t\terr := validateEventDataFilter(dataFilter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test not valid, no path\", func(t *testing.T) {\n\t\tdataFilter := &v1alpha1.DataFilter{\n\t\t\tType:  \"number\",\n\t\t\tValue: []string{\"50.0\"},\n\t\t}\n\n\t\terr := validateEventDataFilter(dataFilter)\n\n\t\tassert.Error(t, err)\n\t})\n\n\tt.Run(\"test not valid, empty value\", func(t *testing.T) {\n\t\tdataFilter := &v1alpha1.DataFilter{\n\t\t\tPath:  \"body.value\",\n\t\t\tType:  \"string\",\n\t\t\tValue: []string{\"\"},\n\t\t}\n\n\t\terr := validateEventDataFilter(dataFilter)\n\n\t\tassert.Error(t, err)\n\t})\n\n\tt.Run(\"test not valid, wrong comparator\", func(t *testing.T) {\n\t\tdataFilter := &v1alpha1.DataFilter{\n\t\t\tComparator: \"fake\",\n\t\t\tPath:       \"body.value\",\n\t\t\tType:       \"string\",\n\t\t\tValue:      []string{\"\"},\n\t\t}\n\n\t\terr := validateEventDataFilter(dataFilter)\n\n\t\tassert.Error(t, err)\n\t})\n}\n\nfunc TestValidateEventCtxFilter(t *testing.T) {\n\tt.Run(\"test all fields\", func(t *testing.T) {\n\t\tctxFilter := &v1alpha1.EventContext{\n\t\t\tType:            \"fake-type\",\n\t\t\tSubject:         \"fake-subject\",\n\t\t\tSource:          \"fake-source\",\n\t\t\tDataContentType: \"fake-content-type\",\n\t\t}\n\n\t\terr := validateEventCtxFilter(ctxFilter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test single field\", func(t *testing.T) {\n\t\tctxFilter := &v1alpha1.EventContext{\n\t\t\tType: \"fake-type\",\n\t\t}\n\n\t\terr := validateEventCtxFilter(ctxFilter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test no fields\", func(t *testing.T) {\n\t\tctxFilter := &v1alpha1.EventContext{}\n\n\t\terr := validateEventCtxFilter(ctxFilter)\n\n\t\tassert.Error(t, err)\n\t})\n}\n\nfunc TestValidateEventTimeFilter(t *testing.T) {\n\tt.Run(\"test start < stop\", func(t *testing.T) {\n\t\ttimeFilter := &v1alpha1.TimeFilter{\n\t\t\tStart: \"00:00:00\",\n\t\t\tStop:  \"06:00:00\",\n\t\t}\n\n\t\terr := validateEventTimeFilter(timeFilter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test stop < start\", func(t *testing.T) {\n\t\ttimeFilter := &v1alpha1.TimeFilter{\n\t\t\tStart: \"06:00:00\",\n\t\t\tStop:  \"00:00:00\",\n\t\t}\n\n\t\terr := validateEventTimeFilter(timeFilter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test start = stop\", func(t *testing.T) {\n\t\ttimeFilter := &v1alpha1.TimeFilter{\n\t\t\tStart: \"00:00:00\",\n\t\t\tStop:  \"00:00:00\",\n\t\t}\n\n\t\terr := validateEventTimeFilter(timeFilter)\n\n\t\tassert.Error(t, err)\n\t})\n}\n\nfunc TestValidTriggers(t *testing.T) {\n\tt.Run(\"duplicate trigger names\", func(t *testing.T) {\n\t\ttriggers := []v1alpha1.Trigger{\n\t\t\t{\n\t\t\t\tTemplate: &v1alpha1.TriggerTemplate{\n\t\t\t\t\tName: \"fake-trigger\",\n\t\t\t\t\tK8s: &v1alpha1.StandardK8STrigger{\n\t\t\t\t\t\tOperation: \"create\",\n\t\t\t\t\t\tSource:    &v1alpha1.ArtifactLocation{},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tTemplate: &v1alpha1.TriggerTemplate{\n\t\t\t\t\tName: \"fake-trigger\",\n\t\t\t\t\tK8s: &v1alpha1.StandardK8STrigger{\n\t\t\t\t\t\tOperation: \"create\",\n\t\t\t\t\t\tSource:    &v1alpha1.ArtifactLocation{},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\terr := validateTriggers(triggers)\n\t\tassert.NotNil(t, err)\n\t\tassert.Equal(t, true, strings.Contains(err.Error(), \"duplicate trigger name:\"))\n\t})\n\n\tt.Run(\"empty trigger template\", func(t *testing.T) {\n\t\ttriggers := []v1alpha1.Trigger{\n\t\t\t{\n\t\t\t\tTemplate: nil,\n\t\t\t},\n\t\t}\n\t\terr := validateTriggers(triggers)\n\t\tassert.NotNil(t, err)\n\t\tassert.Equal(t, true, strings.Contains(err.Error(), \"trigger template can't be nil\"))\n\t})\n\n\tt.Run(\"invalid conditions reset - cron\", func(t *testing.T) {\n\t\ttriggers := []v1alpha1.Trigger{\n\t\t\t{\n\t\t\t\tTemplate: &v1alpha1.TriggerTemplate{\n\t\t\t\t\tName:       \"fake-trigger\",\n\t\t\t\t\tConditions: \"A && B\",\n\t\t\t\t\tConditionsReset: []v1alpha1.ConditionsResetCriteria{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tByTime: &v1alpha1.ConditionsResetByTime{\n\t\t\t\t\t\t\t\tCron: \"a * * * *\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tK8s: &v1alpha1.StandardK8STrigger{\n\t\t\t\t\t\tOperation: \"create\",\n\t\t\t\t\t\tSource:    &v1alpha1.ArtifactLocation{},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\terr := validateTriggers(triggers)\n\t\tassert.NotNil(t, err)\n\t\tassert.Equal(t, true, strings.Contains(err.Error(), \"invalid cron expression\"))\n\t})\n\n\tt.Run(\"invalid conditions reset - timezone\", func(t *testing.T) {\n\t\ttriggers := []v1alpha1.Trigger{\n\t\t\t{\n\t\t\t\tTemplate: &v1alpha1.TriggerTemplate{\n\t\t\t\t\tName:       \"fake-trigger\",\n\t\t\t\t\tConditions: \"A && B\",\n\t\t\t\t\tConditionsReset: []v1alpha1.ConditionsResetCriteria{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tByTime: &v1alpha1.ConditionsResetByTime{\n\t\t\t\t\t\t\t\tCron:     \"* * * * *\",\n\t\t\t\t\t\t\t\tTimezone: \"fake\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tK8s: &v1alpha1.StandardK8STrigger{\n\t\t\t\t\t\tOperation: \"create\",\n\t\t\t\t\t\tSource:    &v1alpha1.ArtifactLocation{},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\terr := validateTriggers(triggers)\n\t\tassert.NotNil(t, err)\n\t\tassert.Equal(t, true, strings.Contains(err.Error(), \"invalid timezone\"))\n\t})\n}\n", "# HTTP Trigger\n\nArgo Events offers HTTP trigger which can easily invoke serverless functions like OpenFaaS, Kubeless, Knative, Nuclio and make REST API calls.\n\n<br/>\n<br/>\n\n<p align=\"center\">\n  <img src=\"https://github.com/argoproj/argo-events/blob/master/docs/assets/http-trigger.png?raw=true\" alt=\"HTTP Trigger\"/>\n</p>\n\n<br/>\n<br/>\n\n## Specification\nThe HTTP trigger specification is available [here](https://github.com/argoproj/argo-events/blob/master/api/sensor.md#httptrigger).\n\n## REST API Calls\n\nConsider a scenario where your REST API server needs to consume events from event-sources S3, GitHub, SQS etc. Usually, you'd end up writing\nthe integration yourself in the server code, although server logic has nothing to do any of the event-sources. This is where Argo Events HTTP trigger\ncan help. The HTTP trigger takes the task of consuming events from event-sources away from API server and seamlessly integrates these events via REST API calls.\n\n\nWe will set up a basic go http server and connect it with the Minio events.\n\n1. The HTTP server simply prints the request body as follows.\n\n        package main\n\n        import (\n        \t\"fmt\"\n        \t\"io/ioutil\"\n        \t\"net/http\"\n        )\n\n        func hello(w http.ResponseWriter, req *http.Request) {\n        \tbody, err := ioutil.ReadAll(req.Body)\n        \tif err != nil {\n        \t\tfmt.Printf(\"%+v\\n\", err)\n        \t\treturn\n        \t}\n        \tfmt.Println(string(body))\n        \tfmt.Fprintf(w, \"hello\\n\")\n        }\n\n        func main() {\n        \thttp.HandleFunc(\"/hello\", hello)\n        \tfmt.Println(\"server is listening on 8090\")\n        \thttp.ListenAndServe(\":8090\", nil)\n        }\n\n2. Deploy the HTTP server.\n\n        kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/09-http-trigger/http-server.yaml\n\n3. Create a service to expose the http server.\n\n        kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/09-http-trigger/http-server-svc.yaml\n\n4. Either use Ingress, OpenShift Route or port-forwarding to expose the http server.\n\n        kubectl -n argo-events port-forward <http-server-pod-name> 8090:8090\n\n5. Our goals is to seamlessly integrate Minio S3 bucket notifications with REST API server created in previous step. So,\n   lets set up the Minio event-source available [here](https://argoproj.github.io/argo-events/setup/minio/).\n   Don't create the sensor as we will be deploying it in next step.\n\n6. Create a sensor as follows.\n\n        kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/http-trigger.yaml\n\n7. Now, drop a file onto `input` bucket in Minio server.\n\n\n8. The sensor has triggered a http request to the http server. Take a look at the logs.\n\n        server is listening on 8090\n        {\"type\":\"minio\",\"bucket\":\"input\"}\n\n9. Great!!!\n\n### Request Payload\n\nIn order to construct a request payload based on the event data, sensor offers\n`payload` field as a part of the HTTP trigger.\n\nLet's examine a HTTP trigger,\n\n        http:\n          url: http://http-server.argo-events.svc:8090/hello\n          payload:\n            - src:\n                dependencyName: test-dep\n                dataKey: notification.0.s3.bucket.name\n              dest: bucket\n            - src:\n                dependencyName: test-dep\n                contextKey: type\n              dest: type\n          method: POST  // GET, DELETE, POST, PUT, HEAD, etc.\n\nThe `payload` contains the list of `src` which refers to the source event and `dest` which refers to destination key within result request payload.\n\nThe `payload` declared above will generate a request payload like below,\n\n        {\n          \"type\": \"type of event from event's context\"\n          \"bucket\": \"bucket name from event data\"\n        }\n\nThe above payload will be passed in the HTTP request. You can add however many number of `src` and `dest` under `payload`.\n\n**Note**: Take a look at [Parameterization](https://argoproj.github.io/argo-events/tutorials/02-parameterization/) in order to understand how to extract particular key-value from\nevent data.\n\n### Parameterization\n\nSimilar to other type of triggers, sensor offers parameterization for the HTTP trigger. Parameterization is specially useful when\nyou want to define a generic trigger template in the sensor and populate values like URL, payload values on the fly.\n\nYou can learn more about trigger parameterization [here](https://argoproj.github.io/argo-events/tutorials/02-parameterization/).\n\n### Policy\nTrigger policy helps you determine the status of the HTTP request and decide whether to stop or continue sensor.\n\nTo determine whether the HTTP request was successful or not, the HTTP trigger provides a `Status` policy.\nThe `Status` holds a list of response statuses that are considered valid.\n\n        http:\n          url: http://http-server.argo-events.svc:8090/hello\n          payload:\n            - src:\n                dependencyName: test-dep\n                dataKey: notification.0s3.bucket.name\n              dest: bucket\n            - src:\n                dependencyName: test-dep\n                contextKey: type\n              dest: type\n          method: POST  // GET, DELETE, POST, PUT, HEAD, etc.\n      retryStrategy:\n        steps: 3\n        duration: 3s\n      policy:\n        status:\n          allow:\n            - 200\n            - 201\n\nThe above HTTP trigger will be treated successful only if the HTTP request returns with either 200 or 201 status.\n\n## OpenFaaS\n\nOpenFaaS offers a simple way to spin up serverless functions. Lets see how we can leverage Argo Events HTTP trigger\nto invoke OpenFaaS function.\n\n1. If you don't have OpenFaaS installed, follow the [instructions](https://docs.openfaas.com/deployment/kubernetes/).\n\n2. Let's create a basic function. You can follow the [steps](https://blog.alexellis.io/serverless-golang-with-openfaas/).\n   to set up the function.\n\n\n        package function\n\n        import (\n        \t\"fmt\"\n        )\n\n        // Handle a serverless request\n        func Handle(req []byte) string {\n        \treturn fmt.Sprintf(\"Hello, Go. You said: %s\", string(req))\n        }\n\n\n3. Make sure the function pod is up and running.\n\n4. We are going to invoke OpenFaaS function on a message on Redis Subscriber.\n\n5. Let's set up the Redis Database, Redis PubSub event-source as specified [here](https://argoproj.github.io/argo-events/setup/redis/).\n   Do not create the Redis sensor, we are going to create it in next step.\n\n6. Let's create the sensor with OpenFaaS trigger.\n\n        apiVersion: argoproj.io/v1alpha1\n        kind: Sensor\n        metadata:\n          name: redis-sensor\n        spec:\n          dependencies:\n            - name: test-dep\n              eventSourceName: redis\n              eventName: example\n          triggers:\n            - template:\n                name: openfaas-trigger\n                http:\n                  url: http://gateway.openfaas.svc.cluster.local:8080/function/gohash\n                  payload:\n                    - src:\n                        dependencyName: test-dep\n                      dest: bucket\n                  method: POST\n\n7. Publish a message on `FOO` channel using `redis-cli`.\n\n        PUBLISH FOO hello\n\n8. As soon as you publish the message, the sensor will invoke the OpenFaaS function `gohash`.\n\n## Kubeless\n\nSimilar to REST API calls, you can easily invoke Kubeless functions using HTTP trigger.\n\n1. If you don't have Kubeless installed, follow the [installation](https://kubeless.io/docs/quick-start/).\n\n2. Lets create a basic function.\n\n        def hello(event, context):\n          print event\n          return event['data']\n\n3. Make sure the function pod and service is created.\n\n4. Now, we are going to invoke the Kubeless function when a message is placed on a NATS queue.\n\n5. Let's set up the NATS event-source. Follow [instructions](https://argoproj.github.io/argo-events/setup/nats/#setup) for details.\n   Do not create the NATS sensor, we are going to create it in next step.\n\n6. Let's create NATS sensor with HTTP trigger.\n\n        apiVersion: argoproj.io/v1alpha1\n        kind: Sensor\n        metadata:\n          name: nats-sensor\n        spec:\n          dependencies:\n            - name: test-dep\n              eventSourceName: nats\n              eventName: example\n          triggers:\n            - template:\n                name: kubeless-trigger\n                http:\n                  serverURL: http://hello.kubeless.svc.cluster.local:8080\n                  payload:\n                    - src:\n                        dependencyName: test-dep\n                        dataKey: body.first_name\n                      dest: first_name\n                    - src:\n                        dependencyName: test-dep\n                        dataKey: body.last_name\n                      dest: last_name\n                  method: POST\n\n7. Once event-source and sensor pod are up and running, dispatch a message on `foo` subject using nats client.\n\n        go run main.go -s localhost foo '{\"first_name\": \"foo\", \"last_name\": \"bar\"}'\n\n8. It will invoke Kubeless function `hello`.\n\n        {'event-time': None, 'extensions': {'request': <LocalRequest: POST http://hello.kubeless.svc.cluster.local:8080/> }, 'event-type': None, 'event-namespace': None, 'data': '{\"first_name\":\"foo\",\"last_name\":\"bar\"}', 'event-id': None}\n\n# Other serverless frameworks\n\nSimilar to OpenFaaS and Kubeless invocation demonstrated above, you can easily trigger KNative, Nuclio, Fission functions using HTTP trigger.\n", "package naivewatcher\n\nimport (\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"syscall\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/common/fsevent\"\n)\n\ntype WatchableTestFS struct {\n}\n\ntype TestFSID struct {\n\tDevice int32\n\tInode  uint64\n}\n\nfunc (w *WatchableTestFS) Walk(root string, walkFn filepath.WalkFunc) error {\n\treturn filepath.Walk(root, walkFn)\n}\n\nfunc (w *WatchableTestFS) GetFileID(fi os.FileInfo) interface{} {\n\tstat := fi.Sys().(*syscall.Stat_t)\n\treturn TestFSID{\n\t\tDevice: int32(stat.Dev),\n\t\tInode:  stat.Ino,\n\t}\n}\n\nfunc TestWatcherAutoCheck(t *testing.T) {\n\twatcher, err := NewWatcher(&WatchableTestFS{})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer watcher.Close()\n\n\ttmpdir, err := ioutil.TempDir(\"\", \"naive-watcher-\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer os.RemoveAll(tmpdir)\n\n\terr = watcher.Add(tmpdir)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\terr = watcher.Start(100 * time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer func() {\n\t\tif err := watcher.Stop(); err != nil {\n\t\t\tfmt.Printf(\"failed to stop the watcher. err: %+v\\n\", err)\n\t\t}\n\t}()\n\n\t// Create a file\n\t_, err = os.Create(filepath.Join(tmpdir, \"foo\"))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\ttime.Sleep(200 * time.Millisecond)\n\tevents := readEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{\n\t\t{Op: fsevent.Create, Name: filepath.Join(tmpdir, \"foo\")},\n\t}, events)\n\n\t// Rename a file\n\terr = os.Rename(filepath.Join(tmpdir, \"foo\"), filepath.Join(tmpdir, \"bar\"))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\ttime.Sleep(200 * time.Millisecond)\n\tevents = readEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{\n\t\t{Op: fsevent.Rename, Name: filepath.Join(tmpdir, \"bar\")},\n\t}, events)\n\n\t// Write a file\n\terr = ioutil.WriteFile(filepath.Join(tmpdir, \"bar\"), []byte(\"wow\"), 0666)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\ttime.Sleep(200 * time.Millisecond)\n\tevents = readEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{\n\t\t{Op: fsevent.Write, Name: filepath.Join(tmpdir, \"bar\")},\n\t}, events)\n\n\t// Chmod a file\n\terr = os.Chmod(filepath.Join(tmpdir, \"bar\"), 0777)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\ttime.Sleep(200 * time.Millisecond)\n\tevents = readEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{\n\t\t{Op: fsevent.Chmod, Name: filepath.Join(tmpdir, \"bar\")},\n\t}, events)\n\n\t// Rename & Write & Chmod a file\n\terr = os.Rename(filepath.Join(tmpdir, \"bar\"), filepath.Join(tmpdir, \"foo\"))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\terr = ioutil.WriteFile(filepath.Join(tmpdir, \"foo\"), []byte(\"wowwow\"), 0666)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\terr = os.Chmod(filepath.Join(tmpdir, \"foo\"), 0770)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tvar actualOps fsevent.Op\n\ttime.Sleep(200 * time.Millisecond)\n\tevents = readEvents(t, watcher)\n\tfor _, event := range events {\n\t\tif event.Name == filepath.Join(tmpdir, \"foo\") {\n\t\t\tactualOps |= event.Op\n\t\t}\n\t}\n\tassert.Equal(t, fsevent.Write|fsevent.Rename|fsevent.Chmod, actualOps)\n\n\t// Remove a file\n\terr = os.Remove(filepath.Join(tmpdir, \"foo\"))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\ttime.Sleep(200 * time.Millisecond)\n\tevents = readEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{\n\t\t{Op: fsevent.Remove, Name: filepath.Join(tmpdir, \"foo\")},\n\t}, events)\n\n\terr = watcher.Stop()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\terr = watcher.Remove(tmpdir)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestWatcherManualCheck(t *testing.T) {\n\twatcher, err := NewWatcher(&WatchableTestFS{})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer watcher.Close()\n\n\ttmpdir, err := ioutil.TempDir(\"\", \"naive-watcher-\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer os.RemoveAll(tmpdir)\n\n\terr = watcher.Add(tmpdir)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tevents := checkAndReadEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{}, events)\n\n\t// Create a file\n\t_, err = os.Create(filepath.Join(tmpdir, \"foo\"))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tevents = checkAndReadEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{\n\t\t{Op: fsevent.Create, Name: filepath.Join(tmpdir, \"foo\")},\n\t}, events)\n\n\t// Rename a file\n\terr = os.Rename(filepath.Join(tmpdir, \"foo\"), filepath.Join(tmpdir, \"bar\"))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tevents = checkAndReadEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{\n\t\t{Op: fsevent.Rename, Name: filepath.Join(tmpdir, \"bar\")},\n\t}, events)\n\n\t// Write a file\n\terr = ioutil.WriteFile(filepath.Join(tmpdir, \"bar\"), []byte(\"wow\"), 0666)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tevents = checkAndReadEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{\n\t\t{Op: fsevent.Write, Name: filepath.Join(tmpdir, \"bar\")},\n\t}, events)\n\n\t// Chmod a file\n\terr = os.Chmod(filepath.Join(tmpdir, \"bar\"), 0777)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tevents = checkAndReadEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{\n\t\t{Op: fsevent.Chmod, Name: filepath.Join(tmpdir, \"bar\")},\n\t}, events)\n\n\t// Rename & Write & Chmod a file\n\terr = os.Rename(filepath.Join(tmpdir, \"bar\"), filepath.Join(tmpdir, \"foo\"))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\terr = ioutil.WriteFile(filepath.Join(tmpdir, \"foo\"), []byte(\"wowwow\"), 0666)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\terr = os.Chmod(filepath.Join(tmpdir, \"foo\"), 0770)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tevents = checkAndReadEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{\n\t\t{Op: fsevent.Write | fsevent.Rename | fsevent.Chmod, Name: filepath.Join(tmpdir, \"foo\")},\n\t}, events)\n\n\t// Remove a file\n\terr = os.Remove(filepath.Join(tmpdir, \"foo\"))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tevents = checkAndReadEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{\n\t\t{Op: fsevent.Remove, Name: filepath.Join(tmpdir, \"foo\")},\n\t}, events)\n\n\terr = watcher.Remove(tmpdir)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc checkAndReadEvents(t *testing.T, watcher *Watcher) []fsevent.Event {\n\terr := watcher.Check()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\treturn readEvents(t, watcher)\n}\n\nfunc readEvents(t *testing.T, watcher *Watcher) []fsevent.Event {\n\tevents := []fsevent.Event{}\nL:\n\tfor {\n\t\tselect {\n\t\tcase event := <-watcher.Events:\n\t\t\tevents = append(events, event)\n\t\tdefault:\n\t\t\tbreak L\n\t\t}\n\t}\n\treturn events\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage amqp\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"either url or urlSecret must be specified\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"amqp.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.AMQP)\n\n\tfor _, value := range eventSource.Spec.AMQP {\n\t\tl := &EventListener{\n\t\t\tAMQPEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage awssns\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto/x509\"\n\t\"encoding/base64\"\n\t\"encoding/json\"\n\t\"encoding/pem\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"reflect\"\n\t\"regexp\"\n\t\"time\"\n\n\tsnslib \"github.com/aws/aws-sdk-go/service/sns\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/pkg/errors\"\n\t\"go.uber.org/zap\"\n\n\t\"github.com/argoproj/argo-events/common\"\n\t\"github.com/argoproj/argo-events/common/logging\"\n\teventsourcecommon \"github.com/argoproj/argo-events/eventsources/common\"\n\tcommonaws \"github.com/argoproj/argo-events/eventsources/common/aws\"\n\t\"github.com/argoproj/argo-events/eventsources/common/webhook\"\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\tmetrics \"github.com/argoproj/argo-events/metrics\"\n\tapicommon \"github.com/argoproj/argo-events/pkg/apis/common\"\n\t\"github.com/argoproj/argo-events/pkg/apis/events\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nvar (\n\t// controller controls the webhook operations\n\tcontroller = webhook.NewController()\n\n\t// used for SNS verification\n\tsnsSigKeys      = map[string][]string{}\n\tsnsKeyRealNames = map[string]string{\n\t\t\"MessageID\": \"MessageId\",\n\t\t\"TopicARN\":  \"TopicArn\",\n\t}\n)\n\n// set up route activation and deactivation channels\nfunc init() {\n\tgo webhook.ProcessRouteStatus(controller)\n\n\tsnsSigKeys[messageTypeNotification] = []string{\n\t\t\"Message\",\n\t\t\"MessageID\",\n\t\t\"Subject\",\n\t\t\"Timestamp\",\n\t\t\"TopicARN\",\n\t\t\"Type\",\n\t}\n\tsnsSigKeys[messageTypeSubscriptionConfirmation] = []string{\n\t\t\"Message\",\n\t\t\"MessageID\",\n\t\t\"SubscribeURL\",\n\t\t\"Timestamp\",\n\t\t\"Token\",\n\t\t\"TopicARN\",\n\t\t\"Type\",\n\t}\n}\n\n// Implement Router\n// 1. GetRoute\n// 2. HandleRoute\n// 3. PostActivate\n// 4. PostDeactivate\n\n// GetRoute returns the route\nfunc (router *Router) GetRoute() *webhook.Route {\n\treturn router.Route\n}\n\n// HandleRoute handles new routes\nfunc (router *Router) HandleRoute(writer http.ResponseWriter, request *http.Request) {\n\troute := router.Route\n\n\tlogger := route.Logger.With(\n\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\tlogging.LabelPort, route.Context.Port,\n\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t)\n\n\tlogger.Info(\"request received from event source\")\n\n\tif !route.Active {\n\t\tlogger.Info(\"endpoint is not active, won't process the request\")\n\t\tcommon.SendErrorResponse(writer, \"inactive endpoint\")\n\t\treturn\n\t}\n\n\tdefer func(start time.Time) {\n\t\troute.Metrics.EventProcessingDuration(route.EventSourceName, route.EventName, float64(time.Since(start)/time.Millisecond))\n\t}(time.Now())\n\n\tbody, err := ioutil.ReadAll(request.Body)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to parse the request body\", zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tvar notification *httpNotification\n\terr = yaml.Unmarshal(body, &notification)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to convert request payload into sns notification\", zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tif notification == nil {\n\t\tcommon.SendErrorResponse(writer, \"bad request, not a valid SNS notification\")\n\t\treturn\n\t}\n\n\t// SNS Signature Verification\n\tif router.eventSource.ValidateSignature {\n\t\terr = notification.verify()\n\t\tif err != nil {\n\t\t\tlogger.Errorw(\"failed to verify sns message\", zap.Error(err))\n\t\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\t\treturn\n\t\t}\n\t}\n\n\tswitch notification.Type {\n\tcase messageTypeSubscriptionConfirmation:\n\t\tawsSession := router.session\n\n\t\tresponse, err := awsSession.ConfirmSubscription(&snslib.ConfirmSubscriptionInput{\n\t\t\tTopicArn: &router.eventSource.TopicArn,\n\t\t\tToken:    &notification.Token,\n\t\t})\n\t\tif err != nil {\n\t\t\tlogger.Errorw(\"failed to send confirmation response to aws sns\", zap.Error(err))\n\t\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\t\treturn\n\t\t}\n\n\t\tlogger.Info(\"subscription successfully confirmed to aws sns\")\n\t\trouter.subscriptionArn = response.SubscriptionArn\n\n\tcase messageTypeNotification:\n\t\tlogger.Info(\"dispatching notification on route's data channel\")\n\n\t\teventData := &events.SNSEventData{\n\t\t\tHeader:   request.Header,\n\t\t\tBody:     (*json.RawMessage)(&body),\n\t\t\tMetadata: router.eventSource.Metadata,\n\t\t}\n\n\t\teventBytes, err := json.Marshal(eventData)\n\t\tif err != nil {\n\t\t\tlogger.Errorw(\"failed to marshal the event data\", zap.Error(err))\n\t\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\t\treturn\n\t\t}\n\t\troute.DataCh <- eventBytes\n\t}\n\n\tlogger.Info(\"request has been successfully processed\")\n}\n\n// PostActivate refers to operations performed after a route is successfully activated\nfunc (router *Router) PostActivate() error {\n\troute := router.Route\n\n\tlogger := route.Logger.With(\n\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\tlogging.LabelPort, route.Context.Port,\n\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t\t\"topic-arn\", router.eventSource.TopicArn,\n\t)\n\n\t// In order to successfully subscribe to sns topic,\n\t// 1. Fetch credentials if configured explicitly. Users can use something like https://github.com/jtblin/kube2iam\n\t//    which will help not configure creds explicitly.\n\t// 2. Get AWS session\n\t// 3. Subscribe to a topic\n\n\tlogger.Info(\"subscribing to sns topic...\")\n\n\tsnsEventSource := router.eventSource\n\n\tawsSession, err := commonaws.CreateAWSSessionWithCredsInVolume(snsEventSource.Region, snsEventSource.RoleARN, snsEventSource.AccessKey, snsEventSource.SecretKey)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\trouter.session = snslib.New(awsSession)\n\tformattedURL := common.FormattedURL(snsEventSource.Webhook.URL, snsEventSource.Webhook.Endpoint)\n\tif _, err := router.session.Subscribe(&snslib.SubscribeInput{\n\t\tEndpoint: &formattedURL,\n\t\tProtocol: func(endpoint string) *string {\n\t\t\tProtocol := \"http\"\n\t\t\tif matched, _ := regexp.MatchString(`https://.*`, endpoint); matched {\n\t\t\t\tProtocol = \"https\"\n\t\t\t\treturn &Protocol\n\t\t\t}\n\t\t\treturn &Protocol\n\t\t}(formattedURL),\n\t\tTopicArn: &snsEventSource.TopicArn,\n\t}); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\n// PostInactivate refers to operations performed after a route is successfully inactivated\nfunc (router *Router) PostInactivate() error {\n\t// After event source is removed, the subscription is cancelled.\n\tif _, err := router.session.Unsubscribe(&snslib.UnsubscribeInput{\n\t\tSubscriptionArn: router.subscriptionArn,\n\t}); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n\n// EventListener implements Eventing for aws sns event source\ntype EventListener struct {\n\tEventSourceName string\n\tEventName       string\n\tSNSEventSource  v1alpha1.SNSEventSource\n\tMetrics         *metrics.Metrics\n}\n\n// GetEventSourceName returns name of event source\nfunc (el *EventListener) GetEventSourceName() string {\n\treturn el.EventSourceName\n}\n\n// GetEventName returns name of event\nfunc (el *EventListener) GetEventName() string {\n\treturn el.EventName\n}\n\n// GetEventSourceType return type of event server\nfunc (el *EventListener) GetEventSourceType() apicommon.EventSourceType {\n\treturn apicommon.SNSEvent\n}\n\n// StartListening starts an SNS event source\nfunc (el *EventListener) StartListening(ctx context.Context, dispatch func([]byte, ...eventsourcecommon.Option) error) error {\n\tlogger := logging.FromContext(ctx).\n\t\tWith(logging.LabelEventSourceType, el.GetEventSourceType(), logging.LabelEventName, el.GetEventName())\n\n\tdefer sources.Recover(el.GetEventName())\n\n\tlogger.Info(\"started processing the AWS SNS event source...\")\n\n\troute := webhook.NewRoute(el.SNSEventSource.Webhook, logger, el.GetEventSourceName(), el.GetEventName(), el.Metrics)\n\n\tlogger.Info(\"operating on the route...\")\n\treturn webhook.ManageRoute(ctx, &Router{\n\t\tRoute:       route,\n\t\teventSource: &el.SNSEventSource,\n\t}, controller, dispatch)\n}\n\nfunc (m *httpNotification) verifySigningCertUrl() error {\n\tregexSigningCertHost := `^sns\\.[a-zA-Z0-9\\-]{3,}\\.amazonaws\\.com(\\.cn)?$`\n\tregex := regexp.MustCompile(regexSigningCertHost)\n\turl, err := url.Parse(m.SigningCertURL)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"SigningCertURL is not a valid URL\")\n\t}\n\tif !regex.MatchString(url.Hostname()) {\n\t\treturn errors.Errorf(\"SigningCertURL hostname `%s` does not match `%s`\", url.Hostname(), regexSigningCertHost)\n\t}\n\tif url.Scheme != \"https\" {\n\t\treturn errors.New(\"SigningCertURL is not using https\")\n\t}\n\treturn nil\n}\n\nfunc (m *httpNotification) verify() error {\n\tmsgSig, err := base64.StdEncoding.DecodeString(m.Signature)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"failed to base64 decode signature\")\n\t}\n\n\tif err := m.verifySigningCertUrl(); err != nil {\n\t\treturn errors.Wrap(err, \"failed to verify SigningCertURL\")\n\t}\n\n\tres, err := http.Get(m.SigningCertURL)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"failed to fetch signing cert\")\n\t}\n\tdefer res.Body.Close()\n\n\tbody, err := ioutil.ReadAll(res.Body)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"failed to read signing cert body\")\n\t}\n\n\tp, _ := pem.Decode(body)\n\tif p == nil {\n\t\treturn errors.New(\"nothing found in pem encoded bytes\")\n\t}\n\n\tcert, err := x509.ParseCertificate(p.Bytes)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"failed to parse signing cert\")\n\t}\n\n\terr = cert.CheckSignature(x509.SHA1WithRSA, m.sigSerialized(), msgSig)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"message signature check error\")\n\t}\n\n\treturn nil\n}\n\nfunc (m *httpNotification) sigSerialized() []byte {\n\tbuf := &bytes.Buffer{}\n\tv := reflect.ValueOf(m)\n\n\tfor _, key := range snsSigKeys[m.Type] {\n\t\tfield := reflect.Indirect(v).FieldByName(key)\n\t\tval := field.String()\n\t\tif !field.IsValid() || val == \"\" {\n\t\t\tcontinue\n\t\t}\n\t\tif rn, ok := snsKeyRealNames[key]; ok {\n\t\t\tkey = rn\n\t\t}\n\t\tbuf.WriteString(key + \"\\n\")\n\t\tbuf.WriteString(val + \"\\n\")\n\t}\n\n\treturn buf.Bytes()\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage awssns\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"must specify topic arn\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"aws-sns.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.SNS)\n\n\tfor _, value := range eventSource.Spec.SNS {\n\t\tl := &EventListener{\n\t\t\tSNSEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage awssqs\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{\n\t\tSQSEventSource: v1alpha1.SQSEventSource{\n\t\t\tRegion: \"test-reg\",\n\t\t},\n\t}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"must specify queue name\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"aws-sqs.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.SQS)\n\n\tfor _, value := range eventSource.Spec.SQS {\n\t\tl := &EventListener{\n\t\t\tSQSEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage azureeventshub\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"FQDN is not specified\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"azure-events-hub.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.AzureEventsHub)\n\n\tfor _, value := range eventSource.Spec.AzureEventsHub {\n\t\tl := &EventListener{\n\t\t\tAzureEventsHubEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage bitbucket\n\nimport (\n\t\"context\"\n\t\"crypto/rand\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"math/big\"\n\t\"net/http\"\n\t\"time\"\n\n\tbitbucketv2 \"github.com/ktrysmt/go-bitbucket\"\n\t\"github.com/mitchellh/mapstructure\"\n\t\"github.com/pkg/errors\"\n\t\"go.uber.org/zap\"\n\n\t\"github.com/argoproj/argo-events/common\"\n\t\"github.com/argoproj/argo-events/common/logging\"\n\teventsourcecommon \"github.com/argoproj/argo-events/eventsources/common\"\n\t\"github.com/argoproj/argo-events/eventsources/common/webhook\"\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/events\"\n)\n\n// controller controls the webhook operations\nvar (\n\tcontroller = webhook.NewController()\n)\n\n// set up the activation and inactivation channels to control the state of routes.\nfunc init() {\n\tgo webhook.ProcessRouteStatus(controller)\n}\n\n// Implement Router\n// 1. GetRoute\n// 2. HandleRoute\n// 3. PostActivate\n// 4. PostInactivate\n\n// GetRoute returns the route\nfunc (router *Router) GetRoute() *webhook.Route {\n\treturn router.route\n}\n\n// HandleRoute handles incoming requests on the route\nfunc (router *Router) HandleRoute(writer http.ResponseWriter, request *http.Request) {\n\troute := router.GetRoute()\n\tlogger := route.Logger.With(\n\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\tlogging.LabelPort, route.Context.Port,\n\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t)\n\n\tlogger.Info(\"received a request, processing it...\")\n\n\tif !route.Active {\n\t\tlogger.Info(\"endpoint is not active, won't process the request\")\n\t\tcommon.SendErrorResponse(writer, \"inactive endpoint\")\n\t\treturn\n\t}\n\n\tbody, err := ioutil.ReadAll(request.Body)\n\tif err != nil {\n\t\tlogger.Desugar().Error(\"failed to parse request body\", zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\treturn\n\t}\n\n\tevent := &events.BitbucketEventData{\n\t\tHeaders:  request.Header,\n\t\tBody:     (*json.RawMessage)(&body),\n\t\tMetadata: router.bitbucketEventSource.Metadata,\n\t}\n\n\teventBody, err := json.Marshal(event)\n\tif err != nil {\n\t\tlogger.Info(\"failed to marshal event\")\n\t\tcommon.SendErrorResponse(writer, \"invalid event\")\n\t\treturn\n\t}\n\n\tlogger.Info(\"dispatching event on route's data channel\")\n\troute.DataCh <- eventBody\n\n\tlogger.Info(\"request successfully processed\")\n\tcommon.SendSuccessResponse(writer, \"success\")\n}\n\n// PostActivate performs operations once the route is activated and ready to consume requests\nfunc (router *Router) PostActivate() error {\n\treturn nil\n}\n\n// PostInactivate performs operations after the route is inactivated\nfunc (router *Router) PostInactivate() error {\n\tbitbucketEventSource := router.bitbucketEventSource\n\tlogger := router.GetRoute().Logger\n\n\tif bitbucketEventSource.DeleteHookOnFinish && router.hookID != \"\" {\n\t\tlogger.Info(\"deleting webhook from bitbucket...\")\n\t\tif err := router.deleteWebhook(router.hookID); err != nil {\n\t\t\tlogger.Errorw(\"failed to delete webhook\", zap.Error(err))\n\t\t\treturn errors.Wrapf(err, \"failed to delete hook for repo %s/%s.\", bitbucketEventSource.Owner, bitbucketEventSource.RepositorySlug)\n\t\t}\n\n\t\tlogger.Infof(\"successfully deleted hook for repo %s/%s\", bitbucketEventSource.Owner, bitbucketEventSource.RepositorySlug)\n\t}\n\n\treturn nil\n}\n\n// StartListening starts an event source\nfunc (el *EventListener) StartListening(ctx context.Context, dispatch func([]byte, ...eventsourcecommon.Option) error) error {\n\tdefer sources.Recover(el.GetEventName())\n\n\tbitbucketEventSource := &el.BitbucketEventSource\n\tlogger := logging.FromContext(ctx).With(\n\t\tlogging.LabelEventSourceType, el.GetEventSourceType(),\n\t\tlogging.LabelEventName, el.GetEventName(),\n\t)\n\n\tlogger.Info(\"started processing the Bitbucket event source...\")\n\troute := webhook.NewRoute(bitbucketEventSource.Webhook, logger, el.GetEventSourceName(), el.GetEventName(), el.Metrics)\n\trouter := &Router{\n\t\troute:                route,\n\t\tbitbucketEventSource: bitbucketEventSource,\n\t}\n\n\tif !bitbucketEventSource.ShouldCreateWebhook() {\n\t\tlogger.Info(\"no need to create webhook\")\n\t\treturn webhook.ManageRoute(ctx, router, controller, dispatch)\n\t}\n\n\tlogger.Info(\"choosing bitbucket auth strategy...\")\n\tauthStrategy, err := router.chooseAuthStrategy()\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"failed to get bitbucket auth strategy\")\n\t}\n\n\trouter.client = authStrategy.BitbucketClient()\n\n\t// When running multiple replicas of the eventsource, they will all try to create the webhook.\n\t// Randomly sleep some time to mitigate the issue.\n\trandomNum, _ := rand.Int(rand.Reader, big.NewInt(int64(2000)))\n\ttime.Sleep(time.Duration(randomNum.Int64()) * time.Millisecond)\n\n\terr = router.applyBitbucketWebhook()\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to save Bitbucket webhook\", zap.Error(err))\n\t}\n\n\t// Bitbucket hooks manager daemon\n\tgo func() {\n\t\t// Another kind of race conditions might happen when pods do rolling upgrade - new pod starts\n\t\t// and old pod terminates, if DeleteHookOnFinish is true, the hook will be deleted from Bitbucket.\n\t\t// This is a workaround to mitigate the race conditions.\n\t\tlogger.Info(\"starting bitbucket hooks manager daemon\")\n\t\tticker := time.NewTicker(60 * time.Second)\n\t\tdefer ticker.Stop()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\tlogger.Info(\"exiting bitbucket hooks manager daemon\")\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t\terr := router.applyBitbucketWebhook()\n\t\t\t\tif err != nil {\n\t\t\t\t\tlogger.Errorw(\"failed to save Bitbucket webhook\", zap.Error(err))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn webhook.ManageRoute(ctx, router, controller, dispatch)\n}\n\n// chooseAuthStrategy returns an AuthStrategy based on the given credentials\nfunc (router *Router) chooseAuthStrategy() (AuthStrategy, error) {\n\tes := router.bitbucketEventSource\n\tswitch {\n\tcase es.HasBitbucketBasicAuth():\n\t\treturn NewBasicAuthStrategy(es.Auth.Basic.Username, es.Auth.Basic.Password)\n\tcase es.HasBitbucketOAuthToken():\n\t\treturn NewOAuthTokenAuthStrategy(es.Auth.OAuthToken)\n\tdefault:\n\t\treturn nil, errors.New(\"none of the supported auth options were provided\")\n\t}\n}\n\n// applyBitbucketWebhook creates or updates the configured webhook in Bitbucket\nfunc (router *Router) applyBitbucketWebhook() error {\n\tlogger := router.GetRoute().Logger\n\tbitbucketEventSource := router.bitbucketEventSource\n\tformattedWebhookURL := common.FormattedURL(bitbucketEventSource.Webhook.URL, bitbucketEventSource.Webhook.Endpoint)\n\n\tlogger.Info(\"listing existing webhooks...\")\n\thooks, err := router.listWebhooks()\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to list webhooks\", zap.Error(err))\n\t\treturn errors.Wrap(err, \"failed to list webhooks\")\n\t}\n\n\tlogger.Info(\"checking if webhook already exists...\")\n\texistingHookSubscription, isFound := router.findWebhook(hooks, formattedWebhookURL)\n\tif isFound {\n\t\tlogger.Info(\"webhook already exists\")\n\t\tif router.shouldUpdateWebhook(existingHookSubscription) {\n\t\t\tlogger.Info(\"webhook requires an update\")\n\t\t\tif _, err = router.updateWebhook(existingHookSubscription); err != nil {\n\t\t\t\tlogger.Errorw(\"failed to update webhook\", zap.Error(err))\n\t\t\t\treturn errors.Wrap(err, \"failed to update existing webhook\")\n\t\t\t}\n\n\t\t\tlogger.Info(\"successfully updated the webhook\")\n\t\t}\n\n\t\treturn nil\n\t}\n\n\tlogger.Info(\"webhook doesn't exist yet, creating a new webhook...\")\n\tnewWebhook, err := router.createWebhook(formattedWebhookURL)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to create new webhook\", zap.Error(err))\n\t\treturn errors.Wrap(err, \"failed to create new webhook\")\n\t}\n\n\trouter.hookID = newWebhook.Uuid\n\n\tlogger.Info(\"successfully created a new webhook\")\n\treturn nil\n}\n\n// createWebhook creates a new webhook\nfunc (router *Router) createWebhook(formattedWebhookURL string) (*bitbucketv2.Webhook, error) {\n\tes := router.bitbucketEventSource\n\topt := &bitbucketv2.WebhooksOptions{\n\t\tOwner:       es.Owner,\n\t\tRepoSlug:    es.RepositorySlug,\n\t\tUrl:         formattedWebhookURL,\n\t\tDescription: \"webhook managed by Argo-Events\",\n\t\tActive:      true,\n\t\tEvents:      es.Events,\n\t}\n\n\treturn router.client.Repositories.Webhooks.Create(opt)\n}\n\n// updateWebhook updates an existing webhook\nfunc (router *Router) updateWebhook(existingHookSubscription *WebhookSubscription) (*bitbucketv2.Webhook, error) {\n\tes := router.bitbucketEventSource\n\topt := &bitbucketv2.WebhooksOptions{\n\t\tOwner:       es.Owner,\n\t\tRepoSlug:    es.RepositorySlug,\n\t\tUuid:        existingHookSubscription.Uuid,\n\t\tDescription: existingHookSubscription.Description,\n\t\tUrl:         existingHookSubscription.Url,\n\t\tActive:      existingHookSubscription.Active,\n\t\tEvents:      es.Events,\n\t}\n\n\treturn router.client.Repositories.Webhooks.Update(opt)\n}\n\n// deleteWebhook deletes an existing webhook\nfunc (router *Router) deleteWebhook(hookID string) error {\n\tes := router.bitbucketEventSource\n\t_, err := router.client.Repositories.Webhooks.Delete(&bitbucketv2.WebhooksOptions{\n\t\tOwner:    es.Owner,\n\t\tRepoSlug: es.RepositorySlug,\n\t\tUuid:     hookID,\n\t})\n\n\treturn err\n}\n\n// listWebhooks gets a list of all existing webhooks in target repository\nfunc (router *Router) listWebhooks() ([]WebhookSubscription, error) {\n\tes := router.bitbucketEventSource\n\thooksResponse, err := router.client.Repositories.Webhooks.Gets(&bitbucketv2.WebhooksOptions{\n\t\tOwner:    es.Owner,\n\t\tRepoSlug: es.RepositorySlug,\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn router.extractHooksFromListResponse(hooksResponse)\n}\n\n// extractHooksFromListResponse helper that extracts the list of webhooks from the response of listWebhooks\nfunc (router *Router) extractHooksFromListResponse(listHooksResponse interface{}) ([]WebhookSubscription, error) {\n\tlogger := router.GetRoute().Logger\n\tres, ok := listHooksResponse.(map[string]interface{})\n\tif !ok {\n\t\tlogger.Errorw(\"failed to parse the list webhooks response\", zap.Any(\"response\", listHooksResponse))\n\t\treturn nil, fmt.Errorf(\"failed to parse the list webhooks response\")\n\t}\n\n\tvar hooks []WebhookSubscription\n\terr := mapstructure.Decode(res[\"values\"], &hooks)\n\tif err != nil || hooks == nil {\n\t\tlogger.Errorw(\"failed to parse the list webhooks response\", zap.Any(\"response\", listHooksResponse))\n\t\treturn nil, fmt.Errorf(\"failed to parse the list webhooks response\")\n\t}\n\n\treturn hooks, nil\n}\n\n// findWebhook searches for a webhook in a list by its URL and returns the webhook if its found\nfunc (router *Router) findWebhook(hooks []WebhookSubscription, targetWebhookURL string) (*WebhookSubscription, bool) {\n\tvar existingHookSubscription *WebhookSubscription\n\tisFound := false\n\tfor _, hook := range hooks {\n\t\tif hook.Url == targetWebhookURL {\n\t\t\tisFound = true\n\t\t\texistingHookSubscription = &hook\n\t\t\trouter.hookID = hook.Uuid\n\t\t\tbreak\n\t\t}\n\t}\n\n\treturn existingHookSubscription, isFound\n}\n\nfunc (router *Router) shouldUpdateWebhook(existingHookSubscription *WebhookSubscription) bool {\n\toldEvents := existingHookSubscription.Events\n\tnewEvents := router.bitbucketEventSource.Events\n\n\treturn !common.ElementsMatch(oldEvents, newEvents)\n}\n", "/*\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage bitbucket\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"project key can't be empty\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"bitbucket.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Bitbucket)\n\n\tfor name, value := range eventSource.Spec.Bitbucket {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tBitbucketEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage bitbucketserver\n\nimport (\n\t\"context\"\n\t\"crypto/hmac\"\n\t\"crypto/rand\"\n\t\"crypto/sha256\"\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"io/ioutil\"\n\t\"math/big\"\n\t\"net/http\"\n\t\"time\"\n\n\tbitbucketv1 \"github.com/gfleury/go-bitbucket-v1\"\n\t\"github.com/mitchellh/mapstructure\"\n\n\t\"github.com/argoproj/argo-events/common\"\n\t\"github.com/argoproj/argo-events/common/logging\"\n\teventsourcecommon \"github.com/argoproj/argo-events/eventsources/common\"\n\t\"github.com/argoproj/argo-events/eventsources/common/webhook\"\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/events\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/pkg/errors\"\n\t\"go.uber.org/zap\"\n)\n\n// controller controls the webhook operations\nvar (\n\tcontroller = webhook.NewController()\n)\n\n// set up the activation and inactivation channels to control the state of routes.\nfunc init() {\n\tgo webhook.ProcessRouteStatus(controller)\n}\n\n// Implement Router\n// 1. GetRoute\n// 2. HandleRoute\n// 3. PostActivate\n// 4. PostDeactivate\n\n// GetRoute returns the route\nfunc (router *Router) GetRoute() *webhook.Route {\n\treturn router.route\n}\n\n// HandleRoute handles incoming requests on the route\nfunc (router *Router) HandleRoute(writer http.ResponseWriter, request *http.Request) {\n\troute := router.GetRoute()\n\n\tlogger := route.Logger.With(\n\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\tlogging.LabelPort, route.Context.Port,\n\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t)\n\n\tlogger.Info(\"received a request, processing it...\")\n\n\tif !route.Active {\n\t\tlogger.Info(\"endpoint is not active, won't process the request\")\n\t\tcommon.SendErrorResponse(writer, \"inactive endpoint\")\n\t\treturn\n\t}\n\n\tdefer func(start time.Time) {\n\t\troute.Metrics.EventProcessingDuration(route.EventSourceName, route.EventName, float64(time.Since(start)/time.Millisecond))\n\t}(time.Now())\n\n\tbody, err := router.parseAndValidateBitbucketServerRequest(request)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to parse/validate request\", zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tevent := &events.BitbucketServerEventData{\n\t\tHeaders:  request.Header,\n\t\tBody:     (*json.RawMessage)(&body),\n\t\tMetadata: router.bitbucketserverEventSource.Metadata,\n\t}\n\n\teventBody, err := json.Marshal(event)\n\tif err != nil {\n\t\tlogger.Info(\"failed to marshal event\")\n\t\tcommon.SendErrorResponse(writer, \"invalid event\")\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tlogger.Info(\"dispatching event on route's data channel\")\n\troute.DataCh <- eventBody\n\n\tlogger.Info(\"request successfully processed\")\n\tcommon.SendSuccessResponse(writer, \"success\")\n}\n\n// PostActivate performs operations once the route is activated and ready to consume requests\nfunc (router *Router) PostActivate() error {\n\treturn nil\n}\n\n// PostInactivate performs operations after the route is inactivated\nfunc (router *Router) PostInactivate() error {\n\tbitbucketserverEventSource := router.bitbucketserverEventSource\n\troute := router.route\n\tlogger := route.Logger\n\n\tif bitbucketserverEventSource.DeleteHookOnFinish && len(router.hookIDs) > 0 {\n\t\tlogger.Info(\"deleting webhooks from bitbucket\")\n\n\t\tbitbucketToken, err := common.GetSecretFromVolume(bitbucketserverEventSource.AccessToken)\n\t\tif err != nil {\n\t\t\treturn errors.Errorf(\"failed to get bitbucketserver token. err: %+v\", err)\n\t\t}\n\n\t\tbitbucketConfig := bitbucketv1.NewConfiguration(bitbucketserverEventSource.BitbucketServerBaseURL)\n\t\tbitbucketConfig.AddDefaultHeader(\"x-atlassian-token\", \"no-check\")\n\t\tbitbucketConfig.AddDefaultHeader(\"x-requested-with\", \"XMLHttpRequest\")\n\n\t\tfor _, repo := range bitbucketserverEventSource.GetBitbucketServerRepositories() {\n\t\t\tid, ok := router.hookIDs[repo.ProjectKey+\",\"+repo.RepositorySlug]\n\t\t\tif !ok {\n\t\t\t\treturn errors.Errorf(\"can not find hook ID for project-key: %s, repository-slug: %s\", repo.ProjectKey, repo.RepositorySlug)\n\t\t\t}\n\n\t\t\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\n\t\t\tdefer cancel()\n\n\t\t\tctx = context.WithValue(ctx, bitbucketv1.ContextAccessToken, bitbucketToken)\n\t\t\tbitbucketClient := bitbucketv1.NewAPIClient(ctx, bitbucketConfig)\n\n\t\t\t_, err = bitbucketClient.DefaultApi.DeleteWebhook(repo.ProjectKey, repo.RepositorySlug, int32(id))\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Errorf(\"failed to delete bitbucketserver webhook. err: %+v\", err)\n\t\t\t}\n\n\t\t\tlogger.Infow(\"bitbucket server webhook deleted\",\n\t\t\t\tzap.String(\"project-key\", repo.ProjectKey), zap.String(\"repository-slug\", repo.RepositorySlug))\n\t\t}\n\t} else {\n\t\tlogger.Info(\"no need to delete webhooks, skipping.\")\n\t}\n\n\treturn nil\n}\n\n// StartListening starts an event source\nfunc (el *EventListener) StartListening(ctx context.Context, dispatch func([]byte, ...eventsourcecommon.Option) error) error {\n\tdefer sources.Recover(el.GetEventName())\n\n\tbitbucketserverEventSource := &el.BitbucketServerEventSource\n\n\tlogger := logging.FromContext(ctx).With(\n\t\tlogging.LabelEventSourceType, el.GetEventSourceType(),\n\t\tlogging.LabelEventName, el.GetEventName(),\n\t\t\"base-url\", bitbucketserverEventSource.BitbucketServerBaseURL,\n\t)\n\n\tlogger.Info(\"started processing the Bitbucket Server event source...\")\n\n\troute := webhook.NewRoute(bitbucketserverEventSource.Webhook, logger, el.GetEventSourceName(), el.GetEventName(), el.Metrics)\n\trouter := &Router{\n\t\troute:                      route,\n\t\tbitbucketserverEventSource: bitbucketserverEventSource,\n\t\thookIDs:                    make(map[string]int),\n\t}\n\n\tlogger.Info(\"retrieving the access token credentials...\")\n\tbitbucketToken, err := common.GetSecretFromVolume(bitbucketserverEventSource.AccessToken)\n\tif err != nil {\n\t\treturn errors.Errorf(\"failed to get bitbucketserver token. err: %+v\", err)\n\t}\n\n\tif bitbucketserverEventSource.WebhookSecret != nil {\n\t\tlogger.Info(\"retrieving the webhook secret...\")\n\t\twebhookSecret, err := common.GetSecretFromVolume(bitbucketserverEventSource.WebhookSecret)\n\t\tif err != nil {\n\t\t\treturn errors.Errorf(\"failed to get bitbucketserver webhook secret. err: %+v\", err)\n\t\t}\n\n\t\trouter.hookSecret = webhookSecret\n\t}\n\n\tlogger.Info(\"setting up the client to connect to Bitbucket Server...\")\n\tbitbucketConfig := bitbucketv1.NewConfiguration(bitbucketserverEventSource.BitbucketServerBaseURL)\n\tbitbucketConfig.AddDefaultHeader(\"x-atlassian-token\", \"no-check\")\n\tbitbucketConfig.AddDefaultHeader(\"x-requested-with\", \"XMLHttpRequest\")\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\tctx = context.WithValue(ctx, bitbucketv1.ContextAccessToken, bitbucketToken)\n\n\tapplyWebhooks := func() {\n\t\tfor _, repo := range bitbucketserverEventSource.GetBitbucketServerRepositories() {\n\t\t\tif err = router.applyBitbucketServerWebhook(ctx, bitbucketConfig, repo); err != nil {\n\t\t\t\tlogger.Errorw(\"failed to create/update Bitbucket webhook\",\n\t\t\t\t\tzap.String(\"project-key\", repo.ProjectKey), zap.String(\"repository-slug\", repo.RepositorySlug), zap.Error(err))\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\ttime.Sleep(500 * time.Millisecond)\n\t\t}\n\t}\n\n\t// When running multiple replicas of the eventsource, they will all try to create the webhook.\n\t// Randomly sleep some time to mitigate the issue.\n\trandomNum, _ := rand.Int(rand.Reader, big.NewInt(int64(2000)))\n\ttime.Sleep(time.Duration(randomNum.Int64()) * time.Millisecond)\n\tapplyWebhooks()\n\n\tgo func() {\n\t\t// Another kind of race conditions might happen when pods do rolling upgrade - new pod starts\n\t\t// and old pod terminates, if DeleteHookOnFinish is true, the hook will be deleted from Bitbucket.\n\t\t// This is a workaround to mitigate the race conditions.\n\t\tlogger.Info(\"starting bitbucket hooks manager daemon\")\n\t\tticker := time.NewTicker(60 * time.Second)\n\t\tdefer ticker.Stop()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\tlogger.Info(\"exiting bitbucket hooks manager daemon\")\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t\tapplyWebhooks()\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn webhook.ManageRoute(ctx, router, controller, dispatch)\n}\n\n// applyBitbucketServerWebhook creates or updates the configured webhook in Bitbucket\nfunc (router *Router) applyBitbucketServerWebhook(ctx context.Context, bitbucketConfig *bitbucketv1.Configuration, repo v1alpha1.BitbucketServerRepository) error {\n\tbitbucketserverEventSource := router.bitbucketserverEventSource\n\troute := router.route\n\n\tlogger := route.Logger.With(\n\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\tlogging.LabelPort, route.Context.Port,\n\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t\t\"project-key\", repo.ProjectKey,\n\t\t\"repository-slug\", repo.RepositorySlug,\n\t\t\"base-url\", bitbucketserverEventSource.BitbucketServerBaseURL,\n\t)\n\n\tbitbucketClient := bitbucketv1.NewAPIClient(ctx, bitbucketConfig)\n\tformattedURL := common.FormattedURL(bitbucketserverEventSource.Webhook.URL, bitbucketserverEventSource.Webhook.Endpoint)\n\n\thooks, err := router.listWebhooks(bitbucketClient, repo)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"failed to list existing hooks to check for duplicates for repository %s/%s\", repo.ProjectKey, repo.RepositorySlug)\n\t}\n\n\tvar existingHook bitbucketv1.Webhook\n\tisAlreadyExists := false\n\n\tfor _, hook := range hooks {\n\t\tif hook.Url == formattedURL {\n\t\t\tisAlreadyExists = true\n\t\t\texistingHook = hook\n\t\t\trouter.hookIDs[repo.ProjectKey+\",\"+repo.RepositorySlug] = hook.ID\n\t\t\tbreak\n\t\t}\n\t}\n\n\tnewHook := bitbucketv1.Webhook{\n\t\tName:          \"Argo Events\",\n\t\tUrl:           formattedURL,\n\t\tActive:        true,\n\t\tEvents:        bitbucketserverEventSource.Events,\n\t\tConfiguration: bitbucketv1.WebhookConfiguration{Secret: router.hookSecret},\n\t}\n\n\trequestBody, err := router.createRequestBodyFromWebhook(newHook)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"failed to create request body from webhook\")\n\t}\n\n\t// Update the webhook when it does exist and the events/configuration have changed\n\tif isAlreadyExists {\n\t\tlogger.Info(\"webhook already exists\")\n\t\tif router.shouldUpdateWebhook(existingHook, newHook) {\n\t\t\tlogger.Info(\"webhook requires an update\")\n\t\t\terr = router.updateWebhook(bitbucketClient, existingHook.ID, requestBody, repo)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Errorf(\"failed to update webhook. err: %+v\", err)\n\t\t\t}\n\n\t\t\tlogger.With(\"hook-id\", existingHook.ID).Info(\"hook successfully updated\")\n\t\t}\n\n\t\treturn nil\n\t}\n\n\t// Create the webhook when it doesn't exist yet\n\tcreatedHook, err := router.createWebhook(bitbucketClient, requestBody, repo)\n\tif err != nil {\n\t\treturn errors.Errorf(\"failed to create webhook. err: %+v\", err)\n\t}\n\n\trouter.hookIDs[repo.ProjectKey+\",\"+repo.RepositorySlug] = createdHook.ID\n\n\tlogger.With(\"hook-id\", createdHook.ID).Info(\"hook successfully registered\")\n\n\treturn nil\n}\n\nfunc (router *Router) listWebhooks(bitbucketClient *bitbucketv1.APIClient, repo v1alpha1.BitbucketServerRepository) ([]bitbucketv1.Webhook, error) {\n\tapiResponse, err := bitbucketClient.DefaultApi.FindWebhooks(repo.ProjectKey, repo.RepositorySlug, nil)\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"failed to list existing hooks to check for duplicates for repository %s/%s\", repo.ProjectKey, repo.RepositorySlug)\n\t}\n\n\thooks, err := bitbucketv1.GetWebhooksResponse(apiResponse)\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"failed to convert the list of webhooks for repository %s/%s\", repo.ProjectKey, repo.RepositorySlug)\n\t}\n\n\treturn hooks, nil\n}\n\nfunc (router *Router) createWebhook(bitbucketClient *bitbucketv1.APIClient, requestBody []byte, repo v1alpha1.BitbucketServerRepository) (*bitbucketv1.Webhook, error) {\n\tapiResponse, err := bitbucketClient.DefaultApi.CreateWebhook(repo.ProjectKey, repo.RepositorySlug, requestBody, []string{\"application/json\"})\n\tif err != nil {\n\t\treturn nil, errors.Errorf(\"failed to add webhook. err: %+v\", err)\n\t}\n\n\tvar createdHook *bitbucketv1.Webhook\n\terr = mapstructure.Decode(apiResponse.Values, &createdHook)\n\tif err != nil {\n\t\treturn nil, errors.Errorf(\"failed to convert API response to Webhook struct. err: %+v\", err)\n\t}\n\n\treturn createdHook, nil\n}\n\nfunc (router *Router) updateWebhook(bitbucketClient *bitbucketv1.APIClient, hookID int, requestBody []byte, repo v1alpha1.BitbucketServerRepository) error {\n\t_, err := bitbucketClient.DefaultApi.UpdateWebhook(repo.ProjectKey, repo.RepositorySlug, int32(hookID), requestBody, []string{\"application/json\"})\n\n\treturn err\n}\n\nfunc (router *Router) shouldUpdateWebhook(existingHook bitbucketv1.Webhook, newHook bitbucketv1.Webhook) bool {\n\treturn !common.ElementsMatch(existingHook.Events, newHook.Events) ||\n\t\texistingHook.Configuration.Secret != newHook.Configuration.Secret\n}\n\nfunc (router *Router) createRequestBodyFromWebhook(hook bitbucketv1.Webhook) ([]byte, error) {\n\tvar err error\n\tvar finalHook interface{} = hook\n\n\t// if the hook doesn't have a secret, the configuration field must be removed in order for the request to succeed,\n\t// otherwise Bitbucket Server sends 500 response because of empty string value in the hook.Configuration.Secret field\n\tif hook.Configuration.Secret == \"\" {\n\t\thookMap := make(map[string]interface{})\n\t\terr = common.StructToMap(hook, hookMap)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"failed to convert webhook to map\")\n\t\t}\n\n\t\tdelete(hookMap, \"configuration\")\n\n\t\tfinalHook = hookMap\n\t}\n\n\trequestBody, err := json.Marshal(finalHook)\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"failed to marshal new webhook to JSON\")\n\t}\n\n\treturn requestBody, nil\n}\n\nfunc (router *Router) parseAndValidateBitbucketServerRequest(request *http.Request) ([]byte, error) {\n\tbody, err := ioutil.ReadAll(request.Body)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to parse request body\")\n\t}\n\n\tif len(router.hookSecret) != 0 {\n\t\tsignature := request.Header.Get(\"X-Hub-Signature\")\n\t\tif len(signature) == 0 {\n\t\t\treturn nil, errors.New(\"missing signature header\")\n\t\t}\n\n\t\tmac := hmac.New(sha256.New, []byte(router.hookSecret))\n\t\t_, _ = mac.Write(body)\n\t\texpectedMAC := hex.EncodeToString(mac.Sum(nil))\n\n\t\tif !hmac.Equal([]byte(signature[7:]), []byte(expectedMAC)) {\n\t\t\treturn nil, errors.New(\"hmac verification failed\")\n\t\t}\n\t}\n\n\treturn body, nil\n}\n", "/*\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage bitbucketserver\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"at least one repository is required\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"bitbucketserver.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.BitbucketServer)\n\n\tfor name, value := range eventSource.Spec.BitbucketServer {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tBitbucketServerEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage calendar\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{\n\t\tCalendarEventSource: v1alpha1.CalendarEventSource{\n\t\t\t// Schedule: \"* * * * *\"\n\t\t},\n\t}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"must have either schedule or interval\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"calendar.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Calendar)\n\n\tfor _, value := range eventSource.Spec.Calendar {\n\t\tl := &EventListener{\n\t\t\tCalendarEventSource: value,\n\t\t}\n\t\terr = l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage emitter\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"broker url must be specified\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"emitter.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Emitter)\n\n\tfor _, value := range eventSource.Spec.Emitter {\n\t\tl := &EventListener{\n\t\t\tEmitterEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage file\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"type must be specified\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"file.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.File)\n\n\tfor _, value := range eventSource.Spec.File {\n\t\tl := &EventListener{\n\t\t\tFileEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage gcppubsub\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"must specify topic or subscriptionID\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"gcp-pubsub.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.PubSub)\n\n\tfor name, value := range eventSource.Spec.PubSub {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tPubSubEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "package generic\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestEventListener_ValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"server url can't be empty\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"generic.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Generic)\n\n\tfor name, value := range eventSource.Spec.Generic {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tGenericEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage github\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/smartystreets/goconvey/convey\"\n\tcorev1 \"k8s.io/api/core/v1\"\n\n\t\"github.com/argoproj/argo-events/eventsources/common/webhook\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nvar (\n\trouter = &Router{\n\t\troute:             webhook.GetFakeRoute(),\n\t\tgithubEventSource: &v1alpha1.GithubEventSource{},\n\t}\n)\n\nfunc TestRouteActiveHandler(t *testing.T) {\n\tconvey.Convey(\"Given a route configuration\", t, func() {\n\t\troute := router.route\n\t\troute.DataCh = make(chan []byte)\n\n\t\tconvey.Convey(\"Inactive route should return error\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\tgithubEventSource := &v1alpha1.GithubEventSource{\n\t\t\t\tWebhook: &v1alpha1.WebhookContext{\n\t\t\t\t\tEndpoint: \"/push\",\n\t\t\t\t\tURL:      \"http://webhook-gateway-svc\",\n\t\t\t\t\tPort:     \"12000\",\n\t\t\t\t},\n\t\t\t\tRepositories: []v1alpha1.OwnedRepositories{\n\t\t\t\t\t{\n\t\t\t\t\t\tOwner: \"fake\",\n\t\t\t\t\t\tNames: []string{\n\t\t\t\t\t\t\t\"fake0\", \"fake1\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tEvents: []string{\n\t\t\t\t\t\"PushEvent\",\n\t\t\t\t},\n\t\t\t\tAPIToken: &corev1.SecretKeySelector{\n\t\t\t\t\tKey: \"accessKey\",\n\t\t\t\t\tLocalObjectReference: corev1.LocalObjectReference{\n\t\t\t\t\t\tName: \"github-access\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tbody, err := yaml.Marshal(githubEventSource)\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tBody: ioutil.NopCloser(bytes.NewReader(body)),\n\t\t\t})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusBadRequest)\n\n\t\t\tconvey.Convey(\"Active route should return success\", func() {\n\t\t\t\troute.Active = true\n\n\t\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\t\tBody: ioutil.NopCloser(bytes.NewReader(body)),\n\t\t\t\t})\n\n\t\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusBadRequest)\n\t\t\t})\n\t\t})\n\t})\n}\n\nfunc TestRouteActiveHandlerDeprecated(t *testing.T) {\n\tconvey.Convey(\"Given a route configuration\", t, func() {\n\t\troute := router.route\n\t\troute.DataCh = make(chan []byte)\n\n\t\tconvey.Convey(\"Inactive route should return error\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\tgithubEventSource := &v1alpha1.GithubEventSource{\n\t\t\t\tWebhook: &v1alpha1.WebhookContext{\n\t\t\t\t\tEndpoint: \"/push\",\n\t\t\t\t\tURL:      \"http://webhook-gateway-svc\",\n\t\t\t\t\tPort:     \"12000\",\n\t\t\t\t},\n\t\t\t\tDeprecatedOwner:      \"fake\",\n\t\t\t\tDeprecatedRepository: \"fake\",\n\t\t\t\tEvents: []string{\n\t\t\t\t\t\"PushEvent\",\n\t\t\t\t},\n\t\t\t\tAPIToken: &corev1.SecretKeySelector{\n\t\t\t\t\tKey: \"accessKey\",\n\t\t\t\t\tLocalObjectReference: corev1.LocalObjectReference{\n\t\t\t\t\t\tName: \"github-access\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tbody, err := yaml.Marshal(githubEventSource)\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tBody: ioutil.NopCloser(bytes.NewReader(body)),\n\t\t\t})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusBadRequest)\n\n\t\t\tconvey.Convey(\"Active route should return success\", func() {\n\t\t\t\troute.Active = true\n\n\t\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\t\tBody: ioutil.NopCloser(bytes.NewReader(body)),\n\t\t\t\t})\n\n\t\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusBadRequest)\n\t\t\t})\n\t\t})\n\t})\n}\n\nfunc TestAddEventTypeBody(t *testing.T) {\n\tconvey.Convey(\"Given a request\", t, func() {\n\t\tvar (\n\t\t\tbuf        = bytes.NewBuffer([]byte(`{ \"hello\": \"world\" }`))\n\t\t\teventType  = \"PushEvent\"\n\t\t\tdeliveryID = \"131C7C9B-A571-4F60-9ACA-EA3ADA19FABE\"\n\t\t)\n\t\trequest, err := http.NewRequest(\"POST\", \"http://example.com\", buf)\n\t\tconvey.So(err, convey.ShouldBeNil)\n\t\trequest.Header.Set(\"X-GitHub-Event\", eventType)\n\t\trequest.Header.Set(\"X-GitHub-Delivery\", deliveryID)\n\t\trequest.Header.Set(\"Content-Type\", \"application/json\")\n\n\t\tconvey.Convey(\"Delivery headers should be written to message\", func() {\n\t\t\tbody, err := parseValidateRequest(request, []byte{})\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\t\t\tpayload := make(map[string]interface{})\n\t\t\terr = json.Unmarshal(body, &payload)\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\t\t\tconvey.So(payload[\"X-GitHub-Event\"], convey.ShouldEqual, eventType)\n\t\t\tconvey.So(payload[\"X-GitHub-Delivery\"], convey.ShouldEqual, deliveryID)\n\t\t})\n\t})\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage github\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"either repositories or organizations is required\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"github.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Github)\n\n\tfor name, value := range eventSource.Spec.Github {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tGithubEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage gitlab\n\nimport (\n\t\"context\"\n\t\"crypto/rand\"\n\t\"encoding/json\"\n\t\"io/ioutil\"\n\t\"math/big\"\n\t\"net/http\"\n\t\"reflect\"\n\t\"time\"\n\n\t\"github.com/argoproj/argo-events/common\"\n\t\"github.com/argoproj/argo-events/common/logging\"\n\teventsourcecommon \"github.com/argoproj/argo-events/eventsources/common\"\n\t\"github.com/argoproj/argo-events/eventsources/common/webhook\"\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/events\"\n\t\"github.com/pkg/errors\"\n\t\"github.com/xanzy/go-gitlab\"\n\t\"go.uber.org/zap\"\n)\n\n// controller controls the webhook operations\nvar (\n\tcontroller = webhook.NewController()\n)\n\n// set up the activation and inactivation channels to control the state of routes.\nfunc init() {\n\tgo webhook.ProcessRouteStatus(controller)\n}\n\n// Implement Router\n// 1. GetRoute\n// 2. HandleRoute\n// 3. PostActivate\n// 4. PostDeactivate\n\n// GetRoute returns the route\nfunc (router *Router) GetRoute() *webhook.Route {\n\treturn router.route\n}\n\n// HandleRoute handles incoming requests on the route\nfunc (router *Router) HandleRoute(writer http.ResponseWriter, request *http.Request) {\n\troute := router.GetRoute()\n\n\tlogger := route.Logger.With(\n\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\tlogging.LabelPort, route.Context.Port,\n\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t)\n\n\tlogger.Info(\"received a request, processing it...\")\n\n\tif !route.Active {\n\t\tlogger.Info(\"endpoint is not active, won't process the request\")\n\t\tcommon.SendErrorResponse(writer, \"inactive endpoint\")\n\t\treturn\n\t}\n\n\tdefer func(start time.Time) {\n\t\troute.Metrics.EventProcessingDuration(route.EventSourceName, route.EventName, float64(time.Since(start)/time.Millisecond))\n\t}(time.Now())\n\n\tif router.secretToken != \"\" {\n\t\tif t := request.Header.Get(\"X-Gitlab-Token\"); t != router.secretToken {\n\t\t\tcommon.SendErrorResponse(writer, \"token mismatch\")\n\t\t\treturn\n\t\t}\n\t}\n\n\tbody, err := ioutil.ReadAll(request.Body)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to parse request body\", zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tevent := &events.GitLabEventData{\n\t\tHeaders:  request.Header,\n\t\tBody:     (*json.RawMessage)(&body),\n\t\tMetadata: router.gitlabEventSource.Metadata,\n\t}\n\n\teventBody, err := json.Marshal(event)\n\tif err != nil {\n\t\tlogger.Info(\"failed to marshal event\")\n\t\tcommon.SendErrorResponse(writer, \"invalid event\")\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tlogger.Info(\"dispatching event on route's data channel\")\n\troute.DataCh <- eventBody\n\n\tlogger.Info(\"request successfully processed\")\n\tcommon.SendSuccessResponse(writer, \"success\")\n}\n\n// PostActivate performs operations once the route is activated and ready to consume requests\nfunc (router *Router) PostActivate() error {\n\treturn nil\n}\n\n// PostInactivate performs operations after the route is inactivated\nfunc (router *Router) PostInactivate() error {\n\tgitlabEventSource := router.gitlabEventSource\n\tif !gitlabEventSource.NeedToCreateHooks() || !gitlabEventSource.DeleteHookOnFinish {\n\t\treturn nil\n\t}\n\n\tlogger := router.route.Logger\n\tlogger.Info(\"deleting Gitlab hooks...\")\n\n\tfor _, p := range gitlabEventSource.GetProjects() {\n\t\tid, ok := router.hookIDs[p]\n\t\tif !ok {\n\t\t\treturn errors.Errorf(\"can not find hook ID for project %s\", p)\n\t\t}\n\t\tif _, err := router.gitlabClient.Projects.DeleteProjectHook(p, id); err != nil {\n\t\t\treturn errors.Errorf(\"failed to delete hook for project %s. err: %+v\", p, err)\n\t\t}\n\t\tlogger.Infof(\"Gitlab hook deleted for project %s\", p)\n\t}\n\treturn nil\n}\n\n// StartListening starts an event source\nfunc (el *EventListener) StartListening(ctx context.Context, dispatch func([]byte, ...eventsourcecommon.Option) error) error {\n\tlogger := logging.FromContext(ctx).\n\t\tWith(logging.LabelEventSourceType, el.GetEventSourceType(), logging.LabelEventName, el.GetEventName())\n\tlogger.Info(\"started processing the Gitlab event source...\")\n\n\tdefer sources.Recover(el.GetEventName())\n\n\tgitlabEventSource := &el.GitlabEventSource\n\n\troute := webhook.NewRoute(gitlabEventSource.Webhook, logger, el.GetEventSourceName(), el.GetEventName(), el.Metrics)\n\trouter := &Router{\n\t\troute:             route,\n\t\tgitlabEventSource: gitlabEventSource,\n\t}\n\n\tif gitlabEventSource.NeedToCreateHooks() {\n\t\t// In order to set up a hook for the GitLab project,\n\t\t// 1. Get the API access token for client\n\t\t// 2. Set up GitLab client\n\t\t// 3. Configure Hook with given event type\n\t\t// 4. Create project hook\n\n\t\tlogger.Info(\"retrieving the access token credentials...\")\n\n\t\tdefaultEventValue := false\n\t\tformattedURL := common.FormattedURL(gitlabEventSource.Webhook.URL, gitlabEventSource.Webhook.Endpoint)\n\t\topt := &gitlab.AddProjectHookOptions{\n\t\t\tURL:                      &formattedURL,\n\t\t\tEnableSSLVerification:    &router.gitlabEventSource.EnableSSLVerification,\n\t\t\tConfidentialNoteEvents:   &defaultEventValue,\n\t\t\tPushEvents:               &defaultEventValue,\n\t\t\tIssuesEvents:             &defaultEventValue,\n\t\t\tConfidentialIssuesEvents: &defaultEventValue,\n\t\t\tMergeRequestsEvents:      &defaultEventValue,\n\t\t\tTagPushEvents:            &defaultEventValue,\n\t\t\tNoteEvents:               &defaultEventValue,\n\t\t\tJobEvents:                &defaultEventValue,\n\t\t\tPipelineEvents:           &defaultEventValue,\n\t\t\tWikiPageEvents:           &defaultEventValue,\n\t\t}\n\n\t\tfor _, event := range gitlabEventSource.Events {\n\t\t\telem := reflect.ValueOf(opt).Elem().FieldByName(event)\n\t\t\tif ok := elem.IsValid(); !ok {\n\t\t\t\treturn errors.Errorf(\"unknown event %s\", event)\n\t\t\t}\n\t\t\tiev := reflect.New(elem.Type().Elem())\n\t\t\treflect.Indirect(iev).SetBool(true)\n\t\t\telem.Set(iev)\n\t\t}\n\n\t\tif gitlabEventSource.SecretToken != nil {\n\t\t\ttoken, err := common.GetSecretFromVolume(gitlabEventSource.SecretToken)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Errorf(\"failed to retrieve secret token. err: %+v\", err)\n\t\t\t}\n\t\t\topt.Token = &token\n\t\t\trouter.secretToken = token\n\t\t}\n\n\t\taccessToken, err := common.GetSecretFromVolume(gitlabEventSource.AccessToken)\n\t\tif err != nil {\n\t\t\treturn errors.Errorf(\"failed to get gitlab credentials. err: %+v\", err)\n\t\t}\n\n\t\tlogger.Info(\"setting up the client to connect to GitLab...\")\n\t\trouter.gitlabClient, err = gitlab.NewClient(accessToken, gitlab.WithBaseURL(gitlabEventSource.GitlabBaseURL))\n\t\tif err != nil {\n\t\t\treturn errors.Wrapf(err, \"failed to initialize client\")\n\t\t}\n\n\t\tgetHook := func(hooks []*gitlab.ProjectHook, url string) *gitlab.ProjectHook {\n\t\t\tfor _, h := range hooks {\n\t\t\t\tif h.URL != url {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\treturn h\n\t\t\t}\n\t\t\treturn nil\n\t\t}\n\n\t\trouter.hookIDs = make(map[string]int)\n\n\t\tf := func() {\n\t\t\tfor _, p := range gitlabEventSource.GetProjects() {\n\t\t\t\thooks, _, err := router.gitlabClient.Projects.ListProjectHooks(p, &gitlab.ListProjectHooksOptions{})\n\t\t\t\tif err != nil {\n\t\t\t\t\tlogger.Errorf(\"failed to list existing webhooks of project %s. err: %+v\", p, err)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\thook := getHook(hooks, formattedURL)\n\t\t\t\tif hook != nil {\n\t\t\t\t\trouter.hookIDs[p] = hook.ID\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tlogger.Infof(\"hook not found for project %s, creating ...\", p)\n\t\t\t\thook, _, err = router.gitlabClient.Projects.AddProjectHook(p, opt)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlogger.Errorf(\"failed to create gitlab webhook for project %s. err: %+v\", p, err)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\trouter.hookIDs[p] = hook.ID\n\t\t\t\ttime.Sleep(500 * time.Millisecond)\n\t\t\t}\n\t\t}\n\n\t\t// Mitigate race condtions - it might create multiple hooks with same config when replicas > 1\n\t\trandomNum, _ := rand.Int(rand.Reader, big.NewInt(int64(2000)))\n\t\ttime.Sleep(time.Duration(randomNum.Int64()) * time.Millisecond)\n\t\tf()\n\n\t\tctx, cancel := context.WithCancel(ctx)\n\t\tdefer cancel()\n\n\t\tgo func() {\n\t\t\t// Another kind of race conditions might happen when pods do rolling upgrade - new pod starts\n\t\t\t// and old pod terminates, if DeleteHookOnFinish is true, the hook will be deleted from gitlab.\n\t\t\t// This is a workround to mitigate the race conditions.\n\t\t\tlogger.Info(\"starting gitlab hooks manager daemon\")\n\t\t\tticker := time.NewTicker(60 * time.Second)\n\t\t\tdefer ticker.Stop()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\tlogger.Info(\"exiting gitlab hooks manager daemon\")\n\t\t\t\t\treturn\n\t\t\t\tcase <-ticker.C:\n\t\t\t\t\tf()\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t} else {\n\t\tlogger.Info(\"no need to create webhooks\")\n\t}\n\n\treturn webhook.ManageRoute(ctx, router, controller, dispatch)\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage gitlab\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"projects can't be empty\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"gitlab.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Gitlab)\n\n\tfor name, value := range eventSource.Spec.Gitlab {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tGitlabEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "package hdfs\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"type is required\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"hdfs.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.HDFS)\n\n\tfor name, value := range eventSource.Spec.HDFS {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tHDFSEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage kafka\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"url must be specified\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"kafka.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Kafka)\n\n\tfor name, value := range eventSource.Spec.Kafka {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tKafkaEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage minio\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"access key can't be empty\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"minio.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Minio)\n\n\tfor _, value := range eventSource.Spec.Minio {\n\t\tl := &EventListener{\n\t\t\tMinioEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage mqtt\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"url must be specified\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"mqtt.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.MQTT)\n\n\tfor name, value := range eventSource.Spec.MQTT {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tMQTTEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage nats\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"url must be specified\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"nats.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.NATS)\n\n\tfor name, value := range eventSource.Spec.NATS {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tNATSEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage nsq\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"host address must be specified\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"nsq.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.NSQ)\n\n\tfor name, value := range eventSource.Spec.NSQ {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tNSQEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\npackage pulsar\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestEventListener_ValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"topics can't be empty list\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"pulsar.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Pulsar)\n\n\tfor name, value := range eventSource.Spec.Pulsar {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tPulsarEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage redis\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateRedisEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"host address must be specified\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"redis.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Redis)\n\n\tfor name, value := range eventSource.Spec.Redis {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tRedisEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage redisstream\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateRedisEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"host address must be specified\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"redis-streams.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.RedisStream)\n\n\tfor name, value := range eventSource.Spec.RedisStream {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage resource\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"version must be specified\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"resource.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Resource)\n\n\tfor name, value := range eventSource.Spec.Resource {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tResourceEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage slack\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"time\"\n\n\t\"github.com/pkg/errors\"\n\t\"github.com/slack-go/slack\"\n\t\"github.com/slack-go/slack/slackevents\"\n\t\"go.uber.org/zap\"\n\n\t\"github.com/argoproj/argo-events/common\"\n\t\"github.com/argoproj/argo-events/common/logging\"\n\teventsourcecommon \"github.com/argoproj/argo-events/eventsources/common\"\n\t\"github.com/argoproj/argo-events/eventsources/common/webhook\"\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\tmetrics \"github.com/argoproj/argo-events/metrics\"\n\tapicommon \"github.com/argoproj/argo-events/pkg/apis/common\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\n// controller controls the webhook operations\nvar (\n\tcontroller = webhook.NewController()\n)\n\n// set up the activation and inactivation channels to control the state of routes.\nfunc init() {\n\tgo webhook.ProcessRouteStatus(controller)\n}\n\n// EventListener implements Eventing for slack event source\ntype EventListener struct {\n\tEventSourceName  string\n\tEventName        string\n\tSlackEventSource v1alpha1.SlackEventSource\n\tMetrics          *metrics.Metrics\n}\n\n// GetEventSourceName returns name of event source\nfunc (el *EventListener) GetEventSourceName() string {\n\treturn el.EventSourceName\n}\n\n// GetEventName returns name of event\nfunc (el *EventListener) GetEventName() string {\n\treturn el.EventName\n}\n\n// GetEventSourceType return type of event server\nfunc (el *EventListener) GetEventSourceType() apicommon.EventSourceType {\n\treturn apicommon.SlackEvent\n}\n\n// Router contains information about a REST endpoint\ntype Router struct {\n\t// route holds information to process an incoming request\n\troute *webhook.Route\n\t// slackEventSource is the event source which refers to configuration required to consume events from slack\n\tslackEventSource *v1alpha1.SlackEventSource\n\t// token is the slack token\n\ttoken string\n\t// refer to https://api.slack.com/docs/verifying-requests-from-slack\n\tsigningSecret string\n}\n\n// Implement Router\n// 1. GetRoute\n// 2. HandleRoute\n// 3. PostActivate\n// 4. PostDeactivate\n\n// GetRoute returns the route\nfunc (rc *Router) GetRoute() *webhook.Route {\n\treturn rc.route\n}\n\n// HandleRoute handles incoming requests on the route\nfunc (rc *Router) HandleRoute(writer http.ResponseWriter, request *http.Request) {\n\troute := rc.route\n\n\tlogger := route.Logger.With(\n\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\tlogging.LabelPort, route.Context.Port,\n\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t)\n\n\tlogger.Info(\"request a received, processing it...\")\n\n\tif !route.Active {\n\t\tlogger.Warn(\"endpoint is not active, won't process it\")\n\t\tcommon.SendErrorResponse(writer, \"endpoint is inactive\")\n\t\treturn\n\t}\n\n\tdefer func(start time.Time) {\n\t\troute.Metrics.EventProcessingDuration(route.EventSourceName, route.EventName, float64(time.Since(start)/time.Millisecond))\n\t}(time.Now())\n\n\tlogger.Info(\"verifying the request...\")\n\terr := rc.verifyRequest(request)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to validate the request\", zap.Error(err))\n\t\tcommon.SendResponse(writer, http.StatusUnauthorized, err.Error())\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tvar data []byte\n\n\t// Interactive element actions are always\n\t// sent as application/x-www-form-urlencoded\n\t// If request was generated by an interactive element or a slash command, it will be a POST form\n\tif len(request.Header[\"Content-Type\"]) > 0 && request.Header[\"Content-Type\"][0] == \"application/x-www-form-urlencoded\" {\n\t\tif err := request.ParseForm(); err != nil {\n\t\t\tlogger.Errorw(\"failed to parse form data\", zap.Error(err))\n\t\t\tcommon.SendInternalErrorResponse(writer, err.Error())\n\t\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\t\treturn\n\t\t}\n\n\t\tswitch {\n\t\tcase request.PostForm.Get(\"payload\") != \"\":\n\t\t\tdata, err = rc.handleInteraction(request)\n\t\t\tif err != nil {\n\t\t\t\tlogger.Errorw(\"failed to process the interaction\", zap.Error(err))\n\t\t\t\tcommon.SendInternalErrorResponse(writer, err.Error())\n\t\t\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\t\t\treturn\n\t\t\t}\n\n\t\tcase request.PostForm.Get(\"command\") != \"\":\n\t\t\tdata, err = rc.handleSlashCommand(request)\n\t\t\tif err != nil {\n\t\t\t\tlogger.Errorw(\"failed to process the slash command\", zap.Error(err))\n\t\t\t\tcommon.SendInternalErrorResponse(writer, err.Error())\n\t\t\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\t\t\treturn\n\t\t\t}\n\n\t\tdefault:\n\t\t\terr = errors.New(\"could not determine slack type from form parameters\")\n\t\t\tlogger.Errorw(\"failed to determine type of slack post\", zap.Error(err))\n\t\t\tcommon.SendInternalErrorResponse(writer, err.Error())\n\t\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\t\treturn\n\t\t}\n\t} else {\n\t\t// If there's no payload in the post body, this is likely an\n\t\t// Event API request. Parse and process if valid.\n\t\tlogger.Info(\"handling slack event...\")\n\t\tvar response []byte\n\t\tdata, response, err = rc.handleEvent(request)\n\t\tif err != nil {\n\t\t\tlogger.Errorw(\"failed to handle the event\", zap.Error(err))\n\t\t\tcommon.SendInternalErrorResponse(writer, err.Error())\n\t\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\t\treturn\n\t\t}\n\t\tif response != nil {\n\t\t\twriter.Header().Set(\"Content-Type\", \"text\")\n\t\t\tif _, err := writer.Write(response); err != nil {\n\t\t\t\tlogger.Errorw(\"failed to write the response for url verification\", zap.Error(err))\n\t\t\t\t// don't return, we want to keep this running to give user chance to retry\n\t\t\t}\n\t\t}\n\t}\n\n\tif data != nil {\n\t\tlogger.Info(\"dispatching event on route's data channel...\")\n\t\troute.DataCh <- data\n\t}\n\n\tlogger.Debug(\"request successfully processed\")\n\tcommon.SendSuccessResponse(writer, \"success\")\n}\n\n// PostActivate performs operations once the route is activated and ready to consume requests\nfunc (rc *Router) PostActivate() error {\n\treturn nil\n}\n\n// PostInactivate performs operations after the route is inactivated\nfunc (rc *Router) PostInactivate() error {\n\treturn nil\n}\n\n// handleEvent parse the slack notification and validates the event type\nfunc (rc *Router) handleEvent(request *http.Request) ([]byte, []byte, error) {\n\tvar err error\n\tvar response []byte\n\tvar data []byte\n\tbody, err := getRequestBody(request)\n\tif err != nil {\n\t\treturn data, response, errors.Wrap(err, \"failed to fetch request body\")\n\t}\n\n\teventsAPIEvent, err := slackevents.ParseEvent(json.RawMessage(body), slackevents.OptionVerifyToken(&slackevents.TokenComparator{VerificationToken: rc.token}))\n\tif err != nil {\n\t\treturn data, response, errors.Wrap(err, \"failed to extract event\")\n\t}\n\n\tif eventsAPIEvent.Type == slackevents.URLVerification {\n\t\tvar r *slackevents.ChallengeResponse\n\t\terr = json.Unmarshal(body, &r)\n\t\tif err != nil {\n\t\t\treturn data, response, errors.Wrap(err, \"failed to verify the challenge\")\n\t\t}\n\t\tresponse = []byte(r.Challenge)\n\t}\n\n\tif eventsAPIEvent.Type == slackevents.CallbackEvent {\n\t\tdata, err = json.Marshal(&eventsAPIEvent.InnerEvent)\n\t\tif err != nil {\n\t\t\treturn data, response, errors.Wrap(err, \"failed to marshal event data, rejecting the event...\")\n\t\t}\n\t}\n\n\treturn data, response, nil\n}\n\nfunc (rc *Router) handleInteraction(request *http.Request) ([]byte, error) {\n\tpayload := request.PostForm.Get(\"payload\")\n\tie := &slack.InteractionCallback{}\n\terr := json.Unmarshal([]byte(payload), ie)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to parse interaction event\")\n\t}\n\n\tdata, err := json.Marshal(ie)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to marshal action data\")\n\t}\n\n\treturn data, nil\n}\n\nfunc (rc *Router) handleSlashCommand(request *http.Request) ([]byte, error) {\n\tcommand, err := slack.SlashCommandParse(request)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to parse command\")\n\t}\n\n\tdata, err := json.Marshal(command)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to marshal command data\")\n\t}\n\n\treturn data, nil\n}\n\nfunc getRequestBody(request *http.Request) ([]byte, error) {\n\t// Read request payload\n\tbody, err := ioutil.ReadAll(request.Body)\n\t// Reset request.Body ReadCloser to prevent side-effect if re-read\n\trequest.Body = ioutil.NopCloser(bytes.NewBuffer(body))\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to parse request body\")\n\t}\n\treturn body, nil\n}\n\n// If a signing secret is provided, validate the request against the\n// X-Slack-Signature header value.\n// The signature is a hash generated as per Slack documentation at:\n// https://api.slack.com/docs/verifying-requests-from-slack\nfunc (rc *Router) verifyRequest(request *http.Request) error {\n\tsigningSecret := rc.signingSecret\n\tif len(signingSecret) > 0 {\n\t\tsv, err := slack.NewSecretsVerifier(request.Header, signingSecret)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"cannot create secrets verifier\")\n\t\t}\n\n\t\t// Read the request body\n\t\tbody, err := getRequestBody(request)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t_, err = sv.Write(body)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"error writing body: cannot verify signature\")\n\t\t}\n\n\t\terr = sv.Ensure()\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"signature validation failed\")\n\t\t}\n\t}\n\treturn nil\n}\n\n// StartListening starts an event source\nfunc (el *EventListener) StartListening(ctx context.Context, dispatch func([]byte, ...eventsourcecommon.Option) error) error {\n\tlog := logging.FromContext(ctx).\n\t\tWith(logging.LabelEventSourceType, el.GetEventSourceType(), logging.LabelEventName, el.GetEventName())\n\n\tlog.Info(\"started processing the Slack event source...\")\n\tdefer sources.Recover(el.GetEventName())\n\n\tslackEventSource := &el.SlackEventSource\n\tlog.Info(\"retrieving the slack token...\")\n\ttoken, err := common.GetSecretFromVolume(slackEventSource.Token)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"failed to retrieve the token\")\n\t}\n\n\tlog.Info(\"retrieving the signing secret...\")\n\tsigningSecret, err := common.GetSecretFromVolume(slackEventSource.SigningSecret)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"failed to retrieve the signing secret\")\n\t}\n\n\troute := webhook.NewRoute(slackEventSource.Webhook, log, el.GetEventSourceName(), el.GetEventName(), el.Metrics)\n\n\treturn webhook.ManageRoute(ctx, &Router{\n\t\troute:            route,\n\t\ttoken:            token,\n\t\tsigningSecret:    signingSecret,\n\t\tslackEventSource: slackEventSource,\n\t}, controller, dispatch)\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage slack\n\nimport (\n\t\"bytes\"\n\t\"crypto/hmac\"\n\t\"crypto/sha256\"\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"strconv\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/slack-go/slack/slackevents\"\n\t\"github.com/smartystreets/goconvey/convey\"\n\n\t\"github.com/argoproj/argo-events/eventsources/common/webhook\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestRouteActiveHandler(t *testing.T) {\n\tconvey.Convey(\"Given a route configuration\", t, func() {\n\t\trouter := &Router{\n\t\t\troute:            webhook.GetFakeRoute(),\n\t\t\tslackEventSource: &v1alpha1.SlackEventSource{},\n\t\t}\n\n\t\tconvey.Convey(\"Inactive route should return 404\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\trouter.HandleRoute(writer, &http.Request{})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusBadRequest)\n\t\t})\n\n\t\trouter.token = \"Jhj5dZrVaK7ZwHHjRyZWjbDl\"\n\t\trouter.route.Active = true\n\n\t\tconvey.Convey(\"Test url verification request\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\turlVer := slackevents.EventsAPIURLVerificationEvent{\n\t\t\t\tType:      slackevents.URLVerification,\n\t\t\t\tToken:     \"Jhj5dZrVaK7ZwHHjRyZWjbDl\",\n\t\t\t\tChallenge: \"3eZbrw1aBm2rZgRNFdxV2595E9CY3gmdALWMmHkvFXO7tYXAYM8P\",\n\t\t\t}\n\t\t\tpayload, err := yaml.Marshal(urlVer)\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\t\t\tconvey.So(payload, convey.ShouldNotBeNil)\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tBody: ioutil.NopCloser(bytes.NewReader(payload)),\n\t\t\t})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusInternalServerError)\n\t\t})\n\t})\n}\n\nfunc TestSlackSignature(t *testing.T) {\n\tconvey.Convey(\"Given a route that receives a message from Slack\", t, func() {\n\t\trouter := &Router{\n\t\t\troute:            webhook.GetFakeRoute(),\n\t\t\tslackEventSource: &v1alpha1.SlackEventSource{},\n\t\t}\n\n\t\trouter.signingSecret = \"abcdefghiklm1234567890\"\n\t\tconvey.Convey(\"Validate request signature\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\tpayload := []byte(\"payload=%7B%22type%22%3A%22block_actions%22%2C%22team%22%3A%7B%22id%22%3A%22T0CAG%22%2C%22domain%22%3A%22acme-creamery%22%7D%2C%22user%22%3A%7B%22id%22%3A%22U0CA5%22%2C%22username%22%3A%22Amy%20McGee%22%2C%22name%22%3A%22Amy%20McGee%22%2C%22team_id%22%3A%22T3MDE%22%7D%2C%22api_app_id%22%3A%22A0CA5%22%2C%22token%22%3A%22Shh_its_a_seekrit%22%2C%22container%22%3A%7B%22type%22%3A%22message%22%2C%22text%22%3A%22The%20contents%20of%20the%20original%20message%20where%20the%20action%20originated%22%7D%2C%22trigger_id%22%3A%2212466734323.1395872398%22%2C%22response_url%22%3A%22https%3A%2F%2Fwww.postresponsestome.com%2FT123567%2F1509734234%22%2C%22actions%22%3A%5B%7B%22type%22%3A%22button%22%2C%22block_id%22%3A%22actionblock789%22%2C%22action_id%22%3A%2227S%22%2C%22text%22%3A%7B%22type%22%3A%22plain_text%22%2C%22text%22%3A%22Link%20Button%22%2C%22emoji%22%3Atrue%7D%2C%22action_ts%22%3A%221564701248.149432%22%7D%5D%7D\")\n\t\t\th := make(http.Header)\n\n\t\t\trts := int(time.Now().UTC().UnixNano())\n\t\t\thmac := hmac.New(sha256.New, []byte(router.signingSecret))\n\t\t\tb := strings.Join([]string{\"v0\", strconv.Itoa(rts), string(payload)}, \":\")\n\t\t\t_, err := hmac.Write([]byte(b))\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\t\t\thash := hex.EncodeToString(hmac.Sum(nil))\n\t\t\tgenSig := strings.TrimRight(strings.Join([]string{\"v0=\", hash}, \"\"), \"\\n\")\n\t\t\th.Add(\"Content-Type\", \"application/x-www-form-urlencoded\")\n\t\t\th.Add(\"X-Slack-Signature\", genSig)\n\t\t\th.Add(\"X-Slack-Request-Timestamp\", strconv.FormatInt(int64(rts), 10))\n\n\t\t\trouter.route.Active = true\n\n\t\t\tgo func() {\n\t\t\t\t<-router.route.DataCh\n\t\t\t}()\n\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tBody:   ioutil.NopCloser(bytes.NewReader(payload)),\n\t\t\t\tHeader: h,\n\t\t\t\tMethod: \"POST\",\n\t\t\t})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusOK)\n\t\t})\n\t})\n}\n\nfunc TestInteractionHandler(t *testing.T) {\n\tconvey.Convey(\"Given a route that receives an interaction event\", t, func() {\n\t\trouter := &Router{\n\t\t\troute:            webhook.GetFakeRoute(),\n\t\t\tslackEventSource: &v1alpha1.SlackEventSource{},\n\t\t}\n\n\t\tconvey.Convey(\"Test an interaction action message\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\tactionString := `{\"type\":\"block_actions\",\"team\":{\"id\":\"T9TK3CUKW\",\"domain\":\"example\"},\"user\":{\"id\":\"UA8RXUSPL\",\"username\":\"jtorrance\",\"team_id\":\"T9TK3CUKW\"},\"api_app_id\":\"AABA1ABCD\",\"token\":\"9s8d9as89d8as9d8as989\",\"container\":{\"type\":\"message_attachment\",\"message_ts\":\"1548261231.000200\",\"attachment_id\":1,\"channel_id\":\"CBR2V3XEX\",\"is_ephemeral\":false,\"is_app_unfurl\":false},\"trigger_id\":\"12321423423.333649436676.d8c1bb837935619ccad0f624c448ffb3\",\"channel\":{\"id\":\"CBR2V3XEX\",\"name\":\"review-updates\"},\"message\":{\"bot_id\":\"BAH5CA16Z\",\"type\":\"message\",\"text\":\"This content can't be displayed.\",\"user\":\"UAJ2RU415\",\"ts\":\"1548261231.000200\"},\"response_url\":\"https://hooks.slack.com/actions/AABA1ABCD/1232321423432/D09sSasdasdAS9091209\",\"actions\":[{\"action_id\":\"WaXA\",\"block_id\":\"=qXel\",\"text\":{\"type\":\"plain_text\",\"text\":\"View\",\"emoji\":true},\"value\":\"click_me_123\",\"type\":\"button\",\"action_ts\":\"1548426417.840180\"}]}`\n\t\t\tpayload := []byte(`payload=` + actionString)\n\t\t\tout := make(chan []byte)\n\t\t\trouter.route.Active = true\n\n\t\t\tgo func() {\n\t\t\t\tout <- <-router.route.DataCh\n\t\t\t}()\n\n\t\t\tvar buf bytes.Buffer\n\t\t\tbuf.Write(payload)\n\n\t\t\theaders := make(map[string][]string)\n\t\t\theaders[\"Content-Type\"] = append(headers[\"Content-Type\"], \"application/x-www-form-urlencoded\")\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tMethod: http.MethodPost,\n\t\t\t\tHeader: headers,\n\t\t\t\tBody:   ioutil.NopCloser(strings.NewReader(buf.String())),\n\t\t\t})\n\t\t\tresult := <-out\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusOK)\n\t\t\tconvey.So(string(result), convey.ShouldContainSubstring, \"\\\"type\\\":\\\"block_actions\\\"\")\n\t\t\tconvey.So(string(result), convey.ShouldContainSubstring, \"\\\"token\\\":\\\"9s8d9as89d8as9d8as989\\\"\")\n\t\t})\n\t})\n}\n\nfunc TestSlackCommandHandler(t *testing.T) {\n\tconvey.Convey(\"Given a route that receives a slash command event\", t, func() {\n\t\trouter := &Router{\n\t\t\troute:            webhook.GetFakeRoute(),\n\t\t\tslackEventSource: &v1alpha1.SlackEventSource{},\n\t\t}\n\n\t\tconvey.Convey(\"Test a slash command message\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\t// Test values pulled from example here: https://api.slack.com/interactivity/slash-commands#app_command_handling\n\t\t\tpayload := []byte(`token=gIkuvaNzQIHg97ATvDxqgjtO&team_id=T0001&team_domain=example&enterprise_id=E0001&enterprise_name=Globular%20Construct%20Inc&channel_id=C2147483705&channel_name=test&user_id=U2147483697&user_name=Steve&command=/weather&text=94070&response_url=https://hooks.slack.com/commands/1234/5678&trigger_id=13345224609.738474920.8088930838d88f008e0&api_app_id=A123456`)\n\t\t\tout := make(chan []byte)\n\t\t\trouter.route.Active = true\n\n\t\t\tgo func() {\n\t\t\t\tout <- <-router.route.DataCh\n\t\t\t}()\n\n\t\t\tvar buf bytes.Buffer\n\t\t\tbuf.Write(payload)\n\n\t\t\theaders := make(map[string][]string)\n\t\t\theaders[\"Content-Type\"] = append(headers[\"Content-Type\"], \"application/x-www-form-urlencoded\")\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tMethod: http.MethodPost,\n\t\t\t\tHeader: headers,\n\t\t\t\tBody:   ioutil.NopCloser(strings.NewReader(buf.String())),\n\t\t\t})\n\t\t\tresult := <-out\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusOK)\n\t\t\tconvey.So(string(result), convey.ShouldContainSubstring, \"\\\"command\\\":\\\"/weather\\\"\")\n\t\t\tconvey.So(string(result), convey.ShouldContainSubstring, \"\\\"token\\\":\\\"gIkuvaNzQIHg97ATvDxqgjtO\\\"\")\n\t\t})\n\t})\n}\n\nfunc TestEventHandler(t *testing.T) {\n\tconvey.Convey(\"Given a route that receives an event\", t, func() {\n\t\trouter := &Router{\n\t\t\troute:            webhook.GetFakeRoute(),\n\t\t\tslackEventSource: &v1alpha1.SlackEventSource{},\n\t\t}\n\n\t\tconvey.Convey(\"Test an event notification\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\tevent := []byte(`\n{\n\"type\": \"name_of_event\",\n\"event_ts\": \"1234567890.123456\",\n\"user\": \"UXXXXXXX1\"\n}\n`)\n\n\t\t\tj := json.RawMessage(event)\n\t\t\tce := slackevents.EventsAPICallbackEvent{\n\t\t\t\tToken:     \"Jhj5dZrVaK7ZwHHjRyZWjbDl\",\n\t\t\t\tType:      slackevents.CallbackEvent,\n\t\t\t\tEventTime: 1234567890,\n\t\t\t\tAPIAppID:  \"AXXXXXXXXX\",\n\t\t\t\tAuthedUsers: []string{\n\t\t\t\t\t\"UXXXXXXX1\",\n\t\t\t\t\t\"UXXXXXXX2\",\n\t\t\t\t},\n\t\t\t\tEventID:    \"Ev08MFMKH6\",\n\t\t\t\tInnerEvent: &j,\n\t\t\t}\n\t\t\tpayload, err := yaml.Marshal(ce)\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\n\t\t\trouter.route.Active = true\n\n\t\t\tgo func() {\n\t\t\t\t<-router.route.DataCh\n\t\t\t}()\n\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tBody: ioutil.NopCloser(bytes.NewBuffer(payload)),\n\t\t\t})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusInternalServerError)\n\t\t})\n\t})\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage slack\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"token not provided\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"slack.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Slack)\n\n\tfor name, value := range eventSource.Spec.Slack {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tSlackEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage storagegrid\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/argoproj/argo-events/pkg/apis/events\"\n\t\"github.com/go-resty/resty/v2\"\n\t\"github.com/google/uuid\"\n\t\"github.com/joncalhoun/qson\"\n\t\"github.com/pkg/errors\"\n\t\"go.uber.org/zap\"\n\n\t\"github.com/argoproj/argo-events/common\"\n\t\"github.com/argoproj/argo-events/common/logging\"\n\teventsourcecommon \"github.com/argoproj/argo-events/eventsources/common\"\n\t\"github.com/argoproj/argo-events/eventsources/common/webhook\"\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\tapicommon \"github.com/argoproj/argo-events/pkg/apis/common\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\n// controller controls the webhook operations\nvar (\n\tcontroller = webhook.NewController()\n)\n\nvar (\n\trespBody = `\n<PublishResponse xmlns=\"http://argoevents-sns-server/\">\n    <PublishResult> \n        <MessageId>` + generateUUID().String() + `</MessageId> \n    </PublishResult> \n    <ResponseMetadata>\n       <RequestId>` + generateUUID().String() + `</RequestId>\n    </ResponseMetadata> \n</PublishResponse>` + \"\\n\"\n\n\tnotificationBodyTemplate = `\n<NotificationConfiguration>\n\t<TopicConfiguration>\n\t  <Id>%s</Id>\n\t  <Topic>%s</Topic>\n\t  %s\n\t</TopicConfiguration>\n</NotificationConfiguration>\n` + \"\\n\"\n)\n\n// set up the activation and inactivation channels to control the state of routes.\nfunc init() {\n\tgo webhook.ProcessRouteStatus(controller)\n}\n\n// generateUUID returns a new uuid\nfunc generateUUID() uuid.UUID {\n\treturn uuid.New()\n}\n\n// filterName filters object key based on configured prefix and/or suffix\nfunc filterName(notification *events.StorageGridNotification, eventSource *v1alpha1.StorageGridEventSource) bool {\n\tif eventSource.Filter == nil {\n\t\treturn true\n\t}\n\tif eventSource.Filter.Prefix != \"\" && eventSource.Filter.Suffix != \"\" {\n\t\treturn strings.HasPrefix(notification.Message.Records[0].S3.Object.Key, eventSource.Filter.Prefix) && strings.HasSuffix(notification.Message.Records[0].S3.Object.Key, eventSource.Filter.Suffix)\n\t}\n\tif eventSource.Filter.Prefix != \"\" {\n\t\treturn strings.HasPrefix(notification.Message.Records[0].S3.Object.Key, eventSource.Filter.Prefix)\n\t}\n\tif eventSource.Filter.Suffix != \"\" {\n\t\treturn strings.HasSuffix(notification.Message.Records[0].S3.Object.Key, eventSource.Filter.Suffix)\n\t}\n\treturn true\n}\n\n// GetEventSourceName returns name of event source\nfunc (el *EventListener) GetEventSourceName() string {\n\treturn el.EventSourceName\n}\n\n// GetEventName returns name of event\nfunc (el *EventListener) GetEventName() string {\n\treturn el.EventName\n}\n\n// GetEventSourceType return type of event server\nfunc (el *EventListener) GetEventSourceType() apicommon.EventSourceType {\n\treturn apicommon.StorageGridEvent\n}\n\n// Implement Router\n// 1. GetRoute\n// 2. HandleRoute\n// 3. PostActivate\n// 4. PostDeactivate\n\n// GetRoute returns the route\nfunc (router *Router) GetRoute() *webhook.Route {\n\treturn router.route\n}\n\n// HandleRoute handles new route\nfunc (router *Router) HandleRoute(writer http.ResponseWriter, request *http.Request) {\n\troute := router.route\n\n\tlogger := route.Logger.With(\n\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\tlogging.LabelPort, route.Context.Port,\n\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t)\n\n\tlogger.Info(\"processing incoming request...\")\n\n\tif !route.Active {\n\t\tlogger.Warn(\"endpoint is inactive, won't process the request\")\n\t\tcommon.SendErrorResponse(writer, \"inactive endpoint\")\n\t\treturn\n\t}\n\n\tlogger.Info(\"parsing the request body...\")\n\tbody, err := ioutil.ReadAll(request.Body)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to parse request body\", zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, \"\")\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tif request.Method == http.MethodHead {\n\t\trespBody = \"\"\n\t}\n\n\twriter.WriteHeader(http.StatusOK)\n\twriter.Header().Add(\"Content-Type\", \"text/plain\")\n\tif _, err := writer.Write([]byte(respBody)); err != nil {\n\t\tlogger.Errorw(\"failed to write the response\", zap.Error(err))\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\t// notification received from storage grid is url encoded.\n\tparsedURL, err := url.QueryUnescape(string(body))\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to unescape request body url\", zap.Error(err))\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\tb, err := qson.ToJSON(parsedURL)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to convert request body in JSON format\", zap.Error(err))\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tlogger.Info(\"converting request body to storage grid notification\")\n\tvar notification *events.StorageGridNotification\n\terr = json.Unmarshal(b, &notification)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to convert the request body into storage grid notification\", zap.Error(err))\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tif filterName(notification, router.storageGridEventSource) {\n\t\tdefer func(start time.Time) {\n\t\t\troute.Metrics.EventProcessingDuration(route.EventSourceName, route.EventName, float64(time.Since(start)/time.Millisecond))\n\t\t}(time.Now())\n\n\t\tlogger.Info(\"new event received, dispatching event on route's data channel\")\n\t\teventData := &events.StorageGridEventData{\n\t\t\tNotification: notification,\n\t\t\tMetadata:     router.storageGridEventSource.Metadata,\n\t\t}\n\t\teventBody, err := json.Marshal(eventData)\n\t\tif err != nil {\n\t\t\tlogger.Errorw(\"failed to marshal the event data\", zap.Error(err))\n\t\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\t\treturn\n\t\t}\n\t\troute.DataCh <- eventBody\n\t\treturn\n\t}\n\n\tlogger.Warn(\"discarding notification since it did not pass all filters\")\n}\n\n// PostActivate performs operations once the route is activated and ready to consume requests\nfunc (router *Router) PostActivate() error {\n\teventSource := router.storageGridEventSource\n\troute := router.route\n\n\tauthToken, err := common.GetSecretFromVolume(eventSource.AuthToken)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"AuthToken not found\")\n\t}\n\n\tregistrationURL := common.FormattedURL(eventSource.Webhook.URL, eventSource.Webhook.Endpoint)\n\n\tclient := resty.New()\n\n\tlogger := route.Logger.With(\n\t\t\"registration-url\", registrationURL,\n\t\t\"bucket\", eventSource.Bucket,\n\t\t\"auth-secret-name\", eventSource.AuthToken.Name,\n\t\t\"api-url\", eventSource.APIURL,\n\t)\n\n\tlogger.Info(\"checking if the endpoint already exists...\")\n\n\tresponse, err := client.R().\n\t\tSetHeader(\"Content-Type\", common.MediaTypeJSON).\n\t\tSetAuthToken(authToken).\n\t\tSetResult(&getEndpointResponse{}).\n\t\tSetError(&genericResponse{}).\n\t\tGet(common.FormattedURL(eventSource.APIURL, \"/org/endpoints\"))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif !response.IsSuccess() {\n\t\terrObj := response.Error().(*genericResponse)\n\t\treturn fmt.Errorf(\"failed to list existing endpoints. reason: %s\", errObj.Message.Text)\n\t}\n\n\tendpointResponse := response.Result().(*getEndpointResponse)\n\n\tisURNExists := false\n\n\tfor _, endpoint := range endpointResponse.Data {\n\t\tif endpoint.EndpointURN == eventSource.TopicArn {\n\t\t\tlogger.Info(\"endpoint with topic urn already exists, won't register duplicate endpoint\")\n\t\t\tisURNExists = true\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif !isURNExists {\n\t\tlogger.Info(\"endpoint urn does not exist, registering a new endpoint\")\n\t\tnewEndpoint := createEndpointRequest{\n\t\t\tDisplayName: router.route.EventName,\n\t\t\tEndpointURI: common.FormattedURL(eventSource.Webhook.URL, eventSource.Webhook.Endpoint),\n\t\t\tEndpointURN: eventSource.TopicArn,\n\t\t\tAuthType:    \"anonymous\",\n\t\t\tInsecureTLS: true,\n\t\t}\n\n\t\tnewEndpointBody, err := json.Marshal(&newEndpoint)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tresponse, err := client.R().\n\t\t\tSetHeader(\"Content-Type\", common.MediaTypeJSON).\n\t\t\tSetAuthToken(authToken).\n\t\t\tSetBody(string(newEndpointBody)).\n\t\t\tSetResult(&genericResponse{}).\n\t\t\tSetError(&genericResponse{}).\n\t\t\tPost(common.FormattedURL(eventSource.APIURL, \"/org/endpoints\"))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif !response.IsSuccess() {\n\t\t\terrObj := response.Error().(*genericResponse)\n\t\t\treturn fmt.Errorf(\"failed to register the endpoint. reason: %s\", errObj.Message.Text)\n\t\t}\n\n\t\tlogger.Info(\"successfully registered the endpoint\")\n\t}\n\n\tlogger.Info(\"registering notification configuration on storagegrid...\")\n\n\tvar events []string\n\tfor _, event := range eventSource.Events {\n\t\tevents = append(events, fmt.Sprintf(\"<Event>%s</Event>\", event))\n\t}\n\n\teventXML := strings.Join(events, \"\\n\")\n\n\tnotificationBody := fmt.Sprintf(notificationBodyTemplate, route.EventName, eventSource.TopicArn, eventXML)\n\n\tnotification := &storageGridNotificationRequest{\n\t\tNotification: notificationBody,\n\t}\n\n\tnotificationRequestBody, err := json.Marshal(notification)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tresponse, err = client.R().\n\t\tSetHeader(\"Content-Type\", common.MediaTypeJSON).\n\t\tSetAuthToken(authToken).\n\t\tSetBody(string(notificationRequestBody)).\n\t\tSetResult(&registerNotificationResponse{}).\n\t\tSetError(&genericResponse{}).\n\t\tPut(common.FormattedURL(eventSource.APIURL, fmt.Sprintf(\"/org/containers/%s/notification\", eventSource.Bucket)))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif !response.IsSuccess() {\n\t\terrObj := response.Error().(*genericResponse)\n\t\treturn errors.Errorf(\"failed to configure notification. reason %s\", errObj.Message.Text)\n\t}\n\n\tlogger.Info(\"successfully registered notification configuration on storagegrid\")\n\treturn nil\n}\n\n// PostInactivate performs operations after the route is inactivated\nfunc (router *Router) PostInactivate() error {\n\treturn nil\n}\n\n// StartListening starts an event source\nfunc (el *EventListener) StartListening(ctx context.Context, dispatch func([]byte, ...eventsourcecommon.Option) error) error {\n\tlog := logging.FromContext(ctx).\n\t\tWith(logging.LabelEventSourceType, el.GetEventSourceType(), logging.LabelEventName, el.GetEventName())\n\tlog.Info(\"started processing the Storage Grid event source...\")\n\tdefer sources.Recover(el.GetEventName())\n\n\tstoragegridEventSource := &el.StorageGridEventSource\n\troute := webhook.NewRoute(storagegridEventSource.Webhook, log, el.GetEventSourceName(), el.GetEventName(), el.Metrics)\n\n\treturn webhook.ManageRoute(ctx, &Router{\n\t\troute:                  route,\n\t\tstorageGridEventSource: storagegridEventSource,\n\t}, controller, dispatch)\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage storagegrid\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/common/webhook\"\n\t\"github.com/argoproj/argo-events/pkg/apis/events\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/smartystreets/goconvey/convey\"\n)\n\nvar (\n\tnotification = `\n{\n  \"Action\": \"Publish\",\n  \"Message\": {\n    \"Records\": [\n      {\n        \"eventName\": \"ObjectCreated:Put\",\n        \"storageGridEventSource\": \"sgws:s3\",\n        \"eventTime\": \"2019-02-27T21:15:09Z\",\n        \"eventVersion\": \"2.0\",\n        \"requestParameters\": {\n          \"sourceIPAddress\": \"1.1.1.1\"\n        },\n        \"responseElements\": {\n          \"x-amz-request-id\": \"12345678\"\n        },\n        \"s3\": {\n          \"bucket\": {\n            \"arn\": \"urn:sgfs:s3:::my_bucket\",\n            \"name\": \"my_bucket\",\n            \"ownerIdentity\": {\n              \"principalId\": \"55555555555555555\"\n            }\n          },\n          \"configurationId\": \"Object-Event\",\n          \"object\": {\n            \"eTag\": \"4444444444444444\",\n            \"key\": \"hello-world.txt\",\n            \"sequencer\": \"AAAAAA\",\n            \"size\": 6\n          },\n          \"s3SchemaVersion\": \"1.0\"\n        },\n        \"userIdentity\": {\n          \"principalId\": \"1111111111111111\"\n        }\n      }\n    ]\n  },\n  \"TopicArn\": \"urn:h:sns:us-east::my_topic_1\",\n  \"Version\": \"2010-03-31\"\n}\n`\n\trouter = &Router{\n\t\troute: webhook.GetFakeRoute(),\n\t}\n)\n\nfunc TestRouteActiveHandler(t *testing.T) {\n\tconvey.Convey(\"Given a route configuration\", t, func() {\n\t\tstorageGridEventSource := &v1alpha1.StorageGridEventSource{\n\t\t\tWebhook: &v1alpha1.WebhookContext{\n\t\t\t\tEndpoint: \"/\",\n\t\t\t\tURL:      \"testurl\",\n\t\t\t\tPort:     \"8080\",\n\t\t\t},\n\t\t\tEvents: []string{\n\t\t\t\t\"ObjectCreated:Put\",\n\t\t\t},\n\t\t\tFilter: &v1alpha1.StorageGridFilter{\n\t\t\t\tPrefix: \"hello-\",\n\t\t\t\tSuffix: \".txt\",\n\t\t\t},\n\t\t}\n\n\t\twriter := &webhook.FakeHttpWriter{}\n\n\t\tconvey.Convey(\"Inactive route should return error\", func() {\n\t\t\tpbytes, err := yaml.Marshal(storageGridEventSource)\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tBody: ioutil.NopCloser(bytes.NewReader(pbytes)),\n\t\t\t})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusBadRequest)\n\t\t})\n\n\t\tconvey.Convey(\"Active route should return success\", func() {\n\t\t\trouter.route.Active = true\n\t\t\trouter.storageGridEventSource = storageGridEventSource\n\t\t\tdataCh := make(chan []byte)\n\t\t\tgo func() {\n\t\t\t\tresp := <-router.route.DataCh\n\t\t\t\tdataCh <- resp\n\t\t\t}()\n\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tBody: ioutil.NopCloser(bytes.NewReader([]byte(notification))),\n\t\t\t})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusOK)\n\t\t})\n\t})\n}\n\nfunc TestGenerateUUID(t *testing.T) {\n\tconvey.Convey(\"Make sure generated UUIDs are unique\", t, func() {\n\t\tu1 := generateUUID()\n\t\tu2 := generateUUID()\n\t\tconvey.So(u1.String(), convey.ShouldNotEqual, u2.String())\n\t})\n}\n\nfunc TestFilterName(t *testing.T) {\n\tconvey.Convey(\"Given a storage grid event, test whether the object key passes the filter\", t, func() {\n\t\tstorageGridEventSource := &v1alpha1.StorageGridEventSource{\n\t\t\tWebhook: &v1alpha1.WebhookContext{\n\t\t\t\tEndpoint: \"/\",\n\t\t\t\tURL:      \"testurl\",\n\t\t\t\tPort:     \"8080\",\n\t\t\t},\n\t\t\tEvents: []string{\n\t\t\t\t\"ObjectCreated:Put\",\n\t\t\t},\n\t\t\tFilter: &v1alpha1.StorageGridFilter{\n\t\t\t\tPrefix: \"hello-\",\n\t\t\t\tSuffix: \".txt\",\n\t\t\t},\n\t\t}\n\t\tvar gridNotification *events.StorageGridNotification\n\t\terr := json.Unmarshal([]byte(notification), &gridNotification)\n\t\tconvey.So(err, convey.ShouldBeNil)\n\t\tconvey.So(gridNotification, convey.ShouldNotBeNil)\n\n\t\tok := filterName(gridNotification, storageGridEventSource)\n\t\tconvey.So(ok, convey.ShouldEqual, true)\n\t})\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage storagegrid\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"topic arn must be provided\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"storage-grid.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.StorageGrid)\n\n\tfor name, value := range eventSource.Spec.StorageGrid {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tStorageGridEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage stripe\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"time\"\n\n\t\"github.com/pkg/errors\"\n\t\"github.com/stripe/stripe-go\"\n\t\"github.com/stripe/stripe-go/webhookendpoint\"\n\t\"go.uber.org/zap\"\n\n\t\"github.com/argoproj/argo-events/common\"\n\t\"github.com/argoproj/argo-events/common/logging\"\n\teventsourcecommon \"github.com/argoproj/argo-events/eventsources/common\"\n\t\"github.com/argoproj/argo-events/eventsources/common/webhook\"\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\tapicommon \"github.com/argoproj/argo-events/pkg/apis/common\"\n\t\"github.com/argoproj/argo-events/pkg/apis/events\"\n)\n\n// controller controls the webhook operations\nvar (\n\tcontroller = webhook.NewController()\n)\n\n// set up the activation and inactivation channels to control the state of routes.\nfunc init() {\n\tgo webhook.ProcessRouteStatus(controller)\n}\n\n// GetEventSourceName returns name of event source\nfunc (el *EventListener) GetEventSourceName() string {\n\treturn el.EventSourceName\n}\n\n// GetEventName returns name of event\nfunc (el *EventListener) GetEventName() string {\n\treturn el.EventName\n}\n\n// GetEventSourceType return type of event server\nfunc (el *EventListener) GetEventSourceType() apicommon.EventSourceType {\n\treturn apicommon.StripeEvent\n}\n\n// Implement Router\n// 1. GetRoute\n// 2. HandleRoute\n// 3. PostActivate\n// 4. PostDeactivate\n\n// GetRoute returns the route\nfunc (rc *Router) GetRoute() *webhook.Route {\n\treturn rc.route\n}\n\n// HandleRoute handles incoming requests on the route\nfunc (rc *Router) HandleRoute(writer http.ResponseWriter, request *http.Request) {\n\troute := rc.route\n\n\tlogger := route.Logger.With(\n\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\tlogging.LabelPort, route.Context.Port,\n\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t)\n\n\tlogger.Info(\"request a received, processing it...\")\n\n\tif !route.Active {\n\t\tlogger.Warn(\"endpoint is not active, won't process it\")\n\t\tcommon.SendErrorResponse(writer, \"endpoint is inactive\")\n\t\treturn\n\t}\n\n\tdefer func(start time.Time) {\n\t\troute.Metrics.EventProcessingDuration(route.EventSourceName, route.EventName, float64(time.Since(start)/time.Millisecond))\n\t}(time.Now())\n\n\tconst MaxBodyBytes = int64(65536)\n\trequest.Body = http.MaxBytesReader(writer, request.Body, MaxBodyBytes)\n\tpayload, err := ioutil.ReadAll(request.Body)\n\tif err != nil {\n\t\tlogger.Errorw(\"error reading request body\", zap.Error(err))\n\t\twriter.WriteHeader(http.StatusServiceUnavailable)\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tvar event *stripe.Event\n\tif err := json.Unmarshal(payload, &event); err != nil {\n\t\tlogger.Errorw(\"failed to parse request body\", zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, \"failed to parse the event\")\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tif ok := filterEvent(event, rc.stripeEventSource.EventFilter); !ok {\n\t\tlogger.Errorw(\"failed to pass the filters\", zap.Any(\"event-type\", event.Type), zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, \"invalid event\")\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\teventData := &events.StripeEventData{\n\t\tEvent:    event,\n\t\tMetadata: rc.stripeEventSource.Metadata,\n\t}\n\n\tdata, err := json.Marshal(eventData)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to marshal event data\", zap.Any(\"event-id\", event.ID), zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, \"invalid event\")\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tlogger.Info(\"dispatching event on route's data channel...\")\n\troute.DataCh <- data\n\tlogger.Info(\"request successfully processed\")\n\tcommon.SendSuccessResponse(writer, \"success\")\n}\n\n// PostActivate performs operations once the route is activated and ready to consume requests\nfunc (rc *Router) PostActivate() error {\n\tif rc.stripeEventSource.CreateWebhook {\n\t\troute := rc.route\n\t\tstripeEventSource := rc.stripeEventSource\n\t\tlogger := route.Logger.With(\n\t\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t\t)\n\t\tlogger.Info(\"registering a new webhook\")\n\n\t\tapiKey, err := common.GetSecretFromVolume(stripeEventSource.APIKey)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"APIKey not found\")\n\t\t}\n\n\t\tstripe.Key = apiKey\n\n\t\tparams := &stripe.WebhookEndpointParams{\n\t\t\tURL: stripe.String(common.FormattedURL(stripeEventSource.Webhook.URL, stripeEventSource.Webhook.Endpoint)),\n\t\t}\n\t\tif stripeEventSource.EventFilter != nil {\n\t\t\tparams.EnabledEvents = stripe.StringSlice(stripeEventSource.EventFilter)\n\t\t}\n\n\t\tendpoint, err := webhookendpoint.New(params)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tlogger.With(\"endpoint-id\", endpoint.ID).Info(\"new stripe webhook endpoint created\")\n\t}\n\treturn nil\n}\n\n// PostInactivate performs operations after the route is inactivated\nfunc (rc *Router) PostInactivate() error {\n\treturn nil\n}\n\nfunc filterEvent(event *stripe.Event, filters []string) bool {\n\tif filters == nil {\n\t\treturn true\n\t}\n\tfor _, filter := range filters {\n\t\tif event.Type == filter {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// StartListening starts an event source\nfunc (el *EventListener) StartListening(ctx context.Context, dispatch func([]byte, ...eventsourcecommon.Option) error) error {\n\tlog := logging.FromContext(ctx).\n\t\tWith(logging.LabelEventSourceType, el.GetEventSourceType(), logging.LabelEventName, el.GetEventName())\n\tlog.Info(\"started processing the Stripe event source...\")\n\tdefer sources.Recover(el.GetEventName())\n\n\tstripeEventSource := &el.StripeEventSource\n\troute := webhook.NewRoute(stripeEventSource.Webhook, log, el.GetEventSourceName(), el.GetEventName(), el.Metrics)\n\n\treturn webhook.ManageRoute(ctx, &Router{\n\t\troute:             route,\n\t\tstripeEventSource: stripeEventSource,\n\t}, controller, dispatch)\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage stripe\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{\n\t\tStripeEventSource: v1alpha1.StripeEventSource{\n\t\t\tCreateWebhook: true,\n\t\t},\n\t}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"api key K8s secret selector not provided\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"stripe.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Stripe)\n\n\tfor name, value := range eventSource.Spec.Stripe {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tStripeEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage webhook\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"time\"\n\n\t\"go.uber.org/zap\"\n\n\t\"github.com/argoproj/argo-events/common\"\n\t\"github.com/argoproj/argo-events/common/logging\"\n\teventsourcecommon \"github.com/argoproj/argo-events/eventsources/common\"\n\t\"github.com/argoproj/argo-events/eventsources/common/webhook\"\n\tmetrics \"github.com/argoproj/argo-events/metrics\"\n\tapicommon \"github.com/argoproj/argo-events/pkg/apis/common\"\n\t\"github.com/argoproj/argo-events/pkg/apis/events\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nvar (\n\tcontroller = webhook.NewController()\n)\n\nfunc init() {\n\tgo webhook.ProcessRouteStatus(controller)\n}\n\n// EventListener implements Eventing for webhook events\ntype EventListener struct {\n\tEventSourceName string\n\tEventName       string\n\tWebhookContext  v1alpha1.WebhookContext\n\tMetrics         *metrics.Metrics\n}\n\n// GetEventSourceName returns name of event source\nfunc (el *EventListener) GetEventSourceName() string {\n\treturn el.EventSourceName\n}\n\n// GetEventName returns name of event\nfunc (el *EventListener) GetEventName() string {\n\treturn el.EventName\n}\n\n// GetEventSourceType return type of event server\nfunc (el *EventListener) GetEventSourceType() apicommon.EventSourceType {\n\treturn apicommon.WebhookEvent\n}\n\n// Router contains the configuration information for a route\ntype Router struct {\n\t// route contains information about a API endpoint\n\troute *webhook.Route\n}\n\n// Implement Router\n// 1. GetRoute\n// 2. HandleRoute\n// 3. PostActivate\n// 4. PostDeactivate\n\n// GetRoute returns the route\nfunc (router *Router) GetRoute() *webhook.Route {\n\treturn router.route\n}\n\n// HandleRoute handles incoming requests on the route\nfunc (router *Router) HandleRoute(writer http.ResponseWriter, request *http.Request) {\n\troute := router.GetRoute()\n\n\tlogger := route.Logger.With(\n\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\tlogging.LabelPort, route.Context.Port,\n\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t)\n\n\tlogger.Info(\"a request received, processing it...\")\n\n\tif !route.Active {\n\t\tlogger.Info(\"endpoint is not active, wont't process the request\")\n\t\tcommon.SendErrorResponse(writer, \"endpoint is inactive\")\n\t\treturn\n\t}\n\n\tdefer func(start time.Time) {\n\t\troute.Metrics.EventProcessingDuration(route.EventSourceName, route.EventName, float64(time.Since(start)/time.Millisecond))\n\t}(time.Now())\n\n\tbody, err := ioutil.ReadAll(request.Body)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to parse request body\", zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tpayload := &events.WebhookEventData{\n\t\tHeader:   request.Header,\n\t\tBody:     (*json.RawMessage)(&body),\n\t\tMetadata: route.Context.Metadata,\n\t}\n\n\tdata, err := json.Marshal(payload)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to construct the event payload\", zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tlogger.Info(\"dispatching event on route's data channel...\")\n\troute.DataCh <- data\n\tlogger.Info(\"successfully processed the request\")\n\tcommon.SendSuccessResponse(writer, \"success\")\n}\n\n// PostActivate performs operations once the route is activated and ready to consume requests\nfunc (router *Router) PostActivate() error {\n\treturn nil\n}\n\n// PostInactivate performs operations after the route is inactivated\nfunc (router *Router) PostInactivate() error {\n\treturn nil\n}\n\n// StartListening starts listening events\nfunc (el *EventListener) StartListening(ctx context.Context, dispatch func([]byte, ...eventsourcecommon.Option) error) error {\n\tlog := logging.FromContext(ctx).\n\t\tWith(logging.LabelEventSourceType, el.GetEventSourceType(), logging.LabelEventName, el.GetEventName())\n\tlog.Info(\"started processing the webhook event source...\")\n\n\troute := webhook.NewRoute(&el.WebhookContext, log, el.GetEventSourceName(), el.GetEventName(), el.Metrics)\n\treturn webhook.ManageRoute(ctx, &Router{\n\t\troute: route,\n\t}, controller, dispatch)\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage webhook\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{\n\t\tWebhookContext: v1alpha1.WebhookContext{},\n\t}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"webhook.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Webhook)\n\n\tfor _, value := range eventSource.Spec.Webhook {\n\t\tl := &EventListener{\n\t\t\tWebhookContext: value,\n\t\t}\n\t\terr = l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "package main\n\nimport (\n\t\"io/ioutil\"\n\n\t\"sigs.k8s.io/yaml\"\n)\n\ntype obj = map[string]interface{}\n\nfunc cleanCRD(filename string) {\n\tdata, err := ioutil.ReadFile(filename)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tcrd := make(map[string]interface{})\n\terr = yaml.Unmarshal(data, &crd)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdelete(crd, \"status\")\n\tmetadata := crd[\"metadata\"].(obj)\n\tif metadata[\"name\"] == \"eventbuses.argoproj.io\" {\n\t\tmetadata[\"name\"] = \"eventbus.argoproj.io\"\n\t}\n\tdelete(metadata, \"annotations\")\n\tdelete(metadata, \"creationTimestamp\")\n\tspec := crd[\"spec\"].(obj)\n\tdelete(spec, \"validation\")\n\tnames := spec[\"names\"].(obj)\n\tif names[\"plural\"] == \"eventbuses\" {\n\t\tnames[\"plural\"] = \"eventbus\"\n\t}\n\tversions := spec[\"versions\"].([]interface{})\n\tversion := versions[0].(obj)\n\tproperties := version[\"schema\"].(obj)[\"openAPIV3Schema\"].(obj)[\"properties\"].(obj)\n\tfor k := range properties {\n\t\tif k == \"spec\" || k == \"status\" {\n\t\t\tproperties[k] = obj{\"type\": \"object\", \"x-kubernetes-preserve-unknown-fields\": true}\n\t\t}\n\t}\n\tdata, err = yaml.Marshal(crd)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\terr = ioutil.WriteFile(filename, data, 0666)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n}\n", "package main\n\nimport (\n\t\"encoding/json\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"os\"\n\t\"strings\"\n\n\t\"k8s.io/kube-openapi/pkg/common\"\n\t\"k8s.io/kube-openapi/pkg/validation/spec\"\n\n\tcv1 \"github.com/argoproj/argo-events/pkg/apis/common\"\n\tebv1 \"github.com/argoproj/argo-events/pkg/apis/eventbus/v1alpha1\"\n\tesv1 \"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\tsv1 \"github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1\"\n)\n\ntype (\n\tobj = map[string]interface{}\n)\n\n// Generate OpenAPI spec definitions for Workflow Resource\nfunc main() {\n\tif len(os.Args) <= 3 {\n\t\tlog.Fatal(\"Supply a version\")\n\t}\n\tlog.Println(os.Args)\n\tversion := os.Args[1]\n\tkubeSwaggerPath := os.Args[2]\n\toutput := os.Args[3]\n\tif version != \"latest\" && !strings.HasPrefix(version, \"v\") {\n\t\tversion = \"v\" + version\n\t}\n\treferenceCallback := func(name string) spec.Ref {\n\t\treturn spec.MustCreateRef(\"#/definitions/\" + common.EscapeJsonPointer(swaggify(name)))\n\t}\n\tdefs := spec.Definitions{}\n\tdependencies := []string{}\n\tfor defName, val := range cv1.GetOpenAPIDefinitions(referenceCallback) {\n\t\tdefs[swaggify(defName)] = val.Schema\n\t\tdependencies = append(dependencies, val.Dependencies...)\n\t}\n\tfor defName, val := range ebv1.GetOpenAPIDefinitions(referenceCallback) {\n\t\tdefs[swaggify(defName)] = val.Schema\n\t\tdependencies = append(dependencies, val.Dependencies...)\n\t}\n\tfor defName, val := range esv1.GetOpenAPIDefinitions(referenceCallback) {\n\t\tdefs[swaggify(defName)] = val.Schema\n\t\tdependencies = append(dependencies, val.Dependencies...)\n\t}\n\tfor defName, val := range sv1.GetOpenAPIDefinitions(referenceCallback) {\n\t\tdefs[swaggify(defName)] = val.Schema\n\t\tdependencies = append(dependencies, val.Dependencies...)\n\t}\n\n\tk8sDefinitions := getKubernetesSwagger(kubeSwaggerPath)\n\tfor _, dep := range dependencies {\n\t\tif !strings.Contains(dep, \"k8s.io\") {\n\t\t\tcontinue\n\t\t}\n\t\td := swaggify(dep)\n\t\tif kd, ok := k8sDefinitions[d]; ok {\n\t\t\tdefs[d] = kd\n\t\t}\n\t}\n\tfor d, s := range k8sDefinitions {\n\t\tdefs[d] = s\n\t}\n\n\tswagger := &spec.Swagger{\n\t\tSwaggerProps: spec.SwaggerProps{\n\t\t\tSwagger:     \"2.0\",\n\t\t\tDefinitions: defs,\n\t\t\tPaths:       &spec.Paths{Paths: map[string]spec.PathItem{}},\n\t\t\tInfo: &spec.Info{\n\t\t\t\tInfoProps: spec.InfoProps{\n\t\t\t\t\tTitle:   \"Argo Events\",\n\t\t\t\t\tVersion: version,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tjsonBytes, err := json.MarshalIndent(swagger, \"\", \"  \")\n\tif err != nil {\n\t\tlog.Fatal(err.Error())\n\t}\n\terr = ioutil.WriteFile(output, jsonBytes, 0644)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tf, err := os.Open(output)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\t// filter out \"default\" fields from swagger definitions properties because they are being set to empty strings and it makes the swagger validation fail.\n\tswaggerObj := obj{}\n\terr = json.NewDecoder(f).Decode(&swaggerObj)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefinitions := swaggerObj[\"definitions\"].(obj)\n\n\tfor _, d := range definitions {\n\t\tprops, ok := d.(obj)[\"properties\"].(obj)\n\t\tif ok {\n\t\t\tfor _, prop := range props {\n\t\t\t\tprop := prop.(obj)\n\t\t\t\tdelete(prop, \"default\")\n\t\t\t\titems, ok := prop[\"items\"].(obj)\n\t\t\t\tif ok {\n\t\t\t\t\tdelete(items, \"default\")\n\t\t\t\t}\n\t\t\t\tadditionalProperties, ok := prop[\"additionalProperties\"].(obj)\n\t\t\t\tif ok {\n\t\t\t\t\tdelete(additionalProperties, \"default\")\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tprops, ok = d.(obj)[\"additionalProperties\"].(obj)\n\t\tif ok {\n\t\t\tdelete(props, \"default\")\n\t\t}\n\t}\n\n\tf, err = os.Create(output)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\te := json.NewEncoder(f)\n\te.SetIndent(\"\", \"  \")\n\terr = e.Encode(swaggerObj)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\terr = f.Close()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n}\n\n// swaggify converts the github package\n// e.g.:\n// github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1.Sensor\n// to:\n// io.argoproj.v1alpha1.Sensor\nfunc swaggify(name string) string {\n\tname = strings.ReplaceAll(name, \"github.com/argoproj/argo-events/pkg/apis\", \"argoproj.io\")\n\tparts := strings.Split(name, \"/\")\n\thostParts := strings.Split(parts[0], \".\")\n\t// reverses something like k8s.io to io.k8s\n\tfor i, j := 0, len(hostParts)-1; i < j; i, j = i+1, j-1 {\n\t\thostParts[i], hostParts[j] = hostParts[j], hostParts[i]\n\t}\n\tparts[0] = strings.Join(hostParts, \".\")\n\treturn strings.Join(parts, \".\")\n}\n\nfunc getKubernetesSwagger(kubeSwaggerPath string) spec.Definitions {\n\tdata, err := ioutil.ReadFile(kubeSwaggerPath)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tswagger := &spec.Swagger{}\n\terr = json.Unmarshal(data, swagger)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn swagger.Definitions\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage artifacts\n\nimport (\n\t\"errors\"\n\t\"io/ioutil\"\n\n\t\"github.com/argoproj/argo-events/common/logging\"\n\t\"github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1\"\n)\n\n// FileReader implements the ArtifactReader interface for file artifacts\ntype FileReader struct {\n\tfileArtifact *v1alpha1.FileArtifact\n}\n\n// NewFileReader creates a new ArtifactReader for inline\nfunc NewFileReader(fileArtifact *v1alpha1.FileArtifact) (ArtifactReader, error) {\n\t// This should never happen!\n\tif fileArtifact == nil {\n\t\treturn nil, errors.New(\"FileArtifact cannot be empty\")\n\t}\n\treturn &FileReader{fileArtifact}, nil\n}\n\nfunc (reader *FileReader) Read() ([]byte, error) {\n\tcontent, err := ioutil.ReadFile(reader.fileArtifact.Path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tlog := logging.NewArgoEventsLogger()\n\tlog.Debugf(\"reading fileArtifact from %s\", reader.fileArtifact.Path)\n\treturn content, nil\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage artifacts\n\nimport (\n\t\"io/ioutil\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1\"\n)\n\nfunc TestFileReader(t *testing.T) {\n\tcontent := []byte(\"temp content\")\n\ttmpfile, err := ioutil.TempFile(\"\", \"argo-events-temp\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tdefer os.Remove(tmpfile.Name())\n\n\tif _, err := tmpfile.Write(content); err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif err := tmpfile.Close(); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tfileArtifact := v1alpha1.FileArtifact{Path: tmpfile.Name()}\n\tfileReader, err := NewFileReader(&fileArtifact)\n\tassert.NotNil(t, fileReader)\n\tassert.Nil(t, err)\n\tdata, err := fileReader.Read()\n\tassert.NotNil(t, data)\n\tassert.Nil(t, err)\n\tassert.Equal(t, content, data)\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage artifacts\n\nimport (\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"path\"\n\t\"strings\"\n\n\t\"github.com/go-git/go-git/v5\"\n\t\"github.com/go-git/go-git/v5/config\"\n\t\"github.com/go-git/go-git/v5/plumbing\"\n\t\"github.com/go-git/go-git/v5/plumbing/transport\"\n\t\"github.com/go-git/go-git/v5/plumbing/transport/http\"\n\tgo_git_ssh \"github.com/go-git/go-git/v5/plumbing/transport/ssh\"\n\t\"github.com/pkg/errors\"\n\t\"golang.org/x/crypto/ssh\"\n\n\t\"github.com/argoproj/argo-events/common\"\n\t\"github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1\"\n)\n\nconst (\n\tDefaultRemote = \"origin\"\n\tDefaultBranch = \"master\"\n)\n\nvar (\n\tfetchRefSpec = []config.RefSpec{\n\t\t\"refs/*:refs/*\",\n\t\t\"HEAD:refs/heads/HEAD\",\n\t}\n\n\tnotAllowedInPath = []string{\"..\", \"~\", \"\\\\\"}\n)\n\ntype GitArtifactReader struct {\n\tartifact *v1alpha1.GitArtifact\n}\n\n// NewGitReader returns a new git reader\nfunc NewGitReader(gitArtifact *v1alpha1.GitArtifact) (*GitArtifactReader, error) {\n\tif gitArtifact == nil {\n\t\treturn nil, fmt.Errorf(\"nil git artifact\")\n\t}\n\tfor _, na := range notAllowedInPath {\n\t\tif strings.Contains(gitArtifact.FilePath, na) {\n\t\t\treturn nil, fmt.Errorf(\"%q is not allowed in the filepath\", na)\n\t\t}\n\t}\n\n\treturn &GitArtifactReader{\n\t\tartifact: gitArtifact,\n\t}, nil\n}\n\nfunc (g *GitArtifactReader) getRemote() string {\n\tif g.artifact.Remote != nil {\n\t\treturn g.artifact.Remote.Name\n\t}\n\treturn DefaultRemote\n}\n\nfunc getSSHKeyAuth(sshKeyFile string) (transport.AuthMethod, error) {\n\tsshKey, err := ioutil.ReadFile(sshKeyFile)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to read ssh key file. err: %+v\", err)\n\t}\n\tsigner, err := ssh.ParsePrivateKey(sshKey)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to parse ssh key. err: %+v\", err)\n\t}\n\tauth := &go_git_ssh.PublicKeys{User: \"git\", Signer: signer}\n\tauth.HostKeyCallback = ssh.InsecureIgnoreHostKey()\n\treturn auth, nil\n}\n\nfunc (g *GitArtifactReader) getGitAuth() (transport.AuthMethod, error) {\n\tif g.artifact.Creds != nil {\n\t\tusername, err := common.GetSecretFromVolume(g.artifact.Creds.Username)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to retrieve username\")\n\t\t}\n\t\tpassword, err := common.GetSecretFromVolume(g.artifact.Creds.Password)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to retrieve password\")\n\t\t}\n\t\treturn &http.BasicAuth{\n\t\t\tUsername: username,\n\t\t\tPassword: password,\n\t\t}, nil\n\t}\n\tif g.artifact.SSHKeySecret != nil {\n\t\tsshKeyPath, err := common.GetSecretVolumePath(g.artifact.SSHKeySecret)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to get SSH key from mounted volume\")\n\t\t}\n\t\treturn getSSHKeyAuth(sshKeyPath)\n\t}\n\treturn nil, nil\n}\n\nfunc (g *GitArtifactReader) readFromRepository(r *git.Repository, dir string) ([]byte, error) {\n\tauth, err := g.getGitAuth()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif g.artifact.Remote != nil {\n\t\t_, err := r.CreateRemote(&config.RemoteConfig{\n\t\t\tName: g.artifact.Remote.Name,\n\t\t\tURLs: g.artifact.Remote.URLS,\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to create remote. err: %+v\", err)\n\t\t}\n\n\t\tfetchOptions := &git.FetchOptions{\n\t\t\tRemoteName: g.artifact.Remote.Name,\n\t\t\tRefSpecs:   fetchRefSpec,\n\t\t\tForce:      true,\n\t\t}\n\t\tif auth != nil {\n\t\t\tfetchOptions.Auth = auth\n\t\t}\n\n\t\tif err := r.Fetch(fetchOptions); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to fetch remote %s. err: %+v\", g.artifact.Remote.Name, err)\n\t\t}\n\t}\n\n\tw, err := r.Worktree()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to get working tree. err: %+v\", err)\n\t}\n\n\tfetchOptions := &git.FetchOptions{\n\t\tRemoteName: g.getRemote(),\n\t\tRefSpecs:   fetchRefSpec,\n\t\tForce:      true,\n\t}\n\tif auth != nil {\n\t\tfetchOptions.Auth = auth\n\t}\n\n\t// In the case of a specific given ref, it isn't necessary to fetch anything\n\t// but the single ref\n\tif g.artifact.Ref != \"\" {\n\t\tfetchOptions.Depth = 1\n\t\tfetchOptions.RefSpecs = []config.RefSpec{config.RefSpec(g.artifact.Ref + \":\" + g.artifact.Ref)}\n\t}\n\n\tif err := r.Fetch(fetchOptions); err != nil && err != git.NoErrAlreadyUpToDate {\n\t\treturn nil, fmt.Errorf(\"failed to fetch. err: %v\", err)\n\t}\n\n\tif err := w.Checkout(g.getBranchOrTag()); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to checkout. err: %+v\", err)\n\t}\n\n\t// In the case of a specific given ref, it shouldn't be necessary to pull\n\tif g.artifact.Ref != \"\" {\n\t\tpullOpts := &git.PullOptions{\n\t\t\tRecurseSubmodules: git.DefaultSubmoduleRecursionDepth,\n\t\t\tReferenceName:     g.getBranchOrTag().Branch,\n\t\t\tForce:             true,\n\t\t}\n\t\tif auth != nil {\n\t\t\tpullOpts.Auth = auth\n\t\t}\n\n\t\tif err := w.Pull(pullOpts); err != nil && err != git.NoErrAlreadyUpToDate {\n\t\t\treturn nil, fmt.Errorf(\"failed to pull latest updates. err: %+v\", err)\n\t\t}\n\t}\n\tfilePath := fmt.Sprintf(\"%s/%s\", dir, g.artifact.FilePath)\n\t// symbol link is not allowed due to security concern\n\tisSymbolLink, err := isSymbolLink(filePath)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif isSymbolLink {\n\t\treturn nil, fmt.Errorf(\"%q is a symbol link which is not allowed\", g.artifact.FilePath)\n\t}\n\treturn ioutil.ReadFile(filePath)\n}\n\nfunc (g *GitArtifactReader) getBranchOrTag() *git.CheckoutOptions {\n\topts := &git.CheckoutOptions{}\n\n\topts.Branch = plumbing.NewBranchReferenceName(DefaultBranch)\n\n\tif g.artifact.Branch != \"\" {\n\t\topts.Branch = plumbing.NewBranchReferenceName(g.artifact.Branch)\n\t}\n\tif g.artifact.Tag != \"\" {\n\t\topts.Branch = plumbing.NewTagReferenceName(g.artifact.Tag)\n\t}\n\tif g.artifact.Ref != \"\" {\n\t\topts.Branch = plumbing.ReferenceName(g.artifact.Ref)\n\t}\n\n\treturn opts\n}\n\nfunc (g *GitArtifactReader) Read() ([]byte, error) {\n\tcloneDir := g.artifact.CloneDirectory\n\tif cloneDir == \"\" {\n\t\ttempDir, err := ioutil.TempDir(\"\", \"git-tmp\")\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to create a temp file to clone the repository\")\n\t\t}\n\t\tdefer os.Remove(tempDir)\n\t\tcloneDir = tempDir\n\t}\n\n\tr, err := git.PlainOpen(cloneDir)\n\tif err != nil {\n\t\tif err != git.ErrRepositoryNotExists {\n\t\t\treturn nil, fmt.Errorf(\"failed to open repository. err: %+v\", err)\n\t\t}\n\n\t\tcloneOpt := &git.CloneOptions{\n\t\t\tURL:               g.artifact.URL,\n\t\t\tRecurseSubmodules: git.DefaultSubmoduleRecursionDepth,\n\t\t}\n\n\t\tauth, err := g.getGitAuth()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif auth != nil {\n\t\t\tcloneOpt.Auth = auth\n\t\t}\n\n\t\t// In the case of a specific given ref, it isn't necessary to have branch\n\t\t// histories\n\t\tif g.artifact.Ref != \"\" {\n\t\t\tcloneOpt.Depth = 1\n\t\t}\n\n\t\tr, err = git.PlainClone(cloneDir, false, cloneOpt)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to clone repository. err: %+v\", err)\n\t\t}\n\t}\n\treturn g.readFromRepository(r, cloneDir)\n}\n\nfunc isSymbolLink(filepath string) (bool, error) {\n\tfi, err := os.Lstat(path.Clean(filepath))\n\tif err != nil {\n\t\treturn false, err\n\t}\n\tif fi.Mode()&os.ModeSymlink != 0 {\n\t\treturn true, nil\n\t}\n\treturn false, nil\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage artifacts\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\n\t\"github.com/minio/minio-go/v7\"\n\t\"github.com/minio/minio-go/v7/pkg/credentials\"\n\n\t\"github.com/argoproj/argo-events/common/logging\"\n\tapicommon \"github.com/argoproj/argo-events/pkg/apis/common\"\n)\n\n// S3Reader implements the ArtifactReader interface and allows reading artifacts from S3 compatible API store\ntype S3Reader struct {\n\tclient *minio.Client\n\ts3     *apicommon.S3Artifact\n\tcreds  *Credentials\n}\n\n// NewS3Reader creates a new ArtifactReader for an S3 compatible store\nfunc NewS3Reader(s3 *apicommon.S3Artifact, creds *Credentials) (ArtifactReader, error) {\n\tclient, err := NewMinioClient(s3, *creds)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &S3Reader{\n\t\tclient: client,\n\t\ts3:     s3,\n\t\tcreds:  creds,\n\t}, nil\n}\n\nfunc (reader *S3Reader) Read() ([]byte, error) {\n\tlog := logging.NewArgoEventsLogger()\n\tlog.Debugf(\"reading s3Artifact from %s/%s\", reader.s3.Bucket.Name, reader.s3.Bucket.Key)\n\tobj, err := reader.client.GetObject(context.Background(), reader.s3.Bucket.Name, reader.s3.Bucket.Key, minio.GetObjectOptions{})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer func() {\n\t\tif err := obj.Close(); err != nil {\n\t\t\tfmt.Printf(\"failed to close object. err: %+v\", err)\n\t\t}\n\t}()\n\n\tb, err := ioutil.ReadAll(obj)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn b, nil\n}\n\n// NewMinioClient instantiates a new minio client object to access s3 compatible APIs\nfunc NewMinioClient(s3 *apicommon.S3Artifact, creds Credentials) (*minio.Client, error) {\n\tvar minioClient *minio.Client\n\tvar err error\n\tif s3.Region != \"\" {\n\t\tminioClient, err = minio.New(s3.Endpoint, &minio.Options{\n\t\t\tCreds: credentials.NewStaticV4(creds.accessKey, creds.secretKey, \"\"), Secure: !s3.Insecure, Region: s3.Region})\n\t} else {\n\t\tminioClient, err = minio.New(s3.Endpoint, &minio.Options{\n\t\t\tCreds: credentials.NewStaticV4(creds.accessKey, creds.secretKey, \"\"), Secure: !s3.Insecure})\n\t}\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn minioClient, nil\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage artifacts\n\nimport (\n\t\"context\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1\"\n\t\"github.com/stretchr/testify/assert\"\n\tapiv1 \"k8s.io/api/core/v1\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/client-go/kubernetes/fake\"\n)\n\ntype FakeWorkflowArtifactReader struct{}\n\nfunc (f *FakeWorkflowArtifactReader) Read() ([]byte, error) {\n\treturn []byte(workflowv1alpha1), nil\n}\n\nfunc TestFetchArtifact(t *testing.T) {\n\treader := &FakeWorkflowArtifactReader{}\n\tobj, err := FetchArtifact(reader)\n\tassert.Nil(t, err)\n\tassert.Equal(t, \"argoproj.io/v1alpha1\", obj.GetAPIVersion())\n\tassert.Equal(t, \"Workflow\", obj.GetKind())\n}\n\nfunc TestGetCredentials(t *testing.T) {\n\tfakeClient := fake.NewSimpleClientset()\n\n\tmySecretCredentials := &apiv1.Secret{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"test\",\n\t\t\tNamespace: \"testing\",\n\t\t},\n\t\tData: map[string][]byte{\"access\": []byte(\"token\"), \"secret\": []byte(\"value\")},\n\t}\n\t_, err := fakeClient.CoreV1().Secrets(\"testing\").Create(context.TODO(), mySecretCredentials, metav1.CreateOptions{})\n\tassert.Nil(t, err)\n\n\t// creds should be nil for unknown minio type\n\tunknownArtifact := &v1alpha1.ArtifactLocation{}\n\tcreds, err := GetCredentials(unknownArtifact)\n\tassert.Nil(t, creds)\n\tassert.Nil(t, err)\n}\n\nfunc TestGetArtifactReader(t *testing.T) {\n\t// test unknown failure\n\tlocation := &v1alpha1.ArtifactLocation{}\n\tcreds := &Credentials{\n\t\taccessKey: \"access\",\n\t\tsecretKey: \"secret\",\n\t}\n\t_, err := GetArtifactReader(location, creds)\n\tassert.NotNil(t, err)\n}\n\nfunc TestDecodeSensor(t *testing.T) {\n\tb, err := ioutil.ReadFile(\"../../examples/sensors/multi-trigger-sensor.yaml\")\n\tassert.Nil(t, err)\n\t_, err = decodeAndUnstructure(b)\n\tassert.Nil(t, err)\n}\n\nfunc TestDecodeWorkflow(t *testing.T) {\n\t_, err := decodeAndUnstructure([]byte(workflowv1alpha1))\n\tassert.Nil(t, err)\n}\n\nvar workflowv1alpha1 = `\napiVersion: argoproj.io/v1alpha1\nkind: Workflow\nmetadata:\n  generateName: hello-world-\nspec:\n  entrypoint: whalesay\n  templates:\n  - name: whalesay\n    container:\n      image: docker/whalesay:latest\n      command: [cowsay]\n      args: [\"hello world\"]\n`\n\nfunc TestDecodeDeploymentv1(t *testing.T) {\n\t_, err := decodeAndUnstructure([]byte(deploymentv1))\n\tassert.Nil(t, err)\n}\n\nvar deploymentv1 = `\n{\n\t\"apiVersion\": \"apps/v1\",\n\t\"kind\": \"Deployment\",\n\t\"metadata\": {\n\t  \"name\": \"nginx-deployment\",\n\t  \"labels\": {\n\t\t\"app\": \"nginx\"\n\t  }\n\t},\n\t\"spec\": {\n\t  \"replicas\": 3,\n\t  \"selector\": {\n\t\t\"matchLabels\": {\n\t\t  \"app\": \"nginx\"\n\t\t}\n\t  },\n\t  \"template\": {\n\t\t\"metadata\": {\n\t\t  \"labels\": {\n\t\t\t\"app\": \"nginx\"\n\t\t  }\n\t\t},\n\t\t\"spec\": {\n\t\t  \"containers\": [\n\t\t\t{\n\t\t\t  \"name\": \"nginx\",\n\t\t\t  \"image\": \"nginx:1.7.9\",\n\t\t\t  \"ports\": [\n\t\t\t\t{\n\t\t\t\t  \"containerPort\": 80\n\t\t\t\t}\n\t\t\t  ]\n\t\t\t}\n\t\t  ]\n\t\t}\n\t  }\n\t}\n  }\n`\n\nfunc TestDecodeJobv1(t *testing.T) {\n\t_, err := decodeAndUnstructure([]byte(jobv1))\n\tassert.Nil(t, err)\n}\n\nvar jobv1 = `\napiVersion: batch/v1\nkind: Job\nmetadata:\n  # Unique key of the Job instance\n  name: example-job\nspec:\n  template:\n    metadata:\n      name: example-job\n    spec:\n      containers:\n      - name: pi\n        image: perl\n        command: [\"perl\"]\n        args: [\"-Mbignum=bpi\", \"-wle\", \"print bpi(2000)\"]\n      # Do not restart containers after they exit\n      restartPolicy: Never\n`\n\nfunc TestDecodeUnsupported(t *testing.T) {\n\t_, err := decodeAndUnstructure([]byte(unsupportedType))\n\tassert.Nil(t, err)\n}\n\nvar unsupportedType = `\napiVersion: extensions/v1beta1\nkind: DaemonSet\nmetadata:\n  # Unique key of the DaemonSet instance\n  name: daemonset-example\nspec:\n  template:\n    metadata:\n      labels:\n        app: daemonset-example\n    spec:\n      containers:\n      # This container is run once on each Node in the cluster\n      - name: daemonset-example\n        image: ubuntu:trusty\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - >-\n          while [ true ]; do\n          echo \"DaemonSet running on $(hostname)\" ;\n          sleep 10 ;\n          done\n`\n\nfunc TestDecodeUnknown(t *testing.T) {\n\t_, err := decodeAndUnstructure([]byte(unsupportedType))\n\tassert.Nil(t, err, \"expected nil error but got\", err)\n}\n", "package artifacts\n\nimport (\n\t\"crypto/tls\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\n\t\"github.com/pkg/errors\"\n\n\t\"github.com/argoproj/argo-events/common/logging\"\n\t\"github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1\"\n)\n\n// URLReader implements the ArtifactReader interface for urls\ntype URLReader struct {\n\turlArtifact *v1alpha1.URLArtifact\n}\n\n// NewURLReader creates a new ArtifactReader for workflows at URL endpoints.\nfunc NewURLReader(urlArtifact *v1alpha1.URLArtifact) (ArtifactReader, error) {\n\tif urlArtifact == nil {\n\t\treturn nil, errors.New(\"URLArtifact cannot be empty\")\n\t}\n\treturn &URLReader{urlArtifact}, nil\n}\n\nfunc (reader *URLReader) Read() ([]byte, error) {\n\tlog := logging.NewArgoEventsLogger()\n\tlog.Debugf(\"reading urlArtifact from %s\", reader.urlArtifact.Path)\n\tinsecureSkipVerify := !reader.urlArtifact.VerifyCert\n\tclient := &http.Client{\n\t\tTransport: &http.Transport{\n\t\t\tTLSClientConfig: &tls.Config{InsecureSkipVerify: insecureSkipVerify},\n\t\t},\n\t}\n\tresp, err := client.Get(reader.urlArtifact.Path)\n\tif err != nil {\n\t\tlog.Warnf(\"failed to read url %s: %s\", reader.urlArtifact.Path, err)\n\t\treturn nil, err\n\t}\n\tdefer resp.Body.Close()\n\n\tif resp.StatusCode != http.StatusOK {\n\t\tlog.Warnf(\"failed to read %s. status code: %d\", reader.urlArtifact.Path, resp.StatusCode)\n\t\treturn nil, errors.Errorf(\"status code %v\", resp.StatusCode)\n\t}\n\n\tcontent, err := ioutil.ReadAll(resp.Body)\n\tif err != nil {\n\t\tlog.Warnf(\"failed to read url body for %s: %s\", reader.urlArtifact.Path, err)\n\t\treturn nil, err\n\t}\n\treturn content, nil\n}\n", "/*\nCopyright 2020 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\npackage argo_workflow\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"os/exec\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/pkg/errors\"\n\t\"go.uber.org/zap\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/apis/meta/v1/unstructured\"\n\t\"k8s.io/apimachinery/pkg/labels\"\n\t\"k8s.io/apimachinery/pkg/runtime/schema\"\n\t\"k8s.io/apimachinery/pkg/util/wait\"\n\t\"k8s.io/client-go/dynamic\"\n\t\"k8s.io/client-go/kubernetes\"\n\n\t\"github.com/argoproj/argo-events/common/logging\"\n\tapicommon \"github.com/argoproj/argo-events/pkg/apis/common\"\n\t\"github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1\"\n\t\"github.com/argoproj/argo-events/sensors/policy\"\n\t\"github.com/argoproj/argo-events/sensors/triggers\"\n)\n\n// ArgoWorkflowTrigger implements Trigger interface for Argo workflow\ntype ArgoWorkflowTrigger struct {\n\t// K8sClient is Kubernetes client\n\tK8sClient kubernetes.Interface\n\t// ArgoClient is Argo Workflow client\n\tDynamicClient dynamic.Interface\n\t// Sensor object\n\tSensor *v1alpha1.Sensor\n\t// Trigger definition\n\tTrigger *v1alpha1.Trigger\n\t// logger to log stuff\n\tLogger *zap.SugaredLogger\n\n\tnamespableDynamicClient dynamic.NamespaceableResourceInterface\n\tcmdRunner               func(cmd *exec.Cmd) error\n}\n\n// NewArgoWorkflowTrigger returns a new Argo workflow trigger\nfunc NewArgoWorkflowTrigger(k8sClient kubernetes.Interface, dynamicClient dynamic.Interface, sensor *v1alpha1.Sensor, trigger *v1alpha1.Trigger, logger *zap.SugaredLogger) *ArgoWorkflowTrigger {\n\treturn &ArgoWorkflowTrigger{\n\t\tK8sClient:     k8sClient,\n\t\tDynamicClient: dynamicClient,\n\t\tSensor:        sensor,\n\t\tTrigger:       trigger,\n\t\tLogger:        logger.With(logging.LabelTriggerType, apicommon.ArgoWorkflowTrigger),\n\t\tcmdRunner: func(cmd *exec.Cmd) error {\n\t\t\treturn cmd.Run()\n\t\t},\n\t}\n}\n\n// GetTriggerType returns the type of the trigger\nfunc (t *ArgoWorkflowTrigger) GetTriggerType() apicommon.TriggerType {\n\treturn apicommon.ArgoWorkflowTrigger\n}\n\n// FetchResource fetches the trigger resource from external source\nfunc (t *ArgoWorkflowTrigger) FetchResource(ctx context.Context) (interface{}, error) {\n\ttrigger := t.Trigger\n\treturn triggers.FetchKubernetesResource(trigger.Template.ArgoWorkflow.Source)\n}\n\n// ApplyResourceParameters applies parameters to the trigger resource\nfunc (t *ArgoWorkflowTrigger) ApplyResourceParameters(events map[string]*v1alpha1.Event, resource interface{}) (interface{}, error) {\n\tobj, ok := resource.(*unstructured.Unstructured)\n\tif !ok {\n\t\treturn nil, errors.New(\"failed to interpret the trigger resource\")\n\t}\n\tif err := triggers.ApplyResourceParameters(events, t.Trigger.Template.ArgoWorkflow.Parameters, obj); err != nil {\n\t\treturn nil, err\n\t}\n\treturn obj, nil\n}\n\n// Execute executes the trigger\nfunc (t *ArgoWorkflowTrigger) Execute(ctx context.Context, events map[string]*v1alpha1.Event, resource interface{}) (interface{}, error) {\n\ttrigger := t.Trigger\n\n\top := v1alpha1.Submit\n\tif trigger.Template.ArgoWorkflow.Operation != \"\" {\n\t\top = trigger.Template.ArgoWorkflow.Operation\n\t}\n\n\tobj, ok := resource.(*unstructured.Unstructured)\n\tif !ok {\n\t\treturn nil, errors.New(\"failed to interpret the trigger resource\")\n\t}\n\n\tname := obj.GetName()\n\tif name == \"\" {\n\t\tif op != v1alpha1.Submit {\n\t\t\treturn nil, errors.Errorf(\"failed to execute the workflow %v operation, no name is given\", op)\n\t\t}\n\t\tif obj.GetGenerateName() == \"\" {\n\t\t\treturn nil, errors.New(\"failed to trigger the workflow, neither name nor generateName is given\")\n\t\t}\n\t}\n\n\tsubmittedWFLabels := make(map[string]string)\n\tif op == v1alpha1.Submit {\n\t\tsubmittedWFLabels[\"events.argoproj.io/sensor\"] = t.Sensor.Name\n\t\tsubmittedWFLabels[\"events.argoproj.io/trigger\"] = trigger.Template.Name\n\t\tsubmittedWFLabels[\"events.argoproj.io/action-timestamp\"] = strconv.Itoa(int(time.Now().UnixNano() / int64(time.Millisecond)))\n\t}\n\n\tnamespace := obj.GetNamespace()\n\tif namespace == \"\" {\n\t\tnamespace = t.Sensor.Namespace\n\t}\n\n\tvar cmd *exec.Cmd\n\n\tswitch op {\n\tcase v1alpha1.Submit:\n\t\tfile, err := ioutil.TempFile(\"\", fmt.Sprintf(\"%s%s\", name, obj.GetGenerateName()))\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"failed to create a temp file for the workflow %s\", obj.GetName())\n\t\t}\n\t\tdefer os.Remove(file.Name())\n\n\t\t// Add labels\n\t\tlabels := obj.GetLabels()\n\t\tif labels == nil {\n\t\t\tlabels = make(map[string]string)\n\t\t}\n\t\tfor k, v := range submittedWFLabels {\n\t\t\tlabels[k] = v\n\t\t}\n\t\tobj.SetLabels(labels)\n\n\t\tjObj, err := obj.MarshalJSON()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tif _, err := file.Write(jObj); err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"failed to write workflow json %s to the temp file %s\", name, file.Name())\n\t\t}\n\t\tcmd = exec.Command(\"argo\", \"-n\", namespace, \"submit\", file.Name())\n\tcase v1alpha1.SubmitFrom:\n\t\twf := obj.GetKind()\n\t\tswitch strings.ToLower(wf) {\n\t\tcase \"cronworkflow\":\n\t\t\twf = \"cronwf\"\n\t\tcase \"workflow\":\n\t\t\twf = \"wf\"\n\t\tdefault:\n\t\t\treturn nil, errors.Errorf(\"invalid kind %s\", wf)\n\t\t}\n\t\tfromArg := fmt.Sprintf(\"%s/%s\", wf, name)\n\t\tcmd = exec.Command(\"argo\", \"-n\", namespace, \"submit\", \"--from\", fromArg)\n\tcase v1alpha1.Resubmit:\n\t\tcmd = exec.Command(\"argo\", \"-n\", namespace, \"resubmit\", name)\n\tcase v1alpha1.Resume:\n\t\tcmd = exec.Command(\"argo\", \"-n\", namespace, \"resume\", name)\n\tcase v1alpha1.Retry:\n\t\tcmd = exec.Command(\"argo\", \"-n\", namespace, \"retry\", name)\n\tcase v1alpha1.Suspend:\n\t\tcmd = exec.Command(\"argo\", \"-n\", namespace, \"suspend\", name)\n\tcase v1alpha1.Terminate:\n\t\tcmd = exec.Command(\"argo\", \"-n\", namespace, \"terminate\", name)\n\tcase v1alpha1.Stop:\n\t\tcmd = exec.Command(\"argo\", \"-n\", namespace, \"stop\", name)\n\tdefault:\n\t\treturn nil, errors.Errorf(\"unknown operation type %s\", string(op))\n\t}\n\n\tcmd.Stdout = os.Stdout\n\tcmd.Stderr = os.Stderr\n\tcmd.Args = append(cmd.Args, trigger.Template.ArgoWorkflow.Args...)\n\tif err := t.cmdRunner(cmd); err != nil {\n\t\treturn nil, errors.Wrapf(err, \"failed to execute %s command for workflow %s\", string(op), name)\n\t}\n\n\tt.namespableDynamicClient = t.DynamicClient.Resource(schema.GroupVersionResource{\n\t\tGroup:    \"argoproj.io\",\n\t\tVersion:  \"v1alpha1\",\n\t\tResource: \"workflows\",\n\t})\n\n\tif op != v1alpha1.Submit {\n\t\treturn t.namespableDynamicClient.Namespace(namespace).Get(ctx, name, metav1.GetOptions{})\n\t}\n\tl, err := t.namespableDynamicClient.Namespace(namespace).List(ctx, metav1.ListOptions{LabelSelector: labels.SelectorFromSet(submittedWFLabels).String()})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(l.Items) == 0 {\n\t\treturn nil, errors.New(\"failed to list created workflows for unknown reason\")\n\t}\n\treturn l.Items[0], nil\n}\n\n// ApplyPolicy applies the policy on the trigger\nfunc (t *ArgoWorkflowTrigger) ApplyPolicy(ctx context.Context, resource interface{}) error {\n\ttrigger := t.Trigger\n\n\tif trigger.Policy == nil || trigger.Policy.K8s == nil || trigger.Policy.K8s.Labels == nil {\n\t\treturn nil\n\t}\n\n\tobj, ok := resource.(*unstructured.Unstructured)\n\tif !ok {\n\t\treturn errors.New(\"failed to interpret the trigger resource\")\n\t}\n\n\tp := policy.NewResourceLabels(trigger, t.namespableDynamicClient, obj)\n\tif p == nil {\n\t\treturn nil\n\t}\n\n\terr := p.ApplyPolicy(ctx)\n\tif err != nil {\n\t\tswitch err {\n\t\tcase wait.ErrWaitTimeout:\n\t\t\tif trigger.Policy.K8s.ErrorOnBackoffTimeout {\n\t\t\t\treturn errors.Errorf(\"failed to determine status of the triggered resource. setting trigger state as failed\")\n\t\t\t}\n\t\t\treturn nil\n\t\tdefault:\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n", "package fixtures\n\nimport (\n\t\"io/ioutil\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/client-go/kubernetes\"\n\t\"k8s.io/client-go/rest\"\n\t\"sigs.k8s.io/yaml\"\n\n\teventbusv1alpha1 \"github.com/argoproj/argo-events/pkg/apis/eventbus/v1alpha1\"\n\teventsourcev1alpha1 \"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\tsensorv1alpha1 \"github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1\"\n\teventbuspkg \"github.com/argoproj/argo-events/pkg/client/eventbus/clientset/versioned/typed/eventbus/v1alpha1\"\n\teventsourcepkg \"github.com/argoproj/argo-events/pkg/client/eventsource/clientset/versioned/typed/eventsource/v1alpha1\"\n\tsensorpkg \"github.com/argoproj/argo-events/pkg/client/sensor/clientset/versioned/typed/sensor/v1alpha1\"\n)\n\ntype Given struct {\n\tt                 *testing.T\n\teventBusClient    eventbuspkg.EventBusInterface\n\teventSourceClient eventsourcepkg.EventSourceInterface\n\tsensorClient      sensorpkg.SensorInterface\n\teventBus          *eventbusv1alpha1.EventBus\n\teventSource       *eventsourcev1alpha1.EventSource\n\tsensor            *sensorv1alpha1.Sensor\n\trestConfig        *rest.Config\n\tkubeClient        kubernetes.Interface\n}\n\n// creates an EventBus based on the parameter, this may be:\n//\n// 1. A file name if it starts with \"@\"\n// 2. Raw YAML.\nfunc (g *Given) EventBus(text string) *Given {\n\tg.t.Helper()\n\tg.eventBus = &eventbusv1alpha1.EventBus{}\n\tg.readResource(text, g.eventBus)\n\tl := g.eventBus.GetLabels()\n\tif l == nil {\n\t\tl = map[string]string{}\n\t}\n\tl[Label] = LabelValue\n\tg.eventBus.SetLabels(l)\n\tg.eventBus.SetName(EventBusName)\n\treturn g\n}\n\n// creates an EventSource based on the parameter, this may be:\n//\n// 1. A file name if it starts with \"@\"\n// 2. Raw YAML.\nfunc (g *Given) EventSource(text string) *Given {\n\tg.t.Helper()\n\tg.eventSource = &eventsourcev1alpha1.EventSource{}\n\tg.readResource(text, g.eventSource)\n\tl := g.eventSource.GetLabels()\n\tif l == nil {\n\t\tl = map[string]string{}\n\t}\n\tl[Label] = LabelValue\n\tg.eventSource.SetLabels(l)\n\tg.eventSource.Spec.EventBusName = EventBusName\n\treturn g\n}\n\n// creates a Sensor based on the parameter, this may be:\n//\n// 1. A file name if it starts with \"@\"\n// 2. Raw YAML.\nfunc (g *Given) Sensor(text string) *Given {\n\tg.t.Helper()\n\tg.sensor = &sensorv1alpha1.Sensor{}\n\tg.readResource(text, g.sensor)\n\tl := g.sensor.GetLabels()\n\tif l == nil {\n\t\tl = map[string]string{}\n\t}\n\tl[Label] = LabelValue\n\tg.sensor.SetLabels(l)\n\tg.sensor.Spec.EventBusName = EventBusName\n\treturn g\n}\n\nfunc (g *Given) readResource(text string, v metav1.Object) {\n\tg.t.Helper()\n\tvar file string\n\tif strings.HasPrefix(text, \"@\") {\n\t\tfile = strings.TrimPrefix(text, \"@\")\n\t} else {\n\t\tf, err := ioutil.TempFile(\"\", \"argo-events-e2e\")\n\t\tif err != nil {\n\t\t\tg.t.Fatal(err)\n\t\t}\n\t\t_, err = f.Write([]byte(text))\n\t\tif err != nil {\n\t\t\tg.t.Fatal(err)\n\t\t}\n\t\terr = f.Close()\n\t\tif err != nil {\n\t\t\tg.t.Fatal(err)\n\t\t}\n\t\tfile = f.Name()\n\t}\n\n\tf, err := ioutil.ReadFile(file)\n\tif err != nil {\n\t\tg.t.Fatal(err)\n\t}\n\terr = yaml.Unmarshal(f, v)\n\tif err != nil {\n\t\tg.t.Fatal(err)\n\t}\n}\n\nfunc (g *Given) When() *When {\n\treturn &When{\n\t\tt:                 g.t,\n\t\teventBusClient:    g.eventBusClient,\n\t\teventSourceClient: g.eventSourceClient,\n\t\tsensorClient:      g.sensorClient,\n\t\teventBus:          g.eventBus,\n\t\teventSource:       g.eventSource,\n\t\tsensor:            g.sensor,\n\t\trestConfig:        g.restConfig,\n\t\tkubeClient:        g.kubeClient,\n\t}\n}\n\nvar OutputRegexp = func(rx string) func(t *testing.T, output string, err error) {\n\treturn func(t *testing.T, output string, err error) {\n\t\tt.Helper()\n\t\tif assert.NoError(t, err, output) {\n\t\t\tassert.Regexp(t, rx, output)\n\t\t}\n\t}\n}\n", "package main\n\nimport (\n\t\"bufio\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"runtime\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/spf13/cobra\"\n\tcorev1 \"k8s.io/api/core/v1\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/runtime/schema\"\n\t\"k8s.io/client-go/dynamic\"\n\t\"k8s.io/client-go/kubernetes\"\n\t_ \"k8s.io/client-go/plugin/pkg/client/auth\"\n\t\"k8s.io/client-go/rest\"\n\t\"k8s.io/client-go/tools/clientcmd\"\n\t\"sigs.k8s.io/controller-runtime/pkg/manager/signals\"\n\t\"sigs.k8s.io/yaml\"\n\n\t\"github.com/argoproj/argo-events/pkg/apis/eventbus\"\n\teventbusv1alpha1 \"github.com/argoproj/argo-events/pkg/apis/eventbus/v1alpha1\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource\"\n\teventsourcev1alpha1 \"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/argoproj/argo-events/pkg/apis/sensor\"\n\tsensorv1alpha1 \"github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1\"\n\teventbusversiond \"github.com/argoproj/argo-events/pkg/client/eventbus/clientset/versioned\"\n\teventbuspkg \"github.com/argoproj/argo-events/pkg/client/eventbus/clientset/versioned/typed/eventbus/v1alpha1\"\n\teventsourceversiond \"github.com/argoproj/argo-events/pkg/client/eventsource/clientset/versioned\"\n\teventsourcepkg \"github.com/argoproj/argo-events/pkg/client/eventsource/clientset/versioned/typed/eventsource/v1alpha1\"\n\tsensorversiond \"github.com/argoproj/argo-events/pkg/client/sensor/clientset/versioned\"\n\tsensorpkg \"github.com/argoproj/argo-events/pkg/client/sensor/clientset/versioned/typed/sensor/v1alpha1\"\n\ttestutil \"github.com/argoproj/argo-events/test/util\"\n)\n\nconst (\n\teventBusName   = \"stress-testing\"\n\tdefaultTimeout = 60 * time.Second\n\n\tSuccess = \"success\"\n\tFailure = \"failure\"\n\n\tFirst = \"first\"\n\tLast  = \"last\"\n\n\tEventNameKey   = \"eventName\"\n\tTriggerNameKey = \"triggerName\"\n\n\tStressTestingLabel      = \"argo-events-stress\"\n\tStressTestingLabelValue = \"true\"\n\n\tlogEventSourceStarted      = \"Eventing server started.\"\n\tlogSensorStarted           = \"Sensor started.\"\n\tlogTriggerActionSuccessful = \"successfully processed trigger\"\n\tlogTriggerActionFailed     = \"failed to execute a trigger\"\n\tlogEventSuccessful         = \"succeeded to publish an event\"\n\tlogEventFailed             = \"failed to publish an event\"\n)\n\ntype TestingEventSource string\n\n// possible values of TestingEventSource\nconst (\n\tUnsupportedEventsource TestingEventSource = \"unsupported\"\n\tWebhookEventSource     TestingEventSource = \"webhook\"\n\tSQSEventSource         TestingEventSource = \"sqs\"\n\tSNSEventSource         TestingEventSource = \"sns\"\n\tKafkaEventSource       TestingEventSource = \"kafka\"\n\tNATSEventSource        TestingEventSource = \"nats\"\n\tRedisEventSource       TestingEventSource = \"redis\"\n)\n\ntype EventBusType string\n\n// possible value of EventBus type\nconst (\n\tUnsupportedEventBusType EventBusType = \"unsupported\"\n\tSTANEventBus            EventBusType = \"stan\"\n\tJetstreamEventBus       EventBusType = \"jetstream\"\n)\n\ntype TestingTrigger string\n\n// possible values of TestingTrigger\nconst (\n\tUnsupportedTrigger TestingTrigger = \"unsupported\"\n\tWorkflowTrigger    TestingTrigger = \"workflow\"\n\tLogTrigger         TestingTrigger = \"log\"\n)\n\nvar (\n\tbackground = metav1.DeletePropagationBackground\n)\n\ntype options struct {\n\tnamespace          string\n\ttestingEventSource TestingEventSource\n\ttestingTrigger     TestingTrigger\n\teventBusType       EventBusType\n\tesName             string\n\tsensorName         string\n\t// Inactive time before exiting\n\tidleTimeout time.Duration\n\thardTimeout *time.Duration\n\tnoCleanUp   bool\n\n\tkubeClient        kubernetes.Interface\n\teventBusClient    eventbuspkg.EventBusInterface\n\teventSourceClient eventsourcepkg.EventSourceInterface\n\tsensorClient      sensorpkg.SensorInterface\n\trestConfig        *rest.Config\n}\n\nfunc NewOptions(testingEventSource TestingEventSource, testingTrigger TestingTrigger, eventBusType EventBusType, esName, sensorName string, idleTimeout time.Duration, noCleanUp bool) (*options, error) {\n\tloadingRules := clientcmd.NewDefaultClientConfigLoadingRules()\n\tconfigOverrides := &clientcmd.ConfigOverrides{}\n\tkubeConfig := clientcmd.NewNonInteractiveDeferredLoadingClientConfig(loadingRules, configOverrides)\n\tconfig, err := kubeConfig.ClientConfig()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnamespace, _, _ := kubeConfig.Namespace()\n\tkubeClient, err := kubernetes.NewForConfig(config)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\teventBusClient := eventbusversiond.NewForConfigOrDie(config).ArgoprojV1alpha1().EventBus(namespace)\n\teventSourceClient := eventsourceversiond.NewForConfigOrDie(config).ArgoprojV1alpha1().EventSources(namespace)\n\tsensorClient := sensorversiond.NewForConfigOrDie(config).ArgoprojV1alpha1().Sensors(namespace)\n\treturn &options{\n\t\tnamespace:          namespace,\n\t\ttestingEventSource: testingEventSource,\n\t\ttestingTrigger:     testingTrigger,\n\t\teventBusType:       eventBusType,\n\t\tesName:             esName,\n\t\tsensorName:         sensorName,\n\t\tkubeClient:         kubeClient,\n\t\teventBusClient:     eventBusClient,\n\t\teventSourceClient:  eventSourceClient,\n\t\trestConfig:         config,\n\t\tsensorClient:       sensorClient,\n\t\tidleTimeout:        idleTimeout,\n\t\tnoCleanUp:          noCleanUp,\n\t}, nil\n}\n\nfunc (o *options) createEventBus(ctx context.Context) (*eventbusv1alpha1.EventBus, error) {\n\tfmt.Printf(\"------- Creating %v EventBus -------\\n\", o.eventBusType)\n\teb := &eventbusv1alpha1.EventBus{}\n\tif err := readResource(fmt.Sprintf(\"@testdata/eventbus/%v.yaml\", o.eventBusType), eb); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to read %v event bus yaml file: %w\", o.eventBusType, err)\n\t}\n\tl := eb.GetLabels()\n\tif l == nil {\n\t\tl = map[string]string{}\n\t}\n\tl[StressTestingLabel] = StressTestingLabelValue\n\teb.SetLabels(l)\n\teb.Name = eventBusName\n\tresult, err := o.eventBusClient.Create(ctx, eb, metav1.CreateOptions{})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create event bus: %w\", err)\n\t}\n\tif err := testutil.WaitForEventBusReady(ctx, o.eventBusClient, eb.Name, defaultTimeout); err != nil {\n\t\treturn nil, fmt.Errorf(\"expected to see event bus ready: %w\", err)\n\t}\n\tif err := testutil.WaitForEventBusStatefulSetReady(ctx, o.kubeClient, o.namespace, eb.Name, defaultTimeout); err != nil {\n\t\treturn nil, fmt.Errorf(\"expected to see event bus statefulset ready: %w\", err)\n\t}\n\treturn result, nil\n}\n\nfunc (o *options) createEventSource(ctx context.Context) (*eventsourcev1alpha1.EventSource, error) {\n\tfmt.Printf(\"\\n------- Creating %v EventSource -------\\n\", o.testingEventSource)\n\tes := &eventsourcev1alpha1.EventSource{}\n\tfile := fmt.Sprintf(\"@testdata/eventsources/%v.yaml\", o.testingEventSource)\n\tif err := readResource(file, es); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to read %v event source yaml file: %w\", o.testingEventSource, err)\n\t}\n\tl := es.GetLabels()\n\tif l == nil {\n\t\tl = map[string]string{}\n\t}\n\tl[StressTestingLabel] = StressTestingLabelValue\n\tes.SetLabels(l)\n\tes.Spec.EventBusName = eventBusName\n\tresult, err := o.eventSourceClient.Create(ctx, es, metav1.CreateOptions{})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create event source: %w\", err)\n\t}\n\tif err := testutil.WaitForEventSourceReady(ctx, o.eventSourceClient, es.Name, defaultTimeout); err != nil {\n\t\treturn nil, fmt.Errorf(\"expected to see event source ready: %w\", err)\n\t}\n\tif err := testutil.WaitForEventSourceDeploymentReady(ctx, o.kubeClient, o.namespace, es.Name, defaultTimeout); err != nil {\n\t\treturn nil, fmt.Errorf(\"expected to see event source deployment and pod ready: %w\", err)\n\t}\n\tcontains, err := testutil.EventSourcePodLogContains(ctx, o.kubeClient, o.namespace, es.Name, logEventSourceStarted)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"expected to see event source pod contains something: %w\", err)\n\t}\n\tif !contains {\n\t\treturn nil, fmt.Errorf(\"EventSource Pod does look good, it might have started failed\")\n\t}\n\treturn result, nil\n}\n\nfunc (o *options) createSensor(ctx context.Context) (*sensorv1alpha1.Sensor, error) {\n\tfmt.Printf(\"\\n------- Creating %v Sensor -------\\n\", o.testingTrigger)\n\tsensor := &sensorv1alpha1.Sensor{}\n\tfile := fmt.Sprintf(\"@testdata/sensors/%v.yaml\", o.testingTrigger)\n\tif err := readResource(file, sensor); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to read %v sensor yaml file: %w\", o.testingTrigger, err)\n\t}\n\tl := sensor.GetLabels()\n\tif l == nil {\n\t\tl = map[string]string{}\n\t}\n\tl[StressTestingLabel] = StressTestingLabelValue\n\tsensor.SetLabels(l)\n\tsensor.Spec.EventBusName = eventBusName\n\tresult, err := o.sensorClient.Create(ctx, sensor, metav1.CreateOptions{})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create sensor: %w\", err)\n\t}\n\tif err := testutil.WaitForSensorReady(ctx, o.sensorClient, sensor.Name, defaultTimeout); err != nil {\n\t\treturn nil, fmt.Errorf(\"expected to see sensor ready: %w\", err)\n\t}\n\tif err := testutil.WaitForSensorDeploymentReady(ctx, o.kubeClient, o.namespace, sensor.Name, defaultTimeout); err != nil {\n\t\treturn nil, fmt.Errorf(\"expected to see sensor deployment and pod ready: %w\", err)\n\t}\n\tcontains, err := testutil.SensorPodLogContains(ctx, o.kubeClient, o.namespace, sensor.Name, logSensorStarted)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"expected to see sensor pod contains something: %w\", err)\n\t}\n\tif !contains {\n\t\treturn nil, fmt.Errorf(\"Sensor Pod does look good, it might have started failed\")\n\t}\n\treturn result, nil\n}\n\nfunc (o *options) getEventSourcePodNames(ctx context.Context, eventSourceName string) ([]string, error) {\n\tlabelSelector := fmt.Sprintf(\"controller=eventsource-controller,eventsource-name=%s\", eventSourceName)\n\tesPodList, err := o.kubeClient.CoreV1().Pods(o.namespace).List(ctx, metav1.ListOptions{LabelSelector: labelSelector, FieldSelector: \"status.phase=Running\"})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tresults := []string{}\n\tfor _, i := range esPodList.Items {\n\t\tresults = append(results, i.Name)\n\t}\n\treturn results, nil\n}\n\nfunc (o *options) getSensorPodNames(ctx context.Context, sensorName string) ([]string, error) {\n\tlabelSelector := fmt.Sprintf(\"controller=sensor-controller,sensor-name=%s\", sensorName)\n\tsPodList, err := o.kubeClient.CoreV1().Pods(o.namespace).List(ctx, metav1.ListOptions{LabelSelector: labelSelector, FieldSelector: \"status.phase=Running\"})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tresults := []string{}\n\tfor _, i := range sPodList.Items {\n\t\tresults = append(results, i.Name)\n\t}\n\treturn results, nil\n}\n\nfunc (o *options) runTesting(ctx context.Context, eventSourceName, sensorName string) error {\n\tesPodNames, err := o.getEventSourcePodNames(ctx, eventSourceName)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to get event source pod names: %v\", err)\n\t}\n\tif len(esPodNames) == 0 {\n\t\treturn fmt.Errorf(\"no pod found for event source %s\", eventSourceName)\n\t}\n\tsensorPodNames, err := o.getSensorPodNames(ctx, sensorName)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to get sensor pod names: %v\", err)\n\t}\n\tif len(sensorPodNames) == 0 {\n\t\treturn fmt.Errorf(\"no pod found for sensor %s\", sensorName)\n\t}\n\n\tsuccessActionReg := regexp.MustCompile(logTriggerActionSuccessful)\n\tfailureActionReg := regexp.MustCompile(logTriggerActionFailed)\n\tsuccessEventReg := regexp.MustCompile(logEventSuccessful)\n\tfailureEventReg := regexp.MustCompile(logEventFailed)\n\n\tfmt.Printf(`\n*********************************************************\nThe application will automatically exit:\n  - If there's no active events and actions in %v.\n`, o.idleTimeout)\n\tif o.hardTimeout != nil {\n\t\tfmt.Printf(\"  - In %v after it starts.\\n\", *o.hardTimeout)\n\t}\n\tfmt.Printf(`\nOr you can terminate it any time by Ctrl + C.\n*********************************************************\n\n`)\n\n\tesMap := map[string]int64{}\n\tesTimeMap := map[string]time.Time{}\n\n\tsensorMap := map[string]int64{}\n\tsensorTimeMap := map[string]time.Time{}\n\n\tvar esLock = &sync.RWMutex{}\n\tvar sensorLock = &sync.RWMutex{}\n\n\tstartTime := time.Now()\n\n\twg := &sync.WaitGroup{}\n\tfor _, sensorPodName := range sensorPodNames {\n\t\twg.Add(1)\n\t\tgo func(podName string) {\n\t\t\tdefer wg.Done()\n\t\t\tfmt.Printf(\"Started watching Sensor Pod %s ...\\n\", podName)\n\t\t\tstream, err := o.kubeClient.CoreV1().Pods(o.namespace).GetLogs(podName, &corev1.PodLogOptions{Follow: true}).Stream(ctx)\n\t\t\tif err != nil {\n\t\t\t\tfmt.Printf(\"failed to acquire sensor pod %s log stream: %v\", podName, err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tdefer func() { _ = stream.Close() }()\n\n\t\t\tsCh := make(chan string)\n\t\t\tgo func(dataCh chan string) {\n\t\t\t\ts := bufio.NewScanner(stream)\n\t\t\t\tfor {\n\t\t\t\t\tif !s.Scan() {\n\t\t\t\t\t\tfmt.Printf(\"Can not read: %v\\n\", s.Err())\n\t\t\t\t\t\tclose(dataCh)\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tdata := s.Bytes()\n\t\t\t\t\ttriggerName := getLogValue(data, startTime, TriggerNameKey)\n\t\t\t\t\tif triggerName == \"\" {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif successActionReg.Match(data) {\n\t\t\t\t\t\tdataCh <- triggerName + \"/\" + Success\n\t\t\t\t\t} else if failureActionReg.Match(data) {\n\t\t\t\t\t\tdataCh <- triggerName + \"/\" + Failure\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}(sCh)\n\n\t\t\tfor {\n\t\t\t\tif o.hardTimeout != nil && time.Since(startTime).Seconds() > o.hardTimeout.Seconds() {\n\t\t\t\t\tfmt.Printf(\"Exited Sensor Pod %s due to the hard timeout %v\\n\", podName, *o.hardTimeout)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\ttimeout := 5 * 60 * time.Second\n\t\t\t\tlastActionTime := startTime\n\t\t\t\tsensorLock.RLock()\n\t\t\t\tif len(sensorMap) > 0 && len(sensorTimeMap) > 0 {\n\t\t\t\t\ttimeout = o.idleTimeout\n\t\t\t\t\tfor _, v := range sensorTimeMap {\n\t\t\t\t\t\tif v.After(lastActionTime) {\n\t\t\t\t\t\t\tlastActionTime = v\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tsensorLock.RUnlock()\n\n\t\t\t\tif time.Since(lastActionTime).Seconds() > timeout.Seconds() {\n\t\t\t\t\tfmt.Printf(\"Exited Sensor Pod %s due to no actions in the last %v\\n\", podName, o.idleTimeout)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase data, ok := <-sCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\t// e.g. triggerName/success\n\t\t\t\t\tt := strings.Split(data, \"/\")\n\t\t\t\t\tsensorLock.Lock()\n\t\t\t\t\tif _, ok := sensorMap[data]; !ok {\n\t\t\t\t\t\tsensorMap[t[0]+\"/\"+Success] = 0\n\t\t\t\t\t\tsensorMap[t[0]+\"/\"+Failure] = 0\n\t\t\t\t\t}\n\t\t\t\t\tif t[1] == Success {\n\t\t\t\t\t\tsensorMap[t[0]+\"/\"+Success]++\n\t\t\t\t\t} else {\n\t\t\t\t\t\tsensorMap[t[0]+\"/\"+Failure]++\n\t\t\t\t\t}\n\t\t\t\t\tif sensorMap[t[0]+\"/\"+Success]+sensorMap[t[0]+\"/\"+Failure] == 1 {\n\t\t\t\t\t\tsensorTimeMap[t[0]+\"/\"+First] = time.Now()\n\t\t\t\t\t}\n\t\t\t\t\tsensorTimeMap[t[0]+\"/\"+Last] = time.Now()\n\t\t\t\t\tsensorLock.Unlock()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(sensorPodName)\n\t}\n\n\tfor _, esPodName := range esPodNames {\n\t\twg.Add(1)\n\t\tgo func(podName string) {\n\t\t\tdefer wg.Done()\n\t\t\tfmt.Printf(\"Started watching EventSource Pod %s ...\\n\", podName)\n\t\t\tstream, err := o.kubeClient.CoreV1().Pods(o.namespace).GetLogs(podName, &corev1.PodLogOptions{Follow: true}).Stream(ctx)\n\t\t\tif err != nil {\n\t\t\t\tfmt.Printf(\"failed to acquire event source pod %s log stream: %v\", podName, err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tdefer func() { _ = stream.Close() }()\n\n\t\t\tsCh := make(chan string)\n\t\t\tgo func(dataCh chan string) {\n\t\t\t\ts := bufio.NewScanner(stream)\n\t\t\t\tfor {\n\t\t\t\t\tif !s.Scan() {\n\t\t\t\t\t\tfmt.Printf(\"Can not read: %v\\n\", s.Err())\n\t\t\t\t\t\tclose(dataCh)\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tdata := s.Bytes()\n\t\t\t\t\teventName := getLogValue(data, startTime, EventNameKey)\n\t\t\t\t\tif eventName == \"\" {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif successEventReg.Match(data) {\n\t\t\t\t\t\tdataCh <- eventName + \"/\" + Success\n\t\t\t\t\t} else if failureEventReg.Match(data) {\n\t\t\t\t\t\tdataCh <- eventName + \"/\" + Failure\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}(sCh)\n\n\t\t\tfor {\n\t\t\t\tif o.hardTimeout != nil && time.Since(startTime).Seconds() > o.hardTimeout.Seconds() {\n\t\t\t\t\tfmt.Printf(\"Exited EventSource Pod %s due to the hard timeout %v\\n\", podName, *o.hardTimeout)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\ttimeout := 5 * 60 * time.Second\n\t\t\t\tlastEventTime := startTime\n\n\t\t\t\tesLock.RLock()\n\t\t\t\tif len(esMap) > 0 && len(esTimeMap) > 0 {\n\t\t\t\t\ttimeout = o.idleTimeout\n\t\t\t\t\tfor _, v := range esTimeMap {\n\t\t\t\t\t\tif v.After(lastEventTime) {\n\t\t\t\t\t\t\tlastEventTime = v\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tesLock.RUnlock()\n\t\t\t\tif time.Since(lastEventTime).Seconds() > timeout.Seconds() {\n\t\t\t\t\tfmt.Printf(\"Exited EventSource Pod %s due to no active events in the last %v\\n\", podName, o.idleTimeout)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase data, ok := <-sCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\t// e.g. eventName/success\n\t\t\t\t\tt := strings.Split(data, \"/\")\n\t\t\t\t\tesLock.Lock()\n\t\t\t\t\tif _, ok := esMap[data]; !ok {\n\t\t\t\t\t\tesMap[t[0]+\"/\"+Success] = 0\n\t\t\t\t\t\tesMap[t[0]+\"/\"+Failure] = 0\n\t\t\t\t\t}\n\t\t\t\t\tif t[1] == Success {\n\t\t\t\t\t\tesMap[t[0]+\"/\"+Success]++\n\t\t\t\t\t} else {\n\t\t\t\t\t\tesMap[t[0]+\"/\"+Failure]++\n\t\t\t\t\t}\n\t\t\t\t\tif esMap[t[0]+\"/\"+Success]+esMap[t[0]+\"/\"+Failure] == 1 {\n\t\t\t\t\t\tesTimeMap[t[0]+\"/\"+First] = time.Now()\n\t\t\t\t\t}\n\t\t\t\t\tesTimeMap[t[0]+\"/\"+Last] = time.Now()\n\t\t\t\t\tesLock.Unlock()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(esPodName)\n\t}\n\n\twg.Wait()\n\n\ttime.Sleep(3 * time.Second)\n\teventNames := []string{}\n\tfor k := range esMap {\n\t\tt := strings.Split(k, \"/\")\n\t\tif t[1] == Success {\n\t\t\teventNames = append(eventNames, t[0])\n\t\t}\n\t}\n\ttriggerNames := []string{}\n\tfor k := range sensorMap {\n\t\tt := strings.Split(k, \"/\")\n\t\tif t[1] == Success {\n\t\t\ttriggerNames = append(triggerNames, t[0])\n\t\t}\n\t}\n\tfmt.Printf(\"\\n++++++++++++++++++++++++ Events Summary +++++++++++++++++++++++\\n\")\n\tif len(eventNames) == 0 {\n\t\tfmt.Println(\"No events.\")\n\t} else {\n\t\tfor _, eventName := range eventNames {\n\t\t\tfmt.Printf(\"Event Name                    : %s\\n\", eventName)\n\t\t\tfmt.Printf(\"Total processed events        : %d\\n\", esMap[eventName+\"/\"+Success]+esMap[eventName+\"/\"+Failure])\n\t\t\tfmt.Printf(\"Events sent successful        : %d\\n\", esMap[eventName+\"/\"+Success])\n\t\t\tfmt.Printf(\"Events sent failed            : %d\\n\", esMap[eventName+\"/\"+Failure])\n\t\t\tfmt.Printf(\"First event sent at           : %v\\n\", esTimeMap[eventName+\"/\"+First])\n\t\t\tfmt.Printf(\"Last event sent at            : %v\\n\", esTimeMap[eventName+\"/\"+Last])\n\t\t\tfmt.Printf(\"Total time taken              : %v\\n\", esTimeMap[eventName+\"/\"+Last].Sub(esTimeMap[eventName+\"/\"+First]))\n\t\t\tfmt.Println(\"--\")\n\t\t}\n\t}\n\n\tfmt.Printf(\"\\n+++++++++++++++++++++++ Actions Summary +++++++++++++++++++++++\\n\")\n\tif len(triggerNames) == 0 {\n\t\tfmt.Println(\"No actions.\")\n\t} else {\n\t\tfor _, triggerName := range triggerNames {\n\t\t\tfmt.Printf(\"Trigger Name                  : %s\\n\", triggerName)\n\t\t\tfmt.Printf(\"Total triggered actions       : %d\\n\", sensorMap[triggerName+\"/\"+Success]+sensorMap[triggerName+\"/\"+Failure])\n\t\t\tfmt.Printf(\"Action triggered successfully : %d\\n\", sensorMap[triggerName+\"/\"+Success])\n\t\t\tfmt.Printf(\"Action triggered failed       : %d\\n\", sensorMap[triggerName+\"/\"+Failure])\n\t\t\tfmt.Printf(\"First action triggered at     : %v\\n\", sensorTimeMap[triggerName+\"/\"+First])\n\t\t\tfmt.Printf(\"Last action triggered at      : %v\\n\", sensorTimeMap[triggerName+\"/\"+Last])\n\t\t\tfmt.Printf(\"Total time taken              : %v\\n\", sensorTimeMap[triggerName+\"/\"+Last].Sub(sensorTimeMap[triggerName+\"/\"+First]))\n\t\t\tfmt.Println(\"--\")\n\t\t}\n\t}\n\treturn nil\n}\n\n// Check if it a valid log in JSON format, which contains something\n// like `\"ts\":1616093369.2583323`, and if it's later than start,\n// return the value of a log key\nfunc getLogValue(log []byte, start time.Time, key string) string {\n\tt := make(map[string]interface{})\n\tif err := json.Unmarshal(log, &t); err != nil {\n\t\t// invalid json format log\n\t\treturn \"\"\n\t}\n\tts, ok := t[\"ts\"]\n\tif !ok {\n\t\treturn \"\"\n\t}\n\ts, ok := ts.(float64)\n\tif !ok {\n\t\treturn \"\"\n\t}\n\tif float64(start.Unix()) > s {\n\t\t// old log\n\t\treturn \"\"\n\t}\n\tv, ok := t[key]\n\tif !ok {\n\t\treturn \"\"\n\t}\n\treturn fmt.Sprintf(\"%v\", v)\n}\n\nfunc (o *options) dynamicFor(r schema.GroupVersionResource) dynamic.ResourceInterface {\n\tresourceInterface := dynamic.NewForConfigOrDie(o.restConfig).Resource(r)\n\treturn resourceInterface.Namespace(o.namespace)\n}\n\nfunc (o *options) cleanUpResources(ctx context.Context) error {\n\thasTestLabel := metav1.ListOptions{LabelSelector: StressTestingLabel}\n\tresources := []schema.GroupVersionResource{\n\t\t{Group: eventsource.Group, Version: \"v1alpha1\", Resource: eventsource.Plural},\n\t\t{Group: sensor.Group, Version: \"v1alpha1\", Resource: sensor.Plural},\n\t\t{Group: eventbus.Group, Version: \"v1alpha1\", Resource: eventbus.Plural},\n\t}\n\tfor _, r := range resources {\n\t\tif err := o.dynamicFor(r).DeleteCollection(ctx, metav1.DeleteOptions{PropagationPolicy: &background}, hasTestLabel); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tfor _, r := range resources {\n\t\tfor {\n\t\t\tlist, err := o.dynamicFor(r).List(ctx, hasTestLabel)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif len(list.Items) == 0 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\ttime.Sleep(100 * time.Millisecond)\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (o *options) Start(ctx context.Context) error {\n\tfmt.Println(\"#################### Preparing ####################\")\n\n\tesName := o.esName\n\tsensorName := o.sensorName\n\n\t// Need to create\n\tif esName == \"\" && sensorName == \"\" {\n\t\t// Clean up resources if any\n\t\tif err := o.cleanUpResources(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\t\ttime.Sleep(10 * time.Second)\n\n\t\t// Create EventBus\n\t\teb, err := o.createEventBus(ctx)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tdefer func() {\n\t\t\tif !o.noCleanUp {\n\t\t\t\t_ = o.eventBusClient.Delete(ctx, eb.Name, metav1.DeleteOptions{})\n\t\t\t}\n\t\t}()\n\n\t\ttime.Sleep(5 * time.Second)\n\n\t\t// Create Sensor\n\t\tsensor, err := o.createSensor(ctx)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdefer func() {\n\t\t\tif !o.noCleanUp {\n\t\t\t\t_ = o.sensorClient.Delete(ctx, sensor.Name, metav1.DeleteOptions{})\n\t\t\t}\n\t\t}()\n\n\t\t// Create Event Source\n\t\tes, err := o.createEventSource(ctx)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdefer func() {\n\t\t\tif !o.noCleanUp {\n\t\t\t\t_ = o.eventSourceClient.Delete(ctx, es.Name, metav1.DeleteOptions{})\n\t\t\t}\n\t\t}()\n\n\t\tesName = es.Name\n\t\tsensorName = sensor.Name\n\t} else {\n\t\tfmt.Printf(\"------- Use existing EventSource and Sensor -------\\n\")\n\t\tfmt.Printf(\"EventSource name : %s\\n\", esName)\n\t\tfmt.Printf(\"Sensor name      : %s\\n\", sensorName)\n\t}\n\n\t// Run testing\n\tfmt.Println(\"\")\n\tfmt.Println(\"################# Started Testing #################\")\n\n\treturn o.runTesting(ctx, esName, sensorName)\n}\n\nfunc readResource(text string, v metav1.Object) error {\n\tvar data []byte\n\tvar err error\n\tif strings.HasPrefix(text, \"@\") {\n\t\tfile := strings.TrimPrefix(text, \"@\")\n\t\t_, fileName, _, _ := runtime.Caller(0)\n\t\tdata, err = ioutil.ReadFile(filepath.Dir(fileName) + \"/\" + file)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to read a file: %w\", err)\n\t\t}\n\t} else {\n\t\tdata = []byte(text)\n\t}\n\tif err = yaml.Unmarshal(data, v); err != nil {\n\t\treturn fmt.Errorf(\"failed to unmarshal the yaml: %w\", err)\n\t}\n\treturn nil\n}\n\nfunc getTestingEventSource(str string) TestingEventSource {\n\tswitch str {\n\tcase \"webhook\":\n\t\treturn WebhookEventSource\n\tcase \"sqs\":\n\t\treturn SQSEventSource\n\tcase \"sns\":\n\t\treturn SNSEventSource\n\tcase \"kafka\":\n\t\treturn KafkaEventSource\n\tcase \"redis\":\n\t\treturn RedisEventSource\n\tcase \"nats\":\n\t\treturn NATSEventSource\n\tdefault:\n\t\treturn UnsupportedEventsource\n\t}\n}\n\nfunc getEventBusType(str string) EventBusType {\n\tswitch str {\n\tcase \"jetstream\":\n\t\treturn JetstreamEventBus\n\tcase \"stan\":\n\t\treturn STANEventBus\n\tdefault:\n\t\treturn UnsupportedEventBusType\n\t}\n}\n\nfunc getTestingTrigger(str string) TestingTrigger {\n\tswitch str {\n\tcase \"log\":\n\t\treturn LogTrigger\n\tcase \"workflow\":\n\t\treturn WorkflowTrigger\n\tdefault:\n\t\treturn UnsupportedTrigger\n\t}\n}\n\nfunc main() {\n\tvar (\n\t\tebTypeStr      string\n\t\tesTypeStr      string\n\t\ttriggerTypeStr string\n\t\tesName         string\n\t\tsensorName     string\n\t\tidleTimeoutStr string\n\t\thardTimeoutStr string\n\t\tnoCleanUp      bool\n\t)\n\tvar rootCmd = &cobra.Command{\n\t\tUse:   \"go run ./test/stress/main.go\",\n\t\tShort: \"Argo Events stress testing.\",\n\t\tLong:  ``,\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tesType := getTestingEventSource(esTypeStr)\n\t\t\ttriggerType := getTestingTrigger(triggerTypeStr)\n\t\t\tif esName == \"\" && sensorName == \"\" {\n\t\t\t\tif esType == UnsupportedEventsource {\n\t\t\t\t\tfmt.Printf(\"Invalid event source %s\\n\\n\", esTypeStr)\n\t\t\t\t\tcmd.HelpFunc()(cmd, args)\n\t\t\t\t\tos.Exit(1)\n\t\t\t\t}\n\n\t\t\t\tif triggerType == UnsupportedTrigger {\n\t\t\t\t\tfmt.Printf(\"Invalid trigger %s\\n\\n\", triggerTypeStr)\n\t\t\t\t\tcmd.HelpFunc()(cmd, args)\n\t\t\t\t\tos.Exit(1)\n\t\t\t\t}\n\t\t\t} else if (esName == \"\" && sensorName != \"\") || (esName != \"\" && sensorName == \"\") {\n\t\t\t\tfmt.Printf(\"Both event source name and sensor name need to be specified\\n\\n\")\n\t\t\t\tcmd.HelpFunc()(cmd, args)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\teventBusType := getEventBusType(ebTypeStr)\n\t\t\tif eventBusType == UnsupportedEventBusType {\n\t\t\t\tfmt.Printf(\"Invalid event bus type %s\\n\\n\", ebTypeStr)\n\t\t\t\tcmd.HelpFunc()(cmd, args)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\n\t\t\tidleTimeout, err := time.ParseDuration(idleTimeoutStr)\n\t\t\tif err != nil {\n\t\t\t\tfmt.Printf(\"Invalid idle timeout %s: %v\\n\\n\", idleTimeoutStr, err)\n\t\t\t\tcmd.HelpFunc()(cmd, args)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\topts, err := NewOptions(esType, triggerType, eventBusType, esName, sensorName, idleTimeout, noCleanUp)\n\t\t\tif err != nil {\n\t\t\t\tfmt.Printf(\"Failed: %v\\n\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tif hardTimeoutStr != \"\" {\n\t\t\t\thardTimeout, err := time.ParseDuration(hardTimeoutStr)\n\t\t\t\tif err != nil {\n\t\t\t\t\tfmt.Printf(\"Invalid hard timeout %s: %v\\n\\n\", hardTimeoutStr, err)\n\t\t\t\t\tcmd.HelpFunc()(cmd, args)\n\t\t\t\t\tos.Exit(1)\n\t\t\t\t}\n\t\t\t\topts.hardTimeout = &hardTimeout\n\t\t\t}\n\t\t\tctx := signals.SetupSignalHandler()\n\t\t\tif err = opts.Start(ctx); err != nil {\n\t\t\t\tpanic(err)\n\t\t\t}\n\t\t},\n\t}\n\trootCmd.Flags().StringVarP(&ebTypeStr, \"eb-type\", \"b\", \"\", \"Type of event bus to be tested: stan, jetstream\")\n\trootCmd.Flags().StringVarP(&esTypeStr, \"es-type\", \"e\", \"\", \"Type of event source to be tested, e.g. webhook, sqs, etc.\")\n\trootCmd.Flags().StringVarP(&triggerTypeStr, \"trigger-type\", \"t\", string(LogTrigger), \"Type of trigger to be tested, e.g. log, workflow.\")\n\trootCmd.Flags().StringVar(&esName, \"es-name\", \"\", \"Name of an existing event source to be tested\")\n\trootCmd.Flags().StringVar(&sensorName, \"sensor-name\", \"\", \"Name of an existing sensor to be tested.\")\n\trootCmd.Flags().StringVar(&idleTimeoutStr, \"idle-timeout\", \"60s\", \"Exit in a period of time without any active events or actions. e.g. 30s, 2m.\")\n\trootCmd.Flags().StringVar(&hardTimeoutStr, \"hard-timeout\", \"\", \"Exit in a period of time after the testing starts. e.g. 120s, 5m. If it's specified, the application will exit at the time either hard-timeout or idle-timeout meets.\")\n\trootCmd.Flags().BoolVar(&noCleanUp, \"no-clean-up\", false, \"Whether to clean up the created resources.\")\n\n\t_ = rootCmd.Execute()\n}\n", "package validator\n\nimport (\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tdir := \"../../examples/event-sources\"\n\tfiles, err := ioutil.ReadDir(dir)\n\tassert.Nil(t, err)\n\tfor _, file := range files {\n\t\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", dir, file.Name()))\n\t\tassert.Nil(t, err)\n\t\tvar es *v1alpha1.EventSource\n\t\terr = yaml.Unmarshal(content, &es)\n\t\tassert.Nil(t, err)\n\t\tes.Namespace = testNamespace\n\t\tnewEs := es.DeepCopy()\n\t\tnewEs.Generation++\n\t\tv := NewEventSourceValidator(fakeK8sClient, fakeEventBusClient, fakeEventSourceClient, fakeSensorClient, es, newEs)\n\t\tr := v.ValidateCreate(contextWithLogger(t))\n\t\tassert.True(t, r.Allowed)\n\t\tr = v.ValidateUpdate(contextWithLogger(t))\n\t\tassert.True(t, r.Allowed)\n\t}\n}\n", "package validator\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\tcorev1 \"k8s.io/api/core/v1\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\n\t\"github.com/argoproj/argo-events/common\"\n\teventbusv1alpha1 \"github.com/argoproj/argo-events/pkg/apis/eventbus/v1alpha1\"\n\t\"github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1\"\n)\n\nvar (\n\tfakeBus = &eventbusv1alpha1.EventBus{\n\t\tTypeMeta: metav1.TypeMeta{\n\t\t\tAPIVersion: eventbusv1alpha1.SchemeGroupVersion.String(),\n\t\t\tKind:       \"EventBus\",\n\t\t},\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: testNamespace,\n\t\t\tName:      common.DefaultEventBusName,\n\t\t},\n\t\tSpec: eventbusv1alpha1.EventBusSpec{\n\t\t\tNATS: &eventbusv1alpha1.NATSBus{\n\t\t\t\tNative: &eventbusv1alpha1.NativeStrategy{\n\t\t\t\t\tAuth: &eventbusv1alpha1.AuthStrategyToken,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tStatus: eventbusv1alpha1.EventBusStatus{\n\t\t\tConfig: eventbusv1alpha1.BusConfig{\n\t\t\t\tNATS: &eventbusv1alpha1.NATSConfig{\n\t\t\t\t\tURL:  \"nats://xxxx\",\n\t\t\t\t\tAuth: &eventbusv1alpha1.AuthStrategyToken,\n\t\t\t\t\tAccessSecret: &corev1.SecretKeySelector{\n\t\t\t\t\t\tKey: \"test-key\",\n\t\t\t\t\t\tLocalObjectReference: corev1.LocalObjectReference{\n\t\t\t\t\t\t\tName: \"test-name\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n)\n\nfunc TestValidateSensor(t *testing.T) {\n\tdir := \"../../examples/sensors\"\n\tfiles, err := ioutil.ReadDir(dir)\n\tassert.Nil(t, err)\n\n\ttestBus := fakeBus.DeepCopy()\n\ttestBus.Status.MarkDeployed(\"test\", \"test\")\n\ttestBus.Status.MarkConfigured()\n\t_, err = fakeEventBusClient.ArgoprojV1alpha1().EventBus(testNamespace).Create(context.TODO(), testBus, metav1.CreateOptions{})\n\tassert.Nil(t, err)\n\n\tfor _, file := range files {\n\t\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", dir, file.Name()))\n\t\tassert.Nil(t, err)\n\t\tvar sensor *v1alpha1.Sensor\n\t\terr = yaml.Unmarshal(content, &sensor)\n\t\tassert.Nil(t, err)\n\t\tsensor.Namespace = testNamespace\n\t\tnewSensor := sensor.DeepCopy()\n\t\tnewSensor.Generation++\n\t\tv := NewSensorValidator(fakeK8sClient, fakeEventBusClient, fakeEventSourceClient, fakeSensorClient, sensor, newSensor)\n\t\tr := v.ValidateCreate(contextWithLogger(t))\n\t\tassert.True(t, r.Allowed)\n\t\tr = v.ValidateUpdate(contextWithLogger(t))\n\t\tassert.True(t, r.Allowed)\n\t}\n}\n"], "fixing_code": ["/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage common\n\nimport (\n\t\"context\"\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"hash/fnv\"\n\t\"net/http\"\n\t\"os\"\n\t\"reflect\"\n\t\"strings\"\n\n\t\"github.com/pkg/errors\"\n\tcorev1 \"k8s.io/api/core/v1\"\n\tv1 \"k8s.io/api/core/v1\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/client-go/kubernetes\"\n\t\"k8s.io/client-go/rest\"\n\t\"k8s.io/client-go/tools/clientcmd\"\n\n\tapicommon \"github.com/argoproj/argo-events/pkg/apis/common\"\n)\n\n// GetClientConfig return rest config, if path not specified, assume in cluster config\nfunc GetClientConfig(kubeconfig string) (*rest.Config, error) {\n\tif kubeconfig != \"\" {\n\t\treturn clientcmd.BuildConfigFromFlags(\"\", kubeconfig)\n\t}\n\treturn rest.InClusterConfig()\n}\n\n// SendSuccessResponse sends http success response\nfunc SendSuccessResponse(writer http.ResponseWriter, response string) {\n\twriter.WriteHeader(http.StatusOK)\n\tif _, err := writer.Write([]byte(response)); err != nil {\n\t\tfmt.Printf(\"failed to write the response. err: %+v\\n\", err)\n\t}\n}\n\n// SendErrorResponse sends http error response\nfunc SendErrorResponse(writer http.ResponseWriter, response string) {\n\twriter.WriteHeader(http.StatusBadRequest)\n\tif _, err := writer.Write([]byte(response)); err != nil {\n\t\tfmt.Printf(\"failed to write the response. err: %+v\\n\", err)\n\t}\n}\n\n// SendInternalErrorResponse sends http internal error response\nfunc SendInternalErrorResponse(writer http.ResponseWriter, response string) {\n\twriter.WriteHeader(http.StatusInternalServerError)\n\tif _, err := writer.Write([]byte(response)); err != nil {\n\t\tfmt.Printf(\"failed to write the response. err: %+v\\n\", err)\n\t}\n}\n\n// SendResponse sends http response with given status code\nfunc SendResponse(writer http.ResponseWriter, statusCode int, response string) {\n\twriter.WriteHeader(statusCode)\n\tif _, err := writer.Write([]byte(response)); err != nil {\n\t\tfmt.Printf(\"failed to write the response. err: %+v\\n\", err)\n\t}\n}\n\n// Hasher hashes a string\nfunc Hasher(value string) string {\n\th := fnv.New32a()\n\t_, _ = h.Write([]byte(value))\n\treturn fmt.Sprintf(\"%v\", h.Sum32())\n}\n\n// GetObjectHash returns hash of a given object\nfunc GetObjectHash(obj metav1.Object) (string, error) {\n\tb, err := json.Marshal(obj)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"failed to marshal resource\")\n\t}\n\treturn Hasher(string(b)), nil\n}\n\n// FormatEndpoint returns a formatted api endpoint\nfunc FormatEndpoint(endpoint string) string {\n\tif !strings.HasPrefix(endpoint, \"/\") {\n\t\treturn fmt.Sprintf(\"/%s\", endpoint)\n\t}\n\treturn endpoint\n}\n\n// FormattedURL returns a formatted url\nfunc FormattedURL(url, endpoint string) string {\n\treturn fmt.Sprintf(\"%s%s\", url, FormatEndpoint(endpoint))\n}\n\nfunc ErrEventSourceTypeMismatch(eventSourceType string) string {\n\treturn fmt.Sprintf(\"event source is not type of %s\", eventSourceType)\n}\n\n// GetSecretValue retrieves the secret value from the secret in namespace with name and key\nfunc GetSecretValue(ctx context.Context, client kubernetes.Interface, namespace string, selector *v1.SecretKeySelector) (string, error) {\n\tsecret, err := client.CoreV1().Secrets(namespace).Get(ctx, selector.Name, metav1.GetOptions{})\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tval, ok := secret.Data[selector.Key]\n\tif !ok {\n\t\treturn \"\", errors.Errorf(\"secret '%s' does not have the key '%s'\", selector.Name, selector.Key)\n\t}\n\treturn string(val), nil\n}\n\n// GetEnvFromSecret retrieves the value of envFrom.secretRef\n// \"${secretRef.name}_\" is expected to be defined as \"prefix\"\nfunc GetEnvFromSecret(selector *v1.SecretKeySelector) (string, bool) {\n\treturn os.LookupEnv(fmt.Sprintf(\"%s_%s\", selector.Name, selector.Key))\n}\n\n// GenerateEnvFromSecretSpec builds a \"envFrom\" spec with a secretKeySelector\nfunc GenerateEnvFromSecretSpec(selector *v1.SecretKeySelector) v1.EnvFromSource {\n\treturn v1.EnvFromSource{\n\t\tPrefix: selector.Name + \"_\",\n\t\tSecretRef: &v1.SecretEnvSource{\n\t\t\tLocalObjectReference: v1.LocalObjectReference{\n\t\t\t\tName: selector.Name,\n\t\t\t},\n\t\t},\n\t}\n}\n\n// GetSecretFromVolume retrieves the value of mounted secret volume\n// \"/argo-events/secrets/${secretRef.name}/${secretRef.key}\" is expected to be the file path\nfunc GetSecretFromVolume(selector *v1.SecretKeySelector) (string, error) {\n\tfilePath, err := GetSecretVolumePath(selector)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tdata, err := os.ReadFile(filePath)\n\tif err != nil {\n\t\treturn \"\", errors.Wrapf(err, \"failed to get secret value of name: %s, key: %s\", selector.Name, selector.Key)\n\t}\n\t// Secrets edited by tools like \"vim\" always have an extra invisible \"\\n\" in the end,\n\t// and it's often neglected, but it makes differences for some of the applications.\n\treturn strings.TrimSuffix(string(data), \"\\n\"), nil\n}\n\n// GetSecretVolumePath returns the path of the mounted secret\nfunc GetSecretVolumePath(selector *v1.SecretKeySelector) (string, error) {\n\tif selector == nil {\n\t\treturn \"\", errors.New(\"secret key selector is nil\")\n\t}\n\treturn fmt.Sprintf(\"/argo-events/secrets/%s/%s\", selector.Name, selector.Key), nil\n}\n\n// GetConfigMapFromVolume retrieves the value of mounted config map volume\n// \"/argo-events/config/${configMapRef.name}/${configMapRef.key}\" is expected to be the file path\nfunc GetConfigMapFromVolume(selector *v1.ConfigMapKeySelector) (string, error) {\n\tfilePath, err := GetConfigMapVolumePath(selector)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tdata, err := os.ReadFile(filePath)\n\tif err != nil {\n\t\treturn \"\", errors.Wrapf(err, \"failed to get configMap value of name: %s, key: %s\", selector.Name, selector.Key)\n\t}\n\t// Contents edied by tools like \"vim\" always have an extra invisible \"\\n\" in the end,\n\t// and it's often negleted, but it makes differences for some of the applications.\n\treturn strings.TrimSuffix(string(data), \"\\n\"), nil\n}\n\n// GetConfigMapVolumePath returns the path of the mounted configmap\nfunc GetConfigMapVolumePath(selector *v1.ConfigMapKeySelector) (string, error) {\n\tif selector == nil {\n\t\treturn \"\", errors.New(\"configmap key selector is nil\")\n\t}\n\treturn fmt.Sprintf(\"/argo-events/config/%s/%s\", selector.Name, selector.Key), nil\n}\n\n// GetEnvFromConfigMap retrieves the value of envFrom.configMapRef\n// \"${configMapRef.name}_\" is expected to be defined as \"prefix\"\nfunc GetEnvFromConfigMap(selector *v1.ConfigMapKeySelector) (string, bool) {\n\treturn os.LookupEnv(fmt.Sprintf(\"%s_%s\", selector.Name, selector.Key))\n}\n\n// GenerateEnvFromConfigMapSpec builds a \"envFrom\" spec with a configMapKeySelector\nfunc GenerateEnvFromConfigMapSpec(selector *v1.ConfigMapKeySelector) v1.EnvFromSource {\n\treturn v1.EnvFromSource{\n\t\tPrefix: selector.Name + \"_\",\n\t\tConfigMapRef: &v1.ConfigMapEnvSource{\n\t\t\tLocalObjectReference: v1.LocalObjectReference{\n\t\t\t\tName: selector.Name,\n\t\t\t},\n\t\t},\n\t}\n}\n\n// GetTLSConfig returns a tls configuration for given cert and key or skips the certs if InsecureSkipVerify is true.\nfunc GetTLSConfig(config *apicommon.TLSConfig) (*tls.Config, error) {\n\tif config == nil {\n\t\treturn nil, errors.New(\"TLSConfig is nil\")\n\t}\n\n\tif config.InsecureSkipVerify {\n\t\ttlsConfig := &tls.Config{\n\t\t\tInsecureSkipVerify: true,\n\t\t\tClientAuth:         0,\n\t\t}\n\t\treturn tlsConfig, nil\n\t}\n\n\tvar caCertPath, clientCertPath, clientKeyPath string\n\tvar err error\n\tif config.CACertSecret != nil {\n\t\tcaCertPath, err = GetSecretVolumePath(config.CACertSecret)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif config.ClientCertSecret != nil {\n\t\tclientCertPath, err = GetSecretVolumePath(config.ClientCertSecret)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif config.ClientKeySecret != nil {\n\t\tclientKeyPath, err = GetSecretVolumePath(config.ClientKeySecret)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif len(caCertPath)+len(clientCertPath)+len(clientKeyPath) == 0 {\n\t\t// None of 3 is configured\n\t\treturn nil, errors.New(\"invalid tls config, neither of caCertSecret, clientCertSecret and clientKeySecret is configured\")\n\t}\n\n\tif len(clientCertPath)+len(clientKeyPath) > 0 && len(clientCertPath)*len(clientKeyPath) == 0 {\n\t\t// Only one of clientCertSecret and clientKeySecret is configured\n\t\treturn nil, errors.New(\"invalid tls config, both of clientCertSecret and clientKeySecret need to be configured\")\n\t}\n\n\tc := &tls.Config{}\n\tif len(caCertPath) > 0 {\n\t\tcaCert, err := os.ReadFile(caCertPath)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"failed to read ca cert file %s\", caCertPath)\n\t\t}\n\t\tpool := x509.NewCertPool()\n\t\tpool.AppendCertsFromPEM(caCert)\n\t\tc.RootCAs = pool\n\t}\n\n\tif len(clientCertPath) > 0 && len(clientKeyPath) > 0 {\n\t\tclientCert, err := tls.LoadX509KeyPair(clientCertPath, clientKeyPath)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"failed to load client cert key pair %s\", caCertPath)\n\t\t}\n\t\tc.Certificates = []tls.Certificate{clientCert}\n\t}\n\treturn c, nil\n}\n\n// VolumesFromSecretsOrConfigMaps builds volumes and volumeMounts spec based on\n// the obj and its children's secretKeyselector or configMapKeySelector\nfunc VolumesFromSecretsOrConfigMaps(obj interface{}, t reflect.Type) ([]v1.Volume, []v1.VolumeMount) {\n\tresultVolumes := []v1.Volume{}\n\tresultMounts := []v1.VolumeMount{}\n\tvalues := findTypeValues(obj, t)\n\tif len(values) == 0 {\n\t\treturn resultVolumes, resultMounts\n\t}\n\tswitch t {\n\tcase SecretKeySelectorType:\n\t\tfor _, v := range values {\n\t\t\tselector := v.(*v1.SecretKeySelector)\n\t\t\tvol, mount := GenerateSecretVolumeSpecs(selector)\n\t\t\tresultVolumes = append(resultVolumes, vol)\n\t\t\tresultMounts = append(resultMounts, mount)\n\t\t}\n\tcase ConfigMapKeySelectorType:\n\t\tfor _, v := range values {\n\t\t\tselector := v.(*v1.ConfigMapKeySelector)\n\t\t\tvol, mount := GenerateConfigMapVolumeSpecs(selector)\n\t\t\tresultVolumes = append(resultVolumes, vol)\n\t\t\tresultMounts = append(resultMounts, mount)\n\t\t}\n\tdefault:\n\t}\n\treturn uniqueVolumes(resultVolumes), uniqueVolumeMounts(resultMounts)\n}\n\n// Find all the values obj's children matching provided type, type needs to be a pointer\nfunc findTypeValues(obj interface{}, t reflect.Type) []interface{} {\n\tresult := []interface{}{}\n\tvalue := reflect.ValueOf(obj)\n\tfindTypesRecursive(&result, value, t)\n\treturn result\n}\n\nfunc findTypesRecursive(result *[]interface{}, obj reflect.Value, t reflect.Type) {\n\tif obj.Type() == t && obj.CanInterface() && !obj.IsNil() {\n\t\t*result = append(*result, obj.Interface())\n\t}\n\tswitch obj.Kind() {\n\tcase reflect.Ptr:\n\t\tobjValue := obj.Elem()\n\t\t// Check if it is nil\n\t\tif !objValue.IsValid() {\n\t\t\treturn\n\t\t}\n\t\tfindTypesRecursive(result, objValue, t)\n\tcase reflect.Interface:\n\t\tobjValue := obj.Elem()\n\t\t// Check if it is nil\n\t\tif !objValue.IsValid() {\n\t\t\treturn\n\t\t}\n\t\tfindTypesRecursive(result, objValue, t)\n\tcase reflect.Struct:\n\t\tfor i := 0; i < obj.NumField(); i++ {\n\t\t\tif obj.Field(i).CanInterface() {\n\t\t\t\tfindTypesRecursive(result, obj.Field(i), t)\n\t\t\t}\n\t\t}\n\tcase reflect.Slice:\n\t\tfor i := 0; i < obj.Len(); i++ {\n\t\t\tfindTypesRecursive(result, obj.Index(i), t)\n\t\t}\n\tcase reflect.Map:\n\t\titer := obj.MapRange()\n\t\tfor iter.Next() {\n\t\t\tfindTypesRecursive(result, iter.Value(), t)\n\t\t}\n\tdefault:\n\t\treturn\n\t}\n}\n\n// GenerateSecretVolumeSpecs builds a \"volume\" and \"volumeMount\"spec with a secretKeySelector\nfunc GenerateSecretVolumeSpecs(selector *v1.SecretKeySelector) (v1.Volume, v1.VolumeMount) {\n\tvolName := strings.ReplaceAll(\"secret-\"+selector.Name, \"_\", \"-\")\n\treturn v1.Volume{\n\t\t\tName: volName,\n\t\t\tVolumeSource: v1.VolumeSource{\n\t\t\t\tSecret: &v1.SecretVolumeSource{\n\t\t\t\t\tSecretName: selector.Name,\n\t\t\t\t},\n\t\t\t},\n\t\t}, v1.VolumeMount{\n\t\t\tName:      volName,\n\t\t\tReadOnly:  true,\n\t\t\tMountPath: \"/argo-events/secrets/\" + selector.Name,\n\t\t}\n}\n\n// GenerateConfigMapVolumeSpecs builds a \"volume\" and \"volumeMount\"spec with a configMapKeySelector\nfunc GenerateConfigMapVolumeSpecs(selector *v1.ConfigMapKeySelector) (v1.Volume, v1.VolumeMount) {\n\tvolName := strings.ReplaceAll(\"cm-\"+selector.Name, \"_\", \"-\")\n\treturn v1.Volume{\n\t\t\tName: volName,\n\t\t\tVolumeSource: v1.VolumeSource{\n\t\t\t\tConfigMap: &v1.ConfigMapVolumeSource{\n\t\t\t\t\tLocalObjectReference: v1.LocalObjectReference{\n\t\t\t\t\t\tName: selector.Name,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}, v1.VolumeMount{\n\t\t\tName:      volName,\n\t\t\tReadOnly:  true,\n\t\t\tMountPath: \"/argo-events/config/\" + selector.Name,\n\t\t}\n}\n\nfunc uniqueVolumes(vols []v1.Volume) []v1.Volume {\n\trVols := []v1.Volume{}\n\tkeys := make(map[string]bool)\n\tfor _, e := range vols {\n\t\tif _, value := keys[e.Name]; !value {\n\t\t\tkeys[e.Name] = true\n\t\t\trVols = append(rVols, e)\n\t\t}\n\t}\n\treturn rVols\n}\n\nfunc uniqueVolumeMounts(mounts []v1.VolumeMount) []v1.VolumeMount {\n\trMounts := []v1.VolumeMount{}\n\tkeys := make(map[string]bool)\n\tfor _, e := range mounts {\n\t\tif _, value := keys[e.Name]; !value {\n\t\t\tkeys[e.Name] = true\n\t\t\trMounts = append(rMounts, e)\n\t\t}\n\t}\n\treturn rMounts\n}\n\n// ElementsMatch returns true if the two provided string slices contain the same elements while avoiding duplications.\n// WARN: this method avoids duplications.\nfunc ElementsMatch(first []string, second []string) bool {\n\tif len(first) == 0 && len(second) == 0 {\n\t\treturn true\n\t}\n\tif len(first) == 0 || len(second) == 0 {\n\t\treturn false\n\t}\n\n\tdiff := make(map[string]int)\n\tfor _, str := range first {\n\t\tdiff[str] = 1\n\t}\n\n\tfor _, str := range second {\n\t\tif _, ok := diff[str]; !ok {\n\t\t\treturn false\n\t\t} else {\n\t\t\tdiff[str] = 2\n\t\t}\n\t}\n\n\tfor _, v := range diff {\n\t\t// 1: only exists in first\n\t\t// 2: exists in both\n\t\tif v < 2 {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\n// SliceContains checks if a string slice contains a specific string\nfunc SliceContains(strSlice []string, targetStr string) bool {\n\tfor _, curr := range strSlice {\n\t\tif curr == targetStr {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc GetImagePullPolicy() corev1.PullPolicy {\n\timgPullPolicy := corev1.PullAlways\n\tif x := os.Getenv(EnvImagePullPolicy); x != \"\" {\n\t\timgPullPolicy = corev1.PullPolicy(x)\n\t}\n\treturn imgPullPolicy\n}\n\nfunc StructToMap(obj interface{}, output map[string]interface{}) error {\n\tdata, err := json.Marshal(obj) // Convert to a json string\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn json.Unmarshal(data, &output) // Convert to a map\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage sensor\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"strings\"\n\t\"testing\"\n\n\teventbusv1alpha1 \"github.com/argoproj/argo-events/pkg/apis/eventbus/v1alpha1\"\n\t\"github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n)\n\nfunc TestValidateSensor(t *testing.T) {\n\tdir := \"../../examples/sensors\"\n\tdirEntries, err := os.ReadDir(dir)\n\trequire.NoError(t, err)\n\n\tfor _, entry := range dirEntries {\n\t\tif entry.IsDir() {\n\t\t\tcontinue\n\t\t}\n\t\tt.Run(\n\t\t\tfmt.Sprintf(\"test example load: %s/%s\", dir, entry.Name()),\n\t\t\tfunc(t *testing.T) {\n\t\t\t\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", dir, entry.Name()))\n\t\t\t\tassert.NoError(t, err)\n\n\t\t\t\tvar sensor *v1alpha1.Sensor\n\t\t\t\teventBus := &eventbusv1alpha1.EventBus{Spec: eventbusv1alpha1.EventBusSpec{JetStream: &eventbusv1alpha1.JetStreamBus{}}}\n\t\t\t\terr = yaml.Unmarshal(content, &sensor)\n\t\t\t\tassert.NoError(t, err)\n\n\t\t\t\terr = ValidateSensor(sensor, eventBus)\n\t\t\t\tassert.NoError(t, err)\n\t\t\t})\n\t}\n}\n\nfunc TestValidDependencies(t *testing.T) {\n\tjetstreamBus := &eventbusv1alpha1.EventBus{Spec: eventbusv1alpha1.EventBusSpec{JetStream: &eventbusv1alpha1.JetStreamBus{}}}\n\tstanBus := &eventbusv1alpha1.EventBus{Spec: eventbusv1alpha1.EventBusSpec{NATS: &eventbusv1alpha1.NATSBus{}}}\n\n\tt.Run(\"test duplicate deps fail for STAN\", func(t *testing.T) {\n\t\tsObj := sensorObj.DeepCopy()\n\t\tsObj.Spec.Dependencies = append(sObj.Spec.Dependencies, v1alpha1.EventDependency{\n\t\t\tName:            \"fake-dep2\",\n\t\t\tEventSourceName: \"fake-source\",\n\t\t\tEventName:       \"fake-one\",\n\t\t})\n\t\terr := ValidateSensor(sObj, stanBus)\n\t\tassert.NotNil(t, err)\n\t\tassert.Equal(t, true, strings.Contains(err.Error(), \"is referenced for more than one dependency\"))\n\t})\n\n\tt.Run(\"test duplicate deps are fine for Jetstream\", func(t *testing.T) {\n\t\tsObj := sensorObj.DeepCopy()\n\t\tsObj.Spec.Dependencies = append(sObj.Spec.Dependencies, v1alpha1.EventDependency{\n\t\t\tName:            \"fake-dep2\",\n\t\t\tEventSourceName: \"fake-source\",\n\t\t\tEventName:       \"fake-one\",\n\t\t})\n\t\terr := ValidateSensor(sObj, jetstreamBus)\n\t\tassert.Nil(t, err)\n\t})\n\n\tt.Run(\"test empty event source name\", func(t *testing.T) {\n\t\tsObj := sensorObj.DeepCopy()\n\t\tsObj.Spec.Dependencies = append(sObj.Spec.Dependencies, v1alpha1.EventDependency{\n\t\t\tName:      \"fake-dep2\",\n\t\t\tEventName: \"fake-one\",\n\t\t})\n\t\terr := ValidateSensor(sObj, jetstreamBus)\n\t\tassert.NotNil(t, err)\n\t\tassert.Equal(t, true, strings.Contains(err.Error(), \"must define the EventSourceName\"))\n\t})\n\n\tt.Run(\"test empty event name\", func(t *testing.T) {\n\t\tsObj := sensorObj.DeepCopy()\n\t\tsObj.Spec.Dependencies = append(sObj.Spec.Dependencies, v1alpha1.EventDependency{\n\t\t\tName:            \"fake-dep2\",\n\t\t\tEventSourceName: \"fake-source\",\n\t\t})\n\t\terr := ValidateSensor(sObj, jetstreamBus)\n\t\tassert.NotNil(t, err)\n\t\tassert.Equal(t, true, strings.Contains(err.Error(), \"must define the EventName\"))\n\t})\n\n\tt.Run(\"test empty event name\", func(t *testing.T) {\n\t\tsObj := sensorObj.DeepCopy()\n\t\tsObj.Spec.Dependencies = append(sObj.Spec.Dependencies, v1alpha1.EventDependency{\n\t\t\tEventSourceName: \"fake-source2\",\n\t\t\tEventName:       \"fake-one2\",\n\t\t})\n\t\terr := ValidateSensor(sObj, jetstreamBus)\n\t\tassert.NotNil(t, err)\n\t\tassert.Equal(t, true, strings.Contains(err.Error(), \"must define a name\"))\n\t})\n}\n\nfunc TestValidateLogicalOperator(t *testing.T) {\n\tt.Run(\"test valid\", func(t *testing.T) {\n\t\tlogOp := v1alpha1.OrLogicalOperator\n\n\t\terr := validateLogicalOperator(logOp)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test not valid\", func(t *testing.T) {\n\t\tlogOp := v1alpha1.LogicalOperator(\"fake\")\n\n\t\terr := validateLogicalOperator(logOp)\n\n\t\tassert.Error(t, err)\n\t})\n}\n\nfunc TestValidateComparator(t *testing.T) {\n\tt.Run(\"test valid\", func(t *testing.T) {\n\t\tcomp := v1alpha1.NotEqualTo\n\n\t\terr := validateComparator(comp)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test not valid\", func(t *testing.T) {\n\t\tcomp := v1alpha1.Comparator(\"fake\")\n\n\t\terr := validateComparator(comp)\n\n\t\tassert.Error(t, err)\n\t})\n}\n\nfunc TestValidateEventFilter(t *testing.T) {\n\tt.Run(\"test empty\", func(t *testing.T) {\n\t\tfilter := &v1alpha1.EventDependencyFilter{}\n\n\t\terr := validateEventFilter(filter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test valid, all\", func(t *testing.T) {\n\t\tfilter := &v1alpha1.EventDependencyFilter{\n\t\t\tExprLogicalOperator: v1alpha1.OrLogicalOperator,\n\t\t\tExprs: []v1alpha1.ExprFilter{\n\t\t\t\t{\n\t\t\t\t\tExpr: \"fake-expr\",\n\t\t\t\t\tFields: []v1alpha1.PayloadField{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tPath: \"fake-path\",\n\t\t\t\t\t\t\tName: \"fake-name\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tDataLogicalOperator: v1alpha1.OrLogicalOperator,\n\t\t\tData: []v1alpha1.DataFilter{\n\t\t\t\t{\n\t\t\t\t\tPath: \"fake-path\",\n\t\t\t\t\tType: \"fake-type\",\n\t\t\t\t\tValue: []string{\n\t\t\t\t\t\t\"fake-value\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tContext: &v1alpha1.EventContext{\n\t\t\t\tType:            \"type\",\n\t\t\t\tSubject:         \"subject\",\n\t\t\t\tSource:          \"source\",\n\t\t\t\tDataContentType: \"fake-content-type\",\n\t\t\t},\n\t\t\tTime: &v1alpha1.TimeFilter{\n\t\t\t\tStart: \"00:00:00\",\n\t\t\t\tStop:  \"06:00:00\",\n\t\t\t},\n\t\t}\n\n\t\terr := validateEventFilter(filter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test valid, expr only\", func(t *testing.T) {\n\t\tfilter := &v1alpha1.EventDependencyFilter{\n\t\t\tExprs: []v1alpha1.ExprFilter{\n\t\t\t\t{\n\t\t\t\t\tExpr: \"fake-expr\",\n\t\t\t\t\tFields: []v1alpha1.PayloadField{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tPath: \"fake-path\",\n\t\t\t\t\t\t\tName: \"fake-name\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\n\t\terr := validateEventFilter(filter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test valid, data only\", func(t *testing.T) {\n\t\tfilter := &v1alpha1.EventDependencyFilter{\n\t\t\tData: []v1alpha1.DataFilter{\n\t\t\t\t{\n\t\t\t\t\tPath: \"fake-path\",\n\t\t\t\t\tType: \"fake-type\",\n\t\t\t\t\tValue: []string{\n\t\t\t\t\t\t\"fake-value\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\n\t\terr := validateEventFilter(filter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test valid, ctx only\", func(t *testing.T) {\n\t\tfilter := &v1alpha1.EventDependencyFilter{\n\t\t\tContext: &v1alpha1.EventContext{\n\t\t\t\tType:            \"type\",\n\t\t\t\tSubject:         \"subject\",\n\t\t\t\tSource:          \"source\",\n\t\t\t\tDataContentType: \"fake-content-type\",\n\t\t\t},\n\t\t}\n\n\t\terr := validateEventFilter(filter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test valid, time only\", func(t *testing.T) {\n\t\tfilter := &v1alpha1.EventDependencyFilter{\n\t\t\tTime: &v1alpha1.TimeFilter{\n\t\t\t\tStart: \"00:00:00\",\n\t\t\t\tStop:  \"06:00:00\",\n\t\t\t},\n\t\t}\n\n\t\terr := validateEventFilter(filter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test not valid, wrong logical operator\", func(t *testing.T) {\n\t\tfilter := &v1alpha1.EventDependencyFilter{\n\t\t\tDataLogicalOperator: \"fake\",\n\t\t}\n\n\t\terr := validateEventFilter(filter)\n\n\t\tassert.Error(t, err)\n\t})\n}\n\nfunc TestValidateEventExprFilter(t *testing.T) {\n\tt.Run(\"test valid\", func(t *testing.T) {\n\t\texprFilter := &v1alpha1.ExprFilter{\n\t\t\tExpr: \"fake-expr\",\n\t\t\tFields: []v1alpha1.PayloadField{\n\t\t\t\t{\n\t\t\t\t\tPath: \"fake-path\",\n\t\t\t\t\tName: \"fake-name\",\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\n\t\terr := validateEventExprFilter(exprFilter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test not valid, no expr\", func(t *testing.T) {\n\t\texprFilter := &v1alpha1.ExprFilter{\n\t\t\tFields: []v1alpha1.PayloadField{\n\t\t\t\t{\n\t\t\t\t\tPath: \"fake-path\",\n\t\t\t\t\tName: \"fake-name\",\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\n\t\terr := validateEventExprFilter(exprFilter)\n\n\t\tassert.Error(t, err)\n\t})\n\n\tt.Run(\"test not valid, no field name\", func(t *testing.T) {\n\t\texprFilter := &v1alpha1.ExprFilter{\n\t\t\tExpr: \"fake-expr\",\n\t\t\tFields: []v1alpha1.PayloadField{\n\t\t\t\t{\n\t\t\t\t\tPath: \"fake-path\",\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\n\t\terr := validateEventExprFilter(exprFilter)\n\n\t\tassert.Error(t, err)\n\t})\n}\n\nfunc TestValidateEventDataFilter(t *testing.T) {\n\tt.Run(\"test valid\", func(t *testing.T) {\n\t\tdataFilter := &v1alpha1.DataFilter{\n\t\t\tPath:  \"body.value\",\n\t\t\tType:  \"number\",\n\t\t\tValue: []string{\"50.0\"},\n\t\t}\n\n\t\terr := validateEventDataFilter(dataFilter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test not valid, no path\", func(t *testing.T) {\n\t\tdataFilter := &v1alpha1.DataFilter{\n\t\t\tType:  \"number\",\n\t\t\tValue: []string{\"50.0\"},\n\t\t}\n\n\t\terr := validateEventDataFilter(dataFilter)\n\n\t\tassert.Error(t, err)\n\t})\n\n\tt.Run(\"test not valid, empty value\", func(t *testing.T) {\n\t\tdataFilter := &v1alpha1.DataFilter{\n\t\t\tPath:  \"body.value\",\n\t\t\tType:  \"string\",\n\t\t\tValue: []string{\"\"},\n\t\t}\n\n\t\terr := validateEventDataFilter(dataFilter)\n\n\t\tassert.Error(t, err)\n\t})\n\n\tt.Run(\"test not valid, wrong comparator\", func(t *testing.T) {\n\t\tdataFilter := &v1alpha1.DataFilter{\n\t\t\tComparator: \"fake\",\n\t\t\tPath:       \"body.value\",\n\t\t\tType:       \"string\",\n\t\t\tValue:      []string{\"\"},\n\t\t}\n\n\t\terr := validateEventDataFilter(dataFilter)\n\n\t\tassert.Error(t, err)\n\t})\n}\n\nfunc TestValidateEventCtxFilter(t *testing.T) {\n\tt.Run(\"test all fields\", func(t *testing.T) {\n\t\tctxFilter := &v1alpha1.EventContext{\n\t\t\tType:            \"fake-type\",\n\t\t\tSubject:         \"fake-subject\",\n\t\t\tSource:          \"fake-source\",\n\t\t\tDataContentType: \"fake-content-type\",\n\t\t}\n\n\t\terr := validateEventCtxFilter(ctxFilter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test single field\", func(t *testing.T) {\n\t\tctxFilter := &v1alpha1.EventContext{\n\t\t\tType: \"fake-type\",\n\t\t}\n\n\t\terr := validateEventCtxFilter(ctxFilter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test no fields\", func(t *testing.T) {\n\t\tctxFilter := &v1alpha1.EventContext{}\n\n\t\terr := validateEventCtxFilter(ctxFilter)\n\n\t\tassert.Error(t, err)\n\t})\n}\n\nfunc TestValidateEventTimeFilter(t *testing.T) {\n\tt.Run(\"test start < stop\", func(t *testing.T) {\n\t\ttimeFilter := &v1alpha1.TimeFilter{\n\t\t\tStart: \"00:00:00\",\n\t\t\tStop:  \"06:00:00\",\n\t\t}\n\n\t\terr := validateEventTimeFilter(timeFilter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test stop < start\", func(t *testing.T) {\n\t\ttimeFilter := &v1alpha1.TimeFilter{\n\t\t\tStart: \"06:00:00\",\n\t\t\tStop:  \"00:00:00\",\n\t\t}\n\n\t\terr := validateEventTimeFilter(timeFilter)\n\n\t\tassert.NoError(t, err)\n\t})\n\n\tt.Run(\"test start = stop\", func(t *testing.T) {\n\t\ttimeFilter := &v1alpha1.TimeFilter{\n\t\t\tStart: \"00:00:00\",\n\t\t\tStop:  \"00:00:00\",\n\t\t}\n\n\t\terr := validateEventTimeFilter(timeFilter)\n\n\t\tassert.Error(t, err)\n\t})\n}\n\nfunc TestValidTriggers(t *testing.T) {\n\tt.Run(\"duplicate trigger names\", func(t *testing.T) {\n\t\ttriggers := []v1alpha1.Trigger{\n\t\t\t{\n\t\t\t\tTemplate: &v1alpha1.TriggerTemplate{\n\t\t\t\t\tName: \"fake-trigger\",\n\t\t\t\t\tK8s: &v1alpha1.StandardK8STrigger{\n\t\t\t\t\t\tOperation: \"create\",\n\t\t\t\t\t\tSource:    &v1alpha1.ArtifactLocation{},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tTemplate: &v1alpha1.TriggerTemplate{\n\t\t\t\t\tName: \"fake-trigger\",\n\t\t\t\t\tK8s: &v1alpha1.StandardK8STrigger{\n\t\t\t\t\t\tOperation: \"create\",\n\t\t\t\t\t\tSource:    &v1alpha1.ArtifactLocation{},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\terr := validateTriggers(triggers)\n\t\tassert.NotNil(t, err)\n\t\tassert.Equal(t, true, strings.Contains(err.Error(), \"duplicate trigger name:\"))\n\t})\n\n\tt.Run(\"empty trigger template\", func(t *testing.T) {\n\t\ttriggers := []v1alpha1.Trigger{\n\t\t\t{\n\t\t\t\tTemplate: nil,\n\t\t\t},\n\t\t}\n\t\terr := validateTriggers(triggers)\n\t\tassert.NotNil(t, err)\n\t\tassert.Equal(t, true, strings.Contains(err.Error(), \"trigger template can't be nil\"))\n\t})\n\n\tt.Run(\"invalid conditions reset - cron\", func(t *testing.T) {\n\t\ttriggers := []v1alpha1.Trigger{\n\t\t\t{\n\t\t\t\tTemplate: &v1alpha1.TriggerTemplate{\n\t\t\t\t\tName:       \"fake-trigger\",\n\t\t\t\t\tConditions: \"A && B\",\n\t\t\t\t\tConditionsReset: []v1alpha1.ConditionsResetCriteria{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tByTime: &v1alpha1.ConditionsResetByTime{\n\t\t\t\t\t\t\t\tCron: \"a * * * *\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tK8s: &v1alpha1.StandardK8STrigger{\n\t\t\t\t\t\tOperation: \"create\",\n\t\t\t\t\t\tSource:    &v1alpha1.ArtifactLocation{},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\terr := validateTriggers(triggers)\n\t\tassert.NotNil(t, err)\n\t\tassert.Equal(t, true, strings.Contains(err.Error(), \"invalid cron expression\"))\n\t})\n\n\tt.Run(\"invalid conditions reset - timezone\", func(t *testing.T) {\n\t\ttriggers := []v1alpha1.Trigger{\n\t\t\t{\n\t\t\t\tTemplate: &v1alpha1.TriggerTemplate{\n\t\t\t\t\tName:       \"fake-trigger\",\n\t\t\t\t\tConditions: \"A && B\",\n\t\t\t\t\tConditionsReset: []v1alpha1.ConditionsResetCriteria{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tByTime: &v1alpha1.ConditionsResetByTime{\n\t\t\t\t\t\t\t\tCron:     \"* * * * *\",\n\t\t\t\t\t\t\t\tTimezone: \"fake\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tK8s: &v1alpha1.StandardK8STrigger{\n\t\t\t\t\t\tOperation: \"create\",\n\t\t\t\t\t\tSource:    &v1alpha1.ArtifactLocation{},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\terr := validateTriggers(triggers)\n\t\tassert.NotNil(t, err)\n\t\tassert.Equal(t, true, strings.Contains(err.Error(), \"invalid timezone\"))\n\t})\n}\n", "# HTTP Trigger\n\nArgo Events offers HTTP trigger which can easily invoke serverless functions like OpenFaaS, Kubeless, Knative, Nuclio and make REST API calls.\n\n<br/>\n<br/>\n\n<p align=\"center\">\n  <img src=\"https://github.com/argoproj/argo-events/blob/master/docs/assets/http-trigger.png?raw=true\" alt=\"HTTP Trigger\"/>\n</p>\n\n<br/>\n<br/>\n\n## Specification\n\nThe HTTP trigger specification is available [here](https://github.com/argoproj/argo-events/blob/master/api/sensor.md#httptrigger).\n\n## REST API Calls\n\nConsider a scenario where your REST API server needs to consume events from event-sources S3, GitHub, SQS etc. Usually, you'd end up writing\nthe integration yourself in the server code, although server logic has nothing to do any of the event-sources. This is where Argo Events HTTP trigger\ncan help. The HTTP trigger takes the task of consuming events from event-sources away from API server and seamlessly integrates these events via REST API calls.\n\nWe will set up a basic go http server and connect it with the Minio events.\n\n1.  The HTTP server simply prints the request body as follows.\n\n        package main\n\n        import (\n        \t\"fmt\"\n        \t\"io\"\n        \t\"net/http\"\n        )\n\n        func hello(w http.ResponseWriter, req *http.Request) {\n        \tbody, err := io.ReadAll(req.Body)\n        \tif err != nil {\n        \t\tfmt.Printf(\"%+v\\n\", err)\n        \t\treturn\n        \t}\n        \tfmt.Println(string(body))\n        \tfmt.Fprintf(w, \"hello\\n\")\n        }\n\n        func main() {\n        \thttp.HandleFunc(\"/hello\", hello)\n        \tfmt.Println(\"server is listening on 8090\")\n        \thttp.ListenAndServe(\":8090\", nil)\n        }\n\n2.  Deploy the HTTP server.\n\n        kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/09-http-trigger/http-server.yaml\n\n3.  Create a service to expose the http server.\n\n        kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/09-http-trigger/http-server-svc.yaml\n\n4.  Either use Ingress, OpenShift Route or port-forwarding to expose the http server.\n\n        kubectl -n argo-events port-forward <http-server-pod-name> 8090:8090\n\n5.  Our goals is to seamlessly integrate Minio S3 bucket notifications with REST API server created in previous step. So,\n    lets set up the Minio event-source available [here](https://argoproj.github.io/argo-events/setup/minio/).\n    Don't create the sensor as we will be deploying it in next step.\n\n6.  Create a sensor as follows.\n\n        kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/http-trigger.yaml\n\n7.  Now, drop a file onto `input` bucket in Minio server.\n\n8.  The sensor has triggered a http request to the http server. Take a look at the logs.\n\n        server is listening on 8090\n        {\"type\":\"minio\",\"bucket\":\"input\"}\n\n9.  Great!!!\n\n### Request Payload\n\nIn order to construct a request payload based on the event data, sensor offers\n`payload` field as a part of the HTTP trigger.\n\nLet's examine a HTTP trigger,\n\n        http:\n          url: http://http-server.argo-events.svc:8090/hello\n          payload:\n            - src:\n                dependencyName: test-dep\n                dataKey: notification.0.s3.bucket.name\n              dest: bucket\n            - src:\n                dependencyName: test-dep\n                contextKey: type\n              dest: type\n          method: POST  // GET, DELETE, POST, PUT, HEAD, etc.\n\nThe `payload` contains the list of `src` which refers to the source event and `dest` which refers to destination key within result request payload.\n\nThe `payload` declared above will generate a request payload like below,\n\n        {\n          \"type\": \"type of event from event's context\"\n          \"bucket\": \"bucket name from event data\"\n        }\n\nThe above payload will be passed in the HTTP request. You can add however many number of `src` and `dest` under `payload`.\n\n**Note**: Take a look at [Parameterization](https://argoproj.github.io/argo-events/tutorials/02-parameterization/) in order to understand how to extract particular key-value from\nevent data.\n\n### Parameterization\n\nSimilar to other type of triggers, sensor offers parameterization for the HTTP trigger. Parameterization is specially useful when\nyou want to define a generic trigger template in the sensor and populate values like URL, payload values on the fly.\n\nYou can learn more about trigger parameterization [here](https://argoproj.github.io/argo-events/tutorials/02-parameterization/).\n\n### Policy\n\nTrigger policy helps you determine the status of the HTTP request and decide whether to stop or continue sensor.\n\nTo determine whether the HTTP request was successful or not, the HTTP trigger provides a `Status` policy.\nThe `Status` holds a list of response statuses that are considered valid.\n\n        http:\n          url: http://http-server.argo-events.svc:8090/hello\n          payload:\n            - src:\n                dependencyName: test-dep\n                dataKey: notification.0s3.bucket.name\n              dest: bucket\n            - src:\n                dependencyName: test-dep\n                contextKey: type\n              dest: type\n          method: POST  // GET, DELETE, POST, PUT, HEAD, etc.\n      retryStrategy:\n        steps: 3\n        duration: 3s\n      policy:\n        status:\n          allow:\n            - 200\n            - 201\n\nThe above HTTP trigger will be treated successful only if the HTTP request returns with either 200 or 201 status.\n\n## OpenFaaS\n\nOpenFaaS offers a simple way to spin up serverless functions. Lets see how we can leverage Argo Events HTTP trigger\nto invoke OpenFaaS function.\n\n1.  If you don't have OpenFaaS installed, follow the [instructions](https://docs.openfaas.com/deployment/kubernetes/).\n\n2.  Let's create a basic function. You can follow the [steps](https://blog.alexellis.io/serverless-golang-with-openfaas/).\n    to set up the function.\n\n         package function\n\n         import (\n         \t\"fmt\"\n         )\n\n         // Handle a serverless request\n         func Handle(req []byte) string {\n         \treturn fmt.Sprintf(\"Hello, Go. You said: %s\", string(req))\n         }\n\n3.  Make sure the function pod is up and running.\n\n4.  We are going to invoke OpenFaaS function on a message on Redis Subscriber.\n\n5.  Let's set up the Redis Database, Redis PubSub event-source as specified [here](https://argoproj.github.io/argo-events/setup/redis/).\n    Do not create the Redis sensor, we are going to create it in next step.\n\n6.  Let's create the sensor with OpenFaaS trigger.\n\n        apiVersion: argoproj.io/v1alpha1\n        kind: Sensor\n        metadata:\n          name: redis-sensor\n        spec:\n          dependencies:\n            - name: test-dep\n              eventSourceName: redis\n              eventName: example\n          triggers:\n            - template:\n                name: openfaas-trigger\n                http:\n                  url: http://gateway.openfaas.svc.cluster.local:8080/function/gohash\n                  payload:\n                    - src:\n                        dependencyName: test-dep\n                      dest: bucket\n                  method: POST\n\n7.  Publish a message on `FOO` channel using `redis-cli`.\n\n        PUBLISH FOO hello\n\n8.  As soon as you publish the message, the sensor will invoke the OpenFaaS function `gohash`.\n\n## Kubeless\n\nSimilar to REST API calls, you can easily invoke Kubeless functions using HTTP trigger.\n\n1.  If you don't have Kubeless installed, follow the [installation](https://kubeless.io/docs/quick-start/).\n\n2.  Lets create a basic function.\n\n        def hello(event, context):\n          print event\n          return event['data']\n\n3.  Make sure the function pod and service is created.\n\n4.  Now, we are going to invoke the Kubeless function when a message is placed on a NATS queue.\n\n5.  Let's set up the NATS event-source. Follow [instructions](https://argoproj.github.io/argo-events/setup/nats/#setup) for details.\n    Do not create the NATS sensor, we are going to create it in next step.\n\n6.  Let's create NATS sensor with HTTP trigger.\n\n        apiVersion: argoproj.io/v1alpha1\n        kind: Sensor\n        metadata:\n          name: nats-sensor\n        spec:\n          dependencies:\n            - name: test-dep\n              eventSourceName: nats\n              eventName: example\n          triggers:\n            - template:\n                name: kubeless-trigger\n                http:\n                  serverURL: http://hello.kubeless.svc.cluster.local:8080\n                  payload:\n                    - src:\n                        dependencyName: test-dep\n                        dataKey: body.first_name\n                      dest: first_name\n                    - src:\n                        dependencyName: test-dep\n                        dataKey: body.last_name\n                      dest: last_name\n                  method: POST\n\n7.  Once event-source and sensor pod are up and running, dispatch a message on `foo` subject using nats client.\n\n        go run main.go -s localhost foo '{\"first_name\": \"foo\", \"last_name\": \"bar\"}'\n\n8.  It will invoke Kubeless function `hello`.\n\n        {'event-time': None, 'extensions': {'request': <LocalRequest: POST http://hello.kubeless.svc.cluster.local:8080/> }, 'event-type': None, 'event-namespace': None, 'data': '{\"first_name\":\"foo\",\"last_name\":\"bar\"}', 'event-id': None}\n\n# Other serverless frameworks\n\nSimilar to OpenFaaS and Kubeless invocation demonstrated above, you can easily trigger KNative, Nuclio, Fission functions using HTTP trigger.\n", "package naivewatcher\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"syscall\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/common/fsevent\"\n)\n\ntype WatchableTestFS struct {\n}\n\ntype TestFSID struct {\n\tDevice int32\n\tInode  uint64\n}\n\nfunc (w *WatchableTestFS) Walk(root string, walkFn filepath.WalkFunc) error {\n\treturn filepath.Walk(root, walkFn)\n}\n\nfunc (w *WatchableTestFS) GetFileID(fi os.FileInfo) interface{} {\n\tstat := fi.Sys().(*syscall.Stat_t)\n\treturn TestFSID{\n\t\tDevice: int32(stat.Dev),\n\t\tInode:  stat.Ino,\n\t}\n}\n\nfunc TestWatcherAutoCheck(t *testing.T) {\n\twatcher, err := NewWatcher(&WatchableTestFS{})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer watcher.Close()\n\n\ttmpdir, err := os.MkdirTemp(\"\", \"naive-watcher-\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer os.RemoveAll(tmpdir)\n\n\terr = watcher.Add(tmpdir)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\terr = watcher.Start(100 * time.Millisecond)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer func() {\n\t\tif err := watcher.Stop(); err != nil {\n\t\t\tfmt.Printf(\"failed to stop the watcher. err: %+v\\n\", err)\n\t\t}\n\t}()\n\n\t// Create a file\n\t_, err = os.Create(filepath.Join(tmpdir, \"foo\"))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\ttime.Sleep(200 * time.Millisecond)\n\tevents := readEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{\n\t\t{Op: fsevent.Create, Name: filepath.Join(tmpdir, \"foo\")},\n\t}, events)\n\n\t// Rename a file\n\terr = os.Rename(filepath.Join(tmpdir, \"foo\"), filepath.Join(tmpdir, \"bar\"))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\ttime.Sleep(200 * time.Millisecond)\n\tevents = readEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{\n\t\t{Op: fsevent.Rename, Name: filepath.Join(tmpdir, \"bar\")},\n\t}, events)\n\n\t// Write a file\n\terr = os.WriteFile(filepath.Join(tmpdir, \"bar\"), []byte(\"wow\"), 0666)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\ttime.Sleep(200 * time.Millisecond)\n\tevents = readEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{\n\t\t{Op: fsevent.Write, Name: filepath.Join(tmpdir, \"bar\")},\n\t}, events)\n\n\t// Chmod a file\n\terr = os.Chmod(filepath.Join(tmpdir, \"bar\"), 0777)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\ttime.Sleep(200 * time.Millisecond)\n\tevents = readEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{\n\t\t{Op: fsevent.Chmod, Name: filepath.Join(tmpdir, \"bar\")},\n\t}, events)\n\n\t// Rename & Write & Chmod a file\n\terr = os.Rename(filepath.Join(tmpdir, \"bar\"), filepath.Join(tmpdir, \"foo\"))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\terr = os.WriteFile(filepath.Join(tmpdir, \"foo\"), []byte(\"wowwow\"), 0666)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\terr = os.Chmod(filepath.Join(tmpdir, \"foo\"), 0770)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tvar actualOps fsevent.Op\n\ttime.Sleep(200 * time.Millisecond)\n\tevents = readEvents(t, watcher)\n\tfor _, event := range events {\n\t\tif event.Name == filepath.Join(tmpdir, \"foo\") {\n\t\t\tactualOps |= event.Op\n\t\t}\n\t}\n\tassert.Equal(t, fsevent.Write|fsevent.Rename|fsevent.Chmod, actualOps)\n\n\t// Remove a file\n\terr = os.Remove(filepath.Join(tmpdir, \"foo\"))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\ttime.Sleep(200 * time.Millisecond)\n\tevents = readEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{\n\t\t{Op: fsevent.Remove, Name: filepath.Join(tmpdir, \"foo\")},\n\t}, events)\n\n\terr = watcher.Stop()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\terr = watcher.Remove(tmpdir)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc TestWatcherManualCheck(t *testing.T) {\n\twatcher, err := NewWatcher(&WatchableTestFS{})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer watcher.Close()\n\n\ttmpdir, err := os.MkdirTemp(\"\", \"naive-watcher-\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer os.RemoveAll(tmpdir)\n\n\terr = watcher.Add(tmpdir)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tevents := checkAndReadEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{}, events)\n\n\t// Create a file\n\t_, err = os.Create(filepath.Join(tmpdir, \"foo\"))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tevents = checkAndReadEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{\n\t\t{Op: fsevent.Create, Name: filepath.Join(tmpdir, \"foo\")},\n\t}, events)\n\n\t// Rename a file\n\terr = os.Rename(filepath.Join(tmpdir, \"foo\"), filepath.Join(tmpdir, \"bar\"))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tevents = checkAndReadEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{\n\t\t{Op: fsevent.Rename, Name: filepath.Join(tmpdir, \"bar\")},\n\t}, events)\n\n\t// Write a file\n\terr = os.WriteFile(filepath.Join(tmpdir, \"bar\"), []byte(\"wow\"), 0666)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tevents = checkAndReadEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{\n\t\t{Op: fsevent.Write, Name: filepath.Join(tmpdir, \"bar\")},\n\t}, events)\n\n\t// Chmod a file\n\terr = os.Chmod(filepath.Join(tmpdir, \"bar\"), 0777)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tevents = checkAndReadEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{\n\t\t{Op: fsevent.Chmod, Name: filepath.Join(tmpdir, \"bar\")},\n\t}, events)\n\n\t// Rename & Write & Chmod a file\n\terr = os.Rename(filepath.Join(tmpdir, \"bar\"), filepath.Join(tmpdir, \"foo\"))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\terr = os.WriteFile(filepath.Join(tmpdir, \"foo\"), []byte(\"wowwow\"), 0666)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\terr = os.Chmod(filepath.Join(tmpdir, \"foo\"), 0770)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tevents = checkAndReadEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{\n\t\t{Op: fsevent.Write | fsevent.Rename | fsevent.Chmod, Name: filepath.Join(tmpdir, \"foo\")},\n\t}, events)\n\n\t// Remove a file\n\terr = os.Remove(filepath.Join(tmpdir, \"foo\"))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tevents = checkAndReadEvents(t, watcher)\n\tassert.Equal(t, []fsevent.Event{\n\t\t{Op: fsevent.Remove, Name: filepath.Join(tmpdir, \"foo\")},\n\t}, events)\n\n\terr = watcher.Remove(tmpdir)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}\n\nfunc checkAndReadEvents(t *testing.T, watcher *Watcher) []fsevent.Event {\n\terr := watcher.Check()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\treturn readEvents(t, watcher)\n}\n\nfunc readEvents(t *testing.T, watcher *Watcher) []fsevent.Event {\n\tevents := []fsevent.Event{}\nL:\n\tfor {\n\t\tselect {\n\t\tcase event := <-watcher.Events:\n\t\t\tevents = append(events, event)\n\t\tdefault:\n\t\t\tbreak L\n\t\t}\n\t}\n\treturn events\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage amqp\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"either url or urlSecret must be specified\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"amqp.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.AMQP)\n\n\tfor _, value := range eventSource.Spec.AMQP {\n\t\tl := &EventListener{\n\t\t\tAMQPEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage awssns\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto/x509\"\n\t\"encoding/base64\"\n\t\"encoding/json\"\n\t\"encoding/pem\"\n\t\"io\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"reflect\"\n\t\"regexp\"\n\t\"time\"\n\n\tsnslib \"github.com/aws/aws-sdk-go/service/sns\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/pkg/errors\"\n\t\"go.uber.org/zap\"\n\n\t\"github.com/argoproj/argo-events/common\"\n\t\"github.com/argoproj/argo-events/common/logging\"\n\teventsourcecommon \"github.com/argoproj/argo-events/eventsources/common\"\n\tcommonaws \"github.com/argoproj/argo-events/eventsources/common/aws\"\n\t\"github.com/argoproj/argo-events/eventsources/common/webhook\"\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\tmetrics \"github.com/argoproj/argo-events/metrics\"\n\tapicommon \"github.com/argoproj/argo-events/pkg/apis/common\"\n\t\"github.com/argoproj/argo-events/pkg/apis/events\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nvar (\n\t// controller controls the webhook operations\n\tcontroller = webhook.NewController()\n\n\t// used for SNS verification\n\tsnsSigKeys      = map[string][]string{}\n\tsnsKeyRealNames = map[string]string{\n\t\t\"MessageID\": \"MessageId\",\n\t\t\"TopicARN\":  \"TopicArn\",\n\t}\n)\n\n// set up route activation and deactivation channels\nfunc init() {\n\tgo webhook.ProcessRouteStatus(controller)\n\n\tsnsSigKeys[messageTypeNotification] = []string{\n\t\t\"Message\",\n\t\t\"MessageID\",\n\t\t\"Subject\",\n\t\t\"Timestamp\",\n\t\t\"TopicARN\",\n\t\t\"Type\",\n\t}\n\tsnsSigKeys[messageTypeSubscriptionConfirmation] = []string{\n\t\t\"Message\",\n\t\t\"MessageID\",\n\t\t\"SubscribeURL\",\n\t\t\"Timestamp\",\n\t\t\"Token\",\n\t\t\"TopicARN\",\n\t\t\"Type\",\n\t}\n}\n\n// Implement Router\n// 1. GetRoute\n// 2. HandleRoute\n// 3. PostActivate\n// 4. PostDeactivate\n\n// GetRoute returns the route\nfunc (router *Router) GetRoute() *webhook.Route {\n\treturn router.Route\n}\n\n// HandleRoute handles new routes\nfunc (router *Router) HandleRoute(writer http.ResponseWriter, request *http.Request) {\n\troute := router.Route\n\n\tlogger := route.Logger.With(\n\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\tlogging.LabelPort, route.Context.Port,\n\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t)\n\n\tlogger.Info(\"request received from event source\")\n\n\tif !route.Active {\n\t\tlogger.Info(\"endpoint is not active, won't process the request\")\n\t\tcommon.SendErrorResponse(writer, \"inactive endpoint\")\n\t\treturn\n\t}\n\n\tdefer func(start time.Time) {\n\t\troute.Metrics.EventProcessingDuration(route.EventSourceName, route.EventName, float64(time.Since(start)/time.Millisecond))\n\t}(time.Now())\n\n\trequest.Body = http.MaxBytesReader(writer, request.Body, 65536)\n\tbody, err := io.ReadAll(request.Body)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to parse the request body\", zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tvar notification *httpNotification\n\terr = yaml.Unmarshal(body, &notification)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to convert request payload into sns notification\", zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tif notification == nil {\n\t\tcommon.SendErrorResponse(writer, \"bad request, not a valid SNS notification\")\n\t\treturn\n\t}\n\n\t// SNS Signature Verification\n\tif router.eventSource.ValidateSignature {\n\t\terr = notification.verify()\n\t\tif err != nil {\n\t\t\tlogger.Errorw(\"failed to verify sns message\", zap.Error(err))\n\t\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\t\treturn\n\t\t}\n\t}\n\n\tswitch notification.Type {\n\tcase messageTypeSubscriptionConfirmation:\n\t\tawsSession := router.session\n\n\t\tresponse, err := awsSession.ConfirmSubscription(&snslib.ConfirmSubscriptionInput{\n\t\t\tTopicArn: &router.eventSource.TopicArn,\n\t\t\tToken:    &notification.Token,\n\t\t})\n\t\tif err != nil {\n\t\t\tlogger.Errorw(\"failed to send confirmation response to aws sns\", zap.Error(err))\n\t\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\t\treturn\n\t\t}\n\n\t\tlogger.Info(\"subscription successfully confirmed to aws sns\")\n\t\trouter.subscriptionArn = response.SubscriptionArn\n\n\tcase messageTypeNotification:\n\t\tlogger.Info(\"dispatching notification on route's data channel\")\n\n\t\teventData := &events.SNSEventData{\n\t\t\tHeader:   request.Header,\n\t\t\tBody:     (*json.RawMessage)(&body),\n\t\t\tMetadata: router.eventSource.Metadata,\n\t\t}\n\n\t\teventBytes, err := json.Marshal(eventData)\n\t\tif err != nil {\n\t\t\tlogger.Errorw(\"failed to marshal the event data\", zap.Error(err))\n\t\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\t\treturn\n\t\t}\n\t\troute.DataCh <- eventBytes\n\t}\n\n\tlogger.Info(\"request has been successfully processed\")\n}\n\n// PostActivate refers to operations performed after a route is successfully activated\nfunc (router *Router) PostActivate() error {\n\troute := router.Route\n\n\tlogger := route.Logger.With(\n\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\tlogging.LabelPort, route.Context.Port,\n\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t\t\"topic-arn\", router.eventSource.TopicArn,\n\t)\n\n\t// In order to successfully subscribe to sns topic,\n\t// 1. Fetch credentials if configured explicitly. Users can use something like https://github.com/jtblin/kube2iam\n\t//    which will help not configure creds explicitly.\n\t// 2. Get AWS session\n\t// 3. Subscribe to a topic\n\n\tlogger.Info(\"subscribing to sns topic...\")\n\n\tsnsEventSource := router.eventSource\n\n\tawsSession, err := commonaws.CreateAWSSessionWithCredsInVolume(snsEventSource.Region, snsEventSource.RoleARN, snsEventSource.AccessKey, snsEventSource.SecretKey)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\trouter.session = snslib.New(awsSession)\n\tformattedURL := common.FormattedURL(snsEventSource.Webhook.URL, snsEventSource.Webhook.Endpoint)\n\tif _, err := router.session.Subscribe(&snslib.SubscribeInput{\n\t\tEndpoint: &formattedURL,\n\t\tProtocol: func(endpoint string) *string {\n\t\t\tProtocol := \"http\"\n\t\t\tif matched, _ := regexp.MatchString(`https://.*`, endpoint); matched {\n\t\t\t\tProtocol = \"https\"\n\t\t\t\treturn &Protocol\n\t\t\t}\n\t\t\treturn &Protocol\n\t\t}(formattedURL),\n\t\tTopicArn: &snsEventSource.TopicArn,\n\t}); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\n// PostInactivate refers to operations performed after a route is successfully inactivated\nfunc (router *Router) PostInactivate() error {\n\t// After event source is removed, the subscription is cancelled.\n\tif _, err := router.session.Unsubscribe(&snslib.UnsubscribeInput{\n\t\tSubscriptionArn: router.subscriptionArn,\n\t}); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n\n// EventListener implements Eventing for aws sns event source\ntype EventListener struct {\n\tEventSourceName string\n\tEventName       string\n\tSNSEventSource  v1alpha1.SNSEventSource\n\tMetrics         *metrics.Metrics\n}\n\n// GetEventSourceName returns name of event source\nfunc (el *EventListener) GetEventSourceName() string {\n\treturn el.EventSourceName\n}\n\n// GetEventName returns name of event\nfunc (el *EventListener) GetEventName() string {\n\treturn el.EventName\n}\n\n// GetEventSourceType return type of event server\nfunc (el *EventListener) GetEventSourceType() apicommon.EventSourceType {\n\treturn apicommon.SNSEvent\n}\n\n// StartListening starts an SNS event source\nfunc (el *EventListener) StartListening(ctx context.Context, dispatch func([]byte, ...eventsourcecommon.Option) error) error {\n\tlogger := logging.FromContext(ctx).\n\t\tWith(logging.LabelEventSourceType, el.GetEventSourceType(), logging.LabelEventName, el.GetEventName())\n\n\tdefer sources.Recover(el.GetEventName())\n\n\tlogger.Info(\"started processing the AWS SNS event source...\")\n\n\troute := webhook.NewRoute(el.SNSEventSource.Webhook, logger, el.GetEventSourceName(), el.GetEventName(), el.Metrics)\n\n\tlogger.Info(\"operating on the route...\")\n\treturn webhook.ManageRoute(ctx, &Router{\n\t\tRoute:       route,\n\t\teventSource: &el.SNSEventSource,\n\t}, controller, dispatch)\n}\n\nfunc (m *httpNotification) verifySigningCertUrl() error {\n\tregexSigningCertHost := `^sns\\.[a-zA-Z0-9\\-]{3,}\\.amazonaws\\.com(\\.cn)?$`\n\tregex := regexp.MustCompile(regexSigningCertHost)\n\turl, err := url.Parse(m.SigningCertURL)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"SigningCertURL is not a valid URL\")\n\t}\n\tif !regex.MatchString(url.Hostname()) {\n\t\treturn errors.Errorf(\"SigningCertURL hostname `%s` does not match `%s`\", url.Hostname(), regexSigningCertHost)\n\t}\n\tif url.Scheme != \"https\" {\n\t\treturn errors.New(\"SigningCertURL is not using https\")\n\t}\n\treturn nil\n}\n\nfunc (m *httpNotification) verify() error {\n\tmsgSig, err := base64.StdEncoding.DecodeString(m.Signature)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"failed to base64 decode signature\")\n\t}\n\n\tif err := m.verifySigningCertUrl(); err != nil {\n\t\treturn errors.Wrap(err, \"failed to verify SigningCertURL\")\n\t}\n\n\tres, err := http.Get(m.SigningCertURL)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"failed to fetch signing cert\")\n\t}\n\tdefer res.Body.Close()\n\n\tbody, err := io.ReadAll(io.LimitReader(res.Body, 65536))\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"failed to read signing cert body\")\n\t}\n\n\tp, _ := pem.Decode(body)\n\tif p == nil {\n\t\treturn errors.New(\"nothing found in pem encoded bytes\")\n\t}\n\n\tcert, err := x509.ParseCertificate(p.Bytes)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"failed to parse signing cert\")\n\t}\n\n\terr = cert.CheckSignature(x509.SHA1WithRSA, m.sigSerialized(), msgSig)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"message signature check error\")\n\t}\n\n\treturn nil\n}\n\nfunc (m *httpNotification) sigSerialized() []byte {\n\tbuf := &bytes.Buffer{}\n\tv := reflect.ValueOf(m)\n\n\tfor _, key := range snsSigKeys[m.Type] {\n\t\tfield := reflect.Indirect(v).FieldByName(key)\n\t\tval := field.String()\n\t\tif !field.IsValid() || val == \"\" {\n\t\t\tcontinue\n\t\t}\n\t\tif rn, ok := snsKeyRealNames[key]; ok {\n\t\t\tkey = rn\n\t\t}\n\t\tbuf.WriteString(key + \"\\n\")\n\t\tbuf.WriteString(val + \"\\n\")\n\t}\n\n\treturn buf.Bytes()\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage awssns\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"must specify topic arn\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"aws-sns.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.SNS)\n\n\tfor _, value := range eventSource.Spec.SNS {\n\t\tl := &EventListener{\n\t\t\tSNSEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage awssqs\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{\n\t\tSQSEventSource: v1alpha1.SQSEventSource{\n\t\t\tRegion: \"test-reg\",\n\t\t},\n\t}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"must specify queue name\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"aws-sqs.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.SQS)\n\n\tfor _, value := range eventSource.Spec.SQS {\n\t\tl := &EventListener{\n\t\t\tSQSEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage azureeventshub\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"FQDN is not specified\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"azure-events-hub.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.AzureEventsHub)\n\n\tfor _, value := range eventSource.Spec.AzureEventsHub {\n\t\tl := &EventListener{\n\t\t\tAzureEventsHubEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage bitbucket\n\nimport (\n\t\"context\"\n\t\"crypto/rand\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"math/big\"\n\t\"net/http\"\n\t\"time\"\n\n\tbitbucketv2 \"github.com/ktrysmt/go-bitbucket\"\n\t\"github.com/mitchellh/mapstructure\"\n\t\"github.com/pkg/errors\"\n\t\"go.uber.org/zap\"\n\n\t\"github.com/argoproj/argo-events/common\"\n\t\"github.com/argoproj/argo-events/common/logging\"\n\teventsourcecommon \"github.com/argoproj/argo-events/eventsources/common\"\n\t\"github.com/argoproj/argo-events/eventsources/common/webhook\"\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/events\"\n)\n\n// controller controls the webhook operations\nvar (\n\tcontroller = webhook.NewController()\n)\n\n// set up the activation and inactivation channels to control the state of routes.\nfunc init() {\n\tgo webhook.ProcessRouteStatus(controller)\n}\n\n// Implement Router\n// 1. GetRoute\n// 2. HandleRoute\n// 3. PostActivate\n// 4. PostInactivate\n\n// GetRoute returns the route\nfunc (router *Router) GetRoute() *webhook.Route {\n\treturn router.route\n}\n\n// HandleRoute handles incoming requests on the route\nfunc (router *Router) HandleRoute(writer http.ResponseWriter, request *http.Request) {\n\troute := router.GetRoute()\n\tlogger := route.Logger.With(\n\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\tlogging.LabelPort, route.Context.Port,\n\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t)\n\n\tlogger.Info(\"received a request, processing it...\")\n\n\tif !route.Active {\n\t\tlogger.Info(\"endpoint is not active, won't process the request\")\n\t\tcommon.SendErrorResponse(writer, \"inactive endpoint\")\n\t\treturn\n\t}\n\n\trequest.Body = http.MaxBytesReader(writer, request.Body, 65536)\n\tbody, err := io.ReadAll(request.Body)\n\tif err != nil {\n\t\tlogger.Desugar().Error(\"failed to parse request body\", zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\treturn\n\t}\n\n\tevent := &events.BitbucketEventData{\n\t\tHeaders:  request.Header,\n\t\tBody:     (*json.RawMessage)(&body),\n\t\tMetadata: router.bitbucketEventSource.Metadata,\n\t}\n\n\teventBody, err := json.Marshal(event)\n\tif err != nil {\n\t\tlogger.Info(\"failed to marshal event\")\n\t\tcommon.SendErrorResponse(writer, \"invalid event\")\n\t\treturn\n\t}\n\n\tlogger.Info(\"dispatching event on route's data channel\")\n\troute.DataCh <- eventBody\n\n\tlogger.Info(\"request successfully processed\")\n\tcommon.SendSuccessResponse(writer, \"success\")\n}\n\n// PostActivate performs operations once the route is activated and ready to consume requests\nfunc (router *Router) PostActivate() error {\n\treturn nil\n}\n\n// PostInactivate performs operations after the route is inactivated\nfunc (router *Router) PostInactivate() error {\n\tbitbucketEventSource := router.bitbucketEventSource\n\tlogger := router.GetRoute().Logger\n\n\tif bitbucketEventSource.DeleteHookOnFinish && router.hookID != \"\" {\n\t\tlogger.Info(\"deleting webhook from bitbucket...\")\n\t\tif err := router.deleteWebhook(router.hookID); err != nil {\n\t\t\tlogger.Errorw(\"failed to delete webhook\", zap.Error(err))\n\t\t\treturn errors.Wrapf(err, \"failed to delete hook for repo %s/%s.\", bitbucketEventSource.Owner, bitbucketEventSource.RepositorySlug)\n\t\t}\n\n\t\tlogger.Infof(\"successfully deleted hook for repo %s/%s\", bitbucketEventSource.Owner, bitbucketEventSource.RepositorySlug)\n\t}\n\n\treturn nil\n}\n\n// StartListening starts an event source\nfunc (el *EventListener) StartListening(ctx context.Context, dispatch func([]byte, ...eventsourcecommon.Option) error) error {\n\tdefer sources.Recover(el.GetEventName())\n\n\tbitbucketEventSource := &el.BitbucketEventSource\n\tlogger := logging.FromContext(ctx).With(\n\t\tlogging.LabelEventSourceType, el.GetEventSourceType(),\n\t\tlogging.LabelEventName, el.GetEventName(),\n\t)\n\n\tlogger.Info(\"started processing the Bitbucket event source...\")\n\troute := webhook.NewRoute(bitbucketEventSource.Webhook, logger, el.GetEventSourceName(), el.GetEventName(), el.Metrics)\n\trouter := &Router{\n\t\troute:                route,\n\t\tbitbucketEventSource: bitbucketEventSource,\n\t}\n\n\tif !bitbucketEventSource.ShouldCreateWebhook() {\n\t\tlogger.Info(\"no need to create webhook\")\n\t\treturn webhook.ManageRoute(ctx, router, controller, dispatch)\n\t}\n\n\tlogger.Info(\"choosing bitbucket auth strategy...\")\n\tauthStrategy, err := router.chooseAuthStrategy()\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"failed to get bitbucket auth strategy\")\n\t}\n\n\trouter.client = authStrategy.BitbucketClient()\n\n\t// When running multiple replicas of the eventsource, they will all try to create the webhook.\n\t// Randomly sleep some time to mitigate the issue.\n\trandomNum, _ := rand.Int(rand.Reader, big.NewInt(int64(2000)))\n\ttime.Sleep(time.Duration(randomNum.Int64()) * time.Millisecond)\n\n\terr = router.applyBitbucketWebhook()\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to save Bitbucket webhook\", zap.Error(err))\n\t}\n\n\t// Bitbucket hooks manager daemon\n\tgo func() {\n\t\t// Another kind of race conditions might happen when pods do rolling upgrade - new pod starts\n\t\t// and old pod terminates, if DeleteHookOnFinish is true, the hook will be deleted from Bitbucket.\n\t\t// This is a workaround to mitigate the race conditions.\n\t\tlogger.Info(\"starting bitbucket hooks manager daemon\")\n\t\tticker := time.NewTicker(60 * time.Second)\n\t\tdefer ticker.Stop()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\tlogger.Info(\"exiting bitbucket hooks manager daemon\")\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t\terr := router.applyBitbucketWebhook()\n\t\t\t\tif err != nil {\n\t\t\t\t\tlogger.Errorw(\"failed to save Bitbucket webhook\", zap.Error(err))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn webhook.ManageRoute(ctx, router, controller, dispatch)\n}\n\n// chooseAuthStrategy returns an AuthStrategy based on the given credentials\nfunc (router *Router) chooseAuthStrategy() (AuthStrategy, error) {\n\tes := router.bitbucketEventSource\n\tswitch {\n\tcase es.HasBitbucketBasicAuth():\n\t\treturn NewBasicAuthStrategy(es.Auth.Basic.Username, es.Auth.Basic.Password)\n\tcase es.HasBitbucketOAuthToken():\n\t\treturn NewOAuthTokenAuthStrategy(es.Auth.OAuthToken)\n\tdefault:\n\t\treturn nil, errors.New(\"none of the supported auth options were provided\")\n\t}\n}\n\n// applyBitbucketWebhook creates or updates the configured webhook in Bitbucket\nfunc (router *Router) applyBitbucketWebhook() error {\n\tlogger := router.GetRoute().Logger\n\tbitbucketEventSource := router.bitbucketEventSource\n\tformattedWebhookURL := common.FormattedURL(bitbucketEventSource.Webhook.URL, bitbucketEventSource.Webhook.Endpoint)\n\n\tlogger.Info(\"listing existing webhooks...\")\n\thooks, err := router.listWebhooks()\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to list webhooks\", zap.Error(err))\n\t\treturn errors.Wrap(err, \"failed to list webhooks\")\n\t}\n\n\tlogger.Info(\"checking if webhook already exists...\")\n\texistingHookSubscription, isFound := router.findWebhook(hooks, formattedWebhookURL)\n\tif isFound {\n\t\tlogger.Info(\"webhook already exists\")\n\t\tif router.shouldUpdateWebhook(existingHookSubscription) {\n\t\t\tlogger.Info(\"webhook requires an update\")\n\t\t\tif _, err = router.updateWebhook(existingHookSubscription); err != nil {\n\t\t\t\tlogger.Errorw(\"failed to update webhook\", zap.Error(err))\n\t\t\t\treturn errors.Wrap(err, \"failed to update existing webhook\")\n\t\t\t}\n\n\t\t\tlogger.Info(\"successfully updated the webhook\")\n\t\t}\n\n\t\treturn nil\n\t}\n\n\tlogger.Info(\"webhook doesn't exist yet, creating a new webhook...\")\n\tnewWebhook, err := router.createWebhook(formattedWebhookURL)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to create new webhook\", zap.Error(err))\n\t\treturn errors.Wrap(err, \"failed to create new webhook\")\n\t}\n\n\trouter.hookID = newWebhook.Uuid\n\n\tlogger.Info(\"successfully created a new webhook\")\n\treturn nil\n}\n\n// createWebhook creates a new webhook\nfunc (router *Router) createWebhook(formattedWebhookURL string) (*bitbucketv2.Webhook, error) {\n\tes := router.bitbucketEventSource\n\topt := &bitbucketv2.WebhooksOptions{\n\t\tOwner:       es.Owner,\n\t\tRepoSlug:    es.RepositorySlug,\n\t\tUrl:         formattedWebhookURL,\n\t\tDescription: \"webhook managed by Argo-Events\",\n\t\tActive:      true,\n\t\tEvents:      es.Events,\n\t}\n\n\treturn router.client.Repositories.Webhooks.Create(opt)\n}\n\n// updateWebhook updates an existing webhook\nfunc (router *Router) updateWebhook(existingHookSubscription *WebhookSubscription) (*bitbucketv2.Webhook, error) {\n\tes := router.bitbucketEventSource\n\topt := &bitbucketv2.WebhooksOptions{\n\t\tOwner:       es.Owner,\n\t\tRepoSlug:    es.RepositorySlug,\n\t\tUuid:        existingHookSubscription.Uuid,\n\t\tDescription: existingHookSubscription.Description,\n\t\tUrl:         existingHookSubscription.Url,\n\t\tActive:      existingHookSubscription.Active,\n\t\tEvents:      es.Events,\n\t}\n\n\treturn router.client.Repositories.Webhooks.Update(opt)\n}\n\n// deleteWebhook deletes an existing webhook\nfunc (router *Router) deleteWebhook(hookID string) error {\n\tes := router.bitbucketEventSource\n\t_, err := router.client.Repositories.Webhooks.Delete(&bitbucketv2.WebhooksOptions{\n\t\tOwner:    es.Owner,\n\t\tRepoSlug: es.RepositorySlug,\n\t\tUuid:     hookID,\n\t})\n\n\treturn err\n}\n\n// listWebhooks gets a list of all existing webhooks in target repository\nfunc (router *Router) listWebhooks() ([]WebhookSubscription, error) {\n\tes := router.bitbucketEventSource\n\thooksResponse, err := router.client.Repositories.Webhooks.Gets(&bitbucketv2.WebhooksOptions{\n\t\tOwner:    es.Owner,\n\t\tRepoSlug: es.RepositorySlug,\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn router.extractHooksFromListResponse(hooksResponse)\n}\n\n// extractHooksFromListResponse helper that extracts the list of webhooks from the response of listWebhooks\nfunc (router *Router) extractHooksFromListResponse(listHooksResponse interface{}) ([]WebhookSubscription, error) {\n\tlogger := router.GetRoute().Logger\n\tres, ok := listHooksResponse.(map[string]interface{})\n\tif !ok {\n\t\tlogger.Errorw(\"failed to parse the list webhooks response\", zap.Any(\"response\", listHooksResponse))\n\t\treturn nil, fmt.Errorf(\"failed to parse the list webhooks response\")\n\t}\n\n\tvar hooks []WebhookSubscription\n\terr := mapstructure.Decode(res[\"values\"], &hooks)\n\tif err != nil || hooks == nil {\n\t\tlogger.Errorw(\"failed to parse the list webhooks response\", zap.Any(\"response\", listHooksResponse))\n\t\treturn nil, fmt.Errorf(\"failed to parse the list webhooks response\")\n\t}\n\n\treturn hooks, nil\n}\n\n// findWebhook searches for a webhook in a list by its URL and returns the webhook if its found\nfunc (router *Router) findWebhook(hooks []WebhookSubscription, targetWebhookURL string) (*WebhookSubscription, bool) {\n\tvar existingHookSubscription *WebhookSubscription\n\tisFound := false\n\tfor _, hook := range hooks {\n\t\tif hook.Url == targetWebhookURL {\n\t\t\tisFound = true\n\t\t\texistingHookSubscription = &hook\n\t\t\trouter.hookID = hook.Uuid\n\t\t\tbreak\n\t\t}\n\t}\n\n\treturn existingHookSubscription, isFound\n}\n\nfunc (router *Router) shouldUpdateWebhook(existingHookSubscription *WebhookSubscription) bool {\n\toldEvents := existingHookSubscription.Events\n\tnewEvents := router.bitbucketEventSource.Events\n\n\treturn !common.ElementsMatch(oldEvents, newEvents)\n}\n", "/*\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage bitbucket\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"project key can't be empty\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"bitbucket.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Bitbucket)\n\n\tfor name, value := range eventSource.Spec.Bitbucket {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tBitbucketEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage bitbucketserver\n\nimport (\n\t\"context\"\n\t\"crypto/hmac\"\n\t\"crypto/rand\"\n\t\"crypto/sha256\"\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"io\"\n\t\"math/big\"\n\t\"net/http\"\n\t\"time\"\n\n\tbitbucketv1 \"github.com/gfleury/go-bitbucket-v1\"\n\t\"github.com/mitchellh/mapstructure\"\n\n\t\"github.com/argoproj/argo-events/common\"\n\t\"github.com/argoproj/argo-events/common/logging\"\n\teventsourcecommon \"github.com/argoproj/argo-events/eventsources/common\"\n\t\"github.com/argoproj/argo-events/eventsources/common/webhook\"\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/events\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/pkg/errors\"\n\t\"go.uber.org/zap\"\n)\n\n// controller controls the webhook operations\nvar (\n\tcontroller = webhook.NewController()\n)\n\n// set up the activation and inactivation channels to control the state of routes.\nfunc init() {\n\tgo webhook.ProcessRouteStatus(controller)\n}\n\n// Implement Router\n// 1. GetRoute\n// 2. HandleRoute\n// 3. PostActivate\n// 4. PostDeactivate\n\n// GetRoute returns the route\nfunc (router *Router) GetRoute() *webhook.Route {\n\treturn router.route\n}\n\n// HandleRoute handles incoming requests on the route\nfunc (router *Router) HandleRoute(writer http.ResponseWriter, request *http.Request) {\n\troute := router.GetRoute()\n\n\tlogger := route.Logger.With(\n\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\tlogging.LabelPort, route.Context.Port,\n\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t)\n\n\tlogger.Info(\"received a request, processing it...\")\n\n\tif !route.Active {\n\t\tlogger.Info(\"endpoint is not active, won't process the request\")\n\t\tcommon.SendErrorResponse(writer, \"inactive endpoint\")\n\t\treturn\n\t}\n\n\tdefer func(start time.Time) {\n\t\troute.Metrics.EventProcessingDuration(route.EventSourceName, route.EventName, float64(time.Since(start)/time.Millisecond))\n\t}(time.Now())\n\n\tbody, err := router.parseAndValidateBitbucketServerRequest(writer, request)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to parse/validate request\", zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tevent := &events.BitbucketServerEventData{\n\t\tHeaders:  request.Header,\n\t\tBody:     (*json.RawMessage)(&body),\n\t\tMetadata: router.bitbucketserverEventSource.Metadata,\n\t}\n\n\teventBody, err := json.Marshal(event)\n\tif err != nil {\n\t\tlogger.Info(\"failed to marshal event\")\n\t\tcommon.SendErrorResponse(writer, \"invalid event\")\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tlogger.Info(\"dispatching event on route's data channel\")\n\troute.DataCh <- eventBody\n\n\tlogger.Info(\"request successfully processed\")\n\tcommon.SendSuccessResponse(writer, \"success\")\n}\n\n// PostActivate performs operations once the route is activated and ready to consume requests\nfunc (router *Router) PostActivate() error {\n\treturn nil\n}\n\n// PostInactivate performs operations after the route is inactivated\nfunc (router *Router) PostInactivate() error {\n\tbitbucketserverEventSource := router.bitbucketserverEventSource\n\troute := router.route\n\tlogger := route.Logger\n\n\tif bitbucketserverEventSource.DeleteHookOnFinish && len(router.hookIDs) > 0 {\n\t\tlogger.Info(\"deleting webhooks from bitbucket\")\n\n\t\tbitbucketToken, err := common.GetSecretFromVolume(bitbucketserverEventSource.AccessToken)\n\t\tif err != nil {\n\t\t\treturn errors.Errorf(\"failed to get bitbucketserver token. err: %+v\", err)\n\t\t}\n\n\t\tbitbucketConfig := bitbucketv1.NewConfiguration(bitbucketserverEventSource.BitbucketServerBaseURL)\n\t\tbitbucketConfig.AddDefaultHeader(\"x-atlassian-token\", \"no-check\")\n\t\tbitbucketConfig.AddDefaultHeader(\"x-requested-with\", \"XMLHttpRequest\")\n\n\t\tfor _, repo := range bitbucketserverEventSource.GetBitbucketServerRepositories() {\n\t\t\tid, ok := router.hookIDs[repo.ProjectKey+\",\"+repo.RepositorySlug]\n\t\t\tif !ok {\n\t\t\t\treturn errors.Errorf(\"can not find hook ID for project-key: %s, repository-slug: %s\", repo.ProjectKey, repo.RepositorySlug)\n\t\t\t}\n\n\t\t\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\n\t\t\tdefer cancel()\n\n\t\t\tctx = context.WithValue(ctx, bitbucketv1.ContextAccessToken, bitbucketToken)\n\t\t\tbitbucketClient := bitbucketv1.NewAPIClient(ctx, bitbucketConfig)\n\n\t\t\t_, err = bitbucketClient.DefaultApi.DeleteWebhook(repo.ProjectKey, repo.RepositorySlug, int32(id))\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Errorf(\"failed to delete bitbucketserver webhook. err: %+v\", err)\n\t\t\t}\n\n\t\t\tlogger.Infow(\"bitbucket server webhook deleted\",\n\t\t\t\tzap.String(\"project-key\", repo.ProjectKey), zap.String(\"repository-slug\", repo.RepositorySlug))\n\t\t}\n\t} else {\n\t\tlogger.Info(\"no need to delete webhooks, skipping.\")\n\t}\n\n\treturn nil\n}\n\n// StartListening starts an event source\nfunc (el *EventListener) StartListening(ctx context.Context, dispatch func([]byte, ...eventsourcecommon.Option) error) error {\n\tdefer sources.Recover(el.GetEventName())\n\n\tbitbucketserverEventSource := &el.BitbucketServerEventSource\n\n\tlogger := logging.FromContext(ctx).With(\n\t\tlogging.LabelEventSourceType, el.GetEventSourceType(),\n\t\tlogging.LabelEventName, el.GetEventName(),\n\t\t\"base-url\", bitbucketserverEventSource.BitbucketServerBaseURL,\n\t)\n\n\tlogger.Info(\"started processing the Bitbucket Server event source...\")\n\n\troute := webhook.NewRoute(bitbucketserverEventSource.Webhook, logger, el.GetEventSourceName(), el.GetEventName(), el.Metrics)\n\trouter := &Router{\n\t\troute:                      route,\n\t\tbitbucketserverEventSource: bitbucketserverEventSource,\n\t\thookIDs:                    make(map[string]int),\n\t}\n\n\tlogger.Info(\"retrieving the access token credentials...\")\n\tbitbucketToken, err := common.GetSecretFromVolume(bitbucketserverEventSource.AccessToken)\n\tif err != nil {\n\t\treturn errors.Errorf(\"failed to get bitbucketserver token. err: %+v\", err)\n\t}\n\n\tif bitbucketserverEventSource.WebhookSecret != nil {\n\t\tlogger.Info(\"retrieving the webhook secret...\")\n\t\twebhookSecret, err := common.GetSecretFromVolume(bitbucketserverEventSource.WebhookSecret)\n\t\tif err != nil {\n\t\t\treturn errors.Errorf(\"failed to get bitbucketserver webhook secret. err: %+v\", err)\n\t\t}\n\n\t\trouter.hookSecret = webhookSecret\n\t}\n\n\tlogger.Info(\"setting up the client to connect to Bitbucket Server...\")\n\tbitbucketConfig := bitbucketv1.NewConfiguration(bitbucketserverEventSource.BitbucketServerBaseURL)\n\tbitbucketConfig.AddDefaultHeader(\"x-atlassian-token\", \"no-check\")\n\tbitbucketConfig.AddDefaultHeader(\"x-requested-with\", \"XMLHttpRequest\")\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\tctx = context.WithValue(ctx, bitbucketv1.ContextAccessToken, bitbucketToken)\n\n\tapplyWebhooks := func() {\n\t\tfor _, repo := range bitbucketserverEventSource.GetBitbucketServerRepositories() {\n\t\t\tif err = router.applyBitbucketServerWebhook(ctx, bitbucketConfig, repo); err != nil {\n\t\t\t\tlogger.Errorw(\"failed to create/update Bitbucket webhook\",\n\t\t\t\t\tzap.String(\"project-key\", repo.ProjectKey), zap.String(\"repository-slug\", repo.RepositorySlug), zap.Error(err))\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\ttime.Sleep(500 * time.Millisecond)\n\t\t}\n\t}\n\n\t// When running multiple replicas of the eventsource, they will all try to create the webhook.\n\t// Randomly sleep some time to mitigate the issue.\n\trandomNum, _ := rand.Int(rand.Reader, big.NewInt(int64(2000)))\n\ttime.Sleep(time.Duration(randomNum.Int64()) * time.Millisecond)\n\tapplyWebhooks()\n\n\tgo func() {\n\t\t// Another kind of race conditions might happen when pods do rolling upgrade - new pod starts\n\t\t// and old pod terminates, if DeleteHookOnFinish is true, the hook will be deleted from Bitbucket.\n\t\t// This is a workaround to mitigate the race conditions.\n\t\tlogger.Info(\"starting bitbucket hooks manager daemon\")\n\t\tticker := time.NewTicker(60 * time.Second)\n\t\tdefer ticker.Stop()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\tlogger.Info(\"exiting bitbucket hooks manager daemon\")\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t\tapplyWebhooks()\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn webhook.ManageRoute(ctx, router, controller, dispatch)\n}\n\n// applyBitbucketServerWebhook creates or updates the configured webhook in Bitbucket\nfunc (router *Router) applyBitbucketServerWebhook(ctx context.Context, bitbucketConfig *bitbucketv1.Configuration, repo v1alpha1.BitbucketServerRepository) error {\n\tbitbucketserverEventSource := router.bitbucketserverEventSource\n\troute := router.route\n\n\tlogger := route.Logger.With(\n\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\tlogging.LabelPort, route.Context.Port,\n\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t\t\"project-key\", repo.ProjectKey,\n\t\t\"repository-slug\", repo.RepositorySlug,\n\t\t\"base-url\", bitbucketserverEventSource.BitbucketServerBaseURL,\n\t)\n\n\tbitbucketClient := bitbucketv1.NewAPIClient(ctx, bitbucketConfig)\n\tformattedURL := common.FormattedURL(bitbucketserverEventSource.Webhook.URL, bitbucketserverEventSource.Webhook.Endpoint)\n\n\thooks, err := router.listWebhooks(bitbucketClient, repo)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"failed to list existing hooks to check for duplicates for repository %s/%s\", repo.ProjectKey, repo.RepositorySlug)\n\t}\n\n\tvar existingHook bitbucketv1.Webhook\n\tisAlreadyExists := false\n\n\tfor _, hook := range hooks {\n\t\tif hook.Url == formattedURL {\n\t\t\tisAlreadyExists = true\n\t\t\texistingHook = hook\n\t\t\trouter.hookIDs[repo.ProjectKey+\",\"+repo.RepositorySlug] = hook.ID\n\t\t\tbreak\n\t\t}\n\t}\n\n\tnewHook := bitbucketv1.Webhook{\n\t\tName:          \"Argo Events\",\n\t\tUrl:           formattedURL,\n\t\tActive:        true,\n\t\tEvents:        bitbucketserverEventSource.Events,\n\t\tConfiguration: bitbucketv1.WebhookConfiguration{Secret: router.hookSecret},\n\t}\n\n\trequestBody, err := router.createRequestBodyFromWebhook(newHook)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"failed to create request body from webhook\")\n\t}\n\n\t// Update the webhook when it does exist and the events/configuration have changed\n\tif isAlreadyExists {\n\t\tlogger.Info(\"webhook already exists\")\n\t\tif router.shouldUpdateWebhook(existingHook, newHook) {\n\t\t\tlogger.Info(\"webhook requires an update\")\n\t\t\terr = router.updateWebhook(bitbucketClient, existingHook.ID, requestBody, repo)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Errorf(\"failed to update webhook. err: %+v\", err)\n\t\t\t}\n\n\t\t\tlogger.With(\"hook-id\", existingHook.ID).Info(\"hook successfully updated\")\n\t\t}\n\n\t\treturn nil\n\t}\n\n\t// Create the webhook when it doesn't exist yet\n\tcreatedHook, err := router.createWebhook(bitbucketClient, requestBody, repo)\n\tif err != nil {\n\t\treturn errors.Errorf(\"failed to create webhook. err: %+v\", err)\n\t}\n\n\trouter.hookIDs[repo.ProjectKey+\",\"+repo.RepositorySlug] = createdHook.ID\n\n\tlogger.With(\"hook-id\", createdHook.ID).Info(\"hook successfully registered\")\n\n\treturn nil\n}\n\nfunc (router *Router) listWebhooks(bitbucketClient *bitbucketv1.APIClient, repo v1alpha1.BitbucketServerRepository) ([]bitbucketv1.Webhook, error) {\n\tapiResponse, err := bitbucketClient.DefaultApi.FindWebhooks(repo.ProjectKey, repo.RepositorySlug, nil)\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"failed to list existing hooks to check for duplicates for repository %s/%s\", repo.ProjectKey, repo.RepositorySlug)\n\t}\n\n\thooks, err := bitbucketv1.GetWebhooksResponse(apiResponse)\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"failed to convert the list of webhooks for repository %s/%s\", repo.ProjectKey, repo.RepositorySlug)\n\t}\n\n\treturn hooks, nil\n}\n\nfunc (router *Router) createWebhook(bitbucketClient *bitbucketv1.APIClient, requestBody []byte, repo v1alpha1.BitbucketServerRepository) (*bitbucketv1.Webhook, error) {\n\tapiResponse, err := bitbucketClient.DefaultApi.CreateWebhook(repo.ProjectKey, repo.RepositorySlug, requestBody, []string{\"application/json\"})\n\tif err != nil {\n\t\treturn nil, errors.Errorf(\"failed to add webhook. err: %+v\", err)\n\t}\n\n\tvar createdHook *bitbucketv1.Webhook\n\terr = mapstructure.Decode(apiResponse.Values, &createdHook)\n\tif err != nil {\n\t\treturn nil, errors.Errorf(\"failed to convert API response to Webhook struct. err: %+v\", err)\n\t}\n\n\treturn createdHook, nil\n}\n\nfunc (router *Router) updateWebhook(bitbucketClient *bitbucketv1.APIClient, hookID int, requestBody []byte, repo v1alpha1.BitbucketServerRepository) error {\n\t_, err := bitbucketClient.DefaultApi.UpdateWebhook(repo.ProjectKey, repo.RepositorySlug, int32(hookID), requestBody, []string{\"application/json\"})\n\n\treturn err\n}\n\nfunc (router *Router) shouldUpdateWebhook(existingHook bitbucketv1.Webhook, newHook bitbucketv1.Webhook) bool {\n\treturn !common.ElementsMatch(existingHook.Events, newHook.Events) ||\n\t\texistingHook.Configuration.Secret != newHook.Configuration.Secret\n}\n\nfunc (router *Router) createRequestBodyFromWebhook(hook bitbucketv1.Webhook) ([]byte, error) {\n\tvar err error\n\tvar finalHook interface{} = hook\n\n\t// if the hook doesn't have a secret, the configuration field must be removed in order for the request to succeed,\n\t// otherwise Bitbucket Server sends 500 response because of empty string value in the hook.Configuration.Secret field\n\tif hook.Configuration.Secret == \"\" {\n\t\thookMap := make(map[string]interface{})\n\t\terr = common.StructToMap(hook, hookMap)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"failed to convert webhook to map\")\n\t\t}\n\n\t\tdelete(hookMap, \"configuration\")\n\n\t\tfinalHook = hookMap\n\t}\n\n\trequestBody, err := json.Marshal(finalHook)\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"failed to marshal new webhook to JSON\")\n\t}\n\n\treturn requestBody, nil\n}\n\nfunc (router *Router) parseAndValidateBitbucketServerRequest(writer http.ResponseWriter, request *http.Request) ([]byte, error) {\n\trequest.Body = http.MaxBytesReader(writer, request.Body, 65536)\n\tbody, err := io.ReadAll(request.Body)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to parse request body\")\n\t}\n\n\tif len(router.hookSecret) != 0 {\n\t\tsignature := request.Header.Get(\"X-Hub-Signature\")\n\t\tif len(signature) == 0 {\n\t\t\treturn nil, errors.New(\"missing signature header\")\n\t\t}\n\n\t\tmac := hmac.New(sha256.New, []byte(router.hookSecret))\n\t\t_, _ = mac.Write(body)\n\t\texpectedMAC := hex.EncodeToString(mac.Sum(nil))\n\n\t\tif !hmac.Equal([]byte(signature[7:]), []byte(expectedMAC)) {\n\t\t\treturn nil, errors.New(\"hmac verification failed\")\n\t\t}\n\t}\n\n\treturn body, nil\n}\n", "/*\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage bitbucketserver\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"at least one repository is required\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"bitbucketserver.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.BitbucketServer)\n\n\tfor name, value := range eventSource.Spec.BitbucketServer {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tBitbucketServerEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage calendar\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{\n\t\tCalendarEventSource: v1alpha1.CalendarEventSource{\n\t\t\t// Schedule: \"* * * * *\"\n\t\t},\n\t}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"must have either schedule or interval\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"calendar.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Calendar)\n\n\tfor _, value := range eventSource.Spec.Calendar {\n\t\tl := &EventListener{\n\t\t\tCalendarEventSource: value,\n\t\t}\n\t\terr = l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage emitter\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"broker url must be specified\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"emitter.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Emitter)\n\n\tfor _, value := range eventSource.Spec.Emitter {\n\t\tl := &EventListener{\n\t\t\tEmitterEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage file\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"type must be specified\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"file.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.File)\n\n\tfor _, value := range eventSource.Spec.File {\n\t\tl := &EventListener{\n\t\t\tFileEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage gcppubsub\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"must specify topic or subscriptionID\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"gcp-pubsub.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.PubSub)\n\n\tfor name, value := range eventSource.Spec.PubSub {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tPubSubEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "package generic\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestEventListener_ValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"server url can't be empty\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"generic.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Generic)\n\n\tfor name, value := range eventSource.Spec.Generic {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tGenericEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage github\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"io\"\n\t\"net/http\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/smartystreets/goconvey/convey\"\n\tcorev1 \"k8s.io/api/core/v1\"\n\n\t\"github.com/argoproj/argo-events/eventsources/common/webhook\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nvar (\n\trouter = &Router{\n\t\troute:             webhook.GetFakeRoute(),\n\t\tgithubEventSource: &v1alpha1.GithubEventSource{},\n\t}\n)\n\nfunc TestRouteActiveHandler(t *testing.T) {\n\tconvey.Convey(\"Given a route configuration\", t, func() {\n\t\troute := router.route\n\t\troute.DataCh = make(chan []byte)\n\n\t\tconvey.Convey(\"Inactive route should return error\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\tgithubEventSource := &v1alpha1.GithubEventSource{\n\t\t\t\tWebhook: &v1alpha1.WebhookContext{\n\t\t\t\t\tEndpoint: \"/push\",\n\t\t\t\t\tURL:      \"http://webhook-gateway-svc\",\n\t\t\t\t\tPort:     \"12000\",\n\t\t\t\t},\n\t\t\t\tRepositories: []v1alpha1.OwnedRepositories{\n\t\t\t\t\t{\n\t\t\t\t\t\tOwner: \"fake\",\n\t\t\t\t\t\tNames: []string{\n\t\t\t\t\t\t\t\"fake0\", \"fake1\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tEvents: []string{\n\t\t\t\t\t\"PushEvent\",\n\t\t\t\t},\n\t\t\t\tAPIToken: &corev1.SecretKeySelector{\n\t\t\t\t\tKey: \"accessKey\",\n\t\t\t\t\tLocalObjectReference: corev1.LocalObjectReference{\n\t\t\t\t\t\tName: \"github-access\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tbody, err := yaml.Marshal(githubEventSource)\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tBody: io.NopCloser(bytes.NewReader(body)),\n\t\t\t})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusBadRequest)\n\n\t\t\tconvey.Convey(\"Active route should return success\", func() {\n\t\t\t\troute.Active = true\n\n\t\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\t\tBody: io.NopCloser(bytes.NewReader(body)),\n\t\t\t\t})\n\n\t\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusBadRequest)\n\t\t\t})\n\t\t})\n\t})\n}\n\nfunc TestRouteActiveHandlerDeprecated(t *testing.T) {\n\tconvey.Convey(\"Given a route configuration\", t, func() {\n\t\troute := router.route\n\t\troute.DataCh = make(chan []byte)\n\n\t\tconvey.Convey(\"Inactive route should return error\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\tgithubEventSource := &v1alpha1.GithubEventSource{\n\t\t\t\tWebhook: &v1alpha1.WebhookContext{\n\t\t\t\t\tEndpoint: \"/push\",\n\t\t\t\t\tURL:      \"http://webhook-gateway-svc\",\n\t\t\t\t\tPort:     \"12000\",\n\t\t\t\t},\n\t\t\t\tDeprecatedOwner:      \"fake\",\n\t\t\t\tDeprecatedRepository: \"fake\",\n\t\t\t\tEvents: []string{\n\t\t\t\t\t\"PushEvent\",\n\t\t\t\t},\n\t\t\t\tAPIToken: &corev1.SecretKeySelector{\n\t\t\t\t\tKey: \"accessKey\",\n\t\t\t\t\tLocalObjectReference: corev1.LocalObjectReference{\n\t\t\t\t\t\tName: \"github-access\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tbody, err := yaml.Marshal(githubEventSource)\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tBody: io.NopCloser(bytes.NewReader(body)),\n\t\t\t})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusBadRequest)\n\n\t\t\tconvey.Convey(\"Active route should return success\", func() {\n\t\t\t\troute.Active = true\n\n\t\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\t\tBody: io.NopCloser(bytes.NewReader(body)),\n\t\t\t\t})\n\n\t\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusBadRequest)\n\t\t\t})\n\t\t})\n\t})\n}\n\nfunc TestAddEventTypeBody(t *testing.T) {\n\tconvey.Convey(\"Given a request\", t, func() {\n\t\tvar (\n\t\t\tbuf        = bytes.NewBuffer([]byte(`{ \"hello\": \"world\" }`))\n\t\t\teventType  = \"PushEvent\"\n\t\t\tdeliveryID = \"131C7C9B-A571-4F60-9ACA-EA3ADA19FABE\"\n\t\t)\n\t\trequest, err := http.NewRequest(\"POST\", \"http://example.com\", buf)\n\t\tconvey.So(err, convey.ShouldBeNil)\n\t\trequest.Header.Set(\"X-GitHub-Event\", eventType)\n\t\trequest.Header.Set(\"X-GitHub-Delivery\", deliveryID)\n\t\trequest.Header.Set(\"Content-Type\", \"application/json\")\n\n\t\tconvey.Convey(\"Delivery headers should be written to message\", func() {\n\t\t\tbody, err := parseValidateRequest(request, []byte{})\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\t\t\tpayload := make(map[string]interface{})\n\t\t\terr = json.Unmarshal(body, &payload)\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\t\t\tconvey.So(payload[\"X-GitHub-Event\"], convey.ShouldEqual, eventType)\n\t\t\tconvey.So(payload[\"X-GitHub-Delivery\"], convey.ShouldEqual, deliveryID)\n\t\t})\n\t})\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage github\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"either repositories or organizations is required\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"github.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Github)\n\n\tfor name, value := range eventSource.Spec.Github {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tGithubEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage gitlab\n\nimport (\n\t\"context\"\n\t\"crypto/rand\"\n\t\"encoding/json\"\n\t\"io\"\n\t\"math/big\"\n\t\"net/http\"\n\t\"reflect\"\n\t\"time\"\n\n\t\"github.com/argoproj/argo-events/common\"\n\t\"github.com/argoproj/argo-events/common/logging\"\n\teventsourcecommon \"github.com/argoproj/argo-events/eventsources/common\"\n\t\"github.com/argoproj/argo-events/eventsources/common/webhook\"\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/events\"\n\t\"github.com/pkg/errors\"\n\t\"github.com/xanzy/go-gitlab\"\n\t\"go.uber.org/zap\"\n)\n\n// controller controls the webhook operations\nvar (\n\tcontroller = webhook.NewController()\n)\n\n// set up the activation and inactivation channels to control the state of routes.\nfunc init() {\n\tgo webhook.ProcessRouteStatus(controller)\n}\n\n// Implement Router\n// 1. GetRoute\n// 2. HandleRoute\n// 3. PostActivate\n// 4. PostDeactivate\n\n// GetRoute returns the route\nfunc (router *Router) GetRoute() *webhook.Route {\n\treturn router.route\n}\n\n// HandleRoute handles incoming requests on the route\nfunc (router *Router) HandleRoute(writer http.ResponseWriter, request *http.Request) {\n\troute := router.GetRoute()\n\n\tlogger := route.Logger.With(\n\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\tlogging.LabelPort, route.Context.Port,\n\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t)\n\n\tlogger.Info(\"received a request, processing it...\")\n\n\tif !route.Active {\n\t\tlogger.Info(\"endpoint is not active, won't process the request\")\n\t\tcommon.SendErrorResponse(writer, \"inactive endpoint\")\n\t\treturn\n\t}\n\n\tdefer func(start time.Time) {\n\t\troute.Metrics.EventProcessingDuration(route.EventSourceName, route.EventName, float64(time.Since(start)/time.Millisecond))\n\t}(time.Now())\n\n\tif router.secretToken != \"\" {\n\t\tif t := request.Header.Get(\"X-Gitlab-Token\"); t != router.secretToken {\n\t\t\tcommon.SendErrorResponse(writer, \"token mismatch\")\n\t\t\treturn\n\t\t}\n\t}\n\trequest.Body = http.MaxBytesReader(writer, request.Body, 65536)\n\tbody, err := io.ReadAll(request.Body)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to parse request body\", zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tevent := &events.GitLabEventData{\n\t\tHeaders:  request.Header,\n\t\tBody:     (*json.RawMessage)(&body),\n\t\tMetadata: router.gitlabEventSource.Metadata,\n\t}\n\n\teventBody, err := json.Marshal(event)\n\tif err != nil {\n\t\tlogger.Info(\"failed to marshal event\")\n\t\tcommon.SendErrorResponse(writer, \"invalid event\")\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tlogger.Info(\"dispatching event on route's data channel\")\n\troute.DataCh <- eventBody\n\n\tlogger.Info(\"request successfully processed\")\n\tcommon.SendSuccessResponse(writer, \"success\")\n}\n\n// PostActivate performs operations once the route is activated and ready to consume requests\nfunc (router *Router) PostActivate() error {\n\treturn nil\n}\n\n// PostInactivate performs operations after the route is inactivated\nfunc (router *Router) PostInactivate() error {\n\tgitlabEventSource := router.gitlabEventSource\n\tif !gitlabEventSource.NeedToCreateHooks() || !gitlabEventSource.DeleteHookOnFinish {\n\t\treturn nil\n\t}\n\n\tlogger := router.route.Logger\n\tlogger.Info(\"deleting Gitlab hooks...\")\n\n\tfor _, p := range gitlabEventSource.GetProjects() {\n\t\tid, ok := router.hookIDs[p]\n\t\tif !ok {\n\t\t\treturn errors.Errorf(\"can not find hook ID for project %s\", p)\n\t\t}\n\t\tif _, err := router.gitlabClient.Projects.DeleteProjectHook(p, id); err != nil {\n\t\t\treturn errors.Errorf(\"failed to delete hook for project %s. err: %+v\", p, err)\n\t\t}\n\t\tlogger.Infof(\"Gitlab hook deleted for project %s\", p)\n\t}\n\treturn nil\n}\n\n// StartListening starts an event source\nfunc (el *EventListener) StartListening(ctx context.Context, dispatch func([]byte, ...eventsourcecommon.Option) error) error {\n\tlogger := logging.FromContext(ctx).\n\t\tWith(logging.LabelEventSourceType, el.GetEventSourceType(), logging.LabelEventName, el.GetEventName())\n\tlogger.Info(\"started processing the Gitlab event source...\")\n\n\tdefer sources.Recover(el.GetEventName())\n\n\tgitlabEventSource := &el.GitlabEventSource\n\n\troute := webhook.NewRoute(gitlabEventSource.Webhook, logger, el.GetEventSourceName(), el.GetEventName(), el.Metrics)\n\trouter := &Router{\n\t\troute:             route,\n\t\tgitlabEventSource: gitlabEventSource,\n\t}\n\n\tif gitlabEventSource.NeedToCreateHooks() {\n\t\t// In order to set up a hook for the GitLab project,\n\t\t// 1. Get the API access token for client\n\t\t// 2. Set up GitLab client\n\t\t// 3. Configure Hook with given event type\n\t\t// 4. Create project hook\n\n\t\tlogger.Info(\"retrieving the access token credentials...\")\n\n\t\tdefaultEventValue := false\n\t\tformattedURL := common.FormattedURL(gitlabEventSource.Webhook.URL, gitlabEventSource.Webhook.Endpoint)\n\t\topt := &gitlab.AddProjectHookOptions{\n\t\t\tURL:                      &formattedURL,\n\t\t\tEnableSSLVerification:    &router.gitlabEventSource.EnableSSLVerification,\n\t\t\tConfidentialNoteEvents:   &defaultEventValue,\n\t\t\tPushEvents:               &defaultEventValue,\n\t\t\tIssuesEvents:             &defaultEventValue,\n\t\t\tConfidentialIssuesEvents: &defaultEventValue,\n\t\t\tMergeRequestsEvents:      &defaultEventValue,\n\t\t\tTagPushEvents:            &defaultEventValue,\n\t\t\tNoteEvents:               &defaultEventValue,\n\t\t\tJobEvents:                &defaultEventValue,\n\t\t\tPipelineEvents:           &defaultEventValue,\n\t\t\tWikiPageEvents:           &defaultEventValue,\n\t\t}\n\n\t\tfor _, event := range gitlabEventSource.Events {\n\t\t\telem := reflect.ValueOf(opt).Elem().FieldByName(event)\n\t\t\tif ok := elem.IsValid(); !ok {\n\t\t\t\treturn errors.Errorf(\"unknown event %s\", event)\n\t\t\t}\n\t\t\tiev := reflect.New(elem.Type().Elem())\n\t\t\treflect.Indirect(iev).SetBool(true)\n\t\t\telem.Set(iev)\n\t\t}\n\n\t\tif gitlabEventSource.SecretToken != nil {\n\t\t\ttoken, err := common.GetSecretFromVolume(gitlabEventSource.SecretToken)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Errorf(\"failed to retrieve secret token. err: %+v\", err)\n\t\t\t}\n\t\t\topt.Token = &token\n\t\t\trouter.secretToken = token\n\t\t}\n\n\t\taccessToken, err := common.GetSecretFromVolume(gitlabEventSource.AccessToken)\n\t\tif err != nil {\n\t\t\treturn errors.Errorf(\"failed to get gitlab credentials. err: %+v\", err)\n\t\t}\n\n\t\tlogger.Info(\"setting up the client to connect to GitLab...\")\n\t\trouter.gitlabClient, err = gitlab.NewClient(accessToken, gitlab.WithBaseURL(gitlabEventSource.GitlabBaseURL))\n\t\tif err != nil {\n\t\t\treturn errors.Wrapf(err, \"failed to initialize client\")\n\t\t}\n\n\t\tgetHook := func(hooks []*gitlab.ProjectHook, url string) *gitlab.ProjectHook {\n\t\t\tfor _, h := range hooks {\n\t\t\t\tif h.URL != url {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\treturn h\n\t\t\t}\n\t\t\treturn nil\n\t\t}\n\n\t\trouter.hookIDs = make(map[string]int)\n\n\t\tf := func() {\n\t\t\tfor _, p := range gitlabEventSource.GetProjects() {\n\t\t\t\thooks, _, err := router.gitlabClient.Projects.ListProjectHooks(p, &gitlab.ListProjectHooksOptions{})\n\t\t\t\tif err != nil {\n\t\t\t\t\tlogger.Errorf(\"failed to list existing webhooks of project %s. err: %+v\", p, err)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\thook := getHook(hooks, formattedURL)\n\t\t\t\tif hook != nil {\n\t\t\t\t\trouter.hookIDs[p] = hook.ID\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tlogger.Infof(\"hook not found for project %s, creating ...\", p)\n\t\t\t\thook, _, err = router.gitlabClient.Projects.AddProjectHook(p, opt)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlogger.Errorf(\"failed to create gitlab webhook for project %s. err: %+v\", p, err)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\trouter.hookIDs[p] = hook.ID\n\t\t\t\ttime.Sleep(500 * time.Millisecond)\n\t\t\t}\n\t\t}\n\n\t\t// Mitigate race condtions - it might create multiple hooks with same config when replicas > 1\n\t\trandomNum, _ := rand.Int(rand.Reader, big.NewInt(int64(2000)))\n\t\ttime.Sleep(time.Duration(randomNum.Int64()) * time.Millisecond)\n\t\tf()\n\n\t\tctx, cancel := context.WithCancel(ctx)\n\t\tdefer cancel()\n\n\t\tgo func() {\n\t\t\t// Another kind of race conditions might happen when pods do rolling upgrade - new pod starts\n\t\t\t// and old pod terminates, if DeleteHookOnFinish is true, the hook will be deleted from gitlab.\n\t\t\t// This is a workround to mitigate the race conditions.\n\t\t\tlogger.Info(\"starting gitlab hooks manager daemon\")\n\t\t\tticker := time.NewTicker(60 * time.Second)\n\t\t\tdefer ticker.Stop()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\tlogger.Info(\"exiting gitlab hooks manager daemon\")\n\t\t\t\t\treturn\n\t\t\t\tcase <-ticker.C:\n\t\t\t\t\tf()\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t} else {\n\t\tlogger.Info(\"no need to create webhooks\")\n\t}\n\n\treturn webhook.ManageRoute(ctx, router, controller, dispatch)\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage gitlab\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"projects can't be empty\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"gitlab.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Gitlab)\n\n\tfor name, value := range eventSource.Spec.Gitlab {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tGitlabEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "package hdfs\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"type is required\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"hdfs.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.HDFS)\n\n\tfor name, value := range eventSource.Spec.HDFS {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tHDFSEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage kafka\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"url must be specified\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"kafka.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Kafka)\n\n\tfor name, value := range eventSource.Spec.Kafka {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tKafkaEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage minio\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"access key can't be empty\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"minio.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Minio)\n\n\tfor _, value := range eventSource.Spec.Minio {\n\t\tl := &EventListener{\n\t\t\tMinioEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage mqtt\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"url must be specified\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"mqtt.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.MQTT)\n\n\tfor name, value := range eventSource.Spec.MQTT {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tMQTTEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage nats\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"url must be specified\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"nats.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.NATS)\n\n\tfor name, value := range eventSource.Spec.NATS {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tNATSEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage nsq\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"host address must be specified\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"nsq.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.NSQ)\n\n\tfor name, value := range eventSource.Spec.NSQ {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tNSQEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\npackage pulsar\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestEventListener_ValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"topics can't be empty list\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"pulsar.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Pulsar)\n\n\tfor name, value := range eventSource.Spec.Pulsar {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tPulsarEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage redis\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateRedisEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"host address must be specified\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"redis.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Redis)\n\n\tfor name, value := range eventSource.Spec.Redis {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tRedisEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage redisstream\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateRedisEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"host address must be specified\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"redis-streams.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.RedisStream)\n\n\tfor name, value := range eventSource.Spec.RedisStream {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage resource\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"version must be specified\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"resource.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Resource)\n\n\tfor name, value := range eventSource.Spec.Resource {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tResourceEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage slack\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"io\"\n\t\"net/http\"\n\t\"time\"\n\n\t\"github.com/pkg/errors\"\n\t\"github.com/slack-go/slack\"\n\t\"github.com/slack-go/slack/slackevents\"\n\t\"go.uber.org/zap\"\n\n\t\"github.com/argoproj/argo-events/common\"\n\t\"github.com/argoproj/argo-events/common/logging\"\n\teventsourcecommon \"github.com/argoproj/argo-events/eventsources/common\"\n\t\"github.com/argoproj/argo-events/eventsources/common/webhook\"\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\tmetrics \"github.com/argoproj/argo-events/metrics\"\n\tapicommon \"github.com/argoproj/argo-events/pkg/apis/common\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\n// controller controls the webhook operations\nvar (\n\tcontroller = webhook.NewController()\n)\n\n// set up the activation and inactivation channels to control the state of routes.\nfunc init() {\n\tgo webhook.ProcessRouteStatus(controller)\n}\n\n// EventListener implements Eventing for slack event source\ntype EventListener struct {\n\tEventSourceName  string\n\tEventName        string\n\tSlackEventSource v1alpha1.SlackEventSource\n\tMetrics          *metrics.Metrics\n}\n\n// GetEventSourceName returns name of event source\nfunc (el *EventListener) GetEventSourceName() string {\n\treturn el.EventSourceName\n}\n\n// GetEventName returns name of event\nfunc (el *EventListener) GetEventName() string {\n\treturn el.EventName\n}\n\n// GetEventSourceType return type of event server\nfunc (el *EventListener) GetEventSourceType() apicommon.EventSourceType {\n\treturn apicommon.SlackEvent\n}\n\n// Router contains information about a REST endpoint\ntype Router struct {\n\t// route holds information to process an incoming request\n\troute *webhook.Route\n\t// slackEventSource is the event source which refers to configuration required to consume events from slack\n\tslackEventSource *v1alpha1.SlackEventSource\n\t// token is the slack token\n\ttoken string\n\t// refer to https://api.slack.com/docs/verifying-requests-from-slack\n\tsigningSecret string\n}\n\n// Implement Router\n// 1. GetRoute\n// 2. HandleRoute\n// 3. PostActivate\n// 4. PostDeactivate\n\n// GetRoute returns the route\nfunc (rc *Router) GetRoute() *webhook.Route {\n\treturn rc.route\n}\n\n// HandleRoute handles incoming requests on the route\nfunc (rc *Router) HandleRoute(writer http.ResponseWriter, request *http.Request) {\n\troute := rc.route\n\n\tlogger := route.Logger.With(\n\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\tlogging.LabelPort, route.Context.Port,\n\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t)\n\n\tlogger.Info(\"request a received, processing it...\")\n\n\tif !route.Active {\n\t\tlogger.Warn(\"endpoint is not active, won't process it\")\n\t\tcommon.SendErrorResponse(writer, \"endpoint is inactive\")\n\t\treturn\n\t}\n\n\tdefer func(start time.Time) {\n\t\troute.Metrics.EventProcessingDuration(route.EventSourceName, route.EventName, float64(time.Since(start)/time.Millisecond))\n\t}(time.Now())\n\n\tlogger.Info(\"verifying the request...\")\n\terr := rc.verifyRequest(request)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to validate the request\", zap.Error(err))\n\t\tcommon.SendResponse(writer, http.StatusUnauthorized, err.Error())\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tvar data []byte\n\n\t// Interactive element actions are always\n\t// sent as application/x-www-form-urlencoded\n\t// If request was generated by an interactive element or a slash command, it will be a POST form\n\tif len(request.Header[\"Content-Type\"]) > 0 && request.Header[\"Content-Type\"][0] == \"application/x-www-form-urlencoded\" {\n\t\tif err := request.ParseForm(); err != nil {\n\t\t\tlogger.Errorw(\"failed to parse form data\", zap.Error(err))\n\t\t\tcommon.SendInternalErrorResponse(writer, err.Error())\n\t\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\t\treturn\n\t\t}\n\n\t\tswitch {\n\t\tcase request.PostForm.Get(\"payload\") != \"\":\n\t\t\tdata, err = rc.handleInteraction(request)\n\t\t\tif err != nil {\n\t\t\t\tlogger.Errorw(\"failed to process the interaction\", zap.Error(err))\n\t\t\t\tcommon.SendInternalErrorResponse(writer, err.Error())\n\t\t\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\t\t\treturn\n\t\t\t}\n\n\t\tcase request.PostForm.Get(\"command\") != \"\":\n\t\t\tdata, err = rc.handleSlashCommand(request)\n\t\t\tif err != nil {\n\t\t\t\tlogger.Errorw(\"failed to process the slash command\", zap.Error(err))\n\t\t\t\tcommon.SendInternalErrorResponse(writer, err.Error())\n\t\t\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\t\t\treturn\n\t\t\t}\n\n\t\tdefault:\n\t\t\terr = errors.New(\"could not determine slack type from form parameters\")\n\t\t\tlogger.Errorw(\"failed to determine type of slack post\", zap.Error(err))\n\t\t\tcommon.SendInternalErrorResponse(writer, err.Error())\n\t\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\t\treturn\n\t\t}\n\t} else {\n\t\t// If there's no payload in the post body, this is likely an\n\t\t// Event API request. Parse and process if valid.\n\t\tlogger.Info(\"handling slack event...\")\n\t\tvar response []byte\n\t\tdata, response, err = rc.handleEvent(request)\n\t\tif err != nil {\n\t\t\tlogger.Errorw(\"failed to handle the event\", zap.Error(err))\n\t\t\tcommon.SendInternalErrorResponse(writer, err.Error())\n\t\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\t\treturn\n\t\t}\n\t\tif response != nil {\n\t\t\twriter.Header().Set(\"Content-Type\", \"text\")\n\t\t\tif _, err := writer.Write(response); err != nil {\n\t\t\t\tlogger.Errorw(\"failed to write the response for url verification\", zap.Error(err))\n\t\t\t\t// don't return, we want to keep this running to give user chance to retry\n\t\t\t}\n\t\t}\n\t}\n\n\tif data != nil {\n\t\tlogger.Info(\"dispatching event on route's data channel...\")\n\t\troute.DataCh <- data\n\t}\n\n\tlogger.Debug(\"request successfully processed\")\n\tcommon.SendSuccessResponse(writer, \"success\")\n}\n\n// PostActivate performs operations once the route is activated and ready to consume requests\nfunc (rc *Router) PostActivate() error {\n\treturn nil\n}\n\n// PostInactivate performs operations after the route is inactivated\nfunc (rc *Router) PostInactivate() error {\n\treturn nil\n}\n\n// handleEvent parse the slack notification and validates the event type\nfunc (rc *Router) handleEvent(request *http.Request) ([]byte, []byte, error) {\n\tvar err error\n\tvar response []byte\n\tvar data []byte\n\tbody, err := getRequestBody(request)\n\tif err != nil {\n\t\treturn data, response, errors.Wrap(err, \"failed to fetch request body\")\n\t}\n\n\teventsAPIEvent, err := slackevents.ParseEvent(json.RawMessage(body), slackevents.OptionVerifyToken(&slackevents.TokenComparator{VerificationToken: rc.token}))\n\tif err != nil {\n\t\treturn data, response, errors.Wrap(err, \"failed to extract event\")\n\t}\n\n\tif eventsAPIEvent.Type == slackevents.URLVerification {\n\t\tvar r *slackevents.ChallengeResponse\n\t\terr = json.Unmarshal(body, &r)\n\t\tif err != nil {\n\t\t\treturn data, response, errors.Wrap(err, \"failed to verify the challenge\")\n\t\t}\n\t\tresponse = []byte(r.Challenge)\n\t}\n\n\tif eventsAPIEvent.Type == slackevents.CallbackEvent {\n\t\tdata, err = json.Marshal(&eventsAPIEvent.InnerEvent)\n\t\tif err != nil {\n\t\t\treturn data, response, errors.Wrap(err, \"failed to marshal event data, rejecting the event...\")\n\t\t}\n\t}\n\n\treturn data, response, nil\n}\n\nfunc (rc *Router) handleInteraction(request *http.Request) ([]byte, error) {\n\tpayload := request.PostForm.Get(\"payload\")\n\tie := &slack.InteractionCallback{}\n\terr := json.Unmarshal([]byte(payload), ie)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to parse interaction event\")\n\t}\n\n\tdata, err := json.Marshal(ie)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to marshal action data\")\n\t}\n\n\treturn data, nil\n}\n\nfunc (rc *Router) handleSlashCommand(request *http.Request) ([]byte, error) {\n\tcommand, err := slack.SlashCommandParse(request)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to parse command\")\n\t}\n\n\tdata, err := json.Marshal(command)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to marshal command data\")\n\t}\n\n\treturn data, nil\n}\n\nfunc getRequestBody(request *http.Request) ([]byte, error) {\n\t// Read request payload\n\tbody, err := io.ReadAll(io.LimitReader(request.Body, 65536))\n\t// Reset request.Body ReadCloser to prevent side-effect if re-read\n\trequest.Body = io.NopCloser(bytes.NewBuffer(body))\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to parse request body\")\n\t}\n\treturn body, nil\n}\n\n// If a signing secret is provided, validate the request against the\n// X-Slack-Signature header value.\n// The signature is a hash generated as per Slack documentation at:\n// https://api.slack.com/docs/verifying-requests-from-slack\nfunc (rc *Router) verifyRequest(request *http.Request) error {\n\tsigningSecret := rc.signingSecret\n\tif len(signingSecret) > 0 {\n\t\tsv, err := slack.NewSecretsVerifier(request.Header, signingSecret)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"cannot create secrets verifier\")\n\t\t}\n\n\t\t// Read the request body\n\t\tbody, err := getRequestBody(request)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t_, err = sv.Write(body)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"error writing body: cannot verify signature\")\n\t\t}\n\n\t\terr = sv.Ensure()\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"signature validation failed\")\n\t\t}\n\t}\n\treturn nil\n}\n\n// StartListening starts an event source\nfunc (el *EventListener) StartListening(ctx context.Context, dispatch func([]byte, ...eventsourcecommon.Option) error) error {\n\tlog := logging.FromContext(ctx).\n\t\tWith(logging.LabelEventSourceType, el.GetEventSourceType(), logging.LabelEventName, el.GetEventName())\n\n\tlog.Info(\"started processing the Slack event source...\")\n\tdefer sources.Recover(el.GetEventName())\n\n\tslackEventSource := &el.SlackEventSource\n\tlog.Info(\"retrieving the slack token...\")\n\ttoken, err := common.GetSecretFromVolume(slackEventSource.Token)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"failed to retrieve the token\")\n\t}\n\n\tlog.Info(\"retrieving the signing secret...\")\n\tsigningSecret, err := common.GetSecretFromVolume(slackEventSource.SigningSecret)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"failed to retrieve the signing secret\")\n\t}\n\n\troute := webhook.NewRoute(slackEventSource.Webhook, log, el.GetEventSourceName(), el.GetEventName(), el.Metrics)\n\n\treturn webhook.ManageRoute(ctx, &Router{\n\t\troute:            route,\n\t\ttoken:            token,\n\t\tsigningSecret:    signingSecret,\n\t\tslackEventSource: slackEventSource,\n\t}, controller, dispatch)\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage slack\n\nimport (\n\t\"bytes\"\n\t\"crypto/hmac\"\n\t\"crypto/sha256\"\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"io\"\n\t\"net/http\"\n\t\"strconv\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/slack-go/slack/slackevents\"\n\t\"github.com/smartystreets/goconvey/convey\"\n\n\t\"github.com/argoproj/argo-events/eventsources/common/webhook\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestRouteActiveHandler(t *testing.T) {\n\tconvey.Convey(\"Given a route configuration\", t, func() {\n\t\trouter := &Router{\n\t\t\troute:            webhook.GetFakeRoute(),\n\t\t\tslackEventSource: &v1alpha1.SlackEventSource{},\n\t\t}\n\n\t\tconvey.Convey(\"Inactive route should return 404\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\trouter.HandleRoute(writer, &http.Request{})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusBadRequest)\n\t\t})\n\n\t\trouter.token = \"Jhj5dZrVaK7ZwHHjRyZWjbDl\"\n\t\trouter.route.Active = true\n\n\t\tconvey.Convey(\"Test url verification request\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\turlVer := slackevents.EventsAPIURLVerificationEvent{\n\t\t\t\tType:      slackevents.URLVerification,\n\t\t\t\tToken:     \"Jhj5dZrVaK7ZwHHjRyZWjbDl\",\n\t\t\t\tChallenge: \"3eZbrw1aBm2rZgRNFdxV2595E9CY3gmdALWMmHkvFXO7tYXAYM8P\",\n\t\t\t}\n\t\t\tpayload, err := yaml.Marshal(urlVer)\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\t\t\tconvey.So(payload, convey.ShouldNotBeNil)\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tBody: io.NopCloser(bytes.NewReader(payload)),\n\t\t\t})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusInternalServerError)\n\t\t})\n\t})\n}\n\nfunc TestSlackSignature(t *testing.T) {\n\tconvey.Convey(\"Given a route that receives a message from Slack\", t, func() {\n\t\trouter := &Router{\n\t\t\troute:            webhook.GetFakeRoute(),\n\t\t\tslackEventSource: &v1alpha1.SlackEventSource{},\n\t\t}\n\n\t\trouter.signingSecret = \"abcdefghiklm1234567890\"\n\t\tconvey.Convey(\"Validate request signature\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\tpayload := []byte(\"payload=%7B%22type%22%3A%22block_actions%22%2C%22team%22%3A%7B%22id%22%3A%22T0CAG%22%2C%22domain%22%3A%22acme-creamery%22%7D%2C%22user%22%3A%7B%22id%22%3A%22U0CA5%22%2C%22username%22%3A%22Amy%20McGee%22%2C%22name%22%3A%22Amy%20McGee%22%2C%22team_id%22%3A%22T3MDE%22%7D%2C%22api_app_id%22%3A%22A0CA5%22%2C%22token%22%3A%22Shh_its_a_seekrit%22%2C%22container%22%3A%7B%22type%22%3A%22message%22%2C%22text%22%3A%22The%20contents%20of%20the%20original%20message%20where%20the%20action%20originated%22%7D%2C%22trigger_id%22%3A%2212466734323.1395872398%22%2C%22response_url%22%3A%22https%3A%2F%2Fwww.postresponsestome.com%2FT123567%2F1509734234%22%2C%22actions%22%3A%5B%7B%22type%22%3A%22button%22%2C%22block_id%22%3A%22actionblock789%22%2C%22action_id%22%3A%2227S%22%2C%22text%22%3A%7B%22type%22%3A%22plain_text%22%2C%22text%22%3A%22Link%20Button%22%2C%22emoji%22%3Atrue%7D%2C%22action_ts%22%3A%221564701248.149432%22%7D%5D%7D\")\n\t\t\th := make(http.Header)\n\n\t\t\trts := int(time.Now().UTC().UnixNano())\n\t\t\thmac := hmac.New(sha256.New, []byte(router.signingSecret))\n\t\t\tb := strings.Join([]string{\"v0\", strconv.Itoa(rts), string(payload)}, \":\")\n\t\t\t_, err := hmac.Write([]byte(b))\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\t\t\thash := hex.EncodeToString(hmac.Sum(nil))\n\t\t\tgenSig := strings.TrimRight(strings.Join([]string{\"v0=\", hash}, \"\"), \"\\n\")\n\t\t\th.Add(\"Content-Type\", \"application/x-www-form-urlencoded\")\n\t\t\th.Add(\"X-Slack-Signature\", genSig)\n\t\t\th.Add(\"X-Slack-Request-Timestamp\", strconv.FormatInt(int64(rts), 10))\n\n\t\t\trouter.route.Active = true\n\n\t\t\tgo func() {\n\t\t\t\t<-router.route.DataCh\n\t\t\t}()\n\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tBody:   io.NopCloser(bytes.NewReader(payload)),\n\t\t\t\tHeader: h,\n\t\t\t\tMethod: \"POST\",\n\t\t\t})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusOK)\n\t\t})\n\t})\n}\n\nfunc TestInteractionHandler(t *testing.T) {\n\tconvey.Convey(\"Given a route that receives an interaction event\", t, func() {\n\t\trouter := &Router{\n\t\t\troute:            webhook.GetFakeRoute(),\n\t\t\tslackEventSource: &v1alpha1.SlackEventSource{},\n\t\t}\n\n\t\tconvey.Convey(\"Test an interaction action message\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\tactionString := `{\"type\":\"block_actions\",\"team\":{\"id\":\"T9TK3CUKW\",\"domain\":\"example\"},\"user\":{\"id\":\"UA8RXUSPL\",\"username\":\"jtorrance\",\"team_id\":\"T9TK3CUKW\"},\"api_app_id\":\"AABA1ABCD\",\"token\":\"9s8d9as89d8as9d8as989\",\"container\":{\"type\":\"message_attachment\",\"message_ts\":\"1548261231.000200\",\"attachment_id\":1,\"channel_id\":\"CBR2V3XEX\",\"is_ephemeral\":false,\"is_app_unfurl\":false},\"trigger_id\":\"12321423423.333649436676.d8c1bb837935619ccad0f624c448ffb3\",\"channel\":{\"id\":\"CBR2V3XEX\",\"name\":\"review-updates\"},\"message\":{\"bot_id\":\"BAH5CA16Z\",\"type\":\"message\",\"text\":\"This content can't be displayed.\",\"user\":\"UAJ2RU415\",\"ts\":\"1548261231.000200\"},\"response_url\":\"https://hooks.slack.com/actions/AABA1ABCD/1232321423432/D09sSasdasdAS9091209\",\"actions\":[{\"action_id\":\"WaXA\",\"block_id\":\"=qXel\",\"text\":{\"type\":\"plain_text\",\"text\":\"View\",\"emoji\":true},\"value\":\"click_me_123\",\"type\":\"button\",\"action_ts\":\"1548426417.840180\"}]}`\n\t\t\tpayload := []byte(`payload=` + actionString)\n\t\t\tout := make(chan []byte)\n\t\t\trouter.route.Active = true\n\n\t\t\tgo func() {\n\t\t\t\tout <- <-router.route.DataCh\n\t\t\t}()\n\n\t\t\tvar buf bytes.Buffer\n\t\t\tbuf.Write(payload)\n\n\t\t\theaders := make(map[string][]string)\n\t\t\theaders[\"Content-Type\"] = append(headers[\"Content-Type\"], \"application/x-www-form-urlencoded\")\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tMethod: http.MethodPost,\n\t\t\t\tHeader: headers,\n\t\t\t\tBody:   io.NopCloser(strings.NewReader(buf.String())),\n\t\t\t})\n\t\t\tresult := <-out\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusOK)\n\t\t\tconvey.So(string(result), convey.ShouldContainSubstring, \"\\\"type\\\":\\\"block_actions\\\"\")\n\t\t\tconvey.So(string(result), convey.ShouldContainSubstring, \"\\\"token\\\":\\\"9s8d9as89d8as9d8as989\\\"\")\n\t\t})\n\t})\n}\n\nfunc TestSlackCommandHandler(t *testing.T) {\n\tconvey.Convey(\"Given a route that receives a slash command event\", t, func() {\n\t\trouter := &Router{\n\t\t\troute:            webhook.GetFakeRoute(),\n\t\t\tslackEventSource: &v1alpha1.SlackEventSource{},\n\t\t}\n\n\t\tconvey.Convey(\"Test a slash command message\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\t// Test values pulled from example here: https://api.slack.com/interactivity/slash-commands#app_command_handling\n\t\t\tpayload := []byte(`token=gIkuvaNzQIHg97ATvDxqgjtO&team_id=T0001&team_domain=example&enterprise_id=E0001&enterprise_name=Globular%20Construct%20Inc&channel_id=C2147483705&channel_name=test&user_id=U2147483697&user_name=Steve&command=/weather&text=94070&response_url=https://hooks.slack.com/commands/1234/5678&trigger_id=13345224609.738474920.8088930838d88f008e0&api_app_id=A123456`)\n\t\t\tout := make(chan []byte)\n\t\t\trouter.route.Active = true\n\n\t\t\tgo func() {\n\t\t\t\tout <- <-router.route.DataCh\n\t\t\t}()\n\n\t\t\tvar buf bytes.Buffer\n\t\t\tbuf.Write(payload)\n\n\t\t\theaders := make(map[string][]string)\n\t\t\theaders[\"Content-Type\"] = append(headers[\"Content-Type\"], \"application/x-www-form-urlencoded\")\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tMethod: http.MethodPost,\n\t\t\t\tHeader: headers,\n\t\t\t\tBody:   io.NopCloser(strings.NewReader(buf.String())),\n\t\t\t})\n\t\t\tresult := <-out\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusOK)\n\t\t\tconvey.So(string(result), convey.ShouldContainSubstring, \"\\\"command\\\":\\\"/weather\\\"\")\n\t\t\tconvey.So(string(result), convey.ShouldContainSubstring, \"\\\"token\\\":\\\"gIkuvaNzQIHg97ATvDxqgjtO\\\"\")\n\t\t})\n\t})\n}\n\nfunc TestEventHandler(t *testing.T) {\n\tconvey.Convey(\"Given a route that receives an event\", t, func() {\n\t\trouter := &Router{\n\t\t\troute:            webhook.GetFakeRoute(),\n\t\t\tslackEventSource: &v1alpha1.SlackEventSource{},\n\t\t}\n\n\t\tconvey.Convey(\"Test an event notification\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\tevent := []byte(`\n{\n\"type\": \"name_of_event\",\n\"event_ts\": \"1234567890.123456\",\n\"user\": \"UXXXXXXX1\"\n}\n`)\n\n\t\t\tj := json.RawMessage(event)\n\t\t\tce := slackevents.EventsAPICallbackEvent{\n\t\t\t\tToken:     \"Jhj5dZrVaK7ZwHHjRyZWjbDl\",\n\t\t\t\tType:      slackevents.CallbackEvent,\n\t\t\t\tEventTime: 1234567890,\n\t\t\t\tAPIAppID:  \"AXXXXXXXXX\",\n\t\t\t\tAuthedUsers: []string{\n\t\t\t\t\t\"UXXXXXXX1\",\n\t\t\t\t\t\"UXXXXXXX2\",\n\t\t\t\t},\n\t\t\t\tEventID:    \"Ev08MFMKH6\",\n\t\t\t\tInnerEvent: &j,\n\t\t\t}\n\t\t\tpayload, err := yaml.Marshal(ce)\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\n\t\t\trouter.route.Active = true\n\n\t\t\tgo func() {\n\t\t\t\t<-router.route.DataCh\n\t\t\t}()\n\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tBody: io.NopCloser(bytes.NewBuffer(payload)),\n\t\t\t})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusInternalServerError)\n\t\t})\n\t})\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage slack\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"token not provided\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"slack.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Slack)\n\n\tfor name, value := range eventSource.Spec.Slack {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tSlackEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage storagegrid\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/argoproj/argo-events/pkg/apis/events\"\n\t\"github.com/go-resty/resty/v2\"\n\t\"github.com/google/uuid\"\n\t\"github.com/joncalhoun/qson\"\n\t\"github.com/pkg/errors\"\n\t\"go.uber.org/zap\"\n\n\t\"github.com/argoproj/argo-events/common\"\n\t\"github.com/argoproj/argo-events/common/logging\"\n\teventsourcecommon \"github.com/argoproj/argo-events/eventsources/common\"\n\t\"github.com/argoproj/argo-events/eventsources/common/webhook\"\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\tapicommon \"github.com/argoproj/argo-events/pkg/apis/common\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\n// controller controls the webhook operations\nvar (\n\tcontroller = webhook.NewController()\n)\n\nvar (\n\trespBody = `\n<PublishResponse xmlns=\"http://argoevents-sns-server/\">\n    <PublishResult> \n        <MessageId>` + generateUUID().String() + `</MessageId> \n    </PublishResult> \n    <ResponseMetadata>\n       <RequestId>` + generateUUID().String() + `</RequestId>\n    </ResponseMetadata> \n</PublishResponse>` + \"\\n\"\n\n\tnotificationBodyTemplate = `\n<NotificationConfiguration>\n\t<TopicConfiguration>\n\t  <Id>%s</Id>\n\t  <Topic>%s</Topic>\n\t  %s\n\t</TopicConfiguration>\n</NotificationConfiguration>\n` + \"\\n\"\n)\n\n// set up the activation and inactivation channels to control the state of routes.\nfunc init() {\n\tgo webhook.ProcessRouteStatus(controller)\n}\n\n// generateUUID returns a new uuid\nfunc generateUUID() uuid.UUID {\n\treturn uuid.New()\n}\n\n// filterName filters object key based on configured prefix and/or suffix\nfunc filterName(notification *events.StorageGridNotification, eventSource *v1alpha1.StorageGridEventSource) bool {\n\tif eventSource.Filter == nil {\n\t\treturn true\n\t}\n\tif eventSource.Filter.Prefix != \"\" && eventSource.Filter.Suffix != \"\" {\n\t\treturn strings.HasPrefix(notification.Message.Records[0].S3.Object.Key, eventSource.Filter.Prefix) && strings.HasSuffix(notification.Message.Records[0].S3.Object.Key, eventSource.Filter.Suffix)\n\t}\n\tif eventSource.Filter.Prefix != \"\" {\n\t\treturn strings.HasPrefix(notification.Message.Records[0].S3.Object.Key, eventSource.Filter.Prefix)\n\t}\n\tif eventSource.Filter.Suffix != \"\" {\n\t\treturn strings.HasSuffix(notification.Message.Records[0].S3.Object.Key, eventSource.Filter.Suffix)\n\t}\n\treturn true\n}\n\n// GetEventSourceName returns name of event source\nfunc (el *EventListener) GetEventSourceName() string {\n\treturn el.EventSourceName\n}\n\n// GetEventName returns name of event\nfunc (el *EventListener) GetEventName() string {\n\treturn el.EventName\n}\n\n// GetEventSourceType return type of event server\nfunc (el *EventListener) GetEventSourceType() apicommon.EventSourceType {\n\treturn apicommon.StorageGridEvent\n}\n\n// Implement Router\n// 1. GetRoute\n// 2. HandleRoute\n// 3. PostActivate\n// 4. PostDeactivate\n\n// GetRoute returns the route\nfunc (router *Router) GetRoute() *webhook.Route {\n\treturn router.route\n}\n\n// HandleRoute handles new route\nfunc (router *Router) HandleRoute(writer http.ResponseWriter, request *http.Request) {\n\troute := router.route\n\n\tlogger := route.Logger.With(\n\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\tlogging.LabelPort, route.Context.Port,\n\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t)\n\n\tlogger.Info(\"processing incoming request...\")\n\n\tif !route.Active {\n\t\tlogger.Warn(\"endpoint is inactive, won't process the request\")\n\t\tcommon.SendErrorResponse(writer, \"inactive endpoint\")\n\t\treturn\n\t}\n\n\tlogger.Info(\"parsing the request body...\")\n\trequest.Body = http.MaxBytesReader(writer, request.Body, 65536)\n\tbody, err := io.ReadAll(request.Body)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to parse request body\", zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, \"\")\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tif request.Method == http.MethodHead {\n\t\trespBody = \"\"\n\t}\n\n\twriter.WriteHeader(http.StatusOK)\n\twriter.Header().Add(\"Content-Type\", \"text/plain\")\n\tif _, err := writer.Write([]byte(respBody)); err != nil {\n\t\tlogger.Errorw(\"failed to write the response\", zap.Error(err))\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\t// notification received from storage grid is url encoded.\n\tparsedURL, err := url.QueryUnescape(string(body))\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to unescape request body url\", zap.Error(err))\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\tb, err := qson.ToJSON(parsedURL)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to convert request body in JSON format\", zap.Error(err))\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tlogger.Info(\"converting request body to storage grid notification\")\n\tvar notification *events.StorageGridNotification\n\terr = json.Unmarshal(b, &notification)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to convert the request body into storage grid notification\", zap.Error(err))\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tif filterName(notification, router.storageGridEventSource) {\n\t\tdefer func(start time.Time) {\n\t\t\troute.Metrics.EventProcessingDuration(route.EventSourceName, route.EventName, float64(time.Since(start)/time.Millisecond))\n\t\t}(time.Now())\n\n\t\tlogger.Info(\"new event received, dispatching event on route's data channel\")\n\t\teventData := &events.StorageGridEventData{\n\t\t\tNotification: notification,\n\t\t\tMetadata:     router.storageGridEventSource.Metadata,\n\t\t}\n\t\teventBody, err := json.Marshal(eventData)\n\t\tif err != nil {\n\t\t\tlogger.Errorw(\"failed to marshal the event data\", zap.Error(err))\n\t\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\t\treturn\n\t\t}\n\t\troute.DataCh <- eventBody\n\t\treturn\n\t}\n\n\tlogger.Warn(\"discarding notification since it did not pass all filters\")\n}\n\n// PostActivate performs operations once the route is activated and ready to consume requests\nfunc (router *Router) PostActivate() error {\n\teventSource := router.storageGridEventSource\n\troute := router.route\n\n\tauthToken, err := common.GetSecretFromVolume(eventSource.AuthToken)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"AuthToken not found\")\n\t}\n\n\tregistrationURL := common.FormattedURL(eventSource.Webhook.URL, eventSource.Webhook.Endpoint)\n\n\tclient := resty.New()\n\n\tlogger := route.Logger.With(\n\t\t\"registration-url\", registrationURL,\n\t\t\"bucket\", eventSource.Bucket,\n\t\t\"auth-secret-name\", eventSource.AuthToken.Name,\n\t\t\"api-url\", eventSource.APIURL,\n\t)\n\n\tlogger.Info(\"checking if the endpoint already exists...\")\n\n\tresponse, err := client.R().\n\t\tSetHeader(\"Content-Type\", common.MediaTypeJSON).\n\t\tSetAuthToken(authToken).\n\t\tSetResult(&getEndpointResponse{}).\n\t\tSetError(&genericResponse{}).\n\t\tGet(common.FormattedURL(eventSource.APIURL, \"/org/endpoints\"))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif !response.IsSuccess() {\n\t\terrObj := response.Error().(*genericResponse)\n\t\treturn fmt.Errorf(\"failed to list existing endpoints. reason: %s\", errObj.Message.Text)\n\t}\n\n\tendpointResponse := response.Result().(*getEndpointResponse)\n\n\tisURNExists := false\n\n\tfor _, endpoint := range endpointResponse.Data {\n\t\tif endpoint.EndpointURN == eventSource.TopicArn {\n\t\t\tlogger.Info(\"endpoint with topic urn already exists, won't register duplicate endpoint\")\n\t\t\tisURNExists = true\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif !isURNExists {\n\t\tlogger.Info(\"endpoint urn does not exist, registering a new endpoint\")\n\t\tnewEndpoint := createEndpointRequest{\n\t\t\tDisplayName: router.route.EventName,\n\t\t\tEndpointURI: common.FormattedURL(eventSource.Webhook.URL, eventSource.Webhook.Endpoint),\n\t\t\tEndpointURN: eventSource.TopicArn,\n\t\t\tAuthType:    \"anonymous\",\n\t\t\tInsecureTLS: true,\n\t\t}\n\n\t\tnewEndpointBody, err := json.Marshal(&newEndpoint)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tresponse, err := client.R().\n\t\t\tSetHeader(\"Content-Type\", common.MediaTypeJSON).\n\t\t\tSetAuthToken(authToken).\n\t\t\tSetBody(string(newEndpointBody)).\n\t\t\tSetResult(&genericResponse{}).\n\t\t\tSetError(&genericResponse{}).\n\t\t\tPost(common.FormattedURL(eventSource.APIURL, \"/org/endpoints\"))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif !response.IsSuccess() {\n\t\t\terrObj := response.Error().(*genericResponse)\n\t\t\treturn fmt.Errorf(\"failed to register the endpoint. reason: %s\", errObj.Message.Text)\n\t\t}\n\n\t\tlogger.Info(\"successfully registered the endpoint\")\n\t}\n\n\tlogger.Info(\"registering notification configuration on storagegrid...\")\n\n\tvar events []string\n\tfor _, event := range eventSource.Events {\n\t\tevents = append(events, fmt.Sprintf(\"<Event>%s</Event>\", event))\n\t}\n\n\teventXML := strings.Join(events, \"\\n\")\n\n\tnotificationBody := fmt.Sprintf(notificationBodyTemplate, route.EventName, eventSource.TopicArn, eventXML)\n\n\tnotification := &storageGridNotificationRequest{\n\t\tNotification: notificationBody,\n\t}\n\n\tnotificationRequestBody, err := json.Marshal(notification)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tresponse, err = client.R().\n\t\tSetHeader(\"Content-Type\", common.MediaTypeJSON).\n\t\tSetAuthToken(authToken).\n\t\tSetBody(string(notificationRequestBody)).\n\t\tSetResult(&registerNotificationResponse{}).\n\t\tSetError(&genericResponse{}).\n\t\tPut(common.FormattedURL(eventSource.APIURL, fmt.Sprintf(\"/org/containers/%s/notification\", eventSource.Bucket)))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif !response.IsSuccess() {\n\t\terrObj := response.Error().(*genericResponse)\n\t\treturn errors.Errorf(\"failed to configure notification. reason %s\", errObj.Message.Text)\n\t}\n\n\tlogger.Info(\"successfully registered notification configuration on storagegrid\")\n\treturn nil\n}\n\n// PostInactivate performs operations after the route is inactivated\nfunc (router *Router) PostInactivate() error {\n\treturn nil\n}\n\n// StartListening starts an event source\nfunc (el *EventListener) StartListening(ctx context.Context, dispatch func([]byte, ...eventsourcecommon.Option) error) error {\n\tlog := logging.FromContext(ctx).\n\t\tWith(logging.LabelEventSourceType, el.GetEventSourceType(), logging.LabelEventName, el.GetEventName())\n\tlog.Info(\"started processing the Storage Grid event source...\")\n\tdefer sources.Recover(el.GetEventName())\n\n\tstoragegridEventSource := &el.StorageGridEventSource\n\troute := webhook.NewRoute(storagegridEventSource.Webhook, log, el.GetEventSourceName(), el.GetEventName(), el.Metrics)\n\n\treturn webhook.ManageRoute(ctx, &Router{\n\t\troute:                  route,\n\t\tstorageGridEventSource: storagegridEventSource,\n\t}, controller, dispatch)\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage storagegrid\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"io\"\n\t\"net/http\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/common/webhook\"\n\t\"github.com/argoproj/argo-events/pkg/apis/events\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/smartystreets/goconvey/convey\"\n)\n\nvar (\n\tnotification = `\n{\n  \"Action\": \"Publish\",\n  \"Message\": {\n    \"Records\": [\n      {\n        \"eventName\": \"ObjectCreated:Put\",\n        \"storageGridEventSource\": \"sgws:s3\",\n        \"eventTime\": \"2019-02-27T21:15:09Z\",\n        \"eventVersion\": \"2.0\",\n        \"requestParameters\": {\n          \"sourceIPAddress\": \"1.1.1.1\"\n        },\n        \"responseElements\": {\n          \"x-amz-request-id\": \"12345678\"\n        },\n        \"s3\": {\n          \"bucket\": {\n            \"arn\": \"urn:sgfs:s3:::my_bucket\",\n            \"name\": \"my_bucket\",\n            \"ownerIdentity\": {\n              \"principalId\": \"55555555555555555\"\n            }\n          },\n          \"configurationId\": \"Object-Event\",\n          \"object\": {\n            \"eTag\": \"4444444444444444\",\n            \"key\": \"hello-world.txt\",\n            \"sequencer\": \"AAAAAA\",\n            \"size\": 6\n          },\n          \"s3SchemaVersion\": \"1.0\"\n        },\n        \"userIdentity\": {\n          \"principalId\": \"1111111111111111\"\n        }\n      }\n    ]\n  },\n  \"TopicArn\": \"urn:h:sns:us-east::my_topic_1\",\n  \"Version\": \"2010-03-31\"\n}\n`\n\trouter = &Router{\n\t\troute: webhook.GetFakeRoute(),\n\t}\n)\n\nfunc TestRouteActiveHandler(t *testing.T) {\n\tconvey.Convey(\"Given a route configuration\", t, func() {\n\t\tstorageGridEventSource := &v1alpha1.StorageGridEventSource{\n\t\t\tWebhook: &v1alpha1.WebhookContext{\n\t\t\t\tEndpoint: \"/\",\n\t\t\t\tURL:      \"testurl\",\n\t\t\t\tPort:     \"8080\",\n\t\t\t},\n\t\t\tEvents: []string{\n\t\t\t\t\"ObjectCreated:Put\",\n\t\t\t},\n\t\t\tFilter: &v1alpha1.StorageGridFilter{\n\t\t\t\tPrefix: \"hello-\",\n\t\t\t\tSuffix: \".txt\",\n\t\t\t},\n\t\t}\n\n\t\twriter := &webhook.FakeHttpWriter{}\n\n\t\tconvey.Convey(\"Inactive route should return error\", func() {\n\t\t\tpbytes, err := yaml.Marshal(storageGridEventSource)\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tBody: io.NopCloser(bytes.NewReader(pbytes)),\n\t\t\t})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusBadRequest)\n\t\t})\n\n\t\tconvey.Convey(\"Active route should return success\", func() {\n\t\t\trouter.route.Active = true\n\t\t\trouter.storageGridEventSource = storageGridEventSource\n\t\t\tdataCh := make(chan []byte)\n\t\t\tgo func() {\n\t\t\t\tresp := <-router.route.DataCh\n\t\t\t\tdataCh <- resp\n\t\t\t}()\n\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tBody: io.NopCloser(bytes.NewReader([]byte(notification))),\n\t\t\t})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusOK)\n\t\t})\n\t})\n}\n\nfunc TestGenerateUUID(t *testing.T) {\n\tconvey.Convey(\"Make sure generated UUIDs are unique\", t, func() {\n\t\tu1 := generateUUID()\n\t\tu2 := generateUUID()\n\t\tconvey.So(u1.String(), convey.ShouldNotEqual, u2.String())\n\t})\n}\n\nfunc TestFilterName(t *testing.T) {\n\tconvey.Convey(\"Given a storage grid event, test whether the object key passes the filter\", t, func() {\n\t\tstorageGridEventSource := &v1alpha1.StorageGridEventSource{\n\t\t\tWebhook: &v1alpha1.WebhookContext{\n\t\t\t\tEndpoint: \"/\",\n\t\t\t\tURL:      \"testurl\",\n\t\t\t\tPort:     \"8080\",\n\t\t\t},\n\t\t\tEvents: []string{\n\t\t\t\t\"ObjectCreated:Put\",\n\t\t\t},\n\t\t\tFilter: &v1alpha1.StorageGridFilter{\n\t\t\t\tPrefix: \"hello-\",\n\t\t\t\tSuffix: \".txt\",\n\t\t\t},\n\t\t}\n\t\tvar gridNotification *events.StorageGridNotification\n\t\terr := json.Unmarshal([]byte(notification), &gridNotification)\n\t\tconvey.So(err, convey.ShouldBeNil)\n\t\tconvey.So(gridNotification, convey.ShouldNotBeNil)\n\n\t\tok := filterName(gridNotification, storageGridEventSource)\n\t\tconvey.So(ok, convey.ShouldEqual, true)\n\t})\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage storagegrid\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"topic arn must be provided\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"storage-grid.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.StorageGrid)\n\n\tfor name, value := range eventSource.Spec.StorageGrid {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tStorageGridEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage stripe\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"io\"\n\t\"net/http\"\n\t\"time\"\n\n\t\"github.com/pkg/errors\"\n\t\"github.com/stripe/stripe-go\"\n\t\"github.com/stripe/stripe-go/webhookendpoint\"\n\t\"go.uber.org/zap\"\n\n\t\"github.com/argoproj/argo-events/common\"\n\t\"github.com/argoproj/argo-events/common/logging\"\n\teventsourcecommon \"github.com/argoproj/argo-events/eventsources/common\"\n\t\"github.com/argoproj/argo-events/eventsources/common/webhook\"\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\tapicommon \"github.com/argoproj/argo-events/pkg/apis/common\"\n\t\"github.com/argoproj/argo-events/pkg/apis/events\"\n)\n\n// controller controls the webhook operations\nvar (\n\tcontroller = webhook.NewController()\n)\n\n// set up the activation and inactivation channels to control the state of routes.\nfunc init() {\n\tgo webhook.ProcessRouteStatus(controller)\n}\n\n// GetEventSourceName returns name of event source\nfunc (el *EventListener) GetEventSourceName() string {\n\treturn el.EventSourceName\n}\n\n// GetEventName returns name of event\nfunc (el *EventListener) GetEventName() string {\n\treturn el.EventName\n}\n\n// GetEventSourceType return type of event server\nfunc (el *EventListener) GetEventSourceType() apicommon.EventSourceType {\n\treturn apicommon.StripeEvent\n}\n\n// Implement Router\n// 1. GetRoute\n// 2. HandleRoute\n// 3. PostActivate\n// 4. PostDeactivate\n\n// GetRoute returns the route\nfunc (rc *Router) GetRoute() *webhook.Route {\n\treturn rc.route\n}\n\n// HandleRoute handles incoming requests on the route\nfunc (rc *Router) HandleRoute(writer http.ResponseWriter, request *http.Request) {\n\troute := rc.route\n\n\tlogger := route.Logger.With(\n\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\tlogging.LabelPort, route.Context.Port,\n\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t)\n\n\tlogger.Info(\"request a received, processing it...\")\n\n\tif !route.Active {\n\t\tlogger.Warn(\"endpoint is not active, won't process it\")\n\t\tcommon.SendErrorResponse(writer, \"endpoint is inactive\")\n\t\treturn\n\t}\n\n\tdefer func(start time.Time) {\n\t\troute.Metrics.EventProcessingDuration(route.EventSourceName, route.EventName, float64(time.Since(start)/time.Millisecond))\n\t}(time.Now())\n\n\tconst MaxBodyBytes = int64(65536)\n\trequest.Body = http.MaxBytesReader(writer, request.Body, MaxBodyBytes)\n\tpayload, err := io.ReadAll(request.Body)\n\tif err != nil {\n\t\tlogger.Errorw(\"error reading request body\", zap.Error(err))\n\t\twriter.WriteHeader(http.StatusServiceUnavailable)\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tvar event *stripe.Event\n\tif err := json.Unmarshal(payload, &event); err != nil {\n\t\tlogger.Errorw(\"failed to parse request body\", zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, \"failed to parse the event\")\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tif ok := filterEvent(event, rc.stripeEventSource.EventFilter); !ok {\n\t\tlogger.Errorw(\"failed to pass the filters\", zap.Any(\"event-type\", event.Type), zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, \"invalid event\")\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\teventData := &events.StripeEventData{\n\t\tEvent:    event,\n\t\tMetadata: rc.stripeEventSource.Metadata,\n\t}\n\n\tdata, err := json.Marshal(eventData)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to marshal event data\", zap.Any(\"event-id\", event.ID), zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, \"invalid event\")\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tlogger.Info(\"dispatching event on route's data channel...\")\n\troute.DataCh <- data\n\tlogger.Info(\"request successfully processed\")\n\tcommon.SendSuccessResponse(writer, \"success\")\n}\n\n// PostActivate performs operations once the route is activated and ready to consume requests\nfunc (rc *Router) PostActivate() error {\n\tif rc.stripeEventSource.CreateWebhook {\n\t\troute := rc.route\n\t\tstripeEventSource := rc.stripeEventSource\n\t\tlogger := route.Logger.With(\n\t\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t\t)\n\t\tlogger.Info(\"registering a new webhook\")\n\n\t\tapiKey, err := common.GetSecretFromVolume(stripeEventSource.APIKey)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"APIKey not found\")\n\t\t}\n\n\t\tstripe.Key = apiKey\n\n\t\tparams := &stripe.WebhookEndpointParams{\n\t\t\tURL: stripe.String(common.FormattedURL(stripeEventSource.Webhook.URL, stripeEventSource.Webhook.Endpoint)),\n\t\t}\n\t\tif stripeEventSource.EventFilter != nil {\n\t\t\tparams.EnabledEvents = stripe.StringSlice(stripeEventSource.EventFilter)\n\t\t}\n\n\t\tendpoint, err := webhookendpoint.New(params)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tlogger.With(\"endpoint-id\", endpoint.ID).Info(\"new stripe webhook endpoint created\")\n\t}\n\treturn nil\n}\n\n// PostInactivate performs operations after the route is inactivated\nfunc (rc *Router) PostInactivate() error {\n\treturn nil\n}\n\nfunc filterEvent(event *stripe.Event, filters []string) bool {\n\tif filters == nil {\n\t\treturn true\n\t}\n\tfor _, filter := range filters {\n\t\tif event.Type == filter {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// StartListening starts an event source\nfunc (el *EventListener) StartListening(ctx context.Context, dispatch func([]byte, ...eventsourcecommon.Option) error) error {\n\tlog := logging.FromContext(ctx).\n\t\tWith(logging.LabelEventSourceType, el.GetEventSourceType(), logging.LabelEventName, el.GetEventName())\n\tlog.Info(\"started processing the Stripe event source...\")\n\tdefer sources.Recover(el.GetEventName())\n\n\tstripeEventSource := &el.StripeEventSource\n\troute := webhook.NewRoute(stripeEventSource.Webhook, log, el.GetEventSourceName(), el.GetEventName(), el.Metrics)\n\n\treturn webhook.ManageRoute(ctx, &Router{\n\t\troute:             route,\n\t\tstripeEventSource: stripeEventSource,\n\t}, controller, dispatch)\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage stripe\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{\n\t\tStripeEventSource: v1alpha1.StripeEventSource{\n\t\t\tCreateWebhook: true,\n\t\t},\n\t}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"api key K8s secret selector not provided\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"stripe.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Stripe)\n\n\tfor name, value := range eventSource.Spec.Stripe {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tStripeEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage webhook\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"io\"\n\t\"net/http\"\n\t\"time\"\n\n\t\"go.uber.org/zap\"\n\n\t\"github.com/argoproj/argo-events/common\"\n\t\"github.com/argoproj/argo-events/common/logging\"\n\teventsourcecommon \"github.com/argoproj/argo-events/eventsources/common\"\n\t\"github.com/argoproj/argo-events/eventsources/common/webhook\"\n\tmetrics \"github.com/argoproj/argo-events/metrics\"\n\tapicommon \"github.com/argoproj/argo-events/pkg/apis/common\"\n\t\"github.com/argoproj/argo-events/pkg/apis/events\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nvar (\n\tcontroller = webhook.NewController()\n)\n\nfunc init() {\n\tgo webhook.ProcessRouteStatus(controller)\n}\n\n// EventListener implements Eventing for webhook events\ntype EventListener struct {\n\tEventSourceName string\n\tEventName       string\n\tWebhookContext  v1alpha1.WebhookContext\n\tMetrics         *metrics.Metrics\n}\n\n// GetEventSourceName returns name of event source\nfunc (el *EventListener) GetEventSourceName() string {\n\treturn el.EventSourceName\n}\n\n// GetEventName returns name of event\nfunc (el *EventListener) GetEventName() string {\n\treturn el.EventName\n}\n\n// GetEventSourceType return type of event server\nfunc (el *EventListener) GetEventSourceType() apicommon.EventSourceType {\n\treturn apicommon.WebhookEvent\n}\n\n// Router contains the configuration information for a route\ntype Router struct {\n\t// route contains information about a API endpoint\n\troute *webhook.Route\n}\n\n// Implement Router\n// 1. GetRoute\n// 2. HandleRoute\n// 3. PostActivate\n// 4. PostDeactivate\n\n// GetRoute returns the route\nfunc (router *Router) GetRoute() *webhook.Route {\n\treturn router.route\n}\n\n// HandleRoute handles incoming requests on the route\nfunc (router *Router) HandleRoute(writer http.ResponseWriter, request *http.Request) {\n\troute := router.GetRoute()\n\n\tlogger := route.Logger.With(\n\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\tlogging.LabelPort, route.Context.Port,\n\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t)\n\n\tlogger.Info(\"a request received, processing it...\")\n\n\tif !route.Active {\n\t\tlogger.Info(\"endpoint is not active, wont't process the request\")\n\t\tcommon.SendErrorResponse(writer, \"endpoint is inactive\")\n\t\treturn\n\t}\n\n\tdefer func(start time.Time) {\n\t\troute.Metrics.EventProcessingDuration(route.EventSourceName, route.EventName, float64(time.Since(start)/time.Millisecond))\n\t}(time.Now())\n\n\trequest.Body = http.MaxBytesReader(writer, request.Body, 65536)\n\tbody, err := io.ReadAll(request.Body)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to parse request body\", zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tpayload := &events.WebhookEventData{\n\t\tHeader:   request.Header,\n\t\tBody:     (*json.RawMessage)(&body),\n\t\tMetadata: route.Context.Metadata,\n\t}\n\n\tdata, err := json.Marshal(payload)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to construct the event payload\", zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tlogger.Info(\"dispatching event on route's data channel...\")\n\troute.DataCh <- data\n\tlogger.Info(\"successfully processed the request\")\n\tcommon.SendSuccessResponse(writer, \"success\")\n}\n\n// PostActivate performs operations once the route is activated and ready to consume requests\nfunc (router *Router) PostActivate() error {\n\treturn nil\n}\n\n// PostInactivate performs operations after the route is inactivated\nfunc (router *Router) PostInactivate() error {\n\treturn nil\n}\n\n// StartListening starts listening events\nfunc (el *EventListener) StartListening(ctx context.Context, dispatch func([]byte, ...eventsourcecommon.Option) error) error {\n\tlog := logging.FromContext(ctx).\n\t\tWith(logging.LabelEventSourceType, el.GetEventSourceType(), logging.LabelEventName, el.GetEventName())\n\tlog.Info(\"started processing the webhook event source...\")\n\n\troute := webhook.NewRoute(&el.WebhookContext, log, el.GetEventSourceName(), el.GetEventName(), el.Metrics)\n\treturn webhook.ManageRoute(ctx, &Router{\n\t\troute: route,\n\t}, controller, dispatch)\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage webhook\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/eventsources/sources\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{\n\t\tWebhookContext: v1alpha1.WebhookContext{},\n\t}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"webhook.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Webhook)\n\n\tfor _, value := range eventSource.Spec.Webhook {\n\t\tl := &EventListener{\n\t\t\tWebhookContext: value,\n\t\t}\n\t\terr = l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}\n", "package main\n\nimport (\n\t\"os\"\n\n\t\"sigs.k8s.io/yaml\"\n)\n\ntype obj = map[string]interface{}\n\nfunc cleanCRD(filename string) {\n\tdata, err := os.ReadFile(filename)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tcrd := make(map[string]interface{})\n\terr = yaml.Unmarshal(data, &crd)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdelete(crd, \"status\")\n\tmetadata := crd[\"metadata\"].(obj)\n\tif metadata[\"name\"] == \"eventbuses.argoproj.io\" {\n\t\tmetadata[\"name\"] = \"eventbus.argoproj.io\"\n\t}\n\tdelete(metadata, \"annotations\")\n\tdelete(metadata, \"creationTimestamp\")\n\tspec := crd[\"spec\"].(obj)\n\tdelete(spec, \"validation\")\n\tnames := spec[\"names\"].(obj)\n\tif names[\"plural\"] == \"eventbuses\" {\n\t\tnames[\"plural\"] = \"eventbus\"\n\t}\n\tversions := spec[\"versions\"].([]interface{})\n\tversion := versions[0].(obj)\n\tproperties := version[\"schema\"].(obj)[\"openAPIV3Schema\"].(obj)[\"properties\"].(obj)\n\tfor k := range properties {\n\t\tif k == \"spec\" || k == \"status\" {\n\t\t\tproperties[k] = obj{\"type\": \"object\", \"x-kubernetes-preserve-unknown-fields\": true}\n\t\t}\n\t}\n\tdata, err = yaml.Marshal(crd)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\terr = os.WriteFile(filename, data, 0666)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n}\n", "package main\n\nimport (\n\t\"encoding/json\"\n\t\"log\"\n\t\"os\"\n\t\"strings\"\n\n\t\"k8s.io/kube-openapi/pkg/common\"\n\t\"k8s.io/kube-openapi/pkg/validation/spec\"\n\n\tcv1 \"github.com/argoproj/argo-events/pkg/apis/common\"\n\tebv1 \"github.com/argoproj/argo-events/pkg/apis/eventbus/v1alpha1\"\n\tesv1 \"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\tsv1 \"github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1\"\n)\n\ntype (\n\tobj = map[string]interface{}\n)\n\n// Generate OpenAPI spec definitions for Workflow Resource\nfunc main() {\n\tif len(os.Args) <= 3 {\n\t\tlog.Fatal(\"Supply a version\")\n\t}\n\tlog.Println(os.Args)\n\tversion := os.Args[1]\n\tkubeSwaggerPath := os.Args[2]\n\toutput := os.Args[3]\n\tif version != \"latest\" && !strings.HasPrefix(version, \"v\") {\n\t\tversion = \"v\" + version\n\t}\n\treferenceCallback := func(name string) spec.Ref {\n\t\treturn spec.MustCreateRef(\"#/definitions/\" + common.EscapeJsonPointer(swaggify(name)))\n\t}\n\tdefs := spec.Definitions{}\n\tdependencies := []string{}\n\tfor defName, val := range cv1.GetOpenAPIDefinitions(referenceCallback) {\n\t\tdefs[swaggify(defName)] = val.Schema\n\t\tdependencies = append(dependencies, val.Dependencies...)\n\t}\n\tfor defName, val := range ebv1.GetOpenAPIDefinitions(referenceCallback) {\n\t\tdefs[swaggify(defName)] = val.Schema\n\t\tdependencies = append(dependencies, val.Dependencies...)\n\t}\n\tfor defName, val := range esv1.GetOpenAPIDefinitions(referenceCallback) {\n\t\tdefs[swaggify(defName)] = val.Schema\n\t\tdependencies = append(dependencies, val.Dependencies...)\n\t}\n\tfor defName, val := range sv1.GetOpenAPIDefinitions(referenceCallback) {\n\t\tdefs[swaggify(defName)] = val.Schema\n\t\tdependencies = append(dependencies, val.Dependencies...)\n\t}\n\n\tk8sDefinitions := getKubernetesSwagger(kubeSwaggerPath)\n\tfor _, dep := range dependencies {\n\t\tif !strings.Contains(dep, \"k8s.io\") {\n\t\t\tcontinue\n\t\t}\n\t\td := swaggify(dep)\n\t\tif kd, ok := k8sDefinitions[d]; ok {\n\t\t\tdefs[d] = kd\n\t\t}\n\t}\n\tfor d, s := range k8sDefinitions {\n\t\tdefs[d] = s\n\t}\n\n\tswagger := &spec.Swagger{\n\t\tSwaggerProps: spec.SwaggerProps{\n\t\t\tSwagger:     \"2.0\",\n\t\t\tDefinitions: defs,\n\t\t\tPaths:       &spec.Paths{Paths: map[string]spec.PathItem{}},\n\t\t\tInfo: &spec.Info{\n\t\t\t\tInfoProps: spec.InfoProps{\n\t\t\t\t\tTitle:   \"Argo Events\",\n\t\t\t\t\tVersion: version,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tjsonBytes, err := json.MarshalIndent(swagger, \"\", \"  \")\n\tif err != nil {\n\t\tlog.Fatal(err.Error())\n\t}\n\terr = os.WriteFile(output, jsonBytes, 0644)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tf, err := os.Open(output)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\t// filter out \"default\" fields from swagger definitions properties because they are being set to empty strings and it makes the swagger validation fail.\n\tswaggerObj := obj{}\n\terr = json.NewDecoder(f).Decode(&swaggerObj)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefinitions := swaggerObj[\"definitions\"].(obj)\n\n\tfor _, d := range definitions {\n\t\tprops, ok := d.(obj)[\"properties\"].(obj)\n\t\tif ok {\n\t\t\tfor _, prop := range props {\n\t\t\t\tprop := prop.(obj)\n\t\t\t\tdelete(prop, \"default\")\n\t\t\t\titems, ok := prop[\"items\"].(obj)\n\t\t\t\tif ok {\n\t\t\t\t\tdelete(items, \"default\")\n\t\t\t\t}\n\t\t\t\tadditionalProperties, ok := prop[\"additionalProperties\"].(obj)\n\t\t\t\tif ok {\n\t\t\t\t\tdelete(additionalProperties, \"default\")\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tprops, ok = d.(obj)[\"additionalProperties\"].(obj)\n\t\tif ok {\n\t\t\tdelete(props, \"default\")\n\t\t}\n\t}\n\n\tf, err = os.Create(output)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\te := json.NewEncoder(f)\n\te.SetIndent(\"\", \"  \")\n\terr = e.Encode(swaggerObj)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\terr = f.Close()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n}\n\n// swaggify converts the github package\n// e.g.:\n// github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1.Sensor\n// to:\n// io.argoproj.v1alpha1.Sensor\nfunc swaggify(name string) string {\n\tname = strings.ReplaceAll(name, \"github.com/argoproj/argo-events/pkg/apis\", \"argoproj.io\")\n\tparts := strings.Split(name, \"/\")\n\thostParts := strings.Split(parts[0], \".\")\n\t// reverses something like k8s.io to io.k8s\n\tfor i, j := 0, len(hostParts)-1; i < j; i, j = i+1, j-1 {\n\t\thostParts[i], hostParts[j] = hostParts[j], hostParts[i]\n\t}\n\tparts[0] = strings.Join(hostParts, \".\")\n\treturn strings.Join(parts, \".\")\n}\n\nfunc getKubernetesSwagger(kubeSwaggerPath string) spec.Definitions {\n\tdata, err := os.ReadFile(kubeSwaggerPath)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tswagger := &spec.Swagger{}\n\terr = json.Unmarshal(data, swagger)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn swagger.Definitions\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage artifacts\n\nimport (\n\t\"errors\"\n\t\"os\"\n\n\t\"github.com/argoproj/argo-events/common/logging\"\n\t\"github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1\"\n)\n\n// FileReader implements the ArtifactReader interface for file artifacts\ntype FileReader struct {\n\tfileArtifact *v1alpha1.FileArtifact\n}\n\n// NewFileReader creates a new ArtifactReader for inline\nfunc NewFileReader(fileArtifact *v1alpha1.FileArtifact) (ArtifactReader, error) {\n\t// This should never happen!\n\tif fileArtifact == nil {\n\t\treturn nil, errors.New(\"FileArtifact cannot be empty\")\n\t}\n\treturn &FileReader{fileArtifact}, nil\n}\n\nfunc (reader *FileReader) Read() ([]byte, error) {\n\tcontent, err := os.ReadFile(reader.fileArtifact.Path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tlog := logging.NewArgoEventsLogger()\n\tlog.Debugf(\"reading fileArtifact from %s\", reader.fileArtifact.Path)\n\treturn content, nil\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage artifacts\n\nimport (\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1\"\n)\n\nfunc TestFileReader(t *testing.T) {\n\tcontent := []byte(\"temp content\")\n\ttmpfile, err := os.CreateTemp(\"\", \"argo-events-temp\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tdefer os.Remove(tmpfile.Name())\n\n\tif _, err := tmpfile.Write(content); err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif err := tmpfile.Close(); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tfileArtifact := v1alpha1.FileArtifact{Path: tmpfile.Name()}\n\tfileReader, err := NewFileReader(&fileArtifact)\n\tassert.NotNil(t, fileReader)\n\tassert.Nil(t, err)\n\tdata, err := fileReader.Read()\n\tassert.NotNil(t, data)\n\tassert.Nil(t, err)\n\tassert.Equal(t, content, data)\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage artifacts\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"path\"\n\t\"strings\"\n\n\t\"github.com/go-git/go-git/v5\"\n\t\"github.com/go-git/go-git/v5/config\"\n\t\"github.com/go-git/go-git/v5/plumbing\"\n\t\"github.com/go-git/go-git/v5/plumbing/transport\"\n\t\"github.com/go-git/go-git/v5/plumbing/transport/http\"\n\tgo_git_ssh \"github.com/go-git/go-git/v5/plumbing/transport/ssh\"\n\t\"github.com/pkg/errors\"\n\t\"golang.org/x/crypto/ssh\"\n\n\t\"github.com/argoproj/argo-events/common\"\n\t\"github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1\"\n)\n\nconst (\n\tDefaultRemote = \"origin\"\n\tDefaultBranch = \"master\"\n)\n\nvar (\n\tfetchRefSpec = []config.RefSpec{\n\t\t\"refs/*:refs/*\",\n\t\t\"HEAD:refs/heads/HEAD\",\n\t}\n\n\tnotAllowedInPath = []string{\"..\", \"~\", \"\\\\\"}\n)\n\ntype GitArtifactReader struct {\n\tartifact *v1alpha1.GitArtifact\n}\n\n// NewGitReader returns a new git reader\nfunc NewGitReader(gitArtifact *v1alpha1.GitArtifact) (*GitArtifactReader, error) {\n\tif gitArtifact == nil {\n\t\treturn nil, fmt.Errorf(\"nil git artifact\")\n\t}\n\tfor _, na := range notAllowedInPath {\n\t\tif strings.Contains(gitArtifact.FilePath, na) {\n\t\t\treturn nil, fmt.Errorf(\"%q is not allowed in the filepath\", na)\n\t\t}\n\t}\n\n\treturn &GitArtifactReader{\n\t\tartifact: gitArtifact,\n\t}, nil\n}\n\nfunc (g *GitArtifactReader) getRemote() string {\n\tif g.artifact.Remote != nil {\n\t\treturn g.artifact.Remote.Name\n\t}\n\treturn DefaultRemote\n}\n\nfunc getSSHKeyAuth(sshKeyFile string) (transport.AuthMethod, error) {\n\tsshKey, err := os.ReadFile(sshKeyFile)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to read ssh key file. err: %+v\", err)\n\t}\n\tsigner, err := ssh.ParsePrivateKey(sshKey)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to parse ssh key. err: %+v\", err)\n\t}\n\tauth := &go_git_ssh.PublicKeys{User: \"git\", Signer: signer}\n\tauth.HostKeyCallback = ssh.InsecureIgnoreHostKey()\n\treturn auth, nil\n}\n\nfunc (g *GitArtifactReader) getGitAuth() (transport.AuthMethod, error) {\n\tif g.artifact.Creds != nil {\n\t\tusername, err := common.GetSecretFromVolume(g.artifact.Creds.Username)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to retrieve username\")\n\t\t}\n\t\tpassword, err := common.GetSecretFromVolume(g.artifact.Creds.Password)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to retrieve password\")\n\t\t}\n\t\treturn &http.BasicAuth{\n\t\t\tUsername: username,\n\t\t\tPassword: password,\n\t\t}, nil\n\t}\n\tif g.artifact.SSHKeySecret != nil {\n\t\tsshKeyPath, err := common.GetSecretVolumePath(g.artifact.SSHKeySecret)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to get SSH key from mounted volume\")\n\t\t}\n\t\treturn getSSHKeyAuth(sshKeyPath)\n\t}\n\treturn nil, nil\n}\n\nfunc (g *GitArtifactReader) readFromRepository(r *git.Repository, dir string) ([]byte, error) {\n\tauth, err := g.getGitAuth()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif g.artifact.Remote != nil {\n\t\t_, err := r.CreateRemote(&config.RemoteConfig{\n\t\t\tName: g.artifact.Remote.Name,\n\t\t\tURLs: g.artifact.Remote.URLS,\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to create remote. err: %+v\", err)\n\t\t}\n\n\t\tfetchOptions := &git.FetchOptions{\n\t\t\tRemoteName: g.artifact.Remote.Name,\n\t\t\tRefSpecs:   fetchRefSpec,\n\t\t\tForce:      true,\n\t\t}\n\t\tif auth != nil {\n\t\t\tfetchOptions.Auth = auth\n\t\t}\n\n\t\tif err := r.Fetch(fetchOptions); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to fetch remote %s. err: %+v\", g.artifact.Remote.Name, err)\n\t\t}\n\t}\n\n\tw, err := r.Worktree()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to get working tree. err: %+v\", err)\n\t}\n\n\tfetchOptions := &git.FetchOptions{\n\t\tRemoteName: g.getRemote(),\n\t\tRefSpecs:   fetchRefSpec,\n\t\tForce:      true,\n\t}\n\tif auth != nil {\n\t\tfetchOptions.Auth = auth\n\t}\n\n\t// In the case of a specific given ref, it isn't necessary to fetch anything\n\t// but the single ref\n\tif g.artifact.Ref != \"\" {\n\t\tfetchOptions.Depth = 1\n\t\tfetchOptions.RefSpecs = []config.RefSpec{config.RefSpec(g.artifact.Ref + \":\" + g.artifact.Ref)}\n\t}\n\n\tif err := r.Fetch(fetchOptions); err != nil && err != git.NoErrAlreadyUpToDate {\n\t\treturn nil, fmt.Errorf(\"failed to fetch. err: %v\", err)\n\t}\n\n\tif err := w.Checkout(g.getBranchOrTag()); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to checkout. err: %+v\", err)\n\t}\n\n\t// In the case of a specific given ref, it shouldn't be necessary to pull\n\tif g.artifact.Ref != \"\" {\n\t\tpullOpts := &git.PullOptions{\n\t\t\tRecurseSubmodules: git.DefaultSubmoduleRecursionDepth,\n\t\t\tReferenceName:     g.getBranchOrTag().Branch,\n\t\t\tForce:             true,\n\t\t}\n\t\tif auth != nil {\n\t\t\tpullOpts.Auth = auth\n\t\t}\n\n\t\tif err := w.Pull(pullOpts); err != nil && err != git.NoErrAlreadyUpToDate {\n\t\t\treturn nil, fmt.Errorf(\"failed to pull latest updates. err: %+v\", err)\n\t\t}\n\t}\n\tfilePath := fmt.Sprintf(\"%s/%s\", dir, g.artifact.FilePath)\n\t// symbol link is not allowed due to security concern\n\tisSymbolLink, err := isSymbolLink(filePath)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif isSymbolLink {\n\t\treturn nil, fmt.Errorf(\"%q is a symbol link which is not allowed\", g.artifact.FilePath)\n\t}\n\treturn os.ReadFile(filePath)\n}\n\nfunc (g *GitArtifactReader) getBranchOrTag() *git.CheckoutOptions {\n\topts := &git.CheckoutOptions{}\n\n\topts.Branch = plumbing.NewBranchReferenceName(DefaultBranch)\n\n\tif g.artifact.Branch != \"\" {\n\t\topts.Branch = plumbing.NewBranchReferenceName(g.artifact.Branch)\n\t}\n\tif g.artifact.Tag != \"\" {\n\t\topts.Branch = plumbing.NewTagReferenceName(g.artifact.Tag)\n\t}\n\tif g.artifact.Ref != \"\" {\n\t\topts.Branch = plumbing.ReferenceName(g.artifact.Ref)\n\t}\n\n\treturn opts\n}\n\nfunc (g *GitArtifactReader) Read() ([]byte, error) {\n\tcloneDir := g.artifact.CloneDirectory\n\tif cloneDir == \"\" {\n\t\ttempDir, err := os.MkdirTemp(\"\", \"git-tmp\")\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to create a temp file to clone the repository\")\n\t\t}\n\t\tdefer os.Remove(tempDir)\n\t\tcloneDir = tempDir\n\t}\n\n\tr, err := git.PlainOpen(cloneDir)\n\tif err != nil {\n\t\tif err != git.ErrRepositoryNotExists {\n\t\t\treturn nil, fmt.Errorf(\"failed to open repository. err: %+v\", err)\n\t\t}\n\n\t\tcloneOpt := &git.CloneOptions{\n\t\t\tURL:               g.artifact.URL,\n\t\t\tRecurseSubmodules: git.DefaultSubmoduleRecursionDepth,\n\t\t}\n\n\t\tauth, err := g.getGitAuth()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif auth != nil {\n\t\t\tcloneOpt.Auth = auth\n\t\t}\n\n\t\t// In the case of a specific given ref, it isn't necessary to have branch\n\t\t// histories\n\t\tif g.artifact.Ref != \"\" {\n\t\t\tcloneOpt.Depth = 1\n\t\t}\n\n\t\tr, err = git.PlainClone(cloneDir, false, cloneOpt)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to clone repository. err: %+v\", err)\n\t\t}\n\t}\n\treturn g.readFromRepository(r, cloneDir)\n}\n\nfunc isSymbolLink(filepath string) (bool, error) {\n\tfi, err := os.Lstat(path.Clean(filepath))\n\tif err != nil {\n\t\treturn false, err\n\t}\n\tif fi.Mode()&os.ModeSymlink != 0 {\n\t\treturn true, nil\n\t}\n\treturn false, nil\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage artifacts\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io\"\n\n\t\"github.com/minio/minio-go/v7\"\n\t\"github.com/minio/minio-go/v7/pkg/credentials\"\n\n\t\"github.com/argoproj/argo-events/common/logging\"\n\tapicommon \"github.com/argoproj/argo-events/pkg/apis/common\"\n)\n\n// S3Reader implements the ArtifactReader interface and allows reading artifacts from S3 compatible API store\ntype S3Reader struct {\n\tclient *minio.Client\n\ts3     *apicommon.S3Artifact\n\tcreds  *Credentials\n}\n\n// NewS3Reader creates a new ArtifactReader for an S3 compatible store\nfunc NewS3Reader(s3 *apicommon.S3Artifact, creds *Credentials) (ArtifactReader, error) {\n\tclient, err := NewMinioClient(s3, *creds)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &S3Reader{\n\t\tclient: client,\n\t\ts3:     s3,\n\t\tcreds:  creds,\n\t}, nil\n}\n\nfunc (reader *S3Reader) Read() ([]byte, error) {\n\tlog := logging.NewArgoEventsLogger()\n\tlog.Debugf(\"reading s3Artifact from %s/%s\", reader.s3.Bucket.Name, reader.s3.Bucket.Key)\n\tobj, err := reader.client.GetObject(context.Background(), reader.s3.Bucket.Name, reader.s3.Bucket.Key, minio.GetObjectOptions{})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer func() {\n\t\tif err := obj.Close(); err != nil {\n\t\t\tfmt.Printf(\"failed to close object. err: %+v\", err)\n\t\t}\n\t}()\n\n\tb, err := io.ReadAll(io.LimitReader(obj, 65536))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn b, nil\n}\n\n// NewMinioClient instantiates a new minio client object to access s3 compatible APIs\nfunc NewMinioClient(s3 *apicommon.S3Artifact, creds Credentials) (*minio.Client, error) {\n\tvar minioClient *minio.Client\n\tvar err error\n\tif s3.Region != \"\" {\n\t\tminioClient, err = minio.New(s3.Endpoint, &minio.Options{\n\t\t\tCreds: credentials.NewStaticV4(creds.accessKey, creds.secretKey, \"\"), Secure: !s3.Insecure, Region: s3.Region})\n\t} else {\n\t\tminioClient, err = minio.New(s3.Endpoint, &minio.Options{\n\t\t\tCreds: credentials.NewStaticV4(creds.accessKey, creds.secretKey, \"\"), Secure: !s3.Insecure})\n\t}\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn minioClient, nil\n}\n", "/*\nCopyright 2018 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage artifacts\n\nimport (\n\t\"context\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1\"\n\t\"github.com/stretchr/testify/assert\"\n\tapiv1 \"k8s.io/api/core/v1\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/client-go/kubernetes/fake\"\n)\n\ntype FakeWorkflowArtifactReader struct{}\n\nfunc (f *FakeWorkflowArtifactReader) Read() ([]byte, error) {\n\treturn []byte(workflowv1alpha1), nil\n}\n\nfunc TestFetchArtifact(t *testing.T) {\n\treader := &FakeWorkflowArtifactReader{}\n\tobj, err := FetchArtifact(reader)\n\tassert.Nil(t, err)\n\tassert.Equal(t, \"argoproj.io/v1alpha1\", obj.GetAPIVersion())\n\tassert.Equal(t, \"Workflow\", obj.GetKind())\n}\n\nfunc TestGetCredentials(t *testing.T) {\n\tfakeClient := fake.NewSimpleClientset()\n\n\tmySecretCredentials := &apiv1.Secret{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"test\",\n\t\t\tNamespace: \"testing\",\n\t\t},\n\t\tData: map[string][]byte{\"access\": []byte(\"token\"), \"secret\": []byte(\"value\")},\n\t}\n\t_, err := fakeClient.CoreV1().Secrets(\"testing\").Create(context.TODO(), mySecretCredentials, metav1.CreateOptions{})\n\tassert.Nil(t, err)\n\n\t// creds should be nil for unknown minio type\n\tunknownArtifact := &v1alpha1.ArtifactLocation{}\n\tcreds, err := GetCredentials(unknownArtifact)\n\tassert.Nil(t, creds)\n\tassert.Nil(t, err)\n}\n\nfunc TestGetArtifactReader(t *testing.T) {\n\t// test unknown failure\n\tlocation := &v1alpha1.ArtifactLocation{}\n\tcreds := &Credentials{\n\t\taccessKey: \"access\",\n\t\tsecretKey: \"secret\",\n\t}\n\t_, err := GetArtifactReader(location, creds)\n\tassert.NotNil(t, err)\n}\n\nfunc TestDecodeSensor(t *testing.T) {\n\tb, err := os.ReadFile(\"../../examples/sensors/multi-trigger-sensor.yaml\")\n\tassert.Nil(t, err)\n\t_, err = decodeAndUnstructure(b)\n\tassert.Nil(t, err)\n}\n\nfunc TestDecodeWorkflow(t *testing.T) {\n\t_, err := decodeAndUnstructure([]byte(workflowv1alpha1))\n\tassert.Nil(t, err)\n}\n\nvar workflowv1alpha1 = `\napiVersion: argoproj.io/v1alpha1\nkind: Workflow\nmetadata:\n  generateName: hello-world-\nspec:\n  entrypoint: whalesay\n  templates:\n  - name: whalesay\n    container:\n      image: docker/whalesay:latest\n      command: [cowsay]\n      args: [\"hello world\"]\n`\n\nfunc TestDecodeDeploymentv1(t *testing.T) {\n\t_, err := decodeAndUnstructure([]byte(deploymentv1))\n\tassert.Nil(t, err)\n}\n\nvar deploymentv1 = `\n{\n\t\"apiVersion\": \"apps/v1\",\n\t\"kind\": \"Deployment\",\n\t\"metadata\": {\n\t  \"name\": \"nginx-deployment\",\n\t  \"labels\": {\n\t\t\"app\": \"nginx\"\n\t  }\n\t},\n\t\"spec\": {\n\t  \"replicas\": 3,\n\t  \"selector\": {\n\t\t\"matchLabels\": {\n\t\t  \"app\": \"nginx\"\n\t\t}\n\t  },\n\t  \"template\": {\n\t\t\"metadata\": {\n\t\t  \"labels\": {\n\t\t\t\"app\": \"nginx\"\n\t\t  }\n\t\t},\n\t\t\"spec\": {\n\t\t  \"containers\": [\n\t\t\t{\n\t\t\t  \"name\": \"nginx\",\n\t\t\t  \"image\": \"nginx:1.7.9\",\n\t\t\t  \"ports\": [\n\t\t\t\t{\n\t\t\t\t  \"containerPort\": 80\n\t\t\t\t}\n\t\t\t  ]\n\t\t\t}\n\t\t  ]\n\t\t}\n\t  }\n\t}\n  }\n`\n\nfunc TestDecodeJobv1(t *testing.T) {\n\t_, err := decodeAndUnstructure([]byte(jobv1))\n\tassert.Nil(t, err)\n}\n\nvar jobv1 = `\napiVersion: batch/v1\nkind: Job\nmetadata:\n  # Unique key of the Job instance\n  name: example-job\nspec:\n  template:\n    metadata:\n      name: example-job\n    spec:\n      containers:\n      - name: pi\n        image: perl\n        command: [\"perl\"]\n        args: [\"-Mbignum=bpi\", \"-wle\", \"print bpi(2000)\"]\n      # Do not restart containers after they exit\n      restartPolicy: Never\n`\n\nfunc TestDecodeUnsupported(t *testing.T) {\n\t_, err := decodeAndUnstructure([]byte(unsupportedType))\n\tassert.Nil(t, err)\n}\n\nvar unsupportedType = `\napiVersion: extensions/v1beta1\nkind: DaemonSet\nmetadata:\n  # Unique key of the DaemonSet instance\n  name: daemonset-example\nspec:\n  template:\n    metadata:\n      labels:\n        app: daemonset-example\n    spec:\n      containers:\n      # This container is run once on each Node in the cluster\n      - name: daemonset-example\n        image: ubuntu:trusty\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - >-\n          while [ true ]; do\n          echo \"DaemonSet running on $(hostname)\" ;\n          sleep 10 ;\n          done\n`\n\nfunc TestDecodeUnknown(t *testing.T) {\n\t_, err := decodeAndUnstructure([]byte(unsupportedType))\n\tassert.Nil(t, err, \"expected nil error but got\", err)\n}\n", "package artifacts\n\nimport (\n\t\"crypto/tls\"\n\t\"io\"\n\t\"net/http\"\n\n\t\"github.com/pkg/errors\"\n\n\t\"github.com/argoproj/argo-events/common/logging\"\n\t\"github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1\"\n)\n\n// URLReader implements the ArtifactReader interface for urls\ntype URLReader struct {\n\turlArtifact *v1alpha1.URLArtifact\n}\n\n// NewURLReader creates a new ArtifactReader for workflows at URL endpoints.\nfunc NewURLReader(urlArtifact *v1alpha1.URLArtifact) (ArtifactReader, error) {\n\tif urlArtifact == nil {\n\t\treturn nil, errors.New(\"URLArtifact cannot be empty\")\n\t}\n\treturn &URLReader{urlArtifact}, nil\n}\n\nfunc (reader *URLReader) Read() ([]byte, error) {\n\tlog := logging.NewArgoEventsLogger()\n\tlog.Debugf(\"reading urlArtifact from %s\", reader.urlArtifact.Path)\n\tinsecureSkipVerify := !reader.urlArtifact.VerifyCert\n\tclient := &http.Client{\n\t\tTransport: &http.Transport{\n\t\t\tTLSClientConfig: &tls.Config{InsecureSkipVerify: insecureSkipVerify},\n\t\t},\n\t}\n\tresp, err := client.Get(reader.urlArtifact.Path)\n\tif err != nil {\n\t\tlog.Warnf(\"failed to read url %s: %s\", reader.urlArtifact.Path, err)\n\t\treturn nil, err\n\t}\n\tdefer resp.Body.Close()\n\n\tif resp.StatusCode != http.StatusOK {\n\t\tlog.Warnf(\"failed to read %s. status code: %d\", reader.urlArtifact.Path, resp.StatusCode)\n\t\treturn nil, errors.Errorf(\"status code %v\", resp.StatusCode)\n\t}\n\n\tcontent, err := io.ReadAll(io.LimitReader(resp.Body, 65536))\n\tif err != nil {\n\t\tlog.Warnf(\"failed to read url body for %s: %s\", reader.urlArtifact.Path, err)\n\t\treturn nil, err\n\t}\n\treturn content, nil\n}\n", "/*\nCopyright 2020 BlackRock, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\npackage argo_workflow\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"os/exec\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/pkg/errors\"\n\t\"go.uber.org/zap\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/apis/meta/v1/unstructured\"\n\t\"k8s.io/apimachinery/pkg/labels\"\n\t\"k8s.io/apimachinery/pkg/runtime/schema\"\n\t\"k8s.io/apimachinery/pkg/util/wait\"\n\t\"k8s.io/client-go/dynamic\"\n\t\"k8s.io/client-go/kubernetes\"\n\n\t\"github.com/argoproj/argo-events/common/logging\"\n\tapicommon \"github.com/argoproj/argo-events/pkg/apis/common\"\n\t\"github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1\"\n\t\"github.com/argoproj/argo-events/sensors/policy\"\n\t\"github.com/argoproj/argo-events/sensors/triggers\"\n)\n\n// ArgoWorkflowTrigger implements Trigger interface for Argo workflow\ntype ArgoWorkflowTrigger struct {\n\t// K8sClient is Kubernetes client\n\tK8sClient kubernetes.Interface\n\t// ArgoClient is Argo Workflow client\n\tDynamicClient dynamic.Interface\n\t// Sensor object\n\tSensor *v1alpha1.Sensor\n\t// Trigger definition\n\tTrigger *v1alpha1.Trigger\n\t// logger to log stuff\n\tLogger *zap.SugaredLogger\n\n\tnamespableDynamicClient dynamic.NamespaceableResourceInterface\n\tcmdRunner               func(cmd *exec.Cmd) error\n}\n\n// NewArgoWorkflowTrigger returns a new Argo workflow trigger\nfunc NewArgoWorkflowTrigger(k8sClient kubernetes.Interface, dynamicClient dynamic.Interface, sensor *v1alpha1.Sensor, trigger *v1alpha1.Trigger, logger *zap.SugaredLogger) *ArgoWorkflowTrigger {\n\treturn &ArgoWorkflowTrigger{\n\t\tK8sClient:     k8sClient,\n\t\tDynamicClient: dynamicClient,\n\t\tSensor:        sensor,\n\t\tTrigger:       trigger,\n\t\tLogger:        logger.With(logging.LabelTriggerType, apicommon.ArgoWorkflowTrigger),\n\t\tcmdRunner: func(cmd *exec.Cmd) error {\n\t\t\treturn cmd.Run()\n\t\t},\n\t}\n}\n\n// GetTriggerType returns the type of the trigger\nfunc (t *ArgoWorkflowTrigger) GetTriggerType() apicommon.TriggerType {\n\treturn apicommon.ArgoWorkflowTrigger\n}\n\n// FetchResource fetches the trigger resource from external source\nfunc (t *ArgoWorkflowTrigger) FetchResource(ctx context.Context) (interface{}, error) {\n\ttrigger := t.Trigger\n\treturn triggers.FetchKubernetesResource(trigger.Template.ArgoWorkflow.Source)\n}\n\n// ApplyResourceParameters applies parameters to the trigger resource\nfunc (t *ArgoWorkflowTrigger) ApplyResourceParameters(events map[string]*v1alpha1.Event, resource interface{}) (interface{}, error) {\n\tobj, ok := resource.(*unstructured.Unstructured)\n\tif !ok {\n\t\treturn nil, errors.New(\"failed to interpret the trigger resource\")\n\t}\n\tif err := triggers.ApplyResourceParameters(events, t.Trigger.Template.ArgoWorkflow.Parameters, obj); err != nil {\n\t\treturn nil, err\n\t}\n\treturn obj, nil\n}\n\n// Execute executes the trigger\nfunc (t *ArgoWorkflowTrigger) Execute(ctx context.Context, events map[string]*v1alpha1.Event, resource interface{}) (interface{}, error) {\n\ttrigger := t.Trigger\n\n\top := v1alpha1.Submit\n\tif trigger.Template.ArgoWorkflow.Operation != \"\" {\n\t\top = trigger.Template.ArgoWorkflow.Operation\n\t}\n\n\tobj, ok := resource.(*unstructured.Unstructured)\n\tif !ok {\n\t\treturn nil, errors.New(\"failed to interpret the trigger resource\")\n\t}\n\n\tname := obj.GetName()\n\tif name == \"\" {\n\t\tif op != v1alpha1.Submit {\n\t\t\treturn nil, errors.Errorf(\"failed to execute the workflow %v operation, no name is given\", op)\n\t\t}\n\t\tif obj.GetGenerateName() == \"\" {\n\t\t\treturn nil, errors.New(\"failed to trigger the workflow, neither name nor generateName is given\")\n\t\t}\n\t}\n\n\tsubmittedWFLabels := make(map[string]string)\n\tif op == v1alpha1.Submit {\n\t\tsubmittedWFLabels[\"events.argoproj.io/sensor\"] = t.Sensor.Name\n\t\tsubmittedWFLabels[\"events.argoproj.io/trigger\"] = trigger.Template.Name\n\t\tsubmittedWFLabels[\"events.argoproj.io/action-timestamp\"] = strconv.Itoa(int(time.Now().UnixNano() / int64(time.Millisecond)))\n\t}\n\n\tnamespace := obj.GetNamespace()\n\tif namespace == \"\" {\n\t\tnamespace = t.Sensor.Namespace\n\t}\n\n\tvar cmd *exec.Cmd\n\n\tswitch op {\n\tcase v1alpha1.Submit:\n\t\tfile, err := os.CreateTemp(\"\", fmt.Sprintf(\"%s%s\", name, obj.GetGenerateName()))\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"failed to create a temp file for the workflow %s\", obj.GetName())\n\t\t}\n\t\tdefer os.Remove(file.Name())\n\n\t\t// Add labels\n\t\tlabels := obj.GetLabels()\n\t\tif labels == nil {\n\t\t\tlabels = make(map[string]string)\n\t\t}\n\t\tfor k, v := range submittedWFLabels {\n\t\t\tlabels[k] = v\n\t\t}\n\t\tobj.SetLabels(labels)\n\n\t\tjObj, err := obj.MarshalJSON()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tif _, err := file.Write(jObj); err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"failed to write workflow json %s to the temp file %s\", name, file.Name())\n\t\t}\n\t\tcmd = exec.Command(\"argo\", \"-n\", namespace, \"submit\", file.Name())\n\tcase v1alpha1.SubmitFrom:\n\t\twf := obj.GetKind()\n\t\tswitch strings.ToLower(wf) {\n\t\tcase \"cronworkflow\":\n\t\t\twf = \"cronwf\"\n\t\tcase \"workflow\":\n\t\t\twf = \"wf\"\n\t\tdefault:\n\t\t\treturn nil, errors.Errorf(\"invalid kind %s\", wf)\n\t\t}\n\t\tfromArg := fmt.Sprintf(\"%s/%s\", wf, name)\n\t\tcmd = exec.Command(\"argo\", \"-n\", namespace, \"submit\", \"--from\", fromArg)\n\tcase v1alpha1.Resubmit:\n\t\tcmd = exec.Command(\"argo\", \"-n\", namespace, \"resubmit\", name)\n\tcase v1alpha1.Resume:\n\t\tcmd = exec.Command(\"argo\", \"-n\", namespace, \"resume\", name)\n\tcase v1alpha1.Retry:\n\t\tcmd = exec.Command(\"argo\", \"-n\", namespace, \"retry\", name)\n\tcase v1alpha1.Suspend:\n\t\tcmd = exec.Command(\"argo\", \"-n\", namespace, \"suspend\", name)\n\tcase v1alpha1.Terminate:\n\t\tcmd = exec.Command(\"argo\", \"-n\", namespace, \"terminate\", name)\n\tcase v1alpha1.Stop:\n\t\tcmd = exec.Command(\"argo\", \"-n\", namespace, \"stop\", name)\n\tdefault:\n\t\treturn nil, errors.Errorf(\"unknown operation type %s\", string(op))\n\t}\n\n\tcmd.Stdout = os.Stdout\n\tcmd.Stderr = os.Stderr\n\tcmd.Args = append(cmd.Args, trigger.Template.ArgoWorkflow.Args...)\n\tif err := t.cmdRunner(cmd); err != nil {\n\t\treturn nil, errors.Wrapf(err, \"failed to execute %s command for workflow %s\", string(op), name)\n\t}\n\n\tt.namespableDynamicClient = t.DynamicClient.Resource(schema.GroupVersionResource{\n\t\tGroup:    \"argoproj.io\",\n\t\tVersion:  \"v1alpha1\",\n\t\tResource: \"workflows\",\n\t})\n\n\tif op != v1alpha1.Submit {\n\t\treturn t.namespableDynamicClient.Namespace(namespace).Get(ctx, name, metav1.GetOptions{})\n\t}\n\tl, err := t.namespableDynamicClient.Namespace(namespace).List(ctx, metav1.ListOptions{LabelSelector: labels.SelectorFromSet(submittedWFLabels).String()})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(l.Items) == 0 {\n\t\treturn nil, errors.New(\"failed to list created workflows for unknown reason\")\n\t}\n\treturn l.Items[0], nil\n}\n\n// ApplyPolicy applies the policy on the trigger\nfunc (t *ArgoWorkflowTrigger) ApplyPolicy(ctx context.Context, resource interface{}) error {\n\ttrigger := t.Trigger\n\n\tif trigger.Policy == nil || trigger.Policy.K8s == nil || trigger.Policy.K8s.Labels == nil {\n\t\treturn nil\n\t}\n\n\tobj, ok := resource.(*unstructured.Unstructured)\n\tif !ok {\n\t\treturn errors.New(\"failed to interpret the trigger resource\")\n\t}\n\n\tp := policy.NewResourceLabels(trigger, t.namespableDynamicClient, obj)\n\tif p == nil {\n\t\treturn nil\n\t}\n\n\terr := p.ApplyPolicy(ctx)\n\tif err != nil {\n\t\tswitch err {\n\t\tcase wait.ErrWaitTimeout:\n\t\t\tif trigger.Policy.K8s.ErrorOnBackoffTimeout {\n\t\t\t\treturn errors.Errorf(\"failed to determine status of the triggered resource. setting trigger state as failed\")\n\t\t\t}\n\t\t\treturn nil\n\t\tdefault:\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n", "package fixtures\n\nimport (\n\t\"os\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/client-go/kubernetes\"\n\t\"k8s.io/client-go/rest\"\n\t\"sigs.k8s.io/yaml\"\n\n\teventbusv1alpha1 \"github.com/argoproj/argo-events/pkg/apis/eventbus/v1alpha1\"\n\teventsourcev1alpha1 \"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\tsensorv1alpha1 \"github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1\"\n\teventbuspkg \"github.com/argoproj/argo-events/pkg/client/eventbus/clientset/versioned/typed/eventbus/v1alpha1\"\n\teventsourcepkg \"github.com/argoproj/argo-events/pkg/client/eventsource/clientset/versioned/typed/eventsource/v1alpha1\"\n\tsensorpkg \"github.com/argoproj/argo-events/pkg/client/sensor/clientset/versioned/typed/sensor/v1alpha1\"\n)\n\ntype Given struct {\n\tt                 *testing.T\n\teventBusClient    eventbuspkg.EventBusInterface\n\teventSourceClient eventsourcepkg.EventSourceInterface\n\tsensorClient      sensorpkg.SensorInterface\n\teventBus          *eventbusv1alpha1.EventBus\n\teventSource       *eventsourcev1alpha1.EventSource\n\tsensor            *sensorv1alpha1.Sensor\n\trestConfig        *rest.Config\n\tkubeClient        kubernetes.Interface\n}\n\n// creates an EventBus based on the parameter, this may be:\n//\n// 1. A file name if it starts with \"@\"\n// 2. Raw YAML.\nfunc (g *Given) EventBus(text string) *Given {\n\tg.t.Helper()\n\tg.eventBus = &eventbusv1alpha1.EventBus{}\n\tg.readResource(text, g.eventBus)\n\tl := g.eventBus.GetLabels()\n\tif l == nil {\n\t\tl = map[string]string{}\n\t}\n\tl[Label] = LabelValue\n\tg.eventBus.SetLabels(l)\n\tg.eventBus.SetName(EventBusName)\n\treturn g\n}\n\n// creates an EventSource based on the parameter, this may be:\n//\n// 1. A file name if it starts with \"@\"\n// 2. Raw YAML.\nfunc (g *Given) EventSource(text string) *Given {\n\tg.t.Helper()\n\tg.eventSource = &eventsourcev1alpha1.EventSource{}\n\tg.readResource(text, g.eventSource)\n\tl := g.eventSource.GetLabels()\n\tif l == nil {\n\t\tl = map[string]string{}\n\t}\n\tl[Label] = LabelValue\n\tg.eventSource.SetLabels(l)\n\tg.eventSource.Spec.EventBusName = EventBusName\n\treturn g\n}\n\n// creates a Sensor based on the parameter, this may be:\n//\n// 1. A file name if it starts with \"@\"\n// 2. Raw YAML.\nfunc (g *Given) Sensor(text string) *Given {\n\tg.t.Helper()\n\tg.sensor = &sensorv1alpha1.Sensor{}\n\tg.readResource(text, g.sensor)\n\tl := g.sensor.GetLabels()\n\tif l == nil {\n\t\tl = map[string]string{}\n\t}\n\tl[Label] = LabelValue\n\tg.sensor.SetLabels(l)\n\tg.sensor.Spec.EventBusName = EventBusName\n\treturn g\n}\n\nfunc (g *Given) readResource(text string, v metav1.Object) {\n\tg.t.Helper()\n\tvar file string\n\tif strings.HasPrefix(text, \"@\") {\n\t\tfile = strings.TrimPrefix(text, \"@\")\n\t} else {\n\t\tf, err := os.CreateTemp(\"\", \"argo-events-e2e\")\n\t\tif err != nil {\n\t\t\tg.t.Fatal(err)\n\t\t}\n\t\t_, err = f.Write([]byte(text))\n\t\tif err != nil {\n\t\t\tg.t.Fatal(err)\n\t\t}\n\t\terr = f.Close()\n\t\tif err != nil {\n\t\t\tg.t.Fatal(err)\n\t\t}\n\t\tfile = f.Name()\n\t}\n\n\tf, err := os.ReadFile(file)\n\tif err != nil {\n\t\tg.t.Fatal(err)\n\t}\n\terr = yaml.Unmarshal(f, v)\n\tif err != nil {\n\t\tg.t.Fatal(err)\n\t}\n}\n\nfunc (g *Given) When() *When {\n\treturn &When{\n\t\tt:                 g.t,\n\t\teventBusClient:    g.eventBusClient,\n\t\teventSourceClient: g.eventSourceClient,\n\t\tsensorClient:      g.sensorClient,\n\t\teventBus:          g.eventBus,\n\t\teventSource:       g.eventSource,\n\t\tsensor:            g.sensor,\n\t\trestConfig:        g.restConfig,\n\t\tkubeClient:        g.kubeClient,\n\t}\n}\n\nvar OutputRegexp = func(rx string) func(t *testing.T, output string, err error) {\n\treturn func(t *testing.T, output string, err error) {\n\t\tt.Helper()\n\t\tif assert.NoError(t, err, output) {\n\t\t\tassert.Regexp(t, rx, output)\n\t\t}\n\t}\n}\n", "package main\n\nimport (\n\t\"bufio\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"runtime\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/spf13/cobra\"\n\tcorev1 \"k8s.io/api/core/v1\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/runtime/schema\"\n\t\"k8s.io/client-go/dynamic\"\n\t\"k8s.io/client-go/kubernetes\"\n\t_ \"k8s.io/client-go/plugin/pkg/client/auth\"\n\t\"k8s.io/client-go/rest\"\n\t\"k8s.io/client-go/tools/clientcmd\"\n\t\"sigs.k8s.io/controller-runtime/pkg/manager/signals\"\n\t\"sigs.k8s.io/yaml\"\n\n\t\"github.com/argoproj/argo-events/pkg/apis/eventbus\"\n\teventbusv1alpha1 \"github.com/argoproj/argo-events/pkg/apis/eventbus/v1alpha1\"\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource\"\n\teventsourcev1alpha1 \"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n\t\"github.com/argoproj/argo-events/pkg/apis/sensor\"\n\tsensorv1alpha1 \"github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1\"\n\teventbusversiond \"github.com/argoproj/argo-events/pkg/client/eventbus/clientset/versioned\"\n\teventbuspkg \"github.com/argoproj/argo-events/pkg/client/eventbus/clientset/versioned/typed/eventbus/v1alpha1\"\n\teventsourceversiond \"github.com/argoproj/argo-events/pkg/client/eventsource/clientset/versioned\"\n\teventsourcepkg \"github.com/argoproj/argo-events/pkg/client/eventsource/clientset/versioned/typed/eventsource/v1alpha1\"\n\tsensorversiond \"github.com/argoproj/argo-events/pkg/client/sensor/clientset/versioned\"\n\tsensorpkg \"github.com/argoproj/argo-events/pkg/client/sensor/clientset/versioned/typed/sensor/v1alpha1\"\n\ttestutil \"github.com/argoproj/argo-events/test/util\"\n)\n\nconst (\n\teventBusName   = \"stress-testing\"\n\tdefaultTimeout = 60 * time.Second\n\n\tSuccess = \"success\"\n\tFailure = \"failure\"\n\n\tFirst = \"first\"\n\tLast  = \"last\"\n\n\tEventNameKey   = \"eventName\"\n\tTriggerNameKey = \"triggerName\"\n\n\tStressTestingLabel      = \"argo-events-stress\"\n\tStressTestingLabelValue = \"true\"\n\n\tlogEventSourceStarted      = \"Eventing server started.\"\n\tlogSensorStarted           = \"Sensor started.\"\n\tlogTriggerActionSuccessful = \"successfully processed trigger\"\n\tlogTriggerActionFailed     = \"failed to execute a trigger\"\n\tlogEventSuccessful         = \"succeeded to publish an event\"\n\tlogEventFailed             = \"failed to publish an event\"\n)\n\ntype TestingEventSource string\n\n// possible values of TestingEventSource\nconst (\n\tUnsupportedEventsource TestingEventSource = \"unsupported\"\n\tWebhookEventSource     TestingEventSource = \"webhook\"\n\tSQSEventSource         TestingEventSource = \"sqs\"\n\tSNSEventSource         TestingEventSource = \"sns\"\n\tKafkaEventSource       TestingEventSource = \"kafka\"\n\tNATSEventSource        TestingEventSource = \"nats\"\n\tRedisEventSource       TestingEventSource = \"redis\"\n)\n\ntype EventBusType string\n\n// possible value of EventBus type\nconst (\n\tUnsupportedEventBusType EventBusType = \"unsupported\"\n\tSTANEventBus            EventBusType = \"stan\"\n\tJetstreamEventBus       EventBusType = \"jetstream\"\n)\n\ntype TestingTrigger string\n\n// possible values of TestingTrigger\nconst (\n\tUnsupportedTrigger TestingTrigger = \"unsupported\"\n\tWorkflowTrigger    TestingTrigger = \"workflow\"\n\tLogTrigger         TestingTrigger = \"log\"\n)\n\nvar (\n\tbackground = metav1.DeletePropagationBackground\n)\n\ntype options struct {\n\tnamespace          string\n\ttestingEventSource TestingEventSource\n\ttestingTrigger     TestingTrigger\n\teventBusType       EventBusType\n\tesName             string\n\tsensorName         string\n\t// Inactive time before exiting\n\tidleTimeout time.Duration\n\thardTimeout *time.Duration\n\tnoCleanUp   bool\n\n\tkubeClient        kubernetes.Interface\n\teventBusClient    eventbuspkg.EventBusInterface\n\teventSourceClient eventsourcepkg.EventSourceInterface\n\tsensorClient      sensorpkg.SensorInterface\n\trestConfig        *rest.Config\n}\n\nfunc NewOptions(testingEventSource TestingEventSource, testingTrigger TestingTrigger, eventBusType EventBusType, esName, sensorName string, idleTimeout time.Duration, noCleanUp bool) (*options, error) {\n\tloadingRules := clientcmd.NewDefaultClientConfigLoadingRules()\n\tconfigOverrides := &clientcmd.ConfigOverrides{}\n\tkubeConfig := clientcmd.NewNonInteractiveDeferredLoadingClientConfig(loadingRules, configOverrides)\n\tconfig, err := kubeConfig.ClientConfig()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnamespace, _, _ := kubeConfig.Namespace()\n\tkubeClient, err := kubernetes.NewForConfig(config)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\teventBusClient := eventbusversiond.NewForConfigOrDie(config).ArgoprojV1alpha1().EventBus(namespace)\n\teventSourceClient := eventsourceversiond.NewForConfigOrDie(config).ArgoprojV1alpha1().EventSources(namespace)\n\tsensorClient := sensorversiond.NewForConfigOrDie(config).ArgoprojV1alpha1().Sensors(namespace)\n\treturn &options{\n\t\tnamespace:          namespace,\n\t\ttestingEventSource: testingEventSource,\n\t\ttestingTrigger:     testingTrigger,\n\t\teventBusType:       eventBusType,\n\t\tesName:             esName,\n\t\tsensorName:         sensorName,\n\t\tkubeClient:         kubeClient,\n\t\teventBusClient:     eventBusClient,\n\t\teventSourceClient:  eventSourceClient,\n\t\trestConfig:         config,\n\t\tsensorClient:       sensorClient,\n\t\tidleTimeout:        idleTimeout,\n\t\tnoCleanUp:          noCleanUp,\n\t}, nil\n}\n\nfunc (o *options) createEventBus(ctx context.Context) (*eventbusv1alpha1.EventBus, error) {\n\tfmt.Printf(\"------- Creating %v EventBus -------\\n\", o.eventBusType)\n\teb := &eventbusv1alpha1.EventBus{}\n\tif err := readResource(fmt.Sprintf(\"@testdata/eventbus/%v.yaml\", o.eventBusType), eb); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to read %v event bus yaml file: %w\", o.eventBusType, err)\n\t}\n\tl := eb.GetLabels()\n\tif l == nil {\n\t\tl = map[string]string{}\n\t}\n\tl[StressTestingLabel] = StressTestingLabelValue\n\teb.SetLabels(l)\n\teb.Name = eventBusName\n\tresult, err := o.eventBusClient.Create(ctx, eb, metav1.CreateOptions{})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create event bus: %w\", err)\n\t}\n\tif err := testutil.WaitForEventBusReady(ctx, o.eventBusClient, eb.Name, defaultTimeout); err != nil {\n\t\treturn nil, fmt.Errorf(\"expected to see event bus ready: %w\", err)\n\t}\n\tif err := testutil.WaitForEventBusStatefulSetReady(ctx, o.kubeClient, o.namespace, eb.Name, defaultTimeout); err != nil {\n\t\treturn nil, fmt.Errorf(\"expected to see event bus statefulset ready: %w\", err)\n\t}\n\treturn result, nil\n}\n\nfunc (o *options) createEventSource(ctx context.Context) (*eventsourcev1alpha1.EventSource, error) {\n\tfmt.Printf(\"\\n------- Creating %v EventSource -------\\n\", o.testingEventSource)\n\tes := &eventsourcev1alpha1.EventSource{}\n\tfile := fmt.Sprintf(\"@testdata/eventsources/%v.yaml\", o.testingEventSource)\n\tif err := readResource(file, es); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to read %v event source yaml file: %w\", o.testingEventSource, err)\n\t}\n\tl := es.GetLabels()\n\tif l == nil {\n\t\tl = map[string]string{}\n\t}\n\tl[StressTestingLabel] = StressTestingLabelValue\n\tes.SetLabels(l)\n\tes.Spec.EventBusName = eventBusName\n\tresult, err := o.eventSourceClient.Create(ctx, es, metav1.CreateOptions{})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create event source: %w\", err)\n\t}\n\tif err := testutil.WaitForEventSourceReady(ctx, o.eventSourceClient, es.Name, defaultTimeout); err != nil {\n\t\treturn nil, fmt.Errorf(\"expected to see event source ready: %w\", err)\n\t}\n\tif err := testutil.WaitForEventSourceDeploymentReady(ctx, o.kubeClient, o.namespace, es.Name, defaultTimeout); err != nil {\n\t\treturn nil, fmt.Errorf(\"expected to see event source deployment and pod ready: %w\", err)\n\t}\n\tcontains, err := testutil.EventSourcePodLogContains(ctx, o.kubeClient, o.namespace, es.Name, logEventSourceStarted)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"expected to see event source pod contains something: %w\", err)\n\t}\n\tif !contains {\n\t\treturn nil, fmt.Errorf(\"EventSource Pod does look good, it might have started failed\")\n\t}\n\treturn result, nil\n}\n\nfunc (o *options) createSensor(ctx context.Context) (*sensorv1alpha1.Sensor, error) {\n\tfmt.Printf(\"\\n------- Creating %v Sensor -------\\n\", o.testingTrigger)\n\tsensor := &sensorv1alpha1.Sensor{}\n\tfile := fmt.Sprintf(\"@testdata/sensors/%v.yaml\", o.testingTrigger)\n\tif err := readResource(file, sensor); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to read %v sensor yaml file: %w\", o.testingTrigger, err)\n\t}\n\tl := sensor.GetLabels()\n\tif l == nil {\n\t\tl = map[string]string{}\n\t}\n\tl[StressTestingLabel] = StressTestingLabelValue\n\tsensor.SetLabels(l)\n\tsensor.Spec.EventBusName = eventBusName\n\tresult, err := o.sensorClient.Create(ctx, sensor, metav1.CreateOptions{})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create sensor: %w\", err)\n\t}\n\tif err := testutil.WaitForSensorReady(ctx, o.sensorClient, sensor.Name, defaultTimeout); err != nil {\n\t\treturn nil, fmt.Errorf(\"expected to see sensor ready: %w\", err)\n\t}\n\tif err := testutil.WaitForSensorDeploymentReady(ctx, o.kubeClient, o.namespace, sensor.Name, defaultTimeout); err != nil {\n\t\treturn nil, fmt.Errorf(\"expected to see sensor deployment and pod ready: %w\", err)\n\t}\n\tcontains, err := testutil.SensorPodLogContains(ctx, o.kubeClient, o.namespace, sensor.Name, logSensorStarted)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"expected to see sensor pod contains something: %w\", err)\n\t}\n\tif !contains {\n\t\treturn nil, fmt.Errorf(\"Sensor Pod does look good, it might have started failed\")\n\t}\n\treturn result, nil\n}\n\nfunc (o *options) getEventSourcePodNames(ctx context.Context, eventSourceName string) ([]string, error) {\n\tlabelSelector := fmt.Sprintf(\"controller=eventsource-controller,eventsource-name=%s\", eventSourceName)\n\tesPodList, err := o.kubeClient.CoreV1().Pods(o.namespace).List(ctx, metav1.ListOptions{LabelSelector: labelSelector, FieldSelector: \"status.phase=Running\"})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tresults := []string{}\n\tfor _, i := range esPodList.Items {\n\t\tresults = append(results, i.Name)\n\t}\n\treturn results, nil\n}\n\nfunc (o *options) getSensorPodNames(ctx context.Context, sensorName string) ([]string, error) {\n\tlabelSelector := fmt.Sprintf(\"controller=sensor-controller,sensor-name=%s\", sensorName)\n\tsPodList, err := o.kubeClient.CoreV1().Pods(o.namespace).List(ctx, metav1.ListOptions{LabelSelector: labelSelector, FieldSelector: \"status.phase=Running\"})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tresults := []string{}\n\tfor _, i := range sPodList.Items {\n\t\tresults = append(results, i.Name)\n\t}\n\treturn results, nil\n}\n\nfunc (o *options) runTesting(ctx context.Context, eventSourceName, sensorName string) error {\n\tesPodNames, err := o.getEventSourcePodNames(ctx, eventSourceName)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to get event source pod names: %v\", err)\n\t}\n\tif len(esPodNames) == 0 {\n\t\treturn fmt.Errorf(\"no pod found for event source %s\", eventSourceName)\n\t}\n\tsensorPodNames, err := o.getSensorPodNames(ctx, sensorName)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to get sensor pod names: %v\", err)\n\t}\n\tif len(sensorPodNames) == 0 {\n\t\treturn fmt.Errorf(\"no pod found for sensor %s\", sensorName)\n\t}\n\n\tsuccessActionReg := regexp.MustCompile(logTriggerActionSuccessful)\n\tfailureActionReg := regexp.MustCompile(logTriggerActionFailed)\n\tsuccessEventReg := regexp.MustCompile(logEventSuccessful)\n\tfailureEventReg := regexp.MustCompile(logEventFailed)\n\n\tfmt.Printf(`\n*********************************************************\nThe application will automatically exit:\n  - If there's no active events and actions in %v.\n`, o.idleTimeout)\n\tif o.hardTimeout != nil {\n\t\tfmt.Printf(\"  - In %v after it starts.\\n\", *o.hardTimeout)\n\t}\n\tfmt.Printf(`\nOr you can terminate it any time by Ctrl + C.\n*********************************************************\n\n`)\n\n\tesMap := map[string]int64{}\n\tesTimeMap := map[string]time.Time{}\n\n\tsensorMap := map[string]int64{}\n\tsensorTimeMap := map[string]time.Time{}\n\n\tvar esLock = &sync.RWMutex{}\n\tvar sensorLock = &sync.RWMutex{}\n\n\tstartTime := time.Now()\n\n\twg := &sync.WaitGroup{}\n\tfor _, sensorPodName := range sensorPodNames {\n\t\twg.Add(1)\n\t\tgo func(podName string) {\n\t\t\tdefer wg.Done()\n\t\t\tfmt.Printf(\"Started watching Sensor Pod %s ...\\n\", podName)\n\t\t\tstream, err := o.kubeClient.CoreV1().Pods(o.namespace).GetLogs(podName, &corev1.PodLogOptions{Follow: true}).Stream(ctx)\n\t\t\tif err != nil {\n\t\t\t\tfmt.Printf(\"failed to acquire sensor pod %s log stream: %v\", podName, err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tdefer func() { _ = stream.Close() }()\n\n\t\t\tsCh := make(chan string)\n\t\t\tgo func(dataCh chan string) {\n\t\t\t\ts := bufio.NewScanner(stream)\n\t\t\t\tfor {\n\t\t\t\t\tif !s.Scan() {\n\t\t\t\t\t\tfmt.Printf(\"Can not read: %v\\n\", s.Err())\n\t\t\t\t\t\tclose(dataCh)\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tdata := s.Bytes()\n\t\t\t\t\ttriggerName := getLogValue(data, startTime, TriggerNameKey)\n\t\t\t\t\tif triggerName == \"\" {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif successActionReg.Match(data) {\n\t\t\t\t\t\tdataCh <- triggerName + \"/\" + Success\n\t\t\t\t\t} else if failureActionReg.Match(data) {\n\t\t\t\t\t\tdataCh <- triggerName + \"/\" + Failure\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}(sCh)\n\n\t\t\tfor {\n\t\t\t\tif o.hardTimeout != nil && time.Since(startTime).Seconds() > o.hardTimeout.Seconds() {\n\t\t\t\t\tfmt.Printf(\"Exited Sensor Pod %s due to the hard timeout %v\\n\", podName, *o.hardTimeout)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\ttimeout := 5 * 60 * time.Second\n\t\t\t\tlastActionTime := startTime\n\t\t\t\tsensorLock.RLock()\n\t\t\t\tif len(sensorMap) > 0 && len(sensorTimeMap) > 0 {\n\t\t\t\t\ttimeout = o.idleTimeout\n\t\t\t\t\tfor _, v := range sensorTimeMap {\n\t\t\t\t\t\tif v.After(lastActionTime) {\n\t\t\t\t\t\t\tlastActionTime = v\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tsensorLock.RUnlock()\n\n\t\t\t\tif time.Since(lastActionTime).Seconds() > timeout.Seconds() {\n\t\t\t\t\tfmt.Printf(\"Exited Sensor Pod %s due to no actions in the last %v\\n\", podName, o.idleTimeout)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase data, ok := <-sCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\t// e.g. triggerName/success\n\t\t\t\t\tt := strings.Split(data, \"/\")\n\t\t\t\t\tsensorLock.Lock()\n\t\t\t\t\tif _, ok := sensorMap[data]; !ok {\n\t\t\t\t\t\tsensorMap[t[0]+\"/\"+Success] = 0\n\t\t\t\t\t\tsensorMap[t[0]+\"/\"+Failure] = 0\n\t\t\t\t\t}\n\t\t\t\t\tif t[1] == Success {\n\t\t\t\t\t\tsensorMap[t[0]+\"/\"+Success]++\n\t\t\t\t\t} else {\n\t\t\t\t\t\tsensorMap[t[0]+\"/\"+Failure]++\n\t\t\t\t\t}\n\t\t\t\t\tif sensorMap[t[0]+\"/\"+Success]+sensorMap[t[0]+\"/\"+Failure] == 1 {\n\t\t\t\t\t\tsensorTimeMap[t[0]+\"/\"+First] = time.Now()\n\t\t\t\t\t}\n\t\t\t\t\tsensorTimeMap[t[0]+\"/\"+Last] = time.Now()\n\t\t\t\t\tsensorLock.Unlock()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(sensorPodName)\n\t}\n\n\tfor _, esPodName := range esPodNames {\n\t\twg.Add(1)\n\t\tgo func(podName string) {\n\t\t\tdefer wg.Done()\n\t\t\tfmt.Printf(\"Started watching EventSource Pod %s ...\\n\", podName)\n\t\t\tstream, err := o.kubeClient.CoreV1().Pods(o.namespace).GetLogs(podName, &corev1.PodLogOptions{Follow: true}).Stream(ctx)\n\t\t\tif err != nil {\n\t\t\t\tfmt.Printf(\"failed to acquire event source pod %s log stream: %v\", podName, err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tdefer func() { _ = stream.Close() }()\n\n\t\t\tsCh := make(chan string)\n\t\t\tgo func(dataCh chan string) {\n\t\t\t\ts := bufio.NewScanner(stream)\n\t\t\t\tfor {\n\t\t\t\t\tif !s.Scan() {\n\t\t\t\t\t\tfmt.Printf(\"Can not read: %v\\n\", s.Err())\n\t\t\t\t\t\tclose(dataCh)\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tdata := s.Bytes()\n\t\t\t\t\teventName := getLogValue(data, startTime, EventNameKey)\n\t\t\t\t\tif eventName == \"\" {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif successEventReg.Match(data) {\n\t\t\t\t\t\tdataCh <- eventName + \"/\" + Success\n\t\t\t\t\t} else if failureEventReg.Match(data) {\n\t\t\t\t\t\tdataCh <- eventName + \"/\" + Failure\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}(sCh)\n\n\t\t\tfor {\n\t\t\t\tif o.hardTimeout != nil && time.Since(startTime).Seconds() > o.hardTimeout.Seconds() {\n\t\t\t\t\tfmt.Printf(\"Exited EventSource Pod %s due to the hard timeout %v\\n\", podName, *o.hardTimeout)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\ttimeout := 5 * 60 * time.Second\n\t\t\t\tlastEventTime := startTime\n\n\t\t\t\tesLock.RLock()\n\t\t\t\tif len(esMap) > 0 && len(esTimeMap) > 0 {\n\t\t\t\t\ttimeout = o.idleTimeout\n\t\t\t\t\tfor _, v := range esTimeMap {\n\t\t\t\t\t\tif v.After(lastEventTime) {\n\t\t\t\t\t\t\tlastEventTime = v\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tesLock.RUnlock()\n\t\t\t\tif time.Since(lastEventTime).Seconds() > timeout.Seconds() {\n\t\t\t\t\tfmt.Printf(\"Exited EventSource Pod %s due to no active events in the last %v\\n\", podName, o.idleTimeout)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\tcase data, ok := <-sCh:\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\t// e.g. eventName/success\n\t\t\t\t\tt := strings.Split(data, \"/\")\n\t\t\t\t\tesLock.Lock()\n\t\t\t\t\tif _, ok := esMap[data]; !ok {\n\t\t\t\t\t\tesMap[t[0]+\"/\"+Success] = 0\n\t\t\t\t\t\tesMap[t[0]+\"/\"+Failure] = 0\n\t\t\t\t\t}\n\t\t\t\t\tif t[1] == Success {\n\t\t\t\t\t\tesMap[t[0]+\"/\"+Success]++\n\t\t\t\t\t} else {\n\t\t\t\t\t\tesMap[t[0]+\"/\"+Failure]++\n\t\t\t\t\t}\n\t\t\t\t\tif esMap[t[0]+\"/\"+Success]+esMap[t[0]+\"/\"+Failure] == 1 {\n\t\t\t\t\t\tesTimeMap[t[0]+\"/\"+First] = time.Now()\n\t\t\t\t\t}\n\t\t\t\t\tesTimeMap[t[0]+\"/\"+Last] = time.Now()\n\t\t\t\t\tesLock.Unlock()\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n\t\t}(esPodName)\n\t}\n\n\twg.Wait()\n\n\ttime.Sleep(3 * time.Second)\n\teventNames := []string{}\n\tfor k := range esMap {\n\t\tt := strings.Split(k, \"/\")\n\t\tif t[1] == Success {\n\t\t\teventNames = append(eventNames, t[0])\n\t\t}\n\t}\n\ttriggerNames := []string{}\n\tfor k := range sensorMap {\n\t\tt := strings.Split(k, \"/\")\n\t\tif t[1] == Success {\n\t\t\ttriggerNames = append(triggerNames, t[0])\n\t\t}\n\t}\n\tfmt.Printf(\"\\n++++++++++++++++++++++++ Events Summary +++++++++++++++++++++++\\n\")\n\tif len(eventNames) == 0 {\n\t\tfmt.Println(\"No events.\")\n\t} else {\n\t\tfor _, eventName := range eventNames {\n\t\t\tfmt.Printf(\"Event Name                    : %s\\n\", eventName)\n\t\t\tfmt.Printf(\"Total processed events        : %d\\n\", esMap[eventName+\"/\"+Success]+esMap[eventName+\"/\"+Failure])\n\t\t\tfmt.Printf(\"Events sent successful        : %d\\n\", esMap[eventName+\"/\"+Success])\n\t\t\tfmt.Printf(\"Events sent failed            : %d\\n\", esMap[eventName+\"/\"+Failure])\n\t\t\tfmt.Printf(\"First event sent at           : %v\\n\", esTimeMap[eventName+\"/\"+First])\n\t\t\tfmt.Printf(\"Last event sent at            : %v\\n\", esTimeMap[eventName+\"/\"+Last])\n\t\t\tfmt.Printf(\"Total time taken              : %v\\n\", esTimeMap[eventName+\"/\"+Last].Sub(esTimeMap[eventName+\"/\"+First]))\n\t\t\tfmt.Println(\"--\")\n\t\t}\n\t}\n\n\tfmt.Printf(\"\\n+++++++++++++++++++++++ Actions Summary +++++++++++++++++++++++\\n\")\n\tif len(triggerNames) == 0 {\n\t\tfmt.Println(\"No actions.\")\n\t} else {\n\t\tfor _, triggerName := range triggerNames {\n\t\t\tfmt.Printf(\"Trigger Name                  : %s\\n\", triggerName)\n\t\t\tfmt.Printf(\"Total triggered actions       : %d\\n\", sensorMap[triggerName+\"/\"+Success]+sensorMap[triggerName+\"/\"+Failure])\n\t\t\tfmt.Printf(\"Action triggered successfully : %d\\n\", sensorMap[triggerName+\"/\"+Success])\n\t\t\tfmt.Printf(\"Action triggered failed       : %d\\n\", sensorMap[triggerName+\"/\"+Failure])\n\t\t\tfmt.Printf(\"First action triggered at     : %v\\n\", sensorTimeMap[triggerName+\"/\"+First])\n\t\t\tfmt.Printf(\"Last action triggered at      : %v\\n\", sensorTimeMap[triggerName+\"/\"+Last])\n\t\t\tfmt.Printf(\"Total time taken              : %v\\n\", sensorTimeMap[triggerName+\"/\"+Last].Sub(sensorTimeMap[triggerName+\"/\"+First]))\n\t\t\tfmt.Println(\"--\")\n\t\t}\n\t}\n\treturn nil\n}\n\n// Check if it a valid log in JSON format, which contains something\n// like `\"ts\":1616093369.2583323`, and if it's later than start,\n// return the value of a log key\nfunc getLogValue(log []byte, start time.Time, key string) string {\n\tt := make(map[string]interface{})\n\tif err := json.Unmarshal(log, &t); err != nil {\n\t\t// invalid json format log\n\t\treturn \"\"\n\t}\n\tts, ok := t[\"ts\"]\n\tif !ok {\n\t\treturn \"\"\n\t}\n\ts, ok := ts.(float64)\n\tif !ok {\n\t\treturn \"\"\n\t}\n\tif float64(start.Unix()) > s {\n\t\t// old log\n\t\treturn \"\"\n\t}\n\tv, ok := t[key]\n\tif !ok {\n\t\treturn \"\"\n\t}\n\treturn fmt.Sprintf(\"%v\", v)\n}\n\nfunc (o *options) dynamicFor(r schema.GroupVersionResource) dynamic.ResourceInterface {\n\tresourceInterface := dynamic.NewForConfigOrDie(o.restConfig).Resource(r)\n\treturn resourceInterface.Namespace(o.namespace)\n}\n\nfunc (o *options) cleanUpResources(ctx context.Context) error {\n\thasTestLabel := metav1.ListOptions{LabelSelector: StressTestingLabel}\n\tresources := []schema.GroupVersionResource{\n\t\t{Group: eventsource.Group, Version: \"v1alpha1\", Resource: eventsource.Plural},\n\t\t{Group: sensor.Group, Version: \"v1alpha1\", Resource: sensor.Plural},\n\t\t{Group: eventbus.Group, Version: \"v1alpha1\", Resource: eventbus.Plural},\n\t}\n\tfor _, r := range resources {\n\t\tif err := o.dynamicFor(r).DeleteCollection(ctx, metav1.DeleteOptions{PropagationPolicy: &background}, hasTestLabel); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tfor _, r := range resources {\n\t\tfor {\n\t\t\tlist, err := o.dynamicFor(r).List(ctx, hasTestLabel)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif len(list.Items) == 0 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\ttime.Sleep(100 * time.Millisecond)\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (o *options) Start(ctx context.Context) error {\n\tfmt.Println(\"#################### Preparing ####################\")\n\n\tesName := o.esName\n\tsensorName := o.sensorName\n\n\t// Need to create\n\tif esName == \"\" && sensorName == \"\" {\n\t\t// Clean up resources if any\n\t\tif err := o.cleanUpResources(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\t\ttime.Sleep(10 * time.Second)\n\n\t\t// Create EventBus\n\t\teb, err := o.createEventBus(ctx)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tdefer func() {\n\t\t\tif !o.noCleanUp {\n\t\t\t\t_ = o.eventBusClient.Delete(ctx, eb.Name, metav1.DeleteOptions{})\n\t\t\t}\n\t\t}()\n\n\t\ttime.Sleep(5 * time.Second)\n\n\t\t// Create Sensor\n\t\tsensor, err := o.createSensor(ctx)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdefer func() {\n\t\t\tif !o.noCleanUp {\n\t\t\t\t_ = o.sensorClient.Delete(ctx, sensor.Name, metav1.DeleteOptions{})\n\t\t\t}\n\t\t}()\n\n\t\t// Create Event Source\n\t\tes, err := o.createEventSource(ctx)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdefer func() {\n\t\t\tif !o.noCleanUp {\n\t\t\t\t_ = o.eventSourceClient.Delete(ctx, es.Name, metav1.DeleteOptions{})\n\t\t\t}\n\t\t}()\n\n\t\tesName = es.Name\n\t\tsensorName = sensor.Name\n\t} else {\n\t\tfmt.Printf(\"------- Use existing EventSource and Sensor -------\\n\")\n\t\tfmt.Printf(\"EventSource name : %s\\n\", esName)\n\t\tfmt.Printf(\"Sensor name      : %s\\n\", sensorName)\n\t}\n\n\t// Run testing\n\tfmt.Println(\"\")\n\tfmt.Println(\"################# Started Testing #################\")\n\n\treturn o.runTesting(ctx, esName, sensorName)\n}\n\nfunc readResource(text string, v metav1.Object) error {\n\tvar data []byte\n\tvar err error\n\tif strings.HasPrefix(text, \"@\") {\n\t\tfile := strings.TrimPrefix(text, \"@\")\n\t\t_, fileName, _, _ := runtime.Caller(0)\n\t\tdata, err = os.ReadFile(filepath.Dir(fileName) + \"/\" + file)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to read a file: %w\", err)\n\t\t}\n\t} else {\n\t\tdata = []byte(text)\n\t}\n\tif err = yaml.Unmarshal(data, v); err != nil {\n\t\treturn fmt.Errorf(\"failed to unmarshal the yaml: %w\", err)\n\t}\n\treturn nil\n}\n\nfunc getTestingEventSource(str string) TestingEventSource {\n\tswitch str {\n\tcase \"webhook\":\n\t\treturn WebhookEventSource\n\tcase \"sqs\":\n\t\treturn SQSEventSource\n\tcase \"sns\":\n\t\treturn SNSEventSource\n\tcase \"kafka\":\n\t\treturn KafkaEventSource\n\tcase \"redis\":\n\t\treturn RedisEventSource\n\tcase \"nats\":\n\t\treturn NATSEventSource\n\tdefault:\n\t\treturn UnsupportedEventsource\n\t}\n}\n\nfunc getEventBusType(str string) EventBusType {\n\tswitch str {\n\tcase \"jetstream\":\n\t\treturn JetstreamEventBus\n\tcase \"stan\":\n\t\treturn STANEventBus\n\tdefault:\n\t\treturn UnsupportedEventBusType\n\t}\n}\n\nfunc getTestingTrigger(str string) TestingTrigger {\n\tswitch str {\n\tcase \"log\":\n\t\treturn LogTrigger\n\tcase \"workflow\":\n\t\treturn WorkflowTrigger\n\tdefault:\n\t\treturn UnsupportedTrigger\n\t}\n}\n\nfunc main() {\n\tvar (\n\t\tebTypeStr      string\n\t\tesTypeStr      string\n\t\ttriggerTypeStr string\n\t\tesName         string\n\t\tsensorName     string\n\t\tidleTimeoutStr string\n\t\thardTimeoutStr string\n\t\tnoCleanUp      bool\n\t)\n\tvar rootCmd = &cobra.Command{\n\t\tUse:   \"go run ./test/stress/main.go\",\n\t\tShort: \"Argo Events stress testing.\",\n\t\tLong:  ``,\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tesType := getTestingEventSource(esTypeStr)\n\t\t\ttriggerType := getTestingTrigger(triggerTypeStr)\n\t\t\tif esName == \"\" && sensorName == \"\" {\n\t\t\t\tif esType == UnsupportedEventsource {\n\t\t\t\t\tfmt.Printf(\"Invalid event source %s\\n\\n\", esTypeStr)\n\t\t\t\t\tcmd.HelpFunc()(cmd, args)\n\t\t\t\t\tos.Exit(1)\n\t\t\t\t}\n\n\t\t\t\tif triggerType == UnsupportedTrigger {\n\t\t\t\t\tfmt.Printf(\"Invalid trigger %s\\n\\n\", triggerTypeStr)\n\t\t\t\t\tcmd.HelpFunc()(cmd, args)\n\t\t\t\t\tos.Exit(1)\n\t\t\t\t}\n\t\t\t} else if (esName == \"\" && sensorName != \"\") || (esName != \"\" && sensorName == \"\") {\n\t\t\t\tfmt.Printf(\"Both event source name and sensor name need to be specified\\n\\n\")\n\t\t\t\tcmd.HelpFunc()(cmd, args)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\teventBusType := getEventBusType(ebTypeStr)\n\t\t\tif eventBusType == UnsupportedEventBusType {\n\t\t\t\tfmt.Printf(\"Invalid event bus type %s\\n\\n\", ebTypeStr)\n\t\t\t\tcmd.HelpFunc()(cmd, args)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\n\t\t\tidleTimeout, err := time.ParseDuration(idleTimeoutStr)\n\t\t\tif err != nil {\n\t\t\t\tfmt.Printf(\"Invalid idle timeout %s: %v\\n\\n\", idleTimeoutStr, err)\n\t\t\t\tcmd.HelpFunc()(cmd, args)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\topts, err := NewOptions(esType, triggerType, eventBusType, esName, sensorName, idleTimeout, noCleanUp)\n\t\t\tif err != nil {\n\t\t\t\tfmt.Printf(\"Failed: %v\\n\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tif hardTimeoutStr != \"\" {\n\t\t\t\thardTimeout, err := time.ParseDuration(hardTimeoutStr)\n\t\t\t\tif err != nil {\n\t\t\t\t\tfmt.Printf(\"Invalid hard timeout %s: %v\\n\\n\", hardTimeoutStr, err)\n\t\t\t\t\tcmd.HelpFunc()(cmd, args)\n\t\t\t\t\tos.Exit(1)\n\t\t\t\t}\n\t\t\t\topts.hardTimeout = &hardTimeout\n\t\t\t}\n\t\t\tctx := signals.SetupSignalHandler()\n\t\t\tif err = opts.Start(ctx); err != nil {\n\t\t\t\tpanic(err)\n\t\t\t}\n\t\t},\n\t}\n\trootCmd.Flags().StringVarP(&ebTypeStr, \"eb-type\", \"b\", \"\", \"Type of event bus to be tested: stan, jetstream\")\n\trootCmd.Flags().StringVarP(&esTypeStr, \"es-type\", \"e\", \"\", \"Type of event source to be tested, e.g. webhook, sqs, etc.\")\n\trootCmd.Flags().StringVarP(&triggerTypeStr, \"trigger-type\", \"t\", string(LogTrigger), \"Type of trigger to be tested, e.g. log, workflow.\")\n\trootCmd.Flags().StringVar(&esName, \"es-name\", \"\", \"Name of an existing event source to be tested\")\n\trootCmd.Flags().StringVar(&sensorName, \"sensor-name\", \"\", \"Name of an existing sensor to be tested.\")\n\trootCmd.Flags().StringVar(&idleTimeoutStr, \"idle-timeout\", \"60s\", \"Exit in a period of time without any active events or actions. e.g. 30s, 2m.\")\n\trootCmd.Flags().StringVar(&hardTimeoutStr, \"hard-timeout\", \"\", \"Exit in a period of time after the testing starts. e.g. 120s, 5m. If it's specified, the application will exit at the time either hard-timeout or idle-timeout meets.\")\n\trootCmd.Flags().BoolVar(&noCleanUp, \"no-clean-up\", false, \"Whether to clean up the created resources.\")\n\n\t_ = rootCmd.Execute()\n}\n", "package validator\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/argoproj/argo-events/pkg/apis/eventsource/v1alpha1\"\n)\n\nfunc TestValidateEventSource(t *testing.T) {\n\tdir := \"../../examples/event-sources\"\n\tdirEntries, err := os.ReadDir(dir)\n\tassert.Nil(t, err)\n\tfor _, entry := range dirEntries {\n\t\tif entry.IsDir() {\n\t\t\tcontinue\n\t\t}\n\t\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", dir, entry.Name()))\n\t\tassert.Nil(t, err)\n\t\tvar es *v1alpha1.EventSource\n\t\terr = yaml.Unmarshal(content, &es)\n\t\tassert.Nil(t, err)\n\t\tes.Namespace = testNamespace\n\t\tnewEs := es.DeepCopy()\n\t\tnewEs.Generation++\n\t\tv := NewEventSourceValidator(fakeK8sClient, fakeEventBusClient, fakeEventSourceClient, fakeSensorClient, es, newEs)\n\t\tr := v.ValidateCreate(contextWithLogger(t))\n\t\tassert.True(t, r.Allowed)\n\t\tr = v.ValidateUpdate(contextWithLogger(t))\n\t\tassert.True(t, r.Allowed)\n\t}\n}\n", "package validator\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/ghodss/yaml\"\n\t\"github.com/stretchr/testify/assert\"\n\tcorev1 \"k8s.io/api/core/v1\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\n\t\"github.com/argoproj/argo-events/common\"\n\teventbusv1alpha1 \"github.com/argoproj/argo-events/pkg/apis/eventbus/v1alpha1\"\n\t\"github.com/argoproj/argo-events/pkg/apis/sensor/v1alpha1\"\n)\n\nvar (\n\tfakeBus = &eventbusv1alpha1.EventBus{\n\t\tTypeMeta: metav1.TypeMeta{\n\t\t\tAPIVersion: eventbusv1alpha1.SchemeGroupVersion.String(),\n\t\t\tKind:       \"EventBus\",\n\t\t},\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: testNamespace,\n\t\t\tName:      common.DefaultEventBusName,\n\t\t},\n\t\tSpec: eventbusv1alpha1.EventBusSpec{\n\t\t\tNATS: &eventbusv1alpha1.NATSBus{\n\t\t\t\tNative: &eventbusv1alpha1.NativeStrategy{\n\t\t\t\t\tAuth: &eventbusv1alpha1.AuthStrategyToken,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tStatus: eventbusv1alpha1.EventBusStatus{\n\t\t\tConfig: eventbusv1alpha1.BusConfig{\n\t\t\t\tNATS: &eventbusv1alpha1.NATSConfig{\n\t\t\t\t\tURL:  \"nats://xxxx\",\n\t\t\t\t\tAuth: &eventbusv1alpha1.AuthStrategyToken,\n\t\t\t\t\tAccessSecret: &corev1.SecretKeySelector{\n\t\t\t\t\t\tKey: \"test-key\",\n\t\t\t\t\t\tLocalObjectReference: corev1.LocalObjectReference{\n\t\t\t\t\t\t\tName: \"test-name\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n)\n\nfunc TestValidateSensor(t *testing.T) {\n\tdir := \"../../examples/sensors\"\n\tdirEntries, err := os.ReadDir(dir)\n\tassert.Nil(t, err)\n\n\ttestBus := fakeBus.DeepCopy()\n\ttestBus.Status.MarkDeployed(\"test\", \"test\")\n\ttestBus.Status.MarkConfigured()\n\t_, err = fakeEventBusClient.ArgoprojV1alpha1().EventBus(testNamespace).Create(context.TODO(), testBus, metav1.CreateOptions{})\n\tassert.Nil(t, err)\n\n\tfor _, entry := range dirEntries {\n\t\tif entry.IsDir() {\n\t\t\tcontinue\n\t\t}\n\t\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", dir, entry.Name()))\n\t\tassert.Nil(t, err)\n\t\tvar sensor *v1alpha1.Sensor\n\t\terr = yaml.Unmarshal(content, &sensor)\n\t\tassert.Nil(t, err)\n\t\tsensor.Namespace = testNamespace\n\t\tnewSensor := sensor.DeepCopy()\n\t\tnewSensor.Generation++\n\t\tv := NewSensorValidator(fakeK8sClient, fakeEventBusClient, fakeEventSourceClient, fakeSensorClient, sensor, newSensor)\n\t\tr := v.ValidateCreate(contextWithLogger(t))\n\t\tassert.True(t, r.Allowed)\n\t\tr = v.ValidateUpdate(contextWithLogger(t))\n\t\tassert.True(t, r.Allowed)\n\t}\n}\n"], "filenames": ["common/util.go", "controllers/sensor/validate_test.go", "docs/sensors/triggers/http-trigger.md", "eventsources/common/naivewatcher/watcher_test.go", "eventsources/sources/amqp/validate_test.go", "eventsources/sources/awssns/start.go", "eventsources/sources/awssns/validate_test.go", "eventsources/sources/awssqs/validate_test.go", "eventsources/sources/azureeventshub/validate_test.go", "eventsources/sources/bitbucket/start.go", "eventsources/sources/bitbucket/validate_test.go", "eventsources/sources/bitbucketserver/start.go", "eventsources/sources/bitbucketserver/validate_test.go", "eventsources/sources/calendar/validate_test.go", "eventsources/sources/emitter/validate_test.go", "eventsources/sources/file/validate_test.go", "eventsources/sources/gcppubsub/validate_test.go", "eventsources/sources/generic/validate_test.go", "eventsources/sources/github/start_test.go", "eventsources/sources/github/validate_test.go", "eventsources/sources/gitlab/start.go", "eventsources/sources/gitlab/validate_test.go", "eventsources/sources/hdfs/validate_test.go", "eventsources/sources/kafka/validate_test.go", "eventsources/sources/minio/validate_test.go", "eventsources/sources/mqtt/validate_test.go", "eventsources/sources/nats/validate_test.go", "eventsources/sources/nsq/validate_test.go", "eventsources/sources/pulsar/validate_test.go", "eventsources/sources/redis/validate_test.go", "eventsources/sources/redisStream/validate_test.go", "eventsources/sources/resource/validate_test.go", "eventsources/sources/slack/start.go", "eventsources/sources/slack/start_test.go", "eventsources/sources/slack/validate_test.go", "eventsources/sources/storagegrid/start.go", "eventsources/sources/storagegrid/start_test.go", "eventsources/sources/storagegrid/validate_test.go", "eventsources/sources/stripe/start.go", "eventsources/sources/stripe/validate_test.go", "eventsources/sources/webhook/start.go", "eventsources/sources/webhook/validate_test.go", "hack/crds.go", "hack/gen-openapi-spec/main.go", "sensors/artifacts/file.go", "sensors/artifacts/file_test.go", "sensors/artifacts/git.go", "sensors/artifacts/s3.go", "sensors/artifacts/store_test.go", "sensors/artifacts/url.go", "sensors/triggers/argo-workflow/argo-workflow.go", "test/e2e/fixtures/given.go", "test/stress/main.go", "webhook/validator/eventsource_test.go", "webhook/validator/sensor_test.go"], "buggy_code_start_loc": [26, 21, 15, 5, 22, 26, 22, 22, 22, 23, 21, 25, 21, 22, 22, 22, 22, 6, 22, 22, 23, 22, 6, 22, 22, 22, 22, 22, 21, 22, 22, 22, 23, 25, 22, 23, 22, 22, 22, 22, 22, 22, 4, 5, 21, 20, 21, 22, 21, 5, 21, 4, 8, 5, 6], "buggy_code_end_loc": [263, 42, 262, 221, 39, 322, 40, 44, 40, 80, 39, 396, 39, 43, 39, 40, 39, 23, 133, 38, 91, 40, 23, 40, 39, 39, 39, 40, 38, 39, 39, 40, 277, 227, 39, 145, 121, 39, 101, 44, 109, 40, 47, 162, 43, 32, 226, 65, 78, 49, 140, 110, 678, 20, 66], "fixing_code_start_loc": [25, 21, 16, 4, 22, 26, 22, 22, 22, 23, 21, 25, 21, 22, 22, 22, 22, 6, 22, 22, 23, 22, 6, 22, 22, 22, 22, 22, 21, 22, 22, 22, 23, 25, 22, 23, 22, 22, 22, 22, 22, 22, 4, 4, 21, 19, 20, 22, 21, 5, 20, 4, 7, 5, 6], "fixing_code_end_loc": [262, 45, 260, 220, 39, 323, 40, 44, 40, 81, 39, 397, 39, 43, 39, 40, 39, 23, 133, 38, 91, 40, 23, 40, 39, 39, 39, 40, 38, 39, 39, 40, 277, 227, 39, 146, 121, 39, 101, 44, 110, 40, 47, 161, 43, 31, 225, 65, 78, 49, 139, 110, 677, 23, 69], "type": "CWE-787", "message": "Argo Events is an event-driven workflow automation framework for Kubernetes. Prior to version 1.7.1, several `HandleRoute` endpoints make use of the deprecated `ioutil.ReadAll()`. `ioutil.ReadAll()` reads all the data into memory. As such, an attacker who sends a large request to the Argo Events server will be able to crash it and cause denial of service. A patch for this vulnerability has been released in Argo Events version 1.7.1.", "other": {"cve": {"id": "CVE-2022-31054", "sourceIdentifier": "security-advisories@github.com", "published": "2022-06-13T20:15:07.897", "lastModified": "2023-01-10T20:45:13.720", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Argo Events is an event-driven workflow automation framework for Kubernetes. Prior to version 1.7.1, several `HandleRoute` endpoints make use of the deprecated `ioutil.ReadAll()`. `ioutil.ReadAll()` reads all the data into memory. As such, an attacker who sends a large request to the Argo Events server will be able to crash it and cause denial of service. A patch for this vulnerability has been released in Argo Events version 1.7.1."}, {"lang": "es", "value": "Argo Events es un marco de automatizaci\u00f3n del flujo de trabajo basado en eventos para Kubernetes. En versiones 1.7.1, varios endpoints de \"HandleRoute\" hac\u00edan uso del obsoleto \"ioutil.ReadAll()\". \"ioutil.ReadAll()\" lee todos los datos en memoria. Por lo tanto, un atacante que env\u00ede una petici\u00f3n grande al servidor de Argo Events podr\u00e1 bloquearlo y causar una denegaci\u00f3n de servicio. Ha sido publicado un parche para esta vulnerabilidad en versi\u00f3n 1.7.1 de Argo Events"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-787"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-400"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:argo_events_project:argo_events:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.7.1", "matchCriteriaId": "A667F219-0024-441E-9D44-0336D782C472"}]}]}], "references": [{"url": "https://github.com/argoproj/argo-events/commit/eaabcb6d65022fc34a0cc9ea7f00681abd326b35", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/argoproj/argo-events/issues/1946", "source": "security-advisories@github.com", "tags": ["Issue Tracking", "Third Party Advisory"]}, {"url": "https://github.com/argoproj/argo-events/pull/1966", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/argoproj/argo-events/security/advisories/GHSA-5q86-62xr-3r57", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/argoproj/argo-events/commit/eaabcb6d65022fc34a0cc9ea7f00681abd326b35"}}